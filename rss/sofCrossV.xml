<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 15 Dec 2023 15:13:49 GMT</lastBuildDate>
    <item>
      <title>列与行匹配时的边际同质自由度（在 R 中）</title>
      <link>https://stats.stackexchange.com/questions/634999/marginal-homogeneity-degrees-of-freedom-when-column-matches-a-row-in-r</link>
      <description><![CDATA[我正在进行分析，并且第一次使用边际同质性/斯图尔特·麦克斯韦。这是一个前后测试，在分析次要结果时我遇到了一个问题。我使用命令“StuartMaxwellTest()”、“stuart.maxwell.mh()”和“ ;mh_test()”。对于我的所有结果，这三个包除了一个之外都一致。
这是我正在分析的表格：
&lt;前&gt;&lt;代码&gt;&gt;情绪化
   
     1 2 3 4
  1 1 0 0 0
  2 0 4 5 0
  3 0 0 23 6
  4 0 0 1 12

问题是第一行/列。
以下是测试结果：
&lt;前&gt;&lt;代码&gt;&gt;斯图尔特麦克斯韦测试(Emo)

    斯图尔特-麦克斯韦测试

数据：情绪
卡方 = 8.5714，df = 3，p 值 = 0.03557

&lt;前&gt;&lt;代码&gt;&gt;斯图尔特·麦克斯韦.mh(Emo)
solve.default(smS) 中的错误：
  Lapack 例程 dgesv：系统完全是奇异的：U[1,1] = 0

&lt;前&gt;&lt;代码&gt;&gt; mh_test（情绪）

    渐近边际齐性检验

数据：条件响应（Var1、Var2）
     按块分层
卡方 = 8.5714，df = 2，p 值 = 0.01376

警告信息：
在 .local(.Object, ...) 中：
  条件协方差矩阵的对角线元素为零

回顾一下：第一个包正常分析它。第二个包未完成测试。我认为第三个包忽略第一列/行并将其视为 3x3 表 *因此 df = 2。
有人知道我应该使用哪个测试结果吗？我倾向于第一个，因为它似乎是最保守的，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/634999/marginal-homogeneity-degrees-of-freedom-when-column-matches-a-row-in-r</guid>
      <pubDate>Fri, 15 Dec 2023 15:12:19 GMT</pubDate>
    </item>
    <item>
      <title>（也许很愚蠢）关于蒙特卡罗模拟的问题</title>
      <link>https://stats.stackexchange.com/questions/634997/perhaps-dumb-question-about-monte-carlo-simulation</link>
      <description><![CDATA[我正在尝试蒙特卡罗模拟，对该方法对我的特定问题的适用性有疑问。
在这个问题中，我有一个参数“Phi”这是正态分布的。然后，我运行多次模拟来随机生成遵循正态分布的 Phi 值（使用 SMath，就像 Mathcad 一样）。到目前为止，一切都很好;然而，我在概念上遇到的问题是下一步。
为了解决我的问题，我需要采用随机生成的 Phi 值，并使用非线性变换函数来计算新参数“Ny”。 Ny 的方程涉及指数和项的平方。然后我使用这个新参数来计算最终答案。如果有帮助的话，那就是土壤的承载力问题，其中沙子的极限承载力为 Q = 0.5 x 基础宽度 x 土壤单位重量 x Ny。
Ny = (Nq-1)tan(1.4Phi)
Nq = exp((πtan(Φ)(tan((π/4)+1/2*(Φ)))^2
当我检查结果时，我注意到 Ny 的期望值应该约为 26.2（直接使用平均 Phi 计算时）；然而，使用随机生成的 Phi 值时，经过 10,000 次模拟后，Ny 的平均值为 31.3。当然，这意味着预期结果与蒙特卡罗模拟得到的结果不同。考虑到这一点，Phi 到 Ny 的变换使用了非线性方程，因此这种差异应该不会令人意外。然而，我不知道这是否意味着蒙特卡罗模拟因此不适用于这个特定问题。我已经看到更简单的点估计方法用于解决相同的问题，并且我注意到这种非线性变换也应该影响结果，但我已经看到了使用该方法的几个已发布的解决方案，所以这让我想知道......
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/634997/perhaps-dumb-question-about-monte-carlo-simulation</guid>
      <pubDate>Fri, 15 Dec 2023 15:00:08 GMT</pubDate>
    </item>
    <item>
      <title>箱线图中未见统计显着差异</title>
      <link>https://stats.stackexchange.com/questions/634996/statistical-significant-difference-not-seen-in-box-plot</link>
      <description><![CDATA[我对如何解释这些数据有疑问：

当两种方法A和B应用于不同的数据集时，我必须对其进行比较（假设$ x_1$ 和 $x_2$）。

A 充满噪音且混乱，因此我们的假设是 A 的重复性较差：$\mathbf{ A}(x_1)$ 与 $\mathbf{A}(x_2)$ 显着不同。

我们的方法B总体上给出了更好的结果（参见小提琴图）。但在比较统计分析时，我们发现B比A有更多显着差异（图中用“***”表示）。


我可以假设 A 不会因为其噪声行为（并且可能样本量较小）而导致显着差异吗？如果我没有更多数据，有没有办法让审阅者相信我们的方法在不同数据集上更具可重复性？
顺便说一句，图中显示了 18 个区域。每把小提琴都显示了左侧 $x_1$ 和左侧 $x_2$ 的方法。正确的。我很想看到更多的明星“*”在下一个。
我知道我不应该过多关注图来查看 SS 差异，但我可以帮助注意到，即使是小提琴中的样本在顶部子图上也是相似的，而它们在下部子图上分布得更广。&lt; /p&gt;

这里的另一个选择是我只是错误地计算了 t 检验。我正在使用配对样本 t 检验，因为我们的 $x_1$ 和 $x_2$ 数据集是相同的数据集，但何时是另一个数据集的简化版本。]]></description>
      <guid>https://stats.stackexchange.com/questions/634996/statistical-significant-difference-not-seen-in-box-plot</guid>
      <pubDate>Fri, 15 Dec 2023 14:53:08 GMT</pubDate>
    </item>
    <item>
      <title>分析微生物组和临床数据以预测事件</title>
      <link>https://stats.stackexchange.com/questions/634994/analyzing-microbiome-and-clinical-data-for-event-prediction</link>
      <description><![CDATA[我正在纵向研究中分析临床数据和复杂的微生物组数据。我已经在基线以及基线和“事件”之间比较了不同的组。使用线性混合模型 (LMM) 和基于排列的分析。
现在，我想探索预测建模。在研究期间，一些参与者遇到了“事件”。我想使用可解释的机器学习来对这些事件的风险进行建模，并找到风险临床/微生物组风险因素。
到目前为止我对此一无所知，但愿意学习 - 哪里是一个好的起点？
我正在与 R 合作。
谨致问候并感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/634994/analyzing-microbiome-and-clinical-data-for-event-prediction</guid>
      <pubDate>Fri, 15 Dec 2023 14:16:08 GMT</pubDate>
    </item>
    <item>
      <title>建模或数据错误导致重复测量的 GLMM (lme4) 中存在较大标准误差</title>
      <link>https://stats.stackexchange.com/questions/634993/modeling-or-data-error-causing-large-standard-errors-in-glmm-lme4-with-repeate</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/634993/modeling-or-data-error-causing-large-standard-errors-in-glmm-lme4-with-repeate</guid>
      <pubDate>Fri, 15 Dec 2023 14:07:33 GMT</pubDate>
    </item>
    <item>
      <title>当存在明显的依赖性时，我的回归 MLP 没有得到训练 [重复]</title>
      <link>https://stats.stackexchange.com/questions/634991/my-regression-mlp-is-not-getting-trained-when-theres-a-clear-dependence</link>
      <description><![CDATA[我正在尝试创建一个回归 MLP 来使用输入数据（我将其称为指标）来预测某个参数。下面我列出了指标 1 至 4 以及参数 1 和 2 的 570 个条目对应的图表。

正如所见，指标和参数 1 之间存在很强的依赖性，但参数 2 之间的依赖性并不强。我创建了一个 MLP，它对以下项使用重复 K 折交叉验证（10 折，5 次重复）模型：输入暗淡：4，隐藏层暗淡：4（relu激活），输出层暗淡：1，优化器：adam，损失：mean_absolute_error_percentage（我选择这个只是为了更好地理解）。我得到的平均最终验证损失的结果是：

参数 1：平均值：37.780 SD：18.929（使用 0.2 的 dropout 时，平均值约为 30%）
参数 2：平均值：13.796 SD：3.824（使用 0.2 的 dropout 时，平均值约为 10%）

我使用不同数量的隐藏层（1,2,3）和每层感知器（1到10）、不同的dropout值（0.2到0.5）、不同的学习率（0.01、0.001、 0.0001），但在参数 2 的验证中总是至少有 20-25% 的低误差。我觉得这是因为 MLP 中存在一个我无法弄清楚的大缺陷，或者是预期的？&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/634991/my-regression-mlp-is-not-getting-trained-when-theres-a-clear-dependence</guid>
      <pubDate>Fri, 15 Dec 2023 14:05:25 GMT</pubDate>
    </item>
    <item>
      <title>使用判别性损失进行实例分割？</title>
      <link>https://stats.stackexchange.com/questions/634984/instance-segmentation-using-a-discriminative-loss</link>
      <description><![CDATA[我一直在阅读这篇论文，我想知道他们的判别性损失定义是否正确分段？
据我了解，他们将图像像素映射到更高的维度，并尝试根据它们所属的实例对它们进行聚类。有一个损失项“拉动”损失。属于同一类别的像素嵌入朝向其平均值（L_var），而另一个术语“推动”不同实例的away 平均值(L_dist)。


但问题是，这是一个分类设置，其中我们的类数量有限。但在实例分割中，每个实例应该有自己独立的簇，这很容易遇到维数灾难问题。此外，该函数如何在推理过程中将看不见的实例映射到其自己的单独集群？
我认为损失函数实际上是根据实例的外观以及图像中像素的位置对实例进行分类。因此，看起来相似且重叠的实例始终是该模型的错误来源。
如果有人能阐明这一点，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/634984/instance-segmentation-using-a-discriminative-loss</guid>
      <pubDate>Fri, 15 Dec 2023 11:46:43 GMT</pubDate>
    </item>
    <item>
      <title>马歇尔·奥尔金算法 R [关闭]</title>
      <link>https://stats.stackexchange.com/questions/634983/marshall-olkin-algorithm-r</link>
      <description><![CDATA[您知道如何使用第 29 页（Cholesky 分解）中提供的广义 Marshall-Olkin 算法在 R-Studio 中模拟 Clayton Copula 样本https://people.math.ethz.ch/~embrecht/ftp/copchapter.pdf?]]></description>
      <guid>https://stats.stackexchange.com/questions/634983/marshall-olkin-algorithm-r</guid>
      <pubDate>Fri, 15 Dec 2023 11:30:23 GMT</pubDate>
    </item>
    <item>
      <title>使用重复测量设计的 gamlss 进行前高斯模型拟合的随机效应[关闭]</title>
      <link>https://stats.stackexchange.com/questions/634982/random-effects-in-ex-gaussian-model-fitting-using-gamlss-with-a-repeated-measure</link>
      <description><![CDATA[我有一个重复测量设计，其中包含目标类型（箭头与注视）和一致性（一致与不一致）等因素，因此每个主题 (id) 都会在每个条件下进行测量。
我正在尝试使用“gamlss”拟合前高斯模型包，允许每个主题在 mu 参数中的 TargetType 和 Congruency 条件上有所不同，但我遇到了一些错误。我正在尝试两种不同的随机效果语法，它们对吗？
模型1：
m1 &lt;- gamlss(RT ~ TargetType * 一致性 + re(random = list(id = pdDiag(~1 + TargetType + Congruency))), data = adhd_exG, family = exGAUS(), control = gamlss.control(n.cyc = 1000))

M1错误：
&lt;块引用&gt;
lme.formula 中的错误（fixed = fix.formula，data = Data，random = random，：
nlminb 问题，收敛错误代码 = 1
message = 达到迭代限制但未收敛 (10)

模型2：
m2 &lt;- gamlss(RT ~ TargetType * 一致性 + re(random = list(id = ~TargetType, id = ~ Congruency)), data = adhd_exG, family = exGAUS(), control = gamlss.控制（n.cyc = 1000））

错误M2：
&lt;块引用&gt;
lme.formula 中的错误（fixed = fix.formula，data = Data，random = random，：
nlminb 问题，收敛错误代码 = 1
message = 达到迭代限制但未收敛 (10)

尽管我已将 n.cyc 更改为 1000，但仍然收到错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/634982/random-effects-in-ex-gaussian-model-fitting-using-gamlss-with-a-repeated-measure</guid>
      <pubDate>Fri, 15 Dec 2023 11:12:51 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么 ES 对干预组和对照组进行前后研究的多级荟萃分析（metafor 包）？</title>
      <link>https://stats.stackexchange.com/questions/634981/what-es-should-i-use-for-a-multilevel-meta-analysis-metafor-package-of-pre-pos</link>
      <description><![CDATA[我们对研究体育锻炼对工人疼痛和残疾的影响进行了系统回顾，并要求我们对数据进行荟萃分析来补充它。
因此，我们选择了以干预组和对照组为特色的研究，并报告了干预前和干预后的措施。
我们拥有的变量是：
&lt;前&gt;&lt;代码&gt;me_pre_int
sd_pre_int
me_post_int
sd_post_int
数字整数

我_pre_c
sd_pre_c
me_post_c
sd_post_c
数字c

干预/实验组和对照组的平均值、标准差和样本量。
我应该使用什么 ES 指标来进行荟萃分析？我们对不同的疼痛程度有不同的测量，因此我们可能需要标准化的平均差，但我不确定该使用什么。
我应该只比较实验组和对照组之间的干预后数据吗？
或者我是否需要计算干预组和对照组的变化分数，然后比较两者？
我正在使用metafor包，所以它基本上可以归结为我应该在escalc()函数中输入哪些数据。
如有必要，我很乐意提供更多详细信息。
我知道 escalc 的选项之一是计算平均变化分数，但它需要数据的相关性，而我没有用于任何研究。
此外，未报告前后差异的标准差。]]></description>
      <guid>https://stats.stackexchange.com/questions/634981/what-es-should-i-use-for-a-multilevel-meta-analysis-metafor-package-of-pre-pos</guid>
      <pubDate>Fri, 15 Dec 2023 11:10:30 GMT</pubDate>
    </item>
    <item>
      <title>消除自变量对因变量的影响</title>
      <link>https://stats.stackexchange.com/questions/634980/remove-effect-of-an-independent-variable-on-a-dependent-one</link>
      <description><![CDATA[目前，我们正在使用 1 公斤重的砖块进行重量测量，作为校准方法。然而，传感器返回的最终重量不是1kg，而是随着环境温度的变化而变化，这可能是由于传感器估计重量的方式所致（我附上了图表上缩放的数据）。

我们希望返回的测量值不受温度的影响，即我们期望一条水平线，因为砖块的重量不会改变。为此，应消除温度对最终重量的影响。这个想法是从植物等其他来源进行测量，这样温度对秤所标记的重量的影响可能会导致将来在处理数据时出现错误的估计。
为此，我尝试运行回归模型，估计温度随时间对体重的影响。估计后，我用中值或最高温度等值保持温度恒定，以便重量保持恒定。另一个想法是减去温度对实际重量测量的估计影响（从线性回归），以便重量也保持恒定。但是，我不确定这些方法是否足够，对于如何实现这一目标有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634980/remove-effect-of-an-independent-variable-on-a-dependent-one</guid>
      <pubDate>Fri, 15 Dec 2023 10:45:50 GMT</pubDate>
    </item>
    <item>
      <title>应该使用哪个数学领域来形式化数据集“几何”结构的分析[关闭]</title>
      <link>https://stats.stackexchange.com/questions/634973/which-field-of-mathematics-should-be-used-to-formalize-the-analysis-of-a-dataset</link>
      <description><![CDATA[我想知道是否可以应用数学形式主义来理解“几何”概念。实验数据集的结构，尤其是。其分类预测变量之间的关系。
&lt;小时/&gt;
首先，定义术语......
交叉与嵌套与嵌套分类预测器

交叉预测变量的每个级别在另一个预测变量的每个级别都有一个测量值。
嵌套预测器的每个级别在另一个预测器的至少两个唯一级别中都有一个测量值。
嵌套预测器的每个级别仅在另一个预测器的一个级别中具有测量值。

在此处显示的图片中，预测变量 A 和 B 相互交叉，预测变量 C 相对于 D 嵌套，预测变量 D 嵌套在 C 内。

请注意，嵌套预测器的级别必须使用唯一的标识号进行编码，否则计算机无法知道它们是嵌套的。
&lt;小时/&gt;
第二，一些例子......
最基本的“复杂”是我可以在这里展示的设计具有三个分类预测变量。由于这篇文章不能太长，因此我将使用速记图形符号，并用箭头连接预测变量来描述交叉/嵌套/嵌套成对关系。双向箭头表示交叉预测变量，单向虚线箭头表示嵌套预测变量。
我看到三个分类预测变量的四种可能组合......

&lt;小时/&gt;
以下是一些可以提出的问题（结合我的想法）：

这种“几何”可以吗？预测信息，例如数据集结构，用于在程序上指定给定实验的设计矩阵？ （是）
是否有任何数学规则，例如嵌套预测器的传递性，可以证明吗？ （我不知道）
仅成对关系就足以指定设计矩阵，还是需要更高维度的分析？这个问题的答案能以某种方式得到证明吗？ （在某些情况下仅成对分析是不够的，但我不知道为什么）
]]></description>
      <guid>https://stats.stackexchange.com/questions/634973/which-field-of-mathematics-should-be-used-to-formalize-the-analysis-of-a-dataset</guid>
      <pubDate>Fri, 15 Dec 2023 08:05:54 GMT</pubDate>
    </item>
    <item>
      <title>分析 Attrak Diff 问卷结果时，Tukey 检验中 R 为正估计，但 p 值不显着</title>
      <link>https://stats.stackexchange.com/questions/634965/tukey-test-in-r-positive-estimate-but-non-significant-p-value-when-analyzing-att</link>
      <description><![CDATA[我是一名硕士生，正在分析我的用户研究中的 Attrak Diff 调查问卷结果。我没有统计学背景，我很难解释我的结果。
我以一种方式重复测量方差分析并获得显着的 p 值，因此我运行 Tukey 来查看四个问卷类别中哪一个具有显着差异。
我现在很困惑，因为其中两个估计值是正值（根据我的阅读，这意味着显着差异？），但只有其中一个 p 值是显着的。在讨论估计值时，我遇到过诸如“可检测差异”之类的措辞，但这只会让我更加困惑。我在这里找不到任何与我的情况完全匹配的问题。
如何准确描述我的结果？


这是我的 R 代码：
g &lt;- glht(M,linfct=mcp(&#39;quality&#39;=&#39;Tukey&#39;))
概要(g)
]]></description>
      <guid>https://stats.stackexchange.com/questions/634965/tukey-test-in-r-positive-estimate-but-non-significant-p-value-when-analyzing-att</guid>
      <pubDate>Fri, 15 Dec 2023 03:00:50 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 R 中的 Tidymodels 解决多项分类模型中因变量中的许多因素？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/633767/how-can-i-address-many-factors-in-the-dependent-variable-in-a-multinomial-classi</link>
      <description><![CDATA[我在 R 中的多项分类模型上遇到了很大的困难。
我有一个 1330 行的数据集。我有两个自变量和一个因变量。
因变量（类别）有 337 个唯一值。
它们分为：
102个值32个值14个值12个值11个值9个值8个值7个值6个值5个值（重复直到完成）
我基本上很难创建任何模型，因为它们都会针对因变量的训练和测试集中的不平衡水平发出警告或错误。
我尝试在initial_split中的strata参数中添加类别，但它说“数据太少，无法分层”
我在配方中尝试了各种重采样参数，但没有一个起作用（参见代码）。
随机森林和 XGBoost 都“有效”但准确性和其他指标都非常低于标准。
我在这里看到了类似的问题，但它与自变量有关。
我的与目标变量有关。
解决我所面临的因变量问题的最佳方法是什么？
我知道您通常需要完整的代码示例，但我觉得这只是理论上的。
感谢您提供的任何意见。
编辑：我想这个问题由于缺乏清晰度而被关闭。我会再试一次。

有没有办法可以将类别中的 337 种类型减少到更易于管理的类型？

这种减少是否仍然允许建立有意义的模型，或者我是否会过多地污染数据？


&lt;前&gt;&lt;代码&gt;
设置.种子(123)

data_split &lt;-initial_split(model_data,
                            道具= 0.7，
                            阶层 = 类别）

训练集 &lt;- 训练（data_split）
test_set &lt;- 测试（data_split）

model_recipe &lt;- 配方（类别 ~ .，数据 = 训练集） %&gt;%
  step_novel(all_nominal_predictors()) %&gt;%
  step_dummy(all_nominal_predictors()) %&gt;%
  step_scale(all_numeric_predictors())
  #step_rose(类别)
  # step_downsample(类别)
  # step_smote(类别)
]]></description>
      <guid>https://stats.stackexchange.com/questions/633767/how-can-i-address-many-factors-in-the-dependent-variable-in-a-multinomial-classi</guid>
      <pubDate>Tue, 12 Dec 2023 23:59:48 GMT</pubDate>
    </item>
    <item>
      <title>混合数据类型的评估者间可靠性？</title>
      <link>https://stats.stackexchange.com/questions/633757/inter-rater-reliability-for-mixed-data-types</link>
      <description><![CDATA[我对统计学非常陌生，我需要帮助确定问卷的最佳相互可靠性测试。我的调查问卷将由三位评估者进行评估。我只是提供我的调查问卷样本及其外观：
dat = data.frame(rater1 =
                   c(3,3.2,4,4,2.4,3,&#39;Y&#39;),
                 评分者2 =
                   c(4,1,3,4,3,2,&#39;N&#39;),
                 评分者3 =
                   c(1,1,4,1,2,1,&#39;Y&#39;)
）

评估混合数据类型调查问卷相互可靠性的最佳方法是什么？我怎样才能知道最大的分歧来自哪里？例如，它是#1，其中rater1=3、rater2=4、rater3=1。我怎么知道这是导致最大差异的问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/633757/inter-rater-reliability-for-mixed-data-types</guid>
      <pubDate>Tue, 12 Dec 2023 22:22:29 GMT</pubDate>
    </item>
    </channel>
</rss>