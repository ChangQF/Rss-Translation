<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 07 Jan 2025 15:59:49 GMT</lastBuildDate>
    <item>
      <title>多元线性回归，得出 $\beta$ 的精确置信集</title>
      <link>https://stats.stackexchange.com/questions/659668/multiple-linear-regression-deriving-an-exact-confidence-set-for-beta</link>
      <description><![CDATA[我正在研究统计学习要素。对于多元线性回归，他们假设输出向量满足$ Y = X\beta + \epsilon$，其中$X \in \mathbb R^{N \times (p+1)}$和$\beta \in \mathbb{R}^{p+1}$是固定的，并且$\epsilon \sim \mathrm{Norm}(0, \sigma^2 I_N)$。
然后他们给出了$\hat\beta = (X^T X)^{-1} X^{T} Y$和$\hat\sigma^2 = \frac{1}{N-p-1} \|Y - X\hat\beta\|^2$，即
$$
\hat\beta \sim \mathrm{Norm}(\beta, (X^T X)^{-1}\sigma^2) \quad\text{and}\quad (N-p-1)\hat\sigma^2 \sim \sigma^2 \chi_{N-p-1}^2。
$$
最后，他们指出（公式 3.15），对于 $\beta$，近似 $1-\alpha$ 置信集由
$$
\{ \beta : (\hat\beta-\beta)^T X^T X(\hat\beta -\beta) \le \hat\sigma^2 \chi_{p+1,1-\alpha}^2\} 给出。
$$
我理解这是一个近似的 $1-\alpha$ 置信集，而用 $\sigma^2$ 替换 $\hat\sigma^2$ 会给出一个精确的 $1-\alpha$ 置信集。
但是，我想知道是否有可能在不知道 $\sigma^2$ 的情况下为 $\beta$ 得出一个精确的 $1-\alpha$ 置信集。
我在这个答案中看到
$$
\frac{(\hat{\beta}-\beta)^TX^TX(\hat{\beta}-\beta)}{(p+1)\hat{\sigma}^2}\sim F_{p+1,N-p-1},
$$
这根据上面给出的分布以及$\hat\beta$和$\hat\sigma^2$是独立的这一事实得出。由此，我们可以说
$$
\{ \beta : (\hat{\beta}-\beta)^TX^TX(\hat{\beta}-\beta) \le (p+1)\hat\sigma^2F_{p+1, N-p-1, 1-\alpha}\}
$$
是 $\beta$ 的精确 $1-\alpha$ 置信集吗？如果是这样，使用上述近似置信集而不是这个精确置信集有什么好处？]]></description>
      <guid>https://stats.stackexchange.com/questions/659668/multiple-linear-regression-deriving-an-exact-confidence-set-for-beta</guid>
      <pubDate>Tue, 07 Jan 2025 15:15:59 GMT</pubDate>
    </item>
    <item>
      <title>混合模型：在 R 中探究聚类内中心化后一级分类变量之间的相互作用</title>
      <link>https://stats.stackexchange.com/questions/659667/mixed-model-probing-an-interaction-between-level-1-categorical-variables-after</link>
      <description><![CDATA[我有以下模型：
model &lt;- lmer(scores ~glasses + D1 + D2 +glasses:D1 +glasses:D2 + (1|participantNumber),data,REML = FALSE)


参与者在戴或不戴眼镜（关 = 0，开 = 1）的情况下完成了一项任务的试验，并且分为三个难度级别（简单 = 0，中等 = 1，困难 = 2）

两个 1 级预测因子（眼镜和任务难度）在概念上都是分类的，但已在集群内居中，因此它们现在是“连续的”


我如何评估每个任务难度级别上分数和眼镜之间的关系？
由于我的预测因子现在是“连续”，我使用 Johnson-Neyman 方法来探测交互作用（使用 interactions 包）。但是，我想报告诸如 t 统计量之类的值，但除非我“选择一个点”，否则我无法这样做，但我不知道该选择哪个点，因为数字范围很广。
例如，在常规回归中，我的虚拟编码变量对于所有参与者都如下所示：



任务难度
D1
D2
D1b
D2b
D1c
D2c




简单
0
0
0
1
1
0


中等
 1
0
0
0
0
1


困难
0
1
0
0
0



之后在集群内居中，参与者有不同的虚拟编码值：
参与者 1



任务难度
D1
D2
D1b
D2b
D1c
D2c




容易
-0.33
-0.33
-0.33
+0.67
+0.67
-0.33


中等
+0.67
-0.33
-0.33
-0.33
-0.33
+0.67


困难
-0.33
+0.67
+0.67
-0.33
-0.33
-0.33



参与者22



任务难度
D1
D2
D1b
D2b
D1c
D2c




简单
-0.48
-0.05
-0.05
+0.95
+0.52
-0.48


中等
+0.52
-0.05
-0.05
-0.05
-0.48
+0.52


困难
-0.48
+0.95
+0.95
-0.05
-0.48
-0.48



因此， Johnson-Neyman 方法告诉我，分数和眼镜之间的关系取决于 D1/D2 是负数还是正数。
probe_interaction(model, pred =glasses, modx = D1, data,
confint=TRUE, cond.int=TRUE, interval=TRUE,
centered=&quot;none&quot;, johnson_neyman=TRUE, jnplot=TRUE)

probe_interaction(model, pred =glasses, modx = D2, data,
confint=TRUE, cond.int=TRUE, interval=TRUE,
centered=&quot;none&quot;, johnson_neyman=TRUE, jnplot=TRUE)

但是，要报告 t 统计量，例如在评估简单任务难度下的分数和眼镜之间的关系时，我不知道如何选择“0” 表示简单条件，因为“0”在一个参与者中为 -0.33，在另一个参与者中为 -0.48。
任何指导（统计或要使用的函数）都值得赞赏，提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/659667/mixed-model-probing-an-interaction-between-level-1-categorical-variables-after</guid>
      <pubDate>Tue, 07 Jan 2025 15:05:35 GMT</pubDate>
    </item>
    <item>
      <title>GAM 中相互作用项的意义</title>
      <link>https://stats.stackexchange.com/questions/659666/significance-of-interaction-term-in-gam</link>
      <description><![CDATA[我有一个广义加性模型，其形式如下：
$E[Y] = \beta_0 + f(X_1) + \beta_2X_2 + f(X_1)\times X_2$
其中 $f(X_1)=\sum^n_i\beta_i\boldsymbol{B}_i(X_{1i})$ 是平滑函数，$\boldsymbol{B}(\cdot)$ 是用于平滑连续协变量 $X_1$ 的基函数（例如三次样条函数），$f(X_1)\times X_2$ 是平滑的 $X_1$ 和二元协变量 $X_2$ 之间的交互项。
我感兴趣的是测试 $X_1$ 和 $X_2=0$ 之间的交互是否与 $X_1$ 和 $X_2=1$ 之间的交互有显著不同，例如测试两个相互作用的斜率是否显著不同。
如果这是一个 GLM，其中人们使用 $X_1$ 而不应用基函数，则可以通过比较两个不同相互作用的参数直接推断出差异（分别为 $X_2=0$ 和 $X_2=1$）。现在涉及到样条函数，我们总共有 $2n$ 个交互项（$n$ 个基函数，每个基函数与两个条件交互）及其相应的系数，我不再确定如何测试交互是否因条件 $X_2$ 而显著不同。
当连续协变量被多个基函数“分割”为区间，并且这些区间与二元协变量的两个级别交互时，如何测试显著交互？特别是在不使用 LRT 或需要拟合嵌套模型的类似方法的情况下。使用例如 Wald 检验来测试两组参数是否显著不同或逐一比较系数是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/659666/significance-of-interaction-term-in-gam</guid>
      <pubDate>Tue, 07 Jan 2025 14:55:32 GMT</pubDate>
    </item>
    <item>
      <title>GARCH 和 Granger 因果关系检验</title>
      <link>https://stats.stackexchange.com/questions/659665/garch-and-granger-causality-test</link>
      <description><![CDATA[我正在尝试重新创建论文&quot;金融和保险行业连通性和系统性风险的计量经济学测量&quot;（开放获取版本此处）来自 Billio 等人（2012 年）的研究，使用 R 中的欧洲股票数据。
他们使用 Granger 因果关系检验来估计金融机构之间的联系。此外，他们还考虑了广义自回归条件异方差 GARCH(1,1) 收益模型，以控制异方差。
我是否正确地理解了作者首先拟合 GARCH(1,1) 模型，例如：
garch_spec &lt;- rugarch::ugarchspec(mean.model = list(armaOrder = c(0, 0)),
variance.model = list(model = &quot;sGARCH&quot;, garchOrder = c(1, 1)),
distribution.model = &quot;sstd&quot;)

garch_fit1 &lt;- rugarch::ugarchfit(spec = garch_spec, data = stock_return_bank1,solver = &quot;hybrid&quot;)
garch_fit2 &lt;- rugarch::ugarchfit(spec = garch_spec, data = stock_return_bank2,solver = &quot;hybrid&quot;)

然后使用残差估计 Granger 因果关系？
residuals1 &lt;- residuals(garch_fit1, standardize = TRUE)
residuals2 &lt;- residuals(garch_fit2, standardize = TRUE)

test_result &lt;- lmtest::grangertest(formula = residuals2 ~ residuals1, order = XYZ, test = &quot;F&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/659665/garch-and-granger-causality-test</guid>
      <pubDate>Tue, 07 Jan 2025 13:56:51 GMT</pubDate>
    </item>
    <item>
      <title>Pickands-Balkema-De Haan 定理、依赖性和改组</title>
      <link>https://stats.stackexchange.com/questions/659664/pickands-balkema-de-haan-theorem-dependence-and-shuffling</link>
      <description><![CDATA[Pickands-Balkema-de Haan 定理指出，条件超额分布函数可以通过广义帕累托分布很好地近似（对于高超额，并且如果底层 RV 可以缩放和规范化，以便条件超额分布函数具有非退化极限）。所以
$\mathbb{P}(X-u\leq y \, \vert\, X &gt; u) \xrightarrow{u \to \infty} G_{\xi, \sigma}$，其中 $G_{\xi, \sigma}$ 是 GPD。
在极值数据分析中，样本 $X_i$ 通常被假定为 $i.i.d.$，然后超过某个高阈值的点 $u$ 用于通过最大似然法拟合参数 $\xi, \sigma$。
该定理有一个针对弱相关样本的版本，在实践中，人们会确定超过阈值的点簇，然后将上述定理仅应用于这些簇的均值或最大值，然后假定这些簇为$i.i.d$。但这会引入一个额外的参数，用于估计“聚类强度”。
那么为什么需要进行去聚类？上述定理仅对条件超额分布的尾部做出陈述。因此，如果我有一个样本概率分布，我可以只取相关样本的时间序列，对其进行混洗，这样新样本就不相关，并且概率分布的尾部看起来会相同，因此在拟合时会给我完全相同的$\xi, \sigma$。
那么我的推理到底哪里出了问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659664/pickands-balkema-de-haan-theorem-dependence-and-shuffling</guid>
      <pubDate>Tue, 07 Jan 2025 12:53:35 GMT</pubDate>
    </item>
    <item>
      <title>非对称独立变量的排序</title>
      <link>https://stats.stackexchange.com/questions/659660/ranks-for-an-asymmetric-independent-variable</link>
      <description><![CDATA[我正在使用回归模型分析数据，其中感兴趣的变量是一种治疗方法，我想估计其效果。我打算调整一组协变量的估计值，包括两个生物标志物。这些生物标志物的分布高度偏斜（大多数个体的值介于 0 和 1 之间，少数个体的值超过 10,000）。最初，我考虑将生物标志物值分为 4 组，这是一种常见的方法。后来，我考虑使用等级，因为与分类相比，这可能会减少丢失的信息量。虽然这会降低参数的可解释性（使用类别更清晰，但使用等级则不那么清晰），但我的主要目标是进行调整，以便更好地估计感兴趣的变量的效果。
您觉得如何？这种方法能带来优势吗？您知道任何描述这种方法的资源吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659660/ranks-for-an-asymmetric-independent-variable</guid>
      <pubDate>Tue, 07 Jan 2025 11:54:44 GMT</pubDate>
    </item>
    <item>
      <title>回归反应的统计比较</title>
      <link>https://stats.stackexchange.com/questions/659658/statistical-comparison-of-regressed-responses</link>
      <description><![CDATA[我记录了 5000 个事件。每个事件属于 50 个细胞中的一个（$C$），并且相对于其基线幅度（$X$）具有相应的响应幅度（$Y$）。每个细胞还属于 $3$ 个组中的一个（$T$）。我想测试在考虑基线后，每个组的响应幅度是否显著不同。我该怎么做？我原本想从 $Y \sim 1 + X + (1|C)$ 中收集每组细胞的随机效应估计值，但这似乎是一种非正统方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/659658/statistical-comparison-of-regressed-responses</guid>
      <pubDate>Tue, 07 Jan 2025 10:51:35 GMT</pubDate>
    </item>
    <item>
      <title>对 DiD 设计中均值中位数估计量的洞察</title>
      <link>https://stats.stackexchange.com/questions/659655/insights-into-median-of-means-estimators-in-did-designs</link>
      <description><![CDATA[我目前正在开展一个研究项目，重点研究双差分 (DiD) 设计中的稳健估计量，特别是在经典的两期两组设置中。我的主要兴趣是对 y 方向异常值的稳健性（我污染了误差项），并且我一直在探索均值中位数 (MoM) 估计量作为标准 DiD 治疗效果估计量（基于均值）的潜在替代方案。
但是，我遇到了几个问题：

缺乏文献：我找不到任何先前的研究或 DiD 环境中均值中位数估计量的应用。有人知道是否存在这样的研​​究或我可以在哪里找到吗？
意外结果：当我模拟和实施 MoM 估计量时，我得到的结果与标准 DiD 估计量相同 - 即使包含受污染的数据点也是如此。这让我开始质疑为什么 MoM 估计量在这种设置下不是更稳健。

有人能解释为什么中位数估计量在这种情况下可能无法按预期执行吗？或者 DiD 框架中是否存在一些基本问题，导致 MoM 方法不太合适？
如果您有任何想法、文献建议，甚至直观的解释，我将不胜感激！
在此先感谢您的帮助！

这是我的模拟设置：

数据生成：我模拟了 N=500 和 T=2 个时间段（治疗前和治疗后）的面板数据。一半的单位在第二期进行治疗。结果方程为 $Y = 0.1 + 0.2⋅time − 0.1⋅group + β_{true}⋅D + ϵ $。这里，$β_{true} = 0.4 $，ϵ 是带有污染的随机噪声。
污染：随机噪声 𝜖 以混合形式生成：
$ ϵ = \begin{cases} N(0, \sigma^2) &amp; \text{with probability } (1 - p), \\
U(-c, c) &amp; \text{概率 } p \end{cases}$ 
我尝试了参数 $\sigma$、$p$ 和 $c$（也尝试了非对称污染），但这似乎没有什么区别。
估计量构造如下：
$ \text{DiD Estimate} =
\left(
\overline{Y}_{\text{Treated, Post}} - \overline{Y}_{\text{Treated, Pre}}
\right)
-
\left(
\overline{Y}_{\text{Control, Post}} - \overline{Y}_{\text{Control, Pre}}
\right)
$
$
\text{均值中位数 (MoM)：}
$

将数据拆分为 $ K = \sqrt(N) $ 个块
计算特定于块的 DiD 估计值：$
\text{块 DiD 估计值} = \text{DiD(Block_i})$
最终 MoM 估计值是块估计值的中位数：$
\text{MoM 估计值} = \text{中位数(块 DiD 估计值)}$


]]></description>
      <guid>https://stats.stackexchange.com/questions/659655/insights-into-median-of-means-estimators-in-did-designs</guid>
      <pubDate>Tue, 07 Jan 2025 10:05:08 GMT</pubDate>
    </item>
    <item>
      <title>这里的 95% 置信区间是多少？我的答案正确吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659650/what-is-the-95-confidence-interval-here-is-my-answer-correct</link>
      <description><![CDATA[我正在处理这个问题：

这个问题要求找出两个城市超速罚单金额差异的 95% 置信区间；换句话说，mu(Orange) - mu(DeLand)。我得到的区间在 31.2103907 和 39.5396093 之间。这是正确的吗？如果不是，正确答案是什么？
我使用了以下公式：
]]></description>
      <guid>https://stats.stackexchange.com/questions/659650/what-is-the-95-confidence-interval-here-is-my-answer-correct</guid>
      <pubDate>Tue, 07 Jan 2025 08:38:28 GMT</pubDate>
    </item>
    <item>
      <title>何时使用哪种样本方差公式？</title>
      <link>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</link>
      <description><![CDATA[我知道样本方差的公式为
$$s^2 = \frac{\sum (x_i - \bar{x})^2}{n - 1}$$
我还知道样本方差的公式为“均值平方减均值平方”。
在计算给定样本的样本方差时，我使用了这两个公式，但发现它们给出了两个不同的答案，因此我想问，什么时候该使用第一个公式，什么时候该使用第二个公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</guid>
      <pubDate>Tue, 07 Jan 2025 05:32:19 GMT</pubDate>
    </item>
    <item>
      <title>具有重复数据但权重不同的加权逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/659641/weighted-logistic-regression-with-duplicated-data-but-different-weights</link>
      <description><![CDATA[设置和传统方法
假设对于每个观察值 1 到 N，您有概率估计 $p_a=P(race=a)$, $p_b=P(race=b)$, $p_c=P(race=c)$，其中 $\sum_{r=\{a,b,c\}}p_r=1$ 和一些二元结果变量 $y$，并且我们希望估计逻辑回归 $\text{logit }y\sim \beta_0 + \beta_1 D^{r}+X\beta$，其中 $\sum_{r=\{a,b,c\}}p_r=1$ class=&quot;math-container&quot;&gt;当 P(race=r)&gt;.8 时，$D^r=1$，否则为 0。但是，由于我们希望明确地并且只比较 a 与 b，因此我们在 P(race=a)&gt;.8 或 P(race=b)&gt;.8 的数据子集上估计 $\text{logit }y\sim \beta_0 + \beta_1 D^{b}+X\beta$。这是传统方法，但它会剔除所有 P(race=a)&lt;.8 AND P(race=b)&lt;.8 的数据。
重复的数据集，但每个重复项的权重不同
为了不剔除 P(race=a)&lt;.8 AND P(race=b)&lt;.8 为真的观测值所包含的信息，有人提出估计加权逻辑回归，其中
\begin{align}
\text{logit }\begin{pmatrix}
y \\
y \\
\end{pmatrix} &amp;= \beta_0+\beta_1\begin{pmatrix}
D^{b} \\
D^{b} \\
\end{pmatrix}
+ \begin{pmatrix} X \\ X\\ \end{pmatrix} \beta
\end{align&gt;
其中 $$\text{weights} =\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$$ 且 $D^b_{1\dots N}$=1 且 $D^b_{(N+1)\dots 2N}=0$（基本上，第一个 1...N 堆栈具有虚拟 $D^b=1$ 且第二个 (N+1)...2N 具有虚拟 $D^b=0$。
问题/担忧
直观地看，这似乎至少会扭曲估计的误差，尽管使用权重也可能使系数估计产生偏差。有人见过这种情况吗？类似地，调整权重以解决重复问题似乎可以减轻一些错误，但正确的因素是什么？
最后，估计一个简单的$\text{logit }y\sim \beta_0 + \beta_1 p_b+\beta_2 p_c+X\beta$似乎更直观，而无需借助权重。
对于有形的直觉，想想比较黑人与白人以及西班牙裔与白人，但不知道谁是白人、西班牙裔和黑人，你只能对每个类别进行概率估计。
请原谅我草率的符号，希望它足以传达这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/659641/weighted-logistic-regression-with-duplicated-data-but-different-weights</guid>
      <pubDate>Tue, 07 Jan 2025 04:28:49 GMT</pubDate>
    </item>
    <item>
      <title>我如何改进季节性的实施，以便更好地为扩展和有效地自动化此方法做好准备？</title>
      <link>https://stats.stackexchange.com/questions/659634/how-can-i-refine-my-seasonality-implementation-to-better-prepare-for-scaling-and</link>
      <description><![CDATA[我不会深入探讨我的模型的细节，而是谈谈我希望解决的问题。
当前方法
我使用离散概率矩阵 (DPM) 来预测单个事件在每月期间发生的可能性。
DPM 按用户特征（例如年龄或性别）细分，每个单元格代表如果特征 Y 存在于 Z 月，则事件 X 发生的概率。
当前方法仅依赖于使用最新的实际值作为所有预测月份的基线。
此基线根据工作日进行了调整，以考虑月份长度的变化，从而有效地跨月份转移概率。尽管如此，概率仍然平均围绕实际值的最后一个点。
挑战
这种方法在某些 DPM 线中难以应对季节性。使用实际值的最后一点可能会严重高估或低估季节性活动。
此外，缺乏季节性成分意味着该模型无法捕捉一年中特定时间的重复模式。这很重要，因为该模型包含在 X 或 Y 月份等发生的几种经济条件。
引入的改进
为了解决季节性问题，我引入了经典加性季节性分解 (ASD) 来得出 DPM 中每个概率系列的季节性因素。
按照现有方法，我对基线应用了工作日调整，并在其上分层了季节性因素以保留季节性模式。
这种改进使模型能够同时考虑月份长度的变化和重复的季节性模式，从而使具有季节性活动的 DPM 线的预测更加准确。
方法的优势
ASD 假设有规律的季节性，这很符合我的模型的需求。
它有效地处理了 DPM 中的零/零概率，使其与我的数据兼容。
该方法很简单在 Excel 和 Python 等工具中实现。
季节性因素被标准化为零，确保它们只会改变值而不会改变年度概率总数。
方法保留了阶跃变化 - 这些变化可以在数据中自然发生。
此外，由于还有其他模型组件控制预测水平，因此这里需要一个相当平坦的基于证据的 DPM。
剩余挑战
ASD 假设所有数据点都是正确的，这突出了异常值检测的重要性。我已经测试了四分位距、Z 分数和修正 Z 分数，但我正在考虑是否存在更有效的方法来处理异常值。是否有测试可以区分阶跃变化和异常值。
使用实际值的最后一点作为基线有局限性。虽然平均值已经足够了，但我测试了更先进的技术，例如 Holt 和 Holt-Winters 指数平滑法，这些技术可能会提供更好的准确性。不过，我想知道是否有更好的方法，因为这些方法在 Python 中不是最容易实现的。
另一个问题是，我的方法将季节性应用于所有 DPM 线，无论它们是否显示季节性（是的，这是一个矛盾的评论）。我正在探索自动检测季节性的方法。我尝试使用自相关函数 (ACF) 来可视化我的时间序列数据中的季节性模式和依赖关系。如果有一个统计数据就太好了，可以利用它来决定是否应用季节性。
询问
我将不胜感激任何关于如何应对这些挑战的建议。我对时间序列分析和方法还很陌生。虽然我当前的方法是有效的，但它需要一定程度的人工干预，随着我扩大其应用范围，这种干预可能会变得难以为继。]]></description>
      <guid>https://stats.stackexchange.com/questions/659634/how-can-i-refine-my-seasonality-implementation-to-better-prepare-for-scaling-and</guid>
      <pubDate>Tue, 07 Jan 2025 01:48:00 GMT</pubDate>
    </item>
    <item>
      <title>探索性因子分析，非正态数据</title>
      <link>https://stats.stackexchange.com/questions/659613/exploratory-factor-analysis-non-normal-data</link>
      <description><![CDATA[我正在分析的数据对于几乎每个观察到的变量都是非正态的。我想在 R 中进行探索性因子分析 (EFA)。KMO 检验和 Bartlett 检验表明数据符合 EFA 条件。在 psych 包的文档中，我没有找到应如何处理非正态分布的数据 (https://personality-project.org/r/psych/HowTo/factor.pdf)。我的样本相对较小 (N=60)。
在进行验证性因子分析时，我可以使用 lavaan 包中的 Satorra-Bentler 校正来处理非正态数据，cfa() 函数，例如cfa(model = spec, data = df_data, std.lv=TRUE, estimator = &quot;MLM&quot;) ，这种使用稳健标准误差的校正是一种可接受的方法。 estimator=&quot;MLM&quot; 代表 Satorra-Bentler 校正。我可以用 psych 包 以某种方式做到这一点吗？
psych 包执行 EFA，fa() 函数，例如fa(data, nfactors = 4, rotate = &quot;oblimin&quot;) 并提供可行的因子，但如果我没有弄错的话，它被设计用于正态分布的数据。
如果我尝试使用 lavaan 包 中的 efa() 和 Satorra-Bentler 校正，它会发出 警告，表示协方差矩阵包含较小的负值，这可能表明模型未被识别：
efa(data = df_data, nfactors=4, rotation=&quot;oblimin&quot;, std.lv=TRUE, estimator = &quot;MLM&quot;)

警告消息：
1：lavaan-&gt;lav_model_vcov()： 
估计参数 (vcov) 的方差-协方差矩阵似乎不是
正定！最小特征值 (= -5.425180e-15) 小于零。这可能是模型无法识别的症状。
2：lavaan-&gt;lav_model_vcov()：
估计参数 (vcov) 的方差-协方差矩阵似乎不是正定的！最小特征值 (= -2.190854e-32) 小于零。这可能是模型无法识别的症状。


那么问题是：如何使用心理学包计算非正态数据的 EFA？
更新：
数据分布：我有 9 个变量，每个变量都有比例尺度，因此理论上它们可以从零到无穷大。在实践中，它们计算活动，因此它们包含每个研究对象的整数值。其中一些只有 2、3 个不同的值，这给出了与理论正态分布不同的分布。我添加了一个关于一个变量的 QQ 图，如下图所示。

我使用 psych 包进行了 EFA，以发现数据可能具有从 1 个因子到 9 个因子的内容，以便我可以看到每种情况的拟合优度指标。 这产生了具有 4 个潜在变量的最佳指标。这就是我从 4 开始的原因。尽管如此，我并没有更改默认的因子提取，也没有提供相关矩阵。
我如何为 fa() 函数提供 Spearman 相关矩阵？如果我提供这个矩阵，我是否应该从 minres 更改因子提取方法？哪种因子提取方法对非正态性不太敏感？非正态性对 TLI、CFI、RMSEA 和 Chi2 指标的计算没有影响吗？
我很感激每一位回复，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659613/exploratory-factor-analysis-non-normal-data</guid>
      <pubDate>Mon, 06 Jan 2025 12:41:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们将标准误差定义为忽略偏差（与包含偏差的 MSE 不同）？</title>
      <link>https://stats.stackexchange.com/questions/659583/why-do-we-define-the-standard-error-to-ignore-bias-unlike-mse-which-includes-bi</link>
      <description><![CDATA[为什么估计量$\hat \theta$的标准误差定义为$$se = \sqrt{Var(\hat \theta)}$$，而不是$$se = \sqrt {MSE(\hat \theta)} = \sqrt{Bias^2(\hat \theta) + Var(\hat \theta)}.$$
也就是说，标准误差应该是均方误差的平方根。当然，如果估计量是无偏的，那就没有区别了。但无论如何，我能想到，如果估计量有偏差，那么我们使用标准误差的地方，偏差需要成为误差的一部分。
例如，考虑执行 Wald 检验。如果我们愿意增加偏差，我们总是可以得出任意低方差的 $\sigma^2$ 估计量。例如，给定 $\hat \sigma^2$，定义 $$\hat \sigma_1^2 = (1-t)\hat \sigma^2 + tk$$，对于任意常数 $t,k$ 将给出这样的估计量。如果我们使用它来执行 Wald 检验，我们可以通过降低 se 来获得我们想要的任何 $\alpha$，而无需真正改进测试。
如果 se 的定义包括偏差，这个问题就会得到解决 - 这会与 标准 错误 一词更加一致。我们为什么不这样做呢？

更新 - 与假设检验的相关性
除了术语之外，这里有一个有影响力的问题：在我们的估计量确实有偏差的情况下，我们应该在假设检验中使用 标准错误 还是上述定义？有些情况下，这会对测试结果产生影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/659583/why-do-we-define-the-standard-error-to-ignore-bias-unlike-mse-which-includes-bi</guid>
      <pubDate>Sun, 05 Jan 2025 21:17:49 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 SHAP 值</title>
      <link>https://stats.stackexchange.com/questions/659566/how-to-interpret-shap-values</link>
      <description><![CDATA[我是 AI 新手。我有一张尺寸为 (28, 28, 3) 的 MNIST 图像，心里有几个问题。如果有人能就此提出建议，那就太好了：

SHAP 如何确定值范围？例如，为什么有时是 -2 到 +2？它应该这么大吗？有时，当我使用其他格式运行它时，它会给出 -0.00005 到 0.00005 的范围。正确的有效范围是什么？

如果我的模型对此图像的置信度得分为 30，那么将 SHAP 值相加是否也会得到 30？这是否意味着总贡献得分应该与置信度得分相匹配？如果不是，为什么？


]]></description>
      <guid>https://stats.stackexchange.com/questions/659566/how-to-interpret-shap-values</guid>
      <pubDate>Sun, 05 Jan 2025 14:51:01 GMT</pubDate>
    </item>
    </channel>
</rss>