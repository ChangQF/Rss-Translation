<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 12 Jul 2024 21:15:07 GMT</lastBuildDate>
    <item>
      <title>变量的联合分布</title>
      <link>https://stats.stackexchange.com/questions/650952/joint-distribution-of-the-variables</link>
      <description><![CDATA[我想使用 copula 为多变量干旱分析建立降水和流量数据的联合分布模型。我已经确定了变量的边际分布。

如何使用 R 代码计算变量的联合分布？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650952/joint-distribution-of-the-variables</guid>
      <pubDate>Fri, 12 Jul 2024 20:24:57 GMT</pubDate>
    </item>
    <item>
      <title>计算长期人口增长的死亡率</title>
      <link>https://stats.stackexchange.com/questions/650951/calculating-death-rates-for-an-increasing-population-over-the-long-term</link>
      <description><![CDATA[我参与了一项针对特定 MH 干预的小型长期结果研究。我们对似乎在 20 多岁时就去世的受试者数量感到有些担忧，我们想确保死亡率确实异常高，并开始对潜在问题发出一些声音。

简而言之，我们有大约 600 名受试者，他们在 25 年的时间里被送入 MH 设施。多年来，他们都是十几岁时被送进这个机构的，现在的年龄在 20-50 岁之间。
我们想做的是计算每 5 年（15-19 岁、20-24 岁等）的死亡率，以便将其与一般人口和更具体/相关的人群进行比较。

从表面上看，这似乎是一个基本问题，但我根本不知道如何面对这样一个事实：我们必须从 25 年的角度来看待这一事实，即人口在这段时间内不断增长（现在稳定下来）。如果有人能牵着我的手，给我指明正确的概念方向，我将不胜感激！谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/650951/calculating-death-rates-for-an-increasing-population-over-the-long-term</guid>
      <pubDate>Fri, 12 Jul 2024 20:20:02 GMT</pubDate>
    </item>
    <item>
      <title>随机变量乘积的分布</title>
      <link>https://stats.stackexchange.com/questions/650950/distribution-of-a-product-of-random-variables</link>
      <description><![CDATA[我有两个分布 $X$ 和 $Y$。$X$ 由分段 CDF 定义
$$F_X(x) = \begin{cases}
F_X^1(x) &amp; x \in (-\infty, a_1)\\
F_X^2(x) &amp; x \in [a_1, a_2)\\
F_X^3(x) &amp; x \in [a_2, \infty)
\end{cases}$$
和 PDF
$$f_X(x) = \begin{cases}
f_X^1(x) &amp; x \in (-\infty, a_1)\\
f_X^2(x) &amp; x \in [a_1, a_2)\\
f_X^3(x) &amp; x \in [a_2, \infty)
\end{cases}$$
并且 Y 由分段 CDF 定义
$$F_{Y}(y) = \begin{cases}
F_Y^1(y) &amp; y&lt;0\\
F_Y^2(y) &amp; y\geq0
\end{cases}$$
和 PDF
$$f_{Y}(y) = \begin{cases}
f_Y^1(y) &amp; y&lt;0\\
f_Y^2(y) &amp; y\geq0
\end{cases}$$
$Z = Xe^Y$ 的 CDF 和 PDF 是多少？

我尝试使用全概率定律来分解这个问题（我省略了下面的一些术语），但我在最后一步卡住了。我不知道如何将其转换为具有正确界限的积分。
\begin{align*}\mathbb{P}(Z&lt;z) &amp;=\mathbb{P}(Xe^{Y}&lt;z) \\
&amp;=\mathbb{P}(X&lt;ze^{-Y}) \\
&amp;=\mathbb{P}(X&lt;ze^{-Y},ze^{-Y} &lt; a_{1})+\mathbb{P}(X&lt;ze^{-Y},a_{1} \leq ze^{-Y} &lt; a_{2})+\dots\\
&amp;=\mathbb{P}(X&lt;ze^{-Y},\ln(z)-\ln\left(a_{1}\right) \leq Y) \\
&amp;\qquad+\mathbb{P}(X&lt;ze^{-Y},\ln(z)-\ln\left(a_{2}\right) &lt; Y \leq \ln(z)-\ln\left(a_{1}\right))+\dots \\
&amp;=\mathbb{P}(X&lt;ze^{-Y},\ln(z)-\ln\left(a_{1}\right) \leq Y,Y&lt;0) \\
&amp;\qquad+\mathbb{P}(X&lt;ze^{-Y},\ln(z)-\ln\left(a_{1}\right) \leq Y,Y\geq0)+\dots \end{align*&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/650950/distribution-of-a-product-of-random-variables</guid>
      <pubDate>Fri, 12 Jul 2024 19:44:48 GMT</pubDate>
    </item>
    <item>
      <title>选择正确数量的特征和正确参数的更快方法</title>
      <link>https://stats.stackexchange.com/questions/650949/a-faster-way-to-choose-the-right-number-of-features-and-the-right-parameters</link>
      <description><![CDATA[对于一个非常小的数据集，样本少于一百个，网格搜索无法给出我们想要的结果，并且存在过度拟合。但是当我手动对模型进行超参数调整并随机选择不同的数字时，会获得想要的结果，但这项工作需要花费大量时间。您有解决方案来加快这项工作吗？或者有比手动方法更好的替代方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650949/a-faster-way-to-choose-the-right-number-of-features-and-the-right-parameters</guid>
      <pubDate>Fri, 12 Jul 2024 18:32:34 GMT</pubDate>
    </item>
    <item>
      <title>计算逆协方差矩阵的偏差</title>
      <link>https://stats.stackexchange.com/questions/650947/computing-the-bias-of-the-inverse-covariance-matrix</link>
      <description><![CDATA[交叉发布到 CV 以防万一！
在统计类中，计算样本协方差矩阵的偏差（或缺乏偏差）是标准做法，但我无法找到任何关于样本协方差矩阵的逆如何估计精度矩阵（即逆协方差矩阵）的确切结果。即使只是取期望值，我也很难想象。取一个 IID 样本 $X_1, \cdots, X_n$，每个样本都在 $\mathbb{R}^d$ 中。如果 $C$ 是协方差矩阵，那么查看逆矩阵的单个分量
$$ 
E[C^{-1}(x,X_i)],
$$
似乎不适用于标准方法，因为逆矩阵隐式地依赖于数据集的所有其他值。所以它实际上看起来像
$$
E[C^{-1}(x,X_i)(X_1,\cdots, X_n)].
$$
我们可以使用类似塔属性的东西来获得
$$
E[C^{-1}(x,X_i)(X_1,\cdots, X_n)]= E_{X_i^c}\big [ E_{X_i}[C^{-1}(x,X_i)(X_1,\cdots, X_n)|X_i^c] \big ]
$$
其中 $X_i^c := \{ X_1, \cdots X_{i-1}, X_{i+1} \cdots X_n \}$。那么我可以扩展到积分定义吗？
我的困惑来自于在进行核密度估计器的计算时，我们得到的是
$$
\begin{align}
E[\frac{1}{hn}\sum_i K_h(x,x_i)] &amp;= E[\frac{1}{h}\sum_i K_h(x,x_i)]\\
&amp;= \frac{1}{h}\int_X K_h(x,y)p(y)d\mu(y)
\end{align}
$$
其中第一个等式来自 IID。我的想法是，理解矩阵求逆的期望意味着什么，将使其余的计算变得清晰起来。
我看过的相关作品：问题 1、问题 2 和 问题 3。]]></description>
      <guid>https://stats.stackexchange.com/questions/650947/computing-the-bias-of-the-inverse-covariance-matrix</guid>
      <pubDate>Fri, 12 Jul 2024 17:35:03 GMT</pubDate>
    </item>
    <item>
      <title>相似时间序列之间的相关性（突破曲线）</title>
      <link>https://stats.stackexchange.com/questions/650946/correlation-between-similar-time-series-breakthroughcurves</link>
      <description><![CDATA[首先声明一下 - 我的背景知识不多，在统计学方面只有非常基础的知识。
我有几个使用不同示踪剂的突破曲线 (BTC)，我想将它们相互比较。
从质量上讲，NaCl 的 BTC 非常相似，几乎是等价的。使用 MX-80 的 BTC 也非常相似，尽管红色和蓝色 BTC (MX-80 Komp) 有点延迟。我现在想用数字来表达。我尝试了皮尔逊相关性，将每个 BTC 与其他 BTC 进行相关，但这会为所有比较对提供非常接近 1 的高相关指数 (r)。如果我比较 -log(1-r)，则可以进行更好的比较，如第二张图片所示（显示了另一个实验中 BTC 之间的相关性）。
还有其他好方法可以定量比较 BTC 吗？
我非常感谢所有的意见！
Diclo

]]></description>
      <guid>https://stats.stackexchange.com/questions/650946/correlation-between-similar-time-series-breakthroughcurves</guid>
      <pubDate>Fri, 12 Jul 2024 17:15:39 GMT</pubDate>
    </item>
    <item>
      <title>“相对风险时间”有意义吗？（暂时性相对风险）</title>
      <link>https://stats.stackexchange.com/questions/650941/is-relative-risk-time-meaningful-transient-relative-risk</link>
      <description><![CDATA[上下文：
我正在尝试为模拟研究指定一个数据生成/机械模型。我假设暴露$e$（一个短暂的事件）对另一个过程$k$的相对速率有短暂的影响。我将这种影响定义为：
$$RR_{e:k}(t-t_e) = 1 + \beta\exp(-(t-t_e)/\tau)$$
其中：
$t$是当前时间；
$t_e$是事件$e$的时间；
$\beta$ 控制效果强度；并且
$\tau$ 控制持续时间。
直观地看，单次暴露 $e$ 的累积效应与 $\beta$ 和 $\tau$ 成正比，并且从数学上讲，曲线下的面积 $(RR-1) = \beta\tau$。
问题：
在不考虑 $k$ 的基准利率的情况下，$(RR(t)-1)$ 曲线下的这个面积是否有助于解释为某种“相对风险时间”的衡量标准？有没有更好的术语来描述这个数量？]]></description>
      <guid>https://stats.stackexchange.com/questions/650941/is-relative-risk-time-meaningful-transient-relative-risk</guid>
      <pubDate>Fri, 12 Jul 2024 16:23:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么 mgcv 的 bam() 不适用于空模型（y~1），但 gam() 可以？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650940/why-does-mgcvs-bam-not-work-with-null-models-y1-but-gam-does</link>
      <description><![CDATA[我试图使用 gam.hp 包得出几个 gam 模型中每个预测因子解释的唯一和共享偏差。
简而言之，该包的方法使用创建一个包含所有可能的预测因子组合的矩阵，为每种组合拟合新模型，然后通过比较有和没有该预测因子的模型来计算与每个预测因子相关的模型拟合的改进，对所有可能的模型组合取平均值。
gam.hp 通过从空模型调用开始并使用 update() 测试新的参数组合来实现这一点。
to_del &lt;- paste(as.character(mod$call$formula)[2],&quot;~&quot;,&quot;1&quot;)
mod_null &lt;- stats::update(object = mod, formula. = to_del, data = dat)
for (i in 1:totalN) {
tmp.name &lt;- iv.name[as.logical(binarymx[, i])]
to_add &lt;- paste(&quot;~&quot;,paste(tmp.name,collapse = &quot; + &quot;),sep=&quot; &quot;)
modnew &lt;- stats::update(object = mod_null, data = dat,to_add) 
if(type==&quot;dev&quot;)commonM[i, 2] &lt;- summary(modnew)$dev.expl
}

对于具有大量 (n) 预测变量的复杂模型，这种方法非常昂贵：O(2^{n-1})。因此，使用 bam() 而不是 gam() 非常有用，因为您可以大幅减少每次迭代的计算时间——在我的例子中，bam() 比 gam() 快约 20 倍。
我遇到的问题是 bam() 显然不适用于空模型公式。
library(mgcv)

## 玩具数据集
set.seed(3)
dat &lt;- gamSim(1,n=25000,dist=&quot;normal&quot;,scale=20)

## 使用 gam()
g &lt;- gam(y ~ s(x0,bs=&quot;cr&quot;) + s(x1,bs=&quot;cr&quot;) + s(x2,bs=&quot;cr&quot;, k=12) + s(x3,bs=&quot;cr&quot;), data=dat) #works
g0 &lt;- gam(y ~ 1, data=dat) #works

## 使用 bam()
b &lt;- bam(y ~ s(x0,bs=&quot;cr&quot;) + s(x1,bs=&quot;cr&quot;) + s(x2,bs=&quot;cr&quot;, k=12) + s(x3,bs=&quot;cr&quot;), data=dat) #works
b0 &lt;- bam(y ~ 1, data=dat) # Error in data[[txt]] : 下标越界

除非您使用 gam() 构建模型，否则 bam() 的这种奇怪行为会破坏 gam.hp()。
问题：有没有办法让 bam() 与空模型一起工作？]]></description>
      <guid>https://stats.stackexchange.com/questions/650940/why-does-mgcvs-bam-not-work-with-null-models-y1-but-gam-does</guid>
      <pubDate>Fri, 12 Jul 2024 15:36:17 GMT</pubDate>
    </item>
    <item>
      <title>紧急：我正在构建线性回归模型。昨天我的 R 平方为 0.792。今天，它已降至 0.267。我没有做任何更改。紧急 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/650935/urgent-i-am-building-a-linear-regression-model-yesterday-my-r-squared-was-0-79</link>
      <description><![CDATA[感谢您的回复。作为进一步的信息，我正在使用 R-Squared，因为它是我正在做的项目的推荐。以下是 2 个文件。昨天的 R 平方为 0.792 ( https://drive.google.com/file/d/1YrqcqNERWTGS6fdQplxuldQIyg9xsBdj/view?usp=sharing )，今天的 R 平方为 0.267 (https://drive.google.com/file/d/17rCGAlwbeighL7uMCG5f0GY4fKbAAzCL/view?usp=sharing )。
我正在构建一个线性回归模型。昨天我的 R 平方为 0.792。今天，它已降至 0.267。我没有做任何更改。请加急]]></description>
      <guid>https://stats.stackexchange.com/questions/650935/urgent-i-am-building-a-linear-regression-model-yesterday-my-r-squared-was-0-79</guid>
      <pubDate>Fri, 12 Jul 2024 12:48:36 GMT</pubDate>
    </item>
    <item>
      <title>如何对密度数据进行功效分析？</title>
      <link>https://stats.stackexchange.com/questions/650687/how-to-do-a-power-analysis-on-density-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650687/how-to-do-a-power-analysis-on-density-data</guid>
      <pubDate>Mon, 08 Jul 2024 18:27:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么逆倾向得分加权有效？</title>
      <link>https://stats.stackexchange.com/questions/650624/why-does-inverse-propensity-score-weighting-work</link>
      <description><![CDATA[假设某些治疗 $D = 0, 1$ 对结果 $Y = 0,1$ 的影响受到性别 $S = 0,1$ 的混淆。对 $D$ 对 $Y$ 的因果影响的无混淆估计将使我们估计层内风险，然后在计算其差异之前根据层的流行程度对这些风险进行加权。从数学上讲，我们会计算
$$ E[Y(D=d)] = \sum_s E[Y \mid D=d, S=s] P(S=s) $$
对每个 $d$ 计算差值。如果简单地写出均值估计量的简单差异，就会发现权重不正确，这是造成混杂的原因
$$ E[Y\mid D=d] = \sum_s E[Y \mid D=d, S=s] P(S=s \mid D=D) $$
请注意，通过贝叶斯规则
$$ P(S=s \mid D=D) = \dfrac{P(D=D \mid S=S) P(S=s)}{P(D=d)} $$
它是倾向得分和正确权重的函数$P(S=s)$。但是，简单地用倾向得分的倒数对 $E[Y \mid D=d]$ 的估计值进行加权，就会在 $E[Y \mid D=d]$ 的表达式中留下一个 $1/P(D=d)$ 因子。
那么，为什么 IPTW 会得出正确的因果对比估计值呢？我希望得到一个符合我在此处所写的期望加权和的答案。具体来说，我希望证明 IPTW 可以得出与我提出的第一个方程类似的表达式。

编辑：
这是我自己的尝试
让每个和的权重为
$$ w(s) = \dfrac{1}{\Pr(D=d \mid S=s)}$$
这些不能保证总和为 1，所以让我们计算它们的总和并创建新的、标准化的权重。
$$ \sum_s w(s, d) = \dfrac{1}{\Pr(D=d \mid S=0)} + \dfrac{1}{\Pr(D=d \mid S=1)}$$
寻找共同点...
$$ \sum_s w(s, d) = \dfrac{\Pr(D=d \mid S=1) + \Pr(D=d \mid S=0)}{\Pr(D=d \mid S=1) \times \Pr(D=d \mid S=0)}$$
现在，事情变得糟糕起来。首先我们来承认
$$ \Pr(D=d \mid S=s) = \dfrac{\Pr(S=s \mid D=d) \Pr(D=d)}{\Pr(S=s)}$$
如果我们用分子和分母替换$D$的条件概率，那么$\Pr(D=d)$的因子就会出现。我们在分子中得到一个因子，在分母中得到 2，因此
$$ \sum_s w(s, d) = \dfrac{f(s, d)}{\Pr(D=d)} $$
其中 $f$ 是使用贝叶斯规则重写的表达式。重要的是，我们得到了 $\Pr(D=d)$ 的因子。
现在，定义 $\Omega(s, d) = \dfrac{w(s, d)}{\sum_s w(s, d)} = \dfrac{w(s) \Pr(D=d)}{f(s, d)} = \dfrac{\Pr(D=d)}{\Pr(D=d \mid S=s) f(s, d)} $
因此，使用 $\Omega(s, d)$ 作为权重的加权和具有我们需要抵消“错误”的因子均值差异中的权重。
我的直觉告诉我 $f(s, d) = 1$，但我不确定，而且尚未证明这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/650624/why-does-inverse-propensity-score-weighting-work</guid>
      <pubDate>Sun, 07 Jul 2024 05:59:37 GMT</pubDate>
    </item>
    <item>
      <title>关于测试可靠性对测试组合权重的影响的问题</title>
      <link>https://stats.stackexchange.com/questions/650558/question-on-the-effect-of-test-reliability-on-weighting-of-a-test-battery</link>
      <description><![CDATA[最初，测试组有 4 个部分：两个 100 项多项选择题测试、一个口语测试和一个论文测试。每个部分测量不同的主题。4 个部分中的每一个权重为 25%。
现在，每个多项选择题测试的测试长度已减少到 60 项（出于实际原因）。每个部分仍占 25%。
如果两个 MC 测试的可靠性降低到零，则两个 MC 测试测量的两个主题的权重将为零。（两个 MC 测试只会产生误差。）实际上，可靠性降低了，但并没有降低到零。
我的问题是，可靠性的变化对两个 MC 测试测量的两个主题的权重有何影响。我如何估计由于变化而导致的权重差异？
澄清：
原始权重是根据相关方的共识选择的。因此，我首先假设原始测试组的权重是理想的（只要各方同意这些权重）。项目数量的减少是出于权宜之计。项目越少，测试可靠性就越低。我试图确定新的测试组与原始测试组相比，在对测试组中每个测试所测量的主题赋予的权重方面，MC 测试时间越短。（直观上看，可靠性越低的测试对测试所测量的主题赋予的有效权重就越低。在极端情况下，如果测试的可靠性为零，它们只会给测试组的总分增加随机噪音，尽管名义权重为 25%，但 MC 测试所测试的主题根本没有任何权重。）
更新以解决评论：
似乎我的问题包含一些不成熟或非标准的词汇。因此，这里是使用其他词语来陈述我的问题的另一种尝试。
25% 的原始权重假设四个测试中的每一个都具有现有的有效性水平，并且一​​致认为这些测试理想情况下应该具有相等的权重。我认为这意味着每个测试最初对总分贡献了 25% 的非随机有效方差。
我推测，切换到较短的 MC 测试已经改变了两个 MC 测试的可靠性，因此也改变了它们的有效性。因此，较短的 MC 测试对总分的有效方差贡献较少。从这个意义上说，它们不再是 25% 的权重。我的问题是，它们的新权重是多少。
两种可能的方法：
这是我对如何处理我提出的问题的一种想法。有效性受可靠性平方根的限制。因此，如果可靠性从 0.8 降低到 0.7，则有效性上限从 0.89 降至 0.84。这似乎意味着新的、更短的 MC 测试的有效贡献比原始测试少 5%。就比例而言，即少 0.05/0.89，或新的较低权重比原始权重少约 6%。也就是说，更短的 MC 测试对总分的有效信息贡献减少了 6%。也许可以通过调整 25% 的权重来弥补这一点。对这种方法有什么看法？
或者，由于可靠性与效用呈线性关系，因此可靠性比率可能是 MC 测试影响减少的更好指标。这可能是 0.7/0.8=0.875，或权重减少 12.5%。对这种方法有什么看法？]]></description>
      <guid>https://stats.stackexchange.com/questions/650558/question-on-the-effect-of-test-reliability-on-weighting-of-a-test-battery</guid>
      <pubDate>Fri, 05 Jul 2024 22:15:38 GMT</pubDate>
    </item>
    <item>
      <title>回归模型中的混杂变量：辛普森悖论</title>
      <link>https://stats.stackexchange.com/questions/650388/confounding-variable-in-regression-model-simpsons-paradox</link>
      <description><![CDATA[我正在研究一个混合效应回归模型，其中 Yi = 学生 i 的考试成绩。
解释变量如下：

级别 3：学校类型（公立与私立）和学校的社会经济水平（数字变量）

级别 2：每个班级的教育模式（主要路径、特殊教育）

级别 1：移民背景（学生是否是移民）、学生的社会经济水平（数字变量）、在家使用的语言（英语或其他语言）以及学生的身份（学生是否必须留级一年）
我使用两个模型来解释 Y。第一个模型不包括变量 student_socioeconomic 和 student_idoneity。
model1 = lmer(data = scores, English_score ~ (1| school_id/group_id) +
school_type + school_socioeconomic + group_educational_model +
student_inmigrant + student_language)
model2 = lmer(data = scores, English_score ~ (1| school_id/group_id) +
school_type + school_socioeconomic + group_educational_model +
student_socioeconomic + student_inmigrant + student_language +
student_idoneity)


在第一个模型中，变量“student_inmigrant”的估计系数为正，并且在 1% alpha 水平上显著。然而，当我添加变量“student_socioeconomic”时和“student_idoneity”，变量“student_inmigrant”的估计系数在 1% alpha 水平上变为负且显著。
我认为这里存在混杂变量的问题，但我不知道如何解决。您能给我一些关于如何处理这个问题的建议吗？
我检查了存在多重共线性时的 VIF 值，但 student_inmigrant、student_idoneity 和 student_socioeconomic 的调整后的 GVIF 都低于 2。]]></description>
      <guid>https://stats.stackexchange.com/questions/650388/confounding-variable-in-regression-model-simpsons-paradox</guid>
      <pubDate>Wed, 03 Jul 2024 12:15:21 GMT</pubDate>
    </item>
    <item>
      <title>指数样本均值的无偏检验</title>
      <link>https://stats.stackexchange.com/questions/650132/unbiased-test-for-homogeneity-of-means-of-exponenential-samples</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650132/unbiased-test-for-homogeneity-of-means-of-exponenential-samples</guid>
      <pubDate>Fri, 28 Jun 2024 19:49:28 GMT</pubDate>
    </item>
    <item>
      <title>计算线性相关随机变量 $X$ 和 $Y=X$ 的联合 pdf</title>
      <link>https://stats.stackexchange.com/questions/650128/calculating-the-joint-pdf-of-linearly-dependent-random-variables-x-and-y-x</link>
      <description><![CDATA[设 $X$ 和 $Y$ 为两个随机变量，$p_{(X,Y)}(x,y)$ 为 $(X,Y)$ 的联合 pdf。假设 $(X,Y)$ 变换为 $(X,X)$。我们想要计算变换后的随机变量的联合 pdf。
由此，我们知道我们通常取 $g(X,Y)=U$ 和 $h(X,Y)=V$。由此可知，使用 $g(X,Y)=X=h(X,Y)$，我们得到 $U=V$。相应的雅可比矩阵也可以表示为
\begin{pmatrix}
1 &amp; 0 \\
0 &amp; 0
\end{pmatrix
但这是不可逆的。我在计算变换后的随机变量的联合 pdf 时遇到了问题。我也在网上看到并知道 $(X,X)$ 的联合 pdf 是 $p_{X}(x)\delta(x-y)$。在这里我无法用通常的方法计算 $\delta$。此外，我已将第一个 cdf 计算为 $P(X&lt;x,Y&lt;y)=P(X&lt;x,X&lt;y)=P(X&lt;\min(x,y))$。根据此 cdf，我可以计算所需的 pdf 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650128/calculating-the-joint-pdf-of-linearly-dependent-random-variables-x-and-y-x</guid>
      <pubDate>Fri, 28 Jun 2024 18:51:03 GMT</pubDate>
    </item>
    </channel>
</rss>