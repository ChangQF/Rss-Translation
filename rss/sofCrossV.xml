<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 12 Dec 2024 09:19:09 GMT</lastBuildDate>
    <item>
      <title>理解平均相对差异（用于 R 中的 all.equal 函数）</title>
      <link>https://stats.stackexchange.com/questions/658609/understanding-of-mean-relative-difference-used-in-all-equal-function-in-r</link>
      <description><![CDATA[有人能解释一下这个 R 代码的结果吗：
x &lt;- c(1, 0, 1, 0, 0)
y &lt;- c(0, 1, 0, 1, 1)
all.equal(x, y)
[1] &quot;平均相对差异：2.5&quot;

据我理解，平均相对差异定义如下：
$$D = \frac{1}{n} \sum d[i]$$
with
$$d[i] = \frac{|x[i] - y[i]|}{\max\left(|x[i]|, |y[i]|, \text{tolerance}\right)}$$
因此，我期望分母始终为 1：
$$|x[1] - y[1]| = |1-0| = 1$$
$$|x[2] - y[2]| = |0-1| = 1$$
$$|x[3] - y[3]| = |1-0| = 1$$
$$|x[4] - y[4]| = |0-1| = 1$$
$$|x[5] - y[5]| = |0-1| = 1$$
分子也始终为 1：
$$\max\left(|x[1]|, |y[1]|, 0.1e-58\right) = max(1,0,0.1e-58) = 1$$
$$\max\left(|x[2]|, |y[2]|, 0.1e-58\right) = max(0,1,0.1e-58) = 1$$
$$\max\left(|x[3]|, |y[3]|, 0.1e-58\right) = max(1,0,0.1e-58) = 1$$
$$\max\left(|x[4]|, |y[4]|, 0.1e-58\right) = max(0,1,0.1e-58) = 1$$
$$\max\left(|x[5]|, |y[5]|, 0.1e-58\right) = max(0,1,0.1e-58) = 1$$
因此平均相对差异将是：
$$\frac{1}{5}\sum_{i=1}^{5} d[i] = \frac{1}{5} * (\frac{1}{1}+\frac{1}{1}+\frac{1}{1}+\frac{1}{1}+\frac{1}{1}) = 1$$
然而 R 打印的结果却是 2.5。我对平均相对差异的理解哪里错了？还是函数有 bug？]]></description>
      <guid>https://stats.stackexchange.com/questions/658609/understanding-of-mean-relative-difference-used-in-all-equal-function-in-r</guid>
      <pubDate>Thu, 12 Dec 2024 08:11:43 GMT</pubDate>
    </item>
    <item>
      <title>对回归模型求偏导数</title>
      <link>https://stats.stackexchange.com/questions/658606/taking-partial-derivatives-of-regression-models</link>
      <description><![CDATA[对于具有函数 $f(x_1, x_2, x_3)$ 的一般统计模型，$x_1$ 的偏效应是我们在将 $x_2$ 和 $x_3$ 固定在特定值（例如 $c_1, c_2$）的同时取偏导数时得到的结果：
$$ \text{} x_1 = \frac{\partial f(x_1, x_2, x_3)}{\partial x_1}\bigg|_{x_2=c_2, x_3=c_3} 的偏效应 $$
另一方面，边际效应涉及对其他变量的分布取期望（其中我们有 $n$ 个数据点，$x_{2i}$ 和 $x_{3i}$ 是我们数据集中的观测值）：
$$ \text{} x_1 = E_{x_2,x_3}\left[\frac{\partial f(x_1, x_2, x_3)}{\partial x_1}\right] 的边际效应 $$
$$ \text{} x_1 = \frac{1}{n}\sum_{i=1}^n \frac{\partial 的估计边际效应f(x_1, x_{2i}, x_{3i})}{\partial x_1} $$
我对以下一点有疑问：对于非线性统计模型，在考虑较大差异的影响时，我们是否必须调整微积分？
例如，对于点 $x$ 周围的小变化 $\Delta x$，使用导数的局部近似为（对于变量 $X_1$，保持其他变量不变）：
$$ \text{Effect}_{\text{}}(\Delta x) \approx \frac{\partial f(x_1, x_2, x_3)}{\partial x_1}\Delta x $$
我认为同样的逻辑并不完全适用于 $\Delta x$ 的较大值，因为这个范围的每个点的斜率现在都会不同：
$$ \text{Effect}_{\text{}}(\Delta x) = \int_{x}^{x + \Delta x} \frac{\partial f(x_1, x_2, x_3)}{\partial x_1} dx_1 $$
这是正确的吗？对于非线性模型，效应量计算所需的导数是否需要相应修改以反映近似相关问题？

关于微积分的注释：https://math.stackexchange.com/questions/5010389/derivatives-of-linear-functions-vs-derivatives-of-non-linear-functions
]]></description>
      <guid>https://stats.stackexchange.com/questions/658606/taking-partial-derivatives-of-regression-models</guid>
      <pubDate>Thu, 12 Dec 2024 01:13:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么非平稳 AR 过程不能表示为无限 MA 过程？</title>
      <link>https://stats.stackexchange.com/questions/658605/why-cant-a-non-stationary-ar-process-be-represented-as-an-infinite-ma-process</link>
      <description><![CDATA[考虑 AR(1) 过程。如果 $|\phi|&lt;1$，则该过程为平稳过程，我们可以将该级数表示为
$$ Y_t = \epsilon_t + \phi\epsilon_{t-1} + \phi^2\epsilon_{t-2} + \phi^3\epsilon_{t-3} + \cdots $$
我听说只有平稳 AR 过程才能表示为无限 MA 过程，因此以 AR(1) 为例，如果 $|\phi| \geq 1$，为什么这不成立？]]></description>
      <guid>https://stats.stackexchange.com/questions/658605/why-cant-a-non-stationary-ar-process-be-represented-as-an-infinite-ma-process</guid>
      <pubDate>Thu, 12 Dec 2024 00:41:34 GMT</pubDate>
    </item>
    <item>
      <title>对数逻辑分布中的“对数平均值”参数是什么？</title>
      <link>https://stats.stackexchange.com/questions/658602/what-is-the-mean-of-logarithmic-values-parameter-in-log-logistic-distribution</link>
      <description><![CDATA[我从 mathworks 网站 上读到：

对数逻辑分布使用以下参数。


但是，对数逻辑分布的维基百科页面 表示该分布有两个参数，即尺度和形状。我有点困惑，我想知道“对数值的平均值”是否有一个简称，或者是否可以将其转换为形状参数。我之所以问这个问题，是因为我需要在工作中表达这个参数，但我不知道如何引用它，并将这个值转换为已知的形状参数。]]></description>
      <guid>https://stats.stackexchange.com/questions/658602/what-is-the-mean-of-logarithmic-values-parameter-in-log-logistic-distribution</guid>
      <pubDate>Wed, 11 Dec 2024 23:16:57 GMT</pubDate>
    </item>
    <item>
      <title>在比较 3 个以上变量的均值之后，我可以使用一系列线性回归对 R 中的调查数据进行事后检验吗？</title>
      <link>https://stats.stackexchange.com/questions/658600/can-i-use-a-series-of-linear-regressions-to-perform-post-hoc-tests-on-survey-dat</link>
      <description><![CDATA[Thomas Lumley 在这篇 StackOverflow 文章中解释说，survey 包的 regTermTest() 函数可用于比较 3 个以上组的平均值。但是，我想澄清的是，如果此测试显示平均值之间存在统计上的显着差异，则应使用哪种事后检验。一系列线性回归在这里是否有意义，如果有意义，我是否需要应用校正来解释我正在执行的多个测试？
例如，假设我正在分析加权调查数据集中共和党人、民主党人和独立人士之间的家庭收入差异。我的 regTermTest() 结果表明这些群体之间存在显着差异；但是，我接下来想确定 (1) 共和党人和民主党人、(2) 共和党人和独立人士以及 (3) 民主党人和独立人士之间的收入差异是否具有统计显著性。
我相信我可以通过执行两个回归来回答这些后续问题，一个以共和党人为截距，另一个以民主党人为截距，然后分析我检索到的系数的统计显著性。 （此方法的灵感来自探索 R 中的复杂调查数据分析第 7 章）但是，鉴于我在这里执行两个不同的测试，我是否需要使用 Holm 或 Bonferroni 校正来降低发生 I 类错误的可能性？
（仔细想想：我是否可以跳过初始 regTermTest 并直接转到这些线性回归，或者首先确保这三个组的平均值实际上不同很重要？
此外，成对 T 检验是否是这些事后回归的更好替代方案，或者该测试输出的结果是否相同？]]></description>
      <guid>https://stats.stackexchange.com/questions/658600/can-i-use-a-series-of-linear-regressions-to-perform-post-hoc-tests-on-survey-dat</guid>
      <pubDate>Wed, 11 Dec 2024 22:55:07 GMT</pubDate>
    </item>
    <item>
      <title>指数平滑应用于随机游走时的最佳参数</title>
      <link>https://stats.stackexchange.com/questions/658598/best-parameter-of-exponential-smoothing-when-applied-on-a-random-walk</link>
      <description><![CDATA[假设我有一个随机游走：
$$X_t = X_0 + \sum_{i =1}^t \epsilon_i$$
其中$\epsilon_i \sim \mathcal{N}(0, \sigma^2)$且独立。
那么在窗口$N$的指数移动平均中，哪个平滑因子$\alpha$可以给出$X_{T+1}$的最佳估计？
我觉得它应该取决于$\sigma$。例如，如果 $\sigma$ 很大，我会直观地减少最近值的权重，而如果 $\sigma$ 很小，我会增加最近值的权重。
但是，$\alpha$ 是否存在可以给出最佳估计的封闭形式？]]></description>
      <guid>https://stats.stackexchange.com/questions/658598/best-parameter-of-exponential-smoothing-when-applied-on-a-random-walk</guid>
      <pubDate>Wed, 11 Dec 2024 22:35:53 GMT</pubDate>
    </item>
    <item>
      <title>是否存在一种标准方法，通过纳入第二个协变量来量化和测试一个协变量的好处？</title>
      <link>https://stats.stackexchange.com/questions/658596/is-there-a-standard-way-to-quantify-test-the-benefit-to-one-covariate-by-inclu</link>
      <description><![CDATA[对于线性模型（或 glm），是否有标准统计数据（和相关测试）来量化包含协变量是否会增加另一个协变量与因变量之间的关联强度？
例如，我有两个模型：

Y ~ X1
Y ~ X1 + X2

我知道我可以使用似然比检验来评估模型 2 是否更能解释 Y，但这可能完全由 X2 的独立贡献驱动。是否有“测试”（甚至只是一个可解释的统计数据）来衡量在给定 X2 的情况下 X1 是否能显著（或有意义地）更好地解释 Y？]]></description>
      <guid>https://stats.stackexchange.com/questions/658596/is-there-a-standard-way-to-quantify-test-the-benefit-to-one-covariate-by-inclu</guid>
      <pubDate>Wed, 11 Dec 2024 22:05:08 GMT</pubDate>
    </item>
    <item>
      <title>如果我从数据框中删除一些变量或将因子载荷限制为 0，保留所有变量，为什么两个 CFA 模型不等效？lavaan</title>
      <link>https://stats.stackexchange.com/questions/658595/why-are-two-cfa-models-not-equivalent-if-i-drop-some-variables-from-my-dataframe</link>
      <description><![CDATA[探索嵌套与非嵌套模型时，我对一个奇怪的结果感到惊讶。第一个模型使用我的数据框中的 21 个变量并运行 CFA。第二个模型使用我的数据框中的 28 个变量，但将 7 个变量的因子载荷限制为 0。
mod1 &lt;- &quot;F1 =~ fig_1 + fig_2 + fig_3 + fig_4 + fig_6 + fig_7 + fig_10 + fig_11 + 
fig_12 + fig_13 + fig_14 + fig_15 + fig_17 + fig_18 + fig_19 + fig_20 +
fig_21 + fig_22 + fig_24 + fig_25 + fig_28&quot;

mod2 &lt;- &quot;F1 =~ fig_1 + fig_2 + fig_3 + fig_4 + fig_6 + fig_7 + fig_10 + fig_11 + 
fig_12 + fig_13 + fig_14 + fig_15 + fig_17 + fig_18 + fig_19 + fig_20 +
fig_21 + fig_22 + fig_24 + fig_25 + fig_28 +
0*fig_26 + 0*fig_23 + 0*fig_8 + 0*fig_9 + 0*fig_5 + 0*fig_16 + 0*fig_27&quot;

这两个 CFA 模型是
cfa1 &lt;- cfa(mod1 ,
data = df_mig %&gt;%
select(fig_1:fig_28) %&gt;%
select(-c(fig_26, fig_23, fig_8, fig_9,
fig_5, fig_16, fig_27)),
estimator = &#39;WLSM&#39;,
ordered=TRUE)
cfa2 &lt;- cfa(mod2 ,
data = df_mig %&gt;%
select(fig_1:fig_28), #使用所有列
estimator = &#39;WLSM&#39;,
ordered=TRUE)
因子载荷都相同，但模型拟合度却大不相同。

有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658595/why-are-two-cfa-models-not-equivalent-if-i-drop-some-variables-from-my-dataframe</guid>
      <pubDate>Wed, 11 Dec 2024 21:52:41 GMT</pubDate>
    </item>
    <item>
      <title>是否存在计算边际效应的标准方法？</title>
      <link>https://stats.stackexchange.com/questions/658594/is-there-a-standard-way-to-calculate-marginal-effects</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658594/is-there-a-standard-way-to-calculate-marginal-effects</guid>
      <pubDate>Wed, 11 Dec 2024 21:11:19 GMT</pubDate>
    </item>
    <item>
      <title>关于 $X^TX$ 的协方差矩阵</title>
      <link>https://stats.stackexchange.com/questions/658584/covariance-matrix-in-terms-of-xtx</link>
      <description><![CDATA[如果我有一个矩阵 $X\in \mathbb{R}^{n\times p}$，那么我可以将协方差写为
$$\text{Cov}(X) = \mathbb{E}[(X-\mu_X)(X-\mu_X)^T]$$
现在，假设数据已居中，则变为 $\text{Cov}(X) = \mathbb{E}[XX^T]$。我见过帖子说协方差是$XX^T$，而其他人提到$X^TX$是协方差。我不太明白这两个是如何得出的。]]></description>
      <guid>https://stats.stackexchange.com/questions/658584/covariance-matrix-in-terms-of-xtx</guid>
      <pubDate>Wed, 11 Dec 2024 18:10:08 GMT</pubDate>
    </item>
    <item>
      <title>如何在我的受污染数据问题中找到具有 ML 组件的去偏估计量？</title>
      <link>https://stats.stackexchange.com/questions/658578/how-to-find-a-de-biased-estimator-with-a-ml-component-in-my-contaminated-data-pr</link>
      <description><![CDATA[我试图使用机器学习模型的输出来估计（使用最大似然法）分布中的参数。我得到的估计量的偏差比参数值大得多。我想使用 Neyman 正交性/双机器学习方法（Chernozhukov et al., 2018）、影响函数或任何相关（或不相关）方法找到一个去偏估计量。但我不清楚如何在我的情况下构建去偏估计量。
我的估计问题
我已经“污染”了数据：大多数数据来自概率分布$P_0(x)$，但部分数据来自不同的分布$P_1(x)$（“污染”）。因此，我假设我的数据点是从分布$$P(x) = (1-\theta) P_0(x) + \theta P_1(x).$$中独立同分布抽取的。我的目标是找出受污染数据的比例$\theta$。 $\theta$ 的最大似然估计量是 $$0 = \frac{1}{n}\sum_i\frac{r(x_i)-1}{1+\hat{\theta}\bigl(r(x_i)-1\bigr)},$$ 的解，其中 $x_1,\ldots,x_n$ 是数据点，$r(x) = \frac{P_1(x)}{P_0(x)}$。
我不知道概率分布 $P_0(x)、P_1(x)$ 或它们的比率 $r(x)$直接，但我确实有另一个标记为数据集 $(\tilde{x}_i, y_i)$ 的数据点，其生成分布是已知的：对于从 $P_0$ 中抽取的点，$y_i=0$ ；对于从 $P_1$ 中抽取的点，$y_i=1$ ：$$Prob(\tilde{x}_i | y_i) = P_{y_i} (\tilde{x}_i)$$ （为简单起见，假设我有相同数量的 $\tilde{x}_i$，其中 $\tilde{x}_i$ class=&quot;math-container&quot;&gt;$y=0$ 和 $y=1$)。因此，我尝试通过两个步骤估计 $\theta$：

在标记数据集上训练 ML 分类器 $f(x)$ 以估计 $Prob(y=1|x)$，从而获得概率比的估计值为：$\hat{r}(x) = \frac{f(x)}{1-f(x)}$。

将此 $\hat{r}$ 代入 MLE 方程，得出 $$0 = \frac{1}{n}\sum_i\frac{\hat{r}(x_i)-1}{1+\hat{\theta}\bigl(\hat{r}(x_i)-1\bigr)},$$ 并求解 $\hat{\theta}$。


请注意，用于 MLE 估计（步骤 2）的数据集与用于训练 ML 模型（步骤 1）的数据不同且独立。
我的问题
$\hat{r}$ 是一个有偏估计量，例如在双重机器学习文献中讨论过（参见上面的链接）。因此，我得到了 $\theta$ 的有偏估计量。在我的案例中，我感兴趣的是 $\theta$ 的值远小于此偏差。因此，我想找到 $\theta$ 的去偏估计量。但我对如何将双重机器学习方法或影响函数应用于我的案例感到困惑。
在我的案例中，Neyman 正交 MLE 方程是什么？我如何使用我拥有的信息来找到污染分数 $\theta$ 的去偏估计量？]]></description>
      <guid>https://stats.stackexchange.com/questions/658578/how-to-find-a-de-biased-estimator-with-a-ml-component-in-my-contaminated-data-pr</guid>
      <pubDate>Wed, 11 Dec 2024 15:48:04 GMT</pubDate>
    </item>
    <item>
      <title>如何从具有分类变量的混合模型中估计总体方差？</title>
      <link>https://stats.stackexchange.com/questions/658575/how-to-estimate-population-variance-from-a-mixed-model-with-a-categorical-variab</link>
      <description><![CDATA[我以为这是一个基本问题，但我被它难住了，找不到解决方案。
我有一个数据库，其中包含不同养猪生产阶段（类别）的粪浆干物质含量，并且由不同的操作员（OP）在不同时刻（季节）采集样本。我只是对估计每个类别的平均值和方差总体感兴趣。
为了解决这个问题，我建立了一个线性混合模型，其中对因变量进行了平方变换。在测试了它们的重要性（AIC，BIC）之后，我将 OP 作为随机效应，将 CATEGORY 和 SEASON 作为固定效应。
 fit &lt;- nlme::lme(sqrt(MS) ~ CATEGORY + SEASON, random=~1|OP, data=dat
据我所知，每个 CATEGORY 中的估计平均值是每个固定效应值的对应 LSM。但是我不太清楚如何估计每个类别的方差。简化一下，我读到在一般线性回归中，模型的均方误差用于估计总体的方差，但在混合模型中，对于一些分组变量，我找不到任何关于如何计算它的解释。
也许每个固定效应的标准误差相当于MSE?
summary(fit)
固定效应：sqrt(MS) ~ CATEGORY + SEASON 
值 标准误差 DF t 值 p 值
(截距) 2.0142552 0.1127073 197 17.871557 0.0000
CATEGORYpiglets -0.2367893 0.1400533 197 -1.690708 0.0925
CATEGORYsows -0.8191891 0.1195440 197 -6.852615 0.0000
SEASONspring -0.0280369 0.02811633 194 -0.997177 0.3199
SEASONsummer -0.0126275 0.03969934 194 -0.318078 0.7508
SEASONoutom -0.0884407 0.02879816 194 -3.071054 0.0024

我的最终目标是估算覆盖 75% 人口的干物质含量值。你能帮我解决这个疑问吗？如果有用的话，我正在使用 R 中的 nlme 包。]]></description>
      <guid>https://stats.stackexchange.com/questions/658575/how-to-estimate-population-variance-from-a-mixed-model-with-a-categorical-variab</guid>
      <pubDate>Wed, 11 Dec 2024 13:37:53 GMT</pubDate>
    </item>
    <item>
      <title>如何用不准确的评估器计算置信区间？</title>
      <link>https://stats.stackexchange.com/questions/658562/how-to-compute-a-confidence-interval-with-an-inaccurate-evaluator</link>
      <description><![CDATA[让我们考虑以下针对 LLM 的提示：

系统提示：您是 Python 语言专家。您的角色是回答任何与 Python 相关的问题。
用户提示：&lt;用户查询&gt;

我想测试此系统提示以检查它是否正确回答了用户的问题。为此，我创建了一个问题数据集：

sqrt 函数在哪个模块中？
我可以使用哪个函数来降低字符串的字符数？
...

此数据集包含 5421 个问题。我已将此数据集提供给我的 LLM，并得到了 5421 个答案。我已审查了其中的 43 个，并使用 PASS/FAIL 评估对每个答案进行了评估。如果答案正确回答了用户的问题，则该答案被视为 PASS。在这 43 个答案中，我发现了 24 个 PASS 答案。
我现在希望另一个 LLM 评估这个系统提示。为此，我创建了一个 LLM-as-a-judge 作为评估者。这个 LLM-as-a-judge 的角色是执行我对 43 个答案所做的相同任务：使用 PASS/FAIL 评估来评估每个答案。
我向 LLM-as-a-judge 提供了我已经评估过的 43 个问题/答案。我发现这位评委 79% 的时间都同意我的观点。
然后，我向 LLM-as-a-judge 提供了我的数据集中的所有 5421 个问题/答案。 LLM-as-a-judge 对系统提示的评分为 87.12%（意味着系统提示的 87.12% 的答案被评估为 PASS）。
现在，由于 LLM-as-a-judge 的准确率为 79%（意味着它并不总是像我一样评估），我想知道我会给整个数据集打多少分（知道评委给出了 87.12% 的分数）。
我如何计算这个分数？是否有可能确定 87.12% 左右的置信区间？
注意：我是统计学新手，如果这个问题之前已经回答过，我很抱歉。我发现很难理解一些现有的问题和答案。请保持您的答案简单明了。]]></description>
      <guid>https://stats.stackexchange.com/questions/658562/how-to-compute-a-confidence-interval-with-an-inaccurate-evaluator</guid>
      <pubDate>Wed, 11 Dec 2024 08:23:24 GMT</pubDate>
    </item>
    <item>
      <title>如何排列 p 值？</title>
      <link>https://stats.stackexchange.com/questions/658523/how-to-permute-p-values</link>
      <description><![CDATA[最近，我的同事在处理一个数据集 df_a 时遇到了一个问题，该数据集包含基因数据。每一行代表一个 基因（通常有数千个，但为了简单起见，我们假设有 1,000 个），列代表不同的样本，这些样本可以分为两组，A 和 B（每组 50 个样本）。
我们使用 t.test 计算每行的 p 值并进行校正。假设我们使用 p.adjust &lt; 0.05 并且得到 30 个阳性结果。
这带来了一个问题：我们如何确保这 30 个结果不是由随机事件产生的？（也许这个问题是一个问题？）
我们设计了一个使用置换检验的流程来解决这个问题。步骤如下：
(1) 对于 df_a，我们随机打乱其列标签，重新计算每行的 p 值和 p.adjust，并计算 p.adjust &lt; 0.05 的行数，记为 Ki。
(2) 重复步骤 1 1,000 次，得到 K1,K2,K3,...,K1000。
(3) 计算大于 30 的 Ki 的数量，记为 n。计算 n/1000。如果该值小于 0.05，我们认为这 30 个结果不是由随机事件产生的。
作为一名程序员，我意识到这在数学上似乎存在问题，但我无法向同事提供严谨的证明来纠正它。希望得到您的帮助。
更新
我想更新的是，我认为这种排列不能提供有意义的附加信息。考虑一下当您对列标签进行混洗时，对于每一行，这相当于将组 A 和 B 混合在一起，然后随机抽取两组 A* 和 B*。基本的统计学原理告诉我们，这两组之间应该没有差异。因此，当您应用 t.test 时，所有 p.values &lt; 0.05 都是假阳性，显著性数字约为 5%。当你对这些数据应用p.adjust（例如使用FDR），并再次控制p.adjust &lt; 0.05时，这里的Ki将（始终）非常小（接近于0），以至于不可能否定任何结果。
我不是数学家，但通过程序模拟很容易看出这一点。我的观点是，当排列数有限（例如：1000）时，Ki的数学期望是一个与行数据相关的常数，并且这个值非常小。
请务必注意我们的步骤与经典排列测试之间的区别，它们非常相似，但存在差异。
我不知道这在数学上是否成立以及如何证明它。]]></description>
      <guid>https://stats.stackexchange.com/questions/658523/how-to-permute-p-values</guid>
      <pubDate>Tue, 10 Dec 2024 14:31:46 GMT</pubDate>
    </item>
    <item>
      <title>分类因变量 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658365/categorical-dependent-variable</link>
      <description><![CDATA[转发：
大家好，非常感谢您的回复。我在这里提供了一些信息。
a. 这是临床数据，样本量约为 859。
b. 它有 11 列作为输入特征，例如基因组的唯一读取，它是细菌还是病毒类型以及测序报告的病原体。它是分类值和数值的混合。
c. 依赖列有 53 个唯一值（医院检测到的病原体），我的模型将尝试预测这些值。
再次，任何关于如何处理这个问题的建议。
上一篇文章：
我正在尝试构建机器学习模型，其中因变量是分类的，并且有超过 60 个值。它们不是序数或遵循任何等级。
任何关于如何处理这个问题的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/658365/categorical-dependent-variable</guid>
      <pubDate>Fri, 06 Dec 2024 07:45:40 GMT</pubDate>
    </item>
    </channel>
</rss>