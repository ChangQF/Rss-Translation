<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 23 Aug 2024 01:08:20 GMT</lastBuildDate>
    <item>
      <title>假设检验中的正态分布参数化</title>
      <link>https://stats.stackexchange.com/questions/653209/paramaterization-of-the-normal-distribution-in-hypothesis-testing</link>
      <description><![CDATA[当查看 z 统计量如何适应正态分布 $f(x) = \frac{1}{\sigma \sqrt{2\pi} } e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}$ 时，我的直觉始终是它只是指数 $(\frac{x-\mu}{\sigma})$。
但是，根据这篇文章：
为什么 z 检验有两个公式？ 它清楚地表明，您应该始终使用标准误差平均值。
所以我的困惑是，在假设检验中使用正态分布时，是否应该将$\sigma$替换为$\sigma/\sqrt{n}$？]]></description>
      <guid>https://stats.stackexchange.com/questions/653209/paramaterization-of-the-normal-distribution-in-hypothesis-testing</guid>
      <pubDate>Fri, 23 Aug 2024 00:02:13 GMT</pubDate>
    </item>
    <item>
      <title>戴明回归的条件解释</title>
      <link>https://stats.stackexchange.com/questions/653204/conditional-interpretation-of-deming-regression</link>
      <description><![CDATA[我有一组 x-y 数据 $(x_i,y_i)$，其中 x 和 y 都有“离散度”。因此，我一直在使用戴明回归对它们进行直线拟合。另外，我使用的是戴明回归而不是正交回归，因为 x 和 y 的单位不同。无论如何，我得到了线性拟合，并且对此感到满意，只是我现在想有条件地解释它：给定 x，最可能的 y 和 y 的离散度是多少？这将对应于 $p(y|x)$。
我可以用这种简单的方式解释戴明模型吗？
这很令人困惑，因为戴明假设 x 和 y 都有误差……我想我可能需要进行某种积分来边缘化事物。可能假设我的 x 值是（比如说）正态分布的最可能值，然后积分正态和线性模型的乘积。不过，我对此并不确定。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653204/conditional-interpretation-of-deming-regression</guid>
      <pubDate>Thu, 22 Aug 2024 22:17:37 GMT</pubDate>
    </item>
    <item>
      <title>r - 动态自引用 [已迁移]</title>
      <link>https://stats.stackexchange.com/questions/653202/r-dynamic-self-referencing</link>
      <description><![CDATA[我试图创建一个列，如果满足条件，该列的值会增加，如果条件不满足，则重置为 1。
df &lt;- data.frame(
occ = c(&quot;11&quot;,&quot;11&quot;,&quot;12&quot;,&quot;13&quot;,&quot;13&quot;,&quot;13&quot;,&quot;13&quot;,&quot;11&quot;))

df$occPrev &lt;- lag(df$occ)

df

occ occPrev
1 11 &lt;NA&gt;
2 11 11
3 12 11
4 13 12
5 13 13
6 13 13
7 13 13
8 13 13
9 11 13

我想创建一个任期变量 ten，从 1 开始，如果 occ == occPrev，则增加 1，如果 occ != occPrev，则重置为 1。我想要得到的输出是
 occ occPrev ten
1 11 &lt;NA&gt; 1
2 11 11 2
3 12 11 3
4 13 12 1
5 13 13 1
6 13 13 2
7 13 13 3
8 13 13 4
9 11 13 5

我理想情况下希望在不依赖 for 循环的情况下实现此结果。到目前为止，我的尝试都没有成功，因为我找不到动态引用前一行的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/653202/r-dynamic-self-referencing</guid>
      <pubDate>Thu, 22 Aug 2024 20:38:56 GMT</pubDate>
    </item>
    <item>
      <title>在绘制主成分分析分数时，可以按比例放大主成分分析载荷来填充绘图区域吗</title>
      <link>https://stats.stackexchange.com/questions/653200/is-it-okay-to-scale-up-principal-component-analysis-loadings-to-fill-the-plottin</link>
      <description><![CDATA[我有以下图表，其中我绘制了主成分分析分数。

我在绘图区域叠加了载荷，但它们都很短，您看不到载荷及其标签。
是否可以将载荷按常数缩放，以便它们实际上可见，从而占据更多的绘图区域，或者这样做不合适？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653200/is-it-okay-to-scale-up-principal-component-analysis-loadings-to-fill-the-plottin</guid>
      <pubDate>Thu, 22 Aug 2024 19:35:48 GMT</pubDate>
    </item>
    <item>
      <title>手动计算的 Kendall tau-b 与 SPSS 输出结果存在差异</title>
      <link>https://stats.stackexchange.com/questions/653196/discrepancy-in-manually-calculated-kendalls-tau-b-vs-spss-output</link>
      <description><![CDATA[统计爱好者！
我在手动计算 Kendall 的 tau-b 时遇到了麻烦。我的结果与 SPSS 输出不同，我不知道哪里出了问题。以下是我的流程：
我正在使用以下数据分析锻炼水平 (0,1,2) 和乐观水平 (0,1,2) 之间的关联：
乐观 (y)：0,0,0,1,1,1,1,1,2,2,2,2,1,2,1
锻炼 (x)：0,0,0,0,0,1,1,1,1,1,2,2,2,2,2
我计算了：
一致对 (C)：49
不一致对 (D)：4
y 中的联系 (Ty)：34
x 中的联系 (Tx)：30
我使用了这个公式：
τb = (Nc - Nd) / √(Nc + Nd + Tx) * √(Nc + Nd + Ty)
代入数值：
τb = (49 - 4) / √(49 + 4 + 30) * √(49 + 4 + 34) ≈ 0.5295
但是，SPSS 给出的结果约为 0.617。
我使用在线计算器(https://statpages.info/ordinal.html) 仔细检查了我对 C、D、Tx 和 Ty 的计算，它们似乎是正确的。所以，我想知道：
公式中的括号是否错误？
我是否错误计算了一致或不一致的对？
我的平局计算有误吗？
我真的很感激任何关于我可能出错的地方的见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/653196/discrepancy-in-manually-calculated-kendalls-tau-b-vs-spss-output</guid>
      <pubDate>Thu, 22 Aug 2024 18:56:12 GMT</pubDate>
    </item>
    <item>
      <title>神经网络逻辑错误[重复]</title>
      <link>https://stats.stackexchange.com/questions/653194/neural-network-logic-errors</link>
      <description><![CDATA[我正在研究一个使用此数据集的神经网络项目；https://archive.ics.uci.edu/dataset/320/student+performance。
数据有两种主要类型。它有二进制（0 或 1）和数值选项（例如 1、2、3、4）。在我的神经网络中，我使用规范化函数将数据转换为二进制（从是/否）并将数值转换为 0 到 1 之间。网络有 32 个输入、1 个隐藏层、该层中的 22 个隐藏节点和一个输出。
网络存在一个问题，即在处理数据和训练时，它会产生荒谬的值，其中 w2 权重为 10^50 次方。
有人对此有什么建议吗？
如果您愿意，我也可以提供更多详细信息。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653194/neural-network-logic-errors</guid>
      <pubDate>Thu, 22 Aug 2024 18:36:55 GMT</pubDate>
    </item>
    <item>
      <title>python stats.spearmanr 和 R cor.test(method='spearman') 没有返回相同的 p 值？</title>
      <link>https://stats.stackexchange.com/questions/653193/python-stats-spearmanr-and-r-cor-testmethod-spearman-dont-return-the-same-p</link>
      <description><![CDATA[我尝试在 Python 和 R 中计算某些数据的斯皮尔曼 rho 值，但我得到的 P 值结果不同，我在 Python 中做错了什么？
import numpy as np
from scipy import stats

data = np.array([
[27,30],
[18,12],
[9,11],
[6,10],
[31,32],
[19,13],
[20,31]
])
stats.spearmanr(data[:,0], data[:,1],alternative=&#39;two-sided&#39;)
# SignificanceResult(statistic=0.9642857142857145, pvalue=0.0004541491691941689)


cor.test(x=c(27,18,9,6,31,19,20), y=c(30,12,11,10,32,13,31), method=&#39;spearman&#39;)
# Spearman 等级相关 rho
#
# 数据：c(27, 18, 9, 6, 31, 19, 20) 和 c(30, 12, 11, 10, 32, 13, 31)
# S = 2, p 值 = 0.002778
# 备选假设：真实 rho 不等于 0
# 样本估计值：
# rho
# 0.9642857

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/653193/python-stats-spearmanr-and-r-cor-testmethod-spearman-dont-return-the-same-p</guid>
      <pubDate>Thu, 22 Aug 2024 18:30:10 GMT</pubDate>
    </item>
    <item>
      <title>在图像分类中评估不同的可解释 AI (XAI) 工具，如 Grad Cam、SHAP 和 LIME</title>
      <link>https://stats.stackexchange.com/questions/653192/evaluating-different-explainable-ai-xai-tools-like-grad-cam-shap-and-lime-in</link>
      <description><![CDATA[祝您一切顺利。我目前正在进行一项论文项目，探索可解释的 AI (XAI) 工具，如 Grad Cam、SHAP 和 LIME 在图像分类中的应用。如果您能参与填写问卷，我将不胜感激，这将有助于评估这些模型的可解释性。您的参与是自愿且匿名的。
提前感谢您的时间和贡献。
https://docs.google.com/forms/d/e/1FAIpQLSf1wa3oX6fMOP0xgbaGrqA2kok_ZLd2RR0nwVXpMTQsr7_rlw/viewform?usp=sf_link]]></description>
      <guid>https://stats.stackexchange.com/questions/653192/evaluating-different-explainable-ai-xai-tools-like-grad-cam-shap-and-lime-in</guid>
      <pubDate>Thu, 22 Aug 2024 18:28:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么线性样条回归的结果显示出生理上不合理的系数？</title>
      <link>https://stats.stackexchange.com/questions/653198/why-are-the-results-from-the-linear-spline-regression-showing-physiologically-im</link>
      <description><![CDATA[为什么线性样条回归的结果显示生理上不可信的系数？
例如，考虑以下公式：
{r }
model_nstatin &lt;- lm(ldl ~ bs(pa, knots = c(600, 2400, 4200), degree = 1) + 
bs(age, knots = c(45, 55, 65), degree = 1) + sex + 
education + smoke + bs(mds, knots = c(4, 7), degree = 1), 
data = chol_nstatin)

该模型的截距为 3.42，体力活动（以 MET min/week 为单位）的样条系数如下：

-0.047（对于小于 600 的值，应该是-0.00047
600 到 2400 之间的值应为 -0.00091，而实际应为 -0.00091
2400 到 4200 之间的值应为 -0.112，而实际应为 -0.00112
大于或等于 4200 的值应为 -0.102，而实际应为 -0.00102

这些系数是以 mmol/L 为单位测量的 LDL 胆固醇。但是，下面提供的预测和图表在数学和生理上都是合理的。为什么样条系数在生理上看起来不正确（LDL 不能为负数）？例如，如果 PA 为 300，则相应的 LDL 值将为 -10.68。
以下是用于预测和绘图的代码：
nstatin &lt;- data.frame(
pa = seq(min(chol_nstatin$pa), max(chol_nstatin$pa), length.out = 117283),
age = mean(chol_nstatin$age),
sex = factor(&quot;Male&quot;, levels = levels(chol_nstatin$sex)),
education = factor(&quot;Vocational&quot;, levels = levels(chol_nstatin$education)),
smoke = factor(&quot;Ex-smoker&quot;, levels = levels(chol_nstatin$smoking)),
mds = mean(chol_nstatin$mds)
)

predictions_nstatin &lt;-预测（model_nstatin，newdata = nstatin，间隔 = “置信度”）

nstatin$ldl_pred &lt;- predictions_nstatin[，“fit”]
nstatin$lower &lt;- predictions_nstatin[，“lwr”]
nstatin$upper &lt;- predictions_nstatin[，“upr”]

结 &lt;- c（600，2400，4200）
x_limit &lt;- 6000
x_interval &lt;- 600

ggplot（nstatin，aes（x = pa，y = ldl_pred））+
geom_line（linewidth = 1.2，color = “red”）+
geom_ribbon（aes（x = pa，ymin = lower，ymax =上图), fill = &quot;lightblue&quot;, alpha = 0.2) +
geom_vline(xintercept = knots, linetype = &quot;dashed&quot;, color = &quot;blue&quot;) +
scale_x_continuous(
limits = c(0, x_limit),
breaks = seq(0, x_limit, by = x_interval),
labels = seq(0, x_limit, by = x_interval)
) +
labs(title = &quot;带置信区间的线性样条拟合&quot;, 
x = &quot;体力活动 (MET min/周)&quot;, y = &quot;LDL 胆固醇 (mmol/L)&quot;) +
theme_minimal()
]]></description>
      <guid>https://stats.stackexchange.com/questions/653198/why-are-the-results-from-the-linear-spline-regression-showing-physiologically-im</guid>
      <pubDate>Thu, 22 Aug 2024 09:28:51 GMT</pubDate>
    </item>
    <item>
      <title>依赖于辅助随机变量的一系列相互独立的变量</title>
      <link>https://stats.stackexchange.com/questions/653136/series-of-mutually-independent-variables-that-are-dependent-on-an-auxiliary-rand</link>
      <description><![CDATA[假设 $X_1, X_2, ... , X_n$ 是相互独立的随机变量。有一个随机变量 $C \sim U(-1,1)$，所有 $X$ 都依赖于它。我如何构造这样的 $X$，使它们无条件独立且均值为零？]]></description>
      <guid>https://stats.stackexchange.com/questions/653136/series-of-mutually-independent-variables-that-are-dependent-on-an-auxiliary-rand</guid>
      <pubDate>Wed, 21 Aug 2024 19:00:09 GMT</pubDate>
    </item>
    <item>
      <title>R lmer 帮助理解我的混合模型输出</title>
      <link>https://stats.stackexchange.com/questions/653130/r-lmer-help-understanding-my-mixed-model-output</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653130/r-lmer-help-understanding-my-mixed-model-output</guid>
      <pubDate>Wed, 21 Aug 2024 15:49:36 GMT</pubDate>
    </item>
    <item>
      <title>纪元 (epoch) 与数据复制相同吗？</title>
      <link>https://stats.stackexchange.com/questions/653012/are-epochs-the-same-as-data-duplication</link>
      <description><![CDATA[时期，即对原始数据重复训练的次数，对于神经网络来说是绝对必要的，因为神经网络的参数通常比原始实例多得多。
对于具有许多参数的其他 ML 方法，使用时期的方法论地位是什么？它们是否用于（我称之为）类技术，如随机森林？通过“方法论地位”，我隐藏了我的真实意图。也就是说，为什么不将时期用于普通的逻辑回归或决策树？为什么不将每个额外的时期视为数据增强，但使用相同的实例？如果建议重复数据以减少偏差，我觉得任何统计学家都会感到恶心。 ML 建模者会毫不犹豫地无限期地增加 epoch，直到训练/测试准确率开始变差（甚至可能到那时也不会变差！）。
那么

在传统预测模型中使用 epoch（基本重复实例）可以吗（只要考虑到过度拟合？
另一方面，一个 epoch 是否应该成为 NN 训练的标准，或者更确切地说，使用重复数据作为增强技术是否存在各种统计问题？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653012/are-epochs-the-same-as-data-duplication</guid>
      <pubDate>Mon, 19 Aug 2024 14:12:29 GMT</pubDate>
    </item>
    <item>
      <title>我可以直接使用模型的估计值而不考虑 p 值吗？</title>
      <link>https://stats.stackexchange.com/questions/652150/can-i-use-the-estimate-of-a-model-directly-without-considering-the-p-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652150/can-i-use-the-estimate-of-a-model-directly-without-considering-the-p-value</guid>
      <pubDate>Thu, 01 Aug 2024 12:43:03 GMT</pubDate>
    </item>
    <item>
      <title>使用比例响应数据和分类预测因子处理 GAM 中的自相关</title>
      <link>https://stats.stackexchange.com/questions/652097/dealing-with-autocorrelation-in-gams-with-proportional-response-data-and-categor</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652097/dealing-with-autocorrelation-in-gams-with-proportional-response-data-and-categor</guid>
      <pubDate>Wed, 31 Jul 2024 16:22:00 GMT</pubDate>
    </item>
    <item>
      <title>不平衡面板数据——最佳选择？</title>
      <link>https://stats.stackexchange.com/questions/651946/unbalanced-panel-data-best-options</link>
      <description><![CDATA[我有 1920-1935 年的一组购房交易。我希望研究一系列变量对这些交易规模的影响。这些交易通常涉及相同的买家，但它们在这段时间内的分布并不一致（例如，公司 A 可能在 1921 年、1927 年和 1933 年有重复交易，而公司 C 在 1922 年、1927 年、1930 年和 1935 年有重复交易）。
理想情况下，我会使用固定效应估计量来解释实体特定特征，但我认为我不能这样做，因为我没有足够的一致重复（如果我选择最佳间隔 - 在我的情况下是 1923 年、1927 年、1932 年和 1934 年 - 在这些年份我可以获得重复数据的公司数量最多为 8 家）。考虑到这个问题，我应该使用合并 OLS 回归吗？或者，我的数据是否最适合时间序列（尽管丢失实体级别变化似乎很可惜）？]]></description>
      <guid>https://stats.stackexchange.com/questions/651946/unbalanced-panel-data-best-options</guid>
      <pubDate>Mon, 29 Jul 2024 15:14:18 GMT</pubDate>
    </item>
    </channel>
</rss>