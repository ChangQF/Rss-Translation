<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 22 Nov 2024 21:16:35 GMT</lastBuildDate>
    <item>
      <title>当所有数量已知时，如何确定样本总体缺陷率代表总体缺陷率</title>
      <link>https://stats.stackexchange.com/questions/657701/how-to-determine-that-sample-population-defect-rate-represents-total-population</link>
      <description><![CDATA[我不知道如何正确表述这个问题，所以提前致歉。
假设我有两个总体的数据。总体 1 代表我制造的所有产品，每个产品都可以告诉我它是否有缺陷（使用属性数据，产品要么有缺陷，要么没有，每个产品只能出现一个缺陷）。因此，我有一个总样本量和整个总体的所有缺陷计数。我对此产品进行了更改，我想知道此更改是否会影响我的缺陷率。我使用较小的样本量对修改后的产品进行了一些试验，并统计了此较小样本量中发生的所有缺陷。
总体 1：100000
缺陷 A 数量：400，0.4%
缺陷 B 数量：8，0.008%
缺陷 C 数量：0，0%

总体 2：500
缺陷 A 数量：2，0.4%
缺陷 B 数量：1，0.2%
缺陷 C 数量：0，0%

如何确定两个总体之间的缺陷率是否相似，以及在这种情况下我可以有多大信心说它们相似？对于缺陷 A，当然，它们具有相同的缺陷率，但总体 2 中缺陷 A 的缺陷数量非常少，因此这在统计上可能并不显著。]]></description>
      <guid>https://stats.stackexchange.com/questions/657701/how-to-determine-that-sample-population-defect-rate-represents-total-population</guid>
      <pubDate>Fri, 22 Nov 2024 20:57:19 GMT</pubDate>
    </item>
    <item>
      <title>没有真实标签的模型比较</title>
      <link>https://stats.stackexchange.com/questions/657699/model-intercomparison-with-no-ground-truth-labels</link>
      <description><![CDATA[领域是天气建模。我有 4 个不同的模型，其中一个是我的，而其他 3 个是独立模型，我认为这些模型相对熟练（即比随机模型好得多）。每个模型在 1000 个感兴趣的空间位置（我将它们称为节点）中的每一个上预测一个值。遗憾的是，每个节点的真实值是无法测量的，因此无法明确地说出哪个模型最好。
但是，我可以说我的模型的预测（模型 A）与其他模型的相关性比任何其他模型都更好：




A
B
C
D




A
1
0.636338
0.571829
0.569591


B
0.636338
1
0.251786
0.283723


C
0.571829
0.251786
1
0.299746


D
0.569591
0.283723
0.299746
1



模型 A 比其他任何模型都更善于预测模型 B，A 与 C 和 A 与 D 也是如此。由于每个模型的预测都是一些预测的组合“真实”信号和一些噪音/错误，我假设我更好的整体相关性意味着我的模型可能比任何其他模型捕获更多的“真实”信号和更少的噪音。
这是一个有效的结论吗？如果是这样，有没有办法量化它，或者我可以引用一个参考资料来支持这个说法？]]></description>
      <guid>https://stats.stackexchange.com/questions/657699/model-intercomparison-with-no-ground-truth-labels</guid>
      <pubDate>Fri, 22 Nov 2024 20:20:57 GMT</pubDate>
    </item>
    <item>
      <title>支持混合数据类型和先验知识的因果发现包</title>
      <link>https://stats.stackexchange.com/questions/657698/causal-discovery-packages-supporting-mixed-data-types-and-prior-knowledge</link>
      <description><![CDATA[我是因果发现领域的新手，想将标准算法应用于我的数据集，该数据集包含分类变量和连续变量。我正在寻找可以处理混合数据类型并结合先验知识的 Python 包。但是，我发现大多数现有的因果发现 Python 包本身并不支持混合数据。
首先，对于基于约束的方法（如 PC 算法），Causal-Learn 包仅支持一种条件独立性测试。
基于约束的方法：实现 PC 算法的 Causal-Learn 包似乎仅支持一种条件独立性测试。这种限制在处理混合数据时可能会带来挑战。
结构方程模型 (SEM)：LiNGAM 系列中的许多方法都假设连续噪声，这可能使它们不适合包含离散变量的数据集（如果我错了，请纠正我）。虽然 LiNGAM 包确实为混合数据类型提供了类似 LiM 的方法，但这些方法似乎不支持纳入先验知识。]]></description>
      <guid>https://stats.stackexchange.com/questions/657698/causal-discovery-packages-supporting-mixed-data-types-and-prior-knowledge</guid>
      <pubDate>Fri, 22 Nov 2024 19:24:12 GMT</pubDate>
    </item>
    <item>
      <title>针对未观测数据的分层 Dirichlet Gibbs 采样</title>
      <link>https://stats.stackexchange.com/questions/657696/heirarchical-dirichlet-gibbs-sampling-for-unobserved-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657696/heirarchical-dirichlet-gibbs-sampling-for-unobserved-data</guid>
      <pubDate>Fri, 22 Nov 2024 18:39:38 GMT</pubDate>
    </item>
    <item>
      <title>比较不同季节中不同温度区间内所花的时间</title>
      <link>https://stats.stackexchange.com/questions/657695/compare-time-spent-within-different-temperature-bins-between-seasons</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657695/compare-time-spent-within-different-temperature-bins-between-seasons</guid>
      <pubDate>Fri, 22 Nov 2024 17:57:13 GMT</pubDate>
    </item>
    <item>
      <title>探索性因子分析、斜向旋转、方差解释</title>
      <link>https://stats.stackexchange.com/questions/657692/exploratory-factor-analysis-oblique-rotation-variance-explained</link>
      <description><![CDATA[如何计算通过探索性因子分析获得的因子模型解释的方差的问题时常出现。这里有一个包含多种可能性的摘要：在 R 中使用斜旋转进行探索性因子分析后计算因子解释的方差
我使用的是 R，带有 psych 包，如代码片段所示：
library(psych)

fa_results &lt;- fa(df_sq1sq9, nfactors = 5, rotate = &quot;oblimin&quot;)
mean(fa_results$communalities)
print(fa_results)


平均共同体数量：0.7418824
摘要表还报告了 0.74 作为解释的斜交旋转方差：
[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.45 1.50 1.07 1.05 0.60
比例方差 0.27 0.17 0.12 0.12 0.07
累积方差 0.27 0.44 0.56 0.68 0.74
解释比例 0.37 0.22 0.16 0.16 0.09
累积比例 0.37 0.59 0.75 0.91 1.00

因子相关性为 
MR1 MR3 MR5 MR2 MR4
MR1 1.00 0.59 0.64 -0.01 0.30
MR3 0.59 1.00 0.33 0.12 0.21
MR5 0.64 0.33 1.00 0.28 0.11
MR2 -0.01 0.12 0.28 1.00 -0.17
MR4 0.30 0.21 0.11 -0.17 1.00


如果我使用正交旋转（例如方差最大法）进行相同的分析，那么我会得到相同的总方差解释值。据我了解，正交旋转会在因子之间重新分配载荷，但总方差解释对于整个系统保持不变。但是，我不确定斜向旋转，因为因子在它们解释的方差方面重叠。在上面的例子中，我发现一些因子之间存在显著的相关性，但与方差最大法相比，我得到的总方差解释值相同。在这种情况下，总解释方差是否也相同，或者我做错了什么？我需要反馈。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657692/exploratory-factor-analysis-oblique-rotation-variance-explained</guid>
      <pubDate>Fri, 22 Nov 2024 17:10:04 GMT</pubDate>
    </item>
    <item>
      <title>如何将收缩应用于非中心二阶矩估计</title>
      <link>https://stats.stackexchange.com/questions/657690/how-to-apply-shrinkage-to-non-centered-second-moment-estimate</link>
      <description><![CDATA[我有一组 $N$ 个样本 $X_i \in \mathbb{R}^m$，属于随机变量 $X$，其中 $m$ 和 $N$ 具有可比性。我想估计二阶矩矩阵$\mathbb{E}\left[XX^T\right]$。
对于估计均值$\mathbb{E}\left[(X-\mu)(X-\mu)^T\right]$（其中$\mu=\mathbb{E}[X]$）周围协方差的相关问题，当$m$和$N$具有可比性时，通常最好不要直接使用样本协方差，而是在估计中应用收缩，例如Ledoit-Wolf 协方差估计。
我想知道的是，我将如何使用这种收缩方法对非中心二阶矩矩阵进行处理。因为
$$\mathbb{E}\left[XX^T\right] = \mathbb{E}\left[(X-\mu)(X-\mu)^T\right] +\mu\mu^T$$
并表示 $A=\mathbb{E}\left[(X-\mu)(X-\mu)^T\right]$ 和 $B=\mu\mu^T$，我认为一个选项是：

使用收缩获得 $A$
使用样本估计的平均值获得 $B$
将它们加在一起以获得估计$\mathbb{E}\left[XX^T\right]$的收缩。

这听起来像是一种合理的方法吗？还是我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657690/how-to-apply-shrinkage-to-non-centered-second-moment-estimate</guid>
      <pubDate>Fri, 22 Nov 2024 15:57:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么在进行超参数调整和模型选择时使用嵌套验证？</title>
      <link>https://stats.stackexchange.com/questions/657688/why-use-nested-validation-when-doing-both-hyper-parameter-tuning-and-model-selec</link>
      <description><![CDATA[专著交叉验证包含一节有关超参数优化的嵌套交叉验证（第 6 页）。作者引用了这篇论文，解释了为什么最好将 hp-search 与模型选择分离，但我没有找到直观易懂的答案。简而言之，我的问题是：

如果具有不同超参数值的 ML 算法可以看作两种不同的 ML 算法（并且似乎可以使用平面验证方法来选择最佳 ML 算法）？为什么要使用嵌套验证进行 hp-search 和模型选择？

为了使问题精确，下面我将详细描述什么是嵌套验证和平面验证。为简单起见，我将省略交叉部分，并且不将数据分成折叠——问题的核心保持不变，因此我相信原因也应该保持不变。
使用平面验证进行 HP 调整和模型搜索
此过程将数据集分为两部分

best_model_family = none
best_hp = none
best_model = none
best_score = none
对于每个 model_family:
对于 model_family 的每个 hp 值:
model = model_family.train(hp, A)
score = assess(model,V)
if score &gt; best_score：//越大越好
best_model_family = model_family
best_hp = hp
best_model = model
best_score = score

完成该过程后，best_hp 包含超参数值，可产生得分最高的模型。值 best_score 是生产模型性能的预测，其中生产模型将在整个数据集上进行训练：model = best_model_family.train(best_hp, A \cup V)。
作者说这种方法容易过度拟合，因为最佳模型和最佳超参数是使用相同数据挑选的。我不明白为什么仅仅使用相同的数据集进行两次搜索就会导致过度拟合。对我来说，使用不同的超参数值类似于使用不同的模型系列。例如，考虑最近邻 ML 算法，并让其超参数为邻居的数量。对我来说，NN(3) 描述的是与 NN(4) 不同的模型系列。使用平面验证来选择最佳模型系列被认为是可以的。但是，一旦我们将邻居的数量视为超参数，使用平面验证就不再合适了。 我在这里遗漏了什么？作为参考，我现在描述什么是嵌套验证方法，用于 hp 调整和模型选择。
嵌套循环中的 HP 调整（嵌套验证）
嵌套验证方法将数据集分为三部分：原始集 A 分为两部分：A = A&#39; \cup B。超参数调整是通过对 A&#39; 进行训练和对 B 进行评估来执行的（这就是该方法被称为“嵌套”的原因），而模型选择与以前一样，通过对 A=A&#39;\cup B 进行训练和对 V 进行评估来执行，使用之前找到的最佳超参数。

对于每个 model_family:
best_score = none
对于 model_family 的每个 hp 值:
model = model_family.train(hp, A&#39;)
score = assess(model,B)
if score &gt; best_score: // 越大越好
best_hp[model_family] = hp

best_model_family = none
best_score = none
对于每个 model_family:
model = model_family.train(best_hp[model_family], A&#39; \cup B)
score = assess(model,V)
if score &gt; best_score：//越大越好
best_model_family = model_family
best_score = score

执行该过程后，best_model_family 就是我们想要在生产中使用的 ML 算法，我们使用超参数值 best_hp[best_model_family] 在整个数据集上对其进行训练。]]></description>
      <guid>https://stats.stackexchange.com/questions/657688/why-use-nested-validation-when-doing-both-hyper-parameter-tuning-and-model-selec</guid>
      <pubDate>Fri, 22 Nov 2024 15:49:41 GMT</pubDate>
    </item>
    <item>
      <title>我是否以正确的方式对加权分类调查数据进行统计显着性检验？</title>
      <link>https://stats.stackexchange.com/questions/657687/am-i-going-about-statistical-significance-testing-for-weighted-categorical-surve</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657687/am-i-going-about-statistical-significance-testing-for-weighted-categorical-surve</guid>
      <pubDate>Fri, 22 Nov 2024 15:12:36 GMT</pubDate>
    </item>
    <item>
      <title>关于神经网络反向传播的问题</title>
      <link>https://stats.stackexchange.com/questions/657684/questions-on-backpropagation-in-a-neural-net</link>
      <description><![CDATA[我理解如何以符号方式应用反向传播，用笔和纸计算公式。当真正将这些推导应用于数据时，我有两个问题：

假设某个梯度看起来像 $o_i \times w_{i,j}$，其中 $o_i$ 是第 $i$ 个神经元的输出，而 $w_{i,j}$ 是其权重之一。现在我有一批数据点，$o_i$ 中的每个数据点都有不同的值，那么我该如何用数字计算它？我是否只需对该批次中的所有数据点取平均值？
换句话说：假设我将误差（最后）定义为平均值，那么该平均值（期望值）是否只是与其余的反向传播一起传播，并且每当我看到输入数据的依赖性时，我只需插入平均运算符？
有人可以提供一些关于此的直觉吗？我的看法是，因为误差位于所有梯度的“分子”中，所以无论我们对它做什么，无论是平均还是求和，都可以简单地向后传播，您只需对您看到的所有项执行该运算符（例如平均）。如果您有一个常数（例如权重），它不会做任何事情，如果您有一个输出，您会对批次进行平均。这是合理的解释吗？

如果我们有一个较早的神经元 $N$，它在后面的层中作为输入出现两次，在进行反向传播时，我们可以在第二次遇到它时对其导数执行 $+=$，即我们可以天真地将各种梯度​​贡献相加。但是这个神经元可以以不同的方式参与后续神经元，它们可能有不同的数学表达式等。然而，我们可以天真地将其所有梯度相加，这是如何工作的？
这是一个很好的属性，但我不明白它是如何如此简单地发挥作用而没有任何问题。有人可以提供直观的解释吗？这似乎与“反向传播如何分块、分步骤地工作，因此确切的依赖关系不应该重要”有关，这是我目前的理解水平。

]]></description>
      <guid>https://stats.stackexchange.com/questions/657684/questions-on-backpropagation-in-a-neural-net</guid>
      <pubDate>Fri, 22 Nov 2024 14:20:10 GMT</pubDate>
    </item>
    <item>
      <title>Ian Goodfellow 的深度学习书中介绍 softmax 近似的原因</title>
      <link>https://stats.stackexchange.com/questions/657683/reason-for-softmax-approximation-in-ian-goodfellows-deep-learning-book</link>
      <description><![CDATA[在第 6.2.2.2 节（公式 6.31）中，他们指出：

总体而言，非正则化最大似然将驱动模型学习驱动 softmax 预测训练集中观察到的每个结果的计数分数的参数：
$$
\text{softmax}(\pmb{z}(\pmb{x},\pmb{\theta}))_i \approx \frac{\sum_{j=1}^{m}\pmb{1}_{y^{(j)}=i,\pmb{x}^{(j)}=\pmb{x}}}{\sum_{j=1}^{m}\pmb{1}_{x^{(j)}=\pmb{x}}}
$$

其中 $m$ 是训练集中的示例数量。
1. 如何得出这个近似值？
（此相关问题仅讨论了一个例子）
2.这个近似值是否等于以下内容：
$$
\begin{align}
&amp;\stackrel{?}{=}\frac{P_\text{data}(y=i,\pmb{x})}{P_\text{data}(\pmb{x})} \\
&amp;=P_\text{data}(y=i|x) \\
&amp;\approx P_\text{true}(y=i|x)
\end{align}
$$
此外，如果是，这是否就是为什么具有 softmax 的神经网络实际上学习所需的概率分布而不是 $[0,1]$ 上其他一些度量的原因？]]></description>
      <guid>https://stats.stackexchange.com/questions/657683/reason-for-softmax-approximation-in-ian-goodfellows-deep-learning-book</guid>
      <pubDate>Fri, 22 Nov 2024 14:02:49 GMT</pubDate>
    </item>
    <item>
      <title>两组样本数不同但增长至相同值的相关性</title>
      <link>https://stats.stackexchange.com/questions/657680/correlation-of-two-sets-growing-to-the-same-value-but-different-number-of-sample</link>
      <description><![CDATA[如何获取两个不同长度的集合之间的相关性？我知道皮尔逊相关性不起作用。但是如果它们增长到相同的值，我可以做些什么吗？这就是我的意思。
假设我有两个集合：
[1, 2, 3, 4] 和 [1, 1, 2, 2, 1, 3]
我们可以看到它们的长度不同，但总和相同。
[1, 3, 6, 10] 和 [1, 2, 4, 6, 7, 10]
我们可以看到它们都累积到 10。
我在想，如果我将它们绘制成 x 轴上的累积和以及 y 轴上的原始点。我可以像“连接点”一样。之后，我在想也许我可以对它们进行卷积或者类似的事情，或者像它们的内积？不太确定我在说什么。
这能行得通吗？你能建议一些可以帮助解决这个问题的方法吗？
非常感谢！
编辑：
在回答这些数据代表什么的问题时，这个问题是一个信号处理问题。
系统的工作方式如下。我在一段时间内收到随机数量的尖峰。就我上面的示例而言，假设为 10 秒。
每 10 秒，我都会读取一些尖峰，但尖峰到达的时间与前一个尖峰的时间不同。这就是这个集合所代表的内容：
[1, 2, 3, 4] 和 [1, 1, 2, 2, 1, 3]
现在的问题是，这两个有多大关系？
编辑 2：
在这种情况下，“相关”是什么意思？
对于我的应用程序，“相关”的概念看起来像这样：
[5, 4, 3, 2, 1]
与...略有关系
[4, 3, 2, 1, 1, 2, 2]
如果我绘制到达时间的曲线，一个只是另一个的延迟版本。
我不知道如何称呼我试图描述的这个属性。希望这个描述有所帮助！
编辑 3：
给定：[5, 4, 3, 2, 1]
我们还可以说它与以下内容相关：
[3.9, 3.1, 2, 0.8, 1.2, 2, 2]
此外，我需要能够判断采样是晚还是早。
我们可以说
[3.9, 3.1, 1.9, 0.8, 1.2, 2, 2]
与给定值相比晚了。
并且
[2.5, 5, 4, 3, 0.5]
与给定值相比早了。
编辑4：
抱歉，这有点令人困惑。
什么是晚，什么是早？
给定 A = [5, 4, 3, 2, 1]
B = [4, 3, 2, 1, 1, 2, 2]
且 C = [1, 5, 4, 3, 2]
与 A 相比，B 晚了。
与 A 相比，C 早了。
直觉是这样的。

[5, 4, 3, 2, 1] -&gt; A：完美时机
[4, 3, 2, 1, 1, 2, 2] -&gt; B：晚时机
[1, 5, 4, 3, 2] -&gt; C：早期时间

看到 B 的某些部分与 A 相似，C 同样与 A 相似。它们有相似之处，但索引发生了偏移。
B 和 C 与 A“相关”。
此外，我们可以说
D = [3.9, 3.1, 2, 0.8, 1.2, 2, 2]
D 是 B 的一个略微不准确的版本。
在我的“相关”上下文中，D 也与 A 相关。
希望有所帮助！
编辑 5：
关于“早期”和“晚期”的更多说明
这是 MATLAB 代码及其结果。注意 C 图中与 A 相似的部分位于 A 的右侧。这就是我所说的“早”的意思。B 中的相同部分位于 A 的左侧。这就是“晚”的意思。就像想象时间域中的信号一样。如果信号是早的，它位于参考的右侧。如果它是晚的，它位于参考的左侧。
A = [5 4 3 2 1];
B = [4 3 2 1 1 2 2];
C = [1 5 4 3 2];
D = [3.9 3.1 2 0.8 1.2 2, 2];

cuA = cumsum(A);
cuB = cumsum(B);
cuC = cumsum(C);
cuD = cumsum(D);

图;
plot(cuA, A, &#39;y&#39;);
等待;
plot(cuB, B, &#39;r&#39;);
plot(cuC, C, &#39;b&#39;);
plot(cuD, D, &#39;g&#39;);

legend(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;);

]]></description>
      <guid>https://stats.stackexchange.com/questions/657680/correlation-of-two-sets-growing-to-the-same-value-but-different-number-of-sample</guid>
      <pubDate>Fri, 22 Nov 2024 12:03:51 GMT</pubDate>
    </item>
    <item>
      <title>如何从 N-2 边际生成 N 维多元正态样本</title>
      <link>https://stats.stackexchange.com/questions/657678/how-to-generate-n-dimensional-multivariate-normal-sample-from-n-2-marginals</link>
      <description><![CDATA[我的“计算器”遇到了一个问题，它使用通过 N 维多元正态分布生成的样本。我在下面附上了一个代码片段来说明这个问题。
我的计算器从 sample_1 中提取：

M：对 sample_1 中的每个数字都敏感的数字
M_n：一个由 N 个数字组成的向量，每个数字都对 sample_1 中的一列且仅一列敏感

现在，我需要分析我的计算器对相关矩阵中一个特定元素的敏感度。我通过将 correlation_matrix_1 中的 (0, 1) 元素从 0.0 更改为 0.02 来实现。简而言之，问题在于 sample_2 中的第 3 列与 sample_1 中的第 3 列不同。这会导致 M_2 发生更改，这是不理想的结果。两个示例的屏幕截图都位于本消息的末尾，
现在的问题是：我如何从以下位置生成 sample_2 的第 0 列和第 1 列：

sample_1 的第 2 列 -&gt;修复 M_2
correlation_matrix_2

请注意，我必须能够对更大的矩阵执行此操作，尽管仍然需要每次更改一个矩阵元素。
import numpy as np

def main(correlation_matrix: np.ndarray, mc_seed: int = 1234,
n_trials: int = 10):
generator = np.random.default_rng(seed=mc_seed)
segment_factor_sample = generator.multivariate_normal(
mean=[0] * correlation_matrix.shape[0],
cov=correlation_matrix,
size=n_trials,
check_valid=&#39;raise&#39;)
returnsegment_factor_sample

if __name__ == &#39;__main__&#39;:
correlation_matrix_1 = np.array([[1.0, 0.0, 0.0],
[0.0, 1.0, 0.0],
[0.0, 0.0, 1.0]])
sample_1 = main(correlation_matrix_1)

correlation_matrix_2 = np.array([[1.0, 0.02, 0.0],
[0.02, 1.0, 0.0],
[0.0, 0.0, 1.0]])
sample_2 = main(correlation_matrix_2)


sample_1


sample_2]]></description>
      <guid>https://stats.stackexchange.com/questions/657678/how-to-generate-n-dimensional-multivariate-normal-sample-from-n-2-marginals</guid>
      <pubDate>Fri, 22 Nov 2024 11:33:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么 R 中的二项式家族（link="log"）的 glm 有时需要起始值？</title>
      <link>https://stats.stackexchange.com/questions/657665/why-does-glm-in-r-with-family-binomiallink-log-sometimes-require-start-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657665/why-does-glm-in-r-with-family-binomiallink-log-sometimes-require-start-value</guid>
      <pubDate>Fri, 22 Nov 2024 09:25:45 GMT</pubDate>
    </item>
    <item>
      <title>rugarch 包中条件方差的初始值是如何计算的？</title>
      <link>https://stats.stackexchange.com/questions/657651/how-are-the-initial-value-of-conditional-variance-calculated-in-rugarch-package</link>
      <description><![CDATA[我正在尝试使用 rugarch 库验证我的零均值 GARCH(1,1) 模型的计算。起初，我认为条件方差的初始第一个值与无条件方差（python 中的 arch 包使用）的值相同，因为没有过去的回报，也没有过去的方差来计算它。
但是当我使用 garch_fit@fit$var 重新检查条件方差的第一个初始值时，它与无条件方差不同。
我尝试使用计算器手动计算无条件方差，它给出的输出与 uncvariance(garch_fit) 相同，这不是模型中条件方差的初始第一个值。那么，如果 GARCH 过程不是由无条件方差初始化的，那么第一个值是如何计算的呢？
以下是我的规范代码：
garch_spec &lt;- ugarchspec(
mean.model = list(armaOrder = c(0, 0), include.mean = FALSE), # 无 ARMA 项，零均值
variance.model = list(model = &quot;sGARCH&quot;, garchOrder = c(1, 1)), # GARCH(1, 1)
distribution.model = &quot;norm&quot; # 正态分布
)
garch_fit &lt;- ugarchfit(
spec = garch_spec,
data = data$log_return_pct,
solver = &quot;hybrid&quot;,
out.sample = 83
)

以及两者之间的区别第一个初始方差
&gt; uncvariance(garch_fit)
[1] 0.5865156
&gt; garch_fit@fit$var[1]
[1] 0.5869211
]]></description>
      <guid>https://stats.stackexchange.com/questions/657651/how-are-the-initial-value-of-conditional-variance-calculated-in-rugarch-package</guid>
      <pubDate>Fri, 22 Nov 2024 00:48:50 GMT</pubDate>
    </item>
    </channel>
</rss>