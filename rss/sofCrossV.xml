<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 29 Oct 2024 01:17:33 GMT</lastBuildDate>
    <item>
      <title>Gamma 分布 glm 标准化</title>
      <link>https://stats.stackexchange.com/questions/656438/gamma-distribution-glm-standardisation</link>
      <description><![CDATA[我想对似乎具有两种分布的生物标志物进行建模。我想对相隔三年的两次就诊中的生物标志物变化进行建模。但是，我正尝试使用 R 中的 glm 和伽马分布来执行此操作。我已经标准化了生物标志物变化，因此我可以比较所有生物标志物。但是它说它不能取负值？有人可以给出建议吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/656438/gamma-distribution-glm-standardisation</guid>
      <pubDate>Mon, 28 Oct 2024 23:33:12 GMT</pubDate>
    </item>
    <item>
      <title>连接词之间的相似性度量</title>
      <link>https://stats.stackexchange.com/questions/656436/similarity-measure-between-copulas</link>
      <description><![CDATA[我有五个 1,000,000$\times$30 矩阵，标记为 $M_1、M_2、M_3、M_4、M_5$。这些矩阵中的每一列都由随机均匀分布 $\in[0, 1]$ 组成。五个 $30\times 30$ 协方差矩阵几乎相同。
我需要确定 $\{M_2, M_3, M_4, M_5\}$ 中的哪个矩阵最“相似”到 $M_1$，即 $\{M_2, M_3, M_4, M_5\}$ 中的哪一个最有可能是来自与 $M_1$ 相同的 copula 的样本。
为方便起见，我们甚至可以假设每个矩阵中的每一列都包含整数 $\in[1, 1000000]$。
那么，两个依赖结构（copulas）的有效相似性度量是什么？在这里我想排除任何与协方差矩阵相关的方法，因为它们几乎相同。
我知道地球移动距离 (EMD)，它可以作为测量两个多元分布之间距离的通用方法。但是，由于我们只对 copula 感兴趣，而 EMD 的计算成本很高，有没有捷径？
天真地讲，我能想到很多启发式方法。例如，我可以
(i) 按第一列对 $M_1$ 和 $M_2$ 进行排序，
(ii) 逐元素计算矩阵之间的平方差和，
(iii) 对每一列重复 (i) 和 (ii)，
(iv) 将所有平方差和相加。
最终的总和将是两个 copula 之间的距离。
或者，我可以计算 $M_1$ 和 $M_2$ 的特征向量，按其各自的特征值排序，然后计算加权（按特征值的平方）欧几里得平方和特征向量之间的距离。
有人能就此提供一些实用的见解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656436/similarity-measure-between-copulas</guid>
      <pubDate>Mon, 28 Oct 2024 22:06:49 GMT</pubDate>
    </item>
    <item>
      <title>R 中的对数变换[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656432/logarithmic-transformation-in-r</link>
      <description><![CDATA[我想知道如何对我的数据进行对数转换。我的因变量是“花费”，我的预测变量是“收入”。但我陷入了这样一个境地：我发现我的数据存在异方差，现在我必须对其进行转换。]]></description>
      <guid>https://stats.stackexchange.com/questions/656432/logarithmic-transformation-in-r</guid>
      <pubDate>Mon, 28 Oct 2024 20:45:29 GMT</pubDate>
    </item>
    <item>
      <title>如果聚类内的样本大小不一致，如何正确计算方差估计值？</title>
      <link>https://stats.stackexchange.com/questions/656430/how-is-the-variance-estimate-calculated-correctly-if-there-are-unequal-sample-si</link>
      <description><![CDATA[我有一个聚类数据集。所有聚类的样本大小都不相等。我想计算聚类稳健方差估计，特别是考虑到聚类内样本大小的不相等。我尝试了一些方法，但不确定是否正确。由于每个聚类的样本数量不同，使用与聚类大小成比例的缩放因子 sqrt(ni/N) 或 (ni/N) 来调整它们对方差估计的贡献是否正确？ （注：其中 ni 是聚类 𝑖 中的观测数，𝑁 是观测总数）
谢谢。
cv.init&lt;-cv.glmnet(X.a, y.a, lambda=seq(2, 0.1, -0.1)*sqrt(2*log(p)/N))
beta.hat&lt;-coef(cv.init, s=cv.init$lambda.min)[-1] 
res&lt;-y.a-X.a %*% beta.hat
lam.seq&lt;-seq(2, 0.1, -0.1)*sqrt(2*log(p)/N)
beta.db.sd &lt;-rep(NA,length=length(coord))
beta.db &lt;-rep(NA,length=length(coord))

for(j in 1:length(coord)){
col.j&lt;-coord[j]

cv.x&lt;-cv.glmnet(X.a[,-col.j], X.a[,col.j], lambda=lam.seq)
gam.j&lt;- coef(cv.x, s=cv.x$lambda.min)[-1]
wj.mlm &lt;- X.a[,col.j]- X.a[,-col.j]%*%gam.j
denom &lt;- sum(wj.mlm * X.a[, col.j]) / N
beta.db[j] = beta.hat[col.j] + sum( wj.mlm * res)/(N*denom)

# 聚类稳健方差估计
psi_i &lt;- wj.mlm * res / (N*denom)
S &lt;- numeric(n)
for (i in seq_len(n)) {
cur.grp = cluster_ids[i]
idx &lt;- which(grp == cur.grp)
ni &lt;- length(idx)
S[i] &lt;- sqrt(ni/N)*sum(psi_i[idx])
}
# 自由度调整
G &lt;- n
var_beta_j &lt;- (G / (G - 1)) * sum(S^2)
beta.db.sd[j] &lt;- sqrt(var_beta_j)
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/656430/how-is-the-variance-estimate-calculated-correctly-if-there-are-unequal-sample-si</guid>
      <pubDate>Mon, 28 Oct 2024 19:42:04 GMT</pubDate>
    </item>
    <item>
      <title>不确定研究场景中测试什么、如何测试以及潜力</title>
      <link>https://stats.stackexchange.com/questions/656429/unsure-as-to-what-tests-how-and-potential-in-a-research-scenario</link>
      <description><![CDATA[有三个教室，里面的学生年级不同。我想分析一下这些变量中哪些影响了考试得 0 分的可能性。这些因素包括：年级（8、9 或 10）和压力水平范围（0 到 3）。对于得分为 0 的学生，我想从统计上比较这些因素。我该怎么做？我有 Excel 和 Jamovi（一款 R 软件）。我主要想将其制作成最多两个图表，最重要的是找出得分为 0 分的学生在压力水平和年龄之间是否存在显著差异。这是我为正在进行的一个项目想出的一个类比，但我不允许分享——但这是我遇到的相同统计问题。我的数据如下所示：测试分数（连续小数变量）-&gt; 分数列表。压力水平（序数变量，0 1 2 或 3）。年级（序数）8、9 或 10]]></description>
      <guid>https://stats.stackexchange.com/questions/656429/unsure-as-to-what-tests-how-and-potential-in-a-research-scenario</guid>
      <pubDate>Mon, 28 Oct 2024 19:07:42 GMT</pubDate>
    </item>
    <item>
      <title>从未知函数的样本中学习概率分布</title>
      <link>https://stats.stackexchange.com/questions/656428/learning-a-probability-distribution-from-samples-drawn-from-unknown-function</link>
      <description><![CDATA[我想从数据中学习一些概率分布$p$（例如，使用核密度估计、正则化流，无论你最喜欢的机器学习模型是什么）。
如果我有一个数据集$D = [x_1, \dots , x_N]$，其中$x_{[0,\dots,N]} \sim p(x)$，如果我正在训练某个模型$\hat{p}_{\theta}$（其中$\theta$是模型参数），我会做一些事情，比如最小化负对数似然，即优化：
$$\arg\min_{\theta} \mathbb{E}_{p(x)}[-\log \hat{p}_{\theta}(x)]$$
其中
$$\mathbb{E}_{p(x)}[-\log\hat{p}_\theta(x)] \approx \sum_{i=0}^{N} -\log \hat{p}_{\theta}(x_i)$$
但是，我目前的情况是不知道数据来自哪个分布，但可以访问 p 下每个数据点的可能性。也就是说，我有：
$$D = [\langle x_1, p(x_1)\rangle, \dots \langle x_N, p(x_N)\rangle]$$
我不知道$x_1, \dots x_N$是在哪个分布下生成的（具体来说，从一些未知的有偏差分布中生成大量样本，然后实验者通过确定性顺序贝叶斯优化过程收集这些“好”样本的子集，然后通过一些昂贵的模拟计算出可能性$p(x_i)$）。
在这种情况下，我还能学到一些关于$p$的知识吗？
因为附注：我知道如果我知道其他分布是什么（假设 $x_i$ 由 q(x) 生成），我可以通过重要性抽样学到一些东西。即，我可以优化：
$$\arg \min_{\theta} E_{q(x)}[-\log \hat{p}_{\theta}(x)\frac{p(x)}{q(x)}]$$
但鉴于我掌握的信息绝对比这少……我还能用这些数据做什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656428/learning-a-probability-distribution-from-samples-drawn-from-unknown-function</guid>
      <pubDate>Mon, 28 Oct 2024 18:57:48 GMT</pubDate>
    </item>
    <item>
      <title>皮特曼相对效率</title>
      <link>https://stats.stackexchange.com/questions/656427/pitman-relative-efficiency</link>
      <description><![CDATA[我遵循 Van Der Vaart 在《渐近统计学》第 14.1 章中给出的 Pitman 相对效率的定义。给定一个用于检验零假设 $\theta=0$ 的检验统计量序列 $T_n$（随样本大小变化），以及一个用于检验备选假设序列 $\theta_n=h/\sqrt{n}$，假设
\begin{align}
\frac{\sqrt{n}(T_n - \mu(\theta_n))}{\sigma(\theta_n)} \leadsto N(0,1)
\end{align&gt;
沿着测量序列 $\theta_n$ 分布。然后$\mu&#39;(0)/\sigma(0)$被定义为&quot;测试斜率&quot;。给定两个满足上述假设的测试统计数据$T_1$和$T_2$，Pitman相对效率就是测试斜率的比率，$\mu_1&#39;(0)/\sigma_1(0)*\sigma_2(0)\mu_2&#39;(0)$。例如，如果测试正态分布 $N(\theta,1)$ 的均值 $\theta$，
$$
\sqrt{n}(\overline{X}-\theta_n) \leadsto N(0,1)
$$
沿着 $\theta_n$，因此测试斜率为 1。但是，我们不能只对 $T_2$ 取一个 $\sqrt{\theta}$ 的估计量，其中 $\mu(\theta)=\sqrt{\theta}$，这样$\mu&#39;(0)=\infty$，这会比平均值效率高出无数倍吗？我误解了 Pitman 效率的定义吗？或者我们无法构建这种类型的估计量，即 $\mu(\theta)=\sqrt{\theta}$？或者 Pitman 效率只是一种不同于通常所说的平均值最高效的效率衡量标准？]]></description>
      <guid>https://stats.stackexchange.com/questions/656427/pitman-relative-efficiency</guid>
      <pubDate>Mon, 28 Oct 2024 18:46:05 GMT</pubDate>
    </item>
    <item>
      <title>以和的范围为条件的负关联</title>
      <link>https://stats.stackexchange.com/questions/656426/negative-association-conditioned-on-range-of-sum</link>
      <description><![CDATA[假设$X_1, \ldots, X_n$是边缘独立的随机变量。然后有条件地给定$S := \sum_{i=1}^n X_i$，可以证明$(X_1,\ldots,X_n)$是负相关的。为清楚起见，负关联的定义如下。
定义：$X_1, \ldots,X_k$ 被称为负关联的，如果对于 $\{1,\ldots,k\}$ 中的任何两个不相交子集 $A_1$ 和 $A_2$，
$$Cov(f_1(X_i, i\in A_1), f_2(X_j, j\in A_2)) \leq 0$$
对于任何两个增函数 $f_1$ 和 $f_2$。
有关负关联的更多性质（尤其是开头提到的结果的证明），可在 Kumar Joag-Dev 和 Frank Proschan 撰写的题为“随机变量的负关联及其应用”的文章中找到。
我的问题是，对于任何非平凡的 $t$，在给定 $\{S&gt;t\}$ 的情况下，$(X_1,\ldots,X_n)$ 是否条件性地负关联？请注意，与一开始对 $\{S=s\}$ 进行条件化不同，我在这里对 $\{S&gt;t\}$ 进行条件化。
编辑：对于我的用例，每个随机变量都略微遵循高斯分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/656426/negative-association-conditioned-on-range-of-sum</guid>
      <pubDate>Mon, 28 Oct 2024 18:45:17 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归中的排列检验，哪种方法是正确的？</title>
      <link>https://stats.stackexchange.com/questions/656424/permutation-test-in-multiple-linear-regression-which-way-is-correct</link>
      <description><![CDATA[我正在拟合线性回归模型$$Y = \beta_0+ \beta_1 Z + \beta_2 X$$响应$Y$和协变量$X$是连续变量，$Z$是0/1二分处理组指标，均为$N \times 1$向量。我想要获得$\beta_1$的置换分布。在排列中，下列哪一项是正确的：
(1) 随机排列 $Y$，并获取 1000 个排列中 $\beta_1$ 的分布
(2) 随机排列 $Z$，并获取 1000 个排列中 $\beta_1$ 的分布
(3) 令 $Z(X)$ 为在 $X$ 上拟合 $Z$ 的残差向量，令 $Y(X)$ 是将 $Y$ 拟合于 $X$ 所得的 残差。 
然后对 $Z(X)$ 进行 1000 次置换，并记录 $Y(X)$ 对 $Z(X)$ 进行回归时 $Z(X)$ 的 1000 个回归系数。
(4) 对 $Y(X)$ 对 $Z$ 进行回归，对 $Z$ 进行 1000 次置换，并记录 1000 个回归系数。这与比较“X 调整值”的平均值相同$Y$ 在 2 个组中的分布。
我认为 (3) 是正确的方法，因为它保留了 $X$ 与 $Y$ 和 $Z$ 的关系。因此 在置换之前，我应该从 $Z$ 和 $Y$ 中清除 $X$ 的影响。但 (4) 对我来说也并非完全不合理。我找不到合适的参考资料来讨论这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/656424/permutation-test-in-multiple-linear-regression-which-way-is-correct</guid>
      <pubDate>Mon, 28 Oct 2024 17:20:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么方差趋向于$\sigma^2/n$？</title>
      <link>https://stats.stackexchange.com/questions/656421/why-does-the-variance-tend-to-sigma2-n</link>
      <description><![CDATA[设 $Y_1, Y_2, \ldots, Y_n$ 为 $n$ 个个体的收入，其中 $E(Y_i) = \mu$ 且 $\text{Var}(Y_i) = \sigma^2$ 适用于所有 $i = 1, 2, \ldots, n$。这 $n$ 个个体组成 $m$ 个组，每个组的大小为 $k$。众所周知，同一组中的个体是相关的，但不同组中的两个个体始终是独立的。假设当个体相关时，所有对的相关系数都相同。
考虑随机变量 $\bar{Y} = \frac{1}{n} \sum_{i=1}^n Y_i$ 当 $m$ 很大但 $k$ 有限时，$\bar{Y}$ 的极限方差为
选项：

(A) $ 0$
(B) $\frac{1}{k}$
(C)​​ $1$
(D) $\frac{\sigma^2}{k}$

根据一些计算，我计算出 $\operatorname{Var}(\bar{Y}) = \frac{\sigma^2}{n}(1+(k-1)r)$（$r$ 是相关系数）。基于此，$n \rightarrow \infty$ 方差项必须趋向于零，但当我查阅 chatGPT 时，它说方差不为零，因为组成员之间存在相关性。这是真的吗？如果是，为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/656421/why-does-the-variance-tend-to-sigma2-n</guid>
      <pubDate>Mon, 28 Oct 2024 16:02:25 GMT</pubDate>
    </item>
    <item>
      <title>使用非参数检验时，要报告配对样本的哪些描述性统计数据？</title>
      <link>https://stats.stackexchange.com/questions/656398/what-descriptive-statistics-to-report-for-a-paired-sample-when-using-a-nonparame</link>
      <description><![CDATA[我有两个变量，A 和 B（配对样本，前后），我需要进行配对样本非参数检验，因为 A 和 B 之间的差异分布不正常（配对值之间的差异的正态性假设不成立）。大约有 14 条记录。我的问题是：为了在表格中提供描述性统计数据，我是否应该提供 A 和 B 的中位数和 IQR，因为我们正在进行配对样本非参数检验，或者我应该首先分别检查每个变量的分布，如果它们遵循正态分布，则在表格中提供平均值和 SD 的值？]]></description>
      <guid>https://stats.stackexchange.com/questions/656398/what-descriptive-statistics-to-report-for-a-paired-sample-when-using-a-nonparame</guid>
      <pubDate>Mon, 28 Oct 2024 08:38:31 GMT</pubDate>
    </item>
    <item>
      <title>小样本观察的重要性</title>
      <link>https://stats.stackexchange.com/questions/656371/significance-of-an-observation-in-a-small-sample</link>
      <description><![CDATA[在 10000 人的群体中，我测试了 30 个人，发现他们全都患有一种疾病。基于这个样本量，我能否进行一些统计测试，以找出在 30 个受试个体都患有这种疾病的情况下，人口中可能患有这种疾病的比例是多少？
我正在进行类似 Cochrane 测试的测试，以找到给定重要性的样本量，但我无法找到上述问题的确切解决方案]]></description>
      <guid>https://stats.stackexchange.com/questions/656371/significance-of-an-observation-in-a-small-sample</guid>
      <pubDate>Sun, 27 Oct 2024 11:06:11 GMT</pubDate>
    </item>
    <item>
      <title>当 Hessian 矩阵过于敏感时该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/656350/what-does-one-do-when-the-hessian-matrix-is-too-sensitive</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656350/what-does-one-do-when-the-hessian-matrix-is-too-sensitive</guid>
      <pubDate>Sat, 26 Oct 2024 16:10:28 GMT</pubDate>
    </item>
    <item>
      <title>了解先验概率对 DD 分类器错误分类率的影响</title>
      <link>https://stats.stackexchange.com/questions/656434/understanding-the-role-of-prior-probabilities-on-the-misclassification-rate-of-a</link>
      <description><![CDATA[因此，我正在分析这篇论文以进行研究：
DD 分类器
我无法理解先验概率在错误分类率公式中的作用。
我的疑问是：
有关于二元分类问题的这个答案并阅读此内容：Cont。先验概率。
具体是什么：
$$\frac{P(\omega_i)\cdot P(\omega_i|X)}{P(\omega_1|X)+P(\omega_2|X)}$$
我的意思是，如果 $1=P(\omega_1\cup\omega_2|X)=P(\omega_1|X)+P(\omega_2|X)$（仅当 $\omega_1\cap\omega_2 = \emptyset$）。那么上面的公式就没有意义了。那么$\omega_1$和$\omega_2$到底是什么？它们之间有什么关系（交集是什么）？它们与我的误分类率的先验概率$\pi_1$、$\pi_2$（即本文的误分类率）有何关系
$$
\widehat{\Delta}_N(r) = \frac{\pi_1}{m} \sum_{i=1}^m I_{\{D_{G_n}(X_i) &gt; r(D_{F_m}(X_i))\}} + \frac{\pi_2}{n} \sum_{i=1}^n I_{\{D_{G_n}(Y_i) \leq r(D_{F_m}(Y_i))\}}.
$$
并且$\pi_1$、$\pi_2$定义如下：
[先验概率定义][1]
谢谢大家！
[1]: https://i.sstatic.net/H3k4nXZO.png]]></description>
      <guid>https://stats.stackexchange.com/questions/656434/understanding-the-role-of-prior-probabilities-on-the-misclassification-rate-of-a</guid>
      <pubDate>Sat, 26 Oct 2024 09:36:05 GMT</pubDate>
    </item>
    <item>
      <title>对于收敛速度慢于 $\sqrt{n}$ 的估计量，交叉拟合似乎总是会降低渐近方差——这怎么可能是真的呢？</title>
      <link>https://stats.stackexchange.com/questions/656435/cross-fitting-seems-to-always-reduce-asymptotic-variance-for-estimators-convergi</link>
      <description><![CDATA[设置：想象一下，对于协变量的固定值，您有一个基于 $n$ 个 i.i.d. 观测值的回归估计量 $\tilde{f}$，该估计量渐近正态，收敛率为 $\alpha$ ($0 \leq \alpha \leq 1/2$)，这意味着
$$n^{\alpha}\{\tilde{f}-f\} \rightarrow \mathcal{N}(\mu,\sigma^2)$$
服从分布，其中 $f$ 为真实值。示例包括在点 $x_0$ 处具有带宽 $h=n^{-1/5}$ 的局部线性回归，其收敛速率为 $\sqrt{nh}=n^{2/5}$；因此，在这种情况下 $\alpha=2/5$。
假设我们进行 $K$ 倍交叉拟合，而不是将所有 $n$ 个观测值输入回归方法，我们将样本随机分成 $K$ 组，然后取结果平均值。用 $\tilde{f}_k$ 表示仅基于折叠 $k$ 中的观测值的回归估计量。让
$$\tilde{f}^{CF} = \frac{1}{K} \sum_{k=1}^K \tilde{f}_k$$
成为交叉拟合估计量。然后
$$n^{\alpha}\{\tilde{f}^{CF} - f\} \rightarrow \mathcal{N}(K^{\alpha}\mu,K^{2\alpha-1}\sigma^2).$$
证明：首先注意
$$n^\alpha\{ \tilde{f}_k-f \} = K^\alpha \times (n/K)^\alpha\{ \tilde{f}_k-f \} \rightarrow K^\alpha \mathcal{N}(\mu,\sigma^2) = \mathcal{N}(K^\alpha \mu , K^{2 \alpha} \sigma^2)$$
因为只有$n/K$ 个观测值用于 $\tilde{f}_k$。现在
$$n^{\alpha}\{\tilde{f}^{CF} - f\} = \frac{1}{K}\sum_{k=1}^{K} n^\alpha \{\tilde{f}_k - f\} \rightarrow \frac{1}{K}\sum_{k=1}^{K} \mathcal{N}(K^\alpha \mu , K^{2 \alpha} \sigma^2) = \mathcal{N}(K^\alpha \mu , K^{2 \alpha-1} \sigma^2)$$
在分布中，其中最后一个等式使用了 $(\tilde{f}_k)_{k=1,\dots,K}$。
问题：当 $\mu \neq 0$ 时，这似乎是合理的，因为增加 $K$ 会导致方差减少，但代价是偏差增加 - 这是典型的偏差-方差权衡。但如果 $\mu=0$，似乎通过增加 $K$ 可以免费获得渐近方差减少。这真的是真的吗？
我对此唯一可能的启发如下：局部线性回归获得 $n^{2/5}$ 的最佳收敛速度（参见 Fan (1993) 第 4 节），但 $\mu \neq 0$。可以通过欠平滑来消除偏差，即为较小的 $\varepsilon&gt;0$ 设置 $h=n^{-1/5-\varepsilon}$。这导致估计量 $\alpha=2/5-\varepsilon/2$ 但 $\mu=0$。收敛速度降低$\varepsilon/2$是渐近性的，因此有空间可以任意减少渐近方差，并且仍然不会破坏任何最优结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/656435/cross-fitting-seems-to-always-reduce-asymptotic-variance-for-estimators-convergi</guid>
      <pubDate>Fri, 25 Oct 2024 07:54:52 GMT</pubDate>
    </item>
    </channel>
</rss>