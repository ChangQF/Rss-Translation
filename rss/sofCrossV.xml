<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 09 Dec 2023 00:59:25 GMT</lastBuildDate>
    <item>
      <title>计算 AP Psych Z 分数</title>
      <link>https://stats.stackexchange.com/questions/633446/computing-z-scores-ap-psych</link>
      <description><![CDATA[可能是个愚蠢的问题
不确定我是否有点慢或大脑受阻，但我已经加载了报告的数据，并且我现在处于恐慌模式
我的报告着眼于阴谋论信仰和批判性思维能力对政治参与的影响。
我基本上必须进行阶乘方差分析，我的 IV 是：
阴谋论信仰
批判性思维能力
我的DV是：
参与政治
IV 已根据中值平均值等转换为高/低组。
我已经陷入了整理数据的第一部分。我必须计算 z 分数。我是否必须为所有变量计算它们？我正在使用 jamovi。
我认为这有点让人不知所措，我将不胜感激任何建议。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/633446/computing-z-scores-ap-psych</guid>
      <pubDate>Fri, 08 Dec 2023 23:40:05 GMT</pubDate>
    </item>
    <item>
      <title>估算缺失值</title>
      <link>https://stats.stackexchange.com/questions/633441/impute-missing-value</link>
      <description><![CDATA[在机器学习中，当我估算缺失值时，我会执行以下操作：
1-Impute数据集然后分割它？
2-将数据集拆分为训练和测试数据集，然后分别估算每个数据集。]]></description>
      <guid>https://stats.stackexchange.com/questions/633441/impute-missing-value</guid>
      <pubDate>Fri, 08 Dec 2023 22:14:16 GMT</pubDate>
    </item>
    <item>
      <title>移动平均模型背后的动机[重复]</title>
      <link>https://stats.stackexchange.com/questions/633440/motivatation-behind-moving-average-models</link>
      <description><![CDATA[假设我有一个平均 $0$ 的时间序列。如果我假设一个 $MA(1)$ 模型，那么我每次的预测 $t$将与“关闭”的程度成正比。我最后的预测是。
这对我来说很奇怪。
假设我的模型只是 $x_t\sim \varepsilon_{t-1}+\varepsilon_t$。我观察 $x_1=1$，并预测 $\hat{x}_2=1$。第二天我观察$x_2=.9$。仍然好于平均水平，但现在我的下一个预测是 $\hat{x}_3=-.1$ 因为这是我之前预测的金额。这是一个比 $\hat{x}_3=0$ 更奇怪的预测。
我知道这样做的目的是为了删除 $\hat{x}_t,\hat{x}_{t+h}$ 之间的相关性$h$ 足够大（在本例中为 $h&gt;1$），因此必须“过度补偿”对于 $\hat{x}_t,\hat{x}_{t+1}$ 之间的正相关性（这解释了 $\hat{x}_3&lt;0$ 怪异)。
但这有什么实际好处吗？显然必须如此，因为它几乎占了 ARIMA 涉及的字母的一半。有什么更好的方法可以理解为什么它应该参与模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/633440/motivatation-behind-moving-average-models</guid>
      <pubDate>Fri, 08 Dec 2023 22:06:43 GMT</pubDate>
    </item>
    <item>
      <title>IV回归中控制变量的时间顺序问题</title>
      <link>https://stats.stackexchange.com/questions/633439/time-order-problem-of-control-variables-in-iv-regression</link>
      <description><![CDATA[Y 是因变量，X 是自变量，C 是控制变量。但是，由于X是内生的，所以我打算对X使用工具变量Z。据我了解，如果我进行两阶段分析，在第一阶段我使用C和Z预测X以获得X的估计值，在第二阶段，我使用 X 的估计值和 C 来计算 Y。
我的问题是关于变量C的时间安排。如果C的顺序在X之后Y之前，那么第二阶段的因果顺序就没有问题。然而，在第一阶段，如果我使用 Z 和 C 来预测 X，则意味着我正在使用未来出现的 C 来预测 X。
那么，在进行 IV 回归时，我应该只使用时间上 X 之前发生的控制变量吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/633439/time-order-problem-of-control-variables-in-iv-regression</guid>
      <pubDate>Fri, 08 Dec 2023 22:02:17 GMT</pubDate>
    </item>
    <item>
      <title>超越 AR(1) 作为具有重复测量的混合模型的协方差结构</title>
      <link>https://stats.stackexchange.com/questions/633436/beyond-ar1-as-a-covariance-structure-for-mixed-models-with-repeated-measures</link>
      <description><![CDATA[我一直在阅读有关针对具有重复测量（及时）的混合模型假设 AR(1) 协方差结构的替代方案。特别是我听说过 Toeplitz 和 Ante 依赖结构，以及这三个结构的同质/异质版本，这显然可以被视为 AR(1) 的推广。
这些的优点/缺点是什么？我们在什么情况下使用它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/633436/beyond-ar1-as-a-covariance-structure-for-mixed-models-with-repeated-measures</guid>
      <pubDate>Fri, 08 Dec 2023 21:35:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么验证准确度会在两个极端之间波动？</title>
      <link>https://stats.stackexchange.com/questions/633435/why-is-validation-accuracy-fluctuating-between-two-extremes</link>
      <description><![CDATA[我正在使用 LSTM 来制作多标签分类器。但问题是，验证准确度在 0.7 到 0.3 之间波动。我有大约 4367 个样本（80-20 个验证分割）和 240 个样本长度。

我当前的模型非常简单，只有 1 个 LSTM 层和 1 个输出层。我尝试过更复杂的模型，例如增加 LSTM 层、密集层、添加 dropout，但准确率图看起来非常相似。我在这里缺少什么？如果我只选择精度更高的拟合可以吗？
def lstmModel(features, seq_length, numClasses):
  初始化学习率 = 0.1
  模型=顺序（）

  model.add(LSTM(512,input_shape=(seq_length,特征),return_sequences=False))
  model.add(Dense(numClasses,kernel_initializer=&#39;normal&#39;,activation=&#39;sigmoid&#39;))
  优化器 = tf.keras.optimizers.Adam(learning_rate=init_learning_rate)
  模型.summary()
  model.compile(loss=&#39;BinaryCrossentropy&#39;,optimizer=optimizer,metrics=[&#39;accuracy&#39;])
  返回模型
]]></description>
      <guid>https://stats.stackexchange.com/questions/633435/why-is-validation-accuracy-fluctuating-between-two-extremes</guid>
      <pubDate>Fri, 08 Dec 2023 21:28:02 GMT</pubDate>
    </item>
    <item>
      <title>对抗性示例搜索中框约束优化的基本原理</title>
      <link>https://stats.stackexchange.com/questions/633434/rationale-for-box-constrained-optimization-in-adversarial-example-search</link>
      <description><![CDATA[在 “神经网络的有趣特性”的第 4.1 节中Szegedy 等人 定义了他们解决的优化问题，以在深度神经网络中查找对抗性示例。我对第二个约束有点困惑：为什么需要要求 (2) $x+r \in [0,1]^m$？
作者表示，此类优化问题的解决方案 $r$ 会产生 $x+r$与 $x$ 最近的数据点被 $f$ 分类为与 $f(x)$。我没有看到约束 (2) 在其中扮演的角色。]]></description>
      <guid>https://stats.stackexchange.com/questions/633434/rationale-for-box-constrained-optimization-in-adversarial-example-search</guid>
      <pubDate>Fri, 08 Dec 2023 21:25:12 GMT</pubDate>
    </item>
    <item>
      <title>对实验数据应用变量变换是否会导致 p-hacking？</title>
      <link>https://stats.stackexchange.com/questions/633431/does-applying-a-variable-transformation-to-experiment-data-result-in-p-hacking</link>
      <description><![CDATA[从正式的统计课堂作业和一些研究经验中，我了解到，如果样本分布不满足正态性条件，则对预测变量应用变换，以便在 A/B 测试设置中进行显着性测试，这是被广泛认为的标准做法。然而，根据一些阅读，我想知道这些变换应用于倾斜数据时是否被视为“方差减少”。变量转换实际上是 p-hacking 的一种形式。
例如，此参考对log、平方根如何进行模拟，逆变换会改变基础测量尺度并导致更高的误报率。额外的阅读使我相信选择这些变换（并检查数据以检查它们是否导致正态分布）实际上会导致自由度的降低。如果是这种情况，对于大样本量（$&gt; 1000$），转换对 $d.o.f$？
总而言之，我的主要问题是
当原始空间中没有显着性时，随机变量的单调变换是否可以在变换后的空间中实现显着性（p &lt; x）？]]></description>
      <guid>https://stats.stackexchange.com/questions/633431/does-applying-a-variable-transformation-to-experiment-data-result-in-p-hacking</guid>
      <pubDate>Fri, 08 Dec 2023 20:09:11 GMT</pubDate>
    </item>
    <item>
      <title>严格处理面板数据的最佳教科书</title>
      <link>https://stats.stackexchange.com/questions/633429/best-textbook-for-a-rigorous-treatment-of-panel-data</link>
      <description><![CDATA[我想知道您推荐哪本书来处理既严格又直观的面板数据。您对Wooldridge(2010)、Baltigi(2021) 和Hsiao(2022) 有何推荐？我在硕士课程中使用 Wooldridge 研究了静态面板数据模型。 Wooldridge 的最新版本是 2010 年的。即使它是 2010 年的书，它仍然是一个不错的选择吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/633429/best-textbook-for-a-rigorous-treatment-of-panel-data</guid>
      <pubDate>Fri, 08 Dec 2023 19:42:08 GMT</pubDate>
    </item>
    <item>
      <title>高斯似然的期望</title>
      <link>https://stats.stackexchange.com/questions/633428/expectation-of-the-gaussian-likelihood</link>
      <description><![CDATA[我正在研究一个具有挑战性的机器学习问题，我需要在给定另一个高斯的参数的情况下找到一个高斯的似然期望。如果任何符号粗糙，请道歉，这对我来说是新领域。
更准确地说，给定两个独立的高斯分布。
$$X \sim \mathcal{N}(\mu_1, \sigma_1^2) $$
$$Z \sim \mathcal{N}(\mu_2, \sigma_2^2)$$
其中 $\mu_1$、$\sigma_1$、$\mu_2$ 和 $\sigma_2$ 是已知的。假设我要从 Z 中随机抽取值，并使用 X 的 pdf 来评估可能性，$p(X)$ 和  $\mu_1, \sigma_1$，预期的可能性是多少？澄清一下，不是 Z 的期望值，而是似然函数本身的期望。
我已经成功获得了预期的可能性 $E[p(X)]$，当 $\mu_1=\mu_2$ 和 $\sigma_1=\sigma_2$，通过以下方式：
X 的 pdf 定义为：
$$ p(X) = \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}\sigma_1} e^ {-\frac{(x-\mu_1)^2}{2\sigma_1^2}} \, dx$$
期望的定义是：
$$E[x] = \int_{-\infty}^{\infty} x \cdot f(x) \ dx$$
x = p(X) 所以
$$E[p(X)] = \int_{-\infty}^{\infty} p(X) \cdot p(X) \ dx$$ 
$$E[p(X)] = \int_{-\infty}^{\infty} \left(\frac{1}{\sqrt{2\pi }\sigma_1} e^{-\frac{(X-\mu_1)^2}{2\sigma_1^2}}\right) \cdot \left(\frac{1}{\sqrt{2\pi}\ sigma_1} e^{-\frac{(X-\mu_1)^2}{2\sigma_1^2}}\right) \ dx$$
重新排列一下可以得到：
$$E[p(X)] = \frac{1}{{\sigma_1^2 \cdot 2 \pi}} \cdot \int_{-\infty} ^{\infty} \exp\left(-\frac{(x - \mu_1)^2}{\sigma_1^2}\right) \ dx $$
最后得到以下结果，我通过模拟凭经验验证了该结果：
$$ E[p(X)] = \frac{1}{{\sigma_1^2 \cdot 2 \pi}} \cdot {\sigma_1 \sqrt{\ pi}} $$
但是，当使用 $\mu_1$ 和 $\sigma_1$ 对 Z 进行积分时，如何计算可能性 来自 X？
我尝试定义 $x = \frac{(z - \mu_2)\sigma_1}{\sigma_2}$ 并使用变量更改方法，替换在 dz 上积分。然而，这不起作用，我肯定做错了什么。
我应该如何继续？我迷路了，非常感谢任何帮助。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/633428/expectation-of-the-gaussian-likelihood</guid>
      <pubDate>Fri, 08 Dec 2023 19:27:31 GMT</pubDate>
    </item>
    <item>
      <title>假设 beta 分布为共轭先验，抛硬币的后验概率是多少</title>
      <link>https://stats.stackexchange.com/questions/633423/what-is-the-posterior-probability-for-flipping-a-coin-assuming-a-beta-distribut</link>
      <description><![CDATA[假设，我抛一枚公平的硬币 n = 10 次，得到 7 次正面和 3 次反面。公平硬币的概率为 p = 0.5。现在，β 分布是二项式似然的共轭先验。我使用了 β 分布的概率密度函数方程，如维基百科 (https://en.wikipedia. org/wiki/Beta_distribution）。我似乎无法理解应该使用什么 alpha 和 beta 值。 alpha - 1 是正面的数量，beta - 1 是反面的数量。现在假设均匀先验分布 U(0,1) 或 Beta(1,1)。我计算后验概率为 1。我的答案正确吗？
如果我的硬币有偏差，假设 p = 0.7（而不是 p = 0.5），那么解决方案是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/633423/what-is-the-posterior-probability-for-flipping-a-coin-assuming-a-beta-distribut</guid>
      <pubDate>Fri, 08 Dec 2023 18:09:54 GMT</pubDate>
    </item>
    <item>
      <title>模拟变量（比例）的统计或机器学习方法</title>
      <link>https://stats.stackexchange.com/questions/633410/statistical-or-machine-learning-approach-for-simulating-variable-proportion</link>
      <description><![CDATA[我目前面临着分析来自电力驱动生产设施的客户满意度数据的挑战。在本月的特定时期，我们的机械遇到了技术问题，导致客户满意度低于预期。
为了提供背景信息，我们在每月 1 日到 11 日进行最佳运营，并且在这些日子里的每一天，我们都会记录满意客户的百分比。然而，从12日到19日，出现了技术问题，影响了客户满意度。本质上，我们经历了 8 天的“非最佳性能”。以及 22 天的最佳性能。
我正在寻求有关最合适的统计或机器学习方法的建议，以模拟或推断在未发生技术问题的情况下整个月的总体满意度。
我正在考虑的方法：

以 95% 置信区间进行引导重采样、重采样
正常时期客户满意度调查数据
操作来推断我们的预期性能。
蒙特卡罗模拟，假设二项式分布
使用输入的满意度百分比的理论分布
最佳性能时期的数据。

我还听说过使用其他月份的数据进行机器学习或时间序列预测。对于解决这个问题的最佳方法，我希望获得消息灵通且有学术支持的观点。
我想要的输出将是该特定月份的客户满意度比例的置信区间，其中是模拟、推断、预测等。目标是在技术困难未发生的假设下获取此信息]]></description>
      <guid>https://stats.stackexchange.com/questions/633410/statistical-or-machine-learning-approach-for-simulating-variable-proportion</guid>
      <pubDate>Fri, 08 Dec 2023 14:42:47 GMT</pubDate>
    </item>
    <item>
      <title>$n$ 次测试的配对比较，每次重复 $k$ 次</title>
      <link>https://stats.stackexchange.com/questions/633384/paired-comparison-on-n-tests-repeated-k-times-each</link>
      <description><![CDATA[假设我在 $n$ 通过/失败（伯努利）任务上测试两个科目，$k$ 次 - 每个科目总共 $n\cdot k$ 次测试。我想比较这些受试者，看看它们之间是否存在统计上的显着差异。许多测试（例如双比例 z 测试）被消除，因为在受试者的测试结果内以及受试者之间的观察结果都是相关的。在这种情况下，最合适的统计测试是什么？
（我想我正在寻找像 McNemar-Bowker 这样的东西，但这似乎不太正确，除非我弄错了。奇怪的是每个结果之间没有一对一的配对主题；它更像是“$k$-to-$k$ 配对，$n$ 次。&#39;&#39;)
如果可能的话，还需要针对受试者之间的差异构建一个置信区间。]]></description>
      <guid>https://stats.stackexchange.com/questions/633384/paired-comparison-on-n-tests-repeated-k-times-each</guid>
      <pubDate>Fri, 08 Dec 2023 07:46:54 GMT</pubDate>
    </item>
    <item>
      <title>多重共线性和大 OLS 估计与岭回归</title>
      <link>https://stats.stackexchange.com/questions/633353/multicollinearity-and-large-ols-estimates-vs-ridge-regression</link>
      <description><![CDATA[正则化方法（例如岭回归）的要点是惩罚大的普通最小二乘估计。我们知道 OLS 估计的方差-协方差矩阵可以使用谱定理分解为
\begin{align}
\Sigma_{\hat \beta} = \sigma^2 (X^TX)^{-1} = \sigma^2 U\Lambda^{-1} U^T
\end{对齐}
其中 $\Lambda$ 是对角线，特征值为 $X^TX$。显然，如果预测变量之间存在高度多重共线性，则 $X^TX$ 几乎不可逆，因此至少有一个非常小的特征值 $\lambda_i$，因此 $\lambda_i^{-1}$ 很大，方差（标准误差）也很大$\hat \beta_i$。估计的不确定性是预料之中的。然而，我不清楚的是为什么多重共线性意味着 $\hat \beta_i$ 的值很大？两个高度相关的变量绝对值很大但符号相反的原因是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/633353/multicollinearity-and-large-ols-estimates-vs-ridge-regression</guid>
      <pubDate>Thu, 07 Dec 2023 20:02:52 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中没有绘图/图表的情况下检查变量的线性？</title>
      <link>https://stats.stackexchange.com/questions/633316/how-to-check-linearity-of-a-variable-without-plots-graphs-in-r</link>
      <description><![CDATA[我正在进行一项纵向研究，比较肺部增生的患者，这些患者要么发展成癌症（cancer_status = 1），要么没有发展成癌症（= 0）。以下是一些随机生成的数据示例，其格式与研究相同：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

患者 ID*
cancer_status
获得结果的时间
cpg_1
cpg_2


&lt;正文&gt;

1
1
-532
0.49578632
0.9301869


1
1
-121
0.51134914
0.9496315


1
1
0
0.51665110
0.9535245


2
0
-564
0.13605940
0.8912563


2
0
-423
0.09577919
0.7950609


2
0
-266
0.13383500
0.8726626


2
0
0
0.11834631
0.8492904


3
1
-128
0.35097042
0.9727214


3
1
0
0.53230504
0.9643870


等等...








*每个患者都进行了多次测量/采样。
按照关于线性混合效果建模的本教程，我正在尝试对以下效果进行建模每个 cpg 变量随时间变化的 cancer_status（即 time_to_outcome，以天为单位测量）。
本教程首先通过绘制一般加性混合模型 (GAMM) 来检查变量是否是线性的（线性混合效应模型的假设）：
库(gamm4)
库（样条线）

# 该 GAMM 针对每个测量值进行调整
# 病人，但不会根据性别或年龄等其他因素进行调整：
cpg1_gamm_cases &lt;- gamm4(cpg_1 ~ 1 + s(time_to_outcome),
    数据 = df[df$cancer_status == 1, ],
随机 = ~ (1|患者 ID)
）

情节（cpg1_gamm_cases$gam，
阴影=真，
移位 = cpg1_gamm_cases$gam$系数[1],
    ylab = &#39;CpG_1 例&#39;,
    残差 = TRUE，
    个数 = 20,
    页数 = 1)

cpg1_f &lt;- 已安装(cpg1_gamm_cases$mer)
cpg1_r &lt;- 残渣(cpg1_gamm_cases$mer)
绘图（x = cpg1_f，
    y = cpg1_r,
    xlab =“拟合值”，
    ylab =“残差”，
       cex = 0.3)
abline(lm(resid(cpg1_gamm_cases$mer) ~ 安装(cpg1_gamm_cases$mer)))

结果 1：
结果 2：
上图显示 cpg_1 和时间之间没有明显的线性关系。 （这是预期的，因为数据是随机生成的）。因此，在这种情况下，对此变量运行线性混合效应模型可能没有意义。
问题是：在研究中，我不仅仅需要对 cpg_1 和 cpg_2 变量进行建模，我还需要对大约 850,000 个不同的 cpg 变量进行建模。（就上下文而言，每个 CpG 都是不同的基因组上的位点，连续值介于 0 和 1 之间 - 这代表该位点的平均 DNA 甲基化）。
我见过的每个消息来源都说，通过绘制数据并查看它来测试线性模型的线性假设，如上所述。然而，我不可能生成并查看 850,000 个不同的图表。是否有可以在 R 中运行的简单线性检查（如函数）？
（有些不相关：可能应该有一种比运行 850k 个单独模型更简单的方法来做到这一点，但这是大多数已发表的研究似乎针对此类数据所采用的方法。）]]></description>
      <guid>https://stats.stackexchange.com/questions/633316/how-to-check-linearity-of-a-variable-without-plots-graphs-in-r</guid>
      <pubDate>Thu, 07 Dec 2023 15:17:52 GMT</pubDate>
    </item>
    </channel>
</rss>