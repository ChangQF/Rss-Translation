<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 28 Nov 2024 09:19:15 GMT</lastBuildDate>
    <item>
      <title>ARIMA(0,1,1) 模型的数学方程是什么？</title>
      <link>https://stats.stackexchange.com/questions/657967/what-is-the-mathematical-equation-for-an-arima0-1-1-model</link>
      <description><![CDATA[ARIMA(0,1,1) 模型的数学方程是什么？
R 软件给出以下结果
系列：goldtime
ARIMA(0,1,1) 带漂移
系数：
ma1 漂移
0.2635 9.6507
s.e. 0.0654 3.8817
sigma^2 = 2260：对数似然 = -1250.51
AIC=2507.01 AICc=2507.12 BIC=2517.42]]></description>
      <guid>https://stats.stackexchange.com/questions/657967/what-is-the-mathematical-equation-for-an-arima0-1-1-model</guid>
      <pubDate>Thu, 28 Nov 2024 08:25:55 GMT</pubDate>
    </item>
    <item>
      <title>以市场份额为因变量的面板回归模型</title>
      <link>https://stats.stackexchange.com/questions/657964/panel-regression-model-with-market-share-as-dependent-variable</link>
      <description><![CDATA[该数据集包含 6 年内不同银行的不同变量。我想了解这些变量与市场份额之间的关系。问题是市场份额是一场零和博弈。如果一家银行的市场份额增加，那么另一家银行的市场份额就会自动减少。我应该如何应对这种情况？我尝试过固定效应的 Logit 变换和向量自回归，但效果并不好。]]></description>
      <guid>https://stats.stackexchange.com/questions/657964/panel-regression-model-with-market-share-as-dependent-variable</guid>
      <pubDate>Thu, 28 Nov 2024 03:02:25 GMT</pubDate>
    </item>
    <item>
      <title>潜在类别分析中分类尺度概率的协方差矩阵</title>
      <link>https://stats.stackexchange.com/questions/657963/covariance-matrix-from-probabilities-of-categorical-scales-in-latent-class-analy</link>
      <description><![CDATA[对于如何从潜在类别分析中分类尺度的每个级别的概率中恢复协方差矩阵，我感到很困惑。
目前，我使用 bootstrap 方法。
在以下示例中（来自 poLCA 包），probs 包含基于 3 个类（矩阵的行）的 5 个项目（矩阵），每个尺度中有 3、2、3、4 和 3 个级别（矩阵中的列）。每个类的比例为 P。通过重新采样 nreps 次，我可以很好地估计协方差矩阵，但我想在不使用引导程序的情况下找到它。
set.seed(42)
probs &lt;- list(matrix(c(0.6, 0.1, 0.3,
0.6, 0.3, 0.1,
0.3, 0.1, 0.6),
ncol = 3,byrow = TRUE), # 条件响应概率到 Y1
matrix(c(0.2, 0.8,
0.7, 0.3,
0.3, 0.7),
ncol = 2, byrow = TRUE), # 条件响应概率到 Y2
matrix(c(0.3, 0.6, 0.1,
0.1, 0.3, 0.6,
0.3, 0.6, 0.1),
ncol = 3,byrow = TRUE), # 条件响应概率到 Y3
matrix(c(0.1, 0.1, 0.5, 0.3,
0.5, 0.3, 0.1, 0.1,
0.3, 0.1, 0.1, 0.5),
ncol = 4,byrow = TRUE), # 条件响应概率到 Y4
matrix(c(0.1, 0.1, 0.8,
0.1, 0.8, 0.1,
0.8, 0.1, 0.1),
ncol = 3,
byrow = TRUE)) # 条件响应概率到 Y5
nreps &lt;- 1000
bootS &lt;- array(0, dim=c(length(probs),length(probs),nreps))
n &lt;- 500
P &lt;- c(.33,.34,.33)
for(i in 1:nreps){
D &lt;- poLCA.simdata(N = n,
probs = probs,
P = P)$dat
bootS[,,i] &lt;- cov(D)# - S
}
S &lt;- apply(bootS, c(1, 2), mean)
round(S,4)
[,1] [,2] [,3] [,4] [,5]
[1,] 0.8044 0.0404 -0.0783 0.1052 -0.1370
[2,] 0.0404 0.2407 -0.0710 0.1134 0.0229
[3,] -0.0783 -0.0710 0.5008 -0.1729 -0.0005
[4,] 0.1052 0.1134 -0.1729 1.4484 0.0447
[5,] -0.1370 0.0229 -0.0005 0.0447 0.6642

我想知道是否有办法根据 probs 计算 S。如果是，如何在 R 中实现？
谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/657963/covariance-matrix-from-probabilities-of-categorical-scales-in-latent-class-analy</guid>
      <pubDate>Thu, 28 Nov 2024 01:51:24 GMT</pubDate>
    </item>
    <item>
      <title>将 PCA 应用于多个个体时间序列数据集</title>
      <link>https://stats.stackexchange.com/questions/657962/apply-pca-to-multi-individual-time-series-dataset</link>
      <description><![CDATA[假设我有 50 个用户的时间序列数据，每个用户有 20 个特征：User1_ts(F1,...F20)、User2_ts(F1,...F20)、...User50_ts(F1,...F20)。F20 是我要估计的目标变量，每个时间序列的长度可能不同。目前，我正在构建一个 AI 模型来估计 F20。训练数据集基于与每个用户相关的每个 ts 的 70% 的连接。而训练集是通过应用 90 天的时间窗口和一天切片来构建的。
我的问题与应用 PCA 来减少空间的方法有关：应该何时应用 PCA？

滚动之前？
滚动之后？
还有其他吗？

我找不到任何研究论文或其他链接来澄清这个方面。]]></description>
      <guid>https://stats.stackexchange.com/questions/657962/apply-pca-to-multi-individual-time-series-dataset</guid>
      <pubDate>Thu, 28 Nov 2024 01:21:42 GMT</pubDate>
    </item>
    <item>
      <title>神经网络使用反向传播可以学习布尔公式吗？</title>
      <link>https://stats.stackexchange.com/questions/657961/learnability-of-boolean-formulae-by-neural-networks-using-back-propagation</link>
      <description><![CDATA[我一直在研究神经网络和布尔公式。从我的努力来看，神经网络似乎通常无法使用反向传播来学习布尔公式。这在直觉上是有道理的，因为布尔公式的输出可以根据输入值表现出巨大的变化，因此会有很多不连续性，从而导致局部最优。
另一方面，我也明白任何布尔公式都可以用神经网络来表示，所以神经网络没有内在原因不能表示，因此可能学习任意的布尔公式。问题似乎出在学习算法上，所有通用的机器学习算法似乎都会陷入局部最优，无论我使用梯度下降、进化算法、期望最大化等，因为它们都基于局部增量改进是通向全局最优解的途径这一前提。
话虽如此，我也知道还有其他类型的算法，如 Quine-McCluskey 和 Espresso，它们可以从真值表中得出最小布尔公式。随后可以使用这些算法生成一个神经网络，该神经网络嵌入从真值表中得出的最小布尔公式算法。然而，据我所知，这些都是非常具体的算法，专门针对布尔公式，在更通用的机器学习环境中没有使用。
所以，这让我想到了我的问题。是否有任何证据表明神经网络能够或不能使用反向传播和梯度下降或任何其他通用机器学习算法来学习任意布尔公式？
我检查了 Cross Validated，并在 Google 上搜索了这个问题，但未能找到任何明确的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/657961/learnability-of-boolean-formulae-by-neural-networks-using-back-propagation</guid>
      <pubDate>Thu, 28 Nov 2024 01:09:53 GMT</pubDate>
    </item>
    <item>
      <title>帮助我将多元线性回归模型中的两个假设结合起来进行方差分析比较！</title>
      <link>https://stats.stackexchange.com/questions/657960/help-me-to-combine-two-hypotheses-in-a-multiple-linear-regression-model-for-anov</link>
      <description><![CDATA[我目前正在研究多元线性回归并使用股票市场数据进行实践。我的数据集包括：

因变量 (Y)：标准普尔 500 指数价格

自变量：

黄金价格 (X1)

铜价 (X2)

表现最佳的行业 (X3)：分类变量，编码如下：

XLK（技术）或 XLE（能源）= 1

所有其他行业 = 0


我有两个假设想要测试：

铜价 (X2) 与 XLK/XLE（X3=1）相互作用，但与其他行业不相互作用(X3=0)。
黄金价格 (X1) 与任何表现最佳的行业 (X3) 均无关联。

我想将这两个假设合并为一个模型，并使用 R 中的 anova(full_model, Reduced_model) 创建一个简化模型，以便与完整模型进行比较。但是，我不确定如何构建简化模型以反映这两个假设。
full_model &lt;- lm(SP500_Adj_Close ~ Gold_Price + Copper_Price + Performing_Sector_Dummy + 
Gold_Price:Performing_Sector_Dummy + Copper_Price:Performing_Sector_Dummy)

以上是我的完整模型。如果我错了，请纠正我。
您能帮我构建简化模型并指导我如何适当地测试这些假设吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657960/help-me-to-combine-two-hypotheses-in-a-multiple-linear-regression-model-for-anov</guid>
      <pubDate>Thu, 28 Nov 2024 01:08:11 GMT</pubDate>
    </item>
    <item>
      <title>从逻辑模型中取预测概率的总和？</title>
      <link>https://stats.stackexchange.com/questions/657953/taking-the-sum-of-predicted-probabilities-from-logit-model</link>
      <description><![CDATA[我正在使用 logit 模型来预测学生通过特定课程的概率。我运行 logit，为样本中的学生生成预测概率，并希望将模型与观察到的通过率进行比较。我创建了分类表并执行了一些其他检查。
有人向我建议的一种方法是对样本（以及感兴趣的子组内）的所有预测概率求和，以将预测的通过次数与观察到的通过次数进行比较。直观地讲，这对我来说很有意义。将预测概率相加将产生模型在我的样本中预测的预期事件总数，这似乎是合理的。然而，当我试图找到同行评审的论证时，我却一无所获，无法找到使用这种方法的经过验证的例子。
我的问题是：将我的样本和样本子组的预测概率相加，以将预期事件计数与观察到的事件计数进行比较是否合适？如果合适，这种方法是否在任何信誉良好的来源中得到验证或使用？]]></description>
      <guid>https://stats.stackexchange.com/questions/657953/taking-the-sum-of-predicted-probabilities-from-logit-model</guid>
      <pubDate>Wed, 27 Nov 2024 19:57:49 GMT</pubDate>
    </item>
    <item>
      <title>Ngram 模型不合适？</title>
      <link>https://stats.stackexchange.com/questions/657932/ngram-model-is-improper</link>
      <description><![CDATA[标准二元模型（例如定义于此处）基于以下原则在语料库$V$上定义概率分布：

单词$w$的边际概率定义为其在$V$中的计数除以$V$中的单词总数（计算重复次数）：$P(w) = \text{count}(w) / |V|$
一个单词跟随另一个单词的条件概率直观地定义为二元组计数与第一个单词计数之比：$p(w_2|w_1) = \text{count}(w_1 w_2) / \text{count}(w_1)$
（马尔可夫假设）：一个句子（一个单词序列）的概率可以通过链式法则计算：$p(w_1 w_2 ... w_n) = p(w_1) p(w_2|w_1) p(w_3|w_1 w_2)... \approx p(w_1) p(w_2|w_1) p(w_3|w_2) ...$

然而，这似乎并没有定义一个适当的概率分布。例如，取一个语料库 $V = \text{&quot;foo bar baz&quot;}$。然后，取所有可能的二元组上定义的联合分布 $w_1 w_2$。根据我们的原则：
\begin{equation}
p(w_1 w_2) = p(w_1) p(w_2|w_1) = [\text{count}(w_1) / 3][\text{count}(w_1 w_2) / \text{count}(w_1)]
\end{equation&gt;
如果 $w_1 w_2$ 不在语料库中，则显然 $p(w_1 w_2) = 0$。因此，联合分布中唯一非零的条目是 $p(\text{foo bar}) = p(\text{bar baz}) = 1/3$。这些的总和是$2/3 \neq 1$，那么这种分配是否不合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/657932/ngram-model-is-improper</guid>
      <pubDate>Wed, 27 Nov 2024 13:18:18 GMT</pubDate>
    </item>
    <item>
      <title>理解基于启发式的异常值检测：对评分、加权和有效性的关注</title>
      <link>https://stats.stackexchange.com/questions/657911/understanding-heuristic-based-outlier-detection-concerns-about-scoring-weighti</link>
      <description><![CDATA[我正在尝试理解《计算机与安全》杂志上新发表的异常值检测算法背后的数学和方法论。该算法使用基于启发式的方法，将基于密度和距离的评分与经验权重相结合。
无监督异常值检测 (OD) 算法通常涉及：

异常值评分：分配“异常值分数”以污染率（例如 contamination=0.05）作为超参数来决定阈值。
基于几何的方法：使用降维技术（例如 PCA、LDA）来投影数据，以便更好地分离类别（例如 矩阵轮廓、矩阵分解）

在他们使用 核高度估计函数 (KHE) (!) 和一些数学不清楚的步骤后，我总结了 GitHub 问题，最终，新算法提出了一个评分公式（公式 #18）：
$$
E(O, W)=\sum_{i=1}^n\left(s_i \cdot s_{c i} \cdot \omega_i\right)^3
$$
其中 $s_i$、$s_{c i}$ 和 $\omega_i$ 是分数成分和权重。作者根据经验设定了权重$\omega_{density}=0.8$和$\omega_{distance}=0.2$（公式 15）。

我的问题：
评分和加权的数学有效性：

将异常值分数、置信度分数和权重组合起来是否有意义，如公式 18 所示？
组合分数的三次变换能否提高检测准确率，还是会引入不必要的偏差？

加权中的人为因素：

作者根据经验设定了权重（$\omega_{density}=0.8$ 和 $\omega_{distance}=0.2$）以提高准确性。但是，这种手动参数调整是否会破坏 OD 算法的无监督性质？

如果没有明确的统计或实验推理，如何证明这些权重的合理性？


权重的可解释性（$\omega_{density}$ &gt; $\omega_{distance}$）：

作者优先考虑基于密度的评分。在异常值检测中，密度比距离更重要，这是否有任何理论或实验依据？

这种权重不平衡是否会引起偏差，尤其是在偏离正态性的不平衡数据集中（例如非高斯分布）？



附加说明：

我在 pyod 存储库中提出了一个 GitHub 问题，总结了本文的方法和有待进一步讨论的问题。
所提出方法的影响是在论文的图 4 中进行了可视化，显示了不同评分组合下的结果。但是，尚不清楚这些结果是否适用于所呈现的数据集之外的结果。


参考文献：

Chris Kuo 的《异常检测手册》：讨论了无监督异常检测中的评分和污染率。
如何测试无监督学习方法进行异常检测？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657911/understanding-heuristic-based-outlier-detection-concerns-about-scoring-weighti</guid>
      <pubDate>Wed, 27 Nov 2024 03:48:42 GMT</pubDate>
    </item>
    <item>
      <title>正态性假设 - qqplot 解释</title>
      <link>https://stats.stackexchange.com/questions/657859/normality-assumption-qqplot-interpretation</link>
      <description><![CDATA[我目前正在从事一个涉及评估多个变量分布的项目，并且我正在使用 Q-Q 图作为分析的一部分。虽然我已经为这些变量生成了 Q-Q 图。确实，我已经研究了很长时间，但我仍然想在这里听取意见。这些变量的样本量接近 70，目的是在纵向分析的几个变量之间进行独立 t 检验。我可以提出，shapiro 和 ks-test 拒绝正态性假设。
如果您能指导我准确解释它们以评估正态性并识别任何偏离高斯分布的情况，我将不胜感激。这些生物标志物通常在尾部变得更重，但我不会进行变换。欢迎任何评论！
编辑：如您所见，我对变量进行了 3 次测量。正如我之前所说，我的主要计划是比较 2 样本测试（_v00 与 _v66 相比，以及 _v66 与 _v01 相比），但我专注于正态性假设。








]]></description>
      <guid>https://stats.stackexchange.com/questions/657859/normality-assumption-qqplot-interpretation</guid>
      <pubDate>Tue, 26 Nov 2024 10:45:29 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的回归中的 HAC（Newey-West）标准误差小于普通标准误差？</title>
      <link>https://stats.stackexchange.com/questions/657795/why-are-the-hac-newey-west-standard-errors-smaller-than-the-ordinary-standard</link>
      <description><![CDATA[我用时间序列进行回归分析，然后进行了 Breusch-Godfrey（BG）检验和 White 检验。检验结果表明，自相关和异方差同时存在。因此，我选择使用 HAC（Newey-West）标准误差进行分析。我惊讶地发现，HAC（Newey-West）标准误差比普通标准误差要小。为什么会这样？在这种情况下，我应该使用哪种标准误差？]]></description>
      <guid>https://stats.stackexchange.com/questions/657795/why-are-the-hac-newey-west-standard-errors-smaller-than-the-ordinary-standard</guid>
      <pubDate>Mon, 25 Nov 2024 10:09:08 GMT</pubDate>
    </item>
    <item>
      <title>没有真实标签的模型比较</title>
      <link>https://stats.stackexchange.com/questions/657699/model-intercomparison-with-no-ground-truth-labels</link>
      <description><![CDATA[领域是天气建模。我有 4 个不同的模型，其中一个是我的，而其他 3 个是独立模型，我认为这些模型相对熟练（即比随机模型好得多）。每个模型在 1000 个感兴趣的空间位置（我将它们称为节点）中的每一个上预测一个值。遗憾的是，每个节点的真实值是无法测量的，因此无法明确地说出哪个模型最好。
但是，我可以说我的模型的预测（模型 A）与其他模型的相关性比任何其他模型都更好：




A
B
C
D




A
1
0.636338
0.571829
0.569591


B
0.636338
1
0.251786
0.283723


C
0.571829
0.251786
1
0.299746


D
0.569591
0.283723
0.299746
1



模型 A 比其他任何模型都更善于预测模型 B，A 与 C 和 A 与 D 也是如此。由于每个模型的预测都是一些预测的组合“真实”信号和一些噪音/错误，我假设我更好的整体相关性意味着我的模型可能比任何其他模型捕获更多的“真实”信号和更少的噪音。
这是一个有效的结论吗？如果是这样，有没有办法量化它，或者我可以引用一个参考资料来支持这个说法？]]></description>
      <guid>https://stats.stackexchange.com/questions/657699/model-intercomparison-with-no-ground-truth-labels</guid>
      <pubDate>Fri, 22 Nov 2024 20:20:57 GMT</pubDate>
    </item>
    <item>
      <title>关于神经网络反向传播的问题</title>
      <link>https://stats.stackexchange.com/questions/657684/questions-on-backpropagation-in-a-neural-net</link>
      <description><![CDATA[我理解如何以符号方式应用反向传播，用笔和纸计算公式。当真正将这些推导应用于数据时，我有两个问题：

假设某个梯度看起来像 $o_i \times w_{i,j}$，其中 $o_i$ 是第 $i$ 个神经元的输出，而 $w_{i,j}$ 是其权重之一。现在我有一批数据点，$o_i$ 中的每个数据点都有不同的值，那么我该如何用数字计算它？我是否只需对该批次中的所有数据点取平均值？
换句话说：假设我将误差（最后）定义为平均值，那么该平均值（期望值）是否只是与其余的反向传播一起传播，并且每当我看到输入数据的依赖性时，我只需插入平均运算符？
有人可以提供一些关于此的直觉吗？我的看法是，因为误差位于所有梯度的“分子”中，所以无论我们对它做什么，无论是平均还是求和，都可以简单地向后传播，您只需对您看到的所有项执行该运算符（例如平均）。如果您有一个常数（例如权重），它不会做任何事情，如果您有一个输出，您会对批次进行平均。这是合理的解释吗？

如果我们有一个较早的神经元 $N$，它在后面的层中作为输入出现两次，在进行反向传播时，我们可以在第二次遇到它时对其导数执行 $+=$，即我们可以天真地将各种梯度​​贡献相加。但是这个神经元可以以不同的方式参与后续神经元，它们可能有不同的数学表达式等。然而，我们可以天真地将其所有梯度相加，这是如何工作的？
这是一个很好的属性，但我不明白它是如何如此简单地发挥作用而没有任何问题。有人可以提供直观的解释吗？这似乎与“反向传播如何分块、分步骤地工作，因此确切的依赖关系不应该重要”有关，这是我目前的理解水平。

]]></description>
      <guid>https://stats.stackexchange.com/questions/657684/questions-on-backpropagation-in-a-neural-net</guid>
      <pubDate>Fri, 22 Nov 2024 14:20:10 GMT</pubDate>
    </item>
    <item>
      <title>如何重新表示概率向量，而不使其值超出 [0, 1] 的界限？</title>
      <link>https://stats.stackexchange.com/questions/657526/how-to-re-mean-a-vector-of-probabilities-without-having-values-beyond-the-0-1</link>
      <description><![CDATA[假设我们有一个概率向量 $x$。其平均值为 $\bar{x}$。现在，假设我们想将向量重新平均为 0 到 1 之间的任意值。这是某个给定的比例 $p$。
我想要做的是从 $x$ 转到 $x&#39;$，其中 $\bar{x&#39;} = p$。但是，这些表示概率，因此也需要满足 $x&#39; \in [0, 1]$。此外，$x&#39;$ 需要保留 $x$ 的相对排序。
实现此目的的一种方法是简单地降低变量的平均数并重新添加 $p$：
$x&#39; = x - \bar{x} + p$
但是，这会强制值低于 0 或高于 1，因此不再表示概率。
实现此目的的另一种方法是将 $x$ 和 $p$ 都带入逻辑空间，在那里重新定义含义，然后将其带回。为了简便起见，我使用 $logit$ 作为逻辑函数，使用 $invlogit$ 作为其逆函数：
$x&#39; = invlogit(logit(x) - \overline{logit(x)} + logit(p))$
但是，概率空间中的平均值将不再是 $p$。
如何重新表示概率向量，而不使值超出 [0, 1] 的界限？
以下是 R 中的演示。
remean &lt;- function(x, p) x - mean(x) + p

remean_logit &lt;- function(x, p) {
x &lt;- qlogis(x)
x &lt;- x - mean(x) + qlogis(p)
return(plogis(x))
}

set.seed(1839)
p &lt;- .56
x &lt;- runif(1000)

summary(x) # 平均值为 .497
summary(remean(x, p)) # 平均值正确，但最大值 &gt; 1
summary(remean_logit(x, p)) # 值在 0 和 1 之间，但平均值不正确
]]></description>
      <guid>https://stats.stackexchange.com/questions/657526/how-to-re-mean-a-vector-of-probabilities-without-having-values-beyond-the-0-1</guid>
      <pubDate>Tue, 19 Nov 2024 19:56:55 GMT</pubDate>
    </item>
    <item>
      <title>正态分布中的 $\mathbb E[M\times\sum{X_i}]$ 是多少，其中 $M$ 是样本中位数？</title>
      <link>https://stats.stackexchange.com/questions/655794/what-is-mathbb-em-times-sumx-i-in-normal-distribution-m-being-the-samp</link>
      <description><![CDATA[给定 $X_{1},\ldots,X_{n}$ 标准正态分布的 iid 样本，设 $M=M(X_1,\ldots,X_n)$ 为该样本的中位数。$$\mathbb E\left[M(X_1,\ldots,X_n)\times\sum_{i=1}^n{X_i}\right]$$ 的值是多少]]></description>
      <guid>https://stats.stackexchange.com/questions/655794/what-is-mathbb-em-times-sumx-i-in-normal-distribution-m-being-the-samp</guid>
      <pubDate>Tue, 15 Oct 2024 09:25:52 GMT</pubDate>
    </item>
    </channel>
</rss>