<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 19 Jan 2025 15:15:58 GMT</lastBuildDate>
    <item>
      <title>层次模型规范和伪复制</title>
      <link>https://stats.stackexchange.com/questions/660236/hierarchical-model-specification-and-pseudoreplication</link>
      <description><![CDATA[我有一个实验，我们测量嵌套在地块内的单棵树的直径。地块在整个景观中成对出现，配对中的其中一个地块随机分配到治疗组，另一个地块分配到对照组。地块内的所有树木要么接受治疗，要么接受对照条件。
至少有两种方法可以对这些数据进行建模。第一种方法是指定一个随机效应模型，考虑配对结构（下面以 R 为例）。
library(nlme)
fit &lt;- lme(diameter ~ treatment, random = ~1|pair)

或者，我也可以将地块指定为嵌套在配对中的随机效应。
fit &lt;- lme(diameter ~ treatment, random = ~1|pair/plot)

这会导致非常不同的功率水平。地块和处理完全混淆了——给定地块内的所有树木要么接受处理条件，要么接受控制条件。因此，我认为将地块指定为随机效应是没有意义的，因为它会在估计过程中“吸收”所有潜在的处理效果。
这里有明显的选择吗？或者可以选择任一结构？指向特定学术文献的回复可获得加分！]]></description>
      <guid>https://stats.stackexchange.com/questions/660236/hierarchical-model-specification-and-pseudoreplication</guid>
      <pubDate>Sun, 19 Jan 2025 14:39:09 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 OLS 中复制数据集会导致参数方差减少 1/2？</title>
      <link>https://stats.stackexchange.com/questions/660225/why-does-duplicating-a-dataset-reduce-the-variance-of-parameter-by-1-2-in-ols</link>
      <description><![CDATA[假设我在数据集 $D$ 和线性回归模型 $y = \beta_0 + \beta_1x + \epsilon$ 上运行 OLS。如果我现在复制数据集以获得 $D&#39;$ 并再次运行 OLS，我会得到 $y = \beta_0&#39; + \beta_1&#39;x + \epsilon$。
根据我的直觉理解，$Var(\beta_1&#39;) = \frac{1}{2} Var(\beta_1)$。但是，我在数学上很难解决这个问题。
设 $S_{XX} = \sum (x_i - \bar{x})^2$，我们知道 $Var(\beta_1) = \frac{\sigma^2}{S_{XX}}$ 和 $\sigma^2 = \frac{SSE}{n-2}$，所以
$$Var(\beta_1) = \frac{1}{(n-2)}\frac{SSE}{S_{XX}} $$
如果我们复制数据集中的每个点，我们有 $S_{XX}&#39; = 2S_{XX}$ 和 $SSE&#39; = 2*SSE$ - 这一切对我来说都很有意义。问题是，如果我们复制数据集，我们现在有 $2n$ 个点，所以自由度不会恰​​好翻倍，因为它是 $2n-2 \neq 2(n-2)$。如果我对此的理解不正确，请告诉我。这导致以下内容：
$$Var(\beta_1&#39;) = \frac{2*SSE}{(2n-2)*2S_{XX}} = \frac{1}{2n-2}\frac{SSE}{S_{XX}} &lt; \frac{1}{2(n-2)}\frac{SSE}{S_{XX}} = \frac{1}{2}Var(\beta_1)$$
我知道如果 $n$ 变得非常大，那么 $\frac{1}{2n-2} \approx \frac{1}{2(n-2)}$，但除了这个（或者可能是我推导中的错误）之外，还有什么合理的解释可以解释为什么在复制数据集后，估计值 $\beta_1$ 的方差不完全是 1/2？]]></description>
      <guid>https://stats.stackexchange.com/questions/660225/why-does-duplicating-a-dataset-reduce-the-variance-of-parameter-by-1-2-in-ols</guid>
      <pubDate>Sun, 19 Jan 2025 06:09:32 GMT</pubDate>
    </item>
    <item>
      <title>哈默斯利·克利福德定理的两个版本</title>
      <link>https://stats.stackexchange.com/questions/660224/two-versions-of-the-hammersley-clifford-theorem</link>
      <description><![CDATA[在学习蒙特卡罗方法时，我了解到完整条件$P(x_j \mid x_1, \ldots, x_{j-1}, x_{j+1}, \ldots, x_p)$在某些条件下决定联合分布。这个结果是使用书中所谓的 Hammersley-Clifford 定理（如下所述）证明的，但我注意到他们使用的形式与我在马尔可夫网络背景下熟悉的形式非常不同。

Hammersley-Clifford 定理（来自书中）
让 $(X_1, \ldots, X_p)$ 满足正性条件并具有联合密度 $f(x_1, \ldots, x_p)$。然后，对于所有 $(\xi_1, \ldots, \xi_p) \in \operatorname{supp}(f)$:
$$
f(x_1, \ldots, x_p) \propto \prod_{j=1}^p \frac{f_{X_j \mid X_{-j}}(x_j \mid x_1, \ldots, x_{j-1}, \xi_{j+1}, \ldots, \xi_p)}{f_{X_j \mid X_{-j}}(\xi_j \mid x_1, \ldots, x_{j-1}, \xi_{j+1}, \ldots, \xi_p)}。
$$

Hammersley-Clifford 定理（针对马尔可夫网络）
设 $P$ 为 $\mathcal{X}$ 上的正分布，$\mathcal{H}$ 为 $\mathcal{X}$ 上的马尔可夫网络图。如果 $\mathcal{H}$ 是 $P$ 的 I-map（即 $\mathcal{H}$ 的马尔可夫独立性作为 $P$ 中的概率独立性成立），则 $P$ 是对 $\mathcal{H}$ 进行因式分解的吉布斯分布。
因式分解意味着 $P$ 是通过因子 $\Phi = \{\phi_1(\boldsymbol{D}_1), \ldots, 参数化的吉布斯分布\phi_K(\boldsymbol{D}_K)\}$:
$$
P_{\Phi}(X_1, \ldots, X_n) = \frac{1}{Z} \prod_{k=1}^K \phi_k(\boldsymbol{D}_k),
$$
其中 $Z$ 是规范化常数，每个 $\boldsymbol{D}_k$ 对应于 $\mathcal{H}$ 的一个完全子图（团）。

我的问题是：Hammersley-Clifford 定理的这两个陈述如何联系在一起？它们是具有相同名称但本质上不同的定理吗，或者是否有办法从另一个定理中证明一个定理（尤其是从第二个定理中证明第一个定理）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660224/two-versions-of-the-hammersley-clifford-theorem</guid>
      <pubDate>Sun, 19 Jan 2025 04:44:17 GMT</pubDate>
    </item>
    <item>
      <title>重要性抽样最优解的存在性</title>
      <link>https://stats.stackexchange.com/questions/660221/existence-of-optimum-of-importance-sampling</link>
      <description><![CDATA[众所周知，为了估计 $\mathbb E_{p(x)}[f(x)] = \int p(x) f(x)\,\mathrm dx$，我们可以对提议分布 $q(x)$ 使用重要性抽样。Wiki 声称最佳 $q$ 的形式为：$q(x) \propto p(x) |f(x)|$，并且归一化常数为 $\int p(x) |f(x)|\,\mathrm dx$。但是，可积性并不意味着绝对可积性，因此$\int p(x) |f(x)|\,\mathrm dx$可能不存在。在这种情况下，最优的$q(x)$是什么？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660221/existence-of-optimum-of-importance-sampling</guid>
      <pubDate>Sun, 19 Jan 2025 03:46:07 GMT</pubDate>
    </item>
    <item>
      <title>R 中的可视化包含太多数据点吗？</title>
      <link>https://stats.stackexchange.com/questions/660219/visualizations-in-r-with-too-many-data-points</link>
      <description><![CDATA[我在 R 中有多个变量的模拟数据：
set.seed(123)
n &lt;- 100
x1 &lt;- rnorm(n, mean = 50, sd = 10)
x2 &lt;- x1 * 0.7 + rnorm(n, mean = 0, sd = 5)
x3 &lt;- -x1 * 0.5 + rnorm(n, mean = 70, sd = 8)
x4 &lt;- rnorm(n, mean = 40, sd = 15)
x5 &lt;- x4 * 0.6 + rnorm(n, mean = 30, sd = 7)

data &lt;- data.frame(
Variable1 = x1,
Variable2 = x2,
Variable3 = x3,
Variable4 = x4,
Variable5 = x5
)

数据$Group &lt;- cut(data$Variable1, 
breaks = 3, 
labels = c(&quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;))

然后我制作了这个可视化（平行坐标图），因为这是唯一一种可以用多个变量完成的可视化类型（据我所知）：
library(GGally)

ggparcoord(data = data,
columns = 1:5,
groupColumn = &quot;Group&quot;,
scale = &quot;uniminmax&quot;,
showPoints = TRUE,
alphaLines = 0.3,
title = &quot;模拟数据的平行坐标图&quot;) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = &quot;bold&quot;),
axis.text.x = element_text(angle = 45, hjust = 1)
) +
scale_color_brewer(palette = &quot;Set2&quot;)


我有以下问题：假设我有很多行数据。有什么办法可以让视觉效果保持完整，而不会太过拥挤？
我唯一想到的想法是使用随机抽样从原始数据集中创建一个较小的数据集，但我正在寻找其他想法。例如，是否可以对彼此非常相似的轨迹进行聚类，从而减少线条数量？（并使线条较多的轨迹的颜色更深）]]></description>
      <guid>https://stats.stackexchange.com/questions/660219/visualizations-in-r-with-too-many-data-points</guid>
      <pubDate>Sun, 19 Jan 2025 01:41:53 GMT</pubDate>
    </item>
    <item>
      <title>交叉熵损失的方差是什么意思？</title>
      <link>https://stats.stackexchange.com/questions/660198/what-is-the-meaning-of-the-variance-of-cross-entropy-loss</link>
      <description><![CDATA[通常我们用所有测试集的交叉熵损失的平均值作为指标，那我们可以用交叉熵损失的方差作为指标吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660198/what-is-the-meaning-of-the-variance-of-cross-entropy-loss</guid>
      <pubDate>Sat, 18 Jan 2025 12:21:24 GMT</pubDate>
    </item>
    <item>
      <title>需要有关时间序列分析中使用的数据的帮助</title>
      <link>https://stats.stackexchange.com/questions/660195/need-help-regarding-the-data-used-in-time-series-analysis</link>
      <description><![CDATA[我是时间序列的初学者。我试图通过获取过去 10 年的月度数据来预测棉花作物的价格。但价格数据仅适用于 1 月至 5 月，然后是 11 月和 12 月。由于棉花在这里是季节性作物，因此没有其他月份的市场数据。那么在这种情况下，我该如何进行时间序列分析，以及我应该使用多少个最小数据点来运行模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/660195/need-help-regarding-the-data-used-in-time-series-analysis</guid>
      <pubDate>Sat, 18 Jan 2025 10:11:48 GMT</pubDate>
    </item>
    <item>
      <title>当响应变量是“一年中的某一天”时，应使用哪种回归模型</title>
      <link>https://stats.stackexchange.com/questions/660197/which-regression-model-to-use-when-response-variable-is-day-of-the-year</link>
      <description><![CDATA[我有一个检测数据集，其中包含一年中被标记动物被重新检测到的天数（即 1 - 365），该天数是在它之前被释放的地点（即 release_location）被重新检测到的。有来自五个不同释放地点的多只被标记的动物，有些动物在被释放后的多年内被重新检测到（即 redetection_year）。示例数据（实际数据集要大得多）：
redetection_year&lt;-c(2,3,2,4,5,3,4,2,5)
redetection_day&lt;-c(25,66,340,129,12,67,200,36,248)
animal_id&lt;-c(1,1,2,3,3,4,4,4,4)
release_location&lt;-c(&quot;A&quot;,&quot;A&quot;,&quot;A&quot;,&quot;B&quot;,&quot;B&quot;,&quot;A&quot;,&quot;A&quot;,&quot;A&quot;)
df&lt;-data.frame(animal_id, release_location, redetection_day, redetection_year)

我想要在 R 中运行模型，以测试释放位置和重新检测年份（预测变量）是否预测重新检测日期（即 1-365）（响应变量）。这可以通过线性回归来实现吗？还是因为响应变量的格式而需要考虑？即它只从 1 到 365，它是循环的。
我读过一些关于 Tobit 回归的文章，这些回归适用于响应变量被审查的情况，以及许多关于当它是预测变量时如何使用“天”变量的示例，但我找不到适合我的问题的解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/660197/which-regression-model-to-use-when-response-variable-is-day-of-the-year</guid>
      <pubDate>Sat, 18 Jan 2025 08:51:33 GMT</pubDate>
    </item>
    <item>
      <title>计算有条件计分的积分制游戏中的概率和预期回合数</title>
      <link>https://stats.stackexchange.com/questions/660191/calculating-probability-and-expected-rounds-in-a-point-based-game-with-condition</link>
      <description><![CDATA[Ann 和 Ben 正在玩一个由多轮组成的游戏。第一个达到 $10$ 分的人将赢得游戏。每轮只有一名获胜者。假设各轮是独立的，Ann 赢得每轮的概率为 $0.6$。
a) 如果每轮获胜者获得 $2$ 分，则计算 Ann 赢得比赛的概率。
b) 与 (a) 相同，但如果获胜者还赢得了上一轮，则他们将获得额外的 $1$ 分。
c) 计算在场景 (a) 和 (b) 中 Ann 获胜所需的预期轮数。
以下是我对 (a) 部分的解决方案：
Ann 的第一个获胜配置是 AAAAA，表示 Ann 连续在所有 $5$ 轮中获胜。显然，这种情况的概率是 $0.6^5$。
Ann 的下一个获胜配置是五个 $6$ 轮 BAAAAA、ABAAAA、AABAAA、AAABAA、AAAABA。它们代表所有 $6$ 个字母的组合，其中只有一个 B，最后一个字母是 A。这五种情况的概率为 $5*0.6^5*0.4$。
Ann 的下一个获胜配置都是 $(6*5)/2 = 3*5 = 15$ 个七个字母的组合，字母 A 和 B，其中 $2$ B 和 $5$ A 的顺序任意，但最后一个字母是 A。这五种情况的概率为 $15*0.6^5*0.4^2$。
系数 $(6*5)/2 = 15$ 是将 $2$ 个字母 B 放置在 $6$ 个可能位置上的数量。
Ann 的下一个获胜配置是所有 $8$ 个字母的单词，字母 A 和 B 分别为 $5$ 个 A 和 $3$ 个 B，其中 A 位于最后一个位置。他们会为这些场景添加概率${7\choose 3}*0.6^5*0.4^3 = 35*0.6^5*0.4^3$。这里 ${7\choose 3} = 35$ 是将 $3$ 个字母 B 放置在 $7$ 个可能位置上的数量。
Ann 的下一个获胜配置是所有 $9$ 个字母的单词，字母 A 和 B 分别为 $5$ 个 A 和 $4$ 个 B，其中 A 位于最后一个位置。他们会为这些场景添加概率${8\choose 4}*0.6^5*0.4^4 = 70*0.6^5*0.4^4$。这里 ${8\choose 4} = 70$ 是将 $4$ 个字母 B 放置在 $8$ 个可能位置上的数量。
现在最后一个计算是计算 $5$ 个加数的总和
$P = 0.6^5 + 5*0.6^5*0.4 + 15*0.6^5*0.4^2 + 35*0.6^5*0.4^3 + 70*0.6^5*0.4^4 = 0.6^5*(1 + 5*0.4 + 15*0.4^2 + 35*0.4^3 + 70*0.4^4) = 0.73343232$。
目前，我没有任何解决部分 (b) 和 (c) 的想法，所以我希望有人能支持我找到这些问题的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/660191/calculating-probability-and-expected-rounds-in-a-point-based-game-with-condition</guid>
      <pubDate>Sat, 18 Jan 2025 07:42:24 GMT</pubDate>
    </item>
    <item>
      <title>排除构成数据结构一部分的相关变量，转而采用生物学上更有意义的变量</title>
      <link>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</link>
      <description><![CDATA[我正在处理从卫星图像 (Sentinel) 捕获的植被覆盖率数据集。数据以季度/季节为间隔捕获。使用 GAM，我正在模拟植被覆盖率如何响应环境变量，降雨量是感兴趣的关键预测变量。但是，降雨量与季度/季节具有合理的相关性，相关系数为 r = -0.73。通常，当两个变量的相关性大于 0.7 时，我会将其中一个排除在分析之外。所以，我的问题是，我可以从分析中排除季度/季节吗？
季度/季节是数据集设计/结构的一部分，通常我的理解是应该在模型中考虑数据结构。但是，从生物学角度来看，连续降雨变量是一个更有趣、更有意义的变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</guid>
      <pubDate>Thu, 16 Jan 2025 03:22:55 GMT</pubDate>
    </item>
    <item>
      <title>嵌入可以在上下文赌博机中使用吗？</title>
      <link>https://stats.stackexchange.com/questions/659792/can-embeddings-be-used-in-contextual-bandits</link>
      <description><![CDATA[我有一个现实问题，即应该为特定客户提供特定产品的折扣/促销，其相互竞争的目标是 1/ 最大化收入和 2/ 最小化模型估计中的方差。
相关文献

在大型电子商务公司中，推荐和个性化团队长期以来一直使用嵌入技术（例如双塔模型）将产品和项目嵌入到同一个潜在空间中。

合成控制允许科学家利用观察数据来构建反事实，其中一些个体收到了需要综合考虑接受治疗的个体在没有治疗的情况下会如何表现（反事实）。

最后，contextual bandits 将动作映射到奖励，平衡探索与利用。


我正在考虑的一般前提是将这些想法结合起来。仅考虑前两个，即嵌入和合成控制，可以将治疗随机应用于用户-产品对，例如促销；其次，对于任何给定的用户-产品对，可以从几个其他用户-产品对中合成一个反事实（嵌入在聚合时会映射到潜在空间中非常相似的位置）。仅这些步骤就可能有效地估计治疗对配对的因果影响。由于嵌入是潜在的，我们不能声称“[有形协变量] 引起了用户响应”；我们的结论仅限于治疗。
现在，包括上下文强盗元素，我们应该能够包括开发（以前只涉及探索）。强盗可能会根据与处理过的配对及其响应的距离提出新的用户-项目对；换句话说，提出远离无效观察的配对（例如：口香糖降价 1%），同时提出更接近有效观察的配对。
我很好奇，这样的设计以前实现过吗？如果是，那么从中吸取了什么教训？]]></description>
      <guid>https://stats.stackexchange.com/questions/659792/can-embeddings-be-used-in-contextual-bandits</guid>
      <pubDate>Thu, 09 Jan 2025 18:04:58 GMT</pubDate>
    </item>
    <item>
      <title>对 DiD 设计中均值中位数估计量的洞察</title>
      <link>https://stats.stackexchange.com/questions/659655/insights-into-median-of-means-estimators-in-did-designs</link>
      <description><![CDATA[我目前正在开展一个研究项目，重点研究双差分 (DiD) 设计中的稳健估计量，特别是在经典的两期两组设置中。我的主要兴趣是对 y 方向异常值的稳健性（我污染了误差项），并且我一直在探索均值中位数 (MoM) 估计量作为标准 DiD 治疗效果估计量（基于均值）的潜在替代方案。
但是，我遇到了几个问题：

缺乏文献：我找不到任何先前的研究或 DiD 环境中均值中位数估计量的应用。有人知道是否存在这样的研​​究或我可以在哪里找到吗？
意外结果：当我模拟和实施 MoM 估计量时，我得到的结果与标准 DiD 估计量相同 - 即使包含受污染的数据点也是如此。这让我开始质疑为什么 MoM 估计量在这种设置下不是更稳健。

有人能解释为什么中位数估计量在这种情况下可能无法按预期执行吗？或者 DiD 框架中是否存在一些基本问题，导致 MoM 方法不太合适？
如果您有任何想法、文献建议，甚至直观的解释，我将不胜感激！
在此先感谢您的帮助！

这是我的模拟设置：

数据生成：我模拟了 N=500 和 T=2 个时间段（治疗前和治疗后）的面板数据。一半的单位在第二期进行治疗。结果方程为 $Y = 0.1 + 0.2⋅time − 0.1⋅group + β_{true}⋅D + ϵ $。这里，$β_{true} = 0.4 $，ϵ 是带有污染的随机噪声。
污染：随机噪声 𝜖 以混合形式生成：
$ ϵ = \begin{cases} N(0, \sigma^2) &amp; \text{with probability } (1 - p), \\
U(d, c) &amp; \text{with probability } p \end{cases}$ 
我尝试过参数 $\sigma$、$p$ 和 $c$（也尝试过不对称污染），但这似乎没有什么区别。在下图中，$\sigma = 0.1$，$p = 0.1$ 和 $c = -d = 50$。
估计量构造如下：
$ \text{DiD 估计} =
\left(
\overline{Y}_{\text{Treated, Post}} - \overline{Y}_{\text{Treated, Pre}}
\right)
-
\left(
\overline{Y}_{\text{Control, Post}} - \overline{Y}_{\text{Control, Pre}}
\right)
$
$
\text{中位数（MoM）：}
$

将数据拆分为 $ K = \sqrt(N) $ 个块
计算特定于块的 DiD 估计值：$
\text{Block DiD Estimate} = \text{DiD(Block_i})$
最终 MoM 估计值是块估计值的中位数：$
\text{MoM Estimate} = \text{Median(Block DiD Estimates)}$




块在单元级别定义。因此，每个单元被随机分配到 K 个块中的一个：
block_assignment &lt;- sample(1:K, length(unique(Y_df$unit)), replace = TRUE)

同一单元（在两个时间段内）的所有观察结果都分配给同一个块：
block_map &lt;- data.frame(unit = unique_units, block = block_assignment)Y_df &lt;- Y_df %&gt;% left_join(block_map, by = &quot;unit&quot;)



时间 (T) 取值 {1,2} = {治疗前、治疗后

组 (P) 取值 {0,1} = {对照、治疗
 P &lt;- rbinom(N, 1, 0.5)


治疗虚拟变量 (D) 取值 {0,1}
 D[P == 1, 2] &lt;- 1 # 治疗开始于第 2 阶段，适用于接受治疗的单位







]]></description>
      <guid>https://stats.stackexchange.com/questions/659655/insights-into-median-of-means-estimators-in-did-designs</guid>
      <pubDate>Tue, 07 Jan 2025 10:05:08 GMT</pubDate>
    </item>
    <item>
      <title>何时使用哪种样本方差公式？</title>
      <link>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</link>
      <description><![CDATA[我知道样本方差的公式为
$$s^2 = \frac{\sum (x_i - \bar{x})^2}{n - 1}$$
我还知道样本方差的公式为“均值平方减均值平方”。
在计算给定样本的样本方差时，我使用了这两个公式，但发现它们给出了两个不同的答案，因此我想问，什么时候应该使用第一个公式，什么时候应该使用第二个公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</guid>
      <pubDate>Tue, 07 Jan 2025 05:32:19 GMT</pubDate>
    </item>
    <item>
      <title>具有相关随机变量的 $E[X\mid U,V]$</title>
      <link>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</link>
      <description><![CDATA[设 $(X,Y,Z)$ 为三维随机变量，其密度函数为 $f(x,y,z)=\frac{2}{3}(x+y+z)$ 在 $0&lt;x,y,z&lt;1$ 上，$U=\min(X,Y,Z)$，$V=\max(X,Y,Z)$。计算$E[X\mid U,V]$。
我认为答案是$\frac{14U^2+26UV+14V^2}{27(U+V)}$，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</guid>
      <pubDate>Thu, 13 Jun 2024 05:43:04 GMT</pubDate>
    </item>
    <item>
      <title>峰度值如何判断不健康事件</title>
      <link>https://stats.stackexchange.com/questions/532032/how-the-kurtosis-value-can-determine-the-unhealthy-event</link>
      <description><![CDATA[我读了一篇关于空气质量的论文。作者提到“PM10 污染物也显示出最高的峰度值，这表明它最常出现在不健康的污染事件中。”
所以我很困惑，峰度值如何用来解释健康和不健康事件？]]></description>
      <guid>https://stats.stackexchange.com/questions/532032/how-the-kurtosis-value-can-determine-the-unhealthy-event</guid>
      <pubDate>Thu, 24 Jun 2021 11:59:06 GMT</pubDate>
    </item>
    </channel>
</rss>