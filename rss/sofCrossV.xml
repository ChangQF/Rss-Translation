<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 07 Jul 2024 18:18:16 GMT</lastBuildDate>
    <item>
      <title>一组可能相关的随机变量的平均值的方差是否小于它们各自方差的平均值？</title>
      <link>https://stats.stackexchange.com/questions/650638/is-the-variance-of-the-mean-of-a-set-of-possibly-dependent-random-variables-less</link>
      <description><![CDATA[一组可能相关的随机变量的均值的方差是否小于或等于它们各自方差的平均值？
从数学上讲，给定可能相关的随机变量$X_1, X_2, ..., X_n$：
设$\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i$为这些随机变量的均值。
以下说法是否正确：
$$\text{Var}(\bar{X}) \leq \frac{1}{n}\sum_{i=1}^n \text{Var}(X_i)$$
我知道对于独立随机变量，我们有以下等式：
$$\text{Var}(\bar{X}) = \frac{1}{n^2}\sum_{i=1}^n \text{Var}(X_i)$$
这显然满足不等式。但是，我不确定这是否适用于因变量。
如果这个不等式成立，是否有证明或直观的解释？
如果它并非总是成立，那么在哪些条件下它成立？以下不等式呢？
$$\text{Var}(\bar{X}) \leq \text{Max}_{i=1}^n \text{Var}(X_i)$$
任何见解、证明或反例都将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650638/is-the-variance-of-the-mean-of-a-set-of-possibly-dependent-random-variables-less</guid>
      <pubDate>Sun, 07 Jul 2024 15:39:10 GMT</pubDate>
    </item>
    <item>
      <title>预测比率的模型建议</title>
      <link>https://stats.stackexchange.com/questions/650637/model-suggestion-to-predict-a-ratio</link>
      <description><![CDATA[我有一个项目，其中有公司数据（一个变量是他们的客户数量以及他们是否有合规性问题）。我试图建立一个模型，以找到给定公司的员工与客户比率，从而最大限度地降低合规性问题的可能性。我拥有的标签属于一种情况（公司有合规性问题），但其余的则没有标签，好像他们没有任何问题，他们可能没事，或者只是尚未发现。我可以采取什么方法来建立一个模型，该模型将公司详细信息提供比率？任何想法或其他可供参考的工作都值得赞赏。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/650637/model-suggestion-to-predict-a-ratio</guid>
      <pubDate>Sun, 07 Jul 2024 14:36:10 GMT</pubDate>
    </item>
    <item>
      <title>通过引导抽样从每日数据中获取月度统计数据</title>
      <link>https://stats.stackexchange.com/questions/650636/bootstrap-sampling-to-get-monthly-statistic-from-daily-data</link>
      <description><![CDATA[我有历史冬季的每日 (iid) 数据：$d:$（价格、价值、温度等）。
“价值”实际上是“价格”和其他协变量的上凹函数。
我感兴趣的是查看一个月的价值，也就是 30 天的“价值”总和。所有数据都是 iid 的，并且每个月出现的可能性相同。
我的想法是从我的每日数据中抽取 10_000 个大小为 30 的样本并计算统计数据，并将其用作分布。我将历史数据用作实际每日分布 F 的离散分布近似值。
我已阅读了一些关于引导估计的证明，大多数都假设引导样本大小等于您的数据样本大小。我知道这对于矩等统计数据来说可能需要，但就我而言，使用这种不同的样本量是否合理？哪里可能出错？]]></description>
      <guid>https://stats.stackexchange.com/questions/650636/bootstrap-sampling-to-get-monthly-statistic-from-daily-data</guid>
      <pubDate>Sun, 07 Jul 2024 14:18:53 GMT</pubDate>
    </item>
    <item>
      <title>关于推导 MAP 估计量的基本问题</title>
      <link>https://stats.stackexchange.com/questions/650635/basic-question-about-deriving-map-estimator</link>
      <description><![CDATA[假设我们有一个随机过程$X(t, u)$，其由$t$和$u$参数化，并生成数据$x$。我们对 $u$ 也有一个先验，$p(u)$。
我说得对吗？找到 仅 $t$ 的最大后验 (MAP) 估计的表达式应该是
$$
t_{MAP} = \underset{t}{\operatorname{argmax}} \int p(x | t, u) p(u) du = \underset{t}{\operatorname{argmax}} p(x|t)
$$
也就是说，你会将干扰参数边缘化，对吗？
现在假设 $U\sim \mathcal{N}[\hat{u}, C_u]$ 和 $X \mid u, t \sim \mathcal{N}[M(t) u, C_x]$。
说 $p(x | t)$ 等于 $M(t) U$ 的 pdf 正确吗？也就是说，
$$X \mid t \sim \mathcal{N}[M(t)\hat{u}, M(t)C_uM(t)^\top]$$
换一种说法，更一般地说，推导出 $f(U, t)$ 的分布是否会得到与 $\int p(x|t, u)p(u)du$ 相同的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/650635/basic-question-about-deriving-map-estimator</guid>
      <pubDate>Sun, 07 Jul 2024 12:46:11 GMT</pubDate>
    </item>
    <item>
      <title>评估测试图像的最佳时期是什么时候？</title>
      <link>https://stats.stackexchange.com/questions/650634/what-is-the-best-epoch-to-evaluate-the-test-images</link>
      <description><![CDATA[我为图像分类任务创建了一个训练集、一个验证集和一个测试集。然后，我使用训练集进行训练，并对验证集进行评估。因此，下一步是评估测试集，基本上是为了推理。为了选择最佳的 epoch 模型，我通常会检查验证损失。但是，我不确定这种方式是否正确。我将结果添加为图片，并标记了最佳的 train/val 准确率和最低的 train/val 损失。损失函数是交叉熵。

后面的步骤显然是过度拟合，但训练损失仍然越来越低，直到第 25 个 epoch。如果我只检查 val 损失，我可能会选择第 13 个 epoch。或者最高的验证准确率也可能很重要。
我读过一些文章或论坛问题，比如这个、这个、这个和其他几个，但这个话题没有真正的结论。那么，对于这种情况，有没有通用的解决方案，或者我应该以不同的方式考虑每个分类/对象检测任务并做出相应的决定？]]></description>
      <guid>https://stats.stackexchange.com/questions/650634/what-is-the-best-epoch-to-evaluate-the-test-images</guid>
      <pubDate>Sun, 07 Jul 2024 12:16:32 GMT</pubDate>
    </item>
    <item>
      <title>主观信心作为回归模型中的权重</title>
      <link>https://stats.stackexchange.com/questions/650629/subjective-confidence-as-weights-in-regression-models</link>
      <description><![CDATA[我有数据，其中受试者在某个范围内对数量进行评分（$y$），但也添加了他们对选择的确定程度的主观信心（$w$）。我最初的想法是将$w$作为权重添加到回归模型中（暂时忽略如何对其进行规范化或标准化的问题）。我的上级要求检查$w$与方差之间的关系 - 指出如果它们与方差成反比，则应加入置信度。我们检查了非加权模型的平均绝对残差（作为方差的代理），发现较高置信度的残差与较低置信度的残差大致相同。我的上级得出结论，我们不应该使用置信度评级。
虽然我同意数据和模型似乎没有表明更高的置信度评级与更低的方差相关，但我仍然不相信这是使用权重的唯一原因。如果对某些数据点有很高的置信度，那么与其他置信度较低的数据点相比，它们是否应该有更多发言权来将回归线拉近它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/650629/subjective-confidence-as-weights-in-regression-models</guid>
      <pubDate>Sun, 07 Jul 2024 09:58:56 GMT</pubDate>
    </item>
    <item>
      <title>报告 clmms 中固定效应的重要性 - 何时使用 ANODE 表？</title>
      <link>https://stats.stackexchange.com/questions/650628/reporting-significance-of-fixed-effects-in-clmms-when-to-use-anode-tables</link>
      <description><![CDATA[我正在使用 clmm 研究一些用于序数结果的混合效应模型。我已经确定了最终模型，现在想展示研究结果。阅读后，我看到 ANODE 表既用于模型比较，也用于分解模型中每个固定效应的贡献。我无法找到任何关于这是否与报告相关的指导，以及最佳实践是什么。该模型是使用 R 中的序数包估计的，ANODE 表来自 RVAideMemoire。
实际上，这与模型输出中报告的 z 检验之间的结果几乎没有差异（如下所示）。但是，我想更多地了解两组输出之间的差异。有人可以提出一些建议吗？我可以找到有关模型比较的信息，但找不到关于如何报告最终模型中固定效应的重要性的具体问题的答案。
非常感谢！
 估计误差 z Pr(&gt;|z|)

Var1 -2.966 0.482 -6.152 &lt;0.001

Var2 -2.102 0.486 -4.32 &lt;0.001

Var3 -1.593 0.476 -3.349 0.001

Var4 0.973 0.474 2.051 0.040

Var5 -0.711 0.175 -4.07 &lt;0.001

偏差分析（II 型检验）

LR Chisq Df Pr(&gt;Chisq) 

Var1 29.2981 1 &lt;0.001 ***
Var2 16.2687 1 &lt;0.001 ***
Var3 10.2870 1 0.001 **
Var4 3.9415 1 0.047 *
Var5 14.5733 1 &lt;0.001 ***
]]></description>
      <guid>https://stats.stackexchange.com/questions/650628/reporting-significance-of-fixed-effects-in-clmms-when-to-use-anode-tables</guid>
      <pubDate>Sun, 07 Jul 2024 08:26:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么考虑自相关残差几乎无助于分布滞后模型中的参数估计</title>
      <link>https://stats.stackexchange.com/questions/650626/why-does-accounting-for-autocorrelated-residuals-barely-help-parameter-estimatio</link>
      <description><![CDATA[这个问题困扰了我很长时间。基本上，我有一个分布式滞后模型$$y_t=\sum_{i=0}^{p} \beta_i x_{t-i} + u_t.$$
回归问题有点错误指定，所以我最终得到自相关错误$$u_t=\alpha u_{t-1}+\epsilon_t.$$
由于我的模型中自相关程度很高，$\beta$的估计应该非常低效，但是当我使用 GLS 校正自相关时，我的$\beta$估计没有任何改善。当我的问题略有不同，并且 $$y_t= \sum_{i=1}^p \beta_i x_t^i + u_t,$$ 时，$y$ 只是同时存在的不同 $x$ 的函数，GLS 表现惊人，而最小二乘则举步维艰。
为什么 GLS 在第一个例子中表现如此糟糕，我如何让它表现得更好（我只关心参数估计）？
我在 R 中编写了两个例子：
n_sim&lt;-15
LS_R2&lt;-rep(0,n_sim)
GLS_R2&lt;-rep(0,n_sim)
ar_noise&lt;-0.7
for(sim in 1:n_sim){
n=5000
set.seed(sim)
x_vec&lt;-arima.sim(list(order=c(1,0,0),ar=c(0.5)),n=n,sd=1)
noise&lt;-arima.sim(list(order=c(1,0,0),ar=c(ar_noise)),n=n,sd=1)
y&lt;-rep(0,n)
p&lt;-150
true_beta&lt;-seq(from=5,to=0,length.out=p)+rnorm(p,sd=0.1)
for(i in p:length(y)){
y[i]&lt;-y[i]+sum(x_vec[i:(i-p+1)]*true_beta)
}
y&lt;-y+noise*var(y)/var(noise)/50

#尝试简单最小二乘法（应该非常低效）
Xmat&lt;-matrix(0,ncol = p,nrow = n)
for(i in 1:ncol(Xmat)){
Xmat[,i]&lt;-c(rep(0,i-1),x_vec[1:(length(x_vec)-i+1)])
}

XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
LS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

#尝试广义最小二乘法（应该是最优且有效的）
get_T&lt;-function(ar,N){
i_vec&lt;-c(1:N,2:N)
j_vec&lt;-c(1:N,1:(N-1))
x_vec&lt;-c(sqrt(1-ar^2),rep(1,N-1),rep(-ar,N-1))
sparseMatrix(i = i_vec, j = j_vec, x = x_vec, dims = c(N,N))
}

T1&lt;-get_T(ar_noise,length(y))

Xmat&lt;-T1%*% Xmat
y&lt;-as.numeric(T1%*% matrix(y,ncol=1))

XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
GLS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

}
LS_R2
GLS_R2
mean(LS_R2)
mean(GLS_R2)

and
n_sim&lt;-15
LS_R2&lt;-rep(0,n_sim)
GLS_R2&lt;-rep(0,n_sim)
for(sim in 1:n_sim){
n=5000
set.seed(sim)
noise&lt;-arima.sim(list(order=c(1,0,0),ar=c(ar_noise)),n=n,sd=1)
y&lt;-rep(0,n)
p&lt;-150
Xmat&lt;-matrix(0,ncol = p,nrow = n)
for(i in 1:ncol(Xmat)){
Xmat[,i]&lt;-arima.sim(list(order=c(1,0,0),ar=c(0.5)),n=n,sd=1)
}
true_beta&lt;-seq(from=5,to=0,length.out=p)+rnorm(p,sd=0.1)
for(i in p:length(y)){
y[i]&lt;-y[i]+sum(Xmat[i,]*true_beta)
}
y&lt;-y+noise*sd(y)/sd(noise)

#尝试简单最小二乘法（应该是非常低效的）
XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
LS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

#尝试广义最小二乘法（应该是最优且有效的）
get_T&lt;-function(ar,N){
i_vec&lt;-c(1:N,2:N)
j_vec&lt;-c(1:N,1:(N-1))
x_vec&lt;-c(sqrt(1-ar^2),rep(1,N-1),rep(-ar,N-1))
sparseMatrix(i = i_vec, j = j_vec, x = x_vec, dims = c(N,N))
}

T1&lt;-get_T(ar_noise,length(y))

Xmat&lt;-T1%*% Xmat
y&lt;-as.numeric(T1%*% matrix(y,ncol=1))

XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
GLS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

}
LS_R2
GLS_R2
mean(LS_R2)
mean(GLS_R2)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/650626/why-does-accounting-for-autocorrelated-residuals-barely-help-parameter-estimatio</guid>
      <pubDate>Sun, 07 Jul 2024 07:15:49 GMT</pubDate>
    </item>
    <item>
      <title>故意发表错误统计方法的著名例子有哪些？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650620/what-are-famous-examples-of-erroneous-statistical-methods-being-deliberately-pub</link>
      <description><![CDATA[是否有著名的错误统计方法发表的例子，作者从一开始就知道他们的方法是错误的，但故意隐瞒它？
例如，我想到的是人们试图测试某些期刊的同行评审过程的可靠性，或者在战争时期，出版物可能旨在鼓励敌人使用错误的方法。但我对其他可能的动机也很感兴趣。促使我提出这个问题的原因是，在社会科学中有几个这样的例子，所以我想知道它是否也发生在统计研究中。
我不认为有很多著名的例子（我从未听说过这样的案例，这就是我问这个问题的原因），因为隐藏方法不正确可能非常困难，所以我想问题的范围不是太广泛。]]></description>
      <guid>https://stats.stackexchange.com/questions/650620/what-are-famous-examples-of-erroneous-statistical-methods-being-deliberately-pub</guid>
      <pubDate>Sun, 07 Jul 2024 04:46:31 GMT</pubDate>
    </item>
    <item>
      <title>拆分数据然后进行回归是否合理？</title>
      <link>https://stats.stackexchange.com/questions/650613/is-it-reasonable-to-split-the-data-and-then-perform-the-regression</link>
      <description><![CDATA[有一家商店销售圆珠笔。我已从该商店获取每笔交易的数据，包括交易 ID、颜色、每笔交易的销售数量、总价等。通过将总价除以每笔交易数量，我计算出了每笔交易中每支笔的单价。我认为每支圆珠笔的单价与其颜色和每笔交易中购买的数量有关。因此，我将使用线性回归来检验这一假设：单价 = Alpha1 x 颜色 + Alpha2 x 数量 + Beta。
原始数据图像：

问题是，我可以在执行回归之前拆分这些数据吗？例如，在原始样本数据中，第一笔交易销售了 2 支圆珠笔，因此我将把它拆分为两个条目。拆分数据如下图所示，回归方程不变：单价 = Alpha1 x 颜色 + Alpha2 x 数量 + Beta。
拆分数据图片：

我的问题是：这个操作可以吗？会有什么影响，为什么？有相关参考吗？
我觉得这个操作可能不合理，比如反而增加了蓝色笔的数据权重。但是我对统计学的理解不够，无法清晰的表达出为什么或者怎么不合理。]]></description>
      <guid>https://stats.stackexchange.com/questions/650613/is-it-reasonable-to-split-the-data-and-then-perform-the-regression</guid>
      <pubDate>Sun, 07 Jul 2024 01:30:45 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 GMM 估计</title>
      <link>https://stats.stackexchange.com/questions/650611/gmm-estimation-in-r</link>
      <description><![CDATA[我正在尝试执行 GMM 估计，但在 R 中。在我的上下文中，我做了几个协方差限制。举一个简单的例子：$Var(y)=a$ 和 $Cov(y, Ly))=b$。现在的问题是，对于任何给定的数据集，可以制作这些样本等价物的观察次数对于两个矩将有所不同 () 通常，STATA 和 R 都会采用样本矩矩阵并通过除以 1/NT 或 1/N(T-1) 来找到平均值，但在这种情况下，这将不起作用！但是，在 STATA 中，可以使用 nocommonesample 选项来解决这个问题。我的问题是，R 中可用的等效选项或方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/650611/gmm-estimation-in-r</guid>
      <pubDate>Sat, 06 Jul 2024 23:46:26 GMT</pubDate>
    </item>
    <item>
      <title>解释交互术语</title>
      <link>https://stats.stackexchange.com/questions/650598/interpreting-interaction-term</link>
      <description><![CDATA[假设我有兴趣估计一种治疗（相对于对照）的效果，完全且有条件地基于基线特征（例如收入水平）的不同水平（例如 3）。我会进行如下回归（T 是治疗，I 是收入水平 1-3）：
$Y = a + b_1T + b_2T(x=1) + b_3T(x=2) + b_4T(x=3) + e$
我不确定我是否理解了三个交互项是与什么进行比较的：是“纯对照”还是 b1？换句话说，我们是否使用来自对照组的收入水平数据来运行此回归？或者我们只是将 b2、b3 和 b4 的结果与 b1 的结果进行比较？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650598/interpreting-interaction-term</guid>
      <pubDate>Sat, 06 Jul 2024 15:42:26 GMT</pubDate>
    </item>
    <item>
      <title>关于测试可靠性对测试组合权重的影响的问题</title>
      <link>https://stats.stackexchange.com/questions/650558/question-on-the-effect-of-test-reliability-on-weighting-of-a-test-battery</link>
      <description><![CDATA[最初，测试组件有 4 个部分：两个 100 项多项选择题测试、一个口语测试和一个论文测试。每个部分测量不同的主题。4 个部分中的每一个权重为 25%。
现在，每个多项选择题测试的测试长度已减少到 60 项（出于实际原因）。每个部分仍占 25%。
如果两个 MC 测试的可靠性降低到零，则两个 MC 测试测量的两个主题的权重将为零。（两个 MC 测试只会产生误差。）实际上，可靠性降低了，但并没有降低到零。
我的问题是，可靠性的变化对两个 MC 测试测量的两个主题的权重有何影响。我如何估计由于变化而导致的权重差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/650558/question-on-the-effect-of-test-reliability-on-weighting-of-a-test-battery</guid>
      <pubDate>Fri, 05 Jul 2024 22:15:38 GMT</pubDate>
    </item>
    <item>
      <title>当我的因变量在 R 中被分数幂运算时，我应该如何反向变换 beta 系数</title>
      <link>https://stats.stackexchange.com/questions/650513/what-should-i-back-transform-beta-coefficients-when-my-dependent-variable-is-fra</link>
      <description><![CDATA[我有这个混合效应回归模型。为了在连续尺度因变量中创建正态分布，我对其进行了分数指数化：
TB_fract &lt;- TB ^ (1/1.4)

我的以下模型是这样的，其中 period 表示时间的整数值，MRN 表示单个受试者：
lme4::lmer(TB_fract ~ Surg_group_fact + (1 + period|MRN), data = full_patient_data_2, na.action = na.omit)

我的输出是这样的。 time_below_sqrt 是 TB_fract 的 DV 表示：


我显然有负 beta 估计值，这不允许转换为 1.4 次方。如果我的 DV 是具有负 beta 系数的原始值的分数值，那么我该如何解释这些结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/650513/what-should-i-back-transform-beta-coefficients-when-my-dependent-variable-is-fra</guid>
      <pubDate>Fri, 05 Jul 2024 09:14:21 GMT</pubDate>
    </item>
    <item>
      <title>对于给定平均值和标准差的正数据，偏度的下限是多少？</title>
      <link>https://stats.stackexchange.com/questions/650039/vintage-of-this-lower-bound-on-skewness-for-positive-data-with-given-mean-and-sd</link>
      <description><![CDATA[事实证明，对于任何具有给定平均值 μ 和标准差 σ 的严格正数据集，其偏度 $g_1$ 都有一个下限：
$$
g_1 &gt; \sigma/\mu - \mu/\sigma。
$$
虽然在最近的一些文献中，它被当作一个新的结果来讨论，但在我看来，它很可能相当古老——原因我在这篇 PubPeer 文章（其中还包含一个基本证明）中概述过。
来这里问这个问题时，我遇到了 2 个可以立即应用这个结果的问题：请参阅我的答案这里和这里。因此，这表明下限至少没有它应该的那么出名。但它可能是最近才出现的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650039/vintage-of-this-lower-bound-on-skewness-for-positive-data-with-given-mean-and-sd</guid>
      <pubDate>Thu, 27 Jun 2024 11:01:24 GMT</pubDate>
    </item>
    </channel>
</rss>