<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 29 Mar 2025 06:23:38 GMT</lastBuildDate>
    <item>
      <title>使用不同先验的贝叶斯推断估算硬币的偏见</title>
      <link>https://stats.stackexchange.com/questions/663264/estimating-a-coins-bias-using-bayesian-inference-with-different-priors</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/663264/estimating-a-coins-bias-using-bayesian-inference-with-different-priors</guid>
      <pubDate>Sat, 29 Mar 2025 05:20:20 GMT</pubDate>
    </item>
    <item>
      <title>双向方差分析 +分段</title>
      <link>https://stats.stackexchange.com/questions/663263/two-way-anova-segmentation</link>
      <description><![CDATA[我有数据集在运行电子邮件广告系列或社交媒体活动后跟踪销售结果，因此总共有4个案例：
电子邮件活动|社交媒体运动
否|    否
是|    否
否|    是
是|    是
除了广告系列外，数据集还包括性别细分，购买历史记录（低，医学，高）和年龄。我使用双向方差分析来测试电子邮件Capaign和社交媒体活动的销售百分比的影响。
我对如何包括测试段有点困惑，我是否执行与以前相同的方差分析，但仅使用我正在查看的细分市场？还是我在方差分析中包括：
销售〜C（emailCampaign） + C（socialmediaad） + c（年龄） + c（parosinginghistory） + c（性别）？]]></description>
      <guid>https://stats.stackexchange.com/questions/663263/two-way-anova-segmentation</guid>
      <pubDate>Sat, 29 Mar 2025 04:32:17 GMT</pubDate>
    </item>
    <item>
      <title>跨不同组的塑造值</title>
      <link>https://stats.stackexchange.com/questions/663261/shap-values-across-different-groups</link>
      <description><![CDATA[ i通过随机森林，支持向量机，逻辑回归和XGBoost（TidyModels R软件包）算法开发并比较了四个ML模型，并使用年龄组分层的数据进行了数据。因此，我有一个全部数据，因为我的数据集没有很多观察结果。
之后，我估计了每个模型的形状值（Dalex R软件包）。为此，我从每个年龄类别（18-64; 65-74; 75岁或以上）中随机选择一个观察结果，以检查每个年龄段的最重要特征（rf; lr; svm; svm; svm; xgboost）。需要这种方法，因为某些功能对每个特定年龄段都很重要。最小和最大的人在糖尿病预测的健康和生物条件方面可能有所不同，我的结果变量。
我想知道这个策略是否正确，也就是说，仅使用每个年龄段的塑形值来解释我的模型。
我担心，通过将数据除以年龄并按年龄类别开发模型，我对每个年龄段的观察结果很少，并且性能可能会受到很大影响，并且该模型可能无法正确解释每个重要的预测指标。。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/663261/shap-values-across-different-groups</guid>
      <pubDate>Sat, 29 Mar 2025 01:30:22 GMT</pubDate>
    </item>
    <item>
      <title>差分与差异方程[关闭]</title>
      <link>https://stats.stackexchange.com/questions/663258/differential-vs-difference-equations</link>
      <description><![CDATA[我来自工程背景，我从未使用过差异方程。在阅读有关它们的同时了解到这只是微分方程的离散对应物。 在使用时间序列分析时，使用微分方程是真的，鉴于它们用于连续性上下文的许多数据？我想这是动态时间序列分析是什么。。]]></description>
      <guid>https://stats.stackexchange.com/questions/663258/differential-vs-difference-equations</guid>
      <pubDate>Fri, 28 Mar 2025 21:24:54 GMT</pubDate>
    </item>
    <item>
      <title>最小二乘的历史</title>
      <link>https://stats.stackexchange.com/questions/663255/history-of-least-squares</link>
      <description><![CDATA[我正在阅读试图将理想化曲线（如椭圆形）适合天文数据的历史。当时（1700年代至1800年代）已经存在各种方法。一个这样的例子是一种简单的平均方法，在该方法中，您将过度确定的线性系统添加成组，直到解决。还存在其他方法，例如用于最小化最大偏差的算法（以及最小化总偏差）。
 Legendre的最小二乘方法是什么使它成为最受欢迎的方法？仅仅是因为它比其他方法容易得多？更具体地说，使用最小二乘有几乎是自动的答案，而要最大程度地减少最大偏差需要一种费力的算法（当时是手工完成的）。
最小二乘作为MLE或蓝色ECT的理由。 ，所有这些都发生了。但是在早期，在1700年代至1800年代之间，与其他现有方法相比，最小二乘的拟合只是最简单的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663255/history-of-least-squares</guid>
      <pubDate>Fri, 28 Mar 2025 18:55:18 GMT</pubDate>
    </item>
    <item>
      <title>在混合模型中与与互动的混合模型中的收敛性和奇异性问题</title>
      <link>https://stats.stackexchange.com/questions/663253/issues-with-convergence-and-singularity-in-mixed-models-with-interactions</link>
      <description><![CDATA[我正在尝试使用 lme4  r 中的包装&gt; r 中的软件包适合某些三级混合模型，以与个人对经济重新分配的态度的数据，其中个人在州年内嵌套在州年内，在州内嵌套在州内（“参考美国州”）。我还获得了对他们接受调查的每个人居住状况的平均房价以及他们是否是房主的数据。一种运行良好且不会引发错误或警告的模型如下：
  lmer（y〜logrealprice_bar +房主 + logrealprice_bar：房主 +  
    logrealprice_demeaned + logrealprice_demeaned：房主 +  
    （1 | fipsStat） +（1 | fipsstatyr），data = d）
 
其中 y 是支持个人 i 更多重新分配的二进制指标；  logrealprice_bar 是1985  -  2022年期间 i 状态中的AVG（log）房价； 房主是一个虚拟，表明 i 是房主；  logrealprice_demeaned 是对 i 在这一年中 i 状态中的平均（日志）房价进行了调查。  fipsStat 是 i 的状态；  fipsStatyr 是 i 的州年。  logrealprice_demeaned 是感兴趣的主要预测指标。此系数代表“州内”平均值。在（日志）平均房价中增加1的影响在特定州年的平均值中，其州的平均值对支持非房屋的重新分布的可能性。除此之外，在州和州年水平上也有随机的拦截。
但是，如果我修改了此模型以包含logrealprice_deaned的随机斜率，该斜率可以在各州中变化，即：
  lmer（y〜logrealprice_bar +房主 + logrealprice_bar：房主 +  
    logrealprice_demeaned + logrealprice_demeaned：房主 +  
    （logrealprice_demeaned | fipsStat） +（1 | fipsstatyr），data = d）
 
我将获得以下输出（带有有关收敛的“单数”拟合的警告）：
 收敛上的reml标准：23628.2

缩放残差： 
    最小1Q中位数3Q最大 
-1.8435 -1.3328 0.5498 0.7645 1.0094 

随机效果：
 组名称差异std.dev。 corr
 fipsstatyr（截距）0.0016712 0.04088      
 fipsStat（截距）0.0003577 0.01891      
            logrealprice_demeaned 0.0005313 0.02305 1.00
 残留0.2122573 0.46071      
OBS数量：18208年，组：FipsStatyr，870； FIPSSTAT，51

固定效果：
                                  估计标准。错误t值
（截距）0.739009 0.280197 2.637
logrealprice_bar 0.001294 0.022606 0.057
HOMEWHORNER1 0.444785 0.28996 1.534
logrealprice_demeaned 0.086037 0.033588 2.562
logrealprice_bar：Homeowner1 -0.045609 0.023372 -1.951
HOMEWHORNER1：LOGREALPRICE_DEMEANED -0.022460 0.039547 -0.568

固定效果的相关性：
            （int）lgrlprc_b homeowner1 lgrlprc_d l_：hom
logrlprc_br -1.000                                      
HOMEWHORNER1 -0.644 0.642                               
lgrlprc_dmn 0.072 -0.072 -0.101                     
L_：Homeowne 0.643 -0.642 -1.000 0.102          
HOMEWHORNER1：-0.081 0.082 0.152 -0.725 -0.155
优化器（nloptwrap）收敛代码：0（确定）
边界（单数）拟合：请参阅帮助（&#39;Issingular&#39;）
 
  lme4 如果据说有单一的拟合，为什么还会给我结果？另外，如果我修改上述模型并消除涉及房主的术语，即：
  lmer（y〜logrealprice_bar + logrealPrice_demeaned +（logrealPrice_demeaned |  
    fipsStat） +（1 | fipsStatyr），data = d）
 
我不会收到有关奇异性或融合的警告。也不使用以下模型来保持房主互动但删除状态年的随机截距：
  lmer（y〜logrealprice_bar +房主 + logrealprice_bar：房主 +  
    logrealprice_demeaned + logrealprice_demeaned：房主 +  
    （logrealprice_demeaned | fipsStat），data = d）
 
这里发生了什么？不幸的是，数据受到保护，因此我无法共享它们，但是似乎我缺少一些理论问题，即引发警告的模型的可识别性。我只是不知道这是什么。而且我也不知道该怎么做的事实是，尽管存在问题，  仍然会打印出结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/663253/issues-with-convergence-and-singularity-in-mixed-models-with-interactions</guid>
      <pubDate>Fri, 28 Mar 2025 17:26:34 GMT</pubDate>
    </item>
    <item>
      <title>LGD模型的欧洲央行回测的t检验描述</title>
      <link>https://stats.stackexchange.com/questions/663252/description-of-t-test-in-ecb-backtest-of-lgd-models</link>
      <description><![CDATA[ 以下文本有关将模型与已实现值与t检验的实现值进行比较的文本发生。我是否在指出零假设的措辞（第一个亮点）是（礼貌地）高度罕见的，并且在第二个亮点中所做的那样，p值的计算会导致1的p值，如果p值是1，那么如果模型过多的实现值？  ？
    &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stats.stackexchange.com/questions/663252/description-of-t-test-in-ecb-backtest-of-lgd-models</guid>
      <pubDate>Fri, 28 Mar 2025 17:23:43 GMT</pubDate>
    </item>
    <item>
      <title>我是对高斯流程的不确定性量化吗？还是我的预测这么糟糕？ （gpytorch）</title>
      <link>https://stats.stackexchange.com/questions/663249/am-i-doing-uncertainty-quantification-for-gaussian-processes-incorrectly-or-are</link>
      <description><![CDATA[快速概述我的数据；我有将近300个样本，大约有40个功能（33个数值，7个编码为0和1，因为它们是绝对的），因此绝对是一个高维数据集。我使用大多数基本的精确高斯流程来在gpytorch中对这些数据进行建模并查看预测的值，我不相信它们都是可怕的，但是当我尝试获得错误界限时，看来置信区间绝对是巨大的。。
事实是，我以前从未做过，我完全不确定UQ如何与GP回归一起工作。我知道这个模型很可能存在认知和态度不确定性。在寻找示例的同时，许多模型似乎对训练值建立了不确定性，而其他模型则在测试集中。我个人的假设是我想检查测试集，并且为了可视化置信区间，我使用标准偏差和情节错误栏。 （当然，我无法真正做人们倾向于用于1-D回归输​​入和输出的漂亮图）。注意：我的代码在Sklearn中使用常规火车测试。
我正在添加我使用的代码段，并且会喜欢任何人都可以拥有的任何见解; 
  model.eval（）
可能性.eval（）

使用Torch.no_grad（）：
    pred_y =似然（模型（test_x））
test_y = test_y.detach（）。numpy（）
pred_mean = pred_y.mean.numpy（）
pred_std = pred_y.stddev.numpy（）

test_real = yscaler.inverse_transform_mean（test_y.reshape（-1，1））。squeeze（）
pred_mean_real = yscaler.inverse_transform_mean（pred_mean.reshape（-1，1））。squeeze（）
std_real = yscaler.inverse_transform_std（pred_std）

轴[1] .scatter（test_real，pred_mean_real，s = 8，c =&#39;b&#39;，alpha = 0.6）
轴[1] .set_xlabel（“测试值”）
轴[1] .set_ylabel（“预测”
axes [1] .plot（[test_real.min（），test_real.max（）]，[test_real.min（），test_real.max（）]，&#39;r--&#39;）
轴[1] .set_title（“预测与腐蚀率的测试值”
plt.tight_layout（）
plt.show（）

upper = 1.96 * std_real
较低= 1.96 * std_real
信任_Region = [下部，上]

plt.errorbar（test_real，pred_mean_real，yerr = upper，fmt =&#39;o&#39;，markersize = 5，color =&#39;b&#39;， 
             ecolor =&#39;灰色&#39;，alpha = 0.5，倾斜= 3）
plt.xlabel（“测试值”）
plt.ylabel（“预测”
plt.plot（[[test_real.min（），test_real.max（）]，[test_real.min（），test_real.max（）]，&#39;r--&#39;，babel =; plabel =; quote;
 
我从中得到的是：
  但显然这不是很漂亮，误差界限（标准偏差 - 使用 gpytorch文档文档，这是完全了解的。 But essentially it states, &quot;If we denote a test point (test_x) as x* with the true output being y*, then model(test_x) returns the model posterior distribution p(f* | x*, X, y), for training data X, y.该后部是我们试图建模的功能的分布，从而量化了模型不确定性。”然后文档继续并列出
  f_preds =模型（test_x）
y_preds =可能性（型号（test_x））

f_mean = f_preds.mean
f_var = f_preds.variance
f_covar = f_preds.covariance_matrix
f_samples = f_preds.sample（sample_shape = torch.size（1000，））
 
但似乎不使用这些？我有一个暗示，这里的卑鄙和差异对我想要的东西很有用，但是老实说，我至少需要一些帮助理解发生了什么，我真的很感激是否有人可以解释我担心的任何事情。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/663249/am-i-doing-uncertainty-quantification-for-gaussian-processes-incorrectly-or-are</guid>
      <pubDate>Fri, 28 Mar 2025 17:06:04 GMT</pubDate>
    </item>
    <item>
      <title>终身估计是自上次次要事件以来的时间（几乎是泊松过程）</title>
      <link>https://stats.stackexchange.com/questions/663245/lifetime-estimates-conditional-on-time-since-last-secondary-event-almost-poisso</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/663245/lifetime-estimates-conditional-on-time-since-last-secondary-event-almost-poisso</guid>
      <pubDate>Fri, 28 Mar 2025 15:21:08 GMT</pubDate>
    </item>
    <item>
      <title>香草方差分析的用法和哲学</title>
      <link>https://stats.stackexchange.com/questions/663242/usage-and-philosophy-of-vanilla-anova</link>
      <description><![CDATA[我没有统计背景，所以请耐心等待。我试图理解简单的一种方差分析布局。特别是我
有一个疑问对用F检验检验的零假设的疑问，这似乎是ANOVA   $$ H_0：\ MU_1 = \ MU_2 =…= \ MU_K $$ $  
这个假设对我来说似乎很奇怪，因为它没有说什么是最好的治疗方法。为什么不直接估计效应大小，例如直接 $ \ mu_i $ 或 $ \ mu_i- \ mu_j $ ？我给自己的答案是这个。当我们没有足够的数据将每种处理与彼此进行比较时（因为单独的每种治疗都有很少的样本，这可能会导致错误低估和误报），但是ANOVA很有用，但是我们有足够的数据回答 $ h_0 $ h_0 $ 。如果 $ h_0 $ 被拒绝，那么我们可以：

 收集更多样本以回答有关个人治疗的更多特定问题或 

 更多地相信ANOVA后完成的效应大小分析的结果（从这个意义上讲，我们构建了一个组合模型）。


从这个意义上讲，方差分析是避免误报或指导实验选择的初步测试。
这真的是ANOVA NULL假设背后的哲学吗？还是我误会了和缺少其他无用的方式或需要的其他方式？
我很抱歉，如果已经解决了这个基本问题。如果我将删除此。]]></description>
      <guid>https://stats.stackexchange.com/questions/663242/usage-and-philosophy-of-vanilla-anova</guid>
      <pubDate>Fri, 28 Mar 2025 13:52:35 GMT</pubDate>
    </item>
    <item>
      <title>训练轨迹：CNN培训中AUC和PR-AUC的不稳定行为</title>
      <link>https://stats.stackexchange.com/questions/663233/training-trajectory-erratic-behaviour-of-auc-and-pr-auc-in-cnn-training</link>
      <description><![CDATA[我已经训练了一个CNN，该CNN旨在预测患者是否死亡。该模型输入大小244x244的图像并输出二进制结果（高度不平衡7％）。我拥有的数据集很小。我总共有965张图像。其中，在火车加载器（772张图像）中使用了80％，测试装载机（193张图像）中使用了20％。我知道我可以使用数据扩展，但是在这一刻，我想保留培训数据。损失是Bceloss。
我是ML和CNN的新手，但我认为该模型正在从火车和测试损失曲线中进行适当训练。令我惊讶的是，与火车和测试损失相比，AUC和PRAUC的不稳定行为。我希望在所有情况下都更加顺畅曲线，但是我会得到上下行为（尽管总体趋势是向上的）。在这些模型中，这种行为通常吗？
此外，即使火车损失减少，从时代20开始，测试损失几乎保持恒定。但是，火车AUC和PR-AUC急剧增加，并且测试AUC仍在增加。损失的改善很小，以这种方式改善AUC是正常的吗？
谢谢
  &lt;img alt =“火车和测试损失，AUC和PR-AUC，auc and pr-auc per acoch” src =“ src”]]></description>
      <guid>https://stats.stackexchange.com/questions/663233/training-trajectory-erratic-behaviour-of-auc-and-pr-auc-in-cnn-training</guid>
      <pubDate>Fri, 28 Mar 2025 07:15:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么主要组件应该是正交的，先验的？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/663219/why-should-principal-components-be-orthogonal-a-priori</link>
      <description><![CDATA[首先，让我开始清楚我不接受的答案。使用光谱定理的任何答案（即在样本协方差）都不是我想要的。相关，我将不接受特征向量/特征值的解释：雷利的原则并不令人满意。我想要的是一个解释纯粹是根据差异的，为什么我们应该期望apriori的主要方向是正交的。
帮助我理解为什么从一开始就实现正交性是自然的约束。]]></description>
      <guid>https://stats.stackexchange.com/questions/663219/why-should-principal-components-be-orthogonal-a-priori</guid>
      <pubDate>Thu, 27 Mar 2025 20:55:10 GMT</pubDate>
    </item>
    <item>
      <title>证明回归参数的差异与确定系数负相关</title>
      <link>https://stats.stackexchange.com/questions/663197/proof-that-variance-of-a-regression-parameter-is-negatively-related-to-the-coeff</link>
      <description><![CDATA[根据古吉拉特语（P.328，等式7.4.12），在具有常数和两个回归器的多线性回归模型中， $ \ hat \ hat \ beta_2 $ 是
 $$
\ frac {\ sigma^2} {\ sum_ix_ {2i}^2（1-r^2_ {23}）}，
$$ 
在哪里
 $$
r^2_ {23} = \ frac {（\ sum_ix_ {2i} x_ {3i}）^2} {\ sum_ix_ {2i}^2 \ sum_ix_ {3i}^2}
$$  
和下案字母表示与变量的平均值的偏差， $ x_ {ji} = x__ {ji}  -  \ bar {x_j} $ 。。
我设法计算直到
  $$ var-cov（\ hat {\ beta}）= \ sigma^{2} {2}（x^{\ prime} x）^{ -  1} = \\
\ frac {\ sigma^{2}}} {\ left | x^{\ prime} x \ right |} \ left [\ begin {array {array} {cccc} 1＆amp; r_ {12} \ sqrt {c_ {11} \ times c_ {22}}＆amp; \ dots＆amp; r1n \ sqrt {c_ {11} \ times c_ {nm}} \\
r_ {21} \ sqrt {c_ {22} \ times c_ {11}}}＆amp; 1＆amp; \ dots＆amp; r2n \ sqrt {c_ {22} \ times c_ {nm}} \\
\ vdots＆amp; \ vdots＆amp; \ ddots＆amp; \ vdots \\
r_ {k1} \ sqrt {c_ {kk} \ times c_ {11}}}＆amp; r_ {k2} \ sqrt {c_ {kk} \ times c_ {22}}}＆amp; \ dots＆amp; 1 \ end {array} \ right] $$  
，但从那里开始很有雾。有人可以告诉我如何从2中得出1个？]]></description>
      <guid>https://stats.stackexchange.com/questions/663197/proof-that-variance-of-a-regression-parameter-is-negatively-related-to-the-coeff</guid>
      <pubDate>Thu, 27 Mar 2025 13:36:15 GMT</pubDate>
    </item>
    <item>
      <title>信息几何因果推断（IGCI）中因果机制的独立性，以确定2个变量之间的因果方向</title>
      <link>https://stats.stackexchange.com/questions/663143/independence-of-causal-mechanism-in-information-geometric-causal-inference-igci</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/663143/independence-of-causal-mechanism-in-information-geometric-causal-inference-igci</guid>
      <pubDate>Wed, 26 Mar 2025 06:31:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么可以将有条件期望的期望重写为OLS差异推导的期望产物</title>
      <link>https://stats.stackexchange.com/questions/661871/why-can-the-expectation-of-a-conditional-expectation-be-rewritten-as-the-product</link>
      <description><![CDATA[ 练习1：了解OLS估计器的方差 - 稳定矩阵 
我正在通过计量经济学练习，需要帮助理解特定期望的理由。
我们考虑线性模型：
  $$
\ MathBf {y} = \ MathBf {X} \ BoldSymbol {\ beta} + \ varepsilon = \ beta_1 \ mathbf {x}^{x}^{（1）} + \ beta_2 + \ beta_2 \ beta_2 \ mathbf {x}} + beta} + \ varepsilon
$$  
其中（\ mathbf {y}，\ Mathbf {x}^{（1）}，\ MathBf {x}^{（2）}，\ \ Mathbf {x}^{（3）}）
在假设1-6下，OLS估计器的方差 - 可使矩阵（\ hat {\ boldsymbol {\ beta}}）有条件在解释变量上有条件
由：给出
  $$
\ sigma _ {\ hat {\ boldsymbol {\ beta}} | \ MathBf {X}} = E \ left [（\ hat {\ boldsymbol {\ beta}}}}  -  e [\ hat {\ boldsymbol {\ boldsymbol {\ beta}} | \ mathbf {x}]） e [\ hat {\ boldsymbol {\ beta}} | \ mathbf {x} \ right] =
\ begin {pmatrix}
\ sigma_ {11 | \ Mathbf {x}}}＆amp; \ sigma_ {12 | \ Mathbf {x}}}＆amp; \ sigma_ {13 | \ Mathbf {x}} \\
\ sigma_ {21 | \ Mathbf {x}}}＆amp; \ sigma_ {22 | \ Mathbf {x}}}＆amp; \ sigma_ {23 | \ Mathbf {x}} \\
\ sigma_ {31 | \ Mathbf {x}}}＆amp; \ sigma_ {32 | \ Mathbf {x}}}＆amp; \ sigma_ {33 | \ Mathbf {x}}
\ end {pmatrix}
$$  
其中每个元素（\ sigma_ {kl | \ mathbf {x}}）表示估计系数的条件（CO）方差。
 问题（b）：
我们被要求证明：
  $$
\ sigma _ {\ hat {\ boldsymbol {\ beta}} | \ MathBf {X}} = E \ left [\ HAT {\ BoldSymbol {\ beta}}} \ hat {\ boldsymbol {\ beta}}}&#39;| \ Mathbf {x} \ right]  -  e [\ hat {\ boldsymbol {\ beta}}} | \ Mathbf {X}] E [\ HAT {\ BoldSymbol {\ beta}} | \ Mathbf {X}]&#39;
$$  
 我的问题：
我正在努力证明简化的合理性：
  $$
e \ left [\ hat {\ boldsymbol {\ beta}} e [\ hat {\ boldsymbol {\ beta}}}&#39;| \ mathbf {x}] | \ Mathbf {x} \ right] = e [\ hat {\ boldsymbol {\ beta}}} | \ Mathbf {X}] E [\ HAT {\ BoldSymbol {\ beta}}}&#39;| \ Mathbf {x}]
$$  
哪些定理或属性允许我们以这种方式提出期望？这是迭代期望定律的应用？
任何指导或参考都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661871/why-can-the-expectation-of-a-conditional-expectation-be-rewritten-as-the-product</guid>
      <pubDate>Wed, 26 Feb 2025 14:16:25 GMT</pubDate>
    </item>
    </channel>
</rss>