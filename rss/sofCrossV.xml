<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 13 May 2024 18:16:58 GMT</lastBuildDate>
    <item>
      <title>当我们一个人的样本多于另一个人的样本时，有没有一种方法可以公平地评判两个人？</title>
      <link>https://stats.stackexchange.com/questions/647163/is-there-a-way-to-judge-two-people-fairly-when-we-have-more-samples-of-one-perso</link>
      <description><![CDATA[我拥有一个人比另一个人更多的表现样本。我应该删除多余的样本吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647163/is-there-a-way-to-judge-two-people-fairly-when-we-have-more-samples-of-one-perso</guid>
      <pubDate>Mon, 13 May 2024 17:50:22 GMT</pubDate>
    </item>
    <item>
      <title>标准误差和置信区间</title>
      <link>https://stats.stackexchange.com/questions/647158/standard-error-and-confidence-intervals</link>
      <description><![CDATA[关于理论概念...我们使用置信区间进行推断，将研究结果外推到类似样本。这是真的吗？
置信区间的差值是多少，结果除以n的平方根，标准误差是怎么产生的？]]></description>
      <guid>https://stats.stackexchange.com/questions/647158/standard-error-and-confidence-intervals</guid>
      <pubDate>Mon, 13 May 2024 17:02:53 GMT</pubDate>
    </item>
    <item>
      <title>批次不同重复次数的均值标准误差</title>
      <link>https://stats.stackexchange.com/questions/647156/standard-error-of-mean-with-varying-replicates-for-batches</link>
      <description><![CDATA[我进行了三批模拟，并从中计算出特定的属性（对于问题而言并不重要）。我想计算这三个批次的组合 SEM
批量| #样本|平均 |标准差|标准错误
B1 | n1 | x1 | sd1 |硒1
B2 | n2| x2 | SD2 |硒2
B3 | n3 | x3 | SD3 |硒3
我的做法如下
SE_combined = $\sqrt{\frac{(n1-1)se1^2 + (n2-1)se2^2 + (n3-1)se3^2}{n1+n2 +n3-3}}$
这是正确的方法吗？另外，我需要一些论文/书籍参考以供引用。任何帮助都会非常有帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/647156/standard-error-of-mean-with-varying-replicates-for-batches</guid>
      <pubDate>Mon, 13 May 2024 16:39:59 GMT</pubDate>
    </item>
    <item>
      <title>序列相关性如何使 OLS 保持无偏（即使在横截面数据中）</title>
      <link>https://stats.stackexchange.com/questions/647155/how-does-serial-correlation-cause-ols-to-remain-unbiased-even-in-cross-section</link>
      <description><![CDATA[为了使 OLS 保持无偏，给定回归量的错误的条件期望必须为零，$E(u_i |x_i )=0$。&lt; /p&gt;
但是，如果我们在误差项中具有序列相关性，这是否不会使误差产生偏差，从而使误差的条件期望不再为零？
例如，如果错误存在序列相关性，那么我们可以拟合方程 $u_i = \phi_i * u_j + \epsilon_i $，则不会这意味着 $u_i$ 现在偏向于具有非零条件均值（因为 $\epsilon_i $ 是 i.i.d)？
例如，如果我们固定了 $x_i$，则更改 $u_j$ 会影响 &lt; span class=&quot;math-container&quot;&gt;$u_i$ 给定 $x_i$？
如果序列相关性被破坏，这是否会违反 OLS 的无偏性？]]></description>
      <guid>https://stats.stackexchange.com/questions/647155/how-does-serial-correlation-cause-ols-to-remain-unbiased-even-in-cross-section</guid>
      <pubDate>Mon, 13 May 2024 16:35:04 GMT</pubDate>
    </item>
    <item>
      <title>A/B 测试与（一阶）随机优势测试之间的关系</title>
      <link>https://stats.stackexchange.com/questions/647153/relationship-between-a-b-testing-and-testing-for-first-order-stochastic-domina</link>
      <description><![CDATA[A/B 测试 https://en.m.wikipedia.org/wiki /A/B_testing A/B_testing 和随机优势，例如一阶随机优势 https://en.m.wikipedia.org/wiki/Stochastic_dominance？我很难在网上找到任何明确的联系。]]></description>
      <guid>https://stats.stackexchange.com/questions/647153/relationship-between-a-b-testing-and-testing-for-first-order-stochastic-domina</guid>
      <pubDate>Mon, 13 May 2024 16:26:20 GMT</pubDate>
    </item>
    <item>
      <title>r 中 plm 对象的 HAC</title>
      <link>https://stats.stackexchange.com/questions/647152/hac-for-plm-object-in-r</link>
      <description><![CDATA[我想估计一个固定效应模型（具有国家和年份固定效应）并另外应用 HAC 标准误差。虽然在 r 中运行以下代码后没有收到任何错误消息，但我不确定是否真的收到了 HAC 标准错误。有人可以确认一下吗？特别是，如果我将 HAC3 更改为 HC3 或完全删除选项 vcovHAC 等，我会得到完全相同的标准错误。
fe1 &lt;- plm( log(DEB) ~ log(IMP),
                   模型=“内”，
                   数据=数据，
                   索引 = c(“国家”,“年份”),
                   效果=“双向”）

fe2 &lt;- plm( log(DEB) ~ log(IMP),
                   模型=“内”，
                   数据=数据，
                   索引 = c(“国家”,“年份”),
                   效果=“双向”，
                   vcovHAC =“HAC3”）

fe3 &lt;- plm( log(DEB) ~ log(IMP),
                   模型=“内”，
                   数据=数据，
                   索引 = c(“国家”,“年份”),
                   效果=“双向”，
                   vcovHC＝“HC3”)
]]></description>
      <guid>https://stats.stackexchange.com/questions/647152/hac-for-plm-object-in-r</guid>
      <pubDate>Mon, 13 May 2024 16:24:08 GMT</pubDate>
    </item>
    <item>
      <title>$R^2$ 与预测值与观测值的回归斜率一致而产生的等式</title>
      <link>https://stats.stackexchange.com/questions/647151/equality-arising-from-coinciding-of-r2-with-slope-of-regression-of-predicted</link>
      <description><![CDATA[如果我能够正确解释这一点，那么在 观测值和预测值之间的回归斜率是否始终等于原始值的 $R^2$模型？ 已证明，与 $R^2_{XY}$ 测量之间存在相等性=&quot;math-container&quot;&gt;$Y = \alpha_{XY} + \beta_{XY} X + \varepsilon_{XY}$，估计值 $\widehat回归方程中斜率的 {\beta}_{Y\widehat{Y}}$ $\widehat{Y} = \alpha_{Y\widehat{Y }} + \beta_{Y\widehat{Y}}Y + \varepsilon_{Y\widehat{Y}}$，其中 $\widehat{Y}$&lt; /span&gt; 是基于第一个回归方程的 $Y$ 的预测。
鉴于 $\widehat{\beta}_{Y\widehat{Y}}^2$ 形式也存在等式
$$
\widehat{\beta}_{Y\widehat{Y}}^2 = \rho_{Y\widehat{Y}}^2\left(\frac{s_\widehat{Y}}{s_Y}\right)^ 2 = R_{XY}^2\left(\frac{s_\widehat{Y}}{s_Y}\right)^2
$$
那么这是否总是意味着
$$
\widehat{\beta}_{Y\widehat{Y}} = \left(\frac{s_\widehat{Y}}{s_Y}\right)^2\,?
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/647151/equality-arising-from-coinciding-of-r2-with-slope-of-regression-of-predicted</guid>
      <pubDate>Mon, 13 May 2024 16:14:42 GMT</pubDate>
    </item>
    <item>
      <title>如何将时间整合到我的隐式反馈数据集中？</title>
      <link>https://stats.stackexchange.com/questions/647150/how-can-i-integrate-time-in-my-implicit-feedback-dataset</link>
      <description><![CDATA[我正在开发一个基于协作过滤的推荐系统。具体来说，我一直在研究 NCF（神经协同过滤）和 SAR（简单推荐算法）等模型，我发现这些模型中的大多数都利用时间数据来做出更好的预测。例如，SAR 对交互应用时间衰减函数，对最近的交互给予比旧交互更大的权重。事实上，许多玩具示例都使用 MovieLens 数据集，其中有一个方便放置的时间戳列。
对于我的特定任务，我有时间信息，但我看不到任何使用它进行建模的方法。用户服务隐式反馈矩阵是通过查询交互数据库、按 userID 和 serviceID 分组并计算行数来构建的：这告诉我该用户有多少次已请求该服务（这被视为我们的隐式评级）。但是，用户X可以在$Z$时间请求服务$Y$ ，再次在时间 $W$ 处，然后在时间 $S$ 处，依此类推。因此，时间信息是丢失的。一个用户可以多次请求多项服务，而一项服务也可以被多个用户多次请求。
我想到了几种解决这个问题的策略：

我可以将交互分组到时间段中，而不是汇总所有历史记录。例如，如果我决定按季度分组，最终会得到  rating_Q1 、  rating_Q2  等。
由于我可以访问每日粒度的所有历史数据，并且我已经对许多可用服务执行了季节性分析，因此我考虑添加功能来捕获季节性趋势，但我不知道如何这样做:)

有人知道吗？谢谢:)]]></description>
      <guid>https://stats.stackexchange.com/questions/647150/how-can-i-integrate-time-in-my-implicit-feedback-dataset</guid>
      <pubDate>Mon, 13 May 2024 16:02:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 emtrends 为不同组提供相同的 SE 值</title>
      <link>https://stats.stackexchange.com/questions/647147/identical-se-values-for-different-groups-using-emtrends</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647147/identical-se-values-for-different-groups-using-emtrends</guid>
      <pubDate>Mon, 13 May 2024 14:49:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么 1/SE 或 1/方差通常用作回归中的权重？</title>
      <link>https://stats.stackexchange.com/questions/647146/why-are-1-se-or-1-variance-commonly-used-as-weights-in-regressions</link>
      <description><![CDATA[我第一次尝试进行荟萃分析，将简单实验处理的测量结果与多个物种的对照进行比较。我首先将混合效应模型拟合到从一组已发表的研究中收集的平均值。这工作得很好，但它当然忽略了一个事实，即平均值是用不同的精度级别估计的。听起来这是一个应该通过适当加权手段来解决的问题。其中几项研究发布了标准误差或其原始数据，因此我可以使用 SE 进行加权。
我的问题是：1/SE（或 1/ σ2）有什么特别之处？为什么不使用 2/SE、10/SE 或任何其他此类加权因子？
我很想问这个问题，因为由于一些研究使用了极其精确的仪器，SE 相差几乎两个数量级。精度越高显然越好，但对我来说，这些精确估计值与 100 次精确估计值相比并不明显。 （在拟合模型时，加权还引入了一些算法问题，但这可能是可以解决的，我对概念论证更感兴趣）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647146/why-are-1-se-or-1-variance-commonly-used-as-weights-in-regressions</guid>
      <pubDate>Mon, 13 May 2024 14:37:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 emtrends 为不同组提供相同的 SE 值</title>
      <link>https://stats.stackexchange.com/questions/647164/identical-se-values-for-different-groups-using-emtrends</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647164/identical-se-values-for-different-groups-using-emtrends</guid>
      <pubDate>Mon, 13 May 2024 14:24:53 GMT</pubDate>
    </item>
    <item>
      <title>集群 SE 与固定中的 0 单元进行跨级交互的行为</title>
      <link>https://stats.stackexchange.com/questions/647143/behavior-of-clustered-ses-for-cross-level-interaction-with-a-0-cell-in-fixest</link>
      <description><![CDATA[我在 R 中使用fixst 来进行具有聚类 SE 的固定效应逻辑回归。我无法分享我的数据，但希望我能很好地解释这个问题。我有 11 个聚类，每个聚类有 29 到 493 个观测值，这些观测值分为基线时间点和后续时间点（称为时间）。
我估计了时间与具有4个级别的簇级因子变量（称为组）之间的跨级别交互作用，因此有3个交互项。对于第二级组，随访时所有结果值均相同。我注意到，对于与时间对应的交互项，使用聚类时 SE 很小，p 值非常小。
m2 = feglm(y ~ time * L2var | group, data = set1, family = “二项式”)
概要(m2)

&gt;概要(m2)
GLM 估计，族 = 二项式，Dep。各不相同
观察次数：1,497
固定效果：站点：11
标准错误：集群（组）
                                         估计标准。误差z值Pr(&gt;|z|)
时间跟进 1.373515 0.342168 4.014151 0.00005966 ***
时间跟进：组1 0.743281 0.778241 0.955078 0.33953814
时间跟进：group2 14.310706 0.342168 41.823604 &lt; 2.2e-16***
时间跟进：组3 0.165190 0.561198 0.294353 0.76848817
...由于共线性，删除了 3 个变量（组 1、组 2 和组 3）
---
西尼夫。代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1&#39;&#39;1
对数似然：-770.6 调整后伪 R2：0.115961
           BIC: 1,650.8 平方 Cor.: 0.138072

如果我通过指定 vcov = “iid” 来删除聚类，则 SE 和 p 值会很大，这就是我在单元格为 0 时所看到的情况。
&lt;前&gt;&lt;代码&gt;&gt;摘要（m2，vcov =“iid”）
GLM 估计，族 = 二项式，Dep。各不相同
观察次数：1,497
固定效果：站点：11
标准错误：IID
                                         估计标准。误差z值Pr(&gt;|z|)
时间随访 1.373515 0.168833 8.135366 4.1070e-16 ***
时间跟进：group1 0.743281 0.784142 0.947891 3.4318e-01
时间跟进：group2 14.310706 359.444491 0.039813 9.6824e-01
时间跟进：组3 0.165190 0.320735 0.515036 6.0653e-01
...由于共线性，删除了 3 个变量（组 1、组 2 和组 3）
---
西尼夫。代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1&#39;&#39;1
对数似然：-770.6 调整后伪 R2：0.115961
           BIC: 1,650.8 平方 Cor.: 0.138072

我的问题是：集群 SE 出现的小 SE 和 p 值是预期的，还是我做错了什么？如果是预期的，有人可以提供直观的解释吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647143/behavior-of-clustered-ses-for-cross-level-interaction-with-a-0-cell-in-fixest</guid>
      <pubDate>Mon, 13 May 2024 13:27:21 GMT</pubDate>
    </item>
    <item>
      <title>方差分析还是稳健分析？</title>
      <link>https://stats.stackexchange.com/questions/647137/ancova-or-moderation</link>
      <description><![CDATA[我正在努力处理一个问题的统计数据，我正在收集数据来回答。
我的论文是关于在控制生活意义时不同的冥想类型是否可以增加幸福感。冥想分为三个组，一组为对照组。在冥想干预之前和之后测量幸福感。生命的意义是我的协变量，在干预前测量一次。每个参与者被随机分配到一个组（3 个冥想条件，一个对照组）。
我想知道：

控制 MIL 时，冥想会增加幸福感吗？
控制 MIL 时，每次冥想增加幸福感的顺序是什么 - 影响最大的顺序（第 1、2、3 组，然后是对照组）？
对于不同级别的 MIL，哪种冥想对于增加幸福感最有效？

我知道我可以通过混合设计（主题因素内和主题因素之间）ANCOVA 来回答 1 和 2，并通过后续事后测试来测试问题 2。
但是，#3 也可以通过此 ANCOVA 分析来回答吗？或者#3 是否需要调节回归？我认为这需要适度的回归；然而，我在制定如何将幸福感的变化纳入调节回归模型时遇到了困难。这是因为我已经了解了使用变化分数的缺点以及如何在 ANCOVA 中使用 time_1 作为 CV 更可取。
关于#3，我希望发现群体与幸福感增加之间的关系会随着不同 MIL 水平的变化而变化。
这一切绝对让我头晕目眩，我希望得到一些帮助！希望这里的一切都清楚！]]></description>
      <guid>https://stats.stackexchange.com/questions/647137/ancova-or-moderation</guid>
      <pubDate>Mon, 13 May 2024 12:36:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在lme4中建模对照实验（三个时间点，两组）？</title>
      <link>https://stats.stackexchange.com/questions/647136/how-to-model-a-controlled-experiment-three-time-points-two-groups-in-lme4</link>
      <description><![CDATA[我们使用以下变量进行了行为改变现场实验：

三个时间点（T0、T1、T2）
两组（干预组与对照组）
个人 ID
工作室 ID

干预措施是在不同的小组、研讨会中进行的，使用 R 中的 lme4 包。我们计划将 T1 和 T2 的组间差异（由于样本量小/退出而分开）与 T0 进行比较分数作为协变量和两个随机截距。我们对所有 DV 进行了子选择 T1 行并添加了 T0 列。
例如：
model_1_post_self_efficacy &lt;- lmer(self_efficacy ~ T0_self_efficacy + group + (1 | individual_ID) +(1 | Workshop_ID), data = data_T1_baseline)

这不起作用，因为每个 individual_ID 只有一行。当我们使用由 T0 和 T1 行以及 T0 协变量列组成的数据集时，它确实有效。然而，从概念上讲，以 T0_DV 作为协变量来预测 T0 和 T1 之间的 DV 似乎很奇怪。
或者，没有协变量的模型，而是时间 * 组交互 + individual_ID + Workshop_ID 作为随机截距）也可以工作。
model_4_post_self_efficacy &lt;- lmer(self_efficacy ~ 时间 * 组 + (1 | 工作室_ID) + (1 | 个人_ID), data = data_T1_T0)

我的问题是：

有没有办法合理地将协变量和个体随机效应结合起来
我们如何最好地决定该做什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/647136/how-to-model-a-controlled-experiment-three-time-points-two-groups-in-lme4</guid>
      <pubDate>Mon, 13 May 2024 11:12:58 GMT</pubDate>
    </item>
    <item>
      <title>我可以在softmax之前使用Tanh吗？</title>
      <link>https://stats.stackexchange.com/questions/647119/can-i-use-tanh-before-softmax</link>
      <description><![CDATA[我正在研究使用神经网络进行金融数据的二元分类任务。输出结果是二维的，如[[0.5,0.5],[0.1,09]]。在只有2000个小样本的情况下，我发现训练非常困难，经常遇到损失和准确率不下降的情况。然而，当我在输出层的softmax之前添加Tanh时，结果表现得非常好。为什么会出现这种情况？
我问了GPT4，它告诉我这样做会限制基本模型的输出，而且由于输出是对称的，这可能对不稳定的模型有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/647119/can-i-use-tanh-before-softmax</guid>
      <pubDate>Mon, 13 May 2024 03:52:51 GMT</pubDate>
    </item>
    </channel>
</rss>