<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 11 Dec 2024 21:16:58 GMT</lastBuildDate>
    <item>
      <title>是否存在计算边际效应的标准方法？</title>
      <link>https://stats.stackexchange.com/questions/658594/is-there-a-standard-way-to-calculate-marginal-effects</link>
      <description><![CDATA[我的问题是关于在计算回归模型的边际效应时如何设置其他预测变量的值。
我有一个 GAM 回归模型（响应在 0 和 1 之间连续）：
$$ g(\mathbb{E}[Y_i]) = \beta_0 + f_1(t_i, x1_i) + f_2(t_i, x2_i) $$

$g(\cdot)$ 是 logit 链接函数 $g(p) = \log(\frac{p}{1-p})$
$Y_i$ 是 Beta 分布：$Y_i \sim \text{Beta}(\alpha, \beta) $
$\beta_0$ 是截距
$f_1$ 和 $f_2$ 是以下相互作用的平滑函数：($t$ 和 $x_1$)
和 ($t$ 和 $x_2$)

以下是该模型的 R 代码：
# 请注意，te() 函数应该包含主效应和相互作用效果：https://stats.stackexchange.com/questions/658558/gam-regression-interactions-vs-main-effects

library(mgcv)

set.seed(123)

n &lt;- 500
t &lt;- seq(0, 365, length.out = n) 
x1 &lt;- rnorm(n, mean = 100, sd = 10) 
x2 &lt;- rpois(n, lambda = 2) 

true_mean &lt;- function(t, x1, x2) {
base &lt;- 0.4 
x1_effect &lt;- 0.003 * x1 * exp(-t/200) 
x2_effect &lt;- 0.05 * x2 * (1 - exp(-t/200)) 
time_effect &lt;- 0.1 * sin(2 * pi * t/365) 
return(base + x1_effect + x2_effect + time_effect)
}

y_mean &lt;- true_mean(t, x1, x2)
y &lt;- 100 * plogis(qlogis(y_mean) + rnorm(n, 0, 0.3)) 

sim_data &lt;- data.frame(
y = y,
t = t,
x1 = x1,
x2 = x2
)

epsilon &lt;- 0.001 
sim_data$y_scaled &lt;- (sim_data$y * (1 - 2 * epsilon) + epsilon) / 100

gam_model &lt;- gam(
y_scaled ~ te(t, x1) + te(t, x2),
data = sim_data,
family = betar(link = &quot;logit&quot;),
method = &quot;REML&quot;
)

我的主要兴趣是研究$X_1$对$Y$的影响以及$X_2$对不同时间段的$Y$的影响。例如在时间 = 5 时，$X_1$ 中 1 个单位的变化是否对响应 $Y$ 产生了更大的变化 - 或者 $X_2$ 中 1 个单位的变化是否对响应 $Y$ 产生了更大的变化？
我目前对边际效应 (ME) 的理解如下：

从模型开始：
$$ g(\mathbb{E}[Y_i]) = \beta_0 + f_1(t_i, x1_i) + f_2(t_i, x2_i) $$
我在时间点观察我的数据 $t* = (t_1, t_2, ... t_n)$.我感兴趣的是计算这些 $n$ 个观察时间点的边际效应。
在保持其他变量的均值不变（即 $\bar{X_1}, \bar{X_2}$）的情况下，$t^*$ 特定值的边际效应为：
$$ \text{ME of } x_1: \quad \left.\frac{\partial \mathbb{E}[Y_i]}{\partial x1}\right|_{x1=x1^*, t=t^*, x2=\bar{x2}} = \left.\frac{\partial g^{-1}(\beta_0 + f_1(t,x1) + f_2(t,\bar{x2}))}{\partial x1}\right|_{x_1=\bar{x_1}, x_2=\bar{x_2} , t=t^*} $$
$$ \text{ME of } x_2: \quad \left.\frac{\partial \mathbb{E}[Y_i]}{\partial x2}\right|_{x2=x2^*, t=t^*, x1=\bar{x1}} = \left.\frac{\partial g^{-1}(\beta_0 + f_1(t,\bar{x1}) + f_2(t,x2))}{\partial x2}\right|_{x_1=\bar{x_1}, x_2=\bar{x_2} , t=t^*}$$

我只是想知道以下问题。计算 $X_1$ 的边际效应：

在每个时间点，为什么我们不使用当时 $X_2$ 的实际观测值，而是使用 $X_2$ 的平均值？
此外，为什么我们要取当时 $X_1$ 的平均值，而不是当时 $X_1$ 的实际观测值？

对于 $X_1$ 的边际效应，我认为在每个时间点 $t_i$ 计算$(t_i, x_{1i}, x_{2i})$ 处的边际效应。但我们显然不会这样做。
这有什么原因吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658594/is-there-a-standard-way-to-calculate-marginal-effects</guid>
      <pubDate>Wed, 11 Dec 2024 21:11:19 GMT</pubDate>
    </item>
    <item>
      <title>如何对两组潜在变量进行 t 检验并比较它们的均值？</title>
      <link>https://stats.stackexchange.com/questions/658587/how-do-i-perform-a-t-test-for-latent-variables-in-two-groups-and-compare-their-m</link>
      <description><![CDATA[我正在尝试对两组潜在变量进行 t 检验。但是，我不确定这是否是合适的方法。
# 加载必要的包（如果尚未加载）
library(readxl)
library(lavaan)
library(semTools)
library(psych)

# 读取数据（根据需要调整文件名和路径）
data &lt;- read_excel(&quot;newpost.xlsx&quot;)

names(data) &lt;- gsub(&quot; &quot;, &quot;_&quot;, names(data))

data$intelligence_score &lt;- rowMeans(data[, c(&quot;intelligent_1&quot;, 
&quot;intelligent_2&quot;, 
&quot;intelligent_3&quot;, 
&quot;intelligent_5&quot;,
&quot;intelligent_6&quot;)],
na.rm = TRUE)

数据$translationgroup &lt;- factor(data$translationgroup, levels = c(0,1), labels = c(&quot;Low_tranlation&quot;, &quot;High_tranlation&quot;))

# 对翻译组的 intelligence_score 执行双样本 t 检验
t_test_result &lt;- t.test(intelligence_score ~ Translationgroup, data = data)

# 打印结果
print(t_test_result)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/658587/how-do-i-perform-a-t-test-for-latent-variables-in-two-groups-and-compare-their-m</guid>
      <pubDate>Wed, 11 Dec 2024 19:21:07 GMT</pubDate>
    </item>
    <item>
      <title>岭回归的闭式解可以用于训练神经网络吗？</title>
      <link>https://stats.stackexchange.com/questions/658585/can-the-closed-form-solution-for-ridge-regression-be-used-in-training-neural-net</link>
      <description><![CDATA[是否确定岭回归的闭式解可用于神经网络训练？如果可以：

使用它的潜在好处是什么？

在什么情况下这种方法特别有用？


我想了解这种技术在神经网络训练中是否有实际应用，或者它是否主要具有理论意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/658585/can-the-closed-form-solution-for-ridge-regression-be-used-in-training-neural-net</guid>
      <pubDate>Wed, 11 Dec 2024 19:18:34 GMT</pubDate>
    </item>
    <item>
      <title>关于 $X^TX$ 的协方差矩阵</title>
      <link>https://stats.stackexchange.com/questions/658584/covariance-matrix-in-terms-of-xtx</link>
      <description><![CDATA[如果我有一个矩阵 $X\in \mathbb{R}^{n\times p}$，那么我可以将协方差写为
$$\text{Cov}(X) = \mathbb{E}[(X-\mu_X)(X-\mu_X)^T]$$
现在，假设数据已居中，则变为 $\text{Cov}(X) = \mathbb{E}[XX^T]$。我见过帖子说协方差是$XX^T$，而其他人提到$X^TX$是协方差。我不太明白这两个是如何得出的。]]></description>
      <guid>https://stats.stackexchange.com/questions/658584/covariance-matrix-in-terms-of-xtx</guid>
      <pubDate>Wed, 11 Dec 2024 18:10:08 GMT</pubDate>
    </item>
    <item>
      <title>依赖于其他回归模型输出的回归模型</title>
      <link>https://stats.stackexchange.com/questions/658581/regression-models-that-depend-on-outputs-of-other-regression-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658581/regression-models-that-depend-on-outputs-of-other-regression-models</guid>
      <pubDate>Wed, 11 Dec 2024 17:19:36 GMT</pubDate>
    </item>
    <item>
      <title>如何在我的受污染数据问题中找到具有 ML 组件的去偏估计量？</title>
      <link>https://stats.stackexchange.com/questions/658578/how-to-find-a-de-biased-estimator-with-a-ml-component-in-my-contaminated-data-pr</link>
      <description><![CDATA[我试图使用机器学习模型的输出来估计（使用最大似然法）分布中的参数。我得到的估计量的偏差比参数值大得多。我想使用 Neyman 正交性/双机器学习方法（Chernozhukov et al., 2018）、影响函数或任何相关（或不相关）方法找到一个去偏估计量。但我不清楚如何在我的情况下构建去偏估计量。
我的估计问题
我已经“污染”了数据：大多数数据来自概率分布$P_0(x)$，但部分数据来自不同的分布$P_1(x)$（“污染”）。因此，我假设我的数据点是从分布$$P(x) = (1-\theta) P_0(x) + \theta P_1(x).$$中独立同分布抽取的。我的目标是找出受污染数据的比例$\theta$。 $\theta$ 的最大似然估计量是 $$0 = \frac{1}{n}\sum_i\frac{r(x_i)-1}{1+\hat{\theta}\bigl(r(x_i)-1\bigr)},$$ 的解，其中 $x_1,\ldots,x_n$ 是数据点，$r(x) = \frac{P_1(x)}{P_0(x)}$。
我不知道概率分布 $P_0(x)、P_1(x)$ 或它们的比率 $r(x)$直接，但我确实有另一个标记为数据集 $(\tilde{x}_i, y_i)$ 的数据点，其生成分布是已知的：对于从 $P_0$ 中抽取的点，$y_i=0$ ；对于从 $P_1$ 中抽取的点，$y_i=1$ ：$$Prob(\tilde{x}_i | y_i) = P_{y_i} (\tilde{x}_i)$$ （为简单起见，假设我有相同数量的 $\tilde{x}_i$，其中 $\tilde{x}_i$ class=&quot;math-container&quot;&gt;$y=0$ 和 $y=1$)。因此，我尝试通过两个步骤估计 $\theta$：

在标记数据集上训练 ML 分类器 $f(x)$ 以估计 $Prob(y=1|x)$，从而获得概率比的估计值为：$\hat{r}(x) = \frac{f(x)}{1-f(x)}$。

将此 $\hat{r}$ 代入 MLE 方程，得出 $$0 = \frac{1}{n}\sum_i\frac{\hat{r}(x_i)-1}{1+\hat{\theta}\bigl(\hat{r}(x_i)-1\bigr)},$$ 并求解 $\hat{\theta}$。


请注意，用于 MLE 估计（步骤 2）的数据集与用于训练 ML 模型（步骤 1）的数据不同且独立。
我的问题
$\hat{r}$ 是一个有偏估计量，例如在双重机器学习文献中讨论过（参见上面的链接）。因此，我得到了 $\theta$ 的有偏估计量。在我的案例中，我感兴趣的是 $\theta$ 的值远小于此偏差。因此，我想找到 $\theta$ 的去偏估计量。但我对如何将双重机器学习方法或影响函数应用于我的案例感到困惑。
在我的案例中，Neyman 正交 MLE 方程是什么？我如何使用我拥有的信息来找到污染分数 $\theta$ 的去偏估计量？]]></description>
      <guid>https://stats.stackexchange.com/questions/658578/how-to-find-a-de-biased-estimator-with-a-ml-component-in-my-contaminated-data-pr</guid>
      <pubDate>Wed, 11 Dec 2024 15:48:04 GMT</pubDate>
    </item>
    <item>
      <title>如何用不准确的评估器计算置信区间？</title>
      <link>https://stats.stackexchange.com/questions/658562/how-to-compute-a-confidence-interval-with-an-inaccurate-evaluator</link>
      <description><![CDATA[让我们考虑以下针对 LLM 的提示：

系统提示：您是 Python 语言专家。您的角色是回答任何与 Python 相关的问题。
用户提示：&lt;用户查询&gt;

我想测试此系统提示以检查它是否正确回答了用户的问题。为此，我创建了一个问题数据集：

sqrt 函数在哪个模块中？
我可以使用哪个函数来降低字符串的字符数？
...

此数据集包含 5421 个问题。我已将此数据集提供给我的 LLM，并得到了 5421 个答案。我已审查了其中的 43 个，并使用 PASS/FAIL 评估对每个答案进行了评估。如果答案正确回答了用户的问题，则该答案被视为 PASS。在这 43 个答案中，我发现了 24 个 PASS 答案。
我现在希望另一个 LLM 评估这个系统提示。为此，我创建了一个 LLM-as-a-judge 作为评估者。这个 LLM-as-a-judge 的角色是执行我对 43 个答案所做的相同任务：使用 PASS/FAIL 评估来评估每个答案。
我向 LLM-as-a-judge 提供了我已经评估过的 43 个问题/答案。我发现这位评委 79% 的时间都同意我的观点。
然后，我向 LLM-as-a-judge 提供了我的数据集中的所有 5421 个问题/答案。 LLM-as-a-judge 对系统提示的评分为 87.12%（意味着系统提示的 87.12% 的答案被评估为 PASS）。
现在，由于 LLM-as-a-judge 的准确率为 79%（意味着它并不总是像我一样评估），我想知道我会给整个数据集打多少分（知道评委给出了 87.12% 的分数）。
我如何计算这个分数？是否有可能确定 87.12% 左右的置信区间？
注意：我是统计学新手，如果这个问题之前已经回答过，我很抱歉。我发现很难理解一些现有的问题和答案。请保持您的答案简单明了。]]></description>
      <guid>https://stats.stackexchange.com/questions/658562/how-to-compute-a-confidence-interval-with-an-inaccurate-evaluator</guid>
      <pubDate>Wed, 11 Dec 2024 08:23:24 GMT</pubDate>
    </item>
    <item>
      <title>多项式协方差矩阵是奇异的吗？</title>
      <link>https://stats.stackexchange.com/questions/658533/multinomial-covariance-matrix-is-singular</link>
      <description><![CDATA[考虑一个多项分布，$\text{multinom}\left(n, \left(p_1,\dots, p_k\right)\right)$。有一个$k\times k$协方差矩阵，$\Sigma$，它取决于多项分布的参数。 对角线入口 $\Sigma_{i,j} = np_i(1 - p_i)$，非对角线入口 $i, j$ 等于 $-np_ip_j$。
到目前为止，一切顺利。让我们用这个想法做一些计算。
multinomial_sigma &lt;- function(n, p){

k &lt;- length(p)

cov_np &lt;- matrix(NA, k, k)
for (i in 1:k){
for (j in 1:k){

if (i == j){
cov_np[i, j] &lt;- n * p[i] * (1 - p[j])
}
if (i != j) {
cov_np[i, j] &lt;- -n * p[i] * p[j]
}
}
}
return(cov_np)
}

s &lt;- multinomial_sigma(1, c(0.5, 0.25, 0.25))
det(s)

我得到行列式为零，因此协方差矩阵是奇异的。无论我传入什么参数，我都会得到一个奇异协方差矩阵。
set.seed(2024)
R &lt;- 100
dets &lt;- rep(NA, R)
for (i in 1:R){
k &lt;- sample(seq(3, 7, 1), 1)
n &lt;- sample(seq(1, 10, 1), 1)
p &lt;- runif(k, 0, 1); p &lt;- p/sum(p)
s &lt;- multinomial_sigma(n, p)
dets[i] &lt;- det(s)
}
summary(dets) # 全部在 10^-15 或 10^-16 的量级上，因此基本上是奇异的

我没有在我的实现代码中看到错误，那么从统计学上讲，给出这些奇异协方差矩阵是否发生了一些有趣的事情？]]></description>
      <guid>https://stats.stackexchange.com/questions/658533/multinomial-covariance-matrix-is-singular</guid>
      <pubDate>Tue, 10 Dec 2024 16:15:42 GMT</pubDate>
    </item>
    <item>
      <title>如何排列 p 值？</title>
      <link>https://stats.stackexchange.com/questions/658523/how-to-permute-p-values</link>
      <description><![CDATA[最近，我的同事在处理一个数据集 df_a 时遇到了一个问题，该数据集包含基因数据。每一行代表一个 基因（通常有数千个，但为了简单起见，我们假设有 1,000 个），列代表不同的样本，这些样本可以分为两组，A 和 B（每组 50 个样本）。
我们使用 t.test 计算每行的 p 值并进行校正。假设我们使用 p.adjust &lt; 0.05 并且得到 30 个阳性结果。
这带来了一个问题：我们如何确保这 30 个结果不是由随机事件产生的？（也许这个问题是一个问题？）
我们设计了一个使用置换检验的流程来解决这个问题。步骤如下：
(1) 对于 df_a，我们随机打乱其列标签，重新计算每行的 p 值和 p.adjust，并计算 p.adjust &lt; 0.05 的行数，记为 Ki。
(2) 重复步骤 1 1,000 次，得到 K1,K2,K3,...,K1000。
(3) 计算大于 30 的 Ki 的数量，记为 n。计算 n/1000。如果该值小于 0.05，我们认为这 30 个结果不是由随机事件产生的。
作为一名程序员，我意识到这在数学上似乎存在问题，但我无法向同事提供严谨的证明来纠正它。希望得到您的帮助。
更新
我想更新的是，我认为这种排列不能提供有意义的附加信息。考虑一下当您对列标签进行混洗时，对于每一行，这相当于将组 A 和 B 混合在一起，然后随机抽取两组 A* 和 B*。基本的统计学原理告诉我们，这两组之间应该没有差异。因此，当您应用 t.test 时，所有 p.values &lt; 0.05 都是假阳性，显著性数字约为 5%。当你对这些数据应用p.adjust（例如使用FDR），并再次控制p.adjust &lt; 0.05时，这里的Ki会非常小（接近于0），以至于不可能否定任何结果。
我不是数学家，但通过程序模拟很容易看出这一点。我的观点是，当排列数是有限的（例如：1000）时，Ki的数学期望是一个与数据行相关的常数，并且这个值非常小。
我不知道这在数学上是否成立，以及如何证明它。]]></description>
      <guid>https://stats.stackexchange.com/questions/658523/how-to-permute-p-values</guid>
      <pubDate>Tue, 10 Dec 2024 14:31:46 GMT</pubDate>
    </item>
    <item>
      <title>关于赫斯特指数定义和持久性属性的澄清</title>
      <link>https://stats.stackexchange.com/questions/658520/clarifications-on-hurst-exponent-definitions-and-persistence-properties</link>
      <description><![CDATA[我对赫斯特指数有疑问，希望有人能帮我澄清一下。
众所周知，赫斯特指数有不同的定义，但找到这些定义之间的明确联系或关系似乎出奇地具有挑战性。我遇到过各种各样的解释，但我还没有找到一个全面的解释来说明这些不同的定义在实际应用中是如何一致或不同的。
此外，人们普遍认为：

对于$H&lt;0.5$，该过程表现出反持久性。
对于$H&gt;0.5$，该过程表现出持久性。

然而，虽然这种分类经常出现，但很少提供其背后的原因或更深层次的解释。
有人可以提供一些澄清，或者给我指出可靠的参考书目来解决：

赫斯特指数的各种定义之间的关系。
清楚地解释为什么$H&lt;0.5$对应于反持久性，而$H&gt;0.5$对应于持久性。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658520/clarifications-on-hurst-exponent-definitions-and-persistence-properties</guid>
      <pubDate>Mon, 09 Dec 2024 09:22:40 GMT</pubDate>
    </item>
    <item>
      <title>带有 Adam 优化器网络的单层/单单元如何工作？</title>
      <link>https://stats.stackexchange.com/questions/658436/how-does-a-single-layer-single-unit-with-adam-optimizer-network-work</link>
      <description><![CDATA[我对 ML 还很陌生，正在尝试使用线性回归。我测试了 sklearn 的 LinearRegression 模型，然后想将结果与一个非常简单的神经网络进行比较。
我创建了一个具有 1 层和 1 个单元的 tensorflow Dense 网络，并带有“线性”激活函数。
我使用了“sgd”和“adam”优化器，并使用 MinMaxScaler 缩放了 x 数据
我得到了与 LinearRegression 模型截然不同的结果（预测和损失）。
我有两个问题：

具有线性激活的 1 层/1 个单元网络是否与 LinearRegression 相同？

SGD 预测非常接近，我正在用房价进行测试，所以我会得到相对接近的结果。目标值在 1000 左右，因此 y_train 数组中的 120,000 美元价格被设置为 120。但是，当我使用 Adam 优化器时，我得到的预测值非常低（不到 20）。我从 100 个 epoch 开始，然后增加到 1000 个，但仍然得到了类似的结果。我是不是在某个地方做错了什么，或者 Adam 优化器是否有限制或某些要求才能正常工作。

]]></description>
      <guid>https://stats.stackexchange.com/questions/658436/how-does-a-single-layer-single-unit-with-adam-optimizer-network-work</guid>
      <pubDate>Sun, 08 Dec 2024 03:47:10 GMT</pubDate>
    </item>
    <item>
      <title>帮助我将多元线性回归模型中的两个假设结合起来进行方差分析比较！</title>
      <link>https://stats.stackexchange.com/questions/657960/help-me-to-combine-two-hypotheses-in-a-multiple-linear-regression-model-for-anov</link>
      <description><![CDATA[我目前正在研究多元线性回归并使用股票市场数据进行实践。我的数据集包括：

因变量 (Y)：标准普尔 500 指数价格

自变量：

黄金价格 (X1)

铜价 (X2)

表现最佳的行业 (X3)：分类变量，编码如下：

XLK（技术）或 XLE（能源）= 1

所有其他行业 = 0


我有两个假设想要测试：

铜价 (X2) 与 XLK/XLE（X3=1）相互作用，但与其他行业不相互作用(X3=0)。
黄金价格 (X1) 与任何表现最佳的行业 (X3) 均无关联。

我想将这两个假设合并为一个模型，并使用 R 中的 anova(full_model, Reduced_model) 创建一个简化模型，以便与完整模型进行比较。但是，我不确定如何构建简化模型以反映这两个假设。
full_model &lt;- lm(SP500_Adj_Close ~ Gold_Price + Copper_Price + Performing_Sector_Dummy + 
Gold_Price:Performing_Sector_Dummy + Copper_Price:Performing_Sector_Dummy)

以上是我的完整模型。如果我错了，请纠正我。
您能帮我构建简化模型并指导我如何适当地测试这些假设吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657960/help-me-to-combine-two-hypotheses-in-a-multiple-linear-regression-model-for-anov</guid>
      <pubDate>Thu, 28 Nov 2024 01:08:11 GMT</pubDate>
    </item>
    <item>
      <title>对物理学家来说有效的逻辑分析吗？</title>
      <link>https://stats.stackexchange.com/questions/657647/valid-logistic-analysis-for-physicists</link>
      <description><![CDATA[我是一名物理学家，正在撰写一篇论文，该论文涉及蒙特卡罗引擎计算辐射场中击中目标的辐射量的结果。
有趣的是，虽然结果通常是准确的，但在某些情况下，结果会大相径庭。据我们所知，没有一个确切的参数集会导致错误，但有些参数集会使错误更有可能发生 --- 例如，将计算网格大小设置为更粗会导致这些错误更有可能发生，但这种情况并不总是发生，即使计算网格大小很细，也可能发生。
我现在有大约 20,000 个来自各种计算的数据点。对于每次计算，我都记录了大约 15 个不同输入参数的值。我稍微知道哪些与输出变量相关，即此计算与已知对几何正确的基准情况之间的计算辐射剂量差异，但许多我不确定它们会如何影响输出变量。我知道我的许多变量都是相关的。我敢打赌我的一些变量是多重共线性的。
该项目的最终目标是为在放射治疗领域使用这些计算提供粗略的经验法则 - 也就是说，让计划进行放射治疗的人可以遵循一些规则，例如“当目标这么大，或者离另一个东西这么近时，那么你必须像这样设置参数 Y 以降低误算的概率”。
为了获得这些，我试图从输入参数创建一个逻辑回归模型，这样我就可以说“当使用参数集 Y、Z、W 时，误算的几率小于 X”。
我不知道最好的解决方法。目前，我正尝试通过迭代计算 VIF 来消除多重共线性，然后删除具有最高 VIF 的解释变量，重复此过程，然后，一旦所有变量的 VIF 都低于 10，就对所有剩余的变量组合运行 BIC 以找到最简约的集合，然后通过使用该集合创建逻辑模型（当然是缩放和居中数据）来创建我的经验法则，然后根据我的逻辑模型检查参数空间的哪些区域具有最低概率。
但是，这个想法只是我从各种 CrossValidated 帖子和阅读教科书的片段中拼凑起来的。真的，我不知道最好的方法是什么。
对于不太了解统计学的物理学家来说，什么方法最能防错？获得我想要的最终结果（经验法则）的正确方法是什么？
我确实读过此处的帖子，该帖子与此相关，但并未明确给出前进的方向。我知道“进行统计分析的最佳方法”这一想法将极具争议，但我主要在寻找对我当前方法的批评、对统计学以外专业的人提出的防错方法的建议以及进一步的阅读。]]></description>
      <guid>https://stats.stackexchange.com/questions/657647/valid-logistic-analysis-for-physicists</guid>
      <pubDate>Thu, 21 Nov 2024 23:35:22 GMT</pubDate>
    </item>
    <item>
      <title>使用 Hausman-McFadden 检验结果解决不相关替代独立性 (IIA) 偏差的有效性</title>
      <link>https://stats.stackexchange.com/questions/657645/validity-of-using-hausman-mcfadden-test-results-for-addressing-departures-from-t</link>
      <description><![CDATA[上下文正在运行多项逻辑模型，主要目的是衡量案例特定变量 A 对多项结果 B 的影响。运行 Hausman-McFadden 检验显示完整模型与 B 的替代方案减少的每个模型有何不同（违反 IIA 的程度）。理想情况下，系数不会改变。
我的问题是，使用这些测试和比较来显示违反 IIA 的程度是否足够，同时论证在这些变化中持续存在的影响仍然有效？例如，在 5 个系数中，4 个没有变化或变化不大，但 1 个有变化，或者对于所有系数，方向在简化模型中没有变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/657645/validity-of-using-hausman-mcfadden-test-results-for-addressing-departures-from-t</guid>
      <pubDate>Thu, 21 Nov 2024 23:01:57 GMT</pubDate>
    </item>
    <item>
      <title>两个独立变量之差的方差是方差之和</title>
      <link>https://stats.stackexchange.com/questions/574806/variance-of-the-difference-of-two-independent-variables-is-the-sum-of-variances</link>
      <description><![CDATA[据说两个独立变量之差的方差是方差之和（主题 - 置信区间。两个均值。独立样本）
我尝试用两个变量的小数据集进行实验。我发现两个独立变量的方差之和不等于差异的方差。实验如下：-
纽约苹果价格 [$3.80, $3.76, $3.87, $3.99, $4.02, $4.25,$4.13, $3.98] 其方差 = 0.027
洛杉矶苹果价格 - [$3.02, $3.22, $3.24, $3.02, $3.06, $3.15, $3.81, $3.44]，方差 = 0.071
它们的价格差异 = [0.78, 0.54, 0.63, 0.97, 0.96, 1.10, 0.32, 0.54] - 方差 = 0.0715
LA 苹果价格方差与 NY 苹果价格方差之和 = 0.098，不等于差异方差 = 0.0715
有人能解释一下为什么会这样吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/574806/variance-of-the-difference-of-two-independent-variables-is-the-sum-of-variances</guid>
      <pubDate>Tue, 10 May 2022 22:23:01 GMT</pubDate>
    </item>
    </channel>
</rss>