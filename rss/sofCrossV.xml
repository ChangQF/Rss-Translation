<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 28 Aug 2024 12:30:58 GMT</lastBuildDate>
    <item>
      <title>交叉重复测量设计的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/653482/linear-mixed-model-for-crossed-repeated-measures-desing</link>
      <description><![CDATA[我正在尝试分析一个纵向实验心理学数据集。每个参与者都完成了一项任务，收集了他们对两种不同刺激（这里我称之为低和高）的反应时间。该任务有多个区块，每个参与者在多个年龄段接受评估。区块嵌套在年龄内，年龄和参与者交叉，每个参与者在所有年龄段接受评估，所有年龄段包含所有参与者的数据。以下是数据的简化子集，以显示一般结构。实际上我有更多区块，实际数据集包含 97 名参与者、20 个区块和 4 个年龄段。区块将被建模为连续的，并估计线性斜率，而年龄将被视为分类的，一个具有 4 个级别的因子。
 主题 刺激 区块 年龄 RT
&lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 10010 高 1 1 1136
2 10010 高 2 1 1111 
3 10010 高 3 1 1220 
4 10010 低 1 1 1224
5 10010 低 2 1 862 
6 10010 低 3 1 893 
7 10010 高 1 2 849 
8 10010 高 2 2 904 
9 10010 高 3 2 878 
10 10010 低 1 2 893 
11 10010 低 2 2 863 
12 10010 低 3 2 851 
13 10010 高 1 3 863 
14 10010 高 2 3 635 
15 10010 高 3 3 603 
16 10010 低 1 3 928
17 10010 低 2 3 606 
18 10010 低 3 3 568 
19 10010 高 1 4 623 
20 10010 高 2 4 538 
21 10010 高 3 4 544 
22 10010 低 1 4 610 
23 10010 低 2 4 670
24 10010 低 3 4 558

我们的主要问题是年龄如何影响刺激类型之间的 RT 差异。但是，我们希望控制基线 RT 和 RT 改进随年龄而产生的巨大差异。随着年龄的增长，基线 RT 变得更小，斜率变平（改进空间更小）。见下图。这是有道理的，也正是我们所期望的。

所以我认为固定效应结构是明确的，我们想要刺激 * 阻断 * 年龄，但我不确定最合适的随机效应结构是什么。 此问题描述了类似的情况，即不同气候模型（年龄）在不同时间（区块）和不同初始条件（主题）下的情况。Ben Bolker 对该问题的回答让我认为，我们案例中合适的模型是：
RT ~ Stimulus*Block*Age + (Stimulus*Block | 主题：年龄)

因此，我们将捕捉每个主题和每个年龄的截距和斜率差异，而无需为年龄设置单独的随机效应项，因为这与其固定效应是多余的。我的这个推理正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653482/linear-mixed-model-for-crossed-repeated-measures-desing</guid>
      <pubDate>Wed, 28 Aug 2024 12:24:15 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Optuna 优化中实现 TimeSeriesSplit</title>
      <link>https://stats.stackexchange.com/questions/653481/how-to-implement-timeseriessplit-in-a-optuna-optimization</link>
      <description><![CDATA[我目前遇到一个问题，希望在这里找到一个快速答案。
我想在 Optuna 超参数优化中为我的 XGBRegressor 执行 TimeSeriesSplit 交叉验证。
我想验证特定的验证数据，已定义为 dval。
提前感谢大家 :)
def objective(trial):

param = {&#39;max_depth&#39;: trial.suggest_int(&#39;max_depth&#39;, 1, 10),
&#39;eta&#39;: trial.suggest_float(&#39;learning_rate&#39;, 0.01, 0.3, log=True)
}

pruning_callback = XGBoostPruningCallback(trial, &#39;validation-mphe&#39;)

model = xgb.train(param,
dtrain,
evals=[(dval, &#39;validation&#39;)],
num_boost_round=200,
early_stopping_rounds=10,
callbacks=[pruning_callback])

score = model.best_score

return score
]]></description>
      <guid>https://stats.stackexchange.com/questions/653481/how-to-implement-timeseriessplit-in-a-optuna-optimization</guid>
      <pubDate>Wed, 28 Aug 2024 11:44:06 GMT</pubDate>
    </item>
    <item>
      <title>多元回归：Albright 和 Winston 书中的性别歧视案例</title>
      <link>https://stats.stackexchange.com/questions/653479/multiple-regression-gender-discrimination-caselet-in-albright-and-winston-book</link>
      <description><![CDATA[在 Albright 和 Winston 合著的《商业分析》一书中，多元回归一章中提供了一个性别歧视案例。该案例位于该书第 7 版第 10.3 节，开头是“斯普林菲尔德第五国民银行面临性别歧视诉讼”。脚注中指出：“此示例和随附数据集基于 1995 年的真实案例。只有银行的名称已更改。”
他们在接下来的几章中通过包含不同的变量对此进行了很好的分析。
是否有任何信息表明此案中实际发生了什么、诉讼如何解决以及是否实际使用了多元回归来帮助以某种方式解决此案？如果实际使用统计数据来解决此案，那就太好了。 :-) 任何指点都值得赞赏。

这也是我在 https://www.reddit.com/r/AskStatistics/comments/1f35gy7/multiple_regression_gender_discrimination_caselet/ 上发布的 X-Post。]]></description>
      <guid>https://stats.stackexchange.com/questions/653479/multiple-regression-gender-discrimination-caselet-in-albright-and-winston-book</guid>
      <pubDate>Wed, 28 Aug 2024 10:47:28 GMT</pubDate>
    </item>
    <item>
      <title>连续中介分析</title>
      <link>https://stats.stackexchange.com/questions/653476/mediation-analysis-with-continious</link>
      <description><![CDATA[我想使用连续中介进行中介分析。我很难找到有关如何执行此操作的全面指南。

据我所知，基于引导的中介是首选，但如果我理解正确，中介包仅允许定性中介。有什么建议怎么做吗？
我的第二个疑问涉及拟合用于中介的模型。我应该使用简单的双变量回归模型，还是应该寻找最佳拟合模型然后计算中介？后一种方法可能会出现问题，因为变量数量和某些模型在拟合优度方面的等效性。
]]></description>
      <guid>https://stats.stackexchange.com/questions/653476/mediation-analysis-with-continious</guid>
      <pubDate>Wed, 28 Aug 2024 09:44:35 GMT</pubDate>
    </item>
    <item>
      <title>具有非平稳控制但平稳残差的回归</title>
      <link>https://stats.stackexchange.com/questions/653475/regression-with-non-stationary-controls-but-stationary-residuals</link>
      <description><![CDATA[我想运行一个二元回归分析来反映政策变化，因此在变化之前它是零，变化之后它是一。因变量是平稳的，但在控制变量中有两个是非平稳的。当我运行回归分析时，尽管存在非平稳性，我得到的结果似乎合理，残差也是平稳的。
鉴于因变量和残差都是平稳的，我可以保持模型原样吗？还是应该进行调整？]]></description>
      <guid>https://stats.stackexchange.com/questions/653475/regression-with-non-stationary-controls-but-stationary-residuals</guid>
      <pubDate>Wed, 28 Aug 2024 09:27:31 GMT</pubDate>
    </item>
    <item>
      <title>GAM 比较的估计自由度</title>
      <link>https://stats.stackexchange.com/questions/653474/estimated-degrees-of-freedom-of-a-gam-comparison</link>
      <description><![CDATA[我想通过将该模型与不包含这些预测因子的基线模型进行比较来评估在 GAM 中包含两个平滑项的重要性。可以使用以下代码重现这种情况的模拟：
library(mgcv)
dat &lt;- gamSim(1,n=1000,dist=&quot;normal&quot;,scale=.1)

model &lt;- gam(y ~ s(x0, bs = &quot;cr&quot;, k = 20) + s(x1, bs = &quot;cr&quot;, k = 20) + te(x2, x3, bs = &quot;cr&quot;), data = dat)
baseline &lt;- gam(y ~ te(x2, x3, bs = &quot;cr&quot;), data = dat)
anova(baseline, model)

但是，我想使用交叉验证方案进行此评估。对部分数据进行模型拟合，并评估左侧折叠的对数似然。为此，我将手动计算左侧折叠的对数似然。要计算与对数似然差异相关的 p 值，我需要自由度。 如何确定此比较的正确自由度？
set.seed(123) 
nfolds &lt;- 5
dat$folds &lt;- sample(1:nfolds, size = nrow(dat), replace = TRUE)

train_data &lt;- dat[dat$folds != 1, ]
test_data &lt;- dat[dat$folds == 1, ]
test_y &lt;- test_data$y

model &lt;- gam(y ~ s(x0, bs = &quot;cr&quot;, k = 20) + s(x1, bs = &quot;cr&quot;, k = 20) + te(x2, x3, bs = &quot;cr&quot;), data = train_data)
baseline &lt;- gam(y ~ te(x2, x3, bs = &quot;cr&quot;), data = train_data)

pred_model &lt;- predict(model, test_data)
pred_baseline &lt;- predict(baseline, test_data)

stdev_model &lt;- sigma(model)
stdev_baseline &lt;- sigma(baseline)

loglik_model &lt;- sum(dnorm(test_y, pred_model, stdev_model, log=TRUE))
loglik_baseline &lt;- sum(dnorm(test_y, pred_baseline, stdev_baseline, log=TRUE))

delta &lt;- loglik_model - loglik_baseline
teststat &lt;- -2 * delta
pval &lt;- pchisq(teststat, df = , lower.tail =错误）
]]></description>
      <guid>https://stats.stackexchange.com/questions/653474/estimated-degrees-of-freedom-of-a-gam-comparison</guid>
      <pubDate>Wed, 28 Aug 2024 08:00:38 GMT</pubDate>
    </item>
    <item>
      <title>如何进行数据驱动的样本量选择</title>
      <link>https://stats.stackexchange.com/questions/653472/how-to-perform-data-driven-choice-of-sample-size</link>
      <description><![CDATA[假设我想比较两个回归模型的结果。一个是参考模型，另一个是新模型，我想知道新模型是否表现更好。每个模型都用皮尔逊相关性进行评估，假设数据集是依赖的，并且测试数据相同，我想得到配对差异的置信区间，看看它是否包含零。
但我事先不知道差异的方差，也不知道正确的样本量是多少，所以我想到了以下方法：
min_diff_to_detect
all_pearsons_ref = []
all_pearsons_new = []
alpha = 0.05

循环直到循环中断 -&gt;对于当前循环 n：
train_ref、train_new、test_data = get_new_data_split()

ref_model = train_ref_model(train_ref)
pearson_ref = assess( ref_model(test_data) )
all_pearsons_ref.append(pearson_ref)

new_model = train_new_model(train_new)
pearson_new = assess( new_model(test_data) )
all_pearsons_new.append(pearson_new)

Differences = all_pearsons_new - all_pearsons_ref # 成对差异
confidence_interval = compute_CI(0, np.std(differences), n, alpha)

如果 min_diff_to_detect 不在 confidence_interval 中：
如果 np.mean(differences) 不在 confidence_interval 中：
返回 are_different
返回are_not_different

train_data 是依赖的，而 test_data 对于两个模型是相同的。这个想法是使用数据来寻找最佳循环数 N。否则 N 将被猜测，并且可能太小而没有足够的统计能力，或者太大而需要太长时间进行训练。
但是，方差在早期循环中也有可能波动很大，从而导致 min_diff_to_detect 可能被错误检测。后一点可以通过在评估 if 条件之前引入最小循环数来缓解，但这感觉很武断，最终，我不知道这种方法是否有效。
我也知道 bootstrapping，但它需要大量的训练才能有效。
那么，第一个 if 条件可以改进以避免错误吗？最终，这是一种有效的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653472/how-to-perform-data-driven-choice-of-sample-size</guid>
      <pubDate>Wed, 28 Aug 2024 07:32:11 GMT</pubDate>
    </item>
    <item>
      <title>从头开始的部分依赖图 - XgBoost 深度 1</title>
      <link>https://stats.stackexchange.com/questions/653471/partial-dependence-plot-from-scratch-xgboost-depth-1</link>
      <description><![CDATA[有几个软件包可以为 XGBoost 等 ML 模型引入增强的可解释性，例如 PiML。网上还有很多关于可解释性不同方面的资源，例如部分依赖图。
https://selfexplainml.github.io/PiML-Toolbox/_build/html/guides/models/xgb1.html
https://medium.com/dataman-in-ai/how-is-the-partial-dependent-plot-computed-8d2001a0e556
我希望从头开始构建可解释性深度为 1 的 XGBoost 模型。
根据上面的 PiMl 链接，第一步是：“计算由唯一分割生成的每个 bin 的累积叶节点值”。
import pandas as pd
import numpy as np
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn import datasets
from sklearn.model_selection import train_test_split
iris = datasets.load_iris() 
X = iris.data 
y = iris.target 

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

y_train = np.array([0 if i==2 else 1 for i in y_train])
y_test = np.array([0 if i==2 else 1 for i in y_test])

train = xgb.DMatrix(X_train, label=y_train)

test = xgb.DMatrix(X_test, label=y_test)

params = {&#39;objective&#39;: &#39;binary:logistic&#39;, 
&#39;eval_metric&#39;: &#39;auc&#39;,
&#39;seed&#39;:10,
&#39;max_depth&#39;: 1
}

model = xgb.train(params, train, num_boost_round=10)

dump = model.get_dump()

dump 对象保存有关拆分和叶值的信息。但是，我很难理解“累积叶值”的含义。如果有人能帮助我理解这一点或指导我获取资源，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653471/partial-dependence-plot-from-scratch-xgboost-depth-1</guid>
      <pubDate>Wed, 28 Aug 2024 06:34:30 GMT</pubDate>
    </item>
    <item>
      <title>控制一个渠道（中介）来检查另一个渠道的影响是否正确？</title>
      <link>https://stats.stackexchange.com/questions/653470/is-it-right-to-control-one-channel-mediator-to-examine-the-impact-of-another-c</link>
      <description><![CDATA[假设冲击 X 通过两个介质/通道（A 和 B）影响 Y。
让我们想象以下有向无环图 (DAG)：
X→𝐴→Y 和 X→𝐵→Y。并且 A 和 B 不相关。
如果我只想检查第二个通道 (B)。在回归中控制 A 以研究 X 通过通道 B 对 Y 的影响是否正确：
Y=𝛼+𝛽X+𝝺A+𝝴
我读过讨论“不良控制”的论文，但它们没有讨论这样的案例。]]></description>
      <guid>https://stats.stackexchange.com/questions/653470/is-it-right-to-control-one-channel-mediator-to-examine-the-impact-of-another-c</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:39 GMT</pubDate>
    </item>
    <item>
      <title>R 中使用多重插补数据集 (mids) 的线性混合模型 EMMEANS 为因子变量添加了级别</title>
      <link>https://stats.stackexchange.com/questions/653467/linear-mixed-model-emmeans-using-multiply-imputed-datasets-mids-in-r-adds-leve</link>
      <description><![CDATA[我使用多重插补数据集 (mids) 在 R 中运行混合线性模型，然后尝试使用 emmeans 包获取带有 p 值的 emmeans。
fit_BAIPsy1 &lt;- 
with(data = df.mids, 
exp = lme4::lmer(
BAI_time ~ factor(Temps) + factor(Groupe) + 
factor(Psychotrope_T1) + T0_Age + factor(T0_Sexe) + 
factor(Temps) * factor(Groupe) + 
factor(Temps) * factor(Psychotrope_T1) + 
factor(Temps) * factor(Groupe) * factor(Psychotrope_T1) + 
ADIS_T0_Score_Dx_principale + (1| Subj)),
reml=TRUE
)

我使用 summary(pool(fit_BAIPsy1)) 从 mice 包中获取模型系数 + 相关统计数据时没有遇到任何问题。一切看起来都很好。
我用我的 Large Mira 对象（使用之前的模型获得）运行了这个来获得我的 emmeans：
emmeans(fit_BAIpsy1, pairwise ~ Groupe|Psychotrope_T1|Temps)
问题：
虽然 Psychotrope_T1 是一个因子 (0, 1)，但 emmeans 给了我额外的 级别 (0, 0.44, 0.48, 0.52, 0.54, [...], 1)。 
这个变量是估算的，但我检查了我的 25 个估算数据集 (df.mids)，看不到这些值。我还检查了我的 Mira 模型元素中的 25 个帧，我看到的只有 0 和 1。混合线性模型输出只给了我 2 个级别。
你能告诉我哪里出错了，以及如何解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653467/linear-mixed-model-emmeans-using-multiply-imputed-datasets-mids-in-r-adds-leve</guid>
      <pubDate>Wed, 28 Aug 2024 02:51:25 GMT</pubDate>
    </item>
    <item>
      <title>如何对 $\mathbb R^2$ 中不平行的两条线进行双变量高斯条件化？</title>
      <link>https://stats.stackexchange.com/questions/653455/how-to-condition-a-bivariate-gaussian-on-two-lines-in-mathbb-r2-that-are-not</link>
      <description><![CDATA[如何对 $\mathbb{R}^2$ 中两条不平行/相交的线 $\{(x,y):a_1x+b_1y+c_1=0\}\cup\{(x,y):a_2x+b_2y+c_2=0\}$ 上的均值为 $\mu$ 和 $\Sigma$（例如 $\sigma=\sigma^2I$）的双变量高斯进行条件化？]]></description>
      <guid>https://stats.stackexchange.com/questions/653455/how-to-condition-a-bivariate-gaussian-on-two-lines-in-mathbb-r2-that-are-not</guid>
      <pubDate>Tue, 27 Aug 2024 23:31:11 GMT</pubDate>
    </item>
    <item>
      <title>在复杂抽样下，效应大小通常如何定义？</title>
      <link>https://stats.stackexchange.com/questions/653452/how-are-effect-sizes-typically-defined-under-complex-sampling</link>
      <description><![CDATA[在某些领域，引用标准化效应大小的比较是很常见的。例如，均值差异通过样本标准差进行缩放以得出效应大小。
这进而导致计算公式从其他输入中提取标准差，例如，$t$统计量乘以其自由度的平方根大约等于缩放后的均值差异。这些计算公式在复杂抽样下无效：均值的标准误差与标准差之间的关系更为复杂。即使是“均值差除以标准差”这一简单定义，也会引发一个问题：哪个标准差——估计的总体标准差？
那么，问题是：是否存在标准的、广泛使用的标准化效应大小公式，可以解释复杂抽样？
[我并不真正关心标准化效应大小是好是坏，甚至不关心在复杂抽样下如何最好地计算它们——我只是试图找出现有的标准]]]></description>
      <guid>https://stats.stackexchange.com/questions/653452/how-are-effect-sizes-typically-defined-under-complex-sampling</guid>
      <pubDate>Tue, 27 Aug 2024 23:09:45 GMT</pubDate>
    </item>
    <item>
      <title>有或没有聚合的混合设计方差分析？</title>
      <link>https://stats.stackexchange.com/questions/653439/mixed-design-anova-with-or-without-aggregation</link>
      <description><![CDATA[我进行了一个反应时间实验，现在想对其进行评估。这是一个重复测量实验，有两个条件（我们称之为条件 A 和条件 B）。还有两个组（我们称之为组 1 和组 2）。每个参与者在条件 1 中完成了 60 次试验，在条件 2 中完成了 60 次试验，因此每个用户有 120 个数据点。我现在想做一个混合方差分析，我想知道我是否应该使用每个参与者的试验平均值，或者我是否应该使用每个参与者的每个数据点。我曾尝试在 R 中使用 ezANOVA 和 afex 将每个数据点引入 ANOVA，但两个软件包都返回了聚合到均值的警告。
这是我的数据的样子：



ID
Group
Conditon
RT




1
Group 1
A
345


1
Group 1
A
746


1
第 1 组
A
824


1
第 1 组
B
542


1
第 1 组
B
235


1
组1
B
654


2
第 2 组
A
324


2
第 2 组
A
345


2
第 2 组
A
123


2
组2
B
623


2
第 2 组
B
235


2
第 2 组
B
654



我尝试这样计算：
afex::aov_car(RT ~ Group*Condition+ Error (ID/Condition), data = df_long)

然后我收到警告：
每个设计单元有多个观察值，使用聚合数据`fun_aggregate = mean`。

要关闭此警告，请明确传递 fun_aggregate = mean。]]></description>
      <guid>https://stats.stackexchange.com/questions/653439/mixed-design-anova-with-or-without-aggregation</guid>
      <pubDate>Tue, 27 Aug 2024 19:11:53 GMT</pubDate>
    </item>
    <item>
      <title>面板数据中的单位不变处理</title>
      <link>https://stats.stackexchange.com/questions/653438/unit-invariant-treatments-in-panel-data</link>
      <description><![CDATA[初学者，想问一个关于双向固定效应的初学者问题。如果相关的话，我正在使用 R。
与这个问题中的用户一样，我感兴趣的是估计随时间变化（但单位不变）的宏观条件如何影响公司情绪；就我而言，是在行业层面。但是，我的问题略有不同。 这个答案也可能部分回答了我的问题，尽管我发现问题和答案都令人困惑。
就我而言，我有以下数据：(1) 各个公司的 ID，(2) 每个公司所属的行业，(3) 日期 (YYYY-MM-DD)，(4) 宏观条件，(5) 公司情绪，以及 (6) 情绪所指的主题。

“处理”[宏观条件] 和响应 [情绪] 都是连续的，范围从负到正。
行业、主题和公司是分类的。

首先，我关心符号以及处理的幅度如何影响响​​应。其次，观察某些行业反应的差异也很重要，对我来说，这意味着一个交互项。我想象我想要估计的关系是这样的：
$$ Sentiment_{ijt} = Macro_{jt} + Sector_i + Macro_{jt} * Sector_i $$
其中 $i$ 是公司，$j$ 是主题，$t$ 是年度汇总。通常，我看到人们将公司和年份作为固定效应。但我怀疑教科书式的方法是否适用于此：

首先，由于每个公司只能被分配到一个部门，并且这个部门不会随时间而变化，$Sector$ 应该与公司 FE 完全共线。
其次，对我来说，重点是估计不同公司响应的差异，因此我认为我不想包含公司 FE。

我想我可以使用 topic FE 而不是公司 FE。但我从未见过这样做；单位（根据我的经验）通常是基于空间或实体的。因此，从概念上讲，我很难理解分析单位（主题年份？）甚至代表什么，或者它是否与我的实际研究问题一致。
我还读到，有 3WFE 解决方案可以解释 $Y$ 上的所有下标，但我觉得这可能是错误的方向，因为我的目标是观察行业级别的差异（以及我的预测变量上的下标与 $Y$ 上的下标不匹配）。
将 $Sentiment_{ijt}$ 建模为 $Macro_{jt} * Sector_i$ 与主题 ($i$) / 年份 ($t$) 2WFE 是否是一种合理的方法，考虑到我的研究问题？或者是否应该重构我的数据以减少$Sentiment$可能变化的维度数量？]]></description>
      <guid>https://stats.stackexchange.com/questions/653438/unit-invariant-treatments-in-panel-data</guid>
      <pubDate>Tue, 27 Aug 2024 19:05:11 GMT</pubDate>
    </item>
    <item>
      <title>R 平方因果推断</title>
      <link>https://stats.stackexchange.com/questions/653295/r-squared-causal-inference</link>
      <description><![CDATA[我想知道在评估系数时，较低的 R 平方值是否会造成问题。我的人群被分为两组（A 和 B），我想评估它们之间在因变量方面是否存在显著差异。我在回归中加入了几个控制变量，但 R 平方值非常低（&lt;0.05）。我应该担心这个问题吗？添加更多控制变量是否明智？
假设我想在学术期刊上发表结果，这会造成问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653295/r-squared-causal-inference</guid>
      <pubDate>Sun, 25 Aug 2024 15:42:45 GMT</pubDate>
    </item>
    </channel>
</rss>