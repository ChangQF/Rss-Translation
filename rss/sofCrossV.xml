<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 30 May 2024 15:16:04 GMT</lastBuildDate>
    <item>
      <title>交错式 diff-in-diff 与 堆叠式 diff-in-diff</title>
      <link>https://stats.stackexchange.com/questions/648291/staggered-diff-in-diff-vs-stacked-diff-in-diff</link>
      <description><![CDATA[只是想更好地理解交错式差分和堆​​叠式差分之间的技术差异到底是什么。我知道 TWFE 交错式差分有其自身的问题，而且几位作者已经想出了更准确的 ATT 估计方法。但我也知道有些作者更依赖堆叠式差分设计，我想更好地理解其中的区别。我的先验是堆叠式差分不允许将已经处理过的单元用作对照，而交错式差分可以？但不确定。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/648291/staggered-diff-in-diff-vs-stacked-diff-in-diff</guid>
      <pubDate>Thu, 30 May 2024 14:16:06 GMT</pubDate>
    </item>
    <item>
      <title>我们有敏感度-特异性空间（ROC 曲线）和精确度-召回率空间（PR 曲线，$F_1$ 分数）。PPV-NPV 空间方面做了哪些工作？</title>
      <link>https://stats.stackexchange.com/questions/648290/we-have-sensitivity-specificity-space-roc-curves-and-precision-recall-space-p</link>
      <description><![CDATA[接收者操作特性 (ROC) 曲线显示了敏感度和特异性之间的平衡：您在检测类别 $1$（敏感度）方面有多好，同时不会将类别 $0$ 错误地识别为类别 $1$（特异性）。这样，我们可以相信预测的 $1$ 确实是 $1$。
精确召回率 (PR) 曲线可以说通过使用精确度直接衡量怀疑程度来改善这一点，精确度是特异性的函数（以及分类器性能的其他方面）。召回率/敏感度衡量的是在一个观测值为 $1$ 的情况下检测到 $1$ 的概率，而准确率则是阳性预测值 (PPV)：你所声称的 $1$ 确实属于 $1$ 类别的概率。此外，$F_1$ 和更一般的 $F_{\beta}$ 分数同时考虑了精确度和召回率。
负预测值 (NPV，不要与金融中的净现值混淆) 与敏感度/召回率的关系，就像正预测值与特异性的关系一样，因为 NPV 给出了您声称的 $0$ 确实属于 $0$ 类别的概率。与 PPV 一样，NPV 通过调节已知预测来估计未知概率，从而测量信息的正向流动。比较 PPV 与 NPV 似乎很有价值：对于 $0$ 类别声明的给定可信度水平，我们对 $1$ 类别的声明的可信度有多高。这可能并不总是我们想知道的，但肯定是可能的。
有哪些工作明确处理 PPV-NPV 空间，无论是 PPV-NPV 曲线还是结合 PPV 和 NPV 的分类器指标，类似于 $F_{\beta}$ 结合 PPV/精度和召回率/灵敏度的方式？当然，我们可以将 ROC 曲线与流行度一起转换为 PPV-NPV 曲线，但这并不明确使用 PPV 和 NPV。]]></description>
      <guid>https://stats.stackexchange.com/questions/648290/we-have-sensitivity-specificity-space-roc-curves-and-precision-recall-space-p</guid>
      <pubDate>Thu, 30 May 2024 14:06:04 GMT</pubDate>
    </item>
    <item>
      <title>如何确定 Gamma-Poisson 模型的 Gamma 分布的参数？</title>
      <link>https://stats.stackexchange.com/questions/648289/how-to-decide-the-parameters-of-a-gamma-distribution-for-a-gamma-poisson-model</link>
      <description><![CDATA[在贝叶斯推断中，Gamma-Poisson 模型通常使用泊松分布的 $\lambda$ 参数上的 Gamma($\alpha$,$\beta$) 先验。
是否有任何规则可以对 Gamma 先验的这些 $\alpha$ 和 $\beta$ 参数设置适当的值？
先验通常在看到数据之前设置；那么，我们需要什么信息才能知道应该给予 $\alpha$ 和 $\beta$ 的值？
我们是否需要至少大致了解我们计划的泊松实验中应该观察到的平均 $\lambda$ 值是多少？
或者我们是否需要至少大致了解我们计划的泊松实验中应该观察到的最大值是多少？
或者任何其他类型的信息，以免立即盲目地给出 $\alpha$ 和 $\beta$ 无意义的值？
任何回报都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/648289/how-to-decide-the-parameters-of-a-gamma-distribution-for-a-gamma-poisson-model</guid>
      <pubDate>Thu, 30 May 2024 14:01:29 GMT</pubDate>
    </item>
    <item>
      <title>训练集和验证集之间的性能显著下降</title>
      <link>https://stats.stackexchange.com/questions/648288/significant-performance-drop-between-train-and-validation-set</link>
      <description><![CDATA[我正在尝试使用 Lgbm 和 RandomForest 进行分类，并且我观察到了同样的问题。我使用各种元参数来防止过度拟合，例如 max_depth、num_trees（对于 Lgbm 保持较小）、reg_alpha 和 reg_lambda（对于 Lgbm）等。
在这两种情况下，AUC 从训练集上的 70% 左右下降到验证集上的 55%（对于最佳参数组合），测试集也是如此，约为 55%。
我在想：我能做些什么来将它们结合起来？提前停止是一种可能性吗？我还能尝试什么来避免在训练集上过度拟合？显然，学到的见解不会从样本中转化出来。
或者它可能是早期步骤中更根本的问题，例如特征工程等？]]></description>
      <guid>https://stats.stackexchange.com/questions/648288/significant-performance-drop-between-train-and-validation-set</guid>
      <pubDate>Thu, 30 May 2024 13:34:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么 $S = X \cdot W + b$，$dS$ 的梯度等于 $\frac{\text{probs} - 1} {N}$，其中 $\text{probs}$ 是 $S$ 的 softmax 分类器？</title>
      <link>https://stats.stackexchange.com/questions/648285/why-is-the-gradient-of-s-x-cdot-w-b-ds-equal-to-frac-textprobs</link>
      <description><![CDATA[为什么$S = X \cdot W + b$，$dS$的梯度等于$\frac{\text{probs} - 1} {N}$？
这里，probs 是一个$1 \times K$数组，表示$X_i$属于类$k$的概率，其中$k = 1, 2, ..., K$，$N$是数据集的大小。
$X_i$ 具有 $J$ 个特征/列 ($X_{i1}$, $X_{i2}$, ... ,$X_{iJ}$)，并且我们在 $S$ 上使用 softmax 激活函数：
$$\text{probs}_k = \frac{\exp(S_K)}{\sum_{k = 1}^{K} \exp(S_k)}$$
以下是代码的具体部分，其中指出 $dS = \frac{\text{probs} - 1} {N}$: 
以下是 NN 的结构：]]></description>
      <guid>https://stats.stackexchange.com/questions/648285/why-is-the-gradient-of-s-x-cdot-w-b-ds-equal-to-frac-textprobs</guid>
      <pubDate>Thu, 30 May 2024 12:58:10 GMT</pubDate>
    </item>
    <item>
      <title>回归：仅具有正值的负截距</title>
      <link>https://stats.stackexchange.com/questions/648284/regression-negative-intercept-with-only-positive-values</link>
      <description><![CDATA[我正在对一些标准差值进行多元线性回归，但许多预测因子的截距和系数为负。
关于我应该如何解释结果，您有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648284/regression-negative-intercept-with-only-positive-values</guid>
      <pubDate>Thu, 30 May 2024 12:38:25 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 GLM Gamma 模型诊断</title>
      <link>https://stats.stackexchange.com/questions/648282/diagnostic-for-glm-gamma-model-in-r</link>
      <description><![CDATA[我正在将具有伽马分布和对数链接函数的 glm 模型应用于仅在 R+ 上定义的连续变量。我尝试拟合模型，但在解释诊断方面遇到了一些困难。我之前没有用 glm 做过这件事。我读了一些资料，也看到了有关此事的其他讨论。我需要一些关于解释结果的建议，更多是获得关于我的想法的反馈。
#fit a glm with gamma distribution gamma_fit &lt;- glm(recoveries ~ loan_amnt+ term+ int_rate + installment + validation_status+ title+ fico_range_low + log(total_pymnt)+ total_rec_prncp + total_rec_int + total_rec_late_fee + last_pymnt_amnt + deal_settlement_flag, data = dati[train,], family = Gamma(link = &quot;log&quot;)) 
summary(gamma_fit) 
vif(gamma_fit) 
predict_recoveries &lt;- predict(gamma_fit, newdata = dati[test,], type = &quot;response&quot;)
rmse &lt;- sqrt(mean((predict_recoveries - dati[test, &quot;recoveries&quot;])^2)) 
rmse deviance_residuals &lt;- residuals(gamma_fit, type = &quot;deviance&quot;) 

plot(density(deviance_residuals))
lines(seq(-5, 5, 0.1), dnorm(seq(-5, 5, 0.1),0,1), col = &quot;red&quot;)

library(&quot;boot&quot;)
glm.diag.plots(gamma_fit)

library(&quot;DHARMa&quot;)
sim_glm &lt;- mockResiduals(gamma_fit, n = 1000, plot = TRUE) plot(sim_glm)

我的问题是关于 glm.giad 的输出。和残差的模拟
据我所知，诊断 GLM 很困难。R^2 值应像 N~(0,1) 一样分布（如果我错了，请纠正我）。glm.diag 给我以下输出。
glm.diag
拟合对我来说似乎相当线性，我不明白的是 qqplot，它反对什么？正常残差？我不确定。这就是为什么我找到了第二个函数，它模拟模型的残差并将它们与计算出的实际残差作图。
DHARMa
这里，在这种情况下，qqplot 似乎更可靠，据我所知，应该来自模拟（您认为它好吗？可以接受吗？我没有足够的经验来肯定地说）。我不明白的是右边的图。如果有人能帮我给出更透彻的解释，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/648282/diagnostic-for-glm-gamma-model-in-r</guid>
      <pubDate>Thu, 30 May 2024 11:28:13 GMT</pubDate>
    </item>
    <item>
      <title>Winsteps：如何获得通过 Rasch 模型调整的分数？</title>
      <link>https://stats.stackexchange.com/questions/648277/winsteps-how-to-obtain-scores-that-are-adjusted-by-rasch-modelling</link>
      <description><![CDATA[我需要验证一组数学分数，并被建议使用 Rasch 模型来实现此目的。因此，我正在学习如何使用 Winsteps，并且正在考虑它是否可以输出由 Rasch 模型调整的分数。如果 Winsteps 可以提供调整后的分数，那么我想我可能会继续使用这些分数。但是，在探索了 [输出文件] 标签中的一些可能选项后，我发现只有 [响应文件] 和 [模拟数据文件] 可以输出与我的原始数据具有相同案例数的数据集。
所以我的问题是：
Winsteps 可以输出 Rasch 调整后的分数吗？如果可以，我该如何获得它？]]></description>
      <guid>https://stats.stackexchange.com/questions/648277/winsteps-how-to-obtain-scores-that-are-adjusted-by-rasch-modelling</guid>
      <pubDate>Thu, 30 May 2024 10:08:15 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 R 计算具有 2 个独立变量、1 个中介变量和 2 个结果变量的中介模型？</title>
      <link>https://stats.stackexchange.com/questions/648273/how-do-i-calculate-a-mediation-model-with-2-independent-variables-1-mediator-an</link>
      <description><![CDATA[有人认为两个独立变量都可能影响中介变量，而中介变量又会对两个结果变量产生影响（预计也会有直接影响）。
所有变量都与李克特量表处于区间尺度水平。样本量为 180。
如何在 R 中计算？我是 R 新手，不知道 R 是否可以做到这一点以及如何做到这一点。
我可以用 SEM 来做这件事吗？如果可以，该怎么做？
我更愿意在一个模型中计算所有内容，而不是计算 4 个不同的中介模型。这可能吗？两个独立变量都有些关联（一个是工作中的积极体验，另一个是消极体验，但仍然不属于同一个构造），两个因变量彼此之间没有关联。
这是一项横断面研究。 （这就是我对相关性感兴趣的原因，因为我不能谈论因果关系）。
任何帮助都非常感谢，非常感谢！
模型图片在这里：
]]></description>
      <guid>https://stats.stackexchange.com/questions/648273/how-do-i-calculate-a-mediation-model-with-2-independent-variables-1-mediator-an</guid>
      <pubDate>Thu, 30 May 2024 09:14:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中执行（流行病学）等时替代分析？</title>
      <link>https://stats.stackexchange.com/questions/648264/how-to-perform-an-epidemiologic-isotemporal-substitution-analysis-in-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648264/how-to-perform-an-epidemiologic-isotemporal-substitution-analysis-in-r</guid>
      <pubDate>Thu, 30 May 2024 07:26:18 GMT</pubDate>
    </item>
    <item>
      <title>添加混杂因素“因子”与减去层内平均值</title>
      <link>https://stats.stackexchange.com/questions/648262/adding-a-confounder-factor-vs-subtracting-within-level-mean</link>
      <description><![CDATA[为了解释已知的混杂因素，可以在线性回归中添加一个额外的因子（描述混杂效应）。
例如，在 R 中，我们可以有：
model &lt;- lm(response ~ predictor + confounder, data = data)

这里，response 是一个 协变量（即连续值），而 predictor 和 confounder 是 因子。
我的理解是，使用上述 公式，估计的 response 将根据 confounder 级别内的样本的 均值 进行调整（如 Law 等人，见图 1）。
现在，我想知道上述建模方法与在拟合模型之前减去每个混杂因素级别内样本的响应的平均值之间的区别。我假设我们应该得到预测变量的系数。
这种方法的缺点是什么？
为了说明为什么这很重要：
我正在建模一个数据集，我知道其中存在混杂因素。但是，我也知道混杂因素的每个级别内的样本可能是异常值。因此，我倾向于通过样本的中位数而不是平均值来调整样本的响应（如上所述，这是在线性回归中完成的），然后从公式中删除混杂因素。
我想知道如果我采用这种方法是否会遗漏某些内容？]]></description>
      <guid>https://stats.stackexchange.com/questions/648262/adding-a-confounder-factor-vs-subtracting-within-level-mean</guid>
      <pubDate>Thu, 30 May 2024 07:17:02 GMT</pubDate>
    </item>
    <item>
      <title>使用结果变量两次估计参数 - 允许吗？什么时候？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648251/use-outcome-variable-twice-to-estimate-parameters-allowed-when</link>
      <description><![CDATA[我正在努力找出在两个可能性中使用相同的结果变量是否合适（是/否/有时），无论是在同一个模型中还是在两个不同的模型中。
我有一个二元结果变量$y$，我想在回归模型$\mu$中使用它，但该模型需要包括对假阴性的校正，$\psi$。
同时，我想估计真实患病率$\theta$，它由第二个变量$u$提供信息。
我能够做到这一点的唯一方法是在两个不同的可能性中使用$y$，如下面的 Stan 示例所示。该模型公式完美地恢复了模拟参数。
不过，有人告诉我，这种结果变量的双重使用是不允许的。
这是真的吗？
如果是这样，具体原因是什么，有没有办法解决这个问题？
例如，如果在第一个模型（$y \sim \text{Bernoulli}( (1-\psi) \theta)$）中估计了$\psi$，然后在第二个模型（$y \sim \text{Bernoulli}( (1-\psi) \mu)$）中使用该估计值，是否允许这样做，还是这归结为同一件事？或者可以调整可能性，这样就可以了吗？
如果确实允许，我该如何论证才能说服稿件审阅者？
任何帮助都将不胜感激。
Benny
PS 我尝试在联合可能性中，在混合模型（Stan 中的 log_mix）中执行此操作，但这会导致 $\mu$ 中回归系数的估计有偏差。它仅在可能性独立时才有效。
model{
y ~ bernoulli( (1-psi) * mu);
y ~ bernoulli( (1-psi) * theta);

u ~ bernoulli( theta);
}

]]></description>
      <guid>https://stats.stackexchange.com/questions/648251/use-outcome-variable-twice-to-estimate-parameters-allowed-when</guid>
      <pubDate>Wed, 29 May 2024 22:38:31 GMT</pubDate>
    </item>
    <item>
      <title>有关路径分析结构/变量表示的问题？</title>
      <link>https://stats.stackexchange.com/questions/648250/question-regrding-path-analysis-structure-variable-representation</link>
      <description><![CDATA[我正在尝试进行路径分析，以评估播种处理（5 种不同物种）对不同类型地被植物（本地、非本地和播种物种）的影响，而这又会对土壤侵蚀产生影响。我不确定播种处理是否应该分组为单个变量（B），还是分成单个因子水平（A）？谢谢！
]]></description>
      <guid>https://stats.stackexchange.com/questions/648250/question-regrding-path-analysis-structure-variable-representation</guid>
      <pubDate>Wed, 29 May 2024 21:51:14 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 R 模拟具有调节效应的 SEM 模型数据？</title>
      <link>https://stats.stackexchange.com/questions/648242/how-to-simulate-data-for-a-sem-model-with-moderation-effect-using-r</link>
      <description><![CDATA[我正在开展一个项目，需要模拟包含调节效应的结构方程模型 (SEM) 的数据。具体来说，我有三个潜在变量：一个独立变量 (IV)、一个调节变量 (MOD) 和一个因变量 (DV)。我需要对 IV 和 MOD 之间的相互作用进行建模，并评估其对 DV 的影响。
我计划使用 R 中的 lavaan 包来拟合模型，但需要有关如何正确生成数据（包括调节效应）的指导。我对使用 simsem 包进行数据模拟有一定的了解，但不确定正确指定模型和生成交互项的最佳方法。
我添加了一个示例模型。simulateData 创建了新的变量，如 iva1:mod1，它不是 iva1 和 mod1 的乘积：
model_test &lt;- &quot;
# 自变量 A 的测量模型 (IVA)
iva =~ iva1 + iva2 + iva3

# 自变量 B 的测量模型 (IVB)
ivb =~ ivb1 + ivb2 + ivb3

# 调节变量的测量模型 (MOD)
mod =~ mod1 + mod2 + mod3

# IVA 和 MOD 之间的交互项
mod_iva =~ iva1:mod1 + iva2:mod1 + iva3:mod1 + 
iva1:mod2 + iva2:mod2 + iva3:mod2 + 
iva1:mod3 + iva2:mod3 + iva3:mod3

# IVB 和 MOD 之间的交互项
mod_ivb =~ ivb1:mod1 + ivb2:mod1 + ivb3:mod1 + 
ivb1:mod2 + ivb2:mod2 + ivb3:mod2 + 
ivb1:mod3 + ivb2:mod3 + ivb3:mod3

# 因变量 (DV) 的测量模型
dv =~ dv1 + dv2 + dv3 + dv4

# 结构模型：回归方程
dv ~ 0.5*iva + 0.4*ivb + -0.3*mod + -0.12*mod_iva + -0.17*mod_ivb

# IVA 和 IVB 之间的协方差
iva ~~ 0.54*ivb
&quot;

result = mockData(model_test, sample.nobs=300L)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648242/how-to-simulate-data-for-a-sem-model-with-moderation-effect-using-r</guid>
      <pubDate>Wed, 29 May 2024 20:19:22 GMT</pubDate>
    </item>
    <item>
      <title>理解元分析中的相关和分层效应模型</title>
      <link>https://stats.stackexchange.com/questions/648224/understanding-correlated-and-hierarchical-effects-models-in-meta-analysis</link>
      <description><![CDATA[我正在做一个三级荟萃分析，我想比较一个三级相关和分层效应模型（其中效应在研究之间嵌套）和一个两级模型（其中研究级别的方差被限制为 0）。
最初，我使用以下简单的三级随机效应模型：
model &lt;- rma.mv(yi = es, 
V = var, 
slab = study,
data =pression,
random = ~ 1 | study/es.id, 
test = &quot;t&quot;, 
method = &quot;REML&quot;)

并将其与这个混合效应模型进行比较。
model.reduced &lt;- rma.mv(yi = es, 
V = var, 
slab = study,
data =pression,
random = ~ 1 | study/es.id, 
test = &quot;t&quot;, 
method = &quot;REML&quot;,
sigma2 = (0,NA))

anova(model, model.reduced)

这使我能够理解模型适应度如何随着聚类效果的变化而变化。到目前为止很简单。
但是，从那时起，我将上述模型拟合为如下所示的相关分层模型（V.6），这将使我能够进一步使用稳健方差估计对其进行拟合，并避免模型错误指定。我通过将方差输入更改为使用 R 中的 ClubSandwich 包得出的 imputed_variance_matrix 来实现此目的。请参阅下面的示例：
V.6 &lt;- with(depression, 
impute_covariance_matrix(vi = var,
cluster = study,
r = rho))

我现在使用以下模型 [che.model.6]，但我无法将其与简化模型 [model.reduced] 进行比较，因为两个模型之间的协方差不相等。使用与上述相同的逻辑，将 che.model.6 与 che.model.60 进行比较，以比较在研究集群水平上将方差限制为 0 时异质性的差异，这是否有问题。
che.model.6 &lt;- rma.mv(yi =es,
V = V.6,
random = ~ 1 | study/es.id,
data =pression,
sparse = TRUE)

che.model.60 &lt;- rma.mv(yi =es,
V = V.6,
random = ~ 1 | study/es.id,
data =pression,
sparse = TRUE,
sigma2 = c(0, NA))

anova(che.model.6, che.model.60)

第二个方差分析是否与第一个方差分析在随机效应模型中发挥相同的作用？或者 RVE，例如：
coef_test(che.model.6, 
vcov = &quot;CR2&quot;)

对我的 CHE 模型来说，本质上发挥的功能与 anova 对我的随机效应三级模型发挥的功能相同？
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/648224/understanding-correlated-and-hierarchical-effects-models-in-meta-analysis</guid>
      <pubDate>Wed, 29 May 2024 16:22:41 GMT</pubDate>
    </item>
    </channel>
</rss>