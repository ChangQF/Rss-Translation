<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 27 Dec 2023 09:13:33 GMT</lastBuildDate>
    <item>
      <title>F1 分数与出版物不符</title>
      <link>https://stats.stackexchange.com/questions/635688/f1-score-mismatch-with-publication</link>
      <description><![CDATA[我正在尝试重现 SEP28k 论文中基线模型的结果，但我很难获取详细信息。最引人注目的是，随机预测的 F1 分数与论文不符。以下是数据集类别的统计数据（论文中所述的来自数据集的 1k 个样本）：
 块延长 SoundRep WordRep 感叹词
计数 1000 1000 1000 1000 1000
独特 2 2 2 2 2
顶部错误错误错误错误错误错误
频率 829 834 879 834 636

为每个标签随机选择 True/False 的 F1 分数：
区块：0.29（纸质版为 0.14）
延伸率：0.25（纸上为0.13）
SoundRep：0.23（纸质版为 0.095）
WordRep：0.22（纸质版为 0.043）
感叹词：0.38（论文中为0.14）

我使用的评估代码是这样的：
导入 pandas 作为 pd
进口火炬
从 sklearn.metrics 导入 f1_score

STUTTER_LABELS = [&#39;阻止&#39;、&#39;延长&#39;、&#39;SoundRep&#39;、&#39;WordRep&#39;、&#39;感叹词&#39;]
如果 __name__ == “__main__”：
    df = pd.read_csv(&#39;SEP-28k_labels.csv&#39;)
    df = df[STUTTER_LABELS][df[STUTTER_LABELS].values.sum(axis=1) &gt;= 2]
    df = df.样本(n=1000)
    打印((df &gt;= 2).describe())
    
    标签 = torch.from_numpy(df.values &gt;= 2).long()
    preds = torch.randint_like(标签, high=2)
    分数 = [f1_score(labels[:, i], preds[:, i]) for i in range(5)]
    论文分数 = [0.137, 0.128, 0.095, 0.043, 0.136, 0.46]
    对于 zip 中的名称、分数、paper_score（STUTTER_LABELS、分数、paper_scores）：
        print(f&quot;{name}: {score:.2} ({paper_score:.2} in paper)&quot;)

并且 csv 可在 SEP28k github 上获取。
我尝试过仅使用口吃语音和口吃/流利语音对数据集进行预测，但随机分类器的结果比论文中所说的要高得多。也许原因是我不确定“软预测层”是什么。意思是
两种模型都有两个输出
分支：流畅/不流畅预测和软预测
对于五种事件类型中的每一种

我假设它单独预测每个类别（例如 5 个输出神经元末尾的 sigmoid）。]]></description>
      <guid>https://stats.stackexchange.com/questions/635688/f1-score-mismatch-with-publication</guid>
      <pubDate>Wed, 27 Dec 2023 08:37:06 GMT</pubDate>
    </item>
    <item>
      <title>在自然实验中具有重复增益分数的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/635687/linear-mixed-models-with-repeated-gain-scores-in-a-natural-experiment</link>
      <description><![CDATA[背景：我正在处理一个数据集，其中包含来自涉及自然实验的调查问卷的观察数据。人们每周都会被问及是否收到了意外消息 (X)、他们睡了多少觉 (Z) 以及他们的健康状况 (Y)。 Y 和 Z 是在另一次子调查中测量的，因此对于 X 的每个观测值，我将 X 之前和之后最接近的 Y 和 Z 观测值合并起来，以获得前/后测量值。现在，每一行都包含用户 ID、x、z 的值以及相应的 Y 前值和后值。作为用前值调整后值以控制预测值的中心假设不满足（组有在基线时没有被随机化），我选择使用增益/变化/差异分数（https://homes.ori.org/keiths/Tips/Stats_GainScores.html）作为我的回归 Ydiff ~ X*Z 的结果，其中 Ydiff = Post - Pre。
问题：观察的数量因人而异：有些人确实比其他人参与更多，导致每个人的分数发生多个变化；其他人只有一个可用的更改分数。使用随机截距为每个用户建模潜在的嵌套结构是否有意义？多个变化分数的出现是否可以称为嵌套？我现在真的不知道如何继续这里。谢谢大家！
数据如下：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

ID
x
z
预
帖子
ydiff


&lt;正文&gt;

356
未收到
4.2590
2
2
0


356
已收到
5.6615
1
5
4


1088
已收到
8.8172
5
5
0


1089
未收到
5.0027
1
3
2


1089
没有检查
5.3050
2
5
3




在 R 中重现的代码：
&lt;前&gt;&lt;代码&gt;n &lt;- 4000
data_frame &lt;- 变换（
  数据.帧(
    ID = 样本(rep(样本(1:2000, 500, 替换 = FALSE), 每个 = 4), n, 替换 = TRUE),
    x = 样本(c(“已收到”,“未收到”,“未检查”), n, 替换 = TRUE),
    z = runif(n, 4, 10),
    前 = 样本(1:5, n, 替换 = TRUE),
    帖子=样本（1：5，n，替换= TRUE）
  ),
  ydiff = 后 - 前
）
]]></description>
      <guid>https://stats.stackexchange.com/questions/635687/linear-mixed-models-with-repeated-gain-scores-in-a-natural-experiment</guid>
      <pubDate>Wed, 27 Dec 2023 08:17:59 GMT</pubDate>
    </item>
    <item>
      <title>回归一个二元向量以获得另一个二元向量</title>
      <link>https://stats.stackexchange.com/questions/635685/regression-of-a-binary-vector-to-obtain-another-binary-vector</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635685/regression-of-a-binary-vector-to-obtain-another-binary-vector</guid>
      <pubDate>Wed, 27 Dec 2023 05:53:14 GMT</pubDate>
    </item>
    <item>
      <title>为什么在推导线性模型时 $\vec{\beta}^T X^T X \vec{\beta}$ 等于 $2X^T X \vec{\beta}$？</title>
      <link>https://stats.stackexchange.com/questions/635681/why-is-vec-betat-xt-x-vec-beta-equal-to-2xt-x-vec-beta-in-derivi</link>
      <description><![CDATA[当我们得出 $\vec{\beta}$ 的估计值时，它们可以最小化平方误差之和 ($SSE$) 我们从 $\sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1x_1 + ... + \beta_kx_k ))^2$。这相当于矩阵向量乘积 $(X \vec{\beta} - \vec{y})^T(X \vec{\beta} - \vec{y} )$ （如果这是错误的，请纠正我）并且等于 $\vec{y}^T\vec{y} - \vec{y}^T X \vec{\beta} - \vec{\beta}^TX^T \vec{y} + \vec{\beta}^TX^T X\vec{\beta}$ 我能够制作把这些都写出来的感觉。
对我来说，我们希望将此表达式设置为零并取相对于 $\vec{\beta}$ 的部分（梯度) 就像这样 $\frac{\partial}{\partial{\vec{\beta}}}$ $\vec {y}^T\vec{y} - \vec{y}^TX\vec{\beta} - \vec{\beta}^TX^T \vec{y} + \vec{\beta}^TX^ T X\vec{\beta} = 0$
我不明白的是为什么这里的结果等于 $-2X^T \vec{y} + 2X^T X \vec{\beta}$ 特别是第二部分，$2X^T X \vec{\beta}$
有人可以解释一下该结果是如何获得的吗？我就是不明白。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/635681/why-is-vec-betat-xt-x-vec-beta-equal-to-2xt-x-vec-beta-in-derivi</guid>
      <pubDate>Wed, 27 Dec 2023 01:54:05 GMT</pubDate>
    </item>
    <item>
      <title>如何处理时变 Cox 模型中时间 0 的暴露或结果</title>
      <link>https://stats.stackexchange.com/questions/635680/how-to-deal-with-exposure-or-outcome-at-time-0-in-a-time-varying-cox-model</link>
      <description><![CDATA[假设我有一个包含汽车列表的数据集，其中一些具有自动驾驶功能，即随时间变化的曝光。有些汽车从一开始（时间 0）就具有此功能，有些汽车是在之后才获得的。兴趣的结果就是崩溃。有些汽车在第 0 天发生了车祸。您如何处理时变 Cox 模型中在时间 0 发生的这些暴露和结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/635680/how-to-deal-with-exposure-or-outcome-at-time-0-in-a-time-varying-cox-model</guid>
      <pubDate>Wed, 27 Dec 2023 01:50:03 GMT</pubDate>
    </item>
    <item>
      <title>在比较多个非参数相关组时，我应该使用什么测试？</title>
      <link>https://stats.stackexchange.com/questions/635678/what-test-do-i-use-when-comparing-multiple-dependent-groups-that-are-non-paramet</link>
      <description><![CDATA[基本上，我正在比较适用于某个领域中每个人的变量的结果与该组的每个子类别（例如，所有护士的平均年薪与所有不同类型护士的年薪），但我不能找到合适的测试。
由于我比较了两个以上组的连续数据，我认为方差分析是合适的，但数据是非参数的，所以我转向克鲁斯卡尔沃利斯。就在那时，我意识到，由于我将大群体与其所有子类别进行比较，所以我基本上是将总体与一堆样本进行比较，我相信这会使关系变得依赖。因此，我最终想到了 RMANOVA 和弗里德曼检验，但我不确定我是否真的可以做弗里德曼检验，因为我是将总体与样本进行比较，而不是对多个实例或几个独立的依赖组进行比较。
如果这令人困惑，我深表歉意。我以前没有在这里写过。]]></description>
      <guid>https://stats.stackexchange.com/questions/635678/what-test-do-i-use-when-comparing-multiple-dependent-groups-that-are-non-paramet</guid>
      <pubDate>Tue, 26 Dec 2023 23:42:53 GMT</pubDate>
    </item>
    <item>
      <title>当您的不变性测试中没有修改索引时，还需要考虑哪些其他措施？</title>
      <link>https://stats.stackexchange.com/questions/635677/what-are-other-measures-to-consider-when-you-dont-have-modification-indices-in</link>
      <description><![CDATA[我有一个考虑纵向不变性测试的问题。
我使用的软件是Mplus，尝试了三种不同规模的应用方式；参考指标法、固定因子法和效应编码法。
在Mplus中，实现效果编码方式时，没有办法得到
当我使用 MODEL CONSTRAINTS: 命令计算时修改索引
因子载荷和项目截距（Mplus 支持告诉我的）。
（我的代码在“模型约束：度量不变性”部分中如下所示）
模型约束：
  LLL1=4-LLL2-LLL3-LLL4；
  !T2L1= 4 - T2L2 - T2L3 - T2L4；
  !T3L1= 4 - T3L2 - T3L3 - T3L4；
  !T4L1= 4 - T4L2 - T4L3 - T4L4；
 

  !所有平均模型约束与配置模型相同
  i1T1= 0 - i2T1 - i3T1 - i4T1；
  i1T2= 0 - i2T2 - i3T2 - i4T2；
  i1T3= 0 - i2T3 - i3T3 - i4T3；
  i1T4= 0 - i2T4 - i3T4 - i4T4；
 

这意味着，据我所知，当我做出决定时，我只有理论来支持我
要释放哪个参数。
或者，我可以考虑其他信息来调整模型吗？
非常感谢您提前的支持。]]></description>
      <guid>https://stats.stackexchange.com/questions/635677/what-are-other-measures-to-consider-when-you-dont-have-modification-indices-in</guid>
      <pubDate>Tue, 26 Dec 2023 23:30:40 GMT</pubDate>
    </item>
    <item>
      <title>如何计算有限混合模型中的HAC标准误差</title>
      <link>https://stats.stackexchange.com/questions/635675/how-to-calculate-hac-standard-error-in-finite-mixture-model</link>
      <description><![CDATA[我有一个面板数据集，我正在使用有限混合模型估计自定义的似然函数。
$$
L_i(\theta)=p\prod^T_tL(y_{it}(\theta)|type1) + (1-p)\prod^T_tL(y_{it}(\theta)|type2)
$$
$$
Log L(\theta)=\sum^N_ilog(L_i(\theta))
$$
如果没有有限混合特征，我们有 $Log L=\sum^N\sum^T log L_{it}(\theta)$
我们可以使用以下公式的平方根来计算 HAC 标准误差：
$$
A^{-1}BA^{-1}
$$
在哪里
$$
A=\frac{\partial^2 Log L(\theta)}{\partial \theta\partial \theta&#39;}
$$
$$
B=\Omega_0+\sum^{m(T)}_{j=1}w(j,m)[\Omega_j+\Omega_j&#39;]
$$
$$w(j,m(T))=1-j/(m(T)+1)$$
$$
\Omega_j=\sum^T_{t=j+1}s_{it}s_{it-j}&#39;, s_{it}=\frac{\partial Log L_{it}(\theta)}{\theta}
$$
要计算 Driscoll 和 Kraay 标准误差，我们可以将 $s_{it}$ 替换为得分向量的聚类总和。
我的数据集有三个级别：个体、群体和治疗。我分别在三个层面上进行估算。对于个体级别数据，我尝试使用 HAC 标准误差，对于组级别数据，我尝试使用 Driscoll 和 Kraay 标准误差，对于治疗级别数据，我使用集群标准误差。
我的问题是，如果我按照上面指定的方式使用有限混合模型，对于个体和群体水平估计，我应该如何计算 HAC 和 D-K 标准误差，具体来说我应该如何计算得分向量（有点）没有 t 维度？]]></description>
      <guid>https://stats.stackexchange.com/questions/635675/how-to-calculate-hac-standard-error-in-finite-mixture-model</guid>
      <pubDate>Tue, 26 Dec 2023 22:57:54 GMT</pubDate>
    </item>
    <item>
      <title>从QQ python获取统计信息[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635673/getting-stats-from-qq-python</link>
      <description><![CDATA[以下是供参考的示例数据集：
导入 pandas 作为 pd
将 numpy 导入为 np
将 statsmodels.api 导入为 sm
随机导入

x = []
对于 [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;] 中的 i：
  对于 [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;] 中的 ii：
    对于 [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;] 中的 iii：
      对于范围内的 _(random.randrange(150,200))：
        x.append([i, ii, iii, np.random.normal(25, 4, 1)[0]])

df = pd.DataFrame(x, columns = [&#39;l_1&#39;,&#39;l_2&#39;,&#39;l_3&#39;,&#39;响应&#39;])

＃ 供测试用
arr1 = df[(df[&#39;l_1&#39;]==&#39;a&#39;) &amp; (df[&#39;l_2&#39;]==&#39;b&#39;) &amp; (df[&#39;l_3&#39;]==&#39;a&#39;)][&#39;响应&#39;]
arr2 = df[(df[&#39;l_1&#39;]==&#39;a&#39;) &amp; (df[&#39;l_2&#39;]==&#39;b&#39;) &amp; (df[&#39;l_3&#39;]==&#39;b&#39;)][&#39;响应&#39;]
sm.qqplot_2samples(arr1, arr2, line=&#39;r&#39;) #很适合

我正在使用层次结构数据构建一个模型，并想确定“l_3”是否是一个重要特征（即，我可以在“l_1”、“l_2”级别建模还是数据的形状在 l_3 级别有所不同）。样本数据集在概念上类似于我的真实数据集 - 每个子组的样本大小不同，每个子组的分布预计是相同的（指数）。我认为 Q-Q 图是比较子组之间分布的最佳方法。问题是我需要为每个子组运行此操作，并且无法自动执行此操作。我认为我无法从 sm.qqplot_2samples 生成统计数据/p 值，所以问题是：

这是一种合适（最合理）的方法吗？
有没有办法在每个子组上进行测试并计算结果统计数据进行比较，而不仅仅是目视检查多个 q-q 图？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635673/getting-stats-from-qq-python</guid>
      <pubDate>Tue, 26 Dec 2023 22:05:06 GMT</pubDate>
    </item>
    <item>
      <title>如何解决推荐系统的“冷启动”问题？</title>
      <link>https://stats.stackexchange.com/questions/635667/how-to-solve-the-cold-start-problem-for-recommender-systems</link>
      <description><![CDATA[假设您正在设计一个推荐系统，冷启动问题有哪些方法。例如，如果您有一个新用户或一个新项目，您如何嵌入它？
如果您学习嵌入，例如使用矩阵分解，则会呈现一个新项目，其中包含电影长度、导演姓名、年份等数据点。您如何从策略上获取更好嵌入所需的数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/635667/how-to-solve-the-cold-start-problem-for-recommender-systems</guid>
      <pubDate>Tue, 26 Dec 2023 19:34:18 GMT</pubDate>
    </item>
    <item>
      <title>对于一个定量自变量和多个定量因变量使用什么分析？</title>
      <link>https://stats.stackexchange.com/questions/635664/what-analysis-to-use-for-one-quantitative-independent-variable-and-multiple-quan</link>
      <description><![CDATA[我的数据基于调查回复。自变量根据评级为 $1$ 到 $5$ 之间的三个 Likert 问题进行聚合（IV 将这三个值相加）并除以 $3$）。四个因变量是 $1$ 到 $5$ 之间的李克特问题。
显而易见（但可能有争议）的解决方案是运行四个简单的线性回归模型，每个因变量一个。然而，我担心的是仅凭偶然就能发现显着的结果。
我研究了多元多元线性回归，但这种分析需要多个 IV，这对我的情况没有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/635664/what-analysis-to-use-for-one-quantitative-independent-variable-and-multiple-quan</guid>
      <pubDate>Tue, 26 Dec 2023 17:38:14 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 网络中的反向传播 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635662/backpropagation-in-lstm-network</link>
      <description><![CDATA[因为我们在 Vanilla RNN 中有消失梯度，而 LSTM 是解决方案，根据一些消息来源，LSTM 也有消失梯度，但它在 LSTM 网络的上下文中不会造成任何问题，因为我们在反向传播期间触及了遗忘门，并且它如果我们有消失梯度并不重要我的问题是我们如何在 LSTM 反向传播中真正达到这个方程？我们有两种方法进行反向传播吗？ （如果我们假设 W 作为串联权重） ]]></description>
      <guid>https://stats.stackexchange.com/questions/635662/backpropagation-in-lstm-network</guid>
      <pubDate>Tue, 26 Dec 2023 16:12:07 GMT</pubDate>
    </item>
    <item>
      <title>使用核密度估计来估计分布之间的距离</title>
      <link>https://stats.stackexchange.com/questions/635658/the-usage-of-kernel-density-estimate-for-distance-between-distributions</link>
      <description><![CDATA[Scipy 的 kde 对象允许集成函数乘以另一个 KDE。我认为这意味着用于估计两个分布之间的距离。据我了解，为了保持一致的度量，在积分之前需要平方根，类似于 $$BC(P,Q)= 给出的 Bhattacharyya 系数的定义\int_\chi\sqrt{p(x)q(x)}dx$$。那么，这个输出是什么？我可以用它来测量分布之间的距离吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635658/the-usage-of-kernel-density-estimate-for-distance-between-distributions</guid>
      <pubDate>Tue, 26 Dec 2023 14:21:51 GMT</pubDate>
    </item>
    <item>
      <title>当基于树的模型通常比线性模型效果更好时，为什么我们要使用线性模型？</title>
      <link>https://stats.stackexchange.com/questions/635642/why-do-we-use-linear-models-when-tree-based-models-often-work-better-than-linear</link>
      <description><![CDATA[在监督机器学习中，特别是在 Kaggle 中，通常会发现树模型通常优于线性模型。即使在基于树的模型中，通常 XGBoost 的性能也优于 RandomForest，而 RandomForest 的性能又优于 DecisionTrees。
如果这不是真的，那么请随时纠正这个假设。
这些只是我的观察，不知何故，很多人都同意这个观点。
为什么我们应该使用线性模型，例如线性回归或逻辑回归？具体来说，什么时候它们的性能不如基于树的模型，并且比基于树的模型有更多的要求？
对于基于树的模型，可以提出关于使用 DecisionTrees 而不是 RandomForest 或 XGBoost 的类似问题。
在某些情况下应该首选线性模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635642/why-do-we-use-linear-models-when-tree-based-models-often-work-better-than-linear</guid>
      <pubDate>Tue, 26 Dec 2023 06:59:42 GMT</pubDate>
    </item>
    <item>
      <title>具有缺失值的向量化线性回归</title>
      <link>https://stats.stackexchange.com/questions/635458/vectorized-linear-regression-with-missing-values</link>
      <description><![CDATA[我有一些关于在矩阵/数组运算期间处理丢失数据的问题。本质上，我正在做一个向量化线性回归，以在一些矩阵/数组运算中执行一堆线性回归。对于形状为 (2, 50, 3) 和 (2, 50) 的随机数据 X_many 和 y_many，我使用以下代码来估计系数矩阵：
X_op = np.einsum(&#39;ikj,ilj-&gt;ilk&#39;, (np.linalg.inv(np.einsum(&#39;ikj,ikl-&gt;ilk)) ijl&#39;，X_many，X_many））），X_many）
Beta_hat = np.einsum(&#39;ikj,ik-&gt;ij&#39;, X_op, y_many)

这里的问题是 X_many 缺少一些值。具体来说，在某些组中，某些变量值是完全不可用的。当我使用这些缺失值运行上面的代码时，矩阵中的整行系数都是 nan 。但是，如果我逐一进行回归，我可以忽略缺失值，估计一组系数，然后假设缺失值系数为 0。这样我仍然可以进行估计，但数据较少，因为一些系数将为 0（参见下面的代码）：
对于 zip 中的 x_i, y_i(X_many, y_many)：
    x_i = x_i[:, np.isfinite(x_i.sum(axis=0))]
    beta_hat_i = np.linalg.inv(x_i.T @ x_i) @ x_i.T @ y_i

有没有办法获得各个运行的系数，但仍然使用数组乘积方法？这让我想到，如果我可以用产生系数 0 的数据来估算缺失值，那么这两个答案将是相同的。插补全 0 不起作用，因为它会导致奇异矩阵错误，因此我决定使用第二好的替代方案，并插补与 y （白噪声）绝对相关性非常低的序列。我也不知道如何生成它，所以我有点暴力地强迫它，它有点工作？
TLDR：如何生成与 y 的相关性恰好为 0 的序列？如果我不能，那么是否有更好的插补方法或者只是一种允许我使用数组点积计算这些系数的方法？
重现结果的代码：
将 numpy 导入为 np
将 statsmodels.api 导入为 sm

# 数据生成
np.随机.种子(42)
人数 = 50
X = np.random.random((n, 2))
X = sm.add_constant(X)
贝塔 = [200, 100, 50]
e = np.random.random(n) * 25
y = np.dot(X, beta) + e

X2 = np.random.random((n, 2))
X2 = sm.add_constant(X2)
β2 = [500, 10, 5]
e2 = np.random.random(n) * 5
y2 = np.dot(X2, beta2) + e

X[:, 1] = np.NaN # 缺失值

X_many = np.array([X, X2])
y_many = np.array([y, y2])

打印（X_many.shape）
打印（y_many.shape）

对于 zip(X_many, y_many) 中的 x_i, y_i：
    x_i = x_i[:, np.isfinite(x_i.sum(axis=0))]
    beta_hat_i = np.linalg.inv(x_i.T @ x_i) @ x_i.T @ y_i
    打印（beta_hat_i）

np.随机.种子(42)
X_many_new = X_many.copy()
噪声 = np.random.normal(0, 1e12, (100, np.isnan(X_many_new).sum()))
X_many_new[np.isnan(X_many_new)] = 噪声[np.argmin(np.abs(np.corrcoef(噪声, y)[-1][:-1]))]

X_op = np.einsum(&#39;ikj,ilj-&gt;ilk&#39;, (np.linalg.inv(np.einsum(&#39;ikj,ikl-&gt;ijl&#39;, X_many_new, X_many_new))), X_many_new)
Beta_hat = np.einsum(&#39;ikj,ik-&gt;ij&#39;, X_op, y_many)
打印（Beta_hat）
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/635458/vectorized-linear-regression-with-missing-values</guid>
      <pubDate>Thu, 21 Dec 2023 21:52:13 GMT</pubDate>
    </item>
    </channel>
</rss>