<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 08 Mar 2024 18:18:25 GMT</lastBuildDate>
    <item>
      <title>是否应该使用整个数据集的迁移学习来调整单个模型？</title>
      <link>https://stats.stackexchange.com/questions/642173/should-transfer-learning-from-the-whole-data-set-be-used-tuning-individual-model</link>
      <description><![CDATA[我正在使用神经网络进行时间序列的异常检测。我的计划是根据历史（基线）数据训练 CNN 或 LSTM 模型，然后应用它来检测新数据流中的异常。有一个共享相同上下文的大型时间序列数据库。我看到两条路：

选项 A：在整个数据集或其代表性样本上训练模型。然后使用迁移学习来调整各个时间序列的模型。我预计不会有什么好处，例如快速调整单个记录的最终模型，所有单个时间序列模型将共享相同的上下文，并且最终调整进度可能会暗示异常值。
选项 B：只需单独处理每个时间序列，因为选项 A 太过分了。

因此这里有一个问题：选择选项A有用吗？我以前从未使用过迁移学习，希望得到实用的见解和评论。]]></description>
      <guid>https://stats.stackexchange.com/questions/642173/should-transfer-learning-from-the-whole-data-set-be-used-tuning-individual-model</guid>
      <pubDate>Fri, 08 Mar 2024 18:09:36 GMT</pubDate>
    </item>
    <item>
      <title>迁移学习期间波动的验证损失和准确性 (ResNet50) - FER+ 数据集</title>
      <link>https://stats.stackexchange.com/questions/642170/fluctuating-validation-loss-accuracy-during-transfer-learning-resnet50-fer</link>
      <description><![CDATA[我正在尝试构建一个用于图像分类的 CNN 模型，更具体地说，使用 FER+ 数据集进行情感分类，但事实证明该模型很难使用。
我尝试了多种模型变体，从“从头开始”到我当前的最佳解决方案 - 迁移学习。到目前为止，我最好的结果来自于使用 ResNet50 或 MobileNetV2 作为我的基础模型以及我自己的自定义可训练头。更具体地说，我截断了基本模型，只冻结前几个块，同时留下最接近头部的块，可训练。到目前为止，这种特征提取和微调的组合已达到 93-95% 的验证准确率（取决于 ResNet50 还是 MobileNetV2）。
虽然这听起来不错，但在训练时会出现问题，其中验证损失和验证损失会增加。尽管尝试进行正则化、向数据生成器添加更多增强功能并在微调时降低学习率，但准确性仍波动很大。下图是我使用 ResNet50 作为基础模型时的训练结果。此外，在混淆矩阵中，您还可以看到它如何从未从测试集中正确预测任何“厌恶”图像，其中包含“厌恶”类中的 20 个图像。此外，无论我使用 ResNet 还是 MobileNet 作为我的基础模型，我似乎仍然在损失和准确度上得到相同的波动。
有关我的模型和训练的一些详细信息：

基础模型：使用“imagenet”权重的 ResNet50 或 MobileNetV2
损失函数：分类交叉熵
优化器：Adam
纪元：100
学习率：0.001



就预处理而言，我重新缩放了图像，而我的最佳结果来自于仅对训练数据应用随机水平翻转。 FER+ 图像的标准灰度为 48x48，因此我将采样上采样到 224x224 并转换为 RGB。我的网络非常深，因此我想减少在小尺寸（例如 1x1、2x2...）上运行的任何卷积实例。
我还应该注意到，数据集本质上是相当不平衡的，这通常需要对类权重进行一些实现，但是，我发现当使用类权重时，我的结果会变得明显更差，验证量减少了 15%-20%准确性以及混淆矩阵的不良结果。下面是训练集的类别分布图。

如何在训练过程中稳定验证损失和准确性？]]></description>
      <guid>https://stats.stackexchange.com/questions/642170/fluctuating-validation-loss-accuracy-during-transfer-learning-resnet50-fer</guid>
      <pubDate>Fri, 08 Mar 2024 17:29:45 GMT</pubDate>
    </item>
    <item>
      <title>我想使用 5 个数据点创建波动率分数</title>
      <link>https://stats.stackexchange.com/questions/642169/i-want-to-create-a-volatility-score-using-5-data-points</link>
      <description><![CDATA[我想使用过去 5 年的活动来衡量客户群的波动性。即 5 年期间按年计算的购买总额。
我计划使用这个公式来计算方差（即找到平方偏差的平均值）。

我想知道这是否是回答这个问题的正确计算方法 - 哪些客户每年波动性最大。我主要看到与证券/股票相关的波动性，但这是一个不同的用例。这是正确的方法还是有更好的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/642169/i-want-to-create-a-volatility-score-using-5-data-points</guid>
      <pubDate>Fri, 08 Mar 2024 17:23:44 GMT</pubDate>
    </item>
    <item>
      <title>我可以找到生成内核指数的显式特征图吗？</title>
      <link>https://stats.stackexchange.com/questions/642167/can-i-find-the-explicit-feature-map-that-generates-exponent-of-a-kernel</link>
      <description><![CDATA[假设我有一个内核 $K$，以及另一个以下形式的内核：
$$
K&#39; = e^K
$$
现在我知道如何证明 K&#39; 是一个内核，我可以使用 $e^x$ 围绕 $0$,
但假设我想找到一个生成 $K&#39;$ 的显式特征图，因为 $\phi(x) $ 生成 $K$。
我该如何做到这一点，或者是否有可能？我正在考虑内核多项式展开的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/642167/can-i-find-the-explicit-feature-map-that-generates-exponent-of-a-kernel</guid>
      <pubDate>Fri, 08 Mar 2024 17:22:02 GMT</pubDate>
    </item>
    <item>
      <title>我应该测试多少个样本才能 95% 确定不存在错误？</title>
      <link>https://stats.stackexchange.com/questions/642165/how-many-samples-should-i-test-to-be-95-sure-that-no-error-exists</link>
      <description><![CDATA[如果我有一百万种产品，我不会容忍其中出现任何错误。我应该测试多少个样本才能 95% 确定不存在错误？
我是统计学新手。我知道您可能需要一些有关分布的假设。但我对此了解不多。有些人做出相应的假设，并请告诉我们可以测试这些假设的方法 - 比如我如何知道分布（如果需要）0。]]></description>
      <guid>https://stats.stackexchange.com/questions/642165/how-many-samples-should-i-test-to-be-95-sure-that-no-error-exists</guid>
      <pubDate>Fri, 08 Mar 2024 16:59:12 GMT</pubDate>
    </item>
    <item>
      <title>使用样本和总体均值/标准差估计大小为 N 的样本的 p 值，使其服从正态分布</title>
      <link>https://stats.stackexchange.com/questions/642164/estimate-the-p-value-for-a-sample-of-size-n-to-come-from-a-normal-distribution-b</link>
      <description><![CDATA[有没有办法检查大小为 N（例如 30）的样本是否来自具有已知总体均值和标准差的正态分布？我想在测试中使用所有可用的信息（样本均值和标准差以及总体均值和标准差）。
我的理解是t检验使用样本标准差，z检验使用总体标准差。我有两个可用的标准差，但我有限的理解是，在测试中使用更多信息会给出更好的估计。]]></description>
      <guid>https://stats.stackexchange.com/questions/642164/estimate-the-p-value-for-a-sample-of-size-n-to-come-from-a-normal-distribution-b</guid>
      <pubDate>Fri, 08 Mar 2024 16:58:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们最大化可能性（对数之和）而不是简单地最大化概率之和？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/642158/why-do-we-maximize-likelihood-sum-of-logs-and-not-simply-maximize-sum-of-proba</link>
      <description><![CDATA[在逻辑回归中，我们找到最大似然估计 - $\max \prod_{i} p(y_i \mid x_i)$。这在实践中意味着最大化对数似然之和。这是有道理的，我了解 MLE。
但是...简单地最大化可能性有什么问题吗？换句话说，如果我们的模型是某个数据集上的简单逻辑回归 $(x_i\in \mathbb{R}^d,y_i \in \{-1,1\}) $，我问的是下面两个优化问题（带日志和不带日志）的区别：
$$\max_{W} \sum_{i : y_i = 1} \log \left(\frac{1}{1+\exp(-W^Tx_i) }\right) + \sum_{i : y_i = -1} \log \left(1 - \frac{1}{1+\exp(-W^Tx_i)}\right)$$
$$\max_{W} \sum_{i : y_i = 1} \left(\frac{1}{1+\exp(-W^Tx_i)}\右) + \sum_{i : y_i = -1} \left(1 - \frac{1}{1+\exp(-W^Tx_i)}\right)$$
我编写了一些简单的代码来训练具有梯度下降的双参数模型（斜率和截距），并且两种方法都有效......除了两件事：

第一个具有更好的损失曲线，似乎对初始化不太敏感，训练速度更快，等等。
我知道没有人真正做到第二个

有人可以给出直观的解释和数学的解释吗？我读过各种关于“评分规则”的博客文章（例如，https://yaroslavvb.blogspot.com /2007/06/log-loss-or-hinge-loss.html），但我还是不明白。 log 在这种情况下具有哪些属性可以使其表现更好？我了解对数损失与交叉熵、MLE 等之间的所有联系；我不明白的是为什么第二个选项（无日志）不好。从实际意义上讲，我对日志将损失范围从 $[0,1]$ 扩展到  有一些模糊的直觉$[-\infty, 0]$。我还有一些直觉，认为准确度（或误差）应该以对数尺度来考虑，因为从 80% 到 90% 的准确度与从 90% 到 95% 的相对改进是相同的。不管怎样，抱歉胡言乱语——我想要一些更强烈的直觉和一些正式的数学/统计数据来支持这一点。
这是对一些非常简单的可分离数据进行第二次（无日志）优化的损失曲线。注意它陷入局部最小值的时间有多长。其他优化只需很少的步骤即可完成。右侧是数据和输出逻辑模型。
 之前用不同的词问过，但这个问题似乎问的是$p(x_i \mid W)$，意思是生成建模而不是分类。最重要的答案是关于概率之和如何对应于“至少一个事件为真”。而不是“所有事件都是真实的”但这似乎不适用于我的情况。如果不出意外的话，两个损失函数（有/没有对数）的全局最小值都对应于完美分类。
另外，其中一条评论说“我不喜欢这种帖子，MLE 在统计上是合理的，但可能性之和则不然”。这是公平的，但我的目标是弄清楚如何向初学者解释事情。我只是告诉他们线性回归，我将能够向他们解释为什么一个“明显的事情”是这样的。在分类中是不好的，这只是表达你想要的损失（训练 $p(y=1\mid x)$ 的模型以输出高概率对于正标签和低概率的负标签）。]]></description>
      <guid>https://stats.stackexchange.com/questions/642158/why-do-we-maximize-likelihood-sum-of-logs-and-not-simply-maximize-sum-of-proba</guid>
      <pubDate>Fri, 08 Mar 2024 16:06:25 GMT</pubDate>
    </item>
    <item>
      <title>是否有现场实验统计功效的最佳方法？</title>
      <link>https://stats.stackexchange.com/questions/642156/is-there-a-best-approach-for-statistical-power-for-field-experiment</link>
      <description><![CDATA[我正在设置一个现场实验，并希望为分析制定一个可靠的计划，因为这就是我在这个过程中感受到压力的地方。我将部署26对陷阱。 13对将在城市森林中，另一半将在乡村森林中。 13 个城市森林点将彼此不同（13 个当地公园），而乡村森林陷阱将放置在森林内（约 35,000 英亩）。我会使用城市地点作为单独的复制品，并希望对乡村陷阱做同样的事情。如果使用分水岭或其他特征在国家森林中明显间隔开，我是否仍然需要汇集 35,000 英亩森林中的所有陷阱进行分析，因为它们位于同一地点？有更好的方法吗？主要问题涉及配对陷阱，但城市/乡村部分是另一个因素。]]></description>
      <guid>https://stats.stackexchange.com/questions/642156/is-there-a-best-approach-for-statistical-power-for-field-experiment</guid>
      <pubDate>Fri, 08 Mar 2024 15:50:24 GMT</pubDate>
    </item>
    <item>
      <title>EM算法中如何定义隐藏数据空间</title>
      <link>https://stats.stackexchange.com/questions/642154/how-do-you-define-hidden-data-space-in-em-algorithm</link>
      <description><![CDATA[如何定义EM算法中的隐藏数据空间？]]></description>
      <guid>https://stats.stackexchange.com/questions/642154/how-do-you-define-hidden-data-space-in-em-algorithm</guid>
      <pubDate>Fri, 08 Mar 2024 15:35:49 GMT</pubDate>
    </item>
    <item>
      <title>解药数据优化问题</title>
      <link>https://stats.stackexchange.com/questions/642153/antidote-data-optimization-problem</link>
      <description><![CDATA[我目前正在阅读论文“Fair clustering through antidote data”查布拉等人。 （2021）。
他们提出了以下优化问题，其中 $V$ 是“解药数据”，$\mathcal{ F}$ 是公平成本，$\mathcal{C}$ 是聚类目标。
$$\begin{alignat}{2}
&amp; \min_{V, \mu} &amp;\qquad&amp;|V| \\
&amp;英石。 &amp;&amp; \mathcal{F}(\mu,U)\leq\alpha \\
&amp;&amp;&amp; \mu=\mathcal{C}(U\ \cup\ V)
\end{alignat}$$
它们还为上述问题提供了以下松弛，其中 $V_s$ 是 $V$ 的最大大小：
$$\begin{alignat}{2}
&amp; \min_{V, \mu} &amp;\qquad&amp;\mathcal{F}(\mu,U) \\
&amp;英石。 &amp;&amp; |V|\leq |V_s| \\
&amp;&amp;&amp; \mu=\mathcal{C}(U\ \cup\ V)
\end{alignat}$$
直观上，我认为第二个问题更容易解决，但我发现很难准确描述原因。究竟什么更容易/以何种方式缓解第一个问题？以及“成本”是多少？那种放松？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642153/antidote-data-optimization-problem</guid>
      <pubDate>Fri, 08 Mar 2024 15:20:35 GMT</pubDate>
    </item>
    <item>
      <title>glmer 在查看所有变量时出现问题</title>
      <link>https://stats.stackexchange.com/questions/642151/glmer-problems-in-seeing-all-variables</link>
      <description><![CDATA[我正在尝试运行二项式 glmm 来了解不同种姓蚂蚁感知的化合物的不同浓度之间的关系。我们有 5 种不同的化合物浓度 (a-e) 和 3 种不同的等级（最小、中值、最大）。我们在 3 个菌落（两个、六个和七个）中进行了测试，看看它们是否对该化合物感兴趣（如果是，则为 1，如果否，则为 0）。我们将 id 列为个人（共有 761 个）。
我们的数据表是这样设置的：

我们使用了 lme4 和 glmer 命令：
m &lt;- glmer(Y ~ Conc * (1 + 种姓|殖民地), data = d, family = 二项式) 摘要(m, corr = FALSE)
当我们运行它时，我们得到的读数是：
 摘要（m，corr = FALSE）
    通过最大似然拟合广义线性混合模型
    （拉普拉斯近似）[glmerMod]
     族：二项式 ( logit )
    公式：Y ~ Conc * (1 + 种姓 | 殖民地)
    数据：d

 AIC BIC logLik 偏差 df.resid
 1067.2 1118.1 -522.6 1045.2 750

缩放残差：
最小 1Q 中值 3Q 最大
 -1.4844 -0.9855 0.7613 1.0076 1.4478

  随机效果：
  组名称方差标准差科尔
   集落（截距） 0.4529 0.6730
    卡斯特梅德 0.4387 0.6624 -1.00
    卡斯特明 0.6416 0.8010 -1.00 1.00
   obs 数量：761，组：Colony，3

 固定效果：
        估计标准。误差z值Pr(&gt;|z|)
 （截距）-0.09754 0.16571 -0.589 0.5561
 浓度 -0.05160 0.23068 -0.224 0.8230
 浓度 0.21758 0.22971 0.947 0.3436
 浓度 0.07658 0.23022 0.333 0.7394
 浓度 0.52070 0.23263 2.238 0.0252 *
 ---
 西尼夫。代码： 0 ‘’ 0.001 ‘’ 0.01 ‘’ 0.05 ‘.’ 0.1 ‘ ’ 1
 优化器（Nelder_Mead）收敛代码：0（OK）
 边界（单数）拟合：参见 help(&#39;isSingular&#39;)

我确实认为浓度 E 与其他浓度有显着不同，但是我们没有看到种姓之间的任何相互作用，并且似乎缺少浓度 A。我不确定是否需要添加额外的代码行获得这些交互比较？我还想知道菌落是否对工蚁对不同浓度的偏好产生影响。我们非常确定种姓在感知力（即他们选择的浓度水平）方面发挥着作用，但我觉得也许我们缺少实现这一点的关键代码。如有任何帮助，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/642151/glmer-problems-in-seeing-all-variables</guid>
      <pubDate>Fri, 08 Mar 2024 14:45:50 GMT</pubDate>
    </item>
    <item>
      <title>我可以通过样本方差比较两个估计值吗？</title>
      <link>https://stats.stackexchange.com/questions/642149/can-i-compare-two-estimates-by-their-sample-variance</link>
      <description><![CDATA[例如，为了估计总体平均值 $\mu$，我得到了两个样本平均值 $\bar{ x}_1$ 和 $\bar{x}_2$ 来自 $ 的两个（独立）数据集分别为 N_1$ 和 $N_2$ 个观测值。
由于无法访问数据集，我被告知样本标准差为 $s_1$ 和 $s_2$ 并询问应该选择哪个样本均值。
我想说这两个估计没有可比性。这是对的吗？ （我的第一个问题）
我的推理如下。
$$s^2 = \frac{1}{N-1}\sum_i (x_i - \bar{x})^2$$
其中 $\bar{x} = \frac{1}{N}\sum_i x_i$。
期望估计量是无偏的意味着我假设 $x_i=\mu + e_i$ 和 $\mathbb{E }[e]=0$。
注入模型，$\bar{x} - \mu = \frac{1}{N}\sum_i e_i$，因此 $s^2 = \frac{1}{N-1}\sum_i (\mu+e_i - \bar{x})^2 = \frac{1}{N-1}\sum_i ( e_i + (\mu - \bar{x}))^2$。
我的结论是，较小的 $s$ 并不意味着较小的 $(\mu-\bar{x})^ 2 美元。
一个相关问题（我的 1-bis 问题）是否有任何方法可以评估“正确性”？两个估计中的哪个？
我的第二个问题是我应该怎样做才能从两个数据集的均值和方差中获得更好的估计？]]></description>
      <guid>https://stats.stackexchange.com/questions/642149/can-i-compare-two-estimates-by-their-sample-variance</guid>
      <pubDate>Fri, 08 Mar 2024 14:09:21 GMT</pubDate>
    </item>
    <item>
      <title>这个谬误的名称以及如何得出结论</title>
      <link>https://stats.stackexchange.com/questions/642144/name-of-this-fallacy-and-how-to-reach-conclusion</link>
      <description><![CDATA[在处理一些人口统计数据时，我陷入了一个无法得出结论的境地（我没有透露实际的数据集以及它涉及的对象，因此我用假设的数据代替它）。

假设我们有两类人； A和B。
我们有两种意识形态/政治观点：Alpha 和 Beta。

确定或加入的个人会员数量如下：
$$\begin{array}{c|c|c|}
 &amp; \text{意识形态-阿尔法} &amp; \text{ 意识形态测试版} \\ \hline
\text{A 组} &amp; 90&amp; 10 \\ \h行
\text{B 组} &amp; 70&amp; 30 \\ \h行
\end{数组}$$
在这种情况下； 新闻来源 1 将数据解释为
&lt;块引用&gt;
“B 组中只有30% 的成员代表意识形态-Beta。 B组成员不想要意识形态Beta”

另一个新闻来源 2 将数据解释为
&lt;块引用&gt;
“大约75%隶属于Ideology Beta成员，得到B组的支持，因此Ideology Beta包含了所属人员的权利和要求社会类别B组”。

现在，我的问题是；哪一个来源值得信任？使用完全相同的民意调查，两个消息来源产生了截然不同的叙述，这令人难以置信的混乱。这两种计算在技术上都是正确的，并且可能部分地显示了事实的不同方面。但我该如何重建真实的故事或从这些数据中得出结论呢？哪一个来源有偏见？或者两种表述都有偏见？这种偏见的名称或文档是什么？
额外问题：
表示此类数据的适当模式应该是什么？
礼貌：我已从此处复制代码以格式化表格https://math.meta.stackexchange.com/questions/4240/how-do-i-insert-a-table-when-asking-a-question]]></description>
      <guid>https://stats.stackexchange.com/questions/642144/name-of-this-fallacy-and-how-to-reach-conclusion</guid>
      <pubDate>Fri, 08 Mar 2024 12:52:31 GMT</pubDate>
    </item>
    <item>
      <title>校准图的 Y 轴：每个 X 的发生率与风险百分比</title>
      <link>https://stats.stackexchange.com/questions/642112/y-axis-of-calibration-plot-incidence-per-x-vs-percentage-at-risk</link>
      <description><![CDATA[我正在考虑通过在 x 轴上绘制风险的第 10 个百分位数与每 100,000 的发生率来显示 cox 比例风险模型的校准有多么错误。对于 x 中的每个 bin，我可以绘制预测发生率和观察到发生率的数据点，以比较它们每 100,000 人的发生率。然而，在文献中似乎更常见的是绘制风险百分比（或经历过该事件的百分比），以便您获得一个很好的 45 度角（理想模型）进行比较。
哪个是更好的选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/642112/y-axis-of-calibration-plot-incidence-per-x-vs-percentage-at-risk</guid>
      <pubDate>Fri, 08 Mar 2024 01:18:00 GMT</pubDate>
    </item>
    <item>
      <title>剂量反应函数估计何时比简单回归更有效？</title>
      <link>https://stats.stackexchange.com/questions/642091/when-does-dose-response-function-estimation-work-better-than-simple-regression</link>
      <description><![CDATA[最近有人问我，剂量反应函数 (DRF) 估计（如 此链接 和 本文）和统计回归方法。因此，我尝试创建一些玩具综合示例，以展示一些回归方法无法估计治疗影响的情况，而 DRF 估计具有这种能力。但我没能找到。
特别是，我创建了此笔记本来测试这两者引用了与线性回归 (LR) 进行比较的方法，并发现以下结果：

在无混杂且没有碰撞器的场景中，没有什么比回归更准确
DRF 估算方法存在偏差/不如我预期的准确
如果我在分析中包含对撞机，将其混淆为混杂因素，那么 DRF 估计方法（仍然有偏差，但更）比 LR 更稳健

鉴于这些发现，我有几个问题。

如果在没有碰撞器的场景中传统回归方法效果更好，那么使用这些方法有什么意义？ （当然，如果用户认为不会出现这种情况，他/她可以执行分析来删除碰撞器）
是否存在 DRF 估计方法比回归方法偏差更小的情况？

欢迎下载并使用我的笔记本，其他一些笔记本示例将不胜感激，谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/642091/when-does-dose-response-function-estimation-work-better-than-simple-regression</guid>
      <pubDate>Thu, 07 Mar 2024 18:31:09 GMT</pubDate>
    </item>
    </channel>
</rss>