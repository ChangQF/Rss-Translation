<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 11 Jan 2025 06:21:30 GMT</lastBuildDate>
    <item>
      <title>贝叶斯后验预测均值比确定性预测更嘈杂吗？</title>
      <link>https://stats.stackexchange.com/questions/659848/bayesian-posterior-predictive-mean-is-noisier-than-deterministic-predictions</link>
      <description><![CDATA[由于复杂性，我使用后验预测均值进行预测，而不是完整的后验预测分布。具体来说，我计算：
$\mathbb{E}[y_* \mid x_*, \mathcal{D}] = \int f(x_*, \theta) p(\theta \mid \mathcal{D}) \, d\theta$，
其中 $f(x_∗ ,θ)$ 是给定参数 $θ$ 的模型输出，而 $p(\theta∣\mathcal{D})$ 是给定数据 $\mathcal{D}$ 的 $θ$ 的后验。
然而，我观察到后验预测均值比完全确定性模型的预测噪声更大。
具体来说：

0% 贝叶斯，（左图）：确定性模型（使用 MSE 训练的 $f(x_*,θ)$）可产生平滑且准确的点预测。
50% 贝叶斯：使用具有固定方差的均值场 VI（即，在 ELBO 中将 MSE 视为“NLL”）会在均值预测中引入一些噪声。
100% 贝叶斯，（右图）：允许模型预测均值和方差 σ(x)（即，在 ELBO 中使用适当的 NLL）会进一步增加噪声。

确定性与贝叶斯（均值）预测的比较


这种平均预测的退化是贝叶斯建模中已知的问题吗？如果是，这种行为的根本原因是什么，如何解决？]]></description>
      <guid>https://stats.stackexchange.com/questions/659848/bayesian-posterior-predictive-mean-is-noisier-than-deterministic-predictions</guid>
      <pubDate>Sat, 11 Jan 2025 00:21:13 GMT</pubDate>
    </item>
    <item>
      <title>使用图查看标量样本和矢量样本是否具有线性关系</title>
      <link>https://stats.stackexchange.com/questions/659847/using-plot-to-see-if-a-scalar-sample-and-a-vector-sample-has-a-linear-relationsh</link>
      <description><![CDATA[假设我们有 $N$ 个样本，每个样本都是一个具有 $p+1$ 个分量的向量：
\begin{equation*}
(y_i, x_{i,1}, \cdots, x_{i, p}) = (y, \mathbf x_i) \quad (1\le i\le N)。
\end{equation*&gt;
通过减去平均值，我们可以假设 $y$ 和 $\mathbf x$ 的平均值 $0$ 和 $\mathbf 0$。
我们进一步假设 $y$ 和 $\mathbf x$ 服从正态分布。
假设我想测试 $y$ 和 $\mathbf x$ 是否具有线性关系。
如果 $\mathbf x$ 是标量，我们可以绘制 $(x_i, y_i)$ ($1\le i\le N$) 的散点图。
但现在 $\mathbf x$ 是一个向量。如果我使用最小二乘法找到了一个向量 $\mathbf a$
，该向量最小化 $$ \sum_{i=1}^{N} (y_i - \langle \mathbf a, \mathbf x_i \rangle ) ^2, $$
，并且我发现 $ (\langle \mathbf a, \mathbf x_i \rangle, y_i) $ 的图并不集中在直线 $y=x$ 附近，
那么我是否可以拒绝承认 $y$ 和 $\mathbf x$ 之间存在线性关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/659847/using-plot-to-see-if-a-scalar-sample-and-a-vector-sample-has-a-linear-relationsh</guid>
      <pubDate>Fri, 10 Jan 2025 23:57:28 GMT</pubDate>
    </item>
    <item>
      <title>Yahoo! Webscope ydata-frontpage-todaymodule-clicks-v1_0 数据集中出现意外功能 ID [关闭]</title>
      <link>https://stats.stackexchange.com/questions/659846/unexpected-feature-id-in-yahoo-webscope-ydata-frontpage-todaymodule-clicks-v1-0</link>
      <description><![CDATA[我正在使用 Yahoo! Webscope 数据集 ydata-frontpage-todaymodule-clicks-v1_0（具体来说，是 2009 年 5 月前十天的点击日志）。数据集描述指出，每个用户和文章都有 6 个特征，编号为 1 到 6。特征 #1 是一个常数（始终为 1），特征 #2-6 是通过联合分析构建的。格式为 feature_id:feature_value 对。
但是，我发现有些文章的特征值为 feature_id = 7。下面是出现这种情况的示例行：

1241196300 109522 0 |user 2:0.008078 3:0.005109 4:0.000172 5:0.007422 6:0.979220 1:1.000000 |109523 2:0.316894 3:0.000023 4:0.210890 5:0.198013 6:0.274180 1:1.000000 |109498 2:0.306008 3:0.000450 4:0.077048 5:0.230439 6:0.386055 1:1.000000 |109509 2:0.306008 3:0.000450 4:0.077048 5:0.230439 6:0.386055 1:1.000000 |109508 2:0.264355 3:0.000012 4:0.037393 5:0.420649 6:0.277591 1:1.000000 |109473 2:0.295442 3:0.000014 4:0.135191 5:0.292304 6:0.277050 1:1.000000 |109524 2:0.274868 3:0.000032 4:0.046639 5:0.362209 6:0.316252 1:1.000000 |109527 2:0.375829 3:0.000025 4:0.033041 5:0.349637 6:0.241468 1:1.000000 |109520 2:0.016328 3:0.953419 4:0.000538 5:0.008263 6:0.021452 1:1.000000 |109503 2:0.306008 3:0.000450 4:0.077048 5:0.230439 6:0.386055 1:1.000000 |109510 2:0.287909 3:0.000025 4:0.008983 5:0.511333 6:0.191751 1:1.000000 |109526 2:0.432433 3:0.000002 4:0.069055 5:0.351774 6:0.146736 1:1.000000 |109495 2:0.313277 3:0.000125 4:0.018413 5:0.410555 6:0.257630 1:1.000000 |109506 2:0.264355 3:0.000012 4:0.037393 5:0.420649 6:0.277591 1:1.000000 |109512 2:0.297322 3:0.000025 4:0.034951 5:0.413566 6:0.254137 1:1.000000 |109511 2:0.381149 3:0.000129 4:0.060038 5:0.269129 6:0.289554 1:1.000000 |109514 2:0.297750 3:0.000013 4:0.011603 5:0.512182 6:0.178452 1:1.000000 |109528 7:1.000000 |109522 2:0.214605 3:0.000037 4:0.410493 5:0.097704 6:0.277162 1:1.000000 |109515 2:0.281649 3:0.000173 4:0.195994 5:0.151003 6:0.371182 1:1.000000 |109525 2:0.306008 3:0.000450 4:0.077048 5:0.230439 6:0.386055 1:1.000000 |109513 2:0.211406 3:0.000036 4:0.002773 5:0.569886 6:0.215900 1:1.000000

具体来说，article_id=109528的文章有特征7:1.000000，这是意料之外的。有没有其他人遇到过此数据集的问题？对于为什么会出现这种差异以及在解析数据时如何处理这种差异，您有什么见解吗？这是否表明数据集中可能存在更广泛的问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659846/unexpected-feature-id-in-yahoo-webscope-ydata-frontpage-todaymodule-clicks-v1-0</guid>
      <pubDate>Fri, 10 Jan 2025 23:56:52 GMT</pubDate>
    </item>
    <item>
      <title>理解相互矛盾的 Cox 回归结果</title>
      <link>https://stats.stackexchange.com/questions/659845/understanding-conflicting-cox-regression-results</link>
      <description><![CDATA[我有一个数据集，其中我使用 Cox 模型检查生存时间与血清胆固醇水平之间的关联，同时调整 BMI 和性别。我以两种不同的方式进行了分析，但难以协调两种不同方法之间的结果：
方法 1：对整个数据集进行 Cox 回归，以生存为结果，以胆固醇、BMI 和性别为预测变量。
coxph(Surv(time = survivor_time, event = censor_status) ~ cholesterol + BMI + sex, data = df)
这导致输出结果为胆固醇与生存时间相关 (P &lt; 0.05)。 BMI 和性别的风险比并不显著，这表明胆固醇与生存时间相关，与本分析中的性别和 BMI 无关（解释正确吗？）

方法 2：Cox 回归，同时将数据集分层为男性和女性队列，而不使用性别作为预测变量：
#女性患者
coxph(Surv(time = survivor_time, event = censor_status) ~ cholesterol + BMI, data = filter(df, sex == &quot;F&quot;))

#男性患者
coxph(Surv(time = survivor_time, event = censor_status) ~ cholesterol + BMI, data = filter(df, sex == &quot;M&quot;))

这导致输出结果为女性患者的胆固醇与生存时间之间没有关联队列，但在男性队列中胆固醇与生存率之间确实存在关联。这难道不表明性别确实是决定胆固醇是否与生存时间相关的一个因素吗？为什么方法 1（其中性别被作为整个数据集中的预测变量）表明胆固醇与生存率相关，而与性别无关？]]></description>
      <guid>https://stats.stackexchange.com/questions/659845/understanding-conflicting-cox-regression-results</guid>
      <pubDate>Fri, 10 Jan 2025 23:37:46 GMT</pubDate>
    </item>
    <item>
      <title>修改主成分分析来与另一个变量相关？</title>
      <link>https://stats.stackexchange.com/questions/659844/modifying-principal-component-analysis-to-correlate-to-another-variable</link>
      <description><![CDATA[主成分分析擅长找到最能描述数据集的简化变量集。是否有类似的方法可以找到最能描述另一个变量的简化变量集？例如，如果我有身高、体重和年龄的数据集，PCA 可以给我 1-2 个可以大致预测身高、体重和年龄的变量。但如果我想要身高、体重和年龄的变换以产生 2 个最能预测力量的变量，该怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/659844/modifying-principal-component-analysis-to-correlate-to-another-variable</guid>
      <pubDate>Fri, 10 Jan 2025 22:29:48 GMT</pubDate>
    </item>
    <item>
      <title>BIBD 块内分析问题</title>
      <link>https://stats.stackexchange.com/questions/659837/bibd-intrablock-analysis-issue</link>
      <description><![CDATA[我很难理解 Peter W. M. John 所著《实验的统计设计和分析》中平衡不完全区组设计部分提出的这个问题。问题如附图所示。
示例问题第 1 部分
示例问题第 2 部分
为了便于复制我的问题，下面是值表，其中每行是一个块，每组 4 个连续行组成一个组：



处理
值
处理
值




A
38
B
29


C
49
D
&lt; td&gt;28


E
32
F
29


G
64
H
32


A
37
C
27


B
37
H
50


D
90
E
89


F
28
G
71


A
15
D
23


B
 47
G
64


C
35
F
39


E
22
H
18


A
3
E
13


B&lt; /td&gt;
45
C
36


D
11
G
24


F
39
H
37


A
23
F
39

&lt; tr&gt;
B
21
D
14


C
18
H
10


E
23
G
53


A
66
G
68


B
23
F
46


C
22
E
28


D
23
H
39


A
28
H
30


B
10
E
40


C
32
G
33


D
18
F
23



我在计算块的 SS（块内）时遇到了特别困难。根据前面的块内分析部分，方程应该是：
$$
\begin{equation}
k^{-1}\sum_{j}B_j^2-G^2/N
\end{equation}
$$
其中 k 是块的图，B 是每个块的治疗观察值的总和，G 是治疗观察值的全局总和，N 是观察值总数。我只能得到 ~15,405。
我很难看出我哪里做错了。治疗 SS 的块内方程运行良好，块间分析中调整后的块 SS 也运行良好。我还通过计算值获得了正确的块内错误！我感觉我漏掉了某个公式，但仔细阅读了整章后，我还是不知道在哪里。任何帮助我都感激不尽。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659837/bibd-intrablock-analysis-issue</guid>
      <pubDate>Fri, 10 Jan 2025 18:28:21 GMT</pubDate>
    </item>
    <item>
      <title>竞争风险情景中 Kaplan-Meier 估计的偏差</title>
      <link>https://stats.stackexchange.com/questions/659822/bias-in-kaplan-meier-estimate-in-competing-risk-scenario</link>
      <description><![CDATA[在阅读了其他地方的大量材料和这里的帖子后，我仍然无法完全理解为什么在竞争风险的情况下，基于 Kaplan-Meier 的累积风险估计（针对特定事件）通常被认为是“有偏差的”或“错误的”，并且累积发生率函数是首选。我理解，如果其他竞争事件（例如死亡和主要关注的事件）不是独立的（共享共同的预测因子），这可能是偏见的来源并影响估计的可解释性。然而，基于 KM 的估计原则上被认为是有偏差的，即使不同事件的发生不能用相同的预测因子来解释。
从 KM 得出的累积概率似乎反映了事件特定的风险，这可能比代表 CIF 所代表的各种影响的数量更有趣。例如，在 Covid 大流行期间，总体死亡率较高，因此竞争风险的负担更高，这将反映在 CIF 中。这似乎不是对事件特定风险负担非常有用的估计。]]></description>
      <guid>https://stats.stackexchange.com/questions/659822/bias-in-kaplan-meier-estimate-in-competing-risk-scenario</guid>
      <pubDate>Fri, 10 Jan 2025 12:42:05 GMT</pubDate>
    </item>
    <item>
      <title>相关性/巧合性测量中的统计数据[重复]</title>
      <link>https://stats.stackexchange.com/questions/659798/statistics-in-correlation-coincidence-measurement</link>
      <description><![CDATA[我从事实验物理工作，对所谓的“巧合”测量中使用的某些统计模型感到困惑。
为了说明背景，我们有可以检测单个粒子（在我的情况下是光子）存在的探测器。您可以想象一束连续的光子撞击探测器。总检测周期被分成非常小的时间段，当它检测到光子撞击传感器时，它会在任何给定的时间段输出 1，如果没有，则输出 0。在某些光源（例如激光器）中，数字统计遵循泊松分布 - 在任何时间段检测到光子的概率与所有其他时间段的概率无关。对于一个探测器，这是一个“单个”测量。当我们有两个探测器和两个光源时，“巧合”事件是每个探测器在同一时间箱中输出 1，即它们同时在各自的路径中检测到一个光子（以时间箱的分辨率为准）。
以下是问题的概述：
假设我们有两个探测器 $1$ 和 $2$。每个探测器都有一个光源输出一束光子。每个光源和每个探测器彼此独立。将每个探测器上的时间段称为$t_1,\ldots,t_N$（所有时间段的持续时间相同，即$t_1=t_2=\cdots=t_n=\Delta t$），总实验时间窗口称为$T=\sum^{N}_{i=1}t_i$。假设每个光源都遵循泊松统计，并且每个探测器实验窗口中的总计数平均值为 $R_1T$ 和 $R_2T$（$R_1$ 和 $R_2$ 是光源已知的固定发射率）。此外，假设 $R_1\Delta t\ll1$ 和 $R_2\Delta t\ll1$，因此我们几乎总是在任何时间段内得到 $0$ 或 $1$。另外假设 $T/\Delta t$ 非常大。我将在每个探测器上随机获得 $1$ 和 $0$ 的组合，如果我多次重复实验，每个探测器上的总计数将有一个大致等于平均值​​平方根的标准差。
我的问题是，巧合计数（当两个探测器在同一时间段上记录 $1$ 时为 $1$，否则为 $0$）是否也遵循泊松分布？我想我知道如何找到实验的平均巧合计数，应该是
$R_CT=T\Delta tR_1R_2$
（$R_C$ 是巧合中的固定计数率）。在许多论文中，巧合计数被假定具有泊松统计量，这是有道理的，因为获得巧合计数的概率在不同时间应该是彼此独立的。
但是，我也可以将巧合计数的数量表示为每个探测器上的单个计数的乘积，其中单个计数本身是泊松的 - 但两个泊松的乘积不是泊松的。
编辑：
为进一步说明，预期的巧合计数如下
$C=R_CT=(\Delta t/T)S_1S_2$
其中 $S_1=R_1T$ 和 $S_2=R_2T$，并且 $S$ 对应于探测器上的预期单数计数。
有人告诉我，一旦我在 $T$ 时间段内测量了 $S_1$ 和 $S_2$，我就可以简单地使用标准误差传播技术 (https://en.wikipedia.org/wiki/Propagation_of_uncertainty#:~:text=.-,Simplification,-%5Bedit%5D)（并假设单数大致为泊松分布）来获得$C$ 中的不确定性，但是我不确定这如何量化巧合事件的统计数据，因为这个新的不确定性似乎有一个 $\sqrt{C(\Delta t/T)(S_1+S_2)}$ 的因素，而不是 $\sqrt{C}$。]]></description>
      <guid>https://stats.stackexchange.com/questions/659798/statistics-in-correlation-coincidence-measurement</guid>
      <pubDate>Thu, 09 Jan 2025 21:09:36 GMT</pubDate>
    </item>
    <item>
      <title>非线性方程的曲线拟合[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659797/curve-fitting-of-non-linear-equation</link>
      <description><![CDATA[
我正在研究通过传输线法 (TLM) 测量获得的实验电流-电压 (I-V) 数据。我的目标是将这些数据拟合到参考资料中公式 (7) 描述的理论模型中。该方程涉及一个隐式关系，其中电压 𝑉1 ​ 是一个必须通过求解两个耦合方程来确定的参数。
具体来说：

该模型依赖于拟合参数，包括 V1 ​ ，它没有明确定义，必须从给定的方程中迭代或数值求解。

我的目标是通过将模型准确地拟合到实验 I-V 数据来提取这些拟合参数。


我的问题：

当模型涉及隐式方程或 V1 等参数时，拟合实验数据的最佳方法是什么？

考虑到每次拟合迭代时都需要求解 V1，我如何有效地实现这个拟合过程？

如果能提供关于拟合策略、推荐算法或代码的任何指导，我将不胜感激可以帮助解决这个问题的例子。


提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/659797/curve-fitting-of-non-linear-equation</guid>
      <pubDate>Thu, 09 Jan 2025 21:04:49 GMT</pubDate>
    </item>
    <item>
      <title>（Fisher z）相关性的平均值与平均值的相关性</title>
      <link>https://stats.stackexchange.com/questions/659787/mean-of-fisher-z-correlations-vs-correlation-of-means</link>
      <description><![CDATA[这可能是一个基本问题，但我花了很长时间试图找到答案，但通常都失败了。
我进行了一项实验，尝试使用新方法多次复制固定变量 X0=[1,2,3,4,5,6,7,8,9,10]，这会产生新变量 X1、X2、...Xi。
评估复制率的一种方法是计算 X0 与 X1...Xi 的分段平均值之间的相关性，从而得到十个均值。我们称之为 r_means。
另一种方法是首先计算 X0 与每个复制 X1...Xi 之间的相关性，然后对这些相关性求平均值（使用或不使用 Fisher z 变换并返回）。那将是 Mean_r
我不断得到非常不同的值 r_means 和 Mean_r，但我无法找出导致差异的原因。我意识到 X1、...Xi 的方差以某种方式参与其中，但无法找到具体原因。
是否有人知道 r_means 和 Mean_r 之间（潜在）差异所涉及的因素？
更新。根据要求，我提供了更多详细信息。我正在开展蒙特卡罗模拟研究，X0 是真实参数的向量。我使用这些参数来模拟数据，然后使用旨在恢复 X0 的新模型对其进行分析。这些方法通过 i 次模拟估计 X1...Xi。
我已经检查了覆盖范围，但我真正感兴趣的是参数的排序，因此我查看了 X0 与每个（或平均）X1...Xi 之间的相关性。Mean_r 和 r_means 是否显示差异？了解发生这种情况的原因可能会对评估模型的问题提供见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/659787/mean-of-fisher-z-correlations-vs-correlation-of-means</guid>
      <pubDate>Thu, 09 Jan 2025 17:00:20 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归假设和 Box-Tidwell 检验</title>
      <link>https://stats.stackexchange.com/questions/659774/logistic-regression-assumptions-and-box-tidwell-test</link>
      <description><![CDATA[我正在做一个逻辑回归，它只包括两个数字独立变量（年龄和受影响器官的总和）和其他分类变量。当我对这些数字变量执行 Box-Tidwell 检验时，它告诉我结果的对数和变量“器官总和 (p &lt;0.05)”之间没有线性关系。
我的问题是，我是否绝对需要从回归中删除这个变量，或者我是否可以使用另一种技术。我刚刚读到样条应该是一个选项，我已经执行了。然而，我没有在科学工作中解释和报告这一点的经验。我甚至读过一篇关于诊所样条的《自然》文章，但我发现很难理解。你能帮我吗？
esplenicos$Angiogenic &lt;- relevel(esplenicos$Angiogenic, ref = &quot;Yes&quot;)
levels(esplenicos$Angiogenic)

regressão_logistica &lt;- glm(Angiogenic ~ Breed2 + Age + Sex + Number_cavities + 
SumAffected_organs, data = esplenicos,
family = binomial())

esplenicos$logAgeInt &lt;- log(esplenicos$Age) * esplenicos$Age
esplenicos$logSumaffectedorganInt &lt;- log(esplenicos$SumAffected_organs）*      
esplenicos$SumAffected_organs

regressão_logistica2 &lt;- glm(血管生成 ~ Breed2 + 年龄 + SumAffected_organs+ 性别 +      
Number_cavities + logSumaffectedorganInt + logAgeInt，数据 = esplenicos，
                   家庭=二项式())
摘要（regressão_logistica2）

logito &lt;- regressão_logistica$linear.predictors
esplenicos$logito &lt;-logito
一瞥（esplenicos）

ggplot(esplenicos, aes(logito, SumAffected_organs)) +
geom_point（大小= 0.5，阿尔法= 0.5） +
geom_smooth(method = &quot;loess&quot;) +
theme_classic()


我包括了 Box-Tidwell 检验的输出，该检验对器官总和具有显著性，以及结果与器官总和变量的对数图。

]]></description>
      <guid>https://stats.stackexchange.com/questions/659774/logistic-regression-assumptions-and-box-tidwell-test</guid>
      <pubDate>Thu, 09 Jan 2025 14:53:13 GMT</pubDate>
    </item>
    <item>
      <title>使用加权逻辑回归对重复数据进行误差估计的校正因子</title>
      <link>https://stats.stackexchange.com/questions/659641/correcting-factor-for-error-estimation-with-weighted-logistic-regression-on-dupl</link>
      <description><![CDATA[假设一个数据集被复制，但第一个副本被分配了一组概率权重（与采样无关），而第二个副本具有另一组权重，其中权重与我们复制数据的事实无关。 主要问题：

我是否应该将每个权重乘以 1/2 以纠正数据重复？

上下文
假设对于每个观察值 1 到 N，您有概率估计 $p_a=P(race=a)$、$p_b=P(race=b)$、$p_c=P(race=c)$，其中 $\sum_{r=\{a,b,c\}}p_r=1$ 和一些二元结果变量 $y$，并且我们希望估计逻辑回归 $\text{logit }y\sim \beta_0 + \beta_1 D^{r}+X\beta$ 其中 X 是一组控制因素，$D^r$ 是治疗组的虚拟变量（假设 &#39;b&#39; 为治疗组，&#39;a&#39; 为对照组）。
为此，我上面的一些高阶专家估计了一个加权逻辑回归，其中
\begin{align}
\text{logit }\begin{pmatrix}
y \\
y \\
\end{pmatrix} &amp;= \beta_0+\beta_1\begin{pmatrix}
D^{b} \\
D^{b} \\
\end{pmatrix}
+ \begin{pmatrix} X \\ X\\ \end{pmatrix} \beta
\end{align&gt;
其中 $$\text{weights} =\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$$ 且 $D^b_{1\dots N}$=1 且 $D^b_{(N+1)\dots 2N}=0$（基本上，第一个 1...N 堆栈具有虚拟 $D^b=1$ 且第二个 (N+1)...2N 具有虚拟 $D^b=0$。
问题：通常，每个观测值的权重为 1/2 应该可以解决因重复数据集而产生的误差估计问题。这是否仍然适用于权重的使用。例如，我可以这样做 $\text{weights} =\frac{1}{2}\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$ 还是这些权重没有意义？
请原谅我潦草的符号，希望它足以传达这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/659641/correcting-factor-for-error-estimation-with-weighted-logistic-regression-on-dupl</guid>
      <pubDate>Tue, 07 Jan 2025 04:28:49 GMT</pubDate>
    </item>
    <item>
      <title>glmmTMB 在我的模型中返回以下消息，且不包含交互：“从秩不足条件模型中删除列”</title>
      <link>https://stats.stackexchange.com/questions/659838/glmmtmb-returns-the-following-message-in-my-model-without-interactions-droppin</link>
      <description><![CDATA[我正在运行的模型如下：
glmmTMB(data=bd, prop_inf~ais+grupo+(1|ano)+(1|bloque)+(1|parcela), 
family=&quot;tweedie&quot;)

prop_inf 是一个比例，值范围从 0 到 1，所有解释变量都是分类变量。问题不在于随机效应因素，因为如果我运行模型 prop_inf ~ ais + grupo，glmmTMB 仍然会返回错误。变量“ais”有 31 个级别，分布在 3 个“grupo”级别中：10 个“ais”级别属于“grupo_1”级别，另外 10 个“ais”级别属于“grupo_2”级别，其余 11 个“ais”级别属于“grupo_3”级别。
我想执行 Anova 检验（我知道我需要使用“car”库）来评估因素“ais”和“grupo”的重要性。运行 Anova(model) 时，car 库不会返回因素“grupo”的 Chisq 值。]]></description>
      <guid>https://stats.stackexchange.com/questions/659838/glmmtmb-returns-the-following-message-in-my-model-without-interactions-droppin</guid>
      <pubDate>Mon, 06 Jan 2025 16:29:10 GMT</pubDate>
    </item>
    <item>
      <title>估计量与合并 OLS/随机效应之间</title>
      <link>https://stats.stackexchange.com/questions/659235/between-estimator-versus-pooled-ols-random-effects</link>
      <description><![CDATA[例如，我熟悉 Hausman 检验可以帮助我选择固定效应模型和随机效应模型中哪个更好。但是，是否有一个检验可以帮助我在估计模型（例如，在 R 中使用 plm(y~x, model=&quot;between&quot;) 实现）与池化 OLS（plm(y~x, model=&quot;pooling&quot;)）和随机效应模型（plm(y~x, model=&quot;random&quot;)）之间进行选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/659235/between-estimator-versus-pooled-ols-random-effects</guid>
      <pubDate>Thu, 26 Dec 2024 16:59:24 GMT</pubDate>
    </item>
    <item>
      <title>最大熵是我正在寻找的解决方案吗（熵的表征是否最适合我的情况）？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659197/is-maximum-entropy-the-solution-i-am-looking-for-is-the-characterization-of-ent</link>
      <description><![CDATA[我的最终目标是后验预测。我讨厌做假设，也讨厌为了“稳健性”而丢弃/过滤/浪费数据。
为此，我需要弄清楚我的可能性模型。我认为最大熵原理类似于无差异原理。因为我什么都不知道，所以我不想把我的偏见放在我的模型上。
我不太喜欢做假设，但我更讨厌 Winsorizing 等。
例如，我正在计算一个班级的后验预测，这个班级参加了一场有 25 道多项选择题的考试（有些缺席），我想知道缺席者在同一场考试中的得分如何（我也想了解考试是容易还是困难，老师做得好不好，班级是聪明还是有挑战性的，评分是马虎、宽松、严格还是公正）。
支持度 (Ω) 为 0、1、2..... 25。我最确定的是学生的分数呈正相关。他们知道考试即将来临，所以自信的人会去参加考试，他们都有同一位老师，所以如果老师很优秀（一个好的指标就是考试成绩好），所有人的分数都会提高。出于各种原因，我相信它们是正相关的（如果我知道一个人做得很好，我相信其他人做得比我原本相信的要好），但我无法量化这种信念（我不知道这种关系是线性的、指数的、二次的、三次的等等）。
我希望能够使用具有不同支持（不同的测试分数范围或不同的目的）的相同方法。
后验预测将是
$$p(x_{\text{new}} | x_{\text{old}}) = \sum_{\mu} \sum_{\sigma} p(x_{\text{new}} | \mu, \sigma, x_{\text{old}}) \cdot p(\mu, \sigma | x_{\text{old}})$$
其中
$$p(\mu, \sigma | x_{\text{old}})$$
如果我们假设独立性，则将是 μ 和 σ 后验的乘积（我宁愿不假设参数独立性，但这是我最不担心的。我最担心的是观测的独立性$x_{\text{old}}$
对于 μ，我对连续截断正态分布和连续均匀分布 [0-25] 没有任何疑虑
μ 的可能性将是$$\frac{\phi\left(\frac{x - \mu}{\sigma}\right)}{\sigma \left( \Phi\left(\frac{25 - \mu}{\sigma}\right) - \Phi\left(\frac{0 - \mu}{\sigma}\right)\right)}$$ 而先前的平原将只是一个统一的 U[0,25]
我对 σ 的可能性有疑问，它应该是从 0 到无穷大的截断正态分布还是伽马？至于先验，它将是一个平坦的非信息先验（从 0 到无穷大的退化均匀分布）。
真正的问题是 $$p(x_{\text{new}} | \mu, \sigma, x_{\text{old}})$$
我知道支持，并且它应该是离散的，例如可能性 $$P(X = x\vert \mu,\sigma,\Omega) = \frac{e^{-\frac{(x-\mu)^2}{2\sigma^2}}}{\sum_{y \in \Omega} e^{-\frac{(y-\mu)^2}{2\sigma^2}}}$$ 具有我想要的支持，但它似乎没有捕捉到与旧观察的相关性，它似乎需要具有 $x_{\text{old}}$ 作为变量，但事实并非如此。
当我甚至不知道观察结果如何相关时，我应该使用什么可能性以及如何计算它？]]></description>
      <guid>https://stats.stackexchange.com/questions/659197/is-maximum-entropy-the-solution-i-am-looking-for-is-the-characterization-of-ent</guid>
      <pubDate>Wed, 25 Dec 2024 15:23:50 GMT</pubDate>
    </item>
    </channel>
</rss>