<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 May 2024 01:06:04 GMT</lastBuildDate>
    <item>
      <title>线性回归中的 Z 分数和标准误差</title>
      <link>https://stats.stackexchange.com/questions/648177/z-score-and-standard-error-in-linear-regression</link>
      <description><![CDATA[我正在阅读《统计学习要素》，在线性回归章节中，我无法理解以下内容：
我们已经从 $N$ 个数据点估计了回归参数 $\beta_1, ..., \beta_p$。
已确定 $\hat{\beta} \sim N(\beta, (X^T X)^{-1}\sigma^2)$，其中 $\beta$ 是 $\hat{\beta}$ 的真实值，$X$ 是数据矩阵。 $\sigma^2$ 是 $Y$ 相对于其均值的方差，即 $Y = X\beta + \epsilon$, $\epsilon \sim N(0, \sigma^2)$。
现在，作者计算 $z_j = \frac{\hat{\beta}_j}{\hat{\sigma}\sqrt{(X^TX)^{-1}_{jj}}}$。
此外，方差估计为 $\hat{\sigma}^2 = \frac{1}{N-p-1}RSS$。
现在，这或多或少清楚了，但是我应该也通过将 $\hat{\beta}_j$ 除以其标准误差来获得相同的 $z_j$。换句话说，它应该成立
$SE(\hat{\beta}_j) = \hat{\sigma}\sqrt{(X^TX)^{-1}_{jj}}$。但相反，我得到了以下结果：
$SE(\hat{\beta}_j) = \frac{\sqrt{(X^TX)^{-1}_{jj}}\sigma}{\sqrt{N}} = \frac{\sqrt{(X^TX)^{-1}_{jj}(N-p-1)}\hat{\sigma}}{\sqrt{N}}$
其中我使用了 $(N-p-1)\hat{\sigma} \sim \sigma^2\mathcal{X}^2_{N-p-1}$
因此 $\sqrt{N-p-1}$ 因子有些不对劲，我担心我从根本上误解了一些东西这里。]]></description>
      <guid>https://stats.stackexchange.com/questions/648177/z-score-and-standard-error-in-linear-regression</guid>
      <pubDate>Wed, 29 May 2024 00:19:01 GMT</pubDate>
    </item>
    <item>
      <title>GLS 与随机效应相结合</title>
      <link>https://stats.stackexchange.com/questions/648176/gls-combined-with-random-effect</link>
      <description><![CDATA[我的数据由每个个体 (ID) 的重复测量 (持续时间) 组成。固定效应是栖息地，目标是查看持续时间是否取决于栖息地。但是，方差似乎因个体而异，即某些个体的持续时间始终大致相同，而对于其他个体，差异很大。
对 ID 使用随机效应 (以解释每个个体的不同截距) 加上广义最小二乘 (以解释每个个体的不同变异性) 是否合理？
在 R 中，我使用包 nmle，模型的形式如下：
model &lt;- lme( 
fixed = Duration ~ Habitat, 
random = ~ 1 | ID, 
weights = varIdent(form = ~ 1 | ID), 
data = dataset 
)

使用这种方法，它还会消耗与个体数量一样多的自由度。是否有其他方法仅使用 1 个参数来解释方差中的这种变化，例如方差的方差参数，就像随机效应对截距的作用一样？还是我在这里想得太多/想得太少了。
使用上述模型，残差看起来确实不错。但我不确定估计值、不确定性和理由。对于报告，我可以将此模型与 ANOVA 中的空模型进行比较，两者都采用 ML 方法，并报告似然比和 $p$ 值吗？我还可以使用 MuMiN::r.squaredGLMM 中的伪 $R^2$ 和摘要表中的标准误差吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648176/gls-combined-with-random-effect</guid>
      <pubDate>Tue, 28 May 2024 23:09:42 GMT</pubDate>
    </item>
    <item>
      <title>关于使用罕见事件和类别不平衡对二元结果进行建模的建议</title>
      <link>https://stats.stackexchange.com/questions/648175/advice-on-modeling-binary-outcome-with-rare-events-and-class-imbalance</link>
      <description><![CDATA[我正在开展一项分析，以确定导致糖尿病患者开始服用两类药物之一的因素。
我最初尝试使用逻辑回归对数据进行建模，但遇到了一些模型拟合问题。
作为参考，我的模型和输出如下：
调用：
glm(formula = metformin ~ centered_age + rfemale + centered_mrcreat * 
days_to_first_fill + cause + dgf + centered_bmi + dgf + C_ModerateSevereLiverDisease + 
fill_era, family = binomial(link = &quot;logit&quot;), data = first_regimen_dt)

系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -4.05186959 0.23783076 -17.037 &lt; 0.0000000000000002 ***
centered_age 0.00007974 0.00480505 0.017 0.986759 
rfemaleFemale 0.04008379 0.11260580 0.356 0.721866 
centered_mrcreat -0.08360708 0.03568126 -2.343 0.019121 * 
days_to_first_fill 0.01944154 0.00120843 16.088 &lt; 0.0000000000000002 ***
原因糖尿病 -1.51663048 0.19201817 -7.898 0.00000000000000283 ***
原因高血压性肾硬化 -0.20857901 0.21709647 -0.961 0.336670 
原因其他 -0.43045419 0.21268158 -2.024 0.042977 * 
dgfYes -0.54979993 0.14787923 -3.718 0.000201 ***
centered_bmi -0.02047943 0.01071770 -1.911 0.056030 . 
C_ModerateSevereLiverDiseaseYes -0.43294637 0.24443026 -1.771 0.076520 . 
fill_era2013-2020 1.10826539 0.14895235 7.440 0.00000000000010038 ***
centered_mrcreat:days_to_first_fill 0.00101324 0.00036170 2.801 0.005089 ** 
---
Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

（二项式系列的分散参数取为 1）

零偏差：15645 个自由度上的 3679.1
残差偏差：15633 个自由度上的 2975.4
AIC：3001.4

Fisher 评分迭代次数：7

Weatherperson 方差图（将观察到的方差与预测方差进行比较）显示拟合度非常差。观察到的方差是使用 var(outcome) 计算的，而预测方差则计算为 mean(fitted_values * (1 - fitted_values))，其中 fitted_values 是逻辑回归模型的预测概率。

伯努利分布的卡方拟合优度检验也产生了一个较大的检验统计量，表明拟合度不足。X-squared = 5209.7, df = 1, p-value &lt; 0.00000000000000022，我的分散参数为 0.797。
我的数据集存在严重的类别不平衡，只有大约 2.5% 的患者（15646 名患者中的 394 名）开始使用二甲双胍，因此这是一种罕见的结果。
考虑到结果的罕见性，我决定尝试互补的对数对数 (cloglog) 链接函数而不是 logit 链接。但是，使用 cloglog 模型时，Weatherperson 方差图看起来更糟，AIC 增加到 3010.1。
weather_var &lt;- first_regimen_dt |&gt;
mutate(fitted_range = cut(fitted_cloglog_values, breaks = seq(0.2, 0.8, by = 0.05))) |&gt;
group_by(fitted_range) |&gt;
总结（obs_var = var（metformin），
pred_var = mean（（1 - exp（-exp（fitted_cloglog_values）））* exp（-exp（fitted_cloglog_values））））


我不确定如何从这里继续，非常感谢您对以下方面的任何见解或建议：

考虑到类别不平衡和罕见结果，我下一步应该采取哪些步骤来改善模型拟合并解决 logit 和 cloglog 模型的糟糕表现？
在我使用罕见事件和罕见事件对这种二元结果进行建模的方法中，我可能缺少哪些关键概念或考虑因素？类别不平衡？
考虑到我的数据的具体特征和手头的研究问题，我应该如何考虑在这种情况下进行建模？

不幸的是，由于保密限制，我无法共享实际数据集。但是，我将不胜感激任何一般指导、推荐资源或我可以探索以应对这一建模挑战的替代策略。]]></description>
      <guid>https://stats.stackexchange.com/questions/648175/advice-on-modeling-binary-outcome-with-rare-events-and-class-imbalance</guid>
      <pubDate>Tue, 28 May 2024 23:08:57 GMT</pubDate>
    </item>
    <item>
      <title>glmer 显著，事后检验不显著</title>
      <link>https://stats.stackexchange.com/questions/648171/glmer-significant-and-post-hoc-test-not-significant</link>
      <description><![CDATA[我运行了一个 glmer 模型来测试治疗对我的响应变量的影响
summary(model1)
通过最大似然法（拉普拉斯近似）拟合的广义线性混合模型 [&#39;glmerMod&#39;]
系列：二项式（logit）
公式：cbind(Numero_foglie_minate, Foglie_sane) ~ Trattamento + Blocco + Data_rilievo + (1 | ID_pianta)
数据：data_infestate
控制：glmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 1e+05))

AIC BIC logLik 偏差 df.resid 
4066.1 4142.5 -2020.0 4040.1 2632

缩放残差：
最小 1Q 中位数 3Q 最大值
-1.6876 -0.4813 -0.3308 0.1900 4.8004 

随机效应：
组名称方差标准差
ID_pianta (截距) 1.307 1.143 
观察数：2645，组：ID_pianta，478

固定效应：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -2.98258 0.18485 -16.135 &lt; 2e-16 ***
TrattamentoLavanda -0.43253 0.19116 -2.263 0.0237 * 
TrattamentoRosmarino -0.40539 0.20355 -1.992 0.0464 * 
TrattamentoTimo -0.22146 0.18686 -1.185 0.2360 
Blocco2 -0.33824 0.17387 -1.945 0.0517 。
Blocco3 -0.04463 0.17187 -0.260 0.7951 
Data_rilievo16 -0.01192 0.12264 -0.097 0.9226 
Data_rilievo22 0.08879 0.12123 0.732 0.4639 
Data_rilievo29 -0.03263 0.12380 -0.264 0.7921 
Data_rilievo36 -0.32984 0.12850 -2.567 0.0103 * 
Data_rilievo52 -0.56837 0.12778 -4.448 8.67e-06 ***
Data_rilievo9 0.03357 0.12290 0.273 0.7848 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应相关性：
（内部）TrttmL TrttmR TrttmT Blocc2 Blocc3 Dt_r16 Dt_r22 Dt_r29 Dt_r36 Dt_r52
TrttmntLvnd -0.468 
TrttmntRsmr -0.411 0.463 
TrattamntTm -0.512 0.495 0.463 
Blocco2 -0.441 -0.034 -0.127 0.018 
Blocco3 -0.436 -0.057 -0.153 -0.002 0.546 
Data_rilv16 -0.331 -0.004 0.044 -0.003 -0.040 -0.039 
Data_rilv22 -0.329 -0.009 0.037 -0.016 -0.043 -0.040 0.551 
Data_rilv29 -0.326 -0.003 0.039 -0.015 -0.041 -0.041 0.542 0.553 
Data_rilv36 -0.317 0.004 0.047 -0.003 -0.041 -0.046 0.519 0.531 0.531 
Data_rilv52 -0.318 0.001 0.046 -0.010 -0.038 -0.036 0.525 0.536 0.540 0.518 
Data_riliv9 -0.324 -0.007 0.046 -0.007 -0.046 -0.044 0.539 0.546 0.536 0.515 0.520

结果表明，两种处理方法（“Lavanda”和“Rosmarino”）以及一些采样日期“Data_rilievo”具有显著性。
然后我应用事后检验，如下所示
&gt; emmeans_trattamento &lt;- emmeans(model1, ~ Trattamento)
&gt; 
&gt; # Esegue i encounteri post-hoc tra i livelli del fattore Trattamento
&gt; facedi_posthoc &lt;- 对(emmeans_trattamento)
&gt; 
&gt; # 事后观察结果
&gt; summary(confronti_posthoc)
对比估计 SE df z.ratio p.value
Controllo - Lavanda 0.4325 0.191 Inf 2.263 0.1069
Controllo - Rosmarino 0.4054 0.204 Inf 1.992 0.1911
Controllo - Timo 0.2215 0.187 Inf 1.185 0.6362
Lavanda - Rosmarino -0.0271 0.205 Inf -0.132 0.9992
Lavanda - Timo -0.2111 0.190 Inf -1.110 0.6831
Rosmarino - Timo -0.1839 0.203 Inf -0.907 0.8011

结果在以下水平上取平均值： Blocco，Data_rilievo 
结果以对数比值比（而非响应）尺度给出。
P 值调整：用于比较 4 个估计值的 Tukey 方法

显著性已经消失。现在的问题是：

为什么在事后检验中进行成对比较时，glmer 中显著的东西变得不显著？
如何解释这个结果？我倾向于说，总体而言，这两种处理是显著的，但它们的影响非常小，以至于在成对比较期间无法观察到。第二种选择是，没有一种处理是显著的。哪一个是最正确的解释？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648171/glmer-significant-and-post-hoc-test-not-significant</guid>
      <pubDate>Tue, 28 May 2024 21:35:33 GMT</pubDate>
    </item>
    <item>
      <title>通过肉眼聚类对跨时间重复测量进行 ICC</title>
      <link>https://stats.stackexchange.com/questions/648168/icc-for-repeated-measures-across-time-with-clustering-by-eye</link>
      <description><![CDATA[我试图评估参与者眼睛在 2 个时间点（基线和 2 个月）的测量结果中的 ICC，因此每行代表一只眼睛，有些参与者在研究中包括两只眼睛。
我能够使用 R 中 psych 包中的 ICC() 命令，如下所示：
&gt; head(data1) 

ID eye var_baseline var_2months
1 L 75 63
1 R 56 67
2 L 54 NA
4 L 78 61
4 R 60 65
6 L 80 81

&gt; ICC(data1[,c(&quot;var_baseline&quot;,&quot;var_2months&quot;)], missing=TRUE, alpha=0.05,lmer=TRUE) 

我使用的是 ICC(3,1)，因此假设时间点是固定的，我感兴趣的是这两个时间点之间的测量一致性。
问：如何解释 ICC 估计中眼睛的额外聚类？
在将数据重塑为长格式后，我使用以下公式拟合了一个 lmer 模型，并在 ID 和 eye 中指定了嵌套结构：
formula1 &lt;- var ~ time + (time | ID/eye)

m1 &lt;- 
lmerTest::lmer(
formula = formula1,
data = data.frame(data1),
control = lmerControl(check.nobs.vs.nRE = &quot;ignore&quot;),
na.action = na.exclude
)

我的随机效应如下所示：
随机效应：
组名称方差标准差校正
eye:ID（截距） 25.0782 5.0078 
time1 5.5080 2.3469 0.15
ID（截距） 30.5598 5.5281 
time1 0.3977 0.6307 0.32
残差 6.9562 2.6375 

我不确定是否可以使用提供的方差分量计算 ICC。或者，是否适合使用 lmer 中的以下公式来拟合不以时间作为随机斜率的模型：
var ~ time + (1| ID/eye)

上述模型具有以下随机效应：
随机效应：
组名称方差标准差
eye:ID（截距）23.143 4.811 
ID（截距）31.354 5.600 
残差 9.893 3.145 

是否有一种方法可以计算两次重复测量（在两个时间点）的类内相关系数 (ICC)，同时考虑聚类，例如参与者中有两只眼睛？
谢谢，任何帮助都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/648168/icc-for-repeated-measures-across-time-with-clustering-by-eye</guid>
      <pubDate>Tue, 28 May 2024 20:33:45 GMT</pubDate>
    </item>
    <item>
      <title>单向方差分析是否显著，但其趋势分析是否不显著</title>
      <link>https://stats.stackexchange.com/questions/648167/can-a-one-way-anova-be-significant-but-have-its-trend-analysis-be-non-significan</link>
      <description><![CDATA[假设我们发现单向方差分析具有统计显著性。在运行方差分析之前，我们决定运行趋势分析（H0：没有线性效应 H1：有线性效应）。
会不会是我们的单向方差分析显著但趋势分析不显著？
反之亦然，会不会是我们的方差分析不显著而趋势分析显著？]]></description>
      <guid>https://stats.stackexchange.com/questions/648167/can-a-one-way-anova-be-significant-but-have-its-trend-analysis-be-non-significan</guid>
      <pubDate>Tue, 28 May 2024 20:01:29 GMT</pubDate>
    </item>
    <item>
      <title>只有一个点的 pROC 图形状</title>
      <link>https://stats.stackexchange.com/questions/648170/proc-plot-shape-with-only-one-point</link>
      <description><![CDATA[我用 pROC 画出了这个图
rocobj &lt;- plot.roc(db$IOT, Pred,
main = &quot;Confidence intervals&quot;, 
percent=TRUE,
ci = TRUE, 
print.auc = TRUE) 
ciobj &lt;- ci.se(rocobj, 
specificities = seq(0, 100, 5)) # over a select set of specificities
plot(ciobj, type = &quot;shape&quot;, col = &quot;#1c61b6AA&quot;) 
plot(ci(rocobj, of = &quot;thresholds&quot;, Thresholds = &quot;best&quot;))

我仅用一个点而不是多个点的阶梯曲线得到了这个图，我认为这取决于独立变量是二分的，是吗正确吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648170/proc-plot-shape-with-only-one-point</guid>
      <pubDate>Tue, 28 May 2024 13:34:59 GMT</pubDate>
    </item>
    <item>
      <title>xy 的平方和大于 x 的平方和——这是怎么回事？</title>
      <link>https://stats.stackexchange.com/questions/648148/sum-of-squares-of-xy-bigger-than-sum-of-squares-for-x-how-can-that-be</link>
      <description><![CDATA[我按照这个教程来可视化 R 平方。首先，他们定义计算平方和的公式：

然后，他们应用公式来获得 x1 和 y 的平方和：

然后，他们使用欧拉图可视化方差：

在他们的例子中，ss_y 为 400，ss_x1 为 292，ss_both_y_x1 为 82。为了找出 x1 变量中不属于 y 的比例，他们执行 ss_x1 - ss_both_y_x1，即 292 - 82 = 210。
我在 R 中编造了一些数据，如果我用它执行 ss_x1 - ss_both_y_x1，我会得到负值！为什么 x 与 y 共享的变体会大于 x 本身的整个变体？因此，如果我们从上面的屏幕截图中获取数字，则 292 &lt; 82（ss_x1 小于 ss_both_y_x1）。用欧拉图直观地解释这个问题：深灰色区域（上面的 210 区域）的大小对我的数据来说是负数。
这是我在 R 中所做的：
library(magrittr)
set.seed(1)
df &lt;- data.frame(x1= rnorm(n= 1000, mean= 28, sd= 4))
df$y &lt;- 2*df$x1 + 10*rnorm(n= nrow(df), mean= 0, sd= 1)

ss_both_y_x1 &lt;- lm(formula= y ~ x1, data= df)%&gt;% aov() %&gt;% summary() %&gt;% .[[1]] %&gt;% .[&quot;x1&quot;, &quot;Sum Sq&quot;] # 代码与链接端基本相同，但除了 magrittr 之外没有其他包
ss_x1 &lt;- sum((df$x1 - mean(df$x1))^2)
ss_x1 &lt; ss_both_y_x1
# TRUE
]]></description>
      <guid>https://stats.stackexchange.com/questions/648148/sum-of-squares-of-xy-bigger-than-sum-of-squares-for-x-how-can-that-be</guid>
      <pubDate>Tue, 28 May 2024 12:27:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么 GLM 拟合与使用逻辑函数的直接拟合不同</title>
      <link>https://stats.stackexchange.com/questions/648147/why-glm-fit-is-different-from-direct-fit-using-logistic-function</link>
      <description><![CDATA[我在我的数据中发现，使用逻辑函数的直接拟合比使用带有逻辑链接函数的二项分布的 GLM 拟合得到不同的、更好的 (R^2) 拟合结果。我天真地期望得到相同的结果，但现在无法解释为什么情况并非如此。
正如下面评论中指出的那样，这可能是由于不同的最小化程序造成的。
假设 fit 和 glm 使用的最小化相同，是否可以期望相同的拟合结果？
以下示例假设相同的最小化程序。
这里有一些 matlab 代码来说明这个问题
直接拟合
x = [-50.4 -39.6 -29.7 -21.6 -18.0 -14.4 -9.9 -8.1 -6.3 -3.6 -1.8 0.0 
1.8 3.6 6.3 8.1 9.9 14.4 18.0 21.6 29.7 39.6 50.4]&#39;;
y = [0.0 0.0 0.0 0.0 0.1 0.1 0.2 0.2 0.2 0.3 0.3 0.4 0.5 0.5 0.6 0.6 
0.7 0.8 0.9 0.9 1.0 1.0 1.0]&#39;;

ft=fittype(&#39;exp(b0+b1*x)/(1 + exp(b0+b1*x))&#39;, &#39;indep&#39;, &#39;x&#39;);
stp=[-0.5 0.1];
[mo, gf] = fit(x, y, ft, &#39;StartPoint&#39;, stp);

mo = 
一般模型：
mo(x) = exp(b0+b1*x)/(1 + exp(b0+b1*x))
系数（95% 置信区间）：
b0 = -0.4201 (-0.4983, -0.3419)
b1 = 0.1268 (0.1167, 0.1368)

GLM 部分
data=table(y,x);

modelspec{1}=&#39;y ~ x&#39;;
mdl1 = fitglm(data, modelspec{1},...
&#39;Distribution&#39;, &#39;binomial&#39;, &#39;Link&#39;,&#39;logit&#39;);

广义线性回归模型：
logit(y) ~ 1 + x
分布 = 二项式

估计系数：
估计 SE tStat pValue 
________ ________ ________ ________

(截距) -0.42089 0.60619 -0.69432 0.48748
x 0.13401 0.060266 2.2236 0.026175

差异并不大，但很明显，尤其是当人们期望结果相同时。
这是另一个数据示例（这个是不对称的，我知道拟合将是对称的）。
y=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.5, 1.0, 
1.0, 1.0, 1.0, 1.0, 0.7, 0.9, 0.7, 0.8, 0.8, 1.0];

结果
mo = 
一般模型：
mo(x) = exp(b0+b1*x)/(1 + exp(b0+b1*x))
系数（95% 置信区间）：
b0 = 0.07416 (-0.793, 0.9413)
b1 = 1.606 (-0.1469, 3.359)

mdl1 = 
广义线性回归模型：
logit(y) ~ 1 + x
分布 = 二项式

估计系数：
估计 SE tStat pValue 
________ ________ ________ ________

（截距） -0.35437 0.61901 -0.57247 0.567
x 0.14666 0.066227 2.2145 0.026791

这里的差异很大。
有没有简单的解释说明为什么输出不同？
（我使用 nlsLM 和 glm 在 R 中检查了相同的数据，得到了相同的结果）]]></description>
      <guid>https://stats.stackexchange.com/questions/648147/why-glm-fit-is-different-from-direct-fit-using-logistic-function</guid>
      <pubDate>Tue, 28 May 2024 12:20:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中使用 ivreg 解释 IV 回归？</title>
      <link>https://stats.stackexchange.com/questions/648152/how-do-i-interperate-iv-regressions-with-ivreg-in-r</link>
      <description><![CDATA[我无法理解 R 中 ivreg 包中 ivreg 函数的回归输出。
例如...

如果我担心变量“收入”可能存在内生性，因此我使用“余额”作为 IV，那么 Wu-Hausman 检验是否具有静态显著性（例如模型 iv.reg 中的检验），是否支持变量“收入”是内生的，或者只是 IV 模型与 OLS 模型不同？

弱工具检验是否提供证据证明变量“收入”和“余额”是否相关，因为它具有统计显著性，例如 iv.reg 中的情况？

当我使用的工具变量多于解释性内生变量时，我该如何解释摘要，例如 iv.reg2 中的摘要？


在此先感谢您的帮助。
library(ISLR2)
library(ivreg)

iv.reg&lt;-ivreg(Rating~Limit+Income|Limit+Balance,data=Credit)
summary(iv.reg)

调用：
ivreg(formula = Rating ~ Limit + Income | Limit + Balance, data = Credit)

残差：
最小值 1Q 中位数 3Q 最大值 
-34.720 -8.625 -1.202 8.616 31.687 

系数：
估计标准差误差 t 值 Pr(&gt;|t|) 
(截距) 37.3754873 1.5089830 24.769 &lt;2e-16 ***
极限 0.0679431 0.0005658 120.073 &lt;2e-16 ***
收入 -0.0925933 0.0410875 -2.254 0.0248 * 

诊断测试：
df1 df2 统计 p 值 
弱工具 1 397 396.05 &lt; 2e-16 ***
Wu-Hausman 1 396 16.42 6.11e-05 ***
Sargan 0 NA NA NA 

iv.reg2&lt;-ivreg(Rating~Limit+Income|Limit+Income+Rating,data=Credit)
summary(iv.reg2)

调用：
ivreg(formula = Rating ~ Limit + Income | Limit + Income + Rating, 
data = Credit)

残差：
最小值 1Q 中位数 3Q 最大值 
-31.895 -8.542 -1.302 8.540 29.729 

系数：
估计标准差误差 t 值 Pr(&gt;|t|) 
(截距) 3.874e+01 1.439e+00 26.918 &lt;2e-16 ***
极限 6.657e-02 4.348e-04 153.124 &lt;2e-16 ***
收入 2.075e-02 2.847e-02 0.729 0.467 
---

]]></description>
      <guid>https://stats.stackexchange.com/questions/648152/how-do-i-interperate-iv-regressions-with-ivreg-in-r</guid>
      <pubDate>Tue, 28 May 2024 12:05:42 GMT</pubDate>
    </item>
    <item>
      <title>具有分类变量数据的最佳模型 lmer</title>
      <link>https://stats.stackexchange.com/questions/648146/best-model-for-data-with-categorical-variables-lmer</link>
      <description><![CDATA[我有一些数据，由几分钟内的连续因变量和几个分类自变量组成。我拟合了这个模型，但在 Stack Overflow 上，当我询问拟合 predict() 函数的问题时，有人建议我的模型可能构建得不太好（我的其他问题）。
这是模型：
model &lt;- lmer(minutes_after_sunrise ~ forest * forest_strata * habitat +
(1 | forest_strata), data = data)

minutes_after_sunrise 是检测到物种的给定分钟，以分钟为单位进行数据处理（我也有负数，日出前几分钟，但没有将它们包括在这个模型中），森林是站点A 和 B，森林地层是森林的垂直部分（从地面到树冠，A 和 B 共有 6 层）和栖息地（两个类别），即森林 A 和 B 内的不同栖息地，它们也具有地层，因此一切都非常嵌套。我曾考虑将地层作为固定效应，但说实话，我对这些模型没有太多经验，所以它很可能完全错误。有人能告诉我什么才是最合适的吗？
我想知道的是，日出后的几分钟在森林 A 和 B 之间是否有所不同，以及地层和栖息地等其他元素也可能如何发挥作用。由于只有分类数据，我发现很难研究这个模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/648146/best-model-for-data-with-categorical-variables-lmer</guid>
      <pubDate>Tue, 28 May 2024 11:47:00 GMT</pubDate>
    </item>
    <item>
      <title>R 中距离相关的置信区间</title>
      <link>https://stats.stackexchange.com/questions/648169/confidence-intervals-for-distance-correlation-in-r</link>
      <description><![CDATA[我一直在尝试计算两个变量之间的距离相关性 (energy::dcor) 的置信区间及其 p 值。
数据为：
structure(c(-0.300232326122519, -0.548312017606863, 0.463488637846498, 
-0.957754830334244, 0.489005536982273, 1.60039641596019, 0.198325183245884, 
0.955655402059422, -0.0985745060548668, -0.91537165915946, 0.821680161225068, 
-0.276711736364627, -0.145523522598367, 1.00647170925371, 1.47737776565003, 
-0.429641721588158, -0.983271729470019, -0.37651945096644, -0.155999049481896, 
-1.08716422579988, -0.393385723005449, 3.06380556423845, -0.0666207802774695, 
-0.983271729470019, -0.196076257229251, 0.278960662381259, -0.641728987053197, 
-0.121785441763213, 0.261876899264989, -0.682069767363957, -0.285408444947535, 
-0.425293367296704, 0.227926864109709, -1.08716422579988, 0.312910697536539, 
0.68133965466455, 0.13653339873247, 0.484958662776278, 0.109524745220057, 
-0.462267094226346, -1.81263562663225, 1.20651893229729, 0.684989465059371, 
-0.906637989461132, -0.96098206068222, 0.360589246740862, -0.300919230157815,
0.309013933026176, 0.892150734542308, 0.574948993393824, 0.579038741277517, 
0.352878039434503, -0.107402964012698, -0.675502008954803, -0.496565311995179, 
-0.700466752538984, -0.742382241262757, 0.938355977216629, -0.14196287615184, 
0.386721998266575, 0.51643524328218, 0.455222542513213, 0.327148349208276, 
0.747334267020053, 1.93710502202678, -1.19755578540738, -0.722586352547963, 
-1.54719618551513, 0.144258727383104, 0.227261483045605), dim = c(35L, 
2L))

我执行了 energy::dcor.test，结果如下：
数据：索引 1，重复1000
dCor = 0.28877, p 值 = 0.4785
样本估计值：
dCov dCor dVar(X) dVar(Y)
0.1469361 0.2887657 0.5039591 0.5137722
因此我认为相关性并不显著，绘制数据时这一点也很明显。但是，当我尝试获取上述相关性的 95% 自举置信区间时，我得到的是：
boot.dcor &lt;- function(data, i) {
x &lt;- data[i, 1]
y &lt;- data[i, 2]
energy::dcor(x,y)
}

boot.out &lt;- boot(data, statistic = boot.dcor, R = 1000, sim = &quot;balanced&quot;)

boot.ci(boot.out, type = &quot;perc&quot;)

自举置信区间计算
基于 1000 个自举重复
调用：
boot.ci(boot.out = boot.out, type = &quot;perc&quot;)
区间：
级别百分位数
95% ( 0.2961, 0.5380 )
如您所见，置信区间与 0 相差甚远，甚至不包含之前获得的 dcor (0.289)，我不明白为什么。任何帮助都将不胜感激，谢谢
我尝试了使用 bootstrapping 计算置信区间的不同方法，例如更改 boot 中的 sim 参数以获得不同的模拟（排列、对立）。我还尝试了另一种获取 CI 的方法，使用 bcaboot::bcajack(data, B = 1000, func = boot.dcor, alpha = 0.05)。但是，我从未在置信区间中得到 0，我想它会存在，因为相关性不显著。尝试相同的程序，但使用 pearson 或 spearman 相关性，然后我得到的置信区间如预期的那样包含 0，并围绕它分布。该问题似乎确实与距离相关性有关，而且我还找不到 dcor.test 中如何计算 p 值，也不知道除了引导法之外还有哪些其他方法可以得到置信区间。]]></description>
      <guid>https://stats.stackexchange.com/questions/648169/confidence-intervals-for-distance-correlation-in-r</guid>
      <pubDate>Tue, 28 May 2024 10:48:00 GMT</pubDate>
    </item>
    <item>
      <title>有界参数的似然比检验</title>
      <link>https://stats.stackexchange.com/questions/648118/likelihood-ratio-tests-on-bounded-parameters</link>
      <description><![CDATA[我对似然比检验的边界条件限制感到困惑。一种常见的说法是，它会导致方差参数出现问题，因为它的边界小于 0。这些模型能与似然比检验相比较吗？
$Y\sim \text{Normal}(a,2)$
$Y\sim \text{Normal}(a,b)$
其中，$a$ 和 $b$ 是参数？这些怎么样
$Y\sim \text{Normal}(a,b)$
$Y\sim \text{Normal}(a,b+cx)$
其中 $a$、$b$ 和 $c$ 是参数，$x$ 是协变量？如果不能使用似然比检验，那么应该如何使用零假设显著性检验来比较它们？
一个相关的问题是，我认为似然比检验在二项式 GLM 中很常用，即使概率参数有上下限。为什么可以将其用于概率参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/648118/likelihood-ratio-tests-on-bounded-parameters</guid>
      <pubDate>Tue, 28 May 2024 05:37:45 GMT</pubDate>
    </item>
    <item>
      <title>关于贝叶斯统计的问题（来自 DSP 估计理论书籍）</title>
      <link>https://stats.stackexchange.com/questions/648113/question-about-bayesian-stats-from-a-dsp-estimation-theory-book</link>
      <description><![CDATA[摘自《统计信号处理基础，第一卷：估计理论》

估计理论的一个基本规则是，使用先验知识将得到更准确的估计量。例如，如果一个参数被限制在已知区间内，那么任何好的估计量都应该只产生该区间内的估计值。在示例 3.1 中，我们表明 $A$ 的 MVU 估计量是样本平均值 $\bar{x}$。然而，这假设 $A$ 可以取区间 $-\infty&lt;A&lt;\infty$ 内的任何值。由于物理限制，可能更合理地假设$A$只能取有限区间$-A_0 \leq A \leq A_0$中的值。保留$\hat{A}=\bar{x}$作为最佳估计量是不可取的，因为$\hat{A}$可能会产生已知区间之外的值。如图 10.1a 所示，这是由于噪声效应。当然，如果我们使用截断样本均值估计量$$
\check{A}=\left\{\begin{array}{cc}
-A_0 &amp; \bar{x}&lt;-A_0 \\ \bar{x} &amp; -A_0 \leq \bar{x} \leq A_0 \\ A_0 &amp; \bar{x}&gt;A_0 \end{array}\right. $$ 这将与
已知约束一致。这样的估计器将具有 PDF $$
\begin{aligned} &amp; p_{\check{A}}(\xi ; A)=\quad
\operatorname{Pr}\left\{\bar{x} \leq-A_0\right\}
\delta\left(\xi+A_0\right) \\ &amp;+p_{\hat{A}}(\xi ;
A)\left[u\left(\xi+A_0\right)-u\left(\xi-A_0\right)\right] \\
&amp;+\operatorname{Pr}\left\{\bar{x} \geq A_0\right\}
\delta\left(\xi-A_0\right) \end{aligned} $$
其中 u(x) 是单位阶跃函数。如图 10.1b 所示。


我见过一些不同的单位阶跃函数定义：

$u(t)= \begin{cases}0 &amp; t&lt;0 \\ 1 &amp; t&gt;0\end{cases}$

$u(t)= \begin{cases}0 &amp; t&lt;0 \\ 1 &amp; t \geq 0\end{cases}$


我对这个等式感到困惑
\begin{aligned}
&amp; \operatorname{Pr}\left\{\bar{x} \leq-A_0\right\} \delta\left(\xi+A_0\right) \\
&amp; \quad+p_{\hat{A}}(\xi ; A)\left[u\left(\xi+A_0\right)-u\left(\xi-A_0\right)\right] \\
&amp; \quad+\operatorname{Pr}\left\{\bar{x} \geq A_0\right\} \delta\left(\xi-A_0\right)
\end{aligned&gt;
我理解 $u\left(\xi+A_0\right)-u\left(\xi-A_0\right)$ 是一个矩形脉冲，它将高斯概率密度函数“窗口化”在 $-A_0$ 和 $A_0$ 之间；它看起来像下面这样

我不明白这个等式的这一部分
\begin{aligned}
\operatorname{Pr}\left\{\bar{x} \leq-A_0\right\} \delta\left(\xi+A_0\right) \quad ,\operatorname{Pr}\left\{\bar{x} \geq A_0\right\} \delta\left(\xi-A_0\right)
\end{aligned&gt;
为什么他们使用 Pr{} 而不是 $p_{\hat{A}}(\xi ; A)$？为什么他们要将其与移位的狄拉克三角洲相乘？
有一件事我特别不清楚，那就是为什么这种截断甚至会产生这两个项。是不是因为可能使用了第一个定义，其中 $u(\xi-A_0)$ 在 $A_0$ 处未定义？]]></description>
      <guid>https://stats.stackexchange.com/questions/648113/question-about-bayesian-stats-from-a-dsp-estimation-theory-book</guid>
      <pubDate>Tue, 28 May 2024 02:34:57 GMT</pubDate>
    </item>
    <item>
      <title>帮助解释卡方的用法以确定赛道是否有任何具有优势的赛道[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648112/help-interpreting-the-use-of-chi-square-to-determine-if-race-course-has-any-lane</link>
      <description><![CDATA[由于问题太开放，因此已关闭。以下是我希望通过寻求帮助学到的东西：

对于这些数据，这是一种好方法吗？
有没有更好的方法？
我该如何解释结果？

假设您获得了一条赛道，赛道上有 1-8 条水道，并且您怀疑某些水道比其他水道更快。更快的水道会拥有更多更高的位置（第一名、第二名等）。假设您举办了 100 场比赛，但没有足够的参赛者来填满赛道，因此为简单起见，比赛从第 1 条水道开始填满，直到比赛满员。大多数赛事很少会满员，因此外侧跑道的数据较少，这可能会给分析带来问题。
假设参赛者从 1 号跑道向外随机排列在赛道上，而不是根据能力进行选择。
使用一些随机数据以均匀概率模拟比赛​​。
# 随机数据（作为示例）
random_data = {
&#39;lane_1&#39;: np.random.choice(range(1, 9), 92, p=[1/8]*8).tolist(),
&#39;lane_2&#39;: np.random.choice(range(1, 9), 93, p=[1/8]*8).tolist(),
&#39;lane_3&#39;: np.random.choice(range(1, 9), 91, p=[1/8]*8).tolist(),
&#39;lane_4&#39;: np.random.choice(range(1, 9), 90, p=[1/8]*8).tolist(),
&#39;lane_5&#39;: np.random.choice(range(1, 9), 88, p=[1/8]*8).tolist(),
&#39;lane_6&#39;: np.random.choice(range(1, 9), 76, p=[1/8]*8).tolist(),
&#39;lane_7&#39;: np.random.choice(range(1, 9), 64, p=[1/8]*8).tolist(),
&#39;lane_8&#39;: np.random.choice(range(1, 9), 34, p=[1/8]*8).tolist()
}

因此，1 号泳道获得 92 项赛事（有一些取消资格的参赛者），2 号泳道获得 93 项赛事...等等。以下是示例热图的样子。

和卡方结果：
卡方：55.82543521120111
p 值：0.23376772081410768
自由度：49

现在看看这与卡方拟合相比如何。所以我做了以下事情：
列联表：首先，构建一个列联表，其中行代表通道，列代表位置。表格中的每个单元格包含该泳道和位置的比赛结果的观测频率。
卡方检验：然后对该列联表执行卡方检验，以确定观测频率是否与泳道和位置之间独立的零假设下的预期频率有显著差异。
预期频率：作为卡方检验的一部分，在独立假设下计算列联表中的每个单元格的预期频率。这些预期频率代表如果泳道和位置之间没有关系时预期的频率。
热图可视化：最后，以热图格式可视化预期频率。热图中的每个单元格代表零假设下该泳道和位置的比赛结果的预期频率。颜色强度表示预期频率的大小，强度越高表示预期频率越高。

这就是一些均匀随机数据的样子。现在有一些真实数据：
data = {
&#39;1&#39;: {&#39;1&#39;: 37, &#39;2&#39;: 17, &#39;3&#39;: 10, &#39;4&#39;: 12, &#39;5&#39;: 11, &#39;6&#39;: 3, &#39;7&#39;: 2, &#39;dq&#39;: 1},
&#39;2&#39;: {&#39;1&#39;: 16, &#39;2&#39;: 31, &#39;3&#39;: 19, &#39;4&#39;: 8, &#39;5&#39;: 5, &#39;6&#39;: 9, &#39;7&#39;: 3, &#39;dq&#39;: 2},
&#39;3&#39;: {&#39;1&#39;: 15, &#39;2&#39;: 16, &#39;3&#39;: 21, &#39;4&#39;: 15, &#39;5&#39;: 9, &#39;6&#39;: 7, &#39;7&#39;: 4, &#39;8&#39;: 3, &#39;dq&#39;: 1},
&#39;4&#39;: {&#39;1&#39;: 10, &#39;2&#39;: 11, &#39;3&#39;: 22, &#39;4&#39;: 17, &#39;5&#39;: 17, &#39;6&#39;: 8, &#39;7&#39;: 4, &#39;dq&#39;: 1},
&#39;5&#39;: {&#39;1&#39;: 4, &#39;2&#39;: 10, &#39;3&#39;: 9, &#39;4&#39;: 23, &#39;5&#39;: 18, &#39;6&#39;: 10, &#39;7&#39;: 8, &#39;8&#39;: 5, &#39;dq&#39;: 1},
&#39;6&#39;: {&#39;1&#39;: 5, &#39;2&#39;: 6, &#39;3&#39;: 5, &#39;4&#39;: 5, &#39;5&#39;: 14, &#39;6&#39;: 15, &#39;7&#39;: 13, &#39;8&#39;: 8},
&#39;7&#39;: {&#39;1&#39;: 6, &#39;2&#39;: 5, &#39;3&#39;: 8, &#39;4&#39;: 7, &#39;5&#39;: 11, &#39;6&#39;: 9, &#39;7&#39;: 13, &#39;8&#39;: 5},
&#39;8&#39;: {&#39;1&#39;: 1, &#39;2&#39;: 1, &#39;4&#39;: 2, &#39;5&#39;: 1, &#39;6&#39;: 10, &#39;7&#39;: 12, &#39;8&#39;: 17}
}

这将产生以下比较图表：

并且卡方
卡方：311.8435818023394
p 值：3.446800747358413e-37
自由度：56

除了看起来有偏差之外，有没有更好的方法来量化或解释结果？我不太精通统计学，因为我的背景是编程。这种技术是别人向我建议的。但是，我并不完全掌握测试或解释它的最佳方法。或者有没有更好的方法？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/648112/help-interpreting-the-use-of-chi-square-to-determine-if-race-course-has-any-lane</guid>
      <pubDate>Tue, 28 May 2024 02:09:46 GMT</pubDate>
    </item>
    </channel>
</rss>