<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 03 May 2024 01:02:51 GMT</lastBuildDate>
    <item>
      <title>如何将观测误差源纳入状态空间模型？</title>
      <link>https://stats.stackexchange.com/questions/646401/how-to-incorporate-sources-of-observational-error-in-state-space-model</link>
      <description><![CDATA[我正在学习状态空间模型。我理解未观察到的潜在过程的概念，以及我们可以用来估计潜在过程的一组嘈杂的观察数据。我试图找到一些清晰的示例（最好是代码），说明模型中包含对观察误差具有已知影响的协变量。
例如，如果要估计鱼类数量，那么可以合理地假设天气会影响测量并成为观测误差的来源。如果我每次测量人口时都记录天气，如何将其合并到我的模型中？
另一个例子——也许我正在测量一个城市居民随时间变化的体重。我询问每个人他们住在哪个社区，最后我发现我对某个社区的样本比我对某些社区的预期要少，而对其他社区的样本则比我对其他社区的预期要多，考虑到每个社区的总人口。
也许随着时间的推移 - 也许我的研究几年前就开始了，我在招募志愿者方面没有太大的吸引力，但随着时间的推移，这项研究变得越来越受欢迎，我今年甚至比去年也能收集到更多的样本尽管人口规模没有变化。
所有这些都是观察误差的来源，不是吗？我如何将该信息包含在状态空间模型中？或者，如果有一本很好的带有示例的“食谱”，那么也会很有帮助。我对 R 或 Python 很熟悉，并且很高兴阅读用 Stan、PyMC 等构建的贝叶斯模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/646401/how-to-incorporate-sources-of-observational-error-in-state-space-model</guid>
      <pubDate>Fri, 03 May 2024 00:23:24 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测帮助[关闭]</title>
      <link>https://stats.stackexchange.com/questions/646394/time-series-forecasting-help</link>
      <description><![CDATA[你能帮忙吗？我的编码技能有限，我必须确保我的代码是否正确？我有如下时间序列数据集。我想预测明年的月度数量，所以 2024 年。我想使用 statforecast 库。我的 mape 和 rmse 结果很高
日期 数量 2020-01-31 5190 2020-02-28 5110 2020-03-31 7154 2020-04-30 2644 2020-05-31 6482 2020-06-30 12223 2020-07-31 11535 2020 -08-31 10250 2020-09-30 13831 2020-10-31 13831 2020-11-30 6162 2020-12-31 13448 2021-01-31 5040 2021-02-28 9699 2021-03-31 11562 2021-0 4-30 5196 2021- 05-31 6358 2021-06-30 3189 2021-07-31 2795 2021-08-31 3300 2021-09-30 599 2021-10-31 4090 2021-11-30 9965 2021-12-31 3935 2022年1月- 31 559 2022-02-28 400 2022-03-31 1959 2022-04-30 4430 2022-05-31 5833 2022-06-30 8113 2022-07-31 400 2022-08-31 6283 2022- 09-30 3640 2022-10-31 400 2022-11-30 2795 2022-12-31 13831 2023-01-31 4025 2023-02-28 1994 2023-03-31 792 2023-04-30 1154 2023-05-31 497 2023- 06-30 2344 2023-07-31 2239 2023-08-31 2800 2023-09-30 4492 2023-10-31 4534 2023-11-30 4386 2023-12-31 502
我的Python代码如下。
&#39;&#39;&#39;
p1.reset_index(inplace=True)
p1 = p1[[‘日期’,‘数量’]]
p1[&#39;unique_id&#39;] = “1”
p1.columns = [‘ds’, ‘y’,‘unique_id’] train_p1 = p1[p1.ds &lt;= ‘2022-12-31’]
test_p1 = p1[p1.ds &gt;= ‘2023-01-31’]
模型_p1 = [
自动ARIMA(),
自动ETS(),
幼稚的（），
] # 我们预测的时期
地平线 = len(test_p1) # 12
sf_p1 = 统计预测(
df=train_p1,
模型=models_p1,
频率=‘M’,
n_职位=-1
）
p1_preds = sf_p1.forecast(地平线)
p1_preds = p1_preds.merge(test_p1, how=&#39;inner&#39;, on=[&#39;unique_id&#39;, &#39;ds&#39;])
plot_p1 = pd.concat([train_p1, p1_preds]).set_index(‘ds’)
无花果, 斧头 = plt.subplots(1, 1, 无花果大小 = (12, 4))
plot_p1[[&#39;y&#39;, &#39;AutoARIMA&#39;, &#39;AutoETS&#39; ]].plot(ax=ax, 线宽=2)
ax.set_title(&#39;(p1)&#39;, 字体大小=10)
ax.set_ylabel(&#39;数量&#39;, fontsize=10)
ax.set_xlabel(&#39;日期&#39;, fontsize=10)
ax.legend(prop={‘大小’: 10})
ax.grid()
def MAPE(true, preds):
绝对百分比错误 = np.abs((true - preds) / true)
绝对百分比错误[np.isnan(绝对百分比错误)] = 0
mape = np.mean(绝对百分比误差) * 100
返回地图
m_autoarima= MAPE(p1_preds[‘y’], p1_preds[‘AutoARIMA’])
m_autoets= MAPE(p1_preds[‘y’], p1_preds[‘AutoETS’])
m_naive= MAPE(p1_preds[‘y’], p1_preds[‘Naive’])
print(&#39;p1 的 MAPE 和 RMSE 结果&#39;)
print(f“AutoARIMA 的 MAPE: {m_autoarima:.2f}%“)
print(f“AutoETS 的 MAPE: {m_autoets:.2f}%”)
print(f“朴素的 MAPE: {m_naive:.2f}%”)
def RMSE(true, preds):
squared_errors = (true - preds) ** 2
rmse = np.sqrt(np.mean(squared_errors))
返回均方根误差
rm_autoarima= RMSE(p1_preds[‘y’], p1_preds[‘AutoARIMA’])
rm_autoets= RMSE(p1_preds[‘y’], p1_preds[‘AutoETS’])
rm_naive= RMSE(p1_preds[‘y’], p1_preds[‘Naive’])
print(f“AutoARIMA 的 RMSE: {rm_autoarima:.2f}”)
print(f“AutoETS 的 RMSE: {rm_autoets:.2f}”)
print(f“朴素的 RMSE：{rm_naive:.2f}”)
AutoARIMA 的 MAPE：314.98%
AutoETS 的 MAPE：382.85%
Naive 的 MAPE：912.52%
AutoARIMA 的 RMSE：3626.45
AutoETS 的 RMSE：4382.10
Naive 的 RMSE：11450.33
2024 年预测
sf_p1_f = 统计预测(
模型=models_p1,
频率=‘M’
）
sf_p1_f.fit(p1)
forecast_p1 = sf_p1_f.predict(h=12, level=[95]) &#39;&#39;&#39;]]></description>
      <guid>https://stats.stackexchange.com/questions/646394/time-series-forecasting-help</guid>
      <pubDate>Thu, 02 May 2024 20:36:53 GMT</pubDate>
    </item>
    <item>
      <title>正态分布变量具有特定排名的概率</title>
      <link>https://stats.stackexchange.com/questions/646393/probability-that-normally-distributed-variables-will-have-a-specific-ranking</link>
      <description><![CDATA[有 $k$ 名玩家在玩游戏，每人给出一个表现 $X_k \sim N(\mu_k, 1)$，我们观察他们从最好到最差的排名（玩家指数的排列）。如果我们知道每个玩家的$\mu_k$，如何计算观察到特定排名的概率？
$X_k$ 是独立的。
目标是在给定一组观察到的排名的情况下计算 $\mu_k$ 参数的 MLE。]]></description>
      <guid>https://stats.stackexchange.com/questions/646393/probability-that-normally-distributed-variables-will-have-a-specific-ranking</guid>
      <pubDate>Thu, 02 May 2024 20:04:28 GMT</pubDate>
    </item>
    <item>
      <title>如何在双对数模型中计算归因</title>
      <link>https://stats.stackexchange.com/questions/646392/how-to-calculate-attributions-in-a-log-log-model</link>
      <description><![CDATA[假设我有一个面向时间序列的对数对数模型，形式为 ln(y) = B0 + B1ln(x1) + B2ln(x2)。假设 B0=1.5、B1=0.7 和 B2=0.9。我使用我的模型在不同时间段进行两次预测。在时间段 1，假设 x1=10 和 x2=20，因此 ŷ1=exp(1.5+0.7ln(10)+0.9ln(20))=332.94。在时间段 2 中，x1=12 且 x2=25，因此 ŷ2=exp(1.5+0.7ln(12)+0.9ln(25))=462.38。
现在我想将两个时间段的预测结果之间的差异归因于 x1 和 x2。例如，我希望能够说 ŷ 的 129.44 差异中，68.24 可归因于 x1 的变化，其余 61.20 可归因于 x2 的变化（当然，这里是假设的）。我该如何计算这个？]]></description>
      <guid>https://stats.stackexchange.com/questions/646392/how-to-calculate-attributions-in-a-log-log-model</guid>
      <pubDate>Thu, 02 May 2024 20:02:57 GMT</pubDate>
    </item>
    <item>
      <title>在 Stata 中使用 CSDID 命令 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/646386/using-csdid-command-in-stata</link>
      <description><![CDATA[我正在使用德国社会经济家庭小组，在那里我运行 CSDID 来检查政策推出的效果。我的因变量是主观幸福感，我的治疗变量是出生年份，因为政策会根据年龄影响人们。
这是我的代码：
设置
genfirst_treat = 0

如果birth_year == 1983，则替换first_treat = 2002
如果birth_year == 1984，则替换first_treat = 2003
如果birth_year == 1985，则替换first_treat = 2004
如果birth_year == 1986，则替换first_treat = 2005
如果birth_year == 1987，则替换first_treat = 2006
如果birth_year == 1988，则替换first_treat = 2007
如果birth_year == 1989，则替换first_treat = 2008
如果birth_year == 1990，则替换first_treat = 2009
如果birth_year == 1991，则替换first_treat = 2010
如果birth_year == 1992，则替换first_treat = 2011

CSDID回归//需要修复ivar识别问题
ssc install csdid，全部替换
ssc安装drdid，全部替换
csdid SWB ivar(individual_id) 时间(年份) gvar(first_treat)
csdid life_satisfaction ivar(individual_id) 时间(年) gvar(first_treat) 方法(dripw)
csdid health_satisfaction ivar(individual_id) 时间(年份) gvar(first_treat) 方法(dripw)
csdid Years_of_education ivar(individual_id) 时间(年份) gvar(first_treat) 方法(dripw)

但是，代码无法运行。它说找不到 ivar。不过，我使用个人唯一识别码作为ivar。
有人可以告诉我我需要解决什么问题吗？这是我设置治疗变量的方式吗？还是别的什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/646386/using-csdid-command-in-stata</guid>
      <pubDate>Thu, 02 May 2024 18:36:23 GMT</pubDate>
    </item>
    <item>
      <title>哪种统计模型合适？</title>
      <link>https://stats.stackexchange.com/questions/646383/which-statistical-model-is-suitable</link>
      <description><![CDATA[我对 132 名患者进行了调查，了解他们的社会经济状况以及他们在移动货币上的消费行为（我的论文主题）。
在调查中，我们询问人们如何在三个类别（流动性、捐赠和销售）上花费 100 个硬币。
我的问题是，哪种统计模型可以帮助我测试如果将 100 个硬币替换为 1 亿枚，支出将如何变化（假设对于像伦敦这样的城市，我们希望针对数千人）。
我很困惑，因为我的输入各不相同并且具有三个因变量。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/646383/which-statistical-model-is-suitable</guid>
      <pubDate>Thu, 02 May 2024 18:00:22 GMT</pubDate>
    </item>
    <item>
      <title>解释中介模型结果</title>
      <link>https://stats.stackexchange.com/questions/646378/interpreting-mediation-model-result</link>
      <description><![CDATA[我正在通过 R 中的 Lavaan 包使用 SEM 测试中介模型，发现中介变量和因变量之间存在显着关系。例如：
model1 &lt;- &#39;
  医学〜工业
  医学部~医学部
&#39;


但是，如果我在模型中包含直接关系，中介变量和因变量之间的关系就变得微不足道。例如：
model1 &lt;- &#39;
  #直接关系
  深度 ~ 工业

  #中介关系
  医学〜工业
  医学部~医学部
&#39;

我如何解释这个结果？另外，我应该在模型中仅使用中介关系还是还必须包括因变量和自变量之间的直接关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/646378/interpreting-mediation-model-result</guid>
      <pubDate>Thu, 02 May 2024 17:19:19 GMT</pubDate>
    </item>
    <item>
      <title>Fisher 评分算法未收敛，但模型输出在 R 中看起来不错</title>
      <link>https://stats.stackexchange.com/questions/646369/fisher-scoring-algorithm-did-not-converge-however-model-output-looks-fine-in-r</link>
      <description><![CDATA[我目前正在尝试将 R 中的逻辑回归模型与分离的数据进行拟合，以分析在这种情况下出现的问题。事实上，以下模型出现了警告消息，但是在模型摘要中，标准误差和系数在我看来并没有表明任何重大问题，而且渔民得分的数量也不高于 25，而是相当低 (= 2)。你们中有人有想法吗，为什么会出现这种情况？我已经检查过数据确实是分开的。
&lt;前&gt;&lt;代码&gt;代码：
lr_master_ECTS_sem &lt;- glm(glm(cod_master_SJ_bin ~ am_ECTS_total + 学期，数据 = 数据，家庭 = 二项式(link = &quot;logit&quot;))
）

输出：
称呼：
glm(公式 = glm(cod_master_SJ_bin ~ am_ECTS_total + 学期,
    数据=数据，族=二项式（链接=“logit”）））

系数：
                估计标准。误差t值Pr(&gt;|t|)
（截距）-0.5920092 0.0982783 -6.024 2.31e-07 ***
am_ECTS_总计 0.0036223 0.0007227 5.012 7.74e-06 ***
学期 0.0442304 0.0123937 3.569 0.000826 ***
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（高斯族的色散参数取0.06791891）

    零偏差：50 自由度上为 8.6275
残余偏差：48 自由度上为 3.2601
AIC：12.478

Fisher 评分迭代次数：2


警告消息：
1：glm.fit：Algorithmus konvergierte nicht（未收敛）
2：glm.fit：Angepasste Wahrscheinlihkeiten mit numerischem Wert 0 oder 1 aufgetreten（值为 0 或 1 的概率）
3：glm.fit：通用算法
4：glm.fit：Angepasste Wahrscheinlihkeiten mit numerischem Wert 0 oder 1 aufgetreten

更新：
 ### 标准化
&gt; # 使用scale()标准化回归量
&gt; data_standardized &lt;- 数据
&gt; data_standardized$am_ECTS_total &lt;- 规模(data$am_ECTS_total)
&gt; data_standardized$学期 &lt;- 规模（数据$学期）
&gt;
&gt; # 使用标准化回归量拟合逻辑回归模型
&gt; lr_master_ECTS_sem_standardized &lt;- glm(cod_master_SJ_bin ~ am_ECTS_total + 学期，数据 = data_standardized，家庭 = 二项式(link = “logit”))
警告消息：
1：glm.fit：通用算法
2：glm.fit：Angepasste Wahrscheinlihkeiten mit numerischem Wert 0 oder 1 aufgetreten
&gt;
&gt; # 具有标准化回归器的模型摘要
&gt;摘要（lr_master_ECTS_sem_standardized）

称呼：
glm(公式 = cod_master_SJ_bin ~ am_ECTS_total + 学期, 家庭 = 二项式(link = &quot;logit&quot;),
    数据=数据_标准化）

系数：
              估计标准。误差z值Pr(&gt;|z|)
（截距）-104.07 48318.32 -0.002 0.998
am_ECTS_总计 82.96 62815.32 0.001 0.999
学期 97.21 68864.96 0.001 0.999

（二项式族的色散参数取1）

    零偏差：50 自由度上为 5.3182e+01
残余偏差：48 自由度上的 8.8010e-09
学分：6

Fisher 评分迭代次数：25

标准化确实揭示了有问题的模型结构。]]></description>
      <guid>https://stats.stackexchange.com/questions/646369/fisher-scoring-algorithm-did-not-converge-however-model-output-looks-fine-in-r</guid>
      <pubDate>Thu, 02 May 2024 16:34:52 GMT</pubDate>
    </item>
    <item>
      <title>关于零假设解释的问题[关闭]</title>
      <link>https://stats.stackexchange.com/questions/646361/question-about-the-interpretation-of-null-hypothesis</link>
      <description><![CDATA[我目前正在学习统计学课程，我正在尝试理解统计假设检验结果的解释。我不知道我的想法是否正确。
在确定零假设时，如果没有更好的选择，我们会选择一个可以接受的值。但是，如果我不想对要测试的实际值做任何假设，该怎么办。假设我想测试断言$\mu &gt; 0$，假设$X_1, X_2, ...,X_n \sim \mathcal{N}(\mu ,\sigma ^{2}=1)$，其中$\mu$未指定，并且它们彼此独立。然后将 p 值重新定义为
$$p=\max_{\mu&lt;0}\ P\left( \bar{X} &gt; \text{some value} \right | \mu)$$
这与使用原始 p 值定义设置 $\mu = 0$ 相同。但推理不同。一个是使用一个特定的 $\mu$ 获得更极端结果的概率，另一个是在 $\mu$ 范围内这种概率的最大值。
这有点像用 $H_0:\mu = 0$ 替换 $H_0:\mu &lt; 0$ 在单尾 Z 检验中，不假设 $\mu$ 的值是多少。]]></description>
      <guid>https://stats.stackexchange.com/questions/646361/question-about-the-interpretation-of-null-hypothesis</guid>
      <pubDate>Thu, 02 May 2024 15:57:19 GMT</pubDate>
    </item>
    <item>
      <title>具有不平衡类别和正态性假设的 Kruskal-Wallis</title>
      <link>https://stats.stackexchange.com/questions/646355/kruskal-wallis-with-unbalanced-classes-and-assumption-of-normality</link>
      <description><![CDATA[我想更好地了解如何正确地处理具有很大程度上不平衡类的重要测试。
考虑一下：
在我的例子中，我有一个音节序列的数据集，以及相关的类 - 行为。
这些类在很大程度上是不平衡的 - 最大的类有 140K 数据点，最小的类有 800 个数据点。
序列看起来像这样：(A, B, B), (B,A), (C, C, D, E), ... - 如你所见，它们的长度各不相同 - 并且行为是分类标签。
我想测试子字符串的长度和行为之间是否存在显着差异。
但很高兴也考虑其他测试，着眼于序列音节的特异性，以探索可能标记行为之间差异的其他方面，具体取决于音节。

我应该考虑 Kruskal-Wallis 检验还是其他检验（例如 ANOVA 或多级模型）？
我应该为每个类别抽取相同数量的项目吗？
如果是这样，我应该如何抽样 - 我应该考虑最小类的整个总体，然后随机选择最大类，还是应该根据大小对抽样进行加权？

背景和疑问

对于非常大的类，使用 Kruskal Wallis 或 Anova 之间存在分歧：一个论证遵循非常大的类经历正态性的假设；另一个论证遵循这样的假设：非常大的类经历正态性；另一个是 Kruskal Wallis 确实适合不平衡类别
https://www.researchgate.net/post/Kruskal_Wallis_test_for_unequal_group_size

我知道方差分析假定方差呈正态性和同质性，但根据我所做的分析，我对在何处应用正态性检验感到有点困惑：


我发现所有类别中所有数据点的长度组合符合重尾分布。所以它不是正态分布。
但是，如果我想测试类之间的显着性差异，我认为我应该将每个类的序列群体视为一个独立的群体。虽然正态性应该适用于每个类，但我感到困惑，因为条形图似乎表明它是正态分布，但统计分析却不然，所以我想知道我是否正确地构建了问题和变量。
具体来说：当我绘制分布的长度时，它“似乎”是来近似它（它实际上是一个条形图，因为长度是离散的，中心值为 5 的钟形图是“镜像”极值），但我尝试了 Levene 检验来测试方差的同质性，并尝试了 Shapiro-Wilk 检验来测试正态分布，并且它们都返回 p = 0.0，表明长度不服从正态分布。

该帖子建议使用多级分析，但不确定如何在我的案例中应用它：
Kruskal-Wallis、ANOVA 或其他测试？

如果您能解释如何正确处理问题并明智地应用重要测试，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/646355/kruskal-wallis-with-unbalanced-classes-and-assumption-of-normality</guid>
      <pubDate>Thu, 02 May 2024 13:45:41 GMT</pubDate>
    </item>
    <item>
      <title>一个随机变量与两个随机变量乘积的协方差[关闭]</title>
      <link>https://stats.stackexchange.com/questions/646325/covariance-of-one-random-variable-with-the-product-of-two-random-variables</link>
      <description><![CDATA[设 $X\sim \mathrm{Bin}(p_x,1)$ 、 $Y\sim \mathrm{Bin}(p_y,1)$ 和 $V\sim \mathrm{Bin}(p_v,1)$ 为三个二项式随机变量，它们彼此不独立。请注意 $X$ 和 $Y$ 均从同一二项分布 $\mathrm{Bin}(p_x,1)={Bin}(p_y,1)$ 中抽样。我的目标是找到协方差的表达式\begin{align}\operatorname{Cov}(XY,V)&amp;\end{align&gt;
来自相关随机变量乘积的协方差和等式。 12 在 https://www.jstor.org/stable/2286081（关于随机变量乘积的精确协方差）中，我了解到这个协方差可以表示为：
\begin{align}\operatorname{Cov}(XY,V)&amp;=\operatorname{E}(X)\operatorname{Cov}(Y,V) + \operatorname{E}(Y)\operatorname{Cov}(X,V) + \operatorname{E}[(\Delta_Y)(\Delta_X)(\Delta_V)]&amp;\end{align&gt;
其中 $\Delta_X = X - \mathbb E[X]$、$\Delta_Y = Y - \mathbb E[Y]$ 和 $\Delta_V = V - \mathbb E[V]$。
请注意，如果三个随机变量呈正态分布，则第三阶矩会消失（Anderson，1958 年）。所以我确实想知道二项式随机变量会发生什么情况。另外，请记住，这些变量可以标准化以获得均值为 0 和方差为 1。
请注意，我可以将任何两个变量的联合分布表示为，例如 $X$ 和 $Y$，如下所示：
\begin{align}P(X,Y) = Cov(X,Y) - P(X)P(Y)&amp;\end{align&gt;
我还想找到一个表达式：
\begin{align}\operatorname{Cov}(X^2,V)&amp;\end{align&gt;
因此，在这种情况下，我们将协方差表达式表示为：
\begin{align}\operatorname{Cov}(X^2,V)&amp;=\operatorname{E}(X)\operatorname{Cov}(X,V) + \operatorname{E}(X)\operatorname{Cov}(X,V) + \operatorname{E}[(\Delta_X)(\Delta_X)(\Delta_V)]= 2\operatorname{E}(X)\operatorname{Cov}(X,V) + \operatorname{E}[(\Delta_X)^2(\Delta_V)]&amp;\end{align&gt;
也许在二次型协方差和类型随机向量中已经提出了类似的问题$\mathbf{G}\,\mathbf{y}$ 但我不确定。
Anderson, T. W. 多元统计分析导论。纽约：John Wiley and Sons，1958 年。]]></description>
      <guid>https://stats.stackexchange.com/questions/646325/covariance-of-one-random-variable-with-the-product-of-two-random-variables</guid>
      <pubDate>Thu, 02 May 2024 01:23:22 GMT</pubDate>
    </item>
    <item>
      <title>邮编解释</title>
      <link>https://stats.stackexchange.com/questions/646315/zip-interpretation</link>
      <description><![CDATA[我希望提高数据分析方面的知识，从而提高统计方面的知识。
我对水下潜水时观察鳐鱼感兴趣。我有一个数据集，对应于近 10,000 次潜水：两年多来，由不同的潜水俱乐部在分布在 4 个岛屿的多个区域进行（同一个潜水俱乐部可以进行多次潜水）。
对于每次潜水，俱乐部都会提供位置（岛屿和区域）、日期、一天中的时间以及看到的鳐鱼数量 (N_eagle)。
我想看看是否有一些岛屿的光线比其他岛屿多。由于射线瞄准数据(N_eagle)包含大量“0”，因此射线瞄准数据(N_eagle)包含大量“0”。 （几乎95%的数据），我选择ZIP。
获得的结果如下。

你能帮我解释一下结果吗？我不确定我是否理解，尤其是如何解释这两个区块以及如何比较岛屿之间的观察结果，尽管在互联网网站上进行了研究（我应该将结果放在指数中来解释它们吗？如何解释负号等......） .
我也愿意接受您的所有建议和建议（特别是在改善统计数据的有用互联网网站方面）。
祝您度过愉快的一天，非常感谢您的帮助，
海洋]]></description>
      <guid>https://stats.stackexchange.com/questions/646315/zip-interpretation</guid>
      <pubDate>Wed, 01 May 2024 21:26:51 GMT</pubDate>
    </item>
    <item>
      <title>比较离散数据的均值</title>
      <link>https://stats.stackexchange.com/questions/646304/compare-means-for-discrete-data</link>
      <description><![CDATA[我有两组观察结果，它们对应于两位不同希腊作家的长短格六音步诗中的单词数量。直方图呈漂亮的钟形，但数据不正常：一节诗中的单词数量只能是离散的。它也不是泊松分布：方差小于平均值（经验上，一节经文的单词数不少于 4 个，不超过 12 个）。

有什么方法可以比较两个平均值来判断它们是否有显著差异？
我考虑使用卡方来比较两个分布，但这样一来，我们似乎将 5 个单词的行和 6 个单词的行视为分类数据（这并非完全没有意义，但很尴尬）。
另一种选择是计算每 n 行（例如 5 行）的平均值，然后应用 z 检验或 t 检验（按中心极限定理）。
然而，这两种解决方案似乎都牵强附会。有没有更优雅的解决方案？
更新。根据下面评论的建议，我添加了 Shapiro 测试的结果和 qq 图。
a) Agronautica 样本的 Shapiro-Wilk 正态性检验返回
W = 0.94682，p 值 = 2.056e-12；对于伊利亚特样本 - W = 0.95116，p 值 = 8.582e-12
b) 两个样本的 QQ 图看起来相似：

upd2：为每个样本添加计数表（第一行是一节诗中的单词数）
iliad_sample
4 5 6 7 8 9 10 11 12
13 33 115 128 124 69 13 3 2
argo_sample
4 5 6 7 8 9 10 11
22 67 136 149 85 32 7 2]]></description>
      <guid>https://stats.stackexchange.com/questions/646304/compare-means-for-discrete-data</guid>
      <pubDate>Wed, 01 May 2024 19:07:14 GMT</pubDate>
    </item>
    <item>
      <title>如何使用不同的统计方法将单个数据集中各个变量的估计 p 值结合起来？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/646293/how-can-i-combine-p-values-estimated-for-individual-variables-within-a-single-da</link>
      <description><![CDATA[我正在分析具有两个类（案例/对照）的多元数据集。我计算了每个变量的 p 值，以使用两种不同的方法测试其辨别性能：1）单变量 t 检验，然后进行多重检验校正，2）PLS 回归和排列检验以建立零分布 H0。 H0 用于估计 PLS 回归系数的 p 值。
因此，每个变量都有两个 p 值，它们是通过根本不同的方法获得的。可以使用 Fisher 方法组合为每个特征获得的两个 p 值对吗？这些值是独立的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646293/how-can-i-combine-p-values-estimated-for-individual-variables-within-a-single-da</guid>
      <pubDate>Wed, 01 May 2024 17:13:13 GMT</pubDate>
    </item>
    <item>
      <title>渐近无偏+渐近零方差=一致性？</title>
      <link>https://stats.stackexchange.com/questions/646259/asymptotic-unbiasedness-asymptotic-zero-variance-consistency</link>
      <description><![CDATA[此处，Ben 表明无偏估计量 $\hat渐近方差为零的参数 $\theta$ 的 \theta$ 收敛于 $ 的概率\theta$。也就是说，$\hat\theta$ 是 $\theta$ 的一致估计量。
我们应该能够将条件放宽到渐近无偏性，这是有道理的：$\underset{n\rightarrow\infty}{\lim} \mathbb E\left[\hat\theta_n - \theta\right] = 0$。这似乎符合估计器接近真实参数值的精神......
...但是数学以前就让我感到惊讶。
我们可以将条件放宽到渐近无偏吗？证据是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/646259/asymptotic-unbiasedness-asymptotic-zero-variance-consistency</guid>
      <pubDate>Wed, 01 May 2024 00:32:23 GMT</pubDate>
    </item>
    </channel>
</rss>