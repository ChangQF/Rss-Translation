<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 19 Jul 2024 06:21:46 GMT</lastBuildDate>
    <item>
      <title>使用数据重新采样来确定子概率。多元收敛？</title>
      <link>https://stats.stackexchange.com/questions/651385/ascertaining-sub-probabilities-using-re-sampling-of-the-data-multivariate-conve</link>
      <description><![CDATA[
我正在尝试计算具有以下信息的在线游戏的赔付：

40% 的损失概率，值为 -2
10% 的损失概率，值为 -1
剩余 50% 的概率，四个潜在的非负赔付分别为 0、2、14 和 62。

基于对大约 150 个观察结果的基本分析，对真实概率的当前初始猜测：

$P_1 \approx 20.5\%$ 没有收益或损失，值为 0。
$P_2 \approx 28.5\%$ 收益为 2。
$P_4 \approx 0.8\%$ 收益为 14。
$P_6 \approx 0.2\%$ 收益为 62。

注意：$P_1 + P_2 + P_4 + P_6 = 50\%$
我做了一些初步抽样，并在绿色，带有蓝色数值。

40%、10%、50% 代表真实值，您可以看到我的基本样本摘要与 40% (38.10) 或 10% (8.84) 并不完全一致。
我可以对数据的不同子集进行重新采样以创建收敛概率。由于这是多变量的（四个概率的总和被限制为 50%），我可以使用一些建议。
我当然可以收集更多数据。
最终，目标是确定游戏是否完全公平（支出 = 0）或偏向正向或负向。如果为负，庄家获胜。如果为正，我可以赢。
如何通过重新采样数据以允许 CLT 收敛来找到四个未知概率的真实值？即求出$P_1, P_2, P_4, P_6$
这些是独立事件，IID。
$P_1$和$P_2$大致相等，我不知道哪个更大。$P_4$小得多，而$P_6$甚至更小。]]></description>
      <guid>https://stats.stackexchange.com/questions/651385/ascertaining-sub-probabilities-using-re-sampling-of-the-data-multivariate-conve</guid>
      <pubDate>Fri, 19 Jul 2024 05:46:03 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程文献建议</title>
      <link>https://stats.stackexchange.com/questions/651382/gaussian-process-literature-suggestion</link>
      <description><![CDATA[我对高斯过程还很陌生，希望能得到一些关于阅读材料的帮助。假设我有以下二维时间序列数据表：
$$\begin{bmatrix}s_{t_1}^{v_1} &amp; s_{t_2}^{v_1} &amp; \ldots &amp; s_{T}^{v_1} \\ s_{t_1}^{v_2} \\ \vdots &amp; &amp; \ddots \\
s_{t_1}^{V} &amp; \ldots &amp;&amp;s_{T}^{V}\end{bmatrix}$$
其中 $t, v$ 是 2 个不同的时间索引。我有两个问题：

假设“逐行”时间序列（在索引 $t$ 中）具有清晰的模式，可以使用高斯过程和平稳核函数进行建模。“逐列”时间序列（在索引 $v$ 中）也具有清晰的模式，但模式意味着不同的内核。在这种情况下，有没有一种方法可以联合建模整个矩阵？如果有，它们叫什么？（我隐约想到了类似 $k_1 \times k_2$ 内核的东西，用于对矩阵中的任意两个项目进行建模，但不确定这是否存在/是否符合我的要求）
假设“逐行 ...时间序列仍然具有如上所示的良好模式，但“逐列”时间序列没有如此良好的模式。具体来说，假设值不是独立的，例如，通过 ACF 图观察到不同列在不同滞后处的强烈季节性。有没有关于核函数形式的研究可以让我们整合这些信号/季节性（可以是指示变量的形式）？在某种程度上，我在想类似的事情：根据这些信号进行条件反射（通过差分等），列中的项目是独立的，我们将列带回到良好的一致模式（例如随机游走）。我们可以通过这个内核对所有列进行建模，它们将考虑到所有差异。

很乐意进一步讨论，感谢你们的任何建议，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651382/gaussian-process-literature-suggestion</guid>
      <pubDate>Fri, 19 Jul 2024 03:23:37 GMT</pubDate>
    </item>
    <item>
      <title>Hausman 测试结果报告</title>
      <link>https://stats.stackexchange.com/questions/651380/hausman-test-reults-report</link>
      <description><![CDATA[我一直在研究一个使用多级回归模型的研究项目，目前正在研究如何呈现豪斯曼检验结果。我见过一些论文，作者提到进行测试但没有包括数字，只是说随机效应模型更合适。
我想知道在稿件中分别报告每个模型的豪斯曼检验结果是否是标准做法。我知道如果测试不显著（p &gt; 0.05），则意味着随机效应模型更合适。但我很好奇是否通常还会报告测试值和其他统计细节，如卡方值，以支持这一结论。顺便说一下，我有八个模型]]></description>
      <guid>https://stats.stackexchange.com/questions/651380/hausman-test-reults-report</guid>
      <pubDate>Fri, 19 Jul 2024 01:33:38 GMT</pubDate>
    </item>
    <item>
      <title>在这个推导中如何使用分部求和技术？</title>
      <link>https://stats.stackexchange.com/questions/651379/how-is-summation-by-parts-technique-used-in-this-derivation</link>
      <description><![CDATA[在这个答案中，whuber 评论说答案中使用的技术是分部求和：

离散情况，假设$X \ge 0$取非负整数
值。然后我们可以将期望写为 $$\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\P}{\mathbb{P}} \E X = \sum_{k=0}^\infty k \P(X=k) $$ 现在，我们首先将其写为双和，然后
改变求和的顺序。观察到 $k = \sum_{j=0}^{k-1} 1$
（$k=0$ 的情况给出的上限小于下限，我们将其视为空和，即零）。这给出了 $$ 
\E X = \sum_{k=0}^\infty \sum_{j=0}^{k-1} 1 \cdot \P(X=k) $$ 现在，在这个双重和中，我们首先对 $j$ 求和，这显然等于 $\infty$。
观察到在内部求和中，指标满足不等式
$$
0 \le j \le k-1 $$ 解 $k$ 可得 $ k \ge j+1$，这又给出了新的内部和中的求和极限：$$ \E X = \sum_{j=0}^\infty \sum_{k=j+1}^\infty \P(X=k) = \sum_{j=0}^\infty \P(X &gt; j) $$ 这就是结果。连续的情况类似。

我去维基百科试图理解他的评论，但我不明白。

假设$\{f_k\}$和$\{g_k\}$是两个序列。那么，
$$
\sum_{k=m}^{n} f_k (g_{k+1} - g_k) = (f_{n+1} g_{n+1} - f_m g_m) - \sum_{k=m}^{n} g_{k+1} (f_{k+1} - f_k)。
$$

重新排列总数与分部求和有何关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/651379/how-is-summation-by-parts-technique-used-in-this-derivation</guid>
      <pubDate>Fri, 19 Jul 2024 01:25:52 GMT</pubDate>
    </item>
    <item>
      <title>给定协方差矩阵的最大条件熵</title>
      <link>https://stats.stackexchange.com/questions/651377/max-conditional-entropy-given-a-covariance-matrix</link>
      <description><![CDATA[随机向量 $(X,Y)$ 分布在 $\mathbb{R}^n \times \mathbb{R}^m$ 上，均值为零，协方差为 $\Sigma \in \mathbb{R}^{n\times m}_+.$
哪些分布可达到 $h(Y|X)$ 的最大值？多元高斯分布就足够了吗？
病态/非标准分布是什么样子的？
类似但不完全的事实：

当且仅当 $Y$ 是联合高斯分布时，$h(Y)$ 的最大值才可达到。
在那些具有固定条件协方差 $K_{Y|X} = E[(Y-E[Y|X])(Y-E[Y|X])&#39;]$ 的 $(X,Y)$ 中，$h(Y|X)$ 的最大值在联合高斯分布中达到（El Gamal 和Kim，第 2.2 节，方程 2.7）。（充分，非必要）
如果 $m=1$，则通过联合高斯分布达到最大值。（充分，非必要）
https://tselab.stanford.edu/mirror/ee376a_winter1617/Lecture_18.pdf
]]></description>
      <guid>https://stats.stackexchange.com/questions/651377/max-conditional-entropy-given-a-covariance-matrix</guid>
      <pubDate>Thu, 18 Jul 2024 23:32:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的卡方检验的 p 值这么高？</title>
      <link>https://stats.stackexchange.com/questions/651374/why-is-my-pvalue-for-chisquared-test-so-high</link>
      <description><![CDATA[我从值 = [0, 1] 中抽样，概率 = [.25, .75]。
我得到 25019 个零和 74981 个一。然而，通过卡方检验结果如下：
statistic=0.0196，pvalue=0.889
这似乎与我的直觉不符。
也许这是使用 Fisher 精确检验的原因？我应该使用 KS 测试来获取频率吗？
这是我的代码
N = 100000
values = [np.random.choice([0, 1], p=[.25, .75]) for _ in range(N)]
one_count = sum(values)
zero_count = len(values) - one_count
test_stat = (N*.75 - one_count)**2/(N*.75) + (N*.25 - zero_count)**2/(N*.25)
print(test_stat, 1 - stats.chi2.cdf(test_stat, 1))
]]></description>
      <guid>https://stats.stackexchange.com/questions/651374/why-is-my-pvalue-for-chisquared-test-so-high</guid>
      <pubDate>Thu, 18 Jul 2024 22:58:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么第一个主成分的特征值比其余主成分高得多？</title>
      <link>https://stats.stackexchange.com/questions/651370/why-is-the-amount-of-eigenvalue-of-the-first-principal-component-is-much-higher</link>
      <description><![CDATA[我有 16 个水质参数的时间序列，在使用 zscore 方法对其进行标准化后，我进行了主成分分析。这些是我的特征值 [7.62675203795075
2.25806327090482
1.72428547604366
1.44517173004117
1.30223669986535
1.18683140226834
1.01121663757535
0.840810909788259
0.68 3733271693109
0.641289626275986
0.427483271093487
0.367733123021385
0.243180116969796
0.216284282138318
0.132868635217870
0.0705244464795644]。

可以看到，第一个主成分的特征值和其余主成分相差很大，这是我在以前的研究中没有见过的，而且是随着间隔变小而减小的。是什么因素导致了结果这样？是不是我的数据不适合做主成分分析？我还做了KMO检验，结果是0.91。]]></description>
      <guid>https://stats.stackexchange.com/questions/651370/why-is-the-amount-of-eigenvalue-of-the-first-principal-component-is-much-higher</guid>
      <pubDate>Thu, 18 Jul 2024 21:47:30 GMT</pubDate>
    </item>
    <item>
      <title>定制配电配件</title>
      <link>https://stats.stackexchange.com/questions/651369/customized-distribution-fitting</link>
      <description><![CDATA[我有一个连续手术时长的样本，想将分布拟合到这个样本，从而生成相应的随机数。使用 Python 中的 scipy 库，我可以拟合各种分布，但得到的分布通常具有较高的 SSE（平方误差和）。
我正在探索是否有任何机器学习算法可以帮助我拟合自定义分布，提供类似于适形预测模型的下限和上限区间，或提供其他相关解决方案。
注意：我已经开发了一个预测模型，可以为每个患者提供个性化的手术时长预测。我正在考虑机器学习方法是否可以为样本中的每个患者提供个性化的分布集，而不是将一般分布拟合到整个样本。原因是我相信我可以利用我掌握的每位患者的其他信息（例如年龄、健康状况、手术类型、优先级），这样我就可以为患者创建更准确的不确定性集。
您能否列出一些好的潜在选项并附上参考资料，让我阅读它们的用例和实现？]]></description>
      <guid>https://stats.stackexchange.com/questions/651369/customized-distribution-fitting</guid>
      <pubDate>Thu, 18 Jul 2024 21:30:02 GMT</pubDate>
    </item>
    <item>
      <title>预测区间准确度与均方误差之间的权衡</title>
      <link>https://stats.stackexchange.com/questions/651367/tradeoff-between-prediction-interval-accuracy-mean-squared-error</link>
      <description><![CDATA[我的目标是量化气候协变量与 GDP 回归模型中的预测不确定性。我从一个模型开始，该模型以温度作为三次多项式，国家固定效应（$\alpha_i$}，年份固定效应（$\theta_t$）和国家增量时间趋势（$\gamma_i$）。
$$ 
GDP_{it} = \beta_1 * Temp_{it} + \beta_2 * Temp^2_{it} + \beta_3 * Temp^3_{it} + \alpha_i + \theta_t + \gamma_i
$$
我使用一些保留数据来收集上述模型的样本外均方误差。我还使用样本外预测的标准误差来构建 95% 的预测间隔，然后检查实际 Y（GDP）值在这些间隔内的实际百分比作为预测间隔准确度。
样本外 MSE：0.017
预测间隔准确度：0.577

为了使预测间隔准确度更接近 95% 的目标，我尝试了一个具有更高次数多项式时间趋势的不同模型，如下所示：
$$ 
GDP_{it} = \beta_1 * Temp_{it} + \beta_2 * Temp^2_{it} + \beta_3 * Temp^3_{it} + \alpha_i + \theta_t + \gamma_i + \gamma^2_i + \gamma^3_i
$$
样本外 MSE： 0.018
预测区间准确度：0.722

由于预测区间更宽，预测区间准确度大大提高，这可能是因为模型在训练数据中纳入了更多方差。但是，可能由于额外的模型复杂性导致过度拟合，第二个模型的 MSE 高于第一个模型。
我的问题与这个特定示例关系不大，而是与我普遍观察到的这种现象关系较大。我想知道：

是否存在一个单一的潜在现象，可以解释为什么增加模型复杂度会导致预测区间更接近 95% 的目标，同时增加模型的 MSE，或者这些本质上是独立的观察结果？

如果我的目标是尽可能量化模型不确定性，那么如何正确考虑以更高质量（在这种情况下意味着更宽）的预测区间换取随后的 MSE 增加？

]]></description>
      <guid>https://stats.stackexchange.com/questions/651367/tradeoff-between-prediction-interval-accuracy-mean-squared-error</guid>
      <pubDate>Thu, 18 Jul 2024 20:44:03 GMT</pubDate>
    </item>
    <item>
      <title>如何证明 Kendall 分布函数（或 Kendall 测量）的这种关系</title>
      <link>https://stats.stackexchange.com/questions/651366/how-to-prove-this-relation-for-kendalls-distribution-function-or-kendalls-mea</link>
      <description><![CDATA[肯德尔分布函数 (Nelsen, 2006, 第 163 页) 或肯德尔测度 (Salvadori et al., 2007, 第 148 页) 或肯德尔函数 (Joe, 2014, 第 419–422 页) 是 $U=(u,v)$ 的累积分布函数 (CDF)，其中 $U$ 服从 copula 分布：$U\sim C(u,v)$。设 $Z$ 为 $C(u,v) : Z=C(u,v)$ 的随机变量，则 Kendall 函数定义为
$$F_K(z;C)=Pr(Z\leq z;U\sim C(u,v))$$
Joe (2014) 没有明确列出可直接计算任何 $C(u,v)$ 的 $F_K(z)$ 表达式，而 Nelsen (2006, p. 163) 仅列出了阿基米德 copulas 的形式。Salvadori 等人。 (2007，等式 3.47，第 147 页) 也列出了阿基米德形式；然而，Salvadori 等人。 (2007，方程 3.49，第 148 页) 还列出了一种可直接计算的形式，适用于任何 $C(u,v)$，如下所示：
$$F_K(z)=z+\int_{z}^{1} \frac{\partial C(u,t)}{\partial u} du$$
其中 $t=C^{(-1)}(u,z)$，适用于 $0 \leq z \leq 1$。
我的问题：Salvadori 如何为 Kendall 函数推导出这种形式？]]></description>
      <guid>https://stats.stackexchange.com/questions/651366/how-to-prove-this-relation-for-kendalls-distribution-function-or-kendalls-mea</guid>
      <pubDate>Thu, 18 Jul 2024 20:08:21 GMT</pubDate>
    </item>
    <item>
      <title>样本外 RMSE 大于标准差的模型是否有任何价值？</title>
      <link>https://stats.stackexchange.com/questions/651365/is-there-any-value-in-models-that-have-a-larger-out-of-sample-rmse-than-a-standa</link>
      <description><![CDATA[我使用各种回归模型、弹性网络和偏最小二乘回归 (PLSR) 根据 x 值预测 y 值。为了量化模型的性能，我们使用均方根误差 (RMSE)。
我们对整个 x 和 y 数据进行回归，以及循环式预测（类似于交叉验证）。在这种循环式预测中，本质上会遗漏一定比例的 x 和 y 数据，比如 5%，模型在剩余 95% 的 x 和 y 数据上进行训练，并预测剩余的 5%。然后，遗漏接下来 5% 的 x 和 y 数据，并使用剩余的 95% 来训练模型并预测保留的 5%。这个过程会反复进行，直到所有 y 数据都被预测为样本外数据。
我担心的是 RMSE 相对于 y 的标准偏差。当使用循环法预测 y 时，样本外 RMSE 总是大于实验 y 本身的标准差。当完全基于 x 和 y 训练模型（非循环方式）时，样本内 RMSE 明显小于 y 的标准差。
据我所知，这意味着当预测样本外 y 的值时，猜测 y 为已知 y 的平均值比使用我们的回归更准确，并且我们应该使用更少的组件/参数/复杂性。
即使这些回归对样本外的预测很差，并且 RMSE 高于标准差，它们是否有任何价值或有效性？]]></description>
      <guid>https://stats.stackexchange.com/questions/651365/is-there-any-value-in-models-that-have-a-larger-out-of-sample-rmse-than-a-standa</guid>
      <pubDate>Thu, 18 Jul 2024 20:02:57 GMT</pubDate>
    </item>
    <item>
      <title>重新创建`lm`分类回归</title>
      <link>https://stats.stackexchange.com/questions/651363/recreate-lm-categorical-regression</link>
      <description><![CDATA[考虑以下代码，它使用来自正确模型的数据，使用两个分类变量和一个连续变量的 lm 进行回归，没有交互作用：
set.seed(12345)

n &lt;- 100
X1 &lt;- as.factor(sample(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), n, replace = TRUE))
X2 &lt;- as.factor(sample(c(&quot;d&quot;, &quot;e&quot;), n, replace = TRUE))
X3 &lt;- rnorm(n, mean = 0, sd = 1)

effeta &lt;- 1
effetb &lt;- 2
effetc &lt;- 3
effetd &lt;- 4
effete &lt;- 5

Y &lt;- 10 + 3*X3 + effeta*(X1 == &quot;a&quot;) + effetb*(X1 == &quot;b&quot;) + effetc*(X1 == &quot;c&quot;) + effetd*(X2 == &quot;d&quot;) + effete*(X2 == &quot;e&quot;) + rnorm(n, mean = 0, sd = 1)

model &lt;- lm(Y ~ X1 + X2 + X3)
print(summary(model))

输出为：
调用：
lm(formula = Y ~ X1 + X2 + X3)

残差：
最小值 1Q 中位数 3Q 最大值
-2.74679 -0.60571 0.06521 0.67873 1.85143

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 15.06741 0.20151 74.773 &lt; 2e-16 ***
X1b 0.95913 0.23994 3.997 0.000127 ***
X1c 1.96010 0.23637 8.292 7.26e-13 ***
X2e 1.08521 0.18887 5.746 1.10e-07 ***
X3 3.03324 0.09537 31.804 &lt; 2e-16 ***
---
显著性代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

残差标准误差：95 自由度上的 0.9327
多重 R 平方：0.9194，调整后的 R 平方：0.916
F 统计量：4 和 95 DF 上的 270.8，p 值：&lt; 2.2e-16

目标是从数学上理解到底发生了什么，然后在 R 中重现它。更具体地说：

可以说 X3 系数的估计是正确的。在线来源表明 lm 将以一个级别为参考，将其效果设置为零。在一般情况下，如何提前预测哪个变量将作为参考？也许是按字母顺序？一旦估计了效果，我们如何知道它们是正确的？
虽然没有参考，但我相信 R 使用虚拟变量将分类观察结果写入矩阵中，将所有内容组合在一起，就像 Searle 中提到的那样，然后进行多元线性回归。在这种情况下，我该如何写下这样的矩阵？

让我们用 $x_3 \in \mathbb{R}^n$ 代替 x3。然后：
\begin{equation*}
x_3 =
\begin{bmatrix}
x_{1,3} \\
x_{2,3} \\
\vdots \\
x_{n,3}
\end{bmatrix}
\end{equation*&gt;
要对分类变量进行盲目计算，可以这样写：
\begin{equation*}
x_1 =
\begin{bmatrix}
x_{1,1a} &amp;&amp; x_{1,1b} &amp;&amp; x_{1,1c} \\
x_{2,1a} &amp;&amp; x_{2,1b} &amp;&amp; x_{2,1c} \\
\vdots &amp;&amp; \vdots &amp;&amp; \vdots\\
x_{n,1a} &amp;&amp; x_{n,1b} &amp;&amp; x_{n,1c} \\
\end{bmatrix};
x_2 =
\begin{bmatrix}
x_{1,1d} &amp;&amp; x_{1,1e} \\
x_{2,1d} &amp;&amp; x_{2,1e}\\
\vdots &amp;&amp; \vdots \\
x_{n,1d} &amp;&amp; x_{n,1e} \\
\end{bmatrix}
\end{equation*&gt;
两个矩阵中的所有元素均为 $0$ 或 $1$。
然后输入：
\begin{equation*}
X =
\begin{bmatrix}
1 &amp;&amp;x_{1,1a} &amp;&amp; x_{1,1b} &amp;&amp; x_{1,1c} &amp;&amp; x_{1,1d} &amp;&amp; x_{1,1e} &amp;&amp; x_{1,3} \\
1 &amp;&amp; x_{2,1a} &amp;&amp; x_{2,1b} &amp;&amp; x_{2,1c} &amp;&amp; x_{2,1d} &amp;&amp; x_{2,1e} &amp;&amp;x_{2,3} \\\\
\vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots \\
1 &amp;&amp; x_{n,1a} &amp;&amp; x_{n,1b} &amp;&amp; x_{n,1c} &amp;&amp; x_{n,1d} &amp;&amp; x_{n,1e} &amp;&amp; x_{n,3}
\end{bmatrix}
\end{equation*
这样我们就可以进行回归分析 lm(Y~X)。但这显然不是实际发生的情况。我如何去掉一些列才能得到实际发生的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/651363/recreate-lm-categorical-regression</guid>
      <pubDate>Thu, 18 Jul 2024 19:45:11 GMT</pubDate>
    </item>
    <item>
      <title>在验证性因子分析中将权重固定为 1 - 如何获得重要性 (p) 值？</title>
      <link>https://stats.stackexchange.com/questions/651362/fixed-weights-to-1-in-confirmatory-factor-analysis-how-significance-p-value</link>
      <description><![CDATA[我有一个与此主题有些相关的问题。
我现在明白了为什么在验证分析中应该将 1 的值固定到其中一条路径上，我也明白可以使用各种技巧来释放这个参数。但我感兴趣的问题是，如何用标准化解决方案计算固定路径到 1 的统计显著性。
让我们考虑一个来自这里的例子，我将使用 R 中的 Lavaan 包的示例。
library(lavaanPlot)
library(foreign) 
library(lavaan)

dat &lt;- read.spss(&quot;https://stats.idre.ucla.edu/wp-content/uploads/2018/05/SAQ.sav&quot;, to.data.frame=TRUE, use.value.labels = FALSE)

m1a &lt;- &#39; f =~ q03 + q04 + q05&#39;
onefac3items_a &lt;- cfa(m1a, data=dat) 
summary(onefac3items_a) 

这里，正如您在摘要中看到的，没有统计意义，因为路径 f~q03 是固定的。
潜在变量：
估计 Std.Err z 值 P(&gt;|z|)
f =~ 
q03 1.000 
q04 -1.139 0.073 -15.652 0.000
q05 -0.945 0.056 -16.840 0.000

摘要相同标准化：
summary(onefac3items_a,standardized=TRUE)
(...)

潜在变量：
估计 Std.Err z 值 P(&gt;|z|) Std.lv Std.all
f =~ 
q03 1.000 0.583 0.543
q04 -1.139 0.073 -15.652 0.000 -0.665 -0.701
q05 -0.945 0.056 -16.840 0.000 -0.551 -0.572

但是，当使用标准化解决方案函数时，我得到了 p 值。怎么回事，为什么？这怎么可能呢？
standardizedsolution(onefac3items_a)
lhs op rhs est.std se z pvalue ci.lower ci.upper
1 f =~ q03 0.543 0.022 25.120 0 0.500 0.585
2 f =~ q04 -0.701 0.024 -29.710 0 -0.747 -0.655
3 f =~ q05 -0.572 0.022 -26.105 0 -0.615 -0.529

同样，当我使用 plot 时，我得到了显著性星号。
lavaanPlot(model = onefac3items_a, coefs=T, covs=T, stars = c(&quot;covs&quot;,&quot;latent&quot;,&quot;regress&quot;), stand=T)

我不完全理解这种机制。为什么一条固定的、没有计算系数的路径突然与标准化解具有统计意义？这里使用了什么方法？是程序简单地改变了固定路径的位置，例如，我们暂时将路径 f~q04 固定为 1 来计算 f~q03 的系数，还是方法完全不同？
附加问题：在 AMOS 中可以实现相同的效果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651362/fixed-weights-to-1-in-confirmatory-factor-analysis-how-significance-p-value</guid>
      <pubDate>Thu, 18 Jul 2024 19:36:32 GMT</pubDate>
    </item>
    <item>
      <title>g-prior 下的高斯线性模型边际似然</title>
      <link>https://stats.stackexchange.com/questions/651354/gaussian-linear-model-marginal-likelihood-under-g-prior</link>
      <description><![CDATA[考虑一个高斯线性模型，其结果向量为 $ n \times 1 $，中心预测变量矩阵为 $ X $：
$ y = \iota\alpha + X\beta + \varepsilon \quad \quad \varepsilon \sim \mathcal{N}(0, \sigma^2 I) $
先验为 $ p(\alpha, \sigma^2) = \sigma^{-2} $，g 先验为 $ p(\alpha, \sigma^2) = \sigma^{-2} $，g 先验为 $ p(\beta \mid \sigma^2) = \mathcal{N}\left(0, \sigma^2 g (X&#39;X)^{-1}\right) $.众所周知，边际似然$p(y)$可以以非常方便的形式导出
$ p(y) = \frac{\Gamma((n-1)/2)}{\sqrt{\pi}^{(n-1)}\sqrt{n}} \|{y} - \bar{{y}}\|^{-(n-1)} \times (1 + g)^{(n-1-p)/2} \times [1 + g(1 - R^2)]^{-(n-1)/2} $
其中$ R^2 $是回归$ y $时的判定系数$ X $ 和截距。这在各种来源中都有说明，例如此处 (等式 5) 和此处 (等式 10)。
是否有任何教科书或“原始论文”详细提供了此特定结果的推导？我大致了解贝叶斯共轭回归更新，但据我所知没有资料涵盖此特定设置（包括在积分出$ \beta $和$ \alpha $后，在先验不当的情况下求解$ \sigma^2 $的积分）。]]></description>
      <guid>https://stats.stackexchange.com/questions/651354/gaussian-linear-model-marginal-likelihood-under-g-prior</guid>
      <pubDate>Thu, 18 Jul 2024 16:33:43 GMT</pubDate>
    </item>
    <item>
      <title>伯恩鲍姆定理：对模型的强烈信念意味着似然函数必须用作数据缩减装置？</title>
      <link>https://stats.stackexchange.com/questions/651340/birnbaums-theorem-strong-belief-in-a-model-implies-the-likelihood-function</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651340/birnbaums-theorem-strong-belief-in-a-model-implies-the-likelihood-function</guid>
      <pubDate>Thu, 18 Jul 2024 13:45:03 GMT</pubDate>
    </item>
    </channel>
</rss>