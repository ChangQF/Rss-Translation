<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 07 Nov 2024 15:17:43 GMT</lastBuildDate>
    <item>
      <title>对具有二元因变量的分类自变量进行适当的统计显着性检验</title>
      <link>https://stats.stackexchange.com/questions/656900/appropriate-statistical-significance-test-for-categorical-independent-variables</link>
      <description><![CDATA[我试图确定语言预测模型是否比其他语言预测模型预测的情绪值准确得多。
我试图预测三种语言预测模型：英语、法语和其他。
以下是用于复制我的研究的虚拟数据：
set.seed(123)

#n 种语言
n_english &lt;- 123
n_french &lt;- 180
n_other &lt;- 52

#unique id
df &lt;- data.frame(id = 1:(n_english + n_french + n_other))

#将语言分配给 df#lang
df$lang &lt;- c(rep(&quot;English&quot;, n_english), rep(&quot;French&quot;, n_french), rep(&quot;Other&quot;, n_other))

#生成随机值
df$accuracy &lt;- NA
df$accuracy[df$lang == &quot;English&quot;] &lt;- rbinom(n_english, 1, prob = 0.87)
df$accuracy[df$lang == &quot;French&quot;] &lt;- rbinom(n_french, 1, prob = 0.75)
df$accuracy[df$lang == &quot;Other&quot;] &lt;- rbinom(n_other, 1, prob = 0.90)

tibble(df)
# A tibble: 355 × 3
ID 语言准确度
&lt;int&gt; &lt;chr&gt; &lt;int&gt;
1 1 英语 1
2 2 英语 1
3 3 英语 1
4 4 英语 0
5 5 英语 0
6 6 英语 1
7 7 英语 1
8 8 英语 0
9 9 英语 1
10 10 英语 1
# ℹ 更多 345 行
# ℹ 使用 `print(n = ...)` 查看更多行

hist(df$accuracy)

数据框表明语言变量具有伯努利分布，因此不满足参数检验的标准。我应该使用什么适当的测试统计数据来确定语言之间是否存在准确预测的显著结果？
下面是我尝试使用箱线图可视化数据的代码，以了解每种语言的准确性平均值差异：
df %&gt;%
group_by(lang) %&gt;%
summary(
mean = mean(accuracy),
sd = sd(accuracy)
) %&gt;%
ggplot(aes(x = lang)) +
geom_boxplot(aes(lower=mean-sd,upper=mean+sd,middle=mean,ymin=mean-0*sd,ymax=mean+0*sd),stat=&quot;identity&quot;) +
labs(x = &quot;lang&quot;, y = &quot;accuracy&quot;) +
theme_bw()


我希望测试统计数据能够显示每个变量准确预测均值的差异方面的显著性。
我在各个论坛上读到的类似问题的每个答案都建议我进行逻辑回归；但是，我并不是想建立一个回归模型来确定给定事件的二元结果的概率。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656900/appropriate-statistical-significance-test-for-categorical-independent-variables</guid>
      <pubDate>Thu, 07 Nov 2024 15:07:43 GMT</pubDate>
    </item>
    <item>
      <title>广义线性模型的假设</title>
      <link>https://stats.stackexchange.com/questions/656898/assumptions-of-a-glm</link>
      <description><![CDATA[我在 R 中运行 glm，从残差图来看，模型并不完全符合假设。我的问题是这些假设需要达到什么程度，或者有些偏差可以接受吗？我尝试过转换、添加交互项、删除异常值等，但似乎没有什么可以改善它。
我正在根据物种比例对产量进行建模，同时还包括虚拟变量以解释特殊混合物/处理（对照）
glm(Annual_DM_Yield ~ 0 + Grass + Legume + I(Legume2) + I(Legume3) + Herb +
AV +
PRG_300N + PRG_150N + PRG_0N + PRGWC_0N + PRGWC_150N + N_Treatment_150N,
data=yield )
任何帮助都非常感谢！
]]></description>
      <guid>https://stats.stackexchange.com/questions/656898/assumptions-of-a-glm</guid>
      <pubDate>Thu, 07 Nov 2024 14:16:18 GMT</pubDate>
    </item>
    <item>
      <title>通过多元数据集进行训练</title>
      <link>https://stats.stackexchange.com/questions/656897/training-by-multivariate-data-sets</link>
      <description><![CDATA[我有以下任务要做：通过连续 3 天的训练来预测第 4 天。每天的数据代表一个尺寸为 24x25 的 CSV 文件。每个 CSV 文件的每个数据点都是像素。我需要使用回归（线性、岭）和 LSTM 等模型。
每个模型训练 3 天：
对于回归模型：通过展平处理每天的数据后，我将数据转置为形状：（600, 3）。
对于 lstm 模型：通过展平处理每天的数据后，我将数据保持原样，形状：（3, 600）。
例如这样：
day_1 = [0.1, 0.2, ..., 0.6] # 第 1 天的 600 个特征
day_2 = [0.15, 0.25, ..., 0.65] # 第 2 天的 600 个特征
day_3 = [0.2, 0.3, ..., 0.7] # 第 3 天的 600 个特征

X_train_linear_ridge = np.array([
[0.1, 0.15, 0.2], # 第 1 天、第 2 天、第 3 天的特征 1
[0.2, 0.25, 0.3], # 第 1 天、第 2 天、第 3 天的特征 2
# ...
[0.6, 0.65, 0.7] # 第 1 天、第 2 天、第 3 天的特征 600
]) # 形状：(600, 3)

X_train_lstm = np.array([
[0.1, 0.2, ..., 0.6], # 第 1 天的特征
[0.15, 0.25, ..., 0.65], # 第 2 天的特征
[0.2, 0.3, ..., 0.7] # 第 3 天的特征
]) # 形状：(3, 600)


有人能告诉我，为形状为 (600, 3) 的回归模型和形状为 (3, 600) 的 lstm 准备数据在概念上是否正确吗？
我的动机：
LSTM：LSTM 旨在处理具有顺序、时间关系的数据。通过输入形状为 (3, 600) 的数据（代表 3 个时间步骤，每个步骤有 600 个特征），LSTM 可以学习整个序列中的模式。每个时间步骤对应数据中的一天，而 600 个特征代表当天的单个值。此结构对于 LSTM 利用时间依赖性至关重要。
线性和岭回归：这些模型缺乏固有的顺序处理能力。它们将每个输入解释为单个平面向量。为了近似顺序学习，我们可以将每天的数据视为一个单独的特征，创建一个形状为 (600, 3) 的设置，其中 600 个特征在 3 天内“堆叠”。每一天都成为回归模型的一个特征，但它无法像 LSTM 那样捕获时间依赖性。
我的概念对于回归和 lstm 模型的形状是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/656897/training-by-multivariate-data-sets</guid>
      <pubDate>Thu, 07 Nov 2024 14:09:12 GMT</pubDate>
    </item>
    <item>
      <title>R：VGLM 适合部分比例几率模型，无法指定要保持比例几率的变量</title>
      <link>https://stats.stackexchange.com/questions/656895/r-vglm-to-fit-a-partial-proportional-odds-model-unable-to-specify-which-variab</link>
      <description><![CDATA[确认我的因变量是一个有序因子，性别是 0.1 的因子，感兴趣的主要变量（首先列出）是我主要关注的，并且使用布伦特检验时假设只对它成立。
当尝试使用 VGLM 进行拟合并指定它被视为符合道具赔率，但不适用于其他时，我并不高兴。
&gt; logit_model &lt;- vglm(dep_var ~ primary_indep_var + 
+ gender + 
+ var_3 + var_4 + var_5,
+ 
+ family =cumulative(parallel = c(TRUE ~ 1 + primary_indep_var), 
+ link = &quot;cloglog&quot;), 
+ data = temp)

x$terms %||% attr(x, &quot;terms&quot;) %||% stop(&quot;no term component nor attribute&quot;) 中的错误： 
no term component nor attribute

如能得到任何帮助，我们将不胜感激！
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/656895/r-vglm-to-fit-a-partial-proportional-odds-model-unable-to-specify-which-variab</guid>
      <pubDate>Thu, 07 Nov 2024 13:58:28 GMT</pubDate>
    </item>
    <item>
      <title>$\epsilon$-贪婪算法对 $k$ 臂老虎机的精确后悔值</title>
      <link>https://stats.stackexchange.com/questions/656894/exact-regret-of-epsilon-greedy-algorithm-for-k-armed-bandit</link>
      <description><![CDATA[对于 $k$ 臂老虎机，$\epsilon$ 贪婪算法在每一轮中以 $\epsilon$ 的成功概率抛硬币，并执行以下操作：

如果不成功，则选择迄今为止最好的臂，并且
如果成功，则随机选择一个臂。

我想证明
$$
\lim_{n\to\infty}R_n=\frac{\epsilon}{k}\sum_{i}\Delta_i
$$
其中 $\Delta_i$ 是臂 $i$。我可以看到遗憾值受右侧值的限制，因为我们可以假设在每个阶段，到目前为止最好的臂实际上是最好的臂。但我看不出如何严格证明左侧限制了右侧。我必须以某种方式论证，随着 $n$ 趋近于无穷大，每个臂的观测平均值趋近于其预期值，因此最终我们会得到右侧的线性界限，但我不知道如何做到这一点。（我怀疑应该使用大数定律，但我不知道如何阐明这一点。）]]></description>
      <guid>https://stats.stackexchange.com/questions/656894/exact-regret-of-epsilon-greedy-algorithm-for-k-armed-bandit</guid>
      <pubDate>Thu, 07 Nov 2024 13:45:04 GMT</pubDate>
    </item>
    <item>
      <title>Cox 比例风险与 AFT 和比例风险假设的比较</title>
      <link>https://stats.stackexchange.com/questions/656893/cox-proportionall-hazards-compared-to-aft-and-the-proportional-hazards-assumptio</link>
      <description><![CDATA[我正在使用 R 对包含数百万行的大型人口数据集进行生存分析。我的第一个选择是 cox 回归
cox_model &lt;- coxph(Surv(time, event) ~ 
var1+ var2+ var3 , data = data)

然而，基于 Schoenfeld 残差，比例风险假设在某些协变量和全局上被违反。我尝试了时间转换，但考虑到数据的大小，模型无法进行计算处理（有关 70-80Gb 向量分配的错误消息）。
作为替代方案，我尝试拟合 AFT。
model_wei &lt;- survreg(Surv(time, event)~ 
var1+ var2+ var3 , data = data, dist = &quot;weib&quot;, maxiter=100)

在使用 exp、wei、logn 和 logl 创建模型后，logn 模型（基于 AIC）提供了最佳拟合。
您能帮助我理解 Cox 回归中的风险比和 AFT 中的 exp(coef) 之间的解释差异吗？
我为 AFT 选择最佳分布的程序是比较 AIC，然后绘制残差以检查正态性为：
resid &lt;- log(data$time) - model.lognormal$linear.predictors 
qqnorm(resid)
qqline(resid)

结果图为

当使用残差的 Kaplan-Meier 估计量来考虑审查时
fitted_values &lt;- model_logn$linear.predictors
resids &lt;- (log(model_logn$y[, 1]) - fitted_values) / model_logn$scale

resKM &lt;- survfit(Surv(resids, event) ~ 1, data = data)
plot(resKM, mark.time = FALSE, xlab = &quot;AFT Residuals&quot;, ylab = &quot;Survival Probability&quot;)
xx &lt;- seq(min(resids), max(resids), length.out = 35)
yy &lt;- exp(- exp(xx))
lines(xx, yy, col = &quot;red&quot;, lwd = 2)
legend(&quot;bottomleft&quot;, c(&quot;KM 估计&quot;, &quot;95% CI KM 估计&quot;, 
&quot;极值分布的生存函数&quot;), 
lty = c(1,2,1), col = c(1,1,2), bty = &quot;n&quot;)

来源
我得到：

这可以被认为是足够的吗？
如果不是，我有什么选择？
最后一个问题是，如果风险似乎不会随着时间的推移而发生太大变化，并且方向始终保持不变，那么即使比例风险假设被违反，提出一个 cox 回归模型是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/656893/cox-proportionall-hazards-compared-to-aft-and-the-proportional-hazards-assumptio</guid>
      <pubDate>Thu, 07 Nov 2024 13:33:11 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 模型的 MA 分量中的参考模型是什么？</title>
      <link>https://stats.stackexchange.com/questions/656889/what-is-the-reference-model-in-the-ma-component-of-an-arima-model</link>
      <description><![CDATA[ARIMA 中的 MA 组件被定义为一种根据滞后观测值的残差（误差）预测值的模型。
但是，这些残差是如何计算的？
当然，它们是作为实际值和预测值之间的差值获得的。
但是，这些预测来自哪个模型？它是一个对最后 q 个观测值取平均值的移动平均模型吗？
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/656889/what-is-the-reference-model-in-the-ma-component-of-an-arima-model</guid>
      <pubDate>Thu, 07 Nov 2024 13:01:27 GMT</pubDate>
    </item>
    <item>
      <title>一个简单的隐马尔可夫模型</title>
      <link>https://stats.stackexchange.com/questions/656887/a-simple-hidden-markov-model</link>
      <description><![CDATA[我正在阐明简单隐马尔可夫模型的 EM 算法的精确公式。这个问题来自 Keener 的教科书《理论统计学》第 9 章第 25 个问题，其中介绍了几个用于计算 MLE 的 EM 算法的实际示例。
这个问题假设以下简单马尔可夫过程。令 $X_1, X_2, \cdots$ 为伯努利变量，$EX_1=1/2$，联合质量函数由递归确定
$$ P(X_{k+1}\ne x_k \vert X_1 =x_1, \cdots, X_k=x_k)=\theta, \quad n=, 1, 2, \cdots $$
且 $X_n, n\ge 1$ 在 $\left\{0, 1\right\}$ 上形成马尔可夫链。现在假设我们能够观察到误差，因此通过$Y_1, Y_2, \cdots$，它们是给定$X_i$条件独立的伯努利变量，满足
$$ P(Y_i \ne X_i\vert X_1, X_2, \cdots) = \gamma$$
其中$\gamma$是已知常数，我们希望通过 EM 算法估计$\theta\in(0, 1)$。
一旦我得到$X$和$Y$ 建立 E-step，即
$$
\begin{cases}
P_{\theta}(X, Y) &amp;= P_{\theta}(Y\vert X)P_{\theta}(X)\\
&amp;= \prod_{i=1}^{n} P_{\theta}(Y_i\vert X_i)P_{\theta}(X_i\vert X_{i-1}), 
\end{cases}
$$
目前还没有办法将这个质量函数总结成一个单一的闭式形式。此外，最终应该计算期望值$E_{\theta}[X\vert Y]$，引入一些新变量使公式更简单的巧妙方法似乎是必要的。
任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/656887/a-simple-hidden-markov-model</guid>
      <pubDate>Thu, 07 Nov 2024 11:36:54 GMT</pubDate>
    </item>
    <item>
      <title>使用哪种类型的模型/分析来预测时间序列数据中的事件</title>
      <link>https://stats.stackexchange.com/questions/656886/what-type-of-model-analysis-to-use-to-predict-events-in-time-series-data</link>
      <description><![CDATA[我有一堆包含已知真实世界事件的时间序列（每个 t/s 一个事件）。事件不一定是 t/s 中可见的变化，但已知它已在现实世界中发生。
我想知道我是否可以训练一个模型来了解事件之前是否存在任何特征模式，以用于预测其他 t/s 或未来相同 t/s 中的类似事件。
这不是干预分析，因为我们不关心事件发生后发生了什么。这也不是变点分析，因为我们确切地知道事件发生的时间。这也不是异常检测，因为事件不一定会对数据产生影响。
RNN 是否是这项任务的正确或最佳工具？这种分析有通用名称吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656886/what-type-of-model-analysis-to-use-to-predict-events-in-time-series-data</guid>
      <pubDate>Thu, 07 Nov 2024 11:21:14 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归何时优于随机森林？</title>
      <link>https://stats.stackexchange.com/questions/656884/when-does-logistic-regression-outperform-random-forests</link>
      <description><![CDATA[假设我们有一个二元分类问题，那么两种可能的统计方法是逻辑和随机森林。
从理论的角度来看，我很清楚，如果对数概率$\log(\frac{q}{1-q})$和特征$X_1, ... X_p$之间有足够的线性关系，那么逻辑在构造上就是更强的候选者。
但是，我们如何以图形方式测试我们是否真的有这种线性关系？例如，在线性回归的情况下，这相当容易做到：我们可以绘制目标与协变量的关系，并且我们对目标和协变量之间的关系的线性程度有合理的理解。但是逻辑的情况呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/656884/when-does-logistic-regression-outperform-random-forests</guid>
      <pubDate>Thu, 07 Nov 2024 11:12:01 GMT</pubDate>
    </item>
    <item>
      <title>𝑛 相关随机变量的加权平均值的方差</title>
      <link>https://stats.stackexchange.com/questions/656883/variance-of-weighted-average-of-correlated-random-variables</link>
      <description><![CDATA[此答案解释了如何计算 n 个相关随机变量的平均值的方差。如何计算 n 个相关随机变量的加权平均值？我的随机变量是联合多元高斯分布的。
此答案解释了如何计算单个随机变量的不同实现的加权平均值，其中权重也是随机变量的实现。我的权重不是随机变量，而是固定数字，所以问题不同。
我知道这很可能是纸笔数学的问题，但我担心这个问题超出了我的能力。]]></description>
      <guid>https://stats.stackexchange.com/questions/656883/variance-of-weighted-average-of-correlated-random-variables</guid>
      <pubDate>Thu, 07 Nov 2024 11:06:46 GMT</pubDate>
    </item>
    <item>
      <title>当增加对数正态分布的标准差时，它是否会趋向于指数分布？</title>
      <link>https://stats.stackexchange.com/questions/656881/does-a-log-normal-distribution-tend-to-an-exponential-distribution-when-increas</link>
      <description><![CDATA[对数正态分布 lognorm(mu, sigma) 随着其标准差 sigma 的增加而变得越来越偏斜。
随着 sigma 的增加，分布是否趋向于指数分布 exp(lambda) ？
这两个函数及其参数之间有什么关系吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656881/does-a-log-normal-distribution-tend-to-an-exponential-distribution-when-increas</guid>
      <pubDate>Thu, 07 Nov 2024 10:59:27 GMT</pubDate>
    </item>
    <item>
      <title>在 mgcv 中选择 GAM 的惩罚，bs =“ts”或 select = TRUE 之间的区别？</title>
      <link>https://stats.stackexchange.com/questions/656878/choosing-penalty-for-gam-in-mgcv-difference-between-bs-ts-or-select-true</link>
      <description><![CDATA[我正在研究一些环境数据，使用 GAM 模型来了解土壤中 DOC 的控制因素。我在选择合适的 GAM 模型和惩罚方面遇到了一些问题。在 mgcv::gam 中，有两种方法可以向协变量引入额外的惩罚：
*) bs = &quot;ts 用于薄板样条函数； bs = &quot;cs&quot; 表示三次样条函数，用于惩罚零空间。
*) select = TRUE 表示对模型中的所有样条函数进行双重惩罚，同时惩罚零空间和范围空间。
更多信息请参见 此处 和 此处。
我有这四个模型
mod1 &lt;- mgcv::gam(y ~ s(x1) + s(x2) + s(x3), select = TRUE)
mod2 &lt;- mgcv::gam(y ~ s(x1, bs = &quot;ts&quot;) + s(x2, bs = &quot;cs&quot;) + s(x3, bs = &quot;ts&quot;))
mod3 &lt;- mgcv::gam(y ~ s(x1) + s(x2, bs = &quot;cr&quot;) + s(x3), select = TRUE)
mod4 &lt;- mgcv::gam(y ~ s(x1, bs = &quot;ts&quot;) + s(x2, bs = &quot;cs&quot;) + s(x3), select = TRUE)
s(x1) 和s(x3) 是具有一定意义的预测因子，而 s(x2) 是时间。
我在这里尝试做的事情：我想通过额外的惩罚来选择一个模型，同时还为一些变量选择样条基函数的类型，我对收缩方法与双重惩罚方法的用法感到困惑。
对我来说，模型 mod4 没有意义，因为它会对基样条的范围和零空间造成 select = TRUE 的双重惩罚，而样条的零空间已经受到 &quot;ts&quot; 和 &quot;cs&quot; 收缩版本的惩罚。
同时，mod3 在我看来是在您有一个时间变量需要通过 bs = 进行平滑的情况下的最佳选择&quot;cr&quot; 加上一个协变量，并且您希望在零空间和范围空间中惩罚平滑项以进行模型选择。
根据我对此的基本理解，最佳选择是 mod2 或 mod3，因为 mod1 只会假设所有平滑的薄板基函数，而情况并非如此，因为 s(x2) 是时间。
最后，如果 mod4 规范完全错误，mgcv::gam 不应该弹出警告或错误吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656878/choosing-penalty-for-gam-in-mgcv-difference-between-bs-ts-or-select-true</guid>
      <pubDate>Thu, 07 Nov 2024 09:03:35 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型的平行中介分析</title>
      <link>https://stats.stackexchange.com/questions/656876/parallel-mediation-analysis-with-linear-mixed-model</link>
      <description><![CDATA[我想用线性混合模型进行并行中介分析，因为我的数据是非正态的。
HAMA_psy 和 RRS_brood 是中介，Sadness 是 IV，Melankoli 是 DV。
我已经创建了一个模型，并使用引导函数计算了间接效应，但是当我不使用 lavaan 时，我没有考虑路径间依赖关系。这就是我认为它错误的原因。
如果您能帮助我使用 LME 进行并行调解，我将非常高兴。
我的模型是：

sadness_to_hama_psy &lt;- lmer(HAMA_psy ~ Sadness + (1 | PartID), data = df)
sadness_to_rrs_brood &lt;- lmer(RRS_brood ~ Sadness + (1 | PartID), data = df)
hama_psy_to_melankoli &lt;- lmer(Melankoli ~ HAMA_psy + Sadness + (1 | PartID), data = df)
rrs​​_brood_to_melankoli &lt;- lmer(Melankoli ~ RRS_brood + Sadness + (1 | PartID), data = df)
indirect_effect_hama_psy &lt;- fixef(sadness_to_hama_psy)[&quot;悲伤&quot;] * fixef(hama_psy_to_melankoli)[&quot;HAMA_psy&quot;]
indirect_effect_rrs_brood &lt;- fixef(sadness_to_rrs_brood)[&quot;悲伤&quot;] *fixef(rrs_brood_to_melankoli)[&quot;RRS_brood&quot;]

total_indirect_effect &lt;- indirect_effect_hama_psy + indirect_effect_rrs_brood

direct_effect &lt;- fixef(hama_psy_to_melankoli)[&quot;悲伤&quot;] + fixef(rrs_brood_to_melankoli)[&quot;悲伤&quot;]

total_effect &lt;- total_indirect_effect + direct_effect
boot_results &lt;- boot(data = df, 
statistic = function(data, indices) {
d &lt;- data[indices, ] # 重新采样数据

# 将模型重新拟合到引导样本
model_sadness_to_hama_psy &lt;- lmer(HAMA_psy ~ Sadness + Stage + (1 | PartID), data = d)
model_sadness_hama_psy_to_melankoli &lt;- lmer(Melankoli ~ Sadness + HAMA_psy + Stage + (1 | PartID), data = d)
model_sadness_rrs_brood_to_melankoli &lt;- lmer(Melankoli ~ Sadness + RRS_brood + Stage + (1 | PartID), data = d)

# 从每个模型中提取系数（固定效应）
coefs_sadness_to_hama_psy &lt;- fixef(model_sadness_to_hama_psy)
coefs_sadness_hama_psy_to_melankoli &lt;- fixef(model_sadness_hama_psy_to_melankoli)
coefs_sadness_rrs_brood_to_melankoli &lt;- fixef(model_sadness_rrs_brood_to_melankoli)

# 计算直接和间接影响
direct_effect &lt;- coefs_sadness_hama_psy_to_melankoli[&quot;Sadness&quot;]

indirect_hama_psy &lt;- coefs_sadness_to_hama_psy[&quot;Sadness&quot;] * coefs_sadness_hama_psy_to_melankoli[&quot;HAMA_psy&quot;]

indirect_rrs_brood &lt;- coefs_sadness_rrs_brood_to_melankoli[&quot;Sadness&quot;] * coefs_sadness_rrs_brood_to_melankoli[&quot;RRS_brood&quot;]

total_indirect_effect &lt;- indirect_hama_psy + indirect_rrs_brood

},
R = 1000)

boot.ci(boot.out = boot_results, type = &quot;perc&quot;)

]]></description>
      <guid>https://stats.stackexchange.com/questions/656876/parallel-mediation-analysis-with-linear-mixed-model</guid>
      <pubDate>Thu, 07 Nov 2024 08:18:53 GMT</pubDate>
    </item>
    <item>
      <title>Seber 和 Lee 的“线性回归分析”中的证明</title>
      <link>https://stats.stackexchange.com/questions/656871/proof-in-linear-regression-analysis-by-seber-and-lee</link>
      <description><![CDATA[在附录结果 A.2.2 中，作者想要证明：
如果 $A$ 是任意矩阵，并且 $P$ 和 $Q$ 是任意一致的非奇异矩阵，则 $rank(PAQ) = rank(A)$
他们通过给出以下不等式序列开始证明：
$rank(A) \leq rank (AQ) \leq rank(AQQ^{-1}) = rank(A)\quad\quad [1]$
此前，在 A.2.1 中，他们已经证明如果 $A$ 和 $B$ 是一致矩阵，那么，$rank(AB) \leq \min({rank(A),rank(B)})$
虽然这个结果可以用来建立 $[1]$ 后面的不等式，但我不清楚第一个不等式 $rank(A)\leq rank(AQ)$ 是如何建立的。如果 $Q$ 是非奇异的，那么 $rank(A)\leq rank(AQ)$ 是否在其他地方已知？任何足够简单的证明该结果或展示该结果的地方都将不胜感激。
这里是他们书中对该结果的陈述和证明的 imgur 链接，在下面内联复制：
]]></description>
      <guid>https://stats.stackexchange.com/questions/656871/proof-in-linear-regression-analysis-by-seber-and-lee</guid>
      <pubDate>Thu, 07 Nov 2024 05:18:35 GMT</pubDate>
    </item>
    </channel>
</rss>