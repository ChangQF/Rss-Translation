<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sun, 06 Apr 2025 06:26:24 GMT</lastBuildDate>
    <item>
      <title>有意义的随机森林及其适合性</title>
      <link>https://stats.stackexchange.com/questions/663573/making-sense-of-random-forest-and-its-suitability</link>
      <description><![CDATA[建议我使用随机森林而不是多级模型。原因是我的一些研究变量是基于性别的角色，这是一个已知的事实，因此，多层次并没有告诉我除了确认现有现实之外的新事物。我现在正在尝试理解并理解随机的森林结果，但我无法理解它们。为了解释，建议我编译频率表。但是，当我查看频率和可变重要性时，它们根本没有意义。  我对模型的期望或理解是，那些具有较高频率或出现的人的排名将更高，并且那些较低的人的重要性较低，并且在该顺序下降低。目标变量是实践。通过指示家庭中是否有该特定属性（现场标题）的人来编码数据。这个想法是确定在塑造实践中至关重要的因素；数据已汇总到家庭水平。
数据位置：
 https://drive.google.com/drive/folders/1zoqup8sdw80ur1fbz0w0_x7bmjthzbpp？usp = sharing  
代码：
 ＃加载必要的库
需要（Randomforest）
需要（ggplot2）
需要（dplyr）
需要（福卡）
需要（CARET）
需要（reshape2）

＃加载数据集
setWD（&#39;文件位置&#39;）

dat＆lt;  -  read.csv（&#39;model_1.csv&#39;）


dat  $练习＆lt;  -  as.factor（dat $ 练习）
表（dat $练习）

set.seed（222）
ind＆lt;  - 样本（2，nrow（dat），替换= true，prob = c（0.7，0.3））
train＆lt;  -  dat [ind == 1，]
test＆lt;  -  dat [ind == 2，]

桌子（火车$练习）

rf＆lt;  -  rancomporest（练习〜。，dat = dat，entiment = t，proximity = true，na.Action = na.Roughfix） 

RF
RF $重要
P2＆lt;  - 预测（RF，测试）

dt＆lt;  -  as.data.frame（rf  $ quiention）
nm＆lt;  -  row.names（dt）
so＆lt;  -  as.data.frame（dt）
因此$ 变量＆lt;  -  nm

so＆lt; -so [订单（SO $ sundecreasegini，降低= true），]，]，]

＃barplot
ggplot（so，aes（x = varible，y = sundecreasegini）） + 
  geom_bar（stat =＆quot; Identity＆quot;）+coord_flip（）

＃基于重要性的排序变量
因此， $ variable＆lt;  - 因子（$ 变量，latver = so $ variable）  
ggplot（so，aes（x = fct_reorder（variable，sundecreasegini），y = sundecreasegini）） + 
  geom_bar（stat =＆quot;身份＆quot;） + 
  coord_flip（） +
  实验室（x =;变量;
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/663573/making-sense-of-random-forest-and-its-suitability</guid>
      <pubDate>Sun, 06 Apr 2025 04:55:01 GMT</pubDate>
    </item>
    <item>
      <title>重量衰减和L2正则化之间的差异</title>
      <link>https://stats.stackexchange.com/questions/663570/difference-between-weight-decay-and-l2-regularization</link>
      <description><![CDATA[我正在阅读[Ilya loshchilov的作品] [1]关于脱钩的重量衰减和正则化。最大的要点似乎是重量衰减， $ l^2 $  norm norm正规化对于SGD而言相同，但亚当的不同。我很惊讶地学习这一点，因为我读过的书籍使用了重量衰减， $ l^2 $ 在大多数情况下互换。是否还有其他上下文，重量衰减和 $ l^2 $  norm正规化产生不同的效果，而不是Adam（例如Adam）？
 [1]：I。，＆amp; Hutter，F。（2019）。重量衰减正则化。在国际学习表现会议上。取自 https://arxiv.org/abs/1711.0511.05101 ]]></description>
      <guid>https://stats.stackexchange.com/questions/663570/difference-between-weight-decay-and-l2-regularization</guid>
      <pubDate>Sun, 06 Apr 2025 00:43:37 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯估计是否需要有限的人口校正？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/663568/does-bayesian-estimation-need-finite-population-correction</link>
      <description><![CDATA[贝叶斯估计是否假定无限的人口，是否要求有限的人口纠正？
假设我们想估计有限人口的平均值，假设IID值是在正态分布中替换而不替换的。]]></description>
      <guid>https://stats.stackexchange.com/questions/663568/does-bayesian-estimation-need-finite-population-correction</guid>
      <pubDate>Sat, 05 Apr 2025 23:52:19 GMT</pubDate>
    </item>
    <item>
      <title>AUROC情节的巨大步骤</title>
      <link>https://stats.stackexchange.com/questions/663567/huge-steps-in-auroc-plot</link>
      <description><![CDATA[我正在为二进制分类任务建立模型。由于我的数据集很小（〜86个带有68类0和18类的样本），因此我使用带有神经网络模型的嵌套K折交叉验证（5英寸循环和5个圈循环）。我正在绘制每个测试的AUROC，并从中获得平均AUROC。但是，我注意到我的地块中的步骤异常大，并且想知道我可以做些什么来解决这个问题。在下面的屏幕截图中，每种颜色代表测试AUROC。谢谢！
  &lt;img alt =“ auroc =” auroc =“ auroc =”]]></description>
      <guid>https://stats.stackexchange.com/questions/663567/huge-steps-in-auroc-plot</guid>
      <pubDate>Sat, 05 Apr 2025 23:15:29 GMT</pubDate>
    </item>
    <item>
      <title>通过/失败实验的稳健性定量</title>
      <link>https://stats.stackexchange.com/questions/663561/robustness-quantification-of-pass-failed-experiment</link>
      <description><![CDATA[我的下表对于在通过/失败的任务中，在两个不同条件下测试的两种不同方法，例如 $ 4/5 $ 意味着该方法在5个试验中成功了4次。
 


 
条件1 
条件2 




方法1 
  $ 4/5 $  
  $ 4/5 $  


方法2 
  $ 4/5 $  
在


 
显然，样本量很小，但是我想以某种方式量化这两种方法的鲁棒性 。 我可以用什么方法来回答这个问题？
我应该尝试计算一些p值并检查统计意义吗？还是计算一些置信区间？使用boottappagping在小样本量问题上工作会很有意义吗？
到目前为止，我一直在想我可以使用Fisher的精确测试，因为它也适用于小样本量，请将每对{条件，方法}与二项式分布的随机抽奖进行比较（不确定我需要多少平局）来获得P值，并可能在统计上很重要，需要更多的试验？
也许我可以计算每对{条件，方法}？]]></description>
      <guid>https://stats.stackexchange.com/questions/663561/robustness-quantification-of-pass-failed-experiment</guid>
      <pubDate>Sat, 05 Apr 2025 19:01:12 GMT</pubDate>
    </item>
    <item>
      <title>转换凸壳顶点重量以均匀分布</title>
      <link>https://stats.stackexchange.com/questions/663559/transform-convex-hull-vertex-weights-for-uniform-distribution</link>
      <description><![CDATA[给定一个 $ n $   - 维二等凸面由 $ m $  vertices  $ v $ v $  \ le n \ le 10 $ ，我想生成 $ p $ 船体中包含的随机点，并通过船体体积尽可能均匀地分布。  $ p $ 可能是成千上万。
生成这些点的快速方法是产生一个随机的权重矩阵 $ w $  shape  $（p，m）$ ，其中每一行都是正常且均匀分布的；然后由于 $ v $  is  $（m，n）$ ，我可以得到product  $ r = wv $ 具有一些正确的特征：

所有要点肯定会包含在船体中
它是随机的

但是，它绝对不是均匀分布的；分布趋向于中心：

更好的一个步骤是而是 $ w $ ，使用例如。
  $$
w&#39;_ {ij}：=
\ frac {w_ {ij}^{ -  1.5}}
{
\ sum_j {w_ {ij}^{ -  1.5}}}
}
$$  
  这显然也不是均匀分布的（它显示了那些类似射线的区域接近顶点），但实际上对于我的应用来说足够均匀。我的问题是：
在 $ n $ 维度的一般性时，有什么权重变换能够提高统一性？这应该是瓦尔德分布吗？尽管我不知道如何自动选择 $ \ lambda $ 和 $ \ mu $ $ ：  相关
 
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/663559/transform-convex-hull-vertex-weights-for-uniform-distribution</guid>
      <pubDate>Sat, 05 Apr 2025 17:53:11 GMT</pubDate>
    </item>
    <item>
      <title>在使用R的GAMM4时，如何获得包含随机效应和更光滑效果的残留物？</title>
      <link>https://stats.stackexchange.com/questions/663557/how-to-get-residuals-that-include-both-random-effects-and-smoother-effects-when</link>
      <description><![CDATA[使用R的GAMM4包装的GAMM4函数拟合了广义的加性混合效应模型后，可以基于更平滑的拟合度（GAM）或基于广义线性混合效应（MER）获得两种类型的残差，（i）。  这是一个示例：
  fit3＆lt; -gamm4（protos〜mass〜mass+frass，random =〜（1 |年）+（1 | nest），data = blue.tits，family，family =＆quot&#39;poisson;

残差（Fit3 $ gam）

残差（FIT3 $ MER）
 
我的理解（？）是 fit3 $ gam 包括固定效果和平滑效果，但不包括随机效果，而 fit3 $ mer 包括固定和随机效果，但不包括平滑效果。  如果是这样，那么我如何获得包括固定效果，随机效应和平滑效果的（响应）残差？]]></description>
      <guid>https://stats.stackexchange.com/questions/663557/how-to-get-residuals-that-include-both-random-effects-and-smoother-effects-when</guid>
      <pubDate>Sat, 05 Apr 2025 17:10:51 GMT</pubDate>
    </item>
    <item>
      <title>COX pH模型中的时间差距，解释和实用性与时间差距有关</title>
      <link>https://stats.stackexchange.com/questions/663536/time-dependent-covariates-with-time-gaps-in-cox-ph-model-interpretation-and-use</link>
      <description><![CDATA[我正在与COX比例危害模型一起工作，并在寄存器数据上进行了依赖的协变量，并且由于（很可能）登记误差，一些协变量在此处和那里的值不知道。到目前为止，我刚刚删除了差距，因为它们不到数据的1％，这意味着 r  i处理此示例的时间依赖性协变量：
 $$ \ begin {matrix} time＆amp;价值＆amp;事件\\
\ hline \ vdots＆amp; \ vdots＆amp; \ vdots \\ 
（3,5]＆amp; 2＆amp; 0 \\
（5,7]＆amp; na＆amp; 0 \\
（7,10]＆amp; 4＆amp; 1 \\
\ vdots＆amp; \ vdots＆amp; \ vdots
\ end {matrix} \ Overset {\ text {remove na}} {\ longrightArrow}
\ begin {matrix}时间＆amp;价值＆amp;事件 \\
\ hline \ vdots＆amp; \ vdots＆amp; \ vdots \\ 
（3,5]＆amp; 2＆amp; 0 \\
（7,10]＆amp; 4＆amp; 1 \\
\ vdots＆amp; \ vdots＆amp; \ vdots
\ end {matrix} $$  
我现在想知道这是否合适且有意义，如果是，如何解释如何将这种观察结果纳入模型。我了解，将一个观察分配到数据集中的更多行中以使协变时间依赖时间是
在 r  生存软件包中， surv 函数用于让 coxph 函数进行回归。 If i understand correctly, if every line in the processed were a separate person with time independent covariates, using Surv(time_start,time_end,event) means that the observation is left truncated at time time_start, we observed the event at time time_end if event = 1, or the observation is right censored at time  time_end 如果事件 = 0。
现在，在我的示例中，我们对两行有一个观察结果，两者之间有差距。在我看来，观察不仅在3时截断，而且在间隔中也被截断（5,7]。我的意思是，我的意思是，我们尝试估计生存函数 $ s（\，\ cdot \ cdot \，| z）$ s（\，\ cdot \，| z，x \ in（3,5] \ cup（7，\ infty））$ 。
这是否正确理解？这样做是有意义的还是坏的？]]></description>
      <guid>https://stats.stackexchange.com/questions/663536/time-dependent-covariates-with-time-gaps-in-cox-ph-model-interpretation-and-use</guid>
      <pubDate>Sat, 05 Apr 2025 06:12:21 GMT</pubDate>
    </item>
    <item>
      <title>测试集插补</title>
      <link>https://stats.stackexchange.com/questions/663514/test-set-imputation</link>
      <description><![CDATA[假设我的一个功能之一中缺少值，并且火车和测试集中都缺少值。我想使用观察到的特征的中位数重合。我应该：

  a）计算火车集中的中位数， $ m _ {\ text {train}} $ ，并将其用于火车和测试的所有缺失值？

  b）计算火车集中的中位数， $ m _ {\ text {train}} $ ，并将其用于仅适用于火车集的所有缺失值。还要计算测试集中的中位数， $ M _ {\ text {test}} $ ，并将其用于仅用于测试集的所有缺失值。


对我来说，a）似乎是一个可怕的想法，因为我正在使用培训数据中的信息来影响我的测试数据，因此我得到的任何测试错误估计都是完全没有用的，因为我将测试数据偏向火车数据。在极端情况下，假设测试集中缺少大部分或所有该功能，并且我使用 $ m _ {\ text {train}} $ ，那么我对测试错误的估计（对于那个功能而言），即使我绝对没有任何东西。
 b）更有意义，因为我在火车和测试数据上应用一致的过程，因此测试错误估计应该更好地反映真实错误。
是否有严格研究这个问题的参考，还是有人告诉我A实际上比B更好？或者如果有更好的选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/663514/test-set-imputation</guid>
      <pubDate>Fri, 04 Apr 2025 16:55:26 GMT</pubDate>
    </item>
    <item>
      <title>最小化MSE的人口差异估计器</title>
      <link>https://stats.stackexchange.com/questions/663497/minimizing-mse-for-the-estimator-of-population-variance</link>
      <description><![CDATA[下面的屏幕截图来自平方平方错误）。有人可以请

帮助我了解最后一个突出显示的句子（鉴于索赔是正确的），
或确认我怀疑有一个错字：“无偏见”应该是“偏见”？

该推导是关于缩放（向下）更正/无偏的样本方差 $ S_ {N-1}^2 $ 。 （它适用于任何有限平均值，差异和过度峰度的人群。）实际上，缩放系数 $ a $ ，如下所示，最小化 $ \ $ \ text {mse {mse {mse}（s_ {n-1}}^2）$ 。但是，只要 $ a \ ne n-1 $ ，我们就进入了有偏见的估计器的领域（可能仍然是一致的，但肯定是有偏见的）。这句话不是应该指出我们可以实现“更好” （即较小的）MSE如果我们牺牲公正性并开始在有偏见的估计器之间进行搜索？
  &lt;img alt =“ ear wikipedia page on Means squared Orror” src =“ src =”]]></description>
      <guid>https://stats.stackexchange.com/questions/663497/minimizing-mse-for-the-estimator-of-population-variance</guid>
      <pubDate>Fri, 04 Apr 2025 12:32:38 GMT</pubDate>
    </item>
    <item>
      <title>使用最佳拟合的多项式线计算x值</title>
      <link>https://stats.stackexchange.com/questions/663574/calculate-x-value-using-polynomial-line-of-best-fit</link>
      <description><![CDATA[我正在计算最适合一组数据的行，然后使用该行来推断新X值的y值。一些计算出的Y值是有意义的，看起来很合适，但有些不属于最佳拟合线。
 ＃计算最佳拟合行
y＆lt;  -  c（0.1、0.5、0.6、0.7、0.8、1.1、1.3）
X＆lt;  -  C（20、30、50、150、650、800、860）
poly＆lt;  -  lm（y〜stats :: poly（x，6，raw = true）））

＃可视化
绘图（x，y，main =“多项式拟合（学位6）”
线（x，predict（poly，data.frame（x = x）），col =; blue; quot;）

＃为新X计算新Y
new_x＆lt;  -  c（15,20,22,25,30,40,80,110,150,150,280,290,645,675，
           810,815,818,820,825,845,860）
ycalc＆lt;  - 预测（poly，newdata = data.frame（x = new_x））
点（new_x，ycalc，col =; red＆quot; pch = 19，cex = 2）
text（new_x，ycalc，labels = round（ycalc，2），pos = 4，col =; red＆quot;）
 
有人可以向我解释为什么X = 30不属于最佳拟合线吗？  使用我的真实数据，有几个点，例如x = 30。]]></description>
      <guid>https://stats.stackexchange.com/questions/663574/calculate-x-value-using-polynomial-line-of-best-fit</guid>
      <pubDate>Thu, 03 Apr 2025 18:41:29 GMT</pubDate>
    </item>
    <item>
      <title>后续数据中的差距和目的是治疗精神治疗耐用性的分析</title>
      <link>https://stats.stackexchange.com/questions/663476/gaps-in-follow-up-data-and-intention-to-treat-analysis-for-durability-of-psychia</link>
      <description><![CDATA[使用PHQ-9，我正在分析诊所治疗对患者抑郁症的影响。患者在治疗前的基线PHQ分数（是一次性TX，而不是像药物一样反复出现的TX），然后进行后续行动，我们监视PHQ分数的变化。
我试图确定对那些对治疗反应的人的治疗持久性。但是，由于我们是一家小型诊所，并且由于我们没有特定的激励措施使患者完成随访，因此我们的数据频繁存在差距。例如，一名患者在治疗后一个月进行随访，然后直到6个月后才进行随访。。
我正在检查TX之后以下时间点的治疗耐用性：[1个月，2个月，3个月，6个月，9个月，12个月]。根据我读过的意向性治疗文献，如果他们在失去的最新FU之前，我可以安全地将患者安全地标记为“不再反应”。
但是，如果我有一个患者在1个月和6个月时显示出反应，但没有其他随访，那么在2＆amp期间将患者作为呼吸者是适当的。 3个月的随访时间点？同样，如果患者通过所有先前的随访都表现出持续的反应，那么在科学上是否可以将他们标记为通过未完成的后续行动进行持续的反应？ （例如，患者显示了1-6个月的反应，并丢失了fu。
我可以将它们标记为在第9个月仍在响应中，我是否应该将它们标记为没有响应，还是应该在该时间点从n中删除它们？）
我知道，其他意向性治疗分析使用其他协变量使用插补来填充缺失的数据点，但是我不确定这适用于我的人群。请让我知道您是否有任何想法！]]></description>
      <guid>https://stats.stackexchange.com/questions/663476/gaps-in-follow-up-data-and-intention-to-treat-analysis-for-durability-of-psychia</guid>
      <pubDate>Tue, 01 Apr 2025 18:59:54 GMT</pubDate>
    </item>
    <item>
      <title>经验度量和直方图的ra子奈克基衍生物</title>
      <link>https://stats.stackexchange.com/questions/662770/radon-nikodym-derivative-of-the-empirical-measure-and-histograms</link>
      <description><![CDATA[是经验“密度”分布函数的经验度量w.r.t的ra射线衍生物？当我们简要介绍课堂上的直方图时，我注意到了正式的关系，但不幸的是找不到有关该主题的信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/662770/radon-nikodym-derivative-of-the-empirical-measure-and-histograms</guid>
      <pubDate>Mon, 17 Mar 2025 21:56:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么最大似然估计过高或在稀疏事件的情况下？</title>
      <link>https://stats.stackexchange.com/questions/662562/why-does-maximum-likelihood-estimation-overestimate-or-in-situations-of-sparse-e</link>
      <description><![CDATA[在统计类别中，我们被教导说，当事件稀疏（相对于预测变量相对于预测变量的结果少），最大的可能性估计（MLE）通常高估了逻辑回归中的几率比（ORS）。）。
我了解为什么MLE在近距离分离或完全分离的情况下产生无限估计，而预测因子可以完美地预测结果。但是，我没有完全掌握为什么，为什么在稀疏数据的情况下（不分开），MLE倾向于高估OR，而不是简单地产生围绕真实价值的宽阔，不精确的置信区间。
一些解释提到，可能性表面在0（当𝛽0）接近0（当𝛽0）附近，使MLE向更陡峭的斜坡漂移，从而发现更大或估计。我不完全了解这种机制是如何工作的 - 为什么一个扁平的可能性表面会导致系统性高估，而不仅仅是不确定性？
有人可以帮助澄清：
为什么在逻辑回归中，可能性功能的形状会导致MLE在稀疏数据设置中高估的趋势？
为什么“更喜欢” mle&#39; β（效果更强​​）的绝对值较大，而不仅仅是在较小的估计值周围产生宽的顺式？]]></description>
      <guid>https://stats.stackexchange.com/questions/662562/why-does-maximum-likelihood-estimation-overestimate-or-in-situations-of-sparse-e</guid>
      <pubDate>Thu, 13 Mar 2025 12:09:35 GMT</pubDate>
    </item>
    <item>
      <title>如何计算Royston Parmar模型的Harrell的C统计数据？</title>
      <link>https://stats.stackexchange.com/questions/661920/how-do-i-calculate-harrells-c-statistic-for-a-royston-parmar-model</link>
      <description><![CDATA[我正在尝试计算Royston-Parmar模型的一致性（C）统计量。我的模型将基线危害分层，并使用花键来建模日志（t）。
我不确定是否正确计算C统计量和/或使用正确的输入。下面我解释了我尝试的东西。
From this post (https://stats.stackexchange.com/a/347081/466963) I understand that the c-statistic can be calculated using survival time as long as we have observed event status and the predictor from the 模型。例如：
 型号＆lt;  -  rstpm2 :: stpm2（surv（time，fail）〜 + age10 + sex，tvc = list（idu = 1，msw = 1，oth = 1），link.type =;
obs_surv＆lt;  - 生存:: surv（时间，失败）
预测器＆lt;  -  rstpm2 ::预测（模型）
输出＆lt;  -  HMISC :: rcorr.cens（预测器，obs_surv）
 
  hmisc :: rcorr.cens（）返回带有以下命名元素的向量：c index，dxy，s.d.，n，丢失，未经审查，相关，一致，不确定和不确定。
但是，此处生成的“ C索引”与使用Stata命令 stcstat2 获得的“ C索引”（在拟合相同的模型之后）。实际上，由 hmisc :: rcorr.cens（）产生的C索引比我在Stata中获得的c索引要小得多（对于同一模型和数据）。  STCSTAT2 （在Stata中与STPM2拟合模型后，计算和报告Harrell的C-Index）。  STCSTAT2 使用PETO – BRESLOW方法进行绑扎故障，并依赖于 ESTAT CONCORDANCE 函数（但与后者功能相比，选项数量有限）。
我尝试了其他功能（在r）中看到我可以得到与 hmisc :: rcorr.cens（）：的答案相同的答案。

 生存:: Concordance（模型）：但是我得到了&#39;没有适用的方法 concordance 应用于class＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quort＆quot＆quote＆quote＆quote＆quote＆quote＆quote＆quote; c（ stpm2 ， mle2 ）
 生存:: concordanceFit（obs_surv，predivor，timewt =; s＆quot; s＆code&gt;：以列表的形式提供了一个列表的输出，其中第一个元素是“和解”，是两个&#39;time&#39;和&#39;状态的矢量，这些值都不类似于“ c index” 

之后，我尝试使用以下公式：c =（e + t/2）/n（其中e是订购/对的数量，t是纽带的数量，n是比较数的数量），但是我使用 hmisc :: rcorr.cens :: rcorr.cens（equivalence&gt; equivalence&gt; equivalences）的输出应用了它。
  e =输出[[&#39;CONCORDANT&#39;]] 
n =输出[[&#39;相关对&#39;]]
t = n -e
 
这给出了一个更接近我从Stata命令 stcstat2 获得的C统计量的值。我假设
我的问题是（1）我是通过使用 hmisc :: rcorr.cens（）（）的术语应用公式来正确计算C统计的方法了吗？ （2）如果是这样，我是否使用正确的输入术语？ （3）来自 hmisc :: rcorr.cens（）纠正乐观的c-index是吗？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/661920/how-do-i-calculate-harrells-c-statistic-for-a-royston-parmar-model</guid>
      <pubDate>Thu, 27 Feb 2025 13:11:33 GMT</pubDate>
    </item>
    </channel>
</rss>