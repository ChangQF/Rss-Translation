<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 23 Dec 2023 18:16:16 GMT</lastBuildDate>
    <item>
      <title>社会科学数据中添加高斯噪声</title>
      <link>https://stats.stackexchange.com/questions/635554/gaussian-noise-added-in-social-sciences-data</link>
      <description><![CDATA[我写信给你是为了解决 1 个问题。任何答复将不胜感激。
在模拟研究中（模拟次数=200），这里是添加高斯噪声模拟的二次/抛物线函数。
y= 4 * (x - 0.5)^2 + rnorm(200, 0, 0.05)

以 x 为变量，服从 0 到 1 的均匀分布。
我的问题涉及添加的高斯噪声：
rnorm(200,0,0.05) 因此
n=200
平均值=0
标准差 = 0.05
提醒一下，标准正态分布（通常称为钟形曲线）的平均值=0，标准差=1。
这种均值=0、标准差=0.05（远低于1）的高斯噪声是否可能出现在社会科学数据中？或者我们是否需要不同类型的高斯噪声：rnorm(200,2,3)，平均值为 2，标准差为 3？或者高斯噪声的任何其他平均值和任何其他标准偏差（例如平均值为 5 或 8 或 12，...以及标准偏差为 3、5、7，...）？
或者说均值和标准差的值在社会科学数据模拟中使用的高斯噪声中没有多大重要性？
最好，]]></description>
      <guid>https://stats.stackexchange.com/questions/635554/gaussian-noise-added-in-social-sciences-data</guid>
      <pubDate>Sat, 23 Dec 2023 17:07:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么我不能通过从所有计数中减一来转换分布？</title>
      <link>https://stats.stackexchange.com/questions/635553/why-cant-i-transform-a-distribution-by-deducting-one-from-all-counts</link>
      <description><![CDATA[假设我有每个渔民一年内从特定湖泊捕获的鱼的数量的记录。分布在数量 = 1 时达到峰值（即大多数渔民一年只从湖中捕获一条鱼），此后逐渐减少，并具有较长的右尾（极少数渔民捕获超过 100 条鱼）。
这样的数据可能符合泊松分布或负二项分布。然而，这两种分布在 count = 0 时都具有非零概率，而对于我们的数据，没有捕获鱼的渔民不会被捕获为数据点。
为什么通过从所有计数中减去 1 来转换我们的原始数据是不正确的，因此将我们的分布向左移动 1，这样现在计数 = 0 时就有非零概率？
（我认为如何处理 count = 0 缺失的正确答案是使用零截断分布）]]></description>
      <guid>https://stats.stackexchange.com/questions/635553/why-cant-i-transform-a-distribution-by-deducting-one-from-all-counts</guid>
      <pubDate>Sat, 23 Dec 2023 16:02:41 GMT</pubDate>
    </item>
    <item>
      <title>推断新数据时考虑训练准确性</title>
      <link>https://stats.stackexchange.com/questions/635552/take-into-account-training-accuracy-when-inferring-new-data</link>
      <description><![CDATA[在我的研究中，我的目标是预测具有可变样本量（例如从 10 个人到 200 个人）的许多样本的生物材料类别。上下文是使用现代、可观察、可靠材料训练的模型对某些类型的存在进行的考古推断。
我已经在具有一定准确度的数据上训练了一些分类器，有时很好（在二元情况下&gt; 95％，有时很差，例如对于5类问题为40％）。我有 6 个这样的模型，用于处理具有不同性能的二元/多重问题。班级之间的样本量是平衡的，我对训练集进行了重新采样并使用了良好的旧线性判别分析。
现在我想使用这些模型来预测新的未知数据上每个模型的类别。更具体地测试“显着性”每个考古样本的计数/比例。目的是检测背景噪音（众所周知，背景噪音巨大、多样且恶毒）之外是否存在（可能）某种类型的噪音。
我怎样才能测试“显着性”？每个样本中每个类别的计数/比例，考虑到 i) 样本大小和 ii) 模型的准确性？
到目前为止，我最好的猜测是为每个样本中的每个类获取多项式（或二项式问题的二项式）的分位数。但是我如何解释训练阶段的准确性结果呢？我有点坚持下去。
换句话来说，假设我有两个模型：一个好，一个坏，每个模型预测三个类别。在训练集上，好 会以 95% 的准确率预测 A、B 或 C，而坏会预测 D、E、F，准确率仅为 50%。
对于一个有 100 个人的样本，当 good 预测 80 A 情况时，人们可以合理地（如果在该领域可能出现这种心态）认为“A”可能存在于该情况中样本（并获取其数字）。现在，如果 bad 也预测 80 &#39;D&#39;，我们的比例相同，但考虑到模型不太准确，我们对预测的信心可能会降低。然而，在具有 3 个等概率 (1/3) 的多项式中测试 80 个案例将得到相同的分位数。
我错过了什么吗？我应该停止考古学中的数据科学吗:-)？
任何指针将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/635552/take-into-account-training-accuracy-when-inferring-new-data</guid>
      <pubDate>Sat, 23 Dec 2023 15:26:44 GMT</pubDate>
    </item>
    <item>
      <title>直觉线性回归逐步选择预测变量</title>
      <link>https://stats.stackexchange.com/questions/635547/intuition-linear-regression-stepwise-selection-of-predictors</link>
      <description><![CDATA[我正在使用遗传学中的一种工具，其工作原理与逐步线性回归非常相似（其称为GCTA-COJO 对于那些感兴趣的人）。基本上开始的情况是这样的：
您有 1000 个预测因子（称为 SNP1、SNP2...）和一个要预测的连续性状 Y。在第一步中，您将拟合一个仅包含一个预测变量的线性模型（即 lm(Y~SNP1)、lm(Y~SNP2)、. ..).
在第二步中，您需要拟合一个联合模型，其中包括多个预测变量（即 lm(Y~SNP1+SNP5+SNP159)）。在这里，我注意到，常常会出现与“单一预测变量”中的结果 Y 不显着相关的预测变量。当关联测试（即 lm(Y~SNP1)）包含在联合模型 (lm(Y~SNP1+SNP5+SNP159)）中时，它们变得显着。不知何故，我很难理解这样的事情是如何可能的，并且如果有人能给我一个直观的解释，说明这是可能的，我会很高兴。
这里是一些示例数据，很好地描述了我的情况：
图书馆（扫帚）
图书馆（tidyverse）

set.seed(123) # 设置种子以实现可重复性

# 为每个变量生成 100 个观测值
n &lt;- 100

# 生成具有不同相关性的预测变量
预测变量 &lt;- 矩阵(rnorm(20 * n), nrow = n)
Predictors[, 1:5] &lt;- Predictors[, 1] + rnorm(n, sd = 0.2) # 引入一些相关性
Predictors[, 6:10] &lt;- Predictors[, 5] + rnorm(n, sd = 0.3) # 引入更多相关性

# 生成与预测变量具有不同关系的结果变量
Y &lt;- 2 + 0.5 * 预测器[, 1] + 0.8 * 预测器[, 5] + 0.3 * 预测器[, 10] + rnorm(n)

# 合并成数据框

data &lt;- data.frame(Y, 预测变量)
名称(数据)[-1] &lt;-paste0(“X”, 1:20) # 指定列名称

# 存储 20 个预测变量的名称
预测器 &lt;- 名称（数据）[-1] # 假设 Y 是第一列

# 为每个预测变量拟合单独的线性回归
for（预测变量中的预测变量）{
  模型 &lt;- lm(公式 = Y ~ 数据[[预测器]], 数据 = 数据)
  打印（预测）
  打印（整洁（模型））
}

# 包含所有预测变量的完整模型
full_model &lt;- lm(Y ~ ., 数据 = 数据)

# 使用AIC逐步选择
best_model &lt;- step(full_model, Direction = &quot;both&quot;) # 同时考虑前向和后向选择

# 打印所选模型的摘要
摘要（最佳模型）

在此示例中，predictor13 在单变量关联测试中并不显着，但在连接模型 (best_model) 中，我们可以看到它变得显着关联。
这让我感到惊讶，因为这两个变量之间似乎没有任何关联：

非常感谢任何关于为什么这是可能的见解！
干杯！]]></description>
      <guid>https://stats.stackexchange.com/questions/635547/intuition-linear-regression-stepwise-selection-of-predictors</guid>
      <pubDate>Sat, 23 Dec 2023 14:44:10 GMT</pubDate>
    </item>
    <item>
      <title>如何找到哪组变量可以预测最佳握力，在进行分析之前首先减少连续变量的数量[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635544/how-can-i-find-which-set-of-variables-predicts-best-handgrip-strength-first-red</link>
      <description><![CDATA[这是我的作业问题：
“哪一组变量最能预测女性的握力？
A。在进行分析之前减少连续变量的数量。”
我应该使用哪些技术以及以什么顺序使用它们，因为我有点卡住了。我有 17 个变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/635544/how-can-i-find-which-set-of-variables-predicts-best-handgrip-strength-first-red</guid>
      <pubDate>Sat, 23 Dec 2023 13:25:31 GMT</pubDate>
    </item>
    <item>
      <title>分别在 m 个数据上训练的两个分类器的多数投票是否比在 2m 个数据上训练的一个分类器更好？</title>
      <link>https://stats.stackexchange.com/questions/635543/is-a-majority-vote-from-two-classifiers-trained-on-m-data-each-better-than-one-c</link>
      <description><![CDATA[在 PAC 学习框架中，集成分类器的性能与单个分类器相比如何？具体来说，考虑 $2m$ i.i.d 样本 $(x, y) \in \mathcal{X} \times \{- 1, 1\}$ 来自分布 $\mathcal{D}$，这是一个二元分类任务。想象一个学习者将数据分为两个大小相等的子集：$S_1$ 和 $S_2$，并且训练两个分类器 $h_1$ 和 $h_2$。该学习器的最终预测是 $h_3 = \text{sign}\left(\frac{h_1 + h_2}{2}\right)$。与在所有 $2m$ 数据点上直接训练单个分类器相比，此方法的样本复杂性和泛化误差如何？如何在 PAC 框架内从数学上论证或反对这一方法？
这可能是错误的，因为我们通常不会以这种方式训练分类器，但是，这可能是正确的，因为多数投票有助于学习。 （PAC 学习的最佳样本复杂度使用多数投票分类器）]]></description>
      <guid>https://stats.stackexchange.com/questions/635543/is-a-majority-vote-from-two-classifiers-trained-on-m-data-each-better-than-one-c</guid>
      <pubDate>Sat, 23 Dec 2023 13:10:12 GMT</pubDate>
    </item>
    <item>
      <title>随机区组设计和混合模型</title>
      <link>https://stats.stackexchange.com/questions/635542/randomized-blocking-design-and-mixed-models</link>
      <description><![CDATA[我正在开发一个研究项目，我们正在评估幼苗的生长情况。这些地块分布在开放式温室中，一些环境参数根据其位置而变化。为了减少这种影响，我们定义了块来对位于不同条件下的图进行分组。
我们将在不同的地块上进行多次测量，因此我们必须使用混合模型。我的问题是：在没有块的实验中，图是随机因子，但在这种情况下，我是否将块视为随机因子？
我还没有数据，也没有进行分析，但我的问题（使用 R）是我应该如何使用模型中的块？：
增长 ~ 因子 1 + 因子 2 + (1|块)

或
增长 ~ 因子 1 + 因子 2 + 块 + (1|图)
]]></description>
      <guid>https://stats.stackexchange.com/questions/635542/randomized-blocking-design-and-mixed-models</guid>
      <pubDate>Sat, 23 Dec 2023 11:40:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SVD 获得所需数量的因子 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635537/how-to-get-required-number-of-factors-using-svd</link>
      <description><![CDATA[我想将以下协方差矩阵分解为 U 和 psi
cov_matrix = np.array([[19, 30, 2, 12],
[30,57,5,23],
[2,5,38,47],
[12,23,47,68]])
L = np.array([[4, 7, -1, 1],[1, 2, 6, 8]]
psi = np.array([2, 4, 1, 3])
其中 np.dot(L.(L.T)) + psi = cov_matrix
我使用了 scikit learn 中的 SVD 和因子分析，但没有得到上述表格。有什么帮助吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635537/how-to-get-required-number-of-factors-using-svd</guid>
      <pubDate>Sat, 23 Dec 2023 09:59:13 GMT</pubDate>
    </item>
    <item>
      <title>第 i 个样本的期望值与随机变量的期望值</title>
      <link>https://stats.stackexchange.com/questions/635536/expected-value-of-ith-sample-versus-expected-value-of-a-random-variable</link>
      <description><![CDATA[考虑一个随机变量$X$。
当我们讨论随机变量的期望值$X$时，我们使用符号$\mathbb{ E}\左(X\右)$。
但是，我发现，在统计入门教科书中，他们使用符号 $\mathbb{E}\left(X_i\right)$，而我不确定这句话的确切含义是什么。
我的猜测是，当我们考虑 $X$ 的随机样本时，$[X_i]_{i= 1,\ldots,N}$，每个$X_i$都是一个随机变量，因此$\ mathbb{E}\left(X_i\right)$ 是有效的符号。
那么，$\mathbb{E}\left(X\right)$ 和  之间的确切区别是什么$\mathbb{E}\left(X_i\right)$?
我认为，如果我们假设样本是“随机”的绘制，$\mathbb{E}\left(X_1\right)=\ldots=\mathbb{E}\left(X_N\right)$，所以我们可以省略下标$i$。
但是，我不确定这是一个正确的解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/635536/expected-value-of-ith-sample-versus-expected-value-of-a-random-variable</guid>
      <pubDate>Sat, 23 Dec 2023 06:49:24 GMT</pubDate>
    </item>
    <item>
      <title>在神经网络训练过程中，训练损失先减少，然后遇到拐点并增加。有哪些可能的解释？</title>
      <link>https://stats.stackexchange.com/questions/635534/during-neural-network-training-training-loss-decreases-then-hits-an-inflection</link>
      <description><![CDATA[“在神经网络训练期间，训练损失先减少，然后达到拐点并增加。有哪些可能的解释？”
我在一次采访中得到了这个问题，并想知道在实践中可能出现这种情况的原因。我给出的答案本质上是，如果您有一个不平衡的数据集并且您的重采样有缺陷，那么您可能会过于频繁地对多数类进行采样。该模型可以学习预测，大多数情况下会导致准确性下降。]]></description>
      <guid>https://stats.stackexchange.com/questions/635534/during-neural-network-training-training-loss-decreases-then-hits-an-inflection</guid>
      <pubDate>Sat, 23 Dec 2023 03:19:57 GMT</pubDate>
    </item>
    <item>
      <title>在实践中充分理解“其他条件不变”的概念</title>
      <link>https://stats.stackexchange.com/questions/635531/understanding-well-the-concept-of-ceteris-paribus-in-practice</link>
      <description><![CDATA[ceteris paribus 的概念表示，要计算一个变量对另一个变量的影响，我们需要保持其他一切不变。我想很好地理解如何在假设的情况下做到这一点。
我有一个假设场景，其中给我一个数据集，其中包含影响学生数学成绩的所有可能的可观察和不可观察变量。这些变量包括学习时间、睡眠时间、休闲时间、收入和性别。我想使用其他条件不变的原则来计算学习时间对数学成绩的影响。使用 R，假设：
# 首先，让我们为 100 名学生创建一个随机数据集。
set.seed(123) # 为了重现性
n &lt;- 100 # 学生人数

# 为每个变量生成随机数据
收入 &lt;- rnorm(n，平均值 = 50000，sd = 10000)
Study_hours &lt;- rnorm(n, 均值 = 10, sd = 2)
sleep_hours &lt;- rnorm(n, 平均值 = 8, sd = 1)
休闲时间 &lt;- rnorm(n, 均值 = 6, sd = 1)
性别 &lt;- 样本(c(“男”,“女”), n, 替换 = TRUE)

# 将性别变量编码为虚拟变量
sex_dummy &lt;- ifelse(性别 == &quot;男&quot;, 1, 0)

# 假设数学成绩是这些变量的函数
math_grade &lt;- 2*学习时间 + 0.5*睡眠时间 - 0.3*休闲时间 + 0.00001*收入 + 性别虚拟

# 将所有内容放入 data.frame 中
data &lt;- data.frame(收入、学习时间、睡眠时间、休闲时间、性别、数学成绩)

对我来说，计算影响最简单的方法是执行以下操作：
# 现在，要分析学习时间对数学成绩的影响，请比较不同学习时间组的数学成绩。

# 例如，让我们将学习时间在 9 到 11 小时之间的学生与学习时间在 11 到 13 小时之间的学生进行比较。
group1 &lt;- data[data$study_hours &gt;= 9 &amp;数据$study_hours &lt; 11、]
group2 &lt;- data[data$study_hours &gt;= 11 &amp;数据$study_hours &lt; 13、]

# 计算每组数学成绩的平均值
Mean_group1 &lt;- 平均值(group1$math_grade)
Mean_group2 &lt;- 平均值(group2$math_grade)

# 学习时间对数学成绩的影响是平均值的差异
影响&lt;-mean_group2-mean_group1
影响


请注意，在计算上述影响时，我们没有控制其他变量。在其他条件不变的情况下如何使用？我们如何保持其他变量不变才能计算真正的影响？
我不确定如何在我的分析中应用这一原则。]]></description>
      <guid>https://stats.stackexchange.com/questions/635531/understanding-well-the-concept-of-ceteris-paribus-in-practice</guid>
      <pubDate>Sat, 23 Dec 2023 01:47:45 GMT</pubDate>
    </item>
    <item>
      <title>NMDS 的生态数据在 R 数据转换中包含许多零</title>
      <link>https://stats.stackexchange.com/questions/635530/nmds-with-ecological-data-containing-many-zeros-in-r-data-transformations</link>
      <description><![CDATA[我正在尝试对 R 中的混合分类数据执行 NMDS metaMDs()。我的分类单元数据按行作为观察值和列作为不同的分类单元进行组织。这些数据包含许多零。我发现使用 decostand(method=&quot;total&quot;) 或 decostand(method=&quot;wisconsin&quot;) 转换数据会导致我的 NMDS 发出压力警告值几乎为零。是否有任何建议、其他转换或其他排序技术可供我尝试处理此类数据？我试图拟合 NMDS 结果的环境数据包含因子和数值变量的混合。]]></description>
      <guid>https://stats.stackexchange.com/questions/635530/nmds-with-ecological-data-containing-many-zeros-in-r-data-transformations</guid>
      <pubDate>Fri, 22 Dec 2023 13:39:55 GMT</pubDate>
    </item>
    <item>
      <title>先前的信念有多主观？</title>
      <link>https://stats.stackexchange.com/questions/635486/how-subjective-are-prior-beliefs</link>
      <description><![CDATA[我发现术语“先验信念”有点模糊，贝叶斯分析中的先验信念可以接受什么？例如，我无法查看任何数据并自行决定“我相信总体平均值将约为 60 个单位”，无论这是基于直觉还是缺乏关心。对于“可靠”的先验信念是否有任何标准？]]></description>
      <guid>https://stats.stackexchange.com/questions/635486/how-subjective-are-prior-beliefs</guid>
      <pubDate>Fri, 22 Dec 2023 09:19:08 GMT</pubDate>
    </item>
    <item>
      <title>关于数据对数转换的有趣观察</title>
      <link>https://stats.stackexchange.com/questions/635466/an-interesting-observation-regarding-the-log-transformation-of-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635466/an-interesting-observation-regarding-the-log-transformation-of-data</guid>
      <pubDate>Fri, 22 Dec 2023 00:42:00 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯深度学习中学习损失衰减的损失函数的推导</title>
      <link>https://stats.stackexchange.com/questions/635300/derivations-of-loss-functions-for-learning-loss-attenuation-in-bayesian-dl</link>
      <description><![CDATA[我对贝叶斯深度学习相当陌生，如果这是一个愚蠢的问题，我很抱歉。
我正在尝试实现本文中的工作：计算机视觉的贝叶斯深度学习需要哪些不确定性？

在整篇论文中，他们给出了最小化目标，使模型能够学习任意不确定性，但他们没有给出任何关于它们来自何处的正式推导。它们不是临时构造，因此必须有一种方法来派生它们。
哪里可以找到推导？
$$
\大的
\mathcal{L}(\theta,p) = -\frac{1}{N} \sum_{i=1}^N
 \text{log} \hspace{1 mm} p(\text{y}_i|\text{f}^\widehat{\text{W}_i}(x_i)) + \frac{1-p}{2N }||\theta||^2
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/635300/derivations-of-loss-functions-for-learning-loss-attenuation-in-bayesian-dl</guid>
      <pubDate>Tue, 19 Dec 2023 22:26:42 GMT</pubDate>
    </item>
    </channel>
</rss>