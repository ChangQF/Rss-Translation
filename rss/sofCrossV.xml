<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 11 Mar 2024 06:17:38 GMT</lastBuildDate>
    <item>
      <title>溢出效应作为购买力平价（PPP）的检验</title>
      <link>https://stats.stackexchange.com/questions/642279/spillovers-as-test-of-purchasing-power-parity-ppp</link>
      <description><![CDATA[VAR 的变换系数产生脉冲响应，可用于在 Diebold 和 Yilmaz (DY) 2012 年论文“给予比接受更好”的框架中产生预测误差方差分解或溢出。 (https://doi.org/10.1016/j.ijforecast.2011.02.006）。在记录即期汇率和价格指数差异的二方程 VAR 中测试相对购买力平价的背景下，是否有将 DY 溢出解释为购买力平价的确认/拒绝的现成解释，包括比例性和对称性假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/642279/spillovers-as-test-of-purchasing-power-parity-ppp</guid>
      <pubDate>Mon, 11 Mar 2024 04:52:14 GMT</pubDate>
    </item>
    <item>
      <title>一阶、二阶、三阶差分背后的直觉是什么以及何时使用它们？</title>
      <link>https://stats.stackexchange.com/questions/642277/what-is-the-intuition-behind-the-first-second-third-order-differencing-and-whe</link>
      <description><![CDATA[我正在处理时间序列数据，出于好奇，我对数据进行了第一个第二个三阶差分。我怎么在使用它们时不太熟悉？
第二个问题是其背后的直觉。第一个订单非常清楚，这就是区别。
$$\begin{方程} \begin{对齐}
\Delta X_t &amp;= X_t - X_{t-1}。
\end{对齐} \end{方程}$$
第二个描述这里是给定时间点的序列曲率。
$$\begin{方程} \begin{对齐}
\Delta^2 X_t = \Delta (\Delta X_t)
&amp;= \Delta (X_t-X_{t-1}) \\[6pt]
&amp;= \Delta X_t - \Delta X_{t-1} \\[6pt]
&amp;= (X_t-X_{t-1})-(X_{t-1}-X_{t-2}) \\[6pt]
&amp;= X_t - 2X_{t-1} + X_{t-2}。 \\[6分]
\end{对齐} \end{方程}$$
但我实际上不知道第三个区别是什么意思？何时使用第一、第二和第三个差异？
$$\begin{方程} \begin{对齐}
\Delta^3 X_t = \Delta (\Delta^2 X_t)
&amp;= \Delta (X_t - 2X_{t-1} + X_{t-2}) \\[6pt]
&amp;= \Delta X_t - 2\Delta X_{t-1} + \Delta X_{t-2} \\[6pt]
&amp;= (X_t - X_{t-1}) - 2(X_{t-1} - X_{t-2}) + (X_{t-2} - X_{t-3}) \\[6pt ]
&amp;= X_t - 3X_{t-1} + 3X_{t-2} - X_{t-3}。 \\[6分]
\end{对齐} \end{方程}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/642277/what-is-the-intuition-behind-the-first-second-third-order-differencing-and-whe</guid>
      <pubDate>Sun, 10 Mar 2024 23:22:58 GMT</pubDate>
    </item>
    <item>
      <title>有哪些关于如何避免作为统计学家被用来为不诚实项目提供虚假可信度的好书？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/642275/what-are-some-good-books-on-how-to-avoid-as-a-statistician-being-used-to-lend</link>
      <description><![CDATA[我的意思是，例如，公司或组织对严肃的数据分析驱动的决策并不真正感兴趣，而是雇用或雇用统计学家试图为“结果”提供虚假的可信度。在实际进行任何认真的数据分析之前就已经决定了。另一个例子可能是一家公司篡改他们提供给他们雇用的统计学家的数据，试图让公司看起来不错。
对于那些试图诚实地完成工作而不被操纵的人来说，是否有关于如何处理这种情况的参考？
我想这是许多领域的专家可能有一天或以后必须面对的一个问题，但我想知道是否有一些参考文献专门从统计学家或数据分析师/科学家的角度来解决这个问题。
谢谢。
--
编辑：
我不完全确定为什么这个问题被关闭。我的问题很笼统，我给出的例子只是说明，也许并不完美。我心里没有更具体的例子，这就是我首先问这个问题的原因：如果我已经具体知道如何操纵统计学家，我想我不需要关于这个主题的参考资料。我认为对细节的无知是导致某人容易受到操纵的原因之一。
在我看来，这个问题只能由对该领域的出版物有充分了解的人来回答，这就是为什么我的第一个想法是在这里问它（否则，我不知道我还能在哪里问它，但如果我的问题保持关闭，我会很高兴得到建议）。
行为准则很有趣并且绝对相关，但我认为他们缺乏而我正在寻找的是“案例研究”例子。因此，如果你愿意，我会发现有趣的是有点像针对统计学家的行为准则，但有详细的现实生活例子，而不仅仅是列出原则。有这样的书吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642275/what-are-some-good-books-on-how-to-avoid-as-a-statistician-being-used-to-lend</guid>
      <pubDate>Sun, 10 Mar 2024 22:27:39 GMT</pubDate>
    </item>
    <item>
      <title>固定效应回归会由于聚合 FE 较多的共线性而降低估计值，但聚合 FE 较少的情况则不会</title>
      <link>https://stats.stackexchange.com/questions/642274/fixed-effects-regression-drops-estimates-due-to-collinearity-for-more-aggregated</link>
      <description><![CDATA[我正在使用带有一些不同设置的 fixest 包在 r 中运行固定效应回归。我无法提供复制错误的数据，因为数据集太大，并且子集会导致其他错误，但一般格式如下：
库（修复）

fmla1 &lt;- as.formula(“DV ~ 因子(Var):(Var2) + Var2 | 州 + 年份”)
fmla2 &lt;- as.formula(“DV ~ 因子(Var):(Var2) + Var2 | 年”)
fmla3 &lt;- as.formula(“DV ~ 因子(Var):(Var2) + Var2 | 状态”)
fmla4 &lt;- as.formula(&quot;DV ~ 因子(Var):(Var2) + Var2 | 城市 + 年份&quot;)
fmla5 &lt;- as.formula(&quot;DV ~ 因子(Var):(Var2) + Var2 | city_year&quot;)

reg1 &lt;- feols(数据 = df, fml = fmla1)
reg2 &lt;- feols(数据 = df, fml = fmla2)
reg3 &lt;- feols(数据 = df, fml = fmla3)
reg4 &lt;- feols(数据 = df, fml = fmla4)
reg5 &lt;- feols(数据 = df, fml = fmla5)


其中固定效应变量state是观测状态的一个因子，year是年份的一个因子，city是一个城市的因子，city_year 是城市年固定效应的因子。 Var2是具有三个类别的因子变量，其中参考水平为“a”。 Var 是另一个因子，范围为 -10 到 10 的整数。两者相互作用，无需对 Var 进行基线估计，因为当 Var2 = =“a”，Var 始终为 0。因此，为了避免共线性，我只对交互作用和 Var2 进行估计。
当我运行这些模型时，前 3 个模型不起作用。我收到如下错误消息：
由于共线性，变量“Var0:Var2a”已被删除（请参阅 $collin.var）。


但是，对于reg4和reg5，不会出现这样的错误。
我试图了解这是如何发生的，并确定 reg4 和 reg5 的结果是否可信。
如上所述，对于 Var2 == “a” 的观察结果，Var 是完全共线的。所以我可以看到多重共线性问题是如何引起的。但当使用城市和城市年份固定效应时，它也是共线的，没有任何下降。
城市和城市年的固定效应明显低于国家固定效应，也就是说城市年和城市年的固定效应将被国家吸收。因此，两个规范下的变量和固定效应之间不应该存在相同的关系吗？对于 Var2 == “a” 的共线情况，没有增加任何变化，这些对只是简单地划分为比州更多的城市，并且全部具有相同的值。
对于其他上下文，根据 Var2 级别将 Var 级别分配给给定州和年份的所有观测值。例如，在 1880 年，如果 Var2 == &quot;b&quot;，则所有这些观测值的 Var 均为 3。因此 Var 的变化code&gt; 发生在州一级（并且通过扩展统一对待该州内的所有城市）。
通过此设置，当治疗分配（Var1 的值）发生在州级别时，为什么我可以在城市级别估计具有固定效应的模型，而不是在州级别？如果在存在州 FE 的情况下与 Var2 交互时 Var 会下降，那么假设它是一个子州单位，那么当使用 city 时不应该发生完全相同的情况吗？ 
如果没有，任何人都可以提出一个例子，说明这种设计会发生并且是合法的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642274/fixed-effects-regression-drops-estimates-due-to-collinearity-for-more-aggregated</guid>
      <pubDate>Sun, 10 Mar 2024 21:57:44 GMT</pubDate>
    </item>
    <item>
      <title>报告多变量分位数回归模型结果的必要统计数据</title>
      <link>https://stats.stackexchange.com/questions/642273/necessary-statistics-for-reporting-outcomes-of-multivariable-quantile-regression</link>
      <description><![CDATA[我想知道多变量分位数回归模型需要哪些统计数据。
我正在考虑创建一个模型，例如使用 quantreg R 包：
模型 &lt;- rq(y ~ x1 + x2+ x3, tau = seq(0.1, 0.9, by = 0.1), data = df, method=&#39;fn&#39;)

要从摘要中获取所有 tau 中每个自变量的估计值、95% 置信区间和 p 值：
summary(model, se = “boot”)

并将结果报告为：1) 表格包含上述所有结果 2) 显示 tau 因变量的估计系数（95% CI）的数字。
1) 我的方法适合这种统计吗？
2) 多变量分位数回归模型是否需要任何诊断图或测试来证明其结构良好？]]></description>
      <guid>https://stats.stackexchange.com/questions/642273/necessary-statistics-for-reporting-outcomes-of-multivariable-quantile-regression</guid>
      <pubDate>Sun, 10 Mar 2024 21:53:08 GMT</pubDate>
    </item>
    <item>
      <title>分位数回归模型中的相互作用分析</title>
      <link>https://stats.stackexchange.com/questions/642272/analysis-of-interactions-in-quantile-regression-models</link>
      <description><![CDATA[我拥有一个 n ~10,000 的大型数据集。我的目标是使用 quantreg R 包中的 rq() 开发分位数回归模型。我选择的 tau 值范围为 0.1 到 0.9，增量为 0.1。
我正在考虑交互分析：我的模型包括分类自变量和连续自变量 - 总共 10 个变量。
我应该对每对因变量（总共 45 个）的潜在交互作用进行分析，还是只对理论上合理的交互作用进行分析？
我应该只分析变量对 [例如，qr(y ~ a + b + a*b, data = data, tau=0.5)？] &lt;强&gt;或整个模型的交互？
是否应该对所有感兴趣的 tau 值进行分析？
如何验证潜在的交​​互是否可以提高模型的性能？ AIC.rq() 合适吗？
我知道对大量交互进行分析可能会导致许多误报关联。我之前删除了表现出多重共线性的变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/642272/analysis-of-interactions-in-quantile-regression-models</guid>
      <pubDate>Sun, 10 Mar 2024 21:05:42 GMT</pubDate>
    </item>
    <item>
      <title>前门调节之谜</title>
      <link>https://stats.stackexchange.com/questions/642270/front-door-adjustment-riddle</link>
      <description><![CDATA[我有一个关于前门调整的具体案例的问题。
假设 $T\rightarrow M\rightarrow Y$ 和 $T\leftarrow C\rightarrow Y$，所以$C$ 是混杂变量，$M$ 是中间变量。
那么前门调整公式为：
$$P(y|do(t)) = \sum_{m}P(m|do(t))P(y|do(m))=\sum_mP(m |t)\sum_{t&#39;}P(y|m,t&#39;)P(t&#39;).$$
我的问题是：以下说法正确吗？最后我得到了一个非常奇怪的结果，所以我认为我在某个地方做错了，但我找不到它。
假设 $T$ 和 $M$ 之间的因果关系是确定性的，即 $M = f(T)$ 对于某些 $f$ 那么如果我将其代入上面的公式中，所有除了 $m=f(t)$ 之外，外部总和的元素为零，因此我得到 $m= f(t)$:
$$P(y|do(t))=\sum_{t&#39;}P(y|m,t&#39;)P(t&#39;)=\sum_{t&#39;:m =f(t&#39;)}P(yμm,t&#39;)P(t&#39;)=\sum_{t&#39;:m=f(t&#39;)}P(yμm)P(t&#39;)=P( y|m)\sum_{t&#39;:m=f(t&#39;)}P(t&#39;).$$
例如，如果 $f(x)=x$，则 $P(y|do(t)) = P (y|m)P(m)=P(y|t)P(t)$，我认为这是错误的。
以上计算正确吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642270/front-door-adjustment-riddle</guid>
      <pubDate>Sun, 10 Mar 2024 18:27:05 GMT</pubDate>
    </item>
    <item>
      <title>长期和短期面板因果关系</title>
      <link>https://stats.stackexchange.com/questions/642269/panel-causality-relationship-in-long-run-and-short-run</link>
      <description><![CDATA[当我想估计面板数据的长期和短期变量之间的因果关系时，应该使用什么计量经济学？面板VAR、面板VECM或面板ADRL等模型是否合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/642269/panel-causality-relationship-in-long-run-and-short-run</guid>
      <pubDate>Sun, 10 Mar 2024 17:22:02 GMT</pubDate>
    </item>
    <item>
      <title>被高斯噪声破坏的均匀分布的估计</title>
      <link>https://stats.stackexchange.com/questions/642254/estimation-of-a-uniform-distribution-corrupted-by-gaussian-noise</link>
      <description><![CDATA[问题定义
我有一个由 $m$ 观测值 $y^{(1)},\dots,y 组成的数据集^{(m)} \in \mathbb{R}^2$ 生成如下
\begin{方程*}\begin{对齐}
y &amp;= z + v \换行符
z&amp; \sim\mathcal{U}([a,b]) \换行符
v&amp; \sim\mathcal{N}(0_{2\times1}, \sigma_v^2 I_2)
\结束{对齐}
\end{方程*}
这里 $z$ 均匀分布在连接顶点 $[\begin{array}{cc}a &amp; 的线上。 0 \end{array}]$, $[\begin{array}{cc}b &amp; 0\end{array}]$ 与 $b&gt;a$，而 $v$ 是具有各向同性协方差的零均值高斯变量 $\sigma_v^2 I_2$ ($I_2$是 $2\times 2$ 单位矩阵）。两个组件 $z$ 和 $v$ 是独立的。
给定数据集$y^{(1)},\dots, y^{(m)}$，我想估计参数$a$ 和 $b$ 定义生成 $z 的段$.
我的尝试
对于 $\sigma_v\triangleq 0$，即没有高斯噪声，如果我没记错的话，$a$ 和 $b$ 应该是
\begin{方程}\begin{对齐}
\hat{\alpha} &amp;triangleq \min_{j=1,\dots,m} [\begin{array}{cc} 1 &amp; 0 \end{array}] y^{(j)} \newline
\hat{\beta} &amp;triangleq \max_{j=1,\dots,m} [\begin{array}{cc} 1 &amp; 0 \end{数组}] y^{(j)}
\结束{对齐}
\标签{$\星星$}
\end{方程}
现在，如果 $\sigma_v$ 是“小”与段长度 $b-a$ 相比，那么上面的估计应该效果很好。随着 $\sigma_v$ 与 $b-a$ 变得相当，我预计估计精度会下降。
我正在考虑一种启发式修正如下
\begin{方程*}\begin{对齐}
\hat{\alpha} &amp;triangleq \min_{j=1,\dots,m} [\begin{array}{cc} 1 &amp; 0 \end{array}] y^{(j)} +\sigma_v\newline
\hat{\beta} &amp;triangleq \max_{j=1,\dots,m} [\begin{array}{cc} 1 &amp; 0 \end{array}] y^{(j)} -\sigma_v
\结束{对齐}
\end{方程*}
因为由于高斯噪声 $v$，最小值和最大值可能会超过 $a$ 和 $b$。
问题
我的解决方案远非严格，我什至不确定它是否有意义。我的问题如下：

基于一些可靠的原则，是否可以修正估计 $(\star)$ 以考虑 $v$?
如果我的方法不起作用，我们如何估算$a$、$b$？&lt; /里&gt;
]]></description>
      <guid>https://stats.stackexchange.com/questions/642254/estimation-of-a-uniform-distribution-corrupted-by-gaussian-noise</guid>
      <pubDate>Sun, 10 Mar 2024 11:22:56 GMT</pubDate>
    </item>
    <item>
      <title>违反广义加性模型 (GAM) 中的假设</title>
      <link>https://stats.stackexchange.com/questions/642125/violation-of-assumptions-in-generalized-additive-models-gams</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/642125/violation-of-assumptions-in-generalized-additive-models-gams</guid>
      <pubDate>Fri, 08 Mar 2024 07:53:52 GMT</pubDate>
    </item>
    <item>
      <title>添加更多数据，GLMM 突然无法收敛 (R)</title>
      <link>https://stats.stackexchange.com/questions/642061/added-more-data-and-suddenly-glmm-fails-to-converge-r</link>
      <description><![CDATA[我有一个数据集，我在其中对住房开发进行了随机抽样，然后在其中系统地对每个栖息地进行了抽样。我现在有一个数据集，其中每个观察结果都是一个 patch_ID，并且我记录了该补丁的变量，例如project_ID（它来自的开发）、Area_ha（补丁的面积，以公顷为单位）、Pre_post（补丁是否来自开发前的场地规划或开发后的场地规划）。我想进行 GLMM 来调查开发前后栖息地斑块的大小 (Area_ha) 之间是否存在差异（例如 Pre_post 变量中的“前”或“后”），同时考虑我的分组因素（project_ID）。我正在使用 GLMM，因为我的 Area_ha 数据严重右偏并且没有零值。区域是连续的，Pre_post 是一个有两个级别的因子（“pre”、“post”），project_ID 是一个有 25 个级别的因子（25 个开发项目中的每个级别）。
上个月我使用以下代码在较小的数据集上成功进行了 GLMM：
glmm_gamma &lt;- glmer(Area_ha ~ Pre_post + (1 | project_ID),
                    family = Gamma(link = &quot;log&quot;),
                    数据 = 大小3)

但是，现在我增加了数据集的大小，并且与上面运行模型相同的代码行给出了错误：
警告：模型未能与 max|grad| 收敛= 0.0209587（tol = 0.002，分量 1）

数据仍然右偏，我已经删除了最麻烦的异常值。
我已尝试以下选项来排除故障，但无济于事：
#重新缩放并居中我的东西：
mu &lt;- 平均值(size3$Area_ha, na.rm = TRUE)
西格玛 &lt;- sd(size3$Area_ha, na.rm = TRUE)
size3$Area_ha_scaled &lt;- (size3$Area_ha - mu) / sigma
#但我后来意识到我不能这样做，因为伽玛分布不允许负值

尝试检查奇点：
tt &lt;- getME(glmm_gamma,“theta”)
ll &lt;- getME(glmm_gamma,“较低”)
分钟(tt[ll==0])
#0.8909557，所以不用担心奇点

尝试更多迭代
glmm_gamma &lt;- glmer(Area_ha ~ Pre_post + (1 | project_ID),
                    family = Gamma(link = &quot;log&quot;),
                    数据=大小3，
                    控制= glmerControl（优化器=“bobyqa”，optCtrl =列表（maxfun = 1000000）））
#还是没用

我完全不知道下一步该怎么做，非常感谢一些帮助！我很困惑为什么添加更多数据会使我的模型完全停止工作 - 我对统计数据不太有信心，所以希望这个社区可以提供帮助！
我已将我的数据放在这里 - 包括数据和一些代码： https://github .com/sirianmckellen/stackex.git
如果有人对我如何前进有任何想法，这是否是一个可解决的问题，或者我是否需要新的模型类型（如果是这样，我应该考虑什么？）等等，我将非常感激！谢谢大家！]]></description>
      <guid>https://stats.stackexchange.com/questions/642061/added-more-data-and-suddenly-glmm-fails-to-converge-r</guid>
      <pubDate>Thu, 07 Mar 2024 12:33:39 GMT</pubDate>
    </item>
    <item>
      <title>神经网络分类 - 针对类概率而不是类本身</title>
      <link>https://stats.stackexchange.com/questions/639435/neural-network-classification-targetting-class-probability-and-not-the-class-t</link>
      <description><![CDATA[假设我有一个二元分类问题；我想从一堆特征中预测两个类 $A$ 和 $B$ 。
但是，我还得到了它属于 $A$ 类的（预测 - 将接近准确）概率和它属于 $B$。假设分别为 $0.78, 0.22$。我想在我的问题中瞄准这些概率。
如果我只是走 $BinaryCrossentropy()$ 损失的标准路线，那么网络对我想要定位的这些概率一无所知。
现在这会变成更多的回归问题吗？或者也许是一个分类问题，但具有自定义损失函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/639435/neural-network-classification-targetting-class-probability-and-not-the-class-t</guid>
      <pubDate>Fri, 16 Feb 2024 13:13:08 GMT</pubDate>
    </item>
    <item>
      <title>我是否需要为每个使用重新参数化技巧的 PDF 获取额外的雅可比行列式日志？</title>
      <link>https://stats.stackexchange.com/questions/620657/do-i-need-to-take-additional-log-det-jacobians-for-every-pdf-that-uses-the-repar</link>
      <description><![CDATA[考虑具有重新参数化功能的 - ELBO 目标，该目标也用于 VAE 中：$$
\mathcal L_{\theta,\phi}(x)=\log p_\theta(X|Z)+\log p_\theta(Z) +\log q_\phi(Z)
$$
重新参数化技巧利用 $g(\epsilon, \phi)$ 使得 $\epsilon$&lt; /span&gt; 不依赖于 $\phi$，因此我们可以推动梯度来优化 ELBO（单个蒙特卡洛样本）。
现在由于变量的转换，我需要采取$$
\log q_\phi(Z)=\log p(\epsilon) +\log\left|\det \frac{\partial Z}{\partial \epsilon} \right|
$$
&lt;小时/&gt;
我的问题是，我是否需要为术语 $\log p_\theta(Z)$ 添加另一个雅可比对数？
$P_\theta(Z)$ 是 $Z$ 的先验。我从 $g(\epsilon,\phi)$ 中采样 $Z$ 以使 ELBO 可反向传播。然而，在 VAE 的常用算法中（如 Kingma 的算法），$P_\theta(Z)$ 没有雅可比对数

此外，如果我采用 $p_\theta(Z)$ 的雅可比行列式对数，雅可比行列式的对数将像 ELBO 中那样取消]]></description>
      <guid>https://stats.stackexchange.com/questions/620657/do-i-need-to-take-additional-log-det-jacobians-for-every-pdf-that-uses-the-repar</guid>
      <pubDate>Thu, 06 Jul 2023 02:56:55 GMT</pubDate>
    </item>
    <item>
      <title>解释三个生存曲线的单个 p 值</title>
      <link>https://stats.stackexchange.com/questions/615899/interpreting-single-p-value-for-three-survival-curves</link>
      <description><![CDATA[假设我使用 R 和 ggsurvplot() 函数绘制三个生存曲线，如下所示：

然后，ggsurvplot() 返回单个 p 值。根据我的阅读，这个 p 值是从零假设的分数测试中得出的，即 cox 模型中的三个生存曲线之间根本没有差异。
如何实际解释这一点？例如，可以说绿色曲线明显不同，或者在这种情况下优于蓝色或红色曲线吗？我很难解释这一点，因为绿色和红色看起来很相似，但蓝色和其他两条曲线之间似乎存在显着差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/615899/interpreting-single-p-value-for-three-survival-curves</guid>
      <pubDate>Mon, 15 May 2023 10:19:47 GMT</pubDate>
    </item>
    <item>
      <title>为时间序列创建合成数据，隐马尔可夫模型</title>
      <link>https://stats.stackexchange.com/questions/589940/creating-synthetic-data-for-time-series-hidden-markov-model</link>
      <description><![CDATA[假设我有一个对时间序列进行分类的任务。我决定使用隐马尔可夫模型 $\lambda(A, B, \pi)$，其中 $A$ 是转移矩阵，$B$ 是发射概率，$\pi$ 是初始值分配。观察到的随机过程如下所示

还有两个未观察到的状态：状态 1 和状态 2，也显示在绘图上。假设我想拟合 HMM 并测试它在状态识别方面的表现。我能做的最好的事情可能是将我的数据分成训练集和测试集，但以特定的方式：最后的 $n$ 观察值构成了我的测试集（绿色虚线右侧的部分），因为由于数据的时间结构，我无法使用交叉验证。但有一个问题：为了可靠地评估性能（即准确性来衡量），我至少需要在该数据未提供的状态之间进行一些转换。
问题：是否有任何方法可以为此类数据创建合成数据？我正在考虑的一件事是反转整个训练集，添加一些高斯噪声并在原始训练集的末尾添加。]]></description>
      <guid>https://stats.stackexchange.com/questions/589940/creating-synthetic-data-for-time-series-hidden-markov-model</guid>
      <pubDate>Sat, 24 Sep 2022 17:55:46 GMT</pubDate>
    </item>
    </channel>
</rss>