<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 16 Dec 2023 00:59:38 GMT</lastBuildDate>
    <item>
      <title>用于重复测量设计的基于精度的样本量计算</title>
      <link>https://stats.stackexchange.com/questions/635034/precision-based-sample-size-calculation-for-repeated-measures-design</link>
      <description><![CDATA[请寻求帮助！
我正在根据估计的精度来计算一项研究所需的样本量，但我很难弄清楚到底如何做。主要让我失望的是 1) 需要考虑测量误差，2) 需要考虑同一参与者的重复测量。另外，我想根据估计精度而不是统计显着性来计算样本量。
设计：在基线时测量二头肌厚度，然后参与者进行 8 组阻力训练。每组结束后，参与者将被要求提供“感知的肌肉肿胀”的主观评分。并再次测量肌肉厚度。这样，我们最终将得到基线肌肉厚度，以及每个参与者的主观肌肉肿胀和测量的肌肉厚度的 8 个后续值。
计划分析：1）主观肌肉肿胀评分与测量的肌肉肿胀之间的相关性。 2) 检查随着进行更多组阻力训练，主观评分和测量的肌肉厚度的变化。
根据之前也使用同一设备测量肌肉厚度的研究，我收集了测量设备的典型重测 ICC 为 ~0.988，典型标准偏差为 ~4.96，以及测量的典型标准误差约为 0.459。我的目标是达到 95% 的置信度，精度高于测量误差（也就是说，我希望有很高的信心，如果观察到时间点之间存在任何差异，它们很可能是真正的差异，而不是简单地通过测量误差来解释）。
我不确定如何将所有这些整合到基于精度的样本量计算中。正如我上面提到的，我需要考虑测量误差和每个参与者的重复测量。一些在线阅读还提醒我，可能需要考虑这些重复测量中的相关模式，我认为在这种情况下，最好将其描述为线性指数自回归 (LEAR) 或一阶自回归 (AR1)。
如果有人有任何意见或建议，我们将不胜感激！非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/635034/precision-based-sample-size-calculation-for-repeated-measures-design</guid>
      <pubDate>Sat, 16 Dec 2023 00:07:58 GMT</pubDate>
    </item>
    <item>
      <title>几年内性别之间的多重比较方差分析或 t 检验？图基事后？邦费罗尼？</title>
      <link>https://stats.stackexchange.com/questions/635030/multiple-comparisions-between-sexes-within-years-anova-or-t-tests-tukey-posthoc</link>
      <description><![CDATA[我正在进行一项遗传分析，比较 2013-2019 年雄性和雌性动物之间的 Fst 和相关系数值。每年分为季度，所以我总共有 40 个季度类别。每年的个体数量有所不同，每年的男性和女性数量也不相等。我想看看每个季度内和每个季度之间的性别价值观是否有所不同。我使用的是 R，所以我做了一个线性模型（Fst ~ Sex*Year），然后使用 Tukey 事后测试对模型进行方差分析，以查看每个季度内性别之间的比较。
Fst.test = lm(Fst ~ 性别*年份，数据 = Fst)
Fst.aov = aov(Fst.test)
摘要(Fst.aov)
Fst.posthoc = TukeyHSD(Fst.aov)

我对每个季度内的性别进行的许多事后比较并没有显着差异，尽管数值看起来相当不同。所以我随机选择了一些并做了标准的 t 检验，它们是显着的。
我应该在这里做哪些统计？方差分析和图基事后检验是最好的方法还是我应该为每个季度进行多次 t 检验并进行某种修正？如果是这样，哪个更正，我记得几年前做过 Bonferroni...]]></description>
      <guid>https://stats.stackexchange.com/questions/635030/multiple-comparisions-between-sexes-within-years-anova-or-t-tests-tukey-posthoc</guid>
      <pubDate>Fri, 15 Dec 2023 22:35:23 GMT</pubDate>
    </item>
    <item>
      <title>局部平滑器的浓度不等式 (Nadaraya Watson)</title>
      <link>https://stats.stackexchange.com/questions/635028/concentration-inequalities-for-local-smoothers-nadaraya-watson</link>
      <description><![CDATA[令 $m(X)=E(Y|X)$ 为随机设计的回归函数，并令  $\hat{m}_h(x)$
\begin{方程}
\hat{m}_h(x)=\frac{\sum_{i=1}^n K_h\left(x-x_i\right) y_i}{\sum_{i=1}^n K_h\left(x- x_i\右）}
\end{方程}
是 Nadaraya Watson 估计器，带宽为 h。对于任何 $\epsilon &gt;0$，我想绑定 Nadaraya Watson 估计器的修改。我那方面，我首先要束缚
\begin{方程}
P (|\hat{m}_h(x) - m(x)|&gt;\epsilon)。
\end{方程}
我试图避免马尔可夫/切比雪夫等不等式和收敛结果的速度。我正在寻找集中不等式的证明。我正在通过偏差方差分解尝试 Hoeffding 不等式，但遇到了困难。
任何人都可以帮助我迈出有用的第一步吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635028/concentration-inequalities-for-local-smoothers-nadaraya-watson</guid>
      <pubDate>Fri, 15 Dec 2023 21:51:45 GMT</pubDate>
    </item>
    <item>
      <title>对于软标签使用 KL 散度而不是交叉熵更好吗？</title>
      <link>https://stats.stackexchange.com/questions/635027/is-it-better-to-use-kl-divergence-for-soft-labels-instead-of-cross-entropy</link>
      <description><![CDATA[所以我正在阅读这篇论文：在 Fuse 之前对齐：利用动量蒸馏进行视觉和语言表示学习 (2017) 由 Junnan Li 等人提出，他们使用 KL 散度执行对比损失。
$$
L_{\text{ITC}} = (1 - \alpha) L_{\text{对比度}} + \frac{\alpha}{2} \left[ \text{KL} \left( q^{i2t} \平行 p^{i2t} \right) + \text{KL} \left( q^{t2i} \平行 p^{t2i} \right) \right]
$$
在此方程中，LITC-base​是基础图像文本对比损失，$\alpha$是权重因子，DKL表示KL散度，&lt; span class=&quot;math-container&quot;&gt;$q^{i2t}$ 和 $q^{t2i}$ 是预测分布（从图像到分别为文本和文本到图像），以及 $p^{i2t}$ 和 $p^{t2i}$&lt; /span&gt; 是 KL 散度项的目标分布。
我假设使用 KL 散度的原因是因为使用软标签而不是真实分布的热标签，因此当我们查看损失图时，熵项不会充当背景噪音，但当我查看时在代码中，我注意到他们本身使用了交叉熵，它与论文中提到的不同，尽管熵项在反向传播中完全没有使用，但我认为当我们看到损失曲线时它会引起问题，而且他们使用了 log_softmax 函数，但如果我们计算它等于交叉熵，并且他们在代码中的其他地方使用了交叉熵，所以不确定他们为什么在这里专门使用它。
与 torch.no_grad():
            self._momentum_update()
            image_embeds_m = self.visual_encoder_m(图像)
            image_feat_m = F.normalize(self.vision_proj_m(image_embeds_m[:,0,:]),dim=-1)
            image_feat_all = torch.cat([image_feat_m.t(),self.image_queue.clone().detach()],dim=1)
            text_output_m = self.text_encoder_m.bert（text.input_ids，attention_mask = text.attention_mask，
                                                return_dict = True, 模式 = &#39;文本&#39;)
            text_feat_m = F.normalize(self.text_proj_m(text_output_m.last_hidden_​​state[:,0,:]),dim=-1)
            text_feat_all = torch.cat([text_feat_m.t(),self.text_queue.clone().detach()],dim=1)

            sim_i2t_m = image_feat_m @ text_feat_all / self.temp
            sim_t2i_m = text_feat_m @ image_feat_all / self.temp

            sim_targets = torch.zeros(sim_i2t_m.size()).to(image.device)
            sim_targets.fill_diagonal_(1)

            sim_i2t_targets = alpha * F.softmax(sim_i2t_m, dim=1) + (1 - alpha) * sim_targets
            sim_t2i_targets = alpha * F.softmax(sim_t2i_m, dim=1) + (1 - alpha) * sim_targets

        sim_i2t = image_feat @ text_feat_all / self.temp
        sim_t2i = text_feat @ image_feat_all / self.temp
                             
        loss_i2t = -torch.sum(F.log_softmax(sim_i2t, dim=1)*sim_i2t_targets,dim=1).mean()
        loss_t2i = -torch.sum(F.log_softmax(sim_t2i, dim=1)*sim_t2i_targets,dim=1).mean()
]]></description>
      <guid>https://stats.stackexchange.com/questions/635027/is-it-better-to-use-kl-divergence-for-soft-labels-instead-of-cross-entropy</guid>
      <pubDate>Fri, 15 Dec 2023 21:37:22 GMT</pubDate>
    </item>
    <item>
      <title>滚动平均值是否有助于将时间序列变量的广义线性模型简化为 OLS？</title>
      <link>https://stats.stackexchange.com/questions/635026/does-rolling-average-help-reduce-generalize-linear-model-on-timeseries-variable</link>
      <description><![CDATA[我有一个数据$Y_t$，它基本上衡量了任何一天某些事件的数量，并且我有一个从 2015 年至今所有国家/地区的时间序列。我试图将 $Y_t$ 适合我拥有的一些 $X_t$ 并添加一个国家变量的虚拟变量（也考虑对国家进行随机/固定效应，但国家越大通常意味着事件越重要）。我尝试使用一些 GLM，如泊松或零膨胀泊松，但结果不太有希望，较小的国家通常有很多天没有事件发生，并且当天产生很多噪音（拟合系数没有意义）。然后我对事件计数进行 30 天的滚动平均值，并进行 OLS，模型系数确实有意义。我想寻求一些关于这是否正确的建议。
所以原因基本上是，每天您实现的 $Y_t$ 类似于泊松参数的样本估计，而采用滚动平均值肯定会对此有所帮助，因为它通过 CLT 变为正态分布。我知道它使你的日期自相关，但至少你得到了正确的系数，或者我可以做一些事情，比如按月重新采样，然后做 OLS。这种方法有哪些注意事项？]]></description>
      <guid>https://stats.stackexchange.com/questions/635026/does-rolling-average-help-reduce-generalize-linear-model-on-timeseries-variable</guid>
      <pubDate>Fri, 15 Dec 2023 19:46:41 GMT</pubDate>
    </item>
    <item>
      <title>规划图和经典图有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/635023/what-is-the-difference-between-planning-graph-and-the-classical-graph</link>
      <description><![CDATA[两者在各方面都有自己的优势，我想知道哪一个更可行且最适合实时使用。如果它们都不够好，请建议我任何其他比这两个更好的规划算法。]]></description>
      <guid>https://stats.stackexchange.com/questions/635023/what-is-the-difference-between-planning-graph-and-the-classical-graph</guid>
      <pubDate>Fri, 15 Dec 2023 19:15:04 GMT</pubDate>
    </item>
    <item>
      <title>独立的特征，但 PCA 显着提高了分类器的准确性。为什么？</title>
      <link>https://stats.stackexchange.com/questions/635022/independent-features-but-pca-improves-classifiers-accuracy-significantly-why</link>
      <description><![CDATA[这是我的第一个问题:)
我正在使用 kNN 分类器对多元正态分布的数据集进行处理。我必须将来自 N(mu_1,I) 和 N(mu_2,I) 的组与不同的期望向量 mu_i 和两个单位矩阵作为协方差（因此特征是独立的）。维度为 1000。一个数据集由来自第 1 组的 3500 个随机抽取条目和来自第 2 组的 1500 个随机抽取条目组成。我想研究 kNN 在不同配置的 mu_i 的高维数据上的性能.
显然，我与维度的诅咒作斗争，但这就是目标。
仍然只是为了好玩，我对前两个分量进行了 PCA 投影，因此有效地降低到了二维，并且分类器的准确度提高了约 10%。
怎么会？我的特征是独立的。这难道不应该使 PCA 不适合吗？
提前感谢您启发我；）]]></description>
      <guid>https://stats.stackexchange.com/questions/635022/independent-features-but-pca-improves-classifiers-accuracy-significantly-why</guid>
      <pubDate>Fri, 15 Dec 2023 19:12:47 GMT</pubDate>
    </item>
    <item>
      <title>临床试验亚组分析结果</title>
      <link>https://stats.stackexchange.com/questions/635020/results-of-subgroups-analysis-in-clinical-trials</link>
      <description><![CDATA[亲爱的临床试验参与者，
我有一个关于如何呈现亚组分析结果以及它们对医生有何帮助的问题。
在我关注的特定研究领域，我们使用基于简单临床数据（例如基线时的年龄和原始细胞计数）的算术分数来估计第 12 个月时的潜在反应。分数使用以下公式计算：例如评分 = a1 * 年龄 + a2 * 原始细胞计数 + a3 * 变量 3，然后我们根据预定义的截止值将患者分为高风险组、中风险组或低风险组。现在，我有了新数据，想要更深入地探索子组。
我可以做哪些事情？我正在考虑的事情是：

我可以细化分数计算中使用的系数或截止值
或创建新的评分系统
或确定重要变量及其截止值

还有什么有用的吗？哪些信息对医生来说是有趣或有价值的？我计划与医生讨论这个问题，但我想听听您对我可以采取的其他步骤的意见]]></description>
      <guid>https://stats.stackexchange.com/questions/635020/results-of-subgroups-analysis-in-clinical-trials</guid>
      <pubDate>Fri, 15 Dec 2023 18:40:43 GMT</pubDate>
    </item>
    <item>
      <title>二项分布样本的方差估计器</title>
      <link>https://stats.stackexchange.com/questions/635019/estimator-of-variance-for-a-binomially-distributed-sample</link>
      <description><![CDATA[我想对一些数据进行贝叶斯分析。假设我们有一个样本，我们认为该样本来自二项式总体。我们有 $m$ 个观察值
$$X_i \sim Bin(n,p) \text{ 对于某些 } i \in \{1,2,\dots,m\}$$
我选择了之前的测试版本。我不确定如何选择参数以使我的分布更好地符合我的信念。我假设我会取样本均值并将贝塔先验的均值设置为等于该数字。但我不确定如何计算方差。任何人都可以提供建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/635019/estimator-of-variance-for-a-binomially-distributed-sample</guid>
      <pubDate>Fri, 15 Dec 2023 17:55:09 GMT</pubDate>
    </item>
    <item>
      <title>（也许很愚蠢）关于蒙特卡罗模拟的问题[关闭]</title>
      <link>https://stats.stackexchange.com/questions/634997/perhaps-dumb-question-about-monte-carlo-simulation</link>
      <description><![CDATA[我正在尝试蒙特卡罗模拟，对该方法对我的特定问题的适用性有疑问。
在这个问题中，我有一个正态分布的参数 $\phi$ 。然后，我运行多次模拟来随机生成遵循正态分布的 $\phi$ 值（使用 SMath，就像 Mathcad 一样）。到目前为止，一切都很好;然而，我在概念上遇到的问题是下一步。
为了解决我的问题，我需要获取 $\phi$ 的随机生成值，并使用非线性变换函数计算新参数$N_y$。 $N_y$ 的方程涉及指数和项的平方。然后我使用这个新参数来计算最终答案。如果有帮助的话，那就是土壤的承载力问题，其中沙子的极限承载力 $Q$ 为
$$\begin{对齐}
Q &amp;= \frac{B\gamma N_y}{2} \\
N_y &amp;= (N_q-1)\text{tan}(1.4\phi) \\
N_q &amp;= \exp(\pi\text{tan}(\phi))\tan^2\left(\frac{\pi}{4} + \frac{\phi}{2}\right),
\end{对齐}$$
其中 $B$ 是基础宽度且恒定，$\gamma$ 是土壤单位重量且恒定.
当我检查结果时，我注意到 $N_y$ 的预期值应该约为 $26.2$（直接使用平均值 $\phi$ 计算时，在本例中为 $33$度）；但是，使用随机生成的 $\phi$ 值时 $N_y$ 的平均值为 $10,000$ 次模拟后，class=&quot;math-container&quot;&gt;$31.3$。当然，这意味着预期结果与蒙特卡罗模拟得到的结果不同。考虑到这一点， $\phi$ 到 $N_y$ 的转换使用了非线性方程因此，这种差异不应是意外的。然而，我不知道这是否意味着蒙特卡罗模拟因此不适用于这个特定问题。我已经看到更简单的点估计方法用于解决相同的问题，并且我注意到这种非线性变换也应该影响结果，但我已经看到了使用该方法的几个已发布的解决方案，所以这让我想知道......
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/634997/perhaps-dumb-question-about-monte-carlo-simulation</guid>
      <pubDate>Fri, 15 Dec 2023 15:00:08 GMT</pubDate>
    </item>
    <item>
      <title>相对差异的置信区间</title>
      <link>https://stats.stackexchange.com/questions/635033/confidence-interval-of-a-relative-difference</link>
      <description><![CDATA[我知道两个样本 $X_1$ 和 $X_2$，但我不知道这些值。如何计算平均值相对差的置信区间界限$(m_1-m_2)/m_1$？
当我尝试进行直接计算时，我必须计算比率的方差。在线发表的论文中提供了一个基于泰勒级数的公式，但在我的情况下，相应的一阶近似并不准确，因为与平均值相比方差相当大。
我想到了一种替代方案，即将参考样本 $X_1$ 的均值和方差视为理论常数值而不是随机变量。这类似于将 $X_2$ 与理论分布进行比较，而不是比较两个样本。在这种情况下，不再有比率，但我不确定该方法是否有意义。
感谢您的反馈]]></description>
      <guid>https://stats.stackexchange.com/questions/635033/confidence-interval-of-a-relative-difference</guid>
      <pubDate>Fri, 15 Dec 2023 13:58:15 GMT</pubDate>
    </item>
    <item>
      <title>我的非线性问题的最大似然估计量是多少？</title>
      <link>https://stats.stackexchange.com/questions/634974/what-is-the-maximum-likelihood-estimator-for-my-nonlinear-problem</link>
      <description><![CDATA[在区域 $0\leq x\leq 1$ 和 $0\leq y\leq 1$ 我在 $(x_b,y_b)$ 中放置了 1 个无线电广播电台和 N 个接收器。广播公司的立场尚不清楚。
然而，每个接收器的位置是已知的： $(x_i,y_i)$ 以及从接收器到广播器的距离：$d_i$。
距离测量中存在一些噪声，我假设这些噪声呈正态分布，均值为 0，并且所有接收器的方差相同：
$$
\sqrt{(x_i - x_b)^2+(y_i - y_b)^2} = d_i + \epsilon_i
$$
在哪里
$$
\epsilon_i \sim \mathcal{N}(0,\,\sigma^{2})
$$
我的目标是估计无线电广播公司最可能的位置：$(x_b,y_b)$。
我想通过将其表述为一个最小化问题来做到这一点。
到目前为止，我正在最小化：
$$
SE = \sum_i \left[\sqrt{(x_i - x_b)^2+(y_i - y_b)^2} - d_i\right]^2
$$
我读到，对于线性回归，最小二乘估计器也是正态分布误差假设下的最大似然估计器。
但是这对于我的非线性问题也适用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634974/what-is-the-maximum-likelihood-estimator-for-my-nonlinear-problem</guid>
      <pubDate>Fri, 15 Dec 2023 08:33:05 GMT</pubDate>
    </item>
    <item>
      <title>混合设计实验：中值缩减还是线性混合模型？</title>
      <link>https://stats.stackexchange.com/questions/634791/mixed-design-experiment-median-reduction-or-linear-mixed-model</link>
      <description><![CDATA[我从混合设计的声学定位实验中收集了数据，其中因素是人群（一个带有助听器 (HA)，一个带有人工耳蜗 (CI)）和条件，第一组人群有四个（带有左 HA、右 HA、两者 HA、无 HA），以及第二个群体的三个（左 CI、右 CI、两者 CI）。在每种情况下，对于 13 个收集的项目（目标定位答案）有 5 次重复测量。并非所有参与者都在每种情况下都进行了测试。我想分析不同条件下受试者内部、受试者之间以及人群之间的差异。混合方差分析不是一种选择，即使它可以容纳丢失的数据，因为数据严重倾斜，并且违反了球形和正态分布假设。我看到两种可能的选择：

通过中位数将每个参与者每个条件的重复测量值减少到一个值。在这种情况下，一些统计功效就会丧失。如何计算和报告效应大小或统计功效？考虑到通过这种减少，所执行的测试不是参数化的。
拟合线性混合效应模型，并随机截取受试者 ID。在这种情况下，没有直线的 Q-Q 图是否违反了必要的假设？如果关系比线性关系更复杂，LMM 是否是一个可行的选择？如果 Q-Q 图是线性的，我会选择 R，如下所示：

&lt;前&gt;&lt;代码&gt;
# 拟合混合效应模型
# - 响应：因变量
# - 总体：受试者间因素（2 个级别）
# - 条件：受试者内因素
# - subjectID：受试者的随机效应

模型 &lt;- lmer(响应 ~ 总体 * 条件 + (1 | subjectID), data = data)

我分析了四个不同的响应变量：头部距离、头部旋转、有符号误差和无符号误差。
平均值 + 2*标准差（针对每种条件）的异常值已被删除。数据已进行对数转换。
以下是 Q-Q 图、残差直方图以及残差与四个变量的拟合值的关系。四个变量残差的偏度值分别为：0.98、-2.69、-4.26、-0.58。











]]></description>
      <guid>https://stats.stackexchange.com/questions/634791/mixed-design-experiment-median-reduction-or-linear-mixed-model</guid>
      <pubDate>Wed, 13 Dec 2023 10:28:47 GMT</pubDate>
    </item>
    <item>
      <title>具有二元结果的纵向数据的变量选择</title>
      <link>https://stats.stackexchange.com/questions/633663/variable-selection-for-longitudinal-data-with-a-binary-outomce</link>
      <description><![CDATA[我有一个大型纵向数据集（100,000 观测值），其中包含固定 ID 和年份，以及大约 1000 特征（大多数数字和一些因子）。我一直在使用一小部分可用功能对此数据运行一些分类任务（随机森林、xgboost、svm）。我希望能够使用这些模型来进行一些特征选择/变量重要性，但是，使用全部或大多数可用预测变量运行这些模型似乎并不可行。
在纵向数据集的上下文中，我可以采用哪些可能的方法来选择相关特征，其中特征随 ID 的不同而变化，也随时间的变化而变化。
我是否要硬着头皮允许这些模型在所有功能上运行，然后检查变量重要性和其他指标？或者在对特征进行子集化之前我可以采取一些探索性数据分析步骤吗？
编辑：在特征子集上运行随机森林可能有意义吗，例如一次 100 个特征，因此 10 RF 模型并使用变量重要性对它们中的每一个进行了解，以了解我最终可以使用哪些预测因子？
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/633663/variable-selection-for-longitudinal-data-with-a-binary-outomce</guid>
      <pubDate>Mon, 11 Dec 2023 22:34:43 GMT</pubDate>
    </item>
    <item>
      <title>适当的统计测试来确定分类数据的内部凝聚力</title>
      <link>https://stats.stackexchange.com/questions/633558/appropriate-statistical-test-to-determine-internal-cohesion-of-a-categorical-dat</link>
      <description><![CDATA[我有一个主要由二进制变量组成的数据集，每行代表一名患者，每列代表一种疾病的症状。患者会勾选 1（如果出现症状），否则勾选 0。每个表代表一种疾病，如下所示：
表 1. 仅疾病 A

&lt;表类=“s-表”&gt;
&lt;标题&gt;

症状 1
症状 2
......
症状 N


&lt;正文&gt;

0
1
....
1


1
1
....
1


....
....
....
0


0
1
...
1




我想进行一项测试来确定患者是否来自同一人群，即他们的反应差异最小。理想情况下，患者应该对特定疾病有相同的症状，因为疾病通常以症状的形式表现出来，但实际上情况并非如此，因为有些人可能会经历这种情况，而另一些人则不会。
我正在寻找一个统计测试来显示患者的反应是一致的（反应是同质的），这表明几乎所有人都有相同的症状，如果患者的反应不一致，那么就需要再次调查原因.
我已经阅读过有关 phi 系数的内容，但它仅适用于两个二元变量，进一步阅读使我进行了卡方检验和多重对应分析，不幸的是，我很困惑这两者中哪一个是最合适的。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/633558/appropriate-statistical-test-to-determine-internal-cohesion-of-a-categorical-dat</guid>
      <pubDate>Sun, 10 Dec 2023 21:29:39 GMT</pubDate>
    </item>
    </channel>
</rss>