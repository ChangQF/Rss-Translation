<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 29 Sep 2024 18:20:45 GMT</lastBuildDate>
    <item>
      <title>时间序列的 AIC 和差分</title>
      <link>https://stats.stackexchange.com/questions/655080/aic-and-differencing-for-time-series</link>
      <description><![CDATA[我正在教授一门应用时间序列课程，并想到了一个我不知道如何回答的问题。假设我们有一个非平稳时间序列，我们尝试使用常规差分、季节性差分或两者的模型。这三种转换都会导致数据看起来是平稳的。像这样的例子出现在《Stat 2》一书的第 12 章中，涉及和平桥上的车辆交通。您可以使用以下 R 块获取数据。
require(Stat2Data)
data(PeaceBridge2003)
plot(PeaceBridge2003$Traffic)

我考虑了几个模型，发现其中三个模型的残差没有自相关性，即

模型 1：SARIMA(1,1,0)x(1,0,0)[12]，这是我“手工”得到的模型来自 ACF 和 PACF
模型 2：SARIMA(0,0,0)x(0,1,1)[12]，auto.arima() 选择的模型
模型 3：SARIMA(0,1,1)x(1,1,0)[12]，来自 Stat 2 一书的模型

我希望这个符号没问题。第一个表示进行一阶正则差分，然后使用 AR(1) 项和季节性 AR(1) 项 $x_{t-12}$。第二个说进行一阶季节性差分，然后包含季节性 MA(1) 项 $w_{t-12}$。
要在这些模型之间进行选择，我的直觉是选择最简单的一个（对我来说，就是模型 1），因为差分是一种破坏性的转换。
但是，我确信我的学生会建议使用 AIC 来比较这三个模型，当你这样做时，它会选择模型 3。我担心的是这三个模型代表了三种不同的转换。响应变量可以是 $\Delta x_t$ 或 $\Delta_{12} x_t = x_t - x_{t-12}$ 或 $\Delta_{12} (\Delta x_t)$。
众所周知，您不应使用 AIC 来比较对响应变量进行不同变换的模型。例如，对响应变量进行对数或平方根变换将产生截然不同的 AIC，正如之前所介绍的那样。
令我惊讶的是，当我模拟数据并使用 stats 包中的函数 AIC() 时，我不会像上例中那样为不同类型的差分获得截然不同的值。而且 AIC 通常会在模拟中选择正确的模型。我开始怀疑它在 R 中的实现方式，是否可以用它来比较上述三个模型，也许是因为，归根结底，这三个模型中的响应变量仍然是 $x_t$（例如，R 内置了反向转换）。这样对吗？或者，我们不应该使用 stats 包中的 AIC() 函数来比较具有不同类型差分的上述模型？
最后，我很清楚，关于使用什么顺序差分的真正决策者是“这种差分后数据是否平稳？”的问题；并且，考虑到生成机制，理论上，三种差分类型中只有一种应该导致平稳性。而且，通常，季节性差异是没有必要的。但问题是，我们没有足够的数据来肯定地说，两个选择会留下非平稳数据，而第三个选择会成功（这里$n = 156$；这是 13 年的月度数据）。据我们所知，这三个选择都是有效的。因此，了解 AIC 是否可用于帮助在这种情况下做出决定将会很有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655080/aic-and-differencing-for-time-series</guid>
      <pubDate>Sun, 29 Sep 2024 17:07:25 GMT</pubDate>
    </item>
    <item>
      <title>随机化和因果 Dag</title>
      <link>https://stats.stackexchange.com/questions/655078/randomization-and-causal-dags</link>
      <description><![CDATA[假设我们有治疗 T 和结果 O，以及变量 A 和 B，具有以下因果 dag：
但是，如果我们使用这些治疗和结果变量进行 RCT，那么将因果 dag 想象成：

指向 T 的传入箭头去哪儿了？]]></description>
      <guid>https://stats.stackexchange.com/questions/655078/randomization-and-causal-dags</guid>
      <pubDate>Sun, 29 Sep 2024 16:12:38 GMT</pubDate>
    </item>
    <item>
      <title>使用多种特征进行预测</title>
      <link>https://stats.stackexchange.com/questions/655077/forecasting-using-many-features</link>
      <description><![CDATA[我有 n 个特征的时间序列。我的目标是以向前的方式预测目标，即预测模型的长度为 T 的训练周期每 k 个周期后向前移动一次。
由于 n &gt;&gt; T，我决定将我的特征分组为 m 个组，其中 m &lt; T。此分组基于数据来源和其他特定于域的信息。每个组，我都会在组特征和目标之间拟合预测模型。然后，这 m 个模型的预测又被用作预测目标的特征。这有意义吗？如果有，这种方法叫什么？
是否有任何统计方法可以将这 n 个特征分组为 m 个组？我尝试过层次聚类，但其结果比现有方法更差。这似乎是由以下事实驱动的：聚类 2 步模型有效地为属于最大特定域组的特征赋予了更多权重。这似乎使结果更糟。有没有办法在创建聚类期间惩罚每个组的聚合权重？]]></description>
      <guid>https://stats.stackexchange.com/questions/655077/forecasting-using-many-features</guid>
      <pubDate>Sun, 29 Sep 2024 15:55:33 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法根据变量的同比变化百分比（YoY）来计算指数值（以 100 为基数）？</title>
      <link>https://stats.stackexchange.com/questions/655076/is-there-away-to-compute-index-values-base-100-from-year-over-year-change-y</link>
      <description><![CDATA[假设我有这样的时间序列：



时间段
同比变化（%）




2024 年 _ Q1
7.00


2024 年 _ Q2
4.85


2024 年 _第三季度
5.77


2024 年 _ 第四季度
5.66


2025 年 _ 第一季度
6.54


2025 年 _ 第二季度
6.48


2025 年 _ 第三季度
6.36


2025 年第四季度
6.25



有没有办法将“同比变化百分比”系列转换为“指数值”系列（以给定日期为基数 100）？
目标系列将类似于：



时间段
指数（以 100 为基数，位于 Y2023_Q1）




Y2023 _ Q1
100


Y2023 _ Q2
103


2023 年 _ 第 3 季度
104


2023 年 _ 第 4 季度
106


2024 年 _ 第 1 季度
107


2024 年 _ 第 2 季度
108


2024 年 _ 第 3 季度
110


2024 年 _ 第 4 季度
112


2025 年 _ 第 1 季度
114


2025 年 _ 第 2 季度
115


2025 年 _ 第三季度
117


2025 年 _ 第四季度
119



或者可能无法重建 2023 年第一季度的数据，所以也许我应该着眼于构建类似的东西，并在 2024 年第一季度修复基准参考（索引 = 100）：



时间段
索引（基数 100 = Y2024_Q1)




Y2024 _ Q1
100


Y2024 _ Q2
1XX


Y2024 _ Q3
1XX


Y2024 _ Q4
等。



如果我们有四分位数据，我知道我们可以使用以下公式计算指数的同比变化百分比：
$$\frac{\mathbf{Index}_{Year\_Y, Quarter\_Q}-\mathbf{Index}_{Year\_(Y-1), Quarter\_Q}}{ \mathbf{Index}_{Year \_(Y-1), Quarter\_Q}}$$
但我只有 YoY 数据，我想将其反转回指数值。有没有实际的方法可以做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/655076/is-there-away-to-compute-index-values-base-100-from-year-over-year-change-y</guid>
      <pubDate>Sun, 29 Sep 2024 15:45:06 GMT</pubDate>
    </item>
    <item>
      <title>组成数据中的零值和使用狄利克雷分布的问题到底是什么？</title>
      <link>https://stats.stackexchange.com/questions/655075/what-exactly-is-the-issue-with-zero-values-in-compositional-data-and-using-the-d</link>
      <description><![CDATA[因此，Aitchison 描述了零值的问题，即无法对这些数字取对数。但他也解释说，如果只有少量的零，我们可以简单地用一个小数字替换它们。他警告说，选择如此小的值可能会影响结果。我有两个问题：

为什么我们不能只取最小的可用数字（R 中的机器 epsilon）？
为什么无论有多少个零都不能使用这种方法？

这篇论文已经过时了，但最近仍然被引用来描述使用狄利克雷建模时与零值相关的问题。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655075/what-exactly-is-the-issue-with-zero-values-in-compositional-data-and-using-the-d</guid>
      <pubDate>Sun, 29 Sep 2024 14:56:09 GMT</pubDate>
    </item>
    <item>
      <title>非线性多模态模型的高维贝叶斯推断</title>
      <link>https://stats.stackexchange.com/questions/655073/bayesian-inference-in-high-dimension-for-a-non-linear-multimodal-model</link>
      <description><![CDATA[考虑以下模型：我正在以概率 $p$ 抽样伯努利变量，其概率为
\begin{equation}
p(\omega_i, \tau) := \frac{1}{2} + \frac{1}{2 n} \left[ \sum_{i=1}^{n} \cos (\omega_i \tau) \right] \; .
\end{equation&gt;
目标是通过观察伯努利变量的许多样本来找到 $\omega_i$ 的后验分布。对于较大的 $n$，这将成为高维非线性问题。此外，由于 $\omega_i$ 的置换对称性，预计后验分布将是多峰的。为了打破 $\omega_i$ 中的退化，必须使用不同的 $\tau$ 值进行测量。如前所述，我的目标是根据一系列观察到的样本计算 $\omega_i$ 的后验分布。我尝试过粒子过滤（即连续蒙特卡罗），但对于 $n=10$，问题变得难以解决，后验分布无法收敛到真实值。我可以使用一个好的 GPU，并希望实现一种快速贝叶斯推理技术，该技术可以在需要时提供后验的粗略估计，但也允许更多时间密集型计算以收敛到真实后验。
当 MCMC 太慢时，解决这个问题的好方法是什么？使用正则化流的变分贝叶斯推理似乎是一个潜在的解决方案，但它需要对后验有一个好的假设，由于多模态性，这很难获得。]]></description>
      <guid>https://stats.stackexchange.com/questions/655073/bayesian-inference-in-high-dimension-for-a-non-linear-multimodal-model</guid>
      <pubDate>Sun, 29 Sep 2024 14:17:30 GMT</pubDate>
    </item>
    <item>
      <title>有/无交互作用的 GEE 模型 - 解释</title>
      <link>https://stats.stackexchange.com/questions/655071/gee-model-with-without-interaction-interpretation</link>
      <description><![CDATA[我在治疗期间（在几个时间点）测量了一种新的生物标志物。所有患者的临床数据都在基线时存在。现在，我正在使用 GEE 模型和探索性方法来识别在治疗期间对生物标志物有影响的临床变量。
我在单独的 GEE 模型中测试了每个临床变量，生物标志物是因变量，并在模型中采用因子时间和临床变量。
我还以相同的方式测试了每个临床变量，但还包括时间和临床变量之间的相互作用。现在我不明白为什么有些临床变量具有主效应，但包括交互时间/临床变量后，其他具有主效应的临床变量也出现了。
哪种方法最适合识别对生物标志物有影响的临床变量 - 使用仅包含因子时间和临床变量的模型，还是我始终必须包括相互作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/655071/gee-model-with-without-interaction-interpretation</guid>
      <pubDate>Sun, 29 Sep 2024 10:23:51 GMT</pubDate>
    </item>
    <item>
      <title>在线性混合效应模型中，随机效应的估计条件模式是否遵循 MVN？</title>
      <link>https://stats.stackexchange.com/questions/655058/do-estimated-conditional-modes-of-random-effects-follow-a-mvn-in-a-linear-mixed</link>
      <description><![CDATA[在教程 GLMM 示例 中提供的 示例中，线性混合效应模型与苔原生态系统的数据（来自 Belshe et al., 2013）拟合，具有以下规范：
cmod_lmer &lt;- lmer(GS.NEE ~ cYear + (1+cYear|Site),
data=mc2B, REML=TRUE,
weights=n)

本教程后面会提出以下建议：

您可以使用 qqmath() 代替 dotplot() 来获取 条件模式的 Q-Q 图。 [强调添加]

我理解，随机效应，无条件和有条件（给定观察到的响应）具有多元正态分布（请参阅为什么假设随机效应遵循正态分布，或这些幻灯片中的第 3.4 节，第 173 页，作者：Dimitris Rizopoulos）。
我从上面提到的建议中推断出，模型中随机效应的条件模式（或均值）的估计值应遵循多元正态（MVN）分布，因此，我们应该检查如果 qqmath(ranef(...)) 确实如此。但是，在线性混合效应模型的公式化中，从未明确假设随机效应的条件模式应具有多元正态分布，对吗？那么使用估计值的 Q-Q 图背后的动机是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655058/do-estimated-conditional-modes-of-random-effects-follow-a-mvn-in-a-linear-mixed</guid>
      <pubDate>Sat, 28 Sep 2024 20:52:25 GMT</pubDate>
    </item>
    <item>
      <title>测试两个变量之间的关联强度随时间的变化</title>
      <link>https://stats.stackexchange.com/questions/654809/test-for-changing-strength-of-association-between-two-variables-across-time</link>
      <description><![CDATA[我想用纵向数据测试两个变量之间的弱化关联。
我有一项调查，用于衡量 2005 年至 2020 年期间每年对政府机构的信任度。我还有县级犯罪率数据。在此期间，大多数县的犯罪率都有所上升。毫不奇怪，犯罪率与对政府机构的信任度降低有关。
我的假设是，犯罪率和对政府机构的信任度之间的关联在几年内会减弱。换句话说，人们“习惯了”犯罪。因此，我应该能够追踪当地犯罪率和结果变量之间的关联如何随着时间的推移而减弱。我该如何测试这一点？最容易实现的策略是建立每年的横截面模型并比较感兴趣变量的 t 值。
请记住，这不是面板数据，而是汇总数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/654809/test-for-changing-strength-of-association-between-two-variables-across-time</guid>
      <pubDate>Tue, 24 Sep 2024 01:00:10 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯结构时间序列的优秀文献</title>
      <link>https://stats.stackexchange.com/questions/654752/good-literature-for-bayesian-structural-time-series</link>
      <description><![CDATA[我目前正在写一些关于时间序列分析的文章，包括一章关于贝叶斯结构时间序列的文章。我有数学背景，了解时间序列分析的基础知识，包括 ARMA 模型等。
你能推荐一些关于贝叶斯结构时间序列的文献（以数学理论为重点）吗？我对数学理论比对实现更感兴趣。我发现很难在互联网上找到好东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/654752/good-literature-for-bayesian-structural-time-series</guid>
      <pubDate>Mon, 23 Sep 2024 05:39:20 GMT</pubDate>
    </item>
    <item>
      <title>回归问题的预期误差减少</title>
      <link>https://stats.stackexchange.com/questions/654594/expected-error-reduction-for-regression-problems</link>
      <description><![CDATA[我想在 Python 中实现一种基于预期误差减少 (EER) 的主动学习方法：
https://axon.cs.byu.edu/Dan/778/papers/Active%20Learning/roy.pdf
https://arxiv.org/abs/2211.09283
对于回归问题，其中机器学习模型是基于树的模型（我计划使用 XGBoost、随机森林回归器或 VotingRegressor，它们只是平均输出我不需要使用贝叶斯推理框架，但如果有必要，我会使用它。目前，我有两个问题：

上述论文中的方程式非常复杂，没有伪代码。我不明白如何为 EER 编写损失函数，以及整体框架是什么。我的粗略理解是，为了计算这个损失，对于每个未标记的输入样本，我需要运行我的 ML 模型，计算每个可能标签在我的 ML 模型下的概率，然后用它来计算损失……但我错过了细节。
这些方程式是针对分类任务给出的。我实际上有一个回归任务。我如何使 EER 适应回归？我想我应该用积分代替对所有可能的标签值求和...因为我可以为输出变量给出上限和下限，高斯-勒让德数值积分可能是计算效率更高的方法。

如何实现基于 EER 的回归主动学习？包含 Python 代码/伪代码的答案是最好的，但即使只是对算法和要使用的方程式的详细解释也足够了（然后我可以尝试自己用 Python 实现它，如果遇到困难，请在 StackOverflow 上提问）。]]></description>
      <guid>https://stats.stackexchange.com/questions/654594/expected-error-reduction-for-regression-problems</guid>
      <pubDate>Thu, 19 Sep 2024 09:39:01 GMT</pubDate>
    </item>
    <item>
      <title>AR(1) 的手动 MLE 产生了一个奇怪的初始值 $y_0$</title>
      <link>https://stats.stackexchange.com/questions/648189/manual-mle-of-ar1-yields-a-weird-initial-value-y-0</link>
      <description><![CDATA[我正在尝试手动实现 AR(1) 模型中参数的最大似然估计 (MLE)
$$
y_t = c + \varphi_1 y_{t-1} + \varepsilon_t
$$
其中 $\text{Var}(\varepsilon_t)=\sigma^2$。我将我的结果与 forecast 包中的 Arima 获得的结果进行比较（基于 stats 包中的 arima）。

我的可能性略高于 Arima。
除了初始值 $y_0$ 之外，估计值并不相同，但相当接近。我的估算器给出的值似乎太高（高于 $y$ 的范围），并且远离 Arima 的更合理值。

我尝试了几个不同的手动 MLE 起始值，但每次都得到相同的结果。
我做错了什么？
library(fpp2) # 示例数据集所需

# AR(1) 的对数似然
loglik &lt;- function(pars){
c &lt;- pars[&quot;c&quot; ] # 常数
phi1 &lt;- pars[&quot;phi1&quot; ] # 斜率
sigma2 &lt;- pars[&quot;sigma2&quot;] # 误差方差
y0 &lt;- pars[&quot;y0&quot; ] # 时间序列的初始值
T &lt;- length(y)
e &lt;- rep(NA,T)
e[1] &lt;- y[1] - ( c + phi1*y0 )
for(t in 2:T){
e[t] &lt;- y[t] - ( c + phi1*y[t-1] )
}
Li &lt;- dnorm(e, mean=0, sd=sqrt(sigma2))
loglik &lt;- sum(log(Li))
return(loglik)
}

y &lt;- diff(log(oil)) # 1966-2013 年沙特阿拉伯石油产量年度变化百分比

# 优化 loglik 函数
opars &lt;- c(c=0, phi1=0, sigma2=var(y), y0=mean(y)) # 参数的初始值
#opt &lt;- optim(par=opars, fn=loglik, method=&quot;BFGS&quot;, control=list(fnscale=-1)) # 无界优化
opt &lt;- optim(par=opars, fn=loglik, method=&quot;L-BFGS-B&quot;, control=list(fnscale=-1), 
lower=c(-Inf,-0.99,1e-10,-Inf), 
upper=c( Inf, 0.99,Inf , Inf)) # 有界优化，-0.99&lt;=phi1&lt;=0.99 且 0&lt;sigma2
opt$convergence # 值为 0 表示优化算法正确收敛
optres &lt;- c(opt$par, logL=opt$value) # 主要结果为单个向量

# 与以下内容进行比较`forecast::Arima` 对相同数据产生的结果
m1 &lt;- Arima(y, order=c(1,0,0), method=&quot;CSS-ML&quot;)
m1 &lt;- Arima(y, order=c(1,0,0), method=&quot;ML&quot; )
chat &lt;- unname(m1$coef[2]*(1 - m1$coef[1])) # 用 mu 的估计值表示的 c 估计值
phi1hat &lt;- unname(m1$coef[1])
y0hat &lt;- (y[1] - chat - m1$residuals[1]) / phi1hat # y0 的估计值
m1par &lt;- c(c=chat, phi1=phi1hat, sigma2=m1$sigma2, y0=y0hat) 
m1res &lt;- c(m1par, logL=m1$loglik) # 单个向量中的主要结果

# 打印并将手动 ML 估计值与 `Arima` 中的估计值进行比较
估计值&lt;- rbind(optres,m1res)
rownames(估计值) &lt;- c(&quot;Manual&quot;,&quot;Arima&quot;) 
print(round(估计值, 数字=6))
]]></description>
      <guid>https://stats.stackexchange.com/questions/648189/manual-mle-of-ar1-yields-a-weird-initial-value-y-0</guid>
      <pubDate>Wed, 29 May 2024 08:09:04 GMT</pubDate>
    </item>
    <item>
      <title>证明对数 Exp 的方差大于对数 Exp 的方差</title>
      <link>https://stats.stackexchange.com/questions/648034/prove-that-variance-of-log-exp-is-greater-than-variance-of-exp-log</link>
      <description><![CDATA[在变分推断的背景下，我们从估计梯度：
$\log E_{q \sim Q(z|x)} [ \frac{p(z,x)}{q(z|x)} ]$
到：
$E_{q \sim Q(z|x)} [ \log \frac{p(z,x)}{q(z|x)} ]$，即 ELBO。
我想明确比较蒙特卡洛估计量对这两个量梯度的方差，但我在代数方面遇到了困难。
通过蒙特卡洛估计量，我的意思是我们用每个期望中的随机变量的样本均值替换每个表达式中的期望。
你能帮忙？
参考文献：https://arxiv.org/pdf/2208.11970，第 3 页，方程 7-8
基本上我不明白为什么我们不最大化上述参考文献中的方程 7 而是方程 8。也许是因为方差较低，但如何严格地证明这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/648034/prove-that-variance-of-log-exp-is-greater-than-variance-of-exp-log</guid>
      <pubDate>Sun, 26 May 2024 22:05:18 GMT</pubDate>
    </item>
    <item>
      <title>神经网络分类——以类别概率为目标，而不是类别本身</title>
      <link>https://stats.stackexchange.com/questions/639435/neural-network-classification-targetting-class-probability-and-not-the-class-t</link>
      <description><![CDATA[假设我有一个二元分类问题；我想从一组特征中预测两个类 $A$、$B$。
但是，我还得到了一个（预测的 - 接近准确的）概率，它是类 $A$ 的概率，以及它是类 $B$ 的概率。假设分别为 $0.78、0.22$。这些概率正是我想要解决的问题。
如果我只采用标准路线 $BinaryCrossentropy()$ 损失，那么网络对我想要解决的这些概率一无所知。
这现在会变成回归问题吗？或者可能是分类问题，但具有自定义损失函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/639435/neural-network-classification-targetting-class-probability-and-not-the-class-t</guid>
      <pubDate>Fri, 16 Feb 2024 13:13:08 GMT</pubDate>
    </item>
    <item>
      <title>寻找具有多个部分和不同尺度的损失函数的系数</title>
      <link>https://stats.stackexchange.com/questions/579487/finding-coefficients-for-a-loss-function-with-multiple-parts-and-different-scale</link>
      <description><![CDATA[我正在努力重复使用论文Pixel2Mesh++：通过变形生成多视图 3D 网格，该论文将 3D 网格变形以使其适合某些 2D 图像，但场景与原始场景不同。
损失函数由四个项组成：倒角损失、余弦损失、拉普拉斯正则化和边长正则化（此处说明）。
这四个项的尺度非常不同，而且有些不受约束，这意味着我无法使用最大值对它们全部进行归一化，如果我保持原样，其中一些将会丢失（哈哈）在优化中。更糟糕的是，并非所有损失部分都同等重要：例如，与正则化因子相比，倒角损失（最小化预期网格与实际网格之间的距离）在优化中应具有更高的权重。
在 github 存储库 中，发现一些系数可能或可能不是当前问题的最佳系数。我猜它们还不错，因为这是作者决定使用的。但是，用于查找这些系数的方法没有在任何地方解释（我甚至尝试打开有关此问题的 github 问题，但没有得到任何答案）。
现在，我已经在这里阅读了许多关于优化多损失优化和损失缩放问题的问题，但我仍然不知道如何处理找到最佳系数的问题。
我考虑过使用超参数优化器（如 Hyperband）来找到最佳系数，但显然会发生的情况是引擎采用每个系数的下限，导致损失很小，但结果并不更好。
我读到过使用平衡因子（如 $ \lambda*loss1 + (1 - \lambda)*loss2 $），但我认为这不能应用于超过两个损失。
最后，我尝试自己设置系数以获得更好的结果，但这看起来像是无休止的搜索。
所以，我的问题是：对于具有多个部分且并非所有部分都具有相同比例的损失函数，有哪些方法可以找到良好的系数？]]></description>
      <guid>https://stats.stackexchange.com/questions/579487/finding-coefficients-for-a-loss-function-with-multiple-parts-and-different-scale</guid>
      <pubDate>Tue, 21 Jun 2022 12:48:33 GMT</pubDate>
    </item>
    </channel>
</rss>