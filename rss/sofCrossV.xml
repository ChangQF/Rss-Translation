<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 19 Oct 2024 15:16:03 GMT</lastBuildDate>
    <item>
      <title>稳健性度量应用于实际问题</title>
      <link>https://stats.stackexchange.com/questions/656005/robustness-measure-applied-to-real-world-problem</link>
      <description><![CDATA[我必须为一个大学项目解决以下任务：
“建议一个稳健性度量以获得最佳定价，并计算手头数据集的此类参数。在这里，您可以测量对消费者数据可能发生变化的稳健性。”
我很乐意听到有关如何解决此问题的建议。请考虑到我的统计知识有限。以下是该项目的描述。
我正在开展的项目主要围绕通过最佳定价策略和税收政策来提高全球南方咖啡农的收入。它涉及三个群体：消费者、咖啡公司和政府，每个群体都关注不同的目标，例如最大化效用、利润和社会福利。这些团队正在分析优质和非优质咖啡的消费者行为和定价决策，并在 13 个时间段内跟踪了 6 个家庭。
关键假设包括：

家庭可以购买优质或非优质咖啡，但不能同时购买两者。
咖啡需求在价格限制内缺乏弹性，家庭行为理性。
公司对风险中性，咖啡的边际效用会随着时间的推移而减少。

最佳价格点和税率是通过平衡消费者的支付意愿和公司的收入门槛来确定的。优质价格 45 和非优质价格 35.5 产生了最高的总收入 546.01，公司的最低门槛为 461.01。政府的税率定为 16%，计算方法为最高收入与公司最低门槛之间的差额除以最高收入。
我还可以提供更详细的文档和/或包含数据和所有计算的 Excel 文件。遗憾的是，我无法在此处附加文档。]]></description>
      <guid>https://stats.stackexchange.com/questions/656005/robustness-measure-applied-to-real-world-problem</guid>
      <pubDate>Sat, 19 Oct 2024 14:57:44 GMT</pubDate>
    </item>
    <item>
      <title>SEM 中的二阶潜变量</title>
      <link>https://stats.stackexchange.com/questions/656004/second-order-latent-variable-in-sem</link>
      <description><![CDATA[我计划使用 SEM 研究教学质量对幸福感的影响。幸福感被概念化为由五个维度组成，也可以计算一般因素。我的假设既涉及特定维度，也涉及一般因素。
验证性因子分析 (CFA) 表明，五因子模型和具有正交一阶因子的二阶因子模型都很好地拟合了数据。进行两次单独的 SEM 分析是否合适：一次以五因子模型为结果，另一次以二阶模型为结果？这种方法使我能够测试与特定因素和一般因素相关的假设。
由于我对 SEM 还比较陌生，因此非常感谢您对我的研究设计的反馈。]]></description>
      <guid>https://stats.stackexchange.com/questions/656004/second-order-latent-variable-in-sem</guid>
      <pubDate>Sat, 19 Oct 2024 14:32:52 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中 95% 的能量减少如何影响准确性和效率？</title>
      <link>https://stats.stackexchange.com/questions/656003/how-does-a-95-energy-reduction-in-neural-networks-affect-accuracy-and-efficienc</link>
      <description><![CDATA[本月初，arXiv 上发表了一篇引人入胜的论文：
“加法是节能语言模型所需的全部”
作者提出了一种算法，$\mathcal{L}\text{-Mul}$，该算法声称可将元素浮点 (FP) 张量乘法的能耗降低高达 95%，点积的能耗降低 80%。关键创新是使用整数加法近似 FP 乘法，有可能保持几乎相同的模型精度，同时大幅提高效率
从表面上看，这似乎是一个突破性的发现。
传统上，FP 算法涉及将两个浮点数的尾数相乘，其复杂度为二次（$O(m^2)$，其中 $m$ 是尾数中的位数）。这通常是一个计算瓶颈。 $\mathcal{L}\text{-Mul}$ 使用加法的线性组合来近似这个尾数乘法，将复杂度降低到 $O(m)$，从而优化了时间效率和功耗。
阅读本文时，我发现了一些问题：

精度比较仅针对 fp8 格式，但节能效果与 fp16 和 fp32 等较大格式进行了比较，这似乎不一致。需要澄清的是，fp8（8 位浮点）、fp16（16 位浮点）和 fp32（32 位浮点）代表浮点格式中不同级别的数值精度，其中 fp8 提供的精度最低，而 fp32 提供的精度最高。位大小越低（例如 fp8），用于存储数字的位就越少，这可以减少内存和计算需求，但代价是精度。将 $\mathcal{L}\text{-Mul}$ 的节能效果与 fp16 和 fp32（本质上使用更多位和功率）进行比较，可能会对能效产生不公平的乐观看法，因为该算法以较低的精度运行。理想情况下，应在一致的水平上比较精度和能量，以避免得出误导性结论。

该论文缺乏大规模测试或实际部署，因此大多数声明都只是理论上的。

有许多拼写和语法错误，有损专业语气，给人一种仓促发布的印象。我知道作者可能不是英语母语人士，但即使粗略校对也能发现大部分错误。

这篇论文包含相当多的拼写和语法错误，这降低了其可读性和专业性。它给人一种仓促完成的印象，这对于旨在引入重大突破的技术预印本来说是不寻常的。仔细校对会加强这篇论文。

实验似乎缺乏大规模测试或实际部署结果。鉴于降低能耗的雄心勃勃的主张，大规模的实际评估将为该方法提供可信度。目前的评估仅限于基准测试，而不是功耗更为关键的大型部署设置。

该方法在硬件效率方面仍处于理论阶段。虽然它在软件模拟中显示出前景，但需要硬件级实现来确认节能效果。如果没有这一点，节能声明可能无法完全转化为实践。


我还认为两位作者都在一家公司工作，而不是在大学工作，这很有趣：BitEnergy AI：https://bitenergy.ai/
好的，最后：
神经网络中 95% 的能量减少如何影响准确性和效率？]]></description>
      <guid>https://stats.stackexchange.com/questions/656003/how-does-a-95-energy-reduction-in-neural-networks-affect-accuracy-and-efficienc</guid>
      <pubDate>Sat, 19 Oct 2024 13:48:05 GMT</pubDate>
    </item>
    <item>
      <title>针对元分析，应选择哪个估计量^REML 还是使用 Wild Bootstrap 的 CR2？</title>
      <link>https://stats.stackexchange.com/questions/656000/which-estimator-to-choose-for-meta-analysis-reml-or-cr2-with-wild-bootstrap</link>
      <description><![CDATA[我正在关注以下书籍：https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/multilevel-ma.html
我无法选择要使用哪个估计器：REML 还是带有 Wild Bootstrap 的 CR2。
或者也许同时运行它们并呈现为敏感性分析，尽管我看不到任何其他元分析这样做，所以也许这会进一步使文章的读者感到困惑。
一些细节：
我的样本量很小（两者都可以帮助）
和依赖效应大小（CR2 最适合它）
我的结果是一个连续变量（REML 似乎更适合）
如果您有类似的问题，您能否建议您做了什么？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656000/which-estimator-to-choose-for-meta-analysis-reml-or-cr2-with-wild-bootstrap</guid>
      <pubDate>Sat, 19 Oct 2024 12:01:22 GMT</pubDate>
    </item>
    <item>
      <title>是否可以将其作为时间序列数据分析？我应该使用什么模型来处理这些数据？</title>
      <link>https://stats.stackexchange.com/questions/655999/is-it-possible-to-analyse-this-as-time-series-data-what-model-should-i-use-for</link>
      <description><![CDATA[我有一个从 1 到 10 的变量，其中 1 表示“永远无法证明”，而 10 表示“始终可以证明”。答案在极端值和中间值（1、10、5、6）处密度较高。此项目还有一个“不想回答”选项。这个问题是在 5 轮研究中从不同人（但在同一个国家）收集的。
我想使用其他 5 个分类和数值变量来预测此变量的响应。问题是，我不知道是否可以使用线性回归、逻辑回归，或者我是否需要切换到机器学习模型。无论如何，如果我可以将它们作为时间数据进行陈述，那将是理想的，但我认为 5 个数据集合少于任何模型所需的数量。
所以我的问题是：

是否可以仅使用 5 个数据集合来对此数据进行陈述？
如果我的 10 分项目作为因变量，我应该使用什么模型？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655999/is-it-possible-to-analyse-this-as-time-series-data-what-model-should-i-use-for</guid>
      <pubDate>Sat, 19 Oct 2024 11:36:18 GMT</pubDate>
    </item>
    <item>
      <title>后验预测 p 值和模型复杂性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655998/posterior-predtive-p-values-and-model-complexity</link>
      <description><![CDATA[我正在执行贝叶斯后验预测检验，我发现更复杂模型（所有随机效应）的后验预测 p 值比更简单模型（所有固定效应或混合效应）的后验预测 p 值更远离（且低于）0.5。这可能吗？显然，一切都是正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655998/posterior-predtive-p-values-and-model-complexity</guid>
      <pubDate>Sat, 19 Oct 2024 08:53:54 GMT</pubDate>
    </item>
    <item>
      <title>令人困惑的逻辑回归模型输出</title>
      <link>https://stats.stackexchange.com/questions/655994/confusing-logistic-regression-model-output</link>
      <description><![CDATA[我正在使用加权逻辑回归模型分析来自样本量大（&gt;88,000）的国家数据集的数据，以预测基于各种组成员身份的结果的概率。我想将每个组成员身份与不属于该组的成员进行比较，而不是与定义的参考组进行比较（例如，添加所有虚拟编码变量，而不是忽略参考变量）。对于我研究的大多数健康结果，这种方法效果很好，但其中一个结果返回的结果是，属于每个详尽且互斥的组的成员的 OR 为 &gt;1，CI 不超过零。我的解释是，与不属于该组的成员相比，每个组的几率都更高……这在逻辑上说不通。
我正在使用 SAS 9.4 surveylogistic 程序，并指定 NOMCAR 来解释缺失数据。域、权重、层、集群和模型都经过了三重准确性检查，看起来不错。所有单元格大小均大于 10。模型收敛且无错误。当我看到加权分析的结果时，所有输出看起来都很合理，并且相对接近我作为诊断的一部分运行的未加权分析的结果，尽管其中一个组在未加权分析中并不显著（未加权 OR 1.06；加权 OR 1.80，CI 1.11-2.9）
我试图确定问题是否在于在没有指定参考组的情况下进行比较（如果是这样，我预计会出现脊状误差，但没有发生）或者模型中的权重是否能够以某种方式将事物转移到这个奇怪的结果。或者相反，如果我的解释有问题，而输出没问题。任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655994/confusing-logistic-regression-model-output</guid>
      <pubDate>Sat, 19 Oct 2024 03:13:18 GMT</pubDate>
    </item>
    <item>
      <title>使用列范数限制精度矩阵的谱范数</title>
      <link>https://stats.stackexchange.com/questions/655993/bound-the-spectral-norm-of-the-precision-matrix-using-column-wise-norm</link>
      <description><![CDATA[在本文中，作者获得了关于谱范数的精度矩阵的收敛速度，（定理 1，第 7 页）
$$
\|\hat{\Omega}-\Omega\|_2 \le CM_p s_p\sqrt{\frac{\log p}{n}}
$$
其中$\|\Omega\|_{L1}=\underset{1\le j\le p}{\max}\sum_{i=1}^{p}|\omega_{ij}|\le M_p$ 和 $\underset{1\le j\le p}{\max}\sum_{i=1}^{p}1\left(\omega_{ij}\neq 0\right)\le s_p$.
他们通过控制精度矩阵的列来证明这个定理（第 37 页，不等式 (9)）：
$$
|\hat{\beta}_{S_i}-\omega_{S_i}|\le C\sqrt{\frac{\log p}{n}}
$$
其中 $\hat{\beta}_i$ 是 $\hat{\Omega}$ 的第 i 列。
我们如何使用逐列边界来控制收敛速度？非常感谢！

本文中的定理2给出了矩阵无穷范数的收敛速度，$|A|_{\infty}=\underset{1\le i\le p,1\le j\le p}{\sum}|a_{ij}|$，他们说
$$
|\hat{\Omega}-\Omega|_{\infty}\le CM_p\sqrt{\frac{\log p}{n}}.
$$
我们可以使用以下事实得到定理1中指定的结果：$\|A\|_2\le\|A\|_{L_1}\le s_p|A|_{\infty}$。也就是说，我们得到了结果
$$
\|\hat{\Omega}-\Omega\|_2\le CM_p s_p\sqrt{\frac{\log p}{n}}.
$$
但是，我仍然不知道如何按照本文所述方法得到谱范数的收敛速度。这可能是笔误。]]></description>
      <guid>https://stats.stackexchange.com/questions/655993/bound-the-spectral-norm-of-the-precision-matrix-using-column-wise-norm</guid>
      <pubDate>Sat, 19 Oct 2024 02:44:14 GMT</pubDate>
    </item>
    <item>
      <title>两个随机变量之间差异的概率区间</title>
      <link>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</link>
      <description><![CDATA[假设 X1 和 X2 是两个随机变量，其中 X1 有 95% 的概率位于区间 [L1, R1] 内，X2 有 95% 的概率位于区间 [L2, R2] 内。这是否意味着差值 X1 - X2 有超过 95% 的概率位于区间 [L1 - R2, R1 - L2] 内？此外，X1 和 X2 可以是相关的，也可以是独立的。
(1) 有人可以澄清概率界限是否适用于这种情况吗？或者这个说法的反例。
(2) 如果有反例，是否有其他条件可以添加以使其成立？]]></description>
      <guid>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</guid>
      <pubDate>Fri, 18 Oct 2024 19:35:37 GMT</pubDate>
    </item>
    <item>
      <title>调整因变量的个别值</title>
      <link>https://stats.stackexchange.com/questions/655970/adjusting-individual-values-of-a-dependent-variable</link>
      <description><![CDATA[我有一个数据集，其中包含 600 个脉搏波速度读数，我需要根据每个参与者的平均动脉血压进行调整。我可以得到这样的结果：
m &lt;- lm(pulse_wave_velocity ~ mean_arterial_bp, data = df)

那么我是否可以使用模型中的残差来计算调整后的脉搏波速度，如果是，是否应该将它们添加到截距中？]]></description>
      <guid>https://stats.stackexchange.com/questions/655970/adjusting-individual-values-of-a-dependent-variable</guid>
      <pubDate>Fri, 18 Oct 2024 14:57:17 GMT</pubDate>
    </item>
    <item>
      <title>负二项回归与普通逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/655965/negative-binominal-regression-vs-ordinary-logistic-regression</link>
      <description><![CDATA[我有选举期间的社交媒体数据，其中包含数千名政治人物在社交媒体上的帖子。数据集有许多控制变量，例如日期、关注者数量、视觉效果的存在、是否是热门演员的转发等。
这项研究本质上是关于语言学的。我的目标是测试隐喻相关指标是否与高参与度（喜欢、分享、评论）相关。由于它是社交媒体数据，因此存在高度过度分散。我确认负二项回归是最佳选择。
在用喜欢计数拟合模型后，我注意到该模型在处理参与度非常高或参与度非常低的帖子时遇到了困难。它似乎也有显著的异常值。




考虑到这是高度密集时期的社交媒体数据，我对模型在某些帖子上遇到困难并不感到惊讶。大多数被低估的帖子都包括特殊/耸人听闻的视觉效果、视频或公告，这些都使它们非常高。
由于它们不是虚假数据并且是社交媒体固有的，所以我没有删除它们。主要目标不是建立一个预测参与度的模型，而是看看隐喻指标是否与参与度呈正相关。
我想知道这是否是正常的，因为数据的性质。此外，NBR 是否对我来说是正确的测试，或者我是否应该在根据百分位数将参与度数据分解为高、中、低参与度后考虑 OLR。]]></description>
      <guid>https://stats.stackexchange.com/questions/655965/negative-binominal-regression-vs-ordinary-logistic-regression</guid>
      <pubDate>Fri, 18 Oct 2024 14:02:35 GMT</pubDate>
    </item>
    <item>
      <title>疾病建模与微生物组建模：结果应该是哪一个？</title>
      <link>https://stats.stackexchange.com/questions/655941/modeling-disease-vs-microbiome-which-should-be-the-outcome</link>
      <description><![CDATA[我有一个与微生物组研究相关的问题，在这个领域，许多研究人员评估疾病组和对照组之间的分类单元丰度是否不同。我经常看到统计模型，其中分类单元作为结果变量，疾病状态作为解释变量。但是，我想知道这种模型是否更适合评估疾病是否影响微生物组，而不是相反。大多数研究人员的目标是找到微生物组影响疾病的证据。鉴于此，该模型是否不合适，使用分类单元作为解释变量，疾病状态作为结果的模型是否更合适？当使用仅包含数值变量且不涉及协变量的线性模型时，等式中的位置（无论是在左侧还是右侧）可能不太重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/655941/modeling-disease-vs-microbiome-which-should-be-the-outcome</guid>
      <pubDate>Fri, 18 Oct 2024 01:10:05 GMT</pubDate>
    </item>
    <item>
      <title>回归模型中每个变量都需要具有统计显著性吗？</title>
      <link>https://stats.stackexchange.com/questions/655938/does-every-variable-need-to-be-statistically-significant-in-a-regression-model</link>
      <description><![CDATA[我最近拟合了一个回归模型 (ARIMAX)，其中有些变量 (3) 具有统计显著性，有些则不显著 (1)。我删除了统计上不显著的变量并重新拟合模型，现在所有变量都具有统计显著性（即新模型有 3 个变量，旧模型有 4 个变量）。
但是，这个新模型（所有变量都具有统计显著性）的表现比旧模型（并非所有变量都具有统计显著性）更差。也就是说，新模型的预测误差比旧模型更严重。
这是统计学中的常见做法吗？如果所有变量都具有统计显著性，选择性能较差的模型是否更可取，还是最好选择性能较好的模型，即使并非所有变量都具有统计显著性。
我知道过度拟合和交叉验证等概念。我使用除过去 6 个月数据之外的所有可用数据训练了这两个模型。我还让这两个模型预测过去 6 个月的可用数据，并将预测值与实际值进行比较。使用旧模型（即并非所有变量都具有统计显著性的模型）我仍然获得了更好的结果。
即使并非所有变量都具有统计显著性，是否可以采用性能更好的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/655938/does-every-variable-need-to-be-statistically-significant-in-a-regression-model</guid>
      <pubDate>Fri, 18 Oct 2024 01:02:57 GMT</pubDate>
    </item>
    <item>
      <title>计数值的统计检验</title>
      <link>https://stats.stackexchange.com/questions/655928/statistical-test-for-count-values</link>
      <description><![CDATA[我有 4 个故事，每个故事都有字数和复数词的数量：



故事
单词数
复数




1
356
45


2
273
23


3
303
28


4
289
42



我想知道是否可以进行统计测试以确定这些故事在字数方面是否存在显着差异，然后再进行另一项测试以确定这些故事在复数数量方面是否存在显着差异。
测试的目的是确保这些故事在阅读难度方面没有显着差异。这是一项心理学研究，我们需要确保故事难度中没有混淆。我们正在测试其他更相关的单词特征，但这些是连续值，我们可以对其进行其他测试。
我没有人口频率可以与之比较，以便使用 Fisher 精确检验，我认为我不能使用卡方检验，因为那里的计数似乎应该是相关的，例如测试一群人是否喜欢苹果、橘子或香蕉，而一个人不能选择两个选项，我有点困惑，不知道我可以在这里使用什么测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/655928/statistical-test-for-count-values</guid>
      <pubDate>Thu, 17 Oct 2024 19:33:29 GMT</pubDate>
    </item>
    <item>
      <title>为什么$\text{rank}(L)=\dim(Z_{h})$？</title>
      <link>https://stats.stackexchange.com/questions/655853/why-textrankl-dimz-h</link>
      <description><![CDATA[高斯隐变量图模型
假设我们有高斯分布的观测变量$Z_o$和隐变量$Z_h$。与这些变量相关的联合精度矩阵$K_{(o,h)}$由以下公式给出：
$$
K_{(o,h)} = \begin{bmatrix} K_o &amp; K_{o,h} \\ K_{h,o} &amp; K_h \end{bmatrix}。
$$
根据 Schur 补函数，$Z_o$ 的边缘化精度矩阵 $\tilde{K}_o$ 可以写成：
$$
\tilde{K}_o = K_o - K_{o,h} K_h^{-1} K_{h,o} = K_o - L,
$$
其乘积矩阵 $L = K_{o,h} K_h^{-1} K_{h,o}$。这两个组件具有特定的属性：$K_o$ 是 $Z_o$ 的稀疏条件精度矩阵，以 $Z_h$ 为条件；乘积矩阵 $L$ 总结了边缘化对隐藏变量的影响。该矩阵的秩（等于隐藏变量 $Z_h$ 的数量）较低，因为隐藏变量的数量应该很少。
给定 $Z_o$ 的 i.i.d. 样本，我们的目标是估计 $K_o$ 和 $L$；我们特别感兴趣的是${\color{red}{\text{}L}}$的秩，因为${\color{red}{\text{它等于隐藏变量的数量 } Z_h}}$。这些矩阵可以通过求解凸松弛来恢复：
$$
(\hat{K}_o, \hat{L}) = \underset{K_o, L}{\text{argmin}} \, \text{trace}((K_o - L)\Sigma_o) - \log \det(K_o - L) + \lambda(\gamma \|K_o\|_1 + \text{trace}(L)),
$$
其中$\hat{K}_o$ 和 $\hat{L}$ 分别是 $K_o$ 和 $L$ 的估计值，$\Sigma_o$ 是 $Z_o$ 的经验边际协方差。

根据矩阵基本理论，$L$ 的秩应该小于或等于 $\dim(Z_h)$，即隐变量的数量。我很难理解为什么许多参考文献直接将$L$的秩与$\dim(Z_h)$等同起来。这种方法的理论依据和实际意义是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655853/why-textrankl-dimz-h</guid>
      <pubDate>Wed, 16 Oct 2024 10:55:39 GMT</pubDate>
    </item>
    </channel>
</rss>