<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 07 Oct 2024 01:17:37 GMT</lastBuildDate>
    <item>
      <title>迭代加权最小二乘法 (IRLS) 和高斯-牛顿法</title>
      <link>https://stats.stackexchange.com/questions/655412/iteratively-reweighted-least-squares-irls-and-gauss-newton</link>
      <description><![CDATA[我正在研究非线性回归优化方法。我想证明高斯-牛顿法可以看作是一种 IRLS。我们想要最大化
$$
- \sum_{i = 1}^{n} (y_i - h(\mathbf{x}_i^T \mathbf{\beta}))^2 
$$
近似$h(\mathbf{x}_i^T \mathbf{\beta})$我们有
$$
- \sum_{i = 1}^{n} [y_i - h(\mathbf{x}_i^T \mathbf{\beta}^{(t)}) - h&#39;(\mathbf{x}_i^T \mathbf{\beta}) \mathbf{x}_i^T (\mathbf{\beta} - \mathbf{\beta}^{(t)}) ]^2 
$$
我不知道该怎么做。我读过的书没有告诉你当你有任何函数$h$时该怎么做，也没有直接解释高斯-牛顿法。任何帮助或建议我都会很感激。我也在寻找这方面的参考资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/655412/iteratively-reweighted-least-squares-irls-and-gauss-newton</guid>
      <pubDate>Mon, 07 Oct 2024 00:48:17 GMT</pubDate>
    </item>
    <item>
      <title>估计双重稳健效应估计的干扰参数时的良好做法</title>
      <link>https://stats.stackexchange.com/questions/655411/good-practice-when-estimating-nuisance-parameters-for-doubly-robust-effect-estim</link>
      <description><![CDATA[我参与了一个项目，该项目使用来自各种医疗登记的数据进行观察性研究，目的是评估治疗效果。已经决定研究将默认使用 TMLE 的特定实现，但一些最近的文献（例如，1，2) 让我不确定在对治疗和结果机制进行建模时是否具有良好做法，尤其是关于样本分割程序。
我目前的理解（大致）如下。如果我们想要安全，我们应该执行嵌套交叉验证。交叉验证的内层是为了确保干扰模型不会过度拟合。这就是我们选择尽可能接近“真相”的模型的方式。交叉验证的外层是为了估计标准误差。如果我们对干扰模型使用非常灵活的（例如基于树的）估计量，除非我们执行目标步骤并估计保留数据中的标准误差，否则我们不能期望有效的推断。从技术上讲，如果我们只有一个干扰参数估计量，我们可以省略交叉验证的内层（用于模型比较）。假设我们有一个我们喜欢的梯度提升树的精确配置；我们可以将其应用于许多训练折叠并使用相应的测试折叠进行方差估计。如果我们将估计量限制为 Donsker 类中的估计量（例如 GLM 或 MARS），我们也可以省略交叉验证的外层（用于方差估计）。因此，如果我们使用一些预先指定的 GLM，则不需要交叉验证。如果我们想比较不同的 GLM 规范，我们可以通过 CV 比较它们（选择最接近事实的规范），但仍然不需要使用保留数据进行方差估计。
这听起来合理吗？我注意到的一件事是 Zivich &amp; 推荐的交叉拟合程序Breskin (2) 还在单独的数据中估计治疗模型和结果模型（本质上增加了另一个必要的数据分割），这是我以前从未见过的程序。是否也建议这样做？
参考文献：
(1) Benkeser, D., Carone, M., Laan, M. V. D., &amp; Gilbert, P. B. (2017). 平均治疗效果的双重稳健非参数推断。Biometrika, 104(4), 863-880.
(2) Zivich, P. N., &amp; Breskin, A. (2021). 因果推断的机器学习：关于使用交叉拟合估计量。流行病学，32(3), 393-401.]]></description>
      <guid>https://stats.stackexchange.com/questions/655411/good-practice-when-estimating-nuisance-parameters-for-doubly-robust-effect-estim</guid>
      <pubDate>Mon, 07 Oct 2024 00:38:18 GMT</pubDate>
    </item>
    <item>
      <title>如何建立多项式多层模型</title>
      <link>https://stats.stackexchange.com/questions/655410/how-to-set-up-a-polynomial-multilevel-model</link>
      <description><![CDATA[我有一个建模情况，但我不能 100% 确定如何处理。我有两个独立变量，信息和时间，时间是重复测量。因变量是差异。当分析跨时间差异的汇总度量时，正如理论所表明的那样，信息和差异之间存在二次关系。信息将差异增加到峰值，超过峰值后，信息越多，差异越小。我想建立一个模型来整合时间，这样我就不必缩减到汇总度量。理论和以前的数据表明时间和差异之间存在线性关系。我应该如何建模？目前，我的完整理论驱动模型如下：
full_model_ml&lt;-lmerTest::lmer(difference ~ I((time - 54)/10)*(cinformation + cinformation2) + 
(I((time - 54)/10) | id), 
data = df,
REML = FALSE,
control = lme4::lmerControl(optimizer =&quot;Nelder_Mead&quot;)).

但考虑到信息和差异之间的预期多项式关系以及时间和差异之间的线性关系，我不确定这是否是正确的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/655410/how-to-set-up-a-polynomial-multilevel-model</guid>
      <pubDate>Mon, 07 Oct 2024 00:29:24 GMT</pubDate>
    </item>
    <item>
      <title>如何衡量训练图像质量下降导致的对象检测算法性能下降？</title>
      <link>https://stats.stackexchange.com/questions/655405/how-does-one-measure-the-fall-in-performance-of-object-detection-algorithms-with</link>
      <description><![CDATA[我正在进行一个项目，该项目涉及研究不同类型的训练图像对对象检测算法的影响。我们（团队）应该在每次数据集发生变化时测量对象检测模型的性能差异，尤其是当图像质量受到质疑时。
我们应该提出一个指标，让我们能够衡量这种性能变化。我被告知平均精度（mAP）和 IoU 可能不是进行推理的最佳方式，而是选择对对象检测本身至关重要的其他方法。如果您能提出一些建议，那就太好了。我开始研究对象检测中的过度拟合以获得一些见解。我一无所获。]]></description>
      <guid>https://stats.stackexchange.com/questions/655405/how-does-one-measure-the-fall-in-performance-of-object-detection-algorithms-with</guid>
      <pubDate>Sun, 06 Oct 2024 19:16:02 GMT</pubDate>
    </item>
    <item>
      <title>与治疗变量不独立的变量是否可以有效地用于治疗变量的协变量调整估计？</title>
      <link>https://stats.stackexchange.com/questions/655404/can-variables-not-independent-of-the-treatment-variable-be-profitably-used-for-c</link>
      <description><![CDATA[我的目标是最小化 T（治疗变量）对 Y 的影响估计的偏差/方差。假设我有一个协变量 (X)，它对 Y 具有极强的预测性。在 𝑋 ⊥ T 的理想情况下，我可以实现模型 $Y \sim \alpha + \beta_TT + \beta_XX$（左）并实现 $\beta_T$ 标准误差的大幅降低。
不幸的是，我无法假设 𝑋 ⊥ T，所以我处于右边的场景中。我试图确认是否有任何方法可以将 X 有效地纳入模型规范中，以减少相对于治疗效果估计的偏差/方差。我理解，如果 X 和 T 是相关的，X 所传达的有用信息量将小于 𝑋 ⊥ T 为真时。但是，我听说如果 X 和 T 是相关的，那么将 X 纳入模型实际上没有任何好处（假设我们唯一感兴趣的系数估计是 $\beta_T$）。
这是真的吗 - 除了 𝑋 ⊥ T 之外，X 对我们理解 $T \rightarrow Y$ 毫无用处？如果是这样，为什么？感谢您的澄清！
]]></description>
      <guid>https://stats.stackexchange.com/questions/655404/can-variables-not-independent-of-the-treatment-variable-be-profitably-used-for-c</guid>
      <pubDate>Sun, 06 Oct 2024 18:41:13 GMT</pubDate>
    </item>
    <item>
      <title>GLM 输出中缺少分类变量的级别（不是参考级别）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655402/level-not-reference-level-of-categorical-variable-missing-in-glm-output</link>
      <description><![CDATA[我正在使用 R 构建一些临床模型。我的一个协变量是“parity.factor”。它是一个具有 3 个级别 (0,1,2) 的因子，代表参与者生育的次数。
当我使用以下代码时，输​​出不包含 parity.factor1：
glm(formula = htn ~ obese + Age + alcohol_in_pregnancy + mat_FH_diabetes + 
mat_FH_HTN + parity.factor + mat_hist_HDP, family = &quot;binomial&quot;, 
data = uganda)

系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -3.24049 0.67419 -4.807 1.54e-06 ***
肥胖1 0.15619 0.23559 0.663 0.507340 
年龄 0.06354 0.02506 2.535 0.011242 * 
妊娠期饮酒2 0.89783 0.47249 1.900 0.057405 . 
mat_FH_diabetes2 0.15590 0.30223 0.516 0.605969 
mat_FH_HTN2 0.21760 0.25195 0.864 0.387769 
parity.factor2 0.06876 0.30141 0.228 0.819551 
mat_hist_HDP2 1.25120 0.34281 3.650 0.000262 ***

parity.factor 肯定被编码为具有三个级别的因子。我已经重新编码以使用不同的级别作为参考级别，但它只会在输出中返回一个级别的 logit。因子的所有级别都有很多数据点。
VIF 并不表明存在显著的多重共线性。当我在因子虚拟变量上使用 cor 时，我得到了以下输出，这表明共线性不应该是变量中的问题。
&gt; design_matrix &lt;- model.matrix(~ parity.factor, data = uganda)
&gt; cor(design_matrix)
(截距) parity.factor0 parity.factor2
(截距) 1 NA NA
parity.factor0 NA 1.0000000 -0.6490515
parity.factor2 NA -0.6490515 1.0000000
警告消息：
在 cor(design_matrix) 中：标准偏差为零
---

我还能做些什么来尝试调查为什么我的变量级别没有显示在输出中？]]></description>
      <guid>https://stats.stackexchange.com/questions/655402/level-not-reference-level-of-categorical-variable-missing-in-glm-output</guid>
      <pubDate>Sun, 06 Oct 2024 15:34:24 GMT</pubDate>
    </item>
    <item>
      <title>Brunner-Munzel 检验的问题 - 只有排名才重要</title>
      <link>https://stats.stackexchange.com/questions/655333/issue-with-brunner-munzel-test-only-the-rankings-matter</link>
      <description><![CDATA[当使用非参数 Brunner-Munzel 检验在两个总体之间进行测试时，我注意到检验统计量
$BM = \frac{\bar{R}_2-\bar{R}_1}{Ns}$
其中 $\bar{R}_i$ 是汇总排名 $R_{ij}$ 的平均值，$N$ 是总体规模 $n_1$ 和 $n_2$ 的总和，并且 $s = \sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}$ 其中 $s_i^2$ 是展示位置 $P_{ij}$ 的样本方差，其中 $P_{ij}=\frac{R_{ij} - R_{ij}^{*}}{N - n_i}$，其中 $R_{ij}^{*}$ 是 $x_{ij}$ 在 $X_i$ 中的总体内排名。因此，如果您将 $\begin{bmatrix}1\\1\\1\\1\\1\\1 \end{bmatrix}$ 与 $\begin{bmatrix}1\\1\\1\\1\\1\\2 \end{bmatrix}$ 进行比较，则得到的检验统计量与将 $\begin{bmatrix}1\\1\\1\\1\\1\\1 \end{bmatrix}$ 与 $\begin{bmatrix}1\\1\\1\\1\\1\\1000 \end{bmatrix}$ 进行比较时得到的检验统计量完全相同。
我的问题是：

我认为第二种情况应该比第一种情况“更加不同”，我的直觉正确吗？
是否有某种替代测试、方法或手段可以纠正这种情况？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655333/issue-with-brunner-munzel-test-only-the-rankings-matter</guid>
      <pubDate>Fri, 04 Oct 2024 18:44:03 GMT</pubDate>
    </item>
    <item>
      <title>当两个多因素变量中的一些因素呈负相关时，如何评估它们之间相关性的绝对强度</title>
      <link>https://stats.stackexchange.com/questions/655291/how-to-assess-the-absolute-strength-of-a-correlation-between-two-multifactorial</link>
      <description><![CDATA[我有两个多因子构造，其中一个由 5 个子因子组成，另一个由 4 个子因子组成。我希望评估这两个构造之间的关联的“绝对”强度。
问题是，当以标准方式（CFA）构建模型时，子因子之间的正向和负向相互关系似乎将构造在全局层面上的关系平均为零。但是，在因子层面上存在显着的关系！
construct1 =~ subfactor1a + subfactor1b + subfactor1c + subfactor1d + subfactor1e
construct2 =~ subfactor2a + subfactor2b + subfactor2c + subfactor2d
construct1 ~~ constrain2




CorrTable
1a
1b
1c
1d
2a
2b
2c
2d
2e




1a
1










1b
.50
1
&lt; /td&gt;








1c
.45
.50
1




&lt; /td&gt;



1d
.60
.50
.45
1








1e
.55
.45
.45
.55
1






2a
-.10
-.20
-.15
-.09
-.11
1





2b
-.20
-.05
-.10
-.10
-.01
.57
1&lt; /td&gt;




2c
-.05
-.02
-.09
-.01
-.05
.65
.55
1



2d
.05
.01
.05
.05
.03
.55
.55
.55
1



评估两个变量之间关系的“绝对”强度的最佳方法是什么，同时避免将整体查看时的影响平均为零？
我曾尝试对第二个构造的前三个子因素进行反向评分，但这并没有改变两个构造之间的关联强度。
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/655291/how-to-assess-the-absolute-strength-of-a-correlation-between-two-multifactorial</guid>
      <pubDate>Thu, 03 Oct 2024 20:38:01 GMT</pubDate>
    </item>
    <item>
      <title>使用不相关特征进行 OLS 高估</title>
      <link>https://stats.stackexchange.com/questions/654617/overestimation-in-ols-using-uncorrelated-features</link>
      <description><![CDATA[我正在使用 OLS 构建最佳线性模型来解释（预测）$Y$的方差，使用两个特征 $X_1$ 和 $X_2$，并考虑以下两个因素：

$X_1$ 和 $X_2$ 不表现出多重共线性，即 $\rho(X_1, X_2) \approx 0 $
$X_1$ 和 $X_2$ 均解释方差的重叠部分在$Y$中，即
$\beta_1 X_1 + \beta_2 X_2$高估了$Y$ 
其中，$\beta_1$和$\beta_2$是两个独立线性回归的结果：$Y = \beta_1 X_1 + \epsilon$和$Y = \beta_2 X_2 + \epsilon$

最好的技术是什么用什么术语来解释#2 中的上述场景？以下是否是解决这种情况的最佳方法：
步骤 1：使用 OLS 估算 $\beta_1$ $Y = \beta_1 X_1 + \epsilon$ 
步骤 2：将误差估算为 $\hat{Y_1} = Y - \beta_1 X_1$ 
步骤 3：使用 OLS 估算 $\hat{Y_1} = \beta_2 X_2 + \epsilon$ 
考虑将其推广到 $n$ 特征 $X_1, X_2, ..., X_n$
背景：
人们可以认为 $X_2$ 是 $X_1$ 的一些非线性变换，几乎没有其他信息内容可以解释 $Y$]]></description>
      <guid>https://stats.stackexchange.com/questions/654617/overestimation-in-ols-using-uncorrelated-features</guid>
      <pubDate>Thu, 19 Sep 2024 20:57:32 GMT</pubDate>
    </item>
    <item>
      <title>样本均值还是 James-Stein 估计量？</title>
      <link>https://stats.stackexchange.com/questions/654558/sample-mean-or-james-stein-estimator</link>
      <description><![CDATA[我有一个简单的实际问题，我将其发布在 Quant Finance SE 中（也发布在这里，因为我没有得到答案）。
假设我们有 $n\geq3$ 个股票金融时间序列（相关或不相关）（例如，$n$ 只股票的 10 个不同收益时间序列，每个序列都有 $T$ 个观测值）。目标是估计每个金融时间序列的平均值，即$\hat{\mu}_{i}$，$i=1,2,...n$。
显然，最直接的方法是计算每个系列的样本平均值，即$\hat{\mu}_{i}=\frac{x_1+x_2+...x_T}{T}$，其中$i=1,2,...n$。然而，James-Stein 估计量表明，如果 $n\geq3$，那么最好将所有这些 $n$ 金融时间序列汇集在一起​​，然后集体估计均值向量。
您会使用哪种方法，为什么？据我所知，对于这样一个简单的问题，所有从业者都使用第一种方法（样本均值），我不知道有谁应用了第二种方法。因此，这是否意味着这是由于 James-Stein 更像是一个理论结果，并且几乎不适用或不太受欢迎？如果不是，那么为什么不使用 James-Stein 呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/654558/sample-mean-or-james-stein-estimator</guid>
      <pubDate>Wed, 18 Sep 2024 16:40:58 GMT</pubDate>
    </item>
    <item>
      <title>如何在以下问题中微调集成级超参数？</title>
      <link>https://stats.stackexchange.com/questions/654550/how-to-fine-tune-an-ensemble-level-hyper-parameter-in-the-following-problem</link>
      <description><![CDATA[我有一个相对较小的数据集，包含 4000 个实例。我打算使用集成方法进行分类。我的集成由 5 个不同的分类器组成，并且我有一个集成级超参数 S。
我计划按照以下步骤训练和评估我的集成模型：

将初始数据集分为 70% 训练、15% 验证和 15% 测试。
使用 5 倍交叉验证在训练数据集上训练每个分类器（在每种情况下，在 4 个折叠上进行训练并评估 1 个保留折叠的准确性）。
根据每个分类器在所有 5 个保留折叠（即整个训练数据集）中的平均准确性，确定每个分类器的权重。在权重计算公式中有一个集成级超参数S，初始化为[0,1]内的随机值。
为了微调S，使用上一步计算出的分类器权重，评估集成模型在验证数据集上的性能。更改S的值，根据新的S值重新计算分类器权重，并重新评估集成模型在验证数据集上的性能，并重复，直到集成性能最大化或达到特定的迭代次数。
在确定S的最终值和相应的分类器权重后，评估集成模型在测试数据集（未见数据）上的性能。

我担心的是，超参数S的微调是在每次迭代中使用整个验证数据集进行的。例如，将验证数据集拆分为 3 个子集（考虑到我的数据集很小），然后针对 S 的每个值评估集成在所有 3 个子集中的平均性能，这样是否更合适？或者我上面描述的初始方法是否足够（考虑到数据集的大小较小）？]]></description>
      <guid>https://stats.stackexchange.com/questions/654550/how-to-fine-tune-an-ensemble-level-hyper-parameter-in-the-following-problem</guid>
      <pubDate>Wed, 18 Sep 2024 14:19:20 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 R 中的逐次试验数据运行重复测量方差分析？</title>
      <link>https://stats.stackexchange.com/questions/654535/how-can-i-run-a-repeated-measures-anova-in-r-with-trial-by-trial-data</link>
      <description><![CDATA[我需要帮助设置数据集并在 R 中运行重复测量方差分析。我当前的数据集是 41 个受试者的试验数据。有一列表示受试者 ID（1-41），一列表示受试者所属的组（“置信度”或“定位”），一列表示相位（“前”或“后”），一列表示滞后位置（1-7），一列表示准确度（0 或 1）。每个受试者有 140 行：其中 70 行来自受试者“前”试验，70 行来自受试者“后”试验。在每组 70 行中，7 个滞后位置（1-7）各有 10 行。准确度是因变量。
我尝试过许多不同的方法，但我认为方差分析一直将数据视为每次试验都是不同的受试者。残差或 DenDF 中的 df 会返回 5166 或 5673 之类的数字，具体取决于我尝试的方法。我对 R 和运行方差分析还很陌生，正在尝试复制已经完成的分析。阶段 * 组 * 滞后的残差 df 应该是 234，而不是 5,000+]]></description>
      <guid>https://stats.stackexchange.com/questions/654535/how-can-i-run-a-repeated-measures-anova-in-r-with-trial-by-trial-data</guid>
      <pubDate>Wed, 18 Sep 2024 00:53:18 GMT</pubDate>
    </item>
    <item>
      <title>我可以同时使用 Greenhouse-Geisser 和 Huynh-Feldt 吗？</title>
      <link>https://stats.stackexchange.com/questions/654482/can-i-use-both-greenhouse-geisser-and-huynh-feldt</link>
      <description><![CDATA[基本上，我正在对以下相互作用进行重复测量方差分析：
刺激、
情绪、
时间-刺激、
时间-情绪、
刺激-情绪、
时间-刺激-情绪
违反了 Mauchly 的球形度检验，Greenhouse-Geisser ε 对某些变量 &gt; .75，对另一些变量 &lt; .75。我的样本量相当小（19），所以我更倾向于 Huynh-Feldt。我想知道，我是否可以结合使用这两种校正，还是只选择更合适的一种？]]></description>
      <guid>https://stats.stackexchange.com/questions/654482/can-i-use-both-greenhouse-geisser-and-huynh-feldt</guid>
      <pubDate>Tue, 17 Sep 2024 12:34:00 GMT</pubDate>
    </item>
    <item>
      <title>适当测试不同森林类型间微生物丰度的差异</title>
      <link>https://stats.stackexchange.com/questions/654474/appropriate-test-for-difference-in-microbial-abundance-between-forest-types</link>
      <description><![CDATA[我想测试两种森林类型在 10 厘米和 50 厘米处的微生物丰度差异（此时独立）。第一个图（10 厘米）不符合正态性，因此我使用非参数检验，另一个图（50 厘米）符合正态性，因此我使用 T 检验。这是否合适，还是无论如何都应该使用相同的测试？感谢您的任何建议。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654474/appropriate-test-for-difference-in-microbial-abundance-between-forest-types</guid>
      <pubDate>Tue, 17 Sep 2024 10:07:22 GMT</pubDate>
    </item>
    <item>
      <title>二项回归的样本大小</title>
      <link>https://stats.stackexchange.com/questions/654359/sample-size-for-binomial-regression</link>
      <description><![CDATA[***这个问题是 STAT 问题。希望它不会被从网站上删除。。
我们如何计算具有以下结构的数据集的样本量。正确的模型是离散时间比例风险，它基于具有互补对数对数链接的二项回归。以下 R 函数可用于分析这种数据结构（我们假设风险率随时间呈线性变化）
 glm(
EVENT ~ Time + TEST STATUS + AGE, 
data = A, 
family = binomial(link = &quot;logit&quot;)

在我们的研究中，受试者每三个月（最多 18 个月）访问一次中心，在以下时间检查其疾病状态：T0、T3、T6、T9、T12、T15 和 T18。主要协变量 Test Status 是二进制的（1 vs. 0）。事件是二元结果（1：健康状况下降，0：健康状况稳定）。该研究是单一事件。数据可能看起来像这样。项目的目的是测试 TEST STATUS=1 是否可以预测感兴趣的事件，即 1：健康状况下降健康。
ID 时间 年龄 事件 测试状态
1 0 45 0 0
1 3 45 1 1

2 0 46 0 0
2 3 46 0 1
2 6 46 0 0
2 9 46 1 1

3 0 34 0 0
3 3 34 0 0
3 6 34 0 1
3 9 34 0 1
3 12 34 0 0
3 15 34 0 1
3 18 34 1 0

实际上，测试状态是一个时间依赖性协变量。但为了简单起见，我们暂时只关注离散时间生存模型。如能得到关于如何计算样本量的任何帮助和建议，尤其是使用正确的函数/模拟代码，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654359/sample-size-for-binomial-regression</guid>
      <pubDate>Sat, 14 Sep 2024 10:33:04 GMT</pubDate>
    </item>
    </channel>
</rss>