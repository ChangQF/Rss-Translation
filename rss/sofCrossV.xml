<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 15 Jan 2025 12:32:22 GMT</lastBuildDate>
    <item>
      <title>RKHS 与核学习中特征空间的关系</title>
      <link>https://stats.stackexchange.com/questions/660057/relation-of-rkhs-to-feature-space-in-kernel-learning</link>
      <description><![CDATA[在标准 SVM 公式中，我们通常会寻找一个向量 $w \in \mathbb{R}^D$，该向量定义 $\mathbb{R}^D$ 中的超平面。决策函数的形式如下：
$$
f(x) = \operatorname{sign}(\langle w, x \rangle + b),
$$
其中 $\langle \cdot, \cdot \rangle$ 是 $\mathbb{R}^D$ 中的标准内积，而 $b \in \mathbb{R}$ 是偏差项。
现在，假设我们有一个 p.d 内核 $k$，我们知道有一个唯一的 RKHS $H_k$，因此我们可以寻找 $f \in H_k$ 在 $H_k$ 中定义一个超平面。相应的决策函数变为：
$$
f(x) = \operatorname{sign}(\langle f, \phi_1(x) \rangle_{H_k} + b),
$$
其中 $\phi_1(x) = k(\cdot, x) \in H_k$ 是进入 RKHS 的规范特征图。现在，例如通过铰链损失公式的软边距 svm，我们可以使用表示定理来论证 $f^*$ 位于由我们的训练模式引起的规范特征图的跨度内。
问题
现在，我的问题如下。在这个公式中，我们“看”对于 RKHS 中的超平面，但在大多数标准介绍中，人们认为我们在（可能无限的）特征空间中寻找超平面。
我知道 $k$ 会诱导另一个特征图（实际上，我认为有无数个，因为内积对正交变换不变？）$\phi_2: X \to F$ 进入某个希尔伯特空间 $F$，满足：
$$
\langle \phi(x)_2, \phi(y)_2 \rangle_{F} = k(x, y)。
$$
因此，我们有两个特征图：
$$
\phi_{1}: x \mapsto k(\cdot, x) \in H_k \quad \text{(进入 RKHS 的规范映射),}
$$
$$
\phi_{2}: x \mapsto \phi_2(x) \in F \quad \text{(进入某个希尔伯特空间 $F$ 的映射)}。
$$
我们现在是否可以争辩说，找到某个 $f^* \in H_k$ 将自动导致 $g^* \in F$，如下所示：
$$
\langle \phi(x)_2, \phi(y)_2 \rangle_{F} = \langle \phi(x)_1, \phi(y)_1 \rangle_{H_k} = k(x, y) $$
因此
$$ \langle f^*, \phi_1(y) \rangle_{H_k} = \sum_{i=1}^n \alpha_i \langle \phi_1(x_i), \phi_1(y) \rangle_{H_k} = \sum_{i=1}^n \alpha_i \langle \phi_2(x_i), \phi_2(y) \rangle_{F} = \langle g^*, \phi_2(y) \rangle_{F}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660057/relation-of-rkhs-to-feature-space-in-kernel-learning</guid>
      <pubDate>Wed, 15 Jan 2025 12:18:36 GMT</pubDate>
    </item>
    <item>
      <title>了解电力市场的样条函数和预测</title>
      <link>https://stats.stackexchange.com/questions/660055/understanding-splines-and-forecasting-in-electricity-market</link>
      <description><![CDATA[我对样条建模还不熟悉，我正在尝试了解它在电力市场预测中的工作原理。
我正在使用意大利电力交易所管理机构 GME 的每小时数据。目标是通过重建竞争对手的供应函数来预测竞争对手的竞标行为，具体来说，就是在不同价格水平上提供的总数量，假设我是市场参与者。
提供一些背景信息：

$D$ 是电力需求
$S_{-i}(p)$ 是企业 $i$ 的竞争对手在价格 $p$ 时的总供应函数
$C_i(q)$ 是企业 $i$ 给定数量 $q$ 时的生产成本函数

利润公司 $i$ 的函数为：
$$ \pi(p) = p \cdot \left(D - S_{-i}(p)\right) - C_i\left(D - S_{-i}(p)\right) $$
根据意大利日前市场规则，生产单位可以提交最多四个价格-数量对，代表逐步供应函数。这些阶跃函数通常通过平滑技术使用连续可微函数来近似。
我的问题：使用样条函数预测残差供应函数需要遵循哪些概念步骤？此外，样条函数是直接用于预测，还是主要用于在应用预测模型之前平滑阶跃函数？
任何指导、澄清或理论概念都将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660055/understanding-splines-and-forecasting-in-electricity-market</guid>
      <pubDate>Wed, 15 Jan 2025 11:23:28 GMT</pubDate>
    </item>
    <item>
      <title>使用季节性虚拟变量来表示季节性</title>
      <link>https://stats.stackexchange.com/questions/660054/using-seasonal-dummies-for-seasonality</link>
      <description><![CDATA[我正在研究月度国内生产者价格指数系列。我需要使用季节性虚拟变量来捕捉确定性季节性。我使用了 11 个虚拟变量和趋势。
为此，我是否需要使用系列 D-PPI 的自然对数 log(DPPI)？还是我应该使用原始数据系列 DPPI？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660054/using-seasonal-dummies-for-seasonality</guid>
      <pubDate>Wed, 15 Jan 2025 11:06:09 GMT</pubDate>
    </item>
    <item>
      <title>BAM mgcv 算法的收敛性</title>
      <link>https://stats.stackexchange.com/questions/660053/convergence-of-bam-mgcv-algorithm</link>
      <description><![CDATA[在之前的文章中，我描述了 mgcv 的 BAM 算法的可重复性问题，并得到了非常有用的反馈：BAM mgcv 算法的可重复性
然而，可重复性并不是我观察到的唯一问题。在某些例子中，我还发现 bam() 无法收敛。
最小可重现示例
以下内容基于由协变量 x、y 和目标变量 z 组成的 20,000 个数据点的数据集，可在此处下载：https://drive.google.com/file/d/14ltM1Z4O9WW7h1jkrAp52v4meiauGsME/view?usp=sharing
以下代码尝试将基于 bam() 的空间平滑拟合到上述数据集：
set.seed(1) # 不确定这是否有区别，但设置种子以防万一

模型 &lt;- mgcv::bam(z ~ s(x, y, k = 500),
数据 = 数据集,
家庭 = tw(link=log),
方法 = &quot;fREML&quot;)

但返回以下警告消息：
警告消息：
在 bgam.fit(G, mf, chunk.size, gp, scale, gamma, method = method, :
算法没有收敛

相比之下，以下代码适合标准 gam 模型而不会引发收敛警告：
set.seed(1) #不确定这是否有区别，但设置种子以防万一

模型 &lt;- mgcv::gam(z ~ s(x, y, k = 500),
数据 = 数据集,
家庭 = tw(link=log),
方法 = &quot;REML&quot;) 

总结和问题
这是已知的 bam() 行为吗？除了简单地切换回 gam() 之外，还能做些什么来确保收敛？我曾尝试使用 maxit 关键字增加 IRLS 迭代次数，但没有成功。
我推测我的数据的“质量”可能相当差，因此有人可能会说，mgcv 很难将波动的空间平滑拟合到它并不完全令人惊讶。另一方面，gam() 似乎没有问题，因此绝对有可能实现所需的收敛。]]></description>
      <guid>https://stats.stackexchange.com/questions/660053/convergence-of-bam-mgcv-algorithm</guid>
      <pubDate>Wed, 15 Jan 2025 10:11:29 GMT</pubDate>
    </item>
    <item>
      <title>在线性误差传播过程中如何选择正确的公式？</title>
      <link>https://stats.stackexchange.com/questions/660052/how-to-choose-the-correct-formula-during-linear-error-propagation</link>
      <description><![CDATA[我正在使用线性误差传播的标准公式来估计变量中的不确定性，这些变量是根据平均实验可观测量计算出来的（使用标准偏差作为不确定性估计），但遇到了一个障碍。例如，考虑一个变量$k$，它可以计算为
$$k = 1-\frac{G\times I}{P} \tag{1}$$
作为可观测量$G$、$I$和$P$的函数。
但是，上述内容可以改写为
$$k = \frac{P-G\times I}{P} \tag{2}$$
但是，与方程 (1) 相关的传播不确定性似乎与方程 (2) 相关的不确定性不同，因为 $P$ 的值在方程 (2) 中出现了两次，而与方程 (1) 中的常数 (&quot;$1$&quot;) 相关的不确定性为零。
我遗漏了什么？在这种情况下，使用错误传播的正确方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660052/how-to-choose-the-correct-formula-during-linear-error-propagation</guid>
      <pubDate>Wed, 15 Jan 2025 09:42:21 GMT</pubDate>
    </item>
    <item>
      <title>L2 惩罚 cox 比例风险回归的统计推断</title>
      <link>https://stats.stackexchange.com/questions/660048/statistical-inference-for-l2-penalized-cox-proportional-hazard-regression</link>
      <description><![CDATA[首先，感谢您阅读我的问题。这是我第一次在这个平台上提问，所以如果某些要求没有得到满足，我深表歉意。
我试图使用 cox 比例风险生存分析来估计多个预测因子（HR 及其 95% CI 和 p 值）对直肠癌复发概率的影响。
由于我的数据集规模小（140 个观测值）且事件计数低（7 个事件），我决定使用 glmnet 包中的岭回归。Lasso 并不可取，因为我想保留所有预测因子，因为我有证据表明它们对复发的重要性。
我搜索了文献并了解到，虽然惩罚模型的统计推断以前由于惩罚引入的偏差而并不可取，但现在已被诸如“hdi”和“selectiveInference”之类的包克服，用于 Lasso 型回归，“lmridge”用于 L2 惩罚线性回归。
我的问题如下：

有没有什么方法可以对 Cox 比例模型上的岭回归进行统计推断。到目前为止，我还没有找到任何具有此功能的文章或 R 包
如果岭回归的统计推断仍然不可接受，我该如何解释 glmnet() 提供的 HR

这是我用于拟合模型的代码：
set.seed(10)
y &lt;- with(df_cox, Surv(df_cox$recurrencetime, df_cox$recurrence)) # 响应变量
x &lt;- model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1] # 预测器
df_cox = model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1] # 预测器
df_cox = model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1]
cv_model &lt;- cv.glmnet(
x, y,
family = &quot;cox&quot;,
alpha = 0, # 弹性网络 (alpha = 0.5 是套索和脊线的混合)
nfolds = 10 # 10 倍交叉验证
)
best_lambda &lt;- cv_model$lambda.min

# 使用最佳 lambda 拟合最终模型
final_model &lt;- glmnet(x, y, family = &quot;cox&quot;, alpha = 0, lambda = best_lambda)
]]></description>
      <guid>https://stats.stackexchange.com/questions/660048/statistical-inference-for-l2-penalized-cox-proportional-hazard-regression</guid>
      <pubDate>Wed, 15 Jan 2025 07:30:52 GMT</pubDate>
    </item>
    <item>
      <title>PSM-DiD 模型及其相关密度图的问题</title>
      <link>https://stats.stackexchange.com/questions/660044/issues-with-psm-did-model-and-its-related-density-plot</link>
      <description><![CDATA[作为项目的一部分，我正在尝试使用 R 中的 MatchIt 包实现 PSM-DiD 模型。我对此非常陌生，因此无法找出代码到底哪里出了问题，因为在运行初始 Logit 模型以及随后的匹配模型后，我得到的倾向得分结果都是错误的。
我的数据的简要说明：
变量：Under14（处理期限；1 表示年龄 &lt; 14，否则为 0），Post1986（毕业后；1 表示年份 &lt;= 1986，否则为 0），LIT（结果），其他协变量 - AGE、SEX、FAMSIZE、NCHILD、URBAN、YEAR、STATE（最后 2 个变量不太相关）。
据我所知，倾向得分是条件概率，因此该模型应该正确给出输出（倾向变量）。但是，处理单元的倾向得分接近 0（2.22e-16），而对照组的倾向得分接近 1，这对我来说没有意义。
这是我用于计算倾向得分的代码：
# 步骤 1：根据“Under14”变量分配组（处理组或对照组）
temp$group &lt;- with(temp, ifelse(Under14 == 1, &quot;Treated&quot;, &quot;Control&quot;))
temp$group &lt;- factor(temp$group, levels = c(&quot;Treated&quot;, &quot;Control&quot;))

# 步骤 2：拟合逻辑回归模型以估计倾向得分
logit_model &lt;- glm(group ~ URBAN + AGE + SEX + NCHILD + FAMSIZE, family = binomial, data = temp)
summary(logit_model)

# 步骤 3：计算预测概率（倾向得分）
temp$propensity &lt;- predict(logit_model, type = &quot;response&quot;)

并对匹配模型执行此操作：
# 步骤 4：使用倾向得分和最近邻匹配执行匹配
psm &lt;- matchit(group ~ URBAN + AGE + SEX + NCHILD + FAMSIZE, method = &quot;nearest&quot;, distance = temp$propensity, data = temp)

# 步骤 5：提取匹配数据
matched_data &lt;- match.data(psm)

# 步骤 6：在匹配数据上拟合 DiD 模型
# 组：治疗组或对照组
# Post1986：治疗后指标
# 交互项：组 * Post1986
did_model &lt;- lm(LIT ~ group * Post1986, data = matching_data, weights = weights)
summary(did_model)

这是 DiD 输出（系数表示 groupControl，出于某种我不明白的原因，也就是说，处理过的系数缺失了）：
输出

它为所有单元赋予权重 1；因此，最终的 DiD 模型不会给出所需的输出。0 和 1 值也存在于最终数据集匹配数据中。我对自己的方法可能存在的问题感到困惑。如果有人能指出错误，那将非常有帮助。
此外，我还想制作倾向得分匹配前后的核密度图，如下所示：
密度图

任何帮助都将不胜感激。我知道我的问题很长，但我完全卡住了。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660044/issues-with-psm-did-model-and-its-related-density-plot</guid>
      <pubDate>Wed, 15 Jan 2025 05:31:06 GMT</pubDate>
    </item>
    <item>
      <title>通过 RKHS 实现的 SVM 解决方案的平滑度</title>
      <link>https://stats.stackexchange.com/questions/660011/smoothness-of-svm-solution-via-rkhs</link>
      <description><![CDATA[我试图将 RKHS 的 SVM 视图与 SVM 解决方案的平滑性联系起来：
经典原始函数由以下公式给出：
\begin{aligned}
\text{最小化} \quad &amp; \frac{1}{2} \|\mathbf{w}\|^2, \quad \mathbf{w} \in \mathbb{R}^d, \, b \in \mathbb{R}, \\
\text{受制于} \quad &amp; y_i (\mathbf{w}^\top \mathbf{x}_i + b) \geq 1, \quad i = 1, \dots, n, \\
&amp; \mathbf{x}_i \in \mathbb{R}^d, \, y_i \in \{-1, 1\}。
\end{aligned&gt;
我们知道：
$\mathbf{w} = \sum_{i=1}^n \alpha_i y_i \mathbf{x}_i$
现在使用内核 $k$ 和一些相关特征图 $\phi(x$) 进行重构
$\mathbf{w} = \sum_{i=1}^n \alpha_i y_i \phi(\mathbf{x}_i)$
$\|\mathbf{w}\|^2 = \mathbf{w}^\top \mathbf{w} = \sum_i \sum_j \alpha_i \alpha_j y_i y_j \phi(\mathbf{x}_i)^\top \phi(\mathbf{x}_j)
= \sum_i \sum_j \alpha_i \alpha_j y_i y_j k(\mathbf{x}_i, \mathbf{x}_j)
= \|f\|^2_{H}.$
因此最小化 $||\mathbf{w}||$ 与最小化 $||f||_H$ 相同。
并且由于对于任何 $f \in H$ 和任意对 $x,x&#39; \in X$
$
|f(\mathbf{x}) - f(\mathbf{x}&#39;)| = |\langle f, K_{\mathbf{x}} - K_{\mathbf{x}&#39;} \rangle_{H}|
\leq \|f\|_{H} \cdot \|K_{\mathbf{x}} - K_{\mathbf{x}&#39;}\|_{H}
= \|f\|_{H} \cdot d_K(\mathbf{x}, \mathbf{x}&#39;),
$
$||f||_H$ 在某种程度上控制了平滑度。那么，这是否是 SVM 优化平滑解决方案的一个论点？]]></description>
      <guid>https://stats.stackexchange.com/questions/660011/smoothness-of-svm-solution-via-rkhs</guid>
      <pubDate>Tue, 14 Jan 2025 14:11:39 GMT</pubDate>
    </item>
    <item>
      <title>例如，I(X;Y|Z) < I(X;Y)</title>
      <link>https://stats.stackexchange.com/questions/660001/example-where-ixyz-ixy</link>
      <description><![CDATA[我问自己是否有可能$I(X;Y|Z)&lt;I(X;Y)$。起初这看起来很奇怪，因为知道$Z$的值怎么会导致$Y$提供的$X$信息比$Z$未知时提供的少。
然后我进入维基百科，我发现这是可能的。 $I(X;Y|Z)$ 可以等于、小于或大于 $I(X;Y)$。$I(X;Y|Z)&lt;I(X;Y)$ 背后的直觉是 $Z$ 解释了 $X$ 和 $Y$ 之间相关性的部分原因。
但是，我很难想出一个简单的例子来说明这一点。维基百科中没有数值示例，我在这个网站上也没有找到。]]></description>
      <guid>https://stats.stackexchange.com/questions/660001/example-where-ixyz-ixy</guid>
      <pubDate>Tue, 14 Jan 2025 10:01:13 GMT</pubDate>
    </item>
    <item>
      <title>连续随机变量的充分统计量的因式分解定理</title>
      <link>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics-in-case-of-continuous-random-var</link>
      <description><![CDATA[根据因式分解定理（Fisher-Neyman），我们得到一个统计量$ T(X) $充分当且仅当存在因式分解：$ f(x|\theta) = g(T(x)|\theta)h(x) $。符号遵循 Casella/Berger 第 276 页。
Casella/Berger 在离散情况下给出了证明，并指出具体因式分解的形式为：$ P(X=x | {\theta}) = P(T(X) = T(x) | {\theta})P(X=x | T(X) = T(x)) $
我的问题是：我们可以将这种解释应用于连续情况吗？它总是成立吗？因此：$ f(x|\theta) = f(T(x)|\theta)f(x|T(x)) $ 其中 $f$ 表示相应的 pdf？]]></description>
      <guid>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics-in-case-of-continuous-random-var</guid>
      <pubDate>Mon, 13 Jan 2025 22:52:25 GMT</pubDate>
    </item>
    <item>
      <title>泊松过程可以变成泊松过程回归吗？</title>
      <link>https://stats.stackexchange.com/questions/659931/can-a-poisson-process-be-made-into-a-poisson-process-regression</link>
      <description><![CDATA[这是我正在考虑的概念验证问题。
数据格式如下（模拟数据）：
patient_id dob gender hospital_visit age_at_visit
1 2019-06-21 F 2024-03-13 4
1 2019-06-21 F 2024-05-22 4
1 2019-06-21 F 2024-07-11 5
1 2019-06-21 F 2024-09-19 5
1 2019-06-21 F 2024-10-02 5
1 2019-06-21 F 2024-10-30 5
1 2019-06-21 F 2024-11-13 5
1 2019-06-21 F 2024-12-15 5
1 2019-06-21 F 2024-12-17 5
2 2007-12-13 M 2024-01-27 16
2 2007-12-13 M 2024-02-09 16
2 2007-12-13 M 2024-06-10 16
3 2024-02-01 M 2024-06-28 0
4 2014-04-12 F 2024-08-17 10
4 2014-04-12 F 2024-12-21 10
5 2010-02-20 F 2024-02-03 13
5 2010-02-20 F 2024-02-21 14
5 2010-02-20 F 2024-03-17 14
5 2010-02-20 F 2024-03-31 14
5 2010-02-20 F 2024-04-09 14

我定义了 2 个泊松过程：一个标准泊松过程（速率恒定）和一个（加速）泊松过程，其中速率函数随着更多事件的发生而变化（$r$ 是速率，$n$ 是已经发生的事件数发生):
$$ \quad\textbf{标准泊松分布：} \quad P(N(t) = k) = \frac{(\lambda t)^k e^{-\lambda t}}{k!} $$
$$ \quad\textbf{标准泊松过程：} \quad P(N(t) = 0) = e^{-\lambda t} $$
$$ \quad\textbf{加速泊松分布：} \quad P(N(t) = k) = \frac{(\lambda_n t)^k e^{-\lambda_n t}}{k!} $$
$$ \quad\textbf{速率增长函数：} \quad \lambda_n = \lambda_0 \cdot (1+r)^n $$
$$ \quad\textbf{加速泊松过程：} \quad P(N(t) = 0) = e^{-\lambda_n t} $$
很明显，当我们模拟和可视化它们时，我们可以看到两者之间的差异（在 R 中）：

我想知道这是否可以用于创建某人下次住院的模型，因为我们知道他已经住院了多少次（假设我们只在患者住院时进行协变量测量）。
我认为这在我们认为未来住院取决于患者过去住院次数的情况下很有用 - 这样，住院频率越高的人住院间隔时间就越短。
例如，我们可以定义这样的风险模型吗？
$$ \ln[h(t|n, X)] = \ln(\lambda_0) + n\ln(1+r) + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p $$
$$h(t) = \lim_{\Delta t \to 0} \frac{P(t \leq T &lt; t + \Delta t | T \geq t)}{\Delta t}$$
或者也许是对数对数链接？
$$ \log(-\log(1 - P(\text{readmission in }[t, t+\Delta t]|n, X))) = \beta_0 + \beta_n n + X\beta $$
$$ \log(-\log(1 - P(\text{readmission in }[t, t+\Delta t]|n))) = \log(\lambda_0) + n\log(1+r) + \log(\Delta t) $$
$$ \log(-\log(1 - P(\text{readmission in }[t, t+\Delta t]|n, X))) = \beta_0 + \beta_n n + X\beta + \log(\Delta t) $$
或者仅仅是一个纯随机过程？
$$ \log(\lambda_n) = \beta_0 + \beta_1n + X\beta $$
$$ \lambda_n = e^{\beta_0 + \beta_1n + X\beta} $$
$$ P(\text{readmission in }[t, t+\Delta t]|n,X) = 1 - e^{-\lambda_n\Delta t} = 1 - e^{-e^{\beta_0 + \beta_1n + X\beta}\Delta t} $$
我不明白如何对此类问题进行建模，因为它涉及纵向分析、随机过程和生存分析的概念。有什么关于如何开始的提示吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659931/can-a-poisson-process-be-made-into-a-poisson-process-regression</guid>
      <pubDate>Sun, 12 Jan 2025 21:26:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么时间序列的差分无助于在 SARIMA 模型中使其平稳？</title>
      <link>https://stats.stackexchange.com/questions/659898/why-does-differencing-of-time-series-not-help-to-make-it-stationary-in-the-sarim</link>
      <description><![CDATA[我在 SARIMA 模型中差分后无法获得平稳时间序列。
我是时间序列分析的初学者，但我读到时间序列 Y_t = \nabla^d (1-L^s)^D X_t 应该是平稳时间序列。然而，在用值 s=12 和不同的 d 和 D 值进行差分后，我的时间序列似乎不是平稳分析 ACF 函数。我也尝试过一开始 lambda=0 的 Box–Cox 变换，但同样没用。
这是我的原始数据
 (data_ts)
它是非平稳的。
经过 lambda = 0 的 Box-Cox 变换之后
data_bc &lt;- BoxCox(data_ts, lambda=0)


这是 ACF 函数：

然后我尝试对我的时间序列进行差分，结果如下：
ts_plot(diff(data_bc))
Acf(diff(data_bc))

.
。
在我看来，它可以是平稳的，但从 ACF 来看，它不是。可能是因为季节性？所以我尝试对滞后 s=12 的时间序列进行差分，然后再次进行差分（s=12、d=1、D=1）。
ts_plot(diff(diff(data_bc, lag=12)))
Acf(diff(diff(data_bc, lag=12)))



再次分析 ACF 函数，它似乎不是平稳的。我错了吗？那我该怎么办？
Box-Cox 变换、差分、消除季节性。我希望得到平稳时间序列。]]></description>
      <guid>https://stats.stackexchange.com/questions/659898/why-does-differencing-of-time-series-not-help-to-make-it-stationary-in-the-sarim</guid>
      <pubDate>Sat, 11 Jan 2025 14:36:19 GMT</pubDate>
    </item>
    <item>
      <title>确保 Fisher 信息矩阵严格正定的条件</title>
      <link>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</link>
      <description><![CDATA[Fisher 信息矩阵定义为：
$$I(\theta):=E\left[\left(\frac{\partial\log f(X;\theta)}{\partial \theta}\right)^2 \mid\theta\right]$$
其中 $f$ 是似然函数。
我正在寻找充分条件 - 最好是关于 $f$ 或 $\log f$ - 以确保 Fisher 矩阵严格正定。
正定性是证明最大似然估计量 (MLE) 渐近一致性的众所周知的临界条件。因此，本次调查具有重要意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</guid>
      <pubDate>Fri, 10 Jan 2025 14:33:43 GMT</pubDate>
    </item>
    <item>
      <title>R 中带有测量误差的优化函数（矩量模拟法）</title>
      <link>https://stats.stackexchange.com/questions/659682/optimizing-function-with-measurement-error-in-r-simulated-method-of-moments</link>
      <description><![CDATA[统计学中的一个常见问题是假设一个总体，模拟许多样本，并找到与所需统计数据集最接近（在 MSE 意义上）的参数。为了说明，下面是如何找到与 AR1 过程匹配的参数的草图。（这只是一组广泛问题的说明 --- 这个特定问题是 AR1 并不重要。）

NT &lt;- 50
match &lt;- c(intercept=0.2, ar1=0.90, expsigma=(-0.1))

sim.and.est.1 &lt;- function(i, p) {

## 模拟某个过程，比如 true ar1
set.seed(i); e &lt;- rnorm(NT, 0, exp(p[3]))
s &lt;- c( 0.2, numeric(NT-1) )
for (t in 2:NT) s[t] &lt;- p[1] + p[2]*s[t-1] + e[t]

## 估计 OLS ar1
a &lt;- lm.fit( cbind(1, s[1:(NT-1)]), s[2:NT] )
c( coef(a), expsigma= log(sd(resid(a)) ))
}

mcsapply &lt;- function( iter, fun, ... ) { 
simply2array(mclapply( iter, fun, ... )) }
penalty &lt;- function( a, b ) mean( (a-b)^2 )

result &lt;- optim(par=c(1.0, 0.0, 0.05),
fn=function( guess3, MC=1000 ) {
## message( paste( p3, collapse=&quot; &quot; ) )
simsests &lt;- 
t(mcsapply( 1:MC, function(i) sim.and.est.1(i, guess3) ))
thisone &lt;- colMeans( simsests )
ov &lt;- penalty( thisone , match )

## 如果我们接近，则抽样更多
if (ov &lt; 1e-2) {
## 增加精度
simsests &lt;- rbind(simsests, 
t(mcsapply( 1:MC*5, function(i) sim.and.est.1(i+MC, guess3) )))
thisone &lt;- colMeans( simsests )
ov &lt;- penalty( thisone , match )
}
ov
},
method=&quot;Nelder-Mead&quot;)

print(result)

R 中是否有更好的方法来处理具有测量误差的函数优化？

我试图处理这样的想法：远离最佳值，我不需要在函数本身中采样那么多点。它完全是临时的。
我也尝试重新启动 Nelder-Mead，但即使从局部最优开始似乎也没有减少其迭代次数（函数评估）。

是否有更适合手头任务的优化器？
我在这里做的事情可以做得更好吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659682/optimizing-function-with-measurement-error-in-r-simulated-method-of-moments</guid>
      <pubDate>Tue, 07 Jan 2025 17:01:55 GMT</pubDate>
    </item>
    <item>
      <title>混合模型中部分合并聚类估计消失或超出总体估计</title>
      <link>https://stats.stackexchange.com/questions/658964/partial-pooled-cluster-estimates-going-away-or-beyond-grand-estimates-in-mixed-m</link>
      <description><![CDATA[我认为我对混合模型中部分池化的主要目标和特征有相当好的理解。然而，部分池化的实际执行中有一些细节与我期望从各个集群得到的行为相冲突。例如，在下面我将链接的所有三个演示中，使用了各种表达式来表明特定于集群的截距和斜率估计应该向样本中相应的总体估计移动（也允许保持静止）。但是，如果您仔细跟踪集群估计从无池化到部分池化版本的一些可视化运动，您就会看到集群估计实际上如何沿着各个轴远离总体估计。在某些情况下，集群估计值也可能超出总体估计值。
https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/
https://towardsdatascience.com/when-mixed-effects-hierarchical-models-fail-pooling-and-uncertainty-77e667823ae8
https://m-clark.github.io/posts/2019-05-14-shrinkage-in-mixed-models/
至少定义集群截距重新定位的公式（参见上面的中间链接和此视频讲座）表明，单个集群的移动范围应限制在初始无合并位置和总体估计值之间（据我所知，如有必要，请纠正我）。但是，上述相互矛盾的观察结果是否与同一模型中随机截距和斜率的存在及其相关性有关？还没有拿尺子，但我的直觉告诉我，虽然聚类估计值可以沿着单个轴发散，但也许在部分池化期间整体斜边会变小。错误：我实际上拿了尺子，通过从屏幕上测量，由于部分池化，至少有一个整体距离增加了（参见最后列出的网站、df = create_data(sd_int = .25, sd_slope = 1) 的图和右上角的一个聚类）。
如果观察到的行为不是由错误引起的，而且我没有误解什么，那么原因能否从直观的实际意义上得到解释。为什么这种行为是有益的，尽管它似乎与部分池化的主要原则不一致。为什么不让所有的聚类估计值都沿着截距和斜率轴更接近总体估计值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658964/partial-pooled-cluster-estimates-going-away-or-beyond-grand-estimates-in-mixed-m</guid>
      <pubDate>Thu, 19 Dec 2024 12:35:28 GMT</pubDate>
    </item>
    </channel>
</rss>