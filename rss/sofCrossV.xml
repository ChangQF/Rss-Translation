<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 15 Dec 2024 18:22:23 GMT</lastBuildDate>
    <item>
      <title>如何从分段分布函数进行模拟？</title>
      <link>https://stats.stackexchange.com/questions/658768/how-to-simulate-from-piecewise-distribution-function</link>
      <description><![CDATA[大家好，提前感谢您的宝贵回复。我有以下分段分布函数：
$$
F(x) = \begin{cases} 
0.5 - 2^{r-1} (0.5 - x)^r &amp; \text{if } 0 \leq x \leq 0.5 \\ 
&amp;\quad\quad\quad\quad\quad\quad\quad\quad\text{for } r = 1.5, 2. \\
0.5 + 2^{r-1} (x - 0.5)^r &amp; \text{if } 0.5 &lt; x \leq 1 
\end{cases}
$$
我想模拟这个分布。我在 R 中编写了以下代码。但是，我认为模拟时存在一个问题，即反函数不成立：
fDr &lt;- function(r, N) {
samples &lt;- numeric(N) 
for (i in 1:N) {
u &lt;- runif(1) 
if (u &lt; 0.5) {
samples[i] &lt;- 0.5*(1-(1-2*u)^(1/r))
} else {
samples[i] &lt;- 0.5*(1-(2*u-1)^(1/r))
}
}
return(samples)
}

能否回复我给定的反函数对于模拟成立？
再次感谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/658768/how-to-simulate-from-piecewise-distribution-function</guid>
      <pubDate>Sun, 15 Dec 2024 18:21:27 GMT</pubDate>
    </item>
    <item>
      <title>重新采样进行 AB 测试，以在 CLT 下实现正态分布</title>
      <link>https://stats.stackexchange.com/questions/658765/resampling-for-ab-testing-to-achieve-normal-distribution-under-the-clt</link>
      <description><![CDATA[我 [终于] 理解了中心极限定理。非常令人兴奋。但是，我正在努力研究如何将其应用于 AB 测试，或者是否应该将其应用于 AB 测试。
原因：

最终测试统计使用正态曲线来可视化零假设为假的概率。因此，如果没有 CLT，我不确定 AB 测试是否准确。
由此产生的标准化曲线使假设检验的结果易于理解。即，我的结果是（统计）与总体中其他样本的平均值的标准差。

反对的原因：

它改变了报告的数据分布。
我不明白它会如何改变我的 AB 测试的结果。

是否应该在 A/B 测试中应用重采样？]]></description>
      <guid>https://stats.stackexchange.com/questions/658765/resampling-for-ab-testing-to-achieve-normal-distribution-under-the-clt</guid>
      <pubDate>Sun, 15 Dec 2024 16:53:45 GMT</pubDate>
    </item>
    <item>
      <title>使用简单泊松近似泊松混合的有效性</title>
      <link>https://stats.stackexchange.com/questions/658764/validity-of-approximating-a-poisson-mixture-with-a-simple-poisson</link>
      <description><![CDATA[我正在考虑用简单泊松分布近似泊松混合分布，方法是使用混合分布$\pi$的平均值$\mu_\pi$作为简单泊松的速率参数$\lambda$。
我的问题涉及底层过程的速率参数$\lambda$波动的时间尺度。如果$\lambda$在整个过程中波动多次（从而提供混合分布的良好样本，$\pi$），但连续事件之间的次数相对较少（例如，许多事件只有一次波动），近似值仍然有效吗？或者，事件之间频繁波动是该近似值有效性的必要条件吗？
根据维基百科（混合泊松分布链接），混合泊松分布的方差由以下公式给出：$\operatorname{Var}(X) = \mu_\pi+\sigma_\pi^2$，其中 $\mu_\pi$ 和 $\sigma_\pi^{2}$ 分别是 $\pi$ 的均值和方差。根据这个公式，只要 $\lambda$ 的波动足够大，可以提供 $\pi$ 的良好样本，无论波动频率如何，混合过程的方差都会接近这个理论值。
但是，我进行了一些数值模拟，似乎表明波动频率对方差也起着重要作用（可能是我的代码中存在一些错误？）。有人可以澄清 $\lambda$ 波动的时间尺度、事件之间的时间以及简单泊松近似的有效性之间的精确关系吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658764/validity-of-approximating-a-poisson-mixture-with-a-simple-poisson</guid>
      <pubDate>Sun, 15 Dec 2024 16:51:48 GMT</pubDate>
    </item>
    <item>
      <title>如何表明协方差不能捕捉非线性关系？</title>
      <link>https://stats.stackexchange.com/questions/658757/how-to-show-covariance-doesnt-capture-nonlinear-relationships</link>
      <description><![CDATA[我听说皮尔逊相关性用于评估线性关系以及协方差。所以我很想知道为什么会这样。
假设我们有随机变量$X$，并且想要计算
$$\operatorname{Cov}(X,Y) = \mathbb{E}\left[ (X-\bar{X})(Y-\bar{Y}) \right]$$
然后假设我们可以用$X$来表示$Y$。
$$Y= g(X) = f(X) + h(X)$$
其中$f$是线性部分，$h$ 是非线性的。
$$
Y = g(X) = aX + b + h(X) 
$$
\begin{align*}
\mathbb{E}[g(X)] &amp; = \mathbb{E}[aX + b + h(X)]\\
&amp;= a \mathbb{E}[X] + b + \mathbb{E}[h(X)] \\
\end{align*&gt;
回想一下，我们有 $\operatorname{Cov}(X,Y) = \mathbb{E}\left[ (X-\bar{X})(Y-\bar{Y}) \right]$，因此我们需要简化 $Y-\bar{Y}$。
\begin{align*}
Y-\bar{Y} &amp;= g(X) - \mathbb{E}[g(X)] \\ 
&amp;= (aX + b + h(X)) - (a\mathbb{E}[X] + b \mathbb{E}[h(X)]) \\ 
&amp;= a(X - \mathbb{E}[X]) + (h(X) - \mathbb{E}[h(X)]) \\ 
\end{align*&gt;
找到这个后，我们现在可以简化原始的 $\operatorname{Cov}(X,Y)$。
\begin{align*}
\operatorname{Cov}(X,Y) &amp;= \mathbb{E}[(X-\bar{X})(Y-\bar{Y})] \\ 
&amp;= \mathbb{E}[(X-\bar{X}) (g(X) - \mathbb{E}[g(X)])] \\ 
&amp;= \mathbb{E}[(X-\bar{X}) (a(X-\mathbb{E}[X]) + (h(X) - \mathbb{E}[h(X)]))]\\ 
&amp;= \mathbb{E}[(X-\bar{X}) (a(X-\mathbb{E}[X])] + \mathbb{E}[(X-\bar{X})(h(X) - \mathbb{E}[h(X)]))]\\ 
&amp;= a\operatorname{Var}(X) + \operatorname{Cov}(X,h(X))\\ 
\end{align*&gt;
所以现在的问题是 $\operatorname{Cov}(X,h(X))$?
所以我想我的问题是，如果协方差是线性关系的度量，这是否意味着 $\operatorname{Cov}(X,h(X)) = 0$?
如果是这样，如果 $h$ 确实是非线性的，我如何证明这保证为 0？]]></description>
      <guid>https://stats.stackexchange.com/questions/658757/how-to-show-covariance-doesnt-capture-nonlinear-relationships</guid>
      <pubDate>Sun, 15 Dec 2024 15:23:15 GMT</pubDate>
    </item>
    <item>
      <title>向量的期望 $L^2$ 范数是否大于向量元素期望的 $L^2$ 范数？</title>
      <link>https://stats.stackexchange.com/questions/658756/is-the-expected-l2-norm-of-a-vector-larger-than-the-l2-norm-of-the-vector</link>
      <description><![CDATA[假设随机变量 $X_1, X_2$ 是独立的。以下不等式是否成立？
$$
\mathbb{E}(​​\sqrt{X_1^2+X_2^2}) \ge \sqrt{\mathbb{E}^2(X_1)+\mathbb{E}^2(X_2)}
$$
如果成立，有简单的证明吗？

请注意，这不是 Jensen 不等式！
（$\sqrt{\mathbb{E}(​​X_1^2+X_2^2)} \ge \mathbb{E}(​​\sqrt{X_1^2+X_2^2})$）]]></description>
      <guid>https://stats.stackexchange.com/questions/658756/is-the-expected-l2-norm-of-a-vector-larger-than-the-l2-norm-of-the-vector</guid>
      <pubDate>Sun, 15 Dec 2024 15:14:16 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 marginaleffects::comparisons 或 avg_comparisons() [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658754/cannot-use-marginaleffectscomparisons-or-avg-comparisons</link>
      <description><![CDATA[亲爱的边际效应开发者/维护者/社区，
您好！我在使用 avg_comparisons() 时收到错误消息。
具体来说，我拟合了一个 lme4 模型“y ~ 条件 * 试验 + (1 | 参与者)”，其中条件是一个两级因子，试验是一个中心连续变量。交互条件：试验不显著
我现在想使用以下代码获取我的交互条件：试验的效果大小。但我收到了我不明白的错误消息

似乎包“data.table”出了问题。但是，我确认这个软件包版本是 1.14.8。
我现在不知道发生了什么。如果您能看看我的问题并提供反馈，那就太好了。我提前非常感激！
祝好，
Ted]]></description>
      <guid>https://stats.stackexchange.com/questions/658754/cannot-use-marginaleffectscomparisons-or-avg-comparisons</guid>
      <pubDate>Sun, 15 Dec 2024 14:23:42 GMT</pubDate>
    </item>
    <item>
      <title>计算不同大小的文本语料库的卡方</title>
      <link>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</link>
      <description><![CDATA[我偶然发现了一篇论文，它批评了某文本分析软件中用于比较六个大小明显不同的文本语料库中的词频的卡方统计量的计算。该软件采用标准公式：
$$
\chi^2 = \sum_{i=1}^{n} \frac{(O_{i} - E_{i})^2}{E_{i}}
$$
这里，$O_{i}$表示在语料库$i$中观察到的频率，$E_{i}$的计算方法是将一个词在所有六个语料库中的总频率除以所有语料库中的单词总数，然后乘以语料库$i$中的单词数。
本文作者批评了这种方法，陈述：

&quot;运行交叉制表也不能产生有效可靠的评估。 [...] 事实证明，该软件使用非标准化的绝对频率，只有当要比较的文本语料库长度相等时才不会引起问题。&quot;

在这种情况下，作者将$O_{i}$解释为绝对频率，并提出了一种替代的&quot;标准化&quot;过程来计算$O_{i}$和$E_{i}$。这涉及：

选择最小的语料库作为参考。
通过将观察到的所有其他语料库的频率除以各自语料库中的单词总数，然后乘以参考语料库中的单词数，对观察到的所有其他语料库的频率进行归一化。
将预期频率计算为所有语料库（包括参考语料库）的归一化频率之和，除以六（语料库数量）。

问题 1：作者声称该软件使用的公式（如上所述）没有考虑到语料库的各种大小，他是否正确。
问题 2：在这种情况下，这种归一化方法是否适用于卡方计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</guid>
      <pubDate>Sun, 15 Dec 2024 13:37:05 GMT</pubDate>
    </item>
    <item>
      <title>箱线图是否假设区间数据？</title>
      <link>https://stats.stackexchange.com/questions/658750/does-a-boxplot-assume-interval-data</link>
      <description><![CDATA[箱线图是否假设区间数据？如果不是，那么使用箱线图来表示李克特量表（序数）数据可以吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658750/does-a-boxplot-assume-interval-data</guid>
      <pubDate>Sun, 15 Dec 2024 11:48:10 GMT</pubDate>
    </item>
    <item>
      <title>如何计算文本 2 中文本 1 的单词出现的次数？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658749/how-do-i-count-the-occurrences-of-words-of-text-1-in-text-2</link>
      <description><![CDATA[我是新来的，英语不是我的母语，所以如果造成任何混淆，我提前道歉。
长话短说，我正在做一项关于学校如何传递知识的博士研究，在这个阶段，我试图弄清楚学习教科书如何有助于考试，然后了解为什么有些学生即使花了几个小时学习教科书，成绩仍然很差，以及这种复习方法在哪个年级失效了。
因此，我试图将试卷中的文本与教科书中的文本进行比较。我想知道试卷中有多少单词直接来自教科书，即文本 1 中有多少单词与文本 2 中的单词相同。理想情况下，结果将如下所示：
文本 1 中的单词出现在文本 2 中：
生日——2 次
姐妹——4 次
... 等等。
我以为已经有某种 AI 助手可以完成这样的任务，但到目前为止我的搜索都是徒劳的。所以我想知道是否有任何方法可以进行这样的比较？非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658749/how-do-i-count-the-occurrences-of-words-of-text-1-in-text-2</guid>
      <pubDate>Sun, 15 Dec 2024 11:25:59 GMT</pubDate>
    </item>
    <item>
      <title>小离散值的分布可视化</title>
      <link>https://stats.stackexchange.com/questions/658744/distributional-visualization-of-small-discrete-values</link>
      <description><![CDATA[对于研究对象，每种测量类型我几乎只得到 40 个小整数计数。计数从零开始，分布高度正偏。参见附图。无需赘述，从样本中可以得出结论，经过测试的、非常简单的测试假设可以肯定地被接受。但是，从这种类型的离散小值数据中可视化分布体有什么合适的方法吗？在图像中，我添加了 ggplot2 R 包中的典型 geom_boxplot，没有离群值和晶须，以显示中位数、第一和第三四分位数，以帮助理解分布。如果仅显示单个测量值（沿 y 轴略微抖动以缓解视觉分离），它看起来有点不直观的“空洞”。您是否保持 geom_boxplot 合理，或者您可以提出其他建议？

从这里找到了小提琴图表的提议：分析/可视化紧密分组的离散结果]]></description>
      <guid>https://stats.stackexchange.com/questions/658744/distributional-visualization-of-small-discrete-values</guid>
      <pubDate>Sun, 15 Dec 2024 08:39:49 GMT</pubDate>
    </item>
    <item>
      <title>GAM(M) 用于 R 中配对对照治疗样本的纵向测量</title>
      <link>https://stats.stackexchange.com/questions/658725/gamm-for-longitudinal-measurements-from-paired-control-treatment-samples-in-r</link>
      <description><![CDATA[我有一个如下所示的测试数据集；



ID
样本
组
周




X1
样本1
健康
0


X1
样本2
疾病
0


X1
样本3
健康
2


X1
样本4
疾病
2


X1
样本5
健康
5


X1
样本6
健康
16


X1
样本7
疾病
16


X2
样本8
健康
0


X2
样本9
疾病
0


X2
样本10
健康
2


X2
样本11
疾病
2


X2
样本12
健康
5


X2
样本13
疾病
5


X2
样本14
健康
16


X2
样本15
疾病
16


X3
样本16
健康
0


X3
样本17
疾病
0


X3
样本18
健康
2


X3
样本19
疾病
2


X3
样本20
健康
5


X3
样本21
疾病
5


X3
样本22
健康
16


X3
样本23
疾病
16


X4
样本24
疾病
0


X4
样本25
健康
2


X4
样本26
疾病
2


X4
样本27
健康
5


X4
样本28
疾病
5


X4
样本29
健康
16


X4
样本30
疾病
16



ID列定义从中收集配对样本的每个受试者。共有四个时间点； 0、2、5 和 16。
正如上面所举例说明的部分数据，我在每个时间点从每个配对站点获取了 200 个不同的对数转换测量值，但并非所有受试者都有完整的样本集。假设测量值不遵循线性趋势，您能否建议（对 GAM/GAMM 新手）我如何通过使用 R 中的 GAM 或 GAMM 处理配对采样策略来测试测量值在健康和疾病组之间是否有显着不同的纵向趋势？
PS：我尝试了一些模型，例如
gam(Measurement1 ~ Group + Week +
s(ID, bs = &#39;re&#39;),
data = data, method = &#39;REML&#39;)

但我需要一些其他的系列来测试，而不是高斯。]]></description>
      <guid>https://stats.stackexchange.com/questions/658725/gamm-for-longitudinal-measurements-from-paired-control-treatment-samples-in-r</guid>
      <pubDate>Sat, 14 Dec 2024 20:39:10 GMT</pubDate>
    </item>
    <item>
      <title>OLS、GLM 和 GLS 中高斯对数似然值是如何计算的？</title>
      <link>https://stats.stackexchange.com/questions/658636/how-is-gaussian-log-likelihood-value-calculated-in-ols-glm-and-gls</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658636/how-is-gaussian-log-likelihood-value-calculated-in-ols-glm-and-gls</guid>
      <pubDate>Thu, 12 Dec 2024 17:03:36 GMT</pubDate>
    </item>
    <item>
      <title>在拟合模型之前通过统计抽样删除数据？</title>
      <link>https://stats.stackexchange.com/questions/658635/statistical-sampling-to-remove-data-before-fitting-a-model</link>
      <description><![CDATA[在正常情况下，其他条件相同，数据越多越好。
我对以下情况感到疑惑：我有一个非常大的数据集，我想拟合一个统计模型。但是，我的计算机不够强大，无法在整个数据集上拟合模型。
假设每个数据点都同样可靠且具有相同的数据质量，我是否可以考虑使用统计抽样来删除某些数据点，以便模型可以在我的计算机上运行？
我认为这可能相当复杂。正如我们在构建数据集时使用调查权重来确保没有一组观察结果被低估或被高估一样，是否可以使用类似的技术来确保减少数据量不会导致任何组被高估/低估？
我认为需要进行一些逻辑检查，以确保与原始数据相比，缩小后的数据集中不存在高估/低估？例如如果原始数据为（60%-40% 男女），我们希望缩减后的数据集中男女比例也大致有 20% 的差异。但是，这只是一种比较方法（例如，缩减后，男女比例保持不变，但就业与失业比例不保持不变）。也许存在一些通用技术来比较两个数据集（即原始数据集与缩减数据集）联合分布之间的差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/658635/statistical-sampling-to-remove-data-before-fitting-a-model</guid>
      <pubDate>Thu, 12 Dec 2024 16:25:22 GMT</pubDate>
    </item>
    <item>
      <title>如何从具有分类变量的混合模型中估计总体方差？</title>
      <link>https://stats.stackexchange.com/questions/658575/how-to-estimate-population-variance-from-a-mixed-model-with-a-categorical-variab</link>
      <description><![CDATA[我以为这是一个基本问题，但我被它难住了，找不到解决方案。
我有一个数据库，其中包含不同养猪生产阶段（类别）的粪浆干物质含量，并且由不同的操作员（OP）在不同时刻（季节）采集样本。我只是对估计每个类别的平均值和方差总体感兴趣。
为了解决这个问题，我建立了一个线性混合模型，其中对因变量进行了平方变换。在测试了它们的重要性（AIC、BIC）后，我将 OP 纳入随机效应，将 CATEGORY 和 SEASON 纳入固定效应。
fit &lt;- nlme::lme(sqrt(MS) ~ CATEGORY + SEASON, 
random= ~ 1|OP, data=dat)

据我了解，每个 CATEGORY 中的估计平均值是每个固定效应值对应的 LSM。但是我不太清楚如何估计每个类别的方差。简化一下，我读到过，在一般线性回归中，模型的均方误差用于估计总体的方差，但在混合模型中，对于一些分组变量，我找不到任何关于如何计算它的解释。
每个固定效应的标准误差是否等同于 MSE？
summary(fit)

固定效应：sqrt(MS) ~ CATEGORY + SEASON 
值 标准误差 DF t 值 p 值
（截距） 2.0142552 0.1127073 197 17.871557 0.0000
CATEGORYpiglets -0.2367893 0.1400533 197 -1.690708 0.0925
CATEGORYsows -0.8191891 0.1195440 197 -6.852615 0.0000
SEASONspring -0.0280369 0.02811633 194 -0.997177 0.3199
SEASONsummer -0.0126275 0.03969934 194 -0.318078 0.7508
SEASONoutom -0.0884407 0.02879816 194 -3.071054 0.0024

我的最终目标是估算覆盖 75% 人口的干物质含量值。您能帮我解决这个疑问吗？如果它有用，我正在使用 R 中的 nlme 包。]]></description>
      <guid>https://stats.stackexchange.com/questions/658575/how-to-estimate-population-variance-from-a-mixed-model-with-a-categorical-variab</guid>
      <pubDate>Wed, 11 Dec 2024 13:37:53 GMT</pubDate>
    </item>
    <item>
      <title>如何使用最大似然估计从数据中拟合/学习非平稳泊松过程？</title>
      <link>https://stats.stackexchange.com/questions/657816/how-do-you-fit-learn-a-nonstationary-poisson-process-from-data-using-maximum-lik</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657816/how-do-you-fit-learn-a-nonstationary-poisson-process-from-data-using-maximum-lik</guid>
      <pubDate>Mon, 25 Nov 2024 17:34:09 GMT</pubDate>
    </item>
    </channel>
</rss>