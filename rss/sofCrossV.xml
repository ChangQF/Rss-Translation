<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 06 Feb 2024 00:58:00 GMT</lastBuildDate>
    <item>
      <title>凯利投注纸中的预期财富解读</title>
      <link>https://stats.stackexchange.com/questions/638634/interpretation-of-expected-wealth-in-kelly-betting-paper</link>
      <description><![CDATA[这是另一个 StackOverflow 问题。
凯利押注于不确定的赛马
概率估计（Metel 2017）描述了“ECC”凯利方法的变体定义为

带有变量

h 马指数，已知；
n已知的马匹数量；
$\pi$ 已知的获胜概率的固定大小向量；
O已知的固定大小的支付赔率向量；
w当前财富，已知；
x 固定大小的赌注向量，未知，优化对象。

计算内部表达式很容易，但我发现解释“预期”是很困难的。和“概率”外在表达困难。如果内部概率值都是已知且固定的，那么财富对数不是小于某个值0或100%的概率吗？
我（以及第一个问题的原始发布者）可能需要一些介绍性的指导，了解这两个表达式对概率向量本质的真正假设 - 这种优化是否仅在存在隐含概率分布函数时才有效？&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/638634/interpretation-of-expected-wealth-in-kelly-betting-paper</guid>
      <pubDate>Tue, 06 Feb 2024 00:34:17 GMT</pubDate>
    </item>
    <item>
      <title>Riddusion 模型如何生成音乐中的人声？</title>
      <link>https://stats.stackexchange.com/questions/638633/how-does-riddusion-model-generate-vocals-in-music</link>
      <description><![CDATA[我想知道 Riffusion 模型如何将我们的文本转换为歌手的声音并为其添加背景音乐。我可以理解它如何生成音乐，但我无法理解它如何生成歌手的声音并将其与音乐融为一体。它使用任何文本转语音引擎吗？它如何将声音速度/节奏与生成的音乐相匹配？]]></description>
      <guid>https://stats.stackexchange.com/questions/638633/how-does-riddusion-model-generate-vocals-in-music</guid>
      <pubDate>Tue, 06 Feb 2024 00:03:00 GMT</pubDate>
    </item>
    <item>
      <title>因果关系</title>
      <link>https://stats.stackexchange.com/questions/638632/cause-and-effect-relation</link>
      <description><![CDATA[我陷入了以下问题。我想从日常生活中找到简单的例子，很明显，分类变量和定量变量之间没有因果关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/638632/cause-and-effect-relation</guid>
      <pubDate>Mon, 05 Feb 2024 23:41:30 GMT</pubDate>
    </item>
    <item>
      <title>奥古斯特·布拉维 (Auguste Bravais) 是如何得出回归线的？</title>
      <link>https://stats.stackexchange.com/questions/638630/how-did-auguste-bravais-come-up-with-the-regression-line</link>
      <description><![CDATA[我是统计学和线性回归的新手，我遇到了奥古斯特·布拉维发现回归线但没有意识到的情况。
&lt;块引用&gt;
奥古斯特·布拉维 (Auguste Bravais) (1811-1863)，天文学和物理学教授，
最著名的可能是他在晶体学方面的工作（Nelson，1998）。
关于误差理论，他最出名的论文是在
1846 年，标题为“分析错误概率的数学”
情况” [翻译：《数学分析》
点的错误概率”]。这部作品因
相关理论的第一个数学阐述。
Pearson（1896）后来回忆起这些言论时说，
布拉维 (Bravais) 最先讨论了数学的基本定理
相关演算。在他 1846 年发表的著名论文《布拉维》中，
数学上，而不是经验上，找到了正常的方程
误差频率的表面。同时使用解析和几何
方法，布拉维还基本上发现了最终的结果
创造了“回归线”。他通过调查如何做到这一点
频率表面的各个椭圆区域因给定的不同而变化
直接观察到的量。通过这个，他发现了一条线
回归，但本质上没有意识到它，因此无法
“实现飞跃” （Walker，1929）有必要声称发现
相关或回归


我的问题是他是如何使用“频率表面的各种椭圆区域”来计算的？遇到回归线？我根本不明白。如果可以的话请使用图表。也没有太多复杂的数学，因为我是新手。只需简单解释一下它是如何工作的。]]></description>
      <guid>https://stats.stackexchange.com/questions/638630/how-did-auguste-bravais-come-up-with-the-regression-line</guid>
      <pubDate>Mon, 05 Feb 2024 22:41:21 GMT</pubDate>
    </item>
    <item>
      <title>相关性固定效应</title>
      <link>https://stats.stackexchange.com/questions/638629/correlations-fixed-effect</link>
      <description><![CDATA[我正在使用 lme4 包和 glmer 拟合广义混合线性模型。每次拟合模型时，我都会在模型开始拟合之前收到此错误消息：
固定效应模型矩阵存在秩缺陷，因此删除 1 列/系数

令人惊讶的是，哪个效果被丢弃的问题取决于公式中变量的顺序。如果我使用 y ~ a + b + c + a*b + a*c 那么，如果我这样做 y ~ a + ，a*c 就会被丢弃b + c + a*c + a*b，然后 a*b 被删除。然而，cor(a*c, a*b)=0.03，这与我对多重共线性的直觉相矛盾。所以我开始调查发生了什么事。
在调查过程中，我注意到以下内容。如果我使用 summary(model) 来查找固定效应的相关性，则相关性比我仅使用 cor(x) 计算相关矩阵时要高得多。&lt; /p&gt;
问题1：为什么这两个表不同？
Q2： summary(model) 仅显示未删除的变量。我可以重新创建包含已删除效果的表格吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638629/correlations-fixed-effect</guid>
      <pubDate>Mon, 05 Feb 2024 22:41:15 GMT</pubDate>
    </item>
    <item>
      <title>如何通过最小化误差平方和来导出 beta 的 OLS 估计？</title>
      <link>https://stats.stackexchange.com/questions/638628/how-to-derive-ols-estimates-of-beta-by-minimizing-the-error-sum-of-squares</link>
      <description><![CDATA[对于模型：$Y_i=\beta_0+\beta_1X_i+\epsilon_i, \epsilon_i \sim^{iid} N(0,\sigma^2)$ $i=1,...,n.$ 让 $X_i &gt;0$ 和 $\sigma^2_i=\sigma^2X_i$。 $\tilde{Q}(\beta)=\sum^{n}_{i=1}\sigma_{i}^{-2}\{Y_{i}- (\beta_0+\beta_1X_{i})\}^2$ 是加权误差平方和。

让 $\hat\beta=(\beta_0,\beta_1)^T$ 表示模型的 OLS 估计量。
让 $Y=(Y_1, ..., Y_n)$ 表示响应变量。
$X = n\times2$ 设计矩阵，其中第一列为 1。
$\beta = (\beta_0, \beta_1)^T$ 为回归系数。

误差平方和为$\sum_{i=1}^{n}\{Y_{i}-(\beta_0+\beta_1X_{i})\}$ 。 I a，尝试通过最小化误差平方和来导出 $\beta$ 的 OLS 估计。我在下面做了，这个问题的另一部分要求我根据我获得的 $\beta$ 的派生估计，我应该找到以下分布： $\hat\beta$ 以及 $\hat\epsilon_i$ 的方差&quot;math-container&quot;&gt;$\hat\epsilon=(\hat\epsilon_1,..\hat\epsilon_n)^T$ 对于 $i=1,.. .,n.$
为了导出 beta 的 OLS，我执行了以下操作：
$\sum_{i=1}^{n}\{Y_{i}-(\beta_0+\beta_1X_{i})\} = ||(Y-X\beta )||^2$。因此，我们必须求解 $argmin_{\beta}||(Y-X\beta)||^{2} \rightarrow \beta_{OLS} = (X^{T}X) ^{-1}X^{T}Y$。我有点困惑如何使用它来查找 $\hat\beta$ 的分布和 $\epsilon_i$。]]></description>
      <guid>https://stats.stackexchange.com/questions/638628/how-to-derive-ols-estimates-of-beta-by-minimizing-the-error-sum-of-squares</guid>
      <pubDate>Mon, 05 Feb 2024 22:21:13 GMT</pubDate>
    </item>
    <item>
      <title>方差分析检验：如果 alpha 较低，我们更常接受假设 H0，这是否正常？</title>
      <link>https://stats.stackexchange.com/questions/638627/anova-test-is-it-normal-that-if-alpha-is-lower-we-accept-more-often-the-hypoth</link>
      <description><![CDATA[假设我们进行方差分析来检验假设 H0：$µ_1 = µ_2 = µ_3$，使用以下数据（每行代表 &lt; em&gt;三个类）：

我们有：


如果我们采用经典值$\alpha = 0.05$，则阈值（用F分布计算）为$F_0 = 4.2565$。由于 $F &gt; F_0$，我们可以拒绝 H0。

如果我们取值$\alpha = 0.01$，那么阈值（用F分布计算）为$F_0 = 8.0215$。由于 $F &lt; F_0$，我们不拒绝 H0。


如何解释“置信度为 95% 时不接受 H0”，但“置信度为 99% 时接受 H0”，这不是违反直觉吗？
直观上，如果目标置信度较高，我们就应该较少断言某些内容，这不是正确的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638627/anova-test-is-it-normal-that-if-alpha-is-lower-we-accept-more-often-the-hypoth</guid>
      <pubDate>Mon, 05 Feb 2024 22:03:06 GMT</pubDate>
    </item>
    <item>
      <title>将函数拟合到曲线，然后删除某些点</title>
      <link>https://stats.stackexchange.com/questions/638626/fitting-a-function-to-a-curve-to-then-remove-certain-points</link>
      <description><![CDATA[我正在尝试提出一个测试，该测试仅考虑明显遵循拟合曲线的点。因此，对于下面的数据，它会切断 x=0.13 附近的任何低于此值的点，因为低于该值的点不能很好地遵循曲线。当 x=0.13 以上时，您可以看到它遵循一条清晰的曲线。我正在尝试最小化用户输入。最初，我只是简单地将幂律曲线拟合到数据，然后计算残差，然后得出最大残差距离。但这意味着我必须提供一些值，而我试图在没有用户输入的情况下自动完成它。
我有以下数据：
x = np.array([0.03751155, 0.05001541, 0.06251926, 0.07502311, 0.08752696,
        0.10003081、0.11253466、0.12503851、0.13754236、0.15004622、
       0.16255007、0.17505392、0.18755777、0.20006162、0.21256547、
       0.22506932、0.23757318、0.25007703、0.26258088、0.27508473、
       0.28758858, 0.30009243])
y = np.array([0.17091544, 0.2196002 , 0.24884891, 0.22784447, 0.365201,
       0.37375478、0.39257039、0.37231073、0.41550739、0.43636989、
       0.45111672、0.46662792、0.48854647、0.49640163、0.51887196、
       0.52827061、0.54437941、0.54929705、0.56552202、0.57508514、
      0.58477563, 0.59755615])

我使用以下方法绘制：
plt.scatter(x, y)

plt.网格（真）
plt.xlabel(“X 数据”)
plt.ylabel(&quot;Y 数据&quot;)

plt.ylim(-0.05,0.65)
plt.xlim(-0.05,0.32)

]]></description>
      <guid>https://stats.stackexchange.com/questions/638626/fitting-a-function-to-a-curve-to-then-remove-certain-points</guid>
      <pubDate>Mon, 05 Feb 2024 21:49:27 GMT</pubDate>
    </item>
    <item>
      <title>皮尔逊卡方检验的修改</title>
      <link>https://stats.stackexchange.com/questions/638624/modification-of-pearsons-chi-square-test</link>
      <description><![CDATA[乍一看，皮尔逊的卡方检验似乎存在重大缺陷。你能帮我找出我的逻辑错误吗？
我有一个结果为 $k$ 的多项分布，$p_i$ 表示假设的概率结果$i$。我从这个分布中获取 $n$ 样本，并用 $n_i$ 表示我观察到的次数结果$i$（因此$\sum n_i=n$）。
我们有 $E[n_i]=np_i$，$Var[n_i]=np_i(1-p_i) $ 和 $Cov[n_i,n_j]=-np_ip_j$ 用于 $i\ne j$。设置 $x_i:=\frac{n_i-np_i}{\sqrt{np_i(1-p_i)}}$，我们有 $E[x_i]=0$、$Var[x_i]=1$ 和
$Cov[x_i,x_j]=-\sqrt{\frac{p_ip_j}{(1-p_i)(1-p_j)}}$。
设 $\vec{x}\in\mathbb{R}^k$ 为 $x_i 的向量$s，所以 $E[\vec{x}]=\vec{0}$ 和
$Var[\vec{x}]_{i,j}=Cov[x_i,x_j]$，上面计算的。该协方差矩阵具有 corank $1$ （这在重新缩放之前更容易显示，并且如果需要，可以在将来的编辑中包含证明）。如果 $n_i$ 都足够大，则每个 $x_i$ 的分布大致为 $\mathcal{N}(0,1)$。但 $Var[\vec{x}]$ 不依赖于 $n$&lt; /span&gt;，并且实际上与单位矩阵不太接近（特别是如果 $k$ 很小），因此  $x_i$ 并非不相关，并且如果 $n$ 变得越来越大，相关性也不会降低。
但我们估计$\sum\limits_{i=1}^{k-1} x^2_i\sim \chi^2_{k-1}$ 来检验这个假设。选择不包含 $x^2_k$ 本身就很奇怪，因为虽然 $x_k$ 确实如此span&gt; 完全依赖于其他 $x_i$，我们忽略了它们在其他上下文中的相关性！难道没有一个简单的解决办法吗？
设 $A$ 为 $(k-1)\times k$ 矩阵，其中 &lt; span class=&quot;math-container&quot;&gt;$ACov[\vec{x}]A^T=I_{k-1}$，$(k-1 )\times (k-1)$ 单位矩阵（可以通过 SVD 等方法计算）。然后$Var[A\vec{x}]=I_{k-1}$。当 $n$ 变得非常大时，$A\vec{x}$ 的各个分量的分布变得非常大方法$\mathcal{N}(0,1)$，它们的相关矩阵是恒等式。这并不意味着它们的联合分布接近联合高斯分布（因为不相关的高斯分布不一定是独立的），但我想这可以证明是正确的。
那么我们为什么不测试 $\|A\vec{x}\|^2\sim \chi_{k-1}^2$反而？这个 $A$ 并不难计算，因为它的复杂性是用 $k$ 来计算的。]]></description>
      <guid>https://stats.stackexchange.com/questions/638624/modification-of-pearsons-chi-square-test</guid>
      <pubDate>Mon, 05 Feb 2024 21:21:06 GMT</pubDate>
    </item>
    <item>
      <title>EDA 词汇</title>
      <link>https://stats.stackexchange.com/questions/638623/vocabulary-in-eda</link>
      <description><![CDATA[我发现自己很难找到合适的词汇来描述散点图作为探索性数据分析的一部分。
我找到了这篇关于图论，虽然它很有趣，但我不确定我可以使用哪些词汇
在这个图中，我可以说蓝色的点比橙色的点更高吗？我没有模型，我不知道交互作用，混杂因素，或者我没有进行错误控制来判断一个比另一个更高。
]]></description>
      <guid>https://stats.stackexchange.com/questions/638623/vocabulary-in-eda</guid>
      <pubDate>Mon, 05 Feb 2024 20:12:05 GMT</pubDate>
    </item>
    <item>
      <title>推论具有估计 p 但未知 N 的二项式比例</title>
      <link>https://stats.stackexchange.com/questions/638621/inference-for-binomial-proportion-with-estimated-p-but-unknown-n</link>
      <description><![CDATA[假设我拥有一家面包店，除了其他甜点外，还销售一种非常美味的巧克力蛋糕。它太好了，我估计我的日常客户中有 80% 会购买小菜一碟，即 $p=0.8$。
但是，由于特殊的原料要求和密集的劳动，我每天只能在开业前制作一个蛋糕。为了平均分配，我计算了在门口等候的顾客数量，并将我的单个蛋糕切成 $N$ 个离散的块，其中 $N \sim 制服\{1,1000\}$。这意味着在任何一天，我都会卖出 0% 到 100% 的巧克力蛋糕，平均值为 80%=p。但当然，如果任何一天 N=1，它就会变成二元，除了全部或全无之外，我永远不会出售任何东西。
我想获得任意给定日/月/年的预期收入的大致范围。 我如何估计某一天我将售出的蛋糕比例的某种区间？
作为一个额外的复杂问题，如果 $p$ 现在是预测而不是已知/估计，那么预测间隔会如何变化？例如，如果通过一些不错但不完美的预测模型，我预测 90% 的周六顾客会想要蛋糕，而不是 80%，该怎么办？
这里还提出了一些其他问题，这些问题在某种程度上属于同一主题，但并不完全相同，例如 此处，和这里。
我已经能够通过模拟 $p$ 和 $N$&lt; 的指定/估计分布来获得估计值/span&gt; 多次并像引导程序一样查看结果，但想知道是否有更严格的方法，特别是如果 $p$ 的分布或$N$ 的预测存在模型错误。如果可以做出一些简化的假设，这似乎可以通过某种比例的贝塔分布来完成，但我不确定那会是什么样子。]]></description>
      <guid>https://stats.stackexchange.com/questions/638621/inference-for-binomial-proportion-with-estimated-p-but-unknown-n</guid>
      <pubDate>Mon, 05 Feb 2024 20:05:17 GMT</pubDate>
    </item>
    <item>
      <title>处理不显着的 beta 系数</title>
      <link>https://stats.stackexchange.com/questions/638618/handling-non-significant-beta-coefficients</link>
      <description><![CDATA[在我们的论文中，我们向参与者（消费者）询问了几个独立因素/变量（例如价格）如何影响购买意愿（依赖因素）。我们使用贝塔系数来分析数据。然而，某些 beta 系数并不显着。关于我们可以如何利用数据来改变这种情况，有什么建议吗？或者，“非重要数据”如何体现？在论文中提出？此外，即使计算中使用的某些 beta 系数并不显着，我们是否可以使用 R 平方得分？
感谢您的帮助。 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/638618/handling-non-significant-beta-coefficients</guid>
      <pubDate>Mon, 05 Feb 2024 19:39:26 GMT</pubDate>
    </item>
    <item>
      <title>用于预测下一个字符的简单 RNN [重复]</title>
      <link>https://stats.stackexchange.com/questions/638617/simple-rnn-for-predicting-the-next-character</link>
      <description><![CDATA[我从头开始实现了一个简单的 RNN（仅使用 numpy 库）来预测下一个字符，并在简单的文本 =“hello world”上对其进行训练。它工作得很好，但我想在非常大的文本上训练它。所以我不知道该怎么训练它。我知道由于消失/爆炸问题，我无法立即在大文本上训练它。所以，我应该小批量地训练它，但我仍然不明白这是如何运作的。网络将如何从所有批次中学习？”
请注意，我从头开始实现了整个 RNN，包括随时间的反向传播，因此我熟悉基础知识。]]></description>
      <guid>https://stats.stackexchange.com/questions/638617/simple-rnn-for-predicting-the-next-character</guid>
      <pubDate>Mon, 05 Feb 2024 19:23:09 GMT</pubDate>
    </item>
    <item>
      <title>如何对不同分布的神经网络的输出进行归一化？</title>
      <link>https://stats.stackexchange.com/questions/638616/how-to-normalise-outputs-of-neural-networks-with-different-distribution</link>
      <description><![CDATA[我有一个可以预测 8 个不同变量的 NN 模型。我使用多任务学习方法，计算 8 个变量中每个变量的预测和目标之间的损失，然后将所有 8 个损失加在一起。然后使用梯度下降最小化损失总和。
输出变量都有不同的物理单位和范围。因此，我想在计算损失之前先对数据进行标准化。但问题是，有些变量是高度偏态的，而有些变量是正态分布（或接近正态分布）的。
我需要确保所有输出都经过标准化，以便它们的值介于特定范围内（例如 0 和 1）。
我的问题是，我应该使用相同的归一化算法还是可以针对不同的输出使用不同的归一化算法？对于极度左偏的数据，建议使用哪些算法？]]></description>
      <guid>https://stats.stackexchange.com/questions/638616/how-to-normalise-outputs-of-neural-networks-with-different-distribution</guid>
      <pubDate>Mon, 05 Feb 2024 18:43:04 GMT</pubDate>
    </item>
    <item>
      <title>具有时间虚拟变量的两个时间段的线性回归与每次两个单独的回归之间有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/638615/what-is-the-difference-between-linear-regression-on-two-time-periods-with-a-time</link>
      <description><![CDATA[我有 50 岁以上个人的两个时间段的面板数据。我有兴趣看看因变量 $X_{it}$（例如年龄、性别、健康状况）的系数是否从一个时间段到另一个时间段发生变化。为此，我对两个时间段都进行了回归，并包含一个时间虚拟变量，如果受访者来自第二个时间段，则该变量等于 1。结果变量是二进制的。
我的回归看起来像这样：
$$
y_{it} = \beta_0 + \gamma X_{it} + \delta (X_{it} \乘以时间) + \varepsilon_{it}
$$
我还尝试分别对每个时间段运行回归，并比较 $X_{i1}$ 和 $X_{i2}$。
$$
y_{i1} = \beta_0 + \gamma X_{i1} + \varepsilon_{i1},
$$
$$
y_{i2} = \beta_0 + \theta X_{i2} + \varepsilon_{i2}
$$
系数与第一个回归中的相同，但标准误差不同。有人可以解释为什么标准错误发生变化吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638615/what-is-the-difference-between-linear-regression-on-two-time-periods-with-a-time</guid>
      <pubDate>Mon, 05 Feb 2024 18:34:59 GMT</pubDate>
    </item>
    </channel>
</rss>