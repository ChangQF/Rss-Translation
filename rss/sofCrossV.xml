<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 20 Jun 2024 03:16:29 GMT</lastBuildDate>
    <item>
      <title>两种实现之间存在数值差异</title>
      <link>https://stats.stackexchange.com/questions/649557/got-numerical-difference-between-two-implementations</link>
      <description><![CDATA[我一直在研究 RetNet（论文：https://arxiv.org/pdf/2307.08621，PyTorch 实现：https://github.com/Jamie-Stirling/RetNet/）。我用 TensorFlow 重写了部分代码：
import tensorflow as tf
from keras import layer
from xpos import XPOS

@tf.keras.utils.register_keras_serializable(&#39;RetNet&#39;)
class SimpleRetention(layers.Layer):
def __init__(self, hidden_​​size, gamma, head_size=None, double_v_dim=False):
super(SimpleRetention, self).__init__()

self.hidden_​​size = hidden_​​size
head_size = head_size if head_size is not None else hidden_​​size
self.head_size = head_size
self.v_dim = head_size * 2 if double_v_dim else head_size
self.gamma = gamma

self.W_Q = layer.Dense(head_size, use_bias=False)
self.W_K =层。密集（头部大小，使用偏差=假）
self.W_V = 层。密集（头部大小，使用偏差=假）

self.xpos = XPOS（头部大小）

def call（self，X）：
Q = self.W_Q（X）
K = self.W_K（X）
V = self.W_V（X）

Q = self.xpos（Q）
K = self.xpos（K，downscale=True）

ret = tf.matmul（Q，K，transpose_b=True）* self._get_D（tf.shape（X）[1]）
return tf.matmul（ret，V）

def call_recurrent（self，x_n，s_n_1，n）：
Q = self.W_Q（x_n）
K = self.W_K（x_n）
V = self.W_V（x_n）

Q = self.xpos(Q, offset=n+1)
K = self.xpos(K, offset=n+1, downscale=True)

s_n = self.gamma * s_n_1 + tf.matmul(K, V, transpose_a=True)
return tf.matmul(Q, s_n), s_n

def _get_D(self, serial_length):
n = tf.range(sequence_length)[:, tf.newaxis]
m = tf.range(sequence_length)[tf.newaxis, :]
D = tf.pow(self.gamma, tf.cast(n - m, dtype=tf.float32))
mask = tf.cast(n &gt;= m, dtype=tf.float32) # 因果掩码
return D * mask

现在我又写了另一个测试用例来验证 call 和 call_recurrent 的输出是否相同，遵循测试用例：
import tensorflow as tf
from retentive import SimpleRetention
import numpy as np
import matplotlib.pyplot as plt

def test_simple():
&quot;&quot;&quot;
验证 SimpleRetention 的三个实现是否相同
&quot;&quot;&quot;
batch_size = 4
sequence_length = 12
hidden_​​size = 6

gamma = 0.9

X = tf.random.uniform((batch_size,sequence_length,hidden_​​size))
sr = SimpleRetention(hidden_​​size,gamma,double_v_dim=True)

Y_parallel = sr(X)

s_n_1 = tf.zeros((batch_size,hidden_​​size,sr.v_dim))
Y_recurrent = []
for i in range(sequence_length):
y_n,s_n = sr.call_recurrent(X[:,i:i+1,:],s_n_1,i)
Y_recurrent.append(y_n)
s_n_1 = s_n

Y_recurrent = tf.concat(Y_recurrent,axis=1)

Yp = Y_parallel.numpy()
Yr = Y_recurrent.numpy()
print(Yp.shape, Yr.shape)

plt.figure()
for i in range(batch_size):
plt.subplot(batch_size // 2, 2, i+1)
error_map = Yp[i] - Yr[i]
plt.imshow(error_map)
plt.title(f&quot;sq error={np.sum(error_map * error_map)}&quot;)
plt.show()

error = np.sum(np.abs(Yp - Yr))
print(f&quot;Error: {error}&quot;)

test_simple()

错误应该非常接近 0.0，但我得到的（绝对）错误相对较大，总体上为 1.27。错误图如下

我不确定这是否是正常情况，如果不是，有人知道可能是什么原因吗？数值差异会损害我的模型的性能吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649557/got-numerical-difference-between-two-implementations</guid>
      <pubDate>Thu, 20 Jun 2024 01:13:47 GMT</pubDate>
    </item>
    <item>
      <title>自治微分方程的解 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649555/solutions-to-autonomous-differential-equations</link>
      <description><![CDATA[我试图理解如何找到这两个自治微分方程的解：
第一个自治微分方程
$\frac{dX}{dt}=aX(1-X)$ 其解应该是：
\begin{align}X_{t}=\frac{X_{0}}{X_{0} + (1 - X_{0})e^{-at}}&amp;\end{align&gt; 假设 $a$ 非常小。
第二个自治微分方程
$\frac{dX}{dt}=aX(X-\frac{1}{2})$ 其解应该是：
\begin{align}X_{t}=\frac{X_{0}}{X_{0} + (1 - X_{0})e^{-at}}&amp;\end{align&gt;解决方案应该是：
\begin{align} X_{t}=\frac{1/2}{1 - (e^{at/2} \cdot (1 - \frac{1}{2X_{0}}))}&amp;\end{align&gt; 假设 $a$ 非常小。
有人可以解释一下获得我提到的解决方案所需的步骤是什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649555/solutions-to-autonomous-differential-equations</guid>
      <pubDate>Thu, 20 Jun 2024 00:33:46 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归分析中，判定系数为 0.99，但残差不呈正态分布。我该如何解释这一点？</title>
      <link>https://stats.stackexchange.com/questions/649554/on-a-linear-regression-analysis-the-determination-coefficient-is-0-99-but-the</link>
      <description><![CDATA[首先我想说的是，这是家庭作业，我不太擅长统计。请像对待 5 岁孩子一样向我解释。而且英语不是我的母语。
因此，家庭作业中有一列是公司在 50 个月期间每月在营销上花费的金额，以及他们在相同 50 个月期间每月的销售额。营销支出是独立变量，销售的产品单位是因变量。使用 excel 上的数据分析选项卡进行回归分析后，显示判定系数为 0.99。根据我上课的笔记，判定系数可以显示模型是否良好，并且越接近数字 1 越好。
但我的笔记还说，如果残差不是正态分布，线性回归不是正确的模型，并且这些残差的平均值必须为 0。在这种情况下，残差不是正态分布的。根据互联网，峰度需要为 3 或更低才能为正态分布，在本例中约为 7。残差的平均值也不为 0。它是 -2.8422E-15，非常接近 0，但实际上并非为 0。
Excel 显示，除第 49 个月（为 -4.39）外，标准化残差都在 -3 和 3 的范围内。帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/649554/on-a-linear-regression-analysis-the-determination-coefficient-is-0-99-but-the</guid>
      <pubDate>Thu, 20 Jun 2024 00:28:48 GMT</pubDate>
    </item>
    <item>
      <title>对模型训练中看到的数据以及新数据进行混合效应模型预测的引导置信度和预测区间</title>
      <link>https://stats.stackexchange.com/questions/649552/bootstrap-confidence-and-prediction-intervals-of-mixed-effect-model-predictions</link>
      <description><![CDATA[假设我使用 lme4 R 库拟合了混合效应模型 mem，并且我想使用 bootMer 函数来计算模型在训练期间看到的一些数据的置信度和预测区间。在这种情况下，我可以包含随机效应（以及固定效应）来计算 mem 的置信度和预测区间，例如 95% 的置信度。
对于预测区间，此 https://www.wavedatalabs.com.au/posts/2023-02-06-prediction-intervals-for-linear-mixed-effects-models/ 源建议定义一个以所有随机效应为条件的预测函数
predfn &lt;- function(.) { predict(., newdata=new, re.form=NULL) }

然后在bootMer 调用，其中 re.form=NULL
boot &lt;- lme4::bootMer(mem, FUN=predfn, nsim=250, re.form=NULL, type=&quot;parametric&quot;)

问题 1) 以上内容正确吗？那么置信区间呢？更具体地说：在 bootMer 中，如何选择 re.form 和 FUN 参数来估计置信区间？
现在让我们假设我们想要计算 mem 对新数据（训练期间未见）的预测的置信度和预测区间，置信度为 95%。在这种情况下，不能考虑随机效应。对于预测区间，我上面链接的同一来源建议定义一个新函数来重新采样来自 mem 的响应（而不是重新采样确定性模型预测）
sfun &lt;- function(.) {
mock(., newdata=new_data, re.form=NULL, allow.new.levels=TRUE)[[1]]
}

然后在 bootMer 调用中使用它
boot &lt;- lme4::bootMer(mem, FUN=sfun, nsim=250, re.form=~0, type=&quot;parametric&quot;, seed=100)

问题 2)：为什么在 sfun 中使用 re.form=NULL？另外：在这种情况下，bootMer 的 re.form 和 FUN 参数的适当选择是什么，以估计 new_data 的置信区间
任何帮助表示感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649552/bootstrap-confidence-and-prediction-intervals-of-mixed-effect-model-predictions</guid>
      <pubDate>Wed, 19 Jun 2024 23:26:22 GMT</pubDate>
    </item>
    <item>
      <title>不同情况下的 LSTM 和 MLP 分布函数[重复]</title>
      <link>https://stats.stackexchange.com/questions/649551/distribution-function-of-lstm-and-mlp-for-different-cases</link>
      <description><![CDATA[我问过这个问题（可以视为案例1），MLP在TEC预测方面不如LSTM。可以观察到，LSTM预测的TEC曲线与观察到的TEC曲线（即ground truth）非常接近，而MLP预测的曲线与ground truth之间存在相当大的差距。
下面还有另外两种TEC曲线的变化：
案例2：从2015/6/18到2015/6/23，TEC的变化非常复杂。除了周期性变化外，在某个时期还存在强烈的扰动。在这种情况下，LSTM 可以捕捉周期性变化，从而给出更好的预测，然而，MLP 的方向完全错误。与 MLP 相比，由于记忆单元的存在，LSTM 具有预测长序列数据的优势。LSTM 可以学习序列数据的长依赖关系，不仅是过去的时刻，而且还考虑了一段历史。而 MLP 不利用历史信息，因此在 TEC 发生动荡的情况下可能会失败。
情况 3：
如果 TEC 突然变化，例如图 6 所示的情况，过去五天观察到的 TEC 峰值很大，而第二天急剧变低。在这种情况下，RMS 误差变得显著。


上面，我们讨论了 TEC 变化的三种情况，其中 LSTM 的表现都优于 MLP。这一成就归功于 LSTM 的特殊设计，因此它可以学习序列数据的长依赖关系。由此可以了解序列数据元素之间的相互作用和关系，从而更好地表示输入数据。
我的问题是：通过查看上述三种情况下的 LSTM 和 MLP 曲线，我们可以说明什么？是否可以根据上述三种情况下的曲线为 LSTM 和 MLP 定义合适的分布函数？三种情况下是否有可能通过分布进行数学表示？]]></description>
      <guid>https://stats.stackexchange.com/questions/649551/distribution-function-of-lstm-and-mlp-for-different-cases</guid>
      <pubDate>Wed, 19 Jun 2024 22:11:19 GMT</pubDate>
    </item>
    <item>
      <title>$\min\{X,Y\}$；其中 $X,Y$ 是几何随机变量</title>
      <link>https://stats.stackexchange.com/questions/649550/min-x-y-where-x-y-are-geometric-random-variables</link>
      <description><![CDATA[
$\min\{X,Y\}$ 是否服从几何分布？$X \sim BN(1,p); Y \sim BN(1,q)$ 独立

$$P(\min\{X,Y \}=k)=P( \min\{X,Y\} \geq k)-P(\min\{X,Y \} \geq k+1)=\sum_{n=k}^{\infty}(1-p)^{n-1}p\sum_{n=k}^{\infty}(1-q)^{n-1}q-\sum_{n=k+1}^{\infty}(1-p)^{n-1}p\sum_{n=k+1}^{\infty}(1-q)^{n-1}q=(1-p)^{k-1}(1-q)^{k-1}-(1-p)^{k}(1-q)^{k}=[(1-p)(1-q)]^{k-1}(1-(1-p)(1-q))$$
因此：
$$\min\{X,Y \} \sim BN(1,1-(1-p)(1-q))$$]]></description>
      <guid>https://stats.stackexchange.com/questions/649550/min-x-y-where-x-y-are-geometric-random-variables</guid>
      <pubDate>Wed, 19 Jun 2024 22:00:26 GMT</pubDate>
    </item>
    <item>
      <title>根据 R 中的多列创建是、否和未知的列 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649549/create-columns-for-yes-no-and-unknown-based-on-multiple-columns-in-r</link>
      <description><![CDATA[我有 5 列，每列代表一个不同的变量，值可以是“是”、“否”或“未知”。我想创建一个 flextable，将变量显示为行，并将“是”、“否”和“未知”显示为行。作为带有计数和百分比的列。
ID 温度 咳嗽 流鼻涕 体重减轻 寒冷
1 是 否 是 否 是
2 是 是 未知 是 是
3 是 未知 否 否 否
4 是 是 是 是 是
5 否 否 否 否

我希望输出看起来像这样：
 是 否 未知
n % n % n %
温度 4 80 1 20 0 0
咳嗽 2 40 1 20 2 40
流鼻涕 2 40 2 40 1 20
体重减轻 2 40 3 60 0 0
寒冷 3 60 2 40 0 0

我知道我需要在这里的某个地方使用数据透视表，但我对如何映射变量以及如何创建双行标题感到困惑计算百分比。]]></description>
      <guid>https://stats.stackexchange.com/questions/649549/create-columns-for-yes-no-and-unknown-based-on-multiple-columns-in-r</guid>
      <pubDate>Wed, 19 Jun 2024 21:57:19 GMT</pubDate>
    </item>
    <item>
      <title>聚类标准误差-直观解释</title>
      <link>https://stats.stackexchange.com/questions/649547/clustered-standard-error-intuitive-explanation</link>
      <description><![CDATA[我理解标准误差是关于某些参数的抽样分布的标准偏差，例如样本均值或回归模型中的系数。
我还知道，当您的数据不符合独立性假设时，例如随机化单元之间的地理或时间关系，我们需要在满足独立性假设的最低级别“聚类”估计参数的标准误差。
让我们以时间为例。假设我们有 RCT 中各种随机化单元的面板数据。因为 $y_t$ 不独立于 $y_{t-1}$，所以我们不能声称独立。因此，我们的样本量不能是 $NT$，而是 $N$。
我相信我已经牢牢掌握了原因。我挣扎的是如何。在这种情况下，我们如何聚类标准误差？聚类标准误差是合并标准误差的概括，包括几个单位（而不是两个）吗？
我们的方法是否因我们试图推断观察到的参数（例如平均值）与潜在参数（例如回归系数$\beta$）而有所不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/649547/clustered-standard-error-intuitive-explanation</guid>
      <pubDate>Wed, 19 Jun 2024 20:13:06 GMT</pubDate>
    </item>
    <item>
      <title>导出 R 预测输出 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649545/export-r-prediction-output</link>
      <description><![CDATA[一个基本问题 - 我想将 R 中运行的特定模型的所有预测结果（预测的因变量值、残差等）+ 原始输入数据列导出到单个外部 .csv。可以吗？如果 .csv 只有预测结果，我可以合并。
如果可以，那么我的第二个问题是 - 我的输入数据中还有 2 列带有地理坐标，因此当我创建训练和测试数据进行验证时，我是否能在导出数据的 .csv 中的原始行中获得完全相同的预测结果。我问这个问题的原因是我想在单独的地图软件中创建空间地图，其中 .csv 包含所有数据列。]]></description>
      <guid>https://stats.stackexchange.com/questions/649545/export-r-prediction-output</guid>
      <pubDate>Wed, 19 Jun 2024 19:47:08 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 OPLS-DA 中的累计 Q2</title>
      <link>https://stats.stackexchange.com/questions/649541/how-to-calculate-cumulative-q2-in-opls-da</link>
      <description><![CDATA[在SIMCA 用户指南中，$p.517$，累计$Q^2$通过以下方式计算：
$$
Q^2(\text{cum})=1−∏_{a=1}^{N_\text{comp}} \left( \frac{PRESS}{SS} \right)_a \tag{1}
$$
其中$∏_{a=1}^{N_\text{comp}}(PRESS/SS)_a$是每个单独组件 $a$ 的 $PRESS/SS$ 乘积。
这让我很困惑。OPLS 模型表示为（请参阅此处的介绍）：
$$
X=t_1p_1^T+T_OP_O^T+E \tag2
$$
或由 J. Trygg 的论文
$$
X=T_pP_p^T+T_OP_O^T+E \tag3
$$
并且从预测成分中预测出一个新的 $y$。
据我所知，

每个单独的成分 $a$

应该参考预测成分，因为所有预测都应该来自 $X$，并通过正交得分 $T_O$ 和载荷 $P_O$ 进行校正，即，$X_P=X-T_OP_O^T$。交叉验证用于确定正交分量的数量。因此，对于新矩阵$X_\text{new}$，它也由正交分量进行校正，然后用于使用预测分量进行预测。但根据方程$(2)$，预测分量的数量为 1。问题是如何计算每个单独分量$a$的$PRESS/SS$？
如果我错了，我应该尝试使用单个交叉验证循环同时获得正交分量的数量和预测分量的数量。这意味着，对于每个正交分量的数量（例如从 1 到 15），我应该遍历每个预测分量的数量（例如从 1 到 15），以便可以确定正交分量的数量和预测分量的数量（如果正交和预测分量的最大数量为 $15$，则应该尝试总共 $15^2=225$ 次循环）。但我不确定这是否正确，因为这个过程有点复杂，我找不到任何提到这方面的材料。
那么如何正确理解这个术语

每个单独的组件$a$

并正确计算$Q^2(\text{cum})$？]]></description>
      <guid>https://stats.stackexchange.com/questions/649541/how-to-calculate-cumulative-q2-in-opls-da</guid>
      <pubDate>Wed, 19 Jun 2024 18:51:47 GMT</pubDate>
    </item>
    <item>
      <title>层次多元回归分析 - 交互作用</title>
      <link>https://stats.stackexchange.com/questions/649540/hierarchical-multiple-regression-analysis-interaction-effect</link>
      <description><![CDATA[我目前正在进行一个研究项目，但我得到的结果是让我很困惑的。
要检验的假设是：自我效能 (Centered_KOMP) 正在调节神经质 (CENTERED_NEUR) 和工作意义 (SUM_ME_WORK) 之间的负相关关系。我在第一步中只使用了主效应，然后在第二步中添加了交互效应。
在第一步中，两个主效应都很重要。在第二个具有交互作用的模型中，自我效能对工作意义的主效应变得不显著。但是交互作用是显著的。
我的一位导师说这是一个不寻常的结果，这让我对解释这种影响感到不安。我的问题是：
我该如何解释这个结果？
这个结果的解释是什么？标准差和范围（可变性）是否可以解释这一点？ （CENTERED_NEUR 的 SD = 26.14；高范围 (107) = 高变异性？）（CENTERED_KOMP 的 SD = 5.34，范围为 21 -&gt; 变异性较低？）神经质量表包含 20 个项目，选项范围从 1 - 7，自我效能量表包含 6 个项目，选项范围从 1-5）
到目前为止，我的解释是这样的，但我非常不确定这是否正确：交互作用可能解释了自我效能的主要影响之前所解释的大部分变异性。自我效能的影响可能只在某些神经质水平上显着（虽然我不确定，因为这是否也意味着神经质也是一个调节因素？）
非常感谢您的帮助！！！]]></description>
      <guid>https://stats.stackexchange.com/questions/649540/hierarchical-multiple-regression-analysis-interaction-effect</guid>
      <pubDate>Wed, 19 Jun 2024 18:47:48 GMT</pubDate>
    </item>
    <item>
      <title>如何评估多场比赛的结果是否符合各自状态的概率分布</title>
      <link>https://stats.stackexchange.com/questions/649538/how-to-evaluate-whether-the-results-of-multiple-games-conform-to-the-probability</link>
      <description><![CDATA[有n局游戏，每局游戏开始后都有一个状态，根据这个状态可以计算出游戏结果的概率，比如有3种结果，概率分别是p1，p2，p3，但是下一局游戏状态不一样，概率就变了，变成了p4，p5，p6，打n局，就有n个结果，那么如何判断这n个结果整体上是否符合这些概率呢？
我也不知道，也许可以用卡方检验，但是条件好像不满足？]]></description>
      <guid>https://stats.stackexchange.com/questions/649538/how-to-evaluate-whether-the-results-of-multiple-games-conform-to-the-probability</guid>
      <pubDate>Wed, 19 Jun 2024 15:56:07 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测的预言库存在的问题</title>
      <link>https://stats.stackexchange.com/questions/649525/problems-with-prophet-library-for-time-series-forecasting</link>
      <description><![CDATA[我有一个很小的数据框，包含两列：time_key，即日期；value，即衡量超市收入的数值变量。这个数据框定义了一个时间序列，我有 16 个月的数据。我正在尝试获取过去 3 个月的预测。
我正在使用 R 中的 fable 和 fable.prophet 库。虽然这是一个小例子，但这个想法是这个过程将自动执行到几十个类似的数据框，所以我的想法是，对于每个数据框，自动计算、优化和比较不同的模型，并选择最小化准确率的模型。以下是我的数据概览：
sales.ts
time_key 值
1 2020-03-01 292.7846
2 2020-04-01 292.2414
3 2020-05-01 296.0398
4 2020-06-01 286.3656
5 2020-07-01 284.5536
6 2020-08-01 272.8100
7 2020-09-01 272.8052
8 2020-10-01 326.2926
9 2020-11-01 306.6977
10 2020-12-01 370.4489
11 2021-01-01 323.3679
12 2021-02-01 308.2357
13 2021-03-01 346.5880
14 2021-04-01 331.0101
15 2021-05-01 303.5761
16 2021-06-01 204.9440

以下脚本在数据上构建 ARIMA、ETS 和 Prophet 模型并进行比较：
library(tidyverse)
library(tsibble)
library(fable)
library(prophet)
library(fable.prophet)

fit &lt;- sales.ts %&gt;%
mutate(time_key = yearmonth(time_key)) %&gt;% 
as_tsibble(index = time_key) %&gt;%
model(
ets = ETS(value),
arima = ARIMA(value),
prophecy = prophecy(value))

fc &lt;- fit %&gt;% prediction(h = 3)

fc %&gt;% autoplot(sales.ts)

您可以在此处查看结果。

正如您所见，似乎没有什么希望。我的问题是：

prophecy 到底发生了什么？特别是因为如果我调用 fit %&gt;% accuracy() 命令，prophet 会显示错误 0。
您对如何改进这一点有什么建议吗？

我知道可能有很大空间来优化指示趋势和季节性等模式的模型（尽管这些特定数据没有显示太多），但我需要这个过程是自动化的，所以我不能逐个数据集地微调模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/649525/problems-with-prophet-library-for-time-series-forecasting</guid>
      <pubDate>Wed, 19 Jun 2024 13:58:35 GMT</pubDate>
    </item>
    <item>
      <title>二次插值的不确定性传播</title>
      <link>https://stats.stackexchange.com/questions/649523/uncertainty-propagation-for-quadratic-interpolation</link>
      <description><![CDATA[我有时间序列数据$(t_i, y_i)$，不确定性为$\Delta y$。我需要插入此数据，以使时间戳与另一个数据集的时间戳相匹配。
理论
为了传播不确定性，我确实找到了参考。重点是第 2 节：
对于某些插值函数 $\hat y = S(t, a_1,\dots,a_N)$，其插值值 $\hat y = S(t, a_1,\dots,a_N)$ 的不确定性，该插值函数拟合为 $\left[(t_1, y_1),\dots,(t_N, y_N)\right]$，可以使用
$$
\Delta \hat y^2 = \sum_{i=1}^N \left( \frac{\partial S}{\partial t_i} \right)^2 \Delta t_i^2 + \sum_{i=1}^N \left( \frac{\partial S}{\partial y_i} \right)^2 \Delta y_i^2 .
$$
到目前为止，一切都很标准。现在到了有趣的部分：我们可以计算
$$
\frac{\partial S}{\partial t_i} = \left. -\frac{\partial S}{\partial t} \right|_{t=t_i} \sum_{j=1}^N M^{-1}_{ij}\frac{\partial S}{\partial a_j}
$$
和
$$
\frac{\partial S}{\partial y_i} = \sum_{j=1}^N M^{-1}_{ij}\frac{\partial S}{\partial a_j}
$$
与
$$
M_{ij} = \left. \frac{\partial S}{\partial a_i} \right|_{t=t_j}
$$
让我们应用它吧！
我只对$y$有不确定性（因为时间戳被认为是正确的）。我的插值函数是二阶多项式：
$$
S(t, a_1, a_2, a_3) = a_1 + a_2t + a_3t^2
$$
结果为
$$
\Delta \hat y^2 = \sum_{i=1}^N \left( \frac{\partial S}{\partial y_i} \right)^2 \Delta y_i^2
$$
$$
\frac{\partial S}{\partial y_i} = \sum_{j=1}^N M^{-1}_{ij}\frac{\partial S}{\partial a_j}
$$
$$
M = \begin{bmatrix}
1 &amp; 1 &amp; 1 \\
t_1 &amp; t_2 &amp; t_3 \\
t_1^2 &amp; t_2^2 &amp; t_3^2 \\
\end{bmatrix}\\
$$
$$
\frac{\partial S}{\partial a} = \begin{bmatrix}
1 \\
t \\
t^2 \\
\end{bmatrix}
$$
代码
我写了一个小脚本来检查算法。
import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import make_interp_spline

@np.vectorize(excluded=[1, 2])
def calc_err(t_new, t, yerr):
M = np.array([np.ones_like(t), t, t**2])
M_inv = np.invert(M)
S_a = np.array([1, t_new, t_new**2])

return np.sqrt((((M_inv @ S_a) * yerr) ** 2).sum())

def plot(t, y, delta_y):
t_hat = np.linspace(t[0], t[-1])
f = make_interp_spline(t, y, k=2)
y_hat = f(t_hat)

delta_y_hat = calc_err(t_hat, t, delta_y)

plt.title(&quot;线性插值的不确定性传播&quot;)
plt.errorbar(t, y, yerr=delta_y, fmt=&quot;.&quot;, c=&quot;black&quot;, barsabove=True, capsize=10, 标签=&quot;$y$&quot;)
plt.plot(t_hat, y_hat, c=&quot;gray&quot;, 标签=&quot;$\hat y$&quot;)
plt.plot(t_hat, y_hat + delta_y_hat, &quot;--&quot;, c=&quot;red&quot;, 标签=&quot;$\Delta \hat y$&quot;)
plt.plot(t_hat, y_hat - delta_y_hat, &quot;--&quot;, c=&quot;red&quot;)
plt.legend()

plot(np.array([1, 2, 3]), np.array([3.1, 4.1, 1.6]), np.array([0.7, 0.4, 0.6]))

但遗憾的是，由此产生的不确定性看起来不正确，而且太大了（我假设在 $t_i$ 时不确定性应该是 $\Delta y_i$）。我做错了什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/649523/uncertainty-propagation-for-quadratic-interpolation</guid>
      <pubDate>Wed, 19 Jun 2024 13:53:23 GMT</pubDate>
    </item>
    <item>
      <title>如何找出两个风险比（风险比的比率）之间的差异</title>
      <link>https://stats.stackexchange.com/questions/649510/how-to-find-difference-between-two-hazard-ratios-ratio-of-hazard-ratios</link>
      <description><![CDATA[我正在阅读荟萃分析，在这篇论文中，作者以某种方式比较了每项研究中两组不同治疗方案的 HR。据我所知，我们可以通过 OR、RR、SMD 比较两组不同治疗方案的结果，但我不明白如何比较两个风险比并找到“风险比”。直观地说，我想说实际上作者在研究中的森林图上表示的是 OR，但作者写道它是图上的 HR。此外，如果有一种方法可以比较两个风险比并找出它们之间的差异，特别是在 Rstudio 中，我恳请您帮助我了解如何执行此操作。]]></description>
      <guid>https://stats.stackexchange.com/questions/649510/how-to-find-difference-between-two-hazard-ratios-ratio-of-hazard-ratios</guid>
      <pubDate>Wed, 19 Jun 2024 11:49:01 GMT</pubDate>
    </item>
    </channel>
</rss>