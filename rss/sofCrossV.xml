<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 06 Sep 2024 01:11:30 GMT</lastBuildDate>
    <item>
      <title>如何计算多个 MCMC 链的积分自相关时间 (IAT)？</title>
      <link>https://stats.stackexchange.com/questions/653944/how-to-calculate-integrated-autocorrelation-time-iat-for-multiple-mcmc-chains</link>
      <description><![CDATA[我正在并行运行多个马尔可夫链蒙特卡罗 (MCMC) 链，并且我想计算整体样本的积分自相关时间 (IAT)。虽然我理解如何基于自相关函数 $ \rho(t) $ 计算单个链的 IAT，但我不确定如何处理多个链。
以下是我不清楚的一些具体要点：

我是否应该分别计算每个链的自相关函数 $\rho(t)$，然后对各个链的 IAT 取平均值？
如果链未达到相同的平稳分布（例如，如果 R-hat 统计量远离 1），推荐的方法是什么？

任何参考资料或示例实现（使用 Python 或 R）也会有所帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/653944/how-to-calculate-integrated-autocorrelation-time-iat-for-multiple-mcmc-chains</guid>
      <pubDate>Fri, 06 Sep 2024 01:02:25 GMT</pubDate>
    </item>
    <item>
      <title>风力发电 PDF</title>
      <link>https://stats.stackexchange.com/questions/653943/wind-generation-pdf</link>
      <description><![CDATA[我有实时风力发电和风力发电预测的历史。利用这些信息，是否可以得出方差或标准差等指标？
我不认为风力发电呈正态分布，但我怀疑它可能呈对数正态分布。有没有办法计算统计数据，显示根据历史数据预测的误差可能有多大，或者实时发电量与预测发电量之间的偏差有多大？]]></description>
      <guid>https://stats.stackexchange.com/questions/653943/wind-generation-pdf</guid>
      <pubDate>Fri, 06 Sep 2024 00:17:04 GMT</pubDate>
    </item>
    <item>
      <title>基于上下文词的词语相似度公式</title>
      <link>https://stats.stackexchange.com/questions/653937/words-similarity-formula-based-on-the-context-words</link>
      <description><![CDATA[我正在研究我的词嵌入计算算法，但遇到了一个相似度公式。
我认为这可以通过统计和概率轻松地正式推导出来，但我做不到。你能帮忙吗？
给定
词素（我们将其命名为并置词素或colex）在文本中（在不同位置）紧接着感兴趣的词素，我们将它们称为lex1和lex2*。
我知道：

lex1跟随colex的次数（Lex1FollowCount）。
lex2跟随colex的次数（Lex2FollowCount）。
对于每个lex1、lex2、colex，我知道它们在文本中出现的次数（*InText）。

目标
根据以上信息，我想计算一些值（最好在[0,1] 范围）反映了词法单元 lex1 和 lex2 的相似程度。我正在寻找概率论的正式推导。包括，我试图解决什么样的概率论任务，我缺少什么以及如何解决它。更正式一点，当所有 colex 词法单元以相同的概率与 lex1 和 lex2 搭配时，两个词法单元是相似的（相似度 = 1）。
有一件事让它变得更难。我理解至少应该有两个结果：相似性和置信度，最后一个应该基于考虑的搭配的数量，但目前我想将它们打包成一个结果，即相似性。
因此，如果对于大文本，我有一个完美的搭配（如上例所示），这种搭配在文本中很少发生（Lex1FollowCount = 3，Lex2FollowCount=5，等等），我希望相似度的值仍然很低。因此，只有在文本中多次出现确认匹配度高的情况下，最终相似度才会很高。
我的最佳猜测
我确信该公式可以正式推导，但我没有这样做，所以我目前使用了我最好的猜测：
$$ P_{lex1} = \frac{ Lex1FollowCount }{ Lex1InText } $$
$$ P_{lex2} = \frac{ Lex2FollowCount }{ Lex2InText } $$
$$ P_{correlated} = P_{lex1} * P_{lex2} $$
$$ 相似度 = P_{correlated} * min(Lex1InText, Lex2InText ) $$
实际上，它有效并且给出了“足够好”的结果，但如果使用更好的公式，仍然可以改进。
我的公式存在问题以及需要考虑的问题
这个公式很难规范化。
在实际文本中，两种项目没有太大帮助：（a）稀有项目，这由最后一个公式中的乘法处理；稀有项目的结果较少；（b）非常频繁的项目（如“and”、“or”等），它们有很多含义，但在大多数语言中对词语相似度计算没有帮助。因此，如果最常见项目的“权重”也很低，那就太好了。
我尝试了几十个受量化词袋的相似性和类似算法启发的公式，但似乎我的任务要简单得多，最终可以形式化。如果不是，请帮助我找到我所遇到的真正问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/653937/words-similarity-formula-based-on-the-context-words</guid>
      <pubDate>Thu, 05 Sep 2024 20:53:48 GMT</pubDate>
    </item>
    <item>
      <title>使用外生变量进行时间序列预测的困难</title>
      <link>https://stats.stackexchange.com/questions/653934/difficulties-in-using-exogenous-variables-for-time-series-forecasting</link>
      <description><![CDATA[在使用外生变量进行时间序列建模时，我有点困惑。假设我正在建模房价，我的一个外生变量是“房屋类型”，其值为“单元”或“房屋”。当预测未来时，预测的值显然是房价。
我该如何确定未来房屋类型的价值？我是否应该为每种房屋类型训练 2 个单独的模型并完全丢弃变量？或者我只是不尝试假设“房屋类型”的值是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/653934/difficulties-in-using-exogenous-variables-for-time-series-forecasting</guid>
      <pubDate>Thu, 05 Sep 2024 19:16:36 GMT</pubDate>
    </item>
    <item>
      <title>ARCH 模型是否对之前的时间序列值或其残差进行回归？</title>
      <link>https://stats.stackexchange.com/questions/653932/is-an-arch-model-regressed-over-previous-time-series-values-or-their-residuals</link>
      <description><![CDATA[假设我们有一个时间序列$\{y_t\}$，我们希望使用 ARCH 或 GARCH 模型对其进行建模。也就是说，我们假设时间序列可以写成以下形式：
$$y_t = \mu_t + \epsilon_t$$
其中 $\mu_t$ 是时间 $t$ 的条件均值，可以通过例如 ARMA 模型和 $\epsilon_t \sim \mathcal{D}(0, \sigma_t^2)$ 估计，其中 $\mathcal{D}$ 为任意分布。
ARCH 和 GARCH 模型的要点都是对条件方差 $\sigma_t^2$ 进行建模。如果我们使用 ARCH 模型，那么我们的想法是使用 AR 模型对 $\sigma_t^2$ 进行建模。这意味着，对于 ARCH(1) 模型：
$$\sigma_t = \alpha_0 + \alpha_1 y_{t-1}。 \tag{1}$$
但是其他来源，例如维基百科，指出我们不对滞后$y_t$项进行回归，而是对滞后残差$\epsilon_t$进行回归：
$$\sigma_t = \alpha_0 + \alpha_1 \epsilon_{t-1} \tag{2}.$$
对于任一模型，都可以使用 OLS 找到参数。
我对上述内容有两个问题：

哪个是正确的 ARCH 模型，(1) 还是 (2)？换句话说，我们应该回归之前的时间序列值$y_t$还是残差$\epsilon_t$？
$\epsilon_t$是不可观察的创新。我读到，在实践中，如果我们使用模型 (2)，那么我们可以将$\epsilon_{t-1}$估计为$\hat{y}_{t-1} - y_{t-1}$。这是真的吗？如果是，有什么理由这样做？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653932/is-an-arch-model-regressed-over-previous-time-series-values-or-their-residuals</guid>
      <pubDate>Thu, 05 Sep 2024 18:47:01 GMT</pubDate>
    </item>
    <item>
      <title>基于 eviews 的货币政策 ARDL 模型研究</title>
      <link>https://stats.stackexchange.com/questions/653931/ardl-model-on-monetary-policy-study-on-eviews</link>
      <description><![CDATA[我实际上正在撰写关于货币政策传导的硕士论文，我对我的 ARDL 方法的结果表示怀疑。我有 4 个模型（1 个基准和 3 个替代方案）
有人可以看一下吗？！！
我的导师说没问题，但他实际上并没有读过。

[
]]></description>
      <guid>https://stats.stackexchange.com/questions/653931/ardl-model-on-monetary-policy-study-on-eviews</guid>
      <pubDate>Thu, 05 Sep 2024 18:45:28 GMT</pubDate>
    </item>
    <item>
      <title>KS 检验与最大似然拟合相矛盾</title>
      <link>https://stats.stackexchange.com/questions/653930/ks-test-contradicts-maximul-likely-hood-fitting</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653930/ks-test-contradicts-maximul-likely-hood-fitting</guid>
      <pubDate>Thu, 05 Sep 2024 18:21:03 GMT</pubDate>
    </item>
    <item>
      <title>参数数量与数据维数关系的来源</title>
      <link>https://stats.stackexchange.com/questions/653929/source-of-the-relationship-between-the-number-of-parameters-and-data-dimensional</link>
      <description><![CDATA[人们普遍认为，在经典统计模型中，观测值的数量应至少等于参数的数量，以确保这些参数的可估计性，例如，如果我们想要获得 MLE。否则，某些参数是不可估计的。当然，在神经网络等中情况并非如此。
我曾从秩的角度看到过线性回归或线性代数的解释。
我想问一下，是否有人可以在更通用的设置中找到这个的来源。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653929/source-of-the-relationship-between-the-number-of-parameters-and-data-dimensional</guid>
      <pubDate>Thu, 05 Sep 2024 18:06:20 GMT</pubDate>
    </item>
    <item>
      <title>具有极不平衡随机变量的混合方差分析</title>
      <link>https://stats.stackexchange.com/questions/653922/mixed-anova-with-extremely-unbalanced-random-variable</link>
      <description><![CDATA[我有一个因变量 y（浓度）、一个独立分类变量（菌株）和一个随机变量（日期）。
当我运行简单的单向方差分析时，我的独立变量菌株不显著（pval=0.3），我的 AIC=158。
当我在模型中添加日期作为随机效应（R 中 lmer 函数中的 +(1|日期)）时，菌株似乎很显著（pval=0.013），随机效应日期也很显著（使用 R 中的 ranova，pval=0.008），但 AIC 更高（160）。
我有两个问题：

我应该考虑 ranova 的 p 值（0.008）并保留模型中的随机效应还是考虑到 AIC 将其删除？
我的随机效应极其不平衡（见下图，颜色代表不同的菌株y 是浓度）。对于某些日期，我只有一个菌株，或者某些菌株只有一个值。对于大多数日期，我只有 5 个菌株中的 3 个。这是个问题吗？


我找不到关于非常不平衡的随机变量是否是个问题的明确答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/653922/mixed-anova-with-extremely-unbalanced-random-variable</guid>
      <pubDate>Thu, 05 Sep 2024 15:24:26 GMT</pubDate>
    </item>
    <item>
      <title>如何判断一名玩家在多人游戏中是否表现更佳？</title>
      <link>https://stats.stackexchange.com/questions/653918/how-to-tell-if-one-player-is-significantly-better-at-a-multi-player-game</link>
      <description><![CDATA[我构建了一个扑克模拟，并让 6 个机器人互相玩了很多游戏（随机就座，始终是相同的六个），您如何确定一个玩家是否明显优于其他玩家？
https://www.science.org/doi/10.1126/science.aay2400 使用 T 检验，但我对两件事有点困惑：
需要独立……玩家不是高度依赖于其他玩家的表现吗？所以我需要进行配对 T 检验，对吗（论文中没有说明）？
假设我想比较前两名玩家。这是否只是在配对 T 检验中比较每个玩家的问题？我举了一个例子来说明在 Python 中这可能是什么样子：
import pandas as pd
import numpy as np
from scipy import stats

##### 可重复性的种子
np.random.seed(42)

##### 游戏数量
n_games = 20

##### 创建一个空的 DataFrame
data = {
&#39;game&#39;: range(1, n_games + 1),
&#39;good&#39;: [0] * n_games,
&#39;bad&#39;: [0] * n_games,
&#39;random_1&#39;: [0] * n_games,
&#39;random_2&#39;: [0] * n_games,
&#39;random_3&#39;: [0] * n_games,
&#39;random_4&#39;: [0] * n_games,
}

df = pd.DataFrame(data)

##### 每场比赛随机选择一名获胜者
winners = np.random.choice([&#39;good&#39;, &#39;bad&#39;, &#39;random_1&#39;, &#39;random_2&#39;, &#39;random_3&#39;, &#39;random_4&#39;], size=n_games)

##### 为每场比赛指定获胜者
for i in range(n_games):
df.loc[i, winnings[i]] = 1

##### 在“好”和“坏”之间执行配对 t 检验
t_stat, p_value = stats.ttest_rel(df[&#39;good&#39;], df[&#39;bad&#39;])

##### 显示 DataFrame 和测试结果
print(df)
print(f&quot;t-statistic: {t_stat}, p-value: {p_value}&quot;)

```]]></description>
      <guid>https://stats.stackexchange.com/questions/653918/how-to-tell-if-one-player-is-significantly-better-at-a-multi-player-game</guid>
      <pubDate>Thu, 05 Sep 2024 14:48:26 GMT</pubDate>
    </item>
    <item>
      <title>百分比比较和数量级</title>
      <link>https://stats.stackexchange.com/questions/653917/percentages-comparison-and-order-of-magnitude</link>
      <description><![CDATA[也许这是一个过于简单的问题。
假设有以下两个案例：
案例 1：患者人数/患者总数：63.080/1.335.636 = 4.7%
案例 2：患者人数/患者总数：5.840.431/59.030.133 = 9.8%
我如何比较这两个百分比？换句话说，如果可以将案例 1 的分子和分母设置为与案例 2 具有相同的数量级，或者最好是反之亦然，那么它们可能并没有太大的不同。既然如此，它们当然是不同的，因为数量级不同。
有人能帮帮我吗？
提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/653917/percentages-comparison-and-order-of-magnitude</guid>
      <pubDate>Thu, 05 Sep 2024 14:46:51 GMT</pubDate>
    </item>
    <item>
      <title>做t检验时，样本标准差应该用样本均值减去原假设均值来估计吗？</title>
      <link>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</link>
      <description><![CDATA[以 t 检验为例，检验实数样本$x_i$是否来自均值为 0 的分布（$H_0:\mu=0, H_a:\mu \neq 0$）。检验统计量将是$t=\frac{\bar{x}}{s/\sqrt{n}}$。
我的问题是$s^2=\frac{\Sigma_i(x_i - \bar{x})^2}{n-1}$还是$s^2=\frac{\Sigma_i x_i^2}{n}$。
在大多数文本中我看到前者，但在财务数据的背景下我有时看到后者。两者似乎也都有意义，前者使用正态样本标准差公式，后者使用零假设，也不再需要贝塞尔校正。
两者的优缺点是什么，有没有更合适的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</guid>
      <pubDate>Thu, 05 Sep 2024 10:20:49 GMT</pubDate>
    </item>
    <item>
      <title>如何解释统计上不显著的估计并排除较大的影响？</title>
      <link>https://stats.stackexchange.com/questions/653890/how-to-interpret-statistically-non-significant-estimates-and-rule-out-large-effe</link>
      <description><![CDATA[我正在做回归分析，并获得了一个统计上不显著的点估计。从经济角度来看，不显著的结果在我的语境中是有意义的，但我想确保这一发现不是由于缺乏效力。相反，我想确认这种影响确实接近于零，而不仅仅是统计上不显著。
我的目标是做出这样的陈述：“...从置信区间来看，我们可以排除大于 1-1.4 个月的预期寿命增加的影响”，正如 Meghir、Palme 和 Simeonova (2018) 所做的那样，或者“这些影响通常可以限制在零附近的一个狭窄区间内”，正如 Cesarini 等人 (2016) 所提到的那样。
根据我的点估计及其置信区间，我如何自信地解释结果以做出类似的陈述？具体来说，我该如何量化估计的精度以排除较大的影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/653890/how-to-interpret-statistically-non-significant-estimates-and-rule-out-large-effe</guid>
      <pubDate>Thu, 05 Sep 2024 07:29:33 GMT</pubDate>
    </item>
    <item>
      <title>simr 模拟是否需要响应变量/因变量数据？</title>
      <link>https://stats.stackexchange.com/questions/653886/is-response-variable-dependent-variable-data-required-for-simr-simulation</link>
      <description><![CDATA[我正在使用 simr 进行线性混合效应模型的功效分析。我见过的大多数示例都使用来自试点研究的数据进行模拟，但我还没有任何数据。我的问题是：

使用 simr 进行功效分析时，因变量/响应变量的数据是否必要？
我尝试使用没有因变量的数据集运行模拟，似乎有效。这种方法有效吗？
如果因变量/响应变量的数据确实是必要的，我应该生成随机值吗？如果是这样，我应该如何处理？

以下是我当前的代码，以防有帮助。
library(dplyr)
library(tidyr)
library(simr)

# 设置参数
n_subjects &lt;- 100
n_events &lt;- 24

# 检索架构的平衡 &amp;平衡频率的条件
counterbal &lt;- read.csv(&quot;counterbalance.csv&quot;)
conditions &lt;- expand.grid(
distance = c(&quot;close&quot;, &quot;far&quot;),
direction = c(&quot;antecedent&quot;, &quot;consequence&quot;)
)

# 随机将平衡组分配给参与者
get_subj_data &lt;- function(subj_id) {
temp &lt;- data.frame(subject = rep(subj_id, n_events))
temp$event &lt;- 1:n_events
counter &lt;- sample(1:4, 1)
temp$conditions &lt;- counterbal[[paste0(&quot;Counter&quot;, counter)]]
temp$distance &lt;- conditions$distance[temp$conditions]
temp$direction &lt;- conditions$direction[temp$conditions]
return(temp)
}

df &lt;- data.frame()

for (i in 1:n_subjects) {
subj_data &lt;- get_subj_data(i)
df &lt;- rbind(df, subj_data)
}

# H1 - 主效应 T(consq) &gt; T(ante)
# 此处指定效应大小！不是系数！
fixed &lt;- c(0.5, 0.5, 0.5, 0.5)
rand &lt;- list(0.2, 0.1) # 不确定这是什么
res &lt;- 2

model &lt;- makeLmer(latency ~ direction * distance + (1|subject) + (1|event),
fixef=fixed, VarCorr=rand, sigma=res, data=df)
model

# 方向模拟？
sim_direction &lt;- powerSim(model, nsim=100, test = fcompare(~ distance))
sim_direction

这给了我以下输出：
&gt; sim_direction
模型比较的功效，（95% 置信区间）：
100.0% (96.38, 100.0)

测试：似然比
与 ~distance + [re] 的比较

基于 100 次模拟，（0 个警告，0 个错误）
alpha = 0.05，nrow = 2400

已用时间：0 小时 0 分 12 秒
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/653886/is-response-variable-dependent-variable-data-required-for-simr-simulation</guid>
      <pubDate>Thu, 05 Sep 2024 03:38:48 GMT</pubDate>
    </item>
    <item>
      <title>简单的卡方无法解决</title>
      <link>https://stats.stackexchange.com/questions/653861/simple-chi-squared-impossible-to-solve</link>
      <description><![CDATA[向两个独立的人群提出了一个“是/否”问题。
A 组：N=20，是=6，否=14。
B 组：“58% 回答是”。
我认为如果不知道（此处）B 组的总 N，就无法进行卡方检验——但我被告知可以这样做。我迷茫了，所以我去寻找信息的原始来源，发现
B 组：N=12，是=7（58%），否=5。
使用此信息，我使用方法（行 x 列）/总 N 生成了预期频率。 （在本例中为 20+12=32。）
我计算出的卡方值为 2.5。
但是，他们给出的答案是“(c^2 = 7.51; p=0.0058)”。
我绞尽脑汁试图理解这一点。不，我不认为答案是打字错误。
可能是我不知道正在执行哪种卡方。我不知道“c^2”是什么。可能是“B 组 58% 是”需要的 N 与 12 完全不同（即使它确实是之前未公开的 N），但是当我对这个 N 进行逆向工程时，代数很复杂，而且 N 似乎非常大。
我做错了什么吗？这太令人抓狂了。]]></description>
      <guid>https://stats.stackexchange.com/questions/653861/simple-chi-squared-impossible-to-solve</guid>
      <pubDate>Wed, 04 Sep 2024 15:27:19 GMT</pubDate>
    </item>
    </channel>
</rss>