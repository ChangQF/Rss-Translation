<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 10 Jul 2024 09:16:04 GMT</lastBuildDate>
    <item>
      <title>没有对应目标数据的时间序列最优窗口</title>
      <link>https://stats.stackexchange.com/questions/650789/time-series-optimal-window-without-corresponding-target-data</link>
      <description><![CDATA[我有一个时间序列预测问题。
我有各种数据，例如 A、B、C，我想预测目标（假设指数 FI）。
基本上，我想预测某种作物的最佳收获窗口。
问题是，最佳窗口是根据指数 FI 定义的。
但该指数仅在种植期结束时测量。
因此，即使我有很长一段时间的其他变量的数据，我也没有相应的 FI。
我只有最后几周的 FI，其余数据大约为 6 个月。
因此，每 6 个月我只有 2-3 周的 FI 指数。
我该如何解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/650789/time-series-optimal-window-without-corresponding-target-data</guid>
      <pubDate>Wed, 10 Jul 2024 08:54:58 GMT</pubDate>
    </item>
    <item>
      <title>如何在 GLM 二元回归中选择一个特征作为偏移量</title>
      <link>https://stats.stackexchange.com/questions/650787/how-to-choose-a-feature-as-an-offset-in-glm-binary-regression</link>
      <description><![CDATA[是否有任何统计测试可以确定特征 A 应该是偏移量，而不是特征 B 和特征 C。
据我所知，如果在保险建模中，通常，偏移量与风险敞口有关。但在欺诈检测或任何其他二元分类中，偏移量是什么？我想到的是转移金额可以作为偏移量。但如何证明或提供证据证明转移金额最好用作偏移量。]]></description>
      <guid>https://stats.stackexchange.com/questions/650787/how-to-choose-a-feature-as-an-offset-in-glm-binary-regression</guid>
      <pubDate>Wed, 10 Jul 2024 08:36:47 GMT</pubDate>
    </item>
    <item>
      <title>如果跨天在不同时间进行测量，应该是交叉随机效应还是嵌套随机效应？</title>
      <link>https://stats.stackexchange.com/questions/650783/if-measured-in-different-time-across-days-should-it-be-crossed-or-nested-random</link>
      <description><![CDATA[每个人。
我有一个数据集，其中对每个受试者在 3-6 天内的早上、下午和晚上（一天中的时间）的幸福感进行了测量。
我的两个问题是：

如果我关心幸福感与其他任务变量（如任务表现）之间的关系，我想我应该将时间和日期作为随机效应。但我不确定这是交叉还是嵌套随机效应。也就是说，我应该将其指定为幸福感 ~ 表现 + (1| 受试者) + (1|天数/时间)，还是幸福感 ~ 1 + (1| 受试者) + (1|天数) + (1|时间)？

我已检查交叉与嵌套随机效应：它们有何不同，如何在 lme4 中正确指定？。
根据答案，如果我认为一天中的时间跨度相同，则应该交叉，或者如果我们认为不同日子的早晨不同，则应该嵌套。

如果现在我关心的是幸福感如何随时间变化，考虑到数据结构，时间是否仍应包含在随机效应中？这意味着，我应该将其指定为 幸福感 ~ 时间 + (1| 受试者) + (1| 天)，还是 幸福感 ~ 时间 + (1| 受试者) + (1| 天/时间)（或 + (1| 天) + (1| 时间)) ？

非常感谢您的任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/650783/if-measured-in-different-time-across-days-should-it-be-crossed-or-nested-random</guid>
      <pubDate>Wed, 10 Jul 2024 08:10:12 GMT</pubDate>
    </item>
    <item>
      <title>比较样本量不一致的模型</title>
      <link>https://stats.stackexchange.com/questions/650782/comparing-models-with-unequal-sample-sizes</link>
      <description><![CDATA[我进行了关联分析，其中我将几个不同的预测变量与一个因变量关联起来。对于每个预测变量，我运行两个模型并通过似然比检验对它们进行比较。第一个模型控制时间的影响，第二个模型仅控制时间。以下是我的建模策略：
表型 1
模型 1 &lt;- Y ~ 表型 1 + 时间 + (1|RE)
模型 2 &lt;- Y ~ 时间 + (1|RE)
anova(模型 1, 模型 2, 测试 = &quot;LRT&quot;)
表型 2
模型 3 &lt;- Y ~ 表型 2 + 时间 + (1|RE)
模型 4 &lt;- Y ~ 时间 + (1|RE)
anova(模型 3, 模型 4, 测试 = &quot;LRT&quot;)
表型 3
模型 5 &lt;- Y ~ 表型 2 + 时间 + (1|RE)
模型 6 &lt;- Y ~ 时间 + (1|RE)
anova(model5, model6, test = &quot;LRT&quot;)
我特别感兴趣的是哪种表型最能解释我的因变量（注意，Y 对于所有模型都是相同的）。另外，我感兴趣的不是哪种表型组合最适合 Y，而是 Y 的最佳预测因子是什么。理想情况下，我会采取在似然比检验中具有显著表型的模型，然后通过它们的 AIC 或似然性进行比较。但是，问题是由于表型抽样，每个模型的样本量都不同。
因此，我的问题是：如何比较样本量不等的模型，以了解哪种表型最能解释我的因变量？
我的一个想法是类似交叉验证的方法，我在数据的不同子集上运行模型。因此，从每个子集（这些子集在不同模型中具有相同的样本量）中，我可以计算 AIC，取所有迭代的平均值，然后根据平均 AIC 值比较模型。此外，每个表型都有合适的样本量（n &gt; 100）。]]></description>
      <guid>https://stats.stackexchange.com/questions/650782/comparing-models-with-unequal-sample-sizes</guid>
      <pubDate>Wed, 10 Jul 2024 08:05:02 GMT</pubDate>
    </item>
    <item>
      <title>测试我的新方法的 I 类错误率是否正确匹配所选的 alpha</title>
      <link>https://stats.stackexchange.com/questions/650781/test-whether-my-new-methods-type-i-error-rate-correctly-matches-chosen-alpha</link>
      <description><![CDATA[这个答案正确吗？在我看来它是正确的，我也喜欢它，但它没有得到任何赞同。
我正在测试两种不同的假设检验方法，即自举似然比检验和假设渐近分布的似然比检验。我想看看 alpha=5% 水平的拒绝次数是否与 0.05 有显著差异。如果答案正确，我将其解释为我可以进行二项式检验，看看我的拒绝率是否不同于 0.05。
但是，我正在考虑的另一种解决方案是进行比较错误率测试，如此处所述（另请参阅此处）。这两次测试的结果似乎并不完全一致，所以我认为它们是不同的。
您可以按如下方式比较这两种方法。假设我的新方法在 5000 个样本中的拒绝率为 5.8%（所以我拒绝了 290 个）。我可以在 R 中按如下方式进行二项式检验
stats::binom.test(x=290,n=5000,p=0.05,conf.level=0.95)

精确二项式检验

数据：290 和 5000
成功次数 = 290，试验次数 = 5000，p 值 = 0.01133
备选假设：成功的真实概率不等于 0.05
95% 置信区间：
0.05168068 0.06484127
样本估计值：
成功概率
0.058

因此，我可以拒绝我的测试具有适当拒绝率的想法。
对于第二种方法，我们可以使用另一篇文章中建议的此在线计算器，即样本量 1 = 5000，百分比响应 1 = 5.8，样本量 2 =5000，百分比响应 2 = 5。我们得到以下结果：比较误差：0.89，差异：0.8，显著性：否。
我的猜测是二项式检验正确地告诉了我真正关心的事情，即我的新方法的拒绝率是否正确，即它是否与我的 alpha 值匹配。但是，我正在比较几种不同的方法，也许“比较误差”测量在某种程度上可用于比较方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/650781/test-whether-my-new-methods-type-i-error-rate-correctly-matches-chosen-alpha</guid>
      <pubDate>Wed, 10 Jul 2024 07:50:07 GMT</pubDate>
    </item>
    <item>
      <title>执行多个 Fisher 精确检验时样本总数变化的影响</title>
      <link>https://stats.stackexchange.com/questions/650780/impact-of-variation-in-the-total-number-of-samples-when-performing-multiple-fish</link>
      <description><![CDATA[我有 2 个时间点的数据集。在每个时间点，我必须比较每个位置上不同成分的计数（位置数 =1000）。我使用 Fisher 精确检验来比较 2 个时间点上不同成分的计数是否存在显著差异。我最终进行了 1000 次 Fisher 检验，然后应用了 FDR 校正。我的问题是：
1. 如果用于比较 2 个时间点的样本总数存在显著差异（如下图所示），这会如何影响结果？以及 p 值？是否存在偏差？
2. 如何修复此问题以获得可靠的结果，或者在执行 Fisher 精确检验时是否有任何方法可以进行标准化或解释这种变化？
这是一个更清晰的示例，因此对于每个位置（此图像中的每一行），我都执行了 Fisher 精确检验，然后应用了 FDR 校正：
]]></description>
      <guid>https://stats.stackexchange.com/questions/650780/impact-of-variation-in-the-total-number-of-samples-when-performing-multiple-fish</guid>
      <pubDate>Wed, 10 Jul 2024 07:18:57 GMT</pubDate>
    </item>
    <item>
      <title>当卷积输出为小数时，keras.layers.Conv2D 的卷积层输出是什么？</title>
      <link>https://stats.stackexchange.com/questions/650777/what-would-be-the-convolutional-layer-output-by-keras-layers-conv2d-when-conv-ou</link>
      <description><![CDATA[我有输入（$n=224$）、步幅（$s=4$）、过滤器大小（$k=11$）且无填充，这给了我一个分数形式的 conv 输出：
$$\texttt{conv output} = (n-k+2p)/s + 1 = 54.25$$
我的问题是，当上述公式得出分数形式时，keras.layers.Conv2D 如何生成 conv output？
对于上述参数，keras.layers.Conv2D 给出的 conv 输出为 $54$。为什么要取小数 conv 输出 的下限？我读到，当它是小数时，我们需要调整 $n$、$s$、$k$，以使该输出为整数。]]></description>
      <guid>https://stats.stackexchange.com/questions/650777/what-would-be-the-convolutional-layer-output-by-keras-layers-conv2d-when-conv-ou</guid>
      <pubDate>Wed, 10 Jul 2024 05:35:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的多项式 Logit 模型（McFadden）的 Rho 平方这么小？</title>
      <link>https://stats.stackexchange.com/questions/650775/why-my-rho-square-on-multinomial-logit-model-mcfadden-so-small</link>
      <description><![CDATA[当我使用 MNL 并尝试找到我的 rho 平方时，发现它太小了。它是 $0.0139$。对于一个良好的拟合模型，rho 平方必须在 $0.2$-$0.4$ 之间。它这么小有什么原因吗？我该如何修复它？
这是对数似然值：
]]></description>
      <guid>https://stats.stackexchange.com/questions/650775/why-my-rho-square-on-multinomial-logit-model-mcfadden-so-small</guid>
      <pubDate>Wed, 10 Jul 2024 03:43:13 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以找到 F 分布的 Kolmogorov-Smirnov 临界值表？</title>
      <link>https://stats.stackexchange.com/questions/650774/where-can-i-find-a-kolmogorov-smirnov-critical-value-table-for-an-f-distribution</link>
      <description><![CDATA[我开发了一个 Excel 模型，用于 F 分布的单样本 Kolmogorov-Smirnov 检验。我有 K-S 检验统计量，但没有 CV 可以与之比较。如果有人知道 K-S F 检验的临界值在线表格，我将不胜感激。我假设输入要求将是参考 F 分布的 df1 和 df2，以及检验的显著性水平。]]></description>
      <guid>https://stats.stackexchange.com/questions/650774/where-can-i-find-a-kolmogorov-smirnov-critical-value-table-for-an-f-distribution</guid>
      <pubDate>Wed, 10 Jul 2024 02:20:12 GMT</pubDate>
    </item>
    <item>
      <title>状态空间模型和卡尔曼滤波器</title>
      <link>https://stats.stackexchange.com/questions/650761/state-space-models-and-kalman-filter</link>
      <description><![CDATA[我有以下模型规范：
$y_t = \mu_t + v_t,$
$\mu_{t+1|t} = \phi \, \mu_{t|t-1} + k\, v_t $
其中 v_t= y_t - mu_{t|t-1}, v_t|F_{t-1} ~ tv(0, sigma^2)。
我被要求提供 mu_t 或 mu_{t|t-1} 的滤波估计值，并估计静态参数：phi、v、sigma^2。
我使用卡尔曼滤波器。一般状态空间表示为：y_t = Z_t* alpha_t + G_t* epsilon_t。 alpha_{t+1} = T_t* alpha_t + H_t* eta_t
在这种情况下：Z_t=1，T_t = phi，G_t= sigma_v，H_t= k*sigma_v，alpha_t= mu_t。
对于卡尔曼滤波器：v_t = y_t - Z_t* alpha_{t|t-1} # 预测误差
F_t = Z_t * P_{t|t-1} Z_t&#39; + G_t G_t&#39; # 预测误差的方差
alpha_{t|t} = alpha_{t|t-1} + P_t* Z_t&#39;* F_t^-1 *vt # E[alpha_t| F_t]
P_{t|t} = P_{t|t-1} - P{t|t-1}*Z_T&#39; * F_t^-1 Z_tP_t # V[alpha_t|F_t]
alpha_{t+1|t} = T_t* alpha_{t|t-1} + k_t *vt# 更新状态估计
P_{t+1|t} = T_t* P_{t|t-1}* T_t&#39;+ H_tQ_tH_t&#39; - K_t * F_t *K_t&#39;# 更新状态方差
卡尔曼增益 K_t= T_t* P_{t|t-1Z_t&#39; F_t^-1
为了计算估计值mu_{t|t}，我是否只需替换 alpha_{t|t} = alpha_{t|t-1} + P_t* Z_t&#39;* F_t^-1 *vt？
mu_{t|t} = mu_{t|t-1} + P_t* Z_t&#39;* F_t^-1 *vt？]]></description>
      <guid>https://stats.stackexchange.com/questions/650761/state-space-models-and-kalman-filter</guid>
      <pubDate>Tue, 09 Jul 2024 19:02:36 GMT</pubDate>
    </item>
    <item>
      <title>样本量对指标提升度的影响</title>
      <link>https://stats.stackexchange.com/questions/650716/impact-of-sample-size-on-metric-lift</link>
      <description><![CDATA[假设我们连续运行了三个随机用户拆分 AB 实验 exp_1、exp_2、exp_3。这三个实验的处理和控制完全相同。
Exp_1 在 2014 年 6 月 1 日至 2014 年 6 月 1 日期间运行了 2 周。 Exp_2 在 06/15-06/28 期间运行了 2 周，Exp_3 在 06/29-07/12 期间运行了 2 周。
Exp_1 有 2% 的用户参与了实验，Exp_2 有 50% 的用户参与了实验，Exp_3 有 100% 的用户参与了实验。
Exp_1 的主要指标提升的 95% CI 为 2.3% - 13.0%
Exp_2 的主要指标提升的 95% CI 为 6.2% - 8.4%
Exp_3 的主要指标提升的 95% CI 为 5.9% - 7.4%
从这些结果中，我们可以得出结论，这三个实验都具有相同的指标提升吗？
如果是/否，为什么？
我原本希望这些实验的指标提升是相同的。因为三个实验的处理方式相同。它们之间唯一的区别是参与实验的用户数量。因此，我想了解的是指标提升是否会根据参与实验的用户数量而变化。如果是这样，那么我们将不得不始终在 100% 用户参与的情况下运行实验。这并不理想，因为我们不能同时运行其他实验。]]></description>
      <guid>https://stats.stackexchange.com/questions/650716/impact-of-sample-size-on-metric-lift</guid>
      <pubDate>Tue, 09 Jul 2024 07:16:34 GMT</pubDate>
    </item>
    <item>
      <title>通过 TP、TN、FP 和 FN 值判断模型</title>
      <link>https://stats.stackexchange.com/questions/650709/judging-a-model-through-the-tp-tn-fp-and-fn-values</link>
      <description><![CDATA[我正在使用多个数据集评估一个模型，该模型可以预测某个“特征”是否存在（例如，“这幅图像中有一只狗”）。系统会针对每个数据集输出 TP、TN、FP 和 FN。
我想要一个指标来判断模型的工作效果如何，但我意识到我无法仅绘制 TP，因为例如第一个数据集有 20 个具有特征（有一只狗）的实例，而第二个数据集只有 10 个。即使模型是完美的，第二个数据集也只有 10 个 TP。
我正在考虑计算每个数据集和所有数据集的准确率、精确率和召回率。
我也对每个数据集运行了三次模型，变化很小
我也在研究精确率-召回率曲线，但似乎这些是针对不同的阈值的，显然每个数据集只有一组精确率、召回率
有什么好方法可以判断模型是否“好”？由于我的经验不足，我无法提出一个好的判断标准
起初我想绘制所有数据集的每个（TP 等）的分布
然后我想绘制一个结合所有数据集的混淆矩阵
任何建议都将不胜感激

作为一个简单的虚构示例，我想到
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confused_matrix, precision_score, recall_score, f1_score, accuracy_score

# 示例虚构数据
datasets = {
&#39;datasetA&#39;: {&#39;TP&#39;: 150, &#39;TN&#39;: 200, &#39;FP&#39;: 50, &#39;FN&#39;: 100, &#39;no_GT&#39;: 34},
&#39;数据集B&#39;：{&#39;TP&#39;：180，&#39;TN&#39;：220，&#39;FP&#39;：40，&#39;FN&#39;：81，&#39;no_GT&#39;：20}，
&#39;数据集C&#39;：{&#39;TP&#39;：160，&#39;TN&#39;：240，&#39;FP&#39;：70，&#39;FN&#39;：110，&#39;no_GT&#39;：30}，
&#39;数据集D&#39;：{&#39;TP&#39;：190，&#39;TN&#39;：250，&#39;FP&#39;：60，&#39;FN&#39;：90，&#39;no_GT&#39;：42}，
}

def calculate_metrics（TP，TN，FP，FN）：
准确度 = (TP + TN) / (TP + TN + FP + FN)
精度 = TP / (TP + FP) if (TP + FP) &gt; 0 else 0
召回率 = TP / (TP + FN) if (TP + FN) &gt; 0 else 0
f1 = 2 * (准确率 * 召回率) / (准确率 + 召回率) if (准确率 + 召回率) &gt; 0 else 0

return {
&#39;Accuracy&#39;: 准确度,
&#39;Precision&#39;: 精度,
&#39;Recall&#39;: 召回率,
&#39;F1 分数&#39;: f1
}

# 聚合计数
total_TP = sum(data[&#39;TP&#39;] for data in datasets.values())
total_TN = sum(data[&#39;TN&#39;] for data in datasets.values())
total_FP = sum(data[&#39;FP&#39;] for data in datasets.values())
total_FN = sum(data[&#39;FN&#39;] for data in datasets.values())

# 计算总体指标
overall_metrics = calculate_metrics(total_TP, total_TN, total_FP, total_FN)

# 计算每个数据集的指标
metrics_df = pd.DataFrame({dataset: calculate_metrics(data[&#39;TP&#39;], data[&#39;TN&#39;], data[&#39;FP&#39;], data[&#39;FN&#39;]) for dataset, data in datasets.items()})

# 添加总体指标
metrics_df[&#39;Overall&#39;] = Overall_metrics

print(metrics_df)

# 可视化
fig, axis = plt.subplots(2, 2, figsize=(14, 10))
axes = axis.flatten()

for i, (dataset, data) in enumerate(datasets.items()):
cm = confused_matrix([1] * data[&#39;TP&#39;] + [0] * data[&#39;TN&#39;] + [1] * data[&#39;FN&#39;] + [0] * data[&#39;FP&#39;],
[1] * (data[&#39;TP&#39;] + data[&#39;FP&#39;]) + [0] * (data[&#39;TN&#39;] + data[&#39;FN&#39;]))
sns.heatmap(cm, annot=True, fmt=&#39;d&#39;, cmap=&#39;Blues&#39;, ax=axes[i])
axes[i].set_title(f&#39;混淆矩阵 - {dataset}&#39;)
axes[i].set_xlabel(&#39;预测&#39;)
axes[i].set_ylabel(&#39;True&#39;)

plt.tight_layout()
plt.show()

我得到了
 数据集A 数据集B 数据集C 数据集D 总体
准确率 0.700000 0.767754 0.689655 0.745763 0.725696
精确率 0.750000 0.818182 0.695652 0.760000 0.755556
召回率 0.600000 0.689655 0.592593 0.678571 0.640905
F1 分数 0.666667 0.748441 0.640000 0.716981 0.693524

和
]]></description>
      <guid>https://stats.stackexchange.com/questions/650709/judging-a-model-through-the-tp-tn-fp-and-fn-values</guid>
      <pubDate>Tue, 09 Jul 2024 05:43:39 GMT</pubDate>
    </item>
    <item>
      <title>无法从 shapley 值的全局热图中识别出重要特征</title>
      <link>https://stats.stackexchange.com/questions/650699/cannot-identify-important-feature-from-global-heatmap-of-shapley-value</link>
      <description><![CDATA[在我的例子中，每个实例有 166 个特征。我以 80:20 的比例分割训练和测试数据集，并训练了一个用于二元分类的 DNN 模型。模型架构如下：

现在对于测试数据，我使用 shap 库 来识别重要特征。我计算 shap 值的代码如下：
dnn_explainer = shap.DeepExplainer(model, X_train_shap.float().to(device)) 
shap_values_test = dnn_explainer.shap_values(X_test_shap.float().to(device))

现在我试图从局部和全局热图中可视化真正样本的重要特征。对于单个真阳性实例，我得到了这个热图：

从这个热图中，我看到大多数特征都很重要，因为它们是红色的，这些特征对模型的预测没有任何影响，因为它们的 shapley 值为零。
我还使用以下代码绘制了全局热图：
import matplotlib.pyplot as plt
import seaborn as sns 

plt.figure(figsize=(10, 2)) 

sns.heatmap(shap_values_test_tp, cmap=&#39;coolwarm&#39;, cbar_kws={&#39;label&#39;: &#39;特征重要性值&#39;}) 
plt.title(&#39;TP 样本的全局分析&#39;, fontsize=10)
plt.show()

使用 SHAP 值的全局热图：
我获得了测试数据集所有真正实例的全局热图，如下所示：

从这个热图中，我也无法在全球范围内识别任何重要特征。我正在尝试找出整个模型解释过程中的错误，但我无法找到。
使用分层相关性传播值的局部和全局热图：
我已经从测试数据中为所有真正的阳性实例计算了分层相关性传播值。

对于单个实例，我有这个热图：

对于所有真正的测试数据阳性实例，我有此热图：

从这些局部和全局热图中，我无法识别重要特征。
我已阅读题为使用逐层相关性传播解释表格数据的深度学习模型的论文，并查看了其局部和全局热图如下：

从这些热图中，我们可以轻松识别局部和全局重要特征。我想在我的模型解释中实现这一点。我在解释我的模型时是否遗漏了任何步骤？任何澄清或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650699/cannot-identify-important-feature-from-global-heatmap-of-shapley-value</guid>
      <pubDate>Mon, 08 Jul 2024 23:22:18 GMT</pubDate>
    </item>
    <item>
      <title>贝塔随机变量的乘积与和的分布</title>
      <link>https://stats.stackexchange.com/questions/650663/distribution-of-product-and-sum-of-beta-random-variables</link>
      <description><![CDATA[我有一组概率，我将其建模为（独立的）$p_{A,i} \sim Beta(\alpha_{A,i},\beta_{A,i})$ 和 $p_{B,i} \sim Beta(\alpha_{B,i},\beta_{B,i})$。我正在计算以下乘积：
$$Y = \sum_{i=1}^N p_{A,i}^{n_{A}}(1-p_{B,i})^{n_{B}} + p_{B,i}^{n_{B}}(1-p_{A,i})^{n_{A}},$$
其中 $n_{A}$ 和 $n_{B}$ 为整数。我想推断（近似）$Y$ 的累积分布。由于 $Y$ 因支持值 $\gt 1$ 而出现偏差，我考虑将 Beta-Prime（或对数正态）密度分布拟合到 $Y$。这样对吗？您能否就 $Y$ 的真实分布或更好的近似值提供一些见解？
PD。如果之前有人问过类似的问题，请见谅。]]></description>
      <guid>https://stats.stackexchange.com/questions/650663/distribution-of-product-and-sum-of-beta-random-variables</guid>
      <pubDate>Mon, 08 Jul 2024 08:59:56 GMT</pubDate>
    </item>
    <item>
      <title>如何将贝叶斯模型拟合到 Beta 和 One-Zero 膨胀数据的混合中？</title>
      <link>https://stats.stackexchange.com/questions/650533/how-to-fit-a-bayesian-model-to-a-mixture-of-beta-and-one-zero-inflated-data</link>
      <description><![CDATA[我的数据非常嘈杂，我相信这是通过多个物理过程的相互作用而产生的。在映射 $Y = f(X),$ 中，$Y$ 是一个比率 $[0, 1]$ 和 $X \ge 0.$，而 $Y$ 是 $X,$ 的函数，它也可以取 $0$（更可能在较低的 $X$ 值时）或 $1$（更可能在较高的 $X$ 值时）。 $Y$ 是每个 $X$ 间隔的 Beta 和 Zero-One 膨胀过程的混合。
对于 $X$ 的选定间隔，$Y$ 的条件分布（即 $Y|X$ ）显示出与数据边际分布（如下所示）类似的模式。但是，$Y|X$ 的扩散在 $X$ 的较低值时更为明显，并且随着 $X$ 的增加而缓慢消失。
如何使用贝叶斯方法对此类过程进行建模？我是贝叶斯统计的新手，希望得到任何帮助。我能够拟合零一膨胀的 Beta 模型，但它无法捕捉到 $X$​ 值较低时 $Y$ 的高分布。
虽然数据的其他特征可以减少模型误差，尤其是在较高的 $X$ 时，但它们在大多数应用中通常是不可观察的。因此，我的目标是一个能够提供最佳映射的函数，以促进实际应用。
模拟真实数据的虚拟数据：
# 设置种子以实现可重复性
set.seed(123)

# 生成 x 值
x &lt;- seq(0, 20, length.out = 1000)

# 为 y 创建非线性函数
y &lt;- 0.15 + 0.005 * x^1.05 + 1 / (2.5 + 2532 * exp(-1.611 * x))

# 添加一些随机噪声
noise_factor &lt;- 0.03
# 使用 beta 噪声创建模型（此处使用正态分布创建）
noisy_y &lt;- rnorm(length(x), mean = 0, sd = noise_factor * sqrt(x))

y &lt;- y + noisy_y

# 向数据添加零个和一个噪声
noisy_indices &lt;- sample(1:length(x), round(0.2 * length(x)))
for (i in noisy_indices) {
if (runif(1) &lt; 1 / (1 + exp(x[i]))) {
y[i] &lt;- 1
} else {
y[i] &lt;- 0
}
}

# 添加指数分布
noisy_indices &lt;- sample(1:length(x), round(0.5 * length(x)))
for (i in noisy_indices) {
if (runif(1) &lt; 100 / (1 + exp(x[i]))) {
y[i] &lt;- rexp(1, rate =4)
} else {
y[i] &lt;- y[i]
}
}

# 创建数据框
数据 &lt;- data.frame(x = x, y = y) |&gt;
filter(y&lt;=1 &amp; y&gt;=0)

ggplot(data, 
aes(x, y)) +
geom_point() +
xlim(0, 20) + 
ylim(0, 1)

ggplot(data = data, 
aes(x=y))+
geom_histogram()

我正在尝试制定一个将 X 映射到 Y 的函数

整个数据集中 Y 的分布。在原始数据集中，从零（@Y=0）到指数部分（Y ~ 0-0.25）的过渡非常平滑。

我尝试（在原始数据上）在 brms 中使用零一膨胀 Beta 得出此后验预测：
]]></description>
      <guid>https://stats.stackexchange.com/questions/650533/how-to-fit-a-bayesian-model-to-a-mixture-of-beta-and-one-zero-inflated-data</guid>
      <pubDate>Fri, 05 Jul 2024 14:49:43 GMT</pubDate>
    </item>
    </channel>
</rss>