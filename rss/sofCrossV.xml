<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 11 Feb 2025 18:22:00 GMT</lastBuildDate>
    <item>
      <title>这个账户在1个月后被耗尽并且余额为零的概率是多少？</title>
      <link>https://stats.stackexchange.com/questions/661238/what-is-the-probability-that-this-account-will-be-depleted-and-its-balance-will</link>
      <description><![CDATA[我在外汇市场有一个 1000 美元的账户

我每笔交易的风险为 5%

每月交易次数为 20

胜率为 50%

风险回报为 1:1

这个账户在 1 个月后耗尽且余额为零的概率是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/661238/what-is-the-probability-that-this-account-will-be-depleted-and-its-balance-will</guid>
      <pubDate>Tue, 11 Feb 2025 18:17:03 GMT</pubDate>
    </item>
    <item>
      <title>部分斯皮尔曼相关性有三种不同的计算方法，每种方法都会得到不同的估计值 - 该使用哪一种？</title>
      <link>https://stats.stackexchange.com/questions/661236/partial-spearman-correlations-done-three-different-ways-each-get-different-estim</link>
      <description><![CDATA[据我所知，有三种不同的方法可以进行 Spearman 偏相关。
方法 1 = 来自这里 (https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/partsp)：“从这个等价性可以看出，Spearman 偏相关等于两个变量的秩对偏变量的秩的线性回归残差之间的 Pearson 相关”
方法 2 = 或者，使用原始数据，对 x 和 z（协变量）进行回归，对 y 和 z 进行回归，从这些模型中获得残差，然后对这些模型运行 Spearman 相关，应该会得到相似的值。
方法3 = 最后，R 中的 ppcor 包使用协方差矩阵（https://pmc.ncbi.nlm.nih.gov/articles/PMC4681537/）。
使用 Pearson（不是 spearman），方法 2 和方法 3 的结果相同，如下所示，https://rpubs.com/KwonPublishing/249631。
但是，下面显示方法 1、2 和 3 都获得了 spearman 偏相关系数的不同相关性估计 相关性。 那么哪一个是最正确的呢？
x_data &lt;- as.data.frame(matrix(runif(50, min=-3, max=3), ncol=5, nrow=10))
y_data &lt;- as.data.frame(matrix(runif(50, min=-3, max=3), ncol=5, nrow=10)) 

z_data &lt;- data.frame(age = c(56, 65, 78, 23, 41, 45, 67, 43, 29,31),
sex=c(2,1,2,1,1,2,2,2,2,2),
days=c(0,0,0,1,1,2,2,3,3,6))

##方法 1 对排序后的 x、y 和 z 数据进行回归，获得残差，然后计算它们之间的皮尔逊 

rx1 &lt;- rank(x_data$V1)
ry1 &lt;- rank(y_data$V1)
rz &lt;- data.frame(apply(z_data, 2, function(x) rank(x)))

residuals_x &lt;- residuals(lm(rx1 ~ rz$age + rz$sex + rz$days))
residuals_y &lt;- residuals(lm(ry1 ~ rz$age + rz$sex + rz$days))

spearman_partial_1 &lt;- cor(residuals_x, residuals_y, method = &quot;pearson&quot;)
spearman_partial_1 ##-0.708

##方法 2 分别对 x 和 y 进行 z 回归，提取残差，然后运行斯皮尔曼相关

residuals_x1 &lt;- residuals(lm(x_data$V1 ~ z_data$age + z_data$sex + z_data$days))
residuals_y1 &lt;- residuals(lm(y_data$V1 ~ z_data$age + z_data$sex + z_data$days))

spearman_partial_2 &lt;- cor(residuals_x1, residuals_y1, method=&quot;spearman&quot;)
spearman_partial_2 #-0.4909

##方法 3 使用 ppcor 包，该包着眼于使用协方差矩阵来加速上述 

residuals_3 &lt;- pcor.test(x_data$V1, y_data$V1, z_data[, c(&quot;age&quot;, &quot;sex&quot;, &quot;days&quot;)])
residuals_3$estimate #-0.6253
]]></description>
      <guid>https://stats.stackexchange.com/questions/661236/partial-spearman-correlations-done-three-different-ways-each-get-different-estim</guid>
      <pubDate>Tue, 11 Feb 2025 16:22:55 GMT</pubDate>
    </item>
    <item>
      <title>LOOCV 设置中的嵌套线性模型比较和回归参数测试？</title>
      <link>https://stats.stackexchange.com/questions/661235/nested-linear-model-comparison-and-regression-parameter-testing-in-loocv-setting</link>
      <description><![CDATA[假设以下情况：需要对多个样本进行荟萃分析，其中一个样本相当小。
我们有两个嵌套模型，一个包含所有需要处理的技术和其他混杂因素（似乎没有争议），第二个包含上述混杂因素以及实际感兴趣的预测因素。
预测因素的数量接近最小样本的样本量，其他样本几乎大一个数量级。此外，我们还有一些（仍然可以忍受？）共线性问题。
整个过程是在高吞吐量设置下完成的，因此我们面临着严峻的多重测试挑战（约 100 万个结果测量）。这通常是通过计算 FWER 或 FDR 来解决的。
但是：可能由于过度拟合，即使经过多次测试校正，我们在小样本中仍然有很多显著的发现，我不相信它们（几乎可以肯定这些是假阳性，因为它们不会出现在较大的样本中）。在我建议对一个较大的样本进行一些敏感性分析（将其剥离到相同的不足样本量）之后，那里的情况是一样的：突然出现许多不可信的微小 p 值，经受住了多次测试校正和最终元分析的偏差结果。使用 rlm（来自 R 中的 MASS 包；遵循分析计划）并没有改善已经怀疑的情况。
当被要求帮助时，我的第一个想法是求助于留一交叉验证（loocv），并根据从 loocv 获得的保留样本预测误差而不是常规线性模型残差对两个模型进行 F 检验比较。乍一看，这似乎有效，并且据称显示了更为现实的画面。
我现在面临的挑战是：使用 loocv 方法，如何获得单个感兴趣的预测因子的合理参数估计（回归 beta）以及此估计的适当标准误差，可用于元分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/661235/nested-linear-model-comparison-and-regression-parameter-testing-in-loocv-setting</guid>
      <pubDate>Tue, 11 Feb 2025 16:14:21 GMT</pubDate>
    </item>
    <item>
      <title>因果关系 - 单组前测后测（准实验）设计</title>
      <link>https://stats.stackexchange.com/questions/661233/causality-one-group-pretest-posttest-quasi-experimental-design</link>
      <description><![CDATA[我进行了一项（准）实验研究，采用单组前测后测设计，以检验旨在培训参与者在求职面试中使用特定非语言线索的干预措施是否能有效提高面试表现。
配对 t 检验显示，干预后的面试表现得分明显高于干预前。但是，我想确定这种改善是否真正归因于干预的有效性，而不仅仅是实践效果。
为了评估这一点，我在干预前后测量了面试表现和非语言线索的使用情况（均作为连续变量进行测量）。如果参与者在干预后比干预前更多地使用有针对性的非语言线索，则该干预将被视为有效。
大多数关于实验设计中的中介作用的研究都包括对照组，但我的设计没有对照组。鉴于此，我正在寻找适当的统计方法来测试非语言线索的增加使用是否有助于提高面试表现。如有任何关于如何对此进行建模的建议，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661233/causality-one-group-pretest-posttest-quasi-experimental-design</guid>
      <pubDate>Tue, 11 Feb 2025 15:30:11 GMT</pubDate>
    </item>
    <item>
      <title>如何在 scikit learn 中模拟 R 的 selectNcomp？</title>
      <link>https://stats.stackexchange.com/questions/661232/how-might-i-emulate-rs-selectncomp-in-scikit-learn</link>
      <description><![CDATA[R 的 mvr 包有一个实用函数 selectNcomp，可通过实施启发式标准误差规则自动选择交叉验证 PLS 模型中的保留潜变量：
“方法“onesigma”仅返回最佳 CV 在绝对最佳值的一个标准误差范围内的第一个模型（Hastie、Tibshirani 和 Friedman，2009 年）。请注意，这里我们仅使用交叉验证残差的标准偏差，与用于计算误差测量本身的程序一致”
如何在 Python 中模仿此功能？从我的 SKlearn 网格搜索中，我可以获得验证所有折叠中每个选定潜变量的平均 RMSE，以及所有折叠的相关标准偏差，但我不确定如何/是否可以根据此信息计算标准误差，或者它是否确实与仅使用标准偏差作为限制有显著不同。
谢谢。
Hastie, T.、Friedman, J. 和 Tibshirani, R.《统计学习要素：数据挖掘、推断和预测》，Springer（2013 年），第 10 次印刷，附有更正，第 7.10 段。]]></description>
      <guid>https://stats.stackexchange.com/questions/661232/how-might-i-emulate-rs-selectncomp-in-scikit-learn</guid>
      <pubDate>Tue, 11 Feb 2025 15:21:13 GMT</pubDate>
    </item>
    <item>
      <title>基于偏差特征的预测建模</title>
      <link>https://stats.stackexchange.com/questions/661231/predictive-modeling-on-biased-features</link>
      <description><![CDATA[我想用于建模的一些特征具有如下分布：

我的数据中经常出现的特征值很高。我可以轻松识别导致这种极化的数据点子集。这里没有现象，这些只是与大城市相关的样本。问题是我应该如何解决这个问题。我应该为大城市建立一个单独的模型吗？或者你会建议最小化极性的转换吗？我知道预测建模没有通用的方法，但也许你对这样的数据集有一些经验和良好的做法。你对如何将这些特征纳入模型有什么建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/661231/predictive-modeling-on-biased-features</guid>
      <pubDate>Tue, 11 Feb 2025 15:19:07 GMT</pubDate>
    </item>
    <item>
      <title>匹配和 AIPW/倾向评分方法</title>
      <link>https://stats.stackexchange.com/questions/661229/matching-and-aipw-propensity-score-methods</link>
      <description><![CDATA[在运行基于倾向得分 (PS) 的匹配算法后，人们是否经常运行增强逆概率加权或双重稳健方法来估计治疗效果？就此而言，人们是否经常在通用匹配算法之后使用基于倾向得分的估计程序？
我的直觉告诉我，当使用基于 PS 的匹配算法时，人们会通过重新估计匹配样本的倾向得分而引起偏差，所以这似乎不是一个好主意。
Ho 等人的一篇论文 (https://gking.harvard.edu/files/matchp.pdf) 认为匹配会降低模型依赖性，因此在匹配后使用基于 PS 的估计方法可能不是常见的做法。很高兴能听取其他人对此的想法：
先进行匹配，然后进行 AIPW 是一种好的做法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661229/matching-and-aipw-propensity-score-methods</guid>
      <pubDate>Tue, 11 Feb 2025 15:04:38 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用卡方还是 Mcnemar</title>
      <link>https://stats.stackexchange.com/questions/661223/should-i-use-chi-squared-or-mcnemar</link>
      <description><![CDATA[我是一名博士生，不可否认，统计学是我的弱项。我正在制定一份提案，必须说明我将对假设数据进行什么测试。我计划看看注意力控制组和干预组之间是否存在差异。参与者将被随机分配到各个组中。每个参与者将进行基线评估。注意力控制组和干预组将参加关于该主题的相同教育。干预组将参加模拟以练习该技能。然后，每个参与者将进行事后评估。我想看看模拟组在干预后是否有更准确的评估结果。评估要么正确，要么不正确。我想比较干预前后两组之间的正确评估数量。我认为由于每个参与者都贡献了两个评估，这是配对数据，我应该进行 McNemars 检验。但是，我的第一稿有卡方，我正在重新考虑自己。我应该更改我提议进行的测试吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661223/should-i-use-chi-squared-or-mcnemar</guid>
      <pubDate>Tue, 11 Feb 2025 13:06:08 GMT</pubDate>
    </item>
    <item>
      <title>如何在 K 均值聚类中获取较小的最优 K 值</title>
      <link>https://stats.stackexchange.com/questions/661222/how-to-get-a-smaller-number-of-optimal-k-in-k-means-clustering</link>
      <description><![CDATA[我想在大小为 $5000$ 的数据集上进行 k 均值聚类，以获得 $k$ 的较小最优值（$k≤5$）。我已使用 BIC 和 Gap 统计量来确定最优聚类数，两种方法均表明最优 $k$ 为 $7$ 或更高。我想知道我是否可以进行调整（例如，通过将 $s(k+1)$ 乘以因子 $c&gt;1$ 或将其作为 BIC 中的惩罚项包括在内），以便获得较小的 $k$ 最佳值。
以下是我为计算 Gap 统计量和 BIC 而执行的计算：
BIC 计算
$$\text{BIC}=n\ln(\frac{W}{n})+m\ln(n)$$
其中 $W$ 是簇内总平方和，
$m$ 是模型中自由参数的数量，$n$ 是数据点的总数。
最优的 $k$ 是 BIC 值最小的那个。
差距统计
$$\text{Gap}(k)≥\text{Gap}(k+1)−s(k+1)$$
其中 $\text{Gap}(k)=\frac{1}{B}\sum_{b=1}^{B}\ln(W_{k} ^{∗(b)})−\ln(W_k)$。
这里 $W_k$ 是 k 个簇的簇内弥散度，$W_{k} ^{∗(b)}$ 是 $W_{k} ^{∗(b)}$ 是 k 个簇的簇内弥散度。 class=&quot;math-container&quot;&gt;$b^\text{th}$ 参考数据集（来自总共 $B$ 参考数据集）从没有明显聚类的分布生成，用于 $k$ 个聚类。
如果我犯了任何错误，如果有其他方法可以获取较小的聚类数，或者我可以做任何修改，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/661222/how-to-get-a-smaller-number-of-optimal-k-in-k-means-clustering</guid>
      <pubDate>Tue, 11 Feb 2025 12:53:35 GMT</pubDate>
    </item>
    <item>
      <title>R 中的权重参数 GLM</title>
      <link>https://stats.stackexchange.com/questions/661237/weight-argument-glm-in-r</link>
      <description><![CDATA[我有一个心理物理学实验，我正在根据对比度测量参与者是否能看到刺激。
我的逻辑回归有两个选项。1) 使用原始数据（0 和 1）来表明他们是否看到了刺激。
但是，我所依据的分析论文对转换后的数据运行二项式（概率单位）GLM，其中考虑了假阳性率。因此，选项 2) 是遵循该论文，让结果变量取 0 到 1 之间的值。
这样，我的数据点就会少很多，因为它们会根据刺激参数折叠起来，从而得到转换后的结果变量。
所以问题是：我可以使用 R 的 GLM 中的权重参数来指定每个单独的转换数据点代表多少次试验吗？
抱歉解释得这么长，但我认为一些背景知识是相关的。
我已经尝试了这两个选项，以及使用没有权重的转换结果变量，它们都产生了不同的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/661237/weight-argument-glm-in-r</guid>
      <pubDate>Tue, 11 Feb 2025 12:10:09 GMT</pubDate>
    </item>
    <item>
      <title>如何从数学上正确计算每个协变量对总模型概率预测的概率加法？</title>
      <link>https://stats.stackexchange.com/questions/661218/how-to-mathematically-properly-calculate-the-probabilistic-addition-of-each-cova</link>
      <description><![CDATA[抱歉，事先已注明。

y&#39; (P) = 1 / (1 + exp(-sum(betas times Xs))) 1

我想知道我的每个 x 对 P 贡献了多少 p，以便它们的总和恰好等于 P。
我的模型的参数是：
logreg_coefs = (139.8640, 11.3660, 61.3583, 115.9492, 237.9015, 38.8623, -3.5466)


假设我有协变量：
协变量 = (0.5, 0.3, 0.2, 0.1, 0, 0, 1)

如果我将 1 用于各个协变量，我会得到奇怪的数字，例如，对于零协变量值，我得到 p = 1/2（期望得到它零...）。
我尝试对各个 ps 求和，然后取份额，但我得到的值 &gt; 0，其中我的协变量为零，因此 b*x 给出零。
稍后更新
我回想起了通过增加模型的阶数（从仅截距到完全协变量存在）来逐步改进模型的做法。考虑到这一点，我可以重现累积概率计算，并对概率值进行一步减差分。至少我现在看到的是更正确的值，并且具有完美的求和结果。
python 中的代码执行以下操作：
logreg_coefs = (139.8640, 11.3660, 61.3583, 115.9492, 237.9015, 38.8623, -3.5466)

exogs = (0, 0.02, 0.03, 0.004, 0.005, 0.006, 1)

exog_ps = []

bx = 0

for x, b in zip(reversed(exogs), reversed(logreg_coefs)):
bx += b * x
exog_ps.append(1 / (1 + np.exp(-bx)))

打印(exog_ps)

x_adds_p = []

exog_ps_reversed = list(reversed(exog_ps))

对于 i 在范围(len(exog_ps_reversed)-1)内：
x_adds_p.append(exog_ps_reversed[i] - exog_ps_reversed[i + 1])

x_adds_p.append(exog_ps[0])

打印(x_adds_p)

打印(sum(x_adds_p))

logreg_prob = 1 / (1 + np.exp(-1 * np.sum(np.array(exogs) * np.array(logreg_coefs))))

打印(logreg_prob)

打印(logreg_prob - sum(x_adds_p))

]]></description>
      <guid>https://stats.stackexchange.com/questions/661218/how-to-mathematically-properly-calculate-the-probabilistic-addition-of-each-cova</guid>
      <pubDate>Tue, 11 Feb 2025 09:59:05 GMT</pubDate>
    </item>
    <item>
      <title>当经验分布收敛时，NLL-交叉熵等价性对于独立数据成立吗？</title>
      <link>https://stats.stackexchange.com/questions/661216/does-the-nll-cross-entropy-equivalence-hold-for-independent-data-when-the-empiri</link>
      <description><![CDATA[在这个先前的问题中，已确定对于 IID 数据，负对数似然 (NLL) 相当于模型与经验分布之间的交叉熵。
对于独立数据（即使分布不同），也可以将联合似然分解为各个项。例如，如果数据点 $(x_1, x_2, \dots, x_n)$ 独立且各自的密度为 $p_i(x)$，则联合似然由
$$
p(x_1, x_2, \dots, x_n) = \prod_{i=1}^n p_i(x_i),
$$
负对数似然变为
$$
-\log p(x_1, x_2, \dots, x_n) = -\sum_{i=1}^n \log p_i(x_i)。
$$
这种分解使我们能够将平均 NLL 直接与使用经验分布计算的交叉熵联系起来
$$
\hat{P}_n(x) = \frac{1}{n}\sum_{i=1}^{n}\delta(x - x_i)。
$$
相比之下，对于依赖数据，联合似然不会以如此直接的方式分解。相反，它必须使用条件密度来表达：
$$
p(x_1, x_2, \dots, x_n) = p(x_1) \prod_{i=2}^n p(x_i \mid x_1, \dots, x_{i-1}),
$$
这样 NLL 就变成
$$
-\log p(x_1, x_2, \dots, x_n) = -\log p(x_1) - \sum_{i=2}^n \log p(x_i \mid x_1, \dots, x_{i-1})。
$$
此处，依赖结构（条件项）阻止对经验分布进行简单平均以恢复模型和数据之间的交叉熵。
现在，假设数据是独立的（但不一定是相同分布的），并且经验分布收敛。这种收敛是否意味着平均 NLL 和交叉熵之间的等价性成立，就像在 IID 情况下一样？或者在处理独立但不相同的数据时是否还有其他微妙之处？
任何关于此主题的见解、参考或示例都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/661216/does-the-nll-cross-entropy-equivalence-hold-for-independent-data-when-the-empiri</guid>
      <pubDate>Tue, 11 Feb 2025 09:32:19 GMT</pubDate>
    </item>
    <item>
      <title>具有不确定性的泊松过程的中值预期上限</title>
      <link>https://stats.stackexchange.com/questions/661210/median-expected-upper-limit-for-a-poisson-process-with-uncertainties</link>
      <description><![CDATA[考虑这样一个问题：在存在不确定的背景速率 $b$ 的情况下，确定过程信号速率 $s$ 的上限。背景速率受到另一次测量的限制，在该测量中观察到 $b_{obs}$ 个事件。观察到 $n_{obs}$ 个事件的总可能性由以下公式给出：
$$
L(s,b| n_{obs}, b_{obs}) = Pois(n_{obs}| s+b) \times Pois(b_{obs} | b)
$$
其中 $Pois(x|\lambda)$ 表示随机变量 $x$ 具有泊松分布，速率参数为 $\lambda$。
这里感兴趣的参数是 $s$。我理解如何建立置信区间，或者对于这个问题更重要的是，使用各种频率学派技术和玩具蒙特卡罗实验提取上限。现在我所苦苦挣扎的是如何计算“预期”中位数上限。几篇文章（我稍后会添加参考资料）只是说，应该在背景唯一的假设中执行“玩具 MC 实验”，将它们视为数据，然后从那里构建上限的分布。如何生成玩具？具体来说，$b$ 使用什么值？
任何帮助都将非常棒！
编辑：我对可能性中的术语做了一些澄清。关于参考资料：[1] 第 2 页，第 7 步提到应该生成背景唯一的玩具，但没有说明如何处理干扰参数。这就是引发我困惑的原因。在我看来，至少从语义上讲，“中位数预期”限制不应该取决于观察到的数据。也许正是这最后一句话是错误的。
[1] https://indico.cern.ch/event/126652/contributions/1343592/attachments/80222/115004/Frequentist_Limit_Recommendation.pdf]]></description>
      <guid>https://stats.stackexchange.com/questions/661210/median-expected-upper-limit-for-a-poisson-process-with-uncertainties</guid>
      <pubDate>Tue, 11 Feb 2025 05:56:06 GMT</pubDate>
    </item>
    <item>
      <title>通过模拟进行对数秩检验的功效</title>
      <link>https://stats.stackexchange.com/questions/661209/power-of-logrank-test-through-simulation</link>
      <description><![CDATA[对数秩检验样本量公式由 Lachin 和 Foulkes (1986) 制定，题为“评估样本量和生存分析的功效，同时考虑患者入组不均匀、失访、不依从和分层”。我正在运行一个玩具模拟来查看公式的准确性。按照论文的符号，患者在 R 年的累积期内被招募，并被跟踪到研究结束 T 年。假设 R = 3、T =5、指数生存、均匀累积，并且在研究结束前没有其他审查，geDesign 包中的 nSurvival 函数使用 Lachin 和 Foulkes (1986) 方法，并给出样本量 = 368 以达到 90% 的功效：
# 事件发生时间样本量计算 (Lachin-Foulkes)
library(gsDesign)

ss &lt;- nSurvival(
lambda1 = .3, lambda2 = .2, eta = 0, Ts = 5, Tr =3,
sided = 1, alpha = .05
)
ss

以下是我的模拟代码来验证此方法：
n &lt;- 368
后续 &lt;- 2
eff &lt;- 0
Nsim &lt;- 20000
级别 &lt;- 0.05
lamda1 &lt;- .2
lamda0 &lt;- .3
p &lt;- 1/2
R &lt;- 3

for (i in 1:Nsim){
trt &lt;- rbinom(n,1,p)

cumentrytime &lt;- runif(n,0,R) #统一应计
censorT &lt;- R + 后续 # 研究结束 T =5

T1 &lt;- rexp(n,lamda1) #指数生存
T0 &lt;- rexp(n,lamda0)
T &lt;- T1
T[trt==0] &lt;- T0[trt==0]

statustrue &lt;- (T+cumentrytime &lt; censorT) # 如果事件时间在研究结束之前，则 status = 1
T[statustrue==0] &lt;- censorT-cumentrytime[statustrue==0] # 审查对象的曝光时间

logrank_testfinal &lt;- survdiff(Surv(T, statustrue) ~ trt)
pvaluefinal &lt;- pchisq(logrank_testfinal$chisq, length(logrank_testfinal$n)-1, lower.tail = 
FALSE)
if (pvaluefinal &lt; level ) eff &lt;- eff+1 
}

eff/Nsim

结果功效约为 83%。模拟和公式之间的功效差异 7% 是否在预期范围内（假设我的模拟进行了公平比较）？如果没有，是否有其他样本量计算公式可以得出与模拟更一致的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/661209/power-of-logrank-test-through-simulation</guid>
      <pubDate>Tue, 11 Feb 2025 03:26:49 GMT</pubDate>
    </item>
    <item>
      <title>偏回归系数线性模型中的缩放坐标（纬度和经度）</title>
      <link>https://stats.stackexchange.com/questions/661202/scaling-coordinates-latitude-and-longitude-in-a-linear-model-for-partial-regre</link>
      <description><![CDATA[我有一个数据集，我想比较一下偏回归系数。我在多个地方都读到，预测变量应该是均值中心化的，并按 1 个标准差缩放，以便于实现这一点，特别是当变量的尺度相差很大时。但是，我的一个预测变量恰好是经度。一般示例：
响应变量 ~ 中心化和缩放变量 1 + 中心化和缩放变量 2 + 经度 + 
中心化和缩放变量 1：中心化和缩放变量 2 + 
中心化和缩放变量 1：经度 + 
中心化和缩放变量 2：经度)

似乎惯例是将所有变量中心化/缩放或不缩放，但这让我想知道缩放和中心化对于纬度和经度是否必要且合适。我偶然发现了这篇 StackOverflow 帖子，似乎暗示答案可能是“否”因为它扭曲了坐标的含义：
（https://stackoverflow.com/questions/48426533/variation-partitioning-using-latitude-and-longitude-as-explanatory-variables）
但是，如果我主要对系数感兴趣，我不太明白在多元线性回归的背景下，缩放和居中纬度/经度是否不合适？
感谢您对此的任何想法！]]></description>
      <guid>https://stats.stackexchange.com/questions/661202/scaling-coordinates-latitude-and-longitude-in-a-linear-model-for-partial-regre</guid>
      <pubDate>Mon, 10 Feb 2025 22:44:18 GMT</pubDate>
    </item>
    </channel>
</rss>