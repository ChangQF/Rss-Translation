<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 18 Sep 2024 01:12:04 GMT</lastBuildDate>
    <item>
      <title>估计玩硬币 1 的后验概率</title>
      <link>https://stats.stackexchange.com/questions/654521/estimating-the-posterior-probability-of-playing-coin-1</link>
      <description><![CDATA[假设某人有两枚硬币，掷出正面的概率分别为 p_1 和 p_2，且 p_2 小于 p_1。此人正在抛硬币，可能以概率 gamma 从掷硬币 1 切换到掷硬币 2，但是一旦他们开始掷第二枚硬币，他们就不会再切换回掷第一枚硬币。我们看到了结果，但是我们不知道此人掷的是第一枚硬币还是第二枚硬币。鉴于我们不知道 p_1、p_2 和 gamma 的确切值，我们如何计算此人掷的硬币是第二枚硬币的后验概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/654521/estimating-the-posterior-probability-of-playing-coin-1</guid>
      <pubDate>Wed, 18 Sep 2024 00:18:40 GMT</pubDate>
    </item>
    <item>
      <title>如何使用高斯混合模型执行用户辅助图像分割？</title>
      <link>https://stats.stackexchange.com/questions/654520/how-to-perform-user-assisted-image-segmentation-using-gaussian-mixture-models</link>
      <description><![CDATA[我对高斯混合模型有一个大致的了解。我的理解：

GMM 是一种聚类数据点的方法，与 K 均值聚类不同，它通过计算后验 $P(\theta_k|X)$ 将它们软分配到不同的分布下，其中 $\theta_k$ 是分布 k 的参数。这是通过期望最大化完成的，其中对数似然函数针对每个分布的参数最大化并更新直到算法收敛。

我仍然不明白分割的“用户辅助”部分是如何工作的。另外，我的讲座中提到，每个类都有自己的高斯混合，用于计算后验概率，并且像素被分配给具有更高概率的类，但我无法理解这个说法。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654520/how-to-perform-user-assisted-image-segmentation-using-gaussian-mixture-models</guid>
      <pubDate>Tue, 17 Sep 2024 23:36:35 GMT</pubDate>
    </item>
    <item>
      <title>样本量相对较小的弹性网络的优势是什么？</title>
      <link>https://stats.stackexchange.com/questions/654519/advantages-of-elastic-net-with-relatively-small-sample-sizeh</link>
      <description><![CDATA[我正在使用样本量为 75 和 140 个变量（特征）进行弹性网络 (EN) 回归。我使用 cv.glmnet 设置最佳 lambda，然后使用 glmnet 执行弹性网络 (EN) 回归。以下是我的一些问题

我计划选择在 5000 次迭代中至少出现 3500 次（70%）的特征。在迭代期间使用 70% 或 80% 作为截止值有什么理由吗？目前，它似乎是一种没有明确依据的启发式方法。

除了弹性网络提供系数之外，在我的数据中使用弹性网络还有其他优势吗？当我绘制相关性图时，大约 90% 的变量显示出显著相关性 (p&lt;0.05)，大约 30% 的变量具有 r&gt;0.5，表明存在多重共线性。

我正在使用 Elastic Net 进行分类、回归和预测。对于使用所有 140 个特征进行初始特征选择和比较，我在单变量线性回归中选择了 p &lt; 0.05 的特征（用于回归），并在具有 4 个协变量的 ANCOVA 中选择了显著到中等影响 (p &lt; 0.1) 的变量（用于分类）。由于这只是选择变量的过程，我是否需要使用 FDR 校正的 p 值，尤其是在 ANCOVA 的情况下？

]]></description>
      <guid>https://stats.stackexchange.com/questions/654519/advantages-of-elastic-net-with-relatively-small-sample-sizeh</guid>
      <pubDate>Tue, 17 Sep 2024 23:22:33 GMT</pubDate>
    </item>
    <item>
      <title>均值的非参数检验？</title>
      <link>https://stats.stackexchange.com/questions/654515/nonparametric-test-for-means</link>
      <description><![CDATA[是否有使用两个独立样本的非参数均值相等性检验？
最流行的非参数检验是比较中位数。这是有道理的，因为它们对异常值更稳健，而在教科书中，异常值是第一种情况下使用非参数检验的动机。
但在现实世界中，使用非参数检验的另一个动机是保护自己免受应用期刊的误导性评论者的误导，他们认为数据生成过程的正态性是进行 z 检验的必要条件。
如果潜在的研究问题涉及均值而不是中位数，是否有可以部署的专门的非参数程序？（当然，可以进行引导等，但只是好奇）。]]></description>
      <guid>https://stats.stackexchange.com/questions/654515/nonparametric-test-for-means</guid>
      <pubDate>Tue, 17 Sep 2024 22:26:06 GMT</pubDate>
    </item>
    <item>
      <title>计算具有特殊规则的彩票盈亏平衡的通用公式</title>
      <link>https://stats.stackexchange.com/questions/654509/general-formula-to-find-break-even-of-lottery-with-special-rules</link>
      <description><![CDATA[我正在研究一种动态彩票，其工作原理如下：每次彩票最终都会抽出一个数字。彩票运营者可以决定难度，即该彩票的独立数字数量。对于难度为 3 的彩票，彩票将在 000 到 999 之间随机选择，难度在 0000 到 9999 之间，依此类推。他们还可以决定彩票价格和他们出售的彩票数量。我试图概括一个彩票公式，该公式将提供“统计上的盈亏平衡”，因此跑者可以使用参数来建立小优势，或者让玩家处于优势地位。我的第一个想法是将中奖彩票的概率乘以彩票价格，再乘以售出的彩票数量，我预计这必须等于跑者所做的投资（他们投入了头奖）。但它似乎不是这样运作的。想象一下难度为 3 的彩票，票价为 2 美元，所有可能的彩票都在出售，公式会给出：1/10^3 * 2 * 1000 = 2？2 是什么意思？我应该如何调整这个公式来实现我的目标？]]></description>
      <guid>https://stats.stackexchange.com/questions/654509/general-formula-to-find-break-even-of-lottery-with-special-rules</guid>
      <pubDate>Tue, 17 Sep 2024 20:50:15 GMT</pubDate>
    </item>
    <item>
      <title>基于模量函数的随机化有效性</title>
      <link>https://stats.stackexchange.com/questions/654506/randomization-validity-based-on-a-modulus-function</link>
      <description><![CDATA[我想在仅支持基于 address_id 分配变体的平台上运行 AB 测试。在我们的平台上，每个用户可以有多个 address_id，即每个 user_id 可以映射到多个 address_id。我想确保每个 user_id 的有效随机化。我相信我的测试有两个选项。

排除具有多个 address_id 的用户，仅对只有一个 address_id 的用户运行测试。（包括具有多个 address_id 的用户意味着在测试期间可能会有用户根据其不同的 address_id 被分配到 A 和 B，因此这违反了组的独立性）

创建称为 bucket_number 的东西，并将 bucket 分配给不同的组。这将以以下方式工作：

根据供应商 ID 计算 bucket 编号。这可以通过 supplier_id mod 10 来计算。每个供应商将始终以这种方式获得一个存储桶编号。
此存储桶编号将分配给一个变体，例如存储桶编号 0-4 分配给 A，存储桶编号 5-9 分配给 B。
这样，每个供应商将始终被分配给相同的变体。



我强烈倾向于方法 2。即创建存储桶编号。但我想检查这是否仍然是一种有效的随机化方法？（请注意，原始 supplier_id 是按顺序创建的随机数，因此没有理由相信 supplier_id 的模数会以某种方式导致偏差）
我的问题：方法 2 有效吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654506/randomization-validity-based-on-a-modulus-function</guid>
      <pubDate>Tue, 17 Sep 2024 20:19:22 GMT</pubDate>
    </item>
    <item>
      <title>具有协变量的多元时间序列聚类</title>
      <link>https://stats.stackexchange.com/questions/654505/clustering-multivariate-time-series-with-covariates</link>
      <description><![CDATA[我有大约 500k 个 3 维时间序列，我想对其进行聚类。每个时间序列都有几个与时间无关的协变量。我想对时间序列进行聚类，并找出与每个聚类相关的协变量。
目前，我正在使用带有 dtw 的 k-means 对时间序列进行聚类，并在具有协变量的聚类标签上创建回归。
有没有更好、更标准的方法来实现这一点？例如，包括协变量的聚类以最小化偏差。]]></description>
      <guid>https://stats.stackexchange.com/questions/654505/clustering-multivariate-time-series-with-covariates</guid>
      <pubDate>Tue, 17 Sep 2024 19:25:51 GMT</pubDate>
    </item>
    <item>
      <title>如果病例总数有限，则确定抽样规模[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654503/sampling-size-determination-if-total-number-of-cases-is-finite</link>
      <description><![CDATA[我正在尝试确定每个月应审核多少案件，以便准确代表每年收到的案件总数。
每年收到 1400 项调查。我使用 calculator.net 样本量计算器来确定样本量。
302 样本量是今年的答案。
25/月。
4 个团队。
6/团队
这种方法正确吗？所以每个团队每月应该审查 6 个案件？]]></description>
      <guid>https://stats.stackexchange.com/questions/654503/sampling-size-determination-if-total-number-of-cases-is-finite</guid>
      <pubDate>Tue, 17 Sep 2024 19:11:49 GMT</pubDate>
    </item>
    <item>
      <title>具有伪观测值的模型中的变量选择（生存分析）</title>
      <link>https://stats.stackexchange.com/questions/654502/variable-selection-in-models-with-pseudo-observations-survival-analysis</link>
      <description><![CDATA[我需要使用伪观测值进行生存研究。因此，我使用 R 中的 eventglm 包以及函数 cumincglm 和 rmeanglm。在我的数据集中，我有许多变量，我想为这些类型的模型（cumincglm 和 rmeanglm）执行变量选择。是否可以使用我们用于经典 GLM 的命令（例如 step() 或 dropterm()）进行变量选择？如果不行，我该如何进行变量选择？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654502/variable-selection-in-models-with-pseudo-observations-survival-analysis</guid>
      <pubDate>Tue, 17 Sep 2024 19:07:56 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分析中的异常预测是否可能？</title>
      <link>https://stats.stackexchange.com/questions/654498/is-anomaly-forecasting-in-time-series-analysis-possible</link>
      <description><![CDATA[我目前正在研究单变量时间序列数据，我想知道时间序列中是否可以进行异常预测。
我之前从事过异常检测，即在异常发生时检测异常（基本上使用基本事实进行检测）。但现在我得到了一个相对具有挑战性的任务，必须在异常发生之前进行预测。由于这是一种异常，所以不会有趋势，而且类别不平衡是显而易见的。
如果不是时间序列数据，那么一些采样技术（例如过采样和欠采样）将有助于平衡异常和非异常数据类别（例如电子邮件中的欺诈检测）。由于它是时间序列数据，因此在采样时可能会获得重复的时间戳。
如果有人能对此提供一些见解，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654498/is-anomaly-forecasting-in-time-series-analysis-possible</guid>
      <pubDate>Tue, 17 Sep 2024 18:11:15 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归中对数变换解释变量的解释</title>
      <link>https://stats.stackexchange.com/questions/654496/interpretation-of-log-transformed-explanatory-variable-in-poisson-regression</link>
      <description><![CDATA[我需要解释泊松模型中经过对数变换的系数。我们称该系数为 log(1+EO)。系数估计值为 0.0651。
EO（即未经对数变换）的平均值是 0.505。标准差为 2.008。
我想计算 EO 增加一个标准差的影响。
我以对数形式计算出一个标准差超过平均值的增加，如下所示：
ln(1+0.505+2.008)-ln(1+0.505)
然后，我计算出 EO 增加一个标准差的经济意义，如下所示：(exp(0.0651) -1) * 100 * (ln(1+0.505+2.008) - ln(1+0.505)) = 5.71%
这是正确的做法吗？我知道，如果没有对数转换，您只需取 exp(coeff)，但对数转换似乎使事情变得复杂。
非常感谢您的见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/654496/interpretation-of-log-transformed-explanatory-variable-in-poisson-regression</guid>
      <pubDate>Tue, 17 Sep 2024 17:22:46 GMT</pubDate>
    </item>
    <item>
      <title>关于可视化的 y 轴范围的选择</title>
      <link>https://stats.stackexchange.com/questions/654491/on-choice-of-y-axis-range-for-visualization</link>
      <description><![CDATA[假设某种疾病的患病率很低。患病率是介于 0% 到 100% 之间的比例。我想可视化患病率随时间的变化趋势。（为了简单起见，我们假设可视化患病率是唯一正确的方法。）
假设 t=1、2 和 3 时的患病率分别为 1%、1.5% 和 1.75%。我们还假设与流行率相关的 CI 比较宽泛。
选项 1：我可以绘制流行率随时间变化的图表，y 轴范围从 0 到 2%，以显示增加趋势。
选项 2：我可以绘制流行率随时间变化的图表，y 轴范围从 0 到 10%，以显示略微增加的趋势。
选项 3：我可以绘制流行率随时间变化的图表，y 轴范围从 0 到 100%，以显示几乎没有增加趋势。
$Q:$ 是否有关于可视化 y 轴范围选择的指南？如果患病率足够高，我会使用 y 轴，范围为 0 到 100%。
$Q:$ 从趋势测试的测试结果来看，我应该以合乎道德的方式报告哪张图表？（有 4 种情况，显著且临床相关、不显著且临床相关、不显著且临床不相关、不显著且临床不相关。）似乎我所做的一切都是在进行宣传。如果人口规模较小，我可以看到选项 2 可能是合理的。如果人口众多，选项 1 可能是合理的，表明随着时间的推移，越来越多的人患上这种疾病。]]></description>
      <guid>https://stats.stackexchange.com/questions/654491/on-choice-of-y-axis-range-for-visualization</guid>
      <pubDate>Tue, 17 Sep 2024 16:05:10 GMT</pubDate>
    </item>
    <item>
      <title>比较具有和不具有交互项的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/654485/comparing-linear-mixed-models-with-and-without-interaction-terms</link>
      <description><![CDATA[我想比较具有和不具有交互项的不同模型，看看哪一个最适合我的数据。我只是想检查我的方法是否正确。
我像这样构建我的模型
my_model &lt;- lmer(myoutcome ~ predictor1 + predictor2 + 
predictor3 + covariate1 + (1 | ParticipantID), data = mydata)

my_model2 &lt;- lmer(myoutcome ~ predictor1*predictor2 + 
predictor1*predictor3 + predictor2*predictor3 + covariate1 +
(1 | ParticipantID), data = mydata)

my_model3 &lt;- lmer(myoutcome ~ predictor1*predictor2*predictor3 + 
covariate1 + (1 | ParticipantID), data = mydata)

然后，我会像这样比较它们，看看添加二向和三向交互项是否会改善模型。
anova(my_model, my_model2, my_model3)

我还在考虑简约性、AICc 和对数似然等因素。
我有以下问题：

将所有双向交互项都包含在单个模型中是否正确？
在更复杂的模型中同时指定主效应和交互作用是否正确？ （因此 predictor1*predictor2 而不是 predictor1:predictor2
如果我对所有双向交互都不感兴趣，我可以将 my_model2.1 &lt;- lmer(myoutcome ~ predictor1*predictor2 + predictor3 + covariate1 + (1 | ParticipantID), data = mydata) 之类的模型与 model3 进行比较吗？
我还应该将我的协变量包括在我的交互模型中吗？
在报告主要影响和交互作用时，我被教导要报告第一个模型的主要影响，并且只报告交互模型的交互影响。但是我现在质疑这是否正确。例如，使用上述方法，我得到了以下仅具有固定效应的模型摘要


此摘要包含一个双向交互作用

我们可以看到，在仅具有固定效应的模型中不显著的变量之一（第二行），在模型中包含交互项时现在变得显著（它是交互作用中的变量之一）。报告结果时，我应该使用第一个还是第二个表中的值？请注意，我不是在谈论解释 - 因为交互作用无论如何都符合主效应，我只是想知道哪些数据应该包含在我的结果表中 :)
提前致谢！
编辑：我有一个 2x2 混合组研究设计，其中一个组间变量（2 个级别）和一个组内变量（2 个级别），因此我使用混合建模。我收集了用于验证性假设检验（即推断统计）的数据]]></description>
      <guid>https://stats.stackexchange.com/questions/654485/comparing-linear-mixed-models-with-and-without-interaction-terms</guid>
      <pubDate>Tue, 17 Sep 2024 13:38:00 GMT</pubDate>
    </item>
    <item>
      <title>对零假设下 p 值的均匀分布感到困惑</title>
      <link>https://stats.stackexchange.com/questions/654484/confused-about-the-uniform-distribution-of-p-values-under-the-null-hypothesis</link>
      <description><![CDATA[我目前正在学习一门生物信息学入门课程，我对零假设下（当零假设为真时）p 值的均匀分布感到困惑。
已经广泛证明和讨论过，在正确的条件下，当零假设成立时，p 值是均匀分布的，正如这篇文章所解释的那样：为什么 p 值在零假设下是均匀分布的？。
我的困惑更多的是关于这个想法背后的直觉和实际意义。
例如，让我们考虑一个简单的（尽管是离散的）场景：抛硬币。如果掷出正面的概率（表示为&quot;1&quot;）为 $p = 0.3$，且我们进行 $1000$ 次抛掷，我们预计大多数情况下掷出正面的次数约为 $300$ 次。因此，我们预计在大多数情况下 p 值将在 $P(X &lt; 300)$ 左右（左尾 p 值，其中 $X$ 是二项式（$1000$，$p$）变量）。
但是，这似乎与 p 值在零假设下应均匀分布的想法相矛盾。如果 p 值是均匀的，那么所有 p 值是否都应该具有同等可能性，而不是聚集在某个值附近？
有人可以解释为什么这个均匀分布在这个例子中仍然成立，或者我是否误解了一些基本的东西？
我已运行以下模拟作为示例：
library(ggplot2)

n_experiments &lt;- 100000 # 实验次数（抛硬币）
n_trials &lt;- 100000 # 每个实验的试验次数
p &lt;- 0.3 # 获得“1”（成功）的概率

# 模拟实验
set.seed(123) # 为了可重复性
results &lt;- rbinom(n_experiments, n_trials, p) # 每个实验中 1 的数量

# 计算每个实验的 p 值
p_values &lt;- sapply(results, function(x) pbinom(x, n_trials, p))

# 创建用于绘图的数据框
df &lt;- data.frame(Experiment = 1:n_experiments, 
Number_of_1s = results, 
p_value = p_values)

# 绘制“1”的数量直方图
ggplot(df, aes(x = Number_of_1s)) +
geom_histogram(binwidth = 1, fill = &#39;skyblue&#39;, color = &#39;black&#39;) +
labs(title = &quot;100 次实验中 1 的数量直方图&quot;, 
x = &quot;1 的数量&quot;, 
y = &quot;频率&quot;) +
theme_minimal()

# 绘制 p 值的直方图
ggplot(df, aes(x = p_value)) +
geom_histogram(binwidth = 0.01, fill = &#39;coral&#39;, color = &#39;black&#39;) +
labs(title = &quot;100 次实验中的 p 值直方图&quot;, 
x = &quot;p 值&quot;, 
y = &quot;频率&quot;) +
theme_minimal()

我发现以下预期结果对我来说感觉矛盾，值的分布不均匀，但 p 值的分布是均匀的。

]]></description>
      <guid>https://stats.stackexchange.com/questions/654484/confused-about-the-uniform-distribution-of-p-values-under-the-null-hypothesis</guid>
      <pubDate>Tue, 17 Sep 2024 13:24:56 GMT</pubDate>
    </item>
    <item>
      <title>适当测试不同森林类型间微生物丰度的差异</title>
      <link>https://stats.stackexchange.com/questions/654474/appropriate-test-for-difference-in-microbial-abundance-between-forest-types</link>
      <description><![CDATA[我想测试两种森林类型在 10 厘米和 50 厘米处的微生物丰度差异（此时独立）。第一个图（10 厘米）不符合正态性，因此我使用非参数检验，另一个图（50 厘米）符合正态性，因此我使用 T 检验。这是否合适，还是无论如何都应该使用相同的测试？感谢您的任何建议。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654474/appropriate-test-for-difference-in-microbial-abundance-between-forest-types</guid>
      <pubDate>Tue, 17 Sep 2024 10:07:22 GMT</pubDate>
    </item>
    </channel>
</rss>