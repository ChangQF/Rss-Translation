<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 03 Jan 2024 15:13:55 GMT</lastBuildDate>
    <item>
      <title>用于生存分析的对数秩与 Cox 风险模型</title>
      <link>https://stats.stackexchange.com/questions/636068/log-rank-vs-cox-hazard-model-for-survival-analysis</link>
      <description><![CDATA[我是一名肿瘤内科医生，对临床试验设计背后的统计数据有一些疑问。对于菜鸟问题​​，我深表歉意，但我没有统计背景。
我的问题涉及使用对数秩与单变量 cox 回归来比较两组之间的生存曲线。假设满足比例风险假设，为什么我看到临床试验执行对数排序来导出p值，然后使用cox风险模型来导出HR和CI，难道不能直接使用cox回归模型来完成吗？
此外，我看到临床试验对每个协变量进行分层对数排名，然后仅对显着协变量的多变量模型使用 cox 回归分析。同样在这种情况下，假设满足比例风险假设，这是执行对数排名而不是单变量 cox 回归的意义吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/636068/log-rank-vs-cox-hazard-model-for-survival-analysis</guid>
      <pubDate>Wed, 03 Jan 2024 14:53:36 GMT</pubDate>
    </item>
    <item>
      <title>MLE 的方差和后验方差何时匹配？</title>
      <link>https://stats.stackexchange.com/questions/636067/when-do-variance-of-mle-and-variance-of-posterior-match</link>
      <description><![CDATA[假设高斯似然，$y \mid x, w \sim \mathcal{N}(w^\top x, \sigma^2)$,最小二乘估计的方差 $\hat{w} = \mathrm{argmax}_w p(y \mid X, w)$ 为 $\mathbb{V}[\hat{w}\mid X, y] = \sigma^2(X^\top X)^{-1}$。
另一方面，分布 $p(w \mid X, y) \propto p(y \mid X, w)$ （“没有先验的后验分布）是高斯分布，因为 $$
\log p(w \mid X, y) = -\frac{1}{2} \left[\sigma^{-2} w^\top X^\top X w - 2 \sigma^{-2} y^\top X w\right] + \mathrm{const}。
$$
该高斯的方差恰好是 $\mathbb{V}[w \mid X, y] = \sigma^2(X^\top X)^{-1}$&lt; /span&gt; 与最小二乘估计的方差相同。
我想知道这两个方差是否匹配，因为可能性是线性的/高斯的/其他一些原因，或者它的方差是否与“后验”方差匹配是 MLE 的更一般属性。分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/636067/when-do-variance-of-mle-and-variance-of-posterior-match</guid>
      <pubDate>Wed, 03 Jan 2024 14:53:25 GMT</pubDate>
    </item>
    <item>
      <title>估算邮政编码级别数据的缺失观测值</title>
      <link>https://stats.stackexchange.com/questions/636066/imputing-missing-observations-of-zip-code-level-data</link>
      <description><![CDATA[我正在使用 R Studio 寻找一种足够的插补方法来弥补邮政编码级别数据中缺失的观察结果。
我有一个随机样本，其中包含居住在一个城市内不同邮政编码的家庭。我的目标是使用这个样本来合成一个“人造”的东西。这个城市的人口普查。不幸的是，样本中的家庭并未涵盖该城市的所有邮政编码。因此，如果我从这个不完整的样本中进行合成，“人造”就可以了。人口普查也不会涵盖那些缺失的邮政编码。
示例数据具有以下结构：
ID 收入 租金 hh-会员 ... 邮政编码
1 43​​67 453 3 12
2 4372 563 1 23
...

因此，我想通过添加“人工家庭”来估算这些邮政编码。在我从中合成人口普查数据之前，先将其添加到我的样本中。 假设，居住在邻近邮政编码的家庭比居住在非邻近邮政编码的家庭彼此更相似。
有什么通用的方法可以解决这个问题吗？
我希望可能有一个解决此问题的软件包。
非常感谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/636066/imputing-missing-observations-of-zip-code-level-data</guid>
      <pubDate>Wed, 03 Jan 2024 14:38:05 GMT</pubDate>
    </item>
    <item>
      <title>层次原则：谁先定义的？</title>
      <link>https://stats.stackexchange.com/questions/636065/hierarchy-principle-who-defined-it-first</link>
      <description><![CDATA[这里的不同问题涉及交互模型中是否包含主效应的问题，例如此处，此处和这里。
但我发现在交互模型中包含主要术语的一般建议称为“层次结构原则”，例如 此处，或“层次原则”，例如 此处。
这个原理的名称有参考吗？谁用这个名字来命名这个原理的？这个原理第一次使用这个名字是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/636065/hierarchy-principle-who-defined-it-first</guid>
      <pubDate>Wed, 03 Jan 2024 14:35:20 GMT</pubDate>
    </item>
    <item>
      <title>如果在三个时间段内重复测量一个受试者，我应该执行什么测试？</title>
      <link>https://stats.stackexchange.com/questions/636060/what-test-should-i-perform-given-repeated-measures-of-one-subject-in-three-time</link>
      <description><![CDATA[我有代表不同时间（从2018年起每天每小时）空气中PM颗粒浓度测量值的数据，我应该测试新冠病毒封锁的规则是否有任何统计意义意义。数据分为三组（2020 年 3 月至 2020 年 12 月的测量数据，又称第一期 - 严格的锁定规则；21 日 3 月 - 21 日 12 月 - 宽松措施；22 日 3 月 - 22 日 12 月 - 解除锁定）。
从可视化和描述性统计中，我们可以推断，规则越宽松，平均浓度就越高（这意味着PM颗粒物与更多的交通和更多的人之间存在相关性）。但令我困惑的是分析统计和测试的选择。数据不是正态分布的，这使我相信弗里德曼的检验是最合适的。任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/636060/what-test-should-i-perform-given-repeated-measures-of-one-subject-in-three-time</guid>
      <pubDate>Wed, 03 Jan 2024 13:53:43 GMT</pubDate>
    </item>
    <item>
      <title>如何计算标准正态分布的绝对矩？</title>
      <link>https://stats.stackexchange.com/questions/636059/how-to-calculate-absolute-moments-of-the-standard-normal-distribution</link>
      <description><![CDATA[在高频金融计量经济学中，通常需要将数量计算为
$E(|U|^p)=m_p$，其中 $U\overset{d}{= }N_{0,1}$。 R studio中有没有直接的命令来获取这样的数量？]]></description>
      <guid>https://stats.stackexchange.com/questions/636059/how-to-calculate-absolute-moments-of-the-standard-normal-distribution</guid>
      <pubDate>Wed, 03 Jan 2024 13:43:24 GMT</pubDate>
    </item>
    <item>
      <title>SPSS 中二分变量的最佳聚类方法</title>
      <link>https://stats.stackexchange.com/questions/636058/best-cluster-approach-for-dichotomous-variables-in-spss</link>
      <description><![CDATA[我正在互联网上阅读相互矛盾的信息，并想了解一些关于使用统计方法的想法。为了便于解释，我将使用一个虚构的示例。
我有一组八个不同的二分变量，代表是否存在症状。例如，“疼痛”（是/否）、“恶心”（是/否）等。当然，我将它们全部编码为 1/0 表示存在/不存在。
我想看看某些症状是否聚集在一起。我招募的样本量相当大，为 1575 人，但我想对比两个亚组中的聚类，其中两个亚组分别为 516 名患有疾病的人和 1059 名未患有疾病的人。我喜欢树状图的想法，因此层次聚类分析对我来说似乎很有意义，但 IBM 建议仅对分类数据使用两步分析。我认为 k 均值没有意义（k 模式也没有意义），因为我使用的是二分变量。我在我的领域看到过一篇研究论文，该论文使用 HCA 与树状图和截止相关值来选择簇的数量。他们只是没有合理化他们的方法，所以我不确定这样做在统计上是否准确。
我希望聚类分析中的叶子代表症状，就像互联网上这张图片中的国家/地区所做的那样：

统计分析的一般目的是确定某些症状是否聚集在一起，无论是在非疾病组 (n=1059) 还是在疾病组 (n=516) 中。如果簇之间存在差异，则可能表明潜在的生物学机制可以在以后进行探索。我正在使用最新的 SPSS，因此对于该软件的建议将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/636058/best-cluster-approach-for-dichotomous-variables-in-spss</guid>
      <pubDate>Wed, 03 Jan 2024 13:37:00 GMT</pubDate>
    </item>
    <item>
      <title>R 调查包：将加权患病率与文献结果进行比较</title>
      <link>https://stats.stackexchange.com/questions/636057/r-survey-package-compare-weighted-prevalence-with-literature-result</link>
      <description><![CDATA[我有一个包含血清学测试结果的大型数据集（&gt; 3000 例）。根据这些结果，我想计算该疾病的加权患病率。数据是分类的（0 = 不存在疾病；1 = 存在疾病）。 12例有此病。根据人口数据按逆向选择概率进行加权后，我得出的加权患病率为 +/- 0.25%（95% CI 0.10% - 0.45%）。
现在我想将此结果与报告的历史患病率进行比较。不幸的是，关于旧结果的信息非常少，并且不可能重建当时使用的权重。该出版物报告加权患病率为 0.7% (95% CI 0.5 - 0.8)，其中 13/1830 例呈阳性。
基于 CI 不重叠的事实，我知道它们具有统计显着性，但我可以使用什么测试来比较结果并生成 p 值？我认为应该考虑我的数据集的调查设计，并且应该考虑事件数量较少。]]></description>
      <guid>https://stats.stackexchange.com/questions/636057/r-survey-package-compare-weighted-prevalence-with-literature-result</guid>
      <pubDate>Wed, 03 Jan 2024 13:15:11 GMT</pubDate>
    </item>
    <item>
      <title>$\mathbb{E}[\frac{1}{1 + X}]$ 的上限，其中 $\mathbb{E}[X] = a$ 且 $0<𝑎<1$</title>
      <link>https://stats.stackexchange.com/questions/636056/upper-bound-on-mathbbe-frac11-x-where-mathbbex-a-and-0</link>
      <description><![CDATA[$𝑋$ 是一个正随机变量（可能无界），其中 $0 \le \mathbb{E}[X ] = a &lt; 1 美元。
由于 $\phi(x) = \frac{1}{x}$ 是凸函数，我们可以使用 Jensen 不等式导出下界：
$\mathbb{E}[\frac{1}{1 + X}] \ge \frac{1}{1 + \mathbb{E}[X]} = \frac {1}{1 + a}$。
是否可以得出上限？
一个简单的上限是 1，因为 $X$ 是正数。我们能否得出涉及 $a$ 的上限，或者至少有关 $X$ 的更多信息？&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/636056/upper-bound-on-mathbbe-frac11-x-where-mathbbex-a-and-0</guid>
      <pubDate>Wed, 03 Jan 2024 13:00:11 GMT</pubDate>
    </item>
    <item>
      <title>如何处理机器学习模型特征工程中的无限值</title>
      <link>https://stats.stackexchange.com/questions/636054/how-to-handle-infinite-values-in-feature-engineering-for-machine-learning-models</link>
      <description><![CDATA[我目前正在从事一个机器学习项目，在该项目中我正在创建与通信网络中发送和接收的字节比率相关的新功能。然而，我面临着一个挑战：当接收到的字节数为零时，比率计算会导致无限值。这对于我的机器学习模型来说是有问题的。
我正在寻求有关在特征工程中处理此类无限值的最佳实践的建议。具体来说，我的问题是：

处理无限值的最有效方法是什么
功能，特别是在比率计算（例如字节）的情况下
发送/接收？我应该用特定的值替换这些无限值吗？
数字，或者是否有更细致的方法可以产生更好的结果
机器学习建模的结果？有没有标准
业界处理此类问题的做法，
特别是在网络数据分析方面？

任何见解、研究论文参考或个人经验的例子将不胜感激。
预先感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/636054/how-to-handle-infinite-values-in-feature-engineering-for-machine-learning-models</guid>
      <pubDate>Wed, 03 Jan 2024 12:36:52 GMT</pubDate>
    </item>
    <item>
      <title>如何从平均、最大预测和历史数据中获取每小时预测</title>
      <link>https://stats.stackexchange.com/questions/636053/how-to-get-an-hourly-forecast-from-mean-max-forecast-and-historicals</link>
      <description><![CDATA[我有一个月（比如一月）的每小时历史温度曲线。我还有 2024 年 3 月的月度峰值和月度平均预测（两个值）。使用这个 - 我们如何获得每小时的预测曲线 - 使得平均值和峰值与预测相同。
一个简单的转换也可以。
我想过按平均值或峰值进行缩放，但发现很难以直观的方式拟合第二个变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/636053/how-to-get-an-hourly-forecast-from-mean-max-forecast-and-historicals</guid>
      <pubDate>Wed, 03 Jan 2024 12:09:37 GMT</pubDate>
    </item>
    <item>
      <title>如何处理极其平滑的对数似然？</title>
      <link>https://stats.stackexchange.com/questions/636052/how-to-deal-with-extremely-smooth-log-likelihood</link>
      <description><![CDATA[我有一个具有四个参数的对数似然函数，其中两个参数的似然变化非常平滑。这表明对于这两个参数的较大范围，导数很小。尽管我知道有一个最大值，但我从未通过尝试过的任何优化（本地或全局）来实现它。如果我使用自己的梯度函数，则需要花费大量时间才能收敛，并且当收敛时，它会收敛到错误的值。是否有一些技术可以让我处理如此平滑的对数似然？
我在下面的方程中仅使用这两个参数编写可能性。
$$ \log(p(Z|\Theta)) = -\sum_{i = 1}^N \left[ \log(\pi (F(f_i, \Theta))) + \frac{\sum_{l=1}^L Z_l(f_i)}{F(f_i, \Theta)} \right], $$
其中 $Z$ 是测量值，$F$ 是期望的模型测量值是参数的函数。
$$F(f_i, \Theta) = M\left[1+ \sum_{q = 1}^{N-1}\left(1 - \frac{ q}{N}\right)\left[\exp(-j2\pi f_iq)G(q, \Theta) + \exp(j2\pi f_iq)G(-q, \Theta)\right]\right] $$
函数 $G(q, \Theta)$ 很困难。
$G(q, \eta, \Lambda) = \exp(jC_1q) \int_{0}^{\infty} x^\eta \exp(-\Lambda x) \exp(-jC_2\exp(-c_3x)) dx, $ 其中 $\Theta = [\eta, \Lambda]$。我还使用了这个积分的近似值。]]></description>
      <guid>https://stats.stackexchange.com/questions/636052/how-to-deal-with-extremely-smooth-log-likelihood</guid>
      <pubDate>Wed, 03 Jan 2024 11:39:13 GMT</pubDate>
    </item>
    <item>
      <title>值始终为零的估计量是线性估计量吗？</title>
      <link>https://stats.stackexchange.com/questions/636049/is-an-estimator-that-always-have-a-value-of-zero-is-a-linear-estimator</link>
      <description><![CDATA[考虑一个简单的线性回归模型：
$$Y=\beta_0+\beta_1 X +u$$
在这里，我们可以考虑一个不使用任何数据的估计器：
$$\hat{\beta}_1=0$$
也就是说，无论观察到的数据如何，估计值始终为零。
然后，我们可以将估计量写为观察到的因变量的线性函数：
$$\hat{\beta}_1=\sum_i c_i y_i,$$
其中 $c_i=0$ 代表所有 $i=1,\ldots,N$。 
当然，这是一个荒谬的估计器，但是，根据定义，我们可以说 $\hat{\beta}_1$ 是一个线性估计器。&lt; /p&gt;
我很确定这是真的。但是，我想仔细检查一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/636049/is-an-estimator-that-always-have-a-value-of-zero-is-a-linear-estimator</guid>
      <pubDate>Wed, 03 Jan 2024 10:44:18 GMT</pubDate>
    </item>
    <item>
      <title>二元分类器的简化样本量计算</title>
      <link>https://stats.stackexchange.com/questions/636046/simplified-sample-size-calculation-for-binary-classifier</link>
      <description><![CDATA[你好，新年快乐，
我正在考虑最近项目中的一个问题，其中神经网络用于检测某些特定事件 - 所以基本上它是一个二元分类器（是/否）。
我们有大量数据，希望以某种方式非常粗略地估计进一步数据收集所需的样本量。通常我会考虑学习曲线并更喜欢基于模拟的方法，因为深度学习技术是一种黑匣子，无法与假设检验的典型样本量计算相比较。但是，这是不可能的，因为我无法访问该软件，我只想根据可用数据做出非常粗略的猜测。
所以我有一个很大的 n，比如 200000，还有敏感性和特异性的值，比如各 80%。此外，我的患病率非常低，比如 0.1%。现在我只是在考虑一种基本上非常古老的方法（Budeer, 1996），我可以在其中插入这些内容并获取样本大小。这对于第一个想法来说可以吗？
我有一个轻微的理解问题 - 不可能通过增加 n 来增加我的灵敏度，这是正确的吗？所以不可能得到某些目标灵敏度的公式，对吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/636046/simplified-sample-size-calculation-for-binary-classifier</guid>
      <pubDate>Wed, 03 Jan 2024 10:13:52 GMT</pubDate>
    </item>
    <item>
      <title>因子载荷是回归系数还是二元相关性？</title>
      <link>https://stats.stackexchange.com/questions/636045/are-factor-loadings-regression-coefficients-or-bivariate-correlations</link>
      <description><![CDATA[探索性因子分析中的因子载荷是双变量相关性还是标准化回归系数？这两种解释都可以在文献中找到。但是，非偏化二元相关性与多元回归中的标准化回归系数不同。从我的角度来看，因子载荷是双变量相关性而不是回归系数更有意义，因为在因子载荷中，多重共线性引起的协方差分量不应该被部分去除。如果我想象有两个几乎完全相关的自变量，并且每个自变量只有一个小的纯随机误差，与因子不相关，那么因子载荷应该非常大，但标准化回归系数将接近于零。这是正确的，还是我的想法有误？]]></description>
      <guid>https://stats.stackexchange.com/questions/636045/are-factor-loadings-regression-coefficients-or-bivariate-correlations</guid>
      <pubDate>Wed, 03 Jan 2024 10:05:32 GMT</pubDate>
    </item>
    </channel>
</rss>