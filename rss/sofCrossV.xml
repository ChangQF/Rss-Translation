<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 22 Jul 2024 03:18:20 GMT</lastBuildDate>
    <item>
      <title>分类规则</title>
      <link>https://stats.stackexchange.com/questions/651501/classification-rule</link>
      <description><![CDATA[在分类中，MAP（最大后验概率）规则、最小误分类规则和贝叶斯决策规则之间有什么区别吗？据我所知，这三个规则似乎都是根据最大后验概率对新实例进行分类。那么它们可以互换吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651501/classification-rule</guid>
      <pubDate>Mon, 22 Jul 2024 02:33:12 GMT</pubDate>
    </item>
    <item>
      <title>梯度提升会单调地减少误差吗？</title>
      <link>https://stats.stackexchange.com/questions/651500/will-gradient-boosting-monotonically-decrease-error</link>
      <description><![CDATA[我仍在努力理解梯度提升回归，特别是 xgboost，并且试图理解是否保证每个步骤在后续迭代中产生较小的残差。如果我们保证单调地减少损失函数，那么是在每个样本级别（即样本 i 的伪残差保证在每次迭代后对所有 i 都减少）还是所有 i 的平方误差之和保证减少？
我的想法是，由于损失函数是所有平方误差之和，我们正在将其最小化，但不能保证每个样本残差在每次迭代中都会下降。我试图想出一种情况，您可以添加一棵新树，它实际上会增加误差之和（例如，如果您的回归树非常差）。我不知道是否存在新树对伪残差的预测非常差以至于实际上会增加误差的情况。]]></description>
      <guid>https://stats.stackexchange.com/questions/651500/will-gradient-boosting-monotonically-decrease-error</guid>
      <pubDate>Mon, 22 Jul 2024 02:22:52 GMT</pubDate>
    </item>
    <item>
      <title>关联后要采取的数据分析步骤</title>
      <link>https://stats.stackexchange.com/questions/651498/data-analysis-steps-to-take-after-correlation</link>
      <description><![CDATA[我的假设是，经济不平等与犯罪率呈显著正相关。为了验证这一点，我拥有县级各种犯罪类型的犯罪率和各种收入等级的人口百分比。我的数据集是 1,441 个县、每个县的犯罪和收入等级数据、各种收入比率（最高等级与最低等级、前 2 个等级与后 2 个等级等）以及每个县的基尼指数。我有 2018-2022 年的数据。
我用两种方法测试了我的假设。
首先，我使用 Pearson 的乘积矩、Kendall 的 Tau 和 Spearman 的 Rho 测试了基尼指数与各种犯罪类型率之间的相关性。鉴于犯罪率不呈正态分布，并且我的 n 很大，Spearman 的 Rho 是最合适的。我使用其他两个进行稳健性检验。结果证明存在非常弱的正相关关系。 Pearson 的结果表明，各种犯罪类型的相关性为 .10 &lt; r &lt; .27 (p &lt; .001)，而 Kendall 和 Spearman 的结果表明，r 和 p &gt; .10 均较低。
其次，我使用 Spearman 的 Rho 检验了各种收入阶层的百分比和收入比率与各种犯罪类型的比率之间的相关性。这些比率没有提供明确的见解 - 它们的 r 几乎总是小于 .20。然而，特定犯罪类型的比率似乎与经济不平等有某种关联。
例如，在我所有五年的数据中，最低收入阶层的人口百分比与入室盗窃/破门行窃率之间的相关性约为。 r = .32，犯罪率与最高收入阶层人口百分比的相关性约为 r = -.15。一般来说，犯罪率与中等收入阶层百分比之间的相关性接近于零（几乎所有的 p &lt; .001）。这表明，随着各县贫困或富裕家庭的集中度增加（取决于犯罪情况），某些类型的犯罪率将趋于上升或下降。这支持了我的假设，即收入不平等与至少某些犯罪率呈显着正相关。
我的问题是：我的下一步统计分析是什么？回归分析、方差分析、更多的稳健性检验？报告我的发现的最佳实践？任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/651498/data-analysis-steps-to-take-after-correlation</guid>
      <pubDate>Mon, 22 Jul 2024 00:08:55 GMT</pubDate>
    </item>
    <item>
      <title>skicit learn 的时间序列交叉验证和 Prophet 的交叉验证</title>
      <link>https://stats.stackexchange.com/questions/651497/time-series-cross-validation-by-skicit-learn-and-cross-validation-by-prophet</link>
      <description><![CDATA[我对 skicit learn 的时间序列交叉验证和 Prophet 的交叉验证感到困惑。所以我试图将 lstm 算法与 prophet 进行比较，方法 LSTM 使用的分割数据是时间序列交叉验证，而 Prophet 交叉验证则使用分割数据。这是同一件事吗？如果不同，交叉验证的哪些参数是按顺序排列的？我应该调整哪些参数以匹配我在 LSTM 中实现的 n_splits =5？]]></description>
      <guid>https://stats.stackexchange.com/questions/651497/time-series-cross-validation-by-skicit-learn-and-cross-validation-by-prophet</guid>
      <pubDate>Sun, 21 Jul 2024 23:54:52 GMT</pubDate>
    </item>
    <item>
      <title>随机变量满足边界点概率界限的条件</title>
      <link>https://stats.stackexchange.com/questions/651495/conditions-for-a-random-variable-to-satisfy-a-probability-bound-on-boundary-poin</link>
      <description><![CDATA[令 $X$ 为 $\mathcal{X}\subset\mathbb{R}^{d}$ 上支持的随机变量，令 $\mathcal{X}$ 为紧凑型。考虑 $ f $ 为 $ X $ 的概率密度。
我的问题是： $ X $ 必须满足哪些条件才能确保
$$
\lim_{n\rightarrow\infty}n\mathbb{P}(X \in B_{h}(x))=\infty \tag{1}
$$
其中 $ x $ 属于 $\mathcal{X}$ 的边界，并且 $ h $ 的形式为 $ h=\left(\frac{\log(n)}{n}\right)^{1/(d+4)} $?
我所说的条件是指统计和概率中经常遇到的条件，例如尾部或矩的条件，以及统计环境中常见的条件。
在一维情况下，我已经验证了几个概率密度（例如某些 Beta 分布）的条件 (1)，并发现条件 (1) 得到满足。我相信在一维情况下，条件 (1) 通常会得到满足，不满足条件的分布将非常罕见。]]></description>
      <guid>https://stats.stackexchange.com/questions/651495/conditions-for-a-random-variable-to-satisfy-a-probability-bound-on-boundary-poin</guid>
      <pubDate>Sun, 21 Jul 2024 22:37:25 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 copula 方法进行预测？</title>
      <link>https://stats.stackexchange.com/questions/651493/how-to-predict-using-a-copula-approach</link>
      <description><![CDATA[我有一个包含连续变量和离散变量的数据集，目标变量是 0-1，我想知道如何使用 copula 回归预测目标变量。
我正在使用 python 来做这件事，但我真的不明白如何使用不同的函数，也不知道哪个包更好用。
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/651493/how-to-predict-using-a-copula-approach</guid>
      <pubDate>Sun, 21 Jul 2024 21:21:47 GMT</pubDate>
    </item>
    <item>
      <title>预言的假设检验</title>
      <link>https://stats.stackexchange.com/questions/651492/hypothesis-testing-of-a-prophecy</link>
      <description><![CDATA[一个高度具体和不可能的预言是否足以让人相信它不是偶然的？还是需要很多预言才能确定这一点？
我明白我们无法（可能）知道所有可能的不同概率描述的全部人口和分布，但让我们假设我们主观地评估预言足够精确和不可能，可以通过我们选择的显着性水平，是否有可能排除预言偶然成功的假设？
此外，您将如何测试预言以确信它不是偶然的？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651492/hypothesis-testing-of-a-prophecy</guid>
      <pubDate>Sun, 21 Jul 2024 20:40:38 GMT</pubDate>
    </item>
    <item>
      <title>使用多重比较校正和复合 DV</title>
      <link>https://stats.stackexchange.com/questions/651491/use-of-multiple-comparison-correction-and-composite-dv</link>
      <description><![CDATA[我正在研究单个 X 对复合 DV Y 的影响。我还想研究 X 对 Y 的 36 个子成分的影响。因此，我必须运行 37 个多元回归模型，特别是具有稳健聚类 SE 和年份 FE 的池化 OLS。X 是时不变的，所以我不能包括国家 FE。
我明白我应该校正多重比较，我打算使用 BH 校正。我的问题是，我是否应该调整所有模型，包括复合 Y 是 DV 的主模型？要清楚，这是一个条件过程：只有当 X 在主模型中显著时，才会针对子成分进行测试。
我很困惑，因为我确实调整了主模型的 p 值，但校正后主模型中的 X 并不显著。然而，X 对很多子成分来说都是显著的。我知道在看到不利结果时质疑模型是不科学的，但如果 X 在主模型中的初始显著影响可归因于噪音，我很难解释结果。
总而言之，我有两个问题：

如果我有一个条件过程，只有当 X 在主模型中具有显著影响时才会运行更多模型，是否需要调整主模型的 p 值以进行多重比较？如果我有一个条件过程，测试是否仍被视为同时进行的？
如果需要调整，我该如何解决由于初始效果显著而需要调整的悖论，但初始效果在调整后变得不显著，因此无需进一步测试并因此进行调整？

任何建议都值得赞赏。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651491/use-of-multiple-comparison-correction-and-composite-dv</guid>
      <pubDate>Sun, 21 Jul 2024 20:05:43 GMT</pubDate>
    </item>
    <item>
      <title>是否可以对正则化器进行逆向工程，以对相关的非正则化回归问题的解决方案进行精确的修改？</title>
      <link>https://stats.stackexchange.com/questions/651488/can-a-regularizer-be-reverse-engineered-to-induce-precise-modifications-to-the-a</link>
      <description><![CDATA[以下是回归问题中正则化的图片...

蓝线表示未正则化或正则化程度较低，绿线表示正则化程度较高。此类问题通常写为$\min_w\ (\frac{\sum_{i = 1}^n l(h_w(x_i),\ y_i)}{n} + \lambda r(w))$，其中$\lambda$设置得越大，解越接近直线、水平线。
这个描述听起来很像$1$维热方程的动态行为。正如此处所示，受偏微分方程$T_t = \alpha T_{xx}$控制，用任意高波动率初始化的棒的温度分布会随着时间的推移平滑为一条水平直线。
虽然我期望与热方程相关的某些东西能够控制正则化，但当我真正研究正则化时，我并没有发现任何联系。有没有办法有意构建一个正则化器，其常数$\alpha$等于热方程中的热扩散率常数，使得对于每个固定的$\alpha$值，增加正则化器上的$\lambda$会修改非正则化的损失函数解，其修改方式与在$1$维热方程中增加$t$（初始温度分布等于非正则化的损失函数解）（“热方程正则化器”）相同？]]></description>
      <guid>https://stats.stackexchange.com/questions/651488/can-a-regularizer-be-reverse-engineered-to-induce-precise-modifications-to-the-a</guid>
      <pubDate>Sun, 21 Jul 2024 18:46:43 GMT</pubDate>
    </item>
    <item>
      <title>统计独立测试/测量的综合可靠性</title>
      <link>https://stats.stackexchange.com/questions/651462/combined-reliability-for-statistically-independent-tests-measurements</link>
      <description><![CDATA[我对维基百科文章“一致性”中的这句话感到困惑：
“从统计学上讲，如果三个不同的测试在给出阳性结果时，每个测试的可靠性为 90%，则所有三个测试的阳性结果的可靠性为 99.9%；五个这样的测试的可靠性为 99.999%，依此类推。这要求测试在统计上是独立的，类似于测量方法中对独立性的要求。”

这些可靠性百分比是如何计算的？例如，如果 4 个独立测试的可靠性不同，比如 77%、88%、90% 和 93%，那么它们的组合可靠性是多少？

这种现象的统计术语是什么？


谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651462/combined-reliability-for-statistically-independent-tests-measurements</guid>
      <pubDate>Sat, 20 Jul 2024 23:04:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 LOOCV 中的正则化减少小型数据集的方差</title>
      <link>https://stats.stackexchange.com/questions/651449/reducing-variance-with-regularization-in-loocv-for-small-datasets</link>
      <description><![CDATA[我有一个小数据集，我正在考虑使用留一交叉验证 (LOOCV) 来评估我的模型。我理解，交叉验证通常是一种评估模型在未见数据上的表现的方法。
但是，我担心偏差-方差权衡。具体来说，使用 LOOCV 时，存在偏差低但方差高的风险。为了缓解这种情况，我正在考虑使用正则化模型（L1、L2 或 Elastic Net）来引入一些偏差并减少方差（在使用 loocv 时同时……）。
您能否提供任何实施此方法的提示或最佳实践？任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/651449/reducing-variance-with-regularization-in-loocv-for-small-datasets</guid>
      <pubDate>Sat, 20 Jul 2024 10:57:12 GMT</pubDate>
    </item>
    <item>
      <title>平均值的假设检验 - z 检验和 t 检验统计量的分布推导[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651439/hypothesis-tests-for-averages-derivation-of-distribution-of-z-test-and-t-test</link>
      <description><![CDATA[在测试平均值时，z 检验和 t 检验都具有相同形式的检验统计量 $T$:
$$T = \frac{\bar{X} - \mu_0}{\text{se}(\bar{X})}$$
在前者中，已知的总体标准偏差 $\sigma$ 用作分母，而在后者中，标准误差 $S = \hat{\sigma}/\sqrt{n}$ 与 $\hat{\sigma} = \sqrt{\frac{1}{n-1}\sum_{i\leq 一起使用N}(x-\bar{x})^2}$。z 检验统计量的分布为：$T_z \sim \Phi(0, 1)$，t 检验统计量的分布为：$T_t \sim t_{n-1}$
有没有推导为什么除以标准误差会产生 t 分布，而除以标准差会产生正态分布？
编辑：对于 z 检验：意味着将 $\sigma/\sqrt{n}$ 写为 z 检验的分母，而不仅仅是 $\sigma$ 作为分母]]></description>
      <guid>https://stats.stackexchange.com/questions/651439/hypothesis-tests-for-averages-derivation-of-distribution-of-z-test-and-t-test</guid>
      <pubDate>Sat, 20 Jul 2024 06:08:32 GMT</pubDate>
    </item>
    <item>
      <title>如何计算所需样本量以实现所需的假阴性率</title>
      <link>https://stats.stackexchange.com/questions/651434/how-to-calculate-required-sample-size-for-desired-false-negative-rate</link>
      <description><![CDATA[我正在尝试设计一个进行二元分类的系统。假阴性的成本很高，所以我想确保我已经进行了足够彻底的测试，以尽量减少这种可能性。我希望系统的假阴性率小于 1%，确定性为 95%。如果我预计真阳性率很小（大约 2%），我应该如何计算达到这一置信度所需的人口规模？ 单侧检验程序是此处适用的正确方程吗？
$$
N \geq \left ( \frac{z_{1-\alpha} \sqrt{p_0(1-p_0)} + z_{1-\beta} \sqrt{p_1(1-p_1)}}{p_1-p_0} \right ) ^2
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/651434/how-to-calculate-required-sample-size-for-desired-false-negative-rate</guid>
      <pubDate>Sat, 20 Jul 2024 01:48:58 GMT</pubDate>
    </item>
    <item>
      <title>模型具有更高的（且更接近 1）$\beta$，但 $R^2$ 和相关性相似</title>
      <link>https://stats.stackexchange.com/questions/651423/model-has-higher-and-closer-to-1-beta-but-similar-r2-and-correlation</link>
      <description><![CDATA[我有一个模型，它产生预测$\hat{y_1}$，后来我又想出了一个新模型，它产生预测$\hat{y_2}$。我有基本事实$y$。 这些模型不是基于回归的，但它们是线性的，我想在回归指标中对它们进行评估。
如果我运行$y \sim \beta_1 \hat{y_1}$、$y \sim \beta_2 \hat{y_2}$，我会看到$\beta_2 \sim 1$和$\beta_1 \sim 0.8$。我认为这意味着我的模型 2 “缩放得更好”。
但如果我直接计算 $R2(y, \hat{y_1}) = 1- \frac{\sum (y_t - \hat{y_1}_t )^2 }{\sum y_t^2}$ 和 $R2(y, \hat{y_2}) = 1- \frac{\sum (y_t - \hat{y_2}_t )^2 }{\sum y_t^2}$（因为我不会尝试重新运行回归 $y \sim \beta_1 \hat{y_1}$ 并得到回归 R2。我只是直接计算 $R2(y, \hat{y_1}) = 1- \frac{\sum (y_t - \hat{y_1}_t )^2 }{\sum y_t^2}$)。我发现它们大致相等。
当我计算 $y$ 和 $\hat{y_1}$ 之间的相关性以及 $y$ 和 $\hat{y_2}$ 之间的相关性时，我发现它们也几乎相等。请注意，这里的相关性可能不是 R2 的平方根，因为我的模型不是基于回归的。
它告诉了我关于预测的什么？我觉得有点惊讶。我认为“更好的规模”预测因子应该出现在回归指标的某个地方吗？为什么“更好的尺度”回归没有给我更好的 R2？]]></description>
      <guid>https://stats.stackexchange.com/questions/651423/model-has-higher-and-closer-to-1-beta-but-similar-r2-and-correlation</guid>
      <pubDate>Fri, 19 Jul 2024 19:10:07 GMT</pubDate>
    </item>
    <item>
      <title>分位数函数容易求解但 CDF 难以求解的分布示例</title>
      <link>https://stats.stackexchange.com/questions/651421/examples-of-distributions-with-easily-solvable-quantile-functions-but-hard-to-so</link>
      <description><![CDATA[我对概率分布的例子很感兴趣，其中分位数函数 $F^{-1}(p)$ 以闭式存在或易于计算，但累积分布函数 (CDF) $F(x)$ 不以闭式存在。特别是分位数函数易于求解但 CDF 难以求解或无法求解的例子，尤其是当分布用于实际应用时。任何例子都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/651421/examples-of-distributions-with-easily-solvable-quantile-functions-but-hard-to-so</guid>
      <pubDate>Fri, 19 Jul 2024 18:14:59 GMT</pubDate>
    </item>
    </channel>
</rss>