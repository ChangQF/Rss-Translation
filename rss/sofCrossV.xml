<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 10 Jan 2025 03:23:59 GMT</lastBuildDate>
    <item>
      <title>使用哪种规范化</title>
      <link>https://stats.stackexchange.com/questions/659807/what-kind-of-normalization-is-used</link>
      <description><![CDATA[yelp_features_1

0 1 2 3 4 ... 27 28 29 30 31
0 8 2.0000 1 0 0 ... 1.4545 1.7439 1.9363 0.000 142.0909
1 9 0.0000 0 0 0 ... 1.4545 1.7439 1.9363 0.000 142.0909
2 2 2.0000 1 0 0 ... 1.4545 1.7439 1.9363 0.000 142.0909
3 6 2.0000 1 0 0 ... 1.4545 1.7439 1.9363   0.000 142.0909
4 3 0.0000 0 0 0 ... 1.4545 1.7439 1.9363 0.000 142.0909
   .. ... .. .. .. .. ... ... ... ... ... ...
45949 3 0.3333 1 0 0 ... 0.7437 0.3631 1.8376 1.6182 170.4366
45950 1 0.6667 0 0 1 ... 0.7437 0.3631 1.8376 1.6182 170.4366
45951 3 1.0000 1 0 0 ... 0.8488 1.0167 1.7599 2.4910 133.1060
45952 2 2.0000 0 0 0 ... 0.8488 1.0167 1.7599 2.4910 133.1060
45953 1 1.0000 1 0 1 ... 0.8488 1.0167 1.7599 2.4910 133.1060

yelp_feature_2
-----------------
0 1 2 3 4 ... 27 28 29 30 31
0 0.0224 0.0705 0.4287 1.0000 1.0000 ... 0.0100 0.0149 0.5920 0.1393 0.4975
1 0.0249 1.0000 1.0000 1.0000 1.0000 ... 0.0100 0.0149 0.5920 0.1393 0.4975
2 0.0062 0.0705 0.4287 1.0000 1.0000 ... 0.0100 0.0149 0.5920 0.1393 0.4975
3 0.0174 0.0705 0.4287 1.0000 1.0000 ... 0.0100 0.0149 0.5920 0.1393 0.4975
4 0.0091 1.0000 1.0000 1.0000 1.0000 ... 0.0100 0.0149 0.5920 0.1393 0.4975
     ……………………………………
45949 0.0091 0.6951 0.4287 1.0000 1.0000 ... 0.4577 0.2687 0.3682 0.3035 0.8458
45950 0.0032 0.5739 1.0000 1.0000 0.0228 ... 0.6020 0.4030 0.4826 0.8010 0.1642
45951 0.0091 0.3500 0.4287 1.0000 1.0000 ... 0.6020 0.4030 0.4826 0.8010 0.1642
45952 0.0062 0.0705 1.0000 1.0000 1.0000 ... 0.7811 0.8557 0.4428 0.4478 0.5871
45953 0.0032 0.3500 0.4287 1.0000 0.0228 ... 0.7811 0.8557 0.4428 0.4478 0.5871

yelp_features_1 被标准化为yelp_feature_2。无法弄清楚使用了什么规范化。看起来像是对数。]]></description>
      <guid>https://stats.stackexchange.com/questions/659807/what-kind-of-normalization-is-used</guid>
      <pubDate>Fri, 10 Jan 2025 03:12:12 GMT</pubDate>
    </item>
    <item>
      <title>分析一个条件涉及内生分配而另一个条件涉及外生分配的设计是否有效？</title>
      <link>https://stats.stackexchange.com/questions/659803/is-it-valid-to-analyze-a-design-where-one-condition-involves-endogenous-and-anot</link>
      <description><![CDATA[我正在使用彩票设置进行一项实验，其中向参与者提供有关风险和奖励的信息。
设计包括两个因素：

条件：在一种条件下（自由序列），参与者可以选择信息的顺序（先有风险还是先有奖励）。在另一个（固定序列）中，它们被分配顺序（先有风险还是先有回报）。

序列顺序：人们首先看到的是风险还是回报。


这导致了 2（固定序列 vs. 自由序列）x 2（先有风险 vs. 先有回报）的设计。
因变量 (DV)：参与者对后续结果的兴趣（二进制：0/1）。
分析计划：
我们计划使用逻辑回归来预测 DV，预测因子如下：

条件（固定序列 vs. 自由序列）
序列顺序（先有风险 vs. 先有回报）
交互项（条件 × 序列顺序）

关键问题：
在“自由序列”条件下，参与者选择先查看风险还是先查看回报，从而使序列顺序具有内生性。在“固定序列”条件下，序列顺序是外生的（随机分配）。序列顺序的这种性质差异（内生与外生）是否会导致分析无效？如果是，我在测试假设时如何解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659803/is-it-valid-to-analyze-a-design-where-one-condition-involves-endogenous-and-anot</guid>
      <pubDate>Fri, 10 Jan 2025 01:35:56 GMT</pubDate>
    </item>
    <item>
      <title>帮助决定哪种测试适合确定两个样本之间是否存在统计上的显着差异</title>
      <link>https://stats.stackexchange.com/questions/659799/help-deciding-which-test-is-appropriate-for-determing-if-there-is-a-statisticall</link>
      <description><![CDATA[我是一名学生，所以我希望我可以在这里发帖/希望这是合适的，因为我不知道还能问谁，而且我不太信任 ChatGPT。
基本上，我有一个（人工）数据集，其中包含约 70% 的相同重复数据，我决定删除这些数据。
我想知道是否有办法证明删除它们不会显著影响未来的分析和数据建模，方法是将旧数据中的变量的均值和分布与重复数据和新清理的数据进行比较。我正在建立一个模型来预测 CKD 的存在。
最初，ChatGPT 和 Google 在秩和检验中表示未配对 Wilcox - 我认为这是有道理的，因为我的样本不是正态分布的并且不匹配 - 行数不同。
进一步阅读后发现，此测试仅适用于独立样本。我的样本在技术上是独立的，还是它们？
我甚至需要证明我的情况吗？我可以说我删除了重复项并就此打住吗？
Kolmogorov-Smirnov 检验是否更合适？
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659799/help-deciding-which-test-is-appropriate-for-determing-if-there-is-a-statisticall</guid>
      <pubDate>Thu, 09 Jan 2025 21:10:13 GMT</pubDate>
    </item>
    <item>
      <title>相关性/巧合性测量中的统计</title>
      <link>https://stats.stackexchange.com/questions/659798/statistics-in-correlation-coincidence-measurement</link>
      <description><![CDATA[我从事实验物理工作，对所谓的“巧合”测量中使用的某些统计模型感到困惑。
为了说明背景，我们有可以检测单个粒子（在我的情况下是光子）存在的探测器。您可以想象一束连续的光子撞击探测器。总检测周期被分成非常小的时间段，当它检测到光子撞击传感器时，它会在任何给定的时间段输出 1，如果没有，则输出 0。在某些光源（例如激光器）中，数字统计遵循泊松分布 - 在任何时间段检测到光子的概率与所有其他时间段的概率无关。对于一个探测器，这是一个“单个”测量。当我们有两个探测器和两个光源时，“巧合”事件是每个探测器在同一时间箱中输出 1，即它们同时在各自的路径中检测到一个光子（以时间箱的分辨率为准）。
以下是问题的概述：
假设我们有两个探测器 $1$ 和 $2$。每个探测器都有一个光源输出一束光子。每个光源和每个探测器彼此独立。将每个探测器上的时间段称为$t_1,\ldots,t_N$（所有时间段的持续时间相同，即$t_1=t_2=\cdots=t_n=\Delta t$），总实验时间窗口称为$T=\sum^{N}_{i=1}t_i$。假设每个光源都遵循泊松统计，并且每个探测器实验窗口中的总计数平均值为 $R_1T$ 和 $R_2T$（$R_1$ 和 $R_2$ 是光源已知的固定发射率）。此外，假设 $R_1\Delta t\ll1$ 和 $R_2\Delta t\ll1$，因此我们几乎总是在任何时间段内得到 $0$ 或 $1$。我将在每个探测器上随机获得 $1$ 和 $0$ 的组合，如果我多次重复实验，每个探测器上的总计数将有一个大致等于平均值​​平方根的标准差。
我的问题是，巧合计数（当两个探测器在同一时间段上注册 $1$ 时为 $1$，否则为 $0$）是否也遵循泊松分布？我认为我知道如何找到实验的平均巧合计数，它应该是 $R_cT=T\Delta tR_1R_2$（$R_c$ 是巧合中的固定计数率）。在许多论文中，巧合计数被假定具有泊松统计量，这是有道理的，因为获得巧合计数的概率在不同时间应该彼此独立。但是，我也可以将巧合计数的数量表示为每个探测器上的单数计数的乘积，其中单数计数本身是泊松的 - 但两个泊松的乘积不是泊松的。如果它是泊松的，有没有严格的方法来证明它？]]></description>
      <guid>https://stats.stackexchange.com/questions/659798/statistics-in-correlation-coincidence-measurement</guid>
      <pubDate>Thu, 09 Jan 2025 21:09:36 GMT</pubDate>
    </item>
    <item>
      <title>非线性方程的曲线拟合</title>
      <link>https://stats.stackexchange.com/questions/659797/curve-fitting-of-non-linear-equation</link>
      <description><![CDATA[
我有 I-V 的实验数据，方程 (7) 代表我的假设模型。我想提取拟合参数，我应该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/659797/curve-fitting-of-non-linear-equation</guid>
      <pubDate>Thu, 09 Jan 2025 21:04:49 GMT</pubDate>
    </item>
    <item>
      <title>控制变量中缺失的值</title>
      <link>https://stats.stackexchange.com/questions/659796/missing-values-in-control-variables</link>
      <description><![CDATA[我目前正在运行几个回归分析。数据集大小为 1067。添加控制变量时，对于一个控制变量，缺少一个值（因此它为 1066）。
最好的做法是什么？我可以排除它。但是，考虑到相对大小（1/1067），我倾向于保留它。特别是因为一个缺失值在这种情况下可能不会产生影响。
到目前为止，我已经看到：

列表删除（不倾向于这样做）；
成对删除（考虑到我正在使用控制变量，这是否会删除所有分析的案例？）；
通过 SPSS 运行 MI（倾向于这样做，并在我的研究中披露）。

您有什么建议？提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659796/missing-values-in-control-variables</guid>
      <pubDate>Thu, 09 Jan 2025 20:52:28 GMT</pubDate>
    </item>
    <item>
      <title>合并方差 VS BLUE 估计量</title>
      <link>https://stats.stackexchange.com/questions/659795/pooled-variance-vs-blue-estimator</link>
      <description><![CDATA[我想知道，假设我收到一份结果列表（例如，两个独立变量 A 和 B 估计相同的值），我可以执行假设检验来检查两个方差是否相等，然后计算合并方差。但是，我也可以使用 BLUE 估计量来计算该方差。假设我在考试中有选择，我应该选择哪种方法？
任何见解或建议都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/659795/pooled-variance-vs-blue-estimator</guid>
      <pubDate>Thu, 09 Jan 2025 20:16:02 GMT</pubDate>
    </item>
    <item>
      <title>重复测量多元线性回归</title>
      <link>https://stats.stackexchange.com/questions/659793/repeated-measures-multiple-linear-regression</link>
      <description><![CDATA[我想回答一个问题：哪些独立变量（年降水量、基岩深度、坡度、基部面积和三个深度的平均土壤湿度）会影响平均季节性地下水位。测量是在四个相邻的子流域进行的。水井位于 200-250 米横断面上的五个山坡位置。这些水井很浅。我们研究的是浅层地下水，而不是区域含水层。子流域的大小大致相同。
我使用从 2016 年到 2022 年每 30 分钟在同一 20 个地点进行的地下水测量来计算每年的平均季节性地下水位。年降水量是当年的降水量，基岩和坡度的深度在所有年份中保持不变，基部面积每年都会发生变化，每个深度的平均季节性土壤湿度是使用每日土壤湿度测量计算得出的。
我的一些独立变量也存在多重共线性（例如，我使用了 3 个不同深度的土壤湿度数据，它们都彼此相关并且与降水量相关）。我可以使用哪些其他类型的统计测试来确定是否/哪些独立变量可能会影响平均季节性地下水位？]]></description>
      <guid>https://stats.stackexchange.com/questions/659793/repeated-measures-multiple-linear-regression</guid>
      <pubDate>Thu, 09 Jan 2025 18:31:47 GMT</pubDate>
    </item>
    <item>
      <title>嵌入可以在上下文赌博机中使用吗？</title>
      <link>https://stats.stackexchange.com/questions/659792/can-embeddings-be-used-in-contextual-bandits</link>
      <description><![CDATA[我有一个现实问题，即应该为特定客户提供特定产品的折扣/促销，其相互竞争的目标是 1/ 最大化收入和 2/ 最小化模型估计中的方差。
相关文献

在大型电子商务公司中，推荐和个性化团队长期以来一直使用嵌入技术（例如双塔模型）将产品和项目嵌入到同一个潜在空间中。

合成控制允许科学家利用观察数据来构建反事实，其中一些个体收到了需要综合考虑接受治疗的个体在没有治疗的情况下会如何表现（反事实）。

最后，contextual bandits 将动作映射到奖励，平衡探索与利用。


我正在考虑的一般前提是将这些想法结合起来。仅考虑前两个，即嵌入和合成控制，可以将治疗随机应用于用户-产品对，例如促销；其次，对于任何给定的用户-产品对，可以从几个其他用户-产品对中合成一个反事实（嵌入在聚合时会映射到潜在空间中非常相似的位置）。仅凭这些步骤，就可以有效地估计治疗对配对的因果影响。由于嵌入是潜在的，我们不能声称“[有形协变量] 引起了用户响应”；我们的结论仅限于治疗。
现在，包括上下文强盗元素，我们应该能够包括开发（以前只涉及探索）。强盗可能会根据与处理过的配对及其响应的距离提出新的用户-项目对；换句话说，提出远离无效观察的配对（例如：口香糖降价 1%），同时提出更接近有效观察的配对。
我很好奇，这样的设计以前实现过吗？如果是，那么从中吸取了什么教训？]]></description>
      <guid>https://stats.stackexchange.com/questions/659792/can-embeddings-be-used-in-contextual-bandits</guid>
      <pubDate>Thu, 09 Jan 2025 18:04:58 GMT</pubDate>
    </item>
    <item>
      <title>（Fisher z）相关性的平均值与平均值的相关性</title>
      <link>https://stats.stackexchange.com/questions/659787/mean-of-fisher-z-correlations-vs-correlation-of-means</link>
      <description><![CDATA[这可能是一个基本问题，但我花了很长时间试图找到答案，但通常都失败了。
我进行了一项实验，尝试使用新方法多次复制固定变量 X0=[1,2,3,4,5,6,7,8,9,10]，这会产生新变量 X1、X2、...Xi。
评估复制率的一种方法是计算 X0 与 X1...Xi 的分段平均值之间的相关性，从而得到十个均值。我们称之为 r_means。
另一种方法是首先计算 X0 与每个复制 X1...Xi 之间的相关性，然后对这些相关性求平均值（使用或不使用 Fisher z 变换并返回）。那将是 Mean_r
我不断得到非常不同的值 r_means 和 Mean_r，但我无法弄清楚是什么导致了这些差异。我意识到 X1、...Xi 的方差以某种方式参与其中，但无法找到具体原因。
有人能提示一下 r_means 和 Mean_r 之间（潜在）差异所涉及的因素吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659787/mean-of-fisher-z-correlations-vs-correlation-of-means</guid>
      <pubDate>Thu, 09 Jan 2025 17:00:20 GMT</pubDate>
    </item>
    <item>
      <title>如何解释对数-对数回归中 x 百分比增幅大于 1% 的系数 [重复]</title>
      <link>https://stats.stackexchange.com/questions/659780/how-to-interpret-coefficient-in-log-log-regression-for-percentage-increase-in-x</link>
      <description><![CDATA[在对数对数回归中，$\beta$ 给出弹性。因此，$b$ 大约等于 $x$ 增加 1% 时 $y$ 的百分比增加。我的问题是：如何计算 $b$ 增加 100% 时 y 的百分比增加（我需要这个来举一个具体的例子）？它只是 $100\times b$ 吗？我在查找时找到了不同的答案。一是确切的公式为：$(\exp(b\times \log(2))-1)\times100$，其中 $\log(2)$ 表示增加 100%，$\log(1.10)$ 表示增加 10%，以此类推。不过我真的不确定这是否正确。任何帮助我都会很感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/659780/how-to-interpret-coefficient-in-log-log-regression-for-percentage-increase-in-x</guid>
      <pubDate>Thu, 09 Jan 2025 15:29:43 GMT</pubDate>
    </item>
    <item>
      <title>进行 A/B 测试后评估对人群的总体影响</title>
      <link>https://stats.stackexchange.com/questions/659770/evaluating-total-effect-on-population-after-conducting-a-b-test</link>
      <description><![CDATA[我进行了一项 A/B 测试，其中的处理包括向客户提供折扣。然而，测试结束后，我发现测试组中的客户并不总是能看到折扣，因为有一个额外的逻辑层决定了折扣是否足够大到可以显示。
为了解决这个问题，我缩小了分析范围，只包括那些折扣足够大到可以显示的客户（对照组和测试组）。当我测试这些组之间的统计显著性时，我发现差异很大。
为了估计对整个人群的总体影响，我假设对于没有获得明显折扣的客户子集，对照组和测试组之间的转化率没有差异（因为他们实际上没有受到任何处理）。然后，我将这个假设与获得明显折扣的组的实际观察结果相结合，计算出总体影响。
从统计角度来看，这种方法站得住脚吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659770/evaluating-total-effect-on-population-after-conducting-a-b-test</guid>
      <pubDate>Thu, 09 Jan 2025 14:24:42 GMT</pubDate>
    </item>
    <item>
      <title>缩小的整数格点是否可以作为概率单纯形中的无偏样本点？</title>
      <link>https://stats.stackexchange.com/questions/659737/do-scaled-down-integer-lattice-points-serve-as-unbiased-sample-points-in-the-pro</link>
      <description><![CDATA[我一直在努力证明一个看起来直观明显但实际上并不容易严格建立的陈述。
$(n-1)$维概率单纯形$X$是集合
$$
X=\left\{\mathbf{x}\in[0,1]^n:\sum_{i=1}^nx_i=1\right\}。
$$
设 $Y$ 为单纯形中按比例缩小的整数格点集：
$$
Y=X\cap\frac{\mathbb{Z}^n}s
$$
其中 $s\in\mathbb{Z}^+$。
我的主张是，当 $s\to\infty$ 时，$Y$ 可作为 $X$ 中无偏的样本点集。也就是说，对于 $P\subseteq X$ 和 $U=Y\cap P$，$P$ 的质心（未加权平均值）由以下公式给出
$$
\tag{1}
\bar{\mathbf{p}}=\frac{1}{\int_{P}dV}\int_{P}\mathbf{p}\,dV
$$
其中 $\mathbf{p}\in P$ 和 $dV$ 是 $(n-1)$ 维体积元素，并且 $\bar p$ 渐近等于
$$
\tag{2}
\bar{\mathbf{u}}=\frac1{\#U}\sum_{i=1}^{\#U}\mathbf{u}_i
$$
其中 $\mathbf{u}_i\in U$，因为 $s\to\infty$；即
$$
\tag{3}
\lim_{s\to\infty}\bar{\mathbf{u}}=\bar{\mathbf{p}}。
$$
这里，$(1)$可视为真实均值，$(2)$可视为样本均值，如果集合$U$提供的样本点在极限上无偏，则$(3)$成立。
对于我的具体情况，该语句不必对$X$中的所有子集都成立，而只对这个特定集合成立：
$$
\tag{4}
{P}=\left\{\mathbf{p}\in[0,1]^n: p_1\le p_2\le\cdots\le p_c\ge\cdots\ge p_n\text{ 和} \sum_{i=1}^n p_i=1\right\}\subset X
$$
顺便说一句，它恰好是凸的。
简而言之，我试图证明$(3)$，无论是在一般情况下，还是当$P$给出为$(4)$时。
任何帮助都将不胜感激。指导我任何相关的关键字或书籍也将很棒。]]></description>
      <guid>https://stats.stackexchange.com/questions/659737/do-scaled-down-integer-lattice-points-serve-as-unbiased-sample-points-in-the-pro</guid>
      <pubDate>Wed, 08 Jan 2025 22:56:09 GMT</pubDate>
    </item>
    <item>
      <title>FE 解释中的相互作用项</title>
      <link>https://stats.stackexchange.com/questions/659728/interaction-term-in-fe-interpretation</link>
      <description><![CDATA[我正在估算固定效应回归，如下所示：
$$
\text{unemployment}_{ict} \sim b_1 \text{wage}_{ict} + b_2 \text{heat}_{ict} + b_3 \text{wage}_{ict} \times \text{heat}_{ict} + \text{FEc} + \text{error}_{ict}
$$
其中 $i$ 为个人，$c$ 为国家，$t$ 为时间。
假设您获得以下效果：$b_1=0.7$，$b_2=1.2$, $b_3=-0.4$
现在您想要解释交互效应。一种思考方式是边际效应：
这里您已估计出给定工资和热量的失业预期值
$$
E[y|a,b]=0.7a+1.2b-0.4ab
$$
如果对上述表达式求导，则 a：
$$
\frac{d}{d a} E[y|a,b] =0.7-0.4b
$$
此表达式以 $b$（热量）递减。热量值表示温度，例如，范围从 0-40。然后您可以将 b 设置为“有趣”的值以进行解释。通常，这些有趣的值是 $b$ 中样本的平均值。
我的疑问：
在平均热量值处可视化边际效应是否有意义？
由于 FE 模型控制了国家层面的差异，因此它仅估计了国家内部的变化。使用平均热量值（捕获国家间和国家内部的变化）会扭曲解释吗？
我应该使用替代方法吗？
考虑到模型的面板结构，我正在考虑使用诸如热量增长率或其国家内部标准差之类的指标进行可视化。这些反映了模型实际捕获的国家内部变化。这种方法更合适吗？
如果有人可以对此发表评论，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659728/interaction-term-in-fe-interpretation</guid>
      <pubDate>Wed, 08 Jan 2025 17:35:13 GMT</pubDate>
    </item>
    <item>
      <title>右删失计数数据的等价性检验</title>
      <link>https://stats.stackexchange.com/questions/659725/equivalence-test-for-right-censored-count-data</link>
      <description><![CDATA[如何对右删失计数数据进行等效性检验？感兴趣的结果是某个时间段内的总癫痫发作次数。但是，用于记录癫痫发作次数的设备在 40 次时停止计数。这是一个硬性限制。因此，需要进行审查。审查的是计数，而不是记录时间——为了清楚起见，范围是 0 到 40+。该设备设置为一次记录几天。每日计数不可用。更复杂的是，有一个“故障”，因此总记录时间可能有所不同。对于某些受试者，记录时间为 168 小时。对于其他受试者，记录时间为 175 小时。我会在更普通的建模中使用这些时间作为偏移量。
因此，我有带偏移量的右删失计数数据。我想进行等效性检验。我应该从哪里开始呢？
这不是我的设计，我也没有记录数据或处理设备。]]></description>
      <guid>https://stats.stackexchange.com/questions/659725/equivalence-test-for-right-censored-count-data</guid>
      <pubDate>Wed, 08 Jan 2025 16:42:35 GMT</pubDate>
    </item>
    </channel>
</rss>