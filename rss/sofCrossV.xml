<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 22 Nov 2024 18:24:26 GMT</lastBuildDate>
    <item>
      <title>比较不同季节中不同温度区间内所花的时间</title>
      <link>https://stats.stackexchange.com/questions/657695/compare-time-spent-within-different-temperature-bins-between-seasons</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657695/compare-time-spent-within-different-temperature-bins-between-seasons</guid>
      <pubDate>Fri, 22 Nov 2024 17:57:13 GMT</pubDate>
    </item>
    <item>
      <title>流问题的基本组合/样本</title>
      <link>https://stats.stackexchange.com/questions/657693/basic-combinatoric-sample-of-stream-problem</link>
      <description><![CDATA[我很难理解这个来自斯坦福书的基本组合/采样问题：
假设用户在过去一个月内发出了一次$s$搜索查询，两次$d$搜索查询，并且没有搜索查询超过两次。如果我们有一个 $\frac{1}{10}$ 个查询样本，我们将在样本中看到该用户预期的 $\frac{s}{10}$ 个搜索查询发出一次。
在两次发出的 $d$ 个搜索查询中，只有 $\frac{d}{100}$ 个会在样本中出现两次；该分数是 $d$ 乘以查询两次出现在 $\frac{1}{10}$ 样本中的概率。
在完整流中出现两次的查询中，$\frac{18d}{100}$ 将恰好出现一次。要了解原因，请注意 $\frac{18}{100}$ 是两次出现之一出现在所选流的 $\frac{1}{10}$ 中，而另一次出现在未选择的流的 $\frac{9}{10}$ 中的概率。
关于重复搜索比例的查询的正确答案是 $\frac{d}{s+d}$。但是，我们从样本中获得的答案是 $\frac{d}{10s + 19d}$。要推导出后一个公式，请注意 $\frac{d}{100}$ 出现两次，而 $\frac{s}{10} + \frac{18d}{100}$ 出现一次。因此，样本中出现两次的分数为：
$
\frac{\frac{d}{100}}{\frac{d}{100} + \frac{s}{10} + \frac{18d}{100}}.
$
此比率简化为 $\frac{d}{10s + 19d}$。对于 $s$ 和 $d$ 的非正值，则 $\frac{d}{s + d} = \frac{d}{10s + 19d}$。

我们总共有 $x + 2d$ 个查询。如果我们从查询总量中抽取 $10\%$ 个样本，我们期望样本中有 $0.1 \cdot (x + 2d)$ 个查询。这包括 $x/10$ 个单例和 $2d/10$ 个重复项（即使它们在我们的样本中可能不是重复项）。
现在我不明白的是：我们会有多少个重复项？
为什么是 $\frac{1}{10} \cdot \frac{1}{10} \cdot d = \frac{d}{100}$？我看不出这里有什么直觉。 $\frac{d^2}{100}$ 对我来说更有意义，因为抽样单个样本的概率是 $\frac{x}{10}$，或者 $\frac{2d}{100}$ 对我来说也更有意义，因为一个项目获得样本的概率为 $10$ ，同一个项目被抽样两次是 $\frac{1}{100}$，现在在所有项目中，有 2d 个重复，因此 $\frac{2d}{100}$。]]></description>
      <guid>https://stats.stackexchange.com/questions/657693/basic-combinatoric-sample-of-stream-problem</guid>
      <pubDate>Fri, 22 Nov 2024 17:36:33 GMT</pubDate>
    </item>
    <item>
      <title>探索性因子分析、斜向旋转、方差解释</title>
      <link>https://stats.stackexchange.com/questions/657692/exploratory-factor-analysis-oblique-rotation-variance-explained</link>
      <description><![CDATA[如何计算通过探索性因子分析获得的因子模型解释的方差的问题时常出现。这里有一个包含多种可能性的摘要：在 R 中使用斜旋转进行探索性因子分析后计算因子解释的方差
我使用的是 R，带有 psych 包，如代码片段所示：
library(psych)

fa_results &lt;- fa(df_sq1sq9, nfactors = 5, rotate = &quot;oblimin&quot;)
mean(fa_results$communalities)
print(fa_results)


平均共同体数量：0.7418824
摘要表还报告了 0.74 作为解释的斜交旋转方差：
[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.45 1.50 1.07 1.05 0.60
比例方差 0.27 0.17 0.12 0.12 0.07
累积方差 0.27 0.44 0.56 0.68 0.74
解释比例 0.37 0.22 0.16 0.16 0.09
累积比例 0.37 0.59 0.75 0.91 1.00

因子相关性为 
MR1 MR3 MR5 MR2 MR4
MR1 1.00 0.59 0.64 -0.01 0.30
MR3 0.59 1.00 0.33 0.12 0.21
MR5 0.64 0.33 1.00 0.28 0.11
MR2 -0.01 0.12 0.28 1.00 -0.17
MR4 0.30 0.21 0.11 -0.17 1.00


如果我使用正交旋转（例如方差最大法）进行相同的分析，那么我会得到相同的总方差解释值。据我了解，正交旋转会在因子之间重新分配载荷，但总方差解释对于整个系统保持不变。但是，我不确定斜向旋转，因为因子在它们解释的方差方面重叠。在上面的例子中，一些因子之间存在显著的相关性，但与方差最大法相比，我得到的总方差解释值相同。在这种情况下，总解释方差是否也相同，或者我做错了什么？我需要反馈。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657692/exploratory-factor-analysis-oblique-rotation-variance-explained</guid>
      <pubDate>Fri, 22 Nov 2024 17:10:04 GMT</pubDate>
    </item>
    <item>
      <title>如何将收缩应用于非中心二阶矩估计</title>
      <link>https://stats.stackexchange.com/questions/657690/how-to-apply-shrinkage-to-non-centered-second-moment-estimate</link>
      <description><![CDATA[我有一组 $N$ 个样本 $X_i \in \mathbb{R}^m$，属于随机变量 $X$，其中 $m$ 和 $N$ 具有可比性。我想估计二阶矩矩阵$\mathbb{E}\left[XX^T\right]$。
对于估计均值$\mathbb{E}\left[(X-\mu)(X-\mu)^T\right]$（其中$\mu=\mathbb{E}[X]$）周围协方差的相关问题，当$m$和$N$具有可比性时，通常最好不要直接使用样本协方差，而是在估计中应用收缩，例如Ledoit-Wolf 协方差估计。
我想知道的是，我将如何使用这种收缩方法对非中心二阶矩矩阵进行处理。因为
$$\mathbb{E}\left[XX^T\right] = \mathbb{E}\left[(X-\mu)(X-\mu)^T\right] +\mu\mu^T$$
并表示 $A=\mathbb{E}\left[(X-\mu)(X-\mu)^T\right]$ 和 $B=\mu\mu^T$，我认为一个选项是：

使用收缩获得 $A$
使用样本估计的平均值获得 $B$
将它们加在一起以获得估计$\mathbb{E}\left[XX^T\right]$的收缩。

这听起来像是一种合理的方法吗？还是我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657690/how-to-apply-shrinkage-to-non-centered-second-moment-estimate</guid>
      <pubDate>Fri, 22 Nov 2024 15:57:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么在进行超参数调整和模型选择时使用嵌套验证？</title>
      <link>https://stats.stackexchange.com/questions/657688/why-use-nested-validation-when-doing-both-hyper-parameter-tuning-and-model-selec</link>
      <description><![CDATA[专著交叉验证包含一节有关超参数优化的嵌套交叉验证（第 6 页）。作者引用了这篇论文，解释了为什么最好将 hp-search 与模型选择分离，但我没有找到直观易懂的答案。简而言之，我的问题是：

如果具有不同超参数值的 ML 算法可以看作两种不同的 ML 算法（并且似乎可以使用平面验证方法来选择最佳 ML 算法）？为什么要使用嵌套验证进行 hp-search 和模型选择？

为了使问题精确，下面我将详细描述什么是嵌套验证和平面验证。为简单起见，我将省略交叉部分，并且不将数据分成折叠——问题的核心保持不变，因此我相信原因也应该保持不变。
使用平面验证进行 HP 调整和模型搜索
此过程将数据集分为两部分

best_model_family = none
best_hp = none
best_model = none
best_score = none
对于每个 model_family:
对于 model_family 的每个 hp 值:
model = model_family.train(hp, A)
score = assess(model,V)
if score &gt; best_score：//越大越好
best_model_family = model_family
best_hp = hp
best_model = model
best_score = score

完成该过程后，best_hp 包含超参数值，可产生得分最高的模型。值 best_score 是生产模型性能的预测，其中生产模型将在整个数据集上进行训练：model = best_model_family.train(best_hp, A \cup V)。
作者说这种方法容易过度拟合，因为最佳模型和最佳超参数是使用相同数据挑选的。我不明白为什么仅仅使用相同的数据集进行两次搜索就会导致过度拟合。对我来说，使用不同的超参数值类似于使用不同的模型系列。例如，考虑最近邻 ML 算法，并让其超参数为邻居的数量。对我来说，NN(3) 描述的是与 NN(4) 不同的模型系列。使用平面验证来选择最佳模型系列被认为是可以的。但是，一旦我们将邻居的数量视为超参数，使用平面验证就不再合适了。 我在这里遗漏了什么？作为参考，我现在描述什么是嵌套验证方法，用于 hp 调整和模型选择。
嵌套循环中的 HP 调整（嵌套验证）
嵌套验证方法将数据集分为三部分：原始集 A 分为两部分：A = A&#39; \cup B。超参数调整是通过对 A&#39; 进行训练和对 B 进行评估来执行的（这就是该方法被称为“嵌套”的原因），而模型选择与以前一样，通过对 A=A&#39;\cup B 进行训练和对 V 进行评估来执行，使用之前找到的最佳超参数。

对于每个 model_family:
best_score = none
对于 model_family 的每个 hp 值:
model = model_family.train(hp, A&#39;)
score = assess(model,B)
if score &gt; best_score: // 越大越好
best_hp[model_family] = hp

best_model_family = none
best_score = none
对于每个 model_family:
model = model_family.train(best_hp[model_family], A&#39; \cup B)
score = assess(model,V)
if score &gt; best_score：//越大越好
best_model_family = model_family
best_score = score

执行该过程后，best_model_family 就是我们想要在生产中使用的 ML 算法，我们使用超参数值 best_hp[best_model_family] 在整个数据集上对其进行训练。]]></description>
      <guid>https://stats.stackexchange.com/questions/657688/why-use-nested-validation-when-doing-both-hyper-parameter-tuning-and-model-selec</guid>
      <pubDate>Fri, 22 Nov 2024 15:49:41 GMT</pubDate>
    </item>
    <item>
      <title>我是否以正确的方式对加权分类调查数据进行统计显着性检验？</title>
      <link>https://stats.stackexchange.com/questions/657687/am-i-going-about-statistical-significance-testing-for-weighted-categorical-surve</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657687/am-i-going-about-statistical-significance-testing-for-weighted-categorical-surve</guid>
      <pubDate>Fri, 22 Nov 2024 15:12:36 GMT</pubDate>
    </item>
    <item>
      <title>关于神经网络反向传播的问题</title>
      <link>https://stats.stackexchange.com/questions/657684/questions-on-backpropagation-in-a-neural-net</link>
      <description><![CDATA[我理解如何以符号方式应用反向传播，用笔和纸计算公式。当真正将这些推导应用于数据时，我有两个问题：

假设某个梯度看起来像 $o_i \times w_{i,j}$，其中 $o_i$ 是第 $i$ 个神经元的输出，而 $w_{i,j}$ 是其权重之一。现在我有一批数据点，$o_i$ 中的每个数据点都有不同的值，那么我该如何用数字计算它？我是否只需对该批次中的所有数据点取平均值？
换句话说：假设我将误差（最后）定义为平均值，那么该平均值（期望值）是否只是与其余的反向传播一起传播，并且每当我看到输入数据的依赖性时，我只需插入平均运算符？
有人可以提供一些关于此的直觉吗？我的看法是，因为误差位于所有梯度的“分子”中，所以无论我们对它做什么，无论是平均还是求和，都可以简单地向后传播，您只需对您看到的所有项执行该运算符（例如平均）。如果您有一个常数（例如权重），它不会做任何事情，如果您有一个输出，您会对批次进行平均。这是合理的解释吗？

如果我们有一个较早的神经元 $N$，它在后面的层中作为输入出现两次，那么在进行反向传播时，我们可以在第二次遇到它时对其导数执行 $+=$，即我们可以天真地将各种梯度​​贡献相加。但是这个神经元可以以不同的方式参与后续神经元，它们可能有不同的数学表达式等。然而，我们可以天真地将其所有梯度相加，这是如何工作的？
这是一个很好的特性，但我不明白它是如何如此简单地发挥作用而没有任何问题。有人可以提供直观的解释吗？这似乎与“反向传播如何分块、分步骤地工作，因此确切的依赖关系不应该重要”有关，这是我目前的理解水平。

]]></description>
      <guid>https://stats.stackexchange.com/questions/657684/questions-on-backpropagation-in-a-neural-net</guid>
      <pubDate>Fri, 22 Nov 2024 14:20:10 GMT</pubDate>
    </item>
    <item>
      <title>Ian Goodfellow 的深度学习书中介绍 softmax 近似的原因</title>
      <link>https://stats.stackexchange.com/questions/657683/reason-for-softmax-approximation-in-ian-goodfellows-deep-learning-book</link>
      <description><![CDATA[在第 6.2.2.2 节（公式 6.31）中，他们指出：

总体而言，非正则化最大似然将驱动模型学习驱动 softmax 预测训练集中观察到的每个结果的计数分数的参数：
$$
\text{softmax}(\pmb{z}(\pmb{x},\pmb{\theta}))_i \approx \frac{\sum_{j=1}^{m}\pmb{1}_{y^{(j)}=i,\pmb{x}^{(j)}=\pmb{x}}}{\sum_{j=1}^{m}\pmb{1}_{x^{(j)}=\pmb{x}}}
$$

其中 $m$ 是训练集中的示例数量。
1. 如何得出这个近似值？
（此相关问题仅讨论了一个例子）
2.这个近似值是否等于以下内容：
$$
\begin{align}
&amp;\stackrel{?}{=}\frac{P_\text{data}(y=i,\pmb{x})}{P_\text{data}(\pmb{x})} \\
&amp;=P_\text{data}(y=i|x) \\
&amp;\approx P_\text{true}(y=i|x)
\end{align}
$$
此外，如果是，这是否就是为什么具有 softmax 的神经网络实际上学习所需的概率分布而不是 $[0,1]$ 上其他一些度量的原因？]]></description>
      <guid>https://stats.stackexchange.com/questions/657683/reason-for-softmax-approximation-in-ian-goodfellows-deep-learning-book</guid>
      <pubDate>Fri, 22 Nov 2024 14:02:49 GMT</pubDate>
    </item>
    <item>
      <title>YouTube 缩略图 A/B/C 测试中的留存模式分析</title>
      <link>https://stats.stackexchange.com/questions/657681/accounting-for-retention-patterns-in-youtube-thumbnail-a-b-c-testing</link>
      <description><![CDATA[我正在使用 YouTube 缩略图 A/B/C 测试功能，但遇到了令人难以置信的结果 - 我正在尝试找出原因。一种理论是 YouTube 在计算时没有考虑留存率，观看时间的巨大差异可能会影响计算结果。
上下文：
视频长达数小时（2-3 小时）。
大多数观众（约 50%）在第一分钟内就离开了
一小部分人观看了整个视频（7-10%）。
测试平台将展示次数（观看缩略图的人）平均分配给缩略图。
成功指标为：（缩略图变体的观看时间）/（所有变体的总观看时间）
示例场景：
如果 10 个人被分配到 2 个缩略图（每个 5 个），并且其中一个组恰好包含观看整个视频的单个观众，这可能会严重扭曲结果。我的直觉是，这种高方差需要更多样本才能获得可靠的结果。
问题：

根据观看时间百分比计算最佳缩略图时，是否需要考虑留存模式？或者这些信息是否不需要直接处理，因为它将反映在观看时间份额百分比中。

如果是这样，需要多少样本才能获得具有统计意义的结果？我需要用什么公式来计算这个？

]]></description>
      <guid>https://stats.stackexchange.com/questions/657681/accounting-for-retention-patterns-in-youtube-thumbnail-a-b-c-testing</guid>
      <pubDate>Fri, 22 Nov 2024 12:07:33 GMT</pubDate>
    </item>
    <item>
      <title>两组样本数不同但增长至相同值的相关性</title>
      <link>https://stats.stackexchange.com/questions/657680/correlation-of-two-sets-growing-to-the-same-value-but-different-number-of-sample</link>
      <description><![CDATA[如何获取两个不同长度的集合之间的相关性？我知道皮尔逊相关性不起作用。但是如果它们增长到相同的值，我可以做些什么吗？这就是我的意思。
假设我有两个集合：
[1, 2, 3, 4] 和 [1, 1, 2, 2, 1, 3]
我们可以看到它们的长度不同，但总和相同。
[1, 3, 6, 10] 和 [1, 2, 4, 6, 7, 10]
我们可以看到它们都累积到 10。
我在想，如果我将它们绘制成 x 轴上的累积和以及 y 轴上的原始点。我可以像“连接点”一样。之后，我在想也许我可以对它们进行卷积或者类似的事情，或者像它们的内积？不太确定我在说什么。
这能行得通吗？你能建议一些可以帮助解决这个问题的方法吗？
非常感谢！
编辑：
在回答这些数据代表什么的问题时，这个问题是一个信号处理问题。
系统的工作方式如下。我在一段时间内收到随机数量的尖峰。就我上面的示例而言，假设为 10 秒。
每 10 秒，我都会读取一些尖峰，但尖峰到达的时间与前一个尖峰的时间不同。这就是这个集合所代表的内容：
[1, 2, 3, 4] 和 [1, 1, 2, 2, 1, 3]
现在的问题是，这两个有多大关系？
编辑 2：
在这种情况下，“相关”是什么意思？
对于我的应用程序，“相关”的概念看起来像这样：
[5, 4, 3, 2, 1]
与...略有关系
[4, 3, 2, 1, 1, 2, 2]
如果我绘制到达时间的曲线，一个只是另一个的延迟版本。
我不知道如何称呼我试图描述的这个属性。希望这个描述有所帮助！
编辑 3：
给定：[5, 4, 3, 2, 1]
我们还可以说它与以下内容相关：
[3.9, 3.1, 2, 0.8, 1.2, 2, 2]
此外，我需要能够判断采样是晚还是早。
我们可以说
[3.9, 3.1, 1.9, 0.8, 1.2, 2, 2]
与给定值相比晚了。
并且
[2.5, 5, 4, 3, 0.5]
与给定值相比早了。
编辑4：
抱歉，这有点令人困惑。
什么是晚，什么是早？
给定 A = [5, 4, 3, 2, 1]
B = [4, 3, 2, 1, 1, 2, 2]
且 C = [1, 5, 4, 3, 2]
与 A 相比，B 晚了。
与 A 相比，C 早了。
直觉是这样的。

[5, 4, 3, 2, 1] -&gt; A：完美时机
[4, 3, 2, 1, 1, 2, 2] -&gt; B：晚时机
[1, 5, 4, 3, 2] -&gt; C：早期时机

看到 B 的某些部分与 A 相似，C 同样与 A 相似。它们有相似之处，但索引发生了偏移。
B 和 C 与 A“相关”。
此外，我们可以说
D = [3.9, 3.1, 2, 0.8, 1.2, 2, 2]
D 是 B 的一个略微不准确的版本。
在我的“相关”上下文中，D 也与 A 相关。
希望有所帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/657680/correlation-of-two-sets-growing-to-the-same-value-but-different-number-of-sample</guid>
      <pubDate>Fri, 22 Nov 2024 12:03:51 GMT</pubDate>
    </item>
    <item>
      <title>如何从 N-2 边际生成 N 维多元正态样本</title>
      <link>https://stats.stackexchange.com/questions/657678/how-to-generate-n-dimensional-multivariate-normal-sample-from-n-2-marginals</link>
      <description><![CDATA[我的“计算器”遇到了一个问题，它使用通过 N 维多元正态分布生成的样本。我在下面附上了一个代码片段来说明这个问题。
我的计算器从 sample_1 中提取：

M：对 sample_1 中的每个数字都敏感的数字
M_n：一个由 N 个数字组成的向量，每个数字都对 sample_1 中的一列且仅一列敏感

现在，我需要分析我的计算器对相关矩阵中一个特定元素的敏感度。我通过将 correlation_matrix_1 中的 (0, 1) 元素从 0.0 更改为 0.02 来实现。简而言之，问题在于 sample_2 中的第 3 列与 sample_1 中的第 3 列不同。这会导致 M_2 发生更改，这是不理想的结果。两个示例的屏幕截图都位于本消息的末尾，
现在的问题是：我如何从以下位置生成 sample_2 的第 0 列和第 1 列：

sample_1 的第 2 列 -&gt;修复 M_2
correlation_matrix_2

请注意，我必须能够对更大的矩阵执行此操作，尽管仍然需要每次更改一个矩阵元素。
import numpy as np

def main(correlation_matrix: np.ndarray, mc_seed: int = 1234,
n_trials: int = 10):
generator = np.random.default_rng(seed=mc_seed)
segment_factor_sample = generator.multivariate_normal(
mean=[0] * correlation_matrix.shape[0],
cov=correlation_matrix,
size=n_trials,
check_valid=&#39;raise&#39;)
returnsegment_factor_sample

if __name__ == &#39;__main__&#39;:
correlation_matrix_1 = np.array([[1.0, 0.0, 0.0],
[0.0, 1.0, 0.0],
[0.0, 0.0, 1.0]])
sample_1 = main(correlation_matrix_1)

correlation_matrix_2 = np.array([[1.0, 0.02, 0.0],
[0.02, 1.0, 0.0],
[0.0, 0.0, 1.0]])
sample_2 = main(correlation_matrix_2)


sample_1


sample_2]]></description>
      <guid>https://stats.stackexchange.com/questions/657678/how-to-generate-n-dimensional-multivariate-normal-sample-from-n-2-marginals</guid>
      <pubDate>Fri, 22 Nov 2024 11:33:44 GMT</pubDate>
    </item>
    <item>
      <title>GAMM 中的 AIC 值问题</title>
      <link>https://stats.stackexchange.com/questions/657675/problems-with-aic-values-in-gamms</link>
      <description><![CDATA[为了检验一个假设，我在 R 中使用广义加性混合模型，并使用 mgcv 包构建了以下模型：
 gam(Resp ~ s(Pred1, bs=&quot;cr&quot;) + s(Pred2, bs=&quot;cr&quot;) + s(Pred3, bs=&quot;cr&quot;) + s(Pred4, bs=&quot;cr&quot;) + ti(Pred3, Pred4) + s(Factor, bs=&quot;re&quot;), data=Data, family=binomial)

然后，我使用 dredge 函数（MuMIn 包）获取按 AIC 值递增排序的所有潜在模型的列表。在此列表中，前四个模型具有相同的 AIC 值，因此具有相同的 DeltaAIC 和 AIC 权重（见下图）。并且这种情况一直发生在以下模型中。
为什么会发生这种情况？这是估算 Pred1 以及 Pred3 和 Pred4 之间相互作用的问题吗？任何帮助都将不胜感激！
]]></description>
      <guid>https://stats.stackexchange.com/questions/657675/problems-with-aic-values-in-gamms</guid>
      <pubDate>Fri, 22 Nov 2024 11:07:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么 R 中的二项式家族（link="log"）的 glm 有时需要起始值？</title>
      <link>https://stats.stackexchange.com/questions/657665/why-does-glm-in-r-with-family-binomiallink-log-sometimes-require-start-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657665/why-does-glm-in-r-with-family-binomiallink-log-sometimes-require-start-value</guid>
      <pubDate>Fri, 22 Nov 2024 09:25:45 GMT</pubDate>
    </item>
    <item>
      <title>rugarch 包中条件方差的初始值是如何计算的？</title>
      <link>https://stats.stackexchange.com/questions/657651/how-are-the-initial-value-of-conditional-variance-calculated-in-rugarch-package</link>
      <description><![CDATA[我正在尝试使用 rugarch 库验证我的零均值 GARCH(1,1) 模型的计算。起初，我认为条件方差的初始第一个值与无条件方差（python 中的 arch 包使用）的值相同，因为没有过去的回报，也没有过去的方差来计算它。
但是当我使用 garch_fit@fit$var 重新检查条件方差的第一个初始值时，它与无条件方差不同。
我尝试使用计算器手动计算无条件方差，它给出的输出与 uncvariance(garch_fit) 相同，这不是模型中条件方差的初始第一个值。那么，如果 GARCH 过程不是由无条件方差初始化的，那么第一个值是如何计算的呢？
以下是我的规范代码：
garch_spec &lt;- ugarchspec(
mean.model = list(armaOrder = c(0, 0), include.mean = FALSE), # 无 ARMA 项，零均值
variance.model = list(model = &quot;sGARCH&quot;, garchOrder = c(1, 1)), # GARCH(1, 1)
distribution.model = &quot;norm&quot; # 正态分布
)
garch_fit &lt;- ugarchfit(
spec = garch_spec,
data = data$log_return_pct,
solver = &quot;hybrid&quot;,
out.sample = 83
)

以及两者之间的区别第一个初始方差
&gt; uncvariance(garch_fit)
[1] 0.5865156
&gt; garch_fit@fit$var[1]
[1] 0.5869211
]]></description>
      <guid>https://stats.stackexchange.com/questions/657651/how-are-the-initial-value-of-conditional-variance-calculated-in-rugarch-package</guid>
      <pubDate>Fri, 22 Nov 2024 00:48:50 GMT</pubDate>
    </item>
    <item>
      <title>使用线性混合模型时，输出变量中缺失多少数据是可以接受的？</title>
      <link>https://stats.stackexchange.com/questions/657631/how-much-missing-data-in-the-output-variable-is-ok-when-using-linear-mixed-model</link>
      <description><![CDATA[我有重复测量数据，但由于缺失，我计划使用线性混合模型。我唯一的预测因子是时间，结果变量是定量测量的幸福感得分。目标是确定幸福感是否随着时间的推移而发生整体变化。
幸福感得分是通过四个时间点的季度调查收集的，参与人数如下：

时间 1：25 名参与者
时间 2：54 名参与者
时间 3：70 名参与者
时间 4：120 名参与者

由于大量缺失数据，近 80% 的答复不完整。许多参与者只参加了一次，特别是在时间 4，缺乏后续数据。为了解决这个问题，我过滤了数据集以仅包含至少参加过两个时间点的参与者。经过筛选后，参与人数如下：

时间 1：21 名参与者
时间 2：35 名参与者
时间 3：46 名参与者
时间 4：47 名参与者

此调整将缺失数据减少至约 36%。排除仅参加过一次的参与者是否合适？缺失数据多少才合适？
我非常感谢任何反馈或建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/657631/how-much-missing-data-in-the-output-variable-is-ok-when-using-linear-mixed-model</guid>
      <pubDate>Thu, 21 Nov 2024 17:24:52 GMT</pubDate>
    </item>
    </channel>
</rss>