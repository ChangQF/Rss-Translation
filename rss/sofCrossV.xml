<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 09 Jun 2024 21:14:12 GMT</lastBuildDate>
    <item>
      <title>考虑分类问题中的非对称损失函数</title>
      <link>https://stats.stackexchange.com/questions/648926/taking-into-account-a-non-symmetric-loss-function-in-a-classification-problem</link>
      <description><![CDATA[
考虑一种二元分类方法，该方法估计类别概率，并且可以指定观察权重（例如 Logistic 回归）。为了适应 TP 和 FP 的差异损失，哪种方法效果更好：

1a) 不要指定权重。相反，调整概率阈值，直到结果从客户端的角度来看看起来不错。
1b) 将概率阈值固定在 0.5 并调整权重。

考虑一个问题，其中响应有超过 2 个类别，并且损失函数取决于观察被错误分类的确切程度。例如，将 1 误分类为 5 比将 1 误分类为 2 损失更大。

2a) 我理解的对吗？仅通过指定观察权重就不可能容纳这种损失函数？
2b) 如果 2a) 的答案是肯定的，您可以推荐什么免费软件来解决该问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/648926/taking-into-account-a-non-symmetric-loss-function-in-a-classification-problem</guid>
      <pubDate>Sun, 09 Jun 2024 21:06:27 GMT</pubDate>
    </item>
    <item>
      <title>广义加性模型中的估计</title>
      <link>https://stats.stackexchange.com/questions/648924/estimation-in-generalized-additive-models</link>
      <description><![CDATA[我目前正在尝试通过 Simon N. Wood 所著的《广义可加模型：R 语言简介》一书来了解广义可加模型 (GAM)。但是，我对以下部分有一些疑问。
第 6.1 章指出，GAM 成为过度参数化的 GLM，形式为
$$g(\mu_i) = X_i\beta, \quad y_i \sim EF(\mu_i, \phi),$$
其中 $EF$ 代表指数族，并且 $\beta$ 通过最大化来估计
$$l_p(\beta) = l(\beta) - \frac{1}{2\phi}\sum_j\lambda_j\beta^TS_j\beta.$$
我的问题是：

简单地从对数似然中减去惩罚项的总和，然后最大化相对于$\beta$的结果函数的理由是什么？
因子$\frac{1}{2\phi}$从何而来？

任何帮助都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648924/estimation-in-generalized-additive-models</guid>
      <pubDate>Sun, 09 Jun 2024 20:48:15 GMT</pubDate>
    </item>
    <item>
      <title>如何利用少量数据集改进模型</title>
      <link>https://stats.stackexchange.com/questions/648923/how-to-imporove-a-model-with-little-dataset</link>
      <description><![CDATA[我有一个包含 20 个特征和 65 个样本的数据集。我进行了数据缩放。我也以不同的方式进行了特征选择。但这是结果。
测试集评估：

MAE：2.3462910007887787
MSE：8.68486045116839
RMSE：2.947008729401457
R2 平方 0.11298965960629503

训练集评估：

MAE：1.9746175830150061
MSE：6.369273380984405
RMSE：2.5237419402514996
R2 平方 0.45535061890623796

adj r2 训练0.4008856807968617
adj r2 测试 -0.12354643116535957
我研究过不同的模型，最好的结果是线性模型，比如线性回归。你有办法改进模型和结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648923/how-to-imporove-a-model-with-little-dataset</guid>
      <pubDate>Sun, 09 Jun 2024 20:42:50 GMT</pubDate>
    </item>
    <item>
      <title>宽浅神经网络 VS 深度神经网络</title>
      <link>https://stats.stackexchange.com/questions/648922/wide-shallow-neural-networks-vs-deep-nn</link>
      <description><![CDATA[我有几个关键的理解点，但我无法得出关于为什么浅层神经网络不能像深度神经网络那样有效地建模数据的最终结论。

我理解我们可以用高维空间中的简单函数来表示低维空间中的任何复杂函数。

我理解高维空间中的机器学习模型更容易过度拟合，因为高维查找表可以记住数据。

我理解更深的神经网络可以比浅层神经网络更好地建模非线性，从而更好地估计将输入映射到输出的真实函数。

我理解核方法将数据投影到无限维空间并计算对之间的点积。在无限维空间中，任何两个数据集都可以线性分离，点积可以帮助确定测试点属于哪个数据集。向高维空间的投影不是明确学习的。


鉴于这些观察，为什么浅层神经网络会失败？将数据点投影到高维空间似乎有益，但容易过度拟合。这个问题也会影响深度神经网络。那么，我在这里遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648922/wide-shallow-neural-networks-vs-deep-nn</guid>
      <pubDate>Sun, 09 Jun 2024 20:31:50 GMT</pubDate>
    </item>
    <item>
      <title>二进制和连续数据的模糊聚类分析</title>
      <link>https://stats.stackexchange.com/questions/648920/fuzzy-cluster-analysis-with-binary-and-continue-data</link>
      <description><![CDATA[我正在使用 R 进行模糊聚类分析。有人告诉我，常见的模糊 c 均值（类似于清晰聚类中的 k 均值）不适用于混合类型的数据。
我想知道我是否可以使用 Gower 系数生成一个不相似矩阵，然后将该矩阵应用于 c 均值？或者 R 中是否有其他可用的包可用于对混合数据进行模糊聚类分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/648920/fuzzy-cluster-analysis-with-binary-and-continue-data</guid>
      <pubDate>Sun, 09 Jun 2024 20:05:48 GMT</pubDate>
    </item>
    <item>
      <title>等级相关性：斯皮尔曼系数和 $R^2$ 有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/648919/rank-correlations-what-is-the-difference-between-spearman-coefficient-and-r2</link>
      <description><![CDATA[当数据不呈正态分布时，斯皮尔曼秩系数与$R^2$有何不同？
据我了解，在进行秩相关时，轴通常不应显示实际的原始数据，而是显示其秩。
但是，我找到了这篇论文，DOI：10.1183/13993003.00092-2016，这里：https://erj.ersjournals.com/content/48/2/484.long
其中图表显示的是实际数据，而不是它们的等级，其中有 Spearman 系数和 $R^2$(图 D)，同样在执行 Mann Whitney 检验时 (图 C)，轴不显示等级，而是原始数据：

我没有正确理解什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648919/rank-correlations-what-is-the-difference-between-spearman-coefficient-and-r2</guid>
      <pubDate>Sun, 09 Jun 2024 19:55:29 GMT</pubDate>
    </item>
    <item>
      <title>Z 分数（热图）以及带有重复和异常值的统计数据</title>
      <link>https://stats.stackexchange.com/questions/648918/z-scores-heatmap-and-statistics-with-replicates-and-outliers</link>
      <description><![CDATA[我的小组进行了一项生物学测定。该测定针对 6 种不同的细胞培养条件（列）和 6 个基因（行）进行。但是，每个基因也进行了 5 次（5 次重复）。
我们的数据示例：



基因
条件 1
条件 2




基因 1 重复 1
0.22
120


基因 1 重复 2
0.34
122


基因 1 重复3
0.45
119


基因 1 重复 4
0.33
34


基因 1 重复 5
0.55
90


基因 2 重复 1
12
0.1


基因 2 重复 2
19.3
0.45


基因 2 重复3
23.4
NA


基因 2 重复 4
11.7
0.89


基因 2 重复 5
12.4
0.1



以此类推...6 个基因和 6 个条件。不幸的是，我们也有 2 个 NA 值（对于基因 5 中的 2 个条件，重复 3 次，这并不意味着该值为 0，只是机器无法检测到（低于可检测值）。
我已经在 stackoverflow 上发布了一个关于如何使用 R 执行分析（z 分数和热图）的问题，一位非常友好的用户也建议在这里询问以获得更统计的见解。
最终的热图将表示这些基因在不同条件下表达的变化。基本上，最后我们想根据它们的基因表达来比较条件，也许是一种模式。最后，我们想说“这种细胞培养条件具有这种基因模式，这与那种细胞培养条件的基因模式不同”。
我们的问题 1 是异常值。重复次数 4 在每个条件下都是异常值。我们应该排除它吗？如果是这样，我们将只有 4 个重复用于统计分析（例如相关性等）。
因为异常值我很困惑，z 分数是否应该用平均值来计算，或者在这种情况下我们是否可以使用中位数。我很清楚这会使结果产生偏差。计算每个 z 分数然后根据基因将它们放在一起在统计上是否正确（例如，将基因 1 条件 1 重复的所有 z 分数放在一起）？
问题 2 是两个缺失值。我怎样才能继续使用数据但忽略这些值？这会如何影响我的统计分析？
此外，您对用于热图这些数据的聚类和距离方法有什么建议吗？
最后，我们考虑执行 Wilcoxon 检验（非参数配对样本检验）和 1 样本 t 检验来对数据进行实际统计分析。我们被建议同时使用这两种方法，因为数据有点奇怪，同时进行两种分析将加强结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/648918/z-scores-heatmap-and-statistics-with-replicates-and-outliers</guid>
      <pubDate>Sun, 09 Jun 2024 19:31:39 GMT</pubDate>
    </item>
    <item>
      <title>具有偏斜（非常低或非常高）比例的超几何分布的样本量计算</title>
      <link>https://stats.stackexchange.com/questions/648915/sample-size-calculation-for-hypergeometric-distribution-with-skewed-very-low-or</link>
      <description><![CDATA[我有超几何分布：
人口规模 N = 500，
人口比例 = 0.01（1%）。这是从以前的实验中估计的比例。我需要计算样本量，以验证人口中的成功次数是否小于 2%。
我发现超几何分布的样本量公式如下：
n = (NZ^2pq)/(E^2(N-1)+Z^2pq)
如果成功率非常小（例如 1%），样本量也会非常小（置信度为 95%，误差幅度为 0.05）。在如此小的样本中，至少有一次成功的概率将非常低。
您能否澄清，对于如此偏斜的人群，问题是否在于 MoE 过高，我需要选择较低的值（例如 0.005）？还是我应该选择其他公式来计算样本量？
当样本量不是非常小但比例较低时，您能否建议我使用哪个置信区间？]]></description>
      <guid>https://stats.stackexchange.com/questions/648915/sample-size-calculation-for-hypergeometric-distribution-with-skewed-very-low-or</guid>
      <pubDate>Sun, 09 Jun 2024 19:11:02 GMT</pubDate>
    </item>
    <item>
      <title>通过 MLE 估计参数与最小化期望偏差之间有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/648914/what-is-the-difference-between-estimating-parameters-via-mle-versus-minimizing-d</link>
      <description><![CDATA[使用 MLE（或具有均匀先验的 MAP）估计参数与使用 MLE（或具有均匀先验的 MAP）估计参数之间有什么区别：
$$\theta^* = \arg \max_\theta p(X|\theta)$$
根据哪种设置估计它们会导致我们的测量数据和基于这些参数的期望之间的偏差最小？也就是说，
$$\theta^* = \arg \min_\theta ||\,\bar{X} - \mathbb E_{p(X|\theta)}[X|\theta]\,||.$$
这是一个例子。我有一枚可能有偏差的硬币（$\theta = p(H) \in \lbrace{0.25, 0.50, 0.75\rbrace}$），但您不知道是哪一枚。我将其抛 $1000$ 次，看到 $625$ 个正面。我们想要估计$\theta$。
爱丽丝说，“嗯，当$\theta = \lbrace{0.25, 0.50, 0.75\rbrace}$时，看到$625$个正面的概率分别为$3.8 \times 10^{-138}、0.5 \times 10^{-19}$和$7.4 \times 10^{-19}$。 $\theta = 0.75$ 最大化二项概率给出的 $\mathscr L = p(X|\theta)$ 可能性，所以这是我的猜测。
Bob 说，“如果 $\theta$ 是 $\theta = \lbrace{0.25, 0.50, 0.75\rbrace}$，那么我们分别会预期看到 $250$、$500$ 和 $750$ 正面。 $0.5$ 和 $0.75$ 最小化了我们看到的结果与预期结果之间的偏差，因此我对这些结果的猜测无所谓。&quot;
Bob 的参数估计风格有名字吗？他的方法有问题吗？它有任何统计保证吗？当然，人们可以将他的算法视为针对损失函数 $L = (\bar{X} - \mathbb E_{\mathscr L}[X|\theta])^2$ 的优化，但我想知道这是否是一种具有直观概率公式的合理方法（就像 OLS 中的 MSE 损失和高斯似然一样）。]]></description>
      <guid>https://stats.stackexchange.com/questions/648914/what-is-the-difference-between-estimating-parameters-via-mle-versus-minimizing-d</guid>
      <pubDate>Sun, 09 Jun 2024 19:05:08 GMT</pubDate>
    </item>
    <item>
      <title>在单位区间上无偏的拟随机数序列</title>
      <link>https://stats.stackexchange.com/questions/648912/quasi-random-number-sequence-that-is-unbiased-on-the-unit-interval</link>
      <description><![CDATA[我试图将 Halton 序列用于二维准蒙特卡罗方法。但是，我遇到的一个问题是序列的平均值始终小于一半（除了选择序列长度），这使其有偏差。
据我所知，如果 $n = b^i - 1$，则 Halton 序列的平均值将恰好为 .5，其中 $n$ 是采样点的数量，$b$ 是基数，$i$ 是某个非负整数。在所有其他 $n$ 中，序列的平均值小于 .5。
我想“调整”此序列的平均值对于任意 $n$ 都是 .5。
我的想法是首先生成一个较长的 Halton 序列，长度为 $b^{\lceil\log_b n\rceil} - 1$，然后保留前 $b^{\lfloor\log_b n\rfloor} - 1$ 个值。这些序列的平均值均为 .5。然后，在剩余的值中选择 $n - \left(b^{\lfloor\log_b n\rfloor} - 1\right)$ 个，使得它们的平均值为 .5。但是，我不确定如何过滤剩余的集合。
我不介意为了确保平均值为 0.5 而保留或删除某个数字。我的意思是，我的序列的长度可以在 $n \pm 1$ 之内，只要平均值是一半，我就会很高兴。
我应该怎么做？还有其他序列/程序可以生成在单位间隔上无偏的准随机数吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648912/quasi-random-number-sequence-that-is-unbiased-on-the-unit-interval</guid>
      <pubDate>Sun, 09 Jun 2024 18:23:21 GMT</pubDate>
    </item>
    <item>
      <title>状态数变化的马尔可夫链</title>
      <link>https://stats.stackexchange.com/questions/648911/markov-chains-with-changing-number-of-states</link>
      <description><![CDATA[我以前见过这些类型的离散状态马尔可夫链（连续时间或离散时间）：

同质（概率转移矩阵是常数）
非同质（概率转移矩阵随时间变化）

但是，以下类型的马尔可夫链的状态数随时间变化又如何呢：

假设马尔可夫链 Xt 最初以 S = 0,1,2...k 个状态开始
存在某个随机变量 Tau，它遵循某个分布 P(tau)。
接下来，我们有一个 S 的概率分布，即 P( |S|_t+1 = k2 给定 |S|_t-1 = k2 AND Tau=t)... 这是 Xt 的状态空间在时间 t+1 有 k2 个状态的概率，假设在时间 t 有 k1 个状态，并且一些Tau 经过的随机时间量（k 必须是正整数）
最后，写下：P(Xt+1 = j 给定 Xt = i, |S|_t =k1, Tau = t)
我想可以添加一些约束来限制 a &lt; |S| &lt; b 之间的状态数...并且我还可以添加一些内容来说明状态总数总是随时间增加或随时间减少，例如 |S|_t+1 &gt;= |S|_t 对所有 t&gt;=0 。或者 P(|S|_t+1 gtiven |S|_t) 可以像简单的随机游走一样，防止状态总数增长或缩小过快（即每次最大增长/减少 1）
我可能还需要一些“概率分配函数”，当状态数量缩小或增加时重新分配概率。例如，无论 |S_t 的大小如何，相应转换矩阵中的所有元素始终彼此相等

这种类型的马尔可夫链在实践中是否被分析过？我认为这有点类似于双重随机过程（例如，考克斯过程 - 泊松过程，其中速率参数根据高斯过程演变）？
我想我在问题中描述的这个过程不再遵循无记忆属性。我在想，也许在一些现实世界的例子（例如队列）中，服务器的数量可能会根据队列的当前条件和历史而改变（例如，随着员工开始辞职，剩余的员工变得更加劳累，现在开始以更高的速度辞职，进一步影响剩余的员工辞职等）
这个问题是否被分析过？]]></description>
      <guid>https://stats.stackexchange.com/questions/648911/markov-chains-with-changing-number-of-states</guid>
      <pubDate>Sun, 09 Jun 2024 17:54:53 GMT</pubDate>
    </item>
    <item>
      <title>使用 MCMC 生成 Gamma 分布 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648909/generate-gamma-distribution-using-mcmc</link>
      <description><![CDATA[我有一个与伽马分布非常相似的分布，我决定使用 MCMC 生成它。但为了回答这个问题，让我们从伽马分布中生成一个观测值。我面临的典型情况是：
N &lt;- 2999
library(MCMCpack)

my_gamma &lt;- function(x){
return(x**N*exp(-2*x))
}

samples = MCMCmetrop1R(fun=my_gamma, theta.init=1,V=as.matrix(1))
print(samples)

分布的平均值是 $1500$，这显然在可行范围内。
但是，我无法让代码工作，因为该方法返回无穷大。我如何调整 R 代码以使此 MCMC 方法工作？该代码适用于较小的$N$。]]></description>
      <guid>https://stats.stackexchange.com/questions/648909/generate-gamma-distribution-using-mcmc</guid>
      <pubDate>Sun, 09 Jun 2024 16:30:35 GMT</pubDate>
    </item>
    <item>
      <title>任意分布的边缘化</title>
      <link>https://stats.stackexchange.com/questions/648901/marginalisation-with-respect-to-arbitrary-distribution</link>
      <description><![CDATA[设$(\Omega, \mathcal{A}, \mathbb{P})$为概率空间。让 $X: \Omega\rightarrow\mathcal{X}$ 和 $Y: \Omega\rightarrow\mathcal{Y}$ 为随机变量。
现在，我知道
$$\int_{C}\mathbb{P}_{Y|X=x}(D)\mathbb{P}_{X}(dx)=\mathbb{P}_{X,Y}(C,D),$$
它定义了 $\mathcal{X}\times\mathcal{Y}$ 上的联合分布
我还知道
$$\int_{\mathcal{X}}\mathbb{P}_{Y|X=x}(D)\mathbb{P}_{X}(dx)=\mathbb{P}_{Y}(D),$$
它定义了 $\mathcal{Y}$ 上的分布。
我现在的问题是，如果我们在这些方程中用 $\mathcal{X}$ 上的任意概率测度代替边际分布 $\mathbb{P}_X$，并称之为 $\mu$，会发生什么情况？即是
$$\int_{C}\mathbb{P}_{Y|X=x}(D)\mu(dx)$$
仍然是
$\mathcal{X}\times\mathcal{Y}$上的联合分布？
并且是
$$\int_{\mathcal{X}}\mathbb{P}_{Y|X=x}(D)\mu(dx)$$
仍然是$\mathcal{Y}$上的分布，并且不再依赖于$x$，即具有$x$
也被边缘化了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648901/marginalisation-with-respect-to-arbitrary-distribution</guid>
      <pubDate>Sun, 09 Jun 2024 12:07:36 GMT</pubDate>
    </item>
    <item>
      <title>如何解释同一棵树/树枝的两种不同组织的多次测量？</title>
      <link>https://stats.stackexchange.com/questions/648890/how-to-account-for-multiple-measurements-of-2-different-tissues-of-a-same-tree-b</link>
      <description><![CDATA[我正在根据光谱法（260/280nm 值）对这些结果进行 DNA 提取和 DNA 质量评估。因此，我想比较或查看从同一棵树的 15 个个体的叶子和芽中提取的 DNA 之间是否存在差异。
我认为 t 检验是我可以使用的方法之一，但我很难在配对和独立 t 检验之间做出选择。我认为 t 检验是可行的方法可能是错误的，因此我非常感谢任何建议]]></description>
      <guid>https://stats.stackexchange.com/questions/648890/how-to-account-for-multiple-measurements-of-2-different-tissues-of-a-same-tree-b</guid>
      <pubDate>Sun, 09 Jun 2024 02:33:17 GMT</pubDate>
    </item>
    <item>
      <title>如何考虑不同阶段和合同特征，模拟取消对法律部门案件解决时间的影响？</title>
      <link>https://stats.stackexchange.com/questions/648888/how-to-model-the-impact-of-cancellations-on-case-resolution-times-in-the-legal-d</link>
      <description><![CDATA[我正在做一项分析，以了解我公司法务部门的案件解决时间。我们的流程可能会出现取消，导致案件回到之前的阶段，从而影响整体解决时间。
具体来说，我想估计这些取消会增加多少额外的时间，具体取决于它们发生的阶段。此外，我需要考虑根据合同类型和请求部门的不同而产生的变化。我最初的方法是使用回归模型，其中因变量是总解决时间，自变量包括阶段之间的取消、合同类型和请求部门。为了处理案例类型的多变性，我考虑使用聚类将案例划分为同类组，然后将回归模型应用于这些聚类。
我的问题是：

对于这种类型的分析，在回归之前进行聚类是个好主意吗？
是否有其他方法或模型可能更适合分析取消对解决时间的影响？
如何验证聚类和后续回归的有效性？

我拥有的数据包括有关每个案例的详细信息，例如每个阶段的开始和结束日期、取消记录及其发生的阶段，以及合同和请求部门的特征。任何关于此分析最佳方法的建议或推荐都将不胜感激。
还有什么您想添加或修改的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648888/how-to-model-the-impact-of-cancellations-on-case-resolution-times-in-the-legal-d</guid>
      <pubDate>Sun, 09 Jun 2024 02:03:28 GMT</pubDate>
    </item>
    </channel>
</rss>