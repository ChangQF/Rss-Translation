<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 26 Sep 2024 06:24:27 GMT</lastBuildDate>
    <item>
      <title>处理连续比率模型中的缺失信息 - 审查？</title>
      <link>https://stats.stackexchange.com/questions/654925/handling-missing-information-in-continuation-ratio-model-censoring</link>
      <description><![CDATA[我正在 R 中拟合连续比率模型，首先使用 rms::cr.setup() 将数据放入“人阈值”或“人周期”格式，然后拟合逻辑回归。（如 Cole &amp; Ananth, 2001 中所述）。我的结果涉及“治疗级联”的进展程度每个人得到：
1 - 需要治疗但未转诊
2 - 转诊（但未参加入院治疗）
3 - 参加入院治疗（但治疗时间 &lt;14 天）
4 - &gt;= 14 天治疗

我的问题是，对于某些人，我们知道他们参加了入院治疗，但没有关于他们接受治疗时间的信息。换句话说，我们知道它们对结果的价值是 &gt;=3，但不知道真实值是 3 还是 4。
我读到，连续模型可以概念化为具有逻辑链接的离散生存或风险模型（例如，Cole &amp; Ananth，2001；Suresh 等人，2022；Tutz &amp; Schmid，2016，第 38 页）。鉴于此，我可以右删失那些我不知道它们是否超出摄入量/第 3 级的情况吗？我该如何实现这一点？
图 1 来自 Suresh 等人。似乎表明我可以通过添加行直到审查点来实现这一点，但对于这些情况将所有值设置为 0（例如，ID 2 在间隔 4 处审查，ID 3 在间隔 5 处审查）：

但我真的不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/654925/handling-missing-information-in-continuation-ratio-model-censoring</guid>
      <pubDate>Thu, 26 Sep 2024 05:09:51 GMT</pubDate>
    </item>
    <item>
      <title>分母可以为 0 时的比率</title>
      <link>https://stats.stackexchange.com/questions/654924/ratios-when-0-denominator-is-possible</link>
      <description><![CDATA[我看过一些讨论类似内容的帖子，但我觉得我的用例有点不同，不符合给出的答案。
我有数字使用记录，用户在给定时间段内可以使用网站或移动应用程序或两者。用户将始终至少使用一次网站或应用程序。我想创建一个标签，上面写着“始终使用网站”、“始终使用应用程序”、“主要使用网站”、“主要使用应用程序”和“甚至”之类的内容。除了简单的标签外，我还想观察比率的“权重” - 不仅仅是它是否不同，而且有多大？我的想法...
使用 x = web 数量/应用数量的比例...

始终是 web - web 数量/0（未定义）
始终是应用 - 0/应用数量（0）
偶数 - 我可能会将 0.9 和 1.1 之间的任何值称为“偶数”
主要两者之一为 &lt; 0.9 或 &gt; 1.1

我的问题是第一个，始终是 web。有人能建议创建某种“加权”指标来显示差异如何/是否不同，以及差异有多大吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654924/ratios-when-0-denominator-is-possible</guid>
      <pubDate>Thu, 26 Sep 2024 02:23:41 GMT</pubDate>
    </item>
    <item>
      <title>如何平滑这些曲线以获取其趋势？</title>
      <link>https://stats.stackexchange.com/questions/654922/how-to-smoothen-these-curves-to-get-their-trends</link>
      <description><![CDATA[我有一组 10 个信号，如下所示：

我们可以看到，它们非常嘈杂，而大多数噪声都是异常值。我需要能够以某种方式使它们平滑，从而保留每个信号中的点数。
到目前为止，我已经尝试了双重应用中值滤波器，并且获得了接近我想要的结果，但不幸的是，它并不是对所有滤波器都有效，并且在信号开始时看起来并不可靠：

那么，您知道对这种情况有用的任何方法吗？我在这个领域的知识非常有限，基本上仅限于中值滤波和 Savitzky-Golay，这似乎没什么用。
我需要非常平滑的线条来保留主要趋势（不是超精确），并且没有异常值/振荡。

数据（10 个列表的列表）
链接：https://jpst.it/3VUqP]]></description>
      <guid>https://stats.stackexchange.com/questions/654922/how-to-smoothen-these-curves-to-get-their-trends</guid>
      <pubDate>Thu, 26 Sep 2024 01:10:42 GMT</pubDate>
    </item>
    <item>
      <title>DoE - 混合两种材料的因子和因子水平</title>
      <link>https://stats.stackexchange.com/questions/654919/doe-factors-and-factor-levels-for-blending-two-materials</link>
      <description><![CDATA[如何在此自定义实验设计中设置因子和因子水平？我正在为沥青混凝土混合料制作不同的骨料混合物。
A 类骨料来自 3 个采石场：A1、A2 和 A3。
B 类骨料来自 3 个不同的采石场：B1、B2 和 B3。
A 类与 B 类以不同的比例混合：1:0（所有 A 类）、2:1、1:2 和 0:1（所有 B 类）。
但这会产生一些奇怪的因子组合。例如...

A1_B1_1:0 实际上意味着混合中没有 B1。
A1_B1_1:0、A1_B2_1:0、A1_B3_1:0 彼此都是多余的。

我可以为“无”添加一个因子水平，但这样它就不会被定义为 2:1 或 1:2。
提前感谢您的帮助！
布莱恩]]></description>
      <guid>https://stats.stackexchange.com/questions/654919/doe-factors-and-factor-levels-for-blending-two-materials</guid>
      <pubDate>Wed, 25 Sep 2024 21:27:27 GMT</pubDate>
    </item>
    <item>
      <title>具有 G 幂分类预测因子的逻辑回归样本大小</title>
      <link>https://stats.stackexchange.com/questions/654915/logistic-regression-sample-size-with-categorical-predictor-in-g-power</link>
      <description><![CDATA[我想弄清楚 G 幂是否适合我的情况，以及我是否做对了。我希望计算先验样本量。
我即将使用注册数据进行队列研究，使用逻辑回归对疾病是/否进行二元结果分析。但是我的预测因子 (x) 有 3 个类别/组。据我所知，我应该“将这些视为”2 个变量（一个参考）。这些组也可能不均衡。
此外，我可能还有多达 7 个其他协变量。
我的问题：
使用 G 幂是否可行？如果可以……
当有 3 个不均匀组时，如何设置我的“x parm”？
即使预测因子有多个类别，x 分布仍然是二项式的？
解释协变量的唯一方法是使用“R2 其他 x”？或者有没有其他方法/应用程序可以做得更好？
在我的测试中，效果大小为 OR 1.27（我希望检测到 2% 的 ARR）。仍然是均等匹配的组。我需要 6703 名患者，似乎很高？或者由于差异如此之小，可能是正确的？对于 x 分布“正态”或“泊松”，样本量要低得多。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654915/logistic-regression-sample-size-with-categorical-predictor-in-g-power</guid>
      <pubDate>Wed, 25 Sep 2024 20:15:55 GMT</pubDate>
    </item>
    <item>
      <title>解释交叉表摘要</title>
      <link>https://stats.stackexchange.com/questions/654911/interpreting-cross-table-summary</link>
      <description><![CDATA[我正在生成一个简单的 2 x N 列联表，总结女性在 COVID-19 之前和期间/之后的就业状况。列代表两个时间段：1) COVID 之前和 2) COVID 期间/之后。
就业状况摘要如下：
就业状况 COVID 之前 COVID 期间/之后
缺失响应 41% 18.6%
失业（家庭主妇） 301 (8.8%) 443 (20%)
就业 1315 (49.9%) 1276 (61.4%)

数据显示，失业家庭主妇的百分比（从 COVID 之前的 8.8% 增加到 COVID 期间/之后的 20%）和就业女性的百分比（从 49.9% 增加到 61.4%）都有所增加。这似乎违反直觉，因为我们预计失业率上升与就业率下降同时发生。
我该如何解释这些结果？任何建议都非常感谢。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654911/interpreting-cross-table-summary</guid>
      <pubDate>Wed, 25 Sep 2024 19:58:04 GMT</pubDate>
    </item>
    <item>
      <title>识别时间序列的平衡点</title>
      <link>https://stats.stackexchange.com/questions/654909/identifying-equilibrium-point-of-a-time-series</link>
      <description><![CDATA[我正在对新产品发布进行分析，特别是新产品发布的生命周期是否随着时间的推移而发生变化。
我感兴趣的一个问题是，用于确定新产品何时达到平衡的统计方法。通常，对于每种新产品，我们都会看到最初的收入激增，最终达到某种平衡点。据我所知，大多数方法都需要知道平衡点是什么，而在这种情况下，我们不知道。
任何想法都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654909/identifying-equilibrium-point-of-a-time-series</guid>
      <pubDate>Wed, 25 Sep 2024 19:09:27 GMT</pubDate>
    </item>
    <item>
      <title>RA Fisher（或“Fisherian”）如何选择样本大小？</title>
      <link>https://stats.stackexchange.com/questions/654905/how-would-ra-fisher-or-a-fisherian-choose-sample-sizes</link>
      <description><![CDATA[正如许多其他 CV.SE 帖子（例如此处或此处）中所述，RA Fisher 和 Neyman &amp; Pearson 的统计假设检验框架在实践和解释上存在差异。
我很好奇他们在如何设计您的研究方面的差异。为了简单起见，我将重点关注样本量（但当然，功效和精度也会受到研究设计的其他方面的影响，例如阻塞等）。
在 N-P 框架下，一般方法对我来说很清楚：首先确定您想要的功效，您感兴趣的特定替代点假设 $H_A$（例如，就您想要检测的最小效应大小而言），以及您可以容忍的 I 类错误率 $\alpha$。从那里，您可以计算出实现 $\alpha$ 和 $H_A$ 所需功效所需的样本量。
但据我了解，在 Fisher 方法中，没有 $\alpha$、没有 $H_A$，也没有明确的功效计算。那么 Fisher 如何为自己的研究选择样本量？（或者他如何建议其他人规划样本量？）

我很好奇，尤其是因为 Fisher 确实写过“一个设计合理的实验”通常会产生较低的 p 值。

就我个人而言，作者更喜欢将显着性标准设定为 5%。点，并完全忽略所有未达到该水平的结果。只有当经过适当设计的实验很少失败时，科学事实才应被视为实验确定的。

-- Fisher, R. A. 田间实验的安排。《农业部期刊》，1926 年，33，第 504 页。
对我来说，这句 1926 年的引言（尤其是“很少失败”）听起来很像说精心设计的实验应该具有很高的功效：尽管他没有指定特定的$H_A$，但 Fisher 想象在相同的人群中重复使用相同设计的相同实验（尽管在这句话中，这些实验是否重复是假设的或应该实际执行的），并反复获得等于或低于 5% 显著性水平的结果。
如果 Fisher 同意设置显著性水平，并且 Fisher 也致力于实现高功效——那么他还能做什么来选择样本量来实现这些目标，同时又与 N-P 的整体方法有实质性的不同？
（当然，还有贝叶斯方法、似然法，也许还有其他非 Fisher 和非 NP 方法。但我特别想问的是，什么才算是 Fisher 但非 NP。）]]></description>
      <guid>https://stats.stackexchange.com/questions/654905/how-would-ra-fisher-or-a-fisherian-choose-sample-sizes</guid>
      <pubDate>Wed, 25 Sep 2024 18:08:15 GMT</pubDate>
    </item>
    <item>
      <title>用连续给定条件概率建模</title>
      <link>https://stats.stackexchange.com/questions/654900/modelling-conditional-probabilities-with-continuous-givens</link>
      <description><![CDATA[我目前正在努力解决这个方程式
$$ p(x; \theta) = P(Y = 1 | X = x) $$
其中 $p$ 是右侧条件概率的模型。如果 $X$ 是连续随机变量，那么这个方程式肯定没有意义。我们是否简单地将 $X$ 视为离散变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654900/modelling-conditional-probabilities-with-continuous-givens</guid>
      <pubDate>Wed, 25 Sep 2024 16:19:27 GMT</pubDate>
    </item>
    <item>
      <title>bfastlite 函数的参数调整</title>
      <link>https://stats.stackexchange.com/questions/654910/parameter-tuning-of-the-bfastlite-function</link>
      <description><![CDATA[我正在使用 bfast 包的 bfastlite() 函数来运行时间序列 (ts) 分析。我从作者的论文（表 2）中引用：

需要调整参数来优化性能，不区分季节性和趋势的中断

到目前为止，我一直在手动微调模型，也就是说，我一个接一个地更改参数，这很耗时。有人对模型的微调有更好的解决方案吗？
为了查看模型的哪些参数可以实现最佳结果，我检查了检测到的断点中的日期（目视检查）。
library(bfast)

plot(simts) # 包含模拟 NDVI 时间序列的 stl 对象
datats &lt;- ts(rowSums(simts$time.series))
# 所有组件的总和（季节、突变、剩余）
tsp(datats) &lt;- tsp(simts$time.series) # 分配正确的时间序列属性
plot(datats)

# 检测断点。默认参数
bp = bfastlite(datats)
plot(bp)

# 优化模型 ??????
bp_opt &lt;- bfastlite()

R 4.4.1，bfast 1.6.1，Windows 11。]]></description>
      <guid>https://stats.stackexchange.com/questions/654910/parameter-tuning-of-the-bfastlite-function</guid>
      <pubDate>Wed, 25 Sep 2024 14:48:51 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证不起作用[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654892/cross-validation-doesnt-work</link>
      <description><![CDATA[我目前在当地大学听一场数据科学演讲。我们是从工作单位来的，我从事 DS/ML 工作，已经 7 年了，但我的学位是计算机科学，因此我在 DS/ML 方面主要是自学的。
这个人告诉我们，DS 文章中写到的很多东西实际上都不起作用。
例如，他提到精确度、召回率和 F1 分数很少使用（相反，他更喜欢 AUC）。
但对我来说，另一个更古怪的事情是，交叉验证也不应该用于业务问题。他解释说它不起作用，因为它不代表现实生活。在现实生活中，你的目标不是预测数据分布中的随机样本，而是必须根据过去 x 年建立一个模型来预测未来 y 个月的数据。
所以他说交叉验证基本上是无用的，应该使用前向优化。
首先，它是如何工作的？它只用于验证还是也可以用于优化？怎么做？
此外，CV 真的那么没用吗？这是我读过的关于 DS 的任何文章中最被接受的验证形式。但也许这是我自学知识的不足之处。
还有什么关于很多事情的“神话”更高大上，但在现实生活中却不起作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/654892/cross-validation-doesnt-work</guid>
      <pubDate>Wed, 25 Sep 2024 12:55:02 GMT</pubDate>
    </item>
    <item>
      <title>使用缺失值的 Wilcoxon 符号秩检验</title>
      <link>https://stats.stackexchange.com/questions/654879/using-wilcoxon-signed-rank-test-with-a-missing-value</link>
      <description><![CDATA[我正在研究一个问题，我应该使用 Wilcoxon 符号秩检验，$9$ 个元素。第九对中的一个值缺失，我只知道它的结果为负数。我应该如何处理该值？我在网上找到了信息，“如果数据范围内有缺失值，则整个对将被排除在分析之外”，但在符号检验的情况下，我知道如果我们不知道最后一个条目但知道它的秩，我们仍然可以使用它。但在这种情况下，我们有配对结果，所以我不确定。我应该手动完成计算，而不是使用 R。
差异如下：$−7$, $−15$, $−1$, $−17$, $−10$, $−5$, $+11$, $−6$, $X_{9}&lt;0$。
我的猜测是，我可以将其省略，因为它是负数，并且与大多数 $X_{i}$ 值没有什么不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/654879/using-wilcoxon-signed-rank-test-with-a-missing-value</guid>
      <pubDate>Wed, 25 Sep 2024 07:34:40 GMT</pubDate>
    </item>
    <item>
      <title>3 种条件下刺激效果比较</title>
      <link>https://stats.stackexchange.com/questions/654875/comparing-stimulation-efficacy-under-3-conditions</link>
      <description><![CDATA[我有一个数据集，其中我比较了 3 种药物情况（药物 a、药物 b、药物 a+b），我的读数是培养皿中对药物有反应的细胞数量。




药物B-00mg
药物B-10mg
药物B-20mg
药物B-20mg




药物 A-00mg






药物A-10mg






药物 A-10mg






药物 A-10mg








因此，在每个培养皿中，我分别测试药物 A（第一列）和药物 B（第一行），以及在其他细胞中的鸡尾酒组合，总共 16 种情况（包括第一种不添加药物的情况）
我的读数是对药物治疗（这是一个在 0-50 之间变化的数字），我已经在 5 次生物重复中完成了此操作。
我想确定不同水平的药物 a+b 条件是否与仅药物 a 或仅药物 b 在统计上不同。
最好的测试形式是某种重复测量克鲁斯卡尔沃利斯法吗？
提前谢谢大家
编辑：更新了问题并提供了一个表格，希望能提供更清晰的信息]]></description>
      <guid>https://stats.stackexchange.com/questions/654875/comparing-stimulation-efficacy-under-3-conditions</guid>
      <pubDate>Wed, 25 Sep 2024 02:10:33 GMT</pubDate>
    </item>
    <item>
      <title>检验统计量适中，但 F 检验的 p 值较低</title>
      <link>https://stats.stackexchange.com/questions/654854/moderate-test-statistic-but-low-p-value-in-an-f-test</link>
      <description><![CDATA[我正在 R 中对模拟数据运行多元回归。样本大小为 100。有一个相关回归量和 18 个不相关回归量。我正在使用 Newey-West 协方差矩阵测试 18 个不相关回归量的联合显著性。
谜题 1：我发现 18 个不相关回归量具有高度统计显著性。
谜题 2：我在 18 自由度下获得了 6.8814 的检验统计量，这对我来说似乎是适中的（在 F(18, 80) 分布的右尾不远），那么这怎么会产生非常低的 p 值 4.5e-10？
我能够解决谜题 1。显然，Newey-West 是问题所在。使用 vanilla 协方差矩阵，结果更加合理。但是，我仍然对谜题 2感到困惑，而这是我的问题。
library(car)
library(sandwich)

m &lt;- 20
n &lt;- 100
set.seed(9999)
x &lt;- rnorm(m * n)
X &lt;- matrix(x, ncol = m)
X[, 2] &lt;- X[, 1] + X[, 2]
# 现在，第二列是第一列 + 一些噪音，
# 而所有其他列都是纯噪音。
# 因此，如果我们尝试预测第一列，那么只有第二列应该有用。
m1 &lt;- lm(X[, 1] ~ X[, -1])
(test &lt;- linearHypothesis(
model = m1,
hypothesis.matrix = (diag(m)[-c(1:2), ]),
rhs = rep(0, m - 2),
test = &quot;F&quot;,
vcov. = NeweyWest(m1)
))

结果：
线性假设检验

假设：

模型 1：受限模型

模型 2：X[, 1] ~ X[, -1]

注意：提供系数协方差矩阵。

Res.Df Df F Pr(&gt;F) 
1 98 
2 80 18 6.8814 4.494e-10 ***

不使用 Newey-West：

(test &lt;- linearHypothesis(
model = m1,
hypothesis.matrix = (diag(m)[-c(1:2), ]),
rhs = rep(0, m - 2),
test = &quot;F&quot;
))

结果：
线性假设检验

假设：

模型 1：受限模型
模型 2：X[, 1] ~ X[, -1]

Res.Df RSS Df Sq F 之和Pr(&gt;F)
1 98 38.856 
2 80 31.982 18 6.8739 0.9552 0.5178

编辑：感谢 Lukas Lohse 的精彩评论。当非正式地评估检验统计量的大小时，我考虑的是 $\chi^2$ 对 $F$ 分布的近似，但忘记了必须将 $F$ 值乘以分子自由度（此处为 18）才能得到相应的 $\chi^2$ 统计量... 好的，因此，我们现在有了新的 谜题 3，而不是 谜题 2：为什么使用 Newey-West 的检验使用 6.8 作为 $F$ 统计量，而使用普通方差估计量的检验使用平方和。]]></description>
      <guid>https://stats.stackexchange.com/questions/654854/moderate-test-statistic-but-low-p-value-in-an-f-test</guid>
      <pubDate>Tue, 24 Sep 2024 15:26:30 GMT</pubDate>
    </item>
    <item>
      <title>在我的背景下，合理处理 Wilcoxon 符号秩检验中的 0 和平局的方法</title>
      <link>https://stats.stackexchange.com/questions/654751/rational-way-of-handling-0s-and-ties-in-wilcoxon-signed-rank-test-in-the-backgro</link>
      <description><![CDATA[在讨论进行 Wilcoxon 符号秩检验时如何处理平局？的背景下，我有以下 2 个后续问题：
我有 52 个前后得分，其中有平局和 0，所以我使用了 coin 包，其中 ties_method = &quot;midrank&quot;，它运行完美，没有给我任何警告。从概念上讲，使用 midrank 是一个好的解决方案吗？
如果您的因变量是具有 1-4 个可能值的序数，并且您将其用作区间变量，则很可能会得到许多平局。在这种情况下，考虑到前后数据没有差异，你的结论是否合理？]]></description>
      <guid>https://stats.stackexchange.com/questions/654751/rational-way-of-handling-0s-and-ties-in-wilcoxon-signed-rank-test-in-the-backgro</guid>
      <pubDate>Mon, 23 Sep 2024 03:40:24 GMT</pubDate>
    </item>
    </channel>
</rss>