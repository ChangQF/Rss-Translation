<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 14 Apr 2024 11:19:27 GMT</lastBuildDate>
    <item>
      <title>如何为 GLM 找到合适的家庭</title>
      <link>https://stats.stackexchange.com/questions/644978/how-to-find-the-appropriate-family-for-a-glm</link>
      <description><![CDATA[我有我们在南极洲进行研究时关于巴布亚企鹅的行为数据。我正在观察两个不同地点的外部和内部巢穴的警惕性。
为了标准化警惕行为的计数，我将一项调查中警惕行为的数量除以调查的长度（最多 30 分钟）。所以现在我的因变量是每分钟警惕行为的数量。
因此，首先查看线性模型 lm(rate_per_min ~ 嵌套位置，data=gentoo_data) 不起作用，因为违反了假设。然后我尝试了转换，但也不起作用，所以我现在尝试 GML，但不确定使用哪个系列。
我不能使用毒药，因为它们不重要，因为它是一个比率。显然不是二项式，所以我想也许是伽玛，但我还没有遇到过这个。我留下了数据分布的图片，我会说它是双峰的？ 请有人解释一下要使用哪个系列以及为什么？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/644978/how-to-find-the-appropriate-family-for-a-glm</guid>
      <pubDate>Sun, 14 Apr 2024 10:46:27 GMT</pubDate>
    </item>
    <item>
      <title>利用 sem amos 模型技术研究影响消费者网上购物行为的因素</title>
      <link>https://stats.stackexchange.com/questions/644977/factors-effecting-on-consumer-online-shopping-behaviour-using-sem-amos-model-tec</link>
      <description><![CDATA[我有五个自变量、一个中介变量和一个因变量。检验后，一个自变量对中介变量不显着，因变量和中介变量对因变量也不显着。然后我排除对中介变量和因变量不显着的自变量。之后我观察了四个对中介变量和因变量显着的自变量。并且还有对因变量显着的中介变量。因此，有时中介变量对于因变量可能不显着。]]></description>
      <guid>https://stats.stackexchange.com/questions/644977/factors-effecting-on-consumer-online-shopping-behaviour-using-sem-amos-model-tec</guid>
      <pubDate>Sun, 14 Apr 2024 10:07:51 GMT</pubDate>
    </item>
    <item>
      <title>关于季节性是非平稳性的矛盾来源</title>
      <link>https://stats.stackexchange.com/questions/644975/contradictory-sources-on-seasonality-being-a-nonstationarity</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644975/contradictory-sources-on-seasonality-being-a-nonstationarity</guid>
      <pubDate>Sun, 14 Apr 2024 08:57:11 GMT</pubDate>
    </item>
    <item>
      <title>LMM 中交互项的不合理估计</title>
      <link>https://stats.stackexchange.com/questions/644972/unreasonable-estimate-in-lmm-with-interaction-terms</link>
      <description><![CDATA[在具有交互效应的 LMM 中，估计似乎不合理，因为 Score 的范围假设为 0-12。
lmer(分数 ~ 组 * 差异 * 年龄 + 性别 + (1|参与者)

观察 = 144，参与者 = 44

LMM 的假设通过performance 包进行检查，check_heteroscedasticity、check_normality 的p 值&gt;1。 .05.
 估计标准。误差df t值Pr(&gt;|t|)
（截距）-10.9589 4.8148 125.1071 -2.28 0.02454 *
差异 8.5475 2.4456 109.8640 3.50 0.00068 ***
年龄 0.2160 0.0651 127.6460 3.32 0.00119 **
第 1 组 44.1487 15.1913 132.4359 2.91 0.00429 **
性别2 -0.2846 0.8334 38.2347 -0.34 0.73456
差异：年龄 -0.1136 0.0335 110.8691 -3.39 0.00097 ***
差异：组 1 -21.4066 7.5641 116.2139 -2.83 0.00549 **
年龄：组1 -0.6079 0.2000 132.3486 -3.04 0.00285 **
差异：年龄：组 1 0.2932 0.0997 116.0751 2.94 0.00395 **

不太确定交互项是否可以使用 VIF 通过 check_collinearity 检查。
低相关性

           术语 VIF VIF 95% CI 增加 SE 耐受性 耐受性 95% CI
            年龄 2.72 [ 2.17, 3.54] 1.65 0.37 [0.28, 0.46]
         性别 1.02 [ 1.00, 16.24] 1.01 0.98 [0.06, 1.00]

高相关性

           术语 VIF VIF 95% CI 增加 SE 耐受性 耐受性 95% CI
           差异 82.97 [ 61.56, 111.95] 9.11 0.01 [0.01, 0.02]
          组 294.11 [217.84, 397.20] 17.15 3.40e-03 [0.00, 0.00]
       差异：年龄 85.69 [ 63.57, 115.62] 9.26 0.01 [0.01, 0.02]
     差异：组 389.33 [288.32, 525.85] 19.73 2.57e-03 [0.00, 0.00]
      年龄：组 291.55 [215.95, 393.75] 17.07 3.43e-03 [0.00, 0.00]
 差异：年龄：组 384.95 [285.08, 519.93] 19.62 2.60e-03 [0.00, 0.00]
]]></description>
      <guid>https://stats.stackexchange.com/questions/644972/unreasonable-estimate-in-lmm-with-interaction-terms</guid>
      <pubDate>Sun, 14 Apr 2024 07:54:33 GMT</pubDate>
    </item>
    <item>
      <title>仅对自变量进行一阶差分</title>
      <link>https://stats.stackexchange.com/questions/644969/only-first-differencing-the-independent-variable</link>
      <description><![CDATA[我故意不提供代码，因为这个问题更具概念性。
我正在尝试研究收入与再分配偏好之间的关系。我有一个面板数据集。
我可以简单地提出模型（1）：偏好= alpha + 收入 + e。
然而，我也对收入的变化而不是水平变量感兴趣。
在这种情况下，我可能会运行 (2) 偏好 = alpha + Δ收入 + e。
我的问题是，只对收入变量进行一阶差分可以吗？此外，包括 Δ收入与仅包括收入水平有什么不同吗？
因为即使模型（1）使用水平变量，它们也会随着时间的推移而变化，所以我现在有点困惑，如果我什至通过一阶差分收入得到不同的结果。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644969/only-first-differencing-the-independent-variable</guid>
      <pubDate>Sun, 14 Apr 2024 06:08:20 GMT</pubDate>
    </item>
    <item>
      <title>工业预测性维护</title>
      <link>https://stats.stackexchange.com/questions/644966/predictive-maintenance-in-industry</link>
      <description><![CDATA[我正在寻找工业机械和仪器（例如电机、泵、发电机）的预测性维护研究。我在网上得到的大多数东西都太通用了。我更喜欢一些 python/R 案例研究，例如关于零件失败的可能性等。
我查看了生存分析库（R 的survival，Python 的pysurvival），但没有与制造业直接相关。我觉得应该有更多相关内容，但我没有寻找正确的关键字。
拥有一些好的数据集也会有所帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/644966/predictive-maintenance-in-industry</guid>
      <pubDate>Sun, 14 Apr 2024 05:25:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在嵌套交叉验证中在整个外环训练集上训练模型？</title>
      <link>https://stats.stackexchange.com/questions/644965/how-to-train-a-model-on-the-whole-outer-loop-training-set-in-nested-cross-valida</link>
      <description><![CDATA[我正在为机器学习项目实施嵌套交叉验证，并且需要使用外循环训练集来明确训练过程。以下是我的流程摘要：

外循环分区：将数据拆分为多个训练集和测试集。
内循环划分：在每个外循环训练集中，进一步划分为训练集和验证集以优化超参数。
模型训练和评估：通过内循环确定最佳超参数后，模型将在整个外循环训练集上进行训练，然后在外循环测试集上进行评估。&lt; /里&gt;

我担心的是：

在训练深度学习模型等场景中，监控过度拟合至关重要，通常通过观察验证损失来完成。当模型在整个外环训练集上进行训练且缺乏单独的验证集时，如何管理这一问题？
同样，对于分类任务，确定决策的最佳阈值通常基于验证集性能。在最后的训练阶段如果没有单独的验证集，如何有效地设置这个阈值？

任何人都可以建议在嵌套交叉验证的背景下解决这些问题的策略或最佳实践吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/644965/how-to-train-a-model-on-the-whole-outer-loop-training-set-in-nested-cross-valida</guid>
      <pubDate>Sun, 14 Apr 2024 05:22:47 GMT</pubDate>
    </item>
    <item>
      <title>这种最大似然估计（MLE）场景可能吗？</title>
      <link>https://stats.stackexchange.com/questions/644964/is-this-maximum-likelihood-estimate-mle-scenario-possible</link>
      <description><![CDATA[我是一名统计新手，目前正在研究系统发育树的 ML 估计。我曾经有过这样的“哲学”经历自从我了解 MLE 方法以来，它就一直存在问题。本质上，考虑一下具有此类似然函数 $L(\theta)$ 的场景：

由于 MLE 方法将选择最大化 $L(\theta)$$\theta$ &gt;（即执行此操作的点），将选择右侧斑点上的点。然而，根据这个概率分布，很明显左侧斑点中的 $\theta$ 更能反映实际的 PDF，碰巧的是右侧较小的斑点有较大的峰值。我研究了 MLE 的问题，发现容易受到异常值的影响，但我不确定我在这里提出的场景是否属于其中任何一个。谁能向我解释一下这是否是 MLE 的实际缺点？
编辑：谢谢您的回答。我意识到我最初的问题也许应该更精确。令 $\theta_l$ 为局部最大化左侧斑点上 𝐿 的参数，并令 $\theta_r$是在右侧斑点上局部最大化 𝐿 的参数（即全局最大值）。现在，尽管 $\theta_r$ 确实为我们提供了一个比 $\theta_l$，$\theta_l$ 可能更能反映实际的基础分布，因为  $\theta_r$ 峰值可能只是一个偶然的异常现象。例如，请注意，右侧斑点可以具有任意小的面积，但仍然比左侧斑点高，这意味着即使范围 $[\theta_l - \epsilon, \theta_l + \ epsilon]$ 对于一个小的 $\epsilon &gt; 0$ 比 $[\theta_r - \epsilon, \theta_r + \epsilon]$ 捕获更高的基础分布比率，我们仍然会得到选择$\theta_r$。因此，我可以想象这样一个场景，其中我们的底层分布的实际参数是 $\theta_l$，但一些异常值或类似值导致参数 $\theta_r$ 具有异常高的峰值，尽管该参数根本不反映实际的基础分布。
TLDR：我们选择最大化点是一个问题并且不会选择
$$\tilde{\theta} = \text{argmax}_{\theta \in \mathbf{R}} \int_{\theta-\epsilon}^{\theta + \epsilon} L(x) dx$$
对于一些 $\epsilon &gt; 0$ 使 MLE 估计更好？]]></description>
      <guid>https://stats.stackexchange.com/questions/644964/is-this-maximum-likelihood-estimate-mle-scenario-possible</guid>
      <pubDate>Sun, 14 Apr 2024 05:17:19 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程的协方差反演</title>
      <link>https://stats.stackexchange.com/questions/644963/covariance-inversion-for-gaussian-process</link>
      <description><![CDATA[背景
让 $x=f(u_x)\in\mathbb{R}$ 并让 $y=[f (u_y^1)\cdots f(u_y^{N})]\in\mathbb{R}^N$ 对于某些函数 $f:u \in \ mathbb{R}\mapsto \mathbb{R}$。
给定 $y$、$u_x$、 $u_{y}^1,\dots, u_{y}^{N}$，我需要计算以下向量
\begin{方程*}
x = \Sigma_{xy}\,\Sigma_{y}^{-1} y
\end{方程*}
和以下矩阵
\begin{方程*}
P=\Sigma_x-\Sigma_{xy}\Sigma_y^{-1}\Sigma_{xy}&#39;
\end{方程*}
交叉协方差 $\Sigma_{xy}$ 和协方差 $\Sigma_y$ 来自包装内核
\begin{方程*}
k(u_1,u_2)\triangleq \sigma_1^2 \exp\left[-\frac{2 \sin^2 \left(\frac{|u_1-u_2|}{2}\right)}{\ell^2 }\右]+\sigma_2^2
\end{方程*}
其中 $\sigma_1, \ell, \sigma_2$ 被赋予超参数。
因此，互协方差 $\Sigma_{xy}\in\mathbb{R}^{1\times N}$ 由下式给出
\begin{方程*}
\Sigma_{xy}\triangleq\left[\begin{array}{ccc}
k(u_x,u_y^1) &amp; \cdots &amp; k(u_x, u_y^N)
\end{数组}\right]
\end{方程*}
协方差 $\Sigma_y \in \mathbb{R}^{N\times N}$ 由下式给出
\begin{方程*}
\Sigma_{y}\triangleq\left[\begin{array}{ccc}
k(u_y^{1},u_y^1) &amp; \cdots &amp; k(u_y^{1}, u_y^N) \\
\vdots&amp; \ddots &amp; \vdots \\
k(u_y^N, u_y^1) &amp; \cdots &amp; k(u_y^{N}, u_y^N) \\
\end{数组}\right]
\end{方程*}
问题
为简单起见，考虑以下情况
\begin{方程*}
u_y^j \triangleq \frac{2 \pi }{N-1} (j-1) \qquad j = 1,\dots,N
\end{方程*}
要修正这些想法，请考虑 $\sigma_1 \triangleq \sigma_2 \triangleq 2, \ell\triangleq \pi/4,$。从数字上看，当 $N$ 足够大时，例如 $N\triangleq 50$， $\Sigma$ 变得病态。特别是，有些特征值变负（但绝对值特别小），而另一些特征值则变大。
显然，这个事实听起来不太好，因为我必须计算 $x$ 和 $P$ -涉及 $\Sigma_y$ 反转的两个操作。
到目前为止，我缓解这种糟糕情况的简单解决方案是通过“人为”强化 $\Sigma_y$ 的对角线。引入一个术语 $\epsilon I_N$，即我计算 $x$ 和 $P$ 与“错误”方程
\begin{方程*}
\开始{对齐}
x &amp;= \Sigma_{xy} (\Sigma_y+\epsilon I_N)^{-1} \Sigma_{xy}&#39; \\
P &amp;= \Sigma_{x} - \Sigma_{xy} (\Sigma_y+\epsilon I_N)^{-1} \Sigma_{xy}&#39;
\结束{对齐}
\end{方程*}
这里 $I_N$ 是 $N\times N$ 单位矩阵，而 $\epsilon$ 是一个小的正标量（例如 $10^{-7}$）。
问题
我知道我的问题在高斯过程估计中并不少见。据我所知，建议的解决方案是避免 $\Sigma_y$ 的反转，而是利用其 Cholesky 分解。问题是我无法分解 $\Sigma_y$ 因为某些特征值不是严格正的。因此，目前我无法采用此解决方案。我有两个问题：

如何在不引入任何“人为失真”的情况下计算 $x$ 和 $P$在 $\Sigma_y$ 上？
假设 $f(\cdot)$ 是周期性的，且周期为 $\pi$，则为是否可以修改内核，使 $\Sigma_y$ 的调节完全没有问题？
]]></description>
      <guid>https://stats.stackexchange.com/questions/644963/covariance-inversion-for-gaussian-process</guid>
      <pubDate>Sun, 14 Apr 2024 05:07:58 GMT</pubDate>
    </item>
    <item>
      <title>对成本标准化的期望 预期改进</title>
      <link>https://stats.stackexchange.com/questions/644962/expectation-over-cost-normalized-expected-improvements</link>
      <description><![CDATA[如果我们假设 f(x) 和 C(x) 独立，下面两个表达式是否等价？
$$
E\left[\frac{E\left[\max\left(f(x) - f(x^*), 0\right)\right]} {C(x)}\right]
$$
$$
\frac{E\left[\max\left(f(x) - f(x^*), 0\right)\right]} {E\left[C(x)\right]}
$$
哪里
f(x) 和 C(x) 分别是目标函数和成本函数，$f(x^*)$ 是之前迭代中记录的最佳目标。]]></description>
      <guid>https://stats.stackexchange.com/questions/644962/expectation-over-cost-normalized-expected-improvements</guid>
      <pubDate>Sun, 14 Apr 2024 03:35:26 GMT</pubDate>
    </item>
    <item>
      <title>当 rpart 函数 xerror 值对不平衡数据成本敏感时，它看起来如何？</title>
      <link>https://stats.stackexchange.com/questions/644961/how-does-the-rpart-function-xerror-value-look-like-this-when-it-is-cost-sensitiv</link>
      <description><![CDATA[库(rpart)
库（应用预测建模）
数据（鲍鱼）
abi &lt;- 鲍鱼
abi$Rings &lt;- Factor((abi$Rings) &gt; 22, labels = c(&quot;L&quot;, &quot;H&quot;)) # 处理成占比悬殊的二类
摘要(abi$Rings)

设置.seed(2)
ctabi_1 &lt;- rpart(Rings ~ ., data = abi, method = “class”, cp = 0,
                   parms = 列表(损失 = 矩阵(c(0, 1, 10, 0), byrow = TRUE, nrow = 2)))
摘要(ctabi_1)

]]></description>
      <guid>https://stats.stackexchange.com/questions/644961/how-does-the-rpart-function-xerror-value-look-like-this-when-it-is-cost-sensitiv</guid>
      <pubDate>Sun, 14 Apr 2024 02:25:34 GMT</pubDate>
    </item>
    <item>
      <title>范围大于步长的滚动预测</title>
      <link>https://stats.stackexchange.com/questions/644949/rolling-forecasts-where-horizon-is-larger-than-step-size</link>
      <description><![CDATA[在预测范围大于步长的情况下执行滚动时间序列预测是否是一种不好的做法？例如，如果我有一个模型可以每天滚动生成每周预测，那么它每年会给出 365 次每周预测，而如果我的步长等于我的预测范围，则会给出 52 次预测。
一方面，每日预测可以为模型提供更多训练数据，但另一方面，误差将呈序列相关。
我无法对设置问题产生良好的直觉，并且希望获得有关如何构建问题/最佳实践的任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/644949/rolling-forecasts-where-horizon-is-larger-than-step-size</guid>
      <pubDate>Sat, 13 Apr 2024 19:17:51 GMT</pubDate>
    </item>
    <item>
      <title>如何解释带有记录 DV 的回归表？</title>
      <link>https://stats.stackexchange.com/questions/644967/how-to-interpret-a-regression-table-with-logged-dvs</link>
      <description><![CDATA[我正在写一篇研究论文，并使用 R 进行定量分析。我正在使用 OLS 回归，并且需要对因变量执行对数转换以实现线性，但是我不再理解我的回归表，希望有人可以帮助我解释它。
为了运行对数回归，我需要使用此代码过滤零，这也可以解释为什么我的结果看起来不同以及日志的效果：
删除零的代码
如果没有日志，它过去看起来像这样：

回归后，它看起来像这样：
]]></description>
      <guid>https://stats.stackexchange.com/questions/644967/how-to-interpret-a-regression-table-with-logged-dvs</guid>
      <pubDate>Sat, 13 Apr 2024 18:41:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 blme 避免 R 中混合模型中的奇异拟合 - 检查外行人的先验</title>
      <link>https://stats.stackexchange.com/questions/644923/avoid-singular-fits-in-mixed-models-in-r-with-blme-checking-laymans-priors</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644923/avoid-singular-fits-in-mixed-models-in-r-with-blme-checking-laymans-priors</guid>
      <pubDate>Sat, 13 Apr 2024 07:39:10 GMT</pubDate>
    </item>
    <item>
      <title>回归悖论</title>
      <link>https://stats.stackexchange.com/questions/644915/regression-paradox</link>
      <description><![CDATA[我必须使用两个二分自变量进行二元逻辑回归。
我发现自己面临着一个悖论，我不知道如何处理。
在完整的数据库中，我有 377 名 volo_1=1 患者的 21 名 (5.6%) 死亡患者，以及 2766 名 volo_1=0 患者的 86 (3.1%) 名死亡患者，volo_1 1vs 0 的 OR 1.84 预测死亡 1 vs 0 。
因此，volo_1 1 vs 0 预测死亡 1 vs 0 的 OR &gt;0，并且 volo_1=0 的死亡患者少于 volo_1=1 的死亡患者。
如果我将数据库替换为二分变量（RTS_cat2），我有两个新数据库，其中 volo_1 1 vs 0 预测死亡 1 vs 0 的 OR &lt;0，并且 volo_1=0 的死亡患者数量比死亡人数多volo_1=1 的患者。
怎么可能呢？
我该如何处理这个问题？
这是我有问题的数据：
&lt;前&gt;&lt;代码&gt;&gt; x &lt;- xtabs(~dead + 交互(volo_1, RTS_cat2), data = db)
&gt; X
     交互（volo_1，RTS_cat2）
死亡 0.0 1.0 0.1 1.1
    0 2485 283 195 73
    1 12 1 74 20

&gt;表（db$dead，db$volo_1）
   
       0 1
  0 2680 356
  1 86 21

&gt; full.model &lt;- glm(dead ~ volo_1 , data = db,family=binomial())
&gt;物流.显示(完整.模型)

逻辑回归预测死亡 1 vs 0
 
               OR(95%CI) P(Wald 检验) P(LR 检验)
volo_1: 1 vs 0 1.84 (1.13,3) 0.015 0.021
                                                       
对数似然 = -464.1848
观察次数 = 3143
AIC 值 = 932.3696

&gt; full.model &lt;- glm(morto ~ volo_1 + RTS_cat2 , data = db,family=binomial())
&gt;物流.显示(完整.模型)

逻辑回归预测死亡率
 
                 粗 OR(95% CI) 调整值OR(95%CI) P(Wald 检验) P(LR 检验)
volo_1：1 vs 0 1.84 (1.13,3) 0.72 (0.42,1.24) 0.24 0.232
                                                                                     
RTS_cat2：1 vs 0 74.68 (41.26,135.18) 78.49 (43.12,142.9) &lt; 0.001＜ 0.001
                                                                                     
对数似然 = -289.3289
观察次数 = 3143
AIC 值 = 584.6577


db_rts &lt;- db[ 其中(db$RTS_cat2==1), ]

&gt;表（db_rts$morto，db_rts$volo_1）
   
      0 1
  0 195 73
  1 74 20
&gt;
&gt; full.model &lt;- glm(morto ~ volo_1 , data = db_rts,family=binomial())
&gt;物流.显示(完整.模型)

逻辑回归预测 morto ：1 vs 0
 
               OR(95%CI) P(Wald 检验) P(LR 检验)
volo_1: 1 vs 0 0.72 (0.41,1.27) 0.256 0.249
                                                          
对数似然 = -206.6552
观察次数 = 362
AIC 值 = 417.3104

db_rts1 &lt;- db[ 其中(db$RTS_cat2==0), ]

&gt;表（db_rts1$morto，db_rts1$volo_1）
   
       0 1
  0 2485 283
  1 12 1
&gt;
&gt; full.model &lt;- glm(morto ~ volo_1 , data = db_rts1,family=binomial())
&gt;物流.显示(完整.模型)

逻辑回归预测死亡率
 
               OR(95%CI) P(Wald 检验) P(LR 检验)
volo_1: 1 vs 0 0.73 (0.09,5.65) 0.765 0.754
                                                          
对数似然 = -82.6736
观察次数 = 2781
AIC 值 = 169.3472

]]></description>
      <guid>https://stats.stackexchange.com/questions/644915/regression-paradox</guid>
      <pubDate>Fri, 12 Apr 2024 22:47:07 GMT</pubDate>
    </item>
    </channel>
</rss>