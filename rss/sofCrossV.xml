<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 10 Nov 2024 21:14:04 GMT</lastBuildDate>
    <item>
      <title>具有一般解释因素的预测校准</title>
      <link>https://stats.stackexchange.com/questions/657045/forecast-calibration-with-a-general-explanatory-factor</link>
      <description><![CDATA[我正在考虑对特朗普​​政府未来两年的执政情况做出一系列基于概率的预测。预测将是一系列命题，例如：

20% 的联邦将禁止堕胎。

这个想法是为了测试我的校准，即理想情况下，我的 20% 预测中的 20% 应该会实现，我的 50% 预测中的 50% 应该会实现，等等。
当我试图思考我的预测时，我很快遇到了一个潜在的问题，即所有预测都有一个共同的因素——我对 DJT 性格的评估。也许他最感兴趣的是赢得选举和获得掌声，在这种情况下，实施他的政策议程可能会几乎一事无成。或者他是一个有远见的人，之前被房间里的各种成年人所阻碍，而这些成年人这次不会在场。如果这种思路是正确的，那么我可能会在一个方向上完全出错，或者在另一个方向上完全出错。 （我觉得这会不公平地搞砸我的校准，因为我已经预见到了这个问题）。
我的问题是，是否有人对我如何将这个共同因素整合到我的预测集中有什么建议？
我的第一个想法是指定每个预测与这个因素的关系，如果一个预测成真，那么将增加所有其他预测的概率（每个命题指定的某个量）。当我试图找出如何做到这一点的细节时，不幸的是我被卡住了。有人对我如何做到这一点有什么建议吗？或者可以告诉我有人做过类似的事情吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657045/forecast-calibration-with-a-general-explanatory-factor</guid>
      <pubDate>Sun, 10 Nov 2024 20:44:40 GMT</pubDate>
    </item>
    <item>
      <title>有一个与用作随机效应的变量重叠的预测因子可以吗？</title>
      <link>https://stats.stackexchange.com/questions/657042/would-it-be-okay-to-have-a-predictor-that-overlaps-with-the-variable-used-as-a-r</link>
      <description><![CDATA[我将使用基于国家紧密度指数（数字）的预测因子，因此每个国家都有一个值。我将在 50 个国家/地区收集数据，但我预计不同国家/地区的参与者数量会有很大差异（预计每个国家/地区的最低参与者数量为 100 名）。
因此，我正在考虑将国家/地区添加为随机效应（因子）。但大多数国家/地区都有独特的预测因子值，其中五个国家/地区的紧密度得分相同。
我担心这可能会使模型变得奇异或扰乱结果，假设国家/地区的随机效应最终可能会吞噬预测因子的大部分可变性。这是我应该担心的事情吗？ （我还没有数据，但我知道结果变量将是二分的）。
数据预期结构示例：
participant_id consequence_variable tightness country 
x01 1 -0.2 USA 
x01 0 -0.2 USA 
x01 0 -0.2 USA 
x01 1 -0.2 USA 
x02 1 -0.2 USA 
x02 1 -0.2 USA 
x02 0 -0.2 USA 
x02 1 -0.2 USA 
x03 1 0.3 UK 
x03 1 0.3 UK 
x03 1 0.3 UK 
x04 0 0.5 FR 
x04 1 0.5 FR 
x04 1 0.5 FR
x04 0 0.5 FR 

预期模型：
glmer(outcome_variable ~ tightness + (1 | contestant_id) + (1 | country), data, family=binomial)]]></description>
      <guid>https://stats.stackexchange.com/questions/657042/would-it-be-okay-to-have-a-predictor-that-overlaps-with-the-variable-used-as-a-r</guid>
      <pubDate>Sun, 10 Nov 2024 18:48:49 GMT</pubDate>
    </item>
    <item>
      <title>经济学教科书数据科学建议</title>
      <link>https://stats.stackexchange.com/questions/657037/data-science-for-economics-textbook-suggestion</link>
      <description><![CDATA[我正在寻找一本经济学研究生学位课程的数据科学课程教科书。它必须基于 Python 并包含大量示例。我会很感激任何建议。
当然，经济学研究生学位课程已经包含统计、回归、时间序列、面板、机器学习、一些使用 R 和 Stata 的编程；以及大量的经济学课程。所以，我认为数据科学课程应该像学生已经知道的知识的应用加上良好的数据处理和可视化措施。]]></description>
      <guid>https://stats.stackexchange.com/questions/657037/data-science-for-economics-textbook-suggestion</guid>
      <pubDate>Sun, 10 Nov 2024 16:15:28 GMT</pubDate>
    </item>
    <item>
      <title>假设检验的 p 值</title>
      <link>https://stats.stackexchange.com/questions/657034/p-values-for-hypothesis-testing</link>
      <description><![CDATA[直观地讲，标准假设检验（其中检验统计量呈正态分布或近似正态分布）中的 p 值被认为是“在假设零假设成立的情况下，观察到至少与统计学家观察到的值一样极端的值的概率”。
我的问题来自“至少一样极端的部分”。这是由于使用了检验统计量的值的 CDF 的补集。这意味着我们正在考虑我们没有观察到的检验统计量的其他更极端（且不相关）的值。为什么使用检验统计量的 pdf 还不够？我担心在拒绝零假设时，我们正在考虑与特定检验无关的极端值。]]></description>
      <guid>https://stats.stackexchange.com/questions/657034/p-values-for-hypothesis-testing</guid>
      <pubDate>Sun, 10 Nov 2024 15:42:55 GMT</pubDate>
    </item>
    <item>
      <title>显示两个变量在数年内变化的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/657033/best-way-to-display-two-variables-changing-over-the-span-of-a-number-of-years</link>
      <description><![CDATA[我试图在 y 轴上显示某个城市的中位租金及其人口，x 轴上显示年份。
我的第一反应是使用气泡图，其中 y 轴对应人口，x 轴对应年份，每个气泡的体积与中位租金相关。但这在视觉上模糊了人口与年份的关系。
有没有更好的方法可以做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/657033/best-way-to-display-two-variables-changing-over-the-span-of-a-number-of-years</guid>
      <pubDate>Sun, 10 Nov 2024 15:26:18 GMT</pubDate>
    </item>
    <item>
      <title>95％置信区间的错误解释？[重复]</title>
      <link>https://stats.stackexchange.com/questions/657032/false-interpretation-of-95-confidence-interval</link>
      <description><![CDATA[免责声明：我来自科学背景，最近开始攻读统计学硕士学位，所以我目前的统计知识来自大学入门课程和偶尔的 MOOC。
我对我的教授在线性模型课上给出的 95% 置信区间的解释感到困惑：

...
因此，$\beta_1$ 的 95% 置信区间变为 $[0.376,0.640]$。因此，我们以 95% 的概率
预计回归系数 $\beta_1$ 介于 $0.376$ 和 $0.640$ 之间。 ...

这实际上是课程笔记中使用的标准公式 - 对我来说，这似乎是观察到的置信区间的臭名昭著的概率解释，还是我在这里错过了一个概念或细微差别？]]></description>
      <guid>https://stats.stackexchange.com/questions/657032/false-interpretation-of-95-confidence-interval</guid>
      <pubDate>Sun, 10 Nov 2024 15:08:11 GMT</pubDate>
    </item>
    <item>
      <title>对图像集的平均值进行标注</title>
      <link>https://stats.stackexchange.com/questions/657030/captioning-an-average-of-image-set</link>
      <description><![CDATA[我正在寻找一个能够用一个句子描述一组图像的字幕模型。或者，我需要一种方法来概念性地平均一组图像，然后再将该“概念”（可能是特征向量）提供给常规字幕模型。
为什么？
用于 Lora 训练评估。在适合整个数据集的提示上测试训练后的生成模型会很有用，而不是选择单个图像的字幕或尝试找出它们之间的共同点。此外，这还允许生成单个负面提示来测试模型在范围外的提示上的表现。
我到目前为止所做的：
我已经修改了现有的 CLIP+BLIP 询问器以处理图像集（它也可以生成负片）。然而，虽然 CLIP 字幕允许在使用图像特征选择最佳字幕之前对其进行平均，但它的准确性远低于 BLIP 生成的字幕，后者仅适用于单幅图像。我需要一个可以像 CLIP 一样接收特征向量的模型，这样我就可以对它们进行预处理。]]></description>
      <guid>https://stats.stackexchange.com/questions/657030/captioning-an-average-of-image-set</guid>
      <pubDate>Sun, 10 Nov 2024 14:15:55 GMT</pubDate>
    </item>
    <item>
      <title>具有时不变主变量的面板数据中的固定效应与随机效应</title>
      <link>https://stats.stackexchange.com/questions/657025/fixed-effects-vs-random-effects-in-panel-data-with-a-time-invariant-main-variab</link>
      <description><![CDATA[我正在处理面板数据并计划使用固定效应模型。但是，我感兴趣的主要变量是时不变的，我无法将其包含在固定效应模型中。
我有两个问题：

改用随机效应模型是否合适？我是否应该先进行豪斯曼检验以确定随机效应是否合适？

如果我需要运行豪斯曼检验，我不确定如何进行，因为我无法创建两个相同的模型进行比较（固定效应与随机效应），因为固定效应模型忽略了时不变变量。我应该如何解决这个问题？


谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657025/fixed-effects-vs-random-effects-in-panel-data-with-a-time-invariant-main-variab</guid>
      <pubDate>Sun, 10 Nov 2024 12:18:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么在随机过程的自相关函数中，两个随机变量乘积的期望给出了它们之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/657024/why-in-auto-correlation-function-of-random-process-the-expectation-of-product-o</link>
      <description><![CDATA[为什么在随机过程的自相关函数中，两个随机变量乘积的期望会给出它们之间的相关性
我理解皮尔逊公式会给出相关性：#rₓ(t1, t2) = cov[x(t1), x(t2)] / [σₓ(t1) * σₓ(t2)];
但在很多地方，他们用以下公式定义自相关性：#rₓ(t1, t2) = e[x(t1).x̄(t2)];
为什么后者会给出不同时间点的随机过程之间的相关性？]]></description>
      <guid>https://stats.stackexchange.com/questions/657024/why-in-auto-correlation-function-of-random-process-the-expectation-of-product-o</guid>
      <pubDate>Sun, 10 Nov 2024 12:08:35 GMT</pubDate>
    </item>
    <item>
      <title>审稿人对基线分析的疑问</title>
      <link>https://stats.stackexchange.com/questions/657021/reviewer-s-questions-about-the-baseline-analysis</link>
      <description><![CDATA[研究背景：
我进行了一项临床研究，以探索变量 A 与心脏病发病率之间的相关性，样本量为 4,000 人。使用四分位数法将样本分为四组（Q1-Q4）。在基线分析期间，对于连续变量，我应用了基于正态或偏态分布的 Kruskal-Wallis H 检验，对于分类变量，我使用了卡方检验。这些检验的 p 值均小于 0.001。
审稿人的顾虑：
审稿人提出了以下顾虑：“在 A 的 Q1-Q4 四分位数中，所有个体的基线特征均存在显著差异（P&lt;0.001）。因此，这些亚组中 CVD 风险因素的表示似乎存在很大的初始偏差。”
问题：
1.我应该如何回应审稿人的评论？
2.我是否应该考虑改变我的统计方法，或者这些方法是否适合解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/657021/reviewer-s-questions-about-the-baseline-analysis</guid>
      <pubDate>Sun, 10 Nov 2024 06:49:47 GMT</pubDate>
    </item>
    <item>
      <title>对于一个比例的单侧置信区间和单侧假设检验的结果相反吗？</title>
      <link>https://stats.stackexchange.com/questions/657016/opposite-results-between-one-side-confidence-interval-and-one-side-hypothesis-te</link>
      <description><![CDATA[我正在尝试 PennState STAT 415 中的一个例子（示例 9-2）

方法 1：右尾假设检验

简而言之，观察到的样本比例为 $\hat{p}=\dfrac{104}{590}=0.176$。零假设为 $H_0 \colon p_0 = 0.14$，备择假设为 $H_A \colon p &gt; 0.14$。显著性水平为 $\alpha = 0.01$，因此临界区域为 $ &gt; 2.326$。计算检验统计量 $Z$ 后，即 $2.52$ ($=\dfrac{0.176-0.14}{\sqrt{\dfrac{0.14(0.86)}{590}}}$，由于 $2.52 &gt; z_{0.01}$，因此拒绝零假设。这意味着真实比例大于$0.14$。

方法 2：样本比例的单侧置信区间
$\hat{p}$

未知真实$p$（方法 1 中不一定是$p_0$）的单侧置信区间（下限为无穷大）的公式为：$[\hat{p}-z_{\alpha} \sqrt{\dfrac{\hat{p}(1-\hat{p})}{n}}, +\infty)$，即：$p \geq 0.176 - 2.326\times\sqrt{\dfrac{0.176(0.824)}{590}} = 0.1395$。因为假设的真实$p$（$0.14$）在$[0.1395, +\infty)$区间内，我们不能说样本比例意味着更大的真实比例。这与方法1得出的结论相反。
为什么两种方法得出的结论相互矛盾？]]></description>
      <guid>https://stats.stackexchange.com/questions/657016/opposite-results-between-one-side-confidence-interval-and-one-side-hypothesis-te</guid>
      <pubDate>Sun, 10 Nov 2024 03:11:42 GMT</pubDate>
    </item>
    <item>
      <title>贝塔回归中的置信区间</title>
      <link>https://stats.stackexchange.com/questions/656994/confidence-intervals-in-beta-regressions</link>
      <description><![CDATA[我在研究中使用混合效应 beta 回归模型，因为我的值介于 0 和 1 之间。当我使用线性混合效应模型运行相同的分析时，我得到了类似的结果（预测因子具有相同的方向并且很重要）。在线性模型中，置信区间保持在数据范围内（即没有负值或大于 1 的值），这使得它们易于解释。虽然效果很重要，但置信区间表明效果大小较小，我想报告这一点。
但是，从我读到的内容来看，beta 回归更适合我的数据。我可以报告 beta 回归模型的置信区间，但有没有办法转换它们以便于解释？此外，beta 回归中是否有类似于效果大小的指标？]]></description>
      <guid>https://stats.stackexchange.com/questions/656994/confidence-intervals-in-beta-regressions</guid>
      <pubDate>Sat, 09 Nov 2024 16:10:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的条件推理树与随机森林如此不同？</title>
      <link>https://stats.stackexchange.com/questions/656938/why-is-my-conditional-inference-tree-so-different-from-my-random-forest</link>
      <description><![CDATA[我正在使用条件推理树和随机森林分析数据集，使用的是 R 包 partykit（v. 1.2.20）。对于我的因变量（响应可能性），树和森林产生的解决方案非常不同，这使得它们都很难解释。我该如何理解这里发生了什么？
下面是我的代码以及树和森林的图像。如有必要，我可以共享数据集。
set.seed(2356)
library(partykit)

&gt; head(s1_images_response_item[,-2])
# A tibble：6 × 14
# 组：item [6]
item category response_mean_img causation colourful familiarity grow intent
&lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 飞机 移动臂… 1 3.25 2.57 4.4 1 1.29
2 藻类 植物 趣味… 0.887 2.44 3.57 2.1 4.14 1.06
3 羚羊 动物 0.981 4.25 2.79 3.85 4.77 3.53
4 自行车 移动臂… 1 2.12 2.64 4.65 1.05 1.12
5 船 移动臂… 0.981 3.19 2.64 3.65 1 1 
6 巨石 不动… 0.943 1.88 1.5 3 1.45 1.18
# ℹ 6 个其他变量：交互 &lt;dbl&gt;、运动 &lt;dbl&gt;、自然&lt;dbl&gt;,
# 感知 &lt;dbl&gt;, 重现 &lt;dbl&gt;, 提示 &lt;chr&gt;

条件推理树：
tree1.i.h &lt;- ctree(response_mean_img ~ 因果关系 + 意图 + 
交互 + 运动 + 感知 + 熟悉度 + 自然 + 
生长 + 重现 + 多彩, data=s1_images_response_item)

plot(tree1.i.h, terminal_panel = node_boxplot(tree1.i.h,id=T),
inner_panel = node_inner(tree1.i.h,id=F, pval = F), 
edge_panel = edge_simple(tree1.i.h, digits = 2))

--&gt;熟悉度是唯一重要的预测因素：

随机森林：
f1.i.h &lt;- cforest(response_mean_img ~ causation + intent + 
interaction + movement + perception + familiarity + natural + 
grow + reproduce + colourful, data=s1_images_response_item, 
ntree = 1000)

f1.i.h.varimp &lt;- varimp(f1.i.h)

dotchart(sort(f1.i.h.varimp,decreasing = F), 
main = &quot;研究 1B 试验的变量条件重要性响应性”）

--&gt; 预测因子交互、再现、感知和因果关系都具有比熟悉度更高的条件重要性值：

为什么交互、再现、感知和因果关系都没有出现在树中？]]></description>
      <guid>https://stats.stackexchange.com/questions/656938/why-is-my-conditional-inference-tree-so-different-from-my-random-forest</guid>
      <pubDate>Fri, 08 Nov 2024 02:26:03 GMT</pubDate>
    </item>
    <item>
      <title>变分自动编码器 - 手工制作的示例</title>
      <link>https://stats.stackexchange.com/questions/656806/variational-autoencoders-handcrafted-example</link>
      <description><![CDATA[在学习变分自动编码器 (VAE) 时，我想提出一个手工制作的小例子来帮助彻底理解它们。为此，假设我知道我的样本来自五维高斯$\mathbf{X}=(X_1,\dots,X_5)$，其中$X_2\sim\mathcal{N}(1,1)$和$X_5\sim\mathcal{N}(-1,4)$是独立的，并且$X_1=X_2$，$X_3=X_5$和$X_4=X_2+X_5$。进一步假设我们即将学习的 VAE 具有两个潜在维度。在这种情况下（如果我错了请纠正我），我预计潜在空间$\mathbf{Z}$实际上只是二维高斯$(X_2,X_5)$，因为观测数据中的所有其他随机变量完全依赖于这两个变量，并且它们是独立的。
$\textbf{Question(s) (1):}$我是否正确地认为，给定一些样本$\mathbf{x}=(x_2,x_5)$，我们理想情况下会得到$\mathbf{Z}|\mathbf{x}$只是$(x_2,x_5)$本身？例如，一个学习良好的编码器是否会产生一些结果，当从非常接近$(x_2,x_5)$的样本中进行采样时？
我不确定，因为我认为$\mathbf{Z}|\mathbf{x}$应该是一个分布，并且为了“保证”输出$(x_2,x_5)$，我们可能需要类似$p(\mathbf{z}|\mathbf{x})=\delta(z_1-x_2)\delta(z_2-x_5)$的东西，其中$\delta$是狄拉克函数。我对这里的严格细节有点困惑，所以非常感谢您的帮助。
$\textbf{问题 (2):}$ 在实践中，我理解 $\mathbf{Z}|\mathbf{x}$ 由某个正态分布近似，其参数由某个神经网络（编码器）输出。我想在这种情况下，一个“好的”编码器输出一个正态分布的参数是有意义的，该正态分布的均值以 $(x_2,x_5)$ 为中心，协方差矩阵是对角线，对角线元素相对较小（例如 $0.01$ 左右）。这种直觉是否正确，是否符合学习编码器在实践中的表现？
$\textbf{Note:}$ 在我的屏幕上，正态分布的“\mathcal{N}”显示为方框。如果读者您也遇到同样的情况，请知道每个方框实际上都是与正态分布有关的通常“N”符号。]]></description>
      <guid>https://stats.stackexchange.com/questions/656806/variational-autoencoders-handcrafted-example</guid>
      <pubDate>Tue, 05 Nov 2024 21:59:13 GMT</pubDate>
    </item>
    <item>
      <title>时间相关效应：使用 coxph() 中的 nsk() 的 tt 函数</title>
      <link>https://stats.stackexchange.com/questions/656611/time-dependent-effects-tt-function-using-nsk-in-coxph</link>
      <description><![CDATA[我使用 coxph() 比较三种处理方法（大、小、对照）之间的树苗存活率数据。然而，coxzph() 显示小处理方法的系数随时间而变化。为了解决这个问题，我在 coxph () 中添加了一个 tt(Small)，并使用 nsk() 来实现回归样条，并且我正在使用指示变量进行治疗。
我的问题是，当使用 tt() 和 nsk() 时，系数是如何解释的，特别是对于时间相关变量？
以下是模型输出。
cox.tt4 &lt;- coxph (Surv (no.yrs.alive, censor) ~ Large + Small +
tt(Small) + frailty (Line), data = spruce.complete,
tt = function (x,t,...) x*nsk(t, knots = c(3)))
summary(cox.tt4)
## 调用：
## coxph(formula = Surv(no.yrs.alive, censor) ~ Large + Small + 
## tt(小) + frailty(Line), 数据 = spruce.complete, tt = function(x, 
## t, ...) x * nsk(t, knots = c(3)))
## 
## n= 96, 事件数= 35 
## 
## coef se(coef) se2 Chisq DF p 
## 大 -2.520 0.7409 0.7396 11.57 1.00 0.00067
## 小 -3.427 1.2067 1.2065 8.07 1.00 0.00450
## tt(小)1 3.056 1.7592 1.7585 3.02 1.00 0.08200
## tt(小)2 3.183 1.4072 1.4061 5.12 1.00 0.02400
## frailty(Line) 6.24 2.33 0.06000
## 
## exp(coef) exp(-coef) lower .95 upper .95
## Large 0.08044 12.43122 0.018830 0.3436
## Small 0.03249 30.77809 0.003052 0.3458
## tt(小)1 21.23826 0.04708 0.675532 667.7166
## tt(小)2 24.12159 0.04146 1.529754 380.3560
## gamma:L1 1.06620 0.93791 0.575824 1.9742
## gamma:L2 0.59206 1.68903 0.283618 1.2359
## gamma:L3 1.27464 0.78454 0.713532 2.2770
## gamma:L5 1.39426 0.71722 0.780017 2.4922
## gamma:L6 0.67284 1.48624 0.326825 1.3852
## 
## 迭代次数：6 外部，22 Newton-Raphson
## 随机效应方差 = 0.1925677 I-似然 = -134.1 
## 项的自由度 = 1.0 1.0 2.0 2.3 
## 一致性 = 0.813 (se = 0.041 )
## 似然比检验 = 44.22 on 6.32 df, p=9e-08

时间相关的 Therneau 等人。 2024 插图第 4.2 节指出“系数是节点 2、3 处的预测值，... - 节点 1 处的预测值”。
在这种情况下，这是否意味着第一个时间段（时间 0 到时间 3）的小治疗系数将是 -3.427 + 3.056 = -0.371？而对于第二个时间段（&gt;时间 3），-3.427 + 3.056 = -0.244？
此外，我可以对这些系数取指数来计算相对于参考治疗的风险比，两个时间段的风险比不同吗？
我对这种方法还不熟悉，非常感谢任何见解或建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/656611/time-dependent-effects-tt-function-using-nsk-in-coxph</guid>
      <pubDate>Fri, 01 Nov 2024 20:17:45 GMT</pubDate>
    </item>
    </channel>
</rss>