<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Tue, 11 Mar 2025 18:25:30 GMT</lastBuildDate>
    <item>
      <title>在临床试验中有效使用多个基线观测</title>
      <link>https://stats.stackexchange.com/questions/662490/efficient-use-of-multiple-baseline-observations-in-clinical-trial</link>
      <description><![CDATA[在一个假设的临床试验中，我对每个参与者进行了多次治疗预测。利用这对观测值以最大化检测对嘈杂结果的真正影响的能力的最佳方法是什么？具体来说，以下是首选吗？
结果〜Arm + Baseline_mean 
 vs。
结果〜ARM +基线_1 +基线_2 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662490/efficient-use-of-multiple-baseline-observations-in-clinical-trial</guid>
      <pubDate>Tue, 11 Mar 2025 17:45:22 GMT</pubDate>
    </item>
    <item>
      <title>测试统计量用于确定从PCA获得的3个氨基酸序列中计算出的属性/特征是否显着差异</title>
      <link>https://stats.stackexchange.com/questions/662489/test-statistic-for-determining-if-a-calculated-property-feature-is-significantly</link>
      <description><![CDATA[因此，我正在分析特定蛋白质中几种生物体（〜700）中的IDR（本质上无序区域）氨基酸序列，并计算了通常使用Localcider软件包计算出针对IDR计算的几个功能。我使用这些功能执行PCA并观察3个簇。我获得了每个群集中的序列（称为群集1，群集2和群集3），它们具有不相等的序列（群集1：200序列，群集2：300和群集3：80）。我想知道可以使用统计测试或统计量是否可以确定三个簇中给定特征是否存在显着差异，哪些簇显示出这种差异。
注意：由于这些特征是生物序列，因此当氨基酸序列相似时（在这种情况下是这种情况），因此特征值往往相同。序列不完全相同，因此为什么PCA基于计算的所有功能形成3个不同的簇。另外，由于PCA需要标准化才能使特征处于相同的比例，因此根据所有序列（700）将A属性归一化]]></description>
      <guid>https://stats.stackexchange.com/questions/662489/test-statistic-for-determining-if-a-calculated-property-feature-is-significantly</guid>
      <pubDate>Tue, 11 Mar 2025 17:44:34 GMT</pubDate>
    </item>
    <item>
      <title>r plm（）还是feols（）？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/662485/r-plm-or-feols</link>
      <description><![CDATA[我正在用相同的数据来喂食这两个功能，但输出不同，我感到困惑为什么会发生这种情况。我知道这两个功能都以不同的方式处理固定效果，但理想情况下，这两个功能都必须产生相同的结果。这是代码：
  model_plm＆lt;  -  plm（
  log（收入）〜x +因子（二_year_fe），
  data = pdata，
  型号=&#39;
）

model_feols＆lt;  -  feols（
  log（收入）  
  SE =“标准”
  数据= PDATA
）
 
为了说明，我可以显示PLM的X估计值为-4.071065E-05，而在feols中为7.739554e-04。
在这种情况下，这是单位和时间的固定效果的最佳功能？]]></description>
      <guid>https://stats.stackexchange.com/questions/662485/r-plm-or-feols</guid>
      <pubDate>Tue, 11 Mar 2025 15:36:12 GMT</pubDate>
    </item>
    <item>
      <title>GLMM用于不平衡数据 - 我需要预先加权的数据吗？</title>
      <link>https://stats.stackexchange.com/questions/662483/glmm-for-unbalanced-data-do-i-need-pre-weighted-data</link>
      <description><![CDATA[我正在使用GLMM进行睡眠研究，因为它可以很好地处理丢失的数据和不同的观察长度。我的数据是不平衡的，因为这是一项现场研究，而不是受控的实验室设置。
偏移情况在受试者之间和受试者之间有所不同，与后（约1周）相比，我们的相期（约3周）更长。
我们在前研究前设计的两组（对照/干预）之间测量了9个班次情况：
预防前：437，干预前：425
控制后：191，干预后：210
每次/组分层的所有情况至少记录了15次，除了一个只有5个记录的情况。
卡方检验显示出明显的失衡（x²（24）= 70.02，p＆lt; .001）。我根据此参考 https://api.istex.fr/ark:/67375/wng-dq4bgh16-p/fulltext.pdf?auth=ip = ip = ip.p.fede&amp;；
 glmm（lmer（sleep_variable〜时间 * group + shift_situation +（1 |主题））已经解释了此不平衡，还是我需要使用加权睡眠数据来提高数据质量？]]></description>
      <guid>https://stats.stackexchange.com/questions/662483/glmm-for-unbalanced-data-do-i-need-pre-weighted-data</guid>
      <pubDate>Tue, 11 Mar 2025 15:16:14 GMT</pubDate>
    </item>
    <item>
      <title>分位数回归的效果大小</title>
      <link>https://stats.stackexchange.com/questions/662482/effect-size-for-quantile-regression</link>
      <description><![CDATA[应该如何计算分位数回归的效果大小？
 Cohen D的公式取决于汇总的标准偏差，这取决于样本量（明确和通过单独的样本标准偏差）。
也许这是一个愚蠢的问题，但是用于分数回归的适当样本量和标准偏差是什么？  我对此感到困惑，因为与沼泽标准的值相比，估计有条件的分位数似乎是一种有趣的动物。
我应该准确地使用样本量和样本标准偏差的最普通值吗？  还是由于分位数而有不同的游戏？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/662482/effect-size-for-quantile-regression</guid>
      <pubDate>Tue, 11 Mar 2025 14:22:44 GMT</pubDate>
    </item>
    <item>
      <title>我对蒙特卡洛模拟的理解是正确的吗？ （外行术语）</title>
      <link>https://stats.stackexchange.com/questions/662476/is-my-understanding-correct-about-monte-carlo-simulation-layman-terms</link>
      <description><![CDATA[我有时会在心理学期刊上遇到蒙特卡洛模拟一词。我不是一个统计书呆子，更像是统计用户，因此，即使阅读了相当数量的材料，我仍然对它的运作方式有些困惑。
假设我收集了400名研究参与者，并将他们的数据输入到统计软件中。统计软件将尝试推断这400名参与者的数据，并想象我设法收集了1000或5000名参与者的数据。我对蒙特卡洛模拟的理解是否正确？
另外，统计软件如何进行仿真过程？我收集了来自400名研究参与者的5个变量的数据。统计软件是否试图检测模式？从这种模式来看，如果我设法收集1000或5000名参与者，它将尝试推断人们如何填写问卷？如果我收集5或6个变量，结果会有所不同吗？
如果我的理解是正确的，是否需要这种统计分析？还是夸张的统计复杂形式？我仍然不确定我们是否需要模拟从10.000参与者那里收集数据的感觉。
对不起，如果这个问题非常业余。我试图理解其背后的逻辑。]]></description>
      <guid>https://stats.stackexchange.com/questions/662476/is-my-understanding-correct-about-monte-carlo-simulation-layman-terms</guid>
      <pubDate>Tue, 11 Mar 2025 13:39:24 GMT</pubDate>
    </item>
    <item>
      <title>使用Engle和Granger重叠数据</title>
      <link>https://stats.stackexchange.com/questions/662473/using-engle-and-granger-for-overlapping-data</link>
      <description><![CDATA[带重叠数据的 ols倾向于夸大 $ r^2 $ 和 $ t $  stats在很大程度上是由于残留物中的自相关。同样的增长率，PMI不是我（1），但它们也不是我（0）。我们还能在残留物中进行OLS并测试单位根吗？然后在实施Engle-Granger方法时使用传统测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/662473/using-engle-and-granger-for-overlapping-data</guid>
      <pubDate>Tue, 11 Mar 2025 13:03:38 GMT</pubDate>
    </item>
    <item>
      <title>如何震惊VAR模型？利率变化对Gini的影响</title>
      <link>https://stats.stackexchange.com/questions/662472/how-to-shock-a-var-model-effect-of-interest-rate-change-on-gini</link>
      <description><![CDATA[我目前正在研究VAR模型，以分析扩张性货币政策对不平等的影响。不平等程度是Gini，我控制了宏观经济学变量，例如GDP和通货膨胀。
我想估计欧洲央行对Gini的利率降低的影响。对于速率变化，我使用欧洲央行的影子率。
 Choleski有序：影子率，GDP，通货膨胀，Gini。
我在数据集中有所有我的4个变量，并构建一个var模型（48个季度，滞后= 1-2）。
但是，我面临的一些挑战希望能得到一些见解：
广泛的置信区间：脉冲响应函数显示出合理的方向，但置信区间很大。我想知道这是否是由于某些变量中的模型规范，样本量或可能非平稳性的问题。
平稳性问题：我仍在辩论哪些变量要差异，以实现平稳性而不会失去重要的长期关系。根据所使用的测试（ADF与KPSS），一些系列的静止状态显示，这使事情变得更加复杂。我已经尝试使用仅使用级别数据或混音和匹配的部分固定部分级别进行每个变量固定。
选择冲击仪器：我正在考虑影子率是否是货币政策冲击的适当工具，尤其是在零下限时期的情况下。另外，我已经使用了欧洲央行的存款设施率，但是我不确定哪个在方法论上更能准确地捕获政策立场。
另外，我是否需要从估计中倒转数据才能获得扩张性货币政策的影响？由于R-Studio默认情况下会震惊变量+1，这意味着收缩的货币政策。
我在这一点上真的很挣扎。这是我的主论文，我无法在这个话题上取得突破。]]></description>
      <guid>https://stats.stackexchange.com/questions/662472/how-to-shock-a-var-model-effect-of-interest-rate-change-on-gini</guid>
      <pubDate>Tue, 11 Mar 2025 12:45:46 GMT</pubDate>
    </item>
    <item>
      <title>了解这种惩罚的完整数据模型</title>
      <link>https://stats.stackexchange.com/questions/662471/understanding-this-penalised-complete-data-log-likelihood</link>
      <description><![CDATA[我正在阅读有关将坡度模型应用于贝叶斯Spike-and-Slab框架 [link]  $$
\ text {pen}（\ lambda）= \ sigma \ sum_ {j = 1}^{p} \ lambda_ {r（\ beta，j）} | \ beta_j |，
$$ 
其中 $ r（\ beta，j）\ in \ {1，2，\ dots，p \} $ 是 $ \ beta_j $ 的等级。 class =“ nath-container”&gt; $ w_j = c \ gamma_j +（1- \ gamma_j）$ 。
为线性模型提供了模型 $ y = x \ beta + \ epsilon $ 
并使用以下层次结构框架
 \ begin {align}
\ pi（\ beta \ mid \ gamma，c，\ sigma^2; \ lambda）＆amp; \ propto c^{\ sum _ {j = 1}^p 1（\ gamma_j = 1） \ left（ -  \ frac {1} {\ sigma} w_j | \ beta_j | \ lambda_ {r（w \ beta，j）} \ right）\\）
\ pi（\ sigma^2）＆amp; \ propto \ sigma^{ -  2} \\
\ pi（\ gamma \ mid \ theta）＆amp; = \ prod_ {j = 1}^p \ theta^{\ gamma_j}（1- \ theta）^{1- \ gamma_j}
\ theta＆amp; \ sim \ text {beta}（a，b）\\
c＆amp; \ sim \ text {u} [0，1]。 \\
\ end {align}  
现在，我努力理解的一部分是在第3.1节的开始时，使用了惩罚的完整data log-likelihoodhood，并给出为 
  \ begin {align*}
    \ ell_ \ text {comp}＆amp; = \ log p（y，x，\ gamma，c; \ beta，\ theta，\ sigma^2） + \ text {pen}（\ beta）\\ \\ \\
    ＆amp; = \ log \ left（p（x | \ mu）p（y | x; \ beta，\ sigma^2）p（\ gamma | \ theta）p（c）\ right） + \ text）
    ＆amp; =  -  \ frac {1} {2} \ log（2 \ pi | \ sigma |） -  \ frac {1} {1} {2} {2}（x- \ mu）^t \ sigma^{ -  sigma^{ -  1}（ -  1}（x  -  \ mu） -  \ \ mu） -  n \ logma（x frac） \ | y -x \ beta \ |^2 \\
    ＆amp; \ quad + \ sum_ {j = 1}^{p} 1（\ gamma_j = 1）\ log \ theta + \ sum_ {
    ＆amp; \ quad  -  \ frac {1} {\ sigma} \ sum_ {j = 1}^{p} w_j | \ beta_j | \ lambda_r（w \ beta，j）。
\ end {align*}  
我的问题：

为什么我们最大程度地提高了受惩罚的完整数据模型？我一直在看其他一些尖峰和斜纹文学，后部经常被最大化。
为什么 $ \ text {pen}（\ beta）$ 在日志之外而与可能性分开？这是惩罚可能性的普遍表述吗？此公式还表示 $ c $ 在 $ \ beta $ 之前的指数之前的指数术语不存在。为什么它只是消失了？
为什么我们不考虑 $ \ pi（\ theta）$ 和 $ \ pi（\ sigma^2）$ 
]]></description>
      <guid>https://stats.stackexchange.com/questions/662471/understanding-this-penalised-complete-data-log-likelihood</guid>
      <pubDate>Tue, 11 Mar 2025 12:06:48 GMT</pubDate>
    </item>
    <item>
      <title>在正常脱离中寻找西格玛</title>
      <link>https://stats.stackexchange.com/questions/662468/finding-sigma-in-a-normal-disribution</link>
      <description><![CDATA[如果我知道x〜n（0，sigma^2），并且p（-3＆lt; x＆lt; 5）= 0.6，我如何找到Sigma？我如何找到Sigma？]]></description>
      <guid>https://stats.stackexchange.com/questions/662468/finding-sigma-in-a-normal-disribution</guid>
      <pubDate>Tue, 11 Mar 2025 10:11:44 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Cohen的Kappa作为数据标签的参考？</title>
      <link>https://stats.stackexchange.com/questions/662463/how-to-use-cohens-kappa-as-reference-for-data-labeling</link>
      <description><![CDATA[我有用于情感分析的数据，目前我正在使用数据标签，但我感到困惑。我应该手动标记数据。但是我担心它会偏见。我的资源仅限于其他人作为所有数据的注释者。
这就是为什么我有想法获取样本，然后自己将数据标记为其他人，并使用科恩的kappa作为措施。如果Kappa的结果表明我们大多是一致的，那么我将继续自己标记所有数据。
我可以这样做吗？在分析情绪中是否有可能和正确的做法？我很犹豫，因为当我没有找到任何这样做的文献时。如果您的答案还包括可靠的来源，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/662463/how-to-use-cohens-kappa-as-reference-for-data-labeling</guid>
      <pubDate>Tue, 11 Mar 2025 09:05:15 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法扩展Mann-Whitney U检验以对使用序数数据具有更大的敏感性？</title>
      <link>https://stats.stackexchange.com/questions/662458/is-there-a-way-to-extend-mann-whitney-u-test-to-have-more-sensitivity-to-varianc</link>
      <description><![CDATA[我有一组类似于质量保证研究系列的满意度调查的小样本，我的目标是评估受访者是否达成共识或至少类似于每个任务的共同意见。
为此，我正在针对理想响应集进行假设测试，鉴于最常见的投票，以查看是否存在显着差异：
  x = {1,1,1,1,1,2,3} 与 y = {1,1,1,1,1,1,1} 相比，因为这将是对满意度得分的完全共识为1。
它肯定可以强调缺乏共识，但我也希望它考虑到差异，以便将意见更强烈的样本视为不太可能达成共识的可能性。而我几乎得到了完全相同的p值：
  x_1 = {1,1,1,1,2,2}  vs  x_2 = {1,1,1,1,1,1,1,2,3}  vs vs   x_3 = {1,1,1,1,1,1,1,3,3}]]></description>
      <guid>https://stats.stackexchange.com/questions/662458/is-there-a-way-to-extend-mann-whitney-u-test-to-have-more-sensitivity-to-varianc</guid>
      <pubDate>Tue, 11 Mar 2025 05:48:52 GMT</pubDate>
    </item>
    <item>
      <title>如果我知道这一方差，是否可以使用每组仅一个实验单元进行统计分析？</title>
      <link>https://stats.stackexchange.com/questions/662451/is-it-possible-to-perform-a-statistical-analysis-with-only-one-experimental-unit</link>
      <description><![CDATA[因此，我正在以不同的底物混合物中种植蘑菇的研究论文。我有3瓶包含不同的底物混合物，我正在测量每个瓶子产生的蘑菇的生物量。
瓶1：182.4g 
瓶2：206.1g 
瓶3：244.2g 
这是问题 - 由于缺乏资源，我只进行了一次实验。因此，不可能执行任何需要多个复制的统计分析方法来确定这些数据是否显着不同（包括ANOVA）。但是，我知道在相似条件下生长的这些蘑菇的产量变异性，因为我购买了5种相同种类的蘑菇套件，并在相同的环境条件下种植它们。
来自GRAW套件的数据：186.4G，212.9g，206.4g，210.1g和195.6g 
是否可以使用这些生长套件中的数据来确定方差？这足以证明瓶子1,2和3个生物量的差异很重要吗？
我确定这些差异很重要，但是我不确定如何证明。
请让我知道是否可能，并告诉我我应该使用的方法的步骤。]]></description>
      <guid>https://stats.stackexchange.com/questions/662451/is-it-possible-to-perform-a-statistical-analysis-with-only-one-experimental-unit</guid>
      <pubDate>Tue, 11 Mar 2025 04:20:31 GMT</pubDate>
    </item>
    <item>
      <title>AUC计算的SQL函数产生意外结果</title>
      <link>https://stats.stackexchange.com/questions/662447/sql-function-for-auc-calculation-producing-unexpected-results</link>
      <description><![CDATA[我已经编写了一个SQL函数，以根据秩和计算曲线下的区域（AUC）。但是，当我将AUC值与 f1分数进行比较时，我会注意到一些奇怪的东西：

 最低f1得分的模型具有最高auc 。

这使我怀疑我的功能是否正确实施。
我的问题：

 我的功能是否犯了任何错误？ 
 如何验证我的功能是否提供正确的AUC值？ 

数据＆amp;功能
我在这里共享了我的数据集： auc dataset（excel）  
 SQL函数以计算AUC：
 创建函数[dbo]。[auccalc]
（（
    @model nvarchar（1000）
）
返回浮动
作为
开始
    声明@auc float;

     - 根据指定模型的降序按预测值按预测值对记录进行排名
    与级别为（
        选择 
            Actuallabel，
            最终标签为Pretlabel，
            row_number（）over（finalPredlabel desc订购）为rn
        来自gptanalysis
        其中（model = @model或@model =&#39;*&#39;）
    ），
     - 计算全部积极和负面因素
    属性为（
        选择 
            总计（*）总计
            sum（当actuallabel = 1然后1 else 0结束时）作为阳性，
            sum（当actuallabel = 0然后1 else 0结束时）作为负
        来自Rankeddata
    ），
     - 总和积极案件的排名
    sumranks as（
        选择总和（RN）作为sumrankpos
        来自Rankeddata
        actuallabel = 1
    ）
     - 使用等级公式计算AUC
    选择@AUC = case 
                    当s.potitives * s.ngatives = 0时，null-避免划分为零
                    else（sr.sumrankpos-（s.pasitives *（s. -potitives + 1） / 2.0））
                         /（s.potitives * s.negatives）
                  结尾
    从统计信息s
    交叉加入Sumranks Sr；
    
    返回@auc;
结尾;
 
其他信息：

我的期望是 AUC和F1分数应该遵循类似的趋势，但结果是违反直觉的。
结果的屏幕截图：
 

关于我的AUC计算是否正确以及为什么我可能会看到这种模式的任何见解？]]></description>
      <guid>https://stats.stackexchange.com/questions/662447/sql-function-for-auc-calculation-producing-unexpected-results</guid>
      <pubDate>Tue, 11 Mar 2025 02:36:57 GMT</pubDate>
    </item>
    <item>
      <title>了解建立假设检验的任意性</title>
      <link>https://stats.stackexchange.com/questions/662440/understanding-the-arbitrariness-of-building-a-hypothesis-test</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662440/understanding-the-arbitrariness-of-building-a-hypothesis-test</guid>
      <pubDate>Mon, 10 Mar 2025 23:20:58 GMT</pubDate>
    </item>
    </channel>
</rss>