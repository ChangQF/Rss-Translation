<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 06 Nov 2024 21:17:02 GMT</lastBuildDate>
    <item>
      <title>观察性研究中测量协变量的顺序 - 因果推断</title>
      <link>https://stats.stackexchange.com/questions/656860/order-in-which-covariates-are-measured-in-an-observational-study-causal-infere</link>
      <description><![CDATA[我想为 1 型糖尿病患者组建立 hba1c 水平模型。我有从登记册中提取的数据，我的目标是回答治疗干预是否会平​​均降低 hba1c 水平。我（试图）使用因果推理，其中平均治疗效果是使用潜在结果计算的。
因此，我的研究问题是
$$
E\{E (Y|A=1,W)-E(Y|A=0,W) \},
$$
其中 $Y$ 是结果，$A$ 是二元治疗，$W$ 是基线变量。
假设是
$$
\begin{array}{cllc}
1 &amp; \text{ 一致性：} &amp; A=a \Rightarrow Y=Y^a,\\
2 &amp; \text{ 可交换性：} &amp; A \perp Y^a|W (\perp \textit{read } \text{ &quot;独立性&quot;}),\\
3 &amp; \text{ 积极性：} &amp; P(A=a|W=w)&gt;0 \text{ when } P(W=w)&gt;0.
\end{array}
$$
我相信这些假设通常用于因果推理。
现在我提出我的问题，它按照数据测量的顺序进行。
正如我所写，数据来自注册表，而不是来自随机对照。因果链显然要求在治疗干预后（对于接受治疗的人）测量结果（hba1c 水平），而不是在治疗干预之前 - 因此尝试评估治疗效果毫无意义。此外，在观察到的结果之前测量基线变量。
但是对于我拥有的各种数据记录，治疗干预是在$\textit{before}$ 提供的，测量了一些基线变量（即非确定性变量，如血压等，会随时间变化）。因此，治疗效果有可能通过基线变量被隐藏或夸大。
有没有办法克服这个问题，因为我猜这个问题以前在寄存器分析中遇到过。
最好]]></description>
      <guid>https://stats.stackexchange.com/questions/656860/order-in-which-covariates-are-measured-in-an-observational-study-causal-infere</guid>
      <pubDate>Wed, 06 Nov 2024 21:09:25 GMT</pubDate>
    </item>
    <item>
      <title>我真的很困惑如何解释这个 GLM</title>
      <link>https://stats.stackexchange.com/questions/656859/im-really-confused-how-to-interpret-this-glm</link>
      <description><![CDATA[这是我第一次在 glm 上下文中处理二项式数据和不相关变量“x”，所以我很难理解。
这是我的数据，我希望使用互补对数对数链接和 R 函数 glm() 中的二项分布使用此数据拟合广义线性模型。
x,r,y
1.6907,59,6
1.7242,60,13
1.7552,62,18
1.7842,56,28
1.8113,63,52
1.8369,59,53
1.8610,62,61
1.8839,60,60


这是输出答案的正确 R 代码
&gt;响应 &lt;- cbind(y, r - y)
&gt; 模型 &lt;- glm(response ~ x, data = dat, family = binomial(link = &quot;cloglog&quot;))
&gt; summary(model)

我不明白 cbind(y, r-y) 的目的是什么，因为它是二项式的，我们不是要绘制从 0 到 1 的概率吗？这与 x 有什么联系？我想我漏掉了什么
有什么提示吗？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/656859/im-really-confused-how-to-interpret-this-glm</guid>
      <pubDate>Wed, 06 Nov 2024 20:52:48 GMT</pubDate>
    </item>
    <item>
      <title>逐步向前/向后推算的数学依据</title>
      <link>https://stats.stackexchange.com/questions/656858/mathematical-justification-for-stepwise-forward-backward</link>
      <description><![CDATA[是否有任何参考资料以数学方式陈述并证明回归（尤其是逻辑回归）的逐步前向和后向变量选择？我找不到任何此类来源。]]></description>
      <guid>https://stats.stackexchange.com/questions/656858/mathematical-justification-for-stepwise-forward-backward</guid>
      <pubDate>Wed, 06 Nov 2024 20:22:49 GMT</pubDate>
    </item>
    <item>
      <title>卡方二项式或 t 检验是比较二分变量的正确检验吗？</title>
      <link>https://stats.stackexchange.com/questions/656855/is-a-binomial-of-chi-square-or-t-test-the-correct-test-to-compare-dichotomous-va</link>
      <description><![CDATA[您有一个 ML 模型，该模型输出二分变量 0 或 1 的一百万个观测值中的 100,000 个。您想要查看模型输出的 100,000 个观测值的分布是否与 100 万相似。您应用该模型 3 次，我们将它们称为 A、B 和 C，您将获得 3 组 100,000 个观测值。您想要测试它们是否具有与原始 1,000,000 相同的分布。您在 100,000 和 1,000,000 中的三个之间应用 T 检验，然后在 100,000 和 1,000,000 中的三个之间应用卡方检验，然后应用二项检验。t 检验和二项检验都认为 B 与整个集合相似，A 和 C 不同，但卡方表明只有 C 相似。那么，哪个模型最能近似这 1,000,000 行？]]></description>
      <guid>https://stats.stackexchange.com/questions/656855/is-a-binomial-of-chi-square-or-t-test-the-correct-test-to-compare-dichotomous-va</guid>
      <pubDate>Wed, 06 Nov 2024 19:30:40 GMT</pubDate>
    </item>
    <item>
      <title>相关组：混合效应作为因子模型</title>
      <link>https://stats.stackexchange.com/questions/656851/correlated-groups-mixed-effects-as-a-factor-model</link>
      <description><![CDATA[这已发布在量化交易所中，但没有人感兴趣，所以我想我可以在这里重新发布它。
我正在尝试建立一个 Fama-French 风格的基本因子模型。我有 FF 因子以及我的资产所属的行业。对于不熟悉 FF 的人，您可以将其视为一些基本因素（与通货膨胀或 GDP 相同）
该模型指定为：
$$
\mathbf{Y} = \mathbf{X}\beta + \mathbf{Z}\gamma + \epsilon 
$$
其中，$\mathbf{Y}$ 是 $N$ 资产和 $T$ 每周回报的横截面时间序列矩阵； $\mathbf{X}$ 是 Fama-French 因子（HML、SMB、WML 和 Market-RF 投资组合的每周回报）；$\mathbf{Z}$ 是随机效应矩阵。我有一个简单的案例，其中只有随机截距而没有随机斜率，即$\mathbf{Z}$ 是一个由 1 和 0 组成的矩阵，表示资产所属的行业。 $\epsilon$ 是分布为 $N(0,1)$ 的残差，$\gamma$ 是随机截距 $N(0,\mathbf{G})$，而 $\beta$ 是本例中通常的固定斜率（和一个固定截距）。
我们可以使用 statsmodels&#39; 混合线性模型 来拟合该模型。
数据框如下所示：

我们只需通过以下方式拟合模型：
md = smf.mixedlm(&quot;y ~ MktRF + SMB + HML + WML&quot;, X, groups=X[&quot;sector&quot;])
res = md.fit()

摘要如下所示。然而，结果很糟糕。残差和拟合值之间几乎存在完美的线性关系。


我怀疑协方差矩阵$\mathbf{G}$出了问题，因为它接近奇异值。关于这个问题，我读到的常见方法之一是，随机效应可能过度参数化，并且可能存在多重共线性。因此，我计算了（出于必要，做了一些填充）行业之间的相关性 - 我们的随机截距。

嗯，是的，这些组是相互关联的（尤其是一些组）。
问题：

我们能做些什么？我可以重新分组一些相关的行业，但这似乎不是一个好主意。例如，“金融”和“工业”的相关性很高，但这些是完全不同的组，可能与其他组具有不同的相关性。

协方差真的是个问题吗？也可能是其他原因？我读过这篇帖子，其中讨论了零方差并不一定意味着模型有问题，即可能没有组变异，所有变异都被残差变异捕获 - 但这仍然不能解释数据和残差之间的线性关系。

]]></description>
      <guid>https://stats.stackexchange.com/questions/656851/correlated-groups-mixed-effects-as-a-factor-model</guid>
      <pubDate>Wed, 06 Nov 2024 18:28:13 GMT</pubDate>
    </item>
    <item>
      <title>对俄罗斯的制裁可以在计量经济分析中作为虚拟变量来建模吗？</title>
      <link>https://stats.stackexchange.com/questions/656850/can-sanctions-against-russia-be-modeled-as-a-dummy-variable-in-econometric-analy</link>
      <description><![CDATA[我目前正在进行计量经济学分析，旨在评估对俄罗斯的制裁对 28 个欧盟国家可再生能源份额（占总能源的百分比）的影响。
我正在考虑将制裁建模为虚拟变量，其中：
0 表示未对俄罗斯实施制裁的时期（2014 年之前）。
1 表示实施制裁的时期（2014 年以后）。
我的因变量是这些国家在特定时间段内可再生能源的份额。
我有一个控制变量向量（GDP、能源价格和政策激励）。
我的问题是：
在这种情况下，使用虚拟变量来表示制裁是否合适？
是否有任何特定的计量经济学模型或技术可以推荐用于分析这种二元处理变量对可再生能源份额等连续结果变量的影响？
我很感激任何关于此类分析最佳实践的见解或建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/656850/can-sanctions-against-russia-be-modeled-as-a-dummy-variable-in-econometric-analy</guid>
      <pubDate>Wed, 06 Nov 2024 17:36:01 GMT</pubDate>
    </item>
    <item>
      <title>如何将 2 个方差与观察到的方差分开？</title>
      <link>https://stats.stackexchange.com/questions/656846/how-to-separate-2-variances-from-observed-variance</link>
      <description><![CDATA[我将其分解为以下内容：
var(predicted_conc) = actual_conc*var1 + var2
请注意，随机变量生成器是独立的，因此添加的是方差而不是标准差。
我首先运行模拟来重新生成该信息。
actual_conc &lt;- c(0,3, 5, 10, 20, 30,50,80,90, 100, 150, 180)

predicted_conc &lt;- c()
for(i in actual_conc){
predicted_conc &lt;- c(predicted_conc, i + rnorm(1000, mean =0, sd = (0.05*i)) + rnorm(1000, mean = 0, sd = 0.1))
}

如您所见，我必须将随机变量生成与按浓度缩放或只是常数分开。
但是，这种关系不是线性的。然后我计算方差，非线性关系变得非常明显，如果我拟合线性或二次回归，我会得到负截距，其中实际常数方差为 0.01。
尽管我在这个模拟中接近真实值，如果我使用 sd 而不是 var，并且将 sd~conc 建模为常数方差很小，但我认为这应该是更正确的建模方法。
欢迎提出想法。
谢谢！
编辑
我猜这与方差有关，因为零会导致零结果！我当然有坚定的假设，即浓度在任何时候都不会为负。]]></description>
      <guid>https://stats.stackexchange.com/questions/656846/how-to-separate-2-variances-from-observed-variance</guid>
      <pubDate>Wed, 06 Nov 2024 16:42:32 GMT</pubDate>
    </item>
    <item>
      <title>针对回归问题的贝叶斯分歧主动学习（BALD）</title>
      <link>https://stats.stackexchange.com/questions/656845/bayesian-active-learning-by-disagreement-bald-for-regression-problems</link>
      <description><![CDATA[我一直在研究 BALD 方法，我理解它在分类问题中的应用，但我不确定如何在回归问题中实现它。
在分类情况下，BALD 最大化了互信息，其定义如下
$$
\mathcal{H}[y | x, D] - \mathbb{E}_{\theta \sim p(\theta | D)}[\mathcal{H}[y | x, \theta]]
$$
其中 $x$ 是输入，$y$ 是可能的标签，$D$ 是训练数据，$\theta$ 是可能的参数。在回归案例中，我们可以使用贝叶斯推理将第一项改为输出的方差。但是，第二项旨在减去随机不确定性。我可以看到在回归场景中，通过使用每个 $(x,y)$ 组合重新训练神经网络以获得可能的输出 y 并再次执行贝叶斯推理来实现这一点。但是，如果您想从 2000 个未标记数据点池中最大化相互信息，这似乎效率低得可笑。我想知道是否存在更直接的方法来计算这种随机不确定性。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/656845/bayesian-active-learning-by-disagreement-bald-for-regression-problems</guid>
      <pubDate>Wed, 06 Nov 2024 16:36:42 GMT</pubDate>
    </item>
    <item>
      <title>难道预期 Sarsa 是离策略的，而 SARSA 只是预期 SARSA 的 MC 估计，为什么它是在策略的呢？</title>
      <link>https://stats.stackexchange.com/questions/656843/is-expected-sarsa-is-off-policy-and-sarsa-is-just-an-mc-estimate-of-expected-sa</link>
      <description><![CDATA[因此，预期 SARSA 将更新定义为：
$$
Q(s,a) = Q(s,a) +\alpha (R+ \mathbb{E}_{a\sim\pi(s&#39;)}[Q(s&#39;, a)] - Q(s,a))
$$
其中 SARSA 将更新定义为 $a&#39;\sim\pi(s&#39;)$：
$$
Q(s,a) = Q(s,a) +\alpha (R+ Q(s&#39;, a&#39;) - Q(s,a))
$$
那么 SARSA 怎么会不仅仅是 ExpSARSA 的 MC 估计呢？既然 MC 是无偏的，那么为什么 SARSA 不应该是一种离策略算法呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/656843/is-expected-sarsa-is-off-policy-and-sarsa-is-just-an-mc-estimate-of-expected-sa</guid>
      <pubDate>Wed, 06 Nov 2024 15:53:03 GMT</pubDate>
    </item>
    <item>
      <title>如何根据障碍伽马模型计算后验分布？</title>
      <link>https://stats.stackexchange.com/questions/656841/how-to-compute-posterior-distribution-from-a-hurdle-gamma-model</link>
      <description><![CDATA[我正在对孢子陷阱中的数据进行建模。响应是 DNA 数量，因此 &gt;0。有很多 0（3/4 的数据）。零主要来自潜在孢子源的缺失，而数量取决于孢子源的强度/接近度。
Hurdle-gamma 模型似乎适合此数据。我确实找到了如何在 JAGS 中拟合 hurdle-gamma 模型，并且它收敛得很好。但是，我正在努力计算响应数据 Y 的后验分布。
• 如何计算 Y 的后验？我想到：
 S1[i]~ dbern(P[i]) 
S2[i]~ dgamme(shape[i], rate[i]) 
Ysim​​[i]&lt;- S1[i]*S2[i]

对吗？
• 我仍然需要弄清楚如何从使用的参数化中检索伽马的形状和速率。
我的模型是：
 cat(&quot;model{ # beta / gamma 成分的先验、尺度参数 r 和随机因子方差
for (i in 1:ng) {gamma[i]~ dnorm(0, 0.0001)}
for (i in 1:nb) {binom[i]~ dnorm(0, 0.0001)} 
r~ dgamma(1e-2, 1e-2)
sigma.a ~ dunif(0.001, 50); tau.a= 1 / sigma.a^2
# 使用零技巧的可能性
C &lt;- 10000
for (i in 1:N) { Zeros[i] ~ dpois(-loglik[i] + C)
# 创建一个虚拟的存在/不存在变量，如果 y 小于 0，则为 0如果 y &gt; 0.0001，则为 0.0001 和 1
z[i] &lt;- step(Y[i] - 0.0001)
# gamma 对数似然
# 如果 y&lt;0.0001（即 z=0），则似然为 log(1 - P) 或
# 如果 y&gt;=0.0001（z=1），则为 P * gammalik
logGamma[i] &lt;- (r - 1) * log(Y[i]) - (Y[i] * r) / mu[i] - loggam(r) + r * log(r / mu[i])
loglik[i] &lt;- (1 - z[i]) * log(1 - P[i]) + z[i] * ( log(P[i]) + logGamma[i] )
# 伽马均值和伯努利概率的线性预测器
log(mu[i]) &lt;- inprod(gamma[], Xg[i,]) + alea[comb[i]]
logit(P[i]) &lt;- inprod(binom[], Xb[i,]) }
for (k in 1:ncomb) { alea[k] ~ dnorm(0, tau.a) }
} #close model&quot;, fill=TRUE, file= &#39;traces.R&#39;)

DATA= list(Y= ANA$conc.spore, # 响应
Xg= model.matrix(~1+PI1, ANA), # 来自 gamma 成分的协变量
Xb= model.matrix(~1+(expose&gt;0.5), ANA), # 来自二元成分的协变量 
comb= ANA$COMB, # 随机因子
ncomb= max(ANA$COMB), # Nb 随机因子组
N= nrow(ANA), # 样本大小
Zeros= rep(0, nrow(ANA)))
DATA$ng= ncol(DATA$Xg); DATA$nb= ncol(DATA$Xb)
]]></description>
      <guid>https://stats.stackexchange.com/questions/656841/how-to-compute-posterior-distribution-from-a-hurdle-gamma-model</guid>
      <pubDate>Wed, 06 Nov 2024 15:22:31 GMT</pubDate>
    </item>
    <item>
      <title>如何测试事件频率（梯度）是否随时间变化？</title>
      <link>https://stats.stackexchange.com/questions/656839/how-to-test-if-the-frequency-of-events-gradient-changes-over-time</link>
      <description><![CDATA[我有 Python 中的时间序列数据，用于跟踪特定操作随时间的变化。我已经量化了这些操作，并想测试这些事件在单位时间内的频率（基本上是梯度）是否随着时间的推移而发生统计变化。基本上，我假设梯度会随着时间的推移而减小，但我想测试这在统计上是否正确。
基本上，我假设梯度会随着时间的推移而减小，但我想测试这在统计上是否正确。
数据由时间戳和一列组成，该列指示操作是否在该时间戳发生。一些时间戳有重复发生的事件（用相同的 ID 分组），而其他时间戳为空或包含单个事件。哪些统计方法（以及 Python 中的库）最适合进行此分析？
data = {
&#39;timestamp&#39;: [
&#39;00:01&#39;, &#39;00:02&#39;, &#39;00:03&#39;, &#39;00:04&#39;, &#39;00:05&#39;, 
&#39;00:06&#39;, &#39;00:07&#39;, &#39;00:08&#39;, &#39;00:09&#39;, &#39;00:10&#39;, 
&#39;00:11&#39;, &#39;00:12&#39;, &#39;00:13&#39;, &#39;00:14&#39;, &#39;00:15&#39;
],
&#39;event_group&#39;: [
1, 1, &#39;&#39;, &#39;&#39;, 2, 
2, 2, &#39;&#39;, &#39;&#39;, 
&#39;&#39;, 3, &#39;&#39;, &#39;&#39;, 4, 4
]
}

df = pd.DataFrame(data)
]]></description>
      <guid>https://stats.stackexchange.com/questions/656839/how-to-test-if-the-frequency-of-events-gradient-changes-over-time</guid>
      <pubDate>Wed, 06 Nov 2024 15:13:25 GMT</pubDate>
    </item>
    <item>
      <title>相关性质的乘积</title>
      <link>https://stats.stackexchange.com/questions/656836/product-of-correlations-properties</link>
      <description><![CDATA[corr(A,B)*corr(B,C) 是否与 corr(A,C) 有一定关联，还是完全独立？
此乘积 (corr(A,B)*corr(B,C)) 有任何属性吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656836/product-of-correlations-properties</guid>
      <pubDate>Wed, 06 Nov 2024 14:31:48 GMT</pubDate>
    </item>
    <item>
      <title>Pymc-BART 索引错误</title>
      <link>https://stats.stackexchange.com/questions/656835/pymc-bart-index-error</link>
      <description><![CDATA[我尝试按照此处的示例笔记本进行操作，但在执行代码时遇到了一些 IndexError。
这是一个最小的工作示例：
import numpy as np
import pandas as pd
import pymc as pm
import pymc_bart as pmb
import pytensor.tensor as pt
from scipy.special import logit

# 读取样本数据
data_df = pd.read_csv(
&quot;https://raw.githubusercontent.com/juanitorduz/website_projects/master/data/retention_data.csv&quot;,
parse_dates=[&quot;cohort&quot;, &quot;period&quot;],
)

# 处理数据
eps = np.finfo(float).eps
train_data_red_df = data_df.query(&quot;cohort_age &gt; 0&quot;).reset_index(drop=True)
train_obs_idx = train_data_red_df.index.to_numpy()
train_n_users = train_data_red_df[&quot;n_users&quot;].to_numpy()
train_n_active_users = train_data_red_df[&quot;n_active_users&quot;].to_numpy()
train_retention = train_data_red_df[&quot;retention&quot;].to_numpy()
train_retention_logit = logit(train_retention + eps)
train_data_red_df[&quot;month&quot;] = train_data_red_df[&quot;period&quot;].dt.strftime(&quot;%m&quot;).astype(int)
features: list[str] = [&quot;age&quot;, &quot;cohort_age&quot;, &quot;month&quot;]
x_train = train_data_red_df[features]

# 模型
with pm.Model(coords={&quot;feature&quot;: features}) as model:
# --- 数据 ---
model.add_coord(name=&quot;obs&quot;, values=train_obs_idx, mutable=True)
x = pm.MutableData(name=&quot;x&quot;, value=x_train, dims=(&quot;obs&quot;, &quot;feature&quot;))
n_users = pm.MutableData(name=&quot;n_users&quot;, value=train_n_users, dims=&quot;obs&quot;)
n_active_users = pm.MutableData(name=&quot;n_active_users&quot;, value=train_n_active_users, dims=&quot;obs&quot;)

# --- 参数化 ---
# BART 组件在
# logit 变换下对保留率的图像进行建模，因此范围不限制在 [0, 1]。
mu = pmb.BART(
name=&quot;mu&quot;,
X=x,
Y=train_retention_logit,
dims=&quot;obs&quot;,
)
# 我们使用逆 logit 变换将保留率恢复到 [0, 1]。
p = pm.Deterministic(name=&quot;p&quot;, var=pm.math.invlogit(mu), dims=&quot;obs&quot;)
# 我们添加一个小的 epsilon 以避免数值问题。
p = pt.switch(pt.eq(p, 0), eps, p)
p = pt.switch(pt.eq(p, 1), 1 - eps, p)

# --- 可能性 ---
n_active_users_estimated = pm.Binomial(
name=&quot;n_active_users_estimated&quot;,
n=n_users,
p=p,
perceived=n_active_users,
dims=&quot;obs&quot;,
)

pm.model_to_graphviz(model=model)

# 拟合模型
使用模型：
idata = pm.sample(draws=100, chains=1)
posterior_predictive = pm.sample_posterior_predictive(trace=idata)

我已检查 x_train 和 train_retention_logit 的形状传递给 BART 方法，它们似乎具有正确的形状，分别为 (1128,3) 和 (1128,)。
然而，后验采样返回了一个我无法追溯到其来源的错误：
IndexError：元组索引超出范围
导致错误的应用节点：BART_rv{&quot;(i00,i01),(i10),(),(),(),(i50)-&gt;(o00)&quot;}(RNG(&lt;Generator(PCG64) at 0x1721017E0&gt;), [], x, [-1.609437 ... .51268651], 100, 0.95, 2.0, [])
Toposort 索引：0
输入类型：[RandomGeneratorType, TensorType(int64, shape=(0,)), TensorType(float64, shape=(None, None)), TensorType(float64, shape=(1128,)), TensorType(int8, shape=()), TensorType(float64, shape=()), TensorType(float32, shape=()), TensorType(float64, shape=(0,))]
输入形状：[&#39;无形状&#39;, (0,), (1128, 3), (1128,), (), (), (), (0,)]
输入步幅：[&#39;无步幅&#39;, (0,), (8, 9024), (8,), (), (), (), (0,)]
输入值：[Generator(PCG64) at 0x1721017E0, array([], dtype=int64), &#39;未显示&#39;, &#39;未显示&#39;, array(100, dtype=int8), array(0.95), array(2., dtype=float32), array([], dtype=float64)]
输出客户端：[[output[1](BART_rv{&quot;(i00,i01),(i10),(),(),(),(i50)-&gt;(o00)&quot;}.0)], [Second(mu, [-3.09309984])]]

相关库的版本为：
python 3.10.15
pymc 5.16.2
pymc-bart 0.7.0

以防它与软件包版本之间的行为差​​异有关。]]></description>
      <guid>https://stats.stackexchange.com/questions/656835/pymc-bart-index-error</guid>
      <pubDate>Wed, 06 Nov 2024 14:10:28 GMT</pubDate>
    </item>
    <item>
      <title>“最好的测试是无偏见的”这一说法的证明</title>
      <link>https://stats.stackexchange.com/questions/656832/proof-of-the-statement-the-best-test-is-unbiased</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656832/proof-of-the-statement-the-best-test-is-unbiased</guid>
      <pubDate>Wed, 06 Nov 2024 12:41:53 GMT</pubDate>
    </item>
    <item>
      <title>样本量越大，错误拒绝 0 假设的风险是否会越大？</title>
      <link>https://stats.stackexchange.com/questions/656828/does-the-risk-of-incorrectly-rejecting-the-0-hypothesis-increase-with-a-large-sa</link>
      <description><![CDATA[我经常看到类似这样的话：“如果样本量足够大，较小的效应量可以产生显著的结果”。我不太明白这一点。
对我来说，这听起来是这样的：增加样本量，你最终肯定会拒绝 0 假设（也就是说，如果你将样本量增加到一定大小，你 100% 肯定会拒绝 0 假设）。
重新阅读此主题。据我所知，鉴于我在统计学方面的经验，0 假设被正确拒绝。
决定在 ttest_1samp 测试的代码中检查这一点，使 popmean=15.03 与样本 (mean=15) 的差异非常小。滑块选择 N - 样本，分布实时重新绘制，垂直条是上限值（蓝色）和 p_value（橙色）。
在大约 N - 4000 之后，在大多数情况下，零假设被拒绝。更不清楚的是，在 popmean=15 时，零假设有时也会被拒绝（即均值相等）。
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import t, norm, ttest_1samp
from matplotlib.widgets import Slider

fig, ax = plt.subplots()
fig.subplots_adjust(bottom=0.25)

ax_n = fig.add_axes([0.25, 0.15, 0.65, 0.03])
s_n = Slider(ax_n, &quot;N&quot;, valmin=15, valmax=16000,valinit=30, valstep=1)
mu_0 = 15.03

rng = np.random.default_rng(1)

def update(val):
N = s_n.val
rvs = np.sort(norm.rvs(loc=15, scale=1, size=N, random_state=rng))
mu, std = np.mean(rvs), np.std(rvs)
z_values = (rvs - mu) / std
df = N - 1
pdf = t.pdf(rvs, loc=mu, scale=std, df=df)
tst = ttest_1samp(rvs, popmean=mu_0)
l, r = t.ppf(1 - 0.975, df=df), t.ppf(0.975, df=df)
ci = tst.confidence_interval(confidence_level=0.95)
ci = (ci - mu) / std
ax.clear()
ax.plot(z_values, pdf, lw=2, color=&quot;red&quot;)
ax.axvline(x=(mu_0 - mu) / std, color=&quot;green&quot;, label=&quot;mean 0&quot;)# 0 假设的平均值
ax.axvline(x=ci[0], linestyle=&quot;--&quot;, color=&quot;magenta&quot;, label=&quot;CI&quot;)
ax.axvline(x=ci[1], linestyle=&quot;--&quot;, color=&quot;magenta&quot;)
ax.axvline(x=l, linestyle=&quot;--&quot;, color=&quot;blue&quot;, label=&quot;alfa&quot;)# alfa
ax.axvline(x=r, linestyle=&quot;--&quot;, color=&quot;blue&quot;)# alfa
ax.axvline(x=t.ppf(tst[1]/2, df=df), linestyle=&quot;--&quot;, color=&quot;orange&quot;, label=&quot;p-value&quot;)#p-value
ax.axvline(x=-t.ppf(tst[1]/2, df=df), linestyle=&quot;--&quot;, color=&quot;orange&quot;)#p-value
ax.text(0, (np.max(pdf) + np.min(pdf))/2, &quot;p_value =&quot; + str(round(tst[1], 4)), fontsize=12)
ax.legend()

s_n.on_changed(update)
update(0)

plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/656828/does-the-risk-of-incorrectly-rejecting-the-0-hypothesis-increase-with-a-large-sa</guid>
      <pubDate>Wed, 06 Nov 2024 11:43:12 GMT</pubDate>
    </item>
    </channel>
</rss>