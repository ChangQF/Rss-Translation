<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 12 Jan 2025 06:22:17 GMT</lastBuildDate>
    <item>
      <title>在因子分析中，为什么因子载荷矩阵中有效参数的个数不是$\frac 12 k(k+1)$？</title>
      <link>https://stats.stackexchange.com/questions/659902/in-factor-analysis-why-is-the-number-of-effective-parameters-in-the-factor-load</link>
      <description><![CDATA[如果这是一个基本问题，我很抱歉，但我不知道我错在哪里。
考虑因子分析模型
\begin{equation*}
\begin{array}{cccccc}
X &amp; = &amp; L&amp; f &amp; + &amp; u \\ 
p\times 1 &amp; &amp; p\times k &amp; k\times k &amp; &amp; 
\end{array} 
\end{equation*
其中 $f \sim N(\mathbf 0, I)$ 和 $X\sim N(\mathbf 0,\Sigma) $。
在进行似然比检验时，我们需要确定因子载荷矩阵 $L$ 中有效参数的数量。
虽然 $L$ 有 $pk$ 个条目，但如果 $L$ 适合模型，那么对于任何 $O$ 正交，$LO$ 也适合。
因此我们实际上需要少于 $pk$ 个数字。我们知道这个数字是 $pk- \frac 12 k(k-1)$。
我理解我们可以添加限制，即 $L&#39;\Psi^{-1} L$ 是对角线的，
这又增加了 $\frac 12 k(k+1)$ 个限制。因此我们得到结果 $pk- \frac 12 k(k-1)$。
但我还推导出有效参数的数量是 $\frac 12 k(k+1)$，我不知道我错在哪里。
我的理由：假设我们知道 $\triangle$ 位置的参数：
\begin{equation*}
\begin{pmatrix}
\triangle &amp; \cdots &amp; &amp; &amp; \triangle \\ 
&amp; \triangle &amp; \cdots &amp; &amp; \triangle \\ 
&amp; &amp; &amp; &amp; \cdots \\ 
\cdots &amp; &amp; &amp; \cdots &amp; \triangle \\ 
\cdots &amp; &amp; &amp; &amp; 
\end{pmatrix} 
\end{equation*
即前 $k\times k$ 行和列的 $k$ 子矩阵的上对角线元素，
然后因为我们知道 $LL^T$，即每行的内积，
然后我们可以确定 $(2,1)$ 元素，并完成第二行。
第三行有两个未知元素，可以通过第三行和第一（第二）行的内积等确定，我们可以完成 $k\times k$ 子矩阵。
一般情况下$\text{rank}( L )=k$，而对于$(k+1),\cdots, p$行，由于我们知道它们与前$k$行的内积，而前$k$行构成一个非奇异矩阵，因此我们可以唯一地确定整个$L$。
因此$L$中有效参数的数量为$\frac 12 k(k+1)$。]]></description>
      <guid>https://stats.stackexchange.com/questions/659902/in-factor-analysis-why-is-the-number-of-effective-parameters-in-the-factor-load</guid>
      <pubDate>Sun, 12 Jan 2025 03:36:01 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 进行多层次结构方程建模？</title>
      <link>https://stats.stackexchange.com/questions/659901/using-r-for-multilevel-structural-equation-modeling</link>
      <description><![CDATA[我通常使用 Mplus，但手头没有。有人告诉我 MSEM 可以在 R 中完成，但我需要指导（网站或代码），因为我是 R 新手。
我对使用随机斜率作为 2 级结果的预测因子很感兴趣。任何关于在哪里查看的建议都会有所帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/659901/using-r-for-multilevel-structural-equation-modeling</guid>
      <pubDate>Sun, 12 Jan 2025 03:29:10 GMT</pubDate>
    </item>
    <item>
      <title>零协方差何时意味着独立？</title>
      <link>https://stats.stackexchange.com/questions/659900/when-does-null-covariance-imply-independence</link>
      <description><![CDATA[众所周知，如果 $X,Y$ 是独立随机变量，则 $\text{Cov}(X,Y) = 0$。认为这一事实的反面成立也是一种很常见的谬论。但是，我的问题是，反面成立的情况不是经常发生吗？
例如，如果随机向量 $(X,Y)$ 呈正态分布，是一个二维随机向量，则 $X,Y$ 独立就等同于它们具有零协方差。
继续下去，由于 CLT，假设 $(X,Y)$ 呈正态分布是很常见的（即使在大多数情况下不是这样）。因此，尽管零协方差在学术意义上并不意味着独立性，但从更实际的意义上来说却意味着独立性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659900/when-does-null-covariance-imply-independence</guid>
      <pubDate>Sun, 12 Jan 2025 03:11:46 GMT</pubDate>
    </item>
    <item>
      <title>分层抽样和可变大小聚类的置信区间</title>
      <link>https://stats.stackexchange.com/questions/659897/confidence-intervals-for-stratified-sampling-and-variable-sized-clusters</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659897/confidence-intervals-for-stratified-sampling-and-variable-sized-clusters</guid>
      <pubDate>Sun, 12 Jan 2025 00:25:49 GMT</pubDate>
    </item>
    <item>
      <title>对已进行 FDR 校正的数据批次进行 FDR 校正</title>
      <link>https://stats.stackexchange.com/questions/659893/fdr-correction-on-batches-of-already-fdr-corrected-data</link>
      <description><![CDATA[背景：
这个问题来自组学背景，其中大量数据有时需要将整个数据集分成几批，并用一些分析软件分别处理它们。
示例：
对于此示例，请考虑两个大小相等的测量数据批次。在每个批次中，可以用各种置信度分数识别 50000 个分子。在 1% 阈值下应用错误发现校正后，每个数据集中仍保留 1000 个具有显著 q 值的分子。任务是重新组合两个批次并获得一个仍具有 1% FDR 的数据集。
问题：
我的问题是，BH 校正（或任何其他类型的调整）是否可用于重新校正批次 q 值并允许组合批次而不会夸大错误发现？任何有关现有实现和/或统计背景的评论都将不胜感激。
示例方法：
我能想到一种方法，其中从每个批次中取出 50000 个 q 值并对整个 100000 个值集运行 BH 校正，同时取 q 值 &lt; 0.01。这基本上相当于解释批次 q 值，就像解释单个数据集中的原始 p 值一样。]]></description>
      <guid>https://stats.stackexchange.com/questions/659893/fdr-correction-on-batches-of-already-fdr-corrected-data</guid>
      <pubDate>Sat, 11 Jan 2025 20:52:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 SARIMA 模型中，时间序列的差分无助于使其平稳？</title>
      <link>https://stats.stackexchange.com/questions/659898/why-does-differencing-of-time-series-not-help-to-make-it-stationary-in-the-sarim</link>
      <description><![CDATA[我在 SARIMA 模型中差分后无法获得平稳时间序列。
我是时间序列分析的初学者，但我读到时间序列 Y_t = \nabla^d (1-L^s)^D X_t 应该是平稳时间序列。然而，在用值 s=12 和不同的 d 和 D 值进行差分后，我的时间序列似乎不是平稳分析 ACF 函数。我也尝试过一开始 lambda=0 的 Box–Cox 变换，但同样没用。
这是我的原始数据
原始数据 (data_ts)
它是非平稳的。
经过 lambda = 0 的 Box-Cox 变换之后
data_bc &lt;- BoxCox(data_ts, lambda=0)

Box-Cox 变换之后
这是 ACF 函数：
ACF 函数
然后我尝试对我的时间序列进行差分，结果如下：
ts_plot(diff(data_bc))
Acf(diff(data_bc))

差分后的时间序列图。
我的时间的 ACF系列。
在我看来，它可以是静止的，但从 ACF 来看，它不是。可能是因为季节性？因此，我尝试对滞后 s=12 的时间序列进行差分，然后再次进行差分（s=12、d=1、D=1）。
ts_plot(diff(diff(data_bc, lag=12)))
Acf(diff(diff(data_bc, lag=12)))

新时间序列
ACF
再次分析 ACF 函数，它似乎不是平稳的。我错了吗？那我该怎么办？
Box-Cox 变换、差分、消除季节性。我希望获得平稳的时间序列。]]></description>
      <guid>https://stats.stackexchange.com/questions/659898/why-does-differencing-of-time-series-not-help-to-make-it-stationary-in-the-sarim</guid>
      <pubDate>Sat, 11 Jan 2025 14:36:19 GMT</pubDate>
    </item>
    <item>
      <title>无法拟合高斯混合模型，估计错误参数</title>
      <link>https://stats.stackexchange.com/questions/659851/cant-fit-gaussian-mixture-model-estimates-wrong-parameters</link>
      <description><![CDATA[下面的测试从高斯混合模型生成样本，然后对其进行拟合。
拟合模型与原始模型完全不同。为什么？这怎么可能呢，结果不只是稍微不同——错误是巨大的。

原文：weights=[0.5, 0.5], means=[0, 0], sigmas=[1, 2]
拟合：weights=[0.525, 0.475], means=[-0.617, 0.716], sigmas=[1.434, 1.443]
代码（带图的完整代码)
import numpy as np
from sklearn.mixture import GaussianMixture

def fit_normal_mixture(*, n_components, values, random_state, n_init):
values = np.array(values).reshape(-1, 1) # 转换为 2D 数组
nmm = GaussianMixture(n_components, covariance_type=&#39;diag&#39;, random_state=random_state, n_init=n_init)
nmm.fit(values)
means = nmm.means_.flatten().tolist()
sigmas = np.sqrt(nmm.covariances_.flatten()).tolist()
weights = nmm.weights_.flatten().tolist()
return weights, means, sigmas

def sample_normal_mixture(*, weights, means, sigmas, n):
if not np.isclose(sum(weights), 1):
raise ValueError(&quot;Weights must sum to 1&quot;)
components = np.random.choice(len(weights), size=n, p=weights)
return np.random.normal(loc=np.array(means)[components], scale=np.array(sigmas)[components])

# 测试
if __name__ == &#39;__main__&#39;:
# 从正态混合模型生成样本
nmm_sample = sample_normal_mixture(weights=[0.5, 0.5], means=[0, 0], sigmas=[1, 2], n=10000)

# 将样本拟合到正态混合模型
print(fit_normal_mixture(n_components=2, values=nmm_sample, random_state=0, n_init = 10))

附言：是否可以告诉拟合算法使用 0 作为平均值？]]></description>
      <guid>https://stats.stackexchange.com/questions/659851/cant-fit-gaussian-mixture-model-estimates-wrong-parameters</guid>
      <pubDate>Sat, 11 Jan 2025 06:59:18 GMT</pubDate>
    </item>
    <item>
      <title>确保 Fisher 信息矩阵严格正定的条件</title>
      <link>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</link>
      <description><![CDATA[Fisher 信息矩阵定义为：
$$I(\theta):=E\left[\frac{\partial\log f(X;\theta)}{\partial \theta} \mid\theta\right]$$
其中 $f$ 是似然函数。
我正在寻找充分条件 - 最好是关于 $f$ 或 $\log f$ - 以确保 Fisher 矩阵严格正定。
正定性是证明最大似然估计量 (MLE) 渐近一致性的众所周知的临界条件。因此，这一探究具有重要意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</guid>
      <pubDate>Fri, 10 Jan 2025 14:33:43 GMT</pubDate>
    </item>
    <item>
      <title>对于 OLS 假设，随机样本是否需要 IID</title>
      <link>https://stats.stackexchange.com/questions/659821/does-random-sample-need-to-be-iid-for-ols-assumption</link>
      <description><![CDATA[假设要为 OLS 回归 创建样本，我分 2 个阶段 在不同的总体中抽样数据。例如，在一个总体中，我有 5000 个数据点，我从该总体中选择了 1000 个数据。而在另一个总体中，有 3000 个数据点，我从该总体中选择了 500 个数据。
然后我 组合 2 个抽样数据集（因此，组合数据集有 1500 个数据点），并构建横截面 OLS 回归。
我的问题是，在这种情况下，随机样本的 OLS 假设 是否得到满足？对于随机样本，我们是否需要数据为 IID？
在另一个抽样选项中，我有相同的 2 个数据总体。但是对于 1 个样本，我进行了 分层抽样，而对于另一个样本，我进行了 简单随机抽样。然后 合并 2 个抽样数据集。
在进行 OLS 回归时，随机样本假设在这种抽样方法下是否成立？
随机样本假设取自 Wooldridge 的计量经济学入门。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659821/does-random-sample-need-to-be-iid-for-ols-assumption</guid>
      <pubDate>Fri, 10 Jan 2025 11:50:05 GMT</pubDate>
    </item>
    <item>
      <title>R 中 Frank's Copula 负二项式模型中 Theta 参数发散问题</title>
      <link>https://stats.stackexchange.com/questions/659647/issue-with-diverging-theta-parameter-in-negative-binomial-models-with-franks-co</link>
      <description><![CDATA[我尝试使用负二项分布结合 Frank 的 copula 来对足球比赛结果进行建模，以建立依赖结构。每支球队都被分配了单独的进攻和防守参数，并且有主场和客场进球的离散参数，以及 Frank 的 copula 的 theta 参数。
我的方法受到 McHale、Ian 和 Phil Scarf 的论文“国际足球比赛中对方球队进球依赖关系建模”中描述的方法的启发（统计建模，11.3（2011）：219-236）。但是，我没有使用基于 FIFA 世界排名位置差异的参数来对进球依赖关系进行建模（如原始研究），而是对其进行了修改，使用单独的球队参数进行进攻和防守。
不幸的是，在优化过程中，theta 参数在几次迭代后开始发散，我不知道如何解决这个问题。我怀疑 Frank 的 copula 的 theta 参数可能需要限制在特定范围内以确保数值稳定性。但是，我使用的优化函数 (nlm) 不直接支持参数约束，这使得这很难实现。
我的方法：

示例数据：

set.seed(123)

data_model &lt;- data.frame(
Heim = sample(c(&quot;Team A&quot;, &quot;Team B&quot;, &quot;Team C&quot;, &quot;Team D&quot;), 100, 
replace = TRUE),
Gast = sample(c(&quot;Team A&quot;, &quot;Team B&quot;, &quot;Team C&quot;, &quot;Team D&quot;), 100, 
replace = TRUE),
ToreHeim = rpois(100, lambda = 1.5), # 主队进球
ToreGast = rpois(100, lambda = 1.2) # 客队进球
)

# 删除主队与客队平分的比赛
data_model &lt;- data_model[data_model$Heim != data_model$Gast, ]


模型函数：

negloglik_double_nb_copula &lt;- function(params, goals_home, 
goals_visitor, team_home, team_visitor, param_skeleton) {
plist &lt;- relist(params, param_skeleton)
plist$defense &lt;- c(sum(plist$defense)*-1, plist$defense)
names(plist$defense)[1] &lt;-名称（plist$attack[1]）

lambda_home &lt;- exp（plist$attack[team_home] + 
plist$defense[team_visitor] + plist$home）
lambda_visitor &lt;- exp（plist$attack[team_visitor] + 
plist$defense[team_home]）

m1 &lt;- exp（plist$m1）
m2 &lt;- exp（plist$m2）
theta &lt;- exp（plist$theta）

log_lik_home &lt;- dnbinom（goals_home，mu = lambda_home，
size = m1^(-1)，log = FALSE）
log_lik_visitor &lt;- dnbinom(goals_visitor, mu = lambda_visitor, 
size = m2^(-1), log = FALSE)
log_lik_copula &lt;- log(frank_copula_density(log_lik_home, 
log_lik_visitor, theta))

log_lik &lt;- sum(log_lik_copula)
return(log_lik * -1)
}

frank_copula_density &lt;- function(p_home, p_visitor, theta) {
num &lt;- theta * exp(-theta * (p_home + p_visitor)) * 
(1 - exp(-theta))
denom &lt;- ((1 - exp(-theta * p_home)) * 
(1 - exp(-theta * p_visitor)) + exp(-theta) - 1)^2
return(num / denom)
}



初始参数：

parameter_list_copula &lt;- list(
attack = rep(0.2, n_teams),
defense = rep(-0.01, n_teams-1),
home = 0.1,
m1 = 0.1,
m2 = 0.15,
theta = 0.5
)

names(parameter_list_copula$attack) &lt;- all_teams
names(parameter_list_copula$defense) &lt;- all_teams[-1]



优化：

nlm_nb_copula &lt;- nlm(negloglik_double_nb_copula, 
unlist(parameter_list_copula), 
goals_home = data_model$ToreHeim,
goals_visitor = data_model$ToreGast,
team_home = data_model$Heim, 
team_visitor = data_model$Gast,
param_skeleton = param_list_copula, 
print.level = 2, 
iterlim = 10000, hessian = FALSE)

尽管设置了合理的起始值，但经过几次迭代后，优化结果在 theta 参数上出现分歧。
切换到支持参数约束的优化方法（例如，使用带有框约束的 optim）是否有意义？或者有其他推荐的策略来解决这个问题？
任何稳定优化的建议或改进该模型的见解都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659647/issue-with-diverging-theta-parameter-in-negative-binomial-models-with-franks-co</guid>
      <pubDate>Sun, 05 Jan 2025 22:58:36 GMT</pubDate>
    </item>
    <item>
      <title>结合多个调查设计对象的年份，何时适当使用交互项</title>
      <link>https://stats.stackexchange.com/questions/659458/combining-years-for-multiple-survey-design-object-when-to-appropriately-use-inte</link>
      <description><![CDATA[我正在使用 KID（儿童住院数据库）并使用 R 中的调查包。我有两个问题

何时使用 Strata 和 PSU 的交互项：
KID 数据库包含每年重新采样的 PSU（医院），而 Strata 包括 10% 的健康新生儿出院和 80% 的其他出院。
我不确定何时在定义 svydesign() 的 id 和 strata 参数时使用交互项。

id 参数应该使用 ~ PSU 还是 ~ interaction(PSU, YEAR) 来解释医院的年度重新采样？
strata 参数应该使用 ~ strata 还是 ~ interaction(strata, YEAR)？
我想确保设计反映了调查结构。

子集化后是否可以合并 survey.design 对象？还是需要先合并原始数据框，创建一个调查设计对象，然后再子集化？

例如，如果我每年按人口统计组对 survey.design 对象进行子集化，是否可以合并生成的对象？]]></description>
      <guid>https://stats.stackexchange.com/questions/659458/combining-years-for-multiple-survey-design-object-when-to-appropriately-use-inte</guid>
      <pubDate>Thu, 02 Jan 2025 16:44:23 GMT</pubDate>
    </item>
    <item>
      <title>DF 和 ADF 检验结果相矛盾</title>
      <link>https://stats.stackexchange.com/questions/657656/conflicting-results-in-df-and-adf-tests</link>
      <description><![CDATA[我正在对 globtemp 数据集进行单位根检验，该数据集显然是具有趋势和季节性（非平稳）的序列。但是，当应用简单的 Dickey-Fuller 检验时，我获得的 p 值很小，导致拒绝零假设并表明该序列是平稳的。
同时，使用增强版本 (ADF) 执行测试，使用 R 的默认滞后数 (k)，p 值不会拒绝零假设，表明时间序列是非平稳的。话虽如此，我很困惑，不明白这种差异。为什么在简单的 DF 测试（k=0）的情况下，测试无法产生真实的结果？此外，如果测试对“k”的选择如此敏感，那么最好的方法是什么？我们应该始终依赖默认值吗？
此外，我读到残差中存在自相关违反了测试中残差不相关的假设，可能会导致错误的结果。因此，我还评估了第一次测试（DF）残差中是否存在自相关，它们的行为与白噪声的行为一致（我也使用 Box-Ljung 对此进行了测试）。这让我对上面提到的不一致的结果更加困惑。
可以检查下面我所做的代码：
library(tseries)

globtemp &lt;- stats::ts(
c(-0.32, -0.32, -0.4, -0.39, -0.65, -0.43, -0.4, -0.52, -0.3, -0.12,
-0.4, -0.42, -0.39, -0.45, -0.35, -0.36, -0.19, -0.14, -0.37, -0.22,
0, -0.08, -0.24, -0.36, -0.49, -0.27, -0.19, -0.43, -0.29, -0.3,
    -0.29、-0.29、-0.28、-0.23、-0.04、-0.02、-0.24、-0.42、-0.35、-0.16、
    -0.17、-0.09、-0.13、-0.16、-0.14、-0.14、0.1、-0.03、0.03、-0.18、
    -0.06、0.04、0.02、-0.13、0.03、-0.06、0.02、0.13、0.13、-0.03、
    0.15、0.12、0.1、0.04、0.11、-0.04、0.01、  0.13、-0.01、-0.06、
    -0.14、-0.02、0.04、0.14、-0.07、-0.06、-0.17、0.1、0.1、0.05、
    -0.01、0.08、0.02、0.02、-0.26、-0.16、-0.09、-0.02、-0.12、0.03、
    0.04、-0.11、-0.07、0.19、-0.07、-0.05、-0.22、0.16、0.09、0.14、
    0.28、0.39、0.07、0.29、0.11、0.11、0.16、 0.32, 0.35, 0.25,
0.47, 0.41, 0.13),
start=1880, end = 1992)

plot(globtemp)

adf.test(globtemp, k=0) #DF 检验
#Dickey-Fuller = -3.4235, 滞后阶数 = 4, p 值 = 0.05414

dx &lt;- diff(globtemp) 
x_lag &lt;- globtemp[-length(globtemp)] 
df_model &lt;- lm(dx ~ x_lag) 
summary(df_model)

residuals_df &lt;- resid(df_model)
acf(residuals_df, 50, main = &quot;&quot;) #否自相关
Box.test(residuals_df, lag = 15, type = &quot;Ljung-Box&quot;)

adf.test(globtemp) #ADF 默认为 &quot;k&quot;
#Dickey-Fuller = -3.4235, 滞后阶数 = 4, p 值 = 0.05414
]]></description>
      <guid>https://stats.stackexchange.com/questions/657656/conflicting-results-in-df-and-adf-tests</guid>
      <pubDate>Fri, 22 Nov 2024 04:44:14 GMT</pubDate>
    </item>
    <item>
      <title>治疗方案的无偏估计与随时间变化的治疗和结果形成对比</title>
      <link>https://stats.stackexchange.com/questions/630973/unbiased-estimation-of-treatment-regime-contrast-with-time-varying-treatment-and</link>
      <description><![CDATA[我在寻找一种策略来从观察到的数据中识别我正在寻找的因果关系时遇到了一些麻烦。我假设以下 DAG：

其中 $Z$ 是抛硬币（随机化）的结果，$A$ 是感兴趣的曝光，$Y$ 是感兴趣的结果。我假设 $A$ 是二进制（0 或 1），$Y$ 是连续的。感兴趣的估计量为：
$$E\left(Y_6^{\bar{A} = \bar{1}} - Y_6^{\bar{A} = \bar{0}}\right)$$
其中 $Y_6^{\bar{A}=\bar{1}}$ 表示如果在每个考虑的时间点将 $A$ 设置为 $1$，则在 $t = 6$ 时观察到的 $Y$ 的值。 $Y_6^{\bar{A}=\bar{0}}$ 遵循相同的定义，但 $A$ 在所有时间点均设置为 $0$。所有变量均完全观察到，没有任何缺失值或测量误差。
我确实认为应该能够根据数据以无偏的方式估计这种影响，但我不确定如何做到这一点。我曾考虑过使用混合模型，但这并不能真正给我我感兴趣的边际估计。
结构边际模型是否有效？如果是，我该如何将其应用于这些数据？如果有人能指出正确的方向，那就太好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/630973/unbiased-estimation-of-treatment-regime-contrast-with-time-varying-treatment-and</guid>
      <pubDate>Fri, 10 Nov 2023 13:53:05 GMT</pubDate>
    </item>
    <item>
      <title>拟合优度是检验相关预测因子有用性的合理方法吗？</title>
      <link>https://stats.stackexchange.com/questions/620586/is-goodness-of-fit-a-reasonable-way-to-test-the-usefulness-of-correlated-predict</link>
      <description><![CDATA[在假设检验框架下，我想对 $Y \sim X_1 + X_2 + Z$ 进行建模，其中 X_1 和 X_2 是同一构造的两个相关且可能相关的度量。
使用 ANOVA 来测试模型拟合度是否合理，以此来测试此构造是否与 Y 有关系？
以下是一些 R 伪代码，概述了我所提出的建议：
fit_1 = lm(y ~ z, data = df)
fit_2 = lm(y ~ x1 + y1 + z, 
data = df)

anova(fit_1, fit_2)
]]></description>
      <guid>https://stats.stackexchange.com/questions/620586/is-goodness-of-fit-a-reasonable-way-to-test-the-usefulness-of-correlated-predict</guid>
      <pubDate>Wed, 05 Jul 2023 13:39:54 GMT</pubDate>
    </item>
    <item>
      <title>EDA（探索性数据分析）和数据分析之间有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/558839/what-is-the-difference-between-eda-explorative-data-analysis-and-data-profilin</link>
      <description><![CDATA[我有点困惑，似乎两者都使用相同/相似的技术。这有什么区别吗？还是是一样的？
有人可以解释一下吗？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/558839/what-is-the-difference-between-eda-explorative-data-analysis-and-data-profilin</guid>
      <pubDate>Fri, 31 Dec 2021 10:18:52 GMT</pubDate>
    </item>
    </channel>
</rss>