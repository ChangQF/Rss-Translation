<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 04 Nov 2024 15:19:20 GMT</lastBuildDate>
    <item>
      <title>对 beta 值进行约束的 OLS 拟合</title>
      <link>https://stats.stackexchange.com/questions/656730/fitting-ols-with-constraint-on-the-betas</link>
      <description><![CDATA[假设我的模型看起来像 $y=\beta_1x_1 + \beta_2x_2 + \beta_3x_3$，但有一个问题：我想强制执行 $\beta_1=\beta_3$。如何在频率派和贝叶斯派设置中做到这一点？具体来说，对于贝叶斯路线，我使用的是 pymc，有什么方法可以实现这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656730/fitting-ols-with-constraint-on-the-betas</guid>
      <pubDate>Mon, 04 Nov 2024 14:28:34 GMT</pubDate>
    </item>
    <item>
      <title>f-散度的数据处理不等式证明</title>
      <link>https://stats.stackexchange.com/questions/656729/proof-of-data-processing-inequality-for-f-divergence</link>
      <description><![CDATA[关于$f$-散度的数据处理不等式。对于任何马尔可夫链$X \to Y \to Z$，一对测度$P_{X,Y,Z}$和$Q_{X,Y,Z}$具有共同马尔可夫核$P_{Z|Y} = Q_{Z|Y}$，一个凸映射$f : (0, \infty) \to \mathbb{R}_+$，以及任意函数$g : \mathcal{X} \times \mathcal{Z} \to \mathbb{R}$，我们有
$$
D_f(P_{X,Y} \| Q_{X,Y}) \geq D_f(P_{X,Z} \| Q_{X,Z}) \geq D_f(P_{g(X,Z)} \| Q_{g(X,Z)})。
$$
如何证明这个不等式？我无法将第一项 $\int dP_{XY} \cdots$ 中的期望转换为第二项 $\int dP_{YZ} \cdots$ 中的期望。我知道，由于马尔可夫特性，我们有 $dP_{XYZ} = dP_X dP_{Y|X} dP_{Z|Y}$。我不确定如何在这里使用它。]]></description>
      <guid>https://stats.stackexchange.com/questions/656729/proof-of-data-processing-inequality-for-f-divergence</guid>
      <pubDate>Mon, 04 Nov 2024 14:09:33 GMT</pubDate>
    </item>
    <item>
      <title>“均值差异”与“差值均值”</title>
      <link>https://stats.stackexchange.com/questions/656728/difference-of-the-means-vs-mean-of-differences</link>
      <description><![CDATA[我是统计实施的新手；据我所知，它们是不同的。请纠正我错的地方。
一个取每个数据点的成对差异[差异的平均值]，另一个取平均值 A 并从平均值 B 中减去它[平均值的差异]。虽然可以计算出相同的差异，但每个差异的置信区间是不同的。我不知道在哪种情况下使用哪种公式。
例如，我有一组来自样本 X、Y 或 Z 的人员的数据。有一个连续变量，我们称之为“沟通技巧”，范围从 0 到 100。我想测试一下样本在统计上是否彼此不同，置信度为 95%。
这两个测试给出了两个不同的置信区间。在这种情况下我会使用哪种测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/656728/difference-of-the-means-vs-mean-of-differences</guid>
      <pubDate>Mon, 04 Nov 2024 13:57:05 GMT</pubDate>
    </item>
    <item>
      <title>我可以执行 IV 回归吗，其中第一阶段的估计没有固定效应，但第二阶段包括固定效应？</title>
      <link>https://stats.stackexchange.com/questions/656727/can-i-perform-an-iv-regression-where-the-first-stage-is-estimated-without-fixed</link>
      <description><![CDATA[我希望执行 IV 回归，其中第一阶段的估计没有固定效应，但第二阶段的估计有固定效应。这可能吗？这种方法有什么明显的问题吗？以前有没有进行过这种操作的论文？]]></description>
      <guid>https://stats.stackexchange.com/questions/656727/can-i-perform-an-iv-regression-where-the-first-stage-is-estimated-without-fixed</guid>
      <pubDate>Mon, 04 Nov 2024 13:12:16 GMT</pubDate>
    </item>
    <item>
      <title>不同大小样本的卡方</title>
      <link>https://stats.stackexchange.com/questions/656725/chi-squared-for-samples-of-different-sizes</link>
      <description><![CDATA[我想测试三个不同样本 X、Y 和 Z 中分类变量的独立性。每个样本可以是 A 类，也可以是 B 类。这似乎是卡方的一个简单实现。但是，X、Y 和 Z 的样本分别为 2,500、2,500 和 5,000。当样本大小不同时，如何计算“预期”值？
我也知道可以用 Python 或 R 来实现；我实际上是用 Python 工作的，但更喜欢手工进行测试，这样我就能理解为什么数字会这样。
预期值是 3,333、3,333 和 3,333 吗？或者它们只是“显而易见”的答案？TIA 回答新手问题！]]></description>
      <guid>https://stats.stackexchange.com/questions/656725/chi-squared-for-samples-of-different-sizes</guid>
      <pubDate>Mon, 04 Nov 2024 13:04:11 GMT</pubDate>
    </item>
    <item>
      <title>通过 svd 进行典型相关分析</title>
      <link>https://stats.stackexchange.com/questions/656720/canonical-correlation-analysis-via-svd</link>
      <description><![CDATA[为了我自己的理解，我尝试使用交叉积和 svd 重现 R CCA::cc 中的典型相关结果。我尝试了几种方法，但都无法正确执行，您能提供一些见解吗？
这是使用 CCA 包的代码：
library(CCA)
data(nutrimouse)
X=as.matrix(nutrimouse$gene[,1:10])
Y=as.matrix(nutrimouse$lipid)

X &lt;- scale(X) # 缩放并居中的 40x10 矩阵
Y &lt;- scale(Y) # 缩放并居中的 40x21 矩阵

res.cc &lt;- cc(X,Y)

我尝试过：
cp &lt;- crossprod(X, Y)
cca_svd &lt;- svd(cp)

我应该怎么做现在如何获取 X 和 Y 矩阵的典型相关系数和系数？
ChatGPT 给出了以下内容，但似乎不正确：
cp &lt;- crossprod(X, Y)

# 步骤 2：对交叉积执行 SVD
cca_svd &lt;- svd(cp)

# 步骤 3：计算典型相关
# 典型相关是来自 SVD 的奇异值
canonical_correlations &lt;- cca_svd$d^2 / (1 + cca_svd$d^2) # 针对典型相关进行调整

# 步骤 4：计算典型变量
# 典型变量可以从 U 和 V 矩阵中获得
U &lt;- cca_svd$u
V &lt;- cca_svd$v

# 典型变量
canonical_variates_X &lt;- X %*% U
canonical_variates_Y &lt;- Y %*% V

例如，ChatGPT 中的典型相关性为：
canonical_correlations
[1] 1.00 1.00 1.00 1.00 1.00 0.99 0.99 0.93 0.85 0.77

而上面的 CCA::cc 给出：
res.cc$cor
[1] 0.99 0.98 0.94 0.92 0.81 0.72 0.64 0.61 0.55 0.36
]]></description>
      <guid>https://stats.stackexchange.com/questions/656720/canonical-correlation-analysis-via-svd</guid>
      <pubDate>Mon, 04 Nov 2024 10:57:58 GMT</pubDate>
    </item>
    <item>
      <title>具有删失协变量的风险——我应该使用哪种方法？</title>
      <link>https://stats.stackexchange.com/questions/656719/risk-with-censored-covariates-which-method-should-i-use</link>
      <description><![CDATA[TL;DR - 我的数据包括：

幼儿因家庭伤害而去医院的年龄。
幼儿爬行、走路和跑步的年龄记录。记录受到审查，因为有些幼儿在开始（例如）走路之前就到了医院。

我想预测“家庭伤害风险”。我应该怎么做？
现在更详细一点：我有因家庭伤害而去医院的幼儿的数据。每个幼儿每隔一段时间都会去社区的护士那里看望，护士会记录幼儿是否可以（A）爬行、（B）走路、（C）跑步。进展是单调的：走路的幼儿肯定可以爬行，而跑步的幼儿不会停止跑步。我认为幼儿年龄和达到上述活动水平 A、B 和 C 的年龄是家庭受伤风险的指标，因为活动能力更强的幼儿受伤的几率更高。
对于特定的幼儿，我想计算家庭受伤的风险指标。我的想法：

我当然无法计算受伤的概率$\Pr(injury)$，因为我没有未去过医院的幼儿的记录。
出于类似的原因，我不能天真地使用逻辑回归。
也许可以计算相对于某个基线年龄的优势比并使用罕见疾病近似值？但是，我该如何整合关于活动水平 A、B 和 C 的信息呢？
我认为 Cox 回归在这里不合适，因为我实际上并没有对事件发生时间进行建模。

请建议定义和查找幼儿“受伤风险”的方法。我也希望您能解释一下我提到的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/656719/risk-with-censored-covariates-which-method-should-i-use</guid>
      <pubDate>Mon, 04 Nov 2024 10:41:05 GMT</pubDate>
    </item>
    <item>
      <title>如何对概率 $\Pr((U,V)\in A)$ 进行核平滑​​估计并显示其一致性？</title>
      <link>https://stats.stackexchange.com/questions/656718/how-to-do-kernel-smoothed-estimation-of-the-probability-pru-v-in-a-and-sh</link>
      <description><![CDATA[假设我有兴趣用随机样本$\{(U_i,V_i)\}_{i=1}^N$估计$p=\Pr((U,V)\in A)$的概率。最简单的方法是使用样本均值：$\widehat{p}=1/N\times \sum_{i=1}^N 1((U_i,V_i)\in A)$，即基于指示函数的相对频率估计量，弱大数定律保证$\widehat{p}$的一致性。但指示函数不平滑，我想要一个平滑的估计量。我知道 Nadaraya-Watson 核密度估计量，我正在考虑提出一些可能看起来类似的内容：$\widehat{p}_s=1/N\times \sum_{i=1}^N \frac{1}{h^2} k(\frac{(U_i,V_i)???}{h})????$，其中 $k(\cdot)$ 是核函数，$h$ 是带宽。我遇到了一个困难，不知道在核函数中要写什么（问号），因此不知道如何继续。
因此，我的问题是，如何为概率构建一个平滑估计量（基于核平滑）？什么时候是一致的？
如果您可以列出内核和带宽的条件，以便估计量对于感兴趣的概率是一致的，并在您的条件下证明其一致性，那就太好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/656718/how-to-do-kernel-smoothed-estimation-of-the-probability-pru-v-in-a-and-sh</guid>
      <pubDate>Mon, 04 Nov 2024 10:25:09 GMT</pubDate>
    </item>
    <item>
      <title>时间序列模型中的递归一步预测</title>
      <link>https://stats.stackexchange.com/questions/656717/recursive-one-step-forecasting-in-timeseries-model</link>
      <description><![CDATA[我正在尝试为随机森林模型实施递归一步预测方法。
这个想法是以迭代方式获得 12 个月的预测，其中每个预测在下一个预测之前成为历史记录的一部分。
鉴于我没有重新训练模型，并且模型的误差在每个递归预测步骤中都会累积，我预计误差图会稳步增加。但是，没有这样的趋势。
我想知道实施过程中是否存在任何问题。我想在现实世界中测试模型的预测能力，我们迭代地预测下一个值（例如，如果我想进行 12 个月的预测）。
import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt

# 设置随机种子以实现可重复性
np.random.seed(1)

# 创建日期范围
date_rng = pd.date_range(start=&#39;2018-01-01&#39;, end=&#39;2024-12-31&#39;, freq=&#39;MS&#39;)
n_points = len(date_rng)

# 趋势成分（线性增长）
trend = np.linspace(100, 200, n_points)
seasonal = 20 * np.sin(2 * np.pi * np.arange(n_points) / 12)
cyclical = 30 * np.sin(2 * np.pi * np.arange(n_points) / (12 * 3))
noise = np.random.normal(0, 10, n_points)
values = trend + seasonal + cyclical + noise

df = pd.DataFrame({
&#39;date&#39;: date_rng,
&#39;value&#39;: values
})

# 格式化数据
df[&#39;year&#39;] = df[&#39;date&#39;].dt.year
df[&#39;month&#39;] = df[&#39;date&#39;].dt.month
df[&#39;value&#39;] = df[&#39;value&#39;].round(2)

# 构建时间特征
df.index = pd.to_datetime(df.date)
df[&#39;quarter&#39;] = df.index.quarter
df[&#39;month&#39;] = df.index.month
df[&#39;year&#39;] = df.index.year
df[&#39;sin_month&#39;] = np.sin(2 * np.pi * df.index.month / 12)
df[&#39;cos_month&#39;] = np.cos(2 * np.pi * df.index.month / 12)

# 构建滞后
num_lags = 12
lagged_columns = {f&#39;lag_{lag}&#39;: df[&#39;value&#39;].shift(lag) for lag in range(1, num_lags + 1)}
df = df.assign(**lagged_columns)
df.dropna(inplace=True)

# 简单移动平均线 (SMA)
sma_window_size = 12
df[f&#39;SMA_{sma_window_size}&#39;] = df[&#39;value&#39;].rolling(window=sma_window_size).mean()

# 指数移动平均线 (EMA)
ema_span_size = 9
df[f&#39;EMA_{ema_span_size}&#39;] = df[&#39;value&#39;].ewm(span=ema_span_size).mean()

# 拆分数据并拟合模型
split_point = &#39;2023-12-31&#39;

# 拆分为训练和测试
train = df.query(&#39;date &lt;= @split_point&#39;)
test = df.query(&#39;date &gt; @split_point&#39;)

# 创建训练特征和目标
X_train = train.drop(columns=[&#39;value&#39;, &#39;date&#39;])
y_train = train[&#39;value&#39;]

# 创建测试特征和目标
X_test = test.drop(columns=[&#39;value&#39;, &#39;date&#39;])
y_test = test[&#39;value&#39;]

rf_model = RandomForestRegressor(n_estimators=100, 
max_depth=10,
random_state=0)
rf_model.fit(X_train, y_train)

# 预测步骤数
num_forecasts = 12 
all_forecasts = {}

# 获取最后一个训练样本
X_last = train.iloc[[-1]].drop(columns=[col for col in train.columns.tolist() if col not in X_train.columns.tolist()]) # 删除不存在的标识符X_train

forecasts = []

for step in range(num_forecasts):

# 进行预测
y_pred = rf_model.predict(X_last.values.reshape(1, -1))[0]
Forecasts.append(y_pred)

# 更新滞后
X_last_series = pd.Series(X_last.iloc[0])
lags = X_last_series.filter(like=&#39;lag_&#39;).copy().shift(1, axis=0)
lags[&#39;lag_1&#39;] = y_pred
X_last_series.update(lags)

# 必要时更新季节性或静态特征
if &#39;month&#39; in X_last_series.index and &#39;quarter&#39; in X_last_series.index:
# 月份和季度
current_month = X_last_series[&#39;month&#39;] % 12 + 1

X_last_series[&#39;month&#39;] = current_month
X_last_series[&#39;quarter&#39;] = (current_month - 1) // 3 + 1

# 年份（如果月份回绕到 1 月，则增加）
if current_month == 1:
X_last_series[&#39;year&#39;] += 1

# 周期性特征（月份）的正弦变换
X_last_series[&#39;sin_month&#39;] = np.sin(2 * np.pi * current_month / 12)
X_last_series[&#39;cos_month&#39;] = np.cos(2 * np.pi * current_month / 12)

# 更新滚动特征
if f&#39;SMA_{sma_window_size}&#39; in X_last_series.index:
past_values = X_last_series.filter(like=&#39;lag_&#39;).values[:sma_window_size - 1]
X_last_series[f&#39;SMA_{sma_window_size}&#39;] = np.mean(np.append(past_values, y_pred))

if f&#39;EMA_{ema_span_size}&#39; in X_last_series.index:
ema_alpha = 2 / (ema_span_size + 1)
X_last_series[f&#39;EMA_{ema_span_size}&#39;] = ema_alpha * y_pred + (1 - ema_alpha) * X_last_series[f&#39;EMA_{ema_span_size}&#39;]

# 更新 X_last 以进行下一个预测步骤
X_last = X_last_series.to_frame().T

def calculate_mape(y_true, y_pred):
return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

steps_mape = []
for i in range(num_forecasts): 
steps_mape.append(calculate_mape(y_test[i], Forecasts[i]))

plt.plot(steps_mape)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/656717/recursive-one-step-forecasting-in-timeseries-model</guid>
      <pubDate>Mon, 04 Nov 2024 10:13:37 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 MBESS 包如何处理缺失值？</title>
      <link>https://stats.stackexchange.com/questions/656716/how-are-missing-values-dealt-with-in-the-mbess-package-in-r</link>
      <description><![CDATA[我目前正在用 R 计算我的量表的麦当劳 Omega。文献建议使用 MBESS 包中的 ci.reliability 函数来获取置信区间。但是，我还没有找到任何关于 MBESS 如何处理缺失值的文档。如果能提供关于此问题的任何信息，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/656716/how-are-missing-values-dealt-with-in-the-mbess-package-in-r</guid>
      <pubDate>Mon, 04 Nov 2024 09:52:19 GMT</pubDate>
    </item>
    <item>
      <title>当阳性事件案例样本量较少时，应如何抽样才能节省成本？</title>
      <link>https://stats.stackexchange.com/questions/656713/when-the-sample-size-of-positive-event-cases-is-small-how-should-the-cases-be-s</link>
      <description><![CDATA[有一个问题困扰了我很久，查阅了很多资料都没有找到准确的答案。我的问题是：假设我有10000个病人，其中只有100个死亡病人，9900个幸存病人，为了降低收集病历的成本，我打算从9900个幸存病人中随机抽取200个病人作为幸存组，然后和100个死亡病人合并，最终样本为300个病人。这种抽样方法可以接受吗？如果可以，这种抽样方法属于哪一类？是不是不等比例分层抽样？]]></description>
      <guid>https://stats.stackexchange.com/questions/656713/when-the-sample-size-of-positive-event-cases-is-small-how-should-the-cases-be-s</guid>
      <pubDate>Mon, 04 Nov 2024 08:36:45 GMT</pubDate>
    </item>
    <item>
      <title>收敛速度的平方 $\|\hat{A}-A\|_F^2$</title>
      <link>https://stats.stackexchange.com/questions/656712/square-of-the-convergence-rate-hata-a-f2</link>
      <description><![CDATA[在高维设置中，如果我们有一个估计量$\hat{A}\in\mathbb{R}^{n\times n}$，我们总是试图得到通过矩阵范数衡量的收敛速度，例如$\|\hat{A}-A\|_F$。
现在，如果我已经以很高的概率获得了收敛速度$\|\hat{A}-A\|_F\le c\sqrt{\frac{\log p}{n}}$，我是否可以直接获得收敛速度$\|\hat{A}-A\|_F^2\le c^2{\frac{\log p}{n}}$?
直觉上，我觉得这个结果是正确的。如果它成立，那么它对所有矩阵范数都成立吗？例如，Frobenius 范数和谱范数。]]></description>
      <guid>https://stats.stackexchange.com/questions/656712/square-of-the-convergence-rate-hata-a-f2</guid>
      <pubDate>Mon, 04 Nov 2024 08:21:18 GMT</pubDate>
    </item>
    <item>
      <title>因变量的水平可能会调节预测因子的影响</title>
      <link>https://stats.stackexchange.com/questions/656711/level-of-dependent-variable-may-moderate-the-effects-of-predictors</link>
      <description><![CDATA[这与我自己的数据无关，但我被要求就以下情况提供建议：
一位研究人员向一组参与者提供了某种自我报告工具。他们想看看分数中是否存在性别和年龄差异，但他们认为，对于在此工具上得分低于某个阈值（假设为 100 分）的参与者和高于该阈值的参与者，性别和年龄对分数的影响将有所不同，并希望对此进行调查。
我想到的唯一方法是创建一个二元变量，指示参与者的得分是低于还是高于 100 分，并包括性别和年龄与此变量之间的相互作用，但这不可能是正确的，因为基于因变量的变量肯定不应该作为预测因子？但有什么方法可以做到这一点，或者有什么办法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656711/level-of-dependent-variable-may-moderate-the-effects-of-predictors</guid>
      <pubDate>Mon, 04 Nov 2024 08:19:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 Bootstrap 与交叉验证来评估机器学习模型的预测性能</title>
      <link>https://stats.stackexchange.com/questions/656710/bootstrap-vs-crossvalidation-for-assessing-the-predictive-performance-of-a-machi</link>
      <description><![CDATA[我正在尝试在引导和交叉验证之间做出选择，以便彻底评估预测模型性能。
引导：

使用替换对数据进行采样，创建 B &gt; 1000（或更多）个不同的训练集，其中由于使用替换采样，每个观察结果都被独立处理！这意味着经验分布函数被用作抽取样本的真实世界分布的替代品。
动态使用袋外 (OOB) 观测值作为保留集：这消除了对单独保留集的需求，并且可以提供更可靠的样本外预测性能估计。
可能捕获更多真实世界方差（通过替换采样，即利用经验分布函数）

如果我必须评估两个不同的模型，我会

生成 B=1000 ... 训练数据集的引导重采样
在 B 个不同的袋外测试样本集上评估这两个模型
计算配对模型性能差异（性能模型 1 - 性能模型 2，其中差异取自相同的 OOB 测试集），配对将用于https://en.wikipedia.org/wiki/Variance_reduction
制作配对模型性能差异的直方图
如果模型性能的密度明显偏离 0，则其中一个模型优于另一个模型（由此也可以设计一些测试以获得 95% 的改进确定性...）

交叉验证：

将数据分成几部分，使用不同的部分进行训练和测试。
可以更有效率，尤其是在数据有限的情况下。
可能导致“相关”训练集，尤其是在 LOOCV 中（训练集几乎没有变化，除了一个观察值）

为了比较两个模型，我会做与 bootstrap 情况相同的事情（只是没有袋外测试样本，但在 LOOCV 的情况下，最大 N= 观察值不同的保留集）。
问题：
鉴于 bootstrap 可以在训练集中引入更多变化（通过替换重采样）并利用 OOB 数据进行验证，与交叉验证（本质上是无替换重采样）相比，它是否会提供更现实的样本外性能估计？尤其是潜在的“相关性” 交叉验证训练集之间是否存在重大问题？
PS：我尝试搜索 stackoverflow 并提出了类似的问题，但它们没有讨论 CV 训练集的潜在相关性问题：

Bootstrap 或 jack-knife 用于预测模型的交叉验证？（无答案）
了解用于验证和模型选择的 bootstrapping
交叉验证和引导法在估计预测误差方面的差异（没有明确的答案哪个更可靠）
交叉验证或引导法评估分类性能？（这个问题似乎很直接，但公认的答案主要涉及只有一个测试训练分割（CV 的退化形式，显然没有像 k 倍 CV 那样的多个测试训练分割），Frank Harell 有一个答案 https://stats.stackexchange.com/a/71189/298651 链接 https://hbiostat.org/doc/simval.html 得出一个结论“普通引导法优于或等于所有尝试过的交叉验证策略”，但这在他的回答中没有明确讨论...)
分类测试的交叉验证与随机抽样（没有明确的结论，无所谓，但有趣的论文？）
]]></description>
      <guid>https://stats.stackexchange.com/questions/656710/bootstrap-vs-crossvalidation-for-assessing-the-predictive-performance-of-a-machi</guid>
      <pubDate>Mon, 04 Nov 2024 07:58:08 GMT</pubDate>
    </item>
    <item>
      <title>带 Cholesky 分解的脉冲响应函数</title>
      <link>https://stats.stackexchange.com/questions/656709/impulse-response-function-with-cholesky-decomposition</link>
      <description><![CDATA[考虑以下 VAR 模型。
$A_0 y_t =\sum_{i=1}^{p} A_i y_{t-i} +\epsilon_t $
其中 $y_t =[oil_t, \pi^e_t, \pi_t ]$ 且 $\epsilon_t$ 是正交结构冲击向量。

以伴随形式定义上述方程。
$A_0 y_t =\sum_{i=1}^{p} A_i y_{t-i} +\epsilon_t $
$y_t =\sum_{i=1}^{p} A^{-1}_0A_i y_{t-i} +A^{-1}_0\epsilon_t $
$X_t =\Lambda X_{t-1}+v_t$
设 $E(v_t&#39; v_t)=\Omega$ , $\tilde{A_0^{-1}}=chol(\Omega)$ 和 $e_j$ 为行向量，第 $j$ 个元素为 1，其他元素为 0。
然后脉冲响应函数变量 $j$ 至 $10\%$ 水平石油冲击 $k$，$\Psi_j^k$ 为
$\Psi_j^k=e_j \Lambda^k \xi$
其中 $\xi=\frac{0.1 \times \tilde{A_0^{-1}}e_1&#39; }{e_1 \tilde{A_0^{-1}} e_1&#39;}$
我跟进了这一点：变量 $j$ 水平的脉冲响应 $k$ = $ e_j \Lambda^k$
但仍然无法理解如何解释 $\xi$ 的分子和分母。
$\tilde{A_0^{-1}}=chol(\Omega)$ 所以 $\Omega = \tilde{A_0^{-1}}\tilde{A_0^{-1}}&#39;$,
那么如果我们想从 var-cov 矩阵中得到导数，我们不应该使用 $\Omega$ 矩阵吗？
为什么 $\xi$ 使用 $\tilde{A_0^{-1}}$?]]></description>
      <guid>https://stats.stackexchange.com/questions/656709/impulse-response-function-with-cholesky-decomposition</guid>
      <pubDate>Mon, 04 Nov 2024 07:54:45 GMT</pubDate>
    </item>
    </channel>
</rss>