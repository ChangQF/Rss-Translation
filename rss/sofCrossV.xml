<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 02 Feb 2024 21:12:19 GMT</lastBuildDate>
    <item>
      <title>报告简单时间序列趋势分析的 R^2 值是否正确？</title>
      <link>https://stats.stackexchange.com/questions/638432/is-it-correct-to-report-r2-value-for-simple-time-series-trend-analyses</link>
      <description><![CDATA[我想知道为简单的趋势分析报告 R^2 值是否有意义。例如，温度或水流随时间变化的趋势。我知道，对于线性回归，R^2 是有意义的，因为它是对 y 中的方差如何由 x 的变化来解释的估计&gt; 即，您的最佳拟合线对实际数据的预测效果如何。然而，对于时间序列x（时间）来说并不是真正的解释变量。也就是说，趋势分析更多的是一种相关性测量或描述性统计，因此时间如何解释 y 的变化是没有意义的。这是正确的吗？
互联网似乎认为趋势分析和回归是同一件事，但这不是我过去被告知的。不幸的是，我找不到或目前无法访问可以为我提供一些见解的权威参考资料。
这个问题来自于在某些软件中使用一个函数，该函数可以计算趋势线，很像Excel的趋势线函数（线性、多项式等），但它不提供R^2值。另一位用户期望 R^2 值，我对这个期望感到惊讶。有一个回归包确实提供了正确报告回归结果所需的指标，包括R^2。我们是否应该为函数添加一个 R^2 值，或者这实际上只是一个回归指标与趋势指标。
那么，有两个问题：

我是否应该提供 R^2 指标以进行趋势分析（时间序列数据）。
是否有权威参考资料，最好是公开的
可访问（互联网）。
]]></description>
      <guid>https://stats.stackexchange.com/questions/638432/is-it-correct-to-report-r2-value-for-simple-time-series-trend-analyses</guid>
      <pubDate>Fri, 02 Feb 2024 21:06:52 GMT</pubDate>
    </item>
    <item>
      <title>A/B 测试：一种对照和多种变体的最佳分流比</title>
      <link>https://stats.stackexchange.com/questions/638431/a-b-test-optimal-split-ratio-for-one-control-and-multiple-variants</link>
      <description><![CDATA[我阅读了 kohavi 等人 2022 部分7 当您在 A/B 测试中进行多种处理时，均匀分配（例如，如果 1 个对照和 3 个处理，则为每个处理分配 25%）并不是执行测试（以最大化功效）的最佳方式。有人可以澄清这是真的还是我误读了？我担心的是，我误解了这种最佳分配的背景，它特别讨论的是在使用一种对照的情况下运行多个实验，而不是使用多个变体的一个实验（或者没有区别？）
此外，给予 Control 的最佳比例公式为 $\frac{1}{\sqrt{k}+1}$ 其中 $k$ 是治疗变体的数量，虽然推导很简单，但我感到困惑的部分是为什么假设 Control 应该更大？更具体地说，最佳控制大小是通过最小化 $\frac{k}{1-x}+\frac{1}{x}$ 来计算的，其中 $x$ 是控件的大小，$k$ 是处理次数，但此公式假设控件应一开始就更大，我不明白为什么会这样？]]></description>
      <guid>https://stats.stackexchange.com/questions/638431/a-b-test-optimal-split-ratio-for-one-control-and-multiple-variants</guid>
      <pubDate>Fri, 02 Feb 2024 20:54:30 GMT</pubDate>
    </item>
    <item>
      <title>gamm4 对象的 gam 和 mer 部分之间的标准误差差异</title>
      <link>https://stats.stackexchange.com/questions/638430/differences-of-standard-errors-between-gam-and-mer-parts-of-a-gamm4-object</link>
      <description><![CDATA[我想从安装了 gamm4 的模型中提取固定效应的估计值，并且我注意到对象的 $mer 部分中的标准误差不存在不完全匹配 $gam 部分 SE。
使用与 gamm4 文档相同的示例。
## 来自 gamm4 手册
设置.seed(0)
dat &lt;- gamSim(1,n=400,scale=2) ## 模拟 4 项加性真值
## 现在添加 20 级随机效果“fac”...
dat$fac &lt;- fac &lt;- as.factor(sample(1:20,400,replace=TRUE))
dat$y &lt;- dat$y + model.matrix(~fac-1)%*%rnorm(20)*.5
br &lt;- gamm4(y~s(x0)+x1+s(x2),data=dat,random=~(1|fac), REML = TRUE)

虽然固定效应完全相同，但协方差不同：
max(abs(coef(br$gam)[1:2]-fixef(br$mer)[1:2]))
## [1] 0
max(abs(vcov(br$gam)[1:2, 1:2]-vcov(br$mer)[1:2, 1:2]))
## [1] 0.001152073

现在，这些差异并没有那么大，但我仍然感到有点惊讶
因为，据我了解， gam 部分仅包含转换后的
结果是lme4返回的mer部分，这些差异看起来有点大
不仅仅是一些舍入误差。
如果使用不受惩罚的加性项，并比较与之对应的固定参数的协方差，观察到的差异甚至更大。
br1 &lt;- gamm4(y~s(x0, fx = TRUE)+x1+s(x2),data=dat,random=~(1|fac), REML = TRUE)
id1 &lt;- grep(“s(x0)”，名称(coef(br1$gam))，固定 = TRUE)
id2 &lt;- grep(“s(x0)”，名称(fixef(br1$mer))，fixed = TRUE)
max(abs(coef(br1$gam)[id1]-fixef(br1$mer)[id2]))
## [1] 0
max(abs(vcov(br1$gam)[id1, id1]-vcov(br1$mer)[id2, id2]))
## [1] 0.3819084

在我正在进行的分析中，两个部分之间的不匹配更加严重。
有趣的是，一旦我们用 s(fac, bs = &quot;re&quot;) 而不是 gamm4 的 random 参数指定随机效应，差异就消失了。
br2 &lt;- gamm4(y~s(x0, fx = TRUE)+x1+s(x2)+s(fac,bs=“re”),data=dat, REML = TRUE)
max(abs(coef(br2$gam)[1:11]-fixef(br2$mer)[1:11]))
## [1] 0
max(abs(vcov(br2$gam)[1:11, 1:11]-vcov(br2$mer)[1:11, 1:11]))
## [1] 8.824941e-12

我的问题：

我的期望是否正确，两个对象的协方差矩阵
对于固定效应参数应该是相同的（即使对于系数
不受惩罚的附加条款）？我是否错过了什么（例如，一些缩放
因素）？
这里发生了什么？是什么导致了这些差异？
这与 gamm4 处理随机效果的方式有何关系？
我应该相信哪些结果？为什么？

如有任何意见或见解，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/638430/differences-of-standard-errors-between-gam-and-mer-parts-of-a-gamm4-object</guid>
      <pubDate>Fri, 02 Feb 2024 20:20:51 GMT</pubDate>
    </item>
    <item>
      <title>尝试通过直接应用来理解贝叶斯理论</title>
      <link>https://stats.stackexchange.com/questions/638429/trying-to-understand-bayes-theory-with-direct-application</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/638429/trying-to-understand-bayes-theory-with-direct-application</guid>
      <pubDate>Fri, 02 Feb 2024 20:19:35 GMT</pubDate>
    </item>
    <item>
      <title>在线混合推理；比窗口 EM 更好的选择？</title>
      <link>https://stats.stackexchange.com/questions/638428/online-mixture-inference-better-alternatives-than-windowed-em</link>
      <description><![CDATA[我有一个在线高斯混合估计问题，希望得到一些意见。更准确地说，我有一个标量观察流 $x_1, x_2, \dotsc$ 随着时间的推移到达，假定来自混合分布
$$
p(x_i) = \sum_{k=1}^K \pi_k \cdot \mathcal N(x_i | \mu_k, \sigma_k^2)。
$$
我希望估计组件数量 $K$ 和参数 $\pi_k, \mu_k, \ sigma_k^2$ 以在线（或伪在线）方式。实际上，我还希望考虑到 $K$ 和参数可能在长时间尺度上发生变化的可能性。
我当前的、有点临时的解决方案是维护一个 $N = 1000$ 最近观察结果的窗口，并每隔 $n = 100$ 观测值（使用窗口数据）。对于每个 $K = 1, 2, \dotsc, 10$，我在（希望）找到 MAP 估计之前运行期望最大化 (EM)。 （先验有助于避免高斯混合的 ML 的奇点问题。）然后我使用贝叶斯信息准则 (BIC) 来选择“最佳”模型。这 10 个的模型。
这个解决方案在实践中效果很好，但是训练有点慢，而且内存占用有点大。我们运行了该算法的许多实例，所以这些东西加起来。我更希望有一个完全在线的算法。
我简要考虑过对混合物使用变分推理。这样做的好处是我可以简单地将 $K$ 设置为最大值 10，因为变分混合会自动抑制多余的成分。但它仍然无法在线。
我搜索了一些期望最大化的在线版本，但我发现的所有内容似乎都非常复杂。有没有我忽略的好的替代方案？]]></description>
      <guid>https://stats.stackexchange.com/questions/638428/online-mixture-inference-better-alternatives-than-windowed-em</guid>
      <pubDate>Fri, 02 Feb 2024 20:18:05 GMT</pubDate>
    </item>
    <item>
      <title>在对照组已接受治疗的情况下进行双重差分分析</title>
      <link>https://stats.stackexchange.com/questions/638427/performing-a-difference-in-difference-analysis-where-the-control-group-is-alread</link>
      <description><![CDATA[我参与了一个项目，其结果是接受手术的癌症患者的比例。此次治疗事件是一项州级政策变更，要求将所有这些癌症患者从 FFS 保险计划转移到 MMC 保险计划（缩写含义与当前问题无关）。
大约 2/3 的患者居住在已经对癌症患者强制执行 MMC 计划的县（已接受治疗的对照组），而 1/3 的患者居住在在治疗事件后强制执行 MMC 计划的县（治疗组）。
我们的假设是，在治疗事件后，相对于对照组，治疗组接受手术的人数比例增加更多。
我的问题是，如果可能的话，如何使用 DiD 概念化这个场景？
在我研究此类模型的可行性时，我从其他人那里得到了相互矛盾的答案，有些人说它行不通，因为已经接受治疗的群体和新接受治疗的群体不可能在治疗前有平行的趋势。 - 期间，而其他人则表示这并不重要，因为已经接受治疗的对照组可以被视为模型中从未接受治疗的对照组，否则方法相同。
非常感谢您提供任何其他见解或帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/638427/performing-a-difference-in-difference-analysis-where-the-control-group-is-alread</guid>
      <pubDate>Fri, 02 Feb 2024 20:13:36 GMT</pubDate>
    </item>
    <item>
      <title>具有卷积响应的非参数回归</title>
      <link>https://stats.stackexchange.com/questions/638424/nonparametric-regression-with-convolution-responses</link>
      <description><![CDATA[这是我遇到的问题。作为某些测量过程的结果，我有一组测量 $f_i \pm \sigma_i$ 。实际上，对于 $x \in D \subset \mathbb{R 存在一个连续信号 $g(x)$ }$ 发生在我的探测器上，探测器将 $g$ 数字化为测量的 $f_i$  使用一些函数 $H_i$，使得 $f_i = \int_D H_i(x) g(x) dx $.
我的问题是，如何推断所有 $x \in D$&lt; 的 $g(x)$ /span&gt;，有不确定性吗？您可以假设 $H_i$ 是已知的。没有理由假设 $g$ 具有任何形式，除了它应该相对平滑之外。一种方法是采用某种形式 $g$，例如具有 $k$ 个控制点的三次样条线，并找到最小化 $\chi^2$，但我想知道是否有一种方法可以强制它达到一定程度的平滑度。如果 $H_i$ 是一个 delta 函数，我会使用高斯过程，但我不确定在这里如何做到这一点。
如果 $H_i$ 中的不确定性能够以某种方式得到解决，则可获得奖励积分。]]></description>
      <guid>https://stats.stackexchange.com/questions/638424/nonparametric-regression-with-convolution-responses</guid>
      <pubDate>Fri, 02 Feb 2024 19:14:07 GMT</pubDate>
    </item>
    <item>
      <title>不平衡类的泛化</title>
      <link>https://stats.stackexchange.com/questions/638422/generalization-with-imbalanced-classes</link>
      <description><![CDATA[我有一个关于具有不平衡类别和泛化的学习（二元分类）的一般性问题。学习不平衡类别的一个方法是将负样本下采样到模型实际上可以学习某些内容的比率。但是，当模型部署在实际的、非常不平衡的数据上时会发生什么？为了解决这个问题，如果正例代表实际数据的 1%，我们可以使用所有正例和相同数量的下采样负例来训练二元分类器。但随后该模型是根据实际正负比为 1:100 的数据发布的。该模型还能找到积极的一面吗？难道它没有接受过与它所使用的问题相同的训练吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638422/generalization-with-imbalanced-classes</guid>
      <pubDate>Fri, 02 Feb 2024 18:42:25 GMT</pubDate>
    </item>
    <item>
      <title>用反向传播解释贝叶斯变分自由能的近似</title>
      <link>https://stats.stackexchange.com/questions/638421/explaining-the-approximation-to-the-variational-free-energy-in-bayes-by-backprop</link>
      <description><![CDATA[在论文神经网络中的权重不确定性，Blundell 等人，2015 中，作者近似确切的成本（变分自由能）
$$
\mathcal F(\mathcal D, \theta) = \mathrm{KL}[q(\mathbf w \vert \theta) \mathrel{\|} P(\mathbf w)] - \mathbb E_{q(\mathbf w \vert \theta)}[\log P(\mathcal D \vert \mathbf w)] \tag{1}
$$
与近似
$$
\mathcal F(\mathcal D, \theta) \approx \sum_{i=1}^n \log q(\mathbf w^{(i)} \vert \theta) - P(\mathbf w^{(i )}) - \log P(\mathcal D \vert \mathbf w^{(i)}) \tag{2},
$$
&quot;其中 $\mathbf w^{(i)}$ 表示 $i$从变分后验$q(\mathbf w^{(i)} \vert \theta)$中提取的蒙特卡罗样本。”
这似乎是一个（简单的）蒙特卡罗估计，但为什么没有包含一个用于期望估计的 $\frac 1n$ 标准化项，即为什么不是正确的近似值：
$$
\mathcal F(\mathcal D, \theta) \approx \frac 1n \sum_{i=1}^n \log q(\mathbf w^{(i)} \vert \theta) - P(\mathbf w^ {(i)}) - \log P(\mathcal D \vert \mathbf w^{(i)}) \tag{2}\;\;?
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/638421/explaining-the-approximation-to-the-variational-free-energy-in-bayes-by-backprop</guid>
      <pubDate>Fri, 02 Feb 2024 18:29:39 GMT</pubDate>
    </item>
    <item>
      <title>警告：在以下估计中检测到 Hauck-Donner 效应：截距</title>
      <link>https://stats.stackexchange.com/questions/638418/warning-hauck-donner-effect-detected-in-the-following-estimates-intercept</link>
      <description><![CDATA[这是一个简短的问题，因为我无法在网上找到答案。
我运行了截断的泊松模型，并在标题中收到了警告（完美分离？），这影响了我的拦截。
输出为：
&lt;前&gt;&lt;代码&gt;调用：
vglm(公式 = private_sensors ~ lag_private_sensors + gov_monitors +
    密度 + 平均收入 + 平均年龄 + log2_性别比率 + 年数_教育 +
    PM10 + 偏移量（log（k_people）），家庭 = pospoisson（），数据 = 过滤器（df_2019_north，
    私人传感器&gt; 0))

系数：
                      估计标准。误差z值Pr(&gt;|z|)
（截距）-2.640e+01 4.657e+00 -5.670 1.43e-08 ***
滞后专用传感器 5.962e-02 7.048e-02 0.846 0.3976
gov_monitors -1.873e-01 1.129e-01 -1.660 0.0970 。
密度 -5.445e-01 7.803e-02 -6.978 2.99e-12 ***
平均收入 1.549e-01 6.375e-02 2.429 0.0151 *
平均年龄 8.810e-02 9.207e-02 0.957 0.3386
log2_性别比率 -6.435e+00 3.111e+00 -2.068 0.0386 *
年_教育 1.591e+00 2.690e-01 5.916 3.30e-09 ***
PM10 -4.209e-04 7.559e-04 -0.557 0.5777
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

线性预测器名称：loglink(lambda)

对数似然：92 自由度上为 -152.373

Fisher 评分迭代次数：7

警告：在以下估计中检测到 Hauck-Donner 效应：
&#39;（截距）&#39;

问题1：这个错误只影响我的拦截还是我必须扔掉我的整个模型？
问题 2：密度 的系数和 SE 似乎也很可疑，知道为什么我没有收到警告吗？
非常感谢任何帮助！
如果您需要更多背景知识，我正在做的事情的描述如下：问题]]></description>
      <guid>https://stats.stackexchange.com/questions/638418/warning-hauck-donner-effect-detected-in-the-following-estimates-intercept</guid>
      <pubDate>Fri, 02 Feb 2024 17:40:49 GMT</pubDate>
    </item>
    <item>
      <title>如何组合两个或多个神经网络的软最大值</title>
      <link>https://stats.stackexchange.com/questions/638416/how-to-combine-soft-max-value-from-two-or-more-neural-networks</link>
      <description><![CDATA[考虑这样一个场景，我们有一些输入变量 $X$ （可能是图像），它经过几个嘈杂的路径，我们生成 $K$ 噪声观测值：
\begin{align}
Y_i = X_i +Z_i, i \in \{1,\ldots, K\}
\end{对齐}
其中噪声是独立的。在这里，我假设是加法结构，但并非必须如此。
假设我在 $Y_i$ 上使用相同的神经网络进行分类。
另外，假设我可以访问 soft-max 值，特别是，让 $p_i$ 为输入 soft-max 值&quot;&gt;$Y_i$，
问题：如何以最佳方式组合这些值来确定我的类别？一种选择是
\begin{align}
p_{new} = \frac{1}{K} \sum_{i=1}^K p_i
\end{对齐}
也可以将阈值设置为 $0.5$ 并找到大多数。
我正在寻找一个有一定理论支持的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/638416/how-to-combine-soft-max-value-from-two-or-more-neural-networks</guid>
      <pubDate>Fri, 02 Feb 2024 17:00:56 GMT</pubDate>
    </item>
    <item>
      <title>GLM 事后配对比较的假设和有效性</title>
      <link>https://stats.stackexchange.com/questions/638414/assumptions-and-validity-of-post-hoc-pairwise-comparisons-of-glms</link>
      <description><![CDATA[用于成对比较的包（例如 multcomp 的 glht(mcp) 和 emmeans pairs()）如何在方差异质性和响应非正态性的情况下保持有效性或残差 - 例如如果拟合类型为 glmmTMB(y ~ factor(a) + b, family = tweedie(link = &quot;log&quot;)) 的模型？
在相关问题中，（执行对具有 Gamma 分布的 GLM 进行事后测试），据称这些包针对 GLM 进行了调整。但是，更全面地解释如何进行此调整以及是否存在模型以外的任何限制将很有用。
根据 glht 文档，除 lm 之外的其他模型的结果 依赖于法线近似。是对 Hothorn (2008) 的正确解释，即除了使用的 glm 模型之外的假设 -模型参数估计值是否服从正态分布，并以中心极限定理为基础？]]></description>
      <guid>https://stats.stackexchange.com/questions/638414/assumptions-and-validity-of-post-hoc-pairwise-comparisons-of-glms</guid>
      <pubDate>Fri, 02 Feb 2024 16:46:26 GMT</pubDate>
    </item>
    <item>
      <title>当所有未标记数据可用时，在交叉验证之前使用无监督方法</title>
      <link>https://stats.stackexchange.com/questions/638412/using-unsupervised-methods-prior-to-cross-validation-when-all-unlabelled-data-is</link>
      <description><![CDATA[关于预处理方法有很多讨论，以及它们是否需要包含在交叉验证过程中，或者它们是否可以在分割数据之前发生 - stackexchange 上的问题：1 2 3 4 以及分析该问题的论文5 6。
主要观点似乎是任何预处理都不应该包含验证/测试数据as：&lt; /p&gt;
&lt;块引用&gt;
交叉验证最好被视为一种估计统计过程性能的方法，而不是统计模型。因此，为了获得无偏差的性能估计，您需要在交叉验证的每个部分中分别重复该过程的每个元素，其中包括标准化。

但是，无监督方法有时被认为是一种可接受的弱数据泄漏形式。
在这些场景中，如所概述的，例如此处，
通常假设您有一个根据某些数据训练模型的程序，并且您希望能够使用它来预测全新的样本。
但是，假设您有一个数据集，可以捕获您感兴趣的所有可能的观察结果，但缺少您想要预测的一些目标标签 --- 假设您有欧洲每栋房屋的数据（X_all，y_all）对于部分数据，您不知道价格，但想要预测它。
在这种情况下，对我来说，在任何无监督预处理步骤中使用所有 X_all 似乎都没有问题，因此可以在使用标记数据进行任何交叉验证之前执行此操作，因为 X_all 是在训练和训练中都固定的常量。测试场景。
我的想法正确还是我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/638412/using-unsupervised-methods-prior-to-cross-validation-when-all-unlabelled-data-is</guid>
      <pubDate>Fri, 02 Feb 2024 16:42:39 GMT</pubDate>
    </item>
    <item>
      <title>曼惠特尼 U 检验 (TOST) 中如何计算差异的中位数？</title>
      <link>https://stats.stackexchange.com/questions/638410/how-is-median-of-the-difference-calculated-in-mann-whitney-u-test-tost</link>
      <description><![CDATA[我在 R 中运行 wilcox_TOST，结果如下。如果 Mann Whitney U 检验等于 Wilcoxon Rank Sum 检验，并考虑该检验的作用（例如，对数据进行排名并对排名求和等），则在任何地方都不会使用或报告差异的中位数。我想知道：
1-此处显示的差异中位数是多少？中位数有什么区别？和
2- 为什么报告的是 95% CI，而不是通常报告的中位数的四分位数范围？
具有连续性校正的 Wilcoxon 秩和检验

等效性检验不显着 W = 252.500，p = 9.41e-01
零假设检验显着 W = 284.000，p = 1.85e-02

NHST：拒绝效应为零的零显着性假设
TOST：不要拒绝零等价假设

TOST 结果
           检验统计量 p 值
NHST 284.0 0.018
TOST 较低 317.0 &lt; 0.001
TOST 上部 252.5 0.941

效应大小
                          估计 C.I.会议。等级
差异中位数 1.2500 [0.4999, 2] 0.9
秩双列相关性 0.4753 [0.183, 0.6904] 0.9
]]></description>
      <guid>https://stats.stackexchange.com/questions/638410/how-is-median-of-the-difference-calculated-in-mann-whitney-u-test-tost</guid>
      <pubDate>Fri, 02 Feb 2024 15:53:26 GMT</pubDate>
    </item>
    <item>
      <title>瓮问题。如何计算这个概率？</title>
      <link>https://stats.stackexchange.com/questions/638401/urn-problem-how-to-calculate-this-probability</link>
      <description><![CDATA[从有 m 个独特元素的瓮中抽取 n 次。一次绘制一张，并替换。平均而言，抽奖期间发生重采样的概率是多少？
澄清：第一次抽奖的重采样概率为 0。第二次抽签的重采样概率为 1/m。对于进一步的绘制，情况会变得更加复杂，因为在之前的绘制期间是否进行重采样以及重采样的频率很重要。
我对 n 次抽签中重新采样的平均概率感兴趣。实际上，我想计算 n 次绘制中的重新采样次数并除以 n。]]></description>
      <guid>https://stats.stackexchange.com/questions/638401/urn-problem-how-to-calculate-this-probability</guid>
      <pubDate>Fri, 02 Feb 2024 14:40:56 GMT</pubDate>
    </item>
    </channel>
</rss>