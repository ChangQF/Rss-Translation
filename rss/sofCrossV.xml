<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 01 Dec 2023 12:26:10 GMT</lastBuildDate>
    <item>
      <title>在多读者多案例 (MRMC) 场景中选择适当的统计测试</title>
      <link>https://stats.stackexchange.com/questions/632779/choosing-an-appropriate-statistical-test-in-multi-reader-multi-case-mrmc-scena</link>
      <description><![CDATA[我正在寻找最适合以下情况的统计测试：
我处于多读者多案例 (MRMC) 场景中，其中 6 个读者将对相同的 165 个样本执行二元分类。
研究中有 2 个阅读阶段：第 1 阶段，读者自己注释；第 2 阶段，他们在人工智能的帮助下，这应该会提高他们在准确性/灵敏度/特异性方面的表现。
我想评估两个阶段之间准确性/灵敏度/特异性增益的重要性。为了评估每个注释者的增益，我使用了 McNemar 测试，这似乎适合这种情况。但是，我想通过将注释器聚合在一起来执行相同的测试以测量总体增益。我认为麦克尼马尔测试不适合这种情况，因为它没有考虑注释者之间的交互。
我尝试在此存储库中使用以 Python 实现的 Obuchowski-Rockette-Hillis (ORH) 方法 https://github.com/Google-Health/google-health/tree/master/analysis，我有一些我不明白的结果。
我将我的分析分为 2 个子组（准确度增益最低的 3 个读者和准确度增益最高的 3 个读者）。
对于增益较低的组，我得到以下结果（第 1 阶段与第 2 阶段）：
准确度 0.931（第 1 阶段）-&gt; 0.968（第 2 阶段），效果 = +0.036，CI=(0.0245, 0.048)，统计量=6.76，dof=11.14，p 值=2.9e-05。
对于取得显着收益的组，我得到以下结果：
准确度 0.915（第 1 阶段）-&gt; 0.982（第 2 阶段），效果 = +0.067，CI=(-0.02, 0.15)，统计量=3.01，自由度=2.34，p 值=0.078。
我很难理解在具有显着收益的组中重要性低得多的情况。让我特别惊讶的是，如果我对这个组中的每个读者分别执行 McNemar 测试，我会得到 p 值 &lt;&lt; 0.05。
您对如何解释这些结果有什么想法吗？
在查看 ORH 方法计算的指标时，我注意到增益显着的组中协方差值较低，这会影响自由度的计算等。
您认为这个方法适合我的情况吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/632779/choosing-an-appropriate-statistical-test-in-multi-reader-multi-case-mrmc-scena</guid>
      <pubDate>Fri, 01 Dec 2023 11:00:04 GMT</pubDate>
    </item>
    <item>
      <title>将 PCA 应用于时间序列情感数据：有效性和解释问题</title>
      <link>https://stats.stackexchange.com/questions/632778/applying-pca-to-time-series-emotional-data-validity-and-interpretation-concerns</link>
      <description><![CDATA[我目前正在探索将主成分分析 (PCA) 应用于表示各种“面部情绪表达”的时间序列数据。状态（例如，愤怒、快乐、悲伤等）。我的目标是简化复杂的、多维的“面部情感表达”。数据以获得更好的可视化和初步见解。
但是，我对 PCA 在这种情况下的有效性和解释有一些担忧：

变量的依赖性：“情绪”往往是相互依赖的。为了
例如，一种“情绪”的存在（如愤怒）可能会影响
他人的表现（如幸福）。这怎么办
相互依赖性影响 PCA 对变量的假设
独立？
时间序列数据：由于数据是时间序列的，因此每种情绪
状态不仅仅是一个独立的观察，而且是序列的一部分。
PCA 是否有效地处理此类数据的顺序性质，或者
时间序列分析是否需要进行特定的调整？
在探索 PCA 的应用时，我们假设，理论上，我们
将识别的“情绪”分为“积极”和“消极”
组。例如，根据典型的人类标签，我们可以放置
诸如幸福或惊喜之类的情感属于一类情感
比如另一个人的愤怒或悲伤，然后将 PCA 应用于每个组
分别地。这种理论分类并不意味着
明确的，而是一个简化的分析模型。这会吗
假设这种拆分的方法有助于提供更清晰的见解
在 PCA 结果中，或者可能会导致
情绪谱过于简单化？
整体情感反思：一个目标是形象化“整体”
情感反思”通过PCA。 PCA 能否有效捕获
“情绪状态”的合成图随着时间的推移，还是错过了
不了解关键的细微差别吗？

我非常感谢社区对这些问题的见解，特别是有关如何最好地处理“情感数据”的 PCA 的任何指导。以时间序列格式。是否有我应该注意的特定陷阱或最佳实践？此外，如果 PCA 不是最适合此类数据的方法，您会推荐哪些替代方法（隐马尔可夫除外）？
感谢您的时间和专业知识！
重要说明：此处使用的情绪数据源自面部情绪识别 (FER) 算法，该算法可识别愤怒、快乐、悲伤等各种表情。我了解人类情感的复杂性和主观本质，并认识到这些算法分类并不是实际情感状态的明确表示。然而，对于本次分析来说，它们是有用的指标。​​
此外，需要澄清的是，这里的目的不是拟合一个确定的模型，而是使用 PCA 作为工具来降低一般可视化数据的复杂性，并初步了解整体“情感”模型。趋势。]]></description>
      <guid>https://stats.stackexchange.com/questions/632778/applying-pca-to-time-series-emotional-data-validity-and-interpretation-concerns</guid>
      <pubDate>Fri, 01 Dec 2023 10:52:12 GMT</pubDate>
    </item>
    <item>
      <title>请问有人可以解释一下这个多元泰勒展开式的表示法吗？</title>
      <link>https://stats.stackexchange.com/questions/632777/please-can-someone-explain-the-notation-of-this-multivariate-taylor-expansion</link>
      <description><![CDATA[Kamanzi-wa-Binyavanga，2009 年撰写了以下论文：计算泰勒累积量
多元函数的展开：

我感到困惑的是，这种符号的精确程度。我知道我们对 $1$ 之间的某个点（$r,s,t$ 此处）取每个偏导数 和 $p$，这可能是统计设置中回归量的数量。我不明白的是：

为什么我们必须对每个 $r,s,t$ 单独求和？
为什么他对 $z$ 和 $s$ 求和，而不是 $r$ 和 $s$ 进行双重求和
为什么他实际上说这些总和是从 1 到 $p_i$。我是否正确地说，例如，第三个应该看起来像 $\frac{1}{3!}\sum_{r=1}^{p_i}\sum_{s= 1}^{p_i}\sum_{t=1}^{p_i}$。
最后，这可能看起来很简单，但如果我想要整个函数的泰勒展开 $Y$，我只需添加 $c$ 之前的container&quot;&gt;$\sum_{i=1}^{q}$？

任何帮助/澄清将不胜感激。我正在尝试学习在这种情况下使用爱因斯坦表示法，但我需要首先准确理解这种展开式。]]></description>
      <guid>https://stats.stackexchange.com/questions/632777/please-can-someone-explain-the-notation-of-this-multivariate-taylor-expansion</guid>
      <pubDate>Fri, 01 Dec 2023 10:47:35 GMT</pubDate>
    </item>
    <item>
      <title>ESL以外的教科书推荐</title>
      <link>https://stats.stackexchange.com/questions/632776/textbook-recommendation-other-than-esl</link>
      <description><![CDATA[我目前的背景如下：（仅限核心科目）
&lt;块引用&gt;
数学：线性代数、分析、测度论（一半）统计：数理统计、回归分析、多元分析

“一半测度理论”意味着我已经涵盖了斯坦因实分析的第 4 章（希尔伯特空间简介）。
我的导师建议我学习《统计学习的要素》一书的一些章节，包括以下章节：
&lt;块引用&gt;
第三章。线性回归方法
第4章。线性分类方法
第5章。基差扩展和正则化
第 6 章。核平滑法
第 12 章。支持向量机和灵活判别式。

他的主要兴趣集中在这些章节上，所以我尝试自学它们。
但是，读完教材后，我发现这本书很难自学。也就是说，似乎有一些遗漏，使我无法完全理解书中的数学表达式，例如为什么该表达式成立或它来自哪里等等。所以我想得到关于涵盖上述章节相同（或相似）主题的其他教科书的一些推荐，这些教科书介绍了对这些理论的更严格的数学解释。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/632776/textbook-recommendation-other-than-esl</guid>
      <pubDate>Fri, 01 Dec 2023 10:33:27 GMT</pubDate>
    </item>
    <item>
      <title>根据年龄人口统计数据查找相似的地点</title>
      <link>https://stats.stackexchange.com/questions/632774/finding-similar-localities-based-on-age-demographics</link>
      <description><![CDATA[我正在使用澳大利亚人口普查数据根据年龄人口统计数据查找类似的城镇。有些地区年轻人口较多，有些地区工作年龄较大，有些地区老年人口较多，退休人员较多。我的问题是有一种通用的方法来分析这个年龄数据以找到相似的地方吗？
到目前为止，我的方法是视觉化的，比较一系列龙卷风图表。]]></description>
      <guid>https://stats.stackexchange.com/questions/632774/finding-similar-localities-based-on-age-demographics</guid>
      <pubDate>Fri, 01 Dec 2023 10:07:36 GMT</pubDate>
    </item>
    <item>
      <title>如何理解计算样本方差有n-1个自由度？</title>
      <link>https://stats.stackexchange.com/questions/632769/how-to-understand-that-there-are-n-1-degrees-of-freedom-in-calculating-sample</link>
      <description><![CDATA[根据维基百科：
在统计学中，自由度数是统计数据最终计算中可以自由变化的值的数量。[1]统计参数的估计可以基于不同量的信息或数据。参与参数估计的独立信息的数量称为自由度。一般来说，参数估计的自由度等于进入估计的独立分数的数量减去用作参数本身估计的中间步骤的参数的数量。例如，如果要根据独立分数的随机样本来估计方差，则自由度等于独立分数的数量 (N) 减去作为中间步骤估计的参数数量（一，即样本平均值），因此等于 N-1。[2]
参考：https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)
我很困惑，因为我们知道样本均值，这意味着 n 个观测值已经已知，所以为什么我们可以让 n-1 个观测值自由变化？我查看了一些视频和博客：大多数都通过一个例子解释说，如果我们有 3 个样本并且知道样本均值，则其中两个可以自由变化，而第三个观察值将由样本均值确定。但如果我们已经知道样本意味着为什么其中两个可以自由变化？我认为这三个观察结果是固定的。]]></description>
      <guid>https://stats.stackexchange.com/questions/632769/how-to-understand-that-there-are-n-1-degrees-of-freedom-in-calculating-sample</guid>
      <pubDate>Fri, 01 Dec 2023 07:51:05 GMT</pubDate>
    </item>
    <item>
      <title>有哪些数学函数可以代表网约车的峰时定价？</title>
      <link>https://stats.stackexchange.com/questions/632767/what-are-some-mathematical-functions-that-can-represent-surge-pricing-for-ride-h</link>
      <description><![CDATA[考虑一下叫车服务，其票价需要动态调整。我知道有很多可能的机器学习驱动模型，但我在这里寻找一个更简单、更合理的数学公式。
票价本身是通过激增系数$s$建模的，实际票价随着该系数作为单调递增函数变化（添加平台费用和一些其他业务）逻辑）。因此，我需要每两分钟更新一次喘振因子，如 $s_1、s_2、s_3...$ 等。任意时刻的$s_n$由以下参数确定

未满足的需求$u_n\geq0$
超额需求因子$e_n\geq0$
之前的激增$s_{n-1}\in\mathbb{R}$
上限 $h&gt;0$ 和下限 $l&lt;0$，因此 &lt; span class=&quot;math-container&quot;&gt;$s$ 将始终保持在该范围内，即 $l\leq s\leq h$。李&gt;

所以基本上，在每一步，我都必须找到 $\delta_n\in\mathbb{R}$ 以便 $s_n=s_{n-1}+\delta_n$。我正在寻找一些好的候选函数来计算 $\delta_n=f\left(s_{n-1}, u_n, e_n, h, l\right)$具有我认为理想的以下属性

与 $u_n$ 和 $e_n$ 单调递增（或非递减）。当然，更多的需求通常意味着更高的价格
遵守约束条件，将 $s_n$ 保持在地板和天花板之间（我可以为此应用最终剪辑函数）
不知何故，步长$\delta_n$（可以是正数或负数，取决于我们是否正在经历需求激增或需求缓解）应该是自适应的这意味着，假设 $\delta_n&gt;0$，那么步长有多大，也是$h-s_{n-1}$ 的函数。如果它有更多的上升空间，它会比几乎触及 $h$ 时上升得更快一些。当它跌向 $l$ 时也是如此。

决定何时提高激增 ($\delta_n&gt;0$) 或减少激增 ($\delta_n&lt; ;0$) 已经大部分制作完成。我只是想在尊重上述限制的情况下，在理想的方向上提出一个合理的步长。因此，任何关于候选函数的想法（最好是可以在 python 中轻松实现的函数）都将受到真诚的赞赏。干杯！]]></description>
      <guid>https://stats.stackexchange.com/questions/632767/what-are-some-mathematical-functions-that-can-represent-surge-pricing-for-ride-h</guid>
      <pubDate>Fri, 01 Dec 2023 07:01:56 GMT</pubDate>
    </item>
    <item>
      <title>高维相关矩阵的行列式</title>
      <link>https://stats.stackexchange.com/questions/632766/determinant-of-high-dimensional-correlation-matrix</link>
      <description><![CDATA[根据[1]：
&lt;块引用&gt;
仅当所有相关性都等于 0 时，相关矩阵的行列式才等于 1.0，否则行列式将小于 1 [...] 当测量不相关时，该空间是一个体积为 1 的球体。当测度相关，所占空间成为体积小于1的椭球体。

我用 2D 和 3D 相关矩阵（2 或 3 个随机变量）尝试了这一点，它似乎是正确的。然而在 $\Re^n$ $(n &gt; 3)$ 中，这条规则似乎失效了分开。
这是我做的实验。我是否误解了该定理，或者它并不适用于所有情况？
导入tensorflow为tf
将tensorflow_probability导入为tfp

# 2 个随机正态变量（均值 0，Var=1），500 个样本
x = tf.random.normal(形状=(2,500))
相关性= tfp.stats.correlation（x，sample_axis = -1，event_axis = 0，keepdims = False，name = None）
tf.linalg.det(corr) # det = 0.99493116 （如预期）

# 3 个随机正态变量（均值 0，Var=1），500 个样本
x = tf.random.normal(形状=(3,500))
相关性= tfp.stats.correlation（x，sample_axis = -1，event_axis = 0，keepdims = False，name = None）
tf.linalg.det(corr) # det = 0.99627995 （如预期）

# 20 个随机正态变量（均值 0，Var=1），500 个样本
x = tf.random.normal(形状=(20,500))
相关性= tfp.stats.correlation（x，sample_axis = -1，event_axis = 0，keepdims = False，name = None）
tf.linalg.det(corr) # det = 0.72647274

# 1000 个随机正态变量（均值 0，Var=1），500 个样本
x = tf.random.normal(形状=(1000,500))
相关性= tfp.stats.correlation（x，sample_axis = -1，event_axis = 0，keepdims = False，name = None）
tf.linalg.det(corr) # det = 0.0（应该是 1。）

这很奇怪，因为相关矩阵的值仍然相对较低。
当我增加样本量时，我会更接近预期结果。但是，成对相关性仍然很低，那么我该如何表达整个矩阵呢？
这是 1000 个随机变量的相关矩阵的一部分：


是否有其他方法来计算高维随机向量的椭球度（整体相关性）？]]></description>
      <guid>https://stats.stackexchange.com/questions/632766/determinant-of-high-dimensional-correlation-matrix</guid>
      <pubDate>Fri, 01 Dec 2023 07:00:13 GMT</pubDate>
    </item>
    <item>
      <title>对曼惠特尼 U 测试的质疑 [已关闭]</title>
      <link>https://stats.stackexchange.com/questions/632765/doubt-on-mann-whitney-u-test</link>
      <description><![CDATA[我怀疑 Mann-Whitney u 检验中 2 个值的排名？例如，男性和女性的社会接受度。如果男性的N较小，女性的N较大，则在排名时男性的排名较高，女性的排名较低。为什么会发生这种情况？这是否意味着男性比女性更容易被接受？]]></description>
      <guid>https://stats.stackexchange.com/questions/632765/doubt-on-mann-whitney-u-test</guid>
      <pubDate>Fri, 01 Dec 2023 06:13:53 GMT</pubDate>
    </item>
    <item>
      <title>我们可以对非正态分布的数据应用地统计学吗？</title>
      <link>https://stats.stackexchange.com/questions/632763/can-we-apply-geostatistics-on-data-which-is-not-normally-distributed</link>
      <description><![CDATA[如果我们处理地下水数据，如果数据不是正态分布，我们可以在不将其转换为正态分布的情况下对该数据应用地质统计学吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/632763/can-we-apply-geostatistics-on-data-which-is-not-normally-distributed</guid>
      <pubDate>Fri, 01 Dec 2023 05:16:25 GMT</pubDate>
    </item>
    <item>
      <title>如何解释贝叶斯分层模型的总体参数？</title>
      <link>https://stats.stackexchange.com/questions/632741/how-to-interpret-the-population-parameters-of-a-bayesian-hierarchical-model</link>
      <description><![CDATA[这几乎肯定是对我/知识差距的致命误解，但我对如何解释贝叶斯分层模型的总体参数感到困惑。
这是非常人为的，但为了证明这一点，让我们假设我们想要拟合以下模型+先验：
$$
\开始{对齐}
X_{ij} &amp;\sim N(\mu_j, \sigma) \\
\mu_j &amp;\sim \text{LogNormal}(\mu, \tau) \\
\mu &amp;\sim \text{N}(2, 1) \\
\sigma &amp;\sim \text{LogNormal}(0.5, 0.5) \\
\tau &amp;\sim \text{LogNormal}(0.5, 0.5) \\
\结束{对齐}
$$
现在假设我们要回答的问题是“$\mu_j$ 的总体平均值是多少？”。
我天真地假设，因为它们遵循对数正态分布，所以分布的平均值是 $exp(\mu + \tau^2/2)$ (wiki)，我们只是将 $\mu$ 和 $\tau$。
但这对我来说不太合适......
例如 $\tau$ 的后验分布不再一定是对数正态分布（这只是我们的先验分布），那么为什么后验总体分布会是$\mu_j$ 仍然是对数正态分布吗？但如果它不是对数正态分布， $\mu$ 和 $\tau$ 的值是什么&gt; 那还意味着什么？
任何关于我的心理模型出了问题的指导将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/632741/how-to-interpret-the-population-parameters-of-a-bayesian-hierarchical-model</guid>
      <pubDate>Thu, 30 Nov 2023 19:27:07 GMT</pubDate>
    </item>
    <item>
      <title>当使用每组观测值较少的线性混合模型时，为什么残差与预测相关？</title>
      <link>https://stats.stackexchange.com/questions/632725/why-are-residuals-correlated-with-prediction-when-using-linear-mixed-model-with</link>
      <description><![CDATA[我有一个数据库，由 n = 1000 个解释变量 (y) 和解释变量 (x) 的观测值组成。观察结果根据变量“组”进行分组，并且每个“组”我只有很少的观察结果。 (大约2)，而不同“组”的数量则为2。很高。
我拟合了一个线性混合模型（带有 R lmer 函数，来自 lme4 包），使用“组”将 y 解释为 x 的函数作为随机效应。然后我检查残差是否正常且独立于拟合值和随机效应。
**在这个阶段我遇到了一个问题：

残差相对于拟合值呈上升趋势
残差显示出与随机效应预测相关的上升趋势，这与 Pinheiro 和 Bates (2000, p174) 中的假设 1 相矛盾：“组内误差 [...] 独立于随机效应” ;**

这里，残差被计算为“观察值-固定效应-随机效应”。拟合计算为“固定效应+随机效应”。
我怀疑这些奇怪的模式是因为每个“组”的观察数量低。事实上，当我用每组更多的观察值来模拟数据时，它们几乎消失了。
我在下面添加了这个测试代码来说明问题：
#生成数据
图书馆（nlme）
库（ggplot2）

nb.组 &lt;- 500
list.group &lt;- as.character(seq(1,nb.group, 1)) # 不同组的 anmes
nb.obs &lt;- 1000

alpha &lt;- 0.3 # 固定效果
gamma &lt;- 1.5 # sd 随机效应
sigma &lt;- 1 # 个别错误的标准偏差

db.RE &lt;- data.frame( # 生成随机效应值
  组=列表.组，
  A = rnorm(nb.group, 0, 伽玛)
）

db &lt;- data.frame(
  x = rgamma(nb.obs, 10, 5), # 解释变量
  group = Sample(list.group, size = nb.obs, Replace = TRUE), # 组向量
  E = rnorm(nb.obs, 0, sigma) # 个体误差
）

db &lt;- merge(db, db.RE, by = &quot;group&quot;) # 属性每个组对应的随机效果值

db$y &lt;- alpha*db$x + db$A + db$E # y :自变量


# 使用 RE 进行校准

模型 &lt;- lme(固定 = as.formula(y ~ x)，随机 = ~ 1|组，数据 = db)

＃ 诊断

摘要（模型）

db_pred &lt;- cbind(predict(model, level = c(0:1)), res =残差(model, level = c(0:1))) # 获取拟合值和残差
db_ranef &lt;- data.frame(group = rownames(ranef(model)), ranef(model)) # 得到随机效应预测
名称(db_ranef) &lt;- c(“group”, “ranef”)
db_pred &lt;- 合并(db_pred, db_ranef, by = &quot;group&quot;)

# 将残差绘制为拟合函数（在总体水平）
graph.1 &lt;- ggplot(data = db_pred, aes(x = cut(predict.fixed,
                                   中断 = seq(min(predict.fixed), max(predict.fixed), length.out = 10)), y = res.group)) +
  geom_boxplot() +
  主题_bw() +
  主题(axis.text.x = element_text(角度 = 45, hjust = 1)) +
  ggtitle(“残差作为拟合函数（在总体水平）”)

# 将残差绘制为拟合函数（在个体级别）
graph.2 &lt;- ggplot(data = db_pred, aes(x = cut(predict.group,
                                   中断 = seq(min(predict.group), max(predict.group), length.out = 10)), y = res.group)) +
  geom_boxplot() +
  主题_bw() +
  主题(axis.text.x = element_text(角度 = 45, hjust = 1)) +
  ggtitle(“残差作为拟合函数（在个体水平）”)

# qq 残差图
graph.3 &lt;- ggplot(data = db_pred, aes(sample = res.group)) +
  stat_qq() + stat_qq_line() +
  主题_bw() +
  ggtitle(“残差的 qq 图”)

# 随机效应的 qq 图
graph.4 &lt;- ggplot(data = db_pred, aes(sample = ranef)) +
  stat_qq() + stat_qq_line() +
  主题_bw() +
  ggtitle(“随机效应的 qq 图”)

# 将残差绘制为随机效应预测的函数
graph.5 &lt;- ggplot(data = db_pred, aes(x = cut(ranef,
                                   中断 = seq(min(ranef), max(ranef), length.out = 10)), y = res.group)) +
  geom_boxplot() +
  主题_bw() +
  主题(axis.text.x = element_text(角度 = 45, hjust = 1)) +
  ggtitle(“残差作为随机效应预测的函数”)


cockplot::plot_grid(plotlist = list(graph.1, graph.2, graph.3, graph.4, graph.5))



相应的诊断图在这里：诊断图
我们观察到两个问题：(i) 残差和拟合值（包括随机效应）之间的相关性和 (ii) 残差和随机效应之间的相关性。
当我们每组的观察很少时，残差和拟合值（或随机效应）之间的相关性是否是预期的？您能向我解释为什么会出现这种情况吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/632725/why-are-residuals-correlated-with-prediction-when-using-linear-mixed-model-with</guid>
      <pubDate>Thu, 30 Nov 2023 16:01:05 GMT</pubDate>
    </item>
    <item>
      <title>生存分析：在观察期开始时未分配治疗</title>
      <link>https://stats.stackexchange.com/questions/632715/survival-analysis-treatment-not-assigned-at-the-beginning-of-the-observation-pe</link>
      <description><![CDATA[我是生存分析领域的新手，正在寻找有关如何处理以下情况的建议：
我有患有某种疾病的患者的数据。有些患者立即接受治疗，有些患者在一段时间后接受治疗，有些患者则从未接受治疗。患者患病时间越长，治疗效果可能越差。您如何比较两个治疗组与对照组？
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/632715/survival-analysis-treatment-not-assigned-at-the-beginning-of-the-observation-pe</guid>
      <pubDate>Thu, 30 Nov 2023 15:15:53 GMT</pubDate>
    </item>
    <item>
      <title>随机相关矩阵</title>
      <link>https://stats.stackexchange.com/questions/632691/random-correlation-matrices</link>
      <description><![CDATA[假设我们通过将 iid $U(-1,1)$ 随机变量分配给所有非对角线条目来模拟随机相关矩阵，并接受矩阵 $\boldsymbol\Sigma$ 是正定的。那么各个相关系数的边际分布显然不再均匀。
基于包括以下在内的模拟，
另一方面，相关的 部分相关性 （以通常的方式定义为 $-p_{ij}/\sqrt{p_{ii}p_{jj}}$ 其中 $\mathbf{P}=\令人惊讶的是，boldsymbol\Sigma^{-1}$) 似乎每个都有统一的边距。
这是为什么呢？我想这也许可以通过矩阵演算来证明，但我怀疑必须有一个简单的解释。
对于 $2\times 2$ 矩阵来说，这是非常正确的。对于 $3\times 3$ 相关矩阵
$$
\开始{b矩阵}
1 \\
u_1 &amp; 1 \\
u_2 &amp; u_3 &amp; 1
\end{b矩阵}
$$
偏相关矩阵是
$$
\开始{b矩阵}
1 \\
\frac{u_2u_3-u_1}{\sqrt{(1-u_2^2)(1-u_3^2)}} &amp; 1 \\
\frac{u_1u_3-u_2}{\sqrt{(1-u_1^2)(1-u_3^2)}} &amp; \frac{u_1u_2-u_3}{\sqrt{(1-u_1^2)(1-u_2^2)}} &amp; 1
\end{b矩阵}
$$
因此，一种方法是使用标准方法从 $u_1,u_2,u_3$ 的均匀密度导出下三角条目的联合密度，然后积分两个偏相关。
set.seed(1)
n＜-5
西格玛 &lt;- diag(n)
partialcorr &lt;- 复制（10000，{
  重复{
    u &lt;- runif(n*(n-1)/2, -1, 1)
    西格玛[下.三(西格玛)] &lt;- u
    西格玛[上.三(西格玛)] &lt;- t(西格玛)[上.三(西格玛)]
    if (sum(特征值(Sigma)$val&gt;0)==n)
      休息（）
  }
  P &lt;- 求解(Sigma)
  D &lt;- diag(1/sqrt(diag(P)))
  (D %*% P %*% D)[下.tri(P)]
})
历史记录(c(partialcorr))

]]></description>
      <guid>https://stats.stackexchange.com/questions/632691/random-correlation-matrices</guid>
      <pubDate>Thu, 30 Nov 2023 12:19:51 GMT</pubDate>
    </item>
    <item>
      <title>我如何判断杂乱随机交叉试验是否出现了分析单位错误？</title>
      <link>https://stats.stackexchange.com/questions/632690/how-can-i-tell-if-a-clutser-randomised-crossover-trial-has-made-a-unit-of-analys</link>
      <description><![CDATA[我正在研究以下论文：
https://jamanetwork.com/journals/jama/fullarticle/2698491 
这是一项具有交叉的整群随机对照试验。我想确保他们没有犯一个分析单位错误，这可能会扩大他们的效应大小并人为地降低他们的 p 值。在不寻求帮助的情况下，我没有信心判断这一点。
如果与统计数据相关，本试验中的交叉并不意味着每个患者都获得干预和控制，而是集群单位（EMS 机构）从提供提供控制的干预（或反之）转变为提供控制的干预。反之亦然），并且每个交叉期的患者群体由不同的患者组成（尽管希望相似，因为他们位于同一集群单元下）。
作者指出：
“为了量化治疗效果，我们使用了具有恒等联系和稳健标准误差的广义估计方程 (GEE)，考虑了随机聚类和中期分析的数量”
他们随后表示：
“我们使用 α 为 0.05 的 2 边检验作为统计显着性的阈值。”
我很欣赏他们似乎通过使用稳健的标准误差和使用 Huber-White 估计器（在他们的协议中提到）来解释聚类，但我想确定他们对 2-side 的评论测试（与 2 尾测试相同？）并不表明他们在不考虑聚类的情况下评估了个体水平的结果。
我认为他们在表 2 中报告的数据表明他们已经评估了主要结果的个体水平差异，因为他们只是报告了干预和控制之间的差异效应。
我是一名护理人员，而不是统计学家，所以我非常感谢您在解决这个问题时提供一些帮助。如果答案是我们无法知道，因为他们没有足够详细地描述问题，那么这也很有用，谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/632690/how-can-i-tell-if-a-clutser-randomised-crossover-trial-has-made-a-unit-of-analys</guid>
      <pubDate>Thu, 30 Nov 2023 12:00:41 GMT</pubDate>
    </item>
    </channel>
</rss>