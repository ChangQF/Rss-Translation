<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 08 Jul 2024 18:20:05 GMT</lastBuildDate>
    <item>
      <title>单位球中最近邻的期望最大距离、平均距离和最小距离的解析渐近近似</title>
      <link>https://stats.stackexchange.com/questions/650686/analytical-asymptotic-approximation-of-the-expected-maximum-mean-and-minimum-d</link>
      <description><![CDATA[假设我均匀随机地将 $x = n^3$ 个（独立同分布）点分布在 $r=1$ 半径的球中，位于 $\mathbb{R}^3$。
对于任何给定点的最近邻居之间的预期最大、最小和平均距离，可以怎样描述，渐近地为 $n\to\infty$？
尝试模拟这些，我得到：

不要太在意“理论平均值”，这实际上只是为了斜率。它是 $\frac{1}{x} = \frac{1}{n^3}$，其中 $n$ 是点数。
我得到：
最小距离拟合：
斜率：-2.0084
截距：1.0666
R²：0.9336
方程式：y = 1.0666 * x^(-2.0084)
平均距离拟合：
斜率：-1.0253
截距：0.9858
R²：0.9987
方程式：y = 0.9858 * x^(-1.0253)
最大距离拟合：
斜率：-0.8986
截距：1.7097
R²：0.9918
方程：y = 1.7097 * x^(-0.8986)
所以这些是相当不错的拟合，但是有没有什么确切的信息吗？
我知道，对于两个点，根据这个答案https://math.stackexchange.com/a/167983/49989，平均值的答案应该是$\frac{35}{36}\approx0.9722$

最小值的斜率明显接近 -2。
我还看到了这个https://en.wikipedia.org/wiki/Complete_spatial_randomness

如果我做对了，这意味着对于给定密度的完全均匀分布的点，我最终会得到带有
$$
P\left(r,\rho,N\right)=\frac{3^{1-N}\left(4\pi\rho\right)^N r^{3 N - 1}e^{-\frac{4}{3}\pi\rho r^3}}{\left(N - 1\right)!}
$$
对于给定密度$\rho$的距离$r$到$N^\text{th}$个最近邻居的概率。
我想我可以用$\rho = \frac{3 n}{4 \pi R^3}$代替$n$ 个点位于半径为 $R$ 的体积中，这给了我
$$
\frac{3 e^{-n\frac{r^3}{R^3}}\left(n\frac{r^3}{R^3}\right)^N}{r\left(N-1\right)!}
$$
对于该期望（在域 $0\leq r\leq\infty$ 上）最终应为
$$
\frac{R\ \Gamma\left(N+\frac{1}{3}\right)}{n^\frac{1}{3} \Gamma\left(N\right)}
$$
这似乎与最近邻平均值的结果相当接近，尽管它并不完全一致：它预测，对于半径为 $R=1$ 且 $x=n^3$ 个点的球体，我得到
$$
\frac{\Gamma\left(\frac{4}{3}\right)}{x}\approx\frac{\text{0.89298}}{x}
$$
而不是
$$
\approx\frac{\text{0.9858}}{x^\text{1.0253}}
$$
但我不确定这是否在模拟误差范围内。从图上看肯定不是这样：对于较大的点集（至少对于均值拟合），方差很快变得非常小，并且该线显然略比该分析值陡峭。]]></description>
      <guid>https://stats.stackexchange.com/questions/650686/analytical-asymptotic-approximation-of-the-expected-maximum-mean-and-minimum-d</guid>
      <pubDate>Mon, 08 Jul 2024 18:11:49 GMT</pubDate>
    </item>
    <item>
      <title>纠正 def 函数的“不可迭代错误”[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650685/correcting-not-iterable-error-for-def-function</link>
      <description><![CDATA[我正尝试根据为一个项目阅读的研究论文绘制这个复杂的 def 函数，但我不断发现 map 函数是不可迭代的。当我单独运行代码时，它很好，但是当我尝试使用给定的代码执行其他功能时，它会出错。
完整代码如下：
&#39;&#39;&#39;
包括来自数学和numpy库的所有函数
导入数学为m
导入numpy为np
导入matplotlib.pyplot为plt
函数Sc的定义见表2了解详情
def Sc(Dd, ki=0.23, ei=5.6*(10-2), Ci=88, T=298.15, sigma=0.072, gmax=10, g=1+1e-11, inc=1.01):
# 计算方程9中的A参数
A = 8.69251e-6sigma/T
# 返回公式 10 中定义的 H(xi)
xi = map(lambda x: x if x &lt; 1 else 1, Ci(g3.0 - 1.0)/ei)
# 计算公式 10 中吸湿性和溶解性向量的点积
k = np.dot(ki,(eixi))
# 定义公式 9 给出的函数
S = lambda D, Dd, k, A: (D3.0-Dd3.0)/(D3.0-Dd3.0(1.0-k))m.exp(A/D)
# 实现成对最大函数；f(2,3) 返回 3
f = lambda x,y: x if x &gt; y else y
# 当 g &gt; gmax 时返回 1，否则返回较大值 S(gDd) 或 S(gDdinc)
如果 g &gt; 返回 1 gmax else np.reduce(f,[S(gDd,Dd,k,A), 
Sc(Dd,ki,ei,Ci,T=T,sigma=sigma,gmax=gmax,inc=inc,g=ginc)])
Dd1=0.01*(10**-6)
print(Sc(Dd1))
&#39;&#39;&#39;
无论我是尝试打印图表还是仅打印某个 Dd 值的响应，都会产生以下错误：
&#39;&#39;&#39;
xi = map(lambda x: x if x &lt; 1 else 1, Ci*(g**3.0 - 1.0)/ei)
TypeError: &#39;float&#39; 对象不可迭代
&#39;&#39;&#39;]]></description>
      <guid>https://stats.stackexchange.com/questions/650685/correcting-not-iterable-error-for-def-function</guid>
      <pubDate>Mon, 08 Jul 2024 17:14:12 GMT</pubDate>
    </item>
    <item>
      <title>应用 IPTW 权重后计算 SMD 的问题</title>
      <link>https://stats.stackexchange.com/questions/650684/issues-calculating-smds-after-applying-iptw-weights</link>
      <description><![CDATA[在对我的数据应用逆治疗概率 (IPTW) 和稳定 IPTW 权重之前和之后，我得到了完全相同的标准化均值差 (SMD)。我使用 cobalt 包创建了一个平衡表，如下所示。我还尝试手动计算加权均值、SD 和 SMD，结果相同。
这是正常的吗？如果是，为什么？对总体应用权重应该会直观地改变协变量的加权平均值，所以我很困惑。提前致谢！
library(&#39;cobalt&#39;)
data(&#39;lalonde&#39;, package = &#39;cobalt&#39;)

# 计算 IPTW 权重
iptw_fit &lt;- glm(treat ~ age + educ + race, 
family = binomial(), 
data = lalonde)

prop_score &lt;- if_else(lalonde$treat == 0, 
1 - predict(iptw_fit, type = &#39;response&#39;),
predict(iptw_fit, type = &#39;response&#39;))

lalonde$iptw &lt;- 1/prop_score

# 计算稳定的 IPTW 权重
numer_fit &lt;- glm(treat~1, family = binomial(), data = lalonde) # numerator
pn_trt &lt;- predict(numer_fit, type = &#39;response&#39;)

denom_fit &lt;- glm(treat ~ age + educ + race, # 分母
family = binomial(),
data = lalonde)
pd_trt &lt;- predict(denom_fit, type = &#39;response&#39;)

lalonde$siptw &lt;- if_else(lalonde$treat == 0, 
((1-pn_trt) / (1-pd_trt)),
pn_trt/pd_trt)

# 计算 SMD

bal_tab &lt;- bal.tab(treat ~ age + educ + race , data = lalonde,
weights = c(&quot;iptw&quot;, &quot;siptw&quot;),
binary = &quot;std&quot;, Continuous = &quot;std&quot;,
stats = c(&#39;mean.diffs&#39;),
s.d.denom = &#39;pooled&#39;
) 

print(bal_tab)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/650684/issues-calculating-smds-after-applying-iptw-weights</guid>
      <pubDate>Mon, 08 Jul 2024 17:12:09 GMT</pubDate>
    </item>
    <item>
      <title>我对公式 SST = SSE + SSR 感到困惑 [重复]</title>
      <link>https://stats.stackexchange.com/questions/650683/i-am-confused-about-the-formula-sst-sse-ssr</link>
      <description><![CDATA[我不知道为什么在这种情况下这个公式不成立。有人可以解释一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650683/i-am-confused-about-the-formula-sst-sse-ssr</guid>
      <pubDate>Mon, 08 Jul 2024 16:40:06 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的多元 LME</title>
      <link>https://stats.stackexchange.com/questions/650682/multivariate-lme-in-python</link>
      <description><![CDATA[我正在计算一些模式在许多时间序列数据观察中出现的频率。我想比较两个时间间隔内的三种情况（因此我计算这些间隔内模式计数的平均值）。存在多种可能的模式，并且它们的计数不是独立的（如果某个时间点显示模式 1，则它不能在同一观察中也显示模式 2）。最后，我的数据框有 subject_index（20 个主题）、condition（3 个级别）、time_period（2 个级别），以及每个级别的因变量 count_pattern0、...count_pattern4。我试过了
from statsmodels.multivariate.manova import MANOVA
model_formula = &#39;count_pattern0 + count_pattern1 + count_pattern2 + count_pattern3+ count_pattern4 ~ condition * time_period + (1|subject_index)&#39;
manova = MANOVA.from_formula(model_formula, data=data)

但所有内容（截距、条件、时间周期、条件 x 时间周期和主题索引）都显得很重要，我不确定这是正确的。我更愿意将条件和时间周期视为固定，将主题索引视为随机效应。有没有办法在 Python 中运行多变量 LME（这在这里是一个明智的选择吗）？
感谢您的时间！]]></description>
      <guid>https://stats.stackexchange.com/questions/650682/multivariate-lme-in-python</guid>
      <pubDate>Mon, 08 Jul 2024 16:38:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们说我们在“预测”扩散模型中的平均值/噪声？</title>
      <link>https://stats.stackexchange.com/questions/650681/why-do-we-say-that-were-predicting-the-mean-noise-in-diffusion-models</link>
      <description><![CDATA[在 DDPM 中，${\tilde\mu}_t$ 是条件分布 $q(x_{t-1}|x_t,x_0)$ 的平均值，而神经网络 $\mu_\theta$ 正在对不同的条件分布 $p_\theta(x_{t-1}|x_t)$ 进行建模。碰巧的是，目标函数 (ELBO) 包含 $l_2$ 损失 $||{\tilde\mu}_t(x_t,x_0)-\mu_\theta(x_t,t)||^2$，而作者声称“$\mu_\theta$ 最直接的参数化是一个预测 ${\tilde\mu}_t$ 的模型”。我想知道我们为什么可以这么说，因为 $\mu_\theta$ 和 ${\tilde\mu}_t$ 甚至不涉及相同的分布。我理解，从数学上讲，如果 $\mu_\theta$ 接近 ${\tilde\mu}_t$，则损失会最小化。但我对神经网络应该预测它没有建模的东西这一事实感到困惑。
问题延伸到噪声。通过重新参数化，事实证明 $\epsilon_\theta$ 旨在从 $x_t$ 预测 $\epsilon$，以最小化损失。但是，如果我们确实在预测总噪声，那么在采样期间，为什么我们不一步就从 $x_T$ 中去除总噪声呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/650681/why-do-we-say-that-were-predicting-the-mean-noise-in-diffusion-models</guid>
      <pubDate>Mon, 08 Jul 2024 16:35:38 GMT</pubDate>
    </item>
    <item>
      <title>为什么残差项$ \ epsilon $没有包含在逻辑回归规范中？[重复]</title>
      <link>https://stats.stackexchange.com/questions/650680/why-residual-term-epsilon-is-not-included-in-logistic-regression-specificatio</link>
      <description><![CDATA[我有一个简单的问题，它困扰着我。在逻辑回归上下文中，几率定义为：
$$\frac{p(X)}{1-p(X)} = e^{\beta_{0}+\beta_{1}X}.$$
我想知道，为什么在文献中残差项$\epsilon$从未包含在指数中？]]></description>
      <guid>https://stats.stackexchange.com/questions/650680/why-residual-term-epsilon-is-not-included-in-logistic-regression-specificatio</guid>
      <pubDate>Mon, 08 Jul 2024 16:31:25 GMT</pubDate>
    </item>
    <item>
      <title>在 ggplot2 中的二维填充图中添加边框[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650678/adding-borders-in-2d-fill-plots-in-ggplot2</link>
      <description><![CDATA[显示的代码使用 ggplot2 生成以下图：
plot_DK &lt;- ggplot(coordinate_grid, aes(coordinate_east, coordinate_north, fill = model1_predictions)) +
geom_tile() +
labs(x = &quot;&quot;, y = &quot;&quot;) +
scico::scale_fill_scico(palette = &quot;vik&quot;) +
theme(axis.text = element_blank())


然而，实际上我的数据框 coordinate_grid 还包含一列，指示每个点所属的区域。我理想情况下希望将此信息添加到图中，以便属于特定区域的每个点集合都被边框包围，如下面的手绘示例所示。有人知道这是否可行吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650678/adding-borders-in-2d-fill-plots-in-ggplot2</guid>
      <pubDate>Mon, 08 Jul 2024 15:36:11 GMT</pubDate>
    </item>
    <item>
      <title>多变量 t 检验等价物 - 对照组与干预组</title>
      <link>https://stats.stackexchange.com/questions/650677/multivariate-t-test-equivalent-control-versus-intervention</link>
      <description><![CDATA[假设有两组具有相同的因变量和自变量。

因变量 = 治疗开始时间 - 连续。
自变量 = 护理点测试 - Y/N。

在上述单变量上下文中，用于评估组间平均差异的非配对 t 检验似乎是合适的（一旦建立了所有 t 检验要求）。
但是，假设您希望控制风险因素（例如，糖尿病状况、社会剥夺等）。
哪种模型可用于控制风险并仍在两组之间进行 t 检验？
任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650677/multivariate-t-test-equivalent-control-versus-intervention</guid>
      <pubDate>Mon, 08 Jul 2024 15:01:00 GMT</pubDate>
    </item>
    <item>
      <title>仅对一个个体进行相关观测的回归</title>
      <link>https://stats.stackexchange.com/questions/650676/regression-with-dependent-observations-of-only-one-individual</link>
      <description><![CDATA[上周，我接到一项任务，计划我的团队希望执行的分析。
我的目标是衡量一位医生是否同意某个工具为一组 N 幅医学图像生成的输出。为此，我会让他查看每幅图像和每个模型输出并回答一份简短的问卷。我的 Y 变量可能是二进制（同意/不同意）或李克特量表（1-5）；我还没有决定。其他 X 变量将是其他问题的答案，我想用 X 因子解释 Y 变异性，例如，看看哪些因素与医生的同意有关。
我最初的想法是使用广义线性模型 (GLM)，但我的观察结果不会是独立的。虽然我可以要求医生在 10 份问卷之间等待一段时间，以尝试减少遗留效应，但不能保证 (1) 他确实会这样做，并且 (2) 这样做会有效，因为尽管存在哲学问题，但他仍然是同一个人。我可以继续这样做并尝试测试独立性，但如果这个假设不成立，我该怎么办？
经过一些初步研究，我想到了一些选择，但由于我对它们不熟悉，我希望得到一些反馈，如果可能的话，我希望得到一些参考。

在 GAMLSS 模型中添加随机项 - 这可行吗？或者也许使用广义线性混合模型 (GLMM)？如果我只有一个集群变量（一个专家），这是否有意义？

使用时间序列回归分析，例如 $$Y_t \sim Y_{t-1} + X1_t + X2_t + ...$$ 这个选项在我看来过于复杂，而且我不太确定我是否能用它回答我的问题。

]]></description>
      <guid>https://stats.stackexchange.com/questions/650676/regression-with-dependent-observations-of-only-one-individual</guid>
      <pubDate>Mon, 08 Jul 2024 14:29:21 GMT</pubDate>
    </item>
    <item>
      <title>效应量分析：Cohen 的 D、Pearson 的 r，还是其他？</title>
      <link>https://stats.stackexchange.com/questions/650675/effect-size-analysis-cohens-d-pearsons-r-or-something-else</link>
      <description><![CDATA[我正在尝试对大坝泄洪对下游温度的影响进行效应量分析。我有一个大型数据集，其中包含在大坝下游各个站点获取温度读数的数据记录器。我试图将这些下游站点与放置在大坝脚下的温度计（作为我的独立变量）进行比较。问了几个问题后，似乎效应量分析就是我所寻找的。做了一些研究后，我看到很多关于 Cohen&#39;s d 和 Pearson&#39;s r 的提及。
我通过移动数据以适应水的行进时间来控制下游的行进时间。我还对数据进行了 24 小时的集中平均值，试图消除水温的昼夜波动，希望不会对相关性产生偏差（这就是为什么 24hrAVG 列在数据集的开头有这么多 NA 的原因）。这是我的数据集。
&gt; dput(head(SaltData_))
structure(list(Date = structure(c(1709942400, 1709943300, 1709944200, 
1709945100, 1709946000, 1709946900), tzone = &quot;UTC&quot;, class = c(&quot;POSIXct&quot;, 
&quot;POSIXt&quot;)), S1 = c(12.824443359375, 12.824443359375, 12.824443359375, 
12.824443359375, 12.824443359375, 12.78154296875), S2 = c(12.86734375, 
12.86734375, 12.86734375, 12.910244140625, 12.86734375, 12.824443359375
), S3 = c(12.223837890625, 12.223837890625, 12.26673828125, 12.26673828125, 
12.223837890625, 12.26673828125), S4 = c(NA, NA, NA, NA, 7.8908984375, 
7.847998046875), S5 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S6 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S7 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S8 = c(12.309638671875, 12.309638671875, 
12.26673828125, 12.3525390625, 12.3525390625, 12.309638671875
), S9 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_
), S10 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_), S11 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_), 仪表温度 = c(8.2, 8.2, 8.2, 8.2, 8.2, 8.2), 仪表高度 = c(70.83, 
70.84, 70.84, 70.85, 70.83, 70.83), 列 1 = c(NA, NA, NA, 
NA, NA), `24hrAVG S1` = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), `24 小时平均 S4` = c(NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_, NA_real_), `24 小时平均 S5` = c(NA_real_, NA_real_, 
NA_real_, NA_real_, NA_real_, NA_real_), `24 小时平均 S6` = c(NA_real_, 
NA_real_, NA_real_, NA_real_, NA_real_, NA_real_), `24 小时平均 S7` = c(NA_real_, 
NA_real_, NA_real_, NA_real_, NA_real_, NA_real_), `24 小时平均 S8` = c(NA_real_, 
NA_real_, NA_real_, NA_real_, NA_real_, NA_real_), `24hrAVG S9` = c(NA_real_, 
NA_real_, NA_real_, NA_real_, NA_real_, NA_real_), `24hrAVG S10` = c(NA_real_, 
NA_real_, NA_real_, NA_real_, NA_real_, NA_real_), `24hrAVG S11` = c(NA_real_, 
NA_real_, NA_real_, NA_real_, NA_real_, NA_real_), `24hrAVG GaugeTemp` = c(NA_real_, 
NA_real_, NA_real_, NA_real_, NA_real_, NA_real_), `24hrAVG GaugeHeight` = c(NA_real_, 
NA_real_, NA_real_, NA_real_, NA_real_, NA_real_)), row.names = c(NA, 
-6L), class = c(&quot;tbl_df&quot;, &quot;tbl&quot;, &quot;data.frame&quot;))

在进行了一些 Pearson r 相关性测试后，似乎这个测试没有找到我期望的结果。大坝泄水的相关性/影响最初随着您向下游前进而下降（即 S4 和 GaugeTemp r 为 0.92，S5 和 GaugeTemp r 为 0.843，S6 和 GaugeTemp r 为 0.8276），但只要到达站点 S7（0.828）就会回升并继续保持这种状态。我应该看到的是，随着你向下游前进，相关性/效应大小会稳步下降，因为越来越多的支流冲走了大坝泄洪效应。
所以我想知道的是，科恩的 d 是否能解决我的问题，或者我是否在正确的地方考虑使用 Pearson 的 r 或科恩的 d 来计算效应大小。我在这个问题上挣扎了很长时间，所以任何帮助都会非常感激。如果需要，我还可以提供更多数据/图表，只需在评论中告诉我，我很乐意分享。]]></description>
      <guid>https://stats.stackexchange.com/questions/650675/effect-size-analysis-cohens-d-pearsons-r-or-something-else</guid>
      <pubDate>Mon, 08 Jul 2024 14:25:32 GMT</pubDate>
    </item>
    <item>
      <title>对生物数据的几何平均比率进行 GLS</title>
      <link>https://stats.stackexchange.com/questions/650674/gls-on-geometric-mean-ratio-from-biological-data</link>
      <description><![CDATA[我的数据是生物数据，其中有 10 种蛋白质，我已测量它们在来自 (N=42) 名参与者的不同 (N=8) 个样本中的浓度。所有这些样本均来自同一参与者，因此它们不是独立的。
我已计算每种样本类型每种蛋白质的几何平均比率 (GMR)：
GMR = 样本类型 (y) 中蛋白质 (x) 的几何平均值 / 所有样本类型中蛋白质 (x) 的平均几何平均值
我的问题是，根据样本类型测量的浓度是否存在差异（因此，本质上是比较样本类型）。
因此，我认为使用具有异质化合物对称性的 GMR 可能是探索这个问题的合适方法。但是，我对此还很陌生，我不确定我的方法是否正确。
这是我目前在 R 中得到的内容：
gls(GMR ~ 1 + Sampling_Method , 
correlation=corCompSymm(form = ~Sampling_Method|Proteins),
weights = varIdent(form = ~1 | Sampling_Method), 
data = da)

AIC BIC logLik
226.4127 270.0066 -96.20636

在这种情况下（使用 GMR），这是否是 GLS 模型的适当应用，还是违反直觉？
我很感激任何想法/提示。]]></description>
      <guid>https://stats.stackexchange.com/questions/650674/gls-on-geometric-mean-ratio-from-biological-data</guid>
      <pubDate>Mon, 08 Jul 2024 14:23:34 GMT</pubDate>
    </item>
    <item>
      <title>使用皂膜平滑器进行问题拟合和绘制 GAM</title>
      <link>https://stats.stackexchange.com/questions/650673/issue-fitting-and-plotting-gam-with-soap-film-smoother</link>
      <description><![CDATA[我在使用 R 中的 mgcv 拟合游戏时遇到问题，正在寻求帮助。简而言之，我有一个数据集，其中包含在大型湖泊系统中的接收器处检测到的两组（孵化场或野生）之一的鱼的数量。这些接收器放置在特定位置，具有唯一的经度和纬度。该数据集是在 4 年内收集的。我希望对研究期间每组接收器处检测到的鱼的数量进行建模。我在 R 中使用 mgcv 完成了此操作，代码如下：
mod1 &lt;- gam(number_of_fish ~ s(x, y, by = origin, k = 40) + s(study_year, k = 3) + origin, offset = log(max_fish),
data = n_fish_spring_utm, 
family=nb(link = &#39;log&#39;),
method = &quot;REML&quot;)

这里，我使用偏移量来表示每组中可以检测到的最大鱼数的对数，因为两组的鱼数不同。我还使用了负二项分布。
这个模型似乎运行良好。
参数系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -2.83417 0.02592 -109.327 &lt; 2e-16 ***
originWild 0.31964 0.04188 7.632 2.3e-14 ***
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df Chi.sq p 值 
s(x,y):originHatchery 16.393 21.146 252.9 &lt;2e-16 ***
s(x,y):originWild 12.041 16.024 144.5 &lt;2e-16 ***
s(study_year) 1.871 1.983 274.2 &lt;2e-16 ***
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) = 0.306 偏差解释 = 50.2%
-REML = 2258.5 尺度估计 = 1 n = 1347


但是，我的湖泊系统有很多轮廓和一些大岛屿，我想使用肥皂膜平滑器来解释它们。
我使用湖泊系统的 shapefile 生成了肥皂膜表面，并使用 soapcheckr() 包检查一切是否正常（即没有结落在边界之外）。

然后我运行了以下模型，包括肥皂膜平滑器：
mod2 &lt;- gam(number_of_fish ~ s(x, y, by = origin, k = 40, bs = &quot;so&quot;, xt = list(bnd = border.aut, nmax=1500)) + s(study_year, k = 3) + origin, offset=log(max_fish),
data = n_fish_spring_utm, 
family=nb(link = &#39;log&#39;),
method = &quot;REML&quot;, 
knots = lake_knots)

模型运行良好。
参数系数：
估计标准差。误差 z 值 Pr(&gt;|z|)
(截距) -2.8287 4.4271 -0.639 0.523
originWild 0.2641 13.2274 0.020 0.984

平滑项的近似显著性：
edf Ref.df Chi.sq p 值 
s(x,y):originHatchery 42.000 42.00 216.9 &lt;2e-16 ***
s(x,y):originWild 42.000 42.00 173.2 &lt;2e-16 ***
s(study_year) 1.827 1.97 230.4 &lt;2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

排名：308/866
R-sq.(adj) = 0.307 偏差解释 = 52.7%
-REML = 1640 尺度估计 = 1 n = 1347

但是，这些图似乎不合理，表明没有检测到任何鱼。


我也无法像以前一样使用 gratia() 包从我的模型生成图表。我收到以下错误消息：
`mutate()` 中的错误：ℹ在参数中：`.loop = rep(seq_along(pts), each = pts)`。由错误引起：！`.loop` 的大小必须是 536 或 1，而不是 1446。

我已经摆弄了大约一个星期，但似乎无法解决这个问题。任何帮助，甚至是正确方向的推动都将不胜感激！
代码、数据和 shapefile 可以在这里找到。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650673/issue-fitting-and-plotting-gam-with-soap-film-smoother</guid>
      <pubDate>Mon, 08 Jul 2024 13:39:39 GMT</pubDate>
    </item>
    <item>
      <title>在期望最大化中，在最大化步骤中，我们是否最大化对数似然的期望（维基百科）或证据下限（cs 229）？</title>
      <link>https://stats.stackexchange.com/questions/650670/in-expectation-maximization-in-the-maximization-step-do-we-maximize-expectatio</link>
      <description><![CDATA[摘自 cs 229 第 6 页：

直观地讲，EM 算法通过以下方式交替更新 Q 和 θ：a) 按照公式 (8) 设置
Q(z) = p(z|x; θ)，使得 ELBO(x; Q, θ) = log p(x; θ)
对于 x 和当前 θ，以及 b) 最大化 ELBO(x; Q, θ) w.r.t θ，同时固定 Q 的选择。

即也就是说，
ELBO 是
$$\Sigma_{z}Q(z)\log[\frac{p(X,Z;\theta)}{Q(Z)}]$$
其中 Q(z) 设置为在期望步骤中给定 x 时 z 的后验。这种 $Q(Z)$ 的选择使 ELBO 最接近证据 ($P(X,Z;\theta)$)
$$Q(Z) = p(Z/X;\theta)$$
来自 维基百科:

哪个一个是正​​确的？分母有$Q(Z)$差异。如果它们都相同，怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/650670/in-expectation-maximization-in-the-maximization-step-do-we-maximize-expectatio</guid>
      <pubDate>Mon, 08 Jul 2024 11:36:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 R STM 包分析评论评级-样本平衡问题</title>
      <link>https://stats.stackexchange.com/questions/650661/analyzing-review-rating-using-r-stm-package-sample-balance-issue</link>
      <description><![CDATA[由于在线评论评分呈正偏J型分布/评分分布不平衡，一些学者倾向于平衡样本量，即随机选择正面评分评论，使其数量与负面评分评论数量相等或相似。如下面介绍的论文：
论文1：酒店顾客抱怨什么？使用结构化主题模型进行文本分析
论文 2：药物消费者的声音：使用结构化主题模型进行在线文本评论分析
除了调查主题比例（正面 vs. 负面）的差异（例如论文 1，图 2）之外，我还想使用线性回归研究主题与评分之间的关​​系。如果我对主题比例的差异进行分析，似乎我必须删除一些评论才能实现样本平衡，但如果我只运行线性回归，则没有必要这样做。
在这种情况下，有没有不删除样本同时解决样本不平衡问题的解决方案？]]></description>
      <guid>https://stats.stackexchange.com/questions/650661/analyzing-review-rating-using-r-stm-package-sample-balance-issue</guid>
      <pubDate>Mon, 08 Jul 2024 08:17:13 GMT</pubDate>
    </item>
    </channel>
</rss>