<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 21 Oct 2024 09:19:16 GMT</lastBuildDate>
    <item>
      <title>各条件等级内两年间面积差异（公顷）</title>
      <link>https://stats.stackexchange.com/questions/656065/difference-between-2-years-in-area-ha-within-each-condition-rating</link>
      <description><![CDATA[我收集了数百块土地的状况数据。我现在已经收集了两次（2017 年和 2023 年）。我之前曾使用 r 中有序数据的精确边际同质性检验比较了 2017 年和 2023 年属于每个状况类别（差、一般、好、非常好）的地块的数量。




非常好（2023 年）
好（2023 年）
一般（2023 年）
差（2023 年）




非常好（2017）
2
5
2
1


好（2017）
2
79
39
4


一般（2017）
2
18
65
6


差（2017）
0
0
4
2



mh_test(as.table(result_table), scores = list(response = 1:length(score)), distribution=&#39;exact&#39;)

我现在想比较两年内属于每个条件类别的面积。使用面积的精确边际同质性检验是否合适，还是应该仅用于计数数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/656065/difference-between-2-years-in-area-ha-within-each-condition-rating</guid>
      <pubDate>Mon, 21 Oct 2024 03:41:05 GMT</pubDate>
    </item>
    <item>
      <title>如果基础特征已经具有相同的单位，那么多元线性回归中的标准化是否必要？</title>
      <link>https://stats.stackexchange.com/questions/656060/is-standardizing-in-multiple-linear-regression-necessary-if-underlying-features</link>
      <description><![CDATA[首先我想说一下，我的统计经验有限。为了解释我的问题，我将提出一个假设的例子。假设我的老板希望公司增加利润，并要求我在两种不同的策略之间做出选择：增加广告或增加企业培训。因此，我收集了我能找到的其他公司的所有公司数据。我可以方便地找到有关他们的年度利润（美元）、广告支出（美元）和企业培训支出（美元）的信息。在我看来，我所需要做的就是运行多元线性回归，其中年度利润是我的因变量，我的两个特征变量是广告支出和企业培训支出。在这种情况下，由于每个特征变量都以美元为单位，我们可以将特征系数解释为广告或企业培训支出分别增加一美元所导致的预期利润变化。因此，基于这种逻辑，我觉得直接比较系数值以确定哪个系数对利润的影响更大是合理的。
虽然这种逻辑对我来说似乎合理，但我注意到网上对这种策略的普遍反对意见。大多数资料表明，您不能简单地比较系数，因为可能存在可以操纵的单位差异；解决方案是使用标准化将特征变量转换为无单位值，然后比较标准化回归的系数。但是，就我而言，每个系数的单位不是相同吗？因此，我们不应该直接比较吗？如果不是，为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/656060/is-standardizing-in-multiple-linear-regression-necessary-if-underlying-features</guid>
      <pubDate>Sun, 20 Oct 2024 23:13:05 GMT</pubDate>
    </item>
    <item>
      <title>使用鲁宾规则对多重响应（相同预测因子，不同结果）进行模型结果汇总</title>
      <link>https://stats.stackexchange.com/questions/656059/pooling-model-results-with-rubins-rule-for-multiple-responses-same-predictors</link>
      <description><![CDATA[我理解，Rubin 规则通常用于在多个插补数据集中汇总模型结果，其中使用同一组预测变量和响应，如下所示：
glmmTMB(varY ~ varA + varB + varC, data=imp1, truncated_nbinom2)
glmmTMB(varY ~ varA + varB + varC, data=imp2, truncated_nbinom2)
glmmTMB(varY ~ varA + varB + varC, data=imp3, truncated_nbinom2)

但是，我的情况略有不同。我有一个估算数据集，但我没有在估算数据集中构建具有相同响应变量的模型，而是构建了几个具有不同响应变量但具有相同预测变量的模型，这些模型来自相同的估算数据集，如下所示：
glmmTMB(varY1 ~ varA + varB + varC, data=imp, truncated_nbinom2)
glmmTMB(varY2 ~ varA + varB + varC, data=imp, truncated_nbinom2)
glmmTMB(varY3 ~ varA + varB + varC, data=imp, truncated_nbinom2)

glmmTMB R 包目前不允许拟合多变量模型（即在单个模型中有多个响应变量），因此我不得不为每个响应变量运行单独的模型。
我的问题是：

我可以申请在这种情况下，Rubin 规则是否汇总了这些模型的结果，即使响应变量不同但预测变量相同？
如果 Rubin 规则不合适，还有其​​他方法可以汇总结果并获得一组模型系数和标准误差吗？

任何建议都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/656059/pooling-model-results-with-rubins-rule-for-multiple-responses-same-predictors</guid>
      <pubDate>Sun, 20 Oct 2024 21:38:33 GMT</pubDate>
    </item>
    <item>
      <title>与常规回归模型相比，简单的算法</title>
      <link>https://stats.stackexchange.com/questions/656058/naive-algorithms-compared-to-the-regular-regression-models</link>
      <description><![CDATA[我有一个文件夹，其中包含许多 CSV 文件，这些文件的尺寸均为 24×25。每个 CSV 文件代表一天的数据。
我正在执行以下任务：
案例 1：考虑以下朴素分类器：对任何一天的猜测都只是前一天的地图。我的意思是简单地猜测第 2 天与第 1 天相同，猜测第 3 天与第 2 天相同，猜测第 4 天与第 3 天相同，......，猜测第 91 天与第 90 天相同。因此，之后我们得到了总共 90 天的数据和 90 个 mse，一个 mse 是我们从一天中获得的。
案例 2： 在这里，我尝试使用训练数据第 1 天、第 2 天、第 3 天预测第 4 天，使用训练数据第 2 天、第 3 天、第 4 天预测第 5 天，使用训练数据第 3 天、第 4 天、第 5 天预测第 6 天，使用训练数据第 90 天、第 91 天、第 92 天预测第 93 天。这里我们得到了 90 个预测文件，意味着总共 90 天的预测数据。这里我使用了 岭回归、线性回归和 LSTM 模型。并且我们为每个模型设置了 90 个 mse，每个模型每天设置一个 mse。
还请注意，对于这两种情况，我都使用 MinMaxScaler 将数据标准化为特定范围，通常在 0 到 1 之间。
我为这两种情况绘制的图表：

我的问题是，从上图中，与常规回归模型相比，您能解释什么（以及如何解释）LSTM 和朴素算法的行为？]]></description>
      <guid>https://stats.stackexchange.com/questions/656058/naive-algorithms-compared-to-the-regular-regression-models</guid>
      <pubDate>Sun, 20 Oct 2024 21:25:25 GMT</pubDate>
    </item>
    <item>
      <title>模型在训练和交叉验证集上表现良好，但在测试集上不准确。如何解决？</title>
      <link>https://stats.stackexchange.com/questions/656057/model-performs-well-on-train-and-cross-validation-sets-but-inaccurate-in-the-tes</link>
      <description><![CDATA[我一直在研究 CNN 二元分类模型，该模型在训练集和交叉验证集上的表现都相当不错（两者的准确率实际上都为 1.0）。但是，我还持有一个独特的测试集，用于在最后设置我的模型。
我这样做是因为我使用基于交叉验证准确率的超参数调整。我认为这可能会导致模型架构根据 cv 集过度拟合。
如何确保在超参数调整后，我的模型在测试集上表现良好，而该测试集在权重训练和 hp 调整期间均未使用？
我将在此处附上模型结果的图像（最底线是测试集上的准确率）：
]]></description>
      <guid>https://stats.stackexchange.com/questions/656057/model-performs-well-on-train-and-cross-validation-sets-but-inaccurate-in-the-tes</guid>
      <pubDate>Sun, 20 Oct 2024 21:09:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么中介模型需要对称的 Sigma 矩阵</title>
      <link>https://stats.stackexchange.com/questions/656056/why-mediation-models-require-a-sigma-matrix-that-is-symmetric</link>
      <description><![CDATA[我正在尝试适应以下称为final的可重现中介模型。但是我收到一条错误消息：

sigma 必须是对称矩阵

您能告诉我如何克服这个错误吗？
可重现的 R 代码：
df &lt;- read.csv(&quot;https://raw.githubusercontent.com/fpqq/w/refs/heads/main/t.csv&quot;)

library(glmmTMB)
library(mediation)

mediator &lt;- glmmTMB(pic_percent ~ con +
(0+con | ID) +
(0+con | TRIAL_INDEX),
data=df,
family = beta_family(),
ziformula = ~1)

outcome &lt;- glmmTMB(acc ~ con + pic_percent +
(0+con+pic_percent | Q),
数据 = df,
家庭 = 二项式())

最终 &lt;- mediate(mediator, 成果, sims=50,
treat=&quot;con&quot;, mediator=&quot;pic_percent&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/656056/why-mediation-models-require-a-sigma-matrix-that-is-symmetric</guid>
      <pubDate>Sun, 20 Oct 2024 20:30:10 GMT</pubDate>
    </item>
    <item>
      <title>比较比例时考虑不同的估计精度</title>
      <link>https://stats.stackexchange.com/questions/656055/accounting-for-varying-estimate-precision-when-comparing-proportions</link>
      <description><![CDATA[我被一个看似简单的问题难住了好几天，却找不到解决办法。
问题是：
我有来自几个流行病学单位（牛群）的血清流行率估计值（即抗体阳性个体的流行率），其中一半牛群的特征 A = 是，另一半牛群的特征 A = 否。这些估计值的精度因牛群而异，因为牛群内的采样率不同（范围从 0.2 到 1）。在评估特征 A 是否与牛群内血清流行率相关时，我该如何解释这种精度变化？
请注意，牛群的大小各不相同，而且是有限的，这意味着 30 个采样和测试的个体可能占整个牛群的 20% 到 100%。
逆方差加权是否合适？如果是，我应该如何处理完全采样的单元（方差 = 0）？
提前感谢您的任何建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/656055/accounting-for-varying-estimate-precision-when-comparing-proportions</guid>
      <pubDate>Sun, 20 Oct 2024 20:27:24 GMT</pubDate>
    </item>
    <item>
      <title>如何根据时间范围内的密度生成随机变量？</title>
      <link>https://stats.stackexchange.com/questions/656062/how-to-generate-a-random-variable-given-a-density-across-the-time</link>
      <description><![CDATA[假设我可以在时间间隔 $(0,1)$ 内观察到其密度 $f$。换句话说，我知道随时间变化的可能性。我不知道真正的 $f$ 是什么。我只有观察到的密度。现在我想进行抽样。假设我想从这个变量及其密度中抽取 200 个随机值。请注意，这 200 个随机值不包含时间信息。这只是重新采样。
例如，时间间隔 $(0,1)$ 内的以下 50 个密度观测值：
[1] 6.397494e-03 2.851705e-02 1.313016e-01 1.678541e-04 9.803000e-06 6.820610e-02 5.282000e-07 3.746964e-03
[9] 1.483590e-02 1.210750e-02 6.205821e-02 1.246754e-01 1.228650e-03 3.747048e-02 1.252511e-02 7.730145e-02 [17] 3.462294e+00 2.197282e-03 3.759454e-02 1.712373e+01 1.801570e-05 8.980809e-03 .132994e-04 4.948000e-07 [25] 2.481309e-02 1.180191e-01 2.097358e+01 1.477098e-02 1.493750e-03 2.860386e-02 1.073369e-01 5.086009e-03 [33] 4.559620e-03 2.331729e-02 5.502453e+00 1.175939e-02 6.951684e-02 2.664841e-03 5.525742e-02 5.367860e-05 1] 1.982810e-02 2.773967e-01 4.631920e-04 3.474500e-05 1.355636e+00 7.440144e-03 7.726980e-05 7.122710e-02 [49] 3.375027e-02 7.498346e-02
现在给定上述随时间观察到的密度，我想进行抽样。怎么做？
感谢 Henry 指出错误。我没有对密度进行标准化。标准化后，
sum(density[1:50,1])

[1] 1

density[1:50,1]
[1] 0.0001279499 0.0005703410 0.0026260318 0.0000033571 0.0000001961 0.0013641219 0.0000000106 0.0000749393
[9] 0.0002967180 0.0002421500 0.0012411641 0.0024935086 0.0000245730 0.0007494095 0.0002505022 0.0015460290 [17] 0.0692458852 0.0000439456 0.0007518908 0.3424745260 0.0000003603 0.0001796162 0 .0000102660 0.0000000099 [25] 0.0004962617 0.0023603813 0.4194716299 0.0002954195 0.0000298750 0.0005720771 0.0021467388 0.0001017202 [33] 0.0000911924 0.0004663458 0.1100490689 0.0002351879 0.0013903367 0.0000532968 0.0011051485 0.0000010736 [4 1] 0.0003965620 0.0055479335 0.0000092638 0.0000006949 0.0271127247 0.0001488029 0.0000015454 0.0014245419 [49] 0.0006750054 0.0014996692

这确实是时间间隔 [0,1] 上的适当概率密度函数。有 50 个点，对应于 50 个时间点。每个值代表过程在该特定时间点处于特定状态的相对可能性。
我现在想做什么？我想生成遵循此经验分布的随机值。这些随机样本（大小 = 200）将代表此密度函数所描述的过程的可能实现。它们只是我的经验密度函数所描述的随机变量的实现。]]></description>
      <guid>https://stats.stackexchange.com/questions/656062/how-to-generate-a-random-variable-given-a-density-across-the-time</guid>
      <pubDate>Sat, 19 Oct 2024 04:02:24 GMT</pubDate>
    </item>
    <item>
      <title>转换单位，用 extRemes 拟合极值分布时得到不同的结果</title>
      <link>https://stats.stackexchange.com/questions/655986/convert-units-get-different-results-when-fitting-extreme-value-distribution-wit</link>
      <description><![CDATA[我正在使用 fevd() 和 lr.test() 函数通过 extRemes R 包检查降水量。我的主要问题是，当我使用英寸和毫米作为输入数据时，我会得到不同的结果。其次，有时我会收到警告，我想知道它们是否表示采取了不同的路径来优化参数。
下面是一个示例，展示了乘数如何产生不同的结果。此外，如果我将种子设置为 3，则不会产生任何警告。如果将种子设置为 4，则当我使用 location.fun 参数拟合 fevd() 时会产生警告。
library(extRemes)
set.seed(3)
dat &lt;- data.frame(values = rnorm(30, mean = 3, sd = 1.5),
years = 1990:2019)
dat$values25 &lt;- dat$values*25
dat

gev_fit &lt;- fevd(x = values, data = dat, type = &quot;GEV&quot;)
gev_fit25 &lt;- fevd(x = values25, data = dat, type = &quot;GEV&quot;)
gev_fit
gev_fit25

# 拟合非平稳 GEV 分布
gev_fit_loc &lt;- fevd(x = values, data = dat, location.fun = ~ years, 
type = &quot;GEV&quot;)
gev_fit_loc25 &lt;- fevd(x = values25, data = dat, 
location.fun = ~ years, type = &quot;GEV&quot;)
gev_fit_loc
gev_fit_loc25

lr.test(gev_fit, gev_fit_loc)
lr.test(gev_fit25, gev_fit_loc25)

这是我的主要关注点：
第一个 lr.test() 给出 p 值为 0.7642，第二个报告 p 值为 1.0，尽管唯一的区别是第二个“25”示例中的输入数据已乘以 25。
有人知道为什么会发生这种情况吗？我是否忽略了一些显而易见的东西？
其次，如果我运行上述代码但将种子设置为 4，我会收到此警告：
&gt;In log(z) : NaNs generated

在拟合非平稳 GEV 时，但仅适用于“values”，而不是“values25”。有人能提供一些关于这个警告指示什么的见解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655986/convert-units-get-different-results-when-fitting-extreme-value-distribution-wit</guid>
      <pubDate>Thu, 17 Oct 2024 14:57:56 GMT</pubDate>
    </item>
    <item>
      <title>如何制作两个完全负相关的增长几何布朗运动（GBM）系列？（不可能）</title>
      <link>https://stats.stackexchange.com/questions/655735/how-to-make-two-perfectly-negatively-correlated-growing-geometric-brownian-motio</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655735/how-to-make-two-perfectly-negatively-correlated-growing-geometric-brownian-motio</guid>
      <pubDate>Fri, 11 Oct 2024 23:13:17 GMT</pubDate>
    </item>
    <item>
      <title>一维激活波的预期时间</title>
      <link>https://stats.stackexchange.com/questions/655603/expected-time-of-activation-waves-in-1-dimension</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655603/expected-time-of-activation-waves-in-1-dimension</guid>
      <pubDate>Fri, 27 Sep 2024 17:03:01 GMT</pubDate>
    </item>
    <item>
      <title>在扩散模型（DDPM）中，如果我们预测总噪声，为什么不直接在一次采样中去除噪声呢？</title>
      <link>https://stats.stackexchange.com/questions/650844/in-diffusion-models-ddpm-if-we-predict-the-total-noise-why-not-just-remove-t</link>
      <description><![CDATA[正如 DDPM 论文所指出的，我们可以选择将均值的预测重新参数化为总噪声的预测“εθ 是一个函数近似器，旨在根据 x 预测 ε”（公式 11）。那么，在采样过程中，我们为什么不直接从最后一步（纯噪声）中去除预测的总噪声，而是逐步采样图像？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650844/in-diffusion-models-ddpm-if-we-predict-the-total-noise-why-not-just-remove-t</guid>
      <pubDate>Thu, 11 Jul 2024 03:07:21 GMT</pubDate>
    </item>
    <item>
      <title>关于真实分数方差估计的效率（低下）我们了解多少？</title>
      <link>https://stats.stackexchange.com/questions/645385/what-is-known-about-the-inefficiency-of-true-score-variance-estimation</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/645385/what-is-known-about-the-inefficiency-of-true-score-variance-estimation</guid>
      <pubDate>Fri, 19 Apr 2024 13:09:09 GMT</pubDate>
    </item>
    <item>
      <title>使用 LightGBM 稀疏分类值时发出警告</title>
      <link>https://stats.stackexchange.com/questions/643248/warning-when-using-sparse-categorical-values-with-lightgbm</link>
      <description><![CDATA[当使用 lgbm.train 训练 LightGBM 模型时，我收到以下警告：

[LightGBM] [警告] 遇到包含稀疏值的分类特征。考虑重新编号为从零开始的连续整数

原因是我有一个指定为分类的列，其中包含以下整数：

[1015, 1033, 1128, 1398, 1541, 1673, 1677]

在lightgbm.train.html的文档中，它说：

“分类特征中的所有值都将转换为 int32，因此应小于 int32 最大值 (2147483647)。大值可能会消耗内存。考虑使用从零开始的连续整数。&quot;

我的值不是特别大。&quot;考虑使用从零开始的连续整数&quot;似乎是一个建议。如果不这样做会发生什么？稀疏性如何影响LightGBM的性能？数据集的另一个分类列具有值

[1, 3, 4]

并且它不会引起相同的警告。]]></description>
      <guid>https://stats.stackexchange.com/questions/643248/warning-when-using-sparse-categorical-values-with-lightgbm</guid>
      <pubDate>Fri, 22 Mar 2024 10:04:47 GMT</pubDate>
    </item>
    <item>
      <title>如何获取目的抽样的样本量？</title>
      <link>https://stats.stackexchange.com/questions/641267/how-to-get-sample-size-for-purposive-sampling</link>
      <description><![CDATA[如果我在研究中使用有目的抽样，我该如何获得样本量？这是对食品产品开发的感官评估，但有排除标准，所以我的顾问建议使用有目的抽样。我们将在一所小学进行调查，但受访者将仅限于愿意并符合标准的 12 岁学生。]]></description>
      <guid>https://stats.stackexchange.com/questions/641267/how-to-get-sample-size-for-purposive-sampling</guid>
      <pubDate>Tue, 27 Feb 2024 12:53:14 GMT</pubDate>
    </item>
    </channel>
</rss>