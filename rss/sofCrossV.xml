<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 25 Mar 2024 06:18:59 GMT</lastBuildDate>
    <item>
      <title>解释表中的危险比</title>
      <link>https://stats.stackexchange.com/questions/643453/interpreting-hazard-ratio-in-table</link>
      <description><![CDATA[此海报最近因其主题和结论而成为头条新闻。具体来说，我有兴趣了解如何计算此表中的风险比：

例如，让我们以“整体样本”为例。例子。参考组“12-16小时”是指参考组“12-16小时”。对于“＜8小时”组，具有423个事件和11831个样本。他们有31个事件，N为414。为了计算组“＜8h”的风险比，我认为这只是该组的危险除以参考组的危险：
（31/414）/（423/11831）
但是，这将等于 2.09，而不是参考的 1.91。有人可以解释一下显示/计算的内容以及它们是如何达到 1.91 的吗？ （或者提供在给定样本的情况下重新创建这些危险值的代码。）]]></description>
      <guid>https://stats.stackexchange.com/questions/643453/interpreting-hazard-ratio-in-table</guid>
      <pubDate>Mon, 25 Mar 2024 06:08:23 GMT</pubDate>
    </item>
    <item>
      <title>选择最通用的机器学习模型</title>
      <link>https://stats.stackexchange.com/questions/643445/select-the-most-general-machine-learning-model</link>
      <description><![CDATA[例如，假设模型 A 通过交叉验证的平均训练 auc 为 0.82，测试 auc 为 0.79。两个分数之间的差异为0.03。
假设模型 B 的训练 auc 为 0.79，测试 auc 为 0.78。两个分数之间的差异为0.01。机器学习的目标是泛化。
据我所知，训练和测试之间的差异越小，机器学习的泛化能力就越好。那么，模型 B 显然比模型 A 的训练和测试之间的差距更小。那么模型 B 是一个更好、更通用的模型吗？或者即使模型 A 的测试 auc 比模型 B 高 0.01，模型 A 仍然是一个优秀模型吗？
要统计选择模型，请获取两个模型的auc的置信区间并进行比较以选择模型。然而，传统统计学和机器学习的目标是不同的。所以我很困惑该怎么办]]></description>
      <guid>https://stats.stackexchange.com/questions/643445/select-the-most-general-machine-learning-model</guid>
      <pubDate>Mon, 25 Mar 2024 03:08:17 GMT</pubDate>
    </item>
    <item>
      <title>调查中 boostrap 和参数方法的误差范围差异</title>
      <link>https://stats.stackexchange.com/questions/643444/difference-in-margin-of-error-for-boostrap-and-parametric-approaches-in-survey</link>
      <description><![CDATA[我想知道使用引导程序导出的误差幅度进行简单调查是否合适。我担心这个估计太小了。我已为这两种上下文方法粘贴了下面的代码。
我对政治观点进行了一项简单的民意调查，样本量约为 450 名受访者。
我通过从数据帧中采样 3 个值（支持、反对、不知道）之一 5000 次来计算引导 MoE。然后，我计算了第 5、50 和 95 个百分位数中每个值的比例。为了获得保守的 MoE，我取了第 50 和第 5 或第 50 和第 95 之间的最大差异。最终比例最大的值约为2.8%（约68%的受访者支持）。
当我使用更传统的参数方法时，我会得到更大的误差范围 (4.3%)。这会产生影响，因为如果引导版本不正确，并且我的一些问题接近 50% 支持，我将需要收集更多回复。
参数化版本和引导版本如此不同是否有原因？举报更合适吗？
引导 MoE
将 numpy 导入为 np
将 pandas 导入为 pd

数据 = df[&#39;q1&#39;][df[&#39;q1&#39;] != &#39;NA&#39;]

print(&#39;样本大小:&#39;,len(数据))

# 初始化一个字典来存储每个值的计数
value_counts_dict = {value: [] for value in np.unique(data)}

# 自举采样循环
对于范围（5000）内的 i：
    # 创建引导样本
    bs_sample = np.random.choice(数据，大小=len(数据)，替换=True)

    # 计算引导样本中每个唯一条目的出现次数
    value_counts = {value: np.sum(bs_sample == value) for value in np.unique(data)}

    # 将计数追加到字典中
    对于值，在 value_counts.items() 中计数：
        value_counts_dict[值].append(count)

# 从字典创建一个DataFrame
df_bootstrap = pd.DataFrame(value_counts_dict)

# 计算每列的置信区间
置信区间 = df_bootstrap.quantile([0.05, 0.5, 0.95])

confidence_intervals_percentage =confidence_intervals.div(confidence_intervals.sum(axis=1), axis=0) * 100


# 计算每列第 50 个百分位数以及第 95 个和第 5 个百分位数之间的差异
Difference_50_95 =confidence_intervals_percentage.loc[0.5] -confidence_intervals_percentage.loc[0.95]
Difference_50_05 =confidence_intervals_percentage.loc[0.5] -confidence_intervals_percentage.loc[0.05]

# 为每列取两个差值中较大的一个
max_differences = Difference_50_95.abs().combine(difference_50_05.abs(), max)

# 找到这些最大差异中最大的项（列）
Maximum_max_difference_item = max_differences.idxmax()
最大最大差异值 = max_differences.max()

# 添加一个名为“moe”的新行每列的最大最大差异值
# 在这里，我们实际上想将其添加为反映观察到的最大差异的特定值
confidence_intervals_percentage.loc[“moe”] = max_differences

（最大最大差异项、最大最大差异值、置信区间百分比）

参数化教育部
导入 pandas 作为 pd
将 numpy 导入为 np
从 scipy.stats 导入规范

# DataFrame 创建示例
# df = pd.DataFrame({&#39;q1&#39;: [&#39;支持&#39;, &#39;反对&#39;, &#39;没有意见/na&#39;, &#39;NA&#39;, &#39;支持&#39;, &#39;反对&#39;, ...]})

# 计算不包括“NA”的响应总数
n = len(df[&#39;q1&#39;][df[&#39;q1&#39;] != &#39;NA&#39;])

# 95% 置信度的 Z 分数置信度
Z =norm.ppf(0.975) # 二尾

# 初始化一个字典来保存每个类别的 MoE
moe_dict = {}

对于 [&#39;无意见/na&#39;, &#39;反对&#39;, &#39;支持&#39;] 中的类别：
    # 计算该类别的比例
    p = len(df[&#39;q1&#39;][df[&#39;q1&#39;] == 类别]) / n
    
    # 计算该类别的 MoE
    MoE = Z * np.sqrt((p * (1 - p)) / n) *100
    
    # 将 MoE 存储在字典中
    moe_dict[类别] = 教育部

# 显示每个类别的 MoE
对于类别，MoE 在 moe_dict.items() 中：
    print(f“‘{category}’的误差范围：{MoE:.4f}”)
]]></description>
      <guid>https://stats.stackexchange.com/questions/643444/difference-in-margin-of-error-for-boostrap-and-parametric-approaches-in-survey</guid>
      <pubDate>Mon, 25 Mar 2024 01:32:13 GMT</pubDate>
    </item>
    <item>
      <title>MLE(Likelihood)和MAP的概念和表示法</title>
      <link>https://stats.stackexchange.com/questions/643442/the-concept-and-notation-about-mlelikelihood-and-map</link>
      <description><![CDATA[一般来说，我们说X1，X2，...，Xi来自某个分布，可以用f(x;θ)来表示，其中θ是一个未知参数。

当我阅读MLE或似然函数相关的内容时，经常看到用f(x|θ)来表示数据X1, X2, ..., Xi的分布。

在频率论中，θ 是一个未知参数，不是随机变量。

f(x;θ) 与 f(x|θ) 相同吗？

即使 θ 不是随机变量，f(x|θ) 也是条件概率吗？为什么？


在贝叶斯中，theta 是一个随机变量，而不是未知参数，公式为：

P 是类似 f 的分布。

为什么 P(x|θ) 是似然？ （θ 是随机变量！）

如果我们将 θ 固定为未知参数，即 P(θ=θ*)，MAP 等于 MLE 吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/643442/the-concept-and-notation-about-mlelikelihood-and-map</guid>
      <pubDate>Mon, 25 Mar 2024 00:43:23 GMT</pubDate>
    </item>
    <item>
      <title>了解 Keras 中 model.get_weights() 的输出 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/643441/understanding-output-of-model-get-weights-in-keras</link>
      <description><![CDATA[为了了解神经网络的工作原理，我决定训练一个超级简单的 2-1 网络来将其两个输入相加。这是我的代码。
将张量流导入为 tf
将 numpy 导入为 np
导入数学

x_train = np.random.rand(10000,2)
y_train = x_train[:,0]+x_train[:,1]

模型 = tf.keras.models.Sequential([
    tf.keras.layers.Dense(2),
    tf.keras.layers.Dense(1)
]）

model.compile(优化器=&#39;亚当&#39;,
              损失=tf.keras.losses.mean_squared_error,
              指标 = [])

model.fit(x_train, y_train, epochs=10)

对于 model.get_weights() 中的 i：
    打印(i,&#39;\n&#39;)

最后一个 for 循环输出以下内容。
&lt;前&gt;&lt;代码&gt;[[ 0.8512728 1.555682 ]
 [-0.04689309 1.6778996]]

[-0.23842156 -0.06958904]

[[0.09876956]
 [0.583725]]

[0.08260487]

模型表现良好，平均均方误差约为 $10^{-4}$。然而...

我不明白为什么有两个权重矩阵。为什么不只有一个，即从第一层（输入）到第二层（输出）的权重？
考虑到这些权重和偏差，我如何才能执行与我的模型 model 相同的计算？就像，我想我知道神经网络的基本代数理论，但现在第一个 2x2 权重矩阵出现了，我不太确定它是如何工作的。特别是，给定输入 $\mathbf{x}$，并将前面引用的输出的权重和偏差考虑为 $分别为 W_0,b_0,W_1,b_1$，我尝试计算
$$\mathbf{y}=W_1(W_0\mathbf{x}+b_0)+b_1$$
但这确实不接近网络的输出，即 $\mathbf{y}$ 强烈不同意 $ (1,1)\mathbf{x}$。

请问有人可以告诉我我在这里缺少什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/643441/understanding-output-of-model-get-weights-in-keras</guid>
      <pubDate>Sun, 24 Mar 2024 23:51:24 GMT</pubDate>
    </item>
    <item>
      <title>为什么最好使用似然比检验来检验预测变量的效果？</title>
      <link>https://stats.stackexchange.com/questions/643440/why-is-it-preferable-to-test-the-effect-of-a-predictor-using-a-likelihood-ratio</link>
      <description><![CDATA[在他们的精彩著作应用纵向数据分析：对变化和事件发生进行建模 Singer 和 Willett 提倡使用迭代模型比较技术来测试预测变量的效果：从基线模型开始，然后添加预测变量，一次一个，对一系列后续模型，使用似然比检验来确定向模型添加新预测变量是否会显着降低 -2LL 偏差。这些是嵌套模型，因此每个 LR 测试实际上都会测试每个新预测变量的效果。如果 -2LL 偏差显着减少，则保留新模型，否则保留先前模型。
他们表示，他们推荐这种技术，而不是简单地将打算在单个回归模型中测试的所有预测变量包括在内，并报告置信区间和 p 值。
我已经接受了他们的建议，但我不太明白为什么（即基于什么理由）他们认为他们的迭代方法优于“全力以赴”的方法。
我问这个问题的原因是，我已经对几篇论文进行了分析，我的合著者对迭代方法感到非常困惑。可能是我解释得不够好，但我想要一些更可靠的使用它的理由，而不是“因为辛格和威利特这么说”。
非常感谢通俗易懂的语言解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/643440/why-is-it-preferable-to-test-the-effect-of-a-predictor-using-a-likelihood-ratio</guid>
      <pubDate>Sun, 24 Mar 2024 23:33:10 GMT</pubDate>
    </item>
    <item>
      <title>cookie问题中有两种计算合取概率的方法吗？</title>
      <link>https://stats.stackexchange.com/questions/643423/are-there-two-ways-to-calculate-conjunction-probability-in-the-cookie-problem</link>
      <description><![CDATA[我正在阅读 Allen B. Downey 的《思考贝叶斯》。
他介绍了一个简单的条件概率问题。
你有两碗饼干。
第 1 碗有 30 块香草饼干和 10 块巧克力饼干
2 号碗有 20 块香草饼干和 20 块巧克力饼干
如果您选择一块饼干并且它是香草饼干，那么它来自第 1 碗的概率是多少？假设您从任一碗中进行选择的概率相同 (0.5)。
您可以使用条件概率公式来解决这个问题。
P(碗 1 | 香草) = P(碗 1 ∩ 香草) / P(香草)
似乎有两种方法可以求解分子：P(Bowl 1 ∩ Vanilla)
据我了解，相交概率 (∩) 可以通过乘以每个事件的概率来计算。因此，要计算分子，您需要乘以 P(Bowl 1) * P(Vanilla)
这将是（0.5 *（从碗 1 中选择香草的概率）
或 (0.5 * 0.75) = 0.375
将其代入条件概率公式，得出 0.375/0.625 = 0.6
克劳德（AI 聊天机器人）提出了这个计算来确定分子。
第 1 碗中的香草饼干/饼干总数，即 30/80 或 0.375
这是计算分子的比我假设的更准确的方法吗？
P（碗1）* P（香草）]]></description>
      <guid>https://stats.stackexchange.com/questions/643423/are-there-two-ways-to-calculate-conjunction-probability-in-the-cookie-problem</guid>
      <pubDate>Sun, 24 Mar 2024 20:39:34 GMT</pubDate>
    </item>
    <item>
      <title>我们相信贝叶斯统计中存在真正的先验分布吗？</title>
      <link>https://stats.stackexchange.com/questions/643422/do-we-believe-in-existence-of-true-prior-distribution-in-bayesian-statistics</link>
      <description><![CDATA[设 $X$ 为 $\mathcal{X}$ 值随机变量。假设我们观察到 $X = x$。
我们使用参数模型，以 $\theta \in \Theta$ 为参数。
在频率论方法中，我们相信存在一个真正的$\theta \in \Theta$，它决定了$X$。推理过程是我们使用 $x$ 来估计这个真实的 $\theta$。
在贝叶斯方法中，我们对 $\Theta$ 施加先验概率测量 $\Pi$ 。实际的推理过程是我们找到一个统计模型（概率度量的集合 $\mathcal{P}$ 其中 $ P_{X \mid \theta = \theta}$ 取值) 以及之前反映客户信念的 $\Pi$，更新 &lt; span class=&quot;math-container&quot;&gt;$\Pi$ 使用$x$，根据后验分布得出结论。实际上没有其他方法可以完成这项工作。
我的问题是，当我们采用贝叶斯框架，选择统计模型$\mathcal{P}$后，我们是否相信存在$\theta$、$P_{\theta}$ 的真实分布（这样我们就可以看到后验分布）作为对这个真实 $P_{\theta}$ 的估计）？我认为，即使我们相信这一点，也可能不会影响我们实际开展工作的方式。但似乎，一旦我们相信它，贝叶斯方法就完全包含了频率论方法（让 $P_{\theta}$ 专注于单例）。 p&gt;
编辑：抱歉。术语“真实先验”是指术语“真实先验”。可能会产生误导。我已经编辑了这个问题，完全避免使用这个术语。]]></description>
      <guid>https://stats.stackexchange.com/questions/643422/do-we-believe-in-existence-of-true-prior-distribution-in-bayesian-statistics</guid>
      <pubDate>Sun, 24 Mar 2024 20:34:31 GMT</pubDate>
    </item>
    <item>
      <title>当有一年中的季节和月份信息时，如何正确评估响应与时间之间的关系作为预测变量？</title>
      <link>https://stats.stackexchange.com/questions/643416/how-to-properly-assess-relationship-between-response-and-time-as-a-predictor-whe</link>
      <description><![CDATA[我希望能够通过线性混合效应模型或分层 GAM（如果适用）进行测试，看看参与者粪便代谢物和时间之间是否存在关系（线性或非线性）。
从 11 月（秋季）开始，每个受试者 (n=150) 每个月都提供一个样本。
我需要考虑不同的时间组成部分，季节（秋季、冬季、春夏、秋季）或月份。

如果我想查看季节性变化（将其作为连续或分类来比较不同的季节对），我是否需要有时间（以月为单位）作为协变量，如果是的话，作为连续或分类？

如果我只想查看与时间的关系（连续或比较月份，而不被季节性变化混淆），我的模型中是否有季节作为协变量？当然，当月份恰好处于同一季节期间时，在进行成对比较时则不然。


我问的原因是根据我见过的一些示例模型，我有点不确定，例如如果有季节和一年中的日期或月份的信息，则在考虑时间与其响应之间任何可能的关系时，他们的模型中不存在季节性协变量，而季节变化会随着时间的推移影响响应。
任何想法或重定向到更好的资源/示例将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/643416/how-to-properly-assess-relationship-between-response-and-time-as-a-predictor-whe</guid>
      <pubDate>Sun, 24 Mar 2024 18:56:48 GMT</pubDate>
    </item>
    <item>
      <title>相关眼睛数据的样本量计算</title>
      <link>https://stats.stackexchange.com/questions/643191/sample-size-calculation-for-correlated-eye-data</link>
      <description><![CDATA[什么公式或软件包可用于计算相关眼数据的样本量？一项观察性研究正在招募具有两只正常眼睛的参与者和一只眼睛患有临床病症且第二只眼睛患有另一种临床病症的参与者。所以我有以下几组（病例对照抽样设计，3组）：
A组：两只眼睛正常的参与者（包括双眼）
B 组：一只眼睛出现临床症状
C 组：另一只眼睛出现临床症状
在A组中，包括参与者的双眼，因此这些眼睛将被关联。在B 组和C 组中，双眼均经过评估，然后分为B 组和C 组，因此这些组也具有相关性。
该研究的目的是评估三组之间连续结果的临床意义差异，其中样本量公式适合此处； i) 如果结果连续正常， ii) 如果结果连续非正常。如果各组是独立的，则方差分析模型的功效分析可能是合适的，但由于我们正在处理相关的眼睛数据，因此不清楚应使用哪个样本量公式。]]></description>
      <guid>https://stats.stackexchange.com/questions/643191/sample-size-calculation-for-correlated-eye-data</guid>
      <pubDate>Thu, 21 Mar 2024 18:20:36 GMT</pubDate>
    </item>
    <item>
      <title>泊松-伽马混合中形状和速率参数的后验分布</title>
      <link>https://stats.stackexchange.com/questions/642931/posterior-distribution-of-shape-rate-parameter-in-poisson-gamma-mixture</link>
      <description><![CDATA[目前我正在努力解决以下问题。
&lt;小时/&gt;
&lt;块引用&gt;
假设 $x_i,(i=1,2,\dots,n)$ 服从泊松分布：
$$p(x_i|\theta) = \frac{\theta^{x_i}e^{-\theta}}{x_i!}, \quad x_i\in\mathbb N ,\quad \theta&gt;0.$$
如果 $\theta|(\alpha,\beta)\sim\Gamma(\alpha,\beta)$，我们有
$$p(x_i|\alpha,\beta) = \binom{\alpha+x_i-1}{x_i}\Bigl(\frac{\beta}{\beta+1 }\Bigr)^{\alpha}\Bigl(\frac{1}{\beta+1}\Bigr)^{x_i},\quad \alpha,\beta&gt;0.$$
在这些事实下，使用非信息性先验 $p(\ alpha,\beta)\propto1$.

&lt;小时/&gt;
我尝试按如下方式解决它：（令 $\mathbf x := (x_1,\dots,x_n)$）
$$\begin{对齐}
p(\alpha,\beta|\mathbf x) &amp;propto p(\alpha,\beta)p(\mathbf x|\alpha,\beta) \\
&amp;\propto1*\prod_{i=1}^n\binom{\alpha+x_i-1}{x_i}\Bigl(\frac{\beta}{\beta+1}\Bigr)^{\alpha} \Bigl(\frac{1}{\beta+1}\Bigr)^{x_i} \\
&amp;=\Biggl\{\prod_{i=1}^n\binom{\alpha+x_i-1}{x_i}\Biggr\}\Biggl(\frac{\beta}{\beta+1}\Biggr )^{n\alpha}\Biggl(\frac{1}{\beta+1}\Biggr)^{\sum_i x_i}。
\end{对齐}$$
起初，我猜测 $(\alpha,\beta)|\mathbf x$ 遵循某种与负二项式分布类似的形式，但我未能得到（我想要的）结果。
所以，我想检查一下我的估计是否错误，如果没有，我该如何完成上面的等式。预先感谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/642931/posterior-distribution-of-shape-rate-parameter-in-poisson-gamma-mixture</guid>
      <pubDate>Tue, 19 Mar 2024 09:02:24 GMT</pubDate>
    </item>
    <item>
      <title>序贯分析——调整效应大小</title>
      <link>https://stats.stackexchange.com/questions/642677/sequential-analysis-adjusting-effect-size</link>
      <description><![CDATA[我知道顺序测试有风险，但无论如何我这样做都是有意义的。所以，我想仔细阅读，并正确地做到这一点。
我的想法（这可能并不新鲜）：
在我的现实中，假设检验中的真实效果有时会大大超过最小效果大小。因此，为了更有效地利用资源，我打算在内曼-皮尔逊框架中使用高假设效应大小进行测试。然后，只有当我无法显示高效应大小时，我才会将假设的效应大小降低到我在开始实验之前确定的某个水平，并根据需要收集更多数据以实现所需的功效。我重复此操作，直到达到我试图确定的最小效果大小。
现在，当然，我的测试不再是独立的，因此 I 类和 II 类错误率的通常计算变得无效。我认为假设效应大小的变化至少应该抵消其中的一部分，但我基本上只是猜测 - 而且猜测并不像内曼皮尔逊那样;)
我发现很难找到这个研究领域的切入点，因为我还不知道术语，所以我不知道要寻找什么。我进行了快速搜索，找到了有关 Wald、Pocock 和 Haybitttle-Peto 的一些一般信息。看来这些策略的开发是为了在效果大小不可知的费舍尔框架中保留 $\alpha$ （如果我没有误解的话）。这和我想象的有点不同。
那么，我需要查找的内容的名称是什么？有什么好书可以开始读呢？
（或者，我的想法有根本缺陷吗？）]]></description>
      <guid>https://stats.stackexchange.com/questions/642677/sequential-analysis-adjusting-effect-size</guid>
      <pubDate>Fri, 15 Mar 2024 09:43:50 GMT</pubDate>
    </item>
    <item>
      <title>卡方去噪的效率</title>
      <link>https://stats.stackexchange.com/questions/637361/efficiency-of-chi-squared-denoising</link>
      <description><![CDATA[假设我的测量 $\theta+\epsilon$ 被 IID 加性噪声损坏 $\epsilon$以卡方分布（已知） $d$ 自由度，合并多个观测值来推断  的效率是多少$\theta$?
使用 Fisher 信息的定义，我得到位置参数 $\theta$ 的 Fisher 信息的以下表达式，奇点位于 $d=4$。
$$\frac{1}{2(d-4)}, d&gt;4$$

Charles 张的答案表明Fisher信息的分歧意味着MLE比$O(1/\sqrt{n})$。
“快”到底有多快？在这种情况下？固定 $d$ 的样本大小是否为多项式？

笔记本]]></description>
      <guid>https://stats.stackexchange.com/questions/637361/efficiency-of-chi-squared-denoising</guid>
      <pubDate>Sun, 21 Jan 2024 00:17:32 GMT</pubDate>
    </item>
    <item>
      <title>从 GAM 获得无偏导数</title>
      <link>https://stats.stackexchange.com/questions/634907/get-unbiased-derivative-from-gam</link>
      <description><![CDATA[我有与时间相关的数据，并且我对零时刻的梯度感兴趣。从理论上讲，我预计真实关系的梯度在零时刻最高。
我想使用 GAM 来估计零时刻的导数。然而，估计有偏差（太低）。我怎样才能减少或最好消除这种偏见？
#HM函数
HM &lt;- 函数(t, f0, phi, kappa) phi + f0 * exp(-kappa * t)/(-kappa)

时间 &lt;- 0:180
Φ &lt;- 530
卡伯 &lt;- 0.025
f0 &lt;- 5
Ctrue &lt;- HM(t, f0, phi, kappa)

sdC &lt;- 5

库（mgcv）
图书馆（谢谢）

设置.种子(1)
res &lt;- 复制(100, {
  
  C &lt;- Ctrue + rnorm(长度(t), sd = sdC)
  
  DF &lt;- data.frame(C, t)
  
  
  拟合 &lt;- gam(C ~ s(t, bs = &quot;bs&quot;, k = 5), data = DF)
  #gam.check(适合)
  
  #ggplot(DF, aes(t, C)) +
  # geom_point() +
  # stat_function(fun = \(t) 预测(fit, newdata = data.frame(t)))
  
  导数（拟合，数据= data.frame（t = 0））
  
}，简化=假）


res &lt;- do.call(rbind, res)

摘要（res$导数）
# 分钟。第一曲。第三曲区中位数平均值。最大限度。
#4.266 4.432 4.508 4.517 4.589 4.773

#真实值为5
]]></description>
      <guid>https://stats.stackexchange.com/questions/634907/get-unbiased-derivative-from-gam</guid>
      <pubDate>Thu, 14 Dec 2023 13:54:29 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们需要在交互模型中对低阶效应进行建模？</title>
      <link>https://stats.stackexchange.com/questions/570759/why-do-we-need-to-model-lower-order-effects-in-models-with-interactions</link>
      <description><![CDATA[最近看到一篇论文，有四向交互。这已经很难解释了（也许如果你有 1 个或多个分类变量，但如果都是连续的，则绝对几乎不可能解释）并且你几乎肯定对此能力不足。
但除了四向交互之外，研究人员仅对一个主效应、两个双向交互作用和两个三向交互作用进行了建模。因此，作者在他们的（已经很难解释的）四向交互中放弃了一堆低阶效应。
我知道这是一个问题。就后果而言，当您忽略低阶效应时，它会增加交互效应显示为误报的可能性。
但是我仍然有点困惑为什么从数学上来说这是一个问题？为什么不同时对交互作用的低阶效应进行建模是一个坏主意或在数学上存在问题？有人可以向我解释或解释为什么在交互中对低阶效应进行建模很重要吗？为什么有必要？任何其他细节或意见将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/570759/why-do-we-need-to-model-lower-order-effects-in-models-with-interactions</guid>
      <pubDate>Thu, 07 Apr 2022 15:23:28 GMT</pubDate>
    </item>
    </channel>
</rss>