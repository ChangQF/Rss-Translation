<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 15 May 2024 12:28:06 GMT</lastBuildDate>
    <item>
      <title>FPP 教科书中的简单指数平滑（状态空间形式）中的误差和残差</title>
      <link>https://stats.stackexchange.com/questions/647280/errors-and-residuals-in-simple-exponential-smoothing-state-space-form-in-fpp-t</link>
      <description><![CDATA[我正在阅读 Hyndman &amp; Athanasopoulos《预测：原理与实践》第二版（FPP2）。 （我知道存在第三版。）在关于指数平滑的章节中，第 7.5 节讨论了具有附加误差的简单指数平滑，ETS(A,N,N)。它引入了残差 $e_t:=y_t-\ell_{t-1}$ 其中 $\ell_{t-1 }$ 是平滑方程的滞后水平。然后就在下面几行，有下面一段话：
&lt;块引用&gt;
对于具有加性误差的模型，我们假设残差（一步训练误差）$e_t$ 是正态分布的白噪声，平均值为 $0$ 和方差 $\sigma^2$。其简写形式为 $e_t = \varepsilon_t \sim NID(0,\sigma^2)$; NID 代表“正态独立分布”。

然后使用 $e_t$ 的一些方程用 $\varepsilon_t$ 重写。我对引用段落中 $e_t = \varepsilon_t$ 的含义有点困惑。它只是为 $e_t$ 引入了一个新符号吗？如果是这样，为什么不从一开始就使用 $\varepsilon_t$ 呢？或者 $e_t = \varepsilon_t$ 是否具有其自身的某种含义，告诉我们一个对象等于另一个对象？如果是这样，会有什么影响？简而言之，编写 $e_t = \varepsilon_t$ 的意义是什么？
（本书的某些部分似乎对模型误差（随机变量）、拟合误差/残差（其拟合值）和输入与输出之间的区别有点粗心，这并没有帮助。 -样本预测误差（随机变量或其实现）。）]]></description>
      <guid>https://stats.stackexchange.com/questions/647280/errors-and-residuals-in-simple-exponential-smoothing-state-space-form-in-fpp-t</guid>
      <pubDate>Wed, 15 May 2024 11:39:19 GMT</pubDate>
    </item>
    <item>
      <title>使用 MMRM（重复测量混合模型）分析的假设是什么？</title>
      <link>https://stats.stackexchange.com/questions/647279/what-are-the-assumptions-of-using-mmrm-mixed-model-for-repeated-measures-analy</link>
      <description><![CDATA[我想知道使用 MMRM 分析的假设是什么？例如，正态分布和因变量是连续和区间水平？]]></description>
      <guid>https://stats.stackexchange.com/questions/647279/what-are-the-assumptions-of-using-mmrm-mixed-model-for-repeated-measures-analy</guid>
      <pubDate>Wed, 15 May 2024 11:37:09 GMT</pubDate>
    </item>
    <item>
      <title>重复测量、混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/647278/the-repeated-measures-mixed-effects-models</link>
      <description><![CDATA[我的数据集包含接受过干预或安慰剂治疗的参与者，结果是唾液流（连续），并在 0、4 和 12 个月时进行测量。结果变量 (Yi) 是因变量，使用多级重复测量随机效应模型，以参与者为随机效应因子，以时间（3 个水平，包括基线）作为基于限制最大似然 (REML) 的固定效应因子） 模型。该统计模型将保存从基线（包括基线）起 12 个月内所有评估点的所有时间间比较，从而可以评估平均效果以及从基线到 12 个月随访的时间轨迹。
以下内容是否包含上述内容：
模型 &lt;- lmer(UnstimSalivaFlow ~ GROUP * MONTH + (1|PtID), data = data)

此外，我希望输出分别为 group_intervention 和 group_placebo 中相对于基线的变化，并报告为最小二乘均值，包括组的 p 值。
谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/647278/the-repeated-measures-mixed-effects-models</guid>
      <pubDate>Wed, 15 May 2024 11:29:03 GMT</pubDate>
    </item>
    <item>
      <title>如何对异质计数数据建模？</title>
      <link>https://stats.stackexchange.com/questions/647277/how-to-model-heterogenenous-count-data</link>
      <description><![CDATA[我一直在尝试不同的模型来模拟高度可变的计数数据（均值 8.5，方差 144.3），该数据按参与者分组（每个参与者进行 4 到 16 次测试）。每个参与者的错误计数也有很大差异。
我感兴趣的是是否有一个模型可以准确捕获这些数据。广义泊松模型给出最低的 AIC/BIC 值（尽管与负二项式模型（glmmTBB 中的 nbinom1）非常相似。
total_errors_mdl_e3a_genp &lt;- glmmTMB(
  公式=total_errors~版本+(1|participant_id)+(1|件)+(1|订单),
  数据=total_errors_table_e3,
  家庭 = genpois()
）

但是在检查模型诊断时，残差存在偏差，我对模型输出持怀疑态度，尽管我不确定问题有多大。

我们的实验涉及钢琴家视奏音乐作品。我们的假设是，当参与者面临挑战时，版本 2 会减少错误，而当测试很简单时，版本 2 则没有效果。为了测试我们是否为每个参与者提供了一系列逐渐升级的难度，一直持续到他们达到最终级别或无法进一步进步为止。
虽然我们可以拆分数据，以便过滤掉“简单”的测试结果，并在最大挑战水平下查看参与者的数据，但我希望有某种方法可以对整个数据集进行建模来测试这一假设。非常感谢任何帮助或指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/647277/how-to-model-heterogenenous-count-data</guid>
      <pubDate>Wed, 15 May 2024 11:11:22 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用 GLS corCAR1 控制个人和家庭内的自相关？</title>
      <link>https://stats.stackexchange.com/questions/647276/is-it-possible-to-control-for-autocorrelation-within-individuals-and-families-us</link>
      <description><![CDATA[我有一个双胞胎样本，并重复测量了 BMI。我想确定某种营养素的摄入量是否与 BMI 轨迹相关。我一直在 R 中的 nlme 包中使用 GLS。我使用了 correlation = corCAR1(form = ~age|twinID) 但意识到这并没有考虑到自相关家庭 (famID)。是否可以同时控制 twinID 和 famID 自相关？我尝试过 correlation = corCAR1(form = ~age|twinID/famID) 但这对输出没有影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/647276/is-it-possible-to-control-for-autocorrelation-within-individuals-and-families-us</guid>
      <pubDate>Wed, 15 May 2024 11:08:44 GMT</pubDate>
    </item>
    <item>
      <title>随机森林模型到底是如何通过插入符中的交叉验证进行训练的？</title>
      <link>https://stats.stackexchange.com/questions/647275/how-exactly-a-random-forest-model-was-trained-by-cross-validation-in-caret</link>
      <description><![CDATA[这是我用于通过插入符中交叉验证来训练随机森林模型的代码：
&lt;前&gt;&lt;代码&gt;库(mlbench)
数据（声纳）

x&lt;-声纳[,1:60]
y&lt;-声纳[,61]

库（插入符号）

设置.种子(1234)
cv_folds &lt;- createFolds(y, k = 10, returnTrain = TRUE)

ctrl &lt;- trainControl(方法 = &quot;cv&quot;,
                     数量 = 10,
                     搜索=&#39;网格&#39;，
                     类概率 = TRUE,
                     保存预测 = TRUE,
                     索引 = cv_folds,
                     摘要函数=两个类摘要）

tuneGrid &lt;- Expand.grid(.mtry = c(1:10))

设置.种子(123)
rf_model &lt;- 训练(Class~.,
                  数据=声纳，
                  方法=“rf”，
                  重要性=真，
                  度量=“ROC”，
                  调网格 = 调网格,
                  trControl = ctrl,
                  n树= 1500，
                  节点大小 = 5)

现在我试图了解模型是如何训练的，这是我的想法：
既然是网格搜索，我们先用mtry=1来走一遍。
首先，生成 10 次折叠 (k=10) 以进行交叉验证。 Sonar 数据集中有 208 个 obs，因此 208/10 约为 21 个。
假设在 Fold01 中，21 个 obs 用于验证，其余 187 个用于训练包含 1500 棵树（ntree = 1500）的随机森林模型。在代码中，method的设置是“cv”。而不是“oob”，所以我认为不会执行装袋来生成 1500 个训练子集。因此，每棵树的生长都将使用相同的 187 个 obs。在每棵树上，用于分裂的节点是从随机生成的 1 个变量池中选择的（即 mtry=1）。当池较大时（即mtry&gt;1），将通过基尼指数选择最佳节点。当剩下少于 5 个 obs 可供节点分裂时（即节点大小 = 5），树停止生长。然后每棵树都会对这187个obs进行分类。最终的分类结果是基于1500棵树的多数票。现在我们在这 21 个 obs 上使用这个经过训练的模型进行验证，并得到 21 个“OOB”。 Fold01 的预测率。 AUC（即指标 =“ROC”）是根据 Fold01 中的 21 个 obs 计算的。
同样的事情在 Fold02 到 Fold10 中重复出现。当 mtry=1 时，我们最终得到了 10 AUC。与 mtry=2,3,...10 中的值进行比较后，将使用这 10 个 AUC 的平均值来选择最佳 mtry 数。
在该示例中，当 mtry=2 时，平均 AUC 达到最高。然后使用 mtry=2 和整个 208 个 obs 来训练最终的模型。通过设置 mtry=2，以与上述相同的方式种植 1500 棵新树。并且不再进行交叉验证。因此每棵树都是使用 208 个 obs 来生长的。
我的理解正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647275/how-exactly-a-random-forest-model-was-trained-by-cross-validation-in-caret</guid>
      <pubDate>Wed, 15 May 2024 10:52:48 GMT</pubDate>
    </item>
    <item>
      <title>使用平衡拉丁方在不完整的平衡措施设计中证明不均匀的组大小</title>
      <link>https://stats.stackexchange.com/questions/647274/justifying-uneven-group-sizes-in-an-incomplete-counterbalanced-measures-design-u</link>
      <description><![CDATA[我正在对一项实验进行统计分析，我们向一组人展示了 6 个视频，并要求他们评价其效果。为了解决顺序带来的偏差，我们将参与者分为 6 组，然后根据平衡拉丁方选择视频顺序。问题是并不是每个人都完成了调查，而且小组规模也参差不齐。现在无法进行更多试验。
我们别无选择，只能按原样使用数据。我想知道这里是否有人可以就如何在论文中表达内容提供一些建议。换句话说，我怎么说“事情没有完全按照计划进行，但他们观看视频的顺序仍然足够混合，结果是可靠的”？以适合研究文章的方式。
其中四组最终有大约 40 名参与者，一组有 20 名参与者，最后一组有 10 名参与者。
谢谢，
格雷格]]></description>
      <guid>https://stats.stackexchange.com/questions/647274/justifying-uneven-group-sizes-in-an-incomplete-counterbalanced-measures-design-u</guid>
      <pubDate>Wed, 15 May 2024 10:35:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么这 2 个 MAG 马尔可夫等价？</title>
      <link>https://stats.stackexchange.com/questions/647272/why-are-these-2-mags-markov-equivalent</link>
      <description><![CDATA[
有人可以帮助我思考为什么这 2 个 MAG 是马尔可夫等效的（暗示 m 分离标准的相同约束）？我问这个问题是因为我还不太熟悉所有 MAG 术语（主动路径、m 分离、诱导路径）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647272/why-are-these-2-mags-markov-equivalent</guid>
      <pubDate>Wed, 15 May 2024 10:04:38 GMT</pubDate>
    </item>
    <item>
      <title>神经网络函数的导数</title>
      <link>https://stats.stackexchange.com/questions/647270/the-derivative-of-the-neural-network-function</link>
      <description><![CDATA[我使用 ANN 来解决使用 Python 预测银行部门客户流失的问题。如果我们将 ANN 视为接受输入向量 $x$ 并返回输出 $f(x)$ 的函数&gt;，这个函数的导数是什么，$f&#39;(x)$？我们如何在Python中计算它？有这方面的图书馆吗？或任何预先准备的代码？
我使用的数据集是来自kaggle的“Churn_Data.xlsx”，我将其转换为xlsx格式...
https://www.kaggle.com/code/kmalit /银行客户流失预测
数据准备代码如下...
导入io
df = pd.read_excel(io.BytesIO(upoaded[&#39;Churn_Data.xlsx&#39;]))
df = df.drop(columns=[&#39;行号&#39;, &#39;CustomerId&#39;, &#39;姓氏&#39;], axis=1)

数据集 = pd.get_dummies(data=df, drop_first=True)

x = dataset.drop(columns=&#39;已退出&#39;)
y = 数据集[&#39;已退出&#39;]

从 sklearn.model_selection 导入 train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)

x_train.shape、x_test.shape、y_train.shape、y_test.shape


训练和测试数据的大小如下...
&lt;前&gt;&lt;代码&gt;((8000, 11), (2000, 11), (8000,), (2000,))

from sklearn.preprocessing import StandardScaler

sc = 标准缩放器()

x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

现在为了构建 ANN 顺序模型，我编写了这段代码......
#构建模型

模型 = tf.keras.models.Sequential()

# 第一个输入层

model.add(tf.keras.layers.Dense(单位=6，激活=&#39;relu&#39;，input_dim=11))

# 第二个输入层

model.add(tf.keras.layers.Dense(单位=6,激活=&#39;relu&#39;))

# 第三输入层

model.add(tf.keras.layers.Dense(单位=1,激活=&#39;sigmoid&#39;))

# 编译模型

model.compile（优化器=&#39;adam&#39;，损失=&#39;binary_crossentropy&#39;，指标=&#39;准确性&#39;）
模型.summary()

# 将模型拟合到数据集

model.fit(x_train, y_train.to_numpy(), batch_size=10, epochs=20)

#评估模型

test_loss, test_accuracy = model.evaluate(x_test, y_test.to_numpy())

print(&#39;测试准确度:{}&#39;.format(test_accuracy))

现在如何找到训练数据中每个向量的导数？]]></description>
      <guid>https://stats.stackexchange.com/questions/647270/the-derivative-of-the-neural-network-function</guid>
      <pubDate>Wed, 15 May 2024 09:47:49 GMT</pubDate>
    </item>
    <item>
      <title>比较人工估计和标准化分数的算法</title>
      <link>https://stats.stackexchange.com/questions/647269/comparing-human-estimates-and-algorithm-on-nomalized-score</link>
      <description><![CDATA[通过算法，我们希望预测一个指标值 $Y$，该值可能因不同项目而异 $ i=1,\ldots,n$。数量 $y_i$ 已由 $N$ 人工注释者估计，我们想要计算性能分数算法。
相对于人类平均值的均方误差或绝对误差（MSE、MAE）并不是衡量算法准确性的良好指标，因为 $y_i$ 可能存在很大差异，和一个错误，例如5 对于 $y_i=50$ 来说很好，但对于 $y_i=6$ 来说很差。为了使 $y_i$ 的规模具有可比性，我们考虑为每个算法结果计算 z 分数*)，然后对所有 z 分数进行平均。然而，这存在一个问题，即对于某些项目，人类之间的方差为零。
*) 与 $z=\frac{y_{alg} \;-\; \overline{y_i}}{\hat{\sigma}_i}$ 与 $\overline{y_i}$ 和 $\hat{\sigma}_i$ 根据人类结果估计。
是否存在一些已确定的“标准化误差”？对于这种情况？请注意，我们对 p 值不感兴趣，即是否有差异，但差异有多大。]]></description>
      <guid>https://stats.stackexchange.com/questions/647269/comparing-human-estimates-and-algorithm-on-nomalized-score</guid>
      <pubDate>Wed, 15 May 2024 09:22:22 GMT</pubDate>
    </item>
    <item>
      <title>描述数据结构并指定 nlme 中具有嵌套和交叉效应的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/647268/describing-data-structure-and-specifying-a-linear-mixed-model-in-nlme-with-neste</link>
      <description><![CDATA[我正在尝试指定一个线性混合模型来分析具有以下结构的数据，并且有几个关于正确描述数据结构以及如何指定模型的问题。在尝试指定混合模型时，我经常遇到类似的问题，这个示例让我有机会查询我的一些（错误）理解。
动物的响应变量（我们称之为代谢率 (MR)）是在 6 种不同条件（A 到 F）下测量的。将动物分为两组（G1 和 G2），每只动物仅在 3 种条件下进行测试。测试顺序（条件）取决于动物所在的组。
整个实验运行两次（R1 和 R2）。不幸的是，第 1 轮和第 2 轮每组内的测试顺序不同，因此每组中的动物按以下顺序进行测试：

运行 1，第 1 组：条件 A，然后是 B，然后是 C，
运行 1，第 2 组：条件 D、E、F，
运行 2，第 1 组：条件 F、B、A，
运行 2，第 2 组：条件 C、E、D。

每次运行和分组组合都使用不同的 10 只动物，每只动物都有一个唯一的 ID（四组中的 ID 为 1-40）。
我在 R 中使用此结构制作了一个示例数据集，这可能会有所帮助：
set.seed(1)

df &lt;- data.frame(Run = rep(c(“R1”, “R2”),each = 60),
                 组＝rep(c(“G1”，“G2”)，每个＝30，次数＝2)，
                  条件=rep(c(rep(c(“A”、“B”、“C”)，每个= 10)，
                                  代表（c（“D”，“E”，“F”），每个= 10），
                                  代表（c（“F”，“B”，“A”），每个= 10），
                                  代表（c（“C”，“E”，“D”），每个= 10））），
                 ID = c(代表(1:10, 3), 代表(11:20, 3),
                        代表(21:30, 3), 代表(31:40, 3)),
                 MR = rnorm(120, 1, 0.1))


在描述数据结构时，下列正确的是：
动物 ID 嵌套在组内？
组是否嵌套在运行中（因为两个运行之间的组 1 和组 2 不同）？
另外，Condition 是否与 Run 完全交叉，但在 Group 内部分交叉？
我主要感兴趣的是运行 1 和运行 2 之间不同条件下的代谢率是否不同，即显着的运行 * 条件交互作用或运行的主效应。如果可能的话，我希望在 R 中使用 nlme 来指定模型。
这是我迄今为止一直在努力的思考过程：
我对数据建模的第一次尝试是：
库(nlme)

m1 &lt;- lme(MR ~ 条件 * 运行，随机 = ~1|ID，数据 = df)
摘要(m1)
方差分析(m1)

但是，我认为这并不能说明 MR 也可能取决于动物测试的顺序（即分组）这一事实。这是真的吗？
由于运行 1 中的组 1 与运行 2 中的组 1 具有不同的条件序列（组 2 也是如此），我指定了一个新的 df 列，为每个组提供了唯一的标识符。
df$GroupRun &lt;- 交互(df$Run, df$Group)

因为我认为 ID 嵌套在 GroupRun 中，所以我尝试了以下模型：
m2 &lt;- lme(MR ~ 条件 * 运行，随机 = ~1|GroupRun/ID，数据 = df)
概要(m2)
方差分析(m2)


这是一个正确的模型规范吗？它是否体现了 Group 的效果？
我担心的两个问题是：

每个组内测试的条件不同是否有问题？
GroupRun 只有四个级别 - 这是随机效应的问题吗？

给定的 ID 也嵌套在 Run 中，为什么不需要指定它（或者这是从 Run 作为主要效果包含在内的事实中隐含的？）。
最初的计划是在两次运行中收集所有数据，每只动物在所有六种条件下进行测试，只是在运行之间采用不同的处理顺序（条件顺序）。每次运行只有一组 20 只动物。在这种情况下，虽然我认为 Animal 仍然嵌套在 run 中，但模型 m1（上面）是否合适？
我认为我不确定如何进行的总结可能是，尽管混合了效果的交叉和嵌套（随机/固定），但仅当涉及随机效果时才需要为随机效果指定嵌套。第二个随机效应 - 这是真的吗？情况总是如此？]]></description>
      <guid>https://stats.stackexchange.com/questions/647268/describing-data-structure-and-specifying-a-linear-mixed-model-in-nlme-with-neste</guid>
      <pubDate>Wed, 15 May 2024 09:03:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么机器学习模型要学习概率分布以及为什么它很重要？</title>
      <link>https://stats.stackexchange.com/questions/647266/why-do-ml-models-learn-probability-distributions-and-why-does-it-matter</link>
      <description><![CDATA[我知道这个问题很愚蠢，但我已经阅读和编写神经网络有一段时间了，研究了反向传播等。
但是，我认为我从未理解过神经网络建模的概率分布是什么？
我确实知道它们是频率与特征图，但我为什么了解数据集中 L 形边界的数量会有帮助呢？
当然，我也没有看到线性回归学习任何这些（我寻找一个非常简单的案例来分析。）
如果可能的话，您的概念解释是什么？您能给我推荐一些针对这方面的初学者的文章吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647266/why-do-ml-models-learn-probability-distributions-and-why-does-it-matter</guid>
      <pubDate>Wed, 15 May 2024 08:46:40 GMT</pubDate>
    </item>
    <item>
      <title>使用哪些统计数据来比较许多（相关）比率</title>
      <link>https://stats.stackexchange.com/questions/647264/what-statistics-to-use-compare-many-dependent-ratios</link>
      <description><![CDATA[我正在尝试比较转基因小鼠胸腺的细胞亚群。我用流式细胞术识别细胞，得到与此类似的结果：

&lt;标题&gt;

细胞类型
小鼠品系 1
小鼠品系2


&lt;正文&gt;

一个
10000； 9000； ...
25000;45000;...


B
200;150;...
800;1200;...


C
50;20;...
400;600;...


D
100;50;...
600;800;...



（每组大约有五个重复）
由于“Mouse 2”中的总体细胞计数较高，我还想看看总体组成是否有变化，因此我通过将每个值除以总细胞计数来计算百分比。
我的主要目标是确定“小鼠品系 1”和“小鼠品系 2”的任何亚群（A、B、C 或 D）之间是否存在显着差异
但是，这会在 A-B-C-D 组之间产生强烈的依赖性​​，因为它们的总和总是为 1，因此我认为使用双向方差分析或多重 T 检验是不够的。
您能为这种情况建议不同的方法或统计测试吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647264/what-statistics-to-use-compare-many-dependent-ratios</guid>
      <pubDate>Wed, 15 May 2024 08:44:11 GMT</pubDate>
    </item>
    <item>
      <title>监测随时间分布的不平等演变</title>
      <link>https://stats.stackexchange.com/questions/647263/monitoring-the-evolution-of-inequality-in-time-dependent-distributions</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647263/monitoring-the-evolution-of-inequality-in-time-dependent-distributions</guid>
      <pubDate>Wed, 15 May 2024 08:17:21 GMT</pubDate>
    </item>
    <item>
      <title>抽样调查中使用权重</title>
      <link>https://stats.stackexchange.com/questions/647261/using-weights-in-sample-survey</link>
      <description><![CDATA[我对样本称重技术相当陌生，目前正在研究一个数据集，我需要计算权重，以便样本更好地代表总体。
我的数据如下所示，样本是使用某种调查设计从人群中提取的 -


据我所知，该数据的设计权重是
每个行项目的选择概率的倒数（即
1/(样本数/总体数))。在这种情况下，设计权重是否足够，还是我们也应该转向分层后权重？

我想了解是否应该应用分层后权重
该数据 - 如果后分层权重是另一个单独的
技术本身，如果是这样，我们什么时候应该特别应用它们
关于我的数据。

我还想知道分层后的权重是否应该是
在这种情况下乘以设计重量？我尝试这样做
但得到了非常奇怪的结果

我们什么时候尝试将 raking 作为一种方法，我们也应该在这里尝试吗？

假设我们有另一列称为响应率，它为我们提供每行的响应百分比（例如 - 第一行的 505 响应率意味着 10 人响应），那么我们如何应用这些方法？


由于这是一个非常简单的数据集，因此如果能够分享最终结果集，我们将不胜感激。我知道不同的技术，但很难理解何时使用什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/647261/using-weights-in-sample-survey</guid>
      <pubDate>Wed, 15 May 2024 07:51:45 GMT</pubDate>
    </item>
    </channel>
</rss>