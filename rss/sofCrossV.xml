<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 13 Sep 2024 09:17:19 GMT</lastBuildDate>
    <item>
      <title>Keras 中的简单梯度下降</title>
      <link>https://stats.stackexchange.com/questions/654312/simple-gradient-descent-in-keras</link>
      <description><![CDATA[我正在通过在笔记本中构建自己的神经网络来练习神经网络。我正尝试将我的模型与 Keras 中的等效模型进行对比。我的模型似乎与其他简单的编码神经网络框架一样工作，例如：https://towardsdatascience.com/coding-neural-network-forward-propagation-and-backpropagtion-ccf8cf369f76
但是，随着我增加 epoch 的数量，Keras 模型的权重逐渐与我自己的权重不同。我正尝试使用简单的梯度下降来训练网络，批量大小等于整个训练集，将初始化权重设置为与我的模型中的初始化权重相同。 （我目前一直在 Iris 数据集上执行此操作，因此批处理大小 = 150。）
我感兴趣的是，这里 keras 中是否存在默认情况，这意味着我下面描述的模型与我的模型（或文章中描述的模型）的功能略有不同？比如批量标准化之类的？
从 tensorflow 导入 keras
从 tensorflow.keras.models 导入 Sequential
从 tensorflow.keras.layers 导入 Dense、Activation、Input

network_shape = np.array([4,20,10,1])
activations=[&quot;relu&quot;,&quot;relu&quot;,&quot;sigmoid&quot;]
model = Sequential()
model.add(Input(shape=(network_shape[0],)))
for i in range(len(activations)):
model.add(Dense(units=network_shape[i+1],activation=activations[i]))

model.set_weights(set_weights)

sgd = keras.optimizers.SGD(learning_rate=alpha,动量=0.0)
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=sgd)

model.fit(X.T, y.T, batch_size=150, epochs=n_iter, verbose=0, shuffle=False)

提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/654312/simple-gradient-descent-in-keras</guid>
      <pubDate>Fri, 13 Sep 2024 08:32:10 GMT</pubDate>
    </item>
    <item>
      <title>逆回归的无偏估计量</title>
      <link>https://stats.stackexchange.com/questions/654311/unbiased-estimator-of-the-reversed-regression</link>
      <description><![CDATA[假设我有随机变量 $X$ 和 $Y$。我对 $\mathbb{E}[Y | X]$ 的无偏估计量感兴趣，但我以另一种方式执行了回归，并得到 $\mathbb{E}[X |Y]$。在什么数据生成分布和进一步假设下，是否知道我可以构建一个无偏估计量 $\mathbb{E}[Y | X] = \beta \mathbb{E}[X |Y]$？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654311/unbiased-estimator-of-the-reversed-regression</guid>
      <pubDate>Fri, 13 Sep 2024 08:29:49 GMT</pubDate>
    </item>
    <item>
      <title>mmrm R 包：没有优化器导致模型拟合成功</title>
      <link>https://stats.stackexchange.com/questions/654310/mmrm-r-package-no-optimizer-led-to-a-successful-model-fit</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654310/mmrm-r-package-no-optimizer-led-to-a-successful-model-fit</guid>
      <pubDate>Fri, 13 Sep 2024 07:52:54 GMT</pubDate>
    </item>
    <item>
      <title>量化对异常值敏感的两个分布之间的差异</title>
      <link>https://stats.stackexchange.com/questions/654309/quantifying-the-discrepancy-between-two-distributions-with-sensitivity-to-outlie</link>
      <description><![CDATA[我在样本空间 $x \in \Omega$ 上有两个概率分布，分别表示为 $P:\Omega \mapsto \mathbb{R}$ 和 $Q:\Omega \mapsto \mathbb{R}$。这些分布出现在构建纠错码解码器的背景下。假设 $\Omega$ 表示所有可能错误的空间，而 $P(\cdot)$ 是一个错误模型，它为 $\Omega$ 中的每个错误事件分配一个概率。本质上，$P(\cdot)$ 捕获了所有不想要的效果。如果解码策略完全了解 $P(\cdot)$，则它可以发挥最佳性能。然而，$P(\cdot)$ 在实践中通常是未知的。相反，我们经常进行校准实验来推断一个模型 $Q(\cdot)$，该模型合理地近似底层噪声过程 $P(\cdot)$。因此，了解$P(\cdot)$和$Q(\cdot)$之间的差异至关重要，尤其是在解码器的性能方面。
在错误校正中，众所周知，位于$P(\cdot)$尾部的$x \in \Omega$错误，即异常值，对解码器的性能有重大影响。例如，如果 $\Omega$ 表示独立的位翻转错误，其中每个位翻转发生的概率为 $p$，则关键异常值是具有较大汉明权重的错误（刚好超过代码距离的一半 $d$），概率约为 $p^{d/2}$。因此，$P(\cdot)$ 和 $Q(\cdot)$ 在异常值上紧密匹配至关重要，而对于非异常值错误，较大的差异更容易被接受。
在这种情况下，什么是合适的可区分性指标来量化 $P(\cdot)$ 和 $Q(\cdot)$ 之间的相关差异？以下常用指标似乎不适合这种特殊情况：

总变异距离 (TVD)：$\sup_{x \in \Omega} |P(x) - Q(x)|$。该指标主要由更可能发生事件的概率差异决定。例如，如果我们有两个误差$x_1, x_2 \in \Omega$，其中$P(x_1) = 0.9$、$Q(x_1) = 0.8$，以及$P(x_2) = 10^{-5}$、$Q(x_2) = 10^{-7}$，则 TVD 对估计$x_2$概率的显著误差不敏感。
Kullback-Leibler 散度 (KL 散度)： $ D(P || Q) = \sum_{x \in \Omega} P(x) \log \left( \frac{P(x)}{Q(x)} \right) $。与 TVD 一样，对于典型事件，KL 散度对 $P(x)$ 和 $Q(x)$ 的差异更为敏感。因此，它无法充分捕捉异常值的差异。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654309/quantifying-the-discrepancy-between-two-distributions-with-sensitivity-to-outlie</guid>
      <pubDate>Fri, 13 Sep 2024 07:37:11 GMT</pubDate>
    </item>
    <item>
      <title>在优化问题中使用零膨胀负二项回归的估计值</title>
      <link>https://stats.stackexchange.com/questions/654307/use-estimates-from-zero-inflated-negative-binomial-regression-in-optimization-pr</link>
      <description><![CDATA[假设我希望将投资预算优化为两个不同的投资机会。在案例 1 中，我们假设我们拥有每个机会的先前投资和销售数据。我们还假设响应（假设为销售额）在两个投资之间不相关，并且投资不会以任何方式相互作用。可以假设两个投资的响应变量遵循零膨胀负二项分布。我们假设投资 1 的销售额可以根据 $y_{1, t} = e^{b_{1, t}} * x_{1, t}^{exponent_{1, t}}$ 建模，其中 $y_{1, t}$ 是时间步 t 时归因于投资 1 的销售额。投资 2 可以以相同的方式建模。
那么我的问题是，是否只需将 $1 - \psi$ 上的后验与 $e^{b_{1, t}}$ 上的后验相乘，然后将其包装在确定性变量中，以获得适当的系数 $e^{b_{1, t, \text{zero-inflation-scaled}}}$，然后将其输入到我们的优化问题中，我们试图最大化我们的投资销售额：
$\max_{x_c} \sum_{c \in \{1, 2\}} \sum_{\text{posterior_sample}} (1 - \psi_{c, \text{posterior_sample}}) \cdot e^{b_{1, \text{posterior_sample}}} \cdot x_c^{\text{exponent}_{c, \text{posterior_sample}}}$
受一些约束，例如：
$\sum_{c \in \{1, 2\}} x_c \leq B \quad \text{and} \quad x_c \geq 0 \quad \forall c$,
其中 posterior_sample 表示一些采样的后验集。
考虑以下用 pymc 编写的代码片段：
def zero_inflated_negative_binomial_test():
# 生成所需的变量
x_1 = np.random.lognormal(sigma=0.5, size=1000)
response_1 = np.array(
[max(0.0, round(x)) for x in np.exp(2 * x_1 ** 0.5) + np.random.normal(scale=1,
size=1000)])
zeros = np.random.binomial(n=1, p=0.4, size=1000)

# 根据零数组在 response_1 中插入零
response_1[zeros == 0] = 0

import pymc as pm
with pm.Model() as model:
b_1 = pm.HalfNormal(&#39;b_1&#39;, sigma=10)
exponent = pm.Beta(&#39;exponent&#39;, alpha=1, beta=1)

mu = pm.math.exp(b_1) * x_1 ** 指数

alpha = pm.Exponential(&quot;alpha&quot;, 10)
psi = pm.Beta(&quot;psi&quot;, alpha=1, beta=1)

truecoefficient = pm.Deterministic(name=&quot;truecoefficient&quot;, var=(1 - psi) * pm.math.exp(b_1))

_ = pm.ZeroInflatedNegativeBinomial(
name=&quot;outcome&quot;,
psi=psi,
mu=mu,
alpha=alpha,
observer=response_1
)

import pymc.sampling_jax as jax
trace = jax.sample_blackjax_nuts(1000,
tune=1000,
target_accept=0.97,
cores=2,
random_seed=0,
idata_kwargs={&quot;log_likelihood&quot;: True},
return_inferencedata=True)

var_names = [&quot;truecoefficient&quot;, &quot;b_1&quot;, &quot;exponent&quot;, &quot;psi&quot;]
inf = pm.sample_posterior_predictive(trace, var_names=var_names,random_seed=0, extend_inferencedata=True)

print(&quot;_&quot;)

其中 truecoefficient 表示零膨胀缩放的 $e^{b_{1, t}}$，其估计值将在优化中替换 $(1 - \psi)e^{b_1}$问题。
类似地，考虑诸如$y_t = 截距 + b_{1, t} * x_{1, t} + b_{2, t} * x_{2, t}$之类的模型，我们能否简单地将右侧后验和未来投资建议与 psi 相乘并将其输入到优化问题中？点预测显然不准确，因为我们不考虑似然函数并且不对输出进行离散化，但这样做难道不应该足以获得某种平均预测吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654307/use-estimates-from-zero-inflated-negative-binomial-regression-in-optimization-pr</guid>
      <pubDate>Fri, 13 Sep 2024 06:46:06 GMT</pubDate>
    </item>
    <item>
      <title>如何根据原始数据框的重复下采样来报告回归模型？</title>
      <link>https://stats.stackexchange.com/questions/654301/how-to-report-on-regression-models-from-repeated-downsamples-of-an-original-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654301/how-to-report-on-regression-models-from-repeated-downsamples-of-an-original-data</guid>
      <pubDate>Thu, 12 Sep 2024 23:50:58 GMT</pubDate>
    </item>
    <item>
      <title>生存模型中的时间间隔</title>
      <link>https://stats.stackexchange.com/questions/654297/time-interval-in-a-survival-model</link>
      <description><![CDATA[要使用 Cox 回归，我们可以使用 R 中的以下函数作为示例。

coxph(Surv(time, status) ~ sex, data = lung)

如果我们有一个时间依赖性协变量，我们需要以一种称为计数过程格式的格式设置一个特殊的数据集。
假设我们有以下数据。
T1 和 delta1 是时间和事件指标变量。
TA 和 deltaA 是继发性疾病的时间和事件指标。

## my_id T1 delta1 TA deltaA
## 1 1 2081 0 67 1
## 2 2 1602 0 1602 0
## 3 3 1496 0 1496 0
## 4 4 1462 0 70 1
## 5 5 1433 0 1433 0

我们需要将数据结构更改为以下格式，以便在 Cox 回归中包含时间相关的协变量。
## my_id T1 delta1 tstart tstop death agvhd
## 1 1 2081 0 0 67 0 0
## 2 1 2081 0 67 2081 0 1
## 3 2 1602 0 0 1602 0 0
## 4 3 1496 0 0 1496 0 0
## 5 4 1462 0 0 70 0 0
## 6 4 1462 0 70 1462 0 1
## 7 5 1433 0 0 1433 0 0

coxph(
Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, 
data = td_dat
) %&gt;% 
tbl_regression(exp = TRUE)

*我的问题是：为什么我们需要定义间隔（添加 tstart）来应用 Cox 回归？为什么不能仅通过包含 tstop 来运行 Surv 函数（如以下函数）？既然我们知道事件发生的确切时间（tstop），那么 tstart 在计算中的作用是什么？
 coxph(Surv(time=tstop, event = death) ~ agvhd, data = .) 
]]></description>
      <guid>https://stats.stackexchange.com/questions/654297/time-interval-in-a-survival-model</guid>
      <pubDate>Thu, 12 Sep 2024 22:20:58 GMT</pubDate>
    </item>
    <item>
      <title>仅具有一个连续预测变量和一个小样本量的二元逻辑回归：我是否过于复杂化了？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654296/binary-logistic-regression-with-only-one-continious-predictor-and-a-small-sample</link>
      <description><![CDATA[我有一个包含 10 个数据点的拟合二元模型。单个连续变量位于 [2.4, 4.4] 区间，有一个二元输出变量 Y。Y 包含 4 个 Y=1 的事件和 6 个 Y=0 的事件。在避免完全分离的情况下，建模效果很好。我使用了 Python。
我读过许多论文，其中指出需要检查逻辑回归的假设（(1)线性：线性预测器是否正确？(2) Logit 变换是将协变量与条件均值联系起来的正确函数，以及 (3) 方差是伯努利）。
我的问题如下：

只有一个预测器，我需要检查线性吗？或者就此而言：任何假设？仅供参考：我无法添加第二个协变量。

如果我只有一个变量，我需要测试变量的显著性吗？这意味着我要用零模型来测试我的模型。这个测试基本上是似然比测试，它总是会告诉我我的协变量是显著的，对吧？所以这个测试不会给我任何信息？


关于评估模型：有预测能力的测量（McFadden 伪 R^2、Brier 分数）和拟合优度测试，它们只是测试是否存在我遗漏的非线性或相互作用。
由此产生了两个问题：

GOF 测试：关于第一个问题：当我假设我的假设得到满足时，我是否还需要执行经典的 GOF 测试，如 Hosmer-Lemeshow 测试？当 HL 测试基本上只是测试是否存在我遗漏的非线性或相互作用，并且我得出结论它们不存在时，我可以不执行测试吗？根据这种推理，这有效吗？当它无效时：对于 10 个样本，哪一个是可接受的/最好的？
关于预测能力测试：对于 10 个样本，哪一个是可接受的/最好的？不幸的是，我没有办法获得更多样本。我喜欢 McFadden Pseudo R^2，它给我的值为 0.41。我可以在这么小的样本量下使用它吗？

如果您需要有关我的模型的更多信息，请告诉我！]]></description>
      <guid>https://stats.stackexchange.com/questions/654296/binary-logistic-regression-with-only-one-continious-predictor-and-a-small-sample</guid>
      <pubDate>Thu, 12 Sep 2024 22:12:20 GMT</pubDate>
    </item>
    <item>
      <title>经常引用的根据增益分数计算 Cohen's d 的公式正确吗？</title>
      <link>https://stats.stackexchange.com/questions/654295/is-the-oft-quoted-formula-for-computing-cohens-d-from-gain-scores-correct</link>
      <description><![CDATA[此引文末尾的公式在多处出现，但均未注明出处或推导。

我看不出这个公式怎么会正确，因为它在维度上不一致。两个标准差 $s$ 和 $s_{gain}$ 应该具有相同的单位。
有人知道这个公式从何而来吗？它似乎被用在很多荟萃分析软件中，所以这具有实际意义……]]></description>
      <guid>https://stats.stackexchange.com/questions/654295/is-the-oft-quoted-formula-for-computing-cohens-d-from-gain-scores-correct</guid>
      <pubDate>Thu, 12 Sep 2024 22:12:13 GMT</pubDate>
    </item>
    <item>
      <title>如何从单个横断面样本中估计检测出疾病的概率/变异流行率估计的置信度？</title>
      <link>https://stats.stackexchange.com/questions/654253/how-to-estimate-probability-of-detecting-a-disease-confidence-in-a-variant-preva</link>
      <description><![CDATA[如何计算从一定数量的个体（例如 300 人）的样本中检测到在给定背景患病率（例如 5%）下在人群中传播的疾病的可能性？
此外，如何计算通过测试样本得出患病率估计值的置信区间？例如，如果从 300 个样本中抽取了 20 个样本，结果呈阳性。]]></description>
      <guid>https://stats.stackexchange.com/questions/654253/how-to-estimate-probability-of-detecting-a-disease-confidence-in-a-variant-preva</guid>
      <pubDate>Thu, 12 Sep 2024 08:52:38 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中进行数据拟合时，如何处理区间数据（具有无限上限）？</title>
      <link>https://stats.stackexchange.com/questions/654300/how-do-i-deal-with-interval-data-having-infinite-upper-limit-when-doing-data-f</link>
      <description><![CDATA[我从一份政府报告中提取了住房建筑面积（​​以平方米 (sqm.) 为单位）的数据。第一类指建筑面积低于 5 平方米，最后一类指建筑面积为 200 平方米或以上。鉴于下限和上限有点模糊，我怀疑在进行数据拟合时这些因素会产生重大影响。实际上，没有零平方米甚至 1 平方米的房屋；此外，人们可以拥有非常宽敞的地板面积，但在给定的数据中，超过 200 平方米的面积限制并没有得到很好的确定。
category &lt;- c(&quot;&lt; 5&quot;, &quot;5 - 9&quot;, &quot;10 - 19&quot;, &quot;20 - 29&quot;, &quot;30 - 49&quot;, &quot;50 - 69&quot;, &quot;70 - 89&quot;, &quot;90 - 119&quot;, &quot;120 - 149&quot;, &quot;150 - 199&quot;, &quot;&gt; 200&quot;)
count &lt;- c(13676, 48589, 111144, 174631, 203851, 124424, 82277, 54410, 31702, 16239, 14516)

为了进行数据拟合，我尝试生成 Cullen 和 Frey 图。我假设我无法处理区间数据，因此我将区间转换为中点。请注意，对于下限和上限，我只是假设它们是 5 平方米。和 200 平方米，尽管我不确定这是否是一个合理的假设，因为概率分布在稍后模拟时会产生误导，即会产生零或接近零的值或远远超过 200 的值。
# 步骤 1：安装必要的软件包
install.packages(&quot;fitdistrplus&quot;)
install.packages(&quot;moments&quot;)

# 步骤 2：加载软件包
library(fitdistrplus)
library(moments)

# 步骤 3：准备数据
类别 &lt;- c(&quot;&lt; 5&quot;, &quot;5 - 9&quot;, &quot;10 - 19&quot;, &quot;20 - 29&quot;, &quot;30 - 49&quot;, &quot;50 - 69&quot;, &quot;70 - 89&quot;, &lt;90 - 119&quot;, &lt;120 - 149&quot;, &lt;150 - 199&quot;, &gt; 200&quot;)
count &lt;- c(13676, 48589, 111144, 174631, 203851, 124424, 82277, 54410, 31702, 16239, 14516)

# 使用中点近似
中点 &lt;- c(5, (5+9)/2, (10+19)/2, (20+29)/2, (30+49)/2, (50+69)/2, 
(70+89)/2, (90+119)/2, (120+149)/2, (150+199)/2, 200)

# 根据计数值重复中点
data &lt;- rep(midpoints, count)

# 步骤 4：Cullen 和 Frey 图测试
descdist(data, discrete = FALSE, boot = 1000)

Cullen 和 Frey 图测试表明分布为 Beta。本能地，我认为楼面面积的概率分布最有可能是对数正态的。不确定的上限和下限是否可能影响 Cullen 和 Frey 图的结果？
总结：
当我有区间数据并且想要找到给定数据集的最佳拟合概率分布时，如何处理不确定的上限和下限？]]></description>
      <guid>https://stats.stackexchange.com/questions/654300/how-do-i-deal-with-interval-data-having-infinite-upper-limit-when-doing-data-f</guid>
      <pubDate>Thu, 12 Sep 2024 00:26:16 GMT</pubDate>
    </item>
    <item>
      <title>我如何确定我的生态 GLMM 是否构建准确？</title>
      <link>https://stats.stackexchange.com/questions/654219/how-do-i-determine-if-my-ecological-glmm-is-accurately-constructed</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654219/how-do-i-determine-if-my-ecological-glmm-is-accurately-constructed</guid>
      <pubDate>Wed, 11 Sep 2024 16:42:13 GMT</pubDate>
    </item>
    <item>
      <title>OLS 回归变换，其中独立变量的总和是因变量的一部分</title>
      <link>https://stats.stackexchange.com/questions/654130/ols-regression-transformation-where-the-sum-of-the-independent-variables-is-part</link>
      <description><![CDATA[我最近看到了以下形式的回归（不是在书中，而是在业余环境中），其 ID 为 $i$，区域为 $j$：
$$\ln\left(\dfrac{1+y_i}{1+\sum_{j\in\{1,2,3\}}x_{ij}}\right) = \ln(1+x_{i1})\beta_1+\ln(1+x_{i2})\beta_2+\ln(1+x_{i3})\beta_3+\epsilon_i\\
=\boldsymbol{X}_i\boldsymbol \beta+\epsilon_i$$
现在，比率 $y_i/\sum_{j\in\{1,2,3\}} x_{ij}$ 具有一定的解释，我们称之为 $\textit{multiplier}$。
我们想要预测给定 $x_1,x_2,x_3$ 的 $\textit{multiplier}$、$\widehat{\textit{multiplier}}$。其实现方式如下：
$$\widehat{\textit{multiplier}}_i=\exp\left(\boldsymbol{X}_i\hat{\boldsymbol \beta}\right)\times\dfrac{ \left(1+\sum_{j\in\{1,2,3\}}x_{ij}\right)}{\sum_{j\in\{1,2,3\}}x_{ij}}-1.$$
我大概明白这种回归的原理。但是，我有以下几点批评意见：

我们已经知道 $x_{ij}$，因此我认为将 $x_{ij}$ 作为因变量是没有意义的。有人能证实这没有意义吗？
$\textbf{Edit}$：在我看来，我们引入了一个额外的变异源。我们不能只重写方程式，将所有 $x$ 都放在右边吗？


在预测中，上述回归的左侧预测如下：$$\hat{Y}_i=\ln\left(\dfrac{1+\hat{y}_i}{1+\sum_{j\in\{1,2,3\}}\hat{x}_{ij}}\right),$$当然，我们不会预测单个 $\hat{y}_i$ 和 $\sum_{j\in\{1,2,3\}} \hat{x}_{ij}$，我们预测这些的比率作为变换。将预测的 $\exp\left(\boldsymbol{X}_i\hat{\boldsymbol \beta}\right)=\dfrac{1+\hat{y}_i}{1+\sum_{j\in\{1,2,3\}}\hat{x}_{ij}}$ 的分母与观察到的 $\left(1+\sum_{j\in\{1,2,3\}}x_{ij}\right)$ 相消是否有意义？

有人能帮我吗？
$\textbf{编辑 2:}$
我认为，当您运行以下形式的回归时，问题似乎相当类似：
$$\dfrac{y_i}{x_i} = x_i\beta+\epsilon_i$$除以 $i$。
我认为，这样做
$x_i\hat{\beta}\times x_i=\hat{y}_i$是不对的。
此外，您始终可以将上述回归重写为 $y_i=x_i^2
\beta+\epsilon_i^*$，对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654130/ols-regression-transformation-where-the-sum-of-the-independent-variables-is-part</guid>
      <pubDate>Mon, 09 Sep 2024 21:30:38 GMT</pubDate>
    </item>
    <item>
      <title>非中心卡方分布的下尾界</title>
      <link>https://stats.stackexchange.com/questions/653811/lower-tail-bound-for-noncentral-chi-squared-distribution</link>
      <description><![CDATA[非中心卡方随机变量 $Z$ 的形式为
$$
Z = \sum_{i=1}^k X_i^2
$$
其中 $(X_1, X_2, \ldots, X_i, \ldots, X_k)$ 是 $k$ 独立的，正态分布，均值为 $\mu_i$，方差为 1。
我正在寻找 $Z$ 的下尾界，也就是说，我想证明
$$
P(|Z - \mathbb{E}[Z]| &gt; t|) \geq ce^{-c&#39; t^2}
$$
其中 $c, c&#39;&gt;0$ 是依赖于 $k$ 和 $\mu_i$ 的常数。]]></description>
      <guid>https://stats.stackexchange.com/questions/653811/lower-tail-bound-for-noncentral-chi-squared-distribution</guid>
      <pubDate>Tue, 03 Sep 2024 21:32:16 GMT</pubDate>
    </item>
    <item>
      <title>多级回归，模型规范</title>
      <link>https://stats.stackexchange.com/questions/653787/multilevel-regression-model-specification</link>
      <description><![CDATA[我们非常感谢您就分析我们的研究设计的最佳方式提出建议：
我们研究了教育内容的传递媒体（即增强现实与视频）对记忆（“binary_memory_score”）随时间（“时间”）的影响。我们有 20 次增强现实体验，每次体验都有三个记忆问题（每个多项选择题有四个选项）。视频是增强现实体验的屏幕录制。
我们有两种条件（增强现实与视频），我们分别随机招募（在受试者之间）。参与者被要求参与教育内容并回答记忆问题。对于这两个组，参与者被招募到五个“群组”，代表不同的教育主题（例如群组 1 = 艺术，群组 2 = 科学），这意味着群组也是一个受试者间变量。在每个队列中，所有队列参与者都经历了五种关于该队列主题的特定体验（在队列 1 中，我们有体验 1、体验 2、体验 3、体验 4、体验 5；在队列 2 中，我们有体验 6、体验 7 等）。
在完成每项体验后的初始记忆测试（time_0）之后，一些参与者在 1 个月后（gap1）或 6 个月后（gap6）再次被问到问题（time_later）。因此，我们有一个受试者内时间因素（time_0 vs time_later）和一个受试者间差距因素（gap1 vs gap6）。我们目前将记忆作为二元变量（正确答案 vs 错误答案）作为单个记忆问题（“exp_title_question”）的“分数”。以下是我们提出的使用 glmer 的分析：
binary_memory_score ~ 1 + media*time*gap + (1 | experience / experience_question) + (1 + time | id) + (1 | cohort / id), family = binomial(&quot;logit&quot;), nAGQ=0, control=glmerControl(optimizer = &quot;nloptwrap&quot;), data=combined_data_cor_screened,contrasts = list(media = contr.sum, time=contr.sum, gap=contr.sum))

我们假设，与体验增强现实的人相比，观看视频（媒体）的人在记忆任务（binary_memory_score）中的表现会更差。
我们还假设，与体验增强现实的人相比，观看视频的人的记忆分数会随着时间的推移而更快地延迟经验。
我们计划通过 emmeans 包探索媒体 * 时间 * 间隙相互作用来测试这些假设。
非常感谢您的想法或建议。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653787/multilevel-regression-model-specification</guid>
      <pubDate>Tue, 03 Sep 2024 08:23:00 GMT</pubDate>
    </item>
    </channel>
</rss>