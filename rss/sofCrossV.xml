<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Mon, 07 Apr 2025 09:21:36 GMT</lastBuildDate>
    <item>
      <title>最大相关性和最小相关性</title>
      <link>https://stats.stackexchange.com/questions/663628/maximum-correlation-and-minimum-correlation</link>
      <description><![CDATA[相关性肯定低于1或1，如果同时增加的量增加，并且在均匀减少期间所需的量高于-1或-1。 Velsius和Wahrenheit之间的相关性是1。千克和吨之间的相关性是1。相关性1的示例是什么？
如果x为34，则y为67。
如果x为67，则y为29。
如果x为25，则y为g。
证明使用desmos的图片有限制。]]></description>
      <guid>https://stats.stackexchange.com/questions/663628/maximum-correlation-and-minimum-correlation</guid>
      <pubDate>Mon, 07 Apr 2025 09:11:23 GMT</pubDate>
    </item>
    <item>
      <title>相关方差协方差</title>
      <link>https://stats.stackexchange.com/questions/663627/correlation-variance-covariance</link>
      <description><![CDATA[
W t
27 54
39 41
67 13
27 38


 w是统治者的质量。
 t是钱包的质量。
 4个统治者的质量总计160。
统治者的平均质量为40。
标尺的质量的差异为（13^2+1^2+27^2+13^2）/4 
科学家会发现下一步为（169+1+729+169）/4 
我们将下一部分评估为1068/4 
差异的最后一个是267。
方差或偏差的根部为16.3。
如果艺术家可以添加所有钱包，他将将总质量计算为146。
每个钱包的平均大小由陪审团计算为36.5。
（17.5^2+4.5^2+23.5^2+1.5^2）/4＆gt;＃钱包重量的差异。
（305+20.2+552+2.25）/4是其方差
 880.375/4是差异。
我们将这一方差得出为220。
我们发现偏差为14.8。
（-13×17.5-1×4.5+27×-23.5-13×1.5）/4是评估的协方差
（-227-4.5+635-19.5）/4是协方差。
 383/4是协方差
 95.8是协方差。
母亲将计算相关性为95.8/14.8/16.3。
 6.47/16.3是相关性
相关性为0.4。
我已经使用相关（x，y）=协方差（x，y）= deviaiton（x）/偏差（y）来计算相关性

那么，您能给我自己的相关性问题，并将其从第一个偏离的偏差和第二个像我这样的第二个偏差的偏差来计算。]]></description>
      <guid>https://stats.stackexchange.com/questions/663627/correlation-variance-covariance</guid>
      <pubDate>Mon, 07 Apr 2025 09:07:14 GMT</pubDate>
    </item>
    <item>
      <title>显着相互作用后，简单的效果分析是否需要进行多重比较校正？</title>
      <link>https://stats.stackexchange.com/questions/663626/do-simple-effects-analyses-after-a-significant-interaction-require-multiple-comp</link>
      <description><![CDATA[我有一个基本但重要的问题，我没有发现太多讨论。
当模型中的相互作用项很重要（例如，分类变量与连续变量之间的相互作用）在进行简单效应分析时需要应用多重比较校正（例如，检查分类变量的每个级别的连续变量的效果）吗？）？）
预先感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/663626/do-simple-effects-analyses-after-a-significant-interaction-require-multiple-comp</guid>
      <pubDate>Mon, 07 Apr 2025 09:05:11 GMT</pubDate>
    </item>
    <item>
      <title>我的ADF和KPSS测试暗示了平稳性，但驻地表现出异质性。如何解释？</title>
      <link>https://stats.stackexchange.com/questions/663625/my-adf-and-kpss-tests-suggests-stationarity-but-the-residauls-exhibit-heterosce</link>
      <description><![CDATA[ 给出概述：我目前正在对每日社交媒体数据进行中断的时间序列分析，重点是发布频率。
最初，我试图实施一个分段的回归模型，但努力考虑自相关。因此，我选择使用预测:: auto.arima使用Arima（1,0,1）模型。
但是，我仍然不确定我的数据是否真正表现出平稳性，这是Arima建模的必要条件。 ADF测试（P值= 0.041）和KPSS测试（P值= 0.075）最初都表明该系列是静止的。但是，在拟合模型之后，我根据Breusch-Pagan检验观察到残差的异质性（P值= 0.016）。这提出了一些问题：
  Q1：异质性的存在是否意味着该模型是非平稳的，即使ADF和KPSS测试都表明了其他方式？
  Q2：我发现在中断的时间序列分析中应用ARIMA模型的文献很难解释。诊断是否仅在事件前或模型拟合后的整个系列中进行？目前，我在拟合模型之前运行ADF和KPSS测试，在模型估计后，对残差的Breusch-Pagan和Box-ljung测试。这是适当的过程吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663625/my-adf-and-kpss-tests-suggests-stationarity-but-the-residauls-exhibit-heterosce</guid>
      <pubDate>Mon, 07 Apr 2025 08:26:34 GMT</pubDate>
    </item>
    <item>
      <title>随着时间的推移计算累积结果</title>
      <link>https://stats.stackexchange.com/questions/663622/calculating-a-cumulative-result-across-a-ratio-over-time</link>
      <description><![CDATA[对于工作，我们有一个主要的指标，这是一个风险调整后的比例 - 计算为
在
在这种情况下，较低的结果比更高的结果好。
对于一个特定的项目，我希望探索更改对特定子组的影响，因此我跑了根据系统创建的“原始”图表来判断，结果明显改善。  但是，我们希望随着时间的推移也能取得某种累积结果。 ＆quot x％降低时间！＆quot;或“ y 观察到在干预后保存！”  该软件包会自动产生类似的东西；但是它假设它收到的数字是计数，因此结果对于此特定情况没有意义。
我研究了的几何和谐波平均值[预测结果]  -  [实际结果] 系列，但是由于该值并不总是大于零，因此似乎不合适，除非我误解了这些计算如何工作。 
到目前为止，我最小的选项是将预期值乘以预测结果产生的因果影响，然后从此减去观察到的值：
在
因此，如果观察到的值在整个干预期间为21，则在整个干预期间预期值为20，而因果影响报告其预测费率为1.17：
  $ saved =（20 * 1.17） -  21 = 23.4-21 = 2.4 $   
 SO 2.4 观察到保存的情况。
但我不确定这是“有意义的”，而且绝对不像“最佳”解决方案。
计算类似内容的正确方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/663622/calculating-a-cumulative-result-across-a-ratio-over-time</guid>
      <pubDate>Mon, 07 Apr 2025 06:57:17 GMT</pubDate>
    </item>
    <item>
      <title>Arima.Sim（1,1,0）公式，它如何成为非平稳的？</title>
      <link>https://stats.stackexchange.com/questions/663619/arima-sim-1-1-0-formula-how-can-it-become-non-stationary</link>
      <description><![CDATA[我的背景：我主要是Python程序员，并且在数学/统计数据方面没有很强的知识，但是我喜欢学习某些常见的ML/AI算法的基本原理。我对R的了解不多，但有时我会用它来模仿Python中没有的内容。
最近，我一直在从I tried to emulate an AR model using arima.sim based on some source codes he provided, because I like to make my own notes and examples as process of my study (I want to make a note about unit root).但是，我意识到 arima.sim 无法直接制作非平稳的AR模型：
  set.seed（1）

＃AR1模型，其中phi = 1.3
ar1＆lt;  -  tsibble（idx = seq_len（100），sim = arima.sim（list（ar = 1.3），n = 100），index = idx）

p1＆lt;  -  ar1％＆gt;％autoplot（sim） +实验室（x =; date＆quot&#39;y =; y y y＆quot））
p2＆lt;  -  ar1％＆gt;％acf（sim）％＆gt;％autoplot（） + labs（x =&#39;lag＆quot&#39;y =&#39;y =&#39;&#39;
p3＆lt;  -  ar1％＆gt;％pACF（sim）％＆gt;％autoplot（） +实验室（x =&#39;lag＆quot&#39;y =&#39;y =&#39;&#39;

P1 /（P2 + P3）
 
如果我尝试执行上面的代码，它将无法运行并返回有关非平稳性的错误。但是经过一段时间的实验，事实证明，我实际上可以将其变成这样的东西：
  set.seed（1）

ar1＆lt;  -  tsibble（idx = seq_len（100），sim = arima.sim（list = c（1，1，1，0），ar = c（0.3）），n = 99），index = idx）

p1＆lt;  -  ar1％＆gt;％autoplot（sim） +实验室（x =; date＆quot&#39;y =;
p2＆lt;  -  ar1％＆gt;％acf（sim）％＆gt;％autoplot（） + labs（x =&#39;lag＆quot&#39;y =&#39;y =&#39;&#39;
p3＆lt;  -  ar1％＆gt;％pACF（sim）％＆gt;％autoplot（） +实验室（x =&#39;lag＆quot&#39;y =&#39;y =&#39;&#39;

P1 /（P2 + P3）
 
上面的代码将运行，绘图结果将是非平稳的：
 但是，我无法直接从他的书中找到Arima（1,1,0）的公式，所以我使用 noreflow noreferrer“根据该参考，我认为我的公式将是：
  \ begin {align} \ hat {y}&#39;_ {t}＆amp; = 0.3y&#39;_ _ {t-1} + c \\ hat {y} {y} _ {y} _ {t} _ {t}  -  { c \\\\ hat {y} _ {t}＆amp; = 1.3y_ {t-1} -0.3y_ {t-2} + c \ end {align}
因此，上面的图实际上是一个非平稳的AR2模型，而不是AR1模型（？）。
但是，如果我尝试使用此代码来模仿AR1模型的差异：
  set.seed（1）

＃将Arima订单从110更改为100，但使用“差异”。功能
ar1＆lt;  -  tsibble（idx = seq_len（100），sim =差异（arima.sim（list = c（1，0，0），ar = c（0.3）），n = 100），index = idx）

p1＆lt;  -  ar1％＆gt;％autoplot（sim） +实验室（x =; date＆quot&#39;y =;
p2＆lt;  -  ar1％＆gt;％acf（sim）％＆gt;％autoplot（） + labs（x =&#39;lag＆quot&#39;y =&#39;y =&#39;&#39;
p3＆lt;  -  ar1％＆gt;％pACF（sim）％＆gt;％autoplot（） +实验室（x =&#39;lag＆quot&#39;y =&#39;y =&#39;&#39;

P1 /（P2 + P3）
 
绘图结果是静止的：
  哪种有意义的是有意义的，因为 $ \ hat {y} _ {t} = 0.3y_ {t-1} + c $  c $ 已经开始固定，因此差异可能不会改变任何东西。&gt; 
我的问题是：

这是否意味着先前编写的AR1或AR2公式是错误的？
场景后面实际上发生了什么（如果适用的话）？  $ \ phi_ {1} = 0.3 $ 当我以前的代码证明不是吗？时

我也尝试了差异化AR2模型，结果是固定的，但显然不是AR1模型，而是AR3模型。这使我更加困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/663619/arima-sim-1-1-0-formula-how-can-it-become-non-stationary</guid>
      <pubDate>Mon, 07 Apr 2025 05:49:59 GMT</pubDate>
    </item>
    <item>
      <title>Pettitt测试 - 给出多个更改点？</title>
      <link>https://stats.stackexchange.com/questions/663624/pettitt-test-multiple-changepoints-given</link>
      <description><![CDATA[我正在趋势包中使用Pettitt的测试，并且有几个变量将多年作为更改点。我知道这是一项非参数测试，想知道这是否是由于领带引起的？
 输出：
Pettitt的单个变更点检测测试

数据：流$ 23FWC

u* = 176，p值= 0.004746

替代假设：两面

样本估算：
可能的更改点k        

  14 15（na）17（na）
 
  &lt;img alt =“ Enter image Description在此处”]]></description>
      <guid>https://stats.stackexchange.com/questions/663624/pettitt-test-multiple-changepoints-given</guid>
      <pubDate>Mon, 07 Apr 2025 04:24:16 GMT</pubDate>
    </item>
    <item>
      <title>多元中断时间序列模型</title>
      <link>https://stats.stackexchange.com/questions/663606/multivariate-interrupted-time-series-model</link>
      <description><![CDATA[让我设置场景：
我正在使用每月的遥感数据时间序列来研究多个研究领域的森林收获。在每个研究领域，我设法将收获的像素与不进行收获的像素进行区分。我想看看收获如何影响这两个类别的可分离性。我有两个用于分类性能的指标：首先，我计算了每个块中每个日期收获和未收获像素之间的jeffries-matusita距离。我还完成了逻辑回归，然后计算了每个块中每个日期下ROC下的区域。 

这是我对如何建模的最初想法：
由于收获是一个相对离散的事件（即，在一个图像中不可见，而在下一个图像中是可见的），所以我正在考虑使用一个中断的时间序列框架，这意味着我的因变量是时间，一个分类变量，指示收获的分类变量，以及是否发生了收获的时间，以及AR（1）术语（1）用于自发性误差。由于我有两个因变量，因此使用多元模型似乎很有意义。 The range of my dependent variables is [0,1] for logistic AUC and [0,2] for JM distance, so it seems like I need to use some kind of GLM, possibly beta regression with JM values transformed by dividing by 2. Since I have multiple blocks, this should be a mixed model with block as the grouping variable.
我的问题：

我所描述的建模方法似乎对我要实现的目标有意义吗？我基本上对线性建模或时间序列分析进行了零正规教育，因此我想知道我是否离基地了。  &lt; /li&gt;
我如何解释每个因变量都有不同范围的事实？
我将如何在r中实施？如果您不想编写代码，则包装建议也很有帮助。 
任何建议都将不胜感激。
]]></description>
      <guid>https://stats.stackexchange.com/questions/663606/multivariate-interrupted-time-series-model</guid>
      <pubDate>Mon, 07 Apr 2025 00:22:44 GMT</pubDate>
    </item>
    <item>
      <title>强大的标准错误是否纠正自相关？</title>
      <link>https://stats.stackexchange.com/questions/663603/do-robust-standard-errors-correct-autocorrelation</link>
      <description><![CDATA[我的目标是检查人力资本（HC）是否对外国直接投资（外国直接投资）的吸收能力有影响。我的数据是在1970  -  2020年之间的小组数据，这是在巴西和韩国的国家假人中使用的合并OLS进行的，巴西== 1和韩国= 0 
我的回归是：
 回归服务_v_added_pct_gdp fdi hc hc hc hc_fdi v2x_pubcorr \\ \ \ \\
gross_capital_formation_pct_gdp brazil_dummy fdi_brazil \\\\
HC_BRAZIL HC_FDI_BRAZIL，强大

回归构造_v_added_pct_gdp fdi hc hc hc hc_fdi v2x_pubcorr \\ \ \ \ \
gross_capital_formation_pct_gdp export_goods_services_prct_gdp \\\\
brazil_dummy fdi_brazil hc_brazil hc_fdi_brazil，强大
 
自相关存在，这是通过wooldridge测试对此进行了测试的，为此，我包括了FDI和HC的滞后。
是正确纠正自相关的正确方法，还是代码中的鲁棒函数足够？
我还想补充一点，我没有进行测试，例如Newey West等。
   &lt;img alt =“在此处输入图像说明” src =“ https://i.sstatic.net/yrsbzdu0/yrsbzdu0.yrsbzdu0.png” src =“]]></description>
      <guid>https://stats.stackexchange.com/questions/663603/do-robust-standard-errors-correct-autocorrelation</guid>
      <pubDate>Sun, 06 Apr 2025 21:54:01 GMT</pubDate>
    </item>
    <item>
      <title>在负二项式与泊松模型中引导与健壮</title>
      <link>https://stats.stackexchange.com/questions/663601/bootstrapped-vs-robust-in-negative-binomial-vs-poisson-model</link>
      <description><![CDATA[对于我的本科论文，我正在对小组数据进行研究，其中我的因变量是计数变量。
我相信我的因变量被过度分散，并且由于我的研究性质，这种过度分散的情况不仅是“白噪声” - 这可能是有意义的。这意味着负二项式模型比泊松模型更好，并且在检查AIC/BIC值之后，负二项式模型的值低于泊松表明更好地拟合的泊松。
 i计划使用FE选项包括固定效果，我还希望包含可靠的标准错误以解决异性恋性。但是，在Stata中，没有选择使用Fe的XTNBREG包含可靠的标准错误（VCE（鲁棒）），但是可以进行引导错误的选项。因此，我想知道使用自举错误是否解决了异性恋。它与使用VCE（稳定）选项相同/等效吗？
我是否应该使用可靠的标准误差进行泊松回归，还是带有自举标准误差的负二项式回归？两者在重要性和系数方面都提供了相似的结果，我只希望我的方法正确。
任何帮助或建议将不胜感激，谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/663601/bootstrapped-vs-robust-in-negative-binomial-vs-poisson-model</guid>
      <pubDate>Sun, 06 Apr 2025 21:34:29 GMT</pubDate>
    </item>
    <item>
      <title>称重迪里奇先验的分类分销可能性</title>
      <link>https://stats.stackexchange.com/questions/663600/categorical-distribution-likelihood-with-weighed-dirichlet-priors</link>
      <description><![CDATA[我正在做一个项目，我想估计给定以前的状态对列表的当前状态混合策略的混合策略的可能性。我想在代理商的混合策略上找到先前的分布，以便我可以估算混合策略的不确定性。我需要某种先前的分布，以便在给定更多示例的策略上可以得到较少的策略估计。
 i将代理的策略定义为分类分布 $ \ MathBf V = \ displayStyle \ sum_ {i = 1}^{| s | | |} s_i \ Mathbf V_I $ 对于所有 $ \ MATHBF V_I $ ， $ \ Mathbf V_I \ SIM \ SIM \ MATHBF {dir}（\ MathBf {\ MathBf {\ Alpha_i}）$ 。换句话说，每个 $ \ mathbf v_i $ 都有其独特的dirichlet分发。
我应该如何找到状态行动对列表 $（x_1，\ mathbf s_1），（x_2，x_2，\ mathbf s_2）\ dots（x_n，x_n，\ mathbf s_n）$  ？我如何计算 $ \ MATHBF V $ 的每个维度的差异？
我还没有找到其他任何实施此策略的人，并且很难计算 $ \ Mathbf V $ 的PDF。我也将感谢任何有关更好先前发行的建议，但我确实想保留以下特性：

分类分布受国家向量的影响。
我们可以更好地了解一个国家的分类分布对更多国家行动对。
]]></description>
      <guid>https://stats.stackexchange.com/questions/663600/categorical-distribution-likelihood-with-weighed-dirichlet-priors</guid>
      <pubDate>Sun, 06 Apr 2025 21:04:57 GMT</pubDate>
    </item>
    <item>
      <title>基于等级观察的回归</title>
      <link>https://stats.stackexchange.com/questions/663575/regression-based-on-rank-observations</link>
      <description><![CDATA[Typically when we fit a regression equation we have raw observations in the form of $\{Y_i, X_{1, i}, , X_{2, i}, \dotsc, , X_{p, i}\}$, where $Y_i$ represent the actual values of一个因变量和 $ \ {{X_ {1，I}，\ dotsc，x_ {p，i}}}} \} $ 表示某些解释变量的实际值。
然而，就我而言，而不是因变量 $ y $ 的实际值，我在观察结果 $ n $ 中，在 $ y $ 的实现值中的等级。因此，因此，我现在有两个基本问题

  $ y_i $ 值，排名，不再是独立
  $ y_i $ 值仅是整数。为简单起见，我们假设没有领带。

下面是我在 r  中生成的示例数据的示例
  set.seed（123）
mydat = data.frame（y =示例（1：20，20，替换= false）， 
      x1 = rnorm（20，1，.5）， 
      x2_cat =示例（C（-10，0，10），20，替换= true））;打印（mydat）
    y x1 x2_cat
＃1 15 2.2641683 10
＃2 19 1.2745484 -10
＃3 14 1.1191065 0
＃4 3 0.4755534 -10
＃5 10 1.6473816 -10
＃6 2 1.4127699 10
＃7 6 0.9721570 -10
＃8 11 0.6078089 0
＃9 5 0.6332484 -10
＃10 4 0.8920673 10
＃11 18 0.8325436 -10
＃12 9 0.4571504 10
＃13 20 0.9572884 0
＃14 17 1.5353053 10
＃15 12 0.9273032 0
＃16 7 0.4172276 0
＃17 16 0.5907421 10
＃18 1 1.3424680 0
＃19 8 0.8399718 0
＃20 13 0.3442388 10
 
如何在此类数据上安装线性回归？我的目标是了解 $ y $ 的统计关系与 $ \ {x_1，\ dotsc，x_p \} $     的值
任何洞察力/书籍/在线资源都将受到这种分析的高度赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/663575/regression-based-on-rank-observations</guid>
      <pubDate>Sun, 06 Apr 2025 08:11:49 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯估计是否需要有限的人口校正？</title>
      <link>https://stats.stackexchange.com/questions/663568/does-bayesian-estimation-need-finite-population-correction</link>
      <description><![CDATA[贝叶斯估计是否假定无限的人口，不需要有限的人口校正？
说，我们想估计有限人口的平均值，假设IID值是在正态分布中替换而不替换的。]]></description>
      <guid>https://stats.stackexchange.com/questions/663568/does-bayesian-estimation-need-finite-population-correction</guid>
      <pubDate>Sat, 05 Apr 2025 23:52:19 GMT</pubDate>
    </item>
    <item>
      <title>解释赔率大于1，预测赔率小于1</title>
      <link>https://stats.stackexchange.com/questions/663403/interpreting-odds-ratios-greater-than-1-predicted-odds-less-than-1</link>
      <description><![CDATA[我正在拟合一个中断的时间序列模型来分析二进制结果：女性是否报告在出生后的前六个月内喂养孩子固体食物（是/否）。
主要暴露是COVID-19（二进制：covid之前，在covid之后）。
连续时间（在几天内）作为混杂因素，并作为与曝光的交互作用进行建模。
目的是比较在库维德（Covid）之后的**第二年回应的那年，在covid回应的妇女中喂食固体食物的几率。
以下是我的模型的关键结果（还可以调整儿童性别，母性BMI，年龄，种族，教育等，尽管我在此处不包括这些估计）：
 covid之前的时间比值比为0.524，而在旋转后期为1.2312。但是，当我绘制喂食固体食品的预测几率（在出生后的前六个月内）时，尽管模型报告的优势比为1.2312。，但趋势会下降。
我期望在杂化后发生趋势（向上）的趋势增加，但相反，该情节显示出下降的趋势。
我喜欢知道我在理解或对预测赔率的解释时出错了，尤其是在Covid时期。预先感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/663403/interpreting-odds-ratios-greater-than-1-predicted-odds-less-than-1</guid>
      <pubDate>Wed, 02 Apr 2025 07:00:35 GMT</pubDate>
    </item>
    <item>
      <title>标准化贝叶斯优化的数据</title>
      <link>https://stats.stackexchange.com/questions/662744/standardizing-data-in-bayesian-optimization</link>
      <description><![CDATA[我正在MATLAB中实现非常基本的贝叶斯优化算法。通常建议将输入（采样点）和输出（采样点上的黑框目标函数评估）标准化。我想知道如何正确执行标准化。

 我当前正在遵循的方法重新计算了每个填充点之后样品和输出的平均值和标准偏差，如采集函数所建议。我的直觉告诉我，这可能不是正确的方法。

 另一种方法是找到初始采样点的平均值和标准偏差，并将其用于标准化后续的填充点和测试数据。


截至目前，我打算使用MATLAB中的GA Optimizer找到预期改进的获取函数的最大值。为此，应提供搜索空间的下限和上限。如果我知道不可分割的采样点的上和下限，我该如何确定搜索空间的标准化上和下限？]]></description>
      <guid>https://stats.stackexchange.com/questions/662744/standardizing-data-in-bayesian-optimization</guid>
      <pubDate>Mon, 17 Mar 2025 14:22:23 GMT</pubDate>
    </item>
    </channel>
</rss>