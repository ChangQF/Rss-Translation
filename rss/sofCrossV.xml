<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 18 Dec 2023 15:14:07 GMT</lastBuildDate>
    <item>
      <title>您是否应该模拟混杂因素对其他混杂因素的影响来测试估计器？</title>
      <link>https://stats.stackexchange.com/questions/635194/should-you-simulate-the-effect-of-confounders-on-other-confounders-to-test-an-es</link>
      <description><![CDATA[想象一下，我正在尝试模拟数据生成过程，其中我对 $Y$ 做出以下假设：
$Y$ = $X$(0.15) + $Z_1$(0.23) + $Z_2$(0.08) + $Z_3$(0.19) + $Z_4$(0.05) + 错误
此外，考虑到我对几个估计器感兴趣，并且我正在尝试找出哪个估计器恢复了 0.15 的定义治疗效果最好。然而，$X$ 被几个变量混淆，所以我相应地调整它们。
我很清楚的是，对于我认为是混杂因素的变量，我需要模拟每个混杂因素对治疗和结果的影响大小。例如，如果 $Z_1$ 对 $Y$ 的影响为 0.23，我还需要在 $X$ 上模拟 0.04 的效果，否则，它不会是一个混杂因素。
然而，在更复杂的数据生成过程中，混杂因素可能会影响其他混杂因素本身的价值。也就是说，将每个混杂因素定义为与其他感兴趣的混杂因素完全外生的分布可能是不合适的。
例如，不要说 $Z_1$ 只是一个平均值为 $\mu 的正态分布变量$ 和标准差 $\sigma$，我也可以说 $Z_2$ 对 $Z_1$ 的影响为 0.33，$Z_3$ 对 $Z_3$ 的影响为 0.07 span class=&quot;math-container&quot;&gt;$Z_1$。
为了实现这个假设模拟的目标（测试不同的估计器，看看哪个估计器能最好地恢复治疗效果），是否有必要定义每个混杂因素对另一个混杂因素的影响？或者，只要我指定每个混杂因素对结果和治疗的影响，模拟分析就可以进行了吗？
一方面，我看到了全面详细说明系统中所有变量的假设数据生成过程的好处。然而，另一方面，我发现我将进一步的假设嵌入到对不感兴趣的效应大小的分析中存在问题（即我没有实际兴趣了解/思考如何 $ Z_3$ 可能会影响 $Z_1$、$Z_2$、$Z_4$ 等）。]]></description>
      <guid>https://stats.stackexchange.com/questions/635194/should-you-simulate-the-effect-of-confounders-on-other-confounders-to-test-an-es</guid>
      <pubDate>Mon, 18 Dec 2023 15:08:33 GMT</pubDate>
    </item>
    <item>
      <title>通过大小为 X 的输入的唯一映射确定算法伪随机性的最佳输出长度</title>
      <link>https://stats.stackexchange.com/questions/635191/determining-optimal-output-length-for-algorithmic-pseudo-randomness-with-unique</link>
      <description><![CDATA[我正在构建一个算法，它应该将每个输入映射到不同的输出，并且输出位应该是统计随机的（也就是说，当放入随机性测试套件（如 NIST）时，它应该给出相当好的分数）。我的问题是，对于输入大小为 X 的情况，输出应该持续多长时间才能满足上述条件？有这个公式吗？如果没有，我该如何研究这个主题？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/635191/determining-optimal-output-length-for-algorithmic-pseudo-randomness-with-unique</guid>
      <pubDate>Mon, 18 Dec 2023 14:12:11 GMT</pubDate>
    </item>
    <item>
      <title>债券和无风险利率</title>
      <link>https://stats.stackexchange.com/questions/635189/bonds-and-the-risk-free-rate</link>
      <description><![CDATA[我正在对债券进行线性回归分析。我的自变量之一（无风险利率）与债券指数（我的因变量）正相关。这应该不可能吧？无风险利率由标准普尔美国十年期国债指数代表。我可能做错了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/635189/bonds-and-the-risk-free-rate</guid>
      <pubDate>Mon, 18 Dec 2023 13:59:42 GMT</pubDate>
    </item>
    <item>
      <title>比较直方图的直方图分布与有限采样</title>
      <link>https://stats.stackexchange.com/questions/635188/comparing-histogram-of-histograms-distributions-with-finite-sampling</link>
      <description><![CDATA[假设我有一个离散概率分布，$p$，在 N 个输入上定义，$x_1$,$x_2$,...,$x_N$，这样 $\sum_i^N p(x_i)=1$。我对相关的概率分布 $F(p)$ 感兴趣，直觉是我基本上对元素进行随机采样 $F$ 的 &gt;$p(x_i)$。换句话说，如果我制作概率的直方图 $p(x_i)$，它们应该遵循 $F(p ）$。该对象$F$有时被称为“直方图的直方图”。或“指纹”，也许还有其他名称（参见，Valiant 2011，估计看不见的事物）。
假设我采用了一组 $M$ 样本，从中重建分布 $\hat{ p}$，然后我可以计算采样的 $F(\hat{p})$。我的目标是，给定候选分布 $F_0(p)$，是测试是否 $F(\hat{ p})$ 和 $F_0(p)$ 是相同的分布。在 $M\rightarrow\infty$ 的限制中，这是相对明确的，我认为使用 Kolmogorov-Smirnov 测试，但在 $M$ 只有${\approx}10N$，我发现由于 $F_0(p)$ 相比可以显着拓宽math-container&quot;&gt;$\hat{p}$，这使得比较变得困难。在进行比较时，是否有关于如何正确处理 $\hat{p}$ 的离散化的建议或文献？或者，更理想的是，有没有办法直接从 $F(\hat{p})$ 中对有限采样的效果进行反卷积？]]></description>
      <guid>https://stats.stackexchange.com/questions/635188/comparing-histogram-of-histograms-distributions-with-finite-sampling</guid>
      <pubDate>Mon, 18 Dec 2023 13:36:25 GMT</pubDate>
    </item>
    <item>
      <title>当 X1 X2 和 Y 具有单位根时的 OLS：I(1)，但不协整</title>
      <link>https://stats.stackexchange.com/questions/635186/ols-when-x1-x2-and-y-have-unit-roots-i1-but-not-cointegrated</link>
      <description><![CDATA[我有三个对数转换的时间序列变量，它们是：I(1) 并且不协整。我在讲座幻灯片中读到，我可以通过添加 LDV 来重新思考我的模型。这解决了我的自相关问题（我添加了 LDV 来解决自相关问题），但外部回归量的效果显着下降。我正在尝试这些组合，看看它们有何不同：
Y(t) = X_1(t) + 错误
Y(t) = X_1 (t) + X_1 (t-1) + Y (t-1) + 误差
Y(t) = X_1 (t-4) + X_2 (t) + 误差
Y(t) = X_1 (t-4) + X_2 (t)+ Y (t-1) + 误差（我进行了顺序测试以确定变量 X_1 的滞后顺序为 4）


对于方程 (2)，我发现系数的符号发生了变化，而对于方程 (4)，与方程 3 相比，两个变量的系数均显着下降。
我经历了这个问题，部分回答了我的问题是在我的模型中使用 LDV，但我想了解为什么方程 2 的符号会发生变化。
我对统计学有一定的了解，所以如果这个问题没有意义，请告诉我。
modelx1 = dynlm(y~x1)
            估计标准。误差t值Pr(&gt;|t|)
（截距）1.8868 0.0306 61.6351 0
x1 -0.3724 0.0091 -41.0770 0
    


modelx1.ar1 = dynlm(y~ L(y, 1)+ L(x1, 0:1))


             估计标准。误差t值Pr(&gt;|t|)
（截距） 0.17596 0.15926 1.10489 0.27581
L(y, 1) 0.91166 0.09068 10.05375 0.00000
L(x1, 0:1)0 -0.41712 0.14231 -2.93118 0.00556
L(x1，0:1)1 0.38155 0.16092 2.37113 0.02264


modelx1.ar1 残差的 ACF 图
]]></description>
      <guid>https://stats.stackexchange.com/questions/635186/ols-when-x1-x2-and-y-have-unit-roots-i1-but-not-cointegrated</guid>
      <pubDate>Mon, 18 Dec 2023 12:48:39 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 RNA seq 数据查看单个基因的组间差异</title>
      <link>https://stats.stackexchange.com/questions/635184/how-to-look-at-between-group-differences-for-a-single-gene-using-rna-seq-data</link>
      <description><![CDATA[我有一个 RNA seq 数据集，但我只对单个基因的表达感兴趣并在组之间（患者表型）进行比较。有人建议我使用方差稳定变换并在组之间进行简单的 t 检验，但我不确定这是否是正确的方法；或者甚至，如果应该这样做的话。
该数据集由 n=50 名患者的 RNA seq 数据组成。我目前正在使用 DESeq2。]]></description>
      <guid>https://stats.stackexchange.com/questions/635184/how-to-look-at-between-group-differences-for-a-single-gene-using-rna-seq-data</guid>
      <pubDate>Mon, 18 Dec 2023 12:26:18 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中隐藏层是否存在隐藏成本函数？</title>
      <link>https://stats.stackexchange.com/questions/635183/is-there-hidden-cost-function-for-hidden-layer-in-the-neural-network</link>
      <description><![CDATA[对于神经网络，不同的隐藏层是否有不同的成本函数？
或者最后一层是否有一个成本函数？
例如，在神经网络中，隐藏层具有 sigmoid 和 Relu 激活，输出层具有线性激活。
那么，成本函数是 MSE 取决于最终输出层的激活吗？或者不同层的成本函数是否不同——隐藏层中 sigmoid 激活的成本函数对数损失？]]></description>
      <guid>https://stats.stackexchange.com/questions/635183/is-there-hidden-cost-function-for-hidden-layer-in-the-neural-network</guid>
      <pubDate>Mon, 18 Dec 2023 12:25:47 GMT</pubDate>
    </item>
    <item>
      <title>分类数据聚类最合适的索引是什么？</title>
      <link>https://stats.stackexchange.com/questions/635182/what-is-the-most-appropriate-index-for-categorical-data-clustering</link>
      <description><![CDATA[我正在尝试复制Bai &amp; 发表的一项研究。 Liang，2022 专注于对纯分类数据进行聚类，这些数据主要在 UCI 存储库。在我的 K 模式实验中，我观察到指数包括归一化信息变化 (NVI)、归一化信息距离 (NDI)、归一化互信息 (NMI)、调整互信息 (AMI) 和调整兰德指数（ARI）并不比随机标签好，根据已发表的论文检查，作者报告的 NMI 和 ARI 值都在 0.5 以上。然而，Folkes-Mallows 指数似乎显示出相对较好的值。
我想知道为什么会发生这种情况，也就是说我正在尝试调查这个可观察到的偏差。我的第一个怀疑是最佳簇的数量太高，这使得原始簇标签（范围在 2 个簇到 4 个簇之间）和生成的簇标签之间的比较太困难。
就上下文而言，我运行了 K-Modes 100 次，并对下表中报告的指数值进行了平均：

鉴于报告的值，我想知道 NVI、NID、NMI、AMI 和 ARI 是否确实是分类数据聚类的良好衡量标准，或者我应该使用内部一致性衡量标准，例如在每个集群上运行潜在类分析检查内部一致性作为集群性能的替代衡量标准。此外，我还想知道卡方距离是否也是一个不错的选择。]]></description>
      <guid>https://stats.stackexchange.com/questions/635182/what-is-the-most-appropriate-index-for-categorical-data-clustering</guid>
      <pubDate>Mon, 18 Dec 2023 12:25:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 ROC 曲线进行阈值移动时，分类阈值变化很大</title>
      <link>https://stats.stackexchange.com/questions/635181/classification-threshold-varies-wildly-when-using-roc-curves-for-threshold-movin</link>
      <description><![CDATA[我正在尝试进行阈值移动以获得不平衡数据集的适当阈值。我有一个一维时间序列，正在其上应用基于二进制变压器的分类器。我有：
训练集：
  样本总数：8133
  0 的数量：6930 (85.21%)
  1 的数量：1203 (14.79%)

验证集：
  样本总数：904
  0 的数量：770 (85.18%)
  1 的数量：134 (14.82%)

测试集：
  样本总数：232
  0 数量：198 (85.34%)
  1 的数量：34 (14.66%)

注意：我正在尝试修复验证集的阈值。我见过很多人为此使用测试集，但我认为这会使测试集上的分类器产生偏差。如果我这里有错，请纠正我。
我使用了 sklearn test_train_split 并使用了 stratify=y 并传递了 random_state 以获得可重现的结果。现在的问题是我得到的“最佳阈值”差异很大。当使用 ROC-AUC 曲线时 - 即使面积大致相同。我正在尝试做两个实验：

使用不同的方法，例如：(a) 正常训练（对频率较低的类别不加权）、(b) 基于 class_weight 的训练、(c) 在训练集上进行 SMOTE
训练到不同的num_epochs（不同的纪元数）

在（1）中，我得到了截然不同的结果，我无法理解。例如，正常训练给出“最佳阈值”。 0.01，class_weights 方法给出的最佳阈值是 0.45，SMOTE 给出的最佳阈值是 0.02。
巨大的差异是我无法理解的。需要注意的是，对于 SMOTE，分布如下（仅在训练集上应用 SMOTE）：
训练集：
  样本总数：13860
  0 的数量：6930 (50.00%)
  1 的数量：6930 (50.00%)

验证集：
  样本总数：904
  0 的数量：770 (85.18%)
  1 的数量：134 (14.82%)

测试集：
  样本总数：232
  0 数量：198 (85.34%)
  1 的数量：34 (14.66%)

即使在历元变化中，当全面使用 class_weights 方法并使用 10、20、40、60、80、100 历元进行训练时，在尝试对验证进行 ROC-AUC 分析时，我会得到很大范围的阈值变化放。一直从 0.002-0.7 - 这很疯狂，我无法真正理解最佳阈值的问题出在哪里。我做事的逻辑有缺陷吗？以下是我正在使用的 ROC-AUC 代码
defplot_roc_auc_curve(y_true, y_pred_probs, best_threshold):
    # 计算ROC曲线和ROC AUC
    fpr、tpr、阈值 = roc_curve(y_true、y_pred_probs)
    roc_auc = auc(fpr, tpr)
    
    # 绘制ROC曲线
    plt.plot(fpr, tpr, lw=1, label=&#39;ROC (面积 = %0.2f)&#39; % (roc_auc))
    plt.plot([0, 1], [0, 1], color=&#39;海军蓝&#39;, lw=1, linestyle=&#39;--&#39;)
    plt.plot(fpr[阈值 == best_threshold], tpr[阈值 == best_threshold], &#39;ko&#39;, label=&#39;最佳阈值&#39;)
    plt.text(fpr[阈值== best_threshold], tpr[阈值== best_threshold], f&#39;最佳阈值:{best_threshold:.2f}&#39;)
    plt.xlim([-0.05, 1.05])
    plt.ylim([-0.05, 1.05])
    plt.xlabel(&#39;误报率&#39;)
    plt.ylabel(&#39;真阳性率&#39;)
    plt.title(&#39;接受者操作特征 (ROC) 曲线&#39;)
    plt.legend(loc=&quot;右下&quot;)
    plt.show()

    返回 roc_auc，阈值

def get_best_threshold(y_true, y_pred_probs):
    fpr、tpr、阈值 = roc_curve(y_true、y_pred_probs)
    best_threshold = 阈值[np.argmax(np.abs(tpr - fpr))]
    返回最佳阈值

我附上了一些 ROC-AUC 曲线的屏幕截图，其中包含根据此代码绘制的最佳阈值。请帮助我调试/解释结果。



编辑：当我按照代码的建议将阈值设置为 0.01（对于普通情况）并重新运行验证时，我得到的 F1 分数比 0.5 时要低]]></description>
      <guid>https://stats.stackexchange.com/questions/635181/classification-threshold-varies-wildly-when-using-roc-curves-for-threshold-movin</guid>
      <pubDate>Mon, 18 Dec 2023 12:24:20 GMT</pubDate>
    </item>
    <item>
      <title>小样本量的 glmnet 包的 Lasso 模型 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635175/lasso-model-by-glmnet-package-in-small-sample-size</link>
      <description><![CDATA[我想创建一个套索模型，但我无法拥有测试集，因为我的样本量很小。所以，我想使用交叉验证来评估模型。
我已经看到像 cv.glmnet 和 caret 这样的函数被用来制作套索模型。现在我想知道是否可以从 cv.glmnet 获取混淆矩阵，或者我应该使用 caret 而不是 cv.glmnet？或者将cv.glmnet用作内部CV来选择lambda并使用caret作为外部CV？了解这个问题对于我确定是否应该使用 cv.glmnet 很重要。]]></description>
      <guid>https://stats.stackexchange.com/questions/635175/lasso-model-by-glmnet-package-in-small-sample-size</guid>
      <pubDate>Mon, 18 Dec 2023 10:36:20 GMT</pubDate>
    </item>
    <item>
      <title>异常值对 QQ 图的影响</title>
      <link>https://stats.stackexchange.com/questions/635163/impact-of-outliers-to-qq-plot</link>
      <description><![CDATA[我正在尝试构建 GLM 回归（10k 样本和 50 个维度）。我对因变量进行了分析，因为回归对因变量有正态性假设。
QQ图（中图）显示y的分布远离正态分布（这是否意味着y存在差距？我没有找到差距在直方图中（上图））。删除 y 的顶部 3% 和底部 3% 后，QQ 图（下图）变成一条直线，暗示着重尾。
我的问题是：1.为什么QQ图对极值如此敏感？ 2.由于QQ图对极值或异常值太敏感，删除某些数据后运行QQ图是否有意义？

上一篇文章没有多大帮助.]]></description>
      <guid>https://stats.stackexchange.com/questions/635163/impact-of-outliers-to-qq-plot</guid>
      <pubDate>Mon, 18 Dec 2023 06:30:06 GMT</pubDate>
    </item>
    <item>
      <title>通过嵌入循环和 fft 来快速 Cholesky 分解 Toepllitz 矩阵</title>
      <link>https://stats.stackexchange.com/questions/635120/fast-cholesky-decomposition-of-a-toepllitz-matrix-via-embedding-in-a-circulant</link>
      <description><![CDATA[据我了解，通过首先将托普利茨矩阵嵌入循环矩阵然后使用 FFT 可以更有效地计算托普利茨矩阵的 Cholesky 分解，但我在任何地方都找不到这种方法的任何实现，也找不到该方法的描述具体的一系列操作我需要自己实现。帮忙？
下面是构建 Toeplitz 的代码，以标准方式计算 Cholesky 分解，然后进行循环嵌入：
&lt;前&gt;&lt;代码&gt;#imports
将 numpy 导入为 np
从 scipy.linalg 导入 toeplitz、循环、cholesky
从 scipy.fftpack 导入 fft, ifft

# 构造托普利茨矩阵
t = toeplitz(np.array([1., 0.5])) + ( 1e-6 * np.eye(2) )
打印（t）
# [[1.000001 0.5]
# [0.5 1.000001]]

# 以标准方式计算胆汁
chol_ltri_std = cholesky(t,lower=True)
打印（chol_ltri_std）
# [[1.0000005, 0.]
# [0.49999975, 0.86602613]]

＃ 核实：
chol_ltri_std @ chol_ltri_std.T # 应该 == t

#embed in circulant（也许需要不同的嵌入？反射和周期性似乎也不起作用）
c = circulant(np.concatenate([t[0,:],t[0,:-1][::-1]]))
打印（三）
# [[1.000001 1.000001 0.5 ]
# [0.5 1.000001 1.000001]
# [1.000001 0.5 1.000001]]

#尝试基于 FFT 的胆斯基分解
特征值 = fft(c)
sqrt_特征值 = np.sqrt(特征值)
inverse_fft_real = ifft(sqrt_eigenvalues).real

打印（inverse_fft_real）
# 产量：
# [[0.93529519 0.52704649 0.11879779]
# [0.52704649 0.11879779 0.93529519]
# [0.93529519 0.11879779 0.52704649]]
#但是这些值都不匹配 chol_ltri_std 的元素
]]></description>
      <guid>https://stats.stackexchange.com/questions/635120/fast-cholesky-decomposition-of-a-toepllitz-matrix-via-embedding-in-a-circulant</guid>
      <pubDate>Sun, 17 Dec 2023 14:46:15 GMT</pubDate>
    </item>
    <item>
      <title>在线性混合模型中，如果因变量对于随机因子是重复的怎么办？</title>
      <link>https://stats.stackexchange.com/questions/635107/in-linear-mixed-model-what-if-the-dependent-variable-is-repetitive-for-a-random</link>
      <description><![CDATA[（一）研究背景：
我的研究设计包括让每个参与者完成多项试验来评估他们的幸福感，同时记录脑电图数据。每个参与者都有不同的脑电图通道。我的目标是使用每个通道的脑电图数据指标（例如 avg_HFB 和 peri_HFB）来预测幸福感评分。由于参与者在不同时间进行重复测量，我构建了一个以主题和频道作为随机变量的线性混合模型。频道嵌套在主题内，幸福评级（z rating）是因变量，如下：
zrate ~ avg_HFB * peri_HFB + (1|主题/频道)
（2）遇到的问题：
但是，在拟合过程中，我遇到了一个奇异拟合问题，其中 subject:channels 的方差等于 0。

(3)示例数据：
这是数据结构和一些示例数据：


大约有 15 名参与者，每个参与者有 1-8 个通道，以及 30-140 次试验。
（4）我所做的尝试：

在线性混合模型中，如果随机因素仅包含主体或渠道，则模型可以拟合成功。




通过复制一些参与者的数据（大约 600 个观察值），可以拟合嵌套模型。


(5)我的假设：
我怀疑，在数据结构中，对于参与者来说，当受试者进行快乐评分时，通道同时记录脑电图数据，这意味着受试者的所有通道对应于同一组因变量数据（快乐评分数据） ）。因此，我假设因变量的变化仅反映在参与者之间。在同一参与者中，渠道之间可能没有差异（尽管数量和具体试验可能有所不同）。如果是这样，将主题或通道作为随机因素应该足以捕获这种可变性。因此，我推测，当受试者和通道都被视为随机因素时，只有受试者方差的原因可能是由于此。
然而，这只是我的逻辑或直觉推测。我不确定这个推理是否准确，并且它无法解释为什么复制数据可以使模型拟合（因为数据结构保持不变）。
这是我第一次在这个平台上提问，所以如果需要任何进一步的信息，请告诉我。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635107/in-linear-mixed-model-what-if-the-dependent-variable-is-repetitive-for-a-random</guid>
      <pubDate>Sun, 17 Dec 2023 09:54:37 GMT</pubDate>
    </item>
    <item>
      <title>虚拟变量的回归[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635106/regression-of-dummy-variable</link>
      <description><![CDATA[有人可以提供公式来手动计算给定数据集的回归中虚拟变量系数的标准误差
种族 西班牙裔 亚洲人 非洲裔美国人 白人 总计
平均值 46.4583 58.0000 48.2000 54.0552 52.7750
N 24 11 20 145 200]]></description>
      <guid>https://stats.stackexchange.com/questions/635106/regression-of-dummy-variable</guid>
      <pubDate>Sun, 17 Dec 2023 09:15:52 GMT</pubDate>
    </item>
    <item>
      <title>比较两个样本的第 90 个百分位数（置信区间、检验）</title>
      <link>https://stats.stackexchange.com/questions/635097/compare-90th-percentiles-of-two-samples-confidence-interval-test</link>
      <description><![CDATA[我有一个质量改进更改前后的救护车响应时间数据集。我想看看更改前后的响应时间是否有差异。具体来说，我试图报告两组（之前和之后）中的第 90 个百分位数值、两个第 90 个百分位数之间的差异、$95$% 置信区间（ CI) 围绕这个差异，以及一个 $p$ 值。
在 R 中，数据集可能如下所示：
set.seed(123)
数据 &lt;- data.frame(
  组=样本（c（“之前”，“之后”），100，替换= TRUE），
  响应时间 = rnorm(100, 平均值 = c(10, 15), sd = 2)
）

我可以使用 t.test 函数轻松测试均值差异：
t.test(data$ResponseTime[data$Group == “之前”],
       数据$ResponseTime[数据$Group ==“之后”])

我还可以像这样计算第 90 个百分位数：
之前 &lt;- 分位数(a$ResponseTime[a$Group==“之前”], probs = 0.9, na.rm = T)
&lt;- 分位数（a$ResponseTime[a$Group==“之后”]，probs = 0.9，na.rm = T）

但我不知道如何比较两者。
我的问题：

这有意义吗？
如果确实有意义，我会使用什么测试来比较第 90 个百分位数？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635097/compare-90th-percentiles-of-two-samples-confidence-interval-test</guid>
      <pubDate>Sun, 17 Dec 2023 02:55:47 GMT</pubDate>
    </item>
    </channel>
</rss>