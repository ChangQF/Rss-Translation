<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 17 Nov 2024 15:16:18 GMT</lastBuildDate>
    <item>
      <title>预测模型和机器学习中的信噪比</title>
      <link>https://stats.stackexchange.com/questions/657395/signal-to-noise-ratio-in-predictive-modeling-and-machine-learning</link>
      <description><![CDATA[对此问题的有趣评论涉及信噪比如何影响预测能力。更明确地说，信噪比如何影响预测的准确性？例如，信噪比究竟是什么意思？它对预测建模意味着什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657395/signal-to-noise-ratio-in-predictive-modeling-and-machine-learning</guid>
      <pubDate>Sun, 17 Nov 2024 13:42:20 GMT</pubDate>
    </item>
    <item>
      <title>用于检验回归模型因果关系的变量选择：应该还是不应该？</title>
      <link>https://stats.stackexchange.com/questions/657394/variable-selection-for-checking-casual-relationship-of-regression-model-should</link>
      <description><![CDATA[我正在寻找文档和在线资源，以了解是否应该通过模型选择（变量选择）从我的模型中排除变量。
我还尝试使用最小绝对收缩和选择算子 (LASSO)、赤池信息准则 (AIC，针对所有可能的子集)、贝叶斯信息准则 (BIC，针对所有可能的子集)、贝叶斯模型平均 (BMA)、统计等效签名 (SES) 等方法进行模型选择。
我的模型有六个变量。
主要有两种思想流派。
一种是我们不应该排除变量。来源如下：
即使很麻烦，使用 LASSO 进行变量选择是否值得？
特征选择后的因果推理
关于变量选择的更权威的讨论
https://www.reddit.com/r/statistics/comments/16x3266/q_variable_selection_for_causal_inference/?rdt=43830
https://discourse.datamethods.org/t/model-selection-and-assessment-of-model-fit/321/5
另一个是我们应该考虑消除虚假变量。来源如下
https://www.degruyter.com/document/doi/10.1515/jci-2017-0010/html
https://academic.oup.com/aje/article/177/4/292/147738?login=true
因此，我很困惑我应该遵循哪些程序。
此外，我认为程序应该是：使用所有变量拟合模型-&gt; 检查因果关系 -&gt; 变量选择（仅适用于传统建模：线性、泊松、负二项式、零膨胀，因为机器学习算法本身会进行变量选择）-&gt; 预测误差评估。这是真的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657394/variable-selection-for-checking-casual-relationship-of-regression-model-should</guid>
      <pubDate>Sun, 17 Nov 2024 13:31:19 GMT</pubDate>
    </item>
    <item>
      <title>具有交互项的负二项式 GLM...Anova 警告？</title>
      <link>https://stats.stackexchange.com/questions/657393/negative-binomial-glm-with-interaction-term-anova-warning</link>
      <description><![CDATA[我正在运行一个看似简单的模型：
model&lt;- glm.nb(PathogenLoad ~ Species*Lifestage, data = data)

物种变量有 3 个级别，生命阶段有 2 个级别。一切似乎在模型本身上运行良好，除了当我尝试运行 ANOVA (anova(model)) 时，我得到了带有以下警告消息的输出。
 Df Deviance Resid。Df Resid。 Dev Pr(&gt;Chi) 
NULL 96 256.4 
Lifestage 1 0.0 95 7152.5 1 
Species 2 3220.2 93 3932.4 &lt;2e-16 ***
Lifestage:Species 2 3793.0 91 139.4 &lt;2e-16 ***

**警告消息：
1：在 anova.negbin(nb_model) 中：测试未重新估计“theta”
2：glm.fit：算法未收敛
3：glm.fit：算法未收敛**

我到处寻找，只是不确定这是否意味着我的模型实际上不起作用，或者仅仅是因为在 glm.nb 上运行 Anova 很复杂？
我希望看到的是独立且交互效果与我驾驶汽车时一样清晰:: 在不同二元模型上进行方差分析。
对于 glm.nb，还有其他我不知道的方法吗？或者可以使用 emmeans 并直接解释我的数据而不进行方差分析吗？我是否可能需要为过度分散的数据尝试不同的系列？]]></description>
      <guid>https://stats.stackexchange.com/questions/657393/negative-binomial-glm-with-interaction-term-anova-warning</guid>
      <pubDate>Sun, 17 Nov 2024 12:14:37 GMT</pubDate>
    </item>
    <item>
      <title>最佳拟合线 = 回归函数，还是 = 简单线性回归函数？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657392/is-the-best-fitted-line-the-regression-function-or-is-it-the-simple-linear</link>
      <description><![CDATA[最佳拟合线对应的是回归函数还是简单线性回归函数？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657392/is-the-best-fitted-line-the-regression-function-or-is-it-the-simple-linear</guid>
      <pubDate>Sun, 17 Nov 2024 11:49:43 GMT</pubDate>
    </item>
    <item>
      <title>HMM 的后向-前向算法</title>
      <link>https://stats.stackexchange.com/questions/657391/backward-forward-algorithm-for-hmm</link>
      <description><![CDATA[我理解HMM中前向-后向算法的推导。
然而，当我尝试在HMM中推导后向-前向算法（简单地说是原始算法的反向）时，我遇到了障碍。
我的第一个方法是将P（S_{t} = k，{O_{t}} t= 1…T）拆分为P{O_{1}，…，O_{t-1} |S_{t} =k)P（O_{t}，…，O_{T}，S_{t} =k），
但后来我发现，即使我将后向概率和前向概率的起点分别更改为t-1和t，这种格式也不适合后向和前向概率。
对此有什么看法？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657391/backward-forward-algorithm-for-hmm</guid>
      <pubDate>Sun, 17 Nov 2024 10:07:06 GMT</pubDate>
    </item>
    <item>
      <title>汇集 OLS 中的 SUR</title>
      <link>https://stats.stackexchange.com/questions/657389/sur-in-pooled-ols</link>
      <description><![CDATA[假设您的样本量为 150，由五个独立实体组成，这些实体的特征是样本，并且假定这些实体具有共同的解释变量。

同方差性：不能拒绝零假设
固定或随机效应：通过降低 t 和 t-1 消除
估计方法：对降低的数据进行合并 OLS，使用共同冲击虚拟变量作为解释变量。

如果 SUR 产生明显更好的 p 值，报告此结果是否是 p-hacking 的一个例子或合法性，因为实体之间的误差相关性可能仍然存在但未被考虑，特别是在样本量相对较小的情况下？]]></description>
      <guid>https://stats.stackexchange.com/questions/657389/sur-in-pooled-ols</guid>
      <pubDate>Sun, 17 Nov 2024 08:02:06 GMT</pubDate>
    </item>
    <item>
      <title>在插值中包含数据但不将其添加为节点</title>
      <link>https://stats.stackexchange.com/questions/657388/including-data-in-an-interpolation-without-adding-them-as-nodes</link>
      <description><![CDATA[我正在编写用于脱气矿物样品和测量释放气体的质谱数据缩减软件。我的软件所做的一件事是测量序列时间内的空白水平，并将该空白水平插入到样品时间，以计算每个样品的唯一空白校正。
除了“真实”空白，我们还有“重新提取”：这些是对每个样品的二次分析，以确保在第一次分析期间释放了所有气体。假设这些处于空白水平（在真实空白平均值的 2$\sigma$ 以内），它们可以用作额外的伪空白。
我想将这些“重新提取”数据包含在三次插值中，而不将它们添加为插值节点。这是因为

相对于真正的空白，重新提取是密集的（有很多）
我们正在测量空白水平，这涉及很多噪音

这些因素意味着当我尝试将重新提取与真正的空白一起添加为插值节点时，它会破坏拟合例程并且一切都归零。
我的问题是：如何将这些数据包含在三次插值中以影响拟合，而无需实际将它们添加为插值节点？当然，有办法，但我不知道正确的术语。
我可以使用简单的加权，但每个空白测量和重新提取也有一个与之相关的错误，我目前正在使用它来加权插值，我不确定如何将错误与一些任意权重相结合。]]></description>
      <guid>https://stats.stackexchange.com/questions/657388/including-data-in-an-interpolation-without-adding-them-as-nodes</guid>
      <pubDate>Sun, 17 Nov 2024 06:01:54 GMT</pubDate>
    </item>
    <item>
      <title>卡方和指数分布</title>
      <link>https://stats.stackexchange.com/questions/657385/chi-square-and-exponential-distributions</link>
      <description><![CDATA[单个卡方 RV 的图在 X^2 = 0 处趋于无穷大。为什么当添加卡方 RV 时，得到的 pdf 图似乎在 Y= 0 处为有限值，其中 Y = 这些 RV 的总和。此外，各种来源都说，具有 2 个 dgf 的卡方 RV 实际上是指数分布的 RV。卡方 RV 通常与方差分布相关，而指数分布的 RV 通常与下一个事件发生的时间概率相关。那么，我们如何解决这两个看似不同的解释，以便它们定性地描述同一件事？我不是在寻找完整的技术数学证明，而是寻找一般的定性直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/657385/chi-square-and-exponential-distributions</guid>
      <pubDate>Sun, 17 Nov 2024 01:01:01 GMT</pubDate>
    </item>
    <item>
      <title>根据方差分析的总体 p 值进行事后检验不是一个问题吗？[重复]</title>
      <link>https://stats.stackexchange.com/questions/657373/isnt-it-a-problem-to-conduct-post-hoc-tests-based-on-the-overall-p-value-from-a</link>
      <description><![CDATA[我寻找过这个问题的答案，但似乎到目前为止还没有人问过。如果这个问题已经有人问过了，我深表歉意。
假设在进行方差分析后，我得到的整体 p 值小于 0.05（或任何 alpha 水平）。之后，我决定进行事后成对检验来检查每个组之间的个体差异（例如 Tukey 诚实显着性检验，但它可能是另一种方法，因为我的问题非常笼统）。
我是否应该相信我从事后检验中获得的 p 值，因为我知道如果我从方差分析中获得了一个较大的整体 p 值，我就不会进行这些检验？（例如 &gt; 0.05）
对整体方差分析的结果进行事后检验感觉有点像我在“搞砸”概率。
但是，我不知道如何用数学术语形式化我的直觉，以检查这样的条件是否是一个严重的问题，或者我只是在想象一个实际上不存在的问题，或者这是否是一个可以忽略的小问题。
我的实际问题是：无论我从方差分析中获得的总体 p 值如何，我是否都应该进行那些事后检验？
我想“这取决于”可能是对我的问题的答案，但我希望得到一些一般性的指导、指示或例子。我没有数据可以分享，因为这实际上是我自己教育的一个假设性问题。
编辑
我已阅读此处的线程在事后检验之前我们需要进行全局检验吗？，如之前的评论中所述，但恐怕它可能无法完全回答我的问题。我不仅想知道在获得总体 p 值 &gt; 0.05（在另一个线程中已解决）后我是否可以进行事后检验，还想知道我是否必须进行这些事后检验（假设如果 p 值 &lt; 0.05，我会进行这些检验），以及为什么/为什么不。如果这取决于分析的情况，我有兴趣了解具体情况会如何影响这一点，可能还会举例说明。我认为其他帖子没有解决我的问题的另一部分。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657373/isnt-it-a-problem-to-conduct-post-hoc-tests-based-on-the-overall-p-value-from-a</guid>
      <pubDate>Sat, 16 Nov 2024 19:07:46 GMT</pubDate>
    </item>
    <item>
      <title>如果 alpha = 0.05 时 p 值为 0.0503，我们是否拒绝原假设？如果有的话，用什么方法可以验证拒绝？</title>
      <link>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</link>
      <description><![CDATA[我知道它大于 0.05，但我只是想知道，因为将其四舍五入到小数点后两位会得到 0.05。我只是想确保我没有错误地接受零假设。有没有办法说，即使这个值接近 alpha，也有足够的证据拒绝零假设？
另外，我知道我不应该这样做，但在进行事后分析后，我得到了不同治疗之间的均值结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</guid>
      <pubDate>Fri, 15 Nov 2024 17:58:11 GMT</pubDate>
    </item>
    <item>
      <title>在几乎为零的数据中寻找异常值</title>
      <link>https://stats.stackexchange.com/questions/657310/finding-outliers-in-mostly-zero-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657310/finding-outliers-in-mostly-zero-data</guid>
      <pubDate>Fri, 15 Nov 2024 12:03:04 GMT</pubDate>
    </item>
    <item>
      <title>结构方程模型 - Semopy</title>
      <link>https://stats.stackexchange.com/questions/657304/structural-equation-modelling-semopy</link>
      <description><![CDATA[我创建了一些模拟数据。为了简单起见，假设我已完成以下操作：
y = (X_1 + X_2 + X_3)/3
其中每个 X_i 均取自正态分布，我通过指定相关矩阵然后执行 cholesky 分解来添加相关性。我创建了大量样本，然后计算 y 的相应值。
现在我的目标是进行推理，但我不想回答这样的问题：如果我更改 X_1，而其他变量保持不变，y 会发生什么情况。相反，我想知道这样的事情：如果我改变 X_1 并考虑相关矩阵，对 y 有什么影响。
我从未做过任何 SEM，所以我可能非常不准确，但这是我在 semopy 中尝试的（我认为符号应该与 lavaan 的符号相似）
model_desc = &quot;&quot;&quot;
# 回归模型
Y ~ X_1 + X_2 + X_3

# 相关性
X_1 ~~ X_2
X_1 ~~ X_3
X_2 ~~ X_3
&quot;&quot;&quot;

然后我传入包含 y、X_1、X_2、X_3 的模拟值的数据框。
当这个模型运行时，我得到了一些奇怪的输出。对于相关变量，我从我的相关矩阵中看到相关系数。即，
X1 ~~ X2 的估计值非常接近我指定的相关性。但是，我的目标变量（例如 y ~ X_1）的估计值全为零。
我的第一个问题是：使用 SEM 是否是我想要实现的正确方法？其次，我的实施哪里出了问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/657304/structural-equation-modelling-semopy</guid>
      <pubDate>Fri, 15 Nov 2024 10:24:04 GMT</pubDate>
    </item>
    <item>
      <title>将 Hessian 矩阵居中并进行 QR 变换后恢复为原始参数 X</title>
      <link>https://stats.stackexchange.com/questions/657210/transforming-hessian-to-original-parameters-after-centering-and-qr-transforming</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657210/transforming-hessian-to-original-parameters-after-centering-and-qr-transforming</guid>
      <pubDate>Wed, 13 Nov 2024 15:34:57 GMT</pubDate>
    </item>
    <item>
      <title>如果分类变量保留在 R 中的最终模型中，那么为什么事后分析表明水平没有差异？</title>
      <link>https://stats.stackexchange.com/questions/655810/if-the-categorical-variable-is-retained-in-my-final-model-in-r-then-why-does-th</link>
      <description><![CDATA[我正在使用 R 中的 anova() 函数进行模型选择，并且我的分类变量在我的最终模型中得到了保留，但是当我使用 emmeans() 函数进行事后分析时，它告诉我水平没有差异。这是什么意思？
我使用 R 软件，我正在研究一种鱼的身体状况在三种河流中的变化：保护性河流、轻微城市化河流和高度城市化河流。每个类别都有一个重复，这意味着我有 2 条保护性河流、2 条轻微城市化河流和 2 条高度城市化河流，这意味着“河流”是一个随机因素，“城市化类别”是我的固定因素和具有 3 个级别的预测变量。在使用 anova() 函数在 R 中执行模型选择时，分类变量“类别”得到保留：
`#它是一个线性混合模型，因为条件呈正态分布
&gt; lmm.1 &lt;- lmer(条件 ~ 城市化类别 + (1|河流), 数据 = 鱼) 
&gt; lmm.null &lt;- lmer(条件 ~ 1 + (1|河流), 数据 = 鱼) 
&gt; anova(lmm.null, lmm.1)
使用 ML（而不是 REML）重新拟合模型
数据：鱼
模型：
lmm.null：条件 ~ 1 + (1 | 河流)
lmm.1：条件 ~ 城市化类别 + (1 | 河流)
npar AIC BIC logLik 偏差 Chisq Df Pr(&gt;Chisq)
lmm.null 3 -214.42 -205.37 110.21 -220.42
lmm.1 5 -219.80 -204.71 114.90 -229.80 9.3806 2 0.009184 **
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1`

`
我忘记在我的问题中包含我的模型摘要，所以这里是：
&gt; summary(lmm.1)
REML [&#39;lmerMod&#39;] 拟合的线性混合模型
公式：条件 ~ 城市化类别 + (1 | 河流)
数据：鱼

收敛时的 REML 标准：-214.3

缩放残差：
最小 1Q 中位数 3Q 最大
-2.65967 -0.54776 -0.07734 0.56748 2.79995

随机效应：
组名称方差标准差。
河流（截距）0.001965 0.04432 
残差 0.012381 0.11127 
观测数：151，组：河流，6

固定效应：
估计标准差。误差 t 值
（截距） -0.12808 0.04154 -3.084
category.of.urbanizationslightly 0.15972 0.05376 2.971
category.of.urbanizationvery 0.17063 0.05432 3.141

固定效应相关性：
（截距） ctgr.d.rbnzcp
ctgr.d.rbnzcp -0.773 
ctgr.d.rbnzcm -0.765 0.591 

我的 p 值为 0.009184，这意味着城市化类别是一个重要的预测因素，我预计分类变量的至少一个级别会与其他级别不同。然而，当尝试进行事后分析时，我调用了 emmeans() 函数，R 说所有水平都没有差异，因为 p 值都高于 0.05：
`&gt; emmeans(lmm.1，成对 ~ category.of.urbanization)
已注册的 S3 方法被“broom”覆盖：
方法来自 
tidy.glht jtools
tidy.summary.glht jtools
$emmeans
category.of.urbanization emmean SE df lower.CL upper.CL
保留 -0.1281 0.0441 3.42 -0.2592 0.00304
略微城市化 0.0316 0.0341 2.20 -0.1030 0.16632
非常城市化 0.0425 0.0350 2.43 -0.0852 0.17032

自由度方法：kenward-roger
使用的置信度：0.95

$contrasts
对比估计 SE df t.ratio p.value
保留 - 略带城市化 -0.1597 0.0558 2.83 -2.863 0.1324
保留 - 非常城市化 -0.1706 0.0563 2.95 -3.028 0.1123
略带城市化 - 非常城市化 -0.0109 0.0489 2.32 -0.223 0.9733

自由度方法：kenward-roger
P 值调整：用于比较 3 个估计值的 Tukey 方法`

请问，这是什么意思？预测变量如何显著，但水平没有差异？我有 151 条鱼，所以我的数据和观察值数量不是很低。如果我犯了拼写错误，我很抱歉，英语不是我的母语。]]></description>
      <guid>https://stats.stackexchange.com/questions/655810/if-the-categorical-variable-is-retained-in-my-final-model-in-r-then-why-does-th</guid>
      <pubDate>Tue, 15 Oct 2024 13:48:27 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法确定两种不同方法获得的测量结果之间是否存在统计上的显著差异？</title>
      <link>https://stats.stackexchange.com/questions/652884/is-there-a-way-to-determine-if-there-is-a-statistically-significant-difference-b</link>
      <description><![CDATA[我的情况如下。我有来自一个数据集的 259 个样本，每个样本都有一个通过两种不同方法计算得出的值。这两种方法都试图描述相同的现象，理想情况下，当方法 1 的测量值较高时，方法 2 的测量值也应该较高，相对于其他样本。然而，我感兴趣的是这种情况不成立的样本。我是否可以运行一个测试来找出两个测量值之间存在统计显著差异的样本（即，方法 1 的测量值较高而方法 2 的测量值较低的样本，反之亦然），或者这不是同类比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/652884/is-there-a-way-to-determine-if-there-is-a-statistically-significant-difference-b</guid>
      <pubDate>Thu, 15 Aug 2024 16:50:20 GMT</pubDate>
    </item>
    </channel>
</rss>