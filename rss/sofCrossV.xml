<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 06 Feb 2024 15:14:24 GMT</lastBuildDate>
    <item>
      <title>剂量反应项目的多级元回归与网络元分析的比较</title>
      <link>https://stats.stackexchange.com/questions/638671/comparing-multi-level-meta-regression-to-network-meta-analysis-for-dose-response</link>
      <description><![CDATA[我正在计划进行荟萃分析，以检查我的研究领域内连续变量随时间的平均变化。为了能够对这种连续关系进行元分析，我通常使用以下结构进行多级元回归，其中 yi = 研究中某个组内给定结果的标准化平均变化，vi = 抽样方差，时间 = 干预持续时间：
metafor::rma.mv(yi,vi,
mods=~时间，
随机 = 列表(~时间|学习,~1|组,~1|es.id),
结构=“GEN”，
方法＝“REML”
dfs =“包含”，
测试=“t”)%&gt;%
稳健（集群=研究，clubSandwich=TRUE）

从这里开始，我将探索评估各种互动主持人影响力的其他模型：
metafor::rma.mv(yi,vi,
mods= ~时间 * 主持人，
随机 = 列表(~时间 * 主持人|学习,~1|组,~1|es.id),
结构=“GEN”，
方法＝“REML”
dfs =“包含”，
测试=“t”)%&gt;%
稳健（集群=研究，clubSandwich=TRUE）

但是，有人向我提到剂量反应网络荟萃分析可能是更好的选择。坦率地说，我对这些方法并不是非常熟悉，但是从我收集到的 ，它们在每个“节点”处拟合剂量-反应关系。在网络中。对我来说，当你有明确分类的互动主持人时，这似乎适用，而我感兴趣的大部分内容都是连续的。
乐于听取经验丰富的用户对每种方法的优点/缺点，并指出我的任何误解。]]></description>
      <guid>https://stats.stackexchange.com/questions/638671/comparing-multi-level-meta-regression-to-network-meta-analysis-for-dose-response</guid>
      <pubDate>Tue, 06 Feb 2024 14:36:18 GMT</pubDate>
    </item>
    <item>
      <title>在实验中，如果将治疗应用于组内的某些人而不是其他人，则会破坏治疗效果</title>
      <link>https://stats.stackexchange.com/questions/638668/experiments-where-the-treatment-is-such-that-the-act-of-applying-the-treatment-t</link>
      <description><![CDATA[假设我们有一个实验，我们想要对某些群体进行某种治疗，以测试该治疗是否“有效”。但治疗是这样的，即对群体中的某些人而不是其他人进行治疗的行为实际上会破坏治疗；换句话说，为了使治疗“正常”/“完全有效”，治疗必须适用于整个群体。在实验设计的世界里，这种现象被称为什么？在我看来，这可能被认为是某种“互动”或依赖效应？是否有一个实验设计领域可以处理这类事情？在这种情况下，所谓的“观察性研究”或“观察性实验设计”是否比所谓的“对照试验”/“随机对照试验”之类的实验设计更合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/638668/experiments-where-the-treatment-is-such-that-the-act-of-applying-the-treatment-t</guid>
      <pubDate>Tue, 06 Feb 2024 13:42:49 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归和 Logit 离散选择模型之间有什么根本区别？</title>
      <link>https://stats.stackexchange.com/questions/638667/what-is-fundamentally-different-between-a-logistic-regression-and-a-logit-discre</link>
      <description><![CDATA[我试图理解两者之间的区别。我知道离散选择建模中有一个背景随机效用理论，但在我读到的内容中，我无法查明 logit 选择模型（有时称为条件 logit 选择模型，以区别于嵌套选择）之间的区别模型）。
也许这与似然方程有关，但我希望获得更多技术说明。]]></description>
      <guid>https://stats.stackexchange.com/questions/638667/what-is-fundamentally-different-between-a-logistic-regression-and-a-logit-discre</guid>
      <pubDate>Tue, 06 Feb 2024 13:14:26 GMT</pubDate>
    </item>
    <item>
      <title>通过计算 SE 差异来比较独立均值的比率 – 适用吗？</title>
      <link>https://stats.stackexchange.com/questions/638666/comparing-ratios-of-independent-means-by-calculating-se-difference-applicable</link>
      <description><![CDATA[我正在进行一项研究，比较三种治疗方法中平均发声次数与平均个体数的比率。对于每种处理，我有平均发声次数（基于 353 个样本）和平均个体数（基于 18 个样本）。由于时间分辨率不同（样本持续时间和重叠），我无法直接除以原始值（请参阅样本大小）。相反，我采用了“元分析方法”，并将比率值计算为平均发声除以平均个体。
现在，我想评估这些比率值在处理之间是否存在显着差异。我正在考虑的一种方法是使用用于生成除值的平均值的标准误差 (SE) 计算每个比率值的“SE 差异”。我发现了 Burns 和 Dobson (1981) 的公式，他们使用 SEdiff 来比较两个均值，而不是通过除以这些均值生成的比率。因此，我不确定这个指标是否适合我的分析。

我将不胜感激：

对使用 SE 差异评估处理之间比率值差异的有效性以及如何解释结果的评论。
计算置信区间 (CI) 或“伪 SE”指标以比较两个划分的独立均值的替代建议。”

一些数据：

Burns, R.B.、Dobson, C.B.，1981。平均值之间差异的标准误差，见：Burns, R.B.、Dobson, C.B.（编辑），实验心理学：研究方法和统计。施普林格荷兰，多德雷赫特，第 151–157 页。 https://doi.org/10.1007/978-94-011-7241- 7_15]]></description>
      <guid>https://stats.stackexchange.com/questions/638666/comparing-ratios-of-independent-means-by-calculating-se-difference-applicable</guid>
      <pubDate>Tue, 06 Feb 2024 12:54:26 GMT</pubDate>
    </item>
    <item>
      <title>了解变分推理和 EM 之间的关系</title>
      <link>https://stats.stackexchange.com/questions/638661/understanding-variational-inference-and-em-in-relation-to-each-other</link>
      <description><![CDATA[我已经阅读了一些答案，例如此处 但是，不知怎的，我仍然有一些疑问。我希望提出我的理解并提出几个问题来消除我的疑虑
EM：

最大化算法
E-step - 找到使 ELBO 尽可能接近似然的分布（A 最大化）。原来这是后路。 这将与我们试图近似后验的变分推理形成对比。事实上，我认为这就是变分推理的动机。这种无法分析计算后验的情况。否则，我们就不需要变分推理
M-step - 在假设的参数空间中最大化 ELBO $P(X|Z)$（也是最大化）

注意事项：

这里的 $P(X)$ 正在发生变化，因为我们正在 $P( X|Z)$。 这将与 $P(X)$ 不变的变化推断形成对比

变分推理：

在 EM 中，我们做出简化的建模假设，允许计算 $P(X)$，从而 $ P(Z|X)$ 使用贝叶斯定理计算。简化假设，例如数据是根据 10 个正态分布 (GMM) 生成的。如果我们不做出这些简化假设，那么贝叶斯定理中的分母就无法计算，因此我们无法计算后验。现在将使用变分推理来近似后验。
（问题 1）：我是否正确地声称，在更复杂的场景中需要变分推理，而 EM 适用于 GMM 等简单模型。事实上，这两种算法可以与变分推理相辅相成，从而可以将 EM 应用到更复杂的场景，其中我们在 E 步骤中使用变分推理来近似后验，然后应用 M 步骤
我的理解是否正确：在变分推理中，似然性被假设为常数，而在 EM 中，似然性正在发生变化？
]]></description>
      <guid>https://stats.stackexchange.com/questions/638661/understanding-variational-inference-and-em-in-relation-to-each-other</guid>
      <pubDate>Tue, 06 Feb 2024 12:33:07 GMT</pubDate>
    </item>
    <item>
      <title>用于具有随机效应但放宽比例赔率假设的序数数据建模的 R 包</title>
      <link>https://stats.stackexchange.com/questions/638660/r-package-for-ordinal-data-modeling-with-random-effects-but-with-relaxation-of</link>
      <description><![CDATA[寻求一个能够对序数数据进行建模的 R 包，包括随机效应（如 clmm），同时放宽比例优势假设。尽管 clmm 可以处理随机效应，但它不允许放宽比例优势假设。任何有关替代软件包的建议将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/638660/r-package-for-ordinal-data-modeling-with-random-effects-but-with-relaxation-of</guid>
      <pubDate>Tue, 06 Feb 2024 12:13:29 GMT</pubDate>
    </item>
    <item>
      <title>p 值 <0.05 Bonferroni 调整但相关描述性统计数据不支持差异</title>
      <link>https://stats.stackexchange.com/questions/638659/p-value-0-05-bonferroni-adjusted-but-associated-descriptive-statistics-not-supp</link>
      <description><![CDATA[我对 4 组参与者的李克特量表反应进行了 Kruskal Wallis 测试。
李克特量表由 5 种可能的回答组成。
这是我与英国物理治疗师进行的一个研究项目的结果。
结果示例如下：
Kruskal Wallis 总和等级检验显示各组之间存在统计显着性（第一组（处方物理治疗师 n = 79）；第二组（物理治疗师学生处方者 n = 12；第三组物理治疗师非处方者 n = 171；第四组学生物理治疗师 n = 35）。 Χ2(3，n=297)=8.992，ρ＜0.029
各组之间的成对比较揭示了以下关系
成对比较请指出您属于以下哪一项
样品 1-样品 2 测试统计 SE 标准。测试统计信号。调整。西加
PSP-物理处方者 5.846 25.240 .232 .817 1.000
PSP-生理 NP -35.558 24.328 -1.462 .144 .863
PSP-学生理疗 -36.533 27.252 -1.341 .180 1.000
理疗处方者-理疗 NP -29.712 11.082 -2.681 .007 .044
物理治疗师-学生物理治疗 -30.687 16.542 -1.855 .064 .381
物理 NP-学生物理 -.975 15.114 -.065 .949 1.000

每一行都检验样本 1 和样本 2 分布相同的原假设。
显示渐近显着性（双面检验）。显着性水平为 0.050。
A。显着性值已通过多项检验的 Bonferroni 校正进行了调整。
表 5.20 成对比较：训练期间的支持
表 5.20 显示了物理治疗师处方者和物理治疗师非处方者之间的统计学显着差异（ρ = 0.007。通过 Bonferroni 校正调整 ρ = 0.044）

对物理治疗师处方者和物理治疗师非处方者的描述性统计分别进行的调查显示，对于物理治疗师处方者，更多的物理治疗师相信他们会在培训期间获得支持，这一比例为 67.1%，而那些被认定为物理治疗师非处方者的比例为 55.2%。两组之间认为自己不会获得支持的比例相似：物理治疗师处方者为 11.4%，物理治疗师非处方者为 11.2%。
在这里，我积累了同意和强烈同意的选项，为物理治疗师处方者给出了 67.1% 的结果，并对那些报告说他们没有得到支持的人进行了同样的处理 - 不同意和强烈不同意的答复。
没有描述性统计数据支持的组之间如何存在显着差异。这是误报的例子吗？或者我误解了这里的统计数据 - 很有可能。
到目前为止，根据董事会的反馈，我得到的结果似乎具有统计意义，但并不重要。事实上，它并不是非常重要，反映了当前的文献，但可能表明需要进一步的工作，特别是 KW 测试强调的两组之间。感谢大家的宝贵反馈]]></description>
      <guid>https://stats.stackexchange.com/questions/638659/p-value-0-05-bonferroni-adjusted-but-associated-descriptive-statistics-not-supp</guid>
      <pubDate>Tue, 06 Feb 2024 11:06:41 GMT</pubDate>
    </item>
    <item>
      <title>具有固定时间效应的双重差分[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638658/difference-in-difference-with-fixed-time-effects</link>
      <description><![CDATA[我想评估部署功能的影响，但不确定我的理解是否正确。
设置如下：

我无法对个人进行随机分配。我一定要介绍一下“城市”这个功能。等级。城市数量有限。
我每天都会测量我的输出指标，并且可以运行大约一个月。历史数据可用。
存在“限时效果”。 X 天的输出指标可能与 Y 天不同。

我附上了每日测量值的示例图，以及每周聚合。
我做了一些研究，得出的结论是 DiD 测试适合此设置。我提出了以下模型：
$y_{it} = \mu + \sum_{t&#39;} \eta_{t&#39;} T_{t&#39;} + \alpha U_i + \tau D_{it} $
其中 i 是单位，t 是时间段，$T_t$ 是时间段虚拟值（1 if $ t=t&#39;$），$U_i$ 是单位虚拟（1 if $i=1$ ），$D_{it}$ 是治疗虚拟变量。
据我了解，运行该回归将通过 $\tau$ 为我提供 ATT。
我有以下问题：

模型合理/回归“正确”吗？或者我错过了什么？

如何才能最好地识别适合 A/B 测试的城市？运行“A/A”就足够了吗？对历史数据进行测试，看看哪一对城市我无法达到统计显着性？

我可能无法识别具有平行趋势的城市。使用合成对照是否“合理”？替代方案？

]]></description>
      <guid>https://stats.stackexchange.com/questions/638658/difference-in-difference-with-fixed-time-effects</guid>
      <pubDate>Tue, 06 Feb 2024 10:48:07 GMT</pubDate>
    </item>
    <item>
      <title>根据需求选择时间序列模型</title>
      <link>https://stats.stackexchange.com/questions/638657/time-series-model-selection-based-on-demand</link>
      <description><![CDATA[我正在办公室开展一个时间序列预测项目。
我们必须预测每个商店级别（无层次结构）对 10 种产品的需求。仅仅在商店层面就足够了。我们有20家商店。所以，我们总共有200个系列。我们有外生变量，如日、周、月、天气等作为该系列的输入变量
现在的问题是，每种产品在每个商店中可能表现出不同的需求模式。例如，商店 1 中的某些零件可能运行速度很快，而商店 3 中的相同零件可能运行速度较慢。
那么，我的问题是，如何根据时间序列数据选择模型？我应该根据我对需求的理解来预先配置模型吗？例如 - 随机森林、Croston（用于间歇性需求）、季节性天真（零星或无需求）等。
所以，唯一的方法是，即使我知道 croston 不是一个适合持续需求、高运行者的模型，代码仍然会通过该模型运行，从而浪费我们的时间和资源？
有没有使用Python的优雅的现有解决方案，它会根据对每个商店产品需求模式的理解来选择模型？
或者唯一的解决方案是预先配置模型列表？例如，假设我向模型字典提供 10 个模型名称，那么所有 200 系列都将针对所有 10 个模型进行测试？这是唯一的方法吗？

这里的时间序列专家通常如何有效地做到这一点？

您通常遵循什么项目方法来完成此类项目？

]]></description>
      <guid>https://stats.stackexchange.com/questions/638657/time-series-model-selection-based-on-demand</guid>
      <pubDate>Tue, 06 Feb 2024 10:47:46 GMT</pubDate>
    </item>
    <item>
      <title>对保留审查的比例/百分比进行建模</title>
      <link>https://stats.stackexchange.com/questions/638642/modelling-a-proportion-percentage-which-is-left-censored</link>
      <description><![CDATA[我正在研究组件磨损类型问题，其中因变量是原始壁厚的百分比。我在这些论坛上读到，假设我的数据集中没有 0% 损失或 100% 损失的示例，则使用 beta 回归对此数据有意义。
我还有一个额外的挑战，即我的壁厚检测器的下限是 10%。低于此值的值被写为零。因此，这将使我的数据也被左删失为 10%。
我能否获得一些有关数据建模策略的一般性建议，以考虑 10% 的左审查和允许的最大值 100%。]]></description>
      <guid>https://stats.stackexchange.com/questions/638642/modelling-a-proportion-percentage-which-is-left-censored</guid>
      <pubDate>Tue, 06 Feb 2024 03:54:59 GMT</pubDate>
    </item>
    <item>
      <title>相关性固定效应</title>
      <link>https://stats.stackexchange.com/questions/638629/correlations-fixed-effect</link>
      <description><![CDATA[我正在使用 lme4 包和 glmer 拟合广义混合线性模型。每次拟合模型时，我都会在模型开始拟合之前收到此错误消息：
固定效应模型矩阵存在秩缺陷，因此删除 1 列/系数

令人惊讶的是，哪个效果被丢弃的问题取决于公式中变量的顺序。如果我使用 y ~ a + b + c + a*b + a*c 那么，如果我这样做 y ~ a + ，a*c 就会被丢弃b + c + a*c + a*b，然后 a*b 被删除。然而，cor(a*c, a*b)=0.03，这与我对多重共线性的直觉相矛盾。所以我开始调查发生了什么事。
在调查过程中，我注意到以下内容。如果我使用 summary(model) 来查找固定效应的相关性，则相关性比我仅使用 cor(x) 计算相关矩阵时要高得多。&lt; /p&gt;
问题1：为什么这两个表不同？
Q2： summary(model) 仅显示未删除的变量。我可以重新创建包含已删除效果的表格吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638629/correlations-fixed-effect</guid>
      <pubDate>Mon, 05 Feb 2024 22:41:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 Excel 中创建 Q-Q 图需要调整 0.5？</title>
      <link>https://stats.stackexchange.com/questions/638611/why-does-creation-of-a-q-q-plot-in-excel-need-an-adjustment-by-0-5</link>
      <description><![CDATA[我知道不同的统计软件包提供Q-Q 图 使用代码或通过黑匣子。例如，Minitab 与 R 集成，用于 此处。
我正在尝试通过 Excel 对一列数据手动执行此操作，希望完全了解潜在的动态。 此处提供了一个示例。 （我相信作为一个大学相关的网站，作者提出的方法是合理的。）
本质上，数据按升序排序，并为每个数据点提供从 1 到 20 的排名（例如，如果有 20 个数据点）。然后，从排名中减去 0.5，然后除以数据点的数量（本例中为 20），以提供百分位，其相应的标准正态 z 变量通过normsinv 函数计算。
为什么要减去0.5？这是因为排名（离散且连续的整数）是由连续分布（正态）近似的，因此这种修正使其更正确？
如果进行 0.5 的校正使 Q-Q 图更加正确，是否有更好的最统计上正确/严格的方法从头开始构建 Q-Q 图，而不将其提供给统计包自动计算？生成 Q-Q 图的基本数学公式到底是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/638611/why-does-creation-of-a-q-q-plot-in-excel-need-an-adjustment-by-0-5</guid>
      <pubDate>Mon, 05 Feb 2024 17:23:19 GMT</pubDate>
    </item>
    <item>
      <title>简单与复合假设问题</title>
      <link>https://stats.stackexchange.com/questions/638609/simple-vs-composite-hypothesis-question</link>
      <description><![CDATA[我正在查看资格考试中的一个问题，其中正在拟合多重逻辑回归模型，其答案是关于死亡。
问题说存在年龄、性别、吸烟等多种潜在危险因素，必须同时控制。
评估吸烟统计显着性的问题之一。具体来说，我们必须显示原假设并判断这是否是一个简单假设。
所以，我知道对于原假设，吸烟的系数估计等于 0（吸烟在统计上不显着）。但我的答案是，这是一个复合假设。
我很困惑。我认为这是一个简单的假设，因为它测试它是否等于零。这是因为必须同时控制多个预测变量吗？
什么使它成为一个简单的假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/638609/simple-vs-composite-hypothesis-question</guid>
      <pubDate>Mon, 05 Feb 2024 17:01:52 GMT</pubDate>
    </item>
    <item>
      <title>MGCV 样条和低 EDF 的导数阶数</title>
      <link>https://stats.stackexchange.com/questions/638436/order-of-derivative-for-mgcv-splines-and-low-edf</link>
      <description><![CDATA[我正在跟进信息丰富的讨论这里涉及 MGCV 样条的 m（导数阶数）的选择。使用 MGCV 中的默认选项（薄板样条、用于优化的 REML、k=10 等），我注意到 m 的选择会影响估计的自由度，这并不奇怪。然而，当使用 m=1 时，这通常会导致 edf 接近于零。在线阅读（包括此处）我认为这可能会发生因为当使用 m=2（默认值）时，线性函数位于惩罚零空间中，因为惩罚基于函数的曲率（二阶导数），而线性函数没有曲率。我猜测当 m 更改为 1 时，这不再适用，因为现在线性函数将导致惩罚，但我承认我并不完全理解为什么。另外，回到前面关于 m 选择的讨论，在 edf 向零收缩的情况下选择 m=1 是否有意义？在这种情况下，样条曲线的解释是什么？最后，为什么与一阶导数相比，默认会惩罚二阶导数？]]></description>
      <guid>https://stats.stackexchange.com/questions/638436/order-of-derivative-for-mgcv-splines-and-low-edf</guid>
      <pubDate>Fri, 02 Feb 2024 22:05:36 GMT</pubDate>
    </item>
    <item>
      <title>关于非完全交叉重复测量设计的最佳随机效应结构的建议？</title>
      <link>https://stats.stackexchange.com/questions/638406/advice-on-optimal-random-effects-structure-for-not-fully-crossed-repeated-measur</link>
      <description><![CDATA[我有一项研究的设计似乎跨越了受试者内和受试者间的设计。我之前发布过此内容 这里，但在那个阶段我希望有一个简单的类似方差分析的解决方案。我开始认为这种模型不存在，并转向了多层次建模文献。如果我在这里找到解决方案，我也会发布原始问题的答案。
回顾一下，我的研究感兴趣的是人们对无家可归者的态度，特别是种族是否与无家可归者相互作用以增加耻辱感。为了研究这一点，参与者阅读了有关某人的小插曲，并进行了与耻辱相关的评级。我的自变量是插图中的角色是否有家（有家、无家可归）和种族（白人、黑人）。在一个完美的世界中，每个人都会收到所有四种结果条件（有家的白人、有家的黑人、无家可归的白人、无家可归的黑人）。但由于时间原因，每位参赛者只能领取两张。因此，每个参与者都会收到以下其中一项：
无家可归的黑 / 有家的白
无家可归的白 / 有家的黑
（两个小插图的顺序相互平衡，但这在这里并不重要 - 同样，由于设计限制，我们只能为每个黑/白字符使用一个名称，并且希望每个角色仅使用 1 个小插图有家和无家可归的情况）
这看起来像是 2 x 2 重复测量设计，因为每个参与者都会收到两个级别的无家可归和两个级别的种族，但事实并非如此，因为他们没有收到所有四个条件，而只有两个。
我的问题是，如果我们将其拟合为多级模型，使用以下随机效应结构是否合适（为方便起见，我使用类似 lme4 的表示法）：
&lt;块引用&gt;
耻辱〜家庭+种族+家庭：种族+（家庭+种族|
主题）

这将包括每个参与者的随机截距，以及主效应的随机斜率，但排除交互作用的随机斜率，因为我们缺乏足够的信息来探索受试者内的变异。我是否正确地认为这是数据允许的最大结构？
也欢迎任何其他建议或分析方法的替代建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/638406/advice-on-optimal-random-effects-structure-for-not-fully-crossed-repeated-measur</guid>
      <pubDate>Fri, 02 Feb 2024 15:15:56 GMT</pubDate>
    </item>
    </channel>
</rss>