<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 09 Nov 2024 06:21:10 GMT</lastBuildDate>
    <item>
      <title>当转换和聚类算法没有帮助时，如何对高度倾斜的 DALY 数据进行聚类？</title>
      <link>https://stats.stackexchange.com/questions/656983/how-to-cluster-highly-skewed-daly-data-when-transformations-and-clustering-algor</link>
      <description><![CDATA[我正在处理一个具有高度偏斜度的残疾调整生命年 (DALY) 值数据集，如下面的直方图所示，其中大多数值聚集在零附近，长尾向更高值延伸。我的目标是对这些数据进行聚类以获得见解，但尽管尝试了各种转换和聚类算法，结果仍然不令人满意。
我尝试了以下操作：
转换：对数、Box-Cox 和幂转换，但没有一个能有效地使分布标准化。
聚类算法：k-means、DBSCAN、HDBSCAN、K 原型和高斯混合模型 (GMM) 无法提供有意义的聚类。特别是 k-means 由于偏斜而苦苦挣扎，而 DBSCAN 经常将许多点标记为噪声。
鉴于这些挑战，是否有人对可以以允许有效聚类的方式处理这种偏斜数据的替代方法或方法提出建议？或者是否有特定的参数调整可以帮助这些方法更好地处理数据？
附加上下文：
数据集包含不同国家/地区的 DALY 值的高度可变性，即使在异常检测和过滤后也存在异常值。
我根据 DALY 和其他特征（6 个分类特征）进行聚类，例如 SDI（社会人口指数），这也显示出一定程度的偏差。
任何指导都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/656983/how-to-cluster-highly-skewed-daly-data-when-transformations-and-clustering-algor</guid>
      <pubDate>Sat, 09 Nov 2024 06:14:59 GMT</pubDate>
    </item>
    <item>
      <title>关于 Clayton Copula 的问题</title>
      <link>https://stats.stackexchange.com/questions/656982/question-on-clayton-copula</link>
      <description><![CDATA[Clayton Copula 定义为 $u=F_X(x)$ 和 $v=F_Y(y)$ 分布函数，例如两个连续 rv，
$$C_{\rm Clayton} = \Big[\max\{u^{-\theta} + v^{-\theta}-1;\,0\}\Big]^{-1/\theta},\quad \theta \in (-1,\infty) \backslash \{0\}.$$
$\max$ 中的 $0$ 值只能在 $\theta &lt;0$。
假设情况如此。那么对于 $[0,1]^2$ 的子集，Copula 也将取零值。很好，但是 Copula 的参数（两个分布函数）确实会在此子集中单独取值。
这是否意味着只有当我们想要反映两个 rv 在联合支持中的此值子集中联合实现的概率为零时，才使用具有 $\theta &lt;0$ 的 Clayton Copula？]]></description>
      <guid>https://stats.stackexchange.com/questions/656982/question-on-clayton-copula</guid>
      <pubDate>Sat, 09 Nov 2024 03:14:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么大型 GAMM 模型中的随机项会使曲线变得尖锐和弯曲？</title>
      <link>https://stats.stackexchange.com/questions/656978/why-does-a-random-term-in-a-large-gamm-model-make-the-curves-spiky-and-wiggly</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656978/why-does-a-random-term-in-a-large-gamm-model-make-the-curves-spiky-and-wiggly</guid>
      <pubDate>Fri, 08 Nov 2024 23:00:16 GMT</pubDate>
    </item>
    <item>
      <title>如何识别一系列马哈拉诺比斯距离的分布？</title>
      <link>https://stats.stackexchange.com/questions/656973/how-can-i-identify-the-distribution-of-a-series-of-mahalanobis-distances</link>
      <description><![CDATA[如果我的数据集服从多元 t 分布，样本外数据点的马哈拉诺比斯距离的 cdf 是多少？换句话说，如果我想使用数据点与分布均值的马哈拉诺比斯距离来计算数据点属于数据集分布的概率，我应该使用什么 cdf？
换句话说，我想知道某个 $\vec X$ 的 $d_M(\vec X, \vec \mu)$ 分布，该 $\vec X$ 服从多元 $t$ 分布，均值为 $\vec\mu$，其中 $d_M$ 是马哈拉诺比斯距离。]]></description>
      <guid>https://stats.stackexchange.com/questions/656973/how-can-i-identify-the-distribution-of-a-series-of-mahalanobis-distances</guid>
      <pubDate>Fri, 08 Nov 2024 20:53:45 GMT</pubDate>
    </item>
    <item>
      <title>MCMC 采样器给出明显不同的分布——哪个更好？</title>
      <link>https://stats.stackexchange.com/questions/656972/mcmc-samplers-give-noticeably-different-distributions-which-is-better</link>
      <description><![CDATA[背景
我们构建了两个 MCMC 采样器，用于对具有 4-20 多个参数的分层贝叶斯模型的后验进行采样。这两个采样器使用不同的方法。对于大多数数据集，它们给出的结果几乎相同（基于比较边际分布）。但是，我们遇到了一些数据集，结果明显不同——边际分布具有相同的基本形状，但根据采样器略有偏移。
问题
如何最好地展示哪个采样器生成的样本更接近后验？在任何给定点，比例后验似然都很容易计算。
一个想法
到目前为止，我有一个想法是拟合两个高斯混合——每个样本一个。然后将混合物视为重要性采样的提议分布，并计算每个样本的权重，就好像它来自提议分布一样。权重的方差将表明每个提议分布与后验的匹配程度（权重的方差越低，匹配程度就越高）。
这种方法有点复杂，但可行。不过，我很高兴能有一个更好的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/656972/mcmc-samplers-give-noticeably-different-distributions-which-is-better</guid>
      <pubDate>Fri, 08 Nov 2024 20:43:05 GMT</pubDate>
    </item>
    <item>
      <title>曲线拟合与参数推导</title>
      <link>https://stats.stackexchange.com/questions/656971/curve-fitting-and-parameter-derivation</link>
      <description><![CDATA[我正在尝试推导一组方程来模拟现实世界的情况：对一段时间内的支出进行分析，但我遇到了许多障碍（都是因为我缺乏专业知识）。一旦我有了合理的方法，我可能会使用 R，并且如果可能的话，我希望从这些数据中得出一些参数。我还需要验证我的理论模型是否准确，或者是否需要进一步修改。这个过程的主要目的是回答一个主要问题：6 个月后我将花费多少钱？
引发这个问题的部分原因是我的数据现在显示支出随着时间的推移减少（我的理论模型尚未考虑到这一点）。如果我绘制累计总数，然后尝试将曲线拟合到该总数，我会得到以下结果：

绘制残差清楚地显示了“分期付款”的影响。虽然我每天都在查看成本支出，但实际数字会以 1 个月甚至 2 个月的分期付款方式累积。到目前为止，我的方法是基于这样的假设：数字会随着时间的推移而平均化，只要我知道残差值相对于平均值的范围，我就可以说明我的预测的极限（一旦我开始考虑信心，但我还没有开始）。

问题

我最初尝试将数据拟合到二次曲线的假设可能是错误的，如第一幅图所示。这是因为直线的斜率永远不能为负。资金只能“单向”流动。使用 R，我将从以下方法开始：expenditure.quadratic = lm(scores ~ poly(time, 2, raw = TRUE))我的方程式是否可以调整以考虑到这一点？
残差图是否表明我迄今为止的方法是合理的？我得到的“锯齿”效应主要是因为现在只有极少数人订阅。另一项服务（人们已经转移到该服务）显示出更加随机的分布。
此时，我的理论模型可以根据订阅特定服务的人数、“平均每日费率”和人们加入服务的速率计算预期支出，由二次曲线$y = a\chi^2 + b\chi + c$给出，并且我知道$a, b,$和$c$的实际值。理想情况下，我想知道人们提前退出服务的比率，和/或人们使用服务的平均时间长度，和/或当服务处于“正常运行”状态时，退出服务的人数是否与使用该服务的总人数有关，或与个人订阅的时长有关（即，我们是否模拟每月 2% 的订阅者退出情况，这是否“更复杂”？）。

有关我如何尝试进行理论建模的更多背景信息，我在https://math.stackexchange.com/questions/4995809/derivation-of-cost-projection-formula上发布了一个单独的问题。 至关重要的是，我还没有考虑到我在本案中看到的情况，即支出率随着时间的推移而下降。
如有必要，我可以发布原始数据，但数据相当多。]]></description>
      <guid>https://stats.stackexchange.com/questions/656971/curve-fitting-and-parameter-derivation</guid>
      <pubDate>Fri, 08 Nov 2024 20:39:01 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中是否以及如何使用 Gamma 分布拟合 GAM</title>
      <link>https://stats.stackexchange.com/questions/656966/whether-and-how-to-fit-a-gam-with-a-gamma-distribution-in-r</link>
      <description><![CDATA[我想通过 mgcv 中的 gam() 函数和 Gamma 分布在 R 中使用海拔作为预测因子、化学浓度作为响应来拟合 GAM。但是，使用 gam(..., bs = &quot;cs&quot;, family = Gamma(link = &quot;log&quot;), method = &quot;REML&quot;, data = dat) 会导致在零处拟合出一条平坦的线
(图 1，ag2_p &lt;- predict_gam(ag_gam2) ag2_p %&gt;% ggplot(aes(elevation, fit)) + geom_smooth_ci()+ geom_point(data = dat, aes(y = alpha.guaiene, x =elevation))+ theme_classic())，而高斯分布（我认为不适合浓度数据）的结果看起来像一个合理的拟合（图 2，ag1_p1 &lt;- predict_gam(ag_gam1) ag1_p1 %&gt;% ggplot(aes(elevation, fit)) + geom_smooth_ci()+ geom_point(data = dat, aes(y = alpha.guaiene, x =elevation))+ theme_classic()).后者的脚本是 gam(..., bs = &quot;cs&quot;, family = gaussian(link = &quot;identity&quot;), method = &quot;REML&quot;, data = dat)
我怀疑问题可能出在绘图脚本而不是模型上，因为当我调用 plot(mod) 时，伽马模型看起来相当不错，如图 3 右侧所示（而高斯在左侧），但我不知道问题是什么。
我的问题是：
(1) 我对伽马分布使用的语法是否正确？
(2) 伽马分布是否确实更适合这些数据
(3) 如果 1 和 2 的答案是肯定的，为什么我得到的伽马模型拟合效果如此糟糕？


]]></description>
      <guid>https://stats.stackexchange.com/questions/656966/whether-and-how-to-fit-a-gam-with-a-gamma-distribution-in-r</guid>
      <pubDate>Fri, 08 Nov 2024 19:25:59 GMT</pubDate>
    </item>
    <item>
      <title>使用分类器预测作为具有受试者内数据的独立变量？</title>
      <link>https://stats.stackexchange.com/questions/656964/using-classifier-prediction-as-independent-variable-with-within-subjects-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656964/using-classifier-prediction-as-independent-variable-with-within-subjects-data</guid>
      <pubDate>Fri, 08 Nov 2024 17:05:16 GMT</pubDate>
    </item>
    <item>
      <title>R 中的嵌套方差分析产生警告消息“Error（）模型是奇异的”</title>
      <link>https://stats.stackexchange.com/questions/656958/nested-anova-in-r-produces-warning-message-error-model-is-singular</link>
      <description><![CDATA[我正在尝试理解嵌套方差分析，特别是使用 R 中的 aov() 函数，但我遇到了一些概念问题，我相信这也是因为互联网上的术语不一致。
作为数据集，我修改了来自此处的“dragons”数据集。除其他外，现在它包含一个数字响应变量（“testScore”）、一个（嵌套）“较低级别”因子变量（“Observer”，8 个级别）和固定的“较高级别”因子变量“Species”（4 个级别）。设计相当平衡，每个“Species”级别包含两个“Observer”级别：
&gt;表（dragons$Species，dragons$Observer）

Erika Hannah Judith Julia Marie Paul Tarek Till
Deathmist 0 0 0 0 0 0 55 63
Fire 0 69 0 56 0 0 0 0
Green 0 0 0 0 54 53 0 0
Thorntail 64 0 66 0 0 0 0 0

目的是测试预测变量“物种”的不同级别是否在响应变量“testScore”中有所不同，同时校正了嵌套因子“观察者”。
我的理解是，嵌套因子始终是一种随机效应（具体而言：较低“随机”因子中给定级别的样本始终只出现在固定“较高”因子的一个级别中，但固定因子级别有来自多个随机因子级别的样本）。但是，包括“嵌套因子”的方差分析有时在互联网上表示为 Y ~ A/B（具有固定因子 A 的主要影响及其与随机因子 B 的相互作用），术语为“因子 B 嵌套在固定因子 A 中”...
&gt; summary(aov(testScore~Species/Observer, data=dragons))
Df Sum Sq Mean Sq F value Pr(&gt;F) 
Species 3 12913 4304 13.30 2.38e-08 ***
Species:Observer 4 87969 21992 67.98 &lt; 2e-16 ***
Residuals 472 152704 324 

(这个结果似乎不对，因为物种在 testScore 中可能不会有差异)
...虽然有时它表示为 Y ~ A + Error(B/A)，术语切换为“固定因子 A 嵌套在随机因子 B 中” （再次参阅此处和此处的回复）...
&gt; summary(aov(testScore~Species+Error(Observer/Species), data=dragons))

错误：观察者
Df Sum Sq Mean Sq F 值 Pr(&gt;F)
物种 3 12913 4304 0.196 0.894
残差 4 87969 21992 

错误：在
Df Sum Sq Mean Sq F 值 Pr(&gt;F)
残差 472 152704 323.5 
警告消息：
在 aov(testScore ~ Species + Error(Observer/Species), data = dragons) 中：
Error() 模型是奇异的

后一个示例提供了我预期的测试结果，其中物种没有差异。但是，警告消息引起了我对给定数据集的模型有效性的担忧。此外，假设后一种方法是正确的，那么何时使用“Y ~ A/B”？
如果有人能帮助我解决我的困惑，并可能建议我警告消息可能暗示什么，我如何针对此数据集更正我的模型，或者数据必须是什么样子才能适用于此模型，我将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656958/nested-anova-in-r-produces-warning-message-error-model-is-singular</guid>
      <pubDate>Fri, 08 Nov 2024 10:44:32 GMT</pubDate>
    </item>
    <item>
      <title>如何确定固定数量的目标函数评估的最佳开发-探索权衡</title>
      <link>https://stats.stackexchange.com/questions/656939/how-to-determine-the-optimal-exploitation-exploration-trade-off-for-a-fixed-numb</link>
      <description><![CDATA[在贝叶斯优化中，我们通过查找$x = \textrm{argmax}_x \alpha(x)$来猜测下一个采样点，其中$\alpha(x)$是采集函数。为简单起见，我们考虑上限置信边界 (UCB) 采集函数：$\alpha(x)=\mu(x) + \sqrt\beta \sigma(x)$，其中$\mu(x)$是通常的平均值，$\sigma(x)$表示方差的通常平方根。这里，$\beta$ 当然是无量纲参数 ($\beta\geq0$)，用于调整探索 (高 $\beta$) 和利用 (低 $\beta$) 之间的权衡。
假设我有 $N$ 个目标函数评估的计算或实验预算。是否有将 $\beta$ 设置为 $N$ 函数的算法或启发式方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/656939/how-to-determine-the-optimal-exploitation-exploration-trade-off-for-a-fixed-numb</guid>
      <pubDate>Fri, 08 Nov 2024 08:21:54 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的条件推理树与随机森林如此不同？</title>
      <link>https://stats.stackexchange.com/questions/656938/why-is-my-conditional-inference-tree-so-different-from-my-random-forest</link>
      <description><![CDATA[我正在使用条件推理树和随机森林分析数据集，使用的是 R 包 partykit（v. 1.2.20）。对于我的因变量（响应可能性），树和森林产生的解决方案非常不同，这使得它们都很难解释。我该如何理解这里发生了什么？
下面是我的代码以及树和森林的图像。如有必要，我可以共享数据集。
set.seed(2356)
library(partykit)

&gt; head(s1_images_response_item[,-2])
# A tibble：6 × 14
# 组：item [6]
item category response_mean_img causation colourful familiarity grow intent
&lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 飞机 移动臂… 1 3.25 2.57 4.4 1 1.29
2 藻类 植物 趣味… 0.887 2.44 3.57 2.1 4.14 1.06
3 羚羊 动物 0.981 4.25 2.79 3.85 4.77 3.53
4 自行车 移动臂… 1 2.12 2.64 4.65 1.05 1.12
5 船 移动臂… 0.981 3.19 2.64 3.65 1 1 
6 巨石 不动… 0.943 1.88 1.5 3 1.45 1.18
# ℹ 6 个其他变量：交互 &lt;dbl&gt;、运动 &lt;dbl&gt;、自然&lt;dbl&gt;,
# 感知 &lt;dbl&gt;, 重现 &lt;dbl&gt;, 提示 &lt;chr&gt;

条件推理树：
tree1.i.h &lt;- ctree(response_mean_img ~ 因果关系 + 意图 + 
交互 + 运动 + 感知 + 熟悉度 + 自然 + 
生长 + 重现 + 多彩, data=s1_images_response_item)

plot(tree1.i.h, terminal_panel = node_boxplot(tree1.i.h,id=T),
inner_panel = node_inner(tree1.i.h,id=F, pval = F), 
edge_panel = edge_simple(tree1.i.h, digits = 2))

--&gt;熟悉度是唯一重要的预测因素：

随机森林：
f1.i.h &lt;- cforest(response_mean_img ~ causation + intent + 
interaction + movement + perception + familiarity + natural + 
grow + reproduce + colourful, data=s1_images_response_item, 
ntree = 1000)

f1.i.h.varimp &lt;- varimp(f1.i.h)

dotchart(sort(f1.i.h.varimp,decreasing = F), 
main = &quot;研究 1B 试验变量的条件重要性响应性”）

--&gt; 预测因子交互、再现、感知和因果关系都具有比熟悉度更高的条件重要性值：

为什么交互、再现、感知和因果关系都没有出现在树中？]]></description>
      <guid>https://stats.stackexchange.com/questions/656938/why-is-my-conditional-inference-tree-so-different-from-my-random-forest</guid>
      <pubDate>Fri, 08 Nov 2024 02:26:03 GMT</pubDate>
    </item>
    <item>
      <title>R 中的卡方检验困难</title>
      <link>https://stats.stackexchange.com/questions/656914/difficulties-with-chi-squared-test-in-r</link>
      <description><![CDATA[我尝试执行 3 个单独的卡方检验来确定 BMI 和 2 型糖尿病之间是否存在显著性。一个针对男性和女性，一个仅针对男性，一个仅针对女性。但是，当我尝试运行代码时，我得到了非常大的 X 平方值和 n/a 的 df 值。
EMLabData 表
代码：
combined &lt;- table(EMLabData$BMI, EMLabData$T2D)
men &lt;- table(EMLabData$BMI[EMLabData$Sex==&quot;Male&quot;], 
EMLabData$T2D[EMLabData$Sex==&quot;Male&quot;])
women &lt;- table(EMLabData$BMI[EMLabData$Sex==&quot;Female&quot;], 
EMLabData$T2D[EMLabData$Sex==&quot;Female&quot;])

chisq.test(combined, mock.p.value = TRUE)
chisq.test(men, mock.p.value = TRUE)
chisq.test(women, mock.p.value = TRUE)

输出：
数据：combined
X-squared = 1423.4, df = NA, p-value = 0.0004998

数据：men
X-squared = 727.94, df = NA, p-value = 0.04798

数据：女性
X 平方 = 1.2297，df = NA，p 值 = 1

我不确定出了什么问题以及如何解决。如能得到任何帮助我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/656914/difficulties-with-chi-squared-test-in-r</guid>
      <pubDate>Thu, 07 Nov 2024 16:09:45 GMT</pubDate>
    </item>
    <item>
      <title>结合多年复杂调查数据的横断面分析</title>
      <link>https://stats.stackexchange.com/questions/656652/cross-sectional-analysis-combining-multiple-years-of-complex-survey-data</link>
      <description><![CDATA[许多大型健康调查，例如欧洲健康、老龄化和退休调查，都具有纵向复杂的调查设计，并且有多年的数据收集能力。我知道可以使用多年堆叠的复杂调查设计对象进行纵向比较，如以下博客文章中所述（即 https://www.r-bloggers.com/2015/11/statistically-significant-trends-with-multiple-years-of-complex-survey-data/），其中提供了此 R 代码作为示例：
# 构建复杂样本调查设计对象
# 堆叠多年并在嵌套层中考虑“年份”
des &lt;- 
svydesign(
id = ~psu , 
strata = ~interaction( stratum , year ),
data = y , 
weights = ~weight , 
nest = TRUE
)

但是，我很好奇是否可以将相同的方法应用于横断面研究问题。以下问题：
问题 1) 一般。一般而言，当研究人员有兴趣研究多年期小组调查中的横断面关联时，构建多年期堆叠复杂调查设计对象是否是一种好的做法？我还没有看到任何论文这样做，但它不会增加统计能力并避免遗漏可用数据吗？
问题 2）聚类。我假设参数 id = ~psu 足以调整同一参与者可以包含在多个年份的事实（前提是他们在每个年份都有相同的 psu 值）。
问题 3）权重。我假设每波的横截面抽样权重可以简单地除以包含的波数以保留正确的总数，如下所述：合并多年调查数据 - 调整调查权重。
问题 4）分层。交互参数是否为 strata = ~interaction( stratum , year ) 如果使用数据进行横断面关联也合适吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656652/cross-sectional-analysis-combining-multiple-years-of-complex-survey-data</guid>
      <pubDate>Sat, 02 Nov 2024 21:02:16 GMT</pubDate>
    </item>
    <item>
      <title>针对元分析，应选择哪个估计量^REML 还是使用 Wild Bootstrap 的 CR2？</title>
      <link>https://stats.stackexchange.com/questions/656000/which-estimator-to-choose-for-meta-analysis-reml-or-cr2-with-wild-bootstrap</link>
      <description><![CDATA[我正在关注以下书籍：https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/multilevel-ma.html
我无法选择要使用哪个估计器：REML 还是带有 Wild Bootstrap 的 CR2。
或者也许同时运行它们并呈现为敏感性分析，尽管我看不到任何其他元分析这样做，所以也许这会进一步使文章的读者感到困惑。
一些细节：
我的样本量很小（两者都可以帮助）
和依赖效应大小（CR2 最适合它）
我的结果是一个连续变量（REML 似乎更适合）
如果您有类似的问题，您能否建议您做了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/656000/which-estimator-to-choose-for-meta-analysis-reml-or-cr2-with-wild-bootstrap</guid>
      <pubDate>Sat, 19 Oct 2024 12:01:22 GMT</pubDate>
    </item>
    <item>
      <title>SLOPE 与 Benjamini-Hochberg 程序之间的联系</title>
      <link>https://stats.stackexchange.com/questions/652379/the-link-between-slope-and-the-benjamini-hochberg-procedure</link>
      <description><![CDATA[假设我们正在执行 $m$ 测试，该测试生成 $m$ 个 p 值 $p_1 \leq \ldots \leq p_m$（按索引排序）。 BH 程序如下：

对于给定的 $\alpha$（所需的 FDR 水平），找到最大的 $k$，使得 $p_k \leq \frac{k}{m}\alpha$。
对所有 $i\leq k$，拒绝零假设 $H_i$。

现在，我已经阅读了一些关于基于此的 Sorted L-One Penalized Estimation (SLOPE) 模型，但我很难看出确切的联系。在 SLOPE 论文 中，BH 程序描述如下（并且该公式用于推导 SLOPE 惩罚序列）：
对于回归模型 $y = X\beta + z,$，其中 $z \sim N(0,\sigma^2)$ 和正交矩阵 $X^TX = I$，将 $\tilde{y} = X^Ty$ 的条目排序为 $|y|_{(1)} \geq \ldots \geq |y|_{(m)}$ 和拒绝所有假设 $H_i$ 其中 $i\leq k_\text{BH}$ 其中
$$k_\text{BH} = \max\left\{k:
\frac{|\tilde{y}|_{(k)}}{\sigma} \geq \Phi^{(-1)}\left(1-\frac{k\alpha}{2m}\right)\right\}.$$
现在，我想知道这两者之间有什么联系以及分位数是如何使用的。我猜这与我们在 SLOPE 中使用 $\tilde{y}$ 而不是 p 值有关，我们需要以某种方式将其转换为与 p 值比较相同的比例。]]></description>
      <guid>https://stats.stackexchange.com/questions/652379/the-link-between-slope-and-the-benjamini-hochberg-procedure</guid>
      <pubDate>Tue, 06 Aug 2024 12:44:45 GMT</pubDate>
    </item>
    </channel>
</rss>