<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 29 Jan 2024 06:17:22 GMT</lastBuildDate>
    <item>
      <title>我应该对我的数据使用哪种统计检验？</title>
      <link>https://stats.stackexchange.com/questions/637979/which-statistical-test-should-i-use-for-my-data</link>
      <description><![CDATA[我正在分析一些数据，这些数据是人工智能算法的输出，这些数据经过人工验证过程，要么接受要么拒绝预测。我需要确定人类决策与每个预测相关的分数相关，例如，接受预测分数较高的预测的可能性是否高于预测分数较低的预测的可能性？
我的方法是查看接受和拒绝的分数，并通过 Mann Whitney U 测试运行它们，以检查分布是否相等。这是一个有效的方法吗？还有其他推荐吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637979/which-statistical-test-should-i-use-for-my-data</guid>
      <pubDate>Mon, 29 Jan 2024 05:25:55 GMT</pubDate>
    </item>
    <item>
      <title>mstl 用于频率未知的多频率时间序列</title>
      <link>https://stats.stackexchange.com/questions/637978/mstl-for-multiple-frequency-time-series-where-the-frequencies-are-unknown</link>
      <description><![CDATA[我创建了 2 个数据，第一个数据在 5 个术语中重复，第二个在 15 个术语中重复。然后将它们相加并使用默认设置转换为 ts。
库（预测）
x0=c(3, 5.8, 6, 6.2, 2)
x1=代表(x0,24)
x2=rep(c(1,5,8,10,10,20,20,22,20,20,10,10,8,5,1),8)
x3=x1+x2
x4=ts(x3,开始=1901)

尝试使用 plot(stl(x4,s.window=&#39;periodic&#39;)) 但收到以下错误消息：
stl(x4, s.window = “periodic”) 中的错误：
  系列不是周期性的或周期少于两个

Tyr mstl by plot(mstl(x4))，但似乎没有检测到季节性并产生：

尝试使用tsp(x4)和Frequency(x4)检查频率。两者都给出输出=1。
但是 findFrequency(x4) 给出输出=15。
看来 stl 和 mstl 是根据 ts() 中的 Frequency= 设置来工作的&gt; 或 msts 本身中的 seasonal.periods=，即频率是在我们创建 ts 或 msts&lt; 时预先确定的/代码&gt;.
如果我有一个多频率时间序列，但不知道频率是什么，我希望该函数能够检测它们，然后进行 mstl 分解，该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/637978/mstl-for-multiple-frequency-time-series-where-the-frequencies-are-unknown</guid>
      <pubDate>Mon, 29 Jan 2024 04:56:23 GMT</pubDate>
    </item>
    <item>
      <title>可能性和概率</title>
      <link>https://stats.stackexchange.com/questions/637977/likelihood-and-probability</link>
      <description><![CDATA[据我了解，概率是固定分布下的区域，可以用数学方式表达给定分布的数据概率：$$P(Data|Distribution)$$
而可能性是具有可移动分布的固定数据点的 y 轴值。所以，从数学上来说
$$L(分布|数据)$$
如果上述情况成立，那么当我试图找到指数分布的可能性时为什么是： $$P(X_{1},X_{2},\cdots X_{ n}|\lambda)=P(X_{1}|\lambda)\cdot P(X_{2}|\lambda)\cdots P(X_{n}|\lambda)$$
因此，这意味着给出的是分布，而不是我之前定义的可能性数据。我觉得我对可能性有一个愚蠢的误解。]]></description>
      <guid>https://stats.stackexchange.com/questions/637977/likelihood-and-probability</guid>
      <pubDate>Mon, 29 Jan 2024 03:11:17 GMT</pubDate>
    </item>
    <item>
      <title>Z 分数和拟似然之间的联系？</title>
      <link>https://stats.stackexchange.com/questions/637975/connection-between-z-score-and-quasi-likelihood</link>
      <description><![CDATA[考虑拟似然函数（我在 GEE 上下文中编写它）：
$$ Q(\beta; y) = \sum_{i=1}^{n} (y_i - \mu_i(\beta))^T V_i^{- 1}(\beta, \alpha) (y_i - \mu_i(\beta))$$
地点：

$y_i$ 是第 $i$ 个主题的响应，
$\mu_i(\beta)$ 是 $i$ 的平均响应主题，
$V_i(\beta, \alpha)$ 是 $i$ 的方差函数-第一个主题，
$\beta$ 是固定效果参数，
$\alpha$ 是色散参数。

查看拟似然，我可以看到与 Z 分数（矩阵形式）非常相似的东西：随机变量减去随机变量的期望值除以方差。
这让我想知道 - 拟似然和 Z 分数之间是否存在任何关系？也许拟似然的动机确切形式被选择为相似？这是否与中心极限定理有关 - 即拟似然是渐近正态的，因为它是归一化随机变量的总和？ （我试图自己证明这一点，并将在另一个问题中展示我的工作）]]></description>
      <guid>https://stats.stackexchange.com/questions/637975/connection-between-z-score-and-quasi-likelihood</guid>
      <pubDate>Mon, 29 Jan 2024 00:17:38 GMT</pubDate>
    </item>
    <item>
      <title>如果 OLS 估计器使 MSE 最小化，那么 James-Stein 估计器如何实现更低的 MSE？</title>
      <link>https://stats.stackexchange.com/questions/637973/if-ols-estimator-minimizes-mse-how-does-james-stein-estimator-achieve-a-lower-m</link>
      <description><![CDATA[OLS 估计器解决了以下最小化问题：
$\min ||y-X\beta||^2$
通过采用 FOC，我们获得 $\hat{\beta}$，它最小化了目标函数。
但是 James-Stein 估计器的 MSE 较低。我知道 James-Stein 的证明，但如何将其与 OLS 估计中平方误差损失已最小化这一事实相协调？我在这里缺少什么？
如果 James-Stein 估计器实现了较低的 MSE，为什么我们仍然使用 OLS？虽然 James-Stein 要求分布是正态的，但是根据中心极限定理的某些版本可以满足近似正态性，它不是仍然有用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637973/if-ols-estimator-minimizes-mse-how-does-james-stein-estimator-achieve-a-lower-m</guid>
      <pubDate>Sun, 28 Jan 2024 23:22:26 GMT</pubDate>
    </item>
    <item>
      <title>减去 Wilcoxon 秩和中的理想秩均值，它有什么作用</title>
      <link>https://stats.stackexchange.com/questions/637961/subtracting-the-ideal-rank-mean-in-wilcoxon-rank-sum-what-does-it-do</link>
      <description><![CDATA[我正在阅读 Andy Field 的《使用 R 发现统计》。在关于如何计算 MWU 中的排名统计量的部分中，步骤之一是从排名总和中减去平均排名。
W = 等级总和 - 平均等级
这个想法是，它可以纠正群组中的人数。
但是我们减去的不是总排名的真实平均值，而是理想平均值（有 10 个观测值，总和为 [1+2+...+10]，而实际排名为 1 ,2,3.5,....12，因为关系。
当我们通常从样本中删除均值时，是为了创建居中。这个程序在这种情况下起什么作用？我不是一个数学素养很高的人，所以对正在发生的事情有一些直观的了解会很有帮助
谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/637961/subtracting-the-ideal-rank-mean-in-wilcoxon-rank-sum-what-does-it-do</guid>
      <pubDate>Sun, 28 Jan 2024 18:48:21 GMT</pubDate>
    </item>
    <item>
      <title>数据/观察本身如何有助于我们确定假设是真是假的能力？</title>
      <link>https://stats.stackexchange.com/questions/637955/how-do-data-observations-themselves-contribute-to-our-ability-to-make-determinat</link>
      <description><![CDATA[假设我有一个假设，并且我正在尝试确定该假设是真是假。如果我没记错的话，在统计中，标准的哲学观点是，从技术上讲，我们无法确定假设是真是假，而是证据（数据）是否无法反驳该假设。但是数据/观察本身如何有助于我们做出此类决定的能力呢？特别是，所有创建的数据都是平等的，还是有些数据的贡献不同/具有优越的“解释力”？天真地思考这一点，在我看来，“独立”的数据/观察结果似乎是“独立的”。彼此之间具有较低的相关性，或者彼此之间具有较低的相关性，将具有更强的“解释力”。 /“信号” /“贡献”进行我们的分析/确定假设是真是假？但是，在我的统计推断研究中，我不记得以这种方式讨论/处理数据点/观察结果的事情。这个想法有什么道理吗，还是我错了？如果这个想法有道理，我可以使用哪些好的资源（教科书）来深入研究这个问题？
&lt;小时/&gt;
编辑
我想这个想法也可以被认为是多么“经济”。数据是。因此，举例来说，如果数据是独立的，我就能够使用较少的数据执行一定程度的假设检验，但如果数据是独立的，则要达到相同的准确性水平，则需要更多的数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/637955/how-do-data-observations-themselves-contribute-to-our-ability-to-make-determinat</guid>
      <pubDate>Sun, 28 Jan 2024 17:28:55 GMT</pubDate>
    </item>
    <item>
      <title>随机化有什么魔力？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637953/whats-the-magic-of-randomization</link>
      <description><![CDATA[我读到可以执行 A/B 测试和测试考虑到总体被随机抽样并分配给 A 和 A 的效果大小推断B组。您只需对 B 组进行治疗，并且由于治疗暴露而导致的提升为 B。
听起来好得令人难以置信？我想是的。
假设您有一些具有 100 个随机化单元的总体。您随机选择 50 名作为治疗组。 “100选50”是 10^29 种可能的 A/B 分割；无论您获得哪一组，分割都是“随机”的。并且适合推理（我觉得非常可疑。）
一些变量是连续的，而另一些变量是分类的。对于分类变量，可以进行分层；例如，将 100 个随机化单位的总体划分为全男性和全女性的同质亚群体，随机分配给 A 或 B，然后聚合。 （A-男 &amp; A-女 -&gt; A。）
假设总人口中男性（或女性）的数量为偶数，则可以确保每个性别在 A 组和 A 组中的代表性均等。 B. 这确保了性别与治疗暴露正交，而不是混淆。如果男性的数量是奇数，你会接近正交（足够接近？我不确定。）事实上，在实验后回归模型中，人们可以以性别及其与治疗暴露的相互作用为条件来学习甚至更多 - 万岁！
这个过程可以对所有分类变量重复递归。但不明显的是连续变量的分层。我见过将此类变量分解为分位数（例如：0-10%，...，90-100%），然后处理这些基于分位数的子总体，然后执行与分类变量详细说明相同的过程。
无论如何，对我来说，随机化似乎并不是“这些人群尽可能相似”的可靠机制。因为这将是一个优化问题，而不是一个洗牌问题。
如果我们正在研究的任何指标存在任何不平衡，那么普通 T 检验就不合适。有一些方法可以适应实验前的均值差异，例如差异差异 (DiD)。但这种方法假设了平行趋势假设，这也不能通过洗牌来保证。
从哲学上讲，我认为随机化被过度炒作，因为替代优化问题的计算量太大。
如果有人能够为为什么 A/B 均值不平衡的随机化是可以接受的提供适当的辩护，我非常有兴趣了解更多信息。
编辑：哇这篇文章收到的赞成票和反对票的数量！甚至是近距离的请求……我没有预见到这个问题对于某些学术界来说会有多么两极分化/政治性。]]></description>
      <guid>https://stats.stackexchange.com/questions/637953/whats-the-magic-of-randomization</guid>
      <pubDate>Sun, 28 Jan 2024 17:01:57 GMT</pubDate>
    </item>
    <item>
      <title>对于具有前测-后测和两个因素的序数因变量，应使用哪种检验？</title>
      <link>https://stats.stackexchange.com/questions/637923/which-test-should-be-used-for-an-ordinal-dependent-variable-with-pretest-posttes</link>
      <description><![CDATA[考虑一个测试前-测试后设计，其中因变量 (y) 通过 3 个序数值 1、2、3 进行测量。还有两个因素：一个因素（例如A）由对照组和实验组组成。另一个因素（例如B）由两个年龄组组成。总样本量为 60，其中因素 A 和 B 组的每种可能组合都有 15 个受试者（总共可能的组合为 4，因此 4*15=60） 。现在我们要测试以下情况：

A 对 y 的影响，
A 和 B 对 y 的影响。

如果y连续服从正态分布，我们可以使用协方差或ANCOVA分析（第一种情况使用单向ANCOVA，第二种情况使用双向ANCOVA）。但这里的 y 不是正规变量，也不能转换为正规变量，因为它只有 3 个序数值。那么您建议对这两种情况进行什么统计测试？
如果您能在 y 是二分变量的情况下回答这个问题，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/637923/which-test-should-be-used-for-an-ordinal-dependent-variable-with-pretest-posttes</guid>
      <pubDate>Sun, 28 Jan 2024 08:13:39 GMT</pubDate>
    </item>
    <item>
      <title>假阳性率二项式过程的标准误是多少</title>
      <link>https://stats.stackexchange.com/questions/637916/what-is-the-standard-error-of-a-binomial-process-with-a-false-positive-rate</link>
      <description><![CDATA[我有一个肯定很常见的问题，但是经过搜索，我找不到解释。假设我们希望估计患有某种疾病的人数百分比 p。我们测试n个人。该测试已知TP 和FP 的真阳性率和假阳性率。预期阳性测试数量为 $E[Y]=TPp+FP(1-p)$。求解 p，p 的估计值为 $$p = \frac{(y/n)-FP}{TP -FP}$$ 我们如何计算p估计中的误差？总体抽样存在不确定性/误差（n 个样本的二项分布和概率 p），以及测试的真阳性和假阳性带来的额外不确定性/误差正率，也是二项式分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/637916/what-is-the-standard-error-of-a-binomial-process-with-a-false-positive-rate</guid>
      <pubDate>Sun, 28 Jan 2024 02:11:18 GMT</pubDate>
    </item>
    <item>
      <title>coxph 函数在我的模拟案例中给出了奇怪的风险比</title>
      <link>https://stats.stackexchange.com/questions/637910/coxph-function-gave-a-weird-hazard-ratio-in-my-simulation-case</link>
      <description><![CDATA[我适合三个 Cox 型号。三个风险比分别为 0.52、1.02 和 0.514。第一个风险比是治疗组和对照组之间的风险比。第二个是控制臂和外部控制臂之间的风险比。这里，1.02 表示控制臂比外部控制臂差。第三个风险比是将控制臂和外部控制臂集中在一起时的风险比。由于控制臂比外部控制臂更差，因此在我们将这两种治疗方法合并在一起后，第三个风险比应该大于第一个。然而，coxph函数却给出了违反直觉的答案。有谁知道原因吗？非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637910/coxph-function-gave-a-weird-hazard-ratio-in-my-simulation-case</guid>
      <pubDate>Sat, 27 Jan 2024 23:06:06 GMT</pubDate>
    </item>
    <item>
      <title>特定组线性变换模型的仿真：Cox</title>
      <link>https://stats.stackexchange.com/questions/637905/simulation-of-group-specific-linear-transformation-models-cox</link>
      <description><![CDATA[在我读过的一篇文章中，他们进行了一项模拟研究：
在此模拟中，我们从以下内容生成 $T_i$
特定组的线性变换模型： $$H(T_i) = \beta_{k,1}
 X_{i,1} + \beta_{k,2} X_{i,2} + \varepsilon_i, i = 1, 2, \ldots,
n; \quad k = 1, 2 $$ 其中 $ H(t) = \log\left(2(e^{4t} - 1)\right)$&lt; /span&gt; 和 $\varepsilon_i $ 遵循标准极值
分配。在这种情况下，线性变换模型是
相当于 Cox 比例风险模型。我们生成样本
来自混合的二元 Cox 比例风险模型
权重 $ \pi_1 = \frac{1}{3}$，$\pi_2 = \frac{2}{3 }$ 和 $ \beta_1
= (-3, -2)^T$, $\beta_2 = (1, 1)^T$。协变量 $X_i$ 由均值为零和一阶自回归结构的多元正态分布生成 $ \ Sigma = (\sigma_{st})$ 与 $ \sigma_{st} = 0.5^{|s - t|}$ 对于 $ s, t = 1, 2$。审查时间是根据 $[0, C]$ 上的均匀分布生成的，
其中选择 $C$ 来实现 $5\%$ 和 $25\%$。
所以，我在这里编写了 R 代码，我想确保我正确生成了 $T_i$ 。
 # 定义变换函数及其逆函数
  H &lt;- 函数(t) log(2 * (exp(4 * t) - 1))
  H_inverse &lt;- 函数(y) (1/4) * log((exp(y)/2) + 1)
  
  # 模型参数
  pi1 &lt;- 1/3； pi2 &lt;- 2/3;n=1000
  beta1 &lt;-c(-3,-2); beta2 &lt;- c(1, 1)
  
  
  # 协变量生成
  西格玛 &lt;- 矩阵(c(1, 0.5, 0.5, 1), ncol = 2)
  X &lt;- MASS::mvrnorm(n, mu = c(0, 0), Sigma)
  
  # 分组分配和生存时间模拟
  组 &lt;- ifelse(runif(n) &lt; pi1, 1, 2)
  epsilon &lt;- extRemes::revd(n,loc=0,scale=1,shape=0) # 标准极值分布

  H_Ti &lt;- 数字(n)
  for (i in 1:n) {
     if (组[i] == 1) {
     H_Ti[i] &lt;- beta1 %*% X[i,] + epsilon[i]
   } 别的 {
     H_Ti[i] &lt;- beta2 %*% X[i,] + epsilon[i]
  }}
  

  T &lt;- H_inverse(H_Ti) # 应用逆变换
  # 应用审查
  C &lt;- runif(n, min = 0, max = c)
  观察到的_T &lt;- pmin(T, C)
  delta &lt;- as.numeric(T &lt;= C)
]]></description>
      <guid>https://stats.stackexchange.com/questions/637905/simulation-of-group-specific-linear-transformation-models-cox</guid>
      <pubDate>Sat, 27 Jan 2024 22:26:09 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器中的非线性 PCA 与编码器</title>
      <link>https://stats.stackexchange.com/questions/637889/nonlinear-pca-vs-encoder-in-autoencoders</link>
      <description><![CDATA[我发现编码器比 PCA 更有优势，因为它们可以转换线性和非线性数据。然而，非线性 PCA 不是为处理非线性数据而设计的吗？那么，为什么我们仍然倾向于使用编码器而不是非线性 PCA？]]></description>
      <guid>https://stats.stackexchange.com/questions/637889/nonlinear-pca-vs-encoder-in-autoencoders</guid>
      <pubDate>Sat, 27 Jan 2024 15:39:05 GMT</pubDate>
    </item>
    <item>
      <title>事件研究使治疗效果显着</title>
      <link>https://stats.stackexchange.com/questions/637572/event-study-renders-treatment-effect-significant</link>
      <description><![CDATA[目前，我正在使用犯罪小组数据（数年的县级数据）来调查警察存在对犯罪的影响。我使用“外源性”每年增加一天的警察存在，以解释内生性偏差，并应用双向固定效应模型来解释未观察到的异质性（县固定效应，以及年、月和周固定效应）。因此，我的主要回归表述为：
$$
C_{ct} = \beta_1 Police_{ct} + 𝜑_c +𝜇年 + 𝜋月 +𝜌日 + \beta_2 X_{ct} + \epsilon_{ct}。
$$
治疗指示符“警察”如果在 $t$ 天，县 $c$ 的警力增加，则等于 1，则等于 0否则。使用相互作用的固定效应运行此回归得到的结果在统计上不显着（p 值 ~ 0.06）。请参阅第一个表（括号中的标准错误）。
但是，当我检查平行趋势假设并包括 5 个滞后和 4 个领先时，处理“警察”将变为“警察”。具有统计显着性（p 值 ~ 0.04）。请参阅第二个表（括号中的标准错误）。


有没有人遇到过类似的问题，可以帮我解决一下吗？
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/637572/event-study-renders-treatment-effect-significant</guid>
      <pubDate>Tue, 23 Jan 2024 17:18:31 GMT</pubDate>
    </item>
    <item>
      <title>Bing 藏语错误表情符号问题</title>
      <link>https://stats.stackexchange.com/questions/637505/the-bing-tibetan-glitch-emoji-problem</link>
      <description><![CDATA[这是一个非常有趣的数理统计难题，是我在使用 Bing 时偶然发现的。事实证明这个问题太深了，我花了相当长的时间思考如何解决它！尽管背景故事相对有趣，但看起来这可能是一个非常普遍（众所周知？）的统计问题。
请原谅我的篇幅，但我认为背景故事很有趣，值得分享:)
谜题：Bing 的新 AI 语言模型有一个非常奇特的错误。如果您向它发送一个来自未知“故障表情符号”列表中的单个表情符号，它会随机用藏语回复。例如，这是它对 🥲 的响应：

目标是描述引起此响应的所有表情符号的特征。由于表情符号有 3782 个，因此每个表情符号发送一条消息需要几个小时。
但有趣的是。如果您向 Bing 发送的消息仅包含有此“故障”的表情符号，财产，它会用西藏的废话来回应。但是，即使您发送一个没有表情符号的表情符号，它也会正常响应。这是两者的示例，其中 🥲🫥🤥🤫🤠 是故障表情符号，而 😊 不是：

因此，可以“批量测试”表情符号，并可能减少表征该集合所需的消息数量。大批量的风险更大，因为如果你足够幸运，选择了所有故障表情符号，你会立即获得大量信息，但如果没有，你除了至少有一个表情符号不是故障表情符号之外，一无所知。 
问题：用最少的消息来描述整套故障表情符号的最佳策略是什么？
为了简单起见，以下是我们可以做出的数学假设：

所有表情符号都同样可能是故障表情符号。
对于哪些表情符号是故障标记、哪些不是故障标记，没有特定的模式。
各种表情符号的故障/非故障状态在条件上都是相互独立的。
特别是，如果我们知道某些表情符号是或不是故障表情符号，我们假设这与概率无关，例如相邻的故障表情符号或任何其他表情符号。
我们可以访问一个黑盒函数，该函数将表情符号的一些子集作为输入，并且当且仅当每个表情符号都是故障表情符号时才返回 TRUE。

那么问题实际上是：如果你作为一个坚定的常客/贝叶斯/无论如何，被要求解决这个问题，并在尽可能少的查询中，在一些可证明最优的问题（相对到您认为“最佳”的任何内容）您会如何处理？
在我看来，“最佳”可能有多种概念。贝叶斯主义者和频率主义者对此可能有不同的看法。一个人可以尝试查看发送的消息数量的预期值；另一个可能会查看似然函数等。所以，我将其保留。我将在下面发布我的部分解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/637505/the-bing-tibetan-glitch-emoji-problem</guid>
      <pubDate>Tue, 23 Jan 2024 01:23:09 GMT</pubDate>
    </item>
    </channel>
</rss>