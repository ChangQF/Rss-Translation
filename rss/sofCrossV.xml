<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 05 Mar 2024 21:13:01 GMT</lastBuildDate>
    <item>
      <title>重复事件的生存分析：“生命线”中的“聚类”方法和 Andersen-Gill 方法有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/641917/survival-analysis-with-recurrent-events-what-is-the-difference-between-the-clu</link>
      <description><![CDATA[下午好，
我想更好地了解 lifelines Python 包中的 cluster 方法与 Andersen-Gill 方法有何不同。根据每个方法的定义（见下文），聚类方法似乎比 Andersen-Gill 方法更保守，因为前者不将重复事件视为独立的。我是否正确地思考了这些差异？
根据生命线文档（链接):
&lt;块引用&gt;
数据集可能具有的另一个属性是相关主题组。这可能是由于：

单个个体出现多次，因此在数据集中多次出现。
具有某些共同属性的主题，例如同一家庭的成员或倾向得分匹配的对象。


&lt;块引用&gt;
我们将这些分组的主题称为“集群”，并假设它们是由 DataFrame 中的某些列指定的（下面的示例）。使用聚类时，模型的点估计不会改变，但标准误差会增加。

相比之下，对于 Andersen-Gill 方法（链接):
&lt;块引用&gt;
Andersen-Gill 模型假设所有观察到的事件时间之间是独立的，无论这些事件时间对应于同一患者还是不同患者。

任何帮助、见解或建议将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/641917/survival-analysis-with-recurrent-events-what-is-the-difference-between-the-clu</guid>
      <pubDate>Tue, 05 Mar 2024 20:18:20 GMT</pubDate>
    </item>
    <item>
      <title>SPSS主成分分析缺失数据</title>
      <link>https://stats.stackexchange.com/questions/641916/principal-components-analysis-missing-data-spss</link>
      <description><![CDATA[我有一个大数据集（27k），有 63 个感兴趣的变量。我尝试将 PCA 作为降维策略。这些项目根据不同的指标进行评分，范围从二分变量到具有 7 个响应选择的变量。还有很多数据缺失。当我尝试运行 PCA（在 SPSS 中）时，我收到一条错误消息。我尝试过标准化分数以及按列表和成对删除缺失的案例，但仍然收到错误消息。我究竟做错了什么？请指教。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/641916/principal-components-analysis-missing-data-spss</guid>
      <pubDate>Tue, 05 Mar 2024 19:49:26 GMT</pubDate>
    </item>
    <item>
      <title>给定两个正态分布变量及其相关性，如何计算条件值？</title>
      <link>https://stats.stackexchange.com/questions/641914/how-to-calculate-a-conditional-value-given-two-normally-distributed-variables-an</link>
      <description><![CDATA[假设我们有两个变量：身高和体重。每个都服从正态分布，并且它们是相关的。假设特定示例的相关性为 0.75。
给定一个特定的高度，我们可以以平均值和标准差的形式估计体重吗？还是信息不够？]]></description>
      <guid>https://stats.stackexchange.com/questions/641914/how-to-calculate-a-conditional-value-given-two-normally-distributed-variables-an</guid>
      <pubDate>Tue, 05 Mar 2024 19:12:18 GMT</pubDate>
    </item>
    <item>
      <title>重叠类的支持向量分类器</title>
      <link>https://stats.stackexchange.com/questions/641912/support-vector-classifiers-for-overlapping-classes</link>
      <description><![CDATA[我目前正在研究支持向量分类器（SVC），更具体地说，是在《统计学习的要素》一书的帮助下研究拉格朗日（沃尔夫）对偶函数的解决方案。作者：Trevor Hastie、Robert Tibshirani 和 Jerome Friedman。据说，从 Karush-Kuhn-Tucker (KKT) 条件，我们可以推断，对于位于边缘边缘的支持向量 $x_i$，相应的拉格朗日乘数 $\alpha_i$ 位于 $0 $0 $\alpha_i$ \alpha_i &lt; C$，其中 $C$ 是拉格朗日原始函数中的成本参数。
考虑到 KKT 条件


我们如何推断支持向量$\alpha_i \neq C$ $x_i$在边距边缘？
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/641912/support-vector-classifiers-for-overlapping-classes</guid>
      <pubDate>Tue, 05 Mar 2024 18:11:22 GMT</pubDate>
    </item>
    <item>
      <title>A/A 测试中的高功率，解释？</title>
      <link>https://stats.stackexchange.com/questions/641911/high-power-in-a-a-test-interpretation</link>
      <description><![CDATA[随机化已经执行，并且已经分配了两组，其中治疗观察和对照观察分别由 df1、df2 捕获。
注意：尚未进行治疗暴露。
尽管存在重尾分布，但随机化似乎做得很好，但由于样本量大和中心极限定理，这也许没问题？
治疗：mu=420，std=178.77，n=2001
对照：mu=418，std=169.07，n=1999

根据我的研究，似乎在 t 测试中上下文，我需要按合并标准差缩放的均值差。但因为我还没有进行治疗，所以这是一个 A/A 测试！
from statsmodels.stats.power import tt_solve_power
def 功率（df1、df2、公制）：
    arr1 = df1[指标].to_list()
    arr2 = df2[metric].to_list()
    
    n1 = 长度（arr1）
    n2 = len(arr2)
    n = n1+n2
    
    mu1 = np.mean(arr1)
    mu2 = np.mean(arr2)
    
    s1 = np.std(arr1)
    s2 = np.std(arr2)
    
    pooled_sd = (s1**2/n1 + s2**2/n2)**(0.5)
    差异 = (mu1-mu2)/pooled_sd
    
    功率 = tt_solve_power(
        效果大小=差异，
        诺布=n，
        阿尔法=0.95，
        功率=无，
        替代=&#39;双面&#39;
    ）
    返回电源

当我运行此分析时，我发现 diff 等于 0.45，并且我的功效为 100%。这告诉我（诚然是一个新手），就科恩距离而言，我的 A/A 效应大小与 0 相差 0.45 个标准差……不太好！而我的力量如此之高，这似乎是对随机化过程的控诉。
我在这里做错了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/641911/high-power-in-a-a-test-interpretation</guid>
      <pubDate>Tue, 05 Mar 2024 17:56:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 Jeffreys 先验的后验分布</title>
      <link>https://stats.stackexchange.com/questions/641910/posterior-distribution-using-jeffreys-prior</link>
      <description><![CDATA[我试图证明如果 $X_1, \cdots, X_n \stackrel{iid}{\sim} N(\mu, \sigma^2)$ 与未知的 $\mu$、$\sigma$ 和之前的 $\pi(\mu, \sigma^2) \propto 1/\sigma^2$ 则 $\mu$ 的后验分布span&gt; 由 $$\frac{\sqrt{n} (\mu - \bar{x})}{s_{n-1}} \sim t_{n- 给出1} $$
其中 $\bar{x} = \frac{1}{n} \sum x_i$ 是样本平均值，$ s_{n-1} = \frac{1}{n-1} \sum (x_i - \bar{x})^2$ 是样本方差。我知道 $\sum (x_i - \bar{x})^2 \sim \chi^2_{n-1}$ 通过标准结果。因此，要表明 $$\frac{\sqrt{n} (\mu - \bar{x})}{s_{n-1}} \sim t_{n-1 } ,$$
我只需要分子为 $N(0, 1)$ 但我不太确定如何。我注意到 $$\pi(\mu, \sigma^2|\mathbf{x}) \propto (\sigma^2)^{-(1 + n/2) } \text{exp} \left( \frac{-1}{2\sigma^2} \sum (x_i - \mu)^2 \right) $$
但我被困在这里了。有人可以从这里给我建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/641910/posterior-distribution-using-jeffreys-prior</guid>
      <pubDate>Tue, 05 Mar 2024 17:51:15 GMT</pubDate>
    </item>
    <item>
      <title>分布模型和回归模型之间的区别</title>
      <link>https://stats.stackexchange.com/questions/641905/difference-between-a-distribution-model-and-a-regression-model</link>
      <description><![CDATA[请帮助我了解与随机性相关的分布模型和回归模型之间的区别]]></description>
      <guid>https://stats.stackexchange.com/questions/641905/difference-between-a-distribution-model-and-a-regression-model</guid>
      <pubDate>Tue, 05 Mar 2024 16:18:38 GMT</pubDate>
    </item>
    <item>
      <title>对同一时间序列数据使用双样本K-S检验</title>
      <link>https://stats.stackexchange.com/questions/641903/using-two-sample-k-s-test-for-the-same-time-series-data</link>
      <description><![CDATA[我有时间序列数据，它记录了神经元在某些刺激之前和之后的神经活动（我知道引入刺激的具体时间）。我正在考虑对刺激前后的神经信号强度分布使用双样本 K-S 检验来检查它们之间是否存在统计上的显着差异，这意味着该神经元对刺激做出了反应。
我是统计学新手，我不确定这些数据是否会违反 K-S 检验的一些假设。我读过 K-S 测试假设被比较的两个分布是独立的，这是否意味着比较来自同一神经元的信号分布会打破这个假设，因为刺激后的活动可能依赖于刺激前的活动？该数据是否可能违反 K-S 检验的任何其他假设？如果是这样，我可以对数据进行任何预处理吗？或者是否有其他更适合的统计测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/641903/using-two-sample-k-s-test-for-the-same-time-series-data</guid>
      <pubDate>Tue, 05 Mar 2024 15:31:07 GMT</pubDate>
    </item>
    <item>
      <title>确定变量选择过程的最佳模型</title>
      <link>https://stats.stackexchange.com/questions/641898/determine-best-model-for-variable-selection-process</link>
      <description><![CDATA[当我们进行变量选择时，理论上我们会为每个选定的变量子集拟合一个模型。然后我们可以比较所有模型并选择最好的。
有各种统计数据可以帮助选择最佳模型，例如贝叶斯信息准则、调整后的 R2。
我的问题是，为什么我们不能只使用 RSE 或 R2 作为模型准确性的统计数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/641898/determine-best-model-for-variable-selection-process</guid>
      <pubDate>Tue, 05 Mar 2024 15:14:44 GMT</pubDate>
    </item>
    <item>
      <title>作为一组线性变换的简单 ANN</title>
      <link>https://stats.stackexchange.com/questions/641885/simple-ann-as-a-set-of-linear-transformations</link>
      <description><![CDATA[我们无法使用隐藏层中的单个感知器对 XOR 问题的点进行分类。然而，我们可以通过在隐藏层使用两个感知器和在输出层使用一个感知器来实现这一点，而不使用激活函数。输入层由两个感知器组成。有一个隐藏层和一个输出层，有两个权重矩阵：第一个矩阵 $A$ 是 $2*2$ ，第二个矩阵$B$是$1*2$。让我们考虑 $A=[[1,1],[0,1]]$ 和 $B=[-2 ,2]$。在前向传播过程中，我们通过矩阵 $A$ 对 $X$ 向量进行线性变换，得到在 $R²$ 中的新向量中。然后这个新向量通过矩阵 $B$ 进行线性变换以产生输出。这意味着我们需要做的就是 $B(AX)$。这就是我的问题出现的地方：
经过研究，发现矩阵乘法是结合律的，即$B(AX)=(BA)X$，并且两个线性变换的组合是一个线性变换。 $A$ 和 $B$ 的组合会产生另一个矩阵，表示为 $K$，形状为 1x2。因此，$B(AX)=KX$。这里的关键是学习 $K$ ；最初，我们通过处理单独的线性变换来实现这一目标，但我们可以通过在隐藏层中仅选择一个感知器来让人工神经网络 (ANN) 一步完成此任务。然而，这种做法是不正确的。那么，我的问题出在哪里？！！”.]]></description>
      <guid>https://stats.stackexchange.com/questions/641885/simple-ann-as-a-set-of-linear-transformations</guid>
      <pubDate>Tue, 05 Mar 2024 12:40:55 GMT</pubDate>
    </item>
    <item>
      <title>我们如何解释矩阵变量正态分布中的协方差矩阵 $\textbf{U}$ 和 $\textbf{V}$？</title>
      <link>https://stats.stackexchange.com/questions/641849/how-do-we-interpret-the-covariance-matrices-textbfu-and-textbfv-in-the</link>
      <description><![CDATA[考虑矩阵正态分布。我的第一个问题是：我们如何解释随机矩阵 $\textbf{X}_{ij}$ 的条目  $\textbf{X}(n\times p)$？我的第二个问题是：我们如何解释所谓的协方差矩阵 $\textbf{U}$ 和 $\textbf{ V}$？最后，我的第三个问题是：我们如何计算矩阵 $\textbf{U}$ 和 $\textbf{V }$？
如有任何帮助，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/641849/how-do-we-interpret-the-covariance-matrices-textbfu-and-textbfv-in-the</guid>
      <pubDate>Tue, 05 Mar 2024 01:59:02 GMT</pubDate>
    </item>
    <item>
      <title>使用哪种预测评估指标？</title>
      <link>https://stats.stackexchange.com/questions/641798/which-forecast-evaluation-metric-to-use</link>
      <description><![CDATA[这是一个预测问题。我需要一个评估指标，它对预测不足的惩罚比对预测过度的惩罚更多。另外我希望它的范围在一定的区间内（比如0-100），以便更容易比较不同模型。可能的评估指标/解决方案是什么？
到目前为止，我已经尝试过 MSE、r2 分数、MAPE、WMAPE、AMAPE、SMAPE。]]></description>
      <guid>https://stats.stackexchange.com/questions/641798/which-forecast-evaluation-metric-to-use</guid>
      <pubDate>Mon, 04 Mar 2024 15:02:41 GMT</pubDate>
    </item>
    <item>
      <title>自举 t 统计量的近似误差阶</title>
      <link>https://stats.stackexchange.com/questions/641741/bootstrapping-t-statistics-order-of-approximation-error</link>
      <description><![CDATA[考虑引导 $t$-统计：$T_n = T(X_1,...,X_n) = \sqrt{n-1}\frac{\bar{X} - \mu}{\hat{\sigma}}$ 用于 iid 观测 $(X_1,. ..X_n)$，其中 $\bar{X} = \frac{1}{n}\sum_{i=1}^{n}X_i$&lt; /span&gt; 和 $\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^{n} (X_i - \bar{X })^2$..
现在，我从中心极限定理知道 $P(T_n \leq x) \xrightarrow[n \rightarrow \infty]{} \Phi(x)$，对于 $\Phi(x)$ 标准正态 cdf。
对于每个引导程序重新采样，假设不是使 $n$ iid 从经验分布中进行替换，而是只进行 $m = n/2$ iid 从经验分布中进行替换。
我想知道引导近似误差的顺序是 $n$ （例如 $O( n^{-2})$) 用于以下内容：$| P(T_n \leq x \mid F_0) - P(T_n^* \leq x \mid F_1)|$。
也许我的符号不清楚，但我表示 $T_n$ 的引导版本，由 $T_n^{* }$，由 $T_n^{*} = T(X_1^*,...,X_m^*) = \sqrt{m-1 给出}\frac{\bar{X}^* - \bar{X}}{\hat{\sigma}^*}$，其中 $(X_1^* ,...,X_m^*)$ 是 $m = n/2$ iid 从经验分布中得出，$F_1$，它将概率 $\frac{1}{n}$ 放在每个观测值 $X_1,...X_n$。设 $\bar{X}^* = \frac{1}{m}\sum_{i=1}^{m}X_i^*$，另外让 $\hat{\sigma}^{*2} = \frac{1}{m}\sum_{i=1}^{m}(X_i^* - \bar {X}^*)^2$。
有人可以帮助我理解如何计算出上述近似误差的顺序吗？ $| P(T_n \leq x \mid F_0) - P(T_n^* \leq x \mid F_1)|$。同样，这与 $| 相比如何？ P(T_n \leq x \mid F_0) - \Phi(x)|$？我的想法是埃奇沃斯展开在这里会有所帮助。我的想法是收敛速度不会改变，误差也不会改变。]]></description>
      <guid>https://stats.stackexchange.com/questions/641741/bootstrapping-t-statistics-order-of-approximation-error</guid>
      <pubDate>Sun, 03 Mar 2024 20:01:49 GMT</pubDate>
    </item>
    <item>
      <title>R pwr 包对于极小样本量 (<10) 的有效性</title>
      <link>https://stats.stackexchange.com/questions/641707/validity-of-r-pwr-package-for-extremely-small-sample-sizes-10</link>
      <description><![CDATA[编辑：这个问题不是：

关于编程
关于事后功效分析（至少不是为了在事后分析中使用样本统计数据 - 我有很好的总体估计值，我想向人们展示如何使用这些数据）

这个问题是关于：

正确使用科学界广泛使用的常用工具。
在此（或任何其他）工具中检查假设和近似值，包括默认的假设和近似值。

因此，我相信结束这个问题（甚至没有提供任何提示
在哪里以及如何得到答案）实际上伤害了这个社区，
通过传达这样的信息：这些检查是多余的，而它们
确实应该放在优先事项列表的首位。
我希望这个请求能够得到重新审理。
———————————-
pwr 包是否使用 Cohen 1988 中描述的小样本近似（例如 1 样本 t 检验中的自由度）来实现？我似乎在文档中找不到这个。
如果是这样，对于非常小的样本量功效计算是否有更好的选择？
感谢您的回复。
————————
可选阅读：我的问题的动机：
在工作（制造操作）中，我们发现很难重现测试结果。对我来说，很明显这是因为我们进行的研究动力严重不足。我的老板同意我应该解决一些问题。
我想计算我们使用的一些典型实验“设计”的功效。
R中的pwr包看起来非常方便。该小插图引用了 Cohen 的书：行为科学的统计功效分析 (1988)。不同的应用领域应该有相同的数学，但我还是决定看看这本书。
我注意到书中的一些近似值，当“小样本量”意味着 &gt; 时，这些近似值是有效的。 30. 对我来说，“非常大的样本量”有时意味着 10。我现在注意到 1 样本 t 检验和配对 t 检验的近似值：书中提到它没有具有正确自由度的表格。这导致 n &gt; 的差异非常小。 30，但我怀疑该近似值对于 n &lt; 30 可能无效。 10. 我想检查一下。这就是我的问题。
————————-
编辑：其中一条评论要求引用，这是合理的。
我引用 Cohen, J. (1988) 的话。行为科学的统计功效分析（第二版），如 pwr 包中引用。
这里有两个例子，科恩提到了近似值的使用：
第 42 页脚注 1 中有关样本量不等的 t 检验的一个不太严重的示例：“这是因为该表将 n 的 t 检验视为基于 df = 2n&#39; - 2，而实际上有 df=nA +nB - 2，较大的值。”
第 46 页，关于单样本 t 检验有一个更严重的例子：
“功效表的计算基础是 n 是两个样本中每个样本的大小，因此 t 检验将基于 2(n-1) 个自由度。在单样本情况下，t 必然仅基于 n - 1 个自由度。”并且：“除非样本量很小（比如小于 25 或 30），否则低估自由度的影响可以忽略不计。”
请注意，我同意这种分析和近似。然而，在我的情况下，我可能会误入歧途，因为我违反了其中一个条件。将错误的东西改成同样错误的东西并不是一种改进，所以我想避免这种情况。
对于现代计算机，不再需要这些近似值 - 但我无法在文档中找到 R 包是否是用近似值编写的。
我知道我们应该做什么，但是获得大于 20 的样本量对我们来说极其罕见。话又说回来，我们可以修改我们的实验以获得比科恩认为的“大”更大的效应量。我只需要向人们解释/激励我们应该这样做。要达到这一点需要付出努力。]]></description>
      <guid>https://stats.stackexchange.com/questions/641707/validity-of-r-pwr-package-for-extremely-small-sample-sizes-10</guid>
      <pubDate>Sun, 03 Mar 2024 10:35:10 GMT</pubDate>
    </item>
    <item>
      <title>机器学习每个类别的最佳观察计数是多少？</title>
      <link>https://stats.stackexchange.com/questions/641697/whats-the-optimal-observation-count-per-category-for-machine-learning</link>
      <description><![CDATA[我正在寻求一些有关分类变量中每个类别所需的最佳观察数量的建议或参考，特别是对于机器学习项目。举个例子，考虑标记为“颜色”的列，其包含三个类别：红色、绿色和蓝色。我遇到过一条一般规则，建议每个类别至少有 20 个观察值，这意味着我需要至少 20 个绿色、红色或蓝色的观察值（行）。然而，我有兴趣更深入地探讨这个话题，并且很想听听社区对此事的意见。是否有任何研究、文献或研究结果可以提供更全面的指导或验证这一经验法则？关于数据集中的红色、绿色和蓝色等类别理想需要多少条目或行的任何见解或建议阅读都将受到高度重视。预先感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/641697/whats-the-optimal-observation-count-per-category-for-machine-learning</guid>
      <pubDate>Sun, 03 Mar 2024 01:33:53 GMT</pubDate>
    </item>
    </channel>
</rss>