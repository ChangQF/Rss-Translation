<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 01 May 2024 06:20:48 GMT</lastBuildDate>
    <item>
      <title>如何将带有 copula 的 ARMA-MGARCH 与数据拟合</title>
      <link>https://stats.stackexchange.com/questions/646264/how-to-fit-an-arma-mgarch-with-a-copula-to-data</link>
      <description><![CDATA[我知道 R 包，但我试图了解将多元模型拟合到多个股票收益的过程。
假设我们有 3 只股票的回报，我们相信它们具有依赖性，尤其是在尾部。我们决定使用 MLE 将单变量 arma-garch 拟合到每个收益（我知道这个过程）。然后我们决定使用 t-copula 来找到它们的依赖关系。这个校准的过程是怎样的？我们是否应该将真实股票收益观察结果放入其 CDF 中以获得统一的观察结果？或者我们应该从拟合模型中生成新的观察结果，然后将它们放入 CDF 中？我们如何“校准”系词？
然后，我们如何使用 copula 和校准的单变量 arma-garch 模型来模拟观察结果？
此外，这与仅校准多元 arma-garch 模型（如 DCC）然后使用 copula 查找它们的依赖性有何不同。
所有在线信息都使用生成的合成数据，因此令人困惑的是真正的观察结果与生成的观察结果，或者只是使用 R 包。]]></description>
      <guid>https://stats.stackexchange.com/questions/646264/how-to-fit-an-arma-mgarch-with-a-copula-to-data</guid>
      <pubDate>Wed, 01 May 2024 02:23:41 GMT</pubDate>
    </item>
    <item>
      <title>随机变量的“坎坷”收敛[关闭]</title>
      <link>https://stats.stackexchange.com/questions/646261/bumpy-convergence-of-random-variables</link>
      <description><![CDATA[考虑序列$\left\{\dfrac{\sin(n)}{n}\right\}_{n = 1}^{\infty}$&lt; /span&gt;.
这收敛到零。然而，仅仅因为一个点位于零的 $\varepsilon$ 范围内，并不意味着每个后续点都在 $\ varepsilon$ 为零。例如， $\left\vert\dfrac{\sin(6)}{6}\right\vert &lt; \left\vert\dfrac{\sin(7)}{7}\right\vert$。 $n=6$ 处的序列比 $n=7$ 处的序列更接近于零。
这个数字没有上限。
当然，序列收敛到零，但是在序列中存在“颠簸”。一路上。这些颠簸变得越来越低，使得序列能够收敛，但在趋向于零的过程中存在颠簸。
也许这些颠簸可以通过序列 $
\左边\{
d\left(0, \dfrac{\sin(n)}{n}\right)
\right\}_{n = 1}^{\infty}
$ 不会单调减少到零（其中 $d$ 是某个度量，即 $\ mathbb R$ 在这种情况下），即使序列从点 $k&gt;1$ 开始，而不是点 $1$。
是否有类似“颠簸”的概念？存在于随机变量的收敛中，要么几乎肯定存在于概率中，要么存在于分布中？]]></description>
      <guid>https://stats.stackexchange.com/questions/646261/bumpy-convergence-of-random-variables</guid>
      <pubDate>Wed, 01 May 2024 00:56:16 GMT</pubDate>
    </item>
    <item>
      <title>变量选择策略</title>
      <link>https://stats.stackexchange.com/questions/646260/variable-selection-strategies</link>
      <description><![CDATA[我想在创建模型的背景下了解有关变量选择的当前最佳实践方法的更多信息。我对套索、引导计算变量包含频率等现代方法没有太多经验，并且一直对使用逐步选择方法感到内疚 - 主要是在预测环境中，但想改变这一点。通过阅读，我得到的总体感觉是，数据驱动的变量选择（有偏差的系数、小 SE/p 值等）引起的所有问题都是因为人们正在测试许多不同的模型而发生的。如果模型是预先指定的并且在评估后没有更改，这些不会是问题吗？
如果模型可以大致分为：

解释/因果 - 变量选择应仅由背景知识/理论驱动，并且最好得到有向非循环图的支持。该模型是预先指定的并且不会改变。您希望能够解释所得系数的“效果”。

预测 - 在这里您可以从许多潜在模型中选择一个，因为您只真正关心预测性能，而不关心单个系数。通常，由于这个原因，不会预先指定模型。因此，像套索这样的东西就可以了，因为它提供了一些变量选择元素以及优化预测性能（但我的理解是你不能轻易解释套索系数）。

描述性 - 包含 1. 和 2. 的元素 - 您对预测感兴趣，但也对系数“效果”的解释感兴趣。在这里您还可以从众多潜在模型中选择一种。我有兴趣知道在这种情况下进行变量选择的良好通用指南是什么？我找到的最接近的解决方案是计算引导包含频率并选择那些最常出现（达到某个阈值）的变量。或者这也不能否定问题吗？


任何提示将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/646260/variable-selection-strategies</guid>
      <pubDate>Wed, 01 May 2024 00:35:00 GMT</pubDate>
    </item>
    <item>
      <title>渐近无偏 + 渐近零方差 = 一致？</title>
      <link>https://stats.stackexchange.com/questions/646259/asymptotic-unbiasedness-asymptotic-zero-variance-consistent</link>
      <description><![CDATA[此处，Ben 表明无偏估计量 $\hat渐近方差为零的参数 $\theta$ 的 \theta$ 收敛于 $ 的概率\theta$。也就是说，$\hat\theta$ 是 $\theta$ 的一致估计量。
我们应该能够将条件放宽到渐近无偏性，这是有道理的：$\underset{n\rightarrow\infty}{\lim} \mathbb E\left[\hat\theta_n - \theta\right] = 0$。这似乎符合估计器接近真实参数值的精神......
...但是数学以前就让我感到惊讶。
我们可以将条件放宽到渐近无偏吗？证据是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/646259/asymptotic-unbiasedness-asymptotic-zero-variance-consistent</guid>
      <pubDate>Wed, 01 May 2024 00:32:23 GMT</pubDate>
    </item>
    <item>
      <title>如何理解实数（或其他无界集合）上的均匀分布？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/646258/how-to-make-sense-of-a-uniform-distribution-over-the-real-numbers-or-on-some-ot</link>
      <description><![CDATA[“选择一个随机实数，”看起来足够无害。但仔细想想，这似乎行不通。这样的 CDF 必须具有恒定的斜率，但又具有 $\underset{x\rightarrow -\infty}{\text{lim}} F_X(x)= 0$ 和 $\underset{x\rightarrow +\infty}{\text{lim}} F_X(x)= 1$。
每条斜线都不符合这些限制条件。
每条水平线至少不满足一个限制条件。
所以看起来 $U\left(-\infty, \infty\right)$ 是无意义的。同时，“选择一个随机实数”，看起来很基本。
能否将$U\left(-\infty, \infty\right)$变得形式化，也许通过一些测度论的技巧？]]></description>
      <guid>https://stats.stackexchange.com/questions/646258/how-to-make-sense-of-a-uniform-distribution-over-the-real-numbers-or-on-some-ot</guid>
      <pubDate>Wed, 01 May 2024 00:05:59 GMT</pubDate>
    </item>
    <item>
      <title>当样本比例不变且样本量增加时概率降低的直觉</title>
      <link>https://stats.stackexchange.com/questions/646256/intuition-behind-probability-decrease-when-sample-fraction-is-constant-and-sampl</link>
      <description><![CDATA[假设 $X \sim Binomial(n_1,p)$ 和 $Y \sim Binomial(n_2, p) $ 含义相同（可以直接比较），选择 $n_1 =16$ 和 $例如，n_2=64$。这些数字可以是任何保留以下内容的数字：
我们希望理论样本分数在 $X$ 和 $Y$ 之间保持恒定，让我们说$\frac{1}{8}$。
可以很容易地证明并证明 $P(X &gt; 2) &gt; P(Y &gt; 16)$ 以及 $P(X=2)&gt;P(Y=16)$ （注意恒定样本分数）。但凭直觉，为什么这是真的呢？
（请注意，我可能会将统计数据与纯概率混淆）
首先，我尝试考虑我们想要的观测数量和期望之间的距离，随着我们以绝对量级而非相对量级增加样本量，期望值会变得更大。
然后我想到了方差。 $\frac{Var(Y)}{Var(X)} = 4$ 这意味着理论数据的间隔更大，样本量更大。我认为 $X$ 的绝对大小低于 $Y$ 和 $X$ 更集中在中心，它比 $Y$ 获得更高的概率，但我不相信这一点.
我也试图想一个例子，它是高度近似的，因为它远非完美的二项式。假设您有一个 8 人家庭。其中 1 人感染新冠病毒的概率感觉高于 80 亿人中的 10 亿人。
如果你们能帮助我直观地理解这一点，我会非常高兴。]]></description>
      <guid>https://stats.stackexchange.com/questions/646256/intuition-behind-probability-decrease-when-sample-fraction-is-constant-and-sampl</guid>
      <pubDate>Tue, 30 Apr 2024 23:20:17 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn 中的average_ precision_score 指标如何用于非概率预测分数</title>
      <link>https://stats.stackexchange.com/questions/646252/how-does-average-precision-score-metric-in-scikit-learn-work-for-non-probability</link>
      <description><![CDATA[Scikit-learn 有一个 AP 指标函数此处
y_score（预测）的描述如下：- 目标分数，可以是正类的概率估计、置信度值或决策的非阈值度量
因此 y_score 的简单概率分数的情况很容易理解，如下所示。
y_true = np.array([0, 0, 1, 1])
y_scores = np.array([0.1, 0.4, 0.35, 0.8])
平均精度分数（y_true，y_scores）

其值为 0.83
但不清楚的是如何处理像下面这样的非概率值
y_true = np.array([1, 0, 0, 1])
y_scores = np.array([3.4, 12.1, 8.35, 0.8])
平均精度分数（y_true，y_scores）

AP值为0.416。在计算指标之前这些值是否转换为某种概率值？
然后，当我们使用负值作为分数时，y_scores = np.array([-3.4, -12.1, -8.35, -0.8]) 然后给出 AP 值为 1.0
与正值相比，为什么使用负值会改变 AP 指标。]]></description>
      <guid>https://stats.stackexchange.com/questions/646252/how-does-average-precision-score-metric-in-scikit-learn-work-for-non-probability</guid>
      <pubDate>Tue, 30 Apr 2024 22:13:32 GMT</pubDate>
    </item>
    <item>
      <title>自变量使用什么时间窗口？</title>
      <link>https://stats.stackexchange.com/questions/646248/what-time-window-to-use-for-independent-variables</link>
      <description><![CDATA[我在不同日期有 10000 个列表。我的 y 变量是上市前 7 天发生的亏损交易的百分比 &gt; 0 是 30% 或更多，然后 1 则为 0。现在，在上市之前也可能发生损失。当我在列出之前为决策树选取 x 变量时，它可能与损失日期重叠。这可以接受吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646248/what-time-window-to-use-for-independent-variables</guid>
      <pubDate>Tue, 30 Apr 2024 21:25:08 GMT</pubDate>
    </item>
    <item>
      <title>如何描述 glm 泊松回归模型的 emmeans p 值</title>
      <link>https://stats.stackexchange.com/questions/646246/how-to-describe-emmeans-p-value-for-a-glm-poisson-regression-model</link>
      <description><![CDATA[描述计算泊松回归中特定预测变量的 p 值（通过 emmeans 对函数计算）的统计检验的正确术语是什么？
即
emmeans(~ glm(formula = ...), family=poisson) %&gt;%
     对 -&gt;产生 p 值。

用于计算这些的统计测试是什么？
另外：默认情况下测试是双面还是单面？]]></description>
      <guid>https://stats.stackexchange.com/questions/646246/how-to-describe-emmeans-p-value-for-a-glm-poisson-regression-model</guid>
      <pubDate>Tue, 30 Apr 2024 21:13:52 GMT</pubDate>
    </item>
    <item>
      <title>统计证据和样本量背景下的第二代 P 值</title>
      <link>https://stats.stackexchange.com/questions/646241/second-generation-p-values-in-the-context-of-statistical-evidence-and-sample-siz</link>
      <description><![CDATA[我目前正在研究统计分析，并且遇到了 Blume 等人提出的第二代 P 值 (SGPV) 的概念。我知道这些用于确定数据的统计显着性，但我很难理解它们与统计证据和样本量的关系。
SGPV 旨在提供观测数据与指定统计模型之间兼容性的直接测量。这似乎解决了对 P 值的一些批评。当我通读时，我有以下问题：

这个概念如何影响样本量？我们都知道，传统上我们主要使用 p 值来计算样本量。
现在，如果 SGPV 解决了 p 值的挑战，那么我们如何才能根据 SGPV 估计样本量？知道如何计算样本量吗？
我知道 Blume 等人的论文中给出的 SGPV 的功效，但我试图看看是否可以根据功效函数计算样本大小，但 n 似乎是非线性的，使得很难使用n作为样本量计算的主题。如果有人清楚地了解如何使用幂函数来计算样本量，我会很高兴。

在您贡献的背景下，如果有人有使用 r 函数来实现上述结果的想法，欢迎他们帮助我理解这个概念并将其应用到我的研究中。
参考文献：
第二代 p 值：改进的严谨性、再现性和准确性统计分析的透明度。
补充或替换 p:
第二代 p 值简介]]></description>
      <guid>https://stats.stackexchange.com/questions/646241/second-generation-p-values-in-the-context-of-statistical-evidence-and-sample-siz</guid>
      <pubDate>Tue, 30 Apr 2024 20:14:54 GMT</pubDate>
    </item>
    <item>
      <title>查找离散感知器的权重和偏差</title>
      <link>https://stats.stackexchange.com/questions/646225/find-weights-and-bias-of-discrete-perceptron</link>
      <description><![CDATA[我正在准备考试，遇到了这个我无法解决的问题。
如何找到相应的权重和偏差。
我知道它是一个感知器，所以激活函数是 sigmoid = 1 / (1 + e^-x)
我尝试使用数据点并形成方程，例如 u = 2w1 + 0w2 + b 等，然后 f(u) = 1/(1 + e^(2w1 + b) ）等，但没有取得任何进展。
]]></description>
      <guid>https://stats.stackexchange.com/questions/646225/find-weights-and-bias-of-discrete-perceptron</guid>
      <pubDate>Tue, 30 Apr 2024 17:15:02 GMT</pubDate>
    </item>
    <item>
      <title>将数据拟合到马尔萨斯指数模型</title>
      <link>https://stats.stackexchange.com/questions/646224/fitting-data-to-a-malthusian-exponential-model</link>
      <description><![CDATA[我有一些来自酵母生长指数阶段的数据，我想将其拟合到指数（马尔萨斯）生长模型或曲线，因此计算增长率（及其误差）和任何拟合优度指标。我一直在浏览 R 中的一些库，但大多数都使用逻辑参数模型或线性模型进行拟合。
有人知道 R 中的一个库可以让我使用马尔萨斯增长模型进行拟合吗？
我想要拟合的数据具有以下形式，每一列都属于一个重复，我想拟合它们中的每一列以获得其单独的增长率。
时间 Lev_NP4 Lev_NP4 Lev_NP4 Lev_NP4
           1 2 3 4
           1 1 1 1
0 6.804 10.242 1.756 8.666
10 6.056 11.887 2.180 9.315
20 7.580 11.681 2.083 10.387
30 8.074 15.904 2.277 11.458
40 7.770 16.321 2.257 13.394
50 8.173 16.958 2.453 14.149
60 7.780 17.233 2.524 15.687
70 8.034 18.534 2.630 16.015
80 9.090 17.923 2.749 15.972
90 3.137 20.148 4.356 17.789
100 3.929 19.205 4.212 17.395
110 3.771 20.506 4.710 18.831
120 3.770 22.257 4.872 14.073
130 4.183 21.989 5.151 12.110
140 3.863 20.855 5.513 12.661
150 4.314 22.081 5.748 14.499
160 5.087 23.145 6.509 14.622
170 5.995 23.185 5.926 14.066
180 6.028 23.847 6.813 14.892
190 5.599 24.778 7.156 14.894
200 6.105 24.550 7.664 15.870
210 6.955 23.927 7.590 13.659
220 10.762 25.918 7.724 15.050
230 12.164 26.139 0.805 15.332
240 10.017 26.603 0.567 17.344
]]></description>
      <guid>https://stats.stackexchange.com/questions/646224/fitting-data-to-a-malthusian-exponential-model</guid>
      <pubDate>Tue, 30 Apr 2024 17:11:37 GMT</pubDate>
    </item>
    <item>
      <title>混合物分布：关于为什么我们不能通过目视检查推断混合物成分数量的直觉</title>
      <link>https://stats.stackexchange.com/questions/646164/mixture-distributions-an-intuition-on-why-we-cannot-infer-the-number-of-mixture</link>
      <description><![CDATA[我正在研究混合模型，我希望您能帮助解决这个问题：
考虑分布 $\Gamma$ 并假设它是有限混合分布，即 $\Gamma=\ sum_{k=1}^K \Gamma_k \lambda_k$ 与每个 $\lambda_k\geq 0$。您能否直观地理解为什么我们不能仅通过目视检查（例如，通过计数）来推断混合物成分的数量 $K$（或其上限）我们在密度函数的图形表示中看到了多少个“钟声”？]]></description>
      <guid>https://stats.stackexchange.com/questions/646164/mixture-distributions-an-intuition-on-why-we-cannot-infer-the-number-of-mixture</guid>
      <pubDate>Tue, 30 Apr 2024 07:52:24 GMT</pubDate>
    </item>
    <item>
      <title>如何测量功效测试的标准偏差</title>
      <link>https://stats.stackexchange.com/questions/646154/how-to-measure-standard-deviation-for-a-power-test</link>
      <description><![CDATA[我有一个“太笨了，我很尴尬”的想法关于计算能力的问题。
假设一篇论文告诉我，在“表 1”中，$y$ 的标准差是 0.8。然后它报告 $y$ 的效果大小为 0.2，$N$ 为 100每个治疗组和对照组。
现在我的假设是我可以运行，例如在 R 中：
power.t.test(n = 100, delta = 0.2, sd = 0.8)

并发现
&lt;前&gt;&lt;代码&gt;功率 = 0.4204383

但是，这是正确的标准差吗？因为两组的标准差包含了两组之间的差异，即效应大小本身。这似乎有些奇怪。当我模拟这样的情况时，我的本能是这样做：
y &lt;- rnorm(200, sd = 0.8)
y[1:100] &lt;- y + 0.2
组&lt;-rep(c(“治疗”，“对照”)，每个= 100)
lm(y ~ 组)

但这里我创建了一个普通变量，其 sd 为 0.8 但不包括效果大小本身。所以这不一样，对吧？
我很困惑，尽管我感觉这在某种程度上确实是一个愚蠢的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/646154/how-to-measure-standard-deviation-for-a-power-test</guid>
      <pubDate>Tue, 30 Apr 2024 05:27:44 GMT</pubDate>
    </item>
    <item>
      <title>多重比较汇总统计中的 I 类错误</title>
      <link>https://stats.stackexchange.com/questions/646135/type-i-error-in-multiple-comparisons-summary-statistics</link>
      <description><![CDATA[我知道如果我们运行“多重比较”，I 类错误可能会增加。但这是指多类别变量（或多组变量）内的比较吗？或者使用相同变量进行多次分析？在描述性统计中，我们通常对每个预测变量与结果进行单变量检验。这算不算多重比较？我们需要采取一些措施来控制 I 类错误吗？
假设有两个连续结果，一个预测变量是具有 3 个类别（红色、蓝色、绿色）的颜色。如果我们想在颜色与结果0之间进行成对比较。这是一个预测变量内的多重比较。如果我们想比较颜色与结果 0、性别与结果 0、性别与结果 1，则不会遗漏任何组。颜色和性别是独立的。我们需要控制 i 类错误吗？
或者如果年龄、性别、肤色都有2组。我对年龄 = 0 中的性别与结果、年龄 = 1 中的性别与结果、年龄 = 性别 = 0 中的颜色与结果进行 t 检验...我应该针对类型 i 错误进行调整，正确吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/646135/type-i-error-in-multiple-comparisons-summary-statistics</guid>
      <pubDate>Mon, 29 Apr 2024 22:00:49 GMT</pubDate>
    </item>
    </channel>
</rss>