<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 10 Jun 2024 15:16:51 GMT</lastBuildDate>
    <item>
      <title>具有比观测值更多的预测变量（p > n）和相同相关性的套索估计量的行为？</title>
      <link>https://stats.stackexchange.com/questions/648976/behavior-of-lasso-estimator-with-more-predictors-than-observations-p-n-and-i</link>
      <description><![CDATA[如果将 Lasso 估计器用于预测因子 (p) 多于观测值 (n) 的数据集，其中所有预测因子均不相关但与
𝑦
y 高度相关，并且与
𝑦
y 具有完全相同的相关性，那么 Lasso 估计器的行为会如何？Lasso 估计器会将哪些预测因子缩小为零，哪些预测因子会保留？
一致的估计器不会将任何
𝑝
p 变量减少为零。但是，据我了解，Lasso 估计器最多会选择
𝑛
n 个预测因子。我的问题是：在这些条件下，Lasso 会选择哪些预测因子以及为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648976/behavior-of-lasso-estimator-with-more-predictors-than-observations-p-n-and-i</guid>
      <pubDate>Mon, 10 Jun 2024 15:04:58 GMT</pubDate>
    </item>
    <item>
      <title>如何在两个不同的 y 轴上显示箱线图？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648975/how-to-show-boxplots-on-two-different-y-axes</link>
      <description><![CDATA[我有一个带有几个箱线图的 ggplot 图，我希望每组中的最后一个箱线图（在我的示例中是所有箱线图 c）显示在右侧的不同 y 轴上（最好用箱线图的颜色标记）。箱线图 c 显示不同的测量值，其数量级可能存在巨大差异，并且以不同的单位进行测量，因此让它们与 a 和 b 共享轴是没有意义的。 （在我的示例中，我使用函数 o 和 f 更改了箱线图的定义。）
我的工作示例：
library(ggplot2)

a1 &lt;- rnorm(n=100, mean=5, sd=20)
a2 &lt;- rnorm(n=100, mean=6, sd=20)
a3 &lt;- rnorm(n=100, mean=8, sd=20)

b &lt;- rnorm(n=100, mean=11, sd=10)

c1 &lt;- rnorm(n=100, mean=500, sd=80)
c2 &lt;- rnorm(n=100, mean=600, sd=80)
c3 &lt;- rnorm(n=100,平均值=800，标准差=80)

字母 &lt;- c(rep(&quot;a&quot;, 300), rep(&quot;b&quot;, 300), rep(&quot;c&quot;, 300))
类型 &lt;- rep(c(rep(1,100), rep(2,100), rep(3,100)),3)

数据 &lt;- data.frame(y=c(a1,a2,a3,b,b,b,c1,c2,c3), 字母, 类型)

f &lt;- 函数(x) {
r &lt;- 分位数(x, probs = c(0.05, 0.25, 0.5, 0.75, 0.95))
名称(r) &lt;- c(&quot;ymin&quot;, &quot;lower&quot;, &quot;middle&quot;, &quot;upper&quot;, &quot;ymax&quot;)
r
}
o &lt;- function(x) {
subset(x, x &lt; quantile(x, 0.05) | quantile(x, 0.95) &lt; x)
}
ggplot(dat, aes(x=letters, y=y, fill=type, group=letters)) + 
stat_summary(fun.data = f, geom=&quot;boxplot&quot;, fill=&quot;white&quot;) +
stat_summary(fun = o, geom=&quot;point&quot;) + facet_wrap(~type, nrow=1) + 
guides(fill=&quot;none&quot;)


我想要的：

当然，一旦轴不再共享，轴范围就会改变，我想要这样，但这太难画了。]]></description>
      <guid>https://stats.stackexchange.com/questions/648975/how-to-show-boxplots-on-two-different-y-axes</guid>
      <pubDate>Mon, 10 Jun 2024 14:35:37 GMT</pubDate>
    </item>
    <item>
      <title>如何处理缺失值？（面板数据）</title>
      <link>https://stats.stackexchange.com/questions/648974/how-to-deal-with-missing-values-panel-data</link>
      <description><![CDATA[我对面板数据有疑问。我正在处理一个面板数据集，该数据集将公司代码描述为 ID 变量，将财政年度描述为时间变量（2013 年至 2022 年的 1500 家公司）。我有几个独立变量和控制变量。但是，在上述时间窗口内，我的变量中有几个缺失值。我还需要滞后独立变量和控制变量。我不确定如何处理缺失值以及在运行描述性分析和回归之前该做什么。我以前从未进行过实证研究，所以我真的很感谢你的帮助。（我使用 Stata）
提前非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648974/how-to-deal-with-missing-values-panel-data</guid>
      <pubDate>Mon, 10 Jun 2024 14:24:28 GMT</pubDate>
    </item>
    <item>
      <title>如何处理重复和 z 分数？</title>
      <link>https://stats.stackexchange.com/questions/648973/how-to-deal-with-replicates-and-z-scores</link>
      <description><![CDATA[如果您想计算 z 分数，您将如何处理重复？
我的最终目标是制作基因表达热图。为此，我必须计算 z 分数。
分析包括 6 种条件下 6 个基因的一些基因表达数据。
但是，我们用于分析的每个基因都分析了 5 次（因此每个基因有 5 个重复）。
此外，我在基因 5 次重复 3 中有 2 个 NA 值，并且重复 5 在每种情况下都是异常值。
您将如何处理这个问题？作为一名无知的生物学家，我的第一个问题是：我应该对我的数据取平均值（或由于异常值而取中位数），然后计算 z 分数吗？但如果是这样，在公式 (x-mean)/sd 中，x 应该是多少？
我也尝试计算每个基因的每个重复的 z 分数，然后取平均值，但结果看起来很奇怪。]]></description>
      <guid>https://stats.stackexchange.com/questions/648973/how-to-deal-with-replicates-and-z-scores</guid>
      <pubDate>Mon, 10 Jun 2024 14:22:37 GMT</pubDate>
    </item>
    <item>
      <title>Salesforce Marketing Cloud 群发电子邮件打开率问题 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648970/salesforce-marketing-cloud-mass-email-open-rate-issue</link>
      <description><![CDATA[我正在使用 Salesforce Marketing Cloud 向订阅者发送群发邮件，发现我在 2023 年发送的群发邮件的打开率比 2024 年发送的群发邮件更高，这意味着 2024 年群发邮件的打开率大幅下降
两年发送的目标受众相同
有人能帮我找出这个问题的根本原因吗？我们应该考虑什么来解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/648970/salesforce-marketing-cloud-mass-email-open-rate-issue</guid>
      <pubDate>Mon, 10 Jun 2024 13:57:36 GMT</pubDate>
    </item>
    <item>
      <title>具有左删失数据的泊松模型</title>
      <link>https://stats.stackexchange.com/questions/648966/poisson-model-with-left-censored-data</link>
      <description><![CDATA[我观察到一种情况，每个人都可以签订每月年金，该年金在事件 A 实现后支付，并取决于生存情况。因此，有些人可能永远不会收到年金，尽管他们签订了年金，因为他们在事件 A 发生前就死了。我的假设是，那些在事件 A 发生后活得更长的人更有可能签订年金。要清楚的是，结果是 A 之后的存活月数。我想使用泊松模型来研究这一点。然而，问题是事件 A 是个人特有的，对于我的一小部分数据来说，A 还没有实现。因此，我可能会有相当多的零是错误的，因为零可能意味着一个人在 A 发生之前就死了，也可能意味着 A 还没有发生，但这个人仍然活着。
很高兴有任何关于如何克服这个问题的想法！]]></description>
      <guid>https://stats.stackexchange.com/questions/648966/poisson-model-with-left-censored-data</guid>
      <pubDate>Mon, 10 Jun 2024 13:13:11 GMT</pubDate>
    </item>
    <item>
      <title>支持向量回归的对偶公式推导</title>
      <link>https://stats.stackexchange.com/questions/648965/derivation-of-dual-formulation-of-support-vector-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648965/derivation-of-dual-formulation-of-support-vector-regression</guid>
      <pubDate>Mon, 10 Jun 2024 13:08:49 GMT</pubDate>
    </item>
    <item>
      <title>多重归纳小鼠 pmm</title>
      <link>https://stats.stackexchange.com/questions/648963/multiple-imputation-mice-pmm</link>
      <description><![CDATA[我需要在我的数据集中估算 20 个是/否变量。在这个数据集中，35% 的个体缺失了这 20 个变量，而其余 65% 的个体拥有这些变量的完整数据。此外，还有大约 25 个其他变量将用作估算的预测因子。
由于缺失数据的组 (35%) 与数据完整的组 (65%) 没有显著差异，因此我们预计估算数据和非估算数据之间不会有显著差异。
我使用 MICE PMM 方法估算了 20 个是/否变量，包括 25 个其他变量作为预测因子。然而，与非估算数据相比，估算数据显示“是”响应的百分比要高得多（有时高出 5 到 10 倍），这是出乎意料的。当我使用 25 个预测变量一次只估算 20 个变量中的一个（忽略其他 19 个）时，估算组中“是”与“否”的百分比比预期的要多。
一个变量的示例：
-45 次非估算中的是
-79 次非估算中的是 + 如果我仅估算这个是/否变量则估算
-260 次非估算中的是 + 如果我估算所有 20 个是/否变量则估算
是否有人了解为什么同时估算多个是/否变量可能会导致“是”响应的百分比异常高？]]></description>
      <guid>https://stats.stackexchange.com/questions/648963/multiple-imputation-mice-pmm</guid>
      <pubDate>Mon, 10 Jun 2024 13:01:08 GMT</pubDate>
    </item>
    <item>
      <title>使用长期倾向来比较独立变量之间的关联程度</title>
      <link>https://stats.stackexchange.com/questions/648961/using-long-run-propensities-to-compare-magnitude-of-association-among-independen</link>
      <description><![CDATA[是否可以将各个独立变量的所有显著滞后相加（忽略不显著的变量），以比较它们与因变量的关联强度或大小？
我指定了一个季度时间序列数据的 ARDL 模型，所有一阶差分，将商品期货价格的变化回归到代表供需条件的几个独立变量的变化。由于所讨论的农产品的作物周期为一年，因此包括所有变量的 4 个滞后，随后进行限制，只消除不显著的最远滞后。因此，当进一步的滞后显著时，模型中独立变量的滞后不显著。
仅供参考，本研究的目的不是预测价格，而是了解价格变动与基础商品基本因素变化之间的关系，以及与另一种（不可投标）商品相关的基本因素，以判断价格是否被无关信息扭曲。
例如，我想说价格与相关供应之间的关联由相关供应变量所有显著滞后的 beta 系数总和（其 LRP）表示；价格与不相关供应之间的关联是不相关供应变量的 LRP。
是否可以得出结论，不相关供应 LRP 是价格扭曲的程度？我可以比较相关和不相关的 LRP 来了解哪个与价格变动的关联更大吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648961/using-long-run-propensities-to-compare-magnitude-of-association-among-independen</guid>
      <pubDate>Mon, 10 Jun 2024 12:30:18 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用均方预测误差来选择 CausalImpact 模型中的先验 SD 吗？</title>
      <link>https://stats.stackexchange.com/questions/648959/can-i-use-the-mean-squared-prediction-error-to-select-the-prior-sd-in-a-causalim</link>
      <description><![CDATA[我正在使用 CausalImpact 包（在 R 中），并且（正如我所期望的那样）结果对所使用的先验非常敏感。
我认为我对先验在此模型中的作用有很好的理解，但我仍然难以从理论上确定先验 SD 应该是多少，特别是因为结果对微小变化非常敏感。在我工作的环境中，我的同事对于放弃默认设置有些犹豫（即使我们正在处理的数据与默认设置的设计不同）。还有一种担心是客户会对任何可能被解释为“偏见”的东西产生怀疑结果。
我正在考虑的想法是，在干预前后半段对每个数据点分别运行具有各种先验水平 SD 的模型，然后（对于每个先验水平 SD）提取并汇总所有分析中的所有预测误差，将其变成一些衡量绩效的分数（可能是均方预测误差）。然后，我可以选择在干预前运行分析时导致最低 MSPE（或某些相关度量）的先验 SD。
这是一种合法的方法吗？在这种情况下，还有其他更有原则的方法来选择先验吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648959/can-i-use-the-mean-squared-prediction-error-to-select-the-prior-sd-in-a-causalim</guid>
      <pubDate>Mon, 10 Jun 2024 11:49:01 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 进行两个连续预测变量的多元回归</title>
      <link>https://stats.stackexchange.com/questions/648958/multiple-regression-with-two-continuous-predictor-variables-with-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648958/multiple-regression-with-two-continuous-predictor-variables-with-r</guid>
      <pubDate>Mon, 10 Jun 2024 11:13:50 GMT</pubDate>
    </item>
    <item>
      <title>计算 GLM-拟泊松模型的权重</title>
      <link>https://stats.stackexchange.com/questions/648957/calculate-weight-for-glm-quasi-poisson-model</link>
      <description><![CDATA[我正在运行几个拟泊松系列模型。我正在查看秃鹫餐厅的数据。每个地点的秃鹫数量都被建模为日期或月份的线性或二次效应函数，以及地点、季节和它们之间相互作用的固定效应。使用 R 中的对数链接函数对模型进行拟泊松误差拟合。最佳模型由最低的拟 AICc 分数选出。为了计算 QAICc 分数，我重新运行了所有具有标准泊松误差的模型，并使用 R 包“bblme”（Bolker 2016）使用每组（日期 2 × 地点 × 季节）中最复杂模型的离散度来校正 AICc 分数。
我想通过报告 QAICc 权重来展示对顶级模型的支持水平。但我在网上找不到如何做到这一点。包中是否有函数可用于计算每个模型的权重？
以下是我从名为 Table_DeltaQAICc 的包“bblme”中获得的结果：

我尝试按照我在网上看到的这个公式来计算权重，这是一个使用 IC 的示例。模型权重的计算公式如下：e(−δIC/2)
Table_DeltaQAICc$Weight &lt;- exp((-Table_DeltaQAICc$dqAICc)/2)

这是我得到的结果，我这样计算每个模型的权重合适吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648957/calculate-weight-for-glm-quasi-poisson-model</guid>
      <pubDate>Mon, 10 Jun 2024 11:08:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么情节看起来不同？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648955/why-do-the-plots-look-different</link>
      <description><![CDATA[如果我使用 SYSTAT 应用程序绘制此数据，它看起来如下所示：

在 ChatGPT 中，它看起来如下所示：

但是，当我使用我的 C# 应用程序绘制它时，它看起来如下所示：

你能告诉我为什么这些图看起来不一样吗？
残基、密度、Tau0
10,0.001,21.937
10,0.001,22.04
10,0.001,22.032
10,0.001,21.962
10,0.001,21.845
10,0.001,21.929
10,0.001,21.794
10,0.001,21.918
10,0.00 1,21.877
10,0.001,21.81
10,0.001,21.832
10,0.001,21.872
10,0.001,21.813
10,0.001,21.608
10,0.001,21.679
10,0.005,22.067
10,0.005,22.037
10,0.005,21.906
10,0.005,21.941
10,0.005,21.964
10,0.005,21.871
10,0.005,21.938
10,0.005,21.918
10,0.005,21.941
10,0.005,21.752
10,0.0 05,21.766
10,0.005,21.821
10,0.005,21.757
10,0.005,21.699
10,0.005,21.776
10,0.01,22.231
10,0.01,22.228
10,0.01,22.116
10,0.01,22.131
10 ,0.01,22.166
10,0.01,22.155
10,0.01,21.951
10,0.01,22.003
10,0.01,21.996
10,0.01,22.126
10,0.01,21.981
10,0.01,21.913
10,0.01,21.984
10 ,0.01,21.947
10,0.01,21.889
15,0.001,55.011
15,0.001,54.892
15,0.001,54.325
15,0.001,54.349
15,0.001,54.554
15,0.001,54.288
15,0.001,54. 213
15,0.001,53.985
15,0.001,54.296
15,0.001,54.29
15,0.001,54.187
15,0.001,53.237
15,0.001,53.908
15,0.001,53.524
15,0.001,52.545
15,0 .005,55.073
15,0.005,55.296
15,0.005,55.072
15,0.005,54.901
15,0.005,54.969
15,0.005,54.625
15,0.005,54.299
15,0.005,53.906
15,0.005,54. 336
15,0.005,53.949
15,0.005,54.12
15,0.005,54.243
15,0.005,53.788
15,0.005,53.831
15,0.005,53.746
15,0.01,55.233
15,0.01,55.165
15,0.0 1,55.057
15,0.01,54.919
15,0.01,54.849
15,0.01,55.066
15,0.01,55.113
15,0.01,54.624
15,0.01,54.419
15,0.01,54.389
15,0.01,54.075
15,0.0 1,54.335
15,0.01,53.77
15,0.01,54.248
15,0.01,53.563
25,0.001,164.724
25,0.001,164.99
25,0.001,163.518
25,0.001,164.708
25,0.001,162.76 9
25,0.001,162.927
25,0.001,162.678
25,0.001,163.869
25,0.001,162.71
25,0.001,161.045
25,0.001,161.379
25,0.001,161.428
25,0.001,161.531
25,0.001,159.493
25,0.001,160.823
25,0.005,167.892
25,0.005,166.525
25,0.005,165.384
25,0.005,164.054
25,0.005,163.825
25,0.005,163.31 9
25,0.005,161.626
25,0.005,161.139
25,0.005,158.917
25,0.005,160.506
25,0.005,161.778
25,0.005,160.07
25,0.005,159.091
25,0.005,160.715
25,0.005,157.838
25,0.01,167.243
25,0.01,166.138
25,0.01,164.303
25,0.01,167.051
25,0.01,164.707
25,0.01,163.833
25,0.01,164.682
25,0. 01,163.755
25,0.01,163.913
25,0.01,162.615
25,0.01,163.848
25,0.01,162.233
25,0.01,160.745
25,0.01,163.592
25,0.01,159.967
]]></description>
      <guid>https://stats.stackexchange.com/questions/648955/why-do-the-plots-look-different</guid>
      <pubDate>Mon, 10 Jun 2024 10:56:32 GMT</pubDate>
    </item>
    <item>
      <title>样本量中固定 alpha 和 beta 的平均差计算的 z 分数总和</title>
      <link>https://stats.stackexchange.com/questions/648954/z-score-total-for-fixed-alpha-and-beta-in-sample-size-calculation-of-mean-differ</link>
      <description><![CDATA[有人能详细解释一下在均值差$\mu_1 - \mu_2$的单尾假设检验中，$z_\text{total}=z_{\alpha} + z_{1-\beta}$如何用共同方差来确定样本量吗？
我找到的所有参考资料都得出了这个公式，但没有分解得出该公式的步骤。]]></description>
      <guid>https://stats.stackexchange.com/questions/648954/z-score-total-for-fixed-alpha-and-beta-in-sample-size-calculation-of-mean-differ</guid>
      <pubDate>Mon, 10 Jun 2024 10:02:27 GMT</pubDate>
    </item>
    <item>
      <title>标准差的最大似然法</title>
      <link>https://stats.stackexchange.com/questions/648950/maximum-likelihood-of-standard-deviation</link>
      <description><![CDATA[我试图更好地理解样本标准差的分布和不确定性。由于我不是数学家，我尝试将数学文献与一些模拟结果进行比较。
我做了一个相当简单的模拟研究，首先假设 X∼N(μ,σ²)。我从这个分布中抽样三次并估计样本方差。
我使用估计的样本方差并模拟卡方分布以获得方差的上限和下限 95% CI。（我知道，我可以通过取分布的分位数而不模拟结果来做到这一点，但出于比较的原因，我希望得到分布）。我取这些结果的平方根并将它们与总体标准差进行比较。通过重复这种方法 2,500 次，我可以显示样本标准差的 95% 置信区间的覆盖率约为 95%。这就是我所期望的。
不过，我还对 2,500 个卡方分布的众数取了平均值，取了平方根，并将该值与平均样本方差的平方根进行了比较。
众所周知，方差是真实总体方差的无偏估计量，我得到了 1 作为结果。但是，平均模式的平方根导致结果约为 0.77。
为了更好地理解这一点，我绘制了模拟 2500 的卡方分布，并将该分布的模式与样本方差（红线）进行了比较。

模式和估计的样本方差之间存在明显偏差。我的下一个想法是，这可能与最大似然 (ML) 与受限最大似然估计 (REML) 有关。所以，我做了一个小改动。我没有将样本方差乘以 n-1，而是将其乘以 n，然后重复该过程。
var_sim &lt;- (n-1)*sample_var[i]/rchisq(n = n_sim, df = n-1)
对比
var_sim &lt;- (n)*sample_var[i]/rchisq(n = n_sim, df = n-1)
样本方差的预期值再次为 1，平均模式的平方根约为 0.95，现在更接近预期值 1。然而，这带来了覆盖率损失（89%）的代价。

我预计卡方分布的众数/最大似然估计量应该与样本方差一起下降。然而，这两种方法都不是这种情况。我想，我对 ML 估计量和卡方样本分布的模式有一个根本性的误解，我希望有人能解释一下我的问题。
这里是重现我的结果的代码：
set.seed(09062024)

result_var &lt;- NULL
sd_qt_upper &lt;- NULL
sd_qt_lower &lt;- NULL
sd_mean &lt;- NULL
sd_mode &lt;- NULL
sample_var &lt;- NULL

n_sim &lt;- 2500
n &lt;- 3

for(i in 1:n_sim){
x &lt;- rnorm(n = n, 0,1)
sample_var[i] &lt;- var(x)

var_sim &lt;- (n-1)*sample_var[i]/rchisq(n = n_sim, df = n-1)

sd_qt_lower[i] &lt;- sqrt(quantile(var_sim, probs = 0.025)) 
sd_qt_upper[i] &lt;- sqrt(quantile(var_sim, probs = 0.975))
sd_mean[i] &lt;- sqrt(mean(var_sim))
var_density_temp &lt;- density(var_sim, n = n_sim, from = 0, to = 10 )
sd_mode[i] &lt;- sqrt(var_density_temp[[&quot;x&quot;]][which(var_density_temp[[&quot;y&quot;]]==max(var_density_temp[[&quot;y&quot;]]))])
}

coverage_sd &lt;- sd_qt_upper&gt;1&amp;sd_qt_lower&lt;1
mean(coverage_sd) #覆盖率
mean(sd_mean) #基于每个卡方分布和模拟轮次的预期值的预期值
sqrt(mean(sample_var)) #基于初始 var 计算的预期值
mean(sd_mode) #基于模拟模式的预期值

#plot
plot(var_density_temp, main = paste(&quot;chi square distribution simulation:&quot;, i, &quot;\n Mode = &quot;, 
round(var_density_temp[[&quot;x&quot;]][which(var_density_temp[[&quot;y&quot;]]==max(var_density_temp[[&quot;y&quot;]]))],2),
&quot;\n 样本方差 = &quot;, round(sample_var[n_sim], 2)))
abline(v = sample_var[n_sim], col = &quot;red&quot;, lwd = 2)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648950/maximum-likelihood-of-standard-deviation</guid>
      <pubDate>Mon, 10 Jun 2024 08:07:12 GMT</pubDate>
    </item>
    </channel>
</rss>