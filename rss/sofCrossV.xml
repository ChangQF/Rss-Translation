<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 27 Jan 2024 18:14:49 GMT</lastBuildDate>
    <item>
      <title>一起使用 NAMCS 和 NHAMCS 时应使用多少重量？</title>
      <link>https://stats.stackexchange.com/questions/637896/what-weight-to-use-for-using-namcs-and-nhamcs-together</link>
      <description><![CDATA[我有兴趣分析 NMCS 和 NHAMCS 中阿司匹林的总处方 (https: //www.cdc.gov/nchs/ahcd/index.htm）在给定年份内的所有访问。 NAMCS 和 NHAMCS 各有一个权重，而且它们的权重差异很大，我注意到这两个权重都不等于美国人口。然而，NAMCS 和 NHAMCS 的采样是相互独立的。这让我认为将它们结合起来很好。然而，组合样本将对观测值进行不同的加权以进行比率估计。对于总体估计，这似乎完全没问题。
$Q:$ 我在不调整权重的情况下组合 NAMCS 和 NHAMCS 是错误的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637896/what-weight-to-use-for-using-namcs-and-nhamcs-together</guid>
      <pubDate>Sat, 27 Jan 2024 17:43:34 GMT</pubDate>
    </item>
    <item>
      <title>仪器较弱但第二阶段意义重大</title>
      <link>https://stats.stackexchange.com/questions/637895/weak-instrument-but-2nd-stage-significant</link>
      <description><![CDATA[我的 IV 的第一阶段 F 统计值为 4.7（根据经验认为很弱）。第二阶段回归系数显着。我想知道解释这些观察结果的最佳方法是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/637895/weak-instrument-but-2nd-stage-significant</guid>
      <pubDate>Sat, 27 Jan 2024 17:41:12 GMT</pubDate>
    </item>
    <item>
      <title>如何仅使用结果而非实际数据绘制标准差图表</title>
      <link>https://stats.stackexchange.com/questions/637894/how-do-i-chart-standard-deviation-with-only-the-results-on-not-the-actual-data</link>
      <description><![CDATA[如果我只有结果而没有数据，如何在 Excel 中绘制标准差图表？
我的结果：
有 25 个数据点，平均值 = 30 秒，标准差 = 12 秒，最小值 = 18 秒，最大值 = 66 秒。]]></description>
      <guid>https://stats.stackexchange.com/questions/637894/how-do-i-chart-standard-deviation-with-only-the-results-on-not-the-actual-data</guid>
      <pubDate>Sat, 27 Jan 2024 17:32:33 GMT</pubDate>
    </item>
    <item>
      <title>如何计算调查结果的统计功效？这是一项探索性调查，没有任何测量结果</title>
      <link>https://stats.stackexchange.com/questions/637893/how-do-i-calculate-the-statistical-power-of-my-survey-results-it-is-an-explorat</link>
      <description><![CDATA[我需要证明我的调查结果或样本量具有统计显着性。我在 R 中进行了 2 个样本 T 检验，我的主管说“由此并不清楚你的结果的统计功效是多少”。我认为 t 检验不适用于我的数据，因为我的数据是探索性调查，有“是”，没有答案，所以没有连续数据。
我需要做什么测试才能显示我的结果具有统计显着性或计算结果的统计功效？作为背景，我在 6 个月内完成了这项调查，样本量为 71 份回复中的 40 份。请指导谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637893/how-do-i-calculate-the-statistical-power-of-my-survey-results-it-is-an-explorat</guid>
      <pubDate>Sat, 27 Jan 2024 17:17:20 GMT</pubDate>
    </item>
    <item>
      <title>决策树的拟合概率</title>
      <link>https://stats.stackexchange.com/questions/637892/fitting-probabilities-for-decision-trees</link>
      <description><![CDATA[我使用决策树执行事故分析。
有些情况很清楚（所有信息都存在），有些情况则不清楚。
根据我以前的经验，我可以添加丢失的数据（恢复成本）。但我不知道如何更数学地合理地调整收入概率。
我可以使用不同收入的经验概率，但我只能预测其中的粗略数量。
主要问题是我们的实验已经结束，我无法获取新的必要数据。
解决这个问题的最佳方法是什么？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637892/fitting-probabilities-for-decision-trees</guid>
      <pubDate>Sat, 27 Jan 2024 17:09:01 GMT</pubDate>
    </item>
    <item>
      <title>聚类和分段回归中断时间序列分析</title>
      <link>https://stats.stackexchange.com/questions/637891/clustering-and-segmented-regression-interrupted-time-series-analysis</link>
      <description><![CDATA[我想进行中断时间序列分析，以使用个体水平数据来了解大流行对癌症发病率的影响。我计划使用负二项式分段回归方法。
我担心治疗机构可能会出现聚集现象，因为特定医院提供不同的治疗方法并专注于特定疾病。我如何在分析中解释这种聚类？有些人建议使用三明治估计器，但我怀疑这可能过于简单化。]]></description>
      <guid>https://stats.stackexchange.com/questions/637891/clustering-and-segmented-regression-interrupted-time-series-analysis</guid>
      <pubDate>Sat, 27 Jan 2024 17:02:51 GMT</pubDate>
    </item>
    <item>
      <title>小样本，多措施</title>
      <link>https://stats.stackexchange.com/questions/637890/small-sample-many-measures</link>
      <description><![CDATA[假设您对 50 种不同的联合生存能力指标有观察。您有一个由 20 名未接受手术的个体组成的对照样本，以及一个由 17 名手术前和术后个体组成的样本。您还有一些有关个人的人口统计数据。有许多简单的 t 检验可以在前与对照、前与后等方面运行。而且，这些测试可以针对 50 种不同的测量中的每一种单独运行。显然，这陷入了多重比较的泥潭（Bonferroni 等），并且不容易总结 50 种不同措施的信息。有没有办法从所有这些措施中获取更多信息？
我们可以使用控制样本来创建“正常”均值和标准差。对于每个测量，然后使用这些平均值和标准差对每个测量的每个单独观察值进行标准化。然后，我们获得了大约 1,700 个测量关节特征的观察值，这些观察值被归一化为 0-1，并且可以被视为单列数据。当然，这个过程因标准化观察值之间缺乏独立性而变得混乱（因为每个组的每个人都会生成 50 个观察值），这会导致所有估计产生偏差。有什么办法可以挽救这个吗？我可以为每个主题和每个度量添加控制 - 这会使该方法合理（以及对每个人的人口统计数据的控制）吗？其他方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/637890/small-sample-many-measures</guid>
      <pubDate>Sat, 27 Jan 2024 16:19:08 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器中的非线性 PCA 与编码器</title>
      <link>https://stats.stackexchange.com/questions/637889/nonlinear-pca-vs-encoder-in-autoencoders</link>
      <description><![CDATA[我发现编码器比 PCA 更有优势，因为它们可以转换线性和非线性数据。然而，非线性 PCA 不是为处理非线性数据而设计的吗？那么，为什么我们仍然倾向于使用编码器而不是非线性 PCA？]]></description>
      <guid>https://stats.stackexchange.com/questions/637889/nonlinear-pca-vs-encoder-in-autoencoders</guid>
      <pubDate>Sat, 27 Jan 2024 15:39:05 GMT</pubDate>
    </item>
    <item>
      <title>导出线性 LM 测试</title>
      <link>https://stats.stackexchange.com/questions/637887/derive-lm-test-for-linearity</link>
      <description><![CDATA[我正在研究非线性模型。我尝试根据明确的参数线性模型导出非线性模型的 LM 检验

书中给出了分数向量$s(\theta)$和信息矩阵$I(\theta)$&lt; /span&gt;.
我知道
$$LM= s(\theta)’ I^{-1}(\theta) s(\theta)$$
$$(1\sigma^2) [ZZ&#39;H&#39;H-ZHH&#39;Z&#39;]^{-1}[\epsilon&#39;HZZ&#39;H&#39;\epsilon] $$
到目前为止我找到了 LM 检验统计量。但从这里开始，我无法驱动方程（10.18）。
但是我无法通过这个公式找到方程（10.18）。
请告诉我如何推导方程（10.18）。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637887/derive-lm-test-for-linearity</guid>
      <pubDate>Sat, 27 Jan 2024 15:05:45 GMT</pubDate>
    </item>
    <item>
      <title>当暴露和结果没有相同的后续时，如何处理 COX 回归</title>
      <link>https://stats.stackexchange.com/questions/637886/what-to-do-with-cox-regression-when-exposure-and-outcome-does-not-have-the-same</link>
      <description><![CDATA[我正在研究 cox 回归来分析暴露与结果之间的关联。我还有一个开始时间（跟进的开始时间）和结束时间（得到结果或审查的时间）。所以模型在R中是这样写的：
模型 &lt;- coxph(Surv(开始、结束、结果) ~ 1 + 曝光 + 地层(性别)，稳健 = TRUE，数据=my_data)
我有一个 10.000+ 1997 年至 2011 年出生的人的大样本。后续也是从 1997 年到 2011 年开始。

系统从 1997 年起就记录了暴露情况（这是您出生时就得到的诊断结果）。
结果从 2004 年起就记录在系统中（这是一种只能在以后的生活中才能检测到的诊断）。

这意味着我的样本中出生于 1997 年的个体会受到暴露，但他们获得结果的风险将从 2004 年开始，因为在 2004 年之前不可能在系统中注册（意味着他们将在 7 岁时登记结果，即使他们可能在 7 岁之前得到结果）。同时，我会让 2003 年出生的人接触过这种病毒，并且他们从 1 岁时就开始面临这种结果的风险。
我应该如何处理此类数据？我可以通过调整模型中的年龄来最大限度地减少偏差吗？
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/637886/what-to-do-with-cox-regression-when-exposure-and-outcome-does-not-have-the-same</guid>
      <pubDate>Sat, 27 Jan 2024 14:55:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的预训练 VGG16 模型的 IOU SCORE 从 0.05 开始，并且没有任何改善......RESNET34 IOU SCORE 从 0.8277 开始？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637883/why-my-pretrained-vgg16-models-iou-score-starting-from-0-05-and-not-getting-an</link>
      <description><![CDATA[使用RESNET 34
&lt;前&gt;&lt;代码&gt;n_classes = 4
激活 = &#39;softmax&#39;
LR = 0.0001
optim = keras.optimizers.Adam(LR)
dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.25, 0.25, 0.25, 0.25]))
focus_loss = sm.losses.CategoricalFocalLoss()
总损失 = dice_loss + (1 * focus_loss)
总损失 = sm.losses.binary_focal_dice_loss
指标 = [sm.metrics.IOUScore(阈值=0.5), sm.metrics.FScore(阈值=0.5)]

BACKBONE1 = &#39;resnet34&#39;
preprocess_input1 = sm.get_preprocessing(BACKBONE1)
X_train1 = 预处理_输入1(X_train)
X_test1 = 预处理_输入1(X_test)

model1 = sm.Unet(BACKBONE1,encoder_weights=&#39;imagenet&#39;,classes=n_classes,
激活=激活）
model1.compile（优化，total_loss，指标=指标）
model1.summary()

历史1=模型1.fit(X_train1,
      y_火车_猫，
      批量大小=8，
      纪元=3，
      详细=1，
      验证数据=（X_test1，y_test_cat））

RESNET34 的输出

使用 VGG16
&lt;前&gt;&lt;代码&gt;初始学习率 = 0.0001
衰减率=0.9
衰减步数=100000
lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,
decay_steps=100000，decay_rate=0.9，楼梯=True）

optim = keras.optimizers.SGD(learning_rate=lr_schedule)

骨干2 = &#39;vgg16&#39;
preprocess_input2 = sm.get_preprocessing(BACKBONE2)

X_train2 = 预处理_输入2(X_train)
X_test2 = 预处理_输入2(X_test)

model2 = sm.Unet(BACKBONE2,encoder_weights=&#39;imagenet&#39;,classes=n_classes,a
激活=激活）

model2.compile（优化，total_loss，指标）
model2.summary()

历史2 = model2.fit(X_train2,
      y_火车_猫，
      批量大小=100，
      纪元=5，
      详细=1，
      验证数据=（X_test2，y_test_cat））


我正在训练模型两次，一次是在 pretrained-resnet34 上，另一次是在 pretrained-vgg16 上，在 resnet34 中，即使在 2-3 个 epoch 上，我也能获得很好的 IOU 分数，但在 vgg16 中，准确性非常差，甚至没有任何改善10-20个epoch后。我在 resnet34 中使用 adam，但使用指数衰减 sgd，使用 adam 进入 vgg16 时收到神秘的错误消息。
vgg16 的平均 IOU SCORE 为 ~.16-.18，而 resnet34 IOU SCORE 为 0.89-.90
VGG16训练时IOU SCORE从0.05开始，最后达到0.1；但在 resnet34 中，我得到了 0.8 的初始 iou 分数，然后更好地达到 0.8
我尝试了所有损失函数。和许多优化器，但没有解决问题。
任何帮助将不胜感激]]></description>
      <guid>https://stats.stackexchange.com/questions/637883/why-my-pretrained-vgg16-models-iou-score-starting-from-0-05-and-not-getting-an</guid>
      <pubDate>Sat, 27 Jan 2024 13:44:09 GMT</pubDate>
    </item>
    <item>
      <title>FE 估计器形式 - 转置如何工作？</title>
      <link>https://stats.stackexchange.com/questions/637882/fe-estimator-form-how-the-transposition-works</link>
      <description><![CDATA[有人可以解释我如何从第一种形式转换为另一种形式以及为什么“”即使它不再是矢量，它仍然存在吗？感谢帮助。

]]></description>
      <guid>https://stats.stackexchange.com/questions/637882/fe-estimator-form-how-the-transposition-works</guid>
      <pubDate>Sat, 27 Jan 2024 13:40:05 GMT</pubDate>
    </item>
    <item>
      <title>当包含两个连续自变量时如何构建最优样条模型</title>
      <link>https://stats.stackexchange.com/questions/637875/how-to-construct-an-optimal-spline-model-when-two-continuous-independent-variabl</link>
      <description><![CDATA[我有兴趣评估年龄、BMI 和血脂水平之间的关系。血脂水平是我研究的一个结果。我认为血脂水平与年龄之间的关系以及血脂水平与BMI之间的关系可能分别是非线性的。因此，我想将限制三次样条应用于 R rms 包中的年龄和 BMI
在这种情况下，我必须考虑两条样条线各应使用多少个结，一个用于年龄，另一个用于 BMI（此外，我必须决定结的位置）。
作为这个问题的解决方案，我正在考虑执行以下命令来分别确定对于年龄和 BMI 而言最佳的节数，更改节数并采用 AIC 最低的模型。
mod &lt;- ols(lipid~rcs(age,num_knot_age)+rcs(BMI,num_knot_BMI),data=dat);
还有其他更好的方法吗？我将不胜感激您的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/637875/how-to-construct-an-optimal-spline-model-when-two-continuous-independent-variabl</guid>
      <pubDate>Sat, 27 Jan 2024 08:46:43 GMT</pubDate>
    </item>
    <item>
      <title>模型过度自信如何与准确分类相一致？</title>
      <link>https://stats.stackexchange.com/questions/637864/how-can-model-overconfidence-coincide-with-accurate-classifications</link>
      <description><![CDATA[Guo 等人 (ICML 2017) 陈述如下。
&lt;块引用&gt;
在训练期间，模型能够正确分类（几乎）所有训练样本后，可以通过增加预测的置信度来进一步最小化 NLL。模型容量的增加会降低训练 NLL，因此模型平均而言会更加（过度）自信。

(“NLL”在某些领域分别指二项式或多项式负对数似然、二元交叉熵损失和分类交叉熵损失。）
我很难理解这一点。如果类别在可用特征上很容易区分，通过分类精度（在某个阈值）高的事实来衡量，那么预测的概率应该很高。考虑到这一点，“过度自信”者不应该有这样的想法吗？预测有合理的信心吗？
参考文献
郭川等人。 “关于现代神经网络的校准。”国际机器学习会议。 PMLR，2017。]]></description>
      <guid>https://stats.stackexchange.com/questions/637864/how-can-model-overconfidence-coincide-with-accurate-classifications</guid>
      <pubDate>Sat, 27 Jan 2024 01:44:19 GMT</pubDate>
    </item>
    <item>
      <title>“z 分数”的首选排版</title>
      <link>https://stats.stackexchange.com/questions/637838/preferred-typography-for-z-score</link>
      <description><![CDATA[我想知道术语“z 分数”是否有首选的印刷形式。
在 Google 学术搜索“z 分数”显示六种形式

无标记：z 分数
连字符：z 分数
大写：Z 分数

和 4、5 和 6：上述形式中 z 为斜体，例如 z-score。
快速浏览前三页后，我没有看到任何收藏夹。]]></description>
      <guid>https://stats.stackexchange.com/questions/637838/preferred-typography-for-z-score</guid>
      <pubDate>Fri, 26 Jan 2024 18:36:36 GMT</pubDate>
    </item>
    </channel>
</rss>