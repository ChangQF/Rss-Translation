<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 18 Jul 2024 21:14:20 GMT</lastBuildDate>
    <item>
      <title>预测区间准确度与均方误差之间的权衡</title>
      <link>https://stats.stackexchange.com/questions/651367/tradeoff-between-prediction-interval-accuracy-mean-squared-error</link>
      <description><![CDATA[我的目标是量化气候协变量与 GDP 回归模型中的预测不确定性。我从一个以温度为三次多项式的模型开始，国家固定效应（$\alpha_i$}，年份固定效应（$\theta_t$），以及按国家/地区划分的增量时间趋势（$\gamma_i$）。
$$ 
GDP_{it} = \beta_1 * Temp_{it} + \beta_2 * Temp^2_{it} + \beta_3 * Temp^3_{it} + \alpha_i + \theta_t + \gamma_i
$$
使用一些保留数据来收集上述模型的样本外均方误差。我还使用样本外预测的标准误差来构建 95% 的预测间隔，然后检查实际 Y（GDP）值在这些间隔内的实际百分比作为预测间隔准确度。
样本外 MSE：0.017
预测间隔准确度：0.577

为了使预测间隔准确度更接近 95% 的目标，我尝试了不同的模型高阶多项式时间趋势，如下所示：
$$ 
GDP_{it} = \beta_1 * Temp_{it} + \beta_2 * Temp^2_{it} + \beta_3 * Temp^3_{it} + \alpha_i + \theta_t + \gamma_i + \gamma^2_i + \gamma^3_i
$$
样本外 MSE： 0.018
预测区间准确度：0.722

由于预测区间更宽，预测区间准确度大大提高，这可能是因为模型在训练数据中纳入了更多方差。但是，可能由于额外的模型复杂性导致过度拟合，第二个模型的 MSE 高于第一个模型。
我的问题与这个特定示例关系不大，而是与我普遍观察到的这种现象关系较大。我想知道：

是否存在一个单一的潜在现象，可以解释为什么增加模型复杂度会导致预测区间更接近 95% 的目标，同时增加模型的 MSE，或者这些本质上是独立的观察结果？

如果我的目标是尽可能量化模型不确定性，那么如何正确考虑以更高质量（在这种情况下意味着更宽）的预测区间换取随后的 MSE 增加？

]]></description>
      <guid>https://stats.stackexchange.com/questions/651367/tradeoff-between-prediction-interval-accuracy-mean-squared-error</guid>
      <pubDate>Thu, 18 Jul 2024 20:44:03 GMT</pubDate>
    </item>
    <item>
      <title>如何证明 Kendall 分布函数（或 Kendall 测量）的这种关系</title>
      <link>https://stats.stackexchange.com/questions/651366/how-to-prove-this-relation-for-kendalls-distribution-function-or-kendalls-mea</link>
      <description><![CDATA[肯德尔分布函数 (Nelsen, 2006, 第 163 页) 或肯德尔测度 (Salvadori et al., 2007, 第 148 页) 或肯德尔函数 (Joe, 2014, 第 419–422 页) 是 $U=(u,v)$ 的累积分布函数 (CDF)，其中 $U$ 服从 copula 分布：$U\sim C(u,v)$。设 $Z$ 为 $C(u,v) : Z=C(u,v)$ 的随机变量，则 Kendall 函数定义为
$$F_K(z;C)=Pr(Z\leq z;U\sim C(u,v))$$
Joe (2014) 没有明确列出可直接计算任何 $C(u,v)$ 的 $F_K(z)$ 表达式，而 Nelsen (2006, p. 163) 仅列出了阿基米德 copulas 的形式。Salvadori 等人。 (2007，等式 3.47，第 147 页) 也列出了阿基米德形式；然而，Salvadori 等人。 (2007，方程 3.49，第 148 页) 还列出了一种可直接计算的形式，适用于任何 $C(u,v)$，如下所示：
$$F_K(z)=z+\int_{z}^{1} \frac{\partial C(u,t)}{\partial u} du$$
其中 $t=C^{(-1)}(u,z)$，适用于 $0 \leq z \leq 1$。
我的问题：Salvadori 如何为 Kendall 函数推导出这种形式？]]></description>
      <guid>https://stats.stackexchange.com/questions/651366/how-to-prove-this-relation-for-kendalls-distribution-function-or-kendalls-mea</guid>
      <pubDate>Thu, 18 Jul 2024 20:08:21 GMT</pubDate>
    </item>
    <item>
      <title>样本外 RMSE 大于标准差的模型是否有任何价值？</title>
      <link>https://stats.stackexchange.com/questions/651365/is-there-any-value-in-models-that-have-a-larger-out-of-sample-rmse-than-a-standa</link>
      <description><![CDATA[我使用各种回归模型、弹性网络和偏最小二乘回归 (PLSR) 根据 x 值预测 y 值。为了量化模型的性能，我们使用均方根误差 (RMSE)。
我们对整个 x 和 y 数据进行回归，以及循环式预测（类似于交叉验证）。在这种循环式预测中，本质上会遗漏一定比例的 x 和 y 数据，比如 5%，模型在剩余 95% 的 x 和 y 数据上进行训练，并预测剩余的 5%。然后，遗漏接下来 5% 的 x 和 y 数据，并使用剩余的 95% 来训练模型并预测保留的 5%。这个过程会反复进行，直到所有 y 数据都被预测为样本外数据。
我担心的是 RMSE 相对于 y 的标准偏差。当使用循环法预测 y 时，样本外 RMSE 总是大于实验 y 本身的标准差。当完全基于 x 和 y 训练模型（非循环方式）时，样本内 RMSE 明显小于 y 的标准差。
据我所知，这意味着当预测样本外 y 的值时，猜测 y 为已知 y 的平均值比使用我们的回归更准确，并且我们应该使用更少的组件/参数/复杂性。
即使这些回归对样本外的预测很差，并且 RMSE 高于标准差，它们是否有任何价值或有效性？]]></description>
      <guid>https://stats.stackexchange.com/questions/651365/is-there-any-value-in-models-that-have-a-larger-out-of-sample-rmse-than-a-standa</guid>
      <pubDate>Thu, 18 Jul 2024 20:02:57 GMT</pubDate>
    </item>
    <item>
      <title>重新创建 `lm` 分类回归</title>
      <link>https://stats.stackexchange.com/questions/651363/recreate-lm-categorical-regression</link>
      <description><![CDATA[考虑以下代码，它使用来自正确模型的数据，使用两个分类变量和一个连续变量的 lm 进行回归，没有交互作用：
set.seed(12345)

n &lt;- 100
X1 &lt;- as.factor(sample(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), n, replace = TRUE))
X2 &lt;- as.factor(sample(c(&quot;d&quot;, &quot;e&quot;), n, replace = TRUE))
X3 &lt;- rnorm(n, mean = 0, sd = 1)

effeta &lt;- 1
effetb &lt;- 2
effetc &lt;- 3
effetd &lt;- 4
effete &lt;- 5

Y &lt;- 10 + 3*X3 + effeta*(X1 == &quot;a&quot;) + effetb*(X1 == &quot;b&quot;) + effetc*(X1 == &quot;c&quot;) + effetd*(X2 == &quot;d&quot;) + effete*(X2 == &quot;e&quot;) + rnorm(n, mean = 0, sd = 1)

model &lt;- lm(Y ~ X1 + X2 + X3)
print(summary(model))

输出为：
调用：
lm(formula = Y ~ X1 + X2 + X3)

残差：
最小值 1Q 中位数 3Q 最大值
-2.74679 -0.60571 0.06521 0.67873 1.85143

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 15.06741 0.20151 74.773 &lt; 2e-16 ***
X1b 0.95913 0.23994 3.997 0.000127 ***
X1c 1.96010 0.23637 8.292 7.26e-13 ***
X2e 1.08521 0.18887 5.746 1.10e-07 ***
X3 3.03324 0.09537 31.804 &lt; 2e-16 ***
---
显著性代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

残差标准误差：95 自由度上的 0.9327
多重 R 平方：0.9194，调整后的 R 平方：0.916
F 统计量：4 和 95 DF 上的 270.8，p 值：&lt; 2.2e-16

目标是从数学上理解到底发生了什么，然后在 R 中重现它。更具体地说：

可以说 X3 系数的估计是正确的。在线来源表明 lm 将以一个级别为参考，将其效果设置为零。在一般情况下，如何提前预测哪个变量将作为参考？也许是按字母顺序？一旦估计了效果，我们如何知道它们是正确的？
虽然没有参考，但我相信 R 使用虚拟变量将分类观察结果写入矩阵中，将所有内容组合在一起，就像 Searle 中提到的那样，然后进行多元线性回归。在这种情况下，我该如何写下这样的矩阵？

让我们用 $x_3 \in \mathbb{R}^n$ 代替 x3。然后：
\begin{equation*}
x_3 =
\begin{bmatrix}
x_{1,3} \\
x_{2,3} \\
\vdots \\
x_{n,3}
\end{bmatrix}
\end{equation*&gt;
要对分类变量进行盲目计算，可以这样写：
\begin{equation*}
x_1 =
\begin{bmatrix}
x_{1,1a} &amp;&amp; x_{1,1b} &amp;&amp; x_{1,1c} \\
x_{2,1a} &amp;&amp; x_{2,1b} &amp;&amp; x_{2,1c} \\
\vdots &amp;&amp; \vdots &amp;&amp; \vdots\\
x_{n,1a} &amp;&amp; x_{n,1b} &amp;&amp; x_{n,1c} \\
\end{bmatrix};
x_2 =
\begin{bmatrix}
x_{1,1d} &amp;&amp; x_{1,1e} \\
x_{2,1d} &amp;&amp; x_{2,1e}\\
\vdots &amp;&amp; \vdots \\
x_{n,1d} &amp;&amp; x_{n,1e} \\
\end{bmatrix}
\end{equation*&gt;
两个矩阵中的所有元素均为 $0$ 或 $1$。
然后输入：
\begin{equation*}
X =
\begin{bmatrix}
1 &amp;&amp;x_{1,1a} &amp;&amp; x_{1,1b} &amp;&amp; x_{1,1c} &amp;&amp; x_{1,1d} &amp;&amp; x_{1,1e} &amp;&amp; x_{1,3} \\
1 &amp;&amp; x_{2,1a} &amp;&amp; x_{2,1b} &amp;&amp; x_{2,1c} &amp;&amp; x_{2,1d} &amp;&amp; x_{2,1e} &amp;&amp;x_{2,3} \\\\
\vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots \\
1 &amp;&amp; x_{n,1a} &amp;&amp; x_{n,1b} &amp;&amp; x_{n,1c} &amp;&amp; x_{n,1d} &amp;&amp; x_{n,1e} &amp;&amp; x_{n,3}
\end{bmatrix}
\end{equation*
这样我们就可以进行回归分析 lm(Y~X)。但这显然不是实际发生的情况。我如何去掉一些列才能得到实际发生的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/651363/recreate-lm-categorical-regression</guid>
      <pubDate>Thu, 18 Jul 2024 19:45:11 GMT</pubDate>
    </item>
    <item>
      <title>在验证性因子分析中将权重固定为 1 - 如何获得重要性 (p) 值？</title>
      <link>https://stats.stackexchange.com/questions/651362/fixed-weights-to-1-in-confirmatory-factor-analysis-how-significance-p-value</link>
      <description><![CDATA[我有一个与此主题有些相关的问题。
我现在明白了为什么在验证分析中应该将 1 的值固定到其中一条路径上，我也明白可以使用各种技巧来释放这个参数。但我感兴趣的问题是，如何用标准化解决方案计算固定路径到 1 的统计显著性。
让我们考虑一个来自这里的例子，我将使用 R 中的 Lavaan 包的示例。
library(lavaanPlot)
library(foreign) 
library(lavaan)

dat &lt;- read.spss(&quot;https://stats.idre.ucla.edu/wp-content/uploads/2018/05/SAQ.sav&quot;, to.data.frame=TRUE, use.value.labels = FALSE)

m1a &lt;- &#39; f =~ q03 + q04 + q05&#39;
onefac3items_a &lt;- cfa(m1a, data=dat) 
summary(onefac3items_a) 

这里，正如您在摘要中看到的，没有统计意义，因为路径 f~q03 是固定的。
潜在变量：
估计 Std.Err z 值 P(&gt;|z|)
f =~ 
q03 1.000 
q04 -1.139 0.073 -15.652 0.000
q05 -0.945 0.056 -16.840 0.000

摘要相同标准化：
summary(onefac3items_a,standardized=TRUE)
(...)

潜在变量：
估计 Std.Err z 值 P(&gt;|z|) Std.lv Std.all
f =~ 
q03 1.000 0.583 0.543
q04 -1.139 0.073 -15.652 0.000 -0.665 -0.701
q05 -0.945 0.056 -16.840 0.000 -0.551 -0.572

但是，当使用标准化解决方案函数时，我得到了 p 值。怎么回事，为什么？这怎么可能呢？
standardizedsolution(onefac3items_a)
lhs op rhs est.std se z pvalue ci.lower ci.upper
1 f =~ q03 0.543 0.022 25.120 0 0.500 0.585
2 f =~ q04 -0.701 0.024 -29.710 0 -0.747 -0.655
3 f =~ q05 -0.572 0.022 -26.105 0 -0.615 -0.529

同样，当我使用 plot 时，我得到了显著性星号。
lavaanPlot(model = onefac3items_a, coefs=T, covs=T, stars = c(&quot;covs&quot;,&quot;latent&quot;,&quot;regress&quot;), stand=T)

我不完全理解这种机制。为什么一条固定的、没有计算系数的路径突然与标准化解具有统计意义？这里用了什么方法？是不是程序只是改变了固定路径的位置，例如，我们暂时将路径 f~q04 固定为 1 来计算 f~q03 的系数，还是方法完全不同？
附加问题：AMOS 中可以实现相同的效果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651362/fixed-weights-to-1-in-confirmatory-factor-analysis-how-significance-p-value</guid>
      <pubDate>Thu, 18 Jul 2024 19:36:32 GMT</pubDate>
    </item>
    <item>
      <title>链式分类器中的阈值选择</title>
      <link>https://stats.stackexchange.com/questions/651361/threshold-selection-in-chain-classifier</link>
      <description><![CDATA[想象一组 $m$ 个分类器和 $N$ 个先例，每个分类器分配一个阈值 $\theta_{i,j}$，这意味着，如果分类器 $j$ 上先例 $i$ 的阈值 $t_j$ 大于 $\theta_{i,j}$，则先例通过分类器：$t_j&gt;\theta_{i,j}$
如果先例通过一个分类器，它将进入下一个分类器。在通过所有分类器后，先例被标记为$+$，如果先例被链中至少 1 个分类器丢弃，则标记为$-$。
问题是，如何为每个$m$分类器选择阈值$t_i$，以使真阳性率最大化，而假阳性率低于某个$T$？
我尝试在互联网上搜索阈值选择算法、常见的机器学习库，并将问题表述为混合整数问题，以便通过某些求解器进行求解，可惜没有成功（目前等待数学 Stackexchange)]]></description>
      <guid>https://stats.stackexchange.com/questions/651361/threshold-selection-in-chain-classifier</guid>
      <pubDate>Thu, 18 Jul 2024 19:18:37 GMT</pubDate>
    </item>
    <item>
      <title>如何使用自定义标签进行 NER</title>
      <link>https://stats.stackexchange.com/questions/651357/ner-with-custom-tags-how-to-approach</link>
      <description><![CDATA[我正在为文档构建一个“字段标记器”。基本上，一个文档（在我的情况下是提案或销售报价）会包含大量分散的实体，我们希望将每个实体与最能描述它的字段/标记进行匹配。问题是，尽管具有描述性，但字段/标签列表并不完全与现有的 NER 实体和类别类型一致。
例如，在我的案例中，一些字段/标签（标签）包括：“所有权”、“帐户类型”、“主要竞争对手”、“帐户名称”、“帐户来源”、“行业”、“帐号”、“金额”、“比较名称”、“主要合作伙伴帐户 ID”、“活跃”、“名称”、“有未结活动”、“概率 (%)”、“所有者别名”、“所有者 ID”、“有订单项”、“说明”、“帐户站点”、“预期金额”、“帐户说明”、“帐户评级”、“员工”。此类事物具有一定程度的语义含义，但可能并不多。
例如，如果文档是文本：
&quot;ABC Company&gt;&gt; 的 &lt;&lt;$500,000&gt;&gt; 机会计划于 &lt;&lt;2024 年 7 月 30 日&gt;&gt; 结束。&quot;

在此阶段，我们可以假设实体已被标记，因此我们不必处理识别原始文档中的实体究竟是什么，我希望该工具系统地检查每个标记的实体并将它们与最合适的字段/标签匹配。
由于缺乏训练数据，我最初的方法是使用零样本文本分类方法，使用 facebook/bart-large-mnli，系统地遍历实体，传递字段/标签列表作为标签，并提示要求分类。问题是我不确定模型是否在语义上理解标签本身的含义。更糟糕的是，我不确定如何将上下文传递给模型，因为简单地将其添加到提示中，一刀切地使预测变得更糟（公司名称等，之前被正确识别，开始被视为日期等）。
没有训练数据是一个限制，所以我的目标反映了这一点。它只是构建一个至少表现良好的工具。例如，如果根据模型的概率分布，最佳标签位于前 5 个最有可能的标签中，我会认为这是一个成功的分类。
有人能建议一种方法，或提供如何调整我现有的方法的建议，以获得更好的结果吗？我该如何提供上下文以增强预测？任何帮助都将不胜感激]]></description>
      <guid>https://stats.stackexchange.com/questions/651357/ner-with-custom-tags-how-to-approach</guid>
      <pubDate>Thu, 18 Jul 2024 17:17:07 GMT</pubDate>
    </item>
    <item>
      <title>生存分析中的差异随访期是否存在问题？</title>
      <link>https://stats.stackexchange.com/questions/651355/is-differential-follow-up-periods-in-survival-analysis-a-problem</link>
      <description><![CDATA[我希望比较两种不同手术方法的术后死亡率。由于技术进步，其中一种手术方法仅在另一种手术方法实施五年后才实施。然而，这两种技术现在都已普遍实施。因此，我有一组患者的随访期比另一组患者滞后五年左右。在进行 Kaplan Meier 生存分析或使用 Cox 回归计算风险比时，这是否存在问题？Kaplan Meier 图显示一种干预措施比另一种干预措施长五年。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/651355/is-differential-follow-up-periods-in-survival-analysis-a-problem</guid>
      <pubDate>Thu, 18 Jul 2024 16:58:38 GMT</pubDate>
    </item>
    <item>
      <title>g-prior 下的高斯线性模型边际似然</title>
      <link>https://stats.stackexchange.com/questions/651354/gaussian-linear-model-marginal-likelihood-under-g-prior</link>
      <description><![CDATA[考虑一个高斯线性模型，其结果向量为 $ n \times 1 $，中心预测变量矩阵为 $ X $：
$ y = \iota\alpha + X\beta + \varepsilon \quad \quad \varepsilon \sim \mathcal{N}(0, \sigma^2 I) $
先验为 $ p(\alpha, \sigma^2) = \sigma^{-2} $，g 先验为 $ p(\alpha, \sigma^2) = \sigma^{-2} $，g 先验为 $ p(\beta \mid \sigma^2) = \mathcal{N}\left(0, \sigma^2 g (X&#39;X)^{-1}\right) $.众所周知，边际似然$p(y)$可以以非常方便的形式导出
$ p(y) = \frac{\Gamma((n-1)/2)}{\sqrt{\pi}^{(n-1)}\sqrt{n}} \|{y} - \bar{{y}}\|^{-(n-1)} \times (1 + g)^{(n-1-p)/2} \times [1 + g(1 - R^2)]^{-(n-1)/2} $
其中$ R^2 $是回归$ y $时的判定系数$ X $ 和截距。这在各种来源中都有说明，例如此处 (等式 5) 和此处 (等式 10)。
是否有任何教科书或“原始论文”详细提供了此特定结果的推导？我大致了解贝叶斯共轭回归更新，但据我所知没有资料涵盖此特定设置（包括在积分出$ \beta $和$ \alpha $后，在先验不当的情况下求解$ \sigma^2 $的积分）。]]></description>
      <guid>https://stats.stackexchange.com/questions/651354/gaussian-linear-model-marginal-likelihood-under-g-prior</guid>
      <pubDate>Thu, 18 Jul 2024 16:33:43 GMT</pubDate>
    </item>
    <item>
      <title>我有一个包含 18 个生物标志物特征和一个目标变量的数据集。我想找到对目标影响最大的特征</title>
      <link>https://stats.stackexchange.com/questions/651353/i-have-a-dataset-with-18-biomarker-features-and-a-target-variable-i-want-to-fin</link>
      <description><![CDATA[我有一些疾病生物标志物数据集，其中包含来自不同样本的 18 个生物标志物读数和一个显示疾病存在与否的目标变量（特征既是分类的又是数值的）。我想看看是否只使用对目标变量影响最大的特征会提高我的预测模型的性能——目前使用 scikit learn。
有人能建议如何最好地做到这一点吗？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/651353/i-have-a-dataset-with-18-biomarker-features-and-a-target-variable-i-want-to-fin</guid>
      <pubDate>Thu, 18 Jul 2024 16:31:46 GMT</pubDate>
    </item>
    <item>
      <title>如何确定GEE模型的正确相关结构？</title>
      <link>https://stats.stackexchange.com/questions/651352/how-to-determine-correct-correlation-structure-for-gee-model</link>
      <description><![CDATA[我想使用广义估计方程 (GEE) 来建模纵向调查数据。参与者的反应是在三个时间点的两个不同治疗点记录的，但每个时间点之间的确切天数在参与者之间略有不同。从我目前所看到的情况来看，一阶自回归结构似乎最适合我的数据，我可以使用 geepack 指定反应之间的间隔。
我也看到了有关可交换相关结构的信息。但是，我的理解是，这种结构假设时间点 1 和时间点 2 之间的相关性与所有参与者的时间点 1 和时间点 3 之间的相关性相同，这对我的数据集不起作用。
我希望对如何决定哪种相关结构最合适有更深入的了解。]]></description>
      <guid>https://stats.stackexchange.com/questions/651352/how-to-determine-correct-correlation-structure-for-gee-model</guid>
      <pubDate>Thu, 18 Jul 2024 16:27:41 GMT</pubDate>
    </item>
    <item>
      <title>ICA 中的维度</title>
      <link>https://stats.stackexchange.com/questions/651350/dimensions-in-ica</link>
      <description><![CDATA[我正在阅读 Andrew Ng 关于 ICA 的笔记，其中的盲源分离示例大部分都是有意义的。本质上，我们有 $d$ 个麦克风录音 $x \in R^d$，以及 $s \in R^d$ 中的 $d$ 个独立扬声器，用 $x = As$ 表示，其中我们希望从观测 $x$ 中恢复混合矩阵 $A$ 和源系数 $s$。但是，如果 $x$ 和 $s$ 不是同一维度，即 $c$ 个录音来自 $d$ 个说话者，会发生什么情况？这仍然有意义吗？这是否仍然可处理，因为 A 现在是非方阵，$A \in R^{c \times d}$，因此系统不确定，$c &lt; d$?
同样，$A$ 是否类似于 PCA 中的主成分矩阵 $V$？
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651350/dimensions-in-ica</guid>
      <pubDate>Thu, 18 Jul 2024 14:56:55 GMT</pubDate>
    </item>
    <item>
      <title>差异中的差异还是 HLM/混合效应模型？</title>
      <link>https://stats.stackexchange.com/questions/651347/difference-in-difference-or-hlm-mixed-effects-model</link>
      <description><![CDATA[我正在评估一项高中干预措施。每年招募一组 14-16 名 9 年级学生兼职就读当地大学。我想了解这对他们的 GPA、获得的大学学分和大学入学率有何影响。对于对照组，我可以访问整个学区的数据（治疗学生来自哪里），并将使用倾向得分匹配为每个学生群体创建一个比较组，包括 6-7 个变量，并与三年前的数据（考试成绩、出勤率、纪律等）建立基线等效性。
我正在尝试找出要提出哪种分析来比较这两个组。起初，我在考虑使用差异-差异模型，但由于它们是在群体中，时间可能是我需要考虑的一个变量，因为随着每个群体的加入，程序本身可能会以更高的保真度实施。那么我是否需要一个嵌套模型，如 HLM/混合效应？或者我应该建议同时运行两个方法，一个用于解释群组，另一个用于衡量程序的整体效果？或者完全是其他方法，例如重复测量方差分析？我还担心相对较小的群组规模……]]></description>
      <guid>https://stats.stackexchange.com/questions/651347/difference-in-difference-or-hlm-mixed-effects-model</guid>
      <pubDate>Thu, 18 Jul 2024 14:46:33 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Car 包中的 Anova() 函数获取球形度结果</title>
      <link>https://stats.stackexchange.com/questions/651346/how-to-get-sphericity-results-with-anova-function-from-car-package</link>
      <description><![CDATA[我有一个不平衡的数据集。我想使用 Car 包运行混合方差分析（类型 III）。我的数据集有 3 个因素：日期（10 个级别，受试者内因素）、性别（2 个级别，受试者间因素）和组（2 个级别，受试者间因素）。我的因变量是体重。
我的数据如下所示：

我的代码如下所示：
weight_gain_SI$Sex &lt;- as.factor(weight_gain_SI$Sex)
weight_gain_SI$Group &lt;- as.factor(weight_gain_SI$Group)
weight_gain_SI$Day &lt;- as.factor(weight_gain_SI$Day)
weight_gain_SI$Rat &lt;- as.factor(weight_gain_SI$Rat)

model &lt;- lm(Weight ~ Sex*Group*Day, data = weight_gain_SI,
contrasts=list(Sex=contr.sum,Group=contr.sum, Day=contr.sum))

Anova(model, type=3)

当我运行此代码时，我没有得到 Mauchly 检验结果和 Geisser - Greenhouse 或 Huynh - Feldt 结果。我需要运行什么代码才能获得这些结果？
我也尝试运行此代码：
new_anova &lt;- Anova(model,
idata=data.frame(Day),
idesign = ~Day,
type=&quot;III&quot;)
summary(new_anova, multivariate=FALSE)

但它给了我这个输出：

这与我在网上看到的人们使用该代码获得的输出非常不同。我想要一个像这样的输出（在线网站的屏幕截图，链接：https://www.crumplab.com/rstatsforpsych/repeated-measures-anova.html）：

有人能帮我解决这个问题吗？提前谢谢了！]]></description>
      <guid>https://stats.stackexchange.com/questions/651346/how-to-get-sphericity-results-with-anova-function-from-car-package</guid>
      <pubDate>Thu, 18 Jul 2024 14:46:14 GMT</pubDate>
    </item>
    <item>
      <title>蒙特卡罗方法估计似然比密度</title>
      <link>https://stats.stackexchange.com/questions/651344/monte-carlo-method-for-likelihoods-ratio-density-estimation</link>
      <description><![CDATA[我最近开始阅读 Stephen Kay 的统计信号处理基础 - 检测理论（第二卷），其中关于似然和假设检验有些东西我不太明白。
假设我们有一个区分两个假设的问题$$\mathcal{H}_0 : x = w \\ \mathcal{H}_1 : x = v$$其中$w$和$v$是具有不同分布的随机变量（它们甚至可能“本质上”不同，例如一个是高斯分布，另一个是瑞利分布）。一种可能的测试是写出似然比$$ \Lambda (x) = \frac{p(x;\mathcal{H}_1)}{p(x;\mathcal{H}_0)} $$，并根据$ \Lambda (x) &gt; \gamma$是否为某个阈值来决定一个或另一个假设。例如，在雷达应用中，人们接收一串样本并对每个样本执行似然比测试，以确定样本是否反映了目标的存在或仅仅是噪声。评估此检测器质量的一种方法是导出所谓的ROC（接收者操作员特性）曲线，该曲线基本上是误报概率（$P_{FA}$）与检测概率（$P_D$）的关系图。
$P_{FA}$可以用$\Lambda$（我认为它本身就是一个随机变量）的概率密度函数来表示，例如Richards 的雷达信号处理基础中的公式 (15.7)：$$ P_{FA} = \int_\gamma^{+\infty} p_\Lambda(s) \, ds. $$
假设 $p(x;\mathcal{H}_1)$ 和 $p(x;\mathcal{H}_0)$ 都有明确的公式，我感兴趣的是找到 $p_\Lambda$（近似值），我正在考虑使用蒙特卡洛：即生成大量 $x$，将它们插入 $\Lambda$ 并绘制直方图。但是我对 $x$ 应该具有哪个分布感到困惑；$w$？ $v$？两者兼而有之？似乎 $x$ 可以兼而有之（同样在雷达应用中，样本可以是噪声或噪声 + 回波目标，只需将它们插入似然比中），但这在蒙特卡洛模拟中是如何编码的？这有意义吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651344/monte-carlo-method-for-likelihoods-ratio-density-estimation</guid>
      <pubDate>Thu, 18 Jul 2024 14:26:48 GMT</pubDate>
    </item>
    </channel>
</rss>