<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 01 Sep 2024 01:21:36 GMT</lastBuildDate>
    <item>
      <title>逻辑回归给出的 AUC 比朴素贝叶斯高得多的场景</title>
      <link>https://stats.stackexchange.com/questions/653685/scenarios-where-logistic-regression-gives-much-higher-auc-than-naive-bayes</link>
      <description><![CDATA[据我所知，在预测变量之间不存在协变的情况下，逻辑回归和朴素贝叶斯在预测准确性方面应该给出几乎相同的结果（以 ROC/AUC 等为衡量标准）。
我试图将此与使用逻辑回归比朴素贝叶斯对一组模拟数据的预测准确性高得多的观察结果相协调。
简而言之，我正在模拟一个非常简单的基因型-表型图模型，其中有 n 个位点（基因座）i=1...n，每个位点都有 0 或 1 个等位基因，概率为 p_i。在每个基因座上，0 等位基因对应于“野生型”，1 对应于“风险”，即第 i 个位点的 1 等位基因与比值比 OR_i &gt; 相关1. 每种基因型的疾病（或某种二元表型）风险是通过计算所有位点的 OR_i 乘积来计算的，并且对照/疾病表型的概率与某个基线值的 OR 成比例。请注意，在这个最简单的情况下，每个位点的影响在统计上是独立的，即 OR 在各个位点之间相乘。
尽管如此，对于这个基因型-表型图的简单乘法模型，我始终发现逻辑回归分类器的 AUC 比使用朴素贝叶斯的分类器高得多（我在 R 中使用 glm family=binomial 执行逻辑回归，并在 e1071 R 库中使用 naiveBayes 函数，两者均采用默认设置）。
我试图找出逻辑回归性能更好的合理解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/653685/scenarios-where-logistic-regression-gives-much-higher-auc-than-naive-bayes</guid>
      <pubDate>Sat, 31 Aug 2024 22:33:31 GMT</pubDate>
    </item>
    <item>
      <title>创建带有集群引导程序的 lm 类对象（R），或者：sensemakr 的集群引导程序（）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653681/create-lm-class-object-with-cluster-bootstrap-in-it-r-or-cluster-bootstrap-f</link>
      <description><![CDATA[我一直在尝试使用 lm 进行一些集群引导，然后可以在包 sensemakr() 中使用它。如果您不熟悉它，它是 Cinelli &amp; 中一些想法的实现Hazlett（2020 年，皇家统计学会杂志：统计方法，B 系列）。
sensemakr() 的工作方式是运行一个回归模型，该模型生成 lm 或 feols 类对象，然后可以在 sensemakr() 中使用该对象。
library(palmerpenguins)
library(sensemakr)

penguin_dat&lt;-penguins

model_lm&lt;-lm(flipper_length_mm ~ sex + body_mass_g, data=penguin_dat)
summary(model_lm)

sensitivity1&lt;-sensemakr(model=model_lm, treatment=&quot;body_mass_g&quot;, benchmark_covariates=&quot;sexmale&quot;)
summary(sensitivity1)

我需要找到一种将具有更复杂错误结构的模型传递给 sensemakr 的方法，特别是具有聚类引导程序的模型。它目前采用 lm 模型，但我读到，如果您愿意使用开发版本，您可以尝试将 feols 模型从 fixest 传递给它（请参阅：https://stackoverflow.com/questions/78363310/use-sensemakr-with-fixest-feols-model-r）。不过，我自己还没有尝试过。
以下是我考虑过的选项：

将我之前的 lm 类对象（上一个示例中的 model_lm）用于 simpleboot 中的 lm.boot()，然后在 sensemakr 中使用该对象。问题：我在 simpleboot 中找不到 cluster-bootstrap 的任何功能。我担心我可能忽略了某些东西——我希望我只是忽略了这个功能，因为它可能是最简单的解决方案。
使用 fwildclusterboot 中的 wild cluster bootstrap。我不确定它会产生什么对象，并且由于依赖性问题，它已从 CRAN 中删除，因此我无法安装它（或查看参考手册）。
使用集群引导包（如 clusbootglm 或 lmeresampler），然后尝试将结果强制转换为 lm 类型对象。这有点超出我的 R 能力，但如果 #1 不起作用，我认为它可能是唯一的选择。
作为 #3 的示例，这里有一个使用 lmtest 中的 coeftest() 和 sandwich 中的 vcovBS() 的示例——但我不知道如何将其强制转换为 lm 对象，或者即使这是不是一个好主意：

library(palmerpenguins)
library(sandwich)
library(sensemakr)
library(lmtest)

penguin_dat&lt;-penguins

model_lm&lt;-lm(flipper_length_mm ~ sex + body_mass_g, data=penguin_dat)

clustered_bootstrap_model_lm&lt;-coeftest(model_lm, vcov = vcovBS, cluster = penguin_dat$species, R = 1000)


具有讽刺意味的是， sensemakr() 也在 Stata 中实现了这一点，并且执行聚类引导然后在另一个命令中使用标准错误非常简单。
sysuse auto2.dta
regress price mpg weight rep78, vce(bootstrap, reps(100)) cluster(foreign)
est sto m1

但是 Stata 实现不允许您传递模型，而是让您在 sensemakr 本身内运行回归……当您这样做时，它不允许更复杂的错误结构。
有人对如何做到这一点有什么想法吗？我非常感谢你能给出的任何建议。
引用：
Cinelli, C., &amp; Hazlett, C. (2020). 理解敏感性：扩展遗漏变量偏差。英国皇家统计学会杂志 B 系列：统计方法，82(1)，39-67。https://doi.org/10.1111/rssb.12348
Cinelli, C.、Ferwerda, J. 和 Hazlett, C. (2020)。sensemakr：R 和 Stata 中 OLS 的敏感性分析工具。可在 SSRN 上获取：https://ssrn.com/abstract=3588978 或 http://dx.doi.org/10.2139/ssrn.3588978]]></description>
      <guid>https://stats.stackexchange.com/questions/653681/create-lm-class-object-with-cluster-bootstrap-in-it-r-or-cluster-bootstrap-f</guid>
      <pubDate>Sat, 31 Aug 2024 18:54:32 GMT</pubDate>
    </item>
    <item>
      <title>概率论初级课程第 9 版：示例 3o</title>
      <link>https://stats.stackexchange.com/questions/653680/a-first-course-in-probability-9th-edition-example-3o</link>
      <description><![CDATA[一名孤独的人犯下了罪行，他在犯罪现场留下了一些 DNA。研究恢复的 DNA 的法医指出，只能识别出五条 DNA 链，而每个无辜者独立地拥有 10-5 的概率，他们的 DNA 链与所有五条 DNA 链相匹配。地方检察官推测，犯罪者可能是该镇 100 万居民中的任何一个。这些居民中有 1 万名在过去 10 年内已从监狱释放；因此，他们的 DNA 样本已存档。在检查 DNA 文件之前，地方检察官认为 10,000 名前罪犯中的每一位都有犯下新罪行的概率 a，而其余 990,000 名居民中的每一位都有犯下新罪行的概率 b，其中 b = ca。 （也就是说，地方检察官认为，每个最近释放的罪犯是犯罪者的可能性是每个不是最近释放的罪犯的城镇成员的 c 倍。）当将分析的 DNA 与 10,000 名前罪犯的数据库进行比较时，结果发现 A. J. Jones 是唯一一个 DNA 与资料相匹配的人。假设地方检察官对 an 和 b 之间关系的估计是准确的，那么 A. J. 有罪的概率是多少？
解决方案如下，但我不明白为什么我们需要以这种方式考虑 AJ 无罪的情况下所有其他人无罪的概率。请指导我，谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/653680/a-first-course-in-probability-9th-edition-example-3o</guid>
      <pubDate>Sat, 31 Aug 2024 18:53:12 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 模型系数估计</title>
      <link>https://stats.stackexchange.com/questions/653678/estimation-of-model-coefficients-of-arima-model</link>
      <description><![CDATA[假设我在 R 中有以下 ARIMA 模型估计
&gt; arima(x = LakeHuron, order = c(0,0,1), xreg = time(LakeHuron) - 1920)

调用：
&gt; arima(x = LakeHuron, order = c(0, 0, 1), xreg = time(LakeHuron) - 1920)

调用：
arima(x = LakeHuron, order = c(0, 0, 1), xreg = time(LakeHuron) - 1920)

系数：
ma1 截距时间(LakeHuron) - 1920
0.7822 579.0821 -0.0233
s.e. 0.0651 0.1400 0.0049

但是，我还分别使用线性回归计算了外生变量和自相关残差的模型系数，如下所示
&gt; model_lm = lm(&#39;y~x&#39;, data = data.frame(x = time(LakeHuron) - 1920, y = LakeHuron))
&gt; model_Res = lm(&#39;y~x-1&#39;, data.frame(y = resid(model_lm), x = c(NA, resid(model_lm)[-length(LakeHuron)])))
&gt; summary(model_lm )

调用：
lm(formula = &quot;y~x&quot;, data = data.frame(x = time(LakeHuron) - 1920, 
y = LakeHuron))

残差：
最小值 1Q 中值 3Q 最大值 
-2.50997 -0.72726 0.00083 0.74402 2.53565 

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 579.088786 0.115047 5033.507 &lt; 2e-16 ***
x -0.024201 0.004036 -5.996 3.55e-08 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：96 个自由度上的 1.13

多重 R 平方：0.2725，调整后的 R 平方：0.2649

F 统计量：1 和 96 DF 上的 35.95，p 值：3.545e-08

&gt; summary(model_Res )

调用：
lm(formula = &quot;y~x-1&quot;, data = data.frame(y = resid(model_lm), 
x = c(NA, resid(model_lm)[-length(LakeHuron)])))

残差：
最小值 1Q 中值 3Q 最大值 
-1.94335 -0.48386 0.01758 0.43251 1.91083 

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
x 0.79084 0.06556 12.06 &lt;2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：96 个自由度上的 0.7125
（由于缺失，删除了 1 个观察值）
多重 R 平方：0.6025，调整后的 R 平方：0.5984

F 统计量：1 和 96 DF 上的 145.5，p 值：&lt; 2.2e-16

这两种方法似乎给出了类似的结果。但是我想知道从理论上讲，对于任何数据，情况是否总是如此？哪种方法更好，为什么？
我还有一个问题，我正在使用 MA 模型，在第二种方法中，我应该使用 自相关调整 SE 而不是正常 SE 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653678/estimation-of-model-coefficients-of-arima-model</guid>
      <pubDate>Sat, 31 Aug 2024 18:05:26 GMT</pubDate>
    </item>
    <item>
      <title>层次结构取决于潜在变量的层次模型</title>
      <link>https://stats.stackexchange.com/questions/653677/hierarchical-models-where-the-hierarchy-structure-depends-on-a-latent-variable</link>
      <description><![CDATA[在实际层次结构取决于潜在变量的情况下，我很难为贝叶斯推理制定层次模型。我想知道这是否可能。这是一个例子。
我有一些观察变量$\theta$，它们依赖于四个潜在变量$m$、$z_1$、$z_2$和$z_3$。这些第一个变量分布为 $m \sim {\rm DiscreteUniform}(3)$ （不确定这里的标准符号，但我的意思是 $P(m=1) = P(m=2) = P(m=3) = 1/3$）您可以将 $m$ 视为一个 RV，它确定 $z_i$ 中的哪个是“最大值”含义如下：
如果 $m=1$，则
$$
\begin{align}
z_1 &amp;\sim {\rm Uniform}(0,1) \\
z_2 &amp;\sim {\rm Uniform}(0, z_1) \\
z_3 &amp;\sim {\rm Uniform}(0, z_2)
\end{align}
$$
如果 $m=2$，则
$$
\begin{align}
z_2 &amp;\sim {\rm Uniform}(0,1) \\
z_1 &amp;\sim {\rm Uniform}(0, z_2) \\
z_3 &amp;\sim {\rm Uniform}(0, z_2)
\end{align}
$$
如果 $m=3$，则
$$
\begin{align}
z_3 &amp;\sim {\rm Uniform}(0,1) \\
z_2 &amp;\sim {\rm Uniform}(0, z_3) \\
z_1 &amp;\sim {\rm Uniform}(0, z_2)
\end{align}
$$
这里的想法是，$z_i$中的一个应该具有最大值，并且没有$z_i$可以大于相邻的（这是我的特征我对整个构造过程非常感兴趣）。我认为，这些 $z_i$ 继续以一种对当前问题不重要的方式确定我观察到的变量。
有没有办法将其表述为适当的分层模型，根据 $m$ 的值具有不同的“分支”？或者这真的是竞争分层模型之间贝叶斯模型选择的问题？无论哪种情况，我都会很感激任何见解或资源建议。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653677/hierarchical-models-where-the-hierarchy-structure-depends-on-a-latent-variable</guid>
      <pubDate>Sat, 31 Aug 2024 17:58:08 GMT</pubDate>
    </item>
    <item>
      <title>蒙特卡洛积分方法利用黑匣子给出的一组代表点</title>
      <link>https://stats.stackexchange.com/questions/653676/monte-carlo-integration-methods-utilizing-a-set-of-representative-points-given-b</link>
      <description><![CDATA[考虑对可能离散的多峰分布进行函数积分的任务。假设一个黑匣子给了我一组独立但分布相同的点，这些点对应于密度/概率最高的模式，但不一定成比例。*
蒙特卡罗方法中是否有一个研究领域可以从这样的集合中受益，同时保留收敛保证？有哪些方法？这里的“收敛保证”是指该方法的估计量是一致的/无偏的。
如果它有助于回答或简化问题，可以进一步假设：

可以从这个未知分布中抽取更多样本，并且
多峰分布是离散的。

*也就是说，它们不是来自目标分布的样本，但恰好聚集在模式周围。更正式地说，从中抽取此代表集的底层分布的密度是未知的。一个梦想的场景是模式搜索算法，保证从分布的精确模式中采样。
例如，Metropolis-Hastings肯定可以从这样的初始化中受益。
一个非示例是重要性采样，因为我们无法获得此类样本集的密度。
类似地，并行回火也可以从概率上获益，但顺序蒙特卡洛采样器则不行。]]></description>
      <guid>https://stats.stackexchange.com/questions/653676/monte-carlo-integration-methods-utilizing-a-set-of-representative-points-given-b</guid>
      <pubDate>Sat, 31 Aug 2024 17:40:22 GMT</pubDate>
    </item>
    <item>
      <title>说统计模型是位置家族是什么意思？</title>
      <link>https://stats.stackexchange.com/questions/653675/what-does-it-mean-to-say-that-a-statistical-model-is-a-location-family</link>
      <description><![CDATA[我想知道说统计模型是位置族是什么意思。查看了一些定义，我得出了位置族定义的三种可能解释。
设$(\mathbb{R},\mathfrak{B}_\mathbb{R},P_\theta )_{\theta\in\Theta }$为一个统计模型，其中$\mathfrak{B}_\mathbb{R}$表示$\mathbb{R}$的 Borel $\sigma$-代数。对于所有 $\theta$，定义 $F_\theta :\mathbb{R\to R}$ 为 $F_\theta (x):=P_\theta ((-\infty ,x])$。
我的问题：下列哪个定义是正确的？
定义 1： 我们说 $(\mathbb{R},\mathfrak{B}_\mathbb{R},P_\theta )_{\theta\in\Theta }$ 是一个位置族，如果对于任何 $\theta\in\Theta$ 并且 $a\in\mathbb{R}$ 函数 $F:\mathbb{R}\to \mathbb{R}$ 由 $F(x):=F\!_{\theta} (x+a)$ 给出，属于集合 $\{F_\theta\}_{\theta\in\Theta }$。
定义 2： 我们说 $(\mathbb{R},\mathfrak{B}_\mathbb{R},P_\theta )_{\theta\in\Theta }$ 是一个位置族，如果存在 $\theta_0\in\Theta$，使得对于所有 $\theta\in\Theta$，都有 $a_\theta \in\mathbb{R}$，使得对于所有 $x\in\mathbb{R}$，都有 $F_\theta (x)=F_{\theta_0}(x-a_\theta )$。
定义 3：我们说 $(\mathbb{R},\mathfrak{B}_\mathbb{R},P_\theta )_{\theta\in\Theta }$ 是位置族，如果存在 $\theta_0\in\Theta$，使得以下命题为真：

对于所有 $a\in\mathbb{R}$，由 $F(x):=F\!_{\theta_0} (x+a)$ 给出的函数 $F:\mathbb{R}\to \mathbb{R}$ 属于集合 $\{F_\theta\}_{\theta\in\Theta }$；$\theta\in\Theta$ 存在 $a_\theta \in\mathbb{R}$ 使得对于所有 $x\in\mathbb{R}$，$F_\theta (x)=F_{\theta_0}(x-a_\theta )$。

例如，使用定义 2，很容易得出统计模型 $ (\mathbb{R},\mathfrak{B}_\mathbb{R},N(\mu ,\sigma ^2))_{\mu \in\mathbb{R}}$（其中 $\sigma^2&gt;0$ 固定）是一个位置系列。]]></description>
      <guid>https://stats.stackexchange.com/questions/653675/what-does-it-mean-to-say-that-a-statistical-model-is-a-location-family</guid>
      <pubDate>Sat, 31 Aug 2024 17:25:13 GMT</pubDate>
    </item>
    <item>
      <title>正态分布是如何由现实世界数据构成的</title>
      <link>https://stats.stackexchange.com/questions/653672/how-is-the-normal-distribution-made-from-real-world-data</link>
      <description><![CDATA[我是一名中学生，我正在尝试理解人们在现实世界中如何创建和应用正态分布。
从我有限的知识来看，常识告诉我，他们收集原始数据，然后继续从中创建一个直方图，如果这个直方图足够接近完美的钟形曲线（我假设他们使用其他统计指标（如偏度等）来确定这一点），然后他们使用标准偏差和平均值并将其插入正态分布函数以获得实际的钟形曲线。
因为即使身高之类的东西是正态分布的，我实际上假设在现实世界中，当有人收集数据时，他们可能会发现身高可能不是正态分布的（例如，一个有很多孩子的城镇等）。所以在我的脑海里，我假设科学家首先制作一个直方图来检查它是否大致接近钟形曲线。]]></description>
      <guid>https://stats.stackexchange.com/questions/653672/how-is-the-normal-distribution-made-from-real-world-data</guid>
      <pubDate>Sat, 31 Aug 2024 12:24:07 GMT</pubDate>
    </item>
    <item>
      <title>与 GARCH-DCC 方法相比，使用多元滤波历史模拟和单变量 GARCH 模型的优缺点是什么？</title>
      <link>https://stats.stackexchange.com/questions/653668/what-are-the-pros-and-cons-of-using-multivariate-filtered-historical-simulation</link>
      <description><![CDATA[我正在评估股票投资组合的市场风险，并在 MATLAB 文档中看到了一个使用多元过滤历史模拟技术的示例：
https://it.mathworks.com/help/econ/using-bootstrapping-and-filtered-historical-simulation-to-evaluate-market-risk.html
这种方法将单变量 GARCH 模型与资产收益概率分布的非参数规范相结合。 FHS 允许通过引导标准化残差和模拟未来回报来生成预测。
我还知道 GARCH-DCC（动态条件相关性）方法，该方法对资产回报之间的时变相关性进行建模。我有兴趣了解使用 FHS 和 GARCH 模型与 GARCH-DCC 方法的优缺点。
每种方法的优点和局限性是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/653668/what-are-the-pros-and-cons-of-using-multivariate-filtered-historical-simulation</guid>
      <pubDate>Sat, 31 Aug 2024 09:51:03 GMT</pubDate>
    </item>
    <item>
      <title>在 MCMC 中转换变量以获得与提议相匹配的先验分布</title>
      <link>https://stats.stackexchange.com/questions/653598/transforming-variables-within-mcmc-to-get-the-prior-distribution-to-match-propos</link>
      <description><![CDATA[我正在做贝叶斯 MCMC，我建议使用一些权重，比如狄利克雷分布中的 a_1:a_5，以确保总和为 1。但是，先前的（Beta）分布是基于这些权重的一些计算，b_1:b_5。我的理解是我应该进行转换。以下是 a 和 b 之间的关系：
a_1=b_1
a_2=(1-b_1)(b_2)
a_3=(1-b_1)(1-b_2)b_3
a_4=(1-b_1)(1-b_2)(1-b_3)b_4
a_5=(1-b_1)(1-b_2)(1-b_3)(1-b_4)b_5

我发现雅可比矩阵为：$(a - 1)^4 \times (b - 1)^3 \times (c - 1)^2 \times (d - 1)$
但我不确定接下来该怎么做。当找到先验密度时，我是否将输入乘以这个雅可比矩阵？下面是我的 R 代码，好像我忽略了先前和提议之间的不匹配。
 a&lt;-rDirichlet.acomp(1,mcmc_chain_weights[i,1:5]*(tuning_parameter))
b=rep(NA,5)
b[1]&lt;-a[1]
b[2]&lt;-a[2]/((1-b[1]))
b[3]&lt;-a[3]/((1-b[1])*(1-b[2]))
b[4]&lt;-a[4]/((1-b[1])*(1-b[2])*(1-b[3]))
b[5]&lt;-a[5]/((1-b[1])*(1-b[2])*(1-b[3])*(1-b[4]))

Hastings_ratio&lt;-L()*dbeta(b,1,tau)*dDirichlet(a_previous,alpha=a) / ...

请注意，tau 是一个常数，我将似然函数留空，因为它在这里无关紧要。任何帮助都将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653598/transforming-variables-within-mcmc-to-get-the-prior-distribution-to-match-propos</guid>
      <pubDate>Fri, 30 Aug 2024 03:22:33 GMT</pubDate>
    </item>
    <item>
      <title>测量两组内部距离差异的重要性</title>
      <link>https://stats.stackexchange.com/questions/653500/measure-the-significance-of-differences-in-internal-distances-in-two-groups</link>
      <description><![CDATA[我是一名语言学家，正在研究 169 名挪威女性作家和 169 名挪威男性作家的语法变异（使用树库），该变异基于八个屈折和句法属性。这八个属性是两种表达类别的备选方式之间的八个二元选择，称为“保守”和“激进”。对于给定属性，记录的是作者保守选择的百分比。因此，它将是 0 到 100 之间的值。因此，这八个属性定义了作者分布的八维空间。然后可以像往常一样计算任何两个作者之间的（欧几里得）距离，取点坐标平方差之和的平方根。两组之间的一个显着差异（在各个属性之间都稳定）是，在八维可能性空间中，男性比女性分散得更多，女性聚集得更密集，选择组合的变化较少。我计算一个群体的密度作为内部距离的平均值——即取每个群体成员与群体中其他作者的平均距离的平均值。该图显示了女性和男性与同性别其他成员的平均距离。男性的平均值为 69（标准差 16.6），女性的平均值为 60（标准差 15.3）。t 检验可以极高置信度地得出显著性，但——不是统计学家——我对 t 检验的适用性表示怀疑。群体成员的数值是相互依赖的，因此我们测试的是性别群体作为整体的属性，而不是两个群体中每个成员的可比属性。因此，我的问题是：是否有适合这种数据的显著性检验——或者我错误地认为 t 检验不合适（这很好）？评论中提到的表格：



作者
F1
F2
F3
F4
F5
F6
F7
F8




author1
92,1
98
 99,2
26,7
71,3
56,8
80
22,7


author2
55,2
73
93,1
6,4
30,9
49,2
37,2
23,8


作者3
97
99,7
100
49
99,1
62,8
86
39,7


作者4
99,5
98,7
100
6,5
50, 3
61,8
51
20,6


author5
23,2
37,9
99,9
5,6
27,2
78,4
57,8
28



]]></description>
      <guid>https://stats.stackexchange.com/questions/653500/measure-the-significance-of-differences-in-internal-distances-in-two-groups</guid>
      <pubDate>Wed, 28 Aug 2024 18:39:51 GMT</pubDate>
    </item>
    <item>
      <title>用于建模财务回报的 AR(1) 过程的时间缩放</title>
      <link>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</link>
      <description><![CDATA[过程：
考虑一个均值为零的 AR(1) 过程，*
$\lambda_t = \kappa \cdot \lambda_{t-1} + \omega_t$，
其中 $\kappa = 0.9$，$\omega \sim N(0, \sigma_{\omega}^2)$，并且 $\sigma_{\omega}^2 = 0.00027$。 $\lambda_0$ 的初始值取自平稳分布 $N \left(0, \frac{\sigma_{\omega}^2}{(1-\kappa^2)} \right)$
我使用此过程生成长度为 $T=672$ 的样本。
* 我知道，对于股票收益建模而言，均值为零是不现实的，但我的问题并不取决于此选择。

上述时间序列应解释为每月收益（以百分点表示），即 672 个月的观测值。
问题：
什么是合适的参数值生成总共 14,112 个每日观测值（即$672 \times 21$，如果我们假设一个月内有 21 个交易日）以符合上述（每月）流程？月回报率是给定月份内所有 21 天回报率的累计乘积。
尝试（在 R 中）：
DAYS &lt;- 21
T &lt;- 672
kappa &lt;- 0.9
variance_omega &lt;- 0.00027

get_init_lambda &lt;- function(variance) return(rnorm(n = 1, mean = 0, sd = sqrt(variance / (1-(kappa)^2))))

#### 月度分析

set.seed(1234)

lambda_T &lt;- vector(mode = &quot;numeric&quot;, length = T)

lambda_shock &lt;- rnorm(T, mean = 0, sd = sqrt(variance_omega))

lambda_T[1] &lt;- kappa * get_init_lambda(variance_omega) + lambda_shock[1]
for(i in 2:T) lambda_T[i] &lt;- kappa * lambda_T[i-1] + lambda_shock[i]

acf(lambda_T)$acf[2]
# [1] 0.9064949 # 符合预期

var(lambda_T)
# [1] 0.001547795

#### 每日分析

set.seed(1234)

kappa_daily &lt;- 0.90 # ??? 如何设置 kappa_daily，使月收益 AC = 0.9？

lambda_T_daily &lt;- vector(mode = &quot;numeric&quot;, length = T * DAYS)

lambda_shock_daily &lt;- rnorm(T * DAYS, mean = 0, sd = sqrt(variance_omega / DAYS))

lambda_T_daily[1] &lt;- kappa_daily * get_init_lambda(variance_omega / DAYS) + lambda_T_daily[1]
for(i in 2:(T * DAYS)) lambda_T_daily[i] &lt;- kappa_daily * lambda_T_daily[i-1] + lambda_shock_daily[i]

# 检索月末指数；假设每个月有 21 个交易日
begin_month &lt;- seq(1, T * DAYS, 21)
end_month &lt;- c(tail(begin_month, -1) - 1, T * DAYS)

lambda_monthly_aggregate &lt;- vector(mode = &quot;numeric&quot;, length = T)

for(i in 1:T){
month_ind &lt;- (begin_month[i]):(end_month[i])

daily_ret_within_month &lt;- 0.01*lambda_T_daily[month_ind] # 收益以 % 表示
monthly_return &lt;- 100*(cumprod(1+daily_ret_within_month) - 1) # 累计每日收益

lambda_monthly_aggregate[i] &lt;- monthly_return[DAYS] # 检索累计。 21 天后返回
}

# 与上述值不相同：自相关性太低，mth 方差返回值太高！
&gt; acf(lambda_monthly_aggregate)$acf[2]
[1] 0.2988249

var(lambda_monthly_aggregate)
[1] 0.01494742

]]></description>
      <guid>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</guid>
      <pubDate>Wed, 14 Aug 2024 16:01:50 GMT</pubDate>
    </item>
    <item>
      <title>将对数链接应用于分位数回归</title>
      <link>https://stats.stackexchange.com/questions/652233/applying-log-link-to-quantile-regression</link>
      <description><![CDATA[我正在研究分位数回归，我开始思考如何实现对数链接（因为我使用的是正界数据）。我听说分位数回归在变换下是等变的，所以我开始思考，即使在线性回归中情况并非如此，对响应变量进行对数处理是否能产生与对数链接相同的效果？这有效吗？还是我运用了错误的想法？我注意到，在 R 中的“rq”函数中似乎没有一种简单的方法来指定对数链接，所以我正在尝试寻找一种解决方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/652233/applying-log-link-to-quantile-regression</guid>
      <pubDate>Fri, 02 Aug 2024 23:12:23 GMT</pubDate>
    </item>
    <item>
      <title>空间数据的 EM 算法</title>
      <link>https://stats.stackexchange.com/questions/650794/em-algorithm-for-spatial-data</link>
      <description><![CDATA[我对地理统计学（空间数据建模）非常陌生，有一些问题：
1- 我发现在许多文献中，空间随机场被划分为空间箱。也就是说，假设我对建模在不同位置测量的锌浓度感兴趣。然后，我们测量所有位置对之间的距离。之后，我们根据观测值之间的距离将观测值划分为空间滞后。例如，第一个滞后包含一对位置，它们之间的空间距离为 10 米，依此类推。我的问题是，我们为什么要执行此步骤？
2- 我们可以使用 EM 将高斯混合模型拟合到数据中，而无需将它们划分为空间箱吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650794/em-algorithm-for-spatial-data</guid>
      <pubDate>Wed, 10 Jul 2024 10:19:19 GMT</pubDate>
    </item>
    <item>
      <title>泊松减去一个常数仍然是泊松吗？</title>
      <link>https://stats.stackexchange.com/questions/649069/is-a-poisson-minus-a-constant-still-a-poisson</link>
      <description><![CDATA[我正在处理一个过程，其中我期望我的变量服从泊松分布。但是，由于与比例有关的原因，我获得的值的最小值为 11。
我注意到，当我使用 R 函数（例如 fitdistrplus::fitdist）估计我的数据与泊松分布的拟合度时，我的数据最适合泊松分布（遵循 AIC 值），但只有当我从观测向量中减去最小值 11 时（这样做的理由是泊松中的值从零开始）。
例如，以下内容与泊松分布的拟合度很差：
obs &lt;- c(15, 15, 13, 14, 13, 12, 12, 14, 14, 12, 11, 13, 11, 12, 12, 
13, 14, 14, 13, 11, 12, 14, 17, 12, 14, 12, 12, 12, 12, 
13, 16, 15, 15, 17, 13, 13, 13, 13, 14, 14, 13, 15)
fitdist(obs, &quot;pois&quot;)

但减去最小值后，拟合效果更好。
fitdist(obs-11, &quot;pois&quot;)

然而，这当然会改变 lambda 参数，在泊松分布中，我相信这也会改变分布的形状。我不仅不确定我的转换是否正确，而且如果不正确，为什么拟合度会提高。
有人可以指出关于这个主题的参考资料，以了解我的转换是否正确吗？即泊松减常数是否仍以泊松分布？
编辑：为了澄清起见，我处理的变量是基因组中新生突变的发生率。这些是罕见事件，通常被建模为泊松过程。在每个单倍体基因组和代的突变数量尺度上，每个单倍体基因组和代（obs向量）观察到几十个突变。这就是最小值为 11 的原因。但是，请注意，这里有尺度的影响。在二倍体基因组的尺度上，obs 中的值将会翻倍，而在每个核苷酸位点（而不是每个基因组）的尺度上，obs 中的值都会非常小（例如 ~6*10e-8），以至于会四舍五入为零。]]></description>
      <guid>https://stats.stackexchange.com/questions/649069/is-a-poisson-minus-a-constant-still-a-poisson</guid>
      <pubDate>Tue, 11 Jun 2024 22:57:56 GMT</pubDate>
    </item>
    </channel>
</rss>