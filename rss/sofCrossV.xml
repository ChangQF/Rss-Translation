<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 13 Oct 2024 01:20:11 GMT</lastBuildDate>
    <item>
      <title>条件不平衡独立变量是回归中的一个问题吗？</title>
      <link>https://stats.stackexchange.com/questions/655709/are-conditional-unbalanced-independent-variables-an-issue-in-regression</link>
      <description><![CDATA[我不确定这种现象是否有名称 - 因此我将对其进行描述：
描述
我有一个具有以下特征的数据集：

Y：平衡二元因变量（例如就业/失业）
X1：平衡二元自变量（例如治疗/控制）
X2：平衡分类自变量（例如国家）

X1 是感兴趣的变量，目标是估计因果影响而不是预测。
问题
但是，如果我将 X1 与 X2 分组（例如按国家/地区划分治疗和未治疗），我可以观察到子组不平衡。在一些国家，大多数数据来自治疗组，在其他国家，大多数数据来自未治疗组，而在一些国家，数据是平衡的。
问题：

这个问题有名字吗？
条件子组不平衡会成为 x1 系数/估计量及其重要性的问题吗？如果一个子组由 100% 控制或治疗单位组成，会发生什么？
如果是，为什么或何时会出现这种情况？
如果是，我该怎么做才能避免这种情况？我应该删除不平衡的组/国家吗？我应该添加交互变量吗？

PS：我找到了很多关于不平衡独立变量或因变量的来源 - 但我很难找到关于“条件独立变量”的来源。]]></description>
      <guid>https://stats.stackexchange.com/questions/655709/are-conditional-unbalanced-independent-variables-an-issue-in-regression</guid>
      <pubDate>Sun, 13 Oct 2024 00:15:01 GMT</pubDate>
    </item>
    <item>
      <title>仅使用信息几何即可访问的统计问题示例</title>
      <link>https://stats.stackexchange.com/questions/655707/examples-of-problems-in-statistics-accessible-only-using-information-geometry</link>
      <description><![CDATA[我只是好奇，统计学中是否存在一些问题的例子，这些问题确实可以通过信息几何来解决，而完全避免使用几何的证明尚不清楚。换句话说，通过将问题中的统计模型$\mathcal{P}$视为统计流形，然后使用微分几何中的结果来解决的问题，而实际上不使用流形结构的证明尚未发现。]]></description>
      <guid>https://stats.stackexchange.com/questions/655707/examples-of-problems-in-statistics-accessible-only-using-information-geometry</guid>
      <pubDate>Sat, 12 Oct 2024 21:32:26 GMT</pubDate>
    </item>
    <item>
      <title>是 $I(X>\infty) = 0$ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/655705/is-ix-infty-0</link>
      <description><![CDATA[$\boxed{\text{设 X 为一个随机变量，其值可从 {0,1,2,...} 中取值。证明 } I(X &gt; \infty) = 0}$
此处，给定一个集合 $A$，指示函数 $I(A)$ 定义为
$$ I(A)= \begin{cases} 
1 &amp; X\in A \\
0 &amp; X \not \in A 
\end{cases}
$$
该陈述正确吗？从直觉上来说，这种陈述对我来说是有道理的，因为没有数字大于无穷大。但是如果你取某个任意大的数字 $n$，可能存在 $X \geq n$，这使得该陈述为假。但是对于任何任意大的数字 $n，n &lt; \infty$。
如果这个陈述是正确的，我该如何严格证明它？]]></description>
      <guid>https://stats.stackexchange.com/questions/655705/is-ix-infty-0</guid>
      <pubDate>Sat, 12 Oct 2024 18:30:24 GMT</pubDate>
    </item>
    <item>
      <title>条件概率作业问题</title>
      <link>https://stats.stackexchange.com/questions/655701/conditional-probability-homework-question</link>
      <description><![CDATA[多年来，我完全没有使用过统计数据，现在我选修了一门统计课程，并且再次讨厌解读条件概率问题。这一篇是关于选举预测的。
因此，让我们定义以下事件及其概率

$p(H)$ = 0.53 是哈里斯赢得选举的概率
$p(H^c)$ = 0.47 是特朗普赢得选举的概率
$p(P)$ = 0.5 是哈里斯赢得宾夕法尼亚州的概率
$p(H \vert P^c)$ = 0.14 是哈里斯在输掉宾夕法尼亚州的情况下赢得选举的概率

现在我被要求找到$p(H^c|P)$，假设哈里斯赢得宾夕法尼亚州，她输掉选举的概率。
我不确定如何处理这个问题。即使与整个答案相比，我也会接受提示...]]></description>
      <guid>https://stats.stackexchange.com/questions/655701/conditional-probability-homework-question</guid>
      <pubDate>Sat, 12 Oct 2024 18:06:43 GMT</pubDate>
    </item>
    <item>
      <title>不平衡数据集和二元分类</title>
      <link>https://stats.stackexchange.com/questions/655700/imbalanced-dataset-and-binary-classification</link>
      <description><![CDATA[我的数据集中有 31657 个数据，每个数据都有一个二进制输出（1 或 0）。
问题是输出 1 只出现了 886/31657 次，而输出 0 出现了 30771/31657 次。
由于我的数据集不平衡，验证集和训练集也不平衡，因为它们是在 LSTM 神经网络中随机抽取的。
我尝试为每个输出分配一个权重（输出 0 为 1，输出 1 为 5），但有没有特定的方法来分配这些权重？
我还尝试以平衡的方式划分验证集和训练集（考虑权重），但结果并不好
我该怎么办？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/655700/imbalanced-dataset-and-binary-classification</guid>
      <pubDate>Sat, 12 Oct 2024 18:04:59 GMT</pubDate>
    </item>
    <item>
      <title>Nate Silver 的 p(doom) 计算</title>
      <link>https://stats.stackexchange.com/questions/655697/nate-silvers-pdoom-calculation</link>
      <description><![CDATA[在他的最新著作《边缘》中，Nate Silver 概述了一种“贝叶斯”计算方法，用于计算核战争的概率，其前提是自 1946 年以来我们从未目睹过核武器的使用。我发现他的设置和解决方案有点模糊，我想遵循他的逻辑。
他写道：

自 1945 年以来，核武器从未在冲突中使用过，我们应该对此感到多么欣慰？假设在 1946 年 1 月 1 日，你召集了一个由三位专家组成的小组来预测再次发生核爆炸的可能性。Peter Pessimist 告诉你，每年使用核武器的可能性为 10%。Ollie Optimist 说可能性只有 0.1%。而 Mary Middleground 估计可能性为 1%。由于没有真正的证据，你只能将他们的预测平均下来，得出每年 3.7% 的概率。这令人恐惧：这意味着在未来二十年内，核武器被使用的可能性更大。这有助于解释为什么冯·诺依曼等人在二战后认为文明可能不会再存在太久。但在 78 年（1946 年至 2023 年）没有使用核武器之后，我们可以更新我们分配给每个分析师的估计的权重；这是贝叶斯定理的直接应用。例如，我们可以说彼得·佩西米斯特可能是错的。如果真的有 10% 的年核战争概率，那么我们迄今为止仅凭运气就避免核战争的概率不到 1/3,000。然而，我们没有足够的证据来对玛丽·米德尔格兰特的估计做出太多评论。她说每年发生核战争的概率是1/100，而我们只有七十八年的数据来反驳她。 （没错，一个好的贝叶斯主义者会稍微降低她的预测，同时增加我们对 Ollie Optimist 的理论的信任度。）在长崎核爆 78 年后，我们修订后的贝叶斯估计是每年发生核战争的可能性约为 0.35%。&quot;

他附上了一张我一直试图重现的图表：

我对 Nate 的步骤有点困惑，以为我可能想太多了。他似乎在更新他的前因，即三位“专家”的平均值((乐观派 0.1% + 中间派 1.0% + 悲观派 10%)/3 = 3.7%)，通过观察随后 78 年的事件结果，对每位专家（称他们为$p_1, p_2, p_3$）进行加权。也就是说，$p$（$n$ 年内未发生的事件 | 事件概率）= $(1-{p_i})^n$
为了复制此结果，我为每个 $n$ 从 0 到 $N$=78 的专家计算了新的权重：
\begin{align}
p&#39;(n) &amp;= \sum_{i=1}^3\frac{p_i(1-p_i)^n}{Z(n)} \\
Z(n) &amp;= \sum_{i=1}^3(1-p_i)^n
\end{align&gt;
然而，这与 Nate 的情节不太相符：

由于我的信封背面没有起作用，我想知道我是不是走运了，Nate 是否对此进行了更复杂的建模？我很想让这个解决方案更正式，并使这些线条相匹配。欢迎任何意见！谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655697/nate-silvers-pdoom-calculation</guid>
      <pubDate>Sat, 12 Oct 2024 16:57:55 GMT</pubDate>
    </item>
    <item>
      <title>测量分布均匀性[重复]</title>
      <link>https://stats.stackexchange.com/questions/655696/measure-for-distribution-uniformity</link>
      <description><![CDATA[是否有某种度量和计算方法，以区分均匀分布在范围内的值和具有许多峰值（其数量）的值？
例如，区分如下序列：
示例 1：1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2

带有
示例 2：1、1、1、1、1、2、1、2、2、2、2、2、1、2、1、2、1、2、1、1、1、1、 1, 2, 2, 2, 2 

和
示例 3：1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2

我正在寻找一个指标，当值（这里假设为 2）均匀分布在序列中时，该指标接近 0，当所有这些值集中在一个地方时，该指标接近 1；当我有像示例 2 中那样的本地组时，我希望该指标接近 0.5，而在示例 3 中，我希望该指标接近 0.7。这些值只是为了解释逻辑，当然，它们是近似的。
例如，如果问题是关于一个峰值，我会使用平均值和方差。但如果有很多峰值，情况就不同了。
是否存在这样的指标（或类似指标）？]]></description>
      <guid>https://stats.stackexchange.com/questions/655696/measure-for-distribution-uniformity</guid>
      <pubDate>Sat, 12 Oct 2024 16:29:13 GMT</pubDate>
    </item>
    <item>
      <title>Z 分数和 Z 检验</title>
      <link>https://stats.stackexchange.com/questions/655694/z-score-and-z-test</link>
      <description><![CDATA[我不明白 Z 检验中 sqrt(n) 的工作原理/目的。Z 分数为 0.7 似乎不错，因为样本平均值小于总体平均值的一个标准差，并且 p 值根据表格为 0.7580。但是当乘以 sqrt(50) 时，它会变成一个很大的数字，如 4.9，而表格中的值非常小，我认为“如果 p 很低，Ho 必须消失”。我做错了什么/想错了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655694/z-score-and-z-test</guid>
      <pubDate>Sat, 12 Oct 2024 16:03:52 GMT</pubDate>
    </item>
    <item>
      <title>在所有数据集中确定正确的输出，其中我们只知道错误率，并且输出具有不均匀分布，这是实际工程问题</title>
      <link>https://stats.stackexchange.com/questions/655687/determining-the-correct-output-among-all-data-set-where-we-only-know-error-rate</link>
      <description><![CDATA[我遇到了一个工程问题，但我没有高级统计背景。让我试着解释一下我的情况。
假设我有一台机器，它接受输入并在内部进行一些计算后给出输出。
机器的属性：

机器总是接受完全相同的输入（我们不知道输入）。

我们的机器也有 30% 的错误率

输出具有非均匀分布。

当我们运行我们的机器时，它有时会给出错误的输出，正如我所说，这些错误的输出可能非常不同，但只有一个正确的输出。在这里，我们不知道输入，只看到机器的输出，并且有信息表明机器也有 30% 的错误率，并且输出具有非均匀分布。

我们可以随心所欲地运行机器。


我想用最少的试验来确定正确的输出。所以我在研究一种在向最终用户提供正确输出之前要执行的技术。

例如，假设我的机器进行 4+6 的计算，那么它的输出可能是 560,11,26,3,1563567,67,9,10,34 ... 我写这个例子是因为即使它有 30% 的错误率，第一个输出可能直到某个时候才包含正确的输出。更重要的是，这是非常低的概率，但一些不正确的输出可能会重复并欺骗我们相信它是正确的。然而，这是最糟糕的情况。

当我在互联网上进行研究时，我遇到了 Walds 的序贯概率比检验，但我不确定它是否是解决我问题的正确工具。更重要的是，我无法理解如何应用该技术。您能否与我分享您的知识来解决我的问题？统计学中是否有任何方法可以将其应用于我的问题。如果 SPRT 是正确的，那么请帮助我应用它]]></description>
      <guid>https://stats.stackexchange.com/questions/655687/determining-the-correct-output-among-all-data-set-where-we-only-know-error-rate</guid>
      <pubDate>Sat, 12 Oct 2024 13:07:12 GMT</pubDate>
    </item>
    <item>
      <title>如果倾向评分匹配 (PSM) -DiD 中的治疗组大于对照组，应该怎么办</title>
      <link>https://stats.stackexchange.com/questions/655677/what-should-it-be-if-the-treatment-group-is-larger-than-control-groups-in-propen</link>
      <description><![CDATA[为了进行差异分析（DiD），以模仿随机对照试验，我们通常使用倾向得分匹配（PSM）在事件日期之前消除对照组和治疗组之间的差异。
通常我们会有一个小的治疗组和大的对照组，我们只需遵循原来的步骤即可。
但今天我遇到了一些不同的事情：
当我尝试检查法律A对澳大利亚所有上市公司的影响时，我应该比较该法律A对澳大利亚公司和新西兰公司的影响（因为新西兰在那段时间没有实施法律A）
事实上，澳大利亚的公司比新西兰多，这意味着治疗组比对照组大。
我尝试过1：2、1：3匹配，但匹配失败（匹配后治疗组和对照组之间存在差异）。只有 1:1 匹配效果良好。
在使用 1:1 匹配运行回归分析后，我仍然发现法律 A 对澳大利亚公司的影响比新西兰公司的影响更大（通过使用 DiD）
我想知道我的 1:1 设置是否可以接受，因为这意味着由于新西兰公司数量较少，并非所有澳大利亚公司都会在匹配样本中匹配。]]></description>
      <guid>https://stats.stackexchange.com/questions/655677/what-should-it-be-if-the-treatment-group-is-larger-than-control-groups-in-propen</guid>
      <pubDate>Sat, 12 Oct 2024 04:51:39 GMT</pubDate>
    </item>
    <item>
      <title>报告缺失数据的分类器准确率</title>
      <link>https://stats.stackexchange.com/questions/655674/report-classifier-accuracy-with-missing-data</link>
      <description><![CDATA[假设我们正在读取血压。有些读数已损坏且无法使用。然后我们训练二元分类器来检测高血压。当我们的模型无法使用某些数据时，实验设计理论对报告分类器准确性有何看法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655674/report-classifier-accuracy-with-missing-data</guid>
      <pubDate>Sat, 12 Oct 2024 00:40:54 GMT</pubDate>
    </item>
    <item>
      <title>需要进行多少次测试（以及必须通过多少次）才能保证我的软件在 90% 的时间内以 95% 的置信度正常运行？</title>
      <link>https://stats.stackexchange.com/questions/655671/how-many-test-executions-are-required-and-how-many-must-pass-to-say-my-softwar</link>
      <description><![CDATA[我有一些软件，其运行方式不确定。根据未知的外部因素，对代码运行测试可能会导致测试通过或失败。假设由于这些因素，测试通过或失败的几率相等，我必须运行测试多少次，软件必须通过测试多少次，这样我才能有 95% 的信心说软件在 90% 的时间内按预期运行？
编辑：假设外部因素导致测试失败的几率未知，而不是测试通过/失败相等。]]></description>
      <guid>https://stats.stackexchange.com/questions/655671/how-many-test-executions-are-required-and-how-many-must-pass-to-say-my-softwar</guid>
      <pubDate>Fri, 11 Oct 2024 22:37:30 GMT</pubDate>
    </item>
    <item>
      <title>估计概率值大于来自未知分布的 x</title>
      <link>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</link>
      <description><![CDATA[假设我们有 N 个项目的总体，其值从 0 到 6000。
假设总体的平均值是 $\mu$。
我们不知道项目的分布。
我们从这个总体中提取一个项目，我们如何估计 $P(x\geq 2500)$？
同样的问题，假设分布是均匀的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</guid>
      <pubDate>Fri, 11 Oct 2024 08:52:55 GMT</pubDate>
    </item>
    <item>
      <title>方差总是等于二阶导数的倒数吗？</title>
      <link>https://stats.stackexchange.com/questions/655583/is-variance-always-equal-to-the-inverse-of-the-second-derivative</link>
      <description><![CDATA[这是基于 Fisher 评分法（本质上是 Newton-Raphson 优化算法的统计版本）估计模型参数的著名公式：
$$\theta^{(k+1)} = \theta^{(k)} + [I(\theta^{(k)})]^{-1}U(\theta^{(k)})$$
其中：

$\theta^{(k)}$ 是迭代时的估计值 $k$
$U(\theta)$ 是得分函数（对数似然的一阶导数）
$I(\theta)$ 是 Fisher 信息矩阵（基于 Hessian，即二阶导数）

我认为 Fisher 评分的真正酷之处在于它同时估计参数的方差：
$$E[-\nabla^2 \log L(\theta)] = I(\theta)$$
$$\text{Var}(\hat{\theta}) \approx I^{-1}(\hat{\theta})$$
在之前的问题中（例如如何防止似然优化中的负方差估计？），我了解到许多软件实现实际上并没有使用这种精确的 Fisher 评分方法，因为执行使用 Fisher 评分方法所需的矩阵微积分可能非常复杂。而是使用拟牛顿方法，例如 BFGS 算法。
BFGS 算法（具有与 Fisher 评分非常相似的结构）按如下方式更新 $\theta$ 的估计值：
$$\theta^{(k+1)} = \theta^{(k)} - \alpha^{(k)} H^{(k)} \nabla L(\theta^{(k)})$$
其中：

$\alpha^{(k)}$ 是由线搜索确定的步长
$H^{(k)}$ 是逆 Hessian 的近似值矩阵
$\nabla L(\theta^{(k)})$ 是对数似然的梯度
梯度$\nabla L(\theta)$与 Fisher 评分中的得分函数$U(\theta)$相同。

所有这些都让我感到疑惑。假设 BFGS 中产生的最终 Hessian（即收敛时）表示为 $H_{final}$。
这样说公平吗？
$$H_{final} \xrightarrow{p} [-\nabla^2 \log L(\theta)]^{-1}$$
$$\text{Var}(\hat{\theta}) \approx H_{final}$$
最终呢？
$$\text{Var}(\hat{\theta}) \approx \begin{cases}
I^{-1}(\hat{\theta}) &amp; \text{for Fisher Scoring} \\
H_{final} &amp; \text{for BFGS}
\end{cases}$$
因此，BFGS 算法似乎也估计了参数估计的方差（就像 Fisher Scoring 一样）。
如果这是真的（即 BFGS 通过避免 Fisher Scoring 所需的矩阵微积分节省了时间，并且 BFGS 仍然提供方差估计），那么为什么 Fisher Scoring 在应用中会使用呢？在我看来，Fisher Scoring 只有在一些非常具体的建模情况下才会真正具有优势（例如指数族、GLM），在这些情况下，我们已经事先知道填充得分函数和预期的 hessian 所需的精确矩阵微积分？或者也许从优化的角度来看，Fisher Scoring 更稳定，与 BFGS 相比，它不太可能陷入困境？]]></description>
      <guid>https://stats.stackexchange.com/questions/655583/is-variance-always-equal-to-the-inverse-of-the-second-derivative</guid>
      <pubDate>Thu, 10 Oct 2024 04:26:36 GMT</pubDate>
    </item>
    <item>
      <title>比较不同重叠组中两个变量的相关性</title>
      <link>https://stats.stackexchange.com/questions/655573/comparing-correlations-for-two-variables-in-different-overlapping-groups</link>
      <description><![CDATA[我有一个样本，其中我为同一种疾病应用了五种（差异很大）诊断定义。例如，50% 的诊断定义 1 下的患病病例不是诊断定义 2 下的患病病例，而 10% 的符合定义 2 的病例不是定义 1 下的病例。定义 1 是目前使用最广泛的“标准”，所有其他定义都将与定义 1 进行比较。
我想比较针对每个人测量的两个变量之间的相关性（称为 X 和 Y），看看定义 1 下的患病病例的 cor(X,Y) 是否与定义 2 下的患病病例的 cor(X,Y) 不同（请记住，有些人同时符合两个定义，并将同时属于两个组）。我想要用几对变量来做这个 - 根据具体变量，我可能会使用 Pearson、Spearman 或四分法相关系数。
将样本限制为“符合五个诊断定义中至少一个的人”后我的样本量约为 80,000，所有诊断定义至少产生 30,000 个病例。
我首先想到的方法是使用引导法：

使用“至少符合一个诊断定义的 80,000 人”的整个样本进行替换抽样。
对于五个诊断定义中的每一个，使用符合该定义的引导样本中的观测值计算 cor(X,Y)。
对得到的相关性使用 Fisher 变换，这样减法就合适了。
对于诊断定义 2-5 中的每一个，从定义 1 病例的相关性中减去该组的相关性。 （使用当前引导迭代中的 Fisher 变换相关性。）
重复步骤 1-4 数千次。
取 min(差异百分比 &gt; 0,差异百分比 &lt; 0)，并将该数字乘以 2，得到双尾检验，以确定相关性之间的差异是否不等于 0。

此过程合适吗？它会做我想做的事情吗（测试相关性的差异，同时考虑产生相关性的两个组之间的重叠）？我是否应该考虑使用其他方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655573/comparing-correlations-for-two-variables-in-different-overlapping-groups</guid>
      <pubDate>Wed, 09 Oct 2024 22:02:40 GMT</pubDate>
    </item>
    </channel>
</rss>