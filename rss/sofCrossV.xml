<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 02 Aug 2024 21:15:16 GMT</lastBuildDate>
    <item>
      <title>线性混合模型中相互作用的功效分析</title>
      <link>https://stats.stackexchange.com/questions/652229/power-analysis-for-interaction-in-linear-mixed-model</link>
      <description><![CDATA[我正在尝试对线性混合模型中的交互作用进行功效分析，以确定所需的样本量。
该模型具有以下结构：
Y ~ C * X + (1|Subject)
Y 和 X 是连续变量，而 C 是两级因子（总和对比编码）且在受试者内。
我知道 X 和 Y 之间主效应的预期效应大小约为 beta = 0.27。现在我想找出不同交互效应大小的样本量（因此基本上进行敏感性分析）。
我知道有讨论说交互效应大小通常需要更大的样本量（https://statmodeling.stat.columbia.edu/2018/03/15/need16/）。但是，这些估计似乎只考虑了学科研究之间的差异。
我也尝试使用 InteractionPoweR 包，但我不确定它是否适用于我的情况。
如能得到任何帮助，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/652229/power-analysis-for-interaction-in-linear-mixed-model</guid>
      <pubDate>Fri, 02 Aug 2024 20:39:25 GMT</pubDate>
    </item>
    <item>
      <title>拟合残差相当于优化全局线性模型吗？</title>
      <link>https://stats.stackexchange.com/questions/652223/fitting-against-residuals-equivalent-to-optimizing-global-linear-model</link>
      <description><![CDATA[假设您正在构建线性模型来针对目标变量$y.$优化$r^2$。您当前有一个模型$m$，并且您正在考虑将许多候选预测因子$x_1, x_2, ..., x_{1000}$添加到该模型中。目标是选择 $x_i$，以 $\beta_m * m + \beta_i * x_i.$ 的形式对当前模型进行最佳补充。这是否等同于选择 $x_i$，使 $y$ 上的单变量 $r^2$ 与当前模型 $m$ 的残差最大化？
从数学角度来看，似乎当你给自己自由参数 $\beta_m$ 时，等价性不再成立。然而，这似乎是梯度提升树等事物中的一种常见技术。我相信典型的随机森林实现会将当前模型的权重固定在$1$，但这似乎是一个重大障碍。如果您不允许自己降低现有模型的权重，那么您对下一个预测因子的搜索似乎会偏离那些强但相关的预测因子，这些预测因子会比弱但不相关的预测因子增加更多价值。]]></description>
      <guid>https://stats.stackexchange.com/questions/652223/fitting-against-residuals-equivalent-to-optimizing-global-linear-model</guid>
      <pubDate>Fri, 02 Aug 2024 19:57:13 GMT</pubDate>
    </item>
    <item>
      <title>调整等效样本量进行研究是自我控制的</title>
      <link>https://stats.stackexchange.com/questions/652222/adjusting-equivalence-sample-size-for-study-is-self-controlled</link>
      <description><![CDATA[我正在尝试获取 DDI 协议的样本量计算，我们正在寻找测试生物等效性假设的方法。我正在使用 FARTSSIE 表，但我担心我高估了我的研究规模，因为它假设了平行研究设计。
我知道这可能是错误的，但如果我的研究是自我控制的，我可以将报告的规模减少一些。
我做了一些谷歌搜索和自我控制，样本量计算似乎总是带来案例研究的内容。
是否有特定的公式或修改可以用于解释自我控制？
我正在寻找有关如何处理这种情况的指示。
提前谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/652222/adjusting-equivalence-sample-size-for-study-is-self-controlled</guid>
      <pubDate>Fri, 02 Aug 2024 19:25:35 GMT</pubDate>
    </item>
    <item>
      <title>VAE：潜在分布。后方崩溃，多重潜在</title>
      <link>https://stats.stackexchange.com/questions/652221/vae-latent-distribution-posterior-collapse-multiple-latents</link>
      <description><![CDATA[在研究 VAE 一段时间后，我有两个问题。在标准 VAE 设置中，我们假设 1 个形状为 (BHWD) 的潜在变量：mu 和 var，以及先验 N(0, I)。

潜在分布：我阅读了一些关于卡方分布的资料，想知道潜在 (B,) 的 L2 范数是否能很好地指示潜在分布是否呈高斯分布。在标准 VAE 训练中，我发现它的值稳定在 (D-1)**0.5 附近，符合 [center Chi distribution][1] 的描述。下一个问题是，如果 L2 范数不等于预期值，我们可以说潜在分布比高斯分布更复杂吗？

后验崩溃：(1) 后验崩溃的症状是什么？它是否必须严格为：mu~0、var~1 和 KL~0？（2）如何解释 var 的平均值。我观察到它也受到 D 的影响。此外，如果极小的 var 表示模型非常确定输入，那么爆炸的 var 会告诉我们编码器缺乏能力吗？一般来说，我们更喜欢较小的 var 还是存在一个理想值。

给定一张图像，我尝试将其转换为 Y/UV 通道并分别学习两组潜在值。具体来说，我对两者应用了标准流程：使用一个/两个编码器为 Y 和 UV 输入生成 mu 和 var，分别计算两个 KL 相对于正常 proir，对两者进行后验采样，在解码之前将它们连接在一起。解码器的工作是重建原始 RGB 图像。
我想象，如果 VAE 能够为图像构建可插值/平滑的潜在空间，它也应该能够处理两个潜在空间并使 Y/UV 潜在空间紧密对齐。不幸的是，我在实验中没有观察到它。重建很好，但潜在空间的统计数据（为了方便，我将它们标记为 1 和 2）非常混乱。 (1) 我没有从 mu1 和 mu2 获得太多信息，因为它们的值非常接近 0。但是，我总是能发现 var2 爆炸（请参阅我在第 2 点中提出的问题），可能高达 200。 (2) 通常，var1 看起来更像高斯，因为它的 L2 范数收敛于 (d-1)**0.5，但 var2 的值稍大一些（请参阅我在第 1 点中提出的问题）。 (3) 我还计算了 mu1 和 mu2 之间的 cos 相似度和 L2 距离。它们大多是正交的，这与高维向量自然彼此正交的说法相符。并且 L2(mu1, mu2) 接近 L2(mu2, origin)，后者大于 L1(mu1, origin)。我不知道如何理解这些？或者一般来说，VAE 框架不适合学习两个独立但相关的高斯类潜在变量？


感谢您的任何见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/652221/vae-latent-distribution-posterior-collapse-multiple-latents</guid>
      <pubDate>Fri, 02 Aug 2024 19:20:12 GMT</pubDate>
    </item>
    <item>
      <title>加权最小二乘与对数变换</title>
      <link>https://stats.stackexchange.com/questions/652220/weighted-least-squares-vs-log-transform</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652220/weighted-least-squares-vs-log-transform</guid>
      <pubDate>Fri, 02 Aug 2024 18:38:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 W 或 p 值来确定使用 Shapiro-Wilk 的正态性是否更好？</title>
      <link>https://stats.stackexchange.com/questions/652218/is-it-better-to-use-the-w-or-p-value-to-determine-normality-using-shapiro-wilk</link>
      <description><![CDATA[我读到过，W 值高于 0.9 被认为是正常的。所以我想用它作为正常性的截止值。然而，在运行各种场景后，我得出的结果为 W = 0.888429，p = 0.254888。
显然，这是一个边缘情况。W 小于 0.9，所以我的截止值认为这是非正常的。但是，如果我四舍五入到小数点后一位，它将是 0.9，因此是正常的。此外，p 值表示零假设未被拒绝，即它是正常的。
当我查看直方图时，它严重向左倾斜。
其他人会如何解释这一点？由于 W 小于 0.9，我倾向于采取强硬路线并将其视​​为非正态，但也许其他人会认为 p 值更重要？
数据为：
0.65,
-1.37,
-1.22,
2.2,
0,
-1.5,
1.1,
-1.5,
-0.5]]></description>
      <guid>https://stats.stackexchange.com/questions/652218/is-it-better-to-use-the-w-or-p-value-to-determine-normality-using-shapiro-wilk</guid>
      <pubDate>Fri, 02 Aug 2024 18:22:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么修改后的 z 分数没有发现明显的异常值？</title>
      <link>https://stats.stackexchange.com/questions/652217/why-does-modified-z-score-not-pick-up-an-obvious-outlier</link>
      <description><![CDATA[希望借鉴您对用于检测异常值的修改后的 z 分数的一些见解。
据我从研究中得知，当分布可能不正常（例如偏斜）时，修改后的 z 分数比 z 分数本身更能指示异常值。这是因为，如果分布不为正态分布，则使用中位数而不是均值，中位数是集中趋势的稳健估计量。
我正在针对一个值列表测试这两种算法以及其他一些异常值检测算法，其中我知道一个值是极端异常值。为了帮助我，我创建了一个小型 Python 程序，它根据该列表计算 z 分数和修改后的 z 分数，然后使用它来检查列表中的任何项目是否看起来像异常值。基本上，我检查了这些算法是否能成功检测到我知道存在的极端异常值。
为了检查我的数据的分布，程序创建了一个箱线图，异常值（值 = 200）非常明显。作为参考，该数据集的中位数为 58。

异常值 200 的修改后的 z 分数仅为 2.81，这大大低于被视为异常值的 3.5，因此它不会被标记为异常值。仅供参考，我使用 3.5，因为这似乎是最推荐的截止值。
异常值 200 的 z 分数为 3.40，这高于被视为异常值的 3.0，因此它确实被标记为异常值。仅供参考，我使用 3.0 作为截止值，因为这似乎最受欢迎。
我的问题是，为什么 z 分数算法可以检测到我的数据集中的异常值，而修改后的 z 分数算法却不能？在我看来，这似乎违反直觉，尤其是当异常值从箱线图中显而易见时。
这是我的 Python，以防我犯了错误：
import matplotlib as plt
import numpy as np
from scipy.stats import zscore

def z_score_mod(obs):
med = np.median(obs)
med_abs_dev = np.median(np.abs(obs - med))
z_score_mod = 0.6745 * ((obs - med) / med_abs_dev)
return z_score_mod

# 具有相当大的异常值 = 200 和索引 = 13 的观察值列表
list_of_obs = [58,71,11,18,90,97,15,53,39,22,62,51,10,200,20,64,94,71,73,18,95,96,92,38,26]

# 将观测值列表转换为 numpy 数组
array_of_obs = np.array(list_of_obs)

# 创建箱线图以显示异常值
plt.pyplot.boxplot(array_of_obs)

median = np.median(array_of_obs)

# 计算每个数组项的修改后的 z 分数
array_of_z_score_mod = z_score_mod(array_of_obs)

# 对于生成的修改后的 z 分数，确定是否有任何异常值
array_of_outlier_evals = abs(array_of_z_score_mod) &gt; 3.5

# 索引 = 13 处的观测值 = 200 是否为异常值？
print(&#39;\r&#39;)
print(f&#39;索引位置 13 处的观察值 = {list_of_obs[13]}&#39;)
print(f&#39;修改后的 z 分数值 = {array_of_z_score_mod[13]:.2f}&#39;)
print(f&#39;在修改后的 z 分数阈值 3.5 处，值是否为异常值：{array_of_outlier_evals[13]}&#39;)

# 计算每个数组项的 z 分数
array_of_z_score = zscore(list_of_obs)

# 对于生成的 z 分数，确定是否有任何异常值
array_of_outlier_evals_2 = abs(array_of_z_score) &gt; 3

# 索引 = 13 处的观察值 = 200 是否为异常值？
print(&#39;\r&#39;)
print(f&#39;索引位置 13 处的观察值 = {list_of_obs[13]}&#39;)
print(f&#39;值的 z-score = {array_of_z_score[13]:.2f}&#39;)
print(f&#39;在 z-score 阈值 3.0 处，值是否为异常值：{array_of_outlier_evals_2[13]}&#39;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652217/why-does-modified-z-score-not-pick-up-an-obvious-outlier</guid>
      <pubDate>Fri, 02 Aug 2024 17:17:52 GMT</pubDate>
    </item>
    <item>
      <title>具有外生变量的 ARMA - GARMA 模型的 p 值</title>
      <link>https://stats.stackexchange.com/questions/652216/p-values-for-a-arma-garma-model-with-exogenous-variable</link>
      <description><![CDATA[我正在尝试估计以下 ARMA(1, 2) - GARCH(1, 1) 模型的参数，其中还带有一个外生变量。模型规范如下：
$ x_t = \mu + \beta_Y \cdot y_{t-1} + AR_1\cdot x_{t-1} + MA_1\cdot \epsilon_{t-1} + MA_2 \cdot \epsilon_{t-2} + \epsilon_t$
$\epsilon_t = \sigma_t\cdot z_t $
$ \sigma_t = \sqrt{\omega + \alpha \cdot \epsilon_{t-1}^2 + \beta\cdot \sigma_{t-1}^2}$
$ z_t \sim Normal(0, 1)$ 适用于所有 $t$。这些误差是 iid 的。
模型参数为：$\mu, \beta_Y, AR_1, MA_1, MA_2, \omega, \alpha, \beta$。
我目前正在通过最大化 pytorch 中的对数似然来估计最佳参数。问题：

是否有能够估计这些参数的 python 包？作为双重检查，它将非常有用

是否有一个 python 包能够为估计的参数生成标准错误和 p 值？

如果答案 2 没有这样的包，有没有关于如何生成这些 p 值的提示？


非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652216/p-values-for-a-arma-garma-model-with-exogenous-variable</guid>
      <pubDate>Fri, 02 Aug 2024 17:14:01 GMT</pubDate>
    </item>
    <item>
      <title>如何读取实验设计的事后（Tukey HSD）输出？</title>
      <link>https://stats.stackexchange.com/questions/652215/how-do-you-read-post-hoc-tukey-hsd-outputs-for-experimental-designs</link>
      <description><![CDATA[我目前正在学习统计学课程中的实验设计，我对事后分析结果的解读方式感到十分困惑。
在我的家庭作业中，我对三个不同快递员的平均送货时间差异进行了事后/Tukey HSD 测试。我为此使用的测试统计量是随机区组设计。我的因变量是运输时间，而我的分类变量是发货批次和快递员。当我通过 Statistica 软件运行数据时，我得到了 1-5 批发货的一列，以及每个 {1}、{2}、{3}、{4} 和 {5} 的一列。
为了直观起见，这是 Statistica 给我的结果。请注意，我只填写了前两行：



装运批次
{1&gt;
{2&gt;
{3&gt;
{4&gt;
{5&gt;




1

0.017177
0.005775
0.94846
0.000722


2
0.017177

0.893692
0.043908
0.090739


3







4








5








在每个 {1}、... {5}（在同一个标​​题块中）下，还标明了该特定货件的平均交货时间。
看到（我认为是）行和列都是货件批次时，我真的很困惑，因为我有兴趣测试快递员之间的平均交货时间差异。
为什么货件是表格中显示的唯一分类变量？我测试运行不正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652215/how-do-you-read-post-hoc-tukey-hsd-outputs-for-experimental-designs</guid>
      <pubDate>Fri, 02 Aug 2024 17:13:44 GMT</pubDate>
    </item>
    <item>
      <title>核均值嵌入的收敛</title>
      <link>https://stats.stackexchange.com/questions/652212/convergence-of-kernel-mean-embeddings</link>
      <description><![CDATA[令 $k(\cdot,\cdot)$ 为有界核，$\mathcal{H}$ 为其关联的 RKHS。定义核均值嵌入 $\mu=\int k(\cdot,x) \, dP_X(x)$，令 $\hat{\mu}=\frac{1}{n}\sum k(x_i,\cdot)$ 为其样本类似物。两者之间的误差为 $\|\mu-\hat{\mu}\|_{\mathcal{H}}=O(\frac{1}{\sqrt{n}})$。各种结果通过使用希尔伯特空间的伯恩斯坦型不等式来证明这一点。
对我来说，从中心极限定理的角度来看，这感觉很直观。有希尔伯特空间 CLT 吗？是否有可能从 CLT 的应用中显示这种速率？]]></description>
      <guid>https://stats.stackexchange.com/questions/652212/convergence-of-kernel-mean-embeddings</guid>
      <pubDate>Fri, 02 Aug 2024 14:32:18 GMT</pubDate>
    </item>
    <item>
      <title>计算不同统计检验的效应大小、统计功效和置信区间</title>
      <link>https://stats.stackexchange.com/questions/652209/calculation-of-effect-size-statistical-power-and-confidence-interval-for-diffe</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652209/calculation-of-effect-size-statistical-power-and-confidence-interval-for-diffe</guid>
      <pubDate>Fri, 02 Aug 2024 11:41:26 GMT</pubDate>
    </item>
    <item>
      <title>E-test 值的多重校正</title>
      <link>https://stats.stackexchange.com/questions/652208/multiple-correction-for-e-test-values</link>
      <description><![CDATA[我目前正在执行多个“E-tests”（poisson.mean），并且想知道使用 E-tests 进行多次校正的最合适方法，以及如何在 R 中进行此操作。
我正在计算 7 个不同实验组（2 个对照组，5 个感兴趣的实验组）中某个事件发生的次数（在给定的时间间隔内）。
我选择通过列出 7 个条件组和值来比较各组之间的泊松分布均值，然后以迭代方式执行泊松检验。然后从结果中获取 P 值，例如。
Cond1 &lt;- c(0,0,0,1,1,2,3,3,3)
Cond2 &lt;- c(0,1,1,1,1,1,2,3,3)
Cond3 &lt;- c(0,1,2,3,3,3,3,3,4)
Cond7 &lt;- c(3,3,3,3,4,4,4,5,6)
result1 &lt;- poisson.test(x c(sum(Cond1), sum(Cond2)),
T = c(length(Cond1), length (Cond2)),
alternative = &quot;two.sided&quot;)
result2 &lt;- poisson.test(x c(sum(Cond1), sum(Cond3)),
T = c(length(Cond1), length (Cond3)),
alternative = &quot;two.sided&quot;) 

result20 &lt;- poisson.test(x c(sum(Cond6), sum(Cond7)),
T = c(length(Cond6), length (Cond7)),
alternative = &quot;two.sided&quot;) 
P1 &lt;- result1§p.value 
P2 &lt;- result2§p.value 
P20&lt;- result20§p.value 

从这一点开始，我需要校正多个测试，并希望使用 Benjamini-Hochberg 类型的排序 p 值显著性校正，但我想知道
A) 哪种测试最适合这种分析
B) 如何在 R 中进行此操作]]></description>
      <guid>https://stats.stackexchange.com/questions/652208/multiple-correction-for-e-test-values</guid>
      <pubDate>Fri, 02 Aug 2024 11:36:56 GMT</pubDate>
    </item>
    <item>
      <title>对单个组的样本大小进行论证以获得所需准确度的平均值估计值</title>
      <link>https://stats.stackexchange.com/questions/652201/sample-size-justification-for-single-group-to-get-estimate-of-mean-to-desired-ac</link>
      <description><![CDATA[
我有一个计算机组件样品
这些计算机组件是分批生产的（1 批 = 1 批次），每批 200 个
组件可以单独进行电子测试
然后对该测试结果进行平均，以得出批次级值，以判断整个批次是否通过
我需要知道需要从一批中抽样多少个组件，以便对整个批次进行
准确的测试测量。
有人知道我应该如何证明这一点吗？
例如，测试 10 个组件是否能让我足够准确地估计出整个批次的平均测试结果？

我知道这里有一些未知数，比如“足够准确” - 也许是某种置信区间？
任何帮助都太棒了！
林肯]]></description>
      <guid>https://stats.stackexchange.com/questions/652201/sample-size-justification-for-single-group-to-get-estimate-of-mean-to-desired-ac</guid>
      <pubDate>Fri, 02 Aug 2024 08:15:30 GMT</pubDate>
    </item>
    <item>
      <title>弗里德曼、皮萨尼和普维斯书中的辛普森悖论</title>
      <link>https://stats.stackexchange.com/questions/652195/simpsons-paradox-in-freedman-pisani-and-purves-book</link>
      <description><![CDATA[本书中有一个研究生录取性别歧视的例子。



专业
男性

女性






申请人数
录取率
申请人数
%录取


A
825
62
108
82


B
560
63
25
68


C
325
37
593
34


D
417
33
375
35


E
191
28
393
24


F
373
6
341
7


总计
2691
45
1835
30



申请人总数只是上述条目的总和。录取的总百分比为男性 45%，为
$$ \frac{62\cdot825 }{2691} + \cdots + \frac{6\cdot373}{2691}$$
女性也是如此。
然后作者提出统计学家会做以下事情的论点：



专业
申请人总数




A
933 = 825 + 108


B
585


C
918


D
792


E
584


F
714 = 373 + 341


总计
4526



然后他们指出男性的加权平均录取率为：
$$ \frac{62\cdot933}{4526} + \cdots + \frac{6\cdot714}{4526} \approx 39 $$
对于女性来说也是如此：
$$ \frac{82\cdot933}{4526} + \cdots + \frac{7\cdot714}{4526} \approx 43 $$
我很难解释最后一对计算“男女加权平均录取率”。
他们说：

加权平均值控制了混杂因素——专业选择。这些平均值表明，如果有的话，录取过程对男性存在偏见。

在这种情况下，39% 和 43% 的加权平均值究竟意味着什么？如何正确解释这些数字？原始百分比 45% 和 30% 似乎对我来说更容易理解和解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/652195/simpsons-paradox-in-freedman-pisani-and-purves-book</guid>
      <pubDate>Fri, 02 Aug 2024 05:33:00 GMT</pubDate>
    </item>
    <item>
      <title>假设 $Z_i$ 是独立同分布的。$N(0, 1).$ 且令 $M_n = \max\{Z_1, \ldots, Z_n\}$，表明 $P(M_n > t) \leq n(1 - \Phi(t))$</title>
      <link>https://stats.stackexchange.com/questions/652187/suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n-sh</link>
      <description><![CDATA[证明 $P(M_n &gt; t) \leq n(1 - \Phi(t))$
我的工作：
\begin{align}
&amp; P(M_n &gt; t) \leq P\left(\bigcup_{i=1}^n (Z_i &gt; t) \right) \\ \leq {} &amp; \sum_{i=1}^n P(Z_i &gt; t)= n(1 - \Phi(t))
\end{align&gt;
以上是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/652187/suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n-sh</guid>
      <pubDate>Thu, 01 Aug 2024 22:30:21 GMT</pubDate>
    </item>
    </channel>
</rss>