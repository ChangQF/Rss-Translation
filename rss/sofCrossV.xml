<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 07 Nov 2024 18:21:49 GMT</lastBuildDate>
    <item>
      <title>如何计算我的 MCMC 样本和目标分布之间的 KL 散度？</title>
      <link>https://stats.stackexchange.com/questions/656911/how-do-i-compute-the-kl-divergence-between-my-mcmc-samples-and-the-target-distri</link>
      <description><![CDATA[假设 $(E,\mathcal E,\lambda)$ 是一个 $\sigma$-有限测度空间，并且 $\nu$ 是 $(E,\mathcal E)$ 上的概率测度，且 $\nu\ll\lambda$。此外，假设$\mu=\sum_{i=0}^{n-1}\delta_{X_i}$，其中$(X_n)_{n\in\mathbb N_0}$是$(E,\mathcal E)$上的马尔可夫链，其分布为$\nu$不变。我们能否给出 $\mu$ 和 $\nu$ 之间的 KL 散度 $$H(\mu,\nu):=\begin{cases}\displaystyle\int\ln\frac{{\rm d}\mu}{{\rm d}\nu}\;{\rm d}\mu=\int\frac{{\rm d}\mu}{{\rm d}\nu}\ln\frac{{\rm d}\mu}{{\rm d}\nu}\;{\rm d}\nu&amp;\text{, if }\mu\ll\nu;\\\infty&amp;\text{, else}\end{cases}$$ 的表达式？我的想法是，我想计算 MCMC 方法的样本 $x_0,\ldots,x_{n-1}$ 之间的 KL 散度，这些样本对应于 $X_0,\ldots,X_{n-1}$ 的实现，以及目标分布 $\nu$。如果必要的话，你可以假设 $\lambda$ 是 $d$ 维勒贝格测度。根据遍历定理，我们应该能够得到 $H(\mu,\nu)$ 的估计量。但我不明白为什么我们应该有$\mu\ll\nu$...]]></description>
      <guid>https://stats.stackexchange.com/questions/656911/how-do-i-compute-the-kl-divergence-between-my-mcmc-samples-and-the-target-distri</guid>
      <pubDate>Thu, 07 Nov 2024 17:10:25 GMT</pubDate>
    </item>
    <item>
      <title>比较频率 - 哪种方法？（基于 Excel）</title>
      <link>https://stats.stackexchange.com/questions/656908/compare-frequencies-which-approach-excel-based</link>
      <description><![CDATA[我想检查两个组的比例是否显著不同。
为了更具体：我有子组 A，它代表组 1 的 X%，子组 B，它代表另一个组 2 的 Y%。从数据上讲，我知道子组 A 和 B 的两个百分比，以及组 1 和组 2 的样本量。
我该如何进行统计？据我所知，我可以同时进行比例差异的 z 检验和计算差异的置信区间（以检查是否包含 0）。哪种方法更合适？我如何在 Excel 中计算它们？我得到了一些结果，但这需要多个步骤，而且由于我需要对大量组进行这些比较，所以我希望将整个公式放在一个单元格中。
非常感谢您的意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/656908/compare-frequencies-which-approach-excel-based</guid>
      <pubDate>Thu, 07 Nov 2024 16:17:00 GMT</pubDate>
    </item>
    <item>
      <title>以总花费时间（持续时间）作为因变量的适当回归模型</title>
      <link>https://stats.stackexchange.com/questions/656904/appropriate-regression-model-for-total-time-spent-duration-as-a-dependent-vari</link>
      <description><![CDATA[在我的研究中，参与者分析了九种不同的音轨，分为三种条件：条件 1（前 3 个音轨）、条件 2（中间 3 个音轨）和条件 3（最后 3 个音轨）。在聆听时，他们将滑块从 0 调整到 10 以指示他们的感知。滑块的中点 (5) 代表“中性”，高于 5 的值表示感知到一种强度不同的声音 (S1)，低于 5 的值表示感知到另一种强度不同的声音 (S2)。每种条件都有不同的声音，并且音轨长度因条件而异。
我已经分析了连续滑块数据（代表感知强度）。但是，我现在感兴趣的是在每个滑块区域花费的总时间：中性（值 = 5）、S1（值 &gt; 5）和 S2（值 &lt; 5）。这种方法将数据离散化，使我能够评估不同条件下中性、S1 和 S2 的总持续时间。这个想法是，在每个区域花费的总时间是否取决于条件。
我的问题是，进行这种分析的合适回归模型是什么？我首先测试了线性混合效应模型，但置信区间显示负值。所以我读过关于泊松和负二项回归的文章，但它们不是用于计数数据吗？我也想过使用比例，但如果我的值在 0 和 1 之间，方法会是什么？我还测试了多项逻辑回归，看看在条件函数中找到特定类别的几率是否会增加，但我对在每个区域花费的总时间感兴趣。我通过使用它作为固定效应来控制轨道的长度。那么，这里正确的方法是什么？
以下是基于真实数据的一些随机数据，以及我迄今为止测试过的示例代码：
track_nb 参与者 S2 S1 中性条件
1 1 121 275 56 C1
1 2 195 138 95 C1
1 3 274 22 19 C1
2 1 199 266 98 C1
2 2 116 182 84 C1
2 3 101 109 20 C1
3 1 115 253 31 C1
3 2 173 78 80 C1
3 3 47 265 96 C1
4 1 35 175 52 C2
4 2 96 205 37 C2 4 3 297 236 97 C2 5 1 137 54 52 C2 5 2 48 261 79 C2 5 3 110 189 40 C2 6 1 142 233 79 C2 6 2 209 208 26 C2 6 3 173 33 42 C2 7 1 202 206 51 C3 7 2 106 94 10 C3 7 3 59 196 94 C3 8 1 267 268 69 C3 8 2 262 109 93 C3 8 3 225 171 21 C3 9 1 129 220 25 C3
9 2 30 126 86 C3
9 3 92 100 31 C3

库（tidyr）
库（lme4）
库（glmmTMB）

测试 &lt;- df %&gt;%
pivot_longer(
cols = c(S2, S1, neutral), 
names_to = &quot;category&quot;, 
values_to = &quot;total_time_spent&quot; 
)

#线性混合效应

m1 &lt;- lmer(total_time_spent ~ condition * category + category:length + (1 | 参与者), REML = FALSE, data = test)

#负二项式示例

model_durations_interaction &lt;- glmmTMB(total_time_spent ~ condition * category + category:length + (1 | 参与者), 
family = nbinom2,
REML = FALSE, data = test)

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656904/appropriate-regression-model-for-total-time-spent-duration-as-a-dependent-vari</guid>
      <pubDate>Thu, 07 Nov 2024 15:57:11 GMT</pubDate>
    </item>
    <item>
      <title>具有积极 p 删除的分层回归真的比逐步回归“更好”吗？</title>
      <link>https://stats.stackexchange.com/questions/656902/is-hierachical-regression-with-aggressive-p-deletion-really-much-better-than-s</link>
      <description><![CDATA[在许多医学领域，“分层回归”是一种流行的方法。
该方法是将变量分成几类，一次添加一类变量，然后在添加下一组变量之前删除它们。
我看到的一种辩护是，由于“领域专业知识选择变量”，因此问题较少。当然，这种情况经常发生，具体取决于如何执行分层回归。
但是，一些团体/研究人员在进行分层回归时，坚持在非常低的阈值（0.05 甚至更低；有人告诉我，我必须在较低的阈值下删除“以纠正多重比较”）。过程是：添加变量类别 --&gt; 丢弃 p &lt; 0.05 的所有内容 --&gt;对每个类别执行相同的操作，直到完成。
这种分层回归的特定方法是否不会重现逐步选择的大部分相同问题？领域专业知识唯一能说明的是类别及其顺序；它不会用于决定是否删除，这由 p 值决定，就像逐步选择一样。]]></description>
      <guid>https://stats.stackexchange.com/questions/656902/is-hierachical-regression-with-aggressive-p-deletion-really-much-better-than-s</guid>
      <pubDate>Thu, 07 Nov 2024 15:43:58 GMT</pubDate>
    </item>
    <item>
      <title>对具有二元因变量的分类自变量进行适当的统计显着性检验</title>
      <link>https://stats.stackexchange.com/questions/656900/appropriate-statistical-significance-test-for-categorical-independent-variables</link>
      <description><![CDATA[我试图确定语言预测模型是否比其他语言预测模型预测的情绪值准确得多。
我试图预测三种语言预测模型：英语、法语和其他。
以下是用于复制我的研究的虚拟数据：
set.seed(123)

#n 种语言
n_english &lt;- 123
n_french &lt;- 180
n_other &lt;- 52

#unique id
df &lt;- data.frame(id = 1:(n_english + n_french + n_other))

#将语言分配给 df#lang
df$lang &lt;- c(rep(&quot;English&quot;, n_english), rep(&quot;French&quot;, n_french), rep(&quot;Other&quot;, n_other))

#生成随机值
df$accuracy &lt;- NA
df$accuracy[df$lang == &quot;English&quot;] &lt;- rbinom(n_english, 1, prob = 0.87)
df$accuracy[df$lang == &quot;French&quot;] &lt;- rbinom(n_french, 1, prob = 0.75)
df$accuracy[df$lang == &quot;Other&quot;] &lt;- rbinom(n_other, 1, prob = 0.90)

tibble(df)
# A tibble: 355 × 3
ID 语言准确度
&lt;int&gt; &lt;chr&gt; &lt;int&gt;
1 1 英语 1
2 2 英语 1
3 3 英语 1
4 4 英语 0
5 5 英语 0
6 6 英语 1
7 7 英语 1
8 8 英语 0
9 9 英语 1
10 10 英语 1
# ℹ 更多 345 行
# ℹ 使用 `print(n = ...)` 查看更多行

hist(df$accuracy)

数据框表明语言变量具有伯努利分布，因此不满足参数检验的标准。我应该使用什么适当的测试统计数据来确定语言之间是否存在准确预测的显著结果？
下面是我尝试使用箱线图可视化数据的代码，以了解每种语言的准确性平均值差异：
df %&gt;%
group_by(lang) %&gt;%
summary(
mean = mean(accuracy),
sd = sd(accuracy)
) %&gt;%
ggplot(aes(x = lang)) +
geom_boxplot(aes(lower=mean-sd,upper=mean+sd,middle=mean,ymin=mean-0*sd,ymax=mean+0*sd),stat=&quot;identity&quot;) +
labs(x = &quot;lang&quot;, y = &quot;accuracy&quot;) +
theme_bw()


我希望测试统计数据能够显示每个变量准确预测均值的差异方面的显著性。
我在各个论坛上读到的类似问题的每个答案都建议我进行逻辑回归；但是，我并不是想建立一个回归模型来确定给定事件的二元结果的概率。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656900/appropriate-statistical-significance-test-for-categorical-independent-variables</guid>
      <pubDate>Thu, 07 Nov 2024 15:07:43 GMT</pubDate>
    </item>
    <item>
      <title>广义线性模型的假设</title>
      <link>https://stats.stackexchange.com/questions/656898/assumptions-of-a-glm</link>
      <description><![CDATA[我在 R 中运行 glm，从残差图来看，模型并不完全符合假设。我的问题是这些假设需要达到什么程度，或者有些偏差可以接受吗？我尝试过转换、添加交互项、删除异常值等，但似乎没有什么可以改善它。
我正在根据物种比例对产量进行建模，同时还包括虚拟变量以解释特殊混合物/处理（对照）
glm(Annual_DM_Yield ~ 0 + Grass + Legume + I(Legume2) + I(Legume3) + Herb +
AV +
PRG_300N + PRG_150N + PRG_0N + PRGWC_0N + PRGWC_150N + N_Treatment_150N,
data=yield )
任何帮助都非常感谢！
]]></description>
      <guid>https://stats.stackexchange.com/questions/656898/assumptions-of-a-glm</guid>
      <pubDate>Thu, 07 Nov 2024 14:16:18 GMT</pubDate>
    </item>
    <item>
      <title>通过多元数据集进行训练</title>
      <link>https://stats.stackexchange.com/questions/656897/training-by-multivariate-data-sets</link>
      <description><![CDATA[我有以下任务要做：通过连续 3 天的训练来预测第 4 天。每天的数据代表一个尺寸为 24x25 的 CSV 文件。每个 CSV 文件的每个数据点都是像素。我需要使用回归（线性、岭）和 LSTM 等模型。
每个模型训练 3 天：
对于回归模型：通过展平处理每天的数据后，我将数据转置为形状：（600, 3）。
对于 lstm 模型：通过展平处理每天的数据后，我将数据保持原样，形状：（3, 600）。
例如这样：
day_1 = [0.1, 0.2, ..., 0.6] # 第 1 天的 600 个特征
day_2 = [0.15, 0.25, ..., 0.65] # 第 2 天的 600 个特征
day_3 = [0.2, 0.3, ..., 0.7] # 第 3 天的 600 个特征

X_train_linear_ridge = np.array([
[0.1, 0.15, 0.2], # 第 1 天、第 2 天、第 3 天的特征 1
[0.2, 0.25, 0.3], # 第 1 天、第 2 天、第 3 天的特征 2
# ...
[0.6, 0.65, 0.7] # 第 1 天、第 2 天、第 3 天的特征 600
]) # 形状：(600, 3)

X_train_lstm = np.array([
[0.1, 0.2, ..., 0.6], # 第 1 天的特征
[0.15, 0.25, ..., 0.65], # 第 2 天的特征
[0.2, 0.3, ..., 0.7] # 第 3 天的特征
]) # 形状：(3, 600)


有人能告诉我，为形状为 (600, 3) 的回归模型和形状为 (3, 600) 的 lstm 准备数据在概念上是否正确吗？
我的动机：
LSTM：LSTM 旨在处理具有顺序、时间关系的数据。通过输入形状为 (3, 600) 的数据（代表 3 个时间步骤，每个步骤有 600 个特征），LSTM 可以学习整个序列中的模式。每个时间步骤对应数据中的一天，而 600 个特征代表当天的单个值。此结构对于 LSTM 利用时间依赖性至关重要。
线性和岭回归：这些模型缺乏固有的顺序处理能力。它们将每个输入解释为单个平面向量。为了近似顺序学习，我们可以将每天的数据视为一个单独的特征，创建一个形状为 (600, 3) 的设置，其中 600 个特征在 3 天内“堆叠”。每一天都成为回归模型的一个特征，但它无法像 LSTM 那样捕获时间依赖性。
我的概念对于回归和 lstm 模型的形状是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/656897/training-by-multivariate-data-sets</guid>
      <pubDate>Thu, 07 Nov 2024 14:09:12 GMT</pubDate>
    </item>
    <item>
      <title>R：VGLM 适合部分比例几率模型，无法指定要保持比例几率的变量</title>
      <link>https://stats.stackexchange.com/questions/656895/r-vglm-to-fit-a-partial-proportional-odds-model-unable-to-specify-which-variab</link>
      <description><![CDATA[确认我的因变量是一个有序因子，性别是 0.1 的因子，感兴趣的主要变量（首先列出）是我主要关注的，并且使用布伦特检验时假设只对它成立。
当尝试使用 VGLM 进行拟合并指定它被视为符合道具赔率，但不适用于其他时，我并不高兴。
&gt; logit_model &lt;- vglm(dep_var ~ primary_indep_var + 
+ gender + 
+ var_3 + var_4 + var_5,
+ 
+ family =cumulative(parallel = c(TRUE ~ 1 + primary_indep_var), 
+ link = &quot;cloglog&quot;), 
+ data = temp)

x$terms %||% attr(x, &quot;terms&quot;) %||% stop(&quot;no term component nor attribute&quot;) 中的错误： 
no term component nor attribute

如能得到任何帮助，我们将不胜感激！
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/656895/r-vglm-to-fit-a-partial-proportional-odds-model-unable-to-specify-which-variab</guid>
      <pubDate>Thu, 07 Nov 2024 13:58:28 GMT</pubDate>
    </item>
    <item>
      <title>$\epsilon$-贪婪算法对 $k$ 臂老虎机的精确后悔值</title>
      <link>https://stats.stackexchange.com/questions/656894/exact-regret-of-epsilon-greedy-algorithm-for-k-armed-bandit</link>
      <description><![CDATA[对于 $k$ 臂老虎机，$\epsilon$ 贪婪算法在每一轮中以 $\epsilon$ 的成功概率抛硬币，并执行以下操作：

如果不成功，则选择迄今为止最好的臂，并且
如果成功，则随机选择一个臂。

我想证明
$$
\lim_{n\to\infty}R_n=\frac{\epsilon}{k}\sum_{i}\Delta_i
$$
其中 $\Delta_i$ 是臂 $i$。我可以看到遗憾值受右侧值的限制，因为我们可以假设在每个阶段，到目前为止最好的臂实际上是最好的臂。但我看不出如何严格证明左侧限制了右侧。我必须以某种方式论证，随着 $n$ 趋近于无穷大，每个臂的观测平均值趋近于其预期值，因此最终我们会得到右侧的线性界限，但我不知道如何做到这一点。（我怀疑应该使用大数定律，但我不知道如何阐明这一点。）]]></description>
      <guid>https://stats.stackexchange.com/questions/656894/exact-regret-of-epsilon-greedy-algorithm-for-k-armed-bandit</guid>
      <pubDate>Thu, 07 Nov 2024 13:45:04 GMT</pubDate>
    </item>
    <item>
      <title>Cox 比例风险与 AFT 和比例风险假设的比较</title>
      <link>https://stats.stackexchange.com/questions/656893/cox-proportionall-hazards-compared-to-aft-and-the-proportional-hazards-assumptio</link>
      <description><![CDATA[我正在使用 R 对包含数百万行的大型人口数据集进行生存分析。我的第一个选择是 cox 回归
cox_model &lt;- coxph(Surv(time, event) ~ 
var1+ var2+ var3 , data = data)

然而，基于 Schoenfeld 残差，比例风险假设在某些协变量和全局上被违反。我尝试了时间转换，但考虑到数据的大小，模型无法进行计算处理（有关 70-80Gb 向量分配的错误消息）。
作为替代方案，我尝试拟合 AFT。
model_wei &lt;- survreg(Surv(time, event)~ 
var1+ var2+ var3 , data = data, dist = &quot;weib&quot;, maxiter=100)

在使用 exp、wei、logn 和 logl 创建模型后，logn 模型（基于 AIC）提供了最佳拟合。
您能帮助我理解 Cox 回归中的风险比和 AFT 中的 exp(coef) 之间的解释差异吗？
我为 AFT 选择最佳分布的程序是比较 AIC，然后绘制残差以检查正态性为：
resid &lt;- log(data$time) - model.lognormal$linear.predictors 
qqnorm(resid)
qqline(resid)

结果图为

当使用残差的 Kaplan-Meier 估计量来考虑审查时
fitted_values &lt;- model_logn$linear.predictors
resids &lt;- (log(model_logn$y[, 1]) - fitted_values) / model_logn$scale

resKM &lt;- survfit(Surv(resids, event) ~ 1, data = data)
plot(resKM, mark.time = FALSE, xlab = &quot;AFT Residuals&quot;, ylab = &quot;Survival Probability&quot;)
xx &lt;- seq(min(resids), max(resids), length.out = 35)
yy &lt;- exp(- exp(xx))
lines(xx, yy, col = &quot;red&quot;, lwd = 2)
legend(&quot;bottomleft&quot;, c(&quot;KM 估计&quot;, &quot;95% CI KM 估计&quot;, 
&quot;极值分布的生存函数&quot;), 
lty = c(1,2,1), col = c(1,1,2), bty = &quot;n&quot;)

来源
我得到：

这可以被认为是足够的吗？
如果不是，我有什么选择？
最后一个问题是，如果风险似乎不会随着时间的推移而发生太大变化，并且方向始终保持不变，那么即使比例风险假设被违反，提出一个 cox 回归模型是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/656893/cox-proportionall-hazards-compared-to-aft-and-the-proportional-hazards-assumptio</guid>
      <pubDate>Thu, 07 Nov 2024 13:33:11 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 模型的 MA 分量中的参考模型是什么？</title>
      <link>https://stats.stackexchange.com/questions/656889/what-is-the-reference-model-in-the-ma-component-of-an-arima-model</link>
      <description><![CDATA[ARIMA 中的 MA 组件被定义为一种根据滞后观测值的残差（误差）预测值的模型。
但是，这些残差是如何计算的？
当然，它们是作为实际值和预测值之间的差值获得的。
但是，这些预测来自哪个模型？它是一个对最后 q 个观测值取平均值的移动平均模型吗？
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/656889/what-is-the-reference-model-in-the-ma-component-of-an-arima-model</guid>
      <pubDate>Thu, 07 Nov 2024 13:01:27 GMT</pubDate>
    </item>
    <item>
      <title>使用哪种类型的模型/分析来预测时间序列数据中的事件</title>
      <link>https://stats.stackexchange.com/questions/656886/what-type-of-model-analysis-to-use-to-predict-events-in-time-series-data</link>
      <description><![CDATA[我有一堆包含已知真实世界事件的时间序列（每个 t/s 一个事件）。事件不一定是 t/s 中可见的变化，但已知它已在现实世界中发生。
我想知道我是否可以训练一个模型来了解事件之前是否存在任何特征模式，以用于预测其他 t/s 或未来相同 t/s 中的类似事件。
这不是干预分析，因为我们不关心事件发生后发生了什么。这也不是变点分析，因为我们确切地知道事件发生的时间。这也不是异常检测，因为事件不一定会对数据产生影响。
RNN 是否是这项任务的正确或最佳工具？这种分析类型有通用名称吗？
为了说明，这里有一个虚拟 t/s，其中用虚线标记了一个事件。我有很多其他类似的 t/s，每个 t/s 都是一种复制单位。在这个虚拟 t/s 中，事件之前有一种“脉冲”，值急剧上升然后急剧下降。这只是为了说明，事件之前的 t/s 中可能存在一些可以作为预测因子的特征，不一定是像这样的脉冲。

然后我还有其他未发生事件的时间序列（数量远远超过发生事件的时间序列）。目的是训练一个模型来预测未来 t/s 中是否以及何时会发生事件，就像在预警系统中一样（在这个虚拟的未来 t/s 中，仅出于说明目的显示类似的“脉冲” - 模型可以预测时间步骤 17 之后的事件，即脉冲之后）。
]]></description>
      <guid>https://stats.stackexchange.com/questions/656886/what-type-of-model-analysis-to-use-to-predict-events-in-time-series-data</guid>
      <pubDate>Thu, 07 Nov 2024 11:21:14 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归何时优于随机森林？</title>
      <link>https://stats.stackexchange.com/questions/656884/when-does-logistic-regression-outperform-random-forests</link>
      <description><![CDATA[假设我们有一个二元分类问题，那么两种可能的统计方法是逻辑和随机森林。
从理论的角度来看，我很清楚，如果对数概率$\log(\frac{q}{1-q})$和特征$X_1, ... X_p$之间有足够的线性关系，那么逻辑在构造上就是更强的候选者。
但是，我们如何以图形方式测试我们是否真的有这种线性关系？例如，在线性回归的情况下，这相当容易做到：我们可以绘制目标与协变量的关系，并且我们对目标和协变量之间的关系的线性程度有合理的理解。但是逻辑的情况呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/656884/when-does-logistic-regression-outperform-random-forests</guid>
      <pubDate>Thu, 07 Nov 2024 11:12:01 GMT</pubDate>
    </item>
    <item>
      <title>当增加对数正态分布的标准差时，它是否会趋向于指数分布？</title>
      <link>https://stats.stackexchange.com/questions/656881/does-a-log-normal-distribution-tend-to-an-exponential-distribution-when-increas</link>
      <description><![CDATA[对数正态分布 lognorm(mu, sigma) 随着其标准差 sigma 的增加而变得越来越偏斜。
随着 sigma 的增加，分布是否趋向于指数分布 exp(lambda) ？
这两个函数及其参数之间有什么关系吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656881/does-a-log-normal-distribution-tend-to-an-exponential-distribution-when-increas</guid>
      <pubDate>Thu, 07 Nov 2024 10:59:27 GMT</pubDate>
    </item>
    <item>
      <title>在回归模型中仅使用滞后预测变量而不使用非滞后预测变量？</title>
      <link>https://stats.stackexchange.com/questions/656870/only-using-a-lagged-predictor-in-a-regression-model-and-not-the-unlagged</link>
      <description><![CDATA[在统计回归模型中，仅使用预测变量的滞后值是否很常见？例如

选项 1

$$
s_{t} = f(i_{t}, i_{t-1}, u_{t}, u_{t-1})
$$

选项 2

$$
s_{t} = f(i_{t}, u_{t})
$$
其中 $s_{t}$ 是时间 $t$ 的销售额，而 $i_{t}$ 和 $u_{t}$ 是通货膨胀以及 $t$ 时刻的失业率。
我的逻辑是，也许前一个时间段的信息比当前时间段的信息更能描述销售额？选项 2 是统计分析建模中的常见做法吗？还是非滞后变量也是强制性的（选项 1）？]]></description>
      <guid>https://stats.stackexchange.com/questions/656870/only-using-a-lagged-predictor-in-a-regression-model-and-not-the-unlagged</guid>
      <pubDate>Thu, 07 Nov 2024 05:02:57 GMT</pubDate>
    </item>
    </channel>
</rss>