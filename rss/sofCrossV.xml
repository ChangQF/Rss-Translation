<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 07 Sep 2024 06:21:19 GMT</lastBuildDate>
    <item>
      <title>如何在 R Notebook 中预览图表？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653994/how-to-preview-plots-in-r-notebook</link>
      <description><![CDATA[我正尝试在 R Notebook 中为我的数据集绘制相关图和周期图，如果我理解正确的话，R Notebook 提供了预览图的功能，而不必像 R Markdown 那样进行编织。但是，即使我能够在 Markdown 下编织和查看图，我仍然不知道如何在 Notebook 下预览这些图。我已将代码附加在下面。我真的很感激您在这方面提供一些建议。
如果这个问题看起来很愚蠢，我很抱歉，但我是一个完全的初学者，我尝试浏览互联网，但仍然找不到解决方案。
---
title：“R Notebook”
输出：html_notebook
---

```{r setup, include=False} # 此代码块已隐藏
knitr::opts_chunk$set(echo = TRUE) # 其余代码块及其输出将显示 
```

```{r}
dollar &lt;- scan(&quot;/Users/Desktop/dollar.txt&quot;) # 将数据集分配给变量 dollar
dollar &lt;- ts(log(dollar)) # 将数据集转换为对数刻度 ts 对象
```

```{r}
# 绘制原始数据的相关图
acf(dollar, main=&quot;Correlogram of the Time Series&quot;, lag.max = 20) 

# 绘制原始数据的周期图
spec.pgram(dollar, main = &quot;Periodogram of Time Series&quot;, demean=T,detrend=F)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/653994/how-to-preview-plots-in-r-notebook</guid>
      <pubDate>Sat, 07 Sep 2024 04:50:45 GMT</pubDate>
    </item>
    <item>
      <title>掷骰子游戏的平均等待时间</title>
      <link>https://stats.stackexchange.com/questions/653991/mean-waiting-time-for-a-dice-rolling-game</link>
      <description><![CDATA[我一直在尝试解决一个概率问题，但答案让我有点困惑。这个问题来自 Wolfgang Schwarz 的《40 个概率和数理统计中的谜题和问题》：

Peter 和 Paula 玩一个简单的掷骰子游戏，如下所示。Peter 不断掷骰子（无偏），直到连续两次掷出序列 1-1。对于 Paula 来说，规则类似，但她会掷骰子，直到连续两次掷出序列 1-2。平均而言，两人都必须掷骰子的次数相同吗？如果不是，谁的预期等待时间更短（不需要明确计算）？

解决方案指出：

Peter 的序列通常由一定数量的 1 组成，每个 1 后面跟着一个不同于 1 的数字，p = 5/6。如果在获得 1 之后，他未能实现所需的 1-1 运行，则抛出的数字必然不同于 1，因此不能构成潜在 1-1 运行的潜在开始。对于 Paula 来说，情况有所不同：如果她在初始 1 之后未能抛出 2，那么她可以通过抛出另一个 1 来做到这一点，而这又可能是潜在 1-2 运行的开始。因此，Paula 的预期等待时间会稍微短一些。

我不太理解这个解决方案，也许我误解了问题/解决方案。据我所知，建议是 Paula 可以先投 1，然后再投 1，这不会是胜利，但会形成 1-2 连胜的潜在开端。让我感到困惑的是，这个序列 (1-1) 为 Peter 带来了胜利，所以 Peter 在这种情况下肯定有优势？]]></description>
      <guid>https://stats.stackexchange.com/questions/653991/mean-waiting-time-for-a-dice-rolling-game</guid>
      <pubDate>Fri, 06 Sep 2024 22:49:15 GMT</pubDate>
    </item>
    <item>
      <title>二维空间中数据之间的引导差异的大小和方向性</title>
      <link>https://stats.stackexchange.com/questions/653988/magnitude-and-directionality-of-bootstrapped-differences-between-data-in-a-2d-sp</link>
      <description><![CDATA[TL;DR：图中蓝色和橙色的自举分布是否不同？这种差异的方向性是什么？
我正在使用类似互相关方法分析两组多元时间序列。（改编自 Seibold &amp; McPhee 1979 和 Hebart et al. 2018）在每一对时间点，分析都会分离两个假设模型 Model1 和 Model2 的共同贡献。这为 Model1 和 Model2 生成了一个重要时间点聚类的 2d 空间。在下面的散点图中：

X 轴和 Y 轴代表每个时间序列。
2 个黑边蓝色和橙色实心圆，位于对角线上方约 (450, 475) 和 (650, 675) 处，是 Model1 和 Model2 聚类的观察到的质心。
许多开放圆是通过对 12 个配对时间序列重新采样约 500 次计算出的引导质心。
基础数据包括 12 个受试者，从中提取配对时间序列，取平均值并进行分析以获得 Model1 和 Model2 的聚类。引导需要对 12 个受试者样本进行重新采样。


我想评估质心是否彼此不同，最好使用考虑方向性的指标。此外，我想评估聚类是否倾向于对角线的一侧或另一侧。（解释是模型先描述一个时间序列，而不是同时描述另一个时间序列。）例如，散点图中的蓝色“趋向”朝向对角线上方。
在熟悉的 1d 情况下，我会检查，例如，自举 (Model2-Model1) 差异分数的 97.5% 以上是否为正。在 2d 情况下，距离出现在 x-y 平面中；因此，将分析投影到一个轴或对角线上会牺牲有用的信号。计算每个自举的欧几里得距离会忽略质心的相对位置，因此距离永远不会为负（甚至在给定噪声的情况下为零）。Kolmogorov-Smirnov 和符号检验很容易区分分布，但假设样本独立，而自举样本违反了这一点。我不确定在这种情况下如何评估分布之间的 2-d 马哈拉诺比斯距离与偶然性。我是否缺少适当的敏感度量，或者我在统计上是否正确？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653988/magnitude-and-directionality-of-bootstrapped-differences-between-data-in-a-2d-sp</guid>
      <pubDate>Fri, 06 Sep 2024 20:59:29 GMT</pubDate>
    </item>
    <item>
      <title>将带有 Arima 误差模型的回归从 R 转移到 Excel（公式帮助）</title>
      <link>https://stats.stackexchange.com/questions/653987/transferring-a-regression-with-arima-error-model-from-r-to-excel-formula-help</link>
      <description><![CDATA[您好，在此先感谢您的帮助。
我正在尝试将 arima 模型转换为 excel 电子表格，以便计算我正在研究的内容。
该模型是一个 4,1,0 模型，我使用 R 中的 Arima 函数进行拟合。
输出系数为 ar1:.2499 ar2:-.0060 ar3:-.1258 ar4:-.0046
xreg 系数为 -29.5243。
无论我怎么尝试，我似乎都无法正确得到公式，并且输出也不一致。我想我感到困惑的是，如果我在 Arima 错误中包含一个差异因子，我不确定如何在后端解释这一点（或者是否必须这样做）。
在此先谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/653987/transferring-a-regression-with-arima-error-model-from-r-to-excel-formula-help</guid>
      <pubDate>Fri, 06 Sep 2024 20:22:36 GMT</pubDate>
    </item>
    <item>
      <title>散点图的视觉评估可以接受吗？</title>
      <link>https://stats.stackexchange.com/questions/653986/visual-assessment-of-scatterplots-acceptable</link>
      <description><![CDATA[我有一个相当基本的问题，关于分析对一些鱼类进行测量的数据集，这是我作为学生项目的一部分进行的。因此，我对四种鱼类进行了测量，我知道这些鱼类的种类（基于 DNA 分析），每组大约有 50 只鱼。此外，我还有十几条未知物种的鱼。我想探索是否可以根据测量结果将未知个体归类为一个物种。事实上，之前的一项研究已经证实了这一点。然而，未知个体很可能属于多个物种。因此，将它们作为一个群体进行分析是没有意义的。因此，它们必须作为个体进行独立分析，而之前研究中进行的典型测试（学生 t 检验、方差分析）将很难应用。
到目前为止，我只在 xy 轴上绘制了测量值，以直观地评估标本与已知鱼类群体的关系。然而，我因没有使用任何适当的统计测试来做出区分而受到批评。所以我有两个问题：1）仅仅对数据进行视觉评估在多大程度上是“错误的”？我知道这是处理数据的一种简单方法，但这是否必然会使我的分析无效？特别是因为未知样本一次只能分析一个。这在多大程度上是可以接受的？2）还有哪些其他测试有用？]]></description>
      <guid>https://stats.stackexchange.com/questions/653986/visual-assessment-of-scatterplots-acceptable</guid>
      <pubDate>Fri, 06 Sep 2024 20:01:15 GMT</pubDate>
    </item>
    <item>
      <title>正确分析解释异常研究设计</title>
      <link>https://stats.stackexchange.com/questions/653985/correct-analysis-interpretation-of-unusual-study-design</link>
      <description><![CDATA[英国皇家麻醉师学院的国家审计项目是一系列研究麻醉罕见并发症的项目。例子包括严重的过敏反应和心脏骤停。（对于任何想阅读具体内容的人，我建议阅读最简单的 NAP3）
他们使用的方法我不熟悉，我正在努力寻找正确分析的良好参考。他们试图估计这些事件的频率，并提出风险因素。基本思想是：

测量分母

执行“活动调查” - 让医院在短时间内（通常是几天到几周左右）记录（匿名）他们处理的每个病例
将其乘以得到感兴趣时间段的分母


测量分子

要求医院报告感兴趣的并发症 - 这一阶段持续更长的时间（通常是几个月）



尝试应用我已经知道的知识，显然这是一项观察性研究；它不是横断面数据，也不是病例对照研究；它看起来有点类似于前瞻性队列研究 - 我们正在观察一段时间内确定的一组人并计算事件 - 但有一些不同：

没有明确定义的队列 - 我们不能谈论被招募到这项研究中的个人，直到他们发生事件
“伪队列”在短时间内进行测量，然后推断出如果我们在感兴趣的时间段内招募，情况可能会如何
只有经历过事件的患者的暴露数据才是众所周知的

这可能是我职业生涯中收集的有关这些事件的最佳数据，它在麻醉实践中被广泛使用，因此正确理解它非常重要。
我的问题是：

这种研究有一个众所周知的名字吗？ （即我可以搜索什么？）
是否有分析此类研究的标准方法或指南？
是否有很好的方法来解释分母数据的不确定性？
使用标准频率学派技术分析此类数据的传统队列研究是否合理？（这很重要，因为这是他们所做的！）
]]></description>
      <guid>https://stats.stackexchange.com/questions/653985/correct-analysis-interpretation-of-unusual-study-design</guid>
      <pubDate>Fri, 06 Sep 2024 19:47:15 GMT</pubDate>
    </item>
    <item>
      <title>有什么方法可以让我练习概率和统计的大 O 符号吗？</title>
      <link>https://stats.stackexchange.com/questions/653984/any-way-i-can-practice-big-o-notations-for-probability-and-statistics</link>
      <description><![CDATA[我一直在使用泰勒展开式来获得一些感受和许多近似结果，试图为我的研究找到创新的想法。而且我已经看到了很多近似相等或渐近相等。我想把它们变成等式和大 O 符号，使它们成为严格和精确的误差界限，例如，f=g+O(...)。
我应该在哪里学习基础知识？有没有系统的方法可以练习和提高？我只学过本科水平的实分析。我还需要上其他课程吗？任何帮助都值得感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653984/any-way-i-can-practice-big-o-notations-for-probability-and-statistics</guid>
      <pubDate>Fri, 06 Sep 2024 19:38:14 GMT</pubDate>
    </item>
    <item>
      <title>在二元变量上对模型输出进行测试</title>
      <link>https://stats.stackexchange.com/questions/653982/test-between-model-output-over-a-binary-variable</link>
      <description><![CDATA[我有一组特征，包括一个二进制变量（称为 $B$）和一些其他变量（二进制或数值变量，我们称这些协变量为 $X$）。
我有一个目标变量，可以是二进制的，也可以是数值的，但我们简单来说，它是数值的，称为 $Y$。
我拟合了一个模型 $M$，以根据特征 $X$ 和 $B$ 预测 $Y$。该模型可以是“优化的”，也可以是垃圾，这无关紧要。事实是模型是拟合的。
现在我预测（使用相同的训练数据或一些看不见的测试数据，我不认为它真的改变了问题？）两个数量。

$Y_{B=1}$ 是当对于个体，我保持其为协变量 $X$，但我强制二元特征 $B$ 为 $1$（即使个体的 $B$ 的实际值不是 $1$）。
$Y_{B=0}$ 是当对于个体，我保持其为协变量 $X$ 但我强制二元特征 $B$ 为 $0$。

然后我想知道平均而言这两个量是否不同。因此，从统计上看，$Y_{B=1} = Y_{B=0}$ 是否等同于 $Y_{B=1} - Y_{B=0} = 0$，并得到该假设的 p 值。
例如，使用没有交互项的简单线性回归，我可以检查 $B$ 的系数和相关的 p 值（并且差值 $Y_{B=1} - Y_{B=0}$ 在这种情况下始终相同，并且等于 $B$ 系数）。
但对于更复杂的模型（随机森林等），通常会有一些相互作用。
所以，我的问题是：哪种统计检验（或测试）似乎合适吗？

数据不独立（$Y_{B=1}$ 和 $Y_{B=0}$ 仍然依赖于同一模型 $M$ 和协变量 $X$）。
组间方差（$B=1$ 和 $B=0$）可能不同。

我寻找了治疗效果（ATE、ATT 等）的估计，但没有找到我可以使用哪种测试的明确解释，因为在这些情况下通常使用简单的线性回归模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/653982/test-between-model-output-over-a-binary-variable</guid>
      <pubDate>Fri, 06 Sep 2024 18:12:06 GMT</pubDate>
    </item>
    <item>
      <title>使用 r 中的 glmer 函数进行预测（二项式数据）</title>
      <link>https://stats.stackexchange.com/questions/653981/predicting-with-the-glmer-function-in-r-binomial-data</link>
      <description><![CDATA[我正在尝试使用 glmer 函数对嵌套数据进行预测。我有来自田地中多个设备的纵向数据，这些设备要么是控制设备，要么是封闭设备。我创建了验证，这样训练集和验证集就不会有相同的设备，因为设备之间存在相关性。在我建立模型并进行预测后，它只预测了控制处理。我不确定我做了什么。总共有 60 000 个观测值，50 个设备，其中 39 个是控制设备，11 个是封闭设备。下面是代码以及前 6 个预测值的样子
cont_data_st = filter(evening_data,treatment==&quot;control&quot;) ##control data
exc_data_st = filter(evening_data,treatment==&quot;exclusion&quot;) ##exclosure data 
devices_cont_st = unique(cont_data_st$station_id) ##control devices
devices_exc_st = unique(exc_data_st$station_id) ##exclosure devices

set.seed(1000)
a = sample(devices_cont_st,27)
b = sample(devices_exc_st,8)

train_devices_st = c(a,b)
train_st &lt;- filter(evening_data,station_id %in% train_devices_st) 
valid_st &lt;- filter(evening_data,!station_id %in% train_devices_st) 

glm_st = glmer(treatment ~ total_ent + aci + bi + ndsi + (1|station_id),
data = train_st,
family =binomial(link = &#39;logit&#39;))

pred = predict(glm_st, type=&quot;response&quot;,newdata=valid_st,allow.new.levels=TRUE)
pred
1 2 3 4 5 6 
1.915576e-09 8.840530e-10 7.312132e-10 6.585357e-09 3.300025e-09 3.662728e-09 

]]></description>
      <guid>https://stats.stackexchange.com/questions/653981/predicting-with-the-glmer-function-in-r-binomial-data</guid>
      <pubDate>Fri, 06 Sep 2024 17:59:20 GMT</pubDate>
    </item>
    <item>
      <title>混合效应逻辑回归模型中的膨胀固定效应</title>
      <link>https://stats.stackexchange.com/questions/653977/inflated-fixed-effects-in-mixed-effects-logistic-regression-model</link>
      <description><![CDATA[我有一个数据集，每个 ID 有多个观测值，并且有一个二元结果。我试图拟合混合效应逻辑回归，但是，截距的固定效应估计值与我的预期相比非常大。无论我使用的是哪个统计软件包或 R 版本，这都是正确的：
library(lme4)
library(glmmTMB)
library(brms)

fit_lme4 &lt;- glmer(outcome ~ (1 | ID), data = data, family = &quot;binomial&quot;)
fit_TMB &lt;- glmmTMB(outcome ~ (1 | ID), data = data, family = &quot;binomial&quot;)
fit_brm &lt;- brm(outcome ~ (1 | ID), data = data, family = bernoulli(link=&quot;logit&quot;))

mean(data$outcome) # 0.7371429
plogis(fixef(fit_lme4)) # 0.9993405
plogis(fixef(fit_lme4)$cond) # 0.9993405
plogis(summary(fit_brm)$fixed[[1]]) # 0.9452537

以下是用于重现上述脚本的 data 的内容。
我怀疑这可能是因为许多 ID 总是有相同的结果（例如，对于 ID 1，结果始终为 1），但我不确定。
对此有什么潜在的解决方案？]]></description>
      <guid>https://stats.stackexchange.com/questions/653977/inflated-fixed-effects-in-mixed-effects-logistic-regression-model</guid>
      <pubDate>Fri, 06 Sep 2024 16:43:55 GMT</pubDate>
    </item>
    <item>
      <title>样本中未观察到任何事件时的患病率上限</title>
      <link>https://stats.stackexchange.com/questions/653965/prevalence-upper-bound-when-no-events-are-observed-in-sample</link>
      <description><![CDATA[在 2000 个观察样本中，未发现阳性病例，但我仍然希望能够提供患病率的上限。
人们似乎使用的一般规则是简单地取 3/n，但这与样本中发现 1 个病例的 95% 上限相同。
3/2000=0.15%，2000 年患病率为 1 例的 95% 上限为 0.15%。
如果观察到 0 个病例，上限肯定应该低于发现 1 个病例的情况？我可以使用其他方法来与其他频率结果在一定置信水平下的上限保持一致吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653965/prevalence-upper-bound-when-no-events-are-observed-in-sample</guid>
      <pubDate>Fri, 06 Sep 2024 12:04:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么置信度 > 50% 还不是“足够好”？</title>
      <link>https://stats.stackexchange.com/questions/653946/why-isnt-a-confidence-level-of-anything-50-good-enough</link>
      <description><![CDATA[我上过研究生水平的统计学课程，所以问这个问题感觉自己很蠢，但我不明白 95% 置信度背后的含义。（请对我好一点。）
我目前正在对两张图片进行 A/B 测试，用于营销。测试将运行并收集数据，直到它能够在 95% 的置信度下做出决定。
当前置信率为 76.55%，其中 A 的点击率为 2.5%，B 的点击率为 4.55%。
由于 A 和 B 在 50% 的置信度下大致相等（一个设计没有显示出比另一个更好），为什么我要等到 95% 的置信度？在 50% 的置信度下，我选择哪种设计并不重要，而在 76.55% 的置信度下，我已经显示 B 的表现优于 A。
我想我不明白为什么我现在不能做出决定。如果是在制药情况下进行测试，比如生死攸关场景中的药物，我觉得我应该等待 95%，但对于像图像选择这样低风险的事情...]]></description>
      <guid>https://stats.stackexchange.com/questions/653946/why-isnt-a-confidence-level-of-anything-50-good-enough</guid>
      <pubDate>Fri, 06 Sep 2024 01:33:52 GMT</pubDate>
    </item>
    <item>
      <title>做t检验时，样本标准差应该用样本均值减去原假设均值来估计吗？</title>
      <link>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</link>
      <description><![CDATA[以 t 检验为例，检验实数样本$x_i$是否来自均值为 0 的分布（$H_0:\mu=0, H_a:\mu \neq 0$）。检验统计量将是$t=\frac{\bar{x}}{s/\sqrt{n}}$。
我的问题是$s^2=\frac{\sum_i(x_i - \bar{x})^2}{n-1}$还是$s^2=\frac{\sum_i x_i^2}{n}$。
在大多数文本中我看到的是前者，但在财务数据中我有时看到后者。两者似乎也都说得通，前者使用正态样本标准差公式，后者使用零假设，也不再需要贝塞尔校正。
两者的优缺点是什么，有没有更合适的方法？
编辑：总结一下，看起来只要对任一检验统计量进行适当的处​​理以获得分位数，检验都是等效的。但即使不这样做，它们也都渐近地接近同一件事。]]></description>
      <guid>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</guid>
      <pubDate>Thu, 05 Sep 2024 10:20:49 GMT</pubDate>
    </item>
    <item>
      <title>比较敏感性和特异性——保持一个稳定以便与另一个进行比较？</title>
      <link>https://stats.stackexchange.com/questions/653882/comparison-sensitivity-and-specificity-hold-one-stable-for-comparison-of-the-o</link>
      <description><![CDATA[给定两个二元诊断测试 T1 和 T2，我想比较这两个测试在对一组受试者进行测试时的敏感性和特异性。每个受试者都将接受这两项测试，并且诊断试图预测“真相”的黄金标准来源。这样，我对敏感性或特异性进行了配对比较，McNemar 测试似乎最合适。
有人建议，要比较这两个测试之间的敏感性，我需要找到提供相同特异性值的每个测试的分数截止值，然后我可以将敏感性与 McNemar 测试进行比较。也有人提出相反的观点 - 要比较特异性，敏感性必须相同。
鉴于这是对两个不同测试的验证，每个测试都有一个在测试开发期间确定的特定分数截止值。似乎应该比较在这些预定截止值下观察到的敏感性和特异性，而不是调整截止值以使敏感性或特异性相同，然后比较另一个。
我的解释正确吗？在我看来，应该通过每个测试在预定截止值下观察到的敏感性和特异性来进行这种比较。还是我误解了？]]></description>
      <guid>https://stats.stackexchange.com/questions/653882/comparison-sensitivity-and-specificity-hold-one-stable-for-comparison-of-the-o</guid>
      <pubDate>Thu, 05 Sep 2024 02:11:04 GMT</pubDate>
    </item>
    <item>
      <title>当必须使用抽样权重时，回归系数可以进行引导吗？</title>
      <link>https://stats.stackexchange.com/questions/652716/can-regression-coefficients-be-bootstrapped-when-sampling-weights-must-be-used</link>
      <description><![CDATA[我有非复杂调查数据 - 它有样本权重，但没有其他关于调查设计需要考虑的因素。我想使用权重获得回归系数的引导分布。我希望引导主要用于计算具有较少假设的置信区间 (CI)。
我发现了大量关于加权回归的文献（和实现），以及大量关于引导的文献，但我几乎没有找到关于将两者结合起来的文献。我的直觉是尝试这样做：使用抽样权重创建引导样本以加权引导抽样，为每个引导样本建立一个非加权模型，然后我得到了引导系数的集合。但我有一种挥之不去的感觉，这种方法对 CI 的惩罚不够。当我使用权重时，我的错误应该更大 - 但不会这样（或者会这样吗？）？]]></description>
      <guid>https://stats.stackexchange.com/questions/652716/can-regression-coefficients-be-bootstrapped-when-sampling-weights-must-be-used</guid>
      <pubDate>Tue, 13 Aug 2024 13:44:25 GMT</pubDate>
    </item>
    </channel>
</rss>