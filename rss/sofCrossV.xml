<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 17 Dec 2023 06:16:14 GMT</lastBuildDate>
    <item>
      <title>马修相关系数和留一交叉验证</title>
      <link>https://stats.stackexchange.com/questions/635098/matthews-correlation-coefficient-and-leave-one-out-cross-validation</link>
      <description><![CDATA[如何确定留一交叉验证的马修相关系数？似乎没有一种方法可以对跨折叠的系数进行平均 - 一个元素不足以支持计算 MCC。]]></description>
      <guid>https://stats.stackexchange.com/questions/635098/matthews-correlation-coefficient-and-leave-one-out-cross-validation</guid>
      <pubDate>Sun, 17 Dec 2023 03:42:41 GMT</pubDate>
    </item>
    <item>
      <title>计算两个样本的第 90 个百分位数的差异</title>
      <link>https://stats.stackexchange.com/questions/635097/calculate-difference-in-90th-percentiles-of-two-samples</link>
      <description><![CDATA[我有一个质量改进更改前后的救护车响应时间数据集。我想看看更改前后的响应时间是否有差异。具体来说，我试图报告两组（之前和之后）中的第 90 个百分位数值、两个第 90 个百分位数之间的差异、$95$% 置信区间（ CI) 围绕这个差异，以及一个 $p$ 值。
在 R 中，数据集可能如下所示：
set.seed(123)
数据 &lt;- data.frame(
  组=样本（c（“之前”，“之后”），100，替换= TRUE），
  响应时间 = rnorm(100, 平均值 = c(10, 15), sd = 2)
）

我可以使用 t.test 函数轻松测试均值差异：
t.test(data$ResponseTime[data$Group == “之前”],
       数据$ResponseTime[数据$Group ==“之后”])

我还可以像这样计算第 90 个百分位数：
之前 &lt;- 分位数(a$ResponseTime[a$Group==“之前”], probs = 0.9, na.rm = T)
&lt;- 分位数（a$ResponseTime[a$Group==“之后”]，probs = 0.9，na.rm = T）

但我不知道如何比较两者。
我的问题：

这有意义吗？
如果确实有意义，我会使用什么测试来比较第 90 个百分位数？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635097/calculate-difference-in-90th-percentiles-of-two-samples</guid>
      <pubDate>Sun, 17 Dec 2023 02:55:47 GMT</pubDate>
    </item>
    <item>
      <title>样条的二阶导数</title>
      <link>https://stats.stackexchange.com/questions/635095/2nd-derivative-of-spline</link>
      <description><![CDATA[这个问题与之前的相关问题有一些相似之处。
如何将样条曲线拟合到包含值和一阶/二阶导数的数据？
我浏览了那篇文章中提到的建议，理论没有问题，但我不确定如何在 R 中实现它。所以基本上我问一个类似的问题，想知道是否有任何简单的解决方案来计算第二个使用下面这个例子的三次样条的导数。
#加载样条曲线包
需要（样条线）

#ISLR 包含数据集
要求（ISLR）
Attach(Wage) #附加工资数据集

Agelims &lt;- 范围（年龄）

#生成测试数据
age.grid &lt;- seq(from=agelims[1], to =agelims[2])


这是具有 3 个节点（分割点）的三次样条曲线

#3 年龄划分点 25 ,50 ,60
bs(年龄, 结 = c(25,40,60))

如何计算三次样条函数 bs 的二阶导数？任何建议都将受到高度赞赏。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/635095/2nd-derivative-of-spline</guid>
      <pubDate>Sun, 17 Dec 2023 00:14:07 GMT</pubDate>
    </item>
    <item>
      <title>比较两个分类器的多类概率</title>
      <link>https://stats.stackexchange.com/questions/635094/compare-multiclass-probabilities-for-two-classifiers</link>
      <description><![CDATA[我有两种算法，可以为每次观察生成 3 个类别的概率向量
&lt;前&gt; &lt;代码&gt; |算法 1 |算法2
-------------------------------------------------
观察 1 | [0.5, 0.3, 0.2] | [0.3,0.3,0.4]
观察2 | [0.3, 0.2, 0.5] | [0.1,0.1,0.8]
观测 3 | [0.2, 0.2, 0.6] | [0.2,0.4,0.4]
....

我想比较这些算法的相似程度。一种简单的方法是将概率向量转换为获胜类别并评估简单的准确度，即匹配次数/观察次数。
是否有可以比较概率向量的测量或统计测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/635094/compare-multiclass-probabilities-for-two-classifiers</guid>
      <pubDate>Sun, 17 Dec 2023 00:04:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么我要为二项式数据选择 beta 先验？更一般地说，我将如何选择先验分布？</title>
      <link>https://stats.stackexchange.com/questions/635091/why-would-i-pick-a-beta-prior-for-binomial-data-more-generally-how-would-i-pic</link>
      <description><![CDATA[显然，作为共轭先验是有用的，因为它可以节省执行棘手的积分或使用模拟，但为什么我要使用 beta 分布呢？更一般地说，如何选择合适的分布作为先验分布？显然，分布可以取的值范围是一个需要考虑的因素，但我们怎么能说我们从先前的经验中相信的内容对应于特定的先验分布呢？
我们可以创建无数种发行版，但我们依赖于选择一个具有“名称”的发行版进行分析。我无法理解如何断然地说特定的先验分布是我们认为最好的分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/635091/why-would-i-pick-a-beta-prior-for-binomial-data-more-generally-how-would-i-pic</guid>
      <pubDate>Sat, 16 Dec 2023 22:59:07 GMT</pubDate>
    </item>
    <item>
      <title>我要报告哪个 Levene 统计数据？</title>
      <link>https://stats.stackexchange.com/questions/635090/which-levene-statistic-do-i-report</link>
      <description><![CDATA[我正在写一篇论文，比较 $5$ 组的定量值。我在 SPSS 29 中执行了方差分析，并要求软件使用 Levene 统计量来判断 $5$ 组之间的方差是否存在同质性。
该软件报告了均值、中位数、基于 df 调整均值的检验以及截尾均值的 Levene 统计量。
我如何知道要使用哪个 Levene 统计数据？有些很重要，有些则不然，所以这会改变我使用的事后测试。我是否必须先运行 Kolmogorov-Smirnov 检验才能知道我的数据是否存在偏差，还是有更快的方法？修剪和调整 df 是什么意思？]]></description>
      <guid>https://stats.stackexchange.com/questions/635090/which-levene-statistic-do-i-report</guid>
      <pubDate>Sat, 16 Dec 2023 22:48:19 GMT</pubDate>
    </item>
    <item>
      <title>生存研究中的单变量分析</title>
      <link>https://stats.stackexchange.com/questions/635089/univariant-analysis-in-survival-study</link>
      <description><![CDATA[我对统计和生存分析了解不多，所以这可能是一个无聊的问题。
我正在进行生存分析，我想研究在另一例直肠病理手术后可能导致直肠病理发生的可能风险或保护因素。我想获得 Kaplan Meier 曲线并使用对数秩检验对它们进行比较。我的问题是我是否可以通过对数秩检验获得单变量 HZ（因为我一直在阅读 de Cox 回归分析是多变量的）。之后，我想向多变量分析介绍在单变量分析中具有统计显着性的变量。在这种情况下，我应该使用 Cox 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635089/univariant-analysis-in-survival-study</guid>
      <pubDate>Sat, 16 Dec 2023 22:40:43 GMT</pubDate>
    </item>
    <item>
      <title>如何使用逻辑回归评估分类的病例级不确定性？</title>
      <link>https://stats.stackexchange.com/questions/635088/how-can-i-assess-case-level-uncertainty-of-classification-using-logistic-regress</link>
      <description><![CDATA[我希望拟合一个二元逻辑回归来预测新案例/观察的二元结果。我想知道是否有任何方法可以衡量个别案例预测的不确定性 - 例如，如果我使用我的模型来预测 500 个案例中的二元结果（未用于构建模型），对于每个案例，是否有可能了解预测结果的确定性？由于逻辑回归的结果是 0 到 1 之间的概率，其中概率 &lt; 1。 0.5通常对应于二进制结果0并且概率&gt;1。 0.5 对应于二元结果 1，假设单个案例的预测概率与 1 或 0 的接近程度对应于该案例的估计的不确定性是否符合逻辑？如果没有，是否有其他方法可以实现这一目标，或者除了逻辑回归之外的分类方法可能更合适？
希望这是有道理的，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635088/how-can-i-assess-case-level-uncertainty-of-classification-using-logistic-regress</guid>
      <pubDate>Sat, 16 Dec 2023 22:13:03 GMT</pubDate>
    </item>
    <item>
      <title>对于软标签使用 KL 散度而不是交叉熵更好吗？</title>
      <link>https://stats.stackexchange.com/questions/635027/is-it-better-to-use-kl-divergence-for-soft-labels-instead-of-cross-entropy</link>
      <description><![CDATA[所以我正在阅读这篇论文：在 Fuse 之前对齐：利用动量蒸馏进行视觉和语言表示学习 (2017) 由 Junnan Li 等人提出，他们使用 KL 散度执行对比损失。
$$
L_{\text{ITC}} = (1 - \alpha) L_{\text{对比度}} + \frac{\alpha}{2} \left[ \text{KL} \left( q^{i2t} \平行 p^{i2t} \right) + \text{KL} \left( q^{t2i} \平行 p^{t2i} \right) \right]
$$
在此方程中，LITC-base​是基础图像文本对比损失，$\alpha$是权重因子，DKL表示KL散度，&lt; span class=&quot;math-container&quot;&gt;$q^{i2t}$ 和 $q^{t2i}$ 是预测分布（从图像到分别为文本和文本到图像），以及 $p^{i2t}$ 和 $p^{t2i}$&lt; /span&gt; 是 KL 散度项的目标分布。

但是，在实现中，交叉熵使用损失，而不是明确地使用KL散度。KL散度用于与软标签的对比损失。这种方法理论上可以避免损失图中出现大的恒定熵，如图所示，即使在反向传播时不使用熵，也可能会掩盖减少。
但是，该实现利用了交叉熵损失。这就提出了为什么选择交叉熵而不是论文中指定的 KL 散度的问题，特别是考虑到对解释训练损失曲线的影响，因为由于高熵掩盖了 KL 散度和论文，我们将无法看到 KL 散度的减少明确提到使用软伪标签进行对比学习。这是一个实际的实施决策，还是反映了模型学习过程的更深层次？
与 torch.no_grad():
            self._momentum_update()
            image_embeds_m = self.visual_encoder_m(图像)
            image_feat_m = F.normalize(self.vision_proj_m(image_embeds_m[:,0,:]),dim=-1)
            image_feat_all = torch.cat([image_feat_m.t(),self.image_queue.clone().detach()],dim=1)
            text_output_m = self.text_encoder_m.bert（text.input_ids，attention_mask = text.attention_mask，
                                                return_dict = True, 模式 = &#39;文本&#39;)
            text_feat_m = F.normalize(self.text_proj_m(text_output_m.last_hidden_​​state[:,0,:]),dim=-1)
            text_feat_all = torch.cat([text_feat_m.t(),self.text_queue.clone().detach()],dim=1)

            sim_i2t_m = image_feat_m @ text_feat_all / self.temp
            sim_t2i_m = text_feat_m @ image_feat_all / self.temp

            sim_targets = torch.zeros(sim_i2t_m.size()).to(image.device)
            sim_targets.fill_diagonal_(1)

            sim_i2t_targets = alpha * F.softmax(sim_i2t_m, dim=1) + (1 - alpha) * sim_targets
            sim_t2i_targets = alpha * F.softmax(sim_t2i_m, dim=1) + (1 - alpha) * sim_targets

        sim_i2t = image_feat @ text_feat_all / self.temp
        sim_t2i = text_feat @ image_feat_all / self.temp
                             
        loss_i2t = -torch.sum(F.log_softmax(sim_i2t, dim=1)*sim_i2t_targets,dim=1).mean()
        loss_t2i = -torch.sum(F.log_softmax(sim_t2i, dim=1)*sim_t2i_targets,dim=1).mean()
]]></description>
      <guid>https://stats.stackexchange.com/questions/635027/is-it-better-to-use-kl-divergence-for-soft-labels-instead-of-cross-entropy</guid>
      <pubDate>Fri, 15 Dec 2023 21:37:22 GMT</pubDate>
    </item>
    <item>
      <title>我的非线性问题的最大似然估计量是多少？</title>
      <link>https://stats.stackexchange.com/questions/634974/what-is-the-maximum-likelihood-estimator-for-my-nonlinear-problem</link>
      <description><![CDATA[在区域 $0\leq x\leq 1$ 和 $0\leq y\leq 1$ 我在 $(x_b,y_b)$ 中放置了 1 个无线电广播电台和 N 个接收器。广播公司的立场尚不清楚。
然而，每个接收器的位置是已知的： $(x_i,y_i)$ 以及从接收器到广播器的距离：$d_i$。
距离测量中存在一些噪声，我假设这些噪声呈正态分布，均值为 0，并且所有接收器的方差相同：
$$
\sqrt{(x_i - x_b)^2+(y_i - y_b)^2} = d_i + \epsilon_i
$$
在哪里
$$
\epsilon_i \sim \mathcal{N}(0,\,\sigma^{2})
$$
我的目标是估计无线电广播公司最可能的位置：$(x_b,y_b)$。
我想通过将其表述为一个最小化问题来做到这一点。
到目前为止，我正在最小化：
$$
SE = \sum_i \left[\sqrt{(x_i - x_b)^2+(y_i - y_b)^2} - d_i\right]^2
$$
我读到，对于线性回归，最小二乘估计器也是正态分布误差假设下的最大似然估计器。
但是这对于我的非线性问题也适用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634974/what-is-the-maximum-likelihood-estimator-for-my-nonlinear-problem</guid>
      <pubDate>Fri, 15 Dec 2023 08:33:05 GMT</pubDate>
    </item>
    <item>
      <title>比率的自然对数和双向固定效应模型偏差</title>
      <link>https://stats.stackexchange.com/questions/634967/natural-log-of-ratios-and-two-way-fixed-effects-model-bias</link>
      <description><![CDATA[Bartlett 和 Partnoy (BP) (2020) 表明具有自然对数因变量（比率）的 OLS 必须在 RHS 上包含 Ln（分母），以避免偏差（请参阅第 24-28 页），除非假设分子和分母具有精确的线性关系。这是因为 $Ln(ratio)$，例如 $Ln(\frac{GDP_{it}}{population_ {it}})$ 相当于 $Ln(GDP_{it})-Ln(population_{it})$。因此，任何在 LHS 上具有 $Ln(\frac{GDP_{it}}{population_{it}})$ 的 OLS 模型都隐式假设：
$$Ln(GDP_{i})= \beta_0 + X_i + 1Ln(population_{i}) + \epsilon_{i}
\tag{E1}$$
解决方案是在 RHS 上包含 $Ln(denominator)$，就像在 TWFE 5 中一样。他们不会在面板数据的上下文中讨论这些问题具有双向固定效应 (TWFE)，如 (E2)。
问题
在 OLS 背景下是否有任何理由怀疑 BP？ (E2) 和模型 TWFE 5 是否低于正确的模型来识别 TWFE 面板环境中治疗的无偏效应？ TWFE 2 模型确实给出了治疗的有偏系数吗？是否有任何方法文献在 OLS 或 TWFE 上下文中讨论 $Ln(ratio)$ 的问题？
在模型 TWFE 5 中，$\beta_2$ 并不接近 $1$，而是 $0.92$ 在 没有单位 FE 的模型的 OLS 版本。在单位固定效应的背景下，我如何理解 BP 关于 $Ln(\frac{numerator}{denominator})$ 之间线性的观点？
下面的模型 TWFE 4 方程修正了线性假设的偏差：
$$
Ln(\frac{GDP_{it}}{人口_{it}}) = \beta_1 治疗_{it} + \beta_2 Ln(人口_{it}) + \lambda_{t} + \alpha_i + \epsilon_{it}
\标签{E2}
$$
双向固定效应模型：
&lt;前&gt;&lt;代码&gt;============================================== =================================
                                     因变量：
                 -------------------------------------------------- ---------
                  log_gdp log_gdp_pc (log_gdp-log_pop) log_gdp log_gdp_pc
                  TWFE 1 TWFE 2 TWFE 3 TWFE 4 TWFE 5
-------------------------------------------------- --------------------------
处理 -0.025 -0.025 0.059*** 0.059***
                            (0.028) (0.028) (0.020) (0.020)
                                                                            
log_pop -0.264*** -0.281*** -1.281***
                  (0.041) (0.042) (0.042)
                                                                            
-------------------------------------------------- --------------------------
TWFE 是 是 是 是 是
观察次数 1,155 1,155 1,155 1,155 1,155
R2 0.712 0.508 0.508 0.714 0.750
=================================================== ==========================
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/634967/natural-log-of-ratios-and-two-way-fixed-effects-model-bias</guid>
      <pubDate>Fri, 15 Dec 2023 03:57:04 GMT</pubDate>
    </item>
    <item>
      <title>可扩展的无序类别编码器</title>
      <link>https://stats.stackexchange.com/questions/633282/scalable-unordered-category-encoders</link>
      <description><![CDATA[我正在尝试为可扩展的目标分配问题设计一个神经元网络，并使用强化学习通过奖励反馈来训练它。我主要关心的是使神经元网络以某种方式适应不同的目标大小（如 5-100）。我使用自注意力来处理可变输入大小（输入：所有资源-目标对，因此如果有 m 资源和 n 目标，则输入形状是(m*n,pair_len))。
但我的问题是如何对目标 id 进行编码？首先，我认为最好的想法是由于 id 数据的无序性质而对其进行热编码。但我很快意识到这是不可扩展的。因为如果我想在 100 个目标问题上训练我的模型，那么 pair_len 会超过 100，并且大部分被 one-hot 向量占据，这很奇怪，我认为可能不会有效.
所以我的问题是是否有可扩展的无序类别编码器？或者我应该妥协使用序数编码器，导致引入不必要的顺序。]]></description>
      <guid>https://stats.stackexchange.com/questions/633282/scalable-unordered-category-encoders</guid>
      <pubDate>Thu, 07 Dec 2023 07:10:26 GMT</pubDate>
    </item>
    <item>
      <title>瑞利变量的假设检验</title>
      <link>https://stats.stackexchange.com/questions/631922/hypothesis-tests-for-rayleigh-variables</link>
      <description><![CDATA[给定来自参数未知的两个瑞利分布随机变量的样本，$X \sim R(\sigma_x), Y \sim R(\sigma_y)$，我们可以使用哪些测试来确定它们的参数（$\sigma_x, \sigma_y$）是否不同以及不同程度如何？
对于瑞利变量，我们对参数 $\sigma$ 以及估计的置信区间有一个封闭形式的无偏 MLE。我们还有一个方便的事实，即瑞利参数的平方是方差，因此我们大概可以采用同方差性的一般检验。
是否有特定于瑞利分布的测试或技术？]]></description>
      <guid>https://stats.stackexchange.com/questions/631922/hypothesis-tests-for-rayleigh-variables</guid>
      <pubDate>Tue, 21 Nov 2023 02:38:16 GMT</pubDate>
    </item>
    <item>
      <title>使用 Dudley Integral 估计高斯随机矩阵的最大奇异值</title>
      <link>https://stats.stackexchange.com/questions/616636/using-dudley-integral-to-estimate-maximum-singular-value-of-gaussian-random-matr</link>
      <description><![CDATA[练习 5.14Wainwright，它提供了一种使用单步离散化界限和高斯比较不等式来估计高斯随机矩阵最大奇异值的方法，如图所示。

我们可以使用 Dudley Integral 来估计它吗？直觉上我认为它有效，但我没有解决它，因为 Wainwright 关于 Dudley Integral。我很难限制它。]]></description>
      <guid>https://stats.stackexchange.com/questions/616636/using-dudley-integral-to-estimate-maximum-singular-value-of-gaussian-random-matr</guid>
      <pubDate>Tue, 23 May 2023 00:54:47 GMT</pubDate>
    </item>
    <item>
      <title>具有节点权重的平衡图社区</title>
      <link>https://stats.stackexchange.com/questions/614837/balanced-graph-communities-with-node-weights</link>
      <description><![CDATA[我正在寻找解决以下问题的最佳起点。
我有一个包含 N 个节点的图，每个节点作为权重。我需要将所有节点分为 X 组，以便每组中的权重总和近似均匀，并且每组都是原始图的连通分量。
经过一些简单的搜索，我发现了用Python实现的lukes分区算法。
https://networkx.org/documentation/stable/reference/algorithms/ generated/networkx.algorithms.community.lukes.lukes_partitioning.html#networkx.algorithms.community.lukes.lukes_partitioning
这大约是我正在寻找的，但对于我正在使用的图表的大小来说，性能感觉很慢。
您有任何可能对您有用的更好的想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/614837/balanced-graph-communities-with-node-weights</guid>
      <pubDate>Thu, 04 May 2023 02:54:42 GMT</pubDate>
    </item>
    </channel>
</rss>