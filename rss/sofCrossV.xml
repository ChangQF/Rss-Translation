<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Fri, 14 Mar 2025 15:17:58 GMT</lastBuildDate>
    <item>
      <title>如何计算R中的重复措施MANOVA？</title>
      <link>https://stats.stackexchange.com/questions/662615/how-do-i-calculate-a-repeated-measures-manova-in-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662615/how-do-i-calculate-a-repeated-measures-manova-in-r</guid>
      <pubDate>Fri, 14 Mar 2025 15:01:21 GMT</pubDate>
    </item>
    <item>
      <title>您如何将MAE分解为偏见和差异组件？</title>
      <link>https://stats.stackexchange.com/questions/662612/how-do-you-decompose-mae-into-bias-and-variance-components</link>
      <description><![CDATA[我们对估算器的MSE具有众所周知的偏差变化权衡权衡，
  $$ MSE（\ hat f（x））= \ text {bias}（\ hat f（x））^2 + \ text {var}（\ hat f（x） + \ sigma
因此，我们可以解释为什么RSME随着估计量的偏差和可变性而增加。
但rsme的“直觉”较少。比商业用户的MAE。不幸的是，尽管MAE可能更容易解释，但它与偏见和差异的关系高度不连续：
示例：假设我们的估算器 $ x $    $（$  i.e.e。 $ e（x） class =“ Math-Container”&gt; $ \ frac12 $ 。
在这里，我们的估计器的偏差为 $ 0 $ ，总方差为 $ a^2 $  and Mae is 现在，让我们添加一些偏见 $ b = \ frac12 $ 在我们的估计器中。现在，我们获得估计器的偏差为 $ b $ 具有相同方差 $ a^2 $ 。由于错误仍然跨越 $ 0 $ ，我们只是“抢劫彼得”付钱。因此，MAE在 $ a $ 上保持不变，尽管有相同的差异和更多的偏见。
即使是怪异的，如果我们设置 $ | b |＆gt; a $ 然后 $ mae = b $  总的来说，MAE的行为似乎与偏见和可变性具有非常不连续的违反关系。
其他人注意到了吗？它使我想使用RMSE vs MAE时要犯错，因为它不涉及这种奇怪的不连续性。
 如果不是偏见和差异，您如何分解MAE？还是仅适用于MSE或更高的“甚至权力”的偏差变化。错误。 
这不是第一次由于缺乏平稳性而引起问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/662612/how-do-you-decompose-mae-into-bias-and-variance-components</guid>
      <pubDate>Fri, 14 Mar 2025 14:45:38 GMT</pubDate>
    </item>
    <item>
      <title>确定隔离森林的最佳超参数</title>
      <link>https://stats.stackexchange.com/questions/662607/determine-the-best-hyperparameters-for-isolation-forest</link>
      <description><![CDATA[我已经实施了一种用于异常检测的隔离森林算法（ 无监督的学习 ），在那里我将数据集分为1000个子集，对于每个子集，我构建了一个隔离树。这导致总共1000棵隔离树。
对于每个观察结果，我使用标准隔离公式计算异常评分，该公式提供单个异常得分。例如，对于观察1，计算的异常得分为0.65。
现在，我想确定这个单个异常得分是否是我观察结果的最佳分数。我考虑使用网格搜索来优化超参数，其中我使用不同的集合，如果值下面的超参数为：
 &#39;n_estimators&#39;：list（range（100，800，5））， 
&#39;max_samples&#39;：列表（范围（1000，1500，2000））， 
“污染”：[0.1、0.2、0.3、0.4、0.5]， 
&#39;max_features&#39;：[20,30,40]， 
&#39;bootstrap&#39;：[true，false]， 
&#39;n_jobs&#39;：[5，10，20，30]
 
我的问题：
  如何确定哪种超参数会产生最佳的异常得分？  
  由于我没有标记的数据（无监督的设置），我应该使用什么指标来评估不同的超参数集？   ]]></description>
      <guid>https://stats.stackexchange.com/questions/662607/determine-the-best-hyperparameters-for-isolation-forest</guid>
      <pubDate>Fri, 14 Mar 2025 13:40:35 GMT</pubDate>
    </item>
    <item>
      <title>Welch的T检验，具有多个测试正确</title>
      <link>https://stats.stackexchange.com/questions/662606/welchs-t-tests-with-multiple-test-correct</link>
      <description><![CDATA[我使用韦尔奇的t检验比较了测试和对照组。但是，在我的实验中，我有不同的对照组和测试组。因此，我使用RSTATIX软件包对不同的组进行了这些T检验。然后，我使用awad_pvalue纠正了p值（方法=; bh＆quot;）。
这是一种适当的方法吗？由于R中的技术问题，我无法使用ANOVA在我的图上添加P值，因此我需要坚持使用Welch的T检验。但是，审稿人声称与t检验不适合多次比较。 （注意：我对P值进行了Benjamini-Hochberg（BH）调整，但没有明确提及多次比较。）
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662606/welchs-t-tests-with-multiple-test-correct</guid>
      <pubDate>Fri, 14 Mar 2025 12:43:11 GMT</pubDate>
    </item>
    <item>
      <title>在密度预测中，是否有标准的清晰度度量？</title>
      <link>https://stats.stackexchange.com/questions/662602/in-density-forecasting-is-there-a-standard-measure-of-sharpness</link>
      <description><![CDATA[在密度预测的背景下， （2007）表征清晰度如下：

清晰度是指预测分布的浓度，仅是预测的特性。预测分布越集中，预测越来越尖锐，并且越来越越好，可以按照校准。

这不足以暗示一个清晰度的量度。在论文中，作者继续这样做：

为了评估清晰度，我们使用了预测间隔宽度的数值和图形摘要。例如，表4显示了我们最初的模拟研究中预测者中心50％和90％预测间隔的平均宽度。

然而，其他方法是可能的，例如预测密度的报告（摘要特征）方差，熵，四分位范围等。适当的评分规则也可以分解为几个要素，其中一个是清晰度，因此可以从那里采取措施。参见例如。至少对于某些适当的评分规则，有许多可能的分解，因此从不同分解中得出的清晰度的度量不一定是相同的。
 问题：在密度预测文献中是否有任何特殊的测量清晰度选择成为标准？没有考虑密度预测的具体用户，我正在考虑在学术文章中要报告的有关密度预测的应用。
 参考 

 Arnold，S.，Walz，E.M.，Ziegel，J。，＆amp; Gneiting，T。（2024）。 Decompositions of the mean连续排名的概率得分。 电子统计杂志，18 （2），4992-5044。
 Gneiting，T.，Balabdaoui，F。，＆amp; Raftery，A。E.（2007）。 概率的预测，校准和敏锐，校准和尖锐， 243-268。
]]></description>
      <guid>https://stats.stackexchange.com/questions/662602/in-density-forecasting-is-there-a-standard-measure-of-sharpness</guid>
      <pubDate>Fri, 14 Mar 2025 09:12:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么一些自变量有巨大的性病错误？</title>
      <link>https://stats.stackexchange.com/questions/662601/why-are-some-independent-variables-having-huge-std-errors</link>
      <description><![CDATA[我想知道我的结果是否正确。我不明白为什么四个独立变量有大的性病错误。
可以在此处访问数据：
 https://drive.google.com/file/d/1iefjzybovmbz1oqq1_rj5xqsi-o3b4d5/view?usp = sharing  
以下是GLM调用：
致电：
  glm（公式=练习〜Urban_zone + peri_urban_zone + rural_zone + 
    remote_rural_zone + num_female_age_10_30 + num_female_age_31_51 + 
    num_female_age_52_72 + num_female_age_73_90plus + num_male_age_10_30 + 
    num_male_age_31_51 + num_male_age_52_72 + num_male_age_age_73_90plus + 
    num_no_education + num_lower_primary + num_upper_primary + 
    num_junior_secondary + num_senior_secondary + num_tertiary + 
    num_employed + num_unemployed + num_pensioners + num_learners， 
    family =二项式，data = beanpurepractice）
 
和结果：
 系数：（3由于奇异性而未定义）
                           估计标准。错误z值pr（＆gt; | z |）  
（截距）2.69299 2.60852 1.032 0.3019  
Urban_Zoneyes -6.17754 2.53048 -2.441 0.0146 *
peri_urban_zoneyes 16.33651 6566.01336 0.002 0.9980  
rural_zoneyes -1.48510 2.13068 -0.697 0.4858  
远程_rural_zoneyes na na na na na na na na na na na  
num_female_age_10_30 -2.27482 2.41113 -0.943 0.3454  
num_female_age_31_51 2.31677 2.66000 0.871 0.3838  
num_female_age_52_72 2.62843 2.80616 0.937 0.3489  
num_female_age_73_90plus 28.03286 5429.89633 0.005 0.9959  
num_male_age_10_30 2.17702 2.20519 0.987 0.3235  
num_male_age_31_51 -0.04994 3.15402 -0.016 0.9874  
num_male_age_52_72 2.23831 3.76589 0.594 0.5523  
num_male_age_73_90plus 21.97843 8491.96006 0.003 0.9979  
num_no_education 0.61582 2.44018 0.252 0.8008  
num_lower_primary 16.32515 5412.19502 0.003 0.9976  
num_upper_primary -0.71340 2.14795 -0.332 0.7398  
num_junior_secondary 0.42343 1.77102 0.239 0.8110  
num_senior_secondary 1.00463 1.47758 0.680 0.4966  
num_tertiary na na na na  
num_employed 0.05111 2.88391 0.018 0.9859  
num_unemployed 0.63221 2.06144 0.307 0.7591  
num_pensioners -4.4.00465 3.29184 -1.217 0.2238  
num_learners na na na na na na na na  
---
象征。代码：0&#39;***’0.001&#39;**’0.01&#39;*’0.05&#39;。’0.1’’1

（二项式家族的分散参数为1）

    空偏差：94.242在119自由度上
剩余偏差：31.062 on 100自由度
AIC：71.062

Fisher评分迭代的数量：21
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662601/why-are-some-independent-variables-having-huge-std-errors</guid>
      <pubDate>Fri, 14 Mar 2025 08:30:56 GMT</pubDate>
    </item>
    <item>
      <title>如何计算样本量对假正率的影响？</title>
      <link>https://stats.stackexchange.com/questions/662600/how-to-calculate-effect-of-sample-size-on-false-positive-rate</link>
      <description><![CDATA[安慰剂对照研究（样本量为500）发现，新药将死亡率从10％降低到7％，而P = 0.04。
这种差异的理想样本量（保持80％的功率，α为0.05）为1353。
研究的批评者指出，较小的样本量增加了假正率，即使p值为0.04（假阳性率为4％）
这是真的吗？如果是这样，该研究如何计算确切的假阳性率？]]></description>
      <guid>https://stats.stackexchange.com/questions/662600/how-to-calculate-effect-of-sample-size-on-false-positive-rate</guid>
      <pubDate>Fri, 14 Mar 2025 08:28:31 GMT</pubDate>
    </item>
    <item>
      <title>解释过程宏中的适度</title>
      <link>https://stats.stackexchange.com/questions/662599/interpreting-moderation-in-process-macro</link>
      <description><![CDATA[我正在测试一个模型，该模型在SPSS中可用的过程宏中具有主持人变量。结果如下：
  因此，效果x*m是正的，这意味着随着m的增加，x对y的影响应增加。但是，当我绘制结果时，我会得到相反的情况：
  图像中
privsco2 = x
vuln_aff = y
DVP = M 
关于如何理解这些结果的任何想法？]]></description>
      <guid>https://stats.stackexchange.com/questions/662599/interpreting-moderation-in-process-macro</guid>
      <pubDate>Fri, 14 Mar 2025 08:06:47 GMT</pubDate>
    </item>
    <item>
      <title>r中的Invlogit（）以及我们是否需要使用截距和斜率或仅使用斜率来估计概率</title>
      <link>https://stats.stackexchange.com/questions/662598/invlogit-in-r-and-whether-we-need-to-use-the-intercept-and-the-slope-or-just-t</link>
      <description><![CDATA[我有兴趣估计二进制结果（y）作为X的函数的概率。使用r中的r中的glm（）在family =二项式中运行logistic回归，我获得了截距和斜率。我的问题：当试图估算y作为X函数的总体概率时，我可以使用ARM :: Invlogit（），但是我是否应该将截距和斜率用作 Invlogit（Intercept+Slope+Slope） 或Just  Invlogit（X slope of x）？？？？？？？？？？？？？？
是要回答以下问题：由于X？
我使用了一个数据集，该数据集预测冠状动脉疾病是年龄的函数，当应用 Invlogit（Slope）时，我能够获得比 Invlogit（Intercept+Slope+Slope）更现实的概率，与0.22％相比，概率约为50％？后者是不现实的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662598/invlogit-in-r-and-whether-we-need-to-use-the-intercept-and-the-slope-or-just-t</guid>
      <pubDate>Fri, 14 Mar 2025 06:48:54 GMT</pubDate>
    </item>
    <item>
      <title>面板数据中的第一差模型与固定效果</title>
      <link>https://stats.stackexchange.com/questions/662595/first-difference-models-vs-fixed-effects-in-panel-data</link>
      <description><![CDATA[我正在使用个人级别的小组数据，以研究政治意识形态如何随收入和其他财务变量而变化。但是，我正在努力决定使用单个固定效果或最初差异（而包括年份或地区等其他假人）。。
一个混乱的一点是，为什么有些研究人员会使用固定效果，而另一些研究人员则包括假人。如果固定效果说明了时间不变的个体特征，则使用其他假人使用第一差异的优势是什么？在什么情况下，一种方法比另一种方法更可取？
我感谢对这些方法之间权衡的任何见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/662595/first-difference-models-vs-fixed-effects-in-panel-data</guid>
      <pubDate>Fri, 14 Mar 2025 05:49:48 GMT</pubDate>
    </item>
    <item>
      <title>使用比例自变量</title>
      <link>https://stats.stackexchange.com/questions/662594/using-a-proportional-independent-variable</link>
      <description><![CDATA[我正在分析财富和收入不平等的偏差如何影响投票行为，使用定义为：的措施
 skewness = wally_gini / income_gini &lt; / p&gt;
但是，我担心如何解释重大结果。具体而言，如何确定偏度度量本身是否有意义，或者结果是否由基础Gini系数之一驱动？
例如，如果收入Gini与政治参与负相关，那么我的偏差措施（Gini Gini在分母中）可能最终仅仅由于相互关系而显示出积极的效果。这不一定表明偏度具有独立的效果，而是机械地捕获了收入基尼的倒数。
最好先将财富基尼和收入Gini分别包括在模型中，然后将该比例作为附加变量引入？还是有其他方法可以测试偏度度量是否具有独立的解释力？
任何建议都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/662594/using-a-proportional-independent-variable</guid>
      <pubDate>Fri, 14 Mar 2025 05:48:38 GMT</pubDate>
    </item>
    <item>
      <title>ACF或PACF的强烈时间依赖性</title>
      <link>https://stats.stackexchange.com/questions/662587/strong-temporal-dependency-with-acf-or-pacf</link>
      <description><![CDATA[我正在使用时间序列数据，其中每天由包含24×25网格的CSV文件表示，每个条目都充当像素。
我已经生成了ACF和PACF来了解我的数据的时间结构，并且整天都使用了第一个功能：
 导入statsmodels.api as s sm
导入matplotlib.pyplot作为PLT

系列= data_flatted [：，0]＃整天使用第一个功能
图，轴= plt.subplot（2，1，无花果=（10，8））
sm.graphics.tsa.plot_acf（系列，滞后= 30，ax = axes [0]）
sm.graphics.tsa.plot_pacf（系列，滞后= 30，ax = axes [1]）
plt.show（）
 
我的输出：
  从上图中，我会说短暂滞后的强大相关性表明时间依赖性很大吗？
或
我的意思是问我的数据集有任何重复模式或趋势？
或
所有数据点都可能遵循一些简单的确定性线性结构方程，并具有一些小的白噪声？
或我的数据集中存在强大的时间依赖性？]]></description>
      <guid>https://stats.stackexchange.com/questions/662587/strong-temporal-dependency-with-acf-or-pacf</guid>
      <pubDate>Fri, 14 Mar 2025 00:47:24 GMT</pubDate>
    </item>
    <item>
      <title>使用测试集评估小样本中的模型：Bootstrap与LOOCV</title>
      <link>https://stats.stackexchange.com/questions/662584/evaluating-a-model-in-a-small-sample-using-a-test-set-bootstrap-vs-loocv</link>
      <description><![CDATA[线程 评估具有小样本的分类器 考虑了其标题中的问题。具体而言，问题是要多次从其他数据分开测试集，而不仅仅是一次以减少样本外部性能的估计值的可变性。
戴夫的回答建议遵循弗兰克·哈雷尔（Frank Harrell）的建议。用戴夫的话来说，

他对样本外测试的建议是通过对整个数据集的替换，在该新样本上构建模型，评估整个数据集上的模型性能，并将此性能与在完整数据集中受过训练和评估的模型的性能进行比较。这是重复的数十个，数百或数千次，以获得性能差异的分布。再次，他的RMS书讨论了这一点。

在一个小样本中对我来说似乎直觉的另一种方法是（允许计算资源！）进行嵌套的剩余交叉验证（LOOCV）。也就是说，在外循环中，将单个观察结果分为测试集。然后在内部循环中do loocv选择和调整模型。厕所而不是k折应最大程度地减少样本外性能的估计偏差，这在处理小样本时可能非常重要，而且这里的情况也是如此。我想相对于k折的loo的差异可能是一个问题，也可能不是一个问题。在这里）。
 cbeleites在对第一个链接线程的评论中警告我，这可能不是一个好主意。我在这里发布此信息以弄清楚细节。因此，我的问题是，弗兰克·哈雷尔（Frank Harrell）的方法比我的方法更可取，如果是，我的方法的主要缺点是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/662584/evaluating-a-model-in-a-small-sample-using-a-test-set-bootstrap-vs-loocv</guid>
      <pubDate>Thu, 13 Mar 2025 19:29:28 GMT</pubDate>
    </item>
    <item>
      <title>为什么负概率密度是不正确的评分规则？反例？</title>
      <link>https://stats.stackexchange.com/questions/662570/why-is-negative-probability-density-an-improper-scoring-rule-a-counterexample</link>
      <description><![CDATA[Gneiting and Katzfuss (2014) discuss (among other things) proper scoring rules for evaluating density forecasts.引用论文（第133页），

 定义4：评分规则 $ s：f \ times r \ rightarrow \ bar r $ 相对于类 $ \ nathcal {f}
 $$ s（g，g）\ leq s（f，g）\ tag {1} $$ 
对于所有 $ f，g \ in \ Mathcal {f} $ 。如果方程式 $ 1 $ 仅在 $ f = g $ 。

以及

 定理3：得分规则 $ s $ 相对于类 $ \ nathcal {f} $ ，仅当预期得分函数 $ e $ e（$ e e（$ e e（f）， class =“数学container”&gt; $ s（f，\ cdot）$ 是 $ e $ 在点 $ f $  $  $ f $ 的超级gradeient

他们指出，线性得分， $ s（f，y）=  -  f（y）$ （即，在目标随机变量实现时评估的负概率密度函数）不是正确的得分规则，因为它不是超级级别。他们引用了Ovcharov（2013）。我在任何地方都找不到Ovcharov（2013）。此外，我并不是想研究涉及凸分析和超级成分的证据。这听起来很技术！
相反，我想了解 intuition 为什么线性得分不是适当的得分规则。理想情况下，我想要一个示例展示某个密度 $ f \ neq g $ 比真实密度 $ g $ 连续随机变量 参考 

 gneiting，T。，＆amp; Katzfuss，M。（2014年）。 概率的预测。 125-151。
 Ovcharov E.2013。多变量的本地适当评分规则。 Heidelberg大学应用数学研究所工作论文。
]]></description>
      <guid>https://stats.stackexchange.com/questions/662570/why-is-negative-probability-density-an-improper-scoring-rule-a-counterexample</guid>
      <pubDate>Thu, 13 Mar 2025 16:21:21 GMT</pubDate>
    </item>
    <item>
      <title>如何在MonoBit测试中确定阈值，为什么要比5％的显着性水平高1％？</title>
      <link>https://stats.stackexchange.com/questions/662552/how-is-the-threshold-determined-in-the-monobit-test-and-why-is-it-larger-for-a</link>
      <description><![CDATA[在随机性的单托测试中，通过或失败的阈值基于置信区间。我了解到1％的显着性水平（99％的置信度）导致阈值较大，而显着性水平为5％（95％的置信度）。
然而，这似乎是违反直觉的 - 由于较高的信心应该意味着与预期的50:50比率更少的偏差，为什么它允许在零数量和零之间有更大的差异？更严格的测试（较低的alpha）不需要较小的偏差吗？
有人可以澄清阈值是如何设定的，为什么会发生这种行为？
我尝试的是：我审查了单片测试公式，该公式根据对应于所选置信度的z得分设置阈值。我还研究了95％和99％置信度的临界值是从正态分布中得出的。
我期望的是：我期望较高的置信度（99％）会导致更严格的测试，这意味着允许的数量和零之间的差异较小。
实际发生的事情：相反，我发现较高的置信度（99％）允许在零和零之间差异更大，而95％则允许置信度更大。这似乎是违反直觉的，因为我认为更严格的测试应该忍受较小的偏差。我想澄清为什么这是数学上会发生的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662552/how-is-the-threshold-determined-in-the-monobit-test-and-why-is-it-larger-for-a</guid>
      <pubDate>Thu, 13 Mar 2025 05:18:08 GMT</pubDate>
    </item>
    </channel>
</rss>