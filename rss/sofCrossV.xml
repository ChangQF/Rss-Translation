<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 18 Jan 2025 15:15:21 GMT</lastBuildDate>
    <item>
      <title>随机森林中的迭代与 set.seed</title>
      <link>https://stats.stackexchange.com/questions/660203/iterations-vs-set-seed-in-a-random-forest</link>
      <description><![CDATA[众所周知，种子参数会影响模型性能，例如，在本线程中讨论过
另一种方法可能是迭代运行模型，如同一研究人员在此处和此处中演示的那样（“简而言之，我们使用了随机森林分类和回归算法，训练集和测试集分割为 80/20，重复 100 次&quot;)。然而，目前尚不清楚他们是否使用迭代来替代 set.seed 或与之结合，因为他们在工作中没有明确说明这一点。
不依赖种子的模型拟合迭代方法似乎是理想的，因为它会在多次运行中平均模型选择。然而，我在网上找不到足够的信息来确认或反驳这种方法的有效性。
你对这种方法有什么看法？]]></description>
      <guid>https://stats.stackexchange.com/questions/660203/iterations-vs-set-seed-in-a-random-forest</guid>
      <pubDate>Sat, 18 Jan 2025 14:58:28 GMT</pubDate>
    </item>
    <item>
      <title>在面板数据上对多元回归的 FGLS 设置协方差矩阵</title>
      <link>https://stats.stackexchange.com/questions/660201/setting-up-covariance-matrix-for-fgls-on-multiple-regressions-on-panel-data</link>
      <description><![CDATA[我将面板数据组织为一组时间指数横截面数据。也就是说，对于超过 1000 个日期，我有一组 40 个点。这 40 个点始终指代相同的“个体”。
在每个日期，我都会运行多元线性回归，因为我对系数随时间的变化很感兴趣。我使用 OLS 来查找我的参数。这些参数在每个时间 $t$ 给出：
$\hat{\beta}_t = (X^\top X)^{-1} X^\top y_t$
然而，在研究我的残差时，我发现了两件事：

横截面研究（分析每个日期的残差）表明我有异方差 - 我的残差似乎在我的值的左侧部分比右侧部分更大，并且主要显示右侧值的自相关性。
。
跨时间研究（对 40 个个体跨时间的残差进行分析）证实了残差之间存在很强的相关性。在每个时间点，我的残差都非常接近 0，尽管它们往往会相互反转（如果一个“残差组”现在为负，则另一个将“补偿”） - 正如我们在下面的相关矩阵中看到的那样：


因此，似乎 OLS 产生 BLUE 的 3 个标准之一没有得到尊重，即我没有形式为 $\sigma^2 \mathbf{I}$ 的协方差。
在这种情况下可以使用 FGLS，整个挑战出现在确定协方差矩阵 $\Omega$（或在这种情况下为 $\Omega_t$？）在 $\hat{\beta}_t = (X^\top \Omega^{-1} X)^{-1} X^\top \Omega^{-1} y_t$ 中。我发现主题讨论确定面板回归的协方差矩阵，用于“简单回归”，但不用于多重时间指数线性回归。
我的问题是：

在这种情况下，FGLS 会是一个很好的解决方案吗？在我看来，我对残差的结构及其行为有相对较好的了解，从而允许我生成一个“合乎逻辑的”协方差矩阵。
横截面多时间指数回归具有独特的优势，即用不同的数据估计相同类型的回归，从而揭示残差随时间的变化行为 - 简单地使用残差随时间的变化历史协方差矩阵作为 FGLS 中的协方差矩阵是否是一个好方法？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660201/setting-up-covariance-matrix-for-fgls-on-multiple-regressions-on-panel-data</guid>
      <pubDate>Sat, 18 Jan 2025 12:51:26 GMT</pubDate>
    </item>
    <item>
      <title>用于样本量估计的 Bootstrap。序数尺度。分布远离正态</title>
      <link>https://stats.stackexchange.com/questions/660200/bootstrap-for-sample-size-estimation-ordinal-scale-distribution-far-from-norma</link>
      <description><![CDATA[我们经常在约 100 个句子的测试翻译上比较人工翻译或机器翻译系统（每次实验中为 2 到 4 个）。
每个句子的翻译都由一名称职的翻译人员进行评分，通常为 5 分制，有时为 10 分制（分数通常为整数，但可以包括中点，例如 3.5），费用昂贵。这是我们的黄金标准，尽管不同评分者之间的结果并非 100% 一致。这意味着我正在寻找经验法则，而不是最严格的方法。
量表由口头描述定义（“小幅编辑”、“严重改变含义”等）。因此它们本质上是有序的，通常是倾斜的，有时是双峰的。
如果有两种翻译，则使用 Wilcoxon 检验来评估结果，如果有两种以上的翻译，则使用 Friedman 检验来评估结果。
如果我们无法拒绝原假设，我们可能想看看更大的样本是否有帮助。下面是我想要使用的算法。

从原始样本中生成引导样本。使用 Wilcoxon/Friedman 检验评估每个样本，并计算我们可以拒绝原假设的样本比例。这是我们估计的功效。

通过从原始样本中重复抽样来生成更大的样本，但这次取的项目要多于原始样本量。按照与上述第 (1) 点相同的方式估计检验功效。

不断增加生成的样本量，直到达到所需功效或样本量变得过大。


从实际角度来看，这有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660200/bootstrap-for-sample-size-estimation-ordinal-scale-distribution-far-from-norma</guid>
      <pubDate>Sat, 18 Jan 2025 12:37:22 GMT</pubDate>
    </item>
    <item>
      <title>交叉熵损失的方差是什么意思？</title>
      <link>https://stats.stackexchange.com/questions/660198/what-is-the-meaning-of-the-variance-of-cross-entropy-loss</link>
      <description><![CDATA[通常我们用所有测试集的交叉熵损失的平均值作为指标，那我们可以用交叉熵损失的方差作为指标吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660198/what-is-the-meaning-of-the-variance-of-cross-entropy-loss</guid>
      <pubDate>Sat, 18 Jan 2025 12:21:24 GMT</pubDate>
    </item>
    <item>
      <title>需要有关时间序列分析中使用的数据的帮助</title>
      <link>https://stats.stackexchange.com/questions/660195/need-help-regarding-the-data-used-in-time-series-analysis</link>
      <description><![CDATA[我是时间序列的初学者。我试图通过获取过去 10 年的月度数据来预测棉花作物的价格。但价格数据仅适用于 1 月至 5 月，然后是 11 月和 12 月。由于棉花在这里是季节性作物，因此没有其他月份的市场数据。那么在这种情况下，我该如何进行时间序列分析，以及我应该使用多少个最小数据点来运行模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/660195/need-help-regarding-the-data-used-in-time-series-analysis</guid>
      <pubDate>Sat, 18 Jan 2025 10:11:48 GMT</pubDate>
    </item>
    <item>
      <title>当响应变量是“一年中的某一天”时，应使用哪种回归模型</title>
      <link>https://stats.stackexchange.com/questions/660197/which-regression-model-to-use-when-response-variable-is-day-of-the-year</link>
      <description><![CDATA[我有一个检测数据集，其中包含一年中被标记动物被重新检测到的天数（即 1 - 365），该天数是在它之前被释放的地点（即 release_location）被重新检测到的。有来自五个不同释放地点的多只被标记的动物，有些动物在被释放后的多年内被重新检测到（即 redetection_year）。示例数据（实际数据集要大得多）：
redetection_year&lt;-c(2,3,2,4,5,3,4,2,5)
redetection_day&lt;-c(25,66,340,129,12,67,200,36,248)
animal_id&lt;-c(1,1,2,3,3,4,4,4,4)
release_location&lt;-c(&quot;A&quot;,&quot;A&quot;,&quot;A&quot;,&quot;B&quot;,&quot;B&quot;,&quot;A&quot;,&quot;A&quot;,&quot;A&quot;)
df&lt;-data.frame(animal_id, release_location, redetection_day, redetection_year)

我想要在 R 中运行模型，以测试释放位置和重新检测年份（预测变量）是否预测重新检测日期（即 1-365）（响应变量）。这可以通过线性回归来实现吗？还是因为响应变量的格式而需要考虑？即它只从 1 到 365，它是循环的。
我读过一些关于 Tobit 回归的文章，这些回归适用于响应变量被审查的情况，以及许多关于当它是预测变量时如何使用“天”变量的示例，但我找不到适合我的问题的解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/660197/which-regression-model-to-use-when-response-variable-is-day-of-the-year</guid>
      <pubDate>Sat, 18 Jan 2025 08:51:33 GMT</pubDate>
    </item>
    <item>
      <title>计算有条件计分的积分制游戏中的概率和预期回合数</title>
      <link>https://stats.stackexchange.com/questions/660191/calculating-probability-and-expected-rounds-in-a-point-based-game-with-condition</link>
      <description><![CDATA[Ann 和 Ben 正在玩一个由多轮组成的游戏。第一个达到 $10$ 分的人将赢得游戏。每轮只有一名获胜者。假设各轮是独立的，Ann 赢得每轮的概率为 $0.6$。
a) 如果每轮获胜者获得 $2$ 分，则计算 Ann 赢得比赛的概率。
b) 与 (a) 相同，但如果获胜者还赢得了上一轮，则他们将获得额外的 $1$ 分。
c) 计算在场景 (a) 和 (b) 中 Ann 获胜所需的预期轮数。
以下是我对 (a) 部分的解决方案：
Ann 的第一个获胜配置是 AAAAA，表示 Ann 连续在所有 $5$ 轮中获胜。显然，这种情况的概率是 $0.6^5$。
Ann 的下一个获胜配置是五个 $6$ 轮 BAAAAA、ABAAAA、AABAAA、AAABAA、AAAABA。它们代表所有 $6$ 个字母的组合，其中只有一个 B，最后一个字母是 A。这五种情况的概率为 $5*0.6^5*0.4$。
Ann 的下一个获胜配置都是 $(6*5)/2 = 3*5 = 15$ 个七个字母的组合，字母 A 和 B，其中 $2$ B 和 $5$ A 的顺序任意，但最后一个字母是 A。这五种情况的概率为 $15*0.6^5*0.4^2$。
系数 $(6*5)/2 = 15$ 是将 $2$ 个字母 B 放置在 $6$ 个可能位置上的数量。
Ann 的下一个获胜配置是所有 $8$ 个字母的单词，字母 A 和 B 分别为 $5$ 个 A 和 $3$ 个 B，其中 A 位于最后一个位置。他们会为这些场景添加概率${7\choose 3}*0.6^5*0.4^3 = 35*0.6^5*0.4^3$。这里 ${7\choose 3} = 35$ 是将 $3$ 个字母 B 放置在 $7$ 个可能位置上的数量。
Ann 的下一个获胜配置是所有 $9$ 个字母的单词，字母 A 和 B 分别为 $5$ 个 A 和 $4$ 个 B，其中 A 位于最后一个位置。他们会为这些场景添加概率${8\choose 4}*0.6^5*0.4^4 = 70*0.6^5*0.4^4$。这里 ${8\choose 4} = 70$ 是将 $4$ 个字母 B 放置在 $8$ 个可能位置上的数量。
现在最后一个计算是计算 $5$ 个加数的总和
$P = 0.6^5 + 5*0.6^5*0.4 + 15*0.6^5*0.4^2 + 35*0.6^5*0.4^3 + 70*0.6^5*0.4^4 = 0.6^5*(1 + 5*0.4 + 15*0.4^2 + 35*0.4^3 + 70*0.4^4) = 0.73343232$。
目前，我没有任何解决部分 (b) 和 (c) 的想法，所以我希望有人能支持我找到这些问题的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/660191/calculating-probability-and-expected-rounds-in-a-point-based-game-with-condition</guid>
      <pubDate>Sat, 18 Jan 2025 07:42:24 GMT</pubDate>
    </item>
    <item>
      <title>季节性虚拟变量回归。为什么我们要在这个回归中使用时间趋势？或者说，在什么情况下我们应该使用时间趋势？</title>
      <link>https://stats.stackexchange.com/questions/660180/regression-with-seasonal-dummies-why-do-we-use-time-trend-in-this-regression-o</link>
      <description><![CDATA[我的导师希望我用季节性虚拟变量进行回归分析。
我有 DPPI 指数（土耳其国内生产者价格指数），这是月度数据。
首先，我需要用截距项和 11 个虚拟变量进行回归分析。
其次，我需要用 12 个虚拟变量进行不带截距项的回归分析。
在这两种情况下，我都应该包括时间趋势项吗？在哪种情况下，或者为什么包括时间趋势项？
或者，我应该同时使用和不使用时间趋势项进行这两个回归分析吗？
我的最后一个问题是我需要分析残差。为此，我应该对残差应用哪些测试或图？
请与我分享您的想法。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660180/regression-with-seasonal-dummies-why-do-we-use-time-trend-in-this-regression-o</guid>
      <pubDate>Fri, 17 Jan 2025 18:42:39 GMT</pubDate>
    </item>
    <item>
      <title>伪似然与似然的比较</title>
      <link>https://stats.stackexchange.com/questions/660172/pseudolikelihood-compared-to-likelihood</link>
      <description><![CDATA[假设我们有一个离散多元概率分布，其密度$f_{\theta}(X=(x_1,\ldots,x_n))=\frac{g_{\theta}(X=(x_1,\ldots,x_n))}{Z}$取决于某个参数$\theta$。我特意以这种形式将其写出，以表示 Z 是难以计算的归一化常数（它也可能依赖于$\theta$）。这种分布的伪似然函数（为简单起见，针对单个数据点）是否定义为：
$$
PL_{\theta}(X=(x_1,\ldots,x_n)) = \prod_{i}f_{\theta}(X_i=x_i | X_j=x_j, i \neq j)
$$
如果是这样，则由此得出的公式在我看来有点奇怪，因为：
$$
= \prod_{i}\frac{g_{\theta}(X)}{\sum_{X_i=a}g_{\theta}(X_1=x_1,\ldots,X_i=a,\ldots)}
$$
调用分母 $Z_i(X)$ 可得到：
$$
\log(PL_{\theta}(X=(x_1,\ldots,x_n))) = n \log(g_{\theta}(X)) - \sum_i \log( Z_i(a))
$$
而真实可能性为
$$
\log(L_{\theta}(X=(x_1,\ldots,x_n))) = \log(g_{\theta}(X)) - \log(Z)
$$
我不知道为什么伪对数可能性可以替代对数可能性。我确实知道计算起来比计算似然性要容易得多，但我无法理解为什么这是一个可接受的估计值。原始文章（Besag Statistical Analysis of Non-Lattice Data (1975)）在这方面没有太大帮助，非常简短的维基百科上关于伪似然性的文章也没有。我知道现在人们可能更喜欢蒙特卡洛之类的方法，但我仍然想了解一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/660172/pseudolikelihood-compared-to-likelihood</guid>
      <pubDate>Fri, 17 Jan 2025 16:25:55 GMT</pubDate>
    </item>
    <item>
      <title>针对 2 个以上类别的卡方检验（2x5 列联表）</title>
      <link>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</link>
      <description><![CDATA[我有一个 2x5 的频率表，其中有 2 列分别名为男性和女性，5 行分别名为病理 A、B、C、D 和 E。
我想确定不同病理类别的性别比例是否存在统计学差异。
例如：男性是否比女性更频繁地受到病理 A 的影响（每个类别都是如此）？
我是否可以将其他类别（例如 B + C + D + E）相加以创建新的 2x2 列联表并对其进行卡方检验？
这在统计上正确吗？如果我的 p 值小于 0.05，我可以得出的结论是：男性比女性更频繁地受到病理 A 的影响？
问题是，如果我对所有数据计算一次卡方检验，我只能对情况有一个整体了解。

感谢大家的回复。实际上，我的不同类别如下：
列：男性和女性
行：A = 无病理（健康患者），B = β-地中海贫血，C = α-地中海贫血，D = db-地中海贫血，E = 其他。
患者只能属于五个类别之一，因为他们被诊断出患有相同的测试。因此，它们是互斥的。
最初，我创建了 5 个 2x2 列联表，如我在第一篇文章中所述，并将其视为二元变量（如 Rick 所述，存在或不存在），但我不确定我能从中得出什么结论，以及将一些类别组合在一起以评估特定类别的频率在两性之间是否存在显着差异是否在统计上正确。
我不一定想计算比值比，只是想知道根据卡方检验，我的病理分布在男性还是女性中更常见。
感谢您的所有回复。我期待阅读您的结论。
此致，
Adrien]]></description>
      <guid>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</guid>
      <pubDate>Fri, 17 Jan 2025 12:27:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Mercer 定理总是被引用于核学习而不是 Moore-Aronszajn</title>
      <link>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</link>
      <description><![CDATA[为什么在大多数关于核技巧的解释中，Mercer 定理都用作依据？
我们能否用 Moore-Aronszajn 来证明这一点，该定理不将紧致性假设置于 $X$ 和 $k$ 连续性上？
编辑：
那么，核技巧背后的想法是，我们能够计算某个希尔伯特空间 $H$ 中的内积，而不必将数据嵌入该空间，因为 $k(x,x&#39;) = \langle \phi(x), \phi(x&#39;) \rangle_{H}$，对于某个 $\phi : X \mapsto H$
现在，经常引用 mercer 定理来证明这样的 $\phi$ 存在。然而，通过 Moore-Aronszajn 定理，我们知道对于 p.d. 核 $k$，特征图 $\phi_{H_k}: X \mapsto H_k = \mathbb{R}^X$，其中 $\phi_{H_k}(x) = k(x,\cdot)$ 满足 $k(x,x&#39;) = \langle \phi(x)_{H_k}, \phi_{H_k}(x&#39;) \rangle_{H_k}$。那么，为什么 Mercer 经常被引用呢？此外，有些 p.d. 核不是连续的，因此无法通过 Mercer 定理进行论证。]]></description>
      <guid>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</guid>
      <pubDate>Fri, 17 Jan 2025 11:39:14 GMT</pubDate>
    </item>
    <item>
      <title>加权交叉熵的理论依据</title>
      <link>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</link>
      <description><![CDATA[假设我们正在构建一个二元分类模型，可以将其视为学习函数
$$ p : X \mapsto [0, 1] $$
其中$p(X) := \mathbb{P}(Y=1|X)$，而$\hat{p}$是某种机器学习模型（例如神经网络）。
常用的损失函数是最小化$p$和$\hat{p}$之间的负交叉熵：
$$ l(p, \hat{p}) = -y\log \hat{p}(x) - (1-y)\log(1-\hat{p}(x))$$
这当然相当于模型$Y|X \sim Bernoulli(p(X))$的最大似然估计。
在某些情况下，结果高度不平衡，这使得训练在实践中变得困难。例如，如果数据是垃圾邮件分类，其中只有 1% 的结果是垃圾邮件，那么很容易收敛到一个简单的解决方案/局部最优，它只为每个观察设置$p(X) \approx 0$。理论上，在大样本量和全局最优的情况下，这不是问题 - 但在实践中，这可能是一个大问题。
解决这个问题的一种常见方法是使用“加权交叉熵”损失，其中权重与观察到的频率成比例。例如，
$$w_0 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=0\}}, w_1 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=1\}} $$
损失为
$$ l^{weighted}(p, \hat{p}) = -w_1y\log\hat{p}(x) - w_0(1-y)\log(1-\hat{p}(x)) $$
其中直觉是稀有类别的权重更高，因此模型“更加关注”对这些观察结果。

通过最小化这个加权损失函数找到的最优函数 $\hat{p}^{weighted}$ 是否有任何已知的理论性质，还是纯粹是启发式的？在全局最优值中，最优 $\hat{p}$ 和 $\hat{p}^{weighted}$ 相比如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</guid>
      <pubDate>Fri, 17 Jan 2025 09:25:45 GMT</pubDate>
    </item>
    <item>
      <title>日食是否减少了新冠肺炎死亡人数？</title>
      <link>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</link>
      <description><![CDATA[我在 R 中模拟了一些现实数据，这些数据显示了 Covid-19 死亡人数随时间的变化情况，以及日食（2024 年 4 月 8 日）发生前的天数：

如果有人不太了解，仅从数据来看，可能会认为日食是降低 Covid 死亡人数的原因。此外，有人可以拟合回归模型，该模型甚至可能很好地拟合数据。
我读到过，我们在统计学中拥有所有这些复杂的技术，例如差异差异、回归不连续性、合成控制、工具变量、倾向得分匹配等 - 所有这些方法旨在在某种程度上找出我们是否能够真正得出结论，统计模型的结果忠实地代表了自然（例如因果关系与联想关系）。
但在某种程度上，我们在决定将哪些变量纳入统计模型时是否只是使用常识？]]></description>
      <guid>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</guid>
      <pubDate>Fri, 17 Jan 2025 05:13:01 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归中的虚拟变量与虚拟变量交互作用</title>
      <link>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</link>
      <description><![CDATA[我正在 R 中进行泊松回归，以估计按年龄组和病毒分类的死亡人数，其中相互作用的项是因子：
model &lt;- glm(death_count ~ strain * cohort + age + year,
family = poisson(link = &quot;log&quot;),
offset = log(exposure),
data = df)

我的 df 是面板数据，其中包含每年特定年龄的死亡人数。每年都以特定病毒为特征，每个年龄分配一个群体。我试图找出以病毒 C 为特征的年份中死亡人数减少的统计意义。以下是简化的回归输出：
 估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -15.39575 0.07621 -202.012 &lt; 2e-16 ***
病毒A -1.29389 0.08358 -3.516 0.000437 ***
病毒B 2.80059 0.06230 12.851 &lt; 2e-16 ***
病毒C 4.22142 0.05298 60.800 &lt; 2e-16 ***
群组X -2.99472 0.02494 -39.890 &lt; 2e-16 ***
群组Y -1.76074 0.02747 -27.691 &lt; 2e-16 ***
群组Z -1.31331 0.03499 -8.953 &lt; 2e-16 ***
病毒A：群组X 1.39666 0.07366 5.385 7.24e-08 ***
病毒B：群组X 1.21714 0.05685 3.820 0.000134 ***
病毒C：群组X -3.97906 0.03390 -28.883 &lt; 2e-16 ***
病毒A：队列Y 1.24520 0.10246 2.393 0.016701 * 
病毒B：队列Y 1.05056 0.07980 0.634 0.526360 
病毒C：队列Y -1.43923 0.03422 -12.836 &lt; 2e-16 ***
virusA:cohortZ 0.12472 0.13408 0.930 0.352274 
virusB:cohortZ -0.33748 0.11851 -2.848 0.004404 ** 
virusC:cohortZ -1.13441 0.04187 -3.210 0.001327 ** 

我知道没有交互项的系数是与参考组相比的，但我听说在泊松回归中，交互项并不那么简单。
我有兴趣解释为什么与队列 Y 和 Z 相比，队列 X 感染病毒 C 的死亡率减少幅度最大。我不太明白如何理解交互系数，我也不明白为什么截距为负。如果没有偏移量，截距 = 0.18252，我无法理解这一点，因为我认为添加偏移量会将 DV 变成速率。]]></description>
      <guid>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</guid>
      <pubDate>Fri, 17 Jan 2025 00:16:33 GMT</pubDate>
    </item>
    <item>
      <title>回归分析中总体模型和样本模型之间的形式差异？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</link>
      <description><![CDATA[术语“样本回归模型”在回归分析中究竟指什么？假设我们有一个数据集$\{(\mathbf{x}_i,\mathbf{y}_i)\}$，我们假设一个底层回归模型形式为
$$
\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon},
$$
其中$\boldsymbol{\theta}$是真实总体参数（频率学派观点）和$\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\Sigma)$。我们所说的样本回归模型到底是什么意思？
以下是我正在探索的一些可能性：

拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}})$，从某种意义上说，我们已经选择了一个估计值$\hat{\boldsymbol{\theta}}$;
拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}}) + \hat{\boldsymbol{\epsilon}}$，其中我们有一个估计值$\hat{\boldsymbol{\theta}}$ 而且 $\hat{\boldsymbol{\epsilon}} \sim \mathcal{N}(\mathbf{0},\hat{\Sigma})$;
从字面上看，人口模型 $\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon}$，但现在以样本指数的形式写出：$\mathbf{y}_i = f(\mathbf{x}_i;\boldsymbol{\theta}) + \boldsymbol{\epsilon}_i$ 使得 $\boldsymbol{\epsilon}_i$ 是观测值，而不是随机向量。
关系 $\mathbf{y}_i = f(\mathbf{x}_i;\hat{\boldsymbol{\theta}}) + \mathbf{e}_i$，其中 $\mathbf{e}_i = \mathbf{y}_i - \hat{\mathbf{y}}_i$ 是残差。

如能得到严格澄清，我们将不胜感激。

编辑：这个问题被认为不清楚，因此这里进行澄清。
问题：术语“样本回归模型”是指什么？
动机：术语“样本回归模型”用于回归分析文献中。例如，Montgomery、Peck 和 Vining 所著的《线性回归分析导论》第六版就使用了该术语。使用 Google 的“图书”标签搜索“样本回归模型”（带引号）也会产生大量结果。但是，我很难理解该术语的正式含义，这就是我提出这个问题的原因。从我目前所见，似乎确实存在对该术语的混淆，因为许多人都在使用该术语，但一些知识渊博的人似乎并不熟悉它。因此，我认为在论坛中回答这个问题是有价值的。]]></description>
      <guid>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</guid>
      <pubDate>Thu, 16 Jan 2025 07:27:25 GMT</pubDate>
    </item>
    </channel>
</rss>