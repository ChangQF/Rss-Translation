<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sun, 16 Mar 2025 01:24:46 GMT</lastBuildDate>
    <item>
      <title>两阶段采样设计的样本尺寸，第一阶段包括分层</title>
      <link>https://stats.stackexchange.com/questions/662691/sample-size-for-two-stage-sampling-design-where-the-first-stage-includes-strati</link>
      <description><![CDATA[我正在使用两阶段的采样设计，其中第一阶段包括分层。我的目标是估计人口比例 $ \ hat {p} $ 具有指定的错误和置信度级别。
具体来说，我需要确定：
 在第一阶段的样本大小（即，在每个层中选择的主要采样单元（PSU）的数量）。
在第二阶段（即，在每个PSU中选择的辅助采样单元（SSU）的数量）。
 
考虑到所需的误差和置信度范围，我应该使用哪些方法或公式来计算两个阶段的样本量？？
任何指导或对实际示例的参考都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/662691/sample-size-for-two-stage-sampling-design-where-the-first-stage-includes-strati</guid>
      <pubDate>Sun, 16 Mar 2025 00:50:57 GMT</pubDate>
    </item>
    <item>
      <title>与Newey-West SE的模型内模型具有很高的T统计数据，但并不重要</title>
      <link>https://stats.stackexchange.com/questions/662688/within-model-with-newey-west-se-has-high-t-stats-but-not-significant</link>
      <description><![CDATA[我在r中使用 feols（）在敏感性测试带有Newey-West标准误差。观察次数为5,672，单个面板ID的数量为3,843，其自由度比通常的纵向分析（2年Fe，15 fe，fe and fe and conteraction）。的相互作用）。的相互作用。
我知道这将影响推断期间T分布的形状。但是，我的T-Statats巨大为-4.673702，但p值为0.13。尽管T统计量很高，但我不太了解输出如何毫无意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/662688/within-model-with-newey-west-se-has-high-t-stats-but-not-significant</guid>
      <pubDate>Sat, 15 Mar 2025 23:09:21 GMT</pubDate>
    </item>
    <item>
      <title>采样事件以预测线性回归中的低频事件</title>
      <link>https://stats.stackexchange.com/questions/662687/sampling-events-to-predict-low-frequency-events-in-linear-regression</link>
      <description><![CDATA[我正在研究一个项目，在该项目中，我正在使用两个不同的数据源来预测一个国家人口的变化为百分比。我从这些不同更新中收到数据的频率相对固定但不同。

  事件类型A ：这些事件给我一个国家人口的快照，并且每五天生产一次数据。

  事件类型b ：这些事件为我提供了有关该国境内城市或州的各种统计数据，并且每天生成几次数据。


请注意，事件类型B 比事件类型A 更频繁地发生。我可以使用事件b 数据来预测事件a 数据。
我正在构建几个功能，以输入线性回归模型。这些功能是在所有事件类型上计算的，我计算出的某些功能是与时间相关的（例如，我可以在事件B中提供给我的某些值的移动平均值，以预测两个事件A类型之间提供的人口的变化）。由于两个不同事件的密度不同，我预测提供较低频率的事件的变化，因此我被引入以下问题：

 在对我的线性回归模型中进行采样事件以进行培训数据时，如果我只在“两个事件” a之间进行一次更新类型？如果我允许在“两个事件”之间进行几个事件进行采样。事件，然后我将绘制相当相关的特征以预测人口增长的相同变化（即，我的“变量变量或“人口增长的变化”，“对于抽样间隔的变化”将是相同的。我认为这可能是一个关注点，因为我有效地复制了我的一些观察值）。

 我是否应该只是抽样事件，在上一个和下一个事件A类型之间计算出的国家人口增长发生巨大变化？在很多情况下，人口增长的变化将接近零（即，在事件A 事件中观察到的国家人口没有变化）。我的“ y”中会有很多零条目可变偏见我的线性模型？我只关心预测的价值超过一定的阈值时，我也不在乎预测小变化（尽管我不想预测在大变化期间的小变化或在小变化期间进行大型移动）。&gt; 


谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662687/sampling-events-to-predict-low-frequency-events-in-linear-regression</guid>
      <pubDate>Sat, 15 Mar 2025 20:54:38 GMT</pubDate>
    </item>
    <item>
      <title>在我的CFA模型中该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/662686/what-to-do-in-my-cfa-model</link>
      <description><![CDATA[我有一个具有11个项目的单构建CFA模型（有关使用Google Maps的焦虑）。该CFA的目的是验证构建体。它已经以英语存在，但随后翻译成阿拉伯语并需要重新验证（样本尺寸= 342）。
所有项目均为序数（5pt李克特量表），所有项目均显示出高度非正态性（高偏度）。为此，R-Software自动使用DWLS（这对这种情况很有益）。
CHI-Square的 P值为STD和捕获数据均为0（对于用户模型和与基线模型的比较）。这是第一个坏消息。
cli / tli bot＆gt; 90％这是个好消息。
STD和缩放数据的RMSEA分别为0.085 / 0.124。
SRMR为0.073
以下是负载，导致可接受的AVE。
  如果我删除了带有SQ-loadings＆lt;的项目。 0.5，结果提高了一点：
 1-Chi-square的p值在STD数据中变为0.140，并且缩放为0（这是模型测试用户模型）。为了与基线进行比较，两个p值为0。
 2- CLI/TLI仍然很好（＆gt; 90％）。
 3- rmsea增强到0.037（对于性病数据）和0.083（对于缩放数据）。强大的RMSEA = 0.126。
 4-SRMR为0.03 
 5- ave = 0.7。
您对我有什么建议？我想验证规模。
还有最好的报告（缩放或性病数据）。因为在某些情况下（如您所见），它们相互矛盾。
而且，对于RMSEA，我应该直接使用强大的rmes。但是，正如您所看到的，它太大了。]]></description>
      <guid>https://stats.stackexchange.com/questions/662686/what-to-do-in-my-cfa-model</guid>
      <pubDate>Sat, 15 Mar 2025 20:48:34 GMT</pubDate>
    </item>
    <item>
      <title>澄清包含排除原则中的非空交集数量</title>
      <link>https://stats.stackexchange.com/questions/662685/clarifying-number-of-non-empty-intersections-in-inclusion-exclusion-principle</link>
      <description><![CDATA[我试图更深入地了解包容性排斥原则，尤其是在不同情况下非空交集的数量。虽然我了解包容和排除的基本交替，但我想澄清的是不同级别的非空交集的结构。
似乎有两个主要情况：

 所有n组都有非空交集。 •如果所有n组的交点是非空的，则所有成对的NCHOOSE2，TRIPE NCHOOSE3和最高n的高阶交叉点也必须是非空的。自然而然的是，这是因为非空交叉路口的每个子集仍然是非空的。

 只有一些K＆lt; n交叉点是非空的。 •这种情况似乎更复杂：如果某些大小K相交但不是全部n的子集，我们如何确定较低级别的非空交集的数量？ •是否有一般条件决定每个级别上有多少个交叉点仍然是非空的？ •是否存在组合框架或现有研究，可以量化给定部分交集信息的非空交叉点的数量？


也想知道这一含义：
如果大小k的所有交叉点都是非空的，是否暗示着大小k-1，k-2等的所有交集，也必须是非空的？
例如，如果您设置了ABCD，请定义k = 3。这些是ABC ABD ACD和BCD的交集。其中包括所有可能的成对交叉点AB AC AD BC BD CD，因此，如果ABC，ABD，ACD和BCD都是非空的，那么所有成对的交集也是如此。
我正在寻找一种更严格的方法来分析这一点，而不是直觉。如果有人可以在包容性排斥中考虑这一点时指出相关的组合结果，资源或常见的陷阱，我将非常感谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/662685/clarifying-number-of-non-empty-intersections-in-inclusion-exclusion-principle</guid>
      <pubDate>Sat, 15 Mar 2025 20:37:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么尽管数据增加和高参数调整，为什么我的VIT和RESNET-18模型不超过77％的精度？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/662684/why-do-my-vit-and-resnet-18-models-not-exceed-77-accuracy-despite-data-augmenta</link>
      <description><![CDATA[我正在处理包含7,839张图像的数据集，以进行三类分类任务。我培训了VIT（Vision Transformer）和Resnet-18，但两种模型都达到了73％至77％的精度，尽管尝试了几次尝试。。
这是我已经尝试的技术：
数据增强（旋转，翻转，变焦等）
更改批处理大小
优化学习率
图像归一化
这是否意味着我的数据集太小了这些模型？还是我还可以尝试提高性能？
欢迎任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/662684/why-do-my-vit-and-resnet-18-models-not-exceed-77-accuracy-despite-data-augmenta</guid>
      <pubDate>Sat, 15 Mar 2025 20:20:21 GMT</pubDate>
    </item>
    <item>
      <title>比较两种交叉验证方法用于高参数调整</title>
      <link>https://stats.stackexchange.com/questions/662683/comparing-two-cross-validation-methods-for-hyperparameter-tuning</link>
      <description><![CDATA[对于超参数的交叉验证，我有一个问题，即在运行正规化回归（特别是弹性Net L1，L2惩罚）的背景下通常认为哪种方法更好
假设您有5倍，并且每个折叠的火车/验证拆分为80％/20％。

对于每个折叠的训练集，请选择（L1，L2）处罚的网格，然后拟合回归系数。
对于每个系数测量，验证集中的平方误差
 a vs b在下方

方法A：
对于5倍的每一个，您都会有一个单数（L1，L2）最佳罚款。平均这5个元组获得最佳最佳（L1，L2）
接近b：
对于每个（L1，L2）元组，计算在5倍上设置的平均平方验证误差。最终最佳（L1，L2）是最低的MSE 

这两个中的哪一个会更好地概括？
在我看来，A VS B是您是否信任AVG（折叠的参数）更多vs avg（折叠之间的平方错误）更多？
我可以想到一个看上去差得多的情况，即您适合超参数 $ ax^\ lambda $ 。方法A可能会给您 $ A_1X^2 $ 和 $ a_2x^4 $ 用于两个不同的折叠。 Averaging the exponent here doesn&#39;t make sense since the hyperparameter is nonlinear (ie you would end up fitting $ax^3$), but is this also true in regularized linear regression (specifically the $|\beta|$ l1 term)?
]]></description>
      <guid>https://stats.stackexchange.com/questions/662683/comparing-two-cross-validation-methods-for-hyperparameter-tuning</guid>
      <pubDate>Sat, 15 Mar 2025 20:10:17 GMT</pubDate>
    </item>
    <item>
      <title>观察值和拟合值的协方差</title>
      <link>https://stats.stackexchange.com/questions/662681/covariance-of-observed-and-fitted-values</link>
      <description><![CDATA[我对我在线性回归中响应和拟合值之间看到的几个计算感到困惑。
例如，这是得出偏见变化权衡的标准步骤，以表明
 $$
\ Mathbb {e} [（y- \ \ m athbb {e} [y]）（\ hat y  -  \ mathbb {e} [\ hat y]）| x = x_0] = 0
$$ 
参见例如在这里 href =“ https://web.archive.org/web/20140821063842/http://ttic.uchicago.edu/%7egregory/courregory/courregory/courregory/wis-ml2012/lectures/biasvardecom.pdecom.pdf” class =“ Math -Container”&gt; $ y  -  \ m athbb {e} [y] = \ epsilon $ 是错误项）。
我的理解是，该计算的关键步骤是，如果我们首先在培训数据集上条件 $ \ Mathcal t = \ {（x_1，y_1），\ dots，（x_n，y_n，y_n）\ \} $ ，然后y] $ 对于固定 $ x = x_0 $ ，因此是常数
 $$
\ begin {align} \ tag {1} \ label {eq：1}
\ Mathbb {e} [（y  -  \ \ Mathbb {e} [y]）（\ hat y  -  \ mathbb {e} \ hat [y]）| x = x_0，\ mathcal t]＆amp; =（\ hat y  -  \ mathbb {e} \ hat [y]）\ mathbb {e} [（y- \ \ m马理bb {e} [y] [y]）| X = X_0，\ Mathcal t] \\＆amp; = 0。
\ end {align}
$$  
另一方面，我已经看到了
 $$
\ operatorName {cov}（y_i，\ hat y_i）\ neq 0，
$$ 
参见例如 $ \ operatorName {cov}（y_i，\ hat y_i）= \ operatorname {cov}（y，\ hat y | x = x_i） \ Mathbb {e} [\ hat y]）| x = x_i] $ ，其中现在 $ x_i $ 不是任意的，而是训练集中的一点。
无论如何，方程\ eqref {eq：1}对于任何 $ x = x_0 $ ，特别是对于 $ x = x_i $  a训练集中的点。
如果有人可以解释这两个显然与之相矛盾的结果是兼容的，我将非常感谢。
我有一种感觉，这全都与一个人的条件有关，但是在我看来，这两种情况只有在单个输入点 $ x = x_0 $ 和两个 $ y $  y $ 和 $ \ hat y $ 取决于 $ y $ 通过 $ \ hat y = x \ hat y = x \ hat \ hat \ beta = x（x^tx）]]></description>
      <guid>https://stats.stackexchange.com/questions/662681/covariance-of-observed-and-fitted-values</guid>
      <pubDate>Sat, 15 Mar 2025 19:28:57 GMT</pubDate>
    </item>
    <item>
      <title>小样本重叠如何影响过度拟合：对系数，P值和R²的影响</title>
      <link>https://stats.stackexchange.com/questions/662680/how-small-sample-overlap-affects-overfitting-impact-on-coefficient-p-value-an</link>
      <description><![CDATA[我使用样本量为4,000的数据集训练了一个模型，并在另一个带有结果B和C的样本上测试了该模型。
 A和B之间的相关性为0.7，A和C之间的相关性为0.5。。
排除了测试集中的100个重叠样品后，该预测因子的系数，P值和增量R²大大下降了结果B。但是，对于结果C，仅影响了P值和增量R²，而该系数则受到影响，而该系数可将其置于无链接状态（请参见下表）。
过度拟合会对不同的结果有所不同的原因是什么？这应该如何从统计角度解释？
  &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stats.stackexchange.com/questions/662680/how-small-sample-overlap-affects-overfitting-impact-on-coefficient-p-value-an</guid>
      <pubDate>Sat, 15 Mar 2025 19:21:32 GMT</pubDate>
    </item>
    <item>
      <title>如何将界限ADF结果与KPSS测试拒绝进行调和，以使财务时间序列的每日日志返回的平稳性？</title>
      <link>https://stats.stackexchange.com/questions/662676/how-can-i-reconcile-borderline-adf-results-with-kpss-test-rejection-for-the-stat</link>
      <description><![CDATA[我正在使用每日欧洲税率数据（从2023年11月30日开始），并计算了每日日志返回。我对日志返回的ADF测试产生了–2.755的测试统计量，p值约为0.065，在常规5％的显着性水平（且在10％时显着），该测试量约为0.065。但是，KPSS测试得出的测试统计量约为0.514，p值为0.0386，导致排斥在5％水平的平稳性假设。视觉检查 -  VIA直方图，Q -Q图和ACF图 - 最大的日志返回大致正态分布，没有显着的自相关。我正在尝试调和这些相互矛盾的测试结果：财务时间序列表现出这种边缘性平稳的证据是否常见，以及我应该如何继续确定我的日志返回是否足够固定，以预测蒙特卡洛模拟以预测未来的欧利伯利率？对进一步测试或转型的​​任何见解或建议将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/662676/how-can-i-reconcile-borderline-adf-results-with-kpss-test-rejection-for-the-stat</guid>
      <pubDate>Sat, 15 Mar 2025 17:27:09 GMT</pubDate>
    </item>
    <item>
      <title>在预测范围内施加Diebold-Mariano测试</title>
      <link>https://stats.stackexchange.com/questions/662658/applying-the-diebold-mariano-test-with-a-decreasing-forecast-horizon</link>
      <description><![CDATA[我正在使用Diebold-Mariano测试来比较两个预测的预测精度，但是我的数据集具有独特的特征：预测范围随着时间的推移而下降。随着事件日期的临近，预测和实现之间的时间缩小，这意味着我的预测是用不同的交货时间进行的，而不是固定的 h  step结构。
 DM测试的大多数应用都采用常数预测范围，通常比较一步或多步预测的预测，其中 h 是固定的。但是，就我而言， h 随着 t 的进展而动态变化，这引起了人们对标准DM测试假设是否存在的担忧。
从我的分析中：

损失差异序列是自相关的，但是DM测试使用其长期差异估计器来解释这一点。
损失差异系列中没有漂移或确定性的时间趋势。
没有足够的异性症证据，因此标准差异假设可能存在。

我的问题：

在此设置中，DM测试仍然有效，其中 h 未修复？
是否有人遇到过文献，其中DM测试（或类似的预测精度测试）已在缩小的预测范围内应用？
如果标准DM测试无效，当预测范围随着时间的推移降低时，是否有其他方法可以比较预测准确性？

预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662658/applying-the-diebold-mariano-test-with-a-decreasing-forecast-horizon</guid>
      <pubDate>Sat, 15 Mar 2025 10:57:12 GMT</pubDate>
    </item>
    <item>
      <title>将文本可读性指标与主观测量相关联</title>
      <link>https://stats.stackexchange.com/questions/662642/correlating-text-readability-metrics-against-subjective-measurements</link>
      <description><![CDATA[假设我想找出文本的不同可读性指标与文本复杂性的主观测量相关。我要求18个人阅读12条短文，我衡量他们认为每个文本的量表都有5个项目的范围（因此得分为5.0表示高复杂性）。我想尝试找出哪些度量与主观复杂性最有关系。
一种幼稚的方法是从所有参与者中获取每个文本的平均主观得分，并在应用于文本时发现哪种复杂性度量与结果的相关性最强。但是，我认为这将丢失很多信息（例如，如果两个参与者将他们的某些分数换成一些文本片段，那将不会影响结果，但感觉应该是这样）。多级模型会在这里适当吗？
评论：这个问题类似于
示例：
一个指标可能将第一个文本的复杂性评为4，第二个文本为6等，而另一个指标将在其自身的尺度上对与10和12相同的文本进行评分。同时，一个参与者关于前两个文本的复杂性的主观得分分别为3和4（满分5）。来自不同量表的数字不是直接可比的。我们只想找出他们与参与者的主观分数有多相关。]]></description>
      <guid>https://stats.stackexchange.com/questions/662642/correlating-text-readability-metrics-against-subjective-measurements</guid>
      <pubDate>Fri, 14 Mar 2025 21:32:21 GMT</pubDate>
    </item>
    <item>
      <title>低坡/歧视问题：IRT的有用性？</title>
      <link>https://stats.stackexchange.com/questions/662618/low-slope-discrimination-questions-usefulness-in-irt</link>
      <description><![CDATA[在项目响应理论中，2-PL模型同时捕获了斜率和截距，而Rasch模型仅捕获截距，将曲线左/右移动（下面捕获）。。
   IRT的一般背景是推断问题难度和学生能力。尽管X轴范围为（-inf，inf），但可以将其转换为范围（0,1）。换句话说， $ x = 0 $ 捕获中位学生能力（或物品难度，因为它们在同一潜在空间中映射。）
通常，给定曲线的歧视力在其拐点处是最大的。关于上面的红色曲线，拐点位于 $ x = 0 $ ，这意味着，如果一个学生真正处于中间位置，则该问题将提供最大的信息，并随着给定的学生的能力增加或降低信息，从而提供了最大的信息。     。
上下文，我的问题很简单：陡峭的斜坡在实践中总是更喜欢？
假设地，如果给定的问题可以通过零差异返回学生的能力（知道学生在拐点以上或以下），则可以使用二进制搜索来找到学生在 $ o（\ log log（\ log log（n））$（\ log（n））$  $ time。
当然，这些问题不是确定性的，因此我们绝对可以确定学生没有超出他们的能力问题。但是，我认为，随着这些曲线的斜率接近无穷大（ $ \ lim：b \ to \ infty）$ 。
考虑到这一假设，较小的歧视性问题（较低的斜率）有用吗？在什么情况下？
我问了一个类似的问题在这里]]></description>
      <guid>https://stats.stackexchange.com/questions/662618/low-slope-discrimination-questions-usefulness-in-irt</guid>
      <pubDate>Fri, 14 Mar 2025 16:10:25 GMT</pubDate>
    </item>
    <item>
      <title>r中的Invlogit（）以及我们是否需要使用截距和斜率或仅使用斜率来估计概率</title>
      <link>https://stats.stackexchange.com/questions/662598/invlogit-in-r-and-whether-we-need-to-use-the-intercept-and-the-slope-or-just-t</link>
      <description><![CDATA[我有兴趣估计二进制结果（y）作为X的函数的概率。使用 glm（）在r中运行逻辑回归，  family = family = biinasial ，我获得了截距和斜率。我的问题：当试图估算y的总体概率作为x的函数时，我可以使用 amm :: invlogit（），但是我是否应该将截距和斜率用作 Invlogit（Intercept+Slope+Slope）或仅仅是  Invlogit（x ivplogit）
是要回答以下问题：由于X？
我使用了一个数据集，该数据集预测冠状动脉疾病是年龄的函数，当应用 Invlogit（Slope）时，我能够获得比 Invlogit（Intercept+Slope+Slope）更现实的概率，与0.22％相比，概率约为50％？后者是不现实的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662598/invlogit-in-r-and-whether-we-need-to-use-the-intercept-and-the-slope-or-just-t</guid>
      <pubDate>Fri, 14 Mar 2025 06:48:54 GMT</pubDate>
    </item>
    <item>
      <title>与自相关和部分自动相关的时间序列</title>
      <link>https://stats.stackexchange.com/questions/662587/time-series-with-autocorelation-and-partial-autocorelation</link>
      <description><![CDATA[我正在使用时间序列数据，其中每天由包含24×25网格的CSV文件表示，每个条目都充当像素。
我已经生成了ACF和PACF来了解我的数据的时间结构，并且整天都使用了第一个功能：
 导入statsmodels.api as s sm
导入matplotlib.pyplot作为PLT

系列= data_flatted [：，0]＃整天使用第一个功能
图，轴= plt.subplot（2，1，无花果=（10，8））
sm.graphics.tsa.plot_acf（系列，滞后= 50，ax = axes [0]）
sm.graphics.tsa.plot_pacf（系列，滞后= 50，ax = axes [1]）
plt.show（）
 
我的输出：
对于 lags = 50  
  对于 lags = 100  
  对于 lags = 150  
  对于 lags = 250  
  对于 lags = 500  
  对于 lags = 900  
  从上面的图像中，我会说短/长滞后时的强大ACF相关性表明时间依赖性很大？
或
我的意思是问我的数据集有任何重复模式或趋势？
或
所有数据点都可能遵循一些简单的确定性线性结构方程，并具有一些小的白噪声？
或我的数据集中存在强大的时间依赖性？]]></description>
      <guid>https://stats.stackexchange.com/questions/662587/time-series-with-autocorelation-and-partial-autocorelation</guid>
      <pubDate>Fri, 14 Mar 2025 00:47:24 GMT</pubDate>
    </item>
    </channel>
</rss>