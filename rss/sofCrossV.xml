<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 25 Jan 2024 15:15:19 GMT</lastBuildDate>
    <item>
      <title>将每日抽样证据汇总为每月估计值</title>
      <link>https://stats.stackexchange.com/questions/637745/aggregating-daily-sampling-evidence-into-a-monthly-estimate</link>
      <description><![CDATA[假设有一个业务流程每天都会进行抽样以进行质量审核，即每天批量生成一批项目，并每天随机抽样以识别生产错误。由于抽样容量的限制，抽样率相当小，例如 50 个项目中的大约 2 个。这意味着无法每天进行重要的统计估计，因为它在任何实际置信水平下都会产生可怕的误差范围。
一个简单的替代方案是重新组织采样过程，在较长的时间段（例如 100 天）内随机采样。假设每天生产的产品数量相当恒定，那么每天对 50 件产品中的 2 件进行抽样的资源需求与在 100 天的窗口内对 5000 件产品中的 200 件进行抽样的资源需求相同。这突然产生了更强大的统计数据，而无需修改统计假设。缺点是5000件产品生产完毕后需要等待100天，然后才开始抽样和质量审查工作。这在生产错误的存在与组织确认错误并做出相应反应的能力之间引入了很长的准备时间。
是否有任何方法可以将每日抽样证据汇总/复合为较长时间范围内（即每周/每月/每季度/每年）的估计值？我的直觉表明，仅仅将每日样本视为独立的并将结果汇​​总在一起就需要假设生产误差的分布与时间无关——这一点很难成立，而且可能也很难测试。
这听起来像是一个必须已经研究过的常见问题 - 至少我知道 ISO 2859-1 等标准的存在可以解决类似的挑战。我不清楚他们如何解决误差分布的时间依赖性问题，以及如何使用它们来导出标准抽样统计数据，例如误差幅度和置信区间。
您对这个问题有何看法？]]></description>
      <guid>https://stats.stackexchange.com/questions/637745/aggregating-daily-sampling-evidence-into-a-monthly-estimate</guid>
      <pubDate>Thu, 25 Jan 2024 14:47:13 GMT</pubDate>
    </item>
    <item>
      <title>高维概率定理 5.1.4</title>
      <link>https://stats.stackexchange.com/questions/637743/theorem-5-1-4-from-high-dimensional-probability</link>
      <description><![CDATA[让M
是 f(X) 的中值
，其中 f 是利普希茨。如何证明如果 ∥f(X)−M∥ψ2≤C
，则∥f(X)−Ef(X)∥ψ2≤C
？
我的直觉是，中位数最小化了 L-1 范数，而 L-1 范数受亚高斯范数限制，所以我很难理解为什么结果成立。我也尝试过使用 Jensen 不等式，但没有结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/637743/theorem-5-1-4-from-high-dimensional-probability</guid>
      <pubDate>Thu, 25 Jan 2024 14:27:55 GMT</pubDate>
    </item>
    <item>
      <title>执行似然比检验来比较两个嵌套 LASSO 模型是否具有统计意义？</title>
      <link>https://stats.stackexchange.com/questions/637742/does-performing-likelihood-ratio-test-to-compare-two-nested-lasso-models-make-st</link>
      <description><![CDATA[根据我的研究，LRT 用于比较两个嵌套模型，即两个具有不同嵌套特征集的模型，在我的例子中，例如

模型 1：binary_outcome ~ X1 + X2
模型2：binary_outcome ~ X1 + X2 + X3 + X4

我可以在网上找到的所有示例都使用简单的线性/逻辑回归。
我想使用 LASSO 来防止过度拟合，因为我有很多特征。然而，我也有很高的共线性，因为许多特征都是相关的。我还读到 LASSO 不稳定，具有高度相关的特征......
所以我的问题是：对两个嵌套 LASSO 模型进行 LRT 测试是否具有统计意义？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/637742/does-performing-likelihood-ratio-test-to-compare-two-nested-lasso-models-make-st</guid>
      <pubDate>Thu, 25 Jan 2024 14:09:05 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型仿真研究中的问题</title>
      <link>https://stats.stackexchange.com/questions/637741/problems-in-a-simulation-study-for-a-linear-mixed-model</link>
      <description><![CDATA[下面的代码对应于涉及线性混合模型的模拟研究。我正在考虑涉及 As、B 和 C 组合的不同场景。为了更好地说明，变量 A 和 B 是嵌套的，即变量 A 包含变量 B（例如，在第一种情况下，变量 A 包含变量 B 的 2 个级别，然后变量 B 将包含变量 C 中的 10 个观测值） - 这将是 27 种可能情况中的第一种情况 (10, 2, 10)。
称为（b0、b1、sdB、sdA 和 sd）的参数来自纳入模拟的相同线性混合模型，但考虑到它已根据我的真实数据集进行调整（lmer(log(y1) ~ x1 + (1 | B)))。请注意，该模型已考虑 log(y1) 进行调整，因此从该模型中获取的用于模拟研究的参数将已经考虑到这种影响，例如在代码的此阶段生成响应变量：resp = b0 + b1 * x1 +standeff，即在代码的第二阶段，不需要应用 log(y1)。
事情是这样的。在代码的第二步中，我还应用了半正态图来评估每个场景的每个重复中每个模型的拟合质量。应用半正态图后，我提取了模拟包络线之外的点数，稍后我打算执行一些指标。
但是，我怀疑阶段 II 中响应变量 (resp) 的生成和模型的拟合存在问题，因为 hnp 中的点都位于图的底部，而不是在图的底部。 band（我怀疑是变量的规格、规模等问题）。
可能出了什么问题？
库(hnp)
图书馆(lme4)

As = c(10, 15, 30)
Bs = c(2, 4, 6)
铯 = c(10, 20, 30)
代表=2

b0 = 2.29
b1 = 0.04
分贝=0.03
标准差=0.02
标准差=0.01
＃ -  -  -  -  -  -  阶段I  -  -  -  -  -  -  -  -  -  - ＃
生成数据 &lt;- 函数（A，B，C）{
  Bseff = rnorm(A * B, 0, sd)
  Aeff = 代表(rnorm(A, 0, sdA), 每个 = B)
  
  Bs = 代表（粘贴（“B”，1：（A * B）），每个= C）
  Bseff = 代表（Bseff，每个 = C）
  A_names = 代表（粘贴（“A”，1：A），每个= B * C）
  Aeff = 代表（Aeff，每个 = C）
  
  x1 = runif(A * B * C, 4, 28)
  分别 = b0 + b1 * x1 + Bseff
  
  return(data.frame(Bs, Bseff, A = A_names, x1, resp))
}

#------------ 第二阶段--------------------#

all_data &lt;- 列表()

all_scenarios_results &lt;- list()

for (A in As) {
  对于（B 中的 B）{
    对于（C in Cs）{
      场景结果 &lt;- list()
      
      for (i in 1:rep) {
        dat &lt;-generate_data(A, B, C)
        dat$Bs &lt;- as.factor(dat$Bs)
        all_data[[粘贴(A, B, C, “Rep”, i, sep = “_”)]] &lt;- dat
        
        模型 &lt;- lmer(resp ~ x1 + (1 | Bs), data = dat)
        
        contenv = hnp::hnp(模型, how.many.out = TRUE)
        
        scene_results[[paste(&quot;Rep&quot;, i, sep = &quot;&quot;)]] &lt;- list(
          lmer_model = 模型，
          模型数据=数据，
          hmo_total = contenv$out,
      hmo_p = 内容$out/内容$总计*100
        ）
        
        print(paste(&quot;场景&quot;, 粘贴(A, B, C, sep = &quot;, &quot;), &quot;: 代表&quot;, i))
      }
      
      all_scenarios_results[[粘贴(A, B, C, sep = &quot;_&quot;)]] &lt;- scene_results
    }
  }
}

]]></description>
      <guid>https://stats.stackexchange.com/questions/637741/problems-in-a-simulation-study-for-a-linear-mixed-model</guid>
      <pubDate>Thu, 25 Jan 2024 13:46:46 GMT</pubDate>
    </item>
    <item>
      <title>帕累托分布的数值求积[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637740/numerical-quadrature-for-pareto-distribution</link>
      <description><![CDATA[当在任何给定点评估 $f(x)$ 时，我想对以下类型的积分进行数值计算：
$$
\int_{x_m}^\infty x^{-\alpha}f(x) \, dx, \quad \alpha &gt; 1, x_m &gt; 0。
$$
我的问题是，最好的方法是什么。或者，是否有一些标准方法可以解决此类问题。
我想到的两个可能的选择是使用（i）高斯-勒让德求积并更改变量来更改 $[x_m, \infty]$ 的积分限制 到 $[-1,1]$ 或 (ii) 高斯-拉盖尔求积分 $g( x) = x^{-\alpha}e^x f(x)$。
但是，我对这些求积方案在变量变化后的稳定性（和其他）属性一无所知，因此我想知道是否有一些针对此类积分的标准方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/637740/numerical-quadrature-for-pareto-distribution</guid>
      <pubDate>Thu, 25 Jan 2024 13:33:01 GMT</pubDate>
    </item>
    <item>
      <title>使用累积自相关数据构建模型的最佳方法</title>
      <link>https://stats.stackexchange.com/questions/637739/best-method-for-building-models-using-cumulative-autocorrelated-data</link>
      <description><![CDATA[上下文：
举个例子，假设我正在尝试使用车辆的用途来查找维护原因。最终目的是了解两者之间的关系。
如果我只有诸如高速公路使用时间和特定日期的维护时间之类的变量。您无法知道高速公路的具体使用时间导致了维护时间。因此，我会累计每天的高速公路行驶时间。如果我每天开车 10 小时，则会显示为（10,20,30 等）。这将确保一旦发生维护事件，每小时都会被考虑在内。维护时间同样会随着时间的推移而累积。
我可以对此运行 GLM 并获得合理的系数和显着的结果。但这一切都违反了要求预测变量独立的回归基本原理。然而，我不知道在这种情况下有什么替代方法？每增加一个新的高速公路使用小时或维护时间，其影响就会更小。 Beta 值在这个模型中是否无关紧要？驾驶时间的贝塔值为 0.01，即 100 个驾驶小时和 1 个维护小时，这会是错误的吗？是否会在模型中添加时间来控制累积？这里最好的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/637739/best-method-for-building-models-using-cumulative-autocorrelated-data</guid>
      <pubDate>Thu, 25 Jan 2024 13:22:37 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试为学校作业做 MLE，为什么我会收到此错误：[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637733/i-am-trying-to-do-mle-for-school-assignment-why-could-i-be-getting-this-error</link>
      <description><![CDATA[ #1) 找到最佳拟合分布参数
最佳拟合（macamil2data）
# {&#39;loglaplace&#39;: {&#39;c&#39;: 1.0603278885766216,
#&#39;位置&#39;：-0.04671203840594998，
#&#39;规模&#39;：10.230045114772532}}

#2) 使用所述参数计算 pdf
def loglaplace_loglikelihood（参数，数据）：
    c，loc，比例=参数
    返回 stats.loglaplace.logpdf(data, c=c, loc=loc, scale=scale).sum()

#3) 最小化使用所述参数
初始参数 = [1.0603278885766216, -0.04671203840594998, 10.230045114772532]
结果=最小化（loglaplace_loglikelihood，initial_params，args =（macamil2data））

打印（结果）

 消息：由于精度损失，不一定能实现所需的误差。
  成功：假
   状态：2
      乐趣：楠
        x: [ 5.127e+03 -1.765e+05 -1.945e+03]
      尼特：2
      江淮：【楠楠楠】
 hess_inv：[[ 6.876e-01 -1.388e+01 5.195e-02]
            [-1.388e+01 5.437e+02 5.473e+00]
            [ 5.195e-02 5.473e+00 1.000e+00]]
     NFEV：464
     新值：116


macamil2数据=
0.916666
1
3.3
3.38333
3.68333
4.16667
4.2
6.08333
6.61667
7.03333
7.5
7.85
8.15
9.08333
9.35
10.0833
10.1833
10.4333
11.2833
14.2
16.5333
20.0333
23.8333
30.35
30.5167
32.4667
37.1
40.8167
45.6
52
70.0667
70.5333
85.2333
130.967
]]></description>
      <guid>https://stats.stackexchange.com/questions/637733/i-am-trying-to-do-mle-for-school-assignment-why-could-i-be-getting-this-error</guid>
      <pubDate>Thu, 25 Jan 2024 11:17:30 GMT</pubDate>
    </item>
    <item>
      <title>计算无偏归一化自相关函数时是否更改平均值/标准差？</title>
      <link>https://stats.stackexchange.com/questions/637732/do-you-change-the-mean-standard-deviation-when-calculating-the-unbiased-normal</link>
      <description><![CDATA[我正在尝试计算无偏归一化自相关函数。我认为这个领域有点复杂，因为不同的来源似乎使用不同的术语来描述相同的事物，并且使用相同的术语来描述不同的事物，所以我会尽力具体说明我的意思。
我想对离散时间序列 $x[n]=(x_1,x_2,x_3...x_N)$ 作为函数执行自相关时间滞后 $\tau$，其中 $\tau$ 是一个整数。我会使用的自相关函数是
$$\mathrm{AC}[\tau]=\frac{1}{N-\tau}\sum_{n=1}^{N} \frac{(x[ n]-\bar{x})*(x[n+\tau]-\bar{x})}{\sigma_x^2}$$
其中 $\bar{x}=\frac{1}{N}\sum_{n=1}^N x[n]$ 和 $\sigma_x=\sqrt{\frac{1}{N}\sum_{n=1}^N(x[n]-\bar{x})^2}$ 是分别为平均值和标准差$^\mathrm{*}$。
对于 $\tau=0$ 来说，没有时间滞后，信号与其自身完美重叠，并且值归一化为 1。对于滞后 &lt; span class=&quot;math-container&quot;&gt;$\tau=1$，现在信号每一侧都有一个不再重叠的元素，对于 $\tau =2$现在有两个不重叠的元素，等等
我应该使用相同的值 $\bar{x}$ 和 $\sigma_x$ 对于所有 $\tau$，或者我应该重新计算 $\bar{x}$ 和 $\sigma_x$ 仅包含重叠的元素？因此，在下图中，当 $\tau=2$ 时，我是否应该仅使用元素 3-11 和 1-9 重新计算平均值和标准差？&lt; /p&gt;
$\tau$ = 0、1 和 2。
我的直觉是不，并对所有 $\tau$ 使用元素 1-11，但是当我这样做时，我不再具有绑定的自相关函数-1 到 1 之间，请参阅下面我的具体示例。
$\tau$ 使用相同的均值和标准差，且不受 1 和 -1 的限制。这里注意，x 轴中的 $\tau$ 不是元素数量，而是时间。由于采样频率为4MHz，4个元件的位移为1$\mu$s。 $N$=4096 在此示例中。
*我知道，如果我使用时间序列的样本而不是整个时间序列，我应该在计算中除以 $N-1$标准差，但在我的工作中 N&gt;&gt;1，所以为了简单起见，我将其省略）。]]></description>
      <guid>https://stats.stackexchange.com/questions/637732/do-you-change-the-mean-standard-deviation-when-calculating-the-unbiased-normal</guid>
      <pubDate>Thu, 25 Jan 2024 11:04:31 GMT</pubDate>
    </item>
    <item>
      <title>什么测试可以比较干预前后的结果？</title>
      <link>https://stats.stackexchange.com/questions/637731/what-test-for-comparing-results-before-and-after-an-intervention</link>
      <description><![CDATA[我正在写一篇论文，其中我们向医生展示了一组患者的一些实验室结果，并要求他盲目地对诊断说“是”或“否”。然后，我告诉他患者的病史和其他重要信息，请他看相同的实验室结果，并请他再次进行诊断。有了这些信息，我可以构建两个 2x2 列联表，其中包含真阳性和阴性以及假阳性和阴性，以获得每个列联表的敏感性和特异性结果。
我想看看这些变化是否具有统计显着性。我应该使用什么测试来计算它？我知道分布不是正态的，所以我想应该使用非参数检验。我看了一点，认为麦克尼马斯的测试是合适的，但我不知道如何根据两个列联表来计算它。有什么帮助吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/637731/what-test-for-comparing-results-before-and-after-an-intervention</guid>
      <pubDate>Thu, 25 Jan 2024 10:55:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Welch 的 t 检验结果与 Welch 的 ANOVA 事后检验不同？</title>
      <link>https://stats.stackexchange.com/questions/637730/why-do-welchs-t-test-results-differ-from-welchs-anova-post-hoc-tests</link>
      <description><![CDATA[我有 Python 中三种不同浆果类型之间海拔的数据（Raspberry、Sunberry、Cranberry），以下是数据：&lt; /p&gt;
 高程作物站点
0 6.38606 R 1
1 3.86458 R 2
2 3.52326 S 3
3 4.74866 R 4
4 4.84225 S 5
………………
163 5.01838 R 8
164 4.91557 S 9
165 5.05761 R 10
166 3.83972 R 11
167 3.83046 R 12

以及有关群组的一些一般统计数据：
&lt;前&gt;&lt;代码&gt;意思是：
参考值：1.938
小号：4.419
C：3.892

标准差：
参考值：2.542
小号：2.046
C：1.987

观测点数量
R：n = 11
小号：n = 6
C：n = 5

我假设它们生长的平均海拔是不同的，我想对此进行测试。我知道方差和组大小不同，因此我选择手动对每个组比较进行 Welch t 检验。然而，当我使用韦尔奇的方差分析测试来比较所有三组时，我得到了不同的结果。这是代码：
导入 pandas 作为 pd
导入 scipy.stats 作为统计数据
将 pingouin 导入为 pg

df = pd.read_csv(&#39;路径/to/data.csv&#39;)

print(stats.ttest_ind(df[df[&#39;Crop&#39;] == &#39;R&#39;].Elevation.dropna(), df[df[&#39;Crop&#39;] == &#39;S&#39;].Elevation.dropna(), equal_var =错误的））
print(stats.ttest_ind(df[df[&#39;Crop&#39;] == &#39;R&#39;].Elevation.dropna(), df[df[&#39;Crop&#39;] == &#39;C&#39;].Elevation.dropna(), equal_var =错误的））
print(stats.ttest_ind(df[df[&#39;Crop&#39;] == &#39;S&#39;].Elevation.dropna(), df[df[&#39;Crop&#39;] == &#39;C&#39;].Elevation.dropna(), equal_var =错误的））

# 执行 Welch 方差分析
welch_result = pg.welch_anova(data = df, dv = &#39;高程&#39;, Between = &#39;作物&#39;)

# 显示 Welch 方差分析结果
print(&quot;韦尔奇方差分析结果：&quot;)
打印（welch_结果）

# 使用 Games-Howell 测试进行成对比较
tukey_results = stats.pairwise_tukey(data = df, dv = &#39;海拔&#39;, Between = &#39;作物&#39;)

# 显示成对比较
print(&quot;\n成对比较（Tukey 测试）：&quot;)
打印（tukey_结果）

测试结果不同：
韦尔奇的 t 检验
Ttest_indResult（统计量= -2.084，p值= 0.06）
Ttest_indResult（统计量= -1.591，p值= 0.14）
Ttest_indResult（统计量= 0.4319，p值= 0.68）

韦尔奇方差分析 w.图基-克莱默
成对比较（Tukey 测试）：
   A B 均值(A) 均值(B) diff se T p-tukey 对冲
0 C R 3.89297 1.93853 1.95444 0.127238 1.536054 0.299653 0.771389
1 C S 3.89297 4.41998 0.52701 0.138132 -0.381527 0.923255 -0.238423
2 R S 1.93853 4.41998 2.48145 0.120228 -2.063948 0.127460 -0.987895

韦尔奇方差分析 w.游戏豪厄尔
   A B 均值(A) 均值(B) ... T df pval 对冲
0 C R 3.89297 1.93853 ... 1.591293 10.313845 0.292242 0.771389
1 C S 3.89297 4.41998 ... -0.431931 8.735549 0.903374 -0.238423
2 R S 1.93853 4.41998 ... -2.084965 12.385126 0.133544 -0.987895

为什么会发生这种情况？
值得相信哪一个：来自 Welch 的方差分析，而不是一遍又一遍地使用 Welch 的 T 检验进行手动成对比较？
干杯]]></description>
      <guid>https://stats.stackexchange.com/questions/637730/why-do-welchs-t-test-results-differ-from-welchs-anova-post-hoc-tests</guid>
      <pubDate>Thu, 25 Jan 2024 10:42:20 GMT</pubDate>
    </item>
    <item>
      <title>Z 测试没有相关样本量，因为我有高斯概率分布</title>
      <link>https://stats.stackexchange.com/questions/637728/z-test-with-no-relevant-sample-size-as-i-have-a-gaussian-probability-distributio</link>
      <description><![CDATA[我有两条高斯曲线，没有样本，这些本质上只是概率分布。所以我可以对它们进行高斯拟合，或者对数据进行加权平均值和加权方差，并且我得到了均值和方差值。
我想计算某种度量来描述两条高斯曲线的差异。当然，首先想到的是 z 检验，因为它同时考虑了两条曲线之间均值的变化和方差，并吐出一个 z 值来描述它。这正是我想要的（因为最终我想比较我在不同条件下计算的 2 条高斯曲线的 z 值）。问题是 z 检验方程中有样本数，这与我的情况无关。有没有办法做到这一点，或者我可以使用其他指标吗？
谢谢
编辑：
曲线示例。我的目标是拥有一个描述两条曲线之间差异的指标，以便我可以改变输入变量以最大化输出分布之间的差异。
]]></description>
      <guid>https://stats.stackexchange.com/questions/637728/z-test-with-no-relevant-sample-size-as-i-have-a-gaussian-probability-distributio</guid>
      <pubDate>Thu, 25 Jan 2024 10:33:48 GMT</pubDate>
    </item>
    <item>
      <title>SPSS 中 PROCESS 4.2 中的简单中介分析。结果变量是二元的，中介变量是连续的，IV 是二元的</title>
      <link>https://stats.stackexchange.com/questions/637715/simple-mediation-analysis-in-process-4-2-in-spss-the-outcome-variable-is-binary</link>
      <description><![CDATA[在第一个模型中，IV (X) 显着预测中介变量 (M)。
在第二模型中，中介显着预测了结果变量 (Y)，但 IV (X) 未预测结果变量 (Y)。
在第三模型中，X 对 Y 的直接影响不显着。 X对Y的间接影响显着。
我记得几年前进行中介分析时，IV（系数）的数量在添加中介后会减少。这表明中介调节了 IV 和结果之间的关系。然而，这里第二模型中的IV(X)的系数数与第三模型中的相同。此外，IV 和结果变量的关系一开始就应该很重要。在我的调解中，这始终是不重要的。我记得过去写道“当将中介输入模型时，DV 的显着 IV 效应变得不显着”。在这里，我不能这样说，因为 PROCESS 根本没有显示 IV 和 DV 之间的显着关系。因此，我什至不知道如何解释结果。我应该回到进行中介分析的旧方法吗？简单明了。]]></description>
      <guid>https://stats.stackexchange.com/questions/637715/simple-mediation-analysis-in-process-4-2-in-spss-the-outcome-variable-is-binary</guid>
      <pubDate>Thu, 25 Jan 2024 02:58:46 GMT</pubDate>
    </item>
    <item>
      <title>随机安慰剂对照试验的样本量计算示例</title>
      <link>https://stats.stackexchange.com/questions/637697/example-of-sample-size-calculation-for-a-randomized-placebo-controlled-trial</link>
      <description><![CDATA[我正在尝试在以下文章中重现样本大小的计算：


n = 每组所需的样本量
p1 = 阿奇霉素组的死亡比例
p2 = 安慰剂组的死亡比例
p1-p2 = 临床显着差异 = 0.15（或 15%）

如何根据提供的信息确定p1和p2？]]></description>
      <guid>https://stats.stackexchange.com/questions/637697/example-of-sample-size-calculation-for-a-randomized-placebo-controlled-trial</guid>
      <pubDate>Wed, 24 Jan 2024 23:07:10 GMT</pubDate>
    </item>
    <item>
      <title>泊松最优三参数变量稳定变换</title>
      <link>https://stats.stackexchange.com/questions/637569/optimal-three-parameter-variable-stabilizing-transformation-of-a-poisson</link>
      <description><![CDATA[论文中：“关于方差稳定变换的经典选择及其应用泊松变量”，Shaul K. Bar-Lev 和 Peter Enis 给出了泊松随机变量的最优二参数方差稳定变换，其中最优性（大致）意味着它确保方差尽可能接近常数大平均极限。
转换为：
$$f_{\alpha,\beta}(x)= 2(x+2\alpha-\beta){(x+\alpha)}^{-\frac{1} {2}}$$
他们给出最佳的 $\alpha$ 和 $\beta$ 作为 $\alpha^*=\frac{3}{8}+\frac{\sqrt{3}}{6}$ 和 $\beta^ *=\frac{3}{8}+\frac{\sqrt{3}}{4}$，因此最终的变换由下式给出：
$$f_{\alpha^*,\beta^*}(x)=\frac{24x+9+2\sqrt{3}}{\sqrt{144x+54+ 24\sqrt{3}}}.$$
它们表明，如果 $X$ 是一个具有平均值 $\lambda$ 的泊松随机变量，然后对于一般的 $\alpha$ 和 $\beta$：
$$\operatorname{var}{f_{\alpha,\beta}(X)}=1+O(\lambda^{-1})$$
为 $\lambda\rightarrow\infty$。然而：
$$\operatorname{var}{f_{\alpha^*,\beta^*}(X)}=1+O(\lambda^{-3})$$&lt; /跨度&gt;
为 $\lambda\rightarrow\infty$。 （这就是精确意义上的最优性。两个最优选择的参数去除了方差的两个前导项。）
他们还提出了一个三参数变换系列，由下式给出：
$$g_{\alpha,\beta,\gamma}(x)= 2(x+2\alpha-\beta){(x+\alpha)}^{-\frac {1}{2}} - {(x+\gamma)}^{-\frac{3}{2}},$$
但他们没有给出最佳的 $\alpha$、$\beta$ 和 $\gamma$ 对于这个三参数族。
最佳的 $\alpha$、$\beta$ 和 $\gamma$?即，什么是 $\alpha^\circ$、$\beta^\circ$ 和 &lt; span class=&quot;math-container&quot;&gt;$\gamma^\circ$ 这样：
$$\operatorname{var}{g_{\alpha^\circ,\beta^\circ,\gamma^\circ}(X)}=1+O( \lambda^{-4})$$
为 $\lambda\rightarrow\infty$。]]></description>
      <guid>https://stats.stackexchange.com/questions/637569/optimal-three-parameter-variable-stabilizing-transformation-of-a-poisson</guid>
      <pubDate>Tue, 23 Jan 2024 16:32:51 GMT</pubDate>
    </item>
    <item>
      <title>卡林-鲁宾定理：具有 MLR 属性的检验统计量与充分性检验统计量之间的关系</title>
      <link>https://stats.stackexchange.com/questions/637347/karlin-rubin-theorem-relationship-between-test-statistic-having-the-mlr-propert</link>
      <description><![CDATA[假设我们正在尝试比较单个参数 $\theta$ 的两个假设。原假设 $H_0$ 是 $\theta = \theta_0$，替代假设是 &lt; span class=&quot;math-container&quot;&gt;$\theta ≥ \theta_0$。
据我所知，卡林-鲁宾定理告诉我们，如果存在这样一个统计量 $T(X)$，它具有单调性似然比（MLR）属性，意味着函数
$$
\frac{P\left(T(X)|\theta_1\right)}{P\left(T(X)|\theta_0\right)}
$$
在$T$中是单调非递减的，我们可以通过基于$T(X)$。
问题：$T(X)$ 是 MLR 和  之间有什么关系$T(X)$ 是一个足够的统计数据吗？

卡林-鲁宾定理是否要求 $T(X)$ 也足够，或者只是 MLR？
对于成为 MLR 和充分性有什么影响吗？

我们是否有足够的 MLR $\to$ 和/或足够的 $\to$ MLR？ 


关于 MLR 和最小足够怎么样？

我们是否有足够的最低 $\to$ MLR 和/或 MLR $\to$ 最低限度够了吗？


这些事情有任何关联吗？

简而言之，我在这里看到很多帖子讨论卡林-鲁宾定理设置中的足够统计量，但当我阅读它时，MLR 属性似乎是真正重要的标准。&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/637347/karlin-rubin-theorem-relationship-between-test-statistic-having-the-mlr-propert</guid>
      <pubDate>Sat, 20 Jan 2024 19:47:12 GMT</pubDate>
    </item>
    </channel>
</rss>