<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 13 May 2024 12:26:53 GMT</lastBuildDate>
    <item>
      <title>如何在lme4中建模对照实验（三个时间点，两组）？</title>
      <link>https://stats.stackexchange.com/questions/647136/how-to-model-a-controlled-experiment-three-time-points-two-groups-in-lme4</link>
      <description><![CDATA[我们进行了行为改变现场实验，分为两组（干预组与对照组）和三个时间点（T0、T1、T2）。我们计划以 T0 分数作为协变量和两个随机截距来比较 T1 和 T2 的组间差异（分别因为样本小/退出）：(1) individual_ID 和 (2) Workshop_ID（干预措施在单独的小组研讨会中进行）在 R 中使用 lme4 包。
为此，我们子选择了 T1 行并为所有 DV 添加了 T0 列。
例如：model_1_post_self_efficacy &lt;- lmer(self_efficacy ~ T0_self_efficacy + group + (1 | individual_ID) +(1 | Workshop_ID), data = data_T1_baseline)
这不起作用，因为每个 individual_ID 只有一行。当我们使用由 T0 和 T1 行以及 T0 协变量列组成的数据集时，它确实有效。然而，从概念上讲，以 T0_DV 作为协变量来预测 T0 和 T1 之间的 DV 似乎很奇怪。
或者，没有协变量的模型，而是时间 * 组交互 + individual_ID + Workshop_ID 作为随机截距）也可以工作。
model_4_post_self_efficacy &lt;- lmer(self_efficacy ~ 时间 * 组 + (1 | 工作室_ID) + (1 | 个人_ID), data = data_T1_T0)
我的问题是：(1) 有没有办法合理地结合协变量和个体随机效应，以及 (2) 我们如何最好地决定做什么？非常感谢您的任何提示。]]></description>
      <guid>https://stats.stackexchange.com/questions/647136/how-to-model-a-controlled-experiment-three-time-points-two-groups-in-lme4</guid>
      <pubDate>Mon, 13 May 2024 11:12:58 GMT</pubDate>
    </item>
    <item>
      <title>处理情况： (x ~ y) == (y ~ x)</title>
      <link>https://stats.stackexchange.com/questions/647134/handling-the-situation-x-y-y-x</link>
      <description><![CDATA[如果使用线性回归拟合以下两个模型，产生的系数本质上是相同的，那么使用什么合适的建模技术？

x ~ y
y ~ x

变量错误模型是正确的选择吗？
还是情况已经毫无希望了，两种模型本质上都毫无意义？
理论告诉我们：
$y=\frac{cov(x, y)}{var(x)}x+ϵx$
$x=\frac{cov(x, y)}{var(y)}y+ϵy$
我有生成模型的数据：

x=1.2+0.59y
y=1.2+0.64x

对于该数据，上述理论产生的斜率值为：0.3689927 和 0.818845，即不满足理论假设
数据可用，并且用于拟合模型的 R 代码是：
bal_mod=glm(log(估计) ~ log(Elapsed_Duration), data=bal, 子集=(Elapsed_Duration &gt; 0) &amp; (估计 &gt; 7))

和：
bal_mod=glm(log(Elapsed_Duration) ~ log(估计), data=bal, 子集=(Elapsed_Duration &gt; 0) &amp; (估计 &gt; 7))

值的分布似乎大致呈泊松分布，添加 family=poisson 会产生更好的拟合，但系数不会发生太大变化。
x 和 y 都是数据的 log 形式。]]></description>
      <guid>https://stats.stackexchange.com/questions/647134/handling-the-situation-x-y-y-x</guid>
      <pubDate>Mon, 13 May 2024 10:44:09 GMT</pubDate>
    </item>
    <item>
      <title>“重复测量测试”数据输入</title>
      <link>https://stats.stackexchange.com/questions/647133/repeated-measurement-test-data-input</link>
      <description><![CDATA[大家好！
几周前我刚刚开始使用 SPSS。假设我想做一个统计测试来检查 4 种不同农药在 5 周内的效率（第一周是对照）。每周我们都会进行测量。我决定采用双向重复测量方差分析测试（分析--&gt;一般线性模型--&gt;重复测量的选择）。
当我必须添加第二个因素（我将第一个因素添加为五级）时，我的问题就出现了。无论我如何插入数据，添加第二个因素都是不可能的。
周控制 Pes1 Pes2 Pes3 Pest4
1 2000 100 20 20 300
2 800 10 90 8 60
3 3 80 80 70 400
4 100 80 30 4 200
5 2 3 40 20 300

或
ID 周 CFU pESID 测量 ID
1 周1 2000 控制 1,00
1 周1 100 PES1 1,00
……
5 周5 40 PES2 2,00
5 周5 20 PES3 3,00
5 周5 300 pes4 4,00

或
产品 week1 week2 week3 week4 week5
1 2000 100 20 20 300
2 800 10 90 8 60
3 3 80 80 70 400
4 100 80 30 4 200
5 2 3 40 20 300

我是否使用了错误的测试或搞乱了设置？
感谢您提供的任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/647133/repeated-measurement-test-data-input</guid>
      <pubDate>Mon, 13 May 2024 10:43:27 GMT</pubDate>
    </item>
    <item>
      <title>在模型中治疗效果后重新计算准确率、精确度和召回率</title>
      <link>https://stats.stackexchange.com/questions/647132/re-calculate-accuracy-precision-and-recall-after-treatment-effect-in-a-model</link>
      <description><![CDATA[采用流失预测模型，其目标是检测很有可能从网站流失的玩家，并向这些玩家发送报价以让他们留在网站。
在初始训练阶段，不会向玩家发送任何报价，因此您可以训练模型（在本例中为分类器）以确定是否失效为 1，如果未失效则为 0。使用准确度、精确度、召回率、f1 等标准指标，您可以选择最佳模型然后进行部署。
现在，一旦模型到位，您检测到的玩家将收到报价，假设几个月后您想要重新计算模型指标以评估模型是否需要重新训练，现在的问题是有一种治疗方法会改变玩家的行为，所以如果模型预测会失效（在本例中为 1），那么您发送报价，然后检查实际值，您可能会看到 0（没有失效），这可能意味着该优惠成功地防止了玩家失效。数据现在看起来像这样：

&lt;标题&gt;

user_id
churn_prediction
实际流失


&lt;正文&gt;

200
0
0


201
1
0


202
1
1



从表中您可以看到，例如 user_id 201 被预测会流失，因此他当时会接受治疗，然后当我们在 x 时间后检查实际/真实状态时，我们可以看到该用户仍然在地点。问题在于，对于分类器指标来说，churn_prediction 为 1 且actual_churn 为 0 将被视为错误的预测，但实际上，玩家的真实行为可能会因处理为 0 而改变（这对于系统，但我们不知道模型是否真的出错了，或者治疗是否影响了这一结果）。没有治疗的情况（预测=0）应该不会影响，因为我可以正确测量模型是否正确预测并检查实际情况，但是有治疗的情况很难估计模型是否正确。这肯定会影响所有分类指标，从而使正确评估模型的纯粹性能以进行重新训练/监控变得更加困难。
我知道我可以衡量与整个系统相关的其他指标，例如，也许报价不是最好的并且需要更改，但如果我只想评估模型的性能，我的问题是如何考虑治疗效果来重新计算指标，以便我可以评估模型的当前性能以进行重新训练/监控。]]></description>
      <guid>https://stats.stackexchange.com/questions/647132/re-calculate-accuracy-precision-and-recall-after-treatment-effect-in-a-model</guid>
      <pubDate>Mon, 13 May 2024 10:41:41 GMT</pubDate>
    </item>
    <item>
      <title>将 softmax 理解为激活函数以及数据和梯度的稀疏性</title>
      <link>https://stats.stackexchange.com/questions/647131/understanding-softmax-as-an-activation-function-and-sparsity-in-data-and-gradie</link>
      <description><![CDATA[我正在开发一个项目，其中包括一个使用单热点的概率模型，并且偶尔会部分冻结权重或将梯度归零到权重的特定区域。在模型的某些部分，我们还尝试使用 softmax 激活来增强模型这些部分的概率解释。我们正在尝试获得更多的可解释性，并看看以后是否可以使用它们来改进我们的分类。
然而，我在这些实验中遇到了一些困难，而且我经常发现模型很容易发散。从我所看到的来看，我相信这些是问题的（部分）——softmax函数往往会给小输入赋予过多的权重，当你再次使用softmax时，这种效果会变得更糟，而且权重的部分冻结（在一层内，而不是在层内）常见的层部分冻结）或者在某些情况下梯度本身已经稀疏，我认为这会影响优化器。单热输入也是一件事，并且可能有所贡献，但我不确定目前我是否有不同的选择。所以我的激活有问题，输入稀疏，梯度稀疏
是否有研究这些问题或类似问题的文献？您是否尝试过任何方法并在这些场景中取得了成功？
我已经尝试了一些关于 softmax 函数的要点，或者用其他东西替换它并添加归一化（总和为 1），但它们要么没有帮助，要么太不稳定，无法使用，现在我要继续数据本身和梯度。我们正在尝试其他不同的事情，但我想首先看看是否可能，如果不可能，至少了解这些主题的更多/原因。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/647131/understanding-softmax-as-an-activation-function-and-sparsity-in-data-and-gradie</guid>
      <pubDate>Mon, 13 May 2024 10:07:24 GMT</pubDate>
    </item>
    <item>
      <title>泊松分布随机变量的高斯场</title>
      <link>https://stats.stackexchange.com/questions/647130/gaussian-field-of-poisson-distributed-random-variables</link>
      <description><![CDATA[即使观测值服从泊松分布，空间过程是否也可能是高斯场？它们的任何有限组合如何遵循多元正态分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/647130/gaussian-field-of-poisson-distributed-random-variables</guid>
      <pubDate>Mon, 13 May 2024 09:39:20 GMT</pubDate>
    </item>
    <item>
      <title>小样本、嵌套、多结果的研究分析</title>
      <link>https://stats.stackexchange.com/questions/647129/analysis-of-research-with-small-sample-size-nesting-and-many-outcomes</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647129/analysis-of-research-with-small-sample-size-nesting-and-many-outcomes</guid>
      <pubDate>Mon, 13 May 2024 09:00:23 GMT</pubDate>
    </item>
    <item>
      <title>从有限的采样数据估计平滑密度场</title>
      <link>https://stats.stackexchange.com/questions/647128/estimating-smooth-density-field-from-limited-sampled-data</link>
      <description><![CDATA[我想估计一个“密度场”，特别是$P(y|x, m)$，用于二进制标签$y$ 与以空间坐标 $m$ 和其他时空特征  为特征的 2D 点相关联$x$。该模型应该旨在预测每个特定点（“逐点概率场”）的概率，而不是整个空间的概率。换句话说，这些点的估计概率在 2D 空间上不需要总和为 1；事实上，它们的总和可能会明显大于 1，除非输入 𝑥 存在一些不利的设置。我认为这个问题也可以看作是估计 3D 表面，其中 x 和 y 跨越 2D 空间，z 介于 0 和 1 之间。
尽管我的数据集由数十万个数据点组成，但这对于估计整个表面来说可能仍然有限。此外，我还面临着确保模型输出平滑的挑战。我想知道什么是好的问题设置、神经网络架构和损失函数来促进输出的平滑度。
问题：

什么类型的损失函数和神经网络架构适合对概率场进行建模，以确保相邻点和相似特征集之间的概率值平滑过渡，特别是当只有有限的点集可用时？
我正在寻找能够解决类似建模挑战的正确术语和文献领域。虽然对分布估计有大量研究（例如，使用高斯混合模型），但它与我估计密度场的需要并不相符。事实上，我什至不确定“密度场”或“逐点概率场”是否是我正在寻找的正确术语。我应该在处理类似问题的文献中搜索哪些术语和问题规范？

我感谢任何可以帮助有效地构建和解决我的问题的类似工作的指导或参考。]]></description>
      <guid>https://stats.stackexchange.com/questions/647128/estimating-smooth-density-field-from-limited-sampled-data</guid>
      <pubDate>Mon, 13 May 2024 08:47:45 GMT</pubDate>
    </item>
    <item>
      <title>什么是重要性抽样中的提案分布</title>
      <link>https://stats.stackexchange.com/questions/647121/what-is-proposal-distribution-in-importance-sampling</link>
      <description><![CDATA[我想用一个简单的例子来学习重要性采样。考虑以下示例代码，它使用 python 对简单的贝叶斯网络实现重要性采样。
我读到我们修复了证据的值，所以在这里我们修复“y” （正在带雨伞）为 True，并且如果我们观察到有人带了雨伞，想要估计晴朗天气的概率。
我不明白为什么它使用均匀分布来生成sunny和rainy样本，我希望使用先验概率来生成它们，然后根据权重进行调整关于“y”的概率考虑到每个样本的天气。
随机导入

# 定义概率
p_sunny = 0.7
p_雨= 0.3
p_y_given_sunny = 0.2
p_y_given_rainy = 0.8

# 使用提案分布生成 10 个样本
样本=[]
对于范围（10）内的 _：
    # 来自提案分布的样本 X
    x_sample = random.choice([&#39;晴天&#39;, &#39;雨天&#39;])
    
    # 根据证据计算权重 Y = yes
    如果 x_sample == &#39;晴朗&#39;:
        重量 = p_sunny * p_y_given_sunny
    别的：
        重量 = p_rainy * p_y_given_rainy
    
    样本.append((x_sample, 权重))

# 标准化权重
Total_weight = sum(w 为 _, w 为样本)
Normalized_samples = [(x, w/total_weight) 对于样本中的 x, w]

print(&quot;生成的样本：&quot;)
对于 x，归一化样本中的权重：
    print(f&quot;X = {x}, 权重 = {权重:.4f}&quot;)

# 计算后验概率
terior_sunny = sum(x 的权重，如果 x == &#39;sunny&#39; 则归一化样本中的权重)
terior_rainy = sum(x 的权重，如果 x == &#39;rainy&#39; 则归一化样本中的权重)

print(&quot;\n后验概率:&quot;)
print(f&quot;P(X = 晴天 | Y = 是) = {posterior_sunny:.4f}&quot;)
print(f&quot;P(X = 下雨 | Y = 是) = {posterior_rainy:.4f}&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/647121/what-is-proposal-distribution-in-importance-sampling</guid>
      <pubDate>Mon, 13 May 2024 06:01:26 GMT</pubDate>
    </item>
    <item>
      <title>机器学习的概率区间</title>
      <link>https://stats.stackexchange.com/questions/647112/probability-intervals-with-machine-learning</link>
      <description><![CDATA[目标：找到概率真正处于 [x]% 置信度的区间。
让我们从一个非预测性实验开始。抛硬币。正面或反面。我们已经知道，在公平的游戏中，正面或反面出现的概率各为 50%，但要实现这一目标，我们需要分析实验数据。
我抛了十次硬币，其中有六次是正面。
话虽这么说，我可以计算出置信度为 95% 的概率区间（z 得分为 1.96）。
置信区间 = 0.6 ± 1.96 × sqrt(0.6 * (1 - 0.6) / 10) = [0.2962, 0.9038]
这意味着，对于我第 11 次抛硬币，我可以有 95% 的置信度说正面朝上的概率等于或大于 29.62% 且等于或小于 90.38%。
酷！任务完成。现在是最困难的部分，机器学习预测。
我们不知道概率应该是多少，但我仍然想达到同样的目标。我希望能够创建一个概率区间，其中真实概率的确定性为 [x]%，而不是获得预测概率。
我创建了一个 C# 机器学习 ml.net 二进制分类模型，对它进行了训练并对其进行了评估，给了我一个 CalibrateBinaryClassificationMetrics 具有大量指标。

准确性；
精确召回曲线下的面积；
Roc曲线下面积；
混淆矩阵；
熵；
F1分数；
对数损失；
对数损失减少；
负精度；
负召回率；
正精度；
积极回忆；

从我去年的研究来看，我发现这些都对我想要实现的目标没有帮助，如果你证明我错了，我会很高兴。
我想预测概率区间，而不仅仅是概率。
我总是将输入样本分为两部分：训练和测试。测试部分用于获取 校准的二进制分类指标。
此测试部分是预测的，然后我将预测概率与实际输出进行比较（1 - 发生，0 - 未发生）。
我可以用这些数据实现预测区间吗？也许是一般误差范围？
我应该怎么做才能获得概率区间而不仅仅是预测概率？如果我们不知道概率有多准确，那么概率本身就没有任何意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/647112/probability-intervals-with-machine-learning</guid>
      <pubDate>Mon, 13 May 2024 01:42:57 GMT</pubDate>
    </item>
    <item>
      <title>提升和逻辑回归之间有什么联系？</title>
      <link>https://stats.stackexchange.com/questions/647099/what-is-the-connection-between-lift-and-logistic-regression</link>
      <description><![CDATA[我注意到两个（显然不同的）措施之间存在有趣的联系。我处于购物篮分析框架（又名频繁项集挖掘，两者都是通用名称）下，其中所有变量都是热编码的。因此，我们的预测变量 Y 和预测变量 X 都是虚拟变量，代表交易中产品是否存在。
第一个度量“提升”来自 apriori 算法。
它被定义为
$$ \frac{置信度(A \rightarrow B)}{support(B)} = \frac{P(B|A)}{P(B)}$$
基本上是 $$ \frac{P(A \cap B)}{P(A)P(B)}$$
第二个度量来自单变量逻辑回归。
$$logit(Y) = a + bX + e_i$$
我的疑问在于逻辑回归部分。
a 是截距，b 表示对数赔率之差。
这两种度量都是对称的，当在 X 上回归 Y 或在 Y 上回归 X 时（或使用先验时），我仍然得到相同的 lift 和 b。但它们有不同的尺度。这有什么关系？
是否有一种形式可以将逻辑回归中的 b 值转换为等效提升力？
非常感谢我可以找到更多信息的任何提示或参考书目。
编辑：

这里我附上一个小样本。这些代表了apriori算法提取的一些规则。列 Antecedent 代表产品 A，列 Consequent 代表产品 B。在本例中，Lift 和 Logistics_coefficients 是我们感兴趣的变量，我试图弄清楚它们是如何相关的，以及我们是否可以从一个映射到另一个。
（如果有人感兴趣，这里是其他结果的链接)]]></description>
      <guid>https://stats.stackexchange.com/questions/647099/what-is-the-connection-between-lift-and-logistic-regression</guid>
      <pubDate>Sun, 12 May 2024 19:10:24 GMT</pubDate>
    </item>
    <item>
      <title>从回归建模策略中的近似模型构建列线图</title>
      <link>https://stats.stackexchange.com/questions/647091/constructing-nomogram-from-approximate-model-in-regression-modelling-strategies</link>
      <description><![CDATA[在 Frank Harrell 的《回归建模策略》第 19.5 节中，我们使用 ols 的线性回归创建了一个近似模型。由于这是一个 ols 对象，我们必须手动计算生存量以制作列线图。
在本书第二版第 472 页（pdf 版本为 491 页）中，值 0.802352037606488 在此计算中出现了两次。这个值从哪里来？书中其他地方没有提到这一点。附上具体代码，其中f为完整模型。
expected.surv &lt;- Mean(f)
quantile.surv &lt;- Quantile(f)
Expected.surv &lt;- 函数(lp = NULL, parms = 0.802352037606488) {
  名称（参数）&lt;- NULL
  exp(lp + exp(2 * 参数)/2)
}

quantile.surv &lt;- 函数(q = 0.5, lp = NULL,
  参数 = 0.802352037606488) {
  名称（参数）&lt;- NULL
  f &lt;- 函数(lp, q, parms) lp + exp(parms) * qnorm(q)
  名称(q) &lt;- 格式(q)
  drop(exp(outer (lp, q, FUN = f, parms = parms )))
}
median.surv &lt;- function(x) quantile.surv(lp=x)


我在文档中找到的唯一有点相关的示例来自函数 transace，其中包含以下示例
## 未运行：
# 另一个例子，关于假设数据
f &lt;- areg.boot(响应 ~ I(年龄) + 单调(血压) + 种族)
# 使用 I(response) 不变换响应变量
情节（f，conf.int=.9）
# 检查残差的分布
绘图（拟合（f），残差（f））
qqnorm(残差(f))
# 使用 ols 重新拟合该模型，以便我们可以绘制它的列线图。
# 列线图将显示线性预测变量、中位数、平均值。
# 最后两个是涂抹估计器。
Function(f, type=&#39;individual&#39;) # 创建转换函数
f.ols &lt;- ols(.response(response) ~ 年龄 +
             .blood.Pressure(血液.Pressure) + .race(race))
# 注意：这个模型与 f 几乎完全相同，但是有
# 由于插值，差异非常小
# 转换
meanr &lt;- Mean(f) # 创建 lp 计算平均响应的函数
medr &lt;- Quantile(f) # 默认分位数为 0.5
列线图(f.ols, fun=list(Mean=meanr,Median=medr))

但在这里他们不做任何转换。
编辑：
似乎包已更新，因此现在默认使用 Mean() 和 Quantile() 进行（正确的）转换。我认为这对于任何模型都适用，例如 Cox 比例风险模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/647091/constructing-nomogram-from-approximate-model-in-regression-modelling-strategies</guid>
      <pubDate>Sun, 12 May 2024 16:23:52 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中如何处理极小的训练数据集？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/647122/how-to-deal-with-extremely-small-training-dataset-in-machine-learning</link>
      <description><![CDATA[我有大约 100 行带有标签的数据
国家/地区 |类别 |标签
-----------+----------------+--------------------
[美国、英国、日本] |电子| 1
[美国] |体育 | 1
[台湾、英国] |杂货| 2
[日本] |预订 | 3

大约 900 行没有标签的数据
国家/地区 |类别
-----------+--------------
[美国、英国] |运动的
[台湾] |运动的
[美国] |杂货店
[日本] |电子的

使用这么小的数据集做分类模型可以吗？如果是这样，我该如何编码Country？或者是否有任何其他聚类/数学方法可以用来处理这种情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/647122/how-to-deal-with-extremely-small-training-dataset-in-machine-learning</guid>
      <pubDate>Sun, 12 May 2024 02:56:14 GMT</pubDate>
    </item>
    <item>
      <title>用两个变量相乘来优化目标？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647060/optimizing-objective-with-two-variables-multiplied-with-each-other</link>
      <description><![CDATA[假设您想要优化以下目标函数：
$$\min_{a,b} \Vert a + ab + b - W \Vert_2^2$$
其中 $a \in \mathbb{R}^{m,n}$ 和 $b \in \ mathbb{R}^{n,p}$ 是可学习矩阵，$W \in \mathbb{R}^{m,p}$ 是给你的一些常数矩阵。
由于 $a$ 和 $b$ 通过乘法错综复杂地联系在一起，有哪些方法可以优化这些类型的多变量目标函数？
普通梯度下降有效吗？我认为我的理解还不足以肯定地说。
经过初步研究，我们似乎可以进行贪婪搜索：在每次迭代中，按住 $a$ （或 $b$) 常量，然后仅针对单个变量进行优化 $b$ （或 $a$ ）通过梯度下降。每次迭代后，交替变量。
贪婪搜索听起来与坐标下降类似，我想知道是否有其他方法在整体上更加稳健并且不易出现局部极小值。
似乎有另一种方法称为 EM（期望最大化算法），它假设 $a$ 或 $b $ 是一个潜在变量，但除此之外，感觉它在做与贪婪搜索相同的事情，只是在随机设置中。
除了贪婪搜索之外，还有哪些其他优化算法可以处理通过乘法错综复杂地链接的多个变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/647060/optimizing-objective-with-two-variables-multiplied-with-each-other</guid>
      <pubDate>Sun, 12 May 2024 00:51:01 GMT</pubDate>
    </item>
    <item>
      <title>使用深度集成量化预测不确定性：如何组合拉普拉斯分布？</title>
      <link>https://stats.stackexchange.com/questions/647054/quantifying-prediction-uncertainty-using-deep-ensembles-how-to-combine-laplace</link>
      <description><![CDATA[对于回归问题，我想训练深度神经网络的集合来预测标记的输出以及不确定性，类似于论文中提出的方法使用深度集成进行简单且可扩展的预测不确定性估计。作者使用高斯分布的负对数似然（NLL）作为损失函数，使模型隐式学习方差
$$
{\ell_\text{NLL}}_G =
-\log p_G\left(y \mid \hat \mu, \hat\sigma^2\right)=
\frac{\log \hat\sigma^2}{2}+
\frac{\left(y-\hat \mu\right)^2}
{2 \帽子\sigma^2}+
\text{常量}
$$
其中 $y$ 是目标，$\hat \mu$ 是预测平均值， $\hat \sigma^2$ 是预测方差。
但是，我注意到当使用平均误差而不是均方误差作为损失函数时，我的模型收敛得更好。因此我想利用拉普拉斯 NLL，它对异常值应该更加鲁棒：
$$
{\ell_\text{NLL}}_L =
-\log p_L\left(y \mid \hat \mu, \hat b\right)=
\log \hat b +
\frac{\left|y-\hat \mu\right|}{\hat b} +
\text{常量}
$$
其中 $\hat b$ 是预测的比例参数。
在高斯情况下，作者将各个模型的预测均值和方差结合起来$m$：
$$
\mu_*=\frac{1}{M} \sum_{m=1}^M \hat \mu_m \\
\text{Var}(\mu_*) = \sigma_*^2=\frac{1}{M} \left(\sum_{m=1}^M\hat\sigma_m^2+\hat \mu_m^2 \右）-\mu_*^2
$$
计算混合拉普拉斯分布的均值和方差的正确方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647054/quantifying-prediction-uncertainty-using-deep-ensembles-how-to-combine-laplace</guid>
      <pubDate>Sat, 11 May 2024 21:35:48 GMT</pubDate>
    </item>
    </channel>
</rss>