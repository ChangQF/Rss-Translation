<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 05 Aug 2024 01:08:58 GMT</lastBuildDate>
    <item>
      <title>弱平稳过程混淆</title>
      <link>https://stats.stackexchange.com/questions/652301/weakly-stationary-process-confusion</link>
      <description><![CDATA[假设我抽样 $2n$ iid 正态分布 $A_k, B_k$，其中 $k=1,...n$，均值为 0，但 $Var(A_k) = Var(B_k)$。利用这些，我可以构建一个随机时间序列
$$X(t) := \sum_{k=1}^n (A_k + iB_k) e^{i\lambda_kt} + (A_k - iB_k) e^{-i\lambda_kt},$$ 其中 $0 &lt; \lambda_k$ 是某个固定（非随机）$n$ 实数序列。
现在，通过构造：

$X(t)$ 是实值。
对于所有 $t$，$E[X(t)] = 0$
$E[X(t)] = 4\sum_k Var(A_k) e^{i\lambda_k \tau}$（为此，写为 $Z_k = A_k + i B_k$，因此只有 4项）

具体来说，$X(t)$ 是一个实值、弱平稳序列。
接下来，我可以用以下代码生成其中一些：
def make_normal(lambdas, stds, T):
assert len(stds) == len(lambdas), &quot;必须为每个 lambda 提供一个 stddev。&quot;
lambdas.sort()
assert all([l &gt;= 0 for l in lambdas]), &quot;输入 lambda 必须是非负的&quot;

Z_real = np.random.normal(scale = stds)
Z_complex = np.random.normal(scale = stds)
如果 lambdas[0] == 0:
Z_real[0] /= 2
Z_complex[0] = 0

Z_real = np.concatenate([Z_real, Z_real])
Z_complex = np.concatenate([Z_complex, -Z_complex])
Z = Z_real + 1j*Z_complex

lambdas = [-l for l in lambdas] + lambdas

exps = np.exp(np.outer(lambdas, T)*1j)

返回 np.matmul(Z, exps)

lambdas = [0.1, 1, 2, 5, 10]
stds = [2, 1, 0.7, 0.5, 0.1]
T = [0.1*i for i in range(500)]
X = make_normal(lambdas, stds, T)
assert max(abs(np.imag(X))) &lt; 1e-10, &quot;TS 有点不对劲... 应该是真的！&quot;
plt.plot(T, np.real(X))


根据我见过的所有启发式方法，这绝对不是&quot;看起来是静止的&quot;。所以我的问题是以下哪项是正确的：

我的代码有问题。
我所了解的有关过程“看起来静止”的启发式方法完全是错误的 - 这个时间序列对我来说并不“看起来静止”，因为它似乎具有趋势、季节性等。我用此代码生成的几乎所有时间序列都具有这些特征。
其他东西完全错误！

感谢您的时间！:)]]></description>
      <guid>https://stats.stackexchange.com/questions/652301/weakly-stationary-process-confusion</guid>
      <pubDate>Sun, 04 Aug 2024 19:42:24 GMT</pubDate>
    </item>
    <item>
      <title>配对测量后提取重要样本</title>
      <link>https://stats.stackexchange.com/questions/652290/extraction-of-significant-samples-after-paired-measures</link>
      <description><![CDATA[我有两组时间成对的值：A 和 B。我知道 B 明显高于
A（使用 Wilcoxon 检验）（我的样本量很小），但我想知道哪些样本的 B 有明显差异。
使用 B-A 的差异，我得到了时间变化的分布，并据此计算了置信区间（通过自举法）。
我不确定应该使用什么阈值来确定哪些样本在 A 和 B 之间确实有显著变化。
提前感谢 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/652290/extraction-of-significant-samples-after-paired-measures</guid>
      <pubDate>Sun, 04 Aug 2024 16:12:40 GMT</pubDate>
    </item>
    <item>
      <title>嵌套 GLM 的 F 检验</title>
      <link>https://stats.stackexchange.com/questions/652281/f-test-for-nested-glm</link>
      <description><![CDATA[假设我们有两个嵌套的 GLM 模型 $M_0 \subset M_1$，分别具有 $q$ 和 $p$ 个参数。我们还知道两个模型中的弥散参数估计为相同的值，表示为 $\widehat{\phi} \neq 1$。我的目标是测试 $p-q$ 个附加参数在更大模型中的重要性。在这种情况下，适当的检验将是 F 检验（例如，参见第 4.7.6.2 节此处），其中
$$
F = \frac{D_0-D_1}{\widehat{\phi} (p-q)},
$$
其中 $D_0, D_1$ 是 $M_0$ 和 $M_1$ 的偏差。在同一本书中，偏差定义为
$$
D = 2 \phi(L_\textrm{full} - L),
$$
其中 $L_\textrm{full}$ 和 $L$ 是完整（饱和）模型和考虑模型的对数似然。简单来说，我们可以通过用 $\widehat{\phi}$ 代替 $\phi$ 来估计偏差，因此在我们的例子中
$$
F = \frac{2 \widehat{\phi} (L_\textrm{full} - L_0) - 2 \widehat{\phi}(L_\textrm{full} - L_1)}{\widehat{\phi} (p-q)} = \frac{2(L_1-L_0)}{p-q}。
$$
另一方面，我偶然发现了一个练习，其中给出了 $L_0, L_1$ 和 $\widehat{\phi}$，并且 F 比率计算为
$$
F = \frac{2(L_1-L_0)}{\widehat{\phi}(p-q)},
$$
这让我认为这里使用了缩放偏差（$D^* = D/\phi$）而不是常规偏差。
计算此统计数据的哪种方法是正确的？
我查找了很多不同的来源（例如 此处 或 此处)，但我觉得每一篇都说得不一样，我无法调和所有版本。任何帮助我都会很感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/652281/f-test-for-nested-glm</guid>
      <pubDate>Sun, 04 Aug 2024 13:05:05 GMT</pubDate>
    </item>
    <item>
      <title>处理小型医疗数据集和处理异常值[重复]</title>
      <link>https://stats.stackexchange.com/questions/652275/dealing-with-small-medical-dataset-and-handling-outliers</link>
      <description><![CDATA[我发布了一个问题，但由于我提供的信息不完整，该问题已被关闭。这次我想完整地提出我的问题。如果您能帮助我，我将不胜感激。我们拥有与放射学相关的信息和参数，包括（MLD、PTV、HI、V95 RTlung(cc)、Dmean Lung、V20、V10、V5 X Jaw、Y Jaw、Med Gantry、Angle Lat Gantry、Angle field size、Weight Med、Weight Lat、Wedge Med Wedge Lat、Post boarder、Lat borderer、Medial Border）。我们已获得 66 位患者的信息。这里我们打算使用机器学习模型（MLD、PTV RTlung(cc)、Dmean Lung V20、V10 V5 X Jaw Y Jaw Med Gantry Angle Lat Gantry Angle field size Weight Med Weight Lat Wedge Med Wedge Lat Post borderer Lat borderer Medial Border）来预测 Dmean lung、V95、v20、v10、HI。

数据集采用数字表的形式，包含 66 行和 22 列。我绘制了 pairplot 图、线性回归图。

我如何改进结果？测试集 r2 结果为负，训练集约为 0.6，这意味着模型没有学习任何东西？我该如何解决这个问题？



]]></description>
      <guid>https://stats.stackexchange.com/questions/652275/dealing-with-small-medical-dataset-and-handling-outliers</guid>
      <pubDate>Sun, 04 Aug 2024 08:33:28 GMT</pubDate>
    </item>
    <item>
      <title>我可以对回归结果进行方差分析吗？</title>
      <link>https://stats.stackexchange.com/questions/652251/can-i-perform-an-anova-on-the-outcomes-of-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652251/can-i-perform-an-anova-on-the-outcomes-of-regression</guid>
      <pubDate>Sat, 03 Aug 2024 15:51:55 GMT</pubDate>
    </item>
    <item>
      <title>在梯度下降中目标是否应该标准化？</title>
      <link>https://stats.stackexchange.com/questions/652232/should-the-target-be-standardized-in-gradient-descent</link>
      <description><![CDATA[假设我们有一个一般的损失函数，它依赖于一些参数$w$（例如神经网络权重）：
$$L_w =\frac{1}{N} \sum_i \ell(\hat{y}_i, y_i)$$
除了特征之外，标准化目标是否有好处？
也就是说，我们是否应该更倾向于优化$L_w&#39;$：
$$L_w&#39; =\frac{1}{N} \sum_i \ell\left(\hat{y}_i, \frac{y_i-\bar{y}}{\sigma} \right)$$
over $L_w$?
相关问题
在此问题的公认答案中，指出：

对输出进行归一化不会影响$f$的形状，因此通常没有必要。

其中$\hat{y} = f_w (x)$。然而，在训练期间我们优化了损失函数，因此$f$的形状无关紧要。]]></description>
      <guid>https://stats.stackexchange.com/questions/652232/should-the-target-be-standardized-in-gradient-descent</guid>
      <pubDate>Fri, 02 Aug 2024 23:09:42 GMT</pubDate>
    </item>
    <item>
      <title>生长曲线分析建议</title>
      <link>https://stats.stackexchange.com/questions/652146/growth-curve-analysis-advice</link>
      <description><![CDATA[我对生长曲线模型还不熟悉，需要一些指导。我有大约 50,000 只羊羔的数据，每只羊羔都有出生体重，并在出生后大约 30、60、90 和 120 天进行了两次额外测量。我想应用 Logistic、Gompertz 和 von Bertalanffy 等生长曲线模型。
我有一些顾虑：
我能否同时使用天数和所有动物记录进行生长曲线分析，还是需要为每只动物计算 A 和 K 等参数？
如果需要单独计算，每只动物进行三次测量是否足够？]]></description>
      <guid>https://stats.stackexchange.com/questions/652146/growth-curve-analysis-advice</guid>
      <pubDate>Thu, 01 Aug 2024 12:16:42 GMT</pubDate>
    </item>
    <item>
      <title>当预测变量出现错误时会发生什么？</title>
      <link>https://stats.stackexchange.com/questions/652131/what-happens-when-there-are-errors-in-the-predictor-variables</link>
      <description><![CDATA[我昨天问了这个问题，但现在无法登录我的账户了：在未来模型中使用响应变量作为预测变量？
在思考了这个问题（估计雇用新员工对工厂生产率的净成本效益影响）之后，我想到了一种看待这个问题的新方法（即当预测变量有错误时该怎么办？）。我认为也许可以使用工具变量？
方法 1：直接使用工具变量分析净收益

对员工和已处理订单之间的关系进行建模：
$$\hat{P}_t = \hat{\alpha} \hat{E}_t + \hat{\epsilon}_t$$
其中 $\hat{E}_t$ 是 $E_t$ 的仪表化版本。我们使用第一阶段回归：
$$E_t = \gamma_0 + \gamma_1 Z_t + \nu_t$$
$$\hat{E}_t = \hat{\gamma}_0 + \hat{\gamma}_1 Z_t$$
此处，$Z_t$ 为工具变量（例如，招聘的滞后预算分配）。

模型的其余部分保持不变，但在所有部分中使用 $\hat{E}_t$ 代替 $E_t$方程。


我认为工具变量$Z_t$（或$Z_{t-1}$）应该与员工人数相关，但不应直接与主方程中的误差项相关。这可能有助于解决潜在的内生性问题？
这就是工具变量的使用方式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652131/what-happens-when-there-are-errors-in-the-predictor-variables</guid>
      <pubDate>Thu, 01 Aug 2024 05:19:04 GMT</pubDate>
    </item>
    <item>
      <title>独立样本均值乘积的 UMVUE</title>
      <link>https://stats.stackexchange.com/questions/652122/umvue-for-the-product-of-means-from-independent-samples</link>
      <description><![CDATA[设 $ x_1, \ldots, x_m $ 为从分布 $P$ 中抽取的 i.i.d. 样本，$ y_1, \ldots, y_n $ 为从分布 $Q$ 中抽取的 i.i.d. 样本。假设样本 $x_i$ 和 $y_j$ 彼此独立。假设 $\bar{X}$ 是 $\mu_X = E_{X \sim P}[X]$ 的均匀最小方差无偏估计量 (UMVUE)，而 $\bar{Y}$ 是 $\mu_Y = E_{Y \sim Q}[Y]$ 的 UMVUE。
参数 $\mu_X \mu_Y$ 的 UMVUE 是多少？ $\bar{X} \bar{Y}$ 是 $\mu_X \mu_Y$ 的 UMVUE 吗，或者有更好的估计量？]]></description>
      <guid>https://stats.stackexchange.com/questions/652122/umvue-for-the-product-of-means-from-independent-samples</guid>
      <pubDate>Thu, 01 Aug 2024 00:38:34 GMT</pubDate>
    </item>
    <item>
      <title>如何量化百分比排序数据集的重要性？</title>
      <link>https://stats.stackexchange.com/questions/652094/how-do-i-quantify-the-significance-of-a-percentage-ranked-data-set</link>
      <description><![CDATA[我正在考虑针对给定数据集的七种不同的预测模型，这些模型经过多次预测迭代，并量化每个预测模型总体上最准确的次数。
我需要某种方法来量化结果的重要性。例如，如果给定的预测模型在 7 个预测中排名第一的概率为 23%（7 个预测中平均分布为 14.2%），那么这有多重要？
我希望能够为这些结果的重要性建立某种基线。我怀疑这可能涉及某种正态分布，但我不知道如何计算。由于我总是使用百分比，并且总是考虑 7 个预测，因此一个参考表将是理想的选择 — 如果我能够指出 23% 是高度重要的，但 18% 是有点重要的或类似的情况。
就其本身而言，这些百分比缺乏足够的背景信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/652094/how-do-i-quantify-the-significance-of-a-percentage-ranked-data-set</guid>
      <pubDate>Wed, 31 Jul 2024 15:26:20 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程文献建议</title>
      <link>https://stats.stackexchange.com/questions/651382/gaussian-process-literature-suggestion</link>
      <description><![CDATA[我对高斯过程还很陌生，希望能得到一些关于阅读材料的帮助。假设我有以下二维时间序列数据表：
$$\begin{bmatrix}s_{t_1}^{v_1} &amp; s_{t_2}^{v_1} &amp; \ldots &amp; s_{T}^{v_1} \\ s_{t_1}^{v_2} \\ \vdots &amp; &amp; \ddots \\
s_{t_1}^{V} &amp; \ldots &amp;&amp;s_{T}^{V}\end{bmatrix}$$
其中 $t, v$ 是 2 个不同的时间索引。我有两个问题：

假设“逐行”时间序列（在索引 $t$ 中）具有清晰的模式，可以使用高斯过程和平稳核函数进行建模。“逐列”时间序列（在索引 $v$ 中）也具有清晰的模式，但模式意味着不同的内核。在这种情况下，有没有一种方法可以联合建模整个矩阵？如果有，它们叫什么？（我隐约想到了类似 $k_1 \times k_2$ 内核的东西，用于对矩阵中的任意两个项目进行建模，但不确定这是否存在/是否符合我的要求）
假设“逐行 ...时间序列仍然具有如上所示的良好模式，但“逐列”时间序列没有如此良好的模式。具体来说，假设值不是独立的，例如，通过 ACF 图观察到不同列在不同滞后处的强烈季节性。有没有关于核函数形式的研究可以让我们整合这些信号/季节性（可以是指示变量的形式）？在某种程度上，我在想类似的事情：根据这些信号进行条件反射（通过差分等），列中的项目是独立的，我们将列带回到良好的一致模式（例如随机游走）。我们可以通过这个内核对所有列进行建模，它们将考虑到所有差异。

很乐意进一步讨论，感谢你们的任何建议，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651382/gaussian-process-literature-suggestion</guid>
      <pubDate>Fri, 19 Jul 2024 03:23:37 GMT</pubDate>
    </item>
    <item>
      <title>在这个推导中如何使用分部求和技术？</title>
      <link>https://stats.stackexchange.com/questions/651379/how-is-summation-by-parts-technique-used-in-this-derivation</link>
      <description><![CDATA[在这个答案中，whuber 评论说答案中使用的技术是分部求和：

离散情况，假设$X \ge 0$取非负整数
值。然后我们可以将期望写为 $$\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\P}{\mathbb{P}} \E X = \sum_{k=0}^\infty k \P(X=k) $$ 现在，我们首先将其写为双和，然后
改变求和的顺序。观察到 $k = \sum_{j=0}^{k-1} 1$
（$k=0$ 的情况给出的上限小于下限，我们将其视为空和，即零）。这给出了 $$ 
\E X = \sum_{k=0}^\infty \sum_{j=0}^{k-1} 1 \cdot \P(X=k) $$ 现在，在这个双重和中，我们首先对 $j$ 求和，这显然等于 $\infty$。
观察到在内部求和中，指标满足不等式
$$
0 \le j \le k-1 $$ 解 $k$ 可得 $ k \ge j+1$，这又给出了新的内部和中的求和极限：$$ \E X = \sum_{j=0}^\infty \sum_{k=j+1}^\infty \P(X=k) = \sum_{j=0}^\infty \P(X &gt; j) $$ 这就是结果。连续的情况也是类似的。

我去维基百科试图理解他的评论，但我不明白。

假设 $\{f_k\}$ 和 $\{g_k\}$ 是两个序列。那么，
$$
\sum_{k=m}^{n} f_k (g_{k+1} - g_k) = (f_{n+1} g_{n+1} - f_m g_m) - \sum_{k=m}^{n} g_{k+1} (f_{k+1} - f_k)。
$$

重新排列总数与分部求和有何关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/651379/how-is-summation-by-parts-technique-used-in-this-derivation</guid>
      <pubDate>Fri, 19 Jul 2024 01:25:52 GMT</pubDate>
    </item>
    <item>
      <title>ICA 中的维度</title>
      <link>https://stats.stackexchange.com/questions/651350/dimensions-in-ica</link>
      <description><![CDATA[我正在阅读 Andrew Ng 关于 ICA 的笔记，其中的盲源分离示例大部分都是有意义的。本质上，我们有 $d$ 个麦克风录音 $x \in R^d$，以及 $s \in R^d$ 中的 $d$ 个独立扬声器，用 $x = As$ 表示，其中我们希望从观测 $x$ 中恢复混合矩阵 $A$ 和源系数 $s$。但是，如果 $x$ 和 $s$ 不是同一维度，即 $c$ 个录音来自 $d$ 个说话者，会发生什么情况？这仍然有意义吗？而且这是否仍然可处理，因为 A 现在不是正方形，$A \in R^{c \times d}$，因此系统不确定，$c &lt; d$？
同样，$A$ 是否类似于 PCA 中的主成分矩阵，$V$？]]></description>
      <guid>https://stats.stackexchange.com/questions/651350/dimensions-in-ica</guid>
      <pubDate>Thu, 18 Jul 2024 14:56:55 GMT</pubDate>
    </item>
    <item>
      <title>根据 AIc/BIC 标准比较具有不同规范的非嵌套模型</title>
      <link>https://stats.stackexchange.com/questions/650312/comparing-non-nested-models-with-different-specifications-based-on-aic-bic-crite</link>
      <description><![CDATA[我想确定在多元概率模型的情况下是否可以使用 AIC/BIC 标准进行模型选择。我有两个具有不同规格的模型：
例如模型 1：mvprobit（$Y_1 = a X_1 + b X_2 + c X_3），（Y_2 = a X_1 + b X_2 + c X_3 + \mathbf{s Y_1}），（Y_3 = a X_1 + b X_2 + c X_3 + \mathbf{s Y_1} + \mathbf{e Y_2}）$。
模型 2：mvprobit（$Y_1 = a X_1 + b X_2 + c X_3），（Y_3 = a X_1 + b X_2 + c X_3 + \mathbf{sY1}），（Y_2 = a X_1 + b X_2 + c X_3 + \mathbf{s Y_1} + \mathbf{e Y_3}$）。
这里（$a、b、c、s$和$e$是系数：$Y_1、Y_2、Y_3$是多元概率模型中的因变量）。
鉴于这些不同的模型规范，如果我从模型 1 和模型 2 获得 AIC/BIC 值，并根据最低 AIC/BIC 值选择更适合的模型，这种方法是否合理？
请注意，两个模型的数据和观测次数相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/650312/comparing-non-nested-models-with-different-specifications-based-on-aic-bic-crite</guid>
      <pubDate>Tue, 02 Jul 2024 10:44:09 GMT</pubDate>
    </item>
    <item>
      <title>用于测量事件发生随时间变化的适当测试（RStudio）</title>
      <link>https://stats.stackexchange.com/questions/650267/appropriate-test-for-measuring-change-in-event-occurrence-over-time-rstudio</link>
      <description><![CDATA[我想看看为组织提供的降低事件发生率的培训计划是否真的具有减少事件发生率的预期效果。
每个参与研究的组织（理论上）都会让尽可能多的组织成员参加一项调查，要求他们以 1 到 5 的评分自我报告他们的经历。我说理论上是因为并非所有组织每年都进行调查，所以有些组织可能在前两年进行调查，第三年不进行调查，但在第四年再次进行调查，在选择统计测试时可能也需要考虑这一点。对于每个组织，都会计算出该组织中给出 4 或 5 评分的人员百分比的平均值。
然后，我在 RStudio 中对组织进行分组，以获得不同日历年（例如 2015、2016、2017）、注册日期的年份（注册的第一年、第二年、第三年等）和调查编号（第一次、第二次、第三次参加调查，无论他们是否在几年之间休息过等）的平均百分比。
我现在想分析这些平均值，看看这些不同的组的平均百分比是否会随着时间的推移而下降，但我不确定最合适的方法是什么。我附上了一些我制作的示例图：

最明显的方法是进行某种相关性/线性回归分析，但由于调查数字是连续的，因此并非完全独立，我不确定这样做是否正确？
我知道有可能做类似配对/重复测量方差分析的事情，但我只见过最多 3 次时间测量，而我有至少 7 个时间点，所以我不确定是否有硬性数字限制。我也没有多个组来比较平均值，这只是逐年的变化 - 但是因为并非所有组织每年都进行调查，所以我不知道是否也应该进行某种注册年份*调查数量方差分析比较来解释这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/650267/appropriate-test-for-measuring-change-in-event-occurrence-over-time-rstudio</guid>
      <pubDate>Mon, 01 Jul 2024 15:59:41 GMT</pubDate>
    </item>
    </channel>
</rss>