<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 11 Dec 2024 12:35:57 GMT</lastBuildDate>
    <item>
      <title>我应该针对此分析或其他分析进行多级分析吗？需要帮助</title>
      <link>https://stats.stackexchange.com/questions/658569/should-i-conduct-a-multilevel-for-this-or-another-analysis-need-help</link>
      <description><![CDATA[我有三个数据源（教师、家长和学生），分三波对学生进行评估。我想评估所有数据，看看各个时刻之间的差异，但同时我也想使用每个来源的变量来确定可能的解释和差异（例如，对于家长使用学业水平和工作，对于学生使用性别和年龄，对于教师使用每个学生的已识别风险水平）。
我正在考虑进行重复测量分析，然后进行多元回归。每个来源都是如此。但是我现在认为我可以进行多级分析，但我不确定，因为我不是这方面的专家。
你能帮我吗？你有什么建议？
可能我没有给你足够的信息，但如果我可以澄清，请告诉我。
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658569/should-i-conduct-a-multilevel-for-this-or-another-analysis-need-help</guid>
      <pubDate>Wed, 11 Dec 2024 11:24:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 glmmTMB 和 emmeans 测试具有非正态残差和伽马分布的增长率差异是否合适？</title>
      <link>https://stats.stackexchange.com/questions/658568/is-it-appropriate-to-use-glmmtmb-and-emmeans-for-testing-differences-in-growth-r</link>
      <description><![CDATA[我有三峰数据，其中残差的分布不符合正态分布。这些连续数据（真菌生长率）由三个因素（培养基、温度和真菌来源）决定，这三个因素解释了我在绘制数据时观察到的三个峰值。我根据温度等决定因素分离了数据，并验证它们符合伽马分布。使用 glmmTMB 确定真菌之间是否存在差异（例如，来自不同来源）并将 emmeans 应用于生成的模型是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/658568/is-it-appropriate-to-use-glmmtmb-and-emmeans-for-testing-differences-in-growth-r</guid>
      <pubDate>Wed, 11 Dec 2024 11:12:44 GMT</pubDate>
    </item>
    <item>
      <title>优化 $\alpha$ 形状计算中的 $\alpha$ 参数：达到什么精度？</title>
      <link>https://stats.stackexchange.com/questions/658566/optimizing-alpha-parameter-in-alpha-shape-calculations-to-what-precision</link>
      <description><![CDATA[我正在为大量 3D 点云（每个约 2000 点）计算 alpha 形状。它们相当均匀，凹面时具有球形拓扑结构，但当然也包含一些更精细的结构，我想捕捉这些结构，因此使用 alpha 形状。
我正在使用 alphashape Python 包，它使用 二分法 来缩小 $\alpha$ 的下限 (L) 和上限 (U) 边界（$\frac{1}{\alpha}$ 是用于创建 alpha 形状的外接圆的半径）。当达到最大迭代次数时（返回 $\alpha=0$，这只会产生一个凸包），或者当 $|L-U|&lt;\delta$ 时，它会停止，在这种情况下它会返回 $U$。在许多情况下，这可以正常工作，但对于许多情况，该过程会进入长时间的迭代（数小时），即使 max_iter 非常大，也会达到最大值。这是因为 optimizealpha.py 使用的精度非常高：$\delta=$np.finfo(float).eps * 2，它是固定的，它们不作为可选参数提供。
我通过更改源代码以包含精度参数来加快速度，并使用 $d_{min}*10^{-6}$ 数量级的参数，其中 $d_{min}\approx 0.03$ 是我的数据中最小的逐点距离（$d_{max}\approx 1.8$）。但现在我不确定这是否明智：
TL;DR 问题：
是否有一种稳健或至少有点合理的方法，可以根据我的数据的某些度量（如成对距离等）为二分法优化 $\alpha$ 参数（最好比 np.eps 大得多）选择一个精度值？
（或者这个问题更适合其他地方？）]]></description>
      <guid>https://stats.stackexchange.com/questions/658566/optimizing-alpha-parameter-in-alpha-shape-calculations-to-what-precision</guid>
      <pubDate>Wed, 11 Dec 2024 10:27:22 GMT</pubDate>
    </item>
    <item>
      <title>构建统计合理的机器学习模型</title>
      <link>https://stats.stackexchange.com/questions/658563/building-a-statistically-sound-ml-model</link>
      <description><![CDATA[统计子堆栈中的沉默读者。我了解到的一件事是，许多“默认”机器学习实践由于基本的统计错误而受到挑战。这很有启发，但也有点让人不知所措。
我正在寻找一个资源或示例，以说明几乎“理想”的数据科学工作流程 - 特别是用于创建分类模型 - 即使是统计专家也几乎不会发现任何问题。
方法的多样性令人着迷，但也可能令人困惑。就上下文而言，我正在为医疗保健/制药领域开展多类分类项目。但是，凭借我获得的新知识，我现在在每一步都对我的 ML 管道进行二次猜测。
我非常感谢任何建议或指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/658563/building-a-statistically-sound-ml-model</guid>
      <pubDate>Wed, 11 Dec 2024 09:06:24 GMT</pubDate>
    </item>
    <item>
      <title>如何用不准确的评估器计算置信区间？</title>
      <link>https://stats.stackexchange.com/questions/658562/how-to-compute-a-confidence-interval-with-an-inaccurate-evaluator</link>
      <description><![CDATA[我有一个大型语言模型，它根据系统和用户提示生成输出，我想评估此系统提示的准确性。为此，我创建了一个 LLM-as-a-judge 作为评估者。
通过抽样并将评估者的评估与我的评估进行比较，我可以说我的评估者的准确率为 79%。
在评估我的评估者之后，我希望它评估包含 5421 个项目的整个数据集。我的评估者评估成功率为 87.12%。
我对这个结果有多大信心？是否有可能计算出它的置信区间？如何计算？
注意：我是统计学新手，如果这个问题之前已经回答过，请原谅。我发现很难理解一些现有的问题和答案。请保持你的答案简单。]]></description>
      <guid>https://stats.stackexchange.com/questions/658562/how-to-compute-a-confidence-interval-with-an-inaccurate-evaluator</guid>
      <pubDate>Wed, 11 Dec 2024 08:23:24 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用多元线性回归来隔离每个独立变量的影响吗？</title>
      <link>https://stats.stackexchange.com/questions/658560/can-i-isolate-the-effect-of-each-independent-variable-by-using-multiple-linear-r</link>
      <description><![CDATA[我用python对因变量Y和自变量（预测变量）X1和X2进行了多元线性回归。
它们都是时间序列数据，我用MLR的结果重建了Y时间序列。
重建的Y = b1 * X1 + b2 * X2 +残差
那么，我可以通过排除另一个变量来隔离每个独立变量的影响吗？例如，Y&#39; = b1 * X1。（系数值来自使用X1和X2的MLR。）
这合理吗？我想逐一查看X1或X2的影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/658560/can-i-isolate-the-effect-of-each-independent-variable-by-using-multiple-linear-r</guid>
      <pubDate>Wed, 11 Dec 2024 07:36:29 GMT</pubDate>
    </item>
    <item>
      <title>GAM 回归：相互作用与主效应？</title>
      <link>https://stats.stackexchange.com/questions/658558/gam-regression-interactions-vs-main-effects</link>
      <description><![CDATA[我有一个 GAM 回归模型（响应介于 0 和 1 之间）：
$$ g(\mathbb{E}[Y_i]) = \beta_0 + f_1(t_i, x1_i) + f_2(t_i, x2_i) $$

$g(\cdot)$ 是 logit 链接函数 $g(p) = \log(\frac{p}{1-p})$
$Y_i$ 是 Beta 分布：$Y_i \sim \text{Beta}(\alpha, \beta) $
$\beta_0$ 是截距
$f_1$ 和 $f_2$ 是以下相互作用的平滑函数：($t$ 和 $x_1$)
和 ($t$ 和 $x_2$)

以下是该模型的 R 代码：
library(mgcv)
gam_model &lt;- gam(
y_scaled ~ te(t, x1) + te(t, x2),
data = sim_data,
family = betar(link = &quot;logit&quot;)，
方法 = &quot;REML&quot;
)

我的主要兴趣是研究$X_1$对$Y$的影响以及$X_2$对$Y$在不同时间段的影响。
从这个模型来看，在我看来，这个模型中只有交互效应。
根据这个讨论，在我看来这可能是一个问题，似乎不建议使用包含交互但不包含主效应的回归模型：
在模型中包含交互但不包含主效应模型。
但当我尝试阅读有关 te 函数的更多信息时，例如 https://r.qcbs.ca/workshop08/book-en/changing-the-basis-function.html ，它指出：

当变量不在同一尺度上，并且交互作用包括主效应时，函数 te() 很有用。函数 ti() 最适合
对不包含主效应的交互曲面进行建模。

这让我感到疑惑：

在 GAM 回归中，如果包含交互，是否也必须包含主效应？
R 中的 mgcv::te() 函数是否默认在模型中包含交互和主效应？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658558/gam-regression-interactions-vs-main-effects</guid>
      <pubDate>Wed, 11 Dec 2024 04:12:36 GMT</pubDate>
    </item>
    <item>
      <title>glmnet多任务回归优化问题中的下标“F”定义什么？</title>
      <link>https://stats.stackexchange.com/questions/658556/what-does-the-subscript-f-in-the-glmnet-multi-task-regression-optimization-pro</link>
      <description><![CDATA[我计划使用 ElasticNet 多目标回归的 glmnet 实现。我正在检查文档，以便在我正在撰写的手稿中准确描述该技术。
ElasticNet 模型的优化问题定义为：
$
\min_{(\beta_0, \beta) \in \mathbb{R}^{(p+1) \times K}} \frac{1}{2N} \sum_{i=1}^N \|y_i - \beta_0 - \beta^T x_i\|_F^2 + \lambda \left[ (1 - \alpha) \frac{\|\beta\|_F^2}{2} + \alpha \sum_{j=1}^p \|\beta_j\|_2 \right]
$
这是glmnet 文章，我在该文章中获得了该定义。
下标“F”表示什么？它出现在 L2 正则化项和 MSE 项的定义中。]]></description>
      <guid>https://stats.stackexchange.com/questions/658556/what-does-the-subscript-f-in-the-glmnet-multi-task-regression-optimization-pro</guid>
      <pubDate>Wed, 11 Dec 2024 02:29:06 GMT</pubDate>
    </item>
    <item>
      <title>处理具有大量缺失值的特征</title>
      <link>https://stats.stackexchange.com/questions/658555/handling-a-very-informative-feature-with-significant-missing-values</link>
      <description><![CDATA[我有一个机器学习模型，其目标是在回归背景下进行预测。
对于我感兴趣的指标，有一个特征非常有用，但有显著的缺失值。仅使用此特征的简单变换来计算指标会产生非常好的结果，因此将其合并到模型中会产生很好的结果。
但是，此功能仅适用于上个月的最近观察结果，数据集可以追溯到几年前。此功能有接近 98% 的缺失值，但不是随机缺失的 - 它只是在上个月之前没有收集到。
关于如何处理此设置，有什么想法？
我正在考虑是仅使用一个月的数据对该特征进行训练，还是排除该特征并使用完整（大得多）的数据集。但这感觉像是两个极端，应该有更好的方法来整合这两种信息来源。
编辑：为了简化设置，我们假设缺失的特征是$Z = Y + \epsilon$，所以我们可以将其视为结果的嘈杂版本。在模型中包含$Z$当然对于预测$Y$非常有用，但我们只观察到$Z$约占数据集的2％。
半监督学习的文献允许缺少标签，并提出了整合这些数据以提高下游监督学习任务性能的方法。有没有办法在缺少关键特征的情况下使用类似的逻辑？]]></description>
      <guid>https://stats.stackexchange.com/questions/658555/handling-a-very-informative-feature-with-significant-missing-values</guid>
      <pubDate>Wed, 11 Dec 2024 02:22:20 GMT</pubDate>
    </item>
    <item>
      <title>这是否意味着在正态线性回归中使用夹心估计量我们不需要正态假设？</title>
      <link>https://stats.stackexchange.com/questions/658539/does-it-mean-that-we-dont-need-a-normal-assumption-for-using-sandwich-estimator</link>
      <description><![CDATA[根据这篇文章，

博主使用估计方程理论构建了稳健夹层方差估计量。
在这篇文章中，它说：

现在我们可以开始应用估计方程理论了。首先，在某些规律性条件下，理论表明，当样本大小 n 趋向于无穷大时，估计量 $\hat{\beta}$ 的分布会收敛到 (多元) 正态分布。重要的是，无论误差 $\epsilon=Y-X^{T}\beta$ 是否呈正态分布，也无论它们是否具有恒定方差，这都是成立的。
这是否意味着我们在正态线性回归中使用夹层估计量不需要正态假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/658539/does-it-mean-that-we-dont-need-a-normal-assumption-for-using-sandwich-estimator</guid>
      <pubDate>Tue, 10 Dec 2024 18:27:17 GMT</pubDate>
    </item>
    <item>
      <title>逻辑链接的边际效应是否也在 0-1 之间？</title>
      <link>https://stats.stackexchange.com/questions/658530/will-marginal-effects-for-a-logit-link-also-be-between-0-1</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658530/will-marginal-effects-for-a-logit-link-also-be-between-0-1</guid>
      <pubDate>Tue, 10 Dec 2024 16:00:11 GMT</pubDate>
    </item>
    <item>
      <title>如何排列 p 值？</title>
      <link>https://stats.stackexchange.com/questions/658523/how-to-permute-p-values</link>
      <description><![CDATA[最近，我的同事在处理一个数据集 df_a 时遇到了一个问题，该数据集包含基因数据。每一行代表一个 基因（通常有数千个，但为了简单起见，我们假设有 1,000 个），列代表不同的样本，这些样本可以分为两组，A 和 B（每组 50 个样本）。
我们使用 t.test 计算每行的 p 值并进行校正。假设我们使用 p.adjust &lt; 0.05 并且得到 30 个阳性结果。
这带来了一个问题：我们如何确保这 30 个结果不是由随机事件产生的？（也许这个问题是一个问题？）
我们设计了一个使用置换检验的流程来解决这个问题。步骤如下：
(1) 对于 df_a，我们随机打乱其列标签，重新计算每行的 p 值和 p.adjust，并计算 p.adjust &lt; 0.05 的行数，记为 Ki。
(2) 重复步骤 1 1,000 次，得到 K1,K2,K3,...,K1000。
(3) 计算大于 30 的 Ki 的数量，记为 n。计算 n/1000。如果该值小于 0.05，我们认为这 30 个结果不是由随机事件产生的。
作为一名程序员，我意识到这在数学上似乎存在问题，但我无法向同事提供严谨的证明来纠正它。希望得到您的帮助。
更新
我想更新的是，我认为这种排列不能提供有意义的附加信息。考虑一下当您对列标签进行混洗时，对于每一行，这相当于将组 A 和 B 混合在一起，然后随机抽取两组 A* 和 B*。基本的统计学原理告诉我们，这两组之间应该没有差异。因此，当您应用 t.test 时，所有 p.values &lt; 0.05 都是假阳性，显著性数字约为 5%。当你对这些数据应用p.adjust（例如使用FDR），并再次控制p.adjust &lt; 0.05时，这里的Ki会非常小（接近于0），以至于不可能否定任何结果。
我不是数学家，但通过程序模拟很容易看出这一点。我的观点是，当排列数是有限的（例如：1000）时，Ki的数学期望是一个与数据行相关的常数，并且这个值非常小。
我不知道这在数学上是否成立，以及如何证明它。]]></description>
      <guid>https://stats.stackexchange.com/questions/658523/how-to-permute-p-values</guid>
      <pubDate>Tue, 10 Dec 2024 14:31:46 GMT</pubDate>
    </item>
    <item>
      <title>如何理解一致中心极限定理</title>
      <link>https://stats.stackexchange.com/questions/658487/how-to-understand-the-uniform-central-limit-theorem</link>
      <description><![CDATA[在 Nickl 的一篇 论文 中，我发现了一个具有中心极限定理形式的定理（定理 4）
$$\sqrt{n}(P_n-P)\rightarrow G$$
在 $l^\infty(F)$ 中，其中 $P$ 是 $\mathbb{R}$ 上的一条定律，$F$ 是一类函数，$G$ 是高斯过程由 $f\in F$ 索引。但我熟悉的中心极限定理的形式为：
$$\sqrt{n}(f_n-f)\rightarrow G$$
其中 $G$ 由 $x\in\mathbb{R}$ 索引。
我正在寻求帮助以理解第一个版本，也想知道是否可以将其转换为第二个版本？在第二个版本中要求 $f\in F$ 是否正确？非常感谢任何提示！]]></description>
      <guid>https://stats.stackexchange.com/questions/658487/how-to-understand-the-uniform-central-limit-theorem</guid>
      <pubDate>Mon, 09 Dec 2024 13:32:48 GMT</pubDate>
    </item>
    <item>
      <title>如何从 softmax 输出计算没有基本事实的模型的置信度和不确定性？</title>
      <link>https://stats.stackexchange.com/questions/658468/how-to-compute-confidence-and-uncertainity-of-model-without-ground-truth-from-so</link>
      <description><![CDATA[假设我有 3 个类 A、B、C。
执行：
y_pred = model.predict(X) # 假设 X 只有两个样本

返回长度为 2 的向量，即形状 (2,3)，仍为概率格式（无 argmax）。
y_pred -&gt; [
{A:0.2, B:0.3, C:0.5}, 
{A:0.7, B:0.2, C:0.1}
]

我将定义模型，而不是置信度，即模型预测的类返回置信度值更接近 1/N，其中 N 是类的数量（因为它既不是真也不是假，它不是断言假即零，也不是断言真即一）。但也许，还有另一个比我的更好的定义。我仍然希望它返回不确定性和置信度的标量值。
如果我的定义是最好的，那么我想使用我的定义将模型预测的总体置信度摘要转换为标量值。
那么，有什么操作或聚合技术可以获取预测的置信度和不确定性，其幅度范围为$[0,1]$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658468/how-to-compute-confidence-and-uncertainity-of-model-without-ground-truth-from-so</guid>
      <pubDate>Mon, 09 Dec 2024 02:06:41 GMT</pubDate>
    </item>
    <item>
      <title>标准化回归模型的变量与回归模型中的权重？</title>
      <link>https://stats.stackexchange.com/questions/658437/standardizing-variables-for-a-regression-model-vs-weights-in-a-regression-model</link>
      <description><![CDATA[我在 R 中有一个纵向 GAM（一般加性模型）回归。
这是模型和数据的一般形式（响应介于 0 和 1 之间）。所有变量均在州一级计算（例如州 GDP、州内疾病率）：
gam_model &lt;- gam(
response ~ 
te(time_var, var1) +
te(time_var, var2) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

state time_varpopulation var1 var2 response
state_1 2005-01-01 1000000 500000 10000 0.45
state_1 2005-02-01 1001000 520000 12000 0.47
state_1 2005-03-01 1002001 540000 11000 0.46
state_1 2005-04-01 1003002 560000 13000 0.48
state_2 2005-01-01 200000 100000 2000 0.42
state_2 2005-02-01 200200 105000 2400 0.44
state_2 2005-03-01 200400 110000 2200 0.43
state_2 2005-04-01 200600 115000 2600 0.45

这里是我遇到的问题：

数据按州提供（多个州，1 个国家），但每个州的人口不同
这让我认为需要对模型进行一些处理，以防止人口较多的州对响应产生比人口较少的州更大的影响
我有每个州的人口

我正在考虑使用以下权重公式（我从这里得到这个想法https://www.nature.com/articles/s41598-024-54441-x）：
$$avg\_weight_s = \frac{1}{T}\sum_{t=1}^{T} \frac{\ln(population_{s,t})}{\frac{1}{N}\sum_{i=1}^{N} \ln(population_{i,t})}$$
其中：

$T$ 是时间段的总数
$N$ 是州的总数
$population_{s,t}$ 是 $t$ 时刻 $s$ 州的人口数
$population_{i,t}$ 表示每个州 $i$ 在时间 $t$ 的人口
请注意，尽管我为每个州设置了多个时间点...但每个州都只有一个权重（将始终使用）。我只是想重申这一点。

这让我考虑不同的模型选项：
# 选项 1：非标准化，无权重

gam_model &lt;- gam(
response ~ 
te(time_var, var1) +
te(time_var, var2) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

# 选项 2：标准化，无权重

gam_model &lt;- gam(
response ~ 
te(time_var, var1/population) +
te(time_var, var2/population) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

# 选项 3：非标准化，权重

gam_model &lt;- gam(
response ~ 
te(time_var, var1) +
te(time_var, var2) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
weights = avg_weight,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

# 选项 4：标准化，权重

gam_model &lt;- gam(
response ~ 
te(time_var, var1/population) +
te(time_var, var2/population) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
weights = avg_weight,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

我有点困惑，不知道这些选项中哪一个在逻辑上是正确的。我认为其中一些可能有点过头了，而另一些则完全不正确。有办法解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658437/standardizing-variables-for-a-regression-model-vs-weights-in-a-regression-model</guid>
      <pubDate>Sun, 08 Dec 2024 04:38:44 GMT</pubDate>
    </item>
    </channel>
</rss>