<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 22 Jan 2025 03:19:53 GMT</lastBuildDate>
    <item>
      <title>我可以在显性分析中使用虚拟交互变量吗？如何解释交互的结果？</title>
      <link>https://stats.stackexchange.com/questions/660354/can-i-use-dummy-interaction-variables-in-dominance-analysis-how-to-interpret-th</link>
      <description><![CDATA[我目前正在进行一项研究，研究社会经济因素和金融包容性如何影响家庭层面的清洁水和卫生设施的获取。以下是我使用的变量列表：
因变量：

改善水质
改善卫生设施
（它们是虚拟变量，1=改善，0=未改善）

自变量：

储蓄（虚拟变量，hhh 是否有储蓄）
信贷（虚拟变量，hhh 户主是否有信贷）
发展区域（虚拟变量，家庭是否居住在快速发展的地区）
4-9。社会经济因素（女性、家庭规模、城市等）

在本研究中，我想了解基于发展区域的金融包容性如何影响两种访问。因此，我将金融包容性的 2 个独立变量与发展区域进行交互，这样就有了 2 个新变量：
10. 储蓄发展状态
11. 信贷发展状态
我的讲师建议查看每个变量的贡献/主导性，所以我需要进行主导性分析。但我很困惑，如果模型中有交互变量，这种分析是否是一种好方法？如果可能，我该如何解释结果？
例如，如果储蓄*发展的标准化主导性分析为 12%，在 15 个变量中排名第 5，这意味着什么？与没有交互的单独储蓄变量排名有什么区别？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/660354/can-i-use-dummy-interaction-variables-in-dominance-analysis-how-to-interpret-th</guid>
      <pubDate>Wed, 22 Jan 2025 03:18:54 GMT</pubDate>
    </item>
    <item>
      <title>处理 glm.nb 模型中的残差分析</title>
      <link>https://stats.stackexchange.com/questions/660349/deal-with-residual-analysis-in-glm-nb-models</link>
      <description><![CDATA[我有以下数据框，代表一个物种的丰度、所有物种的总丰度以及每株植物存在的物种数量
&#39;data.frame&#39;: 474 obs. 5 个变量中的 5 个：
$ 年份：因子，具有 2 个水平“2016”，“2023”：2 2 2 2 2 2 2 2 2 2 ...
$ Tot_O_nubilalis_plant：数字 13 13 13 11 11 11 5 5 5 12 ...
$ Tot_individuals_plant：数字 20 20 20 21 21 21 11 11 11 23 ...
$ N_species_plant：因子，具有 4 个水平“0”、“1”、“2”、“3”：3 3 3 4 4 4 4 4 4 3 ...
$ Gregariousness_O_nubilalis_plant：具有 4 个水平“Doubleton”、“Four or more”的因子，...：2 2 2 2 2 2 2 2 2 2 ...

由于我正在处理计数数据，因此我选择使用以下模型。我首先尝试仅对数据子集（仅 2023 年）进行测试
glm_nb_model &lt;- glm.nb(Tot_O_nubilalis_plant ~ Tot_individuals_plant + 
N_species_plant + Gregariousness_O_nubilalis_plant , 
data = data_unique, 
control = glm.control(maxit = 100))

结果如下：
调用：
glm.nb(formula = Tot_O_nubilalis_plant ~ Tot_individuals_plant + 
N_species_plant + Gregariousness_O_nubilalis_plant, data = data_unique, 
control = glm.control(maxit = 100), init.theta = 43.81661505, 
link = log)

系数：
估计标准差。误差 z 值
（截距） 0.614298 0.723111 0.850
Tot_individuals_plant 0.039424 0.004091 9.638
N_species_plant2 -0.252128 0.769732 -0.328
N_species_plant3 -0.437599 0.763584 -0.573
Gregariousness_O_nubilalis_plant四个或更多 1.092309 0.247407 4.415
Gregariousness_O_nubilalis_plantSingleton -0.599964 0.519276 -1.155
Gregariousness_O_nubilalis_plantTripleton 0.398485 0.297288 1.340
Pr(&gt;|z|) 
(截距) 0.396 
Tot_individuals_plant &lt; 2e-16 ***
N_species_plant2 0.743 
N_species_plant3 0.567 
Gregariousness_O_nubilalis_plantFour 或更多 1.01e-05 ***
Gregariousness_O_nubilalis_plantSingleton 0.248 
Gregariousness_O_nubilalis_plantTripleton 0.180 
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（负二项分布（43.8166）系列的分散参数取为 1）

零偏差：145 个自由度上的 354.94
残差偏差：139 个自由度上的 113.19
（12 个观察值消除了价值损失的原因）
AIC：690.41

Fisher 评分迭代次数：1

Theta：43.8
标准差。错误：28.7 

2 x 对数似然：-674.412 

残差分析对我来说也相当不错：

当我包含 2016 年的数据（或仅分析 2016 年的数据）时，我无法获得如此好的残差分析。我确实认为问题在于数据在不同年份的分布不同（见图）。2016 年，我有许多采样植物没有个体。
我尝试了许多其他模型和数据转换，但没有得到好的结果。如何处理残差分析问题？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660349/deal-with-residual-analysis-in-glm-nb-models</guid>
      <pubDate>Tue, 21 Jan 2025 22:54:50 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中计算样本 IACF</title>
      <link>https://stats.stackexchange.com/questions/660348/computing-the-sample-iacf-in-r</link>
      <description><![CDATA[有谁知道可以计算样本 IACF（逆自相关函数）图的 R 包吗？我觉得这很难获得，这很奇怪。]]></description>
      <guid>https://stats.stackexchange.com/questions/660348/computing-the-sample-iacf-in-r</guid>
      <pubDate>Tue, 21 Jan 2025 22:35:48 GMT</pubDate>
    </item>
    <item>
      <title>给定时间序列数据集中，输出与输入相比时间偏移不规则</title>
      <link>https://stats.stackexchange.com/questions/660346/irregular-time-shifts-of-output-compared-to-inputs-in-given-time-series-data-set</link>
      <description><![CDATA[我有一些具有多个特征的时间序列数据。输出发生了偏移（我的意思是，输出值与相应输入偏移的时间是不规则的）。我对偏移量有一些了解，但并不准确。有没有办法使用长短期记忆 (LSTM) 神经网络来考虑这些不规则的偏移？或者在训练 LSTM 模型之前可以进行任何预处理。]]></description>
      <guid>https://stats.stackexchange.com/questions/660346/irregular-time-shifts-of-output-compared-to-inputs-in-given-time-series-data-set</guid>
      <pubDate>Tue, 21 Jan 2025 21:56:41 GMT</pubDate>
    </item>
    <item>
      <title>确保回归参数估计值始终为正</title>
      <link>https://stats.stackexchange.com/questions/660343/making-sure-that-a-regression-parameter-estimate-is-always-positive</link>
      <description><![CDATA[我有兴趣了解如何完成以下任务：

假设我有两个变量 $X_t$ 和 $Y_t$ 的月度数据。我有兴趣为 $Y_t$ 创建一个 ARIMAX 模型，该模型依赖于 $Y_t$ 和 $X_t$ 的旧版本。我可以像这样编写基本的 ARIMAX 模型：
$$ y_t = c + \phi_1y_{t-1} + \beta x_t + \epsilon_t $$
但是，我希望此模型具有以下属性：假设其他所有条件都相同，$X_t$ 的较大值必须产生 $Y_t$ 的较大值，而 $X_t$ 的较小值则不能产生。从数学上讲，我认为这可以理解为 $\beta$ 必须始终为正。我希望模型尊重这一事实。
$$ \frac{\partial y_t}{\partial x_t} = \beta &gt; 0 $$
$$ y_t = c + \phi_1y_{t-1} + \beta x_t + \epsilon_t $$
$$ \text{subject to: } \beta &gt; 0 $$
我想知道我们如何在模型中强制执行这一点。我天真地想到了两种方法：


基本约束：我不确定如何为这个 ARIMAX 模型写出基本可能性，但它应该是这样的：

$$ L(c, \phi_1, \beta|\textbf{y},\textbf{x}) $$
如果我希望 $\beta$ 为正，我应该能够写出一个受约束的可能性并使用拉格朗日函数来解决这个问题：
$$ \log L(c, \phi_1, \beta|\textbf{y},\textbf{x}) $$
$$ \beta \geq \epsilon $$
$$ \mathcal{L} = \log L(c, \phi_1, \beta|\textbf{y},\textbf{x}) + \lambda(\beta - \epsilon) $$

贝叶斯方法：我认为，如果我策略性地选择先验，我就可以确保 $\beta$ 始终为正。使用贝叶斯原理，我写了联合先验和后验：

$$ P(\theta) = P(\beta)P(c)P(\phi_1)P(\sigma^2) $$
$$ P(\theta|\textbf{y},\textbf{x}) = \frac{L(\theta|\textbf{y},\textbf{x})P(\theta)}{\int L(\theta|\textbf{y},\textbf{x})P(\theta)d\theta} $$
然后在$\beta$上，我可以放置一个先验，例如半正态（https://en.wikipedia.org/wiki/Half-normal_distribution) 以确保正性，但我不确定要使用哪些其他分布作为其他参数的先验。我认为 $\sigma^2$ 上的先验也需要是具有正支持的分布，因为方差不能为负。

我不确定这些方法是否可行且合乎逻辑。社区能否就此提供一些建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/660343/making-sure-that-a-regression-parameter-estimate-is-always-positive</guid>
      <pubDate>Tue, 21 Jan 2025 21:16:28 GMT</pubDate>
    </item>
    <item>
      <title>具有季节性的时间序列中的重复水平转变</title>
      <link>https://stats.stackexchange.com/questions/660342/recurring-level-shift-in-time-series-with-seasonality</link>
      <description><![CDATA[我有一个时间序列，它表现出强烈而可靠的季节性模式。X-13 很好地识别了季节性模式，除 1 月外，拟合度相当平滑。时间序列对应于每年根据外部指数调整的数据。调整以零为底，但实际调整是两个变量的乘积，一个变量是提前知道的，并以零为底，另一个变量是不可观察的，但已知它落在静态范围内（例如 0.05 到 0.15）。有人知道如何解释这种水平转变以提高季节性调整的准确性吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660342/recurring-level-shift-in-time-series-with-seasonality</guid>
      <pubDate>Tue, 21 Jan 2025 20:51:37 GMT</pubDate>
    </item>
    <item>
      <title>N=2 个样本的 Welch t 检验 p 值的潜在精确解</title>
      <link>https://stats.stackexchange.com/questions/660339/potential-exact-solution-to-welch-t-test-p-values-for-n-2-samples</link>
      <description><![CDATA[前段时间，我发帖称现有软件包（例如 scipy.stats.ttest_ind 和 equal_var=False）仅给出了 Welch t 检验的 p 值的近似结果，特别是对于 $N=2$ 样本。我认为我已经找到了一种贝叶斯方法，该方法在假设均值的先验均匀和 Jeffery 对正态分布的标准差$\sigma$的先验均匀的情况下，可以产生相对容易计算的检验，但我希望在完成这一推理时能得到反馈。
考虑从两个正态分布$x_1, x_2\sim \mathcal{N}(\mu_x, \sigma_x)$和$y_1, y_2\sim \mathcal{N}(\mu_y, \sigma_y)$中各抽取两个样本。如果我们对 $\mu_x, \mu_y$ 使用均匀先验，对 $\sigma_x^2,\sigma_y^2$ 使用 Jeffery 先验，这样 $p(\mu, \sigma^2) \propto 1/\sigma^2$，则 $\mu_x$ 的边际后验分布（在 $\sigma_x$ 上积分后）是 $N=2$ 的柯西分布，
$$P(\mu_x | x_1, x_2) = \mathrm{Cauchy}\left(\bar x, d_x\right) $$
对于 $P(\mu_y|y_1, y_2)$ 也类似，其中 $\bar x = \frac{x_1+x_2}{2}$ 和 $d_x = \frac{|x_1-x_2|}{2}$。要执行单侧检验 $\mu_x&gt;\mu_y$，我们可以直接对 $\mu_x &gt; 的这些概率进行积分\mu_y$，所以
$$P(\mu_x &gt; \mu_y|x_1,x_2,y_1,y_2) = \int_{\mu_y&gt;\mu_x} P(\mu_x|x_1, x_2) P(\mu_y | y_1, y_2) = \frac{1}{2} + \frac{1}{\pi}\arctan \left( \frac{\bar x - \bar y}{d_x + d_y} \right)$$
是的，chatgpt 帮助了积分和数学。我可以将其解释为建议检验统计量吗？
$$S=\frac{\bar x-\bar y}{d_x + d_y}$$
在零假设 $\mu_x &gt; \mu_y$ 下，考虑单侧贝叶斯后验概率 $p=\frac{1}{2} + \frac{1}{\pi} \arctan S$ 是否合理？如果 $p &lt; \alpha$ 为典型 $\alpha=0.05$，声称显著性是否合适？如果是这样，这似乎是一个相当简单的表达式。从评论和答案中，我意识到我不应该将其称为适当的 p 值，但我想知道的是它是否是一个合法的统计检验。
编辑：重写了核心问题，使检验统计量和零假设更加清晰，清理了一些表达式，在此过程中学习了更多统计学知识。]]></description>
      <guid>https://stats.stackexchange.com/questions/660339/potential-exact-solution-to-welch-t-test-p-values-for-n-2-samples</guid>
      <pubDate>Tue, 21 Jan 2025 20:16:04 GMT</pubDate>
    </item>
    <item>
      <title>如何比较组内前后的比例？</title>
      <link>https://stats.stackexchange.com/questions/660338/how-to-compare-proportions-for-before-after-within-groups</link>
      <description><![CDATA[我有 4 个阵列，每个阵列有多个站点，我们在每个阵列的 100 个点中收集了主要基质类型（SS 或 LL）。因此，我在每个站点内标记为每种基质的 100 个点中都有一定比例。
我们进行了两次此测试（一次在 1990 年代，一次是今年）。我想测试每个阵列（多个站点）中每种土壤类型的比例在不同年份（1990 年代与今天）之间是否不同。考虑到我们每个阵列内都有成对（前后站点），我不确定我是否应该使用卡方检验或其他方法？
感谢您的帮助



数组
站点
基底
percsub
时间




AC
1
LL
0.6
今天


AC
1
SS
0.4
今天


AC
2
LL
0.6
今天


AC
2
SS
0.4
今天


AC
3
LL
0. 7
今天


AC
3
SS
0.1
今天


LC
5
LL
0.91
今天


LC
8
LL
0.84
至天


LC
8
SS
0.1
今天


LC
14
LL
0.94
今天


LC
15
LL
0.87
今天


LC
16
LL
0.89
今天


LC
17
LL
0.84
今天


LC
17
SS
0.15
今天


SJHW
14
LL
0.95
今天


SJHW
14
SS
0.05
今天


SJHW
16
LL
0.77
今天


SJHW
16
SS
0.23
今天


SJHW
17
LL
0.91
今天


SJHW
17
SS
0.08
今天


WC 
11
LL
0.58
今天


WC
11
SS
0.37
今天


WC
12
LL
0.6
今天


WC
 12
SS
0.38
今天


AC
1
LL
0.7
1990 年代


AC
1
SS
0.3
1990 年代


AC
2
LL 
0.39
1990 年代


AC
2
SS
0.61
1990 年代


AC
3
LL
0.25
1990 年代


AC
3
SS
0. 75
1990 年代


LC
5
LL
0.35
1990 年代


LC
8
LL
0.59
1990 年代


LC
8
SS
0.38
 1990 年代


LC
14
LL
0.6
1990 年代


LC
15
LL
0.39
1990 年代


LC
16
LL
0.5
1990 年代


LC
17
LL
0.63
1990 年代


LC
17
SS
0.3
1990 年代


SJHW
14
LL
0.87
1990 年代


SJHW
14
SS
0.13
1990 年代


SJHW
16
LL
0.71
1990 年代


SJHW
16
SS
0.29
1990 年代


SJHW
17
LL
0.8
1990 年代


SJHW
17
SS
0.13
1990 年代


WC
11
LL
0.46
1990 年代


WC 
11
SS
0.4
1990 年代


WC
12
LL
0.49
1990 年代


WC
12
SS
0.2
1990 年代


]]></description>
      <guid>https://stats.stackexchange.com/questions/660338/how-to-compare-proportions-for-before-after-within-groups</guid>
      <pubDate>Tue, 21 Jan 2025 19:43:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么 GEV 拟合有时不能很好地拟合尾部？</title>
      <link>https://stats.stackexchange.com/questions/660337/why-does-gev-fit-sometimes-not-fit-the-tails-well</link>
      <description><![CDATA[我正在使用每 1 分钟采样一次的约 20 年数据进行广义极值分析。我这样做是为了预测回报水平，例如 1/50 和 1/100 间隔。数据是这样的，独立的极端事件可能至少相隔 10-15 天。因此，我希望使用约 10 天的区块长度，因为（对我而言）这最有意义。
但是，当我使用 10 天的区块长度时，结果在视觉上很糟糕，尤其是在尾部：

但是，如果我使用 50 天的区块长度，那么拟合度会显著提高（视觉上）：

为什么使用 10 天区块长度时拟合度这么差？]]></description>
      <guid>https://stats.stackexchange.com/questions/660337/why-does-gev-fit-sometimes-not-fit-the-tails-well</guid>
      <pubDate>Tue, 21 Jan 2025 19:14:44 GMT</pubDate>
    </item>
    <item>
      <title>选择统计方法来分析前后试验中具有多重共线性的计数资料</title>
      <link>https://stats.stackexchange.com/questions/660328/choosing-statistical-methods-for-analyzing-count-data-with-multicollinearity-in</link>
      <description><![CDATA[我正在对一个数据集进行统计分析，以确定药物 Progabide 是否能减少癫痫发作。该数据集包括 59 名患者：安慰剂组 28 名，Progabide 组 31 名。我的目标是比较治疗后的癫痫发作次数（“计数”），考虑基线癫痫发作频率（“Base”）和年龄（“Age”）。
本研究的目的是确定药物 Progabide 是否能有效减少癫痫发作的频率。具体来说，目标是比较 Progabide 组和安慰剂组治疗后的癫痫发作次数（“计数”），同时考虑基线癫痫发作频率（“Base”）和其他特征，如年龄（“Age”）。
下面是我正在处理的数据集的片段；还有两个标准化版本的变量 Age 和 Base。



ID
年龄
基数
Trt
患者
访问
计数
观察
zAge
zBase




1
31
11
0
1
1
5
1
0.42499501
-0.757172825


2
30
11
0
2
1
3
2
0.26528351
-0.757172825


3
25
6
0
3
1
2
3
-0.53327400
-0.944403322



最初，我进行了双变量分析。我计算了“基础”、“年龄”、“计数”和得出的前后差异之间的相关性。对于这些变量，我检查了它们的整体分布和治疗组分布。使用 Shapiro-Wilk 检验，我发现没有一个分布符合正态性假设，这导致我依赖非参数方法（Mann-Whitney U 检验、中位数零值检验）进行组比较。我还使用了 Wilcox 检验来检验中位数=0 的假设并得出置信区间。
由于我只有两组治疗，所以我没有使用 ANOVA 来比较两组的平均值。
对于建模，我首先使用了 ANCOVA 模型，不包括可变的“年龄”：
$$
\text{Count}_{ij} = \beta_0 + \beta_1 \text{Base}_i + \beta_2 \text{Trt}_i + \epsilon_{ij},
$$
然后我扩展了这个模型以包括“Base”之间的交互项和“Trt”：
$$
\text{Count}_{ij} = \beta_0 + \beta_1 \text{Base}_i + \beta_2 \text{Trt}_i + \beta_3 (\text{Base}_i \cdot \text{Trt}_i) + \epsilon_{ij}。
$$
在两个模型中，残差均不呈正态分布（两个 shapiro p 值均小于 0.001）。
给定“Count”是一个计数变量，我考虑了泊松回归：
$$
\log(\text{Count}_{ij}) = \beta_0 + \beta_1 \text{Base}_i + \beta_2 \text{Age}_i + \beta_3 \text{Trt}_i。
$$
但是，强相关性，特别是“Base”和“Count”之间的相关性，引发了对多重共线性的担忧。
我的主要问题是：

我采取的步骤（双变量分析、ANCOVA 和 Poisson GLM）是否适合此数据集和研究问题？如果不适合，您会推荐哪些替代方法？
我应该如何处理 ANCOVA 模型中的非正态残差？转换或替代模型是否更合适？
考虑到多重共线性以及变量之间存在强相关性的事实，表明它们之间存在线性关系。应用泊松 GLM 是否有意义？
由于我只有两个测量值（计数和基数），重复测量方差分析是否适用？

我很感激任何指导或建议。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660328/choosing-statistical-methods-for-analyzing-count-data-with-multicollinearity-in</guid>
      <pubDate>Tue, 21 Jan 2025 16:51:01 GMT</pubDate>
    </item>
    <item>
      <title>测试一系列点偏离给定线/水平的概率/重要性</title>
      <link>https://stats.stackexchange.com/questions/660269/test-the-probability-significance-that-a-sequence-of-points-will-deviate-from-a</link>
      <description><![CDATA[我想评估后续$n$ 个点（总共 $N$ 个）偏离（即其误差线不涵盖）某个任意水平/线/模型/等的概率（或者，更好的是，如果发生这种情况，其重要性）。在下面的草图中，用红色圈出的三个连续点偏离了蓝色水平/线。在这里，连续性至关重要，我对其他两个偏离点（紫色框中）不感兴趣。
我可能会天真地根据二项分布得出某些东西，但我想知道

是否有一些（或多或少复杂的）机制、统计工具、实现或类似的东西可以解决这个问题，并且
考虑这种序列作为偏差的重要性是否可能/有意义？

请注意，我不想对黑点进行任何拟合 - 我只想判断一些离散点集与预定义的任意线（无论这条线是什么）偏离的概率/重要性。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660269/test-the-probability-significance-that-a-sequence-of-points-will-deviate-from-a</guid>
      <pubDate>Mon, 20 Jan 2025 12:51:52 GMT</pubDate>
    </item>
    <item>
      <title>可逆跳跃 MCMC 中与状态无关的跳跃的接受概率</title>
      <link>https://stats.stackexchange.com/questions/660249/acceptance-probability-in-reversible-jump-mcmc-for-state-independent-jumps</link>
      <description><![CDATA[在可逆跳跃 MCMC 中，从 $\mathbf{x}^p$（在模型 $k$ 中）跳跃到 $\mathbf{x}^q$（在模型 $k&#39;$ 中）的接受概率为 (reference)
\begin{equation}
\alpha = \text{Min}\bigg[1,\,\frac{p(\mathbf{x}^q,k&#39;|\mathbf{d})\,g&#39;(\mathbf{u}^q)}{p(\mathbf{x}^p,k|\mathbf{d})\,g(\mathbf{u}^p)}\,|J|\bigg]
\end{equation&gt;
其中 $g(\mathbf{u}^p)$ 和 $g&#39;(\mathbf{u}^q)$ 是正向步骤 $\mathbf{x}^p\rightarrow\mathbf{x}^q$ 和相应的反向步骤 $\mathbf{x}^q\rightarrow\mathbf{x}^p$。$\mathbf{J}$ 是变换的雅可比矩阵，
\begin{equation}
|J| = \bigg\vert\frac{\partial(\mathbf{x}^q,\mathbf{u}^q)}{\partial(\mathbf{x}^p,\mathbf{u}^p)}\bigg\vert\;。
\end{equation&gt;
当模型 $k$ 和 $k&#39;$ 之间提出的跳跃与状态无关时，接受概率如何变化？例如，假设我在模型 $k$ 中的点 $\mathbf{x}^p$，我想提出一个跳跃以移动到模型 $k&#39;$。我已经计算了模型 $k&#39;$ 中的 最大后验 (MAP) 解，并估计了模型 $k&#39;$ 中的后验密度的协方差。因此（我认为）模型之间的有效移动将从以具有估计协方差的 MAP 解为中心的多元高斯中抽取。此跳跃与状态无关 - 它不依赖于 $\mathbf{x}^p$。那么，接受概率中的雅可比矩阵的行列式似乎定义不明确。这种跳跃的接受概率是多少？模型 $k$ 或 $k&#39;$ 的维度是否会影响概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/660249/acceptance-probability-in-reversible-jump-mcmc-for-state-independent-jumps</guid>
      <pubDate>Sun, 19 Jan 2025 19:35:41 GMT</pubDate>
    </item>
    <item>
      <title>针对 2 个以上类别的卡方检验（2x5 列联表）</title>
      <link>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</link>
      <description><![CDATA[我有一个 2x5 的频率表，其中有 2 列分别名为男性和女性，5 行分别名为病理 A、B、C、D 和 E。
我想确定不同病理类别的性别比例是否存在统计学差异。
例如：男性是否比女性更频繁地受到病理 A 的影响（每个类别都是如此）？
我是否可以将其他类别（例如 B + C + D + E）相加以创建新的 2x2 列联表并对其进行卡方检验？
这在统计上正确吗？如果我的 p 值小于 0.05，我可以得出的结论是：男性比女性更频繁地受到病理 A 的影响？
问题是，如果我对所有数据计算一次卡方检验，我只能对情况有一个整体了解。

感谢大家的回复。实际上，我的不同类别如下：
列：男性和女性
行：A = 无病理（健康患者），B = β-地中海贫血，C = α-地中海贫血，D = db-地中海贫血，E = 其他。
患者只能属于五个类别之一，因为他们被诊断出患有相同的测试。因此，它们是互斥的。
最初，我创建了 5 个 2x2 列联表，如我在第一篇文章中所述，并将其视为二元变量（如 Rick 所述，存在或不存在），但我不确定我能从中得出什么结论，以及将一些类别组合在一起以评估特定类别的频率在两性之间是否存在显着差异是否在统计上正确。
我不一定想计算比值比，只是想知道根据卡方检验，我的病理分布在男性还是女性中更常见。
感谢您的所有回复。我期待阅读您的结论。
此致，
Adrien]]></description>
      <guid>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</guid>
      <pubDate>Fri, 17 Jan 2025 12:27:50 GMT</pubDate>
    </item>
    <item>
      <title>检查平均值和估计标准差的正确程序</title>
      <link>https://stats.stackexchange.com/questions/660353/correct-procedure-to-check-mean-and-estimate-standard-deviation</link>
      <description><![CDATA[这可能很简单，但我希望确认一下推理过程。
假设 X 是随机变量，并且通过一些理论程序，我们已经找到了它的预期值。假设我们能够执行相当大的模拟来找到 X 的样本。

有什么有效的方法可以用经验数据来检查我们对预期值的理论计算是否正确？

X 标准差的合理估计应该是多少？


大约 1，我可能会这样做。首先，选择一个较大的 N（例如 5000 万），并抽取长度为 N 的 X 样本。由此，我们可以计算样本均值和样本标准差（从样本均值开始，因此使用贝塞尔校正 N-1）。然后，利用 CLT，我们可以使用正态分布（近似 t 分布）计算置信区间（假设置信度为 95%）。这样，我们有 95% 的信心认为预期值将位于区间内。想象一下，一个肯定的答案是不够的，所以这应该重复“很多次”(?)
关于 2：此时，我已经发现了一个标准差，它实际上是有偏差的。但如果在第一点我确信我的预期值的理论竞争是正确的，那么我可以再次计算样本的标准差，这次使用实际预期值，而无需使用贝塞尔校正。
所有这些都是进行我的调查的合理方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660353/correct-procedure-to-check-mean-and-estimate-standard-deviation</guid>
      <pubDate>Mon, 13 Jan 2025 22:46:03 GMT</pubDate>
    </item>
    <item>
      <title>线性回归 - 响应变量为百分比改善或 m/s？</title>
      <link>https://stats.stackexchange.com/questions/659686/linear-regression-response-variable-as-percent-improvement-or-m-s</link>
      <description><![CDATA[我正在尝试对包含 8 种不同跑步距离的数据集进行统计，这些距离在遵循训练方案之前和之后都有时间，并且基于距离对改进进行线性回归（所有完成时间都有所下降）。我不确定是否要转换为百分比改进或使用 m/s 之类的变量，然后减去跑步时间 1 和跑步时间 2，以便能够比较不同的距离组。显然，绝对时间差异并不大，因为更长的距离自然会有更大的改进。但我读到过，不建议将百分比改进转换为线性回归中的响应变量。我该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/659686/linear-regression-response-variable-as-percent-improvement-or-m-s</guid>
      <pubDate>Tue, 07 Jan 2025 21:03:50 GMT</pubDate>
    </item>
    </channel>
</rss>