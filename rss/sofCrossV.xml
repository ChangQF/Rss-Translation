<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 13 Jun 2024 12:28:01 GMT</lastBuildDate>
    <item>
      <title>什么是间接原因联系和共同原因联系？</title>
      <link>https://stats.stackexchange.com/questions/649172/what-are-indirect-and-common-cause-links</link>
      <description><![CDATA[本问题是关于 PCMCI 方法（如 Runge et al 2019 所述）用于查找时间序列数据中的因果关系。
该过程的第二部分称为瞬时条件独立性 (MCI)，涉及对目标（$X^3_t$ 在下面示例中）与其因果父级（$X^1_{ t−2}$）进行独立性测试，以两者的因果父级为条件：

然后，MCI 测试（图 3C）解决了高度相互依赖的时间序列案例的假阳性控制问题：例如，对于测试 $X^1_{t−2} \rightarrow X ^3_{ t}$ ，条件 $ \hat{\mathscr{P}}(X^3_ t )$（图 3B 中的蓝色框）足以建立条件独立性（马尔可夫特性），即识别间接和共同原因链接。

供参考，图 3B 如下：

我对这一部分过程“[识别] 间接和共同原因”的说法感到困惑导致链接”。这是什么意思，这一步是如何实现的？]]></description>
      <guid>https://stats.stackexchange.com/questions/649172/what-are-indirect-and-common-cause-links</guid>
      <pubDate>Thu, 13 Jun 2024 12:19:21 GMT</pubDate>
    </item>
    <item>
      <title>PCA。R 与 Python：主成分的维度？</title>
      <link>https://stats.stackexchange.com/questions/649171/pca-r-vs-python-dimension-of-principal-components</link>
      <description><![CDATA[在 Python 中，PCA 的结果给出一个主成分矩阵，其维度为 (观测值数量 x 特征数量)，而在 R 中则为 (特征数量 x 特征数量)。由于特征值分解基于方差-协方差矩阵，因此 R 结果对我来说直观上更有意义。为什么 R 和 Python 中的结果不同？
示例数据：

# 特征和观测值的数量
num_features &lt;- 10000
num_observations &lt;- 300

# 生成数据矩阵
data &lt;- matrix(rnorm(num_features * num_observations), nrow = num_observations, ncol = num_features)

# 将矩阵转换为数据框
data_principal_components &lt;- as.data.frame(data)

Python：

# 对外生因素的中心化和标准化数据集执行 PCA
pca = PCA()
data_pca = pca.fit_transform(data_principal_components)

# 总结 PCA 结果
explained_variance_ratio = pca.explained_variance_ratio_
cumulative_variance_ratio = np.cumsum(explained_variance_ratio)

R:

set.seed(42)
# 计算相关矩阵
corr_matrix &lt;- cor(data_principal_components, use = &quot;complete.obs&quot;)

# 对相关矩阵执行 PCA
data.pca &lt;- princomp(corr_matrix)

# 总结 PCA 结果
sumpca &lt;- summary(data.pca)

# 计算主成分的累积重要性
importance &lt;- cumsum(sumpca$sdev^2 / sum(sumpca$sdev^2))

# 显示累积重要性
print(importance)
]]></description>
      <guid>https://stats.stackexchange.com/questions/649171/pca-r-vs-python-dimension-of-principal-components</guid>
      <pubDate>Thu, 13 Jun 2024 12:04:46 GMT</pubDate>
    </item>
    <item>
      <title>不平衡面板的差异分析</title>
      <link>https://stats.stackexchange.com/questions/649170/diff-in-diff-with-an-unbalanced-panel</link>
      <description><![CDATA[假设我想使用 diff-in-diff 设置研究某些干预措施的效果。我有一组在某个时期内观察到的单位，我可以识别治疗/非治疗组和前期/后期（假设它是经典的 DID，没有交错干预等）。我的问题是我的面板不平衡 - 对于某些单位，包括那些接受治疗的单位，我没有后期的完整观察结果。我可以仅在平衡样本上估计 DID 模型，或者简单地忽略面板不平衡的事实（我猜这对 Stata xtdidrgress 来说不是问题），但我担心这可能会产生有偏差的结果。由于治疗，可能会从样本中删除单位。例如，如果我研究某些医疗手段对血压的影响，可能会发生这样的情况：由于治疗，一些病人的血压下降，他们不再去看医生，这就是为什么没有对他们进行观察的原因。
在这种情况下我该怎么办？
最好]]></description>
      <guid>https://stats.stackexchange.com/questions/649170/diff-in-diff-with-an-unbalanced-panel</guid>
      <pubDate>Thu, 13 Jun 2024 11:55:30 GMT</pubDate>
    </item>
    <item>
      <title>（冗余）传感器数据的（多变量）异常检测</title>
      <link>https://stats.stackexchange.com/questions/649168/multivariate-anomaly-detection-of-redundant-sensor-data</link>
      <description><![CDATA[我目前正在撰写我的硕士论文，我正在寻找以下情况的一些输入：
我有 2-20 个传感器的数据，它们都在 1-3 个不同位置以 15 分钟为间隔测量相同的变量（=96 次观测/天），因此我预计所有测量值几乎相同（如果位置相同）或相对相似（如果位置不同）。在我的论文中，我介绍了一种方法/算法，它使用传感器数据（相同位置）的成对回归和（在我看来😉）系数的智能跟踪来执行异常检测，它似乎表现得相当不错。评估是使用与领域专家合作添加的人工错误进行的，因为通常没有可用的基本事实。一个错误总是只影响一个传感器，但有可能多个错误同时独立活动。 （虽然我非常感谢你对此的评论，但这不应该是我帖子的重点）
出于科学原因，我需要 1-2 种其他技术来与我的方法进行比较，这就是我在这里寻求你的建议的原因。通常，有根本不同的方法会很好（例如，我的回归算法，基于 DL 的算法，完全不同的东西），但这并不是太重要，我只需要一种科学和客观的比较方法。由于上述方法应该是工作的重点，因此额外的方法不应该是太多的工作。我还有 1.5 个月的全职时间，所以我可以（并且会）绝对实施复杂的方法，而不需要采取“开箱即用”的东西（如果存在的话），但实施其他方法不应该是另一篇硕士论文。 😉
我正在研究 Matrix Profile (https://www.cs.ucr.edu/~eamonn/MatrixProfile.html)，因为它似乎是一种非常有前途的技术，但它的主要焦点似乎是单变量时间序列，而我的问题需要考虑为多变量，因为数据的行为可能会发生很大变化（如果它们都显示相同，则很好）。我尝试将 MP 应用于单个传感器数据，但只发现了最明显的错误以及许多误报。有一些关于扩展到多变量情况的论文（例如https://epubs.siam.org/doi/pdf/10.1137/1.9781611977653.ch77），但它似乎不太适合我的情况，因为错误通常只显示在一个传感器上，而不是在 n 个中的 k 个上。所以我真的不知道在这种情况下如何最好地应用 MP。
除此之外，我还考虑了基于深度学习的方法，并找到了 DAEMON (https://ieeexplore.ieee.org/document/9458835) 和 USAD (https://dl.acm.org/doi/10.1145/3394486.3403392)。但是，它们似乎还处于实验阶段，我不想花数周时间根据书面描述重建 NN，而不知道它是否适合我的情况。
因此，如果您能针对我的情况推荐方法（或其他建议），我将不胜感激，如果问题描述中有什么不清楚的地方，请随时询问。
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649168/multivariate-anomaly-detection-of-redundant-sensor-data</guid>
      <pubDate>Thu, 13 Jun 2024 11:05:34 GMT</pubDate>
    </item>
    <item>
      <title>我在不同的种子上对逻辑回归分类器获得了 98% 到 100% 的准确率。这应该发生吗（主要关注 100% 准确率）</title>
      <link>https://stats.stackexchange.com/questions/649167/i-am-getting-98-to-100-accuracy-in-my-logistic-regression-classifier-on-differ</link>
      <description><![CDATA[我的数据分割：
from sklearn.model_selection import train_test_split
df.drop(&#39;id&#39;, axis=1, inplace=True)
X = df.drop(&#39;classification&#39;, axis=1)
y = df[&#39;classification&#39;]
X_train, X_test, y_train, y_test = train_test_split(
X, 
y, 
test_size = 0.30, 
random_state =0 
)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
输出：(280, 23) (120, 23) (280,) (120,)

和我的 ML 模型：
来自 sklearn.linear_model 导入 LogisticRegression
来自 sklearn.metrics 导入 accuracy_score、classification_report、confusion_matrix

model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print(accuracy_score(y_test, y_pred))
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/649167/i-am-getting-98-to-100-accuracy-in-my-logistic-regression-classifier-on-differ</guid>
      <pubDate>Thu, 13 Jun 2024 10:20:44 GMT</pubDate>
    </item>
    <item>
      <title>如何从 GLM 推导出 GEE？</title>
      <link>https://stats.stackexchange.com/questions/649164/how-to-derive-gee-from-glm</link>
      <description><![CDATA[我现在正在阅读以下讲座笔记：
https://dept.stat.lsa.umich.edu/~kshedden/Courses/Regression_Notes/gee.pdf


为什么我们有$V_{i}^{-1}(y_{i}-\mu_{i})$？我无法将第 4 页的最后一个方程链接到第 5 页的最后一个方程。]]></description>
      <guid>https://stats.stackexchange.com/questions/649164/how-to-derive-gee-from-glm</guid>
      <pubDate>Thu, 13 Jun 2024 09:29:20 GMT</pubDate>
    </item>
    <item>
      <title>使用 Kahnemans (2021) 方法计算评分者间噪声</title>
      <link>https://stats.stackexchange.com/questions/649163/calculate-inter-rater-noise-using-kahnemans-2021-approach</link>
      <description><![CDATA[我需要帮助根据 Kahneman 等人 (2021) 在其著作《噪音》中描述的方法计算信号和噪音。他们提供了一种量化评估相同案例的评估者之间噪音的技术。想象一下五位心理学家（评估者）评估 10 位患者（案例）的抑郁程度。设置如下：
假设您有行作为评估者，列作为案例。在零噪音的情况下，每个评估者都完全同意，因此所有差异都在案例之间（信号）。Kahneman 等人进一步将噪音分为（稍微简化一点）：

评估者噪音：评估者之间的稳定差异，例如不同的人有不同的方法


残余噪声：无法用任何事物解释的特殊噪声。

为了计算噪声，他们建议：

计算每列 SD 的平均值（每个案例的标准差）（总噪声）
计算每行平均值的标准差（每个评估者的平均值）（评估者噪声）

然后，您可以通过 1 - 2 = 残余噪声来计算残余噪声。
我的挑战是从数据集中计算噪声和信号。此外，我想将噪声报告为类内相关系数 (ICC)，但我正在努力使用其他分解方法复制 Kahneman 的方法。例如，使用带有 lme4::lmer() 的随机效应模型会给我不同的结果。
我模拟了一些数据来说明我的失败尝试。我还质疑卡尼曼等人分析噪声的方法是否可取，因为我找不到任何其他使用这种方法的研究。
最后，我需要一种合理的方法来测量和报告不确定性。有没有办法在这里引导我找到置信区间？
# 加载必要的包
library(lme4)
library(tidyverse)
library(performance)

# 设置可重复性的种子
set.seed(1234)

# 模拟参数
n_raters &lt;- 600
n_cases &lt;- 30
n_obs &lt;- n_raters * n_cases

# 模拟随机效应
rater_effects &lt;- rnorm(n_raters, mean = 0, sd = 1) # 评估者随机效应
case_effects &lt;- rnorm(n_cases, mean = 0, sd = 2) # 案例随机效应

# 模拟 dat
dat &lt;- expand_grid(rater = factor(1:n_raters), case = factor(1:n_cases))
dat$ratereffect &lt;- rater_effects[as.numeric(dat$rater)]
dat$caseeffect &lt;- case_effects[as.numeric(dat$case)]
dat$residual &lt;- rnorm(n_obs, mean = 0, sd = 3) # 残差噪声
dat$y &lt;- dat$ratereffect + dat$caseeffect + dat$residual

dat

# 拟合混合效应模型（# 这大致从模拟中检索参数）
model &lt;- lmer(y ~ 1 + (1|rater) + (1|case), dat = dat)

# 显示模型摘要
summary(model)

performance::icc(model,by_group = TRUE)
# 噪声分解

# 评分者噪声 = 7.9 %
# 案例方差（信号） = 25 %
# 残余噪声 = 100-(7.9+25) = 67.1 %

# 仅噪声分解
# 评分者 = 7.9/(7.9+67.1) = 10.5 %
# 残余噪声 = 100 - 10.5 = 89.5 %

# Kahneman, Sibony, Cass (2021) 计算
dat &lt;- dat |&gt; 
mutate(case = paste0(&quot;case&quot;,case)) |&gt; 
select(rater,case,y) |&gt; 
pivot_wider(values_from = y,names_from = case)

# 计算每行的平均值 (rater)
dat &lt;- dat |&gt;
select(-rater) |&gt; 
rowwise() |&gt;
mutate(row_mean = mean(c_across(everything())))

# 取行平均值的标准差
sd_ratermean &lt;- sd(dat$row_mean)

# 取每个案例的标准差
sd_case &lt;- dat |&gt;
pivot_longer(everything()) |&gt;
summarise(sd_case = sd(value),.by = name) |&gt;
pull(sd_case)

# 取 case sd 的平均值
mean_case &lt;- mean(sd_case)

total_noise &lt;- mean_case
level_noise &lt;- sd_ratermean
pattern_noise &lt;- total_noise-level_noise

level_noise_percent &lt;- level_noise/total_noise
pattern_noise_percent &lt;- pattern_noise/total_noise

cat(&quot;level noise =&quot;,round(level_noise_percent,2),
&quot;\npattern noise =&quot;,round(pattern_noise_percent,2))

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/649163/calculate-inter-rater-noise-using-kahnemans-2021-approach</guid>
      <pubDate>Thu, 13 Jun 2024 09:22:58 GMT</pubDate>
    </item>
    <item>
      <title>合成控制方法中无与伦比的预处理趋势</title>
      <link>https://stats.stackexchange.com/questions/649162/unparallel-pre-treatment-trends-in-synthetic-control-method</link>
      <description><![CDATA[我正在使用 R 包 Synth 运行合成控制模型，其中包含 44 个季度（36 个处理前和 8 个处理后）200 个地区的犯罪数据。我的模型包括几个社会人口变量（例如，总人口、平均年龄、男性比例、平均收入）和总犯罪作为结果变量。
但是，处理单元和合成单元的趋势并不平行，这与文章中经常看到的近乎完美的模仿不同。这是我的数据中的样子：

我的主要问题是：这足以进行有效的比较吗？如果没有，我该如何改进？
例如，我是否应该考虑在捐赠者池中使用更少的控制单元，如果是，基于哪些标准？
我应该注意，我尝试使用犯罪率（每 1,000 名居民）以及犯罪率的移动平均值（试图“平滑”趋势），但没有帮助。
任何建议都将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649162/unparallel-pre-treatment-trends-in-synthetic-control-method</guid>
      <pubDate>Thu, 13 Jun 2024 08:48:13 GMT</pubDate>
    </item>
    <item>
      <title>使用引导独立时间序列构建预测区间是否有效？</title>
      <link>https://stats.stackexchange.com/questions/649161/is-bootstrapping-independent-time-series-to-construct-prediction-intervals-valid</link>
      <description><![CDATA[问题：
我有一个由多个单变量时间序列组成的数据集，每个时间序列代表随时间变化的独立保险索赔金额序列。我的目标是使用 LSTM 模型预测未来的索赔金额。
鉴于经典的引导方法由于时间依赖性而不直接适用于时间序列数据，我正在考虑以下方法：

每个索赔被视为彼此独立，因此每个单变量时间序列都是独立的。

通过随机选择整个单变量时间序列并替换来创建引导样本（我的数据包含超过一百万个索赔序列）。

在每个引导数据集上训练 LSTM 模型。

对所有 LSTM 模型的预测取平均值以获得最终预测并创建置信区间。


我的问题是：这种方法在统计上有效吗？如果有效，为什么？
其他详细信息：
每个单变量时间序列都假定独立于其他时间序列（例如，来自不同客户或保单的索赔）。
通过对整个时间序列进行重新采样，我旨在保留每个序列内的时间依赖性。
目标是利用引导方法来减少方差并提高 LSTM 预测的稳健性并了解不确定性。
如果您能提供关于此方法有效性的任何见解或参考，以及它是否能适当地解决时间序列数据背景下引导的挑战，我将不胜感激。
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/649161/is-bootstrapping-independent-time-series-to-construct-prediction-intervals-valid</guid>
      <pubDate>Thu, 13 Jun 2024 06:04:16 GMT</pubDate>
    </item>
    <item>
      <title>具有相关随机变量的 $E[X\mid U,V]$</title>
      <link>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</link>
      <description><![CDATA[设 $(X,Y,Z)$ 为三维随机变量，其密度函数为 $f(x,y,z)=\frac{2}{3}(x+y+z)$ 在 $0&lt;x,y,z&lt;1$ 上，$U=\min(X,Y,Z)$，$V=\max(X,Y,Z)$。计算$E[X\mid U,V]$。
我认为答案是$\frac{14U^2+26UV+14V^2}{27(U+V)}$，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</guid>
      <pubDate>Thu, 13 Jun 2024 05:43:04 GMT</pubDate>
    </item>
    <item>
      <title>您能在一般加法模型中使用百分比作为因变量吗？</title>
      <link>https://stats.stackexchange.com/questions/649157/can-you-use-a-percentage-as-the-dependent-variable-in-general-additive-models</link>
      <description><![CDATA[这更像是一个关于统计建模的一般问题，而不是一个项目特定的问题。
在广义加性模型 (GAM) 中，因变量可以是百分比吗？如果因变量是百分比，我需要为自变量使用特定的基础吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649157/can-you-use-a-percentage-as-the-dependent-variable-in-general-additive-models</guid>
      <pubDate>Thu, 13 Jun 2024 05:19:48 GMT</pubDate>
    </item>
    <item>
      <title>模拟中显示逐步回归问题的最小不良逐步程序</title>
      <link>https://stats.stackexchange.com/questions/649156/least-bad-stepwise-procedure-for-a-simulation-that-shows-issues-with-stepwise-re</link>
      <description><![CDATA[我非常清楚逐步回归导致的问题。我想通过特定情况下的模拟来演示其中的一些问题。
我正在考虑一个回归，其中我有一些感兴趣的分类变量，然后是一些协变量。我假设这些协变量的某些组合很重要，并且逐步选择将选择出它们的良好组合（可能不是，但我希望在模拟中显示失败）。
但是，如果我只是运行正常的逐步回归，如 MASS:stepAIC，则存在不包括原始感兴趣的分类变量的风险。
我理想情况下想要做的是只对协变量运行逐步选择，然后找到最终测试的 t 统计量（在逐步消除或包含之后）对原始感兴趣的分类变量，就好像我从一开始就使用该模型一样，但如果完全排除该变量，则不会有 t 统计量。
补救措施是什么？当然，我可以编写自己的不考虑特定变量的逐步选择算法，但我甚至不完全确定如果“正确”的逐步消除步骤是删除感兴趣的主要变量，我会怎么做。我的向后消元法就到此结束了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649156/least-bad-stepwise-procedure-for-a-simulation-that-shows-issues-with-stepwise-re</guid>
      <pubDate>Thu, 13 Jun 2024 05:19:27 GMT</pubDate>
    </item>
    <item>
      <title>对零假设的困惑</title>
      <link>https://stats.stackexchange.com/questions/649145/confusion-regarding-the-null-hypothesis</link>
      <description><![CDATA[我最近在做统计题时看到了这个问题：

一罐 Fun Juice 应该至少装有 64 盎司果汁。

灌装机经过校准，平均每瓶应该装有 64.05 盎司果汁。一位经理想知道机器是否灌装不足。她计划随机抽取一些瓶子样本，然后进行显著性检验。
零假设和备择假设是什么？

答案指出 $H_0$ 是 $\mu=64.05$ 并且 $H_a$ 是 $\mu&lt;64.05$。但是，我得到的结果是 $H_0$ 是 $\mu=64$，而 $H_a$ 是 $\mu&lt;64%$。这里的“未充满”难道不是意味着平均值低于其应包含的量（64 盎司）而不是低于机器校准的填充量（64.05 盎司）吗？这是教科书中的错误，还是我只是遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/649145/confusion-regarding-the-null-hypothesis</guid>
      <pubDate>Wed, 12 Jun 2024 23:15:30 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型中的调节系数 SPSS - 解释</title>
      <link>https://stats.stackexchange.com/questions/649127/moderation-coefficient-in-linear-mixed-models-spss-interpretation</link>
      <description><![CDATA[我的模型：
IV：外向性（5 点李克特）
调节器：能力（值 1-5）
DV：要约（值 5 到 15）
假设：外向性和要约之间的负相关关系受能力调节，因此更高的能力会削弱负相关关系。
我的输出：（显著性截止值为 .1，而不是我的情况中的 .05）
外向性和能力之间没有显著的负面直接影响。
外向性*能力交互作用显著，但系数为正。这是否支持我的假设，还是意味着完全相反（更高的能力信任会加剧外向性和提供之间的负相关关系）。
请帮助我，我对结果的含义感到非常困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/649127/moderation-coefficient-in-linear-mixed-models-spss-interpretation</guid>
      <pubDate>Wed, 12 Jun 2024 19:14:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么建议在对 lmer 模型进行参数引导时保留 use.u=T（在 bootMer 中）？</title>
      <link>https://stats.stackexchange.com/questions/648440/why-is-it-recommended-to-keep-use-u-t-in-bootmer-when-doing-parametric-bootstr</link>
      <description><![CDATA[我正在执行参数引导，目的是使用模拟值为混合模型中的系数创建置信区间。我看到通常建议在 R 的 lme4 包中的 bootMer 函数中设置 use.u=T，我想知道为什么？我认为重新采样随机效应是有意义的，以便捕获完整的不确定性。
需要澄清的是，如果我要在最近收集的数据集上重新运行模型，实际级别（或类别）将相同，只是值会有所不同。
如果有更多资源/论文涉及这一点，那将会很有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/648440/why-is-it-recommended-to-keep-use-u-t-in-bootmer-when-doing-parametric-bootstr</guid>
      <pubDate>Sat, 01 Jun 2024 19:04:25 GMT</pubDate>
    </item>
    </channel>
</rss>