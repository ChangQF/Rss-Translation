<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 20 Dec 2023 06:14:44 GMT</lastBuildDate>
    <item>
      <title>乘以独立条件概率</title>
      <link>https://stats.stackexchange.com/questions/635317/multiplying-independent-conditional-probabilities</link>
      <description><![CDATA[如果我们知道 A 和 B 是独立的，使得 $P(A,B) = P(A)P(B)$，则 $P(A|C)P(B|C)=P(A,B|C)$？
直觉上，这似乎应该是真的，但我不知道如何正式证明这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/635317/multiplying-independent-conditional-probabilities</guid>
      <pubDate>Wed, 20 Dec 2023 04:52:18 GMT</pubDate>
    </item>
    <item>
      <title>基于计数的比例数据的 GLMM</title>
      <link>https://stats.stackexchange.com/questions/635315/glmm-on-proportion-data-based-on-counts</link>
      <description><![CDATA[我正在重复测量研究中对我的小数据集 ($n=31$) 运行 GLMM，该研究具有  $2$ 组和 $5$ 条件（每个人的条件都是固定的）。我对群体和条件的主效应以及交互作用感兴趣。因变量源自两个计数变量（例如响应 $A$ 和响应 $B$），彼此成反比关系。我使用这个公式得出了比例：
$$
\text{变量 A} - \text{变量 B}/\text{变量 A} + \text{变量 B}
$$
结果的值范围从 $-1$ 到 $1$。我知道比例变量通常介于 $0$ 和 $1$ 之间，但在这种情况下，我的负值是考虑到两个响应之间的关系是有意义的。当我尝试运行 GLMM 时，我的许多案例都被排除，因为它们是负值。
有人对如何进行有建议吗？我正在使用 SPSS，我知道它并不理想，但它是我现在所拥有的！我可以根据需要提供任何其他信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/635315/glmm-on-proportion-data-based-on-counts</guid>
      <pubDate>Wed, 20 Dec 2023 04:27:09 GMT</pubDate>
    </item>
    <item>
      <title>71 000 手牌中出现 10 次皇家同花顺的几率是多少？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635314/what-are-the-odds-of-10-royal-flushes-in-71-000-hands</link>
      <description><![CDATA[一些背景。我在线玩扑克。我专门玩 6 手无限注德州扑克，我玩大约 25/18，这意味着我自愿将大约 25% 的牌放入底池，并在翻牌前用大约 18% 的牌加注（25% 的子集）。在过去的 71000 手牌中（这是总手牌数，包括我弃牌的手牌），我个人已经拿到了 10 张皇家同花顺。其中大约7张是1张皇家牌（我手中的一张底牌与4张公共牌相连），3张是2张皇家牌。我相信形成皇家同花顺的几率是 649000:1，并且我相信这是“2 张皇家同花顺”，其中您的两张底牌都被使用 -&gt; 并且您会看到 5 张牌出局。不用说，任何类型的 10 个皇家同花顺都有点令人不安。我想知道是否有人可以对此进行赔率，看看它是否接近可能性（即游戏不是随机的）。具体来说，如果能看到这种情况比平均值高出多少个标准差，那就太酷了。
非常感谢，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635314/what-are-the-odds-of-10-royal-flushes-in-71-000-hands</guid>
      <pubDate>Wed, 20 Dec 2023 04:12:39 GMT</pubDate>
    </item>
    <item>
      <title>对多级模型的残差进行建模意味着什么？</title>
      <link>https://stats.stackexchange.com/questions/635312/what-it-means-to-model-the-residuals-of-a-multilevel-model</link>
      <description><![CDATA[我有一个高度倾斜的数据集。但是，与残差未建模的其他模型相比，我选择的下面的模型显示出显着改进的正态分布残差（和预测值）。
两个问题：
1- 下面的模型是否假设我每个主题的数据都来自正常群体，其方差在X1_categorical级别之间也不相等也是 X2_numeric 变量的幂函数？
2- 残差分布（下面）是否告诉我们有关数据任何部分的分布（例如每个主题的数据，或边际分布）涵盖所有科目等）
hist(resid(MODEL, type = “标准化”))

 模型 &lt;- nlme::lme(y ~ X1_categorical + X2_numeric,
         随机 = ~1|主题，
         数据=数据，
         相关性 = corSymm(~1|主题),
         权重 = varComb(varIdent(form = ~ 1 | X1_categorical ),
                                          varPower(form = ~ X2_numeric )))
]]></description>
      <guid>https://stats.stackexchange.com/questions/635312/what-it-means-to-model-the-residuals-of-a-multilevel-model</guid>
      <pubDate>Wed, 20 Dec 2023 01:45:58 GMT</pubDate>
    </item>
    <item>
      <title>用于同时比较多个参数的贝叶斯 ROPE（实际等效区域）？</title>
      <link>https://stats.stackexchange.com/questions/635309/bayesian-rope-region-of-practical-equivalence-for-simultaneous-comparison-of-m</link>
      <description><![CDATA[我非常喜欢 ROPE（实际等效区域）的想法（例如，参见 此处），您可以在其中计算给定参数位于先前范围（算作“小”）的后验概率。在学科领域方面。 （这不是假设拒绝程序问题的替代品；在我正在研究的特定上下文中，作者希望专门测试等效性。）
正如我所见，ROPE 是一个单变量过程，即测试某些特定参数的边际后验分布。是否存在关于多元版本的讨论？我可以想到一些粗略的方法（例如，测试一堆单变量 ROPE 的同时满足程度 - 位于指定“矩形”区域内的概率 - 或某种平方和/马哈拉诺比斯变体），但我希望不要这样做重新发明任何轮子。]]></description>
      <guid>https://stats.stackexchange.com/questions/635309/bayesian-rope-region-of-practical-equivalence-for-simultaneous-comparison-of-m</guid>
      <pubDate>Wed, 20 Dec 2023 01:27:23 GMT</pubDate>
    </item>
    <item>
      <title>寻找泊松分布之间的相关性的适当归一化是什么？</title>
      <link>https://stats.stackexchange.com/questions/635305/what-is-the-appropriate-normalization-for-finding-correlations-between-poisson-d</link>
      <description><![CDATA[我有兴趣使用这个算法，glm-pca，来找到一个较低的维度嵌入时间序列数据，特别是神经元尖峰数据，这是泊松分布的。我看过一些关于查找两个泊松分布的协方差的帖子 https://math.stackexchange.com/questions/3707140/joint-distribution-and-covariance-of-poisson-process-and-waiting-time 我只是好奇如果有标准化的话会怎样应该应用于我的数据。基本上这将是一个非常稀疏的计数时间序列。我可能会减小窗口大小以减小矩阵的大小并加快计算速度。]]></description>
      <guid>https://stats.stackexchange.com/questions/635305/what-is-the-appropriate-normalization-for-finding-correlations-between-poisson-d</guid>
      <pubDate>Tue, 19 Dec 2023 23:45:02 GMT</pubDate>
    </item>
    <item>
      <title>排列测试图分析[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635304/permutation-test-graph-analyse</link>
      <description><![CDATA[我需要将来自矩阵引导的值与原始的唯一值进行比较，但我不知道如何对我的数据执行此操作。
为了我需要做：
测量原始网络上的目标变量并保存它洗牌我的原始数据（相关矩阵） - 随机（100x）创建测量该随机网络的目标变量的图表保存循环结束的数据比较分布随机目标变量，并在请求时保存原始变量。那么如果原始数据在随机变量的 95% 分布范围之外，则意味着它是显着的（随机数与原始变量不同）。
我在 R 中使用了 t.teste 这种形式。
pval_eq[k] &lt;- t.test(rand, mu = obs)$p.value
我如何无法进行统计来比较这些数据：观察值以及该值的排列。
我可以使用这种形式来计算 p 值：大于或等于观察值的值（统计量）的数量，然后除以值的数量。在代码中，pval = sum(s &gt;= s0)/N;
我在互联网上找到了其他几个公式。但基本上总的来说，我只是想知道一个正确的公式来计算 p 的值，考虑到我想比较原始值和该值的排列 100x]]></description>
      <guid>https://stats.stackexchange.com/questions/635304/permutation-test-graph-analyse</guid>
      <pubDate>Tue, 19 Dec 2023 22:37:17 GMT</pubDate>
    </item>
    <item>
      <title>采样：如果多个样本产生一个输出，我实际上需要处理多少个样本？</title>
      <link>https://stats.stackexchange.com/questions/635303/sampling-if-multiple-samples-produce-one-output-how-many-samples-do-i-actually</link>
      <description><![CDATA[解释一下，假设我根据 $n$ 个连续的现实世界样本计算单个测试统计数据。想象一下，我在实验过程中总共获得了 $m \gg n$ 个真实世界样本。
我是否有 $m$ 或 $m \over n$ 个样本用于假设测试？
&lt;小时/&gt;
作为随机性测试的一部分，我测试均匀分布的示例：假设随机样本总大小为 5120 字节。我的测试统计量是处理窗口为 512 字节的快速傅立叶变换的峰值。因此 512 个字节被处理后产生一个浮点数。我想这意味着我只有 10 次 KS 均匀性测试试验...
就上下文而言，我正在考虑以下声明，摘自采样有关：如果一个样本产生多个输出，我实际上需要工作多少个样本与？ 但它完全相反。]]></description>
      <guid>https://stats.stackexchange.com/questions/635303/sampling-if-multiple-samples-produce-one-output-how-many-samples-do-i-actually</guid>
      <pubDate>Tue, 19 Dec 2023 22:36:54 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯深度学习中学习损失衰减的损失函数的推导</title>
      <link>https://stats.stackexchange.com/questions/635300/derivations-of-loss-functions-for-learning-loss-attenuation-in-bayesian-dl</link>
      <description><![CDATA[我对贝叶斯深度学习相当陌生，如果这是一个愚蠢的问题，我很抱歉。
我正在尝试实现本文中的工作：我们在计算机视觉的贝叶斯深度学习中需要哪些不确定性？

在整篇论文中，他们给出了最小化目标，使模型能够学习任意不确定性，但他们没有给出任何关于它们来自何处的正式推导。它们不是临时构造，因此必须有一种方法来派生它们。
哪里可以找到推导？
$$
\大的
\mathcal{L}(\theta,p) = -\frac{1}{N} \sum_{i=1}^N
 \text{log} \hspace{1 mm} p(\text{y}_i|\text{f}^\widehat{\text{W}_i}(x_i)) + \frac{1-p}{2N }||\theta||^2
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/635300/derivations-of-loss-functions-for-learning-loss-attenuation-in-bayesian-dl</guid>
      <pubDate>Tue, 19 Dec 2023 22:26:42 GMT</pubDate>
    </item>
    <item>
      <title>测量程序的标准误差（SEM）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635297/standard-error-of-measurement-procedure-sem</link>
      <description><![CDATA[在同一尺度上计算不同重量的 SEM 是否正确？例如，比较 10 公斤的所有测量值，然后比较 20 公斤的所有测量值……并取平均值 SEM？或者应该单独报告每个重量的 SEM？]]></description>
      <guid>https://stats.stackexchange.com/questions/635297/standard-error-of-measurement-procedure-sem</guid>
      <pubDate>Tue, 19 Dec 2023 21:45:42 GMT</pubDate>
    </item>
    <item>
      <title>避免预测中的负值[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635269/avoiding-negative-values-in-forecasting</link>
      <description><![CDATA[我对可用于维持正预测的 Box-Cox 变换（对数变换）有疑问。
通过偏差调整应用它是否安全，因为根据我的经验，在某些情况下，它会导致拟合值的 MSE 显着增加（无需偏差调整），我是否可以安全地假设应用偏差调整将解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/635269/avoiding-negative-values-in-forecasting</guid>
      <pubDate>Tue, 19 Dec 2023 16:41:05 GMT</pubDate>
    </item>
    <item>
      <title>比较两个样本的第 90 个百分位数（置信区间、检验）</title>
      <link>https://stats.stackexchange.com/questions/635097/compare-90th-percentiles-of-two-samples-confidence-interval-test</link>
      <description><![CDATA[我有一个质量改进更改前后的救护车响应时间数据集。我想看看更改前后的响应时间是否有差异。具体来说，我试图报告两组（之前和之后）中的第 90 个百分位数值、两个第 90 个百分位数之间的差异、$95$% 置信区间（ CI) 围绕这个差异，以及一个 $p$ 值。
在 R 中，数据集可能如下所示：
set.seed(123)
数据 &lt;- data.frame(
  组=样本（c（“之前”，“之后”），100，替换= TRUE），
  响应时间 = rnorm(100, 平均值 = c(10, 15), sd = 2)
）

我可以使用 t.test 函数轻松测试均值差异：
t.test(data$ResponseTime[data$Group == “之前”],
       数据$ResponseTime[数据$Group ==“之后”])

我还可以像这样计算第 90 个百分位数：
之前 &lt;- 分位数(a$ResponseTime[a$Group==“之前”], probs = 0.9, na.rm = T)
&lt;- 分位数（a$ResponseTime[a$Group==“之后”]，probs = 0.9，na.rm = T）

但我不知道如何比较两者。
我的问题：

这有意义吗？
如果确实有意义，我会使用什么测试来比较第 90 个百分位数？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635097/compare-90th-percentiles-of-two-samples-confidence-interval-test</guid>
      <pubDate>Sun, 17 Dec 2023 02:55:47 GMT</pubDate>
    </item>
    <item>
      <title>C 统计量和测量多级逻辑回归中的上下文效应</title>
      <link>https://stats.stackexchange.com/questions/633717/c-statistic-and-measuring-the-contextual-effect-in-multilevel-logistic-regressio</link>
      <description><![CDATA[我有一个两级逻辑回归模型，其结果是“InfectedqPCR” （通过 qPCR 确定是否感染疟原虫）在个体水平上。
我有一系列个人和家庭层面的变量。
家庭是分组结构。
我一直在阅读 Austin 和 Merlo (2017) 的“多级逻辑回归分析中的中级和高级主题”生物统计学教程 - 医学统计 - 关于使用c-统计量作为一般情境效应大小的度量。
按照他们的方法，我尝试解释以下三个模型的 c 统计输出：
model1 &lt;- glm(Infected_qPCR ~ Sex + Age_Band_Years, family=“二项式”, data=Data_Model_In_Adults)
Cstat(x = 预测(模型1),
      resp = model.response(model.frame(model1))) # 0.653
              # 仅包含固定效应 - 无随机效应结构
Cstat(x = 预测(Mod_MAd_Indi),
      resp = model.response(model.frame(Mod_MAd_Indi))) # 0.823
              # 包含相同的固定效应（Sex 和 Age_Band_Years）和家庭聚类随机效应
Cstat(x = 预测(Mod_MAd_Comb_Vil),
      resp = model.response(model.frame(Mod_MAd_Comb_Vil))) # 0.771
              # 包含相同的个体固定效应（Sex和Age_Band_Years）和各种家庭因素以及家庭聚类随机效应

因此，据此，我认为 c 统计量从仅具有固定效应且无随机效应结构的 model1 到包含随机效应结构的 Mod_MAd_Indi 的变化为 0.17。
在 Austin 和 Merlo 的论文中，他们的示例的 c 统计量发生了 0.004 的变化，这表明“一般上下文效应较弱”。
问题 1：
那么，如果 0.004 很弱，那么如果我的上下文效果是 0.17，我能说什么？这是中等的情境效应还是强烈的效应？有这方面的任何指南或参考吗？
问题2：
Austin 和 Merlo 的论文还强调，“向包含特定簇随机效应的模型添加簇特征不能增加仅包含特定簇随机效应的模型的 c 统计量。”那么，c 统计量的 0.17 变化是否是最大可能变化（Austin 和 Merlo 所说的“上限”）？这就是我添加家庭变量 (Mod_MAd_Comb_Vil) 导致 c 统计量较低的原因吗？它可能相同或更低，但绝对不会更高 - 这就是奥斯汀和梅洛的意思吗？
这是根据 Eric Ruzek 在下面的评论中提供的有用意见进行的补充：
在进一步的系列模型中，我的 C 统计量有所增加，仅在小数点后第二位，但尽管如此，在模型中包含家庭层面的变量后，它还是有所增加。

在个体（和随机效应）模型中，该值为 0.880
在家庭和个人（和随机效应）模型中，该值为 0.892。

这似乎违背了所有统计直觉，但以下内容可以解释这一点吗？
**个别型号如下：**

Mod_Indi_Child_0.05_Apriori &lt;- glmer(Infected_qPCR ~ 1 + Age_Band_Years + Work_Place_Nearby_Forest + Bednet_last_night +
                               (1 | Household_ID.x)，数据 = Data_Model_In_Child，家庭 = 二项式，glmerControl(optimizer = “bobyqa”))

**组合模型如下：**

Mod_Comb_Child_Apriori &lt;- glmer(Infected_qPCR ~ 1 + Age_Band_Years + Work_Place_Nearby_Forest + Bednet_last_night + 规模(Persons_living_in_house_count，center = TRUE，scale = FALSE) +
                          (1 | Household_ID.x)，数据 = Data_Model_In_Child，家庭 = 二项式，glmerControl(optimizer = “bobyqa”))

两种模式的区别在于增加了“家庭级”功能。组合模型中的因素（房屋计数中的人数）。该模型比仅个人模型具有更高的 C 统计量的原因可能是因为该“家庭水平”水平因子实际上也包含个体水平的信息？我的意思是，因为变量是“住在房子里的人数”，所以该个人是该房屋计数的一部分，因此该模型正在处理该“房屋计数”的至少一部分。作为个人层面的变量，因此 C 统计量有所上升。
这是对我所得到的不寻常结果的可能解释，还是我抓住了救命稻草？]]></description>
      <guid>https://stats.stackexchange.com/questions/633717/c-statistic-and-measuring-the-contextual-effect-in-multilevel-logistic-regressio</guid>
      <pubDate>Tue, 12 Dec 2023 12:47:45 GMT</pubDate>
    </item>
    <item>
      <title>您可以使用来自单独模型输出的回归贝塔/系数来运行 t 检验吗？</title>
      <link>https://stats.stackexchange.com/questions/630630/can-you-run-a-t-test-with-regression-betas-coefficients-from-the-output-of-separ</link>
      <description><![CDATA[用外行的话来说，如果各个模型中包含的所有协变量都相同，那么运行 t 检验来比较感兴趣的变量（例如年龄）的系数是否公平，我想在其中比较效果网络 A 中的大脑区域与 B、C 等区域的年龄更大，并且它们都作为单独的模型进行研究，但构造相似。]]></description>
      <guid>https://stats.stackexchange.com/questions/630630/can-you-run-a-t-test-with-regression-betas-coefficients-from-the-output-of-separ</guid>
      <pubDate>Tue, 07 Nov 2023 05:14:56 GMT</pubDate>
    </item>
    <item>
      <title>如何解释此处的因子分析输出</title>
      <link>https://stats.stackexchange.com/questions/615160/how-to-interpret-factor-analysis-output-here</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/615160/how-to-interpret-factor-analysis-output-here</guid>
      <pubDate>Sun, 07 May 2023 15:24:48 GMT</pubDate>
    </item>
    </channel>
</rss>