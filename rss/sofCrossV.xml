<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 30 Nov 2023 03:15:04 GMT</lastBuildDate>
    <item>
      <title>我定义分析期的方法有意义吗？</title>
      <link>https://stats.stackexchange.com/questions/632668/does-my-approach-to-defining-the-analysis-period-make-sense</link>
      <description><![CDATA[我是一名 Google 数据分析证书学生，现在正在参加我的顶点项目。我正在从非数据背景转向，我知道我还需要学习大量的东西。因此，除了直接答案之外，我还希望阅读一些有关该主题的必读文章。提前谢谢大家。
上下文
我被要求找出一家虚构的自行车共享公司的一次性用户和会员用户的骑行模式之间的差异（Cyclistic 案例）。目标是稍后认识到休闲骑手成为年度会员的潜在激励因素。
我可以访问 2013 年至 2023 年 10 月的行程数据，总共有几千万行。数据来自真实的共享单车公司。对我的分析很重要的一组字段多年来保持不变，但其中的数据可能会发生变化：车站、自行车类型等。
现在我正在尝试定义要分析的样本量。项目简介说我可以选择一个季度到一年之间的任何一段时间来分析它。我想尝试将这项任务视为现实世界的任务，因此一年的时间似乎太短而无法定义模式（下面我将描述原因）。现在我想了解“现实世界的方法”。
我的方法
人工智能建议我花几年时间并使用分层抽样：采取一些分层（例如，几年或半年，我还没有定义）并根据预期的误差幅度和置信度从中提取随机样本级别。
这种方法看起来很公平，但我无法决定我应该合理地花多少年。我不喜欢花全部 10 年的想法，原因如下：

我花费的时间越多，手动处理和计算成本就越高
但最重要的是，根据多份出版物（例如一些出版物提到的 此处），影响了人们的共享单车行为。也就是说，本文指出，人们开始减少会员乘车次数，而非会员游乐设施保持不变，这正是影响相关模式的原因。这意味着，如果我采用大流行前 7 年以及大流行和大流行后 3.5 年，我可能会使结果过于偏向大流行前的常态。但如果我按照简报的要求只用一年，比如2022年，即大流行和正常之间的过渡年，那也没有代表性。

我正在考虑从 2016 年 7 月到 2023 年 6 月的时期，因此有 14 个完整的半年作为抽样分层，在大流行之前和大流行时间之间平均分配。这将使我能够看到大流行期间的模式和“正常”模式。
我的方法有问题。
一方面，上述策略似乎是合理的。
另一方面，我又忍不住觉得自己想太多了。所有上述思维过程都超出了顶点项目的要求。该项目简介要求最长一年，一些共享单车非新冠病毒与新冠病毒的比较可以在互联网上进行（例如，链接）也只覆盖了几年，尽管我的证书学生同学人数很多，但我未能在谷歌上搜索任何关心的人分析期。
因此，虽然我愿意付出额外的努力，但我担心它可能会在一个非常错误的地方。
问题
我定义分析期的方法通常有意义吗？
或者，如果没有，您将如何处理？
感谢您的宝贵意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/632668/does-my-approach-to-defining-the-analysis-period-make-sense</guid>
      <pubDate>Thu, 30 Nov 2023 02:32:39 GMT</pubDate>
    </item>
    <item>
      <title>验证功率分析</title>
      <link>https://stats.stackexchange.com/questions/632665/validating-power-analysis</link>
      <description><![CDATA[我目前正在网络上进行一些实验。主要思想是验证某些转化指标的影响。我们的典型漏斗是：流量-&gt;流量注册-&gt;一些激活事件。
我们感兴趣的指标是某些激活事件的 CVR。让我们假设：
交通 -&gt;活动转化率 = 1%
注册-&gt;活动转化率 = 25%
网络的变化将在流量时发生，这意味着我无法在注册阶段将卖家分为控制/处理。
现在，我想使用网络中的埃文斯计算器计算功率样本，这是我的问题：
我应该使用哪种 CVR？流量中的一个还是我可以利用注册中的一个，即使流量发生了拆分？
一旦我有了样本量，这个样本量意味着哪些科目？流量/注册？还是流量/注册+活动的组合？
例如。使用上面的数据，所需的流量样本 -&gt; 50% 提升（功率为 0.8，alpha 0.05）的事件 CVR 为 6,650。但是 6,650 什么，流量？
注意：我知道人们喜欢在堆栈交换中纠正人们，并且有充分的理由，但我并不要求复杂的事情，例如转向贝叶斯、序列测试，或者这甚至不是合适的 A/B测试。我只是想让我的问题得到澄清。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/632665/validating-power-analysis</guid>
      <pubDate>Thu, 30 Nov 2023 00:42:52 GMT</pubDate>
    </item>
    <item>
      <title>什么是特定分布的“似然比检验”？它与假设检验有何关系？</title>
      <link>https://stats.stackexchange.com/questions/632662/what-is-a-likelihood-ratio-test-for-a-specific-distribution-and-how-does-it-r</link>
      <description><![CDATA[刚刚向我介绍了似然比测试 (LRT) ，但我在理解概念和术语时遇到了困难。
例如，我提出了一个关于确定两个样本 {x} 和 {y} 是否来自相同概率分布的问题，这意味着分布的参数采样的两个变量是相同的：即 $\sigma_x = \sigma_y$。该问题的这个答案指的是“似然比检验”。分布，以及后来的“在[特定分布]假设下计算的似然比”。我无法弄清楚这些短语引用的确切计算结果。
现在，我习惯用假设的方式思考，所以如果我们说零假设$H_0$就是场景其中 $\sigma_x = \sigma_y$，则其补集 $H_1$ 是其中 &lt; span class=&quot;math-container&quot;&gt;$\sigma_x \neq \sigma_y$。我想我可以处理这个问题（减去关于 I 类和 II 类错误对称性的模糊性）。
因此，我们可以通过比较 $H_0$ 的可能性，将这个假设问题带入似然比空间 给定样本数据，将 $\mathcal{L}(H_0 | {x,y})$ 写入...好吧，观察到的可能性每个参数对 ($\sigma_x, \sigma_y$) 下的样本数据，其中 $\sigma_x \neq \sigma_y$？！
我认为似然比表达了比假设及其补充更强大的东西，但我还没有找到可以追溯到我所理解的任何具体内容的解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/632662/what-is-a-likelihood-ratio-test-for-a-specific-distribution-and-how-does-it-r</guid>
      <pubDate>Wed, 29 Nov 2023 23:08:11 GMT</pubDate>
    </item>
    <item>
      <title>特斯拉充电站数量逐年变化</title>
      <link>https://stats.stackexchange.com/questions/632660/change-in-number-of-tesla-charging-stations-year-to-year</link>
      <description><![CDATA[我正在分析不同年份不同城市（来自 3 个不同欧盟国家）的数据集。对于每年的每个城市，都有有关犯罪率、GDP、识字率、总人口、平均汽油价格和电动汽车充电站（例如特斯拉）数量的信息。
对于第一个问题：在城市层面，我想看看这些因素的变化是否会影响电动汽车充电站数量逐年增加/减少（城市内）。
对于第二个问题：我想看看新冠疫情对车站数量是否有影响。我还想看看在新冠​​疫情之后封锁超过 2 个月（超过 2 年）的城市是否有更多车站。
我认为这里可以使用不同类型的模型（数据集中的每一行都是年底的一个城市）：



具有外生变量的随机效应 ARIMA (ARIMAX)




具有随机效应的纵向回归（针对计数数据）




面板型号



但我不确定哪个最适合这个问题。我想也许这三个都可以用在这里？对于此类问题有更好的模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/632660/change-in-number-of-tesla-charging-stations-year-to-year</guid>
      <pubDate>Wed, 29 Nov 2023 22:52:49 GMT</pubDate>
    </item>
    <item>
      <title>R 中的中介者或主持人？</title>
      <link>https://stats.stackexchange.com/questions/632659/mediator-or-moderator-in-r</link>
      <description><![CDATA[您好，我正在学习如何确定R中的变量是调节变量还是中介变量。据我所知，如果交互项在统计上不显着，我们需要考虑该变量的中介效应。还是需要同时进行中介和调节分析然后再做出决定？我一时糊涂了。感谢你的帮助。我还有一个问题，样本数据集是连续数字，我是否也可以将其应用于虚拟变量，即逻辑回归？
这是适度分析：
# 在线下载数据。这是本文的模拟数据集。
myData &lt;- read.csv(&#39;http://static.lib.virginia.edu/statlab/materials/data/mediationData.csv&#39;)

# 审核分析
model_interaction &lt;- lm(Y ~ X + M +X*M, data = myData)
摘要（模型交互）

&lt;前&gt;&lt;代码&gt;调用：
lm(公式 = Y ~ X + M + X * M, 数据 = myData)

残差：
    最小 1Q 中值 3Q 最大
-3.8887 -1.1147 0.0062 1.1226 3.9758

系数：
            估计标准。误差t值Pr(&gt;|t|)
（截距）0.84237 1.56674 0.538 0.59206
× 0.22189 0.27122 0.818 0.41531
中号 0.86381 0.32651 2.646 0.00953 **
X：M -0.03700 0.05033 -0.735 0.46403
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残余标准误差：96 自由度上为 1.635
多重 R 平方：0.3765，调整 R 平方：0.357
F 统计量：3 和 96 DF 上为 19.32，p 值：6.972e-10

这是中介分析：
中介分析
# 在线下载数据。这是本文的模拟数据集。
myData &lt;- read.csv(&#39;http://static.lib.virginia.edu/statlab/materials/data/mediationData.csv&#39;)

步骤 1
model.0 &lt;- lm(Y ~ X, myData)
摘要（模型.0）

&lt;前&gt;&lt;代码&gt;调用：
lm(公式 = Y ~ X, 数据 = myData)

残差：
    最小 1Q 中值 3Q 最大
-5.0262 -1.2340 -0.3282 1.5583 5.1622

系数：
            估计标准。误差t值Pr(&gt;|t|)
（截距）2.8572 0.6932 4.122 7.88e-05 ***
X 0.3961 0.1112 3.564 0.000567 ***
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残余标准误差：98 自由度上为 1.929
多重 R 平方：0.1147，调整 R 平方：0.1057
F 统计量：1 和 98 DF 上为 12.7，p 值：0.0005671

步骤 2
model.M &lt;- lm(M ~ X, myData)
摘要(型号.M)

&lt;前&gt;&lt;代码&gt;调用：
lm(公式 = M ~ X, 数据 = myData)

残差：
    最小 1Q 中值 3Q 最大
-4.3046 -0.8656 0.1344 1.1344 4.6954

系数：
            估计标准。误差t值Pr(&gt;|t|)
（截距）1.49952 0.58920 2.545 0.0125 *
X 0.56102 0.09448 5.938 4.39e-08 ***
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残余标准误差：98 自由度上为 1.639
多重 R 平方：0.2646，调整 R 平方：0.2571
F 统计量：1 和 98 DF 上为 35.26，p 值：4.391e-08

步骤 3
model.Y &lt;- lm(Y ~ X + M, myData)
摘要（型号.Y）

&lt;前&gt;&lt;代码&gt;调用：
lm(公式 = Y ~ X + M, 数据 = myData)

残差：
    最小 1Q 中值 3Q 最大
-3.7631 -1.2393 0.0308 1.0832 4.0055

系数：
            估计标准。误差t值Pr(&gt;|t|)
（截距）1.9043 0.6055 3.145 0.0022 **
0.0396 0.1096 0.361 0.7187
中号 0.6355 0.1005 6.321 7.92e-09 ***
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残余标准误差：97 自由度上为 1.631
多重 R 平方：0.373，调整 R 平方：0.3601
F 统计量：2 和 97 DF 上为 28.85，p 值：1.471e-10


或套餐
库（中介）
结果 &lt;- mediate(model.M, model.Y, treat=&#39;X&#39;, mediator=&#39;M&#39;,
                   启动=真，模拟=500）
总结（结果）

因果中介分析

使用百分位法的非参数自举置信区间

               估计 95% CI 较低 95% CI p 值
ACME 0.3565 0.2235 0.52 &lt;2e-16 ***
ADE 0.0396 -0.2016 0.30 0.800
总效应 0.3961 0.1122 0.63 0.004 **
道具介导 0.9000 0.5081 2.36 0.004 **
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

使用的样本量：100


模拟：500
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/632659/mediator-or-moderator-in-r</guid>
      <pubDate>Wed, 29 Nov 2023 22:49:51 GMT</pubDate>
    </item>
    <item>
      <title>多波复杂勘测设计</title>
      <link>https://stats.stackexchange.com/questions/632658/complex-survey-design-with-multiple-waves</link>
      <description><![CDATA[我工作的组织已多次收集个人数据。他们的目标是收集 6 个不同组 (genderXgroup) 中的 333 名个体。如果第一波没有达到每组 333 人，他们计划在第二波中收集更多数据，第二波采用与第一波相同的抽样设计。在创建权重时，我们应该如何为个体分配权重？我假设每个 Wave 都会为个人导出单独的权重。是对的吗？或者，是否应该合并两波数据来估计权重？]]></description>
      <guid>https://stats.stackexchange.com/questions/632658/complex-survey-design-with-multiple-waves</guid>
      <pubDate>Wed, 29 Nov 2023 22:29:18 GMT</pubDate>
    </item>
    <item>
      <title>这种认为英国脱欧导致新冠疫情的统计论点有什么问题吗？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/632657/whats-wrong-with-this-statistical-argument-that-brexit-caused-covid</link>
      <description><![CDATA[纯真的开始
我听到一个笑话，大意是“英国加入欧盟 27 年了，然后 2020 年英国脱欧，突然爆发了一场大流行 - 几率有多大？！”
我正在考虑如何进行统计分析，直觉上我怀疑正确的答案是构建列联表并执行卡方检验，或者可能是费舍尔精确检验。然而，如果我将其作为二项式检验来处理，我会不断得到似乎没有意义的结果。我不知道我的推理的缺陷在哪里。
可疑的建模
英国加入欧盟已经 28 年了，所以我们可以说，从 1 到 28 的每一年 n，全球大流行发生的概率为 pn。根据经验，我们可以假设每年大约有百分之一的机会发生全球大流行。这意味着我们的零假设实际上不是 H0: p1 = ... = p28，而是 H 0：p28 = 1/100。要计算 p 值，我看到两个选项：
P(真实世界数据 | p28 = 1/100) = (99/100)27 * 1/100 = 0.0076
或者，您可能会说之前的 27 年是无关紧要的，因为我们只是测试 p28 的值。所以也许这就像测试一次抛硬币，看看硬币是否被高度操纵。在这种情况下，我们的 p 值为：
P（真实世界数据 | p28 = 1/100）= 0.01
这两个值都远低于 0.05 的统计显着性阈值，因此我们拒绝零假设并得出结论，英国脱欧当年，发生全球大流行的可能性更高。
令人困惑的结论
除了这个简单的模型之外，我还可以想到很多原因来解释为什么这个推理是错误的 - 例如英国脱欧影响新冠肺炎的先验概率极低，最初的笑话制造者专门寻找 2019/2020 年结束的事情等等。但我只是看不出该模型的缺陷在哪里。例如，如果有人告诉我一枚硬币被操纵，正面朝上的概率为百万分之一，然后我翻转它，正面朝上，我可能会假设正面朝上的概率超过一百万。那么为什么类似的推理在这里不起作用呢？
如果这个例子太荒谬，你可以考虑另一种表述：一个朋友有一枚硬币，正面的概率为 1%。经过 27 次抛掷，结果都是正面，第 28 次抛掷，结果是反面。您的朋友想知道这是否证明他可能不小心抓到了一枚普通硬币。 （据我所知，数学应该是相同的？）]]></description>
      <guid>https://stats.stackexchange.com/questions/632657/whats-wrong-with-this-statistical-argument-that-brexit-caused-covid</guid>
      <pubDate>Wed, 29 Nov 2023 22:26:50 GMT</pubDate>
    </item>
    <item>
      <title>当推理例程报告“vcov 失败，改为使用选项 qr”时，哪些策略可以帮助修复 GAMLSS 模型 (BEINF0)？</title>
      <link>https://stats.stackexchange.com/questions/632656/what-strategies-could-help-fix-a-gamlss-model-beinf0-when-inference-routines-r</link>
      <description><![CDATA[我正在使用 GAMLSS 和 R 包 gamlss 来拟合混合线性回归模型，该模型具有一个随机效应、一个交互项，假设有 5 个主效应项（其中一个是分类变量，大约 20 个类别；它不与任何东西交互）。该发行版系列是 BEINF0 系列（beta 发行版，零膨胀）。七个数据集的每一个都有 500-5000 个观察值，这些数据集都具有相同的模型。对于我的模型，我为 $\mu$、$\sigma$ 和 &lt; span class=&quot;math-container&quot;&gt;$\nu$ 参数。我查看了蠕虫图，我不会判断它们是说我有正确的分布，但无论我尝试调整回归模型，或将 BEINF0 更改为 BEINF，我都无法改进它们;我认为蠕虫图不会提供有用的信息，或者可能是 Stasinopoulos 等人。 (2017)，尽管我不确定如何针对零膨胀 beta 分布（既不是离散分布也不是连续分布）做到这一点。
无论如何，我的问题是，在某些拟合模型上调用summary时，我收到警告vcov has failed, option qr isused。该文档称，在描述系数标准误差方面，qr 方法比 vcov 更差，因为它没有考虑 GAMLSS 拟合的多个模型中使用的因素的依赖性。我想尝试解决这个问题，找出 vcov 失败的原因，但我不知道如何解决它。但归根结底，我想要的是对我的模型系数做出有效的推断。也许参数引导方案可以允许估计协方差矩阵，但考虑到除了编程开销之外，估计每次迭代可能需要 5 分钟，我想推迟该解决方案。
建议做什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/632656/what-strategies-could-help-fix-a-gamlss-model-beinf0-when-inference-routines-r</guid>
      <pubDate>Wed, 29 Nov 2023 22:00:22 GMT</pubDate>
    </item>
    <item>
      <title>是否可以用 Python 实现增长混合模型/潜在类混合模型？如果是这样，怎么办？ R 有 lcmm 和 flexmix 等软件包用于此目的</title>
      <link>https://stats.stackexchange.com/questions/632655/is-it-possible-to-implement-growth-mixture-models-latent-class-mixed-models-in-p</link>
      <description><![CDATA[R 对有限混合模型有很多支持，以及针对更具体的混合模型的专门包，用于诸如潜在类混合模型（lcmm 包）和增长混合模型（flexmix 包）等方法，我认为这些方法是有效的相同的建模方法。
https://osf.io/preprints/psyarxiv/m58wx/
我知道 Python 中的包，例如 PyMix、scikit-mixture 和 MixtComp，但我不相信它们支持增长混合模型/潜在类混合模型。如果可以使用这些 Python 包来实现它们，有人可以帮助指导我在文档中描述使用这些包的增长混合模型的位置吗？如果 Python 中的增长混合模型有不同的库/包，有人可以指导我在哪里和/或如何实现吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/632655/is-it-possible-to-implement-growth-mixture-models-latent-class-mixed-models-in-p</guid>
      <pubDate>Wed, 29 Nov 2023 21:59:55 GMT</pubDate>
    </item>
    <item>
      <title>有关欧盟国家的数据。除了联合国数据和欧盟统计局之外还有其他什么吗？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/632648/data-on-eu-countries-something-other-than-undata-and-eurostat</link>
      <description><![CDATA[我的目标是找到有关欧盟不同国家的某些统计信息（与就业、犯罪、生活成本、移民、社交网络等相关），但是我对此很陌生，我不知道在哪里看看。
我找到了两个主要的数据来源：欧盟统计局和联合国数据，但我想知道是否还有其他一些我在谷歌上找不到的来源？]]></description>
      <guid>https://stats.stackexchange.com/questions/632648/data-on-eu-countries-something-other-than-undata-and-eurostat</guid>
      <pubDate>Wed, 29 Nov 2023 19:57:32 GMT</pubDate>
    </item>
    <item>
      <title>多类正确评分规则分解：跨类别的（加权）平均值？</title>
      <link>https://stats.stackexchange.com/questions/632644/multiclass-proper-scoring-rule-decomposition-weighted-average-across-the-cate</link>
      <description><![CDATA[我找到了一个Python函数，可以计算各种适当的评分规则的分解，例如Br​​ier得分和对数损失。然而，它似乎不接受数组作为参数，所以如果我想使用这个函数，我似乎仅限于二进制结果......
...但我想了解两个以上的类别！
但是，通过循环遍历各种分类结果和预测概率，我可以针对函数中的这一缺陷编写一个可能的破解方案。
将 pandas 导入为 pd
将 numpy 导入为 np
从 model_diagnostics.scoring 导入分解，SquaredError
np.随机.种子(2023)

# 真值矩阵：列表示三个类别
# 五个观察值，每个观察值可以属于三个类别之一
#
y_true = np.array([
    [0, 1, 0],
    [0, 1, 0],
    [1,0,0],
    [0,0,1],
    [0,0,1]
]）

# 预测矩阵
#
y_pred = np.array([
    [0.2,0.5,0.3],
    [0.1,0.8,0.1],
    [0.7,0.1,0.2],
    [0.6,0.1,0.3],
    [0.2,0.3,0.5]
]）

&#39;&#39;&#39;
# 尝试用数组来做，但失败了
#
分解（
    y_true，
    y_预测，
    评分函数 = SquaredError()
）
&#39;&#39;&#39;

# 循环遍历类别以获得“分解”结果每个类别的信息
#
dfs = []
对于范围 (3) 内的 i：
    
    d = 分解(
        y_true[:, i],
        y_pred[:, i],
        评分函数 = SquaredError()
    ）
    
    # 创建一个数据框，每个类别占一行
    #
    df_now = pd.DataFrame()
    df_now[“N”] = [np.sum(y_true[:, i])]
    df_now[“校准错误”] = d[“校准错误”]
    df_now[“歧视”] = d[“歧视”]
    df_now[“不确定性”] = d[“不确定性”]
    df_now[“分数”] = d[“分数”]
    
    # 将该数据框保存到列表中
    #
    dfs.append(df_now)

# 连接所有单行数据框
#
df = pd.concat(dfs).reset_index(drop = True)

# 四列的平均值，按每个类别的实例加权
#
错误校准 = np.sum(df[“错误校准”] * df[“N”])/np.sum(df[“N”])
歧视 = np.sum(df[“歧视”] * df[“N”])/np.sum(df[“N”])
不确定性 = np.sum(df[“不确定性”] * df[“N”])/np.sum(df[“N”])
分数 = np.sum(df[&quot;分数&quot;] * df[&quot;N&quot;])/np.sum(df[&quot;N&quot;])

当我尝试并根据每个类别的实例数加权计算每个组件（错误校准、歧视、不确定性和总分）的平均值时，我是否会得到每个组件的正确结果，就像我计算了“正确”使用以数组作为参数的函数的方式？如果没有，是否有其他方法可以仅使用逐个类别的结果来查找整个数据集的分解？
（奖励：对于其他评分规则或可以观察到多个类别的多标签问题，故事是否会发生变化？）]]></description>
      <guid>https://stats.stackexchange.com/questions/632644/multiclass-proper-scoring-rule-decomposition-weighted-average-across-the-cate</guid>
      <pubDate>Wed, 29 Nov 2023 19:05:34 GMT</pubDate>
    </item>
    <item>
      <title>解释系数分类变量</title>
      <link>https://stats.stackexchange.com/questions/632638/interpretation-coefficients-categorical-variables</link>
      <description><![CDATA[我正在使用一个大型面板数据集来长期研究许多公司。在样本期内，其中一些公司收到分析师的负面展望。同样，在整个样本期内，一些公司从分析师那里得到了积极的前景。许多其他公司没有收到任何展望。
我估计了以下模型，但很难解释这些系数：
$Dependent\_variable_{i,t}=截距+Large_{i}+Negative_{i}+Positive_{i}+Negative\_event_{i,t}+Positive \_event_{i,t}+后\_负\_事件_{i,t}+后\_正\_事件_{i,t}+负_{i}×大_i+正_i×大_i+负\_事件_{i,t} \ ×大_i+正\_事件_{i,t}×大_i+后\_负\_事件_{i,t}×大_{i}+后\_正\_事件_{i,t}×大_{i}+行业\_FE+行业\_FE×大_{i}+控制_{i,t}+ϵ_{i,t}$
自变量的描述/定义：

对于市值较大的公司，$Large_i$ 等于 1，否则为零。

对于（在我的样本期间的某个时刻）从分析师处获得负面展望的公司，$Negative_i$ 等于 1。 $Positive_i$ 的类似定义

$Negative\_event_{i,t}$ 在公司成立后 30 天内等于 1  $i$ 经历降级（即该公司$i$ 的评级仅为 1，其他公司则不然）。 $Positive\_event_{i,t}$ 的定义类似。

$Post\_Negative\_Event{i,t}$ 在 30 天之后期间等于 1 （即公司 i 的 $Negative\_event_{i,t}$ 期结束后）直至样本期结束。


我为行业固定效应添加了虚拟变量，其中能源行业被省略。此外，我还添加了大型指标和行业固定效应之间的交互。
任何有关解释该模型系数的帮助将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/632638/interpretation-coefficients-categorical-variables</guid>
      <pubDate>Wed, 29 Nov 2023 18:00:21 GMT</pubDate>
    </item>
    <item>
      <title>独立但非同分布随机变量的中心极限定理</title>
      <link>https://stats.stackexchange.com/questions/632592/central-limit-theorem-for-independent-but-non-identically-distributed-random-var</link>
      <description><![CDATA[我的问题是关于证明Lyapunov CLT（每个均值都是$0$，$\delta = 1$）。它类似于这个问题，但没有对遵循伯努利分布的随机变量进行任何假设。
这个想法是使用泰勒展开式：
$\psi_{X_1}(t) = 1 - \frac{1}{2}\mathbb{E}X_1^2t^2 - \frac{i}{6}\ mathbb{E}X_1^3t^3 + o(t^3)$。
与维基百科条目一样，定义 $s_n^2 = \Sigma_{i = 1}^n\sigma_i^2$。然后 $\psi_{X_1}(\frac{t}{s_n}) = 1 - \frac{1}{2}\mathbb{E}X_1^2\frac{t ^2}{s_n^2} - \frac{i}{6}\mathbb{E}X_1^3\frac{t^3}{s_n^3} + o(\frac{t^3}{s_n^ 3})$.
如果满足李亚普诺夫条件 ($\delta = 1$)，我会看到 $\lim_{n\ rightarrow\infty}\psi_{X_1}(\frac{t}{s_n}) = 1 - \frac{1}{2}\mathbb{E}X_1^2\frac{t^2}{s_n^2} + o(\frac{t^3}{s_n^3})$。
定义$S_n = X_1 + \dots + X_n$。如果随机变量是 i.i.d.，则缩放后方差为 $1$、$\psi_{\frac{S_n} {\sqrt{n}}}$ 涉及将泰勒展开式提高到 $n$ 次方。但由于随机变量分布不同，$\psi_{\frac{S_n}{s_n}}$ 是 $n$ 条款。如何操作它以便我可以使用 $e^x = \lim_{n\rightarrow\infty}(1 + \frac{x}{n})^n$&lt; /跨度&gt;？
（如何将 $s_n^2$ 除法转换为除以 $n$，这是通过在 i.i.d. 情况下对 $\sqrt{n}$ 进行平方来实现的吗？）]]></description>
      <guid>https://stats.stackexchange.com/questions/632592/central-limit-theorem-for-independent-but-non-identically-distributed-random-var</guid>
      <pubDate>Wed, 29 Nov 2023 06:56:54 GMT</pubDate>
    </item>
    <item>
      <title>具有高方差的数据集的协方差矩阵倾向于协方差矩阵（假设它以均值为中心）</title>
      <link>https://stats.stackexchange.com/questions/632552/covariance-matrix-of-a-dataset-with-high-variance-tends-to-the-covariance-matrix</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/632552/covariance-matrix-of-a-dataset-with-high-variance-tends-to-the-covariance-matrix</guid>
      <pubDate>Tue, 28 Nov 2023 17:12:03 GMT</pubDate>
    </item>
    <item>
      <title>广义加性混合模型 (GAMM) 的显着性测试 - mgcv::gam</title>
      <link>https://stats.stackexchange.com/questions/632523/significance-testing-on-generalized-additive-mixed-models-gamms-mgcvgam</link>
      <description><![CDATA[我想知道是否有人对比较两个 GAMM 的性能有任何见解？
具体来说，我想比较两个模型：

一种“嵌套模型”，其中包含指定为单独响应变量的平滑年龄项 s(age) 和性别项 sex。
“复杂模型”带有 s(age,by=sex) 术语。

我的理解是，前者本质上是后者的嵌套版本，因为后者将适合两个平滑/样条项——一个用于男性，一个用于女性——而前者只适合单个全局平滑项/样条术语（如果这是正确的术语）。
我想确定衰老轨迹中是否存在显着的性别二态性。在标准多元线性回归 (MLR) 模型中，我可以包含 age^n*sex 交互作用并检查 p 值，但添加平滑项使问题变得复杂（模型还包含随机效应，因此需要 GAMM）。 summary(complex_model) 打印输出为每个性别的平滑拟合指定了一个单独的 p 值，使得性别二态性的解释更加复杂。我不认为它是与 MLR 模型中相同意义上的交互项。然而，我似乎很清楚，复杂模型相对于嵌套模型的整体模型性能的显着改善仍然可以作为性别二态性的证据。
由于这两个模型都有对数似然，我可以看到使用似然比检验 (LRT) 的论点。然而，我知道 GAMM 的一些特性使得它们的分析不像其他类型的模型那么简单，因此我对不加批判地使用 LRT 持谨慎态度。我也知道我可以比较两个模型的 AIC，但我不清楚如何测试模型的“显着差异”两个 AIC 值之间，或者如果这是可能的。因此，我想知道是否有另一种可靠的方法来比较这两个模型的性能，特别是提供 p 值的模型。
这里有更多信息，以防有帮助：

模型是在 R 中使用 mgcv::gamm() 生成的
我指的summary()是“lme”选项，因为“gam”是选项似乎忽略了模型中指定的随机效应。
“lme”的打印输出摘要为“线性混合效应模型通过最大似然拟合”，因此从技术上讲它可能不是 GAMM，尽管它是使用 mgcv:gamm() 命令生成的(?)
]]></description>
      <guid>https://stats.stackexchange.com/questions/632523/significance-testing-on-generalized-additive-mixed-models-gamms-mgcvgam</guid>
      <pubDate>Tue, 28 Nov 2023 13:22:40 GMT</pubDate>
    </item>
    </channel>
</rss>