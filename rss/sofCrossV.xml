<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 17 Oct 2024 09:18:40 GMT</lastBuildDate>
    <item>
      <title>评分者间信度/一致性（100 位评分者，1 项）</title>
      <link>https://stats.stackexchange.com/questions/655888/inter-rater-reliability-agreement-100-raters-1-item</link>
      <description><![CDATA[我对可靠性/一致性有疑问。
100 名评估员（教师）根据 5 项标准（介绍、眼神接触等）评估 1 名学生的演讲。每位评估员对每项标准进行评分。每项标准均按 5 分制评分。
我现在想分别计算每项标准的评估员间可靠性。换句话说，例如，教师对眼神接触标准的评估在多大程度上达成一致。
由于我只想分析 1 项的可靠性，我认为许多常见的可靠性方法并不适用（Krippendorf 的 alpha、ICC）。
所以我的问题是如何计算这种一致性/可靠性？非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655888/inter-rater-reliability-agreement-100-raters-1-item</guid>
      <pubDate>Thu, 17 Oct 2024 09:10:43 GMT</pubDate>
    </item>
    <item>
      <title>如果单个数据集可作为零假设，为什么不能使用 t 检验？</title>
      <link>https://stats.stackexchange.com/questions/655887/why-can-a-t-test-not-be-used-if-a-single-data-set-is-available-as-a-null-hypothe</link>
      <description><![CDATA[我有一个数据集，我想比较其中是否有变化。但是，我的零假设仅基于一个数据点。但为什么我不能将这个数据点识别为平均值，以便我可以使用它来确定 t 检验？]]></description>
      <guid>https://stats.stackexchange.com/questions/655887/why-can-a-t-test-not-be-used-if-a-single-data-set-is-available-as-a-null-hypothe</guid>
      <pubDate>Thu, 17 Oct 2024 09:05:35 GMT</pubDate>
    </item>
    <item>
      <title>查找具有十进制自由度的 p 值</title>
      <link>https://stats.stackexchange.com/questions/655884/finding-p-value-with-decimal-degree-of-freedom</link>
      <description><![CDATA[我正在学习 Welch 的 t 检验，我成功地发现，在双样本检验中，$t=2.968$，自由度为 $5.1$。然后我使用在线 p 值计算器计算 0.05 显著性水平下的 p 值。结果如下。

问题是我不明白数字 $0.030478$ 是如何生成的。我尝试查看双尾 t 分布表，但我不知道如何从表中插入 p 值。

有人能解释一下为什么 $0.030478$ 是这里的 p 值吗？是否只使用 t 分布表和计算器就可以得到这个数字？我想学习如何在没有在线计算器帮助的情况下得到这个数字。提前谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655884/finding-p-value-with-decimal-degree-of-freedom</guid>
      <pubDate>Thu, 17 Oct 2024 06:24:44 GMT</pubDate>
    </item>
    <item>
      <title>如果我的结果变量是名义的，我可以做差异分析吗？</title>
      <link>https://stats.stackexchange.com/questions/655881/can-i-do-a-difference-in-difference-analysis-if-my-outcome-variable-is-nominal</link>
      <description><![CDATA[当结果变量是名义变量且具有两个以上无特定顺序的类别时，我还能进行差异差异分析吗？
当负面经济冲击来袭时，我对配偶之间的协调性很感兴趣。我将协调性测量为离散变量，如果家庭中的丈夫和妻子都在工作，则取值为 1；如果丈夫在工作而妻子不在工作，则取值为 2；如果妻子在工作而丈夫不在工作，则取值为 3；如果两人都不工作，则取值为 4。
经济冲击是通过处理和时间虚拟变量的相互作用来衡量的。如果家庭来自受影响地区，则处理虚拟变量取值为 1，否则取值为 0。时间虚拟变量在冲击后时间段取值为 1，在冲击前时间段取值为 0。]]></description>
      <guid>https://stats.stackexchange.com/questions/655881/can-i-do-a-difference-in-difference-analysis-if-my-outcome-variable-is-nominal</guid>
      <pubDate>Thu, 17 Oct 2024 03:36:26 GMT</pubDate>
    </item>
    <item>
      <title>我的 XGBoost 模型是否仍然过度拟合（二元分类）？</title>
      <link>https://stats.stackexchange.com/questions/655878/is-my-xgboost-model-still-overfitting-binary-classifcation</link>
      <description><![CDATA[我正在尝试使用 XGBoost 构建二元分类模型。我确保将数据分为训练集、验证集和测试集。我使用二分搜索执行了特征选择、提前停止和超参数调整。
我在随机生成的随机状态下测试了模型，看起来与之前相比，过度拟合有所减少（如学习曲线所示），但平均指标仍然可疑：
平均准确率：0.9965
平均精度：0.98039
平均召回率：1.0
平均 F1 分数：0.98989

]]></description>
      <guid>https://stats.stackexchange.com/questions/655878/is-my-xgboost-model-still-overfitting-binary-classifcation</guid>
      <pubDate>Thu, 17 Oct 2024 02:49:54 GMT</pubDate>
    </item>
    <item>
      <title>特征中的自相关如何破坏线性回归？</title>
      <link>https://stats.stackexchange.com/questions/655877/how-does-autocorrelation-in-a-feature-disrupt-linear-regression</link>
      <description><![CDATA[我正在运行一个线性回归模型，其中一个特征显示出自相关。我试图了解这会如​​何影响我的模型，以及解决它的最佳方法是什么。
据我所知，自相关特征的主要问题是该特征系数的标准误差 (SE) 可能会被夸大。发生这种情况的原因是，当存在自相关时，样本方差会产生偏差。
我的问题是：
1 - 受影响特征系数的 SE 膨胀是唯一的问题吗？例如，自相关是否也会在残差中产生自相关？
2 - 处理自相关的一种方法是对时间序列进行差分。但是，如果时间序列在不同滞后处显示序列自相关，我该如何处理？
3-Ridge 或 Lasso 等正则化技术是否有助于解决自相关的问题？
我正在寻找一些关于如何有效处理此问题的直觉或建议。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655877/how-does-autocorrelation-in-a-feature-disrupt-linear-regression</guid>
      <pubDate>Thu, 17 Oct 2024 02:36:49 GMT</pubDate>
    </item>
    <item>
      <title>如何表明计数与每次计数的不同持续时间无关？</title>
      <link>https://stats.stackexchange.com/questions/655875/how-to-show-that-counts-are-not-associated-with-the-different-durations-over-whi</link>
      <description><![CDATA[科学背景
有一篇出版物[1] 包含相关数据：Zenodo，GitHub。Zenodo 数据缺少两列，而 GitHub 数据缺少几行。
该出版物/数据来自一项关于微塑料对沙蟹影响的实验。 64 只螃蟹被放在单独的罐子里，其中 32 只每四天在水中加入三根微塑料纤维，最多 71 天。
最后计算每只螃蟹体内（我想也包括螃蟹身上）的微塑料纤维数量（在 71 天之前死亡的螃蟹被冷冻）。这在线性混合效应模型中用作固定效应，称为“内化纤维数量”。
科学问题
“内化纤维数量”这个名称似乎不对。如果纤维被摄入然后排出怎么办？生存时间与纤维计数的图表没有显示出太多的关系：

问题
有什么方法可以表明计数与计数累积的不同持续时间之间存在/不存在显着关联？
我的尝试
模型
我在 R 中拟合了以下 GLM（名称根据 Zenodo 数据修改，txs = 治疗螃蟹的一半数据):
glm(num_of_Yellow_fibers_ingested ~ log(num_of_days_alive) + 1, family = poisson(), data = txs)
使用 summary() 得出的结果：



param
估计
标准差。错误
z 值
Pr(&gt;|z|)




(截距)
0.87576
0.69172
1.266
0.205


log(num_of_days_alive)
-0.07686
0.18669
-0.412
0.681



我将其解释为“不，没有太多由于估计值较小、标准误差较大以及 log(num_of_days_alive) 的 Pr() 较小，因此“计数与计数累积的不同持续时间之间的关联”。
我的理由
泊松结果听起来很合适，因为它是计数数据。光纤数量是有上限的，但我没有更好的主意。
我怀疑我可能只对这些数据使用了 lm(counts ~ time)，看看上面的图。
我使用 log(time) 作为预测因子，因为我读到这样做可以让你结合不同曝光时间的数据，系数表示速率随时间的变化。
相关代数：
$$ y \sim Poisson(\lambda)$$
$$\lambda = \mu/\tau$$
$$log(\lambda) = log(\mu/\tau)$$
$$log(\lambda) = log(\mu) - log(\tau) = \alpha + \beta*x$$
$$log(\mu) = log(\tau) + \alpha + \beta*x$$
其中 $\mu$ = 预期事件数，$\tau$ = 时间。
参考文献
[1] &quot;环境相关浓度的微塑料纤维对太平洋鼹鼠蟹 (Emerita analoga) 死亡率和繁殖的影响。&quot; Horn DA；Granek EF；Steele CL。2019 年。]]></description>
      <guid>https://stats.stackexchange.com/questions/655875/how-to-show-that-counts-are-not-associated-with-the-different-durations-over-whi</guid>
      <pubDate>Wed, 16 Oct 2024 23:50:23 GMT</pubDate>
    </item>
    <item>
      <title>如何用语言表达 t 检验结果</title>
      <link>https://stats.stackexchange.com/questions/655858/how-to-verbalise-t-test-results</link>
      <description><![CDATA[我正在阅读统计数据，昨天我问了问题为什么两个不同的 t 检验会得出不同的结果。
statmerkur 给出了以下答案

没有矛盾。双侧 $t$ 检验的拒绝域由以下公式给出：
$$
\left(-\infty, t_{0.05 /2}(1.6778)\right] \cup \left[-t_{0.05 /2}(1.6778), \infty\right) \approx \left(-\infty, -5.2\right] \cup \left[5.2, \infty\right),
$$
其中 $t_{0.05 /2}(1.6778)$ 是学生 $0.05 / 2 = 0.025$ 分位数class=&quot;math-container&quot;&gt;$t$ 分布，自由度为 $1.6778$。

但我不懂数学背景。我想利用这些（“解码”）知识将其转移到其他 t 检验，从而解释其他数据（我在问题中没有提出）。]]></description>
      <guid>https://stats.stackexchange.com/questions/655858/how-to-verbalise-t-test-results</guid>
      <pubDate>Wed, 16 Oct 2024 13:20:37 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归无法生成分类协变量的系数</title>
      <link>https://stats.stackexchange.com/questions/655856/logistic-regression-failing-to-generate-coefficents-for-categorical-covariate</link>
      <description><![CDATA[我有一个二元目标变量，表示新销售机会的产生 (1) 或产生失败 (0)。机会可能恰好在前 60 天内有营销接触点 (mkt_flag=1)，也可能没有营销接触点 (0)。营销接触点自其日期起最多 60 天内可以“有效”地产生机会。这意味着我们可以有以下目标变量和预测变量组合：机会是 + 市场是。机会否 + 市场是。机会是 + 市场否。但是：有机会否 + 市场否的记录。频率表如下：
。
但是，当尝试在 SAS 中对包括 MKT 标志变量的机会目标进行建模时，我得到的 mkt 标志变量的估计值为“0”，这可能是由于 mkt 变量在目标上的分布。对于这种不平衡协变量分布的情况，有什么想法可以建模吗？目的是估计 mkt 标志变量与 opp 目标的关联。]]></description>
      <guid>https://stats.stackexchange.com/questions/655856/logistic-regression-failing-to-generate-coefficents-for-categorical-covariate</guid>
      <pubDate>Wed, 16 Oct 2024 11:54:20 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归的 Frisch-Waugh-Lovell 定理</title>
      <link>https://stats.stackexchange.com/questions/655855/frisch-waugh-lovell-theorem-for-poisson-regression</link>
      <description><![CDATA[我有一个泊松模型，具有以下真实关系：
$$E(y \mid x, z)=exp(bx+cz)$$
是否可以在这里应用 Frisch-Waugh-Lovell 定理的某些非线性版本？
（请注意，之前的帖子试图提出同样的问题，但问题的文本包含错误 - 例如 1) 没有正确指定条件平均值和 2) 可能过于具体地说明了 FWL 的非线性版本是什么样子 - 并且没有收到任何相关回复。）]]></description>
      <guid>https://stats.stackexchange.com/questions/655855/frisch-waugh-lovell-theorem-for-poisson-regression</guid>
      <pubDate>Wed, 16 Oct 2024 11:07:49 GMT</pubDate>
    </item>
    <item>
      <title>ODE 系统场景的问题[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655848/problem-with-ode-system-scenario</link>
      <description><![CDATA[我有一个用于传播 HIV 病毒的 ODE 系统：
$$dx1dt = a1 * x1 * (p1 - x1) + a2 * x2 * (p1 - x1) + e * (p1 - x1) - r1 * x1
$$
$$dx2dt = a3 * x1 * (p2 - x2) + a4 * x2 * (p2 - x2) + a5 * y * (p2 - x2) + e * (p2 - x2) - r2 * x2$$
$$
dydt = c1 * x2 * (q - y) + c2 * z * (q - y) + e * (q - y) - r3 * y
$$
$$ dzdt = d1 * y * (r - z) + e * (r - z) - r4 * z$$
对于所有大于 1 的项，但 $p=0.1$ 且 $p1=10,p2=10$ 且 $q=r=50$

我们同时对双性恋女性和男性（p1 和 p2）以及异性恋男性和女性（q 和 r）进行操作。
首先，我们有一个没有移除/死亡减法（每个方程中没有负项）的模型。
因此，随着时间的推移，我们必须得出接受检查的人数都将是 HIV 阳性。
但是在还加入了移除/死亡减法之后，我的模型看起来仍然与之前的图相同，并且图表在任何时候都没有减少。
我同时使用了 $\tt Python$ 中的 odeint 包 和 数值方法 ( Euler )，并得到了相同的图。
但是，为什么我在减去移除/死亡 $\left(-kx_{1},-kx_{2}\right) ?$ 时没有得到减少的结果呢？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655848/problem-with-ode-system-scenario</guid>
      <pubDate>Wed, 16 Oct 2024 08:53:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么经验贝叶斯估计量没有像预期的那样占据主导地位？</title>
      <link>https://stats.stackexchange.com/questions/655839/why-is-the-empirical-bayes-estimator-not-dominating-like-its-supposed-to</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655839/why-is-the-empirical-bayes-estimator-not-dominating-like-its-supposed-to</guid>
      <pubDate>Wed, 16 Oct 2024 03:58:04 GMT</pubDate>
    </item>
    <item>
      <title>苏联卡车编号 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/655833/soviet-truck-numbers</link>
      <description><![CDATA[我正在尝试交叉验证苏联卡车号码。以下事实不清楚，我找不到来源 - 在 1937 年马格尼托哥尔斯克关闭之前，苏联进口了 1200 万辆福特卡车。但是我可以验证其中的某些部分。

1960 年，苏联每天消耗 200-300 万桶柴油。
每辆卡车的典型柴油消耗量为每天 1-2 桶。
苏联卡车较小，因此消耗量要多几倍。
1960 年之前，苏联在国内生产了少量卡车。

综合所有这些，似乎可以肯定，1960 年代的苏联卡车车队只能是更早进口的，他们不可能生产出那么多卡车，也不可能从租借法案中获得数百万辆卡车。
这个问题中的哪些部分说法是正确的真的吗？
迁移到其他交易所，因为这与主题无关（？）。
就上下文而言，福特当时每年生产一百万辆卡车，但可能会发送额外的套件。]]></description>
      <guid>https://stats.stackexchange.com/questions/655833/soviet-truck-numbers</guid>
      <pubDate>Tue, 15 Oct 2024 22:51:48 GMT</pubDate>
    </item>
    <item>
      <title>我对 t 检验和单尾检验有两种不同的表述</title>
      <link>https://stats.stackexchange.com/questions/655796/i-have-two-different-statements-for-the-t-test-and-the-single-tail-test</link>
      <description><![CDATA[我想检查一个组 (ct2) 的值是否大于 ct1 的值。为此，我应用了 T 检验，结果如下。
t = 5.194，df = 1.6778，p 值 = 0.05009
备选假设：均值的真实差异不等于 0
95% 置信区间：
-0.001132843 1.961132843
样本估计值：
x 的均值 y 的均值
2.10 1.12

我已将显著性水平 (alpha) 指定为 0.05。由于结果 p 值 = 0.05009 高于 0.05，根据 t 检验，均值的变化不应归类为显著。
但是，我已经在单尾检验中测试了这个样本，正如您在图中看到的，t 检验大于临界值！这表明零假设被拒绝，并且发生了变化。矛盾的说法怎么会出现？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655796/i-have-two-different-statements-for-the-t-test-and-the-single-tail-test</guid>
      <pubDate>Tue, 15 Oct 2024 09:58:49 GMT</pubDate>
    </item>
    <item>
      <title>生物测定数据 (LD50) 的荟萃分析</title>
      <link>https://stats.stackexchange.com/questions/655116/meta-analysis-of-bioassay-data-ld50</link>
      <description><![CDATA[我正在尝试进行荟萃分析，并寻求有关如何做某些事情的帮助。
我会尝试解释：
我正在处理 30 份手稿的结果比较。它们都发布了半数致死剂量 (LD50) 数据，其上限和下限在许多人群中具有 95% 的置信度（它们是通过概率回归获得的），以及用于获得该 LD50 的样本量。
所有手稿的方法都是相同的，因此数据不需要标准化，可以直接比较原始发布的数据。但标准差在许多研究中差异很大。
一些手稿还发布了耐药率。我们也可以使用这些数据进行比较。抗药性比率 (RR) 也包含 95% 置信区间的限值。
如果需要，我可以根据限值和样本量计算每个人群的 SD 和 SE。
我们想要：
比较所有手稿人群的致死剂量。致死剂量可以是效果，可以使用原始值。一些人群的值较高，而其他人群的值较小。由于限值较大，某些人群的偏差值非常高。
问题 1：我们如何计算每份手稿的全局效果大小？我们是否对已发表的致死剂量取平均值？在这种情况下，我们如何处理标准差，如果这是正确的做法，我们如何汇总它？
问题 2：如果我想将所有手稿的所有人群汇总到一个表中，然后使用该表的子集（按国家/地区、按年份）。最好的方法是什么？
问题 3：我可以用 log10 转换数据来标准化数据。但是在这个过程中，我丢失了标准差，而标准差是计算均值差异所必需的。
我可以使用 minitab、jamovi、jasp、stata 和 medcalc 统计软件。我经常使用 jamovi 中的 ESCI 和 MAJOR 包（R 包）进行这种分析。 Jasp 也有一个基于 MAJOR 的元分析模块。
这是我正在处理的数据的一个示例（我有 200 多条记录）：
样本国家省份 LD50 下限上限 RR 下限上限 SD SE
150 阿根廷卡塔马卡 0,266 0,181 0,385 2,679 1,66 4,324 0,637 0,052
160 阿根廷门多萨 0,375 0,18 0,773 3,771 2,462 5,779 1,914 0,151
145 阿根廷圣路易斯 0,199 0,141 0,269 2 1,275 3,138 0,393 0,033
149 阿根廷 萨尔塔 0,784 0,553 1,077 7,891 4,999 12,455 1,632 0,134
220 阿根廷 萨尔塔 12,8 11 14 99 78,8 125,3 11,351 0,765
如果需要比较的话，我有一个“基线”人口。]]></description>
      <guid>https://stats.stackexchange.com/questions/655116/meta-analysis-of-bioassay-data-ld50</guid>
      <pubDate>Mon, 30 Sep 2024 13:55:16 GMT</pubDate>
    </item>
    </channel>
</rss>