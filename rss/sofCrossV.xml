<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 11 Jul 2024 01:06:46 GMT</lastBuildDate>
    <item>
      <title>从数学上来说，Fisher 方法下的组合测试为何通常比单独测试更强？</title>
      <link>https://stats.stackexchange.com/questions/650839/how-the-combined-test-under-fishers-method-is-generally-stronger-than-individua</link>
      <description><![CDATA[我已在多种材料中研究了 Fisher 方法的定义，但不清楚 Fisher 方法为何比单个测试更强大。我猜情况并非总是如此，即在某些情况下组合测试可能表现更差，但不确定在哪些情况下。为了验证这一点，我尝试设置以下简单设置，并想比较单个测试和组合测试中的 II 类错误。
假设有 2 个单个测试具有相同的假设 $H_0: \mu=\mu_0$、$H_a:\mu &gt; \mu_0$，其 p 值分别为 $p_1$ 和 $p_2$。 Fisher 的方法通过计算以下检验统计量来合并 p 值：
$$\chi^2=-2(ln(p_1)+ln(p_2))$$
设 $\mu_a$ 为满足 $H_a$ 的值。设 $\beta_f$ 和 $\beta_1$ 分别为组合检验和第一次检验的 2 型错误。我想知道在哪些条件下 $\beta_f&lt;\beta_1$ 和反之亦然，但不确定如何继续。上述公式是否完整，还是需要进一步假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/650839/how-the-combined-test-under-fishers-method-is-generally-stronger-than-individua</guid>
      <pubDate>Thu, 11 Jul 2024 00:57:26 GMT</pubDate>
    </item>
    <item>
      <title>当 $\sigma^2 > 0$ 时，概率 PCA 中的后验均值会向 0 移动</title>
      <link>https://stats.stackexchange.com/questions/650838/posterior-mean-in-probabilistic-pca-shifts-towards-0-when-sigma2-0</link>
      <description><![CDATA[我们知道，在概率​​ PCA 中，$$x = Wz + \mu + \epsilon, \epsilon \sim N(0, I)$$
后验可以推导出为 $$z|x \sim N\left(M^{-1}W^T(x-\mu), \sigma^{-1}M\right)$$
其中 $M = W^TW + \sigma^2I$。
在 Bishop 的模式识别中，它说当 $\sigma^2&gt;0$ 时，后验均值相对于正交投影向原点移动。有人能帮我理解这句话吗？当 $\sigma^2 &gt; 0$ 时，不是不再有正交投影了吗？那么这实际上是在比较什么？在这种情况下，向原点移动在数学上意味着什么？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650838/posterior-mean-in-probabilistic-pca-shifts-towards-0-when-sigma2-0</guid>
      <pubDate>Wed, 10 Jul 2024 23:00:48 GMT</pubDate>
    </item>
    <item>
      <title>入门数据分析研究论文 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/650837/research-paper-for-introductory-data-analytics</link>
      <description><![CDATA[我正在学习一门入门数据分析课程，这门课程要求我们使用统计方法撰写一篇小型研究论文。我们打算找到使用相当简单的技术（如 OLS）的过去研究，并使用更新的数据或额外的预测变量自己尝试该方法。
我感兴趣的领域是经济学，但我很难找到一篇可以借鉴的论文。大多数论文从数学角度来看都太高级了，使用的方法超出了本课程的预期。
有人能给我指出一篇符合这个标准的论文吗？理想情况下应该是经济学方面的，但金融/商业也可以接受。
感谢您的任何帮助或见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/650837/research-paper-for-introductory-data-analytics</guid>
      <pubDate>Wed, 10 Jul 2024 22:47:39 GMT</pubDate>
    </item>
    <item>
      <title>X 中有噪声的回归。我应该使用无偏估计量还是 OLS 估计量进行预测？</title>
      <link>https://stats.stackexchange.com/questions/650835/regression-with-noises-in-x-should-i-use-the-unbiased-estimator-or-the-ols-esti</link>
      <description><![CDATA[我正在处理一个包含变量 $Y$ 和 $X$ 的数据集。我假设
$$ Y = \beta X + \epsilon $$
满足 OLS 的所有假设。根据行业知识，我知道理论上 $\beta = 1$。但是，我知道 $X$ 包含噪声，这意味着我观察到 $\hat{X} = X + u$，其中 $u$ 表示噪声。当我运行 OLS 估计时，我发现估计的 $\beta$ 小于 1，这是由于 $X$ 中的噪声，这增加了 $X$ 的方差。
我有来自不同组的不同对 $(Y, X)$。我可以通过观察在较大的组中（其中数据变异性被中心极限定理降低）来验证我的假设，拟合的$\beta$更接近 1。
鉴于此，我的问题是：如果我想进行样本外预测，我应该使用 1 作为我的$\beta$还是应该使用有偏差的 OLS $\beta$ 估计值？
一方面，似乎使用无偏的$\beta$ 1 是更好的选择，因为它在理论上是无偏的。但是，如果我假设相同的噪声 $u$ 存在于我的样本外 $X$ 中，我的残差项将具有更大的方差，因为它包括项 $\beta^2 \text{Var}(u)$。使用较小的、有偏差的 $\beta$ 可能有助于减少残差方差，尽管存在偏差。
这是一个偏差-方差权衡场景吗？如果我的目标是最小化样本外残差 MSE，那么这里最好的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/650835/regression-with-noises-in-x-should-i-use-the-unbiased-estimator-or-the-ols-esti</guid>
      <pubDate>Wed, 10 Jul 2024 21:49:14 GMT</pubDate>
    </item>
    <item>
      <title>随机变量加权平均的二阶矩</title>
      <link>https://stats.stackexchange.com/questions/650833/second-moment-of-weighted-average-of-random-variables</link>
      <description><![CDATA[我偶然发现了 SOA 考试 P 列表中的第 254 个问题
https://www.soa.org/globalassets/assets/Files/Edu/edu-exam-p-sample-quest.pdf
我对其中描述的解决方案感到困惑
https://www.soa.org/globalassets/assets/files/edu/edu-exam-p-sample-sol.pdf
基本上，他们解决问题的方式是通过声明泊松变量加权平均值的二阶矩是二阶矩的加权平均值来表示的。对于一阶矩（期望值），这显然通常是正确的，但对于二阶矩，人们期望
$E[(aX+bY)^2] = a^2 E[X^2] + 2abE[XY] + b^2 E[Y^2]$。
根本没有提到独立性或相关性，只是说这些是泊松变量，它们的均值为正。这样说是否足以说明
$E[(aX+bY)^2] = a E[X^2] + bE[Y^2]$
如解决方案所述？]]></description>
      <guid>https://stats.stackexchange.com/questions/650833/second-moment-of-weighted-average-of-random-variables</guid>
      <pubDate>Wed, 10 Jul 2024 20:06:19 GMT</pubDate>
    </item>
    <item>
      <title>拉普拉斯继承定律悖论</title>
      <link>https://stats.stackexchange.com/questions/650830/laplace-law-of-succession-paradox</link>
      <description><![CDATA[（我是贝叶斯概率的新手……所以如果这很幼稚，请多多包涵！）
拉普拉斯继承定律：对于二进制下一个事件，(r+1)/(n+2)
Jaynes（“概率论”，第 571 页）似乎将其扩展为：当事件有 k 种可能性时，(r+1)/(n+k)。
现在假设：你抽出 4 个黄球。假设你有 1&#39;000 种颜色可能性（可能是因为你的比色计只有 3 位数字）。
那么下一个球是黄色的概率将是：(4+1)/(4+1000) 约 0.5%
但你也可以这样看待它：球可以是黄色或非黄色（1&#39;000 种颜色中的任何其他颜色）。因此，由于您有一个二元事件：黄色与非黄色，黄色的概率将是 (4+1)/(4+2) = 5/6
这与之前的数字完全不同（您可以说特定非黄色的概率是 (5/6) / 999。
那么下一个球是黄色的概率到底是多少：0.5% 还是 5/6？]]></description>
      <guid>https://stats.stackexchange.com/questions/650830/laplace-law-of-succession-paradox</guid>
      <pubDate>Wed, 10 Jul 2024 19:20:34 GMT</pubDate>
    </item>
    <item>
      <title>R：如何计算检测平均 beta reg 变化的功率？</title>
      <link>https://stats.stackexchange.com/questions/650829/r-how-to-calculate-power-to-detect-a-change-in-mean-beta-reg</link>
      <description><![CDATA[我有兴趣计算通过特定效应大小检测我的平均响应变量变化的功效，但我不知道如何开始。我的 Y 变量是平均植物覆盖率 0-100% 覆盖率（每个站点 10 次随机重复调查的平均值，以小数表示，包括 0 和 1），我想计算检测未来假设覆盖变化的效应大小的功效（单/配对样本检验）。每年在同一位置重复采样植物覆盖率（随机截距）。
我将这个问题输入 chatgpt，但我想验证这是正确的方法。它回复说建议我制作两个单独的模型（一个模型中我的协变量没有影响，另一个模型中它有指定的效应），然后计算每个模型的两个平均响应之间的差异。然后它说使用 t 检验计算功效。
这个答案看起来正确吗？我如何才能准确地模拟出与原始数据相似的数据（如何在 rbeta 中选择 alpha 和 beta）？我如何才能使年份协变量对 cover 产生特定的影响（chatgpt 假设了一个连续协变量并将其设置为 0.5）？此外，我知道我的回答不是概率，但我不应该使用功率计算来计算比例，因为这是 0-&gt;1 数据（即使用 pwr::pwr.p.test）？
我尝试模拟数据以便更容易发布这个问题，但它在摘要输出中没有达到预期的效果。
set.seed(123)

n &lt;- 100
x1 &lt;- rep(seq(1, 10), each = 10)
x2 &lt;- seq(1, 10)

y &lt;- rbeta(n, 2, 5) # 模拟响应变量（beta 分布）

# 创建数据框
data &lt;- data.frame(cover = y, year = x1, site = x2)
data$site &lt;- as.factor(data$site)

我认为这比 betareg 更好，因为它允许随机截距
library(glmmTMB)
# 拟合 beta 回归模型
model &lt;- glmmTMB(y ~ year + (1|site), data=data, family=beta_family(link=&quot;logit&quot;))

Chatgpt:
# 模拟数据以进行功效计算：
# 要计算功效，通常需要在零假设和备择假设下模拟数据。

# 零假设 (H0)：假设预测变量 x1 没有影响。
# 备择假设 (H1)：假设预测变量 x1 具有一定大小的影响。
# 假设您想要计算检测 x1 的两个值之间的平均响应变量 y 的差异的功效：x1 = 0 和 x1 = 0.5。

# 在 H0 下模拟数据（x1 无影响）
data_null &lt;- data.frame(y = rbeta(n, 2, 5), x1 = rnorm(n))

# 在 H1 下模拟数据（x1 = 0.5 的影响）
data_alt &lt;- data.frame(y = rbeta(n, 2, 5), x1 = rnorm(n, mean = 0.5))

model_null &lt;- betareg(y ~ x1, data = data_null)
model_alt &lt;- betareg(y ~ x1, data = data_alt)

# 在 H0 下计算 x1 = 0.5 和 x1 = 0 之间的平均响应变量 (y) 差异
mean_y_alt &lt;- predict(model_alt, newdata = data_null)
mean_y_null &lt;- predict(model_null, newdata = data_null)
effect_size &lt;- mean(mean_y_alt - mean_y_null)

# y 的标准差
sd_y &lt;- sd(predict(model, type = &quot;response&quot;))

# 样本大小
n &lt;- nrow(data)

# 显着性水平
alpha &lt;- 0.05

# 计算功效
power &lt;- pwr.t.test(n = n, delta = effect_size, sd = sd_y, sig.level = alpha, type = &quot;two.sample&quot;)$power
power

这是对比例数据的更好测试，不是吗？
power &lt;- pwr.p.test(h = effect_size, n = n, sig.level = alpha, alternative = &quot;two.sided&quot;)$power
power
]]></description>
      <guid>https://stats.stackexchange.com/questions/650829/r-how-to-calculate-power-to-detect-a-change-in-mean-beta-reg</guid>
      <pubDate>Wed, 10 Jul 2024 19:08:56 GMT</pubDate>
    </item>
    <item>
      <title>当误差不服从正态分布（拉普拉斯分布）时，OLS 与 MLE</title>
      <link>https://stats.stackexchange.com/questions/650828/ols-vs-mle-when-errors-are-not-normally-distributed-laplace-distributed</link>
      <description><![CDATA[我们说，在高斯-马尔可夫定理的假设下，OLS 是 BLUE。高斯-马尔可夫定理没有提到误差的正态性。

如果误差按照拉普拉斯分布分布，那么根据高斯马尔可夫定理，OLS 仍然是 BLUE 吗？

使用拉普拉斯误差的 MLE 估计，我们会得到最佳线性估计量将最小化 MAE，而不是 SSE。因此，当误差不正态时，MLE 估计不再是 OLS 估计。这是什么意思？哪个更适合使用？

]]></description>
      <guid>https://stats.stackexchange.com/questions/650828/ols-vs-mle-when-errors-are-not-normally-distributed-laplace-distributed</guid>
      <pubDate>Wed, 10 Jul 2024 19:07:05 GMT</pubDate>
    </item>
    <item>
      <title>简单的 OLS 回归假设</title>
      <link>https://stats.stackexchange.com/questions/650826/simple-ols-regression-assumptions</link>
      <description><![CDATA[请原谅我；我是统计学的新手。我正在尝试更好地理解 OLS 简单线性回归，并对相关假设有一个直观的认识。根据我的研究，我确定了关于 $Y = \beta_0 + \beta_1$X + $\epsilon$ 中的 $\epsilon$ 项的四个必要假设：
$\epsilon$ 被假定为一个随机变量，....

平均值为 0
正态分布
X 的每个值都有恒定的方差 ($\sigma^2$)
观测值之间独立

我的问题与前两个假设有关。大多数教科书和在线资源都没有阐明前两个假设。也就是说，$\epsilon$ 在每个 X 值或跨 X 值处均值为 0 的假设是否成立？同样，$\epsilon$ 在每个 X 值或跨 X 值处呈正态分布的假设是否成立？如能得到任何帮助，我们将不胜感激。
根据我自己的理解，我相信这两个假设应该适用于 X 的每个值，而不是跨 X 的值，因为我们想使用这些假设来创建一个分布，其中$Y = \beta_0 + \beta_1X + \epsilon$呈正态分布，其平均值为$\beta_0 + \beta_1X$，方差为$\sigma^2$。如果前两个假设适用于跨 X 值的值，我们就不能确定 X 的每个值的平均值都是 0，并且呈正态分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/650826/simple-ols-regression-assumptions</guid>
      <pubDate>Wed, 10 Jul 2024 18:55:29 GMT</pubDate>
    </item>
    <item>
      <title>多元宇宙分析与 SEM 之间切换的效果方向</title>
      <link>https://stats.stackexchange.com/questions/650825/direction-of-effects-switching-between-multiverse-analysis-and-sem</link>
      <description><![CDATA[我正在运行一个分析，研究一些不同过程的宏观预测因子​​。由于宏观预测因子​​（更高层次的东西，如平均受教育年限、劳动力参与率、GDP 等）基本上是因果沙拉/汤，我首先运行了多元宇宙分析。我对我的预测因子的所有可能组合进行了回归分析，然后绘制了 t 值。然后，我提取 t 值永远不会超过零（因此它们总是在同一个方向）并且在其分布的某个点也超过显着性阈值的预测因子。
然后，我将我提取的预测因子放入 SEM 模型中。但是 - 我的其中一个预测因子从多元宇宙分析中的始终为负变为 SEM 中的正。这对我来说没有意义。这是可以预料到的事情吗？如果是这样，我该如何理解这一点？或者这是否像我认为的那样奇怪？如果这像我认为的那样奇怪 - 我应该尝试在这个分析中排除哪些问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/650825/direction-of-effects-switching-between-multiverse-analysis-and-sem</guid>
      <pubDate>Wed, 10 Jul 2024 18:17:52 GMT</pubDate>
    </item>
    <item>
      <title>HMM 与马尔可夫模型相比的“难度”</title>
      <link>https://stats.stackexchange.com/questions/650824/hmms-difficulty-compared-to-a-markov-model</link>
      <description><![CDATA[给定一个 HMM，很容易计算出针对观测值的最佳近似 $n$-gram 模型。例如，对于 $N=1$，我们有 $p(w_i|w_{i-1}) = \sum_{s_i,s_{i-1}}p(w_i,s_i|w_{i-1},s_{i-1})=\sum_{s_i,s_{i-1}}p(w_i|s_i)p(s_i|s_{i-1}) p(s_{i-1} | w_{i-1})$。
这可以根据 HMM 的参数（及其平稳分布）来计算。
说 HMM “困难” 似乎很自然如果其在真实模型下的观测熵（用前向-后向算法计算）明显低于最佳近似 $n$-gram 模型的熵。如果它们接近，则意味着潜​​在变量不起重要作用，您只需计算观测计数即可达到同样的效果。
是否有一种原则性的方法来采样“困难”的 HMM，例如，其熵与最佳近似 $n$-gram 模型的熵之间至少有 $d$ 的差异的 HMM？]]></description>
      <guid>https://stats.stackexchange.com/questions/650824/hmms-difficulty-compared-to-a-markov-model</guid>
      <pubDate>Wed, 10 Jul 2024 17:44:39 GMT</pubDate>
    </item>
    <item>
      <title>条件逻辑如何处理三个或更多替代方案的选择集中的二元预测变量？</title>
      <link>https://stats.stackexchange.com/questions/650823/how-does-conditional-logit-deal-with-binary-predictors-in-choice-sets-of-three-o</link>
      <description><![CDATA[我对 clogit 感兴趣，而不是多项 Logit，以及预测因子对只能通过其属性识别的 n 个替代方案的选择的总体影响（即选择集很少在案例中重复）。
在只有两个替代方案的选择集中，二元预测因子（例如性别）的影响可以从替代方案之间存在差异的情况（例如一个是女性，另一个是男性）中估计出来。我理解没有差异的情况不会对该系数的估计做出贡献。
如果同一选择集中有三个替代方案，其中两个对该二元预测因子采用相同的值，而一个不同，会发生什么？同样的问题也适用于具有 &gt;2 个类别的名义预测因子。]]></description>
      <guid>https://stats.stackexchange.com/questions/650823/how-does-conditional-logit-deal-with-binary-predictors-in-choice-sets-of-three-o</guid>
      <pubDate>Wed, 10 Jul 2024 17:31:40 GMT</pubDate>
    </item>
    <item>
      <title>当 $X$ 为多元正态分布时，如何计算 $P(f_1(X) = \text{max}(f_1(X), \dots, f_K(X))$？</title>
      <link>https://stats.stackexchange.com/questions/650822/how-to-calculate-pf-1x-textmaxf-1x-dots-f-kx-when-x-is-mult</link>
      <description><![CDATA[假设我有一个多元分布 $\mathbf{X} \sim \text{MVN}(\mathbf{\mu}, \mathbf{\Sigma})$ 和一组 $K$ 个标量函数，分别为 $\mathbf{X}$、$f_1(\mathbf{X}), \dots, f_K(\mathbf{X})$。假设我们可以做出额外的假设，即 $f_k$ 对于所有 $k$ 都是平滑且可微的。有没有办法通过分析得出$P(f_1(\mathbf{X}) = \text{max}(f_1(\mathbf{X}), \dots, f_K(\mathbf{X}))$？
我知道一个解决方案是从$\mathbf{X}$中抽样，并在每个样本实现中$\tilde{\mathbf{X}}$计算$f_1(\tilde{\mathbf{X}}), \dots, f_K(\tilde{\mathbf{X}})$，然后计算样本的比例，其中$f_1(\tilde{\mathbf{X}})$ 是最大的。如果可能的话，我更倾向于解析解，甚至是近似解，例如使用 delta 方法（如果存在的话）。
最终目标是对联合估计的参数模型执行一种模型选择和平均，其中 $\mathbf{X}$ 是来自所有模型的系数向量（联合估计以获得它们的联合分布）。$f_k(\mathbf{X})$ 是在每个模型上计算的量，用于选择最佳模型。我感兴趣的不是选择一个单一的模型作为最佳模型，而是考虑到数据的随机性，每个模型都是最佳模型的概率。这些概率将用于一种模型平均。]]></description>
      <guid>https://stats.stackexchange.com/questions/650822/how-to-calculate-pf-1x-textmaxf-1x-dots-f-kx-when-x-is-mult</guid>
      <pubDate>Wed, 10 Jul 2024 17:28:53 GMT</pubDate>
    </item>
    <item>
      <title>如何基于 R 中 nnet 包的 multinom() 函数进行模型比较？</title>
      <link>https://stats.stackexchange.com/questions/650831/how-to-perform-model-comparison-based-on-multinom-function-of-nnet-package-in</link>
      <description><![CDATA[我的自变量是性别和顺序，因变量是干预（包括3种干预方式）。我建立了多项逻辑回归模型来检验性别和顺序对干预的影响。主要步骤为：
我先用multinom()函数建立空模型，再建立全模型，最后用anova()函数比较模型。
代码如下：
model_null&lt;- multinom(intervention~ 1,data = test_data)
model_full&lt;- multinom(intervention~ 1+ gender+sequence,data = test_data)
anova(model_full,model_null,test = &quot;Chisq&quot;)

结果输出如下：
enter image description here
我有两个问题：1.我不确定这种分析方法是否正确，因为这是我第一次使用多项逻辑回归。因为线性回归一般都是用这种方法做模型比较，所以我就采用了这种方法；2.如果正确的话，我不知道如何得到模型比较的卡方值，目前输出的结果没有卡方值，只有P值。
如果能给点帮助，不胜感激~~]]></description>
      <guid>https://stats.stackexchange.com/questions/650831/how-to-perform-model-comparison-based-on-multinom-function-of-nnet-package-in</guid>
      <pubDate>Wed, 10 Jul 2024 13:30:12 GMT</pubDate>
    </item>
    <item>
      <title>如何在 GLM 二元回归中选择一个特征作为偏移量</title>
      <link>https://stats.stackexchange.com/questions/650787/how-to-choose-a-feature-as-an-offset-in-glm-binary-regression</link>
      <description><![CDATA[是否有任何统计测试可以确定特征 A 应该是偏移量，而不是特征 B 和特征 C。
据我所知，如果在保险建模中，通常，偏移量与风险敞口有关。但在欺诈检测或任何其他二元分类中，偏移量是什么？我想到的是转移金额可以作为偏移量。但如何证明或提供证据证明转移金额最好用作偏移量。]]></description>
      <guid>https://stats.stackexchange.com/questions/650787/how-to-choose-a-feature-as-an-offset-in-glm-binary-regression</guid>
      <pubDate>Wed, 10 Jul 2024 08:36:47 GMT</pubDate>
    </item>
    </channel>
</rss>