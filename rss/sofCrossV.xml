<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 21 Sep 2024 06:21:16 GMT</lastBuildDate>
    <item>
      <title>两匹马样本及其伤口大小的配对或非配对 t 检验</title>
      <link>https://stats.stackexchange.com/questions/654681/paired-or-unpaired-t-test-in-two-samples-of-horses-and-their-wound-size</link>
      <description><![CDATA[有一群马。假设随机选择了两组。每组的每个成员都有完全相同的伤口。
您想确定在伤口上涂抹麦卢卡蜂蜜是否会在一段时间后影响伤口的大小。因此，一组伤口未经治疗，另一组用麦卢卡蜂蜜治疗。
问题是这两个组是否独立，即未治疗组的伤口大小独立于或取决于另一组的伤口大小。
这将决定是否使用配对或非配对 t 检验。
在我看来，未经治疗的马的伤口大小与接受治疗的马的伤口大小无关。是的，两匹马都有自然愈合能力，但这在马之间是独立的（它们不是克隆对），而且由于它们可能有独立的遗传和免疫系统，它们的环境也可能不同，等等。
我认为未经治疗的马的伤口大小可能会有所不同，但这不会影响已治疗伤口的大小，反之亦然，因此是独立变量。两组马或伤口不成对。]]></description>
      <guid>https://stats.stackexchange.com/questions/654681/paired-or-unpaired-t-test-in-two-samples-of-horses-and-their-wound-size</guid>
      <pubDate>Sat, 21 Sep 2024 04:59:12 GMT</pubDate>
    </item>
    <item>
      <title>R 中的生态学：mgcv 包中的错误“eval（family$initialize）中的错误：值超出范围”</title>
      <link>https://stats.stackexchange.com/questions/654680/ecology-in-r-error-in-mgcv-package-error-in-evalfamilyinitialize-values-o</link>
      <description><![CDATA[我试图在 R 中拟合一个模型，该模型显示了深度和沉积物类型如何影响海草密度（响应），并收集了一个约 5000 行的数据框。为了便于数据收集，我们将海草密度的离散值设置为 5 个类别，从 1 到 5（每个类别代表一个百分比覆盖范围）。数据框中没有 NA 值。数据中将存在空间自相关，因此我添加了一个带有纬度和经度的平滑项来解释这一点。
我使用带有 logit 链接的 OCAT 系列来解释序数类型数据，并将 theta 设置为 4（因为密度的离散值之间有 4 个“步骤”）。如果其中任何内容不正确，请告诉我。
这是我的模型：
model_gam_spatial &lt;- gam(Density ~ s(Latitude, Longitude) + Depth + Substrate.type, 
data = seagrass_clean, family = ocat(theta = 4, link = &quot;logit&quot;))

当我尝试运行模型时，我不断收到此错误消息
&quot;Error in eval(family$initialize) : values out of range&quot;

有人能指出我做错了什么吗？或者还有其他提示吗？如果有更好的模型适合我的数据，也请告诉我。任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654680/ecology-in-r-error-in-mgcv-package-error-in-evalfamilyinitialize-values-o</guid>
      <pubDate>Sat, 21 Sep 2024 04:55:46 GMT</pubDate>
    </item>
    <item>
      <title>比较不同时间间隔内的投资组合表现</title>
      <link>https://stats.stackexchange.com/questions/654679/comparing-portfolio-performance-across-different-time-intervals</link>
      <description><![CDATA[我想比较 2022 年 1 月发布的一份美国上市公司名单（这意味着我考虑 2022 年 1 月至 2023 年 1 月）与 2022 年 8 月发布的另一份美国上市公司名单（这意味着我考虑 2022 年 8 月至 2023 年 8 月）。本质上，我将计算市场投资组合（sp500 或其他）的超额收益以及两个投资组合在各自时间范围内的无风险利率（即，2022 年 1 月至 2023 年 1 月投资组合的超额收益将通过使用例如 2022 年 1 月至 2023 年 1 月期间的 sp500 和无风险利率来计算，而另一个投资组合的超额收益将使用 2022 年 8 月至 2023 年 8 月期间的 sp500 和无风险利率计算）。一旦计算出每个投资组合的超额收益，是否有可能/有效地进行统计测试以查看这些超额收益之间是否存在显着差异（并获得有意义的结果，例如在这些投资组合所处的市场条件下，一个投资组合是否优于另一个投资组合）？
如果我没有弄错的话，计算超额收益应该在技术上标准化结果（因为由于考虑不同的时间间隔等而导致的市场条件差异应该嵌入基准本身），这意味着对两个投资组合的超额收益差异进行统计测试似乎是可行的。但我并不完全确定，如果有人能告诉我我是否错了，我将不胜感激。如果我错了，还有其他方法可以使用吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654679/comparing-portfolio-performance-across-different-time-intervals</guid>
      <pubDate>Sat, 21 Sep 2024 04:41:42 GMT</pubDate>
    </item>
    <item>
      <title>关于包含集合S的最小sigma-代数的问题</title>
      <link>https://stats.stackexchange.com/questions/654678/a-problem-about-smallest-sigma-algebra-containing-a-set-s</link>
      <description><![CDATA[对于任何子集 S$\subseteq2^{\Omega}$，证明包含 S 的最小 $\sigma-algebra$ 由 $\bigcap\limits_{S\subseteq F\subseteq 2^{\Omega}, F\space is\space a\space\sigma-algebra}F$ 给出（提示：你应该证明它确实是 $\sigma-algebra$ 并且它是包含 S 的最小子集。）]]></description>
      <guid>https://stats.stackexchange.com/questions/654678/a-problem-about-smallest-sigma-algebra-containing-a-set-s</guid>
      <pubDate>Sat, 21 Sep 2024 04:40:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么 PyTorch 中的阻尼系数不像传统 SGD 中的动量系数那样与动量系数互补？</title>
      <link>https://stats.stackexchange.com/questions/654675/why-is-the-damping-coefficient-in-pytorch-not-complementary-to-the-momentum-coef</link>
      <description><![CDATA[在传统的带动量随机梯度下降 (SGD) 中，动量项 $m_t$ 的更新规则通常写为：
$$
m_t = \beta m_{t-1} + (1 - \beta) g_t
$$
其中：

$m_t$ 为动量项，
$g_t$ 为当前梯度，
$\beta$ 为动量系数，
$1 - \beta$ 称为阻尼系数。

在此公式中，动量系数$\beta$和阻尼系数$1 - \beta$之和为 1。
然而，在官方 PyTorch 文档中，阻尼系数的定义不同，为$1 - \eta$，这导致动量系数和阻尼系数之和不为 1 的情况。PyTorch 中动量的更新规则如下：
$$
m_t = \beta m_{t-1} + (1-\eta)g_t
$$
有人能解释一下为什么 PyTorch 会这样定义阻尼系数吗？为什么 PyTorch 不遵循动量和阻尼系数总和为 1 的经典定义？]]></description>
      <guid>https://stats.stackexchange.com/questions/654675/why-is-the-damping-coefficient-in-pytorch-not-complementary-to-the-momentum-coef</guid>
      <pubDate>Sat, 21 Sep 2024 02:19:46 GMT</pubDate>
    </item>
    <item>
      <title>财务模型中 3 个参数的 MLE</title>
      <link>https://stats.stackexchange.com/questions/654667/mle-over-3-parameters-in-financial-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654667/mle-over-3-parameters-in-financial-model</guid>
      <pubDate>Fri, 20 Sep 2024 17:29:36 GMT</pubDate>
    </item>
    <item>
      <title>如何计算多个参与者和观察员的单一变异系数？</title>
      <link>https://stats.stackexchange.com/questions/654676/how-do-i-calculate-a-single-coefficient-of-variation-with-multiple-participants</link>
      <description><![CDATA[我通常会使用 ICC 作为评分者信度的指标。但是，有期刊希望我使用变异系数来做到这一点。我认为变异系数是单个变量的指标，而不是面板的指标，那么生物统计学中在面板上计算此指标的惯例是什么？
设置是，我有 n 名观察员，他们都对 m 名患者进行测量，因此我有 nxm 个数据点需要汇总为单个指标。我见过其他论文这样做，但没有解释他们如何进行计算。]]></description>
      <guid>https://stats.stackexchange.com/questions/654676/how-do-i-calculate-a-single-coefficient-of-variation-with-multiple-participants</guid>
      <pubDate>Fri, 20 Sep 2024 15:37:41 GMT</pubDate>
    </item>
    <item>
      <title>变换随机变量的特征函数</title>
      <link>https://stats.stackexchange.com/questions/654637/characteristic-function-of-transformed-random-variable</link>
      <description><![CDATA[考虑一个随机变量 $X$ 和一个函数 $g(\cdot)$。令 $Y:=g(X)$，令 $\phi_X(\cdot), \phi_Y(\cdot)$ 分别为 $X,Y$ 的特征函数 (cf)。假设 $\phi_X$ 处处非零。
我问的是 $\phi_Y$ 处处也非零的条件。
这种条件的一个例子可能是 $X$ 的分布是无限可分的，而 $g$ 是一个加法函数（因此 $Y$ 的分布也是无限可分的）。但有没有更一般的条件可用？]]></description>
      <guid>https://stats.stackexchange.com/questions/654637/characteristic-function-of-transformed-random-variable</guid>
      <pubDate>Fri, 20 Sep 2024 08:04:56 GMT</pubDate>
    </item>
    <item>
      <title>随机森林预测区间 - 新观测值的总和</title>
      <link>https://stats.stackexchange.com/questions/654629/random-forest-prediction-intervals-sum-of-new-observations</link>
      <description><![CDATA[我对随机森林还比较陌生，但一直在尝试各种可用的 R 包。到目前为止一切顺利。但对于我的应用程序，我正在用多个预测变量建模一个响应变量，这很好，但我真正需要做的是使用生成的模型来预测新数据的值。这很好，我收到一组新的预测变量并预测新的未观察响应变量的值。
但是，问题是我对这些单独的新变量并不真正感兴趣，而是对它们的总和感兴趣。这也很好，我只是将每个预测值相加，这就是我感兴趣的参数估计。但是，我真的还想估计与此相关的预测区间。我可以看到有各种方法和 R 包可以对单个变量执行此操作，例如 Meinhausen 的分位数回归森林方法（和包 quantregForest），基于 bootstrapping 或 jackknife 的替代方法。但尚未找到允许对派生参数（例如对各个变量求和）进行预测区间的方法？
我发现了关于随机森林预测区间的先前问题的一些非常有趣的评论，但没有关于如何对派生参数进行预测的明显信息。也许我很天真，错过了它？
我发现最接近的是这个：
随机森林预测区间的总和？
这基本上是我的确切问题，但实际上没有得到充分的回答。
如果有人有任何想法或可以指出我对此事的一些讨论，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654629/random-forest-prediction-intervals-sum-of-new-observations</guid>
      <pubDate>Fri, 20 Sep 2024 05:40:10 GMT</pubDate>
    </item>
    <item>
      <title>根据多个独立标准进行调节是否会增加共同因素的预期值？</title>
      <link>https://stats.stackexchange.com/questions/654614/does-conditioning-on-multiple-independent-criteria-increase-the-expected-value-o</link>
      <description><![CDATA[我正在尝试解决经济学论文中的一些问题。
我有一个模型，其中$A\sim\operatorname N(0,1),$ 工人的永久能力。$\varepsilon_1,\varepsilon_2 \sim\operatorname N(0,1),$ 对工人能力的“噪音”。$A,\varepsilon_1,\varepsilon_2$ 是独立的。
在每个时期$(t)$ 工人从容易的工作晋升到困难的工作（只有两个工作），如果$\hat A_t = A+εt &gt; A^*.$ 在 $t=1$ 时，所有的工人都从事轻松的工作，这意味着：在 $t=2,$ 时，从事艰苦工作的工人对他们来说：$A+ε_1 &gt; A^*.$ 这里出现了一个转折，公司可以将员工从艰苦的工作岗位调到轻松的工作岗位：在 $t=3$ 时，从事艰苦工作的员工只是那些对他们来说 $(A+ε_1&gt;A^*) \wedge (A+ε_2&gt;A^*).$ 的员工。看着同一批员工，我试图证明在 $t=3$ 时从事艰苦工作的员工的期望值大于在 $t=3,$ 时从事艰苦工作的员工，因此：
\begin{align}
&amp; \operatorname E[A\mid (A+ε_1&gt;A^*) \wedge (A+ε_2&gt;A^*)] \\[6pt] &gt; {} &amp; \operatorname E[A\mid (A+ε_1&gt;A^*)]
\end{align&gt;
这是真的吗？我遗漏了什么吗？尝试了很多次使用风险率来证明这一点，但结果却不是这样。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654614/does-conditioning-on-multiple-independent-criteria-increase-the-expected-value-o</guid>
      <pubDate>Thu, 19 Sep 2024 17:52:50 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 0 至 1 范围内变量的优势比</title>
      <link>https://stats.stackexchange.com/questions/654542/how-to-interpret-odds-ratio-for-variables-that-range-from-0-to-1</link>
      <description><![CDATA[我该如何解释逻辑回归模型中变量的几率比，该变量是一个“比率”，即介于 0 和 1 之间的值？在这种情况下，单位是什么？
例如，假设我正在对篮球投篮数据进行建模，如果球员投篮成功，我的响应变量等于 1，如果投篮失败，则等于 0。此外，我有一个解释变量，即球队到那时为止的投篮准确率，这个变量的范围是 0 到 1。那么，我该如何解释这个变量的系数的几率比？因为我不能说它会增加 1 个单位，因为变量不能超过大于 1 的值。请问有什么关于如何解释这一点的提示吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654542/how-to-interpret-odds-ratio-for-variables-that-range-from-0-to-1</guid>
      <pubDate>Wed, 18 Sep 2024 11:35:11 GMT</pubDate>
    </item>
    <item>
      <title>关于双变量分布的估计</title>
      <link>https://stats.stackexchange.com/questions/654493/on-estimation-of-bivariate-distribution</link>
      <description><![CDATA[我正在处理一个非负、绝对连续的双变量随机向量，其累积分布函数为$F(x, y)$，我正在尝试使用 Epanechnikov 核来估计$$\int_0^{t_1}F^2(x_1,t_2)dx_1$$，$k(u)=\frac{3}{4}(1-u^2),|u|\leq1$，它的 cdf 定义为$K(z)=\int_0^z k(u)du=\frac{1}{4}(3z-z^3)$。对此的估计定义为
$$\widehat{I}=\frac{1}{n^2h_1^2h_2^2}\int_0^{t_1}\left(\sum_{i=1}^n K\left(\frac{x_1-X_{1i}}{h_1}\right)K\left(\frac{t_2-X_{2i}}{h_2}\right)\right)^2dx_1$$
其中 $K(z)=\int_0^z k(x)dx$ 为 ，$k$ 为核。
我使用双变量 Gumbel 分布在我的模拟中。下面是我的代码，但是我在为双变量数据选择合适的带宽时遇到了困难，我得到的估计值与真实值有显著差异。
library(stats)
library(ks)
n &lt;- 40
lambda1 = 2
lambda2 = 0.5
theta = 0.5

for (i in 1:100) {
X1 &lt;- rexp(n, lambda1)
term=1+lambda1*theta*X1
X2 = rgamma(n, (runif(n) &gt; 1 - theta/term)+ 1,(
lambda2*term)
h1 &lt;- 0.5
h2 &lt;- 0.55
t1 &lt;- 0.2
t2 &lt;- 0.3

epan_kernel_cdf &lt;- function(u) {
0.25 * (3 * u - u^3)
}

积分1 &lt;- sapply(X1, function(Xi) h1 * epan_kernel_cdf((t1 - Xi) / h1))
积分2 &lt;- sapply(X2, function(Yi) h2 * epan_kernel_cdf((t2 - Yi) / h2))

被积函数 &lt;- function(x1) {
kernel_cdf_values &lt;- sapply(X1, function(X1) epan_kernel_cdf((x1 - X1) / h1))
prod_kernel &lt;- kernel_cdf_values * 积分2
sum_kernel &lt;- sum(prod_kernel)
(sum_kernel)^2
}

x_vals &lt;- seq(0, t1, length.out = 10000)
dx &lt;- x_vals[2] - x_vals[1]
sum_approx &lt;- sum(sapply(x_vals, integrand)) * dx
estimated_value &lt;- (1/(n^2*h1^2*h2^2))*sum_approx
true_value &lt;- 0.98

bias[i] &lt;-estimated_value[1] - true_value
MSE[i] &lt;-mean((estimated_value[1] - true_value[1])^2)
}

bias
MSE
bias1 &lt;-mean(bias)
bias1
MSE1 &lt;-mean(MSE)
MSE1

我遇到的一些具体问题面临：

为我的双变量数据选择合适的带宽。
我的估计值与真实值 (0.98) 相差甚远。

如能提供任何关于如何改进带宽选择或我应该在代码中进行的其他调整的见解或建议，我将不胜感激。提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654493/on-estimation-of-bivariate-distribution</guid>
      <pubDate>Tue, 17 Sep 2024 16:55:15 GMT</pubDate>
    </item>
    <item>
      <title>对零假设下 p 值的均匀分布感到困惑</title>
      <link>https://stats.stackexchange.com/questions/654484/confused-about-the-uniform-distribution-of-p-values-under-the-null-hypothesis</link>
      <description><![CDATA[我目前正在学习一门生物信息学入门课程，我对零假设下（当零假设为真时）p 值的均匀分布感到困惑。
已经广泛证明和讨论过，在正确的条件下，当零假设成立时，p 值是均匀分布的，正如这篇文章所解释的那样：为什么 p 值在零假设下是均匀分布的？。
我的困惑更多的是关于这个想法背后的直觉和实际意义。
例如，让我们考虑一个简单的（尽管是离散的）场景：抛硬币。如果掷出正面的概率（表示为&quot;1&quot;）为 $p = 0.3$，且我们进行 $1000$ 次抛掷，我们预计大多数情况下掷出正面的次数约为 $300$ 次。因此，我们预计在大多数情况下 p 值将在 $P(X &lt; 300)$ 左右（左尾 p 值，其中 $X$ 是二项式（$1000$，$p$）变量）。
但是，这似乎与 p 值在零假设下应均匀分布的想法相矛盾。如果 p 值是均匀的，那么所有 p 值是否都应该具有同等可能性，而不是聚集在某个值附近？
有人可以解释为什么这个均匀分布在这个例子中仍然成立，或者我是否误解了一些基本的东西？
我已运行以下模拟作为示例：
library(ggplot2)

n_experiments &lt;- 100000 # 实验次数（抛硬币）
n_trials &lt;- 100000 # 每个实验的试验次数
p &lt;- 0.3 # 获得“1”（成功）的概率

# 模拟实验
set.seed(123) # 为了可重复性
results &lt;- rbinom(n_experiments, n_trials, p) # 每个实验中 1 的数量

# 计算每个实验的 p 值
p_values &lt;- sapply(results, function(x) pbinom(x, n_trials, p))

# 创建用于绘图的数据框
df &lt;- data.frame(Experiment = 1:n_experiments, 
Number_of_1s = results, 
p_value = p_values)

# 绘制“1”的数量直方图
ggplot(df, aes(x = Number_of_1s)) +
geom_histogram(binwidth = 1, fill = &#39;skyblue&#39;, color = &#39;black&#39;) +
labs(title = &quot;100 次实验中 1 的数量直方图&quot;, 
x = &quot;1 的数量&quot;, 
y = &quot;频率&quot;) +
theme_minimal()

# 绘制 p 值的直方图
ggplot(df, aes(x = p_value)) +
geom_histogram(binwidth = 0.01, fill = &#39;coral&#39;, color = &#39;black&#39;) +
labs(title = &quot;100 次实验中的 p 值直方图&quot;, 
x = &quot;p 值&quot;, 
y = &quot;频率&quot;) +
theme_minimal()

我发现以下预期结果对我来说感觉矛盾，值的分布不均匀，但 p 值的分布是均匀的。

]]></description>
      <guid>https://stats.stackexchange.com/questions/654484/confused-about-the-uniform-distribution-of-p-values-under-the-null-hypothesis</guid>
      <pubDate>Tue, 17 Sep 2024 13:24:56 GMT</pubDate>
    </item>
    <item>
      <title>具有随时间变化的协变量（生存）的研究</title>
      <link>https://stats.stackexchange.com/questions/654405/a-study-with-a-time-varying-covariate-survival</link>
      <description><![CDATA[我们正在进行一项研究，定期对患者进行癌症复发检测。每四个月安排一次检查（T0、T4、T8、T12、T16、T20）。
以下数据可能具有适合采用离散时间格式的生存分析的结构。如果不正确，请告诉我。
ID TIME EVENT GENDER 
1 T0 0 M 
1 T4 0 M 
1 T8 0 M 
1 T12 1 M 
2 T0 0 F 
2 T4 1 F 
3 T0 0 M 
3 T4 0 M 
3 T8 1 M 
4 T0 0 F 
4 T4 1 F 

现在我们需要向模型中添加一个随时间变化的协变量，即吸烟。
每次预约时都会询问患者的吸烟习惯。
现在，我想知道当模型中存在因变量协变量时，以下数据结构是否合适。另外，可以使用以下函数：glm(event ~ Time + Gender + smoke, family = binomial(link = cloglog))吗？
 ID TIME EVENT GENDER SMOKE 
1 T0 0 M 0 
1 T4 0 M 1 
1 T8 0 M 1 
1 T12 1 M 1 
2 T0 0 F 1 
2 T4 1 F 0 
3 T0 0 M 1 
3 T4 0 M 0 
3 T8 1 M 1 
4 T0 0 F 0 
4 T4 1 F 0 


第二个问题是：当协变量变化的相对时间和事件时间间隔不一样时，我们还能使用上述公式吗？如果没有，我们如何创建具有适当结构的数据集，以及应该使用哪种统计模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/654405/a-study-with-a-time-varying-covariate-survival</guid>
      <pubDate>Sun, 15 Sep 2024 20:00:50 GMT</pubDate>
    </item>
    <item>
      <title>确定适度回归的对比</title>
      <link>https://stats.stackexchange.com/questions/654401/determining-contrasts-for-a-moderated-regression</link>
      <description><![CDATA[我有一个研究设计，包含 4 种治疗条件（A、B、C 和对照组）和一个连续调节器 (Mod)。我正在研究治疗的效果以及它与 Mod 对因变量 (Y) 的相互作用。
我的假设是：
H1：与对照条件相比，所有治疗条件（A、B 和 C）中的 Y 值都会更高。
H2：与 B 和 C 相比，条件 A 中的 Y 值会更高，尤其是当 Mod 值更高时。
我计划使用正交对比来编码治疗变量。我提出的对比如下：
C1：A = -1，B = -1，C = -1，对照 = 3（测试处理组和对照组之间的差异）
C2：A = 2，B = -1，C = -1，对照 = 0（测试 A 与 B 和 C 的组合）
C3：A = 0，B = -1，C = 1，对照 = 0（测试 B 与 C）
我打算运行包含这些对比及其与 Mod 的相互作用的多元回归。我预计 C1 和 C2*Mod 将显著支持我的两个假设。
这种方法正确吗？
此外，我正在考虑另一种假设：
H1：Y 在条件 A 中最高，其次是 B 和 C（预计相等），在对照条件下最低。
H2：当 Mod 较高时，这种模式尤其正确。
在这种情况下，我不知道如何对对比进行编码以反映预期的模式。有人对如何为这种情况设置对比编码/分析有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654401/determining-contrasts-for-a-moderated-regression</guid>
      <pubDate>Sun, 15 Sep 2024 15:38:21 GMT</pubDate>
    </item>
    </channel>
</rss>