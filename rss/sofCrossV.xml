<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 24 Dec 2024 18:21:49 GMT</lastBuildDate>
    <item>
      <title>预测变量在回归中可以相互关联吗？</title>
      <link>https://stats.stackexchange.com/questions/659169/can-predictors-be-correlated-with-each-other-in-regression</link>
      <description><![CDATA[这是我的设置（纵向混合效应）：

时间段：$t = 1,...,T$
集群：$j = 1,...,J$
变量：$z_{jt}$、$x_{jt}$、$y_{jt}$

最初，我想制作以下模型（Z 的当前值取决于 X 和 Y 的先前值）：
$$z_{jt} = \beta_1x_{j,t-1} + \beta_2y_{j,t-1} + \epsilon_{jt}$$
然而，就我而言，存在以下问题：

X 可能影响 Y（例如，X 的过去值和当前值可能影响 Y 的未来值）
Y 可能影响 X（例如，Y 的过去值和当前值可能影响 X 的未来值）
Z 可能同时影响 X 和 Y（例如，Z 的过去值和当前值可能影响 X 和 Y 的未来值）

因此，似乎我的数据中既有内生性问题，也有同时性问题。
我可以使用哪种建模策略来解决这些问题？这是可以使用 SEM（结构方程模型）的地方吗？还是 VAR 模型更好？]]></description>
      <guid>https://stats.stackexchange.com/questions/659169/can-predictors-be-correlated-with-each-other-in-regression</guid>
      <pubDate>Tue, 24 Dec 2024 18:04:00 GMT</pubDate>
    </item>
    <item>
      <title>有争议的观点是，PDF 的卷积可能不是 PDF</title>
      <link>https://stats.stackexchange.com/questions/659168/controversial-view-that-convolutions-of-a-pdf-might-not-be-a-pdf</link>
      <description><![CDATA[有一条帖子说，卷积公式对 f(x) * f(s-x).dx 进行积分，再次返回 PDF。我有点同意这一点。但后来，我偶然发现了这个 YouTube 视频。我在下面提供了它们的链接。
在视频的 00:15:30，如果右侧的单条曲线（三角形）是 PDF，那么当他说“这个数字 s 是该（卷积）函数的输入，相应的输出是左下方图形的面积”时，他的意思是什么。
我理解，s 取精确值的概率理想情况下应该是 0。那么他怎么能说“相应的输出是左下方图形的面积”呢？由于概率，因此面积应限制为 0。
链接：
证明 PDF 的卷积可得到 PDF
https://youtu.be/IaSGqQa5O-M?si=smyv_63FsMNkH9ly&amp;t=930]]></description>
      <guid>https://stats.stackexchange.com/questions/659168/controversial-view-that-convolutions-of-a-pdf-might-not-be-a-pdf</guid>
      <pubDate>Tue, 24 Dec 2024 17:25:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 拟合带有工具变量的负二项混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/659167/fit-negative-binomial-mixed-effects-model-with-instrumental-variables-with-r</link>
      <description><![CDATA[如何使用 R 拟合带有工具变量的固定效应负二项式模型？
我尝试过 fixest 包，但它仅支持 OLS 的工具变量，而不支持负二项式：
id &lt;- rep(seq(1,10), each=5)
year &lt;- rep(seq(2021, 2025), times=10)
df &lt;- data.frame(id=id, year=year)
df[[&quot;weight&quot;]] &lt;- rnorm(nrow(df), 100, 10)
df[[&quot;height&quot;]] &lt;- 2*df$weight+rnorm(nrow(df), 0, 5)
df[[&quot;count&quot;]] &lt;- rpois(nrow(df), df$height+rnorm(nrow(df), 0, 5))
mod &lt;- fixest::fenegbin(count ~ 1 | id | height~weight, df)

fixest::fenegbin(count ~ 1 | id | height ~ weight, df) 中的错误： 
参数“fml”不能包含由竖线（“|”）分隔的两个以上部分。IV 仅适用于“feols”。
语法为：DEP VAR ~ EXPL VARS | FIXED EFFECTS。 （不允许 IV。）

相关：https://stackoverflow.com/questions/73982152/iv-regression-in-fixed-effect-models-with-diagnostics/75144897#75144897]]></description>
      <guid>https://stats.stackexchange.com/questions/659167/fit-negative-binomial-mixed-effects-model-with-instrumental-variables-with-r</guid>
      <pubDate>Tue, 24 Dec 2024 16:55:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么在半监督 VAE 模型中将目标 𝑦 y 用作编码器的输入？</title>
      <link>https://stats.stackexchange.com/questions/659156/why-is-the-target-y-used-as-an-input-to-the-encoder-in-a-semi-supervised-vae</link>
      <description><![CDATA[正如标题所述，我理解 Kingma 的原始论文中方程 (6-7) 的数学推导。但是，由于 𝑦 已在模型中用作分类器的目标，那么将 𝑦 用作编码器的输入的目的是什么？这会不会是多余的？似乎从编码器的输入中删除 𝑦 在实践中也是可行的。]]></description>
      <guid>https://stats.stackexchange.com/questions/659156/why-is-the-target-y-used-as-an-input-to-the-encoder-in-a-semi-supervised-vae</guid>
      <pubDate>Tue, 24 Dec 2024 13:53:10 GMT</pubDate>
    </item>
    <item>
      <title>在具有许多零值的数据中选择正确的相关方法</title>
      <link>https://stats.stackexchange.com/questions/659150/picking-the-right-correlation-method-in-data-that-has-many-zero-values</link>
      <description><![CDATA[我想计算我的数据中两个基因之间的相关性。到目前为止，我所做的是计算 Pearson 或 Spearman 相关性（我更依赖 Spearman，因为基因之间没有线性关系）。
但是 - 许多细胞对基因 1、基因 2 或两者的表达为零，这导致相关性不准确和偏差。
所以我有一些选择 -

我可以只保留表达两个基因的细胞（这将删除大量细胞），然后重新计算相关性。
我应该保留零，因为它是生物学的一部分
使用对零不太敏感的其他方法，例如余弦相似度？

例如，这里有一个图 - 每个点是一个细胞，X 轴是基因 1 的表达，Y 轴是基因 2 的表达：
]]></description>
      <guid>https://stats.stackexchange.com/questions/659150/picking-the-right-correlation-method-in-data-that-has-many-zero-values</guid>
      <pubDate>Tue, 24 Dec 2024 11:42:54 GMT</pubDate>
    </item>
    <item>
      <title>何时在图学习管道（PyTorch Geometric）中执行节点/边图特征提取？</title>
      <link>https://stats.stackexchange.com/questions/659149/when-to-perform-node-edge-graph-feature-extraction-in-graph-learning-pipeline-p</link>
      <description><![CDATA[我有一个 CSV 文件，可以将其转换为 PyG 图形数据对象，用于边缘分类任务。在此之前，我想到使用 NetworkX 库添加一些功能。
但是，由于创建图形后，我将把它拆分为 train/val/test，然后使用数据加载器，我不确定基于图形的预处理应该在拆分之前完成，还是在拆分之后（在创建数据加载器之前）完成，还是在数据加载器构造内部/之后完成。
如果答案是在数据加载器构造内部/之后，这是否意味着我必须为我想要添加的每个功能实现自定义转换，基本上将图形转换为 networkx 图，提取特征，然后将图形重新转换为 pyg？最好的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659149/when-to-perform-node-edge-graph-feature-extraction-in-graph-learning-pipeline-p</guid>
      <pubDate>Tue, 24 Dec 2024 11:37:31 GMT</pubDate>
    </item>
    <item>
      <title>如何为由另外两个类组成的类设计网络和损失函数？</title>
      <link>https://stats.stackexchange.com/questions/659148/how-to-design-a-network-and-loss-function-for-classes-composed-of-two-other-cla</link>
      <description><![CDATA[给定一个包含三个类别的图像数据集，A、B 和 C，其中 C 是 A 和 B 的组合，我们希望训练一个分类器来预测：

如果只有 A，则为 A
如果只有 B，则为 B
如果 A 和 B 都存在，则为 C。

我们如何设计最终的分类层以及损失函数？
我考虑过对 C 类进行阈值处理，即使使用可学习的阈值，但这会受到数据集中类别分布的严重影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/659148/how-to-design-a-network-and-loss-function-for-classes-composed-of-two-other-cla</guid>
      <pubDate>Tue, 24 Dec 2024 11:28:42 GMT</pubDate>
    </item>
    <item>
      <title>如何选择一个固定的 $x_{t-1}$ 值来可视化 MLE 之后的条件密度 $f(x_t \mid x_{t-1})$？</title>
      <link>https://stats.stackexchange.com/questions/659146/how-to-choose-a-fixed-value-of-x-t-1-for-visualizing-conditional-density-f</link>
      <description><![CDATA[假设我已经对某个数据集进行了最大似然估计，以找到某个条件密度函数 $f(x_t\mid x_{t-1})$ 的参数，其中 RHS 将取决于 $x_{t-1}$ 的某个值。
如果我要绘制数据的直方图并与 MLE 找到的密度叠加，我将如何选择要修复哪个 $x_{t-1}$ 值进行绘图？或者在这种情况下绘图时的便利性是否不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/659146/how-to-choose-a-fixed-value-of-x-t-1-for-visualizing-conditional-density-f</guid>
      <pubDate>Tue, 24 Dec 2024 10:05:01 GMT</pubDate>
    </item>
    <item>
      <title>如何用 Python 开始使用项目反应理论</title>
      <link>https://stats.stackexchange.com/questions/659132/how-to-get-started-with-item-response-theory-in-python</link>
      <description><![CDATA[我有一个大型 CSV 文件，其中包含（String studentId、String questionId、bool isCorrect）。问题都是小学的基本数学知识，questionIds 指的是一组类似的问题。例如，我们有这样的 questionId

OPlusO（包含 2+3、5+4 等练习）
OPlusT（包含 2+10、20+4、30+7 等练习）
OPlusOWithCarry（7+8、5+9 等）
Times2（3x2、7x2 等）

一个学生可以对一个 questionId 有多个答案，我们假设所有学生练习都是在一周内完成的。 （我们有一年多的数据）
在第一阶段，我想确定问题 ID 的难度并评估学生的能力。
我认为 IRT 模型在这里很有用，所以我想开始使用它来获得一些实践经验。
但我不确定从哪里/如何开始。最好使用 Python，因为我习惯了，但其他（命令行）工具也可以。我在 Linux 上。
ChatGPT 和 Claude 都让我误以为几行代码就足够了，但都没有给出一个可行的示例。
提前谢谢，
Marc]]></description>
      <guid>https://stats.stackexchange.com/questions/659132/how-to-get-started-with-item-response-theory-in-python</guid>
      <pubDate>Mon, 23 Dec 2024 17:27:05 GMT</pubDate>
    </item>
    <item>
      <title>跨栏模型等同于零膨胀模型吗？</title>
      <link>https://stats.stackexchange.com/questions/659119/are-hurdle-models-equivalent-to-zero-inflated-models</link>
      <description><![CDATA[换句话说，障碍模型可以转换为零膨胀模型吗？
我正在查看障碍模型的维基百科页面。据我理解，障碍模型只是零概率，对于非零情况，分布严格为非零。
零膨胀模型是零概率，对于其他情况，分布包括零。
所以你可以采用零膨胀模型，将零概率分解为单一情况，并将其称为障碍模型，对吗？我遗漏了什么吗？
它们似乎都能够形成相同的总概率分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/659119/are-hurdle-models-equivalent-to-zero-inflated-models</guid>
      <pubDate>Mon, 23 Dec 2024 10:49:34 GMT</pubDate>
    </item>
    <item>
      <title>元分析中嵌套数据的模型简化</title>
      <link>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</link>
      <description><![CDATA[我正在对子组中不同程度的异质性进行荟萃分析。由于数据结构是嵌套的（效应大小嵌套在研究中），我通过添加研究的随机效应和研究内的效应大小来考虑这一点。轮廓似然图在其估计值处达到峰值。
比较具有不同程度异质性的模型和具有共同异质性估计值的模型的似然比检验是显著的。然而，在获得 $ \tau^2_\text{between} $ 和 $ \tau^2_\text{within} $ 的置信区间 (CI) 后，除了一个之外，$ \tau^2_\text{within} $ 的所有 CI 的下限均为零。一个显著的估计值仍然是适中的。
在这种情况下，将模型简化为仅在研究层面具有随机效应的两级模型是否合适，从而仅考虑研究之间的异质性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</guid>
      <pubDate>Sun, 22 Dec 2024 20:41:46 GMT</pubDate>
    </item>
    <item>
      <title>在评估 GLM 模型时，AIC 值或预测显著性的 p 值更重要吗？</title>
      <link>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</guid>
      <pubDate>Sat, 21 Dec 2024 15:14:21 GMT</pubDate>
    </item>
    <item>
      <title>使用麦当劳 Omega 作为非加权总和评分的可靠性度量是合理的</title>
      <link>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</link>
      <description><![CDATA[在最近的文献中，报告麦当劳欧米茄作为可靠性估计值显然比报告系数 alpha 更受青睐（例如 McNeish，2017）。一个经常给出的论点是，系数 alpha（或 Cronbach&#39;s alpha）假设（本质上）tau-euqivalent 测量模型，即因子载荷必须相等，而麦当劳欧米茄允许不同的载荷。由于对 omega 有多种看法，为了简单起见，我们只关注单维尺度上的总 omega，如 McNeish (2017) 所指定的那样：

（其中 $\lambda_i$ 是因子载荷，$\theta_{ii}$ 是第 i 项的误差/残差方差）
在文章中，McNeish 写道：

Omega (McDonald, 1970, 1999）是常用的复合信度测量方法，可用于多种软件程序。Omega 专为同类量表而设计，其中项目与被测构造的相关程度各不相同（即，在因子分析设置中，不会假设负载相等）。换句话说，不假设 tau 等价。当量表中的项目按单位加权以形成总量表分数但量表本身为同类时，复合信度是合适的（Bentler，2007；Geldhof 等人，2014）。单位加权量表意味着量表的总分是通过将各个项目的原始分数（或反向编码的原始分数，如果适用）相加来计算的：每个项目的权重相等。

我觉得这违反直觉：例如，假设 CFA 表明同类模型（自由载荷）比更严格的 tau 等效模型更适合样本数据，因此我们决定使用 omega 而不是系数 alpha。然而，后续分析将使用基于同等权重项目计算得出的总和/平均分数，即使我们刚刚在 CFA 中表明这种类型的测量模型不能很好地拟合我们的数据。
我的问题：
有人可以提供一些合理的解释，为什么对于由同等权重项目组成的分数报告麦当劳的 omega 是有意义的？

来源：
McNeish，D.（2017 年）。感谢系数 alpha，我们将从这里开始。心理方法，23(3)，412–433。https://doi.org/10.1037/met0000144]]></description>
      <guid>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</guid>
      <pubDate>Fri, 20 Dec 2024 12:24:36 GMT</pubDate>
    </item>
    <item>
      <title>防止时间序列数据拆分中的数据泄露</title>
      <link>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</link>
      <description><![CDATA[我正在研究机械系统的故障检测问题，目标是确定故障类型。我使用的数据集对于每种类型的故障（目标标签）都有三种大小，每种故障大小都有四种不同的工作条件，如下图所示。请注意，数据集中的每个样本都是时间序列，由于样本数量太少而且太长，因此需要将每个样本分成固定长度的块。现在的问题是如何将每个块分配给训练集或测试集，以确保公平和无偏见的评估。

在之前的研究中，常见的做法是将所有块随机分成训练集和测试集。

使用这种方法，神经网络模型通常在测试集上实现近乎完美的性能。然而，这种方法似乎存在根本缺陷，因为将近似平稳的信号分成块会导致来自同一信号的块高度相似，而相似的块可能最终出现在两个集合中，从而导致严重的数据泄漏。为了说明这种数据泄漏，我将 t-SNE 算法应用于这些块。

在此图中，每种颜色对应特定的故障类型和故障大小。请注意，来自同一样本的块紧密聚集在一起。以下是放大版的图：

我认为应该根据故障大小来拆分块。例如，故障大小为 1 和 2 的样本块应包含在训练集中，而故障大小为 3 的样本块应包含在测试集中。这可确保测试集中不存在来自训练信号的任何信息。

现在我想问：

我关于数据泄露的说法正确吗？如果正确，是否有其他方法可以更严格地证明数据泄露，例如使用相似性指标或其他可视化？
您如何看待提议的拆分方法？基于故障大小的拆分是否足以防止数据泄露？如果不是，您会推荐哪些替代拆分策略来确保公平评估？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</guid>
      <pubDate>Tue, 17 Dec 2024 15:38:37 GMT</pubDate>
    </item>
    <item>
      <title>比较两个具有不同样本量和响应水平的相同调查</title>
      <link>https://stats.stackexchange.com/questions/658307/comparing-two-identical-surveys-with-different-samples-sizes-and-response-levels</link>
      <description><![CDATA[这是一个愚蠢的问题，但我的大脑一片空白。我正尝试使用在线调查对两个样本（组织绩效）进行简单比较。要获得 80% 的 CI 和 10% 的误差幅度，我分别需要 31 和 35 个回复。我得到了这个数字，但随后不得不丢弃一些错误的提交，这使它略低于要求的水平。在这种情况下你会怎么做？此外，我是否应该尝试解释响应率的差异？
类别样本 1 样本 2
人口 110 210
80% CI 和 10% 误差幅度所需的响应 31 35
收到的回复 34 41
响应率 30% 20%
可行的响应 27 34
]]></description>
      <guid>https://stats.stackexchange.com/questions/658307/comparing-two-identical-surveys-with-different-samples-sizes-and-response-levels</guid>
      <pubDate>Thu, 05 Dec 2024 10:38:15 GMT</pubDate>
    </item>
    </channel>
</rss>