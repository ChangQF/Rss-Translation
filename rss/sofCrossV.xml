<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 27 Jan 2025 18:22:45 GMT</lastBuildDate>
    <item>
      <title>运行 Little 的 MCAR 测试</title>
      <link>https://stats.stackexchange.com/questions/660624/running-littles-mcar-test</link>
      <description><![CDATA[我正在尝试运行 Little 的 MCAR 测试，但我对处理大型数据集有疑问。我在网上看到的大多数示例仅涉及几个列变量，其中测试似乎应用于整个数据集。但是，我的数据集包含多个调查模块，并且相当大。
在这种情况下，我应该只对我特别感兴趣的变量进行子集化，还是应该包括我计划在回归中使用的协变量？
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/660624/running-littles-mcar-test</guid>
      <pubDate>Mon, 27 Jan 2025 17:40:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用等渗回归进行模型校准？</title>
      <link>https://stats.stackexchange.com/questions/660622/why-isotonic-regression-for-model-calibration</link>
      <description><![CDATA[看来，保序回归是一种常用的模型校准方法。虽然我理解保序回归保证单调递增或递减拟合，但如果您可以通过其他回归获得更平滑的拟合，并且也遵守此属性，那么为什么不应该使用这些方法呢？我理解其他方法不能保证单调函数，但如果我可以验证所得拟合对于任何类型的回归都是单调的，那么可以考虑它们吗？我只看到文献中对校准的等渗回归的单一关注，但我不确定它是否是出于任何其他原因使用的唯一回归。
这是我的可靠性曲线：

当我将等渗回归模型拟合到此时，我得到了以下结果：

如果我只拟合一个常规样条回归我得到以下结果：

这也是单调递增的。那么在这种情况下，等渗比样条有什么好处呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/660622/why-isotonic-regression-for-model-calibration</guid>
      <pubDate>Mon, 27 Jan 2025 16:16:48 GMT</pubDate>
    </item>
    <item>
      <title>批次效应作为 GLMM 和 GEE 之间的协变量</title>
      <link>https://stats.stackexchange.com/questions/660621/batch-effect-as-covariate-between-glmm-and-gee</link>
      <description><![CDATA[我有一个包含约 1000 名女性的数据集，其中约 10% 的女性患有我感兴趣的疾病。其中一些女性来自同一个家庭，大约有 525 个唯一的家庭 ID（375 对和 150 个单数）。
我想知道细菌种类（N=~600）是否与我的结果有关。由于我的数据具有非独立性，我首先想到的是单变量 GLMM：
公式 &lt;- &quot;结果 ~ 年龄 + bmi + 批次 + 细菌 + (1 | 家庭 ID)&quot;
glmer(formula, data = df, family = binomial(), 
control = glmerControl(optimizer = &quot;bobyqa&quot;,
optCtrl = list(maxfun = 2e5)), nAGQ = 40)

其中 batch 指的是处理样本以获得细菌丰度的批次，有 4 个级别（因此它是固定效应而不是随机效应，如建议）。
但是，我也在考虑使用 GEE 作为替代方案（主要是出于兴趣/学习）。当我使用以下模型时：
formula &lt;- &quot;Outcome ~ age + bmi + batch + bacteria&quot;
geeglm(formula, data = df, family = binomial, id = family_ID, 
corstr = &quot;exchangeable&quot;) 

所有细菌均不相关（最低 p 值约为 0.2），而在我的 GLMM 中，经过多重假设 (FDR) 检验后，约有 8% 的细菌相关。
有趣的是，如果我从 GEE 公式中删除 batch，通过 FDR 校正的细菌数量几乎与 GLMM 中的数量相同。但是，当我从 GLMM 中删除 batch 时，关联实际上会稍微弱一些（p 值更高，并且约 20% 的 FDR 相关细菌会丢失）。
我希望有人能帮助解释这一点。除了对这里发生的事情的一般解释外，还有一些具体问题：

“如果我的主要兴趣是细菌和结果之间的关联，那么 GEE（群体平均）还是 GLMM（个体水平）更合适？我读过各种帖子（例如这个和这个），但我仍然不清楚，因为相关性对我来说更多的是一种阻碍，而不是我感兴趣的东西。

从 GLMM 转到 GEE 时，我该如何解释 batch 明显相关性的巨大变化？


可能有用的其他信息
batch 有 4 个级别，我们知道最后一个批次是在冷冻柜中放置更长时间。虽然前三个批次的所有样品的 alpha 多样性（样品中物种数量的一般度量）相似，但最后一个批次的 alpha 多样性较低。beta 多样性（欧几里得距离）也表明存在批次效应（R-sq 1.14%；p&lt;0.001）。
几乎所有（97%）的相关个体都在同一批次中测序，这意味着每个 family_ID 的 batch 几乎总是相同的。我怀疑这可以解释为什么在 GLMM 中删除 batch 似乎没有太大变化。
排除了流行率低（&lt;10%）的细菌。]]></description>
      <guid>https://stats.stackexchange.com/questions/660621/batch-effect-as-covariate-between-glmm-and-gee</guid>
      <pubDate>Mon, 27 Jan 2025 16:16:02 GMT</pubDate>
    </item>
    <item>
      <title>如何让我的 ML 模型只优化尾部</title>
      <link>https://stats.stackexchange.com/questions/660618/how-can-i-get-my-ml-model-to-only-optimize-the-tails</link>
      <description><![CDATA[我正在研究一个不平衡的分类模型（5% 少数类），并且只关心输出分布的尾部。我想知道数据中最好的 10% 和最差的 10%。我尝试在 GBM 训练中使用贝叶斯搜索，该搜索使用 ROC AUC 的尾部作为搜索优化器，但还有更好的办法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660618/how-can-i-get-my-ml-model-to-only-optimize-the-tails</guid>
      <pubDate>Mon, 27 Jan 2025 15:18:19 GMT</pubDate>
    </item>
    <item>
      <title>具有不同链接函数的逆高斯混合效应模型中的 ICC 问题</title>
      <link>https://stats.stackexchange.com/questions/660615/issue-with-icc-in-inverse-gaussian-mixed-effects-models-with-different-link-func</link>
      <description><![CDATA[我正在开展一项使用混合效应模型分析反应时间的研究，在使用逆高斯族对我的数据进行建模时，我遇到了类内相关系数 (ICC) 的问题。我希望您的见解能更好地理解和解决这个问题。
背景
我的因变量是反应时间，它是正偏的。
我正在使用混合效应模型，对参与者 (id) 进行随机截距，对两个预测因子进行固定效应：种族和身份。
我的模型是使用 R 中的 lme4 包构建的。
以下是我测试过的模型：
带身份链接的逆高斯：
model1_rt_invGauss_identity &lt;- glmer(Reaction_time ~ Ethnicity + Identity + (1 | id),
data = data_clean,
family = inverse.gaussian(link = &quot;identity&quot;),
control = glmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5)))


ICC：调整后的 ICC = 1，未调整的 ICC = 0.811。
固定效应：系数很简单，对我来说很有意义（例如，表示反应时间的变化（以毫秒为单位）。
随机效应：残差方差非常小 (8.25e-03)，而随机截距的方差则大得多 (40.12)。

带对数链接的逆高斯：
model1_rt_invGauss_log &lt;- glmer(Reaction_time ~ Ethnicity +identity + (1 | id),
data = data_clean,
family = inverse.gaussian(link = &quot;log&quot;),
control = glmerControl(optimizer = &quot;bobyqa&quot;,optCtrl = list(maxfun = 2e5)))


ICC：调整后的 ICC = 0.420，未调整的 ICC = 0.384。
固定效应：由于系数采用对数刻度，因此更难解释。指数化后，它们表示比例变化（例如百分比），但这不如恒等链接直观。
随机效应：残差方差和随机截距方差都更加平衡。

与 lmer（高斯家族）的比较：
使用 lmer 和原始或对数转换的反应时间不会产生 ICC = 1 问题，这表明该问题特定于逆高斯家族。
问题
使用逆高斯家族时，ICC 会根据链接函数发生巨大变化：
对于恒等链接，ICC 为 1，因为残差方差几乎为零。
对于对数链接，ICC 更合理（例如 0.42）。
此外，系数的可解释性各不相同：
身份链接以原始反应时间单位提供直观、附加的解释。
对数链接稳定方差并避免 ICC = 1，但系数变为乘法且更难直接解释。
我尝试过的
诊断：
检查了两个模型的残差和方差分量。
身份链接中的残差方差始终接近零，导致 ICC 膨胀。
模型比较：
比较使用 AIC 和 BIC 的模型，对数链接始终表现更好。
替代分布：
使用高斯分布 (lmer) 避免了 ICC 问题，但没有考虑反应时间的偏斜。
我的问题
为什么逆高斯族中的链接函数选择会极大地影响 ICC？
这是由于逆高斯模型的方差假设，还是与我的特定数据结构有关（例如，参与者内高度一致的反应时间）？
对于反应时间数据，我应该优先考虑哪种链接函数？
身份链接提供直观的系数，但会增加 ICC。
对数链接解决了 ICC 问题，但使解释变得复杂。
是否有其他检查或替代方法可以尝试平衡 ICC 和可解释性？
修改随机效应结构或使用不同的优化器是否有助于稳定身份链接模型中的残差方差？
提前感谢您的见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/660615/issue-with-icc-in-inverse-gaussian-mixed-effects-models-with-different-link-func</guid>
      <pubDate>Mon, 27 Jan 2025 14:23:36 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助实施针对二元分类严重类别不平衡的建议解决方案</title>
      <link>https://stats.stackexchange.com/questions/660613/need-help-implementing-a-suggested-solution-to-severe-class-imbalance-w-binary</link>
      <description><![CDATA[信息：
二元分类问题。少数类在整个数据集中的频率为 1.16%。我的数据集中有 30 万个观测值。我有分类和数字特征的混合。我发现只有两个特征具有高度预测性（基于在不同特征集上使用随机森林多次运行排列重要性）。
我尝试过的事情：

XGBoost：


scale_pos_weight 调整
max_delta_step 调整


随机森林：


class_weight 调整

问题：
帖子中的发帖人 skillsmuggler https://stackoverflow.com/questions/59409967/proper-way-to-handle-highly-imbalanced-data-binary-classification 建议使用平衡折叠的交叉验证。我搞不清楚他到底在建议什么。从他的帖子和他分享的图片来看，他似乎建议在每一折叠中：从同一少数类（100%？）中抽取样本，并从多数类中随机抽取样本，匹配少数类观察值的 2 倍。
如果我这样做，对于在其测试的观察值上进行训练的模型，难道不会出现疯狂的目标泄漏吗？假设我将其分成 10 个折，使用 9 个进行训练，1 个进行验证，则验证的折将具有与模型训练的折相同的观察结果，不是吗？
如果我将其分成更小的折，例如 10% 的少数类观察结果和 2 倍数量的多数类观察结果，我觉得我会丢失太多信息（一开始只有 3500 个少数类观察结果）。
然后，在分成这些折之后，无论期望的结果是什么，假设我的得分很高。目标是在整个数据集上执行该采样方案并以此方式训练最终模型吗？因为 CV 只是为了测试正在测试的任何策略的稳健性……除非他说要进行模型集成……这可能是一个好主意。
我打算尝试许多重新采样方案。我将尝试 SMOTE 变体，通过对少数群体进行重新采样来获得 50/50 的分割，尝试随机欠采样和随机过采样。如果我还应该尝试其他方法，请告诉我！
无论如何……希望对此问题有所帮助！非常感谢，如果我还能提供其他帮助，请告诉我！]]></description>
      <guid>https://stats.stackexchange.com/questions/660613/need-help-implementing-a-suggested-solution-to-severe-class-imbalance-w-binary</guid>
      <pubDate>Mon, 27 Jan 2025 14:14:57 GMT</pubDate>
    </item>
    <item>
      <title>单细胞数据中同时进行差异基因表达检测</title>
      <link>https://stats.stackexchange.com/questions/660612/simultaneous-differential-gene-expression-testing-in-single-cell-data</link>
      <description><![CDATA[我正在研究单细胞数据，想寻找对照组和测试组之间的差异基因表达。我不想单独测试多个基因，而是想看看两个或三个基因是否在同一细胞中存在差异表达。
例如，在测试组中，同一细胞中是否存在基因 A 增加而基因 B 减少的效应？
我希望这可以提高我的统计能力，因为单个基因的效应大小很小。]]></description>
      <guid>https://stats.stackexchange.com/questions/660612/simultaneous-differential-gene-expression-testing-in-single-cell-data</guid>
      <pubDate>Mon, 27 Jan 2025 14:06:56 GMT</pubDate>
    </item>
    <item>
      <title>$\ell_1$ 惩罚分位数回归的收敛速度为 $\sqrt{\frac{s\log (p \vee n)}{n}}$</title>
      <link>https://stats.stackexchange.com/questions/660611/rate-of-convergence-of-ell-1-penalized-quantile-regression-is-sqrt-fracs</link>
      <description><![CDATA[在标准 LASSO 文献中，您经常会遇到 LASSO 估计量以 $\sqrt{\frac{s\log p}{n}}$ 的速率收敛（例如，参见此帖子）。
一种相关方法是 $\ell_1$ 惩罚分位数回归，这意味着您将 $\ell_1$ 惩罚（如在 Lasso 中）添加到分位数回归损失。这样，你就可以估算给定$X$的$Y$的条件分位数，同时将一些系数缩小为零以用于变量选择或正则化目的。设置如下：
$$
\hat{\beta} = \arg \min_{\beta} \sum_{i=1}^n \rho_\tau (y_i - x_i^\top \beta) + \lambda \|\beta\|_1,
$$
其中

$\rho_\tau(u) = u(\tau - \mathbb{I}\{u &lt; 0\})$ 是分位数损失，调整残差的权重，
$\lambda$ 控制惩罚强度，
$\|\beta\|_1 = \sum_{j=1}^p |\beta_j|$ 是鼓励稀疏性的 $\ell_1$-惩罚。

此方法理论的主要参考文献是 Belloni 和 Chernozhukov (2011) 在《统计年鉴》中的文章。
在他们的论文中（例如，请参阅摘要、第 2.6 节或定理 2 了解完整结果），他们提到估计量的收敛速度为 $\sqrt{\frac{s\log (p \vee n)}{n}}$，其中 $\vee$ 用于表示 $p$ 和 $n$ 中的最大值。
因此，与标准 LASSO 速率相比，我们现在可以看到对数中有 $p \vee n$。对于许多有趣的制度，即 $p &gt;&gt; n$，这将提供与标准 LASSO 相同的速率。
有人知道为什么现在 $p$ 和 $n$ 存在最大值吗？任何见解都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660611/rate-of-convergence-of-ell-1-penalized-quantile-regression-is-sqrt-fracs</guid>
      <pubDate>Mon, 27 Jan 2025 14:01:25 GMT</pubDate>
    </item>
    <item>
      <title>均匀分布变量在 $\left\{(u, v); 0 \leq u \leq \sqrt{\tilde{\pi}(v/u)} \right\}$ 中的比率分布为 $\pi$</title>
      <link>https://stats.stackexchange.com/questions/660610/ratio-of-a-uniforms-distributions-variables-in-left-u-v-0-leq-u-leq-s</link>
      <description><![CDATA[问题：设$\pi = \tilde{\pi}/Z_\pi$为$\mathbb{R}$上的任意概率密度函数。证明如果$(U, V)$在$G = \left\{ (u, v)}上均匀分布； 0 \leq u \leq \sqrt{\tilde{\pi}(v/u)} \right\}$，则$V/U$服从$\pi$分布，即承认$\pi$为概率密度函数。
我的尝试：若$(U, V)$在G上均匀分布，则联合概率密度函数$f_{U, V} (u, v)$为
$$
f_{U, V} (u, v) = \frac{1}{\mathtt{Area}(G)}。
$$
我们可以集中精力于 $X = V/U$ 和 $U = u$。然后 $V = Xu$。变换的雅可比行列式为：
$$
J = \begin{Vmatrix}
1 &amp; 0 \\
x &amp; u
\end{Vmatrix} = u。
$$
因此，x 和 u 的联合密度为：
$$
f_{U, X}(u, x) = f_{U, V}(u, ux) \cdot |u|。
$$
那么，我最后的结论是
\begin{align}
f_X(x) &amp;= \int_0^{\sqrt{\tilde{\pi}(\frac{v}{u})}} f_{U, V} (u, xu) u dv \\
&amp;= \frac{1}{\mathtt{Area}(G)} \int_0^{\sqrt{\tilde{\pi} (\frac{v}{u})}} u dv = \frac{1}{\mathtt{Area}(G)} \frac{\tilde{\pi}(x)}{2}。
\end{align
我理解归一化常数的作用是使积分为 1，但我不知道如何将归一化常数添加到最后一个方程（假设其他计算有意义）。
编辑：我们有 $Z_\pi := \int_\mathbb{R} \tilde{\pi}(x) dx$。
编辑 2：我们想要那个
$$
\mathtt{Area}(G) = \int_{- \infty}^\infty \int_0^{\sqrt{\tilde{\pi}(\frac{v}{u})}} 1 du dv = {\color{red} {\cdots}} = \frac{Z_\pi}{2}。
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660610/ratio-of-a-uniforms-distributions-variables-in-left-u-v-0-leq-u-leq-s</guid>
      <pubDate>Mon, 27 Jan 2025 14:00:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在模型训练中根据一致性与准确性选择正则化超参数？</title>
      <link>https://stats.stackexchange.com/questions/660609/how-to-choose-regularization-hyperparameters-based-on-consistency-vs-accuracy-i</link>
      <description><![CDATA[我正在训练一个机器学习模型，并优化正则化超参数以确保模型具有良好的泛化能力。在训练期间，我在损失函数中加入正则化项来控制过度拟合。训练结束后，我通过计算训练数据集和测试数据集上不带正则化项的损失来评估模型的性能。这是因为，在这个阶段，模型是固定的，我只关心它在训练和看不见的测试数据上的表现如何。
挑战如下：
我经常遇到以下情况（为简单起见，假设训练和测试的比例为 50-50）：
情况 1：训练损失很低，但测试损失要高得多（例如，训练损失 = 50，测试损失 = 100）。
情况 2：训练和测试损失更接近且更一致，但总体上更高（例如，训练损失 = 80，测试损失 = 90）。
情况 3：两个损失甚至更高但仍然一致（例如，训练损失 = 120，测试损失 = 122）。
我理解普遍性（训练和测试之间的一致性）性能）通常比绝对准确度更重要，尤其是对于训练嵌入（例如 NLP 中的矩阵分解）等任务。但是，我很难决定以下问题：
我是否应该始终优先考虑一致性（例如案例 2 或 3）而不是准确性（例如案例 1）？
如何决定何时可以接受更高、一致的损失（例如案例 3），而不是即使训练和测试损失不同也要以低测试损失为目标？
我正在寻找一种算法或理论方法来决定哪组正则化超参数最合适。注意：我所说的“超参数”仅指正则化术语中使用的超参数，而不是与模型架构或其他组件相关的超参数。此外，我只处理两个数据分割：训练和测试。
任何关于如何处理这种权衡的指导都将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660609/how-to-choose-regularization-hyperparameters-based-on-consistency-vs-accuracy-i</guid>
      <pubDate>Mon, 27 Jan 2025 14:00:43 GMT</pubDate>
    </item>
    <item>
      <title>关于优化高斯混合模型的建议[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660608/advice-on-optimising-gaussian-mixture-model</link>
      <description><![CDATA[我有一个显然是双峰的数据分布，但我似乎无法应用高斯混合模型来估计两个正态分布。两个估计分布的均值似乎一直默认为 0 处的窄分布，而我希望均值为 ~0 和 0.3。
我是否误解了什么？您对如何优化设置以检测这两个分布有什么建议吗？供参考，我正在使用 MATLAB。]]></description>
      <guid>https://stats.stackexchange.com/questions/660608/advice-on-optimising-gaussian-mixture-model</guid>
      <pubDate>Mon, 27 Jan 2025 13:46:00 GMT</pubDate>
    </item>
    <item>
      <title>哪个更好 - AIC 还是 ANOVA？</title>
      <link>https://stats.stackexchange.com/questions/660603/which-is-better-aic-or-anova</link>
      <description><![CDATA[我正在比较三种不同的嵌套线性回归模型。基于 ANOVA f 统计量，最简单的模型是最好的 (i1)。但是，这些模型的 AIC 非常相似，在 +_3 以内。根据 AIC，第三个模型是最好的 (i3)。最好使用 ANOVA 或 AIC。
此外，查看诊断图时，第二个模型看起来更好。我知道这不是用来确定最佳拟合模型的，但我认为最好最小化方差量。
所以我有点不知道如何决定哪个模型最好。提前致谢！
编辑：
]]></description>
      <guid>https://stats.stackexchange.com/questions/660603/which-is-better-aic-or-anova</guid>
      <pubDate>Mon, 27 Jan 2025 12:49:29 GMT</pubDate>
    </item>
    <item>
      <title>卡方蒙特卡罗模拟反馈和替代方案</title>
      <link>https://stats.stackexchange.com/questions/660599/chi-square-monte-carlo-simulation-feedback-and-alternatives</link>
      <description><![CDATA[我有一个列联表，我想在其上应用卡方检验，但某些单元格不大于 5，这意味着我无法使用该检验。我读到过蒙特卡罗模拟是可行的，但我不知道在这种情况下它是否合适，或者是否有替代测试。
这是我的数据：
data &lt;- matrix(c(326, 32, 22, 2, 96, 115, 271, 4, 132, 29), 
nrow = 5, byrow = TRUE,
dimnames = list(c(&quot;GR1&quot;, &quot;GR2&quot;, &quot;GR3&quot;, &quot;GR4&quot;, &quot;GR5&quot;),
c(&quot;No&quot;, &quot;Yes&quot;)))

这是 R 中的结果：
chisq.test(data, mock.p.value = TRUE, B = 10000)

带模拟 p 值的 Pearson 卡方检验（基于 10000 次重复）

数据：数据
X 平方 = 266.48，df = NA，p 值 = 9.999e-05

我的方法好吗，或者是否有更可靠或更有趣的替代方法？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660599/chi-square-monte-carlo-simulation-feedback-and-alternatives</guid>
      <pubDate>Mon, 27 Jan 2025 12:20:54 GMT</pubDate>
    </item>
    <item>
      <title>多元 Ornstein-Uhlenbeck（Vasicek）过程的最大似然估计</title>
      <link>https://stats.stackexchange.com/questions/660596/maximum-likelihood-estimation-for-multivariate-ornstein-uhlenbeck-vasicek-proc</link>
      <description><![CDATA[我想知道多元 Ornstein-Uhlenbeck (OU) 过程的最大似然估计量 (MLE) 的解析表达式是否可用。
设置如下：考虑一个 $p$ 维 OU 过程 $(\mathbf{X}_t)_{t\geq 0}$，用于求解 SDE
$$d\mathbf{X}_t = \mathbf{\kappa}(\mathbf{\alpha}-\mathbf{X}_t) \, dt+\mathbf{\Sigma} \, d\mathbf{W}_t$$
其中 $\mathbf{\kappa}, \mathbf{\Sigma}$ 是 $k\times k$ 正定矩阵，$\mathbf{\alpha}$ 是 $k$ 向量，$\mathbf{W}_t$ 是 $p$ 维维纳过程。
假设我们在等距时间实例中观察到 OU 过程，即观测结果由
$$\mathbf{x}=\{\mathbf{x}_0, \mathbf{x}_\Delta, \ldots, \mathbf{x}_{n\Delta}\}$$
很明显，$\mathbf{X}_{i\Delta}\mid\mathbf{X}_{(i-1)\Delta}$ 服从高斯分布，利用 OU 过程的马尔可夫特性，我们可以写出观测值 $\mathbf{x}$ 的对数似然。现在我想问的是，是否有可能最大化 $(\mathbf{\kappa,\alpha,\Sigma})$ 的对数似然，并获得 MLE 的解析表达式？
我注意到一篇论文“扩散过程的参数估计和偏差校正”对单变量 OU 过程进行了此操作。如果有人能告诉我显示多变量版本的论文/书籍的方向，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660596/maximum-likelihood-estimation-for-multivariate-ornstein-uhlenbeck-vasicek-proc</guid>
      <pubDate>Mon, 27 Jan 2025 11:35:17 GMT</pubDate>
    </item>
    <item>
      <title>推导 $MSE(x_0) = E(\hat{y_0}-E(\hat{y_0}))^2+(E(\hat{y_0})-f(x_0))^2$（来自 Hastie 等人）</title>
      <link>https://stats.stackexchange.com/questions/660580/deriving-msex-0-e-haty-0-e-haty-02e-haty-0-fx-02-from</link>
      <description><![CDATA[在《统计学习要素》（第二版）（Hastie 等人）第 24 页的恒等式 2.25 中，它说：
$$MSE(x_0) = E(\hat{y_0}-E(\hat{y_0}))^2+(E(\hat{y_0})-f(x_0))^2,$$
这将导致偏差-方差分解。
我在推导这个等式时遇到了一些麻烦。我以前从未见过这种“期望中的期望”。更具体地说，我必须证明
$$2E(\hat{y_0}E(\hat{y_0}))-E(E^2(\hat{y_0}))-E^2(\hat{y_0}) = 0$$
因为当我从第 1 行到第 2 行时，除了想要的项之外，我还得到了这个。
对于那些没有这本书的人来说，第一个等式是
$$MSE(x_0)=E(f(x_0)-\hat{y_0})^2$$
我想这很简单……]]></description>
      <guid>https://stats.stackexchange.com/questions/660580/deriving-msex-0-e-haty-0-e-haty-02e-haty-0-fx-02-from</guid>
      <pubDate>Mon, 27 Jan 2025 05:07:56 GMT</pubDate>
    </item>
    </channel>
</rss>