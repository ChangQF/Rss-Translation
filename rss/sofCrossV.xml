<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 03 Feb 2025 12:31:59 GMT</lastBuildDate>
    <item>
      <title>多级模型中随机截距的显著性检验</title>
      <link>https://stats.stackexchange.com/questions/660908/significance-testing-for-random-intercepts-in-multilevel-model</link>
      <description><![CDATA[我正在估算一个多级 Mundlak 式模型来预测学校内的学生表现。这涉及计算每个学校 j (u_j) 的随机截距。
当我估算 u_j 时，我想比较学校之间的这些截距作为增值衡量标准。我如何获得这些截距的置信区间？是否有进行这些计算的关键参考/信息来源？
我知道截距是使用收缩估计器估算的，该估计器考虑了小组中的不精确性。但在估算单个随机截距的标准误差时，如何解释这一点？
即，标准误差的基本公式是 Var(u_j)^2/sqrt(N_j)。但是，我不确定这是否考虑到了这样一个事实，即基于样本中其他组的信息，小 N 的估计值已经受到收缩的影响。
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/660908/significance-testing-for-random-intercepts-in-multilevel-model</guid>
      <pubDate>Mon, 03 Feb 2025 12:12:25 GMT</pubDate>
    </item>
    <item>
      <title>赢家临床试验的减偏估计量</title>
      <link>https://stats.stackexchange.com/questions/660907/bias-reduced-estimator-for-play-the-winner-clinical-trial</link>
      <description><![CDATA[我正在尝试为一场“赢家必赢”的临床试验制作一个减少偏差的效应大小估计器。
问题是这样的：假设我们在第 2 阶段有两个实验组的结果，我们将它们称为 mA 和 mB，为简单起见，假设已知方差，即 mA~N(muA,1)、mB~N(muB,1)。为简单起见，假设我们与已知 mu0 = 0 的外部对照进行比较。
对于第 3 阶段，如果 mA&gt;mB，我们选择药物 A，如果 mB&gt;mA，我们选择药物 B。最终分析将是第 2 阶段和第 3 阶段数据的汇总分析。
在 H0：muA=muB=0 下，如果我们只是对 max(mA,mB) 和第 3 阶段数据进行简单的汇总，我们会在最终分析中得到正偏差。多重校正程序可以控制 1 类错误率，但我们还需要对 max(muA,muB) 估计进行偏差校正。有一些众所周知的特殊情况，例如，如果 mA&gt;&gt;mB 或 mA=mB 则没有问题，如果 muA=muB 则成为极值理论问题。但我想要更通用的东西。可能每个估计量在频率论意义上都会有偏差，但人们可以希望有一个可辩护的贝叶斯估计量。也许是因为我不擅长贝叶斯统计，但到目前为止我实现的所有估计量都给出了荒谬的结果。
有人知道相关研究吗？我在 Google Scholar 上找不到任何有用的东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/660907/bias-reduced-estimator-for-play-the-winner-clinical-trial</guid>
      <pubDate>Mon, 03 Feb 2025 12:06:15 GMT</pubDate>
    </item>
    <item>
      <title>逆条件累积分布函数</title>
      <link>https://stats.stackexchange.com/questions/660904/inverse-conditional-cdfs</link>
      <description><![CDATA[假设我有一个满足以下条件的条件 CDF 函数：
$\mathbb{P}\left ( Y\leq y| X=x\right )=\mathbb{P}\left ( Y\leq y|X=x&#39; \right ) +c$，其中 $c$ 表示所有概率都限制在单位间隔内。
说 $F^{-1}_{Y|X=x}(.)=F^{-1}_{Y|X=x&#39;}(F_{Y|X=x&#39;}(.)+c)$ 是否正确？我相信根据关于逆的直观推理，这是合理的，但我想确定一下。提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660904/inverse-conditional-cdfs</guid>
      <pubDate>Mon, 03 Feb 2025 11:14:28 GMT</pubDate>
    </item>
    <item>
      <title>Google 评分的误差估计</title>
      <link>https://stats.stackexchange.com/questions/660903/estimate-of-error-for-google-rating</link>
      <description><![CDATA[概述。
对于我的一个私人项目，我正在研究 Google 的评级系统。在那里，您可以为本地商店评级 1、2、3、4 或 5 星。我从我所在地区的一个相当大的设施获取了数据，并计算了平均评级 $m$，该评级与提交的评级数量 $n$ 以及其标准差 $s$ 有关。但是，我不确定在这种情况下使用标准差是否合理。这就是问题所在。
描述。
本地商店 Shop&#39;n&#39;Go（虚构）向我提供了其 Google 评级数据。假设商店不改变其政策、价格或员工，我认为商店的优劣反映在客户的平均评分中，这样在提交大量评分后，平均评分趋向于某个实际值$r$，介于$1$和$5$之间，即
$$\lim_{n \rightarrow \infty} m(n) = r$$
因此，我想预测这个值是什么，所以我计算了平均评分。但为了“估计平均值的准确性”，我还计算了标准差。
下图显示了 Shop&#39;n&#39;Go 的平均评分 $m(n)$ ($\color{blue}{\text{blue}}$) 和标准差 $s(n)$ ($\color{lightgrey}{\text{grey}}$) 与提交的评分数量的关系。可以看出，Shop&#39;n&#39;Go 的评分已超过 10,000 次。

问题陈述。
根据提交的大量评分，我预计平均值的误差很小。然而，事实证明，标准偏差的范围相当大；范围从大约 $5$ 颗星到 $3.5$ 颗星。我认为这种行为是由于客户倾向于给 $5$ 颗星（如果他们喜欢这家商店）或 $1$ 颗星（如果他们不喜欢这家商店）造成的。$\{2,3,4\}$ 颗星通常不常用。这个事实让我怀疑使用标准差的合理性，因为我认为它高估了误差。我猜想，更好更准确的估计与 $\{1,2,3,4,5\}$ 星级评分的分布有关，通常定性地采用与下图类似的形式。

我不太擅长统计，所以我不知道这个命题是否有意义。如果有意义，因此标准差不理想，那么在这种情况下，计算平均值误差的更好方法是什么？是否有任何已知的概率分布可以模拟这种情况或类似情况？如果不是，您认为适合以下分布的拟合函数是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660903/estimate-of-error-for-google-rating</guid>
      <pubDate>Mon, 03 Feb 2025 11:09:01 GMT</pubDate>
    </item>
    <item>
      <title>来自 python 库 linearmodels.panel.PanelOLS 的错误输出 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/660902/wrong-output-from-python-library-linearmodels-panel-panelols</link>
      <description><![CDATA[我正在使用 python linearmodels.panel.PanelOLS 运行回归，并发现当数据集很大（&gt;5 百万个观测值）时结果不正确 - 标准错误似乎正确，但系数完全不正确。
在下面的例子中，我创建了一个包含 10 百万个观测值和三列的数据集：
x：随机整数 0 或 1
const：1
y：x + N(0,1) * 100
然后使用 linearmodels.panelOLS、sm.OLS 和 pyfixest 运行回归。虽然后两个输出显示系数接近 1，但 linearmodels.panelOLS 生成不一致的输出。
### 创建数据集
# 创建一个包含 1000 万行的数据框，
# x 随机整数 0 或 1，
# y = x + N(0,1) * 100
import numpy as np
import pandas as pd

np.random.seed(0)
df = pd.DataFrame({&#39;x&#39;: np.random.randint(0, 2, 10000000),
&#39;const&#39;: 1,
&#39;index1&#39;: np.random.randint(0, 2, 10000000),
&#39;index2&#39;: np.random.randint(0, 2, 10000000),
&#39;y&#39;: np.random.normal(size=10000000) * 100})
df[&#39;y&#39;] = df[&#39;y&#39;] + df[&#39;x&#39;]
df = df.set_index([&#39;index1&#39;, &#39;index2&#39;])

### 使用 pyfixest 进行面板回归
import pyfixest as pf
df_reset = df.reset_index()# 重置索引（pyfixest 不适用于 MultiIndex）
est = pf.feols(&quot;y ~ 1+x&quot;, data=df_reset)# 使用 pyfixest 运行面板回归
print(est.summary())

### 使用 sm.OLS 进行面板回归
import statsmodels.api as sm
model = sm.OLS(df[&#39;y&#39;], df[[&#39;const&#39;, &#39;x&#39;]]).fit()
print(model.summary())

### 使用 PanelOLS 进行面板回归
from linearmodels.panel import PanelOLS
model = PanelOLS(df[&#39;y&#39;], df[[&#39;const&#39;, &#39;x&#39;]]).fit()
print(model.summary)

以下是 pyfixest 的输出

以下是 sm.OLS 的输出

以下是 PanelOLS 的输出

显然 PanelOLS 的系数与其他系数有很大不同，而标准误差却非常接近。

计算机规格：这个问题似乎只出现在一些计算机上，因为我尝试了一些其他计算机，但它在那里运行正常。如果有帮助，我的电脑（出现问题的地方）规格是：

CPU：第 13 代英特尔® 酷睿™ i9-13980HX 处理器
RAM：192 GB DDR5-5600MHz（SODIMM）-（4 x 48 GB）
GPU：NVIDIA RTX™ 3500 Ada 一代笔记本电脑 GPU 12GB GDDR6
存储：4 TB
系统：Windows 11 Pro 64

库版本：我尝试了 linearmodels 版本 5.3、5.4、6.0、6.1，它们都有问题。

样本大小：它似乎可以正确处理 &lt; 的数据集200 万次观察，但随着我将其扩大，它开始变得越来越错误。


任何建议都值得赞赏！提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660902/wrong-output-from-python-library-linearmodels-panel-panelols</guid>
      <pubDate>Mon, 03 Feb 2025 11:04:35 GMT</pubDate>
    </item>
    <item>
      <title>研究中的偏见</title>
      <link>https://stats.stackexchange.com/questions/660900/bias-in-a-study</link>
      <description><![CDATA[我正在进行一项没有对照组的单组研究，由于可用的前瞻性观察数量有限，我们的数据包括前瞻性和回顾性观察结果。研究的目的是将 T3（三个月）和 T6（六个月）的结果与基线进行比较，以评估在转换到新疗法后，与基线相比是否有任何改善。对第一种治疗反应不佳的参与者被选中转换到新疗法。一些病情更严重的患者（回顾性数据）比其他患者更早转换到新疗法（早于我们研究中的基线时间 T0）。
我想知道在这项研究中，是否仍然存在对结合前瞻性和回顾性数据产生的偏差的担忧，如果是，我们应该如何控制它？]]></description>
      <guid>https://stats.stackexchange.com/questions/660900/bias-in-a-study</guid>
      <pubDate>Mon, 03 Feb 2025 10:36:31 GMT</pubDate>
    </item>
    <item>
      <title>用不同估计量的概率平均值来确定最终概率</title>
      <link>https://stats.stackexchange.com/questions/660899/determination-of-final-probability-as-an-average-of-probability-with-different-e</link>
      <description><![CDATA[如果标题与问题不符，请见谅。我不知道如何恰当地总结我的问题。
假设我有一个公式$f$，它描述了基于某些输入$x$的某个结果的概率。该公式具有参数$\eta$，因此$f = f(x;\eta)$。
给定一些数据$D$，可以通过最小化某些损失来确定参数$\hat \eta$的估计值。
但是，如果我们有不同的数据$D&#39;$，估计的参数就会不同。
基于此，似乎有$2+1$个选项：

选项 1：使用数据集 $D_1,\dots, D_n$ 计算估计量 $\hat{\eta}_1,\dots,\hat{\eta}_n$，并设置 $\hat{\eta_0} $ 平均值。

选项 2：定义


$$
\bar{f}(x) = \frac{1}{n} \sum_{i=1}^n f(x;\hat{\eta}_i) 。
$$

选项 3：受上述启发，考虑参数的分布 $p(\eta)$ 并设置

$$
f(x) = \int_H f(x;\eta)\, p(\eta) \, d\eta。
$$
由于数据稀缺，我认为选项 3 是最聪明的选项：为以 $\hat\eta$ 为中心的参数设置分布 $p$（计算方式与选项 1 相同），并计算结果的概率作为加权和。这也具有引入额外参数（如方差）的优势，然后可以针对特定问题进行微调。
我的问题是：

上述任何一种（特别是选项 3）是否有意义？如果有，是否有一个数学框架可以形式化这一点（尤其是选项 3）？

参数在其空间上的分布积分让我想起了贝叶斯推理的参数公式；然而，由于缺乏先前的 $\Pi(\eta)$ 以及我缺乏该领域的专业知识，我不可能知道。]]></description>
      <guid>https://stats.stackexchange.com/questions/660899/determination-of-final-probability-as-an-average-of-probability-with-different-e</guid>
      <pubDate>Mon, 03 Feb 2025 10:19:05 GMT</pubDate>
    </item>
    <item>
      <title>时间序列模型 - 基于机器学习与传统方法 - 具有变化趋势和附加特征的案例</title>
      <link>https://stats.stackexchange.com/questions/660894/time-series-models-ml-based-vs-classical-methods-cases-with-changing-trends</link>
      <description><![CDATA[我是时间序列领域的新手，一直在阅读相关资料。似乎没有压倒性的共识支持使用 ML 或经典方法解决预测问题。ML 方法似乎在较高频率的时间序列或具有较高时间步长的时间序列中效果很好。但经典方法通常具有良好的预测性能。
我也在阅读 FB 的先知模型预印本，其中声称在许多业务问题中存在复杂的季节性模式和变化趋势。此外，可能还有更多特征可以为时间序列提供信息。例如，预测股票的回报可能需要其滞后交易量、价格的每周移动平均值等。
由于时间序列对时间的条件均值的非线性依赖，基于 ML 的方法（例如 xgboost）可以有效地捕获它。此外，在 ML 模型中包含其他特征是非常自然的。因此，直觉上，我会认为机器学习模型在各种业务预测问题中的表现都会优于传统模型。
那么，为什么对于许多业务问题，传统模型仍然优于机器学习模型呢？如果能从经验丰​​富的预测从业者/专家那里获得见解，那就太好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/660894/time-series-models-ml-based-vs-classical-methods-cases-with-changing-trends</guid>
      <pubDate>Mon, 03 Feb 2025 08:50:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么添加截距会改变 python 中的 roc_auc_score？</title>
      <link>https://stats.stackexchange.com/questions/660893/why-does-adding-an-intercept-change-roc-auc-score-in-python</link>
      <description><![CDATA[为什么在 python sklearn 中添加常数会改变 ROC AUC 的值？
import pandas as pd
from sklearn.datasets import make_classification
import statsmodels.api as sm
from sklearn.metrics import roc_auc_score

X, y = make_classification(n_samples=10000, n_features=2, n_informative=2, n_redundant=0, random_state=1)
X_const = sm.add_constant(X)

model1 = sm.Logit(y, X).fit()
model2 = sm.Logit(y, X_const).fit()

y_pred = model1.predict(X)
y_pred_c = model2.predict(X_const)

print(roc_auc_score(y, y_pred))
print(roc_auc_score(y, y_pred_c))

结果：
0.9425059793021525
0.9424627792866007
]]></description>
      <guid>https://stats.stackexchange.com/questions/660893/why-does-adding-an-intercept-change-roc-auc-score-in-python</guid>
      <pubDate>Mon, 03 Feb 2025 08:40:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么不直接使用样本的可能性作为检验统计量呢？</title>
      <link>https://stats.stackexchange.com/questions/660889/why-not-just-use-the-likelihood-of-a-sample-as-a-test-statistic</link>
      <description><![CDATA[这可能是一个愚蠢的问题，但我有点困惑。
假设我们有一个随机变量$x_n = {x_1, x_2, ..., x_n}$的 iid 样本，并且该变量是离散的，因此概率$P(X=x_i)$是明确定义的。现在我们进行某种假设检验，并计算检验统计量 $t_n = T(x_n)$，然后询问，在给定一些关于 $t_n$ 分布方式的假设 $H_0$ 的情况下，观察到比 $t_n$ 更极端的统计量 $t_n&#39;$ 的概率是多少，例如
$$\rho = P(t_n&#39; &gt; t_n | H_0)$$
相当公平。但是假设我们让 $T = P(x|H_0)$，其中由于 $X_i$ 假设为 iid，我们有
$$P(x_n|H_0) = \prod_{i=1}^n P(X=x_i|H_0)$$
然后我们可以通过询问其他样本 $x_n&#39;$ 比 $x_n$ 更有可能的概率来形成一个测试。
$$\rho = \frac{\#\text{ of }x_n&#39;\text{ where } P(x_n&#39;|H_0) &gt; P(x_n|H_0)}{\text{total } \# \text{ of possible } x_n&#39;} $$
我的问题是，为什么这不是一个好的假设检验（如果计算复杂性不是问题）。优点是，如果我们已经知道如何计算$P(X|H_0)$，那么我们不需要做任何进一步的工作来得出某些统计数据的抽样分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/660889/why-not-just-use-the-likelihood-of-a-sample-as-a-test-statistic</guid>
      <pubDate>Mon, 03 Feb 2025 03:00:19 GMT</pubDate>
    </item>
    <item>
      <title>关于 IID 随机变量的有限集合和事件的有限集合的“填充概率”的一般公式</title>
      <link>https://stats.stackexchange.com/questions/660886/general-formula-for-the-filling-probability-with-respect-to-a-finite-collectio</link>
      <description><![CDATA[背景
给定一个有限 IID 离散随机变量集合 $\{X_i\}_{i=1}^n$，其概率质量函数为 $\Pr$，以及一组有限事件 $S = \{ E_j \}_{j=1}^m$，填充概率是至少观察一次 $E_j$ 的概率。
我认为填充概率与分配问题相关，在分配问题中，人们感兴趣的是增加 $n$，以便所有目标 $m$ 事件可能（在一定风险承受能力下）达到通过。
假设我得到了正确的表达式，我打算编写一个轻量级的 Python 包，使用 Rust 扩展，根据 $n$、$m$ 和 $S$ 中每个事件的概率来计算这个数量。
目标
我想要这个填充概率的通用公式。让我展示一下我的工作，以防我犯了错误。
尝试
首先，我认为定义一个事件 $A_j$ 会很有用，它是 不 观察事件 $E_j$ 的事件。我认为$\Pr \left[ \bigcup_{j=1}^m A_j \right]$对这个问题很有用，因为它符合我的直觉，即至少一个事件缺失的概率。所以我的计划是实现这个结果：
$$P(\text{每个 } E_j \text{ 至少被观察到一次}) = 1 - P\left(\bigcup_{j=1}^m A_j\right)$$
接下来我可以使用包含-排除原理将这个概率分解为一个有限和：
$$P\left(\bigcup_{j=1}^m A_j\right) = \sum_{k=1}^{m} (-1)^{k+1} \sum_{1 \leq j_1 &lt; j_2 &lt; \ldots &lt; j_k \leq m} P(A_{j_1} \cap A_{j_2} \cap \ldots \cap A_{j_k})$$
这给我们留下了计算联合概率的任务。我希望它们可以像这样计算：
$$P(A_{j_1} \cap A_{j_2} \cap \ldots \cap A_{j_k}) = \left(1 - \sum_{i \in \{j_1, j_2, \ldots, j_k\}} \Pr(X_i \in E_i) \right)^n$$
然后我们最终可以像这样计算填充概率：
$$P(\text{每个 } E_j \text{ 至少被观察到一次}) = 1 - \sum_{k=1}^{m} (-1)^{k+1} \sum_{1 \leq j_1 &lt; j_2 &lt; \ldots &lt; j_k \leq m} \left(1 - \sum_{i \in \{j_1, j_2, \ldots, j_k\}} \Pr(X_i \in E_i) \right)^n
$$
问题

我犯了什么错误吗？
有没有更好的方法？
有没有比“填充概率”更常规的名称？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660886/general-formula-for-the-filling-probability-with-respect-to-a-finite-collectio</guid>
      <pubDate>Sun, 02 Feb 2025 22:55:55 GMT</pubDate>
    </item>
    <item>
      <title>约翰森测试条件</title>
      <link>https://stats.stackexchange.com/questions/660882/johansen-test-conditions</link>
      <description><![CDATA[我当时正在 Goldkamp Cointegration for Time Series Analysis on medium.
作者提到，对于具有 $k$ 个不同序列的 VAR 过程，我们不能有 $k$ 个有效的协整关系。我的思路是，对于$k=2$：两个有效的协整关系意味着存在$\beta_1$和$\beta_2$，使得$y_t-\beta_1x_t$和$x_t-\beta_2y_t$都是$I(0)$。所以，这似乎有点多余。
只是想澄清我的推理是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/660882/johansen-test-conditions</guid>
      <pubDate>Sun, 02 Feb 2025 19:17:46 GMT</pubDate>
    </item>
    <item>
      <title>限制高斯 S 型函数期望的近似误差</title>
      <link>https://stats.stackexchange.com/questions/660861/bounding-the-approximation-error-of-the-expectation-of-the-sigmoid-of-a-gaussian</link>
      <description><![CDATA[我想限制$\mathbb{E}_x[\sigma(x)],$的近似误差 $\sigma(x):=1/(1+\exp(-x)),$ $x\sim\mathcal{N}(\mu,v)$:
$$\mathbb{E}_x[\sigma(x)]=\sigma(\mu)+\sum_{k=1}^\infty \frac{\sigma^{(k)}(\mu)}{k!}\mathbb{E}[(x-\mu)^k].$$
由于$\mathbb{E}[(x-\mu)^k]=v^k(k-1)!!,$ 这简化为 $$\mathbb{E}_x[\sigma(x)]=\sigma(\mu)+\sum_{k=1}^\infty \frac{v^k\sigma^{(k)}(\mu)}{k!!}.$$
事实上，看起来 $\frac{\sigma^{(k)}(\mu)}{k!!}$ 发散，但这意味着期望发散，而我真的不这么认为。我哪里做错了？
编辑：看来方差在这里至关重要，对于 .05 左右及以下的值，项（至少最多 140 个项，这是我可以计算而不会溢出的极限）不会爆炸。这种期望确实只存在于某些方差中吗？对我来说似乎违反直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/660861/bounding-the-approximation-error-of-the-expectation-of-the-sigmoid-of-a-gaussian</guid>
      <pubDate>Sat, 01 Feb 2025 23:55:33 GMT</pubDate>
    </item>
    <item>
      <title>最小二乘估计量投影视图中的帽子矩阵的维数</title>
      <link>https://stats.stackexchange.com/questions/660854/dimensionality-of-the-hat-matrix-in-the-projection-view-of-the-least-squares-est</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660854/dimensionality-of-the-hat-matrix-in-the-projection-view-of-the-least-squares-est</guid>
      <pubDate>Sat, 01 Feb 2025 18:28:03 GMT</pubDate>
    </item>
    <item>
      <title>卡方检验是参数检验还是非参数检验？</title>
      <link>https://stats.stackexchange.com/questions/660848/is-a-chi-squared-test-a-parametric-or-non-parametric-test</link>
      <description><![CDATA[也许这是一个微不足道的问题，但我一直收到一些相互矛盾的信息，这让我有些困惑。
首先，关于参数检验和非参数检验之间的区别似乎存在一些相互矛盾的信息。即，

一些来源表明参数检验对样本所来自的总体分布的参数做出假设
其他来源表明参数检验仅适用于正态分布的数据

我个人认为第一个说法是正确的，而不是后者，但我希望对此有清晰的认识。
如果第一点是正确的，这就引出了我的第二个问题。我看到多个来源都这么说：

卡方检验是一种非参数检验（a、b、c）

但是我想知道为什么卡方检验是非参数的，如果像 Z 检验、t 检验、ANOVA 等参数检验一样，它假设总体分布遵循特定分布，不是吗？我认为卡方检验假设检验统计量来自卡方分布，因此由于它做出了分布假设，所以它是参数化的。但我肯定是误解了什么。有人能帮忙澄清一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660848/is-a-chi-squared-test-a-parametric-or-non-parametric-test</guid>
      <pubDate>Sat, 01 Feb 2025 16:00:09 GMT</pubDate>
    </item>
    </channel>
</rss>