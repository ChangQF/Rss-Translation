<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 29 Oct 2024 18:23:09 GMT</lastBuildDate>
    <item>
      <title>在结果模型中加入 PS 模型中未包含的协变量是否会引起偏差</title>
      <link>https://stats.stackexchange.com/questions/656472/can-including-a-covariate-in-the-outcome-model-that-wasnt-included-in-the-ps-mo</link>
      <description><![CDATA[在结果模型中包含 PS 模型中未包含的协变量是否会在治疗变量的因果关系中引入偏差？
一位同事分享了一个模拟结果，似乎表明了这一点。
设置如下：

使用多个协变量拟合 PS 模型，$X_1$、$X_2$、$...$、$X_n$
使用步骤 1 中的模型的倾向得分匹配创建了 1:1 治疗：未治疗样本
使用步骤 2 中的样本，使用以下协变量拟合回归，$treatment$、$X_1$、$X_2$、$...$、$X_n$ 的子集，以及 PS 模型中没有的附加变量，$X_{additional}$

在我看来，这似乎应该根据$X_1$、$X_2$、$...$、$X_n$ 和 $X_n$ 的混杂因素进行调整class=&quot;math-container&quot;&gt;$X_{additional}$。
是否存在某种理论原因可以解释为什么结果模型中的这组协变量会给估计的治疗效果带来偏差，而如果不包括这些协变量，这种偏差就不会存在？]]></description>
      <guid>https://stats.stackexchange.com/questions/656472/can-including-a-covariate-in-the-outcome-model-that-wasnt-included-in-the-ps-mo</guid>
      <pubDate>Tue, 29 Oct 2024 17:52:58 GMT</pubDate>
    </item>
    <item>
      <title>从等于两个已知 PDF f(x) 和 g(x) 乘积的 PDF 中采样</title>
      <link>https://stats.stackexchange.com/questions/656469/sampling-from-a-pdf-equal-to-a-product-of-two-known-pdfs-fx-and-gx</link>
      <description><![CDATA[假设我们有两个已知的 PDF $f(x)$ 和 $g(x)$（我们也可以简单地从两个分布中抽样）。
如果相应的 PDF/CDF 无法轻易识别（$k$ 是标准化因子），如何抽样 $k \cdot f \cdot g\,(x)$？具体来说，我正在寻找对 PDF 进行采样，它是 $\mathsf{LogNorm}(\mu_a,\sigma_a)$ 和 $\mathsf{Norm}(\mu_b,\sigma_b)$ 的乘积。
我的目的是应用&quot;weight&quot;使用给定的 $\mathsf{Norm}$ 计算原始 $\mathsf{LogNorm}$ 的概率。
我找到了 Metropolis–Hastings 算法，但我想知道对于 $\mathsf{LogNorm}$ 和 $\mathsf{Norm}$ 分布的乘积的特殊情况，是否有更简单的算法？
一些示例可以澄清我的问题：

这里，有人询问“混合”分布。从呈现的直方图来看，我可以说这可能是我正在寻找的。不幸的是，OP没有说明如何进行采样。
这里，有人谈到“Metropolis-Hastings 算法”对于似乎与我的情况相同的情况的效率。
]]></description>
      <guid>https://stats.stackexchange.com/questions/656469/sampling-from-a-pdf-equal-to-a-product-of-two-known-pdfs-fx-and-gx</guid>
      <pubDate>Tue, 29 Oct 2024 16:23:08 GMT</pubDate>
    </item>
    <item>
      <title>为什么在联合分析中从多项逻辑模型中删除截距？</title>
      <link>https://stats.stackexchange.com/questions/656467/why-is-the-intercept-removed-from-the-multinomial-logit-model-in-conjoint-analys</link>
      <description><![CDATA[我看过多个关于联合分析的资源，其中分析师使用多项 Logit 模型并删除截距或建议从模型中删除截距。但我还没有真正看到关于为什么应该从联合分析的多项 Logit 模型中删除截距的解释？
有人知道为什么要删除联合分析的截距吗？这对于解释意味着什么，为什么要这样做？
此外，MaxDiff 在离散选择模型领域中是联合分析的近亲。您还应该在联合分析中删除截距吗？
https://campus.datacamp.com/courses/choice-modeling-for-marketing-in-r/building-choice-models?ex=4
https://rpubs.com/ecohee/CBC-11488]]></description>
      <guid>https://stats.stackexchange.com/questions/656467/why-is-the-intercept-removed-from-the-multinomial-logit-model-in-conjoint-analys</guid>
      <pubDate>Tue, 29 Oct 2024 16:02:26 GMT</pubDate>
    </item>
    <item>
      <title>检测功能分裂的机器学习方法</title>
      <link>https://stats.stackexchange.com/questions/656462/machine-learning-approach-to-detect-function-splits</link>
      <description><![CDATA[下面是我的问题的卡通图。该函数明显分为两部分。对于人类来说，这很容易识别，但是，机器学习方法如何解决此类问题？如果我使用简单回归，则识别出的函数肯定会经过两个函数的中间，这没有什么帮助。
我还想要一种用于高维情况的方法，在这种情况下，人类无法绘制事物并轻松识别分裂区域/函数。任何有关此类问题的建议都会有所帮助。
]]></description>
      <guid>https://stats.stackexchange.com/questions/656462/machine-learning-approach-to-detect-function-splits</guid>
      <pubDate>Tue, 29 Oct 2024 14:29:44 GMT</pubDate>
    </item>
    <item>
      <title>累积发生率函数 - 比较达到特定累积发生率的时间</title>
      <link>https://stats.stackexchange.com/questions/656461/cumulative-incidence-function-compare-time-at-which-a-specific-cumulative-inci</link>
      <description><![CDATA[我有生存数据，并绘制了按治疗状态分层的累积发病率函数（以年龄为时间尺度）。我使用 Gray 检验来比较总体累积发病率函数，并比较了特定年龄/时间的累积发病率。我还想比较达到给定发病率的年龄。例如，我想估计两组达到 25% 累积发病率的年龄，并比较年龄以询问未治疗组是否比治疗组更早达到 25% 的累积发病率。我可以从累积发病率函数中确定每组达到 25% 累积发病率的年龄，但我不确定如何计算方差/进行假设检验。是否可以根据累积发病率函数计算出这个值？]]></description>
      <guid>https://stats.stackexchange.com/questions/656461/cumulative-incidence-function-compare-time-at-which-a-specific-cumulative-inci</guid>
      <pubDate>Tue, 29 Oct 2024 14:12:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么与变量相关的因子得分不等于载荷？</title>
      <link>https://stats.stackexchange.com/questions/656459/why-factor-scores-correlated-with-variables-do-not-equal-loadings</link>
      <description><![CDATA[我试图理解以下内容：
我有三个变量（x1、x2、x3），我在 SPSS 中对它们进行了 PCA 和 EFA（主轴分解）以获得一个成分/因子。
如果我进行 PCA 并计算因子得分（回归方法），我将其称为变量“F”，则：Cor(x1, F)=成分载荷，x2 和 x3 也是如此。
如果我对 PFA 执行相同操作，那么我显然会得到不同的载荷和因子得分，但同时：
Cor(x1, F) 不再等于载荷（但只是近似值）。
有人可以解释一下为什么会这样吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656459/why-factor-scores-correlated-with-variables-do-not-equal-loadings</guid>
      <pubDate>Tue, 29 Oct 2024 14:09:15 GMT</pubDate>
    </item>
    <item>
      <title>澄清 Microsoft Excel/Powerpoint 图中误差线的默认“标准误差”（不使用 N 或 SD 计算）</title>
      <link>https://stats.stackexchange.com/questions/656458/clarifying-the-default-standard-error-for-error-bars-in-microsoft-excel-powerp</link>
      <description><![CDATA[我注意到 Excel 允许您为任何给定的图切换“误差线”，其中一个选项是让误差线表示标准误差。这很奇怪，因为如果您在 Excel 或 Powerpoint 中绘制具有两个平均值的条形图，则没有关于每个组的标准偏差和每个组内的 N 的信息，而这些信息是估计标准误差所必需的。
此链接描述了 Excel/Powerpoint 图的标准误差：
https://support.microsoft。
com/en-us/office/add-change-or-remove-error-bars-in-a-chart-e6d12c87-8533-4cd6-a3f5-864049a145f0
显示如下：

其中，

s = 系列编号
I = 系列 s 中的点数
m = 图表中点 y 的系列数
n = 每个系列中的点数
y is = 系列 s 的数据值和第 I 个点
n y = 所有系列中的数据值总数

对我来说，这读起来就像是在描绘图中平均平方值的平方根。
同时，实际的标准误差公式如下：

表示标准差除以 N（样本大小）的平方根。
对我来说，Excel 标准误差的公式似乎与标准误差完全不同，因为它省略了有关方差/SD 以及样本大小的任何信息，仅包含有关图中的值（可能是平均值）的信息以及这些值的数量值。
我想知道...

... 我是否正确解释了 Microsoft Excel/Powerpoint 版本的标准错误？
... Excel/Powerpoint 中的标准错误估计是否具有误导性？尽管省略了有关 SD 和 N 的信息，但这是否能近似标准错误？为什么 Microsoft 会得出这个不同的 SE 估计值并将其称为 SE？
]]></description>
      <guid>https://stats.stackexchange.com/questions/656458/clarifying-the-default-standard-error-for-error-bars-in-microsoft-excel-powerp</guid>
      <pubDate>Tue, 29 Oct 2024 13:32:43 GMT</pubDate>
    </item>
    <item>
      <title>当关系是间接的（过度控制偏见？）时寻求有关不良控制的建议</title>
      <link>https://stats.stackexchange.com/questions/656457/seeking-advice-on-bad-control-when-the-relationship-is-indirect-overcontrol-bia</link>
      <description><![CDATA[我正在开展一个项目，我们试图估计国家脆弱性状态对项目结果的影响。我们有分配给每个项目的总赠款资金的数据，我们已将其作为回归分析中的控制变量。然而，有人担心赠款规模可能与脆弱性状态相关，因为用于分配赠款的公式会为具有某些特征的国家（例如较贫穷的国家、小岛国）提供更多赠款。
虽然脆弱性状态没有被考虑在公式中，但公式考虑了与脆弱性密切相关的特征。换句话说，国家脆弱性状态本身并不直接影响赠款资金，但它与那些影响赠款资金的因素相关。
除了多重共线性问题之外，在这种情况下，将赠款规模作为控制因素是否会引起偏差？]]></description>
      <guid>https://stats.stackexchange.com/questions/656457/seeking-advice-on-bad-control-when-the-relationship-is-indirect-overcontrol-bia</guid>
      <pubDate>Tue, 29 Oct 2024 13:02:23 GMT</pubDate>
    </item>
    <item>
      <title>如何使用微分熵作为预处理？</title>
      <link>https://stats.stackexchange.com/questions/656456/how-to-use-differential-entropy-as-pre-processing</link>
      <description><![CDATA[我目前正在实施模型 EEG_DMNet。对于预处理，它要求使用差分熵，如
$$
h(X) = -\int_{-\infty}^{\infty} p(x) \log p(x) \, dx
$$
假设我使用的数据是高斯分布的，公式可以简化为
$$
h(X) = \frac{1}{2} \log(2\pi e \sigma^2)
$$
我的问题是，我不明白“使用差分熵”是什么意思。输入 x 的形状为 $$
x \in \mathbb{R}^{n \times C} \times \mathbb{R}^{n \times T}
$$
输出形状也应相同。在 keras 中尝试添加预处理层时，输出形状不正确。
def call(self, input):
variance = tf.math.reduce_variance(inputs, axis=-1, keepdims=True)
Differential_entropy = 0.5 * tf.math.log(2 * np.pi * np.e * variance)
return Differential_entropy
]]></description>
      <guid>https://stats.stackexchange.com/questions/656456/how-to-use-differential-entropy-as-pre-processing</guid>
      <pubDate>Tue, 29 Oct 2024 12:34:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Prophet 比动态谐波回归更快？</title>
      <link>https://stats.stackexchange.com/questions/656455/why-is-prophet-faster-than-dynamic-harmonic-regression</link>
      <description><![CDATA[预测：原则与实践（第 3 版）的第 12.2 节讨论了 Facebook 的 Prophet 模型。作者写道：

Prophet 的优势在于，与我们之前考虑过的 [动态谐波回归] 模型相比，其估算速度要快得多

动态谐波回归：回归量是傅里叶项 $s(t)$，误差项是 ARMA：
\begin{aligned}
y_t &amp;= s(t) + \eta_t, \\
\eta_t &amp;\sim \text{ARMA}(p,q)。
\end{aligned&gt;
在 R 中，该模型是通过状态空间表示的最大似然法来估计的（我认为）。我们可以假设 auto.arima 用于选择误差项的滞后阶数。
预言：回归量是分段线性趋势 $g(t)$ 和傅里叶项 $s(t)$。（也可能有假日虚拟变量 $h_t$。）误差项是 i.i.d. 正态分布。
\begin{aligned}
y_t &amp;= g(t) + s(t) + \varepsilon_t, \\
\varepsilon_t &amp;\sim i.i.d. N(0, \sigma^2)。
\end{aligned&gt;
问题：

为什么 Prophet 的估计速度比动态谐波回归更快？
这一发现有多普遍（短时间序列与长时间序列、傅里叶项数少与多、其他细微差别）？

我的初步想法（这并不多……）：

贝叶斯估计通常不被认为是快速的。
通过 auto.arima 选择滞后阶数可以使估计时间相对于给定滞后阶数的情况增加大约 10 倍（大约）。
]]></description>
      <guid>https://stats.stackexchange.com/questions/656455/why-is-prophet-faster-than-dynamic-harmonic-regression</guid>
      <pubDate>Tue, 29 Oct 2024 12:14:53 GMT</pubDate>
    </item>
    <item>
      <title>根据 Basharin 渐近正态性结果得出的熵的置信区间</title>
      <link>https://stats.stackexchange.com/questions/656449/confidence-interval-for-entropy-from-basharin-s-asymptotic-normality-result</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656449/confidence-interval-for-entropy-from-basharin-s-asymptotic-normality-result</guid>
      <pubDate>Tue, 29 Oct 2024 10:25:17 GMT</pubDate>
    </item>
    <item>
      <title>模型中的残差方差有可能大于被建模变量的总方差吗？</title>
      <link>https://stats.stackexchange.com/questions/656450/is-it-possible-for-the-residual-variance-in-a-model-to-be-greater-than-the-total</link>
      <description><![CDATA[我使用 survey 包中的 svyglm 在 R 中拟合了线性回归。数据经过加权，模型对响应使用 ^2 变换来校正非正态性。
我想计算模型的 R 平方，我使用以下公式进行计算：1-残差方差/总方差。
在这种情况下，总方差 = 4.48，我使用拟合模型中的离散参数获得残差方差，这比总方差（727.38）大很多。由于模型包含 ^2 转换，我在计算 R-Squared 时尝试使用 sqrt(residual variance)，结果比 1 大很多倍。
因此，有两个问题：

residual variance &gt; total variance 是否表明我所拟合的模型不合适？
我是否误解了使用 sqrt(residual var) 来解释模型中的 ^2 转换？
]]></description>
      <guid>https://stats.stackexchange.com/questions/656450/is-it-possible-for-the-residual-variance-in-a-model-to-be-greater-than-the-total</guid>
      <pubDate>Tue, 29 Oct 2024 03:09:32 GMT</pubDate>
    </item>
    <item>
      <title>不确定研究场景中测试什么、如何测试以及潜力</title>
      <link>https://stats.stackexchange.com/questions/656429/unsure-as-to-what-tests-how-and-potential-in-a-research-scenario</link>
      <description><![CDATA[有三个教室，里面的学生年级不同。我想分析一下这些变量中哪些影响了考试得 0 分的可能性。这些因素包括：年级（8、9 或 10）和压力水平量表（从 0 到 3）。
对于得分为 0 的学生，我想从统计上比较这些因素。我该怎么做？我有 Excel 和 Jamovi（一个 R 软件）。我主要想将其制作成最多两个图表，最重要的是找出得分为 0 的学生在压力水平和年龄之间是否存在显著差异。
这是我为正在进行的一个项目想出的一个类比，但我不允许分享——但这是我遇到的相同统计问题。我的数据如下所示：

测试分数（连续小数变量）——&gt;分数列表
压力水平（序数变量，0 1 2 或 3）
等级（序数）8、9 或 10
]]></description>
      <guid>https://stats.stackexchange.com/questions/656429/unsure-as-to-what-tests-how-and-potential-in-a-research-scenario</guid>
      <pubDate>Mon, 28 Oct 2024 19:07:42 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归中的排列检验，哪种方法是正确的？</title>
      <link>https://stats.stackexchange.com/questions/656424/permutation-test-in-multiple-linear-regression-which-way-is-correct</link>
      <description><![CDATA[我正在拟合一个线性回归模型$$Y = \beta_0+ \beta_1 Z + \beta_2 X+\epsilon$$响应$Y$和协变量$X$是连续变量，$Z$是 0/1 二分治疗组指标，所有这些都是$N \times 1$向量。$\epsilon$是$N \times 1$正态分布的i.i.d向量。期望值为 0 且方差未知的随机误差$\sigma^2$。我想要获得系数$\beta_1$的 t 检验的置换分布。在排列中，下列哪一项是正确的：
(1) 随机排列 $Y$，并获取 1000 个排列中 $\beta_1$ 的分布
(2) 随机排列 $Z$，并获取 1000 个排列中 $\beta_1$ 的分布
(3) 令 $Z(X)$ 为在 $X$ 上拟合 $Z$ 的残差向量，令 $Y(X)$ 是将 $Y$ 拟合于 $X$ 所得的 残差。 
然后对 $Z(X)$ 进行 1000 次置换，并记录 $Y(X)$ 对 $Z(X)$ 进行回归时 $Z(X)$ 的 1000 个回归系数。
(4) 对 $Y(X)$ 对 $Z$ 进行回归，对 $Z$ 进行 1000 次置换，并记录 1000 个回归系数。这与比较“X 调整值”的平均值相同$Y$ 在 2 个组中的分布。
我认为 (3) 是正确的方法，因为它保留了 $X$ 与 $Y$ 和 $Z$ 的关系。因此 在置换之前，我应该从 $Z$ 和 $Y$ 中清除 $X$ 的影响。但 (4) 对我来说也并非完全不合理。我找不到合适的参考资料来讨论这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/656424/permutation-test-in-multiple-linear-regression-which-way-is-correct</guid>
      <pubDate>Mon, 28 Oct 2024 17:20:46 GMT</pubDate>
    </item>
    <item>
      <title>使用倾向评分时的假设</title>
      <link>https://stats.stackexchange.com/questions/656403/assumptions-in-the-use-of-propensity-scores</link>
      <description><![CDATA[一位研究人员进行了倾向得分匹配分析，其中暴露的是性别（即男性与女性）。这并不是一个因果分析，结果仅以“关联”的形式描述 - 手稿中没有提到因果推断。
评论中提出，由于女性成为男性的可能性为零，反之亦然，因此阳性假设被违反。我想知道人们对此的看法，因为我认为，如果倾向得分匹配实际上被用作因果推断分析的一个步骤，那么从技术上讲这是正确的。但这里的情况并非如此 - 相反，其意图更像是一个数据缩减步骤。
我认为诸如阳性、可交换性等假设是因果推断的假设，而不是倾向得分本身的使用假设，对吗？还是我没抓住重点？ - 如果我是的话，我禁不住认为这是一个语义问题（即倾向得分实际上只是一个预测概率，人们通常只是假设在计算倾向得分时，会进行因果分析）。]]></description>
      <guid>https://stats.stackexchange.com/questions/656403/assumptions-in-the-use-of-propensity-scores</guid>
      <pubDate>Mon, 28 Oct 2024 09:57:47 GMT</pubDate>
    </item>
    </channel>
</rss>