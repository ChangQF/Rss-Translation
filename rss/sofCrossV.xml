<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 23 Dec 2023 15:12:44 GMT</lastBuildDate>
    <item>
      <title>直觉线性回归逐步选择预测变量</title>
      <link>https://stats.stackexchange.com/questions/635547/intuition-linear-regression-stepwise-selection-of-predictors</link>
      <description><![CDATA[我正在使用遗传学中的一种工具，其工作原理与逐步线性回归非常相似（其称为GCTA-COJO 对于那些感兴趣的人）。基本上开始的情况是这样的：
您有 1000 个预测因子（称为 SNP1、SNP2...）和一个要预测的连续性状 Y。在第一步中，您将拟合一个仅包含一个预测变量的线性模型（即 lm(Y~SNP1)、lm(Y~SNP2)、. ..).
在第二步中，您需要拟合一个联合模型，其中包括多个预测变量（即 lm(Y~SNP1+SNP5+SNP159)）。在这里，我注意到，常常会出现与“单一预测变量”中的结果 Y 不显着相关的预测变量。当关联测试（即 lm(Y~SNP1)）包含在联合模型 (lm(Y~SNP1+SNP5+SNP159)）中时，它们变得显着。不知何故，我很难理解这样的事情是如何可能的，并且如果有人能给我一个直观的解释，说明这是可能的，我会很高兴。
这里是一些示例数据，很好地描述了我的情况：
图书馆（扫帚）
图书馆（tidyverse）

set.seed(123) # 设置种子以实现可重复性

# 为每个变量生成 100 个观测值
n &lt;- 100

# 生成具有不同相关性的预测变量
预测变量 &lt;- 矩阵(rnorm(20 * n), nrow = n)
Predictors[, 1:5] &lt;- Predictors[, 1] + rnorm(n, sd = 0.2) # 引入一些相关性
Predictors[, 6:10] &lt;- Predictors[, 5] + rnorm(n, sd = 0.3) # 引入更多相关性

# 生成与预测变量具有不同关系的结果变量
Y &lt;- 2 + 0.5 * 预测器[, 1] + 0.8 * 预测器[, 5] + 0.3 * 预测器[, 10] + rnorm(n)

# 合并成数据框

data &lt;- data.frame(Y, 预测变量)
名称(数据)[-1] &lt;-paste0(“X”, 1:20) # 指定列名称

# 存储 20 个预测变量的名称
预测器 &lt;- 名称（数据）[-1] # 假设 Y 是第一列

# 为每个预测变量拟合单独的线性回归
for（预测变量中的预测变量）{
  模型 &lt;- lm(公式 = Y ~ 数据[[预测器]], 数据 = 数据)
  打印（预测）
  打印（整洁（模型））
}

# 包含所有预测变量的完整模型
full_model &lt;- lm(Y ~ ., 数据 = 数据)

# 使用AIC逐步选择
best_model &lt;- step(full_model, Direction = &quot;both&quot;) # 同时考虑前向和后向选择

# 打印所选模型的摘要
摘要（最佳模型）

在此示例中，predictor13 在单变量关联测试中并不显着，但在连接模型 (best_model) 中，我们可以看到它变得显着关联。
这让我感到惊讶，因为这两个变量之间似乎没有任何关联：

非常感谢任何关于为什么这是可能的见解！
干杯！]]></description>
      <guid>https://stats.stackexchange.com/questions/635547/intuition-linear-regression-stepwise-selection-of-predictors</guid>
      <pubDate>Sat, 23 Dec 2023 14:44:10 GMT</pubDate>
    </item>
    <item>
      <title>如何找到哪组变量可以预测最佳握力，在进行分析之前首先减少连续变量的数量[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635544/how-can-i-find-which-set-of-variables-predicts-best-handgrip-strength-first-red</link>
      <description><![CDATA[这是我的作业问题：
“哪一组变量最能预测女性的握力？
A。在进行分析之前减少连续变量的数量。”
我应该使用哪些技术以及以什么顺序使用它们，因为我有点卡住了。我有 17 个变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/635544/how-can-i-find-which-set-of-variables-predicts-best-handgrip-strength-first-red</guid>
      <pubDate>Sat, 23 Dec 2023 13:25:31 GMT</pubDate>
    </item>
    <item>
      <title>分别在 m 个数据上训练的两个分类器的多数投票是否比在 2m 个数据上训练的一个分类器更好？</title>
      <link>https://stats.stackexchange.com/questions/635543/is-a-majority-vote-from-two-classifiers-trained-on-m-data-each-better-than-one-c</link>
      <description><![CDATA[在 PAC 学习框架中，集成分类器的性能与单个分类器相比如何？具体来说，考虑 $2m$ i.i.d 样本 $(x, y) \in \mathcal{X} \times \{- 1, 1\}$ 来自分布 $\mathcal{D}$，这是一个二元分类任务。想象一个学习者将数据分为两个大小相等的子集：$S_1$ 和 $S_2$，并且训练两个分类器 $h_1$ 和 $h_2$。该学习器的最终预测是 $h_3 = \text{sign}\left(\frac{h_1 + h_2}{2}\right)$。与在所有 $2m$ 数据点上直接训练单个分类器相比，此方法的样本复杂性和泛化误差如何？如何在 PAC 框架内从数学上论证或反对这一方法？
这可能是错误的，因为我们通常不会以这种方式训练分类器，但是，这可能是正确的，因为多数投票有助于学习。 （PAC 学习的最佳样本复杂度使用多数投票分类器）]]></description>
      <guid>https://stats.stackexchange.com/questions/635543/is-a-majority-vote-from-two-classifiers-trained-on-m-data-each-better-than-one-c</guid>
      <pubDate>Sat, 23 Dec 2023 13:10:12 GMT</pubDate>
    </item>
    <item>
      <title>随机区组设计和混合模型</title>
      <link>https://stats.stackexchange.com/questions/635542/randomized-blocking-design-and-mixed-models</link>
      <description><![CDATA[我正在开发一个研究项目，我们正在评估幼苗的生长情况。这些地块分布在开放式温室中，一些环境参数根据其位置而变化。为了减少这种影响，我们定义了块来对位于不同条件下的图进行分组。
我们将在不同的地块上进行多次测量，因此我们必须使用混合模型。我的问题是：在没有块的实验中，图是随机因子，但在这种情况下，我是否将块视为随机因子？
我还没有数据，也没有进行分析，但我的问题（使用 R）是我应该如何使用模型中的块？：
增长 ~ 因子 1 + 因子 2 + (1|块)

或
增长 ~ 因子 1 + 因子 2 + 块 + (1|图)
]]></description>
      <guid>https://stats.stackexchange.com/questions/635542/randomized-blocking-design-and-mixed-models</guid>
      <pubDate>Sat, 23 Dec 2023 11:40:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SVD 获得所需数量的因子 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635537/how-to-get-required-number-of-factors-using-svd</link>
      <description><![CDATA[我想将以下协方差矩阵分解为 U 和 psi
cov_matrix = np.array([[19, 30, 2, 12],
[30,57,5,23],
[2,5,38,47],
[12,23,47,68]])
L = np.array([[4, 7, -1, 1],[1, 2, 6, 8]]
psi = np.array([2, 4, 1, 3])
其中 np.dot(L.(L.T)) + psi = cov_matrix
我使用了 scikit learn 中的 SVD 和因子分析，但没有得到上述表格。有什么帮助吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635537/how-to-get-required-number-of-factors-using-svd</guid>
      <pubDate>Sat, 23 Dec 2023 09:59:13 GMT</pubDate>
    </item>
    <item>
      <title>第 i 个样本的期望值与随机变量的期望值</title>
      <link>https://stats.stackexchange.com/questions/635536/expected-value-of-ith-sample-versus-expected-value-of-a-random-variable</link>
      <description><![CDATA[考虑一个随机变量$X$。
当我们讨论随机变量的期望值$X$时，我们使用符号$\mathbb{ E}\左(X\右)$。
但是，我发现，在统计入门教科书中，他们使用符号 $\mathbb{E}\left(X_i\right)$，而我不确定这句话的确切含义是什么。
我的猜测是，当我们考虑 $X$ 的随机样本时，$[X_i]_{i= 1,\ldots,N}$，每个$X_i$都是一个随机变量，因此$\ mathbb{E}\left(X_i\right)$ 是有效的符号。
那么，$\mathbb{E}\left(X\right)$ 和  之间的确切区别是什么$\mathbb{E}\left(X_i\right)$?
我认为，如果我们假设样本是“随机”的绘制，$\mathbb{E}\left(X_1\right)=\ldots=\mathbb{E}\left(X_N\right)$，所以我们可以省略下标$i$。
但是，我不确定这是一个正确的解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/635536/expected-value-of-ith-sample-versus-expected-value-of-a-random-variable</guid>
      <pubDate>Sat, 23 Dec 2023 06:49:24 GMT</pubDate>
    </item>
    <item>
      <title>在神经网络训练过程中，训练损失先减少，然后遇到拐点并增加。有哪些可能的解释？</title>
      <link>https://stats.stackexchange.com/questions/635534/during-neural-network-training-training-loss-decreases-then-hits-an-inflection</link>
      <description><![CDATA[“在神经网络训练期间，训练损失先减少，然后达到拐点并增加。有哪些可能的解释？”
我在一次采访中得到了这个问题，并想知道在实践中可能出现这种情况的原因。我给出的答案本质上是，如果您有一个不平衡的数据集并且您的重采样有缺陷，那么您可能会过于频繁地对多数类进行采样。该模型可以学习预测，大多数情况下会导致准确性下降。]]></description>
      <guid>https://stats.stackexchange.com/questions/635534/during-neural-network-training-training-loss-decreases-then-hits-an-inflection</guid>
      <pubDate>Sat, 23 Dec 2023 03:19:57 GMT</pubDate>
    </item>
    <item>
      <title>在实践中充分理解“其他条件不变”的概念</title>
      <link>https://stats.stackexchange.com/questions/635531/understanding-well-the-concept-of-ceteris-paribus-in-practice</link>
      <description><![CDATA[ceteris paribus 的概念表示，要计算一个变量对另一个变量的影响，我们需要保持其他一切不变。我想很好地理解如何在假设的情况下做到这一点。
我有一个假设场景，其中给我一个数据集，其中包含影响学生数学成绩的所有可能的可观察和不可观察变量。这些变量包括学习时间、睡眠时间、休闲时间、收入和性别。我想使用其他条件不变的原则来计算学习时间对数学成绩的影响。使用 R，假设：
# 首先，让我们为 100 名学生创建一个随机数据集。
set.seed(123) # 为了重现性
n &lt;- 100 # 学生人数

# 为每个变量生成随机数据
收入 &lt;- rnorm(n，平均值 = 50000，sd = 10000)
Study_hours &lt;- rnorm(n, 均值 = 10, sd = 2)
sleep_hours &lt;- rnorm(n, 平均值 = 8, sd = 1)
休闲时间 &lt;- rnorm(n, 均值 = 6, sd = 1)
性别 &lt;- 样本(c(“男”,“女”), n, 替换 = TRUE)

# 将性别变量编码为虚拟变量
sex_dummy &lt;- ifelse(性别 == &quot;男&quot;, 1, 0)

# 假设数学成绩是这些变量的函数
math_grade &lt;- 2*学习时间 + 0.5*睡眠时间 - 0.3*休闲时间 + 0.00001*收入 + 性别虚拟

# 将所有内容放入 data.frame 中
data &lt;- data.frame(收入、学习时间、睡眠时间、休闲时间、性别、数学成绩)

对我来说，计算影响最简单的方法是执行以下操作：
# 现在，要分析学习时间对数学成绩的影响，请比较不同学习时间组的数学成绩。

# 例如，让我们将学习时间在 9 到 11 小时之间的学生与学习时间在 11 到 13 小时之间的学生进行比较。
group1 &lt;- data[data$study_hours &gt;= 9 &amp;数据$study_hours &lt; 11、]
group2 &lt;- data[data$study_hours &gt;= 11 &amp;数据$study_hours &lt; 13、]

# 计算每组数学成绩的平均值
Mean_group1 &lt;- 平均值(group1$math_grade)
Mean_group2 &lt;- 平均值(group2$math_grade)

# 学习时间对数学成绩的影响是平均值的差异
影响&lt;-mean_group2-mean_group1
影响


请注意，在计算上述影响时，我们没有控制其他变量。在其他条件不变的情况下如何使用？我们如何保持其他变量不变才能计算真正的影响？
我不确定如何在我的分析中应用这一原则。]]></description>
      <guid>https://stats.stackexchange.com/questions/635531/understanding-well-the-concept-of-ceteris-paribus-in-practice</guid>
      <pubDate>Sat, 23 Dec 2023 01:47:45 GMT</pubDate>
    </item>
    <item>
      <title>NMDS 的生态数据在 R 数据转换中包含许多零</title>
      <link>https://stats.stackexchange.com/questions/635530/nmds-with-ecological-data-containing-many-zeros-in-r-data-transformations</link>
      <description><![CDATA[我正在尝试对 R 中的混合分类数据执行 NMDS metaMDs()。我的分类单元数据按行作为观察值和列作为不同的分类单元进行组织。这些数据包含许多零。我发现使用 decostand(method=&quot;total&quot;) 或 decostand(method=&quot;wisconsin&quot;) 转换数据会导致我的 NMDS 发出压力警告值几乎为零。是否有任何建议、其他转换或其他排序技术可供我尝试处理此类数据？我试图拟合 NMDS 结果的环境数据包含因子和数值变量的混合。]]></description>
      <guid>https://stats.stackexchange.com/questions/635530/nmds-with-ecological-data-containing-many-zeros-in-r-data-transformations</guid>
      <pubDate>Fri, 22 Dec 2023 13:39:55 GMT</pubDate>
    </item>
    <item>
      <title>SEM：正态理论最大似然拟合函数</title>
      <link>https://stats.stackexchange.com/questions/635502/sem-normal-theory-maximum-likelihood-fitting-function</link>
      <description><![CDATA[我参加了一些课程，其中讨论了结构方程建模中通过最大似然进行的模型估计。我在经典文献中也发现了正态理论 ML 拟合函数的一个定义（例如 博伦，1989）：
$ \hat{F}_{ML} = \ln|\boldsymbol{\Sigma}(\boldsymbol{\theta})| + tr[\mathbf{S} \boldsymbol{\Sigma}(\boldsymbol{\theta})^{-1}] - \ln|\mathbf{S}|- p $
其中 $\boldsymbol{\Sigma}(\boldsymbol{\theta})$ 是模型隐含的协方差矩阵，$\mathbf{S}$ 是观察到的样本协方差矩阵，$p$ 是明显变量的数量。
Bollen (1989) 证明，当 $\hat{\boldsymbol{\Sigma}} = \mathbf{S}$ （且 $\boldsymbol{\Sigma}(\boldsymbol{\theta})$ 替换为 $\hat{\boldsymbol{\Sigma}}$ )，$\hat{F}_{ML}$ 为零，因此代表完美拟合。
但是，在课程中我看到了这样的规范：
$ \hat{F}_{ML} = \ln|\boldsymbol{\Sigma}(\boldsymbol{\theta})| + tr[\mathbf{S} \boldsymbol{\Sigma}(\boldsymbol{\theta})^{-1}] - \ln|\mathbf{S}|- p + [\mathbf{m}-\boldsymbol {\mu}(\boldsymbol{\theta})]&#39;\boldsymbol{\Sigma}^{-1}[\mathbf{m}-\boldsymbol{\mu}(\boldsymbol{\theta})] $
看起来平均结构也被添加到拟合函数中，其中 $\mathbf{m}$ 是观察到的平均向量，$\boldsymbol{\mu}(\boldsymbol{\theta})$ 是模型隐含的均值向量。
我的假设是，为什么有这两种不同的定义，因为在经典的 CFA（以及许多其他类型的更一般的 SEM）中，均值结构是饱和的，并且模型失配不可能来自均值结构。这意味着 $[\mathbf{m}-\boldsymbol{\mu}(\boldsymbol{\theta})]$ 为零，因为 $\mathbf{m}=\boldsymbol{\mu}(\boldsymbol{\theta})$ 并且附加项将消失。然而，我找不到任何文献证实这一点，所以如果有人知道第二个（更一般的）规范来自哪里或者可以更详细地解释它，我将非常感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/635502/sem-normal-theory-maximum-likelihood-fitting-function</guid>
      <pubDate>Fri, 22 Dec 2023 13:33:48 GMT</pubDate>
    </item>
    <item>
      <title>先前的信念有多主观？</title>
      <link>https://stats.stackexchange.com/questions/635486/how-subjective-are-prior-beliefs</link>
      <description><![CDATA[我发现术语“先验信念”有点模糊，贝叶斯分析中的先验信念可以接受什么？例如，我无法查看任何数据并自行决定“我相信总体平均值将约为 60 个单位”，无论这是基于直觉还是缺乏关心。对于“可靠”的先验信念是否有任何标准？]]></description>
      <guid>https://stats.stackexchange.com/questions/635486/how-subjective-are-prior-beliefs</guid>
      <pubDate>Fri, 22 Dec 2023 09:19:08 GMT</pubDate>
    </item>
    <item>
      <title>关于数据对数转换的有趣观察</title>
      <link>https://stats.stackexchange.com/questions/635466/an-interesting-observation-regarding-the-log-transformation-of-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635466/an-interesting-observation-regarding-the-log-transformation-of-data</guid>
      <pubDate>Fri, 22 Dec 2023 00:42:00 GMT</pubDate>
    </item>
    <item>
      <title>条件独立声明的表示[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635350/representation-of-conditional-independence-statement</link>
      <description><![CDATA[在[归纳集：祖先图马尔可夫模型的新视角] (http: //d-scholarship.pitt.edu/id/eprint/42158），有人提到
&lt;块引用&gt;
符号$V$表示非空变量集。令 $A, B, C \subseteq V(AB \neq \emptyset)$ 为不相交集合。 $N_{A,B |C} \equiv \bigcup_{T \subseteq ABC, T \nsubseteq AC, T \nsubseteq BC} \{T\}$,其中 $ABC =A \cup B \cup C$，$AC =A \cup C$， $BC =B \cup C$。然后使用 $N_{A, B |C}$ 定义与条件对应的集合的集合
独立声明$A, B|C$。

我们知道$A, B|C$表示给定C，A和B是条件独立的。
问题 1：为什么 $N_{A, B |C} $ 不包含 $AC$ 4和$BC$的子集？
问题 2：有人可以解释一下 $N_{A, B |C} $ 背后的直觉吗？
问题3：我认为条件独立语句$A, B|C$只存在于集合$AB$ 并设置 $ABC$，我的想法正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635350/representation-of-conditional-independence-statement</guid>
      <pubDate>Wed, 20 Dec 2023 15:38:31 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯深度学习中学习损失衰减的损失函数的推导</title>
      <link>https://stats.stackexchange.com/questions/635300/derivations-of-loss-functions-for-learning-loss-attenuation-in-bayesian-dl</link>
      <description><![CDATA[我对贝叶斯深度学习相当陌生，如果这是一个愚蠢的问题，我很抱歉。
我正在尝试实现本文中的工作：计算机视觉的贝叶斯深度学习需要哪些不确定性？

在整篇论文中，他们给出了最小化目标，使模型能够学习任意不确定性，但他们没有给出任何关于它们来自何处的正式推导。它们不是临时构造，因此必须有一种方法来派生它们。
哪里可以找到推导？
$$
\大的
\mathcal{L}(\theta,p) = -\frac{1}{N} \sum_{i=1}^N
 \text{log} \hspace{1 mm} p(\text{y}_i|\text{f}^\widehat{\text{W}_i}(x_i)) + \frac{1-p}{2N }||\theta||^2
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/635300/derivations-of-loss-functions-for-learning-loss-attenuation-in-bayesian-dl</guid>
      <pubDate>Tue, 19 Dec 2023 22:26:42 GMT</pubDate>
    </item>
    <item>
      <title>什么是 2 阶段估计器？</title>
      <link>https://stats.stackexchange.com/questions/635121/what-is-a-2-stage-estimator</link>
      <description><![CDATA[我以为我会很快找到这个问题的答案，也许我使用站点搜索功能的能力很差，但我没有找到两阶段估计器定义的答案。也许在这种情况下，答案是如此明显，以至于不需要定义。
它是一个通过首先进行中间计算（第一阶段）来计算估计值的估计器，然后将其结果用于第二（也是最后）阶段吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635121/what-is-a-2-stage-estimator</guid>
      <pubDate>Sun, 17 Dec 2023 15:07:40 GMT</pubDate>
    </item>
    </channel>
</rss>