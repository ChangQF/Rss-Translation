<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Thu, 10 Apr 2025 15:19:38 GMT</lastBuildDate>
    <item>
      <title>具有单个指示器的纵向建模，只有两个时间点</title>
      <link>https://stats.stackexchange.com/questions/663817/longitudinal-modelling-with-a-single-indicator-and-only-two-time-points</link>
      <description><![CDATA[ i具有单个指标变量的重复度量，并希望使用此指标和观察变量运行潜在的变更分数模型，并通过基于单个指示器的已知可靠性估计值指定误差方差来识别模型。但是，我还必须将因子加载固定为1，这意味着我无法测试度量或标量不变性。从我有限的理解来看，这大概可以杀死任何建模变化的想法，因为您无法分开随着时间的变化的真正变化，而随着时间的推移，随着时间的推移而变化的实际变化是真正的变化。我了解从技术上讲，我可以无视MI的关注点，并将我的单个指标视为没有测量错误的清单变量，但我觉得这不是一种特别可辩护的方法。
所以我的主要问题是，我该如何处理这些数据？我认为可能是某种模型，其中重点更多地是关于相互关联的，而不是明确地关注个体内部变化，例如跨滞后面板模型，但是我已经读过对这些模型的相当批评，而且我没有足够的波动来运行RI-CLPM。我也不确定我无法用这个单一指标向MI展示MI是否将是我运行的任何纵向模型的巨大问题。我读过一本最新的教科书，介绍了如何估计纵向SEM中单个指标的错误差异，这在IT中没有引用MI问题 - 这是否暗示有纵向方法可以与单个项目一起使用？
这是次要数据，因此不幸的是，我无法控制其性质，并且不太可能收集了另一波数据。我并不是真的想出可能的事情，所以如果上述任何假设/陈述是不正确的，请纠正我，当然，任何建议/资源都将不胜感激。 
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/663817/longitudinal-modelling-with-a-single-indicator-and-only-two-time-points</guid>
      <pubDate>Thu, 10 Apr 2025 14:06:53 GMT</pubDate>
    </item>
    <item>
      <title>如何使用R调查与具有复杂采样过程但仅提供一个无有关层或集群信息的抽样重量的调查数据。”</title>
      <link>https://stats.stackexchange.com/questions/663811/how-to-use-r-survey-with-survey-data-that-had-a-complex-sampling-process-but-off</link>
      <description><![CDATA[我正在使用具有相对复杂的采样过程（选择区域，然后是家庭，然后是家庭中的一个或多个人）的调查数据（不是我自己的）。但是，科学使用文件仅提供一个设计变量，即合并的采样和设计权重。鉴于此，我想知道如何使用调查包构建复杂的样本进行回归分析。到目前为止，我已经使用过：
  svy.dat＆lt;  -  svydesign（ids = 〜1，data = data，
                    strige =数据$ gewicht_w1）
 
鉴于我没有有关设计数据框架的数据的更多信息，这是允许的吗？我确实有针对居民和家庭的标识符。我可以使用这些构建一个数据框架，至少说明我可以对样本中的同一家庭有多个回复？]]></description>
      <guid>https://stats.stackexchange.com/questions/663811/how-to-use-r-survey-with-survey-data-that-had-a-complex-sampling-process-but-off</guid>
      <pubDate>Thu, 10 Apr 2025 11:50:20 GMT</pubDate>
    </item>
    <item>
      <title>纠正多重共线性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/663806/correcting-multicollinearity</link>
      <description><![CDATA[我正在对因变量（服务增值）对FDI（外国直接投资）和HC（人力资本）进行回归。我有一个高Vif＆gt; 10，然后我使用平均居中对此进行了更正。但是，我决定将其缩短一年（我的数据），因为额外的一年是错误的。但是，这重新引入了这个问题。为什么是这样。我有2个国家的数据大约有50年的数据。
对于上下文，我正在进行合并的OLS：
回归如下：
回归服务_v_added_pct_gdp fdi hc hc hc hc hc hc hc hc hc hc v2x_pubcorr export_goods_goods_services_prct_gdp gross_capital_capital_capital_pct_gdp_gdp brazil_dumm_dummy fdiummy fdi_brazil fdi_brazil hc_brazil hc_brazil hc_fdi_brazil robust robust robust robust robust robust robust robust 
在相互作用项和可变的HC中，多重共线性特别高。最初，我在与1970  -  2020年合作时遇到了这个问题，但是以平均居中进行了纠正，并带有Vif＆lt; 10，但是，在将日期更改为1970  -  2019年之后，我的多重共线性高16。
相互作用术语和HC是不可谈判的，因为这些回答了我的问题，即HC在结构转化过程中的吸收有效。 
  这是从1970- 2019年的数据
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/663806/correcting-multicollinearity</guid>
      <pubDate>Thu, 10 Apr 2025 10:39:41 GMT</pubDate>
    </item>
    <item>
      <title>分类的几何平均值计算</title>
      <link>https://stats.stackexchange.com/questions/663800/calculation-of-geometric-mean-for-classification</link>
      <description><![CDATA[考虑二进制分类，几何平均值被定义为 $ \ sqrt {precision \ times \ times Reque} = \ sqrt {\ frac {\ frac {tp} {tp+fp} {tp+fp} \ times \ times \ frac \ frac {tp {tp {但是可以有不同的TP/FP/FN值。例如，对于SVM，有一个ROC曲线，ROC曲线上的不同点具有不同的TP/FP/FN值。因此，我的问题是我们应该使用哪个TP/FP/FN值来计算几何平均值？或者我们应该计算ROC曲线上的所有可能的几何平均值并获得平均几何值？]]></description>
      <guid>https://stats.stackexchange.com/questions/663800/calculation-of-geometric-mean-for-classification</guid>
      <pubDate>Thu, 10 Apr 2025 10:19:24 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型的样本空间$ \欧米茄$是什么？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/663798/what-is-the-sample-space-omega-of-a-diffusion-model</link>
      <description><![CDATA[在降级扩散概率模型中（原始纸张），远期过程是Markov class ，其中每个 $ x_t \ in \ mathbb {r}^n $ 。什么是基本概率空间 $（\ omega，\ Mathcal {f}，\ Mathbb {p}）$  $ 该过程已定义？特别是，什么是 $ \ Omega $ ？它是 $（\ Mathbb {r}^n）^\ Mathbb {n} $ ？感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/663798/what-is-the-sample-space-omega-of-a-diffusion-model</guid>
      <pubDate>Thu, 10 Apr 2025 07:54:54 GMT</pubDate>
    </item>
    <item>
      <title>建模响应是可能审查值的总和</title>
      <link>https://stats.stackexchange.com/questions/663795/modelling-a-response-that-is-the-sum-of-possibly-censored-values</link>
      <description><![CDATA[一些同事的套件约有10个变量，代表样本中的化合物。某些变量中的某些值将被审查，低于所使用的实验室过程的检测极限。虽然主要的重点是建模如何单独地在不同处理下随着时间的流逝而单独进行一些变量，但我的同事们现在想要每个观察中这10个变量的总和的模型，我将在此处称为 total 。。
我知道估计平均值时审查数据的问题，我们一直在使用零增强的伽马模型和TOBIT模型作为单独建模主要响应变量的手段。。
但是，我不确定如何进行建模 total 响应，因为我不确定人们甚至首先要计算总和。从生物学上讲，这些以下检测极限值并没有真正增加我们具有一些审查值的样本中的总数。将这些值视为零会导致相同的偏差和不一致问题，以替代估算值的估计值的审查值？
是否有任何既定方法来处理此类数据？例如，我们可以以某种方式将这些审查的观测值的值算，然后在模型中使用这些值。我忽略了这样的问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663795/modelling-a-response-that-is-the-sum-of-possibly-censored-values</guid>
      <pubDate>Thu, 10 Apr 2025 07:48:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么95％的置信区间也不是95％的可信度？</title>
      <link>https://stats.stackexchange.com/questions/663794/why-is-the-95-confidence-interval-not-also-95-credible</link>
      <description><![CDATA[我知道，在频繁主义者对概率的解释中，说参数属于此特定间隔的概率95％（因为参数不是随机变量，并且要么属于间隔）。但是，从贝叶斯的角度来看，为什么95％CI也不是95％的可信度（平均）？？
考虑以下方案：

有一个带有95个黑球和5个白球的罐子。我选择了一个随机球。没有看球，我95％的人相信它是黑色的。
有100个间隔的列表，其中95个包含参数，而其他5个则没有。我在列表中选择了一个随机间隔。 不查看间隔，我95％的人相信它包含参数。 （当然，在我查看间隔并确定它看起来很荒谬之后，我可能会得出结论，它可能不包含参数）。
 100个频繁构建其95％的置信区间。我们知道，其中大约95个将具有一个包含参数的间隔。我选择了一个随机的频繁主义者，并进行时间间隔。不查看间隔，我95％的人相信它包含参数。
我是这100个常见者之一，我挑选了自己（应该没关系，因为谁在构建间隔的人独立于该间隔是否恰好包含参数）。我95％的人有信心我的间隔包含参数（在我实际研究我的间隔实际上是什么之前）。

如果有的话，这种推理出了什么？

There is a linked question Why does a 95% Confidence Interval (CI) not imply a 95% chance包含均值的？它表明，给定特定的CI，说参数在其中有95％的概率（贝叶斯方面）是不正确的。但是，我上面的理由适用于一般CI，然后才能了解CI的实际是什么，并询问这种CI的预期信誉是什么。
因此，当 $ [29，29] $ 在该反例中只有50％可信，我们不太可能获得 $ [29，29] $ 。很有可能，我们将获得类似 $ [28，29] $ 的东西，这是100％可信的。因此，如果根据频繁的协议执行实验，并且所得的CI为 $ i $ ，那么，平均而言，
  \ begin {align*}
\ pr（\ theta \ in I）＆amp; = \ pr（\ theta \ in I | i = [a，a]）\ pr（i = [a，a]）\\
＆amp;+\ pr（\ theta \ in I | i = [a，a+1]）\ pr（i = [a，a+1]）\\
  ＆amp; = 0.5 \ times 0.5 + 1 \ times 0.5 = 0.75
\ end {align*}  
因此“预期”信誉为0.75。

从这个意义上说，现在我是一个顽固的贝叶斯人。我可以得出结论，常见的方法在实践中起作用是正确的，因为它与贝叶斯的信誉间隔基本相同，但是有一块信息（CI的特定值）被蒙蔽了吗？只要丢失的信息不太明显（对于大多数实际情况来说是正确的，但对于 https：//xkcd.com/1132/1132/1132/1132/1132/ ，，，where＆quord fest y sunder;常见的CI几乎与贝叶斯可信间隔一样好？]]></description>
      <guid>https://stats.stackexchange.com/questions/663794/why-is-the-95-confidence-interval-not-also-95-credible</guid>
      <pubDate>Thu, 10 Apr 2025 07:37:59 GMT</pubDate>
    </item>
    <item>
      <title>了解贝叶斯在线更改点检测的推导</title>
      <link>https://stats.stackexchange.com/questions/663781/understanding-the-derivation-of-bayesian-online-changepoint-detection</link>
      <description><![CDATA[我正在阅读贝叶斯在线更改点检测。与第2节有关。我试图了解该算法是如何在第2节中得出的。我发现很难理解该方程3 
在论文中，作者试图对运行长度进行建模（ $ r_t $ ，在时间t的运行长度。运行长度是自上次更改点以来发生的数据点数，包括当前数据包括当前数据）））
它们以一组基本的假设开始：

数据序列分为非重叠分区
分区内的观察结果是独立的，并且分布相同（i.i.d。）
跨分区的参数是独立的
运行长度仅取决于先前的运行长度
新观察结果的可能性仅取决于当前运行中的数据（观察到了上次更改点以来的观察），而不是整个历史记录。当前运行中的数据是 $ \ BoldSymbol {x} _t^{（r）} $   

他们必须将关节分解在到目前为止观察到的数据上，并且运行长度以达到递归算法。他们像这样做到了：
  \ begin {equination}
p（r_t，\ boldsymbol {x} _ {1：t}）= \ sum_ {r_ {t-1}} p（r_t，r_t，r_t，t-1}，\ boldsymbol {x} _ {x} _ {1：t}）。
\ end {equation} 
接下来，他们观察到
 \ begin {equation}
p（r_t，r_ {t-1}，\ boldsymbol {x} _ {1：t}）= p（r_t，x_t \中间r_ {t-1}，\ boldsymbol {x} _ {1：t-1}）
\ end {equation} 
最后
 \ begin {equation}
p（r_t，x_t \ mid r_ {t-1}，\ boldsymbol {x} _ {1：t-1}）= p（r_t \ mid r_ {t-1}，\ boldsymbol {x} _ {1：t-1}） \ boldsymbol {x} _ {1：t-1}）。
\ end {equation}  
他们观察到，由于运行长度仅取决于他们可以编写的前一个运行长度，所以
 \ begin {equation}
p（r_t \ mid r_ {t-1}，\ boldsymbol {x} _ {1：t-1}）= p（r_t \ mid r_ {t-1}）
\ end {equation}  
，这是他们做我无法理解的事情
他们写信，
 \ begin {equation}
p（x_t \ mid r_t，r_ {t-1}，\ boldsymbol {x} _ {1：t-1}）= p（x_t \ mid r_ {t-1}，\ boldsymbol {x}
\ end {equation}  
其中 $ \ boldsymbol {x} _t^{（r）} $ 是当前运行中的数据
这有什么意义？我从我附上的论文的第2节中挑选了所有内容。]]></description>
      <guid>https://stats.stackexchange.com/questions/663781/understanding-the-derivation-of-bayesian-online-changepoint-detection</guid>
      <pubDate>Thu, 10 Apr 2025 00:27:52 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯估计是否需要有限的人口校正？</title>
      <link>https://stats.stackexchange.com/questions/663568/does-bayesian-estimation-need-finite-population-correction</link>
      <description><![CDATA[贝叶斯估计是否假定无限的人口，不需要有限的人口校正？
说，我们想估计有限人口的平均值，假设IID值是在正态分布中替换而不替换的。]]></description>
      <guid>https://stats.stackexchange.com/questions/663568/does-bayesian-estimation-need-finite-population-correction</guid>
      <pubDate>Sat, 05 Apr 2025 23:52:19 GMT</pubDate>
    </item>
    <item>
      <title>递归的贝叶斯更新高斯分布，观察到有限的观察</title>
      <link>https://stats.stackexchange.com/questions/663311/recursive-bayesian-updating-for-gaussian-distribution-with-limited-observations</link>
      <description><![CDATA[考虑以下自适应贝叶斯推理方案：
我们依次和独立地绘制随机变量： $$ x_i \ sim n（\ mu，\ sigma^2），$$ 
具有已知方差 $ \ sigma^2 $ 和未知的平均值 $$ \ mu \ mu \ sim n（\ mu_0，\ sigma^2_0）。$$ 
我们定义了一系列后验表示 $ \ mu_i $ 如下：
最初，at  $ i = 1 $ ，我们将阈值设置为 $ \ mu_0 $ 。然后，我们只观察到指标：
 $$ y_1 = 1 \ {x_1 \ geq \ mu_0 \}。$$ 
仅使用此二进制观察 $ y_1 $ ，我们为 $ \ MU $ $ 形成后分布，并获得后平均值 $ \ MU_1 $ \ MU_1 $ 。
在时间 $ i = 2 $ ，新的抽奖 $ x_2 $ 是制作的，我们表示 $ y_2 = 1 = 1 \ \ \ \ \ {x_2 \ geq \ geq \ geq \ mu_1 \ 。我们观察二进制成果 $ y_1 $ ， $ y_2 $ ，并更新以前的分发，并计算 $ \ mu_2 $  $   。
在时间 $ i = 3 $ ，同样，我们有一个新的抽奖 $ x_3 $ ，结果 $ y_3 $ ，我们只观察：仅观察：：
 $$ y_1，y_2，y_3，$$ 
我们仅基于这三个实现。
继续以这种方式继续，在一般时间 $ t $ ，我们观察到：$ y^t =（y__1，\ cdots，y_t）。
所使用的阈值始终是上一个步骤中的后验表示（ $ \ mu_ {i-1} $ ），因此观察 $ y_i $  n n n n deportional也不是独立的。
问题：
 $ \ mu $ 的后验分布，基于观察 $ y^t $ 形成class =“ Math-Container”&gt; $ t \ rightarrow \ infty $ ？
由于非IID数据，我们不能将Doob或Freedman的定理用于一致性... 
我会感谢您对这种适应性，综合信息方案和相关理论的参考的见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/663311/recursive-bayesian-updating-for-gaussian-distribution-with-limited-observations</guid>
      <pubDate>Mon, 31 Mar 2025 02:37:15 GMT</pubDate>
    </item>
    <item>
      <title>我不明白为什么我的MCMCGLMM型号具有很高的自相关[关闭]</title>
      <link>https://stats.stackexchange.com/questions/663125/i-dont-understand-why-my-mcmcglmm-model-has-high-autocorrelation</link>
      <description><![CDATA[我第一次在McMCGLMM中进行遗传力分析。我的数据是二进制的，所以我正在使用“阈值”。家庭。我在获得良好的有效样本量（ESS）方面遇到了一些麻烦，因此可以使用更长的时间（550万个迭代），尽管由于R的内存限制而将其设置为220。
我最低的ESS现在是720，所以这对我以前的事物是一个很大的进步，但是当我使用Autocorr（）测试自相关时，仍然说它疯狂地高。我的痕迹对我来说还可以，从看着它们，我似乎已经适当地设置了刻录期。
我做了一个自相关图，这向我显示了“动物”的自相关下降。从第二个样本上的0.9到40日的0.02大约0.02。该情节在那里结束（我不知道如何让我显示以后的样本），但大概它继续向0趋向0。
我有几个问题：

这是否意味着我毕竟没有足够长时间的燃烧时间？ （或者它是模型如何进行的工件，我总是会得到这种形状？）
我不仅可以丢弃这些初始样本吗？我肯定有足够高的样本量可以做到这一点。
痕迹图仅显示燃烧后的时期？看起来一定是一切，但我只是想检查（似乎可以解释我的问题，如果他们这样做）。
]]></description>
      <guid>https://stats.stackexchange.com/questions/663125/i-dont-understand-why-my-mcmcglmm-model-has-high-autocorrelation</guid>
      <pubDate>Tue, 25 Mar 2025 18:14:33 GMT</pubDate>
    </item>
    <item>
      <title>PLS-SEM和共线性</title>
      <link>https://stats.stackexchange.com/questions/663118/pls-sem-and-collinearity</link>
      <description><![CDATA[我希望有人可以帮助我解决这个问题或将我指向正确的方向。
我最近通过PLS-SEM进入了结构方程建模（SEM）。但是，我遇到了处理共线性的问题，我不知道该怎么做。
例如，在使用R中的Seminr进行建模时，我可以通过查看每个变量的VIF输出来轻松识别问题。从机器学习的角度来看，可以使用类型的法规，例如L1或L2，但是这些包中似乎并未在我知道的任何软件包中实现（也许有人知道吗？）
我考虑过在设置模型之前执行PCA，但这是个好主意吗？我还没有看到有人这样做，也许有一个明显的原因我错过了？
所以我的问题归结为：
（1）是否有一些框架为SEM实现了正则化方法？
（2）在执行PLS-SEM之前，例如PCA（或其他维度减少方法）是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/663118/pls-sem-and-collinearity</guid>
      <pubDate>Tue, 25 Mar 2025 16:05:12 GMT</pubDate>
    </item>
    <item>
      <title>聚合（部分等级）相关系数</title>
      <link>https://stats.stackexchange.com/questions/663104/aggregating-partial-rank-correlation-coefficients</link>
      <description><![CDATA[我正在对每个流行模型进行灵敏度分析
 Blower 1994 ，即：
拉丁超立方体抽样
（ lhs ）
从参数（模型输入）先验，然后
部分等级相关系数
（ prcc ）
对于带有兴趣输出的每个参数， $ y $ 。
感兴趣的参数是
对称9  $ \ times $  9 contact matrix  $ x_ {ij {ij} $ 。
假设 $ x_ {ij} \ sim \ text {exp}（\ lambda_ {ij}）$ 其中 $ \ lambda_ {ij} {ij} $ 已知。
通常的LHS-PRCC方法将产生系数 $ \ rho_ {ij} $ 
和 $ h_0：\ rho_ {ij} = 0 $ 的p-value
对于每个唯一参数（总计45个），这很多。
我正在寻找一种总结/汇总每个组的系数 $ G $ 。。
 选项1 
最简单的是，我们可以报告中位数（最小[IQR] max）系数 $ \ rho_ {ij} $ 对于每个组 $ i $ i $ ;但是如何处理显着性测试？
 选项2 
我们可以调整LHS依次检查每个组，使用 $ x_i \ sim \ sim \ text {exp}（\ lambda_i）$ 与每个 $ x_&gt; $ x_&gt; $ x_ {ij} $ span&gt; span-clast class clast clast clast =“ span class”这将破坏 $ x_ {ij} $ 的对称性。
 选项3 
在这种准层次结构的情况下，是否有一种汇总（PRCC）相关系数的方法？理想情况下，这种汇总可以维持统计解释，因此我们可以分配“重要性”。 （例如，拒绝 $ h_0 $ ： $ \ rho_ {ij} = 0，〜\ forall j $ ）。）。）。]]></description>
      <guid>https://stats.stackexchange.com/questions/663104/aggregating-partial-rank-correlation-coefficients</guid>
      <pubDate>Tue, 25 Mar 2025 11:29:13 GMT</pubDate>
    </item>
    <item>
      <title>如何改善VAE中图像的分离？</title>
      <link>https://stats.stackexchange.com/questions/663063/how-to-improve-segregation-of-images-in-vaes</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/663063/how-to-improve-segregation-of-images-in-vaes</guid>
      <pubDate>Mon, 24 Mar 2025 13:51:51 GMT</pubDate>
    </item>
    <item>
      <title>Python中的时间序列预测问题</title>
      <link>https://stats.stackexchange.com/questions/653568/time-series-forecasting-problem-in-python</link>
      <description><![CDATA[我正在从事一个Python项目，我必须在该项目中预测单个家庭的能源消耗。我的数据集由数千个家庭组成，每个家庭每月都有2年的月度价值，但仅在某些月（01-05）中，因此每个家庭的时间序列是a  $ 10 $ 点时间序列。每个家庭都有其他时间依赖性变量，即局部湿度/温度指数，并且几个不依赖时间的特征连续存在，例如房屋尺寸（区域），邮政编码和分类，例如居民拥有家，居民有孩子。任务是使用此信息预测每个家庭的未来几个月的能耗值。
数据集看起来像这样：
 


 house_id 
月
年
 zipcode 
 en_cons 
 weather_idx 
大小
拥有
 has_children 




 1 
 1 
 2021 
 12 
 4.33 
 19.6 
 71 
 0.0 
 1.0 


 1 
 2 
 2021 
 12 
 4.35 
 17.6 
 71 
 0.0 
 1.0 


 1 
 3 
 2021 
 12 
 4.56 
 12.3 
 71 
 0.0 
 1.0 


 1 
 4 
 2021 
 12 
 4.77 
 15.9 
 71 
 0.0 
 1.0 


 1 
 5 
 2021 
 12 
 5.12 
 19.3 
 71 
 0.0 
 1.0 


 1 
 1 
 2022 
 12 
 4.83 
 19.9 
 71 
 0.0 
 1.0 


 ... 
 ... 
 ... 
 ... 
 ... 
 ... 
 .. 
 ... 
 ... 


 1 
 5 
 2022 
 12 
 5.49 
 18.7 
 71 
 0.0 
 1.0 


 2 
 1 
 2021 
 44 
 6.12 
 17.3 
 63 
 1.0 
 0.0 


 ... 
 ... 
 ... 
 ... 
 ... 
 ... 
 .. 
 ... 
 ... 


 10000 
 5 
 2022 
 99 
 5.55 
 14.3 
 100 
 1.0 
 1.0 


 
我试图弄清楚要实施的ML模型以预测未来几个月的 en_cons 以及如何在模型中包括家庭的其他信息。
据我了解，在时间序列预测中使用的典型模型（例如Arima（及其变化））仅作为输入，仅将时间戳和要预测的数量的值（它们预测一个时间 $ t $ t $ 仅基于早期的值，仅基于早期的time times 
另外，由于我想预测每个家庭的能耗，这意味着我只有 $ 10 $ 每个家庭的时间点来创建测试和训练样本，这似乎太少了。这也意味着我必须为每个家庭创建一个单独的模型。这是正确的方法吗？有没有一种方法可以使用所有数据创建某种“全局”模型并为每个家庭分开预测？]]></description>
      <guid>https://stats.stackexchange.com/questions/653568/time-series-forecasting-problem-in-python</guid>
      <pubDate>Thu, 29 Aug 2024 16:52:14 GMT</pubDate>
    </item>
    </channel>
</rss>