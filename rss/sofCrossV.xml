<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 29 Apr 2024 06:19:56 GMT</lastBuildDate>
    <item>
      <title>Frisch-Waugh-Lowell 定理的特例</title>
      <link>https://stats.stackexchange.com/questions/646069/special-case-of-frisch-waugh-lowell-theorem</link>
      <description><![CDATA[该公式只是 FWL 的一个特例。假设我们有一个分区回归， $Y=X_1\beta_1+X_2\beta_2+\epsilon$ 但带有 $X_2$&lt; /span&gt; 是 $n\times 1$ 和 $\beta_2$ 常量。
通过回归 $b_1,b_2$ 成为 $\beta_1,\beta_2$ 的两个 OLS 估计量$X_1,X_2$ 上的 class=&quot;math-container&quot;&gt;$Y$。 $\tilde \beta_1$ 是在 $Y$ 上回归时的 ols 估计器仅container&quot;&gt;$X_1$，并且$\delta$是回归$X_2$时的估计器$X_1$ 上的 span&gt;。
我们想要显示 $\tilde\beta_1=b_1+\delta b_2$。
我认为这应该是FWL的推论，我可以使用$X_1,X_2,Y$的矩阵乘法写出这些系数的值，但是我不知道下一步该做什么。我应该尝试操纵矩阵吗？但我无法得到结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/646069/special-case-of-frisch-waugh-lowell-theorem</guid>
      <pubDate>Mon, 29 Apr 2024 05:16:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的神经网络不学习？我正在使用带有单个隐藏层的 numpy 实现简单的反向传播，以进行二元分类</title>
      <link>https://stats.stackexchange.com/questions/646068/why-isnt-my-neural-network-learning-i-am-implementing-simple-backpropagation-u</link>
      <description><![CDATA[这是我的神经网络的代码（data[i] 是填充二进制数据的向量，标签是二进制的）。经过大量的 epoch，所有数据的输出都趋向于 1（例如 0.99），无论是 0 还是 1。然而，与 0 标签相关的输出似乎更接近 0.97。我只是不知道为什么会发生这种情况。
 # 初始化
    n，输入大小=数据.形状
    总权重大小 = 输入大小*(输入大小+1)+(输入大小+1)
    边界 = 1/math.sqrt(input_size)
    权重 = np.random.uniform(-bound,bound,totalWeightSize)
    theta1 = 权重[:input_size * (input_size+1)].reshape(input_size, input_size+1)
    theta2 = 权重[输入大小 * (输入大小+1):]
    偏差 1, 偏差 2 = 1, 1
    对于范围 (10) 内的 j：
        print(&quot;纪元&quot; + str(j))
        delta1 = np.zeros_like(theta1)
        delta2 = np.zeros_like(theta2)
        对于范围内的 i(data.shape[0])：
            如果我％100==0：
                打印（一）
            # 前向道具
            yi = 标签[i]
            a1 = np.insert(数据[i], 0, 偏差1)
            z2 = θ1 @ a1
            gz2 = sigmoidFunc(z2)
            a2 = np.insert(gz2, 0, 偏差2)
            z3 = θ2 @ a2
            a3 = sigmoidFunc(z3)
            # 反向传播
            d3 = a3 - yi
            gpz2 = a2[1:] * (1 - a2[1:])
            d2 = (theta2[1:].T * d3) * gpz2

            delta1 += d2[:, 无] @ a1[无, :]
            delta2 += (d3 * a2)
        平均调节梯度 1 = (1/n)*delta1
        平均调节梯度2 = (1/n)*delta2
        theta1 -= AvgRegGrad1
        theta2 -= AvgRegGrad2
    返回（theta1，theta2）
]]></description>
      <guid>https://stats.stackexchange.com/questions/646068/why-isnt-my-neural-network-learning-i-am-implementing-simple-backpropagation-u</guid>
      <pubDate>Mon, 29 Apr 2024 05:05:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在生成潜变量分类器中进行预测（评估边际似然）？</title>
      <link>https://stats.stackexchange.com/questions/646067/how-to-do-prediction-evaluate-marginal-likelihood-in-generative-latent-variabl</link>
      <description><![CDATA[
数据集为 $\{\boldsymbol x_t,y_t\}$ for $t=1,\dots, T$，其中 $y_t \in \{0,1\}$。
定义一个生成潜变量分类器，其板图如上所示。
对于每个数据点，关联一个本地潜在 $z_t$，其先验由超参数 $\eta$&lt; /跨度&gt;。条件概率 $p(\boldsymbol x_t \mid z_t)$ 和 $p(y_t \mid z_t)$ 由固定模型参数 $\boldsymbol\theta$ 参数化。由于证据棘手，后验 $p(z_t \mid \boldsymbol x_t,y_t)$ 也很棘手。
使用变分 EM 拟合模型非常简单。困扰我很长时间的是如何对新数据进行预测，即求概率 $p(y \mid \boldsymbol x,\boldsymbol\theta, \eta)$ 。
由于 $p(y \mid \boldsymbol x,\boldsymbol\theta,\alpha) \propto p(y,\boldsymbol x \mid \boldsymbol\theta,\eta)$&lt; /span&gt;，我们只需要评估后一种形式，即证据。
然而，如上所述，证据很棘手：
$$
p(y,\boldsymbol x \mid \boldsymbol\theta,\eta) = \int p(z \mid \eta) p(y,\boldsymbol x \mid z,\boldsymbol\theta)\,\mathrm d z
$$
其中 $z$ 位于某个高维空间（有一些约束的欧几里得空间）。
我的尝试：

我尝试过天真的蒙特卡洛。我从 $p(z \mid \eta)$ 中采样，这很简单，并估计 $p( y,\boldsymbol x \mid z,\boldsymbol\theta)$。这当然失败了。
我尝试过重要性采样。重要性分布设置为 $q(z)$，其中 $q(z) \approx p(z \mid y,\boldsymbol x,\boldsymbol\theta,\eta)$ 通过变分推理（例如，平均场近似）找到。如果 $q(z)$ 与后验完全匹配，则方差应该为零。从 $q(z)$ 采样很容易。然后我找到平均值 $p(z \mid \eta)/q(z) p(y,\boldsymbol x \mid z,\boldsymbol\theta)$ 。令人惊讶的是，似乎采样 100k 次仍然无法对证据产生良好的估计，因为我无法有效地区分 $\log p(y=0,\boldsymbol x \mid \ boldsymbol\theta,\eta)$ 和 $\log p(y=1,\boldsymbol x \mid \boldsymbol\theta,\eta)$ .
我知道 Metropolis-Hastings 算法，该算法在高维中更容易使用 (墨菲，2012）。但我不知道如何将其应用于我的问题，因为从 $p(z \mid \eta)$ 采样已经是一个简单的问题。
我直接使用证据下界 (ELBO) 进行预测，但失败了，因为它偏差太大且区分度不够。

如果删除 $y_t$ 变量，我还发现这个问题有点与 VAE 中的边际似然估计相关。在 (Kingma &amp; Welling, 2014) 中，作者声称边际可能性只能在低维设置。
我的问题：是否有关于如何使用这种生成潜变量分类器进行预测的通用指南？我觉得这应该是一个简单的问题......或者也许我没有走在正确的轨道上 - 应该尝试一些除了找到预测的边际可能性之外的东西？
非常感谢您的帮助和建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/646067/how-to-do-prediction-evaluate-marginal-likelihood-in-generative-latent-variabl</guid>
      <pubDate>Mon, 29 Apr 2024 05:02:37 GMT</pubDate>
    </item>
    <item>
      <title>预测里程碑</title>
      <link>https://stats.stackexchange.com/questions/646066/predicting-milestones</link>
      <description><![CDATA[我有详细说明正在进行的特定项目以及它们何时实现某些里程碑的数据。我试图根据这些里程碑日期来预测项目的结束日期。日期的示例如下：
ID 里程碑 1 里程碑 2 里程碑 3 结束日期 1 08-10-2022 08-24-2022 09-25-2022 10-08-2022 2 09-15-2022 10-10-2022 10-25-2022 11 -04-2022 3 08-17-2022 9-10-2022 10-01-2022 10-26-2022 我还有其他可用的变量，例如项目的位置，但这些变量已被证明远没有那么强大。 
将这个模型付诸实践时遇到了困难。当预测正在进行的项目的结束日期时，他们可能尚未达到所有里程碑。为了模拟这一点，我找到了里程碑之间的平均持续时间，找到了实时数据中缺失里程碑的比例，然后人为地从我的建模数据中删除了该数量，并插入了之前非缺失里程碑日期的总和加上平均持续时间，为那些缺失的事件创建估算的里程碑日期。然后，我将所有这些日期转换为序数并创建了几个模型。
结果非常好，我在大约 12 天的 3 次交叉验证中获得了平均绝对误差。然而，当我在实时（而不是建模）数据上将其付诸实践时，我注意到绝大多数预测的结束日期都落后于我的里程碑 3，并且尽管这些项目正在进行中，但都落后于今天的日期。 
这让我意识到我的过程的天真......通过使用最大结束日期只能到今天的日期的建模数据，那么我对实时数据的预测可能不会超过这个，这就是模型的全部要点.
既然我已经意识到自己的错误，你们会建议我做什么呢？我考虑过使用里程碑之间的持续时间，但这可能最终只是发生的最后一个里程碑日期，加上到结束日期的平均持续时间。这在我的测试中并没有产生显着的结果，这就是我所希望实现的一切吗？任何替代方法将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/646066/predicting-milestones</guid>
      <pubDate>Mon, 29 Apr 2024 03:50:54 GMT</pubDate>
    </item>
    <item>
      <title>Newey-West HAC 协方差估计量中的权重如何使其成为正半定？</title>
      <link>https://stats.stackexchange.com/questions/646065/how-does-the-weighting-in-newey-west-hac-covariance-estimator-make-it-positive-s</link>
      <description><![CDATA[我了解到 Newey-West 协方差估计量的一个重要动机是协方差矩阵的简单估计量不一定是半正定的（从现在开始为 psd）（请参阅下面的参考链接，其中最后一个链接是提出此 HAC 协方差估计量的 Newey-West 1987 论文的论文链接）。
https://en.wikipedia.org/wiki/Newey%E2%80%93West_estimator
https://www.econometrics-with-r.org/15.4-hac-standard-errors.html
https://www.jstor.org/stable/1913610
以下是论文中介绍朴素估计量的段落，它不是必然psd:

下面这段是newey-west HAC估计量:

对比这两个公式，我们可以看出newey-west HAC估计量只是在原有估计量上增加了权重$w(j,m)$。因此，似乎加权是制定新估计量 $\widehat{S}_T$ psd 的关键。但这里有两点让我感到困惑，一是在突出显示的部分，作者声称 $\widehat{S}_T$ 的 psd 遵循样本自协方差 $\widehat{\Omega}_j$ 的 psd（而不是权重）。由于样本自协方差 $\widehat{\Omega}_j$ 已经存在于方程 (4) 中的朴素估计量中，它怎么可能不能保证朴素估计量 $\widetilde{S}_T$ 的 psd，而只能保证新估计量 $\widehat{S}_T$ 的 psd？第二件让我感到困惑的事情是，通常我们可以通过某种对称化来制作矩阵 psd，即 $A$ 变成 $A&#39;A$，并且直观地看不出求和中的权重如何使非 psd 矩阵 psd？一些关于底层机制的直观解释，或者一些关于它们证明的直观解释会很棒！]]></description>
      <guid>https://stats.stackexchange.com/questions/646065/how-does-the-weighting-in-newey-west-hac-covariance-estimator-make-it-positive-s</guid>
      <pubDate>Mon, 29 Apr 2024 03:45:14 GMT</pubDate>
    </item>
    <item>
      <title>证明 Wald 统计量 = 线性限制数乘以 F 统计量</title>
      <link>https://stats.stackexchange.com/questions/646062/prove-wald-statistic-number-of-linear-restrictions-times-f-statistics</link>
      <description><![CDATA[我正在考虑 $F[J,n-k]= \displaystyle \frac{(e_{*}^{&#39;}e_{*}-e&#39;e) \backslash J}{e&#39;e\backslash (n-k)}$，其中 $J$ 代表限制数量。我想证明 $W=(Rb-q)&#39;(Rs^2(X&#39;X)^{-1}R&#39;)^{-1}(Rb-q) =JF$，其中 $s^2=\displaystyle{\frac{e&#39;e}{n-k}}$。因此足以显示 $(e_{*}^{&#39;}e_{*}-e&#39;e)$ 是 $(Rb-q)&#39;(R(X&#39;X)^{-1}R&#39;)^{-1}(Rb-q)$,$ R$代表限制。
在格林的教科书中，他陈述了这一点，但我不知道如何得出它。
在一个可能更简单的特定示例中，考虑分区线性回归模型 $Y=X_1\beta_1+X_2\beta_2+\epsilon$ 和 $H_0$:$\beta_2=0$，所以 $Rb-q =b_2$，它是 $\beta_2$ 的 OLS 估计器。$\beta_1$是 $k_1\times 1$ 且 $\beta_2$ 是 $k_2\times 1$ 所以 $J$ 应该是 $k_2$。我们想要 $k_2F=W$。但即使在这个例子中我也不知道如何导出它。
您能否先给出示例中的证明，然后再给出一般情况下的证明？]]></description>
      <guid>https://stats.stackexchange.com/questions/646062/prove-wald-statistic-number-of-linear-restrictions-times-f-statistics</guid>
      <pubDate>Mon, 29 Apr 2024 02:50:22 GMT</pubDate>
    </item>
    <item>
      <title>假设检验问题中的渐近分布和描述增加功效的来源</title>
      <link>https://stats.stackexchange.com/questions/646061/asymptotic-distribution-and-describe-sources-of-increasing-power-in-an-hypothesi</link>
      <description><![CDATA[我目前在过去的考试中遇到以下问题（没有解决方案）：
&lt;块引用&gt;
假设 $S$ 服从泊松分布，平均值为 $2\lambda&gt;0$，这里 &lt; span class=&quot;math-container&quot;&gt;$\lambda$ 是一个参数。另外两个随机变量 $X,Y$ 是条件独立的伯努利随机变量，给定 $S=s$，并具有以下分布
$$P(X=1|S=s)=2^{-1-s},\,P(Y=1|S=s)=2^{-s }\theta.$$
这里 $\theta\in(0,1)$ 是第二个参数，$S$ 是不可观察的。假设我们观察到 $n$ i.i.d.复制 $(X_i,Y_i)$ 的 $(X,Y)$。

&lt;块引用&gt;
(1) 求 $\hat{\theta}_n:=\frac{\bar{Y}_n}{2\bar{X}_n} 的渐近分布$，其中 $\bar{X}_n,\bar{Y}_n$ 是  的平均值$X_i,Y_i$。

我认为我们可以使用多元中心极限定理来解决这个问题。很清楚
$$E(X)=E(E(X|S))=E(2^{-S-1})=\frac{1}{2}\sum_{ s\geq0}e^{-2\lambda}\frac{(2\lambda)^s}{s!}2^{-s}=\frac{1}{2}e^{-\lambda}。 $$
类似地 $E(Y)=E(E(Y|S))=\theta e^{-\lambda}.$ 请注意
$$E(XY)=E(E(XY|S))=E(E(X|S)E(Y|S))=\frac{\theta}{ 2}E(2^{-2S})=\frac{\theta}{2}e^{-\frac{3}{2}\lambda}.$$
所以 $Cov(X,Y)=\frac{\theta}{2}(e^{-\frac{3}{2}\lambda}-e^{-2 \lambda}).$ 方差由下式给出
$$Var(X)=E(E(X^2|S))-E(X)^2=E(E(X|S))-E(X) ^2=E(X)-E(X)^2=\frac{1}{2}e^{-\lambda}-\frac{1}{4}e^{-2\lambda}.$$ 
$$Var(Y)=E(E(Y^2|S))-E(Y)^2=E(E(Y|S))-E(Y) ^2=E(Y)-E(Y)^2=\theta e^{-\lambda}-\theta^2 e^{-2\lambda}.$$
所以根据中心极限定理，我们知道
$$\sqrt{n}((\bar{X}_n,\bar{Y}_n)-(EX,EY))\to N((0,0), \begin{bmatrix}Var(X)&amp;Cov(X,Y)\\Cov(X,Y)&amp;Var(Y)\end{bmatrix}).$$
从连续性映射定理我们可以推导出渐近分布，但我不知道如何计算它。
&lt;块引用&gt;
(2) 考虑测试 $H_0:\theta=0.5$ 与$H_1:\theta\neq0.5$。构建精确的检验统计量。描述随着 $\theta$ 远离 $0.5$ 增加力量的来源。

现在这是我的问题：
(a) 我在第一个问题中做的事情正确吗？如果是，那么渐近分布是什么？
(b) 对于 (2) 我不知道如何构建精确的检验统计量（也许我可以使用 $\hat{\theta}_n$在（a）中构建？但渐近分布对我来说不清楚。），并且我不知道如何总结增加功率的来源。你能给我一些提示或指导吗？
任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/646061/asymptotic-distribution-and-describe-sources-of-increasing-power-in-an-hypothesi</guid>
      <pubDate>Mon, 29 Apr 2024 02:29:58 GMT</pubDate>
    </item>
    <item>
      <title>我在 Python 中的假设检验中在哪里犯了错误？</title>
      <link>https://stats.stackexchange.com/questions/646059/where-am-i-making-a-mistake-with-this-hypothesis-test-in-python</link>
      <description><![CDATA[我测量了以下体温：
&lt;块引用&gt;
99.6
97.8
98.7
99.2
99.1
96.9
99.9
98.7
97.6
98.7
99.2
97.4 99 98
98.8
98.1 99
98.2
97.9
99.5
97.7
97.8
98.3 98
98.6
96.9
98.6
98.4
98.3 98
97.9
98.8
98.8
98.7
97.2
97.7
98.2
96.4
98.8
98.2 98
98.8
98.8
98.5
98.3
97.7
98.2
98.4 100
98.2
98.9
97.8 99
98.6
98.7
98.7
98.8
98.4
97.9
98.4
99.3
100.8
99.4
97.8
98.8
97.2
98.4
98.2 97 98
98.2
98.3
98.6
98.8
99.2
96.8
98.4 98
97.6
98.4
98.9
97.1
97.4
98.8
96.8 97
98.2
97.8
97.9
98.5
98.6
97.8 98
98.6
97.7
97.8
98.2
97.4 97
97.6
98.8
97.2 97
98.8
98.4
98.3
99.1
97.6
97.3 98 97
98.7
99.4 98
98.4
98.6 98
98.1 99
99.2
97.4
97.5
98.5
97.4
96.6
98.1
98.6
98.4
98.8
97.5
98.2
96.2
98.4
98.2
97.3
98.6 99 99
98.6
98.2 98
97.9
98.4
97.8 98
99.2
98.7
98.3

然后我的作业要求
&lt;块引用&gt;
平均体温是否等于 $98.6^\circ$F？运行一个假设
测试一下就知道了。然后根据平均值构建置信区间。

这是一个“Python 中的统计”类，因此所有解决方案都使用 Python 代码。上述数据被读入名为 temps 的 Pandas 数据帧中。
我的假设是平均值等于 98.6，而另一种情况是它不相等（即双面测试）。
我从开始
&lt;前&gt;&lt;代码&gt;# 测试
阿尔法 = 0.05
# 确定样本大小
n = len(temps[“BodyTemp”])
# 确定样本标准差
s = stats.stdev(temps[“BodyTemp”])
# 和样本均值
xbar = stats.mean(temps[“BodyTemp”])
# 计算我们的检验统计量
t = (xbar - 98.6)/(s* math.sqrt(n))
打印（t）

这会产生 -0.04073692590024498 的检验统计量。然后...
# 临界值
# 对于两侧测试，我们使用 alpha/2
tcrit = stats.t.ppf(q=1-(alpha/2),df=n-1)
打印（tcrit）

结果为 1.9762333088845878。 $t &lt; tcrit$，未能拒绝平均值为98.6的null。
但是根据我得出的置信区间
# 置信区间
# 对于置信区间，我们使用大于 2 的 alpha
tconf = stats.t.ppf(q=1-(alpha/2),df=n-1)
half_width = (tconf * s)/math.sqrt(n)
低 = xbar - half_width
高 = xbar + half_width
print(“(”，低，“，”，高，“)”)

这会产生一个置信区间(98.115, 98.354)，我预计 98.6 会位于该区间内。显然我在某个地方搞砸了，但我没有发现在哪里。]]></description>
      <guid>https://stats.stackexchange.com/questions/646059/where-am-i-making-a-mistake-with-this-hypothesis-test-in-python</guid>
      <pubDate>Mon, 29 Apr 2024 01:41:55 GMT</pubDate>
    </item>
    <item>
      <title>msm 包：“vmmin”中的多状态模型初始值不是有限的</title>
      <link>https://stats.stackexchange.com/questions/646057/msm-package-mutlti-state-model-initial-value-in-vmmin-is-not-finite</link>
      <description><![CDATA[我是 msm 包和马尔可夫模型的新手。我有一个随机试验数据集，其中包含三个时间点的读数：基线、1 年和 2 年。我正在尝试计算以下两种情况下每个状态的年度转换概率和平均 soujurn 时间。

NGT 至 iIFG 以及回归至 NGT 或进展为糖尿病（即 NGT &lt;-&gt; iIFG -&gt; 糖尿病）
NGT 到 iIFG 再到糖尿病（即 NGT -&gt; iIFG -&gt; 糖尿病）

状态是血糖状态（NGT（状态=1）、iIFG（状态=2）和糖尿病（状态=3））。糖尿病是吸收状态。
这是我的数据的样子。请注意，并非所有参与者都具有所有 3 个时间点的读数，但所有人都具有至少 2 个时间点（基线和 1 年）的读数。 df 中没有 NA 值。时间以年为单位。我将基线读数的时间设置为0。
例如显示一些行。
participant_num |时间 |状态
2 0.0000000 2
2 2.0123203 3
3 0.0000000 1
3 1.0157427 1
3 2.0123203 1
4 0.0000000 2
4 1.0157427 2
4 2.0123203 3
5 1.0157427 2
5 2.0123203 2
7 0.0000000 1
7 1.0157427 1
7 2.0123203 2
8 0.0000000 2
8 1.0157427 2
8 2.0123203 2
9 0.0000000 2
9 1.0157427 1
9 2.0123203 1
10 0.0000000 2
10 1.0157427 1
10 2.0123203 1

m1 &lt;- statetable.msm(状态，participant_num，data=df)
米1

     到
 从 1 2 3
    1 269 195 6
    2 162 626 58
    3 0 1 42

摘要(df$时间)
 
    分钟。第一曲。第三曲区中位数平均值。最大限度。
   0.000 0.000 1.185 1.039 2.012 2.585

##场景 1：NGT &lt;-&gt; iIFG-&gt;糖尿病
trans_mat &lt;- 矩阵(c(1, 1,1,
                      1, 1, 1,
                      0, 0, 0),
                    nrow = 3，byrow = TRUE）
rownames(trans_mat) &lt;- colnames(trans_mat) &lt;- c(“NGT”、“iIFG”、“糖尿病”)

          NGT iIFG 糖尿病
 NGT 1 1 1
 IFG 1 1 1
 糖尿病 0 0 0

mm &lt;- msm(状态 ~ 时间，subject=participant_num，data=df，deathexact=TRUE，gen.inits = TRUE，qmatrix=trans_mat)

optim 中的错误（方法 = “BFGS”，控制 = list（），par = c（qbase = -0.943801885337371，：
  “vmmin”中的初始值不是有限的

我该如何解决这个问题？我的trans_mat错了吗？或者我的数据格式错误？我将不胜感激任何帮助和建议。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646057/msm-package-mutlti-state-model-initial-value-in-vmmin-is-not-finite</guid>
      <pubDate>Sun, 28 Apr 2024 23:30:54 GMT</pubDate>
    </item>
    <item>
      <title>具有中低数据要求的 SNN？</title>
      <link>https://stats.stackexchange.com/questions/646056/snns-with-low-moderate-data-requirements</link>
      <description><![CDATA[我一直在考虑为我的数据集使用生存神经网络，但很难找到适合我相对较少数据量的模型。我有大约 300 个人的大约 10 个数据点，有 8 个输入，并且想训练我的模型来预测死亡风险。我尝试使用标准神经网络，每个时间点的数据作为输入，相应的“死亡时间”作为输入。虽然输出也不错，但感觉有些浪费。我尝试过使用在线模型，例如 tdCoxSNN，但输出很差。大家有熟悉的算法吗？我使用神经网络的原因是我将其应用于没有死亡值的不同数据集]]></description>
      <guid>https://stats.stackexchange.com/questions/646056/snns-with-low-moderate-data-requirements</guid>
      <pubDate>Sun, 28 Apr 2024 23:29:52 GMT</pubDate>
    </item>
    <item>
      <title>描述循环平稳随机过程的最常用符号是什么？</title>
      <link>https://stats.stackexchange.com/questions/646054/what-is-the-most-common-notation-to-describe-cyclostationary-stochastic-processe</link>
      <description><![CDATA[循环平稳随机过程可以描述为：
$\{X_t[i]:i\in\mathbb{N}\}\quad\forall~t\in\{1,2, \dots,T\ }$
其中所有重复/季节的 $t^\text{th}$ 索引的变异性遵循多元正态分布：
$X_t\sim\mathcal{N}_K(\mu_t, \Sigma_t)$
与 $\mu_t=E[X_t]\simeq\bar{x_t}$、$\bar{x_t }\in\mathbb{R}^K$
和 $\Sigma_t=\operatorname{var}[X_t]$、$\Sigma_t\in\mathbb{R}^ {K\times K}$,
根据所有 $x_t$ 在索引 $t$ 处的过去观测值估计&quot;&gt;$K$ 尺寸。
我的主要问题与如何处理时间索引$t$有关，考虑到它与过程的随机性质无关；相反，随机过程可以用多个变量表示为
$\{X(t,i):i\in\mathbb{N}\}$
但我仍然不确定表示 $t$ 的最佳方式。
此外，一些循环平稳性参考使用小写字母表示底层过程（例如$x(t)$):
$E[x(t)] = E[x(t+T_0)]$]]></description>
      <guid>https://stats.stackexchange.com/questions/646054/what-is-the-most-common-notation-to-describe-cyclostationary-stochastic-processe</guid>
      <pubDate>Sun, 28 Apr 2024 22:59:02 GMT</pubDate>
    </item>
    <item>
      <title>通过通用神经网络解释时间序列谱熵值的可预测性</title>
      <link>https://stats.stackexchange.com/questions/646053/interpretation-of-time-series-spectral-entropy-values-wrt-forecastability-by-a-g</link>
      <description><![CDATA[我最近开始使用谱熵来分析时间序列（已经加窗）。我很难解释结果，系列最后 25% 的熵是 0.19，整个系列的熵是 0.23，这有意义吗？例如，神经网络拥有的数据越多，预测不是越好吗？主要考虑到最后25%的数据并不包含完整的分布，例如测试数据与训练数据的分布不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/646053/interpretation-of-time-series-spectral-entropy-values-wrt-forecastability-by-a-g</guid>
      <pubDate>Sun, 28 Apr 2024 22:52:40 GMT</pubDate>
    </item>
    <item>
      <title>随机删失数据的似然函数</title>
      <link>https://stats.stackexchange.com/questions/646045/likelihood-function-for-data-with-random-censoring</link>
      <description><![CDATA[以下内容来自 Klein 和 Moeschberger，第 14 页。 76.
设 $(T,\delta)$ 为一个元组，其中 $T = \min(X,C_r) $ 和 $\delta = 0$ 如果生命周期 X 被审查并且 $\delta = 1$&lt; /span&gt; 如果不是； $C_r$ 表示审查时间。我想计算随机审查数据的似然函数。用 $f$ 和 $X$ 的 pdf 和 cdf &quot;&gt;$F$ 分别表示 $C_r$ 乘以 $g$ 的 pdf 和 cdf分别为  和 $G$。
我们计算
\begin{方程*}
\开始{分割}
   P(T_i = t, δ = 1) = P(X_i = t, X_i &lt; C_{r,i} ) &amp;= \frac{\mathrm{d}}{\mathrm{d}t} \int_ {0}^{t} \int_{x}^{\infty} f(x) g(v) \, \mathrm{d}v \, \mathrm{d}x \\
&amp;= \frac{\mathrm{d}}{\mathrm{d}t} \int_{0}^{t} f(x) - f(x)G(x) \, \mathrm{d}x = f(t) - f(t)G(t)
\结束{分割}
\end{方程*}
然而，Klein 和 Moeschberger 给出了
\begin{方程*}
    P(X_i = t, X_i &lt; C_{r,i}) = f(t)G(t)
\end{方程*}
我觉得这是一个非常基本的集成错误，但我查看了它并没有发现任何错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/646045/likelihood-function-for-data-with-random-censoring</guid>
      <pubDate>Sun, 28 Apr 2024 19:15:44 GMT</pubDate>
    </item>
    <item>
      <title>通过未知参数的依赖？</title>
      <link>https://stats.stackexchange.com/questions/646033/dependence-through-an-unknown-parameter</link>
      <description><![CDATA[考虑一个我们可以进行替换采样的瓮。让 $\pi$ 表示瓮中黑色球的比例，其余为白色。
从频率论的角度来看，每个观察值都被视为独立同分布（IID）变量。然而，在贝叶斯的视角下，这些观察结果是否仍然保持其独立性？似乎每次抽奖都会更新我们对 $\pi$ 的估计，可能会影响下一次抽奖为黑色的概率。
有人可以澄清我可能误解的地方吗？
编辑 - 具体示例：
让我们假设一个非常简单的先验。瓮完全黑色的概率为 $q$ ($\pi=1$)，并且$1-q$ 它是完全白色的 ($\pi=0$)。
我们画第一个球，它是黑色的。因此，第二个球也必须是黑色的：$p(x_2=black\mid x_1=black)=1$。这与边际概率 $p(x_2=black)=p(x_1=black)=q$ 形成对比。
相同的逻辑适用于任何先验（不一定是二分法）。如果参数被视为随机变量，它不会自动呈现依赖的观察结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646033/dependence-through-an-unknown-parameter</guid>
      <pubDate>Sun, 28 Apr 2024 15:22:38 GMT</pubDate>
    </item>
    <item>
      <title>数据（排名）与特定数据样本的比较</title>
      <link>https://stats.stackexchange.com/questions/646028/comprasion-of-data-ranks-to-a-certain-data-sample</link>
      <description><![CDATA[请原谅我的错误，这里不是本地人。
我将描述我的大学研究以及我难以解决的问题。
我研究绘画构图的感知，为此我有两个独立的群体：艺术家和非艺术家。我使用配对比较的方法，因此给参与者一定数量的对，每对由两幅画组成，每个参与者应该在每对中选择他们认为更平衡的构图。我计算每幅画的胜率，这意味着每个参与者的分数。每个参与者的绘画分数都会被转化为等级（1 - 最平衡的构图，...，10 - 最不平衡的）。我需要将 2 个组（艺术家和非艺术家）的排名与构图类型的“正确答案”进行比较（我给参与者的 10 幅画有两种类型，5 幅不平衡和 5 幅平衡，取自专业知识的来源）在艺术中​​）。问题是如何以正确的统计方式从中提取有意义的结果。看起来，艺术家群体（显然）更擅长看到正确的构图类型。
问题是：我如何找到每个组与“官方”作品类型的相关性？
我这边有两个想法，但我不太确定。

Guilford 的相关系数，但我无法找到有关这些方法和计算的详细信息。
更复杂的方案，不知道是否有意义。我考虑过将“官方”构图类型转化为排名（在这种情况下排名相同或相等：对于十幅画来说，它是 8,8,8,8,8,3,3,3,3,3。看起来很愚蠢） 。此后，官方排名可以与第一组进行比较，然后与第二组进行比较。我们最终得到了两个与“理想”排名样本的相关系数。这些系数可以通过 Fisher Z 变换进行分析。

此外，两组的排名也包含很多相同的排名，这对于选择正确的统计方法很重要。
顺便说一句，我是否需要为每个组或类似的 smt 找到“平均”排名？
*有没有办法同时调查两组答案的分散情况？ （我希望艺术家比非艺术家更常给每幅画相同的排名）
非常感谢任何帮助。谢谢。
&lt;小时/&gt;
更新：研究日，我似乎找到了一种分析数据的方法 - 对每组进行 anova Friedman 测试。结果看起来不错。不过我仍然愿意讨论！ :)]]></description>
      <guid>https://stats.stackexchange.com/questions/646028/comprasion-of-data-ranks-to-a-certain-data-sample</guid>
      <pubDate>Sun, 28 Apr 2024 14:24:49 GMT</pubDate>
    </item>
    </channel>
</rss>