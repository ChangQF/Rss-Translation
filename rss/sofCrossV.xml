<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 21 Aug 2024 18:20:17 GMT</lastBuildDate>
    <item>
      <title>列联表泊松对数线性模型分析的残差</title>
      <link>https://stats.stackexchange.com/questions/653132/residuals-from-poisson-log-linear-model-analysis-of-contingency-tables</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653132/residuals-from-poisson-log-linear-model-analysis-of-contingency-tables</guid>
      <pubDate>Wed, 21 Aug 2024 16:29:25 GMT</pubDate>
    </item>
    <item>
      <title>R lmer 帮助理解我的混合模型输出</title>
      <link>https://stats.stackexchange.com/questions/653130/r-lmer-help-understanding-my-mixed-model-output</link>
      <description><![CDATA[问题：城市化如何影响功能特征不同的蜜蜂物种的体型？
我们可以预料的是，社会性蜜蜂通常体型较大，并且在低、中、高城市化水平上的分布也不同。也许体型较大的个体出现在高城市地区是因为它们可以在分散的区域之间旅行得更远。
以下是我正在研究的功能性状，为了节省空间和时间，我暂时缩小了表格并将属名保留为数字：

因此，我有一个大型数据框，其中有针对每个属的蜜蜂样本，并且我为每个属列出了这些功能类别。
当将所有功能性状作为随机效应运行时，我的模型：
mixed.lmer.all &lt;- lmer(Head.Width ~ Urban.Intensity + (1|Diet) + (1|社交性/嵌套)，数据=df)
输出为：
REML [&#39;lmerMod&#39;] 拟合的线性混合模型
公式：Head.Width ~ Urban.Intensity + (1 | Diet) + (1 | Sociality/Nesting)
数据：df

收敛时的 REML 标准：1704.6

缩放残差：
最小 1Q 中位数 3Q 最大
-12.1117 -0.6812 0.0663 0.6835 8.6243

随机效应：
组名称方差标准差
社会性（截距）0.51533 0.7179 
嵌套：社会性（截距）0.48658 0.6976 
饮食（截距）0.63559 0.7972 
残差 0.07642 0.2764 
观察数：6209，组：社会性，3；嵌套：社会性，3；饮食，2

固定效应：
估计标准差。误差 t 值
（截距）3.288794 0.807375 4.073
Urban.IntensityMEDIUM -0.018613 0.009258 -2.011
Urban.IntensityLOW -0.034260 0.009601 -3.568

固定效应相关性：
（Intr）U.IMED
Urb.IMEDIUM -0.008 
Urbn.IntLOW -0.007 0.628
偏差表分析（II 型 Wald 卡方检验）

响应：Head.Width
Chisq Df Pr(&gt;Chisq)
Urban.Intensity 12.822 2 0.001643 **
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

我不知道这是否在告诉我，当考虑所有三个功能性状时，蜜蜂体型与城市化水平存在显著差异，并且蜜蜂的功能性状不同并不重要？这是让我很困惑的部分。
我还运行了这些混合模型，将每个功能性状作为随机效应单独进行，所有模型都显示出显著的结果。但如果这意味着功能性状并不重要，我就会感到很困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/653130/r-lmer-help-understanding-my-mixed-model-output</guid>
      <pubDate>Wed, 21 Aug 2024 15:49:36 GMT</pubDate>
    </item>
    <item>
      <title>确定多个分析的样本大小</title>
      <link>https://stats.stackexchange.com/questions/653129/determine-the-sample-size-for-multiple-analyses</link>
      <description><![CDATA[我无法确定样本量。
在时间 1 和时间 2，我有一个治疗组和一个对照组。
变量 A = 其子集 A1、A2、A3 和 A4 的平均值。
变量 B = 其子集 B1、B2 和 B3 的平均值。
对于我的第一次分析（时间 1），我想查看 9 个变量（A 和 B 及其子集）之间的相关性。我认为我应该使用（精确：相关性：双变量正态模型）运行 G*Power。
对于我的第二次分析（时间 1），我想查看 A 的哪些子集可以预测 B，基本上是一个回归模型。我认为我应该使用 (t 检验：线性双变量回归：两组，截距之间的差异) 运行 G*Power。
对于我的第三个分析（时间 1 和时间 2），我想看看我的治疗组与我的对照组相比从时间 1 到时间 2 的 B 是否有所改善。我认为我应该使用 G*Power，使用 (F 检验：ANOVA：重复测量，组内-组间相互作用)。
对于我的最后一个分析（时间 1 和时间 2），我只想查看我的治疗组，即在治疗 A 之后，A1、A2、A3 和 A4 的增益如何导致 B 的增益。我正在考虑 delta delta 分析，所以我不确定这个。
我的问题：

您认为我对这四个分析的选择有意义吗？您有什么建议吗？
我将为这四个 G*Power 获取不同的样本量，但如何确定我研究的最终样本量？我假设是最大的数字，但我不确定。

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653129/determine-the-sample-size-for-multiple-analyses</guid>
      <pubDate>Wed, 21 Aug 2024 15:38:18 GMT</pubDate>
    </item>
    <item>
      <title>使用引导法比较两种治疗方法时 P 值为 0</title>
      <link>https://stats.stackexchange.com/questions/653127/p-value-of-0-when-comparing-two-treatments-using-bootstrap-method</link>
      <description><![CDATA[我正在比较两种治疗方法，并进行 t 检验或 Wilcoxon 检验，我得到的 p 值 为 2.2e-16。
我想尝试引导，因为样本很大（超过 1000 个样本）并且长度不相等（300 个样本差异）。但是，当我尝试在 Rstudio 中运行此代码时，我将得到 p 值 为 0。这难道不是表明没有大于观察到的差异的值吗？这是否在告诉我，两种治疗方法是如此不同，以至于我甚至无法从比较中获得 p 值？
这是我正在运行的脚本的示例，数据集是虚拟数据，而不是实际数据，但它将导致相同的 p 值=0
set.seed(123)

# 虚拟数据集
dataset1 &lt;- rnorm(100, mean = 10, sd = 2)
dataset2 &lt;- rnorm(100, mean = 15, sd = 2)

combined_df &lt;- data.frame(
value = c(dataset1, dataset2),
group = factor(c(rep(&quot;Group1&quot;, length(dataset1)), rep(&quot;Group2&quot;, length(dataset2))))
)

# 数量观察值
n &lt;- length(combined_df$value)
# bootstrap 迭代次数
B &lt;- 10000

# Bootstrap
variable &lt;- combined_df$value
boots &lt;- matrix(sample(variable, size=n*B, replace=TRUE), nrow=n, ncol=B)

bootstat1 &lt;- numeric(B) # 表示平均差异
bootstat2 &lt;- numeric(B) # 表示中位数差异

# 观察到的差异
observed_means_diff &lt;- abs(mean(dataset1) - mean(dataset2))
observed_medians_diff &lt;- abs(median(dataset1) - median(dataset2))

# 循环计算 bootstrap 统计数据
for (i in 1:B) {
boot_sample &lt;- boots[, i]
bootstat1[i] &lt;- abs(mean(boot_sample[1:100]) - mean(boot_sample[101:200]))
bootstat2[i] &lt;- abs(median(boot_sample[1:100]) - median(boot_sample[101:200]))
}

# 计算 p 值
p_value_mean &lt;- mean(bootstat1 &gt;= perceived_means_diff)
p_value_median &lt;- mean(bootstat2 &gt;= perceived_medians_diff)

非常感谢您帮助我了解这里发生的事情]]></description>
      <guid>https://stats.stackexchange.com/questions/653127/p-value-of-0-when-comparing-two-treatments-using-bootstrap-method</guid>
      <pubDate>Wed, 21 Aug 2024 15:31:32 GMT</pubDate>
    </item>
    <item>
      <title>为时间序列预测添加约束</title>
      <link>https://stats.stackexchange.com/questions/653126/adding-a-constraint-to-time-series-forecasts</link>
      <description><![CDATA[我有 3 个变量：$X_t$、$Y_t$、$Z_t$
在我的原始数据中，对于所有 $t$：$Z_t$&gt; $Y_t$&gt; $X_t$
我想制作 3 个基本时间序列模型来预测这些变量中的每一个。
但是，在预测中，我想确保（即约束）在每个预测点 $t$，预测的 $Z_t$ 总是大于预测的 $Yt$ ，并且预测的 $Y_t$ 总是大于预测的 $X_t$。
我目前正在做一些这样的基本方法：
library(stats)
library(forecast)
library(ggplot2)

n &lt;- 100

var3 &lt;- rnorm(n, 平均值 = 10, sd = 2)
var2 &lt;- rnorm(n, 平均值 = var3 - 2, sd = 1.5)
var1 &lt;- rnorm(n, 平均值 = var2 - 2, sd = 1)

df &lt;- data.frame(var1 = var1, var2 = var2, var3 = var3, time = 1:n)

arima_var1 &lt;- auto.arima(df$var1)
arima_var2 &lt;- auto.arima(df$var2)
arima_var3 &lt;- auto.arima(df$var3)

forecast_var1 &lt;- Forecast(arima_var1, h = 12)
forecast_var2 &lt;- 预测(arima_var2, h = 12)
forecast_var3 &lt;- 预测(arima_var3, h = 12)

但是，我注意到在预测中，有时不遵守此约束。是否有某种方法可以强制预测遵守此约束？]]></description>
      <guid>https://stats.stackexchange.com/questions/653126/adding-a-constraint-to-time-series-forecasts</guid>
      <pubDate>Wed, 21 Aug 2024 15:28:37 GMT</pubDate>
    </item>
    <item>
      <title>如何正确报告交叉验证的结果，特别是标准差</title>
      <link>https://stats.stackexchange.com/questions/653125/how-to-properly-report-results-from-cross-validation-specifically-standard-devi</link>
      <description><![CDATA[这似乎是一个标准问题，但不幸的是，我还没有找到任何好的解释资源。
所以，我的情况如下。我想评估一个机器学习模型并报告其对未见数据的准确性。由于我的数据集非常小，我采用交叉验证。
一旦我获得了所有折叠的准确度值，我想报告这些值的平均值和标准差。
但是，互联网上的几个来源并不直接报告标准差。相反，他们倾向于先将标准差除以折叠数的平方根。
我没有找到任何关于为什么这样做的理由。]]></description>
      <guid>https://stats.stackexchange.com/questions/653125/how-to-properly-report-results-from-cross-validation-specifically-standard-devi</guid>
      <pubDate>Wed, 21 Aug 2024 15:27:19 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试寻找基线变化的标准差</title>
      <link>https://stats.stackexchange.com/questions/653122/i-am-trying-to-look-for-the-standard-deviation-of-change-from-baseline</link>
      <description><![CDATA[因此，我目前正在进行荟萃分析，需要找到与基线相比变化的标准差，因为我纳入的大多数研究都没有给出标准差。
我有基线和终点的平均值和标准差。
根据我在 Cochrane 上得到的信息，我需要估算相关系数才能找到变化的标准差，但我的量表在不同研究之间有所不同。
我的导师建议我做一个基线和终点的汇总标准差。
我应该按照导师的建议去做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653122/i-am-trying-to-look-for-the-standard-deviation-of-change-from-baseline</guid>
      <pubDate>Wed, 21 Aug 2024 14:38:15 GMT</pubDate>
    </item>
    <item>
      <title>多元成分数据模型之后该做什么？</title>
      <link>https://stats.stackexchange.com/questions/653121/what-to-do-after-the-multivariate-model-for-compositional-data</link>
      <description><![CDATA[我有一个简单的组合数据集（3 个测量值，必须加起来为 100%）。我知道如何进行 ILR 转换，然后我可以对治疗进行简单的多元回归。但接下来呢？据我所知，没有简单的方法可以将 ILR 转换矩阵与原始测量值关联起来。例如，我如何知道给定的治疗是否最终有利于结果 A 相对于结果 B 和 C 的相对优势？对于该领域的从业者来说，这种说法是合理的，而不仅仅是说治疗彼此不同。有没有一种方法可以将多元结果与原始组合集中的相对水平联系起来，这种方式比回归和回归不能准确描述的三重图更严格？]]></description>
      <guid>https://stats.stackexchange.com/questions/653121/what-to-do-after-the-multivariate-model-for-compositional-data</guid>
      <pubDate>Wed, 21 Aug 2024 14:26:24 GMT</pubDate>
    </item>
    <item>
      <title>根据样本预测唯一观测值总数 - R</title>
      <link>https://stats.stackexchange.com/questions/653120/predict-total-unique-observations-based-on-sample-r</link>
      <description><![CDATA[我有一组包含 N 个唯一元素的数据，这些元素可以重复任意次以得到 X 个总元素。
N 和 X 的值未知。
我有此数据的样本，并计算了样本总大小和样本中唯一元素总数。
为了了解样本的结构，我以一系列样本大小重复进行了子样本抽样，没有进行替换，并计算了唯一元素。
绘制于此处：

（红色 = 总样本，黑色 = 下采样。每个可见黑点实际上是 20 个重复）。
由此，我想在 R 中拟合一条超出 x 的观测值的曲线，以预测 y 的最大值（例如：数据集中唯一元素的总数，N）。
样本中的元素总数：185718411
样本中的唯一元素总数：51588754
下采样数据：
x=c(1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 2.5e+07, 2.5e+07, 2.5e+07, 
2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 
2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 
2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 
5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 
5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 
1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 
1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1.25e+08, 1.25e+08, 
1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08,
1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 
1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.5e+08, 1.5e+08, 
1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 
1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08 , 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 
1.75e+08, 1.75e+08) y=c(8879407L, 8882853L, 8879146L, 8879963L, 8879973L, 8877565L, 8879535L, 8879441L, 8881377L, , 8880186L, 8879063L, 8881647L, 8879511L, 8881403L, 8878382L, 8879544L, 8881002L, 8880604L, 8880240L, 18927193L, 18924435L、18923731L、18920494L、18923974L、18923199L、18923360L、18923648L、18923131L、18922984L、18926592L、18924276L、1 8923680L、18923344L、18926252L、18921600L、18924428L、18928711L、18925935L、18922126L、30157610L、30155501L、30158640L、 30159612L, 30158025L, 30157679L, 
30154834L, 30159222L, 30160493L, 30157565L, 30158045L, 30157807L, 
30155821L, 30155840L, 30158622L, 30159742L, 30161088L, 30158046L, 
30159089L, 30155885L, 37409984L, 37400952L, 37402514L, 37408682L, 
37404248L, 37403547L、37401649L、37407739L、37405915L、37407328L、37402003L、37408206L、37398749L、37406762L、37401890L、37406383L、3 7404693L、37409054L、37403259L、37405316L、42387997L、42386810L、42386963L、42390976L、42390837L、42387186L、42387391L、 42385265L、42383010L、42392749L、42390451L、42390822L、42389636L、42389803L、42385593L、42390989L、42386302L、42389008L、4 2390049L、42386454L、45991832L、45992758L、45991351L、45993242L、45993277L、45990663L、45992366L、45992018L、45994867L、 45996211L、45992212L、45991838L、45991638L、45992517L、45993411L、45993444L、45992878L、45993934L、45993354L、45993045L、4 8707677L、48710261L、48705408L、48705354L、48706640L、48708658L、48708765L、48708926L、48707986L、48709516L、48705780L、 48708451L, 48707766L, 48711356L, 48708200L, 48707612L, 
48708961L, 48707509L, 48708770L, 48706288L, 50821205L, 50820451L, 
50819444L, 50821245L, 50821327L, 50820153L, 50819789L, 50821493L, 
50821043L, 50819115L, 50821689L, 50821538L, 50821014L, 50819974L, 
50821665L, 50819515L, 50820771L, 50819985L, 50820110L, 50819491L, 
51588754L)

我认为曲线的形状符合渐近回归，我研究过各种拟合方法，但我认为这并不是我想要的。
我知道对样本进行下采样并不等同于重复采样 - 但这是我所能获得的全部。因此，我必须基于（有效）假设，即考虑到样本的大小和重复的一致性，样本可以代表整个数据集。
我想对许多不同的数据集重复此操作，因此正在寻找一种可以一致应用的方法。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653120/predict-total-unique-observations-based-on-sample-r</guid>
      <pubDate>Wed, 21 Aug 2024 14:21:44 GMT</pubDate>
    </item>
    <item>
      <title>关于 Jaynes 概率论第 2 章推导的问题：科学的逻辑</title>
      <link>https://stats.stackexchange.com/questions/653119/questions-about-derivations-for-chapter-2-of-jayness-probability-theory-the-lo</link>
      <description><![CDATA[我一直在阅读 Jaynes 的《概率论：科学的逻辑》第 2 章，作者在其中使用一些简单的假设推导出概率的和与积规则。虽然推导过程优雅且不难理解，但我不太明白他们是如何首先想出这些推导步骤的。许多步骤就像魔术一样，不知从何而来。例如：

从等式 2.13 到等式 2.19，他们怎么知道需要引入这些变量替换 u、v 和 G？这是解决此类方程的某种惯例，还是在没有任何先验知识的情况下以某种方式创造性地设计的？
在等式 2.41 中，他们怎么知道引入 \bar{B}=AD 是好的，而在等式 2.42 中，他们怎么知道引入 \bar{B}=AD 是好的？ 2.48，他们怎么知道需要这个 q 来得到最终的函数形式？

我猜我的问题不是关于推导细节，而是关于这些推导思想是如何形成的。任何想法都将不胜感激，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653119/questions-about-derivations-for-chapter-2-of-jayness-probability-theory-the-lo</guid>
      <pubDate>Wed, 21 Aug 2024 13:56:23 GMT</pubDate>
    </item>
    <item>
      <title>回归模型与配对 t 检验比较，但方差膨胀</title>
      <link>https://stats.stackexchange.com/questions/653118/regression-models-comparison-with-paired-t-test-but-inflated-variance</link>
      <description><![CDATA[我有 2 个依赖数据集 D1 和 D2，我用它们在嵌套交叉验证中训练和评估回归模型，该模型具有 L 外循环。对于每个循环，我使用皮尔逊相关性评估模型，因此为每个数据集提供了 L 皮尔逊相关系数。
然后，我用配对 t 检验评估了 2 个模型是否给出了不同的结果（即皮尔逊相关性差异是否平均不同于 0？），但我得到的结果不显著，而我实际上知道 D2 应该给出更高的结果。问题是 D2 产生的模型为 L 皮尔逊相关性增加了更多可变性。我认为方差是由另一个因素引起的，但测试该假设并重新训练模型不是一种选择，主要是因为这会花费太多时间。
那么，是否有任何方法可以运行配对 t 检验并解决此类问题？我已阅读有关提升 L 皮尔逊相关性以获得参数估计，或对其应用 收缩 系数以减少方差的文章。但我不确定这些方法是否真的合适（以及如何应用它们）或者是否有更好的选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/653118/regression-models-comparison-with-paired-t-test-but-inflated-variance</guid>
      <pubDate>Wed, 21 Aug 2024 13:46:33 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型中方差比高、分母低的信号</title>
      <link>https://stats.stackexchange.com/questions/653117/high-variance-ratio-signals-with-low-denominators-in-machine-learning-model</link>
      <description><![CDATA[我正在训练一个模型，根据大约 100 个关于点击和展示的信号来预测网站事件发生的概率。大多数信号都是比率；也就是说，它们的形式是分子/分母，例如每分钟展示次数、每次点击展示次数等等。
随着用户与网站的互动越来越多，他们的会话变成了训练数据行。例如，如果用户 Foo 在 3 个会话中访问了网站，我们将有 3 行 Foo 的训练数据；一个用于第 1 个会话，一个用于第 1 个会话和 2 个会话。 2，以及会话 1 至 3 的一个，并且信号的分子和分母将在会话之间相加（在多个会话的情况下）。
我面临的问题是小分母使我的信号非常嘈杂。例如，如果会话只有 10 秒，那么 1 次展示将转换为每分钟展示 6 的比率，这非常高。
我尝试过的一些改进是：

删除只有 1 个会话的训练行：这很有效，因为大多数嘈杂信号来自 1 个会话行；但是，许多用户只有 1 个会话，因此这会丢弃很大一部分训练集。

对分母取整：例如分子 / max(分母, 5)；这会使比率信号在较低水平上的信息量较少；例如，比率信号 0.2 现在可能意味着 1/1、1/2、1/3、1/4 或 1/5。

直接剪切比率：例如 min(2.0, 分子 / 分母)；这会使一些真正具有信息量的比率信号信息量较少；例如，min(2.0, 20/10) = 2.0 是一个具有信息量的信号，但这相当于 min(2.0, 4/1) = 2.0，一个不具有信息量的信号。


请注意，没有足够的数据来为问题提供更多特征。例如，我不能只是将所有分子和分母放入模型中，并希望它自己找出相互作用。我想知道是否有更好或更具创新性的方法来处理这个问题。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653117/high-variance-ratio-signals-with-low-denominators-in-machine-learning-model</guid>
      <pubDate>Wed, 21 Aug 2024 13:43:14 GMT</pubDate>
    </item>
    <item>
      <title>因变量零值，数据正确结构，零膨胀模型</title>
      <link>https://stats.stackexchange.com/questions/653115/zero-values-in-dependent-variable-correct-structure-of-the-data-zero-inflate</link>
      <description><![CDATA[我想了解宏观经济变量与特定基金（二级基金）募资量之间的关系。
我得到了以下数据集（假设一个表格：
1.
基金名称：
Abbott Secondary Opportunities III LP
募资日期：
06/2024
基金规模：
6200 万
2.
基金名称：
ABS Ventures VI, L.P.
募资日期：
01/2004
基金规模：
6400 万
...
我得到了 2000 年至 2024 年之间的 200 只其他基金。
作为独立变量，我选择了特定时期的利率水平、通货膨胀率、GDP 指数、IPO 数量和 sp500 指数。例如，我查找了 2024 年 6 月和 2004 年 1 月的利率水平以及另外 200 只基金的利率水平2000 年至 2024 年之间。
现在我不知道应该使用哪种类型的回归以及如何构建我的回归。
如果我进行月度回归，我将有 150 个零观测值作为因变量，因为根据数据，每个月都没有筹款，而有些基金在同一时期正在筹集资金。例如，对于 2024 年 6 月，我的因变量将是 6200 万，但对于 2024 年 5 月可能为零……
我可以删除零吗？我可以使用零膨胀模型吗？但我不知道您是否将这些数据视为计数数据？
或者建议使用以下结构？
我只包括获得筹款信息的月份（筹款&gt; 0），因此在这种情况下，我会直接从 06/2024 跳到 01/2004，因为在这两者之间它将是零（当然这个例子是夸张的，这两者之间有资金但不是每个月......）]]></description>
      <guid>https://stats.stackexchange.com/questions/653115/zero-values-in-dependent-variable-correct-structure-of-the-data-zero-inflate</guid>
      <pubDate>Wed, 21 Aug 2024 13:07:38 GMT</pubDate>
    </item>
    <item>
      <title>95% CI 高度重叠，但 p<0.05</title>
      <link>https://stats.stackexchange.com/questions/653114/95-cis-extremely-overlapped-but-p0-05</link>
      <description><![CDATA[我正在使用 pROC（配对数据）比较用 R 编码的两个不同逻辑回归模型的 AUC。

&quot;数据：71 个对照中的 pred2$fixed_effect（实际为 0）&lt; 43 例（实际 1 例）。
模型 1 的曲线下面积：0.8852
95% CI：0.82-0.9412（5000 个分层引导重复）
模型 2 的曲线下面积：0.9017
95% CI：0.8413-0.9515（5000 个分层引导重复）&quot;

如您所见，95% CI 几乎完全重叠，但当我在 r 中执行 roc.test 来比较两个 AUC 时，我得到了显着差异：

&quot;两个相关的引导测试ROC 曲线
数据：模型 1 和模型 2
D = -2.2082，boot.n = 5000，boot.stratified = 1，p 值 = 0.02723
备选假设：AUC 的真实差异不等于 0
样本估计：
roc1 的 AUC   roc2 的 AUC 
0.8851949     0.9017360&quot;

我知道如果 95% CI 有所重叠，那么仍然可以具有统计意义，但在这种情况下，由于重叠程度，我不会预期有显著意义。有人能帮忙解释一下发生了什么吗？
谢谢
]]></description>
      <guid>https://stats.stackexchange.com/questions/653114/95-cis-extremely-overlapped-but-p0-05</guid>
      <pubDate>Wed, 21 Aug 2024 12:51:44 GMT</pubDate>
    </item>
    <item>
      <title>当风险差异如此容易解释时，为什么 Cohen's h 对于比较比例有用？</title>
      <link>https://stats.stackexchange.com/questions/653098/why-is-cohens-h-useful-to-compare-proportions-when-risk-difference-is-so-interp</link>
      <description><![CDATA[当风险差异如此易于解释时，为什么 Cohen&#39;s h 可用于比较比例？
我认为这与标准化不同比例量级的比较有关（例如，当 $p_{1}$ 和 $p_{2}$ 分别接近 0、接近 0.5 和接近 1 时，$p_{1}-p_{2}$）。
但我很难在脑海中将其形式化。]]></description>
      <guid>https://stats.stackexchange.com/questions/653098/why-is-cohens-h-useful-to-compare-proportions-when-risk-difference-is-so-interp</guid>
      <pubDate>Wed, 21 Aug 2024 05:46:44 GMT</pubDate>
    </item>
    </channel>
</rss>