<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 13 Jan 2025 21:14:54 GMT</lastBuildDate>
    <item>
      <title>使用接受的治疗而非随机分组进行约束纵向数据分析 (cLDA)</title>
      <link>https://stats.stackexchange.com/questions/659986/constrained-longitudinal-data-analysis-clda-using-treatment-received-rather-th</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659986/constrained-longitudinal-data-analysis-clda-using-treatment-received-rather-th</guid>
      <pubDate>Mon, 13 Jan 2025 21:05:21 GMT</pubDate>
    </item>
    <item>
      <title>估计受影响的人数（医疗问题）</title>
      <link>https://stats.stackexchange.com/questions/659985/estimate-the-number-of-affected-individuals-medical-problem</link>
      <description><![CDATA[我的问题可以用医学术语来描述。一个人口为 N 的国家有 C 个人患有特定疾病。然而，这种疾病未被充分诊断，我的目标是估计受影响个体的真实数量 T。
为此，我使用了患有这种疾病的人作为样本；至关重要的是，对于他们每个人，我都知道一项测试的结果，该结果显示该疾病是否被成功诊断。城市和农村地区的成功率不同，我运行了 logit 回归：
logit(P(diagnosed = 1) = β0 + β1(urban / Rural)，
这为我提供了城市成功率 u 和农村成功率 r 的估计值。最后，我将人口 N 分为城市和农村部分，并得出受影响个人数量的修正估计值：
N = U + R，
T = U / u + R / r。
这个解决方案有效，但我之前没有处理过医疗问题，并且相信这个问题很常见并且有一个经过验证的解决方案。我不想重新发明自行车，如果能得到建议或参考，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659985/estimate-the-number-of-affected-individuals-medical-problem</guid>
      <pubDate>Mon, 13 Jan 2025 21:01:20 GMT</pubDate>
    </item>
    <item>
      <title>正交和非正交特征</title>
      <link>https://stats.stackexchange.com/questions/659983/orthogonal-and-non-orthogonal-features</link>
      <description><![CDATA[我的理解是，PCA 是一种对可能非正交的特征进行正交化（将输出称为主成分而不是特征）的技术。但是，在我看过的视频以及这个可视化工具中，特征空间的维度在开始时始终具有正交基，因此 PCA 是从一个正交基到另一个正交基的角度保持变换，而不是正交化技术。
当特征被称为非正交时，这是否意味着特征空间的维度由非正交基生成，然后 PCA 对其进行正交化，或者仅仅意味着数据点在由正交基生成的特征空间上相关？这两种几何视图之间是否存在明显的同构性，以便可以互换使用？
例如，假设我们对比两个独立进行的回归分析。我正在创建一个回归来预测 Bearth 表面上随机选择的位置的温度，而您正在创建一个回归来预测 Schmearth 表面上随机选择的位置的温度。我在 Bearth 的同一个城市放置了四个温度传感器，而您在 Schmearth 的四个大陆上分别放置了一个温度传感器。在每个星球上随机跳跃的第五个温度传感器的测量值是相应的预测目标。为了避免时间序列分析的额外复杂性，温度传感器不会对测量值进行时间戳记，但它们会将五个同时进行的测量值相互关联，以便它们输出的是一组数据点（每个数据点 1 个目标测量值和 4 个特征测量值），就像基本回归所需的那样。
事实是，Bearth 的温度在其地理范围内波动很大，而 Schmearth 的温度则不会。然而，我们每个人的训练数据最终都会出现高度相关性。我认为描述这个问题的方式是，我的特征具有很多多重共线性，这是由于我冗余放置了温度传感器造成的，而你的特征几乎没有多重共线性，但你的星球在其地理范围内的温度范围客观上较小，因此波动性主要是由于（未测量的）季节性而发生在数据点之间，而不是固定数据点的特征之间。
这两个回归之间的差异是否由特征空间中的（非）正交性（或甚至（非）线性）捕获？这是直观的，因为温度传感器的位置和特征空间的形状在逻辑上都先于训练数据点的存在。PCA 能否尽可能地解释这种差异？如果可以，我们是否必须手动识别和建模输入到 PCA 的特征空间中的多重共线性，或者即使我们没有认真考虑温度传感器位置的影响，PCA 是否会自动对其进行校正？如果没有，那么是否存在与此类似的环境，其中可以使用像 Gram-Schmidt（真正正交化非正交基）之类的东西来做我想用 PCA 做的事情？]]></description>
      <guid>https://stats.stackexchange.com/questions/659983/orthogonal-and-non-orthogonal-features</guid>
      <pubDate>Mon, 13 Jan 2025 20:37:46 GMT</pubDate>
    </item>
    <item>
      <title>重复测量设计中评估基因-代谢物关系的指导</title>
      <link>https://stats.stackexchange.com/questions/659981/guidance-on-evaluating-gene-metabolite-relationships-in-repeated-measures-design</link>
      <description><![CDATA[我正在对交叉研究的数据进行二次分析。我的目的是确定一个特定的基因（被怀疑在产生某种化学物质/代谢物方面发挥作用）是否与所有样本中的化学物质水平呈正相关，而不管所给予的治疗如何。
我创建了一些虚拟数据来协助分析。我的问题如下：

一个简单的线性混合效应模型是否足以评估基因和化学物质之间的关系，同时考虑到受试者内的重复测量？例如：
model1 &lt;- lmer(chemical ~ gene + (1 | subject_id), data = dummy_data)
anova(model1)

或者，我还应该在模型中考虑治疗（药物 1 和药物 2）和时间（访问次数），以确保这些变量不会混淆基因-化学关系？例如：
model2 &lt;- lmer(chemical ~ gene + time + drug + (1 | subject_id), data = dummy_data)
anova(model2)

或者，我是否应该考虑使用其他方法来评估基因和化学物质之间的关系？

为了进行可视化，根据固定效应创建散点图并在旁边报告模型的 p 值是否合适？如果没有，您能建议一种创建此类图的有效方法吗？


感谢您的指导！
以下是代码：
# 设置可重复性的种子
set.seed(123)

# 参与者人数
n_participants &lt;- 34

# 生成参与者 ID
subject_id &lt;- rep(1:n_participants, each = 4)

# 时间点
visit &lt;- rep(c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;), n_participants)

# 时间段（两个时间段：Period1 和 Period2）
period &lt;- rep(rep(c(&quot;Period1&quot;, &quot;Period2&quot;), each = 2), n_participants)

# 随机分配药物（药物 1 优先或药物 2 优先）
allocation &lt;- rep(sample(c(&quot;Drug1_First&quot;, &quot;Drug2_First&quot;), n_participants, replace = TRUE), each = 4)

# 根据分配和时间点分配药物
drug &lt;- ifelse(
allocation == &quot;Drug1_First&quot;,
rep(c(&quot;Drug1&quot;, &quot;Drug1&quot;, &quot;Drug2&quot;, &quot;Drug2&quot;), n_participants),
rep(c(&quot;Drug2&quot;, &quot;Drug2&quot;, &quot;Drug1&quot;, &quot;Drug1&quot;), n_participants)
)

# 为感兴趣的基因生成随机值（例如，基因表达水平） 
gene_of_interest &lt;- rnorm(n_participants * 4, mean = 5, sd = 1)

# 为感兴趣的化学物质生成随机值（例如，化学浓度） 
chemical_of_interest &lt;- rnorm(n_participants * 4, mean = 100, sd = 15)

# 组合成数据框
dummy_data &lt;- data.frame(
subject_id = subject_id,
time = visit,
period = period,
serial = assignment,
drug = drug,
gene = gene_of_interest,
chemical = chemical_of_interest
)
library(lme4)
library(lmerTest)
model1&lt;-lmer(chemical ~ gene + (1 | subject_id), data = dummy_data)
anova(model1)
]]></description>
      <guid>https://stats.stackexchange.com/questions/659981/guidance-on-evaluating-gene-metabolite-relationships-in-repeated-measures-design</guid>
      <pubDate>Mon, 13 Jan 2025 20:11:27 GMT</pubDate>
    </item>
    <item>
      <title>不同分析中的变量标准化</title>
      <link>https://stats.stackexchange.com/questions/659980/standardization-of-variables-across-different-analyses</link>
      <description><![CDATA[变量标准化
我正在为我的心理学学士学位进行一项研究，需要有关标准化变量以供分析的建议。我的变量是乐观、压力和 4 个独立的弹性子维度，以及整体弹性。
为了计算整体弹性变量，我总结了各个弹性子维度的标准化 z-总和分数（由于项目范围和响应量表不同，我进行了标准化）。我的分析包括：
3 个简单线性回归（测试总体适应力、乐观和压力之间的主要影响）
4 个层次回归（调节分析） - 测试 4 个独立子维度的调节效应（我也已经在每次分析中标准化了调节变量，因为我想比较每个子维度对因变量的影响强度）
1 个中介分析（测试总体适应力作为乐观-压力关系中的中介）
我的问题是：
我是否还需要在我的分析中标准化其他变量（其他预测因子、因变量），因为我已经使用了其他 z 分数变量（总体适应力变量和独立子维度）？
任何见解或建议都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/659980/standardization-of-variables-across-different-analyses</guid>
      <pubDate>Mon, 13 Jan 2025 20:01:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 Blackbox 方式查找依赖链</title>
      <link>https://stats.stackexchange.com/questions/659978/find-dependency-chain-in-blackbox-way</link>
      <description><![CDATA[假设我有 $5$ 个向量：${a,b,c,d,e}$。
我不知道它们之间的关系或它们的依赖链。例如，假设有一个函数接受这五个向量并返回这四个见解：

$a$ 的值取决于 $b$ 的值，反之亦然。

$c$ 的值取决于 $b$ 的值，因此也取决于 $a$ 的值，但 $a$ 和 $b$ 本身与 $c$ 的值相对独立，不会影响 $a$ 和 $b$。

$d$ 的值依赖于 $c$ 和 $b$，但不直接依赖于 $a$。

最后，$e$ 的值完全独立，与 $a$、$b$、$c$ 或 $a$、$b$、$c$ 或 $a$ 没有任何关系（双向或单向）。 class=&quot;math-container&quot;&gt;$d$.


我如何以黑盒方式（例如使用神经网络）了解这四个信息/见解（相关性）？我只输入五个向量。
此外，我希望它还支持非线性关系相关性。

我的解决方案是为所有向量训练五个独立的神经网络，其中每个神经网络对所有样本都有一个输入和四个输出。

输入形状：(n_samples, vector_dims, 1)
输出形状：(n_samples, vector_dims, 4)

问题是，vector_dims可能会有所不同。
那么，我不知道下一个？

或者也许我可以使用变压器编码器？]]></description>
      <guid>https://stats.stackexchange.com/questions/659978/find-dependency-chain-in-blackbox-way</guid>
      <pubDate>Mon, 13 Jan 2025 19:28:48 GMT</pubDate>
    </item>
    <item>
      <title>独立同分布高斯函数的 softmax 变换的集中</title>
      <link>https://stats.stackexchange.com/questions/659977/concentration-of-softmax-transform-of-i-i-d-gaussians</link>
      <description><![CDATA[考虑$n$ 个 i.i.d. 标准高斯随机变量，记为$X_1, \ldots, X_n$。我正在寻找表征函数的集中度的方法，例如 $\sum_{i=1}^n X_i e^{-X_i/\tau}$ 和 $\sum_{i=1}^n e^{-X_i/\tau}$，这些函数可以导致 
$$T_n = \dfrac{\sum_{i=1}^n X_i e^{-X_i/\tau}}{\sum_{i=1}^n e^{-X_i/\tau}}.$$
有人可能会认为 $T_n$ 以概率收敛到 $\frac{\mathbb{E}(​​Ze^{-Z/\tau})}{\mathbb{E}(​​e^{-Z/\tau})}$ 其中 $Z\sim N(0,1)$，但我正在寻找收敛速度，即尾部概率界限。查看 Talagrand 浓度不等式的陈述表明，指数函数增长太快，因此该不等式不适用。我们还能证明我上面提到的统计数据的亚高斯或亚指数类型的尾部界限吗？任何建议都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659977/concentration-of-softmax-transform-of-i-i-d-gaussians</guid>
      <pubDate>Mon, 13 Jan 2025 19:12:54 GMT</pubDate>
    </item>
    <item>
      <title>如何比较多层模型中固定效应和随机效应之间的贡献？</title>
      <link>https://stats.stackexchange.com/questions/659976/how-to-compare-the-contribution-between-a-fixed-effect-and-a-random-effect-in-a</link>
      <description><![CDATA[假设我有一个包含三个变量的数据集：$y$，我想要了解的结果；$x$，与$x$共变的变量，但我们可以假设它是完美测量的；$g$，分组变量，用于标识测量所属的多个群集（例如，主题）之一。我用多级（分层）回归模型拟合数据，形式为
$$y_i = (\beta_0 + b_{0,g[i]}) + (\beta_1 + b_{1, g[i]})x_i + \varepsilon_i$$
其中 $i = 1, \ldots, n$ 索引数据集中的观测值，$g[i]$ 是观测值 $i$ 的变量 $g$ 的值。
在 lme4 表示法中，该模型为 y ~ 1 + x + (1 + x | g)，允许每个簇有自己的斜率和截距，同时计算总斜率和截距。
我想用这个模型回答的问题是对于解释结果变量，哪个更重要：$x$ 的影响还是聚类间变异性？
我认为回答这个问题的一个实用方法可能是划分方差（如果这很重要，可以假设误差分布是正态的），但我真的不知道该怎么做。我知道，如果我拟合一个非分层模型，即 y ~ 1 + x，方差可以划分为回归可以解释的部分和不能解释的部分。
我还知道，当我拟合模型 y ~ 1 + x + (1 + x | g) 时，我会估计由按 g 分组的随机效应解释的方差分量。从这个模型中，是否可以将方差分解为由固定效应解释的部分、由随机效应解释的部分和残差变异性？如果可以，我该怎么做？
有没有更好的方法来回答这个问题？我认为对解释方差进行划分是一种直观的方式，可以说明一个变量“更重要”比其他的要好，但如果有更好的衡量标准，那也是可以的。
举一个具体的例子，我在 R 中模拟了一个遵循此模型的数据集，并且所有模型参数都是可估计的。
set.seed(101)
n_subjects &lt;- 20
x_values_per_subject &lt;- c(0.1, 0.25, 0.5, 0.75)
x &lt;- rep(x_values_per_subject, times = n_subjects)
g &lt;- rep(1:n_subjects, each = length(x_values_per_subject))
global_b0 &lt;- 5
individual_b0 &lt;- rnorm(n_subjects, global_b0, 5)
global_b1 &lt;- -2
individual_b1 &lt;- rnorm(n_subjects, global_b1, 3)
residual_variance &lt;- 1
mu &lt;- global_b0 + individual_b0[g] +
(global_b1 + individual_b1[g]) * x
error_variate &lt;- rnorm(length(mu), 0, residual_variance)
y &lt;- mu + error_variate
observed_data &lt;- data.frame(x, g, y)

此外，这里有一些简单的代码来可视化组级轨迹。
plot(
NULL, NULL,
xlim = range(x_values_per_subject),
ylim = range(observed_data$y),
xlab = &quot;x&quot;, ylab = &quot;y&quot;
)
for (i in unique(observed_data$g)) {
this_g &lt;- subset(observed_data, g == i)
lines(this_g$x, this_g$y, type = &quot;b&quot;)
}

拟合这两个模型都很容易。
library(lme4)
simple_model &lt;- lm(y ~ 1 + x, data = perceived_data)
multilevel_model &lt;- lme4::lmer(y ~ 1 + x + (1 + x | g), data = perceived_data, REML = FALSE)

当我比较这两个模型时，我发现这两个模型对固定效应的点估计值相同，尽管由于我们已经考虑了聚类的额外变化，x 固定效应的标准误差要小得多。如果我们使用 ANOVA 或 AIC 来比较模型，多层级模型显然要好得多。
summary(simple_model)
summary(multilevel_model)
anova(multilevel_model, simple_model)

因此，给定这两个模型，我如何确定 x 的固定效应是否比集群间变异更重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/659976/how-to-compare-the-contribution-between-a-fixed-effect-and-a-random-effect-in-a</guid>
      <pubDate>Mon, 13 Jan 2025 19:01:20 GMT</pubDate>
    </item>
    <item>
      <title>Y 变量具有不同对比度规范的逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/659975/logistic-regression-with-different-contrast-specification-for-y-variable</link>
      <description><![CDATA[我试图理解使用 polr 函数为结果变量指定不同的对比度如何影响 R 中比例几率逻辑回归模型的结果。为了说明问题，我使用了示例数据集“申请研究生院”，可从此处获取。
我的 DV 是变量“apply”。它是一个具有 3 个级别的有序因子。级别为“不太可能”、“有点可能”和“非常可能”，编码为 1、2 和 3。
我的 IV 是变量“pared”。它是一个二元因子变量。级别编码为 0/1，表示至少有一位父母拥有研究生学位。
下面，我指定了两个模型，它们仅在对比应用于 IV（pared）和 DV（apply）的方式上有所不同。
library(MASS)
library(haven)
dat &lt;- read_dta(&quot;https://stats.idre.ucla.edu/stat/data/ologit.dta&quot;)
dat$apply &lt;- factor(dat$apply, ordered=T)
dat$pared &lt;- factor(dat$pared, ordered=F) # 治疗对比
contr_poly &lt;- contr.poly(length(unique(dat$apply))) # 多项式对比
对比（dat$应用）&lt;- contr_poly

dat1 &lt;- dat
scaled_contr_poly &lt;- (contr_poly - apply(contr_poly, 2, mean))/apply(contr_poly, 2, sd)
对比（dat1$应用）&lt;- scaled_contr_poly # 缩放多项式对比
对比（dat1$pared）&lt;- contr.sum(length(unique(dat1$pared))) # 总和对比

x &lt;- polr(apply ~ pared, data = dat, Hess=TRUE) # 非缩放
summary(x)

y &lt;- polr(apply ~ pared, data = dat1, Hess=TRUE) #缩放
summary(y)



对于系数“pared1”，我可以取模型 y 中获得的估计值，然后将其乘以 2，得到模型 x 中获得的估计值
因为，如果预测因子父母​​教育（pared）使用总和对比：1，-1
logit(P &lt;= j | xi = 1) = beta(j0) + eta(1) # 对比为 -1
logit(P &lt;= j | xi = 0) = beta(j0) - eta(1) # 对比为 1
其中 eta(i) = -beta(i)
logit(P &lt;= j | xi = 1) - logit(P &lt;= j | xi = 0) = 2*eta(1)
更多详情 此处
我无法弄清楚如何将 y 结果中获得的截距转换为 x 结果中获得的截距。
如果“apply”是 IV 而不是 DV，我会做类似下面的事情，但对我来说不起作用。
scale_multiplier &lt;- apply(scaled_contr_poly, 2, sd)/apply(contr_poly, 2, sd)
apply1 * scale_multiplier[1]
apply2 * scale_multiplier[2]

其中，apply1 和 apply2 是模型中的 beta 系数。
任何帮助都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659975/logistic-regression-with-different-contrast-specification-for-y-variable</guid>
      <pubDate>Mon, 13 Jan 2025 18:52:43 GMT</pubDate>
    </item>
    <item>
      <title>偏距离相关的解释</title>
      <link>https://stats.stackexchange.com/questions/659974/interpretation-of-partial-distance-correlation</link>
      <description><![CDATA[我想知道这里是否有人可以帮助理解部分距离相关的解释（https://projecteuclid.org/journals/annals-of-statistics/volume-42/issue-6/Partial-distance-correlation-with-methods-for-dissimilarities/10.1214/14-AOS1255.full）？我不是统计学家，所以原文对我来说有点难理解。
在第 4.2 节中，似乎暗示偏距离相关性和条件（不）依赖性并不总是相同的。但我不清楚与标准偏相关相比，偏距离相关性应该如何解释？
相关地，偏距离相关性似乎能够通过控制 Z 作为多维变量来“控制”超过 1 个变量，因为偏距离相关性（和其他能量统计数据）是针对任意不一定相等维度的随机向量定义的。同样在这种情况下，我很难理解当 z 是一个多维控制变量时，与偏相关或偏回归系数相比，对偏距离相关性的准确实质性解释应该是什么？或者，例如，假设我们有一组随机变量，它们呈正态分布，平均值为 0，标准差为 1，如果构建一个图，其中边表示“显著”的部分距离相关性，那么与边是“显著”部分相关性的高斯图模型相比，这种解释会如何？（除了 pdcor 可以捕获非线性依赖关系这一事实之外，对于这个例子，假设所有依赖关系都是真正线性的）。
希望这有点道理！任何帮助都会得到赞赏，在此先致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659974/interpretation-of-partial-distance-correlation</guid>
      <pubDate>Mon, 13 Jan 2025 18:38:55 GMT</pubDate>
    </item>
    <item>
      <title>如何解释基于深度学习的股票预测模型中的非收敛 KL 损失？</title>
      <link>https://stats.stackexchange.com/questions/659968/how-to-interpret-a-non-converging-kl-loss-in-a-deep-learning-based-stock-predict</link>
      <description><![CDATA[我正在使用深度学习构建股票预测模型，我的损失函数定义为：
损失 = MSE + 等级损失 + KL 散度损失。




如训练曲线所示，整体损失正在收敛，MSE 和 Rank Loss 组件也在收敛。但是，KL Divergence Loss 并未收敛。最初，我为 KL Loss 分配了固定权重 0.3。观察到它的不收敛性后，我将其定义为 nn.Parameter（初始化为 0.3），并应用 S 型函数将其限制在 0 和 1 之间，从而使权重可学习。尽管进行了这种调整，KL 损失仍然没有收敛。
有趣的是，与排除 KL 损失相比，当包含 KL 损失时，模型的性能指标（如 IC、等级 IC、夏普比率和 IRR）有所改善。在对五次实验的结果进行平均后，这些指标始终显示 KL 损失具有更好的性能。
我应该如何解释这种 KL 损失不收敛但整体模型性能平均有所提高的情况？KL 损失的不收敛是否仍会对学习过程产生积极贡献？]]></description>
      <guid>https://stats.stackexchange.com/questions/659968/how-to-interpret-a-non-converging-kl-loss-in-a-deep-learning-based-stock-predict</guid>
      <pubDate>Mon, 13 Jan 2025 16:38:15 GMT</pubDate>
    </item>
    <item>
      <title>语料库中作者确定的统计检验</title>
      <link>https://stats.stackexchange.com/questions/659967/statistical-test-for-author-determination-in-corpus</link>
      <description><![CDATA[如何确定匿名作者撰写的语料库中的作者？
编辑：确定书信语料库中不同作者的数量以及它是否具有统计学显著性。]]></description>
      <guid>https://stats.stackexchange.com/questions/659967/statistical-test-for-author-determination-in-corpus</guid>
      <pubDate>Mon, 13 Jan 2025 16:37:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么皮尔逊残差和离差残差比正态残差变化更小？</title>
      <link>https://stats.stackexchange.com/questions/659966/why-are-pearson-and-deviance-residuals-less-variable-than-normal-residuals</link>
      <description><![CDATA[我正在阅读 Agresti 的分类数据分析（第 3 版），第 141 页写道：“当模型成立时，皮尔逊和偏差残差的变化小于标准正态分布，因为它们将 $y_i$ 与拟合均值 $\hat \mu_i$ 进行比较，而不是与真实均值 $\mu_i$ 进行比较...&quot;。我不太明白这句话。对于正态线性回归，残差是 $y_i - \hat y_i$，我们不是也使用预测均值作为 $\hat y_i$ 吗？有人可以解释一下 Agresti 是什么意思吗？
编辑：所指的“模型”是 GLM。 Agresti 在这里讨论了 GLM 的残差，并表示它们不像正态线性模型中的残差那样多变。]]></description>
      <guid>https://stats.stackexchange.com/questions/659966/why-are-pearson-and-deviance-residuals-less-variable-than-normal-residuals</guid>
      <pubDate>Mon, 13 Jan 2025 16:36:37 GMT</pubDate>
    </item>
    <item>
      <title>通过置信区间计算来确定数据收集停止是否“可以”？</title>
      <link>https://stats.stackexchange.com/questions/659962/is-it-ok-to-determine-data-collection-stopping-with-confidence-interval-calcul</link>
      <description><![CDATA[我有一枚加重硬币，正面朝上的概率为 $p$。我可以随意抛这枚硬币并观察结果；我想知道 $p$ 的值是多少。我还想知道我应该抛硬币多少次才能对概率有一个合理准确的估计。
（我的问题的实际“现实世界”背景有点愚蠢——我试图确定视频游戏中某个动作成功或失败的概率；我有理由相信它是伯努利分布，我认为$p \approx 0.15$是一个非常粗略的概念。我的初始样本表明它可能低至~$0.10$或高达~$0.20$。然而，我认为“加权硬币”设置会让它更容易理解，而不会陷入游戏的细节。）
我想做的是计算威尔逊得分区间，这样我就有了一个区间，在这个区间内，我可以有 95% 的信心相信 $p$ 是在这个区间内的。然后，继续抛硬币，直到这个区间“足够窄”（实际上，我更喜欢 $p \pm 0.025$ 或更窄的区间）。
但是，我不确定反复计算这个区间并在区间窄时停止是否在统计上有效。我的数学背景相当不错，但统计是我的弱点。
有人可以澄清这是否是一种有效的方法吗？ （此外，如果我在这里提交了一个 xy 问题，并且有更好的方法来确定我需要收集多少个样本才能获得一定宽度的置信区间，我也很乐意听到这个消息！）]]></description>
      <guid>https://stats.stackexchange.com/questions/659962/is-it-ok-to-determine-data-collection-stopping-with-confidence-interval-calcul</guid>
      <pubDate>Mon, 13 Jan 2025 15:21:47 GMT</pubDate>
    </item>
    <item>
      <title>在完整案例分析中删除一个变量但在多重归因分析中包含它是否有效？</title>
      <link>https://stats.stackexchange.com/questions/659956/is-it-valid-to-drop-a-variable-in-complete-case-analysis-but-include-it-in-multi</link>
      <description><![CDATA[我正在分析一个包含年龄、性别和教育等变量的数据集，其中一些变量有缺失值。其中一个变量（教育）有超过 60% 的缺失数据。对于我的分析，我正在考虑以下方法：

完整案例分析：排除具有大量缺失的变量（教育），并删除具有缺失值的行以保留尽可能多的完整案例。
多重插补分析：在插补过程中包括所有变量，包括教育，以恢复和利用缺失值中的潜在信息。

我的理由是，在完整案例分析中包含教育会导致大量数据丢失，但在插补后仍可以提供有意义的见解。
这种方法有效吗？是否有任何既定的参考或最佳实践支持此策略？应用此方法时应考虑哪些潜在问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659956/is-it-valid-to-drop-a-variable-in-complete-case-analysis-but-include-it-in-multi</guid>
      <pubDate>Mon, 13 Jan 2025 13:28:25 GMT</pubDate>
    </item>
    </channel>
</rss>