<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 13 Dec 2024 18:24:41 GMT</lastBuildDate>
    <item>
      <title>如何处理间歇性的 NUTS Sampler 卡在简单的逆问题中？</title>
      <link>https://stats.stackexchange.com/questions/658681/how-to-deal-with-intermittent-nuts-sampler-stuck-in-simple-inverse-problem</link>
      <description><![CDATA[给定一个模型，我尝试使用 blackjax python 包中的 NUTS 推断参数并量化估计的不确定性。我有多个输入数据集并尝试估计后验。对于使用 blackjax 提供的自动调整的一些人来说，这很有效。然而对于其他人，即使使用手动调整，NUTS 采样器也会遇到非最大似然的点，采样器会卡住。后验和迹线如下所示


问题似乎是先验的下限 &gt;=0，因为压力先验应该是正的。
不，NUTS 采样器似乎卡住了，导致边缘伪影。问题点代表了底层 ODE 的模型简化。除了模型中的硬先验和潜在附加条件（if 语句确定简化）之外，是否有自然的方法来挽救这些后验？我可以从数学上合理地排除事后条件，同时仍然获得有效的不确定性量化吗？
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/658681/how-to-deal-with-intermittent-nuts-sampler-stuck-in-simple-inverse-problem</guid>
      <pubDate>Fri, 13 Dec 2024 16:40:42 GMT</pubDate>
    </item>
    <item>
      <title>截断正态分布方差的选择修正方法</title>
      <link>https://stats.stackexchange.com/questions/658680/selection-correction-method-with-the-variance-of-the-truncated-normal-distributi</link>
      <description><![CDATA[考虑以下数据生成过程：
$$Y=\beta_0+\beta_1X_1+\beta_2X_2+\beta_3u+\varepsilon,$$
$$D=1\left[\gamma_0+\gamma_1Z+\gamma_2X_1+\gamma_3X_2+u&gt;0\right],$$
其中，如果单位被观察到，则$D=1$，否则$0$，并且$u$呈正态分布，均值为零。
众所周知，$Y$对$X_1$ 和 $X_2$ 仅使用观察到的单位（即 $D=1$）会导致有偏差的估计，而经典的解决方案是包括额外的回归量 $$\lambda(\widehat{\gamma})=\frac{\phi\left(-\left(\widehat{\gamma_0}+\widehat{\gamma_1}Z+\widehat{\gamma_2}X_1+\widehat{\gamma_3}X_2\right)\right)}{1-\Phi\left(-\left(\widehat{\gamma_0}+\widehat{\gamma_1}Z+\widehat{\gamma_2}X_1+\widehat{\gamma_3}X_2\right)\right)},$$
其中 $\widehat{\gamma}=\left[\widehat{\gamma_0},\widehat{\gamma_1},\widehat{\gamma_2},\widehat{\gamma_3}\right]&#39;$ 来自 $D$ 在 $Z$、$X_1$ 和 $X_2$ 上的概率单位。
附加回归量解决问题的原因是 $\sigma_u\mathbb{E}\left[u/\sigma_u\middle|D=1\right]=\sigma_u\lambda(\widehat{\gamma})$，可以使用截断正态分布的矩轻松得出。
因此，我认为，如果结果 $Y$ 生成如下（注意 $u$ 的平方），
$$Y=\beta_0+\beta_1X_1+\beta_2X_2+\beta_3u+\beta_4u^2+\varepsilon,$$
额外的回归量 $\lambda(\widehat{\gamma})$ 和 $\lambda_2(\widehat{\gamma})=1-\lambda(\widehat{\gamma})^2-W&#39;\widehat{\gamma}\cdot\lambda(\widehat{\gamma})$，其中 $W=[1, Z, X_1, X_2]&#39;$，可以产生无偏估计结果，这是由于截断正态分布的方差公式为：
$$\sigma_u^2\mathbb{E}\left((u/\sigma_u)^2\middle|D=1\right)=\sigma_u^2\lambda_2(\widehat{\gamma})$$
因此，我检查了这是否属实：
#################################
### 数据生成过程 1 ###
#################################
set.seed(1)
N &lt;- 100000
x1 &lt;- rnorm(N)
x2 &lt;- rnorm(N)
z &lt;- rnorm(N)
u &lt;- rnorm(N)
e &lt;- rnorm(N)

y &lt;- 1 + 2 * x1 + 2 * x2 + 2 * u + e # 结果方程
d &lt;- (1 + 2 * z + x1 + 2 * x2 + u &gt; 0) # 选择方程

# 使用观察单位的回归
lm(y ~ x1 + x2, subset = (d == 1))
# 真值 = 1, 2, 2, 估计值 = 1.536, 1.844, 1.681

# Heckman 的两步估计
prb &lt;- glm(d ~ z + x1 + x2, family = binomial(link = &quot;probit&quot;)) # probit
zgam &lt;- cbind(1, z, x1, x2) %*% c(1, 2, 1, 2)
phi &lt;- dnorm(-zgam)
PHI &lt;- pnorm(-zgam)
lam &lt;- phi / (1 - PHI) # 逆米尔斯比率
lm(y ~ x1 + x2 + lam, subset = (d == 1))
# 真值 = 1, 2, 2，2 估计值 = 1.003，2.001，1.994，1.986

#################################
### 数据生成过程 2 ###
#################################
y &lt;- 1 + 2 * x1 + 2 * x2 + 2 * u + 2 * u^2 + e # 结果方程
d &lt;- (1 + 2 * z + x1 + 2 * x2 + u &gt; 0) # 选择方程

# 使用观察单位的回归
lm(y ~ x1 + x2, subset = (d == 1))
# 真实值 = 1, 2, 2, 估计值 = 3.537, 1.805, 1.582

# 截断正态方差
lam2 &lt;- 1 - lam^2 - zgam * lam
lm(y ~ x1 + x2 + lam + lam2，子集 = (d == 1))
# 真实值 = 1, 2, 2, 2, 2 估计值 = -3.393, 1.974, 1.927, 7.331, 6.565

但是，正如您所见（尤其是最后一行），只有 $\beta_1$ 和 $\beta_2$ 的结果看起来合理。
我是否遗漏了什么要点？]]></description>
      <guid>https://stats.stackexchange.com/questions/658680/selection-correction-method-with-the-variance-of-the-truncated-normal-distributi</guid>
      <pubDate>Fri, 13 Dec 2024 16:23:55 GMT</pubDate>
    </item>
    <item>
      <title>Jeffreys 离散参数空间的先验</title>
      <link>https://stats.stackexchange.com/questions/658678/jeffreys-prior-for-a-discrete-parameter-space</link>
      <description><![CDATA[以下问题涉及二项分布，其概率已知$p$，但试验次数未知$n$。
试验次数的二项置信区间
尝试思考如何为这种情况构建贝叶斯区间，我首先进入了思考 Jeffreys 先验的阶段。但是，对于离散参数空间，这没有定义，因为导数不存在。
是否有根据相同想法找到先验的方法？当然，坐标变换下分布的不变性已经过时，因为概率质量函数不会像概率密度函数那样变换。这是 Jeffreys 先验的唯一属性/动机吗，或者还有其他属性可以应用于概率质量函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/658678/jeffreys-prior-for-a-discrete-parameter-space</guid>
      <pubDate>Fri, 13 Dec 2024 16:07:13 GMT</pubDate>
    </item>
    <item>
      <title>在 Heckman 模型中，我可以使用选择方程中的因变量作为选择方程中的自变量吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658677/in-heckman-model-can-i-use-dependent-variable-in-selection-equation-as-independe</link>
      <description><![CDATA[我已经将上述变量作为选择中的从属变量和结果方程中的独立变量。但在结果中，所选的和最重要的变量被省略了。由于共线性，它显示省略了。如何解决这个问题。请有人给我建议。我的研究是关于 FPOs 的，我想知道 fpos 对 FPO 农民收入的影响。样本量是来自一个地区的 60 名 FPO 农民和 60 名非 fpo 农民，我已经从 3 个不同的地区和作物收集了数据。所以我想知道是什么因素促使农民加入 fpo，加入 fpo 后他们的收入是否增加了。为此，我想要 Heckman 两步模型。

提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/658677/in-heckman-model-can-i-use-dependent-variable-in-selection-equation-as-independe</guid>
      <pubDate>Fri, 13 Dec 2024 15:47:18 GMT</pubDate>
    </item>
    <item>
      <title>关于VC理论的两个问题（关于泛化误差界限）</title>
      <link>https://stats.stackexchange.com/questions/658674/two-questions-about-the-vc-theory-on-the-generalization-error-bound</link>
      <description><![CDATA[在 Andrews Ng 的机器学习笔记 (https://cs229.stanford.edu/main_notes.pdf) 中，他引入了以下泛化误差与训练误差之间的差异界限（见下图），该界限取决于假设类的 VC 维度：

关于这个结果，我有两个问题：

在他的讲义中，这个结果是在二元分类的背景下提出的。这个定理也适用于回归吗？ （如果不是，那么回归问题的界限是什么？）

该学习理论在给定假设集$H$上限制泛化误差与训练误差的偏差。我的问题是，数据驱动的模型选择/正则化如何适应这个框架？假设$\widehat{H}$是数据驱动模型选择的结果（例如，它可能是具有非零系数的回归量的子集），人们是否仅在$H=\widehat{H}$的条件下应用此界限？或者这个界限在模型选择或正则化下不再有用？

]]></description>
      <guid>https://stats.stackexchange.com/questions/658674/two-questions-about-the-vc-theory-on-the-generalization-error-bound</guid>
      <pubDate>Fri, 13 Dec 2024 14:41:39 GMT</pubDate>
    </item>
    <item>
      <title>一个第二阶段协变量是第一阶段回归的内生变量</title>
      <link>https://stats.stackexchange.com/questions/658673/one-second-stage-covariate-is-endogenous-to-first-stage-regression</link>
      <description><![CDATA[我正在研究一个数据库（区域级，称为 DB），以分析通勤模式选择的决定因素。我运行了一个多项逻辑回归：我对一些个人变量（年龄、工作类型、居住地、在家工作……）和一些公司层面的变量（有利于主动模式的基础设施、PT 的可访问性……）对模式选择（汽车、自行车、步行、PT、拼车）进行回归。
这样做，我可能会面临一个反向因果关系的问题：通勤使用的模式可能会对在家工作的事实产生影响（我骑自行车上班，但有点太多，所以我决定每周在家工作一天）。在家工作是我感兴趣的变量之一。
因此，我构建了一个工具来控制这个内生性问题。我使用一个国家就业数据库（称为 NT），并按就业部门（工业、行政、健康等）计算在家工作的人数比例。然后，我的数据库 DB 中的每个受访者都与其公司对应部门的在家工作的人数全国份额相关联。这个工具可能会奏效：它与个人模式选择无关，因为它来自另一个数据库（国家级），并且与受访者声明在家工作的事实相关（我的数据库 DB 的公司属于部门）。
当我运行第一阶段回归时，我的问题出现了：我将我的内生变量（至少部分在家工作的事实）回归到我的主要回归的所有外生变量上。在这些变量中，我们发现通勤距离和居住地。尽管如此，这里可能还会出现另一个内生性问题：通勤距离和居住地会影响在家工作的事实（我更倾向于在家工作，因为我通勤距离很远）。
我现在有点不知道该如何处理这种情况。我非常确定我绝对需要在第一阶段回归中添加第二阶段的所有外生变量。但我也确定我第一阶段的估计必须是一致的，但事实并非如此。
任何帮助都会非常受欢迎！！]]></description>
      <guid>https://stats.stackexchange.com/questions/658673/one-second-stage-covariate-is-endogenous-to-first-stage-regression</guid>
      <pubDate>Fri, 13 Dec 2024 14:28:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么机器学习课程中的回归分析大多侧重于梯度下降，尽管我们有闭式估计量$(X'X)^{-1}X'Y$？[重复]</title>
      <link>https://stats.stackexchange.com/questions/658672/why-do-machine-learning-courses-on-regression-mostly-focus-on-gradient-descient</link>
      <description><![CDATA[在许多在线机器学习课程和视频（例如 Andrew Ng 的 Coursera 课程）中，当谈到回归（例如对特征 $X$ 进行 $Y$ 回归）时，虽然我们有回归系数 $\widehat{\beta}=(X&#39;X)^{-1}X&#39;Y$ 的闭式估计量，并且基于此我们可以得出 $X_i=x$ 的预测为 $x&#39;\widehat{\beta}$。这很简单，不需要数值优化。我的问题是：

鉴于闭式回归估计器（和预测器）的简单性，为什么机器学习课程通常会忽略它，而只关注梯度下降？

以这种方式教授回归有什么优点？

此外，梯度下降在实际性能方面的相对优点是什么？

]]></description>
      <guid>https://stats.stackexchange.com/questions/658672/why-do-machine-learning-courses-on-regression-mostly-focus-on-gradient-descient</guid>
      <pubDate>Fri, 13 Dec 2024 14:08:57 GMT</pubDate>
    </item>
    <item>
      <title>条件概率中的或语句：P(A|B 或 C)</title>
      <link>https://stats.stackexchange.com/questions/658669/or-statement-in-conditional-probability-pab-or-c</link>
      <description><![CDATA[我正在阅读有关竞争风险的 Fine-Gray 模型，其中给出的子分布风险函数的定义[1,2]是：
$$\lambda(t) := \lim_{\Delta t \rightarrow 0} \frac{P \left( T \leq t + \Delta t, \epsilon = 1|T \geq t \bigcup [T \leq t \cap \epsilon \neq 1] \right)}{\Delta t}$$
其中 $T$ 是失败时间，$\epsilon$ 是失败原因。我将 $\cup$ 符号解释为 &quot;OR&quot;，将 $\cap$ 解释为 &quot;AND&quot; - 但这可能不正确？
我从未见过形式为 $P(A|B \cup C)$ 的概率陈述，一个简单的人为示例是伯努利 ($p$) 正面朝上的概率，假设 $p=0.25$ 或 $p=0.8$：$P(H|p = 0.25 \cup p = 0.8)$。我不明白如果不对 $p$ 进行先验分析，或者对于任何陈述 $P(A|B \cup C)$ 进行一般分析，该陈述如何得到答案，除了 $P(A|B) = P(A|C)$ 的特殊情况。我的问题是，形式为 $P(A|B \cup C)$ 的陈述是否有效（在贝叶斯世界之外）？此外，Fine 和 Gray 是否滥用了符号？如果是这样，子分布风险函数是否有正式定义？

Fine, J. P., &amp; Gray, R. J. (1999). A Proportional Hazards Model for the Subdistribution of a Competing Risk.美国统计协会杂志，94(446)，496–509。https://doi.org/10.1080/01621459.1999.10474144

Austin PC，Fine JP。报告竞争风险数据的 Fine-Gray 模型分析的实用建议。医学统计学。2017；36：4391–4400。 https://doi.org/10.1002/sim.7501（开放获取）

]]></description>
      <guid>https://stats.stackexchange.com/questions/658669/or-statement-in-conditional-probability-pab-or-c</guid>
      <pubDate>Fri, 13 Dec 2024 12:38:05 GMT</pubDate>
    </item>
    <item>
      <title>当 $X\sim \operatorname{Beta}(\alpha,\beta)$ 时，$Y=-\log(X)$ 的分布</title>
      <link>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</guid>
      <pubDate>Fri, 13 Dec 2024 11:02:03 GMT</pubDate>
    </item>
    <item>
      <title>检查异常值随时间增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</link>
      <description><![CDATA[有人要求我测试多年来高异常值的数量和大小是否有所增加。目的是表明随着时间的推移（基数保持不变），极端情况会越来越多，越来越高。
我有很多例子和年份、年龄组和性别之间的比较，但下面我只会展示一个。有两组数据，恰当地命名为组 1（2022），包含 207 个样本，组 2（2023），包含 250 个样本。 y 轴变量以整数形式测量。
首先，进行 t 检验，表明平均值有所下降。

绘制了箱线图来可视化这一点
应该注意的是，组 2 中有 9 个点高于 10（约为组 1 的平均值），组 2 中有 10 个点约为 10（总共 12 个高异常值），其中组 2 中的顶级异常值高于组 1。所有异常值都经过严格检查，以确认它们是有效的数据点。

并且为了合理性，绘制了 var 随日期变化的散点图。红线表示箱线图的上限，其中任何高于该上限的点都被视为异常值。

这些都表明平均值有所下降，但是有人要求我统计地确认 2023 年是否存在更多和更高的异常值，而不管平均值的行为如何。有人要求我在不同性别、年龄和性别群体中展示这一点，在某些群体中比其他群体更明显。
我该如何进行统计测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</guid>
      <pubDate>Fri, 13 Dec 2024 06:09:28 GMT</pubDate>
    </item>
    <item>
      <title>哪些统计数据最适合用于评估基于常模的能力评估的有效性和可靠性？</title>
      <link>https://stats.stackexchange.com/questions/658660/which-statistics-are-best-practice-for-assessing-the-validity-and-reliability-of</link>
      <description><![CDATA[我计划评估常模参照能力评估的有效性和可靠性。该工具有 5 个与能力相关的子量表。有现成的常模，但我想对我拥有的样本进行一些额外的研究，以增加对该工具的研究内容。
对于标准参照评估，我会考虑的两个统计数据是每个项目的 Cronbach&#39;s alpha 和因子分析。一般来说，这些是否也构成能力评估的最佳实践？]]></description>
      <guid>https://stats.stackexchange.com/questions/658660/which-statistics-are-best-practice-for-assessing-the-validity-and-reliability-of</guid>
      <pubDate>Fri, 13 Dec 2024 05:44:33 GMT</pubDate>
    </item>
    <item>
      <title>试验次数的二项置信区间</title>
      <link>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</link>
      <description><![CDATA[我有一个过程，其成功概率为已知$p$，失败概率为$q = 1-p$。该过程重复有限但未知的次数$n$。
给定成功次数$r$（失败次数$n-r$，未知），我们应该如何确定导致$r$次成功的试验次数的置信区间？
举一个简单的例子，一枚公平的硬币总共被抛了$n$次，其中150次正面朝上落地。 $n$ 是如何分布的，其平均值的 95% 置信区间是多少，涵盖 $n$ 最可能的值。最可能的$n$ 为 300，最小的$n$ 为 150，最大的$n$ 为无穷大，但我们如何考虑介于两者之间的一切？
注意：如果分布不对称，间隔不必以平均值为中心。

我一直在研究威尔逊分数和其他二项比例置信区间，它们是相关的，但它们估计的是$p$，而不是$n$。我想知道是否存在类似的方法可以准确地找到我所寻找的内容。
由于缺乏估计量的封闭公式，我只能尝试通过拟合两个高斯分布来找到我的置信区间$(n_{low}, n_{high})$的端点，这两个高斯分布的均值为$n_{low}p$和$n_{high}p$，其中$n\hat{p}$（其中$\hat{n} = r/p$是我估计的$n$）落在其 2.5% 面积尾部边界上，使用表格。
（这是我对此的第一个问题论坛）]]></description>
      <guid>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</guid>
      <pubDate>Thu, 12 Dec 2024 17:08:40 GMT</pubDate>
    </item>
    <item>
      <title>高斯对数似然值究竟如何计算？</title>
      <link>https://stats.stackexchange.com/questions/658636/how-is-gaussian-log-likelihood-value-calculated-exactly</link>
      <description><![CDATA[我检查了这些 R 函数 glm.fit() gaussian()$aic stats:::logLik.glm() 和 stats:::logLik.lm()，发现 stats:::logLik.glm() 报告的对数似然值是根据 gaussian()$aic 计算的，其定义为
function (y, n, mu, wt, dev) 
{
nobs &lt;- length(y)
nobs * (log(dev/nobs * 2 * pi) + 1) + 2 - sum(log(wt))
}

stats:::logLik.lm() 报告的对数似然值使用以下公式计算。
0.5 * (sum(log(w)) - N * (log(2 * pi) + 1 - log(N) + 
log(sum(w * res^2))))

这两个公式在高斯家族中得出相同的 logLik 和 AIC。我理解 $AIC = -2 \ln{L} + 2df$ 并且可以重现与基本函数 logLik() 相同的结果，但我不知道为什么要以上述方式计算它们。使用基于经典公式的对数密度值总和，如“正态分布 - 最大似然估计”中所示https://www.statlect.com/fundamentals-of-statistics/normal-distribution-maximum-likelihood，我得到了不同的对数似然值，无法识别我的计算和默认输出之间的关系。请参阅以下最小示例。
Data &lt;- data.frame(
y = c(0.2, 0.2, 0.3), 
n = c(10, 20, 30)
)

# GLS 模型
with(Data, sum(y * n)/sum(n)) # 0.25
summary(Model &lt;- glm(y ~ 1, weights = n, data = Data))
&quot;估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.25000 0.03536 7.071 0.0194 *
(高斯族的分散参数取为 0.075)
零偏差：2 个自由度上的 0.15
残差偏差：2 个自由度上的 0.15
AIC：-5.1731&quot;
with(Model, Prior.weights)
&quot; 1 2 3 
10 20 30 &quot;
with(Model, weights)
&quot; 1 2 3 
10 20 30 相同，无迭代重新加权&quot;

# 默认函数
logLik(Model)
&quot;4.58654 (df=2)&quot;
AIC(模型)
&quot;-5.17308 因为 -2 * 4.58654 + 2 * 2 == -5.17308&quot;
with( # 基于 gaussian()$aic 和 glm.fit()
模型，nobs(模型) * (log(deviance/nobs(模型) * 2 * pi) + 1) + 
2 - sum(log(weights)))
&quot;-7.17308
-7.17308 + 2*1 == -5.17308 是报告的 AIC
logLik 源自 AIC 测量&quot;

# OLS 模型
summary(模型 &lt;- lm(y ~ 1, weights = n, data = Data))
logLik(模型)
&quot;4.58654 (df=2) 与上文相同&quot;
AIC(Model)
&quot;-5.17308 与上文相同&quot;
with(Model, 0.5 * (
sum(log(weights)) - nobs(Model) * (
log(2 * pi) + 1 - log(nobs(Model)) + log(sum(weights * residuals^2)))))
&quot;4.58654 为报告的 logLik&quot;

# 手动计算
with(Model, sum(prior.weights * log(
dnorm(y, mean = coef(Model), sd = sigma(Model)))))
&quot;21.5717&quot;
with(Model, sum(weights) * (-1/2 * log(2 * pi)))
&quot;-55.13631&quot;
带有（模型，总和（权重）*（-1/2 * log（sigma（模型）^2）））
“77.70801”
带有（模型，（-1/（2 * sigma（模型）^2））* 总和（权重*（y - coef（模型））^2））
“-1
-55.13631 + 77.70801 - 1 == 21.5717”
with(Model, sum(weights * (y - coef(Model))^2))

答案和更新
常规高斯密度函数是
$f_a = \frac{1}{\sqrt{2\pi\sigma^2}}\exp{-\frac{(y_i − \hat{y}^2_i)}{2\sigma^2}}$
但当有权重时，它就变成
$f_b = \frac{1}{\sqrt{2\pi\sigma^2/w_i}}\exp{-\frac{(y_i − \hat{y}^2_i)}{2\sigma^2/w_i}}$
这表明底层正态分布的方差为 $\sigma^2/w_i$。直观地看，它类似于计算为$SD/\sqrt{n}$的平均标准误差，这表明组大小（即权重）越大，误差方差$s^2/n$越小。
基于gaussian()$aic的stats:::logLik.lm()和stats:::logLik.glm()都使用$N\sigma^2 = \sum{w_i(y_i - \hat{y}^2_i)}$来取消上面的$\sigma$项。但是，我不明白为什么默认不使用$(N-p)\sigma^2 = \sum{w_i(y_i - \hat{y}^2_i)}$。这就是$\sigma$在lm()和glm()中的导出方式，它对应于残差方差的无偏估计，而不是低估残差方差的最大似然估计量。]]></description>
      <guid>https://stats.stackexchange.com/questions/658636/how-is-gaussian-log-likelihood-value-calculated-exactly</guid>
      <pubDate>Thu, 12 Dec 2024 17:03:36 GMT</pubDate>
    </item>
    <item>
      <title>减少线性指数衰减混合函数中的极端行为</title>
      <link>https://stats.stackexchange.com/questions/658227/reducing-extreme-behavior-in-linear-exponential-decay-hybrid-function</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658227/reducing-extreme-behavior-in-linear-exponential-decay-hybrid-function</guid>
      <pubDate>Tue, 03 Dec 2024 19:48:05 GMT</pubDate>
    </item>
    <item>
      <title>求分布未知但均值已知的方差比的置信区间</title>
      <link>https://stats.stackexchange.com/questions/657834/find-the-confidence-interval-of-ratio-of-variance-with-unknown-distribution-but</link>
      <description><![CDATA[根据上一个问题，我将假设对于随机样本 $X_1,X_2,\dots,X_n$ 和 $Y_1,Y_2,\dots,Y_n$，根据中心极限定理和 $\frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}} \xrightarrow{D} N(0,1)$。我原本想用这些定理将其归结为 F 分布，但我不确定你是否能做到这一点，因为它只是在分布上收敛，而不是实际分布。但除此之外，我不知道如何找到它。]]></description>
      <guid>https://stats.stackexchange.com/questions/657834/find-the-confidence-interval-of-ratio-of-variance-with-unknown-distribution-but</guid>
      <pubDate>Sun, 24 Nov 2024 06:07:49 GMT</pubDate>
    </item>
    </channel>
</rss>