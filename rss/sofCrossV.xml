<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 05 Sep 2024 15:16:49 GMT</lastBuildDate>
    <item>
      <title>这是维基百科中有关标准差的一个错误吗？</title>
      <link>https://stats.stackexchange.com/questions/653921/is-this-a-mistake-on-wikipedia-on-standard-deviation</link>
      <description><![CDATA[在维基百科页面中，关于标准差的部分，在“估计”部分，它说

与估计总体均值的情况不同，样本均值是一个具有许多理想属性（无偏、有效、最大似然）的简单估计量，而标准差没有一个具有所有这些属性的单一估计量……

然而，我认为样本均值不总是总体均值的最大似然估计量。例如，如果我们知道总体具有对数正态分布，那么它就不起作用。
这是维基百科上的错误吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653921/is-this-a-mistake-on-wikipedia-on-standard-deviation</guid>
      <pubDate>Thu, 05 Sep 2024 15:11:29 GMT</pubDate>
    </item>
    <item>
      <title>根据相关泊松分布的总和对其进行采样</title>
      <link>https://stats.stackexchange.com/questions/653920/sampling-correlated-poissons-conditional-on-their-sum</link>
      <description><![CDATA[我想从联合分布$(X,Y)$中抽取大小为$n$的样本，使得边际$X$和$Y$分布都是泊松分布，并且它们的总和被限制为某些值$\sum_n x_i = S_x$和$\sum_n y_i = S_y$。
在单变量情况下，以总和为条件的泊松分布只是一个易于抽样的多项式分布。
在双变量情况下，我们可以通过定义来定义联合泊松分布
$$
X = X&#39; + Z \quad \text{and} \quad Y = Y&#39; + Z
$$
and $X&#39;$、$Y&#39;$ 和 $Z$ 都是泊松分布，$Z$ 控制相关性的强度。我尝试使用与单变量情况相同的方法，但无法得出以总和为条件的联合分布。我想到的最好的办法是简单的拒绝方法，但当我想要生成大样本时，这当然是不可行的。
任何关于如何进行或是否可行的建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653920/sampling-correlated-poissons-conditional-on-their-sum</guid>
      <pubDate>Thu, 05 Sep 2024 15:11:18 GMT</pubDate>
    </item>
    <item>
      <title>如何判断一名玩家在多人游戏中是否表现更佳？</title>
      <link>https://stats.stackexchange.com/questions/653918/how-to-tell-if-one-player-is-significantly-better-at-a-multi-player-game</link>
      <description><![CDATA[我构建了一个扑克模拟，并让 6 个机器人互相玩了很多游戏（随机就座，始终是相同的六个），您如何确定一个玩家是否明显优于其他玩家？
https://www.science.org/doi/10.1126/science.aay2400 使用 T 检验，但我对两件事有点困惑：
需要独立……玩家不是高度依赖于其他玩家的表现吗？所以我需要进行配对 T 检验，对吗（论文中没有说明）？
假设我想比较前两名玩家。这是否只是在配对 T 检验中比较每个玩家的问题？我举了一个例子来说明在 Python 中这可能是什么样子：
import pandas as pd
import numpy as np
from scipy import stats

##### 可重复性的种子
np.random.seed(42)

##### 游戏数量
n_games = 20

##### 创建一个空的 DataFrame
data = {
&#39;game&#39;: range(1, n_games + 1),
&#39;good&#39;: [0] * n_games,
&#39;bad&#39;: [0] * n_games,
&#39;random_1&#39;: [0] * n_games,
&#39;random_2&#39;: [0] * n_games,
&#39;random_3&#39;: [0] * n_games,
&#39;random_4&#39;: [0] * n_games,
}

df = pd.DataFrame(data)

##### 每场比赛随机选择一名获胜者
winners = np.random.choice([&#39;good&#39;, &#39;bad&#39;, &#39;random_1&#39;, &#39;random_2&#39;, &#39;random_3&#39;, &#39;random_4&#39;], size=n_games)

##### 为每场比赛指定获胜者
for i in range(n_games):
df.loc[i, winnings[i]] = 1

##### 在“好”和“坏”之间执行配对 t 检验
t_stat, p_value = stats.ttest_rel(df[&#39;good&#39;], df[&#39;bad&#39;])

##### 显示 DataFrame 和测试结果
print(df)
print(f&quot;t-statistic: {t_stat}, p-value: {p_value}&quot;)

```]]></description>
      <guid>https://stats.stackexchange.com/questions/653918/how-to-tell-if-one-player-is-significantly-better-at-a-multi-player-game</guid>
      <pubDate>Thu, 05 Sep 2024 14:48:26 GMT</pubDate>
    </item>
    <item>
      <title>百分比比较和数量级</title>
      <link>https://stats.stackexchange.com/questions/653917/percentages-comparison-and-order-of-magnitude</link>
      <description><![CDATA[也许这是一个过于简单的问题。
假设有以下两个案例：
案例 1：患者人数/患者总数：63.080/1.335.636 = 4.7%
案例 2：患者人数/患者总数：5.840.431/59.030.133 = 9.8%
我如何比较这两个百分比？换句话说，如果可以将案例 1 的分子和分母设置为与案例 2 具有相同的数量级，或者最好是反之亦然，那么它们可能并没有太大的不同。既然如此，它们当然是不同的，因为数量级不同。
有人能帮帮我吗？
提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/653917/percentages-comparison-and-order-of-magnitude</guid>
      <pubDate>Thu, 05 Sep 2024 14:46:51 GMT</pubDate>
    </item>
    <item>
      <title>为什么 R 中的“dirichletprocess”包会返回最后一次 MCMC 迭代的聚类数量？</title>
      <link>https://stats.stackexchange.com/questions/653913/why-would-the-dirichletprocess-package-in-r-return-the-number-of-clusters-of-t</link>
      <description><![CDATA[我一直在使用 R 中的“dirichletprocess”包，特别是尝试重新创建插图中显示的示例，其中他们使用狄利克雷过程混合模型 (DPMM) 对老忠实数据集中的喷发进行聚类。但是，我遇到了一些问题，我很好奇是否有其他人遇到过同样的问题。
此包中的聚类数定义为 MCMC 例程最后一次迭代中的聚类数。根据我的经验，这感觉有点适得其反。我注意到聚类数的轨迹图波动很大，因此，最后一个值可能在 2 到 5 个聚类之间。这种可变性使最终结果有些随意。
在插图中，他们巧妙地避免显示任何轨迹图，只显示具有 2 个（正确）聚类的最终聚类结果。但是，如果您运行相同的代码，有时可能会得到 3 个簇，其中一个簇只有一个或两个点，这是由于采样过程的随机性而预料到的。然而，这提出了一个问题：最后一次迭代作为簇真实数量的指标有多可靠？作者为什么要做出这样的选择？
就我而言，我使用 $Gamma(1,1)$ 先验作为浓度参数 $α$。我得到的轨迹图显示簇的数量波动很大，平均约为 2.31 个簇。即使使用默认的先验配置也会产生类似的结果，这似乎不稳定。我希望模型能够更一致地检测到 2 个簇，因为它看起来像一个非常简单的例子，但这似乎没有发生，即使使用 2000 次迭代也是如此。 DPMM 真的那么不一致吗？
有人处理过类似的问题或找到让结果更稳定的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653913/why-would-the-dirichletprocess-package-in-r-return-the-number-of-clusters-of-t</guid>
      <pubDate>Thu, 05 Sep 2024 13:48:31 GMT</pubDate>
    </item>
    <item>
      <title>比较两个已知不确定度的（导出）量</title>
      <link>https://stats.stackexchange.com/questions/653910/comparing-two-derived-quantities-for-which-uncertainty-is-known</link>
      <description><![CDATA[我需要确定两个量 A 和 𝐵 及其相关不确定性 $u_A$ 和 $u_B$ 是否在统计上不同。
这两个量都是通过测量得出的。
不确定性是使用不确定性传播计算的。
我知道的一种保守方法是使用以下方法比较差异：
$|A-B| &gt; 1.96 \sqrt{(u_A^2 + u_B^2)}$
这为在 95% 置信水平下确定显著差异提供了一个阈值。
但是，我正在寻找一种不太保守的方法，它可以：

考虑不确定性，测试两个值之间的差异。
提供 p 值以量化统计显著性。

最好的统计方法是什么，它如何解释与每个值相关的不确定性？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653910/comparing-two-derived-quantities-for-which-uncertainty-is-known</guid>
      <pubDate>Thu, 05 Sep 2024 12:42:24 GMT</pubDate>
    </item>
    <item>
      <title>将因子变量纳入 GAM 时产生的矛盾解释</title>
      <link>https://stats.stackexchange.com/questions/653909/contradicting-interpretations-when-including-factor-variables-into-gam</link>
      <description><![CDATA[我建立的模型是这样的：
bam(n ~ s(age, k = 10, m = 2) + 
s(hh_size, k = 7, m = 2) +
s(age, by = pp, k = 10, bs = &quot;tp&quot;, m = 1) +
s(hh_size, by = pp, k = 7, bs = &quot;tp&quot;, m = 1) +
(employment_2cat + weekend + region + marital_2cat + education_2cat)* period * place + 
s(token, k = 864, bs = &quot;re&quot;) + 
s(Bundesland, k = 16, bs = &quot;re&quot;), data = halle_data, family = nb(), method = &quot;fREML&quot;,
drop.unused.levels = FALSE)
# pp 是时期和地点之间的相互作用。

拟合模型后，使用 summary() 获得参数系数。应用 emmeans()、pairs() 和 contrast() 来获取时期和地点对每个因子变量的影响。但结果似乎不对。

从模型的summary()结果来看，可以解释为“未就业”与“就业”相比，联系人数的对数增加25.5%。但从pairs()的结果来看，就业似乎与更高级别的联系有关。这种相互矛盾的解释也出现在周末变量中。

从 summary() 的结果来看，周末的接触次数比工作日多。但从 pairs() 的结果来看，工作日的接触次数比周末多。]]></description>
      <guid>https://stats.stackexchange.com/questions/653909/contradicting-interpretations-when-including-factor-variables-into-gam</guid>
      <pubDate>Thu, 05 Sep 2024 12:19:33 GMT</pubDate>
    </item>
    <item>
      <title>在面板数据中筛选出有/无振荡模式的样本的好方法？</title>
      <link>https://stats.stackexchange.com/questions/653908/good-method-for-sorting-out-samples-with-without-oscillation-pattern-in-panel-da</link>
      <description><![CDATA[我有生物医学面板数据。一些变量是时间序列（约 320 名参与者的血液测试），样本很少（约 20-100 个），其他变量随时间固定（年龄、身高……）。在某个时间点有干预，我想研究它对时间序列的影响。一些序列在图形上似乎在干预后立即呈现出振荡模式（X 轴上约为 0，原因不明），而其他序列则没有。有什么好方法可以将振荡序列与非振荡序列隔离开来以调查发生了什么？我目前正在尝试使用一阶和二阶导数，但无济于事。
]]></description>
      <guid>https://stats.stackexchange.com/questions/653908/good-method-for-sorting-out-samples-with-without-oscillation-pattern-in-panel-da</guid>
      <pubDate>Thu, 05 Sep 2024 11:25:28 GMT</pubDate>
    </item>
    <item>
      <title>brms 中 CAR 的稀疏邻接矩阵？</title>
      <link>https://stats.stackexchange.com/questions/653907/sparse-adjacency-matrix-for-car-in-brms</link>
      <description><![CDATA[我想在 R 包 brms 中拟合一个模型。我的数据由空间多边形组成，我想使用条件自回归来解释自相关。这在 brms 中是可能的，但需要空间邻接矩阵 M。我的问题是我有太多多边形，而我的 M 无法装入内存。
有没有办法在 brms 中使用稀疏矩阵表示？
我的代码：
fit &lt;- brms::brm(
formula = eco_stat_2 ~
shannon + LoadTPArea + LoadTN_Are +
lu_r_urb + lu_r_agr + hy_maf_abs + hy_bfi_abs +
msPAFP5EC5 + car(M = neighbours, type = &quot;escar&quot;),
data = data,
data2 = list(neighbors = neighbours2),
family =cumulative(&quot;logit&quot;),
cores = 6
)

我已经尝试使用 shape2mat() 创建稀疏 M来自 geostan，它创建了 M 的 ngCMatrix 版本。使用此 M 运行上述模型返回错误：
validate_car_matrix(get_from_data2(M, data2)) 中的错误：
此类“ngCMatrix”对象没有 namen“x”的插槽
]]></description>
      <guid>https://stats.stackexchange.com/questions/653907/sparse-adjacency-matrix-for-car-in-brms</guid>
      <pubDate>Thu, 05 Sep 2024 10:50:59 GMT</pubDate>
    </item>
    <item>
      <title>比较同一模型对不同数据集回归的参数</title>
      <link>https://stats.stackexchange.com/questions/653906/compare-parameters-of-same-model-regressed-to-different-data-sets</link>
      <description><![CDATA[我正在寻找解决我提出的问题的指导：如何评估不同的数据集是否具有不同的回归参数，同时考虑相同的模型。
上下文是对 3 个不同样本进行的实验。我事先不知道这些样本是否来自不同的材料，而这正是我想通过查看回归参数的差异来评估的。
实验包括改变施加到样本上的力水平，并在该力水平下对给定的材料属性进行 N 次测量。然后我们取平均值和标准偏差。测试了八个力水平，从而得出八个不同的材料属性值。材料属性预计取决于遵循线性模型的力水平，并且这种线性模型描述的依赖性本身可以被视为材料的特性。这就是为什么我专注于比较样本在回归参数方面的差异，而不仅仅是在不同力水平上测量的属性的平均值。
完成所有实验后，最终输出是三个数据集，每个数据集包含八个不同力水平的八对平均值和标准偏差，以及拟合的线性模型。下面我给出了一个 Python 代码，它非常接近地模拟了我拥有的真实数据集。添加的噪声是任意选择的，以在视觉上模拟真实数据。
import numpy as np
import matplotlib.pyplot as plt

#这是为了模拟材料如何真正依赖于力水平
#当然，这个定律在现实世界中是未知的
def trueSampleDependencyOnForce (X, alfa, beta):
return alfa*X+beta

np.random.seed(42)

######### 实验数据（例如，此处人工生成）

#这是独立变量
X_forceApplied = np.arange(1,9,1)+np.random.normal(0,0.2,8)

#这些是在不同力水平下测量的材料特性
Y_propA_noise = np.random.normal(0,0.3,8)+1.5
Y_propA_error = (Y_propA_noise)**2
Y_propA = trueSampleDependencyOnForce(X_forceApplied, 0.5, 15)+Y_propA_noise

Y_propB_noise = np.random.normal(0,0.3,8)+1.2
Y_propB_error = (Y_propB_noise)**2
Y_propB = trueSampleDependencyOnForce(X_forceApplied, 0.75, 20)+Y_propB_noise

Y_propC_noise = np.random.normal(0,0.3,8)+1.5
Y_propC_error = (Y_propC_noise)**2
Y_propC = trueSampleDependencyOnForce(X_forceApplied, 0.85, 18)+Y_propC_noise

#绘制实验图数据
plt.errorbar(X_forceApplied,Y_propA,yerr=Y_propA_error,fmt=&quot;X&quot;,capsize=5,label=&quot;样本 A&quot;)
plt.errorbar(X_forceApplied,Y_propB,yerr=Y_propB_error,fmt=&quot;o&quot;,capsize=5,label=&quot;样本 B&quot;)
plt.errorbar(X_forceApplied,Y_propC,yerr=Y_propC_error,fmt=&quot;v&quot;,capsize=5,label=&quot;样本 C&quot;)

########## 我正在为每个组拟合一个线性模型
from scipy.optimize import curve_fit

def regressingModel(x, a, b):
return a *x + b

params_A, 协方差 = curve_fit(regressingModel, X_forceApplied, Y_propA, p0=(1,1), sigma=Y_propA_error, absolute_sigma=True)
Y_fit_A = regressingModel(X_forceApplied,*params_A)
params_B, 协方差 = curve_fit(regressingModel, X_forceApplied, Y_propB, p0=(1,1), sigma=Y_propB_error, absolute_sigma=True)
Y_fit_B = regressingModel(X_forceApplied,*params_B)
params_C, 协方差 = curve_fit(regressingModel, X_forceApplied, Y_propC, p0=(1,1), sigma=Y_propC_error, absolute_sigma=True)
Y_fit_C = regressingModel(X_forceApplied,*params_C)

#绘制拟合模型
plt.plot(X_forceApplied,Y_fit_A, c=&quot;C0&quot;,linestyle=&quot;--&quot;,label=&quot;A-fit&quot;)
plt.plot(X_forceApplied,Y_fit_B, c=&quot;C1&quot;,linestyle=&quot;--&quot;,label=&quot;B-fit&quot;)
plt.plot(X_forceApplied,Y_fit_C, c=&quot;C2&quot;,linestyle=&quot;--&quot;,label=&quot;C-fit&quot;)

plt.legend()
plt.xlabel(&quot;力水平（牛顿）&quot;)
plt.ylabel(&quot;材料特性&quot;)

代码的最终输出如下所示，与我手头的数据集在视觉上相似：

因此，总结一下问题：

比较线性模型以了解它们在统计上是否不同的最佳方法是什么？
如果它们不同，如​​何知道哪个样本与哪个样本不同？本质上，可以运行什么事后检验？

附加问题：对于遵循另一种强制依赖类型的另一个属性（例如，Y 通过 $Y=aX^2+bx+c$ 或 $Y=alog(X)$ 依赖于 X），您提出的方法会有所改变吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653906/compare-parameters-of-same-model-regressed-to-different-data-sets</guid>
      <pubDate>Thu, 05 Sep 2024 10:29:25 GMT</pubDate>
    </item>
    <item>
      <title>做t检验时，样本标准差应该用样本均值减去原假设均值来估计吗？</title>
      <link>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</link>
      <description><![CDATA[以 t 检验为例，检验实数样本$x_i$是否来自均值为 0 的分布（$H_0:\mu=0, H_a:\mu \neq 0$）。检验统计量将是$t=\frac{\bar{x}}{s/\sqrt{n}}$。
我的问题是$s^2=\frac{\Sigma_i(x_i - \bar{x})^2}{n-1}$还是$s^2=\frac{\Sigma_i x_i^2}{n}$。
在大多数文本中我看到前者，但在财务数据的背景下我有时看到后者。两者似乎也都有意义，前者使用正态样本标准差公式，后者使用零假设，也不再需要贝塞尔校正。
两者的优缺点是什么，有没有更合适的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</guid>
      <pubDate>Thu, 05 Sep 2024 10:20:49 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待最近的统一理论？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653904/what-do-you-think-about-this-recent-unified-theory</link>
      <description><![CDATA[最近，有一篇关于天体粒子物理学的论文发表，题为“从黎曼几何和普朗克尺度形式论量子物理和广义相对论的同一起源”，声称统一了量子理论和广义相对论。这是一个链接
https://www.sciencedirect.com/science/article/abs/pii/S0927650524001130
然而，当我浏览这篇论文时。有很多值得怀疑的地方，例如添加不同阶的张量和方程 1 中的 Ricci 张量的定义。
希望有人能帮助我澄清这些观点，因为我自己可能会错过一些东西。
PS。这是预印本
https://www.researchgate.net/publication/379310936_On_the_same_origin_of_quantum_physics_and_general_relativity_from_Riemannian_geometry_and_Planck_scale_formalism]]></description>
      <guid>https://stats.stackexchange.com/questions/653904/what-do-you-think-about-this-recent-unified-theory</guid>
      <pubDate>Thu, 05 Sep 2024 10:12:48 GMT</pubDate>
    </item>
    <item>
      <title>生成AR序列时的回填是什么？</title>
      <link>https://stats.stackexchange.com/questions/653902/what-is-backfilling-when-generating-an-ar-sequence</link>
      <description><![CDATA[我正在阅读这篇论文：从非平稳数据中提取周期
我希望在本文中重新创建蒙特卡罗模拟。
在执行此操作之前，我有一个疑问。
第 8 页有脚注 9，作者在其中说：

我们使用 100 个观测值回填了 $ \epsilon_t $。这是为了确保创新序列与 AR(1) 生成机制一致。

我没听懂。有人可以向我解释一下怎么做吗？回填到底是什么？
下面是我如何使用 R 编程语言生成与本文模拟中类似的 AR1 序列，其长度为 216，自回归参数为 .34：
arima.sim(model =list(ar=.34,order=c(1,0,0)),n=216)

我如何回填？有人能帮我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653902/what-is-backfilling-when-generating-an-ar-sequence</guid>
      <pubDate>Thu, 05 Sep 2024 09:56:54 GMT</pubDate>
    </item>
    <item>
      <title>核SHAP——贡献函数估计</title>
      <link>https://stats.stackexchange.com/questions/653900/kernel-shap-estimation-of-contribution-function</link>
      <description><![CDATA[我一直在阅读 Christoph Molnar 的关于可解释机器学习的在线书籍 (链接)
如果我们有
$$\sum_{S \subseteq M} \bigg((v(S) - (\phi_0 + \sum_{j \in S} \phi_j)\bigg)^2 K(M,S)
$$
其中 $S$ 是特征集，$M$ 是联盟中的特征集，$K$ 是 Shapley内核将衡量损失。
Molnar 在 (link) 中讨论了如何近似 $v(S)$，贡献函数定义为
$$v(S)=E[f(x)|x_S=x^*_S]$$
Molnar 在他的书中使用了略有不同的符号：$$v(S)=E[f(x)|x_j=x^*_j]$$ 指的是联盟向量中的索引 $j$，我发现它不太精确。
Molnar 说

从边际分布中抽样意味着忽略现有特征和缺失特征之间的依赖结构。因此，KernelSHAP 遭受与所有基于置换的解释方法相同的问题。估计过分重视不可能的情况。结果可能变得不可靠。但有必要从边际分布中抽样。解决方案是从条件分布中抽样，这会改变价值函数，从而改变 Shapley 值作为解决方案的游戏。因此，Shapley 值具有不同的解释：例如，当使用条件抽样时，模型可能根本没有使用的特征可以具有非零 Shapley 值。对于边际博弈，这个特征值总是会得到
0 的 Shapley 值，因为否则它会违反 Dummy
公理。

我不明白为什么 Molnar 说“必要的”。我还找到了一些资料，例如这个，其中他们确实讨论了使用 copula 和 VAEAC 来估计条件分布$p(x_{\overline{S}}|x_S=x^*_S$ in
$$
v(S) = E[f(x)|x_S=x^*_S)] 
= E[f(x_{\overline{S}},x_S)|x_s=x^*_S] =
\int f(x_{\overline{S}},x^*_S)p(x_{\overline{S}}|x_S=x^*_S) dx_{\overline{S}}
$$
我理解，如果您从边际中抽样，那么您将从联盟中移除特征的 shap 游戏中获得更好的近似值。但是，正如 Molnar 自己所说，使用边际会过分重视不可能的值，并且贡献函数的估计变得不可靠。因此，使用边际分布不仅没有必要，而且最终是不正确的吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/653900/kernel-shap-estimation-of-contribution-function</guid>
      <pubDate>Thu, 05 Sep 2024 09:32:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 OLS 估计协整向量</title>
      <link>https://stats.stackexchange.com/questions/653897/estimating-a-cointegration-vector-using-ols</link>
      <description><![CDATA[我一直在阅读《汉密尔顿》，刚刚遇到了以下概念。

要估计协整向量，首先将第一个分量设置为 1。然后，执行线性回归以估计其余系数。这些系数是通过将每个时间序列与我们将系数设置为 1 的时间序列进行回归来估计的。

用更数学的术语来说，我们有一组时间序列 $y_t^i$。我们可以从这些单独的时间序列中创建一个向量，$\vec{y}_t$。
假设存在一个向量 $\vec{a}$，即协整向量。该向量描述了每个时间序列所需的权重，以便它们的线性组合创建协整时间序列。
要执行上述过程，假设$a_0=1$。然后，在时间序列$y_t^i$和$y_t^0$之间执行 OLS。梯度产生系数$a_i$的估计值。
我的问题是为什么？我在哪里可以找到这个证明，或者更详细的解释？]]></description>
      <guid>https://stats.stackexchange.com/questions/653897/estimating-a-cointegration-vector-using-ols</guid>
      <pubDate>Thu, 05 Sep 2024 09:04:32 GMT</pubDate>
    </item>
    </channel>
</rss>