<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 29 Sep 2024 09:17:42 GMT</lastBuildDate>
    <item>
      <title>Maxout 激活函数与 ReLU（权重数量）</title>
      <link>https://stats.stackexchange.com/questions/655067/maxout-activation-function-vs-relu-number-of-weights</link>
      <description><![CDATA[据我了解，Maxout 函数的工作原理与 ReLU 完全不同。
ReLU 函数是 max(0, x)，因此输入 x 是 (W_T x + b)
Maxout 函数有许多 W，它是 max(W1_T x + b1, W2_T x + b2, ...)
我理解 ReLU 函数在函数中没有感知器的权重，但 Maxout 函数在函数中有权重。 （并且有更多参数）
我理解得对吗？
许多激活函数，例如 ReLU、Sigmoid、tanh、Leaky ReLU 都使用标量值，这是一个已经计算出的值 (W_T x + b)
Maxout 函数与此不同，对吗？
Softmax 函数层没有权重吗？
那么从激活函数的变化来看，权重的数量可以改变吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655067/maxout-activation-function-vs-relu-number-of-weights</guid>
      <pubDate>Sun, 29 Sep 2024 04:23:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有样本偏差的情况下进行超参数调整？</title>
      <link>https://stats.stackexchange.com/questions/655064/how-to-hyperparameter-tune-without-sample-bias</link>
      <description><![CDATA[在寻找微调模型超参数 (HP) 的方法时，我发现了多个关于交叉验证技术 (K-folds、LPO、OOB.632+) 和选择最佳超参数组合的方法 (网格搜索、随机搜索等) 的参考资料。许多人说要使用嵌套交叉验证技术来估计模型的一些质量指标，但没有人解释如何选择最终模型将使用的超参数。
我能找到的最好的文章是有关嵌套交叉验证 (nCV) 或甚至是用于特征选择的 nCV 变体的文章，这将带来相同的模型选择问题。但是这种方法不提供一组唯一的超参数，而是为 CV 技术创建的每个折叠提供多个超参数。
我试图思考的是使用每个折叠的训练集的最佳超参数组合，并在某种类型的投票系统中考虑它们的平均质量指标和它们的“最佳组合出现”率，以确定哪种组合是最佳的，然后使用所有测试集估计所选超参数的质量指标，但我不确定这是否会导致无偏的 HP 选择和质量估计。
你有什么文章或解释可能有用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655064/how-to-hyperparameter-tune-without-sample-bias</guid>
      <pubDate>Sat, 28 Sep 2024 23:14:32 GMT</pubDate>
    </item>
    <item>
      <title>在线性混合效应模型中，随机效应的估计条件模式是否遵循 MVN？</title>
      <link>https://stats.stackexchange.com/questions/655058/do-estimated-conditional-modes-of-random-effects-follow-a-mvn-in-a-linear-mixed</link>
      <description><![CDATA[如果我们考虑由 Laird 和 Ware (1982) 提出的线性混合效应模型，模型中随机效应的条件均值（或众数）的估计值是否应遵循多元正态 (MVN) 分布？
这个问题与之前提出的问题不同（之前提出的问题为什么假设随机效应遵循正态分布）。]]></description>
      <guid>https://stats.stackexchange.com/questions/655058/do-estimated-conditional-modes-of-random-effects-follow-a-mvn-in-a-linear-mixed</guid>
      <pubDate>Sat, 28 Sep 2024 20:52:25 GMT</pubDate>
    </item>
    <item>
      <title>arima 模型和绘图之间存在差异</title>
      <link>https://stats.stackexchange.com/questions/655057/a-discrepancy-between-the-arima-model-and-plot</link>
      <description><![CDATA[我运行了 arima 模型并估算了拟合值。我在 arima 模型中的常数值为 153。由于时间变量 (t_centered) 以零为中心，因此常数表示零处的预测值。但是，时间中零处的红线徘徊在 185 左右。我只是想知道为什么 arima 模型的常数和时间中 0 处的绘制值之间存在差距。两者应该相似或相同。我的理解正确吗？
注意：当我运行 ols 模型时，我没有遇到上述问题。
# 拟合 ARIMA 模型
arima(x = data[, &quot;dv&quot;], order = c(4, 0, 0), xreg = data[, c(&quot;t_centered &quot;, &quot; t_centered2&quot;, &quot;x1&quot;, &quot;t_centered_x1&quot;, &quot;t_centered2_x1&quot;, &quot;x2&quot;, &quot;x3&quot;, &quot;x4&quot;, &quot;x5&quot;)], include.mean = T)

# 估计拟合值
data$fitted_m_all = fitted(m_all)

# 绘制观察值和拟合值：
gall &lt;- ggplot(data, aes(x = t_centered, y = dv, color = x1) ) +
geom_point(color=“grey”,size=2.5) +
geom_smooth(method=“lm”, linewidth = 1.2, se=F, 
mapping=aes(y=fitted_m_all), formula=y~poly(x,2)) +
geom_vline(xintercept = 0, alpha = 1, 
linewidth = .5, linetype =“solid”, color=“black”) +
coord_cartesian(xlim = c(-30, 30), ylim = c(50, 250))+
theme_bw() + 
theme(legend.position=“none”)+
scale_colour_brewer(palette=“Set1”)+
实验室（x =“时间”，y =“数字”）
胆汁

]]></description>
      <guid>https://stats.stackexchange.com/questions/655057/a-discrepancy-between-the-arima-model-and-plot</guid>
      <pubDate>Sat, 28 Sep 2024 20:06:26 GMT</pubDate>
    </item>
    <item>
      <title>3种不同药物的疗效比较</title>
      <link>https://stats.stackexchange.com/questions/655036/comparison-of-effectiveness-of-3-different-drugs</link>
      <description><![CDATA[我正在对 3 种不同的药物进行药物现场试验，以测量它们的功效/效果。每种药物只给予其自己的一组动物。在个体动物中，在药物干预之前和之后测量感兴趣的参数。我使用配对 T 检验来比较各自组中每种药​​物的治疗前后的平均差异。我的主管希望我从统计学上比较这 3 种药物中哪一种最有效。我可以使用哪种测试？PS：我不擅长统计]]></description>
      <guid>https://stats.stackexchange.com/questions/655036/comparison-of-effectiveness-of-3-different-drugs</guid>
      <pubDate>Sat, 28 Sep 2024 08:32:26 GMT</pubDate>
    </item>
    <item>
      <title>brms 中的 Priors 并未按我预期的那样工作</title>
      <link>https://stats.stackexchange.com/questions/655043/priors-in-brms-are-not-working-as-i-expect</link>
      <description><![CDATA[我是贝叶斯统计的新手，我正在尝试使用 brms 拟合一个简单的线性回归并手动设置每个参数的先验，但它并没有像我预期的那样工作
这是我的代码
data_2 &lt;- structure(list(YearsExperience = c(1.1, 1.3, 1.5, 2, 2.2, 2.9, 3, 3.2, 3.2, 3.7, 3.9, 4, 4, 4.1, 4.5, 4.9, 5.1, 5.3, 5.9, 6, 
6.8, 7.1, 7.9, 8.2, 8.7, 9, 9.5, 9.6, 10.3, 10.5), Salary = c(39343L, 
46205L, 37731L, 43525L, 39891L, 56642L, 60150L, 54445L, 64445L, 
57189L, 63218L, 55794L, 56957L, 57081L, 61111L, 67938L, 66029L, 
83088L, 81363L, 93940L, 91738L, 98273L, 101302L, 113812L, 109431L, 
105582L, 116969L, 112635L, 122391L, 121872L)), class = &quot;data.frame&quot;, row.names = c(NA, 
-30L))

priors &lt;- c(
set_prior(&quot;normal(28700, 2000)&quot;, class = &quot;Intercept&quot;),
set_prior(&quot;normal(9006, 1000)&quot;, class = &quot;b&quot;, 
coef = &quot;YearsExperience&quot;),
set_prior(&quot;normal(0, 2000)&quot;, class = &quot;sigma&quot;, lb = 0) 
)

fit_brms &lt;- brm(Salary ~ YearsExperience, data = data_2, Prior=priors)

但是，当我绘制链时，例如，当先验分布远离负值时进行截距。而且我设置的先验并非完全不准确。

如果我使用默认先验进行拟合，效果很好。]]></description>
      <guid>https://stats.stackexchange.com/questions/655043/priors-in-brms-are-not-working-as-i-expect</guid>
      <pubDate>Fri, 27 Sep 2024 21:16:13 GMT</pubDate>
    </item>
    <item>
      <title>具有斜率函数的用户指定值的边际效应</title>
      <link>https://stats.stackexchange.com/questions/655041/marginal-effects-at-user-specified-values-with-slopes-function</link>
      <description><![CDATA[我在使用 marginaleffects 包的 slope 函数估计用户指定值的边际效应时遇到了麻烦
假设我想用帕尔默企鹅数据集预测 body_mass_g
library(marginaleffects)

dat &lt;- read.csv(
&quot;https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv&quot;)


这是我的函数。我想将 flipper_length 设置为 180，将 bill_length_mm  设置为 39 或 40。
mod.lm &lt;- lm(body_mass_g ~ bill_length_mm + flipper_length_mm + 
species, data = dat)

slopes(
mod.lm,
newdata = datagrid(
flipper_length_mm = 180,
bill_length_mm = c(39,40)))



我知道一些事情是错误的，因为所有预测因子的估计值都相同，无论 bill_length_mm 的值设置为 39 还是 40。
我尝试使用 glm 二元结果变量运行类似的模型，它按预期工作。
dat$large_penguin &lt;- ifelse(dat$body_mass_g &gt; 
median(dat$body_mass_g, na.rm = TRUE), 1, 0)

mod &lt;- glm(large_penguin ~ bill_length_mm + flipper_length_mm + 
species, data = dat, family = binomial)

slopes(
mod,
newdata = datagrid(
flipper_length_mm = 180,
bill_length_mm = c(39,40)))


为什么 lm 模型没有按预期执行，而 glm 模型却可以？]]></description>
      <guid>https://stats.stackexchange.com/questions/655041/marginal-effects-at-user-specified-values-with-slopes-function</guid>
      <pubDate>Fri, 27 Sep 2024 21:04:18 GMT</pubDate>
    </item>
    <item>
      <title>当某一组没有进步空间时测量二元预测因子的横截面和纵向效应</title>
      <link>https://stats.stackexchange.com/questions/655065/measuring-the-cross-sectional-and-longitudinal-effect-of-a-binary-predictor-when</link>
      <description><![CDATA[我负责分析老年人的特定疾病，并跟踪该疾病在横向和纵向上对某些结果的影响。我们通过收集结果的重复测量值并运行包含时间和疾病状态之间交互项的混合模型来实现这一点。我们通常假设患有该疾病将与横向上更差的结果分数和纵向上以更快的速度恶化的结果分数相关。在实践中，我们经常看到我们的横向假设得到证实，但纵向假设却相反。也就是说，对照组的分数比疾病组恶化得更快。我相信原因在于，在基线时，患有该疾病对横向分数的影响如此之大，以至于他们的分数几乎没有空间随着时间的推移而进一步恶化。下面是一个可以说明我的观点的例子：
data &lt;- data.frame(&quot;Group&quot; = c(rep(&quot;Disease&quot;,10), rep(&quot;Control&quot;, 10)), 
&quot;Time&quot; = c(1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2), 
&quot;Outcome&quot; = c(8,9, 7, 8, 6, 7, 5, 6, 9, 9, 8, 9, 4, 7, 4, 8, 3, 7, 5, 9))

ggplot(data, aes(x = Time, y = Outcome, color = Group)) +
geom_point() +
geom_smooth(method = &quot;lm&quot;)


因此，在这种情况下，假设结果是某人每天在家中走动时出现并发症的次数，我们在基线（时间点 1）和五年后（时间点 2）测量这个数字。由于我们研究的是老年人群，我们相信随着研究参与者年龄的增长，结果会随着时间的推移而恶化（增加）。显然，疾病组在基线（时间点 1）时有更多并发症。但是，对照组的并发症随着时间的推移而更加严重地增加。这几乎就像基线时患病的横断面效应非常强烈，以至于随着时间的推移，病情没有太大的恶化空间，而对照组则有足够的恶化空间。在这个例子中，一个人可能出现的最高并发症数量是每天 8-10 次，而疾病组在基线时已经接近这个极限。
所以我的问题是：有没有办法从统计上调整这种影响，或者这只是结果固有的一个无法克服的问题？如果我们相信这种现象对于特定结果是真实的，我们是否不应该探索疾病对所述结果的纵向影响？有人知道任何教科书和/或期刊文章解决或提到类似的现象，可以为我提供更多见解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655065/measuring-the-cross-sectional-and-longitudinal-effect-of-a-binary-predictor-when</guid>
      <pubDate>Fri, 27 Sep 2024 17:51:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 simr 计算线性混合模型中计划对比的功率和样本大小？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654818/calculate-power-and-sample-size-for-planned-contrasts-in-linear-mixed-models-usi</link>
      <description><![CDATA[我使用 lmerTest 包在 R 中建立了一个线性混合模型，其中有三个分类因子（A 有 3 个级别，B 有 8 个级别，C 有 2 个级别）和一个针对主题的随机效应。我有兴趣使用 simr 对 B 的两个特定计划水平对比进行功效分析。这可能吗？
例如，我们分别用 B1、B2、B3 和 B4 表示因子 B 的水平 1、2、3、4，用 A1 表示因子 A 的水平 1。我们需要以下对比的功效。

比较 B1 和 B2，比较 B3 和 B4，控制所有其他变量（如果模型不包含交互项）
比较 B1 和 B2，并在特定 A 水平 A2 比较 B3 和 B4（如果考虑 A 和 B 之间的交互）

我理解 simr 可以模拟模型中所有固定效应的功效和样本大小，因此我们可以通过将 B 的参考水平设置为 B1 来将 B1 与 B 的所有其他水平进行比较。但我不确定如何设置它来计算上述特定对比的功效。我也知道 emmeans 可以设置和计算事后对比，但有没有办法将它与 simr 集成以进行功效分析和大小调整？如果没有，那么适当的方法是什么？
有人可以分享使用 simr 模拟这些计划对比的功效和样本大小的经验吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654818/calculate-power-and-sample-size-for-planned-contrasts-in-linear-mixed-models-usi</guid>
      <pubDate>Tue, 24 Sep 2024 03:16:21 GMT</pubDate>
    </item>
    <item>
      <title>我如何确定我的生态 GLMM 是否构建准确？</title>
      <link>https://stats.stackexchange.com/questions/654219/how-do-i-determine-if-my-ecological-glmm-is-accurately-constructed</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654219/how-do-i-determine-if-my-ecological-glmm-is-accurately-constructed</guid>
      <pubDate>Wed, 11 Sep 2024 16:42:13 GMT</pubDate>
    </item>
    <item>
      <title>如果我使用 R 中的 wilcox.test 来处理配对数据，它到底返回什么？我想根据这个结果计算效应大小</title>
      <link>https://stats.stackexchange.com/questions/542165/if-i-use-the-wilcox-test-from-r-for-paired-data-what-exactly-it-returns-i-want</link>
      <description><![CDATA[我想计算成对 Wilcoxon（有符号秩）的效应大小。
有两个选项：Z/sqrt(N_pairs)
或秩-双列相关性。
wilcox.test(... paired=TRUE) 返回“V”。
文献中有很多字母：对于 Mann-Whitney（非成对），它要么是“U”，要么是“W” （取决于方法，即 Wilcoxon 方法），对于成对的 Wilcoxon，它是 Z 或 V。
在我的情况下，V = 0。
数据：
d &lt;- structure(list(PatientId = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L), .Label = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, 
&quot;8&quot;, &quot;9&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;), class = &quot;factor&quot;), 时间点 = 结构 (c(1L, 
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
2L, 1L, 2L, 1L, 2L, 1L, 2L), .标签 = c(&quot;基线&quot;, &quot;第 3 个月&quot;
), class = &quot;factor&quot;), 结果 = c(0, 9, 6, 8, 0, 0, 0, 0, 0, 0, 
0, 0, 1, 2, 3, 3, 1, 2, 1, 1, 3, 3, 7, 7)), row.names = c(NA, 
-24L), class = &quot;data.frame&quot;)

&gt; wilcox.test(结果 ~ 时间点，配对 = TRUE，数据 = d)

带连续性校正的 Wilcoxon 符号秩检验

数据：按时间点的结果
V = 0，p 值 = 0.1
备选假设：真实位置偏移不等于 0

警告消息：
1：在 wilcox.test.default(x = c(0, 6, 0, 0, 0, 0, 1, 3, 1, 1, 3, 7) 中，:
无法计算具有关系的精确 p 值
2：在 wilcox.test.default(x = c(0, 6, 0, 0, 0, 0, 1, 3, 1, 1, 3, 7) 中，:
无法计算具有零的精确 p 值

rank_biserial 不起作用：
&gt; rank_biserial(结果 ~ 时间点，配对 = TRUE，数据 = d)
r (等级 biserial) | 95% CI
----------------------------------
-1.00 | [-1.00, -1.00]
警告消息：
在 ranktransform.numeric((x - y) - mu, sign = TRUE, verbose = verbose) 中：
检测到零。这些不能进行符号等级转换。

但 rstatix 包实现返回了其他内容（匹配 wilcox.test 而没有连续性校正）：
coin::wilcoxsign_test(结果 ~ 时间点 | PatientId，数据=d，zero.method = &quot;Wilcoxon&quot;)

渐近 Wilcoxon 符号秩检验

数据：y x (pos, neg) 
按区块分层
Z = -2，p 值 = 0.07
备选假设：真 mu 不等于 0

&gt; wilcox.test(结果 ~ 时间点，配对 = TRUE，数据 = d，正确 = FALSE)

Wilcoxon 符号秩检验

数据：按时间点的结果
V = 0，p 值 = 0.07
备选假设：真实位置偏移不等于 0

警告消息：
1：在 wilcox.test.default(x = c(0, 6, 0, 0, 0, 0, 1, 3, 1, 1, 3, 7) 中，:
无法计算具有关系的精确 p 值
2：在 wilcox.test.default(x = c(0, 6, 0, 0, 0, 0, 1, 3, 1, 1, 3, 7) 中，:
无法计算具有零的精确 p 值

因此，“V”与“Z”？
在这种情况下，我可以使用 Z/sqrt(12) = 0.577 来计算效果大小，该值是中等到大（根据 Cohen）。
那么，是否有机会直接从 R 库 wilcox.test 获取 Z（并计算效果大小）？我想坚持使用基础库。]]></description>
      <guid>https://stats.stackexchange.com/questions/542165/if-i-use-the-wilcox-test-from-r-for-paired-data-what-exactly-it-returns-i-want</guid>
      <pubDate>Wed, 01 Sep 2021 11:05:27 GMT</pubDate>
    </item>
    <item>
      <title>当连续预测因子是主要关注因素时的 ANCOVA：相关文章的扩展</title>
      <link>https://stats.stackexchange.com/questions/539119/ancova-when-continuous-predictor-is-a-main-factor-of-interest-extension-of-a-re</link>
      <description><![CDATA[从文献中，我了解到我们通常假设 ANCOVA 仅用于“控制”协变量。但是，从此相关 Stack Exchange 帖子来看，当独立变量为连续变量（而非协变量）时，ANCOVA 在数学上也应类似于回归和可能的检验。
我一直在寻找一些文章或评论，甚至提到使用 ANCOVA 来处理感兴趣的连续变量，但迄今为止尚未成功。
有人能推荐任何关于 ANCOVA 的这种特定框架的文献吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/539119/ancova-when-continuous-predictor-is-a-main-factor-of-interest-extension-of-a-re</guid>
      <pubDate>Wed, 04 Aug 2021 15:31:09 GMT</pubDate>
    </item>
    <item>
      <title>多次抽取的贝叶斯定理</title>
      <link>https://stats.stackexchange.com/questions/534710/bayes-theorem-with-multiple-draws</link>
      <description><![CDATA[设置
我对 Allen Downey 的 Think Bayes 2e 中的&quot;Cookie Problem Revisited&quot; 练习有疑问。贝叶斯定理定义为：
$$ P(H | E) = \frac{P(H) \ P(E | H)}{P(E)} $$
其中 E 是证据，H 是假设。
让我们考虑以下示例：两个碗里有不同的饼干。

碗 1 包含 30 块香草饼干和 10 块巧克力饼干。
碗 2 包含 20 块香草饼干和 20 块巧克力饼干。

我们随机选择一个碗并抽取一块香草饼干。它来自碗 1 的概率是多少？
$P(H=\text{Bowl1}) = 0.5$（我们随机选择碗）
$P(E=\text{vanilla} \ | \ H=\text{Bowl1}) = 30/(30+10) = 3/4 $
$P(E=\text{vanilla}) = (30 + 20)/(30 + 20 + 10 + 20) = 5/8$（香草饼干数量除以总饼干数量）
然后，后验 $P(H=\text{Bowl1} \ | \ E=\text{vanilla}) = 0.6 $。
问题
现在我们将香草饼干放回碗中并抽取第二块饼干。我们再次得到香草。我们可以使用刚刚计算的后验作为新的先验。后验现在是：$P(E=\text{vanilla} \ | \ H=\text{Bowl1}) * P(H=\text{previous posterior})$，如之前计算的。但是，证据的概率必须与我们之前计算的（香草饼干除以总饼干）不同，因为否则碗 1 和碗 2 的后验总和不会等于 1（为了简单起见，我没有在本文中表达碗 2 的后验）。
为什么当我们多次抽取时，证据的概率不等于香草饼干与总饼干的比例？在这种情况下我们如何计算它？
编辑：为清晰起见，提供附加信息]]></description>
      <guid>https://stats.stackexchange.com/questions/534710/bayes-theorem-with-multiple-draws</guid>
      <pubDate>Thu, 15 Jul 2021 14:47:49 GMT</pubDate>
    </item>
    <item>
      <title>中心极限定理和偏斜分布</title>
      <link>https://stats.stackexchange.com/questions/499403/central-limit-theorem-and-skewed-distribution</link>
      <description><![CDATA[我正在寻找一个与中心极限定理和高斯分布及偏斜分布相关的问题的简单答案（如果存在的话）。我使用二项式函数计算了 10 次抛掷不公平硬币（p=0.3，q=0.7）可能结果的概率，并获得了偏斜分布。我一直认为这是一种比例抽样分布。如果硬币被抛掷 10 万亿次，其中有 3 万亿次正面和 7 万亿次反面，并且将 10 个抛掷样本绘制到抽样分布中，就会得到我的偏斜曲线。
现在我还“了解到”中心极限定理说任何分布的抽样分布都是高斯曲线，但我承认我对此的研究相对肤浅。偏斜曲线是否仍被视为高斯曲线？关于中心极限定理，还有其他我不清楚的重要方面吗？我不一定需要全面的解释，而只是寻求一些有关我可能存在的误解的指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/499403/central-limit-theorem-and-skewed-distribution</guid>
      <pubDate>Fri, 04 Dec 2020 21:12:27 GMT</pubDate>
    </item>
    <item>
      <title>如何解释为什么分类输入（原样）与分类输入（二进制）在逻辑回归中产生不同的系数</title>
      <link>https://stats.stackexchange.com/questions/488765/how-to-explain-why-categorical-inputs-as-is-versus-categorical-inputs-as-bina</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/488765/how-to-explain-why-categorical-inputs-as-is-versus-categorical-inputs-as-bina</guid>
      <pubDate>Wed, 23 Sep 2020 12:27:41 GMT</pubDate>
    </item>
    </channel>
</rss>