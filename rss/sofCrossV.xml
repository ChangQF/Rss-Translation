<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 23 Oct 2024 21:16:25 GMT</lastBuildDate>
    <item>
      <title>对 SVM 上下文中 AUC ROC 阈值的使用感到困惑</title>
      <link>https://stats.stackexchange.com/questions/656224/confused-with-usage-of-auc-roc-thresholds-in-svm-context</link>
      <description><![CDATA[我的工作：我训练一个二分类 SVM 模型。然后我用一些测试数据文件对其进行测试，每个文件包含一段时间的数据。然后，我对每个文件内获得的标签集应用一些领域特定的逻辑方法；并使用另一种逻辑来获得类似的概率，即在 +ve 类测试数据 (TP) 中找到 +ve 类的概率和在 -ve 类测试数据 (FP) 中找到 +ve 类的概率。
然后，我绘制一条 roc 曲线，将这些概率与一组明确定义的阈值范围进行比较。我对不同的训练实验执行此操作，并根据 AUC ROC 即 roc 曲线下的面积判断性能。
我的问题是：
在单个 roc 图中，在 svm 的上下文中，“偏好”某个允许我获得满意 (TP,FP) 的阈值是没有意义的，对吗？因为最终，经过训练的 svm 将在实际应用中对任何新的特征向量表现出应有的表现。
这是否意味着我应该通过查看 roc 曲线中 FP=0 处的 TP 值来判断不同的训练实验？还是我应该查看阈值=0 时的 (TP,FP) 值？
或者我目前只查看总 auc roc 的方法是否足够？当我开始思考检查不同阈值的意义时，我得到了问题 1 和问题 2。]]></description>
      <guid>https://stats.stackexchange.com/questions/656224/confused-with-usage-of-auc-roc-thresholds-in-svm-context</guid>
      <pubDate>Wed, 23 Oct 2024 21:00:54 GMT</pubDate>
    </item>
    <item>
      <title>基线减法何时能提高统计功效？</title>
      <link>https://stats.stackexchange.com/questions/656223/when-does-baseline-subtraction-increase-statistical-power</link>
      <description><![CDATA[假设您有两组受试者（例如安慰剂和药物），每个受试者在治疗前和治疗后都进行了测量。我知道这种设计可以通过多种方式进行分析，例如对前后差异（即 delta）分数进行 t 检验、混合双向方差分析、ANCOVA...
问题：基线减法（delta 分数）方法何时可以提高统计能力，而不是仅比较治疗后分数？这必须取决于分数的相关性，即治疗前与治疗后，我想我在某处读到过这个 Pearson 相关系数必须至少为 0.5。是这样吗，还是取决于情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/656223/when-does-baseline-subtraction-increase-statistical-power</guid>
      <pubDate>Wed, 23 Oct 2024 20:57:29 GMT</pubDate>
    </item>
    <item>
      <title>关于分布矩的有限性</title>
      <link>https://stats.stackexchange.com/questions/656222/on-the-finiteness-of-moments-of-a-distribution</link>
      <description><![CDATA[考虑一个连续随机变量 $X\equiv\log(Y)$，其支持度高达 $+\infty$。假设
$$
E(\exp(\alpha X))&lt; \infty \quad \text{ 其中 $\alpha&gt;0$}
$$
我想了解这个假设对于 $X$ 和 $Y$ 有厚尾的可能性意味着什么。即：

$X$ 可以有帕累托分布吗？
$Y$ 可以有帕累托分布吗？
$X$ 可以有截断正态分布吗？而 $Y$ 可以有对数正态分布吗？

我的想法：

我不确定。

该条件本质上表明
$$
E(Y^\alpha)&lt; \infty \quad \text{ 对于某些 $\alpha&gt;0$}
$$
当 $Y$ 为帕累托分布时，是否有任何 $\alpha$ 满足此条件，并且它与尾部厚度有何关系？

如果 $X$ 为截断正态分布（仅取正值），则 $E(\exp( X))&lt; \infty$。因此，对于 $\alpha=1$，该假设得到满足。因此，$Y$ 可为对数正态分布。

]]></description>
      <guid>https://stats.stackexchange.com/questions/656222/on-the-finiteness-of-moments-of-a-distribution</guid>
      <pubDate>Wed, 23 Oct 2024 20:46:43 GMT</pubDate>
    </item>
    <item>
      <title>条件概率的极限</title>
      <link>https://stats.stackexchange.com/questions/656221/limit-of-a-conditional-probability</link>
      <description><![CDATA[考虑两个连续随机变量 $X$ 和 $Y$，取值范围为 $-\infty$ 至 $+\infty$。考虑以下极限：
$$
\lim_{t\rightarrow \infty} \Pr(X\leq t+a| Y=x) 
$$
我正在研究的证明假设该极限对于每个 $a\in \mathbb{R}$ 都是 $\ell&gt;0$。我不明白为什么这是一个假设，为什么对于任何 $a$，这个极限并不总是等于 1。您能通过回答以下几点来帮助我更好地理解这一点吗？
首先，当 $Y$ 和 $X$ 独立时，我们有
$$
\lim_{t\rightarrow \infty} \Pr(X\leq t+a| Y=x) =\lim_{t\rightarrow \infty} \Pr(X\leq t+a)\approx \Pr(X\leq \infty)=1。
$$
这是正确的吗？
如果上述内容正确，我不明白 $X$ 和 $Y$ 相关的情况会有什么不同。特别是，滥用概率概念（请原谅我将$Y$视为离散随机变量）：
$$
\lim_{t\rightarrow \infty} \Pr(X\leq t+a| Y=x) =\lim_{t\rightarrow \infty} \frac{\Pr(X\leq t+a, Y=t)}{\Pr(Y=t)}\approx\frac{\Pr(X\leq \infty, Y=\infty)}{\Pr(Y=\infty)}=\frac{\Pr(Y=\infty)}{\Pr(Y=\infty)}=1
$$
上述推导有什么问题？我可能搞乱了限制，但我看不出在哪里。]]></description>
      <guid>https://stats.stackexchange.com/questions/656221/limit-of-a-conditional-probability</guid>
      <pubDate>Wed, 23 Oct 2024 20:42:44 GMT</pubDate>
    </item>
    <item>
      <title>样本来自时间序列时两样本均值差异检验</title>
      <link>https://stats.stackexchange.com/questions/656220/two-sample-difference-of-mean-test-when-the-samples-come-from-time-series</link>
      <description><![CDATA[我有两组观察值，A 组和 B 组。我可以使用 t 检验来检验 B 组的平均值大于 A 组的假设。但这里的固有假设是两组中的样本是独立的。如果样本来自两个时间序列，情况会怎样？那么，它们是相关的，它们独立的假设不再有效。是否可以修改测试以解释自相关？如果可以以某种方式估计相关系数，则可以调整两个样本 t 检验中使用的方差。我找不到任何好的参考资料。有一些标准测试可以查看其中一个序列是否预测另一个序列，但我找不到任何比较均值或其他汇总统计数据的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/656220/two-sample-difference-of-mean-test-when-the-samples-come-from-time-series</guid>
      <pubDate>Wed, 23 Oct 2024 20:17:18 GMT</pubDate>
    </item>
    <item>
      <title>具有零膨胀和 zigamma 系列的 GLMM 中的置信水平问题</title>
      <link>https://stats.stackexchange.com/questions/656216/problem-with-confidence-level-in-glmm-with-zero-inflation-and-zigamma-family</link>
      <description><![CDATA[我正在评估哪种处理方法可以在根系生长分析中促进根系更长。我有五种不同的处理方法，每种方法有四个样本，在三个独立实验（N = 540）中进行了九天的评估。我的数据遵循伽马分布；但是，有些根系长度等于零。因此，我考虑使用 zigamma 系列的零膨胀模型。下面是我应用的 glmmTMB 函数：
 model_zi &lt;- glmmTMB(root_length ~ treatment + (1|exp/day),
family = ziGamma(link = &quot;log&quot;),
ziformula = ~treatment, 
data = data_roots)

结果：
Family：Gamma ( log )
公式：root_length ~ treatment + (1 | exp/day)
零通货膨胀：~treatment
数据：data_roots

AIC BIC logLik 偏差 df.resid 
1953.5 2009.3 -963.7 1927.5 527 

随机效应：

条件模型：
组名称方差标准差。
day:exp（截距）7.641e-01 0.8741496
exp（截距）1.749e-07 0.0004182
观察数：540，组：day:exp，27；exp，3

Gamma 系列的离散度估计（sigma^2）：0.326

条件模型：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 0.18322 0.17816 1.028 0.30377 
treatmenttreat2 0.42944 0.08579 5.006 5.57e-07 ***
treatmenttreat3 0.26535 0.08375 3.168 0.00153 ** 
treatmenttreat4 0.83239 0.08415 9.892 &lt; 2e-16 ***
treatmenttreat5 1.03670 0.08146 12.726 &lt; 2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

零通胀模型：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -2.0794 0.3062 -6.791 1.11e-11 ***
treatmenttreat2 0.7723 0.3860 2.001 0.0454 * 
treatmenttreat3 0.2549 0.4137 0.616 0.5378 
treatmenttreat4 0.3302 0.4088 0.808 0.4192 
treatmenttreat5 -1.8909 0.7766 -2.435 0.0149 * 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

我的问题是，一种治疗方法没有任何根长度等于零，导致这种治疗方法的置信区间非常宽（我应用了 sjPlot 中的 plot_model 进行此分析）您对如何解决这个问题有什么建议吗？我特别感兴趣的是治疗导致根长度为零的概率，这就是我为每种治疗选择零膨胀模型的原因。

我还使用 DHARMa 包中的 mockResiduals 函数进行了残差分析，并且在 K-S 检验中遇到了问题。

我还尝试重写模型如下：
model_zi &lt;- glmmTMB(root_length ~ treatment + (1|exp/day),
family = ziGamma(link = &quot;log&quot;),
ziformula = ~., 
data = data_roots)

但是，在这种情况下残差更糟糕。]]></description>
      <guid>https://stats.stackexchange.com/questions/656216/problem-with-confidence-level-in-glmm-with-zero-inflation-and-zigamma-family</guid>
      <pubDate>Wed, 23 Oct 2024 18:39:50 GMT</pubDate>
    </item>
    <item>
      <title>转换响应和使用非正态分布之间的建模有何差异？</title>
      <link>https://stats.stackexchange.com/questions/656215/difference-in-modelling-between-transforming-the-response-and-using-a-non-normal</link>
      <description><![CDATA[在回归建模中，通过转换响应变量（例如，对 y 应用对数转换）然后将输出反向转换回原始比例来拟合模型，与为响应指定非正态分布（例如，使用对数正态分布）之间有什么区别？
这些方法如何影响模型的解释、准确性和预测？
使用 brms 的示例：
# 对数转换模型
fit_log_transformed &lt;- brm(log(y) ~ x, data = mydata, family = gaussian())
# 然后我们将输出反向转换回原始比例

# 对数正态模型
fit_lognormal &lt;- brm(y ~ x, data = mydata, family = lognormal())
```r
]]></description>
      <guid>https://stats.stackexchange.com/questions/656215/difference-in-modelling-between-transforming-the-response-and-using-a-non-normal</guid>
      <pubDate>Wed, 23 Oct 2024 18:27:52 GMT</pubDate>
    </item>
    <item>
      <title>关于在复杂调查设计中正确使用子集的后续问题</title>
      <link>https://stats.stackexchange.com/questions/656209/follow-up-question-on-the-proper-use-of-subset-in-complex-survey-designs</link>
      <description><![CDATA[我阅读并尝试理解关于复杂调查设计中适当子集的各种贡献，包括：

调查数据的适当子集
在分析之前对调查数据进行子集化何时不是问题？
为什么制作调查设计对象很重要（R 中带有 id 的 svydesign 函数，原始数据和对象中清理数据后，如何从原始数据中提取地层、权重、fpc？
https://notstatschat.rbind.io/2021/07/22/subsets-and-subpopulations-in-survey-inference/

我理解，在 svyby() 中使用 subset() 时，未选定观测值的权重设置为 0，对吗？
我还理解，在构建调查设计对象之前或内进行子集化时，点估计没有差异svyby()，但标准误差和置信区间却如此。
我想我理解或者至少想象这两种方法对整群抽样的影响。如果我们在构建调查设计对象之前删除集群，我们假设删除的集群不存在，剩余的集群代表可能集群的完整范围，而实际上删除的集群也包含重要信息，即它们是空的。我说得对吗？
然而（或者说更糟的是），我很难理解分层抽样的后果。例如，如果我们估计女性的平均值，而忽略男性（即在构建调查设计对象之前选取了一部分女性受访者），我们会错过什么信息。在撰写本文时，我想知道我们是否假设在分层抽样中，男性亚群的方差也提供了有关女性亚群方差的信息？
感谢您的时间；如果我需要提供更多信息，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/656209/follow-up-question-on-the-proper-use-of-subset-in-complex-survey-designs</guid>
      <pubDate>Wed, 23 Oct 2024 16:14:08 GMT</pubDate>
    </item>
    <item>
      <title>集合平均值的统计检验</title>
      <link>https://stats.stackexchange.com/questions/656208/statistical-test-of-ensemble-averages</link>
      <description><![CDATA[机器学习模型通过其预测进行评估，产生单值分数（例如均方误差）。机器学习模型是随机初始化的，这会影响其分数。重复建模会产生不同的分数。通常，从业者会采用最佳模型并继续前进。但要重现表现最佳的模型则基于随机性。
假设模型的平均预测（即集合平均值）比单个最佳模型更具可重复性。
我想确定某种特定方法是否改善了建模性能。对于每个实验单元，我有 20 个重复模型。我可以取重复模型的集合平均值，然后比较分数。但这 20 次重复也容易产生随机性 - 不同的 20 次重复可能会导致不同的集合平均值。
我想要一些比较集合平均值的统计支持。我可以执行 Mann-Whitney U 检验来比较 20 次重复集的性能，但这会给我一个单独比较性能的 p 值。
对模型子集进行整体平均并比较它们的性能是否合适？对于 n &lt; N 的子集，我们确定所有可能子集的整体平均值的性能。
如果合适，是否有确定子集大小的一般准则？
欢迎对此任何部分发表任何意见。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656208/statistical-test-of-ensemble-averages</guid>
      <pubDate>Wed, 23 Oct 2024 16:13:13 GMT</pubDate>
    </item>
    <item>
      <title>理解和报告带有样条项的 Cox 模型</title>
      <link>https://stats.stackexchange.com/questions/656207/understanding-and-reporting-cox-models-with-spline-terms</link>
      <description><![CDATA[我已经用 pspline() 项对连续协变量拟合了一个 Cox 模型。我试图更好地理解如何才能正确报告我的结果。
关于报告，我发现了几个建议（使用 rms 包）。由于我没有使用 rms 包，我正在寻找使用 R 库的替代方案。ggplot(Predict(cph(*))) 和 termplot(coxph(*)) 之间有什么区别？形状相同，但值不同，例如：
library(survival)
library(rms)

# ggplot(Predict(cph(*)))
dd &lt;- datadist(lung)
options(datadist = &quot;dd&quot;)
fit1 &lt;- cph(Surv(time, status) ~ rcs(age, 3) + sex, data = lung)
ggplot(Predict(fit1, age))

# termplot(coxph(*))
fit2 &lt;- coxph(Surv(time, status) ~ rcs(age, 3) + sex, data = lung)
termplot(fit2, term = 1, se = TRUE)



或者使用 pspline() 代替 rcs()：
fit4 &lt;- coxph(Surv(time, status) ~ pspline(age) + sex, data = lung)
termplot(fit4, term = 1, se = TRUE)


无论如何，我并不清楚这些函数实际上起什么作用。如果我理解正确，pspline() 和 rcs() 允许协变量和结果之间的非线性（例如，年龄 = 40 和年龄 = 80 的 HR 不同）。
但是，在绘制 Cox 模型的 pspline() 项的 termplot() 时，我究竟在看什么？例如

如何解释该图？根据第三个图，我们可以说年龄 = 40 时的 HR = exp(-0.2) 和年龄 = 80 时的 HR = exp(0.6) 吗？
我们可以解释曲线的斜率吗？如果没有 pspline()，回归线的斜率对应于完整模型中变量的系数（代码在文章末尾）。
我们可以报告一个平均值吗？

顺便说一句，根据作者和函数的不同，y 轴的标签不同（例如 termplot() 中的“年龄偏向”；rms:::ggplot.Predict() 中的“对数相对风险”；或 样条线小插图中的“相对死亡率”，图2，也这里讨论），这让我更加困惑。

fit3 &lt;- coxph(Surv(time, status) ~ age + sex, data = lung)
age &lt;- termplot(fit3, term = 1, se = TRUE, plot = FALSE)$age
identical(
coef(fit3)[[1]],
(age$y[which.max(age$x)] - age$y[which.min(age$x)]) / (max(age$x) - min(age$x))
)
# [1] TRUE
]]></description>
      <guid>https://stats.stackexchange.com/questions/656207/understanding-and-reporting-cox-models-with-spline-terms</guid>
      <pubDate>Wed, 23 Oct 2024 15:39:56 GMT</pubDate>
    </item>
    <item>
      <title>随着树变得越来越复杂，X-val 相对误差也会增加</title>
      <link>https://stats.stackexchange.com/questions/656206/x-val-relative-error-increases-as-trees-get-more-complex</link>
      <description><![CDATA[我正在使用 rpart 构建 CART 模型。这是我使用的代码：
train_rpart &lt;- rpart(
y ~ x1 + x2 + x3 + x4,
data = train, 
method = &quot;class&quot;, 
control = rpart.control(
minsplit = 20, 
minbucket = 5, 
cp = 0, 
maxdepth = 5, 
xval = 10
),
parms = list(
split = &quot;gini&quot;, 
loss = matrix(c(0, 1, 10, 0), 
byrow = TRUE, 
nrow = 2
)
)

plotcp(train_rpart)

这是我得到的结果：

我知道 x-val 相对误差随着树的大小增加而变大的原因是由于过度拟合。但是，除了我已经做过的事情之外，我不确定我还能做些什么来解决这个问题。我尝试过 SMOTE 来平衡数据集，但仍然没有帮助。我将不胜感激任何帮助和建议。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656206/x-val-relative-error-increases-as-trees-get-more-complex</guid>
      <pubDate>Wed, 23 Oct 2024 15:24:00 GMT</pubDate>
    </item>
    <item>
      <title>时间序列的局部异常值因子</title>
      <link>https://stats.stackexchange.com/questions/656203/local-outlier-factor-for-time-series</link>
      <description><![CDATA[我希望这有意义。我发现了 LOF 并在 R 中尝试了它。但是，由于我处理的是时间序列，所以邻居不能是当前观察的“未来”邻居。我想知道使用 LOF 检测时间序列中的异常值是否会因此而出现问题。基本上，给定一个按日期排序的一维数据集，我希望 LOF 给出一个因子，仅考虑当前观察左侧的邻居，而不是右侧的邻居。
我正在尝试在我的时间序列中查找异常。异常是时间序列中的一个值，在（仅）给定该序列的先前值的情况下，该值是非常出乎意料的。
编辑
提供更多有关我的目标的背景信息。
我想开发一种方法来识别连续时间序列中每月频率的异常，其范围是了解在获取新数据时新记录是否是异常（一种预警系统）。
我目前关注的是找到一种可以识别已经发生的异常的方法，将其应用于我的历史数据并查看其工作原理。
我正在结合不同的方法：LOF 是其中之一，然后我使用 K-means 将我的数据分成 3 组，然后计算这些组的修改后的 z 分数。我对这些计算指标应用了一些阈值，以标记我的系列中的异常值。
我还进行了一些事后调整，以便 1) 如果当前类的聚类中心与前一个不同（因为我们进入了新的“状态”），则将新的异常值添加到列表中；2) 如果之前的观察结果已被标记为异常值，则从列表中删除异常值（因为我们只希望在异常阶段开始时收到警告）。
随着新观察结果的出现，我不确定如何进行，但一个想法是重新运行整个过程（不需要花费太多精力，数据非常小）。我的另一个想法是通过构建一个预测模型来预测未来的新观察结果，其中检测到的历史异常是我的目标值，但我可能需要在进行预测时仍需要计算的信息，所以我认为这没有什么意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/656203/local-outlier-factor-for-time-series</guid>
      <pubDate>Wed, 23 Oct 2024 14:47:24 GMT</pubDate>
    </item>
    <item>
      <title>部署后生成的分发</title>
      <link>https://stats.stackexchange.com/questions/656201/generated-distribution-after-deployment</link>
      <description><![CDATA[设$\mathcal{D}$表示乘积空间$\mathcal{X} \times \mathcal{Y}$上的联合分布，其中$\mathcal{X}$和$\mathcal{Y}$分别表示输入源和输出源。
假设$h$是在样本$S \sim \mathcal{D}^m $上训练的某些学习规则的输出。现在标签取决于$h$，则$\mathcal{X} \times \mathcal{Y}$上产生的新分布是什么？我们如何才能正确定义这个分布？
我的尝试：
我将定义结果分布 $\mathcal{D}_h$：
$$\mathcal{D}_h(\langle x ,y \rangle) = \mathcal{D}_{\mathcal{X}}(x) \times \mathcal{D}(h(x) = y|x) $$
但是如果 $h$ 是随机的，这意味着 $h$ 在给出输出之前使用了一些随机过程（抛硬币），该怎么办？如果 $h$ 是密度，该怎么办？如果 $h$ 是单纯形 $\Delta_\mathcal{Y}$ 上的密度分布，那么表达式是否简单地变为 $\mathcal{D}_h(\langle x ,y \rangle) = \mathcal{D}_{\mathcal{X}}(x) \times h^y(x) $? 其中 $h^y(x)$ 是概率密度。
特别是，保留相同的边际分布 $\mathcal{D}_{\mathcal{X}}$ 是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/656201/generated-distribution-after-deployment</guid>
      <pubDate>Wed, 23 Oct 2024 14:34:58 GMT</pubDate>
    </item>
    <item>
      <title>使用（非常）有限样本的最佳统计分析：MLR 与 GLM 与 GAM 以及其他？</title>
      <link>https://stats.stackexchange.com/questions/656196/best-statistical-analysis-with-very-limited-samples-mlr-vs-glm-vs-gam-vs-som</link>
      <description><![CDATA[我的数据集非常有限（11 个观测值）。我试图获取响应变量和环境协变量之间的关系（我有一组 14 个环境协变量可以使用）。最终目标是能够通过环境协变量的组合来预测响应变量。
我运行了 MLR，得到了非常有趣的结果，但我不确定它们在统计上是否足够稳健，因为我的数据不是参数化的。
我还运行了 GLM 和 GAM，也获得了有趣的关系。
我知道我的数据非常有限，但这种数据通常都是这样，因为每个点都很难获得（时间和金钱昂贵）。]]></description>
      <guid>https://stats.stackexchange.com/questions/656196/best-statistical-analysis-with-very-limited-samples-mlr-vs-glm-vs-gam-vs-som</guid>
      <pubDate>Wed, 23 Oct 2024 12:49:35 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 p 值的逆概率？</title>
      <link>https://stats.stackexchange.com/questions/656193/how-to-calculate-the-inverse-probability-of-a-p-value</link>
      <description><![CDATA[我理解，如果零假设为真，p 值就是获得数据（或更多极端值）的概率。
然而，研究人员真正想知道的是，在给定数据的情况下，零假设为真的概率。
因此，需要计算逆概率，该逆概率基于对零假设基本概率的估计，并对诸如“获得数据的总概率”之类的内容进行加权。
我可以使用贝叶斯推理，结合测试的敏感度、基准率和阳性总数：
P（患病|阳性）= P（阳性|患病）* P（患病）/ P（阳性）
例如，如果一种疾病影响 100 人中的 1 人，测试的敏感度为 99%，我随机测试 100 人，我会得到两个阳性（一个真，一个假），逆概率~0.5：
0.99 * 0.01 / ~0.02 = ~0.5
现在，我的问题是，我应该如何使用贝叶斯推理来计算 p 值的逆概率？
例如，我对 H0 没有任何先验知识，因此假设 P(H0) = 0.5，然后我得到一个显著性检验，假设 p 值 = 0.01。我想知道在这种情况下 P(positif) 对应的是什么：
P(H0|data) = P(data|H0) * P(H0) / P(of what?) = 0.01 * 0.5 / 具体是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/656193/how-to-calculate-the-inverse-probability-of-a-p-value</guid>
      <pubDate>Wed, 23 Oct 2024 12:13:59 GMT</pubDate>
    </item>
    </channel>
</rss>