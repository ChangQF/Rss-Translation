<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 07 Jan 2025 18:23:12 GMT</lastBuildDate>
    <item>
      <title>我应该将点大小（面积）比例缩放为 1/标准误差还是 1/SE^2？</title>
      <link>https://stats.stackexchange.com/questions/659678/should-i-scale-point-size-area-proportion-to-1-standard-error-or-1-se2</link>
      <description><![CDATA[我有一堆估计值，我想将它们绘制在 y 轴上，而 x 轴上则绘制其他值。我想传达每个点的不确定性（x 轴值已知，y 轴值是估计值）。误差线会使图变得非常混乱，所以我想使用点的大小来传达我们对每个点的确定程度。据我所知，建议人们将面积（而不是直径）视为信息量（例如，参见本文或此链接 - 不确定这些是否是标准参考文献）。
但是，有没有研究信息度量应该是 1/SE（标准误差的倒数）还是 1/SE^2（抽样方差的倒数）。鉴于对于误差线，我们将使用 +-SE 或置信区间（95% 的置信区间大约为 +- 1.96*SE），我猜是 1/SE？不知何故，我找不到是否有人尝试过实证检验这是否有效（例如，当人们被问到问题时，他们会根据所选的可视化效果做出适当的回答，即当给定基于 1/SE 或 1/SE^2 或其他东西的点大小时，他们是否会做得更好）。
鉴于我们倾向于绘图]]></description>
      <guid>https://stats.stackexchange.com/questions/659678/should-i-scale-point-size-area-proportion-to-1-standard-error-or-1-se2</guid>
      <pubDate>Tue, 07 Jan 2025 17:47:22 GMT</pubDate>
    </item>
    <item>
      <title>使用 IRT 进行非监考评估</title>
      <link>https://stats.stackexchange.com/questions/659676/using-irt-for-a-non-proctored-assessment</link>
      <description><![CDATA[过去几年，我的研究团队一直在为大学课程结束时参加的学生进行内部多项选择知识评估。我的老板坚持要我们进行有效性测试，并且非常喜欢 IRT 模型。但是，我们没有资源来监考考试，而且为了招聘，我们的研究负责人不想规定我们的合作教师如何进行评估或为其分配多少学分。这允许教师享有某些自由。例如，评估是基于计算机的，我知道许多教师只是让学生在家参加评估，有些教师会给予很少的学分。
我担心的是，当我们运行 IRT 模型时，它们不会非常准确，因为学生很有可能作弊，或者没有付出任何努力。我们过去几次管理中有大约 300-600 名学生，2PL 模型往往是最合适的。但是，它们仍然不太匹配（RMSEA 和 CFI 不错，但 M2 显示预期和实际观察值之间存在显著差异）。此外，最近两个学期的 IRT 结果显示出不一致的结果。在一个学期中，一个项目表现良好；在下一个学期，我会得到负面歧视或难度指数为 30 或类似的奇怪结果。
我的问题是：有没有方法可以减轻非监考评估固有的可变性，以适应 IRT 框架？或者，我运气不好，我需要求助于其他方法来测试有效性？或者，我是否只需要说服我的研究负责人，我们需要投入资源来建立监考管理以进行测试？
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/659676/using-irt-for-a-non-proctored-assessment</guid>
      <pubDate>Tue, 07 Jan 2025 17:32:27 GMT</pubDate>
    </item>
    <item>
      <title>调整 Chernozhukov 等人的通用机器学习推理以获得事件发生时间结果</title>
      <link>https://stats.stackexchange.com/questions/659674/adapting-chernozhukov-et-al-s-generic-machine-learning-inference-for-time-to-ev</link>
      <description><![CDATA[这是一个非常具体的问题，但我们开始吧！
我正在努力将 Chernozhukov 等人的随机实验中对异质性治疗效果的通用机器学习推断中的方法应用于事件发生时间结果（例如生存分析）。本文通过将机器学习方法与最佳线性预测器 (BLP) 估计和有效推理技术相结合，提供了一个估计异质治疗效果 (HTE) 的框架。
虽然对连续或二元结果有一般的扩展，但将其应用于事件发生时间数据会因审查和生存特定指标而带来独特的挑战。
一般问题：
是否有人实施或改编了 Chernozhukov 等人的事件发生时间结果方法？如果是，需要进行哪些修改才能使该方法与生存分析兼容？
是否有任何通用工具、库或资源可用于解决此类问题，特别是用于调整生存数据的第 1 阶段（代理函数估计）和第 2 阶段（BLP）？

具体挑战：
第 1 阶段：代理函数估计（B(Z) 和 S(Z)）
第 1 阶段的损失函数是根据 BLP 估计量身定制的。如何调整它以考虑生存数据中的审查？
标准生存损失函数（例如 Cox 模型或 Brier 评分的负偏对数似然）是否足够？如果不够，建议使用哪些替代方案？

第 2 阶段：最佳线性预测器 (BLP) 估计
在生存分析中，通常使用生存概率、风险比或时间相关指标（例如一致性指数、时间相关 AUC）等结果。如何使 BLP 框架适应此类指标？
BLP 计算应如何处理审查，以及在这种情况下进行有效推理需要考虑哪些因素？

实施和工具
是否有针对事件发生时间数据量身定制的此方法的具体实施（使用 R 或 Python）？

更广泛的背景：
目标是在存在审查的事件发生时间结果的情况下估计异质性治疗效果，同时通过重复数据分割和分位数聚合等技术保持有效推断。任何与将此方法用于生存分析相关的见解、参考或示例都将非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/659674/adapting-chernozhukov-et-al-s-generic-machine-learning-inference-for-time-to-ev</guid>
      <pubDate>Tue, 07 Jan 2025 17:24:47 GMT</pubDate>
    </item>
    <item>
      <title>检测生存分析中的单个变化点/拐点</title>
      <link>https://stats.stackexchange.com/questions/659673/detection-of-a-single-change-point-inflection-in-a-survival-analysis</link>
      <description><![CDATA[我正在对有和没有手术并发症的患者进行生存分析。当检查这两个群体的 Kaplan-Meier 曲线时，很明显手术并发症对术后早期生存的影响更大。Schoenfeld 残差和对数减对数图显示违反了 PH 假设。
有/无并发症的患者的 KM 曲线显示其拐点在术后 3 个月左右发生了明显变化。这表明术后早期并发症的影响更大。术后每个月的调整和未调整 HR 显示​​出相似的趋势。
我如何准确检测和描述这个精确的变化点/拐点？
我想估计一个确切的日期以协助临床决策。我花了好几天到处寻找这个特定问题的答案，但我找不到解决方案。
我正在与 R 合作。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659673/detection-of-a-single-change-point-inflection-in-a-survival-analysis</guid>
      <pubDate>Tue, 07 Jan 2025 17:24:04 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归，得出 $\beta$ 的精确置信集</title>
      <link>https://stats.stackexchange.com/questions/659668/multiple-linear-regression-deriving-an-exact-confidence-set-for-beta</link>
      <description><![CDATA[我正在研究统计学习要素。对于多元线性回归，他们假设输出向量满足$ Y = X\beta + \epsilon$，其中$X \in \mathbb R^{N \times (p+1)}$和$\beta \in \mathbb{R}^{p+1}$是固定的，并且$\epsilon \sim \mathrm{Norm}(0, \sigma^2 I_N)$。
然后他们给出了$\hat\beta = (X^T X)^{-1} X^{T} Y$和$\hat\sigma^2 = \frac{1}{N-p-1} \|Y - X\hat\beta\|^2$，即
$$
\hat\beta \sim \mathrm{Norm}(\beta, (X^T X)^{-1}\sigma^2) \quad\text{and}\quad (N-p-1)\hat\sigma^2 \sim \sigma^2 \chi_{N-p-1}^2。
$$
最后，他们指出（公式 3.15），对于 $\beta$，近似 $1-\alpha$ 置信集由
$$
\{ \beta : (\hat\beta-\beta)^T X^T X(\hat\beta -\beta) \le \hat\sigma^2 \chi_{p+1,1-\alpha}^2\} 给出。
$$
我理解这是一个近似的 $1-\alpha$ 置信集，而用 $\sigma^2$ 替换 $\hat\sigma^2$ 会给出一个精确的 $1-\alpha$ 置信集。
但是，我想知道是否有可能在不知道 $\sigma^2$ 的情况下为 $\beta$ 得出一个精确的 $1-\alpha$ 置信集。
我在这个答案中看到
$$
\frac{(\hat{\beta}-\beta)^TX^TX(\hat{\beta}-\beta)}{(p+1)\hat{\sigma}^2}\sim F_{p+1,N-p-1},
$$
这根据上面给出的分布以及$\hat\beta$和$\hat\sigma^2$是独立的这一事实得出。由此，我们可以说
$$
\{ \beta : (\hat{\beta}-\beta)^TX^TX(\hat{\beta}-\beta) \le (p+1)\hat\sigma^2F_{p+1, N-p-1, 1-\alpha}\}
$$
是 $\beta$ 的精确 $1-\alpha$ 置信集吗？如果是这样，使用上述近似置信集而不是这个精确置信集有什么好处？]]></description>
      <guid>https://stats.stackexchange.com/questions/659668/multiple-linear-regression-deriving-an-exact-confidence-set-for-beta</guid>
      <pubDate>Tue, 07 Jan 2025 15:15:59 GMT</pubDate>
    </item>
    <item>
      <title>混合模型：在 R 中探究聚类内中心化后一级分类变量之间的相互作用</title>
      <link>https://stats.stackexchange.com/questions/659667/mixed-model-probing-an-interaction-between-level-1-categorical-variables-after</link>
      <description><![CDATA[我有以下模型：
model &lt;- lmer(scores ~glasses + D1 + D2 +glasses:D1 +glasses:D2 + (1|participantNumber),data,REML = FALSE)


参与者在戴或不戴眼镜（关 = 0，开 = 1）的情况下完成了一项任务的试验，并且分为三个难度级别（简单 = 0，中等 = 1，困难 = 2）

两个 1 级预测因子（眼镜和任务难度）在概念上都是分类的，但已在集群内居中，因此它们现在是“连续的”


我如何评估每个任务难度级别上分数和眼镜之间的关系？
由于我的预测因子现在是“连续”，我使用 Johnson-Neyman 方法来探测交互作用（使用 interactions 包）。但是，我想报告诸如 t 统计量之类的值，但除非我“选择一个点”，否则我无法这样做，但我不知道该选择哪个点，因为数字范围很广。
例如，在常规回归中，我的虚拟编码变量对于所有参与者都如下所示：



任务难度
D1
D2
D1b
D2b
D1c
D2c




简单
0
0
0
1
1
0


中等
 1
0
0
0
0
1


困难
0
1
0
0
0



之后在集群内居中，参与者有不同的虚拟编码值：
参与者 1



任务难度
D1
D2
D1b
D2b
D1c
D2c




容易
-0.33
-0.33
-0.33
+0.67
+0.67
-0.33


中等
+0.67
-0.33
-0.33
-0.33
-0.33
+0.67


困难
-0.33
+0.67
+0.67
-0.33
-0.33
-0.33



参与者22



任务难度
D1
D2
D1b
D2b
D1c
D2c




简单
-0.48
-0.05
-0.05
+0.95
+0.52
-0.48


中等
+0.52
-0.05
-0.05
-0.05
-0.48
+0.52


困难
-0.48
+0.95
+0.95
-0.05
-0.48
-0.48



因此， Johnson-Neyman 方法告诉我，分数和眼镜之间的关系取决于 D1/D2 是负数还是正数。
probe_interaction(model, pred =glasses, modx = D1, data,
confint=TRUE, cond.int=TRUE, interval=TRUE,
centered=&quot;none&quot;, johnson_neyman=TRUE, jnplot=TRUE)

probe_interaction(model, pred =glasses, modx = D2, data,
confint=TRUE, cond.int=TRUE, interval=TRUE,
centered=&quot;none&quot;, johnson_neyman=TRUE, jnplot=TRUE)

但是，要报告 t 统计量，例如在评估简单任务难度下的分数和眼镜之间的关系时，我不知道如何选择“0” 表示简单条件，因为“0”在一个参与者中为 -0.33，在另一个参与者中为 -0.48。
任何指导（统计或要使用的函数）都值得赞赏，提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/659667/mixed-model-probing-an-interaction-between-level-1-categorical-variables-after</guid>
      <pubDate>Tue, 07 Jan 2025 15:05:35 GMT</pubDate>
    </item>
    <item>
      <title>GAM 中相互作用项的意义</title>
      <link>https://stats.stackexchange.com/questions/659666/significance-of-interaction-term-in-gam</link>
      <description><![CDATA[我有一个广义加性模型，其形式如下：
$E[Y] = \beta_0 + f(X_1) + \beta_2X_2 + f(X_1)\times X_2$
其中 $f(X_1)=\sum^n_i\beta_i\boldsymbol{B}_i(X_{1i})$ 是平滑函数，$\boldsymbol{B}(\cdot)$ 是用于平滑连续协变量 $X_1$ 的基函数（例如三次样条函数），$f(X_1)\times X_2$ 是平滑的 $X_1$ 和二元协变量 $X_2$ 之间的交互项。
我感兴趣的是测试 $X_1$ 和 $X_2=0$ 之间的交互是否与 $X_1$ 和 $X_2=1$ 之间的交互有显著不同，例如测试两个相互作用的斜率是否显著不同。
如果这是一个 GLM，其中人们使用 $X_1$ 而不应用基函数，则可以通过比较两个不同相互作用的参数直接推断出差异（分别为 $X_2=0$ 和 $X_2=1$）。现在涉及到样条函数，我们总共有 $2n$ 个交互项（$n$ 个基函数，每个基函数与两个条件交互）及其相应的系数，我不再确定如何测试交互是否因条件 $X_2$ 而显著不同。
当连续协变量被多个基函数“分割”为区间，并且这些区间与二元协变量的两个级别交互时，如何测试显著交互？特别是在不使用 LRT 或需要拟合嵌套模型的类似方法的情况下。使用例如 Wald 检验来测试两组参数是否显著不同或逐一比较系数是否有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/659666/significance-of-interaction-term-in-gam</guid>
      <pubDate>Tue, 07 Jan 2025 14:55:32 GMT</pubDate>
    </item>
    <item>
      <title>GARCH 和 Granger 因果关系检验</title>
      <link>https://stats.stackexchange.com/questions/659665/garch-and-granger-causality-test</link>
      <description><![CDATA[我正在尝试重新创建论文&quot;金融和保险行业连通性和系统性风险的计量经济学测量&quot;（开放获取版本此处）来自 Billio 等人（2012 年）的研究，使用 R 中的欧洲股票数据。
他们使用 Granger 因果关系检验来估计金融机构之间的联系。此外，他们还考虑了广义自回归条件异方差 GARCH(1,1) 收益模型，以控制异方差。
我是否正确地理解了作者首先拟合 GARCH(1,1) 模型，例如：
garch_spec &lt;- rugarch::ugarchspec(mean.model = list(armaOrder = c(0, 0)),
variance.model = list(model = &quot;sGARCH&quot;, garchOrder = c(1, 1)),
distribution.model = &quot;sstd&quot;)

garch_fit1 &lt;- rugarch::ugarchfit(spec = garch_spec, data = stock_return_bank1,solver = &quot;hybrid&quot;)
garch_fit2 &lt;- rugarch::ugarchfit(spec = garch_spec, data = stock_return_bank2,solver = &quot;hybrid&quot;)

然后使用残差估计 Granger 因果关系？
residuals1 &lt;- residuals(garch_fit1, standardize = TRUE)
residuals2 &lt;- residuals(garch_fit2, standardize = TRUE)

test_result &lt;- lmtest::grangertest(formula = residuals2 ~ residuals1, order = XYZ, test = &quot;F&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/659665/garch-and-granger-causality-test</guid>
      <pubDate>Tue, 07 Jan 2025 13:56:51 GMT</pubDate>
    </item>
    <item>
      <title>Pickands-Balkema-De Haan 定理、依赖性和改组</title>
      <link>https://stats.stackexchange.com/questions/659664/pickands-balkema-de-haan-theorem-dependence-and-shuffling</link>
      <description><![CDATA[Pickands-Balkema-de Haan 定理指出，条件超额分布函数可以通过广义帕累托分布很好地近似（对于高超额，并且如果底层 RV 可以缩放和规范化，以便条件超额分布函数具有非退化极限）。所以
$\mathbb{P}(X-u\leq y \, \vert\, X &gt; u) \xrightarrow{u \to \infty} G_{\xi, \sigma}$，其中 $G_{\xi, \sigma}$ 是 GPD。
在极值数据分析中，样本 $X_i$ 通常被假定为 $i.i.d.$，然后超过某个高阈值的点 $u$ 用于通过最大似然法拟合参数 $\xi, \sigma$。
该定理有一个针对弱相关样本的版本，在实践中，人们会确定超过阈值的点簇，然后将上述定理仅应用于这些簇的均值或最大值，然后假定这些簇为$i.i.d$。但这会引入一个额外的参数，用于估计“聚类强度”。
那么为什么需要进行去聚类？上述定理仅对条件超额分布的尾部做出陈述。因此，如果我有一个样本概率分布，我可以只取相关样本的时间序列，对其进行混洗，这样新样本就不相关，并且概率分布的尾部看起来会相同，因此在拟合时会给我完全相同的$\xi, \sigma$。
那么我的推理到底哪里出了问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659664/pickands-balkema-de-haan-theorem-dependence-and-shuffling</guid>
      <pubDate>Tue, 07 Jan 2025 12:53:35 GMT</pubDate>
    </item>
    <item>
      <title>非对称独立变量的排序</title>
      <link>https://stats.stackexchange.com/questions/659660/ranks-for-an-asymmetric-independent-variable</link>
      <description><![CDATA[我正在使用回归模型分析数据，其中感兴趣的独立变量是治疗，我想估计其效果。我打算调整一组协变量的估计值，包括两个生物标志物。这些生物标志物的分布高度偏斜（大多数个体的值介于 0 和 1 之间，少数个体的值超过 10,000）。最初，我考虑将生物标志物值分为 4 组，这是一种常见的方法。后来，我考虑使用等级，因为与分类相比，这可能会减少丢失的信息量。虽然这会降低参数的可解释性（使用类别更清晰，但使用等级则不那么清晰），但我的主要目标是进行调整，以便更好地估计感兴趣变量的效果。
您觉得如何？这种方法能带来优势吗？您知道任何描述这种方法的资源吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659660/ranks-for-an-asymmetric-independent-variable</guid>
      <pubDate>Tue, 07 Jan 2025 11:54:44 GMT</pubDate>
    </item>
    <item>
      <title>回归反应的统计比较</title>
      <link>https://stats.stackexchange.com/questions/659658/statistical-comparison-of-regressed-responses</link>
      <description><![CDATA[我记录了 5000 个事件。每个事件属于 50 个细胞中的一个（$C$），并且相对于其基线幅度（$X$）具有相应的响应幅度（$Y$）。每个细胞还属于 $3$ 个组中的一个（$T$）。我想测试在考虑基线后，每个组的响应幅度是否显著不同。我该怎么做？我原本想从 $Y \sim 1 + X + (1|C)$ 中收集每组细胞的随机效应估计值，但这似乎是一种非正统方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/659658/statistical-comparison-of-regressed-responses</guid>
      <pubDate>Tue, 07 Jan 2025 10:51:35 GMT</pubDate>
    </item>
    <item>
      <title>对 DiD 设计中均值中位数估计量的洞察</title>
      <link>https://stats.stackexchange.com/questions/659655/insights-into-median-of-means-estimators-in-did-designs</link>
      <description><![CDATA[我目前正在开展一个研究项目，重点研究双差分 (DiD) 设计中的稳健估计量，特别是在经典的两期两组设置中。我的主要兴趣是对 y 方向异常值的稳健性（我污染了误差项），并且我一直在探索均值中位数 (MoM) 估计量作为标准 DiD 治疗效果估计量（基于均值）的潜在替代方案。
但是，我遇到了几个问题：

缺乏文献：我找不到任何先前的研究或 DiD 环境中均值中位数估计量的应用。有人知道是否存在这样的研​​究或我可以在哪里找到吗？
意外结果：当我模拟和实施 MoM 估计量时，我得到的结果与标准 DiD 估计量相同 - 即使包含受污染的数据点也是如此。这让我开始质疑为什么 MoM 估计量在这种设置下不是更稳健。

有人能解释为什么中位数估计量在这种情况下可能无法按预期执行吗？或者 DiD 框架中是否存在一些基本问题，导致 MoM 方法不太合适？
如果您有任何想法、文献建议，甚至直观的解释，我将不胜感激！
在此先感谢您的帮助！

这是我的模拟设置：

数据生成：我模拟了 N=500 和 T=2 个时间段（治疗前和治疗后）的面板数据。一半的单位在第二期进行治疗。结果方程为 $Y = 0.1 + 0.2⋅time − 0.1⋅group + β_{true}⋅D + ϵ $。这里，$β_{true} = 0.4 $，ϵ 是带有污染的随机噪声。
污染：随机噪声 𝜖 以混合形式生成：
$ ϵ = \begin{cases} N(0, \sigma^2) &amp; \text{with probability } (1 - p), \\
U(-c, c) &amp; \text{概率 } p \end{cases}$ 
我尝试了参数 $\sigma$、$p$ 和 $c$（也尝试了非对称污染），但这似乎没有什么区别。
估计量构造如下：
$ \text{DiD Estimate} =
\left(
\overline{Y}_{\text{Treated, Post}} - \overline{Y}_{\text{Treated, Pre}}
\right)
-
\left(
\overline{Y}_{\text{Control, Post}} - \overline{Y}_{\text{Control, Pre}}
\right)
$
$
\text{均值中位数 (MoM)：}
$

将数据拆分为 $ K = \sqrt(N) $ 个块
计算特定于块的 DiD 估计值：$
\text{块 DiD 估计值} = \text{DiD(Block_i})$
最终 MoM 估计值是块估计值的中位数：$
\text{MoM 估计值} = \text{中位数(块 DiD 估计值)}$


]]></description>
      <guid>https://stats.stackexchange.com/questions/659655/insights-into-median-of-means-estimators-in-did-designs</guid>
      <pubDate>Tue, 07 Jan 2025 10:05:08 GMT</pubDate>
    </item>
    <item>
      <title>这里的 95% 置信区间是多少？我的答案正确吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659650/what-is-the-95-confidence-interval-here-is-my-answer-correct</link>
      <description><![CDATA[我正在处理这个问题：

这个问题要求找出两个城市超速罚单金额差异的 95% 置信区间；换句话说，mu(Orange) - mu(DeLand)。我得到的区间在 31.2103907 和 39.5396093 之间。这是正确的吗？如果不是，正确答案是什么？
我使用了以下公式：
]]></description>
      <guid>https://stats.stackexchange.com/questions/659650/what-is-the-95-confidence-interval-here-is-my-answer-correct</guid>
      <pubDate>Tue, 07 Jan 2025 08:38:28 GMT</pubDate>
    </item>
    <item>
      <title>使用加权逻辑回归对重复数据进行误差估计的校正因子</title>
      <link>https://stats.stackexchange.com/questions/659641/correcting-factor-for-error-estimation-with-weighted-logistic-regression-on-dupl</link>
      <description><![CDATA[假设一个数据集被复制，但第一个副本有一组权重，第二个副本有另一组权重，其中权重与我们复制数据的事实无关。主要问题：

将每个权重乘以 1/2 以纠正数据重复是否合理？
在什么条件下这不合适？下面是更多问题。

上下文
假设对于每个观察值 1 到 N，您有概率估计 $p_a=P(race=a)$, $p_b=P(race=b)$, $p_c=P(race=c)$，其中 $\sum_{r=\{a,b,c\}}p_r=1$ 和一些二元结果变量 $y$，并且我们希望估计逻辑回归 $\text{logit }y\sim \beta_0 + \beta_1 D^{r}+X\beta$，其中 当 P(race=r)&gt;.8 时，$D^r=1$，否则为 0。但是，由于我们希望明确地并且只比较 a 与 b，因此我们在 P(race=a)&gt;.8 或 P(race=b)&gt;.8 的数据子集上估计 $\text{logit }y\sim \beta_0 + \beta_1 D^{b}+X\beta$。这是传统方法，但它会剔除所有 P(race=a)&lt;.8 AND P(race=b)&lt;.8 的数据。
重复的数据集，但每个重复项的权重不同
为了不剔除 P(race=a)&lt;.8 AND P(race=b)&lt;.8 为真的观测值所包含的信息，我上面的一些高阶专家估计了一个加权逻辑回归，其中
\begin{align}
\text{logit }\begin{pmatrix}
y \\
y \\
\end{pmatrix} &amp;= \beta_0+\beta_1\begin{pmatrix}
D^{b} \\
D^{b} \\
\end{pmatrix}
+ \begin{pmatrix} X \\ X\\ \end{pmatrix} \beta
\end{align&gt;
其中 $$\text{weights} =\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$$ 且 $D^b_{1\dots N}$=1 且 $D^b_{(N+1)\dots 2N}=0$（基本上，第一个 1...N 堆栈具有虚拟 $D^b=1$ 且第二个 (N+1)...2N 具有虚拟 $D^b=0$。
问题 1：通常，每个观测值的权重为 1/2 应该可以解决因重复数据集而产生的误差估计问题。这是否仍然适用于权重的使用。例如，我可以这样做 $\text{weights} =\frac{1}{2}\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$。假设我无法绕过上述方法，但也许我可以调整权重以使上述方法合理。
问题 2：直观地说，这似乎至少会扭曲估计的误差，尽管使用权重也可能使系数估计产生偏差。有人见过这个吗？
问题 3：最后，估计一个简单的 $\text{logit }y\sim \beta_0 + \beta_1 p_b+\beta_2 p_c+X\beta$ 似乎更直观，无需借助权重。
旁白
对于有形的直觉，想想比较黑人与白人以及西班牙裔与白人，但不知道谁是白人、西班牙裔和黑人，你只能对每个类别有一个概率估计。
请原谅我草率的符号，希望它足以传达要点。]]></description>
      <guid>https://stats.stackexchange.com/questions/659641/correcting-factor-for-error-estimation-with-weighted-logistic-regression-on-dupl</guid>
      <pubDate>Tue, 07 Jan 2025 04:28:49 GMT</pubDate>
    </item>
    <item>
      <title>我如何改进季节性的实施，以便更好地为扩展和有效地自动化此方法做好准备？</title>
      <link>https://stats.stackexchange.com/questions/659634/how-can-i-refine-my-seasonality-implementation-to-better-prepare-for-scaling-and</link>
      <description><![CDATA[我不会深入探讨我的模型的细节，而是谈谈我希望解决的问题。
当前方法
我使用离散概率矩阵 (DPM) 来预测单个事件在每月期间发生的可能性。
DPM 按用户特征（例如年龄或性别）细分，每个单元格代表如果特征 Y 存在于 Z 月，则事件 X 发生的概率。
当前方法仅依赖于使用最新的实际值作为所有预测月份的基线。
此基线根据工作日进行了调整，以考虑月份长度的变化，从而有效地跨月份转移概率。尽管如此，概率仍然平均围绕实际值的最后一个点。
挑战
这种方法在某些 DPM 线中难以应对季节性。使用实际值的最后一点可能会严重高估或低估季节性活动。
此外，缺乏季节性成分意味着该模型无法捕捉一年中特定时间的重复模式。这很重要，因为该模型包含在 X 或 Y 月份等发生的几种经济条件。
引入的改进
为了解决季节性问题，我引入了经典加性季节性分解 (ASD) 来得出 DPM 中每个概率系列的季节性因素。
按照现有方法，我对基线应用了工作日调整，并在其上分层了季节性因素以保留季节性模式。
这种改进使模型能够同时考虑月份长度的变化和重复的季节性模式，从而使具有季节性活动的 DPM 线的预测更加准确。
方法的优势
ASD 假设有规律的季节性，这很符合我的模型的需求。
它有效地处理了 DPM 中的零/零概率，使其与我的数据兼容。
该方法很简单在 Excel 和 Python 等工具中实现。
季节性因素被标准化为零，确保它们只会改变值而不会改变年度概率总数。
方法保留了阶跃变化 - 这些变化可以在数据中自然发生。
此外，由于还有其他模型组件控制预测水平，因此这里需要一个相当平坦的基于证据的 DPM。
剩余挑战
ASD 假设所有数据点都是正确的，这突出了异常值检测的重要性。我已经测试了四分位距、Z 分数和修正 Z 分数，但我正在考虑是否存在更有效的方法来处理异常值。是否有测试可以区分阶跃变化和异常值。
使用实际值的最后一点作为基线有局限性。虽然平均值已经足够了，但我测试了更先进的技术，例如 Holt 和 Holt-Winters 指数平滑法，这些技术可能会提供更好的准确性。不过，我想知道是否有更好的方法，因为这些方法在 Python 中不是最容易实现的。
另一个问题是，我的方法将季节性应用于所有 DPM 线，无论它们是否显示季节性（是的，这是一个矛盾的评论）。我正在探索自动检测季节性的方法。我尝试使用自相关函数 (ACF) 来可视化我的时间序列数据中的季节性模式和依赖关系。如果有一个统计数据就太好了，可以利用它来决定是否应用季节性。
询问
我将不胜感激任何关于如何应对这些挑战的建议。我对时间序列分析和方法还很陌生。虽然我当前的方法是有效的，但它需要一定程度的人工干预，随着我扩大其应用范围，这种干预可能会变得难以为继。]]></description>
      <guid>https://stats.stackexchange.com/questions/659634/how-can-i-refine-my-seasonality-implementation-to-better-prepare-for-scaling-and</guid>
      <pubDate>Tue, 07 Jan 2025 01:48:00 GMT</pubDate>
    </item>
    </channel>
</rss>