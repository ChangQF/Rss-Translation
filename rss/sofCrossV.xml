<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 25 May 2024 06:19:50 GMT</lastBuildDate>
    <item>
      <title>XGBoost：操纵样本是否会使其“推断”？</title>
      <link>https://stats.stackexchange.com/questions/647942/xgboost-does-manipulating-the-sample-make-it-extrapolate</link>
      <description><![CDATA[假设我想使用 XGBoost 进行时间序列预测。我知道基于树的模型无法推断。然而，我正在使用的时间序列是固定的（没有趋势或明显的季节性+ ADF 测试 在训练样本上给出的 p 值基本上为零）。我的问题是，由于我将数据分为训练和测试子样本，因此模型无法预测测试集中的一些观察结果（异常值），因为它在训练集中没有看到如此低/高的值。该模型在边界附近给出了平坦的线。

我知道堆叠/混合模型（例如 XGBoost + LinReg）以允许外推。然而，据我所知，这只能解决推断趋势或季节性模式的问题，而我关心的是数据范围或异常值。如果我要拟合 XGBoost 模型，请获取预测 $\hat{y}_t$，然后对残差进行建模 $y_t -\hat{y}_t$ 与其他一些堆叠模型，那么我不知道有任何模型能够很好地预测一些突然的峰值，而所有其他值都接近于零（所以，基本上，&lt; a href=&quot;https://en.wikipedia.org/wiki/White_noise&quot; rel=&quot;nofollow noreferrer&quot;&gt;白噪声，突然出现峰值）
我还知道 XGBoost 中有一个选项可以选择 gblinear 作为助推器。然而，在我的特殊情况下，我的数据范围是在 $(0,+\infty)$ 中定义的（我预测波动性），所以这将允许模型得到负值。另外，我已经尝试拟合这个模型，但拟合效果很糟糕，比默认的 gbtree 差得多
我唯一想到的就是将训练集中的前两个观察值更改为一些虚构的异常值（例如，我设置 $y_1=0$  和 $y_2=100$），模型肯定不会再看到它来尝试强制这个范围，所以它至少可以考虑值接近这些。尽管在视觉上我没有看到差异，但我使用的所有指标（如 RMSE 和 MAE）仅通过这个简单的修复就得到了很大的改善。然而，该模型仍然在与以前相同的位置上保持平坦

我的问题是：还有其他技术可以尝试解决此问题吗？我的解决方案是否合法？是否允许“外推”？ 
如有任何建议，我们将不胜感激]]></description>
      <guid>https://stats.stackexchange.com/questions/647942/xgboost-does-manipulating-the-sample-make-it-extrapolate</guid>
      <pubDate>Sat, 25 May 2024 04:29:51 GMT</pubDate>
    </item>
    <item>
      <title>Vision Transformer 模型训练和验证准确度停留在 50</title>
      <link>https://stats.stackexchange.com/questions/647941/vision-transformer-model-training-and-validation-accuracy-stuck-at-50</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647941/vision-transformer-model-training-and-validation-accuracy-stuck-at-50</guid>
      <pubDate>Sat, 25 May 2024 04:23:01 GMT</pubDate>
    </item>
    <item>
      <title>在 cox 模型中发现非线性后，我应该如何处理 RCS</title>
      <link>https://stats.stackexchange.com/questions/647937/what-should-i-do-with-rcs-after-finding-non-linearity-in-a-cox-model</link>
      <description><![CDATA[您好，我正在进行 cox 回归分析。
我发现 SAS 上的 RCS 宏我们的变量“收缩压”存在非线性问题。
那么，在这种情况下，我该如何报告结果呢？
我们的主要兴趣不是这个因素。收缩压仅用于多变量 cox 回归分析中的调整。
下面是应用限制三次样条的 cox 回归模型的结果（5 节）
先感谢您！
]]></description>
      <guid>https://stats.stackexchange.com/questions/647937/what-should-i-do-with-rcs-after-finding-non-linearity-in-a-cox-model</guid>
      <pubDate>Sat, 25 May 2024 00:22:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 k=1 的 knn 分类器创建研究论文</title>
      <link>https://stats.stackexchange.com/questions/647936/creating-research-paper-using-knn-classifier-with-k-1</link>
      <description><![CDATA[我正在准备一篇关于使用人工智能和录音来早期检测帕金森病的研究论文。
我现在完成了代码，我创建了一个机器模型来检测帕金森病。我使用的数据集具有 756 个特征。
我无法进行功能选择（删除功能），因为所有功能都很重要。
我开始用许多单一模型训练数据集（分别训练、评估和优化）：cnn 精度 88.16、rnn 精度 84.87、lstm 89.47、svm 82.24、MLP 85.53、Logistic 回归 86.18、LGBM 90.13、knn 84.11 .
然后我对每个模型进行了超参数调整，我发现具有超参数 (n_neighbors=1, p=1) 的 knn 给我带来了准确度 95.39、f1 96.96、召回率 97.32、精度 97.32。
&lt;块引用&gt;
使用默认超参数 (n_neighbors=5, p=2) knn 给出的准确度为 84.11。

然后我对 knn (n_neighbors=1, p=1) 进行了交叉验证 5 倍，它给了我更好的准确度 平均准确度 96.19 +/- 1.14 平均 f1 97.45 +/- 0.76。
然后我用 knn (n_neighbors=1, p=1) 进行装袋，它的准确度为 94.74，
然后我对 BaggingClassifier 进行了超参数调整，发现超参数（max_features=0.37，n_estimators=20）给了我准确度 96.71 f1 97.84
然后我对此 Bagging 进行了交叉验证：knn + CV* 5 倍（max_features=0.37，n_estimators=20），并给了我更好的平均准确度 97.22 +/- 0.78 平均 f1 98.15 +/- 0.52
步骤如下：

第 1 步：knn (n_neighbors=5, p=2)：准确度 84.11 f1 89.66
第 2 步：knn (n_neighbors=1, p=1)：准确度 95.39 f1 96.96
第 3 步：knn (n_neighbors=1, p=1) + 交叉验证 5 倍：平均准确度 96.19 +/- 1.14 平均值 f1 97.45 +/- 0.76。
第 4 步：装袋 + knn (n_neighbors=1, p=1) 准确度 94.74
第 5 步：装袋(max_features=0.37, n_estimators=20) + knn(n_neighbors=1, p=1 ）：精度 96.71 f1 97.84
第 6 步：装袋(max_features=0.37, n_estimators=20) + knn(n_neighbors=1, p=1 ) + 交叉验证 5 倍：平均准确度 97.22 +/- 0.78 平均 f1 98.15 +/- 0.52

这些分数高于之前发表的使用与我使用的相同数据集的研究论文。
问题是我在网上查了一下，发现n_neighbors=1的knn不可靠。
我对之前发表的研究论文进行了广泛的研究，发现了一篇使用knn with k=1的研究论文，并且该研究论文正在接受同行评审]]></description>
      <guid>https://stats.stackexchange.com/questions/647936/creating-research-paper-using-knn-classifier-with-k-1</guid>
      <pubDate>Sat, 25 May 2024 00:18:12 GMT</pubDate>
    </item>
    <item>
      <title>特定人群的生存函数</title>
      <link>https://stats.stackexchange.com/questions/647931/survival-function-for-a-certain-population</link>
      <description><![CDATA[如果某个群体的生存函数由 $$ s(x) = \left( \frac{1}{1+x} \right)^4 $ 给出$ 对于 $x \ge 0$，您预计 $41$ 的人会持续多久能活多少岁？
(a) $14$ 年
(b) $18.5$ 年
(c) $20$ 年
(d) $40$ 年
(e) $42$ 年
我的尝试如下：
$$E\left[X&gt;41\right]=\int _{41}^{\infty }\frac{x}{\left(1+x\right)^ 4}\:dx=\frac{31}{111132}$$
这似乎不正确，请提供任何形式的帮助，谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/647931/survival-function-for-a-certain-population</guid>
      <pubDate>Fri, 24 May 2024 23:11:54 GMT</pubDate>
    </item>
    <item>
      <title>Wishart 密度的积分界限</title>
      <link>https://stats.stackexchange.com/questions/647928/bounds-of-integration-for-the-wishart-density</link>
      <description><![CDATA[我曾经上过一门课程，其中包含无数有关威沙特分布的练习，但据我记得，从未提及威沙特密度。我在这个问题中问了一些关于这个问题的问题，其中我提到了集成可能会很混乱。
回复表示了有关的措施一个积分（在非奇异情况下）是
$$
\prod_{i,j\,:\,1\,\le\,i\,\le\,j\,\le\,p} dx_{i,j}。
$$
我的问题是关于那些“混乱”的问题。整合的界限。
我将进行猜测，看看知道某事的人是否可以证实或否认它，或者（也许是最好的选择）对其进行改进。
我们正在矩阵空间上进行积分$(x_{i,j})_{i,j \, \in\, \{1,\,\ldots, \,p\}}$ 是对称且正定的。
假设这样一个矩阵是
$$
\left[ \begin{array}{cc} \underset{p_1\times p_1} A &amp; \underset{p_1\times p_2} B \\[8pt] \underset{p_2\times p_1}{B^T} &amp; \underset{p_2\times p_2}C \end{array} \right]。
$$
那么 $A$ 和 $C$ 是对称且正定的，且 $B$ 必须使得整个矩阵为正定。
存在这样的一一对应关系：
$$
\left[ \begin{array}{cc} A &amp; B \\[8pt] B^T &amp; C \end{array} \right] \longleftrightarrow \left( \underset{p_1\times p_1} A,\quad \underset{p_2\times p_1} {B^T A^{-1}}, \quad \underset{ p_2\times p_2} {C- B^T A^{-1} B} \right) = (J,K,L)。
$$
因此 $J$ 和 $L$ 是正定的。
这个三元组的第二个组成部分出现在条件期望值的表达式中，第三个组成部分是相应的条件方差。
由此可见
\begin{align}
A&amp; = J，\\
住宿加早餐旅馆= JK^T, \\
C&amp; = L + KJK^T。
\end{对齐}
$(J,K,L)\mapsto(A,B,C)$ 的域是笛卡尔积，其第一和第三因子是所有正数的集合- 适当大小的定对称实矩阵，其第二个因子是（这是有趣的部分）全部 $p_2\times p_1$ 实数矩阵 $K.$ （简单练习：证明这一点。）
因此，我们将积分界限问题简化为较小正定对称实矩阵的积分界限问题，并在矩阵空间上进行积分，其中每个条目的界限为 $-\infty$ 和 $+\infty.$
可以迭代这个过程，直到我们得到 $p=p_1+p_2$ 因子的笛卡尔积，其中每个因子都是  $(0,+\infty),$ 和 $\binom p2$ 因子，每个因子都是 $ (-\infty,+\infty).$
我的问题是：这有用吗？这是标准技术吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647928/bounds-of-integration-for-the-wishart-density</guid>
      <pubDate>Fri, 24 May 2024 23:01:09 GMT</pubDate>
    </item>
    <item>
      <title>当所有数据来自同一个人时相关性的独立性假设</title>
      <link>https://stats.stackexchange.com/questions/647922/independence-assumptions-in-correlations-when-all-data-comes-from-same-individua</link>
      <description><![CDATA[这感觉像是一个愚蠢的问题，但无论如何 - 如果所有数据都来自同一个人并且我不想做出任何更广泛的推论/假设，那么常见相关性测试中的独立性假设是否很重要？
例如：假设我有兴趣知道，对于特定的板球运动员，他们在助跑中的最大跑步速度是否与投球的速度相关，并且我从 1000 个球中获得了数据 - 我可以处理即使球都来自同一名球员，出于相关性分析的目的，这些球也是独立的吗？我只想了解相关玩家的这种关系，而不是对任何更广泛的人群做出推断。]]></description>
      <guid>https://stats.stackexchange.com/questions/647922/independence-assumptions-in-correlations-when-all-data-comes-from-same-individua</guid>
      <pubDate>Fri, 24 May 2024 20:54:30 GMT</pubDate>
    </item>
    <item>
      <title>相对精度公式名称？ n = z²(1-p)/e²p</title>
      <link>https://stats.stackexchange.com/questions/647921/relative-precision-formula-name-n-z%c2%b21-p-e%c2%b2p</link>
      <description><![CDATA[我需要知道我最后一年论文的方法部分中样本量计算的相对精度公式名称（标准化）
$$n = \frac{z^2(1-p)p}{e^2}.$$]]></description>
      <guid>https://stats.stackexchange.com/questions/647921/relative-precision-formula-name-n-z%c2%b21-p-e%c2%b2p</guid>
      <pubDate>Fri, 24 May 2024 20:51:09 GMT</pubDate>
    </item>
    <item>
      <title>如何计算集合预测的估计方差？</title>
      <link>https://stats.stackexchange.com/questions/647919/how-do-i-calculate-estimated-variance-for-an-ensemble-forecast</link>
      <description><![CDATA[基于相同的数据，但使用截然不同的统计模型，我对一个变量有几个（n）个质量相当的不同预测。对于每个预测，我都生成了未来 m 个周期的估计值，使用标准 R 工具为每个预测生成点估计值和置信区间。我希望将这些估计值合并为未来 m 个周期的单点估计值，以及组合点估计值的单个置信区间。
如果这些估计值的误差均通过正态性检验，我倾向于将组合估计值视为 n 个正态变量的平均值，并相应地计算该平均值的点估计值和置信区间。
这是一个合理的方法吗？还有更好的吗？
这是我第一次尝试集成估计，我对文献中的结果几乎一无所知。因此，请毫不犹豫地阐述显而易见的事情]]></description>
      <guid>https://stats.stackexchange.com/questions/647919/how-do-i-calculate-estimated-variance-for-an-ensemble-forecast</guid>
      <pubDate>Fri, 24 May 2024 19:47:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么信度是真实得分方差与总得分方差的比值，而不是真实得分与总得分的比值？</title>
      <link>https://stats.stackexchange.com/questions/647917/why-is-reliability-a-ratio-of-true-score-variance-to-total-score-variance-inste</link>
      <description><![CDATA[可靠性由下式给出：
$r_{xx} = \frac{Var(T)}{Var(X)}$
其中 $T$ 是真实分数，$X$ 是总分。
为什么可靠性不简单：
$r_{xx} = \frac{T}{X}$
其中 $T$ 是所有个人真实分数的总和，$X$ 是是所有个人总分的总和吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647917/why-is-reliability-a-ratio-of-true-score-variance-to-total-score-variance-inste</guid>
      <pubDate>Fri, 24 May 2024 19:14:38 GMT</pubDate>
    </item>
    <item>
      <title>为贝叶斯线性模型中的数据推导条件联合概率模型</title>
      <link>https://stats.stackexchange.com/questions/647915/deriving-a-conditional-joint-probability-model-for-the-data-in-a-bayesian-linear</link>
      <description><![CDATA[我一直在阅读 Tony Lancaster 2004 年出版的书“现代贝叶斯计量经济学简介”。在第 116-117 页，Lancaster 导出了线性模型 $p(y,X|\boldsymbol{\beta})$ 的条件联合分布class=&quot;math-container&quot;&gt;$y=X\boldsymbol{\beta}+\epsilon$ 使用 $X$ 的联合分布和残差，$p(\epsilon, X)$。但他在获得结果的过程中使用的换人似乎并不总是合理的。他们有道理吗？
他从目标开始：给定 $X$ 的情况下，对 $\boldsymbol{\beta}$ 进行后验推理 和 $y$，使用贝叶斯定理
$$p(\boldsymbol{\beta}|y,X)\propto p(y,X|\boldsymbol{\beta})p(\boldsymbol{\beta })$$
这需要导出数据的条件联合分布
$$p(y,X|\boldsymbol{\beta})$$
他的策略是首先获得 $\epsilon$ 和 $X$ 的联合分布，假设 $\epsilon$ 和 $X$ 是独立的，而不仅仅是不相关
$$p(\epsilon, X)=p_{\epsilon}(\epsilon)p(X)$$
他的下一步是使用 $y=X\boldsymbol{\beta}+\epsilon$ 对此联合分布进行替换，然后以 $\boldsymbol{\beta}$，产生所需的条件联合分布
$$p(y,X|\boldsymbol{\beta})=p_{\epsilon}(y-X\boldsymbol{\beta})p(X|\boldsymbol{ \beta})$$
我理解这个结果的右侧，只需使用 $\epsilon=y-X\boldsymbol{\beta}$ 即可。但是左边呢？它不能简单地替换 $y=\epsilon$，因为这没有意义。有人可以帮助我更好地理解这个结果的合理性吗？我错过了一些基本的东西吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647915/deriving-a-conditional-joint-probability-model-for-the-data-in-a-bayesian-linear</guid>
      <pubDate>Fri, 24 May 2024 18:09:37 GMT</pubDate>
    </item>
    <item>
      <title>计算边际效应与 brms 模型的边际效应对比</title>
      <link>https://stats.stackexchange.com/questions/647910/calculating-contrasts-of-marginal-effects-with-marginaleffects-for-brms-model</link>
      <description><![CDATA[我已经使用 brms 拟合了逻辑模型，并希望计算平均边际效应 (AME)。
库(brms)

模型 &lt;- brm(公式 = 结果 ~ var1 + var2 + var3, family = Bernoulli(), data = data)

var1 是分类的，具有两个级别 (1, 0)，var3 是分类的，具有三个级别（“a”、“b”、“0”）。 c”）。 var3 是另一个变量，在计算边际效应时我不想设置/平均其值。
现在，我想计算 var2 每个级别的 var1 的 AME/斜率。 （我不想使用平均协变量 (MEM)。）
库（边际效应）

斜率 &lt;- avg_slopes(
  模型，
  变量=“var1”，
  通过=“var2”
) %&gt;%terior_draws()

这给了我：
 术语对比度 var2 估计 2.5 % 97.5 %
 var1 平均值(dY/dX) a 0.0361 -0.1098 0.1735
 var1 平均值(dY/dX) b 0.0618 -0.0454 0.1666
 var1 平均值(dY/dX) c -0.0788 -0.1667 0.0177

现在，我需要这些对比之间的成对对比。即，a - b、a - c 和 b - c 的估计差异。
我可以像这样手动完成：
slopes_a &lt;- 斜率 %&gt;% 过滤器(var2 == &quot;a&quot;)
lopes_b &lt;- 斜率 %&gt;% 过滤器(var2 == &quot;b&quot;)
lopes_c &lt;- 斜率 %&gt;% 过滤器(var2 == &quot;c&quot;)

df &lt;- data.frame(
  `a - b` =lopes_a$draw-slopes_b$绘制，
  `a - c` =lopes_a$draw-slopes_c$绘制，
  `b - c` =lopes_b$draw-slopes_c$绘制
）

这是一种有效的方法吗？是否有更好/更好的方法，例如直接使用 marginaleffects 包？]]></description>
      <guid>https://stats.stackexchange.com/questions/647910/calculating-contrasts-of-marginal-effects-with-marginaleffects-for-brms-model</guid>
      <pubDate>Fri, 24 May 2024 16:50:10 GMT</pubDate>
    </item>
    <item>
      <title>期望的建议：通过多级模型预测美国龙卷风数量</title>
      <link>https://stats.stackexchange.com/questions/647861/advice-desired-predicting-us-tornado-counts-via-multi-level-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647861/advice-desired-predicting-us-tornado-counts-via-multi-level-model</guid>
      <pubDate>Fri, 24 May 2024 03:07:14 GMT</pubDate>
    </item>
    <item>
      <title>了解 Chinchilla 复制研究中的 Log-Sum-Exp (LSE) 运算符，e 是集合还是 exp？</title>
      <link>https://stats.stackexchange.com/questions/647669/understanding-the-log-sum-exp-lse-operator-in-chinchilla-replication-study-is</link>
      <description><![CDATA[我正在尝试了解 Log-Sum-Exp (LSE) 运算符在 Chinchilla 复制研究中的使用，特别是论文“Chinchilla Scaling：一种复制尝试”中引用的运算符。贝西罗格鲁等人（2024）。在该研究中，LSE 用于损失参数模型的拟合过程。不过，e似乎并不是作为自然对数的标准底，而是作为参数的一组初始值。
为什么 e 是一组值 {-1, =0.5, ..., 1} 而不是 Chinchilla 复制研究中 LSE 运算符上下文中的标准指数函数？ p&gt;
上下文：
Chinchilla复制论文定义参数模型和拟合过程如下：
$$
L(N,D) = E + A N^{-\alpha} + B D^{-\beta}
$$
在龙猫复制研究中，LSE函数的使用如下：
$[
\min_{a,b,e,\alpha,\beta} \sum_{\text{Run } i} \text{Huber}_\delta \left( \text{LSE}(a \alpha \log N_i, b \beta \log D_i, e) - \log L_i \right)
]$
这里，LSE不是传统的log-sum-exp，而是将这些对数项与参数结合起来的函数
𝑒
e 从集合 {-1, -0.5, ..., 1} 初始化
为什么会有差异？
在这项具体研究中，e 用作从一组值初始化的参数，以优化拟合过程。这与 log-sum-exp 函数中 e 的传统用法不同，其中 e 是自然对数的底数。 e 的集合 {-1, -.5, ..., 1} 的选择允许研究人员探索不同的初始化并找到模型的最佳参数。
我希望这有助于阐明 e 在龙猫复制研究中的使用。如果您还有其他问题或需要更多详细信息，请告诉我！
&lt;小时/&gt;
将 numpy 导入为 np
从 scipy.optimize 导入最小化
从 sklearn.metrics 导入mean_squared_error

# 定义参数模型
def model_loss(N, D, E, A, alpha, B, beta):
    返回 E + (A / (N ** alpha)) + (B / (D ** beta))

# 定义Huber损失函数
def huber_loss(delta, pred, 实际):
    diff = np.abs(预测值 - 实际值)
    return np.where(diff &lt; delta, 0.5 * diff ** 2, delta * (diff - 0.5 * delta))

# 示例数据（N：模型大小，D：训练标记数量，L：观察到的损失）
数据 = [
    {&#39;N&#39;：1e6，&#39;D&#39;：1e9，&#39;L&#39;：2.0}，
    {&#39;N&#39;：1e7，&#39;D&#39;：1e10，&#39;L&#39;：1.5}，
    # 根据需要添加更多数据点
]

# 将数据转换为 numpy 数组
N = np.array([d[&#39;N&#39;] for d in data])
D = np.array([d[&#39;D&#39;] for d in data])
L = np.array([d[&#39;L&#39;] for d in data])

# 定义优化目标函数
def 目标（参数）：
    E、A、alpha、B、beta = 参数
    L_pred = model_loss(N、D、E、A、α、B、β)
    返回 np.sum(huber_loss(0.1, L_pred, L))

# 初始参数网格
参数网格 = {
    ‘E’: [0, 0.5, 1],
    ‘A’: [100, 200, 300],
    “阿尔法”：[0.3，0.5，0.7]，
    ‘B’: [1000, 2000, 3000],
    “测试版”：[0.3，0.5，0.7]，
    ‘e’: [-1, -0.5, 0, 0.5, 1]
}

# 执行网格搜索
最佳参数 = 无
最佳损失 = 浮动（&#39;inf&#39;）
对于 param_grid[&#39;E&#39;] 中的 E：
    对于 param_grid[&#39;A&#39;] 中的 A：
        对于 param_grid[&#39;alpha&#39;] 中的 alpha：
            对于 param_grid[&#39;B&#39;] 中的 B：
                对于 param_grid[&#39;beta&#39;] 中的 beta：
                    对于 param_grid[&#39;e&#39;] 中的 e：
                        参数 = (E, A, alpha, B, beta)
                        损失=目标（参数）
                        如果损失&lt;最佳损失：
                            最佳损失 = 损失
                            最佳参数 = 参数

print(&quot;最佳参数：&quot;, best_params)
print(&quot;最佳损失：&quot;, best_loss)

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/647669/understanding-the-log-sum-exp-lse-operator-in-chinchilla-replication-study-is</guid>
      <pubDate>Tue, 21 May 2024 04:37:11 GMT</pubDate>
    </item>
    <item>
      <title>理解分数实验中的“乘法/群运算”</title>
      <link>https://stats.stackexchange.com/questions/643907/understanding-multiplication-group-operation-in-fractional-experiments</link>
      <description><![CDATA[在我试图理解的分数阶乘设计中，至少有一种群运算。为了确定性，假设我们有 3 个因素； A、B、C，各两个级别。请批评我的理解。我们假设效应稀疏，因此复合 ABC 是微不足道的。然后我们以某种方式设置 ABC=1。这1到底是什么？我们是否以某种方式“乘以”？或者将 A 与 B、C 组合以获得这个 1？我们可以单独围绕这个关系和别名定义一个乘法，其中等号的列是等效的吗？
编辑：我假设“1”代表一个无关紧要的结果，其他关系是通过别名给出的，即组合对（抱歉，我在这里在精确的术语上画了一个空白）如果它们的列被认为是相等的对于每个列条目来说都是相等的，例如 AB=C。就是这样，还是还有更多，比如正式的数学描述？]]></description>
      <guid>https://stats.stackexchange.com/questions/643907/understanding-multiplication-group-operation-in-fractional-experiments</guid>
      <pubDate>Sat, 30 Mar 2024 14:41:31 GMT</pubDate>
    </item>
    </channel>
</rss>