<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 02 Aug 2024 03:18:54 GMT</lastBuildDate>
    <item>
      <title>确保我正确地规范化了我的数据</title>
      <link>https://stats.stackexchange.com/questions/652191/making-sure-im-normalizing-my-data-appropritely</link>
      <description><![CDATA[我（实际上）正在评估分拣机的准确性。为简单起见，假设我有 10 个箱子。每天，都会将随机数和各种物品放入机器并进行分类。有时机器不准确，因此为了测试其准确性，我会从每个箱子中抽取随机数量的物品。在这样做的同时，我会记录我评估的物品数量以及错误分类的物品数量。此外，在分类结束时，我会计算当天每种类型的物品应该分拣到每个箱子中的实际分布。
我现在要做的第一件事是获取样本中评估的物品总数，并找出错误物品占总数的百分比。这是原始的、未加权的准确性计算。在现实世界中，它对于故障排除很有用，所以我想保留这些数据。
但我还想建立一个加权系统。例如，如果 50% 的对象被分类到容器 1 中，2% 的对象被分类到容器 4 中，但容器 4 中错误分类的对象更多，那么按理说，这些错误分类的对象的整体权重应该小于正确分类到其中的对象更多的容器。将这种逻辑推广到数百万个已排序的对象，一个容器对准确性的影响应该比另一个容器更大，这是有道理的。
我想要做的是确保我正确地对这些容器进行加权。目前，我正在这样做：
（容器、采样对象、错误分类的对象、实际分布）：
（1、4、0、14%）；
（2、6、0、10%）；
（3、3、1、14%）；
（4、2、0、11%）；
（5、8、0、13%）；
(6, 7, 0, 7%);
(7, 1, 2, 8%);
(8, 15, 1, 12%);
(9, 12, 0, 4%);
(10, 6, 0, 7%);
给定样本数据，如果我想对这些箱子进行归一化，我目前正在执行以下操作：
将采样对象乘以实际分布，将错误排序的对象乘以实际分布，将这些新的相应值相加并重新计算百分比。
这合理吗？还是我在做一些统计上愚蠢的事情？]]></description>
      <guid>https://stats.stackexchange.com/questions/652191/making-sure-im-normalizing-my-data-appropritely</guid>
      <pubDate>Fri, 02 Aug 2024 01:52:35 GMT</pubDate>
    </item>
    <item>
      <title>随机森林和 bagging 中的概率预测与聚合而非投票计数：寻求文献/现有研究</title>
      <link>https://stats.stackexchange.com/questions/652189/probability-predictions-in-random-forest-and-bagging-with-aggregating-not-a-vote</link>
      <description><![CDATA[通常，在整个 bagging 或随机森林集合中，类别概率是通过 投票计数 方法确定的。在该集合中，每棵树都会根据终端节点中的多数类别进行类别预测。设 $T$ 为树的总数，$b_t$ 为集合中的 $t$ 棵树。让 $\mathbb{I}(b_t(x_i) = A)$ 成为指示函数，当 $b_t$ 预测观测 $x_i$ 属于类 $A$ 时，该函数返回 $1$。观测 $x_i$ 属于类 $A$ 的概率计算如下：
$$
\Pr(x_i = A) = \frac{1}{T} \sum_{t=1}^{T} \mathbb{I}(b_t(x_i) = A)。
$$
另一种方法是，为每个 $b_t$ 计算概率预测，然后在整个集合中取平均值。看来，这种方法在 Python 中的 RandomForestClassifier.predict 中使用。虽然我是使用 randomForest 的 R 用户。在数学中，这是：
$$
\Pr(x_i = A) = \frac{1}{T} \sum_{t=1}^{T} \Pr(b_t(x_i) = A)。
$$
我的问题是，我在寻找每种方法相对性能的证据。理想情况下，模拟研究可以帮助我理解这一领域。我四处寻找，但我找不到任何东西。从有限的阅读中我得出的直觉是，每个 CART 模型的概率预测都很差，以至于它们的总体对概率的估计很差。
提前感谢互联网]]></description>
      <guid>https://stats.stackexchange.com/questions/652189/probability-predictions-in-random-forest-and-bagging-with-aggregating-not-a-vote</guid>
      <pubDate>Fri, 02 Aug 2024 01:12:11 GMT</pubDate>
    </item>
    <item>
      <title>对异性恋和同性恋感到困惑。我真的不知道这张图显示了什么</title>
      <link>https://stats.stackexchange.com/questions/652188/confused-about-heterosked-and-homosked-i-really-cant-tell-what-this-graph-sho</link>
      <description><![CDATA[因此，我正在使用大约 13 年期间某些股票的股票数据，现在我想检查 stata 上的异方差和自相关。我已经绘制了残差与拟合值的关系图，并得到了这个，但我真的不知道这里发生了什么。我最初想对异方差进行 Beusch-pagan 或白检验，但潜在的自相关可能会影响这些测试的结果。有谁眼力好，可以告诉我这里是否有异方差吗？此外，目视检查就足够了吗？或者，我还应该求助于任何统计测试，因为仅通过查看图表可能并不总是能清楚地看出情况。非常感谢您的帮助！谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652188/confused-about-heterosked-and-homosked-i-really-cant-tell-what-this-graph-sho</guid>
      <pubDate>Fri, 02 Aug 2024 01:11:41 GMT</pubDate>
    </item>
    <item>
      <title>假设 $Z_i$ 是独立同分布的。$N(0, 1).$ 且令 $M_n = max\{Z_1, \ldots, Z_n\}$，表明 $P(M_n > t) \leq n(1 - \Phi(t))$</title>
      <link>https://stats.stackexchange.com/questions/652187/suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n-sho</link>
      <description><![CDATA[证明 $P(M_n &gt; t) \leq n(1 - \Phi(t))$
我的工作：
\begin{align}
P(M_n &gt; t) &amp;\leq P(\cup_{i=1}^n (Z_i &gt; t))\leq \sum_{i=1}^n P(Z_i &gt; t)= n(1 - \Phi(t))
\end{align
以上是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/652187/suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n-sho</guid>
      <pubDate>Thu, 01 Aug 2024 22:30:21 GMT</pubDate>
    </item>
    <item>
      <title>比较半结构化嵌套文本数据中主题流行度检测的无监督方法</title>
      <link>https://stats.stackexchange.com/questions/652184/comparing-unsupervised-approaches-to-topic-prevalence-detection-in-semi-structur</link>
      <description><![CDATA[我试图理解（理想情况下，概率上）检测半结构化嵌套文本数据中潜在主题的普遍性的方法。具体来说，似乎至少有两种方法（如下所述）使用无监督学习/主题模型来完成这项任务，我想知道这两种方法的缺点/优点。
“半结构化嵌套文本数据”示例
假设数据是一组关于 N 个不同公司的 N 份报告（父文档）。每份报告包含一组要点（子文档），每份要点由 1-3 个句子组成 - 即推文长度。如果需要，我们可以假设每个要点映射到 1 个潜在主题（例如，公司的成本），但该主题可以在报告内和报告之间出现多次（使用不同的词语）。最后，要点的数量和主题因报告而异。因此，不同的报告经常讨论类似的主题，但有些报告可能会讨论更多或独特的主题。
这是一个带有括号中潜在主题的玩具数据示例：

还有一个快速图表，显示主题和项目符号的数量在不同的报告中可能有所不同：

识别和检测的方法主题
方法 1：将数据展平到每份报告的一列，然后使用报告作为文档与多成员主题模型
数据示例：


连接报告中的所有要点，以便每份报告都包含一个大段文字。
使用流行度参数拟合多标签概率模型（例如结构主题模型（BERTopic）来识别主题和流行度。
使用主题流行度参数将报告分配给（一个或多个）主题。

问题：主题流行度是一个概率单纯形，因此例如，一份显然包含 3 个主题的文档将为每个主题分配 0.33 的概率，为其他主题分配 0 的概率。因此，流行度仅告诉我们哪些主题最有可能相对于其他主题，但并未告诉我们绝对概率。
方法 2：将数据加长，然后使用项目符号作为文档，公司名称作为多成员主题模型中主题流行度的预测指标
数据示例：


汇集所有报告中的所有项目符号，以便项目符号被视为文档。
使用与报告关联的公司，将主题模型（例如 STM）与文档相匹配（元数据）作为主题流行度协变量。
使用公司与主题之间关联的系数作为主题相对流行度的衡量标准。

问题：所有系数均相对于平均流行度，因此您只能知道某些公司与主题流行度的相关性更强……您不知道某个主题是否在所有报告中均有提及。]]></description>
      <guid>https://stats.stackexchange.com/questions/652184/comparing-unsupervised-approaches-to-topic-prevalence-detection-in-semi-structur</guid>
      <pubDate>Thu, 01 Aug 2024 21:50:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么弹性网络不能像 lm 那样处理缺失数据？</title>
      <link>https://stats.stackexchange.com/questions/652183/why-doesnt-elastic-net-handle-missing-data-the-way-lm-does</link>
      <description><![CDATA[在 R 中进行计算时，我有一些玩具数据，并尝试使用 glmnet 来拟合弹性网络模型。我注意到，即使只有一个缺失值，算法也不会执行，建议事先估算缺失值。
# 设置可重复性的种子
set.seed(123)

# 生成一个 100x5 的随机数矩阵
data_matrix &lt;- matrix(rnorm(100*5), nrow=100, ncol=5)
data_df &lt;- as.data.frame(data_matrix)
data_df[1:1, 3] &lt;- NA # 单个缺失值
# 生成一个包含 100 个观测值的向量 Y，每个观测值为 1、2 或 3
Y &lt;- sample(1:3, 100, replace=TRUE)
glmnet::cv.glmnet(x = as.matrix(data_df),
y = as.matrix(Y),
alpha = 0.5,
family = &quot;multinomial&quot;)
glmnet(x, y, weights = weights, offset = offset, lambda = lambda, 中的错误：
x 有缺失值；考虑使用 makeX() 来估算它们

从算法上讲，当有缺失值时，是什么原因导致弹性网络不适合？相反，当使用 lm 并且有缺失值时，
ctl &lt;- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,NA)
trt &lt;- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group &lt;- gl(2, 10, 20, labels = c(&quot;Ctl&quot;,&quot;Trt&quot;))
weight &lt;- c(ctl, trt)
lm.D9 &lt;- lm(weight ~ group)

代码运行无任何错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/652183/why-doesnt-elastic-net-handle-missing-data-the-way-lm-does</guid>
      <pubDate>Thu, 01 Aug 2024 21:42:45 GMT</pubDate>
    </item>
    <item>
      <title>正态分布概率密度函数与累积分布函数之比</title>
      <link>https://stats.stackexchange.com/questions/652176/ratio-of-normal-pdf-to-cdf</link>
      <description><![CDATA[我想证明
$$\Bigl\lvert \frac{\phi(a)}{\Phi(a)} - \frac{\phi(b)}{\Phi(b)} \Bigr\rvert \leq |a-b|$$
其中 $\phi$ 是标准正态 pdf，而 $\Phi$ 是标准正态 cdf。]]></description>
      <guid>https://stats.stackexchange.com/questions/652176/ratio-of-normal-pdf-to-cdf</guid>
      <pubDate>Thu, 01 Aug 2024 20:06:38 GMT</pubDate>
    </item>
    <item>
      <title>残差与拟合图显示周期性模式。我从 300 个解释变量中选择了 5 个。我应该添加更多变量还是冒着过度拟合的风险？</title>
      <link>https://stats.stackexchange.com/questions/652174/resids-vs-fitted-plot-shows-cyclical-patterns-i-have-chosen-5-explanatory-varia</link>
      <description><![CDATA[我根据其他属的相对丰度预测 1 个属 (A) 的相对丰度。我随意选择了 5 个似乎最有可能有帮助的属（我所有重复实验中随时间推移最丰富的 5 个属），但我的社区总共有 300 多个属。我使用相同的方法预测了 2 个细菌属和 2 个真核生物属的丰度。
除了残基与拟合值之外，诊断结果看起来都很好，并且该模型在预测未来数据方面表现得出奇的好。
我正在写一篇文章，想说的是，虽然残差与拟合值显示出拟合不足的迹象，并且添加其他属很可能有助于预测，但仅包含这 5 个物种使我们能够相当准确地预测随时间的变化。
该建模不是我文章的核心，目的不是预测现实世界中发生的现象，而是一个探索性过程，只是看看是否可以预测属的相对丰度变化。这种思路在发表的文章中会成立吗？


使用包 mvgam 在 R 中建模]]></description>
      <guid>https://stats.stackexchange.com/questions/652174/resids-vs-fitted-plot-shows-cyclical-patterns-i-have-chosen-5-explanatory-varia</guid>
      <pubDate>Thu, 01 Aug 2024 19:31:37 GMT</pubDate>
    </item>
    <item>
      <title>降维以实现高维流的可视化</title>
      <link>https://stats.stackexchange.com/questions/652173/dimensionality-reduction-for-visualization-of-high-dimensional-flows</link>
      <description><![CDATA[我的问题是如何最好地可视化高维空间中的动态流。以下是所有详细信息：

我已经训练了一个 RNN (GRU) $f(x, u)$，其中包含 50 个单元来执行连续控制任务。我认为这与我的问题不太相关，但具体任务是在二维空间中对牛顿点质量施加力，使其从初始位置的静止移动到目标位置的静止。
就这个问题而言，没有系统噪音。
任务的每个情节持续 100 个时间步（RNN 单元的迭代），并产生 50 维的网络状态轨迹（即形状为 (100, 50) 的数组）。
网络的输入 $u$ 是 1）点质量的目标位置和速度，它们在一个情节期间保持不变，以及 2）关于环境状态的反馈（即点质量的当前位置和速度），它会随时间变化。
我一直在使用 FixedPointFinder 来查找 RNN 的固定点 (FP)。该方法通过使用 RNN 演化一组候选状态 $x_{\mathrm{c},i}$ 直到成本函数 $(f_u(x_{\mathrm{c},i})-x_{\mathrm{c},i})^2$ 低于某个容差，然后排除任何重复项等。请注意，$u$ 对于此操作是固定的 - RNN 的每个输入向量都定义了一个不同的动态系统，可能具有不同的 FP。
对于此任务，对于给定的网络输入向量通常只有一个 FP，我假设这个问题就是这种情况。
我一直在通过将隐藏的轨迹和 FP 投影到前 2 个主要成分上来可视化它们。我将主向量拟合到整个隐藏轨迹批次，然后重新使用这些向量来转换其他所有内容（例如 FP）。
几乎所有的方差都被前 4-5 个 PC 捕获。

我想可视化 RNN 对固定输入 $u$ 的动态流。我目前的方法是这样的：

在 PC 空间（2D）中生成一个规则的点网格 $x_{\mathrm{g},i}$，并将其投影到状态空间（50D）中。
计算 $f_u(x_{\mathrm{g},i})-x_{\mathrm{g},i}$；这些是状态演化向量。
将向量投影回 PC 空间并使用 quiver 进行绘制。

对于轨迹的每个时间步，我存储 RNN 实际收到的输入向量。因此，我在情节的每个时间步找到一个 FP 和一个向量场——即 100 个 FP 和 100 个向量场的轨迹。
但是：

在 PC 空间中，结果向量场的 2 范数的最小值（即最短的 2 向量）与 FP 并不完全一致，也投影到 PC 空间中。我认为这是有道理的，因为投影到前 2 个 PC 不会保留来自状态空间的 50 个向量的长度。
状态空间中向量场的 2 范数的最小值（最短的 50 个向量）随后投影到 PC 空间，确实与 FP 对齐，但仅在试验的开始和结束时对齐。我发现这更令人困惑，因为我不认为这是由于 PCA 造成的，我无法想象为什么向量场$f(x)-x$ 范数的最小值不会与最小化 $(f(x)-x)^2$ 的状态对齐。我曾经认为，这种差异是由于网格投影到状态空间后变得稀疏造成的，但这很难用我目前的方法进行测试，因为当我试图将常规网格扩大到正确覆盖 50D 空间时，内存会耗尽。

这两种效果都可以在以下 PC 空间中单集的动画中看到：

有没有更好的方法可以在 2D 或 3D 中可视化高维空间中的流空间？
我怀疑有一件事会起作用，那就是在 50D 空间中生成流线，这些流线是点而不是矢量，应该至少像 FP 一样投射到 PC 空间中。
我也很高兴了解我的方法的其他局限性。
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652173/dimensionality-reduction-for-visualization-of-high-dimensional-flows</guid>
      <pubDate>Thu, 01 Aug 2024 18:59:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么在零假设中包含最小实际效应大小不是标准？</title>
      <link>https://stats.stackexchange.com/questions/652168/why-is-it-not-standard-to-include-minimum-practical-effect-size-in-null-hypothes</link>
      <description><![CDATA[我是统计学新手。在假设检验中，通常使用 $\theta = \theta_0$ 形式的零假设，这让我感到困惑。在我看来，在许多情况下，我们感兴趣的不是确切的相等性，而是 $|\theta - \theta_0|&lt; \delta$，其中 $\delta$ 的某个阈值使 $\theta$ 和 $\theta_0$ 之间的差异具有实际意义。
有没有研究人员以这种方式制定零假设的例子？为什么这种情况并不常见？]]></description>
      <guid>https://stats.stackexchange.com/questions/652168/why-is-it-not-standard-to-include-minimum-practical-effect-size-in-null-hypothes</guid>
      <pubDate>Thu, 01 Aug 2024 18:00:07 GMT</pubDate>
    </item>
    <item>
      <title>根据非分层变量进行细分</title>
      <link>https://stats.stackexchange.com/questions/652166/breakdown-with-respect-to-a-non-stratification-variable</link>
      <description><![CDATA[假设我有一个关于某国企业投资的研究。假设企业按员工人数分层：三个层级 $s_1$，从 $1$ 到 $9$ 名员工，$s_2$，从 $10$ 到 $49$ 名员工，以及 $S_3$，从 $\ge 50$ 名员工。我们采取分层简单随机抽样。总投资的公式为 $$ I= N_1\overline i_1+N_2\overline i_2+ N_3\overline i_3$$
其中 $N_j$ 是 $s_j$ 层中的企业总数，$\overline i_j$ 是从 $s_j$ 层中抽取的 $n_j$ 个企业的平均投资。
现在为简单起见，假设总体中的企业只有两种工业活动，$A_1$ 和 $A_2$。我想按活动部门细分上述总投资，这意味着 $I=I_1+I_2$，其中 $I_1$ 是活动的总投资 $A_1$，$I_2$ 也是类似情况。既然我从一开始就没有将活动部门作为分层变量，那么如何做到这一点？在选择样本之前，是否强制性将细分变量 $x$ 作为分层变量来细分任何与任何变量相关的总投资？]]></description>
      <guid>https://stats.stackexchange.com/questions/652166/breakdown-with-respect-to-a-non-stratification-variable</guid>
      <pubDate>Thu, 01 Aug 2024 17:28:55 GMT</pubDate>
    </item>
    <item>
      <title>什么是最好的统计分析方法来分析不同代谢物随时间（时间 0、24 和 48 小时）的显著差异</title>
      <link>https://stats.stackexchange.com/questions/652164/what-is-the-best-statistical-analysis-to-analyse-significant-differences-in-diff</link>
      <description><![CDATA[我有 40 种不同的代谢物，我测量了它们在 0、24 和 48 小时时的浓度。我想知道每种代谢物是否随着时间的推移存在显著差异。我对代谢物之间是否存在差异并不感兴趣。我考虑对每种代谢物进行单向 Anova 重复测量 + Tukey 检验。所以最后我会得到 40 种不同的分析（Anova + Tukey）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652164/what-is-the-best-statistical-analysis-to-analyse-significant-differences-in-diff</guid>
      <pubDate>Thu, 01 Aug 2024 17:05:23 GMT</pubDate>
    </item>
    <item>
      <title>因式分解定理是否证明 PDF 的最简单因式分解是最具信息量的？</title>
      <link>https://stats.stackexchange.com/questions/652163/does-the-factorization-theorem-prove-that-the-simplest-factorization-of-the-pdf</link>
      <description><![CDATA[让我将因式分解定理表述为：存在 PDF 因式分解，其中 $X$ 仅通过 $T(X)$ 依赖于参数，证明 $T(X)$ 是充分的，定义为从 $X$ 传达最大可能的参数信息。其证明（或我找到的所有版本）显示了如何将 PDF 分解为两个组件的简单乘积，一个组件独立于参数，另一个组件仅通过 $T(X)$ 依赖于参数。
这只是代数，仅证明了以下陈述：“某些 PDF 可以以这种方式进行因式分解。”然后，证明从定义上强加了 $T(X)$ 是充分的。它似乎依赖于一个直观上吸引人但在数学上没有道理的假设：PDF 的各个因子的信息不能超过它们的集体信息。这个假设没有考虑到，更不用说排除了另一种可能性：可能存在将最简单的因式分解划分为许多因子的情况，其中一些或所有因子单独有条件地增加了 $T(X)$ 的信息，但集体抵消了。让我来举例说明。
Basu (1964) 表明，对于具有总体相关性 $\rho$ 的双变量正态样本 $(X, Y)$，$X$ 和 $Y$ 分别具有辅助性，但联合起来是充分的（尽管显然不是最小充分的）。在这个特殊情况下，条件推理是不可能的，即 $r|X$ 和 $r|Y$ 都不比充分统计 Pearson 的 $r$ 更具信息量。但我们能证明不存在这样的例子吗？难道我们不应该证明 FT 成立吗？
结果是，从多项式中提取因子是基本的代数，否则会抵消$-$，例如，因子与其倒数的乘积，或相反符号的相等加数。FT 不应该驳斥这种可能性吗？如果不是，那它不就是一个公理吗？还是我的逻辑有缺陷？请记住我的例子仅供说明：证明反例的负担不在我身上，而是在 FT 身上，以证明不存在反例。]]></description>
      <guid>https://stats.stackexchange.com/questions/652163/does-the-factorization-theorem-prove-that-the-simplest-factorization-of-the-pdf</guid>
      <pubDate>Thu, 01 Aug 2024 17:04:04 GMT</pubDate>
    </item>
    <item>
      <title>我构建 SIRD 模型并将其拟合到真实 COVID 数据的代码存在什么问题？</title>
      <link>https://stats.stackexchange.com/questions/652178/what-is-the-problem-with-my-code-for-building-and-fitting-an-sird-model-to-real</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652178/what-is-the-problem-with-my-code-for-building-and-fitting-an-sird-model-to-real</guid>
      <pubDate>Thu, 01 Aug 2024 12:30:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么 sem() 与 lavaan 和 lm() 中的线性回归结果不同？</title>
      <link>https://stats.stackexchange.com/questions/652138/why-different-results-for-linear-regression-in-sem-from-lavaan-and-lm</link>
      <description><![CDATA[感谢您阅读本文。
我是一名学生，正在尝试更多地了解社会科学问题的统计数据。我试图在 R 中建立 {lavvan} 中的 sem() 函数和 {stats} 中的 lm() 函数之间的等价性，以进行具有一个结果和一个预测变量的简单线性回归，这两个预测变量都不是潜在变量。但是，即使我可以为模型获得相同的参数估计值，无论我使用哪个估计器，估计的标准误差都会略有不同。下面附上一个例子：
#加载库
library(lavaan)

#创建数据框
set.seed(1231)
n &lt;- 100 #观察值数量

X &lt;- rnorm(n, mean = 50, sd = 10)
Y &lt;- rnorm(n, mean = 65, sd = 8)

df &lt;- data.frame(X, Y)

#使用 lm() 函数
lm &lt;- lm(Y ~ X, data = df)
summary(lm)

#使用 lavaan 的 sem() 函数
model_sem &lt;- &#39;Y~X&#39;
sem &lt;- sem(model_sem, estimator = &quot;ML&quot;, se = &quot;standard&quot;, data = df)
summary(sem, nd = 7)

当前示例的结果：

来自 lm() 输出

 估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 67.30819 4.37739 15.38 &lt;2e-16
X -0.04116 0.08571 -0.48 0.632 


来自 sem() 输出

回归：
估计 Std.Err z 值 P(&gt;|z|)
Y ~ 
X -0.0411622 0.0848524 -0.4851035 0.6276029

参数估计相等，但参数的 SE 和 p 值略有不同。我还使用 {stats4} 中的 vcov() 函数检查了两个模型的方差-协方差矩阵。
vcov(lm)[c(&quot;X&quot;),c(&quot;X&quot;)]
[1] 0.00734687
vcov(sem)[c(&quot;Y~X&quot;),c(&quot;Y~X&quot;)]
[1] 0.007199932

我尝试手动计算 lm() 输出中的方差-协方差矩阵并成功完成。但是，我找不到从 sem() 中提取观察到的（或预期的）信息矩阵或计算 lavaan 文档中使用的对数似然函数的函数。在这种特定情况下，是否有可能实现两者之间的等价性？为什么（我哪里做错了）或者为什么不（有什么区别，是模型估计和规范还是仅仅是因为包）？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652138/why-different-results-for-linear-regression-in-sem-from-lavaan-and-lm</guid>
      <pubDate>Thu, 01 Aug 2024 09:22:58 GMT</pubDate>
    </item>
    </channel>
</rss>