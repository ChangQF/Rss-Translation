<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 29 Jan 2024 12:23:54 GMT</lastBuildDate>
    <item>
      <title>积分函数</title>
      <link>https://stats.stackexchange.com/questions/638012/integral-function</link>
      <description><![CDATA[我们如何找到这个积分的封闭形式？
\begin{align}
f_X(x) = \int_{0}^{\infty} \frac{\theta^{a+2}}{\theta^2+1} e^{-\theta(x+b)} \ d\西塔
\end{对齐}]]></description>
      <guid>https://stats.stackexchange.com/questions/638012/integral-function</guid>
      <pubDate>Mon, 29 Jan 2024 12:16:03 GMT</pubDate>
    </item>
    <item>
      <title>共有 N 名患者，以了解某个频率的精确度，并具有不同的 FU 时间</title>
      <link>https://stats.stackexchange.com/questions/638011/total-n-patients-for-precision-around-a-rate-with-varying-fu-times</link>
      <description><![CDATA[我们必须设计一项回顾性纵向研究，以评估开始治疗后特定事件的发生情况。根据之前的研究，我们估计年化率为 0.06%，即 0.0006/人年（被低估，因为它给出了中位 FU 为一年的 n/N 比例，并且他们发现 13 名患者/2000 名患者平均随访 1 年）年，不包括经常性事件）。从这个出发，在封装预设大小的情况下，比例为 0.0006，宽度为 0.0015，估计 N=5320（Wilson 的），但是对于比率（我们的目标是对所有事件进行计数） ）它给出（速率 0.0006，相同宽度）我们需要 4 个事件，时间 = 5741（我想是年）。问题是，这不是一项前瞻性研究，因此我们需要考虑之前研究中 FU（平均治疗时间）的分布。如果所有患者都接受一年的随访，则没有任何优势（除了不计入复发事件的实际发生率肯定更高这一事实之外）。但是，如果我们得到“右偏” FU时间分布，例如15％的患者FU时间为0-0.5年（我们可以取平均值），25％的平均FU（暴露）时间为5-1年，其余患者移动在 1-2 年的范围内，它将对总样本量产生积极影响，因为我们需要招募更少的患者，对吧？我知道我们严重依赖假设，但对于回顾性研究，描述性的 N学习更多的是预算问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/638011/total-n-patients-for-precision-around-a-rate-with-varying-fu-times</guid>
      <pubDate>Mon, 29 Jan 2024 11:55:37 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAMLSS 进行密度预测</title>
      <link>https://stats.stackexchange.com/questions/638009/density-forecasts-with-gamlss</link>
      <description><![CDATA[有人知道 GAMLSS 包中创建密度预测的函数吗？
预测。公式不正确。预测点预测]]></description>
      <guid>https://stats.stackexchange.com/questions/638009/density-forecasts-with-gamlss</guid>
      <pubDate>Mon, 29 Jan 2024 11:10:19 GMT</pubDate>
    </item>
    <item>
      <title>更改 OLS 协方差矩阵中的主对角线元素使其成为非正半定</title>
      <link>https://stats.stackexchange.com/questions/638008/changing-main-diagonal-elements-in-ols-covariance-matrix-makes-it-non-positive-s</link>
      <description><![CDATA[考虑多元 OLS 估计量的分布：
$\hat{\beta} \stackrel{a}{\sim} \mathcal{N}(\beta, \sigma^2_{\varepsilon}(X&#39;X)^{-1}) $
$\sigma^2_{\varepsilon}$ 是模型残差的方差。
在 (X&#39;X)^{-1}  中，K 个回归量包含在 TxK 矩阵 X 中。
考虑一下这个的计算
将 numpy 导入为 np
x = np.array([[ 6.69799079e-05, 4.47900075e-03, 1.11295513e-02,
        -1.53​​410612e-03、-7.80042874e-03、-5.48828405e-04、
         5.34882257e-03],
       [-2.42506772e-03、1.95076992e-03、-2.76252607e-03、
         2.51163809e-03、-1.29685770e-04、-4.08666327e-04、
        -2.06069156e-04],
       [-9.01853148e-03、1.06805603e-03、-5.68196220e-03、
        -1.58341294e-03、-5.19719531e-04、-1.99096555e-03、
         1.33736638e-02],
       [-1.67686831e-02、1.03756219e-03、-3.09389017e-03、
        -5.82072860e-04、2.45141310e-03、4.23810200e-03、
        -1.04367638e-02],
       [-2.14967470e-03、-1.25276346e-03、8.45706966e-03、
         4.37734736e-03、3.06680473e-04、-5.45079650e-03、
        -7.63559836e-03],
       [ 3.51869582e-03，-8.54104584e-05，2.37355588e-03，
         2.27264507e-03、1.48825104e-03、7.66788949e-04、
        -4.96569702e-03],
       [-1.46948850e-02、-5.84091411e-03、2.67041460e-03、
         7.43433669e-03、-1.71753337e-03、-5.21116327e-03、
        -2.37710797e-02],
       [ 1.08986135e-04，-5.52135816e-03，1.05926302e-02，
         2.85870694e-03、6.74379333e-03、-4.82313521e-04、
        -2.38578052e-02],
       [5.81675409e-03，-9.05253451e-04，5.26505940e-03，
         8.04235863e-03、4.24832362e-03、-2.14712311e-03、
        -9.39914616e-03],
       [-2.49679983e-03，-5.57820624e-03，-1.04127823e-02，
         7.02632088e-04、1.91906586e-03、4.21699091e-03、
        -1.09022326e-02],
       [-8.10825107e-04、-3.21445037e-03、1.14912833e-02、
         1.19578375e-02、-6.81409748e-03、-9.33450269e-03、
        -1.90224184e-02],
       [-1.41592285e-02、-2.37424822e-05、-5.24191507e-03、
        -7.51260381e-03、-3.67436542e-04、4.46313907e-03、
         1.16752528e-02],
       [7.71038146e-03，-1.15729877e-03，6.23115882e-03，
         3.41204766e-03、-3.44834472e-03、-9.94597394e-03、
         9.42412011e-03],
       [-1.35253318e-03、6.10927311e-06、-2.90810278e-04、
        -8.93350225e-04、2.88348652e-03、-1.22831804e-03、
        -4.03440159e-03],
       [ 1.22283674e-02，-3.29613191e-03，7.64826948e-03，
        -1.60845738e-03、-4.37492225e-03、-8.13727061e-04、
        -5.11397030e-03],
       [6.47683914e-03、2.23891270e-03、-3.20663860e-03、
        -1.31661777e-03、1.31306496e-03、3.79381577e-03、
         7.56946850e-03],
       [ 4.91868407e-03，-8.99366452e-04，7.29657836e-05，
        -2.58961303e-03、1.00195797e-03、1.52800194e-03、
        -1.59591138e-03],
       [ 3.90906674e-03，-1.07016349e-03，-6.12236067e-04，
        -4.35170012e-03、1.11034849e-03、-2.68078641e-03、
         5.85990669e-04],
       [-6.24055633e-03、-2.63707255e-03、2.91037728e-03、
         2.33373897e-03、-6.65416524e-03、-2.19221012e-03、
        -1.28810378e-02]])

sigma = 0.003 # $\sigma^2_{\varepsilon}$ 的虚构值

我计算beta的方差协方差矩阵：
covmat = x.T @ x
beta_var = np.linalg.inv(covmat) * sigma

这是正半定：np.all_close(np.linalg.eigvals(beta_var)&gt;0) 
现在假设我想使用样本第一部分的 x 方差来计算 beta 的协方差矩阵。这意味着从主对角线取出元素并在 covmat 中替换它们。换句话说，我想看看协方差矩阵在 x 的方差对应于样本第一部分 (:13) 但协方差（主对角线以外的项）的情况下如何变化x 的各个列是完整示例的列：
new_var = np.diag(x.iloc[:13, :].T @ x.iloc[:13, :])
np.fill_diagonal(covmat, new_var)
beta_var2 = np.linalg.inv(covmat) * sigma

现在这不是更正的半定：np.all_close(np.linalg.eigvals(beta_var2)&gt;0) 
请注意，我仅更改主对角线上的元素，因为我想保留固定的协方差元素（非对角线）。为什么 beta_var2 只需将主对角线元素更改为严格正值，就会变成非正半定？如何操作这种类型的更改以确保矩阵保持半正定？]]></description>
      <guid>https://stats.stackexchange.com/questions/638008/changing-main-diagonal-elements-in-ols-covariance-matrix-makes-it-non-positive-s</guid>
      <pubDate>Mon, 29 Jan 2024 11:09:38 GMT</pubDate>
    </item>
    <item>
      <title>谱图表示方法仅限于单个图结构意味着什么？</title>
      <link>https://stats.stackexchange.com/questions/638007/what-does-it-mean-for-spectral-graph-representation-methods-to-be-limited-to-a-s</link>
      <description><![CDATA[我正在尝试更深入地了解图神经网络的主题。最近在阅读这篇论文时，我发现了这样的说法：使我困惑。作者指出，谱方法仅限于“单一图结构”，而空间方法则不然。
&lt;块引用&gt;
上述的一个限制[参考2] 光谱公式是它们依赖于
图拉普拉斯的固定谱，因此仅适用
对于具有单一结构的图（以及顶点上不同的信号）。
相反，空间表述并不局限于固定的
图结构。

谁能给我解释一下这是什么意思吗？这个限制到底是什么？ GCN（作为谱图卷积的一个实例（？））是否会受到此影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/638007/what-does-it-mean-for-spectral-graph-representation-methods-to-be-limited-to-a-s</guid>
      <pubDate>Mon, 29 Jan 2024 11:03:41 GMT</pubDate>
    </item>
    <item>
      <title>如何统计检验两个1的和</title>
      <link>https://stats.stackexchange.com/questions/638006/how-to-statistically-test-two-sums-of-1s</link>
      <description><![CDATA[我有以下向量：
vec_1=c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1)
vec_2=c(1,1,1,1,1,1,1,1,1)

从中我计算出相应的总和：
&lt;前&gt;&lt;代码&gt;&gt;打印（总和（vec_1））
[1] 18
&gt;打印（总和（vec_2））
[1] 9

有没有办法测试这两个总和是否有统计差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/638006/how-to-statistically-test-two-sums-of-1s</guid>
      <pubDate>Mon, 29 Jan 2024 10:47:35 GMT</pubDate>
    </item>
    <item>
      <title>连续预测器的推荐系统</title>
      <link>https://stats.stackexchange.com/questions/638001/recommender-system-for-continuous-predictors</link>
      <description><![CDATA[我想构建一个能够预测用户与客户端交互结果的模型。
我知道对于分类变量来说，分解机是一个不错的选择。
想象一下，例如我们正在谈论人们与电影互动：人们的分类变量是年龄、性别、种族等，而对于电影来说，它可能是发行年份、类型、主要演员……
在我的例子中，客户端和用户都使用实数向量而不是 calcategori 变量进行编码，如下所示：

用户1：[0.5，1.2，1.5]
用户2：[0.9、1.3、1.7]
...
客户端1：[0.1，0.4，0.7]
客户端2：[0.2，0.5，0.7]
...

我有大多数交互的数据：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

用户
客户端
结果变量 (Y)


&lt;正文&gt;

用户1
客户端1
2.4


用户1
客户端2
2.9


用户2
客户端1
1.9


用户2
客户端2
2.2




我想预测对于没有测量 Y 的用户-客户端对，交互的结果会是什么。
这正是 FM 可以很好地工作的地方，但不同之处在于我使用连续变量作为用户和客户端的描述符，并且据我了解这些算法并不意味着处理这些数据。
我说得对吗？
您知道在这种情况下运行良好的算法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638001/recommender-system-for-continuous-predictors</guid>
      <pubDate>Mon, 29 Jan 2024 10:21:33 GMT</pubDate>
    </item>
    <item>
      <title>哪个数据子集应该用于可解释机器学习 (IML)？</title>
      <link>https://stats.stackexchange.com/questions/638000/which-data-subset-should-be-used-for-interpretable-machine-learning-iml</link>
      <description><![CDATA[在机器学习工作流程中，我们需要将数据集分为训练集和测试集。我们在训练集上训练几个候选模型（通常通过超参数优化进行调整），然后选择在测试集上评估时表现最佳的模型。这样，性能评估可以最大限度地减少训练子集的过度拟合。
最终，我想使用可解释的机器学习 (IML) 技术来解释模型，例如累积的局部效应 ( ALE）。这是我的问题：使用 IML 分析数据时，我们应该使用哪个模型和数据子集？以下是我正在考虑的各种候选选项：

在训练集上训练的最佳模型，IML 仅分析训练集
在训练集上训练的最佳模型，并且 IML 仅分析测试集
在完整数据集（训练+测试数据）上训练的最佳模型，IML 仅分析训练集
在完整数据集（训练+测试数据）上训练的最佳模型，IML 仅分析测试集
在完整数据集（训练 + 测试数据）上训练的最佳模型，并通过 IML 分析完整数据集（训练 + 测试数据）

我希望得到一个合理的答案，解释为什么哪个子集适合训练以及哪个子集适合 IML 数据分析。]]></description>
      <guid>https://stats.stackexchange.com/questions/638000/which-data-subset-should-be-used-for-interpretable-machine-learning-iml</guid>
      <pubDate>Mon, 29 Jan 2024 10:02:54 GMT</pubDate>
    </item>
    <item>
      <title>计数数据回归的误差度量：泊松偏差还是均方误差？</title>
      <link>https://stats.stackexchange.com/questions/637999/error-metric-for-regression-of-count-data-poisson-deviance-or-mean-square-error</link>
      <description><![CDATA[我想了解，如果我使用均方误差或泊松偏差作为计数数据回归的误差度量/损失函数，会产生什么差异。是否有任何先验或理论上的原因让我们更喜欢一种指标而不是另一种指标？
背景
我确实有一个很大的计数数据数据集（即事件和暴露的数量），具体取决于各种协变量。我想将各种模型（经典 GLM 以及机器学习模型）拟合到该数据集并评估它们的质量。我的主要目标是根据协变量对分布的条件均值进行点预测。相应的比率通常很小（比如 0 到 10% 之间），并且在许多情况下观察到的事件为零。我没有任何特定领域的原因（例如成本函数）来选择我的错误度量，并且我对推理不太感兴趣（还）。此刻，我只想要一个“最好的”。预测，无论这意味着什么。
据我了解，我应该选择一个“适当的评分函数”为条件均值。我进一步了解到均方误差和泊松偏差都满足这个要求。
我的问题

除了适当的均值评分函数之外，我还应该注意其他要求吗？
是否还有其他相关指标可以（或应该）用于评估预测的质量？
与其他指标相比，更喜欢泊松偏差或均方误差等一种误差指标的可能原因是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/637999/error-metric-for-regression-of-count-data-poisson-deviance-or-mean-square-error</guid>
      <pubDate>Mon, 29 Jan 2024 09:57:27 GMT</pubDate>
    </item>
    <item>
      <title>两组 VS 的单向方差分析。 t检验</title>
      <link>https://stats.stackexchange.com/questions/637997/one-way-anova-for-two-groups-vs-t-test</link>
      <description><![CDATA[比较 2 个组 (K=2) 时，我们可以执行单向方差分析的 t 检验或 f 检验，因为 f 检验等于 t 检验平方 (t^2 = f) ，它本质上具有相同的阻力，对吧？
只有两组我们才能有方向假设（单尾），但是如果我在 t 检验中使用 alpha=0.05，我将不得不使用 ANOVA alpha=0.1。
我想知道这是为什么？
功效怎么可能与 t 检验保持相同？
为什么显着水平没有改变？]]></description>
      <guid>https://stats.stackexchange.com/questions/637997/one-way-anova-for-two-groups-vs-t-test</guid>
      <pubDate>Mon, 29 Jan 2024 09:26:51 GMT</pubDate>
    </item>
    <item>
      <title>荟萃分析：使用多级分析的估计值来估计偏相关系数</title>
      <link>https://stats.stackexchange.com/questions/637996/meta-analysis-estimating-partial-correlation-coefficients-using-estimates-from</link>
      <description><![CDATA[如果有人能够提供一些想法或指出使用多级分析的估计来计算偏相关系数 (PCC) 的相关文献，我将非常感激。
目前，我们正在进行一项荟萃分析，该分析利用多个回归模型的数据，并使用 PCC 作为常见的效应大小指标。因此，对于我们的荟萃分析中包含的每个相关系数估计，我们正在估计 PCC。我们的荟萃分析中包含的一些模型来自多层次分析。我们感兴趣的预测因子处于 1 级，结果测量也是如此。
估计 PCC 的常规公式如下（Stanley and Doucouliagos 2012）：
r=t/sqrt(t²+df)，其中 t 是回归系数的 t 统计量，df 是自由度。
为了估计 PCC，我们使用 R 中 metafor 包中的 escalc 函数。使用此函数，必须提供预测变量的数量、总样本大小和t 统计量作为输入。
考虑到多级模型中自由度的计算与单级回归中应用的自由度不同，我们有点不确定使用多级模型估计来估计 PCC 的正确方法。特别是，我想知道在从多级模型估计 PCC 时，我们应该为 mi 参数（预测变量总数）提供什么数字。我们应该取 1 级和 2 级预测变量的总和吗？在指定此参数时，我们是否应该考虑 2 级单元的数量？当系数估计完全来自多级模型时，也许escalc不适合计算PCC？
任何帮助将不胜感激 - 非常感谢您的宝贵时间。]]></description>
      <guid>https://stats.stackexchange.com/questions/637996/meta-analysis-estimating-partial-correlation-coefficients-using-estimates-from</guid>
      <pubDate>Mon, 29 Jan 2024 09:08:24 GMT</pubDate>
    </item>
    <item>
      <title>使用复杂度惩罚进行正则化</title>
      <link>https://stats.stackexchange.com/questions/637995/regularization-using-complexity-penalty</link>
      <description><![CDATA[我目前正在阅读墨菲，我遇到了正则化
我面临的问题是在他们使用的复杂性惩罚背后建立直观的感觉 
登录我之前的信念会如何惩罚模型的过度拟合？]]></description>
      <guid>https://stats.stackexchange.com/questions/637995/regularization-using-complexity-penalty</guid>
      <pubDate>Mon, 29 Jan 2024 09:04:59 GMT</pubDate>
    </item>
    <item>
      <title>数据集中在原点的拟合回归</title>
      <link>https://stats.stackexchange.com/questions/637994/fitting-regression-where-data-is-concentrated-at-the-origin</link>
      <description><![CDATA[我正在进行一项探索性数据分析，研究中文书写的许多字符级特征。我目前正在研究的关联是角色的复杂性（离散）和估计的习得年龄（连续）之间的关联。原始形式的数据如下所示：

根据我的观察，数据似乎首先是在原点附近生成的，变成一个弱相关的大椭球体，然后向右篡改。鉴于此信息，我考虑了以下选项：

常规 OLS：这根本不起作用。它大大高估了数据应该在的位置。
无截距线性模型：因为数据起源于原点 $[0,0]$ 我认为是抑制截距，但这似乎难以置信，因为某人在获取单词时不可能年龄为零，而且复杂性得分也可能为零，所以我放弃了这个想法。
GAM：我使用了各种 GAM 拟合，最佳拟合似乎是自适应平滑，但它似乎仍然高估了原点附近的数据。不过，就捕获分布的其余部分而言，这通常仍然可以完成工作。
多项式回归：我通常不喜欢用它们来进行非线性回归，但这似乎可以最好地捕获我关心的分布的左下部分。残留诊断似乎也相当不错。我在这里看到的唯一问题是它在回归线最右侧的插值效果有点差。
泊松或 beta 回归：DV 只能采用 1 或更大的值。但是，因为数据是连续的，所以我认为它在这里不起作用。我也尝试过 beta 回归（通过将数据转换为比例），但模型看起来就是错误的。

以下是四种候选拟合，看起来至少接近现实。

多项式拟合的残差如下所示。残差明显呈带状，并且在某些区域聚集更多，但我认为通常它们看起来并不可怕：


多项式回归在这里效果最好还是其他方法更好？我会注意到这个数据集有数千个值，因此它在散点图中的椭圆体中间聚集了很多。
编辑
过滤接近原点的值 (AoA &lt;= 2)，绘图如下所示（带有自动生成的 LOESS 线）：

编辑2
至于上下文：AoA 是个位数，应该是对中国人最初学习一个字符的时间的估计（这是一种主观的自我回忆测量）。评级基于单个字符的各个主题的平均值，因此采用小数单位。例如，3个人可能记得他们分别在6岁、7岁、7岁的时候学过“我”，平均6.67岁左右。因此，这里的年龄不太可能高于典型的幼儿年龄。
对于周界复杂度，它通常是连续的，公式为：
$$
\frac{P^2}{A 4 \pi}
$$
其中 $P$ 是字符墨迹空间的周长，$A$ 是区域，而 $\pi$ 就是字面上的 $\pi$。但不幸的是，在这个数据集中，它被四舍五入了，我无法取回那些小数值。至于分布的异常情况，我主要担心的是分布的中心要重得多（这里有 3600 多个 obs，以防不清楚），因此分布的外部回归线的权重相当不均匀。我还想在这里平衡模型简约性，因此摆脱过于复杂的多项式将是理想的选择。]]></description>
      <guid>https://stats.stackexchange.com/questions/637994/fitting-regression-where-data-is-concentrated-at-the-origin</guid>
      <pubDate>Mon, 29 Jan 2024 08:56:17 GMT</pubDate>
    </item>
    <item>
      <title>隐马尔可夫模型的数据缩放？</title>
      <link>https://stats.stackexchange.com/questions/637992/data-scaling-for-hidden-markov-models</link>
      <description><![CDATA[我知道扩展数据对于某些机器学习算法很重要，而且这个想法很有意义。我在这里找到了关于流程的精彩描述 https://ourcodingclub.github。 io/tutorials/data-scaling/#Scaling。
我一直在运行隐马尔可夫模型（使用 depmixs4）来解决生态问题。我的问题是数据扩展对于 HMM 有多重要？我尝试过搜索文献，但很少有案例表明数据在 HMM 之前已经进行了缩放。对于生态来说根本没有。
我错过了什么吗？ HMM 不需要数据缩放吗？或者它们可以处理未缩放的数据吗？我在标准 HMM 指南中找不到任何关于此 i 的提及。
对于我的模型，我有四个不同测量值的变量，这些变量不是正态分布的。我计划转换数据，然后适当扩展。使用类似变量的论文根本没有提到数据缩放。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/637992/data-scaling-for-hidden-markov-models</guid>
      <pubDate>Mon, 29 Jan 2024 08:08:36 GMT</pubDate>
    </item>
    <item>
      <title>Neyman-Pearson 检验：交换主要假设和替代假设以确保 P(I 型) < P(II 型)</title>
      <link>https://stats.stackexchange.com/questions/637991/neyman-pearson-testing-swapping-the-main-and-alternative-hypotheses-to-ensure-p</link>
      <description><![CDATA[我一直在阅读假设检验，并意识到我误解了一些东西，这使我将 Fisher 的 p 值与 Neyman-Pearson 的关键区域混合在一起。我要改变这种情况，所以我一直在读。一件事的重要性我很清楚，但我似乎找不到如何实现它的例子，所以我请求你的帮助。
假设我从事控制良好的生产流程，生产的零件具有一些可测量的质量方面$Q = \mu_r$，按标准差呈正态分布$\sigma_r$。我正在调查一项更改，我怀疑该更改会增加 $Q = \mu_t &gt;; \mu_r$，不改变标准差。我可以根据经济论证轻松估计最小效应大小 $\delta$。我会计划一个单样本 t 检验。我刚刚学会用主假设 $H_M$ 替换旧的零假设，并在语句中显式添加最小效应大小，因此我们有：
$$
H_M:\mu_t-\mu_r \le 0 \pm \delta \\
H_t:\mu_t-\mu_r &gt; 0 + δ
$$
这看起来与我以前的零假设类似，我选择 $\alpha$ 和 $\beta$ span&gt; 并计算所需的样本量 $n$。但这让我想到了一些我从未完全理解的事情，但我认为我现在走在正确的轨道上。下面我请求大家朝正确的方向稍微推动一下。
在我的日常工作中有（很多）情况，未能发现真正改进的机会成本超过了我在错误拒绝的路径上浪费的工作成本$H_M$。这提示我设置 $\beta &lt; \alpha$，我不应该这样做。这一直让我很困惑。然而，我读到 Neyman-Pearson 建议了一个简单的解决方案：我必须交换我的假设（这是主要的，也是替代的）。这实际上是完全有道理的，只是我不太清楚我会如何做到这一点。假设是什么样的，我将如何进行测试？
我被“宠坏”了根据我之前的训练，我必须取消其中的一些内容，然后重新学习这些内容。所以我可能想太多了。是简单地交换不等式符号并采用 t 检验的另一条尾部的问题吗？如果是这样，为什么 $\mu_t$ 可能大于 $\delta$ 不是问题，而我们将 $\mu_r$ 视为“已知”？]]></description>
      <guid>https://stats.stackexchange.com/questions/637991/neyman-pearson-testing-swapping-the-main-and-alternative-hypotheses-to-ensure-p</guid>
      <pubDate>Mon, 29 Jan 2024 08:00:07 GMT</pubDate>
    </item>
    </channel>
</rss>