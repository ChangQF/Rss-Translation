<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 11 Sep 2024 03:17:51 GMT</lastBuildDate>
    <item>
      <title>RSPM 服务器上的 MPN 快照更新，需要使用 pkgr 安装包</title>
      <link>https://stats.stackexchange.com/questions/654182/mpn-snapshot-update-on-rspm-server-need-to-install-packages-using-pkgr</link>
      <description><![CDATA[我们需要帮助在我们的 RSPM 服务器上安装以下软件包。

BayesPostEst
rstanarm
starwarsdb
duckdb
tidyposterior

作为 RSPM 软件包更新的一部分，我们正在尝试安装最新的 MPN Snapshot 并运行 pkgr 脚本。虽然我能够安装 1302 个最新的 MPN 软件包，但剩下 5 个以上的软件包。
当我尝试运行“pkgr install”命令时，它既没有安装软件包，也没有给出任何错误，让我永远等待。
我尝试将这 5 个软件包一起安装，也尝试在 pkgr.yml 文件中单独安装。
请对此提出建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/654182/mpn-snapshot-update-on-rspm-server-need-to-install-packages-using-pkgr</guid>
      <pubDate>Wed, 11 Sep 2024 02:11:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么似然理论如此关注于解决得分函数方程？</title>
      <link>https://stats.stackexchange.com/questions/654181/why-is-so-much-of-likelihood-theory-focused-on-solving-the-score-function-equati</link>
      <description><![CDATA[当我第一次学习最大似然估计时，有人告诉我应该检查$\frac{d}{d\theta}\text{log}(L(\theta;x_1,...,x_n)) = 0$的解是否真的是最大似然估计量；这意味着检查它是否真的是最大值，这相当于检查二阶导数，并检查对数似然在参数空间边界的行为。
然而，过了一段时间，教授和教科书开始只关注解决$\frac{d}{d\theta}\text{log}(L(\theta;x_1,...,x_n)) = 0$。我们不需要检查任何其他东西，我们只需要解那个方程。那么为什么我们不需要检查$\frac{d}{d\theta}\text{log}(L(\theta;x_1,...,x_n)) = 0$的解是否真的是最大似然估计量？我们什么时候需要检查？]]></description>
      <guid>https://stats.stackexchange.com/questions/654181/why-is-so-much-of-likelihood-theory-focused-on-solving-the-score-function-equati</guid>
      <pubDate>Wed, 11 Sep 2024 01:56:33 GMT</pubDate>
    </item>
    <item>
      <title>如何创建一个整合分类和数值变量（例如行为类型及其相应的持续时间）的组合指数？</title>
      <link>https://stats.stackexchange.com/questions/654180/how-can-i-create-a-combined-index-that-integrates-categorical-and-numerical-vari</link>
      <description><![CDATA[我想开发一种方法来创建一个统一的指标，将不同的行为（例如，“看电视”= 1，“锻炼”= 2，“做饭”= 3）与其各自的持续时间（例如 10 分钟、20 分钟、30 分钟）结合起来。该指数应有效捕捉行为的分类性质及其定量方面，从而可以全面分析模式和相关性。]]></description>
      <guid>https://stats.stackexchange.com/questions/654180/how-can-i-create-a-combined-index-that-integrates-categorical-and-numerical-vari</guid>
      <pubDate>Wed, 11 Sep 2024 01:36:21 GMT</pubDate>
    </item>
    <item>
      <title>具有点数据和连续数据的线性回归[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654179/linear-regression-with-point-data-and-continuous-data</link>
      <description><![CDATA[问题 - 对于与点数据关联的连续数据，将使用哪种类型的回归或其他统计技术？
数据 - 我的数据是针对经过连续加工线和批处理的产品。我的 Y 变量是通过长度的，保持通过长度看到的可变性很重要。我想对数据集进行分析，而不对连续数据取平均值或复制作为点值的批处理数据。此应用程序的正确统计方法是什么？
感谢您的帮助。我希望这很清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/654179/linear-regression-with-point-data-and-continuous-data</guid>
      <pubDate>Wed, 11 Sep 2024 00:28:47 GMT</pubDate>
    </item>
    <item>
      <title>大都会-黑斯廷斯提案分布乘以标量。这会对黑斯廷斯比率产生什么影响？</title>
      <link>https://stats.stackexchange.com/questions/654178/metropolis-hastings-proposal-distribution-multiplied-by-scalar-how-does-this-af</link>
      <description><![CDATA[因此，如果我从 Q~Dirichlet(theta_i * tau) 中提出 theta*，其中 tau 是某个标量，那么 Hastings 比率是否需要考虑该标量，即
Dirichlet(theta_i|(theta*) * tau) / Dirichlet(theta*|theta_i * tau)？
或者我应该从 Hastings 比率中删除 taus？我查看了 MH 算法的证明，但这一点对我来说不是立即清楚的。提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654178/metropolis-hastings-proposal-distribution-multiplied-by-scalar-how-does-this-af</guid>
      <pubDate>Tue, 10 Sep 2024 23:34:32 GMT</pubDate>
    </item>
    <item>
      <title>何时适合在重复测量混合模型中包含随机截距？</title>
      <link>https://stats.stackexchange.com/questions/654172/when-is-it-appropriate-to-include-random-intercepts-in-repeated-measures-mixed-m</link>
      <description><![CDATA[我有一个问题，即何时适合使用随机截距。我有一个重复测量实验，其中包含 4 种处理方法。每种处理方法在温室中的行中各出现一次（块 = rep）。数据是从 PLOT 中的 10 株植物（不同编号）中收集的，持续 13 周。如果我给块一个随机截距，我会得到非常不同的结果。

如果我给块一个随机截距，我会得到非常不同的结果：
PROC GLIMMIX DATA=AVG initglm pconv=1e-4 plots=residualpanel; 
CLASS PLOT REP TRT WK;
MODEL XWF = TRT|WK / dist=negbin link=log ddfm=kr2/*将其用于重复测量*/;
随机截距/subject=REP;
随机 REP / subject=PLOT;
随机 WK / type=ar(1) subject=PLOT residual;
LSMEANS TRT|WK/ linesslicediff=WK ilinkadjust=Tukey plots=meanplot (cl join);
RUN;


PROC GLIMMIX DATA=AVG initglm pconv=1e-4 plots=residualpanel; 
CLASS PLOT REP TRT WK;
MODEL XWF = TRT|WK / dist=negbin link=log ddfm=kr2/*用于重复测量*/;
随机 REP / subject=PLOT;
随机 WK / type=ar(1) subject=PLOT residual;
LSMEANS TRT|WK/ 线slicediff=WK ilink adjust=Tukey 图=meanplot (cl join);
RUN;

]]></description>
      <guid>https://stats.stackexchange.com/questions/654172/when-is-it-appropriate-to-include-random-intercepts-in-repeated-measures-mixed-m</guid>
      <pubDate>Tue, 10 Sep 2024 21:38:55 GMT</pubDate>
    </item>
    <item>
      <title>在元分析中处理多种类型的数据依赖性时应使用什么方法？</title>
      <link>https://stats.stackexchange.com/questions/654171/what-approach-to-use-when-dealing-with-multiple-types-of-data-dependency-in-a-me</link>
      <description><![CDATA[我正在做单变量荟萃分析和 TSSEM 分析，使用计划行为理论和相关系数作为效应大小，但不知道在处理数据中的多种依赖关系时哪种方法最好。您能否向我解释一下我可以使用哪些选项？
在约 80 项研究中，在 10 项研究中，作者对同一研究中的多个独立样本进行了研究（主要来自不同国家，但不仅限于此）。如果我没记错的话，这些效应大小不是相互依赖的，而是属于 Konstantopoulos2011 聚类数据结构的示例。
在另外 2 项研究中，作者研究了同一样本的不同行为结果（例如，盗版音乐、盗版软件和盗版电影）。
另一项研究仅分别提供了与男性和女性相关的相关系数和样本量，但没有报告整个样本的效应大小。
因此，我有三个效应大小依赖来源，但只针对少数研究。
我（理论上）熟悉这些情况，可以利用：平均、三级荟萃分析、稳健方差估计、相关和分层效应 (CHE)。
我从 OSF 获得了几篇文章和 r 脚本，但在我看来，大多数只处理数据依赖性的个别原因。
我可以使用三级荟萃分析吗？即使我没有考虑在几项基于同一样本报告多个结果的研究中观察到的效应的抽样误差依赖性，考虑到研究中 90% 的依赖性遵循聚类/层次结构？
你能给我一些建议吗？
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/654171/what-approach-to-use-when-dealing-with-multiple-types-of-data-dependency-in-a-me</guid>
      <pubDate>Tue, 10 Sep 2024 21:37:47 GMT</pubDate>
    </item>
    <item>
      <title>PCA 是否可以最大化投影数据点之间的成对平方距离？</title>
      <link>https://stats.stackexchange.com/questions/654159/does-pca-maximize-pairwise-squared-distance-between-projected-data-points</link>
      <description><![CDATA[我们有一个点数据集 $x_i$，其中 $x_i \in \mathbb{R}^n$。如果我们对保留 $k$ 个分量的数据集进行 PCA，则投影到 $k$ 个分量上的结果点 $y_i \in \mathbb{R}^k$ 将最大化向量与均值的平方距离（即 PCA 最大化保留的方差）。如果平均值$\bar{x}=0$，则 PCA 最大化范数平方和$\sum_i \|y_i \|^2$。
直观地讲，最大化点到平均值的总平方距离$\sum_i \|y_i - \bar{y} \|^2$似乎与最大化点之间的成对平方距离$\sum_i \sum_j \|y_i - y_j \|^2$有关。我尝试通过代入 $\bar{y} = \frac{1}{n}\sum_j y_j$ 来查看这两个“目标”是否等价，但得到的公式并不相同，因此目标并不等价。因此，PCA 似乎并没有最大化点之间的成对平方距离。
首先，我想知道在什么条件下最大化 $\sum_i \|y_i - \bar{y} \|^2$ 和 $\sum_i \sum_j \|y_i - y_j \|^2$ 这两个目标可能会重合（即导致相同的解决方案）。其次，我想知道是否存在一些已知的降维方法来最大化成对平方距离而不是方差。
编辑：尝试证明$\sum_i \|y_i - \bar{y} \|^2$和$\sum_i \sum_j \|y_i - y_j \|^2$并不相同：
$$\sum_i \|y_i - \bar{y} \|^2 =
\sum_i \|y_i - \frac{1}{n}\sum_j y_j\|^2 = \frac{1}{n^2}\sum_i \|\sum_j \left( y_i - y_j \right)\|^2 
$$
如果我们可以将$\sum_j$置于平方范数之外，则方差公式将成比例。但似乎我们不能：
$$\|\sum_j \left( y_i - y_j \right)\|^2 =
\langle \sum_j \left( y_i - y_j \right), \sum_k \left( y_i - y_k \right) \rangle = \\
\sum_j \|y_i - y_j \|^2 + 2 \sum_{j \neq k} \langle \left( y_i - y_j \right), \left( y_i - y_k \right) \rangle
$$
我可能遗漏了一些东西，但我不明白为什么术语$\sum_{j \neq k} \langle \left( y_i - y_j \right), \left( y_i - y_k \right) \rangle$ 应该为 0，因为方差和成对平方距离必须相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/654159/does-pca-maximize-pairwise-squared-distance-between-projected-data-points</guid>
      <pubDate>Tue, 10 Sep 2024 14:23:27 GMT</pubDate>
    </item>
    <item>
      <title>通过python进行线性混合效应模型分析</title>
      <link>https://stats.stackexchange.com/questions/654156/linear-mixed-effect-model-analysis-via-python</link>
      <description><![CDATA[我想对我的研究进行线性混合效应分析。我试图了解和比较 3 种不同的干预模式对结果的影响。我对结果有 2 个衡量指标，即事前分析和事后分析。
我使用 Python 代码，但当我将其与 SPSS 结果进行比较时，结果大不相同。我想知道我是否使用了正确的代码。
这是我的变量
DV：ACC
IV：组（3），时间（2）
协变量：性别，年龄，受教育年限。
性别，组和时间是分类变量。
我使用了下面的代码
model = smf.mixedlm(
&quot;ACC ~ C(Time) * C(Group) + Age + C(Sex) + Education years&quot;, 
data, 
groups=data[&quot;ID&quot;]
)
result = model.fit()

您觉得如何？我应该做些改变吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654156/linear-mixed-effect-model-analysis-via-python</guid>
      <pubDate>Tue, 10 Sep 2024 13:34:28 GMT</pubDate>
    </item>
    <item>
      <title>可以对多项研究的标准差取平均值以用于样本量计算吗？</title>
      <link>https://stats.stackexchange.com/questions/654048/can-standard-deviations-from-multiple-studies-be-averaged-to-use-for-a-sample-si</link>
      <description><![CDATA[想象一下，您正在计划一项临床试验，以评估一种新疗法对改善慢性中风患者 VO2peak 的有效性。根据 Jin 等人的初步研究，您使用 Jin 等人报告的 VO2peak 方差估计试验所需的样本量。
来自 Jin 等人的数据：

VO2peak 的标准差 (SD)：2.5 ml/kg/min
估计样本量：每组 40 名参与者

但是，您后来发现，您的试点研究中的 SD 远高于 Jin 等人的估计值。
来自其他研究的数据：

DaCun：SD = 10 ml/kg/min
Mac：SD = 15 ml/kg/min
Len：SD = 20 ml/kg/min
Ive：SD = 18 ml/kg/min
Glob：SD = 25 ml/kg/min

修订方法：
现在，您不再仅仅依赖 Jin 等人的 SD 估计值，而是包括来自这些其他研究的数据：

来自其他研究的平均 SD：(10 + 15 + 20 + 18 + 25) / 5 = 17.6 ml/kg/min

修订样本量计算：使用这个更高的平均 SD，您可以计算出一个新的样本量估计值。


结果：

新的样本量估计值：每组 80 名参与者（基于更高的平均 SD）

这是计算样本的可接受方法吗尺寸？]]></description>
      <guid>https://stats.stackexchange.com/questions/654048/can-standard-deviations-from-multiple-studies-be-averaged-to-use-for-a-sample-si</guid>
      <pubDate>Sun, 08 Sep 2024 17:52:41 GMT</pubDate>
    </item>
    <item>
      <title>具有 [0,1] 中连续权重的随机块模型</title>
      <link>https://stats.stackexchange.com/questions/653746/stochastic-blockmodel-with-continuous-weights-in-0-1</link>
      <description><![CDATA[我想使用随机块模型 (SBM) 对网络中的节点进行聚类，其中边权重是 0 到 1 之间的连续数字。似乎 blockmodels 和 SBM 等 R 软件包为权重提供了伯努利、泊松和高斯分布。高斯是唯一提供的连续分布（在我查看过的软件包中），但我的权重分布为众数为 0（最小值），一些权重恰好为零（可能不是问题，因为似乎允许不存在边），而其他权重从众数为零向上严重倾斜分布。我确实知道 SBM 中的高斯模型并不一定意味着权重必须整体呈高斯分布，因为它可以是社区内和社区之间的不同高斯的混合，但似乎仍然没有办法将两个或几个高斯的混合放在一起来模拟我所拥有的权重分布。此外，我很惊讶地发现边缘权重首先是高斯分布，因为在我知道的几乎所有情况下，权重都被限制为正，而高斯分布将质量放在整个实线上（当然，它有时仍然是正数据的良好近似值）。对于我所拥有的权重分布类型，任何拟合的高斯都会将相当大的概率质量放在负侧。
在这种情况下该怎么办？无论如何都要拟合高斯模型？是否有任何版本的 SBM 实现假设其他分布，例如指数或 Beta？如果可能的话，我是否应该将权重转换为“接近高斯”？
更一般地说，我是否正确理解了高斯假设适用于原始权重（分别在社区之间和社区内），而不是某些潜在变量或允许强非高斯权重的东西？我发现很难找到对连续权重的 SBM 的全面解释。另外，对我来说似乎很奇怪，唯一可用于连续数据的模型似乎是一种作为标准生成负值的模型，而实际上我所看到的只是权重被限制为非负值。]]></description>
      <guid>https://stats.stackexchange.com/questions/653746/stochastic-blockmodel-with-continuous-weights-in-0-1</guid>
      <pubDate>Mon, 02 Sep 2024 14:01:31 GMT</pubDate>
    </item>
    <item>
      <title>三角相关？</title>
      <link>https://stats.stackexchange.com/questions/653518/triangular-correlations</link>
      <description><![CDATA[正如我在 https://stats.stackexchange.com/a/652022/11887 上的回答中所使用的，三角相关似乎是一个有用的概念/术语，可以得到更多的使用。但搜索后我发现它没什么用，下面是一些例子。也许还有其他术语在使用？一些文献中的例子：


这是学生课程成绩与（y 轴）缺课率的关系，似乎缺课率给出了成绩的近似上限。来自 Othmar W Winkler 的论三角相关。他说

尽管缺课和学期成绩之间存在明显的关系，但使用线性回归计算的相关系数为 r = -.18024。对此进行解释$R^2 = .03249$似乎表明，了解缺课百分比几乎无法解释这些课程成绩分散的 3%。

如果没有图表，这似乎非常具有误导性。该论文中的另一个例子：

他将其包括进来是为了展示来自科学而非社会科学的例子。摘自
&quot;Shake hole, A morphometric Field Project for Sixth-Form Geographers&quot; Geography, Vol. 65 pt. 3, July 1980, No. 288&quot;（我无法通过互联网搜索找到它）。其他有趣的例子可以在 Richard R. Hake 的 互动参与与传统方法：对入门物理课程力学测试数据的六千名学生调查中找到。
同一作者的另一篇论文（较短），包含相同的图（没有围起来），是 一种简单的图形方法来评估相关性。
应如何分析和呈现此类数据？相关系数似乎没什么用...还有其他例子吗？是否使用了其他术语？

我尝试将第一个图中的点数字化。以下结果为 R 格式
dput(plot_data2)
structure(list(percent_missed = c(1.24, 1.1, 3.36, 1.75, 12.72, 
5.12, 8.26, 3.65, 13.3, 17.54, 7.82, 0.51, 0.8, 3.14, 5.99, 3.14, 
0.73, 3.14, 5.7, 9.21, 13.3, 16.96, 22.22, 18.79, 24.34, 28.07, 
12.06, 6.51, 7.68, 8.7, 9.43, 9.14, 11.99、14.4、17.69、22.15、19.15、23.25、33.48、0.8、0.88、3、2.85、5.41、5.26、7.24、7.24、9.21、10.09、13.38、3.14、 、0.73、2.56、4.68、7.02、7.38、8.92、10.38、13.3、16.45、10.53、12.43、8.48、6.73、6.65、8.26、9.58、12.21、14.25、 15.13、18.2、24.34、22.37、39.25、2.92、5.7、6.8、9.43、13.01、13.3、17.03、19.3、18.42、34.58、36.48、23.98、2.85、7.38、 11.92、7.02、14.18、16.81、21.93、24.71、32.6、37.43、18.42、7.31、8.92、16.23、16.3、19.74、21.78、21.78、24.49、27.7、
44.88, 41.59, 14.4, 11.99, 22.22, 24.63, 33.04, 53.36, 7.82, 
21.49, 23.68), 等级 = c(20, 19.6, 19.26, 18.93, 18.96, 18.61, 
18.58, 18.25, 18.22, 18.31, 17.95, 17.8, 17.67, 17.8, 17.63, 
17.4, 17.29, 17.12, 17.31, 17.43, 17.58, 17.75, 17.63, 17.33, 
17.09、17.29、17.17、17.09、16.96、16.97、16.91、16.83、16.6、16.62、16.78、16.78、16.29、16.28、16.35、16.72、16.41、 1、16.42、16.77、16.4、16.62、16.28、16.47、16.44、16.16、16.14、15.85、15.56、15.16、15.46、15.61、15.96、16.01、 16.01、15.92、16.01、15.53、15.45、15.27、15.16、14.99、15、14.78、14.69、14.72、15.06、15.39、15.7、15.12、15.24、14.32、 14.6、14.3、14.14、14.32、14.02、14.59、14.54、14.01、14.36、13.99、13.68、13.47、13.7、13.47、13.22、13.09、13.19、 13.28, 13.28, 13.32, 13.15, 12.88, 
12.58, 12.06, 11.94, 12.49, 12.45, 12.66, 12.33, 12.48, 12.3, 
12.66, 12.27, 11.63, 11.13, 11.22, 11.81, 11.05, 9.55, 9.57, 
9.78, 9.27)), row.names = c(NA, -118L), class = &quot;data.frame&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/653518/triangular-correlations</guid>
      <pubDate>Wed, 28 Aug 2024 23:41:28 GMT</pubDate>
    </item>
    <item>
      <title>自回归训练如何帮助限制推理中的复合误差？</title>
      <link>https://stats.stackexchange.com/questions/635852/how-does-autoregressive-training-help-limit-compounding-errors-at-inference</link>
      <description><![CDATA[我有点难以在脑海中证明某些东西，希望有人能提供一些直觉？我理解对于 LSTM 模型或维持序列某些状态的模型，自动回归训练有助于帮助模型学习管理其上下文和状态。我所苦苦挣扎的是，如果我们使用的模型没有保持某些隐藏状态。
对于这个例子，假设我们有一些时间序列 x，我们将 AR 模型应用于该序列。现在假设我们用多个完全连接的层替换 AR 模型的参数。
我相信在一步预测上训练模型并将其应用于多步会引入复合误差，但我无法在脑海中直观地证明这一点。有人能解释一下吗？
我一直认为，基本上这里的一步领先训练就像 LSTMS 的教师强制技术一样。
任何见解都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635852/how-does-autoregressive-training-help-limit-compounding-errors-at-inference</guid>
      <pubDate>Sat, 30 Dec 2023 02:56:42 GMT</pubDate>
    </item>
    <item>
      <title>IRT 混合模型使用贝叶斯方法预测潜在估计</title>
      <link>https://stats.stackexchange.com/questions/632585/irt-hybrid-model-predict-latent-estimate-using-bayesian-method</link>
      <description><![CDATA[我在项目反应理论 (IRT) 预测模型方面遇到了一些问题。
当我使用 IRT 混合模型时，它无法预测潜在值，即使在 IRT 模型处理过程中成功收敛。
它包含二元变量和序数变量。
global pvars1 = &quot;varA&quot; global pvars2 = &quot;varB&quot;

设置种子 2453

IRT 模型
irt 混合 (2pl $pvars1) (grm $pvars2) estat 报告 $pvars1 $pvars2，byparm sort(b) 预测 latent_hybird，潜在 se(latent_se_hybird)


预测 latent_hybird，潜在 se(latent_se_hybird)

(选项 ebmeans 假定) （使用 7 个求积点）无法计算经验贝叶斯均值；评估器返回了缺失值
关于这个问题有什么线索吗？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/632585/irt-hybrid-model-predict-latent-estimate-using-bayesian-method</guid>
      <pubDate>Wed, 29 Nov 2023 03:19:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么带有身份链接的泊松 GLM 收敛，但带有身份链接的负二项式 GLM 不收敛？</title>
      <link>https://stats.stackexchange.com/questions/585330/why-does-my-poisson-glm-with-identity-link-converge-but-a-negative-binomial-glm</link>
      <description><![CDATA[我试图用一个单一特征（也是一个计数）和截距项来拟合 GLM 来计数数据。特征和响应都是非负的（但可能是 0）。我需要使用恒等链接，因为我想检验线性模型中的系数为 1 的假设。
我可以毫无问题地将泊松回归拟合到数据中。但是，由于我的数据肯定是过度分散的，我想改为拟合负二项回归。然而，当我这样做时，优化算法往往无法收敛。我注意到 R 中 MASS 包中的 glm.nb 函数、R 中 VGAM 中的 vglm 函数以及 Python 中的 statsmodels 包中都存在这种行为，因此这种行为似乎与任何特定软件无关。
我有许多数据集，希望按顺序拟合这些模型，其中大多数都观察到了相同的行为。
所以我的问题是：为什么泊松回归会收敛，而负二项式不会？考虑到我的数据的性质和所选的链接函数，我理解截距和系数都必须为正，模型才有意义。但是，我认为这对泊松和负二项式来说都是一个问题，但一个有效，另一个无效。
我怀疑这个问题与这些包在后台使用的优化算法有关。但这种情况发生在两种不同语言的三个包中，这让我怀疑情况是否如此。但如果是的话，我能做些什么来纠正这些问题，比如改变起始值或传递不同的优化方法？
编辑以添加最小可重现示例。原始数据无法共享，但我已经取了一个小样本。当使用 Python 中的 statsmodels 包时，这与泊松收敛，但不与负二项式收敛。注意 x 值为 0 且 y 非常大的数据点。
import statsmodels.api as sm
import numpy as np

X = np.array([60, 16, 32, 0, 1148, 96, 16, 32, 208, 2, 23, 30, 60, 
340, 16, 132, 51, 350, 4, 0])
X = np.vstack((X, [1]*X.shape[0])).T # 添加截距
y = np.array([48, 14, 21, 1, 2779, 96, 16, 24, 79, 1, 12, 30, 1, 135, 
16, 223, 37, 154, 4, 3279])

poiReg = sm.GLM(y, X, family = sm.families.Poisson(
link = sm.families.links.identity)).fit()
poiReg.summary()

nbReg = sm.GLM(y, X, family = sm.families.NegativeBinomial(
link = sm.families.links.identity)).fit()
nbReg.summary()

还请注意，虽然此模型无法与 statsmodels 收敛，但它实际上可以与 R 中的 glm.nb 收敛。但是，完整数据集却无法收敛，而且我没有时间继续尝试样本排列，直到找到一种在所有情况下都失败的排列。]]></description>
      <guid>https://stats.stackexchange.com/questions/585330/why-does-my-poisson-glm-with-identity-link-converge-but-a-negative-binomial-glm</guid>
      <pubDate>Fri, 12 Aug 2022 13:47:13 GMT</pubDate>
    </item>
    </channel>
</rss>