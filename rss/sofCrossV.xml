<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 29 Jan 2024 15:12:59 GMT</lastBuildDate>
    <item>
      <title>理解随机变量之间的等式的含义[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638022/understanding-the-implication-of-equalities-between-random-variables</link>
      <description><![CDATA[有两个二元随机变量 $X$ 和 $Y$，其中 $Y$ 是我对 X 的预测或猜测。
以下哪项陈述在数学上是正确且严格的（如果有）？它们都传达相同的含义吗？

“如果 $X \neq Y$，我们就说预测出现错误”。
&quot;给定 $X=x$ 和 $Y=y$，我们说有如果$x \neq y$”，则预测出错。
“鉴于 $X=x$，如果 $Y \neq，我们称预测存在错误x$”。
]]></description>
      <guid>https://stats.stackexchange.com/questions/638022/understanding-the-implication-of-equalities-between-random-variables</guid>
      <pubDate>Mon, 29 Jan 2024 15:07:13 GMT</pubDate>
    </item>
    <item>
      <title>R：如何在 PFS 生存分析中获得概率（HR<1）和 HR 后验分布</title>
      <link>https://stats.stackexchange.com/questions/638020/r-how-to-get-probhr1-and-posterior-distribution-of-the-hr-in-a-pfs-survival</link>
      <description><![CDATA[我进行了生存分析来比较 3 组之间的 PFS。我使用这段代码来进行分析。
fit &lt;- survfit(Surv(time, censor_status) ~ group, data = df)

然后我使用 ggsurvplot 绘制生存曲线。
我还想计算概率（HR &lt; 1）并绘制 HR 的后验分布，但我找不到有关如何执行此类分析的任何信息。有人可以帮我吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/638020/r-how-to-get-probhr1-and-posterior-distribution-of-the-hr-in-a-pfs-survival</guid>
      <pubDate>Mon, 29 Jan 2024 14:31:09 GMT</pubDate>
    </item>
    <item>
      <title>在线性混合模型中区分功效不足和不显着的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/638019/what-is-the-optimal-method-for-distinguishing-lack-of-power-from-non-significanc</link>
      <description><![CDATA[我有一个线性混合模型，并且对固定效应的重要性感兴趣。
我运行了 2 个相同的模型，但第二个模型消除了异常值的数据点（即敏感性测试）。
假设使用 p 值来确定统计显着性，那么确定 p 值的变化（从显着性到不显着性）是否是由于数据点减少所致的最佳方法是什么？

功耗分析？
效果大小？

在这种情况下，在 R 中使用线性混合模型计算上述内容的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/638019/what-is-the-optimal-method-for-distinguishing-lack-of-power-from-non-significanc</guid>
      <pubDate>Mon, 29 Jan 2024 14:27:42 GMT</pubDate>
    </item>
    <item>
      <title>高斯后验/后验预测的平均值</title>
      <link>https://stats.stackexchange.com/questions/638018/mean-of-gaussian-posterior-posterior-predictive</link>
      <description><![CDATA[考虑高斯先验和似然，后验的均值是否等于后验预测的均值？
如果是这样，这个平均值是否也等于使用 MAP 估计的 $μ$ ？]]></description>
      <guid>https://stats.stackexchange.com/questions/638018/mean-of-gaussian-posterior-posterior-predictive</guid>
      <pubDate>Mon, 29 Jan 2024 14:03:43 GMT</pubDate>
    </item>
    <item>
      <title>皮尔逊交叉表定理[重复]</title>
      <link>https://stats.stackexchange.com/questions/638015/pearsons-theorem-for-cross-table</link>
      <description><![CDATA[为了理解珀森定理（为什么卡方检验是合理的），
我已阅读此讲义 我想我理解了讨论，但我仍然不明白为什么表大小 ab 的自由度变成 (a-1)(b-1)。
谁能给我解释一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638015/pearsons-theorem-for-cross-table</guid>
      <pubDate>Mon, 29 Jan 2024 13:31:38 GMT</pubDate>
    </item>
    <item>
      <title>积分函数[迁移]</title>
      <link>https://stats.stackexchange.com/questions/638012/integral-function</link>
      <description><![CDATA[我们如何找到这个积分的封闭形式？
\begin{align}
f_X(x) = \int_{0}^{\infty} \frac{\theta^{a+2}}{\theta^2+1} e^{-\theta(x+b)} \ d\西塔
\end{对齐}]]></description>
      <guid>https://stats.stackexchange.com/questions/638012/integral-function</guid>
      <pubDate>Mon, 29 Jan 2024 12:16:03 GMT</pubDate>
    </item>
    <item>
      <title>共有 N 名患者，以了解某个频率的精确度，并具有不同的 FU 时间</title>
      <link>https://stats.stackexchange.com/questions/638011/total-n-patients-for-precision-around-a-rate-with-varying-fu-times</link>
      <description><![CDATA[我们必须设计一项回顾性纵向研究，以评估开始治疗后特定事件的发生情况。根据之前的研究，我们估计年化率为 0.06%，即 0.0006/人年（被低估，因为它给出了中位 FU 为一年的 n/N 比例，并且他们发现 13 名患者/2000 名患者平均随访 1 年）年，不包括经常性事件）。从这个出发，在封装预设大小的情况下，比例为 0.0006，宽度为 0.0015，估计 N=5320（Wilson 的），但是对于比率（我们的目标是对所有事件进行计数） ）它给出（速率 0.0006，相同宽度）我们需要 4 个事件，时间 = 5741（我想是年）。问题是，这不是一项前瞻性研究，因此我们需要考虑之前研究中 FU（平均治疗时间）的分布。如果所有患者都接受一年的随访，则没有任何优势（除了不计入复发事件的实际发生率肯定更高这一事实之外）。但是，如果我们得到“右偏” FU时间分布，例如15％的患者FU时间为0-0.5年（我们可以取平均值），25％的平均FU（暴露）时间为5-1年，其余患者移动在 1-2 年的范围内，它将对总样本量产生积极影响，因为我们需要招募更少的患者，对吧？我知道我们严重依赖假设，但对于回顾性研究，描述性的 N学习更多的是预算问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/638011/total-n-patients-for-precision-around-a-rate-with-varying-fu-times</guid>
      <pubDate>Mon, 29 Jan 2024 11:55:37 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAMLSS 进行密度预测</title>
      <link>https://stats.stackexchange.com/questions/638009/density-forecasts-with-gamlss</link>
      <description><![CDATA[有人知道 GAMLSS 包中创建密度预测的函数吗？
预测。公式不正确。预测点预测]]></description>
      <guid>https://stats.stackexchange.com/questions/638009/density-forecasts-with-gamlss</guid>
      <pubDate>Mon, 29 Jan 2024 11:10:19 GMT</pubDate>
    </item>
    <item>
      <title>谱图表示方法仅限于单个图结构意味着什么？</title>
      <link>https://stats.stackexchange.com/questions/638007/what-does-it-mean-for-spectral-graph-representation-methods-to-be-limited-to-a-s</link>
      <description><![CDATA[我正在尝试更深入地了解图神经网络的主题。最近在阅读这篇论文时，我发现了这样的说法：使我困惑。作者指出，谱方法仅限于“单一图结构”，而空间方法则不然。
&lt;块引用&gt;
上述的一个限制[参考2] 光谱公式是它们依赖于
图拉普拉斯的固定谱，因此仅适用
对于具有单一结构的图（以及顶点上不同的信号）。
相反，空间表述并不局限于固定的
图结构。

谁能给我解释一下这是什么意思吗？这个限制到底是什么？ GCN（作为谱图卷积的一个实例（？））是否会受到此影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/638007/what-does-it-mean-for-spectral-graph-representation-methods-to-be-limited-to-a-s</guid>
      <pubDate>Mon, 29 Jan 2024 11:03:41 GMT</pubDate>
    </item>
    <item>
      <title>如何统计测试两个1的和[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638006/how-to-statistically-test-two-sums-of-1s</link>
      <description><![CDATA[我有以下向量：
vec_1=c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1)
vec_2=c(1,1,1,1,1,1,1,1,1)

从中我计算出相应的总和：
&lt;前&gt;&lt;代码&gt;&gt;打印（总和（vec_1））
[1] 18
&gt;打印（总和（vec_2））
[1] 9

有没有办法测试这两个总和是否有统计差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/638006/how-to-statistically-test-two-sums-of-1s</guid>
      <pubDate>Mon, 29 Jan 2024 10:47:35 GMT</pubDate>
    </item>
    <item>
      <title>连续预测器的推荐系统</title>
      <link>https://stats.stackexchange.com/questions/638001/recommender-system-for-continuous-predictors</link>
      <description><![CDATA[我想构建一个能够预测用户与客户端交互结果的模型。
我知道对于分类变量来说，分解机是一个不错的选择。
想象一下，例如我们正在谈论人们与电影互动：人们的分类变量是年龄、性别、种族等，而对于电影来说，它可能是发行年份、类型、主要演员……
在我的例子中，客户端和用户都使用实数向量而不是 calcategori 变量进行编码，如下所示：

用户1：[0.5，1.2，1.5]
用户2：[0.9、1.3、1.7]
...
客户端1：[0.1，0.4，0.7]
客户端2：[0.2，0.5，0.7]
...

我有大多数交互的数据：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

用户
客户端
结果变量 (Y)


&lt;正文&gt;

用户1
客户端1
2.4


用户1
客户端2
2.9


用户2
客户端1
1.9


用户2
客户端2
2.2




我想预测对于没有测量 Y 的用户-客户端对，交互的结果会是什么。
这正是 FM 可以很好地工作的地方，但不同之处在于我使用连续变量作为用户和客户端的描述符，并且据我了解这些算法并不意味着处理这些数据。
我说得对吗？
您知道在这种情况下运行良好的算法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638001/recommender-system-for-continuous-predictors</guid>
      <pubDate>Mon, 29 Jan 2024 10:21:33 GMT</pubDate>
    </item>
    <item>
      <title>哪个数据子集应该用于可解释机器学习 (IML)？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/638000/which-data-subset-should-be-used-for-interpretable-machine-learning-iml</link>
      <description><![CDATA[在机器学习工作流程中，我们需要将数据集分为训练集和测试集。我们在训练集上训练几个候选模型（通常通过超参数优化进行调整），然后选择在测试集上评估时表现最佳的模型。这样，性能评估可以最大限度地减少训练子集的过度拟合。
最终，我想使用可解释的机器学习 (IML) 技术来解释模型，例如累积的局部效应 ( ALE）。这是我的问题：使用 IML 分析数据时，我们应该使用哪个模型和数据子集？以下是我正在考虑的各种候选选项：

在训练集上训练的最佳模型，IML 仅分析训练集
在训练集上训练的最佳模型，并且 IML 仅分析测试集
在完整数据集（训练+测试数据）上训练的最佳模型，IML 仅分析训练集
在完整数据集（训练+测试数据）上训练的最佳模型，IML 仅分析测试集
在完整数据集（训练 + 测试数据）上训练的最佳模型，并通过 IML 分析完整数据集（训练 + 测试数据）

我希望得到一个合理的答案，解释为什么哪个子集适合训练以及哪个子集适合 IML 数据分析。]]></description>
      <guid>https://stats.stackexchange.com/questions/638000/which-data-subset-should-be-used-for-interpretable-machine-learning-iml</guid>
      <pubDate>Mon, 29 Jan 2024 10:02:54 GMT</pubDate>
    </item>
    <item>
      <title>计数数据回归的误差度量：泊松偏差还是均方误差？</title>
      <link>https://stats.stackexchange.com/questions/637999/error-metric-for-regression-of-count-data-poisson-deviance-or-mean-square-error</link>
      <description><![CDATA[我想了解，如果我使用均方误差或泊松偏差作为计数数据回归的误差度量/损失函数，会产生什么差异。是否有任何先验或理论上的原因让我们更喜欢一种指标而不是另一种指标？
背景
我确实有一个很大的计数数据数据集（即事件和暴露的数量），具体取决于各种协变量。我想将各种模型（经典 GLM 以及机器学习模型）拟合到该数据集并评估它们的质量。我的主要目标是根据协变量对分布的条件均值进行点预测。相应的比率通常很小（比如 0 到 10% 之间），并且在许多情况下观察到的事件为零。我没有任何特定领域的原因（例如成本函数）来选择我的错误度量，并且我对推理不太感兴趣（还）。此刻，我只想要一个“最好的”。预测，无论这意味着什么。
据我了解，我应该选择一个“适当的评分函数”为条件均值。我进一步了解到均方误差和泊松偏差都满足这个要求。
我的问题

除了适当的均值评分函数之外，我还应该注意其他要求吗？
是否还有其他相关指标可以（或应该）用于评估预测的质量？
与其他指标相比，更喜欢泊松偏差或均方误差等一种误差指标的可能原因是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/637999/error-metric-for-regression-of-count-data-poisson-deviance-or-mean-square-error</guid>
      <pubDate>Mon, 29 Jan 2024 09:57:27 GMT</pubDate>
    </item>
    <item>
      <title>使用复杂度惩罚进行正则化</title>
      <link>https://stats.stackexchange.com/questions/637995/regularization-using-complexity-penalty</link>
      <description><![CDATA[我目前正在阅读墨菲，我遇到了正则化
我面临的问题是在他们使用的复杂性惩罚背后建立直观的感觉 
登录我之前的信念会如何惩罚模型的过度拟合？]]></description>
      <guid>https://stats.stackexchange.com/questions/637995/regularization-using-complexity-penalty</guid>
      <pubDate>Mon, 29 Jan 2024 09:04:59 GMT</pubDate>
    </item>
    <item>
      <title>数据集中在原点的拟合回归</title>
      <link>https://stats.stackexchange.com/questions/637994/fitting-regression-where-data-is-concentrated-at-the-origin</link>
      <description><![CDATA[我正在进行一项探索性数据分析，研究中文书写的许多字符级特征。我目前正在研究的关联是角色的复杂性（离散）和估计的习得年龄（连续）之间的关联。原始形式的数据如下所示：

根据我的观察，数据似乎首先是在原点附近生成的，变成一个弱相关的大椭球体，然后向右篡改。鉴于此信息，我考虑了以下选项：

常规 OLS：这根本不起作用。它大大高估了数据应该在的位置。
无截距线性模型：因为数据起源于原点 $[0,0]$ 我认为是抑制截距，但这似乎难以置信，因为某人在获取单词时不可能年龄为零，而且复杂性得分也可能为零，所以我放弃了这个想法。
GAM：我使用了各种 GAM 拟合，最佳拟合似乎是自适应平滑，但它似乎仍然高估了原点附近的数据。不过，就捕获分布的其余部分而言，这通常仍然可以完成工作。
多项式回归：我通常不喜欢用它们来进行非线性回归，但这似乎可以最好地捕获我关心的分布的左下部分。残留诊断似乎也相当不错。我在这里看到的唯一问题是它在回归线最右侧的插值效果有点差。
泊松或 beta 回归：DV 只能采用 1 或更大的值。但是，因为数据是连续的，所以我认为它在这里不起作用。我也尝试过 beta 回归（通过将数据转换为比例），但模型看起来就是错误的。

以下是四种候选拟合，看起来至少接近现实。

多项式拟合的残差如下所示。残差明显呈带状，并且在某些区域聚集更多，但我认为通常它们看起来并不可怕：


多项式回归在这里效果最好还是其他方法更好？我会注意到这个数据集有数千个值，因此它在散点图中的椭圆体中间聚集了很多。
编辑
过滤接近原点的值 (AoA &lt;= 2)，绘图如下所示（带有自动生成的 LOESS 线）：

编辑2
至于上下文：AoA 是个位数，应该是对中国人最初学习一个字符的时间的估计（这是一种主观的自我回忆测量）。评级基于单个字符的各个主题的平均值，因此采用小数单位。例如，3个人可能记得他们分别在6岁、7岁、7岁的时候学过“我”，平均6.67岁左右。因此，这里的年龄不太可能高于典型的幼儿年龄。
对于周界复杂度，它通常是连续的，公式为：
$$
\frac{P^2}{A 4 \pi}
$$
其中 $P$ 是字符墨迹空间的周长，$A$ 是区域，而 $\pi$ 就是字面上的 $\pi$。但不幸的是，在这个数据集中，它被四舍五入了，我无法取回那些小数值。至于分布的异常情况，我主要担心的是分布的中心要重得多（这里有 3600 多个 obs，以防不清楚），因此分布的外部回归线的权重相当不均匀。我还想在这里平衡模型简约性，因此摆脱过于复杂的多项式将是理想的选择。]]></description>
      <guid>https://stats.stackexchange.com/questions/637994/fitting-regression-where-data-is-concentrated-at-the-origin</guid>
      <pubDate>Mon, 29 Jan 2024 08:56:17 GMT</pubDate>
    </item>
    </channel>
</rss>