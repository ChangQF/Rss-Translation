<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 15 Mar 2025 01:18:05 GMT</lastBuildDate>
    <item>
      <title>计算错误项的NLME :: GLS（）的不确定性？</title>
      <link>https://stats.stackexchange.com/questions/662645/calculate-uncertainty-for-nlmegls-of-the-error-terms</link>
      <description><![CDATA[我在这里试图与 nlme :: gls（）一起工作，因为这是我发现的最佳解决方案。我想找到类似的数据：
  stdconc_dil＆lt;  -  1：200
res＆lt;  -  lapply（1：nrep，function（i）{
    响应＆lt;  -  stdconc_dil + rnorm（长度（stdconc_dil），0，0.06*stdconc_dil） + rnorm（长度（stdconc_dil），0，0.4）
    data.frame（stdconc = stdconc_dil，conc = revertmon）
}））

res＆lt;  -  do.call（rbind，res）

GLS（conc〜stdconc-1，data = res， 
  striges = varconstprop（form = 〜StdConc），控制=列表（Sigma = 1））
 
我正在尝试对 2标准偏差项进行不确定性估计，而不是斜率。 （实际上，我试图完全删除坡度，直接制​​作y〜x + varconstprop（），但我未能找到解决方案。）
如果我可以提取诸如完整协方差矩阵或黑森州之类的东西，则 solve（），它可能会为我做。
 tia！]]></description>
      <guid>https://stats.stackexchange.com/questions/662645/calculate-uncertainty-for-nlmegls-of-the-error-terms</guid>
      <pubDate>Fri, 14 Mar 2025 21:46:41 GMT</pubDate>
    </item>
    <item>
      <title>两年之间分析盐度数据的最佳统计方法</title>
      <link>https://stats.stackexchange.com/questions/662644/best-statistical-approach-to-analyze-salinity-data-between-two-years</link>
      <description><![CDATA[我有兴趣确定盐度在特定河口的湿年中与干燥年份之间的几个月之间的变化。例如，2000年1月的盐度与2010年1月有很大不同，等等。
数据具有：站点，盐度，年和月列。有4个站点，每个站点都有自己的每日盐度价值，每天在这个时间范围内。我想知道确定这一重要性的适当统计假设检验是什么，以及我是否应平均值进行比较或仅作为每日平均值。任何建议都将不胜感激：）]]></description>
      <guid>https://stats.stackexchange.com/questions/662644/best-statistical-approach-to-analyze-salinity-data-between-two-years</guid>
      <pubDate>Fri, 14 Mar 2025 21:45:57 GMT</pubDate>
    </item>
    <item>
      <title>如何在两个不同n样品中比较相同的回归模型</title>
      <link>https://stats.stackexchange.com/questions/662643/how-to-compare-the-same-regression-model-in-two-samples-with-different-n</link>
      <description><![CDATA[我阅读了一些类似问题的答案，例如在这里href =“ https://stats.stackexchange.com/questions/39227/comparing-regression-coeffitic--with-with-same-model-model-model-but-two-distinct-samples”&gt;在这里，但他们不满意我。
我的问题是我想将两个回归模型与一个互动术语进行比较。
具体来说，我想验证模型之间的模型是否有所不同（编码虚拟编码）。
要创建三向互动术语列（IV X IV X国家 /地区），我是否应该结合数据集并重新计算双向交互项（国家之间的双向互动项的相同方式），还是应该保留旧的交互项（国家之间的双向互动术语的不同手段）？
对我来说，似乎并没有回答“结合后要做什么”的问题。
预先感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/662643/how-to-compare-the-same-regression-model-in-two-samples-with-different-n</guid>
      <pubDate>Fri, 14 Mar 2025 21:38:27 GMT</pubDate>
    </item>
    <item>
      <title>将文本可读性指标与主观测量相关联</title>
      <link>https://stats.stackexchange.com/questions/662642/correlating-text-readability-metrics-against-subjective-measurements</link>
      <description><![CDATA[假设我想找出文本的可读性度量与文本复杂性的主观测量值的相关程度。我要求18个人阅读12条短文，我衡量他们认为每个文本都有5项李克特调查的困难（因此得分为5.0表示高复杂性）。我想尝试找出哪些度量与主观复杂性最有关系。
一种幼稚的方法是从所有参与者中获取每个文本的平均主观得分，并在应用于文本时发现哪种复杂性度量与结果的相关性最强。但是，我认为这将丢失很多信息。多级模型在这里是否合适？
评论：这个问题类似于]]></description>
      <guid>https://stats.stackexchange.com/questions/662642/correlating-text-readability-metrics-against-subjective-measurements</guid>
      <pubDate>Fri, 14 Mar 2025 21:32:21 GMT</pubDate>
    </item>
    <item>
      <title>检查核密度估计的L2标准的渐近正态性</title>
      <link>https://stats.stackexchange.com/questions/662641/checking-the-asymptotic-normality-of-l2-norm-of-kernel-density-estimation</link>
      <description><![CDATA[让  $ \ hat {f} _n $ ， $ n \ in \ Mathbb {n} $ 是kernel密度估计器和 $ f $ f $  true dement&gt; true dementy。我想检查 $$ \ sqrt {nh}（\ lvert \ hat {f} _n \ rvert_2- \ lvert f \ rvert f \ rvert_2）
收敛到 $ \ mathbb {r} $   $ nh \ rightarrow \ rightarrow \ infty $ 时，收敛到任何普通的随机变量， $ \ mathbb {r} $ ，并且找不到任何结果。。
我们无法使用功能增量方法来证明这一点，因为通过 $ \ sqrt {nh}（\ hat {f} _n-f）$ 收敛到功能空间上的任何内容，它可能是0。因此，我尝试使用中心限制定理。第一个问题是 $ \ lvert \ hat {f} _n \ rvert $ ， $ n \ in \ in \ mathbb {n} $ 是独立的。但是我找不到随机函数独立性的定义。另外，我们没有像中心限制定理中的随机变量总和。因此，我不确定我是否处于正确的方式。非常感谢您的提示！]]></description>
      <guid>https://stats.stackexchange.com/questions/662641/checking-the-asymptotic-normality-of-l2-norm-of-kernel-density-estimation</guid>
      <pubDate>Fri, 14 Mar 2025 20:49:10 GMT</pubDate>
    </item>
    <item>
      <title>椭圆形的数据或随机变量的示例？</title>
      <link>https://stats.stackexchange.com/questions/662640/examples-of-data-or-random-variables-on-ellipsoids</link>
      <description><![CDATA[我正在研究一些神经科学模型，这些模型可以被认为是在椭球上分布数据。在这些模型中（例如， 1 ，， 2 ）有一些随机变量 $ \ sqrt {y^t b y} $ ，其中 $ b $ 是一种对称的正定矩阵。结果变量 $ z = y / \ sqrt {y^t b y} $ &lt; / span&gt;在椭圆形的表面上。一个相关的替代变量 $ z = y/\ sqrt {y^t b y + c} $ 其中 $ c $ 是一个积极的标量，是一个积极的标量。
我想知道在其他领域的椭圆机上是否有类似的数据示例或随机变量。例如，一些深度学习应用程序项目高维特征在球体上（例如 href =“ https://academic.up.com/biostatistics/article/9/1/66/253727” rel =“ nofollow noreferrer”&gt;一些生物信息学应用程序。但是，我还没有找到将向量投射到椭圆上的一个示例。有这样的例子吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662640/examples-of-data-or-random-variables-on-ellipsoids</guid>
      <pubDate>Fri, 14 Mar 2025 20:24:01 GMT</pubDate>
    </item>
    <item>
      <title>随着时间的推移比较4种处理中的事件频率</title>
      <link>https://stats.stackexchange.com/questions/662639/comparing-event-frequencies-in-4-treatments-over-time</link>
      <description><![CDATA[我进行了一个实验，其中4种治疗方法我每周一次在所有处理中计算同一事件的频率，而我有26周的数据。 Y轴是每周经历活动的受试者的百分比。我想比较每个系列。我认为我想要的是创建每个模型并测试以查看模型是否相同...基本上，在频率，循环等方面，治疗方法之间是否存在差异。。
  &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stats.stackexchange.com/questions/662639/comparing-event-frequencies-in-4-treatments-over-time</guid>
      <pubDate>Fri, 14 Mar 2025 20:17:26 GMT</pubDate>
    </item>
    <item>
      <title>在有限样本中模拟完整的随机分配到$ K $处理</title>
      <link>https://stats.stackexchange.com/questions/662637/simulating-complete-random-assignment-in-a-finite-sample-to-k-treatments</link>
      <description><![CDATA[我正在尝试创建一个模拟，该模拟随机将有限的样本 $ n $ 进入 $ k $ 处理，并努力地数学上没有这样的任务。我知道如何实施该程序，但是定义了我正在努力的治疗成员的随机变量。
说我们有 $ k = 3 $ 治疗组的总体样本大小为 $ n = 30 $ 。我们希望在每个组中具有平衡的样本量 $ n_k = 10 $ 。
随机变量 $ k_i \ in \ {1,2,3 \} $ 是一个分类变量，代表 $ i $  $  th person。
我们可以建模：
 $$
k_i \ sim多项式（{\ bf {p}} = 1/3，n = 1，k = 3）
$$  
但这不容易 $ n_k $ 仅在期望中常数才能等于 $ n_k $ 。
我将如何注意随机变量 $ k_i $ 给定 $ k_i $ ？]]></description>
      <guid>https://stats.stackexchange.com/questions/662637/simulating-complete-random-assignment-in-a-finite-sample-to-k-treatments</guid>
      <pubDate>Fri, 14 Mar 2025 19:52:47 GMT</pubDate>
    </item>
    <item>
      <title>得分匹配算法</title>
      <link>https://stats.stackexchange.com/questions/662635/score-matching-algorithim</link>
      <description><![CDATA[我一直在阅读有关得分匹配的信息，我有一个非常基本的问题，即一个人（天真地）如何通过梯度下降实现算法。
说，我有某种神经网络，这些神经网络会输出（不符合）概率 $ p_ \ theta（\ Mathbf {x}）$ 对于某些Input  $ \ \ Mathbf {x Mathbf {x} $ 我们试图最大程度地减少损失
 $$ \ MATHBB {E} _ {p _ {\ text {data}}}} \ left [
\ text {tr}（\ nabla _ {\ mathbf {x}}}^2 \ log p_ \ theta（\ mathbf {x}））） + \ frac {1} {2} {2} {2} \ nabla _ {\ Mathbf {x}} \ log p_ \ theta（\ Mathbf {x}）\ | _2^2
\ right]。$$  
其中一个术语是 $ \ nabla _ {\ Mathbf {x}}} \ log p_ \ theta（\ Mathbf {x}）$ 。我可以看到如何通过一个反向传播来估计此梯度的 value （取出输出，应用 $ \ log $  $ 并将一路分化为输入）。但这只是给了我们一个数字。那么，我们应该如何将梯度相对于 $ \ theta $ 并更新参数？看来这似乎需要我们能够将 $ \ nabla _ {\ mathbf {\ mathbf {x}}} \ log p_ \ theta（\ mathbf {x}）$ 
在我看来，对于第一学期，计算Hessian的对角线条目甚至很困难，因为我们需要了解 $ \ nabla _ {\ nabla _ {\ Mathbf {x}}}}} \ log p_ \ p_ \ theta（ class =“ Math-Container”&gt; $ \ Mathbf {X} $ ，但我们只能拿出值。
我问这件事的主要原因是因为我正在阅读 nofollow noreferrer“
可以通过应用反射 $ D $ 来计算跟踪
时代to  $ \ nabla _ {\ MathBf {x}} \ log P_ \ theta（\ Mathbf {x}）$ 其中 $ d $ d $ d $ d $ d $ 是空间的尺寸，我无法做到&lt;/cone dow/de cand of per &lt;/come de cond of per。]]></description>
      <guid>https://stats.stackexchange.com/questions/662635/score-matching-algorithim</guid>
      <pubDate>Fri, 14 Mar 2025 18:59:58 GMT</pubDate>
    </item>
    <item>
      <title>残差图和Breusch-Pagan测试之间的矛盾结果</title>
      <link>https://stats.stackexchange.com/questions/662631/conflicting-results-between-residuals-plot-and-breusch-pagan-test</link>
      <description><![CDATA[我正在使用内置女性数据集（包括15行，2列 - 身高和重量）来说明某些基本的诊断技术，以验证线性模型中的均质性假设。在残差图中有一个dinstint曲线图 $ \ hat {height {height} = a + b \ b \ times strige strige proge $ 型号，即模型1，所以自然而然地，我在模型中添加了一个Quicdratic术语
  data（“女性”）
model1 = lm（公式=女性$ height〜女性$体重，数据=女性）
model2 = lm（公式=女性$ height〜女人$ strige + i（女性$ strage^2），data = women）
 
  在针对拟合和标准化残差的两个残差中，模型1似乎具有明显的不同模式，而模型2在两个图中具有更多随机模式。但是，由学生化的Breusch-Pagan测试对同质性的结果是矛盾的。我最初将其归结为样本量，但这是Breusch-Pagan测试的学生变化，据说这对于小样本案例或偏离正常性的差异更为强大。
有什么想法吗？
  &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stats.stackexchange.com/questions/662631/conflicting-results-between-residuals-plot-and-breusch-pagan-test</guid>
      <pubDate>Fri, 14 Mar 2025 18:39:53 GMT</pubDate>
    </item>
    <item>
      <title>GridSearch结果与学习曲线</title>
      <link>https://stats.stackexchange.com/questions/662629/gridsearch-results-vs-learning-curve</link>
      <description><![CDATA[我正在使用GridSearchCV来优化XGBoost模型上的一些超级参数。但是，尽管根据域知识，logloss（我正在优化的度量）似乎还不错，但学习曲线显示出过度拟合的经典迹象。为了减少过度拟合，手动调整超出拟合的参数（可能是XGBOOSTING，由于其对过度拟合的敏感性）是正常的吗？还是我不正确地解释学习曲线？
  &lt;img alt =“用于neg log损失的优化”]]></description>
      <guid>https://stats.stackexchange.com/questions/662629/gridsearch-results-vs-learning-curve</guid>
      <pubDate>Fri, 14 Mar 2025 18:27:23 GMT</pubDate>
    </item>
    <item>
      <title>如何在线性模型中以不同的重测间隔收集的数据？</title>
      <link>https://stats.stackexchange.com/questions/662624/how-to-account-for-data-collected-at-different-remeasurement-intervals-in-a-line</link>
      <description><![CDATA[我需要在不同的重新测量间隔收集的数据集上运行线性模型。
示例：
 2014-2017-2020-2021-2021-2023 
在此模型中，我应该尝试考虑时间（年） +另一个因素（因子1）效果及其相互作用。
示例：
 mod.1＆lt;  -  lmer（参数〜因子1*年 +（1 | id_rep），data = db）
但是，我的数据尚未定期收集。
我如何在模型中说明这一点？
预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662624/how-to-account-for-data-collected-at-different-remeasurement-intervals-in-a-line</guid>
      <pubDate>Fri, 14 Mar 2025 17:10:32 GMT</pubDate>
    </item>
    <item>
      <title>低坡/歧视问题：IRT的有用性？</title>
      <link>https://stats.stackexchange.com/questions/662618/low-slope-discrimination-questions-usefulness-in-irt</link>
      <description><![CDATA[在项目响应理论中，2-PL模型同时捕获了斜率和截距，而Rasch模型仅捕获截距，将曲线左/右移动（下面捕获）。。
   IRT的一般背景是推断问题难度和学生能力。尽管X轴范围为（-inf，inf），但可以将其转换为范围（0,1）。换句话说， $ x = 0 $ 捕获中位学生能力（或物品难度，因为它们在同一潜在空间中映射。）
通常，给定曲线的歧视力在其拐点处是最大的。关于上面的红色曲线，拐点位于 $ x = 0 $ ，这意味着，如果一个学生真正处于中间位置，则该问题将提供最大的信息，并随着给定的学生的能力增加或降低信息，从而提供了最大的信息。     。
上下文，我的问题很简单：陡峭的斜坡在实践中总是更喜欢？
假设地，如果给定的问题可以通过零差异返回学生的能力（知道学生在拐点以上或低于拐点以上），则可以使用二进制搜索在 $ o（log（log log（log log  time。
当然，这些问题不是确定性的，因此我们绝对可以确定学生没有超出他们的能力问题。但是，我认为，随着这些曲线的斜率接近无穷大（ $ lim：b \ to \ infty）$ 。
考虑到这一假设，较小的歧视性问题（较低的斜率）有用吗？在什么情况下？
我问了一个类似的问题在这里]]></description>
      <guid>https://stats.stackexchange.com/questions/662618/low-slope-discrimination-questions-usefulness-in-irt</guid>
      <pubDate>Fri, 14 Mar 2025 16:10:25 GMT</pubDate>
    </item>
    <item>
      <title>如何计算R中的重复措施MANOVA？</title>
      <link>https://stats.stackexchange.com/questions/662630/how-do-i-calculate-a-repeated-measures-manova-in-r</link>
      <description><![CDATA[我是第一次计算RM Manova。
 i具有3个因变量（RSKO，RSAK，ENKA），主题因子（组）和1之间的1之间（时间点）之间。 ID变量指定属于同一主题的措施。
我发现了分析数据的不同功能，我想知道正确的方法是什么。
另外，我不确定一旦我发现总体效果重大效果，在RM-Manova之后的正确过程是什么。
第一个功能来自统计信息：
  model1＆lt;  -  manova（cbind（rsko_m，rsak_m，exha_m）
摘要（Model1）
 
 Manova（）的摘要输出：
 错误：因子（ID）
           DF Pillai大约f num df den df pr（＆gt; f）  
Gruppe 1 0.05808 2.8159 3 137 0.04154 *
残差139                                         
---
象征。代码：0&#39;***’0.001&#39;**’0.01&#39;*’0.05&#39;。’0.1’’1

错误：内部
                  DF Pillai大约f num df den df pr（＆gt; f）    
时间点1 0.181397 10.1194 3 137 4.581E-06 ***
Gruppe：TimePoint 1 0.041242 1.9644 3 137 0.1222    
残差139                                              
---
象征。代码：0&#39;***’0.001&#39;**’0.01&#39;*’0.05&#39;。’0.1’’1
 
第二个功能来自软件包manova.rm：
  model2＆lt;  -  multrm（cbind（rsko_m，rsak_m，exha_m）〜gruppe * timepoint，data = data_2tp_s_c_w，bucact objection =＆quot;
摘要（模型2）
 
 multrm（）的摘要输出：
 致电： 
cbind（rsko_m，rsak_m，exha_m）〜gruppe *时间点
用1个受试者内因子（S）（时间点）和1个受试者间因子（S）进行多元重复测量分析。 

描述性：
  Gruppe TimePoint N RSKO_M RSAK_M exha_m
1，例如PRE 83 5.306 4.821 3.148
2，例如帖子83 5.337 4.968 3.422
3公斤PRE 58 5.233 4.819 3.539
4千克邮政58 5.192 4.744 4.013

WALD型统计（WTS）：
                 测试统计DF P值 
Gruppe“ 8.688”        “ 3” ＆quot“ 0.034” 
时间点“ 33.405”       “ 3” ＆quot＆lt; 0.001＆quot
Gruppe：TimePoint“ 5.698”        “ 3” ＆quot“ 0.127” 

修改的方差分析型统计量（MATS）：
                 测试统计
格鲁普17.339
时间点8.577
Gruppe：TimePoint 1.846

P值重新采样：
                 参数（WTS）参数（垫子）
Gruppe“ 0.047”       ＆quot“ 0.031”       
时间点“＆lt; 0.001”      ＆quot＆lt; 0.001＆quot      
Gruppe：TimePoint“ 0.138”       ＆quot“ 0.102”       
 
从两个模型产生的输出相似，从某种意义上说，效果通常朝着相同的方向发展。但是，我不确定我应该使用哪个以及结果解释是否存在细微差异。
另外，作为下一步，我为3个因变量中的每个变量中的每个变量做了rm-anovas，以查看哪个有助于整个MANOVA的影响。还有两个选择：
使用来自统计数据包的AOV：
  aov_rsko＆lt;  -  aov（rsko_m〜gruppe * timepoint + error（factor（factor（id）），data = data_2tp_s_c_w）
摘要（AOV_RSKO）
aov_rsak＆lt;  -  aov（rsak_m〜gruppe * timepoint + error（factor（id）），data = data_2tp_s_c_w）
摘要（AOV_RSAK）
aov_exha＆lt;  -  aov（exha_m〜gruppe * timepoint + error（factor（id）），data = data_2tp_s_c_w）
摘要（AOV_EXHA）
 
使用Manova.rm软件包中的RM：
  model_rsko＆lt;  -  rm（rsko_m〜gruppe * TimePoint，data = data_2tp_s_c_w， 
             主题=“ id”，no. -subf = 1，iter = 1000）
摘要（model_rsko）
model_rsak＆lt;  -  rm（rsak_m〜gruppe * timepoint，data = data_2tp_s_c_w， 
                 主题=“ id”，no. -subf = 1，iter = 1000）
摘要（model_rsak）
model_exha＆lt;  -  rm（exha_m〜gruppe * timepoint，data = data_2tp_s_c_w， 
                 主题=“ id”，no. -subf = 1，iter = 1000）
摘要（model_exha）
 
再次，输出是相似的，并且朝着相同的方向行驶。是否有“更正确的”我应该选择的方式？
最后，在显示差异的RM-Anovas中，我想在后面运行哪些群体在什么时间点上有所不同。可能是这样：
  pairwise.t.test（data_2tp_s_c_w $ exha_m， 
                                    data_2tp_s_c_w $ group_timepoint， 
                                    p. adjust.Method =; holm＆quot;）
 
我很想从以前做过类似事情的人那里获得一些指导，要么听到他们所做的事情 /我应该做的事情有所不同，要么得到我的工作是有道理的。&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/662630/how-do-i-calculate-a-repeated-measures-manova-in-r</guid>
      <pubDate>Fri, 14 Mar 2025 11:50:47 GMT</pubDate>
    </item>
    <item>
      <title>与自相关和部分自动相关的时间序列</title>
      <link>https://stats.stackexchange.com/questions/662587/time-series-with-autocorelation-and-partial-autocorelation</link>
      <description><![CDATA[我正在使用时间序列数据，其中每天由包含24×25网格的CSV文件表示，每个条目都充当像素。
我已经生成了ACF和PACF来了解我的数据的时间结构，并且整天都使用了第一个功能：
 导入statsmodels.api as s sm
导入matplotlib.pyplot作为PLT

系列= data_flatted [：，0]＃整天使用第一个功能
图，轴= plt.subplot（2，1，无花果=（10，8））
sm.graphics.tsa.plot_acf（系列，滞后= 50，ax = axes [0]）
sm.graphics.tsa.plot_pacf（系列，滞后= 50，ax = axes [1]）
plt.show（）
 
我的输出：
对于 lags = 50  
  对于 lags = 100  
  对于 lags = 150  
  对于 lags = 250  
  对于 lags = 500  
  对于 lags = 900  
  从上面的图像中，我会说短/长滞后时的强大ACF相关性表明时间依赖性很大？
或
我的意思是问我的数据集有任何重复模式或趋势？
或
所有数据点都可能遵循一些简单的确定性线性结构方程，并具有一些小的白噪声？
或我的数据集中存在强大的时间依赖性？]]></description>
      <guid>https://stats.stackexchange.com/questions/662587/time-series-with-autocorelation-and-partial-autocorelation</guid>
      <pubDate>Fri, 14 Mar 2025 00:47:24 GMT</pubDate>
    </item>
    </channel>
</rss>