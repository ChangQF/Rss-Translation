<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 04 Jul 2024 03:18:40 GMT</lastBuildDate>
    <item>
      <title>模糊集定性比较分析（fsQCA）的结果可以是清晰集吗？</title>
      <link>https://stats.stackexchange.com/questions/650443/can-the-outcome-of-a-fuzzy-set-qualitative-comparative-analysis-fsqca-can-be-a</link>
      <description><![CDATA[例如，我旨在分析年龄、智商和其他影响个人是否上大学的变量等因素。使用 fsQCA 并将结果变量编码为 1 或 0 是否合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/650443/can-the-outcome-of-a-fuzzy-set-qualitative-comparative-analysis-fsqca-can-be-a</guid>
      <pubDate>Thu, 04 Jul 2024 02:55:16 GMT</pubDate>
    </item>
    <item>
      <title>我应该进行多长时间的训练才能了解 NN 模型的运行情况？</title>
      <link>https://stats.stackexchange.com/questions/650442/how-long-should-i-run-a-training-to-realize-how-well-an-nn-model-is-doing</link>
      <description><![CDATA[假设我正在手动调整 NN 模型的超参数。
在停止训练之前，我应该至少运行多少个训练周期才能意识到模型无法提供我所需的准确率？
例如，如果训练开始时的准确率是 75%，那么我不能指望它在 1000 个训练周期后达到 90%。可以吗？
那么，我应该如何运用我的直觉？]]></description>
      <guid>https://stats.stackexchange.com/questions/650442/how-long-should-i-run-a-training-to-realize-how-well-an-nn-model-is-doing</guid>
      <pubDate>Thu, 04 Jul 2024 02:42:55 GMT</pubDate>
    </item>
    <item>
      <title>如何从等级中创建等级？</title>
      <link>https://stats.stackexchange.com/questions/650441/how-to-create-a-rank-from-ranks</link>
      <description><![CDATA[我已根据每列的条件计算了每行的排名。现在我有，
 col1 col2 col3
item 1 2 1 2
item 2 3 2 1
item 3 1 3 3

等等。 

每列的权重相等。我尝试求平均值和总和，但结果相同，最终排名也相同。有没有办法获得唯一的排名？我看到过类似的问题，但找不到任何一致的解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/650441/how-to-create-a-rank-from-ranks</guid>
      <pubDate>Thu, 04 Jul 2024 02:21:27 GMT</pubDate>
    </item>
    <item>
      <title>计算双自然对数拟合的误差</title>
      <link>https://stats.stackexchange.com/questions/650440/calculating-error-on-a-double-natural-log-fit</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650440/calculating-error-on-a-double-natural-log-fit</guid>
      <pubDate>Thu, 04 Jul 2024 02:05:50 GMT</pubDate>
    </item>
    <item>
      <title>最可能结果的可能性有一个名称吗？</title>
      <link>https://stats.stackexchange.com/questions/650439/is-there-a-name-for-the-likelihood-of-the-most-likely-outcome</link>
      <description><![CDATA[在流行统计学中，通常会将最可能的结果描述为非常有意义的属性。
但是，如果不知道最可能的结果有多大可能性，那么它实际上就没有那么大的意义。
例如，在四次抛硬币中，最可能的结果是一半正面，一半反面，
但实际得到该结果的可能性只有 37.5%；近三分之二的时间会是其他结果。
随着硬币数量的增加，最可能的结果不会改变，但实现该结果的可能性接近于零。
也就是说，最有可能发生的事件可能非常不可能。
这似乎是几乎从未提及的事情，但是这个最可能的结果有多（不）可能的概念有名字吗？
（可以针对期望值提出类似的问题。）]]></description>
      <guid>https://stats.stackexchange.com/questions/650439/is-there-a-name-for-the-likelihood-of-the-most-likely-outcome</guid>
      <pubDate>Thu, 04 Jul 2024 00:35:03 GMT</pubDate>
    </item>
    <item>
      <title>生存分析中以年龄为时间尺度的基线协变量</title>
      <link>https://stats.stackexchange.com/questions/650437/baseline-covariates-with-age-as-time-scale-in-survival-analysis</link>
      <description><![CDATA[我正在寻找以年龄为时间尺度的生存分析中纳入基线信息的正确方法（或确认我下面所说的是正确的）。
显然，如果您将原点设置为出生，那么协变量信息在那时将不可用。因此，另一种选择可能是确定感兴趣的最低年龄 - 例如 20 岁，将其设置为原点，然后对任何年龄超过 20 岁进入研究的人进行延迟进入和左截断。
我有两个与此相关的问题：

这依赖于拥有 20 岁时每个人的协变量信息，对吗？即，如果有人在 26 岁时进入研究，那么使用该年龄的协变量值作为基线是不正确的？如果您只有这些，您可以做些什么？
将每个人的年龄居中是否合适/必要？即从每个年龄中减去 20，这样“新”基线就是零？

另外，我还想知道当使用年龄作为时间尺度时，倾向得分匹配的含义是什么。
谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/650437/baseline-covariates-with-age-as-time-scale-in-survival-analysis</guid>
      <pubDate>Wed, 03 Jul 2024 23:03:02 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型、负信息标准值和 Hessian 矩阵不是正定的？</title>
      <link>https://stats.stackexchange.com/questions/650431/linear-mixed-model-negative-information-criteria-values-and-hessian-matrix-not</link>
      <description><![CDATA[我正尝试在 R 中执行此操作。
glmm_res &lt;- glmer(Chla ~ Temp + Sal + TP + Pluviometry + (1 | season) + (1 | river), data = Chla_model, family = poisson)
summary(glmm_res)

我收到以下消息：
通知消息：
1：在 vcov.merMod(object, use.hessian = use.hessian) 中：
根据有限差分 Hessian 计算的方差-协方差矩阵
不是正定的或包含 NA 值：回退到从 RX 估计的 var-cov
2：在 vcov.merMod(object, correlation = correlation, sigm = sig) 中：
根据有限差分 Hessian 计算的方差-协方差矩阵有限差分 Hessian 不是正定的或包含 NA 值：回退到从 RX 估计的 var-cov

在中心化和缩放数据 scale(Chla_model[,2:15],center = T, scale = T) 甚至标准化 normalize(Chla) 之后，消息始终相同。
以下是汇总数据：
Chla_model &lt;- read.csv(&quot;D:/Article Sediment/ACP en langage R/Chla_model.csv&quot;, sep=&quot;;&quot;, stringsAsFactors=TRUE)
str(Chla_model)

&#39;data.frame&#39;: 45 obs. 16 个变量中的 16 个变量：
$ 季节：因子，3 个级别“干旱”、“洪水”等：1 1 1 1 1 1 1 1 1 1 ...
$ 温度：数字 30 28.9 29.8 30 30.7 31.1 32.7 33.3 31 31.7 ...
$ EC：数字 61 126 64 67 74 ...
$ DO：数字 5.59 3.55 3.96 2.74 2.58 5.62 3.37 6.24 4.57 5.14 ...
$ pH：数字 7.6 6.5 7.3 6.8 6.8 7.7 7 8 7.5 7 ...
$ 盐：数字0.0268 0.0579 0.0282 0.0297 0.0314 0.0302 0.0574 0.0345 0.0423 0.0975 ...
$ TP：数量 0.15 0.43 0.09 0.16 0.15 0.09 0.17 0.05 0.65 1.59 ...
$ PO43.：数量 0.08 0.09 0.04 0.04 0.02 0.04 0.02 0.04 0.09 0.09 ...
$ NO3. ：数量 1.4 0.95 0.34 0.17 0.23 0.21 0.25 0.8 1.07 1.15 ...
$ TN ：数量 2.43 1.84 2.39 0.74 2.41 0.37 0.69 1.31 1.96 1.85 ...
$ NH4. ：数字0.06 0.05 0.08 0.03 0.08 0.05 0.1 0.07 0.05 0.04 ...
$ NO2。 : 数值 0.011 0.005 0.019 0.015 0.018 0.013 0.02 0.02 0.012 0.014 ...
$ Chla : 数值 29.84 55.49 18.63 18.72 2.71 ...
$ 排放量 : 数值 9.5 9.5 9.5 9.5 9.5 72.3 72.3 72.3 72.3 72.3 ...
$ 雨量测定法 : 数值 115 115 115 115 115 ...
$ 河流 : 因子 w/3 个级别 “Bandama”、“Bia”、..: 3 3 3 3 3 1 1 1 1 1 ...

我欢迎您提供任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/650431/linear-mixed-model-negative-information-criteria-values-and-hessian-matrix-not</guid>
      <pubDate>Wed, 03 Jul 2024 19:13:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么置信区间有效？[重复]</title>
      <link>https://stats.stackexchange.com/questions/650430/why-are-confidence-intervals-valid</link>
      <description><![CDATA[最近，我开始了我的统计学之旅，以便更好地了解该领域。以前，我的统计学经验包括记住公式、条件和后者的应用。虽然人们常常可以摆脱这种肤浅的理解，但我忽略了大多数统计实践背后的直觉。
特别是，我开始质疑置信区间的数学价值。我的理论理解如下。任何置信区间的基础都是抽样分布的概念，这是一种理论分布，我们将样本统计量纳入每个可能的大小为 n 的样本；该分布的平均值是真实的总体参数。从那里，我们选择一个所需的置信水平（用 t 或 z 值表示），并使用我们的理论抽样分布的标准差，我们构建一个区间。根据定义，我们的置信水平将表示来自我们的样本分布的总样本的百分比，这些样本在真实总体统计量的误差范围内。换句话说，如果我们要重复收集大小为 n 的样本并构建相同置信水平的置信区间，我们会预期这些区间中的 $C%$% 将捕获真实的总体参数。
从理论上讲，数学是可行的。但在实践中，我们所做的事情与这一理论基础背道而驰。我将说明三种我有疑问的情况：
例如，假设我们试图为总体比例创建置信区间。比例的中心极限定理和数学推理使我们得出结论，对于足够大的大小为 n 的样本，抽样分布呈正态分布，其平均值为 $p$，标准差为 $\sqrt(\frac{p(1-p)}{n})$。理论上，如果我们采用 $\hat{p}$ 并使用我们期望的置信度和上面概述的标准差创建一个区间，我们会预期这些区间中的 $C%$% 将捕获真实的总体参数。但是，我们没有这样做，因为我们不知道 $p$ 是什么，因此不知道抽样分布的标准差。相反，我们使用 $\hat{p}$ 作为标准差方程中的替代：$\sqrt(\frac{\hat{p}(1-\hat{p})}{n})$。即使我知道 $\hat{p}$ 是 $p$ 的无偏估计量，我们怎么能确定 $C%$% 的假设区间将捕捉到真实的总体参数呢？
当然，在估计总体平均值时，我也有同样的疑问。比例的中心极限定理和数学推理使我们得出结论，对于足够大的样本 n，抽样分布呈正态分布，其平均值为 $\mu$，标准差为 $\frac{\sigma}{\sqrt(n)}$。理论上，如果我们采用 $\bar{x}$ 并使用我们期望的置信度和上面概述的标准差创建一个区间，我们会预期这些区间中的 $C%$% 将捕获真实的总体参数。但是，我们不会这样做，因为我们通常不知道 $\sigma$ 是什么，因此不知道抽样分布的标准差。在这些情况下，我们使用标准误差来近似标准差：$\frac{s_x}{\sqrt(n)}$。鉴于这一变化，我们如何确保 $C%$% 的假设区间能够捕捉到真实的总体参数？
对于更一般的情况，中心极限定理可能不适用，统计学家使用引导法来计算置信区间。总之，他们从原始大小为 n 的样本中创建许多大小为 n 的有放回样本。通过绘制每个样本的样本统计量，我们可以创建一个伪抽样分布。从那里，我们可以通过选择与第 50 个百分位数等距的两个百分位数来创建置信区间。例如，创建一个间隔，其中第 5 个和第 95 个百分位数的值代表 90% 的置信区间。然而，这似乎是一个很大的延伸。也就是说，我们假设伪分布的标准差是我们真实抽样分布的标准差。我们如何确保$C%$% 的假设区间能够捕捉到真实的总体参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/650430/why-are-confidence-intervals-valid</guid>
      <pubDate>Wed, 03 Jul 2024 18:57:10 GMT</pubDate>
    </item>
    <item>
      <title>在双变量线性回归中，为什么 $Y = \alpha X + \beta + U$，其中 $\alpha$ 和 $\beta$ 是实常数，而 $U$ 是一个假设？</title>
      <link>https://stats.stackexchange.com/questions/650429/in-a-bivariate-linear-regression-why-is-y-alpha-x-beta-u-where-alpha</link>
      <description><![CDATA[假设我想对随机变量$Y$和$X$之间进行双变量回归。在我所阅读的教科书中，主要是 Jeffrey Wooldridge 所著的《计量经济学导论》和 Davidson 与 Mackinnon 所著的《计量经济学中的估计与推断》，其中我们假设 $Y$ 和 $X$ 是线性相关的：$Y = \alpha X + \beta + U $ 其中 $\alpha \text{ and } \beta$ 是实常数，而 $U$ 是被称为误差或扰动的随机变量。我不太明白为什么用 $X$ 来表示 $Y$ 必然是一种假设。似乎我们总是能够用 $X$ 来表示 $Y$，这仅仅是由于对随机变量的算术运算。
我的意思是：从线性代数的角度来看，让我们考虑在公共样本空间 $S$ 上定义的所有实值随机变量的集合，并假设 $Y$ 和 $X$ 属于 $S$。 $S$ 是一个向量空间，前提是标量乘法和向量加法以标准方式定义，因此，对于任何实数 $\alpha$ 和 $\beta$，我们有 $\alpha X + \beta$ 也属于 $S$，并且 $Y$ 与 $\alpha X + \beta$、$Y - \left( \alpha X + \beta \right)$ 之间的差值也位于 $S$ 中。将该差值称为 $Y - \left( \alpha X + \beta \right) = U .$，因此 $Y = \alpha X + \beta + U $。我不明白我们实际上“假设”了什么，除了 $Y$ 和 $X$ 是在公共样本空间中定义的随机变量，但这似乎很简单。我明白，如果我们指定一个标准，例如最小化 $Y$ 和 $\alpha X + \beta$ 之间的 MSE，那么我们就会得到 $\alpha \text{ and } \beta$ 必须是什么。但简单地用 X 线性表示 Y 似乎不是一个假设。我听说真正的关系可能不是，而且通常不是真正线性的，因为 Y = $\alpha X + \beta$ 其中 $U$ 等于零，我明白了。但是我不明白我如何仅通过用 $X.$ 来表达 $Y$ 就假设了任何有关真实关系的事情。我误解了什么吗？我在其他地方问过这个问题，人们断言方程式 $Y = \alpha X + \beta + U$ 是关于 $Y$ 和 $X$ 之间关系的断言，但我就是不明白为什么。任何帮助都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/650429/in-a-bivariate-linear-regression-why-is-y-alpha-x-beta-u-where-alpha</guid>
      <pubDate>Wed, 03 Jul 2024 18:51:54 GMT</pubDate>
    </item>
    <item>
      <title>将相关性与概率联系起来</title>
      <link>https://stats.stackexchange.com/questions/650427/relating-correlation-to-probabilities</link>
      <description><![CDATA[给定两个中心化且经过缩放的随机变量 $X$ 和 $Y$，您能将它们具有相同符号的概率与它们的相关性联系起来吗？如果相关性接近 $1$，我设想平面中的联合分布主要集中在第一象限和第三象限，其中 $X$ 和 $Y$ 具有相同的符号。情况总是如此吗？是否存在反例，其中相关性接近 $1$，但具有相同符号的概率很低？那么是否存在界限？]]></description>
      <guid>https://stats.stackexchange.com/questions/650427/relating-correlation-to-probabilities</guid>
      <pubDate>Wed, 03 Jul 2024 18:27:44 GMT</pubDate>
    </item>
    <item>
      <title>回归的预处理数据：仅缩放/标准化联合观测，还是分别缩放/标准化回归量和回归对象观测？</title>
      <link>https://stats.stackexchange.com/questions/650420/preprocessing-data-for-regression-scale-normalize-only-joint-observations-or-r</link>
      <description><![CDATA[假设您观察到两个变量$X, Y$（回归量和回归函数），它们在统计上是相关的，$Y \sim X$。
您的数据是独立同分布样本$\mathcal{D}:=\{(x_j, y_j) \mid j=1,\ldots, N\}\subset \mathbb{R}^ {d_X}\!\!\times\!\mathbb{R}^{d_Y}$ of $(X,Y)$。
然后，您想对这些数据应用某种回归方法，比如核岭回归或 SVR。
为此，通常建议对数据样本进行预处理$(x_j)$ 和 $(y_j)$ 可以通过对它们进行归一化或标准化来量化。
问题：这样的标准化/归一化是否会应用于联合观测值$\{(x_j, y_j)\}$（的子集），或者组件数据$(x_j)$ 和 $(y_j)$ 是否应该分别缩放？
由于关联$Y\sim X$ 非常非线性（例如$Y = e^X + \varepsilon$ 或类似），分别预处理 $(x_j)$ 和 $(y_j)$ 似乎是有问题的，因为分别对回归对象和回归量样本应用不同的（$(x_j)$- 和 $(y_j)$-依赖）尺度可能会对统计关联 $Y\sim X$ 造成非平凡的干扰。
很高兴看到相关文献或任何最佳实践的链接。]]></description>
      <guid>https://stats.stackexchange.com/questions/650420/preprocessing-data-for-regression-scale-normalize-only-joint-observations-or-r</guid>
      <pubDate>Wed, 03 Jul 2024 16:49:03 GMT</pubDate>
    </item>
    <item>
      <title>计算百分比标准化</title>
      <link>https://stats.stackexchange.com/questions/650415/calculating-percentage-normalisation</link>
      <description><![CDATA[请不要笑或关闭这篇文章，我对如何计算治疗后发生的正常化百分比感到困惑。
所以，这是问题的背景，我从用药物 A 和 B 治疗的对照和患病样本中读取了数据。读数是在药物的两个时间点，即时间 0 和时间 x。这些记录在下表中。
 基因控制 DrugA.to DrugA.tx DrugB.to DrugB.tx
GeneA1 0.255137598 0.996823656 0.841427508 0.838585838 0.637163007
GeneA2 0 1.002128241 1.088924271 0.708817547 0.858001516
GeneA3 0.649779583 0.970614468 0.883699106 0.863034514 0.863533489
GeneA4 0.261785973 1.228567772 0.860292411 0.950751742 1.026950264
基因A5 0 0.964363461 1.177734151 0.831123556 1.496702315
基因A6 0.539853517 1.185978246 0.999361733 0.88790566 0.926980252
基因A7 0.609842771 1.245618868 1.095380831 0.91075683 1.038654277
基因A8 0.546278983 1.143557146 1.31081493 0.961478462 0.955452931
基因A9 0.278067545 1.565468159 1.2463365 1.039837814 0.961697678
基因A10 0.841483131 1.637659304 1.195102944 1.171462249 1.274326013
基因A11 1.066410285 1.40104267 1.200123252 0.957711736 1.525794178
基因A12 2.613408631 1.052950881 0.908745691 0.863034514 0.892767429
基因A13 2.583216456 1.105396939 1.242388547 0.87318548 0.623271818
基因A14 2.800415579 1.097795107 0.999763993 0.893300428 0.863533489
基因A15 1.044277784 1.534601183 1.213267026 1.08889909 1.797417187
GeneA16 0 2.476333854 2.055473655 1.021699805 1.138185985
GeneA17 1.861254616 1.147626264 1.72825638 1.009700622 0.963547498
GeneA18 0.850735068 2.07213776 1.675176397 1.352168483 1.026950264
GeneA19 2.784079193 1.097795107 1.03334891 0.863034514 1.246543636
GeneA20 0.600378056 1.55167128 1.837088792 1.116134855 2.35125585
GeneA21 0.789140187 2.195590214 2.109625834 1.322807345 1.200786951
GeneA22 0.560671399 1.559604269 2.014979635 1.634260415 1.910905861
GeneA23 3.176300908 1.200678944 1.406041611 0.890985128 1.200293773
GeneA24 1.959958568 1.747658569 1.31081493 1.394319133 1.533792282
GeneA25 1.815692 1.933923319 1.221955458 1.08889909 1.971098865
GeneA26 2.918198494 1.2461771 1.847890057 0.998327027 1.200786951

现在我如何显示和/或计算药物 A或者药物 b 使基因表达更接近对照。我所说的“接近对照”是指，治疗后，时间 x 处的基因表达要么减少，要么增加，但其方向与对照方向一致，例如，GeneA1 在对照中的表达为 0.25，而在用药物 A 治疗的患病样本中，表达减少了 15.15% ((0.84-0.99)/0.99)，而用药物 B 治疗的表达减少了 24%。因此，对于基因 A，可以说药物 B 使基因表达更接近对照。现在，我想计算药物 A 和 B 的总体效果，而不是单个基因。
我可以计算每种药物每个基因的倍数变化或百分比倍数变化，但我如何显示哪种药物使基因表达更趋向于控制。
我脑海中有一个这样的图，其中绿色和紫色是药物 A 和 B。

感谢您的时间和帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/650415/calculating-percentage-normalisation</guid>
      <pubDate>Wed, 03 Jul 2024 15:57:27 GMT</pubDate>
    </item>
    <item>
      <title>对于动物袭击记录的时间序列，最佳的混合模型方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/650402/what-is-the-best-mixed-model-approach-for-a-time-series-of-animal-attack-records</link>
      <description><![CDATA[我有 2007 年至 2022 年巴西各州动物袭击记录的数据集。我有三个解释变量，它们已标准化以用于分析。为了将数据的时间自相关性纳入混合模型，我考虑使用具有泊松分布（计数数据）的 glmmPQL（MASS 包）。由于此分析不允许获取 AIC 值，因此我考虑通过目视检查残差来评估模型的最佳自相关结构。模型的结构如下。我使用 r.squaredGLMM 函数获得了 R^2 值，但它给出了两个不同的 R^2 值（见下文）。因为这是我第一次使用具有时间自相关的混合模型，所以我想知道我是否朝着正确的方向前进。
模型 &lt;- glmmPQL(attacks~x1 + x2 + x3,random=~1|ID,data=envir,family=poisson, correlation=corGaus(form = ~ year|ID))
###“ID”代表巴西各州，“年份”代表表示每年（2007-2022 年）和每个州的袭击次数。
plot(model)#检查残差
r.squaredGLMM(model)#package MuMIn
 R2m R2c

delta 0.6348790 0.9995354
lognormal 0.6348793 0.9995358
trigamma 0.6348788 0.9995350]]></description>
      <guid>https://stats.stackexchange.com/questions/650402/what-is-the-best-mixed-model-approach-for-a-time-series-of-animal-attack-records</guid>
      <pubDate>Wed, 03 Jul 2024 14:46:02 GMT</pubDate>
    </item>
    <item>
      <title>关联替代方案/如何测试这种关系？</title>
      <link>https://stats.stackexchange.com/questions/650425/correlation-alternatives-how-to-go-about-testing-this-relationship</link>
      <description><![CDATA[我有来自上游和下游测量仪的大量温度数据。我试图找出大坝泄水对下游温度的影响。为此，我正在比较尾水测量仪（位于大坝正下方）与各个下游站点之间的相关性。这是我的数据集。
&gt; dput(head(TravelTimeAdjustedSaltData))
结构(列表(日期 = 结构(c(1709942400, 1709943300, 1709944200, 
1709945100, 1709946000, 1709946900), 类 = c(&quot;POSIXct&quot;, &quot;POSIXt&quot;
), tzone = &quot;UTC&quot;), S1 = c(12.824443359375, 12.824443359375, 12.824443359375, 
12.824443359375, 12.824443359375, 12.78154296875), S2 = c(12.86734375, 
12.86734375, 12.86734375, 12.910244140625, 12.86734375, 12.824443359375
), S3 = c(12.223837890625, 12.223837890625, 12.26673828125, 12.26673828125, 
12.223837890625, 12.26673828125), S4 = c(NA, NA, NA, NA, 7.8908984375, 
7.847998046875), S5 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S6 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S7 = c(NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_, NA_real_), S8 = c(12.309638671875, 12.309638671875, 
12.26673828125, 12.3525390625, 12.3525390625, 12.309638671875
), S9 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_
), S10 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_), S11 = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, 
NA_real_), GaugeTemp = c(8.2, 8.2, 8.2, 8.2, 8.2, 8.2), GaugeHeight = c(70.83, 
70.84, 70.84, 70.85, 70.83, 70.83)), row.names = c(NA, 6L), class = c(&quot;tbl_df&quot;, 
&quot;tbl&quot;, &quot;data.frame&quot;))

数据根据下游水流的流动时间进行了调整，这就是为什么某些列的前几行有 NA。无论如何，我进行了 Spearman 相关性分析，但发现了一种意料之外的模式，因此，我认为相关性并没有真正检验出我真正想要发现的东西。我发现，下游站点 (S10 / S11) 与尾水水位计的相关性实际上比下游第一个站点 (S4) 更高或大致相同。我同时包含了 S4（距离尾水下游最近的站点）和 S11（距离尾水最远的站点）来说明我的意思。事实并非如此，因为大坝泄水对下游温度的影响应该会随着距离的增加而减小。这让我相信相关性测试不是我的问题的答案。


cor.test(TravelTimeAdjustedSaltData$GaugeTemp, TravelTimeAdjustedSaltData$S11, method = &quot;spearman&quot;, na.rm=TRUE)
cor.test(TravelTimeAdjustedSaltData$GaugeTemp, TravelTimeAdjustedSaltData$S4, method = &quot;spearman&quot;, na.rm=TRUE)
我不知道如何测试大坝泄洪的原因（即尾水压力表温度读数）及其影响（下游温度读数）。我正在研究两者之间的某种非参数回归，但不确定这是否是正确的方法。任何帮助都将不胜感激。我只是想要一种统计方法来显示大坝泄洪是否确实对下游产生影响。相关性似乎没有达到这个目的（虽然不确定为什么）。]]></description>
      <guid>https://stats.stackexchange.com/questions/650425/correlation-alternatives-how-to-go-about-testing-this-relationship</guid>
      <pubDate>Wed, 03 Jul 2024 13:20:19 GMT</pubDate>
    </item>
    <item>
      <title>BFAST Lite 算法中的稳定期：应该持续多长时间？</title>
      <link>https://stats.stackexchange.com/questions/650334/stable-period-in-the-bfast-lite-algorith-how-long-should-it-be</link>
      <description><![CDATA[我即将使用 BFAST Lite 算法执行卫星时间序列分析 (STSA)。我必须指定的参数之一是稳定期的长度（时间序列数据中假定没有重大结构变化的时间段）。
我即将使用的数据是 2013 年至 2023 年的每月卫星夜间灯光 (NTL)。从基本的目视检查中，我发现在 2014 年，我的研究区域变亮了，而在 2019 年变暗了（由于 COVID？）。问题是我想使用 2013 年至 2018 年作为稳定期，但现在不能。
如果我使用它们，算法不会识别出 2019 年的中断（如果我缩短稳定期的长度，我还没有测试该方法的行为）。
我的问题是：BFAST 方法中较小的稳定期有什么好处和缺点？有推荐的时间长度吗？我打算使用 2018-2023 年期间的数据。
注意：BFAST Lite 需要至少 4 年的数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/650334/stable-period-in-the-bfast-lite-algorith-how-long-should-it-be</guid>
      <pubDate>Tue, 02 Jul 2024 16:00:12 GMT</pubDate>
    </item>
    </channel>
</rss>