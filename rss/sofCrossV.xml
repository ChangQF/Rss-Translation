<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 05 Mar 2024 12:23:34 GMT</lastBuildDate>
    <item>
      <title>自定义 pytorch DataFrame 时 pandas 发出警告</title>
      <link>https://stats.stackexchange.com/questions/641884/warning-in-pandas-when-customizing-pytorch-dataframe</link>
      <description><![CDATA[我正在编写一个自定义（但简单）数据集，用于使用 PyTorch 训练 MLP。基本上，我的数据是两个类的数值向量，因此整个数据集是一个 pandas.DataFrame ，其第一列是 0 或 1 （代表两个类），其余列是向量的数值分量。由于每一行代表一个数据，我认为自然的 PyTorch 的数据集类将是：
类 MatrixDataset(数据集):
    def __init__(self, 数据: pd.DataFrame, 设备):
        self.data = 数据
        self.device = 设备

    def __len__(自身):
        返回 self.data.shape[0]

    def __getitem__(self, ind):
        行 = self.data.iloc[ind]
        x = torch.tensor(row.iloc[1:], dtype=torch.float32, device=self.device)
        y = torch.tensor(row.iloc[0], dtype=torch.float32, device=self.device)
        返回 x、y

实际上，这个数据集工作正常，但我收到以下警告
/path_to_my_script/script.py：FutureWarning：Series.__getitem__ 将键视为位置已被弃用。在未来的版本中，整数键将始终被视为标签（与 DataFrame 行为一致）。要按位置访问值，请使用 `ser.iloc[pos]`
  x = torch.tensor(row.iloc[1:], dtype=torch.float32, device=self.device)

搜索完这个警告后，我仍然不明白为什么它会触发，因为很多人都说这个警告是不言自明的：“使用 .iloc 方法”，但我已经在使用它了。此外，我尝试在终端中使用 Python 解释器复制该错误，但它没有触发。
如有任何帮助，我们将不胜感激，提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/641884/warning-in-pandas-when-customizing-pytorch-dataframe</guid>
      <pubDate>Tue, 05 Mar 2024 12:17:05 GMT</pubDate>
    </item>
    <item>
      <title>使用统计软化逻辑含义</title>
      <link>https://stats.stackexchange.com/questions/641882/softened-logical-implication-using-statistics</link>
      <description><![CDATA[在机器学习应用程序中，我有以下布尔含义 $$\forall\,x,y:I_b(x,y)\rightarrow E_b(x,y), $$ 其中 $I_b(x,y)$ 为 true 意味着 $x$ 并且$y$ 是同构的，并且 $E_b(x,y)$ 为 true 意味着之间的距离$x$ 和 $y$ 模型生成的嵌入为零。
现在，我想通过引入 $I(x,y)$ 来软化这种条件，它现在是 $x$ 和 $y$ 使得 $I(x, y)$$x$ 和 $y$ 同构时，&gt; 为 0，而该数较小且为正数“几乎”同构 $x&#39;$ 和 $y&#39;$，对于其他情况则较大且为正值。我还将介绍 $E(x,y)$，它只是 $L_2$ 距离在 $x$ 和 $y$ 的嵌入之间。有了这个，我仍然可以声明 $$\forall\,x,y:\text{Low } I(x,y)\rightarrow\text{Low }E(x, y).$$ 我有 $I(x,y)$ 和 $E( x,y)$ 对于我的所有 $x$ 和 $y$ 对数据集。我如何以统计方式验证上述含义在我的数据集中是否成立。
我想过使用相关性，但相关性是对称的，而含义是单向的。另外，我知道我必须对 $I(x,y)$ 和 $E(x ,y)$ 也使它们成为布尔值，但是这个阈值如何影响含义的真实性？我不知道如何解决最后一个问题。我还在 x- 上绘制了 $I_{\text{similarity}}(x,y)=e^{-I(x,y)}$ 的值axis 和 y 轴上的 $E(x,y)$ （因为我的同事计算了 $I_{\text{similarity }}(x,y)$ 而不是原始的 $I(x,y)$），我应该看到与 $I_\text{相似度}(x,y)$ 和 $E(x,y)$，但是我现在无法理解该图表。
任何解决此问题的方向都值得赞赏。
]]></description>
      <guid>https://stats.stackexchange.com/questions/641882/softened-logical-implication-using-statistics</guid>
      <pubDate>Tue, 05 Mar 2024 11:02:18 GMT</pubDate>
    </item>
    <item>
      <title>在纵向线性混合模型中根据 t 分数计算 Cohen d 的有效性</title>
      <link>https://stats.stackexchange.com/questions/641878/validity-of-calculating-cohens-d-from-t-score-in-longitudinal-linear-mixed-mode</link>
      <description><![CDATA[我正在使用纵向线性混合模型分析来自试点研究的一些数据。由于心理学中的惯例，为了可解释性，通常在 Cohen 的 $d$ 中报告效果大小。我发现这篇文章让我了解了 EMAtools 包和函数 lme.dscore()。
为了帮助澄清我的问题，它可能有助于描述我想要描述的数据结构和效应大小的类型。我对 20 名患者进行了为期 10 周的随访，每周进行评分。我想描述组内变化效应的大小。使用 lme4 包，我对模拟数据进行了建模，如下所示：lmer(y ~weeks + (weeks | id), data = df)，因此随机截距和随机斜率以及时间/周的固定效应。
模拟数据的直观描述也可能有助于澄清：

以下是 20 名模拟个体在 10 周内的随机效应示例（随机截距和斜率）。
我想用$d$来描述固定效应。 lme.dscore() 函数似乎使用以下公式：
$$d=\frac{2t}{\sqrt{df}}$$
我在从简单的 t 检验中提取 Cohen d 的背景下很熟悉，但我不确定它在这种情况下是否有意义？
为了进行比较，我的一位同事引用了Feingold (2013) 并使用了一个如下所示的公式（如果我解释正确的话）：
$$d=\frac{b*duration}{SD_{pre}}$$
这两种方法会产生截然不同的估计，并且可能存在很大差异。例如，lme.dscore() 方法更容易受到斜率方差的影响，而 Feingold 方法几乎不会受到影响 - 只要斜率的平均效果 $b$ 与方法产生相同的 d 分数相同。如果我们将效应大小视为个体进步概率的衡量标准，这对我来说似乎很奇怪。就效果的确定性而言，斜率之间具有低变异性的情况似乎与斜率之间具有高变异性的情况有所不同。 （或者换句话说，个体内相关性，或者在更简单的设置前后相关性中，不应该影响估计吗？）
很高兴了解转换为 $d$ 的方法是否存在问题，或者至少有人为我指明了正确的方向。我目前正在学习 Feingold 方法，因为我的同事在那里工作有先例。]]></description>
      <guid>https://stats.stackexchange.com/questions/641878/validity-of-calculating-cohens-d-from-t-score-in-longitudinal-linear-mixed-mode</guid>
      <pubDate>Tue, 05 Mar 2024 10:26:09 GMT</pubDate>
    </item>
    <item>
      <title>如何确定系统是否平衡？</title>
      <link>https://stats.stackexchange.com/questions/641876/how-can-i-determine-if-a-system-is-equilibrated</link>
      <description><![CDATA[交叉发布于SCSE和MMSE
我正在尝试新的 MCMC 协议和新的研究。
在蒙特卡罗模拟的背景下，“平衡状态”指被模拟的系统已达到稳定配置或属性分布且不会随时间显着变化的情况。这种状态代表作用于系统的各种力、相互作用和约束之间的平衡或平衡。
我编写了以下函数来测试系统是否平衡：
将 numpy 导入为 np

def is_equilibrate(数据, shave_size=50000):
    返回 = 假
    mid_index = len(数据) // 2

    第一个半 = 数据[:mid_index]
    第二半=数据[中间索引：]

    小数 = 6

    而真实：
        first_auto_corr = np.correlate(first_half,first_half,mode=&#39;full&#39;)
        secondary_auto_corr = np.correlate(second_half, secondary_half, mode=&#39;full&#39;)

        corr1 = np.corrcoef(first_auto_corr, secondary_auto_corr)[0, 1]

        print(f&quot;大小 {len(first_half)} 与 {len(second_half)}&quot;)
        打印（f“corr = {corr1}”）

        第一半=第一半[剃须尺寸：]
        第二半=第二半[剃须尺寸：]

        如果 corr1 == 1.0：
            休息

    返回返回

该函数迭代地比较输入数据两半的自相关性，在每次迭代时缩短数据集，直到两半之间实现完美的相关（平衡）或直到手动终止循环。
我编写这个函数是为了检查我的模拟数据是否“成熟”足以进行分析，即足以通过计算提取更多信息。换句话说，它让我知道我运行模拟的时间是否足够长以获得有用的数据集。
该算法的缺点是它使用自相关计算，无论使用哪种编程语言，都会花费大量时间。
您能提出任何替代技术吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/641876/how-can-i-determine-if-a-system-is-equilibrated</guid>
      <pubDate>Tue, 05 Mar 2024 09:49:47 GMT</pubDate>
    </item>
    <item>
      <title>使用随机梯度下降的 Huber-Loss 优化来估计回归线的截距和系数</title>
      <link>https://stats.stackexchange.com/questions/641875/huber-loss-optimisation-using-stochastic-gradient-descent-to-estimate-intercept</link>
      <description><![CDATA[内容：我正在尝试从头开始使用随机梯度下降来最小化线性回归的 Huber 损失。
问题：似乎系数$m$没有得到优化，因此拟合线与OLS回归线相差甚远仅供参考。
期望：优化系数导致拟合回归线接近参考 OLS 回归线。
说明：Huber-Loss 定义为
$$ L_{\delta}(a) = \begin{array}{l}\frac{1}{2}a^2 \quad \textrm{for} \quad \ vert a \vert \leq \delta \\
\delta (\vert a \vert - \frac{1}{2}\delta) \quad \textrm{否则} \end{array} $$
变量 $a$ 指的是残差 $a = y - \hat{y}$，这意味着线性回归：$a = y - (mx+n)$。要使用随机梯度下降，需要对系数 $m$ 和截距 $n$ 求偏导数&gt; 必须计算：
$$\nabla L_{\delta}(m, n, y) = \left[\begin{array}{l}
\dfrac{\partial L}{\partial m} = \begin{array}{l} -x\ (-mx+n-y)\quad \textrm{for} \quad \vert y-(mx+n) \vert \leq \delta \\
\frac{\delta x(mx+n-y)}{\vert mx+n-y \vert} \quad \textrm{否则}
 \end{数组}\\
\dfrac{\partial L}{\partial n} = \begin{array}{l} mx+n-y\quad \textrm{for} \quad \vert y-(mx+n) \vert \leq \delta \\
\frac{\delta (mx+n-y)}{\vert mx+n-y \vert} \quad \textrm{否则}
 \end{数组} \\
\end{数组}\right]$$
我通过以下方式在 R 中实现了上述内容。
grad_m_huber &lt;- 函数（

    是，
    X，
    米，
    ,
    三角洲

）{

    损失 &lt;- ifelse(
        绝对 (Y - (m * X + n)) &lt;= delta,
        -X * (-m * X - n + Y),
        (delta * X * (m * X + n - Y)) / 绝对值(n + m * X - Y)
    ）

    回报（损失）

}


grad_n_huber &lt;- 函数（

    是，
    X，
    米，
    ,
    三角洲

）{

    损失 &lt;- ifelse(
        绝对值((m * X + n) - Y) &lt;= delta,
        m * X + n - Y，
        (δ * (m * X + n - Y)) / 绝对值(m * X + n - Y)
    ）

    回报（损失）

}


huber_sgd &lt;- 函数(

    X，
    是，
    纪元,
    先生，
    批量大小，
    三角洲

）{

    m＜-0
    n &lt;- 0

    for(i in 1:epochs) {

        批次 &lt;- 样本（长度（X），batch_size）
        Y_batch &lt;- Y[batch]
        X_batch &lt;- X[批次]

        g_m &lt;- sum(grad_m_huber(Y_batch, X_batch, m, n, delta))
        g_n &lt;- sum(grad_n_huber(Y_batch, X_batch, m, n, delta))

        m &lt;- m - lr * g_m
        n &lt;- n - lr * g_n

    }

    返回（
        列表（
            grad_m = g_m,
            grad_n = g_n,
            米=米，
            n = n
        ）
    ）

}

但是当我运行增量接近 0 的 Huber-Loss 回归时，这应该会产生接近线性回归的拟合线 (ols_mod &lt;- lm(Y ~ X)) ：
set.seed(303)
Y &lt;- rnorm(550, 155, 15)
比例因子 &lt;- .27
eps &lt;- rnorm(550, 15, 5)

X &lt;- (Y * 比例因子) + eps

huber_sgd_mod &lt;- huber_sgd(
    X，
    是，
    纪元 = 5000，
    ε = .001，
    批量大小 = 1,
    增量 = .01
）

我明白了

由于绘制的损失表明 SGD 尚未收敛，因此我将纪元数更改为 epochs = 10000 并再次运行。似乎只有拦截得到了优化。

我还将我的从头开始的解决方案与通过 MASS::rlm(Y ~ X, psi = MASS::psi.huber) 计算的 Huber 回归进行了比较，后者显示了预期的结果拟合线接近 OLS 回归线。

有谁知道我在这里做错了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/641875/huber-loss-optimisation-using-stochastic-gradient-descent-to-estimate-intercept</guid>
      <pubDate>Tue, 05 Mar 2024 09:36:21 GMT</pubDate>
    </item>
    <item>
      <title>两个变量的 Logit 回归</title>
      <link>https://stats.stackexchange.com/questions/641874/logit-regression-for-two-variables</link>
      <description><![CDATA[我想知道下图中的常数-1.694是如何手工得到的。结果变量是避孕药具的使用，而预测变量是年龄组和欲望。对于单个预测变量，我只需除以使用避孕药具的女性人数并使用其中一个因素作为参考取对数即可得到常数，但在这种情况下，我不知道如何计算 2 个预测变量。我试图汇集每个变量下一个因素的所有值，但我得到 -1.51。
]]></description>
      <guid>https://stats.stackexchange.com/questions/641874/logit-regression-for-two-variables</guid>
      <pubDate>Tue, 05 Mar 2024 09:00:55 GMT</pubDate>
    </item>
    <item>
      <title>恒等式与 Haar 随机酉之间算子范数的期望</title>
      <link>https://stats.stackexchange.com/questions/641873/expectation-of-operator-norm-between-the-identity-and-haar-random-unitary</link>
      <description><![CDATA[我想评估以下期望。
$$\mathbb{E}_{U\text{~Haar}} ||I-U||$$
其中 $||\cdot||$ 是算子范数（即最大特征值）。这相当于积分
$$
\frac{1}{n!(2\pi)^n}\max_i|1-e^{i\theta_i}|\prod_{j\le k}|e^{i\theta_j}-e^{i \theta_k}|^2
$$
超过 $(\theta_i,...,\theta_n)\in[0,2\pi]^{\times n}$。
我如何计算这个积分？]]></description>
      <guid>https://stats.stackexchange.com/questions/641873/expectation-of-operator-norm-between-the-identity-and-haar-random-unitary</guid>
      <pubDate>Tue, 05 Mar 2024 08:57:25 GMT</pubDate>
    </item>
    <item>
      <title>使用校准砝码来纠正单位无响应偏差？</title>
      <link>https://stats.stackexchange.com/questions/641872/use-calibration-weights-to-correct-for-unit-non-response-bias</link>
      <description><![CDATA[我有一个关于如何使用校准权重来充分纠正单位无响应偏差的问题。假设样本为s，响应集为r。
校准应用于响应集r以生成尽可能接近原始采样权重的权重并且同时可以重现所选辅助变量的总体总数。如果辅助变量与单位响应概率和研究变量（强）相关，则将有助于纠正单位无响应偏差并减少方差。但是，我发现理解这一点并不直观。
另一种更直观的方法：首先，使用逻辑回归模型估计响应概率，然后除以估计的响应概率来更新采样权重，从而纠正单位无响应偏差；其次，使用校准进一步调整更新后的权重，以匹配某些变量的已知总体总数，从而减少方差。
总的来说，校准方法（第一种方法）似乎大大简化了过程，这让我想知道在处理单位无响应时它可能不是理想的方法。&lt; /p&gt;
任何想法或评论将不胜感激！ :)]]></description>
      <guid>https://stats.stackexchange.com/questions/641872/use-calibration-weights-to-correct-for-unit-non-response-bias</guid>
      <pubDate>Tue, 05 Mar 2024 08:53:56 GMT</pubDate>
    </item>
    <item>
      <title>将自定义（类似方差分析）对比应用于混合模型（具有堆叠数据集）中的所有交互</title>
      <link>https://stats.stackexchange.com/questions/641871/apply-custom-anova-like-contrasts-to-all-interactions-in-a-mixed-model-with-a</link>
      <description><![CDATA[我正在使用多类别 X（2×2 设计的 4 个级别）进行多级中介分析，我想应用自定义对比来编码两个主要效果和一个交互。对于具有两个指标变量（Sm 和 Sy）、数值结果（Y）和中介变量（M）的堆叠数据集，我有以下“问题”：调用 lmer 时：
下面的 model.matrix 显示 X 的对比仅应用于一个交互项 (Sy:X)，而不应用于其余交互项 (Sm:X)。因此，模型系数反映了 Sy:X 相互作用的这种对比，但对于 Sm:X，它们显示了与参考水平的比较。
&lt;预置&gt;&lt;代码&gt; Sm Sy Sm:X1 Sm:X2 Sm:X3 Sy:X1 Sy:X2 Sy:X3 Sy:M
1 0 1 0 0 0 -1 -1 1 1.5902378
2 0 1 0 0 0 -1 1 -1 0.8355516
3 0 1 0 0 0 1 -1 -1 0.7563719
4 0 1 0 0 0 1 1 1 0.3320396
5 0 1 0 0 0 -1 -1 1 1.4224360
....
121 1 0 1 0 0 0 0 0 0.000000
122 1 0 0 1 0 0 0 0 0.000000
123 1 0 0 0 1 0 0 0 0.000000
124 1 0 0 0 0 0 0 0 0.000000
125 1 0 1 0 0 0 0 0 0.000000
126 1 0 0 1 0 0 0 0 0.000000
127 1 0 0 0 1 0 0 0 0.000000

但是，我的想法是将 X 的自定义对比应用于涉及变量 X 的所有交互。我哪里遗漏了什么？
下面应该是一个可重现的示例：
DF 示例，包含 X（预测变量；分类）、M（中介变量；数值）、Y（结果；数值）、ID（分组变量；因素）：
库(lme4)
库（重塑2）
# 科目数量
n_科目 &lt;- 30

# 条件数
n_条件 &lt;- 4

# 条件级别
条件 &lt;- 因子(rep(1:n_conditions, times = n_subjects))

# 为具有主题和条件效应的中介变量 M 生成随机数据
M &lt;- rnorm(n_subjects * n_conditions, 平均值=rep(1:n_conditions,each = n_subjects), sd = 0.5)

# 为具有主题和条件影响的结果变量 Y 生成随机数据
Y &lt;- rnorm(n_受试者 * n_条件，平均值 = 代表(1:n_条件，每个 = n_受试者)，sd = 1)

# 创建一个数据框
DF &lt;- data.frame(ID = rep(1:n_subjects,each = n_conditions),
                   X = as.factor(条件),
                   中号=中号，
                   Y = Y）

创建自定义对比度并应用于 X：
 custom_contrasts &lt;- 矩阵(c(-1, -1, 1,
                                   -1, 1, -1,
                                   1、-1、-1、
                                   1, 1, 1),
                                 nrow = 4，byrow = TRUE）
对比(DF$X) &lt;- custom_contrasts

现在堆叠数据集：
DF$fid &lt;- 1:nrow(DF)
堆叠&lt;-melt(DF，id.vars＝c(“fid”，“ID”，“Y”，“X”，“M”)，
                measure.vars = c(&quot;Y&quot;, &quot;M&quot;), value.name = &quot;Z&quot;)
堆叠 &lt;- 内（堆叠，{
  Sy &lt;- as.integer(变量 == &quot;Y&quot;)
  Sm &lt;- as.integer(变量 == &quot;M&quot;)
})

堆叠数据集的原因是为了重新制定两个公式......
model.m = lme4::lmer(M ~ 1 + X + (1 | ID) , data = DF)
model.y = lme4::lmer(Y ~ 1 + X + M + (1|ID), data = DF)
...将新的响应变量 Z 转化为一个公式，其中 Y 堆叠在 M 上并估计模型*：
mm = lme4::lmer(Z ~ 0 + Sm + Sy + Sm:X+ Sy:X+ Sy:M+ (0 + Sm + Sy | ID) ，数据 = 堆叠)

Sm：M 的截距
Sy：Y 的截距 // Sm 和 Sy 是指示变量。
SmX：X-&gt;M（一条路径）的回归系数
SyM：M-&gt;Y 的回归系数（b 路径）
SyX：X-&gt;Y 的回归系数（cprime 路径）

参见：多级中介示例，了解如何以及为何堆叠数据集的另一个示例（在本例中，X 是数字，因此不需要对比）
现在，在检查 model.matrix 时，Sy:X1 到 Sy:X3 的对比度已正确编码。对于 Sm:X1 到 Sm:X3，对比度仍然是处理（？）对比度：
# 检查模型矩阵
m.matrix = getME(mm &quot;X&quot;)
视图(m.矩阵)

谢谢:)]]></description>
      <guid>https://stats.stackexchange.com/questions/641871/apply-custom-anova-like-contrasts-to-all-interactions-in-a-mixed-model-with-a</guid>
      <pubDate>Tue, 05 Mar 2024 08:51:13 GMT</pubDate>
    </item>
    <item>
      <title>睡美人问题——为什么不是1/2？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/641869/sleeping-beauty-problem-why-is-it-not-1-2</link>
      <description><![CDATA[问题就在这里https://en.wikipedia.org/wiki/Sleeping_Beauty_problem 
对于唤醒时的头部给出的解决方案是 1/2 或 1/3。我可以很容易地理解 1/2，我在下面提出我的推理。 1/3 是否有类似的简单推理？
据我了解，单次审判是从周日到周三。在这次试验中，美女要么被唤醒一次（如果周一是正面），要么被唤醒两次（如果周一是反面）。
假设有 4 次试验，这意味着周一有 4 次抛硬币。假设一枚公平的硬币，2 个正面，2 个反面，并且美女每周一醒来 4 次。
周一有2条尾巴，周二美女还有2条尾巴。再次假设一枚公平的硬币，1 个是正面，1 个是反面。
所以总共有 4 次试验，6 次觉醒，3 次正面，3 次反面。所以我得到 1/2。
如何使用上述简单的推理得到 1/3？]]></description>
      <guid>https://stats.stackexchange.com/questions/641869/sleeping-beauty-problem-why-is-it-not-1-2</guid>
      <pubDate>Tue, 05 Mar 2024 08:39:50 GMT</pubDate>
    </item>
    <item>
      <title>多级（分层）数据的二元逻辑/逻辑回归（Python）</title>
      <link>https://stats.stackexchange.com/questions/641868/binary-logistic-logit-regression-on-multilevel-hierarchical-data-in-python</link>
      <description><![CDATA[我正在尝试使用 python 对分层数据运行二进制 logit 回归，但我找不到方法来做到这一点。如有任何帮助，我们将不胜感激。
数据集具有以下变量：

准确度，二元响应变量
Mask，使用的掩码类型，具有 3 个类别的分类变量
位置，刺激在屏幕上呈现的位置，分为 3 个类别
RT、反应时间、度量变量
subjectID，分组变量，因为它是重复测量

目前，我正在尝试使用 statsmodels：
导入 statsmodels.formula.api 作为 smf
md = smf.logit(“准确度 ~ Mask * RT + 位置”, data, groups = “subjectID”)

不幸的是，smf.logit() 不考虑多级数据，只会忽略 groups = “subjectID”，给出 ValueWarning:unknown kwargs [&#39;groups&#39;]。
我也尝试过使用sklearn.linear_model.LogisticRegression，但据我所知，它不接受分类自变量。
有人知道该怎么做吗？非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/641868/binary-logistic-logit-regression-on-multilevel-hierarchical-data-in-python</guid>
      <pubDate>Tue, 05 Mar 2024 08:32:21 GMT</pubDate>
    </item>
    <item>
      <title>正尾分布</title>
      <link>https://stats.stackexchange.com/questions/641863/positive-tailed-distribution</link>
      <description><![CDATA[什么分布可以代表 3 的平均值以及 90% 的概率，值在 2 到 3 之间。要计算的 X 值为 2,3,4,5,6,7。]]></description>
      <guid>https://stats.stackexchange.com/questions/641863/positive-tailed-distribution</guid>
      <pubDate>Tue, 05 Mar 2024 07:35:51 GMT</pubDate>
    </item>
    <item>
      <title>建模问题、线性回归或生存分析</title>
      <link>https://stats.stackexchange.com/questions/641859/modeling-quesion-linear-regression-or-survival-analysis</link>
      <description><![CDATA[我正在分析一个数据集，其中结果变量是“青少年在数周内使用娱乐性药物的情况”。这是连续且高度倾斜的结果变量。虽然范围从 2 周到 100 周不等，但大多数青少年报告尝试药物的持续时间在 2 到 25 周之间，很少有超过 25 周的时间。
该数据集包含大约 2000 个儿童，每个儿童都有一行数据。没有重复措施； 每个孩子在不同的时间进入研究。
曝光的兴趣是一个单一事件：联邦政府在 2020 年废除药物顾问职位。
分析的目标是检查2020年吸毒持续时间的变化之前与 2020 年废除药物咨询师之后的情况相比，废除了药物咨询师。
我的问题是分析此类结果的合适模型是什么。我应该应用简单线性模型还是生存分析？我欢迎有关此主题的任何建议。提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/641859/modeling-quesion-linear-regression-or-survival-analysis</guid>
      <pubDate>Tue, 05 Mar 2024 05:53:26 GMT</pubDate>
    </item>
    <item>
      <title>模型选择：多级模型与具有交互作用的线性模型</title>
      <link>https://stats.stackexchange.com/questions/641856/model-choice-multilevel-vs-linear-model-with-interaction</link>
      <description><![CDATA[我有一个面板数据集，我的因变量是长期合同农场工人的 Logit 转换比例。我对以可变田园为代表的田园重点对农业的影响特别感兴趣。困难在于这个变量的影响会随着时间的推移而变化。我有两个模型，一个是多层次的，另一个是田园和年份之间相互作用的线性回归：
model1 &lt;- lmer(logitshare ~ 田园 + 其他变量 + (田园 | 年),
               数据=我的数据）
model2 &lt;- lm(logitshare ~ 田园+其他变量+田园：因子(年份)，
             数据=我的数据）

模型的输出相似。我想知道它们之间有什么区别。即，与基本 LM 相比，更复杂的多级模型有什么优势？]]></description>
      <guid>https://stats.stackexchange.com/questions/641856/model-choice-multilevel-vs-linear-model-with-interaction</guid>
      <pubDate>Tue, 05 Mar 2024 03:59:10 GMT</pubDate>
    </item>
    <item>
      <title>回归系数语言</title>
      <link>https://stats.stackexchange.com/questions/641841/regression-coefficient-language</link>
      <description><![CDATA[考虑两种解释或显示回归中的系数估计值的方法。

对于 X 的小幅增加，Y 会减少系数估计量。

对于 X 增加一个标准差的情况，Y 相对于平均值增加了大约某个百分比。


哪种解释更有洞察力？为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/641841/regression-coefficient-language</guid>
      <pubDate>Tue, 05 Mar 2024 00:35:53 GMT</pubDate>
    </item>
    </channel>
</rss>