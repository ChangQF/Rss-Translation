<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 18 Oct 2024 18:23:06 GMT</lastBuildDate>
    <item>
      <title>引导样条构造</title>
      <link>https://stats.stackexchange.com/questions/655978/bootstrapping-spline-construction</link>
      <description><![CDATA[我想知道我们是否应该引导平滑样条的构造？
我正在 brms（和 mgcv）中用平滑项建模逻辑模型。执行 Bootstrap 时，按照惯例对数据集进行常规替换重采样可能会导致平滑构造中的破坏性错误，因为提供的数据点数量不足（由 mgcv::smooth.construct 引发）。
因此，我正在考虑一种贝叶斯风格的 Bootstrap（模仿包 bayesboot 的实现），其中，不是重新采样数据集，而是按照狄利克雷分布对每个观察值的权重进行采样并将其提供给 brms（或具有准二项式族的 mgcv）。但是，查看生成的代码让我感到疑惑。由于平滑项的构造仍然有效地使用了完整的训练特征空间而不是替代空间，这是否会导致对过度乐观的低估？另一方面，从 mgcv 代码来看，我认为 (!!) s(x) 的构造不依赖于结果 y（平滑系数依赖于结果 y，基本函数不依赖于结果 y）。因此，也许不对其进行引导确实更有意义？但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/655978/bootstrapping-spline-construction</guid>
      <pubDate>Fri, 18 Oct 2024 16:42:08 GMT</pubDate>
    </item>
    <item>
      <title>皂膜平滑器的 GAM 边界条件问题</title>
      <link>https://stats.stackexchange.com/questions/655976/issue-with-boundary-condition-in-a-gam-with-a-soap-film-smoother</link>
      <description><![CDATA[我目前正在尝试安装 GAM 来模拟湖中各种声学接收器检测到的鱼的数量。这些接收器放置在特定位置，具有唯一的经度和纬度。我希望模拟研究期间 4 个治疗组中每个接收器检测到的鱼的数量。我在 R 中使用 mgcv 完成了此操作，代码如下：
mod1 &lt;- gam(number_of_fish ~ treatment +
s(x, y, by = treatment, k = 15, bs = &quot;so&quot;,
xt = list(bnd = shap_bnd_ls, nmax = 1500)),
data = filter(fish_num_final_utm, study_fortnight == 0),
family = ziP(),
method = &quot;REML&quot;,
knots = lake_knots)

请注意，我使用的是从我的研究系统的 shapefile 生成的肥皂膜平滑器。
我添加了一个边界条件，以便模型知道预测湖边有 0 条鱼，如下所示。请注意，shap_bnd_ls 是我的边界列表。
shap_bnd_ls &lt;- lapply(nr,
function(n)
shap_bnd_ls[[n]] &lt;- c(
shap_bnd_ls[[n]],
list(f = rep(0, length(shap_bnd_ls[[n]]$x))
)
)
)

该模型似乎运行正常。但是，我认为边界条件没有正常工作。特别是，该模型似乎始终预测湖边的鱼数量为非零（见下文）。我尝试调整“k”值并使用正态泊松分布，但似乎仍然不起作用。

以下是湖面模型预测：

任何帮助，甚至是正确方向的推动都将不胜感激！
您可以找到数据、代码和shapefile 这里。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655976/issue-with-boundary-condition-in-a-gam-with-a-soap-film-smoother</guid>
      <pubDate>Fri, 18 Oct 2024 16:03:05 GMT</pubDate>
    </item>
    <item>
      <title>在具有对数链接的泊松 GEE 中对二进制结果进行反转编码时，P 值会发生变化，但逻辑 GEE 或 OLS 则不会</title>
      <link>https://stats.stackexchange.com/questions/655975/p-value-changes-when-invert-coding-of-binary-outcome-in-poisson-gee-with-log-lin</link>
      <description><![CDATA[我们在面板数据上运行具有二元结果（是/否）的回归模型。结果非常常见（93.6%=是，n=4231 个观察值中的 3961 个）。我们使用 GEE 模型来解释每个参与者的多个观察值。
当我们运行具有对数链接的泊松 GEE 模型（每个预测变量一个模型）时，p 值会根据结果是正编码（是=1）还是负编码（否=1）而有很大差异，并且某些结果会根据编码而变得重要。但是，当我们在相同变量上运行逻辑 GEE 模型时，基于正编码和负编码的 p 值没有差异。 （注意：对数二项式模型不收敛，因此我们无法测试这一点）。
如果结果的编码可以改变重要性，我们会担心泊松结果的有效性。
1.) 为什么泊松模型会产生不同的逆编码 p 值，但逻辑编码不会产生不同的 p 值？这是否与结果的普遍程度有关（如果编码为 Yes=1）？
2.) 如果使用一致的编码（例如，所有模型的 Yes=1），是否可以使用泊松 GEE 的结果？
模型的示例编码：
model1.poisson.yes = geeglm(formula = consequence_yes ~ binary_predictor1, 
id = uuid,
family = poisson(&quot;log&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

model1.poisson.no = geeglm(formula = consequence_no ~ binary_predictor1, 
id = uuid,
family = poisson(&quot;log&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

model1.logistic.yes = geeglm(formula = consequence_yes ~ binary_predictor1, 
id = uuid,
family = binomial(&quot;logit&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

model1.logistic.no = geeglm(formula = consequence_no ~ binary_predictor1, 
id = uuid,
family = binomial(&quot;logit&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

]]></description>
      <guid>https://stats.stackexchange.com/questions/655975/p-value-changes-when-invert-coding-of-binary-outcome-in-poisson-gee-with-log-lin</guid>
      <pubDate>Fri, 18 Oct 2024 16:02:55 GMT</pubDate>
    </item>
    <item>
      <title>Johansen 协整检验中每个矩阵的用途</title>
      <link>https://stats.stackexchange.com/questions/655974/purpose-of-each-matrix-in-johansen-cointegration-test</link>
      <description><![CDATA[尝试将 Johansen 协整测试迁移到 .NET，但在算法中找到明确的步骤。源代码占用一些空间，因此现在我将发布链接和摘录，但可以根据要求添加更多内容。
这是 Python 中的实现，我相信在 statsmodels 之前每个人都使用过它
https://github.com/iisayoo/johansen/blob/master/johansen/johansen.py
这是 .NET 中的当前实现
https://github.com/Indemos/Terminal/blob/main/Core/Services/CointegrationService.cs
public static double Johansen(Matrix&lt;double&gt; Y)
{
// 步骤 1：Y 的一阶差分
var dY = Lag(Y, 1);

// 步骤 2：创建滞后 Y (Y_{t-1}, ..., Y_{t-lags})
var lagY = Lag(Y, 10);

// 步骤 3：计算滞后 Y 上 dY 的 OLS 残差
var beta = OLS(lagY, dY); // β = (X&#39;X)^(-1) X&#39;Y
var dYhat = lagY * beta;
var residuals = dY - dYhat;

// 步骤 4：计算协方差矩阵 
var covMatrix = GetCovMatrix(residuals, lagY)
var evd = covMatrix.Evd();
var eigenValues = evd.EigenValues.Real();

// 步骤 6：计算轨迹和最大特征值统计数据
var traceTests = eigenValues.Select(o =&gt; -Math.Log(1 - o)).ToList();
var traceStat = traceTests.Sum();

// 步骤 7：将轨迹统计数据与临界值进行比较以确定协整等级
// github.com/iisayoo/johansen/blob/master/johansen/critical_values.py
// 95% 置信水平下 Johansen 轨迹检验的临界值
var criticalValues = new double[] { 2.98, 4.13, 6.94, 10.47, 12.32, 16.36 };
var cointegrationRank = 0;

for (var i = 0; i &lt; traceTests.Count; i++)
{
Console.WriteLine(traceTests[i] + &quot; &gt; &quot; + criticalValues[i]);
if (traceTests[i] &gt; criticalValues[i]) cointegrationRank++;
}

return cointegrationRank;
}

问题

测试期间创建了大约 5 个矩阵（第一个 diff、滞后、beta、残差、协方差），但看起来所有这些矩阵仅用于在残差和滞后矩阵之间创建协方差矩阵，并使用其特征值来定义提供的时间序列之间的协整强度。所以，最后我只需要一个协方差矩阵，对吗？

如果假设 #1 是正确的，那么将残差与滞后矩阵进行比较的逻辑是什么？对我来说，残差似乎是所选 beta/回归/ols 线的误差/偏差，滞后矩阵应该捕获时间序列原始矩阵的长期/趋势部分。比较趋势和噪声/波动有什么意义？如果它们只是分解/去趋势的原始时间序列的一部分，它应该如何检测任何协整？

]]></description>
      <guid>https://stats.stackexchange.com/questions/655974/purpose-of-each-matrix-in-johansen-cointegration-test</guid>
      <pubDate>Fri, 18 Oct 2024 15:20:21 GMT</pubDate>
    </item>
    <item>
      <title>这是优化模型中预测变量数量的好主意吗？</title>
      <link>https://stats.stackexchange.com/questions/655971/is-this-a-good-idea-of-optimizing-the-number-of-predictors-in-my-model</link>
      <description><![CDATA[我在大学项目中的任务是根据一系列难以解释的特征预测二元响应变量。
使用的方法是逻辑回归（无惩罚）。我注意到添加一些二阶多项式项可以提高模型的性能。但是，我认为包含所有这些项是不必要的，可能会导致过度拟合。
我以两种方式应用了前向变量选择：首先，按顺序添加最小化 AIC 的变量，其次，使用 scikit-learn 中的 SequentialFeatureSelector。
我使用 5 倍交叉验证并通过计算拟合数据的 AIC 来评估模型。这产生了以下形式的图表：

现在我希望选择最小化 AIC 而不影响准确性的模型（在本例中通过前向选择选择了 22 个变量）。
这是一种好的模型选择方法吗？有没有更标准化的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655971/is-this-a-good-idea-of-optimizing-the-number-of-predictors-in-my-model</guid>
      <pubDate>Fri, 18 Oct 2024 15:00:57 GMT</pubDate>
    </item>
    <item>
      <title>调整因变量的个别值</title>
      <link>https://stats.stackexchange.com/questions/655970/adjusting-individual-values-of-a-dependent-variable</link>
      <description><![CDATA[我有一个数据集，其中包含 600 个脉搏波速度读数，我需要根据每个参与者的平均动脉血压进行调整。我可以得到这样的结果：
m &lt;- lm(pulse_wave_velocity ~ mean_arterial_bp, data = df)
那么我是否可以使用模型中的残差来计算调整后的脉搏波速度，如果是，是否应该将它们添加到截距中？]]></description>
      <guid>https://stats.stackexchange.com/questions/655970/adjusting-individual-values-of-a-dependent-variable</guid>
      <pubDate>Fri, 18 Oct 2024 14:57:17 GMT</pubDate>
    </item>
    <item>
      <title>测量回归中非正态误差项的 I 类错误率</title>
      <link>https://stats.stackexchange.com/questions/655966/measuring-type-i-error-rate-of-non-normal-error-terms-in-regression</link>
      <description><![CDATA[我有一个简单的线性回归模型，试图测试非正态误差条件下的 I 型错误率。以下是一个场景的代码（均匀误差，方差=100 且 b=-a）：
b0 &lt;- 30
sigma_sq &lt;- 100
temp &lt;- data$temperature
n &lt;- length(temp)

# 场景 1
rejections &lt;- numeric(1000)
a &lt;- -sqrt(12*sigma_sq)/2 # 因为 (b-a)=sqrt(12*Var(e))
b &lt;- sqrt(12*sigma_sq)/2

for (i in 1:1000) {
errors &lt;- runif(n, min=a, max=b)
Y_i &lt;- b0 + errors
model &lt;- lm(Y_i~temp)
p_val &lt;- summary(model)$coefficients[2,4] # grab b1
rejections[i] &lt;- ifelse(p_val &lt; 0.05, 1, 0)
}
type1_percent &lt;- sum(rejections)/1000

温度值保持不变。为什么我总是得到大约 5% 的 I 型错误率。即使在错误为伽马分布或术语自相关的其他场景中，我仍然得到 5%。但是，当我增加 n=5000 时，我在所有场景中都得到 25% 的 I 型错误率。
我的代码中可能存在错误吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655966/measuring-type-i-error-rate-of-non-normal-error-terms-in-regression</guid>
      <pubDate>Fri, 18 Oct 2024 14:12:16 GMT</pubDate>
    </item>
    <item>
      <title>负二项回归与普通逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/655965/negative-binominal-regression-vs-ordinary-logistic-regression</link>
      <description><![CDATA[我有选举期间的社交媒体数据，其中包含数千名政治人物在社交媒体上的帖子。数据集有许多控制变量，例如日期、关注者数量、视觉效果的存在、是否是热门演员的转发等。
这项研究本质上是关于语言学的。我的目标是测试隐喻相关指标是否与高参与度（喜欢、分享、评论）相关。由于它是社交媒体数据，因此存在高度过度分散。我确认负二项回归是最佳选择。
在用喜欢计数拟合模型后，我注意到该模型在处理参与度非常高或参与度非常低的帖子时遇到了困难。它似乎也有显著的异常值。




考虑到这是高度密集时期的社交媒体数据，我对模型在某些帖子上遇到困难并不感到惊讶。大多数被低估的帖子都包括特殊/耸人听闻的视觉效果、视频或公告，这些都使它们非常高。
由于它们不是虚假数据并且是社交媒体固有的，所以我没有删除它们。
主要目标不是拥有一个预测参与度的模型，而是看看隐喻指标是否与参与度呈正相关。
我想知道这是否是正常的，因为数据的性质。此外，NBR 是否适合我，或者我是否应该在将基于百分位数的参与度数据分解为高、中、低参与度后考虑 OLR。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655965/negative-binominal-regression-vs-ordinary-logistic-regression</guid>
      <pubDate>Fri, 18 Oct 2024 14:02:35 GMT</pubDate>
    </item>
    <item>
      <title>非规范化数据的领域自适应——如何将非规范化作为最后一步</title>
      <link>https://stats.stackexchange.com/questions/655964/domain-adaptation-on-non-normalized-data-how-to-denormalize-as-the-last-step</link>
      <description><![CDATA[在读取域适应数据时，我经常遇到“假设我们有规范化的数据...”
我的问题是。如果数据未规范化，并且我想适应我的数据，那么反规范化的正确方法到底是什么？例如我想绘制一个有意义的适应性数据图
我理解的完整过程是：

计算并保存平均值源、标准差源、平均值目标、标准差目标
标准化源和目标并获得源标准化、目标标准化
执行域适应并获得源标准化适应
现在通过与标准差相乘并添加平均值来进行非标准化

但是我应该采用哪种平均值/标准差？
通常，我会说源非标准化 = 源标准化 * 标准差源 + 平均值源。但是，当我们尝试将数据适应新域时，这听起来更像是我应该添加目标平均值和标准差。
感谢您的意见]]></description>
      <guid>https://stats.stackexchange.com/questions/655964/domain-adaptation-on-non-normalized-data-how-to-denormalize-as-the-last-step</guid>
      <pubDate>Fri, 18 Oct 2024 14:00:36 GMT</pubDate>
    </item>
    <item>
      <title>OLS - 奇异值和置信区间之间的关系</title>
      <link>https://stats.stackexchange.com/questions/655963/ols-relationship-between-singular-values-and-confidence-intervals</link>
      <description><![CDATA[我最近读到，数据矩阵的小奇异值（在 SVD 的背景下）会导致 OLS 中 $\beta$ 系数的估计不可靠（嘈杂）。是否有某种公式可以将其与估计的置信区间或标准误差联系起来？换句话说，数据矩阵的（最小）奇异值与 beta 的不确定性之间的关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/655963/ols-relationship-between-singular-values-and-confidence-intervals</guid>
      <pubDate>Fri, 18 Oct 2024 13:49:56 GMT</pubDate>
    </item>
    <item>
      <title>使用样条函数绘制威布尔回归中的 HR</title>
      <link>https://stats.stackexchange.com/questions/655960/plot-hr-in-weibull-regression-with-splines</link>
      <description><![CDATA[我用样条函数（连续变量的四分位数）和 survreg 拟合了一个威布尔回归模型。
 fit &lt;- survreg(Surv(time, event) ~ bs(var1, knots=c(2,3,5)) + var2 + 
var3 + ...

我想给出一个带有 95%CI 的样条函数的 HR 图，有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655960/plot-hr-in-weibull-regression-with-splines</guid>
      <pubDate>Fri, 18 Oct 2024 13:02:13 GMT</pubDate>
    </item>
    <item>
      <title>回归模型中每个变量都需要具有统计显著性吗？</title>
      <link>https://stats.stackexchange.com/questions/655938/does-every-variable-need-to-be-statistically-significant-in-a-regression-model</link>
      <description><![CDATA[我最近拟合了一个回归模型 (ARIMAX)，其中有些变量 (3) 具有统计显著性，有些则不显著 (1)。我删除了统计上不显著的变量并重新拟合模型，现在所有变量都具有统计显著性（即新模型有 3 个变量，旧模型有 4 个变量）。
但是，这个新模型（所有变量都具有统计显著性）的表现比旧模型（并非所有变量都具有统计显著性）更差。也就是说，新模型的预测误差比旧模型更严重。
这是统计学中的常见做法吗？如果所有变量都具有统计显著性，选择性能较差的模型更可取，还是选择性能较好的模型更好，即使并非所有变量都具有统计显著性。
我知道过度拟合和交叉验证等概念。我用除过去 6 个月的数据之外的所有可用数据训练了这两个模型……并让这两个模型预测过去 6 个月的可用数据，并将预测值与实际值进行比较……我仍然用旧模型（即并非所有变量都具有统计意义的模型）获得更好的结果。
即使并非所有变量都具有统计意义，也可以使用性能更好的模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655938/does-every-variable-need-to-be-statistically-significant-in-a-regression-model</guid>
      <pubDate>Fri, 18 Oct 2024 01:02:57 GMT</pubDate>
    </item>
    <item>
      <title>出口数据的结构突变检测</title>
      <link>https://stats.stackexchange.com/questions/655931/structural-break-detection-in-export-data</link>
      <description><![CDATA[我正在查看挪威的出口数据，试图发现俄罗斯逃避制裁的行为。逃避制裁的行为是将商品出口到第三方国家，然后这些国家再将商品出口到俄罗斯。这些数据具有月度分辨率，并且在商品类别方面非常精细。我想知道是否有一种统计测试可以用来检测 2022 年 2 月之后出口与之前相比的显著变化。我想使用该测试来检查多个第三方国家/地区的每个出口类别，以便了解需要仔细研究的内容。
下面我绘制了基站（电信设备）出口到哈萨克斯坦的时间序列：

这是数据集中数据的典型示例。您可以看到大多数月度值为零，只有少数非零值。这些值是离散的，只有整数。]]></description>
      <guid>https://stats.stackexchange.com/questions/655931/structural-break-detection-in-export-data</guid>
      <pubDate>Thu, 17 Oct 2024 20:11:52 GMT</pubDate>
    </item>
    <item>
      <title>计数值的统计检验</title>
      <link>https://stats.stackexchange.com/questions/655928/statistical-test-for-count-values</link>
      <description><![CDATA[我有 4 个故事，每个故事都有字数和复数词的数量：



故事
单词数
复数




1
356
45


2
273
23


3
303
28


4
289
42



我想知道是否可以进行统计测试以确定这些故事在字数方面是否存在显着差异，然后再进行另一项测试以确定这些故事在复数数量方面是否存在显着差异。
测试的目的是确保这些故事在阅读难度方面没有显着差异。这是一项心理学研究，我们需要确保故事难度中没有混淆。我们正在测试其他更相关的单词特征，但这些是连续值，我们可以对其进行其他测试。
我没有人口频率可以与之比较，以便使用 Fisher 精确检验，我认为我不能使用卡方检验，因为那里的计数似乎应该是相关的，例如测试一群人是否喜欢苹果、橘子或香蕉，而一个人不能选择两个选项，我有点困惑，不知道我可以在这里使用什么测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/655928/statistical-test-for-count-values</guid>
      <pubDate>Thu, 17 Oct 2024 19:33:29 GMT</pubDate>
    </item>
    <item>
      <title>稳健标准误差 (HC3) 小于 OLS 标准误差</title>
      <link>https://stats.stackexchange.com/questions/655917/robust-standard-error-hc3-smaller-than-ols-standard-error</link>
      <description><![CDATA[我对温度月时间序列进行了线性回归，以获得温度趋势。我将温度变量视为因变量 (y)，将时间（例如，某一年的月份）视为解释变量 (x)。
当我绘制残差时，我发现了显著的自相关性。这意味着回归系数的标准误差可能被低估了。
当我应用 Cochrane-Orcutt 程序进行分析时，它主要消除了自相关性。Cochrane-Orcutt 程序给出的标准误差比 OLS 方法大约大 2-3 倍，但该方法并不适用于所有情况（我正在获取许多位置的温度趋势）。当 AR(1)、AR(2) 和 AR(3) 同时存在时，回归斜率有时不符合物理规律。理论上，我认为 Cochrane-Orcutt 程序会给出类似的回归斜率，而标准误差会变化得更明显。我想知道，如果 Cochrane-Orcutt 程序的回归系数与普通最小二乘法 (OLS) 有显著差异，那么不使用 Cochrane-Orcutt 程序的结果是否合乎逻辑。
作为替代方案，我考虑了稳健标准误差（或异方差一致标准误差），同时保留了 OLS 方法的回归系数。我考虑了 HC0（McKinnon 和 White，1985 年）。我发现计算出的 HC0 稳健误差通常小于基于 OLS 方法的标准误差。我使用时间作为 x 变量，这意味着当 (xi - E(x)) 较大时（例如，x=1、x=2、x=n-1、x=n-1），在获得稳健标准误差时使用更大的权重。有时这些数据点的残差小于平均残差，导致稳健标准误差小于 OLS 标准误差。我想知道这是否是使用稳健误差的正确方法（赋予数据点的较大权重远离中点）？当我应用 HC3 时，它给出的标准误差比 HC0 稍大，但它仍然通常小于 OLS 标准误差。
因此，稳健标准误差并不大于 OLS 标准误差，这与我的预期相反。我想知道是否仍然值得应用 HC3 方法来处理残差的自相关。这是正常的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655917/robust-standard-error-hc3-smaller-than-ols-standard-error</guid>
      <pubDate>Thu, 17 Oct 2024 17:16:10 GMT</pubDate>
    </item>
    </channel>
</rss>