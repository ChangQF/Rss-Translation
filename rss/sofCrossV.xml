<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 14 Apr 2024 03:52:16 GMT</lastBuildDate>
    <item>
      <title>对成本标准化的期望 预期改进</title>
      <link>https://stats.stackexchange.com/questions/644962/expectation-over-cost-normalized-expected-improvements</link>
      <description><![CDATA[如果我们假设 f(x) 和 C(x) 独立，下面两个表达式是否等价？
$$
E\left[\frac{E\left[\max\left(f(x) - f(x^*), 0\right)\right]} {C(x)}\right]
$$
$$
\frac{E\left[\max\left(f(x) - f(x^*), 0\right)\right]} {E\left[C(x)\right]}
$$
哪里
f(x) 和 C(x) 分别是目标函数和成本函数，$f(x^*)$ 是之前迭代中记录的最佳目标。]]></description>
      <guid>https://stats.stackexchange.com/questions/644962/expectation-over-cost-normalized-expected-improvements</guid>
      <pubDate>Sun, 14 Apr 2024 03:35:26 GMT</pubDate>
    </item>
    <item>
      <title>当 rpart 函数 xerror 值对不平衡数据成本敏感时，它看起来如何？</title>
      <link>https://stats.stackexchange.com/questions/644961/how-does-the-rpart-function-xerror-value-look-like-this-when-it-is-cost-sensitiv</link>
      <description><![CDATA[库(rpart)
库（应用预测建模）
数据（鲍鱼）
abi &lt;- 鲍鱼
abi$Rings &lt;- Factor((abi$Rings) &gt; 22, labels = c(&quot;L&quot;, &quot;H&quot;)) # 处理成占比悬殊的二类
摘要(abi$Rings)

设置.seed(2)
ctabi_1 &lt;- rpart(Rings ~ ., data = abi, method = “class”, cp = 0,
                   parms = 列表(损失 = 矩阵(c(0, 1, 10, 0), byrow = TRUE, nrow = 2)))
摘要(ctabi_1)

]]></description>
      <guid>https://stats.stackexchange.com/questions/644961/how-does-the-rpart-function-xerror-value-look-like-this-when-it-is-cost-sensitiv</guid>
      <pubDate>Sun, 14 Apr 2024 02:25:34 GMT</pubDate>
    </item>
    <item>
      <title>ABC（近似贝叶斯计算）采样，模拟复杂模型中的数据</title>
      <link>https://stats.stackexchange.com/questions/644960/abc-approximate-bayesian-computation-sampling-simulating-data-from-complex-mo</link>
      <description><![CDATA[在 ABC 抽样方法、拒绝、MCMC 和 SMC 中，当我们从先验/提案中抽样潜在参数值时，我们会在模型中使用这些参数并模拟数据值。这可以在不直接评估可能性的情况下完成（这通常很困难、昂贵或不可能），然后我们将这些模拟数据值与观察到的数据值进行比较，看看它们是否“足够接近”，如果是，我们接受建议的参数值。这大致就是这些方法背后的共同思想。
我的问题是，除了具有清晰分布函数的简单模型之外，我们如何实际模拟给定参数的复杂模型中的数据？
例如，如果我们使用 Lotka Volterra、SIR、HMM 或 SDE 模型，直接计算可能性是不切实际的，那么我们如何模拟给定参数的数据？
阅读完此主题后，一些人建议在 ODE 模型中使用数值求解器（例如 Runge Kutta 方法），但这与评估模型不一样吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644960/abc-approximate-bayesian-computation-sampling-simulating-data-from-complex-mo</guid>
      <pubDate>Sun, 14 Apr 2024 01:14:20 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助理解自由度</title>
      <link>https://stats.stackexchange.com/questions/644959/need-help-understanding-degrees-of-freedom</link>
      <description><![CDATA[我很难理解自由度是如何工作的。
考虑这个随机回归模型：
$$Y_i = 2 + 3 x_i + \epsilon_i$$
我想象使用 4 个数据点。
我决定选择 $$x_1 = 2$$ $$x_2 = 3$$
我用这些矩阵来表示这一点
$$\begin{bmatrix}2 \\ 3\\x_3\\x_4\end{bmatrix} = \begin{bmatrix}2+3(2) \\ 2 +3(3)\\2+3x_3\\2+3x_4\end{bmatrix} +\begin{bmatrix}-6 \\-8\\-2x_3-2\\-2x_4-2\end{bmatrix}$ $
其中最终矩阵是残差。 （例如，最终矩阵的最后一项导出为 x4 - (2 + 3x4)
因此，根据我对自由度的了解，这最后两个 x3 x4 应该是预先确定的，因为我们应该有 4 - 2 个剩余自由度。
残差的约束是它们的总和 = 0。因此，
$$-2x_3-2 + -2x_4 - 2 = 14$$
但是，这允许完全独立地选择两者之一吗？我认为我做错了，因为这与我对自由度的了解不符。]]></description>
      <guid>https://stats.stackexchange.com/questions/644959/need-help-understanding-degrees-of-freedom</guid>
      <pubDate>Sun, 14 Apr 2024 00:26:10 GMT</pubDate>
    </item>
    <item>
      <title>β 二项式模型的假设是什么？如何在 r 中测试它们？</title>
      <link>https://stats.stackexchange.com/questions/644958/what-are-the-assumptions-of-beta-binomial-models-and-how-do-i-test-for-them-in</link>
      <description><![CDATA[我想模拟扩散距离 (disp) 和繁殖率 (rep) 对定植率的影响，量化为重新定植的栖息地细胞数 (colonized_hab) 除以可用栖息地细胞数 (vacant_hab)，这是从计数得出的比例（即，在给定时间步长内重新定殖的栖息地细胞的计数相对于可重新定植的栖息地细胞的计数）。我最初使用 r 中的 glm() 函数运行具有二项式分布的广义线性模型：
glm(cbind(colonized_hab, vacant_hab - colonized_hab)~rep + disp, family=“二项式”,data=dat)
但输出表明模型过度分散：
残余偏差：1197 个自由度上的 174938
为了处理模型中的过度离散问题，我使用 glmmTMB 函数运行了 beta 二项式模型（没有任何随机效应）：
mod2 &lt;- glmmTMB(cbind(colonized_hab, vacant_hab - colonized_hab)~rep + disp, family=“二项式”,data=dat)
现在我已经运行了这个模型，我想知道假设是什么，以及我应该进行什么样的诊断测试来确定是否满足模型假设。
到目前为止，我已经尝试使用 DHARMa 包来运行一些诊断测试：
res &lt;-simulateResiduals(mod,plot = T)

hist(simulateResiduals(mod))

testZeroInflation(t)

但是，我不太确定根据 beta 二项式模型的假设应该寻找什么。任何想法或见解将不胜感激。如果我的数据不符合假设，那么处理过度分散的下一步建议是什么？非常感谢任何反馈或见解。
对于上下文，这是我的 data.frame 的屏幕截图，显示了我的数据集的结构：
]]></description>
      <guid>https://stats.stackexchange.com/questions/644958/what-are-the-assumptions-of-beta-binomial-models-and-how-do-i-test-for-them-in</guid>
      <pubDate>Sun, 14 Apr 2024 00:19:47 GMT</pubDate>
    </item>
    <item>
      <title>估计分布的 alpha 支持[重复]</title>
      <link>https://stats.stackexchange.com/questions/644955/estimating-the-alpha-support-of-a-distribution</link>
      <description><![CDATA[我想估计 $\alpha$-支持 ($S_{α}$)分布的，它是概率分布 $P$$S$ 的最小体积子集&gt; ($S=supp(P)$)，支持概率质量为 $\alpha$ ： $S_{α} = min[V(s)]$ 使得 $P(s)=\alpha$ 。
例如，对于平均值=0、标准差 sigma=1 的正态分布，覆盖总概率质量 68% 的最小体积集是区间 [-sigma, sigma]=[-1, 1]。 
如何在 python 中完成此操作（例如仅针对一维数据）？]]></description>
      <guid>https://stats.stackexchange.com/questions/644955/estimating-the-alpha-support-of-a-distribution</guid>
      <pubDate>Sat, 13 Apr 2024 20:42:18 GMT</pubDate>
    </item>
    <item>
      <title>条件似然、条件独立和联合独立</title>
      <link>https://stats.stackexchange.com/questions/644953/conditional-likelihood-conditional-independence-and-joint-independence</link>
      <description><![CDATA[考虑从 $n$ 个独立随机向量生成的数据样本序列 $(X_1, Y_1), (X_2 ,Y_2),(X_3,Y_3) ...$
$$D = (x_1,y_1), (x_2,y_2), (x_3,y_3) ...$$
其中 $(X_i, Y_i)$ - 是随机向量，$X_i$，&lt; span class=&quot;math-container&quot;&gt;$Y_i$ 是缩放器或向量值随机向量，$(x_i,y_i)$ 是数据样本从这些。
似然函数可以定义如下：
$$
L(D) = \prod_{i=1}^n p_i(x_i, y_i) \tag{1}
$$
$p_i$ - 第 $i$ 个随机向量的概率分布函数。&lt; /p&gt;
我们可以计算概率的乘积，因为这些随机向量是独立的。
$(1)$ 也可以表示为：
$$
L(D) = \prod_{i=1}^n p_i(y_i | x_i) * p_i(x_i) \tag{2}
$$
鉴于数据是独立生成的，条件分布也可以表示为：
$$
P(y_1, y_2, ... y_n | x_1, x_2, ... x_n) = \frac{P(x_1, x_2 ... x_n, y_1, y_2 ... y_n)}{P(x_1, x_2 . .. x_n)} \标签{3}
$$
$$
P(y_1, y_2, ... y_n | x_1, x_2, ... x_n) = \frac{\prod_{i=1}^n p_i(x_i, y_i)}{\prod_{i=1}^n p_i(x_i)} \标签{4}
$$
$$
P(y_1, y_2, ... y_n | x_1, x_2, ... x_n) = \prod_{i=1}^n p_i(y_i | x_i) \tag{5}
$$
由于数据的独立性，方程 $(3)$ 变为 $(4)$生成过程。
基于上述：
可以说，如果数据样本是独立生成的，即
$$p_i(x_i,y_i) \mathrel{\unicode{x2AEB}} p_j(x_j,y_j) \forall j \neq i $$
然后是数据样本的条件分布$$p_i(y_i | x_i) \mathrel{\unicode{x2AEB}} p_j(y_j | x_j) \forall j \neq i $ $？
注意我只假设独立性，随机向量序列可以有不同的分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/644953/conditional-likelihood-conditional-independence-and-joint-independence</guid>
      <pubDate>Sat, 13 Apr 2024 20:08:21 GMT</pubDate>
    </item>
    <item>
      <title>用平方根衰减建模非负时间序列？</title>
      <link>https://stats.stackexchange.com/questions/644951/modeling-non-negative-time-series-with-square-root-decay</link>
      <description><![CDATA[问：我应该如何对表现出平方根衰减的非负时间序列 $y_t$ 进行建模？更具体地说，时间序列 $y_t$ 其平方根差 $\sqrt{y_t}-\sqrt{y_{ t-1}}$ 是线性的并且期望为负值。更具体地说，时间序列 $y_t$ 使其平方根变换 $\sqrt{y_t} \sim \mathrm{ ARIMA}(p,1,q)$，大约。
我认为在 ARIMA 建模之前对数据进行平方根变换（appx.，使用 $\lambda=0.5$ 进行 Box-Cox 变换）是合适的。
但后来我观察到我的原始系列的预测在预测期后期呈上升趋势。经过调查，我明白了原因。从技术上讲，我们不能说时间序列 $\sqrt{y_t}\sim\mathrm{ARIMA}(p,d,q)$ 自平方以来-根变换仅在正数线上，而白噪声在整个实数线上。对于整个实数轴上的对数变换来说这不是问题。
很高兴知道。但是，从业者通常在这里做什么？

ARIMA 模型 $\log(y_t)$，即使对数变换过度稳定 $y_t$，可以这么说吗？
ARIMA 对未转换的非负数据建模 $y_t$ 和
截断任何低于零的预测？
使用 &lt; 中实现的众多替代转换之一code&gt;trafo R 包，例如，平方根移位、Bickel-Docksum、Yeo-Johnson。&lt; /里&gt;
退出简单、现成的解决方案的世界，并为泊松、负二项式、伽玛等进行某种 GLM 链接？

我不敢相信我以前从未遇到过这个问题。我想我习惯于对不断增长的数据进行建模，而不是衰减。尽管如此，我还是希望在某个地方、某个时刻能对它发表评论！
请参阅下面的模拟代码来演示我的观点。
库（预测）
图书馆（tsibble）
图书馆（寓言）
库（寓言工具）
图书馆（节日）

# 模拟非负平方根衰减数据
设置种子(10)
亩=-3
x0=100
N=24
x&lt;-cumsum(c(x0,mu+rnorm(N))) # 这将是变换后的序列
绘图（x，类型=&#39;l&#39;）


y&lt;-x^2 # 这将是目标、观察到的序列
盛宴::guerrero(y) # 0.4675001 ~ 0.5，如预期

＃ 合身
fit&lt;-auto.arima(x)
总结（适合）
fit$coef # 漂移：-3.523052 ~ 3，如预期
fcs&lt;-预测（拟合，h=12）
plot(fcs) # 预测将在系列稍后出现


plot(fcs$mean^2) # 是的，预测会在系列稍后出现


# 尝试直接使用 `lambda` 参数
fit2&lt;-auto.arima(x,lambda=0.5)
fcs2&lt;-预测(fit2,h=2)
情节（fcs2）
# 不会预测超过 2 个周期，我被难住了，继续前进。


dat &lt;- tsibble(idx=1:(N+1),y=y,index=&#39;idx&#39;)
数据%&gt;%
  模型(s_arima=ARIMA(sqrt(y))) %&gt;%
  预测(h=12) %&gt;%
  autoplot() # 同样向上卷曲，即使在寓言包中


&lt;前&gt;&lt;代码&gt;数据%&gt;%
  模型(s_arima=ARIMA(box_cox(y,lambda=0.5))) %&gt;%
  预测(h=12) %&gt;%
  自动绘图（）
# 令人惊讶的是，预测的 y 实际上变为负数
# 我猜 `ARIMA` 无法将 `box_cox` 识别为它可以进行的转换
# 反向变换？

]]></description>
      <guid>https://stats.stackexchange.com/questions/644951/modeling-non-negative-time-series-with-square-root-decay</guid>
      <pubDate>Sat, 13 Apr 2024 19:30:11 GMT</pubDate>
    </item>
    <item>
      <title>具有两个预测变量的多元回归中交互项的数学公式</title>
      <link>https://stats.stackexchange.com/questions/644950/mathematical-formula-for-interaction-term-in-multiple-regression-with-two-predic</link>
      <description><![CDATA[我试图理解具有两个预测变量的多元回归系数背后的数学原理及其相互作用。我知道这可以用矩阵表示法或直接在任何统计软件中完成，但我想了解如何使用相关性来设置它。
我将使用 R 中的 mtcars 数据集作为示例：
型号 1：lm(data=mtcars, mpg ~ hp + wt)

在这种情况下，我们得到的方程为mpg ~ 37.22727 + -0.03177 hp + -3.87783 wt
我可以使用三个变量之间的相关性，如下所示，使用以下公式生成这些估计值：
$$
b_{hp} = \frac{s_{mpg}}{s_{hp}} \frac{r_{hp,mpg}-r _{wt,mpg}*r_{hp,wt}}{1-r_{hp ,wt}^2} = -0.03177
$$
$$
b_{wt} = \frac{s_{mpg}}{s_{wt}} \frac{r_{wt,mpg}-r _{hp,mpg}*r_{hp,wt}}{1-r_{hp ,wt}^2} = -3.87783
$$
$$
a = M_{mpg} - b_{hp}M_{hp} - b_{wt}M_{wt} = 37.22727
$$
其中 $M$ 代表均值，$s$ 代表各个变量的标准差。
我想要做的是，当模型中 hp 和 wt 之间存在交互时，以类似的方式获取系数，如下所示：
型号 2：lm(data=mtcars, mpg ~ hp + wt + hp:wt)

在这种情况下如何计算系数？我尝试创建一个乘积术语 $hp*wt$ 并计算出所有成对相关性（$mpg $、$hp$、$wt$ 和 $hp*wt$)，但不知道如何从那里继续。
最终，我想计算 R 返回的系数，得出以下方程：
&lt;前&gt;&lt;代码&gt;mpg ~ 49.80842 + -0.12010 hp + -8.21662 wt + 0.02785 hp:wt
]]></description>
      <guid>https://stats.stackexchange.com/questions/644950/mathematical-formula-for-interaction-term-in-multiple-regression-with-two-predic</guid>
      <pubDate>Sat, 13 Apr 2024 19:19:28 GMT</pubDate>
    </item>
    <item>
      <title>范围大于步长的滚动预测</title>
      <link>https://stats.stackexchange.com/questions/644949/rolling-forecasts-where-horizon-is-larger-than-step-size</link>
      <description><![CDATA[在预测范围大于步长的情况下执行滚动时间序列预测是否是一种不好的做法？例如，如果我有一个模型可以每天滚动生成每周预测，那么它每年会给出 365 次每周预测，而如果我的步长等于我的预测范围，则会给出 52 次预测。
一方面，每日预测可以为模型提供更多训练数据，但另一方面，误差将呈序列相关。
我无法对设置问题产生良好的直觉，并且希望获得有关如何构建问题/最佳实践的任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/644949/rolling-forecasts-where-horizon-is-larger-than-step-size</guid>
      <pubDate>Sat, 13 Apr 2024 19:17:51 GMT</pubDate>
    </item>
    <item>
      <title>稀疏PCA分量权重/线性组合系数来描述PC</title>
      <link>https://stats.stackexchange.com/questions/644948/sparse-pca-component-weights-coefficients-of-linear-combination-to-describe-pc</link>
      <description><![CDATA[根据我对稀疏 PCA 的（有限）理解，通过允许某些载荷为零，您可以更好地近似与每个主成分相关的载荷线性组合1。
按照 Harrell 教授实施的稀疏 PCA + 逐步回归来描述 PC：
&lt;前&gt;&lt;代码&gt;要求(Hmisc)
getHdata(prostate) # 下载并使前列腺可访问
# 将旧日期格式转换为 R 格式
前列腺$sdate &lt;- as.Date(prostate$sdate)

ptrans &lt;-
  跨扫描（~ sz + sg + ap + sbp + dbp +
             年龄 + wt + hg + ekg + pf + bm + hx，估算=TRUE，
           转换 = TRUE，trantab = TRUE，pl = FALSE，
           show.na=TRUE，数据=前列腺，frac=.1，pr=FALSE）

s &lt;- princmp(ptrans$transformed, k=10, method=&#39;sparse&#39;, sw=TRUE, nvmax=3)

输出
&lt;块引用&gt;
稀疏主成分分析
具有累积 R^2 的 PC 的逐步逼近
PC 1 sg (0.83) + ap (0.962) + sz (0.992)
PC 2 sbp (0.836) + dbp (1)

我们可以看到，前两个PC可以描述为变量sg、ap、sz、sbp和dbp的线性组合。假设每个类别的数据点沿轴有明确的方向性和分离...
我的问题是，是否可以计算出所述线性模型中变量的系数，以便我们可以在下游使用它进行分类或其他操作？]]></description>
      <guid>https://stats.stackexchange.com/questions/644948/sparse-pca-component-weights-coefficients-of-linear-combination-to-describe-pc</guid>
      <pubDate>Sat, 13 Apr 2024 18:58:33 GMT</pubDate>
    </item>
    <item>
      <title>环境变量解释野兔的重量 - 4 个区域有 80 个陷阱，每个陷阱捕获的野兔数量不等 - 线性混合效应模型最好吗？</title>
      <link>https://stats.stackexchange.com/questions/644947/environmental-variables-explain-hare-weight-80-traps-in-4-zones-where-each-tra</link>
      <description><![CDATA[研究设计
所以我在50km^2的森林面积里设置了80个野兔陷阱。森林面积分为 4 个区域。由于污染输入水平不同，每个区域的情况预计也会有所不同。每个区域有 20 个陷阱。在每个陷阱的位置，我测量了土壤中的几个环境变量，例如铅、锌……。每个陷阱捕获的野兔数量不同。据我了解，这就是所谓的不平衡设计。 “设计术语”中的正确术语是什么？给出这种类型的设计？
定量方法
我正在对环境变量进行 PCA，并使用主成分 (PC1 - PC3) 来解释大部分方差（环境变量中）作为线性回归中的解释变量。在线性回归中，我使用兔子体重作为响应变量。我将重量数据与 PC 数据合并，以便对于每个陷阱位置，PC1、PC2 和 PC3 都有 1 个唯一值。因此，在合并兔子 PCA 数据的矩阵中，PC1、PC2 和 PC3 的每个值对于每个陷阱出现多次，具体取决于每个陷阱捕获的兔子数量。每个兔子的体重在这个矩阵中大多只出现一次，除非在少数情况下被重新捕获。我将区域作为因子变量。在我看来，线性混合效应模型在这里可能更合适？我试图找出环境变量可以解释多少重量变化。如果您知道任何使用此方法或更合适的方法来通过此类研究设计实现目标的研究/论文，我很乐意提供建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/644947/environmental-variables-explain-hare-weight-80-traps-in-4-zones-where-each-tra</guid>
      <pubDate>Sat, 13 Apr 2024 17:59:57 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 R 中 MANOVA.RM 包中 RM 函数的 Wald 型统计量的功效和效应大小？</title>
      <link>https://stats.stackexchange.com/questions/644942/how-do-i-calculate-the-power-and-effect-size-for-the-wald-type-statistic-of-the</link>
      <description><![CDATA[我已经从 R 中的 MANOVA.RM 包计算了 RM 函数，现在需要计算测试的统计功效以及其Wald类型统计的效应大小，包括自举版本。
“RM 函数使用任意数量的交叉全图（受试者间）和子图（受试者内）因子计算重复测量设计中的 WTS 和 ATS。提供的重采样方法包括排列过程、参数引导方法和使用 Rademacher 权重的狂野引导方法。排列过程没有为 ATS 提供有效的方法，因此未实现。”
https://cran.r-project。 org/web/packages/MANOVA.RM/vignettes/Introduction_to_MANOVA.RM.html
RM 函数只有一个因变量（它不是多元方差分析）。
在我的 2x2 模型设计中，我结合了内部因素和外部因素。
我还需要解释狂野引导程序。
我使用 RM 函数是因为我的数据是非参数的，并且我的样本量总共只有 n=21。
一般来说，我使用 R 和 SPSS。
非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/644942/how-do-i-calculate-the-power-and-effect-size-for-the-wald-type-statistic-of-the</guid>
      <pubDate>Sat, 13 Apr 2024 15:01:02 GMT</pubDate>
    </item>
    <item>
      <title>OLS 估计的 SUR：受限模型具有更高的可能性</title>
      <link>https://stats.stackexchange.com/questions/644934/sur-estimated-by-ols-restricted-model-has-higher-likelihood</link>
      <description><![CDATA[我有线性回归模型系统的三个版本：M、M0 和 M00。我认为它们都是看似无关回归（SUR）的一个例子。模型是嵌套的：M 包含 M0，后者包含 M00。我有兴趣测试 M0 上的（排除/空）限制的有效性，将其转变为 M00。我考虑过对此使用似然比 (LR) 检验。
我正在使用 systemfit 包在 R 中实现这一点。首先，我定义 M 的方程组 (eqSystem) 和限制矩阵（Rmat0 和 Rmat00），用于从 M 获取 M0 和 M00 的向量（qvec0 和 qvec00）。然后我估计 M0 和 M00 并尝试运行 LR 测试：
M0 &lt;- systemfit(formula=eqSystem, method=&quot;OLS&quot;,restrict.matrix=Rmat0,restrict.rhs=qvec0)
M00 &lt;- systemfit(公式=eqSystem，方法=“OLS”，restrict.matrix=Rmat00，restrict.rhs=qvec00)
lr测试（M00，M0）

估计模型没有问题，但是LR测试结果后出现以下警告：
警告消息：
在 lrtest.systemfit(M00, M0) 中：
  模型“2”的对数似然值比限制更严格的模型“1”小

我想知道这怎么可能。毕竟M00是M0的子模型，所以它的最大似然不可能更高。我怀疑答案与 systemfit 包中模型的指定和估计方式有关。也许 method=“OLS” 与可能性最大化并不相符？ （更新：@jbowman 在评论中指出情况确实如此。）
起初我想在 Stack Overflow 上发布一个以编码为中心的问题，但为此我需要一个最小的可重现示例。但是，我想避免共享我的数据。所以我想我可以创建一个模拟数据集来产生上述行为。但为此我当然必须了解发生了什么！因此我发现自己陷入了恶性循环。
你能帮我弄清楚发生了什么事吗？我认为提供一个重现该行为的最小示例会很有启发性。]]></description>
      <guid>https://stats.stackexchange.com/questions/644934/sur-estimated-by-ols-restricted-model-has-higher-likelihood</guid>
      <pubDate>Sat, 13 Apr 2024 12:33:10 GMT</pubDate>
    </item>
    <item>
      <title>回归悖论</title>
      <link>https://stats.stackexchange.com/questions/644915/regression-paradox</link>
      <description><![CDATA[我必须使用两个二分自变量进行二元逻辑回归。
我发现自己面临着一个悖论，我不知道如何处理。
在完整的数据库中，我有 377 名 volo_1=1 患者的 21 名 (5.6%) 死亡患者，以及 2766 名 volo_1=0 患者的 86 (3.1%) 名死亡患者，volo_1 1vs 0 的 OR 1.84 预测死亡 1 vs 0 。
因此，volo_1 1 vs 0 预测死亡 1 vs 0 的 OR &gt;0，并且 volo_1=0 的死亡患者少于 volo_1=1 的死亡患者。
如果我将数据库替换为二分变量（RTS_cat2），我有两个新数据库，其中 volo_1 1 vs 0 预测死亡 1 vs 0 的 OR &lt;0，并且 volo_1=0 的死亡患者数量比死亡人数多volo_1=1 的患者。
怎么可能呢？
我该如何处理这个问题？
这是我有问题的数据：
&lt;前&gt;&lt;代码&gt;&gt; x &lt;- xtabs(~dead + 交互(volo_1, RTS_cat2), data = db)
&gt; X
     交互（volo_1，RTS_cat2）
死亡 0.0 1.0 0.1 1.1
    0 2485 283 195 73
    1 12 1 74 20

&gt;表（db$dead，db$volo_1）
   
       0 1
  0 2680 356
  1 86 21

&gt; full.model &lt;- glm(dead ~ volo_1 , data = db,family=binomial())
&gt;物流.显示(完整.模型)

逻辑回归预测死亡 1 vs 0
 
               OR(95%CI) P(Wald 检验) P(LR 检验)
volo_1: 1 vs 0 1.84 (1.13,3) 0.015 0.021
                                                       
对数似然 = -464.1848
观察次数 = 3143
AIC 值 = 932.3696

&gt; full.model &lt;- glm(morto ~ volo_1 + RTS_cat2 , data = db,family=binomial())
&gt;物流.显示(完整.模型)

逻辑回归预测死亡率
 
                 粗 OR(95% CI) 调整值OR(95%CI) P(Wald 检验) P(LR 检验)
volo_1：1 vs 0 1.84 (1.13,3) 0.72 (0.42,1.24) 0.24 0.232
                                                                                     
RTS_cat2：1 vs 0 74.68 (41.26,135.18) 78.49 (43.12,142.9) &lt; 0.001＜ 0.001
                                                                                     
对数似然 = -289.3289
观察次数 = 3143
AIC 值 = 584.6577


db_rts &lt;- db[ 其中(db$RTS_cat2==1), ]

&gt;表（db_rts$morto，db_rts$volo_1）
   
      0 1
  0 195 73
  1 74 20
&gt;
&gt; full.model &lt;- glm(morto ~ volo_1 , data = db_rts,family=binomial())
&gt;物流.显示(完整.模型)

逻辑回归预测 morto ：1 vs 0
 
               OR(95%CI) P(Wald 检验) P(LR 检验)
volo_1: 1 vs 0 0.72 (0.41,1.27) 0.256 0.249
                                                          
对数似然 = -206.6552
观察次数 = 362
AIC 值 = 417.3104

db_rts1 &lt;- db[ 其中(db$RTS_cat2==0), ]

&gt;表（db_rts1$morto，db_rts1$volo_1）
   
       0 1
  0 2485 283
  1 12 1
&gt;
&gt; full.model &lt;- glm(morto ~ volo_1 , data = db_rts1,family=binomial())
&gt;物流.显示(完整.模型)

逻辑回归预测死亡率
 
               OR(95%CI) P(Wald 检验) P(LR 检验)
volo_1: 1 vs 0 0.73 (0.09,5.65) 0.765 0.754
                                                          
对数似然 = -82.6736
观察次数 = 2781
AIC 值 = 169.3472

]]></description>
      <guid>https://stats.stackexchange.com/questions/644915/regression-paradox</guid>
      <pubDate>Fri, 12 Apr 2024 22:47:07 GMT</pubDate>
    </item>
    </channel>
</rss>