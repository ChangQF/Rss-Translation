<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 26 Nov 2024 09:19:11 GMT</lastBuildDate>
    <item>
      <title>用百分比来描述少于100人的样本是否有问题？</title>
      <link>https://stats.stackexchange.com/questions/657851/is-it-problematic-to-use-percentages-to-describe-a-sample-with-less-than-100-peo</link>
      <description><![CDATA[这是一个非常基础、愚蠢的问题，但我找不到答案，而且最重要的是，我通常对常识/直觉持怀疑态度。
当整个样本中不到 100 人时，如果说“样本中 80% 的人喜欢香蕉口味”，我觉得这是“作弊”。但也许我错了，所以我才问这个问题。我发现至少有两个问题：

如果我忽略了样本量，可能会造成误导

有些百分比是不可能达到的，例如，如果样本中只有 10 个人，就不可能有 0 到 10% 之间的任何百分比


我在这里是否过于谨慎，使用这样的百分比真的可以吗？或者这真的是个问题？是否还有其他我没发现的问题？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657851/is-it-problematic-to-use-percentages-to-describe-a-sample-with-less-than-100-peo</guid>
      <pubDate>Tue, 26 Nov 2024 07:51:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么在分类中不使用软标签是可以的？</title>
      <link>https://stats.stackexchange.com/questions/657850/why-is-it-ok-not-to-use-soft-labels-in-classification</link>
      <description><![CDATA[从某种意义上说，我有一个与使用交叉熵损失函数与软标签可以吗？相反的问题，也就是为什么不可以在分类中使用软标签？
假设您有一个要解决的二元分类任务。以下是您通常的处理方式。您从一些未知的概率分布u(y=1|x)开始。您通过从中抽样来近似u(y=1|x)以生成数据集（概率分布p(y=1|x)）。然后创建一个模型q(y=1|x)。然后，通过最小化 q(y=1|x) 和 p(y=1|x) 之间的交叉熵损失，将模型拟合到概率分布 p(y=1|x)。
为了计算交叉熵，通常假设 p(y=1|x) 始终为 1 或 0，尽管这不一定正确 - 例如，假设我们的数据集中有两个体重、身高等相同的患者，但一个生病，另一个没有生病 - 如果是这样，则 p(y=1|x) = 1/2。相反，您通常会将第一个样本 p(y=1|x) 设置为 0，将第二个样本设置为 1。为什么做出这种假设如此普遍？这是一个安全的假设吗？如果是，为什么？换句话说，为什么软标签不总是用于分类任务？]]></description>
      <guid>https://stats.stackexchange.com/questions/657850/why-is-it-ok-not-to-use-soft-labels-in-classification</guid>
      <pubDate>Tue, 26 Nov 2024 07:50:10 GMT</pubDate>
    </item>
    <item>
      <title>预测确定性数据集的概率分布</title>
      <link>https://stats.stackexchange.com/questions/657848/predicting-the-probability-distribution-of-a-deterministic-dataset</link>
      <description><![CDATA[在经典机器学习回归中，我们通常假设目标变量$y$，给定输入$x$，遵循概率分布，这使我们能够建模和预测不仅$y$的预期值，而且还可以建模和预测其方差。
但是，考虑这样一种情况，其中输入$x$和目标变量$y$之间的关系是确定性的。也就是说，对于任何给定的输入$x$，都存在一个唯一且理论上可知的地面实况$y$。我们训练一个回归模型来预测给定$x$的$y$，生成一个预测$\hat{y}$。在预测$y$的值之后，我们还想预测预测本身的&quot;不确定性&quot;，或者在某种意义上&quot;方差&quot;。我们通过预测给定输入 $x$ 的值 $\sigma$（预测值为 $\hat{y}$，真实值为 $y$）来实现此目的，使得似然值 $f(y | \hat{y}, \sigma)$ 达到最大化，其中 $f$ 是以 $\hat{y}$ 为中心，方差为 $\sigma^2$ 的正态分布的概率密度函数。直观地看，我们针对给定 $x$ 预测的 $\sigma$ 在某种意义上告诉我们预测的不确定性。
由于数据生成过程中没有固有的随机性，并且数据集是确定性的，因此方差的传统概率解释并不直接适用。因此，核心问题是：
我们能否在这种确定性设置中为预测值 $\sigma$ 提供概率或正式解释？如果不是条件概率分布 $p(y|x)$ 的标准差，那么 $\sigma$ 代表什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657848/predicting-the-probability-distribution-of-a-deterministic-dataset</guid>
      <pubDate>Tue, 26 Nov 2024 06:04:39 GMT</pubDate>
    </item>
    <item>
      <title>如何拆分小型数据集以进行生存分析：训练/验证还是包含测试集？</title>
      <link>https://stats.stackexchange.com/questions/657847/how-to-split-a-small-dataset-for-survival-analysis-train-validation-or-include</link>
      <description><![CDATA[我正在使用一个包含 140 个样本的小型数据集对胰腺癌进行生存分析。该数据集包括 WSI 和掩码数据以及生存信息。
1. 当前方法
我在训练/验证拆分中使用 5 倍交叉验证，结果每倍有 112 个样本用于训练，28 个样本用于验证。
2. 合作者的建议
将数据集分成三部分 - 98 个用于训练，28 个用于验证，14 个用于测试集。
鉴于数据集较小且无法使用外部数据集（由于需要掩码和生存信息），我不确定从同一数据集中留出测试集是否合理。

仅依靠训练/验证结果会更好吗？
进一步拆分成测试集是否会冒着未充分利用本来就很小的数据集的风险？

任何关于小样本生存分析最佳实践的见解都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657847/how-to-split-a-small-dataset-for-survival-analysis-train-validation-or-include</guid>
      <pubDate>Tue, 26 Nov 2024 05:06:12 GMT</pubDate>
    </item>
    <item>
      <title>R 最适合拟合正偏指数数据的 glmmTMB 模型系列是什么</title>
      <link>https://stats.stackexchange.com/questions/657842/r-what-is-the-best-glmmtmb-model-family-to-fit-positively-skewed-index-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657842/r-what-is-the-best-glmmtmb-model-family-to-fit-positively-skewed-index-data</guid>
      <pubDate>Tue, 26 Nov 2024 02:34:04 GMT</pubDate>
    </item>
    <item>
      <title>在频率论的背景下，我们如何能够确定零假设为真/假？</title>
      <link>https://stats.stackexchange.com/questions/657840/in-a-frequentist-setting-how-are-we-able-to-condition-on-the-null-hypothesis-be</link>
      <description><![CDATA[引用 Casella 和 Berger (2002) 的话：假设检验由零假设 $H_0: \theta \in \Theta_0 $ 和备择假设 $H_1: \theta \in \Theta_0^c = \bar{H_0}$ 定义，其中 $\Theta$ 是总体参数 $\theta$ 的一组可能值，并且 $\Theta_0^c = \Theta - \Theta_0 $。
在频率论的设定中，$\theta$ 是一个未知但固定的量（也就是说，它是非随机的）。因此，对于给定集合$\Theta_0$，零假设$H_0$严格为真或假（但我们不知道是哪个）。备择假设，即否定，相应地为假或真。
让我们的检验统计量为$\hat{\theta} = f(X_1, ..., X_n)$。我们将拒绝域$RR \subset Range(\hat{\theta})$定义为我们选择拒绝$H_0$的检验统计量$\hat{\theta}$的值集。由于我们的样本 $X_1, ..., X_n$ 是随机的，$\hat{\theta}$ 是一个随机变量，因此数量 $p(\hat{\theta} \in RR)$ 是一个有效概率，类似于更简单的概率，如 $p(X \le 5)$
到目前为止一切顺利。然而，当我们开始定义 I 类错误时，我开始感到困惑。I 类错误是当我们拒绝 $H_0$ 即使它是 True 时。这在数学上定义为：
$$
\alpha = p(\hat{\theta} \in RR | H_0 \text{ is True}) = p(\hat{\theta} \in RR | \theta \in \Theta_0)
$$
这个概率对我来说毫无意义。$\theta$ 不是随机变量，因此 $\theta \in \Theta_0$ 不是概率事件，而是 True 或 False 值。概率框架（据我所知）不允许我们有意义地对实值或布尔值进行条件限制，而只能对事件进行条件限制。
这是怎么回事？我能做出的唯一有意义的解释是$\theta$是否是一个随机变量，这违反了频率统计的核心思想。]]></description>
      <guid>https://stats.stackexchange.com/questions/657840/in-a-frequentist-setting-how-are-we-able-to-condition-on-the-null-hypothesis-be</guid>
      <pubDate>Tue, 26 Nov 2024 01:27:13 GMT</pubDate>
    </item>
    <item>
      <title>理解重复实验中置信区间的解释</title>
      <link>https://stats.stackexchange.com/questions/657838/understanding-the-interpretation-of-confidence-intervals-in-repeated-experiments</link>
      <description><![CDATA[我理解 95% 置信区间 (CI) 的解释是，从长远来看，从重复实验计算出的 95% 的区间将包含真实参数。我还知道 CI 不是关于参数本身的概率陈述 - 我们不能说特定观察到的 CI 有 95% 的概率包含真实值。
但是，我试图理解以下场景：
假设我们运行 100 次实验，每次都计算感兴趣参数的 95% 置信区间。如果我随机选择其中一个 CI，那么说所选区间有 95% 的概率包含真实参数是否正确？
关键区别在于我们不能说相同的固定 CI 在重复实验中将保持 95% 的概率，而是每次新的重复都有新的 CI 值，并且每个新值都有 95% 的概率包含或不包含？]]></description>
      <guid>https://stats.stackexchange.com/questions/657838/understanding-the-interpretation-of-confidence-intervals-in-repeated-experiments</guid>
      <pubDate>Tue, 26 Nov 2024 00:12:44 GMT</pubDate>
    </item>
    <item>
      <title>频率移动平均值</title>
      <link>https://stats.stackexchange.com/questions/657837/moving-average-of-frequency</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657837/moving-average-of-frequency</guid>
      <pubDate>Tue, 26 Nov 2024 00:00:35 GMT</pubDate>
    </item>
    <item>
      <title>非消失步长 Q 学习</title>
      <link>https://stats.stackexchange.com/questions/657836/non-vanishing-stepsize-q-learning</link>
      <description><![CDATA[第一篇关于 q-learning 的论文使用步长 $(\alpha_n)_n\subset (0,1)$，使得
$$
\sum_n \alpha_n = \infty
$$
但
$$
\sum_n \alpha^2_n &lt; \infty。
$$
最近，在浏览 Bertsekas 和 Tsitsiklis 关于命题 $4.4$ 的神经动力学编程书籍时，我看到了以下陈述：
让 $r_t$ 由
$$
r_{t+1}(i) = (1-\alpha_t(i)) r_t(i) + \alpha_t(i) ( (Hr_t)(i)+w_t(i),
$$
其中 $w_t$ 是随机的，并且满足 $E[w_t(i)|\mathcal F_t]=0$ 对所有 $i$ 和 $t$ 和
$$
E[w^2_t(i)|\mathcal F_t \ \leq A + B \| r_t\|^2
$$
对于 $\mathbb R^n$ 上的任何范数。这里我们假设 $H$ 是一个伪收缩，即 $\| Hr - r^* \| \leq \beta \| r- r^* \|$ 对于所有 $r \in \mathbb R^n$ 且某些 $r^*$，其中 $\beta &lt;1$。然后，当 $ \sum_n \alpha_n = \infty$ 和 $\sum_n \alpha^2_n = \infty$ 时，$r_t$ 以概率 $1$ 收敛到 $r^*$ 
这里本质上 $H$ 充当值迭代算法。没有提供任何证据，所以我无法理解他们在哪个阶段使用了 $\sum_n \alpha^2_n = \infty$，但在声明之后提到它将在 $5$ 章中使用。在 $5$ 章中，它仅在命题 $5.5$ 中使用，其中还假设 $\sum_n \alpha^2_n &lt;\infty$。我不确定这里是否是提出这个问题的正确地方，但他们在声明中假设 $\sum_n \alpha^2_n = \infty$ 实际上是拼写错误吗？在此条件下，$Q$-学习是否存在任何已知的收敛条件？我只有这本书的纸质版，因此无法发布实际陈述的截图，对此深表歉意。]]></description>
      <guid>https://stats.stackexchange.com/questions/657836/non-vanishing-stepsize-q-learning</guid>
      <pubDate>Mon, 25 Nov 2024 22:59:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 MatchThem 进行倾向得分匹配 (PSM)</title>
      <link>https://stats.stackexchange.com/questions/657835/propensity-score-matching-psm-using-matchthem</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657835/propensity-score-matching-psm-using-matchthem</guid>
      <pubDate>Mon, 25 Nov 2024 22:53:25 GMT</pubDate>
    </item>
    <item>
      <title>在指数增长的集合中选择相同随机数的概率</title>
      <link>https://stats.stackexchange.com/questions/657833/chances-of-same-random-number-selection-over-an-exponentially-growing-set</link>
      <description><![CDATA[如果我每秒从一组数字中随机选择一个数字，该数字最初是集合 {1-&gt;10^100}，然后每秒大小翻倍，持续 1,000 秒，那么我在此期间两次选择相同两个数字的概率是多少？
1,000,000 秒呢？
1,000,000,000 秒呢？
1,000,000,000,000 秒呢？
当秒数趋于无穷大时，概率会趋于什么？
我之所以问这个问题，是因为我不相信我一直听到物理学家说的话，即如果多元宇宙（由永恒的膨胀创造，包含无限的可观测宇宙，如我们的宇宙）是无限的，那么可以保证有无限的“可观测宇宙”，其中的行星与我一模一样，现在做着和我一样的事情。我认为他们可能忽略了每个“可观测宇宙”的可能性空间无限大这一关键概念，这使得事情不必重复。如果上述数学问题的答案是一个非常低的概率，并且随着秒数趋于无穷大，它趋向于零，那么我觉得这可能支持我的感觉，即物理学家可能是错的。然后，您可以尝试将上述场景中的数字映射到每个“可观测宇宙”中原子的可能组合数，然后询问在无限的宇宙集中找到两个相同宇宙的概率是多少。答案可能是“几乎为零”。也许我问错了问题？想法......？]]></description>
      <guid>https://stats.stackexchange.com/questions/657833/chances-of-same-random-number-selection-over-an-exponentially-growing-set</guid>
      <pubDate>Mon, 25 Nov 2024 22:14:58 GMT</pubDate>
    </item>
    <item>
      <title>概率收敛速度</title>
      <link>https://stats.stackexchange.com/questions/657829/rate-of-convergence-in-probability</link>
      <description><![CDATA[我正在阅读这篇论文
在这篇论文中，他们证明了定理 7，其表述如下

定理 7：让 $p, q, X, Y$ 按照问题 1 中的方式定义，并假设 $0 \leq k(x, y) \leq K$。然后：
$$
\Pr_{X, Y} \left\{ 
\big| \text{MMD}_b[\mathcal{F}, X, Y] - \text{MMD}[\mathcal{F}, p, q] \big| &gt; 2 \left( \left( \frac{K}{m} \right)^{\frac{1}{2}} + \left( \frac{K}{n} \right)^{\frac{1}{2}} \right) + \varepsilon
\right\}
\leq 
2 \exp\left(-\frac{\varepsilon^2 mn}{2K(m+n)}\right),
$$
其中 $Pr_{X, Y}$ 表示 $m$ 个样本 $X$ 和 $n$ 个样本 $Y$ 的概率。

在此之前定理中，作者指出经验 MMD 以 $O((m+n)^{-\frac{1}{2}})$ 的概率收敛到其总体值。我不明白他们是如何得出这个收敛速度的。您能否提醒我一下以速率收敛的概率定义，并解释它与定理 7 有何关联？]]></description>
      <guid>https://stats.stackexchange.com/questions/657829/rate-of-convergence-in-probability</guid>
      <pubDate>Mon, 25 Nov 2024 21:18:24 GMT</pubDate>
    </item>
    <item>
      <title>单一结果，随时间重复的协变量：线性混合模型？</title>
      <link>https://stats.stackexchange.com/questions/657802/single-outcome-repeated-covariates-in-time-linear-mixed-models</link>
      <description><![CDATA[我有一个数据集，我想预测一个结果（最后一次随访的 EDSS，以 0 到 10 的数字尺度测量，仅包括 0.5 个小数）。对于每个患者，我有每个患者的 2 个生物标志物测量值。我想创建一个使用生物标志物预测最后一次随访的 EDSS 的预测模型。
我尝试了线性混合模型，但由于未实现收敛，因此会引发错误。这是我使用的公式
EDSS_lastfollow ~ nfl + (1|ID)
我尝试过使用高斯链接函数，也尝试过将结果用作序数变量，但无法达到收敛。我怀疑这是因为我实际上没有重复的结果，而是重复的协变量。我想考虑协变量的 ID 变异性来对其进行建模。你知道我该如何继续建模吗？只要拍一部简单的电影就更好了？]]></description>
      <guid>https://stats.stackexchange.com/questions/657802/single-outcome-repeated-covariates-in-time-linear-mixed-models</guid>
      <pubDate>Mon, 25 Nov 2024 12:04:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的回归中的 HAC（Newey-West）标准误差小于普通标准误差？</title>
      <link>https://stats.stackexchange.com/questions/657795/why-are-the-hac-newey-west-standard-errors-smaller-than-the-ordinary-standard</link>
      <description><![CDATA[我用时间序列进行回归分析，然后进行了 Breusch-Godfrey（BG）检验和 White 检验。检验结果表明，自相关和异方差同时存在。因此，我选择使用 HAC（Newey-West）标准误差进行分析。我惊讶地发现，HAC（Newey-West）标准误差比普通标准误差要小。为什么会这样？在这种情况下，我应该使用哪种标准误差？]]></description>
      <guid>https://stats.stackexchange.com/questions/657795/why-are-the-hac-newey-west-standard-errors-smaller-than-the-ordinary-standard</guid>
      <pubDate>Mon, 25 Nov 2024 10:09:08 GMT</pubDate>
    </item>
    <item>
      <title>信息标准相对于交叉验证的优势</title>
      <link>https://stats.stackexchange.com/questions/657772/advantages-of-information-criteria-over-cross-validation</link>
      <description><![CDATA[我理解 AIC 渐近等同于留一法交叉验证，而 BIC 具有与留一法交叉验证类似的渐近等同性。我的问题是，除了计算效率之外，还有什么理由比交叉验证更倾向于使用 AIC/wAIC/BIC 等信息标准？
在生态学文献中，使用 AIC 进行模型选择非常常见。但如果可以进行交叉验证，还有什么理由使用 AIC？]]></description>
      <guid>https://stats.stackexchange.com/questions/657772/advantages-of-information-criteria-over-cross-validation</guid>
      <pubDate>Sun, 24 Nov 2024 17:27:03 GMT</pubDate>
    </item>
    </channel>
</rss>