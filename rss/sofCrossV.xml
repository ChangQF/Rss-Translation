<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 17 Jan 2025 12:31:17 GMT</lastBuildDate>
    <item>
      <title>针对 2 个以上类别的卡方检验（2x5 列联表）</title>
      <link>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</link>
      <description><![CDATA[我有一个 2x5 的频率表，其中有 2 列名为男性和女性，还有 5 个原始列名为病理 A、B、C、D 等。
我试图确定性别比例在病理类别之间是否存在统计差异。
例如：男性是否比女性更容易受到病理 A 的影响（每个类别都是如此）？
我的问题如下：我可以将其他类别（例如 B + C + D + E）相加以创建一个新的 2x2 列联表并对其进行卡方检验吗？
这在统计上正确吗？如果我的 p 值小于 0.05，我可以得出的结论是：男性比女性更容易受到病理 A 的影响？
因为问题是，如果我对所有数据计算一次卡方检验，我只能对情况有一个整体了解。
此致，
Adrien]]></description>
      <guid>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</guid>
      <pubDate>Fri, 17 Jan 2025 12:27:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Mercers 定理总是被引用用于核学习而不是 Moore-Aronszajn</title>
      <link>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</link>
      <description><![CDATA[为什么在大多数对核技巧的解释中，Mercer 定理都用作论证？我们能否用 Moore-Aronszajn 定理来证明这一点，而 Moore-Aronszajn 定理并没有将紧致性假设置于 $X$ 和 $k$ 连续性上？]]></description>
      <guid>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</guid>
      <pubDate>Fri, 17 Jan 2025 11:39:14 GMT</pubDate>
    </item>
    <item>
      <title>变换与顺序有关的分布</title>
      <link>https://stats.stackexchange.com/questions/660157/transforming-a-distribution-where-the-order-matters</link>
      <description><![CDATA[我有一组 $E = \{X_{ij}\}$，其中 $1 \leq i &lt; j \leq n$，s.t. $|E| = \binom{n}{2}$。$X_{ij}$ 在 $\sim [0,1]$ 内都是独立同分布的。这些是完整加权图的边。
假设我选择一个顶点并根据此处中描述的规则将其与相关边一起移除，从而获得较小的$E&#39;$。
分布可能会因此而改变。由于我有兴趣保留这些值的顺序（这对于属性在后续步骤中保持充分和必要是必要的），我可以使用此处描述的参数来重新调整剩余的值，并得出结论：$E&#39;$ 仍然是均匀分布的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660157/transforming-a-distribution-where-the-order-matters</guid>
      <pubDate>Fri, 17 Jan 2025 11:37:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 calc 查找 emmeans 中的样本大小，调用准二项式会产生奇怪的结果</title>
      <link>https://stats.stackexchange.com/questions/660156/using-calc-to-find-sample-size-in-emmeans-call-for-quasibinomial-yields-strange</link>
      <description><![CDATA[我在一项实验研究中运行了一个具有准二项式系列的 glm，该研究的因子有 4 个水平、2 个协变量和一个二项分布的响应（10 个正确/错误响应的总和）：
调用：
glm(formula = cbind(PT1SVAAll, 10 - PT1SVAAll) ~ CFGroup + PreSVAAll + 
FBPrePT1SVA, family = quasibinomial(link = &quot;logit&quot;), data = TestResultsAllreorderedPretestDoneFB)
系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) -2.77546 0.58445 -4.749 5.10e-05 ***
CFGroupDA 0.81332 0.53051 1.533 0.136 
CFGroupM -0.37421 0.59334 -0.631 0.533 
CFGroupR 0.57151 0.57806 0.989 0.331 
PreSVAAll 0.70464 0.14138 4.984 2.65e-05 ***
FBPrePT1SVA 0.02369 0.05326 0.445 0.660 
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（准二项式系列的分散参数取为 2.031543）

零偏差：34 个自由度上的 150.183

残差偏差：29 个自由度上的 68.354
（由于缺失，删除了 9 个观测值）
AIC：NA
Fisher 评分迭代次数：4
由此我假设 n=35（零偏差的 df+1）。我尝试使用 calc 语法查找因子 (CFGroup) 每个级别的样本大小，但得到了奇怪的结果：
emmeans(mod.PT1multfactors, &quot;CFGroup&quot;, infer = c(TRUE, TRUE), type=&quot;response&quot;,
+ calc = c(n = &quot;.wgt.&quot;))
CFGroup prob SE df n asymp.LCL asymp.UCL null z.ratio p.value
C 0.209 0.0645 Inf 90 0.1091 0.362 0.5 -3.415 0.0006
DA 0.373 0.0817 Inf 90 0.2305 0.541 0.5 -1.490 0.1363
M 0.153 0.0637 Inf 80 0.0648 0.321 0.5 -3.485 0.0005
R 0.318 0.0898 Inf 90 0.1717 0.512 0.5 -1.842 0.0655

使用的置信度：0.95

区间是从 logit 尺度反向转换而来的

测试是在 logit 尺度上执行的


出于某种原因，calc 似乎可能会将每个级别的 n 乘以权重 10（总共 10 个响应），使得 C、DA 和 R 的每个级别的 n 为 9，M 的每个级别的 n 为 8。但加起来是 36，而不是我上面从模型的零偏差假设的样本大小 35。
有人能解释一下这里发生了什么吗？我如何才能找到每个级别的准确样本量？]]></description>
      <guid>https://stats.stackexchange.com/questions/660156/using-calc-to-find-sample-size-in-emmeans-call-for-quasibinomial-yields-strange</guid>
      <pubDate>Fri, 17 Jan 2025 10:57:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 I() 来更好地管理多个数据点</title>
      <link>https://stats.stackexchange.com/questions/660155/using-i-to-better-manage-many-data-points</link>
      <description><![CDATA[我有一个包含 3200 多行的大型数据框。我使用相关独立变量对疾病结果进行了逻辑回归分析，其中一个变量是液体平衡，范围从 -500 到 +1500。
我咨询的统计学家建议我使用
glm(disease~I(fluidbal/500)+var2+var3...var5, family = &quot;binomial&quot;, data = na.omit(data.frame))

因为这会将液体平衡分成 500 毫升的块。 P 值保持不变，但对于我的森林图 (ggplot2)，这样做可以澄清图（之前，所有值都靠近中心，CI 条不可见）。
社区认为这合法吗？
通过使用 I(fluidbalance/500)，我的目的是实现数据的更好分辨率。]]></description>
      <guid>https://stats.stackexchange.com/questions/660155/using-i-to-better-manage-many-data-points</guid>
      <pubDate>Fri, 17 Jan 2025 10:41:15 GMT</pubDate>
    </item>
    <item>
      <title>加权交叉熵的理论依据</title>
      <link>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</link>
      <description><![CDATA[假设我们正在构建一个二元分类模型，可以将其视为学习函数
$$ p : X \mapsto [0, 1] $$
其中$p(X) := \mathbb{P}(Y=1|X)$，而$\hat{p}$是某种机器学习模型（例如神经网络）。
常用的损失函数是最小化$p$和$\hat{p}$之间的负交叉熵：
$$ l(p, \hat{p}) = -y\log \hat{p}(x) - (1-y)\log(1-\hat{p}(x))$$
这当然相当于模型$Y|X \sim Bernoulli(p(X))$的最大似然估计。
在某些情况下，结果高度不平衡，这使得训练在实践中变得困难。例如，如果数据是垃圾邮件分类，其中只有 1% 的结果是垃圾邮件，那么很容易收敛到一个简单的解决方案/局部最优，它只为每个观察设置$p(X) \approx 0$。理论上，在大样本量和全局最优的情况下，这不是问题 - 但在实践中，这可能是一个大问题。
解决这个问题的一种常见方法是使用“加权交叉熵”损失，其中权重与观察到的频率成比例。例如，
$$w_0 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=0\}}, w_1 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=1\}} $$
损失为
$$ l^{weighted}(p, \hat{p}) = -w_1y\log\hat{p}(x) - w_0(1-y)\log(1-\hat{p}(x)) $$
其中直觉是稀有类别的权重更高，因此模型“更加关注”对这些观察结果。

通过最小化这个加权损失函数找到的最优函数 $\hat{p}^{weighted}$ 是否有任何已知的理论性质，还是纯粹是启发式的？在全局最优值中，最优 $\hat{p}$ 和 $\hat{p}^{weighted}$ 相比如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</guid>
      <pubDate>Fri, 17 Jan 2025 09:25:45 GMT</pubDate>
    </item>
    <item>
      <title>确认蒙特卡洛简历</title>
      <link>https://stats.stackexchange.com/questions/660151/confirmation-on-montecarlo-cv</link>
      <description><![CDATA[我想估算一个测量值。假设我们采用经验估计来估计累积分布函数 (CDF) $F(x,y)$。我想将交叉验证与蒙特卡洛相结合。
我的想法：
方法说明
目标是结合使用经验估计与蒙特卡洛模拟和k 倍交叉验证来估计基于累积分布函数 (CDF) (F(x, y)) 的测量值。

数据生成：
每次蒙特卡洛迭代都会从均匀分布生成数据。例如，两个变量 (X) 和 (Y) 由独立均匀随机变量产生，样本量为 (n = 300)。

为了进行比较，假设测量值有一个固定的真实值（例如 (0.23)）。


蒙特卡罗模拟：为了提供统计稳健性，模拟通过 5,000 次迭代完成。

根据获得的数据，使用平滑的经验 CDF 计算每次迭代中的估计量。


通过 k 倍验证：
每次迭代将数据集分为 (k = 5) 倍。

对训练集（数据）上的每个折叠计算估计量估计量与真实值之间的平均平方差称为“偏差”。估计量与真实值在所有迭代过程中的平均平方差称为均方误差 (MSE)。

实施和输出：- 模拟在 5,000 次迭代中生成测量估计值，以及偏差和 MSE。这些测量值显示出 MSE 随着样本量增加而降低的模式，用于评估估计量的准确性和可靠性。

我们可以这样做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660151/confirmation-on-montecarlo-cv</guid>
      <pubDate>Fri, 17 Jan 2025 07:54:49 GMT</pubDate>
    </item>
    <item>
      <title>r 匹配倾向得分和最近邻</title>
      <link>https://stats.stackexchange.com/questions/660146/r-matching-propensity-scores-and-nearest-neighborhood</link>
      <description><![CDATA[我对匹配过程有理论上的理解，但我不明白 MatchThem 库中是如何实现的。
我像这样指定模型
 matchthem( treatment ~ x1 + x2, x3, 
data = df,
method = &quot;nearest&quot;,
distance = &quot;glm&quot;,
link = &quot;logit&quot;
)

当使用 bal.tab 函数检查余额时，我看到
 Mean.Diff.Unmatch Mean.Diff.Adj
distance 1.087 0.715


我的问题是，Mean.Diff.Unmatched (distance) 1.087 是多少？由于 matchtem 函数估计倾向得分，距离不应该小于 1 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660146/r-matching-propensity-scores-and-nearest-neighborhood</guid>
      <pubDate>Fri, 17 Jan 2025 05:40:43 GMT</pubDate>
    </item>
    <item>
      <title>日食是否减少了新冠肺炎死亡人数？</title>
      <link>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</link>
      <description><![CDATA[我在 R 中模拟了一些现实数据，这些数据显示了 Covid-19 死亡人数随时间的变化情况，以及日食（2024 年 4 月 8 日）发生前的天数：

如果有人不太了解，仅从数据来看，可能会认为日食是降低 Covid 死亡人数的原因。此外，有人可以拟合回归模型，该模型甚至可能很好地拟合数据。
我读到过，我们在统计学中拥有所有这些复杂的技术，例如差异-差异、回归不连续性、合成控制、工具变量、倾向得分匹配等 - 所有这些方法旨在在某种程度上找出我们是否能够真正得出结论，即统计模型的结果忠实地代表了自然。
但在某种程度上，我们在决定将哪些变量纳入统计模型时是否只是使用常识？]]></description>
      <guid>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</guid>
      <pubDate>Fri, 17 Jan 2025 05:13:01 GMT</pubDate>
    </item>
    <item>
      <title>CNN 模型在经过几个周期后仍无法学习</title>
      <link>https://stats.stackexchange.com/questions/660143/cnn-model-is-not-learning-after-some-epochs</link>
      <description><![CDATA[我根据一篇研究论文实现了一个对象检测模型（代码包含在 github 中），并对其进行了一些更改，以便为我的硕士论文创建一个新的更好的模型。为了比较它们，我在相同的环境中使用具有相同参数和其他内容的整个测试数据集。我的模型运行良好，它给了我 90% 的准确率，而原始模型只给了我 63%，因为我只使用部分数据来训练这两个模型，我认为这一定是原始模型的准确率低于研究论文中记录的分数（%86）的原因。这是我的模型的训练损失，它有 5 个损失，并且它们似乎在几个时期后一直在改善，基于高结果和测试集上的准确预测（我已经检查过预测 BBoxes 与 GTs 非常接近），我的模型可能已经达到了一个很好的局部最小值，或者它正在努力达到最佳的全局最小值，因为有 5 个损失，它们的结果似乎在这一点上收敛并且没有得到很好的改善（学习步骤太低）。我检查了各种优化器和学习率调度器，发现它们都以相同的方式运行，但 AdamW 和 Cosing LR Scheduler 是所有调度器中最好的，因为它们的损失最低。

如您所见，没有过度拟合，损失不断减少，模型非常大，我给了模型 1500 张图像（每张 500 张），并将结果翻倍到 3000 张（每张 1000 张），损失略有降低，但模式相同，并且在相同数量的 epoch 之后保持不变。所以我有一些问题：我的模型是否达到了可能的最佳分数？它不能学到更多吗？如何让它学到更多？
我期望模型能学到更多，但它并没有进步。]]></description>
      <guid>https://stats.stackexchange.com/questions/660143/cnn-model-is-not-learning-after-some-epochs</guid>
      <pubDate>Fri, 17 Jan 2025 05:06:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有事实依据的情况下评估重要性抽样的质量</title>
      <link>https://stats.stackexchange.com/questions/660142/how-to-evaluate-the-quality-of-importance-sampling-without-groundtruth</link>
      <description><![CDATA[我对通过重要性抽样估计$\mathbb E_{p(x)}[f(x)]$感兴趣。用$q(x)$表示提议分布。我已推导出一些提议分布$q_j(x)$，我想知道在相同数量的蒙特卡洛样本下，哪个能产生最精确的估计。问题是我不知道真实期望值，而且可能永远无法获得，因为 $x$ 的维度相对较高（~20）。
我能想到的提案分布 $q$ 成为“好”分布的一个必要条件是 $\frac{p(x)f(x)}{q(x)}$ 相对于 $x \sim q(x)$ 的方差应该很小。这是因为当$q(x) \propto p(x) f(x)$时，重要性抽样估计量的方差变为零，而蒙特卡洛平均值给出精确的积分$\int p(x) f(x)\,\mathrm dx$。但这是一个充分条件吗？我应该通过蒙特卡洛方差来评估提案分布的质量吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660142/how-to-evaluate-the-quality-of-importance-sampling-without-groundtruth</guid>
      <pubDate>Fri, 17 Jan 2025 03:42:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 和 R 中提取负二项式参数 $r$ 和 $\pi$？</title>
      <link>https://stats.stackexchange.com/questions/660141/how-to-extract-negative-binomial-parameters-r-and-pi-in-python-and-r</link>
      <description><![CDATA[我尝试使用 Python 和 R 提取移位负二项分布的参数 $r$ 和 $\pi$。但是，我很难在两种语言之间获得一致的结果。
假设我的示例数据是：1,2,3,4,5,6,7,8,9,9,8,7,6,5,4,3,2,1
我对负二项 PMF 使用以下参数化：
$$
p(k) = \binom{k - 2 + r}{k - 1} \cdot \pi^r \cdot (1 - \pi)^{k-1}
$$
这是我的 Python 代码（使用statsmodels):
X = np.ones_like(s)
s = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 8, 7, 6, 5, 4, 3, 2, 1])
res = sm.NegativeBinomial(s, X).fit(start_params=[1, 1], disp=False)
mu = np.exp(res.params[0]) # 平均值 (mu)
p = 1 / (1 + np.exp(res.params[0]) * res.params[1]) # 成功概率

这是我的 R 代码（使用 fitdistr）：
data = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 8, 7, 6, 5, 4, 3, 2, 1)
fit &lt;- fitdistr(data, &quot;Negative Binomial&quot;)
size &lt;- fit$estimate[&quot;size&quot;] # r：size 参数
mu &lt;- fit$estimate[&quot;mu&quot;] # 平均值，用于计算 p
r = size
pi = r / (r + mu)

我不确定我将 Python 中的拟合参数转换为 $r$ 和 $\pi$ 是否正确，我也不清楚这两种方法是否使用相同的参数化。
有人能帮忙澄清一下吗：

我对 $r$ 和 $\pi$ 的转换在 Python 和 R 中是否正确？
Python 和 R 对负二项分布的拟合是否存在差异，或者我应该注意哪些参数化差异？

提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/660141/how-to-extract-negative-binomial-parameters-r-and-pi-in-python-and-r</guid>
      <pubDate>Fri, 17 Jan 2025 03:38:59 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归中的虚拟变量与虚拟变量交互作用</title>
      <link>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</link>
      <description><![CDATA[我正在 R 中进行泊松回归，以估计按年龄组和病毒分类的死亡人数，其中相互作用的项是因子：
model &lt;- glm(death_count ~ strain * cohort + age + year,
family = poisson(link = &quot;log&quot;),
offset = log(exposure),
data = df)

我的 df 是面板数据，其中包含每年特定年龄的死亡人数。每年都以特定病毒为特征，每个年龄分配一个群体。我试图找出以病毒 C 为特征的年份中死亡人数减少的统计意义。以下是简化的回归输出：
 估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -15.39575 0.07621 -202.012 &lt; 2e-16 ***
病毒A -1.29389 0.08358 -3.516 0.000437 ***
病毒B 2.80059 0.06230 12.851 &lt; 2e-16 ***
病毒C 4.22142 0.05298 60.800 &lt; 2e-16 ***
群组X -2.99472 0.02494 -39.890 &lt; 2e-16 ***
群组Y -1.76074 0.02747 -27.691 &lt; 2e-16 ***
群组Z -1.31331 0.03499 -8.953 &lt; 2e-16 ***
病毒A：群组X 1.39666 0.07366 5.385 7.24e-08 ***
病毒B：群组X 1.21714 0.05685 3.820 0.000134 ***
病毒C：群组X -3.97906 0.03390 -28.883 &lt; 2e-16 ***
病毒A：队列Y 1.24520 0.10246 2.393 0.016701 * 
病毒B：队列Y 1.05056 0.07980 0.634 0.526360 
病毒C：队列Y -1.43923 0.03422 -12.836 &lt; 2e-16 ***
virusA:cohortZ 0.12472 0.13408 0.930 0.352274 
virusB:cohortZ -0.33748 0.11851 -2.848 0.004404 ** 
virusC:cohortZ -1.13441 0.04187 -3.210 0.001327 ** 

我知道没有交互项的系数是与参考组相比的，但我听说在泊松回归中，交互项并不那么简单。
我有兴趣解释为什么与队列 Y 和 Z 相比，队列 X 感染病毒 C 的死亡率减少幅度最大。我不太明白如何理解交互系数，我也不明白为什么截距为负。如果没有偏移量，截距 = 0.18252，我无法理解这一点，因为我认为添加偏移量会将 DV 变成速率。]]></description>
      <guid>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</guid>
      <pubDate>Fri, 17 Jan 2025 00:16:33 GMT</pubDate>
    </item>
    <item>
      <title>如果需要真实参数的值来确定统计数据是否无偏，那么无偏估计量的意义何在？</title>
      <link>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</link>
      <description><![CDATA[我对无偏估计量的定义是：“如果用于估计参数的统计数据的抽样分布的平均值等于被估计参数的值，则该统计数据是无偏估计量。”
我知道如何确定统计数据是否是无偏估计量，因为我能够基于此解决应用题，但我不明白我们为什么要使用无偏估计量。我的笔记说，您需要使用无偏估计量，以便您的估计更准确。这对我来说很有意义，但为了确定统计数据是否是无偏估计量，您需要知道参数的值，以便将其与抽样分布的平均值进行比较，看看它们是否相等。如果使用无偏估计量来估计参数的值，如果我们已经知道参数的值，使用它有什么意义呢？
我一直在为此绞尽脑汁，但无济于事，如能得到任何帮助我将不胜感激，谢谢。
（我不擅长措辞，如果我听起来很重复或没有意义，请原谅）]]></description>
      <guid>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</guid>
      <pubDate>Thu, 16 Jan 2025 15:06:38 GMT</pubDate>
    </item>
    <item>
      <title>核学习中 RKHS 与特征空间的关系</title>
      <link>https://stats.stackexchange.com/questions/660057/relation-of-rkhs-to-feature-space-in-kernel-learning</link>
      <description><![CDATA[在标准 SVM 公式中，我们通常会寻找一个向量 $w \in \mathbb{R}^D$，该向量定义 $\mathbb{R}^D$ 中的超平面。决策函数的形式如下：
$$
f(x) = \operatorname{sign}(\langle w, x \rangle + b),
$$
其中 $\langle \cdot, \cdot \rangle$ 是 $\mathbb{R}^D$ 中的标准内积，而 $b \in \mathbb{R}$ 是偏差项。
现在，假设我们有一个 p.d 内核 $k$，我们知道有一个唯一的 RKHS $H_k$，因此我们可以寻找 $f \in H_k$ 在 $H_k$ 中定义一个超平面。相应的决策函数变为：
$$
f(x) = \operatorname{sign}(\langle f, \phi_1(x) \rangle_{H_k} + b),
$$
其中 $\phi_1(x) = k(\cdot, x) \in H_k$ 是进入 RKHS 的规范特征图。现在，例如通过铰链损失公式的软边距 svm，我们可以使用表示定理来论证 $f^*$ 位于由我们的训练模式引起的规范特征图的跨度内。
问题
现在，我的问题如下。在这个公式中，我们“看”对于 RKHS 中的超平面，但在大多数标准介绍中，人们认为我们在（可能无限的）特征空间中寻找超平面。
我知道 $k$ 会诱导另一个特征图（实际上，我认为有无数个，因为内积对正交变换不变？）$\phi_2: X \to F$ 进入某个希尔伯特空间 $F$，满足：
$$
\langle \phi(x)_2, \phi(y)_2 \rangle_{F} = k(x, y)。
$$
因此，我们有两个特征图：
$$
\phi_{1}: x \mapsto k(\cdot, x) \in H_k \quad \text{(进入 RKHS 的规范映射),}
$$
$$
\phi_{2}: x \mapsto \phi_2(x) \in F \quad \text{(进入某个希尔伯特空间 $F$ 的映射)}。
$$
我们现在是否可以争辩说，找到某个 $f^* \in H_k$ 将自动导致 $g^* \in F$，如下所示：
$$
\langle \phi(x)_2, \phi(y)_2 \rangle_{F} = \langle \phi(x)_1, \phi(y)_1 \rangle_{H_k} = k(x, y) $$
因此
$$ \langle f^*, \phi_1(y) \rangle_{H_k} = \sum_{i=1}^n \alpha_i \langle \phi_1(x_i), \phi_1(y) \rangle_{H_k} = \sum_{i=1}^n \alpha_i \langle \phi_2(x_i), \phi_2(y) \rangle_{F} = \langle g^*, \phi_2(y) \rangle_{F}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660057/relation-of-rkhs-to-feature-space-in-kernel-learning</guid>
      <pubDate>Wed, 15 Jan 2025 12:18:36 GMT</pubDate>
    </item>
    </channel>
</rss>