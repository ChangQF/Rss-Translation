<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 25 Dec 2024 09:16:58 GMT</lastBuildDate>
    <item>
      <title>在 Friedman 检验中拒绝 H0，但在任何成对 wilcoxin 检验中均无法拒绝</title>
      <link>https://stats.stackexchange.com/questions/659188/reject-h0-on-friedman-test-but-fail-to-reject-in-any-pairwise-wilcoxin-test</link>
      <description><![CDATA[我目前正在比较不同模型的 auroc，我首先进行了 Friedman 检验，然后进行了成对 Wilcoxon 检验以查看差异。
测试数据：数据链接
这是我的 r 代码：
variables &lt;- c(&quot;model_name&quot;, &quot;n_pcs&quot;, &quot;n_snps&quot;,&quot;treatment&quot;)

# 如果尚未完成，则创建“treatment”变量
auc$treatment &lt;- with(auc, paste(model_name, n_pcs, n_snps, sep = &quot;_&quot;))

# 加载所需库
library(RColorBrewer)

# 加载所需库
library(ggplot2)
library(multcompView)

# 循环遍历变量，执行 Friedman 检验，计算组标签并绘图
结果 &lt;- lapply(variables, function(var) {
# 创建矩阵：行 = 观察值，列 = 组（变量的级别）
组 &lt;- unique(auc[[var]])
样本 &lt;- sapply(groups, function(g) auc$roc_auc[auc[[var]] == g])
y &lt;- auc$roc_auc

# 执行 Friedman 检验
friedman_result &lt;- friedman.test(Sample)

# 打印 Friedman 检验结果
cat(&quot;Friedman test for&quot;, var, &quot;\n&quot;)
print(friedman_result)
cat(&quot;\n&quot;)

# 带 Bonferroni 调整的成对 Wilcoxon 符号秩检验
p_values &lt;- pairwise.wilcox.test(y, auc[[var]], p.adjust.method = &quot;bonferroni&quot;, exact = FALSE)$p.value
print(p_values)

# 创建重要性矩阵
sig_matrix &lt;- matrix(1, nrow = length(groups), ncol = length(groups))
rownames(sig_matrix) &lt;- colnames(sig_matrix) &lt;- groups

# 用调整后的 p 值填充矩阵
for (i in 1:nrow(p_values)) {
for (j in 1:ncol(p_values)) {
if (!is.na(p_values[i, j])) {
sig_matrix[i+1, j] &lt;- p_values[i, j]
sig_matrix[j, i+1] &lt;- p_values[i, j]
}
}
}

print(sig_matrix)

# 分配组标签
group_labels &lt;- multcompLetters(sig_matrix, Threshold = 0.05)$Letters

# 计算每个组的中位数
medians &lt;- tapply(auc$roc_auc, auc[[var]], median, na.rm = TRUE)

# 为 ggplot 准备数据
plot_data &lt;- data.frame(
roc_auc = y,
group = factor(auc[[var]], levels = groups)
)
label_data &lt;- data.frame(
group = names(group_labels),
labels = group_labels,
y = 1.1 # 图上方组标签的位置
)
median_data &lt;- data.frame(
group = names(medians),
medians = medians
)

# 创建 ggplot 箱线图
p &lt;- ggplot(plot_data, aes(x = group, y = roc_auc)) +
geom_boxplot(fill = &quot;#EBEBEB&quot;, color = &quot;black&quot;, width = 0.6, position = position_dodge(0.9)) + # 灰色框，带黑色边框
theme_bw(base_size = 14) +
geom_text(data = median_data, aes(x = group, y = medians + 0.05, label = round(medians, 2)),
color = &quot;red&quot;, size = 3) + # 添加中值
geom_text(data = label_data, aes(x = group, y = y, label = labels),
color = &quot;blue&quot;, size = 4) + # 添加组标签
labs(title = paste(&quot;Friedman Test with Pairwise Wilcoxon:&quot;, var),
x = ifelse(var == &quot;treatment&quot;, &quot;&quot;, var), # 删除 &#39;treatment&#39; 的 x 标签
y = &quot;AUROC&quot;) +
ylim(0, 1.2) # 设置 y 轴限值

if (var == &quot;treatment&quot;) {
p &lt;- p + theme(
plot.margin = margin(10, 10, 10, 10), # 在图周围添加边距
axis.text.x = element_text(angle = 45, hjust = 1, size = 8), # 旋转 x 轴标签
axis.title.x = element_text(size = 10), # 调整 x 轴标题大小
axis.title.y = element_text(size = 10) # 调整 y 轴标题大小
)
} else {
p &lt;- p + theme(
plot.margin = margin(10, 10, 10, 10), # 在图表周围添加边距
axis.title.x = element_text(size = 10), # 调整 x 轴标题大小
axis.title.y = element_text(size = 10) # 调整 y 轴标题大小
)
}

# 打印图表
print(p)

# 返回测试结果和组标签
list(test_result = friedman_result, p_values = p_values, group_labels = group_labels)
})

奇怪的结果：
Friedman chi-squared = 23.952, df = 3, p-value = 2.556e-05
 MLP RandomForest SVM
RandomForest 0.6986949 NA NA
SVM 0.4126711 1.0000000 NA
XGBoost 1.0000000 0.4126711 0.1787532

我写错了代码，还是这种情况比较少见，但确实存在？
谢谢~]]></description>
      <guid>https://stats.stackexchange.com/questions/659188/reject-h0-on-friedman-test-but-fail-to-reject-in-any-pairwise-wilcoxin-test</guid>
      <pubDate>Wed, 25 Dec 2024 06:16:32 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用小样本引导法来满足功效分析要求吗？</title>
      <link>https://stats.stackexchange.com/questions/659185/can-i-use-bootstrapping-for-small-sample-sizes-to-satisfy-the-power-analysis-req</link>
      <description><![CDATA[我有 15 名参与者在条件 A 下执行任务，还有 15 名参与者在条件 B 下执行任务。为了提高数据的有效性，每个参与者重复了 20 次任务。据我了解，在方差分析中，这些数据仍然只被视为每个条件的 15 个数据点，因为对于每个参与者，20 次重复减少为一个平均值。所以我的理解是，方差分析没有考虑到我总共进行了 2*300 次测量，但我可能只对每个参与者进行了一次测量。
问题：虽然条件 A 下的数据似乎始终比条件 B 下的数据小，但功效分析表明，我需要的样本量是条件 A 下的十倍。我不可能再重复这项研究，而且绝对不可能有所需的样本量。
问题：参与者的重复测量表明重复是相互独立的（例如，没有学习效果等）。对我来说，这意味着实际上我在每种情况下都有 300 个数据点，而不仅仅是 15 个平均数据点。如果我将两种条件下的 300 个数据点相互比较，而不对测量值进行平均，则统计数据会起作用。但样本量为 15 时则不行。是否有可能使用重复测量来引导数据，最终目标是满足所需的样本量？您会推荐哪种引导程序？还有其他不需要我重新进行整个实验的建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659185/can-i-use-bootstrapping-for-small-sample-sizes-to-satisfy-the-power-analysis-req</guid>
      <pubDate>Wed, 25 Dec 2024 02:16:43 GMT</pubDate>
    </item>
    <item>
      <title>从指数函数分布获得幂律的必要充分条件？</title>
      <link>https://stats.stackexchange.com/questions/659182/necessary-and-sufficient-conditions-to-obtain-power-law-from-distribution-over-e</link>
      <description><![CDATA[分布 $p(x)$ 的哪些属性 (1) 是充分的且 (2) 是必要的，以使
$$-\log \Bigg(1 - \int_{x=0}^{x=1} p(x) \, (1-x)^k \, dx \Bigg)$$
导致幂律
$$\propto k^{-b}$$
对于某个常数 $b &gt; 0$？
我有一个隐含的假设，即分布 $p(x)$ &quot; n&quot;在某种意义上，但我不确定这个假设到底是什么。也许是平滑的、连续的，还是类似的东西？
我已经得出 Beta 分布和 Kumaraswamy 分布就足够了。从数值上讲，连续伯努利分布也同样有效。我正在寻找这些分布背后的一般“结构”。]]></description>
      <guid>https://stats.stackexchange.com/questions/659182/necessary-and-sufficient-conditions-to-obtain-power-law-from-distribution-over-e</guid>
      <pubDate>Tue, 24 Dec 2024 23:53:30 GMT</pubDate>
    </item>
    <item>
      <title>Stata biprobit - 解释</title>
      <link>https://stats.stackexchange.com/questions/659181/stata-biprobit-interpretation</link>
      <description><![CDATA[生产力和培训都是二元变量。假设我正在研究培训对不同性别的个人生产力的影响。我使用到培训中心的距离作为我的工具变量 (IV)。
biprobit (productive = i.training i.training##i.male age i.gender wealth region) (training = distance age i.male wealth region) 

margins, at(training=(0 1) gender=(0 1)) predict(pmarg1) post

lincom _b[4._at] - _b[3._at]

结果为 0.02
categories:

3._at: training = 1, male = 0 (female with training)
4._at: training = 1, male = 1 (male with training)

我想确认我对 lincom 结果的解释是否正确：
对于接受过培训的人来说，男性比女性更有可能提高生产力 2%女性，并且这种差异具有统计学意义。
问题 2：
我不确定如何导出我的结果。有人能帮我吗？我应该只提供 lincom 结果，还是还应该包括主系数表？我找不到任何显示 lincom 结果的论文。
假设这是我的主表结果（假设）：
 | 系数 P&gt;|z| 
------------------------+----------------------------------------------------------------
productive |
1.training | .1265 0.000 
1.male | .188 0.000 
|
training#male |
1 1 | -.03049 0.315 
|


培训总体上对生产力有积极影响。
男性比女性更有生产力。
培训对男性和女性的生产力的影响并没有显著差异。

我应该坚持使用 lincom，对吧？不应该解释这些？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659181/stata-biprobit-interpretation</guid>
      <pubDate>Tue, 24 Dec 2024 23:48:51 GMT</pubDate>
    </item>
    <item>
      <title>神经网络不学习正弦函数参数</title>
      <link>https://stats.stackexchange.com/questions/659180/neural-network-not-learning-sinusoidal-function-parameters</link>
      <description><![CDATA[我有一个如下所示的正弦函数，带有预定义的a、b 和 c参数
def fun_sin(a, b, c, apply_noise=False):
&quot;&quot;&quot;
返回表示带噪声的正弦曲线的函数。

参数：
a：正弦波的振幅。
b：正弦波的频率。
c：正弦波的相移。
&quot;&quot;&quot;
def ann(x):
x = torch.tensor(x, dtype=torch.float32).to(device) if not isinstance(x, torch.Tensor) else x.to(device)
return (a * torch.sin(b * x + c)) + torch.tensor(random_gen.random(x.shape) * 0.2 if apply_noise else 0).to(device)
return ann

fun, a, b, c, learning_rate = fun_sin, 4, 0.1, 2, 0.0001

以下是该函数的曲线示例：

我创建了一个神经网络，给定 X（x 轴上的点）和 Y 值（fun_sin(a, b, c)(X) 的结果），我希望我的网络能够确定生成该曲线的 a, b, c 的位置。为了做到这一点，我让输出层输出 3 个值，并创建一个具有这些参数的函数，如下所示
def loss_fun(label, pred):
return torch.mean((label - pred) ** 2)

...

my_model = nn.Sequential(
nn.Linear(X_length, 32),
nn.ReLU(),
nn.Linear(32, 32),
nn.ReLU(),
nn.Linear(32, 3) # 具有 3 个参数 (a, b, c) 的输出层
)
...

my_model.train()
for i in epochs:
optimizer.zero_grad()
pred_a, pred_b, pred_c = my_model(X)
Y_pred = fun_sin(pred_a, pred_b, pred_c)(X)
loss = loss_fun(Y_label, Y_pred)
loss.backward()
optimizer.step()

所以事情是这样的：如果我给网络提供大约 100 个 X 和 Y 数据条目，我的网络就会相当合理地学习；我能够找到 a、b 和 c 的良好预测，这些预测能够呈现与原始曲线非常相似的正弦曲线。但是，如果我传递更多数据，通过增加 X &amp; Y 长度（分批或不分批），网络将停止给出良好的损失结果。
我尝试了多种方法来改善这种情况：

规范化数据
使用各种学习率和不同的调度程序（LambdaLR、OneCycleLR）
创建不太复杂的网络（更少的神经元、更少的层）
创建更复杂和更深的网络
更改优化器（Adam、SGD 等）
进行随机重启
进行梯度裁剪
进行梯度的批量传播与每个时期进行单次传播
消除我在 fun_sin 中的噪音
检查我传递的额外数据是否都很好（绘制图表并检查平均值/标准差）
尝试了各种不同的损失函数，这些函数会对网络的错误进行更多的惩罚

当我有更多数据时，我就是无法获得合理的损失。我读过这篇文章https://arxiv.org/abs/1906.00425，它讨论了为什么神经网络在频率较高时会出现收敛循环曲线的问题，但在我的例子中，驱动频率的参数b非常低（0.1），所以不要认为这适用于这里（此外，如果我的数据较少，网络学习得很好）。
有人知道我在这里可能遇到什么问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659180/neural-network-not-learning-sinusoidal-function-parameters</guid>
      <pubDate>Tue, 24 Dec 2024 22:52:19 GMT</pubDate>
    </item>
    <item>
      <title>拟合 glmmTMB 模型后下一步是什么？</title>
      <link>https://stats.stackexchange.com/questions/659177/what-are-next-steps-after-fitting-glmmtmb-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659177/what-are-next-steps-after-fitting-glmmtmb-model</guid>
      <pubDate>Tue, 24 Dec 2024 21:16:30 GMT</pubDate>
    </item>
    <item>
      <title>随机过程的均值、方差和收敛</title>
      <link>https://stats.stackexchange.com/questions/659176/mean-variance-and-convergence-of-stochastic-processes</link>
      <description><![CDATA[假设我有一些随机过程，我初始化两个空数组 A:[]，B:[]。接下来，从 $N(0,1)$ 中采样的元素被分配给 $A$ 或 $B$，每次采样一个元素，都会将其与均值 $\mu_A, \mu_B$ 进行比较。无论哪个均值距离采样值较远，相应的数组都会接收分配的值。
通过模拟，我观察到，当采样单元以相等/均匀的分配概率随机分配给$A,B$时，均值之间的差异收敛于零，方差小于比较值。
这种随机过程有名字吗？是否可以获得其长期行为的解析解，而不是纯粹通过模拟？
编辑：均值分别初始化为 0。分配给 A、B 的概率与元素与均值的距离成正比。而不是硬分配。]]></description>
      <guid>https://stats.stackexchange.com/questions/659176/mean-variance-and-convergence-of-stochastic-processes</guid>
      <pubDate>Tue, 24 Dec 2024 20:52:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们使用梯度*输入来生成 CNN 的显著图？</title>
      <link>https://stats.stackexchange.com/questions/659175/why-we-use-gradientinput-for-producing-the-saliency-map-of-a-cnn</link>
      <description><![CDATA[为 CNN 生成显著性图的最简单方法是计算特定输入的 梯度，如此处所述。
还有另一种方法，其中显著性图等于 梯度*输入。我读到它使显著性图更清晰，但我想解释一下为什么会这样，或者只是与输入相乘背后的动机。]]></description>
      <guid>https://stats.stackexchange.com/questions/659175/why-we-use-gradientinput-for-producing-the-saliency-map-of-a-cnn</guid>
      <pubDate>Tue, 24 Dec 2024 20:29:14 GMT</pubDate>
    </item>
    <item>
      <title>有争议的观点是，PDF 的卷积可能不是 PDF</title>
      <link>https://stats.stackexchange.com/questions/659168/controversial-view-that-convolutions-of-a-pdf-might-not-be-a-pdf</link>
      <description><![CDATA[有一条帖子说，对 $f(x) \cdot f(s-x)\,dx,$ 进行积分的 卷积公式 再次返回 PDF。我有点同意这一点。但后来，我偶然发现了这个 youtube 视频。我在下面提供了它们的链接。
在视频的 00:15:30，如果右侧的单条曲线（三角形）是 PDF，那么当他说“这个数字 $s$ 是该（卷积）函数的输入，而相应的输出是左下方图形的面积”时，他的意思是什么。
我的理解是，$s$ 取精确值的概率理想情况下应该是 $0.$ 那么他怎么能说“相应的输出是左下方图形的面积”呢？由于概率，因此面积应限制为 $0.$
链接：
证明 PDF 的卷积可得到 PDF
https://youtu.be/IaSGqQa5O-M?si=smyv_63FsMNkH9ly&amp;t=930]]></description>
      <guid>https://stats.stackexchange.com/questions/659168/controversial-view-that-convolutions-of-a-pdf-might-not-be-a-pdf</guid>
      <pubDate>Tue, 24 Dec 2024 17:25:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么在半监督 VAE 模型中将目标 𝑦 y 用作编码器的输入？</title>
      <link>https://stats.stackexchange.com/questions/659156/why-is-the-target-y-used-as-an-input-to-the-encoder-in-a-semi-supervised-vae</link>
      <description><![CDATA[正如标题所述，我理解 Kingma 的原始论文中方程 (6-7) 的数学推导。但是，由于 𝑦 已在模型中用作分类器的目标，那么将 𝑦 用作编码器的输入的目的是什么？这会不会是多余的？似乎从编码器的输入中删除 𝑦 在实践中也是可行的。]]></description>
      <guid>https://stats.stackexchange.com/questions/659156/why-is-the-target-y-used-as-an-input-to-the-encoder-in-a-semi-supervised-vae</guid>
      <pubDate>Tue, 24 Dec 2024 13:53:10 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 拟合带有工具变量的负二项混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/659184/fit-negative-binomial-mixed-effects-model-with-instrumental-variables-with-r</link>
      <description><![CDATA[如何使用 R 拟合带有工具变量的固定效应负二项式模型？
我尝试过 fixest 包，但它仅支持 OLS 的工具变量，而不支持负二项式：
id &lt;- rep(seq(1,10), each=5)
year &lt;- rep(seq(2021, 2025), times=10)
df &lt;- data.frame(id=id, year=year)
df[[&quot;weight&quot;]] &lt;- rnorm(nrow(df), 100, 10)
df[[&quot;height&quot;]] &lt;- 2*df$weight+rnorm(nrow(df), 0, 5)
df[[&quot;count&quot;]] &lt;- rpois(nrow(df), df$height+rnorm(nrow(df), 0, 5))
mod &lt;- fixest::fenegbin(count ~ 1 | id | height~weight, df)

fixest::fenegbin(count ~ 1 | id | height ~ weight, df) 中的错误： 
参数“fml”不能包含由竖线（“|”）分隔的两个以上部分。IV 仅适用于“feols”。
语法为：DEP VAR ~ EXPL VARS | FIXED EFFECTS。 （不允许 IV。）

相关：带诊断的固定效应模型中的 IV 回归]]></description>
      <guid>https://stats.stackexchange.com/questions/659184/fit-negative-binomial-mixed-effects-model-with-instrumental-variables-with-r</guid>
      <pubDate>Tue, 24 Dec 2024 13:01:47 GMT</pubDate>
    </item>
    <item>
      <title>比较两个具有相同预测变量但不同数据集的广义线性模型</title>
      <link>https://stats.stackexchange.com/questions/659137/comparing-two-generalized-linear-models-with-same-predictors-but-different-datas</link>
      <description><![CDATA[我想知道两个或多个组之间的系数是否不同（例如老年人与年轻人、白天与夜间事故）。我听说过 Chow 检验，但它只适用于线性回归。我想将其应用于泊松或逻辑回归。我读过一些论文（如这篇），其中使用似然比检验来处理这个问题，但我不确定它是如何工作的。]]></description>
      <guid>https://stats.stackexchange.com/questions/659137/comparing-two-generalized-linear-models-with-same-predictors-but-different-datas</guid>
      <pubDate>Mon, 23 Dec 2024 22:44:10 GMT</pubDate>
    </item>
    <item>
      <title>在回归中独立性是否意味着条件独立性？</title>
      <link>https://stats.stackexchange.com/questions/659012/does-independence-imply-conditional-independence-in-regression</link>
      <description><![CDATA[我正在阅读统计学习要素（第 44 页），并看到了这句话：

&quot;从统计学的角度来看，如果训练观测值$(x_i, y_i)$代表从其总体中独立随机抽取的样本，则该标准是合理的。即使 $x_i$ 不是随机抽取的，如果 $y_i$ 在给定输入 $x_i$ 的情况下是条件独立的，则该标准仍然有效。&quot;

为了探索这一点，我考虑了两种情况下的联合似然：

情况 1：$(x_i, y_i)$ 完全独立
如果 $(x_i, y_i)$ 对完全独立，则联合似然为：
$$
P(x_1, y_1, \dots, x_n, y_n \mid \theta) = \prod_{i=1}^n P(y_i \mid x_i, \theta) P(x_i \mid \theta)。
$$

案例 2：给定 $x_i$，$y_i$ 的条件独立性&gt;
如果给定 $x_i$，$y_i$ 是条件独立的，则联合似然为：
$$
P(x_1, y_1, \dots, x_n, y_n \mid \theta) = \left( \prod_{i=1}^n P(y_i \mid x_i, \theta) \right) P(x_1, x_2, \dots, x_n \mid \theta)。
$$



观察：

边际：
在情况 1中，由于独立性假设，输入的边际分布分解为$\prod_{i=1}^n P(x_i \mid \theta)$。
在情况 2中，输入的边际分布写为单个项$P(x_1, x_2, \dots, x_n \mid \theta)$，因为没有假设$x_i$。

条件：
在这两种情况下，除去边际，给定$x_i$的$y_i$的条件分布是相同的：
$$
\prod_{i=1}^n P(y_i \mid x_i, \theta)。
$$


这表明，尽管对边际的假设不同，但条件结构并没有不同。

问题：
假设$(x_i, y_i)$完全独立（情况 1）是否意味着在给定$x_i$的情况下，$y_i$具有条件独立性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659012/does-independence-imply-conditional-independence-in-regression</guid>
      <pubDate>Fri, 20 Dec 2024 13:04:15 GMT</pubDate>
    </item>
    <item>
      <title>分位数的贝叶斯区间估计</title>
      <link>https://stats.stackexchange.com/questions/658982/bayesian-interval-estimate-for-a-quantile</link>
      <description><![CDATA[这个问题是为了澄清后验分布和后验预测分布是否可用于创建分位数的区间估计。考虑以下设置：
假设我有 $X_i\stackrel{iid}{\sim} N(\mu, \sigma^2)$，其中 $i=1,...,n$。为了论证的目的，我并不关心先验的形式是什么，但让我们假设我在 $\mu$ 和 $\sigma^2$ 上都放置了先验。现在，我可以运行我的 MCMC 采样器并获取 $\mu$ 和 $\sigma^2$ 的后验样本（我们将它们称为 $\mu_{*b}$ 和 $\sigma^2_{*b}$，其中我有 $b=1,...,B$ 个）。现在，给定 $X_i$ 的分布，我可以通过以下方式获得后验样本，例如第 95 分位数：
$$q_b= \mu_{*b} + z_{0.95}\sigma_{*b}$$
其中 $z_{0.95}$ 是标准正态分布的第 95 分位数。此外，由于这是基于样本的，我有一个后验分位数的分布，并且可以取这些后验分位数样本的分位数来获得不确定性区间估计。到目前为止一切顺利。
现在，我很好奇是否有办法使用后验预测分布来做到这一点？例如，在相同的设置下，后验预测分布可能是 $y_{\text{new}}\sim N(\mu_{\text{new}}, \sigma^2_{\text{new}})$，因此我可以模拟该分布的 $y_{\text{new}}$ 值并取第 95 分位数来估计它。但是，这个估计没有像后验分布那样的不确定性量化。我想总结一下我的问题，

基于后验分布和后验预测分布的结果是否应该匹配，并且
后验预测分布是否应该为第 95 分位数产生不确定性估计（以区间的形式）？


编辑以澄清：
似乎人们没有理解我的问题的要点，但也许是我自己的错，可能不够清楚。让我用 R 代码来说明我的观点：
&gt; ### 用于生成第 95 分位数估计的代码 
&gt; ### 并附带 90% 可信区间
&gt; 
&gt; ### 为了举例说明，假设我已经完成了后验 
&gt; ### 计算，并且我有： 
&gt; 
&gt; ### p(sigma^2 | X) ~ Gamma(3, 2)
&gt; ### p(mu | sigma, X) ~ N(200, sigma)
&gt; 
&gt; 
&gt; # 后验样本数
&gt; B &lt;- 10000
&gt; 
&gt; # sigma^2* 和 mu^* 的后验样本
&gt; sigma2.star &lt;- rgamma(B, 3, 2)
&gt; mu.star &lt;- rnorm(B, 200, sqrt(sigma2.star))
&gt; 
&gt; # 第 95 分位数和 90% 可信区间的后验估计
&gt; q &lt;- mu.star + qnorm(0.95) * sigma2.star
&gt;平均值（q）
[1] 202.465
&gt; 
&gt; 分位数（q，probs = c（0.05, 0.95））
5% 95% 
200.0369 206.0277 
&gt; 
&gt; 
&gt; ### 使用后验预测分布
&gt; ynew &lt;- rnorm（B，mu.star，sqrt（sigma2.star））
&gt; 
&gt; q &lt;- 分位数（ynew，prob = 0.95）
&gt; q
95% 
202.7814 

但如您所见，使用后验预测，我仅得到 $q$ 的值的一个估计值，但没有可信区间，因为只有一个值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658982/bayesian-interval-estimate-for-a-quantile</guid>
      <pubDate>Thu, 19 Dec 2024 19:37:12 GMT</pubDate>
    </item>
    <item>
      <title>防止时间序列数据拆分中的数据泄露</title>
      <link>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</link>
      <description><![CDATA[我正在研究机械系统的故障检测问题，目标是确定故障类型。我使用的数据集对于每种类型的故障（目标标签）都有三种大小，每种故障大小都有四种不同的工作条件，如下图所示。请注意，数据集中的每个样本都是时间序列，由于样本数量太少而且太长，因此需要将每个样本分成固定长度的块。现在的问题是如何将每个块分配给训练集或测试集，以确保公平和无偏见的评估。

在之前的研究中，常见的做法是将所有块随机分成训练集和测试集。

使用这种方法，神经网络模型通常在测试集上实现近乎完美的性能。然而，这种方法似乎存在根本缺陷，因为将近似平稳的信号分成块会导致来自同一信号的块高度相似，而相似的块可能最终出现在两个集合中，从而导致严重的数据泄漏。为了说明这种数据泄漏，我将 t-SNE 算法应用于这些块。

在此图中，每种颜色对应特定的故障类型和故障大小。请注意，来自同一样本的块紧密聚集在一起。以下是放大版的图：

我认为应该根据故障大小来拆分块。例如，故障大小为 1 和 2 的样本块应包含在训练集中，而故障大小为 3 的样本块应包含在测试集中。这可确保测试集中不存在来自训练信号的任何信息。

现在我想问：

我关于数据泄露的说法正确吗？如果正确，是否有其他方法可以更严格地证明数据泄露，例如使用相似性指标或其他可视化？
您如何看待提议的拆分方法？基于故障大小的拆分是否足以防止数据泄露？如果不是，您会推荐哪些替代拆分策略来确保公平评估？

编辑：针对评论，我将尝试澄清一些观点。在我的应用中，不同设置中的故障大小可能有很大差异，因此重要的是模型可以在不暴露于与不同故障大小相关的信号的情况下检测故障。理想情况下，我们会在训练集中包含不同故障大小的信号，但这是不切实际的。另一方面，预计在两种故障大小上训练的模型将难以在第三种未见过的故障大小上表现良好。这就引出了一个问题：“训练测试拆分之间的相似度有多大是可以接受的？”如果答案是这取决于应用程序，那么在我的情况下，与某些故障大小相关的信号在测试期间应该保持未知，因为这反映了生产中的条件。
正如@Ggjj11 已经提到的，在我提出的方法中，重复拆分，并报告平均准确度。具体来说，在第一次迭代中，与小故障和中等故障相关的信号包含在训练集中，而与大故障相关的信号包含在测试集中。在第二次迭代中，与小故障和大故障相关的信号包含在训练集中，而中等故障大小包含在测试集中。第三次迭代遵循类似的模式。经过一番研究，我发现这种方法被称为GroupKFold 交叉验证。]]></description>
      <guid>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</guid>
      <pubDate>Tue, 17 Dec 2024 15:38:37 GMT</pubDate>
    </item>
    </channel>
</rss>