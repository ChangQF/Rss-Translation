<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Dec 2024 15:19:50 GMT</lastBuildDate>
    <item>
      <title>为贝叶斯推理生成协方差</title>
      <link>https://stats.stackexchange.com/questions/658269/generate-covariance-for-baysesian-inference</link>
      <description><![CDATA[我目前正在做一个项目，我想使用贝叶斯推理来推导一组参数的分布。我假设这些参数在某种程度上是相关的，我想使用贝叶斯推理来推导多元正态分布的协方差矩阵。但是，我并不完全确定从数字数组生成正定协方差矩阵的最佳方法是什么。我目前没有寻找矩阵的先验。
我目前的方法如下：

我使用数字数组通过将数组的值插入上三角部分来生成三角矩阵$A$。例如，给定数组 $ (a_1, \dots, a_6)$，我构造矩阵：

$
A = \begin{pmatrix}
a_1 &amp; a_2 &amp; a_3 \\
0 &amp; a_4 &amp; a_5 \\
0 &amp; 0 &amp; a_6
\end{pmatrix}
$ 
with $a_i &gt; 0$。

然后，我通过计算 $AA^T$ 生成一个正定对称矩阵，并将其用作协方差矩阵。

但是，在这种方法中，值 $a_i$ 没有明确的解释，而且我不确定这种方法是否可以生成所有可能的半正定协方差矩阵。有没有更好的方法可以使用？
另一种具有更好解释性的方法可能涉及首先创建一个包含每个参数方差的对角矩阵和一个相关矩阵。例如，给定数组 $(a_1, \dots, a_6)$，我可以构造矩阵：
$
A = \begin{pmatrix}
a_1 &amp; 0 &amp; 0 \\
0 &amp; a_2 &amp; 0 \\
0 &amp; 0 &amp; a_3
\end{pmatrix}, \quad 
B = \begin{pmatrix}
1 &amp; a_4 &amp; a_5 \\
a_4 &amp; 1 &amp; a_6 \\
a_5 &amp; a_6 &amp; 1
\end{pmatrix}
$ 
with $ a_1, a_2, a_3 &gt; 0$ 和 $|a_4|, |a_5|, |a_6| \leq 1 $。
协方差矩阵将由 $ABA$ 给出。但是，这个矩阵不一定是正定的。我如何确保得到的矩阵是正定的？]]></description>
      <guid>https://stats.stackexchange.com/questions/658269/generate-covariance-for-baysesian-inference</guid>
      <pubDate>Wed, 04 Dec 2024 15:11:33 GMT</pubDate>
    </item>
    <item>
      <title>R 期刊现状</title>
      <link>https://stats.stackexchange.com/questions/658264/status-of-r-journal</link>
      <description><![CDATA[这可能有点离题，但也许有人有关于 R 期刊当前状态的信息。
网站上列出的最后一期来自 2023 年 12 月，所以我想知道该期刊是否仍然活跃。主页上显示待提交数量的图表仅持续到 2022 年：

但它表明可能存在失控问题，导致待提交的存量不断增加，有一天可能不再可管理。然而，这是否与 2024 年缺乏问题有关仅仅是猜测。该网站没有关于问题的评论或提示。
有没有什么信息可以说明发生了什么（没有发生）？]]></description>
      <guid>https://stats.stackexchange.com/questions/658264/status-of-r-journal</guid>
      <pubDate>Wed, 04 Dec 2024 14:02:06 GMT</pubDate>
    </item>
    <item>
      <title>使用卡方分布构建置信区间时的问题</title>
      <link>https://stats.stackexchange.com/questions/658263/issues-when-constructing-a-confidence-interval-using-chi-squared-distribution</link>
      <description><![CDATA[想象一个随机对照试验，采用二元治疗和多个协变量$X_1,...,X_n$。
随机化后，通常会对两个治疗组之间的协变量进行平衡比较。这种平衡度量例如是 z 差，如下所示
$$ z_i = \frac{\overline{x_1} - \overline{x_2}}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}$$
这些 z 差遵循正态分布$Z_i\sim N(0,1)$。这给出了 $i=1,...,n$ 的协变量特定平衡 $X_i$。
最近引入了一个聚合平衡度量 - 即 $SSQ$ - 它将平方 $z_i$ 相加：
$ssq = \sum_{i=1}^n z_i^2$
由于 z 差异遵循标准正态分布，因此 $SSQ \sim \chi^2_n$。
我现在对 $1-\alpha$ 置信度感兴趣间隔为 $ssq$，但我对构造感到很纠结。我有两种不同的方法，但对于一个点来说，它们似乎都是错误的。

方法：

$SSQ \sim \chi^2_n$，因此可以根据分位数直接估计置信区间 - 不需要进行任何变换，因为中心$\chi^2$分布已经存在
$$
\text{CI}_{95\%} = \left[ \chi^2_{1-\frac{\alpha}{2}, n}, \chi^2_{\frac{\alpha}{2}, n} \right]
$$
但是我对这种方法有所担忧，因为置信区间仅由分位数描述，该分位数指的是包含 95% 的区间ssq。此外，估计值未包含在该区间的构建中（例如，如果我估计 $ssq = 61$ 的 $n=10$ 个协变量，则上述区间将是 $[3.94,20.48]$，不包括估计值。此外，如果我运行模拟研究，包括例如 1,000 个 RCT 并估计 $SSQ$，则覆盖率将始终为 100%，因为真正的 SSQ（即 $n$）将始终包含在置信区间的定义中。因此这种方法不可能是正确的。

方法

与方差置信区间类似，它可能是：
$$[\frac{n\cdot ssq}{\chi^2_{1-\frac{\alpha}{2}, n}}; \frac{n\cdot ssq}{\chi^2_{\frac{\alpha}{2}, n}}]$$
但是，我不明白为什么这应该成立。因此，我还进行了一项小型模拟研究，并使用 95% 以上的 CI 估计了 ssq。这里的覆盖率约为 95%，这就是为什么这个 CI 似乎是正确的。但我没有从数学上得出这个解决方案。
因此，如果您能帮助我构建 $ssq$ 的置信区间，我将不胜感激。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658263/issues-when-constructing-a-confidence-interval-using-chi-squared-distribution</guid>
      <pubDate>Wed, 04 Dec 2024 13:30:19 GMT</pubDate>
    </item>
    <item>
      <title>如何根据 x 和 y 坐标进行聚类</title>
      <link>https://stats.stackexchange.com/questions/658262/how-to-cluster-based-on-x-and-y-coordinates</link>
      <description><![CDATA[我尝试使用聚类算法识别点组中的行。我试图解决的更大问题是根据产品的 x 和 y 坐标识别货架。我可以仅基于 y 坐标进行聚类，并使用 HDBSCAN 等算法获得不错的聚类结果。
我想知道是否也可以以某种方式将 x 坐标合并到聚类中，因为感觉简单地丢弃 x 坐标会浪费有用的信息。
但是，如果我将 x 坐标放入我的聚类算法中（即每个点现在都由一个 2D 矢量表示），则聚类效果很差，因为 x 轴两端的两个点被认为不相关，而位于不同架子上的两个点则直接位于彼此下方。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658262/how-to-cluster-based-on-x-and-y-coordinates</guid>
      <pubDate>Wed, 04 Dec 2024 13:17:59 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost F1 分数改进方法，用于多类分类[重复]</title>
      <link>https://stats.stackexchange.com/questions/658259/xgboost-f1-score-impovement-methods-for-multi-class-classification</link>
      <description><![CDATA[我正在使用 XGBoost 构建多类分类（5 个类别）。目前使用 56 个特征来对 160 万客户群进行均衡分类。
总体准确率为 83%，F1 得分为 0.81，AUC &gt; 0.90。如何提高准确率？
我已经进行了以下测试：
无缺失值
交叉验证
异常值处理
逻辑和随机森林（XGBoost 提供更好的结果）
相关性
超参数调整，以下是最终参数：
model = xgb.XGBClassifier(objective=&#39;multi:softmax&#39;, 
num_class=5,
eval_metric=&#39;mlogloss&#39;,
max_depth=6,
eta=0.3,
seed=42
)

任何有助于进一步提高准确率的帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658259/xgboost-f1-score-impovement-methods-for-multi-class-classification</guid>
      <pubDate>Wed, 04 Dec 2024 12:02:44 GMT</pubDate>
    </item>
    <item>
      <title>估计一对内具有相同响应值但不同协变量值的混合模型</title>
      <link>https://stats.stackexchange.com/questions/658265/estimating-mixed-model-with-identical-response-value-but-different-covariate-val</link>
      <description><![CDATA[假设我们有一个包含个人的数据集。每个个人执行一项任务，无论是单独执行还是与另一个人一起执行（变量 condition），我们测量整个群体的表现，即个人或配对（变量 score）。
换句话说，我们为单独执行的个人设置一个分数值，为配对执行的个人设置两倍相同的分数值。
我们将单独执行的个人视为自己形成一对，从而得到变量 pair。
我们还单独测量了一个协变量，即我们为每个个人设置一个 cov 值。
数据框如下所示：
&gt; head(df, 12)
id 对 得分 cov 条件
1 对1 3 6 solo
2 对2 6 4 对
3 对2 6 3 对
4 对3 3 3 solo
5 对4 5 3 对
6 对4 5 4 对
7 对5 3 5 solo
8 对6 5 5 对
9 对6 5 3 对
10 对7 4 3 solo
11 对8 4 5 对
12 对8 4 4 对

虽然 score 没有重复，但我想知道，考虑到一对中的个体具有不同的 cov 值，拟合混合模型是否有意义。
但是，估计如下模型：
lme4::lmer(score ~ condition * cov + (1 | pair))
导致无法收敛。
我觉得这是可以预料到的，因为 score 变量中存在冗余。话虽如此，我还是不太明白原因。
我读到过残差方差可能与随机效应方差混淆。但残差方差不应该不同于随机方差来解释 cov 中观察到的差异吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658265/estimating-mixed-model-with-identical-response-value-but-different-covariate-val</guid>
      <pubDate>Wed, 04 Dec 2024 11:49:19 GMT</pubDate>
    </item>
    <item>
      <title>使用 semopy 中的分类数据进行预测 [已迁移]</title>
      <link>https://stats.stackexchange.com/questions/658257/prediction-with-categorical-data-in-semopy</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658257/prediction-with-categorical-data-in-semopy</guid>
      <pubDate>Wed, 04 Dec 2024 11:15:40 GMT</pubDate>
    </item>
    <item>
      <title>为两个问题生成表格[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658256/generate-table-for-the-two-questions</link>
      <description><![CDATA[
该组有多少成员 2. 此类组的成员中有多少女性 我在 Stata 中遇到了这两个问题，想生成一个表格，显示上述问题 1 中每个组中女性的百分比。提供生成此表格的步骤
]]></description>
      <guid>https://stats.stackexchange.com/questions/658256/generate-table-for-the-two-questions</guid>
      <pubDate>Wed, 04 Dec 2024 09:49:40 GMT</pubDate>
    </item>
    <item>
      <title>横截面数据中条件独立与边际依赖的真实示例</title>
      <link>https://stats.stackexchange.com/questions/658255/real-world-examples-of-conditional-independence-with-marginal-dependence-in-cros</link>
      <description><![CDATA[在之前的问题中，我探讨了仅使用条件独立性假设来推导联合似然 - 仅使用条件独立性假设（无边际独立性）推导联合似然 。
现在，我有兴趣了解现实世界中的应用或数据集，其中观察到边际依赖性的条件独立性。
问题：

是否存在众所周知的现实世界用例或数据集，其中出现这种类型的关系？
哪些类型的统计模型或领域（例如经济学、医学、社会科学）通常会遇到这种关系？

我希望得到示例、参考资料，或有关该主题的任何相关讨论，以便更好地理解其在实践中的含义。]]></description>
      <guid>https://stats.stackexchange.com/questions/658255/real-world-examples-of-conditional-independence-with-marginal-dependence-in-cros</guid>
      <pubDate>Wed, 04 Dec 2024 09:33:06 GMT</pubDate>
    </item>
    <item>
      <title>在因子分析中，删除唯一性较低的变量后的新模型对原始模型有何影响？</title>
      <link>https://stats.stackexchange.com/questions/658250/in-factor-analysis-what-does-the-new-model-with-a-variable-with-low-uniqueness</link>
      <description><![CDATA[我正在使用 R 中的 factanal 进行因子分析模型：
$$X=Lf+\mathcal E. $$
当将因子设置为相对较大时，
我收到一个错误，即变量的唯一性（即 $E(\epsilon_i^2)$ 的估计值）接近于零。
虽然我可以通过设置非常小的lower值来解决这个问题，但是这篇文章说这会导致问题。
按照这篇文章的建议，我尝试删除唯一性较低的变量$Y_i$，然后模型就可以正常工作了。
但是，我想问一下，删除$Y_i$后的新模型对原始模型意味着什么？
例如，如果在新模型中，$p$ 个因素拟合良好，我们能否断言在原始模型中$p+1$ 个因素拟合良好？]]></description>
      <guid>https://stats.stackexchange.com/questions/658250/in-factor-analysis-what-does-the-new-model-with-a-variable-with-low-uniqueness</guid>
      <pubDate>Wed, 04 Dec 2024 05:51:04 GMT</pubDate>
    </item>
    <item>
      <title>三个相关伯努利随机变量之和的分布，均具有相同的相关性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658241/the-distribution-of-the-sum-of-three-dependent-bernoulli-random-variables-all-w</link>
      <description><![CDATA[$\mathbb{P}(X+Y+Z=z)=\text{?}$
$X,Y,Z\sim \text{Bernoulli}(p)$，并且 $\text{Cor}(X,Y)=\text{Cor}(X,Z)=\text{Cor}(Y,Z)=\rho~, 0&lt;\rho&lt;1$。]]></description>
      <guid>https://stats.stackexchange.com/questions/658241/the-distribution-of-the-sum-of-three-dependent-bernoulli-random-variables-all-w</guid>
      <pubDate>Wed, 04 Dec 2024 01:41:00 GMT</pubDate>
    </item>
    <item>
      <title>如何手动计算自相关</title>
      <link>https://stats.stackexchange.com/questions/658213/how-to-calculate-autocorrelation-manually</link>
      <description><![CDATA[我学过滞后 $k$ 的时间序列中的自相关是所有以此滞后为间隔的值对之间的相关性。
假设我想试一试，并手动计算滞后 1。
模拟一些白噪声
set.seed(123)
TS &lt;- ts(rnorm(1e3))

然后手动计算自相关并使用内置函数。
calc_autocorrelation_manually &lt;- function(x) { cor(x[-1], x[-length(x)]) }

&gt; calc_autocorrelation_manually(TS)
[1] -0.02741628
&gt; 
&gt; acf(TS, lag = 1, plot = F)

序列‘TS’的自相关，按滞后

0 1 
1.000 -0.027

两者给出相同或几乎相同的结果（我知道 acf() 中的计算并不完全相同，因为它不使用偏差调整。不过，我认为这不会产生实质性差异）。
但是，如果我对模拟 AR(1) 过程执行此操作，结果就不一样了！例如，使用没有噪音的“理想”AR(1)：
&gt; TS &lt;- ts(99999) # 初始值
&gt; for (i in 1:350) { TS &lt;- c(TS, TS[i] * 0.3) }
&gt; 
&gt; calc_autocorrelation_manually(TS)
[1] 1
&gt; 
&gt; acf(TS, lag = 1, plot = F)

序列‘TS’的自相关，按滞后

0 1 
1.0 0.3 

我认为手动计算自相关是不正确的，但正确的方法是什么？为什么在第一个例子中它仍然运行良好？]]></description>
      <guid>https://stats.stackexchange.com/questions/658213/how-to-calculate-autocorrelation-manually</guid>
      <pubDate>Tue, 03 Dec 2024 15:05:35 GMT</pubDate>
    </item>
    <item>
      <title>解释 A/B 测试结果中的 p 值</title>
      <link>https://stats.stackexchange.com/questions/658204/interpret-p-value-in-a-b-test-results</link>
      <description><![CDATA[我需要解释 A/B 测试结果。因此，我有一个名为 Baseline 的控制队列，还有另外两个名为 NewFTUE 和 AppReopenFS 的队列。
此 AB 测试数据的最大问题是 NewFTUE 的 p 值几乎等于 1，而 AppReopenFS 的 P 值要低得多。
我无法理解两件事：

据我所知，如果平均差异较大且
标准差较小，则 p 值应该变得更小，即零假设应该更容易被拒绝。但我们可以
在这里看到，对于较大的标准差和较小的均值差，p 值要小得多（0.187 vs 0.991）
第二件我无法理解的事情是 95% CI（正如仪表板上所解释的那样，这是“95% 可能包含均值真实差异的值范围”。）。因此，正如您所看到的，对于 NewFTUE，均值差异的置信区间完全位于 0 的左侧。即我们有 95% 的信心，无论我们采用什么样本（对于相同的样本量），与 Baseline 相比，我们都会得到更差的结果。

那么为什么 NewFTUE 的 p 值为 0.991 并且大于 AppReopenFS 的 0.187 值？

编辑：添加以下 p 值的描述：和 这里是文档页面。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658204/interpret-p-value-in-a-b-test-results</guid>
      <pubDate>Tue, 03 Dec 2024 13:44:27 GMT</pubDate>
    </item>
    <item>
      <title>假阳性率是否可能随着患病率的增加而降低？</title>
      <link>https://stats.stackexchange.com/questions/658195/is-it-possible-that-false-positive-rate-decreases-with-increasing-prevalence</link>
      <description><![CDATA[我对患病率对预测性能的影响很感兴趣。Chouldechova (2016) 指出：

[当]在各组再犯患病率不同的人群中使用测试公平 [再犯预测工具] 时，通常再犯患病率较高的组会具有较高的 FPR 和较低的 FNR。

我想知道如果该工具旨在使两组具有相同的准确度，情况是否如此。因此，我推导出一个考虑准确率、FNR 和患病率的 FPR 函数：
$$FPR=\frac{\left(1-ACC-prevalence\cdot FNR\right)}{1-prevalence}$$
这个等式似乎是正确的，因为它给出的结果与通常的 $ FPR=\frac{FP}{FP+TN}$ 相同。
我注意到，如果 $FNR+ACC&lt;1$（即敏感度低于准确率），该等式仅显示患病率与 FPR 之间的正相关关系。请参阅此处。
我的问题是：在实际情况下，患病率和 FPR 之间的关系是否可能为负？或者我是否遗漏了某些东西，可以将可能的值限制在关系为正的范围内？
编辑：可能对偶然发现这一点的其他人有帮助：FPR 可以描述为基准率、准确率和 PPV 的函数。对于 PPV &gt; 0.5，基准率和 FPR 之间的关联将始终为正。对于 0 &lt; 准确率 &lt; 1：fpr = ((base+acc-1)*(ppv-1))/((base-1)*(2*ppv-1))]]></description>
      <guid>https://stats.stackexchange.com/questions/658195/is-it-possible-that-false-positive-rate-decreases-with-increasing-prevalence</guid>
      <pubDate>Tue, 03 Dec 2024 11:09:43 GMT</pubDate>
    </item>
    <item>
      <title>我的数据适合什么模型？</title>
      <link>https://stats.stackexchange.com/questions/658189/what-model-for-my-data</link>
      <description><![CDATA[我有一个问题，我们想要比较 3 种处理方法（标准方法与 2 种新方法）。对于每种处理方法，我们都会生产 5 个对象。然后将每个对象分成更小的部分，并从每个部分测量给定的属性。
我不知道这是否重要，但每个对象的部分都存在一些空间依赖性（在每个对象中，第 1 部分与第 2 部分相邻，第 2 部分与第 3 部分相邻，依此类推）。
因此，我认为我遇到了独立组的情况，但每个组内都有重复测量。就我在文献中查找的情况而言，它似乎指导我进行混合方差分析或分层模型？您能在这方面给我一些帮助并指导一些文献吗？我也在用 R 做这件事。
谢谢。
编辑：“对象”实际上是工业过程的结果（一种塑料）；“属性”我的意思是物体的机械特性（我不知道细节），以定量变量来衡量]]></description>
      <guid>https://stats.stackexchange.com/questions/658189/what-model-for-my-data</guid>
      <pubDate>Tue, 03 Dec 2024 09:23:14 GMT</pubDate>
    </item>
    </channel>
</rss>