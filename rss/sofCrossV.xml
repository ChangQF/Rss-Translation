<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 14 Jan 2025 01:12:49 GMT</lastBuildDate>
    <item>
      <title>如何正确考虑集群随机试验中的聚类</title>
      <link>https://stats.stackexchange.com/questions/659991/how-to-properly-account-for-clustering-in-cluster-randomized-trial</link>
      <description><![CDATA[假设我们进行了一项集群随机试验，以检验以下假设：在降低 24 个月时的死亡风险方面，主动干预XYZ优于标准治疗。
100 个站点（集群）被随机分配，50 个分配到XYZ，50 个分配到常规护理；每个 site 招募（比如说）100 名患者。
这可以是一个示例数据集（仅用于说明目的），其中 cov1、cov2、... 是用作协变量的基线因子/变量：
set.seed(1) 
df &lt;- data.frame(
patient_id=c(1,2,3,4,5,6,7,8,9,10),
site=c(1,1,2,1,2,3,4,3,3,5),
治疗=c(“XYZ”、“XYZ”、“标准”、“XYZ”、“标准”、“标准”、“标准”、“XYZ”、“标准”、“标准”、“标准”、“XYZ”)，
死亡=c(0,0,0,1,0,1,1,0,0,0)，
时间=c(720,740,721,456,650,580,720,719,702,688)，
cov1=样本(34:100,10)，
cov2=c(&quot;是&quot;,&quot;是&quot;,&quot;是&quot;,&quot;是&quot;,&quot;否&quot;,&quot;是&quot;,&quot;是&quot;,&quot;否&quot;,&quot;是&quot;),
cov3=c(&quot;男性&quot;,&quot;男性&quot;,&quot;女性&quot;,&quot;女性&quot;,&quot;女性&quot;,&quot;女性&quot;,&quot;男性&quot;,&quot;女性&quot;)
)

patient_id 地点 治疗 死亡 时间 cov1 cov2 cov3
1 1 1 XYZ 0 720 93 是 男性
2 2 1 XYZ 0 740 64 是 男性
3 3 2 标准 0 721 58 是 男性
4 4 1 XYZ 1 456 75 是 女性
5 5 2 标准 0 650 87 否 女性
6 6 3 标准 1 580 73 否 女性
7 7 4 XYZ 1 720 82 是 女性
8 8 3 标准 0 719 38 是 男性
9 9 3 标准 0 702 94 否 女性
10 10 5 XYZ 0 688 92 是 女性

假设我们想使用 Cox 回归模型分析 XYZ 是否确实与随访期间的死亡率降低有关。我们需要考虑聚类，使用 site 变量 - 问题是，在集群随机试验的背景下，我们如何才能恰当地做到这一点？
有许多可能的方法（例如此处所述）；虽然其他地方已经介绍了cluster、strata和frailty之间的区别，但我不太确定我是否理解了这如何应用于集群随机试验（例如我上面解释过的虚构示例）。
我们可以考虑 3 个主要选项：

简单地调整site（在我看来不是最优的，也不合适，但首先可以考虑）：

coxph(Surv(time, death) ~ treatment+site+cov1+cov2+..., data=df)

使用 cluster 参数：

coxph(Surv(time, death) ~ treatment+cov1+cov2+..., cluster(site), data=df)

使用 frailty 参数：

coxph(Surv(time, death) ~ treatment+cov1+cov2+..., frailty(site), data=df)
这 3 个选项中的哪一个可以提供最合适的方法来检验开头提出的假设（即 XYZ 在减少死亡方面优于标准治疗），同时适当地考虑聚类？在集群随机试验的背景下，对模型 #2 和 #3 的解释的主要区别是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659991/how-to-properly-account-for-clustering-in-cluster-randomized-trial</guid>
      <pubDate>Mon, 13 Jan 2025 23:07:59 GMT</pubDate>
    </item>
    <item>
      <title>充分统计数据的因式分解定理</title>
      <link>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics</link>
      <description><![CDATA[根据因式分解定理（Fisher-Neyman），我们得到一个统计量$ T(X) $充分当且仅当存在因式分解：$ f(x|\theta) = g(T(x)|\theta)h(x) $。符号遵循 Casella/Berger 第 276 页。
Casella/Berger 在离散情况下给出了证明，并指出具体因式分解的形式为：$ P(X=x | {\theta}) = P(T(X) = T(x) | {\theta})P(X=x | T(X) = T(x)) $
我的问题是：我们可以将这种解释应用于连续情况吗？它总是成立吗？因此：$ f(x|\theta) = f(T(x)|\theta)f(x|T(x)) $ 其中 $f$ 表示相应的 pdf？]]></description>
      <guid>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics</guid>
      <pubDate>Mon, 13 Jan 2025 22:52:25 GMT</pubDate>
    </item>
    <item>
      <title>使用接受的治疗而非随机分组进行约束纵向数据分析 (cLDA)</title>
      <link>https://stats.stackexchange.com/questions/659986/constrained-longitudinal-data-analysis-clda-using-treatment-received-rather-th</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659986/constrained-longitudinal-data-analysis-clda-using-treatment-received-rather-th</guid>
      <pubDate>Mon, 13 Jan 2025 21:05:21 GMT</pubDate>
    </item>
    <item>
      <title>估计受影响的人数（医疗问题）</title>
      <link>https://stats.stackexchange.com/questions/659985/estimate-the-number-of-affected-individuals-medical-problem</link>
      <description><![CDATA[我的问题可以用医学术语来描述。一个人口为 N 的国家有 C 个人患有特定疾病。然而，这种疾病未被充分诊断，我的目标是估计受影响个体的真实数量 T。
为此，我使用了患有这种疾病的人作为样本；至关重要的是，对于他们每个人，我都知道一项测试的结果，该结果显示该疾病是否被成功诊断。城市和农村地区的成功率不同，我运行了 logit 回归：
logit(P(diagnosed = 1) = β0 + β1(urban / Rural)，
这为我提供了城市成功率 u 和农村成功率 r 的估计值。最后，我将人口 N 分为城市和农村部分，并得出受影响个人数量的修正估计值：
N = U + R，
T = U / u + R / r。
这个解决方案有效，但我之前没有处理过医疗问题，并且相信这个问题很常见并且有一个经过验证的解决方案。我不想重新发明自行车，如果能得到建议或参考，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659985/estimate-the-number-of-affected-individuals-medical-problem</guid>
      <pubDate>Mon, 13 Jan 2025 21:01:20 GMT</pubDate>
    </item>
    <item>
      <title>正交和非正交特征</title>
      <link>https://stats.stackexchange.com/questions/659983/orthogonal-and-non-orthogonal-features</link>
      <description><![CDATA[我的理解是，PCA 是一种对可能非正交的特征进行正交化（将输出称为主成分而不是特征）的技术。但是，在我看过的视频以及这个可视化工具中，特征空间的维度在开始时始终具有正交基，因此 PCA 是从一个正交基到另一个正交基的角度保持变换，而不是正交化技术。
当特征被称为非正交时，这是否意味着特征空间的维度由非正交基生成，然后 PCA 对其进行正交化，或者仅仅意味着数据点在由正交基生成的特征空间上相关？这两种几何视图之间是否存在明显的同构性，以便可以互换使用？
例如，假设我们对比两个独立进行的回归分析。我正在创建一个回归来预测 Bearth 表面上随机选择的位置的温度，而您正在创建一个回归来预测 Schmearth 表面上随机选择的位置的温度。我在 Bearth 的同一个城市放置了四个温度传感器，而您在 Schmearth 的四个大陆上分别放置了一个温度传感器。在每个星球上随机跳跃的第五个温度传感器的测量值是相应的预测目标。为了避免时间序列分析的额外复杂性，温度传感器不会对测量值进行时间戳记，但它们会将五个同时进行的测量值相互关联，以便它们输出的是一组数据点（每个数据点 1 个目标测量值和 4 个特征测量值），就像基本回归所需的那样。
事实是，Bearth 的温度在其地理范围内波动很大，而 Schmearth 的温度则不会。然而，我们每个人的训练数据最终都会出现高度相关性。我认为描述这个问题的方式是，我的特征具有很多多重共线性，这是由于我冗余放置了温度传感器造成的，而你的特征几乎没有多重共线性，但你的星球在其地理范围内的温度范围客观上较小，因此波动性主要是由于（未测量的）季节性而发生在数据点之间，而不是固定数据点的特征之间。
这两个回归之间的差异是否由特征空间中的（非）正交性（或甚至（非）线性）捕获？这是直观的，因为温度传感器的位置和特征空间的形状在逻辑上都先于训练数据点的存在。PCA 能否尽可能地解释这种差异？如果可以，我们是否必须手动识别和建模输入到 PCA 的特征空间中的多重共线性，或者即使我们没有认真考虑温度传感器位置的影响，PCA 是否会自动对其进行校正？如果没有，那么是否存在与此类似的环境，其中可以使用像 Gram-Schmidt（真正正交化非正交基）之类的东西来做我想用 PCA 做的事情？]]></description>
      <guid>https://stats.stackexchange.com/questions/659983/orthogonal-and-non-orthogonal-features</guid>
      <pubDate>Mon, 13 Jan 2025 20:37:46 GMT</pubDate>
    </item>
    <item>
      <title>重复测量设计中评估基因-代谢物关系的指导</title>
      <link>https://stats.stackexchange.com/questions/659981/guidance-on-evaluating-gene-metabolite-relationships-in-repeated-measures-design</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659981/guidance-on-evaluating-gene-metabolite-relationships-in-repeated-measures-design</guid>
      <pubDate>Mon, 13 Jan 2025 20:11:27 GMT</pubDate>
    </item>
    <item>
      <title>不同分析中的变量标准化</title>
      <link>https://stats.stackexchange.com/questions/659980/standardization-of-variables-across-different-analyses</link>
      <description><![CDATA[变量标准化
我正在为我的心理学学士学位进行一项研究，需要有关标准化变量以供分析的建议。我的变量是乐观、压力和 4 个独立的弹性子维度，以及整体弹性。
为了计算整体弹性变量，我总结了各个弹性子维度的标准化 z-总和分数（由于项目范围和响应量表不同，我进行了标准化）。我的分析包括：
3 个简单线性回归（测试总体适应力、乐观和压力之间的主要影响）
4 个层次回归（调节分析） - 测试 4 个独立子维度的调节效应（我也已经在每次分析中标准化了调节变量，因为我想比较每个子维度对因变量的影响强度）
1 个中介分析（测试总体适应力作为乐观-压力关系中的中介）
我的问题是：
我是否还需要在我的分析中标准化其他变量（其他预测因子、因变量），因为我已经使用了其他 z 分数变量（总体适应力变量和独立子维度）？
任何见解或建议都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/659980/standardization-of-variables-across-different-analyses</guid>
      <pubDate>Mon, 13 Jan 2025 20:01:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 Blackbox 方式查找依赖链</title>
      <link>https://stats.stackexchange.com/questions/659978/find-dependency-chain-in-blackbox-way</link>
      <description><![CDATA[假设我有 $5$ 个向量：${a,b,c,d,e}$。
我不知道它们之间的关系或它们的依赖链。例如，假设有一个函数接受这五个向量并返回这四个见解：

$a$ 的值取决于 $b$ 的值，反之亦然。

$c$ 的值取决于 $b$ 的值，因此也取决于 $a$ 的值，但 $a$ 和 $b$ 本身与 $c$ 的值相对独立，不会影响 $a$ 和 $b$。

$d$ 的值依赖于 $c$ 和 $b$，但不直接依赖于 $a$。

最后，$e$ 的值完全独立，与 $a$、$b$、$c$ 或 $a$、$b$、$c$ 或 $a$ 没有任何关系（双向或单向）。 class=&quot;math-container&quot;&gt;$d$.


我如何以黑盒方式（例如使用神经网络）了解这四个信息/见解（相关性）？我只输入五个向量。
此外，我希望它还支持非线性关系相关性。

我的解决方案是为所有向量训练五个独立的神经网络，其中每个神经网络对所有样本都有一个输入和四个输出。

输入形状：(n_samples, vector_dims, 1)
输出形状：(n_samples, vector_dims, 4)

问题是，vector_dims可能会有所不同。
那么，我不知道下一个？

或者也许我可以使用变压器编码器？]]></description>
      <guid>https://stats.stackexchange.com/questions/659978/find-dependency-chain-in-blackbox-way</guid>
      <pubDate>Mon, 13 Jan 2025 19:28:48 GMT</pubDate>
    </item>
    <item>
      <title>独立同分布高斯函数的 softmax 变换的集中</title>
      <link>https://stats.stackexchange.com/questions/659977/concentration-of-softmax-transform-of-i-i-d-gaussians</link>
      <description><![CDATA[考虑$n$ 个 i.i.d. 标准高斯随机变量，记为$X_1, \ldots, X_n$。我正在寻找表征函数的集中度的方法，例如 $\sum_{i=1}^n X_i e^{-X_i/\tau}$ 和 $\sum_{i=1}^n e^{-X_i/\tau}$，这些函数可以导致 
$$T_n = \dfrac{\sum_{i=1}^n X_i e^{-X_i/\tau}}{\sum_{i=1}^n e^{-X_i/\tau}}.$$
有人可能会认为 $T_n$ 以概率收敛到 $\frac{\mathbb{E}(​​Ze^{-Z/\tau})}{\mathbb{E}(​​e^{-Z/\tau})}$ 其中 $Z\sim N(0,1)$，但我正在寻找收敛速度，即尾部概率界限。查看 Talagrand 浓度不等式的陈述表明，指数函数增长太快，因此该不等式不适用。我们还能证明我上面提到的统计数据的亚高斯或亚指数类型的尾部界限吗？任何建议都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659977/concentration-of-softmax-transform-of-i-i-d-gaussians</guid>
      <pubDate>Mon, 13 Jan 2025 19:12:54 GMT</pubDate>
    </item>
    <item>
      <title>如何比较多层模型中固定效应和随机效应之间的贡献？</title>
      <link>https://stats.stackexchange.com/questions/659976/how-to-compare-the-contribution-between-a-fixed-effect-and-a-random-effect-in-a</link>
      <description><![CDATA[假设我有一个包含三个变量的数据集：$y$，我想要了解的结果；$x$，与$x$共变的变量，但我们可以假设它是完美测量的；$g$，分组变量，用于标识测量所属的多个群集（例如，主题）之一。我用多级（分层）回归模型拟合数据，形式为
$$y_i = (\beta_0 + b_{0,g[i]}) + (\beta_1 + b_{1, g[i]})x_i + \varepsilon_i$$
其中 $i = 1, \ldots, n$ 索引数据集中的观测值，$g[i]$ 是观测值 $i$ 的变量 $g$ 的值。
在 lme4 表示法中，该模型为 y ~ 1 + x + (1 + x | g)，允许每个簇有自己的斜率和截距，同时计算总斜率和截距。
我想用这个模型回答的问题是对于解释结果变量，哪个更重要：$x$ 的影响还是聚类间变异性？
我认为回答这个问题的一个实用方法可能是划分方差（如果这很重要，可以假设误差分布是正态的），但我真的不知道该怎么做。我知道，如果我拟合一个非分层模型，即 y ~ 1 + x，方差可以划分为回归可以解释的部分和不能解释的部分。
我还知道，当我拟合模型 y ~ 1 + x + (1 + x | g) 时，我会估计由按 g 分组的随机效应解释的方差分量。从这个模型中，是否可以将方差分解为由固定效应解释的部分、由随机效应解释的部分和残差变异性？如果可以，我该怎么做？
有没有更好的方法来回答这个问题？我认为对解释方差进行划分是一种直观的方式，可以说明一个变量“更重要”比其他的要好，但如果有更好的衡量标准，那也是可以的。
举一个具体的例子，我在 R 中模拟了一个遵循此模型的数据集，并且所有模型参数都是可估计的。
set.seed(101)
n_subjects &lt;- 20
x_values_per_subject &lt;- c(0.1, 0.25, 0.5, 0.75)
x &lt;- rep(x_values_per_subject, times = n_subjects)
g &lt;- rep(1:n_subjects, each = length(x_values_per_subject))
global_b0 &lt;- 5
individual_b0 &lt;- rnorm(n_subjects, global_b0, 5)
global_b1 &lt;- -2
individual_b1 &lt;- rnorm(n_subjects, global_b1, 3)
residual_variance &lt;- 1
mu &lt;- global_b0 + individual_b0[g] +
(global_b1 + individual_b1[g]) * x
error_variate &lt;- rnorm(length(mu), 0, residual_variance)
y &lt;- mu + error_variate
observed_data &lt;- data.frame(x, g, y)

此外，这里有一些简单的代码来可视化组级轨迹。
plot(
NULL, NULL,
xlim = range(x_values_per_subject),
ylim = range(observed_data$y),
xlab = &quot;x&quot;, ylab = &quot;y&quot;
)
for (i in unique(observed_data$g)) {
this_g &lt;- subset(observed_data, g == i)
lines(this_g$x, this_g$y, type = &quot;b&quot;)
}

拟合这两个模型都很容易。
library(lme4)
simple_model &lt;- lm(y ~ 1 + x, data = perceived_data)
multilevel_model &lt;- lme4::lmer(y ~ 1 + x + (1 + x | g), data = perceived_data, REML = FALSE)

当我比较这两个模型时，我发现这两个模型对固定效应的点估计值相同，尽管由于我们已经考虑了聚类的额外变化，x 固定效应的标准误差要小得多。如果我们使用 ANOVA 或 AIC 来比较模型，多层级模型显然要好得多。
summary(simple_model)
summary(multilevel_model)
anova(multilevel_model, simple_model)

因此，给定这两个模型，我如何确定 x 的固定效应是否比集群间变异更重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/659976/how-to-compare-the-contribution-between-a-fixed-effect-and-a-random-effect-in-a</guid>
      <pubDate>Mon, 13 Jan 2025 19:01:20 GMT</pubDate>
    </item>
    <item>
      <title>Y 变量具有不同对比度规范的逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/659975/logistic-regression-with-different-contrast-specification-for-y-variable</link>
      <description><![CDATA[我试图理解使用 polr 函数为结果变量指定不同的对比度如何影响 R 中比例几率逻辑回归模型的结果。为了说明问题，我使用了示例数据集“申请研究生院”，可从此处获取。
我的 DV 是变量“apply”。它是一个具有 3 个级别的有序因子。级别为“不太可能”、“有点可能”和“非常可能”，编码为 1、2 和 3。
我的 IV 是变量“pared”。它是一个二元因子变量。级别编码为 0/1，表示至少有一位父母拥有研究生学位。
下面，我指定了两个模型，它们仅在对比应用于 IV（pared）和 DV（apply）的方式上有所不同。
library(MASS)
library(haven)
dat &lt;- read_dta(&quot;https://stats.idre.ucla.edu/stat/data/ologit.dta&quot;)
dat$apply &lt;- factor(dat$apply, ordered=T)
dat$pared &lt;- factor(dat$pared, ordered=F) # 治疗对比
contr_poly &lt;- contr.poly(length(unique(dat$apply))) # 多项式对比
对比（dat$应用）&lt;- contr_poly

dat1 &lt;- dat
scaled_contr_poly &lt;- (contr_poly - apply(contr_poly, 2, mean))/apply(contr_poly, 2, sd)
对比（dat1$应用）&lt;- scaled_contr_poly # 缩放多项式对比
对比（dat1$pared）&lt;- contr.sum(length(unique(dat1$pared))) # 总和对比

x &lt;- polr(apply ~ pared, data = dat, Hess=TRUE) # 非缩放
summary(x)

y &lt;- polr(apply ~ pared, data = dat1, Hess=TRUE) #缩放
summary(y)



对于系数“pared1”，我可以取模型 y 中获得的估计值，然后将其乘以 2，得到模型 x 中获得的估计值
因为，如果预测因子父母​​教育（pared）使用总和对比：1，-1
logit(P &lt;= j | xi = 1) = beta(j0) + eta(1) # 对比为 -1
logit(P &lt;= j | xi = 0) = beta(j0) - eta(1) # 对比为 1
其中 eta(i) = -beta(i)
logit(P &lt;= j | xi = 1) - logit(P &lt;= j | xi = 0) = 2*eta(1)
更多详情 此处
我无法弄清楚如何将 y 结果中获得的截距转换为 x 结果中获得的截距。
如果“apply”是 IV 而不是 DV，我会做类似下面的事情，但对我来说不起作用。
scale_multiplier &lt;- apply(scaled_contr_poly, 2, sd)/apply(contr_poly, 2, sd)
apply1 * scale_multiplier[1]
apply2 * scale_multiplier[2]

其中，apply1 和 apply2 是模型中的 beta 系数。
任何帮助都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659975/logistic-regression-with-different-contrast-specification-for-y-variable</guid>
      <pubDate>Mon, 13 Jan 2025 18:52:43 GMT</pubDate>
    </item>
    <item>
      <title>偏距离相关的解释</title>
      <link>https://stats.stackexchange.com/questions/659974/interpretation-of-partial-distance-correlation</link>
      <description><![CDATA[我想知道这里是否有人可以帮助理解部分距离相关的解释（https://projecteuclid.org/journals/annals-of-statistics/volume-42/issue-6/Partial-distance-correlation-with-methods-for-dissimilarities/10.1214/14-AOS1255.full）？我不是统计学家，所以原文对我来说有点难理解。
在第 4.2 节中，似乎暗示偏距离相关性和条件（不）依赖性并不总是相同的。但我不清楚与标准偏相关相比，偏距离相关性应该如何解释？
相关地，偏距离相关性似乎能够通过控制 Z 作为多维变量来“控制”超过 1 个变量，因为偏距离相关性（和其他能量统计数据）是针对任意不一定相等维度的随机向量定义的。同样在这种情况下，我很难理解当 z 是一个多维控制变量时，与偏相关或偏回归系数相比，对偏距离相关性的准确实质性解释应该是什么？或者，例如，假设我们有一组随机变量，它们呈正态分布，平均值为 0，标准差为 1，如果构建一个图，其中边表示“显著”的偏距离相关性，那么与边是“显著”偏相关的高斯图模型相比，这种解释会如何？（除了 pdcor 可以捕获非线性依赖关系这一事实之外，对于这个例子，假设所有依赖关系都是真正线性的）。
希望这有点道理！任何帮助都会得到赞赏，在此先致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659974/interpretation-of-partial-distance-correlation</guid>
      <pubDate>Mon, 13 Jan 2025 18:38:55 GMT</pubDate>
    </item>
    <item>
      <title>语料库中作者确定的统计检验</title>
      <link>https://stats.stackexchange.com/questions/659967/statistical-test-for-author-determination-in-corpus</link>
      <description><![CDATA[如何确定匿名作者撰写的语料库中的作者？
编辑：确定书信语料库中不同作者的数量以及它是否具有统计学显著性。]]></description>
      <guid>https://stats.stackexchange.com/questions/659967/statistical-test-for-author-determination-in-corpus</guid>
      <pubDate>Mon, 13 Jan 2025 16:37:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么皮尔逊残差和离差残差比正态残差变化更小？</title>
      <link>https://stats.stackexchange.com/questions/659966/why-are-pearson-and-deviance-residuals-less-variable-than-normal-residuals</link>
      <description><![CDATA[我正在阅读 Agresti 的分类数据分析（第 3 版），第 141 页写道：“当模型成立时，皮尔逊和偏差残差的变化小于标准正态分布，因为它们将 $y_i$ 与拟合均值 $\hat \mu_i$ 进行比较，而不是与真实均值 $\mu_i$ 进行比较...&quot;。我不太明白这句话。对于正态线性回归，残差是 $y_i - \hat y_i$，我们不是也使用预测均值作为 $\hat y_i$ 吗？有人可以解释一下 Agresti 是什么意思吗？
编辑：所指的“模型”是 GLM。 Agresti 在这里讨论了 GLM 的残差，并表示它们不像正态线性模型中的残差那样多变。]]></description>
      <guid>https://stats.stackexchange.com/questions/659966/why-are-pearson-and-deviance-residuals-less-variable-than-normal-residuals</guid>
      <pubDate>Mon, 13 Jan 2025 16:36:37 GMT</pubDate>
    </item>
    <item>
      <title>这个问题只能用贝叶斯来解决吗？</title>
      <link>https://stats.stackexchange.com/questions/659942/can-this-problem-only-be-solved-using-bayesian</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659942/can-this-problem-only-be-solved-using-bayesian</guid>
      <pubDate>Mon, 13 Jan 2025 04:46:48 GMT</pubDate>
    </item>
    </channel>
</rss>