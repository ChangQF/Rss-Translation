<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 19 Jan 2024 12:25:59 GMT</lastBuildDate>
    <item>
      <title>$\bar{X}-X_i$ 的分布</title>
      <link>https://stats.stackexchange.com/questions/637221/distribution-of-barx-x-i</link>
      <description><![CDATA[令 $X_1, \ldots, X_n$ 为独立同分布。标准正态分布的随机变量，令 $\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i$ 为他们的样本平均值。
我对 $Y_i = \bar{X}-X_i$ 的分布感兴趣。具体来说，假设存在一个 $p(\varepsilon)$ 使得对于任何 $i$
$$\mathbb{P}(|Y_i|\le\varepsilon) \le p(\varepsilon),$$
我试图将 $\mathbb{P}(\max_i|Y_i|\le\varepsilon)$ 绑定为 $p(\epsilon)$ 和 $n$。
如果 $Y_i$ 是独立的，我们可以很容易地写
$$\mathbb{P}(\max_i|Y_i|\le\varepsilon) = \prod_{i=1}^n \mathbb{P}(|Y_i|\le\ varepsilon) \le p(\varepsilon)^n.$$
不幸的是， $Y_i$ 不是独立的。我尝试了另一种方法，我想知道它是否正确。
第 1 步。
$Y_i$ 呈联合正态分布，且均独立于 $\bar{X}$。 
第 2 步。
因此，给定 $\bar{X}$ 时，$Y_i$ 的条件概率分布等于其无条件分布，因此 $\mathbb{P}(|Y_i|\le\varepsilon) = \mathbb{P}(|Y_i|\le\varepsilon \mid \bar{X }=\bar{x})$。
第 3 步。
当 $\bar{X}=\bar{x}$ 固定时， $Y_i = \bar{X} - X_i = \bar{x} - X_i$ 并且由于 $X_i$ 是独立的，因此 $Y_i给定 $\bar{X}$ 时，$ 都是相互条件独立的。
所以，
$$\mathbb{P}(\max_i|Y_i|\le\varepsilon \mid \bar{X}=\bar{x}) = \prod_{i=1}^ n \mathbb{P}(|Y_i|\le\varepsilon \mid \bar{X}=\bar{x}).$$
在我看来，通过结合步骤 1-3 我们可以得出结论
$$\mathbb{P}(\max_i|Y_i|\le\varepsilon) = \mathbb{P}(\max_i|Y_i|\le\varepsilon \mid \bar{X }=\bar{x}) = \prod_{i=1}^n \mathbb{P}(|Y_i|\le\varepsilon \mid\bar{X}=\bar{x})= \prod_{i =1}^n \mathbb{P}(|Y_i|\le\varepsilon) \le p(\varepsilon)^n.$$
我发现这个结果“好得令人难以置信”因为这就是如果 $Y_i$ 独立的话我们会得到的结果。有人可以确认一下上面的推理是否正确，如果不正确，请指出错误所在？]]></description>
      <guid>https://stats.stackexchange.com/questions/637221/distribution-of-barx-x-i</guid>
      <pubDate>Fri, 19 Jan 2024 12:23:03 GMT</pubDate>
    </item>
    <item>
      <title>“加权”是什么意思？我正在尝试学习逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/637218/what-does-the-weighted-mean-im-trying-to-learn-logistic-regression</link>
      <description><![CDATA[
“饮食失调 &lt;- c(0, 0, 0, 0, 1, 1, 1, 1)
性别 &lt;- c(0, 0, 1, 1, 0, 0, 1, 1)
应力 &lt;- c(0, 1, 0, 1, 0, 1, 0, 1)
加权 &lt;- c(3, 2, 4, 1, 5, 5, 9, 17)
y &lt;- c(3, 2, 4, 1, 5, 3, 5, 6)
AnxietyTreatment &lt;- data.frame(eating_disorder, 性别, 压力, 加权, y)
z &lt;- y / 加权
适合 &lt;- glm(z ~ 饮食失调 + 性别 + 压力, 家庭 = 二项式,
权重 = 加权，数据 = 焦虑治疗）
摘要（适合）”
请帮忙，这些是我用来分析数据的 r 代码，但结果显示“eating_disorder”=11084.3781 的标准错误极高，对我来说看起来不正确。我是否在治疗“加权”？正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637218/what-does-the-weighted-mean-im-trying-to-learn-logistic-regression</guid>
      <pubDate>Fri, 19 Jan 2024 11:52:33 GMT</pubDate>
    </item>
    <item>
      <title>预测力为零情况下的精确率和召回率</title>
      <link>https://stats.stackexchange.com/questions/637217/precision-and-recall-in-the-case-of-null-predictive-power</link>
      <description><![CDATA[对于多类分类问题，如果它是完美预测的，则预测类 $P(j|i)$ -container&quot;&gt;$j$ 对于真实类 $i$ 为 1，当 $j=1$ 时 ，否则为 0。在这种情况下，每个类别的精度为 1，每个类别的召回率为 1
当系统完全不可预测时，精确度和召回率会怎样？我想这相当于说 $P(j|i)$ 不依赖于真正的类 $i$&lt; /span&gt;，但实际上我不知道在这种情况下任何为零的指标。]]></description>
      <guid>https://stats.stackexchange.com/questions/637217/precision-and-recall-in-the-case-of-null-predictive-power</guid>
      <pubDate>Fri, 19 Jan 2024 11:16:52 GMT</pubDate>
    </item>
    <item>
      <title>具有许多短平行链的 ESS</title>
      <link>https://stats.stackexchange.com/questions/637216/ess-with-many-short-parallel-chains</link>
      <description><![CDATA[我有一个奇怪的问题想要分享并寻求参考和建议。
我正在研究 MCMC 问题，我意识到当我同时绘制许多链时，我具有很大的规模经济。也就是说，更新 100 条链 1 次的每次迭代成本远低于更新 1 条链 100 次的成本。
此外，我有一些证据表明我的链几乎没有自相关（如果有的话）。
了解这些元素后，我想采取以下策略：我不想更新一条链几百次，而是更新一百条链几次。即使我对样本中的自相关性较低这一事实有一定的信心，我也想检查一些积分质量的衡量标准。 有效样本量会很棒.
但是，使用无限次自相关的常用公式在这里并不适用，因为它依赖于一条链，并且需要多次迭代。我的情况正好相反。
我的第一个调用是使用所有链计算池自相关，然后将其代入 ESS 公式中。兴趣参数 $x$ 的平均值 $\mu$ 将为
$$\hat \mu = \Sigma _{i=1}^{number ~chains}\Sigma _{j~=~burn~in}^{number ~迭代} x_i^j/((数量~迭代 - 烧入)*(数量~链)) ,$$
x_i^j 在这里是 $i^{th}$$j^{th}$ 迭代&gt; 链。然后，我们得到自协方差
$$\hat\sigma^2(\delta) = \Sigma _{i=1}^{number ~chains}\Sigma _{j~=~burn~in}^ {number ~iterations ~-~ \delta} (x_i^j-\hat \mu)(x_i^{j+\delta}-\hat \mu)/((number ~iterations - burn~in)*(number~chains )),$$
$\delta$ 是滞后。然后获得合并的自相关性：
$$acf(\delta) = \hat\sigma^2(\delta)/\hat\sigma^2(0).$$
现在，我只是将自相关的估计插入 ESS 公式中。
不过我不确定我是对的，我认为带有有限维相关矩阵的 ESS 公式而不是无限 acf 会更好。
有人有评论、见解、参考吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637216/ess-with-many-short-parallel-chains</guid>
      <pubDate>Fri, 19 Jan 2024 11:03:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 方包对连续变量进行截止[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637214/cut-offs-for-continuous-variables-using-party-r-package</link>
      <description><![CDATA[我正在开展一个项目，以确定更好地预测二元结果的变量。为此，我使用 party::cforest 拟合条件随机森林，对于变量重要性，我使用 permimp::permimp 函数。现在，我想确定连续变量的截止值。有没有办法从 R 方包中获取它们，即主要用于相应变量分割的截止值？如果不可能或没有意义，您能否建议这样做的方法或 R 函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/637214/cut-offs-for-continuous-variables-using-party-r-package</guid>
      <pubDate>Fri, 19 Jan 2024 10:29:53 GMT</pubDate>
    </item>
    <item>
      <title>KNN 和局部回归 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637211/knn-and-local-regression</link>
      <description><![CDATA[早上好，
我在一次数据挖掘考试中发现了这个问题：
考虑 K 最近邻 (KNN) 与具有矩形核和带宽 h 的局部回归之间的关系。有哪些差异？在这种情况下，给出完全相同结果的 k 和 h 值是多少？”
非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/637211/knn-and-local-regression</guid>
      <pubDate>Fri, 19 Jan 2024 09:13:26 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 使用 XGBClassifier 学习排名</title>
      <link>https://stats.stackexchange.com/questions/637210/xgboost-learning-to-rank-with-xgbclassifier</link>
      <description><![CDATA[我正在尝试构建一个在二进制标签上训练的模型，该模型对前 k 个预测实例具有高精度，并且不太关心一般情况下的召回率或精度。然后，我对在分类问题中对实例进行排名的想法感兴趣，而不是查看预测概率，因此我认为我可以使用单个查询组来使用 XGBRanker。
我注意到 Learning to Rank 参数可以传递给 XGBClassifier 而不会引发任何错误，事实上，使用单个查询组 XGBClassifier 和 XGBRanker 似乎输出相同的结果（请参阅下面的代码，使用 xgboost v2.0.3 在 python 中重现）。在这里使用 XGBClassifier 会更简单，因为它不会破坏 sklearn 兼容性，但我不确定这是否是正确的用法。
我已在 XGBoost 论坛上询问过此问题&lt; /a&gt;，但也想知道这里是否有人了解将 XGBClassifier 与 objective=&#39;rank:map&#39; 一起使用是否实际上等同于将 XGBRanker 与单个查询组一起使用。
 from sklearn.datasets import make_classification
    将 numpy 导入为 np

    将 xgboost 导入为 xgb

    # 制作一个综合排名数据集用于演示
    种子 = 1994
    X, y = make_classification(random_state=种子)
    rng = np.random.default_rng(种子)
    n_query_groups = 1
    qid = rng.integers(0, n_query_groups, size=X.shape[0])

    # 根据查询索引对输入进行排序
    sorted_idx = np.argsort（qid）
    X = X[sorted_idx, :]
    y = y[已排序_idx]
    qid_sorted = qid[sorted_idx]
    排名器= xgb.XGBRanker（lambdarank_num_pair_per_sample=8，目标=“排名：地图”）
    ranker.fit(X, y, qid=qid_sorted)

    classif = xgb.XGBClassifier(lambdarank_num_pair_per_sample=8, Objective=“排名：地图”)
    分类.fit(X, y)

    排名预测=排名者.预测(X)
    classif_prediction = classif.predict(X)
    classif_prediction_proba = classif.predict_proba(X)[:, 1]

    断言 np.array_equal(rank_prediction, classif_prediction_proba)
]]></description>
      <guid>https://stats.stackexchange.com/questions/637210/xgboost-learning-to-rank-with-xgbclassifier</guid>
      <pubDate>Fri, 19 Jan 2024 08:25:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么方程中张量的阶数会改变 GAM 的结果？</title>
      <link>https://stats.stackexchange.com/questions/637209/why-order-of-tensors-in-equation-changes-results-of-gam</link>
      <description><![CDATA[最近，我尝试在 mgcv 的 GAM 模型中使用负二项分布对每日计数进行建模，以获得 RR。数据来自 20 年的每日时间序列，具有每周和每月的季节性。鉴于之前的系列分解，我假设季节性每年都在变化。因此我使用张量积来建模：
&lt;前&gt;&lt;代码&gt;库(mgcv)

gam_model &lt;- gam(counts ~ te(year, day_of_week, k=c(20,7), bs=c(&quot;tp&quot;,&quot;cc&quot;) +
                          te(年, 年日, k=c(20,12), bs=c(“tp”, “cc”),
                          结=列表(年日=c(0.5, 366.5), 周日=c(0.5, 7.5)),
                          数据=daily_ts，
                          方法＝“REML”，
                          家庭=nb())

我不小心将方程的顺序更改为：
&lt;前&gt;&lt;代码&gt;库(mgcv)

gam_model &lt;- gam(counts ~ te(year, day_of_year, k=c(20,12), bs=c(&quot;tp&quot;,&quot;cc&quot;) +
                          te(年，星期几，k=c(20,7)，bs=c(“tp”，“cc”)，
                          结=列表(年日=c(0.5, 366.5), 周日=c(0.5, 7.5)),
                          数据=daily_ts，
                          方法＝“REML”，
                          家庭=nb())

结果是不同的，例如year和day_of_year的张量从(1st eq)变化：

到（第二个等式）：

为什么会出现这种情况呢？我检查过并发性，没有。我认为方程各分量的顺序并不重要。我应该选择哪种解决方案或如何纠正它？]]></description>
      <guid>https://stats.stackexchange.com/questions/637209/why-order-of-tensors-in-equation-changes-results-of-gam</guid>
      <pubDate>Fri, 19 Jan 2024 07:28:27 GMT</pubDate>
    </item>
    <item>
      <title>不拟合边缘分布的 Copula 函数</title>
      <link>https://stats.stackexchange.com/questions/637207/copula-functions-without-fitting-marginal-distributions</link>
      <description><![CDATA[我正在使用 MvCAT 工具箱，它适合不同的 copula 系列以适应导入的数据并确定哪个 copula 函数表现最好（请注意，它仅适用于两个变量）。我在使用此工具箱时面临的一个问题是，对数据经验概率的拟合边际分布是不可接受的（尽管 MvCAT 尝试了大约 20 个已知的 CDF 函数并优化了它们的参数）。
我想知道是否存在其他方法来拟合 copula，而无需对我的数据拟合边际分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/637207/copula-functions-without-fitting-marginal-distributions</guid>
      <pubDate>Fri, 19 Jan 2024 06:32:45 GMT</pubDate>
    </item>
    <item>
      <title>nlme 包中 PGLS anova 的平方和</title>
      <link>https://stats.stackexchange.com/questions/637185/sum-of-squares-for-pgls-anova-from-package-nlme</link>
      <description><![CDATA[有人可以帮我解决以下问题吗？如何从 nlme 包中获取 PGLS 方差分析的平方值之和（SStotal、SS Between、SSwithin）？这是一个示例模型：
图书馆(ape)
图书馆（nlme）

Barbet &lt;- read.csv(“http://www.phytools.org/Cordoba2017/data/Barbetdata.csv”，header = TRUE，row.names = 1)
Barbet$species &lt;- row.names(Barbet)

树 &lt;- read.nexus(“http://www.phytools.org/Cordoba2017/data/BarbetTree.nex”)

pgls.model &lt;- gls(Lnote ~ Lnalt + wing, 数据 = Barbet, 相关性 = corPagel(值 = 1, 形式 = ~ 物种, phy = 树))
方差分析（pgls.model）

提前感谢您的回答！]]></description>
      <guid>https://stats.stackexchange.com/questions/637185/sum-of-squares-for-pgls-anova-from-package-nlme</guid>
      <pubDate>Thu, 18 Jan 2024 19:23:55 GMT</pubDate>
    </item>
    <item>
      <title>python中STL分解和查找异常值的问题</title>
      <link>https://stats.stackexchange.com/questions/637143/problems-with-stl-decomposition-and-finding-outliers-in-python</link>
      <description><![CDATA[这是我正在制作的一个示例系列，旨在探讨异常值检测主题。我是一名开发人员，不是统计学家。
我的目标是使用 STL 来消除趋势并淡化我的系列。这样我就可以开始分析异常值的残余分量。
我的分解问题是时间步 15 处的异常值成为季节性分量的一部分。这意味着对于剩余部分来说，第一年会出现下降，而不是第二年会出现峰值。
我读过并且已经被告知使用平均值和标准差可能不是最佳的。但这不是这里的主要问题。

我的思维过程有缺陷吗？
您建议我做什么来开始异常值检测领域？
有没有可以推荐的异常值检测方法？
我应该使用哪些指标来代替均值和标准差来检测残差中的异常值？
数据：
&lt;代码&gt;[0, 2, 5, 8, 12, 15, 18, 22, 25, 28, 20, 10, 0, 2, 5, 18, 12, 15, 18, 22, 25, 28 , 20, 10]
代码：
def detector_outliers(timeseries):
    timeseries_values = timeseries[&#39;prognosebasis&#39;].values

    stl = STL(timeseries_values, 周期=12, 稳健=True)
    stl_fit = stl.fit()
    绘图组件（stl_fit）

    resid_mean = stl_fit.resid.mean()
    resid_std = stl_fit.resid.std()

    下=残差平均值 - (3*残差标准差)
    上层 = 残差平均值 + (3*残差标准差)

    异常值 = np.where((stl_fit.resid &gt; upper) | (stl_fit.resid &lt; lower))
    返回异常值

24 年 1 月 19 日更新：
我选择了具有 3 个完整季节周期的时间序列并重新进行了实验。我很惊讶地发现在第三个系列中，异常值没有被正确识别。

我还尝试了 statsmodels season_decompose 进行比较：

关于为什么 STL 以这种方式解释第三个异常值有任何线索吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637143/problems-with-stl-decomposition-and-finding-outliers-in-python</guid>
      <pubDate>Thu, 18 Jan 2024 09:50:05 GMT</pubDate>
    </item>
    <item>
      <title>解释基于深度学习的图像分类模型的 Wilcoxon 符号秩检验 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637129/interpreting-wilcoxon-signed-rank-test-for-deep-learning-based-image-classificat</link>
      <description><![CDATA[我有一种算法可以生成用于图像分类的深度学习模型。我正在研究它是否比随机搜索表现更好。为了实现这一目标，我在多个数据集上运行了 10 次独立执行，并发现了以下结果：

我的算法生成的最佳模型优于所有数据集的随机搜索算法的最佳模型。

但是，对每个数据集进行 Wilcoxon 符号排名测试得出以下结果：


&lt;块引用&gt;
P 值：{“凸”：0.492、“MNIST-BI”：1.0、“MNIST-RB”：0.625、“MNIST-RD”：0.275、“MNIST-RD+BI”：0.02、“矩形” &#39;: 0.275, &#39;矩形-I&#39;: 0.037}

&lt;块引用&gt;
统计值：{&#39;凸&#39;：20.0，&#39;MNIST-BI&#39;：27.0，&#39;MNIST-RB&#39;：22.0，&#39;MNIST-RD&#39;：16.0，&#39;MNIST-RD+BI&#39;：5.0，&#39;矩形&#39; : 16.0, &#39;矩形-I&#39;: 7.0}

我不知道如何表达/解释这两个发现的组合。特别是：

某些数据集中的高 p 值是否意味着我的算法的性能相当于随机搜索，或者更接近于我的算法的中值性能与随机搜索的中值性能相似。后者仍然会为有利于我的算法的性能差异留下空间，因为我的算法可能会以某种方式产生更好的异常值。
我在数据集 MNIST-RD+BI 和 Rectangles-I 中获得的低 p 值是否可能仅仅是由于偶然以及我进行了多次比较的事实？在这种情况下，像方差分析这样的东西会有帮助并且合适吗？
“尽管七个数据集中的五个没有统计差异，但我的算法有可能产生最佳模型”这样的说法是否合理？这是基于这样一个事实：我的算法的最佳模型始终优于随机搜索的最佳模型。

此处显示了每种算法和数据集生成的 10 个模型的准确率：

这是我用来进行测试的代码（Python）：
wilcoxon_results = stats.wilcoxon(base, rnd)
stat_p_values_wilc[数据集] = wilcoxon_results.pvalue.round(3)
stat_statistic_wilc[数据集] = wilcoxon_results.statistic.round(3)

在上面，“基础”是指代表我的算法结果，“rnd”代表随机搜索的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/637129/interpreting-wilcoxon-signed-rank-test-for-deep-learning-based-image-classificat</guid>
      <pubDate>Thu, 18 Jan 2024 05:10:21 GMT</pubDate>
    </item>
    <item>
      <title>调整多个模型的实验错误率的置信区间</title>
      <link>https://stats.stackexchange.com/questions/637118/adjusting-confidence-intervals-for-the-experimentwise-error-rate-across-multiple</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637118/adjusting-confidence-intervals-for-the-experimentwise-error-rate-across-multiple</guid>
      <pubDate>Thu, 18 Jan 2024 01:58:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么矩量法 (MoM) 不是唯一的？什么是独特性？</title>
      <link>https://stats.stackexchange.com/questions/637102/why-is-method-of-moments-mom-not-unique-what-is-uniqueness</link>
      <description><![CDATA[我刚刚了解到 MoM 估计器不是唯一的......这是什么意思？一般来说，独特意味着什么？
例如，如果我们要使用均匀分布的 MoM 估计器求平均值，则这将是 $(a+b)/2$，对吧？它是否被认为是非唯一的，因为有两个变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/637102/why-is-method-of-moments-mom-not-unique-what-is-uniqueness</guid>
      <pubDate>Wed, 17 Jan 2024 21:03:03 GMT</pubDate>
    </item>
    <item>
      <title>如何对重复测量的数据进行混合效应模型？</title>
      <link>https://stats.stackexchange.com/questions/636649/how-to-perform-mixed-effect-model-for-data-with-repeated-measurements</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636649/how-to-perform-mixed-effect-model-for-data-with-repeated-measurements</guid>
      <pubDate>Thu, 11 Jan 2024 14:09:01 GMT</pubDate>
    </item>
    </channel>
</rss>