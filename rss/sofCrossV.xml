<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 31 Jan 2025 06:25:14 GMT</lastBuildDate>
    <item>
      <title>只有神经微分方程的输出才重要</title>
      <link>https://stats.stackexchange.com/questions/660790/only-output-of-neural-ode-matters</link>
      <description><![CDATA[我有一个神经 ODE 问题，形式如下：
$\dot{X}(\theta)$ = $f(\theta)$
其中 $f$ 是一个神经网络。
我想积分得到 $X(2\pi)$。
我没有数据来匹配 $\theta$ 的中间值。
只需要匹配最终目标 $X(2\pi)$。
这是一个神经 ODE 问题吗？或者有更好的方法来构建它？]]></description>
      <guid>https://stats.stackexchange.com/questions/660790/only-output-of-neural-ode-matters</guid>
      <pubDate>Fri, 31 Jan 2025 05:17:06 GMT</pubDate>
    </item>
    <item>
      <title>解析简单门控 RNN 随时间反向传播的解法</title>
      <link>https://stats.stackexchange.com/questions/660789/analytically-solving-backpropagation-through-time-for-a-simple-gated-rnn</link>
      <description><![CDATA[考虑以下简单的门控 RNN：
\begin{aligned}
c_{t} &amp;= \sigma\bigl(W_{c}\,x_{t} + W_{z}\,z_{t-1}\bigr)
\\[6pt]
z_{t} &amp;= c_{t} \,\odot\, z_{t-1} \;\;+\;\; 
(1 - c_{t}) \,\odot\,\bigl(W_{x}\,x_{t}\bigr)。
\end{aligned&gt;
这里，
$$
x_{t}\in \mathbb{R}^{n}, \quad
z_{t}\in \mathbb{R}^{m}, \quad
c_{t}\in \mathbb{R}^{m}, 
$$
和
$$
W_{c}\in \mathbb{R}^{m\times n},\, 
W_{z}\in \mathbb{R}^{m\times m},\,
W_{x}\in \mathbb{R}^{m\times n}。
$$
门$c_{t}=\sigma(\cdot)$是元素级 S 型函数。
我们让损失为
$$
\ell \;=\;\sum_{t=1}^{K}\;\ell_{t}\,\bigl(z_{t}\bigr)
$$
因此每个$z_{t}$都对$\ell$有贡献。
我们试图在给定$\frac{\partial \ell_t}{\partial z_t}$的情况下找到$\frac{\partial \ell}{\partial W_x}$。我们可以从以下公式开始：
$$
\frac{\partial \ell}{\partial W_{x}} =
\sum_{t=1}^{K} \left(\frac{\partial \ell_t}{\partial z_{t}} \cdot
\frac{\partial z_{t}}{\partial W_{x}} \right)
$$
并且我们必须找到$\frac{\partial z_{t}}{\partial W_{x}}$。为了方便起见，我们可以将每个 $z_t$ 视为多个变量的函数 $f$：
$$
f(U, z_{\text{prev}}, c_t, x_t) = c_t \odot z_{\text{prev}} + (1 - c_t)\,\odot\,(U \, x_t)
$$
然后
$$
z_t = f(W_x, z_{t-1}, c_t, x_t)
$$
然后我们有
$$
\frac{\partial z_t}{\partial W_x} = \underbrace{\Bigl(\frac{\partial f}{\partial U}\Bigr)}_{\text{local}} + 
\Bigl(\frac{\partial f}{\partial z_{\text{prev}}}\Bigr)
\frac{d\,z_{t-1}}{d W_x} + 
\Bigl(\frac{\partial f}{\partial c_t}\Bigr) \frac{\partial c_t}{\partial W_x}
$$
其中 $W_x$ 对 $z_t$ 有“局部”或直接影响，以及通过 $z_{t-1}$ 和 $c_t$ 有间接影响。让我们定义
\begin{align*}
\varepsilon_t &amp;= \frac{\partial f}{\partial U}(W_x, z_{t-1}, c_t, x_t) \\
\delta_t &amp;= \frac{\partial \ell}{\partial z_t} 
\end{align*&gt;
如何证明以下说法？
\begin{align*}
\frac{\partial \ell}{\partial W_{x}} = \sum_{t=1}^{K} \delta_t \varepsilon_t
\end{align*&gt;
我可以使用 PyTorch 验证它，但我正在寻找分析证明。]]></description>
      <guid>https://stats.stackexchange.com/questions/660789/analytically-solving-backpropagation-through-time-for-a-simple-gated-rnn</guid>
      <pubDate>Fri, 31 Jan 2025 03:12:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 emmeans() 从 coxph() 估计随时间变化的 HR</title>
      <link>https://stats.stackexchange.com/questions/660788/using-emmeans-to-estimate-time-varying-hrs-from-coxph</link>
      <description><![CDATA[emmeans() 非常棒，我使用它进行了很多事后估计。但是，我想知道是否有办法从指定了协变量-时间交互的 coxph() 模型中获得 HR（如果想要努力考虑潜在的非比例风险）。
我找到了一种估算协变量-协变量交互项的 HR 的方法，但找不到任何关于时间-协变量交互项的方法。
如能得到任何帮助，我将不胜感激。以下是一些虚拟代码：
library(survival)
library(emmeans)
set.seed(123)
# 创建数据
df &lt;- data.frame(time = round(runif(100, min = 1, max = 70)), 
status = round(runif(100, min = 0, max = 1)),
drug = round(runif(100, min = 0, max = 1)),
age40 = round(runif(100, min = 0, max = 1)), 
stringsAsFactors = FALSE)

# 具有协变量-协变量相互作用的模型
mod1 &lt;- coxph(Surv(time, status) ~ drug * age40, data = df)
summary(mod1)

# 估计因子组合的 HR
emmeans(mod1, ~ drug + age40, type = &quot;unlink&quot;) |&gt; 对(rev = T) |&gt; 摘要(infer = T)

# 具有时间协变量相互作用的模型
mod2 &lt;- coxph(Surv(time, status) ~ drug + tt(drug), tt = function(x,t,...) x*t, data = df)
摘要(mod2)

# 估计不同观察时间的 HR？
emmeans(...

# 这可能吗？

编辑：
我应该补充一下，如果不使用 emmeans()，还有其他方法吗（除了根据模型方程手动计算 HR）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660788/using-emmeans-to-estimate-time-varying-hrs-from-coxph</guid>
      <pubDate>Fri, 31 Jan 2025 02:05:34 GMT</pubDate>
    </item>
    <item>
      <title>组合预测因子是否总能改善 AUC？</title>
      <link>https://stats.stackexchange.com/questions/660787/does-combining-predictors-always-improve-auc</link>
      <description><![CDATA[我有两个独立的预测因子，x₁ 和 x₂，以及一个二元结果 y。
模型 1：使用 x₁ 预测 y
模型 2：使用 x₂ 预测 y
模型 3：使用两个预测因子之和 (x₃ = x₁ + x₂) 预测 y

我的预期是，通过将预测因子相加来组合至少会实现两个单独模型的更高 AUC。但是，我发现情况并非总是如此。
例如：
当 AUC(x₁) = 0.59 和 AUC(x₂) = 0.59 时，组合模型实现 AUC(x₃) = 0.63（更好）。
但当 AUC(x₁) = 0.59 且 AUC(x₂) = 0.54 时，组合模型 AUC(x₃) = 0.58，这比单独使用 x₁ 更差。

组合模型的 AUC 低于单个模型之一，这在统计上有效吗？如果是，这背后的原因是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660787/does-combining-predictors-always-improve-auc</guid>
      <pubDate>Fri, 31 Jan 2025 01:36:54 GMT</pubDate>
    </item>
    <item>
      <title>决定是否在模型中包含约束</title>
      <link>https://stats.stackexchange.com/questions/660786/deciding-whether-or-not-to-include-constraints-into-a-model</link>
      <description><![CDATA[我有一个离散随机过程，我认为当前状态$ Y_n $取决于三个最近的状态$ X_{n-1}, X_{n-2}, X_{n-3} $，但具有加权结构，使得较新的状态对结果的影响大于较旧的状态（即$w_1 &gt; w_2 &gt; w_3$）。
使用逻辑回归对此进行建模是有意义的：
$$
P(Y_n = 1 \mid X_{n-1}, X_{n-2}, X_{n-3}) = \sigma\left( b_0 + w_1 X_{n-1} + w_2 X_{n-2} + w_3 X_{n-3} \right),
$$
其中：

$ \sigma(z) = \frac{1}{1 + e^{-z}} $ 是逻辑 (S 型) 函数，
$ b_0 $ 是截距，
$ w_1, w_2, w_3 $ 是分配给过去状态的权重，决定它们对 $ Y_n $ 的影响，


方法 1：无约束
如果不考虑约束，可以使用 MLE。给定一个包含 $ N $ 个观测值的数据集，似然函数和解决方案为：
$$
L(b_0, w_1, w_2, w_3) = \prod_{n=1}^{N} P(Y_n \mid X_{n-1}, X_{n-2}, X_{n-3})^{Y_n} (1 - P(Y_n \mid X_{n-1}, X_{n-2}, X_{n-3}))^{1 - Y_n}。
$$
$$
\ell(b_0, w_1, w_2, w_3) = \sum_{n=1}^{N} \left[ Y_n \log \sigma(z_n) + (1 - Y_n) \log (1 - \sigma(z_n)) \right],
$$
$$
z_n = b_0 + w_1 X_{n-1} + w_2 X_{n-2} + w_3 X_{n-3}。
$$
$$
(b_0^*, w_1^*, w_2^*, w_3^*) = \arg\max_{b_0, w_1, w_2, w_3} \ell(b_0, w_1, w_2, w_3).
$$

方法 2：带约束
考虑以下约束：$w_1 &gt; w_2 &gt; w_3$
现在，我们不再直接估算 $ w_1, w_2, w_3 $，而是引入新参数 $ \beta_1, \beta_2, \beta_3 $，使得：
$$
\beta_1 &gt; \beta_2 &gt; \beta_3.
$$
$$
\beta_1 = \alpha_1, \quad \beta_2 = \alpha_1 - e^{\alpha_2}, \quad \beta_3 = \alpha_1 - e^{\alpha_2} - e^{\alpha_3}.
$$
这保证：
$$
\beta_1 &gt; \beta_2 &gt; \beta_3。
$$
$$
w_i = e^{\beta_i}, \quad i=1,2,3。
$$
从这里开始，定义一个类似的似然函数：
$$
\ell(b_0, \alpha_1, \alpha_2, \alpha_3) = \sum_{n=1}^{N} \left[ Y_n \log \sigma(z_n) + (1 - Y_n) \log (1 - \sigma(z_n)) \right],
$$
$$
z_n = b_0 + w_1 X_{n-1} + w_2 X_{n-2} + w_3 X_{n-3}。
$$
$$
(b_0^*, \alpha_1^*, \alpha_2^*, \alpha_3^*) = \arg\max_{b_0, \alpha_1, \alpha_2, \alpha_3} \ell(b_0, \alpha_1, \alpha_2, \alpha_3).
$$

我的问题与以下内容有关：假设我首先对数据使用方法 1（无约束），并发现 $ w1 \ngtr w2 \ngtr w3 $。这是否意味着（不幸的是）数据不支持我关于 $w_1 &gt; w_2 &gt; w_3$ 的假设，我应该停止研究这个模型？或者我应该使用方法 2（带约束）并强制假设 $w_1 &gt; w_2 &gt; w_3$？
这个问题的统计建模标准做法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660786/deciding-whether-or-not-to-include-constraints-into-a-model</guid>
      <pubDate>Fri, 31 Jan 2025 01:30:00 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 KSG 估计量来计算一个变量的固定值的特定互信息估计？</title>
      <link>https://stats.stackexchange.com/questions/660782/how-can-we-compute-a-specific-mutual-information-estimate-for-a-fixed-value-of-o</link>
      <description><![CDATA[我正在使用 Kraskov-Stögbauer-Grassberger (KSG) 估计器进行互信息 (MI) 计算，并希望计算一个变量固定值的特定互信息估计值，同时考虑另一个变量的所有值。这在概念上类似于 DeWeese &amp; 引入的刺激特定信息Meister (1999)。
互信息的 KSG 估计量由以下公式给出：
$
I(X; Y) = \psi(k) - \frac{1}{N} \sum_{i=1}^{N} \left[ \psi(n_x(i) + 1) + \psi(n_y(i) + 1) \right] + \psi(N)
$
其中 $k$ 是最近邻居的数量，$n_x(i)$ 是 $X$ 中 $k$-NN 半径内的邻居数量（$x_i$, $y_i$), $n_y(i)$ 是 Y 中同一半径内的邻居数量，$\psi(\cdot)$ 是双伽马函数。每对 $(x_i, y_i)$ 对 MI 的贡献可以通过取消平均值来实现：
$
i(x_i; y_i) = \psi(k) - \psi(n_x(i) + 1) - \psi(n_y(i) + 1) + \psi(N)
$
但是，我想调整这个估计量来计算给定值 $Y=y_i$ 的特定互信息，同时考虑 $X$ 的所有值。具体来说，我想估计 $I(X; Y=y_i)$。是否可以使用 KSG 估计器的修改来计算这个特定的相互信息？如果可以，那么实现这一点的最佳方法是什么，同时确保对整个 $y$ 取 $I(X; Y=y_i)$ 的平均仍能恢复总相互信息 I(X; Y)？]]></description>
      <guid>https://stats.stackexchange.com/questions/660782/how-can-we-compute-a-specific-mutual-information-estimate-for-a-fixed-value-of-o</guid>
      <pubDate>Thu, 30 Jan 2025 22:30:18 GMT</pubDate>
    </item>
    <item>
      <title>当每个测试样本的理论分布发生变化时，如何使用（或替代）精确多项式检验</title>
      <link>https://stats.stackexchange.com/questions/660781/how-to-use-or-alternatives-to-exact-multinomial-test-when-the-theoretical-dist</link>
      <description><![CDATA[假设我有一个过程，其结果可以分为 5 个类别：A、B、C、D 和 E。这些类别是相互排斥且详尽的，并且整个过程中的单个试验彼此独立。
我已经建立了这个过程的概率模型，对于给定的一组输入条件，我可以运行蒙特卡罗模拟来为这 5 个类别中的每一个生成一组计数（例如，我运行模型 100 次，分别在 A 到 E 类别中获得 20、30、20、15 和 15 个计数）。
为了评估模型，我假设我可以在与模拟相同的条件下运行一组实验，并使用 精确多项式检验或卡方检验，在数据由蒙特卡洛计数所建议的概率分布生成的零假设下生成 p 值：(.2, .3, .2, .15, .15)。
问题 1
到目前为止，我对此的思考正确吗？精确多项​​式是评估拟合优度的正确方法吗？
现在假设我无法控制现实生活过程的输入条件。假设有 20 个实例映射到 5 个类别 A-E，但 20 个实例中的每一个都有一组不同的输入条件。
问题 2
在这种情况下，我该如何评估我的模型？有没有办法在这里应用精确的多项式检验，对 20 组输入条件中的每一组运行模型 N 次，或者是否有其他一些测试统计量来评估所有 20 个实例的总体表现？
顺便说一句，我也无法控制样本量。通常我可以比较大约 20-60 个真实事件。]]></description>
      <guid>https://stats.stackexchange.com/questions/660781/how-to-use-or-alternatives-to-exact-multinomial-test-when-the-theoretical-dist</guid>
      <pubDate>Thu, 30 Jan 2025 22:12:51 GMT</pubDate>
    </item>
    <item>
      <title>Kruskal-Wallis 检验还是其他？</title>
      <link>https://stats.stackexchange.com/questions/660775/kruskal-wallis-test-or-other</link>
      <description><![CDATA[我有一个包含三组右偏数据的数据集。每个观测值只有四个可能的值：10、20、30 和 40。下面是一年中每个值被观察到的次数的频率表。




10
20
30
40




2022
12
3
1
0


2023
8
0
4
1


2024
29
11
3
0



使用 Kruskal-Wallis 检验来评估这些年份在统计上是否存在差异是否合适？或者因为观测值只有四个可能的值，所以 H 统计量是否存在偏差？]]></description>
      <guid>https://stats.stackexchange.com/questions/660775/kruskal-wallis-test-or-other</guid>
      <pubDate>Thu, 30 Jan 2025 18:47:39 GMT</pubDate>
    </item>
    <item>
      <title>在偏最小二乘潜在空间中提取模式（即聚类）是否有优势？</title>
      <link>https://stats.stackexchange.com/questions/660771/are-there-advantages-in-extracting-patterns-i-e-clustering-on-partial-least-s</link>
      <description><![CDATA[我使用偏最小二乘法，以便在相关协变量的情况下获得线性模型参数。
我想尝试在偏最小二乘潜在空间中进行聚类，即由第一个偏最小二乘分量和第二个偏最小二乘分量构成的空间，或者可能是由第一个偏最小二乘分量的 X 分数和 Y 分数构成的空间。
在这个空间上进行聚类可以揭示一些与 PCA 相关的其他特征吗？
如果我有独立的 X 数据和相关的 Y 数据，PLS 会找到主成分，以便数据在最适合 X 数据的直线上的投影与最适合 Y 数据的直线上的投影之间的协方差最大化。因此，我们最大化 X 空间中的投影和 Y 空间中的投影所形成的空间中的方差。
相反，使用 PCA，您会提取 X 中的所有 Y 数据，并对 X 应用 PCA。PCA 会找到最大化数据之间方差的主成分。
我的问题是：是否可以合理地认为 PLS 潜在空间会根据某些特征分离数据，而使用简单的 PCA 则无法实现这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/660771/are-there-advantages-in-extracting-patterns-i-e-clustering-on-partial-least-s</guid>
      <pubDate>Thu, 30 Jan 2025 17:27:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么在之前的抛硬币过程中，下一次抛硬币的不确定性会随着测量次数的增加而增加？</title>
      <link>https://stats.stackexchange.com/questions/660769/why-does-the-uncertainty-of-the-next-coin-flip-given-previous-flips-goes-up-with</link>
      <description><![CDATA[我对与给定先前抛硬币的抛硬币预测后验相关的一些事情有点困惑。假设我在 N 次抛硬币中看到 k 次正面，我想找出下一次抛硬币是正面的概率。我不仅想量化下一次抛硬币是正面的概率，还想量化我对它是否会是正面的不确定性。如果我假设一个均匀的先验并做一些数学运算，我可以得出下一次抛硬币的预期值为
$$
E_p[E_H[H|p]] = \frac{k+1}{N+2}
$$
方差的期望值为
$$
E_p[Var_H[H|p]] = \frac{(k+1)(N-k+1)}{(N+2)(N+3)}。
$$
但是当我尝试几个 k 和 N 的值，使 k=N/3 保持不变时，我注意到不确定性会随着翻转次数的增加而增加。
 k N E[E[H|p]] E[Var[H|p]]
1 3 0.400000 0.200000
2 6 0.375000 0.208333
4 12 0.357143 0.214286
8 24 0.346154 0.217949
16 48 0.340000 0.220000

为什么我获得更多数据时不确定性会增加？这似乎不正确。我猜想使用方差的期望值作为不确定性的代理肯定是有缺陷的，但我不知道更好的指标是什么。如果是这样的话，你能在下一次抛硬币时提出一个更好的不确定性指标吗，以符合不确定性应该随着数据增加而减少的直觉？否则这里还有其他问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660769/why-does-the-uncertainty-of-the-next-coin-flip-given-previous-flips-goes-up-with</guid>
      <pubDate>Thu, 30 Jan 2025 17:24:09 GMT</pubDate>
    </item>
    <item>
      <title>未调整生存率与 IPW 调整生存率的 Kaplan-Meier 估计时限差异</title>
      <link>https://stats.stackexchange.com/questions/660764/difference-in-time-limits-for-kaplan-meier-estimates-with-unadjusted-vs-ipw-adj</link>
      <description><![CDATA[我正在使用 adjustedsurv 函数计算两组 (Treatment_type_tumor_near_gallbladder) 在特定时间点 (0 到 120 个月，以 12 个月为间隔) 的 Kaplan-Meier (K-M) 总生存期 (OS) 估计值。
但是我遇到了一个问题：
1. 未调整的 K-M 估计值：使用标准 Kaplan-Meier 方法 (method=&quot;km&quot;) 时，我获得了两组长达 84 个月的生存期估计值。
2. IPW 调整后的 K-M 估计值：使用逆概率加权 (IPW) 时，方法为&quot;iptw_km&quot;并且 weight_method=&quot;OptWeight&quot;，生存估计值仅可用于 48 个月以内。
鉴于 IPW 重新加权所有观察值，而不是排除不匹配的患者（如倾向得分匹配），我预计所有患者和事件仍将包括在内。但是，在 IPW 调整的分析中，时间范围似乎被截断了。
有人能解释一下为什么会发生这种情况吗？这是一个“限制”吗？ IPW 方法，还是表明我的代码存在潜在问题？
提前谢谢您！
这是我的代码：
# 未调整的总体生存率 K-M
surv_values &lt;- adaptedsurv(data=df,
variable=&quot;Treatment_type_tumor_near_gallbladder&quot;,
ev_time=&quot;OS_from_target_local_treatment&quot;,
event=&quot;death_mine&quot;,
times=seq(0, 120, by=12),
method=&quot;km&quot;,
conf_int=TRUE,
bootstrap=TRUE,
n_boot=500,
n_cores=10)

# 将列“surv”、“se”、“ci_lower”四舍五入到小数点后第二位， &#39;ci_upper&#39;
surv_values$boot_adj %&gt;%
mutate(across(c(surv, se, ci_lower, ci_upper), ~ round(.x, 2)))

未调整的 OS 选项卡：

# 调整后的总生存率 K-M
adj_values &lt;- adaptedsurv(data=df,
variable=&quot;Treatment_type_tumor_near_gallbladder&quot;,
ev_time=&quot;OS_from_target_local_treatment&quot;,
event=&quot;death_mine&quot;,
times= seq(0, 120, by=12), 
method=&quot;iptw_km&quot;,
conf_int=TRUE,
bootstrap=TRUE,
# stabilize=TRUE,
n_boot=1000,
n_cores=10,
treatment_model=formula_OS,
weight_method=&quot;OptWeight&quot;) # OptWeight, ebal, cbps, energy

# 将列 &#39;surv&#39;、&#39;se&#39;、&#39;ci_lower&#39;、&#39;ci_upper&#39; 四舍五入到小数点后第二位
adj_values$boot_adj %&gt;%
mutate(across(c(surv, se, ci_lower, ci_upper), ~ round(.x, 2)))


调整后的 OS标签：
]]></description>
      <guid>https://stats.stackexchange.com/questions/660764/difference-in-time-limits-for-kaplan-meier-estimates-with-unadjusted-vs-ipw-adj</guid>
      <pubDate>Thu, 30 Jan 2025 16:15:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么必须估计线性回归模型中的参数值？</title>
      <link>https://stats.stackexchange.com/questions/660750/why-must-the-values-of-the-parameters-in-a-linear-regression-model-be-estimated</link>
      <description><![CDATA[我不明白为什么在线性回归模型中无法找到参数 α 和 β 的真实值。为什么它们总是需要估计？
我读到它与包含其他变量的误差项有关（$x_2,x_3 ...$），但我并不完全理解。]]></description>
      <guid>https://stats.stackexchange.com/questions/660750/why-must-the-values-of-the-parameters-in-a-linear-regression-model-be-estimated</guid>
      <pubDate>Thu, 30 Jan 2025 04:46:11 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证来选择岭回归参数 $k$：如果 $\mathbf x_i$ 和 $y_i$ 的平均值在测试/训练集上可能为非零怎么办？</title>
      <link>https://stats.stackexchange.com/questions/660749/use-cross-validation-to-select-ridge-regression-parameter-k-what-if-mean-of</link>
      <description><![CDATA[考虑一个回归模型$$ Y= X\beta+ u.\tag{$\star$} $$
$Y$是一个长度为$n$的列向量，包含$n$个观测值。
$X$是一个$n\times p$矩阵，每行对应一个观测值，每列对应一个特征。
$\beta$是回归系数。
$u$是一个长度为$n$的列向量，包含误差。
对于参数为 $k&gt;0$ 的岭回归，$\beta$ 的估计值为 $$\hat\beta= (X^TX +kI)^{-1}X^TY .$$
我知道正则化参数 $k$ 的选择可以通过交叉验证来选择，例如论文 变量选择与数据增强之间的关系以及预测方法。
我的问题是，假设我们使用十倍交叉验证，数据集的子集为 $S_1,\cdots, S_{10}$。
$(\star)$ 的右侧没有均值项 $\mu$ 的原因是数据 $X,Y$ 被标准化为具有零均值。
但是当应用交叉验证时（例如，使用 $S_{10}$ 进行测试，使用其他数据进行训练），
则 $\cup_{i=1}^9 S_i$ 中的 $\mathbf x_i$ 和 $y_i$ 的均值可能不为零。
$S_{10}$ 中的 $\mathbf x_i$ 和 $y_i$ 的平均值也可能为非零。
那么我们如何才能继续使用公式 $$\hat\beta= (X^TX +kI)^{-1}X^TY$$ 来计算 $\cup_{i=1}^9 S_i$ 上的 $\hat\beta$，以及使用 $$ \sum\nolimits_{(\mathbf x_i, y_i)\in S_{10}} \|y_i- \langle \hat\beta, \mathbf x_i \rangle\|^2 $$
作为测试集 $S_{10}$ 上的误差？
我认为均值项 $\mu$ 也应该考虑。]]></description>
      <guid>https://stats.stackexchange.com/questions/660749/use-cross-validation-to-select-ridge-regression-parameter-k-what-if-mean-of</guid>
      <pubDate>Thu, 30 Jan 2025 04:05:46 GMT</pubDate>
    </item>
    <item>
      <title>这是生态谬误吗？</title>
      <link>https://stats.stackexchange.com/questions/660748/is-this-the-ecological-fallacy</link>
      <description><![CDATA[
使用历史数据，我有一个模型，它根据一些个人特征/协变量告诉我单个单位在某个 $t$ 后存活的概率：

$$\hat{S}_j(t) = [\hat{S}_0(t)]^{\exp(x_j^{new^T}\hat{\beta})}$$

现在，$n$ 个新单位进来，我只有它们的预测因子（与之前相同的预测因子），即它们都还活着。
一般来说，每天要花费 $j$ 美元来维持这些 $n$ 个单位活着。
一旦单位不再活着，就不会产生任何相关成本。此外，单位死亡也不会产生任何相关成本。

我想估算一下这些 $n$ 单位明年会花多少钱。我正在尝试推导成本函数
使用预期值，我为每个新单元和所有新单元定义了一个预期成本函数（如果需要，我可以展示我的工作）：
$$E[\text{Cost}_i] = j\int_0^T tf_i(t)dt + jTS_i(T)$$
$$E[\text{Total Cost}] = \sum_{i=1}^n \left(j\int_0^T tf_i(t)dt + jTS_i(T)\right)$$
我不禁想到，我正在陷入类似生态谬误，使用旧模型来估计新数据的成本。这是因为我实际上是在为每个单独的单元恢复单独的生存函数，这可能会导致非常不稳定的预测。
例如，我认为如果我的历史模型非常简单（例如，仅包含 A 类与 B 类的预测变量），那么我可以使用这个旧模型来预测新数据中所有 A 类和所有 B 类的预期成本（即所有 A 类单元的单一生存曲线和所有 B 类单元的单一生存曲线……然后通过将它们相加来估算成本）。旧模型将有足够的 A 类与 B 类的成本和时间数据，因此可以更好地推断新数据。然而，这样做虽然不太细致，但可能更可靠（更安全的方法是拟合一个没有任何协变量的模型）。
但如果我开始在历史模型中包含更多变量，我感觉我会开始将自己局限在某个领域，历史模型将变得更适合仅提供对历史数据的推断，而不太适合新数据。
这个想法正确吗？我是否陷入了生态谬误，或者我的做法是否正确？
我个人的观点是，我需要进行一些探索性数据分析，看看旧数据与新数据的相似程度，然后决定历史模型是否适合新数据……但这不是一种明确的做法，我也不确定如何客观地做到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/660748/is-this-the-ecological-fallacy</guid>
      <pubDate>Thu, 30 Jan 2025 03:44:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么一个预测区间比另一个大？</title>
      <link>https://stats.stackexchange.com/questions/660694/why-is-one-prediction-interval-bigger-than-the-other</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660694/why-is-one-prediction-interval-bigger-than-the-other</guid>
      <pubDate>Wed, 29 Jan 2025 03:12:53 GMT</pubDate>
    </item>
    </channel>
</rss>