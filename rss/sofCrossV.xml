<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 30 May 2024 09:16:25 GMT</lastBuildDate>
    <item>
      <title>如何使用 R 计算具有 2 个独立变量、1 个中介变量和 2 个结果变量的中介模型？</title>
      <link>https://stats.stackexchange.com/questions/648273/how-do-i-calculate-a-mediation-model-with-2-independent-variables-1-mediator-an</link>
      <description><![CDATA[有人认为两个独立变量都可能影响中介变量，而中介变量又会对两个结果变量产生影响（预计也会有直接影响）。
所有变量都采用李克特量表的区间尺度。样本量为 180。
如何在 R 中计算？我是 R 新手，不知道 R 是否以及如何做到这一点。
我更愿意在一个模型中计算所有内容，而不是计算 4 个不同的中介模型。这可能吗？两个独立变量都有些关联（一个是工作中的积极体验，一个是消极体验，但仍然不属于同一构造），并且两个因变量彼此之间没有关联。
这是一项横断面研究。（这就是我对相关性感兴趣的原因，因为我不能谈论因果关系）。
非常感谢任何帮助，非常感谢！
模型图片在这里：

https://drive.google.com/file/d/1njL4gXpnvkcQfcti1NsW4TpSZpCAoiYf/view?usp=sharing]]></description>
      <guid>https://stats.stackexchange.com/questions/648273/how-do-i-calculate-a-mediation-model-with-2-independent-variables-1-mediator-an</guid>
      <pubDate>Thu, 30 May 2024 09:14:30 GMT</pubDate>
    </item>
    <item>
      <title>两种算法的配对 t 检验</title>
      <link>https://stats.stackexchange.com/questions/648269/paired-t-test-of-two-algorithms</link>
      <description><![CDATA[我想比较两种算法的速度。但是我在解释结果时遇到了麻烦。我的方法正确吗？
零假设：算法速度相同
备选假设：算法 Y 更快。
我的数据：
algorithm_x = np.array(
[1014, 1007, 998, 1040, 999, 1030, 980, 1010, 940, 1030, 1000, 990, 1000, 995, 1020, 990, 1040, 1020, 1015, 940])
algorithm_y = np.array(
[980, 995, 960, 1050, 970, 1010, 1005, 1020, 950, 1000, 1025, 970, 965, 980, 1015, 985, 1010, 995, 990, 955])

使用 scipy，我计算了 p 值：
pvalue = scipy.stats.ttest_rel(algorithm_x, algorithm_y, alternative=&quot;greater&quot;).pvalue

我得到了结果：$pvalue = 0.011638$
我当时的想法是：
因为 pvalue 小于我们的置信区间 95% (0.05)，所以我们拒绝原假设，因此备择假设为真。所以算法Y确实比算法X快。
我的想法正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648269/paired-t-test-of-two-algorithms</guid>
      <pubDate>Thu, 30 May 2024 08:16:25 GMT</pubDate>
    </item>
    <item>
      <title>OLS 变量重要性系数</title>
      <link>https://stats.stackexchange.com/questions/648268/ols-coeff-importance-of-variables</link>
      <description><![CDATA[我正在使用 OLS 模型来确定独立因素对受抚养者的重要性。
所有变量都经过缩放。
我目前使用的系数如下：
独立 1 系数 = 0.04
独立 2 系数 = 0.06
独立 3 系数 = 0.08
1 的重要性：
= 0.04 / sum(0.04, 0.06 , 0.08) = 0.22
因此，我说独立变量 1“解释”了模型的 22%。
但是，如果系数为负：
例如
独立 1 系数 = 0.04
独立 2 系数 = - 0.06
独立 3 系数 = 0.08
采取是否有效这个系数的绝对值（否则最终计算结果将超过 100%）考虑到我对变量的变动不感兴趣，只关心它们对模型的“解释”程度如何？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/648268/ols-coeff-importance-of-variables</guid>
      <pubDate>Thu, 30 May 2024 08:06:41 GMT</pubDate>
    </item>
    <item>
      <title>（非）线性系数组合的似然比和得分检验</title>
      <link>https://stats.stackexchange.com/questions/648266/likelihood-ratio-and-score-tests-of-a-nonlinear-combination-of-coefficients</link>
      <description><![CDATA[似然比和分数检验通常用于简单的标量假设，例如$\beta_1 = 0$或$\beta_1 = \beta_2 = 0$。如何使用似然比和分数检验来检验系数的线性组合，例如$H_0: \beta_1 + 2 \beta_2 - 7 \beta_3 = 0$？更一般地说，是否可以使用似然比和分数检验来检验系数的非线性组合，例如$H_0: \beta_1 + 2 \exp(\beta_2) = 0$？如何在 R 中实现它们？
这些涉及线性和非线性假设的假设是由对交互项、预测值和效果比较的评估所激发的。它们通常使用 Wald 检验进行测试，非线性假设使用 delta 方法在非线性变换后计算标准误差。然而，在广义线性模型中，似然比检验通常比 Wald 检验提供更准确的 p 值和置信区间。
例如，二元 Logit 回归的估计均值结构为 $\text{logit}(p) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3$。有哪些可行的方法可以检验 $H_0: \beta_1 + 2 \beta_2 - 7 \beta_3 = 0$ 和 $H_0: \beta_1 + 2 \exp(\beta_2) = 0$？样本数据和模型：
data(&quot;mtcars&quot;)
View(mtcars)
summary(Model &lt;- glm(
am ~ mpg + disp + hp, 
family = binomial(), data = mtcars))
&quot; 估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -33.81283 24.17533 -1.399 0.1619 
mpg 1.28498 0.89895 1.429 0.1529 
disp -0.06545 0.04305 -1.520 0.1284 
hp 0.14936 0.07871 1.898 0.0577 .
零偏差：31 个自由度上的 43.230
残差偏差：28 个自由度上的 10.148
AIC：18.148&quot;
]]></description>
      <guid>https://stats.stackexchange.com/questions/648266/likelihood-ratio-and-score-tests-of-a-nonlinear-combination-of-coefficients</guid>
      <pubDate>Thu, 30 May 2024 07:42:58 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中执行（流行病学）等时替代分析？</title>
      <link>https://stats.stackexchange.com/questions/648264/how-to-perform-an-epidemiologic-isotemporal-substitution-analysis-in-r</link>
      <description><![CDATA[有人可以链接有关如何实现这一目标的资料视频吗？尤其是关于流行病学研究，例如用“轻度体力活动”代替“久坐时间”？
我有这些变量：

我想问以下研究问题：“哪种形式的体力活动（LPA vs MVPA）替代久坐时间对幸福感和睡眠变量（睡眠效率和 WASO）最有益”
作为因变量，我会使用：幸福感、睡眠效率和 WASO
作为行为替代：久坐时间
作为协变量：性别、教育和婚姻状况
最后，我假设 LPA 会更有利因为 MVPA 会对睡眠变量产生负面影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/648264/how-to-perform-an-epidemiologic-isotemporal-substitution-analysis-in-r</guid>
      <pubDate>Thu, 30 May 2024 07:26:18 GMT</pubDate>
    </item>
    <item>
      <title>添加混杂因素“因子”与减去层内平均值</title>
      <link>https://stats.stackexchange.com/questions/648262/adding-a-confounder-factor-vs-subtracting-within-level-mean</link>
      <description><![CDATA[为了解释已知的混杂因素，可以在线性回归中添加一个额外的因子（描述混杂效应）。
例如，在 R 中，我们可以有：
model &lt;- lm(response ~ predictor + confounder, data = data)

这里，response 是一个 协变量（即连续值），而 predictor 和 confounder 是 因子。
我的理解是，使用上述 公式，估计的 response 将根据 confounder 级别内的样本的 均值 进行调整（如 Law 等人，见图 1）。
现在，我想知道上述建模方法与在拟合模型之前减去每个混杂因素级别内样本的响应的平均值之间的区别。我假设我们应该得到预测变量的系数。
这种方法的缺点是什么？
为了说明为什么这很重要：
我正在建模一个数据集，我知道其中存在混杂因素。但是，我也知道混杂因素的每个级别内的样本可能是异常值。因此，我倾向于通过样本的中位数而不是平均值来调整样本的响应（如上所述，这是在线性回归中完成的），然后从公式中删除混杂因素。
我想知道如果我采用这种方法是否会遗漏某些内容？]]></description>
      <guid>https://stats.stackexchange.com/questions/648262/adding-a-confounder-factor-vs-subtracting-within-level-mean</guid>
      <pubDate>Thu, 30 May 2024 07:17:02 GMT</pubDate>
    </item>
    <item>
      <title>使用治疗后变量进行倾向评分加权</title>
      <link>https://stats.stackexchange.com/questions/648259/propensity-score-weighting-with-post-treatment-variables</link>
      <description><![CDATA[在进行倾向评分加权 (PSW) 时，强调要平衡治疗前变量，因为平衡治疗后变量可能会引入偏差。
我想问一下您对我们没有治疗前变量的情况的看法。设置如下：

我们的目标不是估计治疗的因果效应。相反，我们的目标是尽量减少或降低不同治疗组和对照组之间的不平衡。
在我们的案例中，“治疗”发生在儿童时期，而我们的样本是成年人。因此，除了年龄之外，我们没有治疗前变量。
具体来说，我们计划使用 Greg Ridgeway 开发的广义增强模型 (GBM) 来估计多项治疗的倾向得分。

我们发现朴素无加权模型和 PSW 模型的估计值之间没有显著差异。
我想知道我们是否仍然可以将 PSW 与治疗后协变量一起使用，因为我们没有发现这里存在显著治疗后偏差的证据。此外，正如您可能猜到的那样，在我们的数据设置中，我们不能选择其他方法，例如 IV 或 DID。]]></description>
      <guid>https://stats.stackexchange.com/questions/648259/propensity-score-weighting-with-post-treatment-variables</guid>
      <pubDate>Thu, 30 May 2024 05:00:25 GMT</pubDate>
    </item>
    <item>
      <title>用于预测的反向变换对数对数模型</title>
      <link>https://stats.stackexchange.com/questions/648246/back-transforming-log-log-model-for-prediction</link>
      <description><![CDATA[我有一个对数对数模型，我想用它对 $Y$ 进行原始预测：
$\ln(Y) = B_0 + B_1\ln(X)$
我发现的所有关于反向变换预测的答案和文章都只涉及半对数模型：
要么是 $Y \sim B_0 + B_1 \ln(X)$，要么是 $\ln(Y) \sim B_0 + B_1X $
我看过 Duan 的 Smear，但这也适用于对数对数模型吗？
我希望从百分比转向实际的 $Y$ 预测。]]></description>
      <guid>https://stats.stackexchange.com/questions/648246/back-transforming-log-log-model-for-prediction</guid>
      <pubDate>Wed, 29 May 2024 21:07:01 GMT</pubDate>
    </item>
    <item>
      <title>如何从事后检验（多重比较）输出估计效应大小？</title>
      <link>https://stats.stackexchange.com/questions/648220/how-to-estimate-effect-sizes-from-posthoc-test-multiple-comparison-output</link>
      <description><![CDATA[在 MATLAB 中对不平衡数据集应用单因素方差分析，然后进行事后 (HSD) 分析，我针对每个样本均值比较获得了均值差异的估计值，并给出了 95% 的置信区间。生成的 HSD 表的顶部如下所示（最后一列除外，请参见下文）：



治疗 1
治疗 2
下限
差异
上限
P 值
&quot;效果大小&quot;




3
4
-7.331684264
-2.613425854
2.104832556
0.506628583
1.107792591


3
5
-7.401851955
-2.903169074 
1.595513807
0.354639196
1.290675138


3
6
-13.85293007
-8.895622981
-3.938315891
0.000144039
3.588893252



现在我想按照 Cohen&#39;s d 的精神，从这个输出计算标准化效应大小。该统计数据似乎很直观，即使有多种 替代方案（例如$\eta^2$），而且我不完全确定我会报告哪一个，大概是$d_s$。经过相当多的困惑之后，我偶然发现了一些关于在计算 d 时分母中 SD 项的正确选择的想法：

根据样本和标准公式计算出的值（例如 Lakens 2013 中的公式 1，实际上这可能是我所用到的错误公式），例如使用免费软件 MATLAB 实用程序 (computeCohen_d)
使用方差分析的均方误差的平方根作为差异 SD 的估计值，这篇文章中的答案似乎建议了这种方法
与 95% CI 相关的 SD； CI 括号应等于 4xSD

最后两种方法提供的值相似，这令人鼓舞，我倾向于继续使用最后一种方法，因为我的数据不平衡，每个比较的 SD 估计值应该反映这一点。
我仍然隐约感觉到我做错了，因为计算出的“效应大小”（显示在上一列）很大，即使相关的 p 值并不表明有显著的影响。因此，我要么没有正确解释正确计算的效应大小（因为大小不需要与 p 相关，不应解释为表示显著性），要么反之亦然（我使用错误的输入 SD 计算效应大小），或者两者兼而有之。如果我理解正确，效应大小与样本量一起影响分析的功效。因此，我正在计算的大“效应”可能表明我不需要大样本就能找到显著的影响。大致就是这样吗？
您能帮我弄清楚要使用哪个 SD，以及如何正确解释效果大小吗？
参考
Lakens，D.（2013 年）。计算和报告效果大小以促进累积科学：t 检验和方差分析的实用入门。心理学前沿，4(863)。doi:10.3389/fpsyg.2013.00863]]></description>
      <guid>https://stats.stackexchange.com/questions/648220/how-to-estimate-effect-sizes-from-posthoc-test-multiple-comparison-output</guid>
      <pubDate>Wed, 29 May 2024 15:53:37 GMT</pubDate>
    </item>
    <item>
      <title>使用已知相关矩阵的 glmmPQL（GBLUP 模型）</title>
      <link>https://stats.stackexchange.com/questions/648212/using-glmmpql-with-known-correlation-matrix-gblup-model</link>
      <description><![CDATA[我正在开展一个项目，尝试将 GBLUP（基因组最佳线性无偏预测）模型应用于遗传疾病数据。我的目标是根据某些解释变量（包括性别和与单核苷酸多态性 (SNP) 相关的随机效应）对个体患病的概率进行建模。
我的模型公式如下：
library(MASS)
glmmPQL(Y ~ sex, 
random = list(rs62 = ~1, rs63 = ~1),
family = binomial, 
data = data, 
correlation = pdMat(matrix(c(1,0.5,0.5,1), nrow=2, byrow=FALSE)))

在此公式中，$Y$ 表示二元响应变量，表示个体是否受疾病影响。我试图将这个概率建模为性别和与两个 SNP（rs62 和 rs63）相关的随机效应的函数。
我想对随机效应施加方差结构 $G$，其中 $G$ 是通常的 GBLUP 矩阵。具体来说，我希望随机效应 $Zu$ 遵循高斯分布，方差为 $G$。
以下方程定义了我的模型：
$$
\text{logit}(p) = X\beta + Zu + \epsilon,
$$
其中 $p$ 是个体患病的概率，$\beta$ 是与解释变量（此处为性别）相关的固定系数向量，$X$ 是固定效应的设计矩阵，$Z$ 是随机效应的设计矩阵，$u$ 是随机效应向量，$\epsilon$ 是误差项。
我有点搞不懂如何在 glmmPQL 公式中强加这个方差结构 $G$。如何在 R 中正确指定它？
如能得到任何帮助或说明，我将不胜感激。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648212/using-glmmpql-with-known-correlation-matrix-gblup-model</guid>
      <pubDate>Wed, 29 May 2024 13:49:03 GMT</pubDate>
    </item>
    <item>
      <title>如何在加权 Cox 模型中手动分配权重？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648184/how-can-you-manually-assign-weights-in-a-weighted-cox-model</link>
      <description><![CDATA[如何在加权 Cox 模型中手动输入权重？
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/648184/how-can-you-manually-assign-weights-in-a-weighted-cox-model</guid>
      <pubDate>Wed, 29 May 2024 06:01:16 GMT</pubDate>
    </item>
    <item>
      <title>调整分层变量</title>
      <link>https://stats.stackexchange.com/questions/648132/adjusting-for-stratification-variables</link>
      <description><![CDATA[在临床试验中，分层可用于确保协变量之间的治疗平衡。
根据指导文件（例如 EMA/CHMP/295050/2013），分层变量通常应作为协变量包含在主要分析中。
在模型中包含分层变量的理由是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648132/adjusting-for-stratification-variables</guid>
      <pubDate>Tue, 28 May 2024 09:06:18 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Python 预测斜率变化的增长时间序列？</title>
      <link>https://stats.stackexchange.com/questions/648054/how-to-predict-a-growing-time-series-with-changing-slopes-in-python</link>
      <description><![CDATA[我有一个单变量时间序列数据集，它表示一个持续增长的趋势，但斜率以不同的间隔变化。我想预测这个时间序列的未来值。
以下是一些关键细节：
该系列一直在增加。
斜率在各个点发生变化。
数据只有一个变量。
我正在寻找合适的模型或方法来准确预测未来值。
我需要执行超出测试集的预测，这意味着使用预测迭代地预测未来的未来。
到目前为止，我已经考虑了线性回归，但它不能很好地处理变化的斜率。我也研究过 ARIMA，但我不知道如何针对这种情况进行配置。
有人可以推荐 Python 中合适的模型或技术来处理这种类型的时间序列吗？如果能提供示例或教程参考，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/648054/how-to-predict-a-growing-time-series-with-changing-slopes-in-python</guid>
      <pubDate>Mon, 27 May 2024 07:56:10 GMT</pubDate>
    </item>
    <item>
      <title>工具变量是否要求工具和处理之间独立？</title>
      <link>https://stats.stackexchange.com/questions/647993/does-an-instrumental-variable-require-independence-between-the-instrument-and-tr</link>
      <description><![CDATA[如果以下条件成立，则工具变量 Z 是 T（治疗）的合法工具：

Z 对 Y 具有完全由 T 介导的因果效应（即 Z 对 Y 没有直接影响，因果关系流必须至少通过 T）
Z 没有到 Y 的后门路径。
单调性（工具中的值越高，治疗被采用的值也就越高）
第一阶段确实存在（Z 和 T 之间存在非零相关性）。

但是，如果我们有以下 DAG，会发生什么？

C 是治疗和工具之间的混杂变量。UC 是一组未观察到的混杂因素。Z 是否仍然是 T 的合法工具？我以为答案是否定的，但根据 https://dagitty.net/dags.html#
...C 和 Z 都是 T 的合法工具。我可以看到 C 是合法的工具，因为所有因果路径都通过 T（直接或由 Z 介导）。但是，如果不先对 C 进行调节，Z 怎么可能仍然是 T 的工具呢？我可以通过 C 跳到 T。大多数来源似乎表明 T 和 Z 必须是 d 分离的，但我只是想验证这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/647993/does-an-instrumental-variable-require-independence-between-the-instrument-and-tr</guid>
      <pubDate>Sun, 26 May 2024 00:19:40 GMT</pubDate>
    </item>
    <item>
      <title>详尽测试所有可能的特征组合以找到最佳组合是否有效？</title>
      <link>https://stats.stackexchange.com/questions/647517/is-it-valid-to-exhaustively-test-all-possible-combinations-of-features-to-find-t</link>
      <description><![CDATA[我有大约 1000 个带标签的观察结果，这些观察结果来自大约 50 名受试者，他们在不同的情境下做出生理反应，我正在尝试对情境进行分类（通常分为频率大致相等的三个类别，但有时分为四个或五个类别）。对于每个观察结果，我生成大约 2000 个特征，需要选择最佳的特征子集进行分类。使用 mRMR（最小冗余最大相关性），我可以将特征减少到大约 25-100 个特征，然后 mRMR 得分会降得很低（取决于我包括哪些类别）。
我取其中的前 20 个（以保持数字的可行性），并使用留一交叉验证测试最多 8 个特征的所有可能组合，得到大约 264,000 个组合。然后，我选择准确率最高的组合。对于 LDA，这只需要我的笔记本电脑 6 个小时，但我也在测试需要更长时间的其他分类器。
我的问题是，这是否是一种有效的方法，或者我是否引入了偏差、过度拟合等，如果是，如何弥补。我读到最好在每个折叠内进行特征选择，但我甚至不确定如何做到这一点，尤其是在遗漏一个主题的情况下。
我发现单独使用 mRMR 并不合适：如果我只使用 mRMR 的前 8 个特征，我得到的准确度会比找到最佳组合要低得多。在一个极端情况下，使用高斯 SVM 仅比较两个类，差异是 99% 的准确率和 50% 的准确率，但通常准确率差异约为 10-20%。）
我有两个目标：1）选择最佳特征来在所有数据上训练模型，并用它来对新观察进行分类，2）估计此类模型对未来观察的准确率。
有没有办法可以考虑对准确率的影响，如果我愿意分配这么多的计算量，有没有更好的方法来选择特征？
当我问的时候，使用 PCA 创建 5-10 个组件而不是直接使用特征是否更有意义？
任何建议都值得赞赏！非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/647517/is-it-valid-to-exhaustively-test-all-possible-combinations-of-features-to-find-t</guid>
      <pubDate>Sat, 18 May 2024 18:21:32 GMT</pubDate>
    </item>
    </channel>
</rss>