<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 06 Jan 2025 21:15:34 GMT</lastBuildDate>
    <item>
      <title>调查数据分析的引导方法</title>
      <link>https://stats.stackexchange.com/questions/659627/approach-to-bootstrapping-for-survey-data-analysis</link>
      <description><![CDATA[我进行了一项调查，收集了 $n$ 位受访者的 $k$ 个李克特量表回答。我的分析包括对每位受访者的回答取平均值，并将平均回答向量与表示特定成熟度级别的 $k \times 1$ 大小的基线向量进行比较。我使用了许多 $k$ 样本测试来进行比较，并希望将引导技术应用于我的分析。我的问题如下：

据我所知，我需要进行引导假设检验，并需要抽取 $B$ 个大小为 $2k$ 的样本，并基于样本是总体的真正代表性样本这一信念进行替换。但是，我认为抽取平均值样本似乎没有意义。相反，我应该从整个响应数据集中抽取 $B$ 个样本（即 $k \times n$ 个样本），获取平均响应向量，与基线向量进行 $B$ 次比较，然后计算达到的显著性水平吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/659627/approach-to-bootstrapping-for-survey-data-analysis</guid>
      <pubDate>Mon, 06 Jan 2025 20:55:23 GMT</pubDate>
    </item>
    <item>
      <title>随机匹配概率的主成分分析</title>
      <link>https://stats.stackexchange.com/questions/659626/principal-component-analysis-for-random-match-probabilities</link>
      <description><![CDATA[好的，情况如下。我们有一堆数据，比如说 x1,...,x300，这些数据是我们为一堆样本 y1,...,y1000 收集的。数据 x1,...,x300 是依赖的（x1 的值与 x2-&gt;x300 的值相关，等等）。
作者 A（我试图优雅地证明他犯了一个错误）使用 PCA 来创建新变量。PC1,...,PC300 并指出这些主成分现在是独立的。因此，他们说，我们可以通过将各个主成分生成的概率相乘来计算联合概率（随机匹配概率）。
作者 A 的错误在于他们只表明变量 x1,...,x300 都是正态分布的，但没有表明 P(x1,...,x300) 的 PDF 是多元正态分布的。我的理解是，联合分布必须是多元正态分布，以确保主成分的独立性，而不是每个单独的变量都必须是正态分布（差别很大）。
所以这很好（我想，如果我错了请告诉我）……但我感到困惑的是……假设 P(x1,...,x300) 是多元正态分布。从高度依赖的数据中获取主成分并通过乘以（现在神奇地独立的）值来计算随机匹配概率的想法似乎是错误的……但我无法清楚地说明为什么会这样（或者也许我错了，那完全没问题）。
欢迎任何评论、指导或争论！
谢谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/659626/principal-component-analysis-for-random-match-probabilities</guid>
      <pubDate>Mon, 06 Jan 2025 20:53:28 GMT</pubDate>
    </item>
    <item>
      <title>解释优化 MSE 的模型中的模块权重和激活函数</title>
      <link>https://stats.stackexchange.com/questions/659615/interpreting-module-weights-and-activation-functions-in-a-model-optimizing-mse</link>
      <description><![CDATA[我正在使用一个由三个模块组成的模型：{A、B、C}。每个模块在预测股票价格方面都发挥着作用，模型的学习目标是最小化均方误差 (MSE)。
这些模块具有以下特点：
模块 A：具有较大的正权重。模块 B：具有较小的负权重。模块 C：具有接近于零的权重（例如，绝对值在 0.01 左右）。
权重是从检查点文件分析的，该文件是根据在验证集上评估的最佳性能参数保存的。
我试图了解这些权重如何影响模型以及某些设计决策背后的原理。以下是我的具体问题：
了解 A 和 B 的互补作用：
在训练期间，模块 A 的权重会以幅度（正方向）增加，这会降低 MSE。另一方面，模块 B 的权重变得更负，也会降低 MSE。我发现很难解释为什么一个模块用较大的正权重学习，而另一个模块用较小的负权重学习。我如何理解它们的互补作用，特别是在股票价格预测这样的任务中？
ReLU 的历史用途：
虽然 ReLU 现在不那么常用，但它在过去被广泛使用。采用 ReLU 是否是为了故意忽略负面贡献，例如来自模块 B 的贡献？如果是这样，这是否意味着在某些任务或情况下负权重被认为意义较小？或者，主要动机是为了避免梯度消失或简化计算？
转向 GELU：
像 GELU 这样的现代激活函数允许使用负权重。这是否意味着负面贡献现在被认为更有意义，而 GELU 有助于在模型中保留它们的影响力？
删除权重接近于零的模块：
如果模块 C 的权重非常小（例如 0.01 或 -0.01），这是否应该是将其从模型中删除的信号？这是否表明模块 C 对模型没有做出有意义的贡献，特别是如果消融研究表明删除后没有性能差异？
我特别有兴趣在有效集优化检查点分析的背景下理解上述观点。
摘要：
我使用在验证集上优化的已保存检查点分析了模型权重。我希望了解为什么模块 A 以较大的正权重学习，而模块 B 以较小的负权重学习，两者都降低了 MSE。我还希望确定权重接近于零的模块 C 是否做出了有意义的贡献并应该保留。然而，我很难解释 A 和 B 的互补作用以及模块 C 接近零的权重与模型性能的相关性。]]></description>
      <guid>https://stats.stackexchange.com/questions/659615/interpreting-module-weights-and-activation-functions-in-a-model-optimizing-mse</guid>
      <pubDate>Mon, 06 Jan 2025 13:50:46 GMT</pubDate>
    </item>
    <item>
      <title>探索性因子分析，非正态数据</title>
      <link>https://stats.stackexchange.com/questions/659613/exploratory-factor-analysis-non-normal-data</link>
      <description><![CDATA[我正在分析的数据对于几乎每个观察到的变量都是非正态的。我想在 R 中进行探索性因子分析 (EFA)。KMO 检验和 Bartlett 检验表明数据符合 EFA 条件。在 psych 包的文档中，我没有找到应如何处理非正态分布的数据 (https://personality-project.org/r/psych/HowTo/factor.pdf)。我的样本相对较小 (N=60)。
在进行验证性因子分析时，我可以使用 lavaan 包中的 Satorra-Bentler 校正来处理非正态数据，cfa() 函数，例如cfa(model = spec, data = df_data, std.lv=TRUE, estimator = &quot;MLM&quot;) ，这种使用稳健标准误差的校正是一种可接受的方法。 estimator=&quot;MLM&quot; 代表 Satorra-Bentler 校正。我可以用 psych 包 以某种方式做到这一点吗？
psych 包执行 EFA，fa() 函数，例如fa(data, nfactors = 4, rotate = &quot;oblimin&quot;) 并提供可行的因子，但如果我没有弄错的话，它被设计用于正态分布的数据。
如果我尝试使用 lavaan 包 中的 efa() 和 Satorra-Bentler 校正，它会发出 警告，表示协方差矩阵包含较小的负值，这可能表明模型未被识别：
efa(data = df_data, nfactors=4, rotation=&quot;oblimin&quot;, std.lv=TRUE, estimator = &quot;MLM&quot;)

警告消息：
1：lavaan-&gt;lav_model_vcov()： 
估计参数 (vcov) 的方差-协方差矩阵似乎不是
正定！最小特征值 (= -5.425180e-15) 小于零。这可能是模型无法识别的症状。
2：lavaan-&gt;lav_model_vcov()：
估计参数 (vcov) 的方差-协方差矩阵似乎不是 
正定的！最小特征值 (= -2.190854e-32) 小于零。这可能是模型无法识别的症状。


所以问题是：如何使用非正态数据计算 EFA，可能使用 psych 包？]]></description>
      <guid>https://stats.stackexchange.com/questions/659613/exploratory-factor-analysis-non-normal-data</guid>
      <pubDate>Mon, 06 Jan 2025 12:41:19 GMT</pubDate>
    </item>
    <item>
      <title>auto_arima() 可以在行为不良的时间序列中使用吗？</title>
      <link>https://stats.stackexchange.com/questions/659612/can-auto-arima-be-used-in-badly-behaved-time-series</link>
      <description><![CDATA[也许我无法正确配置它，但是当将 Python 模块 pmdarima 的 auto_arima() 函数应用于表现不佳的时间序列（例如来自加密货币的 OHLC 数据的时间序列）时，我遇到了非常糟糕的体验。
您能否为我提供使用它的指南？由于 pmd_arima 大量借鉴了 Hyndman 在 R 中的 forecast 代码，我阅读了它的 vignette，似乎整个算法最适合 (p, d, q) 分量的低值。]]></description>
      <guid>https://stats.stackexchange.com/questions/659612/can-auto-arima-be-used-in-badly-behaved-time-series</guid>
      <pubDate>Mon, 06 Jan 2025 12:11:24 GMT</pubDate>
    </item>
    <item>
      <title>加权可能性间接模拟可靠性？</title>
      <link>https://stats.stackexchange.com/questions/659550/weighted-likelihood-to-indirectly-model-reliability</link>
      <description><![CDATA[对于纵向回归问题，我可能认为，与信息较少的受试者相比，我观察到的具有更多观察结果的受试者的数据更可靠（情况可能并非总是如此，但假设如此）。这里，可以使用回归权重，以便在模型中考虑到这种感知可靠性吗？

这是针对$i^{th}$主题的基本纵向/随机效应模型：
$$y_{ij} = X_{ij}\beta + u_i + \epsilon_{ij}$$
$$u_i \sim N(0, \sigma^2_u)$$
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon)$$
我看到这种权重格式经常用于最小二乘回归（$n_i$ 是受试者 $i$ 的测量次数，$N$ 是受试者总数):
$$w_i = \frac{n_i}{\sum_{k=1}^N n_k}$$
最后，修改似然函数以包含权重（我不确定哪个更好 - 单个受试者级别权重或单个观察级别权重）：
$$L(\beta, \sigma^2_u, \sigma^2_\epsilon) = \prod_{i=1}^N f(y_i|\beta, \sigma^2_u, \sigma^2_\epsilon)^{w_i}$$
$$L(\beta, \sigma^2_u, \sigma^2_\epsilon) = \prod_{i=1}^N \prod_{j=1}^{n_i} f(y_{ij}|\beta, \sigma^2_u, \sigma^2_\epsilon)^{w_i}$$
从这个来看，似乎即使有了这些权重，这些权重似乎也不会影响方差。使用多层次建模/随机效应中采用的一般方法，也许可以将方差修改为（$I$ 是一个单位矩阵，而$J$ 是一个 1 的矩阵 - 这意味着单个受试者的方差取决于所有受试者的未加权方差加上基于该受试者测量次数的单个受试者的加权方差）。这样做，我们实际上在个体层面上将随机效应引入模型：
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon / n_i)$$
$$Var(y_i) = \sigma^2_u J_{n_i} + (\sigma^2_\epsilon/n_i) I_{n_i}$$
$$Y_i \sim MVN(X_i\beta, V_i)$$
这现在使得可能性（更复杂 - 但最小二乘解可用于固定效应估计）：
$$f(y_i|\beta, \sigma^2_u, \sigma^2_\epsilon) = (2\pi)^{-n_i/2}|V_i|^{-1/2}\exp\left(-\frac{1}{2}(y_i - X_i\beta)^T V_i^{-1}(y_i - X_i\beta)\right)$$
$$\ell(\beta, \sigma^2_u, \sigma^2_\epsilon) = -\frac{1}{2}\sum_{i=1}^N \left[n_i\log(2\pi) + \log|V_i| + (y_i - X_i\beta)^T V_i^{-1}(y_i - X_i\beta)\right]$$
$$\hat{\beta} = \left(\sum_{i=1}^N X_i^T V_i^{-1} X_i\right)^{-1} \left(\sum_{i=1}^N X_i^T V_i^{-1} y_i\right)$$
我可以看到，在这个最终设置中，固定效应估计和方差都受到每个受试者可用的观察次数的影响。 （下一部分超出了我的理解范围，但我听说随机效应是使用 RMLE 估计的）

假设数学是正确的，在纵向研究中，基于每个受试者可用的测量次数的权重可以用来隐式地解释可靠性？
结束语：最后，看起来只需使用基本的多级建模方法就可以解决所有问题，并根据每个受试者的观察次数间接地考虑他们的贡献……]]></description>
      <guid>https://stats.stackexchange.com/questions/659550/weighted-likelihood-to-indirectly-model-reliability</guid>
      <pubDate>Sun, 05 Jan 2025 03:44:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么这么多问题是线性的以及如何解决非线性问题？</title>
      <link>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</link>
      <description><![CDATA[我这学期选修了一门深度学习 Python 课，我们正在学习线性代数。
上一节课，我们从头开始“发明”了梯度下降的线性回归（之前做过最小二乘法），我们讨论了定义假设、损失函数、成本函数等。
为什么许多问题可以看作是线性的，而“只是试图找到方程 Ax = b 的解”？
可以通过最小二乘法或训练神经网络等方法来实现这一点。
在现实世界中，大多数问题都不是线性的。
由于线性代数仅适用于线性函数，那么如何解决这些问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</guid>
      <pubDate>Sat, 04 Jan 2025 19:41:00 GMT</pubDate>
    </item>
    <item>
      <title>BAM mgcv 算法的可重复性</title>
      <link>https://stats.stackexchange.com/questions/659490/reproducibility-of-bam-mgcv-algorithm</link>
      <description><![CDATA[我经常处理大型空间数据集，其中 mgcv 中实现的 bam() 算法非常适合。对于我的分析来说，点估计的可重复性是一个关键问题，不幸的是，我经常看到 BAM 预测的结果取决于所用数据集中数据点的顺序。
最小可重复示例
以下内容基于由协变量 x、y 和目标变量 z 组成的 15.000 个数据点的数据集，可在此处下载：https://drive.google.com/file/d/16dZ66KmT4CrQHkVQtw7vRP065SoztUNg/view?usp=drive_link
另请注意，在执行每个代码示例之前下面，数据集已重新加载并使用相同的随机种子进行了混洗。
首先考虑使用 bam() 拟合的结果：
set.seed(1)

model1 &lt;- mgcv::bam(z ~ s(x, y, k = 100),
data = dataset,
family = Gamma(link = log),
method = &quot;REML&quot;)

dataset &lt;- dataset[sample(nrow(dataset)),]

model2 &lt;- mgcv::bam(z ~ s(x, y, k = 100),
data = dataset,
family = Gamma(link = log),
method = &quot;REML&quot;)

#calculate response on scale of linear predictor
dataset$pred_model1 &lt;- as.vector(predict.gam(model1, dataset))
dataset$pred_model2 &lt;- as.vector(predict.gam(model2, dataset))
plot(dataset$pred_model1, dataset$pred_model2)

这将生成以下图表：

现在考虑 gam() 的结果：
model1 &lt;- mgcv::gam(z ~ s(x, y, k = 100),
data = dataset,
family = Gamma(link = log),
method = &quot;REML&quot;)

数据集 &lt;- 数据集[sample(nrow(数据集)),]

模型2 &lt;- mgcv::gam(z ~ s(x, y, k = 100),
数据 = 数据集,
family = Gamma(link = log),
method = &quot;REML&quot;)

#计算线性预测器尺度上的响应
数据集$pred_model1 &lt;- as.vector(predict.gam(model1, dataset))
数据集$pred_model2 &lt;- as.vector(predict.gam(model2, dataset))

plot(数据集$pred_model1, dataset$pred_model2)


这将生成以下图表：

所以我的问题是：这种行为是预料之中的，还是我这边的一个错误？如果这只是使用 bam() 时必须忍受的事情，那么除了始终确保数据点的顺序相同之外，还能做些什么来确保可重复性？
我已经通过尝试 k=1000 个基函数来测试它是否与有限的空间分辨率有关。在这里我发现了同样的问题。然而，我确实看到将数据集大小减少到只有 1000 个数据点可以大大减少问题。然而，这不是理想的解决方案，因为我想使用所有数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/659490/reproducibility-of-bam-mgcv-algorithm</guid>
      <pubDate>Fri, 03 Jan 2025 13:43:22 GMT</pubDate>
    </item>
    <item>
      <title>理解两个孩子问题的直觉</title>
      <link>https://stats.stackexchange.com/questions/659395/understanding-intuition-of-the-two-child-problem</link>
      <description><![CDATA[受到此推特帖子的启发，发布了这个问题：

我有两个孩子，（至少）其中一个是男孩，出生在星期二

两个孩子都是男孩的概率是多少？


通过Joel Grus，这里是一个建议的答案：

总共 196 种可能性（每种（性别、天）的概率均等）27那些
至少一个星期二男孩（13 个较小的星期二男孩，较大的不是；13 个较大的
星期二男孩，较小的不是，1 个都）其中 13 个都是男孩（6，6，1）所以
13 / 27

这似乎是正确的。但同时也令人困惑。这让我们觉得我们可以任意地以我们知道是真实的任何事物为条件（例如，婴儿出生在银河系；或者婴儿的父母说英语），并以某种方式使用它来改变后验概率。有人能把我从这引起的存在主义困境中解救出来吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659395/understanding-intuition-of-the-two-child-problem</guid>
      <pubDate>Tue, 31 Dec 2024 09:34:01 GMT</pubDate>
    </item>
    <item>
      <title>可视化多种样品类型和杂质水平的 PCA 结果</title>
      <link>https://stats.stackexchange.com/questions/659145/visualizing-pca-results-with-multiple-sample-types-and-impurity-levels</link>
      <description><![CDATA[我正在对一个数据集执行主成分分析 (PCA)，该数据集包含四种材料 (a、b、c、d) 的样本，这些样本的杂质水平各不相同 (10%、20%、30% 和 40%)。此外，还有一个纯样本 (p)。
我打算使用 R 创建一个分数图，以根据这些样本的主要成分直观地显示这些样本的分离情况。我希望在图中有效地表示样本类型 (a、b、c、d、p) 和杂质水平 (10%、20%、30%、40%)。
我正在寻找有关如何在分数图中以最佳方式直观地编码此双重信息 (样本类型和杂质水平) 的建议。是否有既定的最佳实践或建议用于在 PCA 得分图中表示多个分类变量？
其他详细信息
• 数据有 17 列（a、b、c、d 及其级别以及纯样本）和 949 行。
任何见解或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659145/visualizing-pca-results-with-multiple-sample-types-and-impurity-levels</guid>
      <pubDate>Tue, 24 Dec 2024 09:54:49 GMT</pubDate>
    </item>
    <item>
      <title>GAM 留一交叉验证 (LOOCV)，适用于较大的模型</title>
      <link>https://stats.stackexchange.com/questions/659016/gam-leave-one-out-cross-validation-loocv-for-biggish-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659016/gam-leave-one-out-cross-validation-loocv-for-biggish-models</guid>
      <pubDate>Fri, 20 Dec 2024 14:44:07 GMT</pubDate>
    </item>
    <item>
      <title>需要有共同原因的因果调整公式</title>
      <link>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</link>
      <description><![CDATA[
在上述因果模型中，计算$P(X=x \mid \text{do}(Y=y))$时，是否需要使用因果调整公式$\sum_c P(X=x \mid Y=y, C=c) P(C=c)$？一旦我们$\text{do}(Y=y)$，$Y$的生成过程是否就独立于$X$的生成过程，因此$P(X=x \mid \text{do}(Y=y)) = P(X=x)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</guid>
      <pubDate>Mon, 16 Dec 2024 06:30:13 GMT</pubDate>
    </item>
    <item>
      <title>根据另一个统计模型创建非同质队列？</title>
      <link>https://stats.stackexchange.com/questions/657336/creating-a-non-homogenous-queue-based-on-another-statistical-model</link>
      <description><![CDATA[我有一个问题，关于如何根据变化的参数构建/近似统计队列。
我在 R 中创建/模拟了 MMK 队列的这个近似版本：
library(tidyverse)

k &lt;- 3 # 服务器数量
lambda &lt;- 2 # 到达率
mu &lt;- 1 # 每台服务器的服务率
T &lt;- 100 # 模拟时间
n_sims &lt;- 20 # 模拟次数
dt &lt;- 0.05 # 时间步长
initial_n &lt;- 100 # 初始队列长度

simulate_mmk &lt;- function(sim_number) {
n_steps &lt;- ceiling(T/dt)
queue_length &lt;- numeric(n_steps)
queue_length[1] &lt;- initial_n

到达 &lt;- rpois(n_steps, lambda * dt)
出发 &lt;- rpois(n_steps, k * mu * dt)

for(i in 2:n_steps) {
current_n &lt;- 队列长度[i-1]
到达 &lt;- 到达[i]
出发 &lt;- min(departures[i], current_n)
队列长度[i] &lt;- current_n + 到达 - 出发
}

data.frame(
time = seq(0, T-dt, length.out=n_steps),
队列长度 = 队列长度,
模拟 = 因子(sim_number)
)
}

set.seed(123)
sim_data &lt;- bind_rows(
lapply(1:n_sims, function(i) {
set.seed(123 + i)
模拟_mmk(i)
})
)


我有兴趣调整这个队列，以允许改变到达、离开和服务器的数量。
例如，在上面的模拟中，服务器的数量保持不变，到达和离开是从具有固定参数的概率分布中随机选择的。我想制作一些可以随时间变化的分布。
例如，假设到达、离开和服务器随时间变化（例如，分段，时间值变化的概率分布）。
我是否可以预先根据这些变化的分布生成到达、离开和服务器的向量（例如，将回归模型拟合到历史到达、离开和服务器数据），然后从这些模型中模拟随机数据以创建非同质队列？
run_sims &lt;- function(n_sims = 20, T = 100, dt = 0.05, initial_n = 100) {

n​​_steps &lt;- ceiling(T/dt)

set.seed(123)
attendances &lt;- abs(rnorm(n_steps, mean = 25, sd = 2))
service_rates &lt;- abs(rnorm(n_steps, 平均值 = 15, sd = 1))
服务器 &lt;- abs(rnorm(n_steps, 平均值 = 5, sd = 0.5))

sim_data &lt;- map_dfr(1:n_sims, function(i) {
set.seed(123 + i)

队列长度 &lt;- numeric(n_steps)
队列长度[1] &lt;- initial_n

for(i in 2:n_steps) {
current_n &lt;- 队列长度[i-1]
到达 &lt;- rpois(1, 到达[i] * dt)
出发 &lt;- min(rpois(1, 服务器[i] * 服务费率[i] * dt), current_n)
队列长度[i] &lt;- current_n + 到达 - 出发
}

data.frame(
时间= seq(0, T-dt, length.out=n_steps),
queue_length =queue_length,
simulation =factor(i)
)
})
return(sim_data)
}

sim_data &lt;-run_sims(
n_sims = 20,
T = 100,
dt = 0.05,
initial_n = 100
)



澄清：

首先，我将拟合 3 个不同的模型（例如GAM/时间序列）到历史到达、离开和服务器数据
然后，我将根据这 3 个模型在一段时间内预测未来值
然后，在这个范围的每个时间点 - 我将根据以这 3 个模型产生的每个预测值为中心的概率分布（例如指数、泊松）模拟到达、离开和服务器数量
重复
]]></description>
      <guid>https://stats.stackexchange.com/questions/657336/creating-a-non-homogenous-queue-based-on-another-statistical-model</guid>
      <pubDate>Fri, 15 Nov 2024 21:32:48 GMT</pubDate>
    </item>
    <item>
      <title>我们可以将一个随机正态变量大于其他 $N$ 个正态变量的概率写成累积密度函数的乘积吗？</title>
      <link>https://stats.stackexchange.com/questions/655163/can-we-write-the-probability-that-a-random-normal-variable-is-greater-than-other</link>
      <description><![CDATA[对于 $Y_1 \sim N(\mu_y;\sigma_y^2)$ 和 $X_i, ..., X_N$ 个分布为 $N(\mu_i, \sigma_i^2)$ 的随机变量，我们可以将 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})$ 写为 $\prod_{i=1}^{N}F(z_i)$ 吗？其中 $F(\cdot)$ 是标准正态分布的累积密度函数，并且 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})$ 写为 $\prod_{i=1}^{N}F(z_i)$，其中 $F(\cdot)$ 是标准正态分布的累积密度函数，并且 $z_i=\frac{\mu_y-\mu_i}{\sqrt{\sigma_y^2+\sigma_i^2}}$?
对于 $i=1$ 的情况，我知道很容易证明 $P(Y_i \geq X_1)=F(\frac{\mu_y-\mu_i}{\sqrt{\sigma_y^2+\sigma_1^2}})$，但我们能否推广到 $N$ 的情况 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})=\prod_{i=1}^{N}F(z_i)$?
如果 $\mu_y=\mu_i \forall i$，则为 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})=F(z_1)^N$。
我之所以产生疑问，是因为似乎只要 $Y$ 的均值与任何其他 $X_i$ 相同，$Y$ 方差的任何变化都不会影响 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})$。而直观上 $Y$ 需要较高的值才能击败所有其他分布。
（这不是作业，只是好奇心）]]></description>
      <guid>https://stats.stackexchange.com/questions/655163/can-we-write-the-probability-that-a-random-normal-variable-is-greater-than-other</guid>
      <pubDate>Tue, 01 Oct 2024 10:25:44 GMT</pubDate>
    </item>
    <item>
      <title>如何确定复杂过程的理论预测极限？</title>
      <link>https://stats.stackexchange.com/questions/648254/how-to-determine-the-theoretical-prediction-limit-for-a-complex-process</link>
      <description><![CDATA[我们如何找到复杂过程的理论预测极限？
例如，对于抛硬币（平均而言），预测极限是 50%，也就是说，实际上我们无法预测出比这个最大值更好的结果（除非我们能够获得“内部信息”，如初始条件等）。
对于一个复杂的过程，有没有什么工具可以用来确定理论预测最大值，超过这个最大值我们就无法预测了？
所以我对上述问题的措辞不是很满意（抱歉），但我确实问过 GPT4，答案可能有助于更好地理解这个问题：

确定复杂过程的理论预测极限是一项具有挑战性的任务，它涉及理解过程固有的不确定性和不可预测性。有几种来自不同领域的工具和概念，如信息论、混沌理论和统计力学，可以帮助评估这个极限。以下是一些关键方法和工具：

香农熵（信息论）...
柯尔莫哥洛夫复杂度（算法信息论）...
等等


我感兴趣的原因是从机器学习的角度来看的。首先，它可以帮助确定：

过度拟合（是的，我知道还有其他实用方法可以确定这一点，但在这个预测极限下，它可能更具挑战性）
数据泄漏（这些事情可能更难确定，特别是对于时间序列数据）
模型的最大理论性能，接近这个性能，您开始接近帕累托努力与回报原则。

因此，想象一下这样一个复杂的过程（为了论证）是对体育赛事或政治投票结果的预测。]]></description>
      <guid>https://stats.stackexchange.com/questions/648254/how-to-determine-the-theoretical-prediction-limit-for-a-complex-process</guid>
      <pubDate>Thu, 30 May 2024 01:47:50 GMT</pubDate>
    </item>
    </channel>
</rss>