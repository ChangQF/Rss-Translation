<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 08 Jan 2025 01:16:24 GMT</lastBuildDate>
    <item>
      <title>在汇总疾病分类的优势比时，测量工具是否需要同质性？</title>
      <link>https://stats.stackexchange.com/questions/659696/is-homogeneity-of-measurement-tools-necessary-when-pooling-odds-ratios-for-disea</link>
      <description><![CDATA[在荟萃分析中汇总估计值时，众所周知，保持研究之间的同质性至关重要，尤其是在处理连续数据时。在这种情况下，使用一致报告的工具和测量值进行有效汇总非常重要。但是，当使用不同的工具对疾病进行分类，但最终将其归类为疾病的存在或不存在，并且结果以比值比的形式进行统计呈现时，是否仍有必要保持所用工具的同质性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659696/is-homogeneity-of-measurement-tools-necessary-when-pooling-odds-ratios-for-disea</guid>
      <pubDate>Wed, 08 Jan 2025 01:12:47 GMT</pubDate>
    </item>
    <item>
      <title>逆倾向评分和几种结果</title>
      <link>https://stats.stackexchange.com/questions/659691/inverse-propensity-scores-and-several-outcomes</link>
      <description><![CDATA[假设我使用面板数据来估计某些干预措施对两种不同结果的平均治疗效果。由于存在明确定义的治疗组和对照组，因此使用 DID 方法是有意义的，但我希望施加条件平行趋势假设。为此，我使用一组时间不变的治疗前协变量来重新加权对照组，使其看起来更像治疗组。正式地，我估计双向固定效应回归（治疗不交错），概率权重（治疗组的权重为 1，而对照组使用估计的倾向得分）。
我的问题是：我正在处理两个不同的结果变量。我用于条件平行趋势假设的协变量在两者之间是否应该相同？一方面，结果变量的趋势可能仅在不同的组内相同。但另一方面，我只有一种干预措施，即使结果发生变化，使用不同的变量来模拟对同一治疗的选择似乎很奇怪。
有什么要点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659691/inverse-propensity-scores-and-several-outcomes</guid>
      <pubDate>Tue, 07 Jan 2025 22:46:24 GMT</pubDate>
    </item>
    <item>
      <title>与将 $n$ 个物品分配到 $m$ 个容器相关的概率</title>
      <link>https://stats.stackexchange.com/questions/659690/probabilities-related-to-distributing-n-items-into-m-containers</link>
      <description><![CDATA[一辆冰淇淋车停在公园里，随机地将 10 个冰淇淋分发给 20 个孩子。随机选择的孩子没有收到冰淇淋的概率是多少？只收到一个冰淇淋？还是收到两个或更多个冰淇淋？
我目前的方法是使用 20 个孩子找到 10 个冰淇淋的所有整数组合，其中（显然）允许使用零。因此，例如，其中一个整数组合可能是：
1+1+1+1+2+4+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0=20

在上述整数组合中，20 个孩子中有 14 个没有收到冰淇淋，20 个孩子中有 4 个收到了一个冰淇淋，20 个孩子中有 2 个收到了 2 个或更多个冰淇淋。我可以使用许多随机整数组合执行蒙特卡罗模拟来获得概率。
p(x=0) = 0.66
p(x=1) = 0.24
p(x=2) = 0.08
p(x=3) = 0.01
p(x=4) 至 p(x=10) = 小于 0.01
---
p(x&gt;=0 &amp; x &lt;= 10) = 1

这种模式似乎是一种离散概率分布。有人能指出分布的名称吗？出于某种原因，我很难看出一种常见分布（泊松分布、二项分布等）如何适合这个问题！]]></description>
      <guid>https://stats.stackexchange.com/questions/659690/probabilities-related-to-distributing-n-items-into-m-containers</guid>
      <pubDate>Tue, 07 Jan 2025 21:57:43 GMT</pubDate>
    </item>
    <item>
      <title>分子转化的逻辑回归建模</title>
      <link>https://stats.stackexchange.com/questions/659688/logistic-regression-modeling-of-molecule-conversion</link>
      <description><![CDATA[一个最近的问题涉及一种回归分析，其中一种化学物质用具有特定浓度的混合物处理，以查看转化为新物质的化学物质的比例。
回归分析使用浓度作为唯一特征，比例作为结果，而 OP 选择将比例强行塞入逻辑回归的结果变量中。
但是，假设我们知道分子的起始数量。然后，通过了解比例，我们就知道转化的分子数量。然后，我们可以使用更自然的逻辑回归，其中每个转化/非转化都是一个单独的结果，对应于浓度的特征值，例如$x = (0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.4, 0.4, 0.6, 0.6, 0.6, 0.6)$，$y = (0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1)$。
但是，每个浓度水平不会有四个分子。会有数不清的分子。从计算的角度来看，这让我很担心，但从统计上讲，这也感觉像是作弊。我们一开始有三个双变量观测值：$x = (0.2, 0.4, 0.6)$，$y = (0.25, 0.5, 0.75)$。我们最终得到了无数个观测值。
但是，如果我们在三个浓度水平上有不同数量的分子，我可以看到这会给反应更多的反应混合物更高的权重，例如如果我们对一升原始分子进行一次反应，对一毫升进行一次反应。我认为在高浓度物质有恶臭，并且其使用量有限，无法使用一升的大反应混合物的情况下，这是一种合理的实验做法。
如果这样做会增加样本量并降低标准误差，那么这样做是否是作弊？那么，每个浓度水平的分子数量可能不同吗？
（从化学物理学的角度来看，我担心这些转化不太可能是独立事件。答案可以但不必解决这个问题。）]]></description>
      <guid>https://stats.stackexchange.com/questions/659688/logistic-regression-modeling-of-molecule-conversion</guid>
      <pubDate>Tue, 07 Jan 2025 21:37:38 GMT</pubDate>
    </item>
    <item>
      <title>线性回归 - 响应变量为百分比改善或 m/s？</title>
      <link>https://stats.stackexchange.com/questions/659686/linear-regression-response-variabel-as-percent-improvement-or-m-s</link>
      <description><![CDATA[我正在尝试对包含 8 种不同跑步距离的数据集进行统计，这些距离在遵循训练方案之前和之后都有时间，并且基于距离对改进进行线性回归（所有完成时间都有所下降）。我不确定是否要转换为百分比改进或使用 m/s 之类的变量，然后减去跑步时间 1 和跑步时间 2，以便能够比较不同的距离组。显然，绝对时间差异并不大，因为更长的距离自然会有更大的改进。但我读到过，不建议将百分比改进转换为线性回归中的响应变量。我该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/659686/linear-regression-response-variabel-as-percent-improvement-or-m-s</guid>
      <pubDate>Tue, 07 Jan 2025 21:03:50 GMT</pubDate>
    </item>
    <item>
      <title>在 statsmodels 中 GLM 上使用哪些参数</title>
      <link>https://stats.stackexchange.com/questions/659683/what-params-to-use-on-glm-from-statsmodels</link>
      <description><![CDATA[我正在模拟试剂转化率对试剂 L 和 M 之间比率的依赖性。比率越高，试剂转化率越高，在 1.5 左右有一个明显的拐点。下面是我拥有的完整数据集

df = pd.DataFrame({&#39;L_M&#39;:[4.75, 3.8, 3.32, 2.85, 2.37, 1.9, 1.42, 0.95, 0.71, 0.47, 0.24, 0.09],
&#39;Conversion&#39;:[0.992, 0.987, 0.993, 1, 0.9, 0.7, 0.31, 0.1, 0.07, 0.06, 0.07, 0.065]})

为此，我使用二项式家族的 GLM 模型，以 Logit 作为链接函数（又称 Logistic 回归）。这似乎很合适，因为我正在对二项式过程中的成功率进行建模（试剂要么发生反应，要么不发生反应）。我尝试使用 statmodels.GLM 失败了，下面的代码产生了非常差的拟合效果：
# 定义因变量和自变量 
Xtrain = df[&#39;L_M&#39;] 
ytrain = df[&#39;Conversion&#39;]

# 构建模型并拟合数据 
log_reg = sm.GLM(ytrain, Xtrain, family=sm.families.Binomial()).fit()

# 推理 
df[&#39;Predicted&#39;] = log_reg.predict(Xtrain)


然而，我使用了一种 hack 的方法，为每个变量创建了 100 个原始数据实验点，每个原始 y 变量为 0 或 1，概率等于此实验点的转换，然后使用 sklearn 将 logreg 拟合到这个（膨胀很多的）数据集，效果很好，产生更好的拟合效果：
from sklearn.linear_model import LogisticRegression

# 实例化模型（使用默认参数）
logreg = LogisticRegression(random_state=16)

# 用数据拟合模型
logreg.fit(X_train, y_train)
new_X = pd.DataFrame(df[&#39;L_M&#39;])
new_X.columns = [&#39;ratio&#39;]
df[&#39;Predicted&#39;]= logreg.predict_proba(new_X)[::,1]



我在 statsmodels.GLM 中遗漏了哪些参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/659683/what-params-to-use-on-glm-from-statsmodels</guid>
      <pubDate>Tue, 07 Jan 2025 20:27:59 GMT</pubDate>
    </item>
    <item>
      <title>以序数数据作为中介变量，检验数值数据对数值数据的影响：conver</title>
      <link>https://stats.stackexchange.com/questions/659681/testing-the-effect-of-numerical-data-on-numerical-data-with-ordinal-data-as-a-me</link>
      <description><![CDATA[我必须运行一个测试，测试数值数据（ESG 评级；范围 0-300）对数值数据（Tobin&#39;s Q（衡量公司财务业绩的指标：范围 0+））的影响。我添加了信用评级（具有 13 个范围类别的序数）。我应该运行什么测试？
上述数据是非正态的。
到目前为止，我已经看到了两种方法：

将序数数据转换为数值数据（因此为 1-13）并运行回归测试。
为序数数据创建虚拟变量并测试它们对因变量的影响。

此外，建议使用引导程序运行测试。
您认为最好的分析方法是什么？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659681/testing-the-effect-of-numerical-data-on-numerical-data-with-ordinal-data-as-a-me</guid>
      <pubDate>Tue, 07 Jan 2025 20:06:49 GMT</pubDate>
    </item>
    <item>
      <title>mgcv::gam 不能正确地从平滑中分解线性分量</title>
      <link>https://stats.stackexchange.com/questions/659680/mgcvgam-does-not-correctly-decompose-the-linear-component-from-the-smooth</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659680/mgcvgam-does-not-correctly-decompose-the-linear-component-from-the-smooth</guid>
      <pubDate>Tue, 07 Jan 2025 18:52:03 GMT</pubDate>
    </item>
    <item>
      <title>我应该将点大小（面积）比例缩放为 1/标准误差还是 1/SE^2？</title>
      <link>https://stats.stackexchange.com/questions/659678/should-i-scale-point-size-area-proportion-to-1-standard-error-or-1-se2</link>
      <description><![CDATA[我有一堆估计值，我想将它们绘制在 y 轴上，而 x 轴上则绘制其他值。我想传达每个点的不确定性（x 轴值已知，y 轴值是估计值）。误差线会使图变得非常混乱，所以我想使用点的大小来传达我们对每个点的确定程度。据我所知，建议人们将面积（而不是直径）视为信息量（例如，参见本文或此链接 - 不确定这些是否是标准参考文献）。
但是，有没有研究信息度量应该是 1/SE（标准误差的倒数）还是 1/SE^2（抽样方差的倒数）。鉴于对于误差线，我们将使用 +-SE 或置信区间（95% 的置信区间大约为 +- 1.96*SE），我猜是 1/SE？不知何故，我找不到是否有人尝试过实证检验这是否有效（例如，当人们被问到问题时，他们会根据所选的可视化效果做出适当的回答，即当给定基于 1/SE 或 1/SE^2 或其他东西的点大小时，他们是否会做得更好）。
鉴于我们倾向于绘图]]></description>
      <guid>https://stats.stackexchange.com/questions/659678/should-i-scale-point-size-area-proportion-to-1-standard-error-or-1-se2</guid>
      <pubDate>Tue, 07 Jan 2025 17:47:22 GMT</pubDate>
    </item>
    <item>
      <title>使用 IRT 进行非监考评估</title>
      <link>https://stats.stackexchange.com/questions/659676/using-irt-for-a-non-proctored-assessment</link>
      <description><![CDATA[过去几年，我的研究团队一直在为大学课程结束时参加的学生进行内部多项选择知识评估。我的老板坚持要我们进行有效性测试，并且非常喜欢 IRT 模型。但是，我们没有资源来监考考试，而且为了招聘，我们的研究负责人不想规定我们的合作教师如何进行评估或为其分配多少学分。这允许教师享有某些自由。例如，评估是基于计算机的，我知道许多教师只是让学生在家参加评估，有些教师会给予很少的学分。
我担心的是，当我们运行 IRT 模型时，它们不会非常准确，因为学生很有可能作弊，或者没有付出任何努力。我们过去几次管理中有大约 300-600 名学生，2PL 模型往往是最合适的。然而，它们仍然不是很好的匹配（RMSEA 和 CFI 不错，但 M2 显示预期和实际观察值之间存在显著差异）。此外，过去两个学期的 IRT 结果显示出不一致的结果。在一个学期中，一个项目表现良好；在下一个学期，我会得到负面歧视或难度指数为 30 或类似的奇怪结果。
是否有方法可以减轻非监考评估固有的可变性，并适合 IRT 框架？或者，我运气不好，我需要求助于其他方法来测试有效性？或者，我是否只需要说服我的研究负责人，我们需要投入资源来建立监考管理部门以进行测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/659676/using-irt-for-a-non-proctored-assessment</guid>
      <pubDate>Tue, 07 Jan 2025 17:32:27 GMT</pubDate>
    </item>
    <item>
      <title>检测生存分析中的单个变化点/拐点</title>
      <link>https://stats.stackexchange.com/questions/659673/detection-of-a-single-change-point-inflection-in-a-survival-analysis</link>
      <description><![CDATA[我正在对有和没有手术并发症的患者进行生存分析。当检查这两个群体的 Kaplan-Meier 曲线时，很明显手术并发症对术后早期生存的影响更大。Schoenfeld 残差和对数减对数图显示违反了 PH 假设。
有/无并发症的患者的 KM 曲线显示其拐点在术后 3 个月左右发生了明显变化。这表明术后早期并发症的影响更大。术后每个月的调整和未调整 HR 显示​​出相似的趋势。
我如何准确检测和描述这个精确的变化点/拐点？
我想估计一个确切的日期以协助临床决策。我花了好几天到处寻找这个特定问题的答案，但我找不到解决方案。
我正在与 R 合作。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659673/detection-of-a-single-change-point-inflection-in-a-survival-analysis</guid>
      <pubDate>Tue, 07 Jan 2025 17:24:04 GMT</pubDate>
    </item>
    <item>
      <title>R 中带有测量误差的优化函数（矩量法模拟）</title>
      <link>https://stats.stackexchange.com/questions/659682/optimizing-function-with-measurement-error-in-r-simulated-method-of-moments</link>
      <description><![CDATA[统计学中的一个常见问题是假设一个总体，模拟许多样本，并找到与所需统计数据集最接近（在 MSE 意义上）的参数。为了说明，下面是如何找到与 AR1 过程匹配的参数的草图。（这只是一组广泛问题的说明 --- 这个特定问题是 AR1 并不重要。）

NT &lt;- 50
match &lt;- c( 截距=0.2, ar1=0.90, expsigma=(-0.1) )

sim.and.est.1 &lt;- function( i, p ) {

## 模拟某个过程，比如 true ar1
set.seed( i ); e &lt;- rnorm(NT, 0, exp(p[3]))
s &lt;- c( 0.2, numeric(NT-1) )
for (t in 2:NT) s[t] &lt;- p[1] + p[2]*s[t-1] + e[t]

## 估计 OLS ar1
a &lt;- lm.fit( cbind(1, s[1:(NT-1)]), s[2:NT] )
c( coef(a), expsigma= log(sd(resid(a)) ))
}

mcsapply &lt;- function( iter, fun, ... ) { simply2array(mclapply( iter, fun, ... )) }
penalty &lt;- function( a, b ) mean( (a-b)^2 )

result &lt;- optim(par=c(1.0, 0.0, 0.05),
fn=function( guess3, MC=1000 ) {
## message( paste( p3, collapse=&quot; &quot; ) )
simsests &lt;- t(mcsapply( 1:MC, function(i) sim.and.est.1(i, guess3) ))
thisone &lt;- colMeans( simsests )
ov &lt;- penalty( thisone , match )

## 如果我们接近，则抽样更多
if (ov &lt; 1e-2) {
## 增加精度
simsests &lt;- rbind(simsests, t(mcsapply( 1:MC*5, function(i) sim.and.est.1(i+MC, guess3) )))
thisone &lt;- colMeans( simsests )
ov &lt;- penalty( thisone , match )
}
ov
},
method=&quot;Nelder-Mead&quot;)

print(result)

R 中是否有更好的方法来处理具有测量误差的函数优化？

我试图处理这样的想法：远离最佳值，我不需要在函数本身中采样那么多点。它完全是临时的。
我也尝试重新启动 Nelder-Mead，但即使从局部最优开始似乎也没有减少其迭代次数（函数评估）。

是否有更适合手头任务的优化器？
我在这里做的事情是否可以做得更好？
建议表示感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659682/optimizing-function-with-measurement-error-in-r-simulated-method-of-moments</guid>
      <pubDate>Tue, 07 Jan 2025 17:01:55 GMT</pubDate>
    </item>
    <item>
      <title>何时使用哪种样本方差公式？</title>
      <link>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</link>
      <description><![CDATA[我知道样本方差的公式为
$$s^2 = \frac{\sum (x_i - \bar{x})^2}{n - 1}$$
我还知道样本方差的公式为“均值平方减均值平方”。
在计算给定样本的样本方差时，我使用了这两个公式，但发现它们给出了两个不同的答案，因此我想问，什么时候该使用第一个公式，什么时候该使用第二个公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</guid>
      <pubDate>Tue, 07 Jan 2025 05:32:19 GMT</pubDate>
    </item>
    <item>
      <title>使用加权逻辑回归对重复数据进行误差估计的校正因子</title>
      <link>https://stats.stackexchange.com/questions/659641/correcting-factor-for-error-estimation-with-weighted-logistic-regression-on-dupl</link>
      <description><![CDATA[假设一个数据集被复制，但第一个副本被分配了一组特殊权重，而第二个副本具有另一组权重，其中权重与我们复制数据的事实无关。 主要问题：

我是否应该将每个权重乘以 1/2 以纠正数据重复？

上下文
假设对于每个观察值 1 到 N，您有概率估计 $p_a=P(race=a)$、$p_b=P(race=b)$、$p_c=P(race=c)$，其中 $\sum_{r=\{a,b,c\}}p_r=1$ 和一些二元结果变量 $y$，并且我们希望估计逻辑回归 $\text{logit }y\sim \beta_0 + \beta_1 D^{r}+X\beta$ 其中 $D^r=1$ 当 P(race=r)&gt;.8 时，否则为 0。但是，由于我们希望明确地并且只比较 a 与 b，因此我们在 P(race=a)&gt;.8 或 P(race=b)&gt;.8 的数据子集上估计 $\text{logit }y\sim \beta_0 + \beta_1 D^{b}+X\beta$。这是传统方法，但它会丢弃所有 P(race=a)&lt;.8 AND P(race=b)&lt;.8 的数据。
重复的数据集，但每个重复项的权重不同
为了不丢弃 P(race=a)&lt;.8 AND P(race=b)&lt;.8 为真的观测值所包含的信息，我上面的一些高阶估计了一个加权逻辑回归，其中
\begin{align}
\text{logit }\begin{pmatrix}
y \\
y \\
\end{pmatrix} &amp;= \beta_0+\beta_1\begin{pmatrix}
D^{b} \\
D^{b} \\
\end{pmatrix}
+ \begin{pmatrix} X \\ X\\ \end{pmatrix} \beta
\end{align&gt;
其中 $$\text{weights} =\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$$ 且 $D^b_{1\dots N}$=1 且 $D^b_{(N+1)\dots 2N}=0$（基本上，第一个 1...N 堆栈具有虚拟 $D^b=1$ 且第二个 (N+1)...2N 具有虚拟 $D^b=0$。
问题：通常，每个观察值的权重为 1/2 应该可以解决因重复数据集而产生的错误估计问题。这是否仍然适用于权重的使用。例如，我可以这样做 $\text{weights} =\frac{1}{2}\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$。
附言
为了有形的直觉，想想比较黑人与白人以及西班牙裔与白人，但不知道谁是白人、西班牙裔和黑人，你只能对每个类别有一个概率估计。
请原谅我草率的符号，希望它足以传达这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/659641/correcting-factor-for-error-estimation-with-weighted-logistic-regression-on-dupl</guid>
      <pubDate>Tue, 07 Jan 2025 04:28:49 GMT</pubDate>
    </item>
    <item>
      <title>从 nlme 方差结构中修复方差参数</title>
      <link>https://stats.stackexchange.com/questions/659628/fixing-variance-parameters-from-nlme-variance-structure</link>
      <description><![CDATA[我一直在使用 nlme 包中的异方差随机效应模型。我不知道如何设置 varStruct 中的参考水平方差参数。在下面的例子中，我使用样本数据 Orthodont 拟合模型，该模型允许根据受试者的性别在受试者内差异化个体。
我知道值输出代表受试者内误差的标准差比率：
$$
\frac{\hat\sigma_{female}}{\hat\sigma_{male}} = .4533
$$
library(nlme)
ex.data &lt;- as.data.frame(Orthodont)
ex.model &lt;- lme(distance ~ age, data = ex.data,
random = ~1|Subject,
weights = varIdent(form = ~1|Sex))

ex.model$modelStruct$varStruct #如何从这个对象中提取值？
#&gt; 表示类 varIdent 的方差函数结构
#&gt; 男性 女性 
#&gt; 1.000000 0.453369


于 2025-01-06 使用 reprex v2.0.2 创建
有没有办法重新参数化模型，将女性的权重设置为 1，并让男性自由估计，以便我可以找到：
$$
\frac{\hat\sigma_{male}}{\hat\sigma_{female}}
$$
我试过这个，但没有结果：
ex.model_fixed &lt;- lme(distance ~ age, data = ex.data,
random = ~1|Subject,
weights = varIdent(form = ~1|Sex, fixed = c(&quot;Female&quot; = 1))) #如何将级别固定为某些值？

ex.model_fixed$modelStruct$varStruct
#&gt; 类 varIdent 的方差函数结构没有参数，或未初始化

我知道在这个例子中，只需反转比率即可轻松手动计算。一般来说，我想学习如何更改我在实践中使用的这种形式的其他模型的参考级别。]]></description>
      <guid>https://stats.stackexchange.com/questions/659628/fixing-variance-parameters-from-nlme-variance-structure</guid>
      <pubDate>Mon, 06 Jan 2025 21:32:41 GMT</pubDate>
    </item>
    </channel>
</rss>