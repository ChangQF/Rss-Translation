<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 05 Nov 2024 21:15:40 GMT</lastBuildDate>
    <item>
      <title>场景中，X（训练）和 X（测试）上的 PCA 不是数据泄漏</title>
      <link>https://stats.stackexchange.com/questions/656799/scenario-where-pca-on-xtrain-and-xtest-is-not-a-data-leakage</link>
      <description><![CDATA[有无数（转）帖讨论使用主成分分析 (PCA) 作为交叉验证 (CV) 中回归/分类问题特征的预处理方法的问题。我知道在执行 CV 之前将 PCA 应用于整个特征数据集会导致数据泄漏，因为测试数据集与训练数据集并不完全独立。这会影响我们准确评估模型如何推广到新鲜和未见过的数据的能力。
然而，在某种情况下，我认为这并不成立，但我没有发现无数关于这个主题的帖子中提到过这个问题。我认为这甚至可能不是一种罕见的情况：
假设我们想知道特定地理研究区域（$G$）内目标变量（$Y$）的值，例如创建空间地图。对于 $G$，特征 ($X$) 是详尽可用的，例如，将高维遥感特征视为 $X$ 的输入。
我们可以在某些位置 ($Y(s)$) 采样并确定 $Y$；以预测未知的 $Y(u)$。通过这样做，我们能够拟合模型 ($F$) $F: X(s) -&gt; Y(s)$。接下来，我们可以使用该模型预测给定$X(u)$的$Y(u)$，其中预测的$\hat{Y}(u)$ = $F(X(u)$)。我们只对使用我们的模型一次感兴趣，例如创建一个映射，其中 $X(u) ⊆ G$。
为了获得最佳的 $\hat{Y}(u)$，我们将在拟合 $F$ 之前对整个特征数据集 $X(s+u)$ 应用 PCA，因为我们有 $X(u)$ 可用。
接下来，我们要检查我们的 $\hat{Y}(u)$（或 $F$）有多准确。由于我们没有从 $G$ 中抽取的进一步独立样本 $Y$，我们可以使用 CV。
如果我们在 CV 中仅对 $X(train)$ 应用 PCA 并将其投射到 $X(test)$ 上，我们不会得到悲观的结果吗？在我们的实际流程中，我们对 $X(u+s)$ 使用了 PCA，那么在 CV 中，是否有理由以不同的方式执行此操作，因为我们只想知道我们的模型在给定 $X(u) ⊆ G$ 的情况下如何推广到 $X(u)$。
我的想法是不是错了？与典型情况不同的底层概念的名称是什么，我们希望 $F$ 能够很好地推广到新鲜和独立的样本？有人知道任何针对这种特定场景的文献吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656799/scenario-where-pca-on-xtrain-and-xtest-is-not-a-data-leakage</guid>
      <pubDate>Tue, 05 Nov 2024 18:18:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么加权最小二乘（WLS）回归中的逆方差权重会给出“最佳”估计量？</title>
      <link>https://stats.stackexchange.com/questions/656795/why-does-inverse-variance-weights-in-weighted-least-squares-wls-regression-giv</link>
      <description><![CDATA[这是我目前对 WLS 的理解。
在 OLS 中，我们给每个数据点相同的权重。这在某些假设下给出了最佳的线性无偏估计量——其中之一是误差项的方差为常数（同方差性）
但是当残差具有异方差性时，我们确定回归系数的 OLS 估计量不再是“最佳”的估计量。这意味着它具有更多的方差。因此，然后使用 WLS 找到这个最佳估计量（考虑到误差仍然不相关）。
我读到，当权重是误差项的逆方差时，WLS 会给出回归系数的最佳估计量。这意味着我们给 OLS 模型预测高误差方差（由残差方差估计）的数据点赋予较少的权重。误差方差较小的点会获得更大的权重。
我明白这在理论上是可行的。我想更直观地理解它：为什么给予方差较小的点更大的权重会改善估计量？
为什么在执行 WLS 回归时，方差较小的点被认为更“可靠”？
谢谢 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/656795/why-does-inverse-variance-weights-in-weighted-least-squares-wls-regression-giv</guid>
      <pubDate>Tue, 05 Nov 2024 16:42:54 GMT</pubDate>
    </item>
    <item>
      <title>我正在写一篇关于分析作者传记的本科论文，想得到一些建议</title>
      <link>https://stats.stackexchange.com/questions/656794/i-am-doing-an-undergraduate-thesis-on-analysing-biographies-of-authors-and-woul</link>
      <description><![CDATA[我是一名计算机科学专业的学生，​​我的大部分学位都是在做全职的 Web 开发工作的同时完成的，因此我的学习受到了一些影响，现在我快毕业了，我想做一些有趣的事情，而不是用一个默认的 Web 应用程序来结束整个课程，于是我选择了一个数据分析项目。我的顾问在确定这个项目的可行性方面并没有真正提供帮助，所以我决定向你们寻求帮助，如果这整个事情真的很愚蠢，请原谅我。我没有数据科学方面的经验，我刚开始阅读统计学习的介绍。
所以我的想法是，我会分析一堆著名作家的传记，并尝试找出“生活事件”，比如在贫困中长大、移民、经历过战争等，并尝试找到他们经历的事件与他们获得的认可之间的关系，比如销售数字、不同类型的奖项。本质上回答了这样的问题：什么样的经历对一个讲故事的人取得成功很重要。我考虑过预先定义问题并通过 chatgpt 提供个人简介，以创建可用于分析的数据集。我想到的一个问题是，如果生活事件发生了，很容易验证，但如果没有发生，就不太容易验证，而且我不确定如何表示数据。这些有意义吗？你认为可行吗？有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656794/i-am-doing-an-undergraduate-thesis-on-analysing-biographies-of-authors-and-woul</guid>
      <pubDate>Tue, 05 Nov 2024 16:34:35 GMT</pubDate>
    </item>
    <item>
      <title>MLP 函数类的射影性</title>
      <link>https://stats.stackexchange.com/questions/656790/surjectivity-of-a-mlp-function-class</link>
      <description><![CDATA[假设$\mathcal{F}(H,L)$ 是由具有 ReLU 激活、宽度$H$ 和深度$L$的多层感知器实现的所有函数的函数类。此外，还有一组对应于 $k$ 个数据点 $x_1,\cdots,x_k$ 的所有可能值。
我想知道映射 $f\in\mathcal{F}(H,L) \mapsto (f(x_i))_{i=1}^k\in \mathbb{R}^k $ 是否是主观的，即对于任何 $u\in\mathbb{R}^k$，都存在某个 $f\in\mathcal{F}(H,L)$，使得对于所有 $f(x_i)=u_i$ class=&quot;math-container&quot;&gt;$i$。
如果是，$H$ 和 $L$ 的条件应该是什么才能保证单射性？]]></description>
      <guid>https://stats.stackexchange.com/questions/656790/surjectivity-of-a-mlp-function-class</guid>
      <pubDate>Tue, 05 Nov 2024 14:35:14 GMT</pubDate>
    </item>
    <item>
      <title>联合检验复合零假设</title>
      <link>https://stats.stackexchange.com/questions/656789/jointly-testing-a-composite-null</link>
      <description><![CDATA[假设我们有一个 GLM，其 $g^{-1}(\mathbb{E}[y|x]) = \beta_0+x_A\beta_A+x_b\beta_B$。我想检验以下假设：$H_0:\beta_A \leq 0 \cup\beta_B\leq0$ $H_1:\beta_A&gt;0\cap \beta_B&gt;0$。有人能指点我如何构建一个检验方法，在这些情况下得出有效的 p 值吗？如果我没错的话，我正在检验两个复合零假设，但我不知道还能用这些信息做什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/656789/jointly-testing-a-composite-null</guid>
      <pubDate>Tue, 05 Nov 2024 14:01:25 GMT</pubDate>
    </item>
    <item>
      <title>未研究任何治疗方法时转换风险比</title>
      <link>https://stats.stackexchange.com/questions/656786/converting-risk-ratios-when-no-treatment-is-investigated</link>
      <description><![CDATA[我目前正在进行一项荟萃分析，研究抑郁症的患病率在最低收入群体和最高收入群体之间是否存在差异。我感兴趣的效应量是比值比，因为这些似乎是标准的相关研究。
然而，我现在遇到了一项使用患病率而不是 OR 的研究。在我寻找转换方法的过程中，我偶然发现了 effectsize R 包，它提供了一个基于 Grant (2014) 的论文 将 RR 转换为 OR 的功能。为此，您需要 RR 以及基线风险。在论文中，基线风险被描述为对照组中积极结果（例如成功戒烟）的百分比。
我的问题来了：这种基线风险定义对于研究治疗效果的研究非常有意义。但这是否仍然适用于我的荟萃分析的背景？由于我不是在比较治疗组和对照组的效果，而是在比较两个不同组中特定结果的基线可能性，我想知道样本中抑郁症的基线患病率（即所有收入群体中抑郁症的患病率）是否更适合这种转换。]]></description>
      <guid>https://stats.stackexchange.com/questions/656786/converting-risk-ratios-when-no-treatment-is-investigated</guid>
      <pubDate>Tue, 05 Nov 2024 12:15:59 GMT</pubDate>
    </item>
    <item>
      <title>改变参数支持的后验影响</title>
      <link>https://stats.stackexchange.com/questions/656785/posteriors-impact-of-changing-parameters-support</link>
      <description><![CDATA[假设我正在进行贝叶斯推理，并且我有一个参数$\alpha \in (0, 1)$。我正在使用 Metropolis 算法进行 MCMC，为此我考虑变换 $\psi = \log(\alpha/(1 - \alpha))$，先前的 $\psi \sim \text{Normal}(0, 100)$，但我仍然对 $\alpha$（可信区间、HPD 区间等）感兴趣。
我可以使用 Metropolis 算法对 $\psi$ 进行采样，然后变换每个样本，使得 $\alpha = 1/(1 + \exp(-\psi))$ 吗？我什么时候应该关心计算变换的雅可比矩阵？]]></description>
      <guid>https://stats.stackexchange.com/questions/656785/posteriors-impact-of-changing-parameters-support</guid>
      <pubDate>Tue, 05 Nov 2024 11:54:42 GMT</pubDate>
    </item>
    <item>
      <title>“分类数据”是“名义数据”的同义词吗？</title>
      <link>https://stats.stackexchange.com/questions/656778/is-categorical-data-a-synonym-of-nominal-data</link>
      <description><![CDATA[到目前为止，我一直认为名义数据是一种分类数据，而不是它的同义词。对我来说，分类数据包括序数数据，而不仅仅是名义数据。
截至 2024 年 11 月，维基百科说（粗体是我的）：

序数数据是一种分类统计数据类型，其中变量具有自然、有序的类别，并且类别之间的距离未知。

这似乎与 Alan Agresti 的分类数据分析简介（第二版，2007 年）一致。第 2 页：

分类变量有两种主要的测量尺度。 [...]
具有有序尺度的分类变量称为序数
变量。
具有无序尺度的分类变量称为
名义变量。

另一方面，CrossValidated 上的categorical-data 标签 表示（粗体是我的）：

分类（也称为名义）数据可以采用有限数量的
可能值，称为类别。分类值“标记”，它们不“测量”。 [...]
对于分析，分类值被视为抽象实体，
没有任何数学结构，例如顺序或拓扑，
无论它们如何编码和存储。

加州大学洛杉矶分校统计方法和数据分析网站似乎同意 CrossValidated 的定义（粗体是我的）：

分类变量（有时称为名义变量）是具有两个或多个类别的变量，但类别没有内在顺序。 [...] 纯名义变量仅允许您分配类别，但您无法明确排序类别。

因此，这里似乎存在一些差异。虽然我一般对维基百科有点警惕，但我没有理由怀疑我提到的其他资源，特别是当它们的定义似乎不模棱两可时。
这是否反映了对“分类”定义缺乏共识？换句话说，“分类”是一个允许灵活使用的术语吗？还是我误解了某些内容或遗漏了一些可以调和这些不同参考资料的重要信息？
如果有的话，我还对（最好是学术性的）参考资料感兴趣，讨论“分类”的定义以及可能存在不同定义的问题。
我问这个问题的原因当然不是为了吹毛求疵，而是为了避免在阅读或与其他人讨论这个主题时可能出现的误解。]]></description>
      <guid>https://stats.stackexchange.com/questions/656778/is-categorical-data-a-synonym-of-nominal-data</guid>
      <pubDate>Tue, 05 Nov 2024 10:31:33 GMT</pubDate>
    </item>
    <item>
      <title>联合 pdf 中多种情况下的联合 cdf</title>
      <link>https://stats.stackexchange.com/questions/656763/joint-cdf-in-multiple-cases-from-a-joint-pdf</link>
      <description><![CDATA[因此，基本上我们有一个联合 pdf
$$f(x,y) = x + y$$，其中 $0&lt;x&lt;1$ 和 $0&lt;y&lt;1$。
我们知道联合 cdf 如下
$$F(x,y) = P(X\leq x, Y\leq y) = \int_{-\infty}^{y}\int_{-\infty}^{x}f(s,t)dsdt$$
由于我们必须考虑多种情​​况，我定义了 3 种情况
因此；

$x\leq 0 \text{ 和 } y \leq 0 $

$\implies F(x,y) = 0$

$0&lt;x&lt;1 \text{ 和 } 0&lt;x&lt;1 $

$\implies F(x,y) = 0 + \int_{0}^{y}\int_{0}^{x}(s+t)dsdt = \frac{x^2y}{2} + \frac{xy^2}{2}$



$x\geq 1 \text{ and } y \geq 1 $



$\implies F(x,y) = case 1 + case 2 + case 3 = 1$
但我不太确定如何通过简单地以 cdf 格式写入总和为 1 来处理案例 3（我知道案例 1 为 0，案例 2 应为 1，案例 3 将为 0，因为它们超出了界限）
第二个问题是，我认为我们可以有 5 个案例；

$x&lt;0\text{ and }y&lt;0$

$0\leq x\leq 1 \text{ and } 0\leq y\leq 1$

$x&gt;1\text{ and } 0\leq y\leq 1$

$0\leq x\leq 1\text{ and } y&gt;1$

$x\geq 1 \text{ and } y\geq 1$


总之，这个问题可以有多少种情况，我该如何解决最后一种情况（3 种情况问题），如果是 5 种情况，我该如何以累积格式处理它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/656763/joint-cdf-in-multiple-cases-from-a-joint-pdf</guid>
      <pubDate>Tue, 05 Nov 2024 04:54:14 GMT</pubDate>
    </item>
    <item>
      <title>仅基于条件独立假设（无边际独立性）的联合似然推导</title>
      <link>https://stats.stackexchange.com/questions/656735/derivation-of-joint-likelihood-with-only-conditional-independence-assumptions-w</link>
      <description><![CDATA[我正在推导数据集 $(\mathbf{X}_i, \mathbf{y}_i)$ 的联合似然，假设 $\mathbf{y}_i$ 给定，且 $\mathbf{X}_i$ 具有条件独立性，但不假设特​​征 $\mathbf{X}_i$ 具有边际独立性。我正在尝试确认我对联合似然表达式的理解是否正确。
以下是设置：

我有 $N$ 个观测值，其中 $\mathbf{y}_i$ 是目标变量，$\mathbf{X}_i$ 是观测值 $i$ 的特征向量。
我假设在给定 $\mathbf{X}_i$ 的情况下，$\mathbf{y}_i$ 具有条件独立性。这意味着：

$$
p(y_1, y_2, \ldots, y_N \mid \mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_N) = \prod_{i=1}^N p(y_i \mid \mathbf{X}_i)。
$$

我不假设$\mathbf{X}_i$值之间存在任何边际独立性，因此联合分布$p(\mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_N)$可以是任意的。

鉴于此，我推导出观察目标值和特征的联合似然，如下所示：
推导尝试：
使用链式法则，我将联合概率写为：
$$
p(y_1, y_2, \ldots, y_N, \mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_N;\theta) = p(y_1, y_2, \ldots, y_N \mid \mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_N;\theta) \cdot p(\mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_N)。
$$
给定 $\mathbf{X}_i$，应用 $\mathbf{y}_i$ 的条件独立性，我将条件联合概率替换为：
$$
p(y_1, y_2, \ldots, y_N \mid \mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_N;\theta) = \prod_{i=1}^N p(y_i \mid \mathbf{X}_i;\theta)。
$$
因此，联合似然变为：
$$
L(\theta) = p(y_1, y_2, \ldots, y_N, \mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_N) = \left( \prod_{i=1}^N p(y_i \mid \mathbf{X}_i; \theta) \right) \cdot p(\mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_N)。
$$
问题：

在给定的假设下，此推导对于联合似然是否正确？
在最大化 $\theta$ 的似然时，我是否正确地只关注条件部分 $\prod_{i=1}^N p(y_i \mid \mathbf{X}_i; \theta)$，因为 $p(\mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_N)$ 不依赖于 $\theta$？

对此推导或参考资料有任何反馈吗如果能对统计文献中的类似推导做出贡献将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/656735/derivation-of-joint-likelihood-with-only-conditional-independence-assumptions-w</guid>
      <pubDate>Mon, 04 Nov 2024 16:39:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 feols 实现 R 中的系数稳定性</title>
      <link>https://stats.stackexchange.com/questions/656791/coefficient-stability-in-r-using-feols</link>
      <description><![CDATA[我正在开展一个项目，我想测试使用 {fixest 包中的 feols 函数得出的估计系数的稳定性。与 {plm 和其他包相比，此函数生成结果的速度要快得多。我打算按照 Oster (2019) 进行测试，以生成偏差调整系数 (beta)。
由于我无法分享我项目的数据集，下面是我运行的回归类型的示例：
data(&quot;mtcars&quot;)

m1 &lt;- mtcars %&gt;% feols(mpg ~ wt, cluster = ~gear)
m1

m2 &lt;- mtcars %&gt;% feols(mpg ~ wt | cyl, cluster = ~gear)
m2

m3 &lt;- mtcars %&gt;% feols(mpg ~ wt | cyl + drat + cyl^drat, cluster = ~gear)
m3

假设我的项目的目标是估计 wt 对 mpg 的影响。我考虑了三个虚拟模型（或测试模型），它们没有真正的实质性意义，但旨在证明我的问题

无控制
控制 cyl 固定效应。
还控制 drat 固定效应和 cylXdrat（交互）固定效应。
所有回归都包括按 gear 聚类。

如何计算 wt 的偏差调整系数（即 wt 对 mpg 的影响）？
我尝试使用 {robomit 中的 o_beta 来计算，但当我使用 plm 模型在我的数据集上运行固定效应模型时，我的代码失败了。
是否有一个包可以与 {fixest 对象配合使用以实现此目的？
或者，我可以手动计算吗？如果可以，公式是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/656791/coefficient-stability-in-r-using-feols</guid>
      <pubDate>Mon, 04 Nov 2024 16:18:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 beta 约束拟合 OLS [重复]</title>
      <link>https://stats.stackexchange.com/questions/656730/fitting-ols-with-constraint-on-the-betas</link>
      <description><![CDATA[假设我的模型看起来像 $y=\beta_1x_1 + \beta_2x_2 + \beta_3x_3$，但有一个问题：我想强制执行 $\beta_1=\beta_3$。如何在频率派和贝叶斯派设置中做到这一点？具体来说，对于贝叶斯派路线，我使用的是 pymc，有什么方法可以实现这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656730/fitting-ols-with-constraint-on-the-betas</guid>
      <pubDate>Mon, 04 Nov 2024 14:28:34 GMT</pubDate>
    </item>
    <item>
      <title>使用 Bootstrap 与交叉验证来评估机器学习模型的预测性能</title>
      <link>https://stats.stackexchange.com/questions/656710/bootstrap-vs-crossvalidation-for-assessing-the-predictive-performance-of-a-machi</link>
      <description><![CDATA[我正在尝试在引导和交叉验证之间做出选择，以便彻底评估预测模型性能。
引导：

使用替换对数据进行采样，创建 B &gt; 1000（或更多）个不同的训练集，其中由于使用替换采样，每个观察结果都被独立处理！这意味着经验分布函数被用作抽取样本的真实世界分布的替代品。
动态使用袋外 (OOB) 观测值作为保留集：这消除了对单独保留集的需求，并且可以提供更可靠的样本外预测性能估计。
可能捕获更多真实世界方差（通过替换采样，即利用经验分布函数）

如果我必须评估两个不同的模型，我会

生成 B=1000 ... 训练数据集的引导重采样
在 B 个不同的袋外测试样本集上评估这两个模型
计算配对模型性能差异（性能模型 1 - 性能模型 2，其中差异取自相同的 OOB 测试集），配对将用于https://en.wikipedia.org/wiki/Variance_reduction
制作配对模型性能差异的直方图
如果模型性能的密度明显偏离 0，则其中一个模型优于另一个模型（由此也可以设计一些测试以获得 95% 的改进确定性...）

交叉验证：

将数据分成几部分，使用不同的部分进行训练和测试。
可以更有效率，尤其是在数据有限的情况下。
可能导致“相关”训练集，尤其是在 LOOCV 中（训练集几乎没有变化，除了一个观察值）

为了比较两个模型，我会做与 bootstrap 情况相同的事情（只是没有袋外测试样本，但在 LOOCV 的情况下，最大 N= 观察值不同的保留集）。
问题：
鉴于 bootstrap 可以在训练集中引入更多变化（通过替换重采样）并利用 OOB 数据进行验证，与交叉验证（本质上是无替换重采样）相比，它是否会提供更现实的样本外性能估计？尤其是潜在的“相关性” 交叉验证训练集之间是否存在重大问题？
PS：我尝试搜索 stackoverflow 并提出了类似的问题，但它们没有讨论 CV 训练集的潜在相关性问题：

Bootstrap 或 jack-knife 用于预测模型的交叉验证？（无答案）
了解用于验证和模型选择的 bootstrapping
交叉验证和引导法在估计预测误差方面的差异（没有明确的答案哪个更可靠）
交叉验证或引导法评估分类性能？（这个问题似乎很直接，但公认的答案主要涉及只有一个测试训练分割（CV 的退化形式，显然没有像 k 倍 CV 那样的多个测试训练分割），Frank Harell 有一个答案 https://stats.stackexchange.com/a/71189/298651 链接 https://hbiostat.org/doc/simval.html 得出一个结论“普通引导法优于或等于所有尝试过的交叉验证策略”，但这在他的回答中没有明确讨论...)
分类测试的交叉验证与随机抽样（没有明确的结论，无所谓，但有趣的论文？）
]]></description>
      <guid>https://stats.stackexchange.com/questions/656710/bootstrap-vs-crossvalidation-for-assessing-the-predictive-performance-of-a-machi</guid>
      <pubDate>Mon, 04 Nov 2024 07:58:08 GMT</pubDate>
    </item>
    <item>
      <title>使用正交勒让德多项式进行 Copula 密度估计和绘图</title>
      <link>https://stats.stackexchange.com/questions/656746/copula-density-estimation-and-plotting-using-orthogonal-legendre-polynomials</link>
      <description><![CDATA[我一直尝试根据以下步骤复制 copula 密度图，但没有成功：
对 I=[0,1] 使用均匀测度
使用移位勒让德多项式的正交基，公式如下：

[移位勒让德多项式]
对于 d=2，定义

[移位Legendre 多项式应用于数据]
和

[移位 Legendre 多项式的平均值应用于数据 - 新的相关系数。]
copula 密度函数是

[移位 Legendre 变换的 copula 密度函数数据多项式]
对于

其经验对应物是

[新相关系数的样本对应物]
而 copula 密度经验对应物是

[copula 密度的样本对应项。]
现在我的情况只涉及二维数据，即 d=2。在这种情况下，rho_m 只是将移位勒让德多项式变换应用于数据后的相关系数。
我想使用模拟数据绘制 copula 密度 c 的非参数估计量。
它必须看起来像下面的情节（或多或少）

论文可以在这里找到：
https://arxiv.org/pdf/2010.15351
我的情节是

这肯定看起来不对！！
您对如何正确编写 R 函数 (7) 有什么建议吗？您能找到问题吗？无需处理 m&lt;N 的总和

因为在我的例子中，是一个标量！

# 生成双变量样本：
set.seed(1)
datX &lt;- mvrnorm(n=n, mu=mymeans, Sigma, empirical=TRUE)

# Legendre 多项式变换：
library(orthopolynom)

Kcop_pol &lt;- function(m, x) {
legend = slegendre.polynomials(m, normalized = TRUE) # [m+1]?
unlist(polynomial.values(legend, x))
} 

Kcop_rhat &lt;- function(j, datX) {
datX &lt;- pobs(datX)
n1 = nrow(datX)
p1 = ncol(datX)
A = matrix(rep(0, n1 * p1), ncol = p1)
for (i in 1:p1) {
A[, i] &lt;- Kcop_pol(j[i], datX[, i])
} 
sum(apply(A, 1, prod)) / n1
}

# 计算 m=c(1,2) 的 rho_m 
Kcop_rhat(j = c(1,2), datX = datX) 

orthog.poly.copula.surface = function(u,v,n) {
s = seq(1/(n+1), length = n, by = 1/(n+1))
mat = matrix(0, nrow = n, ncol = n)
for (i in 1:n) {
a = s[i]
for (j in 1:n) {
b = s[j]
mat[i, j] = 
Kcop_rhat(j = c(1,2), datX = datX) * 
mean(outer(Kcop_pol(m, a), Kcop_pol(m, b))) 
}
}
list(x=s,y=s,z=data.matrix(mat))
}

z = orthog.poly.copula.surface(u = datX[, 1], v = datX[, 2], n = n)$z

persp(seq(0,1,length = n),
seq(0,1,length = n),
z,
col = &quot;green&quot;,
shade = TRUE,
ylab = &quot;GDP 增长&quot;,
zlab = &quot;Copula 密度&quot;,
xlab = &quot;债务/GDP&quot;,
axis = TRUE,
theta = 150,
phi = 20,
main = &quot;正交多项式 Copula 密度&quot;,
ticktype = &quot;detailed&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/656746/copula-density-estimation-and-plotting-using-orthogonal-legendre-polynomials</guid>
      <pubDate>Mon, 04 Nov 2024 05:54:07 GMT</pubDate>
    </item>
    <item>
      <title>结合加权均匀分布和正态分布变量的复杂概率分布建模</title>
      <link>https://stats.stackexchange.com/questions/656659/modelling-of-a-complex-probability-distribution-combining-weighted-uniform-and-n</link>
      <description><![CDATA[最近，我一直在尝试为视频游戏中的随机分布提出一个准确的概率模型。我试图建模的过程如下：

从加权战利品表中随机选择三个物品（有替换）
每个物品都被分配一个正态分布的大小
然后比较这三个物品的大小，并将其中最大的一个交给玩家

在这个过程中，我已经知道从战利品表中选中每个物品的概率，以及每个物品大小分布的平均值和标准差。我如何将这个基本概率与大小分布结合起来，找出考虑到大小分布后选中某个物品的真实概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/656659/modelling-of-a-complex-probability-distribution-combining-weighted-uniform-and-n</guid>
      <pubDate>Sat, 02 Nov 2024 14:33:55 GMT</pubDate>
    </item>
    </channel>
</rss>