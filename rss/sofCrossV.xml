<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 13 Dec 2024 06:26:42 GMT</lastBuildDate>
    <item>
      <title>检查异常值随时间增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</link>
      <description><![CDATA[有人要求我测试多年来高异常值的数量和大小是否有所增加。目的是表明随着时间的推移（基数保持不变），极端情况会越来越多，越来越高。
我有很多例子和年份、年龄组和性别之间的比较，但下面我只会展示一个。有两组数据，恰当地命名为组 1（2022），包含 207 个样本，组 2（2023），包含 250 个样本。 y 轴变量以整数形式测量。
首先，进行 t 检验，表明平均值有所下降。

绘制了箱线图来可视化这一点
应该注意的是，组 2 中有 9 个点高于 10（约为组 1 的平均值），组 2 中有 10 个点约为 10（总共 12 个高异常值），其中组 2 中的顶级异常值高于组 1。所有异常值都经过严格检查，以确认它们是有效的数据点。

并且为了合理性，绘制了 var 随日期变化的散点图。红线表示箱线图的上限，其中任何高于该上限的点都被视为异常值。

这些都表明平均值有所下降，但是有人要求我统计地确认 2023 年是否存在更多和更高的异常值，而不管平均值的行为如何。有人要求我在不同性别、年龄和性别群体中展示这一点，在某些群体中比其他群体更明显。
我该如何进行统计测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/658661/checking-for-an-increase-in-outliers-over-time</guid>
      <pubDate>Fri, 13 Dec 2024 06:09:28 GMT</pubDate>
    </item>
    <item>
      <title>哪些统计数据最适合用于评估基于常模的能力评估的有效性和可靠性？</title>
      <link>https://stats.stackexchange.com/questions/658660/which-statistics-are-best-practice-for-assessing-the-validity-and-reliability-of</link>
      <description><![CDATA[我计划评估常模参照能力评估的有效性和可靠性。该工具有 5 个与能力相关的子量表。有现成的常模，但我想对我拥有的样本进行一些额外的研究，以增加对该工具的研究内容。
对于标准参照评估，我会考虑的两个统计数据是每项的 cronbachs alpha 和因子分析。一般来说，这些是否也构成能力评估的最佳实践？]]></description>
      <guid>https://stats.stackexchange.com/questions/658660/which-statistics-are-best-practice-for-assessing-the-validity-and-reliability-of</guid>
      <pubDate>Fri, 13 Dec 2024 05:44:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么不使用这种“矩量法”来估计矩阵正态分布？</title>
      <link>https://stats.stackexchange.com/questions/658659/why-the-matrix-normal-distribution-is-not-estimated-with-this-method-of-moments</link>
      <description><![CDATA[根据维基百科页面，随机矩阵$\bf{X}\in \mathbb{R}^{p\times q}$服从矩阵正态分布$\cal{MN}(\bf M, \bf U, \bf V)$，这意味着
$$ \text{vec}(\bf X) \sim \cal N ( \mathrm{vec} (\bf M), \bf V \otimes \bf U),$$
其中$\bf M \in \mathbb{R}^{p\times q}$, $\bf U \in \mathbb{R}^{p\times p}$, 以及 $\bf V \in \mathbb{R}^{q\times q}$.
假设我们观察到矩阵值数据 $\bf X_1, \dots, \bf X_n$，它们被假定为 $\cal{MN}(\bf M, \bf U, \bf V)$ 的 i.i.d. 实现。然后，MLE 具有估计值 $\hat{\bf M}$ 作为通常的样本均值，并且 $\bf U$、$\bf V$ 由以下迭代过程给出：
$$
\begin{aligned}
\hat{\bf U} = \frac{1}{nq} \sum_{i=1}^n (\bf X - \bf M) \hat{\bf V}^{-1} (\bf X - \bf M)^\top, \\
\hat{\bf V} = \frac{1}{np} \sum_{i=1}^n (\bf X - \bf M)^\top \hat{\bf U}^{-1} (\bf X - \bf M)。
\end{aligned}
$$
我理解 MLE 框架，但想知道为什么这种方法不起作用：请注意，从同一个维基百科页面
$$\begin{aligned}
\bf E[(\bf X - \bf M) (\bf X - \bf M)^\top] = \bf U\, \mathrm{tr}(\bf V), \\
\bf E[(\bf X - \bf M)^\top (\bf X - \bf M)] = \bf V\, \mathrm{tr}(\bf U)。
\end{aligned}$$
由于 $\bf U$ 和 $\bf V$ 无法通过缩放因子进行识别，我们提出附加限制 $\mathrm{tr}(\bf V) = q$。那么，我认为可以这样估计：
$$\begin{aligned}
\hat{\bf U} = \frac{1}{nq} \sum_{i=1}^n (\bf X - \bf M) (\bf X - \bf M)^\top, \\
\hat{\bf V} = \frac{1}{n\, \mathrm{tr}(\hat{\bf U})} \sum_{i=1}^n (\bf X - \bf M)^\top (\bf X - \bf M)。
\end{aligned}$$
但是，第二种方法与 MLE 不一致。哪里出了问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658659/why-the-matrix-normal-distribution-is-not-estimated-with-this-method-of-moments</guid>
      <pubDate>Fri, 13 Dec 2024 03:43:57 GMT</pubDate>
    </item>
    <item>
      <title>基于密度比估计的分类</title>
      <link>https://stats.stackexchange.com/questions/658658/density-ratio-estimation-based-classification</link>
      <description><![CDATA[考虑分类问题 $p(y \mid x)$，其中 $y$ 是标签，$x$ 是特征向量，例如图像。通常，我们会拟合卷积网络，并根据 $x$ 预测 $y$。昨天我突然想到，根据贝叶斯规则，$\log p(y \mid x) = \log p(y) + \color{blue}{\log \frac{p(x \mid y)}{p(x)}}$。由于$\log p(y)$可以从数据集中轻松估算出来，因此找到对数密度比（蓝色）将等同于找到分类器$p(y \mid x)$。根据密度比技巧（Sugiyama 等人， 2012；Dhuliawala 等人， 2023），可以通过拟合一组分类器 $T_y(x)$（也可以选择拟合一个摊销分类器）来找到对数密度比，该分类器区分 $p(x \mid y)$ 样本和 $p(x)$ 样本。 $T_y(x)$ 的优化条件是 $\mathbb E_{p(x \mid y)}[\log \sigma(T_y(x))] + \mathbb E_{p(x)}[\log (1-\sigma(T_y(x)))]$ 最大化，其中 $\sigma(\cdot)$ 为 S 型函数。因此，$\log p(y \mid x) = \log p(y) + T_y(x)$。一个优点可能是校准标签偏移很简单。
这种方法在实践中使用过吗？如果有人能给我指出相关文献，我将不胜感激。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658658/density-ratio-estimation-based-classification</guid>
      <pubDate>Fri, 13 Dec 2024 03:36:18 GMT</pubDate>
    </item>
    <item>
      <title>与回归分析相比，生存分析在预测方面有哪些优势？</title>
      <link>https://stats.stackexchange.com/questions/658656/are-there-any-advantages-of-survival-analysis-over-regression-for-prediction</link>
      <description><![CDATA[我最近遇到了生存分析，它似乎对于模拟事件发生时间和/或处理审查非常有用。文献中激励性的例子很有意义，例如在临床试验中，我们可能会有参与者退出，或者那些可能经历了不良影响但研究提前结束的人。
在我的应用程序中，我使用机器学习对事件发生时间进行建模并将其视为回归问题。然而，审查在这里并不是一个真正的问题，我想知道生存分析是否会比标准回归方法提供任何优势。
为了简化设置，假设我们有来自小部件工厂的数据。小部件发生故障的平均时间为$\bar{Y} = 40$天（最多 100 天），而数据集可以追溯到几年前，并且有几百万个观察值。因此，确实存在一些右删失，但考虑到数据的大小，这相对微不足道。我们还观察到小部件级协变量 $X$，它们会影响故障时间。
目前，我只是将其建模为非参数回归问题，即学习函数 $f : X \to Y$，该函数可最小化 $L^2$ 经验风险/MSE。如果这里的目标只是预测故障时间 $Y$，而不考虑推理，那么生存分析是否会比回归方法有任何优势？]]></description>
      <guid>https://stats.stackexchange.com/questions/658656/are-there-any-advantages-of-survival-analysis-over-regression-for-prediction</guid>
      <pubDate>Fri, 13 Dec 2024 01:17:45 GMT</pubDate>
    </item>
    <item>
      <title>与基线纵向模型的变化</title>
      <link>https://stats.stackexchange.com/questions/658655/change-from-baseline-longitudinal-model</link>
      <description><![CDATA[我正在研究一个纵向模型，以分析变量 Y 的相对于基线的变化，该变量在基线 Y1 和后续时间点 (Y2、Y3、Y4 ...) 处针对一组患者进行测量。对于每个测量值，我都有相应的标准差 (Y1_SD、Y2_SD、Y3_SD ...)。
(相对于基线的变化) 平均差异 (MD) 很容易计算为 ( Y1 ) 与每个后续 ( Y_i ) 之间的差异。但是，我很难正确定义 平均差异的标准差 (SD_diff)，因为这需要 ( Y1 ) 和 ( Y2、Y3、...) 之间的相关性 ( r )；编码协方差矩阵（例如自回归矩阵）也需要相关性
我引用的 SD_diff 公式是：
SD_diff = sqrt(S1² + S2² - 2 * r * S1 * S2)
我的问题是：

我需要两个元素来构建纵向模型吗？
纵向模型可以只用协方差矩阵编码吗？

方差和协方差矩阵应该如何定义？
假设任何协方差矩阵（例如 AR(1)）在其公式中包含变量方差；这应该由 SD_diff 定义吗？还是由 Yi_SD 定义？

]]></description>
      <guid>https://stats.stackexchange.com/questions/658655/change-from-baseline-longitudinal-model</guid>
      <pubDate>Fri, 13 Dec 2024 00:07:57 GMT</pubDate>
    </item>
    <item>
      <title>适合我的数据进行因果关系检验的算法/测试</title>
      <link>https://stats.stackexchange.com/questions/658654/algorithms-tests-that-suit-my-data-for-causal-relationship-examination</link>
      <description><![CDATA[我有两份在 18 个采样点和 20 个采样日期收集的观测数据，我想测试我的数据中两个变量之间是否存在因果关系。请注意，由于我的数据是观测数据，因此无法对其进行操纵，并且没有假定的有向无环图 (DAG)。基于这些条件，我想知道哪种算法或测试最适合我的数据？
我相信 Peter-Clark (PC) 算法可能适合我的数据，因为它可以用于表格数据，但我正在寻找更多算法/测试来检查因果关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/658654/algorithms-tests-that-suit-my-data-for-causal-relationship-examination</guid>
      <pubDate>Fri, 13 Dec 2024 00:05:20 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用函数 HSD.test 作为 R 中双向方差分析的事后检验吗？</title>
      <link>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</link>
      <description><![CDATA[我已经做过双向方差分析，现在我想做事后检验。我有 2 个因素，并且都只有 2 个类别。我找到了 agricolae 包中的 HSD.test 函数，我非常喜欢它能给出组别和字母，说明各组之间的差异。但我不确定这个函数是否可以用于两个因素，或者它是否只适用于单向方差分析。有人知道吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</guid>
      <pubDate>Thu, 12 Dec 2024 23:05:32 GMT</pubDate>
    </item>
    <item>
      <title>fixest 和 plm 模型的回归表？</title>
      <link>https://stats.stackexchange.com/questions/658650/regression-table-for-fixest-and-plm-models</link>
      <description><![CDATA[我正在使用 fixest 和 plm 模型。我通常对 fixest 对象使用 fixest 的 etable，对 plm 使用 stargazer。问题是它们不相互兼容。有没有支持这两种对象类的命令？
如果没有，我该怎么办？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658650/regression-table-for-fixest-and-plm-models</guid>
      <pubDate>Thu, 12 Dec 2024 22:58:40 GMT</pubDate>
    </item>
    <item>
      <title>和的联合分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658649/joint-distribution-of-sum</link>
      <description><![CDATA[假设 $X_1$ 和 $Y$ 是两个独立且正值的随机变量，其分布为 $F_{X_1}(x_1)$ 和 $F_{Y}(y)$。
现在，我们定义，
$X_2 = X_1 + Y$
$X_1$ 和 $X_2$ 的联合概率分布是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658649/joint-distribution-of-sum</guid>
      <pubDate>Thu, 12 Dec 2024 22:22:44 GMT</pubDate>
    </item>
    <item>
      <title>支持完全交叉研究设计的评分者间信度系数</title>
      <link>https://stats.stackexchange.com/questions/658648/inter-rater-reliability-coefficients-that-support-fully-crossed-study-designs</link>
      <description><![CDATA[我需要计算一项研究的评分者间信度，该研究有大约 100 名评分者针对 12 个研究对象进行。
评分是无顺序或排名的名义数据。
根据 Hallgren 2012，对于评分者不是针对每个受试者随机抽样的情况，Fleiss&#39; Kappa 不是一种选择。
相反，他建议使用 Light&#39;s kappa 或 Davies &amp;而是使用 Fleiss 的 kappa。
但是，Gwet 2014 不鼓励使用 Light 的 kappa，因为“对多个成对 kappa 系数求平均值将产生没有明确含义的测量值”。
对于 Davies &amp; Fleiss 的 kappa，我在 R 中找不到任何可以使用的实现。
目前尚不清楚 Gwet 手册中推荐的其他系数（如 Conger 的 Kappa、Gwet 的 AC1 或 Krippendorf 的 Alpha）是否也适用于完全交叉设计。
或者研究设计最终不是什么大问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658648/inter-rater-reliability-coefficients-that-support-fully-crossed-study-designs</guid>
      <pubDate>Thu, 12 Dec 2024 22:10:00 GMT</pubDate>
    </item>
    <item>
      <title>“群体间协议”的适当指标</title>
      <link>https://stats.stackexchange.com/questions/658647/appropriate-metrics-for-inter-group-agreement</link>
      <description><![CDATA[我需要比较发给两组不同评分员的问卷结果，并以某种方式量化两组之间的一致性。
问卷中有 12 个问题涉及对某些要求句子的解释，第一组约有 100 名独立评分员回答了这些问题，第二组约有 40 名独立评分员回答了这些问题。
收集的结果数据是无序或无排名的名义数据。
以下是数据摘录：
 V1 V2 V3 V4 V5 
&lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;
1 2 2 3 2 1 
2 2 2 3 2 1 
3 1 4 4 4 1 
4 2 3 3 3 2 
5 1 1 4 2 4 
6 2 2 3 2 2 
7 1 1 3 1 1 
8 2 3 3 2 2 
9 2 2 3 3 3 
10 2 3 3 2 2 

列代表不同的评估者，而每行代表问卷的一个研究对象，可以从 1-3 或 1-4 进行评分（再次，名义数据）。
对于单个评估者组，我可以使用常见的评估者间信度指标（如 Lights&#39; Kappa）轻松计算“组内”一致性水平。
事实上，我已经这样做了，发现第一组 Kappa 为 0.218，第二组 Kappa 为 0.758（使用 R 包 irr 中的 kappam.light 计算）之间存在显著差异。
因此，看起来第二项研究中的组内一致性大幅提高。
但如果评级与第一组中最常见的评级相差很大，这对我没有帮助。
在这种情况下，我将如何计算“组间一致性”的水平。
我能做的就是将第一组的结果与第二组的结果相结合（即合并/连接表格）并计算联合 IRR。这将向我展示整体一致性，同时将两个组视为一个大组。
但这真的能量化第一组与第二组的响应有多接近吗？
如果是，我需要有相等的组大小吗？
或者是否有专门设计用于比较两组之间一致性水平的指标？
我在这里找到了一个类似的问题，但在这种情况下，作者处理的是序数数据。
这里建议计算和比较两组的平均值，然后进行统计显着性检验，这对于名义数据来说可能没有多大意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/658647/appropriate-metrics-for-inter-group-agreement</guid>
      <pubDate>Thu, 12 Dec 2024 21:10:21 GMT</pubDate>
    </item>
    <item>
      <title>重复测量二元变量的 Cohen Kappa</title>
      <link>https://stats.stackexchange.com/questions/658643/cohens-kappa-for-repeated-measures-binary-variables</link>
      <description><![CDATA[我进行了一项实验，展示了两种类型的广告信息：第一种类型具有理性风格，第二种具有感性风格。样本多次接触这些信息（重复测量），每次我都会进行问卷调查，询问这些信息是理性的还是感性的。所以我有一个 2x2 矩阵，其中变量 1 是信息类型（理性/感性），变量 2 是信息的识别（理性/感性）。因此，两个变量都是二元名义分类变量。
我想进行操纵检查，看看受试者是否正确识别了信息风格，我应该使用哪种一致性测试？我考虑过 Cohen 的 kappa，但就我而言，我进行了重复测量，并且我读到这可能不是正确的测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/658643/cohens-kappa-for-repeated-measures-binary-variables</guid>
      <pubDate>Thu, 12 Dec 2024 20:35:46 GMT</pubDate>
    </item>
    <item>
      <title>具有排列标准误差的 Wald 检验？</title>
      <link>https://stats.stackexchange.com/questions/658642/wald-test-with-permutation-standard-error</link>
      <description><![CDATA[许多统计检验都基于 Wald 类 z 统计量：$z = \frac{\hat{\theta} - \theta_0}{\text{SE}(\hat{\theta})}$，其中 $\theta$ 是感兴趣的参数，$\theta_0$ 是零假设下的值，SE 是标准误差。然后可以通过将 $z$ 与标准正态 (0,1) 分布进行比较来计算 p 值。
我想知道是否可以基于 $\theta$ 的置换零分布来估计 z 检验中的标准误差？或者 z 检验的标准误差是否应始终在备择假设下计算？
更多上下文：
我知道我可以直接从置换分布计算 p 值，但就我而言，我正尝试进行荟萃分析，这需要每个队列的点估计和标准误差。但是，我使用的统计数据没有封闭形式的标准误差估计，但我已经有了统计数据的置换零分布。我可以只使用置换分布的标准误差进行荟萃分析吗？
我使用的统计数据是来自 GSEA 的“标准化富集分数”(NES)。 NES 没有标准误差公式，而是使用置换检验来计算其 p 值。我想知道是否可以使用置换分布的标准差作为元分析的标准误差估计量。
编辑：这个答案似乎表明在置换零分布下估计标准误差是可以的，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/658642/wald-test-with-permutation-standard-error</guid>
      <pubDate>Thu, 12 Dec 2024 20:35:35 GMT</pubDate>
    </item>
    <item>
      <title>试验次数的二项置信区间</title>
      <link>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</link>
      <description><![CDATA[我有一个过程，其成功概率为已知$p$，失败概率为$q = 1-p$。该过程重复有限但未知的次数$n$。
给定成功次数$r$（失败次数$n-r$，未知），我们应该如何确定导致$r$次成功的试验次数的置信区间？
举一个简单的例子，一枚公平的硬币总共被抛了$n$次，其中150次正面朝上落地。 $n$ 是如何分布的，其平均值的 95% 置信区间是多少，涵盖 $n$ 最可能的值。最可能的$n$ 为 300，最小的$n$ 为 150，最大的$n$ 为无穷大，但我们如何考虑介于两者之间的一切？
注意：如果分布不对称，间隔不必以平均值为中心。

我一直在研究威尔逊分数和其他二项比例置信区间，它们是相关的，但它们估计的是$p$，而不是$n$。我想知道是否存在类似的方法可以准确地找到我所寻找的内容。
由于缺乏估计量的封闭公式，我只能尝试通过拟合两个高斯分布来找到我的置信区间$(n_{low}, n_{high})$的端点，这两个高斯分布的均值为$n_{low}p$和$n_{high}p$，其中$n\hat{p}$（其中$\hat{n} = r/p$是我估计的$n$）落在其 2.5% 面积尾部边界上，使用表格。
（这是我对此的第一个问题论坛）]]></description>
      <guid>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</guid>
      <pubDate>Thu, 12 Dec 2024 17:08:40 GMT</pubDate>
    </item>
    </channel>
</rss>