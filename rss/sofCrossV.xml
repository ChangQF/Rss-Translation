<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 03 Jan 2025 12:32:08 GMT</lastBuildDate>
    <item>
      <title>如何找到与“先知”影响力评估最相关的值？</title>
      <link>https://stats.stackexchange.com/questions/659483/how-to-find-the-most-correlated-values-for-a-prophet-impact-evaluation</link>
      <description><![CDATA[我正在不太理想的条件下设置 A/B 测试，并计划使用 Prophet 进行评估。以下是我正在考虑的方法：

将 Prophet 应用于实验前数据，使用对照组作为系数。
使用模型的预测作为“虚拟”对照组来估计实验期间的影响。

实验涉及同一国家/地区的约 50 个城市，由于法律限制，这些城市必须分为两组：25 个对照组和 25 个治疗组。确保对照组和治疗组以 Prophet 可以处理的方式高度相关对于获得有用的结果非常重要。
我的问题是：如何使用 Prophet 评估对照组是否适合这种方法？具体来说：

我是否应该在实验前阶段迭代不同的城市划分并根据 Prophet 的 RMSE（均方根误差）评估它们的拟合度？
我是否应该在实验前阶段最小化两组之间的“ATE”？
是否有更好的指标/方法来选择和验证最佳划分？
]]></description>
      <guid>https://stats.stackexchange.com/questions/659483/how-to-find-the-most-correlated-values-for-a-prophet-impact-evaluation</guid>
      <pubDate>Fri, 03 Jan 2025 10:08:01 GMT</pubDate>
    </item>
    <item>
      <title>以家庭为分析单位的二元逻辑数据准备</title>
      <link>https://stats.stackexchange.com/questions/659482/data-preparation-for-binary-logistic-with-households-as-a-unit-of-analysis</link>
      <description><![CDATA[我试图对不同的因素进行二元逻辑分析，以确定哪些因素影响了研究现象。这些数据针对的是特定年龄以上的人群。这意味着不同家庭的人数各不相同。我被告知分析单位应该是家庭，这意味着 Excel 电子表格中的每一行都应该代表一个家庭，最初它代表一个人，如下所示：
实践区域年龄性别教育就业
否城市 31-50 女性中学就业
否城市 31-50 女性高等教育就业
是城市 31-50 女性高等教育就业

假设上述数据（3 人）都在一个家庭中，我如何在 Excel 电子表格中准备以家庭为分析单位的相同数据？因变量是实践。]]></description>
      <guid>https://stats.stackexchange.com/questions/659482/data-preparation-for-binary-logistic-with-households-as-a-unit-of-analysis</guid>
      <pubDate>Fri, 03 Jan 2025 09:49:13 GMT</pubDate>
    </item>
    <item>
      <title>GARCH 标准化残差中的自相关性是否不利于创建新闻影响曲线？</title>
      <link>https://stats.stackexchange.com/questions/659480/is-autocorrelation-in-garch-standardized-residuals-bad-for-creation-of-news-impa</link>
      <description><![CDATA[我已经对各种 MSCI 指数和时间段进行了 GJR-GARCH(1,1) 估计。标准化残差平方中没有自相关 (AC)，但标准化残差中有一些。我想使用估计值来计算新闻影响曲线。由于波动性的依赖关系似乎被正确建模，标准化残差中的 AC 对我的目标来说可以忽略不计吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659480/is-autocorrelation-in-garch-standardized-residuals-bad-for-creation-of-news-impa</guid>
      <pubDate>Fri, 03 Jan 2025 09:00:55 GMT</pubDate>
    </item>
    <item>
      <title>他们如何得到类别平衡损失中有效样本数量的公式？</title>
      <link>https://stats.stackexchange.com/questions/659479/how-they-have-that-formula-of-effective-number-of-samples-in-class-balance-loss</link>
      <description><![CDATA[我偶然看到了这篇论文：基于有效样本数的类平衡损失，但我有些观点不太明白：

(1) 图 1 的含义：这条线是否显示了两个类之间的分类边界？红线是在加权损失中应用 1/n 时，黑线表示无权重，蓝线表示提出的方法。然后我可以看到 1/n 可能会对损失进行过度惩罚，正如论文中的意思：n 个样本集中的数据点之间可能存在一些重叠 -&gt; 真正有意义的数据点小于 n，那么用 1/n 惩罚太难了 -&gt;从图中可以看出，少数类主导多数类，因为它们对梯度的贡献不大，虽然它们有很多样本，但梯度几乎减少了

(2) 方程 (3) 出自哪里？我对这个方程有一点了解，但不知道他们是如何得到这个公式的，他们还提到了 N 中的原型。我只是不明白它们是如何相互关联的。

(3) 我需要将 A 类的数量下采样到 E_n 吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/659479/how-they-have-that-formula-of-effective-number-of-samples-in-class-balance-loss</guid>
      <pubDate>Fri, 03 Jan 2025 07:16:36 GMT</pubDate>
    </item>
    <item>
      <title>如何估计两个坐标系之间的旋转和平移？</title>
      <link>https://stats.stackexchange.com/questions/659476/how-can-i-estimate-the-rotation-and-translation-between-two-cooordinate-frames</link>
      <description><![CDATA[我在两个坐标系（xyz 和 XYZ）中测量了 N 个点 p 的 3D 尺寸：
$$
p_i: \mathbf{x_i}, \mathbf{X_i} 
$$
坐标系相互旋转和平移：
$$
\mathbf{X_i} = T\mathbf{x_i} + \mathbf{\epsilon_i} 
$$
其中
$$
\mathbf{X_i} = 
\begin{bmatrix}X_i\\Y_i\\Z_i\\1\end{bmatrix}
$$
$$
\mathbf{x_i} = 
\begin{bmatrix}x_i\\y_i\\z_i\\1\end{bmatrix}
$$
和
$$
T=\begin{bmatrix}
R_{11} &amp; R_{12} &amp; R_{13} &amp; t_x \\ 
R_{21} &amp; R_{22} &amp; R_{23} &amp; t_y \\
R_{31} &amp; R_{32} &amp; R_{33} &amp; t_z \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
$$
其中 $R_{ij}$ 是 (正交) 3x3 旋转矩阵的元素，$\mathbf{t}=[t_x,t_y,t_z]^T$ 是平移向量，$\mathbf{\epsilon_i} \sim N(0, \sigma)$ 是随机测量误差 (噪声)。
请注意：
$$
\mathbf{X}\mathbf{x^T}=T\mathbf{x}\mathbf{x^T}
$$
$$
T=\mathbf{X}\mathbf{x^T}(\mathbf{x}\mathbf{x^T})^{-1}
$$
以上是根据 $\mathbf{x_i}$ 和 $\mathbf{X_i}$ 的测量值对 T 进行的普通最小二乘 (OLS) 估计。
但是有一个问题；
解决方案的准确性似乎取决于我用于位置的单位。
如果我使用 [hm] (100 m) 作为单位，准确性似乎很差。
如果我使用 [m]，精度似乎还不错，如果我使用 [mm]，精度似乎非常好：
*** Fasit ***
tx：1.000000，ty：2.000000，tz：3.000000
alpha：10.000000，beta：20.000000，gamma：30.000000

*** 单位：[hm] ***
条件编号：232324.8662558334
tx：0.599922，ty：1.755050，tz：2.623534
alpha：-28.609880，beta：50.146974，gamma：-18.499170

*** 单位：[m] ***
条件编号：31.840163979691628
tx：0.995999，ty：1.997551，tz：2.996235
alpha：9.789144，beta：20.450505，gamma：29.656265

*** 单位：[cm] ***
条件编号：27664.490644745576
tx：0.999960，ty：1.999976，tz：2.999962
alpha：9.997907，beta：20.004514，gamma：29.996574

*** 单位：[mm] ***
条件number:2765185.887452584
tx: 0.999996, ty: 1.999998, tz: 2.999996
alpha: 9.999791, beta: 20.000451, gamma: 29.999657

为什么会这样？
这是否与问题的同质性有关？
是否有一个通用程序可以用来为（同质）OLS 问题找到最佳单位（和原点）？
这是 python代码我使用了。
我注意到在上面的例子中，当 unit-&gt;mm 时答案似乎会收敛，因此在这种情况下，我可能已经猜到最佳单位是 mm，而不知道旋转和平移。
这也许可以用作启发式方法来找到最佳单位，但我更喜欢更有动力的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/659476/how-can-i-estimate-the-rotation-and-translation-between-two-cooordinate-frames</guid>
      <pubDate>Fri, 03 Jan 2025 00:11:28 GMT</pubDate>
    </item>
    <item>
      <title>理解 Judea Pearl 在《因果关系》中的稳定性分布示例</title>
      <link>https://stats.stackexchange.com/questions/659475/understanding-stability-distribution-example-in-causality-by-judea-pearl</link>
      <description><![CDATA[在因果关系：模型、推理和推论的第 2.4 节“稳定分布”中，Judea Pearl 通过一个简单的“三元组”引出了稳定性的概念。示例如下：

总结一下，本段中的三元组 $(A, B, C)$ 是根据以下公式设置的：

$A, B \text{ i.i.d.} \sim \mathrm{Bin}(1, p)$，其中 $p = 1/2$；
变量 $C$ 则为定义为 $C = I_{\{A = B\}}$。

我对本段有两个问题。

我很难理解突出显示的断言。&quot;面对不断变化的参数化&quot;，即设置 $p \neq 1/2$，然后很容易验证 $A, B, C$ 之间的独立模式不再成立，即使在自然结构 $A \rightarrow C \leftarrow B$ 下也是如此。例如，简单的计算表明
\begin{align*}
P(A = 1, C = 1) = p^2 \neq p(2p^2 - 2p + 1) = P(A = 1)P(C = 1)。
\end{align*&gt;
如果是这样，作者怎么还能声称“正确的结构将保留其独立模式”？我误解了这里的任何关键见解吗？
我明白当$p = 1/2$时，有三个最小因果结构与依赖约束兼容。但在我看来，只有当我们完全抹去$C$的具体定义（即$C = I_{\{A = B\}}$），而仅仅将$A, B, C$视为三个无关的二元变量时，这种说法才合理。如果是这样，作者所说的只有“$A \rightarrow C \leftarrow B$”才是“正确的结构”又是什么意思呢？如果我们仍然接受$C$的原始定义，那么如何明确地描述除$A \rightarrow C \leftarrow B$之外的其余两个因果结构呢？我在这里感到困惑的是，鉴于 $C$ 已经是 $A$ 和 $B$ 的函数，将 $C$ 视为 $A$ 或 $B$ 的原因在逻辑上是否正确？

由于此示例在证明定义后续关键因果关系概念（例如潜在原因和虚假关联）的动机方面起着非常重要的作用（请参阅此帖子中的讨论），如果有人能对我的问题提供深刻的澄清，那就太好了问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/659475/understanding-stability-distribution-example-in-causality-by-judea-pearl</guid>
      <pubDate>Thu, 02 Jan 2025 23:09:00 GMT</pubDate>
    </item>
    <item>
      <title>与马尔可夫随机场相比，加入 $P(x_i \mid y_i)$ 对马尔可夫链中的依赖结构有何影响？</title>
      <link>https://stats.stackexchange.com/questions/659473/how-does-the-inclusion-of-px-i-mid-y-i-affect-the-dependency-structure-in-m</link>
      <description><![CDATA[我试图理解马尔可夫链的依赖结构以及它与马尔可夫随机场 (MRF) 的依赖结构相比如何，特别是在引入观察变量 $ x_i$ 时。
对于具有观测值的马尔可夫链，联合分布由以下公式给出：
$$
P(y, x) = P(y_0) \prod_{i=1}^n P(y_i \mid y_{i-1}) P(x_i \mid y_i),
$$
其中：
$P(y_i \mid y_{i-1})$ 表示隐藏状态 $y_i$ 的顺序依赖关系，
$P(x_i \mid y_i)$ 编码了给定当前隐藏状态的观测可能性。
相比之下，对于马尔可夫随机场 (MRF)，联合分布通常以团的形式表示：
$$
P(y, x) \propto \exp\left(-\sum_{\text{cliques } C} \phi_C(y_C, x_C)\right),
$$
其中 $\phi_C$ 表示无向图中团 $C$ 上的潜在函数。

在马尔可夫链中，$P(x_i \mid y_i)$ 的加入增加了 $y_i$ 和 $x_i$，但这是否意味着
分布依赖于 $y_i$ 和 $x_i$，类似于 MRF 如何依赖于 $N(y_i)$ 中的邻居？
在马尔可夫链中添加 $P(x_i \mid y_i)$ 是否会引入
多维依赖关系，还是该过程仍然基本上是一维的（具有顺序结构）？
在马尔可夫链中，$P(x_i \mid y_i)$ 引入的依赖关系如何马尔可夫链在概念上与 MRF 中的邻域依赖关系 $P(y_i
\mid N(y_i))$ 有所不同？

如果您能澄清这些模型在依赖结构方面的根本区别，以及 $P(x_i \mid y_i)$ 在这些区别中扮演什么角色，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659473/how-does-the-inclusion-of-px-i-mid-y-i-affect-the-dependency-structure-in-m</guid>
      <pubDate>Thu, 02 Jan 2025 22:15:47 GMT</pubDate>
    </item>
    <item>
      <title>如何从逻辑回归的引导程序中获取 p 值？</title>
      <link>https://stats.stackexchange.com/questions/659465/how-to-obtain-p-values-from-a-bootstrap-of-a-logistic-regression</link>
      <description><![CDATA[我有一个二元响应变量y和一组协变量(x_1, x_2, ..., x_n)。在执行多元逻辑回归时（在我的例子中使用 R 和 glm 函数：glm(y ~ x1 + x2 + x3 + ... + xn, family = binomial)），我可以获得 $p$ 值来检验协变量的系数是否显著，即 $H_0:\beta_j = 0$。
由于我的数据的维度（超过 100000 行和 5000 列），我无法执行多元逻辑回归来获取 $p$ 值（我的数据已经过过滤，即我无法执行变量选择）。我有如此庞大的数据集，以至于我必须对数据进行子采样才能容纳在我的计算机内存中。因此，我选择执行引导程序（b=引导样本数），但在子样本中（占总行数的 $p\%$）以获得多元逻辑回归的系数，如下所示：

我使用替换执行行选择，保持采样的二进制响应变量中 0/1 值的分布，以行的形式降低数据集的维数。
我将 glm 函数拟合到简化的数据集并获得系数和 p 值。
我重复此过程 b 次，获得系数和 p 值的向量。

每个变量的最终系数（在原始数据集中）是每个引导样本中获得的系数之间的平均值。
我的问题是：向量的平均值是多少每个样本中获得的 p 值是最终的 p 值吗？
恐怕不是，但在这种情况下，我如何获得逻辑回归引导程序的 p 值？
您肯定会建议我使用惩罚逻辑回归 (lasso)。我已经尝试过了，计算速度非常快。但是，使用后者，我仍然无法获得这些系数显著性的 p 值。如果您有关于如何获得这些最后的 p 值的参考，这对我也很有用。]]></description>
      <guid>https://stats.stackexchange.com/questions/659465/how-to-obtain-p-values-from-a-bootstrap-of-a-logistic-regression</guid>
      <pubDate>Thu, 02 Jan 2025 19:07:17 GMT</pubDate>
    </item>
    <item>
      <title>三维位置的 James-Stein 估计器</title>
      <link>https://stats.stackexchange.com/questions/659442/james-stein-estimators-for-position-in-3d</link>
      <description><![CDATA[假设我在 3D 中测量一个位置：$(x,y,z)$ 并且我假设 $X,$ $Y,$ 和 $Z$ 呈正态分布，方差（测量误差）相同：
$$
X \sim N(\mu_X,\sigma)
$$
$$
Y \sim N(\mu_Y,\sigma)
$$
$$
Z \sim N(\mu_Z,\sigma)
$$
使用以下估计量似乎很直观：
$$
\hat{\mu}_X = x
$$
$$
\hat{\mu}_Y = y
$$
$$
\hat{\mu}_Z = z
$$
James-Stein 估计量是否：
$$
\hat{\mu}_X = \operatorname{ReLU}\left(1-\frac{\sigma^2}{x^2+y^2+z^2}\right)x
$$
$$
\hat{\mu}_Y = \operatorname{ReLU}\left(1-\frac{\sigma^2}{x^2+y^2+z^2}\right)y
$$
$$
\hat{\mu}_Z = \operatorname{ReLU}\left(1-\frac{\sigma^2}{x^2+y^2+z^2}\right)z
$$
在这种情况下？
James-Stein 估计量的 MSE 是否低于直观估计量？
如果是这样，是否可以给出直观的解释？
例如，让我们假设：
$$
x = y = z = 1, \sigma = 0.005
$$
在这种情况下：
$$
\hat{\mu}_X = 0.999992x
$$
那么 James-Stein 估计量和直观估计量之间的差异在这种情况下似乎可以忽略不计？]]></description>
      <guid>https://stats.stackexchange.com/questions/659442/james-stein-estimators-for-position-in-3d</guid>
      <pubDate>Thu, 02 Jan 2025 08:39:50 GMT</pubDate>
    </item>
    <item>
      <title>如何估计两个坐标系之间的旋转？</title>
      <link>https://stats.stackexchange.com/questions/659430/how-can-i-estimate-the-rotation-between-two-cooordinate-frames</link>
      <description><![CDATA[我在两个坐标系（xyz 和 XYZ）中测量了 N 个点 p 的三维尺寸：
$$
p_i: \vec{xm_i}, \vec{Xm_i} 
$$
我将测量模型化为：
$$
\vec{xm_i} = \vec{x_i} + \vec{\epsilon_i}
$$
$$
\vec{Xm_i} = \vec{X_i} + \vec{\epsilon&#39;_i}
$$
并且
其中 $\vec{x_i}$ 和 $\vec{X_i}$ 是实际尺寸坐标位置（确定性，非随机性）和$\vec{\epsilon_i} \sim \mathcal{N}(0,\sigma)$和$\vec{\epsilon_i&#39;} \sim \mathcal{N}(0,\sigma)$是测量噪声。
坐标系相对于彼此旋转：
$$
\vec{X_i} = R\vec{x_i} 
$$
其中
$$
\vec{X_i} = 
\begin{bmatrix}X_i\\Y_i\\Z_i\end{bmatrix}
$$
$$
\vec{x_i} = 
\begin{bmatrix}x_i\\y_i\\z_i\end{bmatrix}
$$
并且 $R(\alpha,\beta,\gamma)$ 是 3x3 旋转矩阵：

对于 $\alpha$、$\beta$ 和 $\gamma$ 以及为什么？
到目前为止，我所做的是最小化：
$$
\underset{\alpha,\beta,\gamma}{\mathrm{argmin}} 
\{SE(\alpha,\beta,\gamma) = \Sigma_i |R\vec{x_i} - \vec{X_i}|^2\} 
$$
使用 Levenberg-Marquardt 算法 (scipy.optimize.least_squares)。
但是，我仅考虑了这种方法中的 $\vec{\epsilon&#39;_i}$ 错误。我还想考虑 $\vec{\epsilon_i}$ (总最小二乘法) 中的错误。
解决这个问题是否只需最小化：
$$
\underset{\alpha,\beta,\gamma}{\mathrm{argmin}} 
\{TSE(\alpha,\beta,\gamma) = \Sigma_i [|R\vec{x_i} - \vec{X_i}|^2 + |R^{-1}\vec{X_i} - \vec{x_i}|^2]\} 
$$
代替？
此外，我使用 $L_2$ 范数 (最小二乘法)，因为这似乎是标准做法。但为什么它比其他估计器更好呢？为什么不使用 $L_1$ 或 $L_{\infty}$ 呢？
我创建了一个 pandas 测试数据集。
这里我使用了$\alpha = 1°$、$\beta = 2°$和$\gamma = 3°$，并在$\vec{x}$和$\vec{X}$中添加了$\sigma = 0.01$的噪声。
这是我用Python实现的线性求解器。
它产生了以下输出：
实际旋转矩阵：
[[ 0.9980212 -0.05171974 0.03575975]
[ 0.05230407 0.99850932 -0.01560227]
[-0.0348995 0.01744177 0.99923861]]
估计旋转矩阵：
[[ 1.00228603 -0.06671378 0.0452653 ]
[ 0.04621024 0.97714644 -0.01505205​​]
[-0.02123221 0.01683688 1.00103115]]
alpha: 0.971802, beta: 1.886494, gamma: 3.266041

这里我取了 100 个解决方案的平均值（因为估计值是随机变量）。
结果相当不错，但有一个缺陷：
估计的旋转矩阵不正交。
每行的范数应该是 1，但第一行和最后一行都有元素 &gt; 1。
这是我从 Aksakals 的回答中实现的另一个线性求解器 2。它给出的结果与第一个线性求解器完全相同。
这是用 Python 实现的非线性求解器。
它产生了以下输出：
不对称：alpha：1.382373，beta：1.677021，gamma：3.002319
对称：alpha：1.382373，beta：1.677019，gamma：3.002318

总体最小二乘结果（对称）几乎与最小二乘结果（不对称）完全相同。这里我也取了 100 个解决方案的平均值（因为估计值是随机变量）。]]></description>
      <guid>https://stats.stackexchange.com/questions/659430/how-can-i-estimate-the-rotation-between-two-cooordinate-frames</guid>
      <pubDate>Wed, 01 Jan 2025 22:27:53 GMT</pubDate>
    </item>
    <item>
      <title>理解两个孩子问题的直觉</title>
      <link>https://stats.stackexchange.com/questions/659395/understanding-intuition-of-the-two-child-problem</link>
      <description><![CDATA[受到此推特帖子的启发，发布了这个问题：

我有两个孩子，（至少）其中一个是男孩，出生在星期二

两个孩子都是男孩的概率是多少？


通过Joel Grus，这里是一个建议的答案：

总共 196 种可能性（每种（性别、天）的概率均等）27那些
至少一个星期二男孩（13 个较小的星期二男孩，较大的不是；13 个较大的
星期二男孩，较小的不是，1 个都）其中 13 个都是男孩（6，6，1）所以
13 / 27

这似乎是正确的。但同时也令人困惑。这让我们觉得我们可以任意地以我们知道是真实的任何事物为条件（例如，婴儿出生在银河系；或者婴儿的父母说英语），并以某种方式使用它来改变后验概率。有人能把我从这引起的存在主义困境中解救出来吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659395/understanding-intuition-of-the-two-child-problem</guid>
      <pubDate>Tue, 31 Dec 2024 09:34:01 GMT</pubDate>
    </item>
    <item>
      <title>线性 PDF 近似</title>
      <link>https://stats.stackexchange.com/questions/659391/linear-pdf-approximation</link>
      <description><![CDATA[鉴于我的数据不完整，我正在尝试估算帕累托分布 PDF 的形状参数 alpha。具体来说，真实数据集的值介于 $10$ 和 $50,$ 之间，但我观察到的数据仅涵盖 $25$ 到 $50$ 之间的范围（即，我缺少 $10$ 和 $25$ 之间的所有数据）。我的挑战是在给定这些缺失数据的情况下恢复正确的 alpha 值。
背景
帕累托分布由两个参数定义：

alpha（形状参数，决定尾部的斜率）和
xmin（分布的最小值）。

如果我尝试将帕累托分布直接拟合到观察到的数据，则存在两个问题：

如果我设置 xmin${}= 10$（真正的最小值），则拟合无效，因为我的数据不包含低于 25 的值，并且 alpha 不正确。
如果我设置 xmin${}= 25$（我观察到的数据的最小值），则估计的 alpha 不正确，因为它没有考虑到缺失的部分数据。

关键见解
帕累托分布的一个关键特性是，当在对数对数空间 log​​10(x) vs. log10(y) 中绘制时，其概率密度函数 (PDF) 形成一条直线。该线的斜率与形状参数 alpha 的关系为：
$$\text{slope} = -(\alpha + 1)$$
此属性表明，即使缺少大部分数据，我仍然可以通过将观察到的数据转换为对数对数空间、将直线拟合到结果点并使用斜率计算 alpha 来恢复 alpha。
问题
困难在于为观察到的数据构建 PDF。由于我只有一个数据值向量，因此我没有直接的 PDF（或密度值）。这基本上意味着，如果我尝试构建一条直线来恢复 alpha，我有 $x$，但没有 $y.$。为了近似密度，我尝试了以下方法：

使用核密度估计（通过 R 的 density() 函数）生成 PDF 的平滑近似值。

将 $x$ 值（数据）和 $y$ 值（密度估计）转换为 log10 空间，将结果拟合成一条线，并使用斜率估计 alpha。


这是核密度方法的一个例子，但我并不坚持它。
# 模拟观测数据
set.seed(123)
data &lt;- rpareto(1000, alpha = 2, xmin = 10) # 真实数据
observed_data &lt;- data[data &gt;= 25] # 截断到观测范围

# 使用核平滑估计密度
density_est &lt;- density(observed_data, from = 25, to = 50)
log_x &lt;- log10(density_est$x)
log_y &lt;- log10(density_est$y)

# 在对数对数空间中拟合线性模型
lm_fit &lt;- lm(log_y ~ log_x)

# 提取斜率并计算 alpha
slope &lt;- coef(lm_fit)[2]
alpha_est &lt;- -slope - 1

alpha_est

问题

在这种情况下，是否有更原则或更稳健的方法来近似观察到的数据的 PDF，特别是考虑到缺失数据的方法？
有没有办法近似线性 PDF？我知道它并不存在，但有解决方法吗？
为此目的使用核密度估计是否存在任何理论或实践陷阱？
]]></description>
      <guid>https://stats.stackexchange.com/questions/659391/linear-pdf-approximation</guid>
      <pubDate>Tue, 31 Dec 2024 02:55:47 GMT</pubDate>
    </item>
    <item>
      <title>$\text{U}(0, \theta)$ 中 ${θ}/{2}$ 的置信区间</title>
      <link>https://stats.stackexchange.com/questions/659276/confidence-interval-for-%ce%b8-2-in-textu0-theta</link>
      <description><![CDATA[我试图找到 ${\theta}/{ 2}$ 的置信区间，置信度为 $1-\alpha$（使用 $p_1 = \alpha$ 和 $p_2 = 1$ 处的分位数）。因此，我采用 ${\hat{\theta}}/{2} = {X_{(n)}}/{2}$ 的无偏估计量。然后从我们在课堂上学到的知识：
$$\mathbb{P} \bigg( \dfrac{cX_{(n)}}{2\theta} \leqslant q_{p_1} \bigg)
= \mathbb{P} \bigg( \dfrac{X_{(n)}}{\theta} \leqslant \dfrac{2q_{p_1}}{c} \bigg)
= \alpha
= \bigg( \dfrac{2q_{p_1}}{c} \bigg)^n,$$
这意味着 $q_{p_1}=\tfrac{c}{2}\alpha^{{1}/{n}}$ 并且对于 $q_{p_2}$ 将给我们 $q_{p_2} = {c}/{2}$。由此得出：
$$\mathbb{P} \bigg( \dfrac{c}{2}\alpha^{{1}/{n}} \leqslant \dfrac{cX_{(n)}}{\theta} \leqslant \dfrac{c}{2} \bigg)
= \mathbb{P} \bigg( X_{(n)} \leqslant \dfrac{\theta}{2} \leqslant \dfrac{X_{(n)}}{\alpha^{{1}/{n}}} \bigg)
= 1-\alpha,$$
因此得出的 CI 为：
$$\dfrac{\theta}{2} \in \bigg[ X_{(n)}, \dfrac{X_{(n)}}{\alpha^{{1}/{n}}} \bigg].$$
这看起来正确吗？还是我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659276/confidence-interval-for-%ce%b8-2-in-textu0-theta</guid>
      <pubDate>Fri, 27 Dec 2024 21:45:01 GMT</pubDate>
    </item>
    <item>
      <title>巴洛双胞胎如何避免因仿射变换而不同的嵌入？</title>
      <link>https://stats.stackexchange.com/questions/659039/how-barlow-twins-avoid-embeddings-that-differ-by-affine-transformation</link>
      <description><![CDATA[我正在阅读 Barlow Twins (BT) 论文，但就是不明白它如何避免以下情况。
当互相关矩阵等于单位矩阵时，BT 损失最小化。实现这一点的必要条件是 $C_{ii}$ 对角线元素为 1。这可以通过两种不同的方式实现。对于每个 $x$:

$z_A = z_B$
$z_A = a\cdot z_B + b$

其中 $z_A$ 和 $z_B$ 是同一输入 $x$ 的增强。换句话说，嵌入可以不同，但​​这种差异被掩盖了，因为：$corr(X, aX + b) = corr(X, X) = 1$。
直观地说，如果我们的目标是学习对扭曲不变的表示，那么应该避免第二种解决方案。有什么想法可以驱动网络避免这种情况吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659039/how-barlow-twins-avoid-embeddings-that-differ-by-affine-transformation</guid>
      <pubDate>Fri, 20 Dec 2024 23:56:38 GMT</pubDate>
    </item>
    <item>
      <title>在成对 Wilcoxon 检验中选择 p 调整方法</title>
      <link>https://stats.stackexchange.com/questions/653019/choosing-p-adjustment-method-in-pairwise-wilcoxon-test</link>
      <description><![CDATA[我需要一些帮助来选择 p 调整方法，以在四个不同独立组的权重上进行成对 Wilcoxon 检验（使用 R）。
我一直在阅读有关不同方法的文章，并在 Google 上搜索了大量答案。我是统计学新手，不幸的是，其中许多方法变得过于复杂，但我的结论是方法取决于数据。所以我想知道是否有人可以根据我的数据给我一些提示或指导（见下面的测试结果）。
我已经测试了所有可用的方法（“bonferroni”、“holm”、“hochberg”、“hommel”、“BH”、“BY”），除了 Benjamini 和Yekutieli 方法。
如果有人知道根据数据选择方法的一般准则，请告诉我（我找不到任何准则）。
我的测试结果如下：
BH 方法（作为示例 - 除了 BY 之外，N-A 的 p.adj 值对所有值都相同）：
 .y. group1 group2 n1 n2 统计 p p.adj p.adj.signif
&lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
1 权重 S N 127 7696 478037 0.673 0.673 ns 
2 权重 S A 127 164 11542 0.113 0.226 ns 
3 权重 S T 127 195 11720 0.417 0.625 ns 
4 权重 N A 7696 164 711349 0.005 0.031 * 
5 权重 N T 7696 195 734472 0.613 0.673 ns 
6 权重 A T 164 195 14233 0.073 0.219 ns 

按方法：
 .y. group1 group2 n1 n2 统计 p p.adj p.adj.si
&lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
1 权重 S N 127 7696 478037 0.673 1 ns 
2 权重 S A 127 164 11542 0.113 0.554 ns 
3 权重 S T 127 195 11720 0.417 1 ns 
4 权重 N A 7696 164 711349 0.005 0.077 ns 
5 权重 N T 7696 195 734472 0.613 1 ns 
6 权重 A T 164 195 14233 0.073 0.536 ns 

请注意，组 N 的样本比其他组多得多。
两个问题：

哪一个我应该使用什么方法？
为什么 BY 不同？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653019/choosing-p-adjustment-method-in-pairwise-wilcoxon-test</guid>
      <pubDate>Mon, 19 Aug 2024 16:46:59 GMT</pubDate>
    </item>
    </channel>
</rss>