<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 22 Mar 2024 00:57:03 GMT</lastBuildDate>
    <item>
      <title>计算核岭回归中的测试损失</title>
      <link>https://stats.stackexchange.com/questions/643214/computing-test-loss-in-kernel-ridge-regression</link>
      <description><![CDATA[在 Kernel Ridge 回归中，我们有标准损失函数 $$L(\beta) = \|Y-K\beta\|_2^2 + \alpha \beta^T K \beta $$
这里，$K$ 是内核（gram）矩阵。
如果我在训练集上计算 $\beta$，那么 $K$ 就是训练克矩阵，假设我想在测试损失中包含正则化项，那么如何计算测试损失？我是否应该将 $L(\beta)$ 中出现的两次 $K$ 替换为测试版本？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/643214/computing-test-loss-in-kernel-ridge-regression</guid>
      <pubDate>Fri, 22 Mar 2024 00:18:22 GMT</pubDate>
    </item>
    <item>
      <title>III 型 ANCOVA 是否有保证？</title>
      <link>https://stats.stackexchange.com/questions/643210/is-type-iii-ancova-warranted</link>
      <description><![CDATA[我正在运行以下 ANCOVA：
m1 &lt;- aov(公式 = 比率 ~ 处理 * 物种 * 重量，数据 = 数据)
汽车::方差分析（m1，类型 = 2）

我的设计有点不平衡，所以我运行了 II 型方差分析。我得到了这些结果：
响应：速率
                                         Sum Sq Df F 值 Pr(&gt;F)
治疗 8.294 2 2.1963 0.120538
种类 22.110 1 11.7097 0.001157 **
重量 6.943 1 3.6771 0.060180 。
处理：种类 1.016 2 0.2692 0.764987
处理：重量 15.985 2 4.2329 0.019320 *
种类：重量 0.058 1 0.0308 0.861229
处理：种类：重量 3.378 2 0.8945 0.414477
残差 107.628 57

基于本文 ，我的理解是，如果您的数据不平衡，您首先运行 II 型方差分析。如果交互作用很显着，那么您应该运行 III 型方差分析。这是正确的吗？
基于治疗和体重之间的显着交互作用，是否需要进行 III 型方差分析？我不确定类型 III 是否应该用于分类变量和连续变量之间的显着交互作用，或者是否仅适用于两个分类变量之间的交互作用。
当我运行 III 型方差分析时，治疗和体重之间的显着交互作用消失，并大大改变了结论：
type3 &lt;- list(Treatment = contr.sum, Species = contr.sum)
m2 &lt;- aov(公式 = 比率 ~ 处理 * 物种 * 重量，数据 = 数据，对比 = type3)
m2 &lt;- 汽车::Anova(m2, 类型 = 3)

响应：速率
                                         Sum Sq Df F 值 Pr(&gt;F)
(截距)286.377 1 151.6654＜ 2e-16 ***
处理 10.370 2 2.7461 0.07268 。
种类 3.934 1 2.0832 0.15440
重量 2.174 1 1.1514 0.28777
处理：种类 3.590 2 0.9506 0.39257
处理：重量 5.670 2 1.5015 0.23147
种类：重量 0.302 1 0.1600 0.69065
处理：种类：重量 3.378 2 0.8945 0.41448
残差 107.628 57

感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/643210/is-type-iii-ancova-warranted</guid>
      <pubDate>Thu, 21 Mar 2024 23:31:10 GMT</pubDate>
    </item>
    <item>
      <title>R 中的小样本量和零膨胀计数数据</title>
      <link>https://stats.stackexchange.com/questions/643208/small-sample-sizes-and-zero-inflated-count-data-in-r</link>
      <description><![CDATA[我正在努力在 R 中为包含大量零的种子发芽计数数据创建一个模型（约占 264 个总观测值的 50%）。目的是确定处理对植物物种整体和个体的影响。最初，我拟合了一个广义线性混合效应模型（二项式误差结构），尽管我在整个数据集模型中得到了不错的结果，但当我查看单个物种时，该模型无法捕获看似明显的治疗效果，当所有替代情况为 0。例如，以下是仅过滤到具有大约 24 个观察值的一颗种子时模型的摘要输出。输出背后的示例数据也如下。
n&lt;- c(19,20,20,20,20,20,19,19,20,20,20,20,19,20,20,20,20,20,20,20 ,19,19,19,20)
计数&lt;-c(8,11,13,13,15,11,0,0,0,0,0,0,9,9,13,11,14,8,0,0,0,0,0 ,0)
GA&lt;-c(1,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0 ,0)
Sm&lt;-c(1,1,1,0,0,0,1,1,1,0,0,0,1,1,1,0,0,0,1,1,1,0,0 ,0)
光&lt;-c(1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0 ,0)
mod_data&lt;-data.frame(n, 计数, GA, Sm, 光)

&lt;前&gt;&lt;代码&gt;调用：
glm(公式 = cbind(计数, n - 计数) ~ GA + Sm + 光,
    族=二项式，数据= mod_data）

系数：
             估计标准。误差z值Pr(&gt;|z|)
（截距）-23.7210 5592.9950 -0.004 0.997
GA 24.0074 5592.9950 0.004 0.997
钐 -0.2706 0.2627 -1.030 0.303
光 0.2410 0.2627 0.917 0.359

（二项式族的色散参数取1）

    零偏差：23 自由度上为 251.9059
残余偏差：20 个自由度上为 9.9247
工商登记号码：58.669

Fisher 评分迭代次数：20

我最初预计该种子会经过显着的 GA 处理，因为查看原始结果，所有 GA 观察结果产生的计数都比非 GA 结果更高（全部为零）。然而，我后来发现这种类型的模型不使用零，因此不能产生显着的 GA 效果（即使整个模型确实如此）。
这促使我研究零膨胀模型，例如零膨胀负二项式 GLM（使用 pscl 包）。然而，当我查看同一种子的类似模型时，我收到了一条警告消息和我的治疗的所有 NA：
警告消息：
在值[[3L]](cond)中：
  系统在计算上是奇异的：条件数倒数 = 1.09697e-23FALSE
&gt;摘要（模组）

称呼：
Zeroinfl(公式 = count ~ GA + Sm + light | GA + Sm + light, data = mod_data, dist = “negbin”)

皮尔逊残差：
       最小 1Q 中值 3Q 最大
-1.001e+00 -3.804e-02 -6.695e-11 -6.263e-11 9.649e-01

计算模型系数（带日志链接的 negbin）：
            估计标准。误差z值Pr(&gt;|z|)
（拦截）-21.2880 NA NA NA
GA 23.7197 不适用 不适用
Sm -0.1335 不适用 不适用
光 0.1038 不适用 不适用
Log(θ) 15.5141 NA NA NA

零通胀模型系数（带有 logit 链接的二项式）：
              估计标准。误差z值Pr(&gt;|z|)
（拦截）2.557e+01 不适用 不适用 不适用
GA -5.113e+01 不适用 不适用
Sm -9.764e-09 不适用 不适用
光 -9.764e-09 不适用 不适用

西塔 = 5466023.2431
BFGS 优化迭代次数：20
对数似然：9 Df 上的 -27.84

我并不完全清楚为什么在这里生产 NA，但是，整体模型再次产生了不错的（并且比第一个模型更好）结果。
我的问题是，是否有更好的方法来检查处理对像这样的单个种子的效果？或者只查看整体模型和单个种子的初始数据探索是否更好？提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/643208/small-sample-sizes-and-zero-inflated-count-data-in-r</guid>
      <pubDate>Thu, 21 Mar 2024 22:46:15 GMT</pubDate>
    </item>
    <item>
      <title>建模中何时需要误差传播？</title>
      <link>https://stats.stackexchange.com/questions/643202/when-error-propagation-is-necessary-in-modelling</link>
      <description><![CDATA[这是一个有点哲学的问题。在执行经典统计建模时，例如回归、LM、GLM、混合建模等，通常不会提及传播因变量的误差。我见过类似的情况，这通常是一个相对简单的调整，其中测量的标准偏差被添加为线性模型中的权重。
虽然在某些情况下这可能很麻烦（有些东西多次测量的成本很高），但许多变量可以轻松地多次测量。例如，如果对身高与体重进行经典教科书回归，那么从同一受试者中获取多个样本并不困难。
那么为什么模型中的错误传播如此罕见呢？这只是一个假设错误小到可以忽略的问题吗？或者它们是否已在正态分布残差的假设下得到考虑？或者，只是因为这是一个如此复杂的操作，大多数统计学家都懒得理会？]]></description>
      <guid>https://stats.stackexchange.com/questions/643202/when-error-propagation-is-necessary-in-modelling</guid>
      <pubDate>Thu, 21 Mar 2024 20:24:13 GMT</pubDate>
    </item>
    <item>
      <title>实验设计：什么为您提供了更多的统计能力：增加子样本或重复的数量？</title>
      <link>https://stats.stackexchange.com/questions/643199/experimental-design-what-gives-you-more-statistical-power-increasing-number-of</link>
      <description><![CDATA[假设我有一个二进制响应的实验：0 或 1。
在每个实验中，我将 X 个个体放入一个组中（X 个子样本），并测量响应为 1 的比例（实验 2/4）。我用新的 X 个体组重复了 Z 次。即，Z 次重复。
为了最大程度地提高统计功效（以检测平均响应/事后差异，可能是方差分析/Tukey HSD），您会增加每个重复中的子样本数量 X 或增加重复次数 (Z ）。
答案可能是两者都有，但其中一个的贡献力量是否比另一个更大？]]></description>
      <guid>https://stats.stackexchange.com/questions/643199/experimental-design-what-gives-you-more-statistical-power-increasing-number-of</guid>
      <pubDate>Thu, 21 Mar 2024 20:01:15 GMT</pubDate>
    </item>
    <item>
      <title>如何在这种高斯分布场景中使用卡尔曼滤波器</title>
      <link>https://stats.stackexchange.com/questions/643197/how-to-use-kalman-filter-in-this-scenario-with-gaussian-distribution</link>
      <description><![CDATA[我有一个模型如下：
$x_{t+1}=x_{t}+v_t*\delta$ 其中 $v$&lt; /span&gt;（未知）是沿 x 轴移动物体的速度，$\delta$（已知）是时间步长持续时间。假设速度属于离散集，例如 $V=\{50, 100, 150\}$ km/h。
该对象还有另一个数量 $G_{t}=\dfrac{A_t}{x_t}$，其中 $ A_t$ 是一个随机变量，遵循高斯分布，参数为 $0$ 和 $1$ .
最初，对象在 $[0, x_{max}]$ 之间的线上均匀随机生成，然后开始向左或向右随机移动一段 $T$ 个时间步长的时间段。如果在 $0$ 或 $x_{max}$ &gt;$T$，将从 $x_{max}$ 或 $0$ 开始分别，并继续直到达到 $T$。
我想使用扩展 Klaman 过滤器来预测 $G_t$ 的值，但我不知道如何实现？]]></description>
      <guid>https://stats.stackexchange.com/questions/643197/how-to-use-kalman-filter-in-this-scenario-with-gaussian-distribution</guid>
      <pubDate>Thu, 21 Mar 2024 20:00:34 GMT</pubDate>
    </item>
    <item>
      <title>手段和比例的假设检验。 t 检验与 z 检验</title>
      <link>https://stats.stackexchange.com/questions/643196/hypothesis-testing-for-means-proportions-t-test-vs-z-test</link>
      <description><![CDATA[我怎样才能让我的老师相信他在这项任务中是错误的？我们被分配了以下任务，我的老师说我必须使用 z 检验。我认为我必须使用 t 检验。任务如下：
一家公司在电网中安装了核电阻断器，以改善员工的健康。在安装之前，员工多年来平均每年请病假 12.7 天，标准差为 1.2 天。安装后两年内，平均病假天数为 11.4 天。假设标准差未发生变化，使用 95% 置信区间确定健康状况是否确实得到改善。能否证实员工的健康状况有所改善？
我计算t检验是因为有一个规则，如果样本n（在本例中是2年）小于30，那么你应该可以使用t检验。由于 n=2 并且小于 30，我认为 t 检验是正确的选择。我可以使用这条规则吗？还有其他选项可以证明 t 检验是正确的选择吗？ 单击查看 n&lt; ;30则t检验规则]]></description>
      <guid>https://stats.stackexchange.com/questions/643196/hypothesis-testing-for-means-proportions-t-test-vs-z-test</guid>
      <pubDate>Thu, 21 Mar 2024 19:36:54 GMT</pubDate>
    </item>
    <item>
      <title>基于 PCA 负载/旋转手动预测 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/643194/manually-predict-based-on-pca-loadings-rotation</link>
      <description><![CDATA[跟进：predict() 有何作用与 prcomp() 结合做什么？ （右）
如果我理解正确的话：
进行 pca - 计算对应于生物测量值的数据集的前 4 列（“Sepal.Length”“Sepal.Width”“Petal.Length”“Petal.Width”）
&lt;前&gt;&lt;代码&gt;数据（虹膜）
pca &lt;- prcomp(iris[,1:4], retx=F, 中心=F, 比例=F)

验证数据集的 PC 预测
pred &lt;- 预测(pca, newdata=iris[,1:4])

尝试手动预测
W = pca$旋转
X = 虹膜[,1:4]
Z = X*W

但是它们不匹配...
head(Z[,1]);head(pred[,1])

我是否误解或做错了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/643194/manually-predict-based-on-pca-loadings-rotation</guid>
      <pubDate>Thu, 21 Mar 2024 19:10:12 GMT</pubDate>
    </item>
    <item>
      <title>MLE 方差估计量的置信区间（正态分布）</title>
      <link>https://stats.stackexchange.com/questions/643173/confidence-interval-of-mle-variance-estimator-normal-distribution</link>
      <description><![CDATA[我可以使用 Fisher 信息来构建 MLE 方差估计器的置信区间吗？
Fisher 信息应为： $I(\theta) = E[I_0(\theta,Y)] = E\left[ \frac{m}{2(\sigma ^2)^2} \right] = \frac{m}{2(\sigma^2)^2}$
估计参数的方差为：$V(\hat{\theta}) = I(\theta)^{-1} = \frac{2(\sigma^2) )^2}{m}$
假设样本量足够大，我可以使用以下公式计算 95% CI 吗？
$$
\sigma^2 \in \hat{\theta} \pm z_{\frac{\alpha}{2}} \sqrt{V(\hat{\theta})}
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/643173/confidence-interval-of-mle-variance-estimator-normal-distribution</guid>
      <pubDate>Thu, 21 Mar 2024 14:44:29 GMT</pubDate>
    </item>
    <item>
      <title>似然原理与推理</title>
      <link>https://stats.stackexchange.com/questions/643120/likelihood-principle-and-inference</link>
      <description><![CDATA[我一直在阅读卡塞拉和伯杰的统计推断。作者在6.3节中阐述了似然原理：如果两个样本的似然函数成比例，那么基于两个样本的推论应该是相同的。但请考虑以下简单示例：我们从分布 $P(X=1)=\frac{5-2p}{3}$ 和 &lt; span class=&quot;math-container&quot;&gt;$P(X=2)=P(X=3)=\frac{p-1}{3}$。 2 和 3 的可能性相同。因此，基于观察 $X=2$ 和 $p=EX$ 进行推断=&quot;math-container&quot;&gt;$X=3$ 是相同的。这与我的直觉相矛盾，因为 $X$ 对于 $p$ 来说是足够的统计数据（因此我认为我们应该使用 $X$ 来推断 $p$）。
那么，似然原理和关于参数的标准推理之间真的存在矛盾吗？还是我在这里做错了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/643120/likelihood-principle-and-inference</guid>
      <pubDate>Thu, 21 Mar 2024 04:48:06 GMT</pubDate>
    </item>
    <item>
      <title>R - 获取折线图中步数的平均值</title>
      <link>https://stats.stackexchange.com/questions/643212/r-get-average-values-of-steps-in-line-chart</link>
      <description><![CDATA[考虑这个数据
#创建数据框
值 &lt;- c(0, 0, 0, 代表(30, 59), 0, 代表(14, 20), 0, 代表(24, 63), 0, 0 )
df &lt;- data.frame(样本 = 1:长度(值), 值 = 值)
#添加噪音
set.seed(123) # 为了重现性
噪声 &lt;- rnorm(length(values), Mean = 0, sd = 1) # 生成随机噪声
df$Value &lt;- df$Value + Noise # 向值添加噪音`

＃阴谋
库（ggplot2）
ggplot(data = df, aes(y = 值, x = 样本)) +
geom_line(颜色=“红色”，大小=1)


我想得到每一步的平均值和标准差。它们可以具有不同的宽度和高度。
我尝试计算滚动标准差，然后检测最大值，然后测量 SD 最大值之间的平均值，但由于步骤长度的差异，我未能成功准确地检测步骤的开始和结束。]]></description>
      <guid>https://stats.stackexchange.com/questions/643212/r-get-average-values-of-steps-in-line-chart</guid>
      <pubDate>Wed, 20 Mar 2024 23:00:48 GMT</pubDate>
    </item>
    <item>
      <title>审视这些年的变化</title>
      <link>https://stats.stackexchange.com/questions/643109/examine-change-over-the-years</link>
      <description><![CDATA[假设我想测试特定运动项目的前十名运动员在十年内是否变得更轻。对于每年的前十名选手，我每年的数据点数量相似。
我正在考虑简单地在比赛年份和运动员体重之间进行皮尔逊相关。这是解决此问题的合适方法吗？还是我可以/应该研究其他内容？]]></description>
      <guid>https://stats.stackexchange.com/questions/643109/examine-change-over-the-years</guid>
      <pubDate>Wed, 20 Mar 2024 21:31:23 GMT</pubDate>
    </item>
    <item>
      <title>硬币翻转游戏：HH 与 HT 的一系列翻转</title>
      <link>https://stats.stackexchange.com/questions/643092/coin-flip-game-hh-vs-ht-in-a-sequence-of-flips</link>
      <description><![CDATA[一个涉及翻转公平的有趣思想实验正在X/Twitter进行：
&lt;块引用&gt;
抛一枚均匀的硬币 100 次——得到一系列正面 (H) 和反面的序列
（T）。对于翻转序列中的每个 HH，Alice 都会得到一分；为了
每个 HT，Bob 都会这样做，所以例如对于序列 THHHT Alice 得到 2 分
鲍勃得 1 分。谁最有可能获胜？

答案是鲍勃更有可能获胜，这似乎违反直觉。我当然可以对问题进行暴力破解，以证明“鲍勃”是正确的答案——它似乎确实与鲍勃的方差比爱丽丝更低有关。但我很难理解为什么差异会有所不同。
库(dplyr)

sim.flip = 函数(X){
s2 = 样本(x = c(0,1),大小 = X,替换 = T) %&gt;% as.character() %&gt;% as.matrix()

s3 = s2 %&gt;% 矩阵(ncol = 2,byrow = T)
s4 = s2[-c(1,X)] %&gt;% 矩阵(ncol = 2,byrow = T)

s5=应用(s3,1,函数(X){粘贴(X,崩溃=“”,sep=“”)})
s6=应用(s4,1,函数(X){粘贴(X,崩溃=“”,sep=“”)})

A = 长度(grep(x = s5,模式 = “00”) )+
长度（grep（x = s6，模式=“00”））

B = 长度(grep(x = s5,模式 = “01”))+
长度（grep（x = s6，模式=“01”））

返回(数据.frame(A=A,B=B))
}

设置.种子(12345)
sims = sapply(c(1:10000),function(X){sim.flip(X=100)}) %&gt;% unlist() %&gt;% 矩阵(ncol = 2,byrow = T) %&gt;; % as.data.frame()
colnames(sims) = c(“爱丽丝”,“鲍勃”)

sims$winner = ifelse(sims$Alice &gt; sims$Bob,yes = &quot;Alice&quot;,&quot;Bob&quot;)
sims$获胜者[sims$Alice == sims$Bob] = “平局”

表（模拟$获胜者）

爱丽丝·鲍勃·蒂
 4626 4791 583

# 期望值相同
平均值（sims$Alice）
[1]24.7837
意思是（sims$鲍勃）
[1]24.7572

# 方差不同
var(sims$Alice)
[1] 30.36575
var(sims$鲍勃)
[1]6.229471
]]></description>
      <guid>https://stats.stackexchange.com/questions/643092/coin-flip-game-hh-vs-ht-in-a-sequence-of-flips</guid>
      <pubDate>Wed, 20 Mar 2024 17:15:24 GMT</pubDate>
    </item>
    <item>
      <title>IRT - 使用带有 2pl 模型的 mirt 包处理二进制变量时出现问题（？）或意外结果</title>
      <link>https://stats.stackexchange.com/questions/643205/irt-problem-or-unxepected-result-using-the-mirt-package-with-a-2pl-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/643205/irt-problem-or-unxepected-result-using-the-mirt-package-with-a-2pl-model</guid>
      <pubDate>Wed, 20 Mar 2024 10:02:19 GMT</pubDate>
    </item>
    <item>
      <title>GAM 中逐个平滑因子效果的解释</title>
      <link>https://stats.stackexchange.com/questions/642947/interpretation-of-effect-of-factor-by-smooths-in-gam</link>
      <description><![CDATA[根据以下数据和模型，我们希望评估治疗是否会影响conc对摄取的影响。
图书馆（谢谢）
图书馆（tidyverse）
库（mgcv）

＃ 数据
数据（CO2，包=“数据集”）
植物 &lt;- CO2 |&gt;
  as_tibble() |&gt;
  重命名（植物=植物，类型=类型，治疗=治疗）|&gt;
  变异（植物=因子（植物，有序= FALSE），
         摄取 = ifelse(治疗 == “冷冻” &amp; 类型 == “魁北克”, 摄取+10, 摄取))

# GAM
m_plant &lt;- gam(摄取 ~ 处理 * 类型 +
                 s(conc, by = 处理, k = 6) +
                 s（植物，bs =“re”），
               数据=植物，
               方法=“REML”，
               family = Gamma(link = &quot;log&quot;))

# 拟合值
ds &lt;- data_slice(m_plant,
                 治疗 = 水平（治疗），
                 类型 = 级别（类型），
                 浓度 = 均匀（浓度，n = 100））

拟合&lt;-fitting_values(m_plant,
                         数据 = ds,
                         尺度=“响应”，
                         排除 =“s(植物)”)

# 平滑估计
se &lt;- smooth_estimates(m_plant, “s(conc)”,
                       部分匹配 = TRUE)


通过预测吸收量，我们可以看到，在给定的浓度下，类型 = 密西西比冷冻植物的吸收量较高对于 type = Quebec 的非冷冻 植物，/code&gt; 及更高。无论类型如何，我们是否仍可以就治疗对conc对摄取的影响得出一般性结论&gt;，基于平滑的估计？例如，平滑估计图表明，例如conc = 500，对于非冷冻植物来说，对吸收的影响更强。考虑全局平滑效果时，沿 y 轴的截距/位置的这种差异是否有任何意义？或者，是否可以单独比较类型的平滑效果（除了预测值）？
编辑：
我认为我的问题与github上的这个问题/讨论有关。也许我只是在寻找类似 smooth_estimates(..., group_means = TRUE) 的东西。我试图根据平滑的差异来计算..
# 与组均值的差异平滑
ds_gm &lt;- Difference_smooths(m_plant, select = &quot;s(conc)&quot;,
                            部分匹配 = TRUE,
                            group_means = TRUE) %&gt;%
  选择(.diff, conc)

# 过滤非冷冻的平滑估计
se2&lt;-se%&gt;%
  add_confint() %&gt;%
  过滤器(处理==“非冷冻”)%&gt;%
  选择（.估计，浓度）

# 根据差异计算冷冻的平滑估计
left_join(ds_gm, se2) %&gt;%
  mutate(.estimate_chilled = .estimate - .diff) %&gt;%
  ggplot(.) +
  geom_line(aes(x = conc, y = .estimate)) +
  geom_line(aes(x = conc, y = .estimate_chilled), color = “红色”)


这是否可以得出这样的结论：浓缩对吸收的影响对于冷冻来说总是比非冷冻更强植物（置信区间除外）？]]></description>
      <guid>https://stats.stackexchange.com/questions/642947/interpretation-of-effect-of-factor-by-smooths-in-gam</guid>
      <pubDate>Tue, 19 Mar 2024 12:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>