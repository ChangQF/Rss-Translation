<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 29 Dec 2023 06:19:57 GMT</lastBuildDate>
    <item>
      <title>计算药物依从性时控制天数</title>
      <link>https://stats.stackexchange.com/questions/635798/controlling-for-number-of-days-when-calculating-medication-adherence</link>
      <description><![CDATA[我正在尝试评估药物依从性干预的成功程度。我试图根据患者服用药物的天数相对于观察时间的长短（即服用药物的天数/观察的天数）来评估干预前后该计划的成功程度。我面临的挑战是数据集中每个患者的观察周期（程序之前和之后）都是不同的。
我想控制评估的天数以查看实际影响。
我想到的一种方法是在程序之前和之后对每个患者的数据进行标准化（使用最小值/最大值）。例如，对于干预前的观察，我将获取所有患者在干预前观察到的最大和最小天数，并将每位患者的用药天数和观察天数标准化（使其介于 1 和 0 之间）。同样，我也会对干预后观察做同样的事情（干预后观察的最小/最大天数）。
我想知道这在逻辑上是否正确？我可能错的一个原因是我将“观察天数”的范围取为“观察天数”。并用它来标准化“服用药物的天数”。有什么建议或想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635798/controlling-for-number-of-days-when-calculating-medication-adherence</guid>
      <pubDate>Fri, 29 Dec 2023 05:23:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在给定因果图的因果推理中对分类处理进行非线性预测？</title>
      <link>https://stats.stackexchange.com/questions/635797/how-to-make-nonlinear-predictions-on-categorical-treatments-in-causal-inferece-g</link>
      <description><![CDATA[0
这几天在学习因果推理和发现，被这个问题困扰了很久。
从我对文献的理解来看，因果推理似乎与传统的机器学习有很大不同。对于传统的机器学习，一旦模型训练完成，并给定一组X，模型就会直接预测Y的值。
但是，对于因果推断，模型会回答如果 X1 从 1 变为 2，例如，它将返回对 Y 的因果影响。
那么如何使用因果推理来回答预测问题？
以下是使用此图的一些模拟数据：
导入networkx为nx
将 matplotlib.pyplot 导入为 plt

# 创建一个有向图
G = nx.有向图()

# 添加节点 X、Y 和 Z
G.add_nodes_from([&#39;X&#39;, &#39;Y&#39;, &#39;Z&#39;])

# 添加表示因果关系的边
G.add_edge(&#39;X&#39;, &#39;Y&#39;)
G.add_edge(&#39;Z&#39;, &#39;Y&#39;)

# 绘制图表
pos = nx.spring_layout(G)
nx.draw_networkx（G，pos，with_labels = True，node_color =&#39;浅蓝色&#39;，node_size = 500，font_size = 12，edge_color =&#39;灰色&#39;）
plt.title(&#39;因果图&#39;)
plt.show()


# 创建非线性关系：
将 numpy 导入为 np
将 pandas 导入为 pd

# 生成X值
X = np.linspace(0, 10, 100)

# 生成Z值
Z = np.linspace(10, 20, len(X))

# 使用与 X 的非线性关系生成 Y 值
Y = np.sin(X) + np.cos(Z) + np.random.normal(0, 0.1, len(X))

# 将 X、Z、Y 合并到一个 pandas 框架中
# 将 X、Z、Y 合并到一个 pandas DataFrame 中
df = pd.DataFrame({&#39;X&#39;: X, &#39;Z&#39;: Z, &#39;Y&#39;: Y})

# 打印数据框
打印（df）


问题是：
当 X = 10，Z = 20 时，如何假装只知道因果图而不知道详细的因果函数来对 Y 进行预测？
我尝试使用 Microsoft Causia 来识别因果图。还有因果推理，但它们不是传统的预测问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/635797/how-to-make-nonlinear-predictions-on-categorical-treatments-in-causal-inferece-g</guid>
      <pubDate>Fri, 29 Dec 2023 05:00:03 GMT</pubDate>
    </item>
    <item>
      <title>了解卷积神经网络中注意力层的功能（扩散模型中的 U-Net）</title>
      <link>https://stats.stackexchange.com/questions/635795/understanding-the-function-of-attention-layers-in-a-convolutional-neural-network</link>
      <description><![CDATA[我正在尝试了解 Ho 等人使用的神经网络架构。在“去噪扩散概率模型”中（论文，源代码）。它们在模型中包含自注意力层，将它们应用于先前卷积层（ResNet 块）输出的特征图。我在顺序数据的背景下理解自注意力，但这里没有向量序列，只有一个要由自注意力处理的图像。我不明白自注意力层对特征图做了什么。
问题：请您解释一下这个 CNN 中自注意力层的功能？
我的猜测是，自注意力层将像素视为序列元素，即它使用键/查询来查找输入特征图中与输入特征图中某个空间位置处的像素最相关的像素，然后形成这些像素（或者更确切地说它们的相应值）的相关性加权和作为该位置的输出。但这种观点似乎与操作机制并不一致。在顺序数据中，我们有 Q、K、V 矩阵，它们将与不同序列元素相关的嵌入存储为矩阵中的不同行，并且似乎我们将这些矩阵替换为源自单个矩阵的 Q、K、V 矩阵图像。所以当我们例如计算 $QK^\top$ 我们没有计算不同 elements=pixels 的查询和键的点积相似度，因为一行 $Q$ 和一行 $K$ 不对应于图像中的一个 element=pixel（与顺序数据对比，其中它们将对应于特定的序列元素）。
注意：通过阅读论文/源代码，我认为自注意力操作是按照下图进行的，但如果情况并非如此，请纠正我。
]]></description>
      <guid>https://stats.stackexchange.com/questions/635795/understanding-the-function-of-attention-layers-in-a-convolutional-neural-network</guid>
      <pubDate>Fri, 29 Dec 2023 00:19:23 GMT</pubDate>
    </item>
    <item>
      <title>以下对于泊松分布意味着什么？</title>
      <link>https://stats.stackexchange.com/questions/635787/what-does-the-following-mean-with-regards-to-poisson-distribution</link>
      <description><![CDATA[我正在阅读的文字内容如下，
&lt;块引用&gt;
考虑任何不确定事件在时间或空间上的发生，使得该事件在单位时间或空间上的平均发生次数为 m。我们可以取一段时间内发生的事故数量，其中 m 表示每月的平均事故数量；或者我们可能对工厂生产的布条中出现的缺陷数感兴趣，其中 m 表示每米的平均缺陷数。对于每种情况，我们都可以将时间或空间间隔划分为 n 个非常小的片段，以便在一个小片段内保持伯努利过程的条件。这样，一个月就可以被分为（比如说）30 x 24 x 60 个间隔，每个间隔一分钟，这样任意一分钟内发生事故的概率 = m/(30X 24 X60)，并减少到一个很小的量，因此一分钟内几乎不可能发生两次事故，伯努利试验的独立性在这里也成立，因为一分钟的间隔基本上对应于一次试验。类似的可能性也存在于布料示例中。

问题：如果m是一个月内的平均事故发生次数，那么一分钟内的平均事故发生次数，即m/(30 X 24 X 60)如何等于发生概率一分钟就出事故？]]></description>
      <guid>https://stats.stackexchange.com/questions/635787/what-does-the-following-mean-with-regards-to-poisson-distribution</guid>
      <pubDate>Thu, 28 Dec 2023 20:25:48 GMT</pubDate>
    </item>
    <item>
      <title>Logit 中具有多项选择解决方案的功能</title>
      <link>https://stats.stackexchange.com/questions/635759/feature-with-multiple-choice-solutions-in-logit</link>
      <description><![CDATA[我想训练一个 logit 模型，但我有一个特征（外生变量），在一个单元格中具有多个可能的类别。原因是问卷中的一个问题允许多项回答（多项选择）。
示例：变量“美食偏好”
第 1 行：墨西哥、意大利、亚洲
第 2 行：墨西哥、阿拉伯、美国
第 3 行：国际快餐、美式快餐
…………
我进行了热一编码，这样每个列出的结果都是它自己的一个变量。我不知道这是否是正确的方法，因为我会失去一个参考类别。
Python 的方法是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/635759/feature-with-multiple-choice-solutions-in-logit</guid>
      <pubDate>Thu, 28 Dec 2023 11:11:20 GMT</pubDate>
    </item>
    <item>
      <title>时间序列中的残差和“误差项”</title>
      <link>https://stats.stackexchange.com/questions/635738/residuals-and-error-terms-in-time-series</link>
      <description><![CDATA[我正在自学，我发现“残差”似乎是我们去掉非随机成分后剩下的东西。因此，如果我们进行加法分解：
$$ 系列 = 漂移 + 趋势\text{ }_t + 季节性\text{ }_t + RandomComponent\text{ }_t $$
$$ = \alpha + \beta t + S_t + u_t $$
残差为$u_t$。
但是现在，如果我们想在残差 $u_t$ 上拟合 ARMA，比如说 ARMA(2,2)，那么 MA(2) 就是应该是“错误术语”。所以它也可以被认为是残差（残差是观察到的错误）。也许错误的是，我从这个术语中推断出 MA 应该被理解为“残差”。 ARMA 流程：
$$ ARMA(2,2) : $$
$$u_t = X_t = \sum_{i=1}^2 {\phi_{t-i}X_{t-i}} + \sum_{i=1}^2 \theta_{t-i }\varepsilon_{t-i}$$
$$\rightarrow X_t = AR(2) + 错误\_terms$$
$$\rightarrow X_t = AR(2) + 残差 $$
在这种情况下，残差将是 $MA(2)$。
我知道可能存在没有 MA 的情况，因此没有“误差项”，因为我们可能会拟合 ARMA(p,0)。因此，残差将是白噪声 $\varepsilon$，它显示为 AR 过程的残差。
所以每当我们谈论“残差”时，例如当我们执行 Box-Jenkins 算法的测试时，我们的意思是什么？是吗：

整个 ARMA（$u_t$ 分解残差）
或者我们应该放大 $u_t$ 的 MA 分量（错误项）？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635738/residuals-and-error-terms-in-time-series</guid>
      <pubDate>Wed, 27 Dec 2023 22:37:47 GMT</pubDate>
    </item>
    <item>
      <title>如果 Cov(X,Y)=Var(Y)，X 和 Y 之间的依赖关系是什么？</title>
      <link>https://stats.stackexchange.com/questions/635725/if-covx-y-vary-what-is-the-dependence-between-x-and-y</link>
      <description><![CDATA[在一个问题中我发现
$$Cov(X,Y)=Var(Y),$$
其中 $X$ 和 $Y$ 是随机变量。
关于 $X$ 和 $Y$ 之间的线性相关性我可以得出什么结论？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635725/if-covx-y-vary-what-is-the-dependence-between-x-and-y</guid>
      <pubDate>Wed, 27 Dec 2023 19:05:08 GMT</pubDate>
    </item>
    <item>
      <title>比较逻辑回归中分类水平的显着性</title>
      <link>https://stats.stackexchange.com/questions/633745/comparing-significance-of-categorical-levels-in-logistic-regression</link>
      <description><![CDATA[我正在对一些具有二元结果和多个输入变量的数据运行逻辑回归，其中一个变量是具有 5 个级别的分类变量。我使用这些级别之一作为参考，因此解释其他 4 个级别的 OR 非常简单 - 这些是“相对”级别。达到0级。
但我不确定的是，我们是否可以在不完全重新运行分析的情况下说出其他级别的 OR 之间的差异。假设我想比较级别 1 和级别 2 - 如果 $OR_1 = 1.75$ 与 95% CI $1.56-1.93$  和 $OR_2 = 2.35$ 以及 CI $2.08-2.65$，我们可以说水平2的OR“显着高于”水平2。比 1 级的 OR 呢？或者如果差异更加显着，例如 $OR_2 = 9.01$ $(8.5-9.5)$。显然，这些都与参考组的 OR 为 1.00 相关，但是我们可以在其他水平之间进行比较吗？对于其他背景，所有水平的 OR 均具有显着性 p&lt;0.05。
如果可能的话，我希望避免重新运行分析，因为使用级别 0 作为参考组对于这个用例来说是有意义的，而且我不想担心多重比较。]]></description>
      <guid>https://stats.stackexchange.com/questions/633745/comparing-significance-of-categorical-levels-in-logistic-regression</guid>
      <pubDate>Tue, 12 Dec 2023 20:05:35 GMT</pubDate>
    </item>
    <item>
      <title>Pearson/Spearman 相关系数还是组内相关系数？</title>
      <link>https://stats.stackexchange.com/questions/633687/pearson-spearman-correlation-or-intraclass-correlation-coefficient</link>
      <description><![CDATA[我希望研究 150 名参与者对两份同时管理的先前验证的调查问卷（每份都给出数字总结分数作为输出）的响应之间的相关性。两份问卷都给出了与感知的生活质量成正比的数字分数（分数越高=感知的生活质量越好）。
由于每个参与者都会回答两份问卷，我假设这将是配对分析的情况（每个参与者从两份问卷中得到一对分数），并且适当的工具是组内相关系数。然而，我从我们的一位机构统计学家那里收到的反馈详细说明，我应该使用 Pearson（如果数据呈正态分布）或 Spearman（如果不太可能呈正态分布）相关系数，我认为它更适合未配对/独立数据。
我谨就上述情况征求其他意见。谢谢！
编辑：正如 Stephen Kolassa 所纠正的，...“请注意，正态分布与 Pearson 相关性和 Spearman 相关性之间的选择无关。相反，决定您是对线性相关性（使用 Pearson）更感兴趣，还是对更一般的单调相关性（使用 Spearman）更感兴趣......”]]></description>
      <guid>https://stats.stackexchange.com/questions/633687/pearson-spearman-correlation-or-intraclass-correlation-coefficient</guid>
      <pubDate>Tue, 12 Dec 2023 07:03:41 GMT</pubDate>
    </item>
    <item>
      <title>与固定斜率相比，具有随机斜率的多级模型中回归系数的标准差较高</title>
      <link>https://stats.stackexchange.com/questions/633401/high-standard-deviation-for-regression-coefficient-in-multilevel-model-with-rand</link>
      <description><![CDATA[最近，我比较了相同数据的两个多级模型：
具有固定坡度的一个：
R代码：
lmer(RT ~ Kontrast + (1|ID) + (1|Satz),
             数据=阅读次数，
             REML = 假）

还有一个具有随机斜率的：
lmer(RT ~ Kontrast + (Kontrast|ID) + (Kontrast|Satz),
             数据=阅读次数，
             REML = 假）

我发现，预测变量“Kontrast”的回归系数的标准偏差为在具有随机斜率的第二个模型中要高得多。
这有点有道理，因为系数可以在人（ID）和句子（“Satz”）之间变化，这是唯一的原因吗？
有人可以指出具有交叉随机效应的多级模型的优秀文献吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/633401/high-standard-deviation-for-regression-coefficient-in-multilevel-model-with-rand</guid>
      <pubDate>Fri, 08 Dec 2023 13:51:50 GMT</pubDate>
    </item>
    <item>
      <title>$n$ 次测试的配对比较，每次重复 $k$ 次</title>
      <link>https://stats.stackexchange.com/questions/633384/paired-comparison-on-n-tests-repeated-k-times-each</link>
      <description><![CDATA[假设我在 $n$ 通过/失败（伯努利）任务上测试两个科目，$k$ 次 - 每个科目总共 $n\cdot k$ 次测试。我想比较受试者，看看他们通过随机任务的能力是否存在统计上的显着差异。许多测试（例如双比例 z 测试）被消除，因为在受试者的测试结果内以及受试者之间的观察结果都是相关的。在这种情况下，最合适的统计测试是什么？
（我想我正在寻找像 McNemar-Bowker 这样的东西，但这似乎不太正确，除非我弄错了。奇怪的是每个结果之间没有一对一的配对主题；它更像是“$k$-to-$k$ 配对，$n$ 次。&#39;&#39;)
如果可能的话，还需要针对受试者之间的差异构建一个置信区间。]]></description>
      <guid>https://stats.stackexchange.com/questions/633384/paired-comparison-on-n-tests-repeated-k-times-each</guid>
      <pubDate>Fri, 08 Dec 2023 07:46:54 GMT</pubDate>
    </item>
    <item>
      <title>本文中使用逻辑回归和“变量的有序输入”是否具有统计意义？</title>
      <link>https://stats.stackexchange.com/questions/632950/is-the-use-of-logistic-regression-with-ordered-entry-of-variables-in-this-pape</link>
      <description><![CDATA[我正在阅读一篇论文，其中写道：
&lt;块引用&gt;
在进行逻辑回归分析时，预测变量的输入顺序由我们的理论基础和主要假设指导。在每次分析中，首先将反映选择效应的控制变量（收入与需求的比率、对母亲就业好处的信念）输入回归方程，然后检验母亲或儿童特征的主效应。接下来测试儿童保育变量的主效应，然后测试母亲/儿童变量和儿童保育变量之间的交互作用（即其乘积）。

我不明白这里发生了什么。我认为他们正在运行三个独立的逻辑回归，每个都有更多的预测变量，并使用不同的回归来测试不同术语的显着性。 这在统计上有意义吗？与仅将所有变量放入单个逻辑回归相比，这种方法有什么优势？
NB 实际上有 5 个母/子变量 &amp; 5 个儿童保育变量 - 但他们正在运行 25 个单独的分析，查看每一对可能的变量，因此每次分析中只查看每种变量的一个。]]></description>
      <guid>https://stats.stackexchange.com/questions/632950/is-the-use-of-logistic-regression-with-ordered-entry-of-variables-in-this-pape</guid>
      <pubDate>Sun, 03 Dec 2023 16:31:48 GMT</pubDate>
    </item>
    <item>
      <title>VQ-VAE 中的码本困惑</title>
      <link>https://stats.stackexchange.com/questions/600948/codebook-perplexity-in-vq-vae</link>
      <description><![CDATA[我正在进行 VQ-VAE 实验，我注意到困惑度已被用作 VQ 码本的评估指标。此外，大多数工作（包括将码本困惑度作为评估指标）都假设更高的困惑度更好，尽管我觉得在我的直觉中并不是很需要更高的困惑度。例如，在一般情况下，较低的困惑度表示更好的语言模型。
问题是
(1) 当我们计算 VQ 模型中的码本困惑度时，我们到底在测量什么？
(2) 为什么我们想要有大的码本困惑度？ VQ 模型的理想困惑度是多少？
抱歉，如果我的问题不清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/600948/codebook-perplexity-in-vq-vae</guid>
      <pubDate>Thu, 05 Jan 2023 07:34:25 GMT</pubDate>
    </item>
    <item>
      <title>小鼠包中多重插补的缺失值的限制是多少？</title>
      <link>https://stats.stackexchange.com/questions/595240/what-is-the-limit-of-missing-values-for-multiple-imputation-in-the-mice-package</link>
      <description><![CDATA[我有两个关于鼠标包的问题。

第一个是quickpred 参数中的mincor。当在起重机上时，它说这是比较的绝对最小相关性。这是否意味着如果我将 mincor 设置为零，即使非常弱的相关性也会被接受？如果我理解正确，为了获得好的结果，我应该将值设置为接近 1。很抱歉，如果我在这个问题上太外行或无知，但我必须从头开始学习多重插补。
我的另一个问题是关于缺失值的大小。我认为我的数据有很多缺失值，但我不确定是否可以输入。

我如何创建多重插补函数的示例
m.out &lt;- 小鼠(result.wide, m=10,
pred=quickpred(result.wide, mincor=0, include =
c(“类别”,“地区”), 排除=c(“NAME_AP”)))

这些是缺失值的数量。
]]></description>
      <guid>https://stats.stackexchange.com/questions/595240/what-is-the-limit-of-missing-values-for-multiple-imputation-in-the-mice-package</guid>
      <pubDate>Thu, 10 Nov 2022 03:32:59 GMT</pubDate>
    </item>
    <item>
      <title>在时变概率分布之间进行插值</title>
      <link>https://stats.stackexchange.com/questions/523475/interpolating-between-time-varying-probability-distributions</link>
      <description><![CDATA[是否有任何公认的方法可以在两个随时间变化的离散概率分布之间进行插值？
假设我们在 $t=0$ 时有一些数据，其中包含 pmf $p_1$ 和一些数据$t=10$ 时刻的数据与另一个 pmf $p_{10}$ 的数据。是否有任何方法可以在两个两个时变数据之间进行插值并构造一些 $p_{5&#39;}$ 这将是 $t=5$?
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/523475/interpolating-between-time-varying-probability-distributions</guid>
      <pubDate>Mon, 10 May 2021 00:40:05 GMT</pubDate>
    </item>
    </channel>
</rss>