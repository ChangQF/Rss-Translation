<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 14 Feb 2024 21:12:18 GMT</lastBuildDate>
    <item>
      <title>每个参与者具有随机条件子集的多级模型</title>
      <link>https://stats.stackexchange.com/questions/639297/multilevel-model-with-random-subset-of-conditions-per-participant</link>
      <description><![CDATA[我对 5 个因素进行了重复测量实验，每个因素有 3 个不同的水平。我正在尝试找到一种方法来减少对参与者的需求，让他们不必经历每一种情况。
我一直在研究部分因子设计，但我突然想到，我可以运行一个为每个参与者部分完成的多级模型。
所以，我的问题是：是否可以向每个参与者展示条件的随机子集（例如 50%），收集足够的参与者，以便每个单独的条件都有良好的代表性，然后使用多级线性模型来建立各因素的影响？我怀疑可能是这样，但我不确定是否有什么我忽略的事情。]]></description>
      <guid>https://stats.stackexchange.com/questions/639297/multilevel-model-with-random-subset-of-conditions-per-participant</guid>
      <pubDate>Wed, 14 Feb 2024 21:02:54 GMT</pubDate>
    </item>
    <item>
      <title>使用部分审查的类别信息进行分类</title>
      <link>https://stats.stackexchange.com/questions/639294/classification-with-partially-censored-class-information</link>
      <description><![CDATA[我想为我的小部件构建一个分类器！这是我的数据：

&lt;标题&gt;

类
功能 1
功能 2
...


&lt;正文&gt;

[1,5]
0.1
“E”
...


4
1.7
“B”
...


[2,3,5]
0.8
“D”
...


...
...
...
...



也就是说，对于某些观察结果，我只知道它们属于 5 个可能的类标签的子集中的一个类，但我不知道它们到底属于哪个类。
有谁知道解决这个问题的原则方法吗？理想情况下，解决方案是概率 多类分类器有效地合并了部分审查的类信息。
我考虑过的一种方法是将未知类拆分为加权观测值，即将上述数据集转换为：

&lt;标题&gt;

类
重量
功能 1
功能 2
...


&lt;正文&gt;

1
0.5
0.1
“E”
...


5
0.5
0.1
“E”
...


4
1
1.7
“B”
...


2
0.33
0.8
“D”
...


3
0.33
0.8
“D”
...


5
0.33
0.8
“D”
...


...
...
...
...
...



这似乎可以产生合理的输出，但我很想知道是否存在更干净的解决方案！感谢您可能拥有的任何见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/639294/classification-with-partially-censored-class-information</guid>
      <pubDate>Wed, 14 Feb 2024 20:20:46 GMT</pubDate>
    </item>
    <item>
      <title>使用多个其他 PCA 的结果执行 PCA？这是合法的吗，我该如何解释？</title>
      <link>https://stats.stackexchange.com/questions/639293/performing-pca-with-results-of-multiple-other-pcas-is-this-legit-how-do-i-inte</link>
      <description><![CDATA[我是一名生物学研究员，正在撰写一份涉及我学科之外的人员的手稿。他们使用 PCA 创建人口变量指数，对地理区域进行分类。对于其中一种情况，他们实际上使用了变量的子集，运行了 3 个单独的 PCA，然后使用这些分析的结果作为数据来运行另一个 PCA。
从数学角度来看，这似乎是一种合理的技术，但我不知道如何解释结果，至少在底层原始数据属性的贡献方面是这样。
此外，我对这种方法完全不熟悉。这与我之前使用 PCA 的方式非常不同。我想知道做这样的事情有多成熟，是否有任何我可以阅读的文献，或者只是我可以看的例子。]]></description>
      <guid>https://stats.stackexchange.com/questions/639293/performing-pca-with-results-of-multiple-other-pcas-is-this-legit-how-do-i-inte</guid>
      <pubDate>Wed, 14 Feb 2024 20:06:15 GMT</pubDate>
    </item>
    <item>
      <title>百分比平均值，还是总计/总计？</title>
      <link>https://stats.stackexchange.com/questions/639292/average-of-percents-or-sum-total-sum-total</link>
      <description><![CDATA[我有一些数据，需要知道所有商品的平均佣金。对于每一行，我计算发出的项目的百分比。如果我想知道“平均佣金是多少”，正确的是 $14.96$% 或 $12.89$&lt; /span&gt;%?
 项目 成本 收入 佣金
           1,000 289 28.90%
           2,991 190 6.35%
          10,400 1,050 10.10%
          20,000 2,900 14.50%
总计 34,391 4,429 **14.96%**

$14.96$% 在 Excel 中计算如下：
&lt;预&gt;&lt;代码&gt;=平均值(28.90%, 6.35%, 10.10%, 14.50%)

（这称为百分比平均值吗？不知道该怎么称呼它）。
现在，如果我执行4429 / 34391，我会得到$12.88$%。我“想要”哪个平均值？用于回答“平均佣金是多少？”我认为 SUM(Revenue) / SUM(Item Cost) 是我想要的，而不是计算的百分比的平均值，但甚至不知道使用什么术语来查找差异是什么，或者何时使用其中一种而不是另一种。对于前者，AVERAGE()，因为将百分比相加，然后除以 $4$，我不认为这对我的目的来说是准确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/639292/average-of-percents-or-sum-total-sum-total</guid>
      <pubDate>Wed, 14 Feb 2024 19:47:38 GMT</pubDate>
    </item>
    <item>
      <title>岭正则化与CNN数据增强的关系</title>
      <link>https://stats.stackexchange.com/questions/639291/the-relationship-between-ridge-regularization-and-cnn-data-augmentation</link>
      <description><![CDATA[在 James 等人的 Python 应用程序统计学习简介 的第 10.3.4 章中。有一句话是关于 CNN 的数据增强（将图像的自然变换添加到训练集中以提高泛化能力），内容如下：
&lt;块引用&gt;
这种数据肥化在本质上与岭正则化类似

我已阅读此帖子：为什么数据增强是否被归类为正则化的一种类型？并从最上面的答案中了解数据增强如何被视为正则化的一种形式。
我不明白的是引用的句子专门提到了岭正则化。我觉得我缺少一些更深入的概念点，即为什么 ridge 与 lasso 或任何其他正则化方法相比，与数据增强类似。
我能想象到的最好的结果是，使用岭可以有效地平滑模型系数。但增加数据量呢？我没看到。我只是想太多了吗？它们只是意味着一般的正则化吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639291/the-relationship-between-ridge-regularization-and-cnn-data-augmentation</guid>
      <pubDate>Wed, 14 Feb 2024 19:39:52 GMT</pubDate>
    </item>
    <item>
      <title>如何自动生成表示多种治疗之间的异同的字母？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/639290/how-to-automatically-generate-letters-denoting-similarities-and-differences-betw</link>
      <description><![CDATA[我进行了比较治疗的试验，并将治疗作为固定效应进行回归分析。这会生成 p 值，表示各种结果的治疗之间的相似性/差异，我将其输入显着性矩阵（参见图片）以可视化每个治疗比较。上标字母用于表示每种处理之间的相似性/差异；共享字母的治疗相似，而不共享字母的治疗显着不同。目前，我手动分配字母，即在脑海中计算出来，但这对于进行大量治疗的研究来说很棘手。我一直在寻找一种自动生成重要字母的方法，但我发现这很困难，特别是因为我没有编码背景。任何想法将非常感激。
[1]: https://i.stack.imgur.com/u7E2C.png]]></description>
      <guid>https://stats.stackexchange.com/questions/639290/how-to-automatically-generate-letters-denoting-similarities-and-differences-betw</guid>
      <pubDate>Wed, 14 Feb 2024 19:21:28 GMT</pubDate>
    </item>
    <item>
      <title>引导测试集是否提供真实的错误置信区间？</title>
      <link>https://stats.stackexchange.com/questions/639289/does-bootstrapping-the-test-set-provide-a-real-error-confidence-interval</link>
      <description><![CDATA[我的问题是引导测试集？的答案中部分讨论的内容的具体示例。 .
假设我训练一个模型，在该模型中我无法从数学上导出误差的置信区间（考虑随机森林或神经网络），并进一步假设测试集和训练集的目标变量数据分布大致相同。 
引导测试集并对其进行多次评估是否会给出模型误差的真实置信区间？具体来说，我是否可以 X% 确定从未抽样总体中随机抽取与测试集相同大小的随机抽取将在区间内出现错误？]]></description>
      <guid>https://stats.stackexchange.com/questions/639289/does-bootstrapping-the-test-set-provide-a-real-error-confidence-interval</guid>
      <pubDate>Wed, 14 Feb 2024 19:08:54 GMT</pubDate>
    </item>
    <item>
      <title>$P(\text{观察到的极端数据} | \text{替代假设})$</title>
      <link>https://stats.stackexchange.com/questions/639287/p-textdata-as-extreme-as-observed-textalternative-hypothesis</link>
      <description><![CDATA[在频率假设检验中，计算值 $P(\text{与观察到的极端数据} | H_0)$，如果它小于特定阈值，$H_0$ 被拒绝。我理解“极端”的概念是“极端”。需要定义，这取决于$H_1$。它可以使用似然比明确定义，但据我在文献（在我的例子中是生物学）中看到的，对 $H_1$ 的依赖通常是隐含的。这就提出了一个问题：人们使用的“正确”是什么？极端的定义？
现在，这听起来可能像是我很迂腐。但我问这个问题的原因是，在我正在分析的数据集上，我定义了一个统计量和极端的直观定义，并使用采样计算了 pvalue $P(\text {观察到的极端数据} | H_0)$。看到这个值很小，我心里就高兴了。由于我的替代假设 $H_1$ 也得到了很好的定义，我可以计算 $P(\text{与观察到的极端数据} | H_1)$ 也是如此，发现这个值也很小。这让我想知道：

我该如何解释这一点？直观上，这让我认为 $H_0$ 和 $H_1$ 都不是好的假设，并且“ “现实” （当然，定义很宽松），是另一回事。我能想到的另一种解释是，我的数据（或至少是我的汇总统计数据）并不能提供有关这些假设的信息。另一种看待它的方式是，我拒绝了复合假设 $H_C:H_0 \lor H_1$（如果这些概率的总和也很小）。
如果我不报告 $P(\text{观察到的极端数据} | H_1)$，而只报告 pvalue，这实际上可能令人信服至少有一些我能够拒绝的人 $H_0$，因为直观地导致测试的替代方案是 $ H_1$，对于那些人来说，这似乎是 $H_1$ 的证据。这告诉我，至少可能有一些论文存在类似的问题。有人研究过这个吗？我的担心有道理吗？如果这确实是一个值得关注的问题，那么补救措施是什么（除了完全放弃 pvalue 的概念并进行贝叶斯测试之外）？是否应该要求人们始终计算和报告 $P(\text{观察到的极端数据} | H_1)$ 以及 pvalue？这样就能解决问题吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/639287/p-textdata-as-extreme-as-observed-textalternative-hypothesis</guid>
      <pubDate>Wed, 14 Feb 2024 18:15:45 GMT</pubDate>
    </item>
    <item>
      <title>显示统一的覆盖范围</title>
      <link>https://stats.stackexchange.com/questions/639286/show-uniform-coverage</link>
      <description><![CDATA[考虑以下集合
$$
\开始{对齐}
&amp;\Lambda = \Big\{ x\in \mathcal{X}: \Pr\bigg(\lim_{n \to \infty}d\big(p_n, [\ell(x), u(x) ] \big)= 0\bigg)=1 \Big\},\\
&amp; \Lambda_n = \Big\{ x\in \mathcal{X}: d\big(p_n, [\ell(x), u(x) ] \big)= 0\Big\},
\结束{对齐}
$$
其中：

$\mathcal{X}\subseteq \mathbb{R}$。
$(p_n)_n$ 是一些实数序列。
$d\big(p_n, [\ell(x), u(x) ] \big):= \inf \big\{|p_n - y| : y \in [\ell(x), u(x) ] \big\}$。

假设 $\Lambda$ 非空且
$$
\Pr(x\in \Lambda_n)\geq 1-\alpha \quad \forall x\in \Lambda \quad \forall \alpha\in (0,1),
$$
即， $\Lambda_n$ 是“逐点”的为每个 $x\in \Lambda$ 设置置信度。
你能帮我证明上面的覆盖属性是统一的，即：
$$
\inf_{x\in \Lambda} \Pr(x\in \Lambda_n)\geq 1-\alpha \quad？
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/639286/show-uniform-coverage</guid>
      <pubDate>Wed, 14 Feb 2024 18:03:32 GMT</pubDate>
    </item>
    <item>
      <title>高斯混合模型 (GMM) 在什么条件下具有最大熵？</title>
      <link>https://stats.stackexchange.com/questions/639285/under-what-conditions-does-a-gaussian-mixture-model-gmm-have-maximum-entropy</link>
      <description><![CDATA[简介
我正在研究无监督学习框架中的高斯混合模型 (GMM)，并且对其统计特性特别感兴趣，重点关注熵。熵衡量概率分布内的不确定性或随机性。对于奇异高斯分布，其熵可以直接计算，并且已知与分布的方差有关。
GMM 结合了多个高斯分布，每个高斯分布都由其均值、方差和混合系数定义。这种复杂性表明 GMM 的熵受到这些参数的影响，但我寻求对这种影响进行更深入、更正式的探索。
问题
哪些具体条件导致高斯混合模型实现最大熵？是否存在将 GMM 的熵与其构成方差、均值和混合系数联系起来的既定公式或结果？例如，增加具有均匀混合系数和方差的成分数量是否总是会增加熵，或者是否有更多微妙的因素发挥作用？
此外，不同高斯分量之间的动态（例如它们的均值分离和方差重叠）如何影响 GMM 的整体熵？当组件数量保持不变时，这些参数是否有特定的配置可以最大化 GMM 的熵？
请求见解
我正在寻找能够阐明这些关系的见解、理论讨论或实际例子。形式推导、学术著作参考或说明性示例将受到高度重视。
感谢您就这个复杂的主题提供的任何帮助或指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/639285/under-what-conditions-does-a-gaussian-mixture-model-gmm-have-maximum-entropy</guid>
      <pubDate>Wed, 14 Feb 2024 17:20:18 GMT</pubDate>
    </item>
    <item>
      <title>具有偏斜响应的单向重复测量方差分析</title>
      <link>https://stats.stackexchange.com/questions/639280/one-way-repeated-measures-anova-with-skewed-response</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/639280/one-way-repeated-measures-anova-with-skewed-response</guid>
      <pubDate>Wed, 14 Feb 2024 16:20:10 GMT</pubDate>
    </item>
    <item>
      <title>屏蔽自动编码器和屏蔽增强之间的区别</title>
      <link>https://stats.stackexchange.com/questions/639278/difference-between-masked-autoencoder-and-masked-augmentation</link>
      <description><![CDATA[在训练常规自动编码器时，使用屏蔽自动编码器和应用屏蔽增强（如《捉迷藏》论文中提出的）有什么区别吗？
跟进：使用 CNN 的屏蔽增强（而不是 ViT）有什么问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639278/difference-between-masked-autoencoder-and-masked-augmentation</guid>
      <pubDate>Wed, 14 Feb 2024 16:16:22 GMT</pubDate>
    </item>
    <item>
      <title>在使用递归特征消除之前如何处理相关变量？</title>
      <link>https://stats.stackexchange.com/questions/639271/how-to-handle-correlated-variables-before-using-recursive-feature-elimination</link>
      <description><![CDATA[我见过一些 Kaggle 笔记本，它们无缘无故地列出了 RFE 在删除相关变量时效果更好。我很难理解其中的原因，所以我自己进行了一些研究，想验证我的结论是否正确。
根据我对 sklearn 的 CART 算法的研究，我获得了良好的预测特征（特征 A）和带有一些额外噪声的高度相关特征（特征 B）。似乎由于高相关性，它们的平均杂质减少量非常相似，并且划分大致划分了两个变量之间的特征重要性。这就造成了这样的情况：如果特征 A 是一个很好的预测变量，尽管特征 B 是冗余的，特征 A 和特征 B 仍可以排名靠前。特征 B 可能不会在多次迭代中被删除，并会降低前几次迭代的模型得分，从而限制 RFE 考虑的特征组合。
但我认为有多种因素会影响我们识别“高度相关变量”的方式。 我们在哪个相关截止点确定变量会损害 RFE 特征选择过程？
例如，算法中的分割数量将是一个决定因素。如果功能 A 仅具有单个拆分，则功能 B 将不会从与功能 A 的高度相关性中受益，并且很可能会被 RFE 毫无问题地删除。]]></description>
      <guid>https://stats.stackexchange.com/questions/639271/how-to-handle-correlated-variables-before-using-recursive-feature-elimination</guid>
      <pubDate>Wed, 14 Feb 2024 14:48:46 GMT</pubDate>
    </item>
    <item>
      <title>四个不同城市土壤有毒元素与表观遗传老化的关系</title>
      <link>https://stats.stackexchange.com/questions/639266/association-of-soil-toxic-element-with-epigenetic-aging-in-four-different-cities</link>
      <description><![CDATA[我想做土壤有毒元素和表观遗传年龄加速的线性回归分析；我们使用 ICP-MS 测量了四个不同城市的土壤元素（毫克/千克）。
您能否建议以下方法是否正确，或者我们是否应该仅使用 log2 变换土壤元素；
要将原始元素值划分为分位数以进行回归分析，您可以使用 R 中的 cut 函数。以下示例说明了如何修改脚本以包含原始元素值的分位数：
# 读取数据
df &lt;- read.table(&quot;clean.file2.txt&quot;, header = TRUE, sep = &quot;,&quot;)
 
# 检查列名
列名(df)
 
# 为原始元素值创建分位数
quantile_cols &lt;- c(“Zn”、“Cu”、“Hg”、“Pb”)
分位数_列

             锌 铜 汞 铅
          4.55000 0.73000 2.07500 192.00000
          5.33333 0.23667 1.90667 115.33333
 
for (分位数列中的列) {
  df[[paste0(col, &quot;_quantile&quot;)]] &lt;- cut(df[[col]],
               中断 = 分位数(df[[col]], 概率 = 0:4/4),
               标签=假）
}
 
# 拟合回归模型
model1 &lt;- lm(epigenic_age_acceleration ~ 0 + 城市 + 城市：
  (Zn_分位数 + Cu_分位数 + Hg_分位数 + Mo_分位数 +
  Pb_quantile + Smoking_Status + 性别 + 年龄), 数据 = df)
# 总结模型
摘要_模型1 &lt;- 摘要(模型1)

此脚本向数据框“(Zn_quantile, Cu_quantile, Hg_quantile, Mo_quantile, Pb_quantile)”添加新列，表示每个原始元素值的分位数。然后将这些新列用于回归模型。根据您的具体需求和数据结构调整代码。
]]></description>
      <guid>https://stats.stackexchange.com/questions/639266/association-of-soil-toxic-element-with-epigenetic-aging-in-four-different-cities</guid>
      <pubDate>Wed, 14 Feb 2024 14:14:30 GMT</pubDate>
    </item>
    <item>
      <title>具有交互项和固定效应的多重共线性</title>
      <link>https://stats.stackexchange.com/questions/639279/multicollinearity-with-interaction-term-and-fixed-effects</link>
      <description><![CDATA[我有以下回归，包括交互项和固定效应
feols(work ~ i(age_cohort, log(tot_bomb_per)) + yrschool + nchild +
    已婚 + as.factor(少数) | geo1_vn1989 + 年龄_队列，
    子集（phc89，女性 == 1 &amp; 出生年份 &gt; 1925 &amp;
                    出生地1974 年及迁移== 0),
    权重 = ~ perwt, vcov = ~ geo1_vn1989)

age_cohort为个人i的年龄组，tot_bomb_per为p省的省级轰炸强度，geo1_vn1989为省级固定效应和age_cohort是年龄组固定效应。
运行该代码后，我收到此消息
变量 &#39;age_cohort::61-65:log(tot_bomb_per)&#39; 已被删除
   因为共线性（参见 $collin.var）。

您能否帮我解释一下为什么我会遇到此错误消息，以及我是否应该删除固定效果。]]></description>
      <guid>https://stats.stackexchange.com/questions/639279/multicollinearity-with-interaction-term-and-fixed-effects</guid>
      <pubDate>Wed, 14 Feb 2024 13:53:51 GMT</pubDate>
    </item>
    </channel>
</rss>