<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Sep 2024 09:17:25 GMT</lastBuildDate>
    <item>
      <title>如何使用“lme4”R 包中的 lmer() 最好地拟合我的线性混合效应模型？</title>
      <link>https://stats.stackexchange.com/questions/653836/how-do-i-best-fit-my-linear-mixed-effect-model-with-lmer-from-the-lme4-r-pac</link>
      <description><![CDATA[所以，我对 R 和使用“lme4”包中的 lmer 进行建模还很陌生。我希望得到一些帮助，了解如何拟合我的模型来回答我的研究问题；不同的抓取类型是否具有可比性，即抓取是否会对我的响应变量丰度、生物量和底栖无脊椎动物的物种丰富度产生影响。我想比较使用 van Veen 抓取的常见软沉积物采样方法是否与使用另一种称为 Ekman 抓取的采样方法不同。
我有使用两个抓取器在三个不同站点（深度不同）对底部沉积物进行现场采样的数据，我在每个站点使用 Ekman 采集了 10 个样本，使用 van Veen 采集了 5 个样本。所以，总共有 45 个样本；30 个使用 Ekman，15 个使用 van Veen。我只对抓取对响应变量的影响感兴趣，但我想在我的模型中考虑站点之间的差异。这是使用 lmer() 的合理模型拟合吗？我想考虑站点的随机截距，以及抓取和站点之间可能的相互作用。或者其他模型更合适？这不是一个非常复杂的模型，我只有两个因素，但我不确定如何以最佳方式拟合我的模型。如果我想将“站点”视为随机的，那么相互作用也应该是随机的吗？谢谢！
lmer.model5 &lt;- lmer(Abundance ~ Grab + (1|Station) + (1|Grab:Station)
我尝试过拟合几个模型，但不确定要使用哪一个。我需要一些关于如何拟合模型来回答我的研究问题的指导。
lmer.model1 &lt;- lmer(Abundance ~ Grab + (1|Station))
lmer.model2 &lt;- lmer(Abundance ~ Grab * Station + (1|Station))
lmer.model3 &lt;- lmer(Abundance ~ Grab + Station + (1|Station))
lmer.model4 &lt;- lmer(Abundance ~ Grab + (Grab|Station))
lmer.model5 &lt;- lmer(Abundance ~ Grab + (1|Station) + (1|Grab:Station))
交叉发布]]></description>
      <guid>https://stats.stackexchange.com/questions/653836/how-do-i-best-fit-my-linear-mixed-effect-model-with-lmer-from-the-lme4-r-pac</guid>
      <pubDate>Wed, 04 Sep 2024 09:10:43 GMT</pubDate>
    </item>
    <item>
      <title>训练准确率提高至 99%，但验证准确率停止得更早</title>
      <link>https://stats.stackexchange.com/questions/653835/training-accuracy-increases-up-to-99-but-validation-accuracy-stops-much-earlier</link>
      <description><![CDATA[我尝试使用自己实现的 Resnet 模型对 CIFAR-100 数据集进行分类。
我尝试了多种不同的超参数配置，更改了学习率、批量大小、辍学率、数据增强和正则化，但我所做的一切都无法将验证准确率提高 40% 以上，而训练准确率可以达到 99%。
我意识到训练准确率高但验证准确率低是过度拟合的标志，但在增加正则化参数和辍学率后，我仍然没有看到任何改善。训练、验证和测试的分割由 CIFAR-100 提供，因此分别为 40000、10000、10000。
有人知道如何突破这个瓶颈吗？或者有人知道我哪里可能出错了吗？
以下是我一直在尝试的超参数类型：
learning_rates = [0.001, 0.0001]
batch_sizes = [16, 32]
dropout_rates = [0.3,0.5]
decay = [0.001, 0.0001]
optimiser = [&#39;Adam&#39;, &#39;SGD&#39;]

以下是我一直在增强数据的方式：
transform = transforms.Compose([
transforms.RandomCrop(32, padding=4),
transforms.RandomHorizo​​ntalFlip(),
transforms.RandomRotation(10),
transforms.ToTensor(),
transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

DATA_ROOT_FOLDER = &#39;./cifar-100-python&#39; 

train_data = datasets.CIFAR100(root=f&quot;{DATA_ROOT_FOLDER}&quot;, train=True, download=True, transform=transform)
test_data = datasets.CIFAR100(root=f&quot;{DATA_ROOT_FOLDER}&quot;, train=False, download=True, transform=transform)

train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)

batch_size = 64
train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)
test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)

这些是我得到的结果。

]]></description>
      <guid>https://stats.stackexchange.com/questions/653835/training-accuracy-increases-up-to-99-but-validation-accuracy-stops-much-earlier</guid>
      <pubDate>Wed, 04 Sep 2024 09:00:43 GMT</pubDate>
    </item>
    <item>
      <title>不同维度的聚类之间 x-means 的 BIC 和似然分数是否可以比较？</title>
      <link>https://stats.stackexchange.com/questions/653834/are-x-means-bic-and-likelihood-scores-comparable-between-clusters-of-different</link>
      <description><![CDATA[我目前正在实施 x-means 变体，在计算贝叶斯信息准则的对数似然（通过 scipy 的多元正态 logpdf）时遇到了问题，该问题在低空间集群上失败。
用例是通过 3D 笛卡尔坐标对地理点进行类似 k-means 的聚类，但具有可配置的最大 k 个集群。坐标系以 (0,0,0) 为地球中心，所有点都相距约 6371 个单位。因此，集群可以是平坦的、非常弯曲的，甚至有点像 1D，但永远不会是真正的 3D 高斯。因此，目前的计划是在计算 BIC 分数时尝试通过子集群上的 PCA 进行降维。
问题是：当使用此实现（大概基于 Ishioka (2000) 的扩展）时，不同维度的集群之间的 BIC 和对数似然分数是否最具有可比性？请注意，此实现在单个集群上计算 BIC，然后通过它们单独缓存的协方差/似然/BIC 对 2 个新集群执行某种合并的 BIC。
如果不是，最大 k 聚类还有哪些其他选项（替代似然函数、聚类算法等）？]]></description>
      <guid>https://stats.stackexchange.com/questions/653834/are-x-means-bic-and-likelihood-scores-comparable-between-clusters-of-different</guid>
      <pubDate>Wed, 04 Sep 2024 08:58:43 GMT</pubDate>
    </item>
    <item>
      <title>当交错 DID 是我的主要经验方法时，有哪些适当的方法进行稳健性检验？</title>
      <link>https://stats.stackexchange.com/questions/653833/what-are-the-appropriate-methods-to-do-robustness-check-when-a-staggered-did-is</link>
      <description><![CDATA[我正在研究一项健康政策对健康结果指标的因果影响。一个国家的不同地区在不同的时间点采用这项政策，这是使用交错差异法估计该政策因果影响的理想环境。我还想做一些稳健性检验，以表明我的结果对我使用的计量经济学方法具有稳健性。我可以考虑哪些合理的替代方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/653833/what-are-the-appropriate-methods-to-do-robustness-check-when-a-staggered-did-is</guid>
      <pubDate>Wed, 04 Sep 2024 08:29:51 GMT</pubDate>
    </item>
    <item>
      <title>为什么在计算余弦相似度时，如果任一向量的幅度为 0，则比率设置为 1？</title>
      <link>https://stats.stackexchange.com/questions/653831/why-when-calculating-the-cosine-similarity-if-the-magnitudes-of-either-vector-is</link>
      <description><![CDATA[在这个问题中，关于如何高效计算余弦相似度，为什么如果任一向量的幅度为 0，则返回值为 1？
我指的是这部分代码。
 if (u_norm == 0) or (v_norm == 0):
ratio = 1.0
else:
ratio = udotv / (u_norm * v_norm)

由于没有办法确定向量是否相似，返回 0 不是更有意义吗？将其设置为 1 有什么理由吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653831/why-when-calculating-the-cosine-similarity-if-the-magnitudes-of-either-vector-is</guid>
      <pubDate>Wed, 04 Sep 2024 07:51:01 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 HoltWinter 给出的结果与 statsmodels 包中的指数平滑结果不同吗？</title>
      <link>https://stats.stackexchange.com/questions/653830/holtwinter-in-r-gives-different-results-than-exponential-smoothing-from-statsmod</link>
      <description><![CDATA[我正在尝试将我的 R 模型迁移到 Python。在此过程中，R 中 HoltWinters 的预测与 statsmodels 中的指数平滑模型的输出不匹配。
R 实现（默认）：
HoltWinters(ts(train_y$sales_quantity, frequency = 12), alpha = NULL, beta = NULL, gamma = NULL,
seasonal = c(&quot;additive&quot;, &quot;multiplicative&quot;),
start.periods = 2, l.start = NULL, b.start = NULL,
s.start = NULL,
optim.start = c(alpha = 0.3, beta = 0.1, gamma = 0.1),
optim.control = list())

Python 版本
hw_mod = ExponentialSmoothing(train_y[&quot;sales_quantity&quot;],
freq = &#39;MS&#39;,
trend=&#39;add&#39;,
seasonal=&#39;add&#39;,
seasonal_periods=12,
initialization_method = &quot;known&quot;,
initial_level=0.3,
initial_trend=0.1,
initial_seasonal=0.1,
bounds = {&#39;smoothing_level&#39; : (0, 1), &#39;smoothing_trend&#39; : (0, 1), &#39;smoothing_seasonal&#39; : (0, 1)}
).fit(method = &quot;L-BFGS-B&quot;)

我无法公开分享数据。
我已尝试为两个模型匹配尽可能多的参数，但不知道我遗漏了什么，预测并不相似。但是，我使用 Python 模型获得了更好的性能。
R 加权 RMSE：434.6
Py 加权 RMSE：388.39
改进：10.63%
]]></description>
      <guid>https://stats.stackexchange.com/questions/653830/holtwinter-in-r-gives-different-results-than-exponential-smoothing-from-statsmod</guid>
      <pubDate>Wed, 04 Sep 2024 06:43:09 GMT</pubDate>
    </item>
    <item>
      <title>MSE 变好但是 $R^2$ 变差</title>
      <link>https://stats.stackexchange.com/questions/653829/mse-gets-better-but-r2-gets-worse</link>
      <description><![CDATA[考虑以下小数据集（大约 569 个数据点），其中 Uptake 是回归目标：

如您所见，大多数变量都是倾斜的，其中一些变量在某些区域（例如 VT）只有 2 或 3 个数据点。
为了获得一些基线，我决定在这个数据集的不同分割上运行 H2O 的随机森林 AutoML，以及在简化的数据集上运行“异常值” （它们不是噪音，只是观测值稀少的区域的值）被移除（大约 300 个数据点保留）。
在原始数据集上，一些分割在测试集上有非常好的 $R^2$（接近 0.95），但大多数分割的 MSE 都比较平均（~3.2）。另一方面，在缩减的数据集上，大多数分割在测试集上有非常好的 MSE，但所有分割中最好的 $R^2$ 大约为 0.65。
有人能解释为什么会发生这种情况吗？这些“异常值”会干扰 $R^2$ 吗？
此外，关于如何处理这些特征（例如对数变换，...​​）有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653829/mse-gets-better-but-r2-gets-worse</guid>
      <pubDate>Wed, 04 Sep 2024 06:27:09 GMT</pubDate>
    </item>
    <item>
      <title>对框内的线段进行采样</title>
      <link>https://stats.stackexchange.com/questions/653827/sampling-line-segments-within-a-box</link>
      <description><![CDATA[我有点不知道从哪里开始解决我遇到的采样问题，所以任何方向都会有所帮助。我本质上想在一个边界正方形内采样长度相同的线段。想象一下把一根针扔进一个方形圆柱体，看看它是如何落地的（一遍又一遍）。
如果正方形的边小于线段的长度，你可以想象分布是X形的。我想了解随着正方形的增长，这种情况是如何变化的。卷积在这里如何应用？
可能相关：https://math.stackexchange.com/questions/4796686/probability-of-line-segments-intersecting-on-a-plane-a-generalization-to-buffo?rq=1]]></description>
      <guid>https://stats.stackexchange.com/questions/653827/sampling-line-segments-within-a-box</guid>
      <pubDate>Wed, 04 Sep 2024 04:29:24 GMT</pubDate>
    </item>
    <item>
      <title>计算高斯混合模型 Fisher 信息矩阵中的期望值</title>
      <link>https://stats.stackexchange.com/questions/653826/computing-expectations-in-fisher-information-matrix-for-gaussian-mixture-models</link>
      <description><![CDATA[考虑一个具有 $K$ 个分量的高斯混合模型 (GMM)：
$p(x) = \sum_{k=1}^K \pi_k \mathcal{N}(x; \mu_k, \Sigma_k)$
其中 $\pi_k$ 为混合系数，$\mu_k$ 为均值向量，$\Sigma_k$ 为协方差矩阵。
职责 $\gamma_k(x)$ 定义为：
$\gamma_k(x) = \frac{\pi_k \mathcal{N}(x; \mu_k, \Sigma_k)}{\sum_{j=1}^K \pi_j \mathcal{N}(x; \mu_j, \Sigma_j)}$
在计算此 GMM 的 Fisher 信息矩阵 (FIM) 时，我遇到了两种类型的期望：

$\mathbb{E}[\gamma_k(x)\gamma_l(x)]$

$\mathbb{E}[\gamma_k(x)\gamma_l(x)f(x)]$，其中 $f(x)$ 可以是类似 $(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k)$ 的表达式


问题：

是否有更精确的表达式或方法来计算 $\mathbb{E}[\gamma_k(x)\gamma_l(x)]$，尤其是当组件分离不充分时？

我该如何计算 $\mathbb{E}[\gamma_k(x)\gamma_l(x)f(x)]$？是否有针对此类术语的分析方法或标准近似值？

文献中是否有成熟的技术可用于在 GMM 的 FIM 背景下处理此类期望？


如能提供任何见解、参考资料或解决策略，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653826/computing-expectations-in-fisher-information-matrix-for-gaussian-mixture-models</guid>
      <pubDate>Wed, 04 Sep 2024 04:13:05 GMT</pubDate>
    </item>
    <item>
      <title>低 $R^2$ 谜题</title>
      <link>https://stats.stackexchange.com/questions/653822/low-r2-puzzle</link>
      <description><![CDATA[我进行了一项实验，并使用数据拟合了一个基本的线性回归模型。上图显示了拟合结果。$R^2$ 非常低，表明几乎没有解释力（调整后的 $R^2$ 甚至更低）。但是，当我绘制每组 x 值的 y 值平均值时，我可以非常清楚地看到线性关系。第 7 组的平均值比第 2 组的平均值高很多。通常我会根据 F 统计量（2.253）、$R^2$、解释变量的 t 统计量等指标来抛弃这种回归。但很明显，它告诉我，组数越高，效果就越好。组平均值的差异很明显，而且随着组数的增加而增加。我有点困惑。是回归分析让我失望了，还是我对结果的解释是错误的？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653822/low-r2-puzzle</guid>
      <pubDate>Wed, 04 Sep 2024 02:50:44 GMT</pubDate>
    </item>
    <item>
      <title>在轮盘赌中，出现长红色序列的频率是否低于出现短红色序列的频率？</title>
      <link>https://stats.stackexchange.com/questions/653816/in-roulette-is-the-frequency-of-getting-long-sequences-of-reds-lower-than-that</link>
      <description><![CDATA[在一场无限期的轮盘游戏中，与连续 10 次出现红色相比，连续 100 次出现红色的概率（可能每百万次旋转才出现一次）要小得多，这样说对吗？
如果出现一长串红色的概率会随着序列变长而降低，那么为什么认为在一长串红色之后出现黑色的可能性更大会被视为赌徒谬误？如果 101 次出现红色的序列比 100 次出现红色的序列出现的可能性更小，那么为什么认为当前序列更有可能是 100 次出现红色并因此下一轮旋转将是黑色是错误的？
编辑：
我知道这些都是独立事件，概率没有记忆，因此必须保持不变。我在问，这一事实如何与较长序列出现频率较低的说法相一致。
此外，我并不是说根据大数定律，它应该平衡，因此下一次旋转更有可能是黑色。我是说，我们更有可能处于 100 个红色的序列而不是 101 个红色的序列，因为它发生的频率更高，并且如果更有可能假设现在是较短的序列而不是较长的序列，那么从逻辑上讲，下一次旋转更有可能是黑色不是吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653816/in-roulette-is-the-frequency-of-getting-long-sequences-of-reds-lower-than-that</guid>
      <pubDate>Tue, 03 Sep 2024 23:44:05 GMT</pubDate>
    </item>
    <item>
      <title>当尝试找到离散数据的四分位数时，我们是否四舍五入到最接近的整数？</title>
      <link>https://stats.stackexchange.com/questions/653812/when-trying-to-find-the-quartiles-for-discrete-data-do-we-round-to-the-nearest</link>
      <description><![CDATA[我有 2 个案例：
首先，我想找到集合数据的第一个四分位数：1,2,3,4,5。
通常我们计算四分位数如下：
现在 $Q_1 = \frac{2+1}{2} = 1.5$。
但他们从未说明它是连续的（即数据是身高、体重等的集合）还是离散的（即人数、进球数等）
但假设 他们确实说明它是离散的，我们是保留 $Q_1 = 1.5$ 不变，还是四舍五入到2？
第二
当尝试找到分组离散数据的四分位数时，我们是否要四舍五入到最接近的整数？
我找不到一个明确的答案，即我们是否对分组离散数据进行四舍五入（当使用累积频率图查找四分位数时）
示例：前 16 天每天编程时收到的错误数记录在频率表中。
（此数据的示例可以是：0,1,1,8,7,9, 10,11,11,11,19,15, 21,25,29,35）
（y 轴为 c.频率，x 轴为错误）
$Q_1 = 6.5$，我们四舍五入到 7，还是保留 6.5？

如果您能就这个问题提供任何见解，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653812/when-trying-to-find-the-quartiles-for-discrete-data-do-we-round-to-the-nearest</guid>
      <pubDate>Tue, 03 Sep 2024 21:41:09 GMT</pubDate>
    </item>
    <item>
      <title>如何确定双差分设计中未治疗组的治疗时间</title>
      <link>https://stats.stackexchange.com/questions/653633/how-to-determine-the-treatment-time-for-untreated-in-difference-in-differences-d</link>
      <description><![CDATA[我正在使用差异-差异 (DiD) 设计估计治疗启动对健康结果的影响。时间线是相对于治疗日期而不是日历时间定义的。对于治疗组，索引时间 (t=0) 是每个人开始治疗的日期，治疗前期最多为 3 年，治疗后期最多为治疗后 3 年。
我的挑战是确定对照组（未开始治疗的人）的伪治疗日期，以类似地定义他们的治疗前期和治疗后期。
我正在考虑根据治疗组中治疗启动日期的分布随机为对照组分配伪治疗日期。具体来说，我计划根据关键变量对参与者进行分层，并在每个层内，从治疗组中观察到的诊断和治疗开始之间的持续时间进行替换抽样，为该层的对照组分配一个伪治疗日期。
我的问题是：

有没有更好的方法来分配伪治疗日期？
如果这种方法有效，我如何计算由于对照组伪治疗日期的随机性而导致的不确定性？通过改变这些日期进行敏感性分析是否足够？
是否有任何参考文献或研究讨论过这种方法或类似的问题？我在术语方面遇到困难，希望得到有关寻找什么的指导。

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653633/how-to-determine-the-treatment-time-for-untreated-in-difference-in-differences-d</guid>
      <pubDate>Fri, 30 Aug 2024 16:12:41 GMT</pubDate>
    </item>
    <item>
      <title>如何计算比例的 MDE？</title>
      <link>https://stats.stackexchange.com/questions/623502/how-to-calculate-mde-for-proportions</link>
      <description><![CDATA[在进行 AB 测试时，我们使用功效分析来计算样本量，包括 alpha、功效和 MDE（最小可检测效应）参数。
连续变量的平均 MDE 似乎很直观：使用 Cohen&#39;s D 计算标准化均值差 = (M1-M2)/合并 SD
如果我有比例，计算 MDE 的好方法是什么？以及如何反过来计算，如果我们想要检测 5% 的 MDE，如何将其转化为实际的相对变化？
例如，基线转化率为 10%，我们想要检测相对 10% 的提升（即 10% *1.1 = 11% 的转化率），MDE 是多少？如果我们想检测 5% 的 MDE，我们可以从基线转化率检测到的相对变化是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/623502/how-to-calculate-mde-for-proportions</guid>
      <pubDate>Tue, 08 Aug 2023 15:06:11 GMT</pubDate>
    </item>
    <item>
      <title>是否存在基于最大概率的决策树杂质度量？</title>
      <link>https://stats.stackexchange.com/questions/618457/is-there-a-decision-tree-impurity-metric-based-on-maximum-of-probabilities</link>
      <description><![CDATA[我试图理解决策树学习中的杂质指标，特别是基尼杂质。对基尼杂质的假设之一提出质疑让我想到了另一种杂质测量方法，这对我来说更有意义，但我在网上找不到太多关于它的信息。
假设我们有一个分类问题，有 $ K $ 个类。为了决定根据哪个属性进行拆分，我们假装已经完成了拆分，并对子节点的杂质测量结果进行加权求和。我们对每个属性重复此操作，并选择使加权和最小化的属性。
假设子节点处类的相对频率为 $ p_1, \dots, p_K $。那么子节点的基尼不纯度为 $ 1 - \sum_{i=1}^{K} p_i^2 $。我对此的合理解释是，如果我们根据概率分布随机地为子节点分配一个类，那么基尼系数就是该节点上新的随机示例被错误分类的概率。
但是我们为什么要随机分配节点的类别呢？当然，最好的选择是分配该节点上相对频率最高的类别。那么，新的随机示例被错误分类的概率为 $ 1 - \max_{i=1}^{K} p_i $。这给出了一种新的杂质类型。
我遇到了一种称为 Tsallis 熵的东西，它有一个参数 $ q $。在极限 $ q \rightarrow 1 $ 下，Tsallis 熵收敛到 Shannon 熵。对于 $ q = 2 $，它等于基尼不纯度。上面定义的新不纯度与极限 $ q \rightarrow \infty $ 有关。
是否有任何“明显”的理论原因可以解释为什么这种基于最大值的不纯度比主流的 Shannon 熵和基尼不纯度更差？还是只是因为其他不纯度是先发明的，并且在实践中表现良好，所以没有必要寻找其他东西？]]></description>
      <guid>https://stats.stackexchange.com/questions/618457/is-there-a-decision-tree-impurity-metric-based-on-maximum-of-probabilities</guid>
      <pubDate>Sun, 11 Jun 2023 10:11:04 GMT</pubDate>
    </item>
    </channel>
</rss>