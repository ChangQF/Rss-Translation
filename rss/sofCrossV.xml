<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 12 Aug 2024 15:17:44 GMT</lastBuildDate>
    <item>
      <title>R 中接收者操作特征 (ROC) 曲线的功率分析</title>
      <link>https://stats.stackexchange.com/questions/652661/power-analysis-for-receiver-operating-characteristic-roc-curves-in-r</link>
      <description><![CDATA[我需要进行先验功效分析，以确定我们设计的研究的最小样本量。
在本研究中，我们将利用接收者操作特性 (ROC) 曲线来评估三种不同生物标记物 (A、B、C) 在区分给定疾病阶段方面的有效性：正常（无疾病）、轻度阶段和重度阶段。
此外，这些曲线将分别针对携带特定蛋白质基因（携带者）和没有此风险因素（非携带者）的参与者进行分析。值得注意的是，生物标记物 (A、B、C) 将作为连续变量进行测量。
如果您能分析 R 中实现的用于计算功效分析的函数，我将不胜感激。
我主要担心的是，在实现的函数中，每组使用 50 或 5 名参与者会产生高功效结果 (&gt; 80)。我需要选择非常低的效果大小（比如说 0.0、0.1 和 0.2）来实现分析的低功率。在我的研究领域，0.00（基线）、0.2（轻度）和 0.40（重度）的值被视为保守方法，
感谢您的帮助！
library(pROC)

set.seed(123)

# 定义参数
n_sim &lt;- 1000 # 模拟次数
n &lt;- 50 # 每组用于测试的小样本量
mu &lt;- c(0.00, 0.2, 0.40) # 正常、轻度、重度的效果大小 / 我们将正常的效果大小设置为零，因为它可以作为参考组（基线）
sigma &lt;- 0.1 # 标准差（假设方差相等）
alpha &lt;- 0.05 # 显着性水平

# 结果存储
power_results &lt;- data.frame(protein_status = rep(c(&quot;carrier&quot;, &quot;non-carrier&quot;), each = 3),
comparison = rep(c(&quot;Normal vs Mild&quot;, &quot;Normal vs Severe&quot;, &quot;Mild vs Severe&quot;), 2),
biomarker = rep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), each = 6),
power = NA)

# 循环遍历蛋白质状态、生物标志物和成对比较
for (protein in c(&quot;carrier&quot;, &quot;non-carrier&quot;)) {
for (biomarker in c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)) {
for (comparison in c(&quot;Normal vs Mild&quot;, &quot;Normal vs Severe&quot;, &quot;Mild vs Severe&lt;)) {

sig_count &lt;- 0

# 运行模拟
for (i in 1:n_sim) {

# 模拟每个组的数据
data_normal &lt;- rnorm(n, mean = mu[1], sd = sigma)
data_mild &lt;- rnorm(n, mean = mu[2], sd = sigma)
data_severe &lt;- rnorm(n, mean = mu[3], sd = sigma)

# 根据比较选择数据
if (comparison == &quot;Normal vs Mild&quot;) {
data &lt;- data.frame(
value = c(data_normal, data_mild),
group = factor(rep(c(&quot;normal&quot;, &quot;mild&quot;), each = n))
)
} else if (comparison == &quot;正常 vs 严重&quot;) {
data &lt;- data.frame(
value = c(data_normal, data_severe),
group = factor(rep(c(&quot;正常&quot;, &quot;严重&quot;), each = n))
)
} else if (comparison == &quot;轻度 vs 严重&quot;) {
data &lt;- data.frame(
value = c(data_mild, data_severe),
group = factor(rep(c(&quot;轻度&quot;, &quot;严重&quot;), each = n))
)
}

# 计算 ROC 曲线并抑制消息
roc_res &lt;- suppressMessages(roc(data$group, data$value, levels = rev(levels(data$group))))

# 计算置信区间AUC
ci &lt;- ci.auc(roc_res)

# 调试：打印前几次模拟的 AUC 和置信区间
if (i &lt;= 10) {
cat(&quot;Sim:&quot;, i, &quot;AUC:&quot;, auc(roc_res), &quot;CI:&quot;, ci, &quot;\n&quot;)
}

# 检查置信区间的下限是否大于 0.5
if (ci[1] &gt; 0.5) {
sig_count &lt;- sig_count + 1
}
}

# 计算功效
power &lt;- sig_count / n_sim

# 存储结果
power_results[power_results$protein_status == Protein &amp; power_results$biomarker == biomarker &amp; power_results$comparison == Comparison, &quot;power&quot;] &lt;- power
}
}
}

# 打印结果
print(power_results)

]]></description>
      <guid>https://stats.stackexchange.com/questions/652661/power-analysis-for-receiver-operating-characteristic-roc-curves-in-r</guid>
      <pubDate>Mon, 12 Aug 2024 15:15:31 GMT</pubDate>
    </item>
    <item>
      <title>当推导 ELBO 来解决变分推理问题时，为什么我们知道 p(z) 和 p(x,z)，但不知道 p(x) 和 p(z|x)？</title>
      <link>https://stats.stackexchange.com/questions/652660/when-deriving-elbo-to-solve-variational-inference-problems-why-do-we-know-pz-a</link>
      <description><![CDATA[我对 ELBO 的推导有点困惑，因为我不明白为什么有些分布是已知的，而有些分布是未知的。
我猜我们知道 p(z)（先验），因为它是考虑前一个证据后 q(z) 的最后一个值？
我猜我们不能使用 p(z|x) = p(x,z) / p(x)，因为我们不知道 p(x)？
我不知道我们怎么知道 p(x,z) 却不知道 p(x)。p(x) 中的信息肯定包含在 p(x,z) 中？所以如果你知道 p(x,z)，那么你应该能够找到 p(x)？
任何帮助都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652660/when-deriving-elbo-to-solve-variational-inference-problems-why-do-we-know-pz-a</guid>
      <pubDate>Mon, 12 Aug 2024 15:11:54 GMT</pubDate>
    </item>
    <item>
      <title>平方指数核的不同参数化</title>
      <link>https://stats.stackexchange.com/questions/652659/different-parametrizations-of-squared-exponential-kernel</link>
      <description><![CDATA[假设$u, v \in \mathbb R^d$，其中$u = (u_1, \dots, u_d)$且$v = (v_1, \dots, v_d)$。 本文（第 7-8 页）将平方指数（或高斯）相关函数定义为
$$
\rho(u, v) = \exp\left(-\sum_{j = 1}^d \frac{(u_j - v_j)^2}{2\theta_j^2}\right)。 \tag{1}
$$
（我使用的符号与论文中略有不同。）
这篇其他论文（第 367 页）将内核定义为
$$
\rho&#39;(u, v) = \exp\left(-\sum_{j = 1}^d \theta&#39;_j (u_j - v_j)^2\right)。 \tag{2}
$$
（我再次使用了略有不同的符号。）
我希望对从 $(1)$ 中的参数化转换为 $(2)$ 进行健全性检查。假设我使用 $(1)$ 中的内核在 $\mathbb R^2$ 中拟合高斯过程模型，并得到 $\theta_1 = 2$ 和 $\theta_2 = 3$。如果我想从$(2)$的角度分析这些值，我认为只需记下$\theta&#39;_j = 1/(2\theta_j^2)$，这样我就会得到$\theta&#39;_1 = 1/(2 \cdot 2^2) = 1/8$和$\theta&#39;_2 = 1/(2 \cdot 3^2) = 1/18$。
是这样的吗？任何帮助我都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652659/different-parametrizations-of-squared-exponential-kernel</guid>
      <pubDate>Mon, 12 Aug 2024 15:01:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么卡方检验可以拒绝原假设，而 KS 检验却不能？</title>
      <link>https://stats.stackexchange.com/questions/652657/how-can-the-chi-square-reject-the-null-hypothesis-while-the-ks-test-does-not</link>
      <description><![CDATA[与F 检验如何拒绝零假设而 KS 检验却不能？类似，我想知道，卡方检验如何拒绝零假设而 KS 检验却不能？
例如，我可以得到卡方检验的 p 值为 $0.001$，KS 检验的 p 值为 $0.45$。
我指定我指的是双样本检验，其中使用卡方检验和Kolmogorov-Smirnov 检验，零假设是两个数据样本来自同一分布/两个样本相同。
另外，我理解卡方检验“测量” 落入 bin“i” 的观测值数量（第一个数据集/分布）与预计落入 bin“i” 的观测值数量（第二个数据集/分布）之间的平方差，而 Kolmogorov-Smirnov 检验“测量”两个 ECDF 之间的最大距离。
也就是说，KS 测试“往往对分布中心附近比尾部更敏感”，但只是我的解释，卡方检验似乎对分布的每个“部分”都很敏感，因为观测值和预期值之间的平方差是针对分布的所有箱体计算的。
但是，我无法“看到”为什么卡方检验会拒绝零假设，即两个数据集/分布不同，而 KS 检验不会被拒绝（即我们无法拒绝），即我们没有足够的统计证据证明两个数据集/分布不同。
这两种“情况”，即 (i) 卡方检验拒绝零假设和 (ii) KS 检验无法拒绝零假设，可以共存吗？
（附加问题：在科学论文中报告这些相反的结果，即 (i) 和 (ii)，是否正确？）]]></description>
      <guid>https://stats.stackexchange.com/questions/652657/how-can-the-chi-square-reject-the-null-hypothesis-while-the-ks-test-does-not</guid>
      <pubDate>Mon, 12 Aug 2024 14:18:18 GMT</pubDate>
    </item>
    <item>
      <title>相互作用的样条函数与样条函数的相互作用</title>
      <link>https://stats.stackexchange.com/questions/652652/splines-of-interactions-vs-interaction-of-splines</link>
      <description><![CDATA[我对样条函数还不熟悉，我需要开发一个包含 2 个连续变量的样条函数相互作用的模型。我不确定 2 个模型中的哪个是正确的，以及 2 个模型中的解释是什么？我无法在网上找到任何可以指导我找到合适方法的信息。
模型 1：Y= spline (x) + spline(z) + spline(x) * spline(z)
模型 2：Y= spline (x) + spline(z) + spline(x*z)
这两个模型有何不同，它们的解释是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652652/splines-of-interactions-vs-interaction-of-splines</guid>
      <pubDate>Mon, 12 Aug 2024 13:37:36 GMT</pubDate>
    </item>
    <item>
      <title>指数和数值稳定对数概率</title>
      <link>https://stats.stackexchange.com/questions/652651/sums-of-exponentials-numerically-stable-log-probability</link>
      <description><![CDATA[在这个问题中，我问：
如果我们有：$\tau_i \overset{\text{independent}}{\sim}
\exp(\lambda_i)$，对于$i=1,2,3,...,n$，其中$\lambda_i\neq \lambda_j, \forall i\neq j$，那么我想找到概率的一般形式：
$$
\text{Pr}(\sum_{i=1}^{n-1} \tau_i \leq t, \sum_{i=1}^{n} \tau_i &gt; t)
$$
我收到了 Ben 的回答：
$$
\sum_{i=1}^{n-1} m_{n,i} \cdot [ \exp (- \lambda_i t) - \exp (- \lambda_n t) ],
$$
其中术语 $m_{n,j}$ 定义为如：
$$
m_{n,i} = \frac{\lambda_i}{\lambda_n} \prod_{j=1 \\ j \neq i}^{n} \frac{\lambda_j}{\lambda_j-\lambda_i}。
$$
我发现，当 $n$ 相当大（甚至高于 10）时，上述规则计算出的概率在计算上可能会变为负数。即由于 $m_{n,i}$ 既可以为正数也可以为负数，因此计算的精度对于确保概率为正数非常重要。
我想知道是否有一种计算稳定的方法来计算 对数概率？
注意：我意识到 $m_{n,i}$ 的一部分就是所谓的 拉格朗日多项式：
$$
l_j(0) := \prod_{j=1 \\ j \neq i}^{n} \frac{\lambda_j}{\lambda_j-\lambda_i},
$$
其确实有一个稳定的形式定义在这里。不过，我试过了，对于中等大小的 n，我仍然会得到负概率。这也是我希望找到对数概率更稳定表达式的部分原因；使用对数概率也更方便，因为我正在做使用这个的 MCMC。
注意：使用这里设计的一些用于稳定和对数的巧妙解决方案并不简单，因为$m_{n,i}$ 可能是负数。]]></description>
      <guid>https://stats.stackexchange.com/questions/652651/sums-of-exponentials-numerically-stable-log-probability</guid>
      <pubDate>Mon, 12 Aug 2024 13:33:50 GMT</pubDate>
    </item>
    <item>
      <title>自相关和/或非平衡数据的 PCA 和 tICA</title>
      <link>https://stats.stackexchange.com/questions/652650/pca-and-tica-on-autocorrelated-and-or-non-equilibrium-data</link>
      <description><![CDATA[从标题中可以推断，如果我想对一个过程进行 PCA 或时间滞后的独立成分分析，其中我考虑的每个特征都是以点为单位采样的，每个或某些特征都是自相关的（即带有其先前状态的记忆），该怎么办？我不应该认为它们是随机的，那么对于每个提到的算法，结果的含义又如何呢？
然后，假设我有另一种情况，我确实在系列之间以足够的时间间隔对点进行采样，但我对一个仍在向平衡发展的过程进行采样。这两个算法的两个结果的含义是什么？
最后，作为一个单独的问题，我想知道是否需要满足随机性和平稳过程才能应用这两种技术。]]></description>
      <guid>https://stats.stackexchange.com/questions/652650/pca-and-tica-on-autocorrelated-and-or-non-equilibrium-data</guid>
      <pubDate>Mon, 12 Aug 2024 13:32:37 GMT</pubDate>
    </item>
    <item>
      <title>功能性 PCA 仅仅是基于基础系数的 PCA 吗？</title>
      <link>https://stats.stackexchange.com/questions/652643/is-a-functional-pca-just-a-pca-on-basis-coefficients</link>
      <description><![CDATA[函数主成分分析（FPCA）只是正交基系数上的普通 PCA 吗？以下似乎表明确实如此。
首先，让我们对加拿大天气数据进行 FPCA：
import numpy as np
import skfda as fda
from skfda.preprocessing.dim_reduction import FPCA
from sklearn.decomposition import PCA

# 获取加拿大天气数据
weather = fda.datasets.fetch_weather()
weather_data_grid = fda.FDataGrid(data_matrix = weather.data.data_matrix[:, :, 0],
grid_points = weather.data.grid_points,
domain_range = weather.data.domain_range)
# 进行 FPCA
weather_basis = fda.representation.basis.FourierBasis(domain_range = (0.0, 365.0),
n_basis = 25, period = 365)
weather_data_basis = weather_data_grid.to_basis(weather_basis)
weather_fpca = FPCA(n_components = 25)
weather_fpca.fit(weather_data_basis)

现在获取基础系数并对其进行常规的旧 PCA：
pca = PCA(n_components = 25)
pca.fit(weather_data_basis.coefficients)

并比较结果：
np.allclose(weather_fpca.explained_variance_ratio_, pca.explained_variance_ratio_)
np.allclose(weather_fpca.components_.coefficients, pca.components_)

两种比较都是正确的。
FPCA 是否只是基于基础系数的 PCA，还是我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652643/is-a-functional-pca-just-a-pca-on-basis-coefficients</guid>
      <pubDate>Mon, 12 Aug 2024 09:08:08 GMT</pubDate>
    </item>
    <item>
      <title>为什么在运行ARDL模型时变量的符号会随着滞后而变化？</title>
      <link>https://stats.stackexchange.com/questions/652641/why-does-the-sign-on-the-variable-changes-with-the-lag-while-running-ardl-model</link>
      <description><![CDATA[该模型的因变量是死亡率，而自变量是平均值：平均受教育年限，GDP 为国内生产总值，百分比变化。虽然它们都是 I(0) 或 I(1)，所以我使用 ARDL 模型。但是均值的系数为正，而均值的滞后系数为负。这是正常的吗，我该如何解释它？]]></description>
      <guid>https://stats.stackexchange.com/questions/652641/why-does-the-sign-on-the-variable-changes-with-the-lag-while-running-ardl-model</guid>
      <pubDate>Mon, 12 Aug 2024 08:56:08 GMT</pubDate>
    </item>
    <item>
      <title>针对非常小的数据进行测试和训练</title>
      <link>https://stats.stackexchange.com/questions/652638/test-train-for-very-very-small-data</link>
      <description><![CDATA[我只有 25 个观测值。我不确定是否可以测试和训练数据。例如，训练集有 15 个观测值，测试集有 10 个观测值。15 个观测值对于训练来说太少了！我考虑了使用 elastic-net 的置换特征选择和 LOOCV。它在 1000 个特征中留下了 11 个。我在随机森林建模中使用了 LOOCV。所以我用 11 个特征对 15 个观测值进行了建模。我得到了不错的结果，但我不确定我是否过度拟合了]]></description>
      <guid>https://stats.stackexchange.com/questions/652638/test-train-for-very-very-small-data</guid>
      <pubDate>Mon, 12 Aug 2024 08:16:28 GMT</pubDate>
    </item>
    <item>
      <title>仅使用 elastic-net 进行特征选择</title>
      <link>https://stats.stackexchange.com/questions/652636/using-elastic-net-only-for-feature-selection</link>
      <description><![CDATA[我们可以使用正则化模型代替特征选择方法，然后使用机器学习模型来分析数据吗？
我的问题是分类，数据中有 1000 多个特征。数据是数值和分类变量的混合。我想使用正则化方法（如 elastic-net）进行特征选择，然后使用机器学习模型（如随机森林）来分析选定的特征，进行预测并找到特征重要性。但我不确定这是正确的方法！]]></description>
      <guid>https://stats.stackexchange.com/questions/652636/using-elastic-net-only-for-feature-selection</guid>
      <pubDate>Mon, 12 Aug 2024 07:15:11 GMT</pubDate>
    </item>
    <item>
      <title>获得 gamm4 模型的 EDF 1</title>
      <link>https://stats.stackexchange.com/questions/652647/getting-an-edf-of-1-for-gamm4-models</link>
      <description><![CDATA[我试图使用 R 中的 gamm4 来拟合一些 gamm，目的是进行一些模型比较，但我无法理解 GAM(M) 并构建这些模型。
为了给你提供一些背景信息，我打算回答 1. 在我的研究期间（十年），不透水性如何影响物种占有率；2. 哪种测量不透水性的方法（在 ndvi、ndbi 和城市土地覆盖百分比 [ULC] 之间）最能反映城市化对这个物种的影响？我已经使用 glms 完成了此操作，但我希望获得比这些模型提供的更多的灵活性。
对于我的数据：
二元响应变量：发生率（物种发生率；0=244，1=233）
预测因子：不透水性测量值（ndvi、ndbi、ULC）和年份（0:10）
随机效应：siteID（n=67）嵌套在集水区内（n=5）
我计划使用 GAM(M) 交叉验证（留一法或 k 倍）解决第二个问题。
由于某种原因，我的结果表明这些关系是线性的，但从我的 glms 和可视化多年来的发生概率中，我知道这不是真的。

这是我一直在使用的代码
# packages
library(mgcv)
library(gamm4)

# 加载和格式化物种数据
mydata&lt;-read.table(&quot;00_Data/mydata.txt&quot;,header=T)
mydata$siteID&lt;-as.factor(mydata$siteID)
mydata$catchment&lt;-as.factor(mydata$catchment)
mydata$year&lt;-mydata$year-min(mydata$year)
head(mydata);dim(mydata)

# 用年份拟合 gamm作为平滑项
&gt; gammmod1 &lt;- gamm4(occurrence~s(year, k=10), random=~(1|siteID/catchment), data=mydata, family=binomial)
&gt; summary(gammmod1$gam)
Family: binomial 
Link function: logit 

公式:
occurrence ~ s(year, k = 10)

参数系数:
估计标准差。误差 z 值 Pr(&gt;|z|)
(截距) -0.1858 0.2305 -0.806 0.42

平滑项的近似显著性：
edf Ref.df Chi.sq p 值
s(year) 1 1 1.096 0.295

R-sq.(adj) = -0.00317 
glmer.ML = 444.03 尺度估计 = 1 n = 477

# 拟合不带平滑项的 gamm
&gt; gammmodb &lt;- gamm4(occurrence~year, random=~(1|siteID/catchment), data=mydata, family=binomial)
&gt; summary(gammmodb$gam)
公式：
occurrence ~ year

参数系数：
估计标准差误差 z 值 Pr(&gt;|z|)
(截距) -0.69740 0.52779 -1.321 0.186
year 0.08059 0.07698 1.047 0.295

R-sq.(adj) = -0.00317 
glmer.ML = 444.03 比例估计 = 1 n = 477

# 以 ndvi 为平滑项拟合 gamm
gammmod2 &lt;- gamm4(occurrence~s(year,k=15)+s(ndvi,k=15), random=~(1|siteID/catchment),data=mydata, family=binomial)
summary(gammmod2$gam)
smooth.construct.tp.smooth.spec(object, dk$data, dk$knots) 中的误差: 
一个术语具有的唯一协变量组合少于指定的最大自由度


我仍在学习 GAM(M)，因此任何建议或论文推荐都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/652647/getting-an-edf-of-1-for-gamm4-models</guid>
      <pubDate>Mon, 12 Aug 2024 03:37:30 GMT</pubDate>
    </item>
    <item>
      <title>在经典回归中，残差是否不相关？[重复]</title>
      <link>https://stats.stackexchange.com/questions/652631/in-classical-regression-are-residuals-uncorrelated</link>
      <description><![CDATA[经典线性回归的假设之一是误差不相关。这是否意味着残差也不相关？为了具体起见，假设我们对模型参数使用 OLS 估计量。
我的直觉告诉我“不”，这似乎得到了我找不到任何关于残差不相关证据的支持。]]></description>
      <guid>https://stats.stackexchange.com/questions/652631/in-classical-regression-are-residuals-uncorrelated</guid>
      <pubDate>Mon, 12 Aug 2024 00:55:38 GMT</pubDate>
    </item>
    <item>
      <title>运行 GAM 时使用平滑因子以及对每个个体使用 bs="fs" 时的警告解释</title>
      <link>https://stats.stackexchange.com/questions/652624/warning-interpretation-when-running-a-gam-using-factor-by-smooths-and-also-using</link>
      <description><![CDATA[我想看看代谢物水平如何随时间随治疗变量（此处为抗生素）变化。有两个水平（是/否）。当我使用 bs=&quot;fs&quot; 运行以下模型 1 时，它会收到以下警告：
 警告消息：
在 gam.side(sm, X, tol = .Machine$double.eps^0.5) 中：
模型对同一变量进行了重复的一维平滑。

model1 &lt;- gam(Met1 ~ Antibiotics + s(Timepoint, k=7) +
s(Timepoint, by=Antibiotics, k=7, m=1) + 
s(Timepoint, ID_new, bs=&quot;fs&quot;, k=7) + data=pos_fullnew, method=&quot;REML&quot;)

或者，删除常见趋势 s(Timepoint)，以获得以下无警告运行。
 model2 &lt;- gam(Met1 ~ Antibiotics +
s(Timepoint, by=Antibiotics, k=7) + 
s(Timepoint, ID_new, bs=&quot;fs&quot;, k=7) + data=pos_fullnew, method=&quot;REML&quot;)

关于错误/模型将不胜感激 - 谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652624/warning-interpretation-when-running-a-gam-using-factor-by-smooths-and-also-using</guid>
      <pubDate>Sun, 11 Aug 2024 20:20:10 GMT</pubDate>
    </item>
    <item>
      <title>指数联合概率之和</title>
      <link>https://stats.stackexchange.com/questions/652620/sums-of-exponentials-joint-probability</link>
      <description><![CDATA[如果我们有：$\tau_i \overset{\text{independent}}{\sim}
\exp(\lambda_i)$，对于$i=1,2,3,...,n$，其中$\lambda_i\neq \lambda_j, \forall i\neq j$，那么我想找到概率的一般形式：
$$
\text{Pr}(\sum_{i=1}^{n-1} \tau_i \leq t, \sum_{i=1}^{n} \tau_i &gt; t)
$$
注意：我设法找到了一些Mathematica 中的具体结果，但随着 $n$ 的增长，表达式似乎变得难以处理。例如，如果 $n=2$，则上述概率变为：
$$
\frac{\left(e^{-t \lambda_1} - e^{-t \lambda_2}\right) \lambda_1}{\lambda_2 - \lambda_1}。
$$
对于 $n=3$，它变为：
$$
\frac{e^{-t (\lambda_1 + \lambda_2 + \lambda_3)} \lambda_1 \lambda_2 \left(e^{t (\lambda_1 + \lambda_2)} (\lambda_1 - \lambda_2) + e^{t (\lambda_2 + \lambda_3)} (\lambda_2 - \lambda_3) + e^{t (\lambda_1 + \lambda_3)} (-\lambda_1 + \lambda_3)\right)}{(\lambda_1 - \lambda_2) (\lambda_1 - \lambda_3) (\lambda_2 - \lambda_3)}
$$
注意：我意识到：
$$
\sum_{i=1}^{n} \tau_i \sim \text{Hypoexponential}(\lambda_1,\lambda_2,...,\lambda_n),
$$
但我不太确定如何使用它来得出一般结果（甚至是递归结果或良好的近似值）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652620/sums-of-exponentials-joint-probability</guid>
      <pubDate>Sun, 11 Aug 2024 14:56:45 GMT</pubDate>
    </item>
    </channel>
</rss>