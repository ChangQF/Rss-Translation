<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 24 Jun 2024 09:18:16 GMT</lastBuildDate>
    <item>
      <title>最小二乘法中协方差矩阵贝叶斯推导的误差</title>
      <link>https://stats.stackexchange.com/questions/649786/error-in-bayesian-derivation-of-covariance-matrix-in-least-squares</link>
      <description><![CDATA[我知道这个问题的变体已经被问过一百万次了，但我不只是问“我如何推导协方差矩阵”，而是请你检查我计算中的错误，因为我被难住了……
我有最小二乘问题
$$\min_p \frac{1}{2}\lVert r(p)\rVert^2,$$
其中$r(p) = W(y-f(p))$是我的残差向量。这里 $y\in \mathbb{R}^{N_y}$ 是观测向量，$f(p)$ 是向量值模型函数，$p \in \mathbb{R}^{N_p}$ 是参数。权重矩阵为 $W=\text{diag}(1/\sigma_1,...,\sigma_{N_y})$，其中 $\sigma_j$ 为索引 $j$ 处数据的标准差。
我想做的是推导出 此表达式，用于最佳拟合参数 $p^\dagger$ 的协方差矩阵：
$$C_p = \sigma^2 (J^T J)^{-1}$$
其中 $J$ 是 $r$ 的雅可比矩阵，而 $\sigma^2$ 是
$$\sigma^2 = \frac{\lVert r(p^\dagger)\rVert^2}{N_y-N_p}$$
我尝试的方法
我尝试采用贝叶斯方法，其中最小二乘最小化是从均匀先验下给定观测值的参数的最大后验估计中得出的。我将略过这部分，因为这些都是众所周知的。我很乐意提供澄清。此外，如果我在这里掩盖了错误，我也很高兴。
假设所有$y_i$、$y_j$统计独立，我应该能够将后验写为：
$$P(p|y) = K \exp\left(-\frac{1}{2} \sum_j \frac{(y_j-f_j(p))^2}{\sigma_j^2} \right) = K \exp\left( -\frac{1}{2} \lVert r(p) \rVert^2 \right) = K \exp(-g(p)),$$
其中$K$是积分常数，对于简单来说，我这样写：
$$g(p) := \frac{1}{2} \lVert r(p) \rVert^2$$
然后，我使用 I 泰勒展开式对 $g(p)$ 进行最佳拟合参数 $p^\dagger$ 进行展开，即
$$g(p) \approx g(p^\dagger) + \nabla g(p^\dagger)(p-p^\dagger) + (p-p^\dagger)^T H(p^\dagger) (p-p^\dagger) = g(p^\dagger) + \frac{1}{2}(p-p^\dagger)^T H(p^\dagger) (p-p^\dagger),$$
其中 $H(p^\dagger)$ 是 $r(p)$ 的 Hessian 矩阵，在 $p^\dagger$ 处求值，我利用了梯度在 $p^\dagger$ 处消失的事实（有关公式，请参阅 此处第 3 页）。
现在我可以近似后验as
$$P(p|y) = K^\prime \exp\left( -\frac{1}{2}(p-p^\dagger)^T H(p^\dagger) (p-p^\dagger) \right),$$
其中我已将进一步的常数因子吸收到 $K^\prime$ 中。在我看来，这是一个 多元正态分布，其协方差矩阵为 $H(p^\dagger)^{-1}$。现在我知道我们经常用最小二乘近似法将 Hessian 近似为 $H=J^TJ$，这样我就可以得到协方差矩阵：
$$C_p = (J^T J)^{-1}$$
与我想要导出的表达式相比，这个表达式缺少 $\sigma^2$，我不知道我的逻辑哪里有缺陷。我感谢所有的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/649786/error-in-bayesian-derivation-of-covariance-matrix-in-least-squares</guid>
      <pubDate>Mon, 24 Jun 2024 09:16:27 GMT</pubDate>
    </item>
    <item>
      <title>比较同一模型内的风险比</title>
      <link>https://stats.stackexchange.com/questions/649783/comparing-hazard-ratios-within-the-same-model</link>
      <description><![CDATA[我有一个包含两个预测因子的 Cox 回归模型：
预测因子 A：HR = 2.00，Z = 15.24，范围为 0-1（连续）
预测因子 B：HR = 0.97，Z = -6.68，范围为 1-17，
根据这些信息，我能说第一个变量对结果的影响更大吗？如果不是，我如何确定哪个预测因子的影响更大？
本质上，我正在寻找 OLS 中的 Beta 之类的东西。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649783/comparing-hazard-ratios-within-the-same-model</guid>
      <pubDate>Mon, 24 Jun 2024 07:26:53 GMT</pubDate>
    </item>
    <item>
      <title>具有多个独立变量的中介分析</title>
      <link>https://stats.stackexchange.com/questions/649782/mediation-analysis-with-multiple-independent-variables</link>
      <description><![CDATA[我想调查 M 是否在多个独立变量（X1、X2、X3）与 Y 的关系中起中介作用。我使用 R 中的中介包。这种使用 treat = &#39;X1&#39;、treat = &#39;X2&#39; 和 treat = &#39;X3&#39; 运行 3 个中介分析的方法是否正确？如果不是，正确的方法是什么？
fit.totaleffect &lt;- lmer(Y ~ TimePoint + X1 + X2 + X3 + covariate1 + covariate2 + (1 + TimePoint | ID), data = df)
fit.mediator &lt;- lmer(M ~ TimePoint + X1 + X2 + X3 + covariate1 + covariate2 + (1 + TimePoint | ID), data = df)
fit.dv &lt;- lmer(Y ~ M + TimePoint + X1 + X2 + X3 + covariate1 + covariate2 + (1 + TimePoint | ID), data = df)

# 中介分析
results_x1 &lt;- mediation::mediate(fit.mediator, fit.dv, treat=&#39;X1&#39;, mediator=&#39;M&#39;, sims = 500)
summary(results_x1)

results_x2 &lt;- mediation::mediate(fit.mediator, fit.dv, treat=&#39;X2&#39;, mediator=&#39;M&#39;, sims = 500)
summary(results_x2)

results_x3 &lt;- mediation::mediate(fit.mediator, fit.dv, treat=&#39;X3&#39;, mediator=&#39;M&#39;, sims = 500)
summary(results_x3)
]]></description>
      <guid>https://stats.stackexchange.com/questions/649782/mediation-analysis-with-multiple-independent-variables</guid>
      <pubDate>Mon, 24 Jun 2024 06:59:15 GMT</pubDate>
    </item>
    <item>
      <title>（如何）ROC/AUC 分析适应具有两个（或更多）阈值的问题？</title>
      <link>https://stats.stackexchange.com/questions/649780/how-can-roc-auc-analysis-be-adapted-to-problems-with-two-or-more-thresholds</link>
      <description><![CDATA[(如何) ROC/AUC 分析可以适应具有两个（或更多）阈值的问题？
示例 1：
我们测量变量 $x$，如果它落入区间 $[a, b]$，则分配标签 $1$，否则标记 $0$。然后我们有两个参数 $a,b$ 控制 TPR 和 FPR。
示例 2：
如果 $x&lt;a$，我们分配类 $0$，如果 $x&gt;b$ (b&gt;a)，我们分配类 $1$。如果 x 落入区间 $[a,b]$，则决策基于将第二个变量 $y$ 与阈值 $c$ 进行比较。]]></description>
      <guid>https://stats.stackexchange.com/questions/649780/how-can-roc-auc-analysis-be-adapted-to-problems-with-two-or-more-thresholds</guid>
      <pubDate>Mon, 24 Jun 2024 05:48:03 GMT</pubDate>
    </item>
    <item>
      <title>小样本 MLE 与 OLS 效率</title>
      <link>https://stats.stackexchange.com/questions/649779/small-sample-mle-vs-ols-efficiency</link>
      <description><![CDATA[MLE 估计是渐近有效的。MLE 和 OLS 估计都是渐近正态的，并且对于许多分布，它们的极限方差是一致的（在这种情况下，一个观测值的信息是其方差的倒数）。因此，至少从大样本理论来看，我没有看到在这种情况下偏爱其中一个的明确理由。现在，直观地看，我认为，假设概率模型是正确的（并且不是正态的），MLE 对于小样本也应该更有效。在这方面有任何已知结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649779/small-sample-mle-vs-ols-efficiency</guid>
      <pubDate>Mon, 24 Jun 2024 03:58:46 GMT</pubDate>
    </item>
    <item>
      <title>如何实际使用 BCa 引导区间的经验影响函数？</title>
      <link>https://stats.stackexchange.com/questions/649776/how-to-actually-use-the-empirical-influence-function-for-bca-bootstrap-intervals</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/649776/how-to-actually-use-the-empirical-influence-function-for-bca-bootstrap-intervals</guid>
      <pubDate>Mon, 24 Jun 2024 03:28:34 GMT</pubDate>
    </item>
    <item>
      <title>生存分析 - 对于创建随时间变化的协变量，按失败时间进行分裂而不是按协变量变化进行分裂有什么好处吗？</title>
      <link>https://stats.stackexchange.com/questions/649774/survival-analysis-any-benefit-to-splitting-on-failure-time-instead-of-covariat</link>
      <description><![CDATA[当需要为生存模型创建随时间变化的协变量时，我习惯于使用（我所理解的）计数过程结构来处理我的数据，其中每个人可能有多行数据，每行定义一个时间间隔（开始、停止时间）并包含该间隔期间协变量的值。
然而，在阅读有关使用 tvc 的更多内容时，我遇到了一种方法，该方法涉及在每个唯一事件时间（而不是协变量变化）处分割时间，并从中创建适当的时间间隔。但是由于您要考虑所有事件来分割时间，因此数据集可能会变得非常大。
我知道 Cox 模型只关注事件时间（参数模型呢？），所以我想如果您获得了该粒度级别的协变量信息，这可能是更好的方法？但除此之外，这样做还有其他好处吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649774/survival-analysis-any-benefit-to-splitting-on-failure-time-instead-of-covariat</guid>
      <pubDate>Mon, 24 Jun 2024 02:28:55 GMT</pubDate>
    </item>
    <item>
      <title>解释两阶段统计检验问题的引文</title>
      <link>https://stats.stackexchange.com/questions/649761/citations-explaining-the-problems-with-two-stage-statistical-testing</link>
      <description><![CDATA[我正在写一篇关于分析对数正态分布抽样数据的评论，我想解释一下首先运行正态性检验并使用该结果选择运行哪个检验的问题。
首先运行方差相等性检验并使用该结果选择第二个检验也会出现同样的问题。
这种“两阶段”程序（一定有更好的名称）会扭曲第二次检验的结果。
我要求引用一些论文来解释这个问题并举例说明两阶段测试如何产生误导。]]></description>
      <guid>https://stats.stackexchange.com/questions/649761/citations-explaining-the-problems-with-two-stage-statistical-testing</guid>
      <pubDate>Sun, 23 Jun 2024 20:07:09 GMT</pubDate>
    </item>
    <item>
      <title>GAM：平滑和因子交互作用</title>
      <link>https://stats.stackexchange.com/questions/649744/gam-smooth-and-factor-interaction</link>
      <description><![CDATA[我目前正在研究 GAM。它包括平滑因子交互。我正在尝试确定哪个函数是我需要的。
Model_gamlog2 &lt;- mgcv::gam(perpetration_all ~ dar_scale + s(dar_scale, by = age_binary) + age_binary, data = merged_all_complete, family=binomial, method = &quot;REML&quot;)

&gt; summary(Model_gamlog2)

系列：二项式 
链接函数：logit 

公式：
perpetration_all ~ dar_scale + s(dar_scale, by = age_binary) + 
age_binary

参数系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 1.7862 0.3707 4.818 1.45e-06 ***
dar_scale -0.2610 7.0429 -0.037 0.970 
age_binary2 1.7874 1.2895 1.386 0.166 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df Chi.sq p 值
s(dar_scale):age_binary1 1.000 1.000 0.010 0.920
s(dar_scale):age_binary2 1.474 2.122 2.038 0.421

排名：20/21
R-sq.(adj) = 0.0173 偏差解释 = 9.94%
-REML = 39.827 尺度估计 = 1 n = 134

这里我使用了 By= 参数。
我对此输出有一些疑问：

我是否需要 s() 作为平滑参数，或者 ti() 等是否也可以。我只希望每个 IV 级别的平滑参数在需要时有所不同。
如何查看是否存在交互？据我所知，平滑项仅告诉我每个 IV 级别的年龄与 DV 没有显着相关性，而不是它们是否不同。

或者我有以下代码：
Model_gamlog2 &lt;- mgcv::gam(perpetration_all ~ dar_scale + s(dar_scale, age_binary, bs = &quot;fs&quot;) + age_binary, data = merged_all_complete, family=binomial, method = &quot;REML&quot;)

&gt; summary(Model_gamlog2)

系列：二项式

链接函数：logit

公式：
perpetration_all ~ dar_scale + s(dar_scale, age_binary, bs = &quot;fs&quot;) + 
age_binary

参数系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) 1.8761 0.3907 4.802 1.57e-06 ***
dar_scale 0.5246 0.4452 1.178 0.2386 
age_binary2 1.2737 0.7561 1.685 0.0921 . 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df Chi.sq p 值
s(dar_scale,age_binary) 3.346 17 5.558 0.125

R-sq.(adj) = 0.0508 偏差解释 = 13.9%
-REML = 42.792 尺度估计 = 1 n = 134

s(dar_scale,age_binary) 是否显示交互作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/649744/gam-smooth-and-factor-interaction</guid>
      <pubDate>Sun, 23 Jun 2024 11:33:25 GMT</pubDate>
    </item>
    <item>
      <title>广义可加模型的模型检验</title>
      <link>https://stats.stackexchange.com/questions/649509/model-checking-for-generalized-additive-models</link>
      <description><![CDATA[我目前正在构建一个 GAM 模型来描述房价。该数据集是特定地理区域内大约 20 万笔房屋销售的集合。
根据本论坛先前的建议，平均房价$p_{i}$的建模方式如下：
$$
\ln (p_{i}) = \sum_{j}s_{j}(x_{i,j}) \ \ , \ \ P_{i} \sim Tweedie(p_{i}) 
$$
，其中$s_{j}$表示我的一组协变量的第j个平滑值，这些协变量包括地理位置、房屋大小、地块大小等。由于价格的严格正性，我发现对数链接和Tweedie分布的组合提供了以样本外误差衡量的最佳结果（但是，带有对数链接的Gamma分布也表现得相当不错 -有关详细信息，请参阅我之前的帖子从拟合的 t 分布 mgcv 进行模拟）。
为了寻找最佳模型，我尝试了一系列不同的协变量，并得出了一个模型，我认为该模型在预测能力和简约性之间的平衡方面是最佳的。然而，我担心应用 mgcv（或 gratia 库中的 appraise()）提供的模型检查例程时得到的结果，如下所示：

显然，基于 QQ 图的结果表明，我的模型无法捕捉分布中的肥尾。此外，残差与线性预测器图并不像人们希望的那样是平坦的带状，而是在负残差的第一部分中有一些系统线性分量 - 我怀疑这与模型只能输出正值有关。
由于我对 GAM 模型检查的经验有限，因此我想向那些在该领域更有经验的人提出以下问题：
上述模型诊断是否表明我的模型存在严重问题，或者它们是否在人们通常可以接受的容差范围内？如果是这样，人们在基于 QQ 图等评估模型质量时使用的一般经验法则是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/649509/model-checking-for-generalized-additive-models</guid>
      <pubDate>Wed, 19 Jun 2024 11:36:50 GMT</pubDate>
    </item>
    <item>
      <title>加权线性回归的预测带</title>
      <link>https://stats.stackexchange.com/questions/649463/prediction-bands-for-weighted-linear-regression</link>
      <description><![CDATA[对于 $x_i, y_i,$ 的线性回归，我们知道置信区间为：
$$\hat{y} \pm t \cdot s \sqrt{ \frac{1}{n} + \frac{(x - \bar{x})^2}{\sum (x_i - \bar{x})^2} }$$
和预测带：
$$\hat{y} \pm t \cdot s \sqrt{ 1+ \frac{1}{n} + \frac{(x - \bar{x})^2}{\sum (x_i - \bar{x})^2} }$$
在加权线性回归情况下（权重$w_i$），我们有置信区间：
$$\hat{y} \pm t \cdot s \sqrt{ \frac{1}{\sum w_i} + \frac{(x - \bar{x}_w)^2}{\sum w_i (x_i - \bar{x}_w)^2} }$$
但预测带的公式是什么？ （与上一个公式的形式类似）
直观地讲，如果我们将权重 $1, 1, 1, 1, \ldots$ 替换为例如 $0.1, 0.1, 0.1, 0.1, \ldots$，那么波段应该保持不变，因此这表明它可能不是：
$$\hat{y} \pm t \cdot s \sqrt{ 1+ \frac{1}{\sum w_i} + \frac{(x - \bar{x}_w)^2}{\sum w_i (x_i - \bar{x}_w)^2}}$$
目标：假设我们想要在图表上绘制$(x_i, y_i)$散点、加权回归线、置信区间区域和预测带，如下所示：

那么，我们可以使用哪个公式来绘制预测带？]]></description>
      <guid>https://stats.stackexchange.com/questions/649463/prediction-bands-for-weighted-linear-regression</guid>
      <pubDate>Tue, 18 Jun 2024 14:33:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 javascript 计算 p50 和 p99 对数正态分布的 mu 和 sigma</title>
      <link>https://stats.stackexchange.com/questions/649369/calculate-mu-and-sigma-of-a-log-normal-distribution-from-p50-and-p99-in-javascri</link>
      <description><![CDATA[我想用 javascript 生成真实的货币捐赠样本数据。我选择按照对数正态分布对它们进行建模。
我认为，对于外行人来说，指定生成此数据的函数的参数的一种相当直观的方法是给出中位数和第 99 个百分位数。用日常用语来说，“平均（中位数）捐款为 50 英镑，100 笔捐款中有 1 笔超过 1000 英镑”。
我正在尝试编写一个 javascript 函数，该函数取对数正态分布的中位数和第 99 个百分位数，并输出该分布的 mu 和 sigma，以便我可以将它们用作 d3.randomLogNormal(mu, sigma) 的输入。
我已经能够为正态分布编写此函数，如下所示：
import {randomNormal} from &quot;d3&quot;;

function normalGenerator(p50, p99) {

const mu = p50;
// 第 99 个百分位数始终与中位数相差 2.3263 个标准差。
const sigma = (p99 - p50) / 2.3263;

return randomNormal(mu, sigma);
}

但我对 log 正态分布执行此操作时遇到困难。以下是我目前所处的位置：
import {randomLogNormal} from &quot;d3&quot;;

function logNormalGenerator(p50, p99) {

const mu = Math.log(p50);
const sigma = // p50 和 p99 的一些函数

return randomLogNormal(mu, sigma);
}

我相当确定 mu 应该是 Math.log(p50)，但无法弄清楚如何用 p50 和 p99 来表达 sigma（尽管我已阅读了 Wikipedia 对数正态文章和其他各种 SE 答案，并尝试了一些纸笔努力在正态和对数正态之间“转置”）。
我尝试过诸如 (Math.log(p99)-Math.log(p50)) / 2.3263 之类的组合，但此时，感觉我只是在随机输入组合。
也许我需要做的是“重新排列对数正态分布的 CDF 以使 sigma 位于左侧。然后我可以代入 mu=p50 和 x=p99”。如果是这样的话，那么我认为这样做超出了我的数学技能，尽管我想知道是否存在与我对正态分布所做的类似的捷径。无论如何，我对数学有点迷茫！
如果有帮助的话，这里有一个可观察的笔记本https://observablehq.com/d/ac3ebdbc2ab4af78，它通过生成大量样本并检查生成数据的 p50 和 p99 来检查这些函数。
如果能得到这个问题的答案，如果可能的话，对那些对日志有点生疏、对对数正态分布几乎没有经验的人来说，解释一下背后的数学知识，那就太好了:)
附加信息：
我遇到了https://distribution-explorer.github.io/continuous/lognormal.html#pdf-and-cdf-plots 它有一个 GUI 可以做我想做的事情（虽然不是用 javascript）。
如果你把它放在“分位数设置器模式”并插入以下内容：

下 y：50
下分位数：.5
上 y：1000
上分位数：.99

它输出 μ = 3.912，σ = 1.288。
当我将这些数字插入我的可观察的笔记本，我确实得到了适合的样本（我在表格“正确的对数正态性”中添加了一行来说明）。
所以本质上，我正在寻找一个 JS 函数来从上述四个值计算 σ。
最后的想法：
在找到原始问题的解决方案后，我得出结论，硬编码 sigma 是最好的方法。
当你允许人们根据他们的直觉指定 p50 和 p99 时，他们通常会提供产生不切实际的 sigma/形状的参数，例如不切实际的高 sigma 导致大量值接近 0。将 sigma 硬编码为 1 会生成一些相当合理的值。
我还决定允许他们指定平均值而不是中位数，因为平均值对大多数人来说更直观。
这导致了以下函数：
function logNormalGenerator(mean) {
const mu = Math.log(mean) - 1.6487;
return d3.randomLogNormal(mu, 1);
}

或者，如果您不想对 sigma 进行硬编码（并通过其他方法使其保持合理）：
function logNormalGenerator(mean, sigma) {
const mu = Math.log(mean) - ((sigma**2)/2);
返回 d3.randomLogNormal(mu, sigma);
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/649369/calculate-mu-and-sigma-of-a-log-normal-distribution-from-p50-and-p99-in-javascri</guid>
      <pubDate>Mon, 17 Jun 2024 09:58:01 GMT</pubDate>
    </item>
    <item>
      <title>条件模型中的 VIF 较低，但零膨胀模型中的 VIF 较高</title>
      <link>https://stats.stackexchange.com/questions/647064/low-vif-in-conditional-model-but-high-in-zero-inflated-model</link>
      <description><![CDATA[我正在使用 glm ZINB 制作基于 57 个站点的观测结果预测青蛙数量丰度的模型。我使用了 performance 包中的 check_model 函数，它显示最佳模型在条件模型中的 vif 较低（vif&lt;5），但在零膨胀模型中的 vif 较高（高达 50）（我已在下面附上图片）。我是统计领域的新手，我想知道我应该如何处理这些结果。我知道 vif&gt;5 的变量不应该在 glms 中组合，但我不确定它在零膨胀 glms 中如何适用于这两个模型。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647064/low-vif-in-conditional-model-but-high-in-zero-inflated-model</guid>
      <pubDate>Sun, 12 May 2024 03:16:44 GMT</pubDate>
    </item>
    <item>
      <title>AB 测试，哪个分母用于下部漏斗指标</title>
      <link>https://stats.stackexchange.com/questions/617357/ab-testing-which-denominator-to-use-for-lower-funnel-metrics</link>
      <description><![CDATA[假设我为一个从事订阅业务的网站运行 AB 测试。该公司提供 7 天的免费试用，然后自动为用户注册订阅并向他们收费，除非他们在试用期结束前取消。
处理方式是在结帐页面显示试用提醒消息，并在试用期结束前推送通知。用户到达结帐页面将进入实验（只有测试组会在结帐页面上看到试用提醒消息并在之后收到通知），但他们只有在输入信用卡完成结帐后才会开始试用。
如果我们想看看对取消率和每位用户平均费用的影响，我应该使用实验中的所有用户作为分母，还是只使用那些开始试用的用户作为分母来计算取消率和每位用户平均费用？
我觉得我们应该使用实验中的每个人作为分母，但只有那些开始试用的人才能取消，因此使用那些开始试用的人可以让我们更好地衡量取消率。但是，如果测试组和对照组中用户开始试用的速度不同，如果我只包括那些开始试用的用户，那么取消率的结果是否会有偏差？]]></description>
      <guid>https://stats.stackexchange.com/questions/617357/ab-testing-which-denominator-to-use-for-lower-funnel-metrics</guid>
      <pubDate>Tue, 30 May 2023 20:25:39 GMT</pubDate>
    </item>
    <item>
      <title>当变量均值随时间下降时，如何解释 RI-CLPM 参数估计值</title>
      <link>https://stats.stackexchange.com/questions/616632/how-to-interpret-ri-clpm-parameter-estimates-when-means-of-variables-decrease-ov</link>
      <description><![CDATA[为了进行一项研究，我在 4 个时间点运行了 RI-CLPM，观察了这 4 个时间点上负面社交互动 (X) 和抑郁 (Y) 之间的双向关联，并将交叉滞后参数限制为随时间相等。拟合度非常好，交叉滞后路径的参数估计值表明，前一个时间点的人际 X（负面社交互动）越高，则后续时间点的人际 Y（抑郁）就越高（因此是正相关）。这些变量在人际层面上没有显著相关性。乍一看似乎很容易解释。但是，当查看我的样本的描述性统计数据时，X 和 Y 的总体平均值会随着时间的推移而下降。例如，我的整体样本中的负面互动平均分数在 T1 时为 10，在 T2 时为 8，在 T3 时为 7 等，抑郁分数也是如此。我们想知道这是否可能是由于回归平均值或被评估的影响。
我对如何解释我的发现有些困惑。鉴于变量的总体均值随着时间的推移而下降，我是否仍可以这样解释我的结果：当一个人报告的 X（例如，负面的社交互动）比平时更多时，他们也会在随后的时间点报告比平时更多的 Y（例如，抑郁），所以有点像加剧效应。或者这实际上并不代表数据，如果是这样，那么正确的解释是：鉴于 X（负面的社交互动）和 Y（抑郁）的样本均值似乎随着时间的推移而下降（例如，一种恢复效应），“正”交叉滞后路径实际上显示出这种恢复效应的某种阻碍。
所以我想更广泛地说，我想知道当变量的总体均值随着时间的推移呈下降趋势时，“正”的人际关系实际上意味着什么。希望这有意义，并乐于澄清！]]></description>
      <guid>https://stats.stackexchange.com/questions/616632/how-to-interpret-ri-clpm-parameter-estimates-when-means-of-variables-decrease-ov</guid>
      <pubDate>Tue, 23 May 2023 01:12:48 GMT</pubDate>
    </item>
    </channel>
</rss>