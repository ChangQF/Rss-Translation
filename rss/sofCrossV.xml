<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 14 Jun 2024 09:15:54 GMT</lastBuildDate>
    <item>
      <title>如何确定流程或流程动态是否发生变化</title>
      <link>https://stats.stackexchange.com/questions/649226/how-to-determine-if-there-is-changes-in-the-process-or-the-process-dynamics</link>
      <description><![CDATA[我有两组数据代表过滤过程 - 组 1 和组 2。两组的基本原理相同。但是，组 1 中有 11 个过滤器进行过滤，组 2 中有 12 个。我看到两组各自的压力值都发生了变化，这意味着如果我将 pa_group1 与 pa_group2 进行比较，则两个压力的形状并不相同。我如何确定两个过程是否都发生了变化，或者过程的动态是否随时间而变化。
我得到的一件事是对各个组的平稳性测试，如果过程的动态在整个时间范围内保持不变，那么该特定组的数据应该是平稳的。我说得对吗？或者它与恒定过程有关。有人可以澄清这一点并建议一些可用于判断过程或其动态是否发生变化的测试吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649226/how-to-determine-if-there-is-changes-in-the-process-or-the-process-dynamics</guid>
      <pubDate>Fri, 14 Jun 2024 09:11:19 GMT</pubDate>
    </item>
    <item>
      <title>如何在单尾检验的置信区间内调整 SummarySE？</title>
      <link>https://stats.stackexchange.com/questions/649225/how-can-i-adjust-summarysewithin-confidence-intervals-for-one-tailed-test</link>
      <description><![CDATA[我有一项研究评估了不同条件（“Prior”）对结果“Indiff_Point”的影响。每个参与者（“Pt_ID”）完成每个 Prior 条件（因此重复测量）。我使用的是 .05 alpha 水平的单尾 p 值。
我使用 SummarySEwithin 函数（来自 Rmisc 包；Morey，2008）计算 95% 置信区间：
df_forplot = summarySEwithin(cue_data, measurevar= &quot;Indiff_Point&quot;, betweenvars= NULL, withinvars = c(&quot;Prior&quot;), idvar= c(&quot;Pt_ID&quot;), na.rm = FALSE, conf.interval = .95)

然后我使用这些用 ggplot2 创建图以图形方式比较 Prior 条件。我认为我的 95% CI 需要根据测试的单侧性质进行调整？我该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/649225/how-can-i-adjust-summarysewithin-confidence-intervals-for-one-tailed-test</guid>
      <pubDate>Fri, 14 Jun 2024 09:07:34 GMT</pubDate>
    </item>
    <item>
      <title>如果输入大小在训练集和推理之间发生变化，u-net 将使用什么权重？</title>
      <link>https://stats.stackexchange.com/questions/649222/what-weight-does-the-u-net-use-if-the-input-size-changes-between-training-set-an</link>
      <description><![CDATA[当我看到 SD 可以处理多种输入/输出大小时，问题就出现了。我不明白如果我改变输入的大小，权重会使用什么。
假设我在 2x2 图像中训练一个 unet，步长为 2，卷积层“深度”为 1，那么我在编码器中有 4 个权重。如果我使用网络对 2x3 图像进行推理会发生什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/649222/what-weight-does-the-u-net-use-if-the-input-size-changes-between-training-set-an</guid>
      <pubDate>Fri, 14 Jun 2024 06:36:21 GMT</pubDate>
    </item>
    <item>
      <title>倾向得分与倾向得分匹配？</title>
      <link>https://stats.stackexchange.com/questions/649221/propensity-score-vs-propensity-score-matching</link>
      <description><![CDATA[我正在尝试自学双重稳健估计。在我看来，双重稳健估计使用倾向得分，但不使用倾向得分匹配。
以下是我对使用逻辑回归模型的 RCT 二元治疗/二元结果的倾向得分匹配的理解：

步骤 1：没有倾向得分匹配的逻辑回归、可能性和平均治疗效果：
$$ P(Y=1|X=x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + ... + \beta_k x_k)}} $$
$$ L(\beta) = \prod_{i=1}^{N} P(Y_i|X_i)^{Y_i} (1 - P(Y_i|X_i))^{(1-Y_i)} $$
$$ \tau = P(Y=1|X=x, T=1) - P(Y=1|X=x, T=0) $$

步骤 2：创建一个统计模型来估计倾向得分：
$$ e(X_i) = P(T=1|X_i) = \frac{1}{1 + e^{-(\alpha_0 + \alpha_1 x_{i1} + ... + \alpha_k x_{ik})}} $$

步骤 3：使用某种匹配方法（例如贪婪，$g$）将一种治疗中的患者与另一种治疗中最接近的患者进行匹配基于协变量和估计的倾向得分：


$$ g(i) = \underset{j: T_j=0}{\mathrm{argmin}} |e(X_i) - e(X_j)| $$

步骤 4：总结匹配：
$$ w_i = \begin{cases} 
1 &amp; \text{if individual } i \text{ is matching} \\
0 &amp; \text{如果 individual } i \text{ 不匹配}
\end{cases} $$

步骤 5：重写可能性以考虑倾向得分匹配的影响（这里我们假设在原始 $N$ 名患者中只有 $M$ 名患者匹配）：


$$ L_w(\beta) = \prod_{i=1}^{M} \left( P(Y_i|X_i)^{Y_i} (1 - P(Y_i|X_i))^{(1-Y_i)} \right)^{w_i} $$

步骤 6：使用倾向得分定义平均治疗效果匹配：

$$ \tau_{ps} = \frac{1}{M} \sum_{i=1}^{M} \left( Y_i - Y_{g(i)} \right) $$

第 7 步：倾向得分匹配的数学含义 - 使用倾向得分匹配的平均治疗效果可以更接近真实的平均治疗效果（与没有倾向得分匹配的平均治疗效果相比）：

$$ E(\tau_{ps}) \approx E(\tau_{true}) &lt; E(\tau) $$
基于此，我试图了解这与双重稳健估计的关系。在我看来，双重稳健估计使用倾向得分，但不使用倾向得分匹配：

步骤 1：建立一个统计模型，估计给定协变量（即倾向得分）接受治疗的概率：

$$ P(T=1|X) = \frac{1}{1 + e^{-(\alpha + \beta X)}} $$

步骤 2：为结果变量定义一个统计模型，例如

$$ E(Y|T,X) = \gamma + \delta T + \theta X $$
这里 $\gamma$ 是截距，$\delta$ 是治疗效果，$\theta$ 是协变量的系数（这些都需要估计）。

步骤 3：根据治疗和倾向得分定义权重：

对于接受治疗的个体 $T=1$：
$$ w_1 = \frac{1}{P(T=1|X)} $$
对于对照个体 $T=0$：
$$ w_0 = \frac{1}{1 - P(T=1|X)} $$

步骤4：最后，定义双重稳健估计下的平均治疗效果：

$$ ATE = \frac{1}{N} \sum_{i=1}^{N} \left( w_1 \cdot Y_i \cdot T_i + w_0 \cdot (Y_i - \hat{Y}_i) \cdot (1 - T_i) \right) $$
$$\hat{Y}_i = E(Y_i|T_i,X_i) = \gamma + \delta T_i + \theta X_i$$
这是正确的吗？双重稳健估计使用倾向得分而不是倾向得分匹配？]]></description>
      <guid>https://stats.stackexchange.com/questions/649221/propensity-score-vs-propensity-score-matching</guid>
      <pubDate>Fri, 14 Jun 2024 05:43:33 GMT</pubDate>
    </item>
    <item>
      <title>在不了解被标记人员的情况下重新捕获标记</title>
      <link>https://stats.stackexchange.com/questions/649219/mark-recapture-with-no-knowledge-of-marked-individuals</link>
      <description><![CDATA[我是一名数学系学生，与一群野外生物学家一起工作。在对同一群体进行标记-重新捕获的多次实验中，他们声称，如果观察次数（重新捕获次数）足够大，则可以仅基于样本推断出群体大小（$N$）和比例（$p=K/N$），而无需事先了解最初标记的个体数量（$K$）。
考虑到从群体中抽取一个大小为 $n$ 的样本，其中有 $k$ 个标记个体，使用刀切法子样本创建观察到的比例直方图。然后使用最小平方将超几何分布拟合到直方图。这导致了一对估计参数$\hat{p}$和$\hat{N}$。
我确信，在$K$未知的假设下，该估计量收敛到样本大小（$n$），即$\hat{N} \rightarrow n$（或至少收敛到不同于$N$的值）。但是，我还没有证明这一点。
他们用模拟数据测试了这个估计量。我的结论是，在模拟中，$\hat{N}$ 的标准偏差足够大，因此 $N$ 和 $\hat{N}$ 的值有时会重合。
我提出这个问题是为了验证我是否正确。另外，我不太擅长解释自己，需要提出一个论点来说服非专业人士 $\hat{N} \rightarrow n$。感谢大家的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/649219/mark-recapture-with-no-knowledge-of-marked-individuals</guid>
      <pubDate>Fri, 14 Jun 2024 05:04:51 GMT</pubDate>
    </item>
    <item>
      <title>4 臂嗅觉测量法，包括气味源和单个蚜虫，统计测试有助于了解每个区域所花费的时间</title>
      <link>https://stats.stackexchange.com/questions/649216/4-arm-olfactometry-with-odour-sources-and-individual-aphids-stat-test-help-for</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/649216/4-arm-olfactometry-with-odour-sources-and-individual-aphids-stat-test-help-for</guid>
      <pubDate>Fri, 14 Jun 2024 02:07:03 GMT</pubDate>
    </item>
    <item>
      <title>高信噪比测量的不确定度传播</title>
      <link>https://stats.stackexchange.com/questions/649213/propagation-of-uncertainties-for-high-signal-to-noise-ratio-measurements</link>
      <description><![CDATA[我正在编写质谱数据缩减软件，用于计算 4He 体积，我对不确定性传播有一些疑问。
所讨论的系统通过比较已知 4He 标准中 3He 峰值的气体比例与未知 4He 气体与 3He 峰值的比率来测量氦体积：
final_result = Q_vol * sample_ratio / Q_ratio

其中：

Q_vol 是标准中 4He 的体积
x_ratio 是原始质谱数据中质量 4 与质量 3 的比率

该系统还测量样品和标准的空白，其中我们实际上没有测量任何东西 - 也就是说，3He 峰值中有少量 4He，但数量刚好高于基线，因此信噪比对这些气体的测量结果非常高。因此，这些空白测量中 4He 的标准偏差也很高 (~10-20%)，相对于标准 (&lt;0.35%) 或样气等稳定信号而言。有时，这些空白可能会偏离负值范围（为什么质谱会报告负数据，我无法理解...），产生 %SD ~ 80%。
加入空白后，完整方程为：
final_result = Q_vol * (sample_ratio - sample_blank_ratio) / (Q_ratio - Q_blank_ratio)

在结果上传播错误时，
final_error = sqrt(Q_vol_err^2 + sample_ratio_err^2 + sample_blank_ratio_err^2 + Q_ratio_err^2 + Q_blank_ratio_err^2)

空白的高标准偏差最终会导致大量错误：例如，没有空白不确定性，最终结果的错误约为 2%，而没有空白不确定性，最终结果的错误约为 20% 。
虽然我理解添加高误差项也会给最终计算增加误差，但空白处的误差完全主导了不确定性，使其增加了整个数量级，而不是像原始数据的拟合或 Q 比率的分布主导不确定性，这感觉本质上是错误的。这些不确定性不应该被赋予相同的权重，但是，我不确定如何“公平而准确地”（即以科学/统计上有意义的方式）对这些数据进行加权。
如果您处于我的位置，您会如何处理这些数据？
编辑：我尝试了一些新方程式
$$
\sigma_f = \left(\frac{(R_{\text{s}} - R_{\text{sb}})}{(R_{\text{Q}} - R_{\text{Qb}})} \sigma_{Q_{\text{vol}}}\right)^2 +
\left(Q_{\text{vol}} \frac{1}{(R_{\text{Q}} - R_{\text{Qb}})} \sigma_{R_{\text{s}}}\right)^2 +
\left(- Q_{\text{vol}} \frac{1}{(R_{\text{Q}} - R_{\text{Qb}})} \sigma_{R_{\text{sb}}}\right)^2 +
\left(- Q_{\text{vol}} \frac{(R_{\text{s}} - R_{\text{sb}})}{(R_{\text{Q}} - R_{\text{Qb}})^2} \sigma_{R_{\text{Q}}}\right)^2 +
\left(Q_{\text{vol}} \frac{(R_{\text{s}} - R_{\text{sb}})}{(R_{\text{Q}} - R_{\text{Qb}})^2} \sigma_{R_{\text{Qb}}}\right)^2
$$
其中

R 表示 4 amu / 3 amu 比率
下标 Q 表示标准，s 表示样品，b 表示空白
sigma 表示原始不确定性

这会产生较小的 He 体积的不确定性，而较大的 4He 体积的误差较小，这是有道理的，不确定性处于合理水平。]]></description>
      <guid>https://stats.stackexchange.com/questions/649213/propagation-of-uncertainties-for-high-signal-to-noise-ratio-measurements</guid>
      <pubDate>Fri, 14 Jun 2024 00:08:03 GMT</pubDate>
    </item>
    <item>
      <title>根据样品鲜重对吸光度数据进行归一化</title>
      <link>https://stats.stackexchange.com/questions/649209/normalization-of-absorbance-data-by-fresh-weight-of-samples</link>
      <description><![CDATA[A [协议] 称

对于每个样品，将吸光度 (Abs) 读数除以样品的鲜重（以克为单位）。使用控制基因型的任意值 1 对结果进行标准化（1 = 每克鲜重 0.14 个吸光度单位）。

我的数据 -
基因型重复吸光度鲜重（克）
G1 1 0.161 0.2167
G1 2 0.203 0.2251
G1 3 0.127 0.2497
G2 1 0.194 0.2512
G2 2 0.154 0.1987
G2 3 0.3 0.2
G3 1 0.271 0.2013
G3 2 0.213 0.2111
G3 3 0.374 0.1857
G4 1 0.382 0.2326
G4 2 0.26 0.225
G4 3 0.188 0.2012

使用任意值 1=0.14 进行归一化的理由是什么？我应该如何为我的数据选择这个值，或者随机定义 1= 任何分数？最终公式是什么样的？吸光度值 * 任意值/鲜重？]]></description>
      <guid>https://stats.stackexchange.com/questions/649209/normalization-of-absorbance-data-by-fresh-weight-of-samples</guid>
      <pubDate>Thu, 13 Jun 2024 21:48:53 GMT</pubDate>
    </item>
    <item>
      <title>如何比较预定义时间段内的实时生理数据</title>
      <link>https://stats.stackexchange.com/questions/649179/how-to-compare-real-time-physiological-data-between-pre-defined-time-blocks</link>
      <description><![CDATA[我有一组约 20 名患者的生理数据（皮肤电导率、皮肤温度、心率），每秒测量一次，持续时间约为。在虚拟现实练习期间，大约需要 8 到 10 分钟。
数据分为以下时间段：

校准（患者戴上 VR 眼镜并检查/调整技术设备）
测试（患者在四个中性虚拟环境之一中走动）
第一次干预（患者在虚拟环境中受到一个或多个压力源的影响）
第二次干预（患者在虚拟环境中使用预先学习的应对策略）。

我想测试区块之间的显着变化：即变量在测试和第一次干预区块之间是否发生显着变化，变量在第一次和第二次干预区块之间是否发生显着变化。

使用均值或百分比增加/减少来比较数据块是否更好？
根据基线或之前的区块计算百分比增加/减少是否更好数据？
配对 t 检验是否合适，或者其他检验是否更好？
]]></description>
      <guid>https://stats.stackexchange.com/questions/649179/how-to-compare-real-time-physiological-data-between-pre-defined-time-blocks</guid>
      <pubDate>Thu, 13 Jun 2024 13:30:35 GMT</pubDate>
    </item>
    <item>
      <title>不平衡面板的差异分析</title>
      <link>https://stats.stackexchange.com/questions/649170/diff-in-diff-with-an-unbalanced-panel</link>
      <description><![CDATA[假设我想使用 diff-in-diff 设置研究某些干预措施的效果。我有一组在某个时期内观察到的单位。我可以识别治疗/非治疗组和前期/后期（假设它是经典的 DID，没有交错干预等）。我的问题是我有不平衡的面板 - 对于某些单位，包括那些接受治疗的单位，我没有后期的完整观察结果。我可以仅在平衡样本上估计 DID 模型，或者简单地忽略面板不平衡的事实（我猜这对 Stata xtdidrgress 来说不是问题），但我担心这可能会产生有偏差的结果。由于治疗，可能会从样本中删除单位。例如，如果我研究某些医疗治疗对血压的影响，可能会发生由于治疗，一些患者的血压下降，他们不再去看医生，这就是为什么没有对他们的观察结果。
在这种情况下我该怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/649170/diff-in-diff-with-an-unbalanced-panel</guid>
      <pubDate>Thu, 13 Jun 2024 11:55:30 GMT</pubDate>
    </item>
    <item>
      <title>评估残差与拟合值图中的异方差</title>
      <link>https://stats.stackexchange.com/questions/649220/assessing-heteroscedasticity-in-residuals-vs-fitted-values-graph</link>
      <description><![CDATA[我正在运行一个具有 3 个级别（学校、团体和学生）的混合模型回归。我使用 R 函数 coef_test(modelo6b, vcov = &quot;CR2&quot;) 应用了稳健标准误差，一些之前很重要的变量变得不重要。
因此，我认为模型中可能存在异方差。
我想检查模型中是否存在任何类型的异方差，因此我制作了残差与拟合值的离散图。您认为这里有任何异方差的迹象吗？在我看来似乎没有。那么，为什么我在应用稳健标准误差时会得到截然不同的 CI？
]]></description>
      <guid>https://stats.stackexchange.com/questions/649220/assessing-heteroscedasticity-in-residuals-vs-fitted-values-graph</guid>
      <pubDate>Thu, 13 Jun 2024 10:24:17 GMT</pubDate>
    </item>
    <item>
      <title>我在不同的种子上对逻辑回归分类器获得了 98% 到 100% 的准确率。这应该发生吗（主要关注 100% 准确率）</title>
      <link>https://stats.stackexchange.com/questions/649167/i-am-getting-98-to-100-accuracy-in-my-logistic-regression-classifier-on-differ</link>
      <description><![CDATA[我的数据分割：
from sklearn.model_selection import train_test_split
df.drop(&#39;id&#39;, axis=1, inplace=True)
X = df.drop(&#39;classification&#39;, axis=1)
y = df[&#39;classification&#39;]
X_train, X_test, y_train, y_test = train_test_split(
X, 
y, 
test_size = 0.30, 
random_state =0 
)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
输出：(280, 23) (120, 23) (280,) (120,)

和我的 ML 模型：
来自 sklearn.linear_model 导入 LogisticRegression
来自 sklearn.metrics 导入 accuracy_score、classification_report、confusion_matrix

model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print(accuracy_score(y_test, y_pred))
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/649167/i-am-getting-98-to-100-accuracy-in-my-logistic-regression-classifier-on-differ</guid>
      <pubDate>Thu, 13 Jun 2024 10:20:44 GMT</pubDate>
    </item>
    <item>
      <title>如何从 GLM 推导出 GEE？</title>
      <link>https://stats.stackexchange.com/questions/649164/how-to-derive-gee-from-glm</link>
      <description><![CDATA[我现在正在阅读以下讲座笔记：
https://dept.stat.lsa.umich.edu/~kshedden/Courses/Regression_Notes/gee.pdf


为什么我们有$V_{i}^{-1}(y_{i}-\mu_{i})$？我无法将第 4 页的最后一个方程链接到第 5 页的最后一个方程。]]></description>
      <guid>https://stats.stackexchange.com/questions/649164/how-to-derive-gee-from-glm</guid>
      <pubDate>Thu, 13 Jun 2024 09:29:20 GMT</pubDate>
    </item>
    <item>
      <title>如何实施 Anderson-Rubin 检验并计算使用 r 中的 plm 设置的 iv 模型的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/649218/how-to-implement-an-anderson-rubin-test-and-calculate-confidence-intervals-for-a</link>
      <description><![CDATA[我使用 r 中的 plm 包运行了 IV 模型。底层数据是面板数据。
我的工具“弱”，即 F 统计量低于 10。
如何为我的工具实施 Anderson-Rubin 检验并计算置信区间？我读到过这种测试不需要仪器相关性。
fe_model &lt;- plm(
log(Y) ~ log(X) + Controls
| log(instrument) + Controls,
model = &quot;within&quot;,
data = data,
index = c(&quot;country&quot;,&quot;year&quot;),
effect = &quot;twoways&quot;)

# HAC 标准误差
fe_model_se &lt;- coeftest(fe_model, vcov = vcovHC(fe_model, type = &quot;HC3&quot;))[, 2]
]]></description>
      <guid>https://stats.stackexchange.com/questions/649218/how-to-implement-an-anderson-rubin-test-and-calculate-confidence-intervals-for-a</guid>
      <pubDate>Thu, 13 Jun 2024 06:08:50 GMT</pubDate>
    </item>
    <item>
      <title>OLS 加权平均值是什么？</title>
      <link>https://stats.stackexchange.com/questions/649093/what-weighted-average-is-ols</link>
      <description><![CDATA[我们如何从拟合最小二乘的线性回归中找到协变量的加权平均值？
考虑模型
$$
Y = \beta_0 + \beta_1 \tau + \sum_{j = 2}^k \beta_{j} X_{j} + \epsilon
$$
其中 $Y$ 是连续变量，$\tau$ 是二元变量 {0, 1}，$X$ 是分类变量，由 $k + 1$ 个类别组成，其中 $j = k + 1$ 是参照类别。为简单起见，我们假设 $X$ 表示 state。如果我们感兴趣的对象是 $\tau$ 的系数，我们可能对每个 状态（$X$ 类别）的相对贡献感兴趣。
众所周知，$\beta_1$ 是一个加权平均值，其中 $X$ 的每个类别 $j$ 都获得以下权重。
$$
\tag{1}
\frac{w(j)}{\sum{w(j{})}} 
$$
其中

$w(j) = q(j) \cdot e(j) \cdot (1 - e(j))$ 和
$q(j) = \frac{N(j)}{N}$ 是每个州的单位比例
$e(j) = \frac{N_{\tau = 1}(j)}{N(j)}$ 是每个州 $\tau = 1$ 的单位比例。

现在考虑添加一个额外的协变量
$$
Y = \beta_0 + \beta_1 \tau + \beta_2 Z + \sum_{j = 3}^k \beta_{j} X_{j} + \epsilon
$$
其中 $Z$ 是连续变量。当 $Z$ 独立于 $\tau$ 时，则（渐近地）(1) 仍然成立。那么当 $Z$ 不独立于 $\tau$ 时，情况又如何呢？是否有可能找到一个类似 (1) 的方程，我们可以将 $X$ 中每个 $j$ 的个体贡献分解为 $\beta_1$ 的加权平均值？有没有办法使用 Frisch-Waugh-Lovell 定理来找到这些权重？]]></description>
      <guid>https://stats.stackexchange.com/questions/649093/what-weighted-average-is-ols</guid>
      <pubDate>Wed, 12 Jun 2024 09:46:46 GMT</pubDate>
    </item>
    </channel>
</rss>