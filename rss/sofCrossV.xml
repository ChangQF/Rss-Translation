<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 29 Aug 2024 18:20:52 GMT</lastBuildDate>
    <item>
      <title>从汇集材料中进行（子）采样</title>
      <link>https://stats.stackexchange.com/questions/653570/subsampling-from-pooled-materials</link>
      <description><![CDATA[我曾遇到过一个存在技术困难的检测。样本是一种不构成动物大部分的组织。迄今为止，所做的是汇集来自 M 只动物的制剂，然后取 N 个等分试样，其中 N 小于 M。目前还不能使该检测更加灵敏（该技术尚不存在）。很明显，N 个样本不是 N 个重复。假设有两个未混合的治疗组。
如何改进这种设计而不使成本飞涨？
如何对改进的设计进行建模？如果不能改进，可以建模吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653570/subsampling-from-pooled-materials</guid>
      <pubDate>Thu, 29 Aug 2024 17:38:38 GMT</pubDate>
    </item>
    <item>
      <title>可以从梯度提升模型 CatBoost 和 XGBoost 中获得概率预测吗？</title>
      <link>https://stats.stackexchange.com/questions/653569/can-probabilistic-predictions-be-obtained-from-gradient-boosting-models-catboost</link>
      <description><![CDATA[我正在寻找使用 CatBoost 或 XGBoost 对 [0, 1] 中的连续目标变量（即比例）进行概率预测。我可以使用官方库来生成概率预测而不是单个值吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653569/can-probabilistic-predictions-be-obtained-from-gradient-boosting-models-catboost</guid>
      <pubDate>Thu, 29 Aug 2024 17:18:07 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的时间序列预测问题</title>
      <link>https://stats.stackexchange.com/questions/653568/time-series-forecasting-problem-in-python</link>
      <description><![CDATA[我是时间序列预测的新手，我正在从事一个 Python 项目，我需要预测各个家庭的能源消耗。我的数据集包含数千个家庭，每个家庭在两年内每月都有能源消耗值，但仅限于某些月份（01-05），因此每个家庭有 10 个点的时间序列。每个家庭都有一个其他时间相关变量，即当地湿度/温度指数和几个时间无关的特征，既有连续的，例如房屋大小（面积）、邮政编码，也有分类的，例如居民拥有房屋，居民有孩子。任务是使用此信息预测每个家庭未来几个月的能源消耗值。
数据集看起来像这样：



house_id
month
year
zipcode
en_cons
weather_idx
size
owns_house
has_children




1
1
2021
12
4.33
19.6
71
0.0
1.0


1
2
2021
12
4.35
17.6
71
0.0
1.0


1
3
2021
12
4.56
12.3
71
0.0
1.0


1
4&lt; /td&gt;
2021
12
4.77
15.9
71
0.0
1.0


1
5
2021
12
5.12
19.3
71
0.0 
1.0


1
1
2022
12
4.83
19.9
71
0.0
1.0


...
...
...
...
...
...
..
...
...


1
5
2022
12
5.49
18.7
71
0.0
1.0


2
1
2021
44
6.12
17.3
63
1.0
0.0


...
...
...
...
...
..
...
...


10000
5
2022
99
5.55
14.3
100
1.0
1.0



我正在尝试弄清楚要实施什么 ML 模型，以便预测未来几个月的 en_cons，以及如何在模型中包含家庭的其他信息。我上过一些在线课程，在这些课程中，我使用了不同的 ML 分类算法（线性回归、knn、决策树等）来根据多个特征预测分类变量，但我不知道如何处理与时间相关的预测。
据我所知，时间序列预测中使用的典型模型（例如 ARIMA（及其变体））仅将时间戳和要预测的数量值作为输入（它们仅根据更早时间 t-k 的值来预测时间 t 的值）。
因此，似乎一个可以包含所有给定信息的 ML 模型（可能是 XGB 或 LightGBM 之类的东西？）是可行的方法。但我不知道如何实际实现它。
此外，由于问题要求预测每个家庭的能源消耗，这意味着我每个家庭只有 10 个时间点来创建测试和训练样本，这似乎太少了。这也意味着我必须为每个家庭创建一个单独的模型。这是正确的做法吗？有没有办法使用所有数据创建一种“全局”模型并分别预测每个家庭的情况？
如果信息不足，我深表歉意，我严重误解了某些事情，或者这个问题已经被回答了，而我错过了。我以前没有处理过时间序列预测，对 ML 算法的经验有限。任何帮助或提示，为我指明正确的方向，我将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653568/time-series-forecasting-problem-in-python</guid>
      <pubDate>Thu, 29 Aug 2024 16:52:14 GMT</pubDate>
    </item>
    <item>
      <title>如何测量重尾分布的蒙特卡洛收敛？</title>
      <link>https://stats.stackexchange.com/questions/653567/how-can-i-measure-monte-carlo-convergence-in-distribution-with-heavy-tails</link>
      <description><![CDATA[我正在对一个简单的基于代理的模拟进行蒙特卡罗研究，并试图为要使用的 MC 样本数量制定启发式方法。我可以通过查看 Bootstrapped 估计值的方差来测量统计数据（如均值和方差）的收敛性。
我遇到的问题是，我相信我的输出分布有重尾，我想确保我准确估计了极端风险情景（低概率，高后果）的概率。
有没有办法将 Bootstrapping 应用于极端分位数？有什么陷阱我应该注意吗？
编辑：我应该补充一点，我不知道我的输出分布是否是重尾的。我正在寻找一种方法来量化我正确捕捉尾部行为的信心。]]></description>
      <guid>https://stats.stackexchange.com/questions/653567/how-can-i-measure-monte-carlo-convergence-in-distribution-with-heavy-tails</guid>
      <pubDate>Thu, 29 Aug 2024 16:33:18 GMT</pubDate>
    </item>
    <item>
      <title>混合模型模拟研究：与线性模型（功效）和无协变量模型（1 类错误）进行比较，包 lmerTest</title>
      <link>https://stats.stackexchange.com/questions/653566/mixed-model-simulation-study-comparing-to-linear-model-power-and-model-withou</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653566/mixed-model-simulation-study-comparing-to-linear-model-power-and-model-withou</guid>
      <pubDate>Thu, 29 Aug 2024 15:59:58 GMT</pubDate>
    </item>
    <item>
      <title>如何使用实际方差计算夏普比率</title>
      <link>https://stats.stackexchange.com/questions/653563/how-to-use-realized-variance-for-calculating-sharp-ratios</link>
      <description><![CDATA[使用已实现方差 (RV) 公式：
$RV_t= \sum_{i=1}^N r^2_{t,i}$
（例如 $r_{t,i}$ 为 5 分钟 HFD 回报）
RV 是股票时间序列方差的代理。现在我想使用 RV 来计算夏普比率：
$SR= \frac{r^e_t}{\sqrt{Var(r^e_t})} = \frac{r^e_t}{\sigma_{_t}} $（假设 $r^e_t$ 是给定的且为常数）
下面是我的两个问题：
1：
$RV_t = Var(r^e_t) =\sigma_t^2$ 因此 $SR= \frac{r^e_t}{\sqrt{RV_t}}$ 或 
$RV_t = \sqrt{Var(r^e_t)} =\sigma_t$ 因此 $SR= \frac{r^e_t}{RV_t}$
2:
并且“已实现方差”是“已实现波动率”的同义词，因此两者都是 $RV$ 或 
“已实现方差”$= \sigma^2$ 和“已实现波动率”$= \sigma$
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653563/how-to-use-realized-variance-for-calculating-sharp-ratios</guid>
      <pubDate>Thu, 29 Aug 2024 14:54:45 GMT</pubDate>
    </item>
    <item>
      <title>如何在 python 中计算滚动指数加权移动平均收益？</title>
      <link>https://stats.stackexchange.com/questions/653562/how-to-compute-rolling-exponential-weighted-moving-average-of-returns-in-python</link>
      <description><![CDATA[正如问题所述，我不知道如何计算滚动指数加权移动平均收益。这里的关键词是滚动。
我知道我可以执行以下操作，但这是滚动吗？
data = pd.Series(np.random.normal(loc=0, scale=1, size=100))

ewma = data.ewm(alpha=.2).mean()
]]></description>
      <guid>https://stats.stackexchange.com/questions/653562/how-to-compute-rolling-exponential-weighted-moving-average-of-returns-in-python</guid>
      <pubDate>Thu, 29 Aug 2024 14:39:10 GMT</pubDate>
    </item>
    <item>
      <title>数据集的时间分辨率问题</title>
      <link>https://stats.stackexchange.com/questions/653560/time-resolution-problem-with-data-set</link>
      <description><![CDATA[假设我有一个数据集，其中给出的每个数据点（即每行）都是每 15 分钟。
但我需要相同的数据集，其时间分辨率为一小时而不是 15 分钟。
如果我使用时间分辨率为 15 分钟的数据集，我会得到与一小时相同的结果吗？或者如何处理这种情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/653560/time-resolution-problem-with-data-set</guid>
      <pubDate>Thu, 29 Aug 2024 13:38:55 GMT</pubDate>
    </item>
    <item>
      <title>对独立数据和非独立数据一起进行统计检验？</title>
      <link>https://stats.stackexchange.com/questions/653559/statistical-test-for-independent-and-non-independent-data-together</link>
      <description><![CDATA[目的
我想比较几位作者（研究 1 至 5）的研究结果中一些常见精神障碍 (CMD) 的患病率。所有研究都是观察性的。其中四个是横断面研究，一个是纵向研究（研究 4）。
问题
我不能使用独立性卡方检验，因为纵向研究违反了观察独立性的假设。
示例
下表显示了收集的数据的示例。



研究
n
CMD1 (%)
CMD2 (%)
CMD3 (%)




研究 1
54
NA
NA
26.0


研究 2
198
25.0
19.9
27.0


研究 3
278
38.0
40.0
25.0


研究 4 - T1
595
27.0
31.0
3.6


研究 4 - T2
504
21.0
33.0
3.4


研究 4 - T3
374
22.0
35.0
4.9


研究 5
208
20.3
NA
NA



主要问题

已知研究 4 是一项纵向研究，因此违反了观察独立性的假设，那么最适合检查 CMD1、CMD2 和 CMD3 研究之间是否存在统计学上显着差异的分析是什么？

次要问题

如果有多个分析，哪一个最适合，为什么？
我是否应该考虑贝叶斯检验而不是频率检验？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653559/statistical-test-for-independent-and-non-independent-data-together</guid>
      <pubDate>Thu, 29 Aug 2024 12:37:29 GMT</pubDate>
    </item>
    <item>
      <title>循环神经网络的输出</title>
      <link>https://stats.stackexchange.com/questions/653550/output-of-a-recurrent-neural-network</link>
      <description><![CDATA[阅读有关 RNN 的文章时，我们总会得到有关其展开版本的解释，例如来自 Colah 博客的内容：

在本例中，我们有 5 个时间步长的输入数据，$X_0$ 到 $X_4$。而且我们在相同的时间步进行预测，从 $h_0$ 到 $h_4$。
我不明白，我们难道不应该至少提前一步预测，$h_5$？或者可能提前更多步？比如说 $h_5$、$h_6$、$h_7$、$\cdots$？]]></description>
      <guid>https://stats.stackexchange.com/questions/653550/output-of-a-recurrent-neural-network</guid>
      <pubDate>Thu, 29 Aug 2024 11:14:13 GMT</pubDate>
    </item>
    <item>
      <title>MANOVA - 单变量 Wilks 的 Lambda 检验（R 解释）</title>
      <link>https://stats.stackexchange.com/questions/653530/manova-univariate-wilks-lambda-test-r-interpretation</link>
      <description><![CDATA[我正在运行一个具有 2 个因变量和 2 个连续预测变量的 MANOVA 模型。 （仅供参考 - STATA 将此称为 MANCOVA，并要求在每个预测因子前面删除“c。”以表示每个预测因子在 manova 运行期间都是连续缩放的。无论如何，R 将直接接受连续变量，因此使用 manova 命令在 R 中运行 MANCOVA 不会出现问题） - 本质上是 MVNREG。
使用 UC-Irvine ML Repository Wine 数据集，模型为：
model &lt;- lm(cbind(alcohol, hue) ~ flavanoids + ash, na.action=na.exclude, data=wine)
wine.manova=manova(model)

我试图了解使用这两种方法时 Wilks&#39; Lambda 对黄烷类化合物预测因子的 F 近似值之间的差异：
方法1
library(car)
lh.out &lt;- linearHypothesis(model, hypothesis.matrix = c(&quot;flavanoids = 0&quot;))
lh.out

结果如下：

方法 2
以及基于命令的 Wilks&#39; 值
summary(wine.manova,&#39;Wilks&#39;)

输出如下：

尽管 p 值相同，但我试图理解为什么 Wilks&#39; Lambda 的 F 值在基于所有响应变量的黄酮类化合物预测因子的两次零系数检验中有所不同。结果表明，当有更多预测因子或因变量时，这两次 Wilks&#39; Lambda 计算之间的差异更大。
仅供参考 - 当将 R 与 STATA 进行基准测试时，几乎不可能在 STATA 中获得上述方法 2 下列出的表格结果，而方法 1 的结果很容易从 STATA 中获得。]]></description>
      <guid>https://stats.stackexchange.com/questions/653530/manova-univariate-wilks-lambda-test-r-interpretation</guid>
      <pubDate>Thu, 29 Aug 2024 02:58:38 GMT</pubDate>
    </item>
    <item>
      <title>我如何对系数进行随机效应建模[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653509/how-can-i-model-with-random-effect-on-the-coefficient</link>
      <description><![CDATA[简单线性回归模型为：$$y= a x + b + e $$
然而，在实际数据中：

存在随机效应（误差或变化）；
当 $x$ 增加时，随机效应的绝对值会成比例增加。
因此它看起来像 $$y = ax + b + ex$$ 或 $$y = (a + e) x + b$$ 但 $e$ 是随机效应。
对这种建模有什么建议吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653509/how-can-i-model-with-random-effect-on-the-coefficient</guid>
      <pubDate>Wed, 28 Aug 2024 20:29:44 GMT</pubDate>
    </item>
    <item>
      <title>得到一个不显著的 log(theta) 意味着什么？</title>
      <link>https://stats.stackexchange.com/questions/653505/what-does-getting-a-non-significant-logtheta-mean</link>
      <description><![CDATA[我在 R 中运行一个简单的模型，测试鱼密度（单位体积的鱼数量）是否取决于该区域的深度。有很多区域没有鱼，所以我使用 zeroinflated 模型（R 中的包 pscl::zeroinfl）。
模型 &lt;- zeroinfl(FishDensity ~Depth, data = myData, dist = &quot;negbin&quot;, na.action = na.omit)

这些是结果：
计算模型系数（带对数链接的 negbin）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 5.33750 0.24254 22.007 &lt;2e-16 ***
深度 0.03446 0.01367 2.521 0.0117 * 
Log(theta) 0.08603 0.14003 0.614 0.5390 

零膨胀模型系数（带 logit 链接的二项式）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 1.893173 0.288799 6.555 5.55e-11 ***
深度 0.007084 0.016472 0.430 0.667 

在计数模型系数中，我得到了一个不显著的 log(theta)。
这是什么意思？我应该放弃这个模型吗？
深度本身很重要。
我是统计学新手，所以请尝试用简单的术语解释它。]]></description>
      <guid>https://stats.stackexchange.com/questions/653505/what-does-getting-a-non-significant-logtheta-mean</guid>
      <pubDate>Wed, 28 Aug 2024 20:09:05 GMT</pubDate>
    </item>
    <item>
      <title>差异项目功能标准选择</title>
      <link>https://stats.stackexchange.com/questions/653367/differential-item-functioning-criteria-selection</link>
      <description><![CDATA[当使用（有序）逻辑回归框架测试差异项目功能 (DIF) 时，一系列（有序）逻辑回归会拟合数据，使用项目响应 ($Y$) 作为因变量，并使用潜在变量 ($θ$)、测试 DIF 的组变量 ($group$) 作为预测变量：
$$
Y = \beta_1\theta \tag{1}
$$
$$
Y = \beta_1\theta + \beta_2group \tag{2}
$$
$$
Y = \beta_1\theta + \beta_2group + \beta_3\theta \times group \tag{3}
$$
计算这些回归后，似乎有三个常用的标准来检测 DIF。如 Crane et al. 2007 中所述：

在第一个标准中，使用 $X^2$ 统计数据来比较模型；如果后续模型的可能性明显更高，则存在 DIF。
在第二个标准中，为每个模型计算伪$R^2$；如果后续模型具有明显更好的 $R^2$，则存在 DIF。
在第三个标准中，比较 $\beta_1$ 系数；如果后续模型具有明显不同的 $\beta_1$ 系数，则存在 DIF。

这些标准对我来说很有意义，但我不明白为什么在控制潜在变量（即 $\beta_2$ 系数）后，我们不会对 $group$ 的影响感兴趣。如果即使在控制潜在变量后，组成员身份仍显着影响观察到的反应，在我看来，这表明存在 DIF。然而，这似乎不仅没有被用作标准，我唯一一次看到它被引用为一种方法是在 Crane et al. 2004 中，他们驳斥了它。在将方法 (3) 与检查 $\beta_2$ 的方法进行比较时，他们说：

在统一 DIF 检测中，有趣的是，当考虑到人口统计特征时，整体能力水平与项目响应之间的关系幅度是否发生了显着变化。这就是混淆的本质，也是均匀 DIF 的本质……因此，我们选择采用 [$\beta_1$ 标准] 来确定项目中是否存在均匀 DIF。

为什么显著的 $\beta_2$ 系数不表示 DIF？
示例
这个问题是由我正在进行的 DIF 分析引起的，我得到了一些令人困惑的结果。我正在比较大学生和非大学生的 PHQ-9（衡量抑郁症状严重程度的指标）反应。总样本量约为 90,000。我正在使用 lordif 在 R 中测试 DIF。
当我使用第一种方法（$X^2$）时，我发现所有项目都有 DIF；考虑到我的样本量很大，$X^2$ 统计数据显著也就不足为奇了，因此我测试了其他两种方法。
当我使用第二种方法（$R^2$ 中的变化）时，我没有发现 DIF；各个模型之间，伪$R^2$度量（McFadden、Nagelkerke 或 Cox-Snell）的变化均不超过 0.01。
当我使用第三种方法（$\beta_1$的变化）时，我也没有发现 DIF；$\beta_1$系数的变化均不超过 3.3%（即使“少量”的 DIF 也应伴随至少 5% 的变化）。
但是，当我查看模型 $(2)$ 的实际回归结果时，我发现$\beta_2$系数较大且显著。以 PHQ-9 的第七项（注意力不集中）为例：lrm 系数为 0.789（OR = 2.2），这表明在控制潜在抑郁分数后，大学生在更高类别中回答的几率是非大学生的 2.2 倍。在我看来，这似乎是相当大的 DIF，但大多数人似乎并不认为这是 DIF。这是为什么呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/653367/differential-item-functioning-criteria-selection</guid>
      <pubDate>Mon, 26 Aug 2024 22:28:38 GMT</pubDate>
    </item>
    <item>
      <title>利用高维特征预测噪声目标</title>
      <link>https://stats.stackexchange.com/questions/653177/predicting-a-noisy-target-with-high-dimensional-features</link>
      <description><![CDATA[我正在研究一个回归问题，该问题包含两组连续特征 $X_1$ 和 $X_2$，我认为它们对于预测非常嘈杂的连续目标 $y$ 很有用。我所说的“嘈杂”是指，在样本外泛化准确率（例如相关性）不超过 5% 的模型是好的。 $X_i$ 中的一个或两个都是高维的，$n \ll p$，并且对于非正则化的 OLS 拟合来说会过度参数化。
当我拟合两个模型 $f(X_1)$ 和 $f(X_2)$ 来预测 $y$ 时，它们的预测相似并且具有相关的误差（残差）。因此，当集成（例如 bagged 或 boosted）时，它们的帮助较小。但是，我们可以假设 $X_2$ 中的信息可用于预测 $y$，该信息超出 $X_1$ 中的信息，或者与 $X_1$ 中的信息有足够大的不同。
有什么好方法可以强制 $f(X_2)$ 与 $y$ 相关，并且 不 与预测 $f(X_1)$ 相关？
我一直在尝试对 $X_2$ 进行回归分析 $f(X_1)$；或者 PCA 并忽略前几个 PC（与去噪相反）；或者对潜在变量进行偏最小二乘并忽略第一个成分；或者在损失函数中添加相关性惩罚（例如余弦相似度）。有没有更原则性的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/653177/predicting-a-noisy-target-with-high-dimensional-features</guid>
      <pubDate>Thu, 22 Aug 2024 15:33:28 GMT</pubDate>
    </item>
    </channel>
</rss>