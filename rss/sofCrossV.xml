<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 30 Jan 2024 00:57:26 GMT</lastBuildDate>
    <item>
      <title>两个独立置信区间之间的关系以及这两个样本的置信区间（平均值、标准差、n）</title>
      <link>https://stats.stackexchange.com/questions/638071/relationship-between-two-independent-confidence-intervals-and-the-confidence-int</link>
      <description><![CDATA[我试图了解何时存在“统计上显着的差异”以及影响的大小。
想象一下，我们有一种新药，并且有一项随机对照试验（RCT）。结果是（越多越好）。我们无法访问原始数据。
安慰剂：

N = 33
平均值 = 85
标准偏差 = 14

新药：

N = 33
平均值 = 94
标准偏差 = 13

本文显示了这些结果以及 p 值，即 p = 0.001。论文的结论是，结果存在统计学上的显着差异。
我用t-student分布计算了个体置信区间（CI）并得到（下限，上限）：
安慰剂：（80.04，89.96）
新药：(89.39, 98.61)
在个体 CI 中，安慰剂和新药之间存在交叉点。换句话说，在此计算中，结果不存在统计上的显着差异。
不过，我还计算了两个均值之差的置信区间，结果是：
（-15.77432892，-2.225671077）
通过此结果，可以注意到结果之间存在统计上的显着差异。
完成所有这些计算后，结果是否存在统计上的显着差异？
为什么单个置信区间与两个均值之间差异的置信区间有不同的解释？]]></description>
      <guid>https://stats.stackexchange.com/questions/638071/relationship-between-two-independent-confidence-intervals-and-the-confidence-int</guid>
      <pubDate>Tue, 30 Jan 2024 00:02:54 GMT</pubDate>
    </item>
    <item>
      <title>计算具有交互作用的实验中的样本量</title>
      <link>https://stats.stackexchange.com/questions/638070/calculate-sample-size-in-an-experiment-with-interactions</link>
      <description><![CDATA[我需要进行功耗分析，但我不确定我做得是否正确。
最初，我有四个单元，每个单元将分为两半。在单元 1 和 2 中，将施加刺激 (S)，而在单元 3 和 4 中，将不施加刺激 (NS)。这些单位的每一半将接受两种治疗中的一种：治疗 1 (T1)，即对照，以及治疗 2 (T2)。这些处理的具体应用如图所示。

在单元 1 中，处理 1 将应用于第 1 面，处理 2 将应用于第 2 面。对于单元 2，处理安排相反。单元 3 和单元 4 将遵循相同的模式，在各自的侧面进行交替处理。
在我的实验中，（通过机器）施加力并测量所有单元的每一侧。我的想法是，我需要测量切割成单元所需的力。目的是检验以下假设：
$H_0:$ 处理 1 和 2 所施加的力没有区别 ($T_1 = T_2$ ）。
$H_1:$ 处理 1 所施加的力大于处理 2 所施加的力 ($T_1 &gt; $T_1 &gt; T_2$)。
然后，我需要测试处理2在有刺激和无刺激的情况下是否有差异。
$H_0:$ 处理 2 有或没有刺激时施加的力没有差异 ($T_2 \乘 S = T_2 \乘 S$)。
$H_1:$ 处理 2 和刺激时施加的力小于处理 2 没有刺激时施加的力 ( $T_2 \times S &lt; T_2 \times S $)。
我从文献中找到了文章的平均值、标准差和样本量，但我不确定如何计算效应大小以及如何确定正确的样本量（考虑 0.80 的幂和显着性水平为 0.05）。在我的示例中，我有四个单元，但我需要计算出需要重复实验多少次（即，我需要重复这组四个单元多少次）。
我最初使用 R 中 pwr 包中的 pwr.anova.test 函数进行计算，但我不确定结果是否正确。谁能建议我可以用来计算样本量的任何方法？或者我使用的方法听起来正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638070/calculate-sample-size-in-an-experiment-with-interactions</guid>
      <pubDate>Mon, 29 Jan 2024 22:54:54 GMT</pubDate>
    </item>
    <item>
      <title>二元 Cox 比例风险模型仿真</title>
      <link>https://stats.stackexchange.com/questions/638069/two-component-cox-proportional-hazards-model-simulation</link>
      <description><![CDATA[在我读过的一篇文章中，他们进行了一项模拟研究：
&lt;块引用&gt;
在此模拟中，我们从以下内容生成 $T_i$
特定组的线性变换模型： $$H(T_i) = \beta_{k,1}
X_{i,1} + \beta_{k,2} X_{i,2} + \varepsilon_i, i = 1, 2, \ldots, n;
 \quad k = 1, 2 $$ 其中 $ H(t) = \log\left(2(e^{4t} - 1)\right)$&lt; /span&gt; 和
$\varepsilon_i $遵循标准极值分布。在
这种情况下，线性变换模型相当于Cox
比例风险模型。我们从两部分生成样本
具有混合权重的 Cox 比例风险模型 $ \pi_1 =
 \frac{1}{3}$、$\pi_2 = \frac{2}{3}$ 和 $ \beta_1
 = (-3, -2)^T$, $\beta_2 = (1, 1)^T$。协变量 $X_i$ 由均值为零的多元正态分布生成
和一阶自回归结构 $ \Sigma = (\sigma_{st})$
其中 $ \sigma_{st} = 0.5^{|s - t|}$ 对于 $ s，t = 1， 2 美元。审查
时间是根据 $[0, C]$ 上的均匀分布生成的，其中 $C$
选择实现 $5\%$ 和 $25\%$ 的审查比例。

我的问题是，我将如何生成生存时间？这是我的方法：
转换函数：我首先反转转换模型来模拟生存时间。
$$
        H(t) = \log(2(e^{4t} - 1)), \\
        H^{-1}(y) = \frac{1}{4} \log\left(\frac{e^y}{2} + 1\right)。
  $$
模型参数：
该模型涉及两个具有混合权重的组件
$$\pi_1 = \frac{1}{3}, \quad \pi_2 = \frac{2}{3},
$$
和参数向量 $$ \beta_1 = (-3, -2)^{\top}, \quad \beta_2 = (1, 1)^{\top}$$
协变量生成：
$\Sigma$ 是协变量变量的协方差矩阵，因此，协变量是根据多元正态分布 (MVN) 生成的
$$\Sigma = \begin{pmatrix} 1 &amp; 0.5\\0.5&amp; 1 \end{pmatrix}, \\
        X \sim \text{MVN}(\mu = (0, 0)^{\top}, \Sigma)$$
小组分配和生存时间模拟：
$$\text{group}_i = \begin{cases} 1 &amp; \text{如果 } U_i &lt; \pi_1 \\ 2 &amp; \text{否则} \end{cases}$$，其中
$$ U_i \sim \text{统一}(0, 1)$$
$$H(T_i) = \begin{cases} \beta_1 \cdot X_i + \epsilon_i &amp; \text{如果组}_i = 1
\\ \beta_2 \cdot X_i + \epsilon_i &amp; \text{如果组}_i = 2 \end{案例}。
$$
其中 $$\epsilon_i \sim \text{极值分布}(0, 1)$$
生存时间：
因此，可以使用以下方法生成生存时间
$$
    T= H^{-1}(H(T_i))。
  $$
审查：
$$
    C_i \sim \text{统一}(0, c), \\
    \text{观察到的 } T_i = \min(T_i, C_i), \\
    \delta_i = \begin{cases} 1 &amp; \text{if } T_i \leq C_i \\ 0 &amp; \text{其他} \end{案例}。
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/638069/two-component-cox-proportional-hazards-model-simulation</guid>
      <pubDate>Mon, 29 Jan 2024 22:50:52 GMT</pubDate>
    </item>
    <item>
      <title>高斯后验/后验预测平均值[重复]</title>
      <link>https://stats.stackexchange.com/questions/638068/gaussian-posterior-posterior-predictive-mean</link>
      <description><![CDATA[我对后验分布和后验预测分布之间的差异有点困惑。我知道后验是参数的分布，而后验预测是数据的分布。
对于高斯先验和似然，后验均值将等于后验预测分布的均值，我的假设是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/638068/gaussian-posterior-posterior-predictive-mean</guid>
      <pubDate>Mon, 29 Jan 2024 22:42:58 GMT</pubDate>
    </item>
    <item>
      <title>协变量作为预测变量的固有部分</title>
      <link>https://stats.stackexchange.com/questions/638067/a-covariate-as-an-inherent-part-of-predictor</link>
      <description><![CDATA[我想比较两种疾病类别的脑容量：年轻发病与老年发病。我知道，一般来说，年龄是脑容量的协变量；年龄越大，大脑越小。然而，根据定义，它也是我的分组变量的一部分；无论我做什么，老发病组的年龄&gt; 50 另一个是&gt;1 20.我是否仍应将年龄作为协变量，或者是否有任何其他模型可以克服这种高年龄组关系/定义。]]></description>
      <guid>https://stats.stackexchange.com/questions/638067/a-covariate-as-an-inherent-part-of-predictor</guid>
      <pubDate>Mon, 29 Jan 2024 22:28:18 GMT</pubDate>
    </item>
    <item>
      <title>伽玛分布随机变量矩的参考[重复]</title>
      <link>https://stats.stackexchange.com/questions/638064/reference-for-moments-of-gamma-distribution-random-variable</link>
      <description><![CDATA[我想要一个参考来解释具有伽玛分布的形状和尺度参数的伽玛随机变量的 $n^{th}$ 矩，具体如下力矩方程
\begin{方程}
E[X^n]=\theta^n \prod_{i=1}^n(k+i+1)
\end{方程}]]></description>
      <guid>https://stats.stackexchange.com/questions/638064/reference-for-moments-of-gamma-distribution-random-variable</guid>
      <pubDate>Mon, 29 Jan 2024 22:13:21 GMT</pubDate>
    </item>
    <item>
      <title>关于高斯过程分类器优化最佳实践的建议？</title>
      <link>https://stats.stackexchange.com/questions/638063/advice-on-gaussian-process-classifier-optimisation-best-practises</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/638063/advice-on-gaussian-process-classifier-optimisation-best-practises</guid>
      <pubDate>Mon, 29 Jan 2024 22:06:32 GMT</pubDate>
    </item>
    <item>
      <title>我想计算该数据集的每月标准差[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638060/i-want-to-calculate-the-monthly-std-dev-for-this-data-set</link>
      <description><![CDATA[
用于荟萃分析。每3个月测量一次术后肢体角度的变化]]></description>
      <guid>https://stats.stackexchange.com/questions/638060/i-want-to-calculate-the-monthly-std-dev-for-this-data-set</guid>
      <pubDate>Mon, 29 Jan 2024 21:30:30 GMT</pubDate>
    </item>
    <item>
      <title>显示分层和回归之间等价性的示例</title>
      <link>https://stats.stackexchange.com/questions/638058/example-showing-equivalence-between-stratification-and-regression</link>
      <description><![CDATA[展示在回归中使用对照来估计治疗对结果的影响背后的直觉的一种方法是分层。当控制 Z 时，我们会查看具有相似 Z 水平的观测值之间 X 和 Y 之间的关系，如 此处
&lt;块引用&gt;
最简单的方法（也是您提出的）是对数据进行分层，以便获得具有相似特征的子组 - 然后可以使用一些方法将这些结果汇总在一起以获得单个“答案”。如果您想要控制的变量数量非常少，那么这种方法是有效的，但正如您所正确发现的那样，当您将数据分割成越来越小的块时，这种方法很快就会崩溃......一种更常见的方法是包括您想要在回归模型中控制的变量...您将得到的估计...将是其他协变量水平内不耐烦的影响 - 回归允许您基本上平滑没有太多数据的地方（分层方法的问题），尽管应该谨慎行事。

我一直在努力使用模拟数据在 R 中设计一个示例，以显示分层和回归之间的等价性。也就是说，您可以得到相同的答案，要么控制 Z，要么仅在 Z = 0 或 Z = 1 之间拟合 X 和 Y 之间的模型（另一个问题：这会产生两个估计；如何组合？）
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/638058/example-showing-equivalence-between-stratification-and-regression</guid>
      <pubDate>Mon, 29 Jan 2024 20:50:18 GMT</pubDate>
    </item>
    <item>
      <title>独立条件下 Kendall tau 的精确采样分布（无关系情况）</title>
      <link>https://stats.stackexchange.com/questions/638057/exact-sampling-distribution-of-kendalls-tau-under-independence-no-ties-case</link>
      <description><![CDATA[我正在寻找一个 R 包，用于在独立性零假设下计算样本 Kendall&#39;s tau (*) 的 CDF 和逆 CDF，没有关系的情况下。
(*) 需要明确的是，我指的是测量随机样本的一致性或单调相关性的统计 $\hat{\tau}$ &lt;双变量连续随机变量的 span class=&quot;math-container&quot;&gt;$\{(X_1, Y_1), \dots, (X_n,Y_n)\}$ $ (X,Y)$，假设 $X$ 和 $Y$ 是独立的.
到目前为止我找到的唯一包是SuppDists。它提供了函数dKendall、pKendall、qKendall和rKendall。在文档中，它说：
&lt;块引用&gt;
计算值对于 $n &lt;&lt; 13$，此后使用埃奇沃斯展开。

更准确地说，对于 $n$ 的小值，似乎精确的计算是按照 Hajek &amp; 完成的。西达克（1967，第 140 页）。我通过阅读底层 C 代码发现了这一点。如果我没记错的话，它引用了一个递归公式（我没有 1967 年的版本，而是更新的版本）。
无论如何，有人知道有一个包可以实现样本 Kendall&#39;s tau 的 CDF 和逆 CDF 的精确计算，以获取较大的值 $n$?
&lt;小时/&gt;
参考文献
哈耶克·J、西达克·Z (1967)。等级检验理论。学术出版社，纽约。]]></description>
      <guid>https://stats.stackexchange.com/questions/638057/exact-sampling-distribution-of-kendalls-tau-under-independence-no-ties-case</guid>
      <pubDate>Mon, 29 Jan 2024 20:48:45 GMT</pubDate>
    </item>
    <item>
      <title>即使在高n时也记录所有影响因素？</title>
      <link>https://stats.stackexchange.com/questions/638056/record-all-influential-factors-even-at-high-n</link>
      <description><![CDATA[我的任务是评估鱼类捕食者（水獭）对自然水体中鱼类丰度的影响。虽然该国部分地区的水獭数量已经非常丰富，但预计其范围很快就会遍及整个地区。理想情况下，我希望通过在许多不同水体中进行电捕鱼，以标准化方式监测目前未受水獭影响的鱼类种群，同时监测水獭的存在，并持续几年，直到水獭到达所有（或大多数）水体。所以我会得到很好的前后数据，甚至可能是控​​制。然而，财务限制不允许此类数据。
相反，我想到招募钓鱼者来提供全国不同地区的渔获量和努力量数据。理想情况下，假设来自不同地点的 100 名钓鱼者提供以下数据：
名称、水体、日期、水獭的存在、捕捞时间、捕获的鱼数量。
然后我可以应用 GLMM，如下所示：
捕获的鱼数 ~ 水獭的存在 + 偏移量（捕捞小时数）+ (1|水体) + (1|日期) + (1|名称)
然而，我没有考虑到这样一个事实：还有许多其他因素影响着我的渔获量（我的丰度指标）：在某些水体中，每年的鱼类放养数量各不相同。然后可能还有其他捕食者影响鱼类的丰度。洪水或热浪会对鱼类丰度产生负面影响。虽然我无法记录所有水体的所有这些指标。
我的问题如下：
假设只要调查的水体数量很高（假设 n = 50），并且没有理由假设影响鱼类丰度的任何其他变量（其他捕食者、高温、洪水、放养……）是否合适？ ）与水獭的存在系统地共同变化，因此可能没有必要记录它们，并且仍然能够就水獭单独的影响得出结论？
非常感谢您对我的问题提供反馈😊
菲尔]]></description>
      <guid>https://stats.stackexchange.com/questions/638056/record-all-influential-factors-even-at-high-n</guid>
      <pubDate>Mon, 29 Jan 2024 20:45:44 GMT</pubDate>
    </item>
    <item>
      <title>Bootstrap 置信区间：证明正确性</title>
      <link>https://stats.stackexchange.com/questions/638053/bootstrap-confidence-intervals-proving-correctness</link>
      <description><![CDATA[我正在研究使用引导技术来计算感兴趣参数的置信区间。
设 $\textbf{Z}_1, ... \textbf{Z}_n\in\mathbb{R}^d$ 为 (iid)随机抽样。从这个随机样本中，我们计算 $\hat{\theta}$ 参数（很难明确地表达）。我想获取此参数的 CI。
我使用基本的引导技术。这涉及从我们的随机样本中进行随机抽样和替换，以生成多个引导样本，每个样本都与原始数据集的大小相匹配。对于每个引导样本，我计算统计量 $\hat{\theta}^\star$ 的估计值。随后，我们确定重新采样统计数据的 $95%$ 分位数，以得出置信区间。我想证明他们的渐近正确性。有一些我可以使用的一般结果吗？我只发现使用 Berry-Essen 定理对 $\theta$=mean 进行理论论证，但我的统计 $\theta$&lt; /span&gt; 要复杂得多。
总之，我想证明这样的事情：
定理
令 $\hat{\theta}$ 为估计量（来自样本大小 $n$） $\theta$ 并让 $\mathbb{E}||\textbf{Z}||^2&lt;\infty $.
将原始样本的重采样表示为 $(\textbf{Z}^\star_{1,1}, \dots \textbf{Z}^\star_{1, n}),\dots, (\textbf{Z}^\star_{B,1}, \dots, \textbf{Z}^\star_{B,n})$，以及相应的估计值 $\hat{\theta}_1^\star, \dots, \hat{\theta}_B^\star$ 为 $ B\in\mathbb{N}$。
让 $U:=\hat{\theta}_{(\alpha)}^\star$ 代表 $B(1-\alpha)$ $\hat{\theta}_1^\star、\dots、\hat{\theta}_B 中的最大值^\star$.
那么，
$$\lim_{n\to\infty}\lim_{B\to\infty}P(\hat{\theta}]]></description>
      <guid>https://stats.stackexchange.com/questions/638053/bootstrap-confidence-intervals-proving-correctness</guid>
      <pubDate>Mon, 29 Jan 2024 20:23:03 GMT</pubDate>
    </item>
    <item>
      <title>BERT 是否需要使用注意力掩模进行均值池化？</title>
      <link>https://stats.stackexchange.com/questions/638049/is-it-necessary-to-use-attention-mask-for-mean-pooling-for-bert</link>
      <description><![CDATA[我正在开展一个项目，涉及使用“emilyalsentzer/Bio_ClinicalBERT”分析临床文本。来自 Hugging Face 变形金刚库的模型。我的目标是从模型中提取有意义的句子嵌入以用于下游任务。我知道 BERT 嵌入的几种池化策略，但我不确定哪种策略对我的特定用例最有效。
普遍的方法是使用 CLS 令牌进行嵌入。然而，受到最近一篇使用均值池和最佳层选择算法的论文的启发，我&#39;一直在考虑最后一个隐藏状态层的平均池化。许多存储库的常见做法是直接计算最后一层的平均值。但我相信，这可能会忽略一个关键方面：注意力面具。
直观上，在池化之前，首先将最后一个隐藏状态与注意掩码相乘，有效地过滤掉填充序列似乎更准确。根据我的理解，这将确保只有重要的令牌嵌入才会对平均值做出贡献。
这种将注意力掩模纳入均值池的修改方法是否比典型的直接均值计算更有效？我正在寻求有关此方法是否提高下游应用程序嵌入质量的见解。代码示例
导入 torch.nn 作为 nn
从 Transformer 导入 AutoModel、AutoTokenizer

项目_dim = 512
bert_model = AutoModel.from_pretrained(“emilyalsentzer/Bio_ClinicalBERT”，output_hidden_​​states=True)
tokenizer = AutoTokenizer.from_pretrained(“emilyalsentzer/Bio_ClinicalBERT”)
tokenizer.model_max_length = 256
projection_head = nn.Linear(768, proj_dim)

defmean_pooling(model_output,attention_mask):
    token_embeddings = model_output[0] # model_output 的第一个元素包含所有 token 嵌入
    input_mask_expanded=attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    返回 torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)

# 用法示例
输出= bert_model（input_ids=input_ids，attention_mask=attention_mask）
嵌入=mean_pooling（输出，attention_mask）
]]></description>
      <guid>https://stats.stackexchange.com/questions/638049/is-it-necessary-to-use-attention-mask-for-mean-pooling-for-bert</guid>
      <pubDate>Mon, 29 Jan 2024 19:58:48 GMT</pubDate>
    </item>
    <item>
      <title>仅一组的线性混合效应模型的截距的解释是什么</title>
      <link>https://stats.stackexchange.com/questions/638048/whats-the-interpretation-of-the-intercept-of-a-linear-mixed-effect-model-with-o</link>
      <description><![CDATA[我试图理解线性混合模型中截距项的含义。这里需要注意的是，LME 所基于的数据集将仅包含来自单个类别（组）的受试者。所有科目都会有技术重复，有些比其他更多。因此，公式如下：
$y = B0 + (1|\text{subject})$
主题是随机效应（考虑主题内方差），y 是响应变量，B0 是截距。我在进行一些先前搜索时的理解是，这可以被解释为“平均模型”，其中“平均”是一个“平均模型”。是B0。然而，这是在线性模型的背景下，而不是线性混合效应模型。
因此，我想知道是否有人可以帮助阐明 B0 在这种情况下的含义（特别是考虑到数据集仅由来自一个类（组）的受试者组成这一事实），以及它是否是一种有效的方法获得“群体代表值”。例如，我在两个单独的组（组 $A$ 和组 $B$）上运行上述 LME这样我现在就有了
$B_{0_A} $ 和 $B_{0_B} $
考虑到上述组代表值没有通过经典平均方法进行量化，那么使用上述组代表值进行统计测试是否有效？为了澄清起见，我还将使用所用算法的 B0_A 和 B0_B 的标准误差（MATLAB 中的 fitlme）]]></description>
      <guid>https://stats.stackexchange.com/questions/638048/whats-the-interpretation-of-the-intercept-of-a-linear-mixed-effect-model-with-o</guid>
      <pubDate>Mon, 29 Jan 2024 19:54:18 GMT</pubDate>
    </item>
    <item>
      <title>如何计算伽玛分布的分位数？</title>
      <link>https://stats.stackexchange.com/questions/638047/how-to-calculate-quantiles-for-a-gamma-distribution</link>
      <description><![CDATA[我想计算伽马分布的分位数。我发现了一个所谓的示例此处给出为
$$\text{分位数}(a, b, p) = \frac{\gamma^{-1}(a, \Gamma(a) p )}{ b}$$
其中 $\gamma^{-1}$ 是下不完全伽马函数的反函数，$\Gamma $是伽马函数。
在 SciPy 中尝试这一点，我发现对于许多值，我得到了 nan，这表明数值出现了问题。
from scipy.special import (gammaincinv, gamma as gamma_function)

def gamma_quantile_function(a, b, p):
    
    返回 gammaincinv(a, gamma_function(a) * p) / b

gamma_quantile_function(3.8756542398707046, 5349.756221, 0.99) # 返回 `nan`

只是我的实现有问题，还是数学错误？]]></description>
      <guid>https://stats.stackexchange.com/questions/638047/how-to-calculate-quantiles-for-a-gamma-distribution</guid>
      <pubDate>Mon, 29 Jan 2024 19:36:42 GMT</pubDate>
    </item>
    </channel>
</rss>