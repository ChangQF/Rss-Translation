<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 14 Jul 2024 03:18:16 GMT</lastBuildDate>
    <item>
      <title>使用连续风险函数证明参数可分离性</title>
      <link>https://stats.stackexchange.com/questions/651006/proving-parameter-separability-with-a-continuous-risk-function</link>
      <description><![CDATA[我有一个连续函数 $R : \Theta \mapsto \mathbb{R}$，其最小化函数为 $\tilde{\theta}$，我想要证明
$$\inf_{\theta:d(\theta, \tilde{\theta}) &gt; \delta} ( R(\theta) - R(\tilde{\theta}) ) &gt; 0 \text{ 对于任意 } \delta &gt; 0$$
示例函数为 $R(\theta) = -\text{log}(p_{\theta}(y))$，其中 $p_{\theta}(y)$ 是有限混合分布的 pdf
$$p_{\theta}(y) = \sum_{c = 1}^C w_c p_{\psi_c}(y) \quad \theta = (w_1,...w_c, \psi_1, ...\psi_c)$$]]></description>
      <guid>https://stats.stackexchange.com/questions/651006/proving-parameter-separability-with-a-continuous-risk-function</guid>
      <pubDate>Sun, 14 Jul 2024 02:51:38 GMT</pubDate>
    </item>
    <item>
      <title>为了成功地进行特征选择，至少应该使用多少个样本？</title>
      <link>https://stats.stackexchange.com/questions/651005/how-many-samples-should-i-use-at-minimum-for-successful-feature-selection</link>
      <description><![CDATA[假设我的表格数据集中有 100 万个样本和 1000 列。
我想在数据集上运行特征子集选择算法。
加载完整数据集将使我的系统不堪重负。因此，我想加载其中的一部分。
我应该至少使用多少个样本来执行成功的特征选择，以便当我使用这些特征训练神经网络时，它将为我提供最高的准确度。]]></description>
      <guid>https://stats.stackexchange.com/questions/651005/how-many-samples-should-i-use-at-minimum-for-successful-feature-selection</guid>
      <pubDate>Sun, 14 Jul 2024 02:28:26 GMT</pubDate>
    </item>
    <item>
      <title>如何为已知偏差、准确率和召回率的 LLM 分类器构建类别比例置信区间？</title>
      <link>https://stats.stackexchange.com/questions/651004/how-to-construct-class-proportion-confidence-interval-for-an-llm-classifier-with</link>
      <description><![CDATA[假设我有一个数据集 $D$，其中有已知的基本事实标签。尽管如此，我还是在这个数据集上使用了一个少样本 LLM 分类器来预测每个标签的 $k$ 个类别。
从 LLM 结果中，我获得了每个 $k$ 个类别的精确召回率。我还获得了每个标签比例的偏差量，即预测比例与基本事实之间的差异。我知道该模型在预测标签方面的准确性。
我现在计划在新的数据集上预测标签，但我不知道基本事实。我想根据 LLM 的过去表现量化每个类别中标签总数的不确定性。
通常，我可能会使用引导程序简单地重新采样并在循环中重新拟合确定性模型，并采用预测的经验分布来获得预测的置信区间。但是，我们不能这样做，因为 LLM 调用成本太高。
我的想法是，我们应该：

通过从已知比例 $p_k$ 中减去经验估计的类比例 $\frac{TP_k}{N}$，确定每个 $k$ 类的分类器偏差。
使用标准 Wald 正态近似二项式方法确定经验类估计 $\frac{TP_k}{N}$ 的置信区间，并简单地将这些区间移动偏差量。

但是，我不确定这是否有效。它看起来无效，因为标准错误对于 $p_k$ 的值不是不变的。]]></description>
      <guid>https://stats.stackexchange.com/questions/651004/how-to-construct-class-proportion-confidence-interval-for-an-llm-classifier-with</guid>
      <pubDate>Sun, 14 Jul 2024 01:59:37 GMT</pubDate>
    </item>
    <item>
      <title>AMOS 上的稳健最大似然估计量？</title>
      <link>https://stats.stackexchange.com/questions/651003/robust-maximum-likelihood-estimator-on-amos</link>
      <description><![CDATA[有谁有建议或能够使用 AMOS 上的稳健最大似然估计器吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651003/robust-maximum-likelihood-estimator-on-amos</guid>
      <pubDate>Sun, 14 Jul 2024 01:19:00 GMT</pubDate>
    </item>
    <item>
      <title>检验的一致性 - 分位数收敛</title>
      <link>https://stats.stackexchange.com/questions/650998/consistency-of-a-test-convergence-of-quantile</link>
      <description><![CDATA[我给出了统计模型$((0,1)^n, \mathcal{B}(0,1)^n,\mathcal{P}_n)$，其中$\mathcal{P}_n=\{ P_{\theta}^{\otimes n} \ |\ \theta \in (0, \infty) \}$且每个$P_{\theta}$都有密度函数$f_{\theta}(x)=\theta x^{\theta-1}$，且$P_{\theta}^{\otimes n}$表示乘积测量，同时假设独立性。我们想要测试：
$$H:\theta\leq 1\ ; \ K: \theta&gt;1$$
使用测试，$$\varphi_n(x)=\chi_{\{T_n(x)&gt;-\gamma_{n,1,\alpha}\}}$$
其中 $T_n(x)=\sum_\limits{i=1}^nlog(x_i)$ 且 $\gamma_{n,1,\alpha}$ 是 $Erlang(n,1)$ 分布的 $\alpha$-分位数。
我试图表明 $\varphi_n$ 是一个一致性测试，因此：
$$\lim_\limits{n \longrightarrow\infty}\mathbb{E}_{\theta}(\varphi_n)=1, \ \theta &gt;1$$
我的尝试如下：
首先我证明了 $Y_i:=-log(X_i) \sim Exp(\theta), \ X_i \sim P_{\theta}$，然后我们知道 $\sum_\limits{i=1}^n Y_i \sim Erlang(n,\theta)$，或者 $\sum_\limits{i=1}^n \theta Y_i \sim Erlang(n,1)$，因为 $\theta Y_i \sim Exp(1) $，使用假设的独立性。
因此我们最终得到 $-\theta \ T_n(X) \sim Erlang(n,1) $，因此如果我们将 $\gamma_{n,1}(x)$ 表示为 $Erlang(n,1)$ 分布的分布函数，我们得到以下结果：
$$\mathbb{E}_{\theta}(\varphi_n)=P_{\theta}(T_n(X)&gt;-\gamma_{n,1,\alpha})=P(-\theta T_n(X)&lt;\theta \ \gamma_{n,1,\alpha})=\gamma_{n,1}(\theta \ \gamma_{n,1,\alpha})$$
建议证明 $\lim_\limits{n \longrightarrow\infty}\frac{\gamma_{n,1,\alpha}}{n}=1$，我没能证明这一点，但假设我会证明这一点，我们现在可以使用 $\lim_\limits{n \longrightarrow\infty}\gamma_{n,1,\alpha}= \infty$，我假设这意味着
$$\lim_\limits{n \longrightarrow\infty}\gamma_{n,1}(\theta \ \gamma_{n,1,\alpha})=1$$
使用该$\gamma_{n,1}$是一个分布函数。但我不太确定如何严格论证这一点。
所以我的问题在于，如何真正证明$\lim_\limits{n \longrightarrow\infty}\frac{\gamma_{n,1,\alpha}}{n}=1$以及如何使用它来证明$\lim_\limits{n \longrightarrow\infty}\gamma_{n,1}(\theta \ \gamma_{n,1,\alpha})=1$。
任何帮助都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/650998/consistency-of-a-test-convergence-of-quantile</guid>
      <pubDate>Sun, 14 Jul 2024 00:23:24 GMT</pubDate>
    </item>
    <item>
      <title>证明线性回归的残差直方图和 QQ 图</title>
      <link>https://stats.stackexchange.com/questions/650996/justifying-residual-histograms-and-qq-plots-for-linear-regression</link>
      <description><![CDATA[从概念上讲，我很难理解为什么我们要考虑线性回归对角线的分位数-分位数图，经过广泛搜索后，我似乎无法得到明确的答案。
我发现的常见而肤浅的答案是，使用 QQ 图将我们的残差与正态分布进行比较（或通过构建残差直方图）可确保我们满足我们的误差对每个 x 值呈正态分布的假设。但这里面有一个缺陷。也就是说，QQ 图和残差直方图将来自所有 x 值的误差合并为一个分布。这样，我们不再考虑每个 x 值的分布，而是查看单个“拼贴”分布。因此，即使我们的 QQ 图看起来是线性的，或者我们的直方图看起来近似正态，我们也不能确定每个 x 值处的单个分布是否是正态的。这有某种概念上的理由吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650996/justifying-residual-histograms-and-qq-plots-for-linear-regression</guid>
      <pubDate>Sun, 14 Jul 2024 00:08:24 GMT</pubDate>
    </item>
    <item>
      <title>SAE 中的 l2 惩罚和 l2 损失之间的区别</title>
      <link>https://stats.stackexchange.com/questions/650995/difference-between-l2-penalty-and-l2-loss-in-sae</link>
      <description><![CDATA[我读过 Anthropic 的这篇论文 https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html，论文中损失的定义如下：$$
L = \mathbb{E}_x \left[ \| x - \hat{x} \|_2^2 + \lambda \sum_i f_i(x) \cdot \| W_{:,i}^{\text{dec}} \|_2 \right]
$$，其表述如下：损失函数
L 是重建损失的 L2 惩罚和特征激活的 L1 惩罚的组合。但这里不是 L2 惩罚吗？因为这里没有 L2 正则化，所以不是 L2 损失而是 L2 惩罚。我会将重建损失定义为 L2 损失而不是惩罚。你能解释一下吗？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/650995/difference-between-l2-penalty-and-l2-loss-in-sae</guid>
      <pubDate>Sun, 14 Jul 2024 00:06:12 GMT</pubDate>
    </item>
    <item>
      <title>Dickey-Fuller 单位根检验，确定性项</title>
      <link>https://stats.stackexchange.com/questions/650993/dickey-fuller-unit-root-test-deterministic-terms</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650993/dickey-fuller-unit-root-test-deterministic-terms</guid>
      <pubDate>Sat, 13 Jul 2024 22:03:05 GMT</pubDate>
    </item>
    <item>
      <title>我可以将数据增强应用于测试集吗？</title>
      <link>https://stats.stackexchange.com/questions/650992/can-i-apply-data-augmentation-to-the-test-set</link>
      <description><![CDATA[我正在处理一个包含 102 行（表格数据）的数据集，其中 91 行用于训练，11 行用于测试。我通过为训练集添加高斯噪声来使用数据增强。假设我做了所有正确的预处理（没有数据泄露），那么科学出版物将数据增强应用于我的测试集是否正确/可以接受，因此它可以大于 11 行？]]></description>
      <guid>https://stats.stackexchange.com/questions/650992/can-i-apply-data-augmentation-to-the-test-set</guid>
      <pubDate>Sat, 13 Jul 2024 21:47:42 GMT</pubDate>
    </item>
    <item>
      <title>使用什么标准来比较二元变量的多重相关性？</title>
      <link>https://stats.stackexchange.com/questions/650990/what-criterion-to-use-to-compare-multiple-correlations-of-binary-variables</link>
      <description><![CDATA[我有一个测试，其中有 $k$ 个 是/否 道题，有 $N$ 名学生参加。我想测试测试问题的一致性，即不同的考生是否以相同的方式解释这些问题（我认为所有问题的复杂性都相似）。我的零假设是所有问题的表述都同样清晰，而我的备选假设是其中一个问题的表述不如其他问题清晰。作为清晰度的衡量标准，我想使用不同考生对同一问题的答案之间的某种相关性。我的问题是：1) 我应该使用什么相关性指标，2) 我应该采用什么统计标准来测试相关性的同质性？
附言：为了避免误解，我需要补充一点，我实际上想测试定义的一致性，方法是让受访者决定某种情况是否符合定义。我发现在统计背景下思考考试的例子更加直观，但它会引入与考生是否了解正确答案有关的不必要的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/650990/what-criterion-to-use-to-compare-multiple-correlations-of-binary-variables</guid>
      <pubDate>Sat, 13 Jul 2024 20:33:56 GMT</pubDate>
    </item>
    <item>
      <title>如果我们需要整个批次的平均值和方差来进行批次标准化，那么在获得这些值之前我们如何进行单次前向传递？</title>
      <link>https://stats.stackexchange.com/questions/650989/if-we-need-the-mean-and-variance-of-the-entire-batch-for-batch-normalization-ho</link>
      <description><![CDATA[如果我理解正确的话，该模型有多个隐藏层，中间有批量归一化层。当尝试计算前向传递以进行反向传播时，我们如何知道 BN 层应该具有的均值和方差？我们是否只对特定实例应用归一化？]]></description>
      <guid>https://stats.stackexchange.com/questions/650989/if-we-need-the-mean-and-variance-of-the-entire-batch-for-batch-normalization-ho</guid>
      <pubDate>Sat, 13 Jul 2024 19:57:21 GMT</pubDate>
    </item>
    <item>
      <title>评估贝叶斯回归模型后验的黄金标准是什么？</title>
      <link>https://stats.stackexchange.com/questions/650988/what-is-the-gold-standard-for-evaluating-the-posterior-of-a-bayesian-regression</link>
      <description><![CDATA[让我解释一下我的意思和上下文：

我的意思是评估后验的正确性（例如对于近似贝叶斯推理方法）。
我最关心的是贝叶斯深度学习，我想要一种可以扩展到非常高维度的方法&amp;参数计数。。
有许多方法可用于分类（例如 Brier 评分），但我要求一些可与回归相媲美的方法。

一个有前途的想法是后验预测检查，但老实说，鉴于大多数贝叶斯模型输出样本而不是显式 pdf，我不确定如何以实用的方式实现它……
有什么想法吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650988/what-is-the-gold-standard-for-evaluating-the-posterior-of-a-bayesian-regression</guid>
      <pubDate>Sat, 13 Jul 2024 19:51:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们通常用卡方统计量来检验列联表的行/列变量的独立性？</title>
      <link>https://stats.stackexchange.com/questions/650983/why-do-we-usually-test-independence-of-row-column-variables-of-a-contingency-tab</link>
      <description><![CDATA[对于 $r \times c$ 列联表，单元格包含观察到的频率，通常使用 $\chi^2$ 卡方检验来检验零假设“行和列变量是独立的”。数量
$$X^2 = \sum{\dfrac{(O-E)^2}{E}}$$
被使用，其中 $O$ 表示单元格中的观察到的频率，$E$ 表示独立情况下单元格中的预期频率；总和是针对表中所有单元格的。在独立性零假设下（以及所有预期频率“足够大”的附加条件），$X^2$ 服从 $\chi^2$ 分布，自由度为 $(r-1) \times (c-1)$，我们可以使用它来统计检验独立性零假设。
现在假设我们不使用 $X^2$，而是使用另一个量，例如：
$$Q_1 =\sum(O-E)^2$$
或者
$$Q_2 = \sum|O-E|$$
检验假设独立性。出于某种原因，这会是“错误的”吗？我们不使用这些（或其他）替代方案中的任何一个，是因为它们在零假设下的分布是未知的，而不是 $X^2$ 的零分布？也就是说，如果我们在独立性的零假设下生成例如 $Q_1$ 的分布，那么我们是否也可以使用 $Q_1$ 来测试独立性？显然，在独立性下生成例如 $Q_1$ 的精确分布，对于列联表中的大量观测值来说可能是不可行的，但我们可以抽取一个大样本（例如使用 R 中的 r2dtable）。但是，也许还有另一个重要的原因，说明为什么 $X^2$ 是测试独立性的更好甚至最佳选择。如果是这样，那么我想知道这一点。
为了清楚起见，我并不提倡任何其他数量，只是想知道从理论上讲这些替代方案是否也可以使用。感谢您的指导！]]></description>
      <guid>https://stats.stackexchange.com/questions/650983/why-do-we-usually-test-independence-of-row-column-variables-of-a-contingency-tab</guid>
      <pubDate>Sat, 13 Jul 2024 18:58:16 GMT</pubDate>
    </item>
    <item>
      <title>非齐次几何分布方法</title>
      <link>https://stats.stackexchange.com/questions/650982/nonhomogenous-geometric-distribution-approach</link>
      <description><![CDATA[我正尝试通过考虑概率不等的几何分布来解决这个问题。
首先，我使用 Irwin-Hall 分布来推导，对于 n 个独立的均匀随机变量，$P(U_{1}+U_{2} + ... + U_{n} \geq 1) = 1 - \frac{1}{n!}$
因此，如果我们让 $X$ = 成功前的试验次数，那么
\begin{equation}
\begin{aligned}
P(X=2) &amp;= P(U_{1} + U_{2} \geq 1) \\
&amp; = 1-\frac{1}{2} \\
&amp; = \frac{1}{2}
\end{aligned}
\end{equation&gt;
\begin{equation}
\begin{aligned}
P(X=3) &amp;= (1-P(X=2))P(U_{1} + U_{2} + U_{3} \geq 1) \\
&amp; = (1-\frac{1}{2}) (1-\frac{1}{6}) \\
&amp; = \frac{5}{12}
\end{aligned}
\end{equation
一般来说，如果 n &gt; 2，则似乎 $P(X = n) = (1-\frac{1}{n!})\displaystyle \prod_{k=2}^{n-1} (1-P(X=k))$
我读到这个问题的答案应该是 $e$。但使用这种方法，我得到的预期值为 $\approx$ 2.6。这种方法有什么问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650982/nonhomogenous-geometric-distribution-approach</guid>
      <pubDate>Sat, 13 Jul 2024 18:57:55 GMT</pubDate>
    </item>
    <item>
      <title>多类分类的假阴性与假阳性</title>
      <link>https://stats.stackexchange.com/questions/650978/false-negative-vs-false-positive-for-multiclass-classification</link>
      <description><![CDATA[假设我有三个类别 1、2、3。
并且有如下评估，其中第二个元素是错误预测，其中模型预测类别 3，而基本事实是 2。
y_true = [1,2,3]
y_pred = [1,3,3]

我正在制作可视化工具，其中

如果模型预测为类别 1 而基本事实不是类别 1，则为红色
如果模型预测为类别 2 而基本事实不是类别 2，则为绿色
如果模型预测为类别 3 而基本事实不是类别 3，则为红色
真实预测无颜色

第二个元素的错误类型是什么？假阳性还是假阴性？
从我上面的案例来看，第二个元素将是蓝色。]]></description>
      <guid>https://stats.stackexchange.com/questions/650978/false-negative-vs-false-positive-for-multiclass-classification</guid>
      <pubDate>Sat, 13 Jul 2024 16:44:51 GMT</pubDate>
    </item>
    </channel>
</rss>