<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 08 Mar 2025 21:14:13 GMT</lastBuildDate>
    <item>
      <title>始终减少BIC</title>
      <link>https://stats.stackexchange.com/questions/662354/consistently-decreasing-bic</link>
      <description><![CDATA[我试图找出具有每日季节性降雨值的HMM模型中的状态数量，迫使HMM作为10+站的多项式。我的BIC价值观并没有改善；他们不断减少。我不确定如何修复状态数量。请让我知道减少BIC的确切含义以及在这种情况下选择HMM状态选择的任何其他好方法]]></description>
      <guid>https://stats.stackexchange.com/questions/662354/consistently-decreasing-bic</guid>
      <pubDate>Sat, 08 Mar 2025 21:07:18 GMT</pubDate>
    </item>
    <item>
      <title>在哪些情况下，您将使用Dunnett与ANOVA作为多重回归（具有分类预测指标）？</title>
      <link>https://stats.stackexchange.com/questions/662352/in-what-scenarios-would-you-use-dunnett-vs-anova-as-multiple-regression-with-c</link>
      <description><![CDATA[ 上下文：我在纸直升机上有数据。  因变量是到达地面的时候（以秒为单位），在数据的这一子集中，自变量是直升机的纸张的颜色（5个选项）。
 问题：如果与单个2个独立的样本相比，如果参考组成对伪造编码以多重回归（MR）为多个回归（MR）提供不同的P  p   - 值
假设确实需要进行更保守的调整，那么后续问题（这里是主要问题）将是：当每种不同的方法（ANOVA作为MR Model vs. Dunnett测试）时，是否存在场景？
 结果：这是每个参考组成对比较的3个协议中的每个协议中的每个协议中的每个 p   - 值
 


配对
 t检验
 anova为Mr 
 dunnett 




绿色与蓝色
 0.01128 
 0.0564 
 0.16177 


紫色与蓝色
 0.008719 
 0.0521 
 0.15066 


鲑鱼与蓝色
 0.1977 
 0.3911 
 0.82140 


白色与蓝色
 0.0001508 
 1.91E-7 
 5.9792e-7 


 
奇怪的观察： p   - 值得从左到右移动，除了最后一行。  在那里，最保守的价值来自未经调整的配对样本 t  -test。
这是用于运行此分析的代码：
 ＃单独的配对t检验
t.t.test（时间〜颜色，data = subset（tmp.df，color％in％c（“ blue”，&#39;&#39;，; quot; green; quot; quot）），var.equal = t）
t.test（时间〜颜色，data = subset（tmp.df，color％in％c）
t.test（时间〜颜色，data = subset（tmp.df，color％in％c）
t.t.test（时间〜颜色，data = subset（tmp.df，color％in％c（“ blue”，&#39;&#39;白色，“白色”）），var.equal = t）

＃ANOVA作为MR模型
lm.out＆lt;  -  lm（time〜As.factor（color），data = tmp.df）
摘要（lm.out）

＃Dunnett测试
aov.out＆lt;  -  aov（time〜As.factor（color），data = tmp.df）
摘要（dunnetttest（aov.out））
 
这是该语法的输出（省略了配对检验t检验的输出）：
 ＆gt;摘要（lm.out）

称呼：
lm（公式=时间〜As.factor（color），data = tmp.df）

残差：
     最小1Q中位数3Q最大 
-2.26208 -0.48667 -0.00758 0.59750 2.45792 

系数：
                       估计标准。错误t值pr（＆gt; | t |）    
（截距）7.2667 0.1462 49.716＆lt; 2E-16 ***
AS.Factor（颜色）绿色-0.3967 0.2067 -1.919 0.0564。  
AS.Factor（颜色）紫色-0.3867 0.1979 -1.954 0.0521。  
AS.Factor（颜色）鲑鱼-0.1515 0.1763 -0.860 0.3911    
AS.Factor（颜色）白色-1.0046 0.1863 -5.392 1.91E -07 ***
---
象征。代码：0&#39;***’0.001&#39;**’0.01&#39;*’0.05&#39;。’0.1’’1

剩余标准错误：205自由度的0.8006
多个R平方：0.1675，调整后的R平方：0.1512 
F统计：4和205 DF，p值：1.262E-07

＆gt;摘要（dunnetttest（aov.out））

    使用Dunnett的测试对多个测试进行对比较  
                         与一个控件的比较

数据：AS.Factor（颜色）的时间
替代假设：两面
P值调整方法：单步
H0
                   t值pr（＆gt; | t |）    
绿色 - 蓝色== 0 -1.919 0.16177    
紫色-Blue == 0 -1.954 0.15066    
鲑鱼-Blue == 0 -0.860 0.82140    
白色 - 蓝色== 0 -5.392 5.9792E -07 ***
---
象征。代码：0&#39;***’0.001&#39;**’0.01&#39;*’0.05&#39;。’0.1’’1
 

注意：
 首先，我对此网站进行了搜索，并找到了这两个帖子：＆nbsp; ＆bull;＆nbsp; 通过多个线性回归 ＆nbspp; 470906#470906&gt; ＆nbsp; ＆nbsp; ＆nbsp; and• Should I adjust the significance levels in a multiple (linear) regression with dummy variables,进行许多比较时？ 
但是，这两个都没有完全解决我问题的核心。 第二，这个问题的目的本质上是教学的。＆nbsp;简而言之，我希望能够通过具体的示例和场景清楚地向我的学生解释这一点。 用于此示例的数据集来自多级项目，我很高兴能与任何对进一步探索它的兴趣共享数据。 （我将包括一个URL作为评论。）
]]></description>
      <guid>https://stats.stackexchange.com/questions/662352/in-what-scenarios-would-you-use-dunnett-vs-anova-as-multiple-regression-with-c</guid>
      <pubDate>Sat, 08 Mar 2025 17:42:49 GMT</pubDate>
    </item>
    <item>
      <title>如何计算负二比边缘系数上的95％CI？ glmmadaptive :: confint and glmmadaptive :: marginal_coef的奇怪结果</title>
      <link>https://stats.stackexchange.com/questions/662349/how-to-calculate-a-95-ci-on-negative-binomial-marginal-coefficients-strange-re</link>
      <description><![CDATA[我正在为重复测量设置中的计数数据拟合一个负二项模型
 库（glmmadaptive）
图书馆（ggplot2）


mod＆lt;  - 混合_model（fixed = freq〜TimePoint + binary_factor1 + binary_factor2，andand = 〜1 | objectiond，data = df，
                  family = nater.binmial（））
 
它返回以下估计值和95％CI。 Dharma Diagnostics都回来了。
 致电：
混合_model（fixed = vtvf_freq〜时间点 + binary_factor1 + binary_factor1 + 
    binary_factor2，随机= 〜1 | succemid，data = df，family = nater.binomial（））

数据描述：
观察数：34
组数：17 

模型：
 家庭：负二项式
 链接：日志 

适合统计：
   log.lik aic bic
 -69.41618 150.8324 155.8316

随机效应协方差矩阵：
              stddev
（截距）0.290057

固定效果：
                               估计std.err z值p值
（截距）1.6340 0.5204 3.1396 0.0016915
TimePointPost -1.5195 0.6369 -2.3860 0.0170334
binary_factor1 -1.3612 0.5707 -2.3854 0.0170603
binary_factor2 1.3575 0.5364 2.5306 0.0113864

日志（分散）参数：
  估计std.err
   -0.3555 0.4556

一体化：
方法：自适应高斯 - 高仪段规则
正交点：11

优化：
方法：混合EM和Quasi-Newton
融合：正确 


Exp（confint（mod））

                                    2.5％估计97.5％
（截距）1.84772708 5.1243512 14.2115012
TimePointPost 0.06280507 0.2188179 0.7623788
binary_factor1 0.08376849 0.2563429 0.7844442
binary_factor2 1.35812473 3.8863242 11.1208606
 
到目前为止，这一切似乎都是合理的。正如我阅读的那样，我们期望在TimePointPost，速率为0.219（21.9％）的时间点PRE。
 i然后计算边缘系数并指示以获取以下
  mod_marg_coef＆lt;  -  marginal_coefs（mod，std_errors = true，cores = 6）
mod_marg_coef
                               估计std.err z值p值
（截距）1.6788 13.7097 0.1225 0.902537
TimePointPost -1.5195 0.6595 -2.3041 0.021216
binary_factor1 -1.3620 0.8271 -1.6468 0.099598
binary_factor2 1.3549 0.8607 1.5742 0.115430

as.data.frame（mod_marg_coef $ coef_table）|＆gt;
  突变（发病率比&#39;= exp（估算），
         在（c（估算：“发病率比）”，〜圆（.x，4）），
         `p-value` = round（`p-value`，4））|＆gt;
  搬迁（“发病率比”）

                               发病率比估计std.err z值p值
（截距）5.3594 1.6788 13.7097 0.1225 0.9025
TimePointPost 0.2188 -1.5195 0.6595 -2.3041 0.0212
binary_factor1 0.2561 -1.3620 0.8271 -1.6468 0.0996
binary_factor2 3.8763 1.3549 0.8607 1.5742 0.1154
 
看起来时点的估计没有改变，但协变量确实如此。 为什么以前单身的p值成为ns？ 
现在，如果我尝试计算边缘系数的顺式，我会得到一些完全不合理的东西。这是我的过程或模型/数据的问题？
  exp（confint（mod_marg_coef）））

                                      2.5％97.5％
（截距）1.146499E-11 2.505284E+12
TimePointPost 6.008029E-02 7.969545E-01
Binary_Factor1 5.063973E-02 1.295633E+00
Binary_Factor2 7.175118E-01 2.094124E+01
 
 glmmadaptive v 0.9-7 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662349/how-to-calculate-a-95-ci-on-negative-binomial-marginal-coefficients-strange-re</guid>
      <pubDate>Sat, 08 Mar 2025 16:35:40 GMT</pubDate>
    </item>
    <item>
      <title>调整“赌注的轻松度”的布里尔分数</title>
      <link>https://stats.stackexchange.com/questions/662347/adjusting-brier-score-for-the-easiness-of-a-bet</link>
      <description><![CDATA[我正在研究一个依赖于评估歧管用户的预测能力的项目，该网站可以押注事件并赚钱。我计划将Brier分数用作预测技能的指标，但另一个用户指出，在预测市场的背景下，这是一个非常有偏见的分数，因为如果您参与重量达到0或100％的市场，那么您只能获得比仅参与接近50％的市场更好的得分。实际上，您可以随机翻转硬币并随机下注，但是如果您只赌注为1：9，您将获得一个很好的布里尔分数。 （请参阅完整交换
由于这个问题，我建议收集一个新变量，称为50％的平均距离。为了获取此变量，我已经编程了一个将每个下注的函数，将距离计算为
  $$
d = \ bigl（\ text {BET} -0.5 \ bigr）^2
$$  
然后，将所有BET的平均值计算为
  $$
\ text {平均距离50％} = \ frac {1} {n} \ sum_ {i = 1}^{n} d_i
$$  
我打算将此变量与我感兴趣的其他变量一起使用线性回归中的主持人变量（例如，哪些策略预报员使用），以便它充当控制变量。。
我试图枚举的预测技能应该接近“每个BET都以估计的方向解决的可能性有多大的可能性。” - 即“对积极结果的赌注有多少为是，以及有多少负面结果被解决为“否”。。
 我的问题是：这是否是通过线性回归建模预测技能（如上所述）和其他变量之间关系的合法方法？具体而言，控制平方距离从0.5适当地解释了布里尔分数的偏差（即由无关的因素引起的差异，主要是用户选择下注的BET的起始概率），还是我应该考虑不同的转换以更好地捕获BET的“极端”？&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt;
例如，由于布里尔分数是一种二次度量，并且由于以类似的方式计算变异，因此我认为平方距离捕获变异比绝对距离更好 - 但是作为心理学家，我对正确的统计方法非常不确定。 。]]></description>
      <guid>https://stats.stackexchange.com/questions/662347/adjusting-brier-score-for-the-easiness-of-a-bet</guid>
      <pubDate>Sat, 08 Mar 2025 15:51:27 GMT</pubDate>
    </item>
    <item>
      <title>计算高斯加权双积分的置信区间[重复]</title>
      <link>https://stats.stackexchange.com/questions/662346/computing-a-confidence-interval-for-a-gaussian-weighted-double-integral</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662346/computing-a-confidence-interval-for-a-gaussian-weighted-double-integral</guid>
      <pubDate>Sat, 08 Mar 2025 15:32:47 GMT</pubDate>
    </item>
    <item>
      <title>差异和指标与MLE的函数</title>
      <link>https://stats.stackexchange.com/questions/662344/variance-and-metrics-with-a-function-of-mle</link>
      <description><![CDATA[我有一个问题，即如果我已经估算了此参数的功能（由于数值目的，我使用logit函数），我有一个问题。例如，如果我有
 $$
f_x（x）= \ frac {1-p} { -  log（p）} \ frac {\ alpha（1- e^{ -  x \ lambda}）^{\ alpha-1} \ lambda e^{ -  x \ x \ lambda}} \ lambda}）^{\ alpha}}，\ quad x＆gt; 0; \ lambda，\ alpha＆gt; 0，
 p \ in（0,1）$$ 
而且我想使用 $ p^* = logit（p）\ rightarrow p = logit^{ -  1}（p^*）$ 。然后
 $$
f_ {x^*}（x）= \ frac {1-logit^{ -  1}（p^*）} { -  log（logit^{ -  1}（p^*））} \ frac {\ frac {\ alpha（1- e^{ -  x \ lambda}） \ lambda}}} {1-（1-logit^{ -  1}（p^*））（1-e^{ -  x \ lambda}）^{\ alpha}}，\ quad x＆gt; 0; \ lambda，\ alpha＆gt; 0，
 p^* \ in \ mathbb {r} $$ 
我的问题是：

如果我得到 $ \ hat {p}^*$ ，所以我也有 $ \ hat&gt; $ \ hat {p} $ 通过转换，我可以通过评估三个参数

  -solve（hessian（log_like_fx（hat_p，hat_lambda，hat_alpha）））））））
 
而不是
  -solve（hessian（log_like_fx*）（hat_p*，hat_lambda，hat_alpha）））））））
 

如果以前的问题是正确的，我可以从这里获得使用非反应可能性的BIC，AIC等常规指标吗？除了能够使用上一个代码的方差计算P值？

我的问题更专注于使用重新聚体估算参数是否合法，然后仅使用原始模型的日志可能性。注意：我假设数值方法不能很好地估算 $ P $ ，所以我想使用重新聚体化。
问候！]]></description>
      <guid>https://stats.stackexchange.com/questions/662344/variance-and-metrics-with-a-function-of-mle</guid>
      <pubDate>Sat, 08 Mar 2025 13:52:12 GMT</pubDate>
    </item>
    <item>
      <title>估计概率与原始二元结果的分段回归</title>
      <link>https://stats.stackexchange.com/questions/662340/segmented-regression-on-estimated-probabilities-vs-raw-binary-outcome</link>
      <description><![CDATA[我正在对R进行分段回归分析，并希望确认我的方法是否在统计上有效。我首先使用天然花键拟合逻辑回归模型来预测二进制结果。然后，我使用这些估计的概率作为结果估算了独立变量不同值的预测概率，并拟合了准级GLM。最后，我将分段（）函数应用于第二个模型，而不是原始的逻辑回归模型。这种方法是否有效，还是应使用原始二进制结果对初始模型进行分段回归？分割估计的概率会导致不正确的断点估计吗？
 库（dplyr）
图书馆（重量）
图书馆（钴）
图书馆（Marginaleffects）
图书馆（ggplot2）
图书馆（分段）

d＆lt;  -  my_dataset

d  $ binary_outcome＆lt;  - 因子（d $  binary_outcome）

fit＆lt;  -  glm（binary_outcome〜splines :: ns（x_axis_variable，df = 5，intercept = t），
           数据= D，
           family =“二项式”

values＆lt;  -  with（d，seq（d  $ x_axis_variable，na.rm = true）， 
                  max（d $  x_axis_variable，na.rm = true），
                      length.out = nrow（d）））

p＆lt;  -  avg_predictions（fit，
                     变量= list（x_axis_variable = values），
                     byfun =函数（...）qnorm（平均（...）），
                     变换= pnorm）

fit.lm＆lt;  -  glm（估计〜x_axis_variable，data = p，family = quasibinomial）

seg.fit＆lt;  - 分割（fit.lm，seg.z = 〜x_axis_variable，npsi = 1）

断点＆lt;  - 摘要（seg.fit）$ psi [，&#39;es; est。]
打印（断点）

ggplot（p，aes（x = x_axis_variable，y = estime）） +
  geom_point（alpha = 0.5）+
  ＃GEOM_RIBBON（AES（ymin = conf.low，ymax = conf.high），
  ＃alpha = .3，
  ＃fill =&#39;slategray＆quot”）+
  geom_line（aes（y = predict（seg.fit，type，type =＆quote; worlds; quots; quot; quot; quot; quot＆quot =; blue; blue; quot;） +
  geom_vline（Xintercept =断点，color =; red＆quord&#39;，lineType =; dashed＆quot;）
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662340/segmented-regression-on-estimated-probabilities-vs-raw-binary-outcome</guid>
      <pubDate>Sat, 08 Mar 2025 11:28:29 GMT</pubDate>
    </item>
    <item>
      <title>每组进行预测时是否需要归一化？</title>
      <link>https://stats.stackexchange.com/questions/662333/is-normalization-necessary-when-the-predictions-are-made-per-group</link>
      <description><![CDATA[作为ML的初学者，我正在观看
功能之一是历史参与数，例如视图/喜欢。
我不明白的是，面试官问，如果某些用户比其他用户比其他用户单击更多，因为他们通常更活跃，因为他们是点击器，他们点击了很多。并解释说，这就是为什么我们需要将点击标准化（例如，除以某些用户活动的总数）。
如果一个模型正在预测每个组，则预测是针对每个用户的歌曲。  那么您真的必须标准化吗？如果用户A有900个单击歌曲A和歌曲B的100次点击，而用户B有20个点击歌曲A，歌曲B的5次点击，则为歌曲C进行5次点击。归根结底，我们在每个用户之间决定不关心不同用户的歌曲。
，即使您要归一化，您也可以模拟歌曲A的用户为0.9，而歌曲B则为0.1，但用户B观看了3首歌曲，因此他的发行版本是0.6、0.2和0.2。。
标准化对您有何帮助？您仍然无法比较0.9和0.6。它们是每组最佳分数，但整个组仍然是无与伦比的。原始点击数与比率有何不同？
，但根据用户，就像原始数字一样，它可以获得最大的百分比。
所以我的意思是，当预测为每个组时，您需要正常化。您是否必须关心各组的比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/662333/is-normalization-necessary-when-the-predictions-are-made-per-group</guid>
      <pubDate>Fri, 07 Mar 2025 23:14:59 GMT</pubDate>
    </item>
    <item>
      <title>哪个更好 -  FDR或Holm -Bonferroni？</title>
      <link>https://stats.stackexchange.com/questions/662328/which-is-better-fdr-or-holm-bonferroni</link>
      <description><![CDATA[我正在用猴子进行听觉侧翼任务。它是一个受试者内部设计，有4个（6个）受试者，有4个条件。我想在运行单向RM ANOVA后进行成对比较。 Bonferroni被证明是非常保守的。我看着替代方案，罗姆和霍尔姆出现了。两者都给出不同的结果。哪一个对我的数据集更好？是否有一个在认知心理学中比其他人更好地接受的？]]></description>
      <guid>https://stats.stackexchange.com/questions/662328/which-is-better-fdr-or-holm-bonferroni</guid>
      <pubDate>Fri, 07 Mar 2025 21:18:20 GMT</pubDate>
    </item>
    <item>
      <title>初学者：确定数据组是否在统计上相似</title>
      <link>https://stats.stackexchange.com/questions/662323/beginner-determining-whether-data-groups-are-statistically-similar</link>
      <description><![CDATA[我是统计数据的新手，并且具有岩石孔隙率的数据集1）使用三种不同的方法，2）来自两种不同的岩石类型。我正在尝试评估1）三种方法是否产生可比的结果，2）如果两种岩石类型在统计上相似。
这三种方法的数据如下（单位=％）：
  method_a = [17.6，19.3，18.7，28.0，25.8，17.1，18.5]
method_b = [17.6，17.0，18.3，11.1，12.5，16.6，15.3，8.4，15.8，14.9，11.6，9.0，9.0，6.4，9.6]
method_c = [11.1、10.9、9.7、7.8、0.9、11.2、11.0、12.5、14.0、8.3、9.9、9.9、6.9、6.9、8.4、0.4、0.9、0.8]
 
通过岩石类型分离的方法A和B的数据如下（方法C是故意的）：
  rock_a = [17.6，19.3，18.7，28.0，25.8，17.6，17.0，18.3，11.1，12.5，16.6，15.3]）
rock_b = [17.1，18.5，8.4，15.8，14.9，11.6，9.0，6.4，9.6））
 
排除方法C，这是根据所有三个变量列出的数据：岩石类型，方法和孔隙率。请注意，只有2个用method_a测量的rock_b样本。
 


样本
 rock_type 
方法
孔隙率（％）




 1 
 rock_a 
 method_a 
 17.6 


 2 
 rock_a 
 method_a 
 19.3 


 3 
 rock_a 
 method_a 
 18.7 


 4 
 rock_a 
 method_a 
 28.0 


 5 
 rock_a 
 method_a 
 25.8 


 6 
 rock_a 
 method_b 
 17.6 


 7 
 rock_a 
 method_b 
 17.0 


 8 
 rock_a 
 method_b 
 18.3 


 9 
 rock_a 
 method_b 
 11.1 


 10 
 rock_a 
 method_b 
 12.5 


 11 
 rock_a 
 method_b 
 16.6 


 12 
 rock_b 
 method_a 
 17.1 


 13 
 rock_b 
 method_a 
 18.5 


 14 
 rock_b 
 method_b 
 15.3 


 15 
 rock_b 
 method_b 
 8.4 


 16 
 rock_b 
 method_b 
 15.8 


 17 
 rock_b 
 method_b 
 14.9 


 18 
 rock_b 
 method_b 
 11.6 


 19 
 rock_b 
 method_b 
 9.0 


 20 
 rock_b 
 method_b 
 6.4 


 21 
 rock_b 
 method_b 
 9.6 


 
 基于此数据，我应该使用哪些测试来确定这些组在统计上是相似的还是不同的？ 
我以为这是不正确的，但是要了解我的头部的位置，这是我第一次通过的事情：

我使用shapiro-wilk测试来评估每组的正态性。
我使用莱文的测试评估群体之间的差异同质性。
对于方法，我使用了Kruskal-Wallis检验，因为仅方法B是正态分布的。但是，所有组都基于上述测试都具有相似的差异。
对于岩石类型，我使用了学生的t检验，因为两者都是正态分布的，并且基于上述测试具有相似的差异

任何帮助将不胜感激。外行语言是首选，但行话也可以，因为我会尽力研究和理解所有建议。
编辑：添加了代码示例以使数据更可读。
编辑：添加了一个结合岩石类型和方法的表。]]></description>
      <guid>https://stats.stackexchange.com/questions/662323/beginner-determining-whether-data-groups-are-statistically-similar</guid>
      <pubDate>Fri, 07 Mar 2025 17:18:30 GMT</pubDate>
    </item>
    <item>
      <title>如何根据观察到的复合等待时间和协变量来估计和预测潜在事件的活动时间？</title>
      <link>https://stats.stackexchange.com/questions/662317/how-to-estimate-predict-time-to-event-for-latent-events-based-on-observed-comp</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662317/how-to-estimate-predict-time-to-event-for-latent-events-based-on-observed-comp</guid>
      <pubDate>Fri, 07 Mar 2025 14:06:28 GMT</pubDate>
    </item>
    <item>
      <title>Mixt Ancova的零假设是什么？</title>
      <link>https://stats.stackexchange.com/questions/662348/what-are-the-null-hypothesis-for-a-mixt-ancova</link>
      <description><![CDATA[我的问题很简单，但是我自己找不到答案。对于固定效果，H0将是以下内容：

所有定性变量级别的平等
定量和响应变量之间没有线性关系
对于定性变量的所有级别，定量变量与响应变量之间的相关性相同

所以我想对于混合效应，前两个假设成为：

随机效应（σ²= 0）的水平之间没有可变性
定量和响应变量之间没有线性关系

但是我不知道第三是什么？  很抱歉我的英语不好。]]></description>
      <guid>https://stats.stackexchange.com/questions/662348/what-are-the-null-hypothesis-for-a-mixt-ancova</guid>
      <pubDate>Fri, 07 Mar 2025 10:43:51 GMT</pubDate>
    </item>
    <item>
      <title>R中有没有办法测试COX模型回归系数的时间变化功能形式的优点？</title>
      <link>https://stats.stackexchange.com/questions/662228/is-there-a-way-in-r-to-test-the-goodness-of-my-time-varying-functional-form-for</link>
      <description><![CDATA[如果我适合像这样的Cox模型
  m＆lt;  -  coxph（surv（surv（time，status）〜x + x + tt（x），tt = function（x，x，t，…）x*g（t））
 
我怎么知道我选择 g（t）（也可能是花键）很好？
我的两个猜测是

在cox.zph的转换参数中使用相同的 g（t）
使用 survsplit（），使用 i（x*g（time））将我的数据集的长期版本拟合，然后用cox.zph 检查测试

我不确定其中两个。因为在1中。我只是在修改残差图的时间尺度，而在2中。我真的不明白测试的内容。
有什么建议吗？
检查 g（t）是否使用（说）p-splines时调整非比例性？是否有用？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662228/is-there-a-way-in-r-to-test-the-goodness-of-my-time-varying-functional-form-for</guid>
      <pubDate>Wed, 05 Mar 2025 11:38:43 GMT</pubDate>
    </item>
    <item>
      <title>计算高斯加权积分的置信区间</title>
      <link>https://stats.stackexchange.com/questions/662082/computing-a-confidence-interval-for-a-gaussian-weighted-integral</link>
      <description><![CDATA[ 要求：提供 $ 96 \％$   $ i = \ int&gt; $ i = \ int _ { -  \ infty}^\ int&gt; $  

我使用数值集成（例如，蒙特卡洛集成）来近似 $i。$  
这是我可以使用蒙特卡洛集成的方式：

从合适的分布中生成大量随机样本（ $ x_i $ ）（例如，具有较大标准偏差的正态分布）。
计算函数值 $ e^{ -  x^2} \ vert \ sin x \ vert $  for for每个样本。
通过获取这些函数值的平均值来估算积分。
多次重复该过程以获取积分估计的样本。

 导入numpy作为NP
导入scipy，集成为集成

def Integrand（x）：
    返回np.exp（-x ** 2）*np.abs（np.sin（x））

＃使用scipy.integrate.quad的数值集成
结果，错误= Integrate.quad（intemand，-np.inf，np.inf）
打印（f＆quot“数值集成结果：{result};）

＃蒙特卡洛整合
def monte_carlo_integral（num_samples）：
    samples = np.random.normal（0，5，num_samples）＃根据需要调整标准偏差
    function_values = Integrand（样本）
    返回np.mean（function_values）*np.sqrt（2*np.pi）*5＃基于标准偏差调整乘数。

num_iterations = 1000
num_samples = 10000
估计= [range（num_iterations）i的i的monte_carlo_integral（num_samples）]

Mean_estimate = np.mean（估计）
std_estimate = np.std（估计）

打印（f＆quot“蒙特卡洛均值估计：{mean_estimate}＆quot”）
打印（f＆quot“蒙特卡洛标准偏差估计：{std_estimate}”
 

目前，我有$ i $的估算样本。
我可以使用此样本来计算置信区间。
由于我的迭代次数相当多（$ 1000 $），因此我可以使用正常分布来近似置信区间。
置信度水平：96％。
 Z得分具有96％的信心：

找到对应于（1 + 0.96） / 2 = 0.98的z得分。&lt; / li&gt;
使用z表或计算器，z得分约为2.05。


错误的边距（ e ）： 置信区间：（ mean_estimate-  e ，mean_estimate +  e ）

  z_score = 2.05
margin_of_error = z_score *（std_estimate / np.sqrt（num_iterations））
profels_interval =（mean_estimate -margin_of_error，mean_estimate + margin_of_error）

打印（f＆quot; 96％置信区间：{profors_interval}＆quot;）
 

目前，我不知道如何在数学上解决这个问题，所以我希望任何人都可以支持我分析它。]]></description>
      <guid>https://stats.stackexchange.com/questions/662082/computing-a-confidence-interval-for-a-gaussian-weighted-integral</guid>
      <pubDate>Sun, 02 Mar 2025 07:58:42 GMT</pubDate>
    </item>
    <item>
      <title>预测产品错误</title>
      <link>https://stats.stackexchange.com/questions/661523/error-of-product-of-predictions</link>
      <description><![CDATA[Suppose that we have two regression models $A$ and $B$ that predict values $\hat{a}$ and $\hat{b}$ but that we ultimately are interested in their product  $ \ hat {a} \ hat {b} $ （例如，我们可能会预测销售和销售量的数量，但最终对总销售感兴趣）。现在，我们可以观察 $ a $ ， $ b $  and  $ ab $  $ ab $ ，并计算每个模型
是否有一种方法可以分解产品的误差，以便我们可以理解它是否是模型 $ a $ 或模型 $ b $ 正在驱动错误？例如，假设我们为产品计算MSLE，并发现它比预期的要大，我们如何知道此错误是否来自 $ a $ 或 $ b $ ？？？]]></description>
      <guid>https://stats.stackexchange.com/questions/661523/error-of-product-of-predictions</guid>
      <pubDate>Tue, 18 Feb 2025 10:26:05 GMT</pubDate>
    </item>
    </channel>
</rss>