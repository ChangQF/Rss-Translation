<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 02 Jan 2024 09:14:09 GMT</lastBuildDate>
    <item>
      <title>分位数时间序列预测如何工作？</title>
      <link>https://stats.stackexchange.com/questions/635992/how-do-quantile-time-series-forecasts-work</link>
      <description><![CDATA[我的办公室领导有兴趣采用“分位数时间序列预测”，其想法是查询模型，根据给定的特征（例如先前的观察结果、协变量等）来预测 RV 的第 5、25、50、75 和 95 个百分位数。&lt; /p&gt;
我的问题是关于可行性的：是否有 x 个独立的模型，每个分位数一个？训练数据从哪里来？ （例如：在 t 天仅售出了 x 件商品，因此没有观察到分布……）]]></description>
      <guid>https://stats.stackexchange.com/questions/635992/how-do-quantile-time-series-forecasts-work</guid>
      <pubDate>Tue, 02 Jan 2024 08:20:32 GMT</pubDate>
    </item>
    <item>
      <title>关于最大方差准则内部工作原理的问题</title>
      <link>https://stats.stackexchange.com/questions/635991/a-queston-regarding-the-inner-workings-of-the-varimax-criterion</link>
      <description><![CDATA[最大方差准则最大化高值和低值因子载荷并最小化中值因子载荷，以实现其目标函数的最大值。我想问：这样做如何确保varimax准则是最大值？换句话说，拥有一些高极值和许多接近于零的中间值如何有助于实现这一目标？我们如何确定以这种特定方式而不是任何其他方法进行操作会产生标准的最高可能值？有什么证据可以告诉我们这一点吗？有人可以用简单的数字方式证明这一点吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635991/a-queston-regarding-the-inner-workings-of-the-varimax-criterion</guid>
      <pubDate>Tue, 02 Jan 2024 07:53:14 GMT</pubDate>
    </item>
    <item>
      <title>通过不同的努力来估算 CPUE 时间序列数据中的缺失值</title>
      <link>https://stats.stackexchange.com/questions/635990/imputing-missing-values-in-cpue-time-series-data-with-varying-effort</link>
      <description><![CDATA[我有一个数据集，其中包含用于捕获下游迁徙个体的陷阱中几年的鱼类计数。陷阱通常每天清空，但有时间隔时间较长（2-6 天）。我将采样之间的这个间隔称为“捕获周期”。我预计所有向下游移动的鱼都会被捕获，没有一个能逃脱陷阱。示例数据：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

日
计数
n天
环境1
环境2


&lt;正文&gt;

1
1
1
5.6
1.2


2
3
1
5.5
1.3


4
11
2
5.8
1.9


5
7
1
6.0
1.8


6
23
1
6.2
1.9


8
43
2
6.3
1.9


9
31
1
6.5
1.5


10
11
1
7.1
1.2


12
7
2
7.5
0.9


15
5
3
7.7
0.8




Day = 从诱捕季节开始算起的天数；
计数 = 第 n 天陷阱中的鳗鱼数量；
nDays＝诱捕期的长度(即“努力”)；
Env1, Env2, ... = 捕获期间环境变量的平均值。
我对不同的环境变量（例如流量、温度、气压等）如何影响每日捕获的鱼的数量感兴趣。我想到只使用一组候选模型中捕获期间环境变量的平均值来解释 CPUE，而不考虑数据的时间方面，包括作为偏移量的捕获期间（工作量）。这被证明是一种非常好的方法，因为模型表现良好，但完全忽略了计数之间的时间自相关性，从目视检查数据来看，这似乎很有可能，而且也具有生物学意义。所以我一直在尝试找到一种方法来将其作为时间序列数据进行分析。
所以我的问题是：对于我来说，估算持续超过 1 天的捕获期的缺失计数的最佳方法是什么？您认为在这种方法中我应该注意哪些注意事项？]]></description>
      <guid>https://stats.stackexchange.com/questions/635990/imputing-missing-values-in-cpue-time-series-data-with-varying-effort</guid>
      <pubDate>Tue, 02 Jan 2024 07:32:54 GMT</pubDate>
    </item>
    <item>
      <title>如何在自然语言处理中将相似词重命名为基本词？</title>
      <link>https://stats.stackexchange.com/questions/635989/how-to-rename-similar-words-to-base-word-in-natural-language-processing</link>
      <description><![CDATA[我的数据包含多个具有相同含义的单词。例如java脚本、javascripting、java脚本。我想将它们重命名为一个基本词：Javascript。我怎样才能做到这一点？使用Python编程语言。]]></description>
      <guid>https://stats.stackexchange.com/questions/635989/how-to-rename-similar-words-to-base-word-in-natural-language-processing</guid>
      <pubDate>Tue, 02 Jan 2024 06:37:50 GMT</pubDate>
    </item>
    <item>
      <title>如果使用多种不同方法确定年龄，您能否创建人口年龄结构？</title>
      <link>https://stats.stackexchange.com/questions/635983/can-you-create-an-age-structure-of-population-if-the-age-was-established-using</link>
      <description><![CDATA[我想分析样本的年龄结构。然而，我并没有给出年龄本身，而是必须使用具有不同确定系数的多种方法来确定它们（并非每种方法都可以用于每个分析样本），其中一些方法运行两次以检查其可重复性。
因此，对于每个人，我通过不同的方法有不同的估计年龄，如下图所示：

由于存在多个值，我不确定如何创建年龄结构，因为一些结果显示一个人的可能年龄范围超过二十岁。我很确定你不能只平均年龄，因为这些是不同的方法，具有不同的决定系数。
有人可以给我这方面的建议吗？您会尝试从所有方法中创建一个年龄估计，创建重叠的类别还是以完全不同的方式进行？]]></description>
      <guid>https://stats.stackexchange.com/questions/635983/can-you-create-an-age-structure-of-population-if-the-age-was-established-using</guid>
      <pubDate>Tue, 02 Jan 2024 02:26:29 GMT</pubDate>
    </item>
    <item>
      <title>为什么attention中卷积层的最大路径长度$O(n/k)$就足够了？</title>
      <link>https://stats.stackexchange.com/questions/635979/why-is-the-maximum-path-length-for-convolutional-layer-on-k-in-attention-is</link>
      <description><![CDATA[在表 1 第三行中提到了这一点。为什么是$O(n/k)$？以 9 个标记中的 2 个标记的 1d 卷积为例，步长 $1$。它不会是 $n/k$ 或 $9/2=4.5$ 而是大约$n-1$ 或 $8$。
这篇论文没有提到跨步，所以我认为它适用于任何跨步。
来自论文：（链接）
内核宽度 k &lt; 的单个卷积层n 不连接所有输入输出对
职位。 在连续内核的情况下，这样做需要一堆 O(n/k) 卷积层，
或 O(logk(n)) 在扩张卷积的情况下 [18]，]]></description>
      <guid>https://stats.stackexchange.com/questions/635979/why-is-the-maximum-path-length-for-convolutional-layer-on-k-in-attention-is</guid>
      <pubDate>Mon, 01 Jan 2024 23:33:15 GMT</pubDate>
    </item>
    <item>
      <title>通过残差平方回归估计方差</title>
      <link>https://stats.stackexchange.com/questions/635974/estimating-variance-by-regressing-squared-residuals</link>
      <description><![CDATA[对于线性回归，估计新观测值的预测范围的一种方法是计算新观测值的预测区间。
如果将残差平方相对于初始预测变量进行回归会怎样？这是估计新观察方差的另一种方法吗？如果不是，那么回归实际预测的是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/635974/estimating-variance-by-regressing-squared-residuals</guid>
      <pubDate>Mon, 01 Jan 2024 19:44:39 GMT</pubDate>
    </item>
    <item>
      <title>梯度下降的反向传播是否使用损失相对于权重的梯度来更新权重和偏差？</title>
      <link>https://stats.stackexchange.com/questions/635966/does-back-propagation-with-gradient-descent-update-the-weights-and-biases-using</link>
      <description><![CDATA[我绝对是这个领域的初学者。目前正在Andrew Ng的指导下学习Course时代的监督机器学习。我已经进入该续集第二门课程的第二周了。
我实际上对反向传播感到困惑。我了解反向传播的理论知识，它基本上是微分的链式法则，并存储中间导数以查找先验导数，与传统过程相比，这节省了很多更少的迭代和时间。但我无法完全理解反向传播如何集成到梯度下降中。
让我详细阐述一下我的困惑，然后我希望你能明白我所陷入的困境。
假设网络中有 1 个隐藏层。所以总共有 3 层：初始层、隐藏层和最终层。我知道这里我们分配随机权重和偏差。但是我们如何评估梯度下降呢？我的意思是，在线性回归的情况下，我们已经看到权重和偏差随着学习率和成本函数导数相对于权重/偏差的关联而变化。$$w_1 = w_1- \alpha*\frac{d}{dw_1}J$$ 其中 J 是成本函数。神经网络也会发生同样的事情吗？
我的意思是 $$w^3 = w^3 - \alpha*\frac{d}{dw^3}J$$$$w^2_n = w^2_ n - \alpha*\frac{d}{dw^2_n}J$$ 其中 $w^ 3=&gt;$第三层的权重和$w^2_n=&gt;$第二层第n个单元的权重]]></description>
      <guid>https://stats.stackexchange.com/questions/635966/does-back-propagation-with-gradient-descent-update-the-weights-and-biases-using</guid>
      <pubDate>Mon, 01 Jan 2024 15:58:27 GMT</pubDate>
    </item>
    <item>
      <title>与协方差矩阵相关的术语“球形”的起源？</title>
      <link>https://stats.stackexchange.com/questions/635834/origin-of-the-term-spherical-in-relation-to-covariance-matrices</link>
      <description><![CDATA[据我了解，所有对角线元素相等且所有非对角线元素也相等（但与对角线元素不同）的协方差矩阵称为“球形”。我很好奇这个词的由来。据推测它有几何解释。是不是就意味着对于一个球体来说，从中心到表面上任意点的距离都相等那么简单？这是否也意味着表面上的点分布是均匀的？]]></description>
      <guid>https://stats.stackexchange.com/questions/635834/origin-of-the-term-spherical-in-relation-to-covariance-matrices</guid>
      <pubDate>Fri, 29 Dec 2023 17:42:30 GMT</pubDate>
    </item>
    <item>
      <title>计算固定 AR(1) 过程的十分位数之间移动的份额</title>
      <link>https://stats.stackexchange.com/questions/635806/compute-share-moving-between-deciles-of-a-stationary-ar1-process</link>
      <description><![CDATA[我想计算从十分位数 $i$ 移动的概率 $P_{ij}$在一个周期内对 $j$ 进行十分之一 在下一周期内平稳 AR(1) 过程的分布
$$Y_t = \rho Y_{t - 1} + \upsilon_t,$$
其中 $\upsilon_t$ 是独立同分布。分布冲击 $N(0, \sigma^2)$ 和 $|\rho| &lt; 1 美元。 $Y$ 的平稳分布由下式给出 $N(0, \tau^2)$，其中 $\tau \equiv \sigma / \sqrt{1 - \rho^2}$.
下面的表达式是我应该尝试计算的吗？或者有更直接的方法吗？
\begin{align}
P_{ij}
&amp;= \int_{(i - 1) / 10}^{i / 10} \underbrace{\Pr\biggl(\Phi^{-1}\left(\frac{j - 1}{10}\right) ) \leq \frac{Y_t}{\tau} &lt; \Phi^{-1}\left(\frac{j}{10}\right)\biggr)}_{\text{移动到十分位的概率 $ j$ 在时间 $t$}} \underbrace{\frac{\phi\left(\Phi^{-1}(x)\right)}{0.1}}_{\substack{\text{十分位数份额 $ i$} \\[0.5ex] \text{在时间 $t - 1$}}} d x,
\end{对齐}
其中 $\Phi^{-1}$ 是标准正态变量的逆累积分布函数，$\phi$ 它的概率密度函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/635806/compute-share-moving-between-deciles-of-a-stationary-ar1-process</guid>
      <pubDate>Fri, 29 Dec 2023 09:28:18 GMT</pubDate>
    </item>
    <item>
      <title>使用逻辑回归系数为 VTT 计算提供 95% 置信区间</title>
      <link>https://stats.stackexchange.com/questions/610592/providing-95-confidence-intervals-for-vtt-calculation-using-logistic-regression</link>
      <description><![CDATA[我很高兴有人提出并回答了类似的问题，但我认为我的情况有本质上的不同，因为系数的具体解释不相关。
我有一组选择实验结果，用于计算参与者的“旅行时间评估”。执行此操作的标准流程是根据某人是否接受特定出行时间的特定补偿水平的结果来拟合逻辑回归模型。然后，您可以将时间系数除以补偿系数，以生成行程时间的评估（如果没有意义，请不要担心）。因此对于以下模型：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

术语
估计
标准错误
z值
p值


&lt;正文&gt;

（拦截）
1.256319853
0.1096819372
11.45420919
2.24E-30


时间
0.1015354957
0.003527728861
-28.78211442
3.59E-182


比较
0.1532430136
0.005337402709
28.7111582
2.77E-181




“VTT”（大约）为 0.102/0.153 - 即每分钟 0.67 英镑，或每小时 40 英镑。
我想为此估值提供 95% 的置信区间，并且我一直在寻找正确的方法。我的直觉是它只是：
上限：time_coef + 1.96time_SE / comp_coef - 1.96comp_SE
下限：time_coef - 1.96time_SE / comp_coef + 1.96comp_SE
如果没有详细了解 VTT 方法，这看起来正确吗？
编辑 - 根据有用的反馈，如果其他人能够使用此数据来帮助我验证我是否使用了正确的方法，我可以包含协方差表。

&lt;表类=“s-表”&gt;
&lt;标题&gt;


（拦截）
时间
比较


&lt;正文&gt;

（拦截
1.203013e-02
-1.265604e-04
9.785909e-06


时间
-1.265804e
1.244487e-05
-1.437472e-05


比较
9.785909e-06
-1.437472e-05
2.848787e-05



]]></description>
      <guid>https://stats.stackexchange.com/questions/610592/providing-95-confidence-intervals-for-vtt-calculation-using-logistic-regression</guid>
      <pubDate>Fri, 24 Mar 2023 14:50:50 GMT</pubDate>
    </item>
    <item>
      <title>两个单边 t 检验 (TOST) 的置信水平和 alpha</title>
      <link>https://stats.stackexchange.com/questions/587079/confidence-level-and-alpha-with-two-one-sided-t-tests-tost</link>
      <description><![CDATA[我正在进行一项非劣效性研究：两组完成一项测试（可能得分为 0-30 分）。我已经有了B组的测试结果。我想使用两个单边 t 检验 (TOST) 来调查 A 组的表现是否不劣于 B 组。
我选择了 alpha=5% 和 95% CI。为了实现这一点，使用 TOST，我必须指定 90% CI / alpha=10%。评估非劣效性时，我只会查看较低的 CI，因此，我的两侧 90% CI 将对应于一侧 95%（且 alpha=5%）。
我的问题是：1）这理解正确吗？如果是这样：2）我将如何正确地表述这一点？我最初的想法是这样的：“双边 90% CI，alpha=0.10，对应于单边 95% CI，alpha=0.05）。
感谢您的宝贵时间。]]></description>
      <guid>https://stats.stackexchange.com/questions/587079/confidence-level-and-alpha-with-two-one-sided-t-tests-tost</guid>
      <pubDate>Mon, 29 Aug 2022 09:42:52 GMT</pubDate>
    </item>
    <item>
      <title>当元素的大小及其位置都很重要时向量的损失函数</title>
      <link>https://stats.stackexchange.com/questions/566926/loss-function-for-vectors-when-magnitude-of-elements-and-their-position-are-both</link>
      <description><![CDATA[上下文：
我正在使用变压器进行时间序列预测。
目标张量和预测张量的大小均为 (8, 10, 181)，表示（batch_size、预测数量、向量中的元素数量），其中最后一个维度是表示能量分布的 181 元素向量角度范围为 0-180。它基本上是 180 度范围内能量分布的热图。本系列中的每个时间戳都有一个与其关联的热图向量。
如果目标向量为 [0, 0, 1, 0, 0]，则从以下两个预测向量中，第一个向量比第二个向量与目标更“相似”。
第一个预测--&gt; [0, 1, 0, 0, 0]
第二次预测--&gt; [1, 0, 0, 0, 0]
实际的向量如下所示：
&lt;预&gt;&lt;代码&gt;0.27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0, 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0, 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0, 0.0,0.0,0.0,0.0,0.0,0.0,-27.858261076760662,-11.692805944935555,0.0,0.0


虽然这里的向量是稀疏的，但根据能量的分布方式，情况可能并不总是如此。此外，我发现变压器的初始预测几乎所有元素都包含非零值。
预测向量和目标向量在大小和位置方面需要相似，以便模型能够预测时间序列中未来时间戳的热图。
点积、余弦相似度和 MSE 不适用于此用例
我在自定义损失函数中使用了 MSE 损失和余弦相似度的组合，如下所示，其目标是最小化 MSE 损失并最大化余弦相似度。进行累积和运算是为了帮助计算余弦相似度。
导入火炬
将 torch.nn 导入为 nn


类 Custom_Loss(nn.Module):
    ”“”
    包含自定义损失函数的实现的类。
    ”“”

    # 将余弦相似度和 MSE 定义为类变量。
    cos = nn.CosineSimilarity(dim=-1) # Dim = -1 作为我们的张量 (batch_size, preds, len_heatmap)
    mse = torch.nn.MSELoss()

    def __init__(self) -&gt;; __init__(self) -&gt;没有任何：
        ”“”
        custom_loss 类的构造函数
        ”“”
        super(Custom_Loss, self).__init__()
    
    defforward（自身，预测，目标）：
        ”“”
        结合余弦相似度的自定义损失函数
        和 MSE 为：
        损失 = (w1 * MSE 损失) / (w2 * 余弦相似度)

        其中： MSE 和 COS_SIM 的平均值在 length=no_of_preds 上使用。
        ”“”

        # 定义 Cos 和 MSE 函数的权重。
        w1 = 1
        w2 = 10
        
        # 对两个张量应用累积和并计算损失。
        cos_sim = torch.abs(self.cos(torch.cumsum(预测, 暗淡=-1), torch.cumsum(目标, 暗淡=-1))).mean()
        mse_loss = self.mse(torch.cumsum(预测, dim=-1), torch.cumsum(目标, dim=-1))
        损失 = (w1 * mse_loss) / (w2 * cos_sim)
        回波损耗

问题：
在尝试基于此损失函数训练变压器后，我发现训练损失很高但不断下降，而验证损失在整个训练过程中仍然很高。改变批量大小和学习率也没有改变任何事情。
问题：

这样写有什么缺陷吗？
这是为上述目标编写损失函数的合理方法吗？
当我执行 loss.backward() 时，autograd 能够使用它吗？
最后，对于我描述的模型/用例，这是一个足够好的损失函数吗？也欢迎任何有关更好的损失函数的建议。
]]></description>
      <guid>https://stats.stackexchange.com/questions/566926/loss-function-for-vectors-when-magnitude-of-elements-and-their-position-are-both</guid>
      <pubDate>Mon, 07 Mar 2022 05:41:28 GMT</pubDate>
    </item>
    <item>
      <title>哪个 DAG 可以解释 NBA 球员身高和表现之间缺乏相关性？</title>
      <link>https://stats.stackexchange.com/questions/534094/which-dag-would-explain-the-lack-of-correlation-between-height-and-performance-i</link>
      <description><![CDATA[“选择偏差”的典型例子涉及观察职业篮球运动员的表现。举个例子，在 NBA 球员中，身高和表现之间没有相关性。
显然这不能一概而论“对于所有球员来说，身高与是否擅长篮球没有关系”，只是当你被选中为NBA效力时，其他特征更加重要。
我似乎无法通过 DAG 来解释这一点。我或多或少地想出了这个结构：

但我似乎很清楚，这里修复了“为 NBA 效力”的值设置为 TRUE 不会使身高与表现无关。是不是说明DAG的结构是错误的呢？或者有没有更好的方法来表现这种选择偏差？]]></description>
      <guid>https://stats.stackexchange.com/questions/534094/which-dag-would-explain-the-lack-of-correlation-between-height-and-performance-i</guid>
      <pubDate>Sat, 10 Jul 2021 16:18:08 GMT</pubDate>
    </item>
    <item>
      <title>报告 glmer.nb - F 统计的自由度？</title>
      <link>https://stats.stackexchange.com/questions/493048/report-glmer-nb-degrees-of-freedom-for-the-f-statistics</link>
      <description><![CDATA[到目前为止，我安装了一个 glmer.nb 模型用于计数数据，并希望报告结果。在一些论文中，我将 F 统计量视为一个选项 - 但在这里我不确定自由度，因为通常 F 统计量的报告形式为 F（回归 df，残差 df）= F 值，p），但是为此，人们似乎只报告一种自由度值。有谁知道如何解释这个值以及在哪里获取 glmer.nb() 模型的值，因为我的模型方差表给出了固定效应 A、B、C，如下所示：
方差分析表
         npar Sum Sq Mean Sq F 值
2 12.690 6.345 6.3448
B 1 94.272 94.272 94.2717
C 1 10.821 10.821 10.8212

我想报告 A 的 F 值和 P 值]]></description>
      <guid>https://stats.stackexchange.com/questions/493048/report-glmer-nb-degrees-of-freedom-for-the-f-statistics</guid>
      <pubDate>Wed, 21 Oct 2020 16:24:47 GMT</pubDate>
    </item>
    </channel>
</rss>