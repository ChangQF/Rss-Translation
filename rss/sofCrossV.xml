<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 06 Mar 2024 06:19:13 GMT</lastBuildDate>
    <item>
      <title>随机化问题/危机</title>
      <link>https://stats.stackexchange.com/questions/641934/randomisation-issue-crisis</link>
      <description><![CDATA[我使用随机化辅助工具将其随机分为三组，并在 2 个时间点对各组进行了检查。然而，分析发现其中一组的基线存在显着差异。数据呈正态分布，根据研究的进行方式，在给予干预之前没有检测到这种差异。我已经使用ANCOVA来控制这个问题是否足够？有人问我为什么不重新随机]]></description>
      <guid>https://stats.stackexchange.com/questions/641934/randomisation-issue-crisis</guid>
      <pubDate>Wed, 06 Mar 2024 06:13:21 GMT</pubDate>
    </item>
    <item>
      <title>使用损失作为衡量标准？</title>
      <link>https://stats.stackexchange.com/questions/641933/on-using-the-loss-as-a-metric</link>
      <description><![CDATA[上下文是监督学习中的模型评估。我有数值优化背景。对我来说，使用模型的损失（我们在训练期间优化的损失）作为评估指标是很自然的。
然而，这似乎并不常见，数据科学家使用各种指标，通常与原始损失相差甚远。
最重要的是，标准损失（MSE/对数损失）具有各种良好的属性（通常是可导出的，是二元分类的正确评分规则......等）。因此，特别不清楚选择其他东西会得到什么。
所以我想知道是否有任何可靠的来源来说明使用/不使用原始损失作为指标的利弊？]]></description>
      <guid>https://stats.stackexchange.com/questions/641933/on-using-the-loss-as-a-metric</guid>
      <pubDate>Wed, 06 Mar 2024 06:00:34 GMT</pubDate>
    </item>
    <item>
      <title>虚假因果关系？</title>
      <link>https://stats.stackexchange.com/questions/641932/spurious-causation</link>
      <description><![CDATA[我目前对相关性与相关性感兴趣。因果关系讨论。
我知道相关性可能是虚假的（请参阅虚假相关性网站）。
但是，由于因果关系是从统计中推断出来的，那么因果关系是否也有可能是虚假的？我一般应该如何解释？]]></description>
      <guid>https://stats.stackexchange.com/questions/641932/spurious-causation</guid>
      <pubDate>Wed, 06 Mar 2024 05:28:16 GMT</pubDate>
    </item>
    <item>
      <title>将时刻与 OLS 相关</title>
      <link>https://stats.stackexchange.com/questions/641931/relating-moments-to-ols</link>
      <description><![CDATA[我正在尝试了解 OLS 和矩量法之间的关系。
矩方程：对于离散随机变量和以某个点“c”为中心的连续随机变量：
$$E[(X-c)^n] = \sum_{x \in X} (x-c)^n \cdot P(X=x)$$
$$E[(X-c)^n] = \int_{-\infty}^{\infty} (x-c)^n f(x) dx$$
矩量法：对于分布已定义的总体中的 $X_1, X_2, ..., X_n$通过一些参数 $\theta_1, \theta_2, ..., \theta_p$，$\ 的矩估计器方法theta_i$ 是通过将 $i^{th}$ 样本矩设置为等于 $i^ 来获得的{th}$ 人口矩，并求解 $\theta_i$（对于 $i = 1, 2 , ..., p$。）：
$$\frac{1}{n}\sum_{j=1}^{n}X_j^i = E[X^i]$$ 
力矩条件：在应用意义上（用于估计），我们将理论力矩等同于基于力矩条件的应用力矩。例如，如果 $X$ 遵循均值 $\mu$ 和方差 $\sigma^2$，此时条件为：
$$E[X] = \mu$$
$$E[(X-\mu)^2] = \sigma^2$$
OLS 回归：这是我对 OLS 的基本总结 [$(y - X\beta)^T(y - X\beta)$&lt; /span&gt; 是表示误差平方和的矩阵方式]：
$$y = X\beta + \epsilon$$
$$\hat{\beta} = \arg\min_{\beta} (y - X\beta)^T(y - X\beta)$$
$$\frac{\partial}{\partial \beta} (y - X\beta)^T(y - X\beta) = 0$$
为了解决这个问题，我们可以这样写：
$$f(\beta) = (y - X\beta)^T(y - X\beta) = y^Ty - \beta^TX^Ty - y^TX\测试版+\测试版^TX^TX\测试版$$
$$f(\beta) = y^Ty - 2\beta^TX^Ty + \beta^TX^TX\beta$$
$$\frac{\partial f(\beta)}{\partial \beta} = -2X^Ty + 2X^TX\beta$$
$$-2X^Ty + 2X^TX\beta = 0$$
$$X^TX\beta = X^Ty$$
$$\hat{\beta} = (X^TX)^{-1}X^Ty$$
从这里开始，我试图了解 OLS 和矩量法之间的联系。
我在网上读到我们需要一些矩条件 - 我们可以使用以下条件，因为它们通常用于线性回归（例如残差和协变量的独立性，误差之间的相关性为 0）
$$E[\epsilon] = 0$$
$$E[X\epsilon] = 0$$
由于我们知道$\epsilon = y - X\beta$，我们可以将此替换为二阶矩条件（并重新排列）：&lt; /p&gt;
$$E[X\epsilon] = E[X(y - X\beta)] = 0$$
$$E[Xy] - E[XX^T\beta] = 0$$
$$E[Xy] = E[XX^T]\beta$$
现在我们将样本矩和总体矩等同起来（$\frac{1}{n}$ 来自一般期望公式）：
$$\frac{1}{n}\sum_{i=1}^{n}X_iy_i = \left(\frac{1}{n}\sum_{ i=1}^{n}X_iX_i^T\right)\hat{\beta}_{MM}$$
$$\hat{\beta}_{MM} = \left(\frac{1}{n}\sum_{i=1}^{n}X_iX_i^T\right )^{-1}\left(\frac{1}{n}\sum_{i=1}^{n}X_iy_i\right) = (X^TX)^{-1}X^Ty = \hat{ \beta}_{OLS}$$
因此我们可以看到 OLS 提供了与矩量法相同的估计。
但是一阶矩条件是如何使用的呢？这是方差估计所必需的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/641931/relating-moments-to-ols</guid>
      <pubDate>Wed, 06 Mar 2024 04:01:29 GMT</pubDate>
    </item>
    <item>
      <title>隐式岭回归[重复]</title>
      <link>https://stats.stackexchange.com/questions/641930/implicit-ridge-regression</link>
      <description><![CDATA[最近，我了解到岭回归有时是隐式完成的。例如，考虑
$$\underset{\beta \in \mathbb{R}}{\operatorname{argmin}} E_\xi (y-x \xi \beta)^2$$&lt; /跨度&gt;
其中 (x,y) 是回归模型的输入和输出 $\in \mathbb{R} \times \mathbb{R}$ 和 $\xi\sim N(1,\sigma^2)$。另外， $x\xi$ 表示我们的原始数据 $x$ 转换为 $x\xi$，之后我们进行 OLS 回归。 $x$ 是一个标量。
岭回归是
$$\underset{\beta \in \mathbb{R}}{\operatorname{argmin}} (y-x\beta)^2 + \lambda\beta^2$$.
我们可以看到，当$\sigma^2 = \frac{x^2+\lambda}{x^2}$时，上面的解优化问题是相同的：
\begin{align}
&amp; \underset{\beta \in \mathbb{R}}{\operatorname{argmin}} E_\xi(y-x \xi\beta)^2 \\
&amp;= E_\xi(y^2-2yx\xi\beta + x^2\xi^2\beta^2) \\
&amp;= y^2 - 1 *2yx\beta + \sigma^2x^2\beta^2 \\
&amp;= y^2 - 2yx\beta + \sigma^2 x^2\beta^2
\end{对齐}
然后：
\begin{align}
y^2 - 2yx\beta + \sigma^2x^2\beta^2 &amp;= y^2-2yx\beta+x^2\beta^2 + \lambda\beta^2 \\
\sigma^2x^2\beta^2 &amp;= x^2\beta^2 + \lambda\beta^2 \\
\sigma^2 &amp;= \frac{x^2\beta^2 + \lambda\beta^2}{x^2\beta^2} \\
\sigma^2 &amp;= \frac{x^2 +\lambda}{x^2}
\end{对齐}
我有兴趣尝试 $\xi\sim Bern(p)$:
\begin{align}
&amp; \underset{\beta \in \mathbb{R}}{\operatorname{argmin}} E_\xi(y-x \xi\beta)^2 \\
&amp;= E_\xi(y^2-2yx\xi\beta + x^2\xi^2\beta^2) \\
&amp;= y^2 - p *2yx\beta + p(1-p)x^2\beta^2 \\
&amp;= y^2 - p *2yx\beta + \sigma^2 x^2\beta^2
\end{对齐}
那么，
\begin{align}
y^2 - p *2yx\beta + \sigma^2x^2\beta^2 &amp;= y^2-2yx\beta+x^2\beta^2 + \lambda\beta^2 \\
- p *2yx\beta + \sigma^2x^2\beta^2 &amp;= -2yx\beta+x^2\beta^2 + \lambda\beta^2 \\
\sigma^2x^2\beta^2 &amp;= p2yx\beta - 2yx\beta + x^2\beta^2+\lambda\beta^2 \\
\sigma^2 &amp;= \frac{p2yx\beta - 2yx\beta + x^2\beta^2+\lambda\beta^2}{x^2\beta^2} \\
\sigma^2 &amp;= \frac{p2yx - 2yx + x^2\beta+\lambda\beta}{x^2\beta} \\
p(1-p) &amp;= \frac{2yx(p-1) + \beta(x^2+\lambda)}{x^2\beta}
\end{对齐}
这个解决方案对我来说似乎并不完全正确。有没有办法进一步简化这个过程？我尝试将 $\sigma^2$ 保留为 $p(1-p)$，但这似乎没有帮助。任何帮助将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/641930/implicit-ridge-regression</guid>
      <pubDate>Wed, 06 Mar 2024 03:19:40 GMT</pubDate>
    </item>
    <item>
      <title>线性回归模型构建和假设的序列[关闭]</title>
      <link>https://stats.stackexchange.com/questions/641929/sequence-of-linear-regression-model-building-assumptions</link>
      <description><![CDATA[有人可以严格解释我们如何构建线性回归模型的基本步骤，从随机结果变量（Y）和固定变量（X）之间比例的基本怀疑开始，以及假设每一步？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/641929/sequence-of-linear-regression-model-building-assumptions</guid>
      <pubDate>Wed, 06 Mar 2024 02:04:45 GMT</pubDate>
    </item>
    <item>
      <title>具有条件随机化的工具变量？</title>
      <link>https://stats.stackexchange.com/questions/641928/instrumental-variable-with-conditional-randomization</link>
      <description><![CDATA[我正在进行一项 IV 设计的研究。在我的设置中，IV 仅在一年内且在一个队列内是有条件随机的。在这种情况下，我是否只需将年份和队列作为 IV 回归中的对照？需要明确的是，以下是我当前正在运行的回归：
iv_model &lt;- ivreg(y ~ D + 因子(年份) + 因子(队列) | Z + 因子(年份) + 因子(队列) , data=data)

我需要包含任何交互术语吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/641928/instrumental-variable-with-conditional-randomization</guid>
      <pubDate>Wed, 06 Mar 2024 00:18:47 GMT</pubDate>
    </item>
    <item>
      <title>如何对多个布尔类建模</title>
      <link>https://stats.stackexchange.com/questions/641927/how-to-model-multiple-boolean-classes</link>
      <description><![CDATA[我正在研究SAMHSA 心理健康客户级数据集。我删除了一些不相关的列，将一些列标准化为 0-1，并对其他列进行单热编码。我正在尝试训练分类器来预测本专栏其余部分的混乱情况。然而，根据诊断，有 13 个二元疾病列（躁郁症、精神分裂症、多动症等）。
我已经训练了 RandomForestClassifier 和多类 LogisticRegression。 RandomForest 和 LogisticRegression 的准确率均约为 36%、准确率 30%、召回率 36%。在这种情况下，我使用的标签将疾病分类为 [0 种疾病，1 种疾病，&gt; 1 种疾病。 1 个障碍]共 15 个班级。我还尝试对 2^13=8192 种疾病组合进行二进制编码，其准确度相似，但精确度为 17%。前一种情况的随机猜测应该是 ~7%。
如果我尝试预测 k 均值标签，我会获得约 92% 的准确度、精确度和召回率。我认为这只是意味着簇是由数据明确定义的，而其他标签只是分散的，所以没有希望做得更好。
对于分类，我应该使用 LogisticRegression 并删除所有其他列，并对剩余列执行分类，并以这种方式遍历所有 13 个列，获取每个列的概率，然后除以所有这些列的总和即可得到每个类别的概率？



]]></description>
      <guid>https://stats.stackexchange.com/questions/641927/how-to-model-multiple-boolean-classes</guid>
      <pubDate>Wed, 06 Mar 2024 00:01:34 GMT</pubDate>
    </item>
    <item>
      <title>如何找到最佳或接近的预算分配？</title>
      <link>https://stats.stackexchange.com/questions/641924/how-can-i-find-the-optimal-or-close-to-allocation-for-a-budget</link>
      <description><![CDATA[我想使用支出和收入时间序列数据找到最佳或接近最佳的预算分配？您建议我如何解决这个问题？
我正在考虑尝试 VAR 或可能的稳健线性回归。
如果我还可以添加任何其他内容来使问题变得更好，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/641924/how-can-i-find-the-optimal-or-close-to-allocation-for-a-budget</guid>
      <pubDate>Tue, 05 Mar 2024 22:52:58 GMT</pubDate>
    </item>
    <item>
      <title>隐式岭回归[关闭]</title>
      <link>https://stats.stackexchange.com/questions/641921/implicit-ridge-regression</link>
      <description><![CDATA[最近，我了解到岭回归有时是隐式完成的。例如，考虑
$$\underset{\beta \in \mathbb{R}}{\operatorname{argmin}} E_\xi (y-x \xi \beta)^2$$&lt; /跨度&gt;
其中 (x,y) 是回归模型的输入和输出 $\in \mathbb{R} \times \mathbb{R}$ 和 $\xi\sim N(1,\sigma^2)$。另外， $x\xi$ 表示我们的原始数据 $x$ 转换为 $x\xi$，之后我们进行 OLS 回归。 x 应该是一个标量。
岭回归是
$$\underset{\beta \in \mathbb{R}}{\operatorname{argmin}} (y-x\beta)^2 + \lambda\beta^2$$.
我们可以看到，当$\sigma^2 = \frac{x^2+\lambda}{x^2}$时，上面的解优化问题是相同的：
\begin{align}
&amp; \underset{\beta \in \mathbb{R}}{\operatorname{argmin}} E_\xi(y-x \xi\beta)^2 \\
&amp;= E_\xi(y^2-2yx\xi\beta + x^2\xi^2\beta^2) \\
&amp;= y^2 - 1 *2yx\beta + \sigma^2x^2\beta^2 \\
&amp;= y^2 - 2yx\beta + \sigma^2 x^2\beta^2
\end{对齐}
然后：
\begin{align}
y^2 - 2yx\beta + \sigma^2x^2\beta^2 &amp;= y^2-2yx\beta+x^2\beta^2 + \lambda\beta^2 \\
\sigma^2x^2\beta^2 &amp;= x^2\beta^2 + \lambda\beta^2 \\
\sigma^2 &amp;= \frac{x^2\beta^2 + \lambda\beta^2}{x^2\beta^2} \\
\sigma^2 &amp;= \frac{x^2 +\lambda}{x^2}
\end{对齐}
我有兴趣尝试 $\xi\sim Bern(p)$:
\begin{align}
&amp; \underset{\beta \in \mathbb{R}}{\operatorname{argmin}} E_\xi(y-x \xi\beta)^2 \\
&amp;= E_\xi(y^2-2yx\xi\beta + x^2\xi^2\beta^2) \\
&amp;= y^2 - p *2yx\beta + p(1-p)x^2\beta^2 \\
&amp;= y^2 - p *2yx\beta + \sigma^2 x^2\beta^2
\end{对齐}
那么，
\begin{align}
y^2 - p *2yx\beta + \sigma^2x^2\beta^2 &amp;= y^2-2yx\beta+x^2\beta^2 + \lambda\beta^2 \\
- p *2yx\beta + \sigma^2x^2\beta^2 &amp;= -2yx\beta+x^2\beta^2 + \lambda\beta^2 \\
\sigma^2x^2\beta^2 &amp;= p2yx\beta - 2yx\beta + x^2\beta^2+\lambda\beta^2 \\
\sigma^2 &amp;= \frac{p2yx\beta - 2yx\beta + x^2\beta^2+\lambda\beta^2}{x^2\beta^2} \\
\sigma^2 &amp;= \frac{p2yx - 2yx + x^2\beta+\lambda\beta}{x^2\beta}
\end{对齐}
这个解决方案对我来说似乎并不完全正确。有没有办法进一步简化这个过程？我尝试将 $\sigma^2$ 保留为 $p(1-p)$，但这似乎没有帮助。任何帮助将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/641921/implicit-ridge-regression</guid>
      <pubDate>Tue, 05 Mar 2024 21:51:21 GMT</pubDate>
    </item>
    <item>
      <title>关于使用 RFpredInterval 包的问题：如何计算与测试数据点相同的终端节点中的数据点的标准差</title>
      <link>https://stats.stackexchange.com/questions/641922/question-about-using-the-rfpredinterval-package-how-to-calculate-the-standard-d</link>
      <description><![CDATA[我正在使用 RFpredInterval 包（特别是 rfpi 函数）来获取随机森林的预测间隔。我想通过采用与每个测试数据点相同的终端节点中的数据点的标准差（也称为 BOP 数据）来估计测试数据集的置信区间。我已经尝试这样做（详细信息如下），但我认为我没有正确地提取正确的 BOP/终端节点数据来获取标准差。
我编辑了 rfpi 函数以返回“BOPtest”在函数内创建的术语，认为这可能是测试数据集中每个数据点的 BOP 数据列表。我通过取 BOPtest 列表中每个元素的平均值来检查这是否是正确的术语，因为这就是随机森林算法计算最终预测输出的方式。然而，这种情况并非如此。如果有人能帮助我破译 rfpi 函数中的代码以提取 BOP 数据，我将不胜感激。预先感谢您。
这是我所做的一个示例
## 加载示例数据
数据（波士顿住房，包=“RFpredInterval”）
设置.种子(2345)
## 定义训练/测试分割
测试指数 &lt;- 1:10
trainindex &lt;- 样本（11：nrow（波士顿住房），大小= 100，替换= FALSE）
traindata &lt;- BostonHousing[trainindex, ]
测试数据 &lt;- BostonHousing[testindex, ]
px &lt;- ncol(波士顿住房) - 1
## 用“l1”构建 90% PI分割规则和“spi”带校准的 PI 方法
out &lt;- rfpi(公式 = medv ~ ., traindata = traindata,
            测试数据=测试数据，
            阿尔法 = 0.1,
            校准=真，
            split_rule =“ls”，
            pi_method =“lm”，
            params_rfsrc = 列表(ntree = 50),
            params_calib = 列表(范围 = c(0.89, 0.91), 开始 = 0.9, 步骤 = 0.01, 精炼 = TRUE))

#拉出BOP测试列表
bop.test&lt;-out$BOPtest
bop.mean&lt;-t(data.frame(lapply(bop.test,mean)))
bop.sd&lt;-t(data.frame(lapply(bop.test,sd)))

#结果数据框
result_df&lt;-data.frame(cbind(out$test_pred,testdata$medv,bop.mean,bop.sd))
colnames(result_df)&lt;-c(“pred”,“meas”,“bop_mean”,“bop_sd”)


我认为 result_df$pred 和 result_df$bop_mean 应该相等。
以下是 github 上 rfpi 功能页面的链接：https: //github.com/cran/RFpredInterval/blob/master/R/rfpi.R
我还必须加载这些函数：

https://github.com/cran/RFpredInterval /blob/master/R/build.bop.R
https://github.com/cran/RFpredInterval /blob/master/R/calibration.functions.R
https://github.com/cran/RFpredInterval /blob/master/R/formpi.functions.R
]]></description>
      <guid>https://stats.stackexchange.com/questions/641922/question-about-using-the-rfpredinterval-package-how-to-calculate-the-standard-d</guid>
      <pubDate>Tue, 05 Mar 2024 19:40:07 GMT</pubDate>
    </item>
    <item>
      <title>我们如何解释矩阵变量正态分布中的协方差矩阵 $\textbf{U}$ 和 $\textbf{V}$？</title>
      <link>https://stats.stackexchange.com/questions/641849/how-do-we-interpret-the-covariance-matrices-textbfu-and-textbfv-in-the</link>
      <description><![CDATA[考虑矩阵正态分布。我的第一个问题是：我们如何解释随机矩阵 $\textbf{X}_{ij}$ 的条目  $\textbf{X}(n\times p)$？我的第二个问题是：我们如何解释所谓的协方差矩阵 $\textbf{U}$ 和 $\textbf{ V}$？最后，我的第三个问题是：我们如何计算矩阵 $\textbf{U}$ 和 $\textbf{V }$？
如有任何帮助，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/641849/how-do-we-interpret-the-covariance-matrices-textbfu-and-textbfv-in-the</guid>
      <pubDate>Tue, 05 Mar 2024 01:59:02 GMT</pubDate>
    </item>
    <item>
      <title>将多个排名合并为一个的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/641742/what-is-the-best-way-of-combining-multiple-rankings-into-one</link>
      <description><![CDATA[假设我有 $N$ 个不同的项目需要排名，并且 $M$ 个不同的人根据他们的个人喜好提供项目的排名。将所有排名合并为一个的最佳方法是什么？
最简单的方法是计算所有排名的总和，然后将结果从最低到最高排名。但还有其他方法。是否有一种在数学上更正确的方法，可能通过假设一些潜在的分布来实现？
例如，让 $r_{ij}$ 为分配给项目 $i$ 的排名由评估者$j$。上面概述的简单方法相当于将排名转换为分数 $s_{ij} = - r_{ij}$，并为每个项目计算总分 &lt; span class=&quot;math-container&quot;&gt;$S_i = \sum_{j=1}^M{s_{ij}}$ 用于提供项目的最终排名。其他替代方法包括将分数设置为 $s_{ij}=1/r_{ij}$ （调和平均值）或 $ s_{ij}=-\log r_{ij}$（几何平均值）。我如何选择最好的替代方案？]]></description>
      <guid>https://stats.stackexchange.com/questions/641742/what-is-the-best-way-of-combining-multiple-rankings-into-one</guid>
      <pubDate>Sun, 03 Mar 2024 20:25:32 GMT</pubDate>
    </item>
    <item>
      <title>导出线性回归中的残差分布</title>
      <link>https://stats.stackexchange.com/questions/641739/deriving-the-distributions-of-residuals-in-linear-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/641739/deriving-the-distributions-of-residuals-in-linear-regression</guid>
      <pubDate>Sun, 03 Mar 2024 18:51:34 GMT</pubDate>
    </item>
    <item>
      <title>R pwr 包对于极小样本量 (<10) 的有效性</title>
      <link>https://stats.stackexchange.com/questions/641707/validity-of-r-pwr-package-for-extremely-small-sample-sizes-10</link>
      <description><![CDATA[编辑：这个问题不是：

关于编程
关于事后功效分析（至少不是为了在事后分析中使用样本统计数据 - 我有很好的人口估计值，我想向人们展示如何使用这些数据）

这个问题是关于：

正确使用科学界广泛使用的常用工具。
在此（或任何其他）工具中检查假设和近似值，包括默认的假设和近似值。

因此，我相信结束这个问题（甚至没有提供任何提示
在哪里以及如何得到答案）实际上伤害了这个社区，
通过传达这样的信息：这些检查是多余的，而它们
确实应该放在优先事项列表的首位。
我希望这个请求能够得到重新审理。
———————————-
pwr 包是否使用 Cohen 1988 中描述的小样本近似（例如 1 样本 t 检验中的自由度）来实现？我似乎在文档中找不到这个。
如果是这样，对于非常小的样本量功效计算是否有更好的选择？
感谢您的回复。
————————
可选阅读：我的问题的动机：
在工作（制造操作）中，我们发现很难重现测试结果。对我来说，很明显这是因为我们进行的研究动力严重不足。我的老板同意我应该解决一些问题。
我想计算我们使用的一些典型实验“设计”的功效。
R中的pwr包看起来非常方便。该小插图引用了 Cohen 的书：行为科学的统计功效分析 (1988)。不同的应用领域应该有相同的数学，但我还是决定看看这本书。
我注意到书中的一些近似值，当“小样本量”意味着 &gt; 时，这些近似值是有效的。 30. 对我来说，“非常大的样本量”有时意味着 10。我现在注意到 1 样本 t 检验和配对 t 检验的近似值：书中提到它没有具有正确自由度的表格。这导致 n &gt; 的差异非常小。 30，但我怀疑该近似值对于 n &lt; 30 可能无效。 10. 我想检查一下。这就是我的问题。
————————-
编辑：其中一条评论要求引用，这是合理的。
我引用 Cohen, J. (1988) 的话。行为科学的统计功效分析（第二版），如 pwr 包中引用。
这里有两个例子，科恩提到了近似值的使用：
第 42 页脚注 1 中关于样本量不等的 t 检验的一个不太严重的例子：“这是因为该表将 n 的 t 检验视为基于 df = 2n&#39; - 2，而实际上有 df=nA +nB - 2，较大的值。”
第 46 页，关于单样本 t 检验有一个更严重的例子：
“功效表的计算基础是 n 是两个样本中每个样本的大小，因此 t 检验将基于 2(n-1) 个自由度。在单样本情况下，t 必然仅基于 n - 1 个自由度。”并且：“除非样本量很小（比如小于 25 或 30），否则低估自由度的影响可以忽略不计。”
请注意，我同意这种分析和近似。然而，在我的情况下，我可能会误入歧途，因为我违反了其中一个条件。将错误的东西改成同样错误的东西并不是一种改进，所以我想避免这种情况。
对于现代计算机，不再需要这些近似值 - 但我无法在文档中找到 R 包是否是用近似值编写的。
我知道我们应该做什么，但是获得大于 20 的样本量对我们来说极其罕见。话又说回来，我们可以修改我们的实验以获得比科恩认为的“大”更大的效应量。我只需要向人们解释/激励我们应该这样做。要达到这一点需要付出努力。]]></description>
      <guid>https://stats.stackexchange.com/questions/641707/validity-of-r-pwr-package-for-extremely-small-sample-sizes-10</guid>
      <pubDate>Sun, 03 Mar 2024 10:35:10 GMT</pubDate>
    </item>
    </channel>
</rss>