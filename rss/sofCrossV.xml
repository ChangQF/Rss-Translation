<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 26 Jun 2024 01:04:46 GMT</lastBuildDate>
    <item>
      <title>在不同的数据集上同时优化两个函数</title>
      <link>https://stats.stackexchange.com/questions/649913/simultaneously-optimizing-two-functions-on-different-datasets</link>
      <description><![CDATA[我有两个共享参数的函数，每个函数都需要针对不同的数据进行优化。我的问题是：我是否可以简单地将两个函数的残差平方和 (RSS) 添加到我的目标函数中并运行优化？
例如，rss1 是将函数 f1 的结果与数据 d1 进行比较时的值，rss2 是将 f2 与数据 d2 进行比较时的值。我如何在 R 的 optim 函数中使用这两个 rss？这是简单的求和，还是另有隐情？
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/649913/simultaneously-optimizing-two-functions-on-different-datasets</guid>
      <pubDate>Wed, 26 Jun 2024 00:12:19 GMT</pubDate>
    </item>
    <item>
      <title>使用共享参数在两个数据集上优化两个函数</title>
      <link>https://stats.stackexchange.com/questions/649912/optimize-two-functions-on-two-datasets-with-shared-parameters</link>
      <description><![CDATA[我有两个共享参数的函数，每个函数都需要根据单独的数据进行优化。我的问题是：我可以在目标函数中简单地添加两个函数的残差平方和吗？
我将给出一个玩具 R 代码作为示例。
eq_1_optim = function(ka,kel,t){return(0.004*(exp(-kel*t)-exp(-ka*t)))
eq_2_optim = function(kel,t){return(0.004*(exp(-kel*t)))
数据集 1：t1=c(0,0.3,0.7,1,1.5,4,6)，p1=c(0,2.5,4,4.4,3.8,2,0.9)
数据集 2：t2=c(0.01,0.1,0.5,1,8)， p2=c(0.5,0.4,0.01,0.01,0.004)
t=list(t1,t2)
observ = list(p1,p2)
obj_fun = function(par,t,observed){
t1=t[[1]]
t2=t[[2]]
observed_1 = perceived[[1]]
observed_2 = perceived[[2]]
predicted_model_1 = eq_1_optim(par[1],par[2],t1)
predicted_model_2 = eq_2_optim(par[2],t2)
rss1 = sum((observed_1-predicted_model_1)^2)
rss2 = sum((observed_2-predicted_model_2)^2)
return(rss1+rss2)
fit = optim(par=c(5,0.3),fn = obj_fun,t=t,observed=observ,method = &quot;L-BFGS-B&quot;,lower=c(0.5,0.01),upper=c(10,10))
如能得到任何帮助，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/649912/optimize-two-functions-on-two-datasets-with-shared-parameters</guid>
      <pubDate>Tue, 25 Jun 2024 23:54:23 GMT</pubDate>
    </item>
    <item>
      <title>个人卫生用品调查的多元分析</title>
      <link>https://stats.stackexchange.com/questions/649911/multivariate-analysis-for-personal-hygiene-product-survey</link>
      <description><![CDATA[我进行了一项调查，调查涉及 5 种不同的个人卫生产品。每种产品有 6 个不同的品牌，参与者被要求为每种产品选择一个或多个他们喜欢的品牌。除了品牌偏好之外，我还收集了参与者的社会人口统计数据，例如年龄、收入和其他相关特征。
调查详情：

产品：5 种不同的个人卫生产品
品牌：每种产品有 6 个品牌
选择：参与者可以为每种产品选择多个品牌（多选题）
其他数据：社会人口特征（年龄、收入等）。我计划在我的分析中包含这些社会人口变量，以便更好地了解关系和模式。

我的问题：

多变量分析：鉴于我的数据的性质，多变量分析是否合适？如果是，您会推荐哪种特定类型？

资源：您能否推荐一些书籍、研究或文章来解释如何有效地进行这种分析，尤其是针对多项选择题的分析？

]]></description>
      <guid>https://stats.stackexchange.com/questions/649911/multivariate-analysis-for-personal-hygiene-product-survey</guid>
      <pubDate>Tue, 25 Jun 2024 23:01:44 GMT</pubDate>
    </item>
    <item>
      <title>Fisher 信息中的评分函数的导数</title>
      <link>https://stats.stackexchange.com/questions/649907/derivative-of-the-score-function-in-fisher-information</link>
      <description><![CDATA[我正在研究 Fisher 信息，并试图形成一种直观的理解。请记住，我只有本科数学背景，所以我希望得到一个更直观的解释而不是数学推导的答案。
我理解我们使用 Fisher 信息来让我们对 MLE 有某种“信心”。但是，我在数学上感到困惑，我们如何才能在 MLE 处获得除零之外的任何 Fisher 信息。由于 FI 等于得分函数一阶导数平方的期望值（wrt X），因此在等于 MLE 的 theta 处的导数就是 0。而 0 的平方等于 0。那么，如何才能让 FI 在 MLE 处有意义呢？这是否与我们对随机变量 X 的所有值求导数的平均值有关，因此在某些情况下斜率可能不为零？
任何见解都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/649907/derivative-of-the-score-function-in-fisher-information</guid>
      <pubDate>Tue, 25 Jun 2024 22:15:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么单尾研究的标准 alpha 值为 0.025？</title>
      <link>https://stats.stackexchange.com/questions/649904/why-is-the-standard-alpha-for-one-tailed-studies-0-025</link>
      <description><![CDATA[似乎文献中的标准是仅当 p &lt;= 0.025 时才认为单尾研究“显著”。这是为什么呢，特别是如果研究从一开始就计划采用单尾研究的话。]]></description>
      <guid>https://stats.stackexchange.com/questions/649904/why-is-the-standard-alpha-for-one-tailed-studies-0-025</guid>
      <pubDate>Tue, 25 Jun 2024 21:29:59 GMT</pubDate>
    </item>
    <item>
      <title>澄清包括时变协变量的 GEE 模型</title>
      <link>https://stats.stackexchange.com/questions/649900/clarification-on-a-gee-model-including-time-varying-covariates</link>
      <description><![CDATA[我想知道 GEE 方法是否可以用于随时间变化的协变量？我有一项纵向研究，其中包括时间相关的协变量，我不确定是否仍可以使用 GEE 模型
根据以下出版物 https://support.sas.com/resources/papers/proceedings15/3252-2015.pdf
似乎 GEE 方法在使用时间相关的协变量时不能保证具有一致的估计量，同样在以下链接 https://mbounthavong.com/blog/tag/time-varying+covariates 中，提到“执行的传统方法纵向数据分析（例如线性混合效应模型和广义估计方程模型）能够处理随时间变化的协变量。然而，对于随时间变化的元素，治疗暴露的概率总是随时间而不同，这需要在分析单位上应用随时间变化的权重&#39;`*]]></description>
      <guid>https://stats.stackexchange.com/questions/649900/clarification-on-a-gee-model-including-time-varying-covariates</guid>
      <pubDate>Tue, 25 Jun 2024 20:13:18 GMT</pubDate>
    </item>
    <item>
      <title>神经网络如何区分输出 0 的神经元和丢失的神经元？</title>
      <link>https://stats.stackexchange.com/questions/649899/how-does-a-neural-network-differentiate-between-a-neuron-that-outputs-0-and-a-dr</link>
      <description><![CDATA[网络如何区分输出为 0 的神经元和丢失的神经元（该神经元可能输出非零值，但由于丢失而输出 0）？]]></description>
      <guid>https://stats.stackexchange.com/questions/649899/how-does-a-neural-network-differentiate-between-a-neuron-that-outputs-0-and-a-dr</guid>
      <pubDate>Tue, 25 Jun 2024 19:59:58 GMT</pubDate>
    </item>
    <item>
      <title>关于 OLS 估计量的问题（BLUE 证明）</title>
      <link>https://stats.stackexchange.com/questions/649896/question-about-ols-estimator-blue-proof</link>
      <description><![CDATA[我们知道$\beta$的 OLS 估计量是唯一的 BLUE。
证明如下。考虑一般线性估计量
$$\hat{\boldsymbol{\beta}}_\mathbf{A} 
= \hat{\boldsymbol{\beta}}_\text{OLS} + \mathbf{A} \mathbf{Y}
= \bigl[(\mathbf{x}^\text{T} \mathbf{x})^{-1} \mathbf{x}^\text{T} + \mathbf{A}\bigr] \mathbf{Y}$$
$\hat{\boldsymbol{\beta}}_\mathbf{A}$ 的偏差为 $$\begin{align}\mathbb{E}\bigl[\hat{\boldsymbol{\beta}}_\mathbf{A}-\beta\,\vert \mathbf{x}\bigr]&amp;=
\mathbb{E}\bigl[\hat{\boldsymbol{\beta}}_\mathbf{A}-\beta\,\vert \mathbf{x}\bigr] \\[6pt]
&amp;= \mathbb{E}\bigl[\hat{\boldsymbol{\beta}}_\text{OLS} + \mathbf{A} \mathbf{Y} - \boldsymbol{\beta}\bigr\vert \mathbf{x}] \\[6pt]
&amp;= \boldsymbol{\beta} + \mathbf{A} \mathbf{x} \boldsymbol{\beta} - \boldsymbol{\beta} \\[6pt]
&amp;= \mathbf{A} \mathbf{x} \boldsymbol{\beta}, \\[6pt]
\end{align}$$ 因此，$\hat{\boldsymbol{\beta}}_\mathbf{A}$ 的无偏性要求是
$$\mathbf{Ax}\beta=0$$
现在证明说我们可以假设 $\mathbf{Ax}=0$ 并从这里开始。无论如何，其余的证明对我来说都很清楚。
我不清楚为什么这里$\mathbf{Ax}\beta=0\implies \mathbf{Ax}=0$。
我只能说$\mathbf{Ax}\beta=0\implies \mathbf{x}\beta\in\mathrm{Ker}(\mathbf{A})$，这是一个较弱的条件。
换句话说，为了使 $\hat{\boldsymbol{\beta}}_\mathbf{A}$ 不偏不倚，为什么我们要要求 $\mathbf{A}$ 的 Ker 包含整个子空间 $\mathrm{span}(\mathbf{x}_1,\dots,\mathbf{x}_K)$（维度 K），而不仅仅是子空间 $\mathrm{span}(\mathbf{x}\beta)$（维度 1）？
对此的一个可能答案是，出于某种原因，需要条件 $\mathbf{Ax}\beta=0$对所有 $\beta\in\mathbb{R}^K$ 都成立。但我不明白为什么我们应该对所有 $\beta\in\mathbb{R}^K$ 假设这个条件，因为 $\beta$ 这里有一个未知的常数因子，它取决于特定的回归问题。
这个论点有什么问题？任何有关这方面的帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/649896/question-about-ols-estimator-blue-proof</guid>
      <pubDate>Tue, 25 Jun 2024 19:07:56 GMT</pubDate>
    </item>
    <item>
      <title>优化无法收敛到零膨胀贝塔二项分布的已知参数</title>
      <link>https://stats.stackexchange.com/questions/649895/optimization-fails-to-converge-on-known-parameters-for-zero-inflated-beta-binomi</link>
      <description><![CDATA[我尝试使用 R 中 VGAM 提供的分布来拟合模拟的零膨胀 beta 二项式数据。
当我对我编写的似然函数使用 optim 时，优化不会收敛到我用来模拟数据的参数上。收敛的值也会根据我输入的初始值而变化。示例：
library(VGAM)

# 模拟数据
num_obs &lt;- 1e5; num_visits &lt;- 20; alpha &lt;- 0.8; beta &lt;- 0.8; psi_0 &lt;- 0.1
sim_zoibb &lt;- rzoibetabinom.ab(
n = num_obs, size = num_visits, shape1 = alpha, shape2 = beta, pstr0 = psi_0)
hist(sim_zoibb, breaks = -0.5 : (num_visits + 0.5))

# 似然函数
nll &lt;- function(params, num_visits, data) {
alpha &lt;- params[1]; beta &lt;- params[2]; psi_0 &lt;- params[3]
return(-1 * sum(dzoibetabinom.ab(
x = data, size=num_visits, shape1=alpha, shape2=beta, pstr0=psi_0, log = TRUE)))
}

# 尝试最大似然优化
out &lt;- optim(
par = c(0.5, 0.5, 0.5), fn=nll,
num_visits=num_visits, data=sim_zoibb,
control=list(maxit=1e6))

Optim 似乎收敛得很快（例如 out$counts[1] = 150-350）。在 c(0.5, 0.5, 0.5) 的初始值下，它会产生参数估计值 0.62、0.77、7.38e-09。当我使用与我用来模拟数据的参数 c(0.8, 0.8, 0.1) 相同的初始值时，它会估计 0.71、0.94、5.82e-09。它似乎总是将 pstr0（结构性零/零膨胀的概率）估计得非常低/接近 0。
我尝试使用不同的优化方法：BFGS 和 CG 会产生误差 非有限有限差分值，L-BFGS-B 会产生误差 L-BFGS-B 需要“fn”的有限值。 SANN 可以工作，但它收敛速度不快，我让它运行的迭代次数越多，它估计的 pstr0 就越低（例如，10 次迭代时为 0.022，100 次迭代时为 0.0012，1000 次迭代时为 0.00085）。
我也尝试过使用 VGAM 本身来拟合数据，但似乎找不到正确的零膨胀 beta 二项分布。当我尝试使用没有零膨胀的分布时，我收到以下错误：
&gt; vgam(sim_zoibb ~ 1, family=betabinomialff(ishape1 = 0.5, ishape2=0.5))
eval(binomialff()@initialize) 中的错误：
响应值“y”必须为 0 或 1

我不确定哪里出了问题 - 我编写的似然函数中是否存在错误？我是否完全误解了优化过程？]]></description>
      <guid>https://stats.stackexchange.com/questions/649895/optimization-fails-to-converge-on-known-parameters-for-zero-inflated-beta-binomi</guid>
      <pubDate>Tue, 25 Jun 2024 18:53:51 GMT</pubDate>
    </item>
    <item>
      <title>纵向数据的多层模型中的中心变量</title>
      <link>https://stats.stackexchange.com/questions/649893/centering-variables-in-multilevel-models-with-longitudinal-data</link>
      <description><![CDATA[Enders 和 Tofighi 2007 讨论了用户在多级模型中以变量为中心的各种方式以及每种情况的适用情况。虽然他们主要将评论集中在横截面案例上，但他们写道：

&quot;在 [纵向 MLM] 等情况下，1 级预测因子……通常以固定值为中心，而不是以平均值为中心……在纵向研究中以固定时间点为中心可能比在横截面背景下决定使用 CGM（以总平均值为中心）或 CWC（以集群为中心）要简单得多。&quot;

在纵向/面板背景下，以时间段为中心变量的理由是什么？为什么它比 CGM 或 CWC 更常见？最后，在实践中，围绕给定时间点集中变量是什么样的？]]></description>
      <guid>https://stats.stackexchange.com/questions/649893/centering-variables-in-multilevel-models-with-longitudinal-data</guid>
      <pubDate>Tue, 25 Jun 2024 18:31:50 GMT</pubDate>
    </item>
    <item>
      <title>对因变量中含有大量零的数据进行 PLS 回归</title>
      <link>https://stats.stackexchange.com/questions/649875/pls-regression-on-data-with-high-number-of-zeros-in-dependent-variable</link>
      <description><![CDATA[我想对来自光谱图像 (NIRS) 的数据集执行 PLS 回归。我的目标是将不同的光谱与化合物的总量联系起来。为此，我有一个包含数千个样本的数据集，其中该化合物的量从 0 到 25 左右不等。
但是，如附图所示，有大量样本没有可检测到的该化合物量或根本没有产生该化合物。在分类问题的情况下，这可能会因类别之间的不平衡而引发问题，但是，我不知道在回归中是否会出现这种情况。我一直在阅读有关使用 0 膨胀的数据的 Hurdle 模型，但是，我不确定如何进行，因为最终目标是选择与化合物总量最相关的光谱带。有什么建议吗？提前致谢。

编辑：我想到 PLS 回归，因为它是通过 NIRS 获得的光谱确定化合物浓度的常用技术。由于独立变量（光谱）的数量约为 4200，并且正在寻找有关处理此类数据的信息，我在网络上找到了参考。作者通过双循环选择了与化合物量最相关的光谱带，其中他首先优化了用于转换数据的组件数量，然后通过拟合多个模型选择了适当数量的光谱带，其中 MSE 最低。最初，这种方法对我来说似乎很合适，尽管由于数据中零的分布很高，我不确定如何继续。]]></description>
      <guid>https://stats.stackexchange.com/questions/649875/pls-regression-on-data-with-high-number-of-zeros-in-dependent-variable</guid>
      <pubDate>Tue, 25 Jun 2024 13:00:30 GMT</pubDate>
    </item>
    <item>
      <title>少数聚类的标准误差聚类</title>
      <link>https://stats.stackexchange.com/questions/649871/standard-error-clustering-with-few-clusters</link>
      <description><![CDATA[我试图使用来自三个州 166 个县的县级犯罪数据来估计警察在场对犯罪率的因果影响。处理是在州一级分配的。对于我的基本估计（TWFE 包括县、年份、月份和星期几），我将标准误差聚类在县级。但是，我知道常见的方法是在处理级别进行聚类。由于这在只有三个集群的情况下是不可能的，因此另一种方法是使用野生集群引导标准误差（Cameron 等人，2008 年）。我不确定 WCB 方法是否在只有三个集群的情况下可行。
有人遇到过类似的问题或可以提供一些建议吗？
亲切的问候]]></description>
      <guid>https://stats.stackexchange.com/questions/649871/standard-error-clustering-with-few-clusters</guid>
      <pubDate>Tue, 25 Jun 2024 11:32:59 GMT</pubDate>
    </item>
    <item>
      <title>样本的值为 $x$ 的概率是 $ng(x)$ 是什么意思？</title>
      <link>https://stats.stackexchange.com/questions/649826/what-is-meant-by-the-probability-of-a-sample-having-a-value-of-x-is-ngx</link>
      <description><![CDATA[从维基百科中读取：

一个样本具有$x$值的概率是$n g(x)$。

假设整个页面中的符号一致，我会将$g$视为概率质量函数或概率密度函数......我对这个说法有些困惑，我想澄清一下。
如果$g$是密度函数，那么对于正态分布，存在密度$g$ $\mathcal{N}(\mu, \sigma)$ 其中 $\mu$ 和 $\sigma$ 经过充分选择，以保证对于给定的 $x$ 和样本大小 $n$，$1 &lt; ng(x)$。因此，如果它可以超过 1，那就不能是概率。
如果 $g$ 是概率质量函数，则存在足够大的样本大小 $n$ 和 $0 &lt; g(x)$ 使得 $1 &lt; n g(x)$。因此 $n g(x)$ 通常也不是概率。
我不确定我在这里遗漏了什么，但这个前提对于我来说根据 Kolmogorov 公理没有意义，因为它们意味着 $\Pr [x \in A] \leq 1$ 对于事件空间中的任何 $A$。]]></description>
      <guid>https://stats.stackexchange.com/questions/649826/what-is-meant-by-the-probability-of-a-sample-having-a-value-of-x-is-ngx</guid>
      <pubDate>Mon, 24 Jun 2024 18:46:55 GMT</pubDate>
    </item>
    <item>
      <title>与三元变量进行 3 次比较</title>
      <link>https://stats.stackexchange.com/questions/649689/making-3-comparisons-with-a-ternary-variable</link>
      <description><![CDATA[我有一项研究，其中我想研究三元变量 $x$ 与二元变量 $y$ 交互的影响。三元变量是分类变量，出于某些原因，我想在 $3$ 组之间进行 $3$ 比较。
我明白要进行一次比较，我必须进行两次对比。例如，如果我对 group1 与 group3 感兴趣，我定义 $C_1= (-1,0,1)$ 和 $C_2=(-1,2,-1)$。如果我想测试所有的比较，那么我应该做$6$个对比吗？在这种情况下，回归量不会共线吗？有没有更简单的方法可以做到这一点？
谢谢你的帮助！

谢谢你的回答！你的代码运行得很好，但我不确定如何得到我需要的答案。事实上，当我使用我的三元变量的引用（1作为引用，2和3作为另外2个值）并运行一个简单的glm模型时，我得到了这样的输出：
## y 9.782e-03 1.418e-04 69.008 &lt; 2e-16 *** 
## x2 8.677e-05 9.265e-04 0.094 0.92539 
## x3 -3.617e-03 9.229e-04 -3.919 8.96e-05 ***
## y:x2 -5.481e-04 2.935e-04 -1.868 0.06184 . 
## y:x3 9.430e-04 2.941e-04 3.206 0.00135 **

在这里，您可以看到，对于前两个比较，您可以访问关于 x 与变量 y 交互作用的 p 值。我想得到第三个交互项。
当我使用 emmeans 进行多重比较时，我得到了类似这样的结果（它包含的行数比这个还多）：
## (y0 x1) - y1 x2 -0.060 0.0189 159## -3.183 0.0186
## (y0 x1) - (y0 x2) -0.006 0.0277 159## -0.216 0.9999
## (y0 x1) - y1 x2 -0.046 0.0277 159## -1.658 0.5601
## (y0 x1) - (y0 x3) 0.207 0.0277 159## 7.472 &lt;.0001

由于我可以访问所有比较，因此我无法简单地分析变量 x 和 y 之间的相互作用。我希望获得与第一个块相同的输出，但是通过三个比较，有没有办法获得它？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649689/making-3-comparisons-with-a-ternary-variable</guid>
      <pubDate>Fri, 21 Jun 2024 20:51:47 GMT</pubDate>
    </item>
    <item>
      <title>通过限制随机化来实现协变量平衡如何导致未观察变量的不平衡？</title>
      <link>https://stats.stackexchange.com/questions/649609/how-can-restricted-randomization-to-achieve-covariate-balance-lead-to-imbalance</link>
      <description><![CDATA[在文献中，实验设计被认为是协变量平衡和稳健性之间的权衡。例如，Harshaw 等人 (2024) 写道

为了使估计量更精确，实验者有时会限制随机化以实现治疗组之间的协变量平衡。这种方法的一个问题是，即使观察到的特征相似，未观察到的特征（包括潜在结果）在组之间可能不相似。 [...]
实验者必须权衡随机性赋予的稳健性与平衡预测重要协变量可能带来的精度提升。

这意味着减少协变量不平衡的方法（阻断、匹配对、重新随机化等）可能会意外导致未观察变量的差异大于完全随机化设计。
问题：
我不明白平衡协变量如何使另一个未观察变量变得不相似。您能否举一个玩具示例，说明平衡一个协变量会使未观察变量变得不相似？
我的想法：
如果我们使用受限随机化来平衡协变量，任何正/负相关的未观察变量也会变得更平衡。对于不相关的变量，它们不会比完全随机化设计更平衡，但也不会更差。]]></description>
      <guid>https://stats.stackexchange.com/questions/649609/how-can-restricted-randomization-to-achieve-covariate-balance-lead-to-imbalance</guid>
      <pubDate>Thu, 20 Jun 2024 16:37:02 GMT</pubDate>
    </item>
    </channel>
</rss>