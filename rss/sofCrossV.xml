<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Tue, 11 Feb 2025 03:21:19 GMT</lastBuildDate>
    <item>
      <title>建立一个统计模型，说明人们如何对自己的身高说谎</title>
      <link>https://stats.stackexchange.com/questions/661204/making-a-statistical-model-for-how-people-lie-about-their-heights</link>
      <description><![CDATA[这些是我在北美居住时注意到的一些社会趋势：

当人们的自我调整高度时，错误可能会分为2个部分：有意识的错误（即自我报告是故意的，是故意的）和潜意识错误（即，自我报告偶然地报告了错误的高度）
在许多文化中，人们认为男人很高。因此，也许男人更有可能比实际高度高。
一般来说，高个子（即超出一定身高）可能会通过自我报告的高度比实际的高度来获得任何收益。
年长的人可能会更认为他们通过误会高度而获得的收益较少，因此可能是更真实的
我不知道女性的同等推理

假设现在我有一个数据集，其中包含年龄，性别和自我报告的身高（每人1行）。 我想制作一个统计模型，该模型试图纠正高度自我报告的偏见（使用贝叶斯技术），但我不确定如何开始。   
我试图编写基础知识：

  $ h_i^r $  =报告高度
  $ h_i^t $  = true Height（未观察到）
  $ a_i $  = age 
  $ g_i $  =性别（0 =女人，1 =男性）
  $ b_i $ 表示人的报告偏差 $ i $ 。

基本模型现在变为：
  $$ h_i^r = h_i^t + b_i $$ 
 $$ b_i = \ beta_0 + \ beta_1g_i + \ beta_2a_i + \ beta_3（h_i^t- \ \ mu_h）
但我不确定如何将我对自我报告的高度偏见的先入为主的观念转变为贝叶斯先生。此外，我不确定如何以有意义的方式定义关节先验。
有人可以告诉我如何做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661204/making-a-statistical-model-for-how-people-lie-about-their-heights</guid>
      <pubDate>Mon, 10 Feb 2025 22:51:09 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归系数的线性模型中缩放坐标（纬度和经度）</title>
      <link>https://stats.stackexchange.com/questions/661202/scaling-coordinates-latitude-and-longitude-in-a-linear-model-for-partial-regre</link>
      <description><![CDATA[我有一个数据集，我有兴趣比较部分回归系数。我在多个地方读到，预测变量应以均值为中心和缩放（按1个标准偏差）来促进这一点，尤其是如果变量在较大的尺度上。但是，我的预测因素之一恰好是经度。一般示例：
 响应变量〜中心和缩放变量1 +中心和缩放变量2 +经度 + 
中心和缩放变量1：中心和缩放变量2 + 
中心和缩放变量1：经度 + 
中心和缩放变量2：经度）
 
看来，约定是要中心/缩放所有变量，或者没有变量，但这使我想知道缩放和居中是否是必要和适合纬度和经度的。我遇到了这个Stackoverflow帖子，似乎表明答案可能是“否”因为它扭曲了坐标的含义：
在48426533/变异分区 - 使用纬度和宽容 - 解释性变量）
，但我不太了解在多个线性回归的背景下，缩放和居中是否不合适，是否主要对系数感兴趣？
感谢您对此的想法！]]></description>
      <guid>https://stats.stackexchange.com/questions/661202/scaling-coordinates-latitude-and-longitude-in-a-linear-model-for-partial-regre</guid>
      <pubDate>Mon, 10 Feb 2025 22:44:18 GMT</pubDate>
    </item>
    <item>
      <title>危险功能的直觉在生存功能的对数方面</title>
      <link>https://stats.stackexchange.com/questions/661201/intuition-for-hazard-function-in-terms-of-logarithm-of-survival-function</link>
      <description><![CDATA[  this 帖子有助于解释危险功能的直觉。在其中，危险功能被解释为
在
其中 $ f（t）$ 是pdf， $ s（t）$ 是生存功能。这导致身份
  $$ h（t）=  -  \ frac {d} {dt} {dt} \ log（s（t））。 $$  
是否有任何直觉可以从中获得？危险功能是时间t的瞬时死亡率，鉴于患者在时间t中存活。令我惊讶的是，某种程度上等于生存函数对数转换的变化速率。]]></description>
      <guid>https://stats.stackexchange.com/questions/661201/intuition-for-hazard-function-in-terms-of-logarithm-of-survival-function</guid>
      <pubDate>Mon, 10 Feb 2025 22:12:18 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯统计，100页的机器学习书籍</title>
      <link>https://stats.stackexchange.com/questions/661200/bayesian-statistics-the-100-page-machine-learning-book</link>
      <description><![CDATA[我有一个关于本书中的贝叶斯统计数据的问题，“ 100页机器学习书籍的Andriy Burkov。问题是关于贝叶斯统计的。我有一本书中的屏幕截图，其中包含相关信息。这本书可以在这里免费找到： http://themlbook.com/wiki/wiki/wiki/doku.php  
    
 关于红线： 
为什么他替换 $ p（\ theta = \ hat {\ theta}）$ 用 $ \ frac { 1} {n} p（\ theta = \ hat {\ theta} | x = x）$ ？他在这里是什么意思？我不明白的是：当您计算出 $ p（\ theta = \ hat {\ theta} | x = x_1）$ 时，您只有&lt; SPAN class =“ Math-Container”&gt; $ p（\ theta = \ hat {\ theta} | x = x）$  for  $ x_1 $ ，不是其他吗？因此，如何通过所有 $ x的$ 获得 $ \ frac {1} {n} p（\ theta p（\ theta） = \ hat {\ theta} | x = x）$ ？
我在另一本书中看了看，他们这样做了：计算出的 $ p（\ theta = \ hat {\ theta} | x_1）$ ，然后，他们使用此值来计算 $ p（\ theta = \ hat {\ theta} | x_1，x_1，x_2）$ ，然后他们用它来计算 $ p（\ theta = \ hat {\ theta} | x_1，x_2，x_3）$ 。这是他所做的，但在其他符号中？我不明白他的平均值？
 关于绿色框： 
表达式是否与 $ \ text {arg max} _ \ theta p（\ theta = \ hat {\ theta} | x_1，x_2，x_2，x_3，\ ldots ，x_n）$ ？如果没有，这不是更自然的表达方式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661200/bayesian-statistics-the-100-page-machine-learning-book</guid>
      <pubDate>Mon, 10 Feb 2025 22:04:55 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证和固定套件</title>
      <link>https://stats.stackexchange.com/questions/661198/the-use-of-cross-validation-and-a-hold-out-set</link>
      <description><![CDATA[我一直在考虑使用交叉验证和固定集，但我真的没有看到随机选择的保持测试集的使用。不过，我不得不说，当没有随机进行固定时，它被用来评估特殊特征，例如一个超级样本，我完全看到了它的目的。
我的意思是，当我使用交叉验证来做出建模决策时，我已经解决了过度拟合的问题，即使它可以使用所有数据，它可以引入数据集中的一些偏见，但我也将获得。通过不故意减少培训数据而进行预测能力。
尽管如此，我到处都在看到每个人都从培训数据中随机分开测试集。不要分开随机测试集并使用：是不可接受的

 EDA的整个数据集
变量选择的交叉验证
用于模型选择和超参数优化的嵌套交叉验证
重复交叉验证的最终模型的估计误差
将模型运送到使用整个数据集进行训练的生产中。
]]></description>
      <guid>https://stats.stackexchange.com/questions/661198/the-use-of-cross-validation-and-a-hold-out-set</guid>
      <pubDate>Mon, 10 Feb 2025 21:29:23 GMT</pubDate>
    </item>
    <item>
      <title>应用T-SNE时，您是否知道有此行为的数据集吗？</title>
      <link>https://stats.stackexchange.com/questions/661194/do-you-know-of-any-dataset-with-this-behavior-when-applying-t-sne</link>
      <description><![CDATA[    
我正在寻找应用T-SNE时表现出此行为的数据集。 T-SNE是一种降低算法，有时可以分开最初属于同一群集的数据点。
在本文的图9中（ https://arxiv.org/abs/2009.01512 ） ，您可以完全看到这种现象。作者提出了一种拓扑维度降低算法（TOPOMAP），该算法使簇保持完整，并将其与T-SNE进行比较。很明显，T-SNE最终分开应该保留在一个群集中的点。
您曾经遇到过这种现象吗？如果是这样，您可以共享数据集及其上下文吗？我正在研究一个本科研究项目，并非常感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/661194/do-you-know-of-any-dataset-with-this-behavior-when-applying-t-sne</guid>
      <pubDate>Mon, 10 Feb 2025 20:33:58 GMT</pubDate>
    </item>
    <item>
      <title>在这种简单的语言建模情况下，数学概率如何出现？</title>
      <link>https://stats.stackexchange.com/questions/661193/how-does-the-log-probabilities-mathematically-appear-in-this-simple-case-of-lang</link>
      <description><![CDATA[在（又名 word2vec ），说明：
    
一个人如何得出这个公式？如果一个人遍历每个word  $ \ pm c $  words; （即使用单词和周围。）并计算与周围单词发生的单词的关节概率，可以写：
  \ begin {align}
\ prod_ {-c \ leq j \ leq c，j \ neq 0} p（w_ {i+j} | w_i）
\ end {align}  
，总而言之，我们添加了所有单词
  \ begin {align}
1 = \ sum_ {i = 0} \ prod_ {-c \ leq j \ leq c，j \ neq 0} p（w_ {i+j} | w_i）
\ end {align}  
用日志概率替换，因为 $ p（i）$ 总是大于 $ \ log p（ i）它的$ ，为负；然后我们可以说：
  \ begin {align}
0 \ geq \ sum_ {i = 0} \ sum_ {-c \ leq j \ leq c，j \ neq 0} \ log p（w_ {i+j} | w_i）
\ end {align}  
人们想最大化这一点是有道理的。但是我不确定这种推理是正确的，还是背后有不同的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/661193/how-does-the-log-probabilities-mathematically-appear-in-this-simple-case-of-lang</guid>
      <pubDate>Mon, 10 Feb 2025 20:16:48 GMT</pubDate>
    </item>
    <item>
      <title>使用HyperOPT FMIN进行LightGBM超参数调整</title>
      <link>https://stats.stackexchange.com/questions/661191/lightgbm-hyperparameter-tuning-using-hyperopt-fmin</link>
      <description><![CDATA[我正在遇到一个多分类问题。我正在尝试使用HyperOPT FMIN执行超参数调整。但是，我不知道我应该在搜索空间中使用什么合适的值，以及我应该如何解决此问题。我是否先执行随机搜索，然后在该区域进行搜索？每个搜索空间的价值应该是什么？我的数据集为6000行，我有大约200个变量（如果执行一个热编码，则为400个）。我的目标变量有4个级别
 来自sklearn.model_selection导入随机搜索
导入numpy作为NP
从HyperOPT Import Fmin，TPE，HP，status_ok，试验
导入LightGBM作为LGB
来自sklearn.model_selection导入train_test_split
来自Sklearn.metrics导入精度_score
从hyperopt.pyll.base导入范围

＃定义随机搜索的参数分布
param_dist = {
    &#39;num_leaves&#39;：范围（20，150），
    &#39;Learning_rate&#39;：np.linspace（0.01，0.3，10），
    &#39;n_estimators&#39;：范围（100，1000，100），
    &#39;min_child_weight&#39;：np.linspace（0.01，10，10），
    “子样本”：np.linspace（0.5，1.0，6），
    &#39;colsample_bytree&#39;：np.linspace（0.5，1.0，6），
    &#39;reg_alpha&#39;：np.linspace（0.0，1.0，10），
    &#39;reg_lambda&#39;：np.linspace（0.0、1.0、10）
}

＃创建LightGBM分类器
model = lgb.lgbmclassifier（objective =&#39;多类&#39;，num_class = len（set（y）））

＃执行随机搜索
Random_search = RandomizedSearchCV（
    估算器=模型，
    param_distributions = param_dist，
    n_iter = 20，＃采样的参数设置数量
    评分=&#39;准确性&#39;，
    CV = 3，＃交叉验证分裂策略
    Random_State = 42，
    n_jobs = -1＃使用所有可用内核
）

＃适合随机搜索
Random_search.fit（x_train，y_train）

＃获取最佳参数
best_params = Random_search.best_params_
打印（使用随机搜索搜索发现的最佳超参数：＆quot; best_params）

＃定义围绕最佳参数的搜索空间
search_space = {
    &#39;num_leaves&#39;：scope.int（hp.quniform（&#39;num_leaves&#39;，best_params [&#39;num_leaves&#39;]  -  10，best_params [&#39;num_leaves&#39;] + 10，1），），），），），
    &#39;Learning_rate&#39;：hp.Uniform（&#39;Learning_rate&#39;，best_params [&#39;Learning_rate&#39;] * 0.8，best_params [&#39;Learning_rate&#39;] * 1.2）， * 1.2），
    &#39;n_estimators&#39;：scope.int（hp.quuniform（&#39;n_estimators&#39;，best_params [&#39;n_estimators&#39;]  -  100，best_params [&#39;n_estimators&#39;] + 100，10），），
    &#39;min_child_weight&#39;：hp.ribour（&#39;min_child_weight&#39;，best_params [&#39;min_child_weight&#39;] * 0.8，best_params [&#39;min_child_weight&#39;] * 1.2），
    &#39;subsample&#39;：hp. rustom（&#39;subsample&#39;，max（0.5，best_params [&#39;subsampe&#39;] * 0.8），min（1.0，best_params [&#39;subsampe&#39;] * 1.2）），），），
    &#39;colsample_bytree&#39;：hp.uliform（&#39;colsample_bytree&#39;，max（0.5，best_params [&#39;colsample_bytree&#39;] * 0.8），min（1.0，best_params [&#39;colsample_bytree&#39;] * 1.2），），
    &#39;reg_alpha&#39;：hp.riborm（&#39;reg_alpha&#39;，best_params [&#39;reg_alpha&#39;] * 0.8，best_params [&#39;reg_alpha&#39;] * 1.2），
    &#39;reg_lambda&#39;：hp.Uniform（&#39;reg_lambda&#39;，best_params [&#39;reg_lambda&#39;] * 0.8，best_params [&#39;reg_lambda&#39;] * 1.2）
}

＃定义目标功能
DEF目标（参数）：
    型号= lgb.lgbmclassifier（objective =&#39;多类&#39;，num_class = len（set（y_train）），** params）
    得分= cross_val_score（型号，x_train，y_train，cv = 3，评分=&#39;cercucy&#39;）。平均（）
    返回{&#39;损失&#39;：-score，&#39;状态&#39;：status_ok}

＃运行优化
试验=试验（）
best_hyperparams = fmin（fn =客观，
                        space = search_space，
                        algo = tpe.suggest，
                        max_evals = 50，＃根据您的需求调整评估次数
                        试验=试验，
                        rstate = np.random.default_rng（42））

打印（“使用Hyperopt的最佳超参数：＆quot”，best_hyperparams）
``
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661191/lightgbm-hyperparameter-tuning-using-hyperopt-fmin</guid>
      <pubDate>Mon, 10 Feb 2025 19:47:00 GMT</pubDate>
    </item>
    <item>
      <title>分析分位数残差分析回归拟合</title>
      <link>https://stats.stackexchange.com/questions/661190/analysing-regression-fit-with-quantile-residual</link>
      <description><![CDATA[我是指基于估计的 Quantile Restuals  分析回归方程的拟合的论文。
  http://www.statsci.orgg y&gt;  
替代链接：
  nofollow noreferrer“&gt; https://www.researchgate.net/publiation/publiation __net/publiation/2647151 
在第3节中指出，
  如果正确指定了回归参数/方程，分数残差的分布会收敛到标准正态分布。   
以下是其定义的快照
    
然而，鉴于分数残差基于正常分布的逆CDF ”容器“&gt; $ f $ ，不是估计量化残差 始终 be    正态分布至关重要的如果回归方程的响应变量是连续的，无论是否正确指定了回归方程？
任何见解都会非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/661190/analysing-regression-fit-with-quantile-residual</guid>
      <pubDate>Mon, 10 Feb 2025 19:24:06 GMT</pubDate>
    </item>
    <item>
      <title>为不同的交互拟合单独的LMM</title>
      <link>https://stats.stackexchange.com/questions/661189/fitting-separate-lmms-for-different-interactions</link>
      <description><![CDATA[我使用线性混合模型（LMM）分析了主要临床范围（DV）的主要临床量表的纵向变化。我的完整模型包括：
  dv〜time ∗因子1 ∗因子2+协变量+（1 riD）
 
其中：
  dv =抑郁症状的临床量表，
时间=重复测量点，
因子1 =一个分类变量区分两个亚组（条件1 vs条件2），
因子2 =与临床特征相关的二元分类（Group1 vs Group2），
id =对个别参与者的随机效果。
 
三向相互作用时间：factor1：factor2 很重要。
为了更好地了解每个因素的贡献，我分别拟合三个LMM，每个LMM都对不同的相互作用进行建模：
 基线模型：
  dv〜time+协变量+（1月）
 
  factor1相互作用的模型：
  dv〜time ∗因子1+协变量+（1月ID）
 
  factor2相互作用的模型：
  dv〜time ∗因子2+协变量+（1月ID）
 
考虑到完整模型中的三向相互作用很重要，这种方法是否过于普遍？
具体来说，运行单独的模型是否会过分简化解释？
是否有更好的方法可以在保留完整的模型结构的同时分解重要的三向相互作用？
对解释LMM中三向互动的最佳实践的任何见解将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661189/fitting-separate-lmms-for-different-interactions</guid>
      <pubDate>Mon, 10 Feb 2025 19:20:04 GMT</pubDate>
    </item>
    <item>
      <title>GLMM（LME4包）中极低的R²m，无线性趋势怀疑</title>
      <link>https://stats.stackexchange.com/questions/661188/extremely-low-r%c2%b2m-in-glmm-lme4-package-with-a-non-linear-trend-suspected</link>
      <description><![CDATA[上下文和数据集：
我正在使用LME4软件包的GLMER功能的广义线性混合模型（GLMM）来建模“ Mean_cover_of_aquatic_plants”随着时间的流逝（时间=年度抽样，有37年的样本）在人造湖泊中。
响应变量是Mean_cover_of_aquatic_plant，它是一个百分比值，是通过将所有水生植物在同一湖中不同子图中的封面进行求和，然后除以子图的数量。解释性变量是年份，随机效应是katervervation_site（即不同的保护_ site之间的可变性）。
   
型号设置：
  glmer（mean_cover_of_aquatic_plants〜Time +（1 | kedervation_site），family = gaussian（link =＆quos; log＆quot; log＆quot; log＆quot; data = lake_data）
 
我正在使用高斯家族使用日志链接函数，因为我怀疑时间和均值_cover_of_aquatic_plants之间的非线性关系。
 问题： 
r²m（边际R²）值极低，结果始终低于0.001。
  print（r2_values）
             R2M R2C
[1，] 0.001076443 0.2087605
 
我怀疑低R²m表示该模型没有捕获预期趋势，即使我应用了日志变换来处理数据中可疑的非线性（ logistic ？）。或者，即使在同一年之内的变异性如此之高，以至于导致此输出？
我已经检查了模型拟合，探索了替代的随机效应结构（例如随机斜率），并确保对数链接适用于对非线性趋势进行建模。
我已经考虑了模型中的过度分散，但这似乎不是一个问题。
我已经测试了其他潜在的解释变量，但时间是我分析中感兴趣的主要因素。
    ]]></description>
      <guid>https://stats.stackexchange.com/questions/661188/extremely-low-r%c2%b2m-in-glmm-lme4-package-with-a-non-linear-trend-suspected</guid>
      <pubDate>Mon, 10 Feb 2025 19:18:13 GMT</pubDate>
    </item>
    <item>
      <title>将数据集分为培训和测试集方法</title>
      <link>https://stats.stackexchange.com/questions/661187/split-a-dataset-into-training-and-testset-method</link>
      <description><![CDATA[我创建了一个用于培训神经网络的二进制分类问题的数据集。培训数据来自与特定环境（例如2D地图环境）有关的集合。对于测试案例，我考虑了来自同一2D地图的数据点，但培训集中不存在数据点。
这将是有效的测试用例设计？
任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/661187/split-a-dataset-into-training-and-testset-method</guid>
      <pubDate>Mon, 10 Feb 2025 19:17:01 GMT</pubDate>
    </item>
    <item>
      <title>这是最大似然估计的可能替代方法吗？</title>
      <link>https://stats.stackexchange.com/questions/661174/is-this-a-possible-alternative-to-maximum-likelihood-estimation</link>
      <description><![CDATA[如果我来自纯粹的数学背景，请原谅我。直觉上，最大似然估计器是从样本计算得出的统计量，因此可观察到的数据的概率最大化。在我看来，以下未知参数的估计量更自然（鉴于Glivenko – Cantelli定理）：
说我们的模型遵循分布 $ f _ {\ theta_0} $ ，它是分布家族的成员 $ $ \ {f _ {\ theta} \} _ {\ theta \ in I} $ 。 Say  $ x_1，x_2，x_3，... $ 是IID，并关注Distribution  $ f _ {\ theta_0} $ &lt; /span&gt;（so  $ \ theta_0 $ 是true参数）。一个人可以寻找估算器 $ \ hat {\ theta} _n（x_1，x_2，...，...，x_n）$ 定义为 $ \ theta $ 使分布 $ f _ {\ theta} $ 最近 $ x_1，x_2，..，x_n $ 的经验分布，数学范围“&gt; $ l^2 $  Sense）。文献中是否探索过该估计器？它具有合理的属性吗？为什么MLE估计器比我描述的估计器更有利？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/661174/is-this-a-possible-alternative-to-maximum-likelihood-estimation</guid>
      <pubDate>Mon, 10 Feb 2025 09:32:52 GMT</pubDate>
    </item>
    <item>
      <title>分层COX模型：为什么对重采样数据的C索引比明显的C索引更好（Tidymodels和审查的R软件包）？</title>
      <link>https://stats.stackexchange.com/questions/661185/stratified-cox-model-why-is-c-index-on-resampled-data-better-than-apparent-c-in</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661185/stratified-cox-model-why-is-c-index-on-resampled-data-better-than-apparent-c-in</guid>
      <pubDate>Mon, 10 Feb 2025 07:53:22 GMT</pubDate>
    </item>
    <item>
      <title>如何确定偏斜的引导分布的平均值和95％置信区间</title>
      <link>https://stats.stackexchange.com/questions/661165/how-to-determine-the-mean-and-95-confidence-interval-of-a-skewed-bootstrapped-d</link>
      <description><![CDATA[我已经引导了我的数据1000（甚至是10,000），但是此引导分布偏斜，因此真实的组平均值与分布的模式更为一致，而不是平均值。。
在忠于真实群体的含义的同时，如何报告平均值和CI？我可以报告模式吗？
下面的编辑以具体示例阐明我的确切方法：
我正在使用线性SVM在两个变量（来自脑电图数据）之间解码。从20个受试者中，我有一个来自每个条件的解码精度迹线。在这里，解码精度跟踪是每个时间点的％精度（例如，从0到1000ms）。我的目的是测试我可以及时解码的条件（A或B）。
统计测试1：首先，要测试解码精度是否超过了小组级别的机会（对于条件A＆amp; b，分别），我执行基于置换的群集大小的推断。简而言之，我通过将每个样本解码精度输出乘以+1或-1来生成无效分布（设置为50％的机会水平）来缩小样品标签。然后，确定最早的有意义的时间点（即开始时间）。
统计测试2：然后，要测试哪个条件（a或b）具有较早的发作时间，请通过随机进行替换来进行1000次引导数据集。这种方法背后的理由是在两个发病时间之间进行了强有力的统计比较。我不能直接使用发作时间来强烈主张两个条件之间的差异，因为它们是奇异的值，并且不反映基本的分布。参见Sassenhagen和Draschko，心理生理学。 2019; 56：e13335 。
因此，我用更换随机对20次进行样品，执行上述定义的统计测试，并保存第一个重要的时间点。重复此过程1000次后，我的发作时间分布（我计划从中得出平均自举的发作时间和置信区间）。
但是，第二个测试中的发作时间的分布并不正态分布，因此自举的发作时间的平均值与基于群集的置换测试的起始时间不符合。我应该期望在更清洁的数据中有正态分布吗？如果结果是真实的，我可以报告模式+/- CI，而不是均值+/- CI，以说明数据的偏差？
我希望这是有道理的。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661165/how-to-determine-the-mean-and-95-confidence-interval-of-a-skewed-bootstrapped-d</guid>
      <pubDate>Sun, 09 Feb 2025 21:35:46 GMT</pubDate>
    </item>
    </channel>
</rss>