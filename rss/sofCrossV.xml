<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title></title>
    <link>https://stats.stackexchange.com/questions</link>
    <description></description>
    <lastBuildDate>Wed, 22 Jan 2025 18:22:55 GMT</lastBuildDate>
    <item>
      <title>在神经网络开始时权重的更新是否较少？</title>
      <link>https://stats.stackexchange.com/questions/660387/do-weights-update-less-towards-the-start-of-a-neural-network</link>
      <description><![CDATA[也就是说，因为错误来自神经网络的末端（即在输出层）并且通过反向传播回流到神经网络的开始处，这是否意味着靠近末端的权重比开始处的权重变化更大。这是真的吗？如果是，我该如何证明？
更一般地说，相对于网络层，权重增量的分布是怎样的？
直觉上，我认为这对于梯度下降（左）是正确的，但对于符号梯度下降（右）不正确：

最后发现 nanogpt 使用符号梯度下降比 AdamW 训练得更快：https://github.com/nullonesix/sign_nanoGPT
我想知道我的直觉是否可以被证明是正确的（如果是的话）。在此先感谢大家对这个话题的任何其他直觉或资源。]]></description>
      <guid>https://stats.stackexchange.com/questions/660387/do-weights-update-less-towards-the-start-of-a-neural-network</guid>
      <pubDate>Wed, 22 Jan 2025 18:10:55 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://stats.stackexchange.com/questions/660386/connections-between-subset-selection-success-and-logistic-distributions</link>
      <description><![CDATA[我是统计学新手，所以如果我遗漏了一些显而易见的东西，请不要起诉我。我最近在做一项作业，任务是分析以下带有子集选择的模型：
$$
y_i = \beta_1 x_{1, i} + \beta_2 x_{2,i} + \beta_3 x_{3,i} + \beta_4 x_{4,i} + u_i
$$
其中
$$(x_{k,i})_{k=1}^4 \sim \mathcal{N}(0, \Sigma)$$
$$
\Sigma = 
\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; \gamma &amp; \gamma\\
0 &amp; \gamma &amp; 1 &amp; \gamma\\
0 &amp; \gamma &amp; \gamma &amp; 1
\end{pmatrix}
$$
其中 $\gamma \in [-1, 1]$。此外，我们有 $\beta_2 = \beta_3 = \beta_4 = 2$，并且 $\beta_1 &gt; 2$。最后，$u_i$ 是 i.i.d。正态分布，均值为零，方差为 2，$i = 1, \ldots, N$。
我们的任务是确定 $\gamma$ 和 $\beta_1$ 的阈值，对于这些阈值，子集选择（子集大小等于 $1$）正确识别出最重要的协变量，即 $\beta_1$。
在此过程中，我设法得出以下曲线，对于 $N = 500$，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线。 class=&quot;math-container&quot;&gt;$\gamma = 0$ 第二个。
$\gamma$&quot; /&gt;
$\beta$&quot; /&gt;
在我看来，这些看起来非常符合逻辑！因此，我运行了一个简单的逻辑曲线拟合，模型如下：
$$
f(x) = \frac{A}{1 + \exp(-k(x - x_0))}
$$
我管理了以下参数
最适合 gamma 的逻辑函数是： 
A = 1.0011916177515001, x0 = 0.46613345213429164, k = -25.287773424878644
99% 置信区间： 
[[ 0.99834479 1.00403845]
[ 0.46495465 0.46731225]
[-25.94535303 -24.63019382]]
最适合 beta 的逻辑函数是： 
A = 1.0008861957715565, x0 = 4.131595820642967, k = 6.469500267867452
99% 置信区间： 
[[0.99799143 1.00378096]
[4.12631938 4.13687226]
[6.27646573 6.66253481]]

使用以下图表（不提供信息，只是漂亮）：


我不完全理解如何测量非线性最小二乘的拟合优度，但这些是非常严格的置信区间，所以这最终引出了我的问题。
这种行为有一个很好的理论解释吗？看来，正确识别具有子集选择的协变量的概率是具有这些神奇参数的逻辑分布。事实确实如此吗？它是渐近逻辑的吗？这实际上只是一个正态分布（我在写这篇文章时意识到了这一点）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660386/connections-between-subset-selection-success-and-logistic-distributions</guid>
      <pubDate>Wed, 22 Jan 2025 18:06:40 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯理论认为将结果而不是协变量作为似然函数中的数据的理由是什么？</title>
      <link>https://stats.stackexchange.com/questions/660385/what-is-the-bayesian-justification-for-considering-the-outcome-but-not-the-covar</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660385/what-is-the-bayesian-justification-for-considering-the-outcome-but-not-the-covar</guid>
      <pubDate>Wed, 22 Jan 2025 17:38:38 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://stats.stackexchange.com/questions/660383/computing-or-estimating-marginal-likelihood-of-lasso-model</link>
      <description><![CDATA[我有一个 LASSO 模型，想根据该模型计算某些数据的可信度。边际似然是一种理论上非常“干净”的方法。是否有任何简单的闭式表达式来表示边际似然积分，而不需要对（可能非常大的）字典进行积分？
或者，我很乐意得到一些边际似然的估计值，只要知道这个估计值相当接近。这可能是：

已知与边际似然有某种关系的其他标量
已知可以很好地近似真实边际似然积分值的某种积分技术
其他任何东西

如果有其他代表“可信度”的量，我也会很高兴这在这里就足够了吗（MLE 的可能性）？
最后，当然，LASSO 已经从一种近似中构建出来了，因此如果有任何其他稀疏线性模型可以更容易地计算边际似然，我会很感兴趣。]]></description>
      <guid>https://stats.stackexchange.com/questions/660383/computing-or-estimating-marginal-likelihood-of-lasso-model</guid>
      <pubDate>Wed, 22 Jan 2025 16:51:25 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://stats.stackexchange.com/questions/660382/using-andorson-darling-hypothesis-test</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660382/using-andorson-darling-hypothesis-test</guid>
      <pubDate>Wed, 22 Jan 2025 16:35:51 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://stats.stackexchange.com/questions/660379/separating-interaction-and-main-effects-in-generalized-additive-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660379/separating-interaction-and-main-effects-in-generalized-additive-models</guid>
      <pubDate>Wed, 22 Jan 2025 15:13:10 GMT</pubDate>
    </item>
    <item>
      <title>数据集内规范化之后的跨数据集规范化</title>
      <link>https://stats.stackexchange.com/questions/660377/cross-dataset-normalization-following-within-dataset-normalization</link>
      <description><![CDATA[我一直在研究几个大型数据集，它们使用不同的方法来测量某些化学物质。例如，在一个数据集中，代表化合物 1 的值的范围可能是 10E⁴ 到 10⁵，而另一个可能是 50 - 100。到目前为止，我已经分别处理了这些数据集，并在数据集内使用了对数转换和中心缩放。我现在想问一个可以通过合并数据集来回答的问题。
我的问题是 - 为了合并所有数据集，将它们作为一个大组再次缩放是否有意义？或者我是否通过单独执行此操作有效地批量校正了数据集？
编辑：通过合并，我的意思是将数据表合并到一个大型数据集中以执行下游分析，例如聚类。]]></description>
      <guid>https://stats.stackexchange.com/questions/660377/cross-dataset-normalization-following-within-dataset-normalization</guid>
      <pubDate>Wed, 22 Jan 2025 14:09:27 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://stats.stackexchange.com/questions/660376/assessing-my-linear-mixed-effects-model-diagnostics</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660376/assessing-my-linear-mixed-effects-model-diagnostics</guid>
      <pubDate>Wed, 22 Jan 2025 13:22:27 GMT</pubDate>
    </item>
    <item>
      <title>是否存在具有协方差矩阵参数的典型多元离散分布？</title>
      <link>https://stats.stackexchange.com/questions/660374/is-there-a-canonical-multivariate-discrete-distribution-with-a-covariance-matrix</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660374/is-there-a-canonical-multivariate-discrete-distribution-with-a-covariance-matrix</guid>
      <pubDate>Wed, 22 Jan 2025 12:04:04 GMT</pubDate>
    </item>
    <item>
      <title>唯一名称的数量遵循什么分布？</title>
      <link>https://stats.stackexchange.com/questions/660372/what-distribution-does-the-number-of-unique-names-follow</link>
      <description><![CDATA[我有 $N$ 个信封，每个信封里都有一张写有名字的便条。有些名字出现在多张便条上。总共有 $X$ 个唯一名字。
为了找出 $X$ 是什么，我打开 $n$ 个信封，找到 $x$ 个唯一名字。
基于此，唯一名字的实际数量遵循什么统计分布？期望值和标准差是多少？
我的直觉告诉我 $E(X) = x(N/n)^2$，但我不知道这是否正确，我想知道完整的分布，而不仅仅是期望值。
编辑：我不知道姓名计数遵循什么分布。但我知道在我打开的信封中重复了多少次。如果有帮助的话，可以假设单个姓名的最大出现次数比 $N$ 小得多（&lt;1%）。]]></description>
      <guid>https://stats.stackexchange.com/questions/660372/what-distribution-does-the-number-of-unique-names-follow</guid>
      <pubDate>Wed, 22 Jan 2025 11:25:23 GMT</pubDate>
    </item>
    <item>
      <title>确保回归参数估计值始终为正</title>
      <link>https://stats.stackexchange.com/questions/660343/making-sure-that-a-regression-parameter-estimate-is-always-positive</link>
      <description><![CDATA[我有兴趣了解如何完成以下任务：

假设我有两个变量 $X_t$ 和 $Y_t$ 的月度数据。我有兴趣为 $Y_t$ 创建一个 ARIMAX 模型，该模型依赖于 $Y_t$ 和 $X_t$ 的旧版本。我可以像这样编写基本的 ARIMAX 模型：
$$ y_t = c + \phi_1y_{t-1} + \beta x_t + \epsilon_t $$
但是，我希望此模型具有以下属性：假设其他所有条件都相同，$X_t$ 的较大值必须产生 $Y_t$ 的较大值，而 $X_t$ 的较小值则不能产生。从数学上讲，我认为这可以理解为 $\beta$ 必须始终为正。我希望模型尊重这一事实。
$$ \frac{\partial y_t}{\partial x_t} = \beta &gt; 0 $$
$$ y_t = c + \phi_1y_{t-1} + \beta x_t + \epsilon_t $$
$$ \text{subject to: } \beta &gt; 0 $$
我想知道我们如何在模型中强制执行这一点。我天真地想到了两种方法：


基本约束：我不确定如何为这个 ARIMAX 模型写出基本可能性，但它应该是这样的：

$$ L(c, \phi_1, \beta|\textbf{y},\textbf{x}) $$
如果我希望 $\beta$ 为正，我应该能够写出一个受约束的可能性并使用拉格朗日函数来解决这个问题：
$$ \log L(c, \phi_1, \beta|\textbf{y},\textbf{x}) $$
$$ \beta \geq \epsilon $$
$$ \mathcal{L} = \log L(c, \phi_1, \beta|\textbf{y},\textbf{x}) + \lambda(\beta - \epsilon) $$

贝叶斯方法：我认为，如果我策略性地选择先验，我就可以确保 $\beta$ 始终为正。使用贝叶斯原理，我写了联合先验和后验：

$$ P(\theta) = P(\beta)P(c)P(\phi_1)P(\sigma^2) $$
$$ P(\theta|\textbf{y},\textbf{x}) = \frac{L(\theta|\textbf{y},\textbf{x})P(\theta)}{\int L(\theta|\textbf{y},\textbf{x})P(\theta)d\theta} $$
然后在$\beta$上，我可以放置一个先验，例如半正态（https://en.wikipedia.org/wiki/Half-normal_distribution) 以确保正性，但我不确定要使用哪些其他分布作为其他参数的先验。我认为 $\sigma^2$ 上的先验也需要是具有正支持的分布，因为方差不能为负。

我不确定这些方法是否可行且合乎逻辑。社区能否就此提供一些建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/660343/making-sure-that-a-regression-parameter-estimate-is-always-positive</guid>
      <pubDate>Tue, 21 Jan 2025 21:16:28 GMT</pubDate>
    </item>
    <item>
      <title>如何比较组内前后的比例？</title>
      <link>https://stats.stackexchange.com/questions/660338/how-to-compare-proportions-for-before-after-within-groups</link>
      <description><![CDATA[我有 4 个阵列，每个阵列有多个站点，我们在每个阵列的 100 个点中收集了主要基质类型（SS 或 LL）。因此，我在每个站点中标记了 100 个点的比例。
我们进行了两次此测试（一次在 1990 年代，一次在今年）。我想测试每个阵列（多个站点）中每种土壤类型的比例是否在不同年份（1990 年代与今天）之间有所不同。考虑到每个阵列中都有成对（前后站点），我不确定是否应该使用卡方检验或其他方法？
percsub 列表示被视为基质的点数/100，其中 100 是每个站点的点数（其中一些数字对于 percsub 来说可能是错误的，因为我不得不更改一些数据以不公开发布实际收集的数据）。因此第一行表示，在阵列 AC 和站点 1，我们发现 LL 基质在 2024 年占点的 60%。



阵列
站点
基质
percsub
时间




AC
1
LL
0.6
今天


AC
1
SS
0.4
今天


AC
2
LL
0.6
今天


AC
2
SS
0.4
今天


AC
3
LL
0. 7
今天


AC
3
SS
0.1
今天


LC
5
LL
0.91
今天


LC
8
LL
0.84
至天


LC
8
SS
0.1
今天


LC
14
LL
0.94
今天


LC
15
LL
0.87
今天


LC
16
LL
0.89
今天


LC
17
LL
0.84
今天


LC
17
SS
0.15
今天


SJHW
14
LL
0.95
今天


SJHW
14
SS
0.05
今天


SJHW
16
LL
0.77
今天


SJHW
16
SS
0.23
今天


SJHW
17
LL
0.91
今天


SJHW
17
SS
0.08
今天


WC 
11
LL
0.58
今天


WC
11
SS
0.37
今天


WC
12
LL
0.6
今天


WC
 12
SS
0.38
今天


AC
1
LL
0.7
1990 年代


AC
1
SS
0.3
1990 年代


AC
2
LL 
0.39
1990 年代


AC
2
SS
0.61
1990 年代


AC
3
LL
0.25
1990 年代


AC
3
SS
0. 75
1990 年代


LC
5
LL
0.35
1990 年代


LC
8
LL
0.59
1990 年代


LC
8
SS
0.38
 1990 年代


LC
14
LL
0.6
1990 年代


LC
15
LL
0.39
1990 年代


LC
16
LL
0.5
1990 年代


LC
17
LL
0.63
1990 年代


LC
17
SS
0.3
1990 年代


SJHW
14
LL
0.87
1990 年代


SJHW
14
SS
0.13
1990 年代


SJHW
16
LL
0.71
1990 年代


SJHW
16
SS
0.29
1990 年代


SJHW
17
LL
0.8
1990 年代


SJHW
17
SS
0.13
1990 年代


WC
11
LL
0.46
1990 年代


WC 
11
SS
0.4
1990 年代


WC
12
LL
0.49
1990 年代


WC
12
SS
0.2
1990 年代


]]></description>
      <guid>https://stats.stackexchange.com/questions/660338/how-to-compare-proportions-for-before-after-within-groups</guid>
      <pubDate>Tue, 21 Jan 2025 19:43:41 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://stats.stackexchange.com/questions/660263/issues-with-survival-regression-in-r-handling-non-censored-data-and-model-conve</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660263/issues-with-survival-regression-in-r-handling-non-censored-data-and-model-conve</guid>
      <pubDate>Mon, 20 Jan 2025 09:37:55 GMT</pubDate>
    </item>
    <item>
      <title></title>
      <link>https://stats.stackexchange.com/questions/660258/part-2-why-does-the-survival-function-always-decrease-with-time</link>
      <description><![CDATA[我发布了这个问题为什么生存函数总是随着时间的推移而减少？，我得到了一个非常好的答案（https://stats.stackexchange.com/a/660245/455511）解释了为什么生存函数总是随着时间的推移而减少：

是的，随着时间的推移，幸存疾病的概率会增加，
但这不是生存函数。生存函数
会每次告诉你在指定的较早时间患有该疾病的人中有多少人仍然存活下来。

我可以看到风险函数可以随时间增加和减少。例如，对于对数正态分布，风险函数可以随时间增加和减少（对数正态风险的公式是什么？）。我可以在这里看到这一点（https://devinincerti.com/2019/06/18/parametric_survival.html）。
我想知道：即使生存函数本身总是随着时间的推移而减少，生存模型（例如 AFT、Cox-PH）是否可以表明，患病后存活的概率实际上可能（暂时）随着时间的推移而增加？
例如，想象一种疾病通常会在第一年杀死人（即死亡概率很高），但如果它没有杀死你，那么身体就会适应变得更有弹性，因此死亡的概率就会降低……而死亡的概率只有在多年后才会再次增加。我理解风险函数可能能够更自然地捕捉这种行为，但我想知道生存模型是否可以通过概率而不是风险来描述这种现象？
我想也许可以使用条件生存概率来实现？典型的生存函数是生存超过一定时间$t$的概率，即$S(t) = P(T &gt; t)$。但是由于条件生存概率定义为：
$$P(T &gt; t | T &gt; s) = \frac{S(t)}{S(s)}$$
但是似乎条件生存概率必须始终随时间减少？

设 $s &lt; t_1 &lt; t_2$。考虑：
$$P(T &gt; t_2|T &gt; s) &gt; P(T &gt; t_1|T &gt; s)$$
使用定义：$$\frac{S(t_2)}{S(s)} &gt; \frac{S(t_1)}{S(s)}$$
将两边乘以 $S(s)$：$$S(t_2) &gt; S(t_1)$$
由于 $t_2 &gt; t_1$，且生存函数 $S(t)$ 单调递减：$$S(t_2) &lt; S(t_1)$$
这与我们的假设相矛盾。
因此：$$P(T &gt; t_2|T &gt; s) &lt; P(T &gt; t_1|T &gt; s)\ \text{for}\ t_2 &gt; t_1$$

我很困惑：似乎条件生存概率也必须随时间减少？


条件生存概率的推导：

$$P(T &gt; t|T &gt; s) = \frac{P(T &gt; t \cap T &gt; s)}{P(T &gt; s)}$$
$$P(T &gt; t \cap T &gt; s) = P(T &gt; t) \quad \text{when } t &gt; s$$
$$P(T &gt; t|T &gt; s) = \frac{P(T &gt; t \cap T &gt; s)}{P(T &gt; s)} = \frac{P(T &gt; t)}{P(T &gt; s)}$$
由于 $S(t) = P(T &gt; t)$，因此：
$$P(T &gt; t|T &gt; s) = \frac{S(t)}{S(s)}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660258/part-2-why-does-the-survival-function-always-decrease-with-time</guid>
      <pubDate>Mon, 20 Jan 2025 03:47:17 GMT</pubDate>
    </item>
    <item>
      <title>证明 LDA 目标函数 $w^T \Sigma_b w / w^T \Sigma_w w$ 最大化平方配对马哈拉诺比斯距离</title>
      <link>https://stats.stackexchange.com/questions/660113/prove-that-lda-objective-wt-sigma-b-w-wt-sigma-w-w-maximizes-squared-pai</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660113/prove-that-lda-objective-wt-sigma-b-w-wt-sigma-w-w-maximizes-squared-pai</guid>
      <pubDate>Thu, 16 Jan 2025 15:25:24 GMT</pubDate>
    </item>
    </channel>
</rss>