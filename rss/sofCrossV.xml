<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 29 Sep 2024 15:17:51 GMT</lastBuildDate>
    <item>
      <title>组成数据中的零值和使用狄利克雷分布的问题到底是什么？</title>
      <link>https://stats.stackexchange.com/questions/655075/what-exactly-is-the-issue-with-zero-values-in-compositional-data-and-using-the-d</link>
      <description><![CDATA[因此，Aitchison 描述了零值的问题，即无法对这些数字取对数。但他也解释说，如果只有少量的零，我们可以简单地用一个小数字替换它们。他警告说，选择如此小的值可能会影响结果。我有两个问题：

为什么我们不能只取最小的可用数字（R 中的机器 epsilon）？
为什么无论有多少个零都不能使用这种方法？

这篇论文已经过时了，但最近仍然被引用来描述使用狄利克雷建模时与零值相关的问题。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655075/what-exactly-is-the-issue-with-zero-values-in-compositional-data-and-using-the-d</guid>
      <pubDate>Sun, 29 Sep 2024 14:56:09 GMT</pubDate>
    </item>
    <item>
      <title>非线性多模态模型的高维贝叶斯推断</title>
      <link>https://stats.stackexchange.com/questions/655073/bayesian-inference-in-high-dimension-for-a-non-linear-multimodal-model</link>
      <description><![CDATA[考虑以下模型：我正在以概率 $p$ 抽样伯努利变量，其概率为
\begin{equation}
p(\omega_i, \tau) := \frac{1}{2} + \frac{1}{2 n} \left[ \sum_{i=1}^{n} \cos (\omega_i \tau) \right] \; .
\end{equation&gt;
目标是通过观察伯努利变量的许多样本来找到 $\omega_i$ 的后验分布。对于较大的 $n$，这将成为高维非线性问题。此外，由于 $\omega_i$ 的置换对称性，预计后验分布将是多峰的。为了打破 $\omega_i$ 中的退化，必须使用不同的 $\tau$ 值进行测量。如前所述，我的目标是根据一系列观察到的样本计算 $\omega_i$ 的后验分布。我尝试过粒子过滤（即连续蒙特卡罗），但对于 $n=10$，问题变得难以解决，后验分布无法收敛到真实值。我可以使用一个好的 GPU，并希望实现一种快速贝叶斯推理技术，该技术可以在需要时提供后验的粗略估计，但也允许更多时间密集型计算以收敛到真实后验。
当 MCMC 太慢时，解决这个问题的好方法是什么？使用正则化流的变分贝叶斯推理似乎是一个潜在的解决方案，但它需要对后验有一个好的假设，由于多模态性，这很难获得。]]></description>
      <guid>https://stats.stackexchange.com/questions/655073/bayesian-inference-in-high-dimension-for-a-non-linear-multimodal-model</guid>
      <pubDate>Sun, 29 Sep 2024 14:17:30 GMT</pubDate>
    </item>
    <item>
      <title>有/无交互作用的 GEE 模型 - 解释</title>
      <link>https://stats.stackexchange.com/questions/655071/gee-model-with-without-interaction-interpretation</link>
      <description><![CDATA[我在治疗期间（在几个时间点）测量了一种新的生物标志物。所有患者的临床数据都在基线时存在。现在，我正在使用 GEE 模型和探索性方法来识别在治疗期间对生物标志物有影响的临床变量。
我在单独的 GEE 模型中测试了每个临床变量，生物标志物是因变量，并在模型中采用因子时间和临床变量。
我还以相同的方式测试了每个临床变量，但还包括时间和临床变量之间的相互作用。现在我不明白为什么有些临床变量具有主效应，但包括交互时间/临床变量后，其他具有主效应的临床变量也出现了。
哪种方法最适合识别对生物标志物有影响的临床变量 - 使用仅包含因子时间和临床变量的模型，还是我始终必须包括相互作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/655071/gee-model-with-without-interaction-interpretation</guid>
      <pubDate>Sun, 29 Sep 2024 10:23:51 GMT</pubDate>
    </item>
    <item>
      <title>Maxout 激活函数与 ReLU（权重数量）</title>
      <link>https://stats.stackexchange.com/questions/655067/maxout-activation-function-vs-relu-number-of-weights</link>
      <description><![CDATA[据我了解，Maxout 函数的工作原理与 ReLU 完全不同。
ReLU 函数是 max(0, x)，因此输入 x 是 (W_T x + b)
Maxout 函数有许多 W，它是 max(W1_T x + b1, W2_T x + b2, ...)
我理解 ReLU 函数在函数中没有感知器的权重，但 Maxout 函数在函数中有权重。 （并且有更多参数）
我理解得对吗？
许多激活函数，例如 ReLU、Sigmoid、tanh、Leaky ReLU 都使用标量值，这是一个已经计算出的值 (W_T x + b)
Maxout 函数与此不同，对吗？
Softmax 函数层没有权重吗？
那么从激活函数的变化来看，权重的数量可以改变吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655067/maxout-activation-function-vs-relu-number-of-weights</guid>
      <pubDate>Sun, 29 Sep 2024 04:23:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有样本偏差的情况下进行超参数调整？</title>
      <link>https://stats.stackexchange.com/questions/655064/how-to-hyperparameter-tune-without-sample-bias</link>
      <description><![CDATA[在寻找微调模型超参数 (HP) 的方法时，我发现了多个关于交叉验证技术 (K-folds、LPO、OOB.632+) 和选择最佳超参数组合的方法 (网格搜索、随机搜索等) 的参考资料。许多人说要使用嵌套交叉验证技术来估计模型的一些质量指标，但没有人解释如何选择最终模型将使用的超参数。
我能找到的最好的文章是有关嵌套交叉验证 (nCV) 或甚至是用于特征选择的 nCV 变体的文章，这将带来相同的模型选择问题。但是这种方法不提供一组唯一的超参数，而是为 CV 技术创建的每个折叠提供多个超参数。
我试图思考的是使用每个折叠的训练集的最佳超参数组合，并在某种类型的投票系统中考虑它们的平均质量指标和它们的“最佳组合出现”率，以确定哪种组合是最佳的，然后使用所有测试集估计所选超参数的质量指标，但我不确定这是否会导致无偏的 HP 选择和质量估计。
你有什么文章或解释可能有用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655064/how-to-hyperparameter-tune-without-sample-bias</guid>
      <pubDate>Sat, 28 Sep 2024 23:14:32 GMT</pubDate>
    </item>
    <item>
      <title>在线性混合效应模型中，随机效应的估计条件模式是否遵循 MVN？</title>
      <link>https://stats.stackexchange.com/questions/655058/do-estimated-conditional-modes-of-random-effects-follow-a-mvn-in-a-linear-mixed</link>
      <description><![CDATA[在教程 GLMM 示例 中提供的 示例中，线性混合效应模型与苔原生态系统的数据（来自 Belshe et al., 2013）拟合，具有以下规范：
cmod_lmer &lt;- lmer(GS.NEE ~ cYear + (1+cYear|Site),
data=mc2B, REML=TRUE,
weights=n)

本教程后面会提出以下建议：

您可以使用 qqmath() 代替 dotplot() 来获取 条件模式的 Q-Q 图。 [强调添加]

我理解，随机效应，无条件和有条件（给定观察到的响应）具有多元正态分布（请参阅为什么假设随机效应遵循正态分布，或这些幻灯片中的第 3.4 节，第 173 页，作者：Dimitris Rizopoulos）。
我从上面提到的建议中推断出，模型中随机效应的条件模式（或均值）的估计值应遵循多元正态（MVN）分布，因此，我们应该检查如果 qqmath(ranef(...)) 确实如此。但是，在线性混合效应模型的公式化中，从未明确假设随机效应的条件模式应具有多元正态分布，对吗？那么使用估计值的 Q-Q 图背后的动机是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655058/do-estimated-conditional-modes-of-random-effects-follow-a-mvn-in-a-linear-mixed</guid>
      <pubDate>Sat, 28 Sep 2024 20:52:25 GMT</pubDate>
    </item>
    <item>
      <title>brms 中的 Priors 并未按我预期的那样工作</title>
      <link>https://stats.stackexchange.com/questions/655043/priors-in-brms-are-not-working-as-i-expect</link>
      <description><![CDATA[我是贝叶斯统计的新手，我正在尝试使用 brms 拟合一个简单的线性回归并手动设置每个参数的先验，但它并没有像我预期的那样工作
这是我的代码
data_2 &lt;- structure(list(YearsExperience = c(1.1, 1.3, 1.5, 2, 2.2, 2.9, 3, 3.2, 3.2, 3.7, 3.9, 4, 4, 4.1, 4.5, 4.9, 5.1, 5.3, 5.9, 6, 
6.8, 7.1, 7.9, 8.2, 8.7, 9, 9.5, 9.6, 10.3, 10.5), Salary = c(39343L, 
46205L, 37731L, 43525L, 39891L, 56642L, 60150L, 54445L, 64445L, 
57189L, 63218L, 55794L, 56957L, 57081L, 61111L, 67938L, 66029L, 
83088L, 81363L, 93940L, 91738L, 98273L, 101302L, 113812L, 109431L, 
105582L, 116969L, 112635L, 122391L, 121872L)), class = &quot;data.frame&quot;, row.names = c(NA, 
-30L))

priors &lt;- c(
set_prior(&quot;normal(28700, 2000)&quot;, class = &quot;Intercept&quot;),
set_prior(&quot;normal(9006, 1000)&quot;, class = &quot;b&quot;, 
coef = &quot;YearsExperience&quot;),
set_prior(&quot;normal(0, 2000)&quot;, class = &quot;sigma&quot;, lb = 0) 
)

fit_brms &lt;- brm(Salary ~ YearsExperience, data = data_2, Prior=priors)

但是，当我绘制链时，例如，当先验分布远离负值时进行截距。而且我设置的先验并非完全不准确。

如果我使用默认先验进行拟合，效果很好。]]></description>
      <guid>https://stats.stackexchange.com/questions/655043/priors-in-brms-are-not-working-as-i-expect</guid>
      <pubDate>Fri, 27 Sep 2024 21:16:13 GMT</pubDate>
    </item>
    <item>
      <title>具有斜率函数的用户指定值的边际效应</title>
      <link>https://stats.stackexchange.com/questions/655041/marginal-effects-at-user-specified-values-with-slopes-function</link>
      <description><![CDATA[我在使用 marginaleffects 包的 slope 函数估计用户指定值的边际效应时遇到了麻烦
假设我想用帕尔默企鹅数据集预测 body_mass_g
library(marginaleffects)

dat &lt;- read.csv(
&quot;https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv&quot;)


这是我的函数。我想将 flipper_length 设置为 180，将 bill_length_mm  设置为 39 或 40。
mod.lm &lt;- lm(body_mass_g ~ bill_length_mm + flipper_length_mm + 
species, data = dat)

slopes(
mod.lm,
newdata = datagrid(
flipper_length_mm = 180,
bill_length_mm = c(39,40)))



我知道一些事情是错误的，因为所有预测因子的估计值都相同，无论 bill_length_mm 的值设置为 39 还是 40。
我尝试使用 glm 二元结果变量运行类似的模型，它按预期工作。
dat$large_penguin &lt;- ifelse(dat$body_mass_g &gt; 
median(dat$body_mass_g, na.rm = TRUE), 1, 0)

mod &lt;- glm(large_penguin ~ bill_length_mm + flipper_length_mm + 
species, data = dat, family = binomial)

slopes(
mod,
newdata = datagrid(
flipper_length_mm = 180,
bill_length_mm = c(39,40)))


为什么 lm 模型没有按预期执行，而 glm 模型却可以？]]></description>
      <guid>https://stats.stackexchange.com/questions/655041/marginal-effects-at-user-specified-values-with-slopes-function</guid>
      <pubDate>Fri, 27 Sep 2024 21:04:18 GMT</pubDate>
    </item>
    <item>
      <title>测试两个变量之间的关联强度随时间的变化</title>
      <link>https://stats.stackexchange.com/questions/654809/test-for-changing-strength-of-association-between-two-variables-across-time</link>
      <description><![CDATA[我想用纵向数据测试两个变量之间的弱化关联。
我有一项调查，用于衡量 2005 年至 2020 年期间每年对政府机构的信任度。我还有县级犯罪率数据。在此期间，大多数县的犯罪率都有所上升。毫不奇怪，犯罪率与对政府机构的信任度降低有关。
我的假设是，犯罪率和对政府机构的信任度之间的关联在几年内会减弱。换句话说，人们“习惯了”犯罪。因此，我应该能够追踪当地犯罪率和结果变量之间的关联如何随着时间的推移而减弱。我该如何测试这一点？最容易实现的策略是建立每年的横截面模型并比较感兴趣变量的 t 值。
请记住，这不是面板数据，而是汇总数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/654809/test-for-changing-strength-of-association-between-two-variables-across-time</guid>
      <pubDate>Tue, 24 Sep 2024 01:00:10 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯结构时间序列的优秀文献</title>
      <link>https://stats.stackexchange.com/questions/654752/good-literature-for-bayesian-structural-time-series</link>
      <description><![CDATA[我目前正在写一些关于时间序列分析的文章，包括一章关于贝叶斯结构时间序列的文章。我有数学背景，了解时间序列分析的基础知识，包括 ARMA 模型等。
你能推荐一些关于贝叶斯结构时间序列的文献（以数学理论为重点）吗？我对数学理论比对实现更感兴趣。我发现很难在互联网上找到好东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/654752/good-literature-for-bayesian-structural-time-series</guid>
      <pubDate>Mon, 23 Sep 2024 05:39:20 GMT</pubDate>
    </item>
    <item>
      <title>回归问题的预期误差减少</title>
      <link>https://stats.stackexchange.com/questions/654594/expected-error-reduction-for-regression-problems</link>
      <description><![CDATA[我想在 Python 中实现一种基于预期误差减少 (EER) 的主动学习方法：
https://axon.cs.byu.edu/Dan/778/papers/Active%20Learning/roy.pdf
https://arxiv.org/abs/2211.09283
对于回归问题，其中机器学习模型是基于树的模型（我计划使用 XGBoost、随机森林回归器或 VotingRegressor，它们只是平均输出我不需要使用贝叶斯推理框架，但如果有必要，我会使用它。目前，我有两个问题：

上述论文中的方程式非常复杂，没有伪代码。我不明白如何为 EER 编写损失函数，以及整体框架是什么。我的粗略理解是，为了计算这个损失，对于每个未标记的输入样本，我需要运行我的 ML 模型，计算每个可能标签在我的 ML 模型下的概率，然后用它来计算损失……但我错过了细节。
这些方程式是针对分类任务给出的。我实际上有一个回归任务。我如何使 EER 适应回归？我想我应该用积分代替对所有可能的标签值求和...因为我可以为输出变量给出上限和下限，高斯-勒让德数值积分可能是计算效率更高的方法。

如何实现基于 EER 的回归主动学习？包含 Python 代码/伪代码的答案是最好的，但即使只是对算法和要使用的方程式的详细解释也足够了（然后我可以尝试自己用 Python 实现它，如果遇到困难，请在 StackOverflow 上提问）。]]></description>
      <guid>https://stats.stackexchange.com/questions/654594/expected-error-reduction-for-regression-problems</guid>
      <pubDate>Thu, 19 Sep 2024 09:39:01 GMT</pubDate>
    </item>
    <item>
      <title>我如何确定我的生态 GLMM 是否构建准确？</title>
      <link>https://stats.stackexchange.com/questions/654219/how-do-i-determine-if-my-ecological-glmm-is-accurately-constructed</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654219/how-do-i-determine-if-my-ecological-glmm-is-accurately-constructed</guid>
      <pubDate>Wed, 11 Sep 2024 16:42:13 GMT</pubDate>
    </item>
    <item>
      <title>证明对数 Exp 的方差大于对数 Exp 的方差</title>
      <link>https://stats.stackexchange.com/questions/648034/prove-that-variance-of-log-exp-is-greater-than-variance-of-exp-log</link>
      <description><![CDATA[在变分推断的背景下，我们从估计梯度：
$\log E_{q \sim Q(z|x)} [ \frac{p(z,x)}{q(z|x)} ]$
到：
$E_{q \sim Q(z|x)} [ \log \frac{p(z,x)}{q(z|x)} ]$，即 ELBO。
我想明确比较蒙特卡洛估计量对这两个量梯度的方差，但我在代数方面遇到了困难。
通过蒙特卡洛估计量，我的意思是我们用每个期望中的随机变量的样本均值替换每个表达式中的期望。
你能帮忙？
参考文献：https://arxiv.org/pdf/2208.11970，第 3 页，方程 7-8
基本上我不明白为什么我们不最大化上述参考文献中的方程 7 而是方程 8。也许是因为方差较低，但如何严格地证明这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/648034/prove-that-variance-of-log-exp-is-greater-than-variance-of-exp-log</guid>
      <pubDate>Sun, 26 May 2024 22:05:18 GMT</pubDate>
    </item>
    <item>
      <title>寻找具有多个部分和不同尺度的损失函数的系数</title>
      <link>https://stats.stackexchange.com/questions/579487/finding-coefficients-for-a-loss-function-with-multiple-parts-and-different-scale</link>
      <description><![CDATA[我正在努力重复使用论文Pixel2Mesh++：通过变形生成多视图 3D 网格，该论文将 3D 网格变形以使其适合某些 2D 图像，但场景与原始场景不同。
损失函数由四个项组成：倒角损失、余弦损失、拉普拉斯正则化和边长正则化（此处说明）。
这四个项的尺度非常不同，而且有些不受约束，这意味着我无法使用最大值对它们全部进行归一化，如果我保持原样，其中一些将会丢失（哈哈）在优化中。更糟糕的是，并非所有损失部分都同等重要：例如，与正则化因子相比，倒角损失（最小化预期网格与实际网格之间的距离）在优化中应具有更高的权重。
在 github 存储库 中，发现一些系数可能或可能不是当前问题的最佳系数。我猜它们还不错，因为这是作者决定使用的。但是，用于查找这些系数的方法没有在任何地方解释（我甚至尝试打开有关此问题的 github 问题，但没有得到任何答案）。
现在，我已经在这里阅读了许多关于优化多损失优化和损失缩放问题的问题，但我仍然不知道如何处理找到最佳系数的问题。
我考虑过使用超参数优化器（如 Hyperband）来找到最佳系数，但显然会发生的情况是引擎采用每个系数的下限，导致损失很小，但结果并不更好。
我读到过使用平衡因子（如 $ \lambda*loss1 + (1 - \lambda)*loss2 $），但我认为这不能应用于超过两个损失。
最后，我尝试自己设置系数以获得更好的结果，但这看起来像是无休止的搜索。
所以，我的问题是：对于具有多个部分且并非所有部分都具有相同比例的损失函数，有哪些方法可以找到良好的系数？]]></description>
      <guid>https://stats.stackexchange.com/questions/579487/finding-coefficients-for-a-loss-function-with-multiple-parts-and-different-scale</guid>
      <pubDate>Tue, 21 Jun 2022 12:48:33 GMT</pubDate>
    </item>
    <item>
      <title>如果我使用 R 中的 wilcox.test 来处理配对数据，它到底返回什么？我想根据这个结果计算效应大小</title>
      <link>https://stats.stackexchange.com/questions/542165/if-i-use-the-wilcox-test-from-r-for-paired-data-what-exactly-it-returns-i-want</link>
      <description><![CDATA[我想计算成对 Wilcoxon（有符号秩）的效应大小。
有两个选项：Z/sqrt(N_pairs)
或秩-双列相关性。
wilcox.test(... paired=TRUE) 返回“V”。
文献中有很多字母：对于 Mann-Whitney（非成对），它要么是“U”，要么是“W” （取决于方法，即 Wilcoxon 方法），对于成对的 Wilcoxon，它是 Z 或 V。
在我的情况下，V = 0。
数据：
d &lt;- structure(list(PatientId = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L), .Label = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, 
&quot;8&quot;, &quot;9&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;), class = &quot;factor&quot;), 时间点 = 结构 (c(1L, 
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
2L, 1L, 2L, 1L, 2L, 1L, 2L), .标签 = c(&quot;基线&quot;, &quot;第 3 个月&quot;
), class = &quot;factor&quot;), 结果 = c(0, 9, 6, 8, 0, 0, 0, 0, 0, 0, 
0, 0, 1, 2, 3, 3, 1, 2, 1, 1, 3, 3, 7, 7)), row.names = c(NA, 
-24L), class = &quot;data.frame&quot;)

&gt; wilcox.test(结果 ~ 时间点，配对 = TRUE，数据 = d)

带连续性校正的 Wilcoxon 符号秩检验

数据：按时间点的结果
V = 0，p 值 = 0.1
备选假设：真实位置偏移不等于 0

警告消息：
1：在 wilcox.test.default(x = c(0, 6, 0, 0, 0, 0, 1, 3, 1, 1, 3, 7) 中，:
无法计算具有关系的精确 p 值
2：在 wilcox.test.default(x = c(0, 6, 0, 0, 0, 0, 1, 3, 1, 1, 3, 7) 中，:
无法计算具有零的精确 p 值

rank_biserial 不起作用：
&gt; rank_biserial(结果 ~ 时间点，配对 = TRUE，数据 = d)
r (等级 biserial) | 95% CI
----------------------------------
-1.00 | [-1.00, -1.00]
警告消息：
在 ranktransform.numeric((x - y) - mu, sign = TRUE, verbose = verbose) 中：
检测到零。这些不能进行符号等级转换。

但 rstatix 包实现返回了其他内容（匹配 wilcox.test 而没有连续性校正）：
coin::wilcoxsign_test(结果 ~ 时间点 | PatientId，数据=d，zero.method = &quot;Wilcoxon&quot;)

渐近 Wilcoxon 符号秩检验

数据：y x (pos, neg) 
按区块分层
Z = -2，p 值 = 0.07
备选假设：真 mu 不等于 0

&gt; wilcox.test(结果 ~ 时间点，配对 = TRUE，数据 = d，正确 = FALSE)

Wilcoxon 符号秩检验

数据：按时间点的结果
V = 0，p 值 = 0.07
备选假设：真实位置偏移不等于 0

警告消息：
1：在 wilcox.test.default(x = c(0, 6, 0, 0, 0, 0, 1, 3, 1, 1, 3, 7) 中，:
无法计算具有关系的精确 p 值
2：在 wilcox.test.default(x = c(0, 6, 0, 0, 0, 0, 1, 3, 1, 1, 3, 7) 中，:
无法计算具有零的精确 p 值

因此，“V”与“Z”？
在这种情况下，我可以使用 Z/sqrt(12) = 0.577 来计算效果大小，该值是中等到大（根据 Cohen 的说法）。
那么，是否有机会直接从 R 库 wilcox.test 获取 Z（并计算效果大小）？我想坚持使用基础库。]]></description>
      <guid>https://stats.stackexchange.com/questions/542165/if-i-use-the-wilcox-test-from-r-for-paired-data-what-exactly-it-returns-i-want</guid>
      <pubDate>Wed, 01 Sep 2021 11:05:27 GMT</pubDate>
    </item>
    </channel>
</rss>