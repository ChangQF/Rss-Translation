<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 18 Apr 2024 15:14:40 GMT</lastBuildDate>
    <item>
      <title>在训练集上训练的验证准确度比在验证集上训练的要高</title>
      <link>https://stats.stackexchange.com/questions/645316/validation-accuracy-higher-if-trained-on-training-set-than-in-validation-set</link>
      <description><![CDATA[所以，我在模型验证方面遇到问题，特别是，我正在尝试线性读取（附加到神经网络中间层的逻辑回归）
特别是，如果我在训练集上训练线性读数，并在验证集上进行评估，我会得到比在验证集上训练它并在验证集上评估更高的准确性
但是，对我来说这没有什么意义，因为从理论上讲，对数回归的损失是凸的，因此在验证集本身上训练它的准确性应该是最好的
我用来验证它的代码如下，我不明白为什么会发生这种情况：
# val 向前设置
val_data_ = []
val_targets_ = []
对于 k，枚举中的 val_data(tqdm(val_dataloader, desc=“val epoch”))：
    val_img = val_data[0].to(设备)
    idx = val_data[2]
    输出 = torch.zeros((val_img.size(0), ))
    对于范围内的 i(len(sex_target))：
        如果 idx[i] 在 some_set 中，则输出 [i] = 0，否则 1
    val_output_batch = 分类器(val_feature_batch)
    
    val_data_.append(val_feature_batch.cpu().detach().numpy())
    val_targets_.append(output.cpu().detach().numpy())
 # 火车向前行驶
 数据_ = []
 目标_ = []
 使用 torch.no_grad()：
     对于 m，枚举中的数据（tqdm（train_dataloader，desc =“train for val epoch”））：
         img = 数据[0].to(设备)
         输出 = torch.zeros((img.size(0), ))
         对于范围内的 i(len(sex_target))：
             如果 idx[i] 在 some_other_set 中，则输出 [i] = 0，否则 1
         data_.append(模型(img))
         Targets_.append(输出)

    data_ = np.concatenate([el.cpu().numpy() for el in data_], axis=0).astype(float)
    Targets_ = np.concatenate([el.cpu().numpy() for el in Targets_], axis=0).astype(float)

    val_data_ = np.concatenate(val_data_, axis=0).astype(float)
    val_targets_ = np.concatenate(val_targets_, axis=0).astype(float)

    val_clf = LogisticRegression(solver=&quot;newton-cholesky&quot;).fit(val_data_, val_targets_)
    train_clf = LogisticRegression(solver=&quot;newton-cholesky&quot;).fit(data_, Targets_)
    
    val_fair_from_train = Balanced_accuracy_score(val_targets_, train_clf.predict(val_data_))
    val_fair_from_val = Balanced_accuracy_score(val_targets_, val_clf.predict(val_data_))
    # val_fair_from_train 大多数时候都高于 val_fair_from_val
]]></description>
      <guid>https://stats.stackexchange.com/questions/645316/validation-accuracy-higher-if-trained-on-training-set-than-in-validation-set</guid>
      <pubDate>Thu, 18 Apr 2024 15:09:09 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用单向方差分析还是双向方差分析？</title>
      <link>https://stats.stackexchange.com/questions/645315/should-i-use-one-way-or-two-way-anova</link>
      <description><![CDATA[一共有八组处理，浓度不同，各有不同。最初，我们考虑使用双向方差分析，考虑的因素是 1. 实验设置的类型和 2. 不同的浓度。然而，浓度类型仅适用于实验设置，没有给对照组和其他组留下比较的空间。
实验处理：
处理A：浓度（50g、100g、150g）
处理B：浓度（50g、100g、150g）
我真正应该使用什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/645315/should-i-use-one-way-or-two-way-anova</guid>
      <pubDate>Thu, 18 Apr 2024 15:02:59 GMT</pubDate>
    </item>
    <item>
      <title>一系列事件的概率</title>
      <link>https://stats.stackexchange.com/questions/645314/probability-of-a-succession-of-events</link>
      <description><![CDATA[[这是我在这个网站上的第一个问题，我希望它在范围内，如果不在范围内，请原谅我。我也不太了解如何标记这个]
我没有统计学背景，希望有人能帮助我找到以下问题的答案。
假设一个事件成功的概率为 98%，并且该事件重复 X 次（比如 300），每个事件都与之前的事件无关。这些 X 事件中 99% 以上成功的概率是多少？理想情况下，问题中的每个数字（98%、300、99%）都是可以更改的变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/645314/probability-of-a-succession-of-events</guid>
      <pubDate>Thu, 18 Apr 2024 14:59:15 GMT</pubDate>
    </item>
    <item>
      <title>了解渐近相对效率以及如何计算它</title>
      <link>https://stats.stackexchange.com/questions/645310/understanding-asymptotic-relative-efficiency-and-how-to-compute-it</link>
      <description><![CDATA[我正在课堂上学习渐近相对效率 (ARE)，并且我正在尝试准确理解如何计算 ARE。根据我的理解，渐近相对效率是指当我们假设采用无限数量的样本并且它们都收敛到正态分布且各自具有各自的方差时，比较两个估计量的效率。因此，我们通过比较它们的方差之比来计算 ARE。如何计算每一项的方差？我正在考虑应用 delta 方法来表明它的分布收敛于正态分布，并从它们获得的方差进行比较，但想知道是否还有其他方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/645310/understanding-asymptotic-relative-efficiency-and-how-to-compute-it</guid>
      <pubDate>Thu, 18 Apr 2024 14:29:33 GMT</pubDate>
    </item>
    <item>
      <title>我能否根据 Kaplan Meier 的 5 年生存率推断死亡人数 (n_event)？</title>
      <link>https://stats.stackexchange.com/questions/645308/can-i-extrapolate-number-of-deaths-n-event-from-5-year-survival-kaplan-meier</link>
      <description><![CDATA[假设阴性切缘组有 52 名患者，阳性切缘组有 24 名患者。我收到了关于生存率的声明：“与阴性切缘组（5 年生存率 61）相比，阳性切缘组的总体生存率（5 年生存率 70%，95CI 44%−85%）相似%，95CI 45%-75%)； p=.266”

我可以知道 5 年内有多少人死亡 (n_event) 吗？
因为论文中写道“研究期间有 29 名患者（38%）死亡。”死亡患者中，有16人死亡
5 年随访之前。”
如果我使用给定的百分比，我得到的数字是 28。
我理解这些百分比的含义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645308/can-i-extrapolate-number-of-deaths-n-event-from-5-year-survival-kaplan-meier</guid>
      <pubDate>Thu, 18 Apr 2024 14:09:46 GMT</pubDate>
    </item>
    <item>
      <title>宽格式（纵向）重复李克特项多重插补收敛失败的原因</title>
      <link>https://stats.stackexchange.com/questions/645307/reasons-for-failure-of-convergence-in-multiple-imputation-in-wide-format-of-lon</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/645307/reasons-for-failure-of-convergence-in-multiple-imputation-in-wide-format-of-lon</guid>
      <pubDate>Thu, 18 Apr 2024 13:39:38 GMT</pubDate>
    </item>
    <item>
      <title>使用纬度、经度和时间预测新冠病毒传播</title>
      <link>https://stats.stackexchange.com/questions/645306/predict-covid-spread-using-latitude-and-longitude-and-time</link>
      <description><![CDATA[我有一个数据，其中包含个人的纬度和经度以及地理位置的时间戳。我想使用 R 以及纬度/经度和时间来预测 COVID 的传播。我使用 180 万社交距离阈值将传播量化为新冠病毒感染的可能性。任何关于 R 或 Python 的想法（尽管我不太懂 Python）都会受到欢迎。
。到目前为止，我所做的是在每分钟内找到个体之间的成对比较，并得出 
欢迎任何想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/645306/predict-covid-spread-using-latitude-and-longitude-and-time</guid>
      <pubDate>Thu, 18 Apr 2024 13:16:22 GMT</pubDate>
    </item>
    <item>
      <title>平均治疗效果：反事实和图形推导</title>
      <link>https://stats.stackexchange.com/questions/645305/average-treatment-effect-counterfactual-and-graphical-derivation</link>
      <description><![CDATA[我对平均治疗效果 (ATE)，也称为平均因果效应 (ACE) 有一些（可耻的）怀疑。在此设置中，我对二元暴露/治疗变量 A、单个二元混杂变量 W 和结果变量 Y 感兴趣。该问题的有向无环图 (DAG) 如下所示。

那么，ATE定义为：
$$
\Psi = \mathop{\mathbb{E}} [Y(1)] - \mathop{\mathbb{E}} [Y(0)],
$$
其中 $\mathop{\mathbb{E}} [Y(a)]$ 是我们设置 A 时结果的预期值=a 适合我们人口中的每个人。
下一步是提供识别条件，以便我们可以从观察到的数据中识别该参数。让我们假设它们成立。在文献/讲义中，我发现了我认为通常被称为 g 公式的两个推导。
推导1：基于反事实
$$
\开始{对齐*}
\mathop{\mathbb{E}} [Y(a)] &amp; = \mathop{\mathbb{E}} [\mathop{\mathbb{E}} [Y(a)|W=w]] \\
&amp; = \mathop{\mathbb{E}} [\mathop{\mathbb{E}} [Y(a)|W=w,A=a]] \\
&amp; = \mathop{\mathbb{E}} [\mathop{\mathbb{E}} [Y|W=w,A=a]] \\
&amp; = \int_w \mathop{\mathbb{E}} [Y|W=w,A=a] P(W=w) d\nu(w)。
\结束{对齐*}
$$
这些步骤本质上是基于一致性和积极性假设以及迭代的期望。
推导 2：基于图形分解
在其他场合，我看到了以下推导，它通常基于上面 DAG 隐含的因式分解 ($P(A,W, Y) = P(Y|A,W)P(A|W)P(W)$):
$$
\开始{对齐*}
\mathop{\mathbb{E}} [Y] &amp; = \sum_y y f(y) \\
&amp; = \sum_{y,a} y f(y|a)f(a) \\
&amp; = \sum_{y,a, w} y f(y|a,w)f(a|w)f(w)。 \\
\结束{对齐*}
$$
如果我们将A设置为a，那么我们可以删除a和f(a|w)&lt;的求和/code&gt; 在上面的公式中。正如预期的那样，这两个推导似乎是一致的。
我遇到的问题是当我们没有设置 A 为 a 时，而是让它取决于例如A的自然值。也就是说，在第二个推导中，我们不会删除 f(a|w) 而是将其留在那里。在这种设置下，第一个推导会是什么样子？]]></description>
      <guid>https://stats.stackexchange.com/questions/645305/average-treatment-effect-counterfactual-and-graphical-derivation</guid>
      <pubDate>Thu, 18 Apr 2024 13:16:15 GMT</pubDate>
    </item>
    <item>
      <title>比值比悖论？合并 OR 与子组 OR 不一致</title>
      <link>https://stats.stackexchange.com/questions/645304/odds-ratios-paradox-pooled-or-inconsistent-with-subgroup-ors</link>
      <description><![CDATA[我有两个组（A 和 B），每个组的 OR 分别为 1.44 和 1.50。但是，如果我将两个组的频率组合起来创建一个合并数据集，则 OR 值为 1.40。
我知道这不会是一个很好的简单加权平均值或任何东西，但我预计合并的 OR 至少会落在两个 OR 的范围内。经过几天的苦苦思索试图找出原因后，我放弃了，转而求助于这里的集体智慧。
这是我的数据：
A 组频率

&lt;标题&gt;


控制
测试


&lt;正文&gt;

低
1374
1422


高
4759
7062



产生 1.44 的 OR 
B 组频率

&lt;标题&gt;


控制
测试


&lt;正文&gt;

低
825
534


高
4033
3914



产生 1.50 的 OR
合并频率

&lt;标题&gt;


控制
测试


&lt;正文&gt;

低
2199
1956


高
8792
10976



产生 1.40 的 OR
对这里发生的事情有什么想法吗？我使用这两个组来显示模式，但我的数据实际上分为更多组。
我将其称为悖论，因为如果我包括所有组，尽管事实上几乎所有组都产生 1.2-1.8 范围内的 OR（有几个组产生 0.95-1.0 范围内的 OR） ），池化版本基本上变为空（OR = 1.00）。感觉就像存在某种辛普森悖论。
编辑：根据下面的@COOLSerdash，本文 解释了“不可折叠性” OR 的数量。经过一番尝试后，我们发现，如果较大的组的 RR 与其他组的 RR 非常不同，那么它就会产生强烈的“扭曲”效果。效果。]]></description>
      <guid>https://stats.stackexchange.com/questions/645304/odds-ratios-paradox-pooled-or-inconsistent-with-subgroup-ors</guid>
      <pubDate>Thu, 18 Apr 2024 13:07:54 GMT</pubDate>
    </item>
    <item>
      <title>混合模型的功率分析仿真（lme4 和 simr）</title>
      <link>https://stats.stackexchange.com/questions/645303/simulating-power-analysis-for-mixed-models-lme4-and-simr</link>
      <description><![CDATA[我想使用以下设计计算组内研究的先验功效分析：

participant_id
条件（组内 - A、B）
协变量（范围 1-7）
调查问卷项目（范围 1-7）
二进制结果

我生成了一个如下的假数据集，如下所示
# 设置参加人数
参与者人数 &lt;- 50

# 为参与者创建数据框
参与者 &lt;- data.frame(participant_id = 1:num_participants)

# 为每个参与者生成 A 和 B 的随机顺序
参与者顺序 &lt;- 样本（c（“A_first”，“B_first”），num_participants，replace = TRUE）

# 创建一个数据框，每个参与者有两行
dummy_data &lt;- data.frame(participant_id =rep(participants$participant_id,each = 2),
                         条件=代表（c（“A”，“B”），次数= num_participants），
                         顺序 = 代表（participant_order，每个 = 2））

# 添加一个 7 分制的协变量
dummy_data$covariate &lt;- 样本(1:7, num_participants * 2, 替换 = TRUE)

# 模拟条件之间的差异
set.seed(123) # 为了重现性

对于（1:3 中的项目）{
  dummy_data[paste(&quot;item&quot;, item, sep = &quot;_&quot;)] &lt;- rnorm(num_participants * 2, Mean = ifelse(dummy_data$condition == &quot;A&quot;, 4, 6), sd = 1 ）
}

# 模拟二进制结果“bin_1”的差异
dummy_data$bin_1 &lt;- rbinom(num_participants * 2, size = 1, prob = ifelse(dummy_data$condition == &quot;A&quot;, 0.3, 0.7))

虚拟数据 &lt;- 虚拟数据 %&gt;%
  dplyr::变异(
    item_TOTAL = rowMeans(dplyr::select(., item_1, item_2, item_3)))

这指定了 item_TOTAL 上条件 A 和 B 之间的差异。对于功耗分析，我使用 simr 函数，因此我使用 lme4 创建了一个混合模型。
model1 &lt;- lmer(item_TOTAL ~ 条件 + 协变量 + (1|participant_id), data = dummy_data)
摘要（模型1）

这为条件 B 提供了 1.87 的固定效果。按照此处的教程，我可以更改固定效果大小像这样
model2 &lt;- model1
fixef(model2)[“条件B”] &lt;-- 0.05

然后我可以使用 powerSim 函数执行功耗分析
&lt;前&gt;&lt;代码&gt;powerSim（模型1）
powerSim(模型2)

到目前为止，代码似乎一切正常，但是我对编辑实际功耗分析的参数感到困惑。链接的教程提到“指定效应大小”，并且“x 的估计效应大小为 -0.11，使用默认 z 检验在 0.01 水平上显着。”
但据我了解，固定效应系数与效应大小不同，所以我不确定应该如何更改fixef系数以对应不同的预期效应大小（因为我想这也是设计依赖）。由于数据是随机生成的，我也不确定 fixef(model2)[&quot;condition&quot;] &lt;-- 0.05 命令实际上在做什么 - 首先我应该使用以下命令生成随机数据没有效果然后只编辑fixef？或者我应该生成 3 个假数据集，每个数据集都有不同的效果大小（我什至不太确定如何做到这一点），然后比较这 3 个数据集？在现实生活中，我也期望我的协变量和结果变量之间存在正相关，这也应该以某种方式解释吗？
我也不确定进行模拟功耗分析比仅将设计视为重复测量 t 检验并以这种方式计算功耗有什么好处。如有任何建议，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/645303/simulating-power-analysis-for-mixed-models-lme4-and-simr</guid>
      <pubDate>Thu, 18 Apr 2024 12:54:02 GMT</pubDate>
    </item>
    <item>
      <title>最大似然的潜在异方差</title>
      <link>https://stats.stackexchange.com/questions/645302/potential-heteroskedasticity-in-maximum-likelihood</link>
      <description><![CDATA[我使用 Logit 回归和最大似然创建了一个不良贷款分类器模型。实际结果与预期结果的比较如下所示。为了创建图表，我们将观察结果按分数按 5% 为一组进行分组。分数低代表信用质量低，分数高代表信用质量高。
我观察到，对于得分较高的分箱，实际 v 预期存在一些波动。我担心残差的潜在异方差性。不过，我也认为观察到这种波动是正常的，因为不良贷款数量预计会较低，因此估计的标准误差较高。
我的问题是：

如何评估残差是否实际上是异方差的？
如果残差恰好是异方差的，会对我的模型的有效性/准确性产生什么影响？

]]></description>
      <guid>https://stats.stackexchange.com/questions/645302/potential-heteroskedasticity-in-maximum-likelihood</guid>
      <pubDate>Thu, 18 Apr 2024 12:53:01 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助比较两个样本[关闭]</title>
      <link>https://stats.stackexchange.com/questions/645299/need-help-in-comparing-two-samples</link>
      <description><![CDATA[所以我的情况是，在同一人群中，在实施刺激措施之前和之后采集了两个样本。换句话说
t0= 总体 A 中的样本 1
应用刺激。然后，
t1= 来自总体 A 的样本 2。假设对这两个样本都进行了调查。如果个体是从相同的总体和样本框架中随机选择的，那么我如何比较两次调查的结果作为 t0 和 t1 时一般总体的代表。]]></description>
      <guid>https://stats.stackexchange.com/questions/645299/need-help-in-comparing-two-samples</guid>
      <pubDate>Thu, 18 Apr 2024 12:09:11 GMT</pubDate>
    </item>
    <item>
      <title>如何指定每个用户在不同时间进行处理的逻辑回归？</title>
      <link>https://stats.stackexchange.com/questions/645301/how-to-specify-a-logistic-regression-with-treatment-happening-in-different-times</link>
      <description><![CDATA[我有一个时间跨度从 2017 年到 2021 年的数据集。观察结果包含来自某个平台的评论。我想测试精英身份的变化（从精英到非精英，从非精英到精英）对脏话使用的影响。
但是由于精英地位可能会随着时间的推移（在这 4 年内）多次变化，我不知道如何在我的模型规范和数据集中解决这个问题。
我已经尝试过 PSM 并尝试制作 2 个 Logit 模型。 （一个用于失去精英状态，另一个用于获得精英状态）。然而，这并不是解决这个问题的正确方法，因为我没有考虑随着时间的推移而产生的某些差异。因此，我想我可能需要对每年发生的治疗产生交互影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/645301/how-to-specify-a-logistic-regression-with-treatment-happening-in-different-times</guid>
      <pubDate>Thu, 18 Apr 2024 11:58:07 GMT</pubDate>
    </item>
    <item>
      <title>皮尔逊系数的替代方案[关闭]</title>
      <link>https://stats.stackexchange.com/questions/645292/alternative-for-pearson-coefficient</link>
      <description><![CDATA[我继承了一个使用皮尔逊相关系数来完成某些任务的系统。但它有一个明显的问题。
(1,-2)、(2,-1)、(3,0)、(4,1)、(5,2) 和
(1,-20)、(2,-10)、(3,0)、(4,10)、(5,20) 具有相同的结果，即 1。
事实上，(1,-20)、(2,-10)、(3,0)、(4,10)、(5,15) 的相关性较小，这不是我们想要的。这就是我们得到次优结果的原因。
为了改进这一点，我正在考虑将 Pearson 系数与 Y 值或 YTrend 值（对数或线性拟合值）的差值相乘，以便新的系数变得类似于
(1,-2), (2,-1), (3,0), (4,1), (5,2) = 1 * 4 = 4
(1,-20)、(2,-10)、(3,0)、(4,10)、(5,20) = 1 * 40 = 40
(1,-20)、(2,-10)、(3,0)、(4,10)、(5,19) = .99 * 39 = 38.61
这个新系数似乎更适合我们的系统。是否还有其他系数可以解决皮尔逊的这一局限性？在使用上述方法之前，我更愿意先看看这些。我已经检查了斯皮尔曼的，但这不起作用，因为我们绝对关心变化量和排名。
下面是相关代码
&lt;块引用&gt;
SELECT ((Sum_xy - (Sum_x * Sum_y / N))) / (SQRT(Sum_xx - (Sum_x *
Sum_x / N)) * SQRT(Sum_yy - (Sum_y * Sum_y / N))) AS 皮尔逊 FROM
(选择 SUM(x) AS Sum_x、SUM(y) AS Sum_y、AVG(x) AS Avg_x、AVG(y) AS
Avg_y、AVG(x * y) as Avg_xy、SUM(x * x) AS Sum_xx、SUM(x * y) AS
Sum_xy, SUM(y * y) AS Sum_yy, COUNT(*) AS N FROM @OurData) as x

DB Fiddle 是 dbfiddle.uk/2Akwx7Zk]]></description>
      <guid>https://stats.stackexchange.com/questions/645292/alternative-for-pearson-coefficient</guid>
      <pubDate>Thu, 18 Apr 2024 09:35:28 GMT</pubDate>
    </item>
    <item>
      <title>为什么在交叉方程限制下，“systemfit”对于 OLS 和 WLS 会产生不同的结果？</title>
      <link>https://stats.stackexchange.com/questions/645285/why-does-systemfit-yield-different-results-for-ols-and-wls-under-cross-equatio</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/645285/why-does-systemfit-yield-different-results-for-ols-and-wls-under-cross-equatio</guid>
      <pubDate>Thu, 18 Apr 2024 08:00:29 GMT</pubDate>
    </item>
    </channel>
</rss>