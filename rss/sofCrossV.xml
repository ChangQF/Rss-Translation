<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 22 Dec 2024 15:14:33 GMT</lastBuildDate>
    <item>
      <title>在 R 中对分数数据进行建模</title>
      <link>https://stats.stackexchange.com/questions/659095/modelling-fractional-data-in-r</link>
      <description><![CDATA[我有以下一组数据，其中响应变量是比例数据
dat = structure(list(Y = c(0.0104, 0.01044, 0.00809, 0.00413, 0.00634, 
0.0021, 0.00729, 0.02386, 0.00722, 0.0109, 0.00873, 0.00647, 
0.00611, 0.02342, 0.01818, 0.0176, 0.01865, 0.00546, 0.00515, 
0.02477, 0.00625, 0.01538), X = c(0.01077, 0.01956, 0.02298, 
0.10304, 0.02963, 0.04887, 0.01589, 0.00519, 0.05161, 0.00357, 
0.02279, 0.02733, 0.07581, 0.03643, 0.03257, 0.03324, 0.0509, 
0.05552, 0.08214, 0.01031, 0.08347, 0.02489)), row.names = c(NA, 
-22L), class = &quot;data.frame&quot;)

在我的例子中，Y 是比例数据。因此我想在此数据上拟合 分数逻辑模型，如下所示
&gt; summary(glm(&quot;Y ~ X&quot;, dat = dat, family = binomial()))

调用：
glm(formula = &quot;Y ~ X&quot;, family = binomial(), data = dat)

系数：
估计标准差。误差 z 值 Pr(&gt;|z|)
(截距) -4.043 3.381 -1.196 0.232
X -12.650 88.094 -0.144 0.886

(二项式系列的分散参数取为 1)

零偏差：21 个自由度上的 0.086252
残差偏差：20 个自由度上的 0.063149
AIC：4.4969

Fisher 评分迭代次数：8

这表明变量 X 非常不显著
这是违反直觉的，因为 Y 和 X 之间存在显著相关性
现在，我拟合一个 简单线性回归，然后我得到显著X 变量
&gt; library(dplyr)
&gt; summary(glm(&quot;Z ~ X&quot;, dat = dat %&gt;% mutate(Z = log(Y / (1-Y)))))

调用：
glm(formula = &quot;Z ~ X&quot;, data = dat %&gt;% mutate(Z = log(Y/(1 - Y))))

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) -4.1740 0.2074 -20.129 9.55e-15 ***
X -12.7358 4.4171 -2.883 0.00919 ** 
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（高斯族的分散参数取为 0.3104897）

零偏差：21 个自由度上的 8.7910
残差偏差：20 个自由度上的 6.2098
AIC：40.605

Fisher 评分迭代次数：2

您能帮我理解为什么我的第一个使用 glm() 的模型无法显示显著的 X 变量吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659095/modelling-fractional-data-in-r</guid>
      <pubDate>Sun, 22 Dec 2024 14:22:40 GMT</pubDate>
    </item>
    <item>
      <title>引导平均导数估计量</title>
      <link>https://stats.stackexchange.com/questions/659094/bootstrapping-the-average-derivative-estimator</link>
      <description><![CDATA[设 $f(x)=\mathbb E[Y\mathop | X=x]$ 为回归函数，$\hat {f}(x)$ 为其估计值（例如，使用核回归）。平均导数估计量（Härdle 和 Stoker，1989；Rilstone，1991；Rodríguez 和 Shelton，2013）定义为
$$
\hat\mu_X=\frac1n\sum_{i=1}^n{\hat {f^{\prime}}}(X_i)
$$
请注意，$\hat \mu_X$ 是 $\mathbb E[f&#39;(X)]$ 的一致估计量。类似地，我们可以定义高阶导数的估计量$\mathbb E[f^{(n)}(X)]$:
$$
\hat\mu_X^{(m)}=\frac 1n\sum_{i=1}^n\hat f^{(n)}(X_i)
$$
现在我想对平均导数进行假设检验。具体来说，我想测试
$$
H_0:\mathbb E[f&#39;(X)]=0
$$
和
$$
H_0&#39;:\mathbb E[f&#39;&#39;(X)]=0。
$$
我使用引导程序如下：将引导样本表示为$x_1,\cdots,x_B$，每个样本都是一个具有一定大小的向量（例如$k$），在引导数据上重新拟合模型，计算导数的 t 统计量（通过减去$\hat\mu_X$来降低平均值），然后$p$值由引导$t$统计量中大于从整个样本计算出的$t$统计量的比例给出。它类似于随机变量均值的引导检验。 （这里有一些幻灯片，供参考）

现在我想知道，这个测试是否有效（我已经在 R 中实现了它）？我是否应该为每个引导样本重新拟合模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/659094/bootstrapping-the-average-derivative-estimator</guid>
      <pubDate>Sun, 22 Dec 2024 13:18:27 GMT</pubDate>
    </item>
    <item>
      <title>最大似然估计 (MLE) 的矩收敛</title>
      <link>https://stats.stackexchange.com/questions/659091/convergence-of-moments-for-maximum-liklihood-estimators-mle</link>
      <description><![CDATA[设 $\hat{\theta}$ 为参数 $\theta$ 的 MLE 估计量，它来自紧凑空间 $\Theta$。我们知道
$$\hat{\theta}\to_P \theta$$
并且
$$\sqrt{n} (\hat{\theta}-\theta)\to_D N(0,\sigma^2)$$
其中 $\sigma^2$ 是逆 Fisher 信息。
我的问题是：我们在均方结果中是否有以下收敛？
$$E|\sqrt{n} (\hat{\theta}-\theta)|^2 \to \sigma^2$$
我有已完成：

我知道分布收敛加上均匀可积性意味着矩收敛，但是，这里，RV 序列：$\{\sqrt{n} (\hat{\theta}-\theta)\}_n$ 显然不是均匀可积的。

我在 iid 随机变量的中心极限定理 (Thm. 6.3 of 统计和概率的渐近理论):



假设 $X_1,...,X_n$ 是 iid 的，均值为 $\mu$，方差为有限 $\sigma^2$，并且假设对于某个特定的 $k$，$E|X_1|^k&lt;\infty$。假设$Z~N(0,1)$，则
$$E\left[\frac{\sqrt{n}(\bar{X}_n-\mu)}{\sigma}\right]^r = E(Z)^r + O(\frac{1}{\sqrt{n}})$$

这显然意味着
$$E\left[\frac{\sqrt{n}(\bar{X}_n-\mu)}{\sigma}\right]^r \to E(Z)^r$$
从这个结果来看，我猜我的问题应该是文献中研究得很好的问题。但是，我找不到任何参考资料或书籍。]]></description>
      <guid>https://stats.stackexchange.com/questions/659091/convergence-of-moments-for-maximum-liklihood-estimators-mle</guid>
      <pubDate>Sun, 22 Dec 2024 10:52:19 GMT</pubDate>
    </item>
    <item>
      <title>Weightthem后的中介分析</title>
      <link>https://stats.stackexchange.com/questions/659090/mediator-analysis-after-weightthem</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659090/mediator-analysis-after-weightthem</guid>
      <pubDate>Sun, 22 Dec 2024 10:08:42 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据插补生成方法背后的直觉</title>
      <link>https://stats.stackexchange.com/questions/659075/intuition-behind-generative-methods-for-imputing-missing-data</link>
      <description><![CDATA[我正在学习不同的方法来估算混合连续和分类变量的表格数据集，并且假设数据完全随机缺失。我使用频率编码器转换了分类数据，因此所有内容都是数字或 NaN。
我认为平均值、中位数等估算过于简单且容易产生偏差。我正在考虑更复杂的方法，例如确定性和生成性。
对于确定性，我尝试了 LightGBM，它非常直观。我喜欢它。基本上，对于每个具有缺失数据的特征，其非缺失数据作为对其他特征的回归，然后预测/估算缺失数据。很棒。
现在我尝试使用深度学习方法，例如 AE 或 GAN。通过查阅文献，这似乎非常可行且非常有效。但黑匣子很难理解。例如，对于 VAE，我们是否只是简单地基于整个表格数据构建一个 VAE 模型，然后“以某种方式”预测/生成/估算缺失数据？
我仍在研究这个问题以获得更清晰的解释，但我希望也尝试过估算表格数据的人可以分享一些经验。]]></description>
      <guid>https://stats.stackexchange.com/questions/659075/intuition-behind-generative-methods-for-imputing-missing-data</guid>
      <pubDate>Sun, 22 Dec 2024 01:27:59 GMT</pubDate>
    </item>
    <item>
      <title>共形预测对高精度模型有何帮助？</title>
      <link>https://stats.stackexchange.com/questions/659071/what-does-conformal-prediction-add-to-highly-accurate-models</link>
      <description><![CDATA[我研究共形预测 (CP) 已经有一段时间了。我无法理解的是，CP 可以为已经非常准确的机器学习 (ML) 模型添加什么。为什么有人更喜欢在准确率超过 $95\%$ 的 ML 模型上使用 CP？这种 ML 模型的预测怎么能被描述为“启发式”？CP 在什么意义上改善了 ML 模型非常“好”的预测？
编辑：根据评论者的要求，感兴趣的读者可以参考以下来源深入讨论 CP：

&quot;共形预测&quot;统计学习高级主题，2023 年春季
Ryan Tibshirani
Angelopoulos、Anastasios N. 和 Stephen Bates。“共形预测和无分布不确定性量化的简单介绍。”arXiv 预印本 arXiv:2107.07511 (2021)。
Balasubramanian、Vineeth、Shen-Shyang Ho 和 Vladimir Vovk 编辑。可靠机器学习的共形预测：理论、适应和应用。Newnes，2014 年。

附言：请不要给我上 CP 速成课，因为我已经了解它的技术细节。我只是想问一下它相对于高精度 ML（例如分类）模型的优势。]]></description>
      <guid>https://stats.stackexchange.com/questions/659071/what-does-conformal-prediction-add-to-highly-accurate-models</guid>
      <pubDate>Sat, 21 Dec 2024 23:28:09 GMT</pubDate>
    </item>
    <item>
      <title>生成模型 - 有效分布要求</title>
      <link>https://stats.stackexchange.com/questions/659069/generative-models-valid-distribution-requirement</link>
      <description><![CDATA[在 Bishop 的“深度学习”中，对生成模型的要求在我看来是错误的

（公式 14.49，第 452 页，在线网址为 https://www.bishopbook.com/ ）
我认为它应该只要求 p(x|w) 对 1/x 进行积分。书中是否有错误，或者我遗漏了什么？
我怀疑该方程的理由是：如果您考虑 [0, 2] 上的均匀分布 p(x)，即使 p(x|w) 与 p(x) 匹配，该方程也不成立。
（我已经在 Data Science StackExchange 上提问，其中一条评论建议尝试统计相关的社区）]]></description>
      <guid>https://stats.stackexchange.com/questions/659069/generative-models-valid-distribution-requirement</guid>
      <pubDate>Sat, 21 Dec 2024 23:14:38 GMT</pubDate>
    </item>
    <item>
      <title>策略改进定理的使用问题</title>
      <link>https://stats.stackexchange.com/questions/659005/policy-improvement-theorem-usage-issues</link>
      <description><![CDATA[在 Sutton 和 Barto 的《强化学习》一书（2018 年版）第 101-102 页中，需要证明 $\epsilon$-greedy 是对 $\epsilon$-soft 策略的改进，其内容为

因此，根据策略改进定理，$\pi&#39; \geq \pi$（即，$v_{\pi&#39;}(s) \geq v_\pi(s)$，对于所有 $ s \in \mathcal{S} $

书中所述的策略改进定理是

让 $\pi$ 和 $\pi&#39;$ 成为任意一对确定性策略，使得对于所有 $s \in \mathcal{S}$，
$$q_\pi (s, \pi&#39; (s)) \geq v_\pi (s) \tag{4.7} $$
那么策略 $\pi&#39;$ 必须与 $\pi$ 一样好，或者更好。也就是说，它必须从所有状态$s \in \mathcal{S}$获得更大或相等的预期回报：
$$v_\pi&#39; (s) \geq v_\pi (s)$$

他们如何使用策略改进定理，因为之前讨论的定理适用于确定性策略，而这里的情况并非如此。]]></description>
      <guid>https://stats.stackexchange.com/questions/659005/policy-improvement-theorem-usage-issues</guid>
      <pubDate>Fri, 20 Dec 2024 08:44:36 GMT</pubDate>
    </item>
    <item>
      <title>在处理与因子分析的 MLE 相关的函数时，如何保证结果是全局最小值？</title>
      <link>https://stats.stackexchange.com/questions/658953/how-do-we-guarantee-the-result-is-the-global-minimizer-when-dealing-a-function-r</link>
      <description><![CDATA[我正在阅读论文对最大似然因子分析的一些贡献。
考虑因子分析模型$$y=\Lambda x+z, $$
其中$y$是一个包含$p$个特征的向量，$x$是长度为$k&lt;p$的潜在因子向量。
设$z$的协方差矩阵为$\Psi$，$$\Sigma= \Lambda\Lambda&#39;+\Psi.$$
设样本协方差矩阵为$S$.
作者说，要最大化对数似然函数，只需最小化
$$ F_k(\Lambda ,\Psi) =\log|\Sigma|+\text{tr}(S\Sigma^{-1})-\log|S|-p。 $$
然后作者求解了方程$\frac{\partial F_k}{\partial \Lambda}=0$，
并得出结论，这样的$\Lambda$满足$\Psi^{-\frac 12}\Lambda$的列是$\Psi^{-\frac 12}S\Psi^{-\frac 12}$的特征向量，
并且如果我们选择这些特征向量对应于$k$个最大特征值，
则相应的$F_k$小于任何其他选择的特征向量。
作者还求解了$\frac{\partial F_k}{\partial \Psi}=0$，得到$$ \Psi= \text{diag} (S-\Lambda\Lambda&#39;) 。 $$
作者接着说，$\Lambda$和$\Psi$的最大似然估计是通过上述过程确定的对。
我的问题是，既然我们只取了梯度，我们如何保证对于给定的$\Psi$，这样的$\Lambda$不是局部最大值，
并且存在一些$\Lambda$使得$F_k$更小（例如，$F_k\to -\infty$沿某个方向）？
对于$\Psi$，我们如何确保由上述过程确定的$\Psi$不是函数$\Psi\mapsto \min F_k(\Lambda,\Psi)$的局部最大值？
作者说这是 MLE，那么我们能证明这对 $\Lambda$ 和 $\Psi$ 是 $F_k$ 的全局最小化器吗？

这篇文章 提出了一个类似的问题，但针对的是一般的 MLE。我认为答案并没有解决我的困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/658953/how-do-we-guarantee-the-result-is-the-global-minimizer-when-dealing-a-function-r</guid>
      <pubDate>Thu, 19 Dec 2024 04:36:37 GMT</pubDate>
    </item>
    <item>
      <title>使用 simr 了解功率曲线和非单调功率随样本量增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658923/understanding-power-curves-and-non-monotonic-power-increase-with-sample-size-usi</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658923/understanding-power-curves-and-non-monotonic-power-increase-with-sample-size-usi</guid>
      <pubDate>Wed, 18 Dec 2024 13:31:01 GMT</pubDate>
    </item>
    <item>
      <title>在此次治疗师依从性测试中，作者是否适当地应用了重复测量单因素方差分析和 ROC 分析？</title>
      <link>https://stats.stackexchange.com/questions/658834/have-the-authors-appropriately-applied-repeated-measures-one-way-anova-and-roc-a</link>
      <description><![CDATA[我正在阅读一篇关于我所从事的心理治疗类型的研究。我的直觉是，这篇论文对统计数据的使用是有缺陷的，但我在意识形态上想要找出这篇特定研究的缺陷，而且我对统计数据的了解相当基础。出于这些原因，我不会链接到这篇论文。
这篇论文的所有作者都是接受过同一种治疗培训的心理治疗师。他们创建了一份问卷，供接受过该治疗培训的观察员使用，以评估治疗师在特定疗程中对该治疗的治疗程度。（即，这是一项依从性测试。）作者将这份问卷分发给了大约 200 名参与者（均接受过相关治疗培训），并附上了 4 个治疗疗程的视频；其中 2 个由接受过相关治疗培训的治疗师制作，另外 2 个由接受过其他治疗培训的治疗师制作。参与者对前两个视频的评分（每个约平均值 = 16.5，标准差 = 0.2）高于对后两个视频的评分（每个约平均值 = 4.5，标准差 = 0.25），这表明使用问卷可以清楚地区分受过相关疗法培训的人提供的疗法和受过其他疗法培训的人提供的疗法。
作者将上述平均值和标准差值作为“单向重复测量方差分析”的一部分呈现测试，他们说这显示出了统计学意义。
然后，他们进行了 ROC 分析，以确定将感兴趣的疗法与其他类型的疗法区分开来的阈值分数，并获得了 11 的值。
我有两个顾虑：
1：Statology 说，“重复测量单向方差分析用于确定三个或更多组的平均值之间是否存在统计学上的显着差异，其中每个组中都出现了相同的受试者。”我可以看到这里有 4 个组（4 个视频中的每个视频都有 1 组分数），但是，按照 Statology 的字面意思理解，这意味着观察者评分者是受试者，而不是他们正在评分的视频会话。如果研究的目的是找到一种方法来区分感兴趣的疗法和其他类型的疗法，那么我们实际上肯定有两组（2 个感兴趣的疗法样本和 2 个来自另一种疗法的样本）。如果我们只有 4 个样本，那么我认为统计显着性检验尚不合适。我愿意被告知我对此的想法是错误的，并欢迎任何评论。
2：维基百科说 ROC 分析是为了确定什么强度的信号应该被视为值得在雷达上显示的物体而开发的。我认为该任务必然是二进制的，以限制雷达操作员必须解析的信息量。我认为阈值不适用于确定某人是否遵守特定类型的治疗（特别是如果我们只有 4 个样本并且我们只评估了 2 种类型的治疗）。再次，我欢迎任何评论，包括对我的观点的任何更正。
我不知道是否已经发布了足够的有关该研究的信息。如果我应该提供更多详细信息，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/658834/have-the-authors-appropriately-applied-repeated-measures-one-way-anova-and-roc-a</guid>
      <pubDate>Mon, 16 Dec 2024 20:53:10 GMT</pubDate>
    </item>
    <item>
      <title>凸性和唯一或区间最优投资组合的存在性</title>
      <link>https://stats.stackexchange.com/questions/658099/convexity-and-existence-of-an-unique-or-interval-optimal-portfolio</link>
      <description><![CDATA[考虑一个包含两种资产的基本静态投资组合选择问题。投资者选择一个投资组合，即将其固定财富的正部分分配到两种金融资产中。金融资产是取值在 (a,b) 范围内的随机变量。
现在假设我将凸性定义如下：如果投资者偏好资产 1 而非资产 2，那么投资者偏好资产 1 和资产 2（这会产生另一项资产，我们将其命名为资产 3）的投资组合而非资产 2。由于资产 3 优于资产 2，因此资产 3 和资产 2 的投资组合也优于资产 2...
我的问题是，这种凸性假设是否意味着存在唯一或区间最优的投资组合。最优投资组合只是意味着存在一个优于任何其他投资组合的投资组合。我的直觉告诉我是这样，但我找不到任何参考资料。如果有人能详细解释这一点并提供一些参考资料，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658099/convexity-and-existence-of-an-unique-or-interval-optimal-portfolio</guid>
      <pubDate>Sun, 01 Dec 2024 20:18:21 GMT</pubDate>
    </item>
    <item>
      <title>在频率论的背景下，我们如何能够确定零假设为真/假？</title>
      <link>https://stats.stackexchange.com/questions/657840/in-a-frequentist-setting-how-are-we-able-to-condition-on-the-null-hypothesis-be</link>
      <description><![CDATA[引用 Casella 和 Berger (2002) 的话：假设检验由零假设 $H_0: \theta \in \Theta_0 $ 和备择假设 $H_1: \theta \in \Theta_0^c = \bar{H_0}$ 定义，其中 $\Theta$ 是总体参数 $\theta$ 的一组可能值，并且 $\Theta_0^c = \Theta - \Theta_0 $。
在频率论的设定中，$\theta$ 是一个未知但固定的量（也就是说，它是非随机的）。因此，对于给定集合$\Theta_0$，零假设$H_0$严格为真或假（但我们不知道是哪个）。备择假设，即否定，相应地为假或真。
让我们的检验统计量为$\hat{\theta} = f(X_1, ..., X_n)$。我们将拒绝域$RR \subset Range(\hat{\theta})$定义为我们选择拒绝$H_0$的检验统计量$\hat{\theta}$的值集。由于我们的样本 $X_1, ..., X_n$ 是随机的，$\hat{\theta}$ 是一个随机变量，因此数量 $p(\hat{\theta} \in RR)$ 是一个有效概率，类似于更简单的概率，如 $p(X \le 5)$
到目前为止一切顺利。然而，当我们开始定义 I 类错误时，我开始感到困惑。I 类错误是当我们拒绝 $H_0$ 即使它是 True 时。这在数学上定义为：
$$
\alpha = p(\hat{\theta} \in RR | H_0 \text{ is True}) = p(\hat{\theta} \in RR | \theta \in \Theta_0)
$$
这个概率对我来说毫无意义。$\theta$ 不是随机变量，因此 $\theta \in \Theta_0$ 不是概率事件，而是 True 或 False 值。概率框架（据我所知）不允许我们有意义地对实值或布尔值进行条件限制，而只能对事件进行条件限制。
这是怎么回事？我能做出的唯一有意义的解释是$\theta$是否是一个随机变量，这违反了频率统计的核心思想。]]></description>
      <guid>https://stats.stackexchange.com/questions/657840/in-a-frequentist-setting-how-are-we-able-to-condition-on-the-null-hypothesis-be</guid>
      <pubDate>Tue, 26 Nov 2024 01:27:13 GMT</pubDate>
    </item>
    <item>
      <title>使用看似不相关的回归检验两个不同回归的系数相等性</title>
      <link>https://stats.stackexchange.com/questions/657674/testing-equality-of-coefficients-from-two-different-regressions-with-seemingly-u</link>
      <description><![CDATA[我正在运行两个回归，一个嵌套在另一个中。
$$ y = \beta_1 X + \epsilon_1$$
$$ y = \beta_2 X + \beta_3 Z + \nu_2$$
我想评估两个方程式中 X 的系数是否相同 $$\hat\beta_{1} \neq \hat\beta_{2} ?$$
基本上，我想知道添加协变量 Z 是否会显著改变 y 和 X 之间的关联。
我尝试使用 R 执行此操作，如下所示：
# install.packages(&quot;systemfit&quot;)
library(systemfit)

# 指定两个方程式
eq2 &lt;- y ~ x + z
eq1 &lt;- y ~ x

# 将模型组合成一个系统
system &lt;- list(eq1 = eq1, eq2 = eq2)

# 拟合 SUR 模型
fit &lt;- systemfit(system, method = &quot;SUR&quot;, data=data_full2)

# 测试模型间 X 系数的相等性
linearHypothesis(fit, &quot;eq1_x = eq2_x&quot;)

但是，当我查看 eq2 的 fit 结果时，我发现与单独计算每个回归时的情况非常不同。（使用 lm(y ~ x + z, data=data_full2)）。我知道两种情况下的结果可能会有所不同，但差异非常大，因为在单独计算时，受限模型中的系数为 0.1，完整模型中的系数为 0.05，而在 SUR 计算中，两者均变为 0.1 左右。因此，当然，我的 linearHypothesis(fit, &quot;eq1_x = eq2_x&quot;) 命令的结果告诉我差异并不显著。
与两个独立的 lm() 相比，使用 systemfit() 命令运行系数时，系数变化如此之大，这正常吗？我是否仍应相信分析结果，即两个方程中的系数实际上并没有显著差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/657674/testing-equality-of-coefficients-from-two-different-regressions-with-seemingly-u</guid>
      <pubDate>Fri, 22 Nov 2024 10:43:59 GMT</pubDate>
    </item>
    <item>
      <title>去聚类影响、平稳性和离散化</title>
      <link>https://stats.stackexchange.com/questions/649812/declustering-impact-stationarity-and-discretization</link>
      <description><![CDATA[我有一个季节性时间序列，我正在考虑使用运行去聚类对其进行去聚类（在任何其他预处理步骤之前）。如果我观察到极值指数为 1，我可以声称我的数据是 i.i.d.，因此是平稳的吗？这是否允许我避免事先使用非平稳方法？此外，我很好奇运行去聚类时间序列是否类似于离散化，因为我不确定我的去聚类分布是否仍然属于最大吸引域。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/649812/declustering-impact-stationarity-and-discretization</guid>
      <pubDate>Mon, 24 Jun 2024 14:33:04 GMT</pubDate>
    </item>
    </channel>
</rss>