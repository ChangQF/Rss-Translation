<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 31 Jan 2025 18:21:41 GMT</lastBuildDate>
    <item>
      <title>与子集相比，glmer() 模型中固定效应对较大数据集的放大作用</title>
      <link>https://stats.stackexchange.com/questions/660820/amplified-effect-of-fixed-effects-in-glmer-model-for-larger-dataset-compared-t</link>
      <description><![CDATA[我正在用相同的变量将一系列模型拟合到不同形式的数据中。我选择了 GLMM，因为我的数据中有一些结构层次，这对于理解变化可能很重要。当我将模型拟合到较小的数据子集时，我遇到的唯一问题是一些收敛/优化问题，因为响应变量非常小——我进行了平方根变换以避免这个问题，因为我没有遇到任何问题。关系不显著（这是我们预期的）。然而，我们决定在“合并”版本的数据上拟合模型（即一个数据框中的所有子集）。当我这样做时，我必须对数据进行平方根变换以避免收敛问题，就像以前一样。但现在最佳拟合模型显示响应和预测变量之间存在强烈的负相关关系。这对我来说毫无意义，因为与子集数据的所有关系都是完全平坦且不显著的。为什么 GLMM 会预测与更多数据点之间存在强烈的负相关关系？这和转换有关吗？这是不好的做法吗？
以下是我拟合的模型类型的一些示例：
#pooled data (no subsets) -- best model 
m1 &lt;- glmer(transformedY ~ scale(X) + (1 | Z) + (1 | W), family = Gammma(link = &quot;log&quot;), data = d)
#scale(X)estimate = -1.1341, pval ~0
#Random effects: Z variance = 1.76056, Z Std. dev = 1.3269; W variance = 0.09249, W Std. dev = 0.3041 

#数据子集 -- 最佳模型 
m2 &lt;- glmer(transformedY ~ scale(X) + (1 | Z) + (1 | Q), family = Gamma(link = &quot;log&quot;), 
data = ds)
#scale(X) 估计 = -0.02805, p val = 1, 
#随机效应：Z 方差 = 0.061329, Z Std. dev = 0.2476; Q 方差 = 0.020675, Q Std. dv = 0.1438 

#注意：Q 和 W 都以略有不同的单位来测量时间。

我假设它与池中的随机效应有关，这些随机效应吸收了太多的变化，并以某种方式放大了固定效应，即使这种关系不是那么强？但这些随机效应是有意义的，并且包含结构，所以我不想忽视这一点。有什么建议或资源可以解决此问题吗？
编辑：我还使用 allFit() 来调查收敛问题是否非常成问题，但事实并非如此，所以我尝试使用未转换的数据，结果相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/660820/amplified-effect-of-fixed-effects-in-glmer-model-for-larger-dataset-compared-t</guid>
      <pubDate>Fri, 31 Jan 2025 17:49:22 GMT</pubDate>
    </item>
    <item>
      <title>关于通过初始值（高值）和最终值（低值）进行归一化后查找方差的问题</title>
      <link>https://stats.stackexchange.com/questions/660817/question-about-finding-variance-after-normalizing-by-the-initial-high-and-fina</link>
      <description><![CDATA[所以，我不太懂统计学，所以我 90% 肯定这是一个愚蠢的问题，但它已经困扰我有一段时间了，所以我非常感激帮助！我有来自许多“个人”的数据；在 0 到 1 的范围内，每个人最初的得分都很高，假设平均得分为 0.8，然后经过多次试验，他们在最后一次试验中的“最终”得分很低，假设平均得分为 0.2。休息一段时间后，他们的分数会有所恢复，假设平均得分为 0.6。
通过这三种方法，我想计算恢复百分比（即，初始得分和最终得分之间的差异中有多少百分比是通过恢复得分恢复的）。使用这个标准化方程式很容易计算：（平均恢复分数 - 平均最终分数/平均初始分数 - 平均最终分数）* 100。结果是 0.6-0.2/0.8-0.2 * 100 = 67%。
很好。但是，我想用这个来计算统计数据以比较不同组的数据，为此我需要这个百分比恢复值的方差（在本例中为 67%）。我不确定该怎么做。初始值、最终值和恢复值存在差异，所以我要使用误差传播吗？还是别的什么？如果能澄清这一点，我将不胜感激，我觉得这不是人们所做的非常罕见的标准化，但我还没有在任何地方找到这个特定问题的解决方案 :(]]></description>
      <guid>https://stats.stackexchange.com/questions/660817/question-about-finding-variance-after-normalizing-by-the-initial-high-and-fina</guid>
      <pubDate>Fri, 31 Jan 2025 17:14:41 GMT</pubDate>
    </item>
    <item>
      <title>与子集相比，glmer() 模型中固定效应对较大数据集的放大作用</title>
      <link>https://stats.stackexchange.com/questions/660823/amplified-effect-of-fixed-effects-in-glmer-model-for-larger-dataset-compared-t</link>
      <description><![CDATA[我正在用相同的变量将一系列模型拟合到不同形式的数据中。我选择了 GLMM，因为我的数据中有一些结构层次，这对于理解变化可能很重要。当我将模型拟合到较小的数据子集时，我遇到的唯一问题是一些收敛/优化问题，因为响应变量非常小——我进行了平方根变换以避免这个问题，因为我没有遇到任何问题。关系不显著（这是我们预期的）。然而，我们决定在“合并”版本的数据上拟合模型（即一个数据框中的所有子集）。当我这样做时，我必须对数据进行平方根变换以避免收敛问题，就像以前一样。但现在最佳拟合模型显示响应和预测变量之间存在强烈的负相关关系。这对我来说毫无意义，因为与子集数据的所有关系都是完全平坦且不显著的。为什么 GLMM 会预测与更多数据点之间存在强烈的负相关关系？这和转换有关吗？这是不好的做法吗？
以下是我拟合的模型类型的一些示例：
#pooled data (no subsets) -- best model 
m1 &lt;- glmer(transformedY ~ scale(X) + (1 | Z) + (1 | W), family = Gammma(link = &quot;log&quot;), data = d)
#scale(X)estimate = -1.1341, pval ~0
#Random effects: Z variance = 1.76056, Z Std. dev = 1.3269; W variance = 0.09249, W Std. dev = 0.3041 

#数据子集 -- 最佳模型 
m2 &lt;- glmer(transformedY ~ scale(X) + (1 | Z) + (1 | Q), family = Gamma(link = &quot;log&quot;), 
data = ds)
#scale(X) 估计 = -0.02805, p val = 1, 
#随机效应：Z 方差 = 0.061329, Z Std. dev = 0.2476; Q 方差 = 0.020675, Q Std. dv = 0.1438 

#注意：Q 和 W 都以略有不同的单位来测量时间。

我假设它与池中的随机效应有关，这些随机效应吸收了太多的变化，并以某种方式放大了固定效应，即使这种关系不是那么强？但这些随机效应是有意义的，并且包含结构，所以我不想忽视这一点。有什么建议或资源可以配合使用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660823/amplified-effect-of-fixed-effects-in-glmer-model-for-larger-dataset-compared-t</guid>
      <pubDate>Fri, 31 Jan 2025 17:08:18 GMT</pubDate>
    </item>
    <item>
      <title>依赖数据的引导 - 距离矩阵的均值</title>
      <link>https://stats.stackexchange.com/questions/660816/bootstrapping-of-dependent-data-mean-of-means-of-a-distance-matrix</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660816/bootstrapping-of-dependent-data-mean-of-means-of-a-distance-matrix</guid>
      <pubDate>Fri, 31 Jan 2025 16:54:40 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用 Beta 回归还是 Box Cox 变换线性回归？</title>
      <link>https://stats.stackexchange.com/questions/660815/should-i-use-beta-regression-or-box-cox-transformed-linear-regression</link>
      <description><![CDATA[我的响应变量是态度分数，它是比例分数（总分/最高分），因此是连续的，范围从 0-1。最初，我认为 Beta 回归会是一个不错的选择，所以我对分数进行了调整，以便没有真正的 0 或 1。
attitude_self$prop_score &lt;- pmin(pmax(attitude_self$prop_score, 0.001), 0.999)
我的模型如下，AIC 值为 -607：
beta_model &lt;- betareg(prop_score ~ age + group + gender + PerceivedKnowledge, 
data =itude_self, link = &quot;logit&quot;)

然而，经过进一步检查，似乎 prop_score 并不遵循真正的 beta 分布。我检查了分布/密度、偏度和峰度，并进行了 fitdist() 和 Kolmogorov-Smirnov (KS) 检验以测试拟合度。

偏度(prop_score)
[1] -2.792165
峰度(prop_score)
[1] 15.89607

fitdist(prop_score, &quot;beta&quot;)
通过最大似然法拟合分布“beta”
参数：
估计标准差。错误
shape1 2.6511869 0.17474578
shape2 0.7264323 0.03847695

&gt; ks.test(prop_score, &quot;pbeta&quot;, shape1 = 2.65, shape2 = 0.73)

渐近单样本 Kolmogorov-Smirnov 检验

数据：prop_score
D = 0.19366，p 值 &lt; 2.2e-16
备选假设：双侧

然后我使用 Box-Cox 变换对响应变量进行变换，并使用线性回归。
得到的 AIC 较低，为 -900，残差如下：

我转向变换后的线性回归而不是 beta 回归是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/660815/should-i-use-beta-regression-or-box-cox-transformed-linear-regression</guid>
      <pubDate>Fri, 31 Jan 2025 16:53:16 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑回归中，预测变量严重偏斜可以吗？还是应该进行变换？</title>
      <link>https://stats.stackexchange.com/questions/660818/is-it-ok-to-have-highly-skewed-predictors-in-a-logistic-regression-or-should-th</link>
      <description><![CDATA[我有 7 个预测变量和一个二进制 y。我在 r 中使用逻辑回归，想知道我的 4 个变量高度偏斜是否重要？我可以对它们进行对数变换以减少偏斜，虽然这肯定不是正常的，而且这会稍微提高我的分类准确性，但这通常可以做到吗，还是我应该不进行变换以降低准确性但提高可解释性？我的模型不是用于预测的，但我也希望它是准确的，所以这是逻辑回归的假设吗？此外，如果我对它们进行对数转换，这对于解释模型的输出意味着什么？
我的代码：
at_least1 &lt;- glm(at_least_1 ~ log(no_of_employees) + log(board_size) + sqrt(relative_board_size) + log(company_age) + average_age + FTSE,
data = company_data,
family = binomial(link = &quot;logit&quot;))
尝试了转换和不转换预测变量。不转换时，预测准确率为 0.7051，而随机准确率为 0.4999。转换后，准确率为 0.7690576。]]></description>
      <guid>https://stats.stackexchange.com/questions/660818/is-it-ok-to-have-highly-skewed-predictors-in-a-logistic-regression-or-should-th</guid>
      <pubDate>Fri, 31 Jan 2025 16:39:19 GMT</pubDate>
    </item>
    <item>
      <title>哪种统计检验？ - 重复双向方差分析有效吗？</title>
      <link>https://stats.stackexchange.com/questions/660811/which-statistical-test-does-repeated-two-way-anova-work</link>
      <description><![CDATA[我不确定要对我的数据使用哪种统计测试？
我试图找到：

星期几 → 温度在不同的日子里有显著变化吗？2. 位置 → 不同房间的温度有显著差异吗？或者星期几和房间的组合会显著改变温度吗？

我考虑过使用重复双向方差分析，但我不确定。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660811/which-statistical-test-does-repeated-two-way-anova-work</guid>
      <pubDate>Fri, 31 Jan 2025 14:59:45 GMT</pubDate>
    </item>
    <item>
      <title>根据回归分位数生成响应变量的条件分布</title>
      <link>https://stats.stackexchange.com/questions/660810/generating-a-conditional-distribution-of-a-response-variable-from-regression-qua</link>
      <description><![CDATA[在 R 中，我使用 quantreg 包生成回归分位数，以检查响应变量的完整条件分布。散点图呈楔形（非负异方差）。正如预期的那样，由于响应的这种形状，斜率系数增加并在上分位数范围（大于条件中位数）中变得具有统计意义。我想使用回归分位数来估计独立变量特定输入处的响应的条件分布。但是，由于下分位数（小于条件中位数）回归不具有统计意义，我想知道如何在纳入回归分位数的不确定性的同时估计独立变量输入处的条件分布？通常，我从一系列回归分位数中获取拟合值，并使用几种参数（对数正态）和非参数（核密度和对数样条）方法来生成条件分布。任何关于如何将拟合值（或其他方法）的不确定性纳入条件分布的意见都将不胜感激！一个更基本的问题：如果特定的条件分位数不显著（与独立变量无关——假设 tau=0.025）我是否应该使用非条件分位数来代替它？]]></description>
      <guid>https://stats.stackexchange.com/questions/660810/generating-a-conditional-distribution-of-a-response-variable-from-regression-qua</guid>
      <pubDate>Fri, 31 Jan 2025 14:58:55 GMT</pubDate>
    </item>
    <item>
      <title>作为 SMAPE 的替代品，$\min(a,f)/\max(a,f)$ 叫什么名字？</title>
      <link>https://stats.stackexchange.com/questions/660809/what-is-the-name-of-mina-f-maxa-f-as-an-alternative-to-smape</link>
      <description><![CDATA[我的一位同事要求我提供准确度测量。过去我被教导使用绝对百分比误差 (ape) ... 实际上是补充 (1 - ape)。这样更大的数字更好。
这很有效，除非预测是实际值的 2 倍。他提出了另一种方法。min(a,f)/max(a,f)，其中 a 是实际值，f 是预测值。
起初我建议 1 - 对称绝对百分比误差 (1 - (abs(a - f)/ (abs(a) + abs(f))))。SMAPE 是一个经过充分研究的指标。我从未见过他建议的东西，所以我一开始很犹豫。
与另一位数据科学家交谈后，生成了以下图表。它表明 min(a,f)/max(a,f) 具有与 smape 准确度相同/相似的属性，同时更简单。

这个指标有名字吗？
这个指标如何存在无法预见的缺陷？

对我来说，这看起来像是一个很好的错误指标，但我是一名实践者，而不是学者。我肯定我遗漏了一些东西。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660809/what-is-the-name-of-mina-f-maxa-f-as-an-alternative-to-smape</guid>
      <pubDate>Fri, 31 Jan 2025 14:54:54 GMT</pubDate>
    </item>
    <item>
      <title>McNemar 检验是否适合前后比较？</title>
      <link>https://stats.stackexchange.com/questions/660806/is-mcnemars-test-suitable-for-before-after-comparisons</link>
      <description><![CDATA[如果我理解正确的话，McNemar 检验通常用于测试两个二元结果之间的依赖关系。Agresti 在《分类数据分析》（我相信是 2002 年版）中给出了两个与环境相关的问题的示例，受试者同时回答这些问题。我提供了我自己的示例，其中的数字被夸大了，以便进行演示：
 Q2
Q1 同意 不同意
同意 945 5
不同意 10 40

在这里，我可以看到 McNemar 的检验是有道理的：大多数人同意这两个陈述，一些人同意其中一个而不同意另一个，还有少数人不同意两者。这听起来很合理。 p 值为 0.2，即两个问题的同意率没有显著差异。
但是，McNemar 检验也用于比较前后结果，如 Agresti 书中早期版本 (1990) 中的示例。因此，让我们使用上述数字，但将它们视为受试者对一个问题的回答，但在两个不同的时间点，$T_1$ 和 $T_2$。在这两个时间点，他们可能“同意”或“不同意”：
 T2
T1 同意 不同意
同意 945 5
不同意 10 40

由于计数的巨大不平衡，我发现 McNemar 检验中暗示的情景难以置信。我们想看看受试者是否会随着时间的推移而改变主意，结果发现一组（$T_1$ 的“同意者”）几乎没有变化（~0.5%），而“不同意者”则发生了很大变化：在 $T_1$ 不同意的受试者中，约有 20% 在 $T_2$ 同意。我认为这是一个“显著”的差异，但由于表中的数字与第一个示例中的数字相同，因此 McNemar 的检验仍然不显著。
在 $H_0$ 下，非对角线单元格中的绝对数字需要相似，而不是百分比。为了得到相似的数字，“T1 同意者”需要以与“不同意者”不同的概率改变主意，但这两个概率必须相关。换句话说，$H_0$ 意味着两组之间存在某种信息交换。或者，换句话说，“非对角线概率之间没有差异”假设可能意味着行概率之间存在相当大且非常精确的差异。这对我来说似乎非常不随机 - 与人们对零假设的期望完全相反。
或者我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660806/is-mcnemars-test-suitable-for-before-after-comparisons</guid>
      <pubDate>Fri, 31 Jan 2025 14:13:43 GMT</pubDate>
    </item>
    <item>
      <title>结构共线性</title>
      <link>https://stats.stackexchange.com/questions/660805/structural-collinearity</link>
      <description><![CDATA[我很难理解这些数据如何显示结构共线性？
这是否与在同一天在每个房间内进行测量有关？

每个星期一星期二都是新的一周，但每周一星期二都会进行两次测量，等等。]]></description>
      <guid>https://stats.stackexchange.com/questions/660805/structural-collinearity</guid>
      <pubDate>Fri, 31 Jan 2025 14:13:14 GMT</pubDate>
    </item>
    <item>
      <title>如何在 K 均值聚类中聚类/处理 B 样条线的不同长度系数向量</title>
      <link>https://stats.stackexchange.com/questions/660803/how-to-cluster-handle-different-length-coefficient-vectors-of-b-splines-in-k-mea</link>
      <description><![CDATA[我想根据在 3 或 4 个时间点进行的血压 (BP) 测量对数据集进行聚类。为此，我使用二次 B 样条（通过 scipy.interpolate.splrep）对每个人的血压轨迹进行建模，然后使用 k 均值 (sklearn.cluster.KMeans) 对得到的样条系数进行聚类。我采用了以下论文 https://ieeexplore.ieee.org/document/8031156 中的方法。
但是，对于有 4 个测量值的人，这会生成长度为 4 的（非零）样条系数向量，而对于缺少一个时间点的人，则会生成长度为 3 的样条系数向量。这会导致执行 k 均值聚类时出现问题，因为需要向量具有相同的维度。
在这里，我想避免多重插补并将我的分析限制在完整的案例中。然后我偶然发现了这篇论文 https://www.sciencedirect.com/science/article/pii/S1532046421002185#b0025，其中写道
&quot;Luong 和 Chandola（上述论文）提出了一种使用数据的 B 样条基础表示来学习具有 k 均值聚类的单个轨迹聚类的方法。这种方法允许不同的向量长度和缺失数据，而无需插补或分配零。它假设集群内的时间序列可以使用样条函数或多项式函数集合的加权和来近似”。我没有完全理解它们如何处理不同长度的系数向量。任何指导或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660803/how-to-cluster-handle-different-length-coefficient-vectors-of-b-splines-in-k-mea</guid>
      <pubDate>Fri, 31 Jan 2025 13:24:05 GMT</pubDate>
    </item>
    <item>
      <title>当比例风险假设不成立时，如何用重复测量来模拟事件发生时间</title>
      <link>https://stats.stackexchange.com/questions/660801/how-to-model-time-to-event-with-repeated-measures-when-proportional-hazards-assu</link>
      <description><![CDATA[我的数据：
我每天对两个连续变量进行测量，直到他们移民或死亡。
我的目标：
我想使用我的两个每日指标来预测移民时间。
我的模型：
我已经对预测因子进行了 Box Cox 转换和缩放。我已对状态 = 1 的死亡个体和状态 = 2 的移民个体进行了编码。days 是从研究开始到死亡或移民之间的天数。
例如：



ID
metric1
metric2
days
status




A
0.428
-1.42
267
2


A
0.204
-1.97
267
2


A
0.168
-2.65
267
2



我已经开始使用简单的 CoxPH 模型：
coxph(Surv(days, status) ~ metric1 = metric2, data=df)

测试比例风险假设会返回一个显著的全局 p 值。我只能假设这与我的度量随着时间的推移逐渐增加到渐近线有关，而随着年龄的增长，移民的可能性会更大，但死亡的可能性会更小。
我的下一步努力：
我发现了许多处理随时间变化数据的建议方法。这些包括使用tt()拟合时间变换，在coxme中添加随机效应，将预测因子与时间相互作用，使用联合建模，以及添加层或集群。
我的问题：
因为似乎有有如此多的选择被平等地提倡，我正在寻求建议，看是否存在“最佳”选择，如果有的话，对我来说哪个是最佳选择。]]></description>
      <guid>https://stats.stackexchange.com/questions/660801/how-to-model-time-to-event-with-repeated-measures-when-proportional-hazards-assu</guid>
      <pubDate>Fri, 31 Jan 2025 11:37:17 GMT</pubDate>
    </item>
    <item>
      <title>重新缩放特征增加了其进入 LASSO 模型的机会</title>
      <link>https://stats.stackexchange.com/questions/660795/rescaling-feature-increases-its-chances-to-be-in-lasso-model</link>
      <description><![CDATA[假设我们将 LASSO 回归拟合到一个数据集，该数据集具有 $100$ 个特征 $(X_1, \dots X_{100})$。现在，我们通过乘以 $10$（例如 $X_1$）来重新缩放其中一个特征，然后使用相同的正则化参数重新拟合 LASSO 回归。 $X_1$ 是否更有可能被纳入模型？
考虑到以下情况，我猜答案是否定的，但由于不太正式，我不确定

当将 $X_1$ 乘以 $10$ 时，我们将其在 OLS 中的系数除以 $10$。从示意图上看，LASSO 是通过最小化目标函数直到它达到 L1 范数的界限而获得的。我想到这种情况，其中 $\beta_{\text{LASSO}}$ 首先接近（$0.5,0.5$）。实际上，确切的值并不重要，但很明显 $X_1$ 将包含在模型中。然而，在将 $X_1$ 的 OLS 系数除以 10 后，相同的过程将不可避免地将新的 $\beta_{\text{LASSO}}$ 带到 $\approx(0,1)$，它将不会被包括在内。]]></description>
      <guid>https://stats.stackexchange.com/questions/660795/rescaling-feature-increases-its-chances-to-be-in-lasso-model</guid>
      <pubDate>Fri, 31 Jan 2025 09:55:29 GMT</pubDate>
    </item>
    <item>
      <title>在估算缺失值时，变量之间的时间关系重要吗？</title>
      <link>https://stats.stackexchange.com/questions/660792/does-the-temporal-relationship-between-variables-matter-when-imputing-missing-va</link>
      <description><![CDATA[我现在的情况是，我有多个变量，包含缺失值，在时间 $t0$ 测量，还有一些变量在时间 $t1$ 测量，这可能是几年后。
我需要在 $t0$ 时估算变量中的缺失值，为此我将使用当时可用的任何信息。是否还应该使用时间上在之后出现的变量的信息？我知道关于是否包括响应变量的讨论，但在这种情况下，变量之间的关系具有明显的方向性。目标（下游分析）是估计时间 0 时某些暴露对时间 1 时某些结果的因果影响。结果在估算过程中用于估算其他变量，但本身不会被估算。]]></description>
      <guid>https://stats.stackexchange.com/questions/660792/does-the-temporal-relationship-between-variables-matter-when-imputing-missing-va</guid>
      <pubDate>Fri, 31 Jan 2025 08:07:24 GMT</pubDate>
    </item>
    </channel>
</rss>