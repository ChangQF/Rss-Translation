<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 09 Dec 2024 15:19:09 GMT</lastBuildDate>
    <item>
      <title>就业状况类别包括退休人员、学习者、学生和非在校人员</title>
      <link>https://stats.stackexchange.com/questions/658491/employment-status-categories-that-include-pensioners-learners-students-and-non</link>
      <description><![CDATA[我收集了有关就业状况的数据集。我创建了以下类别：退休人员、正式就业人员、非正式就业人员、自雇人员和失业人员。我还有学习者或学生以及那些未在校学生的类别，我的问题是，我是否可以将退休人员、学习者或未在校学生归入就业状态，还是应该将他们都归入失业类别？]]></description>
      <guid>https://stats.stackexchange.com/questions/658491/employment-status-categories-that-include-pensioners-learners-students-and-non</guid>
      <pubDate>Mon, 09 Dec 2024 15:03:35 GMT</pubDate>
    </item>
    <item>
      <title>R：如何用自定义协方差结构拟合两个随机截距的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/658490/r-how-to-fit-a-linear-mixed-model-with-a-custom-covariance-structure-for-two-ra</link>
      <description><![CDATA[假设我有一个在 q 个簇上有重复测量值的数据集。我想在同一个簇上拟合一个具有两个随机截距的 LMM，在随机效应上具有非对角线协方差结构（如果它是对角线，我假设模型将无法识别）。
即：
y_{ij} = x_{ij}^T\beta + b_{1j} + b_{2j} + \varepsilon_{ij}，
其中 y_{ij} 是第 j 个簇中的第 i 个观测值（j = 1, ..., q; i = 1, ... n_j）。同样，如果 b_{1j} 和 b_{2j} 是独立的，我假设模型无法识别，但我希望它们是相关的。假设 b 为长度为 2q 的随机效应向量，则 b 服从均值为 0 且协方差为 2q X 2q 的高斯分布：
q &lt;- 3
rho &lt;- 0.5
sig2b1 &lt;- 1
sig2b2 &lt;- 1
D &lt;- matrix(c(sig2b1 ,rho, rho, sig2b2),nrow = 2) %x% diag(q)
D

[1,] 1.0 0.0 0.0 0.5 0.0 0.0
[2,] 0.0 1.0 0.0 0.0 0.5 0.0
[3,] 0.0 0.0 1.0 0.0 0.0 0.5
[4,] 0.5 0.0 0.0 1.0 0.0 0.0
[5,] 0.0 0.5 0.0 0.0 1.0 0.0
[6,] 0.0 0.0 0.5 0.0 0.0 1.0

（此处 q = 3，对角线上 \sigma^2_{b1} = \sigma^2_{b2} = 1，我们有三个方差分量需要估计，不包括残差方差 \sigma^2_e）
现在该模型是矢量形式的标准 LMM：
y = X\beta + Zb + \varepsilon,
让我们获取一些数据：
library(mvtnorm)

b &lt;- t(rmvnorm(n = 1, mean = rep(0, 2 * q), sigma = D))
# 可以执行：plot(b[1:q], b[(q+1):(2*q)]) 来查看相关性
z &lt;- rep(letters[1:q], times = c(3,3,2) * 10)
n &lt;- length(z)
Z &lt;- model.matrix(~0 + z)
Z &lt;- cbind(Z, Z) # 注意 Z 与自身连接，Z 的阶数为 n X 2q
x &lt;- rnorm(n)
y &lt;- 1 + 2 * x + Z %*% b + rnorm(n)

使用lme4 具有两个随机截距，令人惊讶的是（有时）还不错：
library(lme4)

mod &lt;- lmer(y ~ x + (1|z) + (1|z))

# 可以这样做：plot(b[1:q], ranef(mod)$z[,1])
# 和：plot(b[(q + 1):(2 * q)], ranef(mod)$z[,2])
# 和：VarCorr(mod)

但我想用 D 协方差结构拟合模型，其中每个聚类 j 的随机截距之间存在一定的相关性。]]></description>
      <guid>https://stats.stackexchange.com/questions/658490/r-how-to-fit-a-linear-mixed-model-with-a-custom-covariance-structure-for-two-ra</guid>
      <pubDate>Mon, 09 Dec 2024 13:41:57 GMT</pubDate>
    </item>
    <item>
      <title>Cox 类模型：比例风险的加权和</title>
      <link>https://stats.stackexchange.com/questions/658488/cox-like-model-weighted-sum-of-proportional-hazards</link>
      <description><![CDATA[我们正尝试在风险分层人群中推断流行病期间疫苗有效性 (VE)。
模型：
考虑 Cox 模型：
$$ \lambda_{ik}(t) = \lambda_0(t) \exp [\beta X_{ik}] $$
并与经典传播模型发生率方程进行比较：
$$ \lambda_{ik}(t) = \rho V_k C_i \sum_j \phi_{ij} P_j$$
其中：

$i$ 表示自身风险组，$j$ 表示接触风险组
$k$ 表示疫苗接种状态
$\rho$ 是每次接触的基本传播概率
$V_k$ 是疫苗效果（如果接种疫苗，VE &lt; 1，否则为 1）
$C_i$ 是风险组 $i$ 的接触率
$\phi_{ij}$ 是 $i$ 个人与 $j$ 形成给定接触的概率
$P_j = I_j / N_j$ 是 $j$ 组中的感染流行率。

情况 1：随机混合。
在随机混合的情况下，$\phi_{ij}$ 不依赖于 $i$，因此：

$\lambda_0(t) = \rho \sum_j \phi_{*j} P_j(t)$
$\exp[\beta_V X^V_k] = V_k$
$\exp[\beta_C X^C_i] = C_i$

我们有 Cox 模型和传播模型方程之间的直接对应关系：太棒了！
案例 2：非随机混合。
如果 $\phi_{ij}$ 取决于 $i$，则每个组 $i$ 将经历独特的风险“$\lambda_{0,i}(t)$”，即其接触者风险组 $j$ 的平均患病率，由混合分布 $\phi_{i*}$ 加权：

$\lambda_{0,i}(t) = \rho \sum_j \phi_{ij} P_j(t)$

这显然违反了组/层$i$之间的比例风险假设。但是，我们似乎仍然能够使用一些技巧以类似 Cox 的方式推断 $\beta_V$ - 即避免使用某种条件可能性估计 $P_j(t)$、$\phi_{ij}$ 和/或 $C_i$。
如果有帮助，有一些自然的约束：$0 \le P_j(t) \le 1$、$0 \le \phi_{ij} \le 1$ 和 $\sum_j \phi_{ij} = 1$。对于$\phi_{ij}$，还有合理的参数形式，我们可以使用它来联合估计$\phi_{ij}$。
奖励。当然，$P_j(t)$实际上是传输模型的输出，因此关于是否/如何通过来自$\lambda_i(t)$的反馈来约束估计的任何见解都将是出色的。]]></description>
      <guid>https://stats.stackexchange.com/questions/658488/cox-like-model-weighted-sum-of-proportional-hazards</guid>
      <pubDate>Mon, 09 Dec 2024 13:41:26 GMT</pubDate>
    </item>
    <item>
      <title>如何理解一致中心极限定理</title>
      <link>https://stats.stackexchange.com/questions/658487/how-to-understand-the-uniform-central-limit-theorem</link>
      <description><![CDATA[在 Nickl 的一篇 论文 中，我发现了一个具有中心极限定理形式的定理（定理 4）
$$\sqrt{n}(P_n-P)\rightarrow G$$
在 $l^\infty(F)$ 中，其中 $P$ 是 $\mathbb{R}$ 上的一条定律，$F$ 是一类函数，$G$ 是高斯过程由 $f\in F$ 索引。但我熟悉的中心极限定理的形式为：
$$f_n-f\rightarrow G$$
其中 $G$ 由 $x\in\mathbb{R}$ 索引。
我正在寻求帮助以理解第一个版本，也想知道是否可以将其转换为第二个版本？在第二个版本中要求 $f\in F$ 是否正确？非常感谢任何提示！]]></description>
      <guid>https://stats.stackexchange.com/questions/658487/how-to-understand-the-uniform-central-limit-theorem</guid>
      <pubDate>Mon, 09 Dec 2024 13:32:48 GMT</pubDate>
    </item>
    <item>
      <title>基线和多次随访的前后设计（无控制）（元分析）</title>
      <link>https://stats.stackexchange.com/questions/658486/pre-post-design-no-control-at-baseline-and-multiple-follow-up-times-meta-anal</link>
      <description><![CDATA[我正在从事一个荟萃分析项目，需要有关选择正确统计方法的建议。我们可以查阅大约 18 篇出版物。该设计类似于治疗前后设计（无对照组）。但我们有两个以上的时间点。
在这些出版物中，受试者在治疗前后的不同时间点（T0、T1、T3、T6）来到诊所检查胆固醇值。在接受治疗之前的 T0 测量他们的胆固醇值，然后对他们进行治疗。要求他们在一个月后（T1）回来接受治疗并再次测量。这个过程在三个月和六个月时重复。
研究问题是将每个时间点的治疗效果与基线进行比较，以确定治疗需要多长时间才能见效。如果患者在 3 个月后没有出现改善，他们可能会考虑换一种治疗方法。但是，如果 3 个月没有改善，但 6 个月有明显改善，他们可能会考虑继续注射更多相同的药物。
出版物包括单独配对样本检验（配对 t 检验或 Wilcoxon 符号秩检验）的结果，以比较 T1 与 T0、T3 与 T0 和 T6 与 T0（设计前后的配对样本）。因此，我们可以访问平均值和标准差（治疗前后）的值以及 p 值*
我们的数据是这样的：
出版物 T0 与 T1 T0 与 T3 T0 与 T6

现在，我想知道我们应该如何将荟萃分析方法应用于这些类型的研究？我们是否也应该对每个比较应用单独的荟萃分析？任何关于潜在和正确的统计技术或参考资料的建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658486/pre-post-design-no-control-at-baseline-and-multiple-follow-up-times-meta-anal</guid>
      <pubDate>Mon, 09 Dec 2024 13:30:12 GMT</pubDate>
    </item>
    <item>
      <title>识别策略足球比赛</title>
      <link>https://stats.stackexchange.com/questions/658484/identification-strategy-soccer-match</link>
      <description><![CDATA[我有关于足球比赛中球员在什么时候被出示黄牌的数据。我还知道某位球员在球场上待了多长时间（即他是否从一开始就在球场上，还是被替换下场）。我还知道比赛时的气温是多少。我想调查一下较高的气温是否会影响球员的攻击性行为。
当然，我可以检查一场比赛中的黄牌数量与气温之间的关系：$yellow\_cards \sim beta_{0} + beta_{1} \cdottemperature$
但我想看看这种关系是否在比赛后期更强，那时球员应该更热、更烦躁。同时看看刚被替换下的球员是否不受这种关系的影响。
我应该使用什么回归规范来检查这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/658484/identification-strategy-soccer-match</guid>
      <pubDate>Mon, 09 Dec 2024 12:33:35 GMT</pubDate>
    </item>
    <item>
      <title>如果我没有用于进行第 1 步：形成性测量模型的冗余分析的全局单个项目该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/658482/what-if-i-dont-have-a-global-single-item-for-conducting-step-1-redundancy-anal</link>
      <description><![CDATA[我后来才意识到，CSR 和客户满意度在理论上被视为形成性构造。
这是我的概念框架
我的理论框架及其相应的解释变量包括 Caroll 的 CSR 金字塔 (CSR)、社会认同理论 (客户忠诚度)、信号理论 (企业声誉) 和利益相关者理论 (客户满意度)。
这是我从 Zhang (2022) 中采用的调查工具

希望您能帮忙。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658482/what-if-i-dont-have-a-global-single-item-for-conducting-step-1-redundancy-anal</guid>
      <pubDate>Mon, 09 Dec 2024 11:07:00 GMT</pubDate>
    </item>
    <item>
      <title>二项分布 - IID 假设可以放宽吗？</title>
      <link>https://stats.stackexchange.com/questions/658481/the-binomial-distribution-can-the-iid-assumption-be-relaxed</link>
      <description><![CDATA[上下文：
新手问题：在应用二项分布时
X ~ 二项式 ( n, Theta )
，一个关键假设是每个个体“成功”的概率是相同且独立分布的。经常使用的示例基于同一枚公平硬币被翻转 n 次。X 是成功次数。
问题：
如果我使用 Theta 为 0.25 的硬币进行 n/2 次翻转，并使用 Theta = 0.75 的另一枚硬币进行 n/2 次翻转，该公式是否可靠地给出相同的答案？
我知道在这种情况下通过重新加权 Theta 会给出相同的答案，但它在理论上合理且实际适用吗？
从表面上看，这似乎至少混淆了相同假设。但是，从整个样本来看，预期的 Theta 可以被认为是相同的。我不清楚 IID 假设的确切含义。
理由：
我相信至少在遗传学中，存在 IID 假设可能自然适用的情况，就像单个硬币一样。然而，在社会科学和商业领域，我们经常会有一群“不同 Theta”的人。一项随机调查可能会有 50 人来自低收入地区，50 人来自高收入地区。如果我天真地将二项分布应用于如此复杂的样本，是否需要考虑额外的抽样误差或类似因素？
这是一个初学者问题，我希望得到一个基本的答案，也许可以给出任何值得研究的进一步主题的指示。提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/658481/the-binomial-distribution-can-the-iid-assumption-be-relaxed</guid>
      <pubDate>Mon, 09 Dec 2024 11:06:03 GMT</pubDate>
    </item>
    <item>
      <title>筛选财富 1000 强企业 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658477/filtering-on-fortune-1000-companies</link>
      <description><![CDATA[我正在寻找财富 1000 强公司的股票价格数据。有人知道在 Compustat（或其他数据库）中是否有一种简单的方法可以专门针对财富 1000 强公司进行筛选吗？也就是说，财富 1000 强公司是否有特定的类别或标识符，还是我需要单独查找每家公司？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658477/filtering-on-fortune-1000-companies</guid>
      <pubDate>Mon, 09 Dec 2024 10:08:06 GMT</pubDate>
    </item>
    <item>
      <title>未能提高 Tiny VGG CNN 模型的准确率</title>
      <link>https://stats.stackexchange.com/questions/658476/failing-to-improve-accuracy-in-tiny-vgg-cnn-model</link>
      <description><![CDATA[设置

我试图学习如何在 PyTorch 中编写 CNN 的基础知识。
我几乎是一丝不苟地遵循 05. PyTorch Going Modular 来学习如何以脚本方式建模，写下 CNN Explainer 中描述的 CNN 模型 Tiny VGG。

我正在练习的数据，如 05. PyTorch Going Modular 是 pizza-steak-sushi 数据集；加载和转换方式与 此处 相同。

再次，该模型是这里中的模型。
问题

经过多次尝试设置以下超参数：
NUM_EPOCHS = 20
BATCH_SIZE = 20
HIDDEN_UNITS = 10
LEARNING_RATE = 0.0005

并使用一对损失函数和优化器：
loss_fn = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(tiny_vgg.parameters(), lr=LEARNING_RATE)

我无法提高模型在训练和（大部分）测试数据集中的准确率，目前如下所示：
Epoch：1 | train_loss：1.1018 | train_acc：0.2875 | test_loss：1.0947 | test_acc：0.4500
Epoch：2 | train_loss：1.0974 | train_acc：0.3833 | test_loss：1.0970 | test_acc：0.3125
Epoch：3 | train_loss：1.0960 | train_acc：0.3375 | test_loss：1.0995 | test_acc：0.3125
Epoch：4 | train_loss：1.0895 | train_loss：0.3500 | test_loss：1.1013 | test_acc：0.3125
Epoch：5 | train_loss：1.0626 | train_acc：0.3917 | test_loss：1.0755 | test_acc：0.3250
Epoch：6 | train_loss：1.0566 | train_acc：0.3750 | test_loss：1.0666 | test_acc：0.3375
Epoch：7 | train_loss：1.0105 | train_loss：0.5542 | test_loss：1.0133 | test_acc：0.4208
Epoch：8 | train_loss：0.9488 | train_acc：0.5708 | test_loss：1.0114 | test_acc：0.4792
时期：9 | train_loss：0.8834 | train_acc：0.5625 | test_loss：0.9973 | test_acc：0.4208
时期：10 | train_loss：0.8751 | train_acc：0.5667 | test_loss：1.0350 | test_acc：0.4542
时期：11 | train_loss：0.8098 | train_acc：0.6375 | test_loss：0.9834 | test_acc：0.4458
时期：12 | train_loss：0.8136 | train_acc：0.6333 | test_loss：1.0400 | test_acc：0.3792
时期：13 |训练损失：0.8042 | 训练误差：0.6833 | 测试损失：0.9929 | 测试损失：0.4458
时期：14 | 训练损失：0.7932 | 训练误差：0.6292 | 测试损失：1.0383 | 测试损失：0.4333
时期：15 | 训练损失：0.7796 | 训练损失：0.6458 | 测试损失：1.0025 | 测试损失：0.4833
时期：16 | 训练损失：0.7654 | 训练损失：0.6708 | 测试损失：1.0344 | 测试损失：0.4375
时期：17 | 训练损失：0.7412 | 训练损失：0.6833 | test_loss：1.0358 | test_acc：0.4625
时期：18 | train_loss：0.7168 | train_acc：0.6667 | test_loss：1.0759 | test_acc：0.4125
时期：19 | train_loss：0.7364 | train_acc：0.6500 | test_loss：1.0393 | test_acc：0.4583
时期：20 | train_loss：0.7228 | train_acc：0.7167 | test_loss：1.0826 | test_acc：0.4500


因此，我想知道我是否缺少了架构方面的某些东西、超参数设置，或者其他一些东西，例如此类模型缺乏数据等等。]]></description>
      <guid>https://stats.stackexchange.com/questions/658476/failing-to-improve-accuracy-in-tiny-vgg-cnn-model</guid>
      <pubDate>Mon, 09 Dec 2024 10:00:51 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用 momentFit 显示不同 GMM 模型的结果 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658475/show-results-for-different-gmm-models-with-momentfit-in-r</link>
      <description><![CDATA[我想知道是否有办法显示不同 GMM 模型估计的结果，就像 stargazer 所做的那样，但对于 momentFit 包来说却并非如此。此外，是否可以使用 stargazer 显示 momentFit 的估计结果？
任何评论都将不胜感激。
祝好，]]></description>
      <guid>https://stats.stackexchange.com/questions/658475/show-results-for-different-gmm-models-with-momentfit-in-r</guid>
      <pubDate>Mon, 09 Dec 2024 09:19:50 GMT</pubDate>
    </item>
    <item>
      <title>从多元正态分布中抽样以对 BM 进行抽样</title>
      <link>https://stats.stackexchange.com/questions/658469/sampling-from-the-multivariate-normal-in-order-to-sample-bm</link>
      <description><![CDATA[上周，有人发了一个问题，问是否可以生成多元正态分布并用它来采样布朗运动。我试图解释说这行不通，因为独立增量和 cov(s,t) = min(s,t) 的性质不成立。我并没有特别成功地说服这个人，但我能够找到下面的文档。我再也找不到原始线程，但下面的文档显示，可以通过以下方式生成 BM 样本：
A) 生成多元正态 RV。
B) 乘以时间因子（当前 $Z_{i+1}$ 和 $Z_{i}$ 之间的时间差的平方根），然后将 $Z_{i}$ 相加，直到时间 ${i+1}$。
因此，对于步骤 A)，可以生成多元正态，但步骤 B) 对于模拟 BM 至关重要。没有第二步，就无法实现 BM 的其他关键属性。
我只是想添加“结尾”参与讨论，希望提问的人
会看到这篇文章，并澄清我想对他说的话。如果有人知道原始帖子在哪里并想添加此链接，请随意添加。
https://www.columbia.edu/~ks20/4404-Sigman/4404-Notes-sim-BM.pdf
该算法可能也出现在优秀的布朗运动教科书中，例如 Schilling 和 Wiersema，但我才刚刚开始阅读它们，所以我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/658469/sampling-from-the-multivariate-normal-in-order-to-sample-bm</guid>
      <pubDate>Mon, 09 Dec 2024 03:17:48 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有基本事实的情况下计算模型的整体置信度？</title>
      <link>https://stats.stackexchange.com/questions/658468/how-to-compute-overall-confidence-of-model-without-ground-truth</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658468/how-to-compute-overall-confidence-of-model-without-ground-truth</guid>
      <pubDate>Mon, 09 Dec 2024 02:06:41 GMT</pubDate>
    </item>
    <item>
      <title>IV 等级/相关性条件线性代数直觉</title>
      <link>https://stats.stackexchange.com/questions/658451/iv-rank-relevance-condition-linear-algebra-intuition</link>
      <description><![CDATA[考虑以下计量经济模型（IV）：$Y_1 = X&#39;\beta + e$，其中$Y_1 \in \mathbb{R}$是一些感兴趣的结果变量，我们有一组回归量$X = \begin{bmatrix} Z_1 \\ Y_2 \end{bmatrix} \in \mathbb{R}^k$。 ($Z_1 \in \mathbb{R}^{k_1}, Y_2 \in \mathbb{R}^{k_2}, k_1 + k_2 = k \:$) 假设我们可能有一些混杂因素，因此$\mathbb{E}[Xe] \neq 0$。但是假设我们也有一些工具变量$Z=\begin{bmatrix}Z_1\\Z_2 \end{bmatrix} \in \mathbb{R}^{\mathcal{l}}$，使得$\mathbb{E}[Ze] =0, \mathbb{E}[ZZ&#39;]$为psd，并且$\mathbb{E}[ZX&#39;]$的秩为$k$（相关性）。
我对相关性条件很好奇：$\mathbb{E}[ZX&#39;]$的秩必须为$k$。我可以理解这里与 $Cov(X, Z)$ 的联系，但我只是不太清楚为什么秩条件意味着这一点（与 $Z$ 变换对 $X$ 列的作用有关），以及这在某种意义上必须“保留”至少 $X$ 维度才能相关。
此外，在我看来，这似乎与原始 OLS 案例中的秩条件有些相关：$\hat{\beta} = (X&#39;X)^{-1}X&#39;Y_1$，其中秩也必须是 $k$（这次我们希望我们的回归量是线性独立，每个“提供新的东西”）。这再次将 $\beta$ 的最简单形式概括为 $\frac{Cov}{Var}$。
总结一下，我缺少一些几何直觉，无法理解这些变换如何告诉我们空间中不同变量的方差/协方差。即，形式 $ZX&#39;$ 与解释这些变量之间的协变有什么直观的几何联系？以 $X&#39;X$ 为例，我可以看到当 $X$ 被贬低（或包含一个常数）时，$Var(X) = Cov(X, X) = \mathbb{E}[XX&#39;]$ 如何，因此对于一个样本，它变为 $\frac{1}{n} \mathbf{X&#39;X}$。对于上面的 $\mathbb{E}[ZX&#39;]$，为什么我们需要 rank = $k$ 才能使 $Cov$“不为 0”？]]></description>
      <guid>https://stats.stackexchange.com/questions/658451/iv-rank-relevance-condition-linear-algebra-intuition</guid>
      <pubDate>Sun, 08 Dec 2024 11:34:47 GMT</pubDate>
    </item>
    <item>
      <title>带有 Adam 优化器网络的单层/单单元如何工作？</title>
      <link>https://stats.stackexchange.com/questions/658436/how-does-a-single-layer-single-unit-with-adam-optimizer-network-work</link>
      <description><![CDATA[我对 ML 还很陌生，正在尝试使用线性回归。我测试了 sklearn 的 LinearRegression 模型，然后想将结果与一个非常简单的神经网络进行比较。
我创建了一个具有 1 层和 1 个单元的 tensorflow Dense 网络，并带有“线性”激活函数。
我使用了“sgd”和“adam”优化器，并使用 MinMaxScaler 缩放了 x 数据
我得到了与 LinearRegression 模型截然不同的结果（预测和损失）。
我有两个问题：

具有线性激活的 1 层/1 个单元网络是否与 LinearRegression 相同？

SGD 预测非常接近，我正在用房价进行测试，所以我会得到相对接近的结果。目标值在 1000 左右，因此 y_train 数组中的 120,000 美元价格被设置为 120。但是，当我使用 Adam 优化器时，我得到的预测值非常低（不到 20）。我从 100 个 epoch 开始，然后增加到 1000 个，但仍然得到了类似的结果。我是不是在某个地方做错了什么，或者 Adam 优化器是否有限制或某些要求才能正常工作。

]]></description>
      <guid>https://stats.stackexchange.com/questions/658436/how-does-a-single-layer-single-unit-with-adam-optimizer-network-work</guid>
      <pubDate>Sun, 08 Dec 2024 03:47:10 GMT</pubDate>
    </item>
    </channel>
</rss>