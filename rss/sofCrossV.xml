<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 03 Apr 2024 09:14:26 GMT</lastBuildDate>
    <item>
      <title>RNA-Seq 分析的统计阈值：考虑治疗效果的交叉点</title>
      <link>https://stats.stackexchange.com/questions/644170/statistical-thresholds-for-rna-seq-analysis-considering-the-intersection-of-tre</link>
      <description><![CDATA[我正在进行一项 RNA 测序实验，涉及暴露于化学物质 A、B 和 A+B 的线虫，以观察由于暴露而导致的 mRNA 变化。我特别感兴趣的是确定 A+B 处理与单独处理 A 或 B（作为对照）相比的 mRNA 变化。
为了分析这一点，我使用了edgeR（一种统计方法）来分别比较A与A+B以及B与A+B，然后检查结果的交集（将A与A+B相交以及B与A+B相交） A+B）。
在我的方法中，我使用拦截方法，旨在识别 A 与 A+B 以及 B 与 A+B 中差异表达的转录本。我的问题涉及对每个单独分析（A 与 A+B 和 B 与 A+B）使用高于 0.05 的 p 值阈值的合理性。
为了进一步解释，我正在考虑概率乘法规则。如果事件 A 的概率为 1/2，事件 B 的概率相同为 1/2，则两个事件同时发生的概率计算为 (1/2)*(1/2) = 1/4。 
我很好奇是否可以在这里应用类似的原则。具体来说，如果我开始时每次单独分析的 p 值为 0.223，我是否可以将该值平方以获得截距的 p 值，从而得到 (0.223)^2 = 0.05？但是，我不确定在两次比较中使用相同的 A+B 读数可能会如何影响此计算。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644170/statistical-thresholds-for-rna-seq-analysis-considering-the-intersection-of-tre</guid>
      <pubDate>Wed, 03 Apr 2024 08:27:10 GMT</pubDate>
    </item>
    <item>
      <title>预测收集额外数据的好处</title>
      <link>https://stats.stackexchange.com/questions/644167/predict-benefit-of-gathering-additional-data</link>
      <description><![CDATA[我生成了数据，然后根据这些数据执行数千次独立测试，并在多重假设校正后寻找在 p 值阈值 0.01 时显着的数据。
这给出了有用的结果，但我经常被问到的一个问题是，我们是否可以使用生成的数据来预测，如果我们生成更多的数据，还有多少测试将是重要的。也就是说，如果我们将生成的数据增加 x%，我们就可以预测还有多少测试可能是重要的。
我的直觉是这是不可能的，但也许我可以以某种方式使用 p 值分布（及其与均匀值的偏差）来估计有多少可能在更大的深度上是显着的？我的另一个想法是对数据进行下采样，并尝试构建“显着测试数量”的经验曲线作为数据量的函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/644167/predict-benefit-of-gathering-additional-data</guid>
      <pubDate>Wed, 03 Apr 2024 07:42:30 GMT</pubDate>
    </item>
    <item>
      <title>相对误差优化与对数尺度优化</title>
      <link>https://stats.stackexchange.com/questions/644166/optimization-of-relative-error-vs-optimization-on-log-scale</link>
      <description><![CDATA[我目前正在训练一个模型来预测房屋销售价格，$P$，作为一组特征的函数$\textbf{x}$。我选择的模型是对数指定的回归模型，其形式为：
\begin{align}
\ln(P) = f(\textbf{x}) \ \ \ (1)
\end{对齐}
我用普通最小二乘法拟合。
现在，对于我的应用程序来说，重要的通常不是绝对误差，而是相对误差。使用具体的错误措施，我例如通常对通过平均绝对相对误差进行良好测量的模型更感兴趣
\begin{align}
\varepsilon_{\text{rel}} = \frac{1}{N}\sum_{j} \| P_{j} - \hat{P} \|/P_{j} \ \ \ (2)
\end{对齐}
与更标准的平均绝对误差相反
\begin{align}
\varepsilon = \frac{1}{N}\sum_{j} \| P_{j} - \hat{P} \| \ \ \ (3)
\end{对齐}
我的问题如下：在什么意义上可以将对数尺度上的优化视为相当于模型相对误差的最小化？
为了详细说明是什么导致我提出这个问题，请考虑以下简单示例。假设我只有两个价格数据点 $P_{1} = 10, P_{2} = 100$ 并考虑最简单的模型，该模型仅使用数据点作为模型预测。很明显，使用对数转换可以减少总体相对误差 $\hat{P}_{\text{ln}} = \exp((\ln(100) + \ln(10))/2) \约 32$ 和 $\hat{P} = (100 + 10)/2 = 55$ ，其中前者具有较低的平均绝对相对误差（如（2）所示）。
回到我原来的问题，是否有更精确的数学方法来表达上述推理？我自己的尝试如下。假设训练了（1）中给出的形式的对数指定回归模型。这对应于最小化以下形式的最小二乘成本：
\begin{align}
C = \sum_{j}(\ln(P_{j}) – f(\textbf{x}_{j}))^2
\end{对齐}
现在，鉴于拟合函数接近于 $\ln(P_{j})$ 我们可以写成  $f(\textbf{x}_{j}) = \ln(P_{j} + \Delta P)$，其中 $\Delta P$ span&gt; 是一些小数字。对于第一个订单，我们然后找到
\begin{align}
C = \sum_{j}(\ln(P_{j}) – \ln(P_{j} + \Delta P))^2 = \sum_{j}(\ln((P_{j} + \Delta P)) P )/P_{j}))^2 = \sum_{j}(\ln((1 + \Delta P/P_{j}))^2 \近似 \sum_{j}(\Delta P/P_{ j})^2。
\end{对齐}
这表明，对数尺度上价格的一阶优化相当于相对误差的优化。上述推理是否有意义，或者是否有更简单、更优雅的方式来表达我想说的内容？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/644166/optimization-of-relative-error-vs-optimization-on-log-scale</guid>
      <pubDate>Wed, 03 Apr 2024 07:42:01 GMT</pubDate>
    </item>
    <item>
      <title>ARDL 包中的订单选择</title>
      <link>https://stats.stackexchange.com/questions/644164/order-selection-in-the-ardl-package</link>
      <description><![CDATA[如何在 R 的 ARDL 包中选择正确的顺序？例如，在 dLagM 包中，您可以让包自动选择 ARDL 顺序。你能在 ARDL 包中做到这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644164/order-selection-in-the-ardl-package</guid>
      <pubDate>Wed, 03 Apr 2024 07:25:28 GMT</pubDate>
    </item>
    <item>
      <title>SVM优化目标是如何从铰链损失函数导出的？</title>
      <link>https://stats.stackexchange.com/questions/644163/how-is-the-svm-optimization-objective-derived-from-the-hinge-loss-function</link>
      <description><![CDATA[在 SVM 的背景下，铰链损失函数如下：
$$
\mathcal{L}(\mathbf{\vec w}, b\,; \mathbf{\vec x}^{(i)}, y^{(i)}) = \max(0, 1-y^ {(i)}(\mathbf{\vec w}\cdot \mathbf{\vec x}^{(i)} + b))
$$
相应的成本函数将给出为：
$$
J(\mathbf{\vec w}, b) = \frac{1}{2}\|\mathbf{\vec w}\|^{2}_{2} + C\sum_{i=1}^ {m}\max(0,1 - y ^{(i)}(\mathbf{\vec w}\cdot \mathbf{\vec x}^{(i)} + b))
$$
从这里我们可以将优化目标表述为：
$$
\min _{\mathbf{\vec w, b}} J(\mathbf{\vec w}, b) = \min _{\mathbf{\vec w}, b} \frac{1}{2}\ |\mathbf{\vec w}\|^{2}_{2} + C\sum_{i=1}^{m}\max(0, 1 - y ^{(i)}(\mathbf{\ vec w}\cdot \mathbf{\vec x}^{(i)} + b))
$$
但是，原始优化目标通常给出为：
$$
\开始{对齐}
&amp; \min _{\mathbf{\vec w}, b} \frac{1}{2} \|\mathbf{\vec w}\|^{2}_{2} \\
&amp; \text{s.t.}\; y ^{(i)}(\mathbf{\vec w} \cdot \mathbf{\vec x}^{(i)} + b) \ge 1\; \forall i\in\mathbb{N}_{m}
\结束{对齐}
$$
从这里我们可以使用拉格朗日乘子法和 KKT 条件导出双重优化目标
我的问题是上面制定的原始优化目标是如何从铰链成本函数导出的？
此外，为什么正则化常数不是原始优化目标的一部分，即使它是双重优化目标的一部分（作为约束）？]]></description>
      <guid>https://stats.stackexchange.com/questions/644163/how-is-the-svm-optimization-objective-derived-from-the-hinge-loss-function</guid>
      <pubDate>Wed, 03 Apr 2024 06:55:20 GMT</pubDate>
    </item>
    <item>
      <title>医疗预测 AI 模型、校准曲线轴表示顺序</title>
      <link>https://stats.stackexchange.com/questions/644162/medical-predictive-ai-model-calibration-curve-axes-representation-order</link>
      <description><![CDATA[在医疗环境中表示校准曲线时，通常以实验室分析测定中的方式表示它们，其中浓度类似于“阳性分数”。在x轴上并且“预测概率”在x轴上。在 y 轴上。当看纯机器学习论文时，情况似乎正好相反。你们中那些在医学和人工智能交叉方面具有专业知识的人，轴朝哪边走？]]></description>
      <guid>https://stats.stackexchange.com/questions/644162/medical-predictive-ai-model-calibration-curve-axes-representation-order</guid>
      <pubDate>Wed, 03 Apr 2024 06:49:10 GMT</pubDate>
    </item>
    <item>
      <title>m=365 时 PM10 浓度预测的 SARIMA 模型存在问题</title>
      <link>https://stats.stackexchange.com/questions/644159/issue-with-sarima-model-for-pm10-concentration-forecasting-with-m-365</link>
      <description><![CDATA[我正在尝试构建 SARIMA（季节性自回归综合移动平均线）模型，用于根据五年的数据预测 PM10 浓度。但是，当我将季节性参数 m 设置为 365 时，我的代码似乎无法运行。
有人可以解释一下为什么我的代码没有以 m=365 运行并提出一个可能的解决方案吗？
提前致谢！
这是我的代码片段：
将数据集拆分为训练集和测试集
`train_size = int(len(Alipur_df) * 0.8) # 80% 训练，20% 测试`
`训练，测试 = Alipur_df[:train_size], Alipur_df[train_size:]`

将训练 DataFrame 转换为 numpy 数组
`train_values = train[&#39;Alipur&#39;].values`
`test_values = test[&#39;Alipur&#39;].values`

使用 auto_arima 找到 SARIMA 的最佳参数
`auto_model = auto_arima(train[&#39;Alipur&#39;],seasonal=True,stationary=True,m=365,trac
]]></description>
      <guid>https://stats.stackexchange.com/questions/644159/issue-with-sarima-model-for-pm10-concentration-forecasting-with-m-365</guid>
      <pubDate>Wed, 03 Apr 2024 06:23:04 GMT</pubDate>
    </item>
    <item>
      <title>这是什么样的图表以及如何阅读它？</title>
      <link>https://stats.stackexchange.com/questions/644158/what-kind-of-chart-is-this-and-how-to-read-it</link>
      <description><![CDATA[我发现了这张既奇怪又有趣的图表。这是关于上述地区产生的一些文学作品。 x 轴是时间，y 轴是百分比。

前面的段落有如何阅读的提示，但我仍然迷失了。

阅读阿拉伯半岛的内容很简单，但是比如说伊拉克或伊朗呢？一个简单的演练将会有很大帮助。
这是标准图表还是作者的发明？]]></description>
      <guid>https://stats.stackexchange.com/questions/644158/what-kind-of-chart-is-this-and-how-to-read-it</guid>
      <pubDate>Wed, 03 Apr 2024 05:56:34 GMT</pubDate>
    </item>
    <item>
      <title>Check_model性能包解释图</title>
      <link>https://stats.stackexchange.com/questions/644155/check-model-performance-package-interpretation-plots</link>
      <description><![CDATA[我对 r 和统计相当陌生，我正在使用包含 57 个观测值和 13 个自变量的数据集构建青蛙占用率和丰度的 GLM。由于某些变量是相关的，全局模型有 7 个参数，但基于 AICc 的最佳模型有 2/3 个参数。我使用二项式来计算占用率，而对于丰富度，我尝试了负二项式和零膨胀负二项式，因为零的数量相对较多（观察到的 23 个，预测的 21 个）。
构建模型后，我使用性能包中的 check_model 函数来评估这些模型，但我有一些疑问。
关于二项式 GLM：

后验预测检查图显示 0 和 1 的预测计数在 y 轴上的观测数据范围内，但为什么 x 轴上存在差异？模型预测数据如何在二项式上超过 1？
关于分箱残差图，所有具有最低 AICc 的模型都有相当多的点（约 50%）超出误差范围。如果点非常接近误差范围，那么情况总是那么糟糕还是没有那么糟糕？我附上了两个模型的图：一个有 50% 的点超出范围，AICc 约为 58，另一个只有一个点，AICc 约为 62。



关于负二项式和零膨胀负二项式：

关于错误指定的离差和零膨胀图，所有模型都具有与下面共享的类似模式，其中观察到的方差和预测的方差在 5 左右之前相似，但随后预测的残差方差增加，而观察到的残差方差略有下降。我尝试在网上搜索，但我很困惑，因为从我读到的残差方差=观察到预测。因此，我期望一条线，而图表显示观察到的残差方差和预测残差方差。
关于零膨胀负二项式的 VIF 图，我想知道当条件下所有值都较低或中等时，零膨胀如何产生如此巨大的 VIF 值 (&gt;3,000)。


]]></description>
      <guid>https://stats.stackexchange.com/questions/644155/check-model-performance-package-interpretation-plots</guid>
      <pubDate>Wed, 03 Apr 2024 04:40:20 GMT</pubDate>
    </item>
    <item>
      <title>PERMANOVA 能否按因素确定空间（纬度/经度）差异</title>
      <link>https://stats.stackexchange.com/questions/644154/can-permanova-determine-spatial-lat-lon-differences-by-factor</link>
      <description><![CDATA[我有一个由许多带有纬度和经度坐标的点组成的数据集。每个点都可以用“月份”因子来表征。
我想测试几个月之间这些点的位置是否存在差异。
使用 adonis2 R 包，我运行了一个 PERMANOVA，如下所示，它使用了由每个点的纬度和经度坐标形成的欧几里得相异矩阵。
&lt;前&gt;&lt;代码&gt;adonis2(
  com_hd.df[ , c(“经度”,“纬度”)] ~ 月,
  数据= com_hd.df，
  方法=“euc”；
）

输出：
简化模型下adonis的排列测试
按顺序添加的术语（从第一个到最后一个）
排列：自由
排列数：999

adonis2(公式 = com_hd.df[, c(&quot;经度&quot;, &quot;纬度&quot;)] ~ 月份, 数据 = com_hd.df, 方法 = &quot;euc&quot;)
           Df SumOfSqs R2 F Pr(&gt;F)
第 11 个月 70.72 0.13289 33.437 0.001 ***
剩余 2400 461.49 0.86711
合计 2411 532.22 1.00000
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

这对我来说看起来不错，月份的 sig 效应，数据有很多变化，所以 R2 与残差是有意义的。
问题！！
我找不到任何使用空间数据进行类似测试的示例。我是不是错过了什么？？？这有道理吗？
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/644154/can-permanova-determine-spatial-lat-lon-differences-by-factor</guid>
      <pubDate>Wed, 03 Apr 2024 03:56:53 GMT</pubDate>
    </item>
    <item>
      <title>应该是一个关于熵的简单问题</title>
      <link>https://stats.stackexchange.com/questions/644153/supposed-to-be-a-simple-question-about-entropy</link>
      <description><![CDATA[假设有一个瓮，里面装有不同颜色的球。这是一个众所周知的计算瓮中球的熵的公式：
H = - 总和 Pi*log(Pi)
其中 Pi = Mi/N，其中 Mi - 第 i 种颜色的球的数量，N 是瓮中球的总数。
当每种颜色的球数量相同时，熵值最大；如果所有球颜色相同，则熵值为 0。
这是基本的。
现在假设我们再添加几个骨灰盒。现在如何计算熵？
直观上，如果每个瓮中每种颜色的球数量相同，则熵应该最大。
如果所有瓮都有相同数量的相同颜色的球（并且没有其他球），则熵应为 0。
在这两者之间，如果所有瓮都有相同数量的球，但每个瓮都有自己颜色的球，则存在一些熵；或者如果瓮里的球数量不是偶数或者有些瓮是空的等等。
我们可以使用上面的公式分别计算每个瓮的熵；我们可以使用类似的公式计算瓮之间的熵；我们可以尝试使用算术来组合这些熵，但我觉得一定有一个我很难弄清楚的优雅干净的公式。]]></description>
      <guid>https://stats.stackexchange.com/questions/644153/supposed-to-be-a-simple-question-about-entropy</guid>
      <pubDate>Wed, 03 Apr 2024 03:36:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 boosting 模型时平稳性重要吗？</title>
      <link>https://stats.stackexchange.com/questions/644144/is-stationarity-important-when-using-boosting-models</link>
      <description><![CDATA[过去几个月我研究了时间序列，主要看到了两种构建预测模型的方法：

使用集成算法，使时间序列看起来像横截面数据，其中每一列都是一个滞后（t-1，t-2，...，t-n），目标是 t0。因此，我们将使用 XGBoost 之类的东西来利用滞后来预测下一个日期。我实际上在 Kaggle Grandmaster 的 YouTube 视频中看到过这一点。
使用“传统”计量经济学模型，如 ARIMA。在这种情况下，我们仍然会使用滞后，但以不同的方式，并首先应用一些变换，如差分、对数等。这样做是为了使时间序列平稳。

为什么我们不考虑第一种情况的差异？不是都使用滞后来预测下一个日期值吗？为什么一个会使时间序列静止，而另一个则不然？]]></description>
      <guid>https://stats.stackexchange.com/questions/644144/is-stationarity-important-when-using-boosting-models</guid>
      <pubDate>Tue, 02 Apr 2024 22:36:05 GMT</pubDate>
    </item>
    <item>
      <title>选择机器学习模型的简单结构</title>
      <link>https://stats.stackexchange.com/questions/644115/simple-structure-for-selecting-machine-learning-model</link>
      <description><![CDATA[我最近提出了以下结构来评估哪些模型最适合一些简单的分类任务。假设我们有一些标记的多变量数据，已经分为 X 和 y。
我感兴趣的是以下结构是否合适或者我可以如何改进。如有任何反馈，我们将不胜感激。谢谢！
&lt;前&gt;&lt;代码&gt;N = 10
model = sklearn.discriminant_analysis.LinearDiscriminantAnalysis() # 选择任何模型，例如LDA

对于范围 (N) 内的 i：
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
    
    # 缩放（或变换）
    定标器=标准定标器()
    缩放器.fit(X_train)
    X_train[:] = 缩放器.transform(X_train)
    X_test[:] = 缩放器.transform(X_test)
    
    model.fit(X_train, y_train)
    
    accIS = model.score(X_train, y_train)
    accOS = model.score(X_test, y_test)
    
    train_list.append(accIS)
    test_list.append(accOS)
    
    print(i) # 跟踪迭代，例如对于人工神经网络

打印（np.mean（train_list），np.mean（test_list））

y_pred_train = model.predict(X_train)
print(“样本内 CM：”，confusion_matrix(y_train，y_pred_train))
    
y_pred_test = model.predict(X_test)
print(“样本外 CM:”, fusion_matrix(y_test, y_pred_test))


该过程可以描述如下：
做N次：

在训练、测试样本中随机分割数据
申请例如数据的缩放器或转换器函数（如有必要）
根据训练数据拟合模型
计算训练和测试数据的准确性（或其他指标）
将训练和测试准确率存储在单独的列表中

最后取两个列表的平均准确度，以了解模型在训练和测试数据上的平均表现。]]></description>
      <guid>https://stats.stackexchange.com/questions/644115/simple-structure-for-selecting-machine-learning-model</guid>
      <pubDate>Tue, 02 Apr 2024 15:20:14 GMT</pubDate>
    </item>
    <item>
      <title>具有不同时间长度的动态时间规整（DTW）算法...我应该截断时间序列吗？</title>
      <link>https://stats.stackexchange.com/questions/644094/dynamic-time-warping-dtw-algorithm-with-different-time-lengths-should-i-tr</link>
      <description><![CDATA[我有 $\{Y\}_t$ 个时间序列，并且想要从 $ 中查找最接近的时间序列N$ 个不同的系列，即 $\{X^{1}\}_{t}, \{X^{2}\}_{t}, ..., \{X^{N}\}_{t}$，通过应用DTW算法。每个 $N$ 系列都有不同的长度，即 $Y$ 有 100 个观测值，但其中一些观测值$Xs$ 可以有 1,000 甚至更多。由于长度不同，我是否应该剪切 $\{X^{1}\}_{t}, \{X^{2}\}_{t}, ... , \{X^{N}\}_{t}$ 使其长度与 $\{Y\}_t$ 相同？如果不是，如何在R中管理它？]]></description>
      <guid>https://stats.stackexchange.com/questions/644094/dynamic-time-warping-dtw-algorithm-with-different-time-lengths-should-i-tr</guid>
      <pubDate>Tue, 02 Apr 2024 10:45:25 GMT</pubDate>
    </item>
    <item>
      <title>推导多元资产回报模型并解释乔列斯基分解</title>
      <link>https://stats.stackexchange.com/questions/644090/deriving-the-multivariate-asset-returns-model-and-interpreting-cholesky-factoriz</link>
      <description><![CDATA[我正在尝试了解 Orskaug 第 4 章 DCC-GARCH 中的资产组合的多元资产回报模型 “具有各种误差分布的多元 DCC-GARCH 模型” (2009) 第 15 页。
我想尝试获得直观的理解，因此我尝试推导多元资产回报模型，如下所示：
我的理解是，在资产组合中，单个资产的回报可以分解为该资产的单变量均值成分和投资组合中所有其他资产的协方差的平方根乘以随机成分$Z_t$。
为了简单起见，我们假设所有资产的平均分量为零。
这个想法是，偏差（与零均值的偏差）不仅受到相关资产标准差的影响，而且还受到与投资组合中所有其他资产的相关性的影响。
基本上，投资组合中的其他资产会影响相关资产的回报偏差。这是否意味着两种资产回报之间的相关性是条件相关性？我在这里指的不是随时间变化的相关性，而是在控制所有其他资产的情况下两种资产回报之间的相关性。
我们只需要一项资产与另一项资产的协方差，以便将所有资产的协方差和相关资产的方差相加才有意义。
我的意思如下：
3 种资产回报的投资组合：$x_1, x_2,x_3$
要对 $x_1$ 在某一时刻的回报进行建模，t：
$x_1 = \mu_1 + [ \sqrt{var(x_1|x_2,x_3)}, \sqrt{Cov(x_1,x_2 | x_3)}, \sqrt{Cov (x_1,x_3 | x_2)} ]^T \ [z_1, z_2, z_3] \\ $
$x_2 = \mu_2 + [ \sqrt{Cov(x_2,x_1 | x_3)}, \sqrt{var(x_2|x_1,x_3)}, \sqrt{Cov(x_2, x_3 | x_1)} ]^T \ [z_1, z_2, z_3] \\ $
$x_3 = \mu_3 + [ \sqrt{Cov(x_3,x_1 | x_2)}, \sqrt{Cov(x_3,x_2 | x_1)} , \sqrt{var(x_3| x_1,x_2)}]^T \ [z_1, z_2, z_3] \\ $
其中 $\mu_1,\mu_2,\mu_3 = 0$ 和 $[z_1, z_2, z_3]$  是随机分量向量
这可以简洁地表示为下面的矩阵方程
$ X = M + {COV^{1/2}}Z$
其中平方根是条件协方差矩阵的 Hadamard 根，$COV$。
这个表述正确吗？您能否建议这里出了什么问题以及为什么他们使用协方差矩阵的 choleskly 分解？
下三角矩阵意味着，对于资产 1，由于乔列斯基分解的第一行为零，我们在乘法中不考虑其他资产；对于资产 2，我们在乘法中不考虑除前 2 个资产之外的其他资产，因为到乔尔斯基分解第二行的零。对于乔列斯基分解的所有剩余行都可以这样说。这是否表明我们仅捕获最后一个资产的所有资产间依赖关系？
如何直观地理解中的cholesky分解第 4 章 DCC-GARCH 第 15 页，正如我在推导中尝试做的那样？
编辑：Cholesky 分解通常是在无条件协方差矩阵上执行的，该矩阵表示变量的协方差结构，而不以任何特定值为条件？
无条件协方差矩阵：
$\begin{bmatrix} var(x_1) &amp; Cov(x_1,x_2) &amp; Cov(x_1,x_3) \\ cov(x_2,x_1) &amp; var(x_2) &amp; Cov(x_2,x_3) \\ cov(x_3,x_1) &amp; Cov(x_3,x_2) &amp; var(x_3) \end{bmatrix}$
作为 2 个资产示例，如果 $
\Sigma = \begin{pmatrix} \sigma_1^2 &amp; \rho\sigma_1\sigma_2 \\ \rho\sigma_1\sigma_2 &amp; \sigma_2^2 \end{pmatrix}$
胆囊基分解为：
$L = \begin{pmatrix} l_{11} &amp; 0 \\ l_{21} &amp; l_{22} \end{pmatrix}$
$l_{11}^2 = {\sigma_1^2}$
$l_{22}^2 = \sigma_2^2 - \frac{{\rho^2 \sigma_1^2 \sigma_2^2}}{{l_{11} ^2}}$
$l_{21} = \frac{{\rho\sigma_1\sigma_2}}{{l_{11}}}$
术语 $l^2_{22} = \sigma_2^2 - \rho^2 \sigma_2^2$ 和 $l_{21} = {\rho\sigma_2}$ ?为什么要减去]]></description>
      <guid>https://stats.stackexchange.com/questions/644090/deriving-the-multivariate-asset-returns-model-and-interpreting-cholesky-factoriz</guid>
      <pubDate>Tue, 02 Apr 2024 10:00:23 GMT</pubDate>
    </item>
    </channel>
</rss>