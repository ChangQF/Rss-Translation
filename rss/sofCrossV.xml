<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 27 Jul 2024 12:28:34 GMT</lastBuildDate>
    <item>
      <title>交叉验证后模型表现不佳</title>
      <link>https://stats.stackexchange.com/questions/651860/model-performing-poorly-after-cross-validation</link>
      <description><![CDATA[在使用交叉验证查看自定义预测函数对未见数据的表现后，我将函数应用于原始数据集，结果性能（基于判定系数）大幅下降。
我正在尝试构建一个预测模型来获取 3 个输入特征并预测一个比例。我定义了一个自定义函数来将输出限制在 0 和 1 之间：
def xg_curve(X, a, b, c, d, e):
x1, x2, x3 = X[:, 0], X[:, 1], X[:, 2]
return 1 / (1 + a * b ** (c * x1 + d * x2 + e * x3))

我尝试了分层 5 倍交叉验证，通过按目标变量对数据框进行排序，然后循环分配它们 0-4，这使得所有折叠中的目标分布几乎彼此相同，并且整个数据集也是如此。
测试折叠的平均 R2 为 0.6485，并且在所有折叠中非常紧密地聚集在这个值附近，平均训练 R2 等于0.655，并且非常紧密地聚集在这个值周围。
这是一个相当小的数据集（750 个条目），因此我使用交叉验证来确保模型很好地推广到看不见的数据，而不仅仅是在一个特定的训练/测试分割上表现良好。该模型预测了冰球模拟器中要保存的击球难度等级，所以我想将它应用于已经编程的击球（数据集）和游戏中的任何未来击球。目标是用户保存现有击球的时间百分比。
基于领域知识，我对特征占目标变化的约 65% 感到满意，并将该函数应用于整个数据集。但是，当我这样做时，R2 值下降到 0.478。我在下面提供了我的代码，我找不到任何错误！任何帮助都将不胜感激！
def xg_curve(X, a, b, c, d, e):
x1, x2, x3 = X[:, 0], X[:, 1], X[:, 2]
return 1 / (1 + a * b ** (c * x1 + d * x2 + e * x3))

X_data = over50[[&quot;Required_rate_of_closure&quot;, &quot;Shot angle&quot;, &quot;Lateral_diff_spin&quot;]].values
y_data = over50[&quot;Goal Percentage&quot;].values
folds = over50[&quot;Fold&quot;].values

# 初始化列表以存储每个折叠的 RMSE 和 R^2
train_rmse_values = []
train_r2_values = []
test_rmse_values = []
test_r2_values = []
params_list = []

# 折叠数
k = 5

for i in range(k):

# 将数据拆分为训练集和测试集
train_idx = folds != i
test_idx = folds == i

X_train, X_test = X_data[train_idx], X_data[test_idx]
y_train, y_test = y_data[train_idx], y_data[test_idx]

# 在训练集上拟合模型
popt, _ = curve_fit(xg_curve, X_train, y_train, p0=[1, 1, 1, 1, 1])

# 在训练集上进行预测
y_train_pred = xg_curve(X_train, *popt)
# 在测试集上进行预测
y_test_pred = xg_curve(X_test, *popt)

# 计算训练集的 RMSE 和 R^2
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
train_r2 = r2_score(y_train, y_train_pred)

# 计算测试集的 RMSE 和 R^2
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
test_r2 = r2_score(y_test, y_test_pred)

# 存储结果
train_rmse_values.append(train_rmse)
train_r2_values.append(train_r2)
test_rmse_values.append(test_rmse)
test_r2_values.append(test_r2)
params_list.append(popt)

# 计算所有折叠的 RMSE 和 R^2 的平均值和标准差
mean_train_rmse = np.mean(train_rmse_values)
std_train_rmse = np.std(train_rmse_values)
mean_train_r2 = np.mean(train_r2_values)
std_train_r2 = np.std(train_r2_values)

mean_test_rmse = np.mean(test_rmse_values)
std_test_rmse = np.std(test_rmse_values)
mean_test_r2 = np.mean(test_r2_values)
std_test_r2 = np.std(test_r2_values)

print(&quot;训练 RMSE：平均值 = {:.4f}，标准差 = {:.4f}&quot;.format(mean_train_rmse, std_train_rmse))
print(&quot;训练 R^2：平均值 = {:.4f}，标准差 = {:.4f}&quot;.format(mean_train_r2, std_train_r2))
print(&quot;验证 RMSE：平均值 = {:.4f}，标准差 = {:.4f}&quot;.format(mean_test_rmse, std_test_rmse))
print(&quot;验证 R^2：平均值 = {:.4f}，标准差 = {:.4f}&quot;.format(mean_test_r2, std_test_r2))

final_params, _ = curve_fit(xg_curve, X_data, y_data, p0=[1,1,1,1,1])

a,b,c,d,e = final_params

print(f&#39; 最终参数：a = {a}, b = {b}, c = {c}, d = {d}, e = {e}&#39;)

print(r2_score(xg_curve(X_data, *final_params), y_data))
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/651860/model-performing-poorly-after-cross-validation</guid>
      <pubDate>Sat, 27 Jul 2024 12:16:22 GMT</pubDate>
    </item>
    <item>
      <title>在最小二乘法中，如何检查残差的正态性？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651859/in-least-square-how-to-check-for-the-normality-of-residuals</link>
      <description><![CDATA[假设我有以下数据：
data &lt;- data.frame(
Week_1 = c(2.496714, 1.861736, 2.647689, 3.523030, 1.765847, 1.765863, 3.579213, 2.767435, 1.530526, 2.542560, 1.536582, 1.534270, 2.241962, 0.086720, 0.275082, 1.437712, 0.987169, 2.314247, 1.091976, 0.587696, NA, NA, NA,不适用，不适用，不适用，不适用，不适用，不适用，不适用），周_2 = c(8.931298, 5.548447, 6.135056, 3.150504, 4.911235, 6.221845, 3.698013, 6.751396, 4.798723, 613、4.796587、9.704556、5.973006、3.884578、7.645090、3.558313、6.417727、2.080660、3.343628、6.393722、7.476933、 6.342737, 5.768703, 5.397793, 3.042956, 4.560312, 5.078722, 8.114244, 6.687237, 2.473920),
Week_3 = c(10.583351, 9.306852, 8.781540, 11.101017, 11.855799, 11.676304, 8.489408, 9.443418, 10.596274, 11.755981, 9.137486, 9.665814, 8.008597, 7.846828, 11.462546，NA，NA，NA，NA，NA，NA，NA，NA，NA，NA，NA，NA，NA，NA，NA）
）

我想对数据（值作为周的函数）执行加权线性回归。

问题 1
对于所有三周，我需要确定平均值及其标准误差（s.e.m.）。我是否必须对分布做出假设才能计算这两个参数？

问题 2
在维基百科上，我读到，“如果假设误差遵循正态分布，则推断很容易，因此意味着参数估计值和残差也将服从独立变量值的正态分布。”如果残差需要服从正态分布，是否意味着我只能在执行拟合（使用 QQ 图）后才能检查正态性？

问题 3
假设我没有原始数据，有三个点 (x1,y1)、(x2,y2) 和 (x3,y3)，其中 y_i 是平均值。我该如何检查正态性？


谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/651859/in-least-square-how-to-check-for-the-normality-of-residuals</guid>
      <pubDate>Sat, 27 Jul 2024 11:09:35 GMT</pubDate>
    </item>
    <item>
      <title>反向排序中的增量计算（Google Code jam 问题）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651856/delta-calculation-in-reverse-sortgoogle-code-jam-question</link>
      <description><![CDATA[在工程学中，逆向排序是一道竞争性编程题，涉及编写代码来生成给定大小 N 和成本 C 的数组。要了解有关该问题的更多信息，请访问此处
问题的答案是此处
我的问题是如何计算增量公式，使用δ=C−((N(N−1))/2​+1)而不是δ=C−((N(N−1))/2​-1)有什么意义？
我不明白他们是如何得出这个计算增量值的公式的。]]></description>
      <guid>https://stats.stackexchange.com/questions/651856/delta-calculation-in-reverse-sortgoogle-code-jam-question</guid>
      <pubDate>Sat, 27 Jul 2024 08:36:09 GMT</pubDate>
    </item>
    <item>
      <title>哪个包在 R 中执行多项逻辑回归分析？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651854/what-package-performs-multinomial-logistic-regression-analysis-in-r</link>
      <description><![CDATA[我使用 R 中 nnet 包中的 multinom 函数执行了多项逻辑回归，但我觉得比值比结果不太好。multinom 函数不是多项逻辑回归分析吗？如果是，请告诉我执行多项逻辑回归分析的 R 包。]]></description>
      <guid>https://stats.stackexchange.com/questions/651854/what-package-performs-multinomial-logistic-regression-analysis-in-r</guid>
      <pubDate>Sat, 27 Jul 2024 07:06:28 GMT</pubDate>
    </item>
    <item>
      <title>概率分布之间的距离</title>
      <link>https://stats.stackexchange.com/questions/651853/distance-between-probability-distributions</link>
      <description><![CDATA[我试图理解概率分布之间的三种距离之间的差异，例如它们的优点和缺点是什么，它们强调什么和不强调什么，本质上从实际的角度来看：何时使用这一个而不是另一个，它很容易用数字计算/估计，等等。在这里我只对绝对连续的一维概率分布感兴趣。给定两个这样的概率分布 $P$ 和 $Q$，我感兴趣的三个距离是：

总变异距离 (TVD)：
$$
\mathsf{TVD}(P,Q)=\int_\mathbb{R}\big|p(x)-q(x)\big|\,\mathrm{d}x,
$$
其中 $p$ 是与 $P$ 相关的概率密度函数 (PDF)，而 $q$ 是与 $Q$ 相关的概率密度函数。
 Wasserstein-1 距离：
$$
\mathsf{W}_1(P,Q)=\int_0^1\big|F^{-1}(q)-G^{-1}(q)\big|\,\mathrm{d}q=\int_\mathbb{R}\big|F(x)-G(x)\big|\,\mathrm{d}x,
$$
其中 $F$ 是与 $P$ 相关的累积概率函数 (CDF)，而 $G$ 是与 $Q$ 相关的累积概率函数。
最大均值差 (MMD) 距离，其函数类被视为希尔伯特空间$\mathcal{H}$的单位球:
$$
\textsf{MMD}_\varphi(P,Q)=\big\|\mathbb{E}_{X\sim P}[\varphi(X)]-\mathbb{E}_{Y\sim Q}[\varphi(Y)]\big\|_\mathcal{H},
$$
其中$\varphi:\mathbb{R}\to\mathcal{H}$。在这篇文章中，我主要感兴趣的是 $\varphi$ 与高斯核的关系：
$$
\big\langle\varphi(x),\varphi(y)\big\rangle_\mathcal{H}=k(x,y)=\exp\left(-\frac{1}{2\sigma^2}|x-y|^2\right).
$$

我感兴趣的是这些距离之间的差异。例如，在我看来：

$\mathsf{W}_1$ 比较了分布中分位数或质量分配的差异（注意：我知道 $\mathsf{W}_1$ 的最佳传输解释，而 $\mathsf{TVD}$ 比较了质量，但在“原子级”上，因为它涉及 PDF，所以它会“更紧密”，
上面的 $\textsf{MMD}_\varphi$ 的特定实例将比较两个分布之间的所有矩，如果我们从弥散、偏度和峰度的角度考虑，那么就会强调&quot; 分布的几何形状&quot;。
在数值方面，假设 $P$ 和 $Q$ 未知，如果我得到 $P$ 和 $Q$ 的样本，那么对于 $\mathsf{TVD}$，我必须估计 PDF 并近似积分。对于 $\mathsf{W}_1$ 也是如此：需要估计 CDF 并近似积分。但是，对于 $\textsf{MMD}_\varphi$，使用核技巧很容易获得 &quot; 插件&quot;距离的估计量。

在统计/数据科学/机器学习中，哪些用例会使用一种距离而不是其他距离，为什么？有人有简单的例子可以解释这三种距离之间的差异吗？谢谢帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/651853/distance-between-probability-distributions</guid>
      <pubDate>Sat, 27 Jul 2024 06:57:39 GMT</pubDate>
    </item>
    <item>
      <title>如果我使用正则化方法进行特征选择，然后使用机器学习模型进行预测，是否会重叠？</title>
      <link>https://stats.stackexchange.com/questions/651852/if-i-use-the-regularization-method-for-feature-selection-and-then-use-machine-le</link>
      <description><![CDATA[我使用正则化方法（例如 elastic-net）进行特征选择，然后使用随机森林和深度学习利用所选特征预测目标。问题是分类。我的同事说我重叠了！
我认为没有重叠，因为我只考虑了 elastic-net 中选定的特征
而忽略了它们的重要性。我说得对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651852/if-i-use-the-regularization-method-for-feature-selection-and-then-use-machine-le</guid>
      <pubDate>Sat, 27 Jul 2024 06:56:52 GMT</pubDate>
    </item>
    <item>
      <title>预期值是否相对于 CDF 单调递减？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651851/is-the-expected-value-monotonically-decreasing-with-respect-to-the-cdf</link>
      <description><![CDATA[当$P(X\ge0)=1$时，$E[X]=\int_0^1(1-F(x))dx\in[0,1]$。
那么，$E[X]$相对于$F(x)$单调递减，这一说法正确吗？
如果可以的话，我想要一个简单的证明。
添加：
・$F(x)$ 是随机变量 $X$ 的累积分布函数，而不是 X 的 PDF。
・“$E(X)$ 相对于 $F(x)$ 单调递减吗 ”意味着 $a\ge b\Rightarrow F(a)\ge F(b)\Rightarrow E(F(a)) \le E(F(b))$]]></description>
      <guid>https://stats.stackexchange.com/questions/651851/is-the-expected-value-monotonically-decreasing-with-respect-to-the-cdf</guid>
      <pubDate>Sat, 27 Jul 2024 05:06:34 GMT</pubDate>
    </item>
    <item>
      <title>变换相关的双变量正态性会产生意想不到的结果</title>
      <link>https://stats.stackexchange.com/questions/651850/transforming-correlated-bivariate-normal-gives-unexpected-result</link>
      <description><![CDATA[我想在某个数字 X 处评估相关的双变量正态 CDF。我想转换 X，以便在非相关的双变量正态 CDF 处评估转换后的 X 时得到相同的输出。我想用 Cholesky 分解来做到这一点。我在 Matlab 中得到的结果高度相关，但存在持续的偏差。我不明白为什么。我猜我犯了一个概念错误。
rho=0.4;
cov_mat=[1,rho;rho,1];
input = repmat((-3.5:.01:3.5)&#39;,1,2);
z=mvncdf(input,[0,0],cov_mat);
L = chol(cov_mat, &#39;lower&#39;);
input2 = input/L;
z2 = mvncdf(input2, [0, 0], [1,0;0,1]);
平均值（（z-z2）./z）
%%% 预计此平均值接近于零

一篇数学帖子有同样的问题，但尚未解决：https://math.stackexchange.com/questions/1652545/multivariate-normal-value-standardization（已检查的答案似乎没有帮助，正如 OP 的更新评论所表明的那样）。]]></description>
      <guid>https://stats.stackexchange.com/questions/651850/transforming-correlated-bivariate-normal-gives-unexpected-result</guid>
      <pubDate>Sat, 27 Jul 2024 04:41:50 GMT</pubDate>
    </item>
    <item>
      <title>求解最大熵条件概率</title>
      <link>https://stats.stackexchange.com/questions/651848/solve-for-maximum-entropy-conditional-probability</link>
      <description><![CDATA[我对 max-ent 原理和函数导数还不熟悉。我已知联合数据分布 $p_D(x,y)$（其中 $y$ 被视为标签）和隐变量模型 $(x,y,z)$，其中指定了先验 $p(z)$ 和似然值 $p(y \mid x,z)$。我想找到驱动模型满足数据分布的最大概率$p(x \mid z)$，即：
$$
\int_{-\infty}^\infty p(z) p(x \mid z) p(y \mid x,z)\,\mathrm dz = p_D(x,y)\,.\tag{1}
$$
拉格朗日量为：
$$
\begin{multline}
L(p(x \mid z), \lambda_0, \lambda_1) = -\int_{-\infty}^\infty p(x \mid z) \log p(x \mid z)\,\mathrm dx\\
+ \lambda_0 \left(\int_{-\infty}^\infty p(x \mid z)\,\mathrm dx - 1\right) + \lambda_1 \left(\int_{-\infty}^\infty p(z) p(x \mid z) p(y \mid x,z)\,\mathrm dz - p_D(x,y)\right)\,.
\end{multline}\tag{2}
$$
求导并令其为零：
$$
\begin{aligned}
1 + \log p(x \mid z) &amp;= \lambda_0 + \lambda_1 p(z) p(y \mid x,z)\\
p(x \mid z) &amp;= \exp(\lambda_0 - 1 + \lambda_1 p(z) p(y \mid x,z))\,.\\
\end{aligned}\tag{3}
$$
将 (3) 代入 $\int_{-\infty}^\infty p(x \mid z)\,\mathrm dx = 1$得出：
$$
\int_{-\infty}^\infty \exp(C_0 + C_1 f(x))\,\mathrm dx\,,\tag{4}
$$
其中 $C_0$ 和 $C_1$ 是与 $x$ 无关的常数，并且 $f(x) = p(y \mid x,z)$。
即使 $f(x) = 1$ 和 $C_1 &lt; 0$ 始终存在，积分 (4) 仍会发散。因此，(3) 不是正确解决方案。
因此，我认为我的推导中存在一些错误，最有可能出现在 (3) 中。也许 (2) 中的拉格朗日量一开始就是错误的。有人能帮助我吗？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651848/solve-for-maximum-entropy-conditional-probability</guid>
      <pubDate>Sat, 27 Jul 2024 04:00:51 GMT</pubDate>
    </item>
    <item>
      <title>设计复杂的混合模型分析</title>
      <link>https://stats.stackexchange.com/questions/651846/designing-complex-mixed-model-analysis</link>
      <description><![CDATA[我正在尝试使用混合模型分析患者的脑电图数据。我在这方面已经停滞了一段时间，我阅读了大量论文和一本入门教科书，但仍然不确定自己在做什么。我正在尝试使用 Python 中的 statsmodels 来执行此操作。
有 10 个受试者，每个人在会话期间都会记录他们的脑电波。每个会话都有一个“控制”状态，即他们什么也不做，还有一个状态，即他们正在观看一些视频（治疗）。有多个会话，有些受试者跳过了一些会话。大脑活动局限于大脑中的特定区域。
使用混合模型，对单个受试者的不同会话（时间）重复测量，但也对治疗与控制进行测量。这让我开始感到困惑 - 当时间和治疗条件都在单个受试者内（“嵌套”）时，我该如何处理分析中的复杂情况？我对混合模型的理解非常简单，即存在重复测量（例如，某个位置的大脑活动），并且有受试者接受治疗或控制，但不会同时接受两者。有没有专门处理这个问题的文献？
另一个问题让我更加头疼——我不确定我是否应该对每个大脑区域分别进行分析，或者大脑区域应该是一个独立变量。如果我把它作为IV（不同区域的大脑活动不太可能是独立的，因为论文的一部分是某些区域是相连的）..我想这会使统计分析的设计更加复杂。然后另一个IV可能是不同的脑波频带（alpha vs beta vs theta等），类似的问题也适用——是否单独分析，因为它们也可能不独立..我在这里是一个非常困惑的人，希望能得到正确的指导..
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/651846/designing-complex-mixed-model-analysis</guid>
      <pubDate>Sat, 27 Jul 2024 03:02:37 GMT</pubDate>
    </item>
    <item>
      <title>测量嵌入空间中的相似性？</title>
      <link>https://stats.stackexchange.com/questions/651840/measuring-similarity-in-embedding-spaces</link>
      <description><![CDATA[我试图测量两个不同维度的嵌入空间（特别是文本）的相似度（例如 300d 和 2000d）。较大的嵌入空间是稀疏的。具体来说，我想捕获：

邻域保存得如何？
邻域之间的距离保存得如何？

这是我到目前为止尝试过的：

Kendall 的 Tau，捕获 1. 但不是 2。计算成本也相对较高（在较旧的计算机上约 20 秒）
Gromov-Wasserstein，查看分布而不是特定单词。时间与 1 相似
求解两者之间的线性变换（最小二乘法）。不确定如何将其转换为有意义的指标（残差、幅度？）。成本是可变的。

任何可以帮助我测量相似度的工具、技术或修改我所查看过的东西都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/651840/measuring-similarity-in-embedding-spaces</guid>
      <pubDate>Fri, 26 Jul 2024 22:54:11 GMT</pubDate>
    </item>
    <item>
      <title>似然比检验——多参数多项分布</title>
      <link>https://stats.stackexchange.com/questions/651822/likelihood-ratio-test-multiparameter-multinomial-distribution</link>
      <description><![CDATA[这是 Hogg 和 McKean 的《数理统计学导论》中的一个问题（练习 $6.5.11.$）
问题陈述
设一个实验有 $n$ 次独立试验，其中 $x_1,x_2,\ldots,x_k$ 分别为实验以互斥事件
和穷举事件 $C_1,C_2,\ldots,C_k.$ 结束的次数，如果 $p_i = P(C_i)$ 在 $n$ 次试验中保持不变，则该特定试验序列的概率为 $L=p_1^{x_1}p_2^{x_2}\cdots p_k^{x_k}.$
(a) 回想一下 $p_1 + p_2 + \cdots + p_k = 1$，显示测试的似然比$H_0 : p_i = p_{i0} &gt; 0, i = 1,2,\ldots, k,$ 对所有备选方案的结果是 $$\Lambda = \prod_{i=1}^k \left ( \cfrac{(p_{i0})^{x_i}}{(x_i/n)^{x_i}} \right )$$
(b) 证明 $$-2\log{\Lambda} = \sum_{i=1}^k \cfrac{x_i(x_i-np_{i0})^2}{(np&#39;_{i})^2}$$ 其中 $p_i&#39;$ 介于 $p_{i0}$ 和 $x_i/n$
提示：以泰勒级数展开 $\log{p_{i0}}$，余数在涉及 $(p_{i0} − x_i/n)^2.$ 的项中

(c) 对于较大的 $n$，论证 $x_i/(np_i&#39;)^2$ 由 $1/(np_{i0})$ 近似，因此 $$-2\log{\Lambda} \approx \sum_{i=1}^{k} \cfrac{(x_i-np_{i0})^2}{np_{i0}}.$$
定理$6.5.1$表示，最后一个等式的右边部分定义了一个统计量，该统计量具有近似卡方分布，自由度为$k − 1$。请注意，$\Omega$的维度$-$的维度$\omega = (k − 1) − 0 = k − 1.$
我的尝试：
部分 (a) 有点琐碎。我真的被部分 (b) 难住了。调用$q_i = x_i/n$。使用 $\log{p_{i0}}$ 关于 $q_i$ 的泰勒级数展开，我们得到
\begin{align}
-2\log{\Lambda} &amp;= -2\sum_{i=1}^{k} x_i\left[ \log{p_{i0}} - \log{q_i} \right] \\
&amp;= -2\sum_{i=1}^k x_i\left[ \sum_{j=1}^\infty \frac{(-1)^{j-1}}{j} \left ( \cfrac{p_{i0} - q_i}{q_i} \right )^j\right] \\
&amp;= -2\sum_{i=1}^k (np_{i0}-x_i) -2\sum_{i=1}^k x_i\left[ \sum_{j=2}^\infty \frac{(-1)^{j-1}}{j} \left ( \cfrac{p_{i0} - q_i}{q_i} \right )^j\right] \\
&amp;= \sum_{i=1}^k \cfrac{x_i(x_i-np_{i0})^2}{(nq_i)^2} \left [ 1+2 \sum_{j=3}^{\infty} \frac{(-1)^{j-2}}{j} \left ( \frac{p_{i0}-q_i}{q_i}\right )^{j-2} \right ].
\end{align&gt;
最后一个等式使用了 $\sum_{i=1}^{k}x_i = n$ 和 $\sum_{i=1}^{k}p_{i0} = 1$ 这两个事实。方括号中的表达式可以与分母中的 $q_i^2$ 结合起来，得到 $p&#39;_i$ 的形式。但随后我们需要证明它介于 $p_{i0}$ 和 $q_i$ 之间。
我一读到“介于之间”这个词，就想到了使用均值定理... 那里是死胡同。 MVT 确保存在某个 $p&#39;_i$，使得 $$\log{p_{i0}} - \log{q_i} = \frac{p_{i0}-q_i}{p&#39;_i},$$，使得它位于 $p_{i0}$ 和 $q_i$ 之间。 但无论我尝试多少代数运算，我都无法得出他们在 (b) 部分中要求的关系。
如果您能帮助我解决这个练习问题，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/651822/likelihood-ratio-test-multiparameter-multinomial-distribution</guid>
      <pubDate>Fri, 26 Jul 2024 16:02:06 GMT</pubDate>
    </item>
    <item>
      <title>在对 betadisper 进行显著的方差分析后，使用 Permutest 或 TukeyHSD 进行分组比较？</title>
      <link>https://stats.stackexchange.com/questions/651794/permutest-or-tukeyhsd-for-group-wise-comparison-after-significant-anova-of-betad</link>
      <description><![CDATA[我想使用我的蜘蛛群落数据执行 PERMANOVA，这些数据是在不同的林分中采样的。在应用 PERMANOVA 之前，我想找出各组之间的分散度是否存在差异。
为此，我使用了 betadisper
dispersion_stands_trap &lt;- 
betadisper(all_dist_trap, 
meta_distance_trap$stand)

这将返回一个重要的输出
&gt; anova(dispersion_stands_trap)
方差分析表

响应：距离
Df 总和 平方均值 平方 F 值 Pr(&gt;F) 
组 4 0.2124 0.053107 2.4785 0.04653 *
残差 149 3.1927 0.021427 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

为了正确解释我的数据，我想知道哪些组的分散性完全不同。
我读到我可以使用 TukeyHSD 或 permutest 进行成对比较。
permutest(dispersion_stands_trap, 
Paradise=TRUE)

返回以下内容：
成对比较：
（对角线下方观察到的 p 值，对角线上方置换的 p 值）
D DB B FB F
D 0.1450000 0.0980000 0.0030000 0.399
DB 0.1502930 0.8250000 0.1040000 0.558
B 0.0987879 0.8288240 0.1640000 0.425
FB 0.0035463 0.1172937 0.1621860 0.026
F 0.3962535 0.5326374 0.3977593 0.0291775

但是当我使用
TukeyHSD(dispersion_stands_trap)

显著性比较会发生变化（显著性效应丧失F-FB):
 Tukey 均值多重比较
95% 家族置信水平

拟合：aov（公式 = 距离 ~ 组，数据 = df）

$group
diff lwr upr p adj
DB-D 0.060699868 -0.042825680 0.16422542 0.4875989
B-D 0.068575786 -0.036690784 0.17384236 0.3780614
FB-D 0.112144505 0.009417572 0.21487144 0.0248321
F-D 0.036470261 -0.066256672 0.13919719 0.8637376
B-DB 0.007875918 -0.096552782 0.11230462 0.9995769
FB-DB 0.051444637 -0.050423540 0.15331281 0.6321060
F-DB -0.024229607 -0.126097784 0.07763857 0.9651200
FB-B 0.043568719 -0.060068327 0.14720576 0.7735077
F-B -0.032105525 -0.135742571 0.07153152 0.9124905
F-FB -0.075674244 -0.176730709 0.02538222 0.2395908


这让我想到我应该依赖这两个测试中的哪一个？
我的设计有点不平衡
D 30，
DB 31，
B 29，
FB 32，
F 32
这可能会有问题吗？
TukeyHSD(dispersion_stands_trap)]]></description>
      <guid>https://stats.stackexchange.com/questions/651794/permutest-or-tukeyhsd-for-group-wise-comparison-after-significant-anova-of-betad</guid>
      <pubDate>Fri, 26 Jul 2024 08:29:46 GMT</pubDate>
    </item>
    <item>
      <title>将傅里叶变换级数展开式与狄利克雷分布和狄利克雷过程联系起来</title>
      <link>https://stats.stackexchange.com/questions/651765/connecting-a-fourier-transform-series-expansion-to-the-dirichlet-distribution-an</link>
      <description><![CDATA[我推导出某个一维随机过程位置分布的傅里叶变换表达式，我怀疑它与狄利克雷过程或狄利克雷分布有关。但是，我对这些概念不太熟悉，需要帮助建立联系。我的表达式是：
\begin{equation}
\hat{p}(k) = \sum_{n=0}^{+\infty} \frac{(ik)^{2n}}{(2\mu)^n\, (\frac{\beta}{2})^{(n)}}\, Z_n\left(\frac{\beta}{2}\langle D\rangle,\ldots, \frac{\beta}{2}\langle D^n \rangle\right)\, .
\end{equation&gt;
其中$(\frac{\beta}{2})^{(n)}=\frac{\Gamma\left(\frac{\beta}{2}+n\right)}{\Gamma\left(\frac{\beta}{2}\right)}$是Pochhammer符号，$Z_n$是对称群的循环指数。而$\langle D^n \rangle$是分布的$n^{\text{th}}$矩，我称之为$w(D)$。
在论文“Dirichlet 测度的特征泛函”中作者：Lorenzo Dello Schiavo，我注意到我的级数展开式中的系数与狄利克雷分布的系数几乎相同。然而，我很难在参数之间建立精确的联系。此外，我的总和超过 $(ik)^{2n}$，而他们的总和超过 $(it)^n$。
以下是论文中的相关摘录：


有人可以帮我理解我的结果和狄利克雷分布之间的联系？我该如何对齐参数和项以更清楚地看到这种关系？
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/651765/connecting-a-fourier-transform-series-expansion-to-the-dirichlet-distribution-an</guid>
      <pubDate>Thu, 25 Jul 2024 17:28:52 GMT</pubDate>
    </item>
    <item>
      <title>模型具有更高的（且更接近 1）$\beta$，但 $R^2$ 和相关性相似</title>
      <link>https://stats.stackexchange.com/questions/651423/model-has-higher-and-closer-to-1-beta-but-similar-r2-and-correlation</link>
      <description><![CDATA[我有一个模型，它产生预测$\hat{y_1}$，后来我又想出了一个新模型，它产生预测$\hat{y_2}$。我有基本事实$y$。 这些模型不是基于回归的，但它们是线性的，我想在回归指标中对它们进行评估。
如果我运行$y \sim \beta_1 \hat{y_1}$、$y \sim \beta_2 \hat{y_2}$，我会看到$\beta_2 \sim 1$和$\beta_1 \sim 0.8$。我认为这意味着我的模型 2 “缩放得更好”。
但如果我直接计算 $R2(y, \hat{y_1}) = 1- \frac{\sum (y_t - \hat{y_1}_t )^2 }{\sum y_t^2}$ 和 $R2(y, \hat{y_2}) = 1- \frac{\sum (y_t - \hat{y_2}_t )^2 }{\sum y_t^2}$（因为我不会尝试重新运行回归 $y \sim \beta_1 \hat{y_1}$ 并得到回归 R2。我只是直接计算 $R2(y, \hat{y_1}) = 1- \frac{\sum (y_t - \hat{y_1}_t )^2 }{\sum y_t^2}$)。我发现它们大致相等。
当我计算 $y$ 和 $\hat{y_1}$ 之间的相关性以及 $y$ 和 $\hat{y_2}$ 之间的相关性时，我发现它们也几乎相等。请注意，这里的相关性可能不是 R2 的平方根，因为我的模型不是基于回归的。
它告诉了我关于预测的什么？我觉得有点惊讶。我认为“更好的规模”预测变量应该出现在回归指标的某个地方吗？为什么“更好的尺度”回归不能给我更好的 R2？
[编辑以详细说明]
有些模型以“外生”方式提供系数。例如，在牛顿定律中，我有理由相信$F = ma$，而不是运行回归$F \sim a$，其中$a$可能有噪音，我还不如试着通过一个尺度来估计$m$。
但现在我已经估计了$m = f_1(z)$或$m = f_2(z)$，其中$f_1$和$f_2$是两个不同的尺度。 $z$ 是我的量表的一系列其他参数。现在我想将其重新插入以测量拟合优度 $F \sim f_1(z) a$ 和 $F \sim f_2(z) a $。我可以计算 $F$ 和 $f(z)$ 的 R2。我还可以运行回归$F \sim \beta_1 f(z) a$和$F \sim \beta_2 f(z) a$。
我现在的问题是，我看到$\beta_2$非常接近 1，但$R2( F, f_2(z) a)$并不高于$R2( F, f_1(z) a)$]]></description>
      <guid>https://stats.stackexchange.com/questions/651423/model-has-higher-and-closer-to-1-beta-but-similar-r2-and-correlation</guid>
      <pubDate>Fri, 19 Jul 2024 19:10:07 GMT</pubDate>
    </item>
    </channel>
</rss>