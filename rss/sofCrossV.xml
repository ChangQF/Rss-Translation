<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 08 Aug 2024 12:29:20 GMT</lastBuildDate>
    <item>
      <title>合并引导迭代中的 p 值</title>
      <link>https://stats.stackexchange.com/questions/652489/combining-p-values-from-bootsrap-iterations</link>
      <description><![CDATA[我正在尝试针对连续响应变量 $x$ 建模突变概率。我正在构建一个逻辑回归模型，将每个基因的突变状态作为 $y$，并将 $x$ 作为回归模型中的参数。结果系数表示突变的对数几率概率增加，而 $x$ 的单位增加。我正在为每个基因拟合一个单独的模型，类似于 DESeq2 中所做的。
从这些模型中，我可以轻松计算出 p 值。
我正在引导此过程 $n$ 次，因为我发现输入数据的微小变化经常会得到不稳定的结果。我想根据一些指标对这些基因进行排序，以考虑突变概率（系数）变化的幅度，以及我所掌握的支持这一结果的证据（标准误差）。
我可以根据突变概率的对数几率增加对基因进行排序，但这些并没有考虑与 $x$ 中的测量值相关的标准误差。因此，我想使用一个统计数据，如 p 值，它可以解释这一点，但我正在引导整个过程，并且相信我不能简单地平均 p 值（这里）。
我可以使用什么来对这些基因进行排序，以便在所有引导重复中获得单一排名？在每个单独的引导迭代中排名，然后对这些排名取平均值是否合适？
我对统计学还很陌生，所以您推荐的任何读物都会非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/652489/combining-p-values-from-bootsrap-iterations</guid>
      <pubDate>Thu, 08 Aug 2024 11:49:03 GMT</pubDate>
    </item>
    <item>
      <title>事件研究实施</title>
      <link>https://stats.stackexchange.com/questions/652488/event-study-implementation</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652488/event-study-implementation</guid>
      <pubDate>Thu, 08 Aug 2024 11:48:39 GMT</pubDate>
    </item>
    <item>
      <title>如何估计线性回归中测量变量的标准差？</title>
      <link>https://stats.stackexchange.com/questions/652487/how-do-i-estimate-the-standard-deviation-of-the-measured-variables-in-linear-reg</link>
      <description><![CDATA[假设一个线性模型：
$$
y = \alpha x + \beta
$$
我对$(x_i,y_i)$进行了 n 次观察。
每个观测值都受到测量不确定性的影响，我假设该不确定性呈正态分布，平均值 = 0，但方差未知。
如何在 Python 中估算 $\alpha$、$\beta$ 以及 $\sigma_x$ 和 $\sigma_y$？
以下是一些为 $y = 2x + 1$ 生成测试数据的代码：
import numpy as np
import matplotlib.pyplot as plt
from scipy.linalg import lstsq

n = 20
x = np.linspace(-5,5,n)
y = 2*x + 1

sigma_x = 0.1
sigma_y = 0.2

x_noisy = x + np.random.normal(0, sigma_x, x.shape)
y_noisy = y + np.random.normal(0, sigma_y, y.shape)

plt.plot(x,y, label = &#39;y = 2x + 1&#39;)
plt.scatter(x_noisy,y_noisy, color=&#39;red&#39;, label = &#39;测量的 (x,y) 值&#39;)
plt.xlabel(&#39;x&#39;)
plt.ylabel(&#39;y&#39;)
plt.legend()
plt.show()

给定上面的 x_noisy 和 y_noisy 值，我如何恢复 $\alpha=2$，$\beta=1$、$\sigma_x = 0.1$ 和 $\sigma_y = 0.2$？

也许可以先通过线性回归找到 $\alpha$ 和 $\beta$，然后将每个测量点投影到这条线上：

接下来，可以根据 dx 和 dy 的分布估算出 x 和 y 的标准差吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652487/how-do-i-estimate-the-standard-deviation-of-the-measured-variables-in-linear-reg</guid>
      <pubDate>Thu, 08 Aug 2024 11:07:30 GMT</pubDate>
    </item>
    <item>
      <title>选择正确的效应大小 (Cohen's d) 进行功效分析</title>
      <link>https://stats.stackexchange.com/questions/652485/select-correct-effect-size-cohens-d-for-power-analysis</link>
      <description><![CDATA[根据 Blevins 等人 (2015)，《精神障碍诊断和统计手册》第五版创伤后应激障碍检查表 (PCL-5) 在其两项研究中显示内部一致性 alpha 值 分别为 .94 和 .95。作者表明，该工具的重测信度为 .82（似乎被认为是强的），表明结果随时间推移稳定且一致。作者提到，聚合效度显示出与 PTSD 测量结果的高度相关性（例如，与 PCL 的 .85、与 PDS 的 .85 和与 DAPS 的 .84），这表明 PCL-5 似乎测量与其他已建立的 PTSD 测量结果相同的结构。作者表示，该工具与相关结构显示出中等相关性（例如，抑郁症 r = .60）并且与不相关结构显示出较低相关性（例如，躁狂症 r = .31），所有这些似乎都显示出良好的判别效度。
我的目标是在研究中使用 PCL-5（Blevins 等人，2015 年）。
但是，在执行此操作之前，我需要进行功效分析以计算获得可靠结果所需的先验最小样本量。为此，我需要以下内容：

显著性水平 (α = .05)
功效 (1-β = .80)
Cohen&#39;s d (尚不清楚)

我的问题：

根据上述描述，我可以自己决定 d 效果大小吗？
如果可以，值是多少，我该如何证明它（参考文献）？
如果不是，选项和/或替代方案是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652485/select-correct-effect-size-cohens-d-for-power-analysis</guid>
      <pubDate>Thu, 08 Aug 2024 10:43:46 GMT</pubDate>
    </item>
    <item>
      <title>在 GWAS 中调整协变量时，协变量是否需要取消惩罚？</title>
      <link>https://stats.stackexchange.com/questions/652484/when-adjusting-for-covariates-in-gwas-do-the-covariates-need-to-be-unpenalized</link>
      <description><![CDATA[我想知道是否有人遇到过这个问题并就如何最好地进行提出建议：
我正在使用基因型数据（这是 0、1 或 2 的数据）寻找 SNP 与 2 型糖尿病（二元性状为 0 或 1）之间的关联。需要调整协变量的效应大小，在本例中，协变量是前 10 个主成分（浮点数）、性别和年龄。
我正在使用 sci-kit 学习库、gridSearchCV 和 LogisticRegression。一些文献报告在使用惩罚回归时使用未惩罚的协变量进行此分析。这是为了确保在训练期间保留协变量，因为协变量可能会对遗传数据产生影响，最终的效应大小需要为此进行调整（即混杂）。但是据我所知，sci-kit learn 本身并不支持这一点。
我有两个问题：

有没有办法在 sci-kit learn 库中自定义每个特征的惩罚？或者是否有其他我可以考虑的解决方案？

我已经用协变量训练了几个模型，其中几个模型中只有 1 个协变量的 beta 系数为 0。这是否意味着模型保留了协变量并且这些结果有效？


或者，我可能需要重写 R 中的所有内容以使用 glm 库，该库本身支持这一点，但在走这条路之前我想先联系一下。
任何建议都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/652484/when-adjusting-for-covariates-in-gwas-do-the-covariates-need-to-be-unpenalized</guid>
      <pubDate>Thu, 08 Aug 2024 09:41:22 GMT</pubDate>
    </item>
    <item>
      <title>根据删失数据估计对数正态分布的参数以进行模拟</title>
      <link>https://stats.stackexchange.com/questions/652482/estimate-parameters-of-a-log-normal-distribution-from-censored-data-for-simulati</link>
      <description><![CDATA[我有以下模型
$$Y=X_1/c_1+X_2*X_2/c_2+X_3/c_3+X_3*X_4/c_4.$$
我知道 $X_1$ 和 $X_3$ 遵循不同但已知的正态分布，$c_1\dots,c_4$ 是已知常数，而 $X_2,X_4$ 遵循不同的未知对数正态分布。我想进行蒙特卡罗模拟来估计 $Y$ 的分位数。
我有一些数据可以估计 $X_2,X_4$ 的分布，但这些数据是左删失和右删失的。它可能看起来像这样：
$$\begin{matrix} &lt;0.2 &amp; 0.1 &amp; &gt;4 &amp; 0.7 &amp; 0.9 &amp; &lt;0.3 &amp;&gt;0.7 &amp;0.3 &amp;&lt;0.1 \end{matrix}$$
在较好的情况下，我有 60 个数据点，其中 10 个是删失的。在最坏的情况下，我有 21 个数据点，其中 9 个是删失的。
使用删失数据，我可以估计对数正态分布 $X_2,X_4$ 的参数。我使用 R 包 fitdistrplus 执行此操作。对于 $X_3$，我得到例如：
$$\begin{matrix} &amp; \text{estimate} &amp; \text{Std. Error}\\ \text{meanlog} &amp; -1.5&amp; 0.2\\ \text{sdlog} &amp; 1.8 &amp; 0.19 \end{matrix}$$
我想将估计的不确定性纳入我的模型中。有没有自然的方法可以做到这一点？我的想法是根据错误改变对数正态分布的参数。因此，我可以从 $\mathcal{N}(-1.8,0.19^2)$ 中选择不同的 $\text{meanlog}$，用于模拟形式 $\mathcal{N}(-1.5,0.2^2)$ 和 $\text{sdlog}$。但此处选择正态分布似乎有些武断。如果数据没有被审查，则 t 分布和 $\chi^2$ 分布似乎很自然地被选择（如果我是对的？）但这如何处理被审查的数据？我是否应该忽略计算误差并以任何方式使用它们？但自由度是多少？或者这些数据是否足以使用正态近似？或者还有其他方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652482/estimate-parameters-of-a-log-normal-distribution-from-censored-data-for-simulati</guid>
      <pubDate>Thu, 08 Aug 2024 08:53:39 GMT</pubDate>
    </item>
    <item>
      <title>如果不考虑偏度，峰度的定义是不是不太清楚？</title>
      <link>https://stats.stackexchange.com/questions/652480/isnt-kurtosis-poorly-defined-if-it-doesnt-take-into-account-skewness</link>
      <description><![CDATA[提前致歉，我不是统计学家，所以这个问题可能很幼稚。我的理解如下：
均值是第一个原始矩。
方差是第二个中心矩，即减去第一个原始矩（均值）后得到的。第二个原始矩可能在特定情况下有用，但并不能真正描述分布或数据集形状的某个方面（不考虑数据集的均值）。
类似地，偏度是第三个标准化矩，即减去均值并除以标准差（方差的根）后得到的。
但峰度是第四个标准化矩。它也是一个标准化矩，即它不考虑任何第三矩（偏度）。
这对于峰度的解释来说不是有问题吗？如果不是，为什么不是？如果有，有没有一种方法可以解释峰度并考虑到偏度？
（我说得对吗？没有一种简单的方法可以“去偏度”，即没有类似于集中化和标准化的简单转换会导致平均值为 0、标准差/方差为 1 和偏度为 0？）]]></description>
      <guid>https://stats.stackexchange.com/questions/652480/isnt-kurtosis-poorly-defined-if-it-doesnt-take-into-account-skewness</guid>
      <pubDate>Thu, 08 Aug 2024 08:31:48 GMT</pubDate>
    </item>
    <item>
      <title>使用类似模型生成的标签训练模型：过度拟合？</title>
      <link>https://stats.stackexchange.com/questions/652479/train-model-with-labels-generated-by-similar-model-overfit</link>
      <description><![CDATA[我训练模型来预测航空影像中的一些线性特征。由于参考数据只是线条，我制作了一个简单的缓冲区，以便标签与目标特征的宽度非常接近。它们的宽度从 3 到 15 米不等，因此我将中位数宽度设置为 9 米。UNet 模型很好地预测了它们。事实上，预测比标签更接近现实/图像，因为预测更接近目标特征的边缘，而不是简单的 9 米宽度。但是，准确度指标很差（测试数据集中的 F1 为 0.6），因为标签和预测之间的 IoU 很低。所以，我想到我可以将此模型的预测用作改进的训练和测试标签。然后，我将使用改进的训练标签训练另一个模型，并针对改进的测试标签对其进行测试。结果在视觉上相似，但测试数据集中的 F1 上升到 0.9。这是过度拟合吗？测试数据集显然未用于训练任一模型。
我尝试使用 eCognition 分割整个图像并提取我的目标特征，但这不可行。我的目标特征分割通常非常不准确。
以下是损失和准确度曲线，以防万一：
]]></description>
      <guid>https://stats.stackexchange.com/questions/652479/train-model-with-labels-generated-by-similar-model-overfit</guid>
      <pubDate>Thu, 08 Aug 2024 07:58:07 GMT</pubDate>
    </item>
    <item>
      <title>对于小样本量、不明确（非正态）分布的适当显着性检验</title>
      <link>https://stats.stackexchange.com/questions/652478/appropriate-significance-test-for-small-sample-size-unclear-non-normal-distri</link>
      <description><![CDATA[给定数据：
30 个数据点，以可用性分数的形式呈现（系统可用性量表）
数据中有 2 个组（组 1：17，组 2：13，独立，大小不等）
目标：
看看这两组的可用性分数之间是否存在统计上的显著差异
问题：
这里研究比较两个独立组的统计显著性的适当方法是什么？
初步想法（基于作为非统计学家的一些研究）：
有些测试对底层数据分布做出假设，有些则不做。通过直方图和箱线图可视化数据，我的第一印象是它不是正态分布的。因此，例如 Mann-Whitney-U 检验可能是一种选择。此外，使用 Shapiro-Wilk 等方法进行正态性测试被认为是无用的，因为其拒绝正态性假设的能力很弱，尤其是在样本量较小的情况下。不过，如果这样的测试拒绝了假设（即：它是正态分布），我们确实可以将其视为非正态性的迹象。
有人可以确认或拒绝我得出的结论吗？根据提供的信息，是否有更好的替代方案？
我正在寻找处理此类数据的最佳实践，并希望听取您的意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/652478/appropriate-significance-test-for-small-sample-size-unclear-non-normal-distri</guid>
      <pubDate>Thu, 08 Aug 2024 07:17:57 GMT</pubDate>
    </item>
    <item>
      <title>SKLearn 如何得出 LASSO 系数？</title>
      <link>https://stats.stackexchange.com/questions/652475/how-does-sklearn-derive-lasso-coefficients</link>
      <description><![CDATA[我正在尝试使用 SciPy 优化来推导 SKLearn 的 LASSO 系数，只是为了了解 SKLearn 的内部工作原理。但是，我无法使参数匹配。
import numpy as np
from sklearn.linear_model import Lasso

from sklearn.datasets import load_iris
iris = load_iris()
X, y = iris.data[:,0:3], iris.data[:,3]

lasso_reg = Lasso(alpha=1)
lasso_reg.fit(X, y)

得出 lasso_reg.coef_ = array([ 0. , -0. , 0.09270611]) 和 lasso_reg.intercept_ = 0.8509437849691903
当我尝试自己推导这些时，我试图最小化：
def lasso_min(params):
return sum((y - params[0] - np.matmul(X, params[1:]))**2) + lam * sum([abs(val) for val in params[1:]])

使用：
lam = 1
from scipy import optimize
sol = optimize.minimize(lasso_min, [0,0,0,0])

这给了我 sol.x = array([-0.29598937, -0.14396059, 0.16120468, 0.49060031])
即使我增加 lam 的值，我也无法将系数正则化为 0。有人能解释一下我在这里做错了什么吗？我认为这是我的代码中一些非常基本的东西，而不是缺乏更深层次的理解？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652475/how-does-sklearn-derive-lasso-coefficients</guid>
      <pubDate>Thu, 08 Aug 2024 03:29:09 GMT</pubDate>
    </item>
    <item>
      <title>我需要对 2 Ivs 和 2 DV 进行什么分析？</title>
      <link>https://stats.stackexchange.com/questions/652456/what-analysis-do-i-need-for-2-ivs-and-2-dvs</link>
      <description><![CDATA[我认为我需要 MANOVA，但我可能需要 ANCOVA，然后仅在实验组内进行 ANOVA。
我认为它是干预组内的 2x2 因子独立测量 ANOVA。我没有任何等价的句子可以用于 MANOVA，因为我之前从未写过 MANOVA
我有 2 个 IV：
IV1 有 2 个级别：对照组和干预组
IV2 是干预组中的个性特征，因为这是一个次要假设
我有 2 个相关的 DV：
DV1 是儿童自我评价的幸福感得分随时间的变化（1 个分数在实验开始时，另一个分数在实验结束时）
DV2 儿童父母评价的幸福感得分随时间的变化（1 个分数在实验开始时，另一个分数在实验结束时）
我可以将幸福感得分分为各种不同的子分数（希望、幸福、乐观、价值）
我的假设是：
H0- 实验组和对照组之间的幸福感改善随时间没有显著差异
H1- 与对照组相比，干预组的幸福感得分将显着改善
H2- 干预组的具体幸福感得分显着改善希望、幸福、乐观和价值感
H3- 干预组的改善程度在具有特定人格特质的人中会更高。
我很高兴被告知我完全错了，因为我的论文的分析部分总是花费最长的时间来写，我感到完全迷失了。提前谢谢 :)

Chat GPT 说：
根据您的假设，此分析策略涉及使用 MANOVA、ANCOVA、ANOVA 和回归分析的组合来彻底评估您的干预效果和关于自然相关性的次要假设。
重新审视假设：
H1：使用 MANOVA 评估总体差异并跟进特定 DV 变化的 ANOVA。
H2：使用因子 ANOVA 评估子量表差异。
H3：使用干预组内的方差分析或回归分析自然相关性的影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/652456/what-analysis-do-i-need-for-2-ivs-and-2-dvs</guid>
      <pubDate>Wed, 07 Aug 2024 19:41:25 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用混合逻辑分析 DCE</title>
      <link>https://stats.stackexchange.com/questions/652448/analysing-dce-with-mixed-logit-in-r</link>
      <description><![CDATA[我正在通过调查进行离散选择实验 (DCE)。我的研究基于具有不同属性级别/类型的护肤产品。总共有四个属性（每个属性有 3 个级别/类型），我生成了 81 种不同的产品。我将它们分成 3 个不同的调查（每个调查有 9 个选择集，每个选择集有 3 种产品可供选择，受访者只能选择其中一种）。此外，他们还回答了有关他们的人口统计和对某些品牌（我在产品设计中使用的品牌）的熟悉程度的问题。这些是协变量（年龄组、收入组、居住地区、对 6 个不同品牌的使用熟悉程度）。
我以长格式扩展了数据（总共 2430 行，因为每个受访者考虑了超过 27 种具有不同属性级别的产品，总共有 90 名受访者）。我使用这段代码放入 mlogit 模型中：
expanded_data &lt;- expand_data %&gt;%
mutate(
Age = as.factor(Age),
Income = as.factor(Income),
Region = as.factor(Region),
CeraVe = as.factor(CeraVe),
Maybelline = as.factor(Maybelline),
LOreal = as.factor(LOreal),
LaMer = as.factor(LaMer),
Chanel = as.factor(Chanel),
Dior = as.factor(Dior),
Price = as.factor(Price),
Packaging = as.factor(Packaging),
Quality = as.factor(Quality),
Brand = as.factor(Brand),
ProductChoiceBinary = as.logical(ProductChoiceBinary)
)

mlogit_data &lt;- mlogit.data(expanded_data, 
choice = &quot;ProductChoiceBinary&quot;, 
shape = &quot;long&quot;, 
id.var = &quot;UniqueChoiceID&quot;, 
alt.var = &quot;ProductID&quot;)

complex_model &lt;- mlogit(ProductChoiceBinary ~ 价格 + 包装 + 质量 + 品牌 | 年龄 + 收入 + 地区 + CeraVe + Maybelline + LOreal + LaMer + Chanel + Dior, 
data = mlogit_data, 
random = ~ 价格 + 包装 + 质量 + 品牌 | UniqueChoiceID)

但是这个错误一直出现：“solve.default(H, g[!fixed]) 中的错误：Lapack 例程 dgesv：系统完全是奇异的：U[1,1] = 0”
我已经检查过没有多重共线性，这可能是数据结构的问题。但是，我的时间不多了，我真的需要结果。有人知道哪里出了问题，我该怎么办？
我不确定如何在此处上传我的结构图像。我的数据结构为 2430 行和 19 列（RespondentID、问题、产品、年龄、地区、收入、CeraVe、Maybelline、LOreal、LaMer、Chanel、Dior、ProductChoice、价格、包装、质量、品牌、ProductChoiceBinary、UniqueChoiceID）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652448/analysing-dce-with-mixed-logit-in-r</guid>
      <pubDate>Wed, 07 Aug 2024 14:52:46 GMT</pubDate>
    </item>
    <item>
      <title>Surpyval Weibull 拟合优度</title>
      <link>https://stats.stackexchange.com/questions/652447/surpyval-weibull-goodness-of-fit</link>
      <description><![CDATA[我一直在使用 surpyval 将一些校准数据拟合到威布尔分布。我想评估拟合优度，但我不知道该怎么做。我以前使用过“可靠性”库，它有一个 KS 检验，但我不知道如何在 Surpyval 中执行此操作（可靠性不支持区间删失数据）。代码：
import surpyval as surv
import matplotlib.pyplot as plt
#sample data
Fail = [1,1,3,1,5,1,1,2,1,1,1,1,1]
Type = [1,1,1,2,1,1,2,1,1,2,1,2,1,2,1]
Time = [1820,1987,2176,[2373.0, 2542.0],2373,2731,[2920.0, 3093.0],2920,3279,[3472.0, 3641.0],3472,[3829.0, 4009.0],3829]

model = surv.Weibull.fit(x = Time, c =类型，n = 失败)
model.plot()
plt.show()

libraries:
matplotlib 3.6.0
numpy 1.26.0
scipy 1.14.0
surpyval 0.10.10

包含完整数据集的图。
我的完整数据集有左、右和区间数据。任何其他拟合优度方法/知识都会非常有帮助，并且包括对图像的任何见解。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652447/surpyval-weibull-goodness-of-fit</guid>
      <pubDate>Wed, 07 Aug 2024 14:49:15 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 模型的群体稳定性指数 [重复]</title>
      <link>https://stats.stackexchange.com/questions/652443/population-stability-index-for-xgboost-model</link>
      <description><![CDATA[计算 XGBoost 模型的种群稳定性指数是否有意义？
我将原始值分为 2 到 5 组，并以此方式训练模型。
我认为，如果变量 1 有组 1、组 2 和组 3，一棵树可以拆分为 &gt;组 2，而另一棵树可以拆分为 &gt;**=**组 2。
这样，每棵树都可以对变量 1 进行不同的拆分，并且无法进行 PSI，否则就没有多大意义了。
这样对吗？
编辑：问题没有重复，在这里我问计算 PSI 是否有意义，另一个问题是如何进行计算。]]></description>
      <guid>https://stats.stackexchange.com/questions/652443/population-stability-index-for-xgboost-model</guid>
      <pubDate>Wed, 07 Aug 2024 13:55:48 GMT</pubDate>
    </item>
    <item>
      <title>解释变量高度不平衡的回归</title>
      <link>https://stats.stackexchange.com/questions/652440/regression-with-highly-unbalanced-explanatory-variable</link>
      <description><![CDATA[我有一个回归问题，其中一个解释变量是分类变量，有 2 个类别。我的问题是，一个类别有 90% 的观测值，而第二个类别只有 10% 的观测值。
这种高度不平衡的分类变量的存在是否会对模型系数的统计推断造成任何问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/652440/regression-with-highly-unbalanced-explanatory-variable</guid>
      <pubDate>Wed, 07 Aug 2024 13:20:48 GMT</pubDate>
    </item>
    </channel>
</rss>