<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 25 Mar 2024 09:13:39 GMT</lastBuildDate>
    <item>
      <title>可能不会通过</title>
      <link>https://stats.stackexchange.com/questions/643463/probably-not-going-through</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/643463/probably-not-going-through</guid>
      <pubDate>Mon, 25 Mar 2024 09:11:04 GMT</pubDate>
    </item>
    <item>
      <title>引导生存数据以获得中位生存时间函数的置信区间</title>
      <link>https://stats.stackexchange.com/questions/643462/bootstrapping-survival-data-to-obtain-confidence-interval-for-a-function-of-medi</link>
      <description><![CDATA[我有一组生存数据，足够成熟，可以通过Kaplan-Meier方法估计其样本中位数。我希望估计一个数量，该数量是中位数的递增函数，并计划使用 bootstrap 来获得 95% 的置信区间。
我的问题是，对于引导程序的每次迭代，中值的 Kaplan-Meier 估计很可能不存在，因为重新采样本身可能不够成熟。有没有办法解决？例如设置“未达到”中位数为 Inf 并照常进行？]]></description>
      <guid>https://stats.stackexchange.com/questions/643462/bootstrapping-survival-data-to-obtain-confidence-interval-for-a-function-of-medi</guid>
      <pubDate>Mon, 25 Mar 2024 09:03:52 GMT</pubDate>
    </item>
    <item>
      <title>如何在给定批次结果样本的情况下估计单个结果的平均值和标准差？</title>
      <link>https://stats.stackexchange.com/questions/643459/how-to-estimate-mean-and-standard-deviation-of-individual-result-given-a-sample</link>
      <description><![CDATA[如果我的标题措辞不当，或者我使用了错误的标签，我提前道歉；这是我第一次在这里提问。
我想分析生产系统批量导入数据令牌需要多长时间。目前，系统每导入 500 个 token 就会生成一条日志行；对于给定的 30000 个令牌样本，会生成 60 行（技术上是 61 行，因为 0 % 500 = 0，但我当然忽略了第一个数字。）
从这个 60 个数字的样本中，我可以轻松计算出每组 500 个令牌的平均值和标准差，但是我可以推断出这一点来估计每个令牌导入的平均值和标准差吗？例如，请假设我的平均值是 9878.85，SD 是 3441.64。

我可以将平均值除以 500 来估算每次导入所需的时间 - 在本例中为 19.76？
Google 快速搜索表明我不应该将标准差除以 500，而应该除以 500 的根。但是，当与上面的答案配对时，我得到 153.92，这是没有意义的。我这样做的方法正确吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/643459/how-to-estimate-mean-and-standard-deviation-of-individual-result-given-a-sample</guid>
      <pubDate>Mon, 25 Mar 2024 08:11:29 GMT</pubDate>
    </item>
    <item>
      <title>我可以生成与给定数据集具有相同特征的时间序列，但添加已知的线性趋势系数（不仅仅是趋势强度）吗？</title>
      <link>https://stats.stackexchange.com/questions/643458/can-i-generate-a-time-series-with-same-features-as-a-given-dataset-but-add-a-kn</link>
      <description><![CDATA[我想生成与环境数据特征相匹配的数据（由于非正态性、偏度等原因，通常使用非参数检验进行分析）。我想知道如何最好地捕获存在的任何线性趋势（比较不同的非参数和参数方法），但要做到这一点，我需要一个基准来知道真正的线性趋势是什么。我看到 GRATIS 能够根据给定数据集的特征生成数据，但它似乎不允许设置线性趋势的值（仅趋势强度） - 有没有办法做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/643458/can-i-generate-a-time-series-with-same-features-as-a-given-dataset-but-add-a-kn</guid>
      <pubDate>Mon, 25 Mar 2024 07:27:07 GMT</pubDate>
    </item>
    <item>
      <title>LLM 在生成过程中是有状态的还是无状态的？</title>
      <link>https://stats.stackexchange.com/questions/643457/are-llms-stateful-or-stateless-during-the-generation-process</link>
      <description><![CDATA[像 OpenAI 的 gpt-* 这样的 LLM 在响应生成期间是有状态的还是无状态的？我读过几篇文章，例如 this 但是我对此仍然不太确定。我知道他们正在逐个令牌生成响应令牌。在每个步骤中：该过程是否基本上丢弃除生成的标记之外的所有计算并从头开始，但这次根据原始输入加上已经生成的部分响应来预测下一个标记？ （这就是我所说的无状态。）或者该过程是否保留一些计算出的激活并在下一步中使用它们？
我发现这对于法学硕士的直觉很有趣。如果你“人性化”法学硕士对你的心理模型有点了解，这个问题基本上是：法学硕士是否为生成的文本或下一个句子（=有状态）形成某种计划并遵循该计划，或者它基本上在每个步骤中猜测它想要做什么到目前为止生成的部分响应并用下一个令牌（=无状态）扩展它？从我读到的内容来看，我认为从这个意义上来说它是无状态的，因为以这种方式训练法学硕士似乎更容易，但这似乎有点令人惊讶，而且可能有点浪费，所以我宁愿确定。
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/643457/are-llms-stateful-or-stateless-during-the-generation-process</guid>
      <pubDate>Mon, 25 Mar 2024 07:19:12 GMT</pubDate>
    </item>
    <item>
      <title>使用具有混合变量的 PCA 进行线性回归</title>
      <link>https://stats.stackexchange.com/questions/643456/linear-regression-using-pca-with-mixed-variables</link>
      <description><![CDATA[我有很多变量（数字和分类），我想研究它们对线性模型中因变量的影响。为了避免过度参数化，我决定首先执行 PCAmix 并创建三个组件，但现在我不知道如何提取它们以用作线性模型中的自变量，在这种情况下具有三个自变量。这是我所做的：
库(PCAmixdata)
图书馆（心理学）
split &lt;- splitmix(数据)
pcamix &lt;- PCAmix(X.quanti=split$X.quanti,
                 X.quali=分割$X.quali,
                 重命名.level=TRUE,
                 图=假，ndim=3）
loads &lt;- pcamix$sqload # 提取载荷
pcamix_rotated &lt;- varimax(loadings) # 使用 varimax 旋转来旋转组件
rotated_loadings &lt;- pcamix_rotated$loadings # 获取旋转后的载荷
打印（旋转负载）

这是正确的吗？
然后我想创建一个像这样的线性模型：
ols_pcamix&lt;-lm（因变量~PC1 + PC2 + PC3，数据=数据）

但是，我不知道如何从 PCAmix 中提取三个组件（我在上面的模型中称为 PC1、PC2 和 PC3）。]]></description>
      <guid>https://stats.stackexchange.com/questions/643456/linear-regression-using-pca-with-mixed-variables</guid>
      <pubDate>Mon, 25 Mar 2024 07:06:42 GMT</pubDate>
    </item>
    <item>
      <title>解释表中的危险比</title>
      <link>https://stats.stackexchange.com/questions/643453/interpreting-hazard-ratio-in-table</link>
      <description><![CDATA[此海报最近因其主题和结论而成为头条新闻。具体来说，我有兴趣了解如何计算此表中的风险比：

例如，让我们以“整体样本”为例。例子。参考组“12-16小时”是指参考组“12-16小时”。对于“＜8小时”组，具有423个事件和11831个样本。他们有31个事件，N为414。为了计算组“＜8h”的风险比，我认为这只是该组的危险除以参考组的危险：
（31/414）/（423/11831）
但是，这将等于 2.09，而不是参考的 1.91。有人可以解释一下显示/计算的内容以及它们是如何达到 1.91 的吗？ （或者提供在给定样本的情况下重新创建这些危险值的代码。）]]></description>
      <guid>https://stats.stackexchange.com/questions/643453/interpreting-hazard-ratio-in-table</guid>
      <pubDate>Mon, 25 Mar 2024 06:08:23 GMT</pubDate>
    </item>
    <item>
      <title>指定面板数据作为调查对象</title>
      <link>https://stats.stackexchange.com/questions/643461/specifying-panel-data-as-survey-object</link>
      <description><![CDATA[我有一个在不同波次（总共 30 波）中收集的家庭特征（收入、支出、资产所有权等）的面板数据集。调查数据经过分层，提供了初级抽样单位和分层后权重。
调查包的文档没有提及指定面板数据的方法。从其他示例中，我认为使用交互函数来指定不同的波将是一种可能的方法。
survey_obj_1 &lt;- svydesign(id=~PSU_ID,weights=~weight,
                          地层=~交互（地层，Wave_No），
                          嵌套=真，数据=数据帧）

指定为各个波分配权重，而不是使用
survey_obj_2 &lt;- svydesign（id=~PSU_ID，权重=~权重，strata=~Stratum，
                          嵌套=真，数据=数据帧）

它没有指定数据的面板/时间性质。
这是正确的吗？欢迎任何有关使用面板数据调查对象的建议或示例。
survey_obj_1 和 survey_obj_2 均已成功创建对象。两个对象的平均参数（如平均收入）的估计也相同，但考虑数据时间性质的 survey_obj_1 中的标准误差远低于 survey_obj_2 ]]></description>
      <guid>https://stats.stackexchange.com/questions/643461/specifying-panel-data-as-survey-object</guid>
      <pubDate>Mon, 25 Mar 2024 04:22:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么最好使用似然比检验来检验预测变量的效果？</title>
      <link>https://stats.stackexchange.com/questions/643440/why-is-it-preferable-to-test-the-effect-of-a-predictor-using-a-likelihood-ratio</link>
      <description><![CDATA[在他们的精彩著作应用纵向数据分析：对变化和事件发生进行建模 Singer 和 Willett 提倡使用迭代模型比较技术来测试预测变量的效果：从基线模型开始，然后添加预测变量，一次一个，对一系列后续模型，使用似然比检验来确定向模型添加新预测变量是否会显着降低 -2LL 偏差。这些是嵌套模型，因此每个 LR 测试实际上都会测试每个新预测变量的效果。如果 -2LL 偏差显着减小，则保留新模型，否则保留先前模型。
他们表示，他们推荐这种技术，而不是简单地将打算在单个回归模型中测试的所有预测变量包括在内，并报告置信区间和 p 值。
我已经接受了他们的建议，但我不太明白为什么（即基于什么理由）他们认为他们的迭代方法优于“全力以赴”的方法。
我问这个问题的原因是，我已经对几篇论文进行了分析，我的合著者对迭代方法感到非常困惑。可能是我解释得不够好，但我想要一些更可靠的使用它的理由，而不是“因为辛格和威利特这么说”。
非常感谢通俗易懂的语言解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/643440/why-is-it-preferable-to-test-the-effect-of-a-predictor-using-a-likelihood-ratio</guid>
      <pubDate>Sun, 24 Mar 2024 23:33:10 GMT</pubDate>
    </item>
    <item>
      <title>cookie问题中有两种计算合取概率的方法吗？</title>
      <link>https://stats.stackexchange.com/questions/643423/are-there-two-ways-to-calculate-conjunction-probability-in-the-cookie-problem</link>
      <description><![CDATA[我正在阅读 Allen B. Downey 的《思考贝叶斯》。
他介绍了一个简单的条件概率问题。
你有两碗饼干。
第 1 碗有 30 块香草饼干和 10 块巧克力饼干
2 号碗有 20 块香草饼干和 20 块巧克力饼干
如果您选择一块饼干并且它是香草饼干，那么它来自第 1 碗的概率是多少？假设您从任一碗中进行选择的概率相同 (0.5)。
您可以使用条件概率公式来解决这个问题。
P(碗 1 | 香草) = P(碗 1 ∩ 香草) / P(香草)
似乎有两种方法可以求解分子：P(Bowl 1 ∩ Vanilla)
据我了解，相交概率 (∩) 可以通过乘以每个事件的概率来计算。因此，要计算分子，您需要乘以 P(Bowl 1) * P(Vanilla)
这将是（0.5 *（从碗 1 中选择香草的概率）
或 (0.5 * 0.75) = 0.375
将其代入条件概率公式，得出 0.375/0.625 = 0.6
克劳德（AI 聊天机器人）提出了这个计算来确定分子。
第 1 碗中的香草饼干/饼干总数，即 30/80 或 0.375
这是计算分子的比我假设的更准确的方法吗？
P（碗1）* P（香草）]]></description>
      <guid>https://stats.stackexchange.com/questions/643423/are-there-two-ways-to-calculate-conjunction-probability-in-the-cookie-problem</guid>
      <pubDate>Sun, 24 Mar 2024 20:39:34 GMT</pubDate>
    </item>
    <item>
      <title>我们相信贝叶斯统计中存在真正的先验分布吗？</title>
      <link>https://stats.stackexchange.com/questions/643422/do-we-believe-in-existence-of-true-prior-distribution-in-bayesian-statistics</link>
      <description><![CDATA[设 $X$ 为 $\mathcal{X}$ 值随机变量。假设我们观察到 $X = x$。
我们使用参数模型，以 $\theta \in \Theta$ 为参数。
在频率论方法中，我们相信存在一个真正的$\theta \in \Theta$，它决定了$X$。推理过程是我们使用 $x$ 来估计这个真实的 $\theta$。
在贝叶斯方法中，我们对 $\Theta$ 施加先验概率测量 $\Pi$ 。实际的推理过程是我们找到一个统计模型（概率度量的集合 $\mathcal{P}$ 其中 $ P_{X \mid \theta = \theta}$ 取值) 以及之前反映客户信念的 $\Pi$，更新 &lt; span class=&quot;math-container&quot;&gt;$\Pi$ 使用$x$，根据后验分布得出结论。实际上没有其他方法可以完成这项工作。
我的问题是，当我们采用贝叶斯框架，选择统计模型$\mathcal{P}$后，我们是否相信存在$\theta$、$P_{\theta}$ 的真实分布（这样我们就可以看到后验分布）作为对这个真实 $P_{\theta}$ 的估计）？我认为，即使我们相信这一点，也可能不会影响我们实际开展工作的方式。但似乎，一旦我们相信它，贝叶斯方法就完全包含了频率论方法（让 $P_{\theta}$ 专注于单例）。 p&gt;
编辑：抱歉。术语“真实先验”是指术语“真实先验”。可能会产生误导。我已经编辑了这个问题，完全避免使用这个术语。]]></description>
      <guid>https://stats.stackexchange.com/questions/643422/do-we-believe-in-existence-of-true-prior-distribution-in-bayesian-statistics</guid>
      <pubDate>Sun, 24 Mar 2024 20:34:31 GMT</pubDate>
    </item>
    <item>
      <title>当有一年中的季节和月份信息时，如何正确评估响应与时间之间的关系作为预测变量？</title>
      <link>https://stats.stackexchange.com/questions/643416/how-to-properly-assess-relationship-between-response-and-time-as-a-predictor-whe</link>
      <description><![CDATA[我希望能够通过线性混合效应模型或分层 GAM（如果适用）进行测试，看看参与者粪便代谢物和时间之间是否存在关系（线性或非线性）。
从 11 月（秋季）开始，每个受试者 (n=150) 每个月都提供一个样本。
我需要考虑不同的时间组成部分，季节（秋季、冬季、春夏、秋季）或月份。

如果我想查看季节性变化（将其作为连续或分类来比较不同的季节对），我是否需要有时间（以月为单位）作为协变量，如果是的话，作为连续或绝对的？

如果我只想查看与时间的关系（连续或比较月份，而不被季节性变化混淆），我的模型中是否有季节作为协变量？当然，当月份恰好处于同一季节期间时，在进行成对比较时则不然。


我问的原因是根据我见过的一些示例模型，我有点不确定，例如如果有季节和一年中的日期或月份的信息，则在考虑时间与其响应之间任何可能的关系时，当季节性变化会影响随时间的响应时，他们的模型中不存在季节性协变量。
任何想法或重定向到更好的资源/示例将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/643416/how-to-properly-assess-relationship-between-response-and-time-as-a-predictor-whe</guid>
      <pubDate>Sun, 24 Mar 2024 18:56:48 GMT</pubDate>
    </item>
    <item>
      <title>相关眼睛数据的样本量计算</title>
      <link>https://stats.stackexchange.com/questions/643191/sample-size-calculation-for-correlated-eye-data</link>
      <description><![CDATA[什么公式或软件包可用于计算相关眼数据的样本量？一项观察性研究正在招募具有两只正常眼睛的参与者和一只眼睛患有临床病症且第二只眼睛患有另一种临床病症的参与者。所以我有以下几组（病例对照抽样设计，3组）：
A组：两只眼睛正常的参与者（包括双眼）
B 组：一只眼睛出现临床症状
C 组：另一只眼睛出现临床症状
在A组中，包括参与者的双眼，因此这些眼睛将被关联。在B 组和C 组中，双眼均经过评估，然后分为B 组和C 组，因此这些组也具有相关性。
该研究的目的是评估三组之间连续结果的临床意义差异，其中样本量公式适合此处； i) 如果结果连续正常， ii) 如果结果连续非正常。如果各组是独立的，则方差分析模型的功效分析可能是合适的，但由于我们正在处理相关的眼睛数据，因此不清楚应使用哪个样本量公式。]]></description>
      <guid>https://stats.stackexchange.com/questions/643191/sample-size-calculation-for-correlated-eye-data</guid>
      <pubDate>Thu, 21 Mar 2024 18:20:36 GMT</pubDate>
    </item>
    <item>
      <title>引入鲁棒协方差矩阵估计器时联合显着性大幅增加</title>
      <link>https://stats.stackexchange.com/questions/643152/large-increase-in-joint-significance-when-introducing-robust-covariance-matrix-e</link>
      <description><![CDATA[我有一个线性回归模型，其中 $Y$ 在五个虚拟对象上进行回归 $X_3,X_4,X_5,X_ {10}，X_{20}$。 （在 R 中，我实际上对产生 5 个虚拟变量的因子 $X$ 进行回归 $Y$ 。 ) 我的样本量是 24（加上 6 个NA 观察值）。
当我天真地测试虚拟变量的联合显着性时，$p$ 值是 0.4124。当我引入异方差鲁棒协方差矩阵时，我得到 $p$ 值 0.003324。在我看来，如此重大的变化似乎很可疑。我错过了什么？
（请注意，在引入异方差稳健标准误差后，各个回归量变得不那么重要，这是我直观的感觉。同时，这使得联合显着性的大幅增加更加令人费解。）
&lt;代码&gt;&gt;输出（y）
c(-0.0151021101926254,-0.0309851953937721,0.0114773798796626,
-0.0239734402153541、0.0676350205999363、0.0228620593817569、
不适用，不适用，-0.0475378138063825，0.0646450541679466，不适用，-0.00520255289479559，
0.0405746527075472, 0.0178849404415307, -0.00874351591122196,
-0.0544415483370128、0.0946388458623007、0.0101295037685308、
0.0171868062386878, -0.00259921472353685, -0.0479843871962202,
0.0107363946469932, 0.00597028176762957, -0.0214522363058097,
不适用，-0.0270221434281566，不适用，0.0338132549609079，0.112261926884369，
不适用）
&gt;输出(x)
结构(c(4L, 4L, 3L, 3L, 3L, 6L, 5L, 1L, 3L, 6L, 3L, 3L, 4L,
4L、4L、1L、1L、6L、4L、2L、2L、4L、1L、3L、1L、4L、1L、7L、1L、
1L)，水平＝c(“2”，“3”，“4”，“5”，“7”，“10”，“20”)，类别＝“因子”)
&gt;
&gt; packages=c(“汽车”,“lmtest”,“三明治”)
&gt; for（包中的包）库（包，character.only=TRUE）
&gt;
&gt; m2=lm(y~x);概要(m2)

称呼：
lm(公式 = y ~ x)

残差：
      最小 1Q 中值 3Q 最大
-0.094049 -0.022485 -0.005668 0.018662 0.072655

系数：
             估计标准。误差t值Pr(&gt;|t|)
（截距）0.039607 0.021498 1.842 0.0820 。
x3 -0.064899 0.037236 -1.743 0.0984 。
x4 -0.042783 0.027754 -1.541 0.1406
x5 -0.039041 0.026330 -1.483 0.1554
x10 -0.007062 0.032839 -0.215 0.8322
x20 -0.005794 0.048072 -0.121 0.9054
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残余标准误差：18 个自由度上为 0.043
  （6 个观察因缺失而被删除）
多重 R 平方：0.2281，调整 R 平方：0.01368
F 统计量：5 和 18 DF 上为 1.064，p 值：0.4124

&gt; vcov2=vcovHC(m2,类型=“HC1”)
&gt;打印（coeftest（m2，vcov。= vcov2））

系数 t 检验：

              估计标准。误差t值Pr(&gt;|t|)
（截距）0.0396074 0.0390340 1.0147 0.3237
x3 -0.0648992 0.0432082 -1.5020 0.1504
x4 -0.0427830 0.0426467 -1.0032 0.3291
x5 -0.0390411 0.0401830 -0.9716 0.3441
x10 -0.0070618 0.0420075 -0.1681 0.8684
x20 -0.0057941 0.0390340 -0.1484 0.8836

&gt; hyper=paste0(名称(coef(m2))[-1],“=0”)
&gt; lh2=线性假设（模型=m2，假设.矩阵=hypo，rhs=NULL，vcov.=vcov2）；打印（lh2）
线性假设检验

假设：
x3 = 0
x4 = 0
x5 = 0
x10 = 0
x20 = 0

模型一：受限模型
模型2：y~x

注：提供系数协方差矩阵。

  Res.Df Df F Pr(&gt;F)
1 23
2 18 5 5.397 0.003324 **
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/643152/large-increase-in-joint-significance-when-introducing-robust-covariance-matrix-e</guid>
      <pubDate>Thu, 21 Mar 2024 12:40:20 GMT</pubDate>
    </item>
    <item>
      <title>卡方去噪的效率</title>
      <link>https://stats.stackexchange.com/questions/637361/efficiency-of-chi-squared-denoising</link>
      <description><![CDATA[假设我的测量 $\theta+\epsilon$ 被 IID 加性噪声损坏 $\epsilon$以卡方分布（已知） $d$ 自由度，合并多个观测值来推断  的效率是多少$\theta$?
使用 Fisher 信息的定义，我得到位置参数 $\theta$ 的 Fisher 信息的以下表达式，奇点位于 $d=4$。
$$\frac{1}{2(d-4)}, d&gt;4$$

Charles 张的答案表明Fisher信息的分歧意味着MLE比$O(1/\sqrt{n})$。
“快”到底有多快？在这种情况下？固定 $d$ 的样本大小是否为多项式？

笔记本]]></description>
      <guid>https://stats.stackexchange.com/questions/637361/efficiency-of-chi-squared-denoising</guid>
      <pubDate>Sun, 21 Jan 2024 00:17:32 GMT</pubDate>
    </item>
    </channel>
</rss>