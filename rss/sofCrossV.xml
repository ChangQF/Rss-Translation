<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 04 Jan 2024 18:17:30 GMT</lastBuildDate>
    <item>
      <title>MLM / HLM 组之间需要相同的样本量吗？</title>
      <link>https://stats.stackexchange.com/questions/636160/mlm-hlm-equal-sample-sizes-needed-between-groups</link>
      <description><![CDATA[我正在分析日记研究的数据集（每个参与者 6-14 次重复测量）。我的样本由 2 组（1 组拥有专业知识，1 组没有专业知识）组成，我们认为它们在许多关键变量上存在差异。与非专业组 (150) 相比，我在专业组 (200) 中有更多的参与者。
有人建议我最好在这些组之间拥有相同的样本量，但我不确定这个建议是否适用于我计划的分析。我将在组之间对每日汇总变量进行 t 检验，并对以人为中心的变量进行 MLM/HLM 以了解人内差异。
如果我从体验组中剔除最后 50 名参与者，我将得到平等的组。但显然，除非确实有必要，否则我不想放弃参与者。
任何建议和/或参考资料将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/636160/mlm-hlm-equal-sample-sizes-needed-between-groups</guid>
      <pubDate>Thu, 04 Jan 2024 17:49:15 GMT</pubDate>
    </item>
    <item>
      <title>平方损失的修改类似于绝对损失和弹球损失：得出什么？</title>
      <link>https://stats.stackexchange.com/questions/636159/modification-of-square-loss-analogous-to-absolute-and-vs-pinball-loss-what-is-e</link>
      <description><![CDATA[分位数 $\tau$ 处的分位数回归可最大限度地减少以下“pinball” 损失函数，$L_{\tau}$，以及引出条件分位数$\tau$。
$$
l_{\tau}(y_i, \hat y_i) = \begin{cases}
      \tau\vert y_i - \hat y_i\vert, &amp; y_i - \hat y_i \ge 0 \\
      (1 - \tau)\vert y_i - \hat y_i\vert, &amp; y_i - \hat y_i &lt; 0
   \end{案例}\\
L_{\tau}(y, \hat y) = \sum_{i=1}^n l_{\tau}(y_i, \hat y_i)
$$
当$\tau = 0.5$时，这个损失函数是绝对损失。
如果我们将平方损失推广为绝对损失推广到弹球损失的方式，则表示为下面的 $L^{^*}_{\tau}$，引出什么？
$$
l^{^*}_{\tau}(y_i, \hat y_i) = \begin{cases}
      \tau\left( y_i - \hat y_i\right)^2, &amp; y_i - \hat y_i \ge 0 \\
      (1 - \tau)\left( y_i - \hat y_i\right)^2, &amp; y_i - \hat y_i &lt; 0
   \end{案例}\\
L^{^*}_{\tau}(y, \hat y) = \sum_{i=1}^n l^{^*}_{\tau}(y_i, \hat y_i)
$$
当 $\tau = 0.5$ 时，这只是引出条件均值的通常平方损失。当 $\tau\ne 0.5$ 时，我不确定这样的损失函数会引发什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/636159/modification-of-square-loss-analogous-to-absolute-and-vs-pinball-loss-what-is-e</guid>
      <pubDate>Thu, 04 Jan 2024 17:25:44 GMT</pubDate>
    </item>
    <item>
      <title>cv2.imread 函数的问题</title>
      <link>https://stats.stackexchange.com/questions/636158/a-problem-with-cv2-imread-function</link>
      <description><![CDATA[我有一个目录，其中有两个子目录“Cat”和“Cat”。和“狗” ，每个都包含 14 个图像，我尝试编写一个 python 函数来从该文件夹中获取批量图像，我使用 cv2 读取图像并显示它们，这里是我的代码：
将 numpy 导入为 np
将张量流导入为 tf
导入操作系统
将 matplotlib.pyplot 导入为 plt
导入 matplotlib
导入CV2
d={}




folder_path =“/home/General_use/PycharmProjects/pythonProject1/hi”


def sort_files(files_names):
    对于文件名中的 i：
        n,a=i.split(“.”)

        d[i]=int(n)
    返回 dict(已排序(d.items(),key=lambda x:x[1])).keys()


def get_classes(文件夹路径):
     类=os.listdir(文件夹路径)
     返回类
def count_images(classes_name):
    图像数量=0
    对于classes_name中的k：
        对于 os.listdir(os.path.join(folder_path,k)) 中的 i：
            图像数量=图像数量+1

    返回图像数量

def get_batch(文件夹路径,batch_size):
    类中图像数量=0

    number_of_batches=count_images(get_classes(folder_path))//batch_size
    批次=[]
    开始=0
    对于 get_classes(“/home/General_use/PycharmProjects/pythonProject1/hi”) 中的 a：
        对于列表中的文件（sort_files（os.listdir（os.path.join（folder_path，a））））[开始：]：
            打印（文件）
            im=cv2.imread(os.path.join(folder_path,a,文件))
            cv2.imshow(“赢”, im)
            cv2.waitKey(1000)
            cv2.destroyWindow(“赢”)
            number_of_images_in_class+=1
            if number_of_images_in_class&gt;=batch_size//len(get_classes(folder_path)):
                休息
            批处理.append(im)
        类中图像数量=0
    start = start + batche_size // len(get_classes(folder_path))
    产量批次
    批次=[]

    print(&quot;下一批&quot;)
    类中图像数量 = 0
    对于 get_classes(folder_path) 中的 a：
        对于列表中的文件(sort_files(os.listdir(os.path.join(folder_path,a))))[0:]:
            打印（文件）
            im = cv2.imread(os.path.join(folder_path, a, file))
            打印（即时通讯）
            cv2.imshow(“win2”, im)
            cv2.waitKey(1000)
            cv2.destroyWindow(“win2”)
            类中图像数量 += 1
            if number_of_images_in_class &gt;= batche_size // len(get_classes(folder_path)):
                休息
            批处理.append(im)
        类中图像数量=0
    产量批次


批处理=get_batch(文件夹路径,4)


打印（下一个（批次））
print(&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;)
打印（下一个（批次））

第一批工作得很好，但对于第二批，我看到了这个错误：
´´´
下一批
0.jpg
无
[警告：0@4.414]全局loadsave.cpp：248 findDecoder imread_（&#39;/home/General_use /PycharmProjects/pythonProject1/hi/cat/0.jpg&#39;）：无法打开/读取文件：检查文件路径/完整性
回溯（最近一次调用最后一次）：
  文件“/home/General_use/.config/JetBrains/PyCharmCE2023.2/scratches/scratch.py​​”，第 77 行，在  中
    对于批次中的 y：
  文件“/home/General_use/.config/JetBrains/PyCharmCE2023.2/scratches/scratch.py​​”，第 63 行，在 get_batch 中
cv2.imshow(“win2”, im)
cv2.error: OpenCV(4.8.1) /io/opencv/modules/highgui/src/window.cpp:971: 错误: (-215:断言失败) size.width&gt;0 &amp;&amp;函数“imshow”中的 size.height&gt;0

´´´
问题与 cv2.imread 有关，在第一批中它可以正确读取图像，但在第二批中即使是相同的图像它也不会产生任何结果，那么为什么会发生这种情况？
请注意，我知道我应该对脚本进行大量改进，但现在我只专注于解决显示的错误。（专注于 get_batch 函数）]]></description>
      <guid>https://stats.stackexchange.com/questions/636158/a-problem-with-cv2-imread-function</guid>
      <pubDate>Thu, 04 Jan 2024 17:09:19 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程回归中未知数据的核选择</title>
      <link>https://stats.stackexchange.com/questions/636157/kernel-selection-for-unknown-data-in-gaussian-process-regression</link>
      <description><![CDATA[我是高斯过程回归 (GPR) 的新手。我最近的工作是用探地雷达对一些纵向数据进行建模。
到目前为止，我了解到 GPR 是高度灵活的非参数方法，内核决定了 GPR 模型的行为。然而，在纵向数据建模中，有时随着新观测的输入，数据行为可能会发生巨大变化。例如，令 $x_t$ 表示纵向随机变量 $x$ 在时间 $t$：
$x_0 = 1.2、x_1 = 2.1、x_2 = 3.9、x_3 = 2.2、x_4 = 0.9$
如果观察者仅从 $t = 0$ 到 $t = 2$ 进行观察，他们可能建议使用非周期性内核。观察到 $t=4$ 的观察者可能会得出使用周期性内核的结论。一个粗心的观察者只观察 $x_1$ 和 $x_3$ 甚至可能会说使用固定内核作为数据根本没有太大变化。
目前，我正在考虑使用不同内核的复合内核来解决这个问题，但如果有人能够提供一些更出色的解​​决方案的想法，我将不胜感激。
提前致谢！
P.S.：目前我主要在 Python 中使用 GPyTorch，但也很欣赏其他工具。]]></description>
      <guid>https://stats.stackexchange.com/questions/636157/kernel-selection-for-unknown-data-in-gaussian-process-regression</guid>
      <pubDate>Thu, 04 Jan 2024 17:04:03 GMT</pubDate>
    </item>
    <item>
      <title>过度离散混合广义线性模型</title>
      <link>https://stats.stackexchange.com/questions/636156/overdispersion-mixed-generalized-linear-model</link>
      <description><![CDATA[我正在运行混合广义线性模型来分析诱饵陷阱中的昆虫捕获情况。该实验由 3 个独立的笼子组成，每个笼子中放置一种处理（C+、C- 或 T）并放置 10 只昆虫。第二天，对每次处理中捕获的昆虫数量进行计数。我有一个实验系列，其中每个处理有 5 个重复（晚上）。我的模型是 mod1 &lt;- glmer(捕获/总计 ~ 治疗 + (1 | 试验)，家庭 = 二项式，权重 = 总计，数据 = data1)。在检查假设时，我得到的色散为 5.42，（色散 &lt;- sum(res^2) / df）。我尝试运行准泊松模型，离散度降至 0.7，但我发现很难用该模型解释结果。我还有另一个实验系列，有 8 个重复，离散值为 1.6。在这种情况下，我应该对该值给予多大的重视才能放弃二项式分布的模型？对于这两个系列，考虑到过度离散，使用准泊松进行此类分析是否正确？我应该使用负二项式模型吗？有没有一种方法可以比较不同分布系列的模型，以了解哪一个最适合？我理解ANOVA只是比较同族的模型。我很感谢您的回复。]]></description>
      <guid>https://stats.stackexchange.com/questions/636156/overdispersion-mixed-generalized-linear-model</guid>
      <pubDate>Thu, 04 Jan 2024 16:48:33 GMT</pubDate>
    </item>
    <item>
      <title>Cox 模型：极高的舍恩菲尔德残差</title>
      <link>https://stats.stackexchange.com/questions/636155/cox-model-extreemly-high-schoenfeld-residuals</link>
      <description><![CDATA[我已经运行了固定时间 Cox 模型（粗略和协变量调整）以获得二元曝光的效果。样本大小约为。 200,000，大约有。 10,000 个事件和 4000 个“是”曝光值。
我对缩放舍恩菲尔德残差的非常大的值感到担忧和困惑，请参阅下面的粗略模型图。非常高的值（幅度为 50+）似乎来自暴露的 (5) 和未暴露的 (50) 对象。

我使用 R 中的生存包中的 coxph() 函数拟合模型。我使用同一包中的 cox.zph() 函数和恒等变换来生成所示的图。]]></description>
      <guid>https://stats.stackexchange.com/questions/636155/cox-model-extreemly-high-schoenfeld-residuals</guid>
      <pubDate>Thu, 04 Jan 2024 16:45:19 GMT</pubDate>
    </item>
    <item>
      <title>广义矩量法的应用</title>
      <link>https://stats.stackexchange.com/questions/636154/application-of-the-generalized-method-of-moments</link>
      <description><![CDATA[教授给了我们一个练习，但对我来说并不完全清楚。
我有一个依赖于参数 x 的分布函数
我需要估计。该函数描述角度 y 的分布
我知道其中的一个样本 y1,..,yn。
为了估计 x，我们的教授告诉我们将样本分成小组（每组 3
或 4) .例如，我考虑 y1,y2,y3,y4。
使用这四种方法，我考虑使用最大似然法来获得 x 的估计值。
我们将从前 4 个样本获得的估计值称为 x1
z1 是 y1,y2,y3,y4 的平均值。
通过迭代此过程，我找到了估计参数 xi 的向量
以及一个带有小组 zi 平均值的向量。
之后我必须进行线性回归（我使用了R），因为最终目标是获得一个将x与均值z联系起来的公式，这是因为我们将样本分成了小组。
教授告诉我们，这或多或少是广义矩方法的应用，我们必须解释我们如何使用这种方法，但对我来说不太清楚，有人可以帮助我吗？
他说这不完全是矩量法的广义方法，但是我必须找到我所做的事情和GMM之间的关系。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/636154/application-of-the-generalized-method-of-moments</guid>
      <pubDate>Thu, 04 Jan 2024 16:42:04 GMT</pubDate>
    </item>
    <item>
      <title>边际结构模型根据时间分割产生不同的风险比</title>
      <link>https://stats.stackexchange.com/questions/636152/marginal-structural-model-yielding-different-hazard-ratios-depending-on-time-spl</link>
      <description><![CDATA[我正在使用边际结构建模方法来调整时间依赖性混杂因素，观察患病的风险。我在 R 中使用 tmerge 来解释与时间相关的变量，然后使用 ipwtm 创建权重，并将其输入到 Cox 模型中以计算风险比。然而，我注意到，当我还使用 survsplit 将数据切割成预先指定的间隔时，我会得到不同的总体风险比。除了时间分割之外，一切都一样。
我知道您可能有与时间相关的系数，但为什么总体风险比会受到数据分割程度的影响？也许我忽略了一些事情。]]></description>
      <guid>https://stats.stackexchange.com/questions/636152/marginal-structural-model-yielding-different-hazard-ratios-depending-on-time-spl</guid>
      <pubDate>Thu, 04 Jan 2024 16:35:38 GMT</pubDate>
    </item>
    <item>
      <title>确定样本集的有效索引</title>
      <link>https://stats.stackexchange.com/questions/636150/determining-an-efficient-index-on-sample-sets</link>
      <description><![CDATA[上下文：我有一个不断增长的样本数据集。 （目前它由大约 $500$ 个样本组成。）该集中的每个样本都是一个 $m \times 3$ 矩阵，其中 $m$ 行代表 $m$ 个不同的测量站点 每行包含一个在该站点测量的 $3$ 维向量。所有样品均使用相同的测量部位。网站数量 $m$ 也在 $500$ 左右。由于测量站点具有一定的逻辑空间分布，因此预计附近站点的测量结果将是相关的。
问题：我想确定一个好的“索引”这样，给定一个新样本，该索引有助于在给定集合中找到附近的样本。 （最接近的值不是必需的，也不是预期的。）这个想法是确定 $m$ 测量值的一个小子集站点，仅在此子集进行测量就足够了。 （由于测量不是免费的，因此最好对索引使用尽可能少的测量位置。）然后可以在这个有限集合上使用某种空间数据结构（例如，R 树或 kd 树）来定位附近的样本测量值。作为一个极端的例子和动机：假设所有样本在两个测量站点的测量结果都是相同的，那么显然该索引中不需要这两个站点。
问题：您将如何确定一个好的索引？简单地尝试所有可能的集合并通过某种交叉验证方法选择一个集合不会很好地扩展。到目前为止我的方法：
&lt;块引用&gt;
美白每个测量部位的样品。将每个样本展平为单个 $3m$ 维向量。使用 PCA 查找可捕获样本中大部分变化的 $m&#39;$ 个组件。然后选择 $m&#39;&#39;$（至少 $m&#39;/3$）测量站点，以便这些站点上的投影最接近 PCA 提供的 $m&#39;$ 组件上的投影。

此外，诸如多变量 CCA 之类的东西似乎在某种程度上相关，但目前我不知道如何（甚至不知道哪个版本的 CCA）适用于这个问题。建议或指示将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/636150/determining-an-efficient-index-on-sample-sets</guid>
      <pubDate>Thu, 04 Jan 2024 16:23:06 GMT</pubDate>
    </item>
    <item>
      <title>在分析“最多选择 X 项”调查结果时如何表述此问题</title>
      <link>https://stats.stackexchange.com/questions/636147/how-to-formulate-this-problem-when-analysing-choose-up-to-x-items-survey-resul</link>
      <description><![CDATA[我有这些来自我公司营销团队的调查结果。该调查有几个问题，您可以从列表中选择最多 3 或 5 个项目。我不知道此类问题的名称，并且很高兴了解更多信息。
我们将结果绘制在条形图中，我很清楚列表中的某些项目是最喜欢的，而有些则不是。但是，有大量项目可能位于一个我不太清楚它们是否具有“统计显着性”的区域。 - 如果这是此类调查中的一个问题。
在我当前的表述中，一个项目将映射到我们必须开发的功能或功能集，因此与回报相关联。我假设回报是选择该特定项目的用户数量的函数。为了使我的表述简单明了，我假设它与选择该项目的人数成正比。
我想要了解的是，确定预计回报率高于平均水平的项目的好方法是什么 - 再次，以“统计显着性”的方式确定回报率高于平均水平的项目。感觉 - 很像一个独臂强盗问题。我正在尝试了解有关一般调查的更多信息，并且我想澄清你们中的任何人如何更好地制定本次调查的分析，或者是否有任何特定的测试或统计数据可以用来分析它。]]></description>
      <guid>https://stats.stackexchange.com/questions/636147/how-to-formulate-this-problem-when-analysing-choose-up-to-x-items-survey-resul</guid>
      <pubDate>Thu, 04 Jan 2024 15:37:20 GMT</pubDate>
    </item>
    <item>
      <title>原始模型输出或模型预测的敏感性分析？</title>
      <link>https://stats.stackexchange.com/questions/636146/sensitivity-analysis-for-raw-model-output-or-model-predictions</link>
      <description><![CDATA[由于多种原因，许多研究人员建议，在尝试使用非线性统计模型进行因果推断时，通常应避免对原始模型输出赋予因果解释（心情 2009&lt; /a&gt;，Daniel 等人。2020，诺顿等人。2019，Long 和 Mustillo 2018）。相反，模型预测可用于评估给定治疗的因果效应（假设识别假设成立）。
获得模型预测的一种流行策略是估计边际效应。然而，即使在估计边际效应之后，观察性研究的估计边际效应本身并不表明因果关系。引起怀疑的罪魁祸首是未经调整的混杂因素可能使边际效应估计产生偏差。
因此，敏感性分析是提供可信度或进一步怀疑给定估计的关键工具。我相当熟悉  开发的敏感性分析西内利等人。 2020 和McGowan 2022。然而，这些敏感性分析检查给定的系数、比率等在一组假设下会发生多大的变化。但是，如果我对模型的原始输出不感兴趣，那么我首先应该在多大程度上关心这样的系数、比率等的敏感性？或者对原始模型输出的敏感性是否类似于模型预测（例如平均边际效应）的敏感性（对未指定混杂的敏感性）？]]></description>
      <guid>https://stats.stackexchange.com/questions/636146/sensitivity-analysis-for-raw-model-output-or-model-predictions</guid>
      <pubDate>Thu, 04 Jan 2024 15:31:06 GMT</pubDate>
    </item>
    <item>
      <title>线性回归中的二次项</title>
      <link>https://stats.stackexchange.com/questions/636142/quadratic-terms-in-linear-regression</link>
      <description><![CDATA[我制作回归模型已经有一段时间了，我对 $$y = \beta_0 +\beta_1x^2 \text{ 是线性的并且} y =\beta_0 +\beta_1^2x \text{ 不是}$$
但我一直不明白为什么会这样。在我看来，我们假设 $\beta_1$ 是一个固定数字，那么为什么我们不能直接说 $ \beta_{new} = \beta_1^2$ 并从那里开始。另外，什么时候我会出现二次回归系数？总的来说，我真的很好奇为什么这很重要。]]></description>
      <guid>https://stats.stackexchange.com/questions/636142/quadratic-terms-in-linear-regression</guid>
      <pubDate>Thu, 04 Jan 2024 15:05:59 GMT</pubDate>
    </item>
    <item>
      <title>异方差趋势回归中的 OLS 与 WLS</title>
      <link>https://stats.stackexchange.com/questions/636135/ols-vs-wls-in-a-heteroskedastic-trending-regression</link>
      <description><![CDATA[假设我们有以下异方差趋势回归模型：$$y_i=bi+a_i u_i$$ 对于一些非零常数序列$a_i$ 和 $u_i$ 是一个 i.i.d.均值 0 和方差 1 随机变量的序列。我想找到 OLS 和不可行的 WLS 估计器的渐近分布并比较它们的效率。
为此，我计算了两个渐近分布的归一化常数。我使用 Lindeberg-Feller CLT 并假设相关的 Grenander 条件成立。我计算 $\hat{b}_{OLS}$ 和 $\hat{b}_{WLS} $, $$\left(\sum_{i=1}^n i^2\right)\left(\sum_{i=1}^n a_i^2 i^2\right)^{-1/2}(\hat{b}_{OLS}-b)\xrightarrow{d} N(0,1)$$
$$\left(\sum_{i=1}^n i^2\right)\left(\sum_{i=1}^n \frac{i^2}{a_i ^2} \right)^{-1/2}(\hat{b}_{WLS}-b)\xrightarrow{d} N(0,1)$$
但是，我认为这一定是不正确的，因为我不明白为什么 WLS 一定比 OLS 估计器更有效。我认为在某些情况下，任一标准化都较大，这意味着任一估计器在不同情况下都可能有效。例如，我认为这些意味着如果 $a_i&gt;1$ 对于所有 $i$ 则 WLS效率更高，但如果 $a_i&lt;1$ 对于所有 $i$ 则 OLS 效率更高.
我的计算有问题吗？我希望 WLS 更加高效，但看不出我的工作中出现了错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/636135/ols-vs-wls-in-a-heteroskedastic-trending-regression</guid>
      <pubDate>Thu, 04 Jan 2024 14:36:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么大量的审查在生存分析中是不好的？</title>
      <link>https://stats.stackexchange.com/questions/636114/why-is-large-amounts-of-censoring-bad-in-survival-analysis</link>
      <description><![CDATA[我试图理解为什么大量的审查（即许多患者被审查）在生存分析中是不可取的。
作为概念证明，假设有 5 名患者：

患者 1 在 t1 发生事件
患者 2 在 t2 发生事件
患者 3 在 t3 时退出研究
患者 4 在 t4 发生事件
当研究在 t5 结束时，患者 5 没有发生该事件

（半参数方法）这是我在这种情况下尝试编写 Cox-PH 回归的模型和可能性：
$$ h(t|X) = h_0(t) \exp(\beta^T X) $$
$$ L(\beta) = \prod_{i: \delta_i = 1} \frac{h(t_i|X_i)}{\sum_{j: t_j \geq t_i} \ exp(\beta^T X_j)} $$
$$ L(\beta) = \frac{h(t_1|X_1)}{\sum_{j: t_j \geq t_1} \exp(\beta^T X_j)} \次\frac{h(t_2|X_2)}{\sum_{j: t_j \geq t_2} \exp(\beta^T X_j)} \次\frac{h(t_4|X_4)}{\sum_{j: t_j \geq t_4} \exp(\beta^T X_j)} $$
$$ L(\beta) = \frac{h(t_1|X_1)}{\exp(\beta^T X_1) + \exp(\beta^T X_2 ) + \exp(\beta^T X_3) + \exp(\beta^T X_4) + \exp(\beta^T X_5)} \times \frac{h(t_2|X_2)}{\exp(\beta ^T X_2) + \exp(\beta^T X_3) + \exp(\beta^T X_4) + \exp(\beta^T X_5)} \times \frac{h(t_4|X_4)}{\exp (\beta^T X_3) + \exp(\beta^T X_5)} $$
（参数方法）这是我在这种情况下尝试编写 AFT 模型的模型和可能性：
$$ \log(T) = \mu + \sigma \beta^TX + \epsilon $$
$$ L(\mu, \sigma, \beta) = \prod_{i=1}^{n} \left[ \frac{1}{\sigma} f\left( \frac{\log(t_i) - \mu - \beta^T X_i}{\sigma} \right) \right]^{\​​delta_i} \left[ 1 - F\left( \frac{\ log(t_i) - \mu - \beta^T X_i}{\sigma} \right) \right]^{1-\delta_i} $$
$$ L(\mu, \sigma, \beta) = \left[ \frac{1}{\sigma} f\left( \frac{\log(t_1) ) - \mu - \beta^T X_1}{\sigma} \right) \right] \times \left[ \frac{1}{\sigma} f\left( \frac{\log(t_2) - \mu - \beta^T X_2}{\sigma} \right) \right] \times \left[ 1 - F\left( \frac{\log(t_3) - \mu - \beta^T X_3}{\sigma} \right) \right] \times \left[ \frac{1}{\sigma} f\left( \frac{\log(t_4) - \mu - \beta^T X_4}{\sigma} \right) \右] \times \left[ 1 - F\left( \frac{\log(t_5) - \mu - \beta^T X_5}{\sigma} \right) \right] $$
因此，在 Cox-Ph 和 AFT 模型中，推理（例如，可能会导致高方差、高偏差、不一致性、较大的样本量以实现比较结果与较小的样本量和较少的审查）和参数估计如何当大量患者受到审查时会产生负面影响吗？数学优化是否变得困难（例如，矩阵秩不完整、矩阵逆未定义、模型不可识别）？]]></description>
      <guid>https://stats.stackexchange.com/questions/636114/why-is-large-amounts-of-censoring-bad-in-survival-analysis</guid>
      <pubDate>Thu, 04 Jan 2024 06:08:48 GMT</pubDate>
    </item>
    <item>
      <title>估计不良行为者的数量</title>
      <link>https://stats.stackexchange.com/questions/636104/estimate-number-of-bad-actors</link>
      <description><![CDATA[这可能是一个愚蠢的问题，但它让我难住了。我正在尝试估计系统中不良行为者的数量。
假设我们有 100 个用户，其中一定比例的用户是不良行为者。在我们的系统中，用户正在生成剪辑，假设每个人平均生成 100 个剪辑。不良演员在一定比例的情况下会生成不良剪辑。我想知道有多少坏人。
从我们的数据库中采样剪辑以估计有多少不良演员的最有效方法是什么？我可以随机抽取 100 个剪辑并计算出不良演员的百分比吗？
&lt;小时/&gt;
我已经尝试过这个问题好几次了，但我总是被这样一个事实所困扰：你不知道坏演员会生成的剪辑的分布。我不知道如何克服这个问题并通过采样生成准确的估计。您是否首先需要找到不良演员，并计算他们可能生成的不良剪辑的百分比？]]></description>
      <guid>https://stats.stackexchange.com/questions/636104/estimate-number-of-bad-actors</guid>
      <pubDate>Thu, 04 Jan 2024 00:37:47 GMT</pubDate>
    </item>
    </channel>
</rss>