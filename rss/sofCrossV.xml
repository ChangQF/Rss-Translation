<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 08 Mar 2024 00:56:46 GMT</lastBuildDate>
    <item>
      <title>按患者进行随机森林交叉验证</title>
      <link>https://stats.stackexchange.com/questions/642111/random-forest-cross-validaton-by-patient</link>
      <description><![CDATA[我有一个包含 10 名患者和 10 名对照者的各种特征的数据集。每个患者都有很多数据点。
当使用随机 70%-30% 训练测试分割或 10 K 折叠交叉验证时，随机森林在预测数据点是来自患者还是来自对照方面表现出色。
然后我意识到这是因为部分训练数据和测试数据重叠。也就是说，训练集中的一些数据点来自患者A，当然用这个模型来预测患者A自己的数据时，它是非常准确的。
我尝试按患者拆分数据并使用“LOOCV”，每次留下一名患者作为测试集。但是，当我这样做时，随机森林模型无法运行，因为在测试集中只有一个类别（即“患者”，并且没有“对照”）。
我使用R
rftrain &lt;- randomForest(group ~ person_id + 许多其他功能，
                    数据 = 火车，localImp = TRUE）

# 使用测试数据进行 Pyellowictive 模型评估
混乱 &lt;- 混乱矩阵（预测（rftrain，测试），测试$组，阳性=“患者”）
困惑

是否有更好的包或更好的方法来进行此评估？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642111/random-forest-cross-validaton-by-patient</guid>
      <pubDate>Fri, 08 Mar 2024 00:49:13 GMT</pubDate>
    </item>
    <item>
      <title>k 个最近邻的贝叶斯误差的渐近上限</title>
      <link>https://stats.stackexchange.com/questions/642109/assymptotic-upper-bound-of-k-nearest-neighbors-in-terms-of-bayes-error</link>
      <description><![CDATA[假设 p 是贝叶斯误差，而 $P_{3-nn}$ 是我们需要的 3-nn 的误差证明 3-nn 的上限是
$$
P_{3-nn} &lt;= p(1-p)(4p-p^2+1)
$$
我可以在各种文本中找到 1-nn 的渐近上限由 $2p$ 给出，
因此，我尝试使用组合逻辑，如下所示：
假设对于 3-nn 有以下情况：

所有 3 个都被正确预测：错误为：$p$，因为这是最小错误。
2 再次被正确预测：错误将是 $p$
预测错误 2：$^3C_2 * (1-p)*p^2$
所有 3 个预测均错误：$p^3$

但我不知道如何继续，甚至不知道如何在最终结果中得到 4 的幂，并且我不知道如何将这些结合起来。]]></description>
      <guid>https://stats.stackexchange.com/questions/642109/assymptotic-upper-bound-of-k-nearest-neighbors-in-terms-of-bayes-error</guid>
      <pubDate>Fri, 08 Mar 2024 00:28:12 GMT</pubDate>
    </item>
    <item>
      <title>混合效应逻辑回归模型</title>
      <link>https://stats.stackexchange.com/questions/642108/mixed-effect-logistic-regression-model</link>
      <description><![CDATA[我对统计世界非常陌生，我需要一些帮助。我目前正在做一个实验，我必须分析数据，但老实说我对统计学一无所知（我曾尝试参加大学的一些课程，但它们只涉及描述性统计；我从有些书，但在很多情况下，很难找到真正的入门课程）。然而，根据我所了解到的情况，我了解到我需要运行混合效应逻辑回归模型。我有一个二元因变量（是/否）和不同的预测变量：

group_age（分为三个级别：20、30、40）
偏好（有两个级别：a、b）
季节（有两个级别：夏季、冬季）
天气（分两个级别：晴天、雨天）

作为随机效果，我有 id 和项目编号（每个参与者有 25 个 obs，并且所有项目都是相同的）。
如何选择正确的型号？在我的预测中，因变量受到 group_age、季节和天气以及季节和天气之间相互作用的影响。相反，我不认为变量偏好会影响结果，但我想对此进行控制。
是否可以使用 RStudio 中的包 glmulti 来找到正确的模型？我读过有关比较某些指数（例如 BIC 和 AIC）的必要性。但一般来说，例如，模型的 BIC 值是多少？例如，BIC 2700 是否太高？如果不同型号共享相同的 BIC/AIC 怎么办？
运行模型后，什么应该包含完整的统计分析？
对于这些愚蠢的问题，我真的很抱歉，但我认为一步一步地对段落进行阐述会对我有很大帮助，因为我没有“方法论”。 （或者我不知道在哪里可以学到它）。
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/642108/mixed-effect-logistic-regression-model</guid>
      <pubDate>Fri, 08 Mar 2024 00:10:42 GMT</pubDate>
    </item>
    <item>
      <title>根据查找事件的概率查找事件日期</title>
      <link>https://stats.stackexchange.com/questions/642106/find-event-date-given-the-probabilities-of-finding-an-event</link>
      <description><![CDATA[我有一组临床记录，其中包含每位患者的日期和一个 NLP 模型，该模型对记录中存在的特定事件给出 0.0 到 1.0 之间的分数。根据分数，确定事件发生日期的最佳方法是什么。
基本思想是，一旦事件发生，我们将在后续访问期间看到它至少在一段时间内被提及。
一种简单的方法是采用我们看到高概率的第一个日期，但鉴于基础数据不是很好，如果这样做，我们会失去一些精度。另一方面，我们只考虑具有多个高概率注释的患者，然后我们会错过一些可能是新患者且注释较少的患者。]]></description>
      <guid>https://stats.stackexchange.com/questions/642106/find-event-date-given-the-probabilities-of-finding-an-event</guid>
      <pubDate>Thu, 07 Mar 2024 23:51:51 GMT</pubDate>
    </item>
    <item>
      <title>pyimagesearch.com - 反向传播算法。在构建三角洲链时到底发生了什么？</title>
      <link>https://stats.stackexchange.com/questions/642105/pyimagesearch-com-backpropagation-algorithm-what-is-happening-exactly-when-bu</link>
      <description><![CDATA[在教程提供的代码中，您可以找到以下行：
delta = np.matmul(D[-1], self.W[层].T) * self.sigmoid_derivative(A[层])

这一行是算法中最让我困惑的部分。根据链式法则，这条线应该具有以下外观： ∂C/∂a1 * ∂a1/∂a0 * ∂a0/w0 ...但事实并非如此。它直接乘以权重矩阵，而不是与另一个导数。更具体地说，是对权重矩阵进行转置。我根本不知道这里发生了什么。据我理解，它实际上应该看起来像： delta = D[-1] * self.sigmoid_derivative(A[layer])
这对我来说才有意义。我不明白权重矩阵作为一个术语在那里做什么。而且特别是为什么它被转置。]]></description>
      <guid>https://stats.stackexchange.com/questions/642105/pyimagesearch-com-backpropagation-algorithm-what-is-happening-exactly-when-bu</guid>
      <pubDate>Thu, 07 Mar 2024 23:32:13 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Python包“fastkde”来预测每个给定数据点的密度？</title>
      <link>https://stats.stackexchange.com/questions/642104/how-to-use-python-package-fastkde-to-predict-density-at-each-given-data-point</link>
      <description><![CDATA[我正在尝试使用 包 fastkde 来估计样品的密度。作者举了一个例子
&lt;前&gt;&lt;代码&gt;“”“”演示第一个 README 示例。 ”“”
将 numpy 导入为 np
导入fastkde
将 matplotlib.pyplot 导入为 plt

#生成两个随机变量数据集（代表100,000对数据点）
N = int(1e5)
x = 50*np.random.normal(大小=N) + 0.1
y = 0.01*np.random.normal(大小=N) - 300

#进行自洽密度估计
PDF = fastkde.pdf(x, y, var_names = [&#39;x&#39;, &#39;y&#39;])

PDF.plot();

就我而言，我有一个包含 100,000 个观察值的示例 z。我想预测 w 中每个数据点的密度：
将 numpy 导入为 np
导入fastkde

N = int(1e5)
z = 50*np.random.normal(大小=N) + 0.1
w = 列表(范围(10, 0, -2))

您能详细说明一下如何做到这一点吗？非常感谢您的详细阐述！]]></description>
      <guid>https://stats.stackexchange.com/questions/642104/how-to-use-python-package-fastkde-to-predict-density-at-each-given-data-point</guid>
      <pubDate>Thu, 07 Mar 2024 22:40:23 GMT</pubDate>
    </item>
    <item>
      <title>Prophet 算法是否需要假期的历史数据来预测未来的假期？</title>
      <link>https://stats.stackexchange.com/questions/642102/does-prophet-algorithms-need-historical-data-with-holidays-to-foreacast-predicti</link>
      <description><![CDATA[我计划使用 Prophet 算法进行预测，因为它似乎非常适合季节性数据。
我正在专门阅读这篇有关假期影响的文章 https:/ /facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html
我想使用holidays来确保模型针对假期进行调整。
我的问题：我需要提供包含假期的历史数据吗？
例如，如果我的训练数据来自 2023 年 10 月至 12 月，我想对 1 月进行预测并确保针对 2024 年 1 月 3 日的年度假期进行调整。考虑到没有 2023 年 1 月的训练数据，这是否可能2023 年 1 月 3 日？
如果有人可以帮助我理解这一点 - 我将非常感激！谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642102/does-prophet-algorithms-need-historical-data-with-holidays-to-foreacast-predicti</guid>
      <pubDate>Thu, 07 Mar 2024 21:57:02 GMT</pubDate>
    </item>
    <item>
      <title>应该使用什么方法来比较不同GAM的拟合度？</title>
      <link>https://stats.stackexchange.com/questions/642101/what-method-should-be-used-to-compare-fit-of-different-gams</link>
      <description><![CDATA[我正在构建以下形式的 GAM（使用 R 的 mgcv 表示法），并希望比较每个模型之间的拟合度。
model1 &lt;- gam(dependent_var ~ metric +
                             s(纬度,经度) +
                             s(单位, bs = &#39;re&#39;),
                             数据 = df)
model2 &lt;- gam(dependent_var ~ metric2 +
                             s(纬度,经度) +
                             s(单位, bs = &#39;re&#39;),
                             数据 = df)

我通常会考虑使用 AIC 或 LRT 来比较拟合度，但请注意，模型之间的差异仅是 metric 和 metric2，即模型是不是彼此的截断版本。
我考虑过的另一个选择是构建训练和测试数据集，并比较测试数据集中的残差总和以比较拟合度。是否有正确的方法来使用两个未截断的 GAM 来比较拟合度？]]></description>
      <guid>https://stats.stackexchange.com/questions/642101/what-method-should-be-used-to-compare-fit-of-different-gams</guid>
      <pubDate>Thu, 07 Mar 2024 21:43:44 GMT</pubDate>
    </item>
    <item>
      <title>在线性混合模型中导出 $\sigma_{\epsilon}^2$、$\beta$ 和 $Q$ 的 MLE</title>
      <link>https://stats.stackexchange.com/questions/642099/deriving-mles-for-sigma-epsilon2-beta-and-q-in-a-linear-mixed-mode</link>
      <description><![CDATA[我目前正在研究一个涉及以下形式的线性混合模型的问题：
$Y_i = X_i \beta + Z_i b_i + \epsilon_i,$
其中 $\epsilon_i \sim N (0, \sigma_{\epsilon}^2 I_{Ji})$。该模型也可以表示为：
$V_i = Z_i GZ_i^T + \sigma_{\epsilon}^2 I_{Ji} = \sigma_{\epsilon}^2 (I_{Ji} + Z_i QZ_i ^T),$
与$Q = G/\sigma_{\epsilon}^2$。
我正在尝试推导：
a. $\hat{\sigma}_{\epsilon}^2$ 的最大似然估计的显式表达式sigma_{\epsilon}^2$ 表示为 $\beta$ 和 $Q$.
b. $\hat{\beta}$ 和 $\hat{Q}$ 的目标函数是不含 $\sigma_{\epsilon}^2$，使用 $\hat{\sigma}_{ 的表达式对数似然（轮廓似然）中的 \epsilon}^2$。
c.证明 $\beta$ 的最大似然估计满足：
$\hat{\beta} = \left( \sum_{i=1}^{n} X_i^T H_i^{-1} X_i \right)^{ -1} \left( \sum_{i=1}^{n} X_i^TH_i^{-1} Y_i \right),$
其中$H_i = (I_{Ji} + Z_i QZ_i^T)$。
我尝试用 $Q$ 和 $\sigma_{\epsilon 重新表达似然函数}^2$，考虑到重新参数化，但我不确定如何继续进行显式推导。
有人可以指导我完成推导或提供解决这些问题的见解吗？任何对类似示例或文献的引用也将受到高度赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/642099/deriving-mles-for-sigma-epsilon2-beta-and-q-in-a-linear-mixed-mode</guid>
      <pubDate>Thu, 07 Mar 2024 20:36:51 GMT</pubDate>
    </item>
    <item>
      <title>OLS 回归中的变量构造</title>
      <link>https://stats.stackexchange.com/questions/642098/variable-construction-in-ols-regression</link>
      <description><![CDATA[我有国家/地区的时间序列数据，并且有一个变量，该变量在一个国家/地区的所有年份编码为 1，在另一个国家/地区的所有年份编码为 0。有什么方法可以将该变量包含在 OLS 回归模型中吗？非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/642098/variable-construction-in-ols-regression</guid>
      <pubDate>Thu, 07 Mar 2024 20:24:53 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么指标来比较概率预测任务上的多类分类器？</title>
      <link>https://stats.stackexchange.com/questions/642096/what-metrics-should-i-use-to-compare-multiclass-classifiers-on-probability-predi</link>
      <description><![CDATA[我有一个平衡的数据集，其中每个对象（歌曲）都有四个目标类标签之一（歌曲的情绪）。示例：

&lt;标题&gt;

ID
功能1
功能2
功能3
目标类


&lt;正文&gt;

0
0.5
0.11
125
乐观


1
0.23
0.75
136
悲伤



数据集有一些异常值，我决定不删除它们，因为它们不是测量误差。我想预测每个对象属于四个类别中每个类别的概率，例如：

&lt;标题&gt;

ID
乐观
悲伤
精力充沛
放松


&lt;正文&gt;

0
0.75
0.13
0.5
0.7


1
0.2
0.65
0.03
0.12



我计划在未知数据上使用这个分类器来构建音乐数据库。我想要预测概率的原因是，用户在数据库中搜索音乐时，可以在四种情绪之间进行选择，而不是选择四种情绪中的一种。
我想比较几个分类器，以便选择最适合此任务的分类器。到目前为止我决定比较随机森林、XGBoost、LightGBM、CatBoost。我正在使用 Optuna 来调整超参数，优化 LogLoss（这是正确的方法吗？）。调整超参数后，我还使用 sklearn CalibrateClassifierCV 在预拟合模型上执行等渗和逻辑校准。在评估了所有这些模型后，我一直在思考如何选择最好的模型。我正在计算LogLoss、AUC-ROC、Brier 分数和 ECE。 模型评估后我是否应该考虑 LogLoss？ AUC-ROC 和 Brier 分数比 ECE 更重要吗？ 经过几次评估后，逻辑校准后的随机森林似乎倾向于使用 AUC-ROC 和 LogLoss 给出最佳结果，而等渗随机森林或未校准的 XGBoost 往往会给出最佳结果。以获得更好的 Brier 分数。在比较除等渗校准后的 ECE 之外的所有这些指标时，CatBoost 往往表现最差。这些结果出乎我的意料，我确信 RandomForest 会优于所有其他模型，而 CatBoost 也会优于所有其他模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/642096/what-metrics-should-i-use-to-compare-multiclass-classifiers-on-probability-predi</guid>
      <pubDate>Thu, 07 Mar 2024 19:57:28 GMT</pubDate>
    </item>
    <item>
      <title>估计不规则更新时间序列的协方差矩阵</title>
      <link>https://stats.stackexchange.com/questions/642093/estimating-covariance-matrix-of-irregularly-updated-time-series</link>
      <description><![CDATA[我想估计一组不定期更新的时间序列的收益协方差矩阵。准确地说，就我而言，所有系列都分为两类。 A 类每天更新一次，B 类每隔几天更新一次（但全部同时更新）。基本假设是实际的隐藏变量是多维随机游走，但某些变量仅在某些时间点显示。是否有对此类数据进行建模的标准方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/642093/estimating-covariance-matrix-of-irregularly-updated-time-series</guid>
      <pubDate>Thu, 07 Mar 2024 19:03:17 GMT</pubDate>
    </item>
    <item>
      <title>如何训练和测试分割不平衡的数据集？</title>
      <link>https://stats.stackexchange.com/questions/642085/how-do-you-train-test-split-an-imbalanced-dataset</link>
      <description><![CDATA[我有一个不平衡的数据集，我正在尝试预测二进制目标。少数类别约占所有观测值的 0.4%（6000 万个观测值，其中 25 万属于少数类别）。
我对多数类进行了欠采样，并对少数类进行了过采样，因此我的目标列的平均值现在为 23%。训练测试分割这个平衡数据集是否正确？
换句话说，我应该：

重新平衡后，train-test 分割数据；或
分配原始数据集的子集用于测试、分配原始数据集的子集用于训练并重新平衡训练数据集？
]]></description>
      <guid>https://stats.stackexchange.com/questions/642085/how-do-you-train-test-split-an-imbalanced-dataset</guid>
      <pubDate>Thu, 07 Mar 2024 17:56:48 GMT</pubDate>
    </item>
    <item>
      <title>通过结构方程建模获得简单单变量回归的 R 平方等价物</title>
      <link>https://stats.stackexchange.com/questions/642026/getting-an-equivalent-of-r-squared-for-simple-univariate-regression-done-with-st</link>
      <description><![CDATA[我需要计算一个非常简单的回归模型结果〜预测器。为了处理缺失，我必须使用 FIML 并且还需要引导。由于 R 中的 lavaan 包提供了这两种功能，因此我使用了以下代码：
模型 &lt;- sem(&#39;结果 ~ 预测器&#39;, data = data, Missing = &quot;FIML&quot;, se=&quot;BOOTSTRAP&quot;, bootstrap = 2000,fixed.x = F)
摘要（模型）

不幸的是，在这种结构方程建模方法中，没有 $R^2$ 或调整的 $R^2$&lt; /span&gt; 在输出中可用。有人能告诉我如何获得表明效应大小的等效度量吗？
是否有比使用 lavaan 更简单的方法来为单变量回归提供 FIML、引导和效应大小输出？那就更好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/642026/getting-an-equivalent-of-r-squared-for-simple-univariate-regression-done-with-st</guid>
      <pubDate>Thu, 07 Mar 2024 02:44:45 GMT</pubDate>
    </item>
    <item>
      <title>如何导出协变量平衡倾向得分的 GMM 估计量？</title>
      <link>https://stats.stackexchange.com/questions/641993/how-to-derive-the-gmm-estimator-for-the-covariate-balancing-propensity-score</link>
      <description><![CDATA[Imai 和 Ratkovic (2014) 描述的协变量平衡倾向得分 (CBPS) 涉及使用倾向得分 $\pi_\beta(\mathbf{X}) = P(T = 1\vert\mathbf{X})$ 拟合逻辑回归广义矩方法 (GMM)，使用协变量平衡矩条件来增强逻辑回归的常用矩条件。由于矩条件比要估计的参数多（两倍），系统被过度识别。
以下是 Imai 和 Ratkovic 定义该方法的方式（此处针对平均治疗效果 [ATE]）：
由 $p$ 索引的每个系数的逻辑回归得分条件为
$$s_{\beta_p}(T, \mathbf{X}) = (T - \pi_\beta(\mathbf{X})) X_p$$
平衡力矩条件为
$$w_{\beta_p}(T, \mathbf{X}) = \frac{T - \pi_\beta(\mathbf{X})}{\pi_\beta( \mathbf{X})(1 - \pi_\beta(\mathbf{X}))} X_p$$
当我们叠加这些时，我们得到 GMM 矩条件：
$$g_\mathbf{\beta}(T, \mathbf{X}) = \left(\array{s_{\beta_p}(T, \mathbf{X}) \ \w_{\beta_p}(T, \mathbf{X})} \right)$$
和
$$\bar{g}_\mathbf{\beta}(T, \mathbf{X}) = \frac{1}{N}\sum_{i = 1}^ N{g_\mathbf{\beta}(T_i, \mathbf{X}_i)}$$
他们估计 $\hat{\beta}$ 为
$$\hat{\beta} = \mathop{\arg \min}\limits_{\beta} \bar{g}_\mathbf{\beta}(T, \mathbf {X})^T \Sigma_\beta (T, \mathbf{X})^{-1} \bar{g}_\mathbf{\beta}(T, \mathbf{X})$$
他们使用
$$
\Sigma_\beta (T, \mathbf{X}) = \frac{1}{N}\sum_{i = 1}^N \left(\array{
\pi_\beta(\mathbf{X})(1-\pi_\beta(\mathbf{X}))X_iX_i^T &amp; X_i X_i^T \\
X_i X_i^T &amp; \frac{X_i X_i^T}{\pi_\beta(\mathbf{X})(1-\pi_\beta(\mathbf{X}))}
} \正确的）
$$
我的问题是 $\Sigma_\beta (T, \mathbf{X})$ 的这个表达式是如何导出的？ 他们声称
&lt;块引用&gt;
我们发现该协方差估计量优于矩条件的样本协方差，因为后者不会惩罚大权重。

这似乎与通常的高效 GMM 权重矩阵不同，我认为它是
$$
\Sigma_\beta (T, \mathbf{X}) = \frac{1}{N}\sum_{i = 1}^Ng_\mathbf{\beta}(T_i, \mathbf{X}_i)g_\mathbf {\beta}(T_i, \mathbf{X}_i)^T
$$
但我发现这两者并不相等。那么这个公式从何而来呢？
更新
我通过实验发现$$
\Sigma_\beta (T, \mathbf{X}) = -\frac{1}{N}\sum_{i = 1}^Ng_\mathbf{\beta}(1, \mathbf{X}_i)g_\ mathbf{\beta}(0, \mathbf{X}_i)^T
$$
这是一条线索！此外，根据 @Pusto 的评论，作者指出派生表达式是通过“整合”处理变量 $T_i$ 以预处理协变量为条件找到的$X_i$”。我仍然不清楚这种积分应该如何工作，但我认为可能可以使用此描述推导出他们的估计量。]]></description>
      <guid>https://stats.stackexchange.com/questions/641993/how-to-derive-the-gmm-estimator-for-the-covariate-balancing-propensity-score</guid>
      <pubDate>Wed, 06 Mar 2024 19:11:04 GMT</pubDate>
    </item>
    </channel>
</rss>