<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 15 Aug 2024 09:16:00 GMT</lastBuildDate>
    <item>
      <title>对列联表进行卡方检验，检验的两个参数的输入相同</title>
      <link>https://stats.stackexchange.com/questions/652848/chi-square-test-on-contingency-tables-with-same-input-for-both-arguments-of-the</link>
      <description><![CDATA[在这里，我在 R 中运行卡方检验，在列联表中有两组观察到的计数，其中零假设是它们来自同一分布。
# 创建对数正态分布数据
set.seed(0,kind=&quot;Mersenne-Twister&quot;)
a &lt;- 0
b &lt;- 100
r1 &lt;- (b-a) * round(rlnorm(1000,1,1)) + a
r2 &lt;- (b-a) * round(rlnorm(1000,.88,1.1)) + a
## 将创建的数据放入 20 个箱中
r1b &lt;- cut(r1,breaks=20)
r2b &lt;- cut(r2,breaks=20)
## 获取每个级别的计数
r1bs &lt;- summary(r1b)
r2bs &lt;- summary(r2b)
## 执行列联表检验
chisq.test(r1bs,r2bs)

结果如下：
&gt; chisq.test(r1bs,r2bs)

皮尔逊卡方检验

数据：r1bs 和 r2bs
X-squared = 150.79, df = 100, p-value = 0.0007807

现在，我执行相同的测试，但对 chisq.test 的两个参数使用相同的输入：
chisq.test(r1bs,r1bs)

我得到以下结果：
&gt; chisq.test(r1bs,r1bs)

皮尔逊卡方检验

数据：r1bs 和 r1bs
X-squared = 200，df = 100，p 值 = 1.178e-08

我的问题是：如果我对 chisq.test 的两个参数使用相同的输入，难道我不应该得到更高的 p 值吗？可能接近 1？
或者，我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652848/chi-square-test-on-contingency-tables-with-same-input-for-both-arguments-of-the</guid>
      <pubDate>Thu, 15 Aug 2024 09:02:33 GMT</pubDate>
    </item>
    <item>
      <title>比较词汇分布分析可视化</title>
      <link>https://stats.stackexchange.com/questions/652847/comparative-word-distribution-analysis-visualization</link>
      <description><![CDATA[我使用下面的代码生成图表来展示 R 中的比较词分布分析。
sum_word_freqs &lt;- function(doc_list) {
Reduce(&quot;+&quot;, lapply(doc_list, function(x) tabulate(x, nbins = length(vocab))))
}

word_freqs &lt;- tibble(
word = vocab,
positive = sum_word_freqs(docs[meta$rating_text == &quot;positive&quot;]),
negative = sum_word_freqs(docs[meta$rating_text == &quot;negative&quot;])
) %&gt;%
mutate(
positive_freq = positive / sum(positive),
negative_freq = negative / sum(negative)
) %&gt;%
filter(positive + negative &gt;= 5) # 包含至少出现 4 次的单词

word_freqs &lt;- word_freqs %&gt;%
mutate(
log_odds_ratio = log((positive_freq + 0.0001) / (negative_freq + 0.0001)),
abs_log_odds_ratio = abs(log_odds_ratio)
) %&gt;%
range(desc(abs_log_odds_ratio))

ggplot(word_freqs, aes(x = positive_freq, y = negative_freq)) +
geom_point(alpha = 0.6, color = &quot;gray&quot;) +
geom_abline(color = &quot;red&quot;, lty = 3) +
geom_text_repel(aes(label = word), size = 3,
data =子集（word_freqs，abs_log_odds_ratio＆gt; 2 | positive_freq＆gt; 0.0001 | negative_freq＆gt; 0.0001)) +
scale_x_log10(labels = scales::percent_format(), 
breaks = c(0.00001, 0.0001, 0.001, 0.01, 0.1)) +
scale_y_log10(labels = scales::percent_format(), 
breaks = c(0.00001, 0.0001, 0.001, 0.01, 0.1)) +
xlab(&quot;Positive&quot;) +
ylab(&quot;Negative&quot;) +
theme_minimal() +
theme_gray() +
theme(panel.grid.minor = element_blank()) +
ggtitle(&quot;词频比较：正面评论与负面评论&quot;)

我的结果如下所示（图 1）。抱歉，出于隐私问题，我不得不隐藏一些文字。

我需要对图进行细微更改，以便它能够类似于下面的图（图 2）：

具体来说，我的一些几何点和文字超出了边界，无法在图中完全显示。我可以进一步将几何点和单词移至图的右侧尺寸，以便它们可以完全显示吗？图 2 中 x 轴和 y 轴的 0.001% 之前没有几何点和单词。]]></description>
      <guid>https://stats.stackexchange.com/questions/652847/comparative-word-distribution-analysis-visualization</guid>
      <pubDate>Thu, 15 Aug 2024 07:49:28 GMT</pubDate>
    </item>
    <item>
      <title>具有空值的互相关函数</title>
      <link>https://stats.stackexchange.com/questions/652842/cross-correlation-function-with-null-values</link>
      <description><![CDATA[我正在分析与另一个特征的上升趋势相关的特征。为了消除噪音，我删除了除因变量 y 呈上升趋势的日期之外的所有日期，例如 7 天的时间段。对于我的独立变量，我正在查看 y 呈上升趋势的同一周，加上前两周，总共 21 天。
当我计算时间序列的互相关函数时，我的系数是 NaN，因为 7 天周期开始前两周对于因变量来说为空，因为它们不在趋势周期内。
为了便于理解，我使用了模仿 r ccf 函数的这个 python 函数：
from scipy import signal
import numpy as np
import pandas as pd

def ccf_values(series1, series2):
p = series1
q = series2
p = (p - np.mean(p)) / (np.std(p) * len(p))
q = (q - np.mean(q)) / (np.std(q)) 
c = np.correlate(p, q, &#39;full&#39;)
返回 c

ccf = ccf_values(df[&#39;y&#39;], df[&#39;x&#39;])
lags = signal.correlation_lags(len(df[&#39;y&#39;]), len(df[&#39;x&#39;]))

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/652842/cross-correlation-function-with-null-values</guid>
      <pubDate>Thu, 15 Aug 2024 05:09:20 GMT</pubDate>
    </item>
    <item>
      <title>基于自适应阈值的嵌套交叉验证结果比较</title>
      <link>https://stats.stackexchange.com/questions/652840/nested-cross-validation-results-comparison-based-on-adaptive-thresholding</link>
      <description><![CDATA[我正在寻找一种通用的阈值机制，可以让我整理出嵌套的交叉验证结果。以下是问题陈述：
假设我有一个回归模型 Reg、一个大小为 S1 的参考数据集 D_ref 和候选数据集 Dc = {Dc_1, Dc_2, ..., Dc_n，大小均为 S2 (S2 &gt; S1)。此外，所有数据集都是相互依赖的。每个配置 Reg x Dc_i 都使用嵌套交叉验证进行评估，其中内部循环优化超参数，外部循环在 L 个循环中使用多个训练/测试分割。每个外循环使用给定的度量来评估模型，每个嵌套交叉验证的最终输出是 L 个循环中当前 Reg x Dc_i 的度量的平均值 (mean(metric(Dc_i))) 和标准差 (std(metric(Dc_i)))。
目标是仅保留可提高参考数据集 D_ref 性能的候选数据集 Dc_i。在这里，我正在寻找一种阈值机制，而不是纯粹的统计测试，作为通用方法的一部分（通用方法实际上构建了数据集 Dc_i，但这与此无关）。此外，尽管阈值方法和统计检验并没有太大区别，但问题是某些配置可能具有较小的数据集，这会限制 t 检验的功效。
起初，我使用了一种简单的方法，其中 threshold = mean(metric(Dc_ref))，然后仅保留候选数据集，其中 mean(metric(Dc_i)) &gt; 阈值。但显然这会导致假阳性（假阴性也是如此，但这不是这里的问题），我知道这一点，因为我可以访问基本事实。
因此，我正在寻找一种方法，其中阈值将类似于 threshold = mean(metric(Dc_ref)) + offset，或类似 threshold = coef * mean(metric(Dc_ref))，或任何考虑到 mean(metric(Dc_ref)) 和 mean(metric(Dc_i)) 之间的差异有多大以及 std(metric(.)) 有多大的变体，以便整理出可能为假阳性的小改进。
注意：我无法访问除 mean(metric(.)) 和 std(metric(.)) 之外的其他数据，首先是因为运行每个 Reg x Dc_i 配置，我没有保存其他结果（遗憾）。也是因为我需要该方法易于应用。]]></description>
      <guid>https://stats.stackexchange.com/questions/652840/nested-cross-validation-results-comparison-based-on-adaptive-thresholding</guid>
      <pubDate>Thu, 15 Aug 2024 04:47:43 GMT</pubDate>
    </item>
    <item>
      <title>我可以比较 GLM 和 GLMM 之间的截距来估计随机效应的影响吗？</title>
      <link>https://stats.stackexchange.com/questions/652835/can-i-compare-intercepts-between-glms-and-glmms-to-estimate-the-effect-of-a-rand</link>
      <description><![CDATA[我正在开展一项统计分析，其中我在同一数据集上运行了广义线性模型 (GLM) 和广义线性混合效应模型 (GLMM)。我可以解释 GLM 和 GLMM 截距之间的差异吗？可以说这两个截距之间的差异代表了随机效应的效应大小吗？如果没有，是否有标准方法或公式来调整 GLMM 截距以估计如果没有随机效应它会是什么（有效地使其与 GLM 截距相当）？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652835/can-i-compare-intercepts-between-glms-and-glmms-to-estimate-the-effect-of-a-rand</guid>
      <pubDate>Thu, 15 Aug 2024 00:21:55 GMT</pubDate>
    </item>
    <item>
      <title>晚年仍有不健康行为（如吸烟）可能表明整体健康状况良好。这种“偏见”有名字吗？</title>
      <link>https://stats.stackexchange.com/questions/652831/the-ability-to-engage-in-an-unhealthy-behavior-e-g-smoking-late-in-life-may-i</link>
      <description><![CDATA[在流行病学中，这种现象有名字吗？我想阅读一些例子和方法来识别和解释它。
场景：
想象一下，你有一个老年人群体。
这些人中的大多数人在他们生命的某个阶段都是忠实的吸烟者。事实上，在那些曾经吸烟的人中，大多数人戒烟只是因为他们变得非常不健康，无法继续吸烟。例如，肺气肿使吸烟在身体上变得不可能。
另一方面，那些继续吸烟到老年的人这样做是因为他们在其他方面足够健康，可以继续吸烟。没有肺气肿。
在这个群体中，吸烟是整体健康状况良好的指标。如果用作短期死亡率的预测指标，吸烟将被视为“保护性”无论你使用什么模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/652831/the-ability-to-engage-in-an-unhealthy-behavior-e-g-smoking-late-in-life-may-i</guid>
      <pubDate>Wed, 14 Aug 2024 23:00:30 GMT</pubDate>
    </item>
    <item>
      <title>应用于随机向量的对比序列的分布收敛，该向量收敛到多元正态分布</title>
      <link>https://stats.stackexchange.com/questions/652827/convergence-in-distribution-of-a-sequence-of-contrasts-applied-to-a-random-vecto</link>
      <description><![CDATA[假设我们知道
$$\Sigma_n^{-1/2}(\hat{\theta}_n - \theta^*_n) \overset{\text{d}}{\longrightarrow} N_{k}(0, I_{k})$$
其中$\hat{\theta}_n$是长度为$k$的随机向量，$\theta_n^*$是长度为$k$的确定性向量，而$\Sigma_n$是确定性的对角矩阵，其元素对于所有$n$均为正值。还假设我们有一个对比序列，其形式为向量 $u_n \in \mathbb{R}^k$，并且对于所有 $n$，$\Vert u_n \Vert_2^2 = 1$。请注意，$\theta_n^*$ 不一定会收敛到任何值，因此我们不能说 $\hat{\theta}_n$ 对于 $\theta_n^*$ 是一致的，但我们知道 $\hat{\theta}_n - \theta^*_n \overset{\text{p}}{\rightarrow} 0$。
我对 $(u_n^\top \Sigma_n u_n)^{-1/2} (u_n^\top \hat{\theta}_n - u_n^\top 的渐近分布感兴趣\theta_n^*)$。
作为启发式论证，如果我们让$n$出现在极限分布的右侧，从而使我们的渐近线变得马虎和不正确，那么我们可以首先说，我们最初的收敛意味着$$\hat{\theta}_n - \theta^*_n \overset{\text{d}}{\longrightarrow} N_k(0, \Sigma_n),$$，这又意味着$$u_n^\top \hat{\theta}_n - u_n^\top \theta_n^* \overset{\text{d}}{\longrightarrow} N(0, u_n^\top \Sigma_n u_n),$$给出一个我希望得到的结果，即 $(u_n^\top \Sigma_n u_n)^{-1/2} (u_n^\top \hat{\theta}_n - u_n^\top \theta_n^*) \overset{\text{d}}{\longrightarrow} N(0,1)$。
然而，显然上述只是一种启发式方法，并不是真正的证明。我知道对于一般的 $u_n$，结果显然是错误的，因为对 $n$ 的依赖将允许 $u_n$ 的条目以某种速率激增，从而使最终结果变得不可能。但是，$\Vert u_n \Vert_2^2 = 1$ 意味着这样可能没问题？
如果变化很大，我可以让 $u$ 不依赖于 $n$，而只让 $\Vert u \Vert_2^2 = 1$。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652827/convergence-in-distribution-of-a-sequence-of-contrasts-applied-to-a-random-vecto</guid>
      <pubDate>Wed, 14 Aug 2024 21:41:47 GMT</pubDate>
    </item>
    <item>
      <title>粒子与时间无关的检验</title>
      <link>https://stats.stackexchange.com/questions/652826/particle-independence-of-time-test</link>
      <description><![CDATA[我对粒子位置 (x_i, y_i)（设其为二维）进行了一系列观察，每次观察都是在时间 t_i 进行，使用一些不精确且会产生一些噪音的探测器。我们可以假设这种噪音呈正态分布。我想验证一个假设，即我的粒子不会移动，因为它的位置与时间无关，并且有一定的可信度。您能推荐我可以使用哪些方法来完成这项任务吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652826/particle-independence-of-time-test</guid>
      <pubDate>Wed, 14 Aug 2024 21:23:25 GMT</pubDate>
    </item>
    <item>
      <title>预测新手——对于使用合适的模型有什么建议吗？</title>
      <link>https://stats.stackexchange.com/questions/652811/new-to-forecasting-any-tips-for-proper-model-to-use</link>
      <description><![CDATA[所以我做了大量的互联网研究，但失败了。我试图预测海上钻井船的日费率。我有两个外生变量与我的历史日费率数据密切相关。（需求和供应指数的日费率数据相关性约为 0.75）。大量数据输入到这些数据中。
问题是，这些数据非常繁荣 - 萧条。我的数据集是 2010-2024 年的日费率。我已经预测了 2029 年的数据，因为其中很多值都是“已知的”（新建船舶队列、未经证实/未经批准的 E&amp;P 活动等）。对于我的问题，绝对最佳的模型是什么？我相信我的需求供应指数是这些费率的非常强的预测指标。
我尝试过 SARIMAX 和后来的马尔可夫切换 ARIMAX，但它们似乎都没有考虑到我的萧条阶段。最终，我确实相信我的供需指数在历史上是强有力的预测指标——我应该如何处理这个问题？
我真的只是想征求一个建议，哪些模型可能适合这些数据。供需指数约为 1-150（最小-最大），代表总深水投资需求（以十亿美元计），而供应紧张程度则为 0-1，来自其他几个数据集。
以下是我的一小部分数据：
日期 平均 铅 日费率 供应紧张指数 需求指数

2010 年 6 月 1 日 500869.5381 0.578840012 94.82266832
]]></description>
      <guid>https://stats.stackexchange.com/questions/652811/new-to-forecasting-any-tips-for-proper-model-to-use</guid>
      <pubDate>Wed, 14 Aug 2024 18:58:38 GMT</pubDate>
    </item>
    <item>
      <title>随机过程的底层 sigma 代数</title>
      <link>https://stats.stackexchange.com/questions/652810/underlying-sigma-algebra-of-a-random-process</link>
      <description><![CDATA[随机过程通常定义为一个集合$(X_i)_{i\in \mathcal{I}}$，其中$\mathcal{I}$是某个索引集，每个$X_i$都是一个随机变量$X_i:(\Omega,\mathcal{A})\rightarrow(\mathcal{X},\mathcal{B})$。若某个随机过程中的每一个随机变量$X_i$都作用于共同可测空间$(\Omega_b,\mathcal{A}_b)$，则该随机过程的底层$\Omega$就不是$\Omega_b$，而是$\Omega\times\Omega\cdots$。比如，如果 $X_i$ 是 $i$ 次硬币抛掷中正面朝上的次数，则随机过程 $(X_i)$ 的底层 $\Omega$ 不是 $\{H,T\}$，而是 $\{H,T\}^\infty$（具有相应的 $\sigma$-代数）。我说得对吗？
有些文本省略了这个基本概念，并认为例如这个过程存在于 $\{H,T\}$ 上。我认为这种理解在应用方面是很好的，除非我们开始思考它的数学原理。如果我理解错了，一些概念，如过滤、马丁格尔等，对我来说就是没有意义的。例如，如果我们将子$\sigma$-代数$\mathcal{A}$的某些过滤视为截至时间$n$的信息，则$\mathcal{A}_n$的形式为$\mathcal{A}_n$=\mathcal{P}(\{H,T\})\otimes \mathcal{P}(\{H,T\}) \otimes \cdots \otimes \mathcal{P}(\{H,T\}) \otimes \{\emptyset,\{H,T\}\}\otimes \{\emptyset,\{H,T\}\} \cdots$.
有人能告诉我，我的这种理解是否正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652810/underlying-sigma-algebra-of-a-random-process</guid>
      <pubDate>Wed, 14 Aug 2024 18:57:22 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用已知范围但未知平均值生成正态分布的变量</title>
      <link>https://stats.stackexchange.com/questions/652807/generating-a-normally-distributed-variable-using-a-known-range-but-an-unknown-m</link>
      <description><![CDATA[我想生成一个具有已知范围（例如 $10.4\text{–}16.6$）但不知道平均值的 100 个数据点的正态分布变量。要使用 rnorm，我需要平均值和标准差。如果我假设它是精确的中点（平均值${} = (10.4 + 16.6) \cdot 0.5 = 13.5).$，我可以估计平均值，并对 sd 进行一些类似的估计（sd${} = (13.5 - 10.4) /2 = 1.55).$，然后我可以使用 rnorm 函数
rnorm (n=100, 平均值 = 13.5, sd = 1.55)

但结果变量的范围超出了我的初始范围 $10.4\text{–}16.6.$，我想看看是否有更好的方法来生成这个变量并强制以保持我预期的范围。]]></description>
      <guid>https://stats.stackexchange.com/questions/652807/generating-a-normally-distributed-variable-using-a-known-range-but-an-unknown-m</guid>
      <pubDate>Wed, 14 Aug 2024 18:22:10 GMT</pubDate>
    </item>
    <item>
      <title>加权平均值（平均客户与产品互动）</title>
      <link>https://stats.stackexchange.com/questions/652806/weighted-averages-average-customer-product-interactions</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652806/weighted-averages-average-customer-product-interactions</guid>
      <pubDate>Wed, 14 Aug 2024 18:10:16 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 CausalImpact 包 - 单尾概率</title>
      <link>https://stats.stackexchange.com/questions/652794/causalimpact-package-in-r-one-tailed-probability</link>
      <description><![CDATA[这是我第一次使用贝叶斯统计和 R 中的 CausalImpact 包。我有点困惑，不知道这是使用单尾还是双尾概率测试，想知道是否有人知道答案？摘要输出的详细选项表明它是单尾的。我试图测试干预后是否有任何方向（正向或负向）的变化，而不是考虑特定的方向。这仍然是一种合适的方法吗？
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652794/causalimpact-package-in-r-one-tailed-probability</guid>
      <pubDate>Wed, 14 Aug 2024 15:23:38 GMT</pubDate>
    </item>
    <item>
      <title>简单的 OLS 来测量相关性</title>
      <link>https://stats.stackexchange.com/questions/652774/simple-ols-to-measure-correlation</link>
      <description><![CDATA[我有两个变量，X 和 Y，我有充分的理由相信它们是同时确定的。
$$Y_{i} = a_{1i} + b_{1i}X_{i} + u_{1i}\tag{1}$$
$$X_{i} = a_{2i} + b_{2i}Y_{i} + u_{2i}\tag{2}$$
我的问题是：只要我远离任何因果关系，我是否仍可以使用简单的 OLS 研究变量之间的关系？
我有兴趣做出这种类型的陈述：“X 的单位增加与 Y 的预测值 b1 的变化相关”。我不想暗示任何有关因果关系方向的内容，我只想描述变量如何共同变动。在这种情况下，我承认明显的内生性，报告系数是否仍然具有误导性？
更新：数据纯粹是横截面数据]]></description>
      <guid>https://stats.stackexchange.com/questions/652774/simple-ols-to-measure-correlation</guid>
      <pubDate>Wed, 14 Aug 2024 10:25:27 GMT</pubDate>
    </item>
    <item>
      <title>Delta 方法和方差收敛</title>
      <link>https://stats.stackexchange.com/questions/652753/delta-method-and-the-variance-convergence</link>
      <description><![CDATA[在我看过的参考文献中，$\Delta$ 方法通常以分布收敛的形式来表述：对于 $X_i$ i.i.d.，$\mathbb{E}[X_i]=\mu$ 和 $\mathrm{Var}_\mu(X_i)=\sigma^2&lt;\infty$（因此 CLT 对样本均值成立，$\bar{X}_n$），并且 $g$ 是一个足够平滑的函数，
$$
\sqrt{n}g(\bar{X}_n) -g(\mu))\Rightarrow N(0,g&#39;(\mu)^2\sigma^2)
$$
我正在看一篇论文（参见 https://arxiv.org/abs/1910.06222 中的 (11)），其中有以下估计：
$$
\lim_{n\to \infty} n \mathbb{E}[(\bar{X}_n) -g(\mu))^2] = g&#39;(\mu)^2\sigma^2
$$
我意识到，我不确定如何将 CLT 型弱收敛映射到二阶中心矩的这种收敛。我将如何论证这一点？
编辑：不出所料，我发现如果我们对导数有先验界限，那么结果就会成立（参见 Bickel 和 Doksum 的教科书）。但这一假设似乎并不存在于 Song &amp; Ermon 的论文中。]]></description>
      <guid>https://stats.stackexchange.com/questions/652753/delta-method-and-the-variance-convergence</guid>
      <pubDate>Wed, 14 Aug 2024 00:00:08 GMT</pubDate>
    </item>
    </channel>
</rss>