<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 22 Jan 2024 06:19:42 GMT</lastBuildDate>
    <item>
      <title>顺序随机抽样</title>
      <link>https://stats.stackexchange.com/questions/637425/sequential-random-sampling</link>
      <description><![CDATA[这道题出自Rice的《数理统计与数据分析》。 （我不是学生，所以你不用担心回答这个问题会帮我“作弊”！）假设你的人口为 $N$ 已排序的元素，并且您想要对 $n$ 元素进行采样。您想要按照总体排序的顺序依次选择元素。您以概率选择元素 $i$
$$
\frac{n - n_i}{N - i + 1}，
$$
其中 $n_i$ 是元素 $i$ 之前已选择的元素数量。证明任何可能的样本都有概率出现
$$
\frac{1}{{N \选择n}}。
$$
直观上，这对我来说非常有意义，因为在每一步中，您选择一个元素的可能性是剩余所需样本的数量除以剩余总体成员的数量。然而，当我尝试正式证明这一点时，我的尝试都失败了，因为我最终得到了复杂的结构，例如带有 $1 / {N - i \choose n -i}$ 等术语的求和，我陷入困境，不知道如何继续。到目前为止，我所有的尝试都是各种形式的归纳证明。
我预感有一个简单的解决方案，但我就是找不到。在过去的几天里，我一直在尝试不同的方法，但到目前为止我还没有找到收获。如果有人能够提供这一点的证明，我终于能够开始思考生活中的其他事情了:)]]></description>
      <guid>https://stats.stackexchange.com/questions/637425/sequential-random-sampling</guid>
      <pubDate>Mon, 22 Jan 2024 04:29:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 Cramer's V 查找哪个变量具有最强的相关性</title>
      <link>https://stats.stackexchange.com/questions/637424/using-cramers-v-to-find-which-variable-has-the-strongest-correlation</link>
      <description><![CDATA[如果之前曾询问过此问题，请提前致歉；我是一名统计爱好者，我的搜索运气不佳。我目前正在分析产品数据，并试图找出哪些变量（所有名义类别）与从试用产品到已售产品的转换最密切相关。更详细地说：在试用产品中，用户可以完成某些操作，我想看看这些完成的操作中哪些与产品销售的相关性最强。
我已经使用卡方关联检验来确认每个正在完成的操作与产品销售之间确实存在相关性，但我现在希望能够比较每个操作并查看哪个操作具有最强的相关性，这样我就可以形成最有利于鼓励用户完成的假设。找到每个动作的 Cramer V，然后比较这些值是否是回答这个问题的有效方法？换句话说，如果同一数据集中一个变量的 Cramer V 值高于另一个变量，那么得出该变量与结果的相关性比另一个变量更强的结论是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/637424/using-cramers-v-to-find-which-variable-has-the-strongest-correlation</guid>
      <pubDate>Mon, 22 Jan 2024 04:04:43 GMT</pubDate>
    </item>
    <item>
      <title>GAM 中“bs=fs”和“by=”术语的概念解释</title>
      <link>https://stats.stackexchange.com/questions/637423/conceptual-interpretation-of-bs-fs-and-by-term-in-gam</link>
      <description><![CDATA[我想知道如何解释 bs=fs 和 by= 术语，以及相似编码模型的两个版本在分层广义中可能有何不同（概念上）加法模型。
例如，如果“调查地点位于相同的栖息地类型”，可以使用s(CYR.std) + s(CYR.std, fSite, bs = &quot;fs&quot;) （相同的沙滩）并且在世界的相似地区，因此它们可能共享全球（年度）趋势，但与该共享趋势存在一些细微的特定地点偏差”？而 s(CYR.std, by = fSite) + fSite 更像是“调查地点位于不同的栖息地和世界的不同地区，因此我们应该将其建模为没有共同的全球趋势”时间 (s(CYR.std))，因为站点距离很远，可能不会对响应产生相同的一般效果 (?)
那么，by= 术语是否类似于治疗水平效应（即每个水平都具有彼此独立的影响），而 fs 术语更相似偏离总体趋势？如果这看起来合理，那么类似描述的现实世界场景可能类似于这两个术语都存在的情况；像这样s(CYR.std) + fSeason + s(CYR.std, fSite, bs = &quot;fs&quot;, by = fSeason)？
# 物种计数
df &lt;- as.data.frame(rnbinom(1000, mu = 0.6971, 大小 = 1))

df$year &lt;- 代表(2011:2020,each=100)
df$CYR.std &lt;- df$year - 分钟(df$年)
df$fCYR &lt;- as.factor(df$年)

df$site &lt;- seq(1, 50, 1)
df$fSite &lt;- as.factor(df$site)

df$season &lt;-rep(c(&quot;DRY&quot;, &quot;WET&quot;),each=50)
df$fSeason &lt;- as.factor(df$season)

# 盐度（连续协变量）
df$sal &lt;- 样本(0.5:40, 1000, 替换 = TRUE)

# 调查区域
df$区域 &lt;- 3

名称(df)[1] &lt;-“计数”

这两个模型在概念上有什么区别？它们的编码是否不正确？
m &lt;- bam(count ~ s(CYR.std) + # 总体趋势
           fSeason + #季节表示固定效应
           s(CYR.std, fSite, bs = “fs”, by = fSeason) +
           # 每个站点的共同年度和季节性趋势存在偏差..？
           s(fCYR, bs = &quot;re&quot;), # 逐年影响（某些年份的平均丰度较高）
         offset(log(面积)), # 3m^2面积
         方法=“fREML”，
         离散=真，
         家庭= nb（链接=“日志”），
         数据 = df)

m2 &lt;- bam(count ~ s(CYR.std) +
           f季节+
           s(CYR.std, fSite, bs = “fs”) +
           s(CYR.std, by = fSeason) +
           s(fCYR, bs = “re”),
         偏移量（日志（面积）），
         离散=真，
         家庭= nb（链接=“日志”），
         数据 = df)
]]></description>
      <guid>https://stats.stackexchange.com/questions/637423/conceptual-interpretation-of-bs-fs-and-by-term-in-gam</guid>
      <pubDate>Mon, 22 Jan 2024 01:58:10 GMT</pubDate>
    </item>
    <item>
      <title>使用辛格马达拉回归</title>
      <link>https://stats.stackexchange.com/questions/637421/use-of-singh-maddala-regression</link>
      <description><![CDATA[我试图了解使用具有 Singh-Maddala 分布的响应变量 (y) 进行回归的用途。
为了对许多变量进行回归，我使用以下代码：
median_y = 中位数(datos[,y])
公式 = as.formula(paste0(y,&quot; ~ &quot;,paste(变量,collapse=&quot; + &quot;)))
fit2 &lt;- vglm(公式, sinmad(lss = FALSE, iscale=median_y)
，数据 = datos，跟踪 = FALSE，控制 = vglm.control(maxit=100) )

我不知道我是否能正确做出预测。我不明白 iscale 参数。我不知道是否使用“y”的中位数是正确的选择（我随意放置）。我使用这段代码来实现结果：
拦截 1：shape.a
拦截2：scale.b
拦截3：shape.q

Formula2 = as.formula(paste0(&quot;~&quot;,paste(all.vars(Formula)[-1],sep=&quot;&quot;,collapse=&quot;+&quot;),&quot;-1&quot;))
matriz_datos &lt;- model.matrix(Formula2, data = datos)
beta &lt;- 系数(fit2)
betas1 &lt;- betas[colnames(matriz_datos)]
betas1 &lt;- betas1[!is.na(betas1)]

形状.a = betas[1]
scale.b = betas[2] + matriz_datos[,名称(betas1)]%*%betas1
形状.q = betas[3]

y_pred = (exp( scale.b )* (gamma(1 + 1/exp( shape.a ))) * ( gamma(exp( shape.q ) - 1/exp( shape.a )) ) / gamma(exp ( 形状.q )))

而且我不知道我工作的初始参数设置是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/637421/use-of-singh-maddala-regression</guid>
      <pubDate>Mon, 22 Jan 2024 00:55:18 GMT</pubDate>
    </item>
    <item>
      <title>函数主成分回归的误差函数本身就是一条曲线。为什么？</title>
      <link>https://stats.stackexchange.com/questions/637417/error-function-of-functional-principal-component-regression-is-itself-a-curve-w</link>
      <description><![CDATA[
我的数据索引从 0 到 54。使用 6 个主成分解释了 99% 的数据变化，我没想到误差函数会表现出如此清晰的形状？由误差函数得出如下公式：
$$ y_t(x) = \hat{\mu}(x) + \sum_{k=1}^{10} \hat{\phi}_k(x) \hat {\beta}_{k,t} + \epsilon_t(x) $$
其中 $$\hat{\phi}_k(x)$$ 是主成分向量，$$\ hat{\beta}_{k,t}$$ 是各自的分数。
据我了解，如果我进行的 PCA 可以解释 99% 的数据，那么我的数据中的任何函数曲线都可以使用主成分向量和分数来重建。事实上，在我的分析中情况并非如此，我相信这是因为误差函数本身是一条曲线，或者可能是一个 K 高于 10 的主成分向量？
为什么会发生这种情况？即使将 K 增加到 20，也无法消除这种形状的错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/637417/error-function-of-functional-principal-component-regression-is-itself-a-curve-w</guid>
      <pubDate>Sun, 21 Jan 2024 22:52:32 GMT</pubDate>
    </item>
    <item>
      <title>K-means 的终止条件及其互连</title>
      <link>https://stats.stackexchange.com/questions/637411/termination-conditions-for-k-means-and-their-interconnection</link>
      <description><![CDATA[据我所知，K-means聚类算法有两个终止标准：

数据点的分配不会改变
质心不变

我想知道这些标准之间是否存在某种关系。它们互相暗示吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637411/termination-conditions-for-k-means-and-their-interconnection</guid>
      <pubDate>Sun, 21 Jan 2024 19:34:24 GMT</pubDate>
    </item>
    <item>
      <title>排名比较测试？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637401/a-rank-comparison-test</link>
      <description><![CDATA[是否有可以用来执行排名比较测试的测试。
换句话说，如果我有 2 个变量（例如 X 国所有 10 个地区的收入；以及 Y 国所有 10 个地区的收入），并且我想知道其中一个变量的排名模式是否与另一个。]]></description>
      <guid>https://stats.stackexchange.com/questions/637401/a-rank-comparison-test</guid>
      <pubDate>Sun, 21 Jan 2024 18:40:50 GMT</pubDate>
    </item>
    <item>
      <title>研究两个自变量之间关系的相关性度量</title>
      <link>https://stats.stackexchange.com/questions/637391/correlation-metric-for-investigating-relationship-between-two-independent-variab</link>
      <description><![CDATA[我正在从事一项计算机工程研究，其中我正在分析不确定性故障场景中指令的动态执行计数（频率）与相应的数据错误率 (SDC) 之间的关系。每条指令都会注入故障，故障注入过程是不确定的，并且在指令之间均匀分布。
我有一个表，其中包括当我们注入故障时每条指令的频率及其对应的SDC错误率。实际上，故障注入过程确保所有指令都注入相似数量的故障。
考虑到该研究的性质，其中故障是非确定性且均匀地注入的，我想知道哪种相关性度量最适合调查频率和 SDC 错误率之间是否存在相关性；因此我们可以得出这样的结论：“保护频繁执行的指令将导致高故障覆盖率，即提高系统的可靠性。”
我考虑使用斯皮尔曼等级相关系数，因为它的稳健性和对非正态分布数据的适用性。不过，我想向社区寻求建议，看看是否有更适合此特定场景的相关性指标。
这里是我数据的一小部分
&lt;前&gt;&lt;代码&gt;指令。频率SDC
0x103f8 64 3
0x10410 64 2
0x10830 13 7
0x1083c 13 6
0x1086c 13 7
0x108ac 13 7
0x108b0 13 6
0x108bc 13 6
0x10a40 7 6
0x10a48 7 4
0x10a9c 7 5
0x103a0 1 0
0x1049c 1 4
0x104a0 1 4
0x106e0 1 0
0x106e8 1 6
0x10710 1 3
0x10724 1 6
0x10780 1 1
0x1078c 1 0
0x107b8 1 2
0x1090c 1 0

谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637391/correlation-metric-for-investigating-relationship-between-two-independent-variab</guid>
      <pubDate>Sun, 21 Jan 2024 13:50:12 GMT</pubDate>
    </item>
    <item>
      <title>随机变量函数的泰勒近似</title>
      <link>https://stats.stackexchange.com/questions/637385/taylor-approximation-for-function-of-a-random-variable</link>
      <description><![CDATA[有一个函数$f$，其域是$\mathbb{R}_+上的CDF空间$ 其范围为 $[0,1]$，例如$f$ 将 CDF 映射到实数。此外， $f$ 是连续的，相对于一阶随机优势递增，并且具有 $I(\delta_d) = d$ 对于每个 $d \in \mathbb{R}_+$。
我的问题是，在对 $f(X)$ 进行线性泰勒近似时，其中 $X$&lt; /span&gt; 是一个 CDF，围绕一个确定性的结果 $d$，什么情况下允许写：
$f(X) \大约 f(d) + f&#39;(d) (E(X) - d)$？
（这里，滥用符号并让 E(X) 为 CDF 为 X 的随机变量的期望。
我主要关心的是 $E(X)$ 部分，因为 $f$ 需要概率不是线性的，甚至可能是一个复合函数，例如 $f = \left(E[X^{1/2}] \right)^2$。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/637385/taylor-approximation-for-function-of-a-random-variable</guid>
      <pubDate>Sun, 21 Jan 2024 13:15:57 GMT</pubDate>
    </item>
    <item>
      <title>为（隐藏的）抛硬币问题编写最大似然方程</title>
      <link>https://stats.stackexchange.com/questions/637371/writing-maximum-likelihood-equations-for-a-hidden-coin-toss-problem</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637371/writing-maximum-likelihood-equations-for-a-hidden-coin-toss-problem</guid>
      <pubDate>Sun, 21 Jan 2024 06:22:09 GMT</pubDate>
    </item>
    <item>
      <title>卡林-鲁宾定理：具有 MLR 属性的检验统计量与充分性检验统计量之间的关系</title>
      <link>https://stats.stackexchange.com/questions/637347/karlin-rubin-theorem-relationship-between-test-statistic-having-the-mlr-propert</link>
      <description><![CDATA[假设我们正在尝试比较单个参数 $\theta$ 的两个假设。原假设 $H_0$ 是 $\theta = \theta_0$，替代假设是 &lt; span class=&quot;math-container&quot;&gt;$\theta ≥ \theta_0$。
据我所知，卡林-鲁宾定理告诉我们，如果存在这样一个统计量 $T(X)$，它具有单调性似然比（MLR）属性，意味着函数
$$
\frac{P\left(T(X)|\theta_1\right)}{P\left(T(X)|\theta_0\right)}
$$
在$T$中是单调非递减的，我们可以通过基于$T(X)$。
问题：$T(X)$ 是 MLR 和  之间有什么关系$T(X)$ 是一个足够的统计数据吗？

卡林-鲁宾定理是否要求 $T(X)$ 也足够，或者只是 MLR？
对于成为 MLR 和充分性有什么影响吗？

我们是否有足够的 MLR $\to$ 和/或足够的 $\to$ MLR？ 


关于 MLR 和最小足够怎么样？

我们是否有足够的最低 $\to$ MLR 和/或 MLR $\to$ 最低限度够了吗？


这些事情有任何关联吗？

简而言之，我在这里看到很多帖子讨论卡林-鲁宾定理设置中的足够统计量，但当我阅读它时，MLR 属性似乎是真正重要的标准。&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/637347/karlin-rubin-theorem-relationship-between-test-statistic-having-the-mlr-propert</guid>
      <pubDate>Sat, 20 Jan 2024 19:47:12 GMT</pubDate>
    </item>
    <item>
      <title>估计缺少信息的抛硬币概率</title>
      <link>https://stats.stackexchange.com/questions/637338/estimating-coin-flip-probabilities-with-missing-information</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637338/estimating-coin-flip-probabilities-with-missing-information</guid>
      <pubDate>Sat, 20 Jan 2024 17:53:04 GMT</pubDate>
    </item>
    <item>
      <title>使用天数计算多项式回归但在绘图上显示月份是否合理？</title>
      <link>https://stats.stackexchange.com/questions/637296/is-it-reasonable-to-calculate-a-polynomial-regression-using-days-but-showing-mon</link>
      <description><![CDATA[我的数据涉及在一个日历年（2009 年 1 月 17 日至 2010 年 1 月 16 日）内以不规则的时间间隔在多达 30 个地点记录的荨麻植物的相对植被覆盖度以及不同地点组的不同日期。我希望能够通过回归方程来描述一年中的变化，并计算 F 统计量以及变化与季节相关的概率。
对于因 x 变量，我使用了从研究开始算起的天数（而不是日期），以便为 y 截距提供较小的值。然而，在以图形方式显示结果时，我希望 x 轴间隔指示月份。这将更直接地显示与生长季节的关系。但是我意识到使用每月的第一天会产生轻微的（难以察觉的？）不均匀的间隔。
这是合理的方法，还是有其他方法可以更好地实现这些目标？
如果有任何建议，我将不胜感激。
我现在添加之前完成的多项式回归的结果：
 colMeans(mse)
[1] 1521.902 1312.779 1283.366 1250.781 1272.761
&gt;最好= lm（覆盖〜聚（天，2，原始= T），数据= frpd）
&gt;总结（最佳）

称呼：
lm(公式 = cover ~ poly(天数, 2, raw = T), 数据 = frpd)

残差：
    最小 1Q 中值 3Q 最大
-63.814 -32.384 -3.897 30.337 57.270

系数：
                          估计标准。误差t值Pr(&gt;|t|)
（拦截）98.4301664 14.8925413 6.609 6.74e-09 ***
聚（天数，2，原始= T）1 -0.5816455 0.1771272 -3.284 0.00161 **
聚（天数，2，原始= T）2 0.0015144 0.0004444 3.408 0.00110 **
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

剩余标准误差：69 自由度上为 36.29
多重 R 平方：0.1443，调整 R 平方：0.1195
F 统计量：2 和 69 DF 上为 5.819，p 值：0.00462

&gt; lm(公式=cover~poly(天数,2,raw=T),data=frpd)

称呼：
lm(公式 = cover ~ poly(天数, 2, raw = T), 数据 = frpd)

系数：
            （截距）poly(天数，2，原始 = T)1 聚(天数，2，原始 = T)2
              98.430166 -0.581645 0.001514

]]></description>
      <guid>https://stats.stackexchange.com/questions/637296/is-it-reasonable-to-calculate-a-polynomial-regression-using-days-but-showing-mon</guid>
      <pubDate>Sat, 20 Jan 2024 05:45:20 GMT</pubDate>
    </item>
    <item>
      <title>对于离散 $X_n$，如果 $X_n \stackrel{d}{\to} U$，则 $P_e \to 1$，其中 $P_e$ 是最佳贝叶斯误差，$U$ 是均匀的</title>
      <link>https://stats.stackexchange.com/questions/637279/for-discrete-x-n-if-x-n-stackreld-to-u-does-p-e-to-1-where-p-e-is</link>
      <description><![CDATA[考虑以下设置。令 $ \{X_n\}_{n=1}^\infty \subseteq [-1,1] $ 为离散随机数收敛为分布中的连续均匀随机变量的变量。
令 $Y_n = X_n +Z_n$ 其中 $Z_n$ 是独立于 $X_n$。
因为 $X_n$ 是离散的，所以来自观察 $X_n$ 的最大后验估计量-container&quot;&gt;$Y_n$ 由下式给出
\begin{align}
\widehat{X}_n = \arg \max_{x} p_{X_n|Y_n}(x|Y_n)
\end{对齐}
其中 $p_{X_n|Y_n}$ 是给定 $X_n$ 的条件 pmf =&quot;math-container&quot;&gt;$Y_n$。错误概率定义为
\begin{align}
P_{n}^{(e)}= \mathbb{P} [\widehat{X}_n \neq X_n]
\end{对齐}
我的问题：我们能否证明 $\lim_{n \to \infty} P_{n}^{(e)} = 1$ ？
对于上限，我们可以使用次优估计器随机选择 $X_n$ 的支撑点之一，这意味着
\begin{align}
P_e \le 1 - \max_{x} p_{X_n}(x)
\end{对齐}
显然，上限收敛于 $1$。我想不出一个好的下限。]]></description>
      <guid>https://stats.stackexchange.com/questions/637279/for-discrete-x-n-if-x-n-stackreld-to-u-does-p-e-to-1-where-p-e-is</guid>
      <pubDate>Fri, 19 Jan 2024 23:17:01 GMT</pubDate>
    </item>
    <item>
      <title>如果文档集对于运行主题模型来说太小，您可以简单地将文档集乘以 10 倍来运行模型吗？</title>
      <link>https://stats.stackexchange.com/questions/637124/if-a-document-set-is-too-small-for-running-a-topic-model-can-you-simply-multipl</link>
      <description><![CDATA[假设我使用 Top2Vec 作为主题模型来捕获文档中前 10 个显着主题。我有一个包含语料库文档的数组。最初，没有足够的文档来运行 Top2Vec。不过，样本量足以运行 LDA 并获得可用的结果。如果接下来我将数组乘以 10，那么就会有足够的文档来运行 Top2Vec。如果我将文档数组乘以 100 或 1000，假设每个原始文档在结果数组中按比例（且相同）重复，结果是否始终相同？就结果而言，这种扩大规模是否微不足道，还是会以某种方式扭曲结果？这仅用于比较两种方法的结果。
编辑：
我意识到乘以文档数组不会生成任何新信息，但如果不以某种方式扩展数组，模型甚至无法运行。我只需要了解运行 Top2Vec 时的结果会是什么样子。这是为了与另一个模型进行比较，该模型已经在未改变的样本量上生成了有意义的结果，没有任何增强。在不乘以集合的情况下，总长度已经是 200,000 个单词。问题是这样的比较是否公平。由于通过乘以该集合不会生成新信息，因此在我看来，仅仅为了让 Top2Vec 运行而进行增强应该没问题（无论是乘以 10 还是 100，结果都不会改变，因为没有新信息正在生成，对吗？）。为了比较的目的，我试图确保我的想法没有错误。即使 Top2Vec 的结果质量在原始信息量上较低，但仍然可以显示出来，以证明为什么第一个模型可能更合适。我错过了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637124/if-a-document-set-is-too-small-for-running-a-topic-model-can-you-simply-multipl</guid>
      <pubDate>Thu, 18 Jan 2024 04:20:44 GMT</pubDate>
    </item>
    </channel>
</rss>