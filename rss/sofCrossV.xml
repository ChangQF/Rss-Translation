<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 24 Jan 2025 18:22:05 GMT</lastBuildDate>
    <item>
      <title>层规范化如何处理特征具有很大尺度差异的情况？</title>
      <link>https://stats.stackexchange.com/questions/660492/how-does-layer-normalization-handle-cases-where-features-have-very-different-sca</link>
      <description><![CDATA[我目前正在学习批量标准化和层标准化，但我对它们的实现和潜在影响有一些疑问。
在批量标准化中，我们在批次级别对特征进行标准化。具体来说，对于批次中的给定特征，我们计算其平均值和方差，并汇总批次中的所有观测值。
另一方面，在层标准化中，标准化是在观测级别完成的。对于给定的观测，将计算所有特征的平均值和方差
这让我想到了我的问题：
由于层标准化会汇总特征，它是否可以处理特征具有非常不同尺度的情况？这种尺度上的差异是否会对性能产生负面影响，因为量级较大的特征可能会主导每次观察的标准化过程？
谢谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/660492/how-does-layer-normalization-handle-cases-where-features-have-very-different-sca</guid>
      <pubDate>Fri, 24 Jan 2025 17:42:24 GMT</pubDate>
    </item>
    <item>
      <title>混合模型：我应该使用哪一种？</title>
      <link>https://stats.stackexchange.com/questions/660490/mixed-model-which-should-i-use</link>
      <description><![CDATA[抱歉，我问了个愚蠢的问题，但我对统计学很陌生。我需要帮助。
我必须使用混合模型分析一些数据。
具体来说，我计算了两种声音（我们称之为“A”和“B”）在不同类型的对话中出现的频率。
在某些情况下，A 在同一对话中出现很多次，而在其他情况下只出现一次甚至零次。B 也是如此。A 和 B 的出现应该与一些预测因子有关：

上下文（3 个级别：中性、修改、修改后）
态度（4 个级别：可靠、不可靠、中性、自信）

我认为我应该使用具有泊松分布的混合回归模型。
但是，这样可以检测声音 A 的发生是否受上下文和态度的调节（B 也是如此）吗？
此外，为了检测 A 和 B 之间在预测变量方面是否存在差异，我是否应该将预测变量声音类型（2 个级别：A、B）也添加到固定效应结构中？
如果频率（2 个声音的因变量在不同对话中不同）也将其作为随机截距对话类型是否正确？
您能为我提供您要运行的模型的代码吗？（我知道您可能需要更多信息，但我无法为您提供更多信息）。]]></description>
      <guid>https://stats.stackexchange.com/questions/660490/mixed-model-which-should-i-use</guid>
      <pubDate>Fri, 24 Jan 2025 17:27:26 GMT</pubDate>
    </item>
    <item>
      <title>MLE 的正式定义是否是最大化样本数据的联合似然？</title>
      <link>https://stats.stackexchange.com/questions/660489/is-the-mle-formally-defined-as-maximizing-the-joint-likelihood-of-the-sample-dat</link>
      <description><![CDATA[我正在尝试了解随机向量序列实现的最大似然估计量 (MLE) 的计算。我目前的理解是，MLE 应该通过最大化从样本数据的联合分布得出的对数似然函数来计算。
这种理解基于 John Stachurski 的书中的一句话（链接在此处：QuantEcon Notes），其中指出：

“最大似然原理告诉我们要最大化由样本联合密度形成的对数似然函数。”

这是否意味着 MLE 始终基于观测值的联合密度（或离散数据的联合概率质量函数）计算？这个原则有什么例外或细微差别吗？
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/660489/is-the-mle-formally-defined-as-maximizing-the-joint-likelihood-of-the-sample-dat</guid>
      <pubDate>Fri, 24 Jan 2025 16:38:45 GMT</pubDate>
    </item>
    <item>
      <title>使用它们的相关性来理解 $X$ 和 $Y$ 的联合 CDF？</title>
      <link>https://stats.stackexchange.com/questions/660487/understanding-joint-cdf-of-x-and-y-using-their-correlation</link>
      <description><![CDATA[假设我们有两个连续随机变量 $X$ 和 $Y$，它们具有相关性 $\rho$，并考虑它们的联合 CDF $F_{X,Y}(x,y) = \mathbb{P}[X&lt;x,Y&lt;y]$。问题是：假设我们有 $X$ 和 $Y$ 之间的相关性，我们可以对它们的联合 CDF 说什么？
我知道它很通用，所以可以包括其他假设（如高斯性）。
例如，我的问题得到以下事实的支持：如果 $\rho = 1$，那么我们只需要边际分布。如果 $\rho &lt; 1$，那么我们“丢失”了信息，但我们仍然有一些信息，因为我们知道 $\rho$，所以我想知道我们是否可以部分地谈论联合 CDF。]]></description>
      <guid>https://stats.stackexchange.com/questions/660487/understanding-joint-cdf-of-x-and-y-using-their-correlation</guid>
      <pubDate>Fri, 24 Jan 2025 16:17:58 GMT</pubDate>
    </item>
    <item>
      <title>定义“辅助信息”，但不引用辅助统计数据</title>
      <link>https://stats.stackexchange.com/questions/660486/define-ancillary-information-without-referencing-ancillary-statistics</link>
      <description><![CDATA[我正在寻找辅助信息的定义，但该定义本质上不是“辅助统计数据中的信息”。有趣的是，辅助信息的定义似乎很难找到。至少有一篇被广泛引用的辅助统计数据评论甚至没有包含该短语。我不喜欢上述定义，因为它不仅是循环的，而且还让我陷入矛盾。
即：完整统计数据没有辅助信息。因此，不完整统计数据必须具有一些辅助信息。然后，不完整的充分统计数据具有一些辅助信息，但该信息无法根据辅助统计数据来定义。如果可以的话，您可以根据辅助统计量来获得方差小于充分统计量的估计量。但充分统计量是最具信息量的度量……您看到了问题所在。]]></description>
      <guid>https://stats.stackexchange.com/questions/660486/define-ancillary-information-without-referencing-ancillary-statistics</guid>
      <pubDate>Fri, 24 Jan 2025 16:03:59 GMT</pubDate>
    </item>
    <item>
      <title>解释变量是共线的，但我无法删除它们</title>
      <link>https://stats.stackexchange.com/questions/660482/explanatory-variables-are-collinear-but-i-can-t-remove-them</link>
      <description><![CDATA[我试图使用逻辑回归模型，在给定价格和其他解释变量的情况下估计我们（装修公司）的报价被接受的可能性。但是，由于我的公司没有定量定价策略（主要使用他们的直觉 - 他们是老派的），我必须包括解释变量，如油漆表面积、石膏板的计量等。
但是，所需的材料数量以及所需的劳动力数量很可能与价格高度相关/直接相关。
我想知道我可以使用什么技术来消除或测试多重共线性。
我问过尝试在给定解释变量的情况下估计价格，然后在逻辑回归模型中使用它并只使用估计价格，但被告知这被称为“禁止回归”。
有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660482/explanatory-variables-are-collinear-but-i-can-t-remove-them</guid>
      <pubDate>Fri, 24 Jan 2025 14:58:11 GMT</pubDate>
    </item>
    <item>
      <title>如何提取和比较两个混合效应模型的预测值分布？</title>
      <link>https://stats.stackexchange.com/questions/660480/how-to-extract-and-compare-the-distribution-of-predicted-values-of-two-mixed-eff</link>
      <description><![CDATA[我有 6 天的 100 个样本（每天 100 个观测值，总共 600 个观测值）。我尝试将混合模型拟合到数据中。还有一次，我尝试将混合模型仅用于从相同数据中获取的两天观测值（例如：第 1 天和第 2 天的观测值 - 总共 200 个观测值）。我知道数据中存在人与人之间的差异会导致错误。我尝试使用混合效应模型将其消除。现在，我的问题是如何提取响应变量的分布？如何比较两个混合模型的分布？一般来说，有什么建议可以消除数据中的人与人之间的差异吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660480/how-to-extract-and-compare-the-distribution-of-predicted-values-of-two-mixed-eff</guid>
      <pubDate>Fri, 24 Jan 2025 14:45:03 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Google Colab 上的 AWQ 量化阿拉伯语预训练 LLM？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660477/how-to-quantize-an-arabic-pretrained-llm-using-awq-on-google-colab</link>
      <description><![CDATA[我想在 Google colab 上运行一个预训练的阿拉伯语模型来生成文本，并在需要时使用 AWQ 对其进行量化。我尝试了许多模型，但总是出现与 AWQ 相关的错误。您能否给我推荐一些资源（代码）来运行和量化使用 AWQ 的阿拉伯语 LLM？]]></description>
      <guid>https://stats.stackexchange.com/questions/660477/how-to-quantize-an-arabic-pretrained-llm-using-awq-on-google-colab</guid>
      <pubDate>Fri, 24 Jan 2025 14:17:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用$\pm h$计算梯度时误差会更小？</title>
      <link>https://stats.stackexchange.com/questions/660475/why-is-the-error-smaller-using-pm-h-to-calculate-gradients</link>
      <description><![CDATA[这里他们说：

这需要您评估损失函数两次以检查梯度的每个维度（因此成本大约是原来的 2 倍），但梯度近似结果要精确得多。要看到这一点，您可以使用 $f(x+h)$
和 $f(x−h)$ 的泰勒展开式，并验证第一个公式的误差为 $O(h)$ 阶，而第二个公式的误差项仅为 $O(h^2)$ 阶（即它是二阶近似）。

上下文：与 $f(x+h) - f(h)$ 进行比较
问题
证明这一点应遵循哪些数学步骤？
我尝试计算该系列，但无法将其与他们的段落匹配。]]></description>
      <guid>https://stats.stackexchange.com/questions/660475/why-is-the-error-smaller-using-pm-h-to-calculate-gradients</guid>
      <pubDate>Fri, 24 Jan 2025 13:13:48 GMT</pubDate>
    </item>
    <item>
      <title>竞争风险模型外部验证的校准曲线：为什么需要互补对数-对数变换？</title>
      <link>https://stats.stackexchange.com/questions/660474/calibration-curve-for-external-validation-of-competing-risks-model-why-the-need</link>
      <description><![CDATA[我想制作一条平滑的校准曲线，以从外部验证竞争风险模型。我遵循本文中提出的建议：
https://diagnprognres.biomedcentral.com/articles/10.1186/s41512-021-00114-6
标题为：“竞争风险模型的图形校准曲线和校准指标”的部分。
这建议在我们想要从外部验证的模型的预测风险（概率）的互补对数对数的样条上拟合观察到的生存率（时间、事件）的竞争风险模型（例如原因特定 Cox 模型、Fine-Gray 模型等）。假设有足够多的事件，我理解使用样条函数实现非线性的好处。但为什么在拟合模型之前需要对独立变量进行互补对数-对数变换？]]></description>
      <guid>https://stats.stackexchange.com/questions/660474/calibration-curve-for-external-validation-of-competing-risks-model-why-the-need</guid>
      <pubDate>Fri, 24 Jan 2025 13:11:41 GMT</pubDate>
    </item>
    <item>
      <title>具有可训练基线风险的 Cox 模型</title>
      <link>https://stats.stackexchange.com/questions/660473/cox-model-with-trainable-baseline-hazard</link>
      <description><![CDATA[我正在研究生存分析，并使用 Cox 比例风险模型。在大多数实现中，使用部分似然估计模型参数，然后使用 Breslow 估计量（或类似方法）估计基线风险函数。
但是，我想知道：
为什么我们不最大化完全似然，联合估计模型参数和基线风险函数？
例如，如果我们将基线风险建模为分段常数函数，原则上我们可以最大化回归系数和基线风险的完全似然。这似乎可以提供一种更直接的估计方法。
完全似然方法不常用的理论或实际原因/含义是什么？这种方法是否在文献中得到研究或实施？如果是，我在哪里可以找到相关论文或参考文献？]]></description>
      <guid>https://stats.stackexchange.com/questions/660473/cox-model-with-trainable-baseline-hazard</guid>
      <pubDate>Fri, 24 Jan 2025 12:47:28 GMT</pubDate>
    </item>
    <item>
      <title>哪些损失函数可以用 Lipschitz 梯度微分？</title>
      <link>https://stats.stackexchange.com/questions/660471/which-loss-functions-are-differentiable-with-lipschitz-gradient</link>
      <description><![CDATA[我正在阅读一篇优化论文，该论文要求损失函数具有 Lipschitz 梯度可微分性。我发现一些资料表明线性和逻辑回归的损失函数满足这一点，但我无法找到有关 GLM 系列其他成员的任何资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/660471/which-loss-functions-are-differentiable-with-lipschitz-gradient</guid>
      <pubDate>Fri, 24 Jan 2025 12:41:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 Kaplan-Meier 解决方法计算累积发生率？</title>
      <link>https://stats.stackexchange.com/questions/660468/compute-cumulative-incidence-with-workaround-kaplan-meier</link>
      <description><![CDATA[我们能否通过这种方式计算累积发生率函数：为除关注事件之外的竞争事件的所有人分配最大跟进时间，并在该时间点对其进行审查。然后在此转换后的数据集上计算关注事件的 KM。然后 1-KM 将呈现累积发生率函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/660468/compute-cumulative-incidence-with-workaround-kaplan-meier</guid>
      <pubDate>Fri, 24 Jan 2025 12:02:41 GMT</pubDate>
    </item>
    <item>
      <title>对分类响应变量和比例作为解释变量进行建模/显着性检验</title>
      <link>https://stats.stackexchange.com/questions/660457/modelling-significance-testing-for-a-categorical-response-variable-and-proportio</link>
      <description><![CDATA[我是一名初学研究生，正在尝试首次建模。我正在努力寻找适合我的变量的正确模型。我的结果相当简单，所以我担心我可能会忽略最简单的解决方案。
-我有一个具有三个级别的分类响应变量（这些类别是根据个体的生长特征而分为“慢”、“中”和“快”的类别）。这些类别虽然有名称，但都是名义上的，因为它们不是由单个变量定义的。
-解释变量是这些个体所经历的良好和不良喂养周的比例，范围从 0-1。每个个体生长了多个星期，并且根据喂养质量（在之前的分析步骤中确定）将每个单独的星期分配为良好或不良。例如，一只生长了 8 周的动物可能经历了 3 个好周和 5 个坏周，因此好周的比例为：3/8 = 0.375。
我想知道本周质量比例是否能解释个体属于哪个类别。
尝试：
所以我的第一个想法是使用 GLM 来模拟分类响应变量，但据我所知，GLM 主要用于计数（泊松系列）或比例/二元（二项式）响应变量。问题当然是我的解释变量是一个比例，而不是我的响应。如果我运行以比例为响应的模型，它与所有经过检查的假设完全吻合，这很糟糕，因为这不是我希望我的分析测试的内容。
我研究过多项逻辑回归，有人告诉我它可能适用于我的变量。但考虑到我的结果很简单，它似乎很复杂。我只想比较组之间的平均值，而不是从一个类别转移到另一个类别的对数几率（我理解多项式是如何工作的）。
因此，我尝试了 Kruskal-Wallis 检验，因为我的比例不遵循正态性，因为它们是有界的。
我想我是在向比我更了解的人寻求确认。多项式方法可能是我想要的，但 Kruskal-Wallis 检验似乎不错，但它是一个简单的测试。只是我对我为这些数据选择的模型并不完全有信心，所以我不能选择一种方法而不是另一种方法。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/660457/modelling-significance-testing-for-a-categorical-response-variable-and-proportio</guid>
      <pubDate>Fri, 24 Jan 2025 03:40:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么在复协方差中共轭第二个变量？</title>
      <link>https://stats.stackexchange.com/questions/660451/why-conjugate-second-variable-in-complex-covariance</link>
      <description><![CDATA[除了历史/传统原因之外，是否有任何实际原因可以解释为什么两个复变量 $z$ 和 $w$ 的协方差应该写成
$$\mathrm{Cov}[z,w] = \mathrm{E}[(z-\mathrm{E}[z])(w-\mathrm{E}[w])^\ast]\quad\cdots(1)$$
而不是
$$\mathrm{Cov}[z,w] = \mathrm{E}[(z-\mathrm{E}[z])^\ast(w-\mathrm{E}[w])]\quad\cdots(2)$$
?
符号 (2) 与物理学中用于矢量的符号更一致，因为考虑 $\mathbf{z}\cdot\mathbf{w} = \mathbf{w}^{H}\mathbf{z}$ 是违反直觉的。同样，在互相关的情况下，当应用卷积定理时，共轭是第一个参数。
例如，符号 (1) 在 维基百科 中被简单提及：

请注意定义中第二个因子的复杂共轭。

这根本不能解释原因。
这是历史事实吗？或者是否有任何实际理由来共轭第二个变量？此外，符号 (1) 在文本和计算机代码中有多“普遍”？]]></description>
      <guid>https://stats.stackexchange.com/questions/660451/why-conjugate-second-variable-in-complex-covariance</guid>
      <pubDate>Fri, 24 Jan 2025 02:09:13 GMT</pubDate>
    </item>
    </channel>
</rss>