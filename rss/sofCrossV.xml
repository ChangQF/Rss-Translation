<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 12 Jun 2024 21:14:16 GMT</lastBuildDate>
    <item>
      <title>在正方形的边缘随机行走，允许停留在同一位置</title>
      <link>https://stats.stackexchange.com/questions/649136/random-walk-on-the-edges-of-a-square-where-staying-at-same-position-is-allowed</link>
      <description><![CDATA[从正方形的一角移动到另一角的经典问题。我发现了一种直观的方法来解决这个问题，即考虑我们处于位置 $(0,0)$ 并希望到达位置 $(1,1)$。
如果我们希望分两步完成，我们可以这样做：
$$(0,0) \xrightarrow{1} (1,0) \xrightarrow{\frac{1}{2}} (1,1)$$
箭头上方的数字表示转换的概率。注意：这里 $(1,0)$ 并不代表点 $(1,0)$，而是粒子距离目标 1 个距离。这就是此处概率为 1 的原因。
因此，2 步内到达对角的概率为 $\frac{1}{2}$。在此设置下，不可能在 3 步（或任何奇数步）内到达 $(1,1)$。类似地，对于 4 步，我们有以下情况：
$$(0,0) \xrightarrow{1} (1,0) \xrightarrow{\frac{1}{2}} (0,0) \xrightarrow{1} (1,0) \xrightarrow{\frac{1}{2}} (1,1)$$
这表明在 4 步内达到 $(1,1)$ 的概率为 $\frac{1}{4}$。通过归纳推理，我们可以证明在 $2 + n$, $n \geq 0$ 步中达到 $(1,1)$ 的概率是 $\frac{1}{2^{n+1}}$。因此，到达 $(1,1)$ 的预期转弯次数为：
$$\sum_{n=0}^\infty \frac{2+2n}{2^{n+1}} = \sum_{n=0}^\infty \frac{1 + n}{2^{n}} = 4$$
我的问题：
如果我们被允许以相等的概率停留在当前位置会怎样？
现在使用相同的想法，通过 2 步从 $(0,0)$ 到达 $(1,1)$，
$$(0,0) \xrightarrow{\frac{2}{3}} (1,0) \xrightarrow{\frac{1}{3}} (1,1)$$ 因此现在 2 步的概率为 $\frac{2}{9}$。在此设置下，我们可以有 3 个步骤，这给了我们，
$$(0,0) \xrightarrow{\frac{1}{3}} (0,0) \xrightarrow{\frac{2}{3}} (1,0) \xrightarrow{\frac{1}{3}} (1,1)$$
$$(0,0) \xrightarrow{\frac{2}{3}} (1,0) \xrightarrow{\frac{1}{3}} (1,0) \xrightarrow{\frac{1}{3}} (1,1)$$
这给了我们概率 $\frac{2 + 2}{27} = \frac{4}{27}$。这使得接下来的 4 步看起来应该是 $\frac{8}{81}$，但让我们看一下，
$$ (0,0) \xrightarrow{\frac{1}{3}}(0,0) \xrightarrow{\frac{1}{3}} (0,0) \xrightarrow{\frac{2}{3}} (1,0) \xrightarrow{\frac{1}{3}} (1,1)$$
$$ (0,0) \xrightarrow{\frac{1}{3}}(0,0) \xrightarrow{\frac{2}{3}} (1,0) \xrightarrow{\frac{1}{3}} (1,0) \xrightarrow{\frac{1}{3}} (1,1)$$
$$(0,0) \xrightarrow{\frac{2}{3}} (1,0) \xrightarrow{\frac{1}{3}} (0,0) \xrightarrow{\frac{2}{3}} (1,0) \xrightarrow{\frac{1}{3}} (1,1)$$
$$(0,0) \xrightarrow{\frac{2}{3}} (1,0) \xrightarrow{\frac{1}{3}} (1,0) \xrightarrow{\frac{1}{3}} (1,0) \xrightarrow{\frac{1}{3}} (1,0) \xrightarrow{\frac{1}{3}} (1,1)$$
这给了我们概率 $\frac{2 + 2 + 4 + 2}{81} = \frac{10}{81}$。由此我无法看出模式。我该怎么做？我不熟悉马尔可夫链，所以如果可能的话，我希望找到一种简单而优雅的前进方式。
（这不是家庭作业或分级评估。我看到了一个关于随机游走的谜题，出于自己的兴趣想到了这个修改）]]></description>
      <guid>https://stats.stackexchange.com/questions/649136/random-walk-on-the-edges-of-a-square-where-staying-at-same-position-is-allowed</guid>
      <pubDate>Wed, 12 Jun 2024 21:09:03 GMT</pubDate>
    </item>
    <item>
      <title>多元概率估计</title>
      <link>https://stats.stackexchange.com/questions/649135/estimation-of-multivariate-probability</link>
      <description><![CDATA[假设 $(X_{1}, \dots, X_{n})$ 为多元分布，我可以从中生成样本。接下来，假设我必须计算
$$
P(X_{1}\in A_{1}, \dots, X_{n}\in A_{n}),
$$
其中 $A_{1}, \dots, A_{n}$ 是一些区间。然后，自然的方法是从样本$(x_{1}^{i}, \dots, x_{n}^{i})$中进行估计，其中$i = 1:N$
$$
\frac{\sum_{i=1}^{N}I\{ x_{1}^{i}\in A_{1}, \dots, x^{i}_{n}\in A_{n})\}}{N}。
$$
对于哪些分布来说，这是一种不好的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/649135/estimation-of-multivariate-probability</guid>
      <pubDate>Wed, 12 Jun 2024 20:45:24 GMT</pubDate>
    </item>
    <item>
      <title>复制数据集是否是一种增强？</title>
      <link>https://stats.stackexchange.com/questions/649133/is-duplicating-dataset-an-augmentation</link>
      <description><![CDATA[对于非常小的数据集，随机森林回归模型中存在大量过拟合。我已经删除了无关数据、缩放和特征选择，但过拟合仍然存在。过采样技术极大地改善了结果，但由于它不会创建不切实际的数据，因此不允许我使用这种技术。我可以将数据集加倍（重复数据两次）并像这样改进数据集吗？或者我应该将数据集乘以一个数字并将其添加到主数据集？您认为这些方法合理有效吗？数据集是表格和数字。]]></description>
      <guid>https://stats.stackexchange.com/questions/649133/is-duplicating-dataset-an-augmentation</guid>
      <pubDate>Wed, 12 Jun 2024 20:31:16 GMT</pubDate>
    </item>
    <item>
      <title>在核回归的背景下，为什么我们将特征图定义为等于核 $\varphi(x)=k(\cdot ,x)$？</title>
      <link>https://stats.stackexchange.com/questions/649132/in-the-contex-of-kernel-regression-why-do-we-define-the-feature-map-as-equal-to</link>
      <description><![CDATA[我有一个符号上的困惑，正在努力澄清。在核回归的上下文中，核和特征图之间的关系定义如下：
考虑一个正定实值核$ k:{\mathcal {X}}\times {\mathcal {X}}\to \mathbb {R} $，它位于非空集$\mathcal {X}$上，其对应的再生核希尔伯特空间$H_{k} $。
定义映射
${\begin{aligned}\varphi \colon {\mathcal {X}}&amp;\to H_{k}\\\varphi (x)&amp;=k(\cdot ,x)\end{aligned}}$
（因此 $ \varphi (x)=k(\cdot ,x) $ 本身就是一个映射 $ \mathcal {X}\to \mathbb{R} $）。由于 $k$ 是一个再生核，因此
$ \varphi (x)(x&#39;)=k(x&#39;,x)=\langle \varphi (x&#39;),\varphi (x)\rangle ,$
其中$ \langle \cdot ,\cdot \rangle $ 是 $ H_{k}$ 的内积。
现在这一切都很好，但是当我看一个例子时，我不确定 $ \varphi (x)=k(\cdot ,x) $ 是如何的。例如，取 2 次多项式核：
$$
k(x, x&#39;) = (x \cdot x&#39; + 1)^2,
$$
在这种情况下，特征图为
$$
\varphi(x) = \begin{pmatrix}
x^2 \\
\sqrt{2} \cdot x \\
1
\end{pmatrix},
$$
事实上 $\langle \varphi (x&#39;),\varphi (x)\rangle = k(x, x&#39;)$。但是 $ \varphi (x)=k(\cdot ,x) $ 又是如何呢？在这种情况下我该如何理解这个符号？]]></description>
      <guid>https://stats.stackexchange.com/questions/649132/in-the-contex-of-kernel-regression-why-do-we-define-the-feature-map-as-equal-to</guid>
      <pubDate>Wed, 12 Jun 2024 20:23:11 GMT</pubDate>
    </item>
    <item>
      <title>复制增量和复制参考归纳之间的差异</title>
      <link>https://stats.stackexchange.com/questions/649131/difference-between-copy-increments-and-copy-reference-imputation</link>
      <description><![CDATA[我正在阅读基于参考的插补（Carpenter 等人，2013 年，但解释对我来说有点太数学化了），我不太确定我是否理解复制增量参考（允许退出者从其既定位置继续，但随后的平均概况变化遵循指定参考组的变化）和复制参考（退出前和退出后的结果值都等于控制（参考））之间的区别。这是否意味着在复制参考插补的情况下，我需要替换退出前参与者的观察值？有人可以在 RCT 的背景下解释这种差异吗？
来源：https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5796638/]]></description>
      <guid>https://stats.stackexchange.com/questions/649131/difference-between-copy-increments-and-copy-reference-imputation</guid>
      <pubDate>Wed, 12 Jun 2024 20:17:34 GMT</pubDate>
    </item>
    <item>
      <title>调查短期序列中的季节性和趋势</title>
      <link>https://stats.stackexchange.com/questions/649128/investigating-seasonality-and-trend-in-short-time-series</link>
      <description><![CDATA[我有兴趣调查非常短的时间序列（通常最多 12 个观测值）中季节性或趋势的存在与否。举个例子：假设有人正在按月查看足球联赛中每场比赛的平均进球数（假设目标是调查进球频率的任何季节内变化）。每个足球联赛“赛季”通常有 9-10 个月。因此，每个赛季只有 9-10 个数据点可用于推断任何模式。现在，人们可以查看从一个赛季到下一个赛季的模式，以大幅增加样本量，但问题是球员和经理往往会在每个赛季发生变化，因此一个赛季的模式可能并不总是延续到下一个赛季。
人们将如何处理/适应这种类型的系列以尝试推断任何模式？]]></description>
      <guid>https://stats.stackexchange.com/questions/649128/investigating-seasonality-and-trend-in-short-time-series</guid>
      <pubDate>Wed, 12 Jun 2024 19:37:41 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型中的调节系数 SPSS - 解释</title>
      <link>https://stats.stackexchange.com/questions/649127/moderation-coefficient-in-linear-mixed-models-spss-interpretation</link>
      <description><![CDATA[我的模型：
IV：外向性（5 点李克特）
调节器：能力（值 1-5）
DV：要约（值 5 到 15）
假设：外向性和要约之间的负相关关系受能力调节，因此更高的能力会削弱负相关关系。
我的输出：（显著性截止值为 .1，而不是我的情况中的 .05）
外向性和能力之间没有显著的负面直接影响。
外向性*能力交互作用显著，但系数为正。这是否支持我的假设，还是意味着完全相反（更高的能力信任会加剧外向性和提供之间的负相关关系）。
请帮助我，我对结果的含义感到非常困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/649127/moderation-coefficient-in-linear-mixed-models-spss-interpretation</guid>
      <pubDate>Wed, 12 Jun 2024 19:14:33 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 tf.image.SSIM 函数</title>
      <link>https://stats.stackexchange.com/questions/649126/how-to-use-the-tf-image-ssim-function</link>
      <description><![CDATA[有人能帮我理解如何使用这个 SSIM 函数吗（https://www.tensorflow.org/api_docs/python/tf/image/ssim）？根据文档信息，filter_size 参数的默认值为 11，“由于过滤器大小，图像大小必须至少为 11x11”。如果我使用 8x11 大小的图像，我应该如何调整这个参数，如果适用的话，还有其他函数参数吗？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/649126/how-to-use-the-tf-image-ssim-function</guid>
      <pubDate>Wed, 12 Jun 2024 19:11:18 GMT</pubDate>
    </item>
    <item>
      <title>如何根据先验概率 $P(R)$ 和后验概率 $P(R/B)$ 获得似然值 ($P(B/R)$)</title>
      <link>https://stats.stackexchange.com/questions/649125/how-to-obtain-likelihood-pb-r-given-the-prior-pr-and-the-posterior-pr</link>
      <description><![CDATA[我正在研究一个与多项选择题相关的主题。我想衡量信息源（或学生的信息搜索）的效率，我相信贝叶斯统计是正确的方法；但是，由于我只知道基础知识，所以我想展示它以查看我的推理是否连贯。
给定一个多项选择题（例如，有 4 个答案），其中只有一个答案是正确的，学生可以仅根据他/她在家学习的内容来回答，为每个答案分配一个概率，例如 P(R)=(0.4, 0.3, 0.15, 0.15)。答案可能就此结束，或者学生可能会查阅书籍并更新这些概率，例如 P(R|B)=(0.4,0.6,0,0)。 P(R) 是先验概率，P(R|B) 是后验概率，(多项式) 和 P(B/R) 都是似然率，我将其理解为我先前信念 P(R) 的更新，并将其转换为 P(R|B)。
所以我想知道 P(B|R)，我也想看看我是否可以确定 P(B|R) 会使 P(R|B)=(1,0,0,0)，也就是说，确定地选择正确的答案。
我理解这是一种逆问题，不会有唯一的解决方案；但也许有一些启发式方法来近似解决方案，至少对于寻找 P(B|R) 的第一个挑战而言。
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/649125/how-to-obtain-likelihood-pb-r-given-the-prior-pr-and-the-posterior-pr</guid>
      <pubDate>Wed, 12 Jun 2024 19:08:35 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归给出了重复 ID 变量上的多个预测变量</title>
      <link>https://stats.stackexchange.com/questions/649124/poisson-regression-given-multiple-predictors-on-a-repeating-id-variable</link>
      <description><![CDATA[我想知道，对于我的数据集，泊松回归将如何工作，该数据集描述了一系列按年龄组、性别和死亡人数分层的邮政编码。
回归将使用死亡人数作为因变量，邮政编码、年龄组和性别作为预测因子。
问题是每个相同的邮政编码有多行，我不确定如何在泊松回归模型中解释这一点。我必须重新排列数据集吗？
![数据集部分示例]
(https://imgur.com/a/UlmEiJ3)]]></description>
      <guid>https://stats.stackexchange.com/questions/649124/poisson-regression-given-multiple-predictors-on-a-repeating-id-variable</guid>
      <pubDate>Wed, 12 Jun 2024 18:57:48 GMT</pubDate>
    </item>
    <item>
      <title>在中介分析中解释 ACME 和 ADE 中的相反符号和控制/处理</title>
      <link>https://stats.stackexchange.com/questions/649123/interpreting-opposite-signs-and-control-treatment-in-acme-and-ade-in-mediation-a</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/649123/interpreting-opposite-signs-and-control-treatment-in-acme-and-ade-in-mediation-a</guid>
      <pubDate>Wed, 12 Jun 2024 18:53:39 GMT</pubDate>
    </item>
    <item>
      <title>高阶矩评估变量间线性关系的强度</title>
      <link>https://stats.stackexchange.com/questions/649122/higher-order-moments-to-evaluate-strength-of-linear-relationship-between-variabl</link>
      <description><![CDATA[设 $X_1,\dots,X_n$ 为实数随机变量，其中 $\alpha_1X_1+\dots+\alpha_nX_n=0$，其中未知数为 $\alpha_1,\dots,\alpha_n$。如果$n=2$，我们可以通过观察相关性
$\rho_{X_1,X_2}=\frac{\mathbb{E}(​​X_1-\mu_1)(X_2-\mu_2)}{\sigma_1\sigma_2}$来研究线性关系的强度，其中$\mu_i$和$\sigma_i$分别是$X_i$的预期值和标准差。正如预期的那样，当我使用（一个很好的）数据样本时，我得到了$\rho_{X_1,X_2}\simeq 1$。
我想通过观察此刻将这个想法推广到任意$\rho_{X_1,\dots,X_n}:=\frac{\mathbb{E}\left[\prod_{i=1}^n (X_i-\mu_i)\right]}{\prod_{i=1}^n\sigma_i}$，但是当我使用数据样本时，我得到了$\rho_{X_1,\dots,X_n}\simeq 0$。我在这里误解了什么？
这看起来与模型选择非常相似，我正在考虑使用多重相关系数$R^2$，但这里我没有区分因变量，在我的实验中，样本$R^2$的值实际上取决于选择哪个$X_i$作为“因”变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/649122/higher-order-moments-to-evaluate-strength-of-linear-relationship-between-variabl</guid>
      <pubDate>Wed, 12 Jun 2024 18:40:13 GMT</pubDate>
    </item>
    <item>
      <title>参数族 $1-e^{-\theta x}$ 的度量熵</title>
      <link>https://stats.stackexchange.com/questions/649121/metric-entropy-for-the-parametric-family-1-e-theta-x</link>
      <description><![CDATA[考虑参数函数类
$$
f_\theta (x) = 1-e^{-\theta x}
$$
定义在区间$[0, 1]$上，并且$\theta \in [0,1]$。
使用 sup-norm，我们可以将函数类的$\delta$覆盖数$N(\delta)$限制为
$$
1 + \lfloor \frac{1-1/e}{2\delta} \rfloor \leq N(\delta) \leq \frac{1}{2\delta} + 2，
$$
（参见 Wainwright 关于 HDS 的教科书示例 5.9。）
我的问题是，如何证明
在此示例中，$\log N(\delta)$ 的渐近速率为 $\log \frac{1}{\delta}$，即
$$
\log N(\delta) \asymp \log \frac{1}{\delta}。
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/649121/metric-entropy-for-the-parametric-family-1-e-theta-x</guid>
      <pubDate>Wed, 12 Jun 2024 18:26:37 GMT</pubDate>
    </item>
    <item>
      <title>Yeo-Johnson 变换的正态逆高斯分布随机变量的闭式 Lambda</title>
      <link>https://stats.stackexchange.com/questions/649116/closed-form-lambda-for-yeo-johnson-transformed-normal-inverse-gaussian-distribut</link>
      <description><![CDATA[我想知道是否存在一个闭式解来表示$\lambda$参数，该解可以最大化 Yeo-Johnson 变换后的随机变量的对数似然函数，这些变量（在变换之前）服从正态-逆高斯分布。
即，给定参数$\mu$、$\delta$、$\beta$和$\alpha$，它们指定正态-逆高斯分布，我的目标是找到Yeo-Johnson 变换参数$\lambda$，该变换最大化对数似然函数（例如此处和此处给出）以封闭形式（而不是从分布中抽样，转换这些采样值，并对各种$\lambda$ 来最大化对数似然函数）。
我怀疑这种闭式解不存在，但我不确定。
任何见解或建议都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649116/closed-form-lambda-for-yeo-johnson-transformed-normal-inverse-gaussian-distribut</guid>
      <pubDate>Wed, 12 Jun 2024 16:57:02 GMT</pubDate>
    </item>
    <item>
      <title>我们能无限次地得到 $|\overline{X}_n - E[X_1]| > \varepsilon$ 吗？</title>
      <link>https://stats.stackexchange.com/questions/649110/can-we-have-overlinex-n-ex-1-varepsilon-infinitely-often</link>
      <description><![CDATA[假设我有一些随机变量，$X_1, X_2, ...$，它们服从相同分布，具有有限期望值，$E[X_1]$，并且它们满足大数定律的要求。设
$$\overline{X}_n = \frac{X_1 + \cdots + X_n}{n}.$$
LLN 在概率和 a.s 上都表示$\overline{X}_n \to E[X_1]$。但是，我的问题是：对于某些 $\varepsilon &gt; 0$，$|\overline{X}_n - E[X_1]| &gt; \varepsilon$ 是否可能无限次地以非零概率发生？为此，我们是否需要方差无限大，还是可以用有限方差来实现？$X_i$ 是否独立重要吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649110/can-we-have-overlinex-n-ex-1-varepsilon-infinitely-often</guid>
      <pubDate>Wed, 12 Jun 2024 15:52:54 GMT</pubDate>
    </item>
    </channel>
</rss>