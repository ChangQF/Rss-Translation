<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 28 May 2024 03:15:57 GMT</lastBuildDate>
    <item>
      <title>关于贝叶斯统计的问题（来自DSP估计理论书）</title>
      <link>https://stats.stackexchange.com/questions/648113/question-about-bayesian-stats-from-a-dsp-estimation-theory-book</link>
      <description><![CDATA[摘自“统计信号处理基础知识，第一卷：估计理论”
&lt;块引用&gt;
估计理论的一个基本规则是使用先验
知识将导致更准确的估计。例如，如果一个
参数被限制在一个已知的区间内，那么任何好的
估计器应该只生成该区间内的估计值。在
例3.1显示$A$的MVU估计器是样本
意思是 $\bar{x}$。但是，这假设 $A$ 可以采用任何值
在区间 $-\infty 中。由于身体条件的限制，可能
更合理的假设是 $A$ 只能采用
有限区间$-A_0 \leq A \leq A_0$。将 $\hat{A}=\bar{x}$ 保留为
最好的估计器是不可取的，因为 $\hat{A}$ 可能会产生
超出已知区间的值。如图10.1a所示，这是
由于噪声的影响。当然，我们希望能够改善我们的
如果我们使用截断样本均值估计器进行估计 $$
&gt; \check{A}=\left\{\begin{array}{cc}
&gt; -A_0 &amp; \bar{x}&lt;-A_0 \\ \bar{x} &amp; -A_0 \leq \bar{x} \leq A_0 \\ A_0 &amp; \bar{x}&gt;A_0\end{array}\right。 $$ 这将与
已知的限制。这样的估计器将具有 PDF $$
&gt; \begin{对齐} &amp; p_{\tilde{A}}(\xi ; A)=\quad
&gt; \operatorname{Pr}\left\{\bar{x} \leq-A_0\right\}
&gt; \delta\left(\xi+A_0\right) \\ &amp;+p_{\hat{A}}(\xi ;
&gt; A)\left[u\left(\xi+A_0\right)-u\left(\xi-A_0\right)\right] \\
&gt; &amp;+\operatorname{Pr}\left\{\bar{x} \geq A_0\right\}
&gt; \delta\left(\xi-A_0\right) \end{对齐} $$
其中 u(x) 是单位阶跃函数。如图所示
10.1b。


我对这个方程感到困惑
\begin{对齐}
&amp; \operatorname{Pr}\left\{\bar{x} \leq-A_0\right\} \delta\left(\xi+A_0\right) \\
&amp; \quad+p_{\hat{A}}(\xi ; A)\left[u\left(\xi+A_0\right)-u\left(\xi-A_0\right)\right] \\
&amp; \quad+\operatorname{Pr}\left\{\bar{x} \geq A_0\right\} \delta\left(\xi-A_0\right)
\end{对齐}
我知道 $u\left(\xi+A_0\right)-u\left(\xi-A_0\right)$ 是一个矩形脉冲“窗户” $-A_0$ 和 $A_0$ 之间的高斯 pdf；看起来像下面这样

我不明白等式的这一部分
\begin{对齐}
 \operatorname{Pr}\left\{\bar{x} \leq-A_0\right\} \delta\left(\xi+A_0\right) \quad ,\operatorname{Pr}\left\{\bar{x } \geq A_0\right\} \delta\left(\xi-A_0\right)
\end{对齐}
为什么他们使用 Pr{} 而不是 $p_{\hat{A}}(\xi ; A)$？为什么他们要把它与位移狄拉克三角洲相乘？]]></description>
      <guid>https://stats.stackexchange.com/questions/648113/question-about-bayesian-stats-from-a-dsp-estimation-theory-book</guid>
      <pubDate>Tue, 28 May 2024 02:34:57 GMT</pubDate>
    </item>
    <item>
      <title>帮助解释卡方的使用以确定赛道是否有具有优势的车道</title>
      <link>https://stats.stackexchange.com/questions/648112/help-interpreting-the-use-of-chi-square-to-determine-if-race-course-has-any-lane</link>
      <description><![CDATA[情况是这样的。  假设您有一个赛道，其中 1-8 号泳道位于水上，并且怀疑某些泳道比其他泳道更快。更快的车道将有更多更高的位置（第一、第二等）。假设您举办了 100 场比赛，但没有足够的参赛者来填满赛道，因此为简单起见，比赛从泳道 1 开始填满，直到比赛满为止。大多数赛事很少满员，因此外部泳道的数据较少，这可能是此分析的问题。
假设参赛者被随机放置在球场上从泳道 1 向外的位置，并且不按能力选择。
使用一些随机数据来模拟均匀概率的比赛。
# 随机数据（作为示例）
随机数据 = {
    &#39;lane_1&#39;: np.random.choice(range(1, 9), 92, p=[1/8]*8).tolist(),
    &#39;lane_2&#39;: np.random.choice(range(1, 9), 93, p=[1/8]*8).tolist(),
    &#39;lane_3&#39;: np.random.choice(range(1, 9), 91, p=[1/8]*8).tolist(),
    &#39;lane_4&#39;: np.random.choice(range(1, 9), 90, p=[1/8]*8).tolist(),
    &#39;lane_5&#39;: np.random.choice(range(1, 9), 88, p=[1/8]*8).tolist(),
    &#39;lane_6&#39;: np.random.choice(range(1, 9), 76, p=[1/8]*8).tolist(),
    &#39;lane_7&#39;: np.random.choice(range(1, 9), 64, p=[1/8]*8).tolist(),
    &#39;lane_8&#39;: np.random.choice(range(1, 9), 34, p=[1/8]*8).tolist()
}

因此，第 1 泳道有 92 个项目（有一些取消参赛资格的赛事），第 2 泳道有 93 个……等等。以下是热图示例。

和卡方结果：
&lt;前&gt;&lt;代码&gt;卡方：55.82543521120111
p 值：0.23376772081410768
自由度：49

现在看看它与卡方拟合相比如何拟合。所以我执行以下操作：
列联表：首先，构建一个列联表，其中行代表泳道，列代表位置。表中的每个单元格包含观察到的该车道和位置的比赛结果频率。
卡方检验：然后对此列联表执行卡方检验，以确定观察到的频率是否与泳道和位置之间独立性零假设下的预期频率显着不同。 
预期频率：作为卡方检验的一部分，在独立性假设下计算列联表中每个单元格的预期频率。这些预期频率代表了如果车道和位置之间没有关系的情况下的预期频率。
热图可视化：最后，以热图格式可视化预期频率。热图中的每个单元格代表原假设下该车道和位置的比赛结果的预期频率。颜色强度表示预期频率的大小，颜色强度越高表示预期频率越高。

这就是一些统一随机数据的样子。  现在有一些真实数据：
&lt;前&gt;&lt;代码&gt;数据 = {
    &#39;1&#39;: {&#39;1&#39;: 37, &#39;2&#39;: 17, &#39;3&#39;: 10, &#39;4&#39;: 12, &#39;5&#39;: 11, &#39;6&#39;: 3, &#39;7&#39;: 2, &#39;dq&#39; : 1},
    &#39;2&#39;: {&#39;1&#39;: 16, &#39;2&#39;: 31, &#39;3&#39;: 19, &#39;4&#39;: 8, &#39;5&#39;: 5, &#39;6&#39;: 9, &#39;7&#39;: 3, &#39;dq&#39; : 2},
    &#39;3&#39;: {&#39;1&#39;: 15, &#39;2&#39;: 16, &#39;3&#39;: 21, &#39;4&#39;: 15, &#39;5&#39;: 9, &#39;6&#39;: 7, &#39;7&#39;: 4, &#39;8&#39; : 3, &#39;dq&#39;: 1},
    &#39;4&#39;: {&#39;1&#39;: 10, &#39;2&#39;: 11, &#39;3&#39;: 22, &#39;4&#39;: 17, &#39;5&#39;: 17, &#39;6&#39;: 8, &#39;7&#39;: 4, &#39;dq&#39; : 1},
    &#39;5&#39;: {&#39;1&#39;: 4, &#39;2&#39;: 10, &#39;3&#39;: 9, &#39;4&#39;: 23, &#39;5&#39;: 18, &#39;6&#39;: 10, &#39;7&#39;: 8, &#39;8&#39; : 5, &#39;dq&#39;: 1},
    &#39;6&#39;: {&#39;1&#39;: 5, &#39;2&#39;: 6, &#39;3&#39;: 5, &#39;4&#39;: 5, &#39;5&#39;: 14, &#39;6&#39;: 15, &#39;7&#39;: 13, &#39;8&#39; : 8},
    &#39;7&#39;: {&#39;1&#39;: 6, &#39;2&#39;: 5, &#39;3&#39;: 8, &#39;4&#39;: 7, &#39;5&#39;: 11, &#39;6&#39;: 9, &#39;7&#39;: 13, &#39;8&#39; : 5},
    &#39;8&#39;: {&#39;1&#39;: 1, &#39;2&#39;: 1, &#39;4&#39;: 2, &#39;5&#39;: 1, &#39;6&#39;: 10, &#39;7&#39;: 12, &#39;8&#39;: 17}
}

这会产生以下比较图表：

和卡方
&lt;前&gt;&lt;代码&gt;卡方：311.8435818023394
p 值：3.446800747358413e-37
自由度：56

除了看起来存在偏差之外，是否有更好的方法来量化或解释结果？我不太精通统计，因为我的背景是编程。这项技术是其他人向我建议的。然而，我不完全掌握测试或解释它的最佳方法。或者有更好的方法吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/648112/help-interpreting-the-use-of-chi-square-to-determine-if-race-course-has-any-lane</guid>
      <pubDate>Tue, 28 May 2024 02:09:46 GMT</pubDate>
    </item>
    <item>
      <title>使用 WAIC 和 WAIC 自由度测试两个模型之间的差异</title>
      <link>https://stats.stackexchange.com/questions/648111/testing-difference-between-two-models-using-waic-and-degrees-of-freedom-of-waic</link>
      <description><![CDATA[我正在 R 中使用 bayesreg 包进行贝叶斯惩罚回归，特别是马蹄形回归 请参阅此处。一个模型嵌套在另一个模型中，即对于第二个模型，我简单地使用了第一个模型中存在的所有预测变量，并添加了几个预测变量。
我想测试我添加到第二个模型中的预测变量是否添加了足够的解释力来保证将其包含在内，如果没有，我将简单地使用第一个模型。在频率统计中，我可以通过似然比检验来回答这个问题，取两个模型之间的偏差差异，并查看结果值是否超过临界值（例如 $\alpha &lt; ; .05$) 的卡方分布，其自由度等于两个模型的自由度差。
bayesreg::bayesreg 函数的两个输出是 waic，在帮助中将其描述为“广泛适用的信息标准 (WAIC)”模型的得分”，以及 waic.dof，其被描述为“模型的有效自由度，由 WAIC 估计” &gt;.
对于我的两个模型，WAIC 如下（模型 2 更复杂的模型）：模型 1 = 1043.902，模型 2 = 1046.783。
两个模型的有效自由度为：模型 1 = 22.9001，模型 2 = 28.35734
显然，更复杂的模型并没有增加太多的解释力，我可能只会使用更简单的模型，但我想要一些正式的方法来证明我不使用更复杂模型的决定，类似于似然比检验的概念。
我的问题是有人知道使用 WAIC 和有效自由度测试两个模型之间差异的正式方法吗？
非常感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/648111/testing-difference-between-two-models-using-waic-and-degrees-of-freedom-of-waic</guid>
      <pubDate>Tue, 28 May 2024 00:21:45 GMT</pubDate>
    </item>
    <item>
      <title>生成模型中的不确定性如何传播到整体对数似然？</title>
      <link>https://stats.stackexchange.com/questions/648110/how-can-uncertainties-in-a-generative-model-be-propagated-to-an-overall-log-like</link>
      <description><![CDATA[我正在尝试使用贝叶斯方法来进行模型选择并估计峰值拟合场景（准弹性中子散射）中参数的后验分布。生成模型可以用以下方式描述：
$y_{m, calc}(x_m, \Theta) = R(x_m) \circledast \left[f_0(x_m, \theta_0)+f_1(x_m, \theta_1) )+...+f_n(x_m, \theta_n)\right]$
即n 个函数的总和，然后与仪器响应函数 R 进行卷积。n 个函数中的每一个都有一组参数 $\theta_n$，其走向制作整体参数向量，$\Theta$。
如果 R 是解析的，那么计算测量数据的对数似然就很简单。
$\ln p(y|x, \Theta) = -0.5 * \sum_m [(\frac{y_{m, calc}(x_m, \Theta) - y_ {m, obs}}{\sigma_m})^2 + \ln(2\pi \sigma_m^2)]$
其中$\sigma_m$是m个测量点的不确定度，$y_{m, obs}$&lt; /span&gt;.
到目前为止，这是一个“正常”非线性最小二乘问题（$f_n$ 是非线性的）。
但是，如果响应函数 R 不再是解析函数，但由于是测量的，因此也具有实验不确定性，我不知道如何修改对数似然。
任何人都可以提供有关此主题的指导吗？或者它更适合例如堆栈溢出？]]></description>
      <guid>https://stats.stackexchange.com/questions/648110/how-can-uncertainties-in-a-generative-model-be-propagated-to-an-overall-log-like</guid>
      <pubDate>Tue, 28 May 2024 00:00:07 GMT</pubDate>
    </item>
    <item>
      <title>分割 3D 架构</title>
      <link>https://stats.stackexchange.com/questions/648109/segmentation-3d-architectures</link>
      <description><![CDATA[我想请您为我的问题提供最佳解决方案。我有一个任务，根据对象的部分信号对其进行分割。也就是说，我有大小为 T x H x W 的输入对象，其中 T 是时间。在输出端，我想要获得大小为 D x H x W 的体积掩模。也就是说，粗略地说，我有一组 T 秒的信号图像。
我正在尝试使用 3D 卷积及其相关架构来解决这个问题。我已经尝试过 Unet3D、AttentionUnet3D、UNETR、TransU
net。这些是我尝试过的最基本的。到目前为止，我的主要问题是传统的 2D 分割网络在训练时间方面优于 3D 网络，但质量并没有显著提高。您能给我一些建议，告诉我应该尝试什么吗？
如果我的问题看起来有点模糊，那么这里有两个问题我想得到答案。

对于开头和结尾的不同张量，您推荐什么架构？（例如，让输入为 150 x 100 x 100，输出为 30 x 100 x 100）
在这种情况下，最佳损失是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648109/segmentation-3d-architectures</guid>
      <pubDate>Mon, 27 May 2024 23:27:34 GMT</pubDate>
    </item>
    <item>
      <title>系列对象和摘要输出之间不兼容的置信区间</title>
      <link>https://stats.stackexchange.com/questions/648106/incompatible-confidence-intervals-between-the-series-object-and-the-summary-outp</link>
      <description><![CDATA[我遇到了 CausalImpact 包的奇怪行为，我不知道如何解释。下面是一个可重现的示例
库(tidyverse)
图书馆（因果影响）
#&gt;加载所需包：bsts
#&gt;加载所需包：BoomSpikeSlab
#&gt;加载所需包：Boom
#&gt; 
#&gt;附加包：“Boom”
#&gt;以下对象被“package:stats”屏蔽：
#&gt; 
#&gt;     威沙特
#&gt; 
#&gt;附加包：“BoomSpikeSlab”
#&gt;以下对象被“package:stats”屏蔽：
#&gt; 
#&gt;     结
#&gt;加载所需包：zoo
#&gt; 
#&gt;附加包：&#39;zoo&#39;
#&gt;以下对象被“package:base”屏蔽：
#&gt; 
#&gt;     as.Date、as.Date.numeric
#&gt;加载所需包：xts
#&gt; 
#&gt; #########################来自“xts”包的警告################## #######
#&gt; ##
#&gt; # dplyr lag() 函数打破了基础 R 的 lag() 函数的预期 #
#&gt; # 工作，打破滞后（my_xts）。调用您键入的 lag(my_xts) 或 #
#&gt; # source() 进入此会话将无法正常工作。                            #
#&gt; ##
#&gt; # 使用 stats::lag() 确保您没有使用 dplyr::lag()，或者您可以添加 #
#&gt; #将conflictRules(&#39;dplyr&#39;, except = &#39;lag&#39;)添加到你的.Rprofile中以停止#
#&gt; # dplyr 破坏了基础 R 的 lag() 函数。                                #
#&gt; ##
#&gt; # 包中的代码不受影响。它受到 R 的命名空间机制的保护#
#&gt; # 设置 `options(xts.warn_dplyr_breaks_lag = FALSE)` 来抑制此警告。  #
#&gt; ##
#&gt; #################################################### #############################
#&gt; 
#&gt;附加包：&#39;xts&#39;
#&gt;以下对象被“package:dplyr”屏蔽：
#&gt; 
#&gt;     第一个，最后一个
#&gt; 
#&gt;附加包：&#39;bsts&#39;
#&gt;以下对象被“package:BoomSpikeSlab”屏蔽：
#&gt; 
#&gt;     建议刻录
设置.种子(1)
x1 &lt;- 100 + arima.sim(模型 = 列表(ar = 0.999), n = 100)
y &lt;- 1.2 * x1 + rnorm(100)
y[71:100] &lt;- y[71:100] + 10
数据 &lt;- cbind(y, x1)

前期 &lt;- c(1, 70)
后期 &lt;- c(71, 100)


影响 &lt;- CausalImpact(数据, 前期, 后期)

# 输出1
影响$系列|&gt; 
  数据.frame() |&gt; 
  切片（71：100）|&gt; 
  rownames_to_column(var = “时间”) |&gt; 
  蒂布尔（）|&gt;  
  总结（
    跨（c（响应，point.pred，包含（“point.effect”）），平均值），
  ）
#&gt; # 小标题：1 × 5
#&gt;   响应点.预测点.效应点.效应.下限.效应.上限
#&gt;                                                
#&gt; 1 117. 107. 10.5 7.80 13.3


# 输出2
影响$摘要
#&gt;               实际 Pred Pred.lower Pred.upper Pred.sd AbsEffect
#&gt;平均 117.0485 106.5372 105.8365 107.2868 0.3724158 10.51134
#&gt;累计 3511.4555 3196.1154 3175.0955 3218.6046 11.1724731 315.34013
#&gt;            AbsEffect.lower AbsEffect.upper AbsEffect.sd RelEffect
#&gt;平均 9.761698 11.212 0.3724158 0.09873264
#&gt;累计 292.850949 336.360 11.1724731 0.09873264
#&gt;            RelEffect.lower RelEffect.upper RelEffect.sd alpha p
#&gt;平均 0.09098693 0.105937 0.003841021 0.05 0.001003009
#&gt;累计 0.09098693 0.105937 0.003841021 0.05 0.001003009

创建于 2024 年 5 月 27 日，使用 reprex v2.1.0
您可以看到效果估计完全相同，但从 impact$series 和 impact$summary 生成的置信区间不同。我尝试使用不同的数据集，得到相同的结果。
有什么想法吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/648106/incompatible-confidence-intervals-between-the-series-object-and-the-summary-outp</guid>
      <pubDate>Mon, 27 May 2024 22:41:37 GMT</pubDate>
    </item>
    <item>
      <title>SPSS 中的正态分布 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648105/normal-distribution-in-spss</link>
      <description><![CDATA[我必须写一篇研究论文，在我在 SPSS 中用 kolgoomorov 测试检查我的分布后，我的 10 个变量中只有 3 个没有意义，我用计算中的 IDF 正态对它们进行了标准化，我只有 2 个显着变量但他们的 z 分数没有达到 -1.96 和 +1.96 限制，他们可以解释为正态分布吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648105/normal-distribution-in-spss</guid>
      <pubDate>Mon, 27 May 2024 21:36:16 GMT</pubDate>
    </item>
    <item>
      <title>Minitab 标准化效应背后的数学</title>
      <link>https://stats.stackexchange.com/questions/648104/math-behind-the-standardized-effects-from-minitab</link>
      <description><![CDATA[我想了解 Minitab 等标准化效应 (SE) 背后的数学原理。我远不是统计学专家，但我发现 此页面处理相同的问题。然而，接受的答案仅显示如何计算主效应 A、B 和 C 等的 SE。SE 定义为每个参数的 +1 水平和 -1 水平的所有响应平均值之间的差异。我还想知道的是如何计算交叉项（例如AB，甚至AB*C）的SE（效果和系数）。如何定义交叉项的 +1 和 -1 水平？]]></description>
      <guid>https://stats.stackexchange.com/questions/648104/math-behind-the-standardized-effects-from-minitab</guid>
      <pubDate>Mon, 27 May 2024 21:20:10 GMT</pubDate>
    </item>
    <item>
      <title>动态选择唯一访客</title>
      <link>https://stats.stackexchange.com/questions/648101/choosing-a-unique-visitor-on-the-fly</link>
      <description><![CDATA[我一直认为这是“本周的奖项”问题。假设您经营一家商店，并且希望每周向随机选择购买的人发放一次奖品。您在购买时发放奖品，但希望确保每周发放一份奖品。选择是否将奖品作为给定交易的一部分授予的最佳方式是什么？
作为第一个近似值，我可以以每周平均交易数 1 的概率随机选择。一旦颁发了奖品，直到新的一周开始我才能检查，一周内不得颁发超过一个奖品。
但这并不能解决没有人被选中的可能性。看来，到本周末，获奖的可能性应该会上升。我可以查找该发行版的名称以供进一步阅读吗？
我意识到这个问题没有完美的解决方案。通常周五很忙，但偶尔也会有午饭后没人进来的情况。我还在寻找有关如何对此进行建模并根据典型行为限制未能奖励的概率的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/648101/choosing-a-unique-visitor-on-the-fly</guid>
      <pubDate>Mon, 27 May 2024 20:49:08 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中预测斜率不断变化的增长时间序列？</title>
      <link>https://stats.stackexchange.com/questions/648054/how-to-predict-a-growing-time-series-with-changing-slopes-in-python</link>
      <description><![CDATA[我有一个单变量时间序列数据集，它表示持续增长的趋势，但斜率以不同的间隔变化。我想预测这个时间序列的未来值。
以下是一些关键细节：
该系列一直在增加。
斜率在不同点发生变化。
数据只有一个变量。
我正在寻找合适的模型或方法来准确预测未来价值。
我需要在测试集之外执行预测，这意味着使用预测来迭代地进一步预测未来。
到目前为止，我已经考虑过线性回归，但它不能很好地处理不断变化的斜率。我也研究过 ARIMA，但我不确定如何针对这种情况配置它。
任何人都可以推荐适当的 Python 模型或技术来处理这种类型的时间序列吗？示例或教程参考将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/648054/how-to-predict-a-growing-time-series-with-changing-slopes-in-python</guid>
      <pubDate>Mon, 27 May 2024 07:56:10 GMT</pubDate>
    </item>
    <item>
      <title>如果一组患者呈正态分布，而另外两组则不是，如何比较三组患者？</title>
      <link>https://stats.stackexchange.com/questions/647839/how-to-compare-three-groups-of-patients-if-one-group-is-normally-distributed-but</link>
      <description><![CDATA[涉及三组患者的回顾性研究。第 1 组是被诊断患有败血症的患者。第 2 组是被诊断患有局部感染的患者。第3组是“健康的”控制。我正在查看血液分析仪上可用的称为细胞群数据的参数。例如，CPD 参数 LY-X 在第 2 组和第 3 组中呈正态分布，但在第 3 组中不显示正态分布。我使用 SPSS 中的 Shapiro Wilks 来评估正态性。我这样做是为了确定我是否需要参数或非参数测试。我还尝试将数据转换为日志，但这并没有改变结果。我不知道如何比较三组患者，其中两组患者是正态分布的，一组不是正态分布的。如果所有三个组都保持一致，事情会更容易。我希望这是有道理的。我没有统计背景，我的大学不会提供任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/647839/how-to-compare-three-groups-of-patients-if-one-group-is-normally-distributed-but</guid>
      <pubDate>Thu, 23 May 2024 16:57:20 GMT</pubDate>
    </item>
    <item>
      <title>协方差的不同度量</title>
      <link>https://stats.stackexchange.com/questions/647761/different-measures-of-covariances</link>
      <description><![CDATA[假设我有两个随机时间序列变量，$X$ 和~$Y,$ 以及
特定的实现 $x_{t}$ 和 $y_{t}.$ 假设我发现
$cov\left(X,Y\right)&gt;0.$ 这对 i) 意味着什么 $cov( \三角形X，\三角形Y)$
其中 $\triangle$ 是相对于时间的（第一个）差分运算符
$t$ 和 ii) $cov(\triangle log(X),\triangle log(Y))$ 其中 $\triangle log$
对应于 $X$ 和 $Y$ 的大致百分比变化
相邻的时间段。直觉是什么？一个例子是非常
有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/647761/different-measures-of-covariances</guid>
      <pubDate>Wed, 22 May 2024 13:53:48 GMT</pubDate>
    </item>
    <item>
      <title>关于线性回归的基本数据清理的问题</title>
      <link>https://stats.stackexchange.com/questions/647593/questions-on-basic-data-cleansing-for-linear-regression</link>
      <description><![CDATA[我正在遵循一些有关进行线性回归的教程，并且在构建笔记本时，我正在研究异常值检测，并且在用于进行异常值检测的技术中，其中之一涉及计算标准偏差，但是对于我需要知道我的列是否服从高斯分布。我知道有不同的技术，例如：
直方图
KDE 图
Q-Q图
科洛莫戈洛夫-斯米尔诺夫检验
夏皮罗-威尔克检验
达戈斯蒂诺和皮尔逊检验
我敢打赌还有更多。那么最好使用哪一种呢？我想直方图只是提供了线索，但并没有显示出真正的意图。识别数据集是否为高斯分布的标准做法是什么？例如，我绘制了波士顿数据集和 RM 列的直方图（每间住宅的平均房间数），我发现它是高斯分布：

但是当我使用 shapiro 和 kstest 时，它说 RM 不是高斯！
对于 X.columns 中的 i：
    print(f&#39;{i}: {“非高斯” if shapiro(X[i])[1]&lt;0.05 else “高斯”} {shapiro(X[i])}&#39;)
    print(f&#39;{i}: {“非高斯” if kstest(X[i].values,“范数”)[1]&lt;0.05 else “高斯”} {kstest(X[i].values) ,“标准”)}&#39;)

上面的代码打印：
RM：非高斯 ShapiroResult（统计=0.9608722575483464，pvalue=2.411976537849353e-10）
RM：非高斯 KstestResult（统计=0.9998152774582629，pvalue=0.0，statistic_location=3.561，statistic_sign=-1）

怎么会这样呢？我应该相信什么？
此外，我计算了零和 NaN 的数量，如下所示：
列 ZN：零 = 372，NaN = 0
CHAS 列：零 = 471，NaN = 0

查看这些列的含义：
ZN - 划分为 25,000 平方英尺以上地块的住宅用地比例。
CHAS - 查尔斯河虚拟变量（如果区域边界为河流，则为 1；否则为 0）

我如何决定将它们作为特征列还是忽略它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/647593/questions-on-basic-data-cleansing-for-linear-regression</guid>
      <pubDate>Mon, 20 May 2024 05:21:30 GMT</pubDate>
    </item>
    <item>
      <title>缩减长轴回归是总最小二乘法的特例吗？</title>
      <link>https://stats.stackexchange.com/questions/647178/is-reduced-major-axis-regression-a-special-case-of-total-least-squares</link>
      <description><![CDATA[我正在阅读https://influenceialpoints.com/训练/errors-in-variables_regression-principles-properties-assections.htm
这表示总最小二乘法有以下解决方案：

然而，后来似乎表明，当两个方差之间的比率为 $\lambda = V_{x}/V_{ 时，减少的长轴回归是这种情况的特殊情况y}$。   具体来说，它说

但是，它随后给出以下公式作为 $\beta_{1}$ 的解：

但是，当 $\lambda = V_{x}/V_{y}$ 时，我无法确定这实际上是上面更通用的解决方案的特殊情况。  当我尝试将此比率插入 $\lambda$ 时，我无法将其简化为标准差之比，而这应该是解决方案。
我还有两个问题。  首先，从概念上讲，为什么减少垂直残差平方和水平残差平方的加权和会得到与减少水平残差和垂直残差的乘积相同的答案并不明显，我相信这就是 RMA（减少长轴）回归应该做的做。
其次，共识似乎是 RMA 不能用于测试 $H_{null}:Beta_{1}=0$。  但我猜想可以用总最小二乘法来检验这个假设。  那么为什么 $\lambda = V_{x}/V_{y}$ 的这种特殊情况会使 $beta_{1 }=0$ 无法测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/647178/is-reduced-major-axis-regression-a-special-case-of-total-least-squares</guid>
      <pubDate>Tue, 14 May 2024 01:31:00 GMT</pubDate>
    </item>
    <item>
      <title>批次不同重复次数的均值标准误差</title>
      <link>https://stats.stackexchange.com/questions/647156/standard-error-of-mean-with-varying-replicates-for-batches</link>
      <description><![CDATA[我进行了三批模拟，并从中计算出特定的属性（对于问题来说并不重要）。我想计算这三个批次的组合 SEM
批量| #样本|平均 |标准差|标准错误
B1 |     n1 |     x1 |          sd1 |          硒1
B2 |     n2|     x2 |          SD2 |          硒2
B3 |     n3 |     x3 |          SD3 |          硒3
我的做法如下
SE_combined = $\sqrt{\frac{(n1-1)se1^2 + (n2-1)se2^2 + (n3-1)se3^2}{n1+n2 +n3-3}}$
这是正确的方法吗？另外，我需要一些论文/书籍参考以供引用。任何帮助都会非常有帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/647156/standard-error-of-mean-with-varying-replicates-for-batches</guid>
      <pubDate>Mon, 13 May 2024 16:39:59 GMT</pubDate>
    </item>
    </channel>
</rss>