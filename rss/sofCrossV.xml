<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 21 Nov 2024 03:28:26 GMT</lastBuildDate>
    <item>
      <title>批量计算 STS 分数或 EuroScore 3</title>
      <link>https://stats.stackexchange.com/questions/657593/batch-computation-of-sts-score-or-euroscore-3</link>
      <description><![CDATA[是否有用于批量计算 STS 评分或 EuroScore 3 的 R 包？（这些是预测心脏手术死亡率的模型。）我设法找到的唯一包是 https://github.com/meyera/riskscorer/，其历史可追溯到 2016 年，因此已经过时且不起作用。]]></description>
      <guid>https://stats.stackexchange.com/questions/657593/batch-computation-of-sts-score-or-euroscore-3</guid>
      <pubDate>Thu, 21 Nov 2024 02:26:27 GMT</pubDate>
    </item>
    <item>
      <title>难以浏览熊猫文档</title>
      <link>https://stats.stackexchange.com/questions/657591/dificulty-navigating-pandas-documentation</link>
      <description><![CDATA[我想绘制一个箱线图，它不会在 IQR*1.5 处停止，而是一直延伸，不对异常值进行分类
事实证明，Chatgpt 知道答案
ax = df_heights[&#39;height&#39;].plot.box(sym=&#39;&#39;)
但是，我找不到此 sym 参数的文档！
我去了
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.box.html#pandas.DataFrame.plot.box
然后寻找“其他关键字”在
https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot
按照说明操作。但我在那里找不到该参数。
我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657591/dificulty-navigating-pandas-documentation</guid>
      <pubDate>Thu, 21 Nov 2024 01:56:51 GMT</pubDate>
    </item>
    <item>
      <title>人体新陈代谢统计数据的准确性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657590/accuracy-of-statistics-on-human-metabolism</link>
      <description><![CDATA[体重 100 公斤的人每五秒钟站立一次，消耗 10,000 卡路里。关于人类活动，最简单的动能计算驳斥了能量守恒定律。
我们使用 pe=mgh。体重 100 公斤的人站立 1 米的势能为 1kj。每五秒钟，这相当于 200 瓦。生物利用度为 50% 时，食物能量为 400 瓦。
5mj 为 1000 卡路里。体重 100 公斤的人每五秒钟站立一次，消耗 20mj。100 瓦基础代谢为 10mj。
每次心跳将 5 公斤血液移动 1 米，消耗 50 瓦。血液中的氧气是固体，密度是空气的 877 倍。对于 10 克空气，1 个大气压下的 877 倍压缩是 2100 万焦耳。将 10 克空气压缩成固体血红素需要 2100 万焦耳，因为氧气作为固体比作为气体密度高 877 倍。
体积守恒似乎是正确的，能量守恒是一个过时的理论。我听过这种解释，但我不是在问它。
如果一个人不使用肌肉能量，他会因重力而坠落 1 米。9.81 m/s2 的加速度导致坠落过程中的速度为 4.5 m/s。在这个速度下 100 公斤是 2kj。如果您必须逆转这种能量才能站立，那么在这种情况下，它是 500 瓦，生物利用度为 1kw。
这意味着动能计算得出每天 100mj 或 20,000 卡路里。
同样，一个体重 100 公斤的人每五秒钟站立一次，就是 3000 万焦耳或 6,000 卡路里。我如何将这个统计数据与能量守恒定律相协调？请不要说能量守恒定律是假的，即使这是 stack exchange 上的主流观点。]]></description>
      <guid>https://stats.stackexchange.com/questions/657590/accuracy-of-statistics-on-human-metabolism</guid>
      <pubDate>Thu, 21 Nov 2024 01:53:14 GMT</pubDate>
    </item>
    <item>
      <title>多目标结构因果赌博机</title>
      <link>https://stats.stackexchange.com/questions/657589/multi-objective-structural-causal-bandits</link>
      <description><![CDATA[我正在阅读 Lee &amp; Bareinboim (2018) 的论文“结构因果赌博：在哪里进行干预？”。这里有一个链接：https://papers.nips.cc/paper_files/paper/2018/file/c0a271bc0ecb776a094786474322cb82-Paper.pdf
我试图将他们的结果扩展到多目标情况，也就是说，有多个目标变量$\mathbf{Y} = \{Y_1,\dots,Y_m \}$。以下是对可能最优最小干预集的重新表述：
定义。给定$\langle \mathcal{G}, \mathbf{Y}, \mathbf{X} \rangle$，设$\mathbf{X}_s$为最小干预集，且$\mathbf{x}_s \in \mathcal{D}(\mathbf{X}_s)$。然后，如果不存在其他最小干预集$\mathbf{X}_s&#39;$和$\mathbf{x}_s&#39; \in \mathcal{D}(\mathbf{X}_s&#39;)$且$\mathbb{E}[Y_i | \text{do}(\mathbf{X}_s = \mathbf{x}_s)] \geq \mathbb{E}[Y_i | \text{do}(\mathbf{X}_s&#39;=\mathbf{x}_s&#39;)]$ 对所有 $1 \leq i \leq m$ 且 $\mathbb{E}[Y_i | \text{do}(\mathbf{X}_s = \mathbf{x}_s)] &gt; \mathbb{E}[Y_i | \text{do}(\mathbf{X}_s&#39;=\mathbf{x}_s&#39;)]$ 至少有一个 $1 \leq i \leq m$，对于某些符合 $\mathcal{G}$ 的 SCM。
我想证明多目标情况下的命题 2。以下是多目标情况下命题的重新表述以及我得出的证明：
命题。如果没有 $Y_i$ 与 $\text{an}(Y_i)_{\mathcal{G}}$ 通过未观察到的混杂因素而混淆，则 $\text{pa}(\mathbf{Y})_{\mathcal{G}}$ 是唯一可能最优的最小干预集。
证明。
让 $\mathbf{X}_s$ 成为最小干预集，并且 $\mathbf{x}_s \in \mathcal{D}(\mathbf{X}_s)$。设 $\mathbf{X}_s&#39; = \text{pa}(\mathbf{Y})_{\mathcal{G}}$ 且 $\mathbf{Z} = \mathbf{X}_s&#39; \backslash (\mathbf{X}_s \cap \mathbf{X}_s&#39;)$。然后，对于所有 $i=1,\dots,m$ 它都成立
\begin{align}
\mathbb{E}[Y_i | \text{do}(\mathbf{X}_s=\mathbf{x}_s)] &amp;= \int_{\mathcal{D}(\mathbf{Z})} \mathbb{E}[Y_i | \text{do}(\mathbf{X}_s=\mathbf{x}_s), \mathbf{Z} = \mathbf{z}] P(\mathbf{Z} = \mathbf{z} | \text{do}(\mathbf{X}_s=\mathbf{x}_s)) d\mathbf{z} \\
    &amp;= \int_{\mathcal{D}(\mathbf{Z})} \mathbb{E}[Y_i | \text{do}(\mathbf{X}_s=\mathbf{x}_s, \mathbf{Z} = \mathbf{z})] P(\mathbf{Z} = \mathbf{z} | \text{do}(\mathbf{X}_s=\mathbf{x}_s)) d\mathbf{z}\\
    &amp;= \int_{\mathcal{D}(\mathbf{Z})} \mathbb{E}[Y_i | \text{do}(\mathbf{X}_s \cap \mathbf{X}_s&#39;=\mathbf{x}_s[\mathbf{X}_s&#39;], \mathbf{Z} = \mathbf{z})] P(\mathbf{Z} = \mathbf{z} | \text{do}(\mathbf{X}_s=\mathbf{x}_s)) d\mathbf{z} \\
    &amp; \geq \int_{\mathcal{D}(\mathbf{Z})} \mathbb{E}[Y_i | \text{do}(\mathbf{X}_s&#39;=\mathbf{x}_s&#39;)] P(\mathbf{Z} = \mathbf{z} | \text{do}(\mathbf{X}_s=\mathbf{x}_s)) d\mathbf{z}\\
&amp; = \mathbb{E}[Y_i | \text{do}(\mathbf{X}_s&#39;=\mathbf{x}_s&#39;)]
\end{align&gt;
其中 $\mathbf{x}_s&#39; \in \mathcal{D}(\mathbf{X}_s&#39;)$ 是非支配干预值。请注意，第二个等式是通过 do-calculus 的第二条规则推导出来的，第三个等式假设 $Y_i$ 不会通过未观察到的混淆因素与 $\text{an}(Y_i)_{\mathcal{G}}$ 混淆。
如果 $\mathbf{X}_s \neq \text{pa}(\mathbf{Y})_{\mathcal{G}}$，则可以构造一个符合 $\mathcal{G}$ 的 \textsc{scm}，使得严格不等式至少对一个 $Y_i$ 成立。这表明$\mathbf{X}_s&#39;$可能是唯一可能最优的最小干预集。
不幸的是，我很确定这个证明是不正确的，因为不等式不需要对所有$\mathbf
{z} \in \mathbf{Z}$都成立。有人能帮我吗？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657589/multi-objective-structural-causal-bandits</guid>
      <pubDate>Thu, 21 Nov 2024 01:15:50 GMT</pubDate>
    </item>
    <item>
      <title>Bai-Ng PC 选择标准在 R 上实施“dfms”的奇怪结果</title>
      <link>https://stats.stackexchange.com/questions/657587/weird-results-from-bai-ng-pcs-selection-criteria-implementation-of-dfms-on-r</link>
      <description><![CDATA[我试图根据 Bai 和 Ng (2002) 在 R 上的最优性标准选择此数据的主成分数量。
来自 dfms 包的函数 ICr 应该可以方便地实现 Bai 和 Ng 程序，但输出对我来说看起来相当奇怪。具体来说，第一个主成分解释了大部分方差，但信息标准似乎建议采用与原始变量数量一样多的因子。
发生了什么？如何解决？
MWE:
library(dfms)

# 加载数据并删除索引列
data &lt;- read.csv(&quot;your/path/to/the/csv&quot;)

# 删除索引列
data &lt;- data[,-1]

# 执行包的函数
ict &lt;- ICr(data, max.r = ncol(data))

# 输出如下图所示
screeplot(ict)
plot(ict)


]]></description>
      <guid>https://stats.stackexchange.com/questions/657587/weird-results-from-bai-ng-pcs-selection-criteria-implementation-of-dfms-on-r</guid>
      <pubDate>Thu, 21 Nov 2024 00:10:12 GMT</pubDate>
    </item>
    <item>
      <title>如何计算对数减少的标准差</title>
      <link>https://stats.stackexchange.com/questions/657586/how-to-calculate-sd-of-a-log-reduction</link>
      <description><![CDATA[我有几个对数值，每个值代表不同的一天，它们都与一个标准差相关联。我必须计算对数减少量，这基本上是第一天的值减去最后一天的值。
如何计算与对数减少量相关的标准差？
谢谢 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/657586/how-to-calculate-sd-of-a-log-reduction</guid>
      <pubDate>Wed, 20 Nov 2024 23:02:03 GMT</pubDate>
    </item>
    <item>
      <title>Mcnemar 检验为 z 检验或卡方检验</title>
      <link>https://stats.stackexchange.com/questions/657582/mcnemar-test-as-z-test-or-chi-squared-test</link>
      <description><![CDATA[我是统计学入门课的助教。我们正​​在向学生介绍 McNemar 检验，以比较相关样本上的两个比例。我注意到教科书中，我们将 Mcnemar 检验定义为遵循 z 分布的 z 统计量：
$$
z = \frac{b-c}{\sqrt{b+c}}
$$
而其他来源，例如维基百科，将检验统计量定义为遵循卡方分布
$$
\chi_1^2 = \frac{(b-c)^2}{b+c}
$$
我从数理统计中得知，z 统计量的平方服从自由度为 1 的卡方分布。
有人知道为什么人们可能更喜欢将一种框架作为 z 检验或将另一种框架作为 z 检验吗？我认为这两个统计数据会产生相同的推论。我怀疑如果学生决定自己阅读这个主题，他们可能会感到困惑。
将测试框架为 z 检验确实允许计算与卡方框架无关的标准误差。]]></description>
      <guid>https://stats.stackexchange.com/questions/657582/mcnemar-test-as-z-test-or-chi-squared-test</guid>
      <pubDate>Wed, 20 Nov 2024 21:28:46 GMT</pubDate>
    </item>
    <item>
      <title>一组不完整集合中的发生推断/统计</title>
      <link>https://stats.stackexchange.com/questions/657580/occurence-extrapolation-statistics-in-a-set-of-incomplete-collections</link>
      <description><![CDATA[我的统计学课程现在还很遥远（我是一名生物学家）。我的问题可能微不足道，但我不知道从哪里开始。
我的目标是计算一组基因组中基因 X 的出现率。基本上，包含感兴趣基因的基因组的比例是多少。问题是基因组很少是完整的。因此，如果没有观察到基因 X，可能是它实际上不在这里，或者它在缺失数据中。但我们可以估计基因组的完整性，即检测到的基因的百分比。如果可能的话，我想考虑到这一点，以获得更正的发生。
这是用非生物学术语对这个问题的“翻译”。

Ci​ ：第 i 个集合（1 到 n）
Si ：集合 Ci​ 中的元素总数。
Ki ：Ci​​ 中已知（非缺失）元素的数量。
Mi ：Ci​​ 中缺失元素的数量。
XCi ：指示变量，如果在集合 Ci​​（已知元素中）中找到元素 X，则为 1，否则为 0否则。

观察到的 X 的发生是：
$$ O_{obs}=\frac{\sum_{i=1}^{n} X_{ci}}{n} $$
如何推断真实发生？有没有办法评估推断或测量发生的稳健性？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657580/occurence-extrapolation-statistics-in-a-set-of-incomplete-collections</guid>
      <pubDate>Wed, 20 Nov 2024 21:07:20 GMT</pubDate>
    </item>
    <item>
      <title>Metropolis-Within-Gibbs 算法的数学参考</title>
      <link>https://stats.stackexchange.com/questions/657579/mathematical-reference-for-metropolis-within-gibbs-algorithm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657579/mathematical-reference-for-metropolis-within-gibbs-algorithm</guid>
      <pubDate>Wed, 20 Nov 2024 21:05:28 GMT</pubDate>
    </item>
    <item>
      <title>DBSCAN 之前数据集中缺少值</title>
      <link>https://stats.stackexchange.com/questions/657578/missing-values-in-data-set-before-dbscan</link>
      <description><![CDATA[我的目标是识别应用程序的机器人和欺诈用户。理想情况下，这将是一个回归问题，其中用户按连续尺度进行评级。我有 4 个表，涵盖了指纹识别和欺诈评分 API 计算出的不同统计数据。这些表按它们涵盖的指标进行划分，即：电子邮件数据、电话数据、IP 数据和指纹数据。
虽然我不确定这些指标是如何计算的，因为它们来自外部 API，但这些数据集包含各种各样的列类型。以下是显示列类型的文档：https://www.ipqualityscore.com/documentation/overview
最后，我想综合创建标签以用于监督机器学习算法，因为我现在拥有的标签不是最好的。我认为我可以通过先聚类来生成标签，或者我可以使用领域知识和规则为监督机器学习生成标签，然后使用隔离森林之类的东西来补充监督部分以保持算法的通用性。
但是，无论我采用哪种方法，通常情况下，用户可能只有来自 1、2 或 3 个来源的数据，而不是全部 4 个来源的数据。我该如何处理此处的缺失数据？例如，用户可能只使用手机注册，而不是电子邮件。
此外，我有大约 50 万个样本，几乎有 100 多个特征。由于每组特征来自不同的表，我应该使用 PCA 来最小化特征数量吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657578/missing-values-in-data-set-before-dbscan</guid>
      <pubDate>Wed, 20 Nov 2024 20:59:44 GMT</pubDate>
    </item>
    <item>
      <title>回归结果 - 解释交互项</title>
      <link>https://stats.stackexchange.com/questions/657576/regression-result-interpretation-interaction-term</link>
      <description><![CDATA[我对如何解释回归结果中的交互项感到困惑。
结果如下：

WorkatHome 是二元变量，当人们在家工作时为 1；否则为 0（在办公室工作）
SingleFamily 也是二元变量，当人们生活在单户住宅中时为 1；否则为 0（住在多户家庭中）

我的解释是“在家工作的人住在单户家庭中时往往比在办公室工作的人有更高的工作满意度”。
我收到一条评论说这种解释是错误的。评论说这种解释应该是与住在多户家庭中的人进行比较。
请帮我理解正确的解释是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/657576/regression-result-interpretation-interaction-term</guid>
      <pubDate>Wed, 20 Nov 2024 20:34:21 GMT</pubDate>
    </item>
    <item>
      <title>显示模型对于 MLE 是可识别的（可估计的）</title>
      <link>https://stats.stackexchange.com/questions/657594/show-model-is-identifiable-estimatable-for-mle</link>
      <description><![CDATA[我正在尝试做一些 MLE 工作，但我的统计学背景非常有限，所以我正在学习。

定义。让 $\mathcal{P} = \{ P_\boldsymbol{\rho} : \boldsymbol{\rho}\in \Theta \}$
成为具有参数空间 $\Theta$ 的统计模型。如果映射 $\rho \mapsto P_{\boldsymbol{\rho}}$ 是一对一的，即对于所有 $\boldsymbol{\rho}_1, \boldsymbol{\rho}_2 \in \Theta$，$P_{\rho_1} = P_{\boldsymbol{\rho}_2} \Rightarrow \boldsymbol{\rho}_1= \boldsymbol{\rho}_2$，则我们说 $\mathcal{P}$ 是可识别的。
我的分布由缩放的非中心 $\chi^2$ 分布，自由度为 $d$，非中心参数为 $\lambda$，参数为 $\boldsymbol{\rho}=(\kappa, \theta,\sigma)$，其中 $$
d=4 \kappa \theta / \sigma^{2} ; \quad n(t, T)=\frac{4 \kappa e^{-\kappa(T-t)}}{\sigma^{2}\left(1-e^{-\kappa(T-t)}\right)}, \quad \lambda=r_t \cdot n(t, T), \quad T&gt;t
$$
换句话说，在$r_t, r_T$的条件下，其分布为$e^{-\kappa(T-t)} / n(t, T)$乘以非中心卡方分布，其自由度为$d$，非中心参数为$\lambda$。即，
$$
\operatorname{Pr}(r_T&lt;x \mid r_t)=F_{\chi^{\prime 2}}\left(\frac{x \cdot n(t, T)}{e^{-\kappa(T-t)}} ; d, r_t \cdot n(t, T)\right) .
$$
问题：上述统计模型是否可识别？即映射
$$
\boldsymbol{\rho}\mapsto P_\boldsymbol{\rho},
$$
是一一对应的。一般来说，我们如何证明这样的性质？我发现对于一些较简单的模型，通过反例证明它们不是一一对应的是相当容易的。例如上述模型的渐近分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/657594/show-model-is-identifiable-estimatable-for-mle</guid>
      <pubDate>Wed, 20 Nov 2024 18:28:39 GMT</pubDate>
    </item>
    <item>
      <title>对于前测/后测设置，我应该使用原始分数、标准分数还是标准分数来进行学生 t 检验？</title>
      <link>https://stats.stackexchange.com/questions/657564/for-a-pre-test-post-test-setting-should-i-use-the-raw-score-the-scaled-score-o</link>
      <description><![CDATA[我有点迷茫。我正在做一个旨在评估教育干预效果的项目。为此，在干预前后对同一组进行标准化测试（前测/后测）。样本很小，只有 35 个人。问题是测试有三种类型的分数：原始分数、量表分数和标准分数（取决于学生的年龄）。我计划进行 Shapiro-Wilk 检验来评估数据的正态性。如果分布为正态，我将使用学生 t 检验来评估干预的有效性，但我不确定我会使用什么分数：原始分数、量表分数还是标准分数？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/657564/for-a-pre-test-post-test-setting-should-i-use-the-raw-score-the-scaled-score-o</guid>
      <pubDate>Wed, 20 Nov 2024 15:31:24 GMT</pubDate>
    </item>
    <item>
      <title>Head First 统计学书籍：假设检验有错误吗？</title>
      <link>https://stats.stackexchange.com/questions/657544/head-first-statistics-book-error-in-hypothesis-test</link>
      <description><![CDATA[《Head First Statistics》一书的第 13 章讨论了假设检验。其示例如下：

一种名为 snorecull 的药物可以治愈打鼾，治愈率为 0.9。然后，得到以下结果。




治愈
未治愈




频率
11
4



如何确定药物是否有效？

本书仅使用二项分布来检验假设，如下所示（在 R 中）：
pbinom(11, 15, 0.9) = 0.0555 

根据结果，书中指出没有证据表明药物不起作用。
我的问题是：我们是否需要使用“样本比例（均值）分布逻辑”来检验假设？
据此，我们知道$P_s$（样本量为 15 时的样本比例）如下：
\begin{align}
Ps &amp;\sim \mathcal{N}(p, pq/n) \\\\
p &amp;= .9 \\\\
pq/n &amp;= var.ps = 0.006 \\\\
\sqrt{pq/n} &amp;= se = ps 的标准差 = 0.07745967
\end{align&gt;
因此，我们需要在 R 中像这样测试：
pnorm(11/15, p, se) 

哪个结果值为 0.01571217。
我错了吗？
--- 在 Arya 的评论后添加
是的，这本书提供了 $np, nq &gt; 5$。基本上这本书建议如下：
&gt; # 这本书
&gt; p &lt;- .9
&gt; q &lt;- 1-p
&gt; n &lt;- 100
&gt; cured &lt;- 80
&gt; not.cured &lt;- n-cured
&gt; 
&gt; pbinom(cured, n, p)
[1] 0.001978561
&gt;

我的想法是，我应该使用某种抽样分布思想。所以
&gt; # 从分布 X ~ B(n, .9) 
&gt; # 我们知道样本比例 
&gt; # = Ps ~ N(p, pq/n)
&gt; vs.ps &lt;- p*q/n
&gt; sd.ps &lt;- sqrt(p*q/n)
&gt; vs.ps 
[1] 0.09
&gt; sd.ps
[1] 0.03
&gt; # 因此我们需要像这样测试：
&gt; pnorm(0.8, p, sd.ps)
[1] 0.0004290603
&gt; # 或下面相同
&gt; z.sc &lt;- (0.8-p)/sd.ps
&gt; z.sc
[1] -3.333333
&gt; pnorm(z.sc)
[1] 0.0004290603
&gt; 

希望这有意义。抱歉编辑了原始问题。我不熟悉在 R 编码中使用注释...]]></description>
      <guid>https://stats.stackexchange.com/questions/657544/head-first-statistics-book-error-in-hypothesis-test</guid>
      <pubDate>Wed, 20 Nov 2024 03:47:42 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测的 LSTM 局限性</title>
      <link>https://stats.stackexchange.com/questions/657543/lstm-limitations-for-time-series-forecasting</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657543/lstm-limitations-for-time-series-forecasting</guid>
      <pubDate>Wed, 20 Nov 2024 03:38:09 GMT</pubDate>
    </item>
    </channel>
</rss>