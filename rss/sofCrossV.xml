<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 07 Jan 2025 01:16:30 GMT</lastBuildDate>
    <item>
      <title>以 Y 的指标为条件，对 X 对 Y 的影响进行条件化</title>
      <link>https://stats.stackexchange.com/questions/659633/condition-the-effect-of-x-on-y-on-the-indicator-of-y</link>
      <description><![CDATA[正如标题所示，我正在做一个研究项目，研究X（因变量）和Y（自变量）之间的关系。它们都是连续变量，Y在0附近对称分布。朴素的OLS回归模型是：
Y ~ X + e 

但我们有强有力的理论论据，即X对Y的影响应该取决于Y是正还是负：
Y ~ X + Z + X*Z + e
Z = I(Y&gt;0)

显然，Z是内生的。我有两个问题：
1，我可以使用交互模型吗？如果可以，需要什么条件？
2，还有其他方法可以实现我正在做的事情吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659633/condition-the-effect-of-x-on-y-on-the-indicator-of-y</guid>
      <pubDate>Tue, 07 Jan 2025 01:07:53 GMT</pubDate>
    </item>
    <item>
      <title>时间序列 CV 中的模型再训练频率是否必须与生产再训练频率相匹配？</title>
      <link>https://stats.stackexchange.com/questions/659632/does-model-retrain-frequency-in-time-series-cv-have-to-match-production-retrain</link>
      <description><![CDATA[假设我们每年在生产中重新训练模型，并且积累了 50 年的数据。如果在每年年底使用时间序列 CV（例如 sklearn 中的 TimeSeriesSplit）进行超参数重新校准，我们是否也需要在 CV 程序中每年重新训练模型（假设我们使用扩展窗口）？换句话说，确保每个验证分割的长度正好是 1 年？
我的理解是 CV 应该反映建模“过程”的泛化误差方差，因此我们使用它来尽可能接近地复制生产建模过程，所以答案是肯定的。但是，如果每天在生产中重新训练模型，情况会怎样？这是否意味着验证分割的长度必须是 1 天？]]></description>
      <guid>https://stats.stackexchange.com/questions/659632/does-model-retrain-frequency-in-time-series-cv-have-to-match-production-retrain</guid>
      <pubDate>Tue, 07 Jan 2025 00:19:42 GMT</pubDate>
    </item>
    <item>
      <title>条件变量的影响是否独立？</title>
      <link>https://stats.stackexchange.com/questions/659629/independence-of-conditioning-variables-effects</link>
      <description><![CDATA[通常，我们讨论独立性时，将其表示为 f(A,B) = f(A)f(B)，或讨论条件独立性时，将其表示为 f(A,B|X) = f(A|X)f(B|X)。
但是，我想知道您会如何称呼类似这样的内容：
f(Y|A,B) = f(Y|A)f(Y|B)
也就是说，给定 A 和 B，Y 发生的概率与您分别给定 A 和 B 计算 Y 发生的概率相同。换​​句话说，A 和 B 不是关于 Y 的联合信息，而是提供“唯一”的信息有关 Y 的信息。
例如，在预测的背景下，上述方程将表明 A 和 B 提供对 Y 的独立预测。[当然，如果它不成立，则 f(Y|A,B) =/= f(Y|A)f(Y|B)]
这个概念有通用术语吗？如果有，它在什么情况下使用/应用？
提前谢谢，抱歉问题模糊]]></description>
      <guid>https://stats.stackexchange.com/questions/659629/independence-of-conditioning-variables-effects</guid>
      <pubDate>Mon, 06 Jan 2025 21:46:29 GMT</pubDate>
    </item>
    <item>
      <title>从 nlme 方差结构中修复方差参数</title>
      <link>https://stats.stackexchange.com/questions/659628/fixing-variance-parameters-from-nlme-variance-structure</link>
      <description><![CDATA[我一直在使用 nlme 包中的异方差随机效应模型。我不知道如何设置 varStruct 中的参考水平方差参数。在下面的例子中，我使用样本数据 Orthodont 拟合模型，该模型允许根据受试者的性别在受试者内差异化个体。
我知道值输出代表受试者内误差的标准差比率：
$$
\frac{\hat\sigma_{female}}{\hat\sigma_{male}} = .4533
$$
library(nlme)
ex.data &lt;- as.data.frame(Orthodont)
ex.model &lt;- lme(distance ~ age, data = ex.data,
random = ~1|Subject,
weights = varIdent(form = ~1|Sex))

ex.model$modelStruct$varStruct #如何从这个对象中提取值？
#&gt; 表示类 varIdent 的方差函数结构
#&gt; 男性 女性 
#&gt; 1.000000 0.453369


于 2025-01-06 使用 reprex v2.0.2 创建
有没有办法重新参数化模型，将女性的权重设置为 1，并让男性自由估计，以便我可以找到：
$$
\frac{\hat\sigma_{male}}{\hat\sigma_{female}}
$$
我试过这个，但没有结果：
ex.model_fixed &lt;- lme(distance ~ age, data = ex.data,
random = ~1|Subject,
weights = varIdent(form = ~1|Sex, fixed = c(&quot;Female&quot; = 1))) #如何将级别固定为某些值？

ex.model_fixed$modelStruct$varStruct
#&gt; 类 varIdent 的方差函数结构没有参数，或者未初始化
]]></description>
      <guid>https://stats.stackexchange.com/questions/659628/fixing-variance-parameters-from-nlme-variance-structure</guid>
      <pubDate>Mon, 06 Jan 2025 21:32:41 GMT</pubDate>
    </item>
    <item>
      <title>调查数据分析的引导方法</title>
      <link>https://stats.stackexchange.com/questions/659627/approach-to-bootstrapping-for-survey-data-analysis</link>
      <description><![CDATA[我进行了一项调查，收集了 $n$ 位受访者的 $k$ 个李克特量表回答。我的分析包括对每位受访者的回答取平均值，并将平均回答向量与表示特定成熟度级别的 $k \times 1$ 大小的基线向量进行比较。我使用了许多 $k$ 样本测试来进行比较，并希望将引导技术应用于我的分析。我的问题如下：

据我所知，我需要进行引导假设检验，并需要抽取 $B$ 个大小为 $2k$ 的样本，并基于样本是总体的真正代表性样本这一信念进行替换。但是，我认为抽取平均值样本似乎没有意义。相反，我应该从整个响应数据集中抽取 $B$ 个样本（即 $k \times n$ 个样本），获取平均响应向量，与基线向量进行 $B$ 次比较，然后计算达到的显著性水平吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/659627/approach-to-bootstrapping-for-survey-data-analysis</guid>
      <pubDate>Mon, 06 Jan 2025 20:55:23 GMT</pubDate>
    </item>
    <item>
      <title>随机匹配概率的主成分分析</title>
      <link>https://stats.stackexchange.com/questions/659626/principal-component-analysis-for-random-match-probabilities</link>
      <description><![CDATA[好的，情况如下。我们有一堆数据，比如说 x1,...,x300，这些数据是我们为一堆样本 y1,...,y1000 收集的。数据 x1,...,x300 是依赖的（x1 的值与 x2-&gt;x300 的值相关，等等）。
作者 A（我试图优雅地证明他犯了一个错误）使用 PCA 来创建新变量。PC1,...,PC300 并指出这些主成分现在是独立的。因此，他们说，我们可以通过将各个主成分生成的概率相乘来计算联合概率（随机匹配概率）。
作者 A 的错误在于他们只表明变量 x1,...,x300 都是正态分布的，但没有表明 P(x1,...,x300) 的 PDF 是多元正态分布的。我的理解是，联合分布必须是多元正态分布，以确保主成分的独立性，而不是每个单独的变量都必须是正态分布（差别很大）。
所以这很好（我想，如果我错了请告诉我）……但我感到困惑的是……假设 P(x1,...,x300) 是多元正态分布。从高度依赖的数据中获取主成分并通过乘以（现在神奇地独立的）值来计算随机匹配概率的想法似乎是错误的……但我无法清楚地说明为什么会这样（或者也许我错了，那完全没问题）。
欢迎任何评论、指导或争论！
谢谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/659626/principal-component-analysis-for-random-match-probabilities</guid>
      <pubDate>Mon, 06 Jan 2025 20:53:28 GMT</pubDate>
    </item>
    <item>
      <title>解释优化 MSE 的模型中的模块权重和激活函数</title>
      <link>https://stats.stackexchange.com/questions/659615/interpreting-module-weights-and-activation-functions-in-a-model-optimizing-mse</link>
      <description><![CDATA[我正在使用一个由三个模块组成的模型：{A、B、C}。每个模块在预测股票价格方面都发挥着作用，模型的学习目标是最小化均方误差 (MSE)。
这些模块具有以下特点：
模块 A：具有较大的正权重。模块 B：具有较小的负权重。模块 C：具有接近于零的权重（例如，绝对值在 0.01 左右）。
权重是从检查点文件分析的，该文件是根据在验证集上评估的最佳性能参数保存的。
我试图了解这些权重如何影响模型以及某些设计决策背后的原理。以下是我的具体问题：
了解 A 和 B 的互补作用：
在训练期间，模块 A 的权重会以幅度（正方向）增加，这会降低 MSE。另一方面，模块 B 的权重变得更负，也会降低 MSE。我发现很难解释为什么一个模块用较大的正权重学习，而另一个模块用较小的负权重学习。我如何理解它们的互补作用，特别是在股票价格预测这样的任务中？
ReLU 的历史用途：
虽然 ReLU 现在不那么常用，但它在过去被广泛使用。采用 ReLU 是否是为了故意忽略负面贡献，例如来自模块 B 的贡献？如果是这样，这是否意味着在某些任务或情况下负权重被认为意义较小？或者，主要动机是为了避免梯度消失或简化计算？
转向 GELU：
像 GELU 这样的现代激活函数允许使用负权重。这是否意味着负面贡献现在被认为更有意义，而 GELU 有助于在模型中保留它们的影响力？
删除权重接近于零的模块：
如果模块 C 的权重非常小（例如 0.01 或 -0.01），这是否应该是将其从模型中删除的信号？这是否表明模块 C 对模型没有做出有意义的贡献，特别是如果消融研究表明删除后没有性能差异？
我特别有兴趣在有效集优化检查点分析的背景下理解上述观点。
摘要：
我使用在验证集上优化的已保存检查点分析了模型权重。我希望了解为什么模块 A 以较大的正权重学习，而模块 B 以较小的负权重学习，两者都降低了 MSE。我还希望确定权重接近于零的模块 C 是否做出了有意义的贡献并应该保留。然而，我很难解释 A 和 B 的互补作用以及模块 C 接近零的权重与模型性能的相关性。]]></description>
      <guid>https://stats.stackexchange.com/questions/659615/interpreting-module-weights-and-activation-functions-in-a-model-optimizing-mse</guid>
      <pubDate>Mon, 06 Jan 2025 13:50:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么这么多问题是线性的以及如何解决非线性问题？</title>
      <link>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</link>
      <description><![CDATA[我这学期选修了一门深度学习 Python 课，我们正在学习线性代数。
上一节课，我们从头开始“发明”了梯度下降的线性回归（之前在课上做过最小二乘），我们讨论了定义假设、损失函数、成本函数等。
为什么许多问题可以看作是线性的，而“只是试图找到方程 Ax = b 的解”？
可以通过最小二乘或训练神经网络等方法来实现这一点。
在现实世界中，大多数问题都不是线性的。
由于线性代数仅适用于线性函数，那么如何解决这些问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</guid>
      <pubDate>Sat, 04 Jan 2025 19:41:00 GMT</pubDate>
    </item>
    <item>
      <title>理解两个孩子问题的直觉</title>
      <link>https://stats.stackexchange.com/questions/659395/understanding-intuition-of-the-two-child-problem</link>
      <description><![CDATA[受到此推特帖子的启发，发布了这个问题：

我有两个孩子，（至少）其中一个是男孩，出生在星期二

两个孩子都是男孩的概率是多少？


通过Joel Grus，这里是一个建议的答案：

总共 196 种可能性（每种（性别、天）的概率均等）27那些
至少一个星期二男孩（13 个较小的星期二男孩，较大的不是；13 个较大的
星期二男孩，较小的不是，1 个都）其中 13 个都是男孩（6，6，1）所以
13 / 27

这似乎是正确的。但同时也令人困惑。这让我们觉得我们可以任意地以我们知道是真实的任何事物为条件（例如，婴儿出生在银河系；或者婴儿的父母说英语），并以某种方式使用它来改变后验概率。有人能把我从这引起的存在主义困境中解救出来吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659395/understanding-intuition-of-the-two-child-problem</guid>
      <pubDate>Tue, 31 Dec 2024 09:34:01 GMT</pubDate>
    </item>
    <item>
      <title>GAM 留一交叉验证 (LOOCV)，适用于较大的模型</title>
      <link>https://stats.stackexchange.com/questions/659016/gam-leave-one-out-cross-validation-loocv-for-biggish-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659016/gam-leave-one-out-cross-validation-loocv-for-biggish-models</guid>
      <pubDate>Fri, 20 Dec 2024 14:44:07 GMT</pubDate>
    </item>
    <item>
      <title>需要有共同原因的因果调整公式</title>
      <link>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</link>
      <description><![CDATA[
在上述因果模型中，计算$P(X=x \mid \text{do}(Y=y))$时，是否需要使用因果调整公式$\sum_c P(X=x \mid Y=y, C=c) P(C=c)$？一旦我们$\text{do}(Y=y)$，$Y$的生成过程是否就独立于$X$的生成过程，因此$P(X=x \mid \text{do}(Y=y)) = P(X=x)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</guid>
      <pubDate>Mon, 16 Dec 2024 06:30:13 GMT</pubDate>
    </item>
    <item>
      <title>根据另一个统计模型创建非同质队列？</title>
      <link>https://stats.stackexchange.com/questions/657336/creating-a-non-homogenous-queue-based-on-another-statistical-model</link>
      <description><![CDATA[我有一个问题，关于如何根据变化的参数构建/近似统计队列。
我在 R 中创建/模拟了 MMK 队列的这个近似版本：
library(tidyverse)

k &lt;- 3 # 服务器数量
lambda &lt;- 2 # 到达率
mu &lt;- 1 # 每台服务器的服务率
T &lt;- 100 # 模拟时间
n_sims &lt;- 20 # 模拟次数
dt &lt;- 0.05 # 时间步长
initial_n &lt;- 100 # 初始队列长度

simulate_mmk &lt;- function(sim_number) {
n_steps &lt;- ceiling(T/dt)
queue_length &lt;- numeric(n_steps)
queue_length[1] &lt;- initial_n

到达 &lt;- rpois(n_steps, lambda * dt)
出发 &lt;- rpois(n_steps, k * mu * dt)

for(i in 2:n_steps) {
current_n &lt;- 队列长度[i-1]
到达 &lt;- 到达[i]
出发 &lt;- min(departures[i], current_n)
队列长度[i] &lt;- current_n + 到达 - 出发
}

data.frame(
time = seq(0, T-dt, length.out=n_steps),
队列长度 = 队列长度,
模拟 = 因子(sim_number)
)
}

set.seed(123)
sim_data &lt;- bind_rows(
lapply(1:n_sims, function(i) {
set.seed(123 + i)
模拟_mmk(i)
})
)


我有兴趣调整这个队列，以允许改变到达、离开和服务器的数量。
例如，在上面的模拟中，服务器的数量保持不变，到达和离开是从具有固定参数的概率分布中随机选择的。我想制作一些可以随时间变化的分布。
例如，假设到达、离开和服务器随时间变化（例如，分段，时间值变化的概率分布）。
我是否可以预先根据这些变化的分布生成到达、离开和服务器的向量（例如，将回归模型拟合到历史到达、离开和服务器数据），然后从这些模型中模拟随机数据以创建非同质队列？
run_sims &lt;- function(n_sims = 20, T = 100, dt = 0.05, initial_n = 100) {

n​​_steps &lt;- ceiling(T/dt)

set.seed(123)
attendances &lt;- abs(rnorm(n_steps, mean = 25, sd = 2))
service_rates &lt;- abs(rnorm(n_steps, 平均值 = 15, sd = 1))
服务器 &lt;- abs(rnorm(n_steps, 平均值 = 5, sd = 0.5))

sim_data &lt;- map_dfr(1:n_sims, function(i) {
set.seed(123 + i)

队列长度 &lt;- numeric(n_steps)
队列长度[1] &lt;- initial_n

for(i in 2:n_steps) {
current_n &lt;- 队列长度[i-1]
到达 &lt;- rpois(1, 到达[i] * dt)
出发 &lt;- min(rpois(1, 服务器[i] * 服务费率[i] * dt), current_n)
队列长度[i] &lt;- current_n + 到达 - 出发
}

data.frame(
时间= seq(0, T-dt, length.out=n_steps),
queue_length =queue_length,
simulation =factor(i)
)
})
return(sim_data)
}

sim_data &lt;-run_sims(
n_sims = 20,
T = 100,
dt = 0.05,
initial_n = 100
)



澄清：

首先，我将拟合 3 个不同的模型（例如GAM/时间序列）到历史到达、离开和服务器数据
然后，我将根据这 3 个模型在一段时间内预测未来值
然后，在这个范围的每个时间点 - 我将根据以这 3 个模型产生的每个预测值为中心的概率分布（例如指数、泊松）模拟到达、离开和服务器数量
重复
]]></description>
      <guid>https://stats.stackexchange.com/questions/657336/creating-a-non-homogenous-queue-based-on-another-statistical-model</guid>
      <pubDate>Fri, 15 Nov 2024 21:32:48 GMT</pubDate>
    </item>
    <item>
      <title>我们可以将一个随机正态变量大于其他 $N$ 个正态变量的概率写成累积密度函数的乘积吗？</title>
      <link>https://stats.stackexchange.com/questions/655163/can-we-write-the-probability-that-a-random-normal-variable-is-greater-than-other</link>
      <description><![CDATA[对于 $Y_1 \sim N(\mu_y;\sigma_y^2)$ 和 $X_i, ..., X_N$ 个分布为 $N(\mu_i, \sigma_i^2)$ 的随机变量，我们可以将 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})$ 写为 $\prod_{i=1}^{N}F(z_i)$ 吗？其中 $F(\cdot)$ 是标准正态分布的累积密度函数，并且 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})$ 写为 $\prod_{i=1}^{N}F(z_i)$，其中 $F(\cdot)$ 是标准正态分布的累积密度函数，并且 $z_i=\frac{\mu_y-\mu_i}{\sqrt{\sigma_y^2+\sigma_i^2}}$?
对于 $i=1$ 的情况，我知道很容易证明 $P(Y_i \geq X_1)=F(\frac{\mu_y-\mu_i}{\sqrt{\sigma_y^2+\sigma_1^2}})$，但我们能否推广到 $N$ 的情况 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})=\prod_{i=1}^{N}F(z_i)$?
如果 $\mu_y=\mu_i \forall i$，则为 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})=F(z_1)^N$。
我之所以产生疑问，是因为似乎只要 $Y$ 的均值与任何其他 $X_i$ 相同，$Y$ 方差的任何变化都不会影响 $P(Y_1 \geq X_i \ \forall i \in \{2,...,N\})$。而直观上 $Y$ 需要较高的值才能击败所有其他分布。
（这不是任务，只是好奇心）]]></description>
      <guid>https://stats.stackexchange.com/questions/655163/can-we-write-the-probability-that-a-random-normal-variable-is-greater-than-other</guid>
      <pubDate>Tue, 01 Oct 2024 10:25:44 GMT</pubDate>
    </item>
    <item>
      <title>如何确定复杂过程的理论预测极限？</title>
      <link>https://stats.stackexchange.com/questions/648254/how-to-determine-the-theoretical-prediction-limit-for-a-complex-process</link>
      <description><![CDATA[我们如何找到复杂过程的理论预测极限？
例如，对于抛硬币（平均而言），预测极限是 50%，也就是说，实际上我们无法预测出比这个最大值更好的结果（除非我们能够获得“内部信息”，如初始条件等）。
对于一个复杂的过程，有没有什么工具可以用来确定理论预测最大值，超过这个最大值我们就无法预测了？
所以我对上述问题的措辞不是很满意（抱歉），但我确实问过 GPT4，答案可能有助于更好地理解这个问题：

确定复杂过程的理论预测极限是一项具有挑战性的任务，它涉及理解过程固有的不确定性和不可预测性。有几种来自不同领域的工具和概念，如信息论、混沌理论和统计力学，可以帮助评估这个极限。以下是一些关键方法和工具：

香农熵（信息论）...
柯尔莫哥洛夫复杂度（算法信息论）...
等等


我感兴趣的原因是从机器学习的角度来看的。首先，它可以帮助确定：

过度拟合（是的，我知道还有其他实用方法可以确定这一点，但在这个预测极限下，它可能更具挑战性）
数据泄漏（这些事情可能更难确定，特别是对于时间序列数据）
模型的最大理论性能，接近这个性能，您开始接近帕累托努力与回报原则。

因此，想象一下这样一个复杂的过程（为了论证）是对体育赛事或政治投票结果的预测。]]></description>
      <guid>https://stats.stackexchange.com/questions/648254/how-to-determine-the-theoretical-prediction-limit-for-a-complex-process</guid>
      <pubDate>Thu, 30 May 2024 01:47:50 GMT</pubDate>
    </item>
    <item>
      <title>多重共线性与联立方程模型中识别问题的联系</title>
      <link>https://stats.stackexchange.com/questions/648240/connection-between-multicollinearity-and-problem-of-identification-in-simultaneo</link>
      <description><![CDATA[多重共线性和联立方程模型中的识别问题之间有什么联系吗？
我知道多重共线性是指多元回归模型中两个或多个独立变量之间存在高度相互相关性，而联立方程模型是一种统计模型，其中因变量是其他因变量的函数，而不仅仅是独立变量。
想知道这两者之间是否有联系？SEM 中是否存在多重共线性？]]></description>
      <guid>https://stats.stackexchange.com/questions/648240/connection-between-multicollinearity-and-problem-of-identification-in-simultaneo</guid>
      <pubDate>Wed, 29 May 2024 19:41:35 GMT</pubDate>
    </item>
    </channel>
</rss>