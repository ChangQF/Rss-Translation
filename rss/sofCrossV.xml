<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 03 Dec 2024 15:19:04 GMT</lastBuildDate>
    <item>
      <title>如何手动计算自相关</title>
      <link>https://stats.stackexchange.com/questions/658213/how-to-calculate-autocorrelation-manually</link>
      <description><![CDATA[我学过滞后 $k$ 的时间序列中的自相关是所有以此滞后为间隔的值对之间的相关性。
假设我想尝试一下，并手动计算滞后 1。
模拟一些白噪声
set.seed(123)
TS &lt;- ts(rnorm(1e3))

然后手动计算自相关并使用内置函数。
&gt; calc_autocorrelation_manually(TS)
[1] -0.02741628
&gt; 
&gt; acf(TS, lag = 1, plot = F)

序列‘TS’的自相关，按滞后

0 1 
1.000 -0.027

两者给出相同或几乎相同的结果（我知道 acf() 中的计算并不完全相同，因为它不使用偏差调整。不过，我认为这不会产生实质性差异）。
但是，如果我对模拟 AR(1) 过程执行此操作，结果就不一样了！例如，使用没有噪音的“理想”AR(1)：
&gt; TS &lt;- ts(99999) # 初始值
&gt; for (i in 1:350) { TS &lt;- c(TS, TS[i] * 0.3) }
&gt; 
&gt; calc_autocorrelation_manually(TS)
[1] 1
&gt; 
&gt; acf(TS, lag = 1, plot = F)

序列‘TS’的自相关，按滞后

0 1 
1.0 0.3 

我认为手动计算自相关是不正确的，但正确的方法是什么？为什么在第一个例子中它仍然运行良好？]]></description>
      <guid>https://stats.stackexchange.com/questions/658213/how-to-calculate-autocorrelation-manually</guid>
      <pubDate>Tue, 03 Dec 2024 15:05:35 GMT</pubDate>
    </item>
    <item>
      <title>统计/概率瓮模型在课堂之外还有其他应用吗？</title>
      <link>https://stats.stackexchange.com/questions/658212/do-statistical-probability-urn-models-have-any-applications-beyond-the-classroom</link>
      <description><![CDATA[我正在学习 Polya Urn 问题（例如 https://en.wikipedia.org/wiki/Urn_problem）。在我看来，这类问题对于教授学生概率非常有用。但我只是想知道这些问题在现实世界中是否有任何应用？
例如，我们学习回归模型，回归模型也用于医学界和经济学。
但这些类型的 Urn 模型是否出现过？我们是否曾经将任何东西建模为瓮？它们是否在其他一些模型的背景中使用（例如：用于从后验分布中抽取样本）？或者它们只是纯粹的理论教学示例？]]></description>
      <guid>https://stats.stackexchange.com/questions/658212/do-statistical-probability-urn-models-have-any-applications-beyond-the-classroom</guid>
      <pubDate>Tue, 03 Dec 2024 14:50:21 GMT</pubDate>
    </item>
    <item>
      <title>修正二项式 GLMM 以反映物种出现的时间趋势</title>
      <link>https://stats.stackexchange.com/questions/658211/correct-binomial-glmm-for-temporal-trends-in-species-occurrences</link>
      <description><![CDATA[我有一个包含 80 个物种的数据集，这些物种是在两个时间段（历史/最近）从大约 120 个水体中采样的。仅考虑每个水体中物种的存在/不存在。长格式的数据如下所示：
water_no_name 物种 成功时间 
水体 1 物种 A 0 t1 
水体 2 物种 A 0 t1 
水体 3 物种 A 1 t1 
水体 4 物种 A 0 t1 
水体 5 物种 A 0 t1 
水体 1 物种 A 1 t2 
水体 2 物种 A 0 t2 
水体 3 物种 A 0 t2 
水体 4 物种 A 0 t2 
水体 5 物种 A 0 t2 
水体 1 物种 B 1 t1 
水体 2 物种 B 0 t1 
水体 3 物种 B 0 t1 
水体 4 物种 B 1 t1 
水体 5 物种 B 1 t1 
水体 1 物种 B 1 t2 
水体 2 物种 B 0 t2 
水体 3 物种 B 1 t2 
水体 4 物种 B 1 t2 
水体 5 物种 B 0 t2 

我想检查哪些物种的频率随时间显著增加或减少。
因此，我决定使用水体（= 地点）作为随机因素来计算二项式 GLMM，以解释重复测量设计。
我不确定这两种方法中的哪一种更合适：

为每个物种计算单独的 GLMM：
mod &lt;- glmer(success ~ time + (1 | water_no_name), family = binomial)
使用这种方法，我将对物种数量进行 p 值校正 (FDR)。

使用时间和物种之间的相互作用计算所有物种的组合 GLMM：
mod &lt;- glmer(success ~ time * species + (1 | water_no_name), family = binomial)
为了分析相互作用，我将使用这种方法进行事后分析，以查看对比 t1/t2 对哪些物种有意义：
emmeans(mod, pairwise ~ time |物种）


在计算这两种模型时，结果大致相似，但计数较低的物种会有一些差异。方法 (2) 需要大约一个小时来计算。
我理解，一个主要区别是，复杂模型 (2) 对所有物种使用相同的随机位点效应，而使用单独的模型 (1) 我会为每个物种获得不同的随机位点效应（参见 几个单物种 GLMM -&gt; 一个多物种 GLMM（随机效应语法？））
我仍然不确定哪种方法更适合我的情况。我发现更简单的方法 (1) 更直观地解释，也足以回答我的问题。我也不确定是否应该让所有物种都具有随机地点效应。
有人能给我建议我应该选择哪种方法吗？
或者你推荐另一种方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/658211/correct-binomial-glmm-for-temporal-trends-in-species-occurrences</guid>
      <pubDate>Tue, 03 Dec 2024 14:44:29 GMT</pubDate>
    </item>
    <item>
      <title>强制排名调查</title>
      <link>https://stats.stackexchange.com/questions/658208/survey-with-forced-ranking</link>
      <description><![CDATA[我创建了一个调查问卷，其排名等级为 1 = 最不有效，2 = 有点有效，3 = 有效，4 = 最有效。
回答问题的人被迫每列只能选择一个答案。
问题例如：请使用 1 到 4 的等级对以下金融工具在促进使用自产天然纤维绝缘产品方面的有效性进行评分。（答案 FI1/FI2/FI3/FI4）
由于每个响应总和的方差为零，我无法计算 Cronbach&#39;s Alpha，因此我如何计算调查的可靠性。]]></description>
      <guid>https://stats.stackexchange.com/questions/658208/survey-with-forced-ranking</guid>
      <pubDate>Tue, 03 Dec 2024 14:15:32 GMT</pubDate>
    </item>
    <item>
      <title>在 GAM mgcv 中使用 d 关键字时如何正确指定点约束 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658207/how-to-correctly-specify-point-constrains-when-using-d-keyword-in-gam-mgcv</link>
      <description><![CDATA[这个问题已经在以下之前的帖子中提出，但我怀疑那里给出的答案是否令人满意：Constaint on te() tensor product gam mgcv
那么对于 mgcv 专家来说：使用 d 关键字指定的 gam 模型提供点约束的正确方法是什么？
这里有一些例子来详细说明这个问题，并展示我到目前为止所尝试过的
示例 1：
model &lt;- mgcv::bam(Y ~ s(x, y, k = 500, pc = c(0, 0)) +
s(z, k = 5, pc = 0) +
ti(x, y, z, d = c(2,1), k = c(20, 5), pc = c(0, 0, 0)),
data = data,
family = tw(link=log),
method = &quot;fREML&quot;)

示例 2：
model &lt;- mgcv::bam(Y ~ s(x, y, k = 500, pc = c(0, 0)) +
s(z, k = 5, pc = 0) +
ti(x, y, z, d = c(2,1), k = c(20, 5), pc = list(c(0, 0), c(0)),
data = data,
family = tw(link=log),
method = &quot;fREML&quot;)

示例3：
模型 &lt;- mgcv::bam(Y ~ s(x, y, k = 500, pc = c(0, 0)) +
s(z, k = 5, pc = 0) +
ti(x, y, z, d = c(2,1), k = c(20, 5), pc = list(list(0, 0), list(0)),
data = data,
family = tw(link=log),
method = &quot;fREML&quot;)

示例 4：
模型 &lt;- mgcv::bam(Y ~ s(x, y, k = 500, pc = c(0, 0)) +
s(z, k = 5, pc = 0) +
ti(x, y, z, d = c(2,1), k = c(20, 5), pc = list(0,0,0),
data = data,
family = tw(link=log),
method = &quot;fREML&quot;)

.. 但它们都会导致错误
if (length(pc) &lt; d) stop(&quot;supply a value for each variable for a point constrain&quot;) 中的错误：条件的长度 &gt; 1
仔细检查表明，这与将 d 指定为 d=c(2,1) 有关。有一种解决方案是切换到 d = 3。事实上，这就是上一篇文章中所建议的。然而，这并不令人满意，因为我想利用前两个坐标中的各向同性。]]></description>
      <guid>https://stats.stackexchange.com/questions/658207/how-to-correctly-specify-point-constrains-when-using-d-keyword-in-gam-mgcv</guid>
      <pubDate>Tue, 03 Dec 2024 13:52:43 GMT</pubDate>
    </item>
    <item>
      <title>解释 A/B 测试结果中的 p 值</title>
      <link>https://stats.stackexchange.com/questions/658204/interpret-p-value-in-a-b-test-results</link>
      <description><![CDATA[我需要解释 A/B 测试结果。因此，我有一个名为 Baseline 的控制队列，还有另外两个名为 NewFTUE 和 AppReopenFS 的队列。
此 AB 测试数据的最大问题是 NewFTUE 的 AP 值几乎等于 1，而 AppReopenFS 的 P 值要低得多。
我无法理解两件事：

据我所知，如果平均差异较大且
标准差较小，则 p 值应该变得更小，即零假设应该更容易被拒绝。但我们可以
在这里看到，对于较大的标准差和较小的均值差，p 值要小得多（0.187 vs 0.991）
第二件我无法理解的事情是 95% CI（正如仪表板上所解释的那样，这是“95% 可能包含均值真实差异的值范围”。）。因此，正如您所看到的，对于 NewFTUE，均值差异的置信区间完全位于 0 的左侧。即我们有 95% 的信心，无论我们采用什么样本（对于相同的样本量），与 Baseline 相比，我们都会得到更差的结果。

那么为什么 NewFTUE 的 p 值为 0.991 并且大于 AppReopenFS 的 0.187 值？

编辑：添加以下 p 值的描述：和 这里是文档页面。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658204/interpret-p-value-in-a-b-test-results</guid>
      <pubDate>Tue, 03 Dec 2024 13:44:27 GMT</pubDate>
    </item>
    <item>
      <title>Gamma 分布函数中参数的特殊情况？</title>
      <link>https://stats.stackexchange.com/questions/658203/special-case-of-parameters-in-the-gamma-distribution-function</link>
      <description><![CDATA[我目前正在使用 Voronoi 镶嵌处理图像并评估相应细胞区域的分布。这些区域被称为伽马分布，源自 1D 情况。
维基百科上的 Gamma 分布 (pdf) 版本具有形状参数 (alpha) 和速率参数 (beta)。
请参阅此处 --&gt; 维基百科版本的 Gamma 分布
我对一篇论文（以及引用这篇论文的其他一些论文）感到困惑。在这里，另一个版本被称为“Gamma 函数”。
请参阅此处--&gt; 论文中的 Gamma 分布，第 436 页
我现在的问题是：
有人能用相对简单的术语向我解释这是否是 Gamma 分布的一个特例，以及/或者两个版本之间的关系吗？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658203/special-case-of-parameters-in-the-gamma-distribution-function</guid>
      <pubDate>Tue, 03 Dec 2024 13:36:40 GMT</pubDate>
    </item>
    <item>
      <title>根据相关数据进行方差估计</title>
      <link>https://stats.stackexchange.com/questions/658200/variance-estimation-from-dependent-data</link>
      <description><![CDATA[我想从形式为 $y_n = u_n x_n$ 的数据中估计零均值正态分布 $x_n \sim \mathcal{N}(0, \sigma^2)$ 的方差，其中输入 $u_n \in [u_{\min}, u_{\max}]$ 可以在每次迭代 $n$ 中主动选择，即 $u_n$ 不是先验固定的，而是高度依赖于先前的选择。
在这种情况下，如何估计方差 $\sigma^2$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658200/variance-estimation-from-dependent-data</guid>
      <pubDate>Tue, 03 Dec 2024 12:19:22 GMT</pubDate>
    </item>
    <item>
      <title>费舍尔精确检验和 Bonferroni 校正？</title>
      <link>https://stats.stackexchange.com/questions/658199/fishers-exact-tests-and-the-bonferroni-correction</link>
      <description><![CDATA[由于我的数据样本很小，因此我将 Fisher 精确检验应用于我的数据，我的数据与这个数据非常相似（我通过 Reddit 找到的）。




N1 = 男人
N2 = 女人




菜单 1
1
6


菜单 2
2
9


菜单 3
2
4


菜单 4
4
3


菜单 5
4
3


菜单6
3
3


总计
16
28



但是，除了使用 Fisher 精确检验来测试性别是否与菜单选择方式有关之外，我还想测试几个假设，例如，选择菜单 1 的女性数量与男性相比有显著差异，选择菜单 2 的女性数量与男性有显著差异等，我应该做什么样的测试？
据我所知，我需要创建六个单独的列联表（如下所示），对每个表进行 Fisher 精确检验假设。




N2 = 男人
N2 = 女人




菜单 1 已选中
1
6


菜单 1 未选中
15
22



我想问一下这种方法是否正确？另外我想知道如果我这样做，是否需要应用 Bonferroni 校正？
感谢您的回答！]]></description>
      <guid>https://stats.stackexchange.com/questions/658199/fishers-exact-tests-and-the-bonferroni-correction</guid>
      <pubDate>Tue, 03 Dec 2024 11:54:14 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制剂量反应的 S 形曲线以找到饱和点和 EC50</title>
      <link>https://stats.stackexchange.com/questions/658198/how-to-plot-a-sigmoidal-curve-to-a-dose-response-to-find-the-saturation-point-an</link>
      <description><![CDATA[
大家好，我在 x 轴（不是对数刻度）上注入了电压 (mV)，在 y 轴上注入了网络的神经响应（曲线下面积 (AUC)）。数据还包括每个电压的样本大小为 n = 8 个孔，以及每个数据点的面积 SE。虽然我可以大致看到饱和点的位置，但我希望得到更数学/统计上严谨的东西。
干杯！]]></description>
      <guid>https://stats.stackexchange.com/questions/658198/how-to-plot-a-sigmoidal-curve-to-a-dose-response-to-find-the-saturation-point-an</guid>
      <pubDate>Tue, 03 Dec 2024 11:45:39 GMT</pubDate>
    </item>
    <item>
      <title>假阳性率是否可能随着患病率的增加而降低？</title>
      <link>https://stats.stackexchange.com/questions/658195/is-it-possible-that-false-positive-rate-decreases-with-increasing-prevalence</link>
      <description><![CDATA[我对患病率对预测性能的影响很感兴趣。Chouldechova (2016) 指出：

[当]在各组再犯患病率不同的人群中使用测试公平 [再犯预测工具] 时，通常再犯患病率较高的组会具有较高的 FPR 和较低的 FNR。

我想知道如果该工具旨在使两组具有相同的准确度，情况是否如此。因此，我推导出一个考虑准确率、FNR 和患病率的 FPR 函数：
$$FPR=\frac{\left(1-ACC-prevalence\cdot FNR\right)}{1-prevalence}$$
这个等式似乎是正确的，因为它给出的结果与通常的 $ FPR=\frac{FP}{FP+TN}$ 相同。
我注意到，如果 $FNR+ACC&lt;1$（即敏感度低于准确率），该等式仅显示患病率与 FPR 之间的正相关关系。请参阅此处。
我的问题是：在实际情况下，患病率和 FPR 之间的关系是否可能为负？或者我是否遗漏了某些东西，可以将可能的值限制在关系为正的范围内？]]></description>
      <guid>https://stats.stackexchange.com/questions/658195/is-it-possible-that-false-positive-rate-decreases-with-increasing-prevalence</guid>
      <pubDate>Tue, 03 Dec 2024 11:09:43 GMT</pubDate>
    </item>
    <item>
      <title>模型对噪声数据的回归性能的最大可能是多少？</title>
      <link>https://stats.stackexchange.com/questions/658193/what-is-the-maximum-possible-regression-performance-of-a-model-on-noisy-data</link>
      <description><![CDATA[假设我对某种物质的衰减速度很感兴趣，因此我会测量其随时间变化的水平。我执行了几次重复，因此在每个时间点都有几次测量，然后使用这些数据来估计指数衰减模型 $y=e^{-\lambda t}$ 的衰减率，从而给出 $\lambda$ 的估计值和该估计值的标准误差。现在假设标准误差与衰减率相比相当大，因此数据是有噪声的。
现在假设我对找出影响衰减率的因素很感兴趣。数据可能（大部分）有噪声，但我有数万个案例。
我将数据分为训练、验证和测试，并尝试训练一系列模型 - 套索回归、随机森林、梯度提升树，我甚至还快速尝试了 CNN。在测试集中，无论我做什么，这些模型的 $R^2$ 都在 0.4 左右。
对此有几种解释。一种是缺少重要变量，或者模型在形式或结构上存在错误。但也可能是由于数据中的噪声。
在给定数据置信度的情况下，是否有任何方法可以衡量回归模型的最大可能性能？
这个问题：估计噪声数据中的最大预测能力与分类任务有关，但我在这里想知道回归。此外，我认为需要了解真实模型，但事实并非如此。
我突然想到，一个模型很难比真实数据的额外重复做得更好。我想知道，如果我模拟一万个案例中的每一个的新重复（通过从标准差等于真实数据标准误差的正态分布中随机挑选一个新的 lambda），然后测量一万个模拟值和一万个真实值之间的相关性，这可能会给我一个我可以期望的模型的上限。这样做会得到一个大约 0.4 的 $R^2$！这听起来合理吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658193/what-is-the-maximum-possible-regression-performance-of-a-model-on-noisy-data</guid>
      <pubDate>Tue, 03 Dec 2024 10:44:04 GMT</pubDate>
    </item>
    <item>
      <title>提取重复测量设计的前后相关性</title>
      <link>https://stats.stackexchange.com/questions/658191/extraction-pre-post-correlation-of-repeated-measures-design</link>
      <description><![CDATA[根据各种参考资料，例如https://matthewbjane.github.io/blog-posts/blog-post-3.html，如果配对 t 统计量 (t) 的值可用，则可以计算前测和后测分数之间的相关性 (配对 t 检验)。
我的问题是，当我们需要应用非参数检验 (Wilcoxon 符号秩检验) 而不是参数检验 (配对 t 检验) 时，我们如何计算相关性？]]></description>
      <guid>https://stats.stackexchange.com/questions/658191/extraction-pre-post-correlation-of-repeated-measures-design</guid>
      <pubDate>Tue, 03 Dec 2024 10:32:48 GMT</pubDate>
    </item>
    <item>
      <title>几率 $O_1 O_2$ 乘积的含义（及其几何平均值）</title>
      <link>https://stats.stackexchange.com/questions/658190/meaning-of-product-of-odds-o-1-o-2-and-its-geometric-mean</link>
      <description><![CDATA[假设我有两个独立事件 $E_1$ 和 $E_2$，其相关概率分别为 $p_1$ 和 $p_2$。$E_1$ 的概率为 $O_1 = \frac{p_1}{1-p_1}$，而 $E_2$ 的概率也类似。在我面临的问题中，这些几率的几何平均值 $G=\sqrt{O_1 O_2}$ 从数学中得出。
几率的乘积似乎与两个事件发生的概率与两个事件都不发生的概率之间的比率有关：
$$
O_1 O_2 = \frac{p_1 p_2 }{(1-p_1)(1-p_2)} = \frac{\Pr(E_1 \land E_2)}{\Pr(\lnot E_1 \land \lnot E_2)}
$$
但我无法将其与任何有用的东西联系起来，我不知道这个比率在任何情况下是有意义的或可以被赋予某种意义。此外，问题不仅在于$O_1 O_2$，还在于它的几何平均值。也许一个事件$E_3$的概率，其两次成功概率与两次失败概率之比等于$O_1 O_2$？
你见过类似的东西吗？我可以看看它来建立一些相似之处吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658190/meaning-of-product-of-odds-o-1-o-2-and-its-geometric-mean</guid>
      <pubDate>Tue, 03 Dec 2024 09:55:26 GMT</pubDate>
    </item>
    <item>
      <title>我的数据适合什么模型？</title>
      <link>https://stats.stackexchange.com/questions/658189/what-model-for-my-data</link>
      <description><![CDATA[我有一个问题，我们想比较 3 种处理方法（标准处理方法与 2 种新方案）。对于每种处理方法，我们生成 5 个对象。然后，将每个对象划分为较小的部分，并从每个部分测量给定的属性。
我不知道这是否重要，但每个对象的部分都存在一些空间依赖性（在每个对象中，第 1 部分与第 2 部分相邻，第 2 部分与第 3 部分相邻，依此类推）。
因此，我认为我遇到的是独立组的情况，但每个组内都有重复测量。就我查阅的文献而言，它似乎指导我进行混合方差分析或分层模型？您能在这方面给我一些帮助并指导一些文献吗？我也在用 R 做这件事。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658189/what-model-for-my-data</guid>
      <pubDate>Tue, 03 Dec 2024 09:23:14 GMT</pubDate>
    </item>
    </channel>
</rss>