<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 23 Jul 2024 12:29:06 GMT</lastBuildDate>
    <item>
      <title>比较生物样本中预期和观察到的特征组合</title>
      <link>https://stats.stackexchange.com/questions/651588/compare-expected-and-observed-feature-combinations-in-biological-samples</link>
      <description><![CDATA[我有 1000 个生物样本的分类数据和 4 个特征 (A,B,C,D)，它们告诉我样本对药物 A、B、C、D 是否 耐药 (1) 或 易感 (0)。
在此基础上，我可以计算出所有样本中每种药物耐药性的观察频率：
P(A = &quot;R&quot;) = 0.4
P(B = &quot;R&quot;) = 0.3
P(C = &quot;R&quot;) = 0.3
P(D = &quot;R&quot;) = 0.2

另一方面，我观察到多种药物耐药性，我想找出耐药性的组合是否比预期更频繁：
P(observed) = P(A = R + B = R + C = R + D = R) = 0.1
P(预期) = P(A = R)* R(B = R) * P(C = R) * P(D = R) =
0.4*0.3*0.3*0.2

给出 P(observed) = 0.1 和 P(expected)=0.0072 之间的巨大差异
我想使用 R 中的 chisq.test 函数来比较这些比率。有没有更好的测试？如何设置列联表？
祝好，迈克尔]]></description>
      <guid>https://stats.stackexchange.com/questions/651588/compare-expected-and-observed-feature-combinations-in-biological-samples</guid>
      <pubDate>Tue, 23 Jul 2024 12:14:21 GMT</pubDate>
    </item>
    <item>
      <title>通过拉普拉斯变换证明 mgf 确定分布</title>
      <link>https://stats.stackexchange.com/questions/651587/proving-that-mgf-determines-distribution-via-laplace-transform</link>
      <description><![CDATA[我正在阅读这个问题以及那里提供的关于矩生成函数 (mgf) 的答案，以及如何通过拉普拉斯变换的唯一性来证明其唯一性。在我的书测度理论、概率和随机过程（作者：Le Gall）中，证明了非负随机变量的拉普拉斯变换的唯一性，但我真的很难理解如何将这个结果扩展到任意符号的随机变量，即 mgf（实际上是一个双面拉普拉斯变换）决定了 $X$ 的定律。
我认为链接帖子中的答案做出了错误的陈述。答案声称

$$M_X(-t)=\mathcal{L}\{f(x)\}(t)+\mathcal{L}\{f(-x)\}(-t),$$且 $M_X(t)$ 是唯一的当且仅当 $\mathcal{L}\{f(x)\}(t)$ 和 $\mathcal{L}\{f(-x)\}(-t)$ 都是唯一的。

但加法不是单射。假设$Y$的密度为$g(x)$。如果 $M_X(-t)=M_Y(-t)$ 且其中 $|t|&lt;h$ 其中 $h&gt;0$，且如果 $F(t)=\mathcal{L}\{f(x)\}(t)$，$G(t)=\mathcal{L}\{f(-x)\}(-t)$，$H(t)=\mathcal{L}\{g(x)\}(t)$ 且 $K(t)=\mathcal{L}\{g(-x)\}(-t)$，然后$$F(t)+G(t)=H(t)+K(t)\rlap{\ \quad\not\ }\implies F(t)=H(t),G(t)=K(t),$$所以看起来我们不能使用拉普拉斯变换的唯一性来得出这样的结论：$f(x)=g(x)$和$f(-x)=g(-x)$在$x&gt;0$上，所以$f(x)=g(x)$。
我的推理正确吗？还是我误解了什么？例如Casella 和 Berger 也将这个结果称为拉普拉斯变换理论的结果，但我不明白上面引用的陈述如何正确，也不知道如何证明 mgf 决定了 $X$ 的定律，因为我们知道单边拉普拉斯变换决定了 $X$ 的定律。]]></description>
      <guid>https://stats.stackexchange.com/questions/651587/proving-that-mgf-determines-distribution-via-laplace-transform</guid>
      <pubDate>Tue, 23 Jul 2024 12:04:15 GMT</pubDate>
    </item>
    <item>
      <title>如何验证我的组中的某些受试者是否发生了显著变化</title>
      <link>https://stats.stackexchange.com/questions/651585/how-to-verify-if-some-subjects-within-my-group-show-significant-changes</link>
      <description><![CDATA[我有一个样本，在不同的认知任务治疗前、治疗中和治疗后 3 次对其进行测试，测量对刺激的反应时间。我使用了重复测量方差分析，并使用 Tukey 的事后检验观察了每个 T 时间之间的差异。看起来，作为一个整体，样本并没有显著差异，但一些 p 值非常接近显著性。
现在，我想在个体层面验证，某些个体是否似乎发生了显著变化或改善。我如何将我的样本分为“改善的人”和“没有变化的人”？或者我应该对每个受试者进行 2 次 Wilcoxon 非参数检验分析，以确定他们是否随着时间的推移而改善？
我在 Jamovi 上进行了分析（因为它非常适合初学者），但如果能提供 R 的示例语法，我将不胜感激]]></description>
      <guid>https://stats.stackexchange.com/questions/651585/how-to-verify-if-some-subjects-within-my-group-show-significant-changes</guid>
      <pubDate>Tue, 23 Jul 2024 11:11:25 GMT</pubDate>
    </item>
    <item>
      <title>Cohen's Kappa 的功效计算</title>
      <link>https://stats.stackexchange.com/questions/651584/power-calculations-for-cohens-kappa</link>
      <description><![CDATA[我想确定所需的样本量，以测量二元诊断测试的评分者间信度。有两位评分者。两位评分者的预期阳性诊断率均为 7.5%。

如何确定所需的样本量，以便分析具有足够的说服力？我使用了 R 中的 irr 包，但结果数字似乎太低：
irr::N.cohen.kappa(
rate1 = 0.075,
rate2 = 0.075,
k1 = 0.6,
k0 = 0,
alpha = 0.05,
power = 0.8,
twosided = FALSE
)
# [1] 25

如果 N=25，患病率为 7.5%，则只有 ~2 个阳性病例。我的解释正确吗？

假设 k0（零假设下的 Kappa 值）为 0，即除偶然之外没有其他一致性，这样对吗？我读到过，这应该是最低可接受的 Kappa，例如 0.4，而不是 0。


谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/651584/power-calculations-for-cohens-kappa</guid>
      <pubDate>Tue, 23 Jul 2024 10:16:12 GMT</pubDate>
    </item>
    <item>
      <title>商和比率的统计推断</title>
      <link>https://stats.stackexchange.com/questions/651583/statistical-inference-for-quotients-and-ratios</link>
      <description><![CDATA[我有一些关于 RCT 的数据，我们有兴趣计算干预的投资回报率。我们希望比较每个变体的两个总数的商，而不是以总和表示的更传统的结果。
主要问题是我们无法访问个人层面的数据，只能访问汇总到变体的数据。
我们知道每个变体的展示次数$n$、点击次数$c$和转化次数$k$。我们还知道我们总共花了多少钱，$X$，赚了多少钱$Y$。
我们想要比较
$$ Z = \frac{X}{Y} $$
每个变化。
我的直觉是取对数并计算
$$ \tilde{X_A} = \log(X_A) / n_A $$
$$ \tilde{Y_A} = \log(Y_A) / n_A $$
$$ \tilde{X_B} = \log(X_B) / n_B $$
$$ \tilde{Y_B} = \log(Y_B) / n_B $$&lt;​​/span&gt;
然后计算：
$$ (Y_B - X_B) - (Y_A - X_A) $$
作为检验统计量。
我的问题：
这是一种有效的方法吗？如果是，我如何传播不确定性来计算置信区间，或找到（合并）标准差？
有没有关于 RCT 这种指标的更广泛的文献？]]></description>
      <guid>https://stats.stackexchange.com/questions/651583/statistical-inference-for-quotients-and-ratios</guid>
      <pubDate>Tue, 23 Jul 2024 09:31:54 GMT</pubDate>
    </item>
    <item>
      <title>根据 beta、标准误差、样本大小和回归参数数量计算 p 值</title>
      <link>https://stats.stackexchange.com/questions/651582/compute-p-vale-from-beta-standard-error-sample-size-and-number-of-regression-p</link>
      <description><![CDATA[如果我只知道 beta（即线性回归的回归系数）、标准误差、样本大小和回归参数的数量，我该如何计算 p 值？
除了 p 值之外，还有其他方法可以确定统计显著性吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651582/compute-p-vale-from-beta-standard-error-sample-size-and-number-of-regression-p</guid>
      <pubDate>Tue, 23 Jul 2024 09:27:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 RCT 进行分类交互效应假设检验：我们应该将它们纳入逻辑回归模型吗？</title>
      <link>https://stats.stackexchange.com/questions/651580/hypothesis-testing-with-categorical-interaction-effects-with-rcts-should-we-inc</link>
      <description><![CDATA[我有一个二元治疗/控制的 RCT，其中用户会接触到新的 UI 元素和协变量，如下所示：

用户的种族（大约 5 个种族）
用户的设备（3 个设备）

我的结果是一个二元转换变量。
我已经建立了一个逻辑回归模型，并想推断群组（设备、种族或两者）对结果变量的影响大小。
因此，我将回归模型设置为包含所有主效应和所有双向交互作用。由于参考，这导致大约 15 个术语左右。我每组有 20,000 个观察值，所以这没问题。
但是，结果似乎不正确。我使用了 0-1 虚拟编码，而不是 -1、1 对比，似乎所有相互作用都与参考治疗-队列相互作用相关，这并不是我们真正想要的。这似乎只是告诉我一些治疗队列是否比参考类别具有显著更大的效果。
相反，我想针对治疗效果等同于对照效果的零假设对每个队列进行显着性检验。因此，这似乎并没有为我们提供进行我们想要的假设检验的方法。
所以我想知道：

我是否应该针对队列控制效应的零假设对每个队列组进行卡方检验？
我应该对比编码虚拟变量吗？

我还注意到，如果我包括所有交互作用和主效应，治疗系数就不显著，我认为这是因为我现在正在考虑参考与参考交互作用中的治疗效果。]]></description>
      <guid>https://stats.stackexchange.com/questions/651580/hypothesis-testing-with-categorical-interaction-effects-with-rcts-should-we-inc</guid>
      <pubDate>Tue, 23 Jul 2024 09:00:16 GMT</pubDate>
    </item>
    <item>
      <title>在SVM中使用增广权重向量和增广设计矩阵时，如何得到截距对应的第二个驻点条件？</title>
      <link>https://stats.stackexchange.com/questions/651575/how-to-get-the-second-stationary-point-condition-corresponding-to-intercept-when</link>
      <description><![CDATA[以下是我在使用 w.x + b = 0 作为分类器方程时得到的 SVM 公式

我想知道为什么当我使用包括截距的增强权重向量和通过在开头添加一列 1 获得的增强设计矩阵（形状为 nx(d+1)）时，我没有得到第二个平稳条件，即从 1 到 n 的 i 的总和 (alpha_i*y_i) = 0。这就是说，当我使用 w.x = 0 作为分类器方程并继续使用 SVM 公式时，我没有得到第二个平稳条件。]]></description>
      <guid>https://stats.stackexchange.com/questions/651575/how-to-get-the-second-stationary-point-condition-corresponding-to-intercept-when</guid>
      <pubDate>Tue, 23 Jul 2024 06:12:28 GMT</pubDate>
    </item>
    <item>
      <title>离散随机变量的归一化先验</title>
      <link>https://stats.stackexchange.com/questions/651573/normalized-prior-for-discretized-random-variable</link>
      <description><![CDATA[我想确认一下我对从离散化的连续随机变量中推导先验的理解，以及先验标准化条件的正确表达式，请告知以下工作是否一致且正确：
假设我们已经离散化了一个连续随机变量$\theta$，使得$\theta_1,...,\theta_d \in [0, \pi]$。然后我们得到贝叶斯规则给出的后验分布
$$P(\theta_j|\mu) = \frac{P(\mu|\theta_j)P(\theta_j)}{P(\mu)},$$ 其中 $\mu$ 表示测量结果，$P(\mu)$ 使后验标准化。然后，后验的标准化由 $\sum_{i}^{d}P(\theta_j|\mu)\delta \theta = 1$ 给出，其中 $\delta \theta = \theta_d/(d-1)$。
可以通过对 $\theta_j$ 的所有可能值求和来计算 $\mu$ 的边际分布，得出
$$P(\mu) = \sum_{j=1}^{d}P(\mu|\theta_j)P(\theta_j)\delta \theta.$$
我们还可以表示先验 $P(\theta_j)$ 作为边际分布
$$P(\theta_j) = \sum_{\mu}P(\theta_j|\mu)P(\mu),$$ 从而得出
$$P(\theta_j) = \sum_{\mu}P(\theta_j|\mu)\sum_{k=1}^{d}P(\mu|\theta_k)P(\theta_k)\delta \theta.$$
然后我们预期先验的正则化成立，因为 $\sum_{j=1}^{d} P(\theta_j)=1$。因此，我们不需要将因子 $\delta \theta$ 纳入先验的正则化，因为 $\sum_{j=1}^{d} P(\theta_j) \delta \theta=1$。这是正确的吗？感谢您的时间和帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/651573/normalized-prior-for-discretized-random-variable</guid>
      <pubDate>Tue, 23 Jul 2024 05:55:18 GMT</pubDate>
    </item>
    <item>
      <title>回归：下限和上限</title>
      <link>https://stats.stackexchange.com/questions/651569/regression-lower-and-upper-bounds</link>
      <description><![CDATA[假设我想预测电子商务/物流服务的预计交货时间范围。范围越窄，可靠性就越高。我对既能 1/ 准确预测范围，又能 2/ 生成尽可能窄的范围的损失函数感到好奇。
我现在正在构思的设计是一个具有二维输出的回归模型（可以包括但不限于深度神经网络）。这些参数分别是 [l, u] 下限和上限。
假设给定观测的地面实况观测是 e（eta。）我提出的损失函数是
$$\frac{1}{(u-e)(e-l)}$$
一些说明

如果 $u&gt; e$，则第一项为负；但第二项将为正。
如果 $e&gt;l$，则第二项为负，但第一项为正。
取倒数是为了惩罚过宽的范围，例如 60 天。
理论上，边界可以翻转，其中 $l&gt;u$。在这种情况下，这两个负数将抵消，产生较大的分母和较小的奖励。

目标是最大化奖励（而不是最小化损失）。
我的问题是

对下限和上限的预测是否常见？这通常是如何做到的？
我是否错过了这个奖励函数在很大程度上适得其反的关键方法？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651569/regression-lower-and-upper-bounds</guid>
      <pubDate>Tue, 23 Jul 2024 02:11:27 GMT</pubDate>
    </item>
    <item>
      <title>如何模拟二元结果中分类变量和连续变量之间的相互作用？</title>
      <link>https://stats.stackexchange.com/questions/651524/how-to-simulate-interaction-between-categorical-and-continuous-variables-over-a</link>
      <description><![CDATA[为了进行功效分析，我需要模拟数据以运行 glmer 模型，该模型在二元结果 (0,1) 上具有分类 (三个级别) 和连续 (将成为调节因素；高分参与者与低分参与者) 之间的交互作用。我不知道如何为每种情况定义不同的效果大小或平均差异。我预计高分参与者在 a 级的结果比例较高，在 b 级的比例适中，在 c 级的比例较低，而低分参与者在 a 级和 b 级的比例较低，但在 c 级的比例适中。或者这些细节与功效分析无关？]]></description>
      <guid>https://stats.stackexchange.com/questions/651524/how-to-simulate-interaction-between-categorical-and-continuous-variables-over-a</guid>
      <pubDate>Mon, 22 Jul 2024 11:09:16 GMT</pubDate>
    </item>
    <item>
      <title>计算 p 值 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/651519/calculating-p-values</link>
      <description><![CDATA[下面的代码汇总了单个事件研究回归的估计值，以计算所有治疗的平均效果。平均效果在概念上等同于堆叠回归的输出，但具有能够使用自定义权重来计算更有效的平均值的优势。但是，代码只给出了每个结果的系数和标准误差。我还想找到 p 值来确定统计显著性。由于我不想对我的代码进行重大修改，我该怎么做呢？
或者，我如何在给定系数和标准误差的情况下手动计算 p 值？
salesVars &quot;w_log_net log_WAC log_units log_sales&quot;
local coverageVars &quot;glp_chm&quot;

local sets `&quot; &quot;&quot; &quot;&quot; _trend&quot; &quot;&#39;

foreach 本地集合 {

* 打开文件，写入标题
file open tableA1 using &quot;${paperdir}\Tables\Table A1`set&#39;.csv&quot;, write replace

file write tableA1 &quot;变量，所有交易，高于 HSR 阈值的交易，低于 HSR 阈值的交易，由收购方拥有&quot; _n

foreach 销售覆盖率中的样本 {

use &quot;${coeffdir}\coefficients_`sample&#39;_all.dta&quot;, replace

* 横向收购的平均效应
foreach 本地 `sample&#39;Vars 的 var {

* ALL
qui egen wavg_`var&#39; = wtmean(b_`var&#39;_b`set&#39;) ///
if acquire == 1 &amp; same_atc3 == 1，权重（1/（se_`var&#39;_b`set&#39;^2））
qui egen wvar_`var&#39; = mean（1/（se_`var&#39;_b`set&#39;^2）） ///
if acquire == 1 &amp; same_atc3 == 1
qui replace wvar_`var&#39; = sqrt（1/wvar_`var&#39;）
// qui egen simplevar_`var&#39; = total（se_`var&#39;_b`set&#39;^2） ///
// if acquire == 1 &amp; same_atc3 == 1 &amp; medVH == 0
// qui replace simplevar_`var&#39; = sqrt（simplevar_`var&#39;）

* 记录值
// sum b_`var&#39;_b`set&#39; if acquire == 1 &amp; same_atc3 == 1 &amp; medVH == 0
// 本地 avgAll : 显示 %4.2f r(平均值)
// 求和 simplevar_`var&#39;
// 本地 sdAll : 显示 %4.2f r(平均值)
// 删除 simplevar_`var&#39;
求和 wavg_`var&#39;
本地 avgAllEff : 显示 %4.2f r(平均值)
删除 wavg_`var&#39;
求和 wvar_`var&#39;
本地 sdAllEff : 显示 %4.2f r(平均值)
删除 wvar_`var&#39; 

// 文件写入 tableA1 &quot;`var&#39;,`avgAbove&#39;,`avgAboveEff&#39;,`avgBelow&#39;,`avgBelowEff&#39;,`avgOwned&#39;,`avgOwnedEff&#39;&quot; _n
// 文件写入表A1 `&quot;,=&quot;(`sdAbove&#39;)&quot;,=&quot;(`sdAboveEff&#39;)&quot;,=&quot;(`sdBelow&#39;)&quot;,=&quot;(`sdBelowEff&#39;)&quot;,=&quot;(`sdOwned&#39;)&quot;,=&quot;(`sdOwnedEff&#39;)&quot;&quot;&#39; _n

文件写入表A1 &quot;`var&#39;,`avgAllEff&#39;,`avgAboveEff&#39;,`avgBelowEff&#39;,`avgOwnedEff&#39;&quot; _n
文件写入表A1 `&quot;,=&quot;(`sdAllEff&#39;)&quot;,=&quot;(`sdAboveEff&#39;)&quot;,=&quot;(`sdBelowEff&#39;)&quot;,=&quot;(`sdOwnedEff&#39;)&quot;&quot;&#39; _n

}

}

文件关闭表A1

]]></description>
      <guid>https://stats.stackexchange.com/questions/651519/calculating-p-values</guid>
      <pubDate>Mon, 22 Jul 2024 10:17:03 GMT</pubDate>
    </item>
    <item>
      <title>如何在多项回归中找到 $p_k$ 的期望值</title>
      <link>https://stats.stackexchange.com/questions/651424/how-to-find-the-expected-value-of-p-k-in-multinomial-regression</link>
      <description><![CDATA[给定多项回归，某个类$k$的概率是预测因子的函数。假设我们知道 ${\bf X}_i$ 的分布，那么如何通过分析找到 $p_k$ 的期望值？
多项回归作为对数线性模型：
$$
\text{ln Pr}(Y_i = k) = \beta_k \cdot{\bf X}_i - \text{ln} Z 
$$
$$
Z = \sum_{k=1}^K e^{\beta_k\cdot{\bf X}_i}
$$
$$
\text{Pr}(Y_i = k) = \frac{e^{\beta_k \cdot{\bf X}_i}}{\sum_{k=1}^K e^{\beta_k\cdot{\bf X}_i}} 
$$
感兴趣的数量是$\mathbf{E}(\text{Pr}(Y_i = k))$。条件期望：$\mathbf{E}(\text{Pr}(Y_i = k)|X_i))$不是感兴趣的，可以通过插入$X_i$的值来找到
我们还可以将多项回归指定为具有参考类别的对数几率。不确定哪种方法更容易进行分析。
一个预测变量和 3 个类的示例：
$$
X_i \sim Norm(0,1)
$$
$$
\beta_1 = a, \beta_2 = b, \beta_3 = c
$$
$$
Pr(Y_i = k) = \frac{e^{\beta_k \cdot X_i}}{e^{\beta_1 \cdot X_i} + e^{\beta_2 \cdot X_i} + e^{\beta_3 \cdot X_i}}
$$
有什么解决这个问题的技巧吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651424/how-to-find-the-expected-value-of-p-k-in-multinomial-regression</guid>
      <pubDate>Fri, 19 Jul 2024 19:46:46 GMT</pubDate>
    </item>
    <item>
      <title>对贝叶斯决策理论感到困惑</title>
      <link>https://stats.stackexchange.com/questions/651418/confused-on-bayesian-decision-theory</link>
      <description><![CDATA[我试图理解选择“动作”的正确方法是什么，正如 Murphy 在《机器学习的概率视角》一书中在“贝叶斯决策理论”一节中所说的那样。
我会把问题说得更清楚，因为在上一篇文章中并没有。假设我们的数据来自一个线性过程 $Y = \beta X + \epsilon$。理论上，给定一组训练数据 $D = (\mathbb{Y}, \mathbb{X})$，我们希望最小化泛化误差 $E_{Y|X,\theta^*, D}[\mathcal{L}(Y, g(X, D))|D]$，其中 $\mathcal{L}$ 是损失函数，$g$ 是我们在 $D$ 上训练的预测模型，也就是说，一旦给出新的输入，它就会输出一个决策 $\hat{Y}$，并且期望值是根据真实的、未知的数据生成过程得出的，即 $\hat{Y}$， class=&quot;math-container&quot;&gt;$Y = \beta X + \epsilon$，对于本例中的未知 $\beta$。我们估计泛化误差的唯一方法是使用分离的测试集，但如果我们用它来选择预测模型，这当然就不再是测试集了。因此，在频率论中，假设目标是泛化误差，人们会寻找策略来评估它，它在训练集上的平均值，它的其他代理或使用一些理论选择标准，所有这些都基于这样的想法：你的训练是真实 DGP 下可能的一种。
现在，我不清楚的是你应该如何在贝叶斯框架中推理，你的目标是什么。所以，就我所理解的而言，即使在贝叶斯框架中，为了评估我的模型的泛化能力，我也需要一个测试集。如果我根据我的后验来做这件事，我想最终我会对一些实际上不太好的事情感到满意。因此，即使在贝叶斯框架中，我的理想目标也是之前定义的泛化误差，其中平均值是相对于真实 DGP 取的。因此，即使在贝叶斯框架中，我们也无法直接将其最小化，因为我们无法使用测试数据来选择模型。
因此，问题 1，作为贝叶斯，我们所做的是否正确，即尝试通过取其均值除以后验预测值来近似这个泛化误差？
因此，而不是：
$
err(g) = E_{Y|X,\theta^*}[\mathcal{L}(Y, g(X, D))] =\int \mathcal{L}(y, g(X, D))p(Y|X, \theta^*)\mathrm{d}y = \int \mathcal{L}(y, \beta_{\lambda}(D)X) p(Y|X, \theta^*)\mathrm{d}y
$
这就是感兴趣的泛化误差，在最后一个等式中，我明确地写出了相对于给定估计值的岭惩罚下的参数的预测，该估计值是特定值 $\lambda$，我们评估：
$
\int \mathcal{L}(y, g(X, D))p(y|X, g)p(g|D)\mathrm{d}y\mathrm{d}g = 
\int \mathcal{L}(y, \beta_{\lambda}X)p(y|X, \beta)p(\beta|\lambda, D) p(\lambda |D)\mathrm{d}y\mathrm{d}\beta\mathrm{d}\lambda
$
然后是另一个令人困惑的点。假设我们有一个岭模型先验，并且是$\lambda$这种先验的超参数。假设我们使用二次损失，使用绝对值不会改变我的观点。
如何根据新的未见数据 X 建立预测？
选项 1：
Be
$
p(Y|X, D) = \int p(Y|X, \beta)p(\beta|D, \lambda) p(\lambda | D) \mathrm{d}\beta\mathrm{d}\lambda
$
我的后验预测。如果您的最小化问题是：
$
a^*(X) = \mathrm{argmin}_{a: \mathcal{D}_X \to \mathcal{D}_Y}\int\mathcal{L}(y, a(X))P(y|X, D) \mathrm{d}y
$
那么对于二次损失，您的预测$a(X)$将是后验的平均值。
选项 2：
$
a^*(X) = \mathrm{argmin}_{a}\int\mathcal{L}(y, a(X, \beta, \lambda))p(Y|X, \beta)p(\beta|D, \lambda) p(\lambda | D) \mathrm{d}\theta\mathrm{d}\lambda
\mathrm{d}y
$
在第二种情况下，我不清楚如何选取一个，而是在每个新点重新评估积分。]]></description>
      <guid>https://stats.stackexchange.com/questions/651418/confused-on-bayesian-decision-theory</guid>
      <pubDate>Fri, 19 Jul 2024 16:58:44 GMT</pubDate>
    </item>
    <item>
      <title>以和为条件的 iid 平方的期望值</title>
      <link>https://stats.stackexchange.com/questions/651402/expected-value-of-iid-squared-conditioned-on-sum</link>
      <description><![CDATA[我有兴趣找到以下表达式的值：
$$\mathbb{E}[X_k^2\mid S_N]$$
其中 $X_k$ 是 iid 随机变量，$\mathbb{E}[X_k]=\mu$ 和 $\operatorname{Var}[X_k]=\sigma^2$，$N$ 是确定性常数，并且：
$$S_N=\sum_{i=1}^N X_i$$
我尝试使用
$$\mathbb{E}[S_N^2]=N\mathbb{E}[X_k^2 \mid S_N]+N(N-1)\mathbb{E}[X_i X_j\mid S_N]$$
其中$i\neq j$。尽管如此，即使不同的 $X_k$ 是独立的，它们也不一定满足 $\mathbb{E}[X_i X_j\mid S_N]=\mathbb{E}[X_i\mid S_N]^2$
编辑：我尝试的另一种方法是使用以下事实：
$$\mathbb{E}[X_k^2\mid S_N] = \text{Var}(X_k\mid S_N) - \mathbb{E}[X_k\mid S_N]^2$$
总和的第二项可以很容易地证明为 $S_N^2/N^2$。尽管如此，条件方差对我来说仍然不容易破解。我尝试将 $\text{Var}(X_k\mid S_N)$ 与 $\text{Cov}(X_k, S_N) = \sigma^2$ 关联起来，但没有成功。]]></description>
      <guid>https://stats.stackexchange.com/questions/651402/expected-value-of-iid-squared-conditioned-on-sum</guid>
      <pubDate>Fri, 19 Jul 2024 13:00:49 GMT</pubDate>
    </item>
    </channel>
</rss>