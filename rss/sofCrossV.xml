<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 08 Dec 2024 15:17:33 GMT</lastBuildDate>
    <item>
      <title>如何分配列中的真实类别以进行分析</title>
      <link>https://stats.stackexchange.com/questions/658453/how-to-assign-the-true-classes-in-a-column-to-proceed-the-analysis</link>
      <description><![CDATA[我想基于两个独立变量 question_type 和 string_lenght 以及一个因变量 response_time 进行双向方差分析。
但我有这个数据集，其中 question_type 列存在问题，我错误地分配了“base_line”值，而不是“sidebyside_base_line”、“sidebyside_color”、“topofeach_color”或“topofeach_base_line”。我该如何解决这个问题，因为您知道唯一可能有帮助的列是 length_string 或 response_time 或 isAnswerCorrect。那么我该如何修复这个问题并分配真实值而不是“base_line”呢？
正如您在图中看到的，每个类别的值数量。

我的目标是用这些行的真实类替换 base_line。 i
我的数据在这里：
https://docs.google.com/spreadsheets/d/16cwLFGaF4KqLvwYNjHIcCyHaWup8vSJpL7gOEqk_XPA/edit?usp=sharing]]></description>
      <guid>https://stats.stackexchange.com/questions/658453/how-to-assign-the-true-classes-in-a-column-to-proceed-the-analysis</guid>
      <pubDate>Sun, 08 Dec 2024 13:59:36 GMT</pubDate>
    </item>
    <item>
      <title>具有多个结果变量的潜在类别线性混合模型与 R 中的 LCMM 的收敛</title>
      <link>https://stats.stackexchange.com/questions/658452/convergence-of-latent-class-linear-mixed-model-with-lcmm-in-r-with-multiple-outc</link>
      <description><![CDATA[我正在寻求帮助，使用 R 中的 LCMM 包 使我的 潜在类别线性混合模型 收敛。
我正在处理一个关于帕金森病认知功能的大型纵向数据集，并试图从 0 到 10 年的数据点中识别认知概况。每年都会进行多项认知测试来评估认知领域。这会产生 8 个独立的结果变量。我的数据集包含 732 名帕金森病患者，其中一些患者在数据点有缺失值。
我正在使用 R 中的 lcmm 包的潜在类别线性混合模型来模拟随时间变化的认知变化。这是模型设置，其中我只包含了 3 个认知变量：
mlclmm_model &lt;- multlcmm(

fixed = DVT_SDM + DVT_TOTAL_RECALL + DVT_SFTANIM ~ YEAR + age,

random = ~ YEAR | PATNO,

subject = &quot;PATNO&quot;,

data = Data_plot,

ng = 1,

maxiter = 200,

link = &quot;linear&quot;

)

这是模型摘要的输出：

一般潜在类混合模型

通过最大似然法拟合

multlcmm(fixed = DVT_SDM + DVT_TOTAL_RECALL + DVT_SFTANIM ~ YEAR +

age, random = ~YEAR | PATNO, subject = &quot;PATNO&quot;, ng = 1, link = &quot;linear&quot;,

data = Data_plot, maxiter = 200)

统计模型：

数据集：Data_plot

受试者数量：732

观察次数：11085

潜在类别数量：1

参数数量：13

链接函数：DVT_SDM 为线性

DVT_TOTAL_RECALL 为线性

DVT_SFTANIM 为线性

迭代过程：

未收敛时达到最大迭代次数

迭代次数：200

收敛标准：参数= 4.8e-08

: 似然= 1.5e-11

: 二阶导数= 1

拟合优度统计：

最大对数似然：-40602.06

AIC：81230.12

BIC： 81289.86 

最大似然估计：

纵向模型中的固定效应：

coef Se Wald p 值

截距（未估计） 0.00000 

YEAR -0.08738 

age -0.02394 

随机效应的方差-协方差矩阵：

（第一个随机效应的方差未估计）

截距 YEAR | PATNOTRUE

截距 1.00000 

YEAR | PATNOTRUE 0.46015 3.24264

DVT_SDM DVT_TOTAL_RECALL DVT_SFTANIM

残差标准误差：1.80111 4.34913 4.04510 

链接函数的参数：

coef Se Wald p 值

DVT_SDM-Linear 1 51.61487 

DVT_SDM-Linear 2 3.70604 

DVT_TOTAL_RECALL-Linear 1 49.70980 

DVT_TOTAL_RECALL-Linear 2 2.37214 

DVT_SFTANIM-Linear 1 55.30213 

DVT_SFTANIM-Linear 2 2.39356

问题：
模型达到了最大迭代次数 (200) 而未收敛。
收敛标准非常小（参数 = 4.8e-8，似然 = 1.5e-11），但仍未实现收敛。
输出报告二阶导数 = 1，这表明可能存在数值稳定性或不可识别性问题。我也尝试过使用更多变量的模型，但这也无法实现收敛。
鉴于我的模型的复杂性，我在收敛方面遇到了困难。此问题的潜在原因可能是什么？是否有任何最佳实践或策略可确保此类模型收敛？我是否应该考虑将参数固定为零（例如样条系数），或者是否有其他方法可以解决这个问题？任何有关提高模型稳定性或改进收敛过程的建议都将不胜感激。我最终想考虑更多的认知变量，而不仅仅是 3 个。]]></description>
      <guid>https://stats.stackexchange.com/questions/658452/convergence-of-latent-class-linear-mixed-model-with-lcmm-in-r-with-multiple-outc</guid>
      <pubDate>Sun, 08 Dec 2024 12:58:50 GMT</pubDate>
    </item>
    <item>
      <title>IV 等级/相关性条件线性代数直觉</title>
      <link>https://stats.stackexchange.com/questions/658451/iv-rank-relevance-condition-linear-algebra-intuition</link>
      <description><![CDATA[我正在研究工具变量，我遇到了矩阵形式的相关性条件：$\mathbb{E}[ZX&#39;]$ 必须具有秩 k，其中$Z \in \mathbb{R}^\mathcal{l}, X \in \mathbb{R}^k, \mathcal{l} \geq k$。我可以理解这里与 $Cov(X, Z)$ 的联系，但我只是不太清楚为什么秩条件意味着这一点（与 $Z$ 变换对 $X$ 列的作用有关），以及这在某种意义上必须“保留”至少 $X$ 维度以使其相关。
此外，在我看来，这似乎与原始 OLS 案例中的秩条件有些相关：$\hat{\beta} = (X&#39;X)^{-1}X&#39;y$，其中秩也必须是 k（这次我们希望我们的回归量是线性独立的，并且每个回归量都“提供一些新的东西”）。再次，这将 $\beta$ 的最简单形式概括为 $\frac{Cov}{Var}$。（这里的 $Var(X)$ 和 $(X&#39;X)$ 之间有什么联系？）。
总而言之，我缺少一些几何直觉，无法理解这些变换如何告诉我们空间中不同变量的方差/协方差。我一直在尝试复习一些线性代数知识，但还是无法理解。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658451/iv-rank-relevance-condition-linear-algebra-intuition</guid>
      <pubDate>Sun, 08 Dec 2024 11:34:47 GMT</pubDate>
    </item>
    <item>
      <title>一些软件将时间序列数据转换为持久同源性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658450/some-software-s-to-convert-time-series-data-to-persistance-homology</link>
      <description><![CDATA[目前我正在研究拓扑数据分析。我是一个完全的初学者。我正在尝试将时间序列数据转换为持久性同源性和景观。有哪些管道和软件可以做到这一点？
我可以用 python 和 R 做到这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658450/some-software-s-to-convert-time-series-data-to-persistance-homology</guid>
      <pubDate>Sun, 08 Dec 2024 11:32:16 GMT</pubDate>
    </item>
    <item>
      <title>在多输出回归中设置加权 MSE 权重的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/658449/what-is-the-best-way-to-set-weights-for-weighted-mse-in-multi-output-regression</link>
      <description><![CDATA[我正在研究一个回归任务，目标是从给定的输入预测 6 个标量输出值。输入由衰减信号数据组成，输出是信号方程的参数。
最初，我认为这将是一项简单的任务。我的第一种方法是训练一个具有 6 个输出节点的简单 MLP。但是，我遇到了一个问题，即 6 个参数的尺度相差很大。
为了解决这个问题，我尝试使用加权 M​​SE 损失，其中权重设置为标签中每个参数的平均值的倒数。不幸的是，这种方法的表现始终不如为每个参数单独训练 6 个独立的（小得多）网络。当我使用不带权重的标准 MSE 损失时，结果更糟。
我还考虑过根据训练数据集对输出标签进行规范化并将其用于推理。但是，它不是可以推广的（抱歉，找不到更好的词）。
在这种情况下，有什么有效的方法可以尝试吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658449/what-is-the-best-way-to-set-weights-for-weighted-mse-in-multi-output-regression</guid>
      <pubDate>Sun, 08 Dec 2024 11:31:34 GMT</pubDate>
    </item>
    <item>
      <title>即使在标准化之后，K 均值聚类仍然过于强调单个变量：如何纠正？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658448/k-means-clustering-is-giving-too-much-emphasis-on-a-single-variable-even-after-n</link>
      <description><![CDATA[即使是基于两个变量的 z 分数进行聚类，K 均值聚类的结果也主要基于单个变量。我真的不明白为什么下面散点图右下角的点不属于同一组。
问题是：我应该使用另一种聚类算法，还是应该调整 Kmeans（给我的数据添加一定的权重？怎么做？）？
谢谢，
]]></description>
      <guid>https://stats.stackexchange.com/questions/658448/k-means-clustering-is-giving-too-much-emphasis-on-a-single-variable-even-after-n</guid>
      <pubDate>Sun, 08 Dec 2024 11:15:20 GMT</pubDate>
    </item>
    <item>
      <title>Copula 模型是否适合解释橄榄种植园数据的时间动态？</title>
      <link>https://stats.stackexchange.com/questions/658446/is-copula-modeling-suitable-for-accounting-for-temporal-dynamics-in-olive-planta</link>
      <description><![CDATA[我正在开展一个分析橄榄种植园数据的项目，目的是模拟投资成本（Costs）、收入（Revenues）和温度（Temp）随时间的变化关系，并考虑数据的特定时间动态。 目标是为未来的树木种植园生成现实的情景。我的想法是使用 copula。
我拥有的数据包括 10 年的年度记录，其中：

成本代表橄榄种植园所需的投资。
收入代表橄榄销售的回报。
温度是年平均温度。
TempCng是年度温度变化。

由于数据本质上是时间性的（即，成本和收入不是独立的，也不是随时间相同分布的），我的目标是捕捉时间结构，特别是重要的初始投资（成本），其次是收入（收入），只有由于树木需要时间生长，因此需要几年时间才能实现。为了解决这个问题，我在分析中加​​入了时间趋势变量。
这是我目前的方法：
# 软件包
library(VineCopula)
library(copula)

# 为方便起见，使用合成数据
成本 &lt;- c(100, 0, 150, 50, 0, 0, 0, 0, 0)
收入 &lt;- c(0, 0, 0, 50, 0, 225, 100, 0, 150, 5)
温度 &lt;- c(20.00, 21.60, 16.05, 15.68, 17.40, 19.51, 19.87, 19.02, 18.21, 18.18)
TempCng &lt;- c(0.001464764, diff(Temp) / head(Temp, -1))
Years &lt;- seq(2008,2017)

# 创建数据框
OliveTrees &lt;- data.frame(Costs, Revenues, Temp, TempCng, row.names = Years)

# 计算平均值和标准差
mu_C &lt;- mean(Costs)
mu_R &lt;- mean(Revenues)
mu_T &lt;- mean(TempCng)

sigma_C &lt;- sd(Costs)
sigma_R &lt;- sd(Revenues)
sigma_T &lt;- sd(TempCng)

# 规范化数据
OliveTrees$CNorm &lt;- (OliveTrees$成本 - mu_C) / sigma_C
OliveTrees$RNorm &lt;- (OliveTrees$收入 - mu_R) / sigma_R
OliveTrees$TNorm &lt;- (OliveTrees$TempCng - mu_T) / sigma_T

# 应用经验分布
C_dist &lt;- pobs(OliveTrees$CNorm)
R_dist &lt;- pobs(OliveTrees$RNorm)
T_dist &lt;- pobs(OliveTrees$TNorm)

# 时间趋势（年份序列）
S_dist &lt;- pobs(1:nrow(OliveTrees))

# 合并分布
U &lt;- cbind(C_dist, R_dist, T_dist, S_dist)

# 拟合高斯 copula
CopulaModel &lt;- normalCopula(dim = 4, dispstr = &#39;un&#39;)
FittedCopula &lt;- fitCopula(CopulaModel, U, method = &#39;ml&#39;)
CopulaModel@parameters &lt;- coef(FittedCopula)

# 从 copula 进行模拟
set.seed(321)
U &lt;- rCopula(n = nrow(OliveTrees), CopulaModel)

# 对模拟值进行排序以说明时间趋势
U &lt;- U[order(U[, 4]), ]

# 应用逆 CDF 来获取模拟值
C_sim &lt;- quantile(OliveTrees$CNorm, U[, 1])
R_sim &lt;- quantile(OliveTrees$RNorm, U[, 2])
T_sim &lt;- quantile(OliveTrees$TNorm, U[, 3])

# 对模拟值进行非规范化
C_sim &lt;- round(C_sim * sigma_C + mu_C, 2)
R_sim &lt;- round(R_sim * sigma_R + mu_R, 2)
T_sim &lt;- T_sim * sigma_T + mu_T

# 为模拟结果创建数据框
OliveTrees_sim &lt;- data.frame(C_sim, R_sim, T_sim, row.names = Years)
OliveTrees_sim$Temp &lt;- round(OliveTrees$Temp[1] * c(1, cumprod(1 + OliveTrees_sim$T_sim[2:length(OliveTrees_sim$T_sim)])), 2)

我的问题：

这种 copula 方法是否适用于解释橄榄种植园数据的时间动态？具体而言，时间动态是指初始成本很高，随后收入不断增长，由于时间结构的原因，两者并非 IID。

包括时间趋势（以年序列的形式）是否是建模时间依赖性的合适解决方案？

是否有任何文献或研究支持这种方法，或者是否有更好的方法来对数据中的时间依赖性进行建模？

是否有更好的建模方法或改进可以更好地捕捉成本、收入和温度之间的时间动态？


感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/658446/is-copula-modeling-suitable-for-accounting-for-temporal-dynamics-in-olive-planta</guid>
      <pubDate>Sun, 08 Dec 2024 10:45:46 GMT</pubDate>
    </item>
    <item>
      <title>频率显著性和引导法之间的不一致</title>
      <link>https://stats.stackexchange.com/questions/658444/inconsistencies-between-frequentist-significance-and-bootstrapping</link>
      <description><![CDATA[我偶然发现了以下说法：
频率显著性检验的不一致并不罕见，可能由各种因素引起。然而，当样本独立且样本量足够大时，非参数引导法通常更可靠。
这个说法正确吗？有人能提供一些参考资料来支持这一点吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658444/inconsistencies-between-frequentist-significance-and-bootstrapping</guid>
      <pubDate>Sun, 08 Dec 2024 10:13:08 GMT</pubDate>
    </item>
    <item>
      <title>小基因集 RT-qPCR 研究中多重检验校正</title>
      <link>https://stats.stackexchange.com/questions/658442/multiple-test-correction-in-rt-qpcr-studies-with-small-gene-set</link>
      <description><![CDATA[我进行了一项实验，使用 RT-qPCR 分析了手动选择的 12 个基因的小型集合的表达。这些基因的选择基于它们密切的生物学关系及其在研究的特定过程中的参与。与同时筛选数千个基因的 RNA-seq 不同，这项研究更有针对性且以假设为导向，针对少数已知相关性的基因。
一个反复出现的问题是，在这种情况下如何处理多重测试校正。虽然在高通量实验中校正是强制性的，但将其应用于小的、相互关联的和可能相互依赖的基因
关键考虑因素

生物依赖性：

由于基因是根据其生物学相关性手动选择的，因此有人可能会认为严格的多重测试校正可能过于保守并导致假阴性。


低维数据：

在这种情况下，多重测试校正的影响不太严重，置信度为 0.95，我甚至没有达到一个假阳性的概率（12 个基因 x 0.05）。一些研究人员认为，如果研究是假设驱动的，那么可能甚至没有必要。


基因独立性（缺乏）：

所选基因并不独立；它们是同一生物网络的一部分，我们可能会发现它们之间存在共线性。这违反了大多数校正方法的一个关键假设，即将测试视为独立。还有其他方法吗？（只是出于好奇）




您认为多次测试校正对于这个实验有多必要？
在这样的有针对性的研究中，您如何平衡所研究的生物标志物之间已证实的生物依赖性？对多重假设的依赖背后有什么理由吗？

提前感谢您的贡献。]]></description>
      <guid>https://stats.stackexchange.com/questions/658442/multiple-test-correction-in-rt-qpcr-studies-with-small-gene-set</guid>
      <pubDate>Sun, 08 Dec 2024 09:20:02 GMT</pubDate>
    </item>
    <item>
      <title>使用调查平均值从单个预测中得出估计值的难度</title>
      <link>https://stats.stackexchange.com/questions/658440/difficulty-in-deriving-a-estimator-using-survey-means-from-individual-forecasts</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658440/difficulty-in-deriving-a-estimator-using-survey-means-from-individual-forecasts</guid>
      <pubDate>Sun, 08 Dec 2024 07:58:33 GMT</pubDate>
    </item>
    <item>
      <title>我可以在 Cox PH 中使用年龄作为随时间变化的协变量吗？</title>
      <link>https://stats.stackexchange.com/questions/658439/can-i-use-age-as-a-time-varying-covariate-in-a-cox-ph</link>
      <description><![CDATA[我正在研究叛乱团体领导人在被迫下台之前会掌管叛乱团体多长时间。我有领导人年份数据，其中包含以下变量：

groupid = 每个团体的唯一 ID 号
leaderid = 每个领导人的唯一 ID 号
tenure = 领导人首次掌权以来的时间（从 0 开始计数）
forcedexit = 领导人被迫下台时取值为 1，其他年份取值为 0
groupage = 团体成立以来的时间（从 0 开始计数）

我的数据集中，叛乱团体活跃的每一年都有一行。数据通常如下所示：
 groupid leaderid forcedexit tenure groupage
&lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 411 1 0 0 0
2 411 1 0 1 1
3 411 1 0 2 2
4 411 2 1 0 3
5 411 2 0 1 4
6 411 2 0 2 5
7 411 2 0 3 6
8 411 3 0 0 7
9 411 3 0 1 8
10 411 3 0 2 9

请注意，新领导人可以通过强制退出以外的方式上台，因此即使 forcedexit = 0，领导人也可能离职（例如，参见上述数据中的 leaderid = 3）。
我想测试一下在较老的群体中，领导人是否更难被罢免。我的直觉是运行 Cox PH 模型（我使用的是 R）：
mod &lt;- coxph(Surv(tenure, forcedexit) ~ groupage, data = df)
如果我运行这个，我会得到 groupage 系数的负且显著的估计值，这与我的直觉一致。但是，出于两个原因，我对这个结果持谨慎态度。
首先，我可以在 Cox PH 中使用 groupage 作为随时间变化的变量吗？我读过的大多数使用 Cox PH 的医学研究都使用不会随时间变化的年龄变量（例如，试验开始时的年龄）。我的 groupage 变量确实会随时间而变化。
其次，我担心 groupage 和 tenure 变量之间的关系会出现一些问题。某些 tenure 值在 groupage 的某些值下不可能存在。例如，tenure = 5 和 groupage = 0 永远不可能存在，因为组必须存在，领导者才能负责该组。因此，较高的 groupage 值可能与较高的 tenure 值一起机械地出现。如果领导者拥有较大的 tenure，则 groupage 也必须较大。
对这两个问题的任何想法都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658439/can-i-use-age-as-a-time-varying-covariate-in-a-cox-ph</guid>
      <pubDate>Sun, 08 Dec 2024 05:02:32 GMT</pubDate>
    </item>
    <item>
      <title>标准化回归模型的变量与回归模型中的权重？</title>
      <link>https://stats.stackexchange.com/questions/658437/standardizing-variables-for-a-regression-model-vs-weights-in-a-regression-model</link>
      <description><![CDATA[我在 R 中有一个纵向 GAM（一般加性模型）回归。
以下是模型和数据的一般形式（响应介于 0 和 1 之间）：
gam_model &lt;- gam(
response ~ 
te(time_var, var1) +
te(time_var, var2) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

state time_varpopulation var1 var2 response
state_1 2005-01-01 1000000 500000 10000 0.45
state_1 2005-02-01 1001000 520000 12000 0.47
state_1 2005-03-01 1002001 540000 11000 0.46
state_1 2005-04-01 1003002 560000 13000 0.48
state_2 2005-01-01 200000 100000 2000 0.42
state_2 2005-02-01 200200 105000 2400 0.44
state_2 2005-03-01 200400 110000 2200 0.43
state_2 2005-04-01 200600 115000 2600 0.45

我遇到的问题如下：

数据按州提供（多个州，1 个国家），但每个州的人口不同
这让我认为需要对模型进行一些处理，以防止人口较多的州对响应的影响比人口较少的州更大
我有每个州的人口

我正在考虑使用以下权重公式（我从这里得到这个想法https://www.nature.com/articles/s41598-024-54441-x）：
$$avg\_weight_s = \frac{1}{T}\sum_{t=1}^{T} \frac{\ln(population_{s,t})}{\frac{1}{N}\sum_{i=1}^{N} \ln(population_{i,t})}$$
其中：

$T$ 是时间段的总数
$N$ 是州的总数
$population_{s,t}$ 是 $t$ 时刻 $s$ 州的人口数
$population_{i,t}$ 表示每个州 $i$ 在时间 $t$ 的人口。

这让我考虑不同的模型选项：
# 选项 1：非标准化，无权重

gam_model &lt;- gam(
response ~ 
te(time_var, var1) +
te(time_var, var2) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

# 选项 2：标准化，无权重

gam_model &lt;- gam(
响应 ~ 
te(time_var, var1/population) +
te(time_var, var2/population) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

# 选项 3：未标准化，权重

gam_model &lt;- gam(
响应 ~ 
te(time_var, var1) +
te(time_var, var2) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
weights = avg_weight,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

# 选项 4：标准化，权重

gam_model &lt;- gam(
response ~ 
te(time_var, var1/population) +
te(time_var, var2/population) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
weights = avg_weight,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

我有点困惑，不知道这些选项中哪一个在逻辑上是正确的。我认为其中一些可能有点过度，而另一些则完全不正确。有办法解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658437/standardizing-variables-for-a-regression-model-vs-weights-in-a-regression-model</guid>
      <pubDate>Sun, 08 Dec 2024 04:38:44 GMT</pubDate>
    </item>
    <item>
      <title>如果异常值少于数据点的 10％，您可以删除它们吗？[重复]</title>
      <link>https://stats.stackexchange.com/questions/658405/can-you-remove-outliers-if-they-are-less-than-10-of-the-datapoints</link>
      <description><![CDATA[我目前正在上我的第一堂数据分析课，我们会做一些简单的假设检验，比如 t 检验等。我们的老师告诉我们，只要异常值不超过样本量 n 的 10%，我们就可以删除它们。这准确吗？在我看来，这太过方法论化了，我不明白为什么我们要这样处理每种情况。一般方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658405/can-you-remove-outliers-if-they-are-less-than-10-of-the-datapoints</guid>
      <pubDate>Sat, 07 Dec 2024 10:22:05 GMT</pubDate>
    </item>
    <item>
      <title>考虑 HGAM 中的非独立性和自相关性</title>
      <link>https://stats.stackexchange.com/questions/658383/accounting-for-non-independence-and-autocorrelation-in-hgam</link>
      <description><![CDATA[我目前正在尝试拟合 HGAM，以模拟两种处理中鱼类日常活动模式的差异。数据是通过高分辨率遥测技术收集的，目前我已估算出三个湖泊（湖泊 A-C）中 30 条鱼（每种处理约 15 条）在约 35 个实验日内每小时（1-24）游动的总距离（米）。这些数据具有清晰的层次结构，我正尝试用随机效应来解释它（如果我的语法有误，请告诉我，因为我习惯于在 brms /lme4 中建模）。我正在为每个湖泊创建一个单独的模型，以降低模型复杂性。模型结构如下：
mod &lt;- gam(as.numeric(total_distance) ~ 
Treatment + exp_day_z + weight_z +
s(hour, by = Treatment, k = 22, bs = &quot;cc&quot;) + # 这是我感兴趣的交互
s(individual_ID, bs = &#39;re&#39;) + # 个体级随机截距
s(individual_ID, exp_day_z, bs = &#39;re&#39;) + # 实验日的个体级随机斜率（居中）
s(individual_ID, hour, bs = &#39;re&#39;), # 一小时的个体级随机斜率
data = filter(perch, lake == &#39;A&#39;),
method = &quot;REML&quot;,
knots=list(hour=c(0.5, 24.5)),
family = Gamma(link = &#39;log&#39;))

然而，残差中似乎仍然存在相当大的自相关性。

在阅读了 Eric Pedersen 的 HGAM 论文、观看了他的和Gavin Simpson的精彩教程，并阅读了一些较早的帖子，我决定在模型中尝试一个自回归项来解释这一点，如下所示：
perch &lt;- perch %&gt;%
allocate(individual_ID, exp_day, hour) %&gt;%
mutate(start = if_else(is.na(lag(individual_ID)) | individual_ID != lag(individual_ID), TRUE, FALSE))

mod2 &lt;- bam(as.numeric(total_distance) ~ 
Treatment + exp_day_z + weight_z +
s(hour, by = Treatment, k = 22, bs = &quot;cc&quot;) + 
s(individual_ID, bs = &#39;re&#39;) +
s(individual_ID, exp_day_z, bs = &#39;re&#39;) +
s(individual_ID, hour, bs = &#39;re&#39;),
data = filter(perch, lake == &#39;A&#39;),
method = &quot;fREML&quot;,
rho = 0.6,
AR.start = start,
discrete = TRUE,
knots=list(hour=c(0.5, 24.5)),
family = Gamma(link = &#39;log&#39;))

这似乎改善了残差自相关（注意：此 acf 图是使用 check_resid(mod2) 生成的，其中灰色条表示标准残差，黑色条表示标准化 AR1 校正残差）。

与我之前的模型相比，该模型似乎也产生了合理的预测，其 CI 略宽（注意：对比度是使用 marginaleffects 包中的 comparisons 函数估计的）。

我仍然对一些事情有点不确定：

我是否应该在同一个模型中包含随机效应和自回归项？
我的随机效应结构格式是否正确，其中小时和实验日是个体级随机斜率？
使用 bam() 函数时选择特定 rho 值的理由是什么？
最后，有点不相关，有没有办法从一个整体模型中获得湖泊和处理特定的平滑度，而不是分别对三个湖泊进行建模（我最初尝试使用 by =互动（治疗，湖泊）但这需要很长时间才能运行，但也许这是唯一的方法）？

如能提供任何帮助，我们将不胜感激！
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658383/accounting-for-non-independence-and-autocorrelation-in-hgam</guid>
      <pubDate>Fri, 06 Dec 2024 16:25:03 GMT</pubDate>
    </item>
    <item>
      <title>具有局部二次估计的函数导数的交叉验证带宽</title>
      <link>https://stats.stackexchange.com/questions/658285/cross-validated-bandwidth-for-the-derivative-of-the-function-with-local-quadrati</link>
      <description><![CDATA[我正在尝试非参数化地估计函数 g(x) 的一阶导数。我正在使用局部多项式（二次）程序估计 $g(x)$。我知道如何计算 $g(x)$ 的留一交叉验证带宽，但是，我想要做的是直接估计 $g’(x)$ 的交叉验证带宽。我的猜测是，导数的最佳带宽不一定与 $g(x)$ 的最佳带宽相同，因此 $g(x)$ 的交叉验证实际上不是我应该做的。但是，我还没有找到任何关于如何对 $g’(x)$ 进行交叉验证带宽的资料，这要困难得多，因为我没有与 $Y_i$ 等效的导数。
有关于如何做到这一点的资源吗？任何 R、Python 或 Stata 中的实现也将不胜感激！
到目前为止，我正在实施 Fan 和 Gijbels (1995) RSC 标准，但感觉它不如适当的交叉验证那么充分（特别是因为从原始带宽到导数带宽的路径仅由预定的调整常数驱动）。也许我可以在交叉验证中使用相同的调整常数？但这感觉“太简单了”。
当我对函数（而不是导数）使用交叉验证或 RSC 或经验法则（来自 Fan 和 Gijbels，1996）时，我得到的带宽通常“太小”，因为导数太不稳定。我尝试了模拟数据，结果总是比建议的带宽大得多。但我想用“科学”标准来证明我的选择，而不是挥手......
PS：我也尝试了 R 中的 locfit 包，默认情况下它实现了自适应带宽（使用最近邻算法，我猜是取 70% 的最近邻居并据此确定自适应带宽，但我不太确定）。如果我也能找到“最佳”的最近邻居数量，我会没问题的。]]></description>
      <guid>https://stats.stackexchange.com/questions/658285/cross-validated-bandwidth-for-the-derivative-of-the-function-with-local-quadrati</guid>
      <pubDate>Wed, 04 Dec 2024 22:47:00 GMT</pubDate>
    </item>
    </channel>
</rss>