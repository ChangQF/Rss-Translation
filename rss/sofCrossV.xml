<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 27 Mar 2024 06:17:55 GMT</lastBuildDate>
    <item>
      <title>当预测变量增加时预测二元结果</title>
      <link>https://stats.stackexchange.com/questions/643620/predicting-binary-outcome-when-predictor-variable-increases</link>
      <description><![CDATA[假设我有一个包含大量观测值的简单数据集，每个观测值都有一个连续数值变量 $x$ 和一个二进制数值变量 $y$（值为 0 表示不满意，1 表示满意）。
当平均值 $x 时，如何预测我的观察中有多少会满足 $y=1$我的数据集中的 $ 增加了，比如 50%？
我正在考虑从逻辑回归模型开始，但我不确定如何继续。
任何指导将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/643620/predicting-binary-outcome-when-predictor-variable-increases</guid>
      <pubDate>Wed, 27 Mar 2024 00:36:18 GMT</pubDate>
    </item>
    <item>
      <title>对比两种不同方法的可信区间</title>
      <link>https://stats.stackexchange.com/questions/643619/contrasting-credible-intervals-with-two-different-approaches</link>
      <description><![CDATA[我有一个数据集，我以两种方式使用 bmrs 进行建模：1) 多年来的趋势和 2) 几十年之间的比较。我通过两种不同的方式从这两个模型中获得了可信区间，两种方法之间的 CI 范围存在相当大的差异。我怎么知道哪个是正确的？
图书馆(tidyverse)
图书馆（tidybayes）
图书馆（brms）

设置.种子(42)
df &lt;- data.frame(x = rep(seq(1970, 1999, 1),each = 20),
                 a = 样本(字母[1:3], 200, 替换 = TRUE)) %&gt;%
  变异(y = (x/100)^2 + rnorm(600, 1, 2),
         yc = 比例（y，中心 = TRUE，比例 = TRUE），
         d = as.factor(paste(str_sub(x, -2, -2), &quot;0s&quot;, sep = &quot;&quot;)))

m1 &lt;- brm(yc ~ x, data = df) # 模型 1 具有跨年趋势
m2 &lt;- brm(yc ~ d, data = df) # 模型 2 比较数十年的值

不同(df, a, x) %&gt;%
  add_predicted_draws(m1) %&gt;%
  median_qi() %&gt;% # 计算中位数和 95% CI
  重命名（估计 = .预测，loCI = .lower，hiCI = .upper） %&gt;%
  ggplot() +
  geom_boxplot(data = df, aes(x = x, y = yc, group = x)) + # 原始数据
  geom_ribbon(aes(x = x, ymin = loCI, ymax = hiCI), col = “grey80”, alpha = 0.2) + # 95% CI
  geom_line(aes(x = x, y = 估计)) + # 中值估计
  facet_wrap(~a)

terior_summary(m2) %&gt;% data.frame() %&gt;% # 获取值
  rownames_to_column(var = &quot;pred&quot;) %&gt;% 过滤器(grepl(&quot;b_&quot;, pred)) %&gt;%
  mutate(ycF = if_else(grepl(“b_I”, pred), Estimate, Estimate + min(Estimate)), # 十年调整
         loCI = if_else(grepl(“b_I”, pred), Q2.5, Q2.5 + min(估计)),
         hiCI = if_else(grepl(“b_I”, pred), Q97.5, Q97.5 + min(估计))) %&gt;%
  切片(rep(row_number(), 3)) %&gt;%
  变异(d =rep(c(“70s”,“80s”,“90s”), 3),
         a = 代表(字母[1:3], 每个 = 3)) %&gt;%
  ggplot() +
  geom_boxplot(data = df, aes(x = d, y = yc, col = d)) + # 原始数据
  geom_linerange(aes(x = d, ymin = loCI, ymax = hiCI), 线宽 = 0.6) + # 95% CI
  geom_point(aes(x = d, y = ycF), shape = 1, size = 2) + # 中值估计
  facet_wrap(~a)

情节#1

情节#2
]]></description>
      <guid>https://stats.stackexchange.com/questions/643619/contrasting-credible-intervals-with-two-different-approaches</guid>
      <pubDate>Wed, 27 Mar 2024 00:20:12 GMT</pubDate>
    </item>
    <item>
      <title>反事实招聘决定的影响</title>
      <link>https://stats.stackexchange.com/questions/643618/impact-of-counterfactual-hiring-decisions</link>
      <description><![CDATA[作为我的小部件公司的招聘经理，为了决定是否让申请人参加面试，我进行了智商测试。如果申请人的测试分数高于 110 分，我会让他们参加招聘经理的面试，否则他们会立即被拒绝。
我的公司多年来一直这样做，因此有大量关于有多少候选人在后续面试中通过和失败的数据。
现在，我想增加成功申请者的数量，所以我想知道如果我也让所有智商测试达到 110 或声称拥有学士学位的申请者通过会发生什么在他们的应用程序中。对于这个问题，假设我有以前申请者的记录，并且我知道他们是否声称自己拥有学士学位（尽管当时这不是他们录取面试的标准）。
在反事实场景下，我可以采用什么方法来预测申请者的成功率，其中使用智商&gt;110或学士学位（而不是仅使用智商测试，我有实际数据）。这种方法的局限性/假设是什么？
答案应该考虑到智商测试结果和学士学位的存在作为因变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/643618/impact-of-counterfactual-hiring-decisions</guid>
      <pubDate>Wed, 27 Mar 2024 00:12:37 GMT</pubDate>
    </item>
    <item>
      <title>计算 R 中的 Marten 协方差返回非正定矩阵</title>
      <link>https://stats.stackexchange.com/questions/643617/calculating-marten-covariance-in-r-returns-matrices-that-are-not-positive-defini</link>
      <description><![CDATA[在 R 中，我试图计算 Marten 协方差矩阵，其输入是随机创建的距离矩阵。然而，我经常最终得到的协方差矩阵不是正定的，这没有什么意义。
起初，我在 StackOverflow 上问过这个问题的一个版本，但那里的一些评论让我确信代码没有错误。此外，我被告知虽然 Marten 协方差矩阵在理论上显然总是正定的，但实际上可能并非如此。
那时，我意识到这成为一个更适合 CrossValidated 的问题。所以，我想要理解的是如何确保在实践中生成正定的Marten协方差矩阵。
也许 Marten 方程参数之间存在特定关系来确保这一点？也许还有其他技巧 - 例如，有关确保正定性的更一般性问题实践通常通过简单地向距离矩阵的零对角线添加一个微小的常数来回答 - 这并不能解决我的问题。
作为参考，以下是我生成随机距离矩阵的方法：
nrows &lt;- 100
ncols &lt;- 100
d &lt;- 矩阵(runif(nrows*ncols, 0, 1), ncols, nrows)
# 强制对称：
d[下.tri(d)] &lt;- t(d)[下.tri(d)]
diag(d) &lt;- 0.000000000001 # 而不是零以避免数值问题
# 检查我们是否有正确的距离矩阵：
范围(d)

然后我遵循维基百科的 Marten 协方差公式：

# 计算Marten协方差矩阵：
西格玛 &lt;- 1
v &lt;- 3
p &lt;- 5
项 1 &lt;- (2**(1-v))/(gamma(v))
项 2 &lt;- (sqrt(2*v)*(abs(d)/p))**v
term3 &lt;- besselK(sqrt(2*v)*(abs(d)/p), nu = v)
m &lt;- (sigma**2)*term1*term2*term3

但是，当我检查 Marten 协方差矩阵的特征值时，我发现它不是一个正定矩阵，它应该是：
g &lt;- eigen(m, only.values=TRUE)
print(min(g$values)) # 应该大于零，但实际上是大约。 -0.15
print(sum(g$values&lt;0)/length(g$values)) # 因此，这应该为零，但实际上是大约。 0.46

令我惊讶的是，得出非正定 Marten 协方差矩阵是如此容易，然后我对如何确保正定性感到困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/643617/calculating-marten-covariance-in-r-returns-matrices-that-are-not-positive-defini</guid>
      <pubDate>Tue, 26 Mar 2024 23:00:18 GMT</pubDate>
    </item>
    <item>
      <title>我的模型是否过度拟合或者我的训练过程是否错误？</title>
      <link>https://stats.stackexchange.com/questions/643612/is-my-model-overfitting-or-is-my-training-process-wrong</link>
      <description><![CDATA[我正在使用 CatBoost 分类器预测多类概率。
我有一个平衡的数据集，大约有 4000 行、13 个特征、4 个目标类标签。数据集有一些异常值，我决定不删除它们。
我在分割数据时使用 random_state=42 ，并在超参数调整和使用最佳找到的超参数进行模型评估期间将其用作 CatBoost 参数。
我的模型训练和评估步骤：

将数据按 0.7:0.15:0.15 的比例分层划分为训练集、验证集和测试集。
使用 Optuna 执行超参数调整，使用 LogLoss 作为评估指标（在训练集上进行训练，在 val 集上进行评估），并使用 (X_val, y_val) 作为模型的 eval_set 来执行早期停止轮次 在超参数调整期间。
使用训练集上找到的最佳超参数来拟合模型 (model.fit(X_train, y_train))
预测 X_train 和 X_test 的概率：model.predict_proba(X_train) 和 model.predict_proba(X_test)
比较训练集和测试集的指标，结果如下：


&lt;标题&gt;


对数丢失
AUC-ROC
Brier 分数
ECE


&lt;正文&gt;

火车
0.30
0.99
0.07
0.05


测试
0.55
0.94
0.08
0.02



这些结果是否表明我的模型过度拟合，或者我的训练和评估步骤有问题？
LogLoss 的差异似乎很严重（我认为这是过度拟合的迹象），AUC-ROC 和 Brier Score 似乎大部分都很好（我认为？），而 ECE 在测试集上变得更好，我觉得很奇怪在过度拟合的情况下。此外，验证集上最好的 Optuna 试验 LogLoss 与我在超参数调整后在测试集上评估模型时得到的结果几乎相似。]]></description>
      <guid>https://stats.stackexchange.com/questions/643612/is-my-model-overfitting-or-is-my-training-process-wrong</guid>
      <pubDate>Tue, 26 Mar 2024 22:30:05 GMT</pubDate>
    </item>
    <item>
      <title>如何使用学习模型绝对误差的箱线图来比较\评估学习模型的性能？</title>
      <link>https://stats.stackexchange.com/questions/643610/how-boxplot-over-absolute-error-of-learning-models-could-be-used-to-compare-eval</link>
      <description><![CDATA[最近翻了这篇代表评测的论文通过 Boxplot 在 $Absolute~Error~(AE)$ 上显示单个数据集中各种模型的性能，如下所示：

&lt;标题&gt;




&lt;正文&gt;

图。图 12：我们的方法和 M1 先前研究的基线方法的箱线图。 参考



通常我们使用 $Mean~Absolute~Error~(MAE)$ 或 $Mean~Square~Error~( MSE)$等进行不同模型比较。
我已经检查了这篇文章：用示例解释箱线图但仍然有一些注意事项像：

集中趋势 中央趋势趋势 &amp; 中位数：定义和用途
变异性 变异性测量&lt; /a&gt;
偏度：偏态分布

我的问题：

如何解释这一表述？ （知道误差越低，模型就越好）
这是否意味着不使用 $mean$ 或 $average$ 进行误差计算，例如$Mean~Absolute~Error~(MAE)$ 通过条形图，可以在学习过程中收集所有误差估计并绘制箱线图？那么哪些额外信息可以翻译 MAE 上的经典条形图无法翻译的内容？

我不明白它背后的好处和逻辑是什么。
&lt;小时/&gt;
可能相关的帖子：

绝对误差作为评估模型的工具
根据平均绝对误差箱线图删除异常值以改进回归模型是否作弊&lt; /里&gt;
可以使用误差估计箱线图得出模型方差吗？
数据集上模型性能的“绝对”基准
平均绝对误差与总绝对误差
最低“推荐”值箱线图的样本大小？不同样本量的箱线图
我们应该如何用小样本绘制箱线图？
]]></description>
      <guid>https://stats.stackexchange.com/questions/643610/how-boxplot-over-absolute-error-of-learning-models-could-be-used-to-compare-eval</guid>
      <pubDate>Tue, 26 Mar 2024 21:49:55 GMT</pubDate>
    </item>
    <item>
      <title>与中值的相关性</title>
      <link>https://stats.stackexchange.com/questions/643604/correlation-with-median-values</link>
      <description><![CDATA[只是一个简单的问题，因为我在任何地方都找不到答案。
我想将多个性状的值与 RNA-seq 数据相关联。由于这些特征是在不同个体上测量的（与获得 RNA-seq 数据的个体不同），我被建议使用平均值。我想知道是否可以使用中位数代替。问题是，有时我有异常值，并且使用中位数不需要删除每个特征基础上的异常值。]]></description>
      <guid>https://stats.stackexchange.com/questions/643604/correlation-with-median-values</guid>
      <pubDate>Tue, 26 Mar 2024 20:13:35 GMT</pubDate>
    </item>
    <item>
      <title>非欧几里德空间上 k 中心点的间隙统计量的等效项</title>
      <link>https://stats.stackexchange.com/questions/643599/equivalent-of-gap-statistic-for-k-medoids-on-non-euclidean-spaces</link>
      <description><![CDATA[我有一个带有加权边的连通图。我想使用聚类算法将图划分为社区。我选择了 K-medoids，并在距离矩阵上运行它，其中距离 = 1 / (1 + 边权重)。
如果特征空间是欧几里得空间，我可以模拟特征上的均匀分布并计算“间隙统计量”作为真实数据上 k-medoids 的损失与模拟数据上 k-medoids 的损失之间的差异。但这个空间不是欧几里得空间，我认为我无法模拟均匀分布并计算间隙统计量。
如何选择最佳的簇数？]]></description>
      <guid>https://stats.stackexchange.com/questions/643599/equivalent-of-gap-statistic-for-k-medoids-on-non-euclidean-spaces</guid>
      <pubDate>Tue, 26 Mar 2024 19:41:15 GMT</pubDate>
    </item>
    <item>
      <title>不同回归模型中相同 X 的 p 值的 FDR</title>
      <link>https://stats.stackexchange.com/questions/643595/fdr-for-p-values-of-the-same-x-accross-different-regression-models</link>
      <description><![CDATA[我有 3 个 X 变量和 44 个 Y：

年龄（连续）(X)
性别（二进制）(X)
microRNA（连续）(X)（感兴趣的变量）
大脑区域（连续）(Y)

我们的问题是，在控制年龄和性别的影响的情况下，microRNA 是否可以预测大脑区域。我对每个 Y 执行了一系列回归模型来解决我们的问题。
我的主管说，因为我们的 Y 变量并不完全独立，所以我们必须纠正 beta 系数的 p 值。
我想执行 FDR 程序，但我有点困惑：
1- 我应该对所有 p 值（年龄、性别和 microRNA）执行 FDR 程序，还是应该对每个 X 变量分别执行？ （请注意，年龄和性别对我们来说都不重要，将其输入模型只是为了控制其影响。）
2- 纠正来自不同回归模型的一组 p 值是否有意义？我分别修正了每个模型的贝塔系数，但我的主管不同意。
Edit1：请注意，我们的研究问题需要对每个 Y 变量进行单独分析，不能将其作为解决方案进行更改。
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/643595/fdr-for-p-values-of-the-same-x-accross-different-regression-models</guid>
      <pubDate>Tue, 26 Mar 2024 19:15:26 GMT</pubDate>
    </item>
    <item>
      <title>更好的功能来适应类似日志的数据？</title>
      <link>https://stats.stackexchange.com/questions/643589/better-function-to-fit-log-like-data</link>
      <description><![CDATA[我正在尝试将双参数函数拟合为如下所示的数据（黑点，x 刻度为对数）：

我能找到的最合适的是 $arctan$，由 MSE 测量。我测试的所有七个函数和Python代码如下所示。
是否有更好的函数来适应我可能忽略的这些数据？
&lt;小时/&gt;
&lt;前&gt;&lt;代码&gt;
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt


def main():
    x = np.array([0.033, 0.062, 0.104, 0.210, 0.424, 0.861, 1.040, 1.133, 1.935, 3.803, 6.289, 11.519, 29.118])
    y = np.array([
        0.077、0.149、0.187、0.229、0.299、0.419、0.469、0.499、0.679、0.806、
        0.888, 0.928, 0.956])

    N = 100
    对于 i，func in enumerate((f1, f2, f3, f4, f5, f6, f7))：
        beta_opt、alpha_opt、delta_old = np.nan、np.nan、np.inf
        对于 np.linspace(0., 2, N) 中的 alpha：
            对于 np.linspace(0., 5, N) 中的 beta：
                y_fit = func(x, 阿尔法, 贝塔)
                delta = np.square(y - y_fit).sum()
                如果 delta &lt;增量_旧：
                    beta_opt, alpha_opt = 贝塔, 阿尔法
                    delta_old = 增量
        x0 = np.linspace(0.01, 30, 100)
        y0 = func(x0, alpha_opt, beta_opt)
        plt. 绘图（
            x0, y0, ls=&#39;:&#39;, lw=2,
            label=“f{}, alpha={:.3f}, beta={:.3f}, MSE={:.3f}”.format(i+1, alpha_opt, beta_opt, delta_old))

    plt.scatter(x, y, c=&#39;k&#39;)
    plt.xscale(&#39;日志&#39;)
    plt.图例()
    plt.show()

def f1(x, 阿尔法, 贝塔):
    返回 alpha + beta*np.log(x)

def f2(x, 阿尔法, 贝塔):
    返回 alpha*np.tanh(x*beta)

def f3(x, 阿尔法, 贝塔):
    返回 alpha + beta*np.tanh(x)

def f4(x, 阿尔法, 贝塔):
    返回 1/(alpha+beta*np.exp(-x))

def f5(x, 阿尔法, 贝塔):
    返回 alpha + 1/(1+beta*np.exp(-x))

def f6(x, 阿尔法, 贝塔):
    返回 alpha - np.exp(-beta*x)

def f7(x, 阿尔法, 贝塔):
    返回 alpha + beta*np.arctan(x)


如果 __name__ == &#39;__main__&#39;:
    主要的（）
]]></description>
      <guid>https://stats.stackexchange.com/questions/643589/better-function-to-fit-log-like-data</guid>
      <pubDate>Tue, 26 Mar 2024 18:57:16 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 的 ar() 和 lm() 之间的系数差异？</title>
      <link>https://stats.stackexchange.com/questions/643573/difference-in-coefficients-between-ar-and-lm-using-r</link>
      <description><![CDATA[当我使用 ar(method=&quot;ols&quot;) 时，它应该返回与 lm() 相同的结果，对吗？它没有：
&lt;前&gt;&lt;代码&gt;# AR
设置.种子(12345)
n &lt;- 100
y &lt;- as.numeric(arima.sim(列表(ar = 0.6), n = n))
model_ar &lt;- ar(y, method = &quot;ols&quot;, order.max = 1, demean = TRUE, aic = FALSE)
model_lm &lt;- lm(y[2:n] ~ y[1:(n - 1)])

c(model_ar$x.intercept, model_ar$ar) # 查看 coefs ar
model_lm$coefficients # 查看系数 lm()

结果：斜率相同，截距不同。为什么？如何手动复制 ar() 结果？
&lt;前&gt;&lt;代码&gt;# 结果：
# r$&gt; c(model_ar$x.intercept, model_ar$ar) # 查看 coefs ar
# [1] -0.009013242 0.532853591

# r$&gt; model_lm$系数 # 查看系数 lm()
#（截取）y[1:(n - 1)]
# 0.2478445 0.5328536

（类似问题此处和这里但它们不一样.他们询问的是 arima() 而不是 ar()，或者问题是关于 coef 的重要性，而不是估计。）]]></description>
      <guid>https://stats.stackexchange.com/questions/643573/difference-in-coefficients-between-ar-and-lm-using-r</guid>
      <pubDate>Tue, 26 Mar 2024 15:17:24 GMT</pubDate>
    </item>
    <item>
      <title>在重复测量实验中使用两个中介进行 R 中介分析（受试者内设计）</title>
      <link>https://stats.stackexchange.com/questions/643570/mediation-analysis-in-r-with-two-mediators-in-a-repeated-measure-experiment-wit</link>
      <description><![CDATA[我目前面临挑战，非常感谢您的帮助。我正在尝试使用 R 在受试者内设计实验中对两个中介进行中介分析。以下是我的情况的简要概述：
研究问题：我正在研究自变量（可以取绿色、黄色或红色值）和单个因变量之间的关系。
中介分析：我的分析涉及两个中介，我想了解这些中介如何影响自变量和因变量之间的关系。
之前的尝试：最初，我尝试使用 R 中的 PROCESS 函数进行中介分析。然而，我遇到了困难，因为该函数没有考虑重复测量，而这在我的研究设计中至关重要。
当前方法：经过进一步探索，我发现了中介包。虽然这个函数似乎很有希望处理重复的测量，但我不确定它是否可以容纳两个中介的分析。同样，我不确定 lameer 函数在这种情况下的功能。
如果您能指导如何进行此分析，我将不胜感激。任何关于合适的 R 包或用两个中介进行中介分析的方法的见解或建议，特别是在重复测量的研究中，都将非常有价值。
非常感谢您考虑我的请求。非常感谢您的专业知识和帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/643570/mediation-analysis-in-r-with-two-mediators-in-a-repeated-measure-experiment-wit</guid>
      <pubDate>Tue, 26 Mar 2024 14:32:26 GMT</pubDate>
    </item>
    <item>
      <title>是否可以计算多元线性回归中特定 beta 系数的功效？</title>
      <link>https://stats.stackexchange.com/questions/643560/is-it-possible-to-calculate-the-power-for-a-specific-beta-coefficient-in-a-multi</link>
      <description><![CDATA[我想进行多元线性回归，其中我只对解释一个 beta 系数感兴趣，但我将调整两个额外的协变量（即总共三个变量）。是否可以计算出我给定样本大小 $n = 150$ 来检测（比方说）$0.3$ ？如果是这样，我需要哪些额外信息？是否有 R 包或代码可以为我运行计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/643560/is-it-possible-to-calculate-the-power-for-a-specific-beta-coefficient-in-a-multi</guid>
      <pubDate>Tue, 26 Mar 2024 12:40:47 GMT</pubDate>
    </item>
    <item>
      <title>指定面板数据作为调查对象</title>
      <link>https://stats.stackexchange.com/questions/643461/specifying-panel-data-as-survey-object</link>
      <description><![CDATA[我有一个在不同波次（总共 30 波）中收集的家庭特征（收入、支出、资产所有权等）的面板数据集。调查数据经过分层，提供了初级抽样单位和分层后权重。
调查包的文档没有提及指定面板数据的方法。从其他示例中，我认为使用交互函数来指定不同的波将是一种可能的方法。
survey_obj_1 &lt;- svydesign(id=~PSU_ID,weights=~weight,
                          地层=~交互（地层，Wave_No），
                          嵌套=真，数据=数据帧）

指定为各个波分配权重，而不是使用
survey_obj_2 &lt;- svydesign（id=~PSU_ID，权重=~权重，strata=~Stratum，
                          嵌套=真，数据=数据帧）

它没有指定数据的面板/时间性质。
这是正确的吗？欢迎任何有关使用面板数据调查对象的建议或示例。
survey_obj_1 和 survey_obj_2 均已成功创建对象。两个对象的平均参数（如平均收入）的估计也相同，但考虑数据时间性质的 survey_obj_1 中的标准误差远低于 survey_obj_2 ]]></description>
      <guid>https://stats.stackexchange.com/questions/643461/specifying-panel-data-as-survey-object</guid>
      <pubDate>Mon, 25 Mar 2024 04:22:13 GMT</pubDate>
    </item>
    <item>
      <title>估计选择加入的用户的营销贡献</title>
      <link>https://stats.stackexchange.com/questions/643289/estimating-marketing-contribution-from-opted-in-users</link>
      <description><![CDATA[我正在尝试估计营销对我们产品的使用有多大贡献，但由于同意要求，我只能收集一部分用户的数据 - 那些同意我们收集和分析他们的数据的用户营销目的。
我的问题涉及我需要多少用户同意才能对营销贡献做出任何可靠的推断，其中营销贡献定义为点击后首次使用我们产品的用户百分比在营销 URL 上。我一直将其视为一个抽样问题 - 给定 99% 的置信区间和 1% 的置信区间，我需要多大的样本才能获得 3000 万用户的用户群（人口）的营销贡献的统计显着性指标误差范围？ （暂时先不考虑让用户选择加入可能会引入抽样偏差的事实。）
在我们付出所有努力获得上述同意之前，我只需要一个粗略的近似值来直观地检查它是否看起来是一个可以达到的数字，所以我尝试将一些数字插入一些在线工具，但我得到的数字由于样本量太小，我不相信结果。 3000 万用户中约有 17000 名？我一定在构建这个框架的某个地方犯了错误。
样本大小是思考这个问题的错误方式吗？我应该如何考虑我需要多少选择率才能使我收集的数据足以满足分析目的？]]></description>
      <guid>https://stats.stackexchange.com/questions/643289/estimating-marketing-contribution-from-opted-in-users</guid>
      <pubDate>Fri, 22 Mar 2024 20:15:22 GMT</pubDate>
    </item>
    </channel>
</rss>