<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 07 Jun 2024 21:15:42 GMT</lastBuildDate>
    <item>
      <title>对于缺少很多天的时间序列，最好的输入选择是什么</title>
      <link>https://stats.stackexchange.com/questions/648849/what-are-the-best-options-for-imputing-time-series-that-is-missing-lots-of-days</link>
      <description><![CDATA[我有好几个月的温度数据，大约每十分钟记录一次。除非它有间隙。如果间隙为一小时左右，我可以线性插值，但如果间隙为几天，这显然行不通。
我目前所做的是取每日平均值，然后进行样条拟合以获得每天的平均值。我还从每天中减去平均值，以计算数据随时间变化的滚动平均值，按小时计算。然后，我可以用每小时滚动偏移量来填充缺失的天数，该偏移量由插值样条拟合所表示的平均值应为的值决定。
这有点用，但你可以看到我拼接的地方。例如，连接处的梯度不连续。我想我可以通过每天对总变化进行每日估计，然后将其插入间隙来改进，但是......
这肯定应该是机器学习的一个很棒的应用？我正在摆弄一些 scikit-learn 包，但它们似乎都希望在学习之前删除 NaN。
如能提供任何指点，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/648849/what-are-the-best-options-for-imputing-time-series-that-is-missing-lots-of-days</guid>
      <pubDate>Fri, 07 Jun 2024 20:38:31 GMT</pubDate>
    </item>
    <item>
      <title>SVRG 与完全梯度下降</title>
      <link>https://stats.stackexchange.com/questions/648848/svrg-vs-full-gradient-descent</link>
      <description><![CDATA[随机梯度下降法让我们能够避免计算全梯度，但代价是引入收敛噪声底限。为了降低此噪声底限，SGD 需要减小步长，这会导致在强凸情况下失去线性收敛。 SVRG（随机方差降低梯度）允许我们返回这种线性收敛，但我看不出这在计算上比简单的全梯度下降有什么好处。
SVRG 在外循环的每次迭代中对完整梯度进行采样，然后执行形式为 $w_t = w_{t-1} - \eta \left(\nabla f_{i_t}(w_{t-1})-\nabla f_{i_t}(\hat{w}) + \nabla f(\hat{w})\right)$ 的内循环步骤，其中 $\hat{w}$ 是当前外循环值。我们的想法是利用梯度之间的正相关性来减少估计量中的方差。在强凸情况下，论文中的分析会选择这些内循环子步骤中的一个随机步骤作为我们的下一个外循环步骤。然后他们继续将其呈现为返回 GD 的线性收敛，但收敛程度取决于我们运行的外循环步骤数。这些外循环步骤中的每一个都在计算一个完整的梯度，那么这是否不是在进行完整的梯度下降加上这些内循环步骤的一些额外工作 - 所有这些都是为了实现与 GD 相同的收敛？]]></description>
      <guid>https://stats.stackexchange.com/questions/648848/svrg-vs-full-gradient-descent</guid>
      <pubDate>Fri, 07 Jun 2024 20:06:54 GMT</pubDate>
    </item>
    <item>
      <title>比较两个随着时间的推移而不平等的群体？</title>
      <link>https://stats.stackexchange.com/questions/648846/comparing-two-unequal-groups-over-time</link>
      <description><![CDATA[我对 rstudio 和统计学还不熟悉，所以请耐心等待。我试图比较两个不同变量随时间的变化，但它们来自非常不同的样本量。
我正在研究现场样本测量值和实验室样本测量值之间的差异。它们以不同的单位测量，但应该是相关的，因为它们本质上测量的是同一件事。
我有一个数据集“Probe”，其中测量了感兴趣的变量“value”。
这应该与我的其他数据集“Field”中的“value”变量相关。
哪种统计测试可以给我我想要的分析？我想看看“Field”值的峰值是否与“Probe”值的峰值相关，依此类推。我试图随着时间的推移跟踪它们是否显示出相似的趋势。我想做一些类似相关性的事情，但不能，因为“Probe”数据由 1606 个观测值组成，而“现场”数据由 197 个观测值组成，因此它们的长度不同，并且无法关联（据我迄今为止的研究所知）。]]></description>
      <guid>https://stats.stackexchange.com/questions/648846/comparing-two-unequal-groups-over-time</guid>
      <pubDate>Fri, 07 Jun 2024 19:59:43 GMT</pubDate>
    </item>
    <item>
      <title>寻找在线性回归中非线性组合特征的最佳方法</title>
      <link>https://stats.stackexchange.com/questions/648845/finding-the-best-way-for-combining-features-non-linearly-within-a-linear-regress</link>
      <description><![CDATA[问题陈述
我有一组两个特征，$X_1$ 和 $X_2$，我将它们组合起来尝试预测以下形式的回归中的目标变量：$ Y_0 = \frac{X_1 - X_2}{X_1 + X_2} $。您可以将其视为两者之间的插值，将差异标准化为所有数据点的$[-1, 1]$之间的差异。
$X_1, X_2$受到其他一些特征的非线性影响：$Z_1, Z_2$。
我正在尝试找到一种方法来改进原始回归$Y_0$，使用某个函数$f$，以便$Y_1 = \frac{f(X_1, Z_1) - f(X_2, Z_2)}{f(X_1, Z_1) + f(X_2, Z_2)} $改进$Y_0$。
我很清楚要从哪个类的函数开始。但我意识到，理想情况下，我希望针对我的具体问题调整我使用的任何函数。因此，如果我使用指数函数：$f(X_i, Z_i) = X_i * e^{Z_i} $，我希望找到最佳参数 lambda，其中 $f(X_i, Z_i, \lambda) = X_i * e^{\lambda * Z_i} $ 提供最佳拟合。 （$\lambda$ 是所有数据点的固定值）

具体示例
我认为用一个例子来说明会更容易。假设我们正试图通过进行许多平衡实验来预测跷跷板的倾斜角度。$Y=1$ 表示 $X_1$ 重（无限），跷跷板在那一侧接触地板。类似地，$Y=-1$ 表示 $X_2$ 重无限，跷跷板在相应的一侧接触地板。在理想情况下，这个目标变量恰好由两者的相对质量决定。这是之前的初始简单回归，$Y_0$。
但现在我们有一个未知的力作用在每个物体上：$Z_1$ 和 $Z_2$。我们有一个作用在每一侧的力的值，但我们不知道它如何准确地影响不平衡。把它想象成外星引力。下面是我所说的这一切的粗略图表，希望它能有所帮助。 
但现在我们有了这种奇怪的力量，我们想找到一种完美的建模方法。
实际数据不同，因此请在此示例中允许一些创造性想象力 :)

我的进度：
我尝试回归 $Y = \beta_1 X_1 + \beta_2 X_2 + \alpha$，按 $Z_1$ 和 $Z_2$ 的每个十分位数细分，然后绘制系数与十分位数的关系。我发现，随着 $Z_1$ 的增加，$X_1$ 的系数以指数方式增加，$X_2$ 和 $Z_2$ 的系数也以相同的方式（但为负）增加。因此，这表明我假设存在指数关系可能是正确的。

我的问题：
&quot;以指数方式&quot; 非常不切实际。我希望对这个建模过程有一个合理的方法。我需要找到最佳 lambda，并确认指数拟合是最佳选择。不太确定该怎么做。

我尝试过的方法
我尝试将指数曲线拟合到系数与十分位数图，这为 lambda 提供了一些值。但问题是，当我进行完全回归时，这种方法不起作用？只尝试一堆 lambda 值听起来也不对，感觉像是过度拟合。我这样做了，最佳 lambda 与我从另一种方法中获得的完全不同。所以我现在完全迷路了。

任何关于如何开始解决或查找此问题的指导都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/648845/finding-the-best-way-for-combining-features-non-linearly-within-a-linear-regress</guid>
      <pubDate>Fri, 07 Jun 2024 19:51:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的风险比系数在 Coxph 回归中这么大或这么小？</title>
      <link>https://stats.stackexchange.com/questions/648843/why-is-my-hazard-ratio-coefficients-so-large-or-small-in-coxph-regression</link>
      <description><![CDATA[我有一些我工作的机构中特定子群体的成绩数据，并将其与一段时间内的留校情况进行比较。下面的第一个表格是 R 中 coxph 回归的一些风险比，使用 D&amp;F GPA 学生作为比较组。这是一个通常会离开我们机构去另一所机构的子群体，所以我希望看到 A（学术货币）与离开与留下有关。
时间单位基于学分数量。

我的解释是，获得 A 的学生离开的可能性大约是平均成绩为 D 或 F 的学生的 15 倍。作为一项健全性检查，我想检查一下汇总的原始数据：

我很困惑，因为这个值比两组之间的比例要高得多。我是否应该进行更好的比较来计算“原始”数据？从汇总数据透视表值中得出风险比？
另一个示例是下面比较学生程序的输出（程序 3 是参考组）。

与原始数据相比，这里的比例似乎也不支持风险比。程序是分析中最具预测性的变量。

为了进一步参考，我附上了一份 Kaplan Maier 成绩生存图，该图似乎并未表明如此大的 coxph 系数。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648843/why-is-my-hazard-ratio-coefficients-so-large-or-small-in-coxph-regression</guid>
      <pubDate>Fri, 07 Jun 2024 19:36:29 GMT</pubDate>
    </item>
    <item>
      <title>对于采用和使用健康赤池信息准则 (hAIC) 有何见解？</title>
      <link>https://stats.stackexchange.com/questions/648841/any-insights-on-the-adoption-and-use-of-the-healthy-akaike-information-criterion</link>
      <description><![CDATA[最近，我偶然发现了 Demidenko 在其 2004 年出版的《混合模型：R 的理论与应用》一书中提出的健康赤池信息准则 (hAIC)。尽管它具有（潜在的）优势，但我在文献中发现的对它的引用却非常少。
一些背景知识：健康赤池信息准则 (hAIC) 由 Demidenko 开发，用于解决传统赤池信息准则 (AIC) 在解释变量之间存在高度多重共线性时的局限性。 AIC 的计算方法如下：
$$
AIC = −2\log(\text{max})+2k
$$
其中 $\log(\text{max})$ 是最大对数似然，$k$ 是参数数量，hAIC 通过合并惩罚项来修改此值，该惩罚项考虑了参数向量的长度，Demidenko 声称这使得 hAIC 在存在不适定问题和/或高度相关预测变量的场景中特别有用。
hAIC 公式为：
$$
HAIC = H + AIC
$$
其中
$$
H = k \left[ \log\left(\frac{\|\beta_{\text{ls}}\|^2}{k}\right) - 1 \right]
$$
这里，$\beta_{ls}$表示参数和范数的最小二乘估计，$\|\beta_{\text{ls}}\|$是参数向量的欧几里得长度：
$$
\|\beta_{\text{ls}}\| = \sqrt{\sum_{i=1}^k (\beta_{\text{ls},i})^2}
$$
这个惩罚项旨在惩罚具有较大参数估计的模型，这表明存在多重共线性。通过纳入参数向量的范数，hAIC 可确保对系数过大的模型进行惩罚，从而促进更稳定、更可靠的估计。过度的多重共线性可能导致不适定问题，即模型矩阵几乎是奇异的，从而导致参数估计值出现较大方差。额外的惩罚项有助于缓解这一问题，因为它倾向于使用参数估计值较小、更稳定的模型（到目前为止，我所读到的资料中还没有提到如何区分由于多重共线性而导致的较大参数估计值和真正较大的参数效应）。传统的 AIC 只考虑参数的数量，而不考虑它们的大小。另一方面，hAIC 整合了参数的数量和大小，旨在采用更全面的模型选择方法，考虑模型的整体稳定性和可靠性。
我发现的唯一已发表的研究是 Harezlak 等人 (2007) 的一篇题为“函数回归问题的惩罚解”的论文。在本研究中，hAIC 通过结合误差方差估计、自由度和基函数系数范数来增强模型稳定性和可解释性。
所以，我想知道这里是否有其他人使用过 hAIC，或者见过它被使用，甚至听说过它？如果有，你对它有什么想法和经验？如果没有，您对我在这里介绍的内容有什么看法？
为了增加背景信息，以下是我想到的 AIC、hAIC 和 BIC 的一些优缺点：
惩罚结构：

AIC：惩罚项为 $2k$，重点关注参数数量。
BIC：惩罚项为 $k\log(n)$，随着观察次数的增加而增加，并为其他参数提供更强的惩罚。
hAIC：惩罚项包括参数数量和参数向量的范数，还解决了参数估计的大小问题。

模型选择：

AIC：由于每个惩罚较低，通常会选择更复杂的模型参数。
BIC：由于惩罚力度较大，倾向于使用更简单的模型，尤其是样本量增加时。
hAIC：旨在平衡模型拟合度和复杂性之间的权衡，同时专门解决多重共线性和参数不稳定的问题。

应用场景：

AIC：适用于主要关注预测准确性且观测次数不是过多时的模型选择。
BIC：在认为真实模型在候选模型中且样本量较大的情况下是首选。
hAIC：在具有高多重共线性或不适定问题的场景中特别有用，在这些场景中，传统 AIC 可能无法提供稳定可靠的模型选择。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648841/any-insights-on-the-adoption-and-use-of-the-healthy-akaike-information-criterion</guid>
      <pubDate>Fri, 07 Jun 2024 18:34:18 GMT</pubDate>
    </item>
    <item>
      <title>用于实验推断的逻辑回归？</title>
      <link>https://stats.stackexchange.com/questions/648840/logistic-regression-for-experimental-inference</link>
      <description><![CDATA[我很好奇，当任务是推断治疗对比例的影响（例如：成功率）时，如果存在协变量，并且治疗组和对照组之间存在一些不平衡，那么逻辑回归是否合适。（换句话说，本质上是比例的 ANCOVA。）
我知道逻辑回归在对数几率空间中模拟线性趋势。并且这种线性关系通过 S 型函数传递，该函数将对数几率转换为概率。但是，与非线性变换相关的曲率量在 0.0 和 1.0 附近最大，在 0.5 附近最轻微。
当数据远离 50% 时，使用这种方法有什么问题吗？
为了增加假设背景，假设一个研究实验室正在尝试创建一种蛇毒治疗方法，如果不进行治疗，存活的概率为 5%。理想情况下，治疗效果会增加存活的概率。 （我没有这方面的背景，这也不是我的工作，所以我们不需要讨论蛇毒治疗的现实情况。）
是否有人担心，由于控制概率非常接近于零（因此 S 型函数对对数几率进行了大量“弯曲”），估计结果会​​不可靠？]]></description>
      <guid>https://stats.stackexchange.com/questions/648840/logistic-regression-for-experimental-inference</guid>
      <pubDate>Fri, 07 Jun 2024 17:57:52 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯法比尼·托内利</title>
      <link>https://stats.stackexchange.com/questions/648839/bayesian-fubini-tonelli</link>
      <description><![CDATA[我正在研究一个贝叶斯框架，其中我在函数$f\sim GP$上放置了一个高斯过程，并且有数据$D^n=\{(X_i,Z_i,W_i)\}^n$。
然后我得到了后验测量$\mu(f|D^n)$。后验均值估计量由 $\hat{f}=\int fd\mu(f|D^n)$ 给出。
我现在感兴趣的是找到另一个估计量的误差，我将其定义为：
\begin{align*}
\beta(x,z) &amp;=E_W[\hat{f}(x,z,W)]\\
&amp;=\int_\mathcal{W}\hat{f}(x,z,W)dP(W)\\
&amp;=\int_\mathcal{W}\int_\mathcal{F}f(x,z,W)d\mu(f|D^n)dP(W)
\end{align*&gt;
我现在想知道是否可以调用 Fubini Tonelli 来切换积分顺序 $\int_\mathcal{W}\int_\mathcal{F}f(x,z,W)d\mu(f|D^n)dP(W)=\int_\mathcal{F}\int_\mathcal{W}f(x,z,W)dP(W)d\mu(f|D^n)$.
我猜我的疑惑来自于我没有对整个数据分布$P(X,Z,W)$进行积分，并且测量$\mu$依赖于数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/648839/bayesian-fubini-tonelli</guid>
      <pubDate>Fri, 07 Jun 2024 16:33:20 GMT</pubDate>
    </item>
    <item>
      <title>什么转换可以“平滑地”调整经验数据方差？</title>
      <link>https://stats.stackexchange.com/questions/648838/what-transformation-to-adjust-empirical-data-variance-smoothly</link>
      <description><![CDATA[假设我们拥有产生该数据的过时流程的经验数据。
我们有理由相信当今的流程是相似的（例如相同的分布），但方差不同。
一般问题：在这种情况下，如何调整过时的经验数据以更好地反映当今情况？即，对数据应用哪种一般变换将允许创建提供最新方差（我们假设具有）的伪数据？
如果我们有“均值”而不是“方差”，那么翻译就可以了。
对于方差，用标量计时样本将提供以此标量的平方计时的方差，但在这种情况下，整个经验样本将按相同的量进行调整。我更多地考虑一些更“有弹性”的东西，如果接近平均值，它不会改变观察结果，但如果远离平均值，它就会改变很多（我猜是平方根的东西）。]]></description>
      <guid>https://stats.stackexchange.com/questions/648838/what-transformation-to-adjust-empirical-data-variance-smoothly</guid>
      <pubDate>Fri, 07 Jun 2024 16:19:50 GMT</pubDate>
    </item>
    <item>
      <title>与独立 ARMA 模型相比，为什么使用 VARMA 模型时某些序列的预测值会下降？</title>
      <link>https://stats.stackexchange.com/questions/648836/why-does-the-forecast-for-some-series-degrade-when-using-a-varma-model-comparing</link>
      <description><![CDATA[我正在处理多个我怀疑有关联的时间序列，并且我假设使用 VARMA 模型至少不会降低每个序列的预测，甚至会改善它们。但是，当我在 Python 中使用 statsmodels.tsa.statespace.varmax 预测两个时间序列时，与使用单变量模型相比，其中一个时间序列的预测会降低。
我已确保序列是平稳的。使用 VARMA 模型时，其中一个序列的预测性能下降的原因可能是什么？这是由于解决 VARMA 模型的计算限制，还是我可能忽略了 VARMA 模型的理论方面？]]></description>
      <guid>https://stats.stackexchange.com/questions/648836/why-does-the-forecast-for-some-series-degrade-when-using-a-varma-model-comparing</guid>
      <pubDate>Fri, 07 Jun 2024 16:10:34 GMT</pubDate>
    </item>
    <item>
      <title>李克特量表和样本量</title>
      <link>https://stats.stackexchange.com/questions/648828/likert-scale-and-sample-size</link>
      <description><![CDATA[我想研究母亲收到论文或网站信息的满意度。我至少会问 5 个问题，每个问题都使用李克特量表（5 分）。
样本量：

我是否应该使用调查的样本量公式进行计算（从 $y$ 中抽取 $x$ 名女性）？
我是否应该根据我预期的最重要的问题的李克特量表之间的差异来计算样本量？
我是否应该调整问题数量？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648828/likert-scale-and-sample-size</guid>
      <pubDate>Fri, 07 Jun 2024 14:57:59 GMT</pubDate>
    </item>
    <item>
      <title>在 Wedderburn 1974 中的矩量法中使用 $n-m$ 的动机是什么？</title>
      <link>https://stats.stackexchange.com/questions/648811/what-is-the-motivation-for-the-use-of-n-m-in-the-method-of-moments-in-wedderbu</link>
      <description><![CDATA[在回答这个问题时方差和卡方之间有关系吗？
我写道

因此，要找到分散参数，必须使用不同的技巧。在 Wedderburn 1974 中，这是通过使用 矩法 来实现的。
方差的期望大约为：
$$E\left[\sum_{i=1}^n \frac{(x_i-\mu_i)^2}{V(\mu_i)} \right] \approx \phi({n-m})$$
（该近似值基于假设 $V(\mu_i)$ 近似线性，并且分布服从 $\chi^2$ 分布）

括号中的这部分不正确。分布不服从 $\chi^2$ 分布。这是针对正态分布族而言的，但一般情况下并非如此。
但它也不必如此。对于矩量法而言，重要的是分布具有该期望值。
然而，我想知道的是：
缩放残差平方和的期望值是否等于样本大小 $n$ 减去参数 $m$？
我们如何证明这一点？如果它只是近似正确，我们如何证明近似是合理的？
我们确实知道残差位于较小的子空间中（如此处所述：为什么残差在 $\mathbb{R}^{n-p}$ 中？），但误差的分布不是球对称的，方差可能不需要均等分割。]]></description>
      <guid>https://stats.stackexchange.com/questions/648811/what-is-the-motivation-for-the-use-of-n-m-in-the-method-of-moments-in-wedderbu</guid>
      <pubDate>Fri, 07 Jun 2024 11:14:28 GMT</pubDate>
    </item>
    <item>
      <title>离散时间生存中的审查类型</title>
      <link>https://stats.stackexchange.com/questions/648701/type-of-censoring-in-discrete-time-survival</link>
      <description><![CDATA[*我有一个前瞻性纵向研究。在这项研究中，患者每三个月来医院检查一次。T0（手术前一周）、T3（手术后三个月）、T6（手术后六个月）、T9、T12、、、、、、T24（手术后 24 个月）。所以有 9 个时间点。
我们对预测性 Cox 回归感兴趣，其中包括二元时间相关协变量和连续自变量。在事件发生前退出、完成无事件随访（T24）或在研究结束时显示特定水平的时间相关协变量的病例是审查者。
*似乎在计数过程方法中，只有右审查者。并且为了使用离散时间生存，必须满足以下条件（如果我说得不对，请纠正我）

所有患者的时间间隔相同
时间点数量有限
区间审查*

1. 我不确定我的研究中的审查类型。如果研究中同时有右审查和区间审查，我们可以使用离散时间生存方法吗？
2. 如果研究允许患者在错过一个间隔点后重新加入试验（一个时间段内的所有观察数据都缺失），我想知道我们应该如何评估他们。当有缺失信息时，我们还能使用离散时间生存分析吗？例如，患者没有出席 T6 预约（手术后六个月），但他在 T9 时返回学习。
有关研究的更多信息
事件变量是疾病进展（是-否），主要协变量（时间相关变量-感兴趣的变量）是智力（是-否）。我们正在调查改变智力状态是否可以预测疾病的增加。]]></description>
      <guid>https://stats.stackexchange.com/questions/648701/type-of-censoring-in-discrete-time-survival</guid>
      <pubDate>Wed, 05 Jun 2024 19:03:51 GMT</pubDate>
    </item>
    <item>
      <title>t 代之后回归的方差是多少？</title>
      <link>https://stats.stackexchange.com/questions/648671/what-is-the-variance-of-a-regression-after-t-generations</link>
      <description><![CDATA[假设我们有一个回归：
$$x_{t+1} = b x_t + e_t.$$
取每边的方差，我们得到
$$\operatorname{Var}(x_{t+1}) = b^2 \operatorname{Var}(x_t) + \operatorname{Var}(e_t)。 $$
现在假设 $\operatorname{Var}(e_t) = \sigma^2$ 是所有 $t$ 的常数。
然后我们有一个一阶递归关系，因此我们可以明确地解决：
$$\operatorname{Var}(x_t) = \frac{\sigma^2 (1 - b^{2t})}{(1-b^2)}。$$
不幸的是，我正在阅读的书 Gregory Clark 的《儿子也复活了》给出的方差为 $\sigma^2 (1 - b^{2t})$。我的推导正确吗？
（注意：对于拥有这本书的人来说，页码是 297。这不是打字错误，后续文本已明确指出。）]]></description>
      <guid>https://stats.stackexchange.com/questions/648671/what-is-the-variance-of-a-regression-after-t-generations</guid>
      <pubDate>Wed, 05 Jun 2024 10:18:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么要正式检验工具变量的相关性假设？</title>
      <link>https://stats.stackexchange.com/questions/648577/why-can-we-formally-test-the-relevance-assumption-of-instrument-variable</link>
      <description><![CDATA[我在我以前的关于 IV 的幻灯片中看到，教授说我们无法测试 IV 的排除假设，但我们可以测试 IV 的相关性假设。他关于无法测试排除的论据是：

$y=\beta_1 x_1 +\beta_2 x_2+\gamma z + u$如果 z 不独立于 u，那么您无法通过执行此回归来测试排除要求，并与 $\gamma=0$ 争论，因为 $cov(z,u)\ne 0$ 会使 $\gamma$ 的估计产生偏差

同时，他说您可以通过以下方式测试相关性假设：

$x_1=\eta x_2+\lambda z+v$，如果 $\eta $ 与 0 显著不同，我们满足相关性要求

但是，第二个不是也存在内生性问题吗？因此，如果 z 不独立于 v，但与 x_2 相关，则 $\eta $ 会有偏差。如果我们观察到非零 gamma，则可能存在向上偏差，如果没有偏差，z 本身与 x 没有任何关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/648577/why-can-we-formally-test-the-relevance-assumption-of-instrument-variable</guid>
      <pubDate>Mon, 03 Jun 2024 21:57:36 GMT</pubDate>
    </item>
    </channel>
</rss>