<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 01 Jul 2024 03:17:47 GMT</lastBuildDate>
    <item>
      <title>我应该使用什么测试来计算加权平均比例？</title>
      <link>https://stats.stackexchange.com/questions/650227/what-test-should-i-use-for-weighted-mean-proportions</link>
      <description><![CDATA[我想知道组织中某个种族群体的“加权平均比例”（整体）与组织中某个种族群体的“加权平均比例”是否显著不同。部门内群组的比例。
我将该群组在 30 个组织中的比例分为两个级别：(a) 组织整体级别和 (b) 营销部门级别（在这些组织内）。
我创建了两个对象 - 每个级别一个。
prop.Overall &lt;- c(45.60, 38.98, 39.15, 40.09, 42.71, 44.68, 
43.43, 44.68, 45.60, 45.76, 45.85, 46.11, 
46.98, 47.83, 42.71, 49.22, 45.60, 51.54, 
53.08, 42.71, 56.67, 56.88, 57.54, 57.93, 
42.71, 63.13, 63.23, 66.25, 68.34, 68.42)

以上每一项都是特定组织中种族群体的比例。 （共 30 个组织）。
我在下面做了类似的事情，但针对的是这 30 个组织中市场营销部门级别的组比例。
prop.in.Mktg &lt;- c(40.78, 32.36, 41.33, 32.36, 28.11, 28.11, 
29.93, 28.11, 32.03, 44.12, 38.22, 28.87, 
27.19, 46.44, 41.93, 32.36, 32.99, 32.36, 
49.12, 32.36, 41.33, 39.55, 45.08, 42.23, 
35.45, 41.33, 41.33, 30.28, 26.65, 36.61)

使用这两个对象，我可以轻松找到频率、唯一条目并计算权重，然后计算该组在两个级别的加权平均比例。
我的问题：（这些对专家来说可能看起来很愚蠢，但还是要问：）
a) 在这个特殊情况下，（记住：我想知道组织中某个种族群体的“加权平均比例”是否与部门内某个种族群体的“加权平均比例”有显著差异...）——我是在进行均值统计检验还是比例检验？不知何故，这对我来说似乎比它应该的要复杂。 （我倾向于进行“单比例 Z 检验”——在这里这样做正确吗？）
b) 如果我使用“加权平均比例”，是否也需要使用“加权 SE”（围绕加权平均比例）？或者典型的标准误差就可以了？
注意：当然，这只是一个最小示例。差异权重在完整数据中确实很重要，使用加权平均比例进行比较很重要。然后，我们必须对营销部门以外的其他几个部门重复相同的测试。
如能澄清此处应使用哪种测试，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650227/what-test-should-i-use-for-weighted-mean-proportions</guid>
      <pubDate>Mon, 01 Jul 2024 00:56:25 GMT</pubDate>
    </item>
    <item>
      <title>导出 $k_i$ 以获得 $\hat{\beta} = \sum_{i=1}^n k_i y_i$，其中 $\hat{\beta}$ 是 OLS 估计量</title>
      <link>https://stats.stackexchange.com/questions/650226/deriving-k-i-for-hat-beta-sum-i-1n-k-i-y-i-where-hat-beta-is-t</link>
      <description><![CDATA[此问题与此帖子相关：证明截距的 OLS 估计量为 BLUE
由于我还不能直接在原始帖子下发表评论，所以我在这里发布我的问题。
在原始帖子中，回归模型定义为 $y_i = \alpha + \beta x_i + u_i$，而 $\beta$ 的 OLS 估计量自然表示为 $\hat{\beta}$。
然后 $\hat{\beta}$ 进一步定义为线性组合，形式为 $\hat{\beta} = \sum_{i=1}^n k_i y_i$，其中 $k_i = \frac{x_i - \bar{x}}{\sum_{i=1}^n (x_i - \bar{x})^2}$。
我假设 $\hat{\beta}=\frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2}$，我想知道 $k_i$ 是从所述线性组合直接得出的。]]></description>
      <guid>https://stats.stackexchange.com/questions/650226/deriving-k-i-for-hat-beta-sum-i-1n-k-i-y-i-where-hat-beta-is-t</guid>
      <pubDate>Mon, 01 Jul 2024 00:51:52 GMT</pubDate>
    </item>
    <item>
      <title>如果我应用过采样，我应该如何分割我的数据集？</title>
      <link>https://stats.stackexchange.com/questions/650218/how-should-i-split-my-dataset-if-i-am-applying-oversampling</link>
      <description><![CDATA[相关： 如何将多种采样技术应用于单个数据集？
假设我有一个名为 my_dataset.dat 的数据集，长度为 1079134 行。
此数据集有三个类，并且存在类不平衡，如下所示：
LabelColumn
A 459325
C 377954
B 241855

我想将 随机过采样 和 SMOTE 应用于此数据集。
但是，我应该如何以及何时将数据集拆分为training-set、validation-set 和 testing-set？
选项 1。

将数据集拆分为 training_set、validation_set 和 testing_set
仅对 training_set 应用过采样
使用 training_set 训练模型
使用 validation_set 验证模型
使用 testing_set 测试模型

选项 2。

将数据集拆分为 set_1 和 validation_set
对set_1
将 set_1 拆分为 training_set 和 testing_set
使用 training_set 训练模型
使用 validation_set 验证模型
使用 testing_set 测试模型

选项 #2 对我来说没有任何意义。但是，Q1 影响因子 10 的期刊 中提出了这种技术。
注意：需要权威答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/650218/how-should-i-split-my-dataset-if-i-am-applying-oversampling</guid>
      <pubDate>Sun, 30 Jun 2024 19:34:35 GMT</pubDate>
    </item>
    <item>
      <title>如何将多种采样技术应用于单个数据集？</title>
      <link>https://stats.stackexchange.com/questions/650217/how-can-i-apply-multiple-sampling-techniques-to-a-single-dataset</link>
      <description><![CDATA[相关： 如果我应用过采样，我应该如何分割我的数据集？
假设我有一个名为 my_dataset.dat 的数据集，其中包含三个类。该数据集存在类别不平衡，如下所示：
LabelColumn
A 459325
C 377954
B 241855

我想将随机过采样和SMOTE应用于此数据集。
我应该连续应用这两种采样技术吗？
即

将数据集拆分为train_data和test_data
对train_data应用随机过采样以获得ros_data
对ros_data应用SMOTE以获得ros_smote_data
使用 serial_ros_smote_data 训练 ML 模型

或者，我应该并行应用这两种采样技术吗？
即，

将数据集拆分为 train_data 和 test_data
对 train_data 应用 随机过采样 以获得 ros_data
对 train_data 应用 SMOTE 以获得 smote_data
将 ros_data 和 smote_data 连接到palallel_ros_smote_data
使用 palallel_ros_smote_data 训练 ML 模型

注意：需要权威答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/650217/how-can-i-apply-multiple-sampling-techniques-to-a-single-dataset</guid>
      <pubDate>Sun, 30 Jun 2024 19:18:32 GMT</pubDate>
    </item>
    <item>
      <title>运行多项式混合效应回归模型时出现错误：model.info\$wcount：$ 运算符对于原子向量无效</title>
      <link>https://stats.stackexchange.com/questions/650216/running-polynomial-mixed-effects-regression-model-with-error-model-info-wcount</link>
      <description><![CDATA[我正在使用 LCC 包 来估计两种方法随时间变化的一致性。模型估计类似于 lme，因为它基于混合效应模型。
我的数据框如下：
&#39;data.frame&#39;: 50000 obs. 5 个变量中的 5 个：
$ blood_gluc：数值 5.5 6.1 5.4 6.7 5.2 4.8 7.0 ...
$ method：具有 2 个水平“新”、“旧”的因子：2 2 2 2 2 2 2 2 2 2 ...
$ time：数值 1 2 3 4 5 6 7 8 9 10 ...
$ group：具有 2 个水平“0”、“1”的因子：2 1 2 1 1 2 2 1 2 1 ...
$ ID：具有 50 个水平“1”、“2”、“3”、“4”、...的因子：1 1 1 1 1 1 1 1 1 1 ...

我的 lcc 模型如下：
m1&lt;-lcc(data = df, subject = &#39;ID&#39;, resp = &#39;blood_gluc&#39;,
method = &#39;method&#39;, time = &#39;time&#39;, 
qf = 1, qr = 1, show.warnings = TRUE, components = TRUE, 
lme.control = list(opt=&#39;optim&#39;))

这个模型会运行，但是当我尝试添加&amp;;group&amp;; 的协变量时带有：
m2 &lt;- update(m1, covar =&#39;group&#39;)

我收到以下消息：

colnames&lt;-(*tmp*, value = paste(covar[[1]][i], levels(Data[, 中出现错误：尝试在少于两个维度的对象上设置“colnames”
model.info 中出现错误$wcount 中出现错误：$ 运算符对原子向量无效&quot;

我不确定如何更正此错误，因为此变量是我数据框中的一个因素。我猜想这与我的模型规范存在一些冲突。任何建议都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/650216/running-polynomial-mixed-effects-regression-model-with-error-model-info-wcount</guid>
      <pubDate>Sun, 30 Jun 2024 19:07:16 GMT</pubDate>
    </item>
    <item>
      <title>块金效应的无偏估计</title>
      <link>https://stats.stackexchange.com/questions/650189/unbiased-estimator-of-nugget-effect</link>
      <description><![CDATA[问题：我正在尝试测量块金效应，该效应由$(1-\lambda)$参数化，在以下方差-协方差中用于描述我的 n 个观测的多元正态分布：$\sigma_{x}^{2}[(\lambda)A_{n}+(1-\lambda)\mathbb{I}_{n}]$，其中$A_{n}$是完全已知的，对角线值全为 1，并且是半正定的，而$\mathbb{I}_{n}$是单位矩阵。分布的平均向量 $\mu_{x}$ 只是重复 n 次的相同数字。到目前为止，我使用了最大似然估计和受限最大似然估计 (REML)，但它们都有偏差。对于我的问题，$\lambda$ 被限制为 $[0,1]$，但是因为我使用的是现成的实现，所以对于我的 REML 估计，限制被取消（例如允许负值），但理想情况下不会这样。无论如何，您可以从模拟结果中看到，两个估计量都给出了真实 $\lambda$ 值的有偏估计。是否有可用于 $\lambda$ 的无偏估计量？是否存在可能与 MLE 估计不同的最小 MSE 估计量？
模拟结果：对于 ${0.0,0.1,0.2,...0.9,1.0}$ 中的每个 $\lambda$ 值，我使用已知 $\mu_{x}$、$\sigma_{x}^{2}$、$\lambda$ 和 $A_{n}$ 的模型模拟了 5000 个数据集，然后拟合两种方法（ML、REML）。在表格中，我报告了误差的平均值、方差和 MSE（均方误差）。
注意：对于此表，误差是估计值-真实值，因此如果估计值为 1.0，真实值为 0.9，则误差为 +0.1。



Lambda 用于模拟
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0




ML：平均值（误差）
0.0096
-0.076
-0.11
-0.059
0.050
0.15
0.21
0.21
0.17
0.093
-0.00081


ML：方差（误差）
0.00086
0.0022
0.0084
0.017
0.018
0.012
0.0049
0.0015
0.00028
3.8e-05
4.9e-06


ML： MSE
0.00096
0.0081
0.020
0.021
0.021
0.034
0.049
0.047
0.029
0.0088
5.6e-06


REML：平均值（误差）
0.0058
-0.068
-0.082
-0.027
0.074
0.17
0.22
0.22
0.17
0.094
-0.00033


REML：方差（误差）
0.0031
0.0050
0.011
0.017
0.017
0.011
0.0045
0.0013
0.00027
3.7e-05
6.0e-06


REML： MSE
0.0031
0.0097
0.017
0.017
0.022
0.039
0.052
0.048
0.029
0.0088
6.1e-06



如果您有兴趣，可以找到有关我的数据处理的生物学问题的更多详细信息这里和这里，但我很乐意回答任何问题；你不必去阅读那些链接。]]></description>
      <guid>https://stats.stackexchange.com/questions/650189/unbiased-estimator-of-nugget-effect</guid>
      <pubDate>Sun, 30 Jun 2024 01:59:28 GMT</pubDate>
    </item>
    <item>
      <title>如何根据多项逻辑回归的输出手动计算边际效应</title>
      <link>https://stats.stackexchange.com/questions/650183/how-to-manually-calculate-marginal-effects-from-output-of-a-multinomial-logistic</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650183/how-to-manually-calculate-marginal-effects-from-output-of-a-multinomial-logistic</guid>
      <pubDate>Sat, 29 Jun 2024 22:19:00 GMT</pubDate>
    </item>
    <item>
      <title>小数据集的相关性？</title>
      <link>https://stats.stackexchange.com/questions/650146/correlation-for-small-dataset</link>
      <description><![CDATA[我有一个 $x$ 和一个 $y$，我想找到它们的相关性以进一步了解它们之间的关系。不幸的是，我只有 $10$ 个点。我可以真诚地使用皮尔逊相关系数吗（在数据集大小的情况下，是否有普遍接受的规则来决定何时不使用它）？是否有某种推荐用于这种情况的替代相关性？
如果相关的话，我实际上有很多 $x$ 和 $y$，每个都有 $10$ 个点，我正在使用相关系数来总结我所看到的。通过图表进行目视检查会发现很多混合结果（一些结果看起来有点线性，并且给出约为$0.8$的皮尔逊相关系数，但大多数都有奇怪的非线性关系）。]]></description>
      <guid>https://stats.stackexchange.com/questions/650146/correlation-for-small-dataset</guid>
      <pubDate>Sat, 29 Jun 2024 04:01:59 GMT</pubDate>
    </item>
    <item>
      <title>对于给定平均值和标准差的正数据，偏度的下限是多少？</title>
      <link>https://stats.stackexchange.com/questions/650039/vintage-of-this-lower-bound-on-skewness-for-positive-data-with-given-mean-and-sd</link>
      <description><![CDATA[事实证明，对于任何具有给定平均值 μ 和标准差 σ 的严格正数据集，其偏度 $g_1$ 都有一个下限：
$$
g_1 &gt; \sigma/\mu - \mu/\sigma。
$$
虽然在最近的一些文献中，它被当作一个新的结果来讨论，但在我看来，它很可能相当古老——原因我在这篇 PubPeer 文章（其中还包含一个基本证明）中概述过。
来这里问这个问题时，我遇到了 2 个可以立即应用这个结果的问题：请参阅我的答案这里和这里。因此，这表明下限至少没有它应该的那么出名。但它可能是最近才出现的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650039/vintage-of-this-lower-bound-on-skewness-for-positive-data-with-given-mean-and-sd</guid>
      <pubDate>Thu, 27 Jun 2024 11:01:24 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中，结合 IV 方法对面板数据进行 Tobit 估计？</title>
      <link>https://stats.stackexchange.com/questions/649981/tobit-estimation-on-panel-data-in-combination-with-an-iv-approach-in-r</link>
      <description><![CDATA[我有面板数据（按年份划分的国家），并且我的因变量是左删失的（许多国家/地区的值是零，其他国家/地区的数字非常大）。因此，我认为我应该在面板数据上实施 Tobit 模型。此外，我怀疑存在反向因果关系，同时还需要实施 IV 方法。如何在 R 中执行此操作？如何确保我的标准错误计算正确？
理想情况下，我可以使用
a. 固定效应，
b. 池化，
c. 随机效应和
d.一阶差分。
# 第二阶段和第一阶段 IV 回归
fixed1_iv_2sls_IMP &lt;- ivreg(Y ~ X + W + factor(country) + 
factor(year) | Z + W + 
factor(country) + factor(year),
data = data)

# 提取残差
data$res_fixed1_iv_2sls_IMP &lt;- residuals(fixed1_iv_2sls_IMP)

# 残差的 Tobit 回归
tobit_model &lt;- censReg(res_fixed1_iv_2sls_IMP ~ X + W + 
factor(country) + factor(year),
left = 0, right = 100, data = data)

# Tobit 模型摘要
summary(tobit_model)

# HAC 标准错误
fixed1_iv_2sls_IMP_se &lt;- coeftest(fixed1_iv_2sls_IMP, 
vcov = vcovHC(fixed1_iv_2sls_IMP, type = &quot;HC3&quot;))[, 2]
]]></description>
      <guid>https://stats.stackexchange.com/questions/649981/tobit-estimation-on-panel-data-in-combination-with-an-iv-approach-in-r</guid>
      <pubDate>Wed, 26 Jun 2024 16:49:50 GMT</pubDate>
    </item>
    <item>
      <title>cor_mat、cor.test 和调整 p 值</title>
      <link>https://stats.stackexchange.com/questions/649986/cor-mat-cor-test-and-adjusting-p-values</link>
      <description><![CDATA[我想确定 R 数据框中一个变量与所有其他变量之间的相关性和 p 值，因此我使用 cor_mat 创建了一个相关矩阵，然后使用 cor_get_pval。相关 p 值均为 p&lt;.0001。为了测试准确性，我分别对我的一个变量和其他一些变量使用了 cor.test。我得到了相同的相关系数，但 p 值非常高 (p&gt;.5)。
我认为原因在于 cor_mat 不会调整多重假设检验的 p 值，而 cor.test 会，但 cor_mat 的 p 值通常不应该高于 cor.test 值吗？无论如何，为了尽量减少 I 类错误的可能性（这就是调整 p 值的原因），我将 cor_mat 中的置信度提高到 0.9999，并得到了同样非常低的 p 值。这是我的代码：
cor_crime2022_test &lt;- cor_mat(Crime2022_Gini , method = &quot;pearson&quot; , 
conf.level = 0.9999)
pval &lt;- cor_get_pval(cor_crime2022_test)

cor.test(Crime2022_Gini$TotIncidents , Crime2022_Gini$Gini2022)

我的想法正确吗？我应该依赖 cor_mat 或 cor.test 中的 p 值吗？我应该做点别的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649986/cor-mat-cor-test-and-adjusting-p-values</guid>
      <pubDate>Wed, 26 Jun 2024 15:29:19 GMT</pubDate>
    </item>
    <item>
      <title>用分数多项式预测重建模型</title>
      <link>https://stats.stackexchange.com/questions/650011/reproducing-model-with-fractional-polynomial-predictions</link>
      <description><![CDATA[我正在使用分数多项式拟合 gamlss 模型。我的 x 变量是一个正实数，包括零，y 也是正实数，范围从 1000 到 2000。
当我尝试手动重现链接 mu 项的预测时（出于教育目的），结果与“预测”函数的结果不匹配。例如，在下面的模型中，我的截距估计值为 7.1397169（使用摘要函数）。使用 getSmo 函数，我得到了分数多项式的估计值和幂。由于我有两次相同的功率，所以第二项后面跟着一个对数。
据我所知，要手动计算这些项，我需要执行以下操作：
link(mu) = 7.1397169 -0.19476 + 0.05359new_age**(0.5) + 
0.07165new_age**(0.5)*log(new_age)

但是当我将结果与预测函数进行比较时，它们不匹配。例如，如果 new_age = 1，我得到 link(mu) = 6.998547，但使用 predict 我得到 6.917356。
我的线索是我总是收到一条警告，说我的 x 变量已移动 1。但即使我将其与 new_age = 0 或 new_age = 2 进行比较，结果仍然不匹配。有人知道我哪里错了吗？
library(gamlss)
set.seed(42)

# 模拟数据
x &lt;- seq(0, 95, length.out = 96)
y &lt;- seq(1000, 2000, length.out = 96)
df = data.frame(cbind(x, y))

# fp 模型
model &lt;- gamlss(formula = y ~ fp(x, npoly = 2),
sigma.formula = ~fp(x, npoly = 1),
family = GA(), data = df, 
method = combined(100),
trace = FALSE) 
# 摘要以获取截距
summary(model)

# 获取分数多项式的估计值
getSmo(model)

#获取分数多项式的幂
getSmo(model)$power

# 手动预测
new_age = 1
mu = 7.1397169 -0.19476 + 0.05359*new_age**(0.5) + 
0.07165*new_age**(0.5)*log(new_age)

# 通过 predict 进行预测
predict(model)
]]></description>
      <guid>https://stats.stackexchange.com/questions/650011/reproducing-model-with-fractional-polynomial-predictions</guid>
      <pubDate>Wed, 26 Jun 2024 14:55:02 GMT</pubDate>
    </item>
    <item>
      <title>非递归 SEM 在 lavaan 中的特定间接影响</title>
      <link>https://stats.stackexchange.com/questions/649387/specific-indirect-effects-of-a-non-recursive-sem-in-lavaan</link>
      <description><![CDATA[我目前正在分析的结构方程模型包含一个间接循环，我无法找到一种直接的方法来计算它的具体间接影响。具有此问题的模型的一个最小示例是：
Y ~ yb*B
A ~ ax*X + ac*C
B ~ ba*A + bc*C
C ~ cb*B

现在我想知道，例如，A 对 Y 的具体增量间接影响。我知道，通常，lavaan 中的解决方案是使用 := 运算符来定义间接影响的路径。但是在这种情况下，我必须计算一个无穷和：
IE_A := ba*yb + ba*cb*ac*ba*yb + ba*cb*ac*ba*cb*ac*ba*yb + ...

我找到了一些关于如何基于系数矩阵手动计算该影响的论文，但计算这些标准误差会非常繁琐，我想知道是否还有其他方法可以做到这一点，例如我错过的 lavaan 中的功能或用于这些计算的另一个包。]]></description>
      <guid>https://stats.stackexchange.com/questions/649387/specific-indirect-effects-of-a-non-recursive-sem-in-lavaan</guid>
      <pubDate>Mon, 17 Jun 2024 15:10:15 GMT</pubDate>
    </item>
    <item>
      <title>如何在建模过程中衡量两种方法之间改进的显著性</title>
      <link>https://stats.stackexchange.com/questions/649384/how-to-measure-significance-of-improvement-between-two-methods-during-modeling</link>
      <description><![CDATA[大家好，我有两种开发模型的方法。我使用一组输入特征（set1）来训练模型1，另一组输入特征具有（set1 特征 + 额外的 set2 特征）。然后，我开发预测值和观察值之间的斯皮尔曼相关性来比较这两个模型，并发现具有更多特征的模型2 具有更好的相关性。
例如：使用模型1 的基因1 的相关性约为 0.56
使用模型2 的基因1 的相关性约为 0.62
因此，通过添加更多 set2 特征可以实现约 0.06 的改进

现在，我想了解这种约 0.06 的改进是否显着，或者这种改进是否是由于随机噪声/波动造成的
有人可以告诉我如何衡量每个基因模型改进的重要性，并衡量添加导致改进的 set2 特征是否是由于添加了更多信息特征而不是由于随机噪声/波动造成的。]]></description>
      <guid>https://stats.stackexchange.com/questions/649384/how-to-measure-significance-of-improvement-between-two-methods-during-modeling</guid>
      <pubDate>Mon, 17 Jun 2024 14:37:29 GMT</pubDate>
    </item>
    <item>
      <title>PCA中权重矩阵与载荷矩阵的区别</title>
      <link>https://stats.stackexchange.com/questions/648365/difference-between-weight-matrix-and-loading-matrix-in-pca</link>
      <description><![CDATA[目前我正在使用 PCA 技术（特别是稀疏 PCA 技术），但我的问题围绕着获取 PCA 中的权重矩阵。
此参考为 PCA 提供了以下表示：
$X = X W P&#39; + E$
其中 $X$ 是包含 $I$ 个观测值和 $J$ 个变量的分数的数据矩阵。假设我们选择有 $Q$ 个组件，则 $W$ 是 $J \times Q$ 权重矩阵，$P$ 是 $J \times Q$ 加载矩阵，$E$ 是 $I \times J$ 残差矩阵。他进一步提到，它通常用 $T = XW$ 表示（因此 $X = TP&#39; +E$）。
当我想检查矩阵时，我感到困惑。例如，scikit-learn 中的 PCA 仅提供加载矩阵，但对于我的工作，我还需要权重矩阵。其他实现（在本例中为稀疏 PCA 实现）也仅提供加载向量。
简而言之，我的问题，加载矩阵是否与权重矩阵相同（即 $W=P$？）。如果不是，我如何获得 $W$？有什么区别？]]></description>
      <guid>https://stats.stackexchange.com/questions/648365/difference-between-weight-matrix-and-loading-matrix-in-pca</guid>
      <pubDate>Fri, 31 May 2024 11:34:39 GMT</pubDate>
    </item>
    </channel>
</rss>