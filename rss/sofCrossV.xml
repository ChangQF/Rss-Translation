<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 Jan 2025 15:17:17 GMT</lastBuildDate>
    <item>
      <title>r 面板数据 - 哪个标准误差 - Driscoll-Kraay，Beck-Katz，还是减少偏差的线性化估计量？</title>
      <link>https://stats.stackexchange.com/questions/660717/r-panel-data-which-standard-error-driscoll-kraay-beck-katz-or-bias-reduced</link>
      <description><![CDATA[使用面板数据（不平衡），我想知道应该对以下 plm 使用哪种标准误差来理解事件的影响（跨用户相同）：
m = plm(y ~ x + time + event + time:event, 
data=df, 
index=c(&quot;user_id&quot;, &quot;date&quot;),
model=&quot;within&quot;, 
effect = &quot;individual&quot;)

数据包括嵌套在 800 多个用户中的 ~400,000 个观察值，其中几个用户的观察值很少，而其他用户的观察值则很多。
为了解释异方差和自相关，不确定我们是否应该使用 Driscoll-Kraay 标准误差、Beck-Katz 或 CR2 偏差减少线性化估计器：
lmtest::coeftest(m, vcov = vcovSCC(m, type = &#39;HC1&#39;)) ##Driscoll-Kraay
lmtest::coeftest(m, vcov = vcovBK(m, type = &#39;HC1&#39;)) ##Beck-Katz
clubSandwich::coef_test(m, vcov = &quot;CR2&quot;, cluster = df$user_id) ##Bell &amp; McCaffrey (2002); Pustejovsky &amp; Tipton (2017) 

虽然幸运的是，感兴趣的变量的重要性对于假设检验来说并没有太大变化，但不确定哪一个最适合使用。
它们是否都解决了异方差性和自相关性问题，但只是在解决方式上有所不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/660717/r-panel-data-which-standard-error-driscoll-kraay-beck-katz-or-bias-reduced</guid>
      <pubDate>Wed, 29 Jan 2025 15:08:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 构建和预测每日功能曲线（电力供应）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660716/build-and-forecast-daily-functional-curves-electricity-supply-in-python</link>
      <description><![CDATA[我正在处理一个大型电力市场数据集（约 9700 万行），时间跨度从 2022 年 12 月 1 日到 2024 年 12 月 20 日。主要列如下：
[&#39;PURPOSE_CD&#39;, &#39;STATUS_CD&#39;, &#39;UNIT_REFERENCE_NO&#39;, &#39;INTERVAL_NO&#39;, &#39;BID_OFFER_DATE_DT&#39;, &#39;QUANTITY_NO&#39;, &#39;AWARDED_QUANTITY_NO&#39;, &#39;ENERGY_PRICE_NO&#39;, &#39;MERIT_ORDER_NO&#39;, &#39;PARTIAL_QTY_ACCEPTED_IN&#39;, &#39;ADJ_QUANTITY_NO&#39;, &#39;ZONE_CD&#39;, &#39;AWARDED_PRICE_NO&#39;, &#39;OPERATORE&#39;]

我已过滤掉 OPERATORE == 的行&quot;Bilateralista&quot;（这些对应于不通过市场的双边合同，因此它们具有“虚假”或未知的价格）。我还只保留 PURPOSE_CD == &quot;OFF&quot;（官方报价）的行。我已将日期字段 BID_OFFER_DATE_DT 转换为适当的日期时间（格式 &#39;%Y%m%d&#39;）。
接下来，对于每个日期和每个小时（由 INTERVAL_NO 给出），我按 ENERGY_PRICE_NO 对数据进行分组并求和 QUANTITY_NO。然后我按价格排序并计算累计数量以构建供应曲线的“阶梯”版本。由于我需要更平滑的表示，我应用样条/核平滑将这些阶跃函数转换为连续、非递减曲线$S(p)$。因此，本质上，对于每一天和每小时，我最终得到一个一维函数$S_t(p)$，其中$t$表示时间（天 + 小时），$p$表示价格轴。
我的目标：

以时间序列的方式预测这些剩余供应曲线（平滑函数）。
理想情况下，我希望实现函数自回归模型（如 FAR(1) 或类似模型）或广义加性模型 (GAM) 方法，将每条每日/每小时曲线视为函数时间序列中的观测值。我很好奇是否有现有的 Python 库或工作流程可以更直接地处理：

函数自回归模型，或
函数 GAM（其中每个函数都是响应），或
推荐的 Python 函数时间序列预测“最佳实践”方法。



非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660716/build-and-forecast-daily-functional-curves-electricity-supply-in-python</guid>
      <pubDate>Wed, 29 Jan 2025 14:51:20 GMT</pubDate>
    </item>
    <item>
      <title>SEM 中因果关系的作用（示例）</title>
      <link>https://stats.stackexchange.com/questions/660714/role-of-causality-in-sem-via-an-example</link>
      <description><![CDATA[我问过一个关于SEM和解释结构系数的先前问题，但我找到了一个更实质性的例子，并决定提出一个新问题来帮助我理解。
在《结构方程模型：第二门课程》一书中由 Hershberger 等人撰写，讨论了这对模型：

这些是统计上等效的模型，即给出相同的隐含协方差矩阵和拟合指标。在他们的例子中，他们说
$$ b_{\text{V2V1}} = 0.470, b_{\text{V3V2}} = 0.361 \rightarrow b_{\text{V2V1}}b_{\text{V3V2}} = 0.170 $$
$$ b_{\text{V1V2}} = 0.522, b_{\text{V2V3}} = 0.433 \rightarrow b_{\text{V1V2}}b_{\text{V2V3}} = 0.226 $$
换句话说，$V1$ 对 为class=&quot;math-container&quot;&gt;$V3$ 或反之亦然，具体取决于所选的模型。
我通常认为，“如何绘制箭头”（即断言什么因果关系）的选择应该有实质性理论作为依据。但鉴于此示例，感觉您选择的理论（结合您的数据）现在对一个变量对另一个变量的影响做出了定量预测。如果两个方向都有合理的理论论据，那么人们几乎可以任意选择根据您的研究问题做出的定量论据。
这是正确的理解吗？我以前真的想将 SEM 中的箭头视为真正的双向箭头，即我无法从中推断出任何因果关系。也许我确实无法从 SEM 中推断出因果关系，但我可以从构建 SEM 模型所用的理论中推断出因果关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/660714/role-of-causality-in-sem-via-an-example</guid>
      <pubDate>Wed, 29 Jan 2025 14:00:31 GMT</pubDate>
    </item>
    <item>
      <title>测试回归斜率是否接近零</title>
      <link>https://stats.stackexchange.com/questions/660713/testing-if-a-regression-slope-is-close-to-zero</link>
      <description><![CDATA[我正在编写一个程序，希望在其中找到某个信号的本底噪声。为此，我对缓冲区执行线性回归，直到遇到斜率为零，这应该告诉我我的缓冲区已充满本底噪声。
这意味着我必须能够判断观察到的斜率是否确实为零。但是，标准线性回归程序通常会为您提供测试的 p 值或统计量
$H_0$：斜率为零
$H_1$：斜率非零（或单侧替代中的正或负）
我想要的是实际上相反的测试，我希望能够拒绝零假设“$H_0$：斜率非零”。但这个问题感觉像是不适定的，我不确定如何计算这个测试的 t 统计量。有没有好的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/660713/testing-if-a-regression-slope-is-close-to-zero</guid>
      <pubDate>Wed, 29 Jan 2025 13:44:02 GMT</pubDate>
    </item>
    <item>
      <title>这个散点图显示的是同方差性还是异方差性？</title>
      <link>https://stats.stackexchange.com/questions/660710/does-this-scatter-plot-show-homoscedasticity-or-heteroscedasticity</link>
      <description><![CDATA[回归模型的残差和预测值的散点图
]]></description>
      <guid>https://stats.stackexchange.com/questions/660710/does-this-scatter-plot-show-homoscedasticity-or-heteroscedasticity</guid>
      <pubDate>Wed, 29 Jan 2025 12:26:18 GMT</pubDate>
    </item>
    <item>
      <title>如何用 IPW（WeightIt/weightthem）正确调整混杂因素，并用 adaptedCurves 绘制调整后的生存曲线？</title>
      <link>https://stats.stackexchange.com/questions/660709/how-to-properly-adjust-for-confounders-with-ipw-weightit-weightthem-and-plot-a</link>
      <description><![CDATA[我正在估计两组之间的总体生存率 (OS) 差异，同时调整混杂因素。我的工作流程包括：

缺失数据的多重插补。
使用 weightthem 包进行逆概率加权 (IPW)，方法为 &quot;cbps&quot; （estimand = &quot;ATE&quot;）。
使用 bal.tab() 和 love.plot()（来自 cobalt 包）检查平衡。
对加权数据进行 Cox 回归（在每个插补数据集中使用 coxph_weightit()）。
绘制调整后的生存曲线（使用 adjustedCurves 包，方法为 &quot;iptw_cox&quot;）。

以下是我的代码：
# 1. 生成 IPW 权重
w.out_model1 &lt;- weightthem(
formula_OS, 
data = df, 
method = &quot;cbps&quot;, # 例如 &quot;ebal&quot;、&quot;cbps&quot;、&quot;glm&quot; 等。
estimand = &quot;ATE&quot;,
criterion = &quot;smd.mean&quot;,
link = &quot;logit&quot;
)

# 2. 检查 IPW 前后的平衡
bal.tab(
w.out_model1, 
data = df, 
s.d.denom = &quot;pooled&quot;, 
m.threshold = 0.1, 
v.threshold = 2, 
imp.fun = &quot;max&quot;, 
un = TRUE, 
abs = TRUE,
binary = &quot;std&quot;
)

love.plot(
w.out_model1, 
stats = c(&quot;mean.diffs&quot;), 
Thresholds = c(m = 0.1), 
abs = TRUE, 
var.order = &quot;alphabetical&quot;,
grid = TRUE,
drop.distance = TRUE,
wrap = 20,
binary = &quot;std&quot;
)

# 3. 通过 coxph_weightit 在每个估算数据集上拟合 Cox 模型
fit.imp.cox &lt;- with(
df,
WeightIt::coxph_weightit(
Surv(OS_from_target_local_treatment, death) ~
age_binary + sex + bmi_binary + ASA_binary + 
comorbidities_Major + extrahep_metastases_at_diagnosis_CRLM +
RAS + BRAF + MMR + Systemic_treatment_prior_local_treatment +
Metastasis_diameter + Segments_treated_per_session_binned +
min_distance_gallblad_mm_binned + Margin_size_binary + stage_binary +
syn_meta_label_binary + Treatment_type_tumor_near_gallbladder
)
)

# 4. 来自 Cox 的汇总结果模型
summary(mice::pool(fit.imp.cox), conf.int = TRUE, exponentiate = TRUE)

# 5. 使用 adaptedCurves 绘制调整后的生存曲线
adj &lt;- adaptedsurv(
data = df,
variable = &quot;Treatment_type_tumor_near_gallbladder&quot;,
ev_time = &quot;OS_from_target_local_treatment&quot;,
event = &quot;death&quot;,
method = &quot;iptw_cox&quot;,
times = c(12, 36, 60, 96, 120),
bootstrap = TRUE,
n_boot = 500,
n_cores = 10,
treatment_model = Treatment_type_tumor_near_gallbladder ~
age_binary + sex + bmi_binary + ASA_binary + 
comorbidities_Major + extrahep_metastases_at_diagnosis_CRLM +
RAS + BRAF + MMR + Systemic_treatment_prior_local_treatment +
Metastasis_diameter + Segments_treated_per_session_binned +
min_distance_gallblad_mm_binned + Margin_size_binary + stage_binary +
syn_meta_label_binary,
weight_method = &quot;cbps&quot;
)

plot(adj, use_boot = TRUE, risk_table = TRUE, risk_table_stratify = TRUE, 
censoring_ind = &#39;lines&#39;)

经过此分析，我发现两组之间的 OS 没有统计学上的显著差异。但是，我想确认我的步骤是正确的，并且是 IPW + Cox 建模的最佳实践。此外，我想在调整后的生存曲线上绘制置信区间，但无法让它们出现在 adaptedCurves 生成的图中。

我的整体工作流程（多重插补中的 IPW + 通过 coxph_weightit 的 Cox 模型 + 通过 adaptedCurves 绘图）是否适合估计两组之间的调整生存曲线？

在使用 adaptedCurves 和 IPW 时，如何包含置信区间？我看到 use_boot =TRUE 选项，但置信区间仍未显示在最终图中。是否有不同的参数或已知的解决方法？


任何有关最佳实践、替代方法或调试技巧的指导都将不胜感激。提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/660709/how-to-properly-adjust-for-confounders-with-ipw-weightit-weightthem-and-plot-a</guid>
      <pubDate>Wed, 29 Jan 2025 12:02:36 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中 ELBO 推导的澄清</title>
      <link>https://stats.stackexchange.com/questions/660708/clarification-on-the-elbo-derivation-in-diffusion-models</link>
      <description><![CDATA[我正在阅读一篇关于去噪扩散模型的论文，第 10 页有以下 ELBO 推导。
$$
\begin{aligned}
\log p(\mathbf{x}_0) &amp;= \log \int p(\mathbf{x}_{0:T}) \, d\mathbf{x}_{1:T} \\
&amp;= \log \int \frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} q(\mathbf{x}_{1:T} | \mathbf{x}_0) \, d\mathbf{x}_{1:T} \\
&amp;= \log \mathbb{E}_{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \left[ \frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \right] \\
&amp;\geq \mathbb{E}_{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \right] \\
&amp;= \mathbb{E}_{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) \prod_{t=1}^{T} p_\theta (\mathbf{x}_{t-1} | \mathbf{x}_t)}{\prod_{t=1}^{T} q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right]
\end{aligned}
$$
我只是想澄清一下几件事。$x_0$ 是随机变量 $X_0$ 的实现吗？如果是，$q(x_{0:T})$ 是否意味着 $x_0$ 是实现，而其余的 $x_{1:T}$ 是随机变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/660708/clarification-on-the-elbo-derivation-in-diffusion-models</guid>
      <pubDate>Wed, 29 Jan 2025 11:54:19 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 预测区间的宽度随时间保持不变的原因是什么？</title>
      <link>https://stats.stackexchange.com/questions/660707/what-can-be-a-reason-of-width-of-arima-prediction-interval-being-constant-over-t</link>
      <description><![CDATA[我使用 forecast 包中的 forecast.Arima 来计算我的 SARIMA 模型的预测区间。我无法分享确切的数据，但我可以说它不是完全平稳的，并且模型是 SARIMA(3,0,0)(0,0,1)[12]。
forecast::forecast(model, h = 12, level = c(0.95), bootstrap = TRUE, npaths = 10^5)

我还看到了其他人的预测结果，据说他们使用相同的模型和数据，但使用其他编程语言实现 - 它们是不同的。在我的例子中，预测区间随时间变宽，而在他们的例子中，预测区间的宽度大致固定。
造成这种差异的潜在原因是什么（除了代码中的拼写错误）？

我尝试设置 bootstrap = FALSE - 结果预测区间非常宽。我知道 bootstrap = TRUE 使用蒙特卡洛模拟来计算区间，我猜 TRUE 使用的是理论区间，但目前我不知道如何得出它们以及它们为什么这么宽（也许这与数据不是静止的事实以及 $\sigma$ 的估计有关？）
]]></description>
      <guid>https://stats.stackexchange.com/questions/660707/what-can-be-a-reason-of-width-of-arima-prediction-interval-being-constant-over-t</guid>
      <pubDate>Wed, 29 Jan 2025 11:22:56 GMT</pubDate>
    </item>
    <item>
      <title>非参数方法检查观测值是否与平均值不同</title>
      <link>https://stats.stackexchange.com/questions/660705/non-parametric-method-to-check-if-observations-are-different-than-mean</link>
      <description><![CDATA[我有一个随机变量的独立观测列表，我想检查这个变量的平均值是否与某个固定数字不同。我该怎么做？
分布不一定是正态的，甚至不是对称的。
有人建议我使用置换检验，但阅读更多内容后，我明白它是用来比较两个分布，而不是一个分布和一个固定数字。虽然我可以说另一个分布是固定的，但这不会有问题吗，因为方差当然是不同的？我的意思是，我想知道这个测试是否可以发现方差而不是平均值的差异，这不是我想要的。]]></description>
      <guid>https://stats.stackexchange.com/questions/660705/non-parametric-method-to-check-if-observations-are-different-than-mean</guid>
      <pubDate>Wed, 29 Jan 2025 10:39:34 GMT</pubDate>
    </item>
    <item>
      <title>从复杂的协方差矩阵生成数据是预期结果的转置[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660702/generating-data-from-complex-covariance-matrix-is-transpose-of-expected-result</link>
      <description><![CDATA[这是我的 Matlab 代码：
M = 2;
N = 100000;
R = [1, 0.5+0.1i; 0.5-0.1i, 1]
x = randn(M, N);
L = chol(R, &#39;lower&#39;);
x = L*x;
R_est = cov(x.&#39;)

我期望当 N 趋向于无穷大时，R_est 应该趋向于 R。相反，R_est 趋向于转置 (R)。我的理由如下：
一般来说，如果 $x=N(\mu, \Sigma)$，则 $Lx=N(L\mu, L\Sigma L^H)$。如果 $z=N(0, I)$（多元标准正态分布）且 $LL^H=\Sigma$，则 $Lz=N(0, \Sigma)$。因此，我的代码根据标准正态分布生成数据集 $x$，并采用 $Lx$ 来获取我想要的协方差矩阵。我已在我的代码中确认，$LL^H=\Sigma$。]]></description>
      <guid>https://stats.stackexchange.com/questions/660702/generating-data-from-complex-covariance-matrix-is-transpose-of-expected-result</guid>
      <pubDate>Wed, 29 Jan 2025 09:25:26 GMT</pubDate>
    </item>
    <item>
      <title>维数灾难是否适用于狄利克雷分布？</title>
      <link>https://stats.stackexchange.com/questions/660700/does-the-curse-of-dimensionality-apply-to-the-dirichlet-distribution</link>
      <description><![CDATA[我正在分析狄利克雷分布的解空间如何随着参数数量的增加而演变。我最初试图测量狄利克雷分布所覆盖的“体积”，期望它会随着参数数量的增加而增长。然而，我发现体积实际上随着参数数量的增加而缩小。
狄利克雷分布定义在$(K-1)$维单纯形上：
$$ S_{K-1} = \left\{ (x_1, x_2, \dots, x_K) \ \Big| \ x_i \geq 0, \sum_{i=1}^{K} x_i = 1 \right\}。 $$
这个单纯形的体积与 成正比
$$ \frac{1}{(K-1)!}。$$
由于阶乘增长迅速，因此随着 $K$ 的增加，这个体积会缩小。这表明，狄利克雷分布并没有扩展到广阔的空间（正如人们从维数灾难中预期的那样），而是越来越受到限制。
我的问题：

维数灾难是否适用于狄利克雷分布？我的直觉是，它并不像通常意义上的那样，因为空间在缩小而不是增长，从而防止了高维空间中常见的稀疏性问题。
狄利克雷分布是否仍然表现出高维效应（例如集中现象）？

如果能提供任何见解或参考资料来澄清这一点，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660700/does-the-curse-of-dimensionality-apply-to-the-dirichlet-distribution</guid>
      <pubDate>Wed, 29 Jan 2025 08:53:32 GMT</pubDate>
    </item>
    <item>
      <title>Somers 的二元结果 D，Python 与 SAS</title>
      <link>https://stats.stackexchange.com/questions/660697/somers-d-for-binary-outcome-python-vs-sas</link>
      <description><![CDATA[我正在尝试在编程语言之间迁移。 SAS 和 Python 似乎对 Somers&#39; D 的定义并不一致。在此示例中，x 被视为独立变量，而 y 是二元结果（因变量）。
以下是使用 scipy.stats.somersd 计算 Somers&#39; D 的 Python 代码片段，并与精心手动计算的 Somers&#39; D 进行交叉检查，结果为
$$\frac{C-D}{C+D+T},$$
其中 $C$、$D$ 和 $T$ 分别是一致、不一致和并列对的数量：
import scipy

def manual_somers_d(x, y):
# 初始化计数
C = 0
D = 0
T_Y = 0

# 计算 X 和 Y 中的一致、不一致对和关系
for i in range(len(x)):
for j in range(i + 1, len(x)):
if x[i] &lt; x[j] and y[i] &lt; y[j]: # 一致
C += 1
elif x[i] &gt; x[j] and y[i] &gt; y[j]: # 一致
C += 1
elif x[i] &lt; x[j] and y[i] &gt; y[j]: # 不一致
D += 1
elif x[i] &gt; x[j] and y[i] &lt; y[j]: # 不一致
D += 1
elif y[i] == y[j] and x[i] != x[j]: # Y 中一致（但 X 中不一致）
T_Y += 1

# 计算 Somers 的 D
return (C - D) / (C + D + T_Y)

x = [1,2,3,4,5]
y = [0,1,0,1,1]

print(manual_somers_d(x, y))
print(scipy.stats.somersd(x, y).statistic)

两种计算均得出相同结果 (0.4)。
但是，当针对同一数据集移至 SAS 时，计算结果将返回 Somers 的 D 值 2/3：
数据示例;
输入 x y;
数据线;
1 0
2 1
3 0
4 1
5 1
;
运行;

proc logistic data=example;
model y = x;
ods output Association=assoc;
运行;

proc print data=assoc;
运行;

顺便说一句，这与上面代码中计算 scipy.stats.somersd(y,x) 相同（切换变量）
一些观察：

文档 scipy.stats.somersd 指出 (x,y) 是 y 依赖于 x 的正确顺序。
模型语句文档 (SAS) 指出 model y = x 表达了相同的意思。

我在文档中遇到了错误吗？为什么值不匹配？]]></description>
      <guid>https://stats.stackexchange.com/questions/660697/somers-d-for-binary-outcome-python-vs-sas</guid>
      <pubDate>Wed, 29 Jan 2025 07:58:34 GMT</pubDate>
    </item>
    <item>
      <title>等效结构方程模型中结构系数的解释</title>
      <link>https://stats.stackexchange.com/questions/660684/interpretation-of-structure-coefficients-in-equivalent-structural-equation-model</link>
      <description><![CDATA[本文描述了统计等效结构方程模型的问题，其中变量之间的关联（即因果关系的方向）各不相同，但拟合指标相同。作为示例，他们展示了以下两个模型的结构系数：

在模型 2 和模型 3 之间，SE、感知认可和兴趣变量之间的一些箭头被翻转（作者选择通过重新排列变量来绘制）。得到的拟合指数是相同的。
然而，这种翻转导致性别和三个中介变量的结构系数不同。例如，模型 2 预测性别对 SE 的影响为 0.27，但在模型 3 中为 0.08。
我应该怎么做？这些模型之一是“正确的”吗？ （即有充分的理论依据，并可能有实验可以找出因果关系）并且其结构系数是否正确？我是否应该不关注这些“中间”系数，而只考虑总体效应？]]></description>
      <guid>https://stats.stackexchange.com/questions/660684/interpretation-of-structure-coefficients-in-equivalent-structural-equation-model</guid>
      <pubDate>Tue, 28 Jan 2025 21:58:29 GMT</pubDate>
    </item>
    <item>
      <title>具有 beta geom 分布分位数函数的 CDF</title>
      <link>https://stats.stackexchange.com/questions/660681/cdf-with-beta-geom-distribution-quantile-function</link>
      <description><![CDATA[我有一个带 CDF 的 beta 几何 (BG) 分布：
$$F(x) = \Bigg( 1 - \frac{\text{B}(a,b+x)}{\text{B}(a,b)} \Bigg)
\quad \quad \quad 
\text{for } x \geqslant 0,$$
其中 $\text{B}$ 是 beta 函数。有没有办法在不借助数值方法和求根算法的情况下找到上述分布的分位数。我知道 beta 分布与 F 分布相关，我正在尝试看看我们是否可以找到与 BG 分布的类似关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/660681/cdf-with-beta-geom-distribution-quantile-function</guid>
      <pubDate>Tue, 28 Jan 2025 20:03:16 GMT</pubDate>
    </item>
    <item>
      <title>双向方差分析 - 参数估计解释</title>
      <link>https://stats.stackexchange.com/questions/660677/two-way-anova-parameter-estimates-interpretation</link>
      <description><![CDATA[双向方差分析中生成的参数估计表：

当我解释参数估计表时，我被引导相信截距是数据的整体总平均值？这是正确的吗？
但是，我很困惑它与参考类别有什么关系？它们的参数估计值为 0？这是否意味着设计 C 和尺寸小（参考类别）嵌入在截距内？
我的问题是设计 C 和尺寸小对因变量和整体总平均值的影响怎么会相同？]]></description>
      <guid>https://stats.stackexchange.com/questions/660677/two-way-anova-parameter-estimates-interpretation</guid>
      <pubDate>Tue, 28 Jan 2025 19:17:58 GMT</pubDate>
    </item>
    </channel>
</rss>