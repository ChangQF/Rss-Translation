<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 10 Jun 2024 21:15:15 GMT</lastBuildDate>
    <item>
      <title>在回归不连续设计的背景下将管理数据集与调查数据合并：我应该考虑哪些事情？</title>
      <link>https://stats.stackexchange.com/questions/648992/merging-an-administrative-dataset-with-survey-data-in-the-context-of-a-regressio</link>
      <description><![CDATA[我有一个管理数据集，其中包含回归不连续设计 (RDD) 研究的运行变量。我计划将此数据集与为其他目的收集的调查数据合并，以获取我研究的因变量。除了外部有效性之外，此过程是否还可能导致其他方法论陷阱？
此外，我可能想使用调查权重来提高外部有效性。这有意义吗？如果有意义，您知道如何使用 rdrobust 命令（在 STATA 或 R 中）实现它们吗？所讨论的调查使用了复杂的样本设计。]]></description>
      <guid>https://stats.stackexchange.com/questions/648992/merging-an-administrative-dataset-with-survey-data-in-the-context-of-a-regressio</guid>
      <pubDate>Mon, 10 Jun 2024 20:42:40 GMT</pubDate>
    </item>
    <item>
      <title>Firth 物流与 AIC 传统物流的比较</title>
      <link>https://stats.stackexchange.com/questions/648990/comparing-firths-logistic-and-traditional-logistic-by-aic</link>
      <description><![CDATA[我的数据包含罕见事件，因此我决定使用 logistf 包开发 Firth 惩罚逻辑回归。我还想应用传统的 ML 逻辑回归来比较它们的性能。我选择了“赤池信息准则”来比较这两个模型，但它的计算似乎不同，因为我读到这里。
我想知道哪一个对我的数据更准确。使用 AIC 是否正确？如果是，我应该手动计算它们吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648990/comparing-firths-logistic-and-traditional-logistic-by-aic</guid>
      <pubDate>Mon, 10 Jun 2024 20:28:24 GMT</pubDate>
    </item>
    <item>
      <title>SPSS 软件更新和 PROCESS/RLM 宏扩展输出打印 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648987/spss-software-update-and-process-rlm-macro-extensions-output-print</link>
      <description><![CDATA[最近将我的 SPSS 更新到最新版本后，PROCESS 和 RLM Macro 扩展生成的输出现在难以读取/解释（可能是由于软件更新不一致）。还有其他人遇到过这个问题吗？如果是这样，您是否找到了让输出再次可解释的方法？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648987/spss-software-update-and-process-rlm-macro-extensions-output-print</guid>
      <pubDate>Mon, 10 Jun 2024 20:04:24 GMT</pubDate>
    </item>
    <item>
      <title>证明马尔可夫链是否不可约/循环？（Metropolis-within-Gibbs）</title>
      <link>https://stats.stackexchange.com/questions/648985/proving-whether-or-not-a-markov-chain-is-irreducible-recurrent-metropolis-with</link>
      <description><![CDATA[我们希望使用切片采样的变体从标准正态分布中生成样本。为此，提出了以下 Gibbs 方案，从集合 $S = \{(u,x)\colon 0 &lt; u &lt; \phi(x)\}$ 中均匀采样：
给定 $(U_0,X_0)\in A$ 和 $\delta &gt; 0$,
\begin{align}
\text{for } i &amp;= 1,2,\ldots, M\\
&amp;U_i \sim \text{Unif}(0, \phi(X_{i-1})) \\
&amp;\text{Sample }X_i \text{ with an MH-step goals against $f(x\,|\, U_{i}) \propto I(0 &lt; u &lt; \phi(x))$},\\ &amp; \text{使用提议 }\text{Unif}(X_{i-1}-\delta, X_{i-1}+\delta)
\end{align
即，我们将从标准切片采样器中的垂直切片中进行采样的步骤已被 Metropolis-Hastings 步骤取代。
问题是确定/证明此过程生成的链是否不可约且可循环。
我对这个问题的看法是，由于 $\phi(\cdot)$ 的支持是连通的，因此该链至少应该是不可约的，因为我们应该能够通过写下完全在 $S$ 内的适当步骤序列，以有限的步骤移动到任何点 $(U^*, X^*)\in S$，该算法从任意起点出发，$(U_0, X_0)$ 到达目的地。有什么想法可以将其形式化吗？
至于递归，我真的不知道该怎么做。]]></description>
      <guid>https://stats.stackexchange.com/questions/648985/proving-whether-or-not-a-markov-chain-is-irreducible-recurrent-metropolis-with</guid>
      <pubDate>Mon, 10 Jun 2024 19:55:05 GMT</pubDate>
    </item>
    <item>
      <title>非中心 t 分布的非中心参数</title>
      <link>https://stats.stackexchange.com/questions/648983/noncentrality-parameter-of-noncentral-t-distribution</link>
      <description><![CDATA[设 $X_{1}, \dots, X_{n}$ 为 iid $\mathbb{N}(\mu, \sigma^{2})$。接下来，设
$$
T_{n} = \frac{\bar{X}}{s/\sqrt{n}},
$$
其中 $\bar{X}$ 和 $s$ 分别为样本均值和样本方差。据我所知，$T_{n}$ 具有非中心 t 分布，自由度为 $n-1$。我很困惑，非中心参数是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648983/noncentrality-parameter-of-noncentral-t-distribution</guid>
      <pubDate>Mon, 10 Jun 2024 18:08:12 GMT</pubDate>
    </item>
    <item>
      <title>在评估性能之前使用异常检测器标记数据</title>
      <link>https://stats.stackexchange.com/questions/648982/labeling-data-with-an-anomaly-detector-prior-to-evaluating-performance</link>
      <description><![CDATA[利用模型标记数据，然后执行训练/测试拆分以评估该模型的性能，这样做是否错误？
假设我有一个未标记的数据集，其中缺失的标签是一个表示类别的二进制变量，并且类别非常不平衡（异常检测场景的典型情况）。
我一直在考虑使用异常检测器来帮助标记过程。该过程看起来像这样。

假设数据仅包含一个类
在整个数据集上训练模型
仔细查看检测器的输出并确定排名更独特/孤立的数据是否实际上包含稀有类。
在训练模型之前，可能会重复此过程多次，并删除新发现的稀有类实例。

这对于标记来说很有意义，但在评估性能时，这似乎是错误的。如果我使用检测器来帮助我标记数据，那么我会因此而预期性能估计会过于乐观。当然，我（人类）实际上会审查和添加稀有类的标签。
一旦数据有了标签，我就会将数据分成训练集和测试集，其中训练集没有稀有类的实例，而测试集包含稀有类的所有实例以及常见类的许多实例。在这样的流程中，在测试集中找到“真阳性”似乎是一个自我实现的预言。但是，这种训练/测试分割的模型将不同于用于帮助标记的模型，因为模型参数将用较少的数据来估计。
在本次对话的背景下，异常检测器是一个通用术语，可能是许多不同算法中的一种。有关示例，请参阅https://builtin.com/machine-learning/anomaly-detection-algorithms。]]></description>
      <guid>https://stats.stackexchange.com/questions/648982/labeling-data-with-an-anomaly-detector-prior-to-evaluating-performance</guid>
      <pubDate>Mon, 10 Jun 2024 17:58:49 GMT</pubDate>
    </item>
    <item>
      <title>平行于 x 轴的直线的自相关曲线[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648980/autocorrelation-curve-of-a-line-parallel-to-x-axis</link>
      <description><![CDATA[以下是两个图：

直线，与 x 轴平行
滞后 = 0 至 100 的直线自相关

现在，我的问题是：为什么自相关曲线逐渐减小并接近于零？这种减小代表什么？
问题源于这样一个事实：直线总是相同的。没有变化。
那么，为什么自相关会变化？

]]></description>
      <guid>https://stats.stackexchange.com/questions/648980/autocorrelation-curve-of-a-line-parallel-to-x-axis</guid>
      <pubDate>Mon, 10 Jun 2024 16:59:54 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么假设检验方法来比较分级延迟计数</title>
      <link>https://stats.stackexchange.com/questions/648979/what-hypothesis-testing-method-should-i-use-for-comparing-binned-latency-counts</link>
      <description><![CDATA[我正在尝试选择一种适当的假设检验方法来测试一组服务器的延迟是否高于另一组。但是，我所拥有的只是对延迟箱数量的计数，而我无法访问原始延迟值。数据如下所示




[0, 0.01)
[0.01, 0.05)
[0.05, 1)
...




第 1 组
$n_{11}$
$n_{12}$
$n_{13}$
...


组2
$n_{21}$
$n_{22}$
$n_{23}$
...



其中列是单位为秒的延迟箱，$n_{ij}$ 显示 (组，延迟箱) 对记录的请求数。
最初，我考虑使用 Pearson 的 $\chi^2$ 检验，但这没有考虑到箱的排序。另外，不清楚如何使用 $\chi^2$ 测试进行定向测试。有没有更好的推荐？]]></description>
      <guid>https://stats.stackexchange.com/questions/648979/what-hypothesis-testing-method-should-i-use-for-comparing-binned-latency-counts</guid>
      <pubDate>Mon, 10 Jun 2024 16:57:46 GMT</pubDate>
    </item>
    <item>
      <title>从 MFVI 获取准确的不确定性？</title>
      <link>https://stats.stackexchange.com/questions/648978/getting-accurate-uncertainty-from-mfvi</link>
      <description><![CDATA[我想知道是否有任何研究方法可以提高均值场变分推理（不丢弃均值场近似）的准确性。显然，它以低估不确定性而闻名，我理解这是因为它是贝叶斯推理的单峰近似。
但我特别想知道，在贝叶斯深度学习的背景下，是否有后处理校准方法（例如，拟合线性模型来转换预测）可以使贝叶斯高密度区间（或贝叶斯可信区间）合理准确？]]></description>
      <guid>https://stats.stackexchange.com/questions/648978/getting-accurate-uncertainty-from-mfvi</guid>
      <pubDate>Mon, 10 Jun 2024 16:26:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么增加模型复杂性会减少整个数据分布的偏差？</title>
      <link>https://stats.stackexchange.com/questions/648977/why-does-increasing-model-complexity-reduce-bias-over-the-entire-data-distributi</link>
      <description><![CDATA[在机器学习中，我们经常谈论偏差-方差权衡，以及如何增加模型复杂度既可以减少偏差又可以增加方差。我理解为什么增加模型复杂度一开始会减少偏差，但一旦进入过度拟合领域，我就不太清楚了。
以下是偏差的公式：
$\operatorname{Bias}_D\big[\hat{f}(x;D)\big] = \operatorname{E}_D\big[\hat{f}(x;D)- f(x)\big]$。随着模型复杂度超过某个点（忽略双重下降），模型开始严重过度拟合其训练数据，并开始对其余大部分数据分布做出疯狂且越来越错误的预测。为什么这会减少整个数据分布的偏差？
在这篇文章中：偏差最终会随着模型复杂度的增加而增加吗？，公认的答案声称，从数据分布中抽样的训练集的模型预测平均值将平均为接近真实值的值。但我不清楚为什么这是真的，以及为什么它不能平均为其他值。]]></description>
      <guid>https://stats.stackexchange.com/questions/648977/why-does-increasing-model-complexity-reduce-bias-over-the-entire-data-distributi</guid>
      <pubDate>Mon, 10 Jun 2024 16:01:10 GMT</pubDate>
    </item>
    <item>
      <title>计算结果的标准差</title>
      <link>https://stats.stackexchange.com/questions/648949/standard-deviation-on-result-of-calculation</link>
      <description><![CDATA[我正在根据实验数据计算一个值。计算结果为
$$ k = \frac{a - b}{c} \cdot \frac{1}{T}, $$
并且 $a$、$b$ 和 $c$ 都是通过多次实验测量的，样本之间会有一些差异，并且 $T$ 是一个常数。它们也是独立测量的，因此即使我碰巧有 $a$、$b$ 和 $c$ 各 $N$ 个值，我也不能说它们在三元组中彼此“属于”对方，或诸如此类。
计算结果 $k$ 中的标准差的正确方法是什么？我相信我不能完全不合理地假设 $a$、$b$ 和 $c$ 服从正态分布，尽管严格来说，这些数字（无论是在现实中还是在测量中）都被限制为正值，因此它们不是真正正态的。
（我尝试从 $a$、$b$ 和 $c$ 的不同值的所有排列中计算 $k$。假设 $N = 4$，那么我有 $4 \times 4我可以使用 \times 4 = 64$ 种不同的组合来计算 $k$，然后我可以取其标准差。不过，这有点像黑客攻击，所以一些理论见解会很好。）
为了提供一个更具体的例子，这里有一些数字（以 Python 代码的形式，为方便起见）。这些是通过测量获得的，其中 $a$ 的值是从四个不同的样本中测得的，$b$ 的值是从另外四个样本中测得的，而 $c$ 的值是从另外四个样本中测得的。
a = np.array([286641, 266093, 227900, 165559])
b = np.array([136748, 159846, 108337, 164340])
c = np.array([303791, 327579, 410016, 340820])
T = 5

因此问题就变成了：给出这些数据，并且假设 $k$ 是根据上面的公式计算出来的，如果我能说出的话，那么关于我计算出的 $k$ 值中的标准差（或其他表达不确定性的方式）是什么呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/648949/standard-deviation-on-result-of-calculation</guid>
      <pubDate>Mon, 10 Jun 2024 07:59:51 GMT</pubDate>
    </item>
    <item>
      <title>广义加性模型中的估计</title>
      <link>https://stats.stackexchange.com/questions/648924/estimation-in-generalized-additive-models</link>
      <description><![CDATA[我目前正在尝试通过 Simon N. Wood 所著的《广义可加模型：R 语言简介》一书来了解广义可加模型 (GAM)。但是，我对以下部分有一些疑问。
第 6.1 章指出，GAM 成为过度参数化的 GLM，形式为
$$g(\mu_i) = X_i\beta, \quad y_i \sim EF(\mu_i, \phi),$$
其中 $EF$ 代表指数族，并且 $\beta$ 通过最大化来估计
$$l_p(\beta) = l(\beta) - \frac{1}{2\phi}\sum_j\lambda_j\beta^TS_j\beta.$$
我的问题是：

简单地从对数似然中减去惩罚项的总和，然后最大化相对于$\beta$的结果函数的理由是什么？
因子$\frac{1}{2\phi}$从何而来？

任何帮助都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648924/estimation-in-generalized-additive-models</guid>
      <pubDate>Sun, 09 Jun 2024 20:48:15 GMT</pubDate>
    </item>
    <item>
      <title>我可以在具有非平稳每日变化的时间序列上使用 Prophet 吗？</title>
      <link>https://stats.stackexchange.com/questions/648884/can-i-use-prophet-on-a-timeseries-with-a-nonstationary-daily-variation</link>
      <description><![CDATA[我有一些有间隙的温度数据，需要将其插入到统一的时间序列中（也需要进行一些外推）。我正在尝试使用 FB Prophet，它看起来几乎完美。然而......
如果您查看图表，您会发现如果缺失数据远离每日极值，那么 Prophet 就没问题。但是当缺失数据接近每日最大值/最小值时，它会忽略测量数据。

阅读文档后发现，Prophet 似乎可以预测 a(t) + F(H) 形式的数据，其中 t 是每日时间，a(t) 缓慢变化但不平稳，H 是每小时时间，F(H) 是当天的周期性变化，但它无法预测 a(t) + b(t) F(H)，其中 b 也是缓慢变化但不平稳的。
我看到 非平稳时间序列预测的自适应归一化：这些作者将每一天分解成片段，然后通过移除和恢复非平稳因子 a(t) 和 b(t) 来应用归一化。这是正确的方法吗？它似乎并不完全容易实现，因为他们使用机器学习来进行拼接和切块。
或者，我确实看到 Prophet 允许引入任意回归量。如果我以某种方式估算了 b(t)（例如通过每天取平均值）或其他什么，那么有没有办法告诉 Prophet 有关 b 的信息？
人们还如何在时间序列中插入间隙？这似乎应该是一个完全标准的问题，但我遇到了麻烦。
df_p = df[[&quot;Time&quot;,&quot;Temperature&quot;]].copy()
df_p = df_p.rename(columns={&quot;Time&quot;:&quot;ds&quot;, &quot;Temperature&quot;: &quot;y&quot;})

model = Prophet(changepoint_prior_scale=0.1)
model.fit(df_p.dropna())
end = end=df_p[&#39;ds&#39;].iloc[-1] + pd.Timedelta(1,&quot;d&quot;)
uniform_dates = pd.date_range(start=df_p[&#39;ds&#39;].iloc[0], end=end, freq=&#39;15T&#39;)
uniform_df = pd.DataFrame({&#39;ds&#39;: uniform_dates})

#
# 填写值
#
forecast = model.predict(uniform_df)

plt.plot(df_p[&quot;ds&quot;],df_p[&quot;y&quot;],&#39;o&#39;,markersize=1)
plt.plot(forecast[&quot;ds&quot;], Forecast[&quot;yhat&quot;])
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/648884/can-i-use-prophet-on-a-timeseries-with-a-nonstationary-daily-variation</guid>
      <pubDate>Sun, 09 Jun 2024 00:17:04 GMT</pubDate>
    </item>
    <item>
      <title>如何处理固定效应和随机效应之间的方差竞争？</title>
      <link>https://stats.stackexchange.com/questions/648880/how-to-deal-with-competition-for-variance-between-a-fixed-and-random-effect</link>
      <description><![CDATA[我正在对数据进行分析，其中 X（预测变量）和 Y（响应）在广泛范围内存在假设关系，但由于预测变量的局部混合，在观察组中是随机的（无关系）。一个有趣的类比可能是餐厅里的杂烩碗，每个碗里都有不同数量的扇贝，从 10 到 100 个不等（大碗）。一碗杂烩包含未知数量的扇贝（非常大的碗）。
这是浓稠的杂烩，因此您只能用大勺“品尝”，大勺平均能舀出与碗中扇贝总数成比例的扇贝。您还可以用勺子品尝杂烩 - 扇贝密度越高，味道越浓。此外，整个碗的味道混合均匀。我们想要确定勺子上的扇贝数量和勺子上杂烩汤的味道之间的关系（我们假设味道是由碗决定的，而不是勺子上的扇贝）。我们从每个碗中取出几把勺子（忽略消耗 - 大碗）。我们想应用一个混合模型，以味道强度作为预测因子（OK 风味浓度），勺子上的扇贝数量作为响应，碗作为随机效应的分组变量。理想情况下，我们希望定义整个餐厅的味道和数量之间的关系。我们可以轻松地汇总每个碗中的味道和计数并获得整体关系 - 但这并不能解释碗内计数的变化。当应用混合模型时，随机效应似乎解释了所有的计数变化，而预测因子（味道）并不显着。有没有比“汇总”更好的方法？在混合模型框架内如何理解这种关系？
之前有人问过类似的问题（当固定和随机效应重叠时会发生什么？），但没有得到回答。我在本文末尾添加了一个简单的模拟来说明这个问题（遗憾的是我没有添加任何杂烩）。感谢您的考虑。
干杯，Darren
#
# 固定和随机效应方差竞争
#
library(mgcv)
# 模拟一些包含 8 个组的数据
slope = 1
sY = 1 # 组内变异性
sYbar = 0.2 # 组关系变异性

# 潜在关系
grpX &lt;- c(1,1,2,2,4,4,6,6) # 每组平均 X
grpYbar &lt;- slope*grpX + rnorm(length(grpX))*sYbar
plot(grpX,grpYbar)
cor(grpX,grpYbar)^2

# 执行 500 次模拟
#
# 每组模拟 5 个响应
grp &lt;- c(1,2,3,4,5,6,7,8)
replicate &lt;- c(1,2,3,4,5)
# 要保存在向量中的值
Xp &lt;- as.numeric(NULL)
Sp &lt;- as.numeric(NULL)
Bx &lt;- as.numeric(NULL)
#
for (dups in 1:500) {
#
simData &lt;- as.data.frame(list(grp=as.numeric(NULL),
replicate=as.numeric(NULL),
X=as.numeric(NULL),
Y=as.numeric(NULL)))
for (i in grp) {
for (j in replicate) {
g &lt;- grp[i]
r &lt;- replicate[j]
X &lt;- grpX[i] + rnorm(1)
Y &lt;- grpYbar[i] + rnorm(1)*sY
simData &lt;- rbind(simData,list(grp=g,
replicate=r,
X=X,
Y=Y))
}
}
#
s1 &lt;- gam(Y ~ X + s(grp, bs = &#39;re&#39;),
data=simData,method=&quot;REML&quot;)
#
Xp &lt;- c(Xp,summary(s1)$p.table[2,4])
Sp &lt;- c(Sp,summary(s1)$s.table[1,4])
Bx &lt;- c(Bx,summary(s1)$p.table[2,1])
#
}

# 绘制重要性
par(mfrow=c(2,2))
hist(Xp,main = &quot;Slope p 值&quot;)
abline(v=0.05,lty=2,col=&quot;red&quot;)
hist(Sp,main = &quot;随机效应 p 值&quot;)
abline(v=0.05,lty=2,col=&quot;red&quot;)
plot(Xp,Sp)
hist(Bx)

# 显著斜率
sum(Xp&lt;0.05)
# 显著 RE
sum(Sp&lt;0.05)
# RE(col) 的显著斜率(行)
Xsig &lt;- Xp&lt;0.05
Ssig &lt;- Sp&lt;0.05
sigTableData &lt;- as.data.frame(list(Xsig=Xsig,
Ssig=Ssig))
table(sigTableData)
]]></description>
      <guid>https://stats.stackexchange.com/questions/648880/how-to-deal-with-competition-for-variance-between-a-fixed-and-random-effect</guid>
      <pubDate>Sat, 08 Jun 2024 20:13:46 GMT</pubDate>
    </item>
    <item>
      <title>对于采用和使用健康赤池信息准则 (hAIC) 有何见解？</title>
      <link>https://stats.stackexchange.com/questions/648841/any-insights-on-the-adoption-and-use-of-the-healthy-akaike-information-criterion</link>
      <description><![CDATA[最近，我偶然发现了 Demidenko 在其 2004 年出版的《混合模型：R 的理论与应用》一书中提出的健康赤池信息准则 (hAIC)。尽管它具有（潜在的）优势，但我在文献中发现的对它的引用却非常少。
一些背景知识：健康赤池信息准则 (hAIC) 由 Demidenko 开发，用于解决传统赤池信息准则 (AIC) 在解释变量之间存在高度多重共线性时的局限性。 AIC 的计算方法如下：
$$
AIC = −2\log(\text{max})+2k
$$
其中 $\log(\text{max})$ 是最大对数似然，$k$ 是参数数量，hAIC 通过合并惩罚项来修改此值，该惩罚项考虑了参数向量的长度，Demidenko 声称这使得 hAIC 在存在不适定问题和/或高度相关预测变量的场景中特别有用。
hAIC 公式为：
$$
HAIC = H + AIC
$$
其中
$$
H = k \left[ \log\left(\frac{\|\beta_{\text{ls}}\|^2}{k}\right) - 1 \right]
$$
这里，$\beta_{ls}$表示参数和范数的最小二乘估计，$\|\beta_{\text{ls}}\|$是参数向量的欧几里得长度：
$$
\|\beta_{\text{ls}}\| = \sqrt{\sum_{i=1}^k (\beta_{\text{ls},i})^2}
$$
这个惩罚项旨在惩罚具有较大参数估计的模型，这表明存在多重共线性。通过纳入参数向量的范数，hAIC 可确保对系数过大的模型进行惩罚，从而促进更稳定、更可靠的估计。过度的多重共线性可能导致不适定问题，即模型矩阵几乎是奇异的，从而导致参数估计值出现较大方差。额外的惩罚项有助于缓解这一问题，因为它倾向于使用参数估计值较小、更稳定的模型（到目前为止，我所读到的资料中还没有提到如何区分由于多重共线性而导致的较大参数估计值和真正较大的参数效应）。传统的 AIC 只考虑参数的数量，而不考虑它们的大小。另一方面，hAIC 整合了参数的数量和大小，旨在采用更全面的模型选择方法，考虑模型的整体稳定性和可靠性。
我发现的唯一一项已发表的研究是 Harezlak 等人 (2007) 在一本名为“函数回归问题的惩罚解”的书中所做的研究。在本研究中，hAIC 通过结合误差方差估计、自由度和基函数系数范数来增强模型稳定性和可解释性。
所以，我想知道这里是否有其他人使用过 hAIC，或者见过它被使用，甚至听说过它？如果有，你对它有什么想法和经验？如果没有，您对我在这里介绍的内容有什么看法？
为了增加背景信息，以下是我想到的 AIC、hAIC 和 BIC 的一些优缺点：
惩罚结构：

AIC：惩罚项为 $2k$，重点关注参数数量。
BIC：惩罚项为 $k\log(n)$，随着观察次数的增加而增加，并为其他参数提供更强的惩罚。
hAIC：惩罚项包括参数数量和参数向量的范数，还解决了参数估计的大小问题。

模型选择：

AIC：由于每个惩罚较低，通常会选择更复杂的模型参数。
BIC：由于惩罚力度较大，倾向于使用更简单的模型，尤其是样本量增加时。
hAIC：旨在平衡模型拟合度和复杂性之间的权衡，同时专门解决多重共线性和参数不稳定的问题。

应用场景：

AIC：适用于主要关注预测准确性且观测次数不是过多时的模型选择。
BIC：在认为真实模型在候选模型中且样本量较大的情况下是首选。
hAIC：在具有高多重共线性或不适定问题的场景中特别有用，在这些场景中，传统 AIC 可能无法提供稳定可靠的模型选择。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648841/any-insights-on-the-adoption-and-use-of-the-healthy-akaike-information-criterion</guid>
      <pubDate>Fri, 07 Jun 2024 18:34:18 GMT</pubDate>
    </item>
    </channel>
</rss>