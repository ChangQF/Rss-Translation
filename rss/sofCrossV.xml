<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 17 Jan 2025 18:21:50 GMT</lastBuildDate>
    <item>
      <title>条件与边际：概率、可能性和模型</title>
      <link>https://stats.stackexchange.com/questions/660175/conditional-vs-marginal-probability-likelihood-and-models</link>
      <description><![CDATA[我很难理清这些想法。
1) 条件概率与边际概率：这是我最了解的一个，它依赖于概率的基本定律。
如果我们有两个连续随机变量 $X$ 和 $Y$。
$X$ 的边际概率密度函数，表示为 $f_X(x)$，是通过对 $Y$ 所有可能值的联合 PDF 进行积分获得的：
$$f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) dy$$
给定 $Y=y$，$X$ 的条件概率密度函数：
$$f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}$$
$$f_{X|Y}(x|y) = \frac{f_{Y|X}(y|x)f_X(x)}{f_Y(y)}$$
到目前为止一切正常。
2) 条件似然与边际似然：这个我也理解，因为它是一个第一部分的扩展。
我可以定义一个联合似然函数$L(\theta, \phi|X)$为：
$$L(\theta, \phi|X) \propto f_X(X|\theta, \phi)$$
从这里，边际似然和条件似然可以写成：
$$L_M(\theta|X) = \int_{-\infty}^{\infty} L(\theta, \phi|X) d\phi$$
$$L_C(\theta|X,\phi) = L(\theta, \phi|X)$$
3) 条件模型与边际模型（第 1 部分） 事情开始让我感到困惑。我以前听说过“条件和边际”这两个术语用于混合效应回归模型。例如，在纵向/聚类模型的背景下，我听说过以下内容：

像 GEE（一般估计方程）这样的回归框架被称为边际模型，因为它们估计整个总体的边际平均值。虽然 GEE 能够在估计阶段使用数据中存在的聚类级相关性，但最终模型无法在聚类级别提供任何统计推断。 GEE 只能描述整个人口层面上正在发生的事情。

$$ \text{logit}(P(Y_{ij} = 1|X_{ij})) = X_{ij}\beta^* $$

另一方面，混合/随机效应等回归框架被称为条件模型，因为它们可以通过其随机效应结构在集群级别提供统计推断。举例来说，聚类级别均值可以看作是条件均值（即以聚类为条件）。

$$ \text{logit}(P(Y_{ij} = 1|X_{ij}, b_i)) = X_{ij}\beta + b_i $$
我认为在我看来这一切都是合理的。
4) 条件模型与边际模型（第 2 部分）：我感到困惑的根源来自这里：https://en.wikipedia.org/wiki/Conditional_logistic_regression。虽然我并没有完全理解这一点，但这似乎是一种固定效应回归，我们不再对估计集群级别效应感兴趣。相反，我们似乎根据某些集群级别信息集来匹配人员，以避免变量混淆。这是维基百科上关于条件逻辑回归的一个示例 - 这次我们不是估计聚类级别的影响（就像在随机影响中所做的那样），而是对它们进行匹配以控制它们的影响：
$$P(Y_{i1}=1, Y_{i2}=0|X_{i1},X_{i2}, Y_{i1}+Y_{i2}=1) = \frac{\exp(\beta^TX_{i1})}{\exp(\beta^TX_{i1}) + \exp(\beta^TX_{i2})}$$
因此，似乎在所有这些情况下，被条件化的术语及其条件化方式都会发生变化。
我说得对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660175/conditional-vs-marginal-probability-likelihood-and-models</guid>
      <pubDate>Fri, 17 Jan 2025 17:36:04 GMT</pubDate>
    </item>
    <item>
      <title>采用交错干预且无对照组的混合效应中断时间序列分析</title>
      <link>https://stats.stackexchange.com/questions/660174/mixed-effects-interrupted-time-series-analysis-with-staggered-intervention-and-n</link>
      <description><![CDATA[我有在不同时间点在不同县（集群）实施的干预措施的数据。我该如何评估干预措施的影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/660174/mixed-effects-interrupted-time-series-analysis-with-staggered-intervention-and-n</guid>
      <pubDate>Fri, 17 Jan 2025 17:20:45 GMT</pubDate>
    </item>
    <item>
      <title>如何用 SE 和 P 值计算每 100,000 个比率之间的差异</title>
      <link>https://stats.stackexchange.com/questions/660173/how-to-calculate-the-difference-between-2-rates-per-100-000-with-se-and-p-value</link>
      <description><![CDATA[我有一个数据集，其中包含每年记录的每 100,000 人口年龄调整后的死亡率及其针对特定疾病的标准误差 (SE)。从 CDC Wonder 数据库 中提取。
我旨在通过计算差异、构建置信区间 (CI) 和确定此差异的 p 值来比较两个特定年份之间的死亡率。
此外，我旨在通过以下方式计算相对变化率：
相对变化 = (Rate_year_2 - Rate_year_1) / Rate_year_2
这在统计上合适吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660173/how-to-calculate-the-difference-between-2-rates-per-100-000-with-se-and-p-value</guid>
      <pubDate>Fri, 17 Jan 2025 16:46:06 GMT</pubDate>
    </item>
    <item>
      <title>伪似然与似然的比较</title>
      <link>https://stats.stackexchange.com/questions/660172/pseudolikelihood-compared-to-likelihood</link>
      <description><![CDATA[假设我们有一个离散多元概率分布，其密度$f_{\theta}(X=(x_1,...,x_n))=\frac{g_{\theta}(X=(x_1,...,x_n))}{Z}$取决于某个参数$\theta$。我特意以这种形式将其写出，以表示 Z 是难以计算的归一化常数。这种分布的伪似然函数（为简单起见，针对单个数据点）是否定义为：
$$
PL_{\theta}(X=(x_1,...,x_n)) = \Pi_{i}f_{\theta}(X_i=x_i | X_j=x_j, i \neq j)
$$
如果是这样，那么由此得出的公式在我看来有点奇怪，因为：
$$
= \Pi_{i}\frac{g_{\theta}(X)}{\sum_{X_i=a}g_{\theta}(X_1=x_1,...,X_i=a,...)}
$$
将分母称为 $Z_i(X)$，可得到：
$$
log(PL_{\theta}(X=(x_1,...,x_n))) = n log(g_{\theta}(X)) - \sum_i log( Z_i(a))
$$
而真实似然度为
$$
log(L_{\theta}(X=(x_1,...,x_n))) = log(g_{\theta}(X)) - log(Z)
$$
我不明白为什么伪对数似然度可以作为对数似然度的可接受替代品。我确实明白它比似然度更容易计算，但我无法理解为什么它是一个可接受的估计。原始文章（格点数据的统计分析）在这方面没有太大帮助，维基百科上非常简短的文章也没有。我知道现在人们可能更喜欢蒙特卡洛方法，但我仍然想了解一下。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660172/pseudolikelihood-compared-to-likelihood</guid>
      <pubDate>Fri, 17 Jan 2025 16:25:55 GMT</pubDate>
    </item>
    <item>
      <title>t 检验/z 检验的分布假设是什么？是关于总体、样本、样本均值还是检验统计量？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660170/what-are-the-distributional-assumptions-of-t-test-z-test-pertaining-to-is-it-ab</link>
      <description><![CDATA[我一直认为，t 检验、z 检验和一般线性模型的正态性假设与残差的正态性有关，不一定与样本的正态性有关。
但是，我最近听到几个人保证，由于中心极限定理，A/B 测试中的大多数数值结果都可以在样本量 (N) 足够大的情况下用 t 检验建模。我理解 CLT 与样本均值的抽样分布有关，在足够高的 N 下接近正态性，所以我认为在足够大的 N 下使用 t 检验是没有道理的，因为这是为样本建模的，我认为 t 检验的正态性分布假设与残差有关。但是，我听说 t 检验在足够大的 N 下可以很稳健。
我还知道 Z 检验通常用于比较比例。我理解这也是由于 CLT，因为虽然比例是二项式数据的平均值，但如果您抽样足够多的比例，它将接近正态性。但是，此数据的样本分布和总体分布（例如点击率）将是二项式的。 Z 检验如何适用于二项式样本数据？
同时，网上关于 t 检验对正态性的假设的描述到处都是：

样本数据呈正态分布
样本数据呈正态分布
样本均值呈正态分布
样本数据呈正态分布
样本均值呈正态分布
我也读过检验统计量的正态性，但我认为这相当于指样本的正态性均值。

这让我有几个问题：

t 检验/z 检验的假设是否与样本正态性、总体正态性或样本均值/检验统计量的正态性有关？
如果 t 检验的假设也与上述之一有关，那么它是否也与残差的正态性有关？
如何证明 Z 检验用于比较二项分布或比例？样本数据和总体数据呈二项分布，但根据 CLT，样本均值将接近正态性。我认为应该对此类数据使用二项逻辑回归，因为它是二项数据。
t 检验是一般线性模型的一个特例。我一直认为线性模型的假设是关于残差的正态性，而不是其他东西。如果 t 检验涉及样本均值/检验统计量的正态性，这是否也意味着在足够大的 N 下，一般线性模型对于非正态分布的样本也是合理的（例如，点击次数、任务时间等）？
如果 Z 检验或 T 检验是关于样本均值的正态性，那么在足够大的 N 下进行 Z 检验或 T 检验的合理性对我来说仍然很困惑。如果样本 N 很大，那么它就是一个均值。但 CLT 不是关于对样本均值的重复抽样吗？在抽取超过 1,000 或 1,000,000 个样本均值后，无论原始总体样本分布如何，抽样分布都会近似为正态分布？我不清楚更高的样本量如何确保你可以对非正态样本数据进行 t 检验或 z 检验。

感谢您的任何见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/660170/what-are-the-distributional-assumptions-of-t-test-z-test-pertaining-to-is-it-ab</guid>
      <pubDate>Fri, 17 Jan 2025 16:06:56 GMT</pubDate>
    </item>
    <item>
      <title>一致性检验：p 值较低是否正常？[重复]</title>
      <link>https://stats.stackexchange.com/questions/660168/consistency-check-is-it-normal-to-have-a-low-p-value</link>
      <description><![CDATA[我正在使用 kruskal-wallis 检验来检查不同类型的群体之间是否存在差异，在获得显著结果后，我进行了事后检验并获得了较低的 p 值。关于每个组的样本是这样的：


我的问题是，得到这些低 p 值是正常的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660168/consistency-check-is-it-normal-to-have-a-low-p-value</guid>
      <pubDate>Fri, 17 Jan 2025 14:56:33 GMT</pubDate>
    </item>
    <item>
      <title>是否可以预测边际效应曲线的形状？</title>
      <link>https://stats.stackexchange.com/questions/660166/is-it-possible-to-predict-the-shape-of-a-marginal-effects-curve</link>
      <description><![CDATA[这是逻辑回归的一般方程：
$$ P(Y=1|x_1,x_2) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + \beta_2x_2)}} $$
要找到边际效应，我们需要对每个预测变量求导。对于 $x_1$:
$$ \frac{\partial p}{\partial x_1} = \frac{\partial}{\partial x_1}\left(\frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + \beta_2x_2)}}\right) $$
$$ \frac{\partial p}{\partial x_1} = \beta_1 \cdot p \cdot (1-p) $$
对于 $x_2$:
$$ \frac{\partial p}{\partial x_2} = \beta_2 \cdot p \cdot (1-p) $$
正如预期的那样，两个变量的边际效应方程具有相同的形式。我尝试为不同的值绘制此方程：

所以这是我的问题：如果我们比较两种相同类型的模型（例如逻辑回归，没有交互作用，没有高阶项），边际效应曲线是否总是具有相同的形状？从理论上讲，我们甚至可以在分析它们之前就知道这种形状会是什么样子吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660166/is-it-possible-to-predict-the-shape-of-a-marginal-effects-curve</guid>
      <pubDate>Fri, 17 Jan 2025 14:51:46 GMT</pubDate>
    </item>
    <item>
      <title>当同时使用随机临床试验和随机对照试验时，如何计算效果大小？</title>
      <link>https://stats.stackexchange.com/questions/660165/how-to-calculate-effect-sizes-when-using-both-randomised-clinical-trials-and-ran</link>
      <description><![CDATA[我正在开展系统评价（10 篇论文）。6 项研究有对照组，4 项没有，并且正在比较多种干预措施。
要计算效果大小，我最好使用 RCT 中对照组和干预组的干预后平均值吗？
或者，由于我正在为临床试验进行事前/事后计算，我是否将其应用于 RCT 并仅查看事前/事后的平均值？
如果只查看一个组（事前/事后），我是否不必汇总标准差？]]></description>
      <guid>https://stats.stackexchange.com/questions/660165/how-to-calculate-effect-sizes-when-using-both-randomised-clinical-trials-and-ran</guid>
      <pubDate>Fri, 17 Jan 2025 14:32:34 GMT</pubDate>
    </item>
    <item>
      <title>针对 2 个以上类别的卡方检验（2x5 列联表）</title>
      <link>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</link>
      <description><![CDATA[我有一个 2x5 的频率表，其中有 2 列分别名为男性和女性，5 行分别名为病理 A、B、C、D 和 E。
我想确定不同病理类别的性别比例在统计上是否存在差异。
例如：男性是否比女性更频繁地受到病理 A 的影响（每个类别都是如此）？
我是否可以将其他类别（例如 B + C + D + E）相加以创建新的 2x2 列联表并对其进行卡方检验？
这在统计上正确吗？如果我的 p 值小于 0.05，我可以得出的结论是：男性比女性更频繁地受到病理 A 的影响？
问题是，如果我对所有数据计算一次卡方检验，我只能对情况有一个整体了解。]]></description>
      <guid>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</guid>
      <pubDate>Fri, 17 Jan 2025 12:27:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Mercer 定理总是被引用于核学习而不是 Moore-Aronszajn</title>
      <link>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</link>
      <description><![CDATA[为什么在大多数关于核技巧的解释中，Mercer 定理都用作依据？
我们能否用 Moore-Aronszajn 来证明这一点，该定理不将紧致性假设置于 $X$ 和 $k$ 连续性上？
编辑：
那么，核技巧背后的想法是，我们能够计算某个希尔伯特空间 $H$ 中的内积，而不必将数据嵌入该空间，因为 $k(x,x&#39;) = \langle \phi(x), \phi(x&#39;) \rangle_{H}$，对于某个 $\phi : X \mapsto H$
现在，经常引用 mercer 定理来证明这样的 $\phi$ 存在。然而，通过 Moore-Aronszajn 定理，我们知道对于 p.d. 核 $k$，特征图 $\phi_{H_k}: X \mapsto H_k = \mathbb{R}^X$，其中 $\phi_{H_k}(x) = k(x,\cdot)$ 满足 $k(x,x&#39;) = \langle \phi(x)_{H_k}, \phi_{H_k}(x&#39;) \rangle_{H_k}$。那么，为什么 Mercer 经常被引用呢？此外，有些 p.d. 核不是连续的，因此无法通过 Mercer 定理进行论证。]]></description>
      <guid>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</guid>
      <pubDate>Fri, 17 Jan 2025 11:39:14 GMT</pubDate>
    </item>
    <item>
      <title>变换与顺序有关的分布</title>
      <link>https://stats.stackexchange.com/questions/660157/transforming-a-distribution-where-the-order-matters</link>
      <description><![CDATA[我有一组 $E = \{X_{ij}\}$，其中 $1 \leq i &lt; j \leq n$，s.t. $|E| = \binom{n}{2}$。$X_{ij}$ 在 $\sim [0,1]$ 内都是独立同分布的。这些是完全加权图的边。
假设我选择一个顶点$z$并根据此处中描述的规则将其与相关边一起移除，从而获得一个较小的$E&#39;$。为了提供更多背景信息，我删除了 $n-1$ 条边，其中 2 条边取决于图的其余部分（删除顶点 $p$ 和 $q$ 的最小值和最大值 此处 会更改这两个顶点的新的最小值和最大值）。因此，$E&#39;$ 取决于所选的顶点，并且分布会因此而改变。
由于我有兴趣保留这些值的顺序（该属性在后续步骤中保持其顺序是充分且必要的），我可以放宽这种依赖关系并使用此处描述的参数对剩余值应用非线性单调变换，并得出结论 $E&#39;$ 仍将呈均匀分布吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660157/transforming-a-distribution-where-the-order-matters</guid>
      <pubDate>Fri, 17 Jan 2025 11:37:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 calc 查找 emmeans 中的样本大小，调用准二项式会产生奇怪的结果</title>
      <link>https://stats.stackexchange.com/questions/660156/using-calc-to-find-sample-size-in-emmeans-call-for-quasibinomial-yields-strange</link>
      <description><![CDATA[我在一项实验研究中运行了一个具有准二项式系列的 glm，该研究的因子有 4 个水平、2 个协变量和一个二项分布的响应（10 个正确/错误响应的总和）：
调用：
glm(formula = cbind(PT1SVAAll, 10 - PT1SVAAll) ~ CFGroup + PreSVAAll + 
FBPrePT1SVA, family = quasibinomial(link = &quot;logit&quot;), data = TestResultsAllreorderedPretestDoneFB)
系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) -2.77546 0.58445 -4.749 5.10e-05 ***
CFGroupDA 0.81332 0.53051 1.533 0.136 
CFGroupM -0.37421 0.59334 -0.631 0.533 
CFGroupR 0.57151 0.57806 0.989 0.331 
PreSVAAll 0.70464 0.14138 4.984 2.65e-05 ***
FBPrePT1SVA 0.02369 0.05326 0.445 0.660 
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（准二项式系列的分散参数取为 2.031543）

零偏差：34 个自由度上的 150.183

残差偏差：29 个自由度上的 68.354
（由于缺失，删除了 9 个观测值）
AIC：NA
Fisher 评分迭代次数：4
由此我假设 n=35（零偏差的 df+1）。我尝试使用 calc 语法查找因子 (CFGroup) 每个级别的样本大小，但得到了奇怪的结果：
emmeans(mod.PT1multfactors, &quot;CFGroup&quot;, infer = c(TRUE, TRUE), type=&quot;response&quot;,
+ calc = c(n = &quot;.wgt.&quot;))
CFGroup prob SE df n asymp.LCL asymp.UCL null z.ratio p.value
C 0.209 0.0645 Inf 90 0.1091 0.362 0.5 -3.415 0.0006
DA 0.373 0.0817 Inf 90 0.2305 0.541 0.5 -1.490 0.1363
M 0.153 0.0637 Inf 80 0.0648 0.321 0.5 -3.485 0.0005
R 0.318 0.0898 Inf 90 0.1717 0.512 0.5 -1.842 0.0655

使用的置信度：0.95

区间是从 logit 尺度反向转换而来的

测试是在 logit 尺度上执行的

出于某种原因，calc 似乎可能会将每个级别的 n 乘以权重 10（总共 10 个响应），使得 C、DA 和 R 的每个级别的 n 为 9，M 的每个级别的 n 为 8。但加起来是 36，而不是我上面从模型的零偏差假设的样本大小 35。
有人能解释一下这里发生了什么吗？我如何才能找到每个级别的准确样本量？]]></description>
      <guid>https://stats.stackexchange.com/questions/660156/using-calc-to-find-sample-size-in-emmeans-call-for-quasibinomial-yields-strange</guid>
      <pubDate>Fri, 17 Jan 2025 10:57:04 GMT</pubDate>
    </item>
    <item>
      <title>日食是否减少了新冠肺炎死亡人数？</title>
      <link>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</link>
      <description><![CDATA[我在 R 中模拟了一些现实数据，这些数据显示了 Covid-19 死亡人数随时间的变化情况，以及日食（2024 年 4 月 8 日）发生前的天数：

如果有人不太了解，仅从数据来看，可能会认为日食是降低 Covid 死亡人数的原因。此外，有人可以拟合回归模型，该模型甚至可能很好地拟合数据。
我读到过，我们在统计学中拥有所有这些复杂的技术，例如差异-差异、回归不连续性、合成控制、工具变量、倾向得分匹配等 - 所有这些方法旨在在某种程度上找出我们是否能够真正得出结论，统计模型的结果忠实地代表了自然（例如因果关系与联想关系）。
但在某种程度上，我们在决定将哪些变量纳入统计模型时是否只是使用常识？]]></description>
      <guid>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</guid>
      <pubDate>Fri, 17 Jan 2025 05:13:01 GMT</pubDate>
    </item>
    <item>
      <title>在 Anderson-Gill 模型中，tstart 和 tstop 可以相同吗？</title>
      <link>https://stats.stackexchange.com/questions/660134/can-tstart-and-tstop-be-the-same-in-an-anderson-gill-model</link>
      <description><![CDATA[我正在处理事件发生时间数据，并使用 R 中生存包的 coxph() 函数中实现的 Anderson-Gill 模型。在此模型中，时间间隔由 tstart（开始时间）和 tstop（停止时间）定义，我需要了解如何处理 tstart == tstop 的间隔。
具体来说，我想知道：
在 Anderson-Gill 模型中，tstart 和 tstop 相同是否有效？
如果不是，零长度间隔的含义是什么，应该如何处理？
例如，考虑以下数据集：



id
tstart
tstop
event




1
0
10
0


1
10
10
1


2
5
5
1



当我尝试使用 coxph(Surv(tstart, tstop, event) ~ 1, data = my_data)，我收到有关 tstart == tstop 的警告。我理解零长度间隔并不代表有意义的风险时间，但我想确认解决这种情况的最佳方法。
我应该如何处理这些情况？我应该：排除 tstart == tstop 的行？为 tstop 添加一个小值（例如，tstop = tstart + 1e-5）？还有其他推荐的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660134/can-tstart-and-tstop-be-the-same-in-an-anderson-gill-model</guid>
      <pubDate>Thu, 16 Jan 2025 23:19:41 GMT</pubDate>
    </item>
    <item>
      <title>如果需要真实参数的值来确定统计数据是否无偏，那么无偏估计量的意义何在？</title>
      <link>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</link>
      <description><![CDATA[我对无偏估计量的定义是：“如果用于估计参数的统计数据的抽样分布的平均值等于被估计参数的值，则该统计数据是无偏估计量。”
我知道如何确定统计数据是否是无偏估计量，因为我能够基于此解决应用题，但我不明白我们为什么要使用无偏估计量。我的笔记说，您需要使用无偏估计量，以便您的估计更准确。这对我来说很有意义，但为了确定统计数据是否是无偏估计量，您需要知道参数的值，以便将其与抽样分布的平均值进行比较，看看它们是否相等。如果使用无偏估计量来估计参数的值，如果我们已经知道参数的值，使用它有什么意义呢？
我一直在为此绞尽脑汁，但无济于事，如能得到任何帮助我将不胜感激，谢谢。
（我不擅长措辞，如果我听起来很重复或没有意义，请原谅）]]></description>
      <guid>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</guid>
      <pubDate>Thu, 16 Jan 2025 15:06:38 GMT</pubDate>
    </item>
    </channel>
</rss>