<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Dec 2024 09:20:00 GMT</lastBuildDate>
    <item>
      <title>如何进行时间序列预测</title>
      <link>https://stats.stackexchange.com/questions/658251/how-to-approach-time-series-forecasting</link>
      <description><![CDATA[我正在研究一个涉及高频数据（每小时或每 10-15 分钟）的时间序列预测问题，例如能耗或其他 IoT 设备指标。我的目标是预测第二天（或可能更短的时间范围，取决于可行性）的能耗。
过去，我曾使用 LSTM 神经网络解决过类似的问题，但这次，我想采用更系统的方法。我的目标是尝试不同的模型，以确定最适合我的用例的模型。
目前，我有几个月的数据。我正在考虑是否使用此数据集来测试模型，或者使用 Kaggle 中涵盖数年的类似数据集。由于我要预测的数据表现出很高的季节性，因此拥有更多数据似乎很有益。我检查了 ADF 测试和 ACF 图，发现数据是平稳的，并且具有很强的季节性。
我拥有的数据集包括以下变量：

时间戳
能源消耗
其他一些与电力相关的变量

由于数据的季节性很强，我正在考虑添加诸如一年中的某天、一天中的某小时和一周中的某天等特征。我的探索性数据分析表明，这些特征会显著影响数据，尤其是一天中的某小时。添加这些特征会将问题从单变量预测转变为多变量预测，这可能会影响模型的选择。我目前正在考虑的模型是 XGBoost 或深度学习模型。
最后，我正在考虑如何在生产中维护模型。在训练和部署模型后，是否应该定期使用新数据对其进行重新训练以纳入更多背景信息？如果是，建议的再培训频率是多少？
我明白，这些问题中的一些可能不是针对每个用例都有明确的答案，但我非常感激任何建议。如果您有可以提供帮助的参考资料或资源，我很乐意探索它们。]]></description>
      <guid>https://stats.stackexchange.com/questions/658251/how-to-approach-time-series-forecasting</guid>
      <pubDate>Wed, 04 Dec 2024 07:10:12 GMT</pubDate>
    </item>
    <item>
      <title>在因子分析中，删除唯一性较低的变量后的新模型对原始模型有何影响？</title>
      <link>https://stats.stackexchange.com/questions/658250/in-factor-analysis-what-does-the-new-model-with-a-variable-with-low-uniqueness</link>
      <description><![CDATA[我正在使用 R 中的 factanal 进行因子分析模型：
$$X=Lf+\mathcal E. $$
当将因子设置为相对较大时，
我收到一个错误，即变量的唯一性（即 $E(\epsilon_i^2)$ 的估计值）接近于零。
虽然我可以通过设置非常小的lower值来解决这个问题，但是这篇文章说这会导致问题。
按照这篇文章的建议，我尝试删除唯一性较低的变量$Y_i$，然后模型就可以正常工作了。
但是，我想问一下，删除$Y_i$后的新模型对原始模型意味着什么？
例如，如果在新模型中，$p$ 个因素拟合良好，我们能否断言在原始模型中$p+1$ 个因素拟合良好？]]></description>
      <guid>https://stats.stackexchange.com/questions/658250/in-factor-analysis-what-does-the-new-model-with-a-variable-with-low-uniqueness</guid>
      <pubDate>Wed, 04 Dec 2024 05:51:04 GMT</pubDate>
    </item>
    <item>
      <title>我可以在使用组学数据的两阶段研究的两个阶段中使用 FDR 进行多重校正吗？</title>
      <link>https://stats.stackexchange.com/questions/658248/can-i-use-fdr-for-multiple-correction-in-both-stages-of-a-two-stage-study-using</link>
      <description><![CDATA[请问我是否可以在使用组学数据的两阶段研究的两个阶段中使用 FDR 进行多重校正。例如，基于 RNA-seq 数据，我想识别 20 名患者和 20 名健康受试者之间基因表达差异的基因。我正在考虑一个两阶段的研究设计。首先，作为发现阶段，对 10,000 个基因进行学生 t 检验（我知道可以使用 edgeR 或其他分析方法，但由于这个问题是关于多重比较的，我将使用 t 检验）。获得的 P 值会根据错误发现率 (FDR) 进行校正，q 值 &lt; 0.05 被认为是显著的。结果，50 个基因显示出显著差异。作为下一个阶段，我在与 RNA-seq 测量的样本不同的样本中验证这 50 个基因。另外 20 名患者和 20 名健康受试者通过 RNA-seq 以外的方法进行测量，并再次通过 t 检验进行比较。因此，测试了 50 次（50 个基因），所以我必须进行多次校正。我可以在这里再次调整 FDR 并假设 q 值 &lt; 0.05 是显著的吗？或者我应该在此阶段对 Bonferro 应用校正并将显著性水平设置为 P 值 &lt; 0.05/50（=0.001）？如果您能启发我，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658248/can-i-use-fdr-for-multiple-correction-in-both-stages-of-a-two-stage-study-using</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:39 GMT</pubDate>
    </item>
    <item>
      <title>XGboost 分类特征影响预测的顺序</title>
      <link>https://stats.stackexchange.com/questions/658246/xgboost-classification-order-of-features-influencing-predictions</link>
      <description><![CDATA[我正在使用 xgboost 分类创建一个 UFC 比赛预测模型，该模型在包含 2 名战士的统计数据和比赛结果的数据集上进行训练。在训练模型后，我定义了一个函数，我只需输入战士姓名，它就会从战士统计数据数据集中获取他们的统计数据，并将其输入到模型中以预测谁将获胜。但是，当尝试进行新的预测时（例如：xgb_ufc(&quot;Vicente Luque&quot;, &quot;Themba Gorimbo&quot;) 和 xgb_ufc(&quot;Themba Gorimbo&quot;, &quot;Vicente Luque&quot;)），预测结果不同（在这两种情况下，第一个战士都被选为&quot;获胜&quot;））。我尝试过减少过度拟合的方法，但似乎输入比赛统计数据/特征的顺序仍然会影响预测。有人知道这是为什么以及如何解决它吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658246/xgboost-classification-order-of-features-influencing-predictions</guid>
      <pubDate>Wed, 04 Dec 2024 04:06:09 GMT</pubDate>
    </item>
    <item>
      <title>查找随机过程的方差</title>
      <link>https://stats.stackexchange.com/questions/658243/finding-the-variance-of-a-stochastic-process</link>
      <description><![CDATA[这是该问题的第二部分计算随机过程的均值和方差？
对于 Polya Urn 问题，我试图理解为什么方差的比率是：
$$\operatorname{Var}(X_n) = E[X_n](1-E[X_n]) \left(\frac{d}{w+b+d} - \frac{w+b}{w+b+d}\frac{1}{n}\right).$$
我知道一般方差公式是$E[X_n^2] - (E[X_n])^2$ 并且 $E[X_n] = \frac{w}{w+b}$。我只需要找到 $E[X_n^2]$。
当我们有 $n$ 个球时，如果我们抽出一个白球（概率 $X_{n-1}$），我们会添加 $d$ 个白球。如果我们抽到黑球（概率为$1-X_{n-1}$），我们添加$d$个黑球（$k$是前面步骤中添加的白球数量）。
$$ X_n = \begin{cases}
\frac{w + (k+1)d}{w+b+nd} &amp; \text{如果抽到白球} \\
\frac{w + kd}{w+b+nd} &amp; \text{如果抽出黑球}
\end{cases} $$
使用二阶总期望定律：
$$ E[X_n^2|X_{n-1}] = X_{n-1}\left(\frac{w + (k+1)d}{w+b+nd}\right)^2 + (1-X_{n-1})\left(\frac{w + kd}{w+b+nd}\right)^2 $$
通过扩展和替换：
$$ \left(\frac{w + (k+1)d}{w+b+nd}\right)^2 = \frac{w^2 + 2w(k+1)d + ((k+1)d)^2}{(w+b+nd)^2} $$
$$ \left(\frac{w + kd}{w+b+nd}\right)^2 = \frac{w^2 + 2wkd + (kd)^2}{(w+b+nd)^2} $$
$$ E[X_n^2|X_{n-1}] = X_{n-1}\frac{w^2 + 2w(k+1)d + ((k+1)d)^2}{(w+b+nd)^2} + (1-X_{n-1})\frac{w^2 + 2wkd + (kd)^2}{(w+b+nd)^2} $$
我尝试扩展再次：
$$ \begin{align*}
E[X_n^2|X_{n-1}] &amp;= \frac{X_{n-1}(w^2 + 2w(k+1)d + ((k+1)d)^2)}{(w+b+nd)^2} + \frac{(1-X_{n-1})(w^2 + 2wkd + (kd)^2)}{(w+b+nd)^2} \\
&amp;= \frac{w^2 + 2wkd + (kd)^2}{(w+b+nd)^2} + X_{n-1}\frac{2wd + 2d^2(k+1)}{(w+b+nd)^2}
\end{align*} $$
我知道我需要再次计算期望，这样 $E(E[X_n^2|X_{n-1}]) = E[X_n^2]$
但这就是我陷入困境的地方，不知道如何继续。我感觉自己在兜圈子。有什么想法可以继续吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658243/finding-the-variance-of-a-stochastic-process</guid>
      <pubDate>Wed, 04 Dec 2024 02:04:46 GMT</pubDate>
    </item>
    <item>
      <title>当系数 < 1 时，解释对数转换结果回归中的指数系数</title>
      <link>https://stats.stackexchange.com/questions/658242/interpreting-an-exponentiated-coefficient-from-a-regression-of-a-log-transformed</link>
      <description><![CDATA[网上有很多资料（请参阅此处和此处），关于对结果进行对数变换时该做什么（指数回归系数）以及如何解释系数（1-系数*100 = 预测变量一个单位变化的百分比变化/差异）。
我无法找到如何解释小于 1 的系数。如果它是来自二项回归指数对数几率系数例如 0.57 表示 (1-0.57)/0.57 = 0.75 = 预测变量每增加 1 个单位，结果几率就会降低 75%。
我的问题是 我能否以同样的方式解释对数转换结果的回归系数？ 0.57 的系数是否也表示预测变量水平下降 75%。]]></description>
      <guid>https://stats.stackexchange.com/questions/658242/interpreting-an-exponentiated-coefficient-from-a-regression-of-a-log-transformed</guid>
      <pubDate>Wed, 04 Dec 2024 01:59:24 GMT</pubDate>
    </item>
    <item>
      <title>三个相关伯努利随机变量之和的分布，所有变量均具有相同的相关性</title>
      <link>https://stats.stackexchange.com/questions/658241/the-distribution-of-the-sum-of-three-dependent-bernoulli-random-variables-all-w</link>
      <description><![CDATA[$\mathbb{P}(X+Y+Z=z)=\text{?}$
$X,Y,Z\sim \text{Bernoulli}(p)$，并且 $\text{Cor}(X,Y)=\text{Cor}(X,Z)=\text{Cor}(Y,Z)=\rho~, 0&lt;\rho&lt;1$。]]></description>
      <guid>https://stats.stackexchange.com/questions/658241/the-distribution-of-the-sum-of-three-dependent-bernoulli-random-variables-all-w</guid>
      <pubDate>Wed, 04 Dec 2024 01:41:00 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制 sem() 的结果？</title>
      <link>https://stats.stackexchange.com/questions/658240/how-to-plot-results-from-sem</link>
      <description><![CDATA[我使用 lavaan 包中的 sem() 函数建立了以下 SEM 模型。
这是我的 SEM 代码：
sem.model &lt;- &#39;
#潜在变量
latent_edu =~ 教育

#观察变量
latent_edu ~ Sexuality_Straight + Racialized_Minority + Age.in.years + Gender_Women + Gender_Minority

Recruit_Online ~ latent_edu + Age.in.years + Sexuality_Straight + Income

Income ~ Gender_Women + Gender_Minority + Sexuality_Straight + Age.in.years + Racialized_Minority

Aware_Yes ~ Age.in.years + Recruit_Online + Sexuality_Straight + Racialized_Minority

Test_Yes ~ Age.in.years + Recruit_Online + Sexuality_Straight + Racialized_Minority

#Covariances
Gender_Women ~~ Sexuality_Straight
Gender_Minority ~~ Sexuality_Straight
Sexuality_Straight ~~ Racialized_Minority

&#39;
fit &lt;- sem(sem.model, data = imputed_data, ordered = c(&quot;Education&quot;, &quot;Income&quot;))
summary(fit)

当我尝试使用 semPaths() 函数绘制上述方程时，出现以下错误：
&gt; semPlot::semPaths(fit, what = &quot;path&quot;, layout = &quot;tree&quot;)
dimnames(x) 中的错误 &lt;- dn: 
&#39;dimnames&#39; [2] 的长度不等于数组范围

这是我的数据结构：
 $ Income : num 5 5 2 1 2 5 4 1 2 5 ...
$ Age.in.years : int 43 39 27 30 24 25 28 34 28 38 ...
$ Education : num 3 3 3 2 3 3 3 2 2 3 ...
$ Racialized_Minority : num 0 0 1 0 0 0 1 0 0 1 ...
$ White : num 1 1 0 1 1 1 0 1 1 0 ...
$ Recruit_Online ：数量 0 0 0 0 0 0 0 0 0 0 ...
$ Recruit_InPersonPaper ：数量 1 1 1 1 1 1 1 1 1 1 ...
$ Gender_Men ：数量 1 0 0 0 1 0 0 0 0 0 ...
$ Gender_Women ：数量 0 1 1 1 0 1 1 0 0 1 ...
$ Gender_Minority ：数量 0 0 0 0 0 0 0 1 1 0 ...
$ Sexuality_Straight ：数量 1 0 1 0 0 0 1 0 0 1 ...
$ Sexuality_Minority ：数量 0 1 0 1 1 1 0 1 1 0 ...
$ Aware_Yes : num 0 0 1 0 1 0 0 1 1 1 ...
$ Aware_No : num 1 1 0 1 0 1 1 0 0 0 ...
$ Test_Yes : num 0 0 0 0 0 0 0 1 1 0 ...
$ Test_No : num 1 1 1 1 1 1 1 1 0 0 1 ...

我不知道是什么原因导致了这个错误，我正在寻找导致它发生的指导。 sem() 工作正常，并且计算系数没有错误，所以当 semPaths() 抛出这个错误时，我不知道为什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/658240/how-to-plot-results-from-sem</guid>
      <pubDate>Wed, 04 Dec 2024 00:21:07 GMT</pubDate>
    </item>
    <item>
      <title>UMAP、t-SNE 或 PCA 我该选择哪一个？</title>
      <link>https://stats.stackexchange.com/questions/658239/umap-t-sne-or-pca-which-do-i-choose</link>
      <description><![CDATA[我有从健康和患病植物样本（包括玉米、水稻和小麦）中获得的约 64 个基因（列）的微阵列数据。对于某些基因，数据分布在样本之间有所不同，要么呈正态分布（例如，健康玉米中的基因 1），要么呈非正态分布（例如，患病玉米中的基因 1）。哪种降维算法最适合识别区分植物的基因？PCA、UMAP 还是 t-SNE？我知道 PCA 适用于正态分布，而 t-SNE 可以处理非参数数据，但如果是混合数据，t-SNE 可以应用吗？UMAP 呢？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658239/umap-t-sne-or-pca-which-do-i-choose</guid>
      <pubDate>Wed, 04 Dec 2024 00:04:53 GMT</pubDate>
    </item>
    <item>
      <title>探索逻辑回归中的所有选项</title>
      <link>https://stats.stackexchange.com/questions/658233/exploring-all-options-in-a-logistic-regression</link>
      <description><![CDATA[这组代码相当简单，使用了在线教程中的一些示例
# 导入并重命名数据集
library(kmed)
dat &lt;- heart
library(dplyr)

# 重命名变量
dat &lt;- dat |&gt;
重命名（
胸痛 = cp，
最大心率 = thalach，
心脏病 = 类
）

# 重新编码性别
dat$sex &lt;- factor(dat$sex，
levels = c(FALSE, TRUE)，
labels = c(&quot;female&quot;, &quot;male&quot;)
)

# 重新编码胸痛
dat$chest_pain &lt;- factor(dat$chest_pain，
levels = 1:4，
labels = c(&quot;典型心绞痛&quot;, &quot;非典型心绞痛&quot;, &quot;非心绞痛&quot;, &quot;无症状&quot;)
)

# 将心脏病重新编码为 2 个类别
dat$heart_disease &lt;- ifelse(dat$heart_disease == 0,
0,
1
)

m3 &lt;- glm(heart_disease ~ .,
data = dat,
family = &quot;binomial&quot;
)

# 打印结果
summary(m3)

但是，如果我想自动运行 dat 中所有列的预测变量，或者自动寻找最高的 AIC 模型，我应该用什么呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/658233/exploring-all-options-in-a-logistic-regression</guid>
      <pubDate>Tue, 03 Dec 2024 21:08:08 GMT</pubDate>
    </item>
    <item>
      <title>解释 A/B 测试结果中的 p 值</title>
      <link>https://stats.stackexchange.com/questions/658204/interpret-p-value-in-a-b-test-results</link>
      <description><![CDATA[我需要解释 A/B 测试结果。因此，我有一个名为 Baseline 的控制队列，还有另外两个名为 NewFTUE 和 AppReopenFS 的队列。
此 AB 测试数据的最大问题是 NewFTUE 的 p 值几乎等于 1，而 AppReopenFS 的 P 值要低得多。
我无法理解两件事：

据我所知，如果平均差异较大且
标准差较小，则 p 值应该变得更小，即零假设应该更容易被拒绝。但我们可以
在这里看到，对于较大的标准差和较小的均值差，p 值要小得多（0.187 vs 0.991）
第二件我无法理解的事情是 95% CI（正如仪表板上所解释的那样，这是“95% 可能包含均值真实差异的值范围”。）。因此，正如您所看到的，对于 NewFTUE，均值差异的置信区间完全位于 0 的左侧。即我们有 95% 的信心，无论我们采用什么样本（对于相同的样本量），与 Baseline 相比，我们都会得到更差的结果。

那么为什么 NewFTUE 的 p 值为 0.991 并且大于 AppReopenFS 的 0.187 值？

编辑：添加以下 p 值的描述：和 这里是文档页面。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658204/interpret-p-value-in-a-b-test-results</guid>
      <pubDate>Tue, 03 Dec 2024 13:44:27 GMT</pubDate>
    </item>
    <item>
      <title>如何处理 1-5 星评级中的偏见？</title>
      <link>https://stats.stackexchange.com/questions/658166/how-to-handle-bias-in-1-5-star-ratings</link>
      <description><![CDATA[我和一位朋友讨论了我在一家健康保险公司的不愉快经历，为了支持我的印象，我向她指出 trustpilot 给它的分数很低。
有 70 条评论，分布如下：{1：61、2：3、3：0、4：1、5：5}（星级：投票数）。
她的回答是：“哦，但是只有 70 条评论，所以它不算数”。
我最初的想法是 70 不是一个很小的数字；从多项分布来看，如果人们实际上总体上对这家保险公司感到满意，那么随机获得如此负面结果的可能性就很小。
经过进一步思考，我发现问题可能不在于评论的数量，而在于数据收集过程中可能存在的偏见。
由于这不是真正随机选择的调查结果，而是自发报告的结果，数据是否真的代表了整体客户群体？
例如，对保险公司更满意的人是否不太可能留下评论，反之亦然，不太满意的人是否更有可能报告他们的不满？
假设是这样，是否有任何已知的方法或途径可以减少这种偏见？
例如能否根据某种概率分布对评论进行加权？
下面是更多信息，仅用于说明我的进一步研究和思考过程。
我看到了一些关于贝叶斯平均值估计的帖子，例如这个，事实上，根据上述数据得出的 trustpilot 平均评分并不是通过简单的算术平均值得到的。
但是，我不确定这是否解决了我在这里讨论的偏见问题，因为它似乎更侧重于比较具有相同纯算术平均值但基于不同评论总数的评分对。从这个意义上讲，我当然不得不同意有必要进行纠正。但它是否解决了数据收集部分？
我正在讨论的保险公司示例的平均分数（不考虑贝叶斯校正或 trustpilot 所做的任何其他校正）是：
$$\frac {\sum_{n=1}^5 {votes(n) \cdot n}} {\sum_{n=1}^5 {votes(n)}} = \frac {61 \cdot 1+3 \cdot 2+ 0 \cdot 3 + 1 \cdot 4+5 \cdot 5} {70} = \frac {48} {25} \approx 1.37$$
我猜测偏差校正可能看起来像一个非常简单的例子：假设我们知道对保险公司的看法为“n 星”的人写评论的概率与 $\frac 1 n$ 成比例。
那么 $PMF(n)$ 将是 $\frac 1 n \cdot \frac {60} {137}$。
这意味着如果 $x(n)$ 人投了 $n$ 颗星，那么实际考虑该评分的人数将成比例增加 $\frac 1 {PMF(n)}$。 （顺便说一句，这是我边写边编的，如果我错了，请纠正我：这篇文章的目的是就此事征求建议）。
如果我没有记错的话，根据这个逻辑修正后的平均值将是：
$$\frac {\sum_{n=1}^5 {votes(n) \cdot n \cdot \frac 1 {PMF(n)}}} {\sum_{n=1}^5 {votes(n) \cdot \frac 1 {PMF(n)}}} = \frac {\sum_{n=1}^5 {votes(n) \cdot n^2}} {\sum_{n=1}^5 {votes(n) \cdot n }} = \frac {61 \cdot 1^2 + 3 \cdot 2^2 + 0 \cdot 3^2 + 1 \cdot 4^2 + 5 \cdot 5^2} {61 \cdot 1+3 \cdot 2+ 0 \cdot 3 + 1 \cdot 4+5 \cdot 5} = \frac {103} {48} \approx 2.14$$
我的看法是：由于对保险公司满意度较高的人不太可能撰写评论和投票，因此这种方法会给他们的投票赋予更大的权重，以更好地接近如果有可能从所有人那里获得投票，则会获得的平均水平。
这有意义吗？
根据上述问题，是否有任何旨在减少自发报告与设计民意调查可能导致的偏差的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/658166/how-to-handle-bias-in-1-5-star-ratings</guid>
      <pubDate>Mon, 02 Dec 2024 19:29:10 GMT</pubDate>
    </item>
    <item>
      <title>已知 Copula 函数的随机变量和的最优覆盖集</title>
      <link>https://stats.stackexchange.com/questions/658123/optimal-coverage-sets-of-a-sum-of-random-variables-with-known-copula</link>
      <description><![CDATA[设$X, Y$为已知系动词$C$的连续随机变量。让我们访问集合（区间）$S_x(\alpha),S_y(\alpha), \alpha\in(0,1)$，使得$$P(X\in S_x(\alpha))\geq \alpha,$$ $$P(Y\in S_y(\alpha))\geq \alpha$$
对于任何$\alpha$。
如果有帮助，我们可以假设集合是对称的，即$$P(X &gt; \sup S_x(\alpha))&lt; 1-\alpha/2,$$
$$P(X &lt; \inf S_x(\alpha))&lt; 1-\alpha/2.$$
我想找到一个（至少是一个很好的近似值）最短可能集 $S$，使得 $$P(X+Y\in S)\geq 0.9.$$
您知道如何做到这一点吗（至少对于一些非平凡的 copula 示例）？一个基本的猜测是 $S=S_x(0.95) + S_y(0.95)$，其中我使用符号 $A+B = \{a+b: a\in A, b\in B\}$ 表示两个集合 $A,B$。但是，显然，当且仅当 $X=-Y$ 时，这才是最优集合。
此外，我觉得应该存在某种理论将集合 $S$ 描述为 copula 和边际分布 $F_X, F_Y$ 的函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/658123/optimal-coverage-sets-of-a-sum-of-random-variables-with-known-copula</guid>
      <pubDate>Mon, 02 Dec 2024 06:31:31 GMT</pubDate>
    </item>
    <item>
      <title>如何最好地预测显示水平变化和方波类型噪声行为的时间序列</title>
      <link>https://stats.stackexchange.com/questions/658059/how-to-best-forecast-a-time-series-showing-level-changes-and-square-wave-kind-of</link>
      <description><![CDATA[这是 2019 年 3 月至 12 月每隔 1 分钟测量一次的交流电力数据。我想对时间序列进行建模，但样本外预测基本上是恒定的。我从 EDA 中发现了以下内容：

每个工作日的上午 8 点到下午 5 点功率较高，其余时间功率较低。
周六和周日功率较低，其他日子功率较高。

因此，似乎在小时级别和天级别存在季节性。
数据图及其季节性分解如下所示，

我尝试使用带有 exog 变量的 ARIMA 作为一天中的小时和一周中的天，以及带有季节性周期的 SARIMA。由于数据量太大，我暂时无法得到结果。
寻找一些关于如何解决这个问题的指示。
如果我想预测分钟级数据，我是否仍需要平滑数据。在我看来，ARIMA/SARIMA 不起作用，基于 ML 的方法可能更适合。
ARIMA 模型非常适合输入样本，但输出样本只是一个常数值，根本没有跟踪模式。
我是时间序列的新手，很乐意根据需要提供其他信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/658059/how-to-best-forecast-a-time-series-showing-level-changes-and-square-wave-kind-of</guid>
      <pubDate>Sat, 30 Nov 2024 07:05:56 GMT</pubDate>
    </item>
    <item>
      <title>倾向得分匹配：如何决定优先考虑平衡还是样本量</title>
      <link>https://stats.stackexchange.com/questions/657980/propensity-score-matching-how-to-decide-if-prioritise-balance-or-sample-size</link>
      <description><![CDATA[我尝试使用 MatchThem 包以不同的方法（最近或无放回法、最优法、完全法、遗传法）在两组之间执行 PSM。最终，我确定了两个表现良好的模型：一个模型中所有变量都是平衡的，但排除了一些情况；另一个（完整模型）中一个变量略微不平衡，但所有情况都保留。
NEAREST LOGIT
# 在每个插补数据集中执行匹配
m.out_model1 &lt;- matchthem(formula, 
data = new_df_imputed, 
method = &quot;nearest&quot;, 
distance = &quot;logit&quot;,
replace = TRUE,
ratio = 3,
caliper = 0.2)

输出：
所有插补的平衡摘要
Type Max.Diff.Adj M.Threshold
distance Distance 0.0130 Balanced, &lt;0.1
Metastasis_size_at_treatment_mm Contin. 0.0136 平衡，&lt;0.1
Segments_treated_per_session 持续。 0.0336 平衡，&lt;0.1
Metastasis_location_superficial_Yes 二进制 0.0089 平衡，&lt;0.1

平衡平均差异计数
count
平衡，&lt;0.1 4
不平衡，&gt;0.1 0

具有最大平均差异的变量
Variable Max.Diff.Adj M.Threshold
Segments_treated_per_session 0.0336 平衡，&lt;0.1

插补的平均样本大小
0 1
全部 53. 77
匹配（ESS） 26.96 75
匹配（未加权） 45. 75
不匹配 8. 2

完整方法
m.out_full &lt;- matchthem(formula,
data = new_df_imputed,
method = &quot;full&quot;,
distance = &quot;mahalanobis&quot;)

输出：
所有插补的平衡摘要
类型 Max.Diff.Adj M.Threshold
Metastasis_size_at_treatment_mm Contin. 0.0477 平衡，&lt;0.1
Segments_treated_per_session Contin. 0.1179 不平衡，&gt;0.1
Metastasis_location_superficial_Yes 二进制 0.0260 平衡，&lt;0.1

平衡平均差异计数
count
平衡，&lt;0.1 2
不平衡，&gt;0.1 1

具有最大平均差异的变量
Variable Max.Diff.Adj M.Threshold
Segments_treated_per_session 0.1179 不平衡，&gt;0.1

插补的平均样本大小
0 1
全部 53. 77
匹配（ESS） 27.47 77
匹配（未加权） 53. 77

如果我使用第一个模型，我会失去能力（而且我的队列已经很小）。另一方面，选择第二个模型允许我保留整个人群，但这两个群体略微不平衡。但是，我可以通过多变量逻辑回归中包含不平衡变量来解释这一点。
我的问题是：有没有办法确定哪个模型是最佳选择？计算与每个匹配数据集相关的功效以评估使用哪个模型在方法论上是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/657980/propensity-score-matching-how-to-decide-if-prioritise-balance-or-sample-size</guid>
      <pubDate>Thu, 28 Nov 2024 13:21:04 GMT</pubDate>
    </item>
    </channel>
</rss>