<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 07 Aug 2024 01:08:09 GMT</lastBuildDate>
    <item>
      <title>2x2 列联表：z 或 t 检验（又名 $chi^2$ 或 F 检验）</title>
      <link>https://stats.stackexchange.com/questions/652412/2x2-contingency-table-z-or-t-test-aka-chi2-or-f-test</link>
      <description><![CDATA[这个问题是关于老式的 2x2 列联表。用于比较此类表格中的比例的一种非常常见的测试是 Pearson 的 $\chi^2$ 检验（例如 此处 或 此处）。现在，对于 2x2 表格，此测试“退化”为 比例 z 检验。因为对于 2x2 表，$\chi^2$ 有 1 个自由度 (d.f)，它只是 z 统计量的平方。$\chi^2$ 统计量将恰好是 z 统计量的平方，2 个 p 值将完全相同，等等。到目前为止，一切都很好，这些都是众所周知的；我只是在提出问题。
现在，我们知道 z 检验实际上只应在我们知道总体标准差时使用。而当我们不知道总体标准差时，我们应该使用 t 检验。但对于我们的 2x2 表情况，我们没有；我们只有一个观察到的估计值。我们甚至对标准差也有不同的估计（合并或非合并；但我们现在先不讨论这个问题）。
我对此进行了实验，结果通常在 z 和 t 之间非常接近，但我可以很容易地找到 2x2 表的例子，这些表对 z 很重要，但对 t 却不重要。
所以问题是；我们不应该使用 t 检验而不是 z 检验，也就是说，使用 F 检验而不是 $\chi^2$ 检验吗？（F 分布，分子上有 1 个自由度，分母上有 $n$ 自由度，是 t 分布的平方，其自由度为 $n$）。事实上，我们不应该使用 Welch t 检验（而不是 z 检验）来处理方差可能不同的情况吗？
我搜索了网络（和 C.V.），但没有找到任何提倡使用 t 检验的参考资料。那么，是否有理论原因不优先使用 t 检验来处理 2x2 列联表，还是这只是历史遗留问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/652412/2x2-contingency-table-z-or-t-test-aka-chi2-or-f-test</guid>
      <pubDate>Wed, 07 Aug 2024 00:59:52 GMT</pubDate>
    </item>
    <item>
      <title>随机向量中乘积变量的独立性</title>
      <link>https://stats.stackexchange.com/questions/652408/independence-of-product-variables-in-random-vectors</link>
      <description><![CDATA[考虑一个随机向量$U = (U_1,U_2)$，其中$U_1$和$U_2$是独立且同分布的。设$X =(X_1,X_2)$，其中$X_1$和$X_2$是相关随机变量。
假设$X = (X_1,X_2)$和$U = (U_1,U_2)$是独立的。定义 $Z_1 = X_1 U_1$ 和 $Z_2 = X_2 U_2$。当前的问题是确定变量 $Z_1$ 和 $Z_2$ 是否独立。
尝试：
为了调查 $Z_1$ 和 $Z_2$ 的独立性，我们需要分析它们的联合分布。令 $f_{Z_1,Z_2}(z_1,z_2)$ 表示 $Z_1$ 和 $Z_2$ 的联合分布。我们可以将此联合分布表示为：
$$f_{Z_1,Z_2}(z_1,z_2) = \int_{-\infty}^{\infty} f_{X_1,X_2}(z_1/u_1,z_2/u_2) \, f_{U_1,U_2}(u_1,u_2) \, du_1 \, du_2.$$
如果此表达式不能分解为 $Z_1$ 和 $Z_2$ 的边际分布的乘积，则 $Z_1$ 和 $Z_2$ 不是独立。
有反例吗？或者这是真的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652408/independence-of-product-variables-in-random-vectors</guid>
      <pubDate>Tue, 06 Aug 2024 23:18:05 GMT</pubDate>
    </item>
    <item>
      <title>在回归中添加交互作用：主效应与交互作用不显著</title>
      <link>https://stats.stackexchange.com/questions/652407/adding-interaction-to-regression-main-effect-and-interaction-non-significant</link>
      <description><![CDATA[我在我的数据集上使用了两个模型：
模型 1：临床评分 ~ X + Z：X 和 Z 都很重要。
模型 2：临床评分 ~ X + Z + X*Z：X 不再重要，交互作用也不重要，而 Z 仍然重要。
对于交互作用重要而 X 不再重要的情况，我会有更好的直觉，但这里可以解释什么？有没有办法以图形或其他方式探索这个问题？我附上了临床评分与 X 的散点图，Z 的高值和低值用不同的颜色表示（它是连续的，但我将其设为二分图），如果 X 不重要，我真的不明白 Z 怎么会在这里重要。
这两个模型中的 R 平方几乎相同，所以也许最好将交互作用排除在外，并进行直接解释。但是我担心这可能是 p-hacking，并且模型 2 中显著性的丧失意味着 X 的影响实际上并不存在。欢迎对这两点发表任何想法！
]]></description>
      <guid>https://stats.stackexchange.com/questions/652407/adding-interaction-to-regression-main-effect-and-interaction-non-significant</guid>
      <pubDate>Tue, 06 Aug 2024 22:12:56 GMT</pubDate>
    </item>
    <item>
      <title>对 $\beta$ 进行正向支持的先验正态线性回归</title>
      <link>https://stats.stackexchange.com/questions/652406/conjugate-prior-normal-linear-regression-with-positive-support-for-beta</link>
      <description><![CDATA[我有线性回归模型
$$y \sim N(X\beta, \sigma^2V); X = (\textbf{1}, \textbf{x}) \text{ and }\beta = (\beta_0, \beta_1), \quad \beta_1 &gt; 0$$
众所周知，当 $\beta_1$ 的支持为实数线时，$(\beta, \sigma^2)$ 上的共轭贝叶斯先验分布是正态逆$\chi^2$。我的问题是，在对 $\beta_1$ 支持的限制下，是否存在已知的参数共轭先验？也许是 $\beta_0$ 上的正态先验、$\beta_1$ 上的截断正态先验和 $\chi^2$ 上的逆$\sigma^2$？]]></description>
      <guid>https://stats.stackexchange.com/questions/652406/conjugate-prior-normal-linear-regression-with-positive-support-for-beta</guid>
      <pubDate>Tue, 06 Aug 2024 22:11:50 GMT</pubDate>
    </item>
    <item>
      <title>根据已发表的论文，R2_test>R2_train。这怎么可能始终如一呢？</title>
      <link>https://stats.stackexchange.com/questions/652404/r2-testr2-train-from-a-published-paper-how-can-it-be-consistently-possible</link>
      <description><![CDATA[
此图来自一篇论文，作者在一个小数据集（总共包含 117 个样本）上训练并测试了不同的模型。我有以下观察结果和他们的问题。 （他计算出 R2 = SSR/SST，尽管 Python 等几种编程语言计算出 R2 = 1- SSE/SST）

R2_test&gt;1&gt;&gt;R2_train：对于作者训练和测试的几个模型（&gt;90%），我发现了这种关系，其中测试集的 R2 超过 1，并且远远超过训练分割的 R2。如果对准确模型的要求是正确的，那么它如何证明 R2&gt;1（意味着 SSR&gt;SST）。此外，测试分割的 R2 得分如何始终优于训练分割？（这不可能是纯属巧合！还是与小数据集、数据泄漏有关的问题？）
]]></description>
      <guid>https://stats.stackexchange.com/questions/652404/r2-testr2-train-from-a-published-paper-how-can-it-be-consistently-possible</guid>
      <pubDate>Tue, 06 Aug 2024 21:33:55 GMT</pubDate>
    </item>
    <item>
      <title>如何标准化具有平行中介的回归的置信区间</title>
      <link>https://stats.stackexchange.com/questions/652403/how-to-standardise-confidence-intervals-for-a-regression-with-parallel-mediation</link>
      <description><![CDATA[我使用 Hayes Process Macro 在 SPSS 上运行了平行中介回归，它为我计算了标准化 beta - 但我刚刚意识到 95% 的置信区间都是非标准化的！有没有办法让我自己手动计算 ULCI 和 LLCI？
我在一篇类似的帖子上找到了一种手动计算的方法（我很绝望），但当我这样做时，我得到的 CI 是 -41.54 之类的。
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/652403/how-to-standardise-confidence-intervals-for-a-regression-with-parallel-mediation</guid>
      <pubDate>Tue, 06 Aug 2024 21:31:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么通过调整分类阈值可以改善分类器的预测标签（相对于分类器优化的相同指标）？</title>
      <link>https://stats.stackexchange.com/questions/652402/why-can-a-classifiers-predicted-labels-be-improved-with-respect-to-the-same-me</link>
      <description><![CDATA[我希望增强我（也许还有其他人）对一些基本原则的理解，这些原则似乎出奇地难以捉摸。
首先，我想考虑不平衡的二元分类，其中假阳性的成本与假阴性的成本相同。经过训练以优化特定指标（例如，马修斯相关系数，但任何指标都应该如此）的分类器提供 0-1 的分数，反映给定实例（数据点）属于正类的概率（可能未校准），如果该分数高于分类阈值，则转换为正预测类标签，否则转换为负预测标签。分类阈值默认为 0.5，但调整阈值以提高分类性能（“性能”仍然意味着算法最初优化的指标）似乎是一种常见的做法，而不会改变模型及其预测分数，而只改变阈值和预测标签。
这对我来说似乎令人费解，因为我希望大多数模型在内部做到这一点，通过调整分数使其对于给定阈值（例如 0.5）达到最佳效果。我希望有一些相对简单的方法来转换分数，同时保持阈值不变，以便预测标签与移动阈值（同时保持分数不变）产生的标签相同。“相对简单”的意思是大多数分类器模型都可以实现它。如果分数可以取任何正值或负值，那么将阈值移动一个值将等同于（即产生相同的预测标签）将分数在相反方向上移动相同的值（这对任何模型来说都是微不足道的）。我猜问题源于分数被限制在 0 和 1 之间；但话又说回来，难道没有基于无限制分数和决策函数的分类器吗？其中正分数产生正标签，否则产生负标签？它们能从阈值优化中受益吗？
在我看来，一个数学上能够等同于改变阈值来调整分数的模型不应该从阈值优化中受益。
所以问题是人们为什么要这样做（或何时这样做）。为什么可以通过调整已经训练以最大化 MCC 的分类器获得的预测的阈值来进一步提高 MCC？
可能想到的解释但不真实：

没有流行的分类器，包括神经网络和集成能够以相当于移动阈值的方式转换预测分数；
分数可以转换，但分数的相关噪声也会以有害的方式转换；
看似经过训练以优化某个指标的模型实际上并非如此（使用近似值或基于分数而不是标签的损失函数）；
性能的改进（调整阈值后）只能在验证或测试中观察到，但不能在训练集上观察到，这意味着它是一种对验证进行微调的形式，不是对超参数进行微调，而是对模型的实际基本参数进行微调，只是一次性进行；
...

我只是希望在这里进行一些有见地的讨论，或者也许有人指出我的推理中的缺陷或隐含假设。或者检查资源。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652402/why-can-a-classifiers-predicted-labels-be-improved-with-respect-to-the-same-me</guid>
      <pubDate>Tue, 06 Aug 2024 21:25:41 GMT</pubDate>
    </item>
    <item>
      <title>当 f 不服从正态分布时，误差传播的方差公式是否有用？</title>
      <link>https://stats.stackexchange.com/questions/652401/is-the-variance-formula-for-error-propagation-useful-when-f-is-not-normally-dist</link>
      <description><![CDATA[假设我有 n 个独立随机变量 $X_i$，它们服从正态分布，已知 $\mu_i$ 和 $\sigma_i$。
我有 f，它是 $X_i$ 的非线性组合。
方差公式 (1) 指出：
$$
\sigma_f^2 \approx \Sigma_{i=1}^N (\frac{\partial f}{\partial X_i}\sigma_i)^2 
$$
假设 f 的泰勒展开式收敛。
在随机变量 $X_i$ 的 95% 置信区间为：
$$
-2\sigma_i &lt;= x_i &lt;= 2\sigma_i
$$
但是由于 f 通常不是正态分布，$\sigma_f$ 有多大用处？
当然，我可以找到范围：
$$
-2\sigma_f &lt;= f &lt;= 2\sigma_f
$$
但我不知道这是 95% 还是 5% 的置信区间。
1 不确定性传播]]></description>
      <guid>https://stats.stackexchange.com/questions/652401/is-the-variance-formula-for-error-propagation-useful-when-f-is-not-normally-dist</guid>
      <pubDate>Tue, 06 Aug 2024 21:13:07 GMT</pubDate>
    </item>
    <item>
      <title>差距统计的推导</title>
      <link>https://stats.stackexchange.com/questions/652400/derivation-in-gap-statistic</link>
      <description><![CDATA[我正在阅读 Tibshirani (2001) 的论文“通过间隙统计估计数据集中的聚类数量”，其中有一个公式我不知道它是如何得出的。它说
$$
E[\log(W_k)] = \log(pn/12) - (2/p)\log(k) + C 
$$
但我不知道它是如何得出的。有人能给我解释一下吗？这是论文第 413 页。我已将论文链接附在下面。谢谢！

论文链接：https://academic.oup.com/jrsssb/article/63/2/411/7083348]]></description>
      <guid>https://stats.stackexchange.com/questions/652400/derivation-in-gap-statistic</guid>
      <pubDate>Tue, 06 Aug 2024 20:44:59 GMT</pubDate>
    </item>
    <item>
      <title>两个循环预测变量之间有交互项的 GLMM？</title>
      <link>https://stats.stackexchange.com/questions/652399/glmm-with-interaction-terms-between-two-circular-predictor-variables</link>
      <description><![CDATA[我正在运行 GLMM，以查看多种天气和巢箱协变量是否影响占用率（二元线性响应）。我想在我的模型中包含两个圆形预测因子（风向和巢箱入口方向），以及它们的相互作用（加上其他预测因子，如温度、巢箱面积等）。假设是鸟类会选择占据朝向与风向相同的巢箱（例如，当风向为西风时，巢箱朝向东）。
在我当前的模型中，我使用正弦和余弦函数将风向和巢箱方向从度转换为弧度，从而得到 4 个“线性”预测因子。因此，对于交互项，我将线性 EW 分量相乘，并将线性 NS 分量相乘，并将这些交互项添加到我的其他预测变量和随机效应中。
这是正确的方法吗？我只是很难找到有关两个圆形预测变量之间相互作用的信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/652399/glmm-with-interaction-terms-between-two-circular-predictor-variables</guid>
      <pubDate>Tue, 06 Aug 2024 20:42:47 GMT</pubDate>
    </item>
    <item>
      <title>如果测量时间间距不一致，我可以进行重复测量方差分析吗？</title>
      <link>https://stats.stackexchange.com/questions/652397/can-i-conduct-a-repeated-measures-anova-if-there-is-unequal-spacing-between-meas</link>
      <description><![CDATA[我计划进行一项小样本（约 20-25）的纵向调查研究，试图确定最佳的测量时间表，使分析顺利进行。
我最初的计划：在一周内进行事前调查（教育干预前后），然后在 1 年和 5 年后进行跟踪测量。我还考虑在干预后 7 年进行第三次跟踪。仅供参考，没有对照组。
我想看看我们在干预后直接看到的短期影响是否在经过一段时间（1 年）后仍然存在。最后两个随访时间点是根据参与者的受教育阶段选择的（例如，5 年将是他们高中毕业的时候），但这还不是一成不变的。
但是我想知道测量之间的时间不等/级别之间的间隔不等是否会使分析变得困难，比如如果我们要进行重复测量方差分析/多元方差分析。这是否可能会导致球形度假设出现问题？最坏的情况是，我们可以在时间点对之间进行配对样本 t 检验，对吗？在这种情况下，对于测量和分析方法的安排，您会有什么建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/652397/can-i-conduct-a-repeated-measures-anova-if-there-is-unequal-spacing-between-meas</guid>
      <pubDate>Tue, 06 Aug 2024 20:04:29 GMT</pubDate>
    </item>
    <item>
      <title>区间均匀分布的期望</title>
      <link>https://stats.stackexchange.com/questions/652393/expectation-of-uniform-distribution-conditioned-on-an-interval</link>
      <description><![CDATA[我试图更好地理解条件事件的概念。为此，我设计了以下小问题，然后尝试在均匀分布的背景下对其进行概括。
假设 $X$ 在 $[0,1].$ 上均匀分布，我想计算 $\mathbb{E}[X\vert I]$，其中 $I$ 是 $X\in[0,1/4] \cup [3/4,1]$ 事件。我很确定我已经正确地应用了定义，但如果有任何帮助进行验证，我将不胜感激！
我的尝试：写 $f$ 来表示密度，
$$f_{X\vert I}(x\vert I)= \frac{f_X(x)}{\int_I f_X(x)\,dx}=\frac{f_X(x)}{\int_0^{1/4} f_X(x)\,dx+\int_{3/4}^1 f_X(x)\,dx}=2 $$
第二个等式来自 $[0,1/4]$ 和 $[3/4,1]$ 不相交的事实，第三个等式来自 $[0,1/4]$ 的分布class=&quot;math-container&quot;&gt;$X$。
根据定义，
$$\mathbb{E}[X\vert I]=\int_I x\cdot f_{X\vert I}(x\vert I)\, dx=2\cdot \Bigg[\int_{0}^{1/4}x\,dx+\int_{3/4}^{1}x\,dx\Bigg]=\frac{1}{2}$$
概括地说，假设 $J=I_1\cup I_2$ 其中 $I_1$ 和 $I_2$ 不相交，并且 $J$ 是$[0,1]$ 的严格子集。使用类似的论点，我声称
$$\mathbb{E}[X\vert J]=\frac{1}{\int_{I_{1}}dx+\int_{I_{2}}dx}\cdot\Bigg[\int_{I_1}x\,dx+\int_{I_2}x\,dx\Bigg]$$
我的主张正确吗？提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/652393/expectation-of-uniform-distribution-conditioned-on-an-interval</guid>
      <pubDate>Tue, 06 Aug 2024 18:25:00 GMT</pubDate>
    </item>
    <item>
      <title>我如何将某个系列重新调整为不同的基准年？</title>
      <link>https://stats.stackexchange.com/questions/652392/how-can-i-rebase-a-series-to-a-different-base-year</link>
      <description><![CDATA[我有三份进口价格月度数据集。
第一份 --&gt; 基准年 = 2003 年（2003=100），数据期：2003 年第一季度 - 2012 年第一季度。
第二份 --&gt; 基准年 = 2010 年（2010=100），数据期：2010 年第一季度 - 2020 年第一季度
第三份 --&gt; 基准年 = 2015 年（2015 = 100），数据期 = 2013 年第一季度 - 2024 年第五季度。
我想创建一个涵盖所有时期（2003 年第一季度至 2024 年第五季度之间）的数据集，并使用相同的基准年？我该怎么做？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652392/how-can-i-rebase-a-series-to-a-different-base-year</guid>
      <pubDate>Tue, 06 Aug 2024 18:23:26 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在保持标准差的同时对数据进行标准化？</title>
      <link>https://stats.stackexchange.com/questions/652390/is-there-any-way-to-normalize-data-while-keeping-standard-deviation</link>
      <description><![CDATA[我有两个实验组，每个实验组由 3 个独立实验组成。我想分析它们在给定特征上的差异，但我想通过标准化结果但保持标准差来实现。有什么办法吗？或者可能是我没有想到的另一种解决方案。
让我举个例子来说明。假设我的 A 组和 B 组显示以下结果：
组 A：100、130、135
组 B：84、100、110
（这里我以这种格式呈现结果：组 X：实验 1、实验 2、实验 3）。
当我运行非配对 t 检验时，A 组和 B 组之间没有显着差异。我当时想做一个标准化，这样我就可以量化每个组之间的倍数变化。此外，我认为这种标准化是合适的，因为试剂批次会导致一些实验变异。因此，我认为标准化如下：
组 A：1、1、1
组 B：0.84、0.77、0.81
在这里，我只是为每个实验划分了组 A/组 A 和组 B/组 A。
问题是：我不知道这是否是正确的做法。此外，我想保留组 A 的标准差，但每个实验之间没有差异，因此也没有 SD。
有什么办法可以解决这个问题吗？有什么方法可以解决或帮助我解决这个问题吗？
提前谢谢！
附注：我已经用 Shapiro-Wilk 检验测试了我的数据集的标准化，A 组和 B 组都是正常的，所以我要做非配对 t 检验。
编辑：
我正在分析两种不同细胞系在 DNA 复制过程中掺入了多少核苷酸。然而，这是一种间接测定。它是通过与特定人工核苷酸结合的抗体的荧光来测量的。我通过流式细胞仪获取数据，荧光强度的平均值以任意单位给出。此外，它对许多因素很敏感，尤其是抗体。
不过，我认为这些信息并不是绝对必要的，因为我只想知道是否有一种数学方法可以在保持标准差的同时对数据进行标准化。
我不是数学家，所以我不确定我是否恰当地使用了标准化一词。通过标准化，我的意思是“将对照组/A 定义为 1，并计算 B 组与 B 组的偏差”。我实际上想做的是计算倍数变化。
但是，如果像我说的那样“将对照组定义为 1”，我将失去与对照组的标准差，因为所有 3 个实验的所有值都将是 1。有没有办法在不丢失对照组/A 的 SD 的情况下进行这种“标准化”或“倍数变化”？
这样更清楚吗？如有误解，敬请谅解。]]></description>
      <guid>https://stats.stackexchange.com/questions/652390/is-there-any-way-to-normalize-data-while-keeping-standard-deviation</guid>
      <pubDate>Tue, 06 Aug 2024 17:19:36 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 符号秩检验与符号检验假设</title>
      <link>https://stats.stackexchange.com/questions/652389/wilcoxon-signed-rank-test-vs-sign-test-assumptions</link>
      <description><![CDATA[我有一组离散（李克特）配对数据，其中有许多 0 差异/平局（之后 - 之前），差异的分布不对称。 Wilcoxon 符号秩检验有效吗？或者符号检验是更安全的选择？
符号检验必须检查哪些假设？
如果符号检验也无效，那么在这种情况下哪种检验有效？]]></description>
      <guid>https://stats.stackexchange.com/questions/652389/wilcoxon-signed-rank-test-vs-sign-test-assumptions</guid>
      <pubDate>Tue, 06 Aug 2024 17:16:02 GMT</pubDate>
    </item>
    </channel>
</rss>