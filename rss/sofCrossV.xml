<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 31 Jul 2024 03:17:24 GMT</lastBuildDate>
    <item>
      <title>情境学习中的突发性</title>
      <link>https://stats.stackexchange.com/questions/652052/burstiness-in-in-context-learning</link>
      <description><![CDATA[我正在阅读论文上下文分类任务中数据依赖性和突发学习的机制基础。我对参数化数据分布部分感到非常困惑。

这个“数据分布”是指训练数据还是测试数据？（两者都是一批输入序列。）
对于那些突发序列，类别究竟是如何分布的？是不是像来自特定（随机选择的）类别的 B 个项目，然后其余的 N-B 个项目遵循剩余类别的秩频率分布？

]]></description>
      <guid>https://stats.stackexchange.com/questions/652052/burstiness-in-in-context-learning</guid>
      <pubDate>Wed, 31 Jul 2024 03:08:17 GMT</pubDate>
    </item>
    <item>
      <title>这个 Kaplan-Meier 思想实验违反了哪些假设？</title>
      <link>https://stats.stackexchange.com/questions/652048/what-assumptions-does-this-kaplan-meier-thought-experiment-violate</link>
      <description><![CDATA[我一直在思考，在跟踪时间的某个特定点，假设被审查的受试者仍然活着，那么简单的逻辑回归将始终高估与乘积极限估计值相比的生存比例。
但是，我该如何合理化这个荒谬的例子（我假设有关审查的基本假设被打破了）？
想象一下，你有 100 个受试者，你跟踪了（几乎）100 天。在第 99 天，99 人退出了研究，在第 100 天，最后一个离开的人死了。根据乘积极限估计器，生存率是 0%，对吗？ （即事件发生率（累积发生率）为 100%。
但实际上，生存率基本上是 99%，而事件发生率只有 1%。而使用逻辑回归更接近真相，错误地假设那些被审查的人在研究结束时仍然活着。
我认为我没有正确思考问题，但有兴趣纠正。]]></description>
      <guid>https://stats.stackexchange.com/questions/652048/what-assumptions-does-this-kaplan-meier-thought-experiment-violate</guid>
      <pubDate>Wed, 31 Jul 2024 01:58:39 GMT</pubDate>
    </item>
    <item>
      <title>正常性评估中的冲突</title>
      <link>https://stats.stackexchange.com/questions/652047/conflicts-in-normality-assesment</link>
      <description><![CDATA[我有一个小数据集（n=11），当我对正态分布进行评估时，我遇到了这个问题：

偏度和峰度介于（+2，-2）之间
shapiro - wilk p&gt;0,05，表示正态性

但是，直方图和Q-Q图告诉我数据分布不正常。
我计划根据分布进行 wilxocon 排序符号检验或 t 检验。我检查了两个结果，一个结果是 p&gt;0,05，另一个结果是 &lt;0,05，这完全改变了结果。
在某些来源中；有一条一般讨论的规则，即当样本量 &lt; 30i 数据应被假定为非正态分布。
那么在我的问题中，我应该如何得出结论，是正态分布还是非正态分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/652047/conflicts-in-normality-assesment</guid>
      <pubDate>Wed, 31 Jul 2024 01:48:20 GMT</pubDate>
    </item>
    <item>
      <title>如何正确计算百分比的平均数？</title>
      <link>https://stats.stackexchange.com/questions/652044/how-to-correctly-average-percentages</link>
      <description><![CDATA[我正在处理基因组数据；百分比拼接 (psi) 值可以通过包含计数与排除计数的比例找到。为了获得样本的平均 psi 值，我只是计算百分比的平均值，现在我意识到这是错误的，因为它们不是来自相等的权重。
我是一个纯粹的“计算人”，不太擅长统计，所以我只是把东西扔进去，看看结果。分数 2（z 标准化 psi 的平均值）和分数 4（psi 的几何平均值）在实际数据中效果最好；我通过将另一个测量值与分数关联起来来实现这一点。我希望并感谢你们指导我正确的方法，也许解释为什么它是正确的。也欢迎提出更复杂的方法（也许是 Cohen D？）。非常感谢。实际数据非常嘈杂且庞大，下面是我在 R 中尝试的一个例子：
inc &lt;- data.frame(sampleA = c(1755,175 ,11 ,35),
sampleB = c(1500,199,15,20),
sampleC = c(1768,900,122,60),
sampleD = c(1808,881,123,65))

exc &lt;- data.frame(sampleA = c(11311,706 ,257 ,8900),
sampleB = c(12000,706,257,8780),
sampleC = c(2958,354,257,7000),
sampleD = c(2800,354,257,7990))
psi &lt;- inc / (inc + exc)

得分1 &lt;- colMeans(psi)
得分2 &lt;- colMeans(t(scale(t(psi))))
得分3 &lt;- colSums(inc)/(colSums(inc)+colSums(exc))
geometric.mean &lt;- function(x,na.rm=TRUE){exp(mean(log(x),na.rm=na.rm))} 
得分4 &lt;- apply(psi, 2, geometry.mean)

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/652044/how-to-correctly-average-percentages</guid>
      <pubDate>Wed, 31 Jul 2024 00:41:01 GMT</pubDate>
    </item>
    <item>
      <title>关于具有负二项分布的多元广义回归混合模型</title>
      <link>https://stats.stackexchange.com/questions/652041/about-multivariate-generalized-regression-mixed-models-with-negative-binomial-di</link>
      <description><![CDATA[我有一个关于封锁前和封锁期间接触模式的个体内变化的研究问题。我将解释接触模式的定义以及我用测试数据构建的模型。我的问题是，我不确定我构建的模型是否可以回答研究问题。
接触模式是指特定年龄、位置分层的接触率。这里有一个图表可能会给你一些提示。
。
我将接触次数和位置作为结果，因为这是计数数据，其分布是右偏的。所以我的选择有三个：1）具有泊松分布的多元广义线性混合模型，2）具有负二项分布的多元广义回归混合模型，3）具有负二项分布的多元广义回归混合模型。经过对比AIC，我选择的模型是第二个。
下面是测试数据和我使用R建立的模型。
data &lt;- data.frame(
contacts_education = rpois(100, lambda = 5),
contacts_work = rpois(100, lambda = 10),
contacts_household = rpois(100, lambda = 8),
contacts_others = rpois(100, lambda = 3),
token = rep(as.character(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;)), each = 20), 
age = rep(c(56, 77, 15, 32, 27), each = 20),
sex =因子（样本（c（&quot;男性&quot;, &quot;女性&quot;），100，替换 = TRUE）），
hh_size = rnorm（100，平均值 = 3，标准差 = 1），
city = 因子（样本（c（&quot;城市A&quot;, &quot;城市B&quot;, &quot;城市C&quot;），100，替换 = TRUE）），
period = 因子（样本（c（&quot;1&quot;, &quot;2&quot;, &quot;3&quot;），100，替换 = TRUE））
)

data_long &lt;- data %&gt;%
pivot_longer（cols = starts_with（&quot;联系人&quot;），
names_to = &quot;位置&quot;，
values_to = &quot;num_contacts&quot;）

nb_model &lt;- glmmTMB(num_contacts ~ period * location * (I(age/100) + sex + I(hh_size) + city) + (1 | location) + (1|token ) + (1|city), 
family = nbinom2, 
data = data_long)

这里，token 是参与者 id，age 是参与者年龄，sex 是参与者性别，hh_size 是家庭规模。因为研究问题是关于个体内变异，所以我只包括至少在两个时间点报告联系信息的参与者，即使他们处于同一时期。period 指的是封锁前、封锁期间（受季节影响）和封锁期间。]]></description>
      <guid>https://stats.stackexchange.com/questions/652041/about-multivariate-generalized-regression-mixed-models-with-negative-binomial-di</guid>
      <pubDate>Tue, 30 Jul 2024 23:57:09 GMT</pubDate>
    </item>
    <item>
      <title>包含所有观测因素的状态空间模型</title>
      <link>https://stats.stackexchange.com/questions/652040/state-space-model-with-all-observed-factors</link>
      <description><![CDATA[我见过当我们想要揭示潜在/未观察到的因素时实施的状态空间模型，这些因素共同解释了因变量时间序列的动态。我也见过混合了可观察和未观察因素的状态空间模型。拟合一个所有因素都可观察的状态空间模型是否有意义？这意味着我有一个因子 f_t 的数据矩阵 X，我想拟合一个状态空间模型，其中的因子遵循 AR(1) 过程，然后从给定 f_t 的 f_t+1 分布中抽样。]]></description>
      <guid>https://stats.stackexchange.com/questions/652040/state-space-model-with-all-observed-factors</guid>
      <pubDate>Tue, 30 Jul 2024 23:35:03 GMT</pubDate>
    </item>
    <item>
      <title>高斯数据无监督聚类的损失函数</title>
      <link>https://stats.stackexchange.com/questions/652039/loss-functions-for-unsupervised-clustering-of-gaussian-data</link>
      <description><![CDATA[我得到了由 $n$ 个具有不同均值和协方差的多元高斯分布生成的数据，这意味着它们是可分离的，我的任务是使用神经网络以无监督的方式对它们进行分类，也就是说不使用真实标签。
我想创建一个简单的 DNN 并定义一个损失函数，该函数根据诸如簇之间的距离、簇协方差等指标对当前批次的模型预测进行评分。
这里我遗漏了什么典型损失函数吗？我在文献中找不到任何东西。此外，如果我知道数据是从不同的分布（不是高斯分布）生成的，它将如何影响损失函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/652039/loss-functions-for-unsupervised-clustering-of-gaussian-data</guid>
      <pubDate>Tue, 30 Jul 2024 22:58:02 GMT</pubDate>
    </item>
    <item>
      <title>给定一个预测变量 $x$，在什么情况下，你会得到较高的 $R^2$ 但较低的 $\beta$</title>
      <link>https://stats.stackexchange.com/questions/652036/given-a-predictor-x-under-what-circumstance-would-you-have-high-r2-but-low</link>
      <description><![CDATA[假设我有一个时间序列 $y$ 和一个预测变量 $x$。假设它们都以零为中心。
$$R^2 = 1 - \frac{ \sum (y_i - x_i)^2 }{\sum y_i^2}$$
现在我运行一个新的回归 $y \sim \beta x$，试图“重新调整”我的预测变量。
$\beta = \frac{\operatorname{cov}(x,y)}{\operatorname{var}(x)} = \frac{\sum x_i y_i}{\sum x_i^2}$
我想找到 $\beta$ 和 $R^2$ 之间的关系 （请注意，此 $R^2$ 是我在上面计算的 $R^2 = 1 - \frac{ \sum (y_i - x_i)^2 }{\sum y_i^2}$，而不是我的新回归的 $R^2$，它产生了 $\beta$，$x$ 已经是一个预测因子 )
我的假设是 $\beta = 1$ 时 $R^2$ 最大化。因为这意味着我的预测因子 $x$ 是“尺度良好的”。但我很难证明这一点……如果这不是真的，为什么当我的预测变量是“最佳缩放”时，$R^2$ 不会最大化？
$$\sum x_i y_i = \beta \sum x_i^2,$$
插入
\begin{align}
R^2 &amp; = 1 - \frac{ \sum (y_i - x_i)^2 }{\sum y_i^2} \\[6pt] &amp; = 1 - \frac{ \sum x_i^2 - 2\sum x_i y_i + \sum y_i^2 }{\sum y_i^2} \\[6pt] &amp; = \frac{ 2 \sum x_i y_i - \sum x_i^2 }{\sum y^2_i} = (2\beta-1) \frac{ \sum x_i^2 }{ \sum y_i^2}。
\end{align&gt;
没有任何迹象表明 $\beta = 1$ 时 $R^2$ 最大化，但正如我所提到的，不确定为什么当我的预测器“最佳缩放”时 $R^2$ 没有最大化？]]></description>
      <guid>https://stats.stackexchange.com/questions/652036/given-a-predictor-x-under-what-circumstance-would-you-have-high-r2-but-low</guid>
      <pubDate>Tue, 30 Jul 2024 22:09:04 GMT</pubDate>
    </item>
    <item>
      <title>规范化实时数据</title>
      <link>https://stats.stackexchange.com/questions/652034/normalizing-live-data</link>
      <description><![CDATA[我正在研究一个使用孤立森林检测实时数据异常的模型，但我不确定应该使用哪种方法来实时规范化它。我正在研究使用窗口的 MinMax 缩放，但这似乎不是最佳选择，可能会出现问题。我有超过 700 个数据集，它们的最大值从不到 10 到大约 115 不等。对于孤立森林模型来说，规范化这些数据的最佳方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652034/normalizing-live-data</guid>
      <pubDate>Tue, 30 Jul 2024 21:41:53 GMT</pubDate>
    </item>
    <item>
      <title>对 p 值和 Cohen's d 感到困惑</title>
      <link>https://stats.stackexchange.com/questions/652003/confused-about-the-p-value-and-cohens-d</link>
      <description><![CDATA[我有以下代码，用于计算 p 值和 cohen 距离。
import numpy as np
from scipy.stats import ttest_ind

# 计算 Cohen 的 d
def calculate_cohens_d(group1, group2):
mean_group1 = np.mean(group1)
mean_group2 = np.mean(group2)
std_group1 = np.std(group1, ddof=1)
std_group2 = np.std(group2, ddof=1)
n_group1 = len(group1)
n_group2 = len(group2)
pooled_std = np.sqrt(((n_group1 - 1) * (std_group1 ** 2) + (n_group2 - 1) * (std_group2 ** 2)) / (n_group1 + n_group2 - 2))
cohen_d = (mean_group1 - mean_group2) / pooled_std
return cohen_d

# 模拟数据并执行 t 检验和 Cohen&#39;s d 计算的函数
def perform_experiment():
# 模拟数据
group1_EXP = np.random.normal(80, 10, 10)
group2_EXP = np.random.normal(81, 10, 10)

# 执行多重 t 检验
_, p_value_EXP = ttest_ind(group1_EXP, group2_EXP)
cohen_d_EXP = calculate_cohens_d(group1_EXP, group2_EXP)

return p_value_EXP, cohen_d_EXP


如果我使用给定的种子运行代码两次：
# 可重复性的种子
np.random.seed(42)

# 执行 2 次实验
p_value_EXP, cohen_d_EXP = perform_experiment()
print(f&#39;p-value: {p_value_EXP:.4f}, Cohen\&#39;s d: {cohen_d_EXP:.4f}&#39;)

p_value_EXP, cohen_d_EXP = perform_experiment()
print(f&#39;p-value: {p_value_EXP:.4f}, Cohen\&#39;s d: {cohen_d_EXP:.4f}&#39;)

我得到：
p-value: 0.0029， Cohen 的 d：1.5402
p 值：0.9792，Cohen 的 d：-0.0118

因此可以说，第一个实验的 p 值为 0.0029，Cohen 距离“较大”，是显著的。
相比之下，我会说第二个实验并不那么重要。
现在，如果我运行 1,000 次模拟
# 执行 1000 次实验

n_simulations = 1000

p_values_EXP = np.zeros(n_simulations)

cohen_ds_EXP = np.zeros(n_simulations)

for i in range(n_simulations):
p_values_EXP[i], cohen_ds_EXP[i] = perform_experiment()

# 计算 p 值 &gt; 的比例0.05
prop_p_value_EXP_greater_0_05 = np.mean(p_values_EXP &gt; 0.05)

print(&quot;Proportion of p-values &gt; 0.05:&quot;, prop_p_value_EXP_greater_0_05)

我得到
Proportion of p-values &gt; 0.05: 0.951

这意味着更有可能观察到不显著的结果。但前 2 个实验显示相反的结果。
因此，我不确定在这种情况下 Cohen 距离的用处。]]></description>
      <guid>https://stats.stackexchange.com/questions/652003/confused-about-the-p-value-and-cohens-d</guid>
      <pubDate>Tue, 30 Jul 2024 12:20:20 GMT</pubDate>
    </item>
    <item>
      <title>控制变量时的多重共线性</title>
      <link>https://stats.stackexchange.com/questions/652000/multicollinearity-when-controlling-for-a-variable</link>
      <description><![CDATA[我对数据中的多重共线性有几个问题：我正在查看 MRI 扫描中发现的某种类型的病变；对于每位患者，我都知道这些病变的体积以及捕捉其分布模式的指标。我对模式指标对临床评分的影响感兴趣，而不仅仅是体积的影响。然而，模式指标与体积高度相关（r = 0.7），这是事物的本质，因为病变在大脑中覆盖的面积越大，它们就越成为一个有凝聚力的区域的一部分，而不是单独的斑点。这让我想知道一些事情：

在像临床评分 ~ 模式 + 体积这样的回归中是否存在多重共线性问题？缓解这样的问题似乎违背了我想要看到的目的。
模式指标已根据体积进行了校正，即每个人的指标已除以该人的病变体积。如果体积已经以某种方式纳入，我是否仍需要在回归中考虑体积？
如果我想进行相关性而不是回归，那么 a) 考虑体积后临床评分和模式指标的偏相关性与 b) 临床评分和残差模式指标的相关性（在将模式指标回归到体积后）之间有什么区别？
当我计算临床评分和残差模式指标的相关性时，相关性高于残差之前，这是正常观察结果吗？我注意到临床评分和体积的相关性为负，而临床评分和模式的相关性为正，鉴于模式和体积的相关性为正且很大，我不确定这是否表明出了问题。也许这就是为什么残差化后与临床评分的相关性更高的原因？有没有更深入的分析方法？

提前谢谢您！
]]></description>
      <guid>https://stats.stackexchange.com/questions/652000/multicollinearity-when-controlling-for-a-variable</guid>
      <pubDate>Tue, 30 Jul 2024 11:23:33 GMT</pubDate>
    </item>
    <item>
      <title>测量误差模型中“朴素”估计量的渐近方差</title>
      <link>https://stats.stackexchange.com/questions/651990/asymptotic-variance-of-the-naive-estimator-in-measurement-error-model</link>
      <description><![CDATA[考虑经典测量误差模型：
$$Y= \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \varepsilon$$
其中 $W=X+U$ 是观测值。X 是“真实”量，U 是测量误差。 Var$(X) = \Sigma_x$，Var$(U) = \Sigma_U$。
“朴素”估计量$\hat{\beta}_{\text{naive}} = (W^TW)^{-1}W^TY$是$\beta = (\beta_1, \beta_2)^T$的 OLS 估计量。一个众所周知的结果是 E$(\hat{\beta}_{\text{naive}}) = \Lambda \beta$，其中 $\Lambda = \Sigma_x (\Sigma_x + \Sigma_u)^{-1}$
我对“朴素”估计量的渐近方差感兴趣，其中 $\Sigma_x$ 和 $ \Sigma_u$ 已知。根据非线性模型中的测量误差 - Carrol (2006)中的结果，我相当有信心，$p=1$ 情况下的渐近方差由$\frac{\sigma^2_\epsilon + \beta^2 \sigma^2_x \frac{\sigma^2_u}{\sigma^2_u + \sigma^2_x}}{n (\sigma^2_u + \sigma^2_x)}$ 给出，如果这有帮助的话。]]></description>
      <guid>https://stats.stackexchange.com/questions/651990/asymptotic-variance-of-the-naive-estimator-in-measurement-error-model</guid>
      <pubDate>Tue, 30 Jul 2024 07:55:40 GMT</pubDate>
    </item>
    <item>
      <title>对数尺度图中的相对误差线与绝对误差线</title>
      <link>https://stats.stackexchange.com/questions/651983/relative-vs-absolute-error-bars-in-log-scaled-plots</link>
      <description><![CDATA[关于在对数刻度图上显示误差线的正确方法，看似知识渊博的来源提供了相互矛盾的信息。

$log_{10}(x \pm \Delta x)$ 显示绝对误差。一方面，它很容易解释：如果我们以某种概率知道 $x$ 在 $\vert x - \Delta x, x + \Delta x \vert$ 内，那么对数转换后该概率不会改变。我们可以读取刻度标记并轻松了解间隔。另一方面，当 $\Delta x$ 接近 $x$ 时，误差线看起来不对称，各种来源都认为这是不好的（有时没有解释，有时因为它在视觉上暗示该值低于平均值的概率大于高于平均值的概率）。对于 $\Delta x \ge x$，下部误差线部分将延伸出图外。

$x \pm \frac{\Delta x}{x \ln 10}$ 使用不确定性传播显示相对误差。误差线在视觉上是对称的。但我不明白当根据刻度线读取时，您应该如何解释长度。


例如：

这里，第一个点（蓝色）的 $x = 8000$ 和 $\Delta x = 7000$，第二个点的 $x = 5000$ 和 $\Delta x = 500$第二（黄色）。当 $\Delta x \ll x$（黄色）时，两种方法基本无法区分。当 $\Delta x \approx x$（蓝色）时，条形图显示范围从 3,335 到 19,190。 您应该如何解释这些数字？
显示误差线的正确方法是什么？为什么？

各种来源：

Eric Stuve 的讲座
https://physics.stackexchange.com/q/95254/31907（请注意，我对我的评论中的第二个答案也感到困惑）
对数-对数图上的相对误差
]]></description>
      <guid>https://stats.stackexchange.com/questions/651983/relative-vs-absolute-error-bars-in-log-scaled-plots</guid>
      <pubDate>Tue, 30 Jul 2024 03:30:15 GMT</pubDate>
    </item>
    <item>
      <title>均匀分布中的无偏估计量</title>
      <link>https://stats.stackexchange.com/questions/651951/unbiased-estimators-in-uniform-distributions</link>
      <description><![CDATA[变量 $x$ 在区间 $(a-1,a+1)$ 内均匀分布，其中 $a$ 的值未知。对 $x$ 的一次观察给出了值 $x_1$。
如何（有证据）使用 $x_1$ 的这个值来确定 $a$ 的无偏估计，并确定 $a$ 的 $99\%$ 置信限度？
我知道
$$E(x)=\frac{\int_{a-1}^{a+1} xf(x) \;\mathrm{d}x}{\int_{a-1}^{a+1} f(x) \;\mathrm{d}x}=a$$但接下来该怎么做呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/651951/unbiased-estimators-in-uniform-distributions</guid>
      <pubDate>Mon, 29 Jul 2024 16:07:54 GMT</pubDate>
    </item>
    <item>
      <title>通过模拟评估功效 - 敏感度</title>
      <link>https://stats.stackexchange.com/questions/651912/estimating-power-by-simulation-sensitivity</link>
      <description><![CDATA[我正在开展一个项目，该项目比较了两个给出二元结果的不同测试，我们想根据它们的灵敏度来评估这些测试。毫不奇怪，需要多少样本才能达到一定程度的功效的问题出现了。幸运的是，它是先验出现的，因此这不是事后功效计算。
我知道有很多方法可以比较两个具有二元结果的测试的灵敏度 - Fisher 精确检验、McNemar 检验和比例检验。此外，我们对第一个测试的灵敏度进行了估计，约为 75%。为了计算不同样本量的功效，我编写了如下所示的 R 函数。
我尝试将我的结果与一些文献资料进行比较，但到目前为止我发现的所有资料都没有指定测试的一些细节，例如使用哪种特定测试，是否假设测试独立（两个测试是针对同一个人还是针对两组不同的人？），重要性水平等。
对于我的代码，我假设两个测试在不同的组上运行，并且我在代码中指定了所有其他假设。这看起来正确吗？如果不正确，我将不胜感激任何建议。如果两个测试在同一受试者上运行，我将如何进行模拟？我假设我需要考虑两个测试之间的预期相关性，但我不确定如何做到这一点。此外，我是否正确地认为可以进行相同的模拟来估计特异性比较的功效？
set.seed(303)

se1 &lt;- .75 # 测试 1 的灵敏度（或特异性）
se2 &lt;- .80 # 测试 2 的灵敏度（或特异性）

Nd &lt;- 60 # 每组的 dz 数量
Z &lt;- 10000 # 试验次数
alpha = 0.05 # 目标显着性水平

powercalc(se1, se2, Nd, Z, alpha, &#39;fisher&#39;)

#####
powercalc &lt;- function(se1, se2, Nd, Z, alpha, 
test = c(&#39;fisher&#39;, &#39;mcnemar&#39;, &#39;proportion&#39;)){
p_vals &lt;- sapply(1:Z, function(z) {
s1_pos &lt;- rbinom(1, Nd, se1) 
# 使用二项式抽样可能的测试结果
s1_neg &lt;- Nd - s1_pos
s2_pos &lt;- rbinom(1, Nd, se2)
s2_neg &lt;- Nd - s2_pos

# 创建一个矩阵，行对应于两个测试
# 列对应于这些测试的结果
# 这些是具有条件的受试者的结果
# 敏感性
# 或不具有特异性条件的受试者的结果
m &lt;- matrix(c(s1_pos, s1_neg,
s2_pos, s2_neg),
nrow = 2, byrow = TRUE)

if(test == &#39;fisher&#39;)
fisher.test(m)$p.value
else if(test == &#39;mcnemar&#39;)
mcnemar.test(m)$p.value
else if(test == &#39;proportion&#39;)
prop.test(c(s1_pos, s2_pos), c(Nd, Nd))$p.value
})

# 计算我们看到极端排列的次数

# 对于双侧测试
lte_alpha = mean(p_vals &lt;= alpha / 2)
gte_alpha = mean(p_vals &gt;= 1 - (alpha /2))
power_2sided = lte_alpha + gte_alpha
beta_2sided = 1 - power_2sided

# 对于单侧，假设测试二具有更高的敏感度
beta_1sided = mean(p_vals &gt;= alpha)
power_1sided = 1 - beta_1sided

c(one_sided = power_1sided, two_sided = power_2sided)
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/651912/estimating-power-by-simulation-sensitivity</guid>
      <pubDate>Sun, 28 Jul 2024 23:03:29 GMT</pubDate>
    </item>
    </channel>
</rss>