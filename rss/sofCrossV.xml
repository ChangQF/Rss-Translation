<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 01 Jul 2024 06:23:16 GMT</lastBuildDate>
    <item>
      <title>如何使用额外的二维数据集来扩充一维表格数据集？</title>
      <link>https://stats.stackexchange.com/questions/650236/how-can-i-augment-a-1d-tablar-dataset-using-an-additional-2d-dataset</link>
      <description><![CDATA[我有以下两种类型的数据集：

dataset-1 是描述 7000 种蛋白质的表格数据。 dataset-1 只有一个文件。

dataset-2 由 7000 个单独的数据文件组成，这些文件是 2D 矩阵，也描述了 7000 种蛋白质。


dataset-1.dat
ProtNo ResNo Label fet0 fet1 fet2 fet3 fet4 fet5 fet6 fet7 fet8 
0 0 2 0.000 0.000 0.000 1 1 1 1 1 0 
0 1 1 7.057 10.394 0.000 1 1 1 1 1 0 
0 2 1 6.710 9.449 13.140 0 0 0 0 1 0 
0 3 1 6.552 9.752 12.974 0 0 0 0 0 0 
0 4 2 6.544 7.584 11.239 0 0 0 0 0 0 
1 0 2 5.407 5.140 5.159 0 0 0 0 0 0 
1 1 2 5.485 7.378 5.152 0 0 0 0 0 0 
1 2 2 5.723 9.048 9.571 0 0 0 1 1 0 
1 3 2 6.347 9.102 10.812 0 0 0 2 2 0 
1 4 1 6.219 9.620 12.486 0 1 1 3 4 0 
1 5 1 6.412 9.721 12.781 0 0 0 3 4 0 
1 6 1 6.603 10.294 13.140 0 1 1 2 3 0 
1 7 1 7.219 10.586 13.126 0 0 0 2 2 0 
2 0 0 6.939 10.295 13.972 0 0 0 0 1 0 
2 1 0 6.814 10.472 13.764 0 0 0 0 0 0 
2 2 0 7.061 9.189 12.947 0 0 0 0 0 0 
2 3 0 6.872 9.856 11.521 0 0 0 0 0 0 
2 4 2 6.988 9.388 11.337 0 0 0 0 0 0 
2 5 2 6.903 7.889 9.055 0 0 0 0 0 0 
2 6 2 6.378 8.943 9.999 0 0 0 0 0 0 
2 7 1 6.756 10.264 12.361 0 0 0 0 0 0 
2 8 1 6.710 10.006 13.244 0 0 0 0 0 0 
2 9 1 6.539 9.762 13.091 0 0 0 0 0 0 
3 0 0 6.417 9.794 12.952 0 0 0 0 0 0 
3 1 0 6.453 9.944 13.193 0 0 0 0 0 0 
3 2 2 6.842 10.288 13.447 0 0 0 0 0 0 
3 3 2 7.021 8.226 11.805 0 0 0 0 0 0 
... ... ...

dataset-2
distance-matrix-for-protein-0.dat (a 5x5矩阵)

distance-matrix-for-protein-1.dat (8x8 矩阵)

distance-matrix-for-protein-2.dat (10x10 矩阵)

distance-matrix-for-protein-3.dat (4x4 矩阵)

... ... ... 

我使用 dataset-1 训练了一个 AdaBoost 模型，并获得了 81% 的测试准确率。
现在，我想使用 dataset-2 来增强 dataset-1，从而提高模型的测试准确率。
我该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/650236/how-can-i-augment-a-1d-tablar-dataset-using-an-additional-2d-dataset</guid>
      <pubDate>Mon, 01 Jul 2024 06:08:04 GMT</pubDate>
    </item>
    <item>
      <title>预测模型的因果路径问题</title>
      <link>https://stats.stackexchange.com/questions/650233/a-causal-path-problem-of-prediction-models</link>
      <description><![CDATA[我正在做一个利用血糖、糖化血红蛋白、甘油三酯等因素预测非糖尿病人群10年患糖尿病风险的研究。采血时间并不局限于空腹，也就是说人们可以根据自己的判断选择在任何时候抽血。
这里有一个问题，就是采血时间对血糖和甘油三酯的影响。餐后8小时内，血糖和甘油三酯都会上升，餐后6小时左右开始下降。8小时后的空腹状态下，血糖和甘油三酯趋于稳定。我使用受限三次样条函数（rcs）和交互作用构建了以下模型。
 Surv(py, diabetes) ~ AGE + SEXC +
rcs(HBA1C) +
rcs(GLU) +
rcs(TG) * rcs(餐后时间) +
rcs(GLU) :rcs(餐后时间) + 
rcs(GLU) : rcs(TG) +
其他因素......

餐后时间会影响血糖和甘油三酯，因此其交互作用是必要的。一种常见的做法是将人分为禁食和非禁食进行分层分析。我知道分层分析有很多问题。特别是，我觉得禁食/非禁食状态是一个碰撞器。虽然没有要求，但高血糖或糖尿病前期的人，空腹采血的可能性更大，10年糖尿病发病率高于非空腹状态。
我的假设是
A→C←O
O→糖尿病发病率。
A是餐后时间，餐后时间长，就进入空腹状态
C是空腹状态
O是高血糖，担心高血糖的人可以选择空腹采血，而不是非空腹采血
一旦限定在空腹采血的人群，就意味着餐后时间与高血糖挂钩，也就是餐后（空腹）时间长可能意味着高血糖。而高血糖也与糖尿病风险息息相关。因此，空腹采血与较高的糖尿病风险相关（即空腹采血人群糖尿病发病率较高）。但空腹不应该与糖尿病发病率相关。
我不确定我的理解是否正确，如果有人能帮我确认或指出我理解中的问题，以及我上面提到的模型构建是否合理，那就太好了。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/650233/a-causal-path-problem-of-prediction-models</guid>
      <pubDate>Mon, 01 Jul 2024 05:27:08 GMT</pubDate>
    </item>
    <item>
      <title>如何评估期望最大化中 E 步骤的条件期望？</title>
      <link>https://stats.stackexchange.com/questions/650232/how-to-evaluate-this-conditional-expectation-for-the-e-step-in-expectation-maxim</link>
      <description><![CDATA[我正在尝试为某个问题设计一个期望最大化算法，但是我无法在 E 步骤中推导出条件期望。为了回答这个问题，我将简化问题并丢弃不必要的细节。
假设

$X$ 和 $Y$ 是具有 已知 多元正态分布的随机变量（最初分别表示潜在数据和观测数据）。
$Y = AX$ 其中 $A$ 是已知的奇异矩阵。
$X = \begin{bmatrix}X_1 \\ X_2\end{bmatrix}$。

那么，如何找到 $\mathbb{E}_{X \vert Y} \left[ ||X_1 - m_1 ||_{C_1^{-1}}^2 \right] $ 其中 $m_1$ 和 $C_1$ 分别是 $X_1$ 的均值和协方差？
这是我的尝试：
$$ \begin{align} \mathbb{E}_{X \vert Y} \left[ ||X_1 - m_1 ||_{C_1^{-1}}^2 \right] &amp;= \int ||X_1 - m_1 ||_{C_1^{-1}}^2 p(x \vert y) dx \\
&amp;= \int ||X_1 - m_1 ||_{C_1^{-1}}^2 \frac{p(y \vert x) p(x)}{p(y)} dx \end{align} $$
$p(x)$ 和 $p(y \vert x)$ 当然是已知的，但这个表达式计算起来非常繁琐。有没有更简单、更优雅的方法？否则，如何处理结果积分（其中包括一个复杂的指数项）？]]></description>
      <guid>https://stats.stackexchange.com/questions/650232/how-to-evaluate-this-conditional-expectation-for-the-e-step-in-expectation-maxim</guid>
      <pubDate>Mon, 01 Jul 2024 05:25:41 GMT</pubDate>
    </item>
    <item>
      <title>如何证明因变量由两个（相关的）独立变量解释？</title>
      <link>https://stats.stackexchange.com/questions/650231/how-to-prove-that-the-dependent-variable-is-explained-by-the-two-independent-var</link>
      <description><![CDATA[我想说明因变量 Y 主要由两个自变量（A1 和 A2）解释。理论上，A1 增加会导致 Y 增加，A2 增加会导致 Y 减少。此外，对于每个样本，通常 A1 越大，A2 越小，它们是相关的，两者之和接近 100%。随着样本单位的变化，Y、A1 和 A2 都可以拟合成三次关系（请查看下图）。

最初，我使用A1，A2及其交互项通过多元回归分析预测了Y，发现残差很小，但残差随样本单位的变化存在规律，也表现出了类似的三次函数的变化关系。如何理解这种情况，这是否意味着还有其他因素影响Y。（图1和图2是两个例子。）

还有其他合适的统计分析来证明A1和A2对Y的解释吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650231/how-to-prove-that-the-dependent-variable-is-explained-by-the-two-independent-var</guid>
      <pubDate>Mon, 01 Jul 2024 03:41:06 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么测试来计算加权平均比例？</title>
      <link>https://stats.stackexchange.com/questions/650227/what-test-should-i-use-for-weighted-mean-proportions</link>
      <description><![CDATA[我想知道组织中某个种族群体的“加权平均比例”（整体）与组织中某个种族群体的“加权平均比例”是否显著不同。部门内群组的比例。
我将该群组在 30 个组织中的比例分为两个级别：(a) 组织整体级别和 (b) 营销部门级别（在这些组织内）。
我创建了两个对象 - 每个级别一个。
prop.Overall &lt;- c(45.60, 38.98, 39.15, 40.09, 42.71, 44.68, 
43.43, 44.68, 45.60, 45.76, 45.85, 46.11, 
46.98, 47.83, 42.71, 49.22, 45.60, 51.54, 
53.08, 42.71, 56.67, 56.88, 57.54, 57.93, 
42.71, 63.13, 63.23, 66.25, 68.34, 68.42)

以上每一项都是特定组织中种族群体的比例。 （共 30 个组织）。
我在下面做了类似的事情，但针对的是这 30 个组织中市场营销部门级别的组比例。
prop.in.Mktg &lt;- c(40.78, 32.36, 41.33, 32.36, 28.11, 28.11, 
29.93, 28.11, 32.03, 44.12, 38.22, 28.87, 
27.19, 46.44, 41.93, 32.36, 32.99, 32.36, 
49.12, 32.36, 41.33, 39.55, 45.08, 42.23, 
35.45, 41.33, 41.33, 30.28, 26.65, 36.61)

使用这两个对象，我可以轻松找到频率、唯一条目并计算权重，然后计算该组在两个级别的加权平均比例。
我的问题：（这些对专家来说可能看起来很愚蠢，但还是要问：）
a) 在这个特殊情况下，（记住：我想知道组织中某个种族群体的“加权平均比例”是否与部门内某个种族群体的“加权平均比例”有显著差异...）——我是在进行均值统计检验还是比例检验？不知何故，这对我来说似乎比它应该的要复杂。 （我倾向于进行“单比例 Z 检验”——在这里这样做正确吗？）
b) 如果我使用“加权平均比例”，是否也需要使用“加权 SE”（围绕加权平均比例）？或者典型的标准误差就可以了？
注意：当然，这只是一个最小示例。差异权重在完整数据中确实很重要，使用加权平均比例进行比较很重要。然后，我们必须对营销部门以外的其他几个部门重复相同的测试。
如能澄清此处应使用哪种测试，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650227/what-test-should-i-use-for-weighted-mean-proportions</guid>
      <pubDate>Mon, 01 Jul 2024 00:56:25 GMT</pubDate>
    </item>
    <item>
      <title>导出 $k_i$ 以获得 $\hat{\beta} = \sum_{i=1}^n k_i y_i$，其中 $\hat{\beta}$ 是 OLS 估计量</title>
      <link>https://stats.stackexchange.com/questions/650226/deriving-k-i-for-hat-beta-sum-i-1n-k-i-y-i-where-hat-beta-is-t</link>
      <description><![CDATA[此问题与此帖子相关：证明截距的 OLS 估计量为 BLUE
由于我还不能直接在原始帖子下发表评论，所以我在这里发布我的问题。
在原始帖子中，回归模型定义为 $y_i = \alpha + \beta x_i + u_i$，而 $\beta$ 的 OLS 估计量自然表示为 $\hat{\beta}$。
然后 $\hat{\beta}$ 进一步定义为线性组合，形式为 $\hat{\beta} = \sum_{i=1}^n k_i y_i$，其中 $k_i = \frac{x_i - \bar{x}}{\sum_{i=1}^n (x_i - \bar{x})^2}$。
我假设 $\hat{\beta}=\frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2}$，我想知道 $k_i$ 是从所述线性组合直接得出的。]]></description>
      <guid>https://stats.stackexchange.com/questions/650226/deriving-k-i-for-hat-beta-sum-i-1n-k-i-y-i-where-hat-beta-is-t</guid>
      <pubDate>Mon, 01 Jul 2024 00:51:52 GMT</pubDate>
    </item>
    <item>
      <title>如何将多种采样技术应用于单个数据集？</title>
      <link>https://stats.stackexchange.com/questions/650217/how-can-i-apply-multiple-sampling-techniques-to-a-single-dataset</link>
      <description><![CDATA[相关： 如果我应用过采样，我应该如何分割我的数据集？
假设我有一个名为 my_dataset.dat 的数据集，其中包含三个类。该数据集存在类别不平衡，如下所示：
LabelColumn
A 459325
C 377954
B 241855

我想将随机过采样和SMOTE应用于此数据集。
我应该连续应用这两种采样技术吗？
即

将数据集拆分为train_data和test_data
对train_data应用随机过采样以获得ros_data
对ros_data应用SMOTE以获得ros_smote_data
使用 serial_ros_smote_data 训练 ML 模型

或者，我应该并行应用这两种采样技术吗？
即，

将数据集拆分为 train_data 和 test_data
对 train_data 应用 随机过采样 以获得 ros_data
对 train_data 应用 SMOTE 以获得 smote_data
将 ros_data 和 smote_data 连接到palallel_ros_smote_data
使用 palallel_ros_smote_data 训练 ML 模型

注意：需要权威答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/650217/how-can-i-apply-multiple-sampling-techniques-to-a-single-dataset</guid>
      <pubDate>Sun, 30 Jun 2024 19:18:32 GMT</pubDate>
    </item>
    <item>
      <title>运行多项式混合效应回归模型时出现错误：model.info \$wcount：$ 运算符对于原子向量无效[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650216/running-polynomial-mixed-effects-regression-model-with-error-model-info-wcount</link>
      <description><![CDATA[我正在使用 LCC 包 来估计两种方法随时间变化的一致性。模型估计类似于 lme，因为它基于混合效应模型。
我的数据框如下：
&#39;data.frame&#39;: 50000 obs. 5 个变量中的 5 个：
$ blood_gluc：数值 5.5 6.1 5.4 6.7 5.2 4.8 7.0 ...
$ method：具有 2 个水平“新”、“旧”的因子：2 2 2 2 2 2 2 2 2 2 ...
$ time：数值 1 2 3 4 5 6 7 8 9 10 ...
$ group：具有 2 个水平“0”、“1”的因子：2 1 2 1 1 2 2 1 2 1 ...
$ ID：具有 50 个水平“1”、“2”、“3”、“4”、...的因子：1 1 1 1 1 1 1 1 1 1 ...

我的 lcc 模型如下：
m1&lt;-lcc(data = df, subject = &#39;ID&#39;, resp = &#39;blood_gluc&#39;,
method = &#39;method&#39;, time = &#39;time&#39;, 
qf = 1, qr = 1, show.warnings = TRUE, components = TRUE, 
lme.control = list(opt=&#39;optim&#39;))

这个模型会运行，但是当我尝试添加&amp;;group&amp;; 的协变量时带有：
m2 &lt;- update(m1, covar =&#39;group&#39;)

我收到以下消息：

colnames&lt;-(*tmp*, value = paste(covar[[1]][i], levels(Data[, 中出现错误：尝试在少于两个维度的对象上设置“colnames”
model.info 中出现错误$wcount 中出现错误：$ 运算符对原子向量无效&quot;

我不确定如何更正此错误，因为此变量是我数据框中的一个因素。我猜想这与我的模型规范存在一些冲突。任何建议都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/650216/running-polynomial-mixed-effects-regression-model-with-error-model-info-wcount</guid>
      <pubDate>Sun, 30 Jun 2024 19:07:16 GMT</pubDate>
    </item>
    <item>
      <title>小数据集的相关性？</title>
      <link>https://stats.stackexchange.com/questions/650146/correlation-for-small-dataset</link>
      <description><![CDATA[我有一个 $x$ 和一个 $y$，我想找到它们的相关性以进一步了解它们之间的关系。不幸的是，我只有 $10$ 个点。我可以真诚地使用皮尔逊相关系数吗（在数据集大小的情况下，是否有普遍接受的规则来决定何时不使用它）？是否有某种推荐用于这种情况的替代相关性？
如果相关的话，我实际上有很多 $x$ 和 $y$，每个都有 $10$ 个点，我正在使用相关系数来总结我所看到的。通过图表进行目视检查会发现很多混合结果（一些结果看起来有点线性，并且给出约为$0.8$的皮尔逊相关系数，但大多数都有奇怪的非线性关系）。]]></description>
      <guid>https://stats.stackexchange.com/questions/650146/correlation-for-small-dataset</guid>
      <pubDate>Sat, 29 Jun 2024 04:01:59 GMT</pubDate>
    </item>
    <item>
      <title>对于给定平均值和标准差的正数据，偏度的下限是多少？</title>
      <link>https://stats.stackexchange.com/questions/650039/vintage-of-this-lower-bound-on-skewness-for-positive-data-with-given-mean-and-sd</link>
      <description><![CDATA[事实证明，对于任何具有给定平均值 μ 和标准差 σ 的严格正数据集，其偏度 $g_1$ 都有一个下限：
$$
g_1 &gt; \sigma/\mu - \mu/\sigma。
$$
虽然在最近的一些文献中，它被当作一个新的结果来讨论，但在我看来，它很可能相当古老——原因我在这篇 PubPeer 文章（其中还包含一个基本证明）中概述过。
来这里问这个问题时，我遇到了 2 个可以立即应用这个结果的问题：请参阅我的答案这里和这里。因此，这表明下限至少没有它应该的那么出名。但它可能是最近才出现的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650039/vintage-of-this-lower-bound-on-skewness-for-positive-data-with-given-mean-and-sd</guid>
      <pubDate>Thu, 27 Jun 2024 11:01:24 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中，结合 IV 方法对面板数据进行 Tobit 估计？</title>
      <link>https://stats.stackexchange.com/questions/649981/tobit-estimation-on-panel-data-in-combination-with-an-iv-approach-in-r</link>
      <description><![CDATA[我有面板数据（按年份划分的国家），并且我的因变量是左删失的（许多国家/地区的值是零，其他国家/地区的数字非常大）。因此，我认为我应该在面板数据上实施 Tobit 模型。此外，我怀疑存在反向因果关系，同时还需要实施 IV 方法。如何在 R 中执行此操作？如何确保我的标准错误计算正确？
理想情况下，我可以使用
a. 固定效应，
b. 池化，
c. 随机效应和
d.一阶差分。
# 第二阶段和第一阶段 IV 回归
fixed1_iv_2sls_IMP &lt;- ivreg(Y ~ X + W + factor(country) + 
factor(year) | Z + W + 
factor(country) + factor(year),
data = data)

# 提取残差
data$res_fixed1_iv_2sls_IMP &lt;- residuals(fixed1_iv_2sls_IMP)

# 残差的 Tobit 回归
tobit_model &lt;- censReg(res_fixed1_iv_2sls_IMP ~ X + W + 
factor(country) + factor(year),
left = 0, right = 100, data = data)

# Tobit 模型摘要
summary(tobit_model)

# HAC 标准错误
fixed1_iv_2sls_IMP_se &lt;- coeftest(fixed1_iv_2sls_IMP, 
vcov = vcovHC(fixed1_iv_2sls_IMP, type = &quot;HC3&quot;))[, 2]
]]></description>
      <guid>https://stats.stackexchange.com/questions/649981/tobit-estimation-on-panel-data-in-combination-with-an-iv-approach-in-r</guid>
      <pubDate>Wed, 26 Jun 2024 16:49:50 GMT</pubDate>
    </item>
    <item>
      <title>非递归 SEM 在 lavaan 中的特定间接影响</title>
      <link>https://stats.stackexchange.com/questions/649387/specific-indirect-effects-of-a-non-recursive-sem-in-lavaan</link>
      <description><![CDATA[我目前正在分析的结构方程模型包含一个间接循环，我无法找到一种直接的方法来计算它的具体间接影响。具有此问题的模型的一个最小示例是：
Y ~ yb*B
A ~ ax*X + ac*C
B ~ ba*A + bc*C
C ~ cb*B

现在我想知道，例如，A 对 Y 的具体增量间接影响。我知道，通常，lavaan 中的解决方案是使用 := 运算符来定义间接影响的路径。但是在这种情况下，我必须计算一个无穷和：
IE_A := ba*yb + ba*cb*ac*ba*yb + ba*cb*ac*ba*cb*ac*ba*yb + ...

我找到了一些关于如何基于系数矩阵手动计算该影响的论文，但计算这些标准误差会非常繁琐，我想知道是否还有其他方法可以做到这一点，例如我错过的 lavaan 中的功能或用于这些计算的另一个包。]]></description>
      <guid>https://stats.stackexchange.com/questions/649387/specific-indirect-effects-of-a-non-recursive-sem-in-lavaan</guid>
      <pubDate>Mon, 17 Jun 2024 15:10:15 GMT</pubDate>
    </item>
    <item>
      <title>如何在建模过程中衡量两种方法之间改进的显著性</title>
      <link>https://stats.stackexchange.com/questions/649384/how-to-measure-significance-of-improvement-between-two-methods-during-modeling</link>
      <description><![CDATA[大家好，我有两种开发模型的方法。我使用一组输入特征（set1）来训练模型1，另一组输入特征具有（set1 特征 + 额外的 set2 特征）。然后，我开发预测值和观察值之间的斯皮尔曼相关性来比较这两个模型，并发现具有更多特征的模型2 具有更好的相关性。
例如：使用模型1 的基因1 的相关性约为 0.56
使用模型2 的基因1 的相关性约为 0.62
因此，通过添加更多 set2 特征可以实现约 0.06 的改进

现在，我想了解这种约 0.06 的改进是否显着，或者这种改进是否是由于随机噪声/波动造成的
有人可以告诉我如何衡量每个基因模型改进的重要性，并衡量添加导致改进的 set2 特征是否是由于添加了更多信息特征而不是由于随机噪声/波动造成的。]]></description>
      <guid>https://stats.stackexchange.com/questions/649384/how-to-measure-significance-of-improvement-between-two-methods-during-modeling</guid>
      <pubDate>Mon, 17 Jun 2024 14:37:29 GMT</pubDate>
    </item>
    <item>
      <title>最小化 $KL(q_\phi|p)$ 而不是 $KL(p|q_\phi)$ 的理论依据是什么？</title>
      <link>https://stats.stackexchange.com/questions/649292/theoretical-justification-for-minimizing-klq-phip-rather-than-klpq-phi</link>
      <description><![CDATA[假设我们有一个真实但未知的分布$p$，分布在某个离散集上（即假设没有结构或领域知识），以及一个参数化的分布族$q_\phi$。
总的来说，我认为最小化$KL(p|q)$是有意义的。这表示当我们弄清楚真实分布是 $p$ 而不是 $q$ 时，我们获得的惊讶或信息量。
如果我们最小化 $KL(q|p)$，那么我们通常会做出过度自信的估计：我们原则上可以为根据 $p$ 很可能发生的事件分配零概率。
然而，在各种实际应用中（例如变分贝叶斯），我们最小化 $KL(q|p)$，我通常看到的理由是这更容易计算。
但是，是否有更原则的理论理由来最小化 $KL(q|p)$？ class=&quot;math-container&quot;&gt;$KL(q|p)$ 而不是 $KL(p|q)$? 如果我们真的对 $\text{argmin} KL(p|q)$ 感兴趣，那么即使假设它实际上不可计算，为什么我们要特别选择 $\text{argmin} KL(q|p)$？例如，如果后者只是一个估计量，那么是否有一些更好的估计量不具有 $\text{argmin} KL(q|p)$ 的过度自信属性？]]></description>
      <guid>https://stats.stackexchange.com/questions/649292/theoretical-justification-for-minimizing-klq-phip-rather-than-klpq-phi</guid>
      <pubDate>Sat, 15 Jun 2024 14:35:35 GMT</pubDate>
    </item>
    <item>
      <title>PCA中权重矩阵与载荷矩阵的区别</title>
      <link>https://stats.stackexchange.com/questions/648365/difference-between-weight-matrix-and-loading-matrix-in-pca</link>
      <description><![CDATA[目前我正在使用 PCA 技术（特别是稀疏 PCA 技术），但我的问题围绕着获取 PCA 中的权重矩阵。
此参考为 PCA 提供了以下表示：
$X = X W P&#39; + E$
其中 $X$ 是包含 $I$ 个观测值和 $J$ 个变量的分数的数据矩阵。假设我们选择有 $Q$ 个组件，则 $W$ 是 $J \times Q$ 权重矩阵，$P$ 是 $J \times Q$ 加载矩阵，$E$ 是 $I \times J$ 残差矩阵。他进一步提到，它通常用 $T = XW$ 表示（因此 $X = TP&#39; +E$）。
当我想检查矩阵时，我感到困惑。例如，scikit-learn 中的 PCA 仅提供加载矩阵，但对于我的工作，我还需要权重矩阵。其他实现（在本例中为稀疏 PCA 实现）也仅提供加载向量。
简而言之，我的问题，加载矩阵是否与权重矩阵相同（即 $W=P$？）。如果不是，我如何获得 $W$？有什么区别？]]></description>
      <guid>https://stats.stackexchange.com/questions/648365/difference-between-weight-matrix-and-loading-matrix-in-pca</guid>
      <pubDate>Fri, 31 May 2024 11:34:39 GMT</pubDate>
    </item>
    </channel>
</rss>