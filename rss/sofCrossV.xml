<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 19 Aug 2024 21:16:52 GMT</lastBuildDate>
    <item>
      <title>违反莱德曼界限以下因子模型的识别</title>
      <link>https://stats.stackexchange.com/questions/653029/violation-of-the-identification-of-factor-model-below-ledermann-bound</link>
      <description><![CDATA[在Bekker和ten Berge, 1997中，有人说，当因子个数低于ledermann界限时，独立误差$\sum$的方差几乎肯定是唯一确定的。
在论文中，作者指出，即使在ledermann界限以下，违反确定性的情况也有测度为零，直观上如何理解这个零测度集？]]></description>
      <guid>https://stats.stackexchange.com/questions/653029/violation-of-the-identification-of-factor-model-below-ledermann-bound</guid>
      <pubDate>Mon, 19 Aug 2024 21:01:14 GMT</pubDate>
    </item>
    <item>
      <title>在生存随机森林中，采样越大，误差越大</title>
      <link>https://stats.stackexchange.com/questions/653028/bigger-sampling-gives-bigger-errors-in-survival-random-forests</link>
      <description><![CDATA[我有一个包含 7 个分类变量的生存数据集。我使用随机生存森林（R 中的 randomForestSRC），并且尝试了不同的样本大小和树的数量。
在训练模型之前，我会随机抽取数据样本。总的来说，我有 180 万个数据点。我尝试了 1%、5%、10% 和 50% 的随机样本。由于相关的计算复杂性（每次训练都需要几个小时），我无法使用整个数据集。
我观察到，样本量越大，误差越大（以 1 减去 C 指数计算）。
以下是我的结果：

我的问题是为什么会发生这种情况。似乎，我用来训练随机森林模型的数据越多，误差就越大。
我的猜测是，我使用的数据越多，算法就越难找到解决方案，最终找到的答案就越不准确。]]></description>
      <guid>https://stats.stackexchange.com/questions/653028/bigger-sampling-gives-bigger-errors-in-survival-random-forests</guid>
      <pubDate>Mon, 19 Aug 2024 20:57:51 GMT</pubDate>
    </item>
    <item>
      <title>处理稀疏分类数据以进行贝叶斯优化</title>
      <link>https://stats.stackexchange.com/questions/653027/handling-sparse-categorical-data-for-bayesian-optimization</link>
      <description><![CDATA[我正在使用贝叶斯优化。在使用它来指导我的现实世界湿实验室化学实验的选择过程之前，我将拥有更大的灵活性，我想评估它在先前训练数据集上的有效性，在该数据集中，我追溯使用贝叶斯优化来评估它将如何导航景观。但是，由于以下原因，此训练数据集不是贝叶斯优化的典型用例：

一些变量是分类的；为了更好地表示分类变量而不是简单的独热编码，我在 tSNE 中提供了嵌入以更好地捕获相对差异。但是，该模型最终仍应建议提供的离散类别之一。

它是稀疏的。对于上下文，每行代表不同的化学混合物，其中为每种混合物测量单个功能目标值（即“target_value”）。我总共有 7 个不同的变量需要学习，即



component1_structure（3 个 tSNE 维度，但实际上是分类的）

component1_ratio（1 维，连续）

component1_weight（1 维，连续）

component2_structure（2 个 tSNE 维度，但实际上是分类的）

component2_ratio（1 维，连续）

component3_ratio（1 维，连续）

component4_ratio（1 维，连续）


这个组合空间理论上非常大。但是，我只有 1801 种不同的混合物（即这些变量的组合）具有功能数据；我希望模型严格探索/建议我拥有功能数据的这 1801 种混合物。

与顺序优化不同，每轮实验将有多种（即 10 种）不同的混合物需要测试。因此，如本文所述，我采用了克里金信度算法。
我的目标是证明使用贝叶斯优化搜索这些训练数据是有效的；因此，最终激励将其动态地用于实际的真实世界数据集（幸运的是，上面描述的第二个约束不适用）。尽管如此，我想设想一种方法来针对这些预先存在的训练数据使用贝叶斯优化。

这是 Colab 上的一个实现示例：https://colab.research.google.com/drive/19cY54d6M7jYl1fRDpL7oGVPF832JU247?usp=sharing
正如您在 Colab 上看到的，我目前的策略是使用加权距离度量来基本上识别最接近模型建议的唯一点（在 1801 个尚未选择的点中）。然而，我怀疑这是否是一个合理的方法。
关于如何改进此策略和/或代码实现的建议将非常有帮助。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653027/handling-sparse-categorical-data-for-bayesian-optimization</guid>
      <pubDate>Mon, 19 Aug 2024 20:50:56 GMT</pubDate>
    </item>
    <item>
      <title>比较记录的频率</title>
      <link>https://stats.stackexchange.com/questions/653023/compare-the-frequency-of-records</link>
      <description><![CDATA[我有如下记录：
\begin{array}{}
\hline
\textrm{2024-07-27 21:52:39} \\
\textrm{2024-07-27 21:54:15} \\
\textrm{...} \\
\textrm{2024-07-28 21:58:44} \\
\textrm{2024-07-28 22:01:15} \\
\textrm{...} \\
\textrm{...} \\
\hline
\end{array&gt;
我想比较这些记录在工作日和周末的频率。
这是我的方法：

设置一个间隔 - 对于现在 15 分钟并计算这些间隔内的记录
分成两组 a) 工作日，b) 周末
结果数据如下：

\begin{array}{c}
\hline
间隔 &amp; 计数 \\ 
\hline
\textrm{00:00:00} &amp; 3450 \\
\textrm{00:15:00} &amp; 2144 \\
\textrm{...} \\
\textrm{23:45:00} &amp; 4712 \\
\hline
\end{array&gt;
工作日和周末
现在我的问题是：

我应该“规范化”吗？数据，例如将工作日的计数除以 5，将周末的计数除以 2，因为现在收集的数据涵盖不同的天数？或者可能是不同天数的总数（我总是有一整天），例如，如果只是从星期二到星期日，那么我会将其除以 4（工作日总数）和 2（周末天数总数）？
我被建议使用双样本 Kolmogorov-Smirnov 检验来确定分布是否相同，那么使用如下方法是否正确？：

weekdays = [3450, 2144, ..., 4712]
weekends = [2147, 1544, ..., 3894]

_, p_value = scipy.stats.ks_2samp(weekends, weekdays)
if p_value &lt; 0.05:
print(&quot;工作日和周末的分布不一样。&quot;)
else:
print(&quot;分布相同&quot;)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/653023/compare-the-frequency-of-records</guid>
      <pubDate>Mon, 19 Aug 2024 19:16:51 GMT</pubDate>
    </item>
    <item>
      <title>glmmTMB 的预测函数</title>
      <link>https://stats.stackexchange.com/questions/653020/predict-function-for-glmmtmb</link>
      <description><![CDATA[我有以下模型：
mod &lt;- glmmTMB(cound_data ~ year-1 +(1|Site), ziformula = ~year-1, data = df, family = &quot;nbinom2&quot;)。我正在对 4 个不同年份和 38 个不同站点的计数数据进行建模。由于数据中存在许多零，我使用零膨胀模型。我的主要兴趣在于年份的影响，但我也对探索不同站点的结果感兴趣。
我使用代码获得固定效应：fixef(mod)，使用代码获得随机效应：ranef(mod)。
假设对于 2018 年，我的固定效应为 0.85，对于站点&quot;X&quot;，我的随机效应（截距）为 -0.18。根据我的理解，要获得站点&quot;X&quot;的预测值在 2018 年，我应该手动计算如下：exp(0.85-0.18)=1.95。
但是，当我使用 predict() 函数时：df$predicted_mean &lt;- predict(mod, newdata = df, re.form = NULL, type = &quot;response&quot;) 我获得了 2018 年站点 &quot;X&quot; 的不同值，例如 1.1。我不认为这种差异是由于舍入误差造成的。
predict() 函数计算的值与我的手动计算不同吗？它也考虑了 ziformula 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653020/predict-function-for-glmmtmb</guid>
      <pubDate>Mon, 19 Aug 2024 17:37:05 GMT</pubDate>
    </item>
    <item>
      <title>在成对 Wilcox 检验中选择 p 调整方法</title>
      <link>https://stats.stackexchange.com/questions/653019/choosing-p-adjustment-method-in-pairwise-wilcox-test</link>
      <description><![CDATA[我需要一些帮助来选择 p 调整方法，以在四个不同独立组的权重上进行成对 Wilcox 检验（使用 R）。
我一直在阅读有关不同方法的文章，并在 Google 上搜索了大量答案。我是统计学新手，不幸的是，其中许多方法变得过于复杂，但我的结论是方法取决于数据。所以我想知道是否有人可以根据我的数据给我一些提示或指导（见下面的测试结果）。
我已经测试了所有可用的方法（“bonferroni”、“holm”、“hochberg”、“hommel”、“BH”、“BY”），除了 Benjamini 和Yekutieli 方法。
如果有人知道根据数据选择方法的一般准则，请告诉我（我找不到任何准则）。
我的测试结果如下：
BH 方法（作为示例 - 除了 BY 之外，N-A 的 p.adj 值对所有值都相同）：
 .y. group1 group2 n1 n2 统计 p p.adj p.adj.signif
&lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
1 权重 S N 127 7696 478037 0.673 0.673 ns 
2 权重 S A 127 164 11542 0.113 0.226 ns 
3 权重 S T 127 195 11720 0.417 0.625 ns 
4 权重 N A 7696 164 711349 0.005 0.031 * 
5 权重 N T 7696 195 734472 0.613 0.673 ns 
6 权重 A T 164 195 14233 0.073 0.219 ns 

按方法：
 .y. group1 group2 n1 n2 统计 p p.adj p.adj.si
&lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
1 权重 S N 127 7696 478037 0.673 1 ns 
2 权重 S A 127 164 11542 0.113 0.554 ns 
3 权重 S T 127 195 11720 0.417 1 ns 
4 权重 N A 7696 164 711349 0.005 0.077 ns 
5 权重 N T 7696 195 734472 0.613 1 ns 
6 权重 A T 164 195 14233 0.073 0.536 ns 

请注意，组 N 的样本比其他组多得多。
两个问题：

哪一个我应该使用什么方法？
为什么 BY 不同？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653019/choosing-p-adjustment-method-in-pairwise-wilcox-test</guid>
      <pubDate>Mon, 19 Aug 2024 16:46:59 GMT</pubDate>
    </item>
    <item>
      <title>具有相同因变量的看似不相关的回归（SUR）对于时间序列有意义吗？</title>
      <link>https://stats.stackexchange.com/questions/653018/does-seemingly-unrelated-regressions-sur-with-the-same-dependent-variable-make</link>
      <description><![CDATA[SUR 对我来说是一个新概念，我的导师提到过它，我应该在研究中探索它。
我有一个变量（我们称之为 y），它是我的因变量。我还有 6 个控制变量和一个表示不同国家情绪的变量（比如说，sentiment_country_A 和 sentiment_country_B）。
我将所有这些变量都放在一个表中，它们的值在 6 年内每三个月出现一次（30 行）。
我想知道每个国家的情绪如何影响我的因变量。所以，我想创建这两个回归：
y ~ sentiment_country_A + 控制变量
y ~ sentiment_country_B + 控制变量
我尝试对它们运行 SUR，结果得到的 R 平方非常低（0.36），而且并非所有变量的 p&lt;0.05。残差也高度相关（~0.99）。
对于我的场景，这是正确的方法吗？我应该使用其他方法吗？我没有统计学背景，因此获得一些见解将非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653018/does-seemingly-unrelated-regressions-sur-with-the-same-dependent-variable-make</guid>
      <pubDate>Mon, 19 Aug 2024 16:42:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么 R 或 Eviews 中的 arima() 无法为 ARMA(1,1) 提供准确的 ML 估计量？为什么我的代码可以给出更好的估计？</title>
      <link>https://stats.stackexchange.com/questions/653013/why-arima-in-r-or-eviews-cant-provide-accurate-ml-estimators-for-an-arma1-1</link>
      <description><![CDATA[我模拟了一个遵循 ARMA(1,1) 模型的时间序列，具体来说就是 y(t)=2+0.8y(t-1)+e(t)-0.4e(t-1)。我根据精确似然函数编写了一些代码来执行最大似然估计 (MLE)。代码如下
library(numDeriv)
#生成一个时间序列
n &lt;- 50
set.seed(123)
epsilon=rnorm(n,0,1)
y=c(1:n)

for(i in 2:n)
{
y[i]=2+0.8*y[i-1]+epsilon[i]-0.4*epsilon[i-1]
}
#--------------------------------------------------------

llk &lt;- function(miu,alpha,beta,sigma2){
mean = miu /(1-alpha)
sigma_total = (1 + (alpha+beta)^2/(1-alpha)) * sigma2 #方差
log_likelihood &lt;- sum(dnorm(y, mean, sigma_total, log = TRUE)) 
return(-log_likelihood)
}

library(bbmle)
lower_bounds &lt;- c(miu = -Inf, alpha = -1, beta = -1, sigma2 = 0)
fit_norm &lt;- mle2(llk, start = list(miu=0.1,alpha=0.1,beta=-0.1,sigma2=0.25)
summary(fit_norm)

运行结果为：
系数：
估计标准误差z值Pr(z) 
miu 2.4832e+00 1.2019e+00 2.0661 0.03882 * 
alpha 7.2875e-01 1.2790e-01 5.6977 1.214e-08 ***
beta -9.0982e-05 2.3149e-01 -0.0004 0.99969 
sigma2 1.4708e+00 1.4708e-01 9.9998 &lt; 2.2e-16 ***

然而，当我使用 R 或 Eviews 中的 arima() 函数估算模型时，我注意到：（1）从两个软件包获得的结果之间有细微的差异。但我自己的结果和软件的结果之间存在显着差异。（2）与从软件获得的估计值相比，我的 MLE 估计更接近真实参数。“
为什么？
R 的结果是
arma_model&lt;-arima(y,order=c(1,0,1))
arma_model$coef
ar1 ma1 截距 
0.9493775 -0.1092253 7.7225015 

Eviews 的结果是
 变量系数 
C 7.513484
AR(1) 0.968957
MA(1) -0.199021
SIGMASQ 1.326798
]]></description>
      <guid>https://stats.stackexchange.com/questions/653013/why-arima-in-r-or-eviews-cant-provide-accurate-ml-estimators-for-an-arma1-1</guid>
      <pubDate>Mon, 19 Aug 2024 14:33:18 GMT</pubDate>
    </item>
    <item>
      <title>纪元 (epoch) 与数据复制相同吗？</title>
      <link>https://stats.stackexchange.com/questions/653012/are-epochs-the-same-as-data-duplication</link>
      <description><![CDATA[时期，即对原始数据重复训练的次数，对于神经网络来说是绝对必要的，因为神经网络的参数通常比原始实例多得多。
对于具有许多参数的其他 ML 方法，使用时期的方法论地位是什么？它们是否用于（我称之为）类技术，如随机森林？通过“方法论地位”，我隐藏了我的真实意图。也就是说，为什么不将时期用于普通的逻辑回归或决策树？为什么不将每个额外的时期视为数据增强，但使用相同的实例？如果建议重复数据以减少偏差，我觉得任何统计学家都会感到恶心。 ML 建模者会毫不犹豫地无限期地增加 epoch，直到训练/测试准确率开始变差（甚至可能到那时也不会变差！）。
那么

在传统预测模型中使用 epoch（基本重复实例）可以吗（只要考虑到过度拟合）？
另一方面，一个 epoch 是否应该成为 NN 训练的标准，或者更确切地说，将重复数据作为增强技术是否存在各种统计问题？

注意：这可能是一个很难回答的问题，因为它需要了解两种不同文化中的原理，即统计学和机器学习中的原理，即使它们本质上在做同样的事情。]]></description>
      <guid>https://stats.stackexchange.com/questions/653012/are-epochs-the-same-as-data-duplication</guid>
      <pubDate>Mon, 19 Aug 2024 14:12:29 GMT</pubDate>
    </item>
    <item>
      <title>回归中的独立指标变量在改变类别数量时变得显著</title>
      <link>https://stats.stackexchange.com/questions/653011/independent-indicator-variable-in-regression-becomes-significant-when-changing-t</link>
      <description><![CDATA[我正在使用二元响应变量运行逻辑回归。无论我是否使用家庭作为指示变量，家庭规模都会产生微小的正向但不显著的影响。
当将家庭规模视为具有 3 个级别的分类变量（单户、中型或大型家庭）来检查其是否有影响时，与排除的类别（单户）相比，两个包含的虚拟变量都具有很强的显著性和正向性。为什么会这样？
假设不仅家庭规模会对结果产生积极影响，而且家庭规模也会产生积极影响。我也将家庭规模视为分类变量，因为它在数据集中只能采用 7 个不同的值。
（我有大量观察值和其他预测因子。）
非常感谢您的帮助，br]]></description>
      <guid>https://stats.stackexchange.com/questions/653011/independent-indicator-variable-in-regression-becomes-significant-when-changing-t</guid>
      <pubDate>Mon, 19 Aug 2024 13:47:05 GMT</pubDate>
    </item>
    <item>
      <title>包含一些随机和固定效应因素的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/653005/linear-mixed-models-with-some-factors-included-as-both-random-and-fixed-effects</link>
      <description><![CDATA[我目前正在分析一项实地试验的数据，该试验最初设计用于双向方差分析。该试验涉及两个因素——土壤（2 个级别）和植物（2 个级别），在区块设计中重复 6 次。该试验包括三个采样时间和两个土壤深度的数据。
考虑到随时间和不同深度重复测量，我担心双向方差分析所需的独立性假设。虽然对每个采样和深度进行单独的双向方差分析是一种选择，但它会导致统计能力的损失，并阻碍不同采样和深度之间的交叉比较，这对我的研究至关重要。
为了应对这些挑战，我正在考虑使用具有以下结构的线性混合模型：
soil_carbon ~ (SOILPLANTDEPTH*TIME) + (1|BLOCK) + (1|PLOT) + (1|PLOT:SAMPLING) + (1|PLOT:DEPTH)
模型说明：
(SOILPLANTDEPTH*TIME)：该术语表示研究的固定效应之间的相互作用。
(1|BLOCK)：阻塞的随机效应
1|PLOT)：不同地块的随机效应
(1|PLOT:SAMPLING)：嵌套在 PLOT 中的 SAMPLING。考虑到采样总是在同一图中完成的事实。
（1|PLOT:DEPTH）：PLOT 内嵌套的 DEPTH。考虑到每个图中采样的深度不同。
具体问题：
a) 鉴于随机效应中的 SAMPLING 和 DEPTH 嵌套在 PLOT 内，这些因素是否也可以作为固定效应包含在模型中？我的目标是比较不同级别的深度和采样。它们应该同时包含在随机效应和固定效应中，还是只包含在随机效应中？
b) 为了检验固定效应的显著性，我正在考虑使用似然比检验来简化模型。这种方法适用于线性混合模型吗？
如果您对分析这些数据有任何其他建议或推荐，我将非常感谢您的见解。
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/653005/linear-mixed-models-with-some-factors-included-as-both-random-and-fixed-effects</guid>
      <pubDate>Mon, 19 Aug 2024 11:21:13 GMT</pubDate>
    </item>
    <item>
      <title>与连续和分类变量的 emtrends 或 emmeans 进行双向交互</title>
      <link>https://stats.stackexchange.com/questions/653021/2-way-interaction-with-emtrends-or-emmeans-for-a-continues-and-categorical-varia</link>
      <description><![CDATA[我有一个数据集，其中包含一个连续结果变量（好奇心）和三个独立变量：年龄和准确度（均为两个级别的分类），以及具有线性和二次项的置信度。这是一个与我的类似的示例数据集（id 是主题编号）：
 set.seed(300)
df&lt;-data.frame(
id=rep(c(1:10), each=100),
confidence=sample(1000, 100, replace=TRUE),
curry=sample(1000, 100, replace=TRUE),
age=as.factor(rep(c(1:2), each=500)),
accuracy=as.factor(sample(c(1,2), replace=TRUE, size=1000))
)

df &lt;- df %&gt;%
polypoly::poly_add_columns(confidence, degree = 2, prefix = &quot;c&quot;, scale_width = 101)

假设，我对此数据集进行分层贝叶斯回归拟合，如下所示（这里我将 chain 和 iter 设置为较低，以简化和提高速度）
reg_model = brm(curiosity~(c1+c2)*age*accuracy+
((c1 + c2) * accuracy | id),
data=df,
chains = 1, iter = 500)

这给了我以下结果。
describe_posterior(
reg_model,
test = &quot;pd&quot;, ci = 0.95, centrality = &quot;mean&quot;,
effects = &quot;fixed&quot;, diagnostic = NULL, distribution = TRUE
) %&gt;%
as_tibble() %&gt;% 
mutate(pd = percent(pd, .01)) %&gt;%
kbl(digits = 2,
caption = &quot;原始模型的参数&quot;) %&gt;% 
kable_classic(html_font = &quot;Arial&quot;, full_width = FALSE)


如您所见，此示例中没有显著的交互作用。但是，假设准确度和 c1 之间的交互作用是显著的。因此，我想跟踪这种交互作用，看看正确（准确度=1）和不正确（准确度=2）的 c1 斜率有何不同。也就是说，我想查看不正确的 c1 斜率，正确的 c1 分钟斜率。我使用了 emtreand 和 emmeans 但总是得到三向交互结果。这是我尝试过的。
emm &lt;- emtrends(
reg_model,
var = &quot;c1&quot;, by = c(&quot;accuracy&quot;),
at = list(confidence1 = 0, c2 = -32.9)
)
describe_posterior(
emm,
test = &quot;pd&quot;, ci = 0.95, centrality = &quot;mean&quot;, distribution = TRUE
) %&gt;%
bind_rows(
describe_posterior(
pair(emm),
test = &quot;pd&quot;, ci = 0.95, centrality = &quot;mean&quot;, distribution = TRUE
) 
) %&gt;% 
mutate(pd = percent(pd, .01)) %&gt;%
kbl(digits = 2,
caption = &quot;线性趋势对比&quot;) %&gt;% 
kable_classic(html_font = &quot;Arial&quot;, full_width = FALSE)

这给了我这个

如您所见，此表还包括年龄。有办法解决这个问题吗？非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653021/2-way-interaction-with-emtrends-or-emmeans-for-a-continues-and-categorical-varia</guid>
      <pubDate>Sun, 18 Aug 2024 23:41:37 GMT</pubDate>
    </item>
    <item>
      <title>如果获得的样本量比功效分析中显示的大得多，该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</link>
      <description><![CDATA[老实说，我们没想到这一点——毕竟我们一切都是按照剧本做的。
我们计划对一些心理问题进行研究，我们将问卷输入到 Qualtrics，在 G*Power 的帮助下，我们进行了功效分析以获得最小样本量，最后我们在互联网上发布了该研究的链接。然后样本量激增。几天后，我们检查了我们设法收集了多少观察结果，结果发现数量增加了四倍（所以我们匆忙停止收集数据）。功效分析表明 N = 500，我们得到了 N = 2000（当然是 2000 多）。开心吗？不，我们离幸福还很远。
问：现在我们有一个问题，如何处理超大样本（记住超强研究）。
想法是：

在第 500 次观察时截断——丢弃其余数据（听起来像是在浪费数据）
在第 500 次观察时截断，使用其余数据作为复制研究（听起来很狡猾，我们实际上没有进行复制研究，数据来自原始研究）
从我们的大数据（N = 2000）中抽取样本 - 不放回抽样，样本由N = 500 次观察组成（并丢弃休息）。
... 大家还有其他想法吗？你们遇到过这种情况吗？你们做了什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</guid>
      <pubDate>Sun, 18 Aug 2024 14:54:41 GMT</pubDate>
    </item>
    <item>
      <title>估计未知分布分位数的高置信上限</title>
      <link>https://stats.stackexchange.com/questions/652924/estimating-high-confidence-upper-bound-for-quantile-of-unknown-distribution</link>
      <description><![CDATA[我获得了一个分布未知的随机变量 $\mathbb R$ 上的 $X$。
我想确定获得 X 的 $1-\alpha$ 分位数的高置信上限 $\hat Q_{1-\alpha}$ 所需的最小样本量 $n$。
具体来说，我对高百分位数感兴趣，比如第 95 或第 99 个百分位数。
对于给定的置信水平 $1-\epsilon$，我想确保 $\Pr(\Pr(X&gt;\hat Q_{1-\alpha})&lt;\alpha) \geq 1-\epsilon$，而不管 $X$ 的分布如何。
虽然这个问题看起来很笼统，但我不确定如何使用经典统计方法来解决它。
直观地说，我会从我的样本中估计 $1-\alpha$ 分位数。
使用 bootstrapping 等方法，我也可以获得该参数的置信区间。
但是，我不确定如何根据基础样本的大小$n$准确量化这些方法的不确定性。
我的问题有两个方面。
首先，是否有统计工具可以回答这个问题并根据样本大小估计参数估计器的置信度？我似乎缺乏查找相关信息的统计背景。如果能提供来源或关键字来为我指明正确的方向，我将不胜感激。
其次，我知道这个问题可以用 PAC-Learning 的方法来解决。
但是，尽管这个问题相对普遍，但我也找不到使用这种界限的例子。
我怀疑有更好的工具来回答这个问题，或者这个问题一开始就不是很有趣，因为人们可以简单地假设某种分布，然后使用参数方法。
如果有人能告诉我这两个假设是否正确，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/652924/estimating-high-confidence-upper-bound-for-quantile-of-unknown-distribution</guid>
      <pubDate>Fri, 16 Aug 2024 11:09:53 GMT</pubDate>
    </item>
    <item>
      <title>非参数和半参数 cif</title>
      <link>https://stats.stackexchange.com/questions/652920/non-parametric-and-semi-parametric-cif</link>
      <description><![CDATA[我最近尝试使用 {survival 来深入了解竞争风险分析。
使用的数据来自 {survival。
library(survival)
library(ggsurvfit)

mgus2$etime &lt;- with(mgus2, ifelse(pstat==0, futime, ptime))
event &lt;- with(mgus2, ifelse(pstat==0, 2*death, 1))
mgus2$event &lt;- factor(event, 0:2, labels=c(&quot;censor&quot;, &quot;pcm&quot;, &quot;death&quot;))

我使用非参数方法计算了累积发生率函数，并得出了事件或死亡在时间的概率t。
可以通过 summary_mfit2$lower 和 summary_mfit2$upper 显示概率的置信区间。
此外，我绘制了累积发生率函数：
mfit2 &lt;- survfit(Surv(etime, event) ~ sex, data=mgus2)

summary_mfit2 &lt;- summary(mfit2, times=c(20))

&gt; summary_mfit2
调用：survfit(formula = Surv(etime, event) ~ sex, data = mgus2)

sex=F 
time n.risk n.event Pr((s0)) Pr(pcm) Pr(death)
20 540 93 0.852 0.0175 0.130

sex=M 
time n.risk n.event Pr((s0)) Pr(pcm) Pr(death)
20 621 137 0.818 0.0106 0.171

ggcuminc(mfit2, consequence = c(&quot;pcm&quot;)) +
add_confidence_interval()

接下来，我尝试了半参数方法，如下所示：
cfit1 &lt;- coxph(Surv(etime, event) ~ sex, mgus2, id=id)

dummy &lt;- expand.grid(sex = c(&quot;F&quot;, &quot;M&quot;))

csurv &lt;- survfit(cfit1, newdata = dummy)

temp &lt;- summary(csurv, times = c(20))

&gt; temp 
调用：survfit(formula = cfit1, newdata = dummy)

数据 1 
时间 n.风险 n.事件 Pr((s0)) Pr(pcm) Pr(死亡) 
20.0000 1161.0000 230.0000 0.8668 0.0111 0.1221 

数据 2 
时间 n.风险 n.事件 Pr((s0)) Pr(pcm) Pr(死亡) 
20.0000 1161.0000 230.0000 0.8388 0.0102 0.1510 

问题：

由于只使用了一个二元协变量（性别），使用半参数模型是否有意义方法还是应该使用非参数方法？
当有人描述使用原因特异性 cox ph 回归时，我的理解是这自动指的是半参数方法来估计风险 (CIF)，还是我错了？
非参数方法为时间 t 的风险提供 CI。如何为半参数方法推导出这些 CI？
如果推导出 CI，如何绘制半参数对象 csurv 的置信区间？函数 ggcuminc() 不起作用，使用基本函数 plot()（确实有效）很麻烦。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652920/non-parametric-and-semi-parametric-cif</guid>
      <pubDate>Fri, 16 Aug 2024 09:18:11 GMT</pubDate>
    </item>
    </channel>
</rss>