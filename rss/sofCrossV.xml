<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 16 Jan 2024 09:14:07 GMT</lastBuildDate>
    <item>
      <title>R 中的哪个包可用于离散选择实验？</title>
      <link>https://stats.stackexchange.com/questions/636965/what-package-in-r-to-use-for-a-discrete-choice-experiment</link>
      <description><![CDATA[我需要在 R 中创建一个离散选择实验（这是一个未标记的实验）。但是，我找不到适合我的实验的软件包来使其发挥作用。
选项由 8 个属性组成，每个属性有 2 个级别（2^8 = 256 个可能的选项）。现在，我需要生成一个部分因子设计（我设法在 R 中完成，例如使用 AlgDesign 包）。但是，如何生成由 2 个选项组成的选择集，使其仍然有效？我还需要实施阻止，因为我的受访者只会评估 1 或 2 个选择集。
我读过 Ngene 中的最佳正交差异设计，它能够处理属性由两个级别组成的事实。 R中有类似的东西吗？即使无法收集先前的数据，在这种情况下使用高效设计是否合适？
非常感谢您的帮助！
我尝试了 ExpertChoice 包，但我认为它不合适，因为我的属性由 2 个级别组成，并且我需要添加阻止。我也尝试过AlgDesign，但我不知道如何生成选择集（特别是当想要有主效果和双向交互效果时）。]]></description>
      <guid>https://stats.stackexchange.com/questions/636965/what-package-in-r-to-use-for-a-discrete-choice-experiment</guid>
      <pubDate>Tue, 16 Jan 2024 08:43:37 GMT</pubDate>
    </item>
    <item>
      <title>使用针对单个问题的混合效应逻辑回归模型比较大型数据集上的分类器系列</title>
      <link>https://stats.stackexchange.com/questions/636964/comparing-families-of-classifiers-on-large-datasets-using-mixed-effect-logistic</link>
      <description><![CDATA[我有一个包含大约 6000 张图像的测试数据集，我将在多类分类问题中尝试大约 25 个不同的神经网络。每个网络将属于大约 5 个系列（例如 ResNet、EfficientNet 等），并且每个系列内将有多个规模不断增大的网络（EfficientNetB0、B2 ... B7）。
每个测试集案例都属于一个类（这是一个多类问题），因此预测可能是正确的，也可能是错误的。
考虑到模型大小，查看家庭性能是否存在差异的最佳统计方法是什么？
我没有在线性模型中使用正确百分比（并且只有 n_networks 结果），而是考虑将每个答案视为正确/不正确并使用多级逻辑回归模型，并且每个网络都使用相同的测试用例进行测试，将案例作为随机效应：
模型 &lt;- glmer( Correct_prediction ~ model_size + (1 | model_family/specific_model) + (1 | image_id),
               数据 = 数据，族 = 二项式）

但是我以前没有见过这种方法。另外，由于它是随机效应，而不是固定效应，我认为它不允许我比较各个网络系列？
相反，我可以做这样的事情：
模型 &lt;- glmer( Correct_prediction ~ model_family + model_size + (1 | model_family/specific_model) + (1 | image_id),
               数据 = 数据，族 = 二项式）

其中我将 model_family 包含为固定效应和随机效应。
最后，我几乎可以肯定 model_size 将具有非线性关系（小型到中型模型将提供很大的提升，但中型到大型模型的提升较小），因此我正在考虑使用受限三次样条对其进行建模，例如所以：
&lt;前&gt;&lt;代码&gt;库(rms)
图书馆(lme4)
库（lmerTest）
dat &lt;- datadist(数据)
选项(datadist = &#39;dat&#39;)

模型 &lt;- glmer(正确预测 ~ rcs(model_size, 3) + model_family + (1 | model_family/specific_model) + (1 | image_id),
               数据 = 数据，族 = 二项式）

这看起来是一个明智的方法吗？正如我所说，我还没有真正看到人们使用逻辑回归来计算测试成绩，但对我来说，这感觉是一种非常合乎逻辑的（抱歉）方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/636964/comparing-families-of-classifiers-on-large-datasets-using-mixed-effect-logistic</guid>
      <pubDate>Tue, 16 Jan 2024 07:48:49 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归|变化的暴露变量</title>
      <link>https://stats.stackexchange.com/questions/636963/logistic-regression-varying-exposure-variable</link>
      <description><![CDATA[我有一些数据，其中我跟踪了一些人 365 天。我有一个响应变量，它是 1 或 0。我一直在成功地进行逻辑回归。
现在数据发生了变化，一些客户突然出现了不同的暴露（少于 365 天）。我的经理说我仍然可以做逻辑回归，我只需要考虑不同的暴露，即将暴露作为模型中的解释变量。我觉得这不对，我说这就是 cox 回归/生存分析的用途，但我无法真正争论为什么这是错误的按照建议的方式进行操作。
我的经理错了吗？如果是的话：有人可以解释一下原因吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636963/logistic-regression-varying-exposure-variable</guid>
      <pubDate>Tue, 16 Jan 2024 07:18:22 GMT</pubDate>
    </item>
    <item>
      <title>证明两个正交对比不相关</title>
      <link>https://stats.stackexchange.com/questions/636961/prove-two-orthogonal-contrasts-are-uncorrelated</link>
      <description><![CDATA[我正在阅读一些方差分析笔记，并且在证明两个正交对比不相关时遇到问题。
这是我尝试过的：
假设 $\bar X_i, i=1,\dots,n$ 不相关。假设我们有两个对比
$$
C_1 = \sum_i a_i \bar X_i, \quad C_2 = \sum_i b_i \bar X_i, \quad
$$
我们有
\begin{align*}
\text{cov}(C_1, C_2) &amp;= \text{cov}(\sum_i a_i \bar X_i, \sum_j b_j X_j) \\
&amp;= \sum_{i} \sum_j a_i b_j \text{cov}(\bar X_i, \bar X_j) \\
&amp;= \sum_{i} a_i b_i \text{var}(\bar X_i)。
\end{对齐*}
因此，$C_1$ 和 $C_2$ 不相关当且仅当 $ \sum_{i} a_i b_i \text{var}(\bar X_i) = 0$。
但是根据对比和正交对比的定义，我们只知道
$$\sum_{i} a_i = 0, \quad \sum_{i} b_i = 0, \quad \sum_{i} a_i b_i =0$$
我该怎么走？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/636961/prove-two-orthogonal-contrasts-are-uncorrelated</guid>
      <pubDate>Tue, 16 Jan 2024 07:00:38 GMT</pubDate>
    </item>
    <item>
      <title>测量具有不同 bin 计数的 KDE 分布之间的距离</title>
      <link>https://stats.stackexchange.com/questions/636960/measuring-the-distance-between-kde-distributions-with-different-bin-counts</link>
      <description><![CDATA[我有两个 KDE 发行版，每个发行版都有不同数量的 bin。我想有效地比较它们，我想知道是否有推荐的技术。我应该统一垃圾箱的数量吗？如果是的话，最好的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/636960/measuring-the-distance-between-kde-distributions-with-different-bin-counts</guid>
      <pubDate>Tue, 16 Jan 2024 05:37:37 GMT</pubDate>
    </item>
    <item>
      <title>A/B 测试所需的最小样本量</title>
      <link>https://stats.stackexchange.com/questions/636959/minimum-sample-size-needed-for-a-b-testing</link>
      <description><![CDATA[词汇表：

样本 SD = 您当前拥有的样本（对照组）的标准差。我们还没有开始治疗，所以我们不应该使用治疗组的SD。
MDE＝“最小可检测效应” = 估计您愿意检测到的最小改进。

&lt;小时/&gt;
问题：
我得到了巨大的价值，但不知道为什么。
获得治疗组和对照组所需的最小样本量的快捷公式是：
16*sample_SD^2 / MDE^2

感兴趣的指标是购买次数。
对照组的sample_SD 是 185 次购买。
MDE 是购买量增加 3%。

如果我将这些数字代入，我会得到每组所需的样本数量非常高，超过 6 亿个。我在这里做错了什么？
&lt;前&gt;&lt;代码&gt;sd_sample = 185
平均DE = 0.03
每个组中所需的n_n =（16 * sd_sample ** 2）/（mde ** 2）
每个组中必需的_n_n = 608632862.6163108

]]></description>
      <guid>https://stats.stackexchange.com/questions/636959/minimum-sample-size-needed-for-a-b-testing</guid>
      <pubDate>Tue, 16 Jan 2024 05:33:01 GMT</pubDate>
    </item>
    <item>
      <title>从具有非参数累积分布函数的多元相关数据生成样本</title>
      <link>https://stats.stackexchange.com/questions/636958/generate-samples-from-multivariate-correlated-data-which-have-non-parametric-cum</link>
      <description><![CDATA[我有 40 个样本，其中包含 6 个变量的信息（因此是 40x6 数据矩阵）。每个变量（列）都有一个基于 40 个值的累积分布函数（边际分布），该函数不是高斯分布，而存在将变量相互关联的相关矩阵（我正在使用 Spearsman rho ）。我想做的是为每个变量（1000x6的数据矩阵）生成1000个样本，满足原始采样数据集的相关值，并遵循每个变量的原始40个样本的经验累积分布函数。我的理解是我可以使用 copula 来达到这个目的。所以，我想到的步骤是：
计算每个变量的平均值和标准差，并为给定的相关性 (Spearsman rho) 矩阵生成高斯边缘分布。高斯变量的值不限于[0,1]。
接下来，将每个变量的边际分布转换为单位分布（每个变量的值范围位于 [0,1] 范围内）。这是在不改变数据排序的情况下完成的，因此排名相关系数保持不变。
最后，我使用初始数据集（40x6 数据矩阵）的累积分布函数来生成每个变量的模拟值，特别是通过分位数匹配（对于单位变量的特定值，我假设等于累积分布值（垂直轴），我通过查找与此 cdf 值对应的 x 轴上的值来找到模拟值）。
上述描述准确吗？抱歉，描述很长，我对此很陌生，我不太有信心跳过部分讨论。]]></description>
      <guid>https://stats.stackexchange.com/questions/636958/generate-samples-from-multivariate-correlated-data-which-have-non-parametric-cum</guid>
      <pubDate>Tue, 16 Jan 2024 04:59:40 GMT</pubDate>
    </item>
    <item>
      <title>平面上 N 维高斯边缘化的概率，以及平面上点的可能性</title>
      <link>https://stats.stackexchange.com/questions/636957/probability-of-n-dim-gaussian-marginalized-over-a-plane-and-a-likelihood-of-a-p</link>
      <description><![CDATA[上下文：我想将一系列坐标（每个坐标都有其不确定性）拟合到（超）平面。我试图推导出在平面上观察到的一点的可能性。我需要验证我所做的事情，如果可能的话，我需要一个可以引用的来源。
假设 $\vec{x}$ 位于 $\mathbb{R}^N$ 服从高斯分布，
$$
\vec{x}\sim\mathcal{N}(\vec{\mu},\mathbf{\Sigma})
$$
和空间中的一个平面给出为
$$\hat{n}\cdot\vec{x}=k$$
Q1。如果我对平面上所有点的概率分布进行积分，我将得出点和平面之间的（有符号）距离 $h$，如下
$$
h\equiv\hat{n}\cdot\vec{x}-k\sim \mathcal{N}(-k+\hat{n}\cdot\vec{\mu},\hat{n}\cdot\mathbf {\Sigma}\cdot\hat{n})
$$
这是正确的吗？我使用多元高斯的属性导出它维基百科；对坐标进行仿射变换，使第一个轴的坐标变为 $r$，然后通过与 $\vec{e}_1$。
第二季度。假设概率 $P(h(\vec{x})|\hat{n},k,\vec{\mu},\mathbf{\Sigma})$ Q1 中的  是正确的。在回归的背景下，假设我们观察到 $\vec{\mu}$ 上的一个点，其协方差为 $\mathbf {\Sigma}$。是
$$
P(h(\vec{x})=0|\hat{n},k,\vec{\mu},\mathbf{\Sigma})
$$
确定平面的参数可能性的正确表达式，$\hat{n}, k$？]]></description>
      <guid>https://stats.stackexchange.com/questions/636957/probability-of-n-dim-gaussian-marginalized-over-a-plane-and-a-likelihood-of-a-p</guid>
      <pubDate>Tue, 16 Jan 2024 03:50:37 GMT</pubDate>
    </item>
    <item>
      <title>带有回归边际的参数联结函数</title>
      <link>https://stats.stackexchange.com/questions/636956/parametric-copulas-with-marginals-that-are-regressions</link>
      <description><![CDATA[在《Copulas 依赖建模》（Harry Joe）中，我正在努力解释语句的含义。第5.1章指出：
&lt;块引用&gt;
copula 的参数推理
对于使用联结函数进行依赖建模，最常见的是使用参数联结函数系列。 copula 模型参数推理方法的优点如下。

它们比非参数方法更容易通过数字实现。
它们可以在高维度中使用。
通过使用似然度，连续、离散或混合响应变量的理论相同，并且可以适应删失或缺失的数据。
它们可以适应回归或时间序列模型的单变量边际，或时变依赖性。协变量可以包含在单变量或相关参数中。
它们可以轻松用于比较竞争模型。


我的问题涉及第四点，特别是它们可以适应回归的单变量边距。这似乎意味着联结规范需要一些额外的参数化，因为边际现在是回归，依赖于协变量。
直观上，我可以理解这一点，因为协变量将决定边际的实际分布，因此连接函数也需要对此做出响应。然而，我也可以凭直觉知道，联结已经使用边际回归的数据进行了估计，因此已经从协变量中捕获了这些信息。
也就是说，用于估计 copula 的 $(u,v)$ 已经反映了这些边际分布的协变量。联结规范是否可以不考虑这些协变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/636956/parametric-copulas-with-marginals-that-are-regressions</guid>
      <pubDate>Tue, 16 Jan 2024 03:23:52 GMT</pubDate>
    </item>
    <item>
      <title>为三重交互编写自定义计划对比背后的逻辑</title>
      <link>https://stats.stackexchange.com/questions/636955/logic-behind-writing-custom-planned-contrasts-for-a-triple-interaction</link>
      <description><![CDATA[我有一个具有三重交互作用的模型，涉及两个因素和一个连续变量。
可复制的示例：
# %%%
设置.种子(1234)

make_times &lt;- 函数(n, n_per_group) {
  向量&lt;-c()
  for (i in 1:n) {
    one_increment_sequence &lt;- seq(0, to = n_per_group - 1)
    增量向量 &lt;- c(0, c(runif(n_per_group - 1, 0, 1)))
    向量 &lt;- c(向量, one_increment_sequence +increment_vecor)
  }
  返回（向量）
}

# 定义数据集
数据集 &lt;- data.frame(
  结果 = rnorm(60),
  组＝rep(c(“A”、“B”、“C”)，每个＝20)，
  性别=rep(c(“M”,“F”),每个=15,次=4),
  TimeFromBaseline = make_times(20, 3), # 连续
  Extra = Sample(c(&quot;Foo&quot;, &quot;Bar&quot;), 60, Replace = TRUE) # 固定协变量
）
数据集$Group &lt;-因子(dataset$Group,levels = c(“A”,“B”,“C”,“D”) ）
数据集$Sex &lt;- 因子(dataset$Sex, level = c(&quot;M&quot;, &quot;F&quot;))
数据集$Extra &lt;-因子(dataset$Extra,levels = c(“Foo”,“Bar”))
字符串（数据集）

# 拟合模型
模型 &lt;- lm(结果 ~ 性别 * 组 * TimeFromBaseline + Extra, 数据 = 数据集)
摘要（模型）

# 绘制模型
sjPlot::plot_model(model, type = &quot;pred&quot;, terms = c(&quot;TimeFromBaseline&quot;, &quot;Group&quot;, &quot;Sex&quot;))


模型中有 13 个系数。我的目标是定义长度为 13 的对比向量来测试某些假设。 这是因为我将进行大脑体素分析，并且该软件需要预先手动指定计划的对比
我对 R 默认使用的处理编码方案中每个系数代表的内容有了基本的了解：

Beta0 是参考水平的平均值（在本例中为 A 组，男性，在截距处）
Beta1 是相对于基本参考水平的增量，改变男性 -&gt; 男性。女
等等

因此，大概，测试 A 组男性在零时间（截距）时是否具有非零结果的对比向量将是：
c(1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
或者描述 B 组女性斜率的对比向量为
c(1, 1, 1, 0, 0.04, 0, 1, 0, -1.35, -0.36, 0, 1.86, 0)
对吗？
如果是这样，对我来说困难的是理解如何构建假设检验对比矩阵。
例如，这里的对比矩阵（大概有 13 列）将检验假设：三重相互作用大于零
^ 谁能概述一下如何构造这样的对比矩阵？
为 emmeans 或 lsmeans 或 multcomp 等包提供的对比是短向量，专门针对为其库焦点对象提供的内容就像emmGrid。这不是我要找的。
P.S 如果有一个 R 库可以提供这些“完整”的内容或“先验”。模型中的对比矩阵，例如 model.matrix 如何提供设计矩阵，这会让我很高兴。]]></description>
      <guid>https://stats.stackexchange.com/questions/636955/logic-behind-writing-custom-planned-contrasts-for-a-triple-interaction</guid>
      <pubDate>Tue, 16 Jan 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>分子的 3 次方互信息真的存在吗？</title>
      <link>https://stats.stackexchange.com/questions/636954/does-mutual-information-by-the-power-of-3-for-the-numerator-really-exist</link>
      <description><![CDATA[我目前正在尝试使用互信息 (MI) 来衡量搭配强度。 MI 为专有和不常见的单词提供了优势。正如 Brezina (2018) 所说，在衡量搭配强度时，可以使用互信息，公式如下：
Log2(O11/E11)，
地点：
O11=搭配频率
E11 = 预期搭配频率
除了上述MI公式外，作者还给出了MI3公式，该公式与MI几乎相似，但它赋予了O11 3的幂。这个公式为排他性和频繁出现的单词提供了优势。公式如下：
Log2(O11^3/E11)
谁能向我解释一下军情三处中的三的幂叫什么？我试图在网上找到确切的公式，但没有找到。这是统计学中的一般做法吗？为什么要给出三的幂来导致这样的变化，即使 MI 对频繁和排他的搭配更加敏感？
我希望我的问题很清楚，提前谢谢！
参考：
布雷齐纳，V. (2018)。语料库语言学统计：实用指南。剑桥大学出版社。]]></description>
      <guid>https://stats.stackexchange.com/questions/636954/does-mutual-information-by-the-power-of-3-for-the-numerator-really-exist</guid>
      <pubDate>Tue, 16 Jan 2024 02:27:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 Z 分数将每周结果与平均值进行比较，然后确定一个人与平均值相比的平均表现如何</title>
      <link>https://stats.stackexchange.com/questions/636953/comparing-weekly-results-to-a-mean-using-z-scores-then-determining-how-well-a-p</link>
      <description><![CDATA[我目前领导着一组传教士，我想了解每位传教士与所在地区的平均水平相比表现如何。每个区域都有其执行情况的历史数据。假设记录的统计数据之一是结识新朋友。我计算过：

在特定区域结识的平均新朋友数量
在特定区域结识的新朋友的标准差
当前传教士在特定区域每周结识的新朋友的 Z 分数，假设呈正态分布

我现在想要计算当前传教士在其特定领域高于或低于平均值的平均表现。我尝试过对传教士的 Z 分数进行平均，但到目前为止我认为它没有给我任何有用的信息。计算传教士对其所在地区的影响的更好方法是什么？也许是 t 检验？]]></description>
      <guid>https://stats.stackexchange.com/questions/636953/comparing-weekly-results-to-a-mean-using-z-scores-then-determining-how-well-a-p</guid>
      <pubDate>Tue, 16 Jan 2024 01:43:49 GMT</pubDate>
    </item>
    <item>
      <title>证明正态分布的可能性不是非凸的</title>
      <link>https://stats.stackexchange.com/questions/636950/proving-that-the-likelihood-of-a-normal-distribution-is-not-non-convex</link>
      <description><![CDATA[作为学习练习（从这里开始为什么可能性是指数族凸函数？），我想尝试证明正态分布的似然函数不是非凸的。
这是正态分布及其（对数）可能性：
$$
f(x; \mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{ -\frac{(x-\mu)^2}{2\sigma^ 2} }
$$
$$
L(\mu, \sigma^2 | x_1, x_2, ..., x_n) = \prod_{i=1}^{n} f(x_i; \mu, \sigma)
$$
$$L(μ, σ^2 | x) = -\frac{n}{2} \log(2π) - \frac{n}{2} \ log(σ^2) - \frac{1}{2σ^2} Σ_{i=1}^{n} (x_i - μ)^2$$
现在，为了证明似然函数不是非凸的，我需要证明其 Hessian 矩阵（二阶导数矩阵）的所有特征值要么全部为正，要么全部为负。如果特征值既为正又为负，则该函数是非凸的。
首先我计算雅可比行列式（一阶导数）：
$$\frac{∂L}{∂μ} = \frac{1}{σ^2} Σ_{i=1}^{n} (x_i - μ)$$
$$\frac{∂L}{∂σ^2} = -\frac{n}{2σ^2} + \frac{1}{2(σ^2)^ 2} Σ_{i=1}^{n} (x_i - μ)^2$$
$$J = [\frac{1}{σ^2} Σ_{i=1}^{n} (x_i - μ), -\frac{n {2σ^2} + \frac{1}{2(σ^2)^2} Σ_{i=1}^{n} (x_i - μ)^2]$$
现在，我计算 Hessian 矩阵：
$$\frac{∂^2L}{∂μ^2} = -\frac{n}{σ^2}$$
$$\frac{∂^2L}{∂(σ^2)^2} = \frac{n}{2(σ^2)^2} - \压裂{1}{(σ^2)^3} Σ_{i=1}^{n} (x_i - μ)^2$$
$$H = [-\frac{n}{σ^2}, 0; 0, \frac{n}{2(σ^2)^2} - \frac{1}{(σ^2)^3} Σ_{i=1}^{n} (x_i - μ)^2 ]$$
从这里，我计算特征值 - 对于矩阵 $A$，特征值由 $det| 给出A-\lambda I|$ 。在 2x2 矩阵（我们的 Hessian 矩阵）中，我们有：
$$
A = \begin{bmatrix}
一个&amp;乙\
和d
\end{b矩阵}
$$
$$
\lambda^2 - \lambda(a+d) + (ad-bc) = 0
$$
此函数将有两个根 $\lambda_1$ 和 $\lambda_2$：
$$
\lambda_1 = -\frac{n}{\sigma^2}, \quad \lambda_2 = \frac{n}{2(\sigma^2)^2} - \frac{1}{(\sigma^2) ^3} \sum_{i=1}^{n} (x_i - \mu)^2
$$
目前尚不清楚 $\lambda_2$ 中的第二项是否大于 $\ 中的第一项lambda_2$。如果第二项确实大于第一项，则 $\lambda_2$ 将为负数。
如果我们使用这样的论点：
$$
s^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2
$$
$$
n s^2 = \sum_{i=1}^{n} (x_i - \mu)^2
$$
$$E(s^2) = \sigma^2$$
然后我们可以说：
$$E[(x_i - μ)^2] = nσ^2$$
$$\lambda_2 = \frac{n}{2(\sigma^2)^2} - \frac{1}{(\sigma^2)^3} n\sigma ^2 = \frac{n}{2(\sigma^2)^2} - \frac{n}{(\sigma^2)^2} = -\frac{n}{2} \frac{1} {(\sigma^2)^2}$$
因此，$\lambda_2$ 近似为负。
因此，我们可以说两个特征值均为负，这表明似然函数是凹的。据我了解，从优化的角度来看，优化凹函数和优化凸函数是一样的。
令人担忧的情况是当特征值既为正又为负时，表明该函数是非凸的（即多个局部最小值）并且是一个潜在的难以优化的问题。
我的分析正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636950/proving-that-the-likelihood-of-a-normal-distribution-is-not-non-convex</guid>
      <pubDate>Tue, 16 Jan 2024 00:48:27 GMT</pubDate>
    </item>
    <item>
      <title>在序数回归累积链接模型中，何时使用尺度效应（与/使用随机截距）</title>
      <link>https://stats.stackexchange.com/questions/636947/in-ordinal-regression-cumulative-link-models-when-to-use-scale-effects-versus</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636947/in-ordinal-regression-cumulative-link-models-when-to-use-scale-effects-versus</guid>
      <pubDate>Tue, 16 Jan 2024 00:14:38 GMT</pubDate>
    </item>
    <item>
      <title>每年加权平均值[关闭]</title>
      <link>https://stats.stackexchange.com/questions/636943/weighted-averages-per-year</link>
      <description><![CDATA[我有按年份划分的制造缺陷数据和每年的样本量。我正在尝试创建一个加权 Yes/No ，按 N 加权。
 是 否 N 年
  1402 (92.5%) 114 (7.5%) 1516 2018
  1697 (93.1%) 126 (6.9%) 1823 2019
  1023 (91.5%) 96 (8.5%) 1119 2020
  1302 (92.43%) 108 (7.57%) 1410 2021
  1204 (92.49%) 98 (7.51%) 1302 2022

我知道这就是我们创建权重的方式。
 是 否 N 重量年份
  1402 (92.5%) 114 (7.5%) 1516 1516/7170=0.211 2018
  1697 (93.1%) 126 (6.9%) 1823 1823/7170=0.254 2019
  1023 (91.5%) 96 (8.5%) 1119 1119/7170=0.156 2020
  1302 (92.43%) 108 (7.57%) 1410 1410/7170=0.196 2021
  1204 (92.49%) 98 (7.51%) 1302 1302/7170=0.181 2022

不确定此后如何继续。
数据 &lt;- data.frame(
  是 = c(1402, 1697, 1023, 1302, 1204),
  否 = c(114, 126, 96, 108, 98),
  N = c(1516, 1823, 1119, 1410, 1302),
  年份 = c(2018, 2019, 2020, 2021, 2022)
）

Total_sample_size &lt;- sum(data$N)
数据$权重&lt;-数据$N /total_sample_size

非常感谢任何建议。提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/636943/weighted-averages-per-year</guid>
      <pubDate>Mon, 15 Jan 2024 22:01:26 GMT</pubDate>
    </item>
    </channel>
</rss>