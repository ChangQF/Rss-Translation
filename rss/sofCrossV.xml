<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 16 Dec 2024 15:19:07 GMT</lastBuildDate>
    <item>
      <title>使用SMOTEENN后数据不平衡</title>
      <link>https://stats.stackexchange.com/questions/658812/imbalanced-data-after-using-smoteenn</link>
      <description><![CDATA[我正在研究分类问题，我的初始数据不平衡。我使用 SMOTE + ENN 算法来修改数据。应用 SMOTE 后，数据变得平衡，但应用 ENN 后，数据再次变得不平衡。我该怎么办？
我知道 ENN 用于删除异常数据点，但我不知道在 SMOTE 之后是否应该使用 ENN]]></description>
      <guid>https://stats.stackexchange.com/questions/658812/imbalanced-data-after-using-smoteenn</guid>
      <pubDate>Mon, 16 Dec 2024 14:43:56 GMT</pubDate>
    </item>
    <item>
      <title>AB 测试中是否应使用重采样？[重复]</title>
      <link>https://stats.stackexchange.com/questions/658810/should-resampling-be-used-in-an-ab-test</link>
      <description><![CDATA[我有 14,000 个用户的样本，其中 7,000 个为对照组，7,000 个为实验组。所讨论的指标是数值。两个组都呈伯努利分布的右偏态。
虽然一种可能的解决方案是使用 t 检验替代方案，但由于非正态性，这是一个下游决策，因此从程序上讲，执行重新采样的决定应该在决定使用哪种测试之前进行。我将完全忽略要使用的测试类型。
相反，这个问题涉及是否执行重新采样的初步经验法则。是否应该将重新采样应用于此 AB 测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/658810/should-resampling-be-used-in-an-ab-test</guid>
      <pubDate>Mon, 16 Dec 2024 13:05:14 GMT</pubDate>
    </item>
    <item>
      <title>灾难性遗忘发生在服务器，但本地不会发生</title>
      <link>https://stats.stackexchange.com/questions/658809/catastrophic-forgetting-in-the-server-but-not-in-local</link>
      <description><![CDATA[我不明白为什么会发生这种情况。我正在非 IID MNIST 数据集上训练联邦学习算法（FedAvg，学习率为 5e-2）。当我在本地机器上运行实验时，该算法的最终准确率达到 98%。但是，当我在具有 GPU 访问权限的服务器上运行它（甚至仅使用 CPU）时，准确率中途下降到 10%，并一直停留在那里直到最后。但是，损失值似乎在波动。我在客户端上使用完全相同的数据集分布和相同的种子。是什么原因造成的？]]></description>
      <guid>https://stats.stackexchange.com/questions/658809/catastrophic-forgetting-in-the-server-but-not-in-local</guid>
      <pubDate>Mon, 16 Dec 2024 12:58:05 GMT</pubDate>
    </item>
    <item>
      <title>套索和交叉验证：模型选择</title>
      <link>https://stats.stackexchange.com/questions/658807/lasso-and-cross-validation-model-selection</link>
      <description><![CDATA[对交叉发布表示歉意
我开始使用 Lasso 和交叉验证进行模型选择，以使用线性模型解释因变量，但我不明白为什么所选模型中的所有 p 值系数都不低于 0.05：
我使用以下步骤将此示例发布在：
https://www.stata.com/features/overv...on-prediction/
代码：

sysuse auto, clear
splitsample, generate(sample) nsplit(2) rseed(1234)

lasso linear mpg i.foreign i.rep78 headroom weight turn gear_ratio price trunk length Displacement if sample == 1, Selection(bic)
estimates store bic

lasso linear mpg i.foreign i.rep78 净空重量转动齿轮比价格后备箱长度位移如果样本 == 1
估计存储 cv

lasso linear mpg i.foreign i.rep78 净空重量转动齿轮比价格后备箱长度位移如果样本 == 1，选择（自适应）
估计存储自适应

lassocoef cv bic 自适应，排序（系数，标准化）

-------------------------------------------------------------
| cv bic 自适应
-------------+--------------------------------
重量 | x x 
5.rep78 | x x x 
长度 | x x x 
齿轮比 | x x 
价格 | x x 
_cons | x x x 
----------------------------------------------
图例：
b - 基准水平
e - 空单元格
o - 省略
x - 估计

lassogof cv bic 自适应，过（样本）后选择

后选择系数
-------------------------------------------------------------------------
名称样本 | MSE R 平方 Obs
------------------------+------------------------------------
cv |
1 | 10.92984 0.7046 35
2 | 10.77016 0.6496 34
------------------------+------------------------------------
bic |
1 | 11.82234 0.6805 35
2 | 11.0608 0.6401 34
------------------------+------------------------------------
自适应 |
1 | 10.98369 0.7032 35
2 | 10.56047 0.6564 34
--------------------------------------------------------------

*adaptive 在样本 2 中具有较低的 MSE 和较高的 R^2

*我选择 Adaptive 作为最佳模型：

. reg mpg length 5.rep78 gear_ratio price

来源 | SS df MS 观测数 = 69
-------------+---------------------------------- F(4, 64) = 38.57
模型 | 1654.03213 4 413.508033 Prob &gt; F = 0.0000
残差 | 686.170766 64 10.7214182 R 平方 = 0.7068
-------------+----------------------------------- Adj R 平方 = 0.6885
总计 | 2340.2029 68 34.4147485 根 MSE = 3.2744

--------------------------------------------------------------------------------------------
mpg | 系数标准误差 t P&gt;|t| [95% 置信区间]
-------------+----------------------------------------------------------------
长度 | -.1484211 .0270004 -5.50 0.000 -.2023607 -.0944816
5.rep78 | 3.380391 1.163954 2.90 0.005 1.055125 5.705657
gear_ratio | 1.558014 1.251733 1.24 0.218 -.9426098 4.058637
价格 | -.0002964 .0001545 -1.92 0.060 -.0006049 .0000122
_缺点 | 45.84562 7.960131 5.76 0.000 29.94343 61.74781
--------------------------------------------------------------------------------------------

这里选择了 gear_ratio，但其 p 值为 0.218，太高了，无法解释 mpg？
在使用 Lasso 和交叉验证进行模型选择时，我错过了一些步骤或概念？
我现在知道 Lasso 不使用 p 值来选择模型，但我应该在最终模型中删除 gear_ratio？
任何评论我都会感激不尽
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658807/lasso-and-cross-validation-model-selection</guid>
      <pubDate>Mon, 16 Dec 2024 11:55:26 GMT</pubDate>
    </item>
    <item>
      <title>针对种族数据/群体数据的最自然的机器学习模型类</title>
      <link>https://stats.stackexchange.com/questions/658803/most-natural-class-of-machine-learning-models-for-race-data-group-data</link>
      <description><![CDATA[我有一个学生考试成绩的数据集，如下所示：
班级 ID 班级规模 学生编号 智商 小时数 分数
1 3 3 101 10 98
1 3 4 99 19 80
1 3 6 130 3 95
2 5 4 93 5 50
2 5 5 103 9 88
2 5 8 112 12 99
2 5 1 200 10 100
2 5 2 90 19 78
3 2 5 100 12 84
3 2 7 102 13 88

我想建立一个机器学习模型，尝试预测谁将成为班级第一名（即最高分数）给定 Class_ID，使用 IQ 和 Hours（学习小时数）作为特征。
换句话说，输入是班级中每个学生（例如 1 到 n）的 IQ 和 Hours，输出是概率向量 (p_1, ..., p_n)，其中每个 p_i 是学生 i 在班级中获得最高分数的概率。
这是我尝试过的：

由于这是一个排名问题，因此自然的一类学习模型是使用 XGBoost 中的 XGBRanker 或 lightgbm 中的 LGBMRanker。不幸的是，输出是 相关性得分 列表，而不是概率列表，概率列表在概率方面没有自然解释。

解决这个问题的一种方法是在 xgboost 中对相关性得分应用 softmax，但没有直接有意义的概率解释，如基于能量的模型，如 RBM 的能量函数。事实上，我试过这样做，概率变得非常极端（大多数概率质量集中在每个班级的一名学生身上，导致测试结果不佳且方差较大）

另一类学习模型是分类模型，如逻辑回归/决策树。然而，我遇到的问题是每个班级的学生人数不同，因此要训练这样的模型，我们必须首先“扁平化”特征矩阵：

Class_ID Class_size IQ_1 IQ_2 IQ_3 IQ_4 IQ_5 小时_1 小时_2 小时_3 小时_4 小时_5 Score_1 Score_2 Score_3 Score_4 Score_5
1 1 101 99 130 南 南 10 19 3 南 南 98 80 95 南 南
2 5 93 103 112 200 90 5 9 12 10 19 50 88 99 100 78
3 2 100 102 南 南 南 12 13 南 南 南 84 88 南 南 南

使得 1 行代表 1 个训练示例。但是这样一来，特征矩阵就会变得非常稀疏（因为不同班级的学生人数可能有很大差异）
因此，逻辑模型/普通前馈神经网络/基于树的模型似乎也不适用于这类群体数据。
所以我的问题是，是否有任何自然的机器学习模型可以处理这些“群体数据”，就像我上面的数据集一样？
此外，在这个问题中，我只关心最终名列前茅的人（或者可能是前三名），所以排名并不是那么重要（例如，知道学生 4 排名第 11 位，学生 8 排名第 12 位并不重要）
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/658803/most-natural-class-of-machine-learning-models-for-race-data-group-data</guid>
      <pubDate>Mon, 16 Dec 2024 09:50:29 GMT</pubDate>
    </item>
    <item>
      <title>Cox 回归假设</title>
      <link>https://stats.stackexchange.com/questions/658802/cox-regression-assumptions</link>
      <description><![CDATA[我正在分析血浆生物标志物与疾病发病率之间的关联，这些关联是通过年度问卷自我报告的。总样本量为 824，其中 65 人报告了至少一个事件（我不考虑多个事件）。除了事件发生之外，所有其他变量都是在基线测量的。我会使用 Cox 比例风险回归模型，但我不熟悉这个模型，并且对我获得的假设图感到很困惑。
我的完全调整模型如下所示：
assumpt.cox &lt;- coxph(Surv(time, event) ~ contvar1 + 
contvar2 + catvar1 + catvar2 + 
catvar3 + contvar3 + catvar4 + contvar4 + contvar5, data = data_assumpt.cox)

其中 contvar 是连续变量，catvar 是分类变量。我主要关注的是 contvar1。
我检查了 PH 假设，它没有表明违反（所有变量和全局变量的 p&gt;0.05）。
对于有影响的点，我检查了偏差并注意到所有报告事件的参与者都聚集在图表的顶部，而没有报告事件的参与者则聚集在底部。此外，平均偏差不为 0。但我不清楚我应该怎么做。
ggcoxdiagnostics(assumpt.cox, type = &quot;deviance&quot;,
linear.predictions = FALSE, ggtheme = theme_bw()) 


对于线性，我发现了两种主要方法来检查这个假设。

使用空模型：

 ggcox functional(Surv(time, event) ~ contvar1 + I(contvar1)^2 + log(contvar1) + 
sqrt(contvar1), data = data_assumpt.cox)



使用完全调整的模型：

data_assumpt.cox %&gt;% 
ggplot(aes(x=contvar1, y=residuals(assumpt.cox, type=&quot;martingale&quot;))) + 
geom_point() + 
geom_hline(yintercept = 0, color=&quot;blue&quot;) +
geom_smooth(color=&quot;red&quot;) +
theme_bw()



我明白，在第一组图中，我应该看到数据点和残差线之间有很好的相关性，而在第二组图中，红线应该（大部分）在 0 处笔直。但总的来说，它们应该告诉我同样的事情。这是正确的吗，还是应该优先考虑其中一个？
从这些图中，我得出结论，线性假设被违反了。
但如果是这样，我该怎么办，因为转换似乎没有帮助？我也试图排除 contvar1 中的两个极端值（一个有事件，一个没有事件），但效果只略有改善。
抱歉发了这么长的帖子，我希望至少能说清楚。
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658802/cox-regression-assumptions</guid>
      <pubDate>Mon, 16 Dec 2024 09:44:18 GMT</pubDate>
    </item>
    <item>
      <title>多个非独立同分布 beta 素数变量之和</title>
      <link>https://stats.stackexchange.com/questions/658799/the-sum-of-multiple-non-i-i-d-beta-prime-variables</link>
      <description><![CDATA[假设 $X_1$,$X_2$,$X_3$ 是独立同分布的。伽马随机变量，则$\frac{X_1}{X_2}$、$\frac{X_2}{X_3}$、$\frac{X_3}{X_1}$服从 beta 素数分布且相互关联。
那么，$\frac{X_1}{X_2}+\frac{X_2}{X_3}+\frac{X_3}{X_1}$的分布是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658799/the-sum-of-multiple-non-i-i-d-beta-prime-variables</guid>
      <pubDate>Mon, 16 Dec 2024 08:29:57 GMT</pubDate>
    </item>
    <item>
      <title>在回归模型中意外地两次包含同一个变量？</title>
      <link>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</link>
      <description><![CDATA[我在 R (mgcv) 中有这种混合效应 GAM 回归：
library(mgcv)
gam_beta &lt;- gam( 
y ~ te(time, x1) + te(time, x2) + s(time, by = city) + s(city, bs = &quot;re&quot;), 
data = my_data,
method = &quot;REML&quot;, 
family = betar(link = &quot;logit&quot;)
)

我尝试为该模型编写方程（基于我对 mgcv 中张量积函数 te 的理解 https://www.rdocumentation.org/packages/mgcv/versions/1.9-1/topics/te):
$$ y_{ij} \sim \text{Beta}(\mu_{ij}\phi, (1-\mu_{ij})\phi) $$
$$\mu_{ij} = \frac{1}{1+e^{-\eta_{ij}}}$$
$$ \text{logit}(\mu_{ij}) = \eta_{ij}= \beta_0 + f_{12}(time_{ij}, x1_{ij}) + f_{34}(time_{ij}, x2_{ij}) + h_i(time_{ij}) + b_i $$
我尝试将其进一步扩展：
$$ \eta_{ij} = \underbrace{\sum_{k=1}^{K_1} \hat{\gamma}_{1k}f_{1k}(time_{ij}) + \sum_{l=1}^{L_1} \hat{\gamma}_{2l}g_{1l}(x1_{ij}) + \sum_{k=1}^{K_1}\sum_{l=1}^{L_1} \hat{\gamma}_{3kl}f_{1k}(time_{ij})g_{1l}(x1_{ij})}_{\text{first te(): time and x1 term}} + $$
$$ \underbrace{\sum_{m=1}^{M_1} \hat{\gamma}_{4m}f_{2m}(time_{ij}) + \sum_{n=1}^{N_1} \hat{\gamma}_{5n}g_{2n}(x2_{ij}) + \sum_{m=1}^{M_2}\sum_{n=1}^{N_2} \hat{\gamma}_{6mn}f_{2m}(time_{ij})g_{2n}(x2_{ij})}_{\text{second te(): time and x2 term}} + $$
$$ \underbrace{\sum_{p=1}^P \hat{\alpha}_{ip}h_p(time_{ij})}_{\text{city-specific smooth}} + \underbrace{\hat{b}_i}_{\text{random effect}} $$
我的问题如下：我知道 mgcv 中的 te 函数包含主效应和交互效应 (GAM 回归：交互与主效应？)。但这是否意味着某个术语存在被重复计算并在 GAM 方程中出现两次的风险？
例如，我有 te(time,x1) 和 te(time,x2)。这是因为我想在我的模型中包含与协变量 x1 和 x2 的时间交互。但这是否会导致时间的主效应被包含两次？或者 mgcv 会识别这一点并且只包含一次？]]></description>
      <guid>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</guid>
      <pubDate>Mon, 16 Dec 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>数据分类</title>
      <link>https://stats.stackexchange.com/questions/658795/data-categorization</link>
      <description><![CDATA[我已将我的教育数据集分类以供以下分析。但是，我遇到过一位受访者就读于一所传教学校，我不知道其水平，也不确定将他们放在何处。我应该将他们排除在外吗？我的决定基于什么依据？
教育 是 否 总计
高等教育 22 13 35
中学 144 47 191
小学 103 52 155
未受过教育 23 13 36
]]></description>
      <guid>https://stats.stackexchange.com/questions/658795/data-categorization</guid>
      <pubDate>Mon, 16 Dec 2024 06:47:39 GMT</pubDate>
    </item>
    <item>
      <title>需要有共同原因的因果调整公式</title>
      <link>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</link>
      <description><![CDATA[
在上述因果模型中，计算$P(X=x \mid \text{do}(Y=y))$时，是否需要使用因果调整公式$\sum_c P(X=x \mid Y=y, C=c) P(C=c)$？一旦我们$\text{do}(Y=y)$，$Y$的生成过程是否就独立于$X$的生成过程，因此$P(X=x \mid \text{do}(Y=y)) = P(X=x)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</guid>
      <pubDate>Mon, 16 Dec 2024 06:30:13 GMT</pubDate>
    </item>
    <item>
      <title>用于 AB 测试的测试类型，非正态分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658765/the-type-of-test-to-use-for-an-ab-test-non-normal-distribution</link>
      <description><![CDATA[在此示例中，假设我想执行 t 检验来确定两组用户之间的差异，其中一组用户看到的是登录页面 A，另一组用户看到的是登录页面 B。我跟踪指标“网站停留时间”。数据看起来不错，但我意识到它不是正态分布。
在将数据输入单向独立样本 t 检验之前，我是否应该使用重采样来规范化这些数据？原因如下：

它实现了正态性，这（至少在视觉上）与我的最终决策标准一致
得到的标准化曲线使假设检验的结果易于理解。即，我的结果是 _ 与我所测试样本的平均值的标准差；这个的 p 值为 p，所以我们接受/拒绝零假设
它只是与我们对问题的解决方案更加一致

反对的理由：

它改变了数据的分布，我不确定这会对我的 AB 测试的“正确性”产生什么影响。
它可能是“过度工程”问题
t 检验可以接受非正态数据，无论 t 检验中仍然使用的正态曲线的视觉效果如何（见下图）。


请注意，我描述的是重新采样，即创建许多平均值的采样分布，而不是简单地采样，即选择随机指标并使用该组作为分布。简而言之，在每个分布上调用 mean() 并将一组均值输入到我的 AB 测试中。
我应该为 AB 测试重新采样吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658765/the-type-of-test-to-use-for-an-ab-test-non-normal-distribution</guid>
      <pubDate>Sun, 15 Dec 2024 16:53:45 GMT</pubDate>
    </item>
    <item>
      <title>使用简单泊松近似泊松混合的有效性</title>
      <link>https://stats.stackexchange.com/questions/658764/validity-of-approximating-a-poisson-mixture-with-a-simple-poisson</link>
      <description><![CDATA[已编辑：
我正在考虑使用一个简单的泊松分布来模拟一个过程，其中事件的瞬时速率（用 $\lambda$ 表示）不是恒定的。相反，$\lambda$ 取决于复杂底层系统的当前状态，该系统具有许多相互作用的因素，这些因素会随着时间的推移而快速变化。
由于系统的复杂性，我正在探索使用简单泊松分布近似该过程的可能性，其中速率参数 $\lambda$ 设置为波动瞬时速率的时间平均值 $\mu_\pi$。我主要关心的是了解$\lambda$的波动时间如何影响此近似值。
虽然我没有底层系统动态的精确模型，但我知道影响$\lambda$的因素在整个过程期间会多次变化，从而提供瞬时速率分布的良好样本。但是，我不确定连续事件之间的这些变化的数量是否也起着至关重要的作用。
具体来说，我感兴趣的是了解连续事件之间$\lambda$波动的频率/速度如何影响简单泊松近似的准确性。如果
$\lambda$ 在整个过程中波动多次（从而提供瞬时速率分布的良好样本，我将其表示为 $\pi$），但连续事件之间的波动次数相对较少，这会影响泊松近似的质量吗？
根据维基百科（链接至混合泊松分布），混合泊松分布的方差由以下公式给出：$\operatorname{Var}(X) = \mu_\pi+\sigma_\pi^2$ 其中 $\mu_\pi$ 和 $\sigma_\pi^{2}$ 分别是 $\pi$ 的均值和方差。根据此公式，只要 $\lambda$ 的波动足够大，可以提供 $\pi$ 的良好样本，人们可能就会预期混合过程的方差接近该理论值，而不管各个事件之间的波动是多是少。但是，我进行了一些数值模拟，似乎表明波动频率对方差也起着重要作用（可能是我的代码中存在一些错误？）。
似乎近似值系统地高估了方差，是否引入了其他偏差？]]></description>
      <guid>https://stats.stackexchange.com/questions/658764/validity-of-approximating-a-poisson-mixture-with-a-simple-poisson</guid>
      <pubDate>Sun, 15 Dec 2024 16:51:48 GMT</pubDate>
    </item>
    <item>
      <title>计算不同大小的文本语料库的卡方</title>
      <link>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</link>
      <description><![CDATA[我偶然发现了一篇论文，它批评了某文本分析软件中用于比较六个大小明显不同的文本语料库中的词频的卡方统计量的计算。该软件采用标准公式：
$$
\chi^2 = \sum_{i=1}^{n} \frac{(O_{i} - E_{i})^2}{E_{i}}
$$
这里，$O_{i}$表示在语料库$i$中观察到的频率，$E_{i}$的计算方法是将一个词在所有六个语料库中的总频率除以所有语料库中的单词总数，然后乘以语料库$i$中的单词数。
本文作者批评了这种方法，陈述：

&quot;运行交叉制表也不能产生有效可靠的评估。 [...] 事实证明，该软件使用非标准化的绝对频率，只有当要比较的文本语料库长度相等时才不会引起问题。&quot;

在这种情况下，作者将$O_{i}$解释为绝对频率，并提出了一种替代的&quot;标准化&quot;过程来计算$O_{i}$和$E_{i}$。这涉及：

选择最小的语料库作为参考。
通过将观察到的所有其他语料库的频率除以各自语料库中的单词总数，然后乘以参考语料库中的单词数，对观察到的所有其他语料库的频率进行归一化。
将预期频率计算为所有语料库（包括参考语料库）的归一化频率之和，除以六（语料库数量）。

问题 1：作者声称该软件使用的公式（如上所述）没有考虑到语料库的各种大小，他是否正确。
问题 2：在这种情况下，这种归一化方法是否适用于卡方计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</guid>
      <pubDate>Sun, 15 Dec 2024 13:37:05 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn QuantileRegressor 中 L1 正则化的 alpha 参数是什么</title>
      <link>https://stats.stackexchange.com/questions/658748/what-is-the-alpha-parameter-for-l1-normalization-in-scikit-learn-quantileregress</link>
      <description><![CDATA[scikit-learn Quantile Regression 文档中的 示例 展示了一个将参数 alpha 设置为零的示例。默认值为 1。
文档 QuantileRegressor 显示默认值设置为 1.0。它指出这是一个乘以 L1 惩罚项的正则化常数。
我对 Lasso 是什么或 L1 回归的确切含义没有直观的理解。
参数 alpha 与这些事物的关系是否有直观的解释？
有一篇与分位数回归相关的 维基百科文章，非常详细。浏览此文，在正则化参数的选择部分中，alpha 似乎就是 lambda。它在其他地方也可能被称为t。
我的直觉可能是错的。
到目前为止，我的结论是 alpha 可能只在多维（&gt; 1）回归问题中起作用，它可能用于选择维度的子集，即具有最强统计预测能力的最重要维度？]]></description>
      <guid>https://stats.stackexchange.com/questions/658748/what-is-the-alpha-parameter-for-l1-normalization-in-scikit-learn-quantileregress</guid>
      <pubDate>Sun, 15 Dec 2024 08:40:50 GMT</pubDate>
    </item>
    <item>
      <title>带条件的多元随机正态分布</title>
      <link>https://stats.stackexchange.com/questions/658734/multivariate-random-normal-distribution-with-conditions</link>
      <description><![CDATA[我正在开发一个模拟模型，该模型将作为对实证考古数据进行分类的基础。我正在使用 R 语言，并使用有界版本的 mvrnorm() 来模拟 8 个抛射点（即箭头/矛头）尺寸（最大长度、轴向长度、最大宽度等），并使用从实证数据集得出的相关矩阵。然后，模拟数据将遵循文化传播规则，并投射到 n 代，以模拟不同社会学习场景的影响。大多数文物尺寸都具有显著相关性，并且有几个必须具有特定的关系，才能使我的模拟文物逼真。例如，轴向长度不能大于最大长度，因为它们是相同的。我尝试通过添加需要满足​​的条件（包括上限和下限）来调整 mvrnorm 函数。我尝试在模拟期间进行拒绝抽样，并在模拟后进行调整。然而，在这两种情况下，Gen 1 的结果协方差矩阵与我试图在 Gen 1 中复制的原始协方差矩阵相差甚远。我希望找到一个解决方案：1）导致 Gen 1 相关矩阵非常接近我在经验数据中看到的矩阵；2）导致模拟测量值落入经验数据集设定的范围内（最小和最大观测值）；并且 3) 满足实际工件测量的条件。
下面是我尝试在模拟后调整记录的一个例子，这似乎是所有方法中问题最少的，但仍然导致 Gen 1 中的协方差矩阵明显不同：
adjust_simulated_data &lt;- function(data,traits,mu,Sigma,bounds,
max_iterations = 10) {
n&lt;-nrow(data)
p&lt;-length(traits)

# 定义要检查的条件
check_conditions&lt;-function(row) {
c(
row[&quot;LengthAxial&quot;]&lt;=row[&quot;LengthMax&quot;],
row[&quot;WidthBasal&quot;]&lt;=row[&quot;WidthMax&quot;],
row[&quot;WidthNeck&quot;] &lt;= row[&quot;WidthMax&quot;],
row[&quot;PSA&quot;] &lt;= row[&quot;DSA&quot;]
)
}

# 对违反条件的单个行进行重新采样
for (iteration in 1:max_iterations) {
licences &lt;- logical(n)

# 检查违规
for (i in 1:n) {
row &lt;- data[i, ]
conditions &lt;- check_conditions(row)
if (any(!conditions)) {
licences[i] &lt;- TRUE
}
}

# 如果不存在违规，则退出循环
if (!any(violations)) {
message(&quot;All conditions satisfied after &quot;, iteration, 
&quot; iterations.&quot;)
break
}

# 对违规行进行重新采样
for (i in which(violations)) {
# 保留非特征列
non_trait_columns &lt;- data[i, !(names(data) %in% characters), 
drop = FALSE]

# 使用 mvrnorm_bounded 和原始 param_list 值对特征进行重新采样
resampled_traits &lt;- mvrnorm_bounded(
n = 1,
mu = mu,
Sigma = Sigma,
bounds = bounds
)

# 使用重新采样的特征更新数据行
data[i, characters] &lt;- resampled_traits
data[i, !(names(data) %in% characters)] &lt;- non_trait_columns
}
}

# 如果达到最大迭代次数，则发出警告
if (any(!violations) &amp;&amp; iteration == max_iterations) {
warning(&quot;已达到最大迭代次数；可能仍违反某些约束。&quot;)
}

return(data)
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/658734/multivariate-random-normal-distribution-with-conditions</guid>
      <pubDate>Sun, 15 Dec 2024 04:27:32 GMT</pubDate>
    </item>
    </channel>
</rss>