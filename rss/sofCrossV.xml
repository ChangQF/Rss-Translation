<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 17 Nov 2024 09:17:17 GMT</lastBuildDate>
    <item>
      <title>汇集 OLS 中的 SUR</title>
      <link>https://stats.stackexchange.com/questions/657389/sur-in-pooled-ols</link>
      <description><![CDATA[假设您的样本量为 150，由五个独立实体组成，这些实体的特征是样本，并且假定这些实体具有共同的解释变量。

同方差性：不能拒绝零假设
固定或随机效应：通过降低 t 和 t-1 消除
估计方法：对降低的数据进行合并 OLS，使用共同冲击虚拟变量作为解释变量。

如果 SUR 产生明显更好的 p 值，报告此结果是否是 p-hacking 的一个例子或合法性，因为实体之间的误差相关性可能仍然存在但未被考虑，特别是在样本量相对较小的情况下？]]></description>
      <guid>https://stats.stackexchange.com/questions/657389/sur-in-pooled-ols</guid>
      <pubDate>Sun, 17 Nov 2024 08:02:06 GMT</pubDate>
    </item>
    <item>
      <title>在插值中包含数据但不将其添加为节点</title>
      <link>https://stats.stackexchange.com/questions/657388/including-data-in-an-interpolation-without-adding-them-as-nodes</link>
      <description><![CDATA[我正在编写用于脱气矿物样品和测量释放气体的质谱数据缩减软件。我的软件所做的一件事是测量序列时间内的空白水平，并将该空白水平插入到样品时间，以计算每个样品的唯一空白校正。
除了“真实”空白，我们还有“重新提取”：这些是对每个样品的二次分析，以确保在第一次分析期间释放了所有气体。假设这些处于空白水平（在真实空白平均值的 2$\sigma$ 以内），它们可以用作额外的伪空白。
我想将这些“重新提取”数据包含在三次插值中，而不将它们添加为插值节点。这是因为

相对于真正的空白，重新提取是密集的（有很多）
我们正在测量空白水平，这涉及很多噪音

这些因素意味着当我尝试将重新提取与真正的空白一起添加为插值节点时，它会破坏拟合例程并且一切都归零。
我的问题是：如何将这些数据包含在三次插值中以影响拟合，而无需实际将它们添加为插值节点？当然，有办法，但我不知道正确的术语。
我可以使用简单的加权，但每个空白测量和重新提取也有一个与之相关的错误，我目前正在使用它来加权插值，我不确定如何将错误与一些任意权重相结合。]]></description>
      <guid>https://stats.stackexchange.com/questions/657388/including-data-in-an-interpolation-without-adding-them-as-nodes</guid>
      <pubDate>Sun, 17 Nov 2024 06:01:54 GMT</pubDate>
    </item>
    <item>
      <title>卡方和指数分布</title>
      <link>https://stats.stackexchange.com/questions/657385/chi-square-and-exponential-distributions</link>
      <description><![CDATA[单个卡方 RV 的图在 X^2 = 0 处趋于无穷大。为什么当添加卡方 RV 时，得到的 pdf 图似乎在 Y= 0 处为有限值，其中 Y = 这些 RV 的总和。此外，各种来源都说，具有 2 个 dgf 的卡方 RV 实际上是指数分布的 RV。卡方 RV 通常与方差分布相关，而指数分布的 RV 通常与下一个事件发生的时间概率相关。那么，我们如何解决这两个看似不同的解释，以便它们定性地描述同一件事？我不是在寻找完整的技术数学证明，而是寻找一般的定性直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/657385/chi-square-and-exponential-distributions</guid>
      <pubDate>Sun, 17 Nov 2024 01:01:01 GMT</pubDate>
    </item>
    <item>
      <title>与网格搜索结合的 StackingClassifier</title>
      <link>https://stats.stackexchange.com/questions/657381/stackingclassifier-with-conjunction-with-gridsearch</link>
      <description><![CDATA[我试图在我的 stackingClassifier 上使用 GridSearchCV，但是我想知道鉴于这是一个堆叠分类器，网格搜索如何在后端运行。GridSearchCV 是否会将折叠外的预测与剩余的特征值聚合在一起，以优化超参数？这是我的代码片段，其中包含虚拟变量。
stacked_model = StackingClassifier(estimators= [(&#39;Log&#39;, Log_model), (&#39;Rf&#39;, Random_Forest_model), (&#39;XGBoost&#39;, XGBoost_model)], 
final_estimator = LogisticRegression(), cv = tscv)

grid_search = GridSearchCV(estimator= stacked_model, param_grid=param_grid,scoring=&#39;neg_log_loss&#39;, cv=tscv)
]]></description>
      <guid>https://stats.stackexchange.com/questions/657381/stackingclassifier-with-conjunction-with-gridsearch</guid>
      <pubDate>Sat, 16 Nov 2024 22:01:10 GMT</pubDate>
    </item>
    <item>
      <title>分层模型的吉布斯采样器</title>
      <link>https://stats.stackexchange.com/questions/657379/gibbs-sampler-for-hierarchical-model</link>
      <description><![CDATA[我正在研究 MCMC 方法，我有以下模型
$$
y_i \mid \lambda_i \overset{\text{iid}}{\sim} \text{Poisson}(\lambda_i) \\
\lambda_i \mid \alpha, \beta \overset{\text{iid}}{\sim} \text{Gamma}(\alpha, \beta) \\
\alpha \sim \text{Gamma}(A, B), \quad \beta \sim \text{Gamma}(C, D)
$$
其中 $\alpha,\beta$ 独立。我想实现 Gibbs 采样器来模拟后验分布。我已经确定了
\begin{align*}
p(\lambda; \alpha ;\beta | y) &amp; = \left( \prod_{i = 1}^{16} \frac{ \lambda_i^{y_i} e^{-\lambda_i} }{y_i!} \times \frac{ \beta^{\alpha} \lambda_i^{\alpha - 1} e^{-\lambda_i \beta} } {\Gamma(\alpha)} \right) \times \frac{ B^{A} \alpha^{A-1} e^{- \alpha B} }{\Gamma(A)} \times \frac{ D^{C} \beta^{C-1} e^{- \beta D} }{\Gamma(C)} 
\end{align*&gt;
和
\begin{align*}
p(\lambda_j | \cdots ) &amp; \sim \mathcal{G}( y_j + \alpha, 1+\beta) \\
p(\beta | \cdots ) &amp; \sim \mathcal{G}\left( n \alpha + C , \sum_{i = 1}^{n} \lambda_i + D \right)
\end{align*&gt;
但我不知道 $\alpha$ 的条件分布如何，因为
$$
p( \alpha | \cdots) \propto \frac{ \beta^{\alpha n } }{ \Gamma(\alpha)^n } \left( \prod_{i = 1}^{16} \lambda_i \right)^{\alpha - 1} \alpha^{A-1} e^{-\alpha B}, \quad n = 16
$$
在这种情况下我该怎么办？我曾计划实施 M-H，但我不知道选择哪个分布来模拟。我将不胜感激任何有关此主题的帮助，尤其是参考资料。注意：
y = c(7,5,9,7,8,9,7,10,7,8,6,8,6,8,5,7)
]]></description>
      <guid>https://stats.stackexchange.com/questions/657379/gibbs-sampler-for-hierarchical-model</guid>
      <pubDate>Sat, 16 Nov 2024 21:38:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么在引导均值差异时需要合并均值？</title>
      <link>https://stats.stackexchange.com/questions/657378/why-is-a-pooled-mean-necessary-in-bootstrapping-the-difference-in-means</link>
      <description><![CDATA[公式化问题
在用于测试均值差异的双样本自举程序中，为什么从每个自举观察值中减去组特定均值（以零为中心）是不够的？这种方法使两个组的共同均值等于零。相反，为什么需要使用合并的总体平均值来调整自举样本？数学上：

设 $$ X = \{x_1, x_2, \dots, x_n\} $$ 和 $$ Y = \{y_1, y_2, \dots, y_m\} $$ 为两个独立样本，且：

样本均值：
$$
\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i, \quad \bar{y} = \frac{1}{m} \sum_{j=1}^m y_j
$$
观察到的均值差异：
$$
\Delta_{\text{obs}} = \bar{x} - \bar{y}
$$


通过减去相应的组均值，可获得中心化的引导样本：

对于组 (X)：
$$
x_i^* = x_i - \bar{x}, \quad \text{for } i = 1, 2, \dots, n
$$
对于组 (Y)：
$$
y_j^* = y_j - \bar{y}, \quad \text{for } j = 1, 2, \dots, m
$$
中心化后，两个组的均值均为零：
$$
\bar{x}^* = 0, \quad \bar{y}^* = 0
$$
这可确保引导样本模拟组特定均值相等的场景。


但是，有些方法建议不要将数据集中在组特定均值$$( \bar{x}, \bar{y} )$$周围，而应通过添加合并均值来调整引导样本：
$$
\bar{z} = \frac{n \cdot \bar{x} + m \cdot \bar{y}}{n + m}
$$
调整后的引导样本变为：

对于组 (X)：
$$
x_i^* = x_i - \bar{x} + \bar{z}
$$
对于组 ( Y )：
$$
y_j^* = y_j - \bar{y} + \bar{z}
$$


问题：为什么需要对合并平均值 $$( \bar{z} )$$ 进行额外调整？如果中心引导样本的组特定平均值已经为零，这是否不能确保满足均值相等的零假设？为什么以零为中心是不够的？

]]></description>
      <guid>https://stats.stackexchange.com/questions/657378/why-is-a-pooled-mean-necessary-in-bootstrapping-the-difference-in-means</guid>
      <pubDate>Sat, 16 Nov 2024 21:36:07 GMT</pubDate>
    </item>
    <item>
      <title>根据方差分析的总体 p 值进行事后检验不是一个问题吗？[重复]</title>
      <link>https://stats.stackexchange.com/questions/657373/isnt-it-a-problem-to-conduct-post-hoc-tests-based-on-the-overall-p-value-from-a</link>
      <description><![CDATA[我寻找过这个问题的答案，但似乎到目前为止还没有人问过。如果这个问题已经有人问过了，我深表歉意。
假设在进行方差分析后，我得到的整体 p 值小于 0.05（或任何 alpha 水平）。之后，我决定进行事后成对检验来检查每个组之间的个体差异（例如 Tukey 诚实显着性检验，但它可能是另一种方法，因为我的问题非常笼统）。
我是否应该相信我从事后检验中获得的 p 值，因为我知道如果我从方差分析中获得了一个较大的整体 p 值，我就不会进行这些检验？（例如 &gt; 0.05）
对整体方差分析的结果进行事后检验感觉有点像我在“搞砸”概率。
但是，我不知道如何用数学术语形式化我的直觉，以检查这样的条件是否是一个严重的问题，或者我只是在想象一个实际上不存在的问题，或者这是否是一个可以忽略的小问题。
我的实际问题是：无论我从方差分析中获得的总体 p 值如何，我是否都应该进行那些事后检验？
我想“这取决于”可能是对我的问题的答案，但我希望得到一些一般性的指导、指示或例子。我没有数据可以分享，因为这实际上是我自己教育的一个假设性问题。
编辑
我已阅读此处的线程在事后检验之前我们需要进行全局检验吗？，如之前的评论中所述，但恐怕它可能无法完全回答我的问题。我不仅想知道在获得总体 p 值 &gt; 0.05（在另一个线程中已解决）后我是否可以进行事后检验，还想知道我是否必须进行这些事后检验（假设如果 p 值 &lt; 0.05，我会进行这些检验），以及为什么/为什么不。如果这取决于分析的情况，我有兴趣了解具体情况会如何影响这一点，可能还会举例说明。我认为其他帖子没有解决我的问题的另一部分。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657373/isnt-it-a-problem-to-conduct-post-hoc-tests-based-on-the-overall-p-value-from-a</guid>
      <pubDate>Sat, 16 Nov 2024 19:07:46 GMT</pubDate>
    </item>
    <item>
      <title>匹配和边际效应</title>
      <link>https://stats.stackexchange.com/questions/657366/matchthem-and-marginaleffect</link>
      <description><![CDATA[这是我的代码：
# 在每个估算数据集中执行匹配
m.out_model1 &lt;- matchthem(Treatment_type_tumor_near_gallbladder ~ age + sex + bmi + ASA + comorbidities + Systemic_treatment_prior_local_treatment + Segments_treated_per_session + Metastasis_size_at_treatment_mm + min_distance_gallblad_mm + stage_binary, 
data = new_amcore_imputed, 
method = &quot;nearest&quot;, 
distance = &quot;logit&quot;,
replace = TRUE,
ratio = 3,
caliper = 0.2)

# 对匹配的数据执行逻辑回归
results &lt;- with(m.out_model1, svyglm(complications ~ Treatment_type_tumor_near_gallbladder + age + sex + bmi + ASA + 合并症 + Systemic_treatment_prior_local_treatment + Segments_treated_per_session + Metastasis_size_at_treatment_mm + min_distance_gallblad_mm + stage_binary,
family = quasibinomial()), cluster = FALSE)

完成此步骤后，如何正确使用 marginaleffects::avg_comparisons() 函数？
我尝试了以下操作：
# 计算平均边际效应
comparisons &lt;- marginaleffects::avg_comparisons(results)
summary(comparisons, exponentiate = TRUE)

但是，我不确定这是否正确，因为输出不是我所期望的。我按照这里提供的教程操作：https://ngreifer.github.io/blog/treatment-effects-mi/，但我无法将其应用于我的情况。
我也尝试了这种方法，它给了我一个更易于理解的输出：
output &lt;- pool(results, dfcom = NULL)

summary(output, exponentiate = TRUE, conf.int = TRUE) %&gt;% 
mutate(across(where(is.numeric), round, digits = 3))

这两种方法可以比较吗？
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/657366/matchthem-and-marginaleffect</guid>
      <pubDate>Sat, 16 Nov 2024 15:48:18 GMT</pubDate>
    </item>
    <item>
      <title>协变量平衡爱情情节和距离</title>
      <link>https://stats.stackexchange.com/questions/657337/covariate-balance-loveplot-and-distance</link>
      <description><![CDATA[love.plot 上绘制的距离参数是什么？我无法在 cobalt 包中找到任何参考或解释。任何有助于理解此值“距离”的信息都会有所帮助。谢谢。
library(MatchThem)

data(&quot;osteoarthritis&quot;)

library(mice)
imputed.datasets &lt;- mice(osteoarthritis, m = 5)

table(imputed.datasets$data$OSP)

table(imputed.datasets$data$KOA)

matched.datasets &lt;- matchthem(OSP ~ AGE + SEX + BMI + RAC + SMK,
datasets = imputed.datasets,
approach = &#39;within&#39;,
method = &#39;nearest&#39;,
caliper = 0.05,
ratio = 2)

]]></description>
      <guid>https://stats.stackexchange.com/questions/657337/covariate-balance-loveplot-and-distance</guid>
      <pubDate>Fri, 15 Nov 2024 22:06:49 GMT</pubDate>
    </item>
    <item>
      <title>在几乎为零的数据中寻找异常值</title>
      <link>https://stats.stackexchange.com/questions/657310/finding-outliers-in-mostly-zero-data</link>
      <description><![CDATA[背景
我正在研究一种算法，用于在长 DNA 序列中查找短的 DNA 序列片段。我不会详细介绍它的实际工作原理，但让我更正式地说明它以提供足够的背景信息。每个 DNA 序列只是字母表 ATGC 中的一个字符串。给定参考 r，我们沿着参考 r 移动窗口 w。例如，如果参考 r 是 ATGCA 且 w=3，我们将生成窗口 ATG、TGC、GCA。然后将每个窗口与每个查询进行比较以生成计数 c，该计数类似于它们的匹配程度。从而基本上生成一个矩阵，其中列是 r 中的窗口起始位置，行是每个查询的每个窗口的计数。根据实验数据，我们预计在参考的左侧和右侧会看到计数峰值。但是，这并不能保证，左侧、右侧或两个峰值可能都不存在，并且每侧（甚至中间）可能有多个峰值。
图
颜色代表不同的查询，但省略了图例，因为它占用了太多空间
示例 1。大多数窗口实际上与查询不匹配，因此零占主导地位（参见底部面板，不确定为什么绘图库将条形图放在 0 旁边，但第一个条形图是零）。但是，左右两侧的两个蓝绿色峰值明显突出，计数超过 20。

示例 2
与示例 1 类似，但是左侧峰值不太明显。从视觉上看，我认为蓝色仍然高于“平均”水平它不像橙色那么明显。

示例 3
这是一个单侧有多个峰值的示例：

问题
我的第一直觉是使用 z 分数、百分位数或 IQR 之类的东西来选择这些高值。但是由于零占主导地位，计数 3 或 5 实际上也被视为“异常值”，但这不是我感兴趣的。我真的很想知道如何“自动”检测出如此高的异常值。主要目的只是尽量减少用户输入，因为设置最小计数并不直观。此外，当我设置最小 z 分数时，例如，一个峰值会通过，但另一个不会通过，等等。虽然从视觉上看它们似乎很明显，但我无法想出一种方法来巧妙地检测它们。
好奇地想看看回复！

编辑 1
我注意到一件事，因为它是一个滑动窗口，正确的区域通常有多个良好的匹配，随着窗口沿着区域滑动，这些匹配从坏到峰值再到坏。这将显示在累积得分图中：


左右匹配的累积得分曲线与其他曲线有很大不同。那么也许我可以使用任何曲线属性来评估重要性。刚刚检查了最终值、AUC、曲率和增长率：

（红色部分我刚刚手动为上面的绿色曲线上色）]]></description>
      <guid>https://stats.stackexchange.com/questions/657310/finding-outliers-in-mostly-zero-data</guid>
      <pubDate>Fri, 15 Nov 2024 12:03:04 GMT</pubDate>
    </item>
    <item>
      <title>将 Hessian 矩阵居中并进行 QR 变换后恢复为原始参数 X</title>
      <link>https://stats.stackexchange.com/questions/657210/transforming-hessian-to-original-parameters-after-centering-and-qr-transforming</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657210/transforming-hessian-to-original-parameters-after-centering-and-qr-transforming</guid>
      <pubDate>Wed, 13 Nov 2024 15:34:57 GMT</pubDate>
    </item>
    <item>
      <title>如果调节变量与 IV 和 DV 之间的相关性在统计上不显著，我们是否放弃进行中介分析？</title>
      <link>https://stats.stackexchange.com/questions/657121/do-we-abandon-doing-mediation-analysis-if-the-correlations-between-the-moderator</link>
      <description><![CDATA[假设我有一个研究问题，最好通过中介分析来回答。但是，在运行相关性分析后，中介变量与 IV 和 DV 之间没有显著相关性。我是否应该放弃进行中介分析？
我该如何继续回答研究问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/657121/do-we-abandon-doing-mediation-analysis-if-the-correlations-between-the-moderator</guid>
      <pubDate>Tue, 12 Nov 2024 07:16:22 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 MatchThem 和混合效应逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/657071/matchthem-and-mixed-effects-logistic-regression-in-r</link>
      <description><![CDATA[R 中的 MatchThem 和 Logistic 回归
我正在开展一项非随机研究，以评估两种治疗方法之间并发症发生率的差异。观察到的并发症发生率在两组之间有显著差异（22% vs. 50%）。为了考虑潜在的混杂因素，我计划使用二项式 Logistic 回归模型。鉴于样本量相对较小（130 名患者，分为 53 名 vs. 77 名），并且我的一个协变量（合并症）中存在 7 个缺失值，我选择使用 MICE（链式方程多重插补）方法插补缺失数据，以避免失去这些患者。代码如下：
# 估算缺失值
new_df_imputed &lt;- mice(selected_data, m = 5, maxit = 50, method = &quot;pmm&quot;, seed = 123)

接下来，我使用 MatchThem 包执行倾向得分匹配 (PSM)：
# 在每个估算数据集中执行匹配
m.out_model1 &lt;- matchthem(Treatment_type_tumor_near_gallbladder ~ age + sex + bmi + ASA + comorbidities + Systemic_treatment_prior_local_treatment + Segments_treated_per_session + Metastasis_size_at_treatment_mm + min_distance_gallblad_mm + stage, 
data = new_df_imputed, 
method = &quot;nearest&quot;, 
distance = &quot;logit&quot;,
replace = TRUE,
ratio = 3,
caliper = 0.2) 

匹配过程实现了良好的平衡，结果令人满意：
平衡平均差异计数
count
平衡，&lt;0.1 16
不平衡，&gt;0.1 2

平均差异最大的变量
Variable Max.Diff.Adj M.Threshold
Segments_treated_per_session 0.1602 不平衡，&gt;0.1

插补的平均样本量
0 1
全部 53. 77. 
匹配（ESS） 29.34 67.8
匹配（未加权） 46.8 67.8
不匹配 6.2 9.2

之后，我实施了一个多变量使用以下代码进行分析：
结果 &lt;- with(m.out_model1, svyglm(complications ~ Treatment_type_tumor_near_gallbladder + age + sex + bmi + ASA + comorbidities + Systemic_treatment_prior_local_treatment + Segments_treated_per_session + Metastasis_size_at_treatment_mm + min_distance_gallblad_mm + stage,
family = quasibinomial()))

输出 &lt;- pool(results, dfcom = NULL)

summary(output, exponentiate = TRUE, conf.int = TRUE) %&gt;% 
mutate(across(where(is.numeric), round, digits = 3))

问题 1：
svyglm 函数是否自动考虑因为我进行了替换匹配并使用了 3:1 的比例？
问题 2：
是否可以对模型摘要执行向后消除过程？这有意义吗？
提前感谢您的任何建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/657071/matchthem-and-mixed-effects-logistic-regression-in-r</guid>
      <pubDate>Mon, 11 Nov 2024 10:50:46 GMT</pubDate>
    </item>
    <item>
      <title>使用 mgcv 从 gamm 中提取随机效应</title>
      <link>https://stats.stackexchange.com/questions/622551/extract-random-effects-from-gamm-with-mgcv</link>
      <description><![CDATA[嗨，我已经开始使用 mgcv 和 bs=&#39;re&#39; 拟合具有随机截距的简单 gams，但我似乎找不到如何提取我的因子的每个级别的条件模式/随机效应/BLUP。即 lmer 中 ranef() 的等价物。我的谷歌搜索也一无所获。这可能吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/622551/extract-random-effects-from-gamm-with-mgcv</guid>
      <pubDate>Fri, 28 Jul 2023 12:42:16 GMT</pubDate>
    </item>
    <item>
      <title>G*Power ANOVA 重复测量内部交互作用</title>
      <link>https://stats.stackexchange.com/questions/619514/gpower-anova-repeated-measures-within-between-interaction</link>
      <description><![CDATA[我希望对我在 G*Power 中运行的样本量计算进行合理性检查。我计划进行一项有 2 个组和 2 个测量点的研究，目标是 f 为 0.10，因为据我所知，这相当于 Cohen&#39;s D 为 0.20。基线结果和随访结果之间的相关性为 0.75，因此我将其输入为“重复测量之间的相关性”。我希望功效为 0.8，alpha=0.05。
当我将该信息输入 GPower 时（如下所示），我得到的所需样本量估计值比忽略受试者内成分并将其视为受试者间研究要低得多。我知道重复测量可以提高功效，但我没想到会这么大。根据我的解释，下面的 GPower 截图看起来正确吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/619514/gpower-anova-repeated-measures-within-between-interaction</guid>
      <pubDate>Thu, 22 Jun 2023 23:24:58 GMT</pubDate>
    </item>
    </channel>
</rss>