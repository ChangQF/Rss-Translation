<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 02 Aug 2024 09:16:44 GMT</lastBuildDate>
    <item>
      <title>RM Anova 或 2 配对 t 检验？并使用 RCI 验证个体差异</title>
      <link>https://stats.stackexchange.com/questions/652203/rm-anova-or-2-paired-t-tests-and-verifying-for-individual-differences-with-rci</link>
      <description><![CDATA[对于一个使用记录对刺激的反应时间的测试来评估麻醉后认知能力变化的研究项目，我们在麻醉后基线、1 小时和 4 小时对受试者进行了测试，总共进行了三次。该研究旨在判断麻醉后开车是否危险。
RM Anovas 或配对 t 检验是否更适合比较这 3 个时刻？另一项类似于小时的研究使用了 RM Anovas，但我担心会失去统计能力。RM Anova 的优点是它更具表现力，我可以在我的分析中添加受试者间因素（例如他们的代谢对麻醉剂的吸收）。
第二个问题，当我们处理安全问题时，报告是否有一个人受到镇静的负面影响非常重要。为此，我决定暂时采用可靠变化指数，但我不确定这是否是最好的选择，因为我手头没有重测信度。我使用了这个公式：calculate_RCI &lt;- function(M1, SD1, M2, SD2) {return((M1 - M2) / sqrt(SD1^2 + SD2^2))
是使用整个组的 SD 更好，还是使用不同时间点的个人的 SD 更好？]]></description>
      <guid>https://stats.stackexchange.com/questions/652203/rm-anova-or-2-paired-t-tests-and-verifying-for-individual-differences-with-rci</guid>
      <pubDate>Fri, 02 Aug 2024 08:59:59 GMT</pubDate>
    </item>
    <item>
      <title>对单个组的样本大小进行论证以获得所需准确度的平均值估计值</title>
      <link>https://stats.stackexchange.com/questions/652201/sample-size-justification-for-single-group-to-get-estimate-of-mean-to-desired-ac</link>
      <description><![CDATA[
我有一个计算机组件样品
这些计算机组件是分批生产的（1 批 = 1 批次），每批 200 个
组件可以单独进行电子测试
然后对该测试结果进行平均，以得出批次级值，以判断整个批次是否通过
我需要知道需要从一批中抽样多少个组件，以便对整个批次进行
准确的测试测量。
有人知道我应该如何证明这一点吗？
例如，测试 10 个组件是否能让我足够准确地估计出整个批次的平均测试结果？

我知道这里有一些未知数，比如“足够准确” - 也许是某种置信区间？
任何帮助都太棒了！
林肯]]></description>
      <guid>https://stats.stackexchange.com/questions/652201/sample-size-justification-for-single-group-to-get-estimate-of-mean-to-desired-ac</guid>
      <pubDate>Fri, 02 Aug 2024 08:15:30 GMT</pubDate>
    </item>
    <item>
      <title>如何手动计算零膨胀泊松回归的伪 R2（McFadden）</title>
      <link>https://stats.stackexchange.com/questions/652200/how-to-calculate-pseudo-r2-mcfadden-for-zero-inflated-poisson-regression-by-ha</link>
      <description><![CDATA[我正在寻找在 R 中手动计算伪 R2 McFadden 的方法。但是，当我使用下面的代码时
zeropr &lt;- zeroinfl(g ~ a + f | a + f, data = xuly240731_1000) summary(zeropr)
结果如下：
调用：
zeroinfl(formula = g ~ a + f | a + f, data = xuly240731_1000)
皮尔逊残差：
最小 1Q 中位数 3Q 最大
-2.4010 -1.0299 -0.4369 0.6539 6.2740
计算模型系数（带对数链接的泊松）：
估计标准差。误差 z 值 Pr(&gt;|z|)
（截距）0.709857 0.115392 6.152 7.67e-10 ***
a 0.038266 0.002577 14.846 &lt; 2e-16 ***
f 0.927251 0.282940 3.277 0.00105 **
零通胀模型系数（带 logit 链接的二项式）：
估计标准差。误差 z 值 Pr(&gt;|z|)
(截距) 0.22235 1.03148 0.216 0.8293
a -0.14307 0.06518 -2.195 0.0282 *
f -1.81661 2.19863 -0.826 0.4087
有效代码：0 &#39;&#39; 0.001 &#39;&#39; 0.01 &#39;&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
但是，当我尝试计算 Pseudo-R2 McFadden 时
library(performance)

library(DescTools)
PseudoR2(zeropr,c(&quot;McFadden&quot;))
结果是 &gt; PseudoR2(zeropr,c(&quot;McFadden&quot;))
[1] NA
您能告诉我如何处理这个问题并计算 Pseudo-R2 (McFadden) 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652200/how-to-calculate-pseudo-r2-mcfadden-for-zero-inflated-poisson-regression-by-ha</guid>
      <pubDate>Fri, 02 Aug 2024 07:56:36 GMT</pubDate>
    </item>
    <item>
      <title>处理表格小数据集</title>
      <link>https://stats.stackexchange.com/questions/652198/dealing-with-tabular-small-data-set</link>
      <description><![CDATA[我有一个表格数据集。该数据集有 18 列和 66 行。我借助 IQR 技术删除了异常值。我缩放了数据。但结果非常差。您建议我如何改进这个模型？我的问题是回归，应该借助其他 17 列来预测第 18 列。
训练和测试图
结果]]></description>
      <guid>https://stats.stackexchange.com/questions/652198/dealing-with-tabular-small-data-set</guid>
      <pubDate>Fri, 02 Aug 2024 07:30:07 GMT</pubDate>
    </item>
    <item>
      <title>频率嵌入的聚类方法</title>
      <link>https://stats.stackexchange.com/questions/652196/clustering-method-for-frequency-embeddings</link>
      <description><![CDATA[例如，我有以下要聚类的单词列表。列表的长度可能不同，词汇表为 $W = \{a,b,c\}$。将两个列表聚类到同一个簇中的标准是“它们重叠得越多，它们就越相似”。



索引
列表
嵌入




1
$[a,a,b,c]$
$[2,1,1]$


2
$[b,b,c]$
$[0,2,1]$


3
$[a,b,c,c,c]$
$[1,1,3]$


4
$[a,a,a]$
$[3,0,0]$



我发现使用欧几里得距离的经典聚类方法（例如 Kmeans）存在一些问题，即 $[a], [b],$ 和 $[c]$（具有嵌入 $[1,0,0], [0,1,0],$ 和 $[0,0,1]$）可以聚类到同一个聚类中，即使列表中存在不重叠的事件。此外，当嵌入是整数并且可能包含大量 0 时，Kmeans 不是一种好的聚类方法。
对于这个聚类问题，我应该使用哪种距离和哪种聚类方法？或者我应该在这里使用一些不同的嵌入？]]></description>
      <guid>https://stats.stackexchange.com/questions/652196/clustering-method-for-frequency-embeddings</guid>
      <pubDate>Fri, 02 Aug 2024 06:31:45 GMT</pubDate>
    </item>
    <item>
      <title>弗里德曼、皮萨尼和普维斯书中的辛普森悖论</title>
      <link>https://stats.stackexchange.com/questions/652195/simpsons-paradox-in-freedman-pisani-and-purves-book</link>
      <description><![CDATA[本书中有一个研究生录取性别歧视的例子。



专业
男性

女性






申请人数
录取率
申请人数
%录取


A
825
62
108
82


B
560
63
25
68


C
325
37
593
34


D
417
33
375
35


E
191
28
393
24


F
373
6
341
7


总计
2691
45
1835
30



总申请人数只是上述条目的总和。录取的总百分比，男性为 45%，是
62 * 825 / 2691 + ... + 6 * 373 / 2691

女性也是如此。
然后作者提出统计员会执行以下操作的论点：



专业
申请人总数




A
933 = 825 + 108


B
585


C
918


D
792


E
584


F
714 = 373 + 341


总计
4526



然后他们指出男性的加权平均录取率为：
62 * 933 / 4526 + ... + 6 * 714/4526 = 39（近似值）

对于女性来说也是如此：
82 * 933 / 4526 + ... + 7 * 714/4526 = 43（近似值）

我很难解释最后一对计算“男女加权平均录取率”。
他们说：

加权平均值控制了混杂因素——专业选择。这些平均值表明，如果有的话，录取过程对男性有偏见。

在这种情况下，39% 和 43% 的加权平均值究竟意味着什么？如何正确解释这些数字？原始百分比 45% 和 30% 似乎对我来说更容易理解和解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/652195/simpsons-paradox-in-freedman-pisani-and-purves-book</guid>
      <pubDate>Fri, 02 Aug 2024 05:33:00 GMT</pubDate>
    </item>
    <item>
      <title>确保我正确地规范化了我的数据</title>
      <link>https://stats.stackexchange.com/questions/652191/making-sure-im-normalizing-my-data-appropritely</link>
      <description><![CDATA[我（实际上）正在评估分拣机的准确性。为简单起见，假设我有 10 个箱子。每天，都会将随机数和各种物品放入机器并进行分类。有时机器不准确，因此为了测试其准确性，我会从每个箱子中抽取随机数量的物品。在这样做的同时，我会记录我评估的物品数量以及错误分类的物品数量。此外，在分类结束时，我会计算当天每种类型的物品应该分拣到每个箱子中的实际分布。
我现在要做的第一件事是获取样本中评估的物品总数，并找出错误物品占总数的百分比。这是原始的、未加权的准确性计算。在现实世界中，它对于故障排除很有用，所以我想保留这些数据。
但我还想建立一个加权系统。例如，如果 50% 的对象被分类到容器 1 中，2% 的对象被分类到容器 4 中，但容器 4 中错误分类的对象更多，那么按理说，这些错误分类的对象的整体权重应该小于正确分类到其中的对象更多的容器。将这种逻辑推广到数百万个已排序的对象，一个容器对准确性的影响应该比另一个容器更大，这是有道理的。
我想要做的是确保我正确地对这些容器进行加权。目前，我正在这样做：
（容器、采样对象、错误分类的对象、实际分布）：
（1、4、0、14%）；
（2、6、0、10%）；
（3、3、1、14%）；
（4、2、0、11%）；
（5、8、0、13%）；
(6, 7, 0, 7%);
(7, 1, 2, 8%);
(8, 15, 1, 12%);
(9, 12, 0, 4%);
(10, 6, 0, 7%);
给定样本数据，如果我想对这些箱子进行归一化，我目前正在执行以下操作：
将采样对象乘以实际分布，将错误排序的对象乘以实际分布，将这些新的相应值相加并重新计算百分比。
这合理吗？还是我在做一些统计上愚蠢的事情？]]></description>
      <guid>https://stats.stackexchange.com/questions/652191/making-sure-im-normalizing-my-data-appropritely</guid>
      <pubDate>Fri, 02 Aug 2024 01:52:35 GMT</pubDate>
    </item>
    <item>
      <title>随机森林和 bagging 中的概率预测与聚合而非投票计数：寻求文献/现有研究</title>
      <link>https://stats.stackexchange.com/questions/652189/probability-predictions-in-random-forest-and-bagging-with-aggregating-not-a-vote</link>
      <description><![CDATA[通常，在整个 bagging 或随机森林集合中，类别概率是通过 投票计数 方法确定的。在该集合中，每棵树都会根据终端节点中的多数类别进行类别预测。设 $T$ 为树的总数，$b_t$ 为集合中的 $t$ 棵树。让 $\mathbb{I}(b_t(x_i) = A)$ 成为指示函数，当 $b_t$ 预测观测 $x_i$ 属于类 $A$ 时，该函数返回 $1$。观测 $x_i$ 属于类 $A$ 的概率计算如下：
$$
\Pr(x_i = A) = \frac{1}{T} \sum_{t=1}^{T} \mathbb{I}(b_t(x_i) = A)。
$$
另一种方法是，为每个 $b_t$ 计算概率预测，然后在整个集合中取平均值。看来，这种方法在 Python 中的 RandomForestClassifier.predict 中使用。虽然我是使用 randomForest 的 R 用户。在数学中，这是：
$$
\Pr(x_i = A) = \frac{1}{T} \sum_{t=1}^{T} \Pr(b_t(x_i) = A)。
$$
我的问题是，我在寻找每种方法相对性能的证据。理想情况下，模拟研究可以帮助我理解这一领域。我四处寻找，但我找不到任何东西。从有限的阅读中我得出的直觉是，每个 CART 模型的概率预测都很差，以至于它们的总体对概率的估计很差。
提前感谢互联网]]></description>
      <guid>https://stats.stackexchange.com/questions/652189/probability-predictions-in-random-forest-and-bagging-with-aggregating-not-a-vote</guid>
      <pubDate>Fri, 02 Aug 2024 01:12:11 GMT</pubDate>
    </item>
    <item>
      <title>对异性恋和同性恋感到困惑。我真的不知道这张图显示了什么</title>
      <link>https://stats.stackexchange.com/questions/652188/confused-about-heterosked-and-homosked-i-really-cant-tell-what-this-graph-sho</link>
      <description><![CDATA[因此，我正在使用大约 13 年期间某些股票的股票数据，现在我想在 stata 上检查异方差和自相关性。残差与拟合值如下所示。


该图是否暗示异方差？

如果该图不够充分，我可以使用什么测试？潜在的自相关性可能会影响 Beusch-pagan 或怀特检验的结果，以确定异方差

]]></description>
      <guid>https://stats.stackexchange.com/questions/652188/confused-about-heterosked-and-homosked-i-really-cant-tell-what-this-graph-sho</guid>
      <pubDate>Fri, 02 Aug 2024 01:11:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么弹性网络不能像 lm 那样处理缺失数据？</title>
      <link>https://stats.stackexchange.com/questions/652183/why-doesnt-elastic-net-handle-missing-data-the-way-lm-does</link>
      <description><![CDATA[在 R 中进行计算时，我有一些玩具数据，并尝试使用 glmnet 来拟合弹性网络模型。我注意到，即使只有一个缺失值，算法也不会执行，建议事先估算缺失值。
# 设置可重复性的种子
set.seed(123)

# 生成一个 100x5 的随机数矩阵
data_matrix &lt;- matrix(rnorm(100*5), nrow=100, ncol=5)
data_df &lt;- as.data.frame(data_matrix)
data_df[1:1, 3] &lt;- NA # 单个缺失值
# 生成一个包含 100 个观测值的向量 Y，每个观测值为 1、2 或 3
Y &lt;- sample(1:3, 100, replace=TRUE)
glmnet::cv.glmnet(x = as.matrix(data_df),
y = as.matrix(Y),
alpha = 0.5,
family = &quot;multinomial&quot;)
glmnet(x, y, weights = weights, offset = offset, lambda = lambda, 中的错误：
x 有缺失值；考虑使用 makeX() 来估算它们

从算法上讲，当有缺失值时，是什么原因导致弹性网络不适合？相反，当使用 lm 并且有缺失值时，
ctl &lt;- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,NA)
trt &lt;- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group &lt;- gl(2, 10, 20, labels = c(&quot;Ctl&quot;,&quot;Trt&quot;))
weight &lt;- c(ctl, trt)
lm.D9 &lt;- lm(weight ~ group)

代码运行无任何错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/652183/why-doesnt-elastic-net-handle-missing-data-the-way-lm-does</guid>
      <pubDate>Thu, 01 Aug 2024 21:42:45 GMT</pubDate>
    </item>
    <item>
      <title>正态分布概率密度函数与累积分布函数之比</title>
      <link>https://stats.stackexchange.com/questions/652176/ratio-of-normal-pdf-to-cdf</link>
      <description><![CDATA[我想证明
$$\Bigl\lvert \frac{\phi(a)}{\Phi(a)} - \frac{\phi(b)}{\Phi(b)} \Bigr\rvert \leq |a-b|$$
其中 $\phi$ 是标准正态 pdf，而 $\Phi$ 是标准正态 cdf。]]></description>
      <guid>https://stats.stackexchange.com/questions/652176/ratio-of-normal-pdf-to-cdf</guid>
      <pubDate>Thu, 01 Aug 2024 20:06:38 GMT</pubDate>
    </item>
    <item>
      <title>残差与拟合图显示了周期性模式。我从 300 个解释变量中选择了 5 个。我应该添加更多变量还是冒着过度拟合的风险？</title>
      <link>https://stats.stackexchange.com/questions/652174/resids-vs-fitted-plot-shows-cyclical-patterns-i-have-chosen-5-explanatory-varia</link>
      <description><![CDATA[我根据其他属的相对丰度预测 1 个属 (A) 的相对丰度。我随意选择了 5 个似乎最有可能有帮助的属（我所有重复实验中随时间推移最丰富的 5 个属），但我的社区总共有 300 多个属。我使用相同的方法预测了 2 个细菌属和 2 个真核生物属的丰度。
除了残基与拟合值之外，诊断结果看起来都很好，并且该模型在预测未来数据方面表现得出奇的好。
我正在写一篇文章，想说的是，虽然残差与拟合值显示出拟合不足的迹象，并且添加其他属很可能有助于预测，但仅包含这 5 个物种使我们能够相当准确地预测随时间的变化。
该建模不是我文章的核心，目的不是预测现实世界中发生的现象，而是一个探索性过程，只是看看是否可以预测属的相对丰度变化。这种思路在发表的文章中会成立吗？


使用包 mvgam 在 R 中建模]]></description>
      <guid>https://stats.stackexchange.com/questions/652174/resids-vs-fitted-plot-shows-cyclical-patterns-i-have-chosen-5-explanatory-varia</guid>
      <pubDate>Thu, 01 Aug 2024 19:31:37 GMT</pubDate>
    </item>
    <item>
      <title>如何在 GLM 中推导出指数分布的典型链接函数</title>
      <link>https://stats.stackexchange.com/questions/652165/how-to-derive-canonical-link-function-of-exponential-distribution-in-glm</link>
      <description><![CDATA[我想知道推导过程，以及基本如何计算它]]></description>
      <guid>https://stats.stackexchange.com/questions/652165/how-to-derive-canonical-link-function-of-exponential-distribution-in-glm</guid>
      <pubDate>Thu, 01 Aug 2024 17:22:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么 sem() 与 lavaan 和 lm() 中的线性回归结果不同？</title>
      <link>https://stats.stackexchange.com/questions/652138/why-different-results-for-linear-regression-in-sem-from-lavaan-and-lm</link>
      <description><![CDATA[感谢您阅读本文。
我是一名学生，正在尝试更多地了解社会科学问题的统计数据。我试图在 R 中建立 {lavvan} 中的 sem() 函数和 {stats} 中的 lm() 函数之间的等价性，以进行具有一个结果和一个预测变量的简单线性回归，这两个预测变量都不是潜在变量。但是，即使我可以为模型获得相同的参数估计值，无论我使用哪个估计器，估计的标准误差都会略有不同。下面附上一个例子：
#加载库
library(lavaan)

#创建数据框
set.seed(1231)
n &lt;- 100 #观察值数量

X &lt;- rnorm(n, mean = 50, sd = 10)
Y &lt;- rnorm(n, mean = 65, sd = 8)

df &lt;- data.frame(X, Y)

#使用 lm() 函数
lm &lt;- lm(Y ~ X, data = df)
summary(lm)

#使用 lavaan 的 sem() 函数
model_sem &lt;- &#39;Y~X&#39;
sem &lt;- sem(model_sem, estimator = &quot;ML&quot;, se = &quot;standard&quot;, data = df)
summary(sem, nd = 7)

当前示例的结果：

来自 lm() 输出

 估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 67.30819 4.37739 15.38 &lt;2e-16
X -0.04116 0.08571 -0.48 0.632 


来自 sem() 输出

回归：
估计 Std.Err z 值 P(&gt;|z|)
Y ~ 
X -0.0411622 0.0848524 -0.4851035 0.6276029

参数估计相等，但参数的 SE 和 p 值略有不同。我还使用 {stats4} 中的 vcov() 函数检查了两个模型的方差-协方差矩阵。
vcov(lm)[c(&quot;X&quot;),c(&quot;X&quot;)]
[1] 0.00734687
vcov(sem)[c(&quot;Y~X&quot;),c(&quot;Y~X&quot;)]
[1] 0.007199932

我尝试手动计算 lm() 输出中的方差-协方差矩阵并成功完成。但是，我找不到从 sem() 中提取观察到的（或预期的）信息矩阵或计算 lavaan 文档中使用的对数似然函数的函数。在这种特定情况下，是否有可能实现两者之间的等价性？为什么（我哪里做错了）或者为什么不（有什么区别，是模型估计和规范还是仅仅是因为包）？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652138/why-different-results-for-linear-regression-in-sem-from-lavaan-and-lm</guid>
      <pubDate>Thu, 01 Aug 2024 09:22:58 GMT</pubDate>
    </item>
    <item>
      <title>导出有界函数估计误差和的大 $O_p$</title>
      <link>https://stats.stackexchange.com/questions/651980/deriving-the-big-o-p-of-a-sum-involving-estimation-errors-of-bounded-functions</link>
      <description><![CDATA[假设 $\frac{1}{n}\sum_{i=1}^n\{f(X) - \hat{f}(X)\}^2$ 和 $\frac{1}{n}\sum_{i=1}^n\{g(X) - \hat{g}(X)\}^2$ 为 $O_p(a^2_n)$，其中某个序列 $a_n$ 使得 $a_n = O(n^{-r}$)，其中 $r &gt; 1/4$。
假设 $Y_i$ 为二进制 0/1 随机变量，$f(\cdot)$ 介于 -1 和 1 之间，$g(\cdot)$ 介于 0 和 1 之间。假设观测值 $i = 1, \ldots, n$ 为 i.i.d。对于$O_p$来说，最大的是什么呢？
$$\frac{1}{n}\sum_{i=1}^n [(f(X_i) - \hat{f}(X_i))g(X_i) + (\hat{f}(X_i) - Y_i)(g(X_i) - \hat{g}(X_i))]^2?$$
展开平方，我们得到 3 项之和：
\begin{align*}
&amp;\frac{1}{n}\sum_{i=1}^n [(f(X_i) - \hat{f}(X_i))g(X_i) + (\hat{f}(X_i) - Y_i)(g(X_i) - \hat{g}(X_i))]^2\\
&amp;=\frac{1}{n}\sum_{i=1}^n \{f(X_i) - \hat{f}(X_i)\}^2g^2(X_i)+2(f(X_i) - \hat{f}(X_i))g(X_i)(\hat{f}(X_i) - Y_i)(g(X_i) - \hat{g}(X_i)) + (\hat{f}(X_i) - Y_i)^2(g(X_i) - \hat{g}(X_i))^2
\end{align*&gt;
术语 1：$\frac{1}{n}\sum_{i=1}^n \{f(X_i) - \hat{f}(X_i)\}^2g^2(X_i)$
由于 $g(X_i)$ 有界，且 $\frac{1}{n}\sum_{i=1}^n\{f(X)-\hat{f}(X)\}^2$ 为 $O_p(a^2_n)$，因此 项 1 为 $O_p(a^2_n)$。
项 2：$\frac{2}{n}\sum_{i=1}^n (f(X_i) - \hat{f}(X_i))g(X_i)(\hat{f}(X_i) - Y_i)(g(X_i) - \hat{g}(X_i))$
因为 $g(X_i) \leq 1$ 且 $|\hat{f}(X_i) - Y_i| \leq 2$，则我们有
\begin{align*}
&amp;\frac{2}{n}\sum_{i=1}^n (f(X_i) - \hat{f}(X_i))g(X_i)(\hat{f}(X_i) - Y_i)(g(X_i) - \hat{g}(X_i))\\ &amp;\leq C \sqrt{\left(\frac{1}{n}\sum_{i=1}^n \{f(X_i)-\hat{f}(X_i)\}^2\right)\left(\frac{1}{n}\sum_{i=1}^n \{g(X_i) - \hat{g}(X_i)\}^2\right)}\\
&amp;= O_p(a^2_n)
\end{align*&gt;
其中 $C$ 是某个正常数，不等式由柯西-施瓦茨定理成立。
第 3 项：$\frac{1}{n}\sum_{i=1}^n (\hat{f}(X_i) - Y_i)^2(g(X_i) - \hat{g}(X_i))^2$
因为 $|\hat{f}(X_i) - Y_i| \leq 2$
$$\frac{1}{n}\sum_{i=1}^n (\hat{f}(X_i) - Y_i)^2(g(X_i) - \hat{g}(X_i))^2 \leq \frac{4}{n}\sum_{i=1}^n (g(X_i) - \hat{g}(X_i))^2 = O_p(a^2_n)$$
总之，我们有
\begin{align*}
&amp;\frac{1}{n}\sum_{i=1}^n [(f(X_i) - \hat{f}(X_i))g(X_i) + (\hat{f}(X_i) - Y_i)(g(X_i) - \hat{g}(X_i))]^2\\ &amp;= O_p(a^2_n) + O_p(a^2_n) + O_p(a^2_n)\\
&amp;= O_p(a^2_n)
\end{align*&gt;
以上内容正确吗？我不太确定第 2 项和第 3 项，特别是关于分解$|\hat{f}(X_i)-Y_i|$。]]></description>
      <guid>https://stats.stackexchange.com/questions/651980/deriving-the-big-o-p-of-a-sum-involving-estimation-errors-of-bounded-functions</guid>
      <pubDate>Tue, 30 Jul 2024 02:22:39 GMT</pubDate>
    </item>
    </channel>
</rss>