<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 10 May 2024 21:14:56 GMT</lastBuildDate>
    <item>
      <title>帮助解释这些 P 值</title>
      <link>https://stats.stackexchange.com/questions/647002/help-interpret-these-p-values</link>
      <description><![CDATA[当模型 P 值大于 alpha 但主效应之一的 P 值小于 alpha 时，这意味着什么？实际的方差分析如下。阿尔法值为 0,0027。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647002/help-interpret-these-p-values</guid>
      <pubDate>Fri, 10 May 2024 21:09:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么简单的随机样本需要一个框架？</title>
      <link>https://stats.stackexchange.com/questions/647001/why-is-a-frame-needed-for-a-simple-random-sample</link>
      <description><![CDATA[在一本入门统计学教科书中，我读到，简单随机抽样 (SRS) 在抽样技术中是独一无二的，因为它需要一个框架。教科书将框架定义为“识别所有人口成员的列表”。教科书接着说：“简单随机抽样技术的主要缺点是必须形成抽样框架。”有一些抽样技术旨在解决该问题，其中一种称为整群抽样。&quot;
此论坛上提出了一个相关问题，但基本上没有得到回答：
在没有抽样框架的情况下获取代表性样本？
简单随机样本需要抽样框架的说法在我看来似乎不正确，如下例所示。
==================================================================
当仅知道总体规模 (N) 但特定成员未知时，计算简单随机样本不是。
示例：我拥有一家杂货店，在任何一天，我预计会有 N=150 位顾客。我想对当天的顾客进行简单的随机抽样，看看有多少人看到了我在肉类部门进行的促销活动。
当我开始抽样时，框架是未知的，因为我不知道在促销活动的那一天会有哪些顾客来。大致的人口规模是已知的，因为在平常的日子里，我有 150 位顾客。
将我的预期客户数量从 1 分配到 150。让计算机根据该数字生成 150 位客户的简单随机样本。例如，对于包含 n=20 位客户的 SRS，让计算机从 150 个整数中随机选择 20 个值。在商店前面等候，并在选定的顾客离开时与他们交谈。
讨论：为我的人口生成一个虚拟框架，以便可以完成简单的随机抽样。这个虚拟框架与教科书中讨论的框架不同，因为如果教科书是这个意思的话，它应该会说只需要人口规模 (N)。通过使用“框架”一词，教科书表示我必须知道实际客户是谁才能进行简单随机抽样。这是不正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/647001/why-is-a-frame-needed-for-a-simple-random-sample</guid>
      <pubDate>Fri, 10 May 2024 20:54:58 GMT</pubDate>
    </item>
    <item>
      <title>什么估计器和 r 包可用于与（非面板）横截面数据、控制和交互的交错双重差分</title>
      <link>https://stats.stackexchange.com/questions/647000/what-estimator-and-r-package-can-be-used-for-staggered-difference-in-difference</link>
      <description><![CDATA[我正在尝试在 r 中运行双重差分分析。我的数据是非面板数据，所以我依赖于 TWFE 模型，其中我有一组在经期或未接受治疗的个体。治疗交付是交错的，因此
我的基本事件研究模型如下所示，采用 R 语法，使用 mtcars 数据集中的虚假数据来实现可重复性：
库（修复）
图书馆（tidyverse）
图书馆（固定）
设置.种子(123)

mtcars$time_til &lt;- 样本(-10:10, nrow(mtcars), 替换 = TRUE)

mtcars = mtcars |&gt;;
  突变（治疗 = case_when（time_til &gt;= 0 ~ TRUE，
                           time_til &lt; 0 ~ 假)) |&gt;
  变异（am_factor = 因子（am））

feols(fml = mpg ~ am_factor + am_factor:(time_til) + disp + disp:(time_til) | vs, vcov = ~cyl,data = mtcars)

）


其中 mpg 是连续结果变量，time_til 表示治疗前的年数，例如 0 是治疗的第一年，正数是超出初始治疗的连续治疗年数，负数是治疗前的年数。 disp 是与 time_til 治疗相互作用的连续控制变量，am_factor 是受访者组的变量。 vs 是国家/地区-年份固定效应，尽管数据是横截面的，但仍可以估计 DiD，因为同一单位没有重复观察。我的治疗被认为是非吸收性的。 cyl 代替我聚类的大陆年份变量。
感兴趣的估计是不同 am_factor 水平的受访者组之间的 did（治疗后减去治疗前）效果的差异。我不关心 time_til （治疗）对 mpg 的总体影响，我关心与治疗相互作用的某些因素组的影响比其他因素大多少。同样，我想确保预处理的不同 am_factor 级别的成员之间存在平行趋势。需要明确的是，我想了解不同因素水平下单位之间的平均治疗效果有何不同。
我想知道什么r包和差分估计器可以处理这种估计方法。我已经尝试了多种，并且知道有大量不同的 DiD 方法正在使用（LP-DiD、插补 [Borusyak 等人]、Gardiner 等），但是我还没有找到一种似乎满足所有条件的方法我的经验问题。据我了解（如果我错了，请纠正我），一些软件包不接受控制变量，其他软件包无法处理与治疗的交互项以按组计算治疗，其他软件包根本无法处理横截面数据并需要面板数据，而其他人仍然无法处理交错治疗的采用。
有人可以推荐为此任务配备的 DiD 估计器和 r 软件包吗？我在指定型号时犯了错误吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647000/what-estimator-and-r-package-can-be-used-for-staggered-difference-in-difference</guid>
      <pubDate>Fri, 10 May 2024 20:47:57 GMT</pubDate>
    </item>
    <item>
      <title>关于导出复杂多元正态分布的 Fisher 信息的具体问题</title>
      <link>https://stats.stackexchange.com/questions/646998/specific-question-about-deriving-the-fisher-information-for-a-complex-multivaria</link>
      <description><![CDATA[我从以下形式开始，为具有维度 $d$ 和平均值 $\boldsymbol \mu$：
$$
p(\mathbf x|\boldsymbol \theta)=\frac{1}{\pi^d |\boldsymbol\Sigma|}\exp\left[-\frac{1}{2} (\mathbf x-\boldsymbol \mu)^{\mathrm H} \boldsymbol\Sigma^{-1} (\mathbf x-\boldsymbol \mu)\right]
$$
要计算 Fisher 信息，我首先必须找到对数似然函数。取自然对数，可得：
$$
\要求{取消}
\开始{对齐}
\log p(\mathbf x|\boldsymbol \theta)
&amp;= \log \Biggl( \frac{1}{\pi^d |\boldsymbol\Sigma|}\exp\left[-\frac{1}{2} (\mathbf x-\boldsymbol \mu)^ {\mathrm H} \boldsymbol\Sigma^{-1} (\mathbf x-\boldsymbol \mu)\right]
\Biggr) \\
&amp;= \log \Biggl( \frac{1}{\pi^d |\boldsymbol\Sigma|} \Biggr) +
\bcancel{\log} \Biggl( \bcancel{\exp} \left[-\frac{1}{2} (\mathbf x-\boldsymbol \mu)^{\mathrm H} \boldsymbol\Sigma^{- 1} (\mathbf x-\boldsymbol \mu)\right]
  \Biggr) \\
&amp;= \bcancel{\log 1} - \log \Bigl(\pi^d |\boldsymbol\Sigma| \Bigr) -\frac{1}{2} (\mathbf x-\boldsymbol \mu)^{ \mathrm H} \boldsymbol\Sigma^{-1} (\mathbf x-\boldsymbol \mu) \\
&amp;= -\log \left(\pi^d \right) -\log |\boldsymbol\Sigma| -\frac{1}{2} (\mathbf x-\boldsymbol \mu)^{\mathrm H} \boldsymbol\Sigma^{-1} (\mathbf x-\boldsymbol \mu)
\结束{对齐}
$$
下一步是对参数求偏导数来计算 Hessian 矩阵。执行此操作时，第一项是常数，因此它会消失。我的问题涉及第二项和第三项。

对参数求协方差矩阵行列式的对数的导数是什么意思？我困惑的根源是：我假设数据向量是参数的函数，并且从数据获得的协方差矩阵，因此行列式将是参数的函数。通过这个推理，导数将是非零的——然而，在“标准”图解中没有出现这种情况的表示。 Fisher 信息的结果。
类似地，当对参数求数据向量 $\mathbf x$ 的导数时，我希望由于数据取决于参数，导数应该是非零。但是，我认为事实并非如此。

我能想到的最好的推理是：数据向量 $\mathbf x$ 代表数据的特定快照，因此不是参数本身。一旦获得数据，就应将其视为常数，因此与分布参数无关。不知道这样的推理是否合理。]]></description>
      <guid>https://stats.stackexchange.com/questions/646998/specific-question-about-deriving-the-fisher-information-for-a-complex-multivaria</guid>
      <pubDate>Fri, 10 May 2024 19:53:23 GMT</pubDate>
    </item>
    <item>
      <title>哪种统计模型最适合这些数据？</title>
      <link>https://stats.stackexchange.com/questions/646997/which-statistical-model-will-be-best-for-this-data</link>
      <description><![CDATA[我正在尝试确定因变量和自变量之间的关系。我已经使用了线性回归，但我不确定它是否适合考虑到我的数据分布。您能否建议我如何有效地解释数据的差异？

我在这里只展示了我的几个变量，但其余的分布几乎相同
我的模型：
model1 &lt;- lmer(dep_var ~ var1 + var2 + var3 + var4 + var5 + var6 + var7 + var8 + var9 + var10 +
                var11 + var12 + var13 + var14 + var15 + var16 + var17 + var18 + var19 + var20 +
                (1|基因) + (1|ID) + (1|状态)，数据 = 数据11)

摘要：
随机效果：
 组名称方差标准差
 ID（截距）3.605e-04 0.018988
 基因（截获）4.488e-02 0.211848
 状态（拦截）2.915e-05 0.005399
 残余 1.656e-02 0.128704
obs数量：209542，组：ID，1088；基因，961；状态, 3

固定效果：
              估计标准。误差df t值Pr(&gt;|t|)
(截距) 1.609e-01 9.418e-03 1.419e+02 17.080＜ 2e-16 ***
变量1 1.217e-03 5.367e-04 8.568e+02 2.267 0.023628 *
变量2 1.005e-04 6.023e-04 8.360e+02 0.167 0.867529
var3 1.320e-03 5.431e-04 8.507e+02 2.430 0.015297 *
var4 -4.154e-04 1.007e-03 8.838e+02 -0.413 0.680029
var5 1.130e-03 5.879e-04 8.398e+02 1.921 0.055036 。
var6 9.305e-04 5.881e-04 8.517e+02 1.582 0.113985
var7 -9.708e-04 7.902e-04 8.570e+02 -1.229 0.219582
var8 1.879e-03 6.657e-04 8.736e+02 2.822 0.004875 **
var9 -8.587e-04 6.772e-04 8.647e+02 -1.268 0.205152
var10 -4.270e-04 7.362e-04 8.665e+02 -0.580 0.562010
变量11 4.382e-04 6.182e-04 8.521e+02 0.709 0.478555
var12 1.847e-04 5.788e-04 8.600e+02 0.319 0.749717
var13 3.404e-04 7.175e-04 8.451e+02 0.474 0.635299
var14 -6.316e-04 5.982e-04 8.495e+02 -1.056 0.291350
var15 -6.653e-04 6.163e-04 8.438e+02 -1.080 0.280655
var16 3.811e-04 6.196e-04 8.500e+02 0.615 0.538629
var17 6.515e-04 6.586e-04 8.470e+02 0.989 0.322847
var18 7.140e-04 8.014e-04 8.486e+02 0.891 0.373221
var19 -2.639e-03 7.015e-04 8.524e+02 -3.761 0.000181 ***
var20 -3.904e-04 6.714e-04 8.465e+02 -0.582 0.561052

以及残差摘要：
&lt;前&gt;&lt;代码&gt; 最小。第一曲。第三曲区中位数平均值。最大限度。
-7.33078 -0.32714 -0.07541 0.00000 0.21434 7.79032

如果需要，我将分享任何其他信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/646997/which-statistical-model-will-be-best-for-this-data</guid>
      <pubDate>Fri, 10 May 2024 19:30:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么比例的置信区间使用 z 而不是 t 分数？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/646995/why-confidence-interval-for-proportion-uses-z-instead-of-t-score</link>
      <description><![CDATA[二项分布的参数$p$的置信区间（Wald区间）是根据正态分布的近似值计算的：
$$ \ p ~~ \approx ~~ \hat p \pm \frac{\; z_\alpha\ }{\ \sqrt{n\; }\ }\ \sqrt{ \hat p\ \left(1 - \hat p \right)\ }\ $$
(来源)
当然，上面的样本标准差使用样本/观测数据 ($\hat{p}$)，因为原始值未知。回想一下，人口圣。开发人员。二项式的值为 $np(1-p)$。
我想知道为什么使用 $z$ 分数而不是 $t$ 分数。在总体平均值 $\mu$ 的模拟情况下，已知 $\sigma$&lt; 情况下的置信区间/span&gt; 是：
$$ \ \mu ~~ \approx ~~ \bar{x} \pm \frac{\; z_\alpha\ }{\ \sqrt{n\; }\ }\ \西格玛$$
而对于未知的情况是：
$$ \ \mu ~~ \approx ~~ \bar{x} \pm \frac{\; t_\alpha\ }{\ \sqrt{n\; }\ }\ S $$
其中 $S$ 是示例 st。开发。
在二项式情况下，我们使用样本 st。 dev，所以我不明白为什么使用 $z$ 而不是 $t$ 。这是一个近似值，因为 $n$ 被假定足够大？
PD：此相关问题说Student的说法不恰当，但解释不清楚，也不清楚真假。]]></description>
      <guid>https://stats.stackexchange.com/questions/646995/why-confidence-interval-for-proportion-uses-z-instead-of-t-score</guid>
      <pubDate>Fri, 10 May 2024 18:23:36 GMT</pubDate>
    </item>
    <item>
      <title>处理对数似然计算中的零值和负值[关闭]</title>
      <link>https://stats.stackexchange.com/questions/646994/handling-zero-and-negative-values-in-log-likelihood-computations</link>
      <description><![CDATA[我正在研究贝叶斯分析问题，需要计算模型的对数似然。似然函数涉及对某些表达式取对数，这些表达式有时可能为零或负数，这导致我的计算出现问题。
这是我的似然函数：
log_likelihood &lt;- function(theta, x) {
n &lt;- length(x)
I &lt;- matrix(0, n, 3)
I[x &gt;= 0 &amp; x &lt;= 1/3, 1] &lt;- 1
I[x &gt; 1/3 &amp; x &lt;= 2/3, 2] &lt;- 1
I[x &gt; 2/3 &amp; x &lt;= 1, 3] &lt;- 1

component1 &lt;- I[,1]*log(theta[1]*x)
component2 &lt;- I[,2]*log((theta[1]-theta[2])/3 + theta[2]*x)
component3 &lt;- I[,3]*log((theta[1]+theta[2]-2*theta[3])/3 + theta[3]*x)

return(sum(component1, component2, component3))
}

问题是对数内的表达式有时可能为零或负数，这会导致对数似然的值为 NaN。我知道对数对于零和负数是未定义的，但我不确定如何在计算中处理这个问题。
我考虑过在取对数之前在值中添加一个小常数（即拉普拉斯平滑），但我担心这可能会引入偏差。我也考虑过重新参数化我的模型，但我不确定如何以确保对数内的表达式始终为非负值。
有人对如何在对数似然计算中处理零和负值有什么建议吗？任何建议都将不胜感激！
编辑：
我正在计算贝叶斯因子以比较给定数据的两个统计模型。贝叶斯因子是两个相互竞争的假设下观察到的数据的似然比。在这种情况下，假设由模型的不同参数设置表示。在本计算中使用对数似然函数，因为它可以简化计算并有助于避免数值下溢或溢出问题。但是，当对数似然函数涉及对零或负数取对数时，我遇到了问题。我正在寻求有关如何处理这些情况的建议，以确保准确计算贝叶斯因子。
我选择了平坦先验。
$$\theta_1 \geq 0$$
$$-\theta_1 \leq \theta_2 \leq \frac{10-2\theta_1}{2}$$
$$\theta_3 = 10-2\theta_1-\theta_2$$
因此，theta 的支持是 $$\mathbb{R}^3$$ 中满足这些条件的所有 theta 向量的集合。对于此支持范围内的任何 theta，先验密度 $$f(\theta)$$ 为 1，而对于此支持范围之外的任何 theta，$$f(\theta)$$ 为 0。]]></description>
      <guid>https://stats.stackexchange.com/questions/646994/handling-zero-and-negative-values-in-log-likelihood-computations</guid>
      <pubDate>Fri, 10 May 2024 18:06:28 GMT</pubDate>
    </item>
    <item>
      <title>关于 LASSO、RMSE 和标准化的问题</title>
      <link>https://stats.stackexchange.com/questions/646993/question-about-lasso-rmse-and-standardization</link>
      <description><![CDATA[我有一个关于在 R 中使用 glmnet 执行 LASSO 的问题。这是一个概念性问题；我了解到我们应该在执行 glmnet 后解释 RMSE，以检查模型的性能。 RMSE 越低越好，但我仍然不知道阈值是多少。
我还了解到，在执行 LASSO 之前标准化 IV 至关重要。此外，我们也可以标准化 DV，以实现更好的推理。当我没有标准化 DV 时，rmse 是 2.55。当我标准化 DV 时，rmse 为 0.90。
我了解到这意味着模型表现不佳。我真的不明白为什么会发生这种情况 - 这是否意味着执行 OLS 是更好的选择？
澄清LASSO中RMSE的含义]]></description>
      <guid>https://stats.stackexchange.com/questions/646993/question-about-lasso-rmse-and-standardization</guid>
      <pubDate>Fri, 10 May 2024 17:15:47 GMT</pubDate>
    </item>
    <item>
      <title>为成对距离的预期分布建立方程</title>
      <link>https://stats.stackexchange.com/questions/646992/make-a-equation-for-expected-distribution-of-pairwise-distances</link>
      <description><![CDATA[我需要通过方程检查我的排列结果。我有一个序列 ABCABC。这里 AA、BB 和 CC 成对距离为 3。如果我们检查从 0 到 5 的观测值，则为
距离 0.1.2.3.4.5.
观察发现。 0.0.0.3.0.0.
Exp.Dic。 - - - - - -
如果我们将序列随机化 10,000 次，那么上述序列的预期距离分布值是多少。我已经尝试过使用Python，但我需要设计一个方程，以便我们可以通过任何公式来检查它。
我通过这个方程计算了每个位置的期望值，
E(X)=x。 P(x) // 我们如何计算 10,000 个随机结果
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/646992/make-a-equation-for-expected-distribution-of-pairwise-distances</guid>
      <pubDate>Fri, 10 May 2024 17:12:49 GMT</pubDate>
    </item>
    <item>
      <title>已实现 GARCH 最大似然</title>
      <link>https://stats.stackexchange.com/questions/646990/realized-garch-maximum-likelihood</link>
      <description><![CDATA[我正在尝试估计已实现的 Garch 模型的最大可能性。 xt 这是我实现的衡量标准，是根据 5 分钟平方收益计算得出的。
ut 是 0。我有每日收益，rt。

我使用下面的函数来最大化可能性，但它非常不一致。我尝试过使用真实数据和模拟数据，这样我就可以检查真实参数。 MLE 估计器根本不是最优的。如果我选择另一组参数，我实际上可以获得更好的残差图，并且它更好地拟合数据。另外，我的 MLE 对我的初始参数值非常敏感。如果我围绕真实值初始化它们，它会更好地拟合数据......
有谁知道为什么会发生这些事情？我在代码中做错了什么吗？
garch11_filter &lt;- 函数（返回，RM，参数）{
  # 初始化
  欧米茄 &lt;- 参数[1]
  beta &lt;- 参数[2]
  gamma &lt;- 参数[3]
  T &lt;- 长度（返回）
  
  log_sig2 &lt;- 数字(T)
  z &lt;- 数字(T)
  对数 &lt;- 0
  log_sig2[1] &lt;- log(var(返回))
  sig2 &lt;- exp(log_sig2[1])
  z[1] &lt;- 返回[1]/sqrt(sig2[1])
  # for循环提前一步计算
  对于 (t in 2:T){
    log_sig2[t] &lt;- omega + beta * log_sig2[t-1] + gamma * log(RM[t-1])
    sig2[t] &lt;- exp(log_sig2[t])
    z[t] &lt;- 返回[t]/sqrt(sig2[t])
  }
  # 逻辑
  loglik &lt;- -T/2*log(2*pi) - sum(log(sig2))/2 - sum(returns^2/sig2)/2
  返回（列表（sig2 = sig2，z = z，loglik = loglik））
}

干杯]]></description>
      <guid>https://stats.stackexchange.com/questions/646990/realized-garch-maximum-likelihood</guid>
      <pubDate>Fri, 10 May 2024 16:14:57 GMT</pubDate>
    </item>
    <item>
      <title>为了估计综合控制方法中的权重，使用什么结果和对称矩阵的线性组合？</title>
      <link>https://stats.stackexchange.com/questions/646989/for-estimating-weights-in-the-synthetic-control-method-what-linear-combination</link>
      <description><![CDATA[我正在阅读比较案例研究论文的综合控制方法，并在第 12 页上。第 5 节说明了如何估计综合控制权重。以下是对论文中方法的总结。我对两点很困惑：

为什么对干预前结果的线性组合给予如此大的灵活性？ （即可以是平均值，可以等于最后的结果）
我一直认为 $X_1$ 和 $X_0$ 是协变量，但它似乎包括协变量和干预前结果。这是为什么
在衡量差异时，为什么要引入$V$？这对我来说似乎完全超出了我的范畴，这是优化理论中的技术吗？

提前非常感谢您提供任何启发性的想法。
&lt;块引用&gt;
设 $W$ 为正权重求和的 $(J \times 1)$ 向量致一：
$$W = (w_2, \ldots, w_{J+1})^{\top}, \quad w_2 + \cdots + w_{J+1} =
&gt; 1.$$
$W$ 的每个值代表一个加权平均值的综合控制
可用的控制区域。观察感兴趣的结果
处理组 ($Y_{1t}$) 和对照组 ($Y_{jt}$)
区域，其中 $j = 2, \ldots, J + 1$。
设 $(T_0 \times 1)$ 向量 $K = (k_1, \ldots, k_{T_0 })^{\top}$
定义干预前结果的线性组合：
$$\bar{Y}_{K_i} = \sum_{s=1}^{T_0} k_s Y_{is}.$$
考虑 $M$ 这样的线性组合，$K_1, \ldots, K_M$。让：
$$X_1 = (Z_1^{\top}, \bar{Y}_{K_1}^{1}, \ldots,\bar{Y}_{K_M }^{1})^{\top},$$
一个 $(k \times 1)$ 的预干预特征向量
处理区域，其中 $k = r + M$。类似地， $X_0$ 是一个 $(k \times J)$ 矩阵，包含相同的控制变量地区，与
$j$-第列为：
$$(Z_j^{\top}, \bar{Y}_{K_1}^{j}, \ldots, \bar{Y}_{K_M}^ {j})^{\top}.$$
其中 $Z_i$ 是观察到的协变量向量。
向量$W^{\ast}$最小化$X_1$和&lt;之间的距离跨度类=“数学容器”&gt;$X_0
&gt; W$，使用
$$\| X_1 - X_0 W \|_V = \sqrt{(X_1 - X_0 W)^{\top} V (X_1 - X_0 W)},$$
其中 $V$ 是对称正半定矩阵。 $V$ 的最佳选择
为 $X_0$ 和 $X_1$ 中变量的线性组合分配权重，以最小化
综合控制估计量的 MSE。
]]></description>
      <guid>https://stats.stackexchange.com/questions/646989/for-estimating-weights-in-the-synthetic-control-method-what-linear-combination</guid>
      <pubDate>Fri, 10 May 2024 15:30:06 GMT</pubDate>
    </item>
    <item>
      <title>通过固定多重线性回归的 Beta 值来计算 R 平方（无需截距）会产生较大的 R 平方</title>
      <link>https://stats.stackexchange.com/questions/646983/compute-r-squared-by-fixing-betas-for-multi-linear-regression-without-intercept</link>
      <description><![CDATA[我想根据我拥有的一些数据修复多元线性回归中的贝塔值，这会导致基于 Tibshirani、Hastie 等人中提到的投影方法的 R 方值小于 0% 且大于 100%。所有书籍。
修复运​​行无截距多元线性回归的 beta 值后计算 R 方的最佳方法是什么 -
加载数据
将 numpy 导入为 np
将 pandas 导入为 pd

将 statsmodels.api 导入为 sm

数据 = sm.datasets.get_rdataset(&#39;iris&#39;).data

定义x和y变量 -
x = data.iloc[:, 1:4].values
y = data.iloc[:, 0].values

根据 Tibshirani 书籍求解 beta -
betas = np.linalg.solve(x.T @ x, x.T @ y)

数组([ 1.12106169, 0.92352887, -0.89567583])

sm.OLS(y, x).fit().params

数组([ 1.12106169, 0.92352887, -0.89567583])

或者，根据对环境的一些了解来固定测试版 -
alt_betas = [3.7, -10, 45.78]

现在，用 3 种方法计算 R 平方 -

使用不带拦截的 Statsmodel

使用 R Sq 的投影方法

使用投影方法但使用 RSq 的固定 Beta


统计模型
&lt;小时/&gt;
sm.OLS(y, x).fit().rsquared * 100

99.61972754365206

投影
&lt;小时/&gt;
&lt;预&gt;&lt;代码&gt;(y @ x @ betas / (y @ y) ) * 100

99.61972754365208

具有固定贝塔值的预测
&lt;小时/&gt;
&lt;预&gt;&lt;代码&gt;(y @ x @ alt_betas / (y @ y) ) * 100

511.1237918393523

现在我明白，鉴于我使用不同的 beta，它应该有所不同，但这违反了 RSq 应介于 0 和 1 之间的规则。
如果我有一些替代测试版，有没有办法修复它并使用 statsmodels OLS 来计算 R 平方？
将其视为我需要使用替代测试版作为我的用例，我认为从我的角度来看，这是环境的真实表示。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646983/compute-r-squared-by-fixing-betas-for-multi-linear-regression-without-intercept</guid>
      <pubDate>Fri, 10 May 2024 13:49:29 GMT</pubDate>
    </item>
    <item>
      <title>状态转移矩阵的幂和（几何级数）</title>
      <link>https://stats.stackexchange.com/questions/646956/sum-of-powers-geometric-series-of-state-transition-matrix</link>
      <description><![CDATA[我正在对一些大型状态转换图进行离散时间马尔可夫链分析。我想找到从初始状态到终端/接受状态所需的奖励/成本。
我有状态转移概率矩阵 M（n x n 稀疏矩阵）、每次转移的预期成本矩阵 C（n x n 稀疏矩阵）以及初始分布向量 v。（对于最常见的情况，v[0] = 1并且 v[i&gt;0] = 0，如果这有助于加速某些计算）
根据我的理解，要计算稳态分布，我们不需要对分布向量进行乘法运算并计算稳态，我们只需得到矩阵幂，因此 M -&gt; M^2-&gt; M^4-&gt; M^8 等等，我们可以根据我们如何将矩阵表示为平稳分布来选择第一列/行。
我认为这足够快了。但对于成本估算，我有点困惑。
经过一个时间步长后，到目前为止所产生的成本将为
c1 = v_0 * C，然后进行下一个时间步
c2 = v_1 * C = v0 * M * C，
延伸这个，
c_n+1 = v_n * C = v0 * M^n * C
总成本为
c1 + c2 + c3 + ...
= v0 * C + v0 * M * C + v0 * M^2 * C + .... V0 * M^n * C
= v0 *(1 + M + M^2 + M^3 + ... + M^n) * C # 因为矩阵乘法具有分配性
我的问题是，这类似于几何级数，会收敛到
如果 n 趋于无穷大，则为 1/(1-M) 或 (1-M^n)/(1-M)。
这个公式也适用于矩阵吗？
后续问题：如果我们有一个马尔可夫链，其中一些状态正在吸收，而一些状态形成一个循环，永远没有到达吸收节点的路径。我需要知道当它收敛时我们是否仍然可以获得平稳分布和吸收概率以及吸收成本。使用吸收矩阵分解[[Q R][0 I]]和相关公式还有效吗？
&lt;小时/&gt;
另一个问题，根据我的理解，这给出了到达最终状态的预期成本。是否也可以有效地获得直方图？让我们举一个简单的例子，从初始状态a，抛硬币，如果你头朝上，就进入吸收状态b。在状态 a 的尾部，它保持在 a 状态。在这种情况下，到达最终状态的预期时间是2。 [H，TH，TTH，...]＝&gt; [1+0.5+0.25+...]=2
在这里，我想得到一个像 [(0.5p, 1),(0.75p,2),(0.875,3)...] 这样的直方图]]></description>
      <guid>https://stats.stackexchange.com/questions/646956/sum-of-powers-geometric-series-of-state-transition-matrix</guid>
      <pubDate>Fri, 10 May 2024 00:05:01 GMT</pubDate>
    </item>
    <item>
      <title>指示变量/治疗变量作为自变量？</title>
      <link>https://stats.stackexchange.com/questions/646940/indicator-variables-treatment-variables-as-an-independent-variable</link>
      <description><![CDATA[虚拟变量或治疗变量可以是自变量吗？如果特定国家在特定年份发生洪水，我的自变量取值 1；如果没有发生洪水，则自变量取值 0。我的另一个自变量也是如此。我使用双向固定效应模型来估计干旱和洪水对 log_meanweeklyhoursworked 的因果影响。这里的问题是，我得到的关于洪水发生和干旱发生因变量的统计结果并不显着。这是为什么？我该如何解决这个问题？请提供我的编码的正确版本：
reg1a &lt;- plm(log_meanweeklyhoursworked ~洪水_发生 +
             干旱_发生 + 劳动力党 +
             log_gdp_percapita + 国民人口 + log_education +
             城市化+ log_householdsize，
              数据 = 全国劳工组织，
              索引 = c(“参考区域”, “开始年份”),
              model = “within”, # 实体内的固定效应模型
              effect = &quot;twoway&quot;) # 实体和时间都固定
                 包括 # 个效果

# 计算实体的集群鲁棒性标准误差
#（参考区域）级别
vcov_entity &lt;- vcovHC(reg1a，类型=“HC1”，簇=“组”)

# 计算年份级别的集群稳健标准误差
vcov_year &lt;- vcovHC(reg1a，类型 =“HC1”，簇 =“时间”)

# 合并结果
摘要组合 &lt;- 列表（
  实体级别 = 摘要(reg1a, vcov = vcov_entity),
  year_level = coeftest(reg1a, vcov.= vcov_year)
）
]]></description>
      <guid>https://stats.stackexchange.com/questions/646940/indicator-variables-treatment-variables-as-an-independent-variable</guid>
      <pubDate>Thu, 09 May 2024 18:12:35 GMT</pubDate>
    </item>
    <item>
      <title>从高斯分布中获取的一式三份样本的中位数分布</title>
      <link>https://stats.stackexchange.com/questions/646807/distribution-of-medians-of-triplicate-samples-taken-from-gaussian-distribution</link>
      <description><![CDATA[我的蒙特卡罗模拟似乎表明，从高斯分布中获取的一式三份样本的中位数的标准差接近原始分布的 SD 的 2/3。直观上，这似乎是与取一式三份样本的平均值（而不是中位数）类似的采样策略 - 平均值标准误差背后的想法。虽然中位数与平均值 (1/sqrt(3)) 相比总体 SD 估计值的降低较低，但如果样本受到污染，它似乎具有审查异常值的实际优势。
与标准误差的 CLT 不同，在使用一式三份方法的中位数时，我找不到任何支持 2/3*SD 值的理论 - 这全部基于模拟。有人能指出我正确的方向吗？
附：我从其他发行版中采样了一式三份。从每个一式三份中获取的中位数分布的 SD 对于对数正态：0.501，对于均匀：0.775，对于三角形：0.702。在我的应用程序（一系列收缩压和舒张压测量）中，这种采样几乎就像时间序列的平滑中值滤波器一样。看来对于监测高血压还是相当实用的。我仍然不明白它背后的理论 - 当以类似的封闭形式方式取一式三份样本的中位数时，是否有可能计算预期的分散减少，就像对平均值的标准误差（例如，一式三份样本）？]]></description>
      <guid>https://stats.stackexchange.com/questions/646807/distribution-of-medians-of-triplicate-samples-taken-from-gaussian-distribution</guid>
      <pubDate>Wed, 08 May 2024 11:46:03 GMT</pubDate>
    </item>
    </channel>
</rss>