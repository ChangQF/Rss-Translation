<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 05 Jun 2024 12:27:44 GMT</lastBuildDate>
    <item>
      <title>PLM VS LM 估计：为什么相同的模型会产生非常不同的调整后的 r2？</title>
      <link>https://stats.stackexchange.com/questions/648679/plm-vs-lm-estimation-why-does-the-same-model-yield-very-different-adjusted-r2</link>
      <description><![CDATA[我使用 r 中的 plm 包建立了一个具有国家和年份固定效应的模型，并获得了负调整后的 R2。然后我尝试了其他几种面板方法（仅国家固定效应、仅年份固定效应、随机效应、一阶差分、池化），所有模型都产生了负调整后的 R2。
然后我决定使用 r 中的 lm 包复制该模型，结果我得到了一个高调整后的 R2。我不明白为什么相同的模型会产生非常不同的调整 R2（估计的系数完全相同）。
fixed1_plm &lt;- plm( log(WAM_new) ~ log(IMP) + log(GOV) + log(TAX) + BUC + NEX
+ INF,
model = &quot;within&quot;, 
data = data, 
index = c(&quot;country&quot;,&quot;year&quot;), 
effect = &quot;twoways&quot;)

# 计算 Newey-West 校正标准误差
fixed1_plm_se &lt;- coeftest(fixed1_plm, vcov = vcovNW)[, 2]

fixed1_lm &lt;- lm( log(WAM_new) ~ log(IMP) + log(GOV) + log(TAX) + BUC + NEX + INF +因子（国家）+因子（年份），
数据 = 数据）

stargazer（fixed1_plm，fixed1_lm，se = list（fixed1_plm_se，NULL），type = &quot;text&quot;）

]]></description>
      <guid>https://stats.stackexchange.com/questions/648679/plm-vs-lm-estimation-why-does-the-same-model-yield-very-different-adjusted-r2</guid>
      <pubDate>Wed, 05 Jun 2024 12:07:32 GMT</pubDate>
    </item>
    <item>
      <title>t 代之后回归的方差是多少？</title>
      <link>https://stats.stackexchange.com/questions/648671/what-is-the-variance-of-a-regression-after-t-generations</link>
      <description><![CDATA[假设我们有一个回归：
$x_{t+1} = b x_t + e_t$。
取每边的方差，我们得到
$Var(x_{t+1}) = b^2 Var(x_t) + Var(e_t)$。
现在假设 $Var(e_t) = \sigma^2$ 是所有 $t$ 的常数。
然后我们有一个一阶递归关系，因此我们可以明确地求解：
$Var(x_t) = \frac{\sigma^2 (1 - b^{2t})}{(1-b)}$。
不幸的是，我正在阅读的 Gregory Clark 的《儿子也复活》一书给出的方差为 $\sigma^2 (1 - b^{2t})$。我的推导正确吗？
（注意：对于拥有这本书的人来说，页码是 297。这不是打字错误，后续文本已明确指出。）]]></description>
      <guid>https://stats.stackexchange.com/questions/648671/what-is-the-variance-of-a-regression-after-t-generations</guid>
      <pubDate>Wed, 05 Jun 2024 10:18:23 GMT</pubDate>
    </item>
    <item>
      <title>简单线性回归的$t$值在线更新</title>
      <link>https://stats.stackexchange.com/questions/648669/online-updating-of-t-value-for-simple-linear-regression</link>
      <description><![CDATA[假设我使用一个简单的普通最小二乘回归模型$y = \beta_1 x + \beta_0$将一个因变量$y$回归到一个独立变量$x$。假设我从 $n$ 个数据点 $(x_1,y_1), \ldots (x_n, y_n)$ 开始，然后拟合回归以获得
$$
\hat{\beta_1} = \frac{s_{xy}}{s^2_x}
$$
and
$$
\hat{\beta_0} = \bar{y} - \hat{\beta_1} \bar{x}
$$
现在假设我有一系列新传入数据 $(x_{n+1},y_{n+1}),\ldots$。
我 知道如何计算新数据集的项$\bar{x}, \bar{y},s^2_x,s^2_y,s_{xy}$，并使用新到达的点进行扩充，从而实现高效计算 - 也就是说，我可以利用我从前$n$个数据点对它们的了解，在恒定的时间内更新所有这些数量。因此，我也知道如何有效地更新数量 $\hat{\beta_1},\hat{\beta_0},r^2$。
我想知道是否有任何巧妙的技巧可以让我有效地更新我的 $t$ 分数，即
$$
t = \frac{\hat{\beta_1}}{\frac{s}{\sqrt{\sum{(x_i-\bar{x})^2}}}}
$$
其中 $s$ 是我们在模型中假设的误差中底层常数标准差 $\sigma$ 的无偏估计量，由
$$
s = \frac{1}{n-2} \sum{(y_i - \hat{y_i})^2}
$$
在我看来，主要问题是，当我们添加新数据点时，所有 $\hat{y_i}$ 值都会发生变化，因此，在重新计算 $s$ 时，它们都是必需的。有没有办法解决这个问题？我可以在恒定时间内更新 $t$ 得分（或等效地 $s$）吗？
假设答案是否定的，我认为对 $t$ 得分可以改变多少进行一些控制会很有用。我可以推导出这一点，但我也希望得到任何文献指点。]]></description>
      <guid>https://stats.stackexchange.com/questions/648669/online-updating-of-t-value-for-simple-linear-regression</guid>
      <pubDate>Wed, 05 Jun 2024 10:13:51 GMT</pubDate>
    </item>
    <item>
      <title>如果分布中缺少数据，哪种统计数据可以最好地替代真实样本均值？</title>
      <link>https://stats.stackexchange.com/questions/648668/what-statistic-is-best-alternative-to-the-true-sample-mean-in-case-of-missing-da</link>
      <description><![CDATA[我有一组值，其中每个值代表基于一个样本的分布的统计数据。底层可观察值可以假设为粒子长度，因此该值是粒子长度分布的平均值或中位数或其他统计数据。问题是使用图像分析来评估分布。由于粒子重叠，分布不完整且有偏差，因此较长的长度相对于较短的长度被过度代表。一个样本分布中最长的粒子的长度是准确的。每个分布中的粒子数量实际上并不相同，可以假设在 10-50 之间，每个粒子通常与 1-5 个其他粒子重叠。
总而言之，每个样本都会生成一个不完整的离散分布，从中可以计算出一个代表性统计数据。统计数据“最大值”是准确的，其他数据（例如中位数或均值）可能不是，但没有办法通过实验来测试这一点。长度分布未知，但可能不是高斯分布，可能略微偏向大值，而短值很少。还请注意，不同样本的个体分布可能会有所不同，但您可以假设不同样本的分布的一般形状相似，并且真实统计量的分布是正态的。
我的问题是，基于此信息，是否有可能选择最能代表每个样本分布的真实平均值的统计量。特别是，如果离散采样分布中的最大值是准确的，但分布的其他区域由于重叠而采样不足。直观地说，如果我有 N 个样本，“最佳”意味着真实均值与我为这些分布选择的统计量之间的平方偏差之和最小化，因此 SSE 最小。
我的直觉是中位数是最好的统计数据。我正在考虑进行一些数值模拟，但为了节省时间，因为这可能是统计学家可以轻松诊断的问题，我首先在这里询问。在此先感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/648668/what-statistic-is-best-alternative-to-the-true-sample-mean-in-case-of-missing-da</guid>
      <pubDate>Wed, 05 Jun 2024 10:06:22 GMT</pubDate>
    </item>
    <item>
      <title>计算负二项模型中两个变量的组合置信区间（在 R 中）</title>
      <link>https://stats.stackexchange.com/questions/648666/calculate-combined-confidence-interval-of-two-variables-in-a-negative-binomial-m</link>
      <description><![CDATA[我在 R 中有一个多变量负二项模型，我想将两个变量组合起来：

变量 1：二元变量（否/是）

变量 2：连续变量（0-3）


我想计算以下组合的置信区间：

变量 1 + 变量 2

变量 1 + 2*变量 2

变量 1 + 3*变量 2


我不想将变量重新编码为 1 个变量，因为我还想保留“是”的总体估计值对于变量 1。
我读到过，第一个组合的方差可以计算为方差（变量 1）+方差（变量 2）+ 2*协方差（变量 1，变量 2）。有人知道这是否正确以及如何获得其他组合的方差（和置信区间）吗？或者是否有其他方法来计算组合置信区间？]]></description>
      <guid>https://stats.stackexchange.com/questions/648666/calculate-combined-confidence-interval-of-two-variables-in-a-negative-binomial-m</guid>
      <pubDate>Wed, 05 Jun 2024 09:36:44 GMT</pubDate>
    </item>
    <item>
      <title>生成等效正态分布和对数正态分布</title>
      <link>https://stats.stackexchange.com/questions/648665/generating-equivalent-normal-and-lognormal-distributions</link>
      <description><![CDATA[设 $X \sim N(\mu, \sigma)$ 和 $Y = e^X \sim LN(\mu, \sigma)$，我想使用 R 或其他程序生成相同的分布。我的理解是参数 $\mu$ 和 $\sigma$ 应该相同。
但是，两个概率密度图不一致。
# 参数
mX &lt;- 1 # muX
sX &lt;- 1 # sigmaX

# 分位数
x &lt;- qnorm(seq(.001, .999, length = 1000), mX, sX)
y &lt;- qlnorm(seq(.001, .999, length = 1000), mX, sX)

# prob.密度
pX &lt;- dnorm(x, mX, sX)
pY &lt;- dlnorm(y, mX, sX)

# plot
plot.new()
plot.window(c(-5, 5), c(0, .8))
lines(x, pX, col = 1)
lines(log(y), pY, col = 2)
legend(&quot;topright&quot;, lty = 1, col = 1:2, legend = c(&quot;X&quot;, &quot;Y&quot;))
axis(1)
axis(2)
box()


我做错了什么？我知道
$$
E[Y] = e^{\mu + \frac{1}{2}\sigma^2}
$$
和
$$
Var[Y] = e^{2\mu + \sigma^2}(e^{\sigma^2} - 1)
$$
但根据应该提供给 qlnorm 和 dlnorm 的参数，我不认为这是对数正态分布的参数应该使用的。（以及其他程序中的等效函数。）]]></description>
      <guid>https://stats.stackexchange.com/questions/648665/generating-equivalent-normal-and-lognormal-distributions</guid>
      <pubDate>Wed, 05 Jun 2024 09:34:18 GMT</pubDate>
    </item>
    <item>
      <title>重复测量的负二项回归，每天进行一周</title>
      <link>https://stats.stackexchange.com/questions/648663/negative-binomial-regression-for-repeated-measures-daily-for-one-week</link>
      <description><![CDATA[我有一个包含 2,000 名受试者的数据集，每个受试者提供一周的每日社交接触数据（14,000 次观察 = 2000 名受试者 * 7 天）。我打算使用受试者的年龄、家庭规模、星期几以及可能的其他因素（例如居住地或职业地区）等变量来描述接触人数。
结果变量，即人均每日接触人数，过于分散，所以我想尝试一个假设负二项分布的广义线性模型。但是，数据包括对同一受试者的重复测量（即每个受试者 7 次观察），这违反了独立性假设。因此，我尝试了一个广义线性混合模型（R 中 lme4 包中的 glmer.nb），但尽管调整了各种控制参数，优化算法仍未收敛。我正在寻找问题的替代解决方案，而无需诉诸广义线性混合建模。
这是我的问题：以下方法是否合理？我从原始数据中抽样，这样通过为每个受试者均匀随机地选择一周中的一天，每个受试者只存在一个观察值。这将数据集从 14,000 个观察值减少到 2,000 个观察值。然后，我对这个子集执行负二项回归，并重复此过程多次（例如，20,000 次）。
作为练习，我对 14000 个观察值执行了负二项回归（忽略重复测量独立性假设的违反），并且还对 2,000 个观察值的 4,000 个样本运行了负二项回归。两种方法的估计值（95% 置信区间）相似，尽管抽样子集的标准误差更宽（如下）。估计_2000 的置信区间取自 4,000 次模拟的中央 95% 百分位数。




var
estimates_14000
estimates_2000




1
(截距)
3.05 (2.78 - 3.34)
3.04 (2.51 - 3.66)


2
age_grp5-9
1.67 (1.53 - 1.82)
1.66 (1.41 - 1.96)


3
年龄组10-14
1.54 (1.41 - 1.68)
1.54 (1.34 - 1.79)


4
年龄组15-19
1.45 (1.33 - 1.59)
1.45 (1.25 - 1.69)


5
年龄组20-29
0.60 (0.55 - 0.65)
0.60 (0.52 - 0.69)


6
年龄组30-39
0.69 (0.63 - 0.74)
0.69 (0.60 - 0.79)


7
年龄组40-49
0.75 (0.69 - 0.81)
0.75 (0.66 - 0.86)


8
年龄组50-59
0.82 (0.75 - 0.88)
0.82 (0.72 - 0.94)


9
年龄组60-69
1.05 (0.97 - 1.13)
1.04 (0.92 - 1.21)


10
age_grp70-79
1.11 (1.02 - 1.21)
1.11 (0.96 - 1.29)


11
sexM
1.00 (0.98 - 1.02)
1.00 (0.96 - 1.04)


12
dayofweek星期一
1.47 (1.41 - 1.54)
1.47 (1.28 - 1.68)


13
dayofweek星期二
1.46 (1.39 - 1.52)
1.46 (1.26 - 1.67)


14
dayofweek星期三
1.74 (1.67 - 1.82)
1.75 (1.52 - 2.00)


15
dayofweek星期四
1.58 (1.51 - 1.66)
1.58 (1.38 - 1.82)


16
dayofweek星期五
1.55 (1.48 - 1.63)
1.56 (1.35 - 1.78)


17
dayofweek星期六
1.13 (1.08 - 1.19)
1.14 (0.98 - 1.31)


18
hhsize_grp2
1.15 (1.10 - 1.20)
1.15 (1.05 - 1.26)


19
hhsize_grp3
1.27 (1.22 - 1.33)
1.27 (1.16 - 1.39)


20
hhsize_grp4
1.47 (1.40 - 1.53)
1.47 (1.34 - 1.60)


21
hhsize_grp5+
1.66 （1.57 - 1.74）
1.65（1.48 - 1.85）


]]></description>
      <guid>https://stats.stackexchange.com/questions/648663/negative-binomial-regression-for-repeated-measures-daily-for-one-week</guid>
      <pubDate>Wed, 05 Jun 2024 07:51:07 GMT</pubDate>
    </item>
    <item>
      <title>测试两个预测（通过多元回归模型）是否存在显著差异</title>
      <link>https://stats.stackexchange.com/questions/648662/test-whether-two-predictions-via-a-multiple-regression-model-are-significantly</link>
      <description><![CDATA[我正在 JMP 中为学校开展一个医学研究项目，其中我使用多元线性回归模型，该模型尝试根据以下内容预测中风患者的临床结果（以称为“出院 mRS”的数值量表形式）：

1 个连续预测因子（入院时 NIHSS，即入院时中风严重程度的测量值）
1 个分类预测因子（EVT 时间，即中风患者可能接受的治疗），可以是以下 3 个值中的任何一个：

1 = 到达医院后立即实施 EVT（治疗）
2 = 经过一段时间后实施 EVT
0 = EVT 未管理


交互项 (入院时 NIHSS * EVT 时间)

请参阅本文底部，了解 JMP 中当前的模型样子。

但首先，我的问题是：
对于任何一个给定的 入院时 NIHSS 值，我想计算预测的平均结果（基于此模型）在患者接受 EVT 立即（即EVT 时间 = 1）与 无 EVT（即 EVT 时间 = 0） - 也就是说，在分类预测变量的两个不同值之间。
有没有办法在 JMP 中进行这种分析？
（概念上，我的目标是能够以临床有用的方式利用该模型中的 2 个预测变量，例如希望该模型可以帮助我们决定哪些患者 - 在这种情况下，根据他们中风的严重程度 - 应该接受治疗或不接受治疗，并预测所述治疗的结果。）
感谢您的帮助！

JMP 生成的模型如下所示：


再次感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648662/test-whether-two-predictions-via-a-multiple-regression-model-are-significantly</guid>
      <pubDate>Wed, 05 Jun 2024 07:47:41 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用虚拟变量来估计 Translog 函数？</title>
      <link>https://stats.stackexchange.com/questions/648660/is-it-possible-to-estimate-a-translog-function-with-a-dummy-variable</link>
      <description><![CDATA[我想估计一个超对数生产函数，但我的独立变量中有一个虚拟变量。但是，我在这里读到一些评论，本质上，超对数估计中的所有解释变量都必须是对数。真正的答案是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648660/is-it-possible-to-estimate-a-translog-function-with-a-dummy-variable</guid>
      <pubDate>Wed, 05 Jun 2024 06:36:08 GMT</pubDate>
    </item>
    <item>
      <title>时间序列回归模型是否需要平稳性或一阶协整？</title>
      <link>https://stats.stackexchange.com/questions/648655/is-stationarity-or-co-integration-of-order-one-needed-for-time-series-regression</link>
      <description><![CDATA[在阅读了著名优秀书籍预测原理与实践（作者：Hyndman &amp; Athanasopoulos）的第 7 章时间序列回归模型后，我发现其中没有提到时间序列是否需要平稳，或者如果它们是一阶积分，I(1)，是否需要进行协整检验。我的理解是，如果时间序列不是平稳的（例如，如果它们有趋势），回归模型将是虚假的。
图 7.2 和 7.6 中用作示例的时间序列乍一看似乎是平稳的。因此，该示例无助于阐明我的问题：
时间序列回归模型（无论是否为多变量）是否必须满足所有变量的平稳性或必须为一阶协整才能用于预测？]]></description>
      <guid>https://stats.stackexchange.com/questions/648655/is-stationarity-or-co-integration-of-order-one-needed-for-time-series-regression</guid>
      <pubDate>Wed, 05 Jun 2024 03:45:30 GMT</pubDate>
    </item>
    <item>
      <title>负二项模型的离散度</title>
      <link>https://stats.stackexchange.com/questions/648654/dispersion-of-a-negative-binomial-model</link>
      <description><![CDATA[在 R 的 glm.nb 摘要中，它表示色散参数 $\phi$ 设置为 1。当模型为
$Y \sim \text{Negbin}(\mu,\theta)$
其中 $E(Y)=\mu$ 和 $V(Y)=\mu+\mu^2/\theta$。这里的色散 $\phi$ 是否意味着指数族公式中的 $V(Y)=\phi(\mu+\mu^2/\theta)$？鉴于$\theta$可以自由调整，测试$H_0: \phi=1$是否有意义？我知道负二项式模型可能由于各种原因（例如，许多零和其他值之间的关系）不能很好地拟合数据，但如果我们说它是过度分散，我们还需要考虑正态分布的过度分散，但人们经常说高斯模型中没有过度分散。
set.seed(1)
x &lt;- round(rep(seq(3,30,by=3),each=10))
y &lt;- rnbinom(length(x),mu=exp(1+0.1*x),size=5)

plot(x,y)
library(MASS)
model &lt;- glm.nb(y~x)
r &lt;- resid(model,type=&quot;pearson&quot;)
(phi &lt;- sum(r^2)/(length(x)-3)) #分散

类似帖子：链接]]></description>
      <guid>https://stats.stackexchange.com/questions/648654/dispersion-of-a-negative-binomial-model</guid>
      <pubDate>Wed, 05 Jun 2024 02:46:33 GMT</pubDate>
    </item>
    <item>
      <title>比较匹配的前后李克特量表数据（n = 40）</title>
      <link>https://stats.stackexchange.com/questions/648644/comparing-matched-pre-post-likert-scale-data-n-40</link>
      <description><![CDATA[我有需要分析的前后匹配李克特量表数据（约 20 个问题）。1) 分析这些数据的最佳方法是什么？我最初认为使用均值并进行配对样本 t 检验是可以的，但这似乎不适用于李克特量表数据。配对样本 wilcoxin 合适吗？一些背景信息，这是评估数据，用于查看课程前后学生的知识和技能。]]></description>
      <guid>https://stats.stackexchange.com/questions/648644/comparing-matched-pre-post-likert-scale-data-n-40</guid>
      <pubDate>Tue, 04 Jun 2024 20:53:20 GMT</pubDate>
    </item>
    <item>
      <title>负偏数据的转换[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648633/transformation-of-negatively-skewed-data</link>
      <description><![CDATA[我问了一个问题，感谢您的反馈，我注意到它是多么不具体，没有经过充分考虑。
所以，我试图更具体一点。
我目前正在尝试计算一个调节分析，以愤怒（分数从 5 到 25）作为 IV，男性年龄作为调节因素，IPV 种类作为因变量。DV 描述了伴侣经历过的不同形式的 IPV 的数量。它们可以从 0 到 5。2 表示例如这个人经历了 2 种形式的 IPV，无论具体是哪一种。
我的大多数参与者都经历过所有 5 种形式（值 5）。
现在我发现，使用 ggplot 和平滑“loess”，至少交互图不是线性的（看起来更像三次函数）。
所以我想计算一个非线性模型。
model_gam &lt;- mgcv::gam(ipv_variety ~ s(dar_scaled) + s(age_scaled, k = 12) + ti(dar_scaled, age_scaled), data = merged_all_complete, method = &quot;REML&quot;)
#alternative
gam1 &lt;- lm(ipv_variety ~ ns(dar_scaled, 5) * age_scaled, data=merged_all_complete)

据我所知（我可能不正确），所选的系列取决于 DV 的分布。目前，默认的高斯分布不适合我的数据。
因此，我想知道是否有适合我的数据的系列，或者是否有办法转换我的 DV 以便高斯分布适合。
我比较新，所以如果我忽略了一些关键细节，我深表歉意。
如果还有其他问题，我很乐意回答。
再次感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/648633/transformation-of-negatively-skewed-data</guid>
      <pubDate>Tue, 04 Jun 2024 18:31:19 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 GAM、模型和假设</title>
      <link>https://stats.stackexchange.com/questions/648609/gam-in-r-model-and-assumptions</link>
      <description><![CDATA[我遇到了以下问题：我的调节分析显示非线性。因此，我尝试拟合 GAM。我有几个问题：

我的 DV 是左偏的，有很多高值和一些低值。
在拟合模型时，我没有足够的 k 来表示 1 个变量，但增加 k 也无济于事。
我的共轭性很高。

我对这个话题比较陌生，过去几天没有找到答案。
这是我的代码：我有几个模型：
model_gam &lt;- mgcv::gam(ipv_variety ~ s(dar_scaled) +
s(age_scaled, k = 12) + ti(dar_scaled, age_scaled), 
data = merged_all_complete, method = &quot;REML&quot;)

model_gam2 &lt;- mgcv::gam(ipv_variety ~ te(dar_scaled, k = 12) + 
te(age_scaled, k = 13) + ti(dar_scaled, age_scaled), 
data = merged_all_complete)

#alternative
gam1 &lt;- lm(ipv_variety ~ ns(dar_scaled, 5) * age_scaled, 
data=merged_all_complete)

mgcv::gam.check(model_gam)

方法：REML 优化器：外牛顿
12 次迭代后完全收敛。
梯度范围 [-4.809951e-05,4.615121e-05]
(得分 251.5576 &amp; 比例 2.881421)。
Hessian 正定，特征值范围 [7.643802e-06,62.50661]。
模型等级 = 37 / 37 

基础维度 (k) 检查结果。低 p 值 (k 指数&lt;1) 可能
表示 k 太低，尤其是当 edf 接近 k&#39; 时。

k&#39; edf k 指数 p 值 
s(dar_scaled) 9.00 1.00 0.94 0.260 
s(age_scaled) 11.00 1.00 0.86 0.045 *
ti(dar_scaled,age_scaled) 16.00 2.29 0.98 0.365 
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

mgcv::gam.check(model_gam2)

方法：GCV 优化器：magic
平滑参数选择在 18 次迭代后收敛。
收敛时的 RMS GCV 得分梯度为 1.247369e-07。
Hessian 为正定。
模型等级 = 40 / 40

基础维度 (k) 检查结果。低 p 值（k 指数&lt;1）可能
表示 k 太低，尤其是当 edf 接近 k&#39; 时。

k&#39; edf k 指数 p 值 
te(dar_scaled) 11.00 2.78 0.96 0.29 
te(age_scaled) 12.00 1.00 0.84 0.02 *
ti(dar_scaled,age_scaled) 16.00 2.95 1.02 0.52 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

concurvity(model_gam)
para s(dar_scaled) s(age_scaled) ti(dar_scaled,age_scaled)
最差 0.686332 0.9685481 0.9463088 0.9723609
观察值 0.686332 0.4515971 0.7249471 0.4033396
估计值 0.686332 0.4769273 0.7471936 0.2483518
&gt; concurvity(model_gam2)
para te(dar_scaled) te(age_scaled) ti(dar_scaled,age_scaled)
最差 0.7006861 0.9708301 0.9635877 0.9779052
观察到的 0.7006861 0.5241473 0.7229355 0.4458624
估计 0.7006861 0.2949492 0.3336875 0.2602797

我尝试使用 bs = &quot;ps&quot; 进行惩罚，但这对 concurvity 没有帮助。我不知道哪种方法最好，默认方法与 REML 显示出类似的结果。我找不到正确的分布。目前它是高斯的。
提前非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/648609/gam-in-r-model-and-assumptions</guid>
      <pubDate>Tue, 04 Jun 2024 12:44:45 GMT</pubDate>
    </item>
    <item>
      <title>Python 拟合的 Sigmoid 极值几乎未被使用</title>
      <link>https://stats.stackexchange.com/questions/648607/python-fitted-sigmoid-extreme-values-barely-being-used</link>
      <description><![CDATA[我最初处理的是大量值对。我使用自定义启发式方法从每对值计算得分，并将该集合转换为值数组。我对其进行了排序，并将每个值分配给 x，将其标准化排名（介于 0 和 1 之间，均排除）分配给 y。
这是一个例子：

我尝试拟合 S 型函数，但我认为它被大量居中数据误导，没有考虑到极端值，而我实际上计划使用这个新函数将 0 到 1 之间的得分分配给任何新值。现在，使用该解决方案，任何超过阈值 31 的值的排名都会达到大约 0.93。
如何降低中心点的影响？我考虑过简单地删除一些，但我不知道正确的方法，甚至不知道这是否是正确的方法。
这是我的代码：
import json
import numpy as np
from scipy.optimize import curve_fit
import matplotlib.pyplot as plt

filename = &quot;scores.json&quot;

使用 open(filename, &#39;r&#39;) 作为 f:
data = json.load(f)

x_values = [point[&#39;x&#39;] for point in data]
y_values = [point[&#39;y&#39;] for point in data]

x_data = np.array(x_values)
y_data = np.array(y_values)

def sigmoid(x, L, x0, k):
return L / (1 + np.exp(-k * (x - x0)))

initial_guess = [1, np.median(x_data), 1]

params, covariance = curve_fit(sigmoid, x_data, y_data, p0=initial_guess, maxfev=10000)

L, x0, k = params

print(f&quot;优化参数：L = {L}, x0 = {x0}, k = {k}&quot;)

plt.scatter(x_data, y_data, marker=&#39;+&#39;, label=&#39;Data&#39;)

x_fit = np.linspace(min(x_data), max(x_data), 400)
y_fit = sigmoid(x_fit, *params)
plt.plot(x_fit, y_fit, label=&#39;Fitted Sigmoid&#39;, color=&#39;red&#39;)

plt.legend()
plt.show()

以下是找到的参数：
# 优化参数：L = 0.9305200252602871，x0 = 2.107303517527327，k = 0.24761667539895446
]]></description>
      <guid>https://stats.stackexchange.com/questions/648607/python-fitted-sigmoid-extreme-values-barely-being-used</guid>
      <pubDate>Tue, 04 Jun 2024 12:07:38 GMT</pubDate>
    </item>
    </channel>
</rss>