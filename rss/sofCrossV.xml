<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 31 Jan 2024 09:13:03 GMT</lastBuildDate>
    <item>
      <title>从理论版本导出 Anderson Darling 检验统计量的样本版本</title>
      <link>https://stats.stackexchange.com/questions/638179/deriving-sample-version-of-anderson-darling-test-statistic-from-the-theoretical</link>
      <description><![CDATA[在文献中，我见过两种类型的 Anderson-Darling 检验统计量。其一表示为
$A_T^2 = n\int_{-\infty}^{\infty}\frac{(F_n(x)-F(x))^2}{F (x)(1-F(x))}dF(x)$ 另一个由 $A_s^2 = -n-\sum_{i= 给出1}^{n}\frac{2i-1}{n}[\ln F(Y_i)+\ln(1-F(Y_{n+1-i}))]$，其中 &lt; span class=&quot;math-container&quot;&gt;$Y_1, Y_2,\cdots, Y_n$ 是有序样本。
我的问题是，我们如何从 $A_T^2$ 获取 $A^2_s$ ？我的猜测是我们必须求解 Riemann-Stieltjes 积分，但我不知道如何继续。]]></description>
      <guid>https://stats.stackexchange.com/questions/638179/deriving-sample-version-of-anderson-darling-test-statistic-from-the-theoretical</guid>
      <pubDate>Wed, 31 Jan 2024 09:10:35 GMT</pubDate>
    </item>
    <item>
      <title>2xN 卡方检验后的事后分析</title>
      <link>https://stats.stackexchange.com/questions/638178/post-hoc-after-a-2xn-chi-squared-test</link>
      <description><![CDATA[我有两组人，我想确定他们的语言是否存在显着差异。我的数据由词频组成（一个人在给定时间范围内说出给定单词的次数），因此：

我使用卡方检验来比较词频的平均值（向量x和y），发现两组之间存在显着差异（非常低的 p -价值）。现在，我正在考虑仅对两组进行事后分析是否有意义。在这种情况下如何进行事后分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/638178/post-hoc-after-a-2xn-chi-squared-test</guid>
      <pubDate>Wed, 31 Jan 2024 08:58:16 GMT</pubDate>
    </item>
    <item>
      <title>伯努利试验的成功具有不同的概率，但概率只有在成功后才会改变</title>
      <link>https://stats.stackexchange.com/questions/638175/success-of-bernoulli-trials-with-different-probabilities-but-a-probability-is-o</link>
      <description><![CDATA[我想计算不同概率的伯努利试验，但概率只有在成功后才会改变。
比如这里，下图中每个状态下所有p都不同，s: (0, 1, ..., m)。

审判将从状态 (0) 开始。
然后，p_0将作为概率用于试验。成功的秘诀。
如果我们成功，那么 p_1 将用于下一次试验。
一般情况如何推导Pr[X=i]？更简单的方法？
我指的是泊松二项分布，但似乎有点不同。
i 是 k 次试验的成功结果。
目前，我得出如下。
$Pr[X=0] = p_0^0 \times (1-p_1)^(k-0)$。
$Pr[X=1] = p_0^1 \times (\text{所有失败组合的总和，$1-p_0$, $1-p_1$ k-1 次试验}) $。
...]]></description>
      <guid>https://stats.stackexchange.com/questions/638175/success-of-bernoulli-trials-with-different-probabilities-but-a-probability-is-o</guid>
      <pubDate>Wed, 31 Jan 2024 08:52:15 GMT</pubDate>
    </item>
    <item>
      <title>伯努利试验的成功具有不同的概率，但概率只有在成功后才会改变</title>
      <link>https://stats.stackexchange.com/questions/638174/success-of-bernoulli-trials-with-different-probabilities-but-a-probability-is-o</link>
      <description><![CDATA[我想计算不同概率的伯努利试验，但概率只有在成功后才会改变。
比如这里，下图中每个状态下所有p都不同，s: (0, 1, ..., m)。

审判将从状态 (0) 开始。
然后，p_0将作为概率用于试验。成功的秘诀。
如果我们成功，那么 p_1 将用于下一次试验。
一般情况如何推导Pr[X=i]？更简单的方法？
我指的是泊松二项分布，但似乎有点不同。
i 是 k 次试验的成功结果。
目前，我得出如下。
$Pr[X=0] = p_0^0 \times (1-p_1)^(k-0)$。
$Pr[X=1] = p_0^1 \times (\text{所有失败组合的总和，$1-p_0$, $1-p_1$ k-1 次试验}) $。
...]]></description>
      <guid>https://stats.stackexchange.com/questions/638174/success-of-bernoulli-trials-with-different-probabilities-but-a-probability-is-o</guid>
      <pubDate>Wed, 31 Jan 2024 08:52:15 GMT</pubDate>
    </item>
    <item>
      <title>了解 0-1 和铰链损耗之间的关系</title>
      <link>https://stats.stackexchange.com/questions/638171/understanding-relation-between-0-1-and-hinge-losses</link>
      <description><![CDATA[假设我们使用线性预测器，我试图从概念上理解对于一组点，它如何具有相对较低的 0-1 损失但相对较高的铰链损失。例如，有人告诉我，可以选择一组点，使得所有这些线性预测变量的 0-1 损失最小（即 $p_w(x) = \langle w, x \rangle$），其中 $w$ 位于二维平面中）低于 0.1，但对于同一组点，预测器最小化铰链损失高于某个阈值，例如 $0.5$。
针对这个问题，在我看来，学习了SVM之后，一直很难理清0-1损失和铰链损失的概念。我对铰链损失的理解是，随着错误分类的点进一步增加，它会变得更大，但对我来说，“最小化铰链损失”的预测器会带来什么并不直观。对于给定的一组点来说，它看起来像是立即的，至少在 $\mathbb{R^2}$ 中，对我来说很明显最小化超平面是什么0-1 输球的样子。谁能帮助我获得一些直觉并理解这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/638171/understanding-relation-between-0-1-and-hinge-losses</guid>
      <pubDate>Wed, 31 Jan 2024 07:44:50 GMT</pubDate>
    </item>
    <item>
      <title>先验和证据之间实际上有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/638170/what-is-actually-the-difference-between-prior-and-evidence</link>
      <description><![CDATA[当看到贝叶斯定理先验和证据时，它与联合概率(A n B)有相似之处。那么它们之间真的有明显的区别吗？？？]]></description>
      <guid>https://stats.stackexchange.com/questions/638170/what-is-actually-the-difference-between-prior-and-evidence</guid>
      <pubDate>Wed, 31 Jan 2024 06:37:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么 SSL 不能处理表格数据？</title>
      <link>https://stats.stackexchange.com/questions/638166/why-cant-ssl-handle-tabular-data</link>
      <description><![CDATA[
标准遗传编程自我监督策略的性能分析

&lt;块引用&gt;
1 简介
自监督学习（SSL）方法已被广泛用于训练计算机视觉和自然语言处理领域的深度学习模型。这种训练范例的工作原理是在特定领域的借口任务上利用大量未标记的数据，从而允许学习数据中的底层关系和模式。这些模型可以针对标记数据量减少的下游任务进行微调，与专门针对减少的标记数据进行训练相比，可以提高性能。这些策略是计算机视觉 [3, 7] 和自然语言处理 [11] 中的常见做法，借口任务通常涉及输入数据的更改。一些常见的借口任务是旋转[6]、上下文预测[5]和排列预测[8]。
虽然 SSL 在这些域中无缝工作，但对于表格数据却不能如此。表格数据本质上是异构的并且不具有全局结构，这使得借口任务的开发并非微不足道。最近，已经提出了为表格数据定义特定领域借口任务的框架，例如损坏的数据重建和对比 Mixup，它产生的模型可以产生强大的特征转换 [4, 14]。
大多数标准机器学习算法不符合经过大量处理的数据，甚至要求数据以特定方式分布。与更传统的机器学习模型相比，遗传编程（GP）[10]通过执行自己的特征构建和选择，其基本假设要少得多。这一特性引发了以下研究问题：标准 GP 是否能够利用 SSL 方法处理的数据来提高其性能？
据我们所知，之前尚未对 GP 的任何类型的 SSL 进行过研究。在这项工作中，我们的目标是通过分析标准 GP 算法在使用 SSL 模型进行数据转换时的性能来填补这一空白。

我不明白强调的文字。
为什么 SSL 处理表格数据更困难？
这是什么意思 - 表格数据本质上是异构的并且不具有全局结构？]]></description>
      <guid>https://stats.stackexchange.com/questions/638166/why-cant-ssl-handle-tabular-data</guid>
      <pubDate>Wed, 31 Jan 2024 05:23:22 GMT</pubDate>
    </item>
    <item>
      <title>Skellam 分布的分位数函数是什么？</title>
      <link>https://stats.stackexchange.com/questions/638165/what-is-the-quantile-function-of-a-skellam-distribution</link>
      <description><![CDATA[阅读 是否有 Skellam 分布或两个泊松 r.v. 差异的 95% 置信区间的公式？，我意识到 我宁愿使用分位数函数。不幸的是 Wiki 表明第一类修正贝塞尔函数位于概率质量函数中，这意味着我不知道如何直接求解 $k$。
能够计算 Skellam 分布式回归模型的预测区间在商业、医疗保健和物理（以及我确信的其他领域）中可能会很方便。]]></description>
      <guid>https://stats.stackexchange.com/questions/638165/what-is-the-quantile-function-of-a-skellam-distribution</guid>
      <pubDate>Wed, 31 Jan 2024 05:11:35 GMT</pubDate>
    </item>
    <item>
      <title>与常规 Copula 相比，使用 Vine Copula 有何优势？</title>
      <link>https://stats.stackexchange.com/questions/638164/advantages-of-using-vine-copulas-over-regular-copulas</link>
      <description><![CDATA[我是 Copula 的新手，我试图从概念上理解两种主要类型的 Copula 之间的差异：常规 Copula 和 Vine Copula。两者都用于模拟相关多元概率分布的数据（这是一个难题） - 特别是在边际分布不是同一类型的情况下（例如正态分布和指数分布的联合分布）。
据我所知，Vine Copula 似乎比常规 Copula 更复杂。这让我想知道：与常规 Copulas 相比，使用 Vine Copulas 可以获得哪些优势？
这是我自己尝试回答这个问题：
定义： Copula 是将边际分布与其多元分布联系起来的函数。如果我们有两个具有累积分布函数的随机变量 $X$ 和 $Y$ $F_X(x)$ 和 $F_Y(y)$ ，以及一个 copula 函数 $C(u, v)$，则联合 CDF 为：
$$
F(x, y) = C(F_X(x), F_Y(y))
$$
为了说明使用 Vine Copula 相对于常规 Copula 的额外优势，我尝试创建以下示例：
示例：考虑以下 3 维概率分布：
$$f(x, y, z)$$
使用链式法则https://en.wikipedia.org/wiki/Chain_rule_(概率） - 我们可以将其分为两部分：
$$
f(x, y, z) = f_X(x) f_{Y|X}(y|x) f_{Z|XY}(z|x, y)
$$
现在，比较使用 Vine Copula 与常规 Copula 的优势：

如果我们使用常规 Copula，我们可以使用单个 Copula 函数来表示此概率分布（即有 1 个 copula 函数是各个分布的函数）：

$$
F(x, y, z) = C[F_X(x) , F_{Y|X}(y|x) , F_{Z|XY}(z|x, y)]
$$

使用 Vine Copula，我认为我们可以使用多个 Copula 函数来表示此概率分布（即，我们将 3 个不同的 Copula 彼此相乘）：

$$
F(x, y, z) = C_{12}[F_X(x), F_{Y|X}(y|x)] \cdot C_{13}[(F_X(x), F_{Z|XY} (z|x, y)] \cdot C_{23|1}[F_{Y|X}(y|x), F_{Z|XY}(z|x, y)|F_X(x)]
$$
因此，与常规 Copula 相比，使用 Vine Copula 的优势在于您可以更灵活地决定要在各个分布集之间拟合哪些 Copula 函数。
结论：因此，这是 Vine Copulas 相对于常规 Copulas 的主要优势吗？我们有能力将不同的 Copula 函数（例如高斯函数、阿基米德函数）组合在一起，使我们能够捕获数据中更复杂的关系？
我的理解正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638164/advantages-of-using-vine-copulas-over-regular-copulas</guid>
      <pubDate>Wed, 31 Jan 2024 05:07:45 GMT</pubDate>
    </item>
    <item>
      <title>是否有 Skellam 分布或两个 Poisson r.v. 差异的 95% 置信区间的公式？</title>
      <link>https://stats.stackexchange.com/questions/638163/is-there-a-formula-for-the-95-confidence-interval-for-the-skellam-distribution</link>
      <description><![CDATA[我有两个独立的泊松随机变量，想要评估 X - Y 的置信界限。我知道泊松置信界限有一个封闭形式的解决方案，但需要差异。我可以针对给定的泊松故障率进行数值计算吗？例如，假设 X ~ Poisson(20) 和 Y ~ Poisson(18)。我可以从 X 和 Y 生成样本，减去并找到 0.025 和 0.975 处的分位数吗？或者类似地，从 Skillam(20,18) 生成样本并找到 0.025 和 0.975 分位数？]]></description>
      <guid>https://stats.stackexchange.com/questions/638163/is-there-a-formula-for-the-95-confidence-interval-for-the-skellam-distribution</guid>
      <pubDate>Wed, 31 Jan 2024 04:57:49 GMT</pubDate>
    </item>
    <item>
      <title>关于二元随机变量的问题[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638162/a-problem-on-bivariate-random-variables</link>
      <description><![CDATA[假设我们有绝对连续的随机向量 $X=(X_1,X_2)$ 和 $Y=(Y_1, Y_2)$。我们有 $Y_i=a_iX_i+b_i$ 和 $a_i&gt;0, b_i\geq 0$ $i=1,2$ 。令 ${F}$ 为分布函数，使得
${F}_X(x_1,x_2)=P(X_1\leq x_1,X_2\leq x_2).$
我们知道$\frac{\partial^2}{\partial x_1\partial x_2}F_X(x_1,x_2)=f_X(x_1,x_2).$&lt; /p&gt;
现在，\begin{align}
F_Y(y_1,y_2)&amp;=P(Y_1\leq y_1,Y_2\leq y_2)\\
&amp;=P(a_1X_1+b_1\leq y_1,a_2X_2+b_2\leq y_2)\\
&amp;=P(X_1\leq(y_1-b_1)/a_1,X_2\leq(y_2-b_2)/a_2)\\
&amp;=F_X((y_1-b_1)/a_1,(y_2-b_2)/a_2)\\
&amp;=F_X(x_1,x_2)
\end{对齐}
这里的形式我们可以说 $f(y_1,y_2)=f(x_1,x_2)$ 吗？
预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/638162/a-problem-on-bivariate-random-variables</guid>
      <pubDate>Wed, 31 Jan 2024 04:45:38 GMT</pubDate>
    </item>
    <item>
      <title>使用 IPTW 创建加权数据集后，我们可以在生存分析的回归过程中再次使用相同的协变量吗？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/638160/after-creating-a-weighted-dataset-using-iptw-can-we-use-the-same-covariates-aga</link>
      <description><![CDATA[我正在两个非随机治疗组之间进行一项观察性研究。我计划使用 IPTW（治疗加权的逆概率）来平衡两者。在加权之前，我将首先使用一些协变量（年龄、种族、癌症分期、农村地区等）来创建倾向得分。我的问题是，我是否必须在最终的回归模型中再次包含这些协变量才能评估两组之间的总体或癌症特异性生存率？ [我们不是已经将协变量纳入权重了吗？
我计划使用 R 进行总体生存分析（Kaplan-Meier 和多元 Cox 回归）以及癌症特异性生存分析（累积发生率 Fine 和 Gray，以及特定原因比例风险），分别用于预后和病因学问题。我将对未加权和加权数据集运行分析。
PS：这里绝对是新手:)！
TIA
~困惑的医生]]></description>
      <guid>https://stats.stackexchange.com/questions/638160/after-creating-a-weighted-dataset-using-iptw-can-we-use-the-same-covariates-aga</guid>
      <pubDate>Wed, 31 Jan 2024 04:08:53 GMT</pubDate>
    </item>
    <item>
      <title>纵向数据预测任务的上采样</title>
      <link>https://stats.stackexchange.com/questions/638159/upsampling-for-longitudinal-data-prediction-task</link>
      <description><![CDATA[我有一个纵向数据集，其中包含大约 14000 ID 和 110,000 观测值，每个 ID 不一定具有相同长度的时间窗口。
我正在执行一项预测任务，但是，我感兴趣的结果类别高度不平衡。鉴于我感兴趣的结果在给定 ID 的特定时间发生，并且仅发生一次（该 ID 的最后一个时间段，很像事件时间数据集）。
我的问题是：

如何在考虑结果变量的性质的同时对数据进行上采样？

是否有任何来源提供类似任务的实施细节？


我没有尝试对负类进行下采样，因为这会给我留下一个非常小的数据集。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/638159/upsampling-for-longitudinal-data-prediction-task</guid>
      <pubDate>Wed, 31 Jan 2024 03:36:02 GMT</pubDate>
    </item>
    <item>
      <title>Purging 和 Embargo 比 TimeSeriesSplit 更好吗？</title>
      <link>https://stats.stackexchange.com/questions/638157/are-purging-and-embargo-better-than-timeseriessplit</link>
      <description><![CDATA[众所周知，经典的 k 重 CV 在处理时间序列数据时效果不佳。我最近发现了两种方法，称为 Purging 和 Embargo，其目的是修改 k 倍 CV，从而不存在数据泄漏。我的问题是：

如果您可以简单地使用 TimeSeriesSplit，那么为什么要费力这样做呢？TimeSeriesSplit 更易于理解和实现？
是否有任何证据表明使用 Purging 和/或 Embargo 会产生更好的结果？

我特别有兴趣在金融时间序列的背景下回答这些问题。非常感谢任何对论文和/或直观论点的引用]]></description>
      <guid>https://stats.stackexchange.com/questions/638157/are-purging-and-embargo-better-than-timeseriessplit</guid>
      <pubDate>Wed, 31 Jan 2024 02:09:06 GMT</pubDate>
    </item>
    <item>
      <title>知识前测-后测/对照组和治疗组的 Cronbach 阿尔法</title>
      <link>https://stats.stackexchange.com/questions/638153/cronbachs-alpha-for-knowledge-pretest-posttest-control-and-treatment-groups</link>
      <description><![CDATA[我无法找到有关计算克朗巴赫阿尔法的这些具体问题的明确答案。为了我的论文研究，我进行了教学干预。我进行了前测和后测，以调查干预后知识的增长。我开发了测试项目，并且还开发了并行项目以尽量减少测试效果（因此参与者在测试前和测试后没有回答完全相同的问题）。我还有一个对照组，他们没有经历干预。
我使用 alpha 来衡量测试中六个分量表的内部一致性以及整个测试的内部一致性。每个子量表由 8 个多项选择项目组成，这些项目应该衡量我在治疗中教授的一个子主题。这些都是一个更大主题的一部分，这就是为什么我也想查看整个测试的 alpha 版本。
这是我的问题：

我是一起、单独还是仅计算和报告治疗组和对照组的 alpha？看起来预测时将它们结合起来就可以了，但是干预后，既然一组人经历了干预，那么他们不是不同的人群吗？我预计治疗组会有所改善，而对照组则保持不变。 （这就是实际发生的事情。）

我是否在预测和后测时单独、组合、仅后测、仅预测计算和报告 alpha？如果参与者在干预前不知道材料，那么预测试似乎会包含随机猜测。因此，我不确定测试该数据的内部一致性是否有意义。


测试题为知识选择题（不是李克特题）。我已将响应编码为正确或错误。我已经对所有这些不同的可能性进行了阿尔法分析，但我不知道我应该报告什么。我的顾问也不知道。
如果有人有信誉良好的引用，那将是理想的，但我也非常感谢了解您自己的做法和原因。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/638153/cronbachs-alpha-for-knowledge-pretest-posttest-control-and-treatment-groups</guid>
      <pubDate>Wed, 31 Jan 2024 00:38:50 GMT</pubDate>
    </item>
    </channel>
</rss>