<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 29 Jul 2024 12:29:34 GMT</lastBuildDate>
    <item>
      <title>为什么我们要对 t 分布进行测试，而不是对任何其他渐近正态分布进行测试？</title>
      <link>https://stats.stackexchange.com/questions/651937/why-do-we-test-on-the-t-distribution-rather-than-any-other-asymptotically-normal</link>
      <description><![CDATA[根据这个问题，答案指出，对于非正态分布的数据，t 分布并没有什么特别之处，我想知道为什么使用 t 分布。
对我的链接问题的回答是，t 分布比 z 分布更保守。但是，t 分布对于任何基础分布都不保守（我认为？），那么为什么不选择更保守的渐近正态分布呢？（我们有无限的可能性）。显然，如果我们走得太远，我们的测试就会太弱，所以也许提出这个问题的最佳方式是：
我们如何决定对非正态分布数据的小样本量进行测试的分布有多保守？为什么人们普遍认为 t 分布最能平衡这种权衡？]]></description>
      <guid>https://stats.stackexchange.com/questions/651937/why-do-we-test-on-the-t-distribution-rather-than-any-other-asymptotically-normal</guid>
      <pubDate>Mon, 29 Jul 2024 12:23:41 GMT</pubDate>
    </item>
    <item>
      <title>基于精度的平均变化计算</title>
      <link>https://stats.stackexchange.com/questions/651935/precision-based-calculation-of-mean-change</link>
      <description><![CDATA[我有两个关于平均变化（基于精度）的 SS 计算的基本问题（我是一名医生，不是生物统计学家，所以如果问题非常基础，请见谅）：

我的一位同事建议使用 0 相关性来计算保守的变化。我的观点是（保守估计可能是 0.5 相关性或 0.4），如果 Corr=0，即独立性，那么计算变化就没有什么意义了，最好使用事后平均值。对此有什么看法？
与问题无关，他计算了精度公式中输入的变化 SD，即 SDchange=SQRT(VARpre/npre+VARpost/Npost)，认为 CI 计算中用于平均变化的参数是 SEM。我会使用 SDchange=SQRT(VARpre+VARpost)，然后在公式中输入 SD 以进行基于精度的样本大小计算。

我的计算：我们使用测试前 SD 1.2 和测试后 SD 0.8 计算受试者内标准差。测试不同的相关性 0.5、0.6、0.7 和 0.8，我们分别获得了 1.058、0.963、0.858 和 0.738 的 SD 变化。平均值计算的精度为 1，平均值为 1，产生的 95% 置信区间范围为 [0.913, 1.087]（SD 为 1.05）到 [0.940, 1.060]（SD 为 0.73），共有 564 名受试者
对此有什么看法？
BR
亚历克斯]]></description>
      <guid>https://stats.stackexchange.com/questions/651935/precision-based-calculation-of-mean-change</guid>
      <pubDate>Mon, 29 Jul 2024 11:47:40 GMT</pubDate>
    </item>
    <item>
      <title>在双向固定效应中，添加时间和感兴趣的变量之间的交互项是否合适？</title>
      <link>https://stats.stackexchange.com/questions/651934/is-it-appropiate-to-add-a-interaction-term-between-time-and-the-variable-of-inte</link>
      <description><![CDATA[我感兴趣的是评估各国经济发展对其民主程度的影响。为此，我使用了双向固定效应。固定效应包括单位和时间固定效应。我读到过，使用固定效应模型时的一个隐含假设是效应大小随时间保持不变，因此，我应该在我感兴趣的系数和时间变量之间添加一个交互项。在这种情况下，变量可以是年份。然后，这个交互项可以指示系数的影响是否随时间保持不变。但是，我对使用双向固定效应还很陌生，我想知道这是否合适，因为模型已经包括了时间固定效应。希望有人能回答这是否合适。]]></description>
      <guid>https://stats.stackexchange.com/questions/651934/is-it-appropiate-to-add-a-interaction-term-between-time-and-the-variable-of-inte</guid>
      <pubDate>Mon, 29 Jul 2024 11:44:00 GMT</pubDate>
    </item>
    <item>
      <title>有哪些情况不应同时使用 Kolmogorov-Smirnov 检验和卡方检验来比较两个数据集？</title>
      <link>https://stats.stackexchange.com/questions/651933/are-there-cases-where-the-kolmogorov-smirnov-test-and-chi-squared-test-should-no</link>
      <description><![CDATA[通过关注Kolmogorov-Smirnov 检验与卡方检验问题，看起来这两个检验都可用于比较两组数据。显然，对于 Kolmogorov-Smirnov 检验，将数据保持“未分箱”，而对于卡方检验，将数据“分箱”。
是否存在两种检验可能互斥的情况，即您使用其中一种而不使用另一种，或者，它们不应一起使用来比较两组数据（因此当您“分箱”数据时，直方图/分布）的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/651933/are-there-cases-where-the-kolmogorov-smirnov-test-and-chi-squared-test-should-no</guid>
      <pubDate>Mon, 29 Jul 2024 11:20:50 GMT</pubDate>
    </item>
    <item>
      <title>Cox 回归的置信上限较高</title>
      <link>https://stats.stackexchange.com/questions/651931/high-upper-confidence-limit-on-cox-regression</link>
      <description><![CDATA[我正在对癌症的生存分析进行 Cox 回归分析。我在 Cox 回归中得到的置信区间上限很大，风险比 (expB) 也很高。我已纳入 10 个变量，并在 SPSS 中输入了方法。样本量为 32。置信上限高的原因是什么？如何处理？我已附上 spss 输出。
除癌症分期外，所有变量均有二分结果 (0,1)
]]></description>
      <guid>https://stats.stackexchange.com/questions/651931/high-upper-confidence-limit-on-cox-regression</guid>
      <pubDate>Mon, 29 Jul 2024 11:07:51 GMT</pubDate>
    </item>
    <item>
      <title>如何在影响评估中解释不平衡数据和治疗前暴露？</title>
      <link>https://stats.stackexchange.com/questions/651929/how-to-account-for-imbalanced-data-and-pre-treatment-exposure-in-an-impact-evalu</link>
      <description><![CDATA[我正在尝试评估辅导干预的影响，并且有接受治疗的儿童和对照组的测试成绩数据。但是，治疗组的研究报名时间早于对照组。因此，在对照组报名时，治疗组可能在基线测量之前最多接受了三个月的干预。
有两种不同的测试：
测试 1（不平衡数据）：自实施开始以来，治疗组的数据可用，但对照组的数据仅在报名后可用（即，治疗组的数据较早）
测试 2（治疗前暴露）：对于这两个组，数据仅在对照组报名后可用（即数据集是平衡的，但治疗组在第一个数据点之前已经接受了长达 3 个月的干预）。
在这两种情况下，是否有任何缓解策略？对于测试 1，是否有任何方法可以仅解释治疗组的早期测试分数数据？对于测试 2，我是否只需要接受效应大小的任何系数实际上都是下限估计值？]]></description>
      <guid>https://stats.stackexchange.com/questions/651929/how-to-account-for-imbalanced-data-and-pre-treatment-exposure-in-an-impact-evalu</guid>
      <pubDate>Mon, 29 Jul 2024 11:04:02 GMT</pubDate>
    </item>
    <item>
      <title>数据集比较的异常值检测</title>
      <link>https://stats.stackexchange.com/questions/651927/outlier-detection-for-data-set-comparison</link>
      <description><![CDATA[我有两个数据集，它们具有相似的列，一个是数值列，其余的是分类列。
col_1= categorical: city_name,
col_2= categorical: company_name,
col_3 = categorical: product_name,
col_4 = numeric : volume。
行数约为 5000。
city_name 有大约 300-400 个唯一值，公司名称有大约 10 个唯一值，有 5 种不同类型的产品，其中产品“a”是最常见的产品类型。volume 对于每个 col_1、col_2、col_3 组合都是唯一的（过去 12 个月的总和）。
我们将第一个数据集称为 df1，将第二个数据集称为 df2。假设从 df2 中删除异常值后，df1 与 df2 相似。在移除异常值之前，这两个数据集在描述性统计方面显示出截然不同的数字。
根据散点图手动从 df2 中移除异常值后，df1 和 df2 具有更相似的描述性统计。
我们认为 df2 中的异常值来自我们目前无法访问的数据。因此，移除这些异常值目前基于“数据领域专家知识”，即具有领域知识的人查看散点图并做出决定。
我的问题是，是否有可能以更复杂的方式进行这种异常值检测？我一直在研究 k-nn 算法，并尝试将分类值转换为 id/数字，并得出了一些受数量和邻域影响很大的随机异常值选择。
所以我的问题是，对于任何特定情况，复杂的异常值检测模型有什么好方法？任何建议都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/651927/outlier-detection-for-data-set-comparison</guid>
      <pubDate>Mon, 29 Jul 2024 10:39:04 GMT</pubDate>
    </item>
    <item>
      <title>如何解释逻辑回归中的相反系数估计？</title>
      <link>https://stats.stackexchange.com/questions/651926/how-interpret-contrary-coefficient-estimates-in-a-logistic-regression</link>
      <description><![CDATA[我需要帮助来解释中介分析的结果输出。
我有一个预测因子 X，它以负面的方式预测三个中介变量 M1、M2、M3。当 X 增加时，M1、M2、M3 会减少。M1、M2、M3 预测二元响应结果 Y，但 M1 和 M3 以正向方式，而 M3 以负向方式。
我在解释结果时遇到了一些困难，其中 X 和 M 之间的关系是平行的，但 M 对 Y 的影响在 M 个变量之间是相反的。你能帮助我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651926/how-interpret-contrary-coefficient-estimates-in-a-logistic-regression</guid>
      <pubDate>Mon, 29 Jul 2024 10:15:53 GMT</pubDate>
    </item>
    <item>
      <title>r 中稳健零膨胀和稳健障碍模型的模型拟合</title>
      <link>https://stats.stackexchange.com/questions/651925/model-fitting-for-the-robust-zero-inflated-and-robust-hurdle-models-in-r</link>
      <description><![CDATA[我正在寻找一种在 r 中拟合稳健障碍和零膨胀模型的方法，以分析我的论文数据
这是我尝试过的方法，但它没有达到我想要的效果，我想使用 BIC 或 AIC 比较这些稳健模型

]]></description>
      <guid>https://stats.stackexchange.com/questions/651925/model-fitting-for-the-robust-zero-inflated-and-robust-hurdle-models-in-r</guid>
      <pubDate>Mon, 29 Jul 2024 09:58:08 GMT</pubDate>
    </item>
    <item>
      <title>如果某些变量仅存在于横截面数据的一部分中，如何在不同的横截面数据中创建潜在类别？</title>
      <link>https://stats.stackexchange.com/questions/651924/how-can-i-create-latent-classes-in-different-cross-sectional-data-if-certain-var</link>
      <description><![CDATA[我有几年的横截面数据（总共 6 年）。其中只有两年查询了 4 个变量。我想根据这些变量和其他社会经济变量形成潜在类别。
我如何才能在没有这四个变量的情况下为这些年份形成这些潜在类别？我可以根据其他社会经济变量做到这一点吗？
这样做的背景是，我还想根据这些潜在类别进行时间序列分析。]]></description>
      <guid>https://stats.stackexchange.com/questions/651924/how-can-i-create-latent-classes-in-different-cross-sectional-data-if-certain-var</guid>
      <pubDate>Mon, 29 Jul 2024 09:43:34 GMT</pubDate>
    </item>
    <item>
      <title>用于局部多项式平滑的 Stata lpoly 方法的 R 等效方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/651923/what-is-the-r-equivalent-of-stata-lpoly-method-for-local-polynomial-smoothing</link>
      <description><![CDATA[我需要（在 R 中）重现 Stata 中完成的实验结果，其中包括使用 lpoly 方法对时间序列进行去趋势处理，该方法实现了一种称为局部多项式平滑的算法。我在 Google 上搜索了“R 中的局部多项式平滑”，发现了许多不同的方法，例如 loess 函数（docs）。同时，我还发现了 stl 方法，该方法根据 ?stl 使用 Loess 进行季节性分解。
我有点困惑，因为我不太了解这些方法，现在也没有足够的时间阅读详细信息，所以我来这里询问是否有人知道我应该使用哪种方法（即 lpoly 的 R 等效方法是什么）。]]></description>
      <guid>https://stats.stackexchange.com/questions/651923/what-is-the-r-equivalent-of-stata-lpoly-method-for-local-polynomial-smoothing</guid>
      <pubDate>Mon, 29 Jul 2024 09:22:52 GMT</pubDate>
    </item>
    <item>
      <title>中介系数的混合符号——这实际上意味着什么？</title>
      <link>https://stats.stackexchange.com/questions/651920/mixed-signs-of-coefficient-in-mediation-what-does-that-mean-in-fact</link>
      <description><![CDATA[我有一个解释问题，我无法使用我找到的任何一本关于调解的书来解决它。我了解它的许多方面，但符号混杂的模型给我带来了解释问题 - 即正确理解这种调解的真正本质。
考虑以下模型。我附上了数据。我们有三个定量变量：独立变量 X、因变量 Y 和调解人 M。
让我们从使用经典的 Baron/Cohen/Kenny 方法进行调解开始。我们有部分调解，Sobel Z 检验是显著的。我们可以谈谈调解。结果如下：

我们可以使用 AMOS/R 中的 SEM 建模获得相同的结果，其中我们获得相同的标准化路径系数。可以使用 bootstrap 方法获得间接影响路径的路径系数值，以及其统计显著性。再次，我们可以谈论中介。

它很弱，我知道在某些情况下它可以被认为是可以忽略不计的产物，但我也知道，如果我深入研究数据，我可以轻松增加这种影响的强度，所以这不是重点。
我对迄今为止找到的一般答案并不满意，这些答案只是解释迹象，而不了解中介内部发生了什么以及如何正确理解影响。以下是我无法理解的地方：

当所有迹象都相同时，我们可以大致了解在中介的影响下会发生什么。但在这种情况下，出现了一个奇怪的矛盾。独立变量X直接增加了Y的水平，但（考虑到间接效应的符号）同时通过中介M降低了其水平。我理解得对吗？
如果是这样，那么Y变量实际上发生了什么？我们可能可以从标准化系数的差异中读出哪个是Y变量的更强的预测因子（因此它是减少还是增加更多），但如果b系数更相似，我们是否知道在这样的变量集合中Y变量发生了什么？此外，考虑到经典模型的结果，中介似乎增加了X对Y的影响水平，但中介的符号为负！
我们怎么知道（在这种情况下）存在中介或抑制？在相同符号的情况下，我们知道存在中介，因为预测因子改变了“强度”回归方程中标准化系数的函数，但这里我们同时有两个相互矛盾的影响。中介究竟如何“知道”它是中介（在这种情况下）？
对这种影响有标准的解释吗？也许人们应该简单地转向其他分析，这样的结果只是一种更非标准方法的暗示？我在三维投影中看到了轻微的曲线关系，但子组中相互作用的影响在统计上并不显著。现在还有其他方法/事情应该采取/测试吗？
中介是否会增加/减少因变量的水平，或者它的数学属性是否只会降低我们对 X 对 Y 的影响的观察？也就是说，事实上，X 对 Y 的影响程度没有改变，独立变量的影响强度保持不变，唯一真正发生的事情是标准化系数人为降低，由此我们观察到中介作用。

提前感谢您提出的所有建议以及共同努力解决这个问题。当然，我很乐意阅读您推荐的文献和文章。]]></description>
      <guid>https://stats.stackexchange.com/questions/651920/mixed-signs-of-coefficient-in-mediation-what-does-that-mean-in-fact</guid>
      <pubDate>Mon, 29 Jul 2024 06:50:24 GMT</pubDate>
    </item>
    <item>
      <title>SNPs 遗传标记数据的 AMOVA - pegas 与 ade4 的不同结果和负方差</title>
      <link>https://stats.stackexchange.com/questions/651917/amova-on-snps-genetic-marker-data-pegas-vs-ade4-different-results-negative-v</link>
      <description><![CDATA[我希望有人能澄清我的疑惑。
我需要在 SNPs 数据集上使用 AMOVA 来测试 3 个级别的遗传分化：i）种群内个体之间，ii）区域内种群之间，以及 iii）区域之间。
我考虑过使用包 poppr::amova(, method=c(&quot;pegas, ade4&quot;)) 中的 pegas 实现，但是当我使用 pegas vs ade4 运行它时，我得到了截然不同的结果。所以，我想知道你们中是否有人遇到过这个问题。
此外，获得负 sigma 值是正常的吗？在计算每个级别解释的总方差百分比时，您如何解释这一点？
我非常感谢您的反馈！
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651917/amova-on-snps-genetic-marker-data-pegas-vs-ade4-different-results-negative-v</guid>
      <pubDate>Mon, 29 Jul 2024 05:26:24 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 z 分数的总和和 z 分数的平均总和？</title>
      <link>https://stats.stackexchange.com/questions/651913/how-to-interpret-sum-of-z-scores-and-average-sum-of-z-scores</link>
      <description><![CDATA[假设我有来自 5 个子测试和 2 组参与者的数据。z 分数的总和（即，将所有 5 个测量值转换为 z 分数并将它们相加）与平均总和（即，将总和除以 5）的解释有什么区别？

例如，如果我想分析诸如 lm(scores ~ age + group) 之类的模型。预测变量中的“1 个单位变化”在每个上下文中意味着什么（总和 x 平均总和）？

注意。在我的实际数据中，如果我有足够的参与者，我会运行 PCA 来创建综合分数，但我做不到，这就是我选择 z 分数的原因。我需要各分项测试的综合分数。 
注释2：这些是准确度分数（正确答案的数量）。

一些虚拟数据：

library(tidyverse)
set.seed(123)

# 生成虚拟数据
n &lt;- 100 # 参与者人数
data &lt;- data.frame(
contestant_id = 1:n,
age = sample(18:30, n, replace = TRUE), # 参与者年龄
group = sample(c(&quot;male&quot;, &quot;female&quot;), n, replace = TRUE), # 组 
subtest1 = rnorm(n), subtest2 = rnorm(n), subtest3 = rnorm(n), subtest4 = rnorm(n), subtest5 = rnorm(n)
)

# 标准化子测试分数
data_z &lt;- data %&gt;%
mutate(across(starts_with(&quot;subtest&quot;), scale)) %&gt;% # 缩放（标准化）子测试分数
mutate(sum_z_scores = rowSums(select(.,starts_with(&quot;subtest&quot;))), # z 分数总和
avg_z_scores = rowMeans(select(., starts_with(&quot;subtest&quot;)))) # z 分数平均值

# 拟合线性模型
model_sum &lt;- lm(sum_z_scores ~ age + group, data = data_z)
model_avg &lt;- lm(avg_z_scores ~ age + group, data = data_z)
]]></description>
      <guid>https://stats.stackexchange.com/questions/651913/how-to-interpret-sum-of-z-scores-and-average-sum-of-z-scores</guid>
      <pubDate>Sun, 28 Jul 2024 23:08:04 GMT</pubDate>
    </item>
    <item>
      <title>rpart() 决策树无法生成分割（只有一个节点（根节点）的决策树）</title>
      <link>https://stats.stackexchange.com/questions/651910/rpart-decision-tree-fails-to-generate-splits-decision-tree-with-only-one-node</link>
      <description><![CDATA[我正在尝试创建决策树来预测特定贷款申请人是否会违约或偿还债务。
我正在使用以下数据集

library(readr)
library(dplyr)
library(rpart)
library(rpart.plot)

贷款 &lt;- read_csv(&#39;https://assets.datacamp.com/production/repositories/718/datasets/7805fceacfb205470c0e8800d4ffc37c6944b30c/loans.csv&#39;)

由于响应变量 default 被编码为 dbl，我首先将其转换为 chr，然后将其转换为 fct 类型变量以在我的分类中使用它模型。
loans &lt;- loans %&gt;% mutate(default = factor(as.character(default), levels = c(0, 1), labels = c(&#39;repaid&#39;, &#39;defaulted&#39;)))

现在，我开始构建递归分区 (rpart()) 对象 loans_model：响应变量为 default，解释变量为 loan_amount + credit_score + deal_to_income。
loans_model &lt;- rpart(default ~ loan_amount + credit_score + deal_to_income, data = loans, method = &#39;class&#39;)

当我使用此模型进行预测时，所有预测值都得到相同的值，即 repaid。
loans$pred_default &lt;- predict(loans_model, newdata = loans, type = &quot;class&quot;)

unique(loans$pred_default)


输出：
[1] 已偿还
级别：已偿还 已违约

此外，当我尝试可视化决策树时，我只得到一个节点（根节点）。
rpart.plot(loan_model)

输出：

您能帮我理解为什么我构建的模型没有做出适当的预测吗？
编辑：拼写错误并添加了 as.character()]]></description>
      <guid>https://stats.stackexchange.com/questions/651910/rpart-decision-tree-fails-to-generate-splits-decision-tree-with-only-one-node</guid>
      <pubDate>Sun, 28 Jul 2024 22:55:36 GMT</pubDate>
    </item>
    </channel>
</rss>