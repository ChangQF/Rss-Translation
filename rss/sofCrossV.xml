<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 08 Mar 2025 01:05:28 GMT</lastBuildDate>
    <item>
      <title>2个不等大小的样品的分布测试</title>
      <link>https://stats.stackexchange.com/questions/662336/distribution-testing-for-2-samples-with-unequal-sizes</link>
      <description><![CDATA[说我有两个示例 $ n $ 和大小 $ m $ 的另一个样本，我不知道每个样本的先验分布。每个示例中的每个数据点均为 $ d $ 尺寸。为了测试分布平等，我可以使用具有一定校正（Bonferroni）的Kolmogorov-Smirnov或使用2样本内核测试（具有最大平均差异）。
我想知道，如果 $ n $ 比 $ m $ （但是 $ m $ 仍然非常大） class =“ Math-Container”&gt; $ n = 20000 $ 。测试技术（我上面提到的确切条件）是否仍然存在？
如果没有，那我该怎么办？如果有已知技术，请随时向我指出资源。]]></description>
      <guid>https://stats.stackexchange.com/questions/662336/distribution-testing-for-2-samples-with-unequal-sizes</guid>
      <pubDate>Sat, 08 Mar 2025 00:34:51 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯过滤 - 为什么我们不能迭代地直接更新联合分布？为什么需要预测和更新步骤？</title>
      <link>https://stats.stackexchange.com/questions/662335/bayesian-filtering-why-cant-we-iteratively-update-the-joint-distribution-dire</link>
      <description><![CDATA[进行贝叶斯过滤时，我们有一个贝叶斯网络，因此：
  $$
p（x_ {0：t}）= p（x_0）\ prod_ {k = 1}^t p（x_k | x__ {k-1}）
$$ 
 $$
p（y_ {1：t} | x_ {0：t}）= \ prod_ {k = 1}^t p（y_ _ {k} | x_ {k {k}）
$$  
和
  $$
p（x_ {0：t}，y_ {1：t}）= p（y_ {1：t} | x_ {0：t}）p（x_ {0：t}）
$$  
给定
  $$
p（x_ {0：t+1}，y_ {1：t+1}）= p（x_0）p（x_ {t+1} | x_t）
$$  
如果我们有 $ p（x_ {0：t}，y_ {1：t}）$ ，为什么我们不能简单地计算 $ p（x__ {0：x_ {0：t+1}
  $$
p（x_ {0：t}，y_ {1：t}）p（x_ {t+1} | x_t）p（y_ {t+1} | x__ {t+1}）
$$  
因此，迭代地计算了一段时间的关节分布，而不是在每个时间步骤进行预测和更新步骤？
我知道，在过滤我们实际关心的分布时，是 $ p（x_ {t} | y_ {1：t}）$ ，但是如果我们忽略归一化常规化，这不应该等于关节分布吗？即。
  $$
p（x_ {0：t} | y_ {1：t}）\ propto p（y_ {1：t} | x_ {0：t}）p（x_ {0：t}）= p（x__ {0：t}，y__ ___ {1：t}）
$$  
我觉得我一定会缺少一些东西，所以如果有人可以指出它是什么，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662335/bayesian-filtering-why-cant-we-iteratively-update-the-joint-distribution-dire</guid>
      <pubDate>Sat, 08 Mar 2025 00:03:15 GMT</pubDate>
    </item>
    <item>
      <title>每组进行预测时是否需要归一化？</title>
      <link>https://stats.stackexchange.com/questions/662333/is-normalization-necessary-when-the-predictions-are-made-per-group</link>
      <description><![CDATA[作为ML的初学者，我正在YouTube上观看视频（ https://youtu.be/vyzmylgbsbm?si = d9dygpgxab8v6661v 
精明10）
关于在Spotify上设计歌曲建议模型。对于每个用户，都有关于推荐哪些歌曲的预测。
功能之一是历史参与数，例如视图/喜欢。
我不明白的是，面试官问，如果某些用户比其他用户比其他用户单击更多，因为他们通常更活跃，因为他们是点击器，他们点击了很多。并解释说，这就是为什么我们需要将点击标准化（例如，除以某些用户活动的总数）。
如果一个模型正在预测每个组，则预测是针对每个用户的歌曲。  那么您真的必须标准化吗？如果用户A有900个单击歌曲A和歌曲B的100次点击，而用户B有20个点击歌曲A，歌曲B的5次点击，则为歌曲C进行5次点击。归根结底，我们在每个用户之间决定不关心不同用户的歌曲。
，即使您要归一化，您也可以模拟歌曲A的用户为0.9，而歌曲B则为0.1，但用户B观看了3首歌曲，因此他的发行版本是0.6、0.2和0.2。。
标准化对您有何帮助？您仍然无法比较0.9和0.6。它们是每组最佳分数，但整个组仍然是无与伦比的。原始点击数与比率有何不同？
，但根据用户，就像原始数字一样，它可以获得最大的百分比。
所以我的意思是，当预测为每个组时，您需要正常化。您是否必须关心各组的比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/662333/is-normalization-necessary-when-the-predictions-are-made-per-group</guid>
      <pubDate>Fri, 07 Mar 2025 23:14:59 GMT</pubDate>
    </item>
    <item>
      <title>绘制测试统计量与其相应的PVALUE</title>
      <link>https://stats.stackexchange.com/questions/662329/plotting-a-test-statistic-vs-their-corresponding-pvalues</link>
      <description><![CDATA[我想可视化特定测试的p值与其测试统计量的关系。该测试是“两次采样的未配对t检验，具有不平等的差异（welch的t检验）＆quot。
这样的数据，如果汇总40次左右，则可能出现：
  q = tstat_lst = [0.9660006171910432，
 0.7721621329351528，
 1.8100610634639722，
 -1.658160637924077，
 0.40426388807743174，
 -0.39322170596362177，
 -0.10057948819452832，
 -0.184443124516603937，
 0.12476123296525302，
 0.15156528516797133，
 -0.09564454667893868，
 -0.3565764937019235，
 0.6296035952012742，
 0.41864142400724524，
 -0.2947978905804754，
 -2.0477391038941315，
 0.6516953409964041，
 -0.10427275892823629，
 -0.383987967078378，
 0.49301579010836505，
 0.34309883856311163，
 -0.555996825678678，
 -0.9614457089082035，
 -0.4307174435897561，
 -0.2402370244487562，
 2.7217356150809198，
 -0.017687813740055347，
 0.37063599036565176，
 -1.433975290423805，
 -2.3163482190361595，
 0.527195768444428，
 1.0793544390271224，
 1.3726447186789736，
 2.1823987824609015，
 -1.886371488297514，
 -0.3327480340089581，
 -0.845831028027378，
 0.14159397099600338，
 1.770628236732337，
 -0.7129657016096798]

a = pvals_lst = [0.3351428270482858，
 0.44086256073619356，
 0.07167660898253647，
 0.09875110470687849，
 0.6864215472089106，
 0.6945485673825906，
 0.9199788061143731，
 0.8538488639722835，
 0.9008289373935419，
 0.8796716928044668，
 0.9238915619509784，
 0.7217575250663029，
 0.5296193782796346，
 0.6758955006039，
 0.7684339395166478，
 0.04185437874159891，
 0.51530430232936，
 0.9170562755796249，
 0.7013651604121057，
 0.6225036851619269，
 0.7318582035931929，
 0.5787900268922169，
 0.3374373699051052，
 0.6671072554315649，
 0.8103783128508254，
 0.007040388064127454，
 0.9859042929350978，
 0.7112719001389117，
 0.15302591592384204，
 0.021480204407496793，
 0.5986165798143437，
 0.2816495551645849，
 0.17128927509245642，
 0.030158422398817143，
 0.06060294356030884，
 0.7396484229164317，
 0.39859184655628466，
 0.8875327037601481，
 0.0780364091452371，
 0.4766433668999457]
 
是否有一个通用图？]]></description>
      <guid>https://stats.stackexchange.com/questions/662329/plotting-a-test-statistic-vs-their-corresponding-pvalues</guid>
      <pubDate>Fri, 07 Mar 2025 21:35:51 GMT</pubDate>
    </item>
    <item>
      <title>哪个更好 -  FDR或Holm -Bonferroni？</title>
      <link>https://stats.stackexchange.com/questions/662328/which-is-better-fdr-or-holm-bonferroni</link>
      <description><![CDATA[我正在用猴子进行听觉侧翼任务。它是一个受试者内部设计，有4个（6个）受试者，有4个条件。我想在运行单向RM ANOVA后进行成对比较。 Bonferroni被证明是非常保守的。我看着替代方案，罗姆和霍尔姆出现了。两者都给出不同的结果。哪一个对我的数据集更好？是否有一个在认知心理学中比其他人更好地接受的？]]></description>
      <guid>https://stats.stackexchange.com/questions/662328/which-is-better-fdr-or-holm-bonferroni</guid>
      <pubDate>Fri, 07 Mar 2025 21:18:20 GMT</pubDate>
    </item>
    <item>
      <title>对称与不对称分布的引导程序</title>
      <link>https://stats.stackexchange.com/questions/662327/bootstrap-for-symmetric-vs-asymmetric-distributions</link>
      <description><![CDATA[昨天我发布了这个问题（ bootstrap对非线性功能的效果与我能够使我能够更好地使我能够与我自己的lin linap相结合的bootstrap是否有效，这是否可以与我的位置相结合。功能。
我对一个相关问题感兴趣：假设我正在处理不对称的分布 -  Bootstrap方法会面临更多的“挑战”。 （例如，较大的偏见，收敛速度较慢）与对称函数相比？ 
我听说有时是这种情况，但是我试图理解为什么这是这种情况。我发现一些参考文献也表明可能是正确的：

 估算错误时，当引导结果偏斜时
  Bootstrapping置信区间，用于cassymetric分布    
 
数学上，是否有可能查看为什么引导程序与对称分布相比面临更多不对称分布的挑战？
（我已经开始学习Edgeworth扩展分布的扩展，并试图为对称分布与不对称分布（例如正常人与指数级）进行一个小例子，以了解为什么是这种情况。我会随后发布进度））]]></description>
      <guid>https://stats.stackexchange.com/questions/662327/bootstrap-for-symmetric-vs-asymmetric-distributions</guid>
      <pubDate>Fri, 07 Mar 2025 21:04:15 GMT</pubDate>
    </item>
    <item>
      <title>什么是研究报告中的SD，SE和覆盖概率？</title>
      <link>https://stats.stackexchange.com/questions/662326/what-is-sd-se-and-coverage-probability-in-research-report</link>
      <description><![CDATA[当我阅读论文时，在模拟研究中，我经常看到它们报告的表与以下相似的表格   
我认为

估计值是2000年以上的平均模拟运行
 SD是估算的标准偏差 $ \ beta_1 $ 在2000模拟中运行
他们没有报告偏见，但是在其他报道偏见的论文中，我认为这是根据2000年模拟的平均估计与真相之间的差异来计算的。

我不确定在这种情况下是什么标准错误以及如何计算。
同样，我想知道如何计算覆盖范围。我的猜测是 - 在每个模拟运行中，计算一个置信区间，我们存储了真相是否在置信区间，然后我们计算了2000年模拟中真相的比例。 
也许这是非常标准的知识，这就是为什么论文通常省略了有关如何计算这些数量的描述，我还在寻找任何有助于解释的教科书。]]></description>
      <guid>https://stats.stackexchange.com/questions/662326/what-is-sd-se-and-coverage-probability-in-research-report</guid>
      <pubDate>Fri, 07 Mar 2025 19:23:41 GMT</pubDate>
    </item>
    <item>
      <title>初学者：确定数据组是否在统计上相似</title>
      <link>https://stats.stackexchange.com/questions/662323/beginner-determining-whether-data-groups-are-statistically-similar</link>
      <description><![CDATA[我是统计数据的新手，并且具有岩石孔隙率的数据集1）使用三种不同的方法，2）来自两种不同的岩石类型。我正在尝试评估1）三种方法是否产生可比的结果，2）如果两种岩石类型在统计上相似。
这三种方法的数据如下（单位=％）：
  method_a = [17.6，19.3，18.7，28.0，25.8，17.1，18.5]
method_b = [17.6，17.0，18.3，11.1，12.5，16.6，15.3，8.4，15.8，14.9，11.6，9.0，9.0，6.4，9.6]
method_c = [11.1、10.9、9.7、7.8、0.9、11.2、11.0、12.5、14.0、8.3、9.9、9.9、6.9、6.9、8.4、0.4、0.9、0.8]
 
通过岩石类型分离的方法A和B的数据如下（方法C是故意的）：
  rock_a = [17.6，19.3，18.7，28.0，25.8，17.6，17.0，18.3，11.1，12.5，16.6，15.3]）
rock_b = [17.1，18.5，8.4，15.8，14.9，11.6，9.0，6.4，9.6））
 
 基于此数据，我应该使用哪些测试来确定这些组在统计上是相似的还是不同的？ 
我以为这是不正确的，但是要了解我的头部的位置，这是我第一次通过的事情：

我使用shapiro-wilk测试来评估每组的正态性。
我使用莱文的测试评估群体之间的差异同质性。
对于方法，我使用了Kruskal-Wallis检验，因为仅方法B是正态分布的。但是，所有组都基于上述测试都具有相似的差异。
对于岩石类型，我使用了学生的t检验，因为两者都是正态分布的，并且基于上述测试具有相似的差异

任何帮助将不胜感激。外行语言是首选，但行话也可以，因为我会尽力研究和理解所有建议。
编辑：添加了代码示例以使数据更可读。]]></description>
      <guid>https://stats.stackexchange.com/questions/662323/beginner-determining-whether-data-groups-are-statistically-similar</guid>
      <pubDate>Fri, 07 Mar 2025 17:18:30 GMT</pubDate>
    </item>
    <item>
      <title>热情的多元数据集中的变量选择</title>
      <link>https://stats.stackexchange.com/questions/662322/variable-selection-in-higly-multivariate-dataset</link>
      <description><![CDATA[ i具有超过200万特征的宏基因组学数据集（每个都是基因家族的相对丰度，这是基因序列的簇） 。首先，我将数据集转化为CLR。现在，我想通过执行某种变量选择来减少矩阵大小。
这样做的目的是删除那些不影响样本差异的变量，因为我稍后将使用多摩学方法来搜索宏基因组学与其他OMIC数据之间的关联。我想保留一部分相关特征，如果它们仅在样品之间是变量（并且研究为什么，它们仅是嘈杂的，或者是其他生物学原因）或治疗之间的。
但是，我不确定要遵循的最优势的变量选择程序。到目前为止，我尝试了r。中的几种策略

  pca ：我试图通过为两个第一个组件的PCA中的负载来选择变量。但是，这些组件不能解释很多方差（10和5％），并且最大载荷的绝对值为0.003，在两个组件中最大值。
 gf_pca＆lt;  -  prcomp（clrmatrix） 
  umap ：我还尝试了这些功能，而对其功能有很好的了解。看来我无法通过这种方法查看变量的重要性。
 gf_umap＆lt;  -  umap（clrmatrix，n_neighbors = 10，metric =&#39;euclidean&#39;） 
 随机森林：我读到有关运行无监督随机森林的选择。它给了我一组可以使用的变量，但是我不知道该如何检查模型是否足够好。
 gf_rforest＆lt;  -  Randomforest（x = clrmatrix，ntree = 5000，值
 删除相关特征：我想直接计算所有相对丰度之间的相关矩阵，并删除高度相关的相关矩阵。但是，计算成本使我知道的方法变得不可能。
 corr_matrix＆lt;  -  cor（clrmatrix） 

 i也是关于使用样品的分类因素来进行某些监督的东西，因为我的样品分为两个分类因素：温度（3个水平）和养分量（两个水平）。为此，我可以使用：

 （s）PLS ：我以前使用此使用此的经验是该模型通常具有较低的Q2值。
 套索回归：使用我的治疗变量（温度和营养）与 y （尽管它们不是真正的响应变量）。
 随机森林：使用治疗变量（温度和营养）进行监督。

测试方法足够好，还是还有其他更好的选择？
在使用测试方法之一的情况下，我该如何解决遇到的问题？
使用分类因素信息并使用监督方法会更好吗？
事先感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/662322/variable-selection-in-higly-multivariate-dataset</guid>
      <pubDate>Fri, 07 Mar 2025 16:30:36 GMT</pubDate>
    </item>
    <item>
      <title>如何根据观察到的复合等待时间和协变量来估计和预测潜在事件的活动时间？</title>
      <link>https://stats.stackexchange.com/questions/662317/how-to-estimate-predict-time-to-event-for-latent-events-based-on-observed-comp</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662317/how-to-estimate-predict-time-to-event-for-latent-events-based-on-observed-comp</guid>
      <pubDate>Fri, 07 Mar 2025 14:06:28 GMT</pubDate>
    </item>
    <item>
      <title>解释这篇经典统计文章如何定义此非参数统计的累积物</title>
      <link>https://stats.stackexchange.com/questions/662316/explain-how-this-classic-statistics-article-is-defining-the-cumulants-of-this-no</link>
      <description><![CDATA[让 $（x，y）$ 是大小的随机双变量样本 $ n $ ，预期的是spearman  rho&gt; rho rho  rank corlation  $ e（\ rho）在样本中定义A 固定点为任何配对的观察 $（x_i，y_i）$ ，以便 $ x_i $ 是 $ x $ 和 $ y_i $ 是 $ i^{th} $   $ y $ y $ y $ $ ，他们的相对等级。令样本中的固定点总数（匹配）表示为 $ r $ ，然后让 $ r $  $ p_1（r）$ p_1（r）$ 。  class =“ Math-Container”&gt; $ P_1（r）$ 全部 $（n-1）\ Omega + 1 $ ＆quot （p。72），其中 $ \ omega $ 被证明是Spearman的 rho rho 。。的预期值。
这让我感到困惑，因为如果（例如） $ n = 30 $  and  $ e（\ rho）= .1 $ ，他们的公式意味着他们的第一个累积累积等于 $ 3. $ 3.9 $ 。据我了解，如果分发的第一个累积剂等于其预期值，则这是A 巨大数字。为了进行比较，众所周知，在真实零（0个群体相关）下的期望值为 $ e（r）= 1 $ （由蒙特莫特（Montmort）著名的匹配定理在随机统一释放中的预期固定点上的匹配定理，与他们的公式一致）。在错误的空中，我自己的模拟给出了大约 $ e（r）= 1.1 $  for  $ e（\ rho）= .1 $ ！另外，根据其公式，如果 $ e（\ rho）= .5 $ ，那么一半以上的样本将是固定点，这只是疯狂的。
他们不给出累积物的推导，但我不愿拒绝作者的陈述，因为这是一本最高的日记，他们是有成就的统计学家。但是该论文已经70岁了，所以我想知道某些术语或数学符号是否不同？我想不出差异的任何其他解释。你能让我直接吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662316/explain-how-this-classic-statistics-article-is-defining-the-cumulants-of-this-no</guid>
      <pubDate>Fri, 07 Mar 2025 13:57:10 GMT</pubDate>
    </item>
    <item>
      <title>在调解分析中获得间接效应的两种方法的等效性</title>
      <link>https://stats.stackexchange.com/questions/662311/equivalence-of-two-ways-to-obtain-indirect-effect-in-mediation-analysis</link>
      <description><![CDATA[在与常规线性回归有关的简单调解分析中，我们有3个拟合回归模型：

 y = ax 
 y = bx + cz 
 z = dx 

在这里y是结果，x是解释性变量，z是中介者。
通常将间接效应（调解效应）定义为乘积 cd 。
但是，在线性回归中，显然也确实确实可以估算 cd = a-b ，而无需拟合最后一个回归模型而可以估算间接效应。有一种简单的方法可以证明这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662311/equivalence-of-two-ways-to-obtain-indirect-effect-in-mediation-analysis</guid>
      <pubDate>Fri, 07 Mar 2025 09:58:20 GMT</pubDate>
    </item>
    <item>
      <title>在GLMMTMBβ-二元模型中设置先验</title>
      <link>https://stats.stackexchange.com/questions/662294/setting-priors-in-a-glmmtmb-beta-binomial-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662294/setting-priors-in-a-glmmtmb-beta-binomial-model</guid>
      <pubDate>Thu, 06 Mar 2025 21:20:54 GMT</pubDate>
    </item>
    <item>
      <title>统计贝叶斯引起先验拉普拉斯$ \ pi（\ theta）= 1 $</title>
      <link>https://stats.stackexchange.com/questions/662257/statistics-bayesian-eliciting-of-prior-laplace-pi-theta-1</link>
      <description><![CDATA[我有一个要解决的贝叶斯统计数据的问题，也就是说，引起了先验的教师，建议使用拉普拉斯先验等于1的laplace（因为它们都是不当的法律），我有一个考试，我被问到 

考虑随机变量 $𝑋$ 带有条件密度函数 $$ f_x（x | \ theta）\ propto \ propto \ frac {x^3} x＆lt; \ theta}，\ quad \ theta＆gt; 0。  
$$  

 1）提供密度函数的归一化版本
2）确定是否可以假定𝜃 的拉普拉斯先验
要找到归一化，我只需要集成 $ x $ 的支持，然后将函数集成到 $ x $ 中。
然后，我采用给定的功能并将其除以积分的结果。
关于第二个问题，教授在课堂上解释说，拉普拉斯先验设置为1，但我已经知道这是一个不当的分布。但是，如果我获得的后部结合给定密度函数的可能性（具有归一化常数？）并且先验（哪个是1）与已知分布成正比的后部是可以的。如果我找到已知发行版的内核，我都会确定；否则，我需要检查它是否是正确的分布。但是如何？我需要计算积分并检查它是否收敛？
另外，我想问：初始函数是写为f（xθ）还是f（x;θ）
它不是给定的形式，它会改变练习中的任何内容吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662257/statistics-bayesian-eliciting-of-prior-laplace-pi-theta-1</guid>
      <pubDate>Thu, 06 Mar 2025 12:15:01 GMT</pubDate>
    </item>
    <item>
      <title>在部分相关分析中处理分类变量</title>
      <link>https://stats.stackexchange.com/questions/662090/handling-categorical-variables-in-partial-correlation-analysis</link>
      <description><![CDATA[我正在分析具有两个条件的实验的数据：野生型（WT）和突变基因型。每个基因型大约有25个样本。
对于每个样品，测量了〜15个基因和〜5代谢产物的表达。
目的是研究基因与代谢产物之间的关系，以及基因本身之间的关系。
但是，我注意到基因型之间的基因和代谢产物水平的主要差异。这意味着简单的相关分析将主要捕获基因型驱动的差异而不是真实的关联。
我遇到了部分相关（ ppcor :: pcor.test  in R），该在R）中计算两个变量之间的相关性，同时控制第三个变量（在这种情况下，基因型）。该方法可以应用于所有变量对，并在具有多测试校正的相关图中可视化。 Spearman的等级相关性（似乎是适当的选择）可以计算。
但是， ppcor 要求控制变量是数字的，而基因型为分类（WT/MUT）。
一种方法是将基因型编码为（0,1），但我不确定这种转换的含义。

 将基因型（WT，MUT）转换为（0,1）的统计后果是什么？？

 是否有任何有效性检查以确保此方法合适？

]]></description>
      <guid>https://stats.stackexchange.com/questions/662090/handling-categorical-variables-in-partial-correlation-analysis</guid>
      <pubDate>Mon, 03 Mar 2025 07:55:24 GMT</pubDate>
    </item>
    </channel>
</rss>