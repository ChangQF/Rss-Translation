<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 31 May 2024 06:21:36 GMT</lastBuildDate>
    <item>
      <title>小样本与大样本的因果效应和外生性</title>
      <link>https://stats.stackexchange.com/questions/648335/causal-effect-and-exogeneity-in-small-samples-vs-in-large-samples</link>
      <description><![CDATA[这个标题下有两个问题。
在Y对X和控制Z的回归中，随机误差为e，

在小样本中，如果满足严格外生性，即E(e|X,Z)=0，是否意味着X的系数具有因果关系的意义？
在大样本中，严格外生性的条件是否可以放宽为不相关，即Cov(e,X)=0和Cov(e,Z)=0，以描述因果关系？如果答案是肯定的，请用公式推导原因。

我发现很多书和论文（例如关于IV）讨论的是相关性而不是外生性。我查过一些教科书，它们只解释了从小样本的无偏变为大样本的一致性的性质，这与因果关系无关。]]></description>
      <guid>https://stats.stackexchange.com/questions/648335/causal-effect-and-exogeneity-in-small-samples-vs-in-large-samples</guid>
      <pubDate>Fri, 31 May 2024 03:26:25 GMT</pubDate>
    </item>
    <item>
      <title>具有共变预测变量的线性回归模型中的方差比例</title>
      <link>https://stats.stackexchange.com/questions/648334/proportion-of-variance-in-a-linear-regression-model-with-a-covaring-predictor</link>
      <description><![CDATA[给定一个模型：
\begin{align}Y_{i}=Z_{i}*\beta * X_{i} + Z_{i}\tag{Eq. 1}&amp;\end{align&gt;
我对预测变量 $X$ 解释的方差比例的封闭公式感兴趣，通常也称为判定系数。请注意，在此模型中，变量 $Z_{i}$ 与 $X_{i}$ 共变，因此这不一定是具有单个预测变量的线性回归模型。
我知道可以使用以下表达式计算方差比例（又名判定系数）：
\begin{align}R^2=\beta^2*\frac{V(X)}{V(Y)}\tag{Eq. 2}&amp;\end{align&gt;
我认为有两种可能的替代方案可以实现我的目标：

将响应变量 $Y_{i}$ 除以 $Z_{i}$，这样：
\begin{align}\frac{Y_{i}}{Z_{i}}=\beta * X_{i} + 1\tag{Eq. 3}&amp;\end{align&gt;
然后使用 $Eq. 2$。

将 $Z_{i}$ 的期望视为常数，使得：
\begin{align}Y_{i}=\beta&#39; * X_{i} + \operatorname{E}(Z)\tag{Eq. 4}&amp;\end{align
其中 $\beta&#39;=\operatorname{E}(Z)*\beta$。然后相应地使用 $Eq. 2$。


当我将某些模拟数据（此处未显示）上通过线性回归估计的斜率与预期斜率（使用模拟数据的先前信息计算）进行比较时，对于 Eq. 3 和 Eq. 4，我确实得到了非常准确的结果。
对于 Eq. 4 模型中计算的 $R^2$，情况并非如此。
我推测，将 $R^2$ 表达式应用于 Eq. 2（对于单个预测器线性回归准确）可能对 Eq. 1 中的模型不太好。]]></description>
      <guid>https://stats.stackexchange.com/questions/648334/proportion-of-variance-in-a-linear-regression-model-with-a-covaring-predictor</guid>
      <pubDate>Fri, 31 May 2024 01:21:40 GMT</pubDate>
    </item>
    <item>
      <title>带截距的 AR(p) 过程的特征多项式</title>
      <link>https://stats.stackexchange.com/questions/648332/characteristic-polynomials-for-arp-processes-with-intercepts</link>
      <description><![CDATA[这是我试图理解的；
如果我们有无截距的 AR(1) 过程，例如：
$x_t=\phi x_{t-1}+w_t$
当 $|\phi|$=1 时，它有一个单位根” ]
我们有一个没有常数的 AR(p) 过程
$x_t=\phi_1 x_{t-1}+\phi_2 x_{t-2}+\cdots+\phi_p x_{t-p}+w_t $
其特征多项式定义为
$$\phi(B)=1-\phi_1 B-\phi_2 B^2-\ldots-\phi_p B^p .$$
因此，对于 AR(p)，此特征多项式需要有一个根为 1 或 -1。
我的问题是，如果我们有一个常数项 c（例如下面），那么“特征多项式”是否与上面的相同，我们只需查看相同的特征多项式即可找出单位根（或者在 AR(1) 的情况下，查看 $|\phi|$）
$x_t=\phi x_{t-1}+w_t +c$
$x_t=\phi_1 x_{t-1}+\phi_2 x_{t-2}+\cdots+\phi_p x_{t-p}+w_t+c$]]></description>
      <guid>https://stats.stackexchange.com/questions/648332/characteristic-polynomials-for-arp-processes-with-intercepts</guid>
      <pubDate>Fri, 31 May 2024 00:45:44 GMT</pubDate>
    </item>
    <item>
      <title>使用零膨胀泊松回归从 IRR 获得发生率</title>
      <link>https://stats.stackexchange.com/questions/648330/getting-incidence-rates-from-irr-using-zero-inflated-poisson-regression</link>
      <description><![CDATA[我的数据如下所示：

因此我使用零膨胀泊松回归模型来模拟事件（例如，因特定情况住院）。
pois_model &lt;- zeroinfl(counts~cases+offset(log(pyear)),
data=df)

摘要显示：
&gt; summary(pois_model)

调用：
zeroinfl(formula = counts ~ cases + offset(log(pyear)), data = df)

Pearson 残差：
最小值 1Q 中位数 3Q 最大值 
-0.3694 -0.2851 -0.2851 -0.2807 203.6724 

计数模型系数（带对数链接的泊松）：
估计标准误差 z 值 Pr(&gt;|z|) 
（截距） -0.759272 0.012431 -61.081 &lt;2e-16 ***
casesRA -0.002534 0.023278 -0.109 0.913 

零通胀模型系数（带对数链接的二项式）：
估计标准误差 z 值 Pr(&gt;|z|) 
（截距） -0.759272 0.012431 -61.081 &lt;2e-16 ***
casesRA -0.002534 0.023278 -0.109 0.913 

零通胀模型系数（带对数链接的二项式）：
误差 z 值 Pr(&gt;|z|) 
(截距) 0.50933 0.01524 33.427 &lt;2e-16 ***
casesRA 0.03112 0.02932 1.061 0.289 
---
有效代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 

BFGS 优化中的迭代次数：17 
对数似然：-4.047e+04 on 4 Df

如何获取病例（2 个因素：病例/对照）的具体发生率？
手动执行此操作不能解释过度分散：
 &gt;模型 &lt;- glm(counts ~ 0 + cases + offset(log(pyear)),
+ data = df, 
+ family = poisson(link=&quot;log&quot;))
&gt; 系数(模型) %&gt;%
+ exp() %&gt;%
+ (\(x) x*100000)()
casesControl casesRA 
4394.661 4481.076 

如能得到任何帮助，我们将不胜感激！谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648330/getting-incidence-rates-from-irr-using-zero-inflated-poisson-regression</guid>
      <pubDate>Fri, 31 May 2024 00:30:16 GMT</pubDate>
    </item>
    <item>
      <title>重复测量的贝叶斯多元回归</title>
      <link>https://stats.stackexchange.com/questions/648328/bayesian-multivariate-regression-with-repeated-measures</link>
      <description><![CDATA[我正在尝试使用混合效应模型估计方差成分（具体来说，遗传相关性）。我的随机效应是受试者 ID，我的因变量 y1 和 y2 是从两个不同测试中获得的分类分数。每个受试者在每次测试中都经过多次测试，但受试者之间的次数不同（例如，受试者 1 可能进行了一次测试 1 和两次测试 2，而受试者 2 可能进行了三次测试 1 和两次测试 2），因此每个受试者的 y1 和 y2 重复次数不同。y1 和 y2 保存在两个单独的数据集中。有没有办法运行多元模型，同时保留 y1 和 y2 的所有重复？我应该如何组合这两个数据集来实现这一点？或者我应该只为每个受试者的 y1 和 y2 使用一个值？我正在使用 R 包 MCMCglmm 和 brms。
我希望我的问题足够清楚。
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648328/bayesian-multivariate-regression-with-repeated-measures</guid>
      <pubDate>Thu, 30 May 2024 23:22:49 GMT</pubDate>
    </item>
    <item>
      <title>如果 KPSS 涉及趋势平稳性与单位根，那么如何测试平稳性？</title>
      <link>https://stats.stackexchange.com/questions/648327/how-does-kpss-test-for-stationarity-if-it-is-about-trend-stationarity-vs-unit-ro</link>
      <description><![CDATA[ADF 检验：

零假设：该序列具有单位根。
备择假设：该序列没有单位根。

KPSS 检验：

零假设：该过程趋势平稳。
备择假设：该序列具有单位根（序列不是平稳的）。


最好同时应用这两种检验，这样可以确保
该序列确实是平稳的。

来源：
https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html
我不明白的是，如果您使用 KPSS 检验，如果零假设是趋势平稳的，为什么无法拒绝零假设就意味着平稳？]]></description>
      <guid>https://stats.stackexchange.com/questions/648327/how-does-kpss-test-for-stationarity-if-it-is-about-trend-stationarity-vs-unit-ro</guid>
      <pubDate>Thu, 30 May 2024 23:20:38 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用粒子边际大都市黑斯廷斯来估计转换矩阵和输入？</title>
      <link>https://stats.stackexchange.com/questions/648325/is-it-possible-to-use-particle-marginal-metropolis-hastings-to-estimate-the-tran</link>
      <description><![CDATA[状态空间模型定义为：
$$x_{t+1} = A_tx_t + B_tu_t$$
$$y_{t+1} = H_tx_{t+1}$$
所以我的问题是：是否可以使用粒子边缘大都市黑斯廷斯根据观测值、矩阵 H 和 B 来估计转换矩阵 $$A_t$$ 和输入 $$u_t$$？]]></description>
      <guid>https://stats.stackexchange.com/questions/648325/is-it-possible-to-use-particle-marginal-metropolis-hastings-to-estimate-the-tran</guid>
      <pubDate>Thu, 30 May 2024 22:55:38 GMT</pubDate>
    </item>
    <item>
      <title>线性模型关于残差的导数</title>
      <link>https://stats.stackexchange.com/questions/648323/derivative-of-linear-model-with-respect-to-residual</link>
      <description><![CDATA[我正在查看维基百科页面上有关总体最小二乘法的两个部分，具体来说：
#Allowing_observation_errors_in_all_variables 和 #Example
我有两个问题，第一个是如何对线性
模型的残差求导，第二个，在维基百科页面上的具体方程中，$K_{X}$ 是向量还是矩阵？
以下是这两个部分的屏幕截图：


所以我的第一个问题是示例中的公式 1（我的注释）应该是描述中的公式 3？一旦我根据示例的公式 3 得到公式，我如何对残差取导数以得到 $K_{X}$ 和 $K_{Y}$，这些是向量还是矩阵？]]></description>
      <guid>https://stats.stackexchange.com/questions/648323/derivative-of-linear-model-with-respect-to-residual</guid>
      <pubDate>Thu, 30 May 2024 21:50:32 GMT</pubDate>
    </item>
    <item>
      <title>计算比例数据的置信区间（多个数据点）</title>
      <link>https://stats.stackexchange.com/questions/648316/calculating-confidence-intervals-for-proportion-data-multiple-data-points</link>
      <description><![CDATA[各位 -
我正在寻找一种方法来计算数据系列（多个数据点的样本）的置信区间（例如 95%）或其他变异性指标，其中数据都是比例（即每个数据都在零和一之间）。我认为这种方法不同于计算连续数据的标准 CI，可以是任何数值等。请注意，我并不是要求对单个比例进行 CI 估计（例如，Clopper-Pearson 方法）。R 代码或 Excel 公式会有所帮助。似乎在任何基础教科书中都找不到这个。谢谢。
示例数据集：
0.12、0.24、0.93、0.56、0.02]]></description>
      <guid>https://stats.stackexchange.com/questions/648316/calculating-confidence-intervals-for-proportion-data-multiple-data-points</guid>
      <pubDate>Thu, 30 May 2024 20:21:41 GMT</pubDate>
    </item>
    <item>
      <title>非常低的 p 值的正确格式是什么？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648307/what-is-the-proper-formatting-of-very-low-p-values</link>
      <description><![CDATA[一般来说，我认为应该给出精确的 p 值，而不是像“p &lt; 0.05”这样的值。但是，有时 p 值非常低，大约为 $10^{-10}$ 甚至更低。在什么情况下我们应该 a) 四舍五入并说“$p &lt; 10^{-5}$”或 b) 以科学计数法给出完整的估计值，例如“$p = 3.46\times 10^{-7}$”？]]></description>
      <guid>https://stats.stackexchange.com/questions/648307/what-is-the-proper-formatting-of-very-low-p-values</guid>
      <pubDate>Thu, 30 May 2024 19:10:14 GMT</pubDate>
    </item>
    <item>
      <title>方差分析不显著但事后分析显著 - 如何解释？</title>
      <link>https://stats.stackexchange.com/questions/648329/anova-not-significant-but-post-hoc-is-how-to-interpret</link>
      <description><![CDATA[我有一些关于动物的数据，它们的饮食（食肉动物、杂食动物、食草动物）以及它们的轨道相对于头骨中线的角度。通常，食肉动物的眼睛更多朝前，而食草动物的眼睛角度更大（眼睛在头部侧面），以便在进食/饮水等时能够看到更多周围环境。
我的数据如下所示：
头骨数据
我在同一个块中运行了方差分析和事后检验，但方差分析返回 p&gt;0.05，而 Tukey 显示某些组之间存在差异
diet.aov2 &lt;- aov(mean_pos ~ Diet, data= raw_skull)
summary(diet.aov)

TukeyHSD(diet.aov2)

----------

Df Sum Sq Mean Sq F 值 Pr(&gt;F)
Diet 2 501 250.5 2.345 0.13
残差 15 1602 106.8 
Tukey 均值多重比较
95% 家族置信水平

拟合：aov（公式 = mean_pos ~ Diet，数据 = raw_skull）

$Diet
diff lwr upr p adj
食草动物-食肉动物 16.474861 6.96985 25.979873 0.0003479
杂食动物-食肉动物 -3.728538 -12.86324 5.406165 0.5881155
杂食动物-食草动物 -20.203399 -29.17716 -11.229635 0.0000054

I没想到这是可能的，我也不知道该如何解释。事后检验的结果从生物学角度来看是有意义的，但为什么方差分析不显著呢？
这怎么解释呢？还是我应该进行不同的测试？
这是我的图
在此处输入图片描述]]></description>
      <guid>https://stats.stackexchange.com/questions/648329/anova-not-significant-but-post-hoc-is-how-to-interpret</guid>
      <pubDate>Thu, 30 May 2024 06:59:52 GMT</pubDate>
    </item>
    <item>
      <title>使用治疗后变量进行倾向评分加权</title>
      <link>https://stats.stackexchange.com/questions/648259/propensity-score-weighting-with-post-treatment-variables</link>
      <description><![CDATA[在进行倾向评分加权 (PSW) 时，强调要平衡治疗前变量，因为平衡治疗后变量可能会引入偏差。
我想问一下您对我们没有治疗前变量的情况的看法。设置如下：

我们的目标不是估计治疗的因果效应。相反，我们的目标是尽量减少或降低不同治疗组和对照组之间的不平衡。
在我们的案例中，“治疗”发生在儿童时期，而我们的样本是成年人。因此，除了年龄之外，我们没有治疗前变量。
具体来说，我们计划使用 Greg Ridgeway 开发的广义增强模型 (GBM) 来估计多项治疗的倾向得分。

我们发现朴素无加权模型和 PSW 模型的估计值之间没有显著差异。
我想知道我们是否仍然可以将 PSW 与治疗后协变量一起使用，因为我们没有发现这里存在显著治疗后偏差的证据。此外，正如您可能猜到的那样，在我们的数据设置中，我们不能选择其他方法，例如 IV 或 DID。]]></description>
      <guid>https://stats.stackexchange.com/questions/648259/propensity-score-weighting-with-post-treatment-variables</guid>
      <pubDate>Thu, 30 May 2024 05:00:25 GMT</pubDate>
    </item>
    <item>
      <title>调整分层变量</title>
      <link>https://stats.stackexchange.com/questions/648132/adjusting-for-stratification-variables</link>
      <description><![CDATA[在临床试验中，分层可用于确保协变量之间的治疗平衡。
根据指导文件（例如 EMA/CHMP/295050/2013），分层变量通常应作为协变量包含在主要分析中。
在模型中包含分层变量的理由是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648132/adjusting-for-stratification-variables</guid>
      <pubDate>Tue, 28 May 2024 09:06:18 GMT</pubDate>
    </item>
    <item>
      <title>详尽测试所有可能的特征组合以找到最佳组合是否有效？</title>
      <link>https://stats.stackexchange.com/questions/647517/is-it-valid-to-exhaustively-test-all-possible-combinations-of-features-to-find-t</link>
      <description><![CDATA[我有大约 1000 个带标签的观察结果，这些观察结果来自大约 50 名受试者，他们在不同的情境下做出生理反应，我正在尝试对情境进行分类（通常分为频率大致相等的三个类别，但有时分为四个或五个类别）。对于每个观察结果，我生成大约 2000 个特征，需要选择最佳的特征子集进行分类。使用 mRMR（最小冗余最大相关性），我可以将特征减少到大约 25-100 个特征，然后 mRMR 得分会降得很低（取决于我包括哪些类别）。
我取其中的前 20 个（以保持数字的可行性），并使用留一交叉验证测试最多 8 个特征的所有可能组合，得到大约 264,000 个组合。然后，我选择准确率最高的组合。对于 LDA，这仅花费我的笔记本电脑 6 个小时，但我也在测试需要更长时间的其他分类器（例如高斯 SVM，将五个类转换为十个二元分类器，或将三个类转换为三个二元分类器）。
我的问题是这是否是一种有效的方法，或者我是否引入了偏差、过度拟合等，如果是，如何补偿。我读到最好在每个折叠内进行特征选择，但我甚至不确定如何做到这一点，尤其是在遗漏一个主题的情况下。
我发现单独使用 mRMR 并不合适：如果我仅使用 mRMR 的前 8 个特征，我得到的准确度会比找到最佳组合低得多。在一个极端情况下，使用高斯 SVM 仅比较两个类，差异是 99% 的准确率对 50%，但通常准确率差异约为 10-20%。）
我有两个目标：1）选择最佳特征来在所有数据上训练模型，并用它来对新观察进行分类，2）估计这种模型对未来观察的准确率。
有没有办法可以考虑对准确率的影响，如果我愿意分配这么多的计算量，有没有更好的方法来选择特征？
当我问的时候，使用 PCA 创建 5-10 个组件而不是直接使用特征是否更有意义？
任何建议都值得赞赏！非常感谢。
更多信息（根据要求）：
为了防止出现 X-Y 问题，也许我应该退一步并问：在我的处境下，选择特征的正确/最佳/合理方法是什么？我正在探索不同的分类技术，但现在我将一个五类问题分解为十个二元高斯 SVM 分类器。对于每个分类器，我都试图选择用于这些特定类别的最佳特征。如果我仅使用第一个特征作为我的 mRMR 评分，我会得到较低的结果。就“有效”而言，我的方法可以大大提高准确度，但它们只是人为地提高了吗？或者这是一种被认为是坏主意的方法？我还需要预测未见数据的分类准确度。有些响应对很容易分类，例如98% 的准确率，而一对仅能达到 70% 的准确率，总体准确率达到约 60%（在将十个分类器的后验概率得分相加并选择得分最高的响应之后）。
在选择八个特征（或有时仅选择六个特征，以便训练速度提高四倍）后，我尝试了 SVM 超参数优化（核尺度和框约束），但我发现最好对它们都使用“1”，这也让我认为我可能正在为这些核尺度和框约束值选择最佳特征，但将测试不同的核尺度和框约束添加到循环中将为我提供更多组合进行测试。
为什么我要减少特征数量？：
如果我包含所有特征，或者仅使用 mRMR 评分的前 8 个或 20 个等特征，我会得到更糟糕的结果。我想避免过度拟合，有人告诉我，如果只有 50 个受试者，那么这个数字应该更接近 5-10，而不是 2000。我想要一个更简单、更易于解释的模型，并且出于研究目的，我希望确定哪些特征是最重要的。]]></description>
      <guid>https://stats.stackexchange.com/questions/647517/is-it-valid-to-exhaustively-test-all-possible-combinations-of-features-to-find-t</guid>
      <pubDate>Sat, 18 May 2024 18:21:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么机器学习模型要学习概率分布以及这为什么重要？</title>
      <link>https://stats.stackexchange.com/questions/647266/why-do-ml-models-learn-probability-distributions-and-why-does-it-matter</link>
      <description><![CDATA[我知道这个问题很愚蠢，但我已经阅读和编码 NN 很长一段时间了，研究了反向传播等等。
但是，我认为我从未理解过 NN 模型的概率分布是什么？
我确实知道它们是频率与特征图，但我为什么学习数据集中的 L 形边框数量会有帮助？
当然，我也没有看到线性回归学习任何这些（我寻找了一个非常简单的案例来分析。）
如果可能的话，你的概念解释是什么？你能给我推荐一些这方面的初学者文章吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647266/why-do-ml-models-learn-probability-distributions-and-why-does-it-matter</guid>
      <pubDate>Wed, 15 May 2024 08:46:40 GMT</pubDate>
    </item>
    </channel>
</rss>