<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 14 Nov 2024 01:15:23 GMT</lastBuildDate>
    <item>
      <title>模型堆叠 - 折叠程序</title>
      <link>https://stats.stackexchange.com/questions/657230/model-stacking-out-of-fold-procedures</link>
      <description><![CDATA[我尝试使用模型堆叠程序，其中我使用时间序列分割我拥有的一组数据（大约 5000 个条目）。目标是二元分类。
在使用训练集上的 CV 获得基础模型的超参数后，我随后在折叠中训练基础模型并存储折叠外预测的预测概率。我最终将这些折叠外预测用作元模型中的特征。
但是存在一些问题。

当使用时间序列分割时，我似乎注意到我的平均折叠外预测大小明显小于折叠内预测中的数据量。因此，我没有一个很好的方法来选择我在训练/调整元模型时应该使用的折叠数量。例如，我注意到使用 10 的折叠大小会导致我的模型根本不合适（无论基础模型输入如何，它都只投射一个分类类别）。我的假设是，折叠量越大，元模型的数据量就越小，因此无法找到最佳拟合。
堆叠模型的模型性能似乎明显差于基础模型性能，尽管基础模型的预测不同（因此基础模型之间存在差异，但性能几乎相同）。我认为使用性能相同但差异化良好的基础模型是堆叠的良好候选者 - 然而我的元模型却不是。
]]></description>
      <guid>https://stats.stackexchange.com/questions/657230/model-stacking-out-of-fold-procedures</guid>
      <pubDate>Thu, 14 Nov 2024 01:07:12 GMT</pubDate>
    </item>
    <item>
      <title>当数据集中存在 NA 时，predict() 函数对 R 中的 lmer 不起作用</title>
      <link>https://stats.stackexchange.com/questions/657227/predict-function-fails-for-lmer-in-r-when-nas-present-in-dataset</link>
      <description><![CDATA[当数据集中存在 NA 时，predict() 函数对 lmer 失败，例如

请参阅附件 LMEM_TEST_withNA.csv。
R 代码读取（为简单起见，省略了数据重新缩放等）
library(tidyverse)
library(lme4)
library(lmerTest)

#### 读入数据 
fileName = paste0(&#39;LMEM_TEST&#39;)
DF &lt;- read.csv(paste0(fileName,&#39;.csv&#39;), check.names=FALSE, header = T) #
DF$SEX &lt;- as.factor(DF$SEX)
DF$TRT &lt;- as.factor(DF$TRT)

# 拟合线性混合效应模型
model_lmer &lt;- lmer(ENDPOINT ~ TIME + TRT + SEX + AGE + WT + BIOMARKER1 + BIOMARKER2 + TRT*TIME + (1 | ID), 
data = DF)

# 检查 model_lmer 的摘要
print(summary(model_lmer))

# 绘制数据和预测
p = ggplot(data = DF, aes(x=TIME, y=ENDPOINT, colour=factor(ID))) +
facet_wrap(~ ID) +
geom_point(size=2) +
geom_line(aes(y=predict(model_lmer)),linewidth=1)
print(p)

我收到的错误消息是
Stack/LMEM_withNA.R:28:1 处的 `geom_line()` 出错：
! 计算美学时出现问题。
ℹ 错误发生在第二层。
由 `check_aesthetics()` 中的错误引起：
! 美学的长度必须为 1 或与数据 (96) 相同。
✖ 修复以下映射：`y`。
运行 `rlang::last_trace()` 以查看错误发生的位置。

有什么想法可以修复它吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657227/predict-function-fails-for-lmer-in-r-when-nas-present-in-dataset</guid>
      <pubDate>Wed, 13 Nov 2024 23:28:54 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有特定选择变量的模型中使用 mlogit</title>
      <link>https://stats.stackexchange.com/questions/657226/how-to-use-mlogit-for-models-where-there-are-no-choice-specific-variables</link>
      <description><![CDATA[假设有人想在两部手机和两种颜色之间建立产品选择模型，但手机 1 只有红色或绿色，而手机 2 只有蓝色或黑色。因此选择中存在嵌套。但是，没有特定于选择的变量。如果为此使用 mlogit，下面的代码是否正确？
mlogit(choice ~ 1 | gender + age, data = ddataset, nests = nests)
其中 ddataset 格式化为长格式，每个参与者有 4 行（每个选择一行），但性别和年龄对于每一行都具有相同的值（因为它们属于同一个人）。]]></description>
      <guid>https://stats.stackexchange.com/questions/657226/how-to-use-mlogit-for-models-where-there-are-no-choice-specific-variables</guid>
      <pubDate>Wed, 13 Nov 2024 22:25:54 GMT</pubDate>
    </item>
    <item>
      <title>比较时间序列中不同位置的数据</title>
      <link>https://stats.stackexchange.com/questions/657224/comparing-data-at-different-locations-over-a-time-series</link>
      <description><![CDATA[我有来自放置在湖泊不同位置的探测器的水质数据，这些数据在整个夏季每小时收集一次。我想知道我收集的参数在四个位置之间是否存在差异。我还想知道在夏季的什么时候出现了最大的差异。我不知道可以运行什么统计测试来调查这两个问题。我绘制了时间序列数据，但这只能提供定性分析。
根据简短的搜索，我发现重复测量方差分析可能有效，因为数据都与时间戳配对，但我还看到广义线性模型或其他模型（如 AIRMA 模型）可能更好。我不太熟悉这些模型，所以我不确定它们是否适合我的数据或如何使用它们。
任何有关如何处理这些数据的建议都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/657224/comparing-data-at-different-locations-over-a-time-series</guid>
      <pubDate>Wed, 13 Nov 2024 21:01:16 GMT</pubDate>
    </item>
    <item>
      <title>木材分解</title>
      <link>https://stats.stackexchange.com/questions/657223/wold-decomposition</link>
      <description><![CDATA[AR(p) 模型的自协方差总和
为什么这个等式成立？
$$
\sum_{k=0}^{\infty} \psi_k = \frac{1}{1-\sum_{i=1}^{p}\phi_{i}}
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/657223/wold-decomposition</guid>
      <pubDate>Wed, 13 Nov 2024 20:15:45 GMT</pubDate>
    </item>
    <item>
      <title>配对样本（SD 和 SE）</title>
      <link>https://stats.stackexchange.com/questions/657222/paired-sample-sd-and-se</link>
      <description><![CDATA[在一些出版物中，没有关于数据是基于标准差 (SD) 还是标准误差 (SE) 的信息。例如，在一篇出版物中，他们写道：“切换前后的平均注射间隔是可比的（33.8 ± 11.2 vs. 29.3 ± 2.6 天；p = 0.08）。”通常，± 后的数字指的是 SD（标准差）或 SE（标准误差）。（例如在这个例子中：11.2 指的是 SD 还是 SE）？]]></description>
      <guid>https://stats.stackexchange.com/questions/657222/paired-sample-sd-and-se</guid>
      <pubDate>Wed, 13 Nov 2024 20:09:58 GMT</pubDate>
    </item>
    <item>
      <title>Kaplan Meier 与累积发生率和事件发生率有区别吗？</title>
      <link>https://stats.stackexchange.com/questions/657220/is-there-a-difference-in-kaplan-meier-and-cumulative-incidence-and-incidence-of</link>
      <description><![CDATA[卡普兰迈耶 (Kaplan Meier) 和累积发病率有区别吗？CI 只是 1 公里吗？例如，如果住院后 5 年内心血管死亡的估计发病率为 43%，那么 KM 生存率估计为 100 - 43%，这样说对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657220/is-there-a-difference-in-kaplan-meier-and-cumulative-incidence-and-incidence-of</guid>
      <pubDate>Wed, 13 Nov 2024 19:58:40 GMT</pubDate>
    </item>
    <item>
      <title>X/Z 和 Y/Z 的相关系数</title>
      <link>https://stats.stackexchange.com/questions/657218/correlation-coefficient-of-x-z-and-y-z</link>
      <description><![CDATA[设 $X$ 和 $Y$ 为随机变量，相关系数为 $r_{x,y} \neq 0$。让 $Z$ 成为另一个随机变量，独立于 $Y$ 和 $X$。
定义 $W \equiv \frac{X}{Z}$ 和 $T \equiv \frac{Y}{Z}$。
就 $r_{x,y}$ 而言，$W$ 和 $T$ 的相关系数是多少？
我的第一个方法是尝试假设 $EX = EY = EZ= 0$。然后：
$$r_{w,t} = \frac{E(\frac{X}{Z} \frac{Y}{Z})}{\sqrt{V(\frac{X}{Z}) V(\frac{Y}{Z})}}$$
对于分母，我们有这个属性
$\mathrm{Var}(XY)=E(X)^2 \mathrm{Var}(Y)+E(Y)^2 \mathrm{Var}(X)+\mathrm{Var}(X)\mathrm{Var}(Y)$
在这种情况下，这等于 $V(X/Z) = V(X)V(1/Z)$
因此：
$$r_{w,t} = \frac{E(\frac{X}{Z} \frac{Y}{Z})}{\sqrt{V(X)V(1/Z)V(Y)V(1/Z)}}$$
由于在此情况下 $V(.) = E(.^2)$，我们得到：
$$r_{w,t} = \frac{E(\frac{1}{Z^2}) E(XY)}{\sqrt{V(X)V(Y) E(\frac{1}{Z^2})^2}}$$
简单来说：
$$r_{w,t} = \frac{E(XY)}{\sqrt{V(X)V(Y)}} \equiv r_{x,y}$$
如果我尝试删除所有期望等于零的假设，代数运算会相当麻烦。这是否符合 $EX, EY, EZ \neq 0$？]]></description>
      <guid>https://stats.stackexchange.com/questions/657218/correlation-coefficient-of-x-z-and-y-z</guid>
      <pubDate>Wed, 13 Nov 2024 18:44:06 GMT</pubDate>
    </item>
    <item>
      <title>R ad Stata 中的不同共线性处理</title>
      <link>https://stats.stackexchange.com/questions/657217/different-collinearity-treatment-across-r-ad-stata</link>
      <description><![CDATA[我有 59 个面板单元的不平衡面板数据集。数据频率为季度，我的样本包括 10 年的数据。缺失数据为缺失数据（无插补）。我的主要回归模型包括 5 个银行特定控制变量（其中 3 个是主要关注变量）、1 个危机虚拟变量、3 个感兴趣的独立变量的 3 个交互项（与危机虚拟变量交互）、3 个宏观经济控制变量、时间固定效应和银行固定效应。在整个回归过程中，我使用聚类标准误差（在银行层面）。此回归在 Stata 中运行顺利。然而，在 R 中，由于共线性，危机虚拟变量和 VSTOXX 变量（3 个宏观经济控制中的 1 个）被省略。你知道为什么会发生这种情况以及 R 和 Stata 之间的差异吗？如果我打印相关矩阵，对于危机虚拟变量，我得到与所有其他变量相关的 NA（但我想这是正常的，因为虚拟变量在好的时候取 0 值，在坏的时候取 1 值）。我提前感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/657217/different-collinearity-treatment-across-r-ad-stata</guid>
      <pubDate>Wed, 13 Nov 2024 17:25:51 GMT</pubDate>
    </item>
    <item>
      <title>将 Hessian 矩阵居中并进行 QR 变换后恢复为原始参数 X</title>
      <link>https://stats.stackexchange.com/questions/657210/transforming-hessian-to-original-parameters-after-centering-and-qr-transforming</link>
      <description><![CDATA[在进行最大似然估计 (MLE) 或贝叶斯后验抽样时，我开始更常规地对设计矩阵 $X$ 进行均值中心化和 QR 旋转。这有助于收敛，并在存在共线性时加快后验抽样。在对 $X$ 的列进行均值中心化之后，R qr 函数会转换（正交归一化）$X$，并提供一个矩阵 Rinv（我将其缩写为 $R$），该矩阵可与参数向量相乘以获得原始尺度上的参数。然后，将均值中心化反转以调整截距。我正在使用比例优势半参数模型来计算因变量 $k+1$ 个不同值 $Y$，因此有 $k$ 个截距 $\alpha_{1}, \ldots, \alpha_{k}$。在原始尺度上，当 $p$ 个 $X$ 列时，有 $p$ 个回归系数 $\beta_{1}, \ldots, \beta_{p}$。假设变换后的 $X$ 上的 MLE 为 $\delta$ 和 $\gamma$，分别对应于原始 $X$ 上的 $\alpha, \beta$。
给定矩阵 $R$ 和均值向量，很容易从 $\delta, \gamma$ 计算出 $\alpha, \beta$。令 $M$ 为 $k$ 行行重复矩阵，其中 $p$ 列包含 $X$ 的 $p$ 个原始列均值，即 $M = 1_{k\times 1} \times \bar{X}$，其中 $\bar{X}$ 是 $1\times p$ 均值向量。然后
$\beta = R \gamma$
$\alpha = \delta - M R \gamma$
让 $H$ 表示 $\delta, \gamma$ 的对数似然函数的二阶偏导数的 $(k+p)\times (k+p)$ 矩阵。将 $H$ 划分为
$$
\begin{bmatrix}
A_{k\times k} &amp; B_{k \times p} \newline
B&#39; &amp; D_{p\times p}
\end{bmatrix}
$$
我的理解是，变换参数尺度上的 $H$ 由以下公式计算得出
$J&#39;HJ$
其中雅可比矩阵 $J$ 由以下公式给出
$$
\begin{bmatrix}
\frac{\partial\alpha}{\partial\delta} &amp; \frac{\partial\alpha}{\partial\gamma} \newline
\frac{\partial\beta}{\partial\delta} &amp; \frac{\partial\beta}{\partial\gamma}
\end{bmatrix}
$$
等于
$$
\begin{bmatrix}
I_{k\times k} &amp; -M_{k\times p}R_{p\times p} \newline
0_{p\times k} &amp; R_{p\times p}
\end{bmatrix}
$$
其中 $I$ 是单位矩阵，而 $0$ 是零矩阵。
我用于计算转换后的 $H$ 的 R 代码是
M &lt;- matrix(1, nrow=k, ncol=1) %*% matrix(xbar, nrow=1)
J &lt;- rbind(cbind(diag(k), -M %*% R),
cbind(matrix(0, nrow=p, ncol=k), R ) )
H2 &lt;- t(J) %*% H %*% J

但在我的例子中，我得到的 H2 值，尤其是 $\beta$ 的右下子矩阵，偏差很大。有人能发现我哪里出错了吗？在贝叶斯设置中，一切都很简单，因为您只需为每个后验抽样计算 $\alpha$ 和 $\beta$，即可获得原始参数的正确后验分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/657210/transforming-hessian-to-original-parameters-after-centering-and-qr-transforming</guid>
      <pubDate>Wed, 13 Nov 2024 15:34:57 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA：对于通货膨胀数据，对数差分比二阶差分更好吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657158/arima-log-differencing-is-better-tnan-two-order-differencing-on-inflation-data</link>
      <description><![CDATA[我正在尝试对通货膨胀数据执行 ARIMA
我可以看到：

我需要两个顺序差分才能获得平稳性数据
并且只需要一个对数差分即可获得平稳性。
在对数差分中，我有两个数据下降，然后在 2020 年出现大幅飙升
在两次差分中，我首先出现大幅飙升，然后在 2020 年出现低点
两者在 ADF 测试中的 p 值几乎相同（约为 .01）。

在这种情况下，最好的差分方法是什么，以获得更好的 ARIMA？（我在 Rstudio 中工作）谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/657158/arima-log-differencing-is-better-tnan-two-order-differencing-on-inflation-data</guid>
      <pubDate>Tue, 12 Nov 2024 19:08:03 GMT</pubDate>
    </item>
    <item>
      <title>对数-对数变换数据的多元回归的预测区间</title>
      <link>https://stats.stackexchange.com/questions/657151/prediction-intervals-for-multiple-regression-on-log-log-transformed-data</link>
      <description><![CDATA[我正在使用对数对数变换数据进行普通最小二乘线性多元回归来建立树木生物量估计模型。最后，我希望得到一个生物量预测，其预测区间在原始范围内。我读过几篇关于这个主题的帖子（这里和其他地方），但没有变得更聪明。我是统计学新手，希望能得到一些实际的建议。以下是我所知道的：
我希望我的独立变量（$x_i$）和独立变量（$y$）之间的关系是幂函数。回归是在对数对数变换数据上执行的，如下所示：
$$\ln(y)=\alpha+\beta_1\ln(x_1)+\dots+\beta_n \ln(x_n)$$
我意识到我需要一个校正因子来获得无偏估计，并检查残差的恒定方差和正态分布，因此估计值应如下所示：
$$\hat y=e^{a+b_1 \ln(x_1)+\dots +b_n \ln(x_n)+\hat\sigma^2/2}$$
其中 $a$ 和 $b_i$ 是回归系数，$\hat\sigma$ 是残差的标准误差。
到目前为止一切顺利（我希望！）。我想要的是我的 $\hat y$ 的 PI（即一个方程，指定 95% 的未来观测值将落在一个范围内，以 kg 为单位）。我怀疑转换和误差与 $y$ 不独立这一事实可能会导致一些复杂情况。阅读​​这个主题只会让我感到困惑。我有两个猜测：

从回归中计算${\ln(y)}$的PI，添加${\hat\sigma^2/2}$并对其进行反向转换。
从$s=\sqrt{{1\over{N-p}}\sum{(\hat y-y_{obs})^2}}$计算新的误差估计并使用它来计算PI，但我猜异方差会是一个问题。

当然，我很感激能提供能提高我理解的评论和参考资料，但我真正需要的是一种能给我一个统计上有效的结果的清晰方法。在这种情况下，GLM 对我来说不是一个选择。
坚持使用 OLS 而不是使用 GLM 的原因仅仅是因为它（目前）是该领域最常用的方法。
根据要求，我添加了残差图。]]></description>
      <guid>https://stats.stackexchange.com/questions/657151/prediction-intervals-for-multiple-regression-on-log-log-transformed-data</guid>
      <pubDate>Tue, 12 Nov 2024 16:42:45 GMT</pubDate>
    </item>
    <item>
      <title>零点的中位绝对偏差</title>
      <link>https://stats.stackexchange.com/questions/657149/median-absolute-deviation-of-zero</link>
      <description><![CDATA[我使用 MAD 来衡量不同数字数据分布的分布范围，其中一些分布的 MAD 为 0。我很好奇，这怎么可能呢？如果我理解正确的话，MAD 是衡量数据集变异性的指标。我检查了一下，这些数据集的观测值并非全部相同。如果是这样的话，MAD 怎么会是零呢？
对于那些好奇的人，我在 R 中使用 mad() 函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/657149/median-absolute-deviation-of-zero</guid>
      <pubDate>Tue, 12 Nov 2024 16:39:02 GMT</pubDate>
    </item>
    <item>
      <title>如何检验相关观测值的方差是否相等？</title>
      <link>https://stats.stackexchange.com/questions/657075/how-to-test-for-equal-variances-of-correlated-observations</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657075/how-to-test-for-equal-variances-of-correlated-observations</guid>
      <pubDate>Mon, 11 Nov 2024 12:02:09 GMT</pubDate>
    </item>
    <item>
      <title>论文讨论 - 汉密尔顿神经网络</title>
      <link>https://stats.stackexchange.com/questions/656626/paper-discussion-hamiltonian-neural-networks</link>
      <description><![CDATA[我正在写一篇关于 Sam Greydanus 等人的发现的论文：https://arxiv.org/abs/1906.01563v1
我想知道是否有人可以帮助我提供一些见解：
他们强调了如何让模型直接预测汉密尔顿量，并从框架公理中推导出梯度 dp/dt 和 dq/dt 得到更好的结果：
[![汉密尔顿动力学关系动量和位置][1]
[1]：https://i.sstatic.net/Im4x43Wk.png
他们确实获得了很好的结果，甚至比直接预测梯度的传统神经网络更好。 HNN 创建的映射正确地保存了理想摆锤等的能量。
我的问题是：为什么这很重要？我们不只是在强化偏见吗？如果我们使用神经网络的目标是模拟复杂系统，为什么要强制执行现有框架？
模型的准确性只能与框架一样，让神经网络自己发现这些框架和映射不是更有趣吗？由于现实世界在某种程度上是可预测的，因此应该有一个底层框架，其映射比人造框架更准确。我们在神经网络中有数百万个参数，而分析/数值解决方案中只有几个参数？
我可能完全偏离了主题（我只是一名工程专业的学生），但我认为在我的论文中讨论这个问题以及实际讨论结果可能是一个很酷的角度。]]></description>
      <guid>https://stats.stackexchange.com/questions/656626/paper-discussion-hamiltonian-neural-networks</guid>
      <pubDate>Thu, 31 Oct 2024 12:19:58 GMT</pubDate>
    </item>
    </channel>
</rss>