<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 26 Sep 2024 09:18:08 GMT</lastBuildDate>
    <item>
      <title>应用 GMM 检测器后，如何知道哪些特征对异常值得分贡献最大？</title>
      <link>https://stats.stackexchange.com/questions/654930/how-to-know-which-features-contribute-the-most-to-the-outlier-score-after-applyi</link>
      <description><![CDATA[我有一个包含 100 多个特征的数据集，我在此数据集上测试 GMM 以检测异常。例如，我向 100 个点的 5-6 个特征添加一些高斯噪声。GMM 可以轻松检测到这些点，但下一步建议的步骤是让 GMM 本身定位带有噪声的特征。这就是我陷入困境的地方。
sklearn 返回的异常值分数是作为数据点所有维度的总和计算的。我尝试检索内部变量以了解分数计算的过程，并以某种方式分离具有突出值的特征，但没有成功。我怀疑这与协方差矩阵的计算方式有关。
我很乐意得到一些关于在 GMM 算法内部查看哪里的提示或一些检测后分析方法的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/654930/how-to-know-which-features-contribute-the-most-to-the-outlier-score-after-applyi</guid>
      <pubDate>Thu, 26 Sep 2024 09:13:54 GMT</pubDate>
    </item>
    <item>
      <title>模拟人们离开鸡尾酒会</title>
      <link>https://stats.stackexchange.com/questions/654926/simulate-people-leaivng-a-cocktail-party</link>
      <description><![CDATA[这是我研究了一段时间的一道数学题 https://math.stackexchange.com/questions/4976090/probability-of-people-leaving-a-cocktail-party
在这个问题中，有一个有“n”个人的鸡尾酒会。然而，随着越来越多的人离开聚会，人们离开聚会的速度也会增加。我们假设没有新人可以加入派对，离开派对的客人将永远离开。
我试图模拟客人在以下条件下离开派对的情况：

加速离开：客人离开派对的速度取决于派对上目前有多少客人
标准离开：客人离开派对的速度完全随机

我试图在 R 中对此进行模拟：
library(ggplot2)
library(dplyr)

simulate_party_accelerating &lt;- function(n, alpha) {
t &lt;- 0
X &lt;- n
times &lt;- c(0)
​​people &lt;- c(n)
while (X &gt; 0) {
lambda &lt;- alpha * (n - X + 1) / X
T &lt;- rexp(1, lambda * X)
t &lt;- t + T
X &lt;- X - 1
次 &lt;- c(次, t)
人 &lt;- c(人, X)
}
data.frame(时间 = 次, 人 = 人)
}

simulate_party_fixed &lt;- function(n, lambda) {
t &lt;- 0
X &lt;- n
次 &lt;- c(0)
​​人 &lt;- c(n)
while (X &gt; 0) {
T &lt;- rexp(1, lambda * X)
t &lt;- t + T
X &lt;- X - 1
times &lt;- c(times, t)
people &lt;- c(people, X)
}
data.frame(time = times, people = people)
}

run_simulations &lt;- function(n_sims, n_people, alpha, lambda) {
sim_data_accelerating &lt;- lapply(1:n_sims, function(i) {
df &lt;- mock_party_accelerating(n_people, alpha)
df$simulation &lt;- i
df$type &lt;- &quot;Accelerating&quot;
return(df)
})

sim_data_fixed &lt;- lapply(1:n_sims, function(i) {
df &lt;- mock_party_fixed(n_people, lambda)
df$simulation &lt;- i
df$type &lt;- &quot;Fixed&quot;
return(df)
})

rbind(do.call(rbind, sim_data_accelerating),
do.call(rbind, sim_data_fixed))
}

n_people &lt;- 100
alpha &lt;- 0.1
lambda &lt;- 0.1 
n_sims &lt;- 100

set.seed(123) # 用于可重复性
sim_results &lt;- run_simulations(n_sims, n_people, alpha, lambda)

ggplot(sim_results, aes(x = time, y = people, group = interaction(simulation, type), color = type)) +
geom_line(alpha = 0.3) +
scale_color_manual(values = c(&quot;加速&quot; = &quot;蓝色&quot;, &quot;固定&quot; = &quot;red&quot;)) +
labs(title = &quot;派对出发模拟：加速与固定速度&quot;,
x = &quot;时间&quot;, y = &quot;剩余人数&quot;,
subtitle = paste(n_people, &quot;initial people,&quot;, n_sims, &quot;simulations each&quot;)) +
theme_minimal() +
guides(color = guide_legend(title = &quot;出发率&quot;))


乍一看，这似乎有些不合逻辑。似乎加速离场的派对比完全随机离场的派对持续时间更长。
我是不是哪里搞错了？或者这仅仅取决于 alpha 和 lambda 的选择？（例如，我注意到，对于其他 alpha 和 lambda 值，加速离场的派对持续时间比另一方短）。
对问题可能是什么有什么想法？]]></description>
      <guid>https://stats.stackexchange.com/questions/654926/simulate-people-leaivng-a-cocktail-party</guid>
      <pubDate>Thu, 26 Sep 2024 05:36:11 GMT</pubDate>
    </item>
    <item>
      <title>处理连续比率模型中的缺失信息 - 审查？</title>
      <link>https://stats.stackexchange.com/questions/654925/handling-missing-information-in-continuation-ratio-model-censoring</link>
      <description><![CDATA[我正在 R 中拟合连续比率模型，首先使用 rms::cr.setup() 将数据放入“人阈值”或“人周期”格式，然后拟合逻辑回归。（如 Cole &amp; Ananth, 2001 中所述）。我的结果涉及“治疗级联”的进展程度每个人得到：
1 - 需要治疗但未转诊
2 - 转诊（但未参加入院治疗）
3 - 参加入院治疗（但治疗时间 &lt;14 天）
4 - &gt;= 14 天治疗

我的问题是，对于某些人，我们知道他们参加了入院治疗，但没有关于他们接受治疗时间的信息。换句话说，我们知道它们对结果的价值是 &gt;=3，但不知道真实值是 3 还是 4。
我读到，连续模型可以概念化为具有逻辑链接的离散生存或风险模型（例如，Cole &amp; Ananth，2001；Suresh 等人，2022；Tutz &amp; Schmid，2016，第 38 页）。鉴于此，我可以右删失那些我不知道它们是否超出摄入量/第 3 级的情况吗？我该如何实现这一点？
图 1 来自 Suresh 等人。似乎表明我可以通过添加行直到审查点来实现这一点，但对于这些情况将所有值设置为 0（例如，ID 2 在间隔 4 处审查，ID 3 在间隔 5 处审查）：

但我真的不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/654925/handling-missing-information-in-continuation-ratio-model-censoring</guid>
      <pubDate>Thu, 26 Sep 2024 05:09:51 GMT</pubDate>
    </item>
    <item>
      <title>分母可以为 0 时的比率</title>
      <link>https://stats.stackexchange.com/questions/654924/ratios-when-0-denominator-is-possible</link>
      <description><![CDATA[我看过一些讨论类似内容的帖子，但我觉得我的用例有点不同，不符合给出的答案。
我有数字使用记录，用户在给定时间段内可以使用网站或移动应用程序或两者。用户将始终至少使用一次网站或应用程序。我想创建一个标签，上面写着“始终使用网站”、“始终使用应用程序”、“主要使用网站”、“主要使用应用程序”和“甚至”之类的内容。除了简单的标签外，我还想观察比率的“权重” - 不仅仅是它是否不同，而且有多大？我的想法...
使用 x = web 数量/应用数量的比例...

始终是 web - web 数量/0（未定义）
始终是应用 - 0/应用数量（0）
偶数 - 我可能会将 0.9 和 1.1 之间的任何值称为“偶数”
主要两者之一为 &lt; 0.9 或 &gt; 1.1

我的问题是第一个，始终是 web。有人能建议创建某种“加权”指标来显示差异如何/是否不同，以及差异有多大吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654924/ratios-when-0-denominator-is-possible</guid>
      <pubDate>Thu, 26 Sep 2024 02:23:41 GMT</pubDate>
    </item>
    <item>
      <title>如何平滑这些曲线以获取其趋势？</title>
      <link>https://stats.stackexchange.com/questions/654922/how-to-smoothen-these-curves-to-get-their-trends</link>
      <description><![CDATA[我有一组 10 个信号，如下所示：

我们可以看到，它们非常嘈杂，而大多数噪声都是异常值。我需要能够以某种方式使它们平滑，从而保留每个信号中的点数。
到目前为止，我已经尝试了双重应用中值滤波器，并且获得了接近我想要的结果，但不幸的是，它并不是对所有滤波器都有效，并且在信号开始时看起来并不可靠：

那么，您知道对这种情况有用的任何方法吗？我在这个领域的知识非常有限，基本上仅限于中值滤波和 Savitzky-Golay，这似乎没什么用。
我需要非常平滑的线条来保留主要趋势（不是超精确），并且没有异常值/振荡。

数据（10 个列表的列表）
链接：https://jpst.it/3VUqP]]></description>
      <guid>https://stats.stackexchange.com/questions/654922/how-to-smoothen-these-curves-to-get-their-trends</guid>
      <pubDate>Thu, 26 Sep 2024 01:10:42 GMT</pubDate>
    </item>
    <item>
      <title>多层次建模？</title>
      <link>https://stats.stackexchange.com/questions/654913/multi-level-modelling</link>
      <description><![CDATA[在一项教学研究中，我对写作质量进行了前测和后测测量——没有控制条件。10 个班级中有 110 名学生。我对拼写技能和手写流畅度进行了前测测量，作为协变量。我想测试：
-从前测到后测，分数是否有所增加？
-每个协变量是否预测了文本质量水平？
-每个协变量是否预测了从前测到后测的文本质量增益？
-从前测到后测，各个班级的文本质量增益是否不同？
-如果可能，测试班级之间在文本质量增益方面的差异是否受到手写和拼写的影响
只有两个时间点，我可以使用多级建模吗？在 SPSS 中？
感谢您对此提出的任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/654913/multi-level-modelling</guid>
      <pubDate>Wed, 25 Sep 2024 20:09:10 GMT</pubDate>
    </item>
    <item>
      <title>解释交叉表摘要</title>
      <link>https://stats.stackexchange.com/questions/654911/interpreting-cross-table-summary</link>
      <description><![CDATA[我正在生成一个简单的 2 x N 列联表，总结女性在 COVID-19 之前和期间/之后的就业状况。列代表两个时间段：1) COVID 之前和 2) COVID 期间/之后。
就业状况摘要如下：
就业状况 COVID 之前 COVID 期间/之后
缺失响应 41% 18.6%
失业（家庭主妇） 301 (8.8%) 443 (20%)
就业 1315 (49.9%) 1276 (61.4%)

数据显示，失业家庭主妇的百分比（从 COVID 之前的 8.8% 增加到 COVID 期间/之后的 20%）和就业女性的百分比（从 49.9% 增加到 61.4%）都有所增加。这似乎违反直觉，因为我们预计失业率上升与就业率下降同时发生。
我该如何解释这些结果？任何建议都非常感谢。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654911/interpreting-cross-table-summary</guid>
      <pubDate>Wed, 25 Sep 2024 19:58:04 GMT</pubDate>
    </item>
    <item>
      <title>用连续给定条件概率建模</title>
      <link>https://stats.stackexchange.com/questions/654900/modelling-conditional-probabilities-with-continuous-givens</link>
      <description><![CDATA[我目前正在努力解决这个方程式
$$ p(x; \theta) = P(Y = 1 | X = x) $$
其中 $p$ 是右侧条件概率的模型。如果 $X$ 是连续随机变量，那么这个方程式肯定没有意义。我们是否简单地将 $X$ 视为离散变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654900/modelling-conditional-probabilities-with-continuous-givens</guid>
      <pubDate>Wed, 25 Sep 2024 16:19:27 GMT</pubDate>
    </item>
    <item>
      <title>bfastlite 函数的参数调整</title>
      <link>https://stats.stackexchange.com/questions/654910/parameter-tuning-of-the-bfastlite-function</link>
      <description><![CDATA[我正在使用 bfast 包的 bfastlite() 函数来运行时间序列 (ts) 分析。我从作者的论文（表 2）中引用：

需要调整参数来优化性能，不区分季节性和趋势的中断

到目前为止，我一直在手动微调模型，也就是说，我一个接一个地更改参数，这很耗时。有人对模型的微调有更好的解决方案吗？
为了查看模型的哪些参数可以实现最佳结果，我检查了检测到的断点中的日期（目视检查）。
library(bfast)

plot(simts) # 包含模拟 NDVI 时间序列的 stl 对象
datats &lt;- ts(rowSums(simts$time.series))
# 所有组件的总和（季节、突变、剩余）
tsp(datats) &lt;- tsp(simts$time.series) # 分配正确的时间序列属性
plot(datats)

# 检测断点。默认参数
bp = bfastlite(datats)
plot(bp)

# 优化模型 ??????
bp_opt &lt;- bfastlite()

R 4.4.1，bfast 1.6.1，Windows 11。]]></description>
      <guid>https://stats.stackexchange.com/questions/654910/parameter-tuning-of-the-bfastlite-function</guid>
      <pubDate>Wed, 25 Sep 2024 14:48:51 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证不起作用[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654892/cross-validation-doesnt-work</link>
      <description><![CDATA[我目前在当地大学听一场数据科学演讲。我们是从工作单位来的，我从事 DS/ML 工作，已经 7 年了，但我的学位是计算机科学，因此我在 DS/ML 方面主要是自学的。
这个人告诉我们，DS 文章中写到的很多东西实际上都不起作用。
例如，他提到精确度、召回率和 F1 分数很少使用（相反，他更喜欢 AUC）。
但对我来说，另一个更古怪的事情是，交叉验证也不应该用于业务问题。他解释说它不起作用，因为它不代表现实生活。在现实生活中，你的目标不是预测数据分布中的随机样本，而是必须根据过去 x 年建立一个模型来预测未来 y 个月的数据。
所以他说交叉验证基本上是无用的，应该使用前向优化。
首先，它是如何工作的？它只用于验证还是也可以用于优化？怎么做？
此外，CV 真的那么没用吗？这是我读过的关于 DS 的任何文章中最被接受的验证形式。但也许这是我自学知识的不足之处。
还有什么关于很多事情的“神话”更高大上，但在现实生活中却不起作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/654892/cross-validation-doesnt-work</guid>
      <pubDate>Wed, 25 Sep 2024 12:55:02 GMT</pubDate>
    </item>
    <item>
      <title>3 种条件下刺激效果比较</title>
      <link>https://stats.stackexchange.com/questions/654875/comparing-stimulation-efficacy-under-3-conditions</link>
      <description><![CDATA[我有一个数据集，其中我比较了 3 种药物情况（药物 a、药物 b、药物 a+b），我的读数是培养皿中对药物有反应的细胞数量。




药物B-00mg
药物B-10mg
药物B-20mg
药物B-20mg




药物 A-00mg






药物A-10mg






药物 A-10mg






药物 A-10mg








因此，在每个培养皿中，我分别测试药物 A（第一列）和药物 B（第一行），以及在其他细胞中的鸡尾酒组合，总共 16 种情况（包括第一种不添加药物的情况）
我的读数是对药物治疗（这是一个在 0-50 之间变化的数字），我已经在 5 次生物重复中完成了此操作。
我想确定不同水平的药物 a+b 条件是否与仅药物 a 或仅药物 b 在统计上不同。
最好的测试形式是某种重复测量克鲁斯卡尔沃利斯法吗？
提前谢谢大家
编辑：更新了问题并提供了一个表格，希望能提供更清晰的信息]]></description>
      <guid>https://stats.stackexchange.com/questions/654875/comparing-stimulation-efficacy-under-3-conditions</guid>
      <pubDate>Wed, 25 Sep 2024 02:10:33 GMT</pubDate>
    </item>
    <item>
      <title>在我的背景下，合理处理 Wilcoxon 符号秩检验中的 0 和平局的方法</title>
      <link>https://stats.stackexchange.com/questions/654751/rational-way-of-handling-0s-and-ties-in-wilcoxon-signed-rank-test-in-the-backgro</link>
      <description><![CDATA[在讨论进行 Wilcoxon 符号秩检验时如何处理平局？的背景下，我有以下 2 个后续问题：
我有 52 个前后得分，其中有平局和 0，所以我使用了 coin 包，其中 ties_method = &quot;midrank&quot;，它运行完美，没有给我任何警告。从概念上讲，使用 midrank 是一个好的解决方案吗？
如果您的因变量是具有 1-4 个可能值的序数，并且您将其用作区间变量，则很可能会得到许多平局。在这种情况下，考虑到前后数据没有差异，你的结论是否合理？]]></description>
      <guid>https://stats.stackexchange.com/questions/654751/rational-way-of-handling-0s-and-ties-in-wilcoxon-signed-rank-test-in-the-backgro</guid>
      <pubDate>Mon, 23 Sep 2024 03:40:24 GMT</pubDate>
    </item>
    <item>
      <title>一个具有多个预测因子的逻辑回归模型或多个具有一个预测因子的模型？</title>
      <link>https://stats.stackexchange.com/questions/654712/one-logistic-regression-model-w-multiple-predictors-or-multiple-models-with-one</link>
      <description><![CDATA[我认为这是解决我的问题的一个草率方法，甚至可能完全无效，但我正在尝试拟合一个逻辑回归模型，其中有一些空值（NA，因为我在 R 中执行此操作）。空值是由于数据收集不完整造成的，因此我对任何类型的插补方法都非常犹豫，因为在我看来，这（我认为）类似于伪造我的数据。我只好删除具有空值的观测值，但这可能意味着删除很多对一个预测变量有用的观测值，因为它们缺少另一个预测变量的值。
作为一个极其简化的示例，假设我有以下数据集：
data &lt;- data.frame(
&quot;Gender&quot; = c(&quot;Man&quot;, &quot;Woman&quot;, &quot;Woman&quot;, NA, &amp;​​quot;Woman&quot;),
&quot;Race&quot; = c(&quot;White&quot;, &quot;Black&quot;, NA, &amp;​​quot;Black&quot;, &quot;White&quot;),
&quot;State&quot; = c(&quot;Sad&quot;, &quot;Happy&quot;, &quot;Sad&quot;, &quot;Happy&quot;, &quot;Sad&quot;)
)

如果我想看看 Gender 和 Race 是否可以预测 State，我的第一个想法是制作一个看起来像这样的模型：
State ~ Gender + Race

但是，如果我通过删除这些观察值来处理 NAs，我会从 Gender 中删除一个有效数据点，从 Race 中删除一个有效数据点，剩下 3 个观察值。
如果我决定制作两个单独的模型，我可能会得到类似这样的结果：
State ~ Gender
State ~ Race

现在，如果我删除 NA 观察值，我仍然有性别 有 4 个观察值，种族 有 4 个观察值，而不是每个有 3 个。但从统计上来说，这样做是不是很愚蠢？将其拆分成两个独立模型有什么损失？我所失去的比获得的观察值更重要吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654712/one-logistic-regression-model-w-multiple-predictors-or-multiple-models-with-one</guid>
      <pubDate>Sat, 21 Sep 2024 22:47:47 GMT</pubDate>
    </item>
    <item>
      <title>最大对数似然拟合中优化参数的置信区域</title>
      <link>https://stats.stackexchange.com/questions/654427/confidence-regions-of-optimized-parameters-in-maximum-log-likelihood-fits</link>
      <description><![CDATA[我正在使用数值优化算法来最大化对数似然函数，$\mathcal{L}$。对数似然函数具有固定数量的参数，$\{\theta_i\}$。这些参数通过优化算法进行优化，以最大化对数似然函数，从而获得参数$\theta_i$值的最佳估计值。
我知道可以推导或计算$\Delta \mathcal{L}$的一些临界值，这些临界值可用于获取参数$\theta_i$的置信区域。
但是，我不知道如何找到这些信息，或者在哪里可以找到这些信息。
我浏览了Casella和Berger的统计推断，希望找到$\Delta \mathcal{L}$的值表，或者某种计算此类值表的方法。我期望在区间估计一章中找到它，但没有。如果信息在那里，那么我不明白我在读什么，因此它超出了我的理解范围。
有人能指出我正确的方向吗？
以下是一些进一步的信息：

由于$\mathcal{L}$是参数$\theta_i$的函数，通过改变$\theta_i$的值，我们也会改变$\mathcal{L}$的值。
参数$\hat{\theta}_i$的最佳估计值是通过最大化$\mathcal{L}$。
如果我们想要估计与 $\theta_i$ 相关的置信区域，我们可以改变 $\theta_i$ 的其中一个值，直到对数似然函数 $\mathcal{L}$ 的值改变某个临界值 $\Delta \mathcal{L}$。
$\Delta \mathcal{L}$ 的值取决于参数 $i$ 的数量和目标置信水平。
例如，置信度越大，该值越大带。
如果我们想要 99% CL，那么所需的 $\Delta \mathcal{L}$ 值将大于我们估计 95% CL 区域时的值。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654427/confidence-regions-of-optimized-parameters-in-maximum-log-likelihood-fits</guid>
      <pubDate>Mon, 16 Sep 2024 13:03:01 GMT</pubDate>
    </item>
    <item>
      <title>OLS 回归变换，其中独立变量的总和是因变量的一部分</title>
      <link>https://stats.stackexchange.com/questions/654130/ols-regression-transformation-where-the-sum-of-the-independent-variables-is-part</link>
      <description><![CDATA[我最近看到了以下形式的回归（不是在书中，而是在业余环境中），其 ID 为 $i$，区域为 $j$：
$$\ln\left(\dfrac{1+y_i}{1+\sum_{j\in\{1,2,3\}}x_{ij}}\right) = \ln(1+x_{i1})\beta_1+\ln(1+x_{i2})\beta_2+\ln(1+x_{i3})\beta_3+\epsilon_i\\
=\boldsymbol{X}_i\boldsymbol \beta+\epsilon_i$$
现在，比率 $y_i/\sum_{j\in\{1,2,3\}} x_{ij}$ 具有一定的解释，我们称之为 $\textit{multiplier}$。
我们想要预测给定 $x_1,x_2,x_3$ 的 $\textit{multiplier}$、$\widehat{\textit{multiplier}}$。其实现方式如下：
$$\widehat{\textit{multiplier}}_i=\exp\left(\boldsymbol{X}_i\hat{\boldsymbol \beta}\right)\times\dfrac{ \left(1+\sum_{j\in\{1,2,3\}}x_{ij}\right)-1}{\sum_{j\in\{1,2,3\}}x_{ij}}.$$
我大概明白这个回归的概念。但是，我有以下几点批评意见：

我们已经给出了 $x_{ij}$，因此将 $x_{ij}$ 作为因变量的一部分对我来说毫无意义。有人能证实这没有意义吗？
$\textbf{Edit}$：在我看来，我们引入了一个额外的变异源。我们不能只重写方程式，将所有 $x$ 都放在右边吗？


在预测中，上述回归的左侧预测如下：$$\hat{Y}_i=\ln\left(\dfrac{1+\hat{y}_i}{1+\sum_{j\in\{1,2,3\}}\hat{x}_{ij}}\right),$$当然，我们不会预测单个 $\hat{y}_i$ 和 $\sum_{j\in\{1,2,3\}} \hat{x}_{ij}$，我们预测这些的比率作为变换。将预测的 $\exp\left(\boldsymbol{X}_i\hat{\boldsymbol \beta}\right)=\dfrac{1+\hat{y}_i}{1+\sum_{j\in\{1,2,3\}}\hat{x}_{ij}}$ 的分母与观察到的 $\left(1+\sum_{j\in\{1,2,3\}}x_{ij}\right)$ 相消是否有意义？

有人能帮我吗？
$\textbf{编辑 2:}$
我认为，当您运行以下形式的回归时，问题似乎相当类似：
$$\dfrac{y_i}{x_i} = x_i\beta+\epsilon_i$$ over $i$.
我认为，这样做是不正确的
$x_i\hat{\beta}\times x_i=\hat{y}_i$。
此外，您始终可以将上述回归重写为 $y_i=x_i^2
\beta+\epsilon_i^*$，对吗？
$\textbf{编辑 3}$：我将更明确地说明数据：
我们正在考虑保险数据，其中我们通过预期获得预期损失的补偿回报。当然，我们期望预期回报为$\geq$预期损失，否则，我们不会承保该合同。
$x$值是每个地区$j$的合同$i$的预期损失，为保险金额的$\%$（正数）（它们是聚合合同），$y$值是预期回报，为保险金额的$\%$（正数）。
在这种情况下，我很难考虑使用抵消。此外，$\sum_j x_{ij}$s 和 $y_i$s 之间的关系看起来像一个上三角，其中对于每个 $i$，$y_{i}\geq \sum_j x_{ij}$。]]></description>
      <guid>https://stats.stackexchange.com/questions/654130/ols-regression-transformation-where-the-sum-of-the-independent-variables-is-part</guid>
      <pubDate>Mon, 09 Sep 2024 21:30:38 GMT</pubDate>
    </item>
    </channel>
</rss>