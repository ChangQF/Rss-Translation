<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 22 Jan 2025 21:12:42 GMT</lastBuildDate>
    <item>
      <title>比较覆盖概率和间隔长度：BCa 与百分位数引导方法</title>
      <link>https://stats.stackexchange.com/questions/660390/comparing-coverage-probabilities-and-interval-lengths-bca-vs-percentile-bootst</link>
      <description><![CDATA[我进行了一项参数引导研究，以评估四个参数的覆盖概率，样本量分别为 35、50 和 100。在研究中，我计算了百分位数 CI 和 BCa CI。结果表明，百分位数方法的覆盖概率往往更为保守，而 BCa 方法通常可实现更接近标称水平的覆盖概率（$1-\alpha$）。但是，百分位数方法的平均间隔长度通常较短。
我怀疑这种差异是由于研究中使用的样本量较小造成的。我查阅的一篇参考文献提到，BCa CI 可调整偏差和偏斜度，除小样本外通常准确。我也知道最短的 CI 并不总是最好的。从覆盖概率的角度来看，在这种情况下，BCa 似乎优于百分位数方法。但与直觉相反，较短的 CI 也提供了更高的覆盖概率。我该如何证明我认为 BCa 更好？
我查阅了经典书籍，例如 Efron, B., &amp; Tibshirani, R. J. (1994) An Introduction to the Bootstrap、Davison, A. C., &amp; Hinkley, D. V. (1997) Bootstrap Methods and Their Application，并搜索了一些论文以找到类似的现象或讨论。但是，我还没有找到解决这一特定观察的明确理由，尤其是较短的 CI 提供更高的覆盖概率。
是否有人有见解或参考资料可以提供对这种行为的更深入了解？在此先感谢您的想法和指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/660390/comparing-coverage-probabilities-and-interval-lengths-bca-vs-percentile-bootst</guid>
      <pubDate>Wed, 22 Jan 2025 18:45:21 GMT</pubDate>
    </item>
    <item>
      <title>我可以针对不同的独立变量（特征）使用不同的核函数吗？我应该这样做吗？</title>
      <link>https://stats.stackexchange.com/questions/660389/can-i-use-different-kernel-functions-for-different-independent-variables-featur</link>
      <description><![CDATA[我正在使用核回归来模拟几个独立变量和一个因变量之间的非线性关系。我了解核函数和带宽选择，但我想知道是否有可能或有益于对不同类型的独立变量使用不同的核函数。
例如：

特征 1：连续变量（例如，以平方米为单位的大小）。
特征 2：离散变量（例如，房间数量）。

使用以下方法是否有意义：

特征 1（连续）使用 高斯核？
特征 2（离散）使用 三角核？

此外，我应该使用不同的核吗？这样做的利弊是什么？具体来说，我想了解：]]></description>
      <guid>https://stats.stackexchange.com/questions/660389/can-i-use-different-kernel-functions-for-different-independent-variables-featur</guid>
      <pubDate>Wed, 22 Jan 2025 18:35:03 GMT</pubDate>
    </item>
    <item>
      <title>在神经网络开始时权重的更新是否较少？</title>
      <link>https://stats.stackexchange.com/questions/660387/do-weights-update-less-towards-the-start-of-a-neural-network</link>
      <description><![CDATA[也就是说，因为错误来自神经网络的末端（即在输出层）并且通过反向传播回流到神经网络的开始处，这是否意味着靠近末端的权重比开始处的权重变化更大。这是真的吗？如果是，我该如何证明？
更一般地说，相对于网络层，权重增量的分布是怎样的？
直觉上，我认为这对于梯度下降（左）是正确的，但对于符号梯度下降（右）不正确：

最后发现 nanogpt 使用符号梯度下降比 AdamW 训练得更快：https://github.com/nullonesix/sign_nanoGPT
我想知道我的直觉是否可以被证明是正确的（如果是的话）。在此先感谢大家对这个话题的任何其他直觉或资源。]]></description>
      <guid>https://stats.stackexchange.com/questions/660387/do-weights-update-less-towards-the-start-of-a-neural-network</guid>
      <pubDate>Wed, 22 Jan 2025 18:10:55 GMT</pubDate>
    </item>
    <item>
      <title>子集选择成功与逻辑分布之间的联系</title>
      <link>https://stats.stackexchange.com/questions/660386/connections-between-subset-selection-success-and-logistic-distributions</link>
      <description><![CDATA[我是统计学新手，所以如果我遗漏了一些显而易见的东西，请不要起诉我。我最近在做一项作业，任务是分析以下带有子集选择的模型：
$$
y_i = \beta_1 x_{1, i} + \beta_2 x_{2,i} + \beta_3 x_{3,i} + \beta_4 x_{4,i} + u_i
$$
其中
$$(x_{k,i})_{k=1}^4 \sim \mathcal{N}(0, \Sigma)$$
$$
\Sigma = 
\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; \gamma &amp; \gamma\\
0 &amp; \gamma &amp; 1 &amp; \gamma\\
0 &amp; \gamma &amp; \gamma &amp; 1
\end{pmatrix}
$$
其中 $\gamma \in [-1, 1]$。此外，我们有 $\beta_2 = \beta_3 = \beta_4 = 2$，并且 $\beta_1 &gt; 2$。最后，$u_i$ 是 i.i.d。正态分布，均值为零，方差为 2，$i = 1, \ldots, N$。
我们的任务是确定 $\gamma$ 和 $\beta_1$ 的阈值，对于这些阈值，子集选择（子集大小等于 $1$）正确识别出最重要的协变量，即 $\beta_1$。
在此过程中，我设法得出以下曲线，对于 $N = 500$，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线。 class=&quot;math-container&quot;&gt;$\gamma = 0$ 第二个。
$\gamma$&quot; /&gt;
$\beta$&quot; /&gt;
在我看来，这些看起来非常符合逻辑！因此，我运行了一个简单的逻辑曲线拟合，模型如下：
$$
f(x) = \frac{A}{1 + \exp(-k(x - x_0))}
$$
我管理了以下参数
最适合 gamma 的逻辑函数是： 
A = 1.0011916177515001, x0 = 0.46613345213429164, k = -25.287773424878644
99% 置信区间： 
[[ 0.99834479 1.00403845]
[ 0.46495465 0.46731225]
[-25.94535303 -24.63019382]]
最适合 beta 的逻辑函数是： 
A = 1.0008861957715565, x0 = 4.131595820642967, k = 6.469500267867452
99% 置信区间： 
[[0.99799143 1.00378096]
[4.12631938 4.13687226]
[6.27646573 6.66253481]]

使用以下图表（不提供信息，只是漂亮）：


我不完全理解如何测量非线性最小二乘的拟合优度，但这些是非常严格的置信区间，所以这最终引出了我的问题。
这种行为有一个很好的理论解释吗？看来，正确识别具有子集选择的协变量的概率是具有这些神奇参数的逻辑分布。事实确实如此吗？它是渐近逻辑的吗？这实际上只是一个正态分布（我在写这篇文章时意识到了这一点）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660386/connections-between-subset-selection-success-and-logistic-distributions</guid>
      <pubDate>Wed, 22 Jan 2025 18:06:40 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯理论认为将结果而不是协变量作为似然函数中的数据的理由是什么？</title>
      <link>https://stats.stackexchange.com/questions/660385/what-is-the-bayesian-justification-for-considering-the-outcome-but-not-the-covar</link>
      <description><![CDATA[在频率论者的情况下，人们经常注意到，固定回归量的假设在实验研究的历史背景下是有意义的，但在观察数据的背景下，它在最好的情况下是一种近似值，在最坏的情况下是一种严重的错误指定（与问题对回归量进行条件化与将其视为固定量之间有什么区别？相关，特别是kjetil halvorsen 的回答）。
然而，贝叶斯线性回归示例似乎以相同的方式进行$^1$，其中协变量被视为不进入似然函数的固定量，尽管没有调用任何类型的辅助参数。 其原因是否与频率论案例中的过程相同，或者这种建模选择是否有贝叶斯依据？
更具体地说，我们以通常的形式调用贝叶斯定理：
$$
\operatorname{\pi}(\boldsymbol{\beta}, \sigma^{2} | \text{Data}) \propto \operatorname{\pi(\text{Data}| \boldsymbol{\beta}, \sigma^{2})} \operatorname{\pi}(\boldsymbol{\beta}, \sigma^{2})
$$
典型的贝叶斯线性模型将考虑以下模型规范：
$$
\begin{gather}
\boldsymbol{y} | \boldsymbol{\beta}, \sigma^{2} \sim \operatorname{N}(\boldsymbol{X \beta}, \sigma^{2} \boldsymbol{I}) \\
\boldsymbol{\beta}|\sigma^{2} \sim \operatorname{N}(\mu_{\beta}, \Sigma(\sigma^{2})) \\ \\
\sigma^{2} \sim \operatorname{IG}(a, b)
\end{gather}
$$
推断的目标是回归系数$\boldsymbol{\beta}$，它们显然是结果和协变量的函数，那么，决定 $\text{Data} = (\boldsymbol{y}) \neq (\boldsymbol{y}, \boldsymbol{X})$？在一个被吹捧为传播不确定性的框架中，典型的设置会默认选择忽略一个重要的不确定性来源，这似乎很奇怪。这只是一种教学选择吗？

$^1$：例如“[...] 配备共轭正态逆伽马先验的经典线性模型。所有关于贝叶斯分析的教科书中都描述了这个标准模型 [...]”回归（Fahrmeir、Kneib、Lang &amp; Marx，2013 年，第 225 页）]]></description>
      <guid>https://stats.stackexchange.com/questions/660385/what-is-the-bayesian-justification-for-considering-the-outcome-but-not-the-covar</guid>
      <pubDate>Wed, 22 Jan 2025 17:38:38 GMT</pubDate>
    </item>
    <item>
      <title>计算或估计 LASSO 模型的边际似然</title>
      <link>https://stats.stackexchange.com/questions/660383/computing-or-estimating-marginal-likelihood-of-lasso-model</link>
      <description><![CDATA[我有一个 LASSO 模型，想根据该模型计算某些数据的可信度。边际似然是一种理论上非常“干净”的方法。是否有任何简单的闭式表达式来表示边际似然积分，而不需要评估从可能非常大的字典中得出的巨大积分？
或者，我很乐意得到一些边际似然的估计值，只要知道这个估计值相当接近。这可能是：

已知与边际似然有某种关系的其他标量
已知可以很好地近似真实边际似然积分值的某种积分技术
其他任何东西

如果有其他代表“可信度”的量，我也会很高兴这在这里就足够了吗（MLE 的可能性）？
最后，当然，LASSO 已经从一种近似中构建出来了，因此如果有任何其他稀疏线性模型可以更容易地计算边际似然，我会很感兴趣。]]></description>
      <guid>https://stats.stackexchange.com/questions/660383/computing-or-estimating-marginal-likelihood-of-lasso-model</guid>
      <pubDate>Wed, 22 Jan 2025 16:51:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 Andorson-Darling 假设检验 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/660382/using-andorson-darling-hypothesis-test</link>
      <description><![CDATA[我有一个自定义 PDF 分布函数。我想测试自定义 PDF 分布函数是否适合数据，并将其与其他内置分布（如正态分布、威布尔分布、莱斯分布、中上分布和瑞利分布）进行比较。自定义 pdf 函数如下所示
function pdf_values = bivariate_pdf_r(r, phi, mr, mi, sr, si, cf)

% 定义正值的自定义 PDF 函数
f = @(r, phi) r&#39;.* (1 / (2 * pi * sr * si * sqrt(1 - cf^2))) .* ...
exp((-1 / (2 * (1 - cf^2))) * (((r .* cos(phi) - mr).^2 / sr^2) + ...
((r .* sin(phi) - mi).^2 / si^2) - 2 * cf * (r .* cos(phi) - mr) .* (r .* sin(phi) - mi) / (sr * si)));

% 在样本点处评估函数
pdf_values = f(r, phi);
end
]]></description>
      <guid>https://stats.stackexchange.com/questions/660382/using-andorson-darling-hypothesis-test</guid>
      <pubDate>Wed, 22 Jan 2025 16:35:51 GMT</pubDate>
    </item>
    <item>
      <title>分离广义加性模型中的相互作用和主效应</title>
      <link>https://stats.stackexchange.com/questions/660379/separating-interaction-and-main-effects-in-generalized-additive-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660379/separating-interaction-and-main-effects-in-generalized-additive-models</guid>
      <pubDate>Wed, 22 Jan 2025 15:13:10 GMT</pubDate>
    </item>
    <item>
      <title>数据集内规范化之后的跨数据集规范化</title>
      <link>https://stats.stackexchange.com/questions/660377/cross-dataset-normalization-following-within-dataset-normalization</link>
      <description><![CDATA[我一直在研究几个大型数据集，它们使用不同的方法来测量某些化学物质。例如，在一个数据集中，代表化合物 1 的值的范围可能是 10E⁴ 到 10⁵，而另一个可能是 50 - 100。到目前为止，我已经分别处理了这些数据集，并在数据集内使用了对数转换和中心缩放。我现在想问一个可以通过合并数据集来回答的问题。
我的问题是 - 为了合并所有数据集，将它们作为一个大组再次缩放是否有意义？或者我是否通过单独执行此操作有效地批量校正了数据集？
编辑：通过合并，我的意思是将数据表合并到一个大型数据集中以执行下游分析，例如聚类。]]></description>
      <guid>https://stats.stackexchange.com/questions/660377/cross-dataset-normalization-following-within-dataset-normalization</guid>
      <pubDate>Wed, 22 Jan 2025 14:09:27 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么估算器来估计不同名称的数量？</title>
      <link>https://stats.stackexchange.com/questions/660372/what-estimator-of-the-number-of-distinct-names-should-i-use</link>
      <description><![CDATA[我有 $N$ 个信封，每个信封都包含一张写有姓名的便条。有些姓名出现在多张便条上。总共有 $X$ 个不同的姓名。
为了弄清 $X$ 是什么，我打开 $n$ 个信封，找到 $x$ 个不同的姓名。
我应该使用什么 $X$ 估计量？理想情况下，我希望得到 $X$ 的估计量，并带有置信区间。
编辑：我不知道姓名计数遵循什么分布。但我知道我打开的信封中重复了多少次。如果有帮助的话，可以假设单个名字的最大出现次数比$N$小得多（&lt;1%）。]]></description>
      <guid>https://stats.stackexchange.com/questions/660372/what-estimator-of-the-number-of-distinct-names-should-i-use</guid>
      <pubDate>Wed, 22 Jan 2025 11:25:23 GMT</pubDate>
    </item>
    <item>
      <title>R 中使用二元变量的结构方程模型[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660356/structural-equation-modelling-with-binary-variables-in-r</link>
      <description><![CDATA[我的项目重点是使用电子病历数据探索疾病 A 的癌前合并症模式。在之前的项目中，我们根据诊断/实验室测试/药物信息确定了大约 30 种合并症。在这个项目中，我们旨在使用探索性因子分析（通过 psych 包）分析这些合并症如何聚类，并检查疾病 B 在疾病 A 发展中的中介作用（使用 lavaan 包）。我目前有以下主要问题：

数据显示 KMO 值较低（约为 0.2）。我们删除了共现率为零的变量对，这改善了 KMO，但导致一些变量丢失。我们是否应该继续使用低 KMO，因为我们更愿意保留这些变量？

对于包含所有二元变量的探索性因子分析，我可以使用四分相关（wls 估计量）吗？

A 和 B 是二元变量。对于中介分析，我可以使用对 A 和 B 进行排序的 lavaan 包（wls 估计器）吗？


非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/660356/structural-equation-modelling-with-binary-variables-in-r</guid>
      <pubDate>Wed, 22 Jan 2025 05:10:03 GMT</pubDate>
    </item>
    <item>
      <title>确保回归参数估计值始终为正</title>
      <link>https://stats.stackexchange.com/questions/660343/making-sure-that-a-regression-parameter-estimate-is-always-positive</link>
      <description><![CDATA[我有兴趣了解如何完成以下任务：

假设我有两个变量 $X_t$ 和 $Y_t$ 的月度数据。我有兴趣为 $Y_t$ 创建一个 ARIMAX 模型，该模型依赖于 $Y_t$ 和 $X_t$ 的旧版本。我可以像这样编写基本的 ARIMAX 模型：
$$ y_t = c + \phi_1y_{t-1} + \beta x_t + \epsilon_t $$
但是，我希望此模型具有以下属性：假设其他所有条件都相同，$X_t$ 的较大值必须产生 $Y_t$ 的较大值，而 $X_t$ 的较小值则不能产生。从数学上讲，我认为这可以理解为 $\beta$ 必须始终为正。我希望模型尊重这一事实。
$$ \frac{\partial y_t}{\partial x_t} = \beta &gt; 0 $$
$$ y_t = c + \phi_1y_{t-1} + \beta x_t + \epsilon_t $$
$$ \text{subject to: } \beta &gt; 0 $$
我想知道我们如何在模型中强制执行这一点。我天真地想到了两种方法：


基本约束：我不确定如何为这个 ARIMAX 模型写出基本可能性，但它应该是这样的：

$$ L(c, \phi_1, \beta|\textbf{y},\textbf{x}) $$
如果我希望 $\beta$ 为正，我应该能够写出一个受约束的可能性并使用拉格朗日函数来解决这个问题：
$$ \log L(c, \phi_1, \beta|\textbf{y},\textbf{x}) $$
$$ \beta \geq \epsilon $$
$$ \mathcal{L} = \log L(c, \phi_1, \beta|\textbf{y},\textbf{x}) + \lambda(\beta - \epsilon) $$

贝叶斯方法：我认为，如果我策略性地选择先验，我就可以确保 $\beta$ 始终为正。使用贝叶斯原理，我写了联合先验和后验：

$$ P(\theta) = P(\beta)P(c)P(\phi_1)P(\sigma^2) $$
$$ P(\theta|\textbf{y},\textbf{x}) = \frac{L(\theta|\textbf{y},\textbf{x})P(\theta)}{\int L(\theta|\textbf{y},\textbf{x})P(\theta)d\theta} $$
然后在$\beta$上，我可以放置一个先验，例如半正态（https://en.wikipedia.org/wiki/Half-normal_distribution) 以确保正性，但我不确定要使用哪些其他分布作为其他参数的先验。我认为 $\sigma^2$ 上的先验也需要是具有正支持的分布，因为方差不能为负。

我不确定这些方法是否可行且合乎逻辑。社区能否就此提供一些建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/660343/making-sure-that-a-regression-parameter-estimate-is-always-positive</guid>
      <pubDate>Tue, 21 Jan 2025 21:16:28 GMT</pubDate>
    </item>
    <item>
      <title>如何比较组内前后的比例？</title>
      <link>https://stats.stackexchange.com/questions/660338/how-to-compare-proportions-for-before-after-within-groups</link>
      <description><![CDATA[我有 4 个阵列，每个阵列有多个站点，我们在每个阵列的 100 个点中收集了主要基质类型（SS 或 LL）。因此，我在每个站点中标记了 100 个点的比例。
我们进行了两次此测试（一次在 1990 年代，一次在今年）。我想测试每个阵列（多个站点）中每种土壤类型的比例是否在不同年份（1990 年代与今天）之间有所不同。考虑到每个阵列中都有成对（前后站点），我不确定是否应该使用卡方检验或其他方法？
percsub 列表示被视为基质的点数/100，其中 100 是每个站点的点数（其中一些数字对于 percsub 来说可能是错误的，因为我不得不更改一些数据以不公开发布实际收集的数据）。因此第一行表示，在阵列 AC 和站点 1，我们发现 LL 基质在 2024 年占点的 60%。



阵列
站点
基质
percsub
时间




AC
1
LL
0.6
今天


AC
1
SS
0.4
今天


AC
2
LL
0.6
今天


AC
2
SS
0.4
今天


AC
3
LL
0. 7
今天


AC
3
SS
0.1
今天


LC
5
LL
0.91
今天


LC
8
LL
0.84
至天


LC
8
SS
0.1
今天


LC
14
LL
0.94
今天


LC
15
LL
0.87
今天


LC
16
LL
0.89
今天


LC
17
LL
0.84
今天


LC
17
SS
0.15
今天


SJHW
14
LL
0.95
今天


SJHW
14
SS
0.05
今天


SJHW
16
LL
0.77
今天


SJHW
16
SS
0.23
今天


SJHW
17
LL
0.91
今天


SJHW
17
SS
0.08
今天


WC 
11
LL
0.58
今天


WC
11
SS
0.37
今天


WC
12
LL
0.6
今天


WC
 12
SS
0.38
今天


AC
1
LL
0.7
1990 年代


AC
1
SS
0.3
1990 年代


AC
2
LL 
0.39
1990 年代


AC
2
SS
0.61
1990 年代


AC
3
LL
0.25
1990 年代


AC
3
SS
0. 75
1990 年代


LC
5
LL
0.35
1990 年代


LC
8
LL
0.59
1990 年代


LC
8
SS
0.38
 1990 年代


LC
14
LL
0.6
1990 年代


LC
15
LL
0.39
1990 年代


LC
16
LL
0.5
1990 年代


LC
17
LL
0.63
1990 年代


LC
17
SS
0.3
1990 年代


SJHW
14
LL
0.87
1990 年代


SJHW
14
SS
0.13
1990 年代


SJHW
16
LL
0.71
1990 年代


SJHW
16
SS
0.29
1990 年代


SJHW
17
LL
0.8
1990 年代


SJHW
17
SS
0.13
1990 年代


WC
11
LL
0.46
1990 年代


WC 
11
SS
0.4
1990 年代


WC
12
LL
0.49
1990 年代


WC
12
SS
0.2
1990 年代


]]></description>
      <guid>https://stats.stackexchange.com/questions/660338/how-to-compare-proportions-for-before-after-within-groups</guid>
      <pubDate>Tue, 21 Jan 2025 19:43:41 GMT</pubDate>
    </item>
    <item>
      <title>R 中的生存回归问题：处理非删失数据和模型收敛问题</title>
      <link>https://stats.stackexchange.com/questions/660263/issues-with-survival-regression-in-r-handling-non-censored-data-and-model-conve</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660263/issues-with-survival-regression-in-r-handling-non-censored-data-and-model-conve</guid>
      <pubDate>Mon, 20 Jan 2025 09:37:55 GMT</pubDate>
    </item>
    <item>
      <title>具有相关随机变量的 $E[X\mid U,V]$</title>
      <link>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</link>
      <description><![CDATA[设 $(X,Y,Z)$ 为三维随机变量，其密度函数为 $f(x,y,z)=\frac{2}{3}(x+y+z)$ 在 $0&lt;x,y,z&lt;1$ 上，$U=\min(X,Y,Z)$，$V=\max(X,Y,Z)$。计算$E[X\mid U,V]$。
我认为答案是$\frac{14U^2+26UV+14V^2}{27(U+V)}$，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</guid>
      <pubDate>Thu, 13 Jun 2024 05:43:04 GMT</pubDate>
    </item>
    </channel>
</rss>