<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 10 Feb 2024 15:12:00 GMT</lastBuildDate>
    <item>
      <title>错误传播。更简单的平均误差</title>
      <link>https://stats.stackexchange.com/questions/639002/error-propagation-simpler-average-errors</link>
      <description><![CDATA[我正在设计一个实验室实习来研究错误传播。假设我将测量 $x \pm\varepsilon_x$ 和 $y \pm \varepsilon_y$，其中$\varepsilon_x = \varepsilon_y = \varepsilon$ 为简单起见。这两个变量都与数学表达式相关：
$z=c \frac{x}{y}$，其中 $c$ 是一个常数。
我想确定错误 $\delta z$ 以获得 $z \pm \delta z$跨度&gt;，所以：
$\delta z = |\frac{\partial z}{\partial x}|\varepsilon+|\frac{\partial z}{\partial y}|\varepsilon = c\varepsilon ({ \frac{1}{y}+\frac{x}{y^2}})$。
测量三次 $x$ 和 $y$，最终得到三个值： $z_1 \pm \delta z_1$、$z_2 \pm \delta z_2$ 和 $z_3 \pm \delta z_3$。我想获得平均值。下面的计算是否正确？
$\bar{z} \pm \delta z = \frac{z_1 + z_2 + z_3}{3}\pm \frac{\delta z_1 +\delta z_2 + \delta z_3}{3}$
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/639002/error-propagation-simpler-average-errors</guid>
      <pubDate>Sat, 10 Feb 2024 15:02:02 GMT</pubDate>
    </item>
    <item>
      <title>当测量误差本来就很高时进行比较测试？</title>
      <link>https://stats.stackexchange.com/questions/639000/comparison-test-when-measurement-error-is-inherently-high</link>
      <description><![CDATA[相关问题。
注意：我认为这个问题与其他问题足够不同，值得单独询问。
我的问题：
我需要确定一台设备的性能是否等于或不差于另一台设备的性能。我计划进行配对 T 测试，直接在实验室测试中比较这两个设备。我做了一个初步实验，设置类似于交叉规格 R&amp;R 研究，以评估我的实验室测试中的误差来源。我发现测量间方差远大于我想要检测的组间最小差异。另一方面，我的设备间差异非常低 - 比我想要检测的差异小得多。
我有充分的理由怀疑测量误差是被测量事物的本质所固有的，并且该误差无法进一步减小。 （测试涉及将一袋粘性液体拉过狭窄处；液体在袋内移动的方式以及袋子折叠的方式存在固有的可变性，我无法控制，但会影响袋子移动的阻力通过狭窄）。
当我使用实验中的标准差对配对 T 检验进行功效/样本量计算时，我发现需要 约 25,000 个观察值才能有 90% 的功效来检测组之间的合理差异。即使我将功率降低到 80%，我仍然需要约 10,000 次观察，而且我无法测试那么多设备（这是多年生产的价值）。实际上，测试超过 15 或 20 个单独的设备是令人望而却步的，但在同一设备上重复测量既便宜又容易，而且数据并不表明测量之间的依赖性（即回归分析的残差没有显示任何迹象）时间依赖性）。尽管如此，10,000 个重复样本仍然需要很长时间，而且不切实际。我想说，总共 200 个观察值大约是我实际上可以做的最大值。
我的问题：
在样本间方差较低但测量方差本质上较高的情况下，可以考虑哪些其他类型的比较测试？或者我可以采用哪些技术来帮助解决此测量错误（即转换、附加测试、研究设计等）
注意：
从我提出的问题类型中可以明显看出，但我是一名工程师，而不是统计学家。当然愿意花时间去理解和学习新概念，但请尽量让外行人可以理解的答案:)]]></description>
      <guid>https://stats.stackexchange.com/questions/639000/comparison-test-when-measurement-error-is-inherently-high</guid>
      <pubDate>Sat, 10 Feb 2024 14:03:21 GMT</pubDate>
    </item>
    <item>
      <title>当对连续值应用 QWK 时，SPSS 会计算什么？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638998/what-does-spss-calculate-when-applying-qwk-for-continuous-values</link>
      <description><![CDATA[即使您插入的变量是连续变量而不是有序变量，SPSS 也允许您直接计算 QWK。我很好奇SPSS内部是如何实现的。我想知道是否有一种方法可以在不分类的情况下计算QWK。
在我的实验中，我尝试使用从 0 到 10 的变量，并尝试创建变量的不同分区（3 路、5 路、10 路、等距值），并根据分区数越大，QWK 值与 SPSS 使用连续变量计算的值越趋近。
我的具体问题是，考虑到变量分类的结果与分 3 部分或分 10 部分相比变化很大，这里最好的近似值是什么？ （我提到SPSS的做法是因为它似乎是通过创建大量分区或直接使用连续变量进行一些计算来实现的）。]]></description>
      <guid>https://stats.stackexchange.com/questions/638998/what-does-spss-calculate-when-applying-qwk-for-continuous-values</guid>
      <pubDate>Sat, 10 Feb 2024 12:14:19 GMT</pubDate>
    </item>
    <item>
      <title>存在预定回归量和序列相关性时 GLS 估计器的不一致</title>
      <link>https://stats.stackexchange.com/questions/638997/inconsistency-of-gls-estimator-in-the-presence-of-predetermined-regressors-and-s</link>
      <description><![CDATA[设 为线性模型：
$$y_i = x_i&#39;\beta + \varepsilon_i$$
利用其矩阵形式，分别考虑严格外生假设和球形假设：
$$E[\varepsilon | X]=0, \quad E[\varepsilon \varepsilon&#39;|X]= \sigma^2 I_n$$
我们知道球形假设等价于 i) $E[\varepsilon_i^2|X]= \sigma^2$ 和 ii) $E[\varepsilon_i \varepsilon_j|X]=0$，$i \neq j$。
在这些条件下，我们的 OLS 估计量为蓝色。然而，如果违反球形条件，我们仍然有无偏 OLS 估计器，但我们不再有效率。因此，通过适当的变换，我们可以使用BLUE GLS估计器来纠正这个问题。
根据 Hayashi Econometrics 书籍（第 1.6 节广义最小二乘法 (GLS)）：
&lt;块引用&gt;
关于 GLS 有限样本特性的所有乐观结论都基于
假设广义回归模型中的回归量严格
外源性

值得注意的是，如果我们没有严格的外生性，OLS 和 GLS 估计器都不一定是无偏的。某些自回归过程就是这种情况，其中严格的外生性不成立。然而，如果回归量是“预先确定的”（比严格的外生性弱），则 OLS 估计量将具有一些良好的大样本属性（例如“一致性”和“渐近正态性”），即使它具有序列相关性。 Hayashi 继续说道：
&lt;块引用&gt;
相比之下，GLS 估计器没有这种可取之处。也就是说，如果误差不是严格外生的而仅仅是预先确定的，则校正序列相关性的 GLS 过程可能会使估计量不一致（参见第 6.7 节）。在保持一致性的同时明确考虑序列相关性的过程将在
第 6 章。

我只学习了林书的前两章，距离第六章还有很长的路要走，但我想更好地理解最后一句话。你能给我解释一下或者给我直觉吗？你能否给我一个例子，让我看到 GLS 如何在没有严格外生性但仅使用预定回归量的情况下无法纠正序列相关性？]]></description>
      <guid>https://stats.stackexchange.com/questions/638997/inconsistency-of-gls-estimator-in-the-presence-of-predetermined-regressors-and-s</guid>
      <pubDate>Sat, 10 Feb 2024 12:13:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么每次重新运行相同的代码时，最佳集群数量都会发生变化？这是正常的吗？</title>
      <link>https://stats.stackexchange.com/questions/638996/why-do-my-optimal-number-of-clusters-changes-everytime-i-re-run-the-same-code-i</link>
      <description><![CDATA[我有以下代码：
from matplotlib.lines import Line2D
从 sklearn.metrics 导入 Silhouette_score
从 sklearn.cluster 导入 SpectralClustering
from shapely.wkt import Loads # 确保从 shapely.wkt 导入负载

# 将 WKT 列转换为几何图形
gdf_coefficients[&#39;geometry&#39;] = gdf_coefficients[&#39;WKT&#39;].apply(loads)
gdf_coefficients = gdf_coefficients.set_geometry(&#39;几何&#39;)

# 迭代每个月包含 GWR 系数的 GeoDataFrame
对于（年，月），gdf_coefficients.groupby（[&#39;年&#39;，&#39;月&#39;]）中的gdf_month：
    # 从 GeoDataFrame 中提取 GWR 系数
    gwr_coefficients = gdf_month[[&#39;截距系数&#39;, &#39;温度均值系数&#39;, &#39;接触均值均值系数&#39;,
                                   &#39;policyIdx_max_coefficient&#39;, &#39;gdp_2019_coefficient&#39;, &#39;total_households_2021_coefficient&#39;,
                                   &#39;人口密度系数&#39;, &#39;daytime_population_2021_coefficient&#39;,
                                   &#39;elevation_mean_coefficient&#39;、&#39;NDVI_mean_coefficient&#39;、&#39;connectivity_index_coefficient&#39;]].values
    
    # 使用 Silhouette 系数确定最佳簇数
    剪影分数 = []
    对于范围 (2, 11) 中的 n_clusters：
        光谱 = SpectralClustering(n_clusters=n_clusters,affinity=&#39;nearest_neighbors&#39;)
        标签 = Spectrum.fit_predict(gwr_coefficients)
        Silhouette_scores.append（silhouette_score（gwr_coefficients，标签））
    
    # 找到最佳簇数
    最优簇 = Silhouette_scores.index(max(silhouette_scores)) + 2
    
    # 具有最佳簇数的谱聚类
    光谱 = SpectralClustering(n_clusters=optimal_clusters,affinity=&#39;nearest_neighbors&#39;)
    gdf_month[&#39;spectral_cluster&#39;] = Spectra.fit_predict(gwr_coefficients)
    
    # 直接从 gdf_month DataFrame 绘制集群
    plt.figure(figsize=(12, 8))
    ax = gdf_month.plot(column=&#39;spectral_cluster&#39;, cmap=&#39;Wistia&#39;, legend=False, Figsize=(12, 8))

    plt.title(f&#39;GWR 的谱聚类结果 - 年：{year}，月：{month}&#39;)

    # 计算当月的聚类中心（平均系数）
    cluster_centers = gdf_month.drop([&#39;NUTS3&#39;, &#39;WKT&#39;, &#39;几何&#39;], axis=1).groupby(&#39;spectral_cluster&#39;).mean()

    # 计算并绘制每个谱簇的簇中心（质心）
    对于集群，在 gdf_month.groupby(&#39;spectral_cluster&#39;) 中分组：
        cluster_union = group[&#39;geometry&#39;].unary_union
        cluster_center = 点(cluster_union.centroid.x, cluster_union.centroid.y)
        
        # 绘制聚类中心
        plt.scatter(cluster_center.x，cluster_center.y，color=plt.cm.cool(cluster / (optimal_clusters - 1))，marker=&#39;o&#39;，s=50，alpha=1，label=f&#39;Cluster {cluster } 中心&#39;）

    # 创建具有正确颜色的图例元素
    legend_elements = [Line2D（[0]，[0]，marker=&#39;o&#39;，color=&#39;w&#39;，markerfacecolor=plt.cm.cool（cluster /（optimal_clusters - 1）），markersize=5，alpha=0.5， label=f&#39;Cluster {cluster} Center&#39;) for cluster_centers.index]
    ax.legend(handles=legend_elements, title=&#39;聚类中心&#39;, bbox_to_anchor=(1.05, 1), loc=&#39;左上&#39;)

    plt.show()

    # 打印最优簇数
    print(“年：”,year,“月:”,month,“最佳簇数:”,optimal_clusters)

每次，无论出于何种原因，我重新运行代码时，基于 Silhouette 分数和谱聚类的最佳聚类数量都会发生变化。
如果这是预期的话，我找不到任何具体信息。
我的原始数据已经过预处理、归一化和标准化，所以我想知道这是否与噪声数据或算法的随机过程有关。
非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/638996/why-do-my-optimal-number-of-clusters-changes-everytime-i-re-run-the-same-code-i</guid>
      <pubDate>Sat, 10 Feb 2024 11:47:27 GMT</pubDate>
    </item>
    <item>
      <title>探索性因素分析与 PCA</title>
      <link>https://stats.stackexchange.com/questions/638994/exploratory-factor-analysis-vs-pca</link>
      <description><![CDATA[有一种非常漂亮且清晰的方法来说明 PCA 的几何结构。是否有类似的几何方法来说明探索性因子分析？例如，我们有 3D 数据，并且使用 2 个因子。如何想象我们进行全民教育时会发生什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/638994/exploratory-factor-analysis-vs-pca</guid>
      <pubDate>Sat, 10 Feb 2024 11:24:01 GMT</pubDate>
    </item>
    <item>
      <title>面板与合并 OLS</title>
      <link>https://stats.stackexchange.com/questions/638993/panel-vs-pooled-ols</link>
      <description><![CDATA[我的样本包含 2009-22 年间进行 IPO 的公司的会计业绩数据。我想研究一下，外国投资者参与IPO的公司是否比国内投资者参与IPO的公司表现更好。为此，我的因变量是资产回报率 (roa)，我的自变量是国内参与度 (domperc) 和国外 IPO 参与度 (forperc)。还有一些影响资产回报的控制变量，例如流动性 (cr)、杠杆 (der) 等。我想知道这个数据集是否符合面板数据回归分析或汇总 OLS 回归分析的条件？我的困惑源于以下事实：

我的样本不像大多数面板数据集那样是固定的。有些IPO发生在2009年，有些发生在2010年，有些发生在2012年。对于每一次IPO，我想检查IPO后3年的资产回报率。因此，对于2010年IPO的公司，我查看2011-2013年的资产回报率，对于2017年IPO的公司，我查看2018-20年的资产回报率数据。这赋予了数据时间序列性质。然而，由于 IPO 日期的不同，并非所有公司的资产回报率都可以在同一年进行分析。
我的样本具有时不变变量。虽然每次 IPO 的资产回报率每年都不同，但由于 IPO 并非每年都会进行，因此外资参与 IPO 的程度仍然是固定的。境内首次公开募股的参与程度也是如此。

为清楚起见，这是我的数据快照：

对于此事的任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/638993/panel-vs-pooled-ols</guid>
      <pubDate>Sat, 10 Feb 2024 08:24:01 GMT</pubDate>
    </item>
    <item>
      <title>计算$E[(\sum X_i)^4]$</title>
      <link>https://stats.stackexchange.com/questions/638992/calculating-e-sum-x-i4</link>
      <description><![CDATA[尝试找出以下内容中的错误所在。我的目标是使用 $E[(\bar X_n)^4 计算 var$(\bar X_n^2)$ ]=\frac{1}{n^4}E[(\sum X_i)^4]$ 鉴于 $X_1,...X_n$ 与 $EX_1=\mu, E[(X_1-\mu)^k]=\alpha_k$ 独立同分布。
$$E\left[\left(\sum X_i\right)^4\right]=E\left[\sum_i X_i\sum_jX_j\sum_kX_k\sum_lX_l\right]=\sum_ {i,j,k,l}E(X_iX_jX_kX_l)$$
现在，我根据索引 $i,j,k,l$ 将其分为 5 类。

全部不同。 $${n\选择 4}E^4(X_1)=\frac{n(n-1)(n-2)(n-3)}{24}\mu ^4$$
一对。 $${3\选择 1}{n\选择 3}E(X_1^2)E^2(X_1)=\frac{n(n-1)(n-2) )}{2}\mu^2\left[E(X_1-\mu)^2+\mu^2+2\mu E(X_1-\mu)\right]\\=\frac{n(n- 1)(n-2)}{2}\mu^2\left[\alpha_2+\mu^2\right]\\=\frac{n(n-1)(n-2)}{2}\mu ^2\alpha_2+\frac{n(n-1)(n-2)}{2}\mu^4$$
两对。 $${n \选择 2}E^2(X_1^2)=\frac{n(n-1)}{2}(\alpha_2+\mu^2)^2 \\=\frac{n(n-1)}{2}\alpha_2^2+n(n-1)\mu^2\alpha_2+\frac{n(n-1)}{2}\mu^4 $$
三个一样。 $${3\选择 1}{n\选择 2}E(X_1)E(X_1^3)=\frac{3n(n-1)}{2}\mu [E(X_1-\mu)^3+\mu^3+3\mu E(X_1-\mu)^2]\\=\frac{3n(n-1)}{2}\mu\alpha_3+\压裂{9n(n-1)}{2}\mu^2\alpha_2+\frac{3n(n-1)}{2}\mu^4$$
都是一类。 $$nE(X_1^4)=n[E(X_i-\mu)^4+\mu^4+4\mu E(X_i-\mu)^3+6 \mu^2 E(X_i-\mu)^2]\\=n\alpha_4+4n\mu\alpha_3+6n\mu^2\alpha_2+n\mu^4$$

我知道最后一个更简单的形式，但事情并没有那么好。如有错误请指出。
编辑。更多相关背景信息。我按照此处提到的方法获取$$\text{var}(\bar X_n^2)=\frac{4\mu^2\alpha_2}{n}+\frac{4\mu\alpha_3}{n^2}+\frac{\ alpha_4}{n^3}+(\frac{2}{n^2}-\frac{3}{n^3})\alpha_2^2$$ 与所需的表达式 $$\text{var}(\bar X_n^2)=\frac{4\mu^2\alpha_2}{n}+\frac{4\mu\alpha_3}{n^2 }+\frac{\alpha_4}{n^3}$$
（参考 The Jackknife &amp; Bootstap，Jun Shao）。这种强力表达式在简化后也有所不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/638992/calculating-e-sum-x-i4</guid>
      <pubDate>Sat, 10 Feb 2024 07:58:27 GMT</pubDate>
    </item>
    <item>
      <title>约束优化的必要条件</title>
      <link>https://stats.stackexchange.com/questions/638990/necessary-condition-for-constrained-optimization</link>
      <description><![CDATA[假设 $X=(X_1,\cdots,X_k)$ 服从已知大小的多项分布 $n $ 和未知概率向量 $(p_1,\cdots,p_k)$。
在约束$\prod_{i=1}^n p_i$的约束下找到解决方案的必要条件-container&quot;&gt;$p_1&gt;0$、$\sum_{i=1}^np_i = 1$ 和 $\sum_{i=1}^np_ih(X_i) = 0$。
这是我的处理方法：我需要找到满足 $\lambda_*\in\mathbb{R}^c$ 的唯一拉格朗日乘数 $\lambda_*\in\mathbb{R}^c$ class=&quot;math-container&quot;&gt;$Df(x^*) - \lambda_*^T Dg(x^*) = 0$，其中 $f(x )$ 是目标函数，$g(x)=0$ 是约束方程。但是，我不确定在这种情况下需要求导的目标函数是什么，因为我正在处理 $\prod_{i=1}^n p_i$ 的最大化。正确的方程式是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/638990/necessary-condition-for-constrained-optimization</guid>
      <pubDate>Sat, 10 Feb 2024 07:21:40 GMT</pubDate>
    </item>
    <item>
      <title>在存在违反球面假设的情况下，GLS 估计器对于 OLS 的优势</title>
      <link>https://stats.stackexchange.com/questions/638984/advantages-of-gls-estimator-for-ols-in-the-presence-of-violated-spherical-assump</link>
      <description><![CDATA[令 为由下式给出的线性模型：
$$y_i = x_i&#39;\beta + \varepsilon_i$$
利用其矩阵形式，分别考虑严格外生假设和球形假设：
$$E[\varepsilon | X]=0, \quad E[\varepsilon \varepsilon&#39;|X]= \sigma^2 I_n$$
我们知道球形假设等价于 i) $E[\varepsilon_i^2|X]= \sigma^2$ 和 ii) $E[\varepsilon_i \varepsilon_j|X]=0$，$i \neq j$。
在这些条件下，我们的 OLS 估计量为蓝色。然而，如果违反球形条件，我们仍然有无偏 OLS 估计器，但我们不再有效率。因此，通过对原始模型进行适当的变换，我们可以使用 GLS 估计器来纠正这个问题。 GLS 估计器将是蓝色的，因此，它将是有效的。
我很难想象 GLS 估算器的优势。我很清楚估计器本身是有利的，因为它在新的转换模型中是蓝色的，但我相信我的兴趣仍然是原始模型的 OLS 估计器。
那么，我想了解使用 GLS 作为原始模型的 OLS 估计器有什么好处？换句话说，鉴于我们原始模型 OLS 估计器仍然无偏但效率低下，那么使用 GLS 效率的优势是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/638984/advantages-of-gls-estimator-for-ols-in-the-presence-of-violated-spherical-assump</guid>
      <pubDate>Sat, 10 Feb 2024 04:29:33 GMT</pubDate>
    </item>
    <item>
      <title>点估计的均方误差</title>
      <link>https://stats.stackexchange.com/questions/638972/mean-squared-error-for-point-estimation</link>
      <description><![CDATA[在评估特定感兴趣参数的点估计器时，我试图理解均方误差。我们在课堂上阅读的书内容如下：
参数 $\theta$$W$ 的均方误差 (MSE) &gt; 是函数 $\theta$ 定义
$$
E_{\theta} (W-\theta)^2 = \text{Var}_{\theta}W + (E_{\theta} W - \theta)^2=\text{Var}_{\theta} W + (\text{偏差}_{\theta} W)^2
$$
我们将估计器的偏差定义如下：
$$\text{偏差}_{\theta} W = E_{\theta}W-\theta$$
偏置等于（在 $\theta$ 中）等于 $0$ 的估计器称为无偏且满足所有 $\theta$ 的 $E_{\theta}W=\theta$。&lt; /p&gt;
&lt;块引用&gt;
对于无偏估计量，我们有 $E_{\theta} (W-\theta)^2 = \text{Var}_{\theta}W$，因此如果估计量是无偏的，则其 MSE 等于其方差。

我很困惑为什么当估计器无偏时我们只留下估计器的方差。我认为这是由于我们计算估计量的样本可能存在变异性，但我不能 100% 确定这是否是正确的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/638972/mean-squared-error-for-point-estimation</guid>
      <pubDate>Fri, 09 Feb 2024 21:25:03 GMT</pubDate>
    </item>
    <item>
      <title>IRT 标称响应模型 theta</title>
      <link>https://stats.stackexchange.com/questions/638939/irt-nominal-response-model-theta</link>
      <description><![CDATA[我对多种IRT模型非常熟悉；但是，我似乎无法理解标称响应模型。 θ是如何估计的？例如，如果我们进行多项选择项的科学测试（“以下哪一项是动物？”A）椅子，B）猫，C）猫头鹰，D）向日葵），模型如何“ “知道”哪个答案体现了最伟大的知识？我是否必须将答案放在“逻辑”中？我自己排序（如 0 - 椅子、1 - 向日葵、2 - 猫头鹰、3 - 猫），因此类别越大，“越正确”。答案？或者我必须将密钥添加到模型中吗？
这很令人困惑，因为我到处都读到答案可以是无序的（这就是为什么它被称为名义上的）。但是，如果我不添加密钥或自己以逻辑方式重新排序答案，那么我真的无法理解能力/theta 是如何估计的。]]></description>
      <guid>https://stats.stackexchange.com/questions/638939/irt-nominal-response-model-theta</guid>
      <pubDate>Fri, 09 Feb 2024 13:30:49 GMT</pubDate>
    </item>
    <item>
      <title>在不会或不能重复的研究中计算置信区间的理由是什么？</title>
      <link>https://stats.stackexchange.com/questions/638934/what-is-the-rationale-for-computing-a-confidence-interval-in-a-study-that-wont</link>
      <description><![CDATA[据我了解，当我们计算置信区间（例如 $95$% CI）时，我们对程序有信心，而不是对当前的结果有信心。我们拥有的数据（作为 $95$% CI 意味着为许多其他计算的置信区间的 $95$%假设样本将包含总体中的真实值）。
因此仅凭我们收集的样本，无法知道我们看到的当前区间是否包含真实值，即使区间非常小。
所以我想知道：在一项不会或不能精确重复的研究中计算置信区间是否有（科学）原理？或者说在这种情况下计算 CI 是没有用的吗？我也非常感谢有关此特定主题的任何参考资料或论文。]]></description>
      <guid>https://stats.stackexchange.com/questions/638934/what-is-the-rationale-for-computing-a-confidence-interval-in-a-study-that-wont</guid>
      <pubDate>Fri, 09 Feb 2024 12:03:39 GMT</pubDate>
    </item>
    <item>
      <title>将线性模型的系数设置为混合效应模型的固定效应分量时的注意事项或注意事项</title>
      <link>https://stats.stackexchange.com/questions/638929/cautions-or-considerations-when-setting-coefficients-from-linear-model-into-the</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/638929/cautions-or-considerations-when-setting-coefficients-from-linear-model-into-the</guid>
      <pubDate>Fri, 09 Feb 2024 11:07:00 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯非线性回归中的双峰后验</title>
      <link>https://stats.stackexchange.com/questions/638912/bimodal-posteriors-in-bayesian-non-linear-regression</link>
      <description><![CDATA[我将在序言中感谢您阅读本文，并且任何评论者都应该随意批评您认为天真或无知的建模规范或工作流程的任何方面。
我正在模拟这个双 S 形曲线过程中的两个组：
$$ y = \frac{y_{\text{mid}}}{1 + e^{-(a \cdot \text{time} + b)}} + \frac{y_{\text{max}}}{1 + e^{-(c \cdot \text{时间} + d)}}, \quad 0 \leq y \leq 100, \quad \text{时间} \in [0, 300]
$$
在brms中使用以下代码：
sw_dbl_log &lt;- 函数（a、b、c、d、时间）{
  ((50)/(1+exp(-a*时间 + b)))+((50)/(1+exp(-c*时间 + d)))
}

神经网络 = 300
原始 &lt;- tibble(n = 1:(nn*2),
              组=rep(c(“对照”，“实验”)，每个=nn)，
              a = c(rnorm(nn, 0.1, 0.01),
                    rnorm(nn, 0.1, 0.01)),
              b = c(rnorm(nn, 5, 0.01),
                    rnorm(nn, 5, 0.01)),
              c = c(rnorm(nn, 0.1, 0.01),
                    rnorm(nn, 0.1, 0.002)),
              d = c(rnorm(nn, 5, 0.01),
                    rnorm(nn, 25, 0.01))
) %&gt;%
  tidyr::expand(嵌套(n,组,a,b,c,d),
                时间 = seq(0, 300, by = 10)) %&gt;%
  突变（y = sw_dbl_log（a，b，c，d，时间））

正如预期的那样，这会为每个组的参数 (a:d) 生成高斯分布，而对照组的时间序列类似于具有一个生长阶段的单个 sigmoid。正如预期的那样，实验组的时间序列有两个增长阶段。我利用这个规范是因为每个参数都给出了清晰可解释的输出，即 a 和 c 代表增长率，b 代表每个生长阶段的拐点时间点。

我的适配过程如下：
公式 &lt;- bf(y ~ (50/(1+exp(-a*Time + b))) + (50/(1+exp( -c*时间 + d))),
              a + b + c + d ~ 0 + 组,
              set_rescor(FALSE),
              nl = 真）

先验 1 &lt;- c(
  先验（正常（0.1，0.1），nlpar =“a”，lb = 0），
  先验（正常（5, 2），nlpar =“b”，lb = 0，ub = 10），
  先验（正常（0.1，0.1），nlpar =“c”，lb = 0），
  先验(正常(25, 5), nlpar = “d”, coef = “组实验”),
  先验（正常（5, 2），nlpar =“d”，coef =“GroupControl”）
）

拟合 &lt;-brm(公式,
           数据=原始数据，
           先验=先验1，
           控制=列表（adapt_delta = 0.95，max_treedepth = 15），
           迭代= 10000，
           热身= 5000，
           核心 = 3,
           链 = 3)

我在上面的代码中省略了之前的拟合和预测检查，但目视检查看起来不错。
我目前遇到的这个问题是模型拟合很差，即 Rhat 和 ESS 数字太低，这主要是由于任一组（有时是 Control）参数后验分布的双峰性有时是实验性的，这会导致链不收敛。因此，对于某些拟合，按组（例如“b_a_GroupExperimental”）的 a、b、c、d 的任何或所有后验分布将是双峰的。
我似乎无法定义为什么模型拟合不佳并导致这种双峰性。我的第一个猜测是先验导致了问题，但是，根据我天真的理解，先验是围绕原始模拟分布非常紧密地指定的，所以我不明白为什么它们可能会导致问题。我必须承认，这个结论可能会暴露我对这个主题的无知，这导致我无法解决适合问题。
我应该更改先验、模型、规定初始值还是只是运行更多迭代？任何帮助将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/638912/bimodal-posteriors-in-bayesian-non-linear-regression</guid>
      <pubDate>Fri, 09 Feb 2024 03:36:53 GMT</pubDate>
    </item>
    </channel>
</rss>