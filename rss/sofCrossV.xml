<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 14 Aug 2024 12:29:55 GMT</lastBuildDate>
    <item>
      <title>将 z 标准化数据缩放回原始数据范围（使用时间序列聚类）</title>
      <link>https://stats.stackexchange.com/questions/652780/scale-z-normalized-data-back-to-original-data-range-using-clustering-of-time-se</link>
      <description><![CDATA[我对 Python 的 tslearn 包中的信息有点困惑。
文档中说（例如 https://tslearn.readthedocs.io/en/stable/auto_examples/clustering/plot_kmeans.html）：

在此示例中，使用 TimeSeriesScalerMeanVariance 对时间序列进行预处理。此缩放器使得每个输出时间序列均值为零且方差为单位。这里的假设是，给定时间序列的范围不具信息量，人们只想以幅度不变的方式比较形状（当时间序列是多变量时，这也会重新调整所有模态，这样就不会有一个单一的模态负责大部分方差）。这意味着人们无法将重心缩放回数据范围，因为每个时间序列都是独立缩放的，因此不存在整体数据范围。

但是，如果我发现，例如，一个集群分配的时间序列最初具有非常相似的平均值和标准差（或者平均值和标准差遵循该组中的函数，即它们不同但与某些元数据相关，例如数据来自的活动的大小），那么重新缩放数据不是非常可能吗？
或者我遗漏了什么？
要重新缩放 z 标准化，请将数据点乘以标准差并添加平均值。其他类型的规范化也是如此，每个输入都是独立缩放的；否则，规范化不会产生任何影响，只会改变数据。
我并不是说你总能得到有意义的平均值或标准差的估计值，但“这根本不可能”的说法让我很困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/652780/scale-z-normalized-data-back-to-original-data-range-using-clustering-of-time-se</guid>
      <pubDate>Wed, 14 Aug 2024 12:04:57 GMT</pubDate>
    </item>
    <item>
      <title>是否有一种（标准）方法来组合贝叶斯因子？</title>
      <link>https://stats.stackexchange.com/questions/652778/is-there-a-standard-way-to-combine-the-bayes-factor</link>
      <description><![CDATA[我目前正在研究一个由大量单独（且独立）对象组成的超大数据集。我正在做的是将两个完全不同的模型拟合到数据集中的每个对象，而我的输出的一部分是贝叶斯证据。
为了进一步说明，我将我的第一个模型拟合到所有 100 个对象，并为每个对象获得 100 个贝叶斯证据。然后，我将不同的模型拟合到相同的 100 个对象，并再次为所有对象获得贝叶斯证据。我可以通过证据的比率计算贝叶斯因子来比较单个对象。但是，我试图了解总体而言，哪种模型在整个数据集上表现更好。是否有一种“标准”方法来完成此类任务，即结合贝叶斯因子来获得模型的整体最佳性能？
根据一些（简单的）阅读，此链接表示您可以乘以贝叶斯因子以获得组合研究模型性能结果https://www.pnas.org/doi/full/10.1073/pnas.2217331120#:~:text=Thus%2C%20the%20Bayes%20factor%20for,factors%20from%20the%20individual%20studies.
但是，除此之外，我还没有发现其他可以证实这种方法的东西。
任何见解都将不胜感激
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/652778/is-there-a-standard-way-to-combine-the-bayes-factor</guid>
      <pubDate>Wed, 14 Aug 2024 11:42:23 GMT</pubDate>
    </item>
    <item>
      <title>多臂老虎机问题中随机选择一个臂</title>
      <link>https://stats.stackexchange.com/questions/652777/random-selection-of-an-arm-in-the-multi-armed-bandits-problem</link>
      <description><![CDATA[我正在尝试了解简单的多臂老虎机问题的数学框架。我将按照我正在学习的讲义中所述重写该问题。
问题设置。
假设我们有一组动作$A = \{1, \ldots, K\}$;
代理在时间步$t$采取动作$a_t \in A$;
$r(a_t)$是代理从采取动作$a_t$中获得的奖励;
让$\mu_k = \mathbb{E}(​​r(k))$成为真正的平均奖励采取行动 $k$ 和 $\mu^* = \max\limits_{k}\mu_k$ 是 $k$ 台机器中的最佳平均奖励。
我们首先考虑最简单的策略，即每次随机选择一个臂。由于每个分支的选择概率为 $\dfrac{1}{K}$，因此任何时间 $t$ 的预期奖励可以计算为：
$$\mathbb{E}[r(a_t)] = \sum\limits_{k=1}^{K}\dfrac{1}{K}\mu_k = \dfrac{1}{K}\sum\limits_{k=1}^{K}\mu_k \quad (*)$$
我的问题。
据我了解，这个问题中有两个随机变量（两个随机变量序列）：$a_t$ 是一个随机变量，对应于在时间 $t$ 和一个随机变量 $r(a_t)$，它是采取行动 $a_t$ 的奖励。在这个特定的设置中，
$$\forall t \in \mathbb{N},~ a_t \sim \operatorname{Uniform}\{1,\ldots, K\} \iff \forall k \in \{1,\ldots,K\}, ~ \mathbb{P}(a_t = k) = \dfrac{1}{K}$$
起初，我试图找到 $\mathbb{E}[r(a_t)]$ 作为随机变量函数的期望：
$$\mathbb{E}[r(a_t)] = \sum\limits_{k = 1}^{K}r(k)\mathbb{P}(a_t = k) = \dfrac{1}{K}\sum\limits_{k = 1}^{K}r(k)$$
但这个方程与 $(*)$ 不同，所以我看不出它们怎么能等价。
对我来说，尝试使用总期望定律是合乎逻辑的：
$$\mathbb{E}(​​r(a_t)) = \sum\limits_{k=1}^{K}\mathbb{E}(​​r(a_t) \mid a_t = k)\mathbb{P}(a_t = k) = \dfrac{1}{K}\sum\limits_{k=1}^{K} \mathbb{E}(​​r(a_t) \mid a_t = k)$$
但我不明白我如何正式在此推导出$\mathbb{E}(​​r(a_t) \mid a_t = k) = \mathbb{E}(​​r(k))$与公式$(*).$一致
因此，似乎我在将这个问题转换为概率设置时遗漏了一些重要的东西，也许这些注释中没有明确说明一些假设。有人可以指出我的推理失败的地方吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652777/random-selection-of-an-arm-in-the-multi-armed-bandits-problem</guid>
      <pubDate>Wed, 14 Aug 2024 11:21:55 GMT</pubDate>
    </item>
    <item>
      <title>Aalen Johansen - 绝对风险和置信区间</title>
      <link>https://stats.stackexchange.com/questions/652776/aalen-johansen-absolute-risks-and-confidence-intervals</link>
      <description><![CDATA[如果存在竞争风险情况，可以使用 AJ 估计量来计算累积发生率函数 (CIF)。
在 R 中，使用 survfit{survival 和事件 0,1,2 来实现 AJ 非常简单。
在检查时间 20 的绝对风险时，R 还会计算置信区间 $lower 和 $upper，例如：



时间
cif
cif_lower
cif_upper




20
0.0175
0.0097
0.0314



因此，在时间 20 时，1.75% 的人遭遇了该事件 (CI 0.97% - 3.14%)
问题：

那是什么样的置信区间？
AJ 估计量是否需要特定的置信区间？
这个特定的置信区间使用匹配/加权后是否需要进一步调整？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652776/aalen-johansen-absolute-risks-and-confidence-intervals</guid>
      <pubDate>Wed, 14 Aug 2024 10:55:55 GMT</pubDate>
    </item>
    <item>
      <title>简单的 OLS 来测量相关性</title>
      <link>https://stats.stackexchange.com/questions/652774/simple-ols-to-measure-correlation</link>
      <description><![CDATA[我有两个变量，X 和 Y，我有充分的理由相信它们是同时确定的。
$$Y_{i} = a_{1i} + b_{1i}X_{i} + u_{1i}\tag{1}$$
$$X_{i} = a_{2i} + b_{2i}Y_{i} + u_{2i}\tag{2}$$
我的问题是：只要我远离任何因果关系，我是否仍可以使用简单的 OLS 研究变量之间的关系？
我有兴趣做出这种类型的陈述：“X 的单位增加与 Y 的预测值 b1 的变化相关”。我不想暗示任何有关因果关系方向的内容，我只想描述变量如何共同变动。在这种情况下，我承认明显的内生性，报告系数是否仍然具有误导性？
更新：数据纯粹是横截面数据]]></description>
      <guid>https://stats.stackexchange.com/questions/652774/simple-ols-to-measure-correlation</guid>
      <pubDate>Wed, 14 Aug 2024 10:25:27 GMT</pubDate>
    </item>
    <item>
      <title>成本效益分析中的蒙特卡罗模拟和詹森不等式：模拟的点估计与预期值</title>
      <link>https://stats.stackexchange.com/questions/652773/monte-carlo-simulations-and-jensen-s-inequality-in-cost-effectiveness-analysis</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652773/monte-carlo-simulations-and-jensen-s-inequality-in-cost-effectiveness-analysis</guid>
      <pubDate>Wed, 14 Aug 2024 10:15:29 GMT</pubDate>
    </item>
    <item>
      <title>如何解释泊松模型估计的离散度？</title>
      <link>https://stats.stackexchange.com/questions/652770/how-to-interpret-dispersion-estimated-for-a-poisson-model</link>
      <description><![CDATA[假设我有以下数据：$(N_i, x_i, \nu_i)$，其中 $i=1,\dots,n$。我很快从汽车保险定价中得到启发。$N_i$ 代表索赔数量，$x_i$ 是我知道的一些特征，$\nu_i$ 是一些曝光（=时间）。例如：在半年的时间里（即 $\nu_i = 0.5$），我观察到两起（即 $N_i = 2$）索赔，索赔人年龄为 35 岁，车龄为 1 年（即 $x_i = (35, 1)$，在这种情况下，我的特征包括驾驶员年龄和车龄）。
根据数据，我可以选择以下建模方法：
$$
N_i \overset{ind.}{\sim} \mathrm{Poisson}(\lambda(x_i)\nu_i),
$$
因此，索赔数量由独立的泊松随机变量建模，其中频率函数 $x_i \to \lambda (x_i)$ 需要建模。请注意，曝光不是由 $\lambda(.)$ 建模的，而只是包含在模型中。
此示例源自我正在阅读的一本书，即这。现在，人们可以为$\lambda(.)$选择不同的建模方法，如 GLM、神经网络等。
为了评估拟合优度，本书讨论了两种方法：首先，计算（样本内）Pearson 残差，公式为
$$
\hat \delta_i^P = \frac{N_i - \lambda(x_i)\nu_i}{\sqrt{\lambda(x_i)\nu_i}}。
$$
根据我的（泊松）建模假设，这些应该是独立的，大致以单位方差为中心。
其次，他们定义了泊松偏差残差，由以下公式给出
$$
\hat \delta_i^D = \mathrm{sgn}(N_i - \lambda(x_i)\nu_i) \sqrt{2N_i \left[\frac{\lambda(x_i)\nu_i}{N_i} - 1 - \log\left(\frac{\lambda(x_i)\nu_i}{N_i}\right)\right]}
$$
最后，作者为模型的离散度定义了两个估计量（这里$q+1$是特征的数量$x_i$):
$$
\hat \p​​hi^P = \frac1{n-(q+1)} \sum_{i=1}^n (\hat \delta_i^P)^2
$$
并且
$$
\hat \p​​hi^D = \frac1{n-(q+1)} \sum_{i=1}^n (\hat \delta_i^D)^2 = \frac{D^*(\mathbf{N}, \lambda(.))}{n-(q+1)},
$$
其中 $D^*(\mathbf{N}, \lambda(.))$ 是泊松偏差损失。
问题：我不太明白我们为什么要查看这些离散度估计量。据我了解，离散度告诉我，模型方差是否接近其均值（我知道在泊松模型中方差等于其均值）。$\hat \p​​hi^P$ 和 $\hat \p​​hi^D$ 的哪些值会支持我的泊松模型假设？特别是，为什么 $\hat \p​​hi^D$ 是查看此问题的一个好方法，我该如何解释其值以及哪些值会支持我的假设？
如您所见，我并不清楚为什么（尤其是 $\hat\delta^D$）值得关注。他们只是来告诉我我选择的泊松模型是好是坏吗？如果有更有经验的人能阐明我的想法，我会很高兴。
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652770/how-to-interpret-dispersion-estimated-for-a-poisson-model</guid>
      <pubDate>Wed, 14 Aug 2024 09:39:06 GMT</pubDate>
    </item>
    <item>
      <title>拟合GAM模型时如何区分分组效应和随机效应？</title>
      <link>https://stats.stackexchange.com/questions/652769/how-to-differentiate-the-grouping-effect-and-the-random-effect-when-fitting-gam</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652769/how-to-differentiate-the-grouping-effect-and-the-random-effect-when-fitting-gam</guid>
      <pubDate>Wed, 14 Aug 2024 08:32:16 GMT</pubDate>
    </item>
    <item>
      <title>在一个层内使用不同的激活函数？</title>
      <link>https://stats.stackexchange.com/questions/652768/using-a-different-activation-functions-within-a-layer</link>
      <description><![CDATA[作为一项实验，可以尝试在一个层中拥有 n 个不同的激活/神经元/单元。
一种是采用深度学习框架中的自动反向传播算法，因为它们在一个层中使用相同的激活。
一种简单（但效率低下）的方法是使用不同的激活函数将输入层连接到 n 个 1 个单元的层。
类似于此图：

将它们相加可以通过将激活作为单个激活相加来替代，而不需要两个层，但如果将结果连接起来，那将有所区别。
例如，可以有 -x 和 x。
这已经完成并测试过了吗？它对你来说看起来有潜在用处吗？还是一个合理的探索基础？（只是为了避免自己做的麻烦。）
其他地方的相关文章

https://community.deeplearning.ai/t/why-i-need-the-same-activation-function-in-a-layer-with-multiple-neurons/226930

https://stackoverflow.com/questions/51175117/how-to-implement-different-activation-functions-in-a-layer-of-a-neural-network-i

]]></description>
      <guid>https://stats.stackexchange.com/questions/652768/using-a-different-activation-functions-within-a-layer</guid>
      <pubDate>Wed, 14 Aug 2024 08:23:12 GMT</pubDate>
    </item>
    <item>
      <title>敏感度 - 为什么响应比设计有更多行</title>
      <link>https://stats.stackexchange.com/questions/652766/sensitivity-why-the-response-has-more-rows-compared-to-the-design</link>
      <description><![CDATA[我想使用 sensitivity::tell(x, y)，但所需的 y 比 x 长
我制作了一个 Sobol 设计 X，然后（在 R 之外）我执行了实验来获取 y。现在我有了设计和数据。查看此响应，似乎我应该使用sensitivity::tell，但y的长度没有意义。
示例代码如下
n &lt;- 1000
X1 &lt;- data.frame(matrix(runif(8 * n), nrow = n))
X2 &lt;- data.frame(matrix(runif(8 * n), nrow = n))

#Sensitivity 分析
x &lt;- sobol(model = NULL, X1, X2, nboot = 100)
y &lt;- ishigami.fun(x$X)
tell(x,y)
print(x)
plot(x)

它可以工作，但是 ishigami.fun(x$X) 给出的向量比输入设计长得多。如果设计长度为 2,000（X1 和 X2），响应怎么会是 9,000 个观测值？
如果我的设计有 2000 个实验行，响应应该同样长。
如何使用这些函数获得模型的敏感度？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652766/sensitivity-why-the-response-has-more-rows-compared-to-the-design</guid>
      <pubDate>Wed, 14 Aug 2024 07:49:15 GMT</pubDate>
    </item>
    <item>
      <title>McNemar 检验 1 个受试者与 3 个受试者需要多次测试校正吗？</title>
      <link>https://stats.stackexchange.com/questions/652765/mcnemar-test-1-subject-versus-3-subjects-need-multiple-testing-correction</link>
      <description><![CDATA[我向不同的人询问特定跑步者马拉松的持续时间。我想将 1 个人（人 A）的估计与另外 3 个人（人 B、C 和 D）的估计进行比较，如下所示：
我会问

人 A 跑步者是否需要：&lt;= 2 小时，&gt; 2 &lt;= 3 小时，&gt; 3 &lt;= 4 小时或 &gt; 4 小时

人 B 是否需要 &gt; 2 小时

人 C 是否需要 &gt; 3 小时

人 D 是否需要 &gt; 4 小时


由于涉及相同的跑步者，我想进行 McNemar 检验并比较 A 与 B、A 与 C 和 A 与 D。从 A 的 1 个估计中，我可以推断出 3 个估计。例如，如果 A 的估计是跑步将花费 &gt;3 &lt;= 4 小时。我可以说 A 对 &gt;2 小时说的是假的，对超过 3 小时说的是真的，对 &gt;4 小时说的是假的。这样，我可以针对 B、C 和 D 的估计值制作 3 个列联表。
我担心的是，如果我的研究问题是 A 的表现优于 B、C 和 D，
这些测试将需要进行多重检验校正，因为我对来自 A 的 1 个估计值进行了 3 次测试。
如果我的研究问题是 A 的表现是否优于 B、C 或 D，那么 McNemar 检验可能不需要进行多重检验校正。
我很想听听你对此的看法。]]></description>
      <guid>https://stats.stackexchange.com/questions/652765/mcnemar-test-1-subject-versus-3-subjects-need-multiple-testing-correction</guid>
      <pubDate>Wed, 14 Aug 2024 07:26:44 GMT</pubDate>
    </item>
    <item>
      <title>nlme 交叉随机效应和自回归协方差结构</title>
      <link>https://stats.stackexchange.com/questions/652764/nlme-crossed-random-effects-und-autoregressive-covariance-structure</link>
      <description><![CDATA[我想问您两个具体问题，关于一个模型，其中要考虑交叉随机效应和自回归协方差结构（AR1 --&gt;
因此使用包 nlme 而不是 lme4）。这是基于 16 周的饲养试验（2x2 因子设计），其中有 32 头奶牛，每头奶牛有 16 个测量点（每周测量间隔）。

如何在 nlme 中实现两个非嵌套随机效应（在 lme4 中：+ (1|animal) + (1|test_week)）？
o 因为 random = list(one1 = pdMat (~ animal - 1), one2 = pdMat (~experimental_week - 1))，其中 one1 和 one2 是“辅助”变量，为 1（对于每个观察值）？来源：r - 在 lmer 和 nlme:lme 中建模随机结构 - 交叉验证 (stackexchange.com)
o 否则：random = list(animal = pdMat (~1),experimental_week = pdMat (~1)) ?
o 否则？
o 由此必须选择正确的 pdMat 对象 (pdDiag、pdIdent 等)。

如何正确解释自回归协方差结构？
o Correlation = corAR1(0.99, form = ~ 1)
o 或 correlation = corAR1(form = ~experimental_week |animal)


目前我有这样的情况：
-&gt;首先建立对比：
contr2 &lt;- rbind( &quot;HeuvsSIL P1&quot; = c(-1,-1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,1,-1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
new_model_1 &lt;- lme(
fixed = ECM ~ Index,
random = list(Animal = pdDiag(~1), ExpWeek = pdDiag(~1)),
data = data1,
correlation = corAR1(form = ~ ExpWeek |Animal), na.action = na.omit)
summary(glht(new_model_1, linfct = mcp(Index = contr2), test = adapted(&quot;BH&quot;)))]]></description>
      <guid>https://stats.stackexchange.com/questions/652764/nlme-crossed-random-effects-und-autoregressive-covariance-structure</guid>
      <pubDate>Wed, 14 Aug 2024 06:23:18 GMT</pubDate>
    </item>
    <item>
      <title>添加控制变量后，豪斯曼检验 p 值跳转到 1？</title>
      <link>https://stats.stackexchange.com/questions/652763/hausman-test-p-value-jumps-to-1-after-adding-control-variable</link>
      <description><![CDATA[我想测试固定或随机效应模型是否更适合我的数据。我包括了所有不使 p 值跳跃的变量，估计两个模型，而豪斯曼检验给出了以下输出：
豪斯曼检验

数据：DV ~ IV + CV1 + CV2 + CV3 + CV4 + CV5 + ...
chisq = 62.595，df = 9，p 值 = 4.227e-10
备选假设：一个模型不一致

所以，非常重要，这意味着我应该使用固定效应模型
现在，如果我再添加一个（或多个）我已经确定为使 p 值跳跃到 1 的变量，则输出如下：
豪斯曼检验

数据：DV ~ IV + CV1 + CV2 + CV3 + CV4 + CV5 + ...
chisq = 0.23564，df = 10， p 值 = 1
备选假设：一个模型不一致

这些导致 p 值大幅跳变的变量中，有些在回归模型中非常重要，因此我无法直接排除它们。但我不知为何感觉我的模型有问题。p 值为 1 似乎很奇怪。或者它就是这样，并且包含这些变量后应该使用随机效应模型？
我期待您的回答！
为了估计模型，我使用以下代码，其中 CV10 是使 p 值跳转到 1 的变量：
fe_model&lt;-plm(DV ~ IV + CV1 + CV2 + CV3 + CV4 + CV5 + CV6 + CV7 + CV8
+ CV9 + factor(Industry) + CV10, data=sample, index = c(&quot;Company&quot;, &quot;Year&quot;), model=&quot;within&quot;, effect=&quot;twoways&quot;) 

re_model&lt;-plm(DV ~ IV + CV1 + CV2 + CV3 + CV4 + CV5 + CV6 + CV7 + CV8 
+ CV9 + 因子（行业）+ CV10，数据=样本，索引 = c（“公司”，“年份”），模型=“随机”，效果=“双向”，随机方法 =“walhus”）
]]></description>
      <guid>https://stats.stackexchange.com/questions/652763/hausman-test-p-value-jumps-to-1-after-adding-control-variable</guid>
      <pubDate>Wed, 14 Aug 2024 06:05:09 GMT</pubDate>
    </item>
    <item>
      <title>Johnson、Kotz 和 Balakrishnan 中的符号：$\beta_1$ 和 $\beta_2$</title>
      <link>https://stats.stackexchange.com/questions/652745/notation-in-johnson-kotz-and-balakrishnan-beta-1-and-beta-2</link>
      <description><![CDATA[我面前有一本由 Johnson、Kotz 和 Balakrishnan 编写的《连续单变量分布》第 1 卷第二版。第 19 页上写着：

Pearson 和 Hartley (1972) 中的表格给出了 $\sqrt{\beta_1}=0.0(0.1)2.0$ 和 $\beta_2$ 的 Pearson 系统分布的标准化分位数（百分位数），精确到小数点后四位，间隔为 $0.2.$

在那之前，我在这本书中找不到任何地方提到 $\beta_1$ 和 $\beta_2$ 是什么，但这本书在续集中严重依赖这种符号。
什么是我错过了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652745/notation-in-johnson-kotz-and-balakrishnan-beta-1-and-beta-2</guid>
      <pubDate>Tue, 13 Aug 2024 21:01:35 GMT</pubDate>
    </item>
    <item>
      <title>GARCH 模型（使用 rugarch R）的条件方差只是一条倾斜的线</title>
      <link>https://stats.stackexchange.com/questions/652739/conditional-variance-from-the-garch-model-using-rugarch-r-is-just-a-sloping-li</link>
      <description><![CDATA[我试图使用 R 中的 GARCH 模型估计 1970 年至 2022 年实际汇率 USD/MGA 的波动性。
我一直在使用此代码，但不确定哪部分是错误的，或者我错过了什么错误：
library(fpp2)
library(fpp3)
library(tidyverse)
library(ggplot2)
library(urca)
library(rugarch)
library(openxlsx)
library(tseries)

d = read.xlsx(&quot;GARCH.xlsx&quot;)

donnes = ts(d$Taux.de.change.réel, start = 1970, frequency = 1)
donnees = log(donnes)
plot(donnees)

adf.test(donnees)
ggtsdisplay(donnees)

vrai = diff(donnes)
adf.test(vrai)
ggtsdisplay(vrai)

ARIMA = auto.arima(donnees, d=1, stepwise = FALSE, approximation = FALSE, trace = TRUE)

garch_spec = ugarchspec(variance.model = list(model = &quot;sGARCH&quot;, garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0,0)),
distribution.model = &quot;norm&quot;)
fit &lt;- ugarchfit(spec = garch_spec, data = vrai)
fit
Volatilité = ts(fit@fit$sigma^2, frequency = 1, start = 1970)
图（波动性）

我得到了这个输出：
增强型 Dickey-Fuller 检验

数据：donnees
Dickey-Fuller = -1.4992，滞后阶数 = 3，p 值 = 0.776
备选假设：平稳

增强型 Dickey-Fuller 检验

数据：vrai
Dickey-Fuller = -3.9759，滞后阶数 = 3，p 值 = 0.01738
备选假设：平稳

系列：donnees 
ARIMA(0,1,0) 

sigma^2 = 0.01336：对数似然 = 38.42
AIC=-74.84 AICc=-74.76 BIC=-72.89

*---------------------------------*
* GARCH 模型拟合度 *
*---------------------------------*

条件方差动态
-----------------------------------
GARCH 模型：sGARCH(1,1)
均值模型：ARFIMA(0,0,0)
分布：范数

最优参数
------------------------------------
估计标准差。误差 t 值 Pr(&gt;|t|)
mu 16.828 3.3798e+01 0.497912 0.61855
omega 75.742 1.8822e+03 0.040242 0.96790
alpha1 0.000 7.7490e-03 0.000002 1.00000
beta1 0.999 2.5192e-02 39.655890 0.00000

稳健标准误差：
估计标准差。误差 t 值 Pr(&gt;|t|)
mu 16.828 2.7135e+01 0.620176 0.53514
omega 75.742 2.1577e+03 0.035103 0.97200
alpha1 0.000 9.6160e-03 0.000001 1.00000
beta1 0.999 4.3444e-02 22.994979 0.00000

对数似然：-359.5829 

信息标准
------------------------------------

Akaike 13.984
Bayes 14.134
Shibata 13.973
Hannan-Quinn 14.042

标准化残差的加权 Ljung-Box 检验
------------------------------------
统计 p 值
Lag[1] 0.9055 0.3413
Lag[2*(p+q)+(p+q)-1][2] 1.1155 0.4623
Lag[4*(p+q)+(p+q)-1][5] 1.2851 0.7925
d.o.f=0
H0：无序列相关

标准化平方残差的加权 Ljung-Box 检验
------------------------------------
统计 p 值
Lag[1] 0.003144 0.9553
Lag[2*(p+q)+(p+q)-1][5] 3.196283 0.3724
Lag[4*(p+q)+(p+q)-1][9] 5.055452 0.4213
d.o.f=2

加权 ARCH LM 检验
------------------------------------
统计形状尺度 P 值
ARCH Lag[3] 4.708 0.500 2.000 0.03002
ARCH Lag[5] 4.765 1.440 1.667 0.11641
ARCH Lag[7] 5.616 2.315 1.543 0.16921

Nyblom 稳定性检验
------------------------------------
联合统计：0.7215
个体统计：
mu 0.0724
omega 0.2989
alpha1 0.2336
beta1 0.2986

渐近临界值（10% 5% 1%）

联合统计量：1.07 1.24 1.6

个体统计量：0.35 0.47 0.75

符号偏差检验
------------------------------------
t 值 prob sig
符号偏差 1.2085 0.2329 
负符号偏差 0.5125 0.6107 
正符号偏差 0.1342 0.8938 
联合效应 5.0905 0.1653 

调整后的 Pearson 拟合优度检验：
------------------------------------
组统计量 p 值（g-1）
1 20 11.08 0.9212
2 30 25.31 0.6622
3 40 34.15 0.6904
4 50 40.31 0.8072

我得到了这个图表：

提前感谢您的帮助。
Tldr：我尝试了 rugarch，但条件方差根本没有反映数据的波动性，我不确定我做错了什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/652739/conditional-variance-from-the-garch-model-using-rugarch-r-is-just-a-sloping-li</guid>
      <pubDate>Tue, 13 Aug 2024 19:13:36 GMT</pubDate>
    </item>
    </channel>
</rss>