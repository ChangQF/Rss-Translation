<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 06 May 2024 15:14:46 GMT</lastBuildDate>
    <item>
      <title>在训练逻辑回归以预测未来结果时如何分割和采样“面板数据”</title>
      <link>https://stats.stackexchange.com/questions/646624/how-to-split-and-sample-panel-data-when-training-a-logistic-regression-to-pred</link>
      <description><![CDATA[简介
我有面板数据，可以观察一段时间内的客户行为。对于给定参考日期的每位客户，我有 12 个月的回顾窗口用于生成功能，以及 12 个月的展望窗口用于识别结果，例如取消订阅、默认或类似操作。

每个客户按月存在于我的数据集中，方式如下：

现在我想训练逻辑回归来预测二元结果，这就是我有很多问题的地方。我大多只能找到有关时间序列验证的博客和书籍，但找不到有关面板数据的博客和书籍。但以下是我的想法，我想提出意见。
拆分的最佳实践是什么？
我需要将数据集分成训练/有效/测试，其中训练/有效将用于训练逻辑回归和对抗模型（验证数据用于超参数调整和早期停止），以及测试数据将用于最终评估。
由于模型必须随着时间的推移以及新客户的表现而变化，我想做两种类型的“样本外”测试：验证：1）时间验证（过时）以确保其适用于未来未见的数据，2）“外部验证”，以便训练数据、验证数据和数据中不存在相同的客户测试数据。

什么是“最佳实践”？用于拆分面板数据？
大多数博客文章都提到做“不合时宜”的事情。验证，但没有人真正提到对训练数据中不存在的样本进行验证。最后一部分没有必要吗？
如何处理“串行相关性”？
在逻辑回归中，观察之间的独立性假设通常很重要。让同一客户在训练数据中多次出现（可能具有相关变量和结果）违反了这一假设，因为他们的每月观察并不真正独立。这可能会导致低估标准误差和过度自信的预测，因为该模型不会考虑受试者内的相关性。
什么是“最佳实践”？用于处理这些“序列相关性”？
我处理这个问题的一些想法：

数据中仅保留单个客户一次

一个潜在的问题是，我可能会丢失重要分段和二进制结果上的太多数据


使用聚集标准错误

对非独立观察结果（客户）进行聚类，并计算修正的标准误差以考虑客户内的相关性。


使用广义估计方程 (GEE)

我对这些不太熟悉，但他们应该能够根据数据中的相关结构调整模型指标



您将如何验证模型的时间方面？
我希望模型能够随着时间的推移尽可能保持高性能，但它需要在为测试留出多少时间方面进行权衡。已经充分证明，“最近的过去”已经过去了。比“遥远的过去”更好地预测未来。但我正在考虑这样的事情，我在 2 年的评估期内每月单独评估模型，有或没有校准（将预测率调整为过去一年的观察率）。
整个“校准”的原因是步骤是我们期望模型的排名性能随着时间的推移而保持一致，而总体结果率预计会随着时间的推移而变化。
什么是“最佳实践”？获得最“值得信赖”的随着时间的推移有效的评估指标？

您还有其他很酷的提示和技巧吗？
这里可能缺少很多东西，所以请随时提供其他建议和最佳实践。]]></description>
      <guid>https://stats.stackexchange.com/questions/646624/how-to-split-and-sample-panel-data-when-training-a-logistic-regression-to-pred</guid>
      <pubDate>Mon, 06 May 2024 15:13:32 GMT</pubDate>
    </item>
    <item>
      <title>使用连续输入和分类结果拟合“bnlearn”模型时出错</title>
      <link>https://stats.stackexchange.com/questions/646621/error-when-fitting-bnlearn-model-with-continuous-inputs-and-categorical-outcom</link>
      <description><![CDATA[我有一个关于 bnlearn 中变量类型的基本问题。我在看
拟合贝叶斯网络模型，其中预测变量（或至少
其中一些）是连续的，而结果是分类的
（是/否，即二进制）。
首先，我创建了一个非常小的模型 net，其中 A 和 B 是
预测变量，C 是结果，如下所示：
库(bnlearn)

net = model2network(“[A][B][C|A:B]”)
情节（净）


现在，当使用输入数据 dat 时，其中 A 和 B 是连续的，而
C 是分类的：
dat = data.frame(
    A = r范数(10),
    B = r范数(10),
    C = 因子(样本(c(&#39;否&#39;, &#39;是&#39;), 10, 替换 = TRUE))
）
数据

&lt;前&gt;&lt;代码&gt;## A B C
## 1 1.4409734 -0.7174069 无
## 2 -2.2561945 0.6199236 无
## 3 -0.0788327 1.1691368 无
## 4 -0.1327248 -0.8090412 是
## 5 0.2824567 -0.8949076 无
## 6 -0.2571486 1.2250626 无
## 7 -0.7173780 -0.4481589 是
## 8 1.9991288 0.4964841 无
## 9 2.0103807 -0.4971404 是
## 10 -2.6614089 0.7371227 无

尝试拟合模型会引发错误：
fit = bn.fit(x = net, data = dat)

## check.arcs.against.asclusions(x$arcs, data, method) 中的错误：arc A -&gt; C 违反了模型的假设。

作为参考，我还尝试使用数据拟合模型，其中 A, B,
和C都是分类，效果很好：
dat = data.frame(
    A = 因子(样本(c(&#39;否&#39;, &#39;是&#39;), 10, 替换 = TRUE)),
    B = 因子(样本(c(&#39;否&#39;, &#39;是&#39;), 10, 替换 = TRUE)),
    C = 因子(样本(c(&#39;否&#39;, &#39;是&#39;), 10, 替换 = TRUE))
）
fit = bn.fit(x = net, 数据 = dat)
预测（拟合，节点=“C”，dat）

## [1] 是 否 是 否 否 是 否 是
## 级别： 否 是

然后我还尝试使用数据来拟合模型，其中 A、B 和 C
都是连续的，这也可以正常工作：
dat = data.frame(
    A = r范数(10),
    B = r范数(10),
    C = r范数(10)
）
fit = bn.fit(x = net, 数据 = dat)
预测（拟合，节点=“C”，dat）

&lt;前&gt;&lt;代码&gt;## [1] 1.1804221 0.7789704 0.8053814 0.1266163 0.7005048 0.8392106 0.4928314
## [8] 0.8563145 0.2687796 1.3578046

我也是偶然发现这个论坛的
发布
似乎提到了同样的问题，但没有提供任何解决方案。
所以我的问题是：

有没有办法将模型拟合为
上面的第一个st示例，其中 A 和 B 是连续的，而 C
是绝对的吗？
如果是这样，怎么做？
如果没有，我很乐意
了解原因，以及是否可以使用另一种技术/包
适合这样的模型。

非常感谢任何帮助！
会话信息：
sessionInfo()

## R 版本 4.4.0 (2024-04-24)
## 平台：x86_64-pc-linux-gnu
## 运行环境：Ubuntu 22.04.4 LTS
##
## 矩阵产品：默认
## BLAS：/usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0
## LAPACK：/usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0
##
## 语言环境：
## [1] LC_CTYPE=en_IL LC_NUMERIC=C
## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_IL
## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_IL
## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C
## [9] LC_ADDRESS=C LC_电话=C
## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
##
## 时区：亚洲/耶路撒冷
## tzcode 来源：系统（glibc）
##
## 附加基础包：
## [1] 统计图形 grDevices utils 数据集 方法 基础
##
## 其他附加包：
## [1]bnlearn_4.9.3
##
## 通过命名空间加载（且未附加）：
## [1] 编译器_4.4.0 fastmap_1.1.1 cli_3.6.2 并行_4.4.0
## [5]tools_4.4.0 htmltools_0.5.8.1 yaml_2.3.8 rmarkdown_2.26
## [9] highr_0.10 knit_1.46 xfun_0.43digest_0.6.35
## [13] rlang_1.1.3 评估_0.23
]]></description>
      <guid>https://stats.stackexchange.com/questions/646621/error-when-fitting-bnlearn-model-with-continuous-inputs-and-categorical-outcom</guid>
      <pubDate>Mon, 06 May 2024 14:33:08 GMT</pubDate>
    </item>
    <item>
      <title>确定 $H_0$ 或 $H_1$ 是否成立所需的方差？</title>
      <link>https://stats.stackexchange.com/questions/646619/variance-needed-to-determine-whether-h-0-or-h-1-holds</link>
      <description><![CDATA[给出实验室 12 次脑部扫描持续时间的样本：
X = {22, 19, 20, 17, 19, 25, 23, 20, 25, 27, 19, 22}
我可以测试平均扫描时间是否小于 20 分钟，且显着性水平为 $\alpha = 0.05$。为此，我需要（但可以轻松计算）方差。
在不知道方差的情况下是否可以进行相同的分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/646619/variance-needed-to-determine-whether-h-0-or-h-1-holds</guid>
      <pubDate>Mon, 06 May 2024 13:50:29 GMT</pubDate>
    </item>
    <item>
      <title>确定样本大小的中心极限定理</title>
      <link>https://stats.stackexchange.com/questions/646617/central-limit-theorem-to-determine-sample-size</link>
      <description><![CDATA[给定一个示例 $X_1, ..., X_n \sim^{iid} $ Bern(p)。我想测试 $H_0: p = 0.49$ 与 $H_1: p = 0.51$。&lt; /p&gt;
如何确定 I 类错误（和 II 类错误）概率等于 0.02 的样本量？
我尝试使用中心极限定理，但到目前为止没有成功。谁能帮帮我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646617/central-limit-theorem-to-determine-sample-size</guid>
      <pubDate>Mon, 06 May 2024 13:04:55 GMT</pubDate>
    </item>
    <item>
      <title>从简单的合成模型进行一致的特征重要性估计</title>
      <link>https://stats.stackexchange.com/questions/646616/consistent-feature-importance-estimation-from-a-simple-sintetic-model</link>
      <description><![CDATA[我有一个简单的数据生成模型，其中 $x_{[1,2,3,5,6]}$ 是 $\sim U(0,10)$ 和 $x_4 = 2x_1*\gamma + 10$ 其中 $\gamma \sim U(0.8,1.2)$
$y$ 生成为 $y=10*x_1-x_2-0.1*x_3*x_1$，即 $x_1$ 应该具有最大的重要性，$x_2$ 具有较小的重要性，$x_3$ 与 $x_1$、 交互相关的重要性$x_4$ 与 $x_1$ 相关，但其本身并不影响 $y$ 和 $x_5, x_6$ 在 y 根本没有贡献。
我发现检索变量“重要性”是很困难的。这个例子的实现是极其困难的。我本希望按照重要性递增的顺序检索类似 [$x_6, x_5, x_4, x_3, x_2, x_1$] 的内容，但我尝试了我个人的解决方案基于平均准确率下降和 Sobol 总指数的计算（打乱列并忽略预测中的列），我得到了非常不一致的结果，其中通常 $x_5$ 或$x_6$ 被视为重要。
然后我尝试了其他人的方法（Shapley值），但我仍然遇到同样的问题（Julia中的两种实现都是在此论坛帖子中）。
所以我看得更广泛，但我发现的所有例子都取自一些玩具数据集，并最终得到了“重要性”指标，但不能保证算法返回的指标确实是“正确的”。
我的例子是不是特别“难”？ ？是否有任何从合成数据生成中给出的、可复制且稳健的特征重要性算法的示例？]]></description>
      <guid>https://stats.stackexchange.com/questions/646616/consistent-feature-importance-estimation-from-a-simple-sintetic-model</guid>
      <pubDate>Mon, 06 May 2024 13:01:54 GMT</pubDate>
    </item>
    <item>
      <title>当不使用样本数据而是使用整个总体的数据时，置信区间的含义是什么？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/646615/what-is-the-meaning-of-confidence-intervals-when-not-using-sample-data-and-inste</link>
      <description><![CDATA[我试图理解，当您的数据不是来自样本，而您拥有整个人口的数据时，为什么需要置信区间或计算统计检验（用于比较比例）。
我的例子。
2014 年，重症监护病房有 100 人死亡。其中 40 人在死前表示他们希望在死后捐献器官。因此，持积极态度的死者比例为 40%。其余 60% 要么持消极态度，要么在死前未表明意愿。2015 年，重症监护病房有 120 人死亡。其中 60 人在死前表示他们希望在死后捐献器官。因此，2015 年持积极态度的死者比例为 50%。其余 50% 的人要么持否定态度，要么在去世前没有表明意愿。
现在回答我的问题。
我们知道，2014 年至 2015 年间，这一比例已从 40% 增加到 50%。我们真的需要围绕这两个比例构建置信区间，以确保这一增长是显著的吗？或者我们真的需要进行统计测试（建议的测试？）以确保百分比确实增加了？
我听说，在处理人口数据时，您可能希望构建置信区间，然后置信区间控制“自然变异”。
此外，如果有人有关于这个主题的一些文献，我将非常感激一些链接。]]></description>
      <guid>https://stats.stackexchange.com/questions/646615/what-is-the-meaning-of-confidence-intervals-when-not-using-sample-data-and-inste</guid>
      <pubDate>Mon, 06 May 2024 12:49:14 GMT</pubDate>
    </item>
    <item>
      <title>当我们在没有 prefit 的情况下使用 CaliberatedClassifierCV 时，幕后发生了什么？</title>
      <link>https://stats.stackexchange.com/questions/646614/what-is-happening-behind-the-scenes-when-we-use-calibratedclassifiercv-without-p</link>
      <description><![CDATA[根据我通过阅读sklearn概率校准的理解，当我们运行时在 CalibatedClassifierCV 中，我们将拟合“一个回归器（称为校准器），它将分类器的输出（由 Decision_function 或 Predict_proba 给出）映射到 [0, 1] 中的校准概率”。然而，它提到我们可以使用 prefit 或不使用 prefit，我们可以使用 ensemble 或不使用 ensemble，但这两个参数对我来说都不清楚。
当我们使用 cv=prefit 时，我们会将数据分为训练集、测试集和校准集，然后使用训练集拟合模型，使用校准集进行校准，然后将校准后的模型与测试集一起使用？当我们不使用cv=prefit时，我们只使用训练和测试？用于拟合模型的相同训练集也用于校准？
那么 ensemble = True 呢？这个参数我完全不清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/646614/what-is-happening-behind-the-scenes-when-we-use-calibratedclassifiercv-without-p</guid>
      <pubDate>Mon, 06 May 2024 12:37:59 GMT</pubDate>
    </item>
    <item>
      <title>计算正态分布的平均值和标准差[重复]</title>
      <link>https://stats.stackexchange.com/questions/646613/calculating-the-mean-and-standard-deviation-from-a-normal-distribution</link>
      <description><![CDATA[我对求正态分布的平均值和标准差的方法很感兴趣。它受到以下问题的启发，该问题属于英国 A 级数学课程的一部分。

随机变量 $X \sim N(\mu, \sigma^2)$。已知 $P(X&gt;35)=0.025$ 和 $P(X&lt;15)=0.1469$，求出 $\mu$ 和 $\sigma$ 的值。

这可以使用关系 $Z= \frac{X - \mu}{\sigma}$ 来求解，从而得到两个联立方程。需要明确的是，我有信心使用 Z 值来解决这个问题：
$1.9599=\frac{35-\mu}{\sigma}$ 和 $-1.0499=\frac{15-\mu}{\sigma}$
我对推广此方法有两个问题：

如果给出了两个以上的概率，如何确定 $\mu$ 和 $\sigma$ 的“最佳”值？问题在于可以成对求解联立方程以得到不同的解。

此方法是否用于统计学中估计正态分布的平均值和标准差。天真地，我期望$\mu$和$\sigma$可以通过数据样本的平均值和标准差来估计。

]]></description>
      <guid>https://stats.stackexchange.com/questions/646613/calculating-the-mean-and-standard-deviation-from-a-normal-distribution</guid>
      <pubDate>Mon, 06 May 2024 11:25:08 GMT</pubDate>
    </item>
    <item>
      <title>我的训练/验证数据准确率达到 99-100%，但在全新数据上表现不佳</title>
      <link>https://stats.stackexchange.com/questions/646611/getting-99-100-accuracy-on-my-training-validation-data-but-performs-bad-on-comp</link>
      <description><![CDATA[我有一个大型 ASL（美国手语）数据集。我将这些数据分成 70:15:15 进行训练、验证和测试。
然后我在其上训练了一个 CNN 模型，其中我使用 70% 进行训练，并在 15% 的验证集上进行评估。经过几个轮次后，我能够在训练/验证数据上实现 100% 的准确率。然后我在剩余的“未见”测试数据上运行这个训练模型，它也实现了 99% 的准确率，我认为这很好。
但是，我随后从第三方来源获得了更多的 ASL 数据，这些数据是更多的“未见数据”，我只实现了大约 40% 的准确率。看起来我的模型在这个原始数据源上过度拟合（数据集有大约 87000 张图像），而且我很确定我没有将测试集泄露到模型的训练中。
首先，还有其他解释吗？其次，我有什么方法可以改进我当前的模型吗？我最初的想法是将这些第三方数据与我的原始数据混合在一起，但数据集仍然会不平衡吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646611/getting-99-100-accuracy-on-my-training-validation-data-but-performs-bad-on-comp</guid>
      <pubDate>Mon, 06 May 2024 10:59:38 GMT</pubDate>
    </item>
    <item>
      <title>乘以外生变量会减少内生性吗？</title>
      <link>https://stats.stackexchange.com/questions/646610/does-multiplying-an-exogenous-variable-reduce-endogeneity</link>
      <description><![CDATA[设$X$为内生变量，$Y$为非负外生变量，和 $e$ 错误项。将 $\operatorname{cov}(.,.)$ 定义为协方差。然后， $\operatorname{cov}(X,e) \neq 0$ 和 $\operatorname{cov}(Y ,e) = 0$。定义 $Z = XY$。
那么，如何评估$\operatorname{cov}(Z,e)$？它是否大于 $\operatorname{cov}(X,e)$？
如果我理解正确，假设多元正态性并遵循 Bohrnstedt &amp; Goldberger (1969) - 方程 (12)，我们有：
$\operatorname{cov}(Z,e)$ = $\operatorname{E}(Y)$  $\cdot$ $\operatorname{cov}(X,e)$
这里，作为 $Y$ 的非负数 $E(Y) \geq 0$。因此，在这种特定情况下，乘以外生变量不会减少内生性，除非 $E(Y) = 0$。它是否正确？这对我来说似乎违反直觉，因为我们期望与 $\operatorname{cov}(Z,e)$ “数学容器”&gt;$\operatorname{cov}(X,e)$。
参考文献：Bohrnstedt、George W. 和 Arthur S. Goldberger。 “关于随机变量乘积的精确协方差。”美国统计协会杂志，卷。 64，没有。 328，1969 年，第 1439-42 页。 JSTOR，https://doi.org/10.2307/2286081。]]></description>
      <guid>https://stats.stackexchange.com/questions/646610/does-multiplying-an-exogenous-variable-reduce-endogeneity</guid>
      <pubDate>Mon, 06 May 2024 10:43:16 GMT</pubDate>
    </item>
    <item>
      <title>解决面板数据分析中的比例偏差</title>
      <link>https://stats.stackexchange.com/questions/646607/addressing-scaling-bias-in-panel-data-analysis</link>
      <description><![CDATA[我正在运行（不平衡）面板数据分析，其中因变量是农业公司 $i$ 在 $t$ 时期的 $fixed\ cost\ (per\ ha)$。解释变量是每公顷作物的种植面积，包括作物 A、作物 B 和作物 C。
$fixed\ cost\ (per\ ha)_{it} = hect\ crop\ A_{it} + hect\ crop\ B_{it} + hect\ crop\ C_{it}$
因变量以每公顷表示，因为它具有首选解释。但是，我怀疑当农作物也以公顷表示时会出现问题。
农作物$A、B$和$C$的系数（显示在其他条件不变的情况下该农作物增加 1 公顷的影响）会衡量$A$、$B$、$C$的增加对除以该额外公顷的因变量的影响吗？
如果是这样，那将导致问题，因为它可能会在农作物公顷和成本之间产生负相关关系，因为它显示了分母增加一公顷时的影响。
真正令人感兴趣的是农作物 A 增加 1 公顷，转换为另一种作物，保持总公顷数不变。
我如何指定我的模型来反映这一点？
应该是这样的：
$fixed\ cost\ (per\ ha)_{it} = (hect\ crop\ A\ \div tot\ hect)_{it} + (hect\ crop\ B\ \div tot\ hect)_{it} + (hect\ crop\ C\ \div tot\ hect)_{it}$
我改用作物和总公顷数的百分比，甚至：
$fixed\ cost_{it} = (hect\ crop\ A\ \div tot\ hect)_{it} + (hect\ crop\ B\ \div tot\ hect)_{it} + (hect\ crop\ C\ \div tot\ hect)_{it}$
不过我还假设，当我使用比率时，我不能同时使用这三个比率？因为它们加起来会是 100%。
任何见解都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/646607/addressing-scaling-bias-in-panel-data-analysis</guid>
      <pubDate>Mon, 06 May 2024 09:56:54 GMT</pubDate>
    </item>
    <item>
      <title>密度函数之和</title>
      <link>https://stats.stackexchange.com/questions/646594/sum-of-density-functions</link>
      <description><![CDATA[考虑四个 pdf $f_1(x), \ldots, f_4(x)$。对于任何 $x$，$f_1(x) \neq \cdots \neq f_4(x)$ 。
我们能否证明对于某些 $f_1(x) + f_2(x) \neq f_3(x) + f_4(x)$ &quot;&gt;$x$？]]></description>
      <guid>https://stats.stackexchange.com/questions/646594/sum-of-density-functions</guid>
      <pubDate>Mon, 06 May 2024 06:10:37 GMT</pubDate>
    </item>
    <item>
      <title>对于包含李克特量表项目的模型应使用哪种技术？</title>
      <link>https://stats.stackexchange.com/questions/646591/which-technique-to-use-for-models-that-include-likert-scale-items</link>
      <description><![CDATA[我有三个或更多自变量（使用李克特量表）和 GWA 作为因变量，以了解哪些变量影响学生遵守学校的成绩保留政策。多元回归适用于此吗？另外，我还有哪些其他测试选项？]]></description>
      <guid>https://stats.stackexchange.com/questions/646591/which-technique-to-use-for-models-that-include-likert-scale-items</guid>
      <pubDate>Mon, 06 May 2024 03:34:16 GMT</pubDate>
    </item>
    <item>
      <title>自举置信区间高估了均值差异的方差</title>
      <link>https://stats.stackexchange.com/questions/646569/bootstrapped-confidence-interval-overestimates-variance-in-difference-of-means</link>
      <description><![CDATA[我正在尝试将 Welch T 检验转化为引导抽样方案。然而，我发现自举 95% 置信区间比 Welch T 检验大得多。也许这只是引导 CI 的一个已知属性？
综合数据、不同的平均值、方差和大小。
A = np.random.normal(loc=10，scale=2，size=90)
B = np.random.normal(loc=8，比例=1.5，大小=100)

韦尔奇 T 检验
导入 scipy.stats 作为统计数据
测试 = stats.ttest_ind(A, B, equal_var = False)
测试.confidence_interval(confidence_level=0.95)
&gt;&gt;&gt;&gt;&gt;
置信区间（低=1.5130925732256637，高=2.503357120571464）

然后是引导方案
def bootstrap_ci(A, B, size=30, itrs=100):
  delta_arr = []
  对于范围内的 itr(itr)：
    a_mu = np.mean(np.random.choice(a=A, 替换=True, 大小=大小))
    b_mu = np.mean(np.random.choice(a=B, 替换=True, 大小=大小))
    d = a_mu - b_mu
    delta_arr.append(d)

  d_mu = np.mean(delta_arr)
  d_std = np.std(delta_arr)
  
  返回（d_mu - 1.96*d_std，d_mu + 1.96*d_std）

引导 CI 调用和结果
bootstrap_ci（A，B，大小= 30，itrs = 500）
&gt;&gt;&gt;&gt;&gt;
（1.1214979199515835、2.862487579486028）

因此，Bootstrap 估计似乎没有偏高或偏低，但标准差被高估了。作为参考，我之前手动实现了样本标准差函数（分母为 $n-1$），但这显然进一步增加了方差。
以下问题纯粹是出于好奇，没有多大实际意义

Bootstrap 方法是否会高估方差？
是否有一些引导 CI 计算指南？例如，样本量 (30) 和迭代次数 (500) 可能太小。
我认为我没有错误地计算出标准误差平均值。我不认为 $\frac{s}{\sqrt{n-1}}$ 是必要的，因为 delta_arr 已经在A、B 均值之差项。不是原始群体，A 或 B。但是这个结论准确吗？

谢谢！
编辑：
鉴于 Christian Hennig 的评论，我通过以下方式修改了引导 CI：1/ 使用完整样本并进​​行替换，2/ 假设中心为 $\mu_A - \ mu_B$ 以避免将随机误差纳入评估，并使用 3/ 百分位数（第 2.25 个和第 97.5 个）来避免正态性假设。
def bootstrap_ci(A, B, 置信度=0.95, itrs=1000):
  alpha = 1.0 - 置信度
  lb_idx = int(alpha/2.0 * itrs)
  ub_idx = int((1.0 - alpha/2.0) * itrs)

  delta_arr = []
  对于范围内的 itr(itr)：
    a_mu = np.mean(np.random.choice(a=A, 替换=True, 大小=A.size))
    b_mu = np.mean(np.random.choice(a=B, 替换=True, 大小=B.size))
    d = a_mu - b_mu
    delta_arr.append(d)

  sort_arr = 排序(delta_arr)
  lb = sort_arr[lb_idx]
  ub = sort_arr[ub_idx]
  
  返回（磅，UB）

结果更接近事实
&lt;前&gt;&lt;代码&gt;bootstrap_ci(A,B)
&gt;&gt;&gt;&gt;&gt;
（1.526411681562184、2.5033789920789973）
]]></description>
      <guid>https://stats.stackexchange.com/questions/646569/bootstrapped-confidence-interval-overestimates-variance-in-difference-of-means</guid>
      <pubDate>Sun, 05 May 2024 19:52:05 GMT</pubDate>
    </item>
    <item>
      <title>两张 2x2 的表格是否来自同一人群？</title>
      <link>https://stats.stackexchange.com/questions/646550/were-two-2x2-tables-drawn-from-the-same-population</link>
      <description><![CDATA[如何检验两个 2x2 表（频率）来自同一群体的零假设？
更具体地说，我有两个样本大小不等的 2x2 样本。我想检验这两个样本来自同一人群的假设。我对样本大小不感兴趣。
下表相当详细地说明了我的数据。这两个样本由一年内在两个设施中出现的病例组成。我认为这两个 2x2 表是两个设施地理区域的无偏样本。我预计在不久的将来不会收到更多数据。
我只对比较两个样本的存活率感兴趣。
]]></description>
      <guid>https://stats.stackexchange.com/questions/646550/were-two-2x2-tables-drawn-from-the-same-population</guid>
      <pubDate>Sun, 05 May 2024 14:47:17 GMT</pubDate>
    </item>
    </channel>
</rss>