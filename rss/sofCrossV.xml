<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 28 Oct 2024 15:18:53 GMT</lastBuildDate>
    <item>
      <title>如何确定样本中某个混淆元素是否仍然属于同一个总体（由样本和用于价值计算的样本定义）？</title>
      <link>https://stats.stackexchange.com/questions/656418/how-to-determine-if-an-obfuscated-element-of-the-sample-is-still-in-the-same-pop</link>
      <description><![CDATA[我想确定新值 X 属于我的总体的概率。问题是我不仅使用样本来定义我的总体，而且我的值也是利用样本创建的。
更具体地说：我有一个由大约 400 个类似程序组成的样本。我想将我的总体定义为所有与这 400 个程序执行类似操作的程序。
我可以通过度量来计算两个程序之间的相似性得分。因此，对于我的样本（大小为 N）中的任何程序 p_i，我都可以计算 N-1 个分数，然后进一步计算这些分数的均值 m_i 的 N-1 倍。
现在我想知道给定的程序（实际上是从样本中的一个程序派生出来的）是否属于我的总体（如果它仍然接近其他程序）。所以我认为我需要一个假设检验作为其中的一部分。
或者，我也愿意接受这样的想法，即只衡量某些程序与我的总体/样本的差异。
现在我的想法是计算所有 N 个均值 (m_i´s) 并将它们视为分布的随机变量。 （我不确定它们是否服从正态分布，但不知何故，我认为我可以说它们是服从正态分布的，这要归功于中心极限定理的魔力，而且我的样本量大于 30。1. 这是真的吗？）
然后我可以计算新混淆程序与样本中所有其他程序之间的 N（2. 不是 N-1，这会是个问题吗？）分数。
我认为我现在可以计算 z 分数，作为输入程序与我的分布相差多远的度量（它仍然是相同分布的可能性有多大），但该程序不是我的样本的一部分，所以我不知道这是否有效。
那么 3. 这种方法有效吗？ 和 4. 有没有更好/有效的方法？。
此外，只有在可能的情况下，我才需要论证我的方法是有效的，所以如果你能提供任何答案的来源，那将为我提供很大的帮助。
注意：这不是我尝试的第一件事，我查阅了各种文献和 ChatGPT。我阅读了关于学生化、置信区间、有限总体和 Bootstrap 抽样的内容。然而，我非常不确定这些方法是否适用，因为不幸的是，我的问题显然根本不是“教科书”。
非常感谢您花时间阅读这篇文章，我将不胜感激您提供的任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/656418/how-to-determine-if-an-obfuscated-element-of-the-sample-is-still-in-the-same-pop</guid>
      <pubDate>Mon, 28 Oct 2024 15:15:44 GMT</pubDate>
    </item>
    <item>
      <title>两个输出的指标和损失问题[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656415/metrics-and-loss-problem-for-two-output</link>
      <description><![CDATA[我的自定义损失和指标出现了问题。我的目的是用图像训练一个 CNN 模型，并使用图像中物体的角度方向的切线，我有一列表示切线是正还是负。最后我有两个输出，一个是切线（回归），另一个是（分类）。现在当我写 model.evaluate 时，我把回归写为第一个出现的东西，但它并没有作为第一个出现。我不确定它们是否以某种方式被反转了。因为我无法找到我得到的奇怪结果的解释。这是我的代码：
 # 自定义损失和度量函数
@keras.utils.register_keras_serializable(package=&quot;Custom&quot;)

def angular_loss(y_true, y_pred):
angles_true = tf.math.atan(y_true) * 180.0 / np.pi
angles_pred = tf.math.atan(y_pred) * 180.0 / np.pi
return tf.abs(angles_true - angles_pred)

@keras.utils.register_keras_serializable(package=&quot;Custom&quot;)
def rmse_degrees(y_true, y_pred):
a = tf.constant(np.pi)
angles_true = tf.math.atan(y_true) * 180.0 / a
angles_pred = tf.math.atan(y_pred) * 180.0 / a
b = tf.square(angles_true - angles_pred)
return tf.reduce_mean(b)
# 定义模型
input_image = Input(shape=X_train_images.shape[1:], name=&#39;input_image&#39;)
x = layer.Conv2D(32, (3, 3),activation=&#39;relu&#39;)(input_image)
x = layer.MaxPooling2D((2, 2))(x)
x = layer.Dropout(0.3)(x)
x = layer.Conv2D(64, (3, 3),activation=&#39;relu&#39;)(x)
x = layer.MaxPooling2D((2, 2))(x)
x = layer.Dropout(0.3)(x)
x = layer.Flatten()(x)
x = layer.Dense(128,activation=&#39;relu&#39;)(x) # 中间密集层
x = layer.Dropout(0.3)(x)

output_regression = layer.Dense(1,activation=&#39;linear&#39;,name=&#39;reg_output&#39;)(x)
output_classification = layer.Dense(1,activation=&#39;sigmoid&#39;,name=&#39;cls_output&#39;)(x)
model = keras.Model(inputs=input_image,outputs=[output_regression,output_classification])
model.summary()
model.save(&quot;modelfinal3.keras&quot;)
# 编译模型

model.compile(
optimizer = RMSprop(learning_rate=0.0001),
loss={
&#39;reg_output&#39;: angular_loss,
&#39;cls_output&#39;: &#39;binary_crossentropy&#39;
},
metrics={
&#39;reg_output&#39;: [rmse_degrees],
&#39;cls_output&#39;: [&#39;accuracy&#39;]
}
)

# 定义 ModelCheckpoint 回调以保存最佳模型
callbacks = [
keras.callbacks.ModelCheckpoint(&quot;modelfinal3.keras&quot;, monitor=&quot;reg_output_loss&quot;, save_best_only=True , mode=&#39;min&#39;),
keras.callbacks.EarlyStopping(monitor=&#39;reg_output_loss&#39; , waiting = 8 ,mode=&#39;min&#39; )
]

# 在没有验证数据的情况下训练模型
history = model.fit(
X_train_images,{&#39;reg_output&#39; : Y1_regression ,&#39;cls_output&#39; : Y2_classification} ,
epochs= 10 ,
batch_size= 64,
callbacks=callbacks
)

test_model =keras.models.load_model(&quot;modelfinal3.keras&quot;, custom_objects ={&#39;angular_loss&#39;: angular_loss, &#39;rmse_degrees&#39;: rmse_degrees })
results = test_model.evaluate(X_test_images, {&#39;reg_output&#39; : Y1_regression_test ,&#39;cls_output&#39; : Y2_classification_test },return_dict=True )

print(results)

&#39;在此处输入代码结果
30/30 ━━━━━━━━━━━━━━━━━━━━━ 51s 2s/步 - cls_output_accuracy：0.6618 - cls_output_loss：9.0815 - loss：14.4716 - reg_output_loss：5.3914 - reg_output_rmse_degrees：2806.2744

Epoch 7/10
30/30 ━━━━━━━━━━━━━━━━━━━━━━━ 53s 2s/步 - cls_output_accuracy：0.6401 - cls_output_loss：8.9781 - 损失：14.7173 - reg_output_loss：5.7363 - reg_output_rmse_degrees：2787.8420
Epoch 8/10
30/30 ━━━━━━━━━━━━━━━━━━━━━━ 51s 2s/步 - cls_output_accuracy：0.6524 - cls_output_loss：9.0007 - 损失：14.5403 - reg_output_loss：5.5401 - reg_output_rmse_degrees： 2789.3442
时代 9/10
30/30 ━━━━━━━━━━━━━━━━━━━━━━ 51s 2s/步 - cls_output_accuracy：0.6674 - cls_output_loss：9.4412 - 损失：14.7438 - reg_output_loss：5.3030 - reg_output_rmse_degrees：2844.9971
时代 10/10
30/30 ━━━━━━━━━━━━━━━━━━━━━ 52s 2s/步 - cls_output_accuracy：0.6610 - cls_output_loss：9.3189 - 损失：14.7248 - reg_output_loss：5.4059 - reg_output_rmse_degrees：2828.9368
11/11 ━━━━━━━━━━━━━━━━━━━━━━━ 2s 142ms/步 - cls_output_accuracy： 1.0000 - cls_output_loss：9.4424 - loss：9.4928 - reg_output_loss：1.1921e-07 - reg_output_rmse_degrees：2435.0107
{&#39;cls_output_accuracy&#39;：1.0，&#39;cls_output_loss&#39;：8.932900428771973，&#39;loss&#39;：9.235373497009277，&#39;reg_output_loss&#39;：1.1920930376163597e-07，&#39;reg_output_rmse_degrees&#39;：2396.7568359375
进程已完成，退出代码为 0&#39;]]></description>
      <guid>https://stats.stackexchange.com/questions/656415/metrics-and-loss-problem-for-two-output</guid>
      <pubDate>Mon, 28 Oct 2024 14:40:00 GMT</pubDate>
    </item>
    <item>
      <title>多元模型需要随机截距吗？</title>
      <link>https://stats.stackexchange.com/questions/656412/is-a-random-intercept-necessary-for-multivariate-models</link>
      <description><![CDATA[我正在使用 brms 将 height 和 weight 建模为贝叶斯多变量模型中的联合结果，使用 mvbind(height, weight) ~ x。由于两个回答都来自同一个受试者，是否有必要添加随机截距 (1 | subject) 来解释重复测量？
我的数据如下所示：
+-------+-------+-------+
|subject|weight |height |
+-------+-------+-------+
|S1 | 65 | 1.3 |
+-------+-------+-------+
|S2 | 75 | 1.7 |
+-------+-------+-------+
|S3 | 80 | 1.8 |
+-------+-------+-------+
|... | ... | ... |
+-------+-------+-------+
]]></description>
      <guid>https://stats.stackexchange.com/questions/656412/is-a-random-intercept-necessary-for-multivariate-models</guid>
      <pubDate>Mon, 28 Oct 2024 13:29:31 GMT</pubDate>
    </item>
    <item>
      <title>从非独立样本进行估计？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656411/estimation-from-non-independent-samples</link>
      <description><![CDATA[假设 $X_1,X_2,...$ 是具有未知均值和方差的 iid 高斯 rv。然后从估计理论中，我们知道如何估计 $n$ 个样本的均值和方差。现在我对这个问题进行了概括。假设 $X = (X_1,\cdots,X_n\cdots)$ 是一个高斯过程，使得边际 $X_i$ 相同。那么从样本中，您能估计均值和方差吗？如何估计？]]></description>
      <guid>https://stats.stackexchange.com/questions/656411/estimation-from-non-independent-samples</guid>
      <pubDate>Mon, 28 Oct 2024 13:04:15 GMT</pubDate>
    </item>
    <item>
      <title>样本均值的切比雪夫不等式（弱大数定律）[重复]</title>
      <link>https://stats.stackexchange.com/questions/656408/chebyshevs-inequality-for-sample-mean-weak-law-of-large-numbers</link>
      <description><![CDATA[大家好，我的书里有一个我不理解的不等式（图片中的第 2 行）。他们想证明弱大数定律
它说我可以取任何大于...的 k
但这很荒谬，例如：
如果我选择：
epsilon=1、标准差=2 和样本大小 5，选择任何 k 都可以荒谬地保证距离样本平均值最多为 1 的概率几乎是确定的。]]></description>
      <guid>https://stats.stackexchange.com/questions/656408/chebyshevs-inequality-for-sample-mean-weak-law-of-large-numbers</guid>
      <pubDate>Mon, 28 Oct 2024 12:37:45 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN 自动编码器以及格拉姆角场图像编码对时间序列数据进行异常检测 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/656407/anomaly-detection-using-cnn-autoencoder-along-with-gramian-angular-field-image-e</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656407/anomaly-detection-using-cnn-autoencoder-along-with-gramian-angular-field-image-e</guid>
      <pubDate>Mon, 28 Oct 2024 11:19:00 GMT</pubDate>
    </item>
    <item>
      <title>了解负部分依赖值</title>
      <link>https://stats.stackexchange.com/questions/656405/understanding-negative-partial-dependency-values</link>
      <description><![CDATA[负部分依赖值（例如随着输入的增加从 -0.7 变为 -0.5）对于参数来说意味着什么？
这是否意味着该参数与输出呈负相关，还是意味着预测通常低于平均值？
]]></description>
      <guid>https://stats.stackexchange.com/questions/656405/understanding-negative-partial-dependency-values</guid>
      <pubDate>Mon, 28 Oct 2024 10:08:51 GMT</pubDate>
    </item>
    <item>
      <title>如何模拟具有 L1 和 L2 方差分量的多层预测变量？</title>
      <link>https://stats.stackexchange.com/questions/656404/how-to-simulate-a-multilevel-predictor-variable-with-both-l1-and-l2-variance-com</link>
      <description><![CDATA[我正在模拟多级数据，其中我有一个在级别 1 (L1) 上测量的预测变量，它同时具有 L1 和 L2 方差分量。例如，我想模拟在学校班级内以个人级别测量的社会经济地位 (SES) 变量。在多级模型中，我通常使用组均值中心化来分离此预测变量的组内 (L1) 和组间 (L2) 方差。
具体来说，我感兴趣的是模拟 L1 预测变量（例如，个人 SES）及其以组均值为中心的对应变量，以捕获组级 (L2) 方差。我的目标是创建以下数据：
反映 SES 的组内和组间变异性。
允许我使用多级建模方法来解开这些方差分量，类似于组均值中心化在实际数据中的工作方式。
我的问题是：
我该如何模拟具有 L1 和 L2 方差的 L1 预测变量？
我应该遵循哪些步骤来生成 L2 上的组均值中心版本？
这里是一篇关于类似问题的精彩帖子。
模拟 L1 预测器然后在 L2 上创建它的中心版本并不难。但是，在这种方法中，L1 没有真正的 L2 方差：
# 定义模拟参数
n_groups &lt;- 50 # 组数（级别 2）
n_individuals &lt;- 10 # 每组个体数（级别 1）
total_n &lt;- n_groups * n_individuals

# 定义方差
between_var &lt;- 1 # 组间方差
within_var &lt;- 0.5 # 组内方差

# 模拟每个组的随机截距（级别 2 随机效应）
group_effect &lt;- rnorm(n_groups, mean = 0, sd = sqrt(between_var))

# 创建一个数据框来存储模拟数据
data &lt;- data.frame(
group_id = rep(1:n_groups, each = n_individuals),
individual_id = 1:total_n
)

# 生成具有组内和组间变异性的 1 级预测因子 `x1ij`
data$x1ij &lt;- group_effect[data$group_id] + rnorm(total_n, mean = 0, sd = sqrt(within_var))

# 计算 `x1ij` 的组均值（2 级组件）
data$x1j_mean &lt;- ave(data$x1ij, data$group_id, FUN = mean)

# 创建以组均值为中心的 `x1ij` 版本
data$x1ij_centered &lt;- data$x1ij - data$x1j_mean

# 显示数据集的前几行
head(data)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/656404/how-to-simulate-a-multilevel-predictor-variable-with-both-l1-and-l2-variance-com</guid>
      <pubDate>Mon, 28 Oct 2024 10:00:42 GMT</pubDate>
    </item>
    <item>
      <title>使用倾向评分时的假设</title>
      <link>https://stats.stackexchange.com/questions/656403/assumptions-in-the-use-of-propensity-scores</link>
      <description><![CDATA[一位研究人员进行了倾向得分匹配分析，其中暴露的是性别（即男性与女性）。这并不是一个因果分析，结果仅以“关联”的形式描述 - 手稿中没有提到因果推断。
评论中提出，由于女性成为男性的可能性为零，反之亦然，因此阳性假设被违反。我想知道人们对此的看法，因为我认为，如果倾向得分匹配实际上被用作因果推断分析的一个步骤，那么从技术上讲这是正确的。但这里的情况并非如此 - 相反，其意图更像是一个数据缩减步骤。
我认为诸如阳性、可交换性等假设是因果推断的假设，而不是倾向得分本身的使用假设，对吗？还是我没抓住重点？ - 如果我是的话，我禁不住认为这是一个语义问题（即倾向得分实际上只是一个预测概率，人们通常只是假设在计算倾向得分时，会进行因果分析）。]]></description>
      <guid>https://stats.stackexchange.com/questions/656403/assumptions-in-the-use-of-propensity-scores</guid>
      <pubDate>Mon, 28 Oct 2024 09:57:47 GMT</pubDate>
    </item>
    <item>
      <title>函数中是否存在一组紧凑的充分必要标准，可以保证梯度下降找到*全局*最小值？</title>
      <link>https://stats.stackexchange.com/questions/656402/is-there-a-compact-set-of-sufficient-and-necessary-criteria-a-function-can-have</link>
      <description><![CDATA[显然，我们需要所讨论的函数是可微的，这样这个概念才有意义。
现在，凸性是一个充分条件。（强）拟凸性是一个较弱的条件，但我认为仍然是充分条件。
但这两个条件都太强了。当你考虑高维空间时，会存在非常复杂、高度非凸的函数，其中梯度下降对于任何初始化总是收敛的。
例如，一个向下倾斜的地形，上面有一座山。（任何东西要么滚过山，要么滚下山，然后滚下地形）。]]></description>
      <guid>https://stats.stackexchange.com/questions/656402/is-there-a-compact-set-of-sufficient-and-necessary-criteria-a-function-can-have</guid>
      <pubDate>Mon, 28 Oct 2024 09:46:48 GMT</pubDate>
    </item>
    <item>
      <title>如何解释子样本分析和交互分析得出的截然不同的结果</title>
      <link>https://stats.stackexchange.com/questions/656401/how-to-explain-the-totally-different-results-from-subsample-analysis-and-interac</link>
      <description><![CDATA[我正在运行面板数据回归。
主要独立变量 A 是治疗指标。还有另一个变量 B，可以将样本分为两个在线和离线观察。
在运行子样本分析时，A 对在线观察的影响不显著（col 5,6）。A 对离线观察的影响显著为负（col 7,8）。
然而，在运行 B 与 A 交互的回归时，在线观察的影响显著为负，而离线观察的影响显著为正（col 9,10）。
为什么结果会这样？
我知道辛普森悖论，但我似乎无法理解这种情况。
Ps。我使用的是双向固定效应模型。
这是我的结果的屏幕截图：
]]></description>
      <guid>https://stats.stackexchange.com/questions/656401/how-to-explain-the-totally-different-results-from-subsample-analysis-and-interac</guid>
      <pubDate>Mon, 28 Oct 2024 09:33:08 GMT</pubDate>
    </item>
    <item>
      <title>如何解决多重假设检验问题？</title>
      <link>https://stats.stackexchange.com/questions/656399/how-to-solve-a-multiple-hypothesis-test-problem</link>
      <description><![CDATA[我们在进行多重假设检验时遇到了一个问题。我们有一个向量 $x$，当假设 H0 为真时，该向量中的分量服从标准正态分布。我们构建了三个卡方分布检验统计数据 $T_1$、$T_2$ 和 $T_3$，其中 $T_1=x^T(A-B)x$、$T_2=x^T(A-C)x$ 和 $T_3=x^T(A-D)x$。 $A$、$B$和$C$为半正定矩阵，秩分别为6、3、3。根据卡方分布的性质，$T_1$、$T_2$和$T_3$的自由度分别为6、3、3。四个假设定义如下

如果$T_1&lt;=Th_1$或（$T_1&gt;Th_1$ &amp; $T_2&lt;=Th_2$ &amp; $T_3&lt;=Th_3$），则假设$H_0$为真；
如果$T_1&gt;Th_1$ &amp; $T_2&gt;Th_2$ &amp; $T_3&lt;=Th_3$，假设$H_1$为真；
如果$T_1&gt;Th_1$ &amp; $T_2&lt;=Th_2$ &amp; $T_3&gt;Th_3$，假设$H_2$为真；
如果$T_1&gt;Th_1$ &amp; $T_2&gt;Th_2$ &amp; $T_3&gt;Th_3$，假设 $H_3$ 为真。

I 类错误的概率定义为 $Pr(H_1 \cup H_2 \cup H_3 | H_0)$。这个问题的难点在于检验统计量 $T_1$、$T_2$ 和 $T_3$ 是相关的，因为它们“共享”项 $x^TAx$。此外，每个假设都涉及多个检验统计量
我们如何设置阈值$T_1$、$T_2$和$T_3$来控制 I 型错误的概率，使其等于显着性水平 α。
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/656399/how-to-solve-a-multiple-hypothesis-test-problem</guid>
      <pubDate>Mon, 28 Oct 2024 08:41:05 GMT</pubDate>
    </item>
    <item>
      <title>使用非参数检验时，要报告配对样本的哪些描述性统计数据？</title>
      <link>https://stats.stackexchange.com/questions/656398/what-descriptive-statistics-to-report-for-a-paired-sample-when-using-a-nonparame</link>
      <description><![CDATA[我有两个变量，A 和 B（配对样本，前后），我需要进行配对样本非参数检验，因为 A 和 B 之间的差异分布不正常（配对值之间的差异的正态性假设不成立）。大约有 14 条记录。我的问题是：为了在表格中提供描述性统计数据，我是否应该提供 A 和 B 的中位数和 IQR，因为我们正在进行配对样本非参数检验，或者我应该首先分别检查每个变量的分布，如果它们遵循正态分布，则在表格中提供平均值和 SD 的值？]]></description>
      <guid>https://stats.stackexchange.com/questions/656398/what-descriptive-statistics-to-report-for-a-paired-sample-when-using-a-nonparame</guid>
      <pubDate>Mon, 28 Oct 2024 08:38:31 GMT</pubDate>
    </item>
    <item>
      <title>将对数应用于指数和线性拟合[重复]</title>
      <link>https://stats.stackexchange.com/questions/656374/applying-a-log-to-exponential-and-linear-fitting</link>
      <description><![CDATA[我使用或不使用线性变换来拟合一些数据。
这不应该给出与此问题中所示的相同结果：指数回归方法之间的差异。但在这里，在转换时，我通过添加权重来考虑误差传播。
我仍然得到不同的结果。哪里错了？
代码如下：
# 清除环境
rm(list=ls())

# 生成 x 值和 y 值
x_values_exp &lt;- c(0.1, 0.2, 0.5, 1, 2, 3, 4) 
y_values_exp &lt;- c(9, 8.5, 7.5, 6.4, 5.2, 4.7, 4.5)
# 创建数据框
my_data &lt;- data.frame(x = x_values_exp, y = y_values_exp)

# 使用未知权重拟合非线性模型 (exp)
mod_exp &lt;- nls(y ~ A * exp(B * x), data = my_data, start = list(A = 1, B = 1))

# 估计误差在 mod_exp 上（因为我有 2 个参数，所以是 2）
residuals &lt;- residuals(mod_exp)
y_error_estimated &lt;- sqrt(sum(residuals^2)/(length(residuals)-2))
my_data$y_error_estimated &lt;- y_error_estimated

# 应用 log
y_lin &lt;- log(y_values_exp)
# 我必须计算 y 上的相应误差（使用误差传播）
y_lin_errors &lt;- y_error_estimated / y_values_exp
my_data$y_lin_errors &lt;- y_lin_errors

# 拟合线性模型（使用转换后的数据并考虑估计误差）
mod_lin&lt;- nls(log(y) ~ A + B * x, data = my_data, start = list(A = 1, B = 1), weights = 1/(y_lin_errors^2))

# 打印
log( coef(mod_exp)[1]) # log
coef(mod_lin)[1] # lin

结果如下：
&gt; log( coef(mod_exp)[1]) # log
A 
2.151668 
&gt; coef(mod_lin)[1] # lin
A 
2.154402 

使用
y_lin_errors &lt;- y_error_estimated / predict(mod_exp)

如评论 (Sextus Empiricus) 中所述，结果更佳：
&gt; log( coef(mod_exp)[1]) # log
A 
2.151668 
&gt; coef(mod_lin)[1] # lin
A 
2.150832 

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/656374/applying-a-log-to-exponential-and-linear-fitting</guid>
      <pubDate>Sun, 27 Oct 2024 11:52:18 GMT</pubDate>
    </item>
    <item>
      <title>变分推理描述的难解性问题中的混淆[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656368/confusion-in-intractability-issue-described-by-variational-inference</link>
      <description><![CDATA[（已在 reddit 上发布了更长的版本）
我阅读 VAE 论文 已经有一段时间了，并查阅了各种资料，以便对指定的难解性问题有清晰的了解。然而，在试图理解它时，我仍然面临很多困惑。我会解释，但这里只是一些符号，以确保我们的观点一致：

z - 维度为 M 的潜在变量
Z - 表示潜在变量集 z 的随机变量
x - 输入变量（比如说图像）
X - 输入图像数据集

目标是了解潜在空间 Z 的分布，以便从该空间采样时，可以使用某个函数 f(z)（神经网络）生成新的数据点 x&#39;，该函数也属于 P(X) 的输入分布。因此，问题建模如下：

P(Z|X) = P(Z) * P(X|Z) / P(X)

然后，作者声称 P(Z|X) 是难解的，因为 P(X) 是难解的。从高层次上讲，我想了解难解性方面，所以我的问题是：

为什么 P(Z) 在这里不可解？事实上，P(Z) 甚至都不知道，那么为什么它不被认为是难解的？
我假设，P(X|Z) 可以通过应用 f(Z) 来计算，因此如果 P(Z) 是可解的，那么 P(X|Z) 也可以被认为是可解的？
为什么 P(X) 在这里令人担忧？就像它不是可以在整个 P(Z|X) 中假设为常数的某个归一化因子吗？

此外，如果有人可以通过举例而不是仅使用抽象符号来解释这一点以增加清晰度，那将非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/656368/confusion-in-intractability-issue-described-by-variational-inference</guid>
      <pubDate>Sun, 27 Oct 2024 06:04:08 GMT</pubDate>
    </item>
    </channel>
</rss>