<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 05 Jun 2024 09:18:08 GMT</lastBuildDate>
    <item>
      <title>重复测量的负二项回归，每天进行一周</title>
      <link>https://stats.stackexchange.com/questions/648663/negative-binomial-regression-for-repeated-measures-daily-for-one-week</link>
      <description><![CDATA[我有一个包含 2,000 名受试者的数据集，每个受试者提供一周的每日社交接触数据（14,000 次观察 = 2000 名受试者 * 7 天）。我打算使用受试者的年龄、家庭规模、星期几以及可能的其他因素（例如居住地或职业地区）等变量来描述接触人数。
结果变量，即人均每日接触人数，过于分散，所以我想尝试一个假设负二项分布的广义线性模型。但是，数据包括对同一受试者的重复测量（即每个受试者 7 次观察），这违反了独立性假设。因此，我尝试了一个广义线性混合模型（R 中 lme4 包中的 glmer.nb），但尽管调整了各种控制参数，优化算法仍未收敛。我正在寻找问题的替代解决方案，而无需诉诸广义线性混合建模。
这是我的问题：以下方法是否合理？我从原始数据中抽样，这样通过为每个受试者均匀随机地选择一周中的一天，每个受试者只存在一个观察值。这将数据集从 14,000 个观察值减少到 2,000 个观察值。然后，我对这个子集执行负二项回归，并重复此过程多次（例如，20,000 次）。
作为练习，我对 14000 个观察值执行了负二项回归（忽略重复测量独立性假设的违反），并且还对 2,000 个观察值的 4,000 个样本运行了负二项回归。两种方法的估计值（95% 置信区间）相似，尽管抽样子集的标准误差更宽（如下）。估计_2000 的置信区间取自 4,000 次模拟的中央 95% 百分位数。




var
estimates_14000
estimates_2000




1
(截距)
3.05 (2.78 - 3.34)
3.04 (2.51 - 3.66)


2
age_grp5-9
1.67 (1.53 - 1.82)
1.66 (1.41 - 1.96)


3
年龄组10-14
1.54 (1.41 - 1.68)
1.54 (1.34 - 1.79)


4
年龄组15-19
1.45 (1.33 - 1.59)
1.45 (1.25 - 1.69)


5
年龄组20-29
0.60 (0.55 - 0.65)
0.60 (0.52 - 0.69)


6
年龄组30-39
0.69 (0.63 - 0.74)
0.69 (0.60 - 0.79)


7
年龄组40-49
0.75 (0.69 - 0.81)
0.75 (0.66 - 0.86)


8
年龄组50-59
0.82 (0.75 - 0.88)
0.82 (0.72 - 0.94)


9
年龄组60-69
1.05 (0.97 - 1.13)
1.04 (0.92 - 1.21)


10
age_grp70-79
1.11 (1.02 - 1.21)
1.11 (0.96 - 1.29)


11
sexM
1.00 (0.98 - 1.02)
1.00 (0.96 - 1.04)


12
dayofweek星期一
1.47 (1.41 - 1.54)
1.47 (1.28 - 1.68)


13
dayofweek星期二
1.46 (1.39 - 1.52)
1.46 (1.26 - 1.67)


14
dayofweek星期三
1.74 (1.67 - 1.82)
1.75 (1.52 - 2.00)


15
dayofweek星期四
1.58 (1.51 - 1.66)
1.58 (1.38 - 1.82)


16
dayofweek星期五
1.55 (1.48 - 1.63)
1.56 (1.35 - 1.78)


17
dayofweek星期六
1.13 (1.08 - 1.19)
1.14 (0.98 - 1.31)


18
hhsize_grp2
1.15 (1.10 - 1.20)
1.15 (1.05 - 1.26)


19
hhsize_grp3
1.27 (1.22 - 1.33)
1.27 (1.16 - 1.39)


20
hhsize_grp4
1.47 (1.40 - 1.53)
1.47 (1.34 - 1.60)


21
hhsize_grp5+
1.66 （1.57 - 1.74）
1.65（1.48 - 1.85）


]]></description>
      <guid>https://stats.stackexchange.com/questions/648663/negative-binomial-regression-for-repeated-measures-daily-for-one-week</guid>
      <pubDate>Wed, 05 Jun 2024 07:51:07 GMT</pubDate>
    </item>
    <item>
      <title>测试两个预测（通过多元回归模型）是否存在显著差异</title>
      <link>https://stats.stackexchange.com/questions/648662/test-whether-two-predictions-via-a-multiple-regression-model-are-significantly</link>
      <description><![CDATA[我正在 JMP 中为学校开展一个医学研究项目，其中我使用多元线性回归模型，该模型尝试根据以下内容预测中风患者的临床结果（以称为“出院 mRS”的数值量表形式）：

1 个连续预测因子（入院时 NIHSS，即入院时中风严重程度的测量值）
1 个分类预测因子（EVT 时间，即中风患者可能接受的治疗），可以是以下 3 个值中的任何一个：

1 = 到达医院后立即实施 EVT（治疗）
2 = 经过一段时间后实施 EVT
0 = EVT 未管理


交互项 (入院时 NIHSS * EVT 时间)

请参阅本文底部，了解 JMP 中当前的模型样子。

但首先，我的问题是：
对于任何一个给定的 入院时 NIHSS 值，我想计算预测的平均结果（基于此模型）在患者接受 EVT 立即（即EVT 时间 = 1）与 无 EVT（即 EVT 时间 = 0） - 也就是说，在分类预测变量的两个不同值之间。
有没有办法在 JMP 中进行这种分析？
（概念上，我的目标是能够以临床有用的方式利用该模型中的 2 个预测变量，例如希望该模型可以帮助我们决定哪些患者 - 在这种情况下，根据他们中风的严重程度 - 应该接受治疗或不接受治疗，并预测所述治疗的结果。）
感谢您的帮助！

JMP 生成的模型如下所示：


再次感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648662/test-whether-two-predictions-via-a-multiple-regression-model-are-significantly</guid>
      <pubDate>Wed, 05 Jun 2024 07:47:41 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用虚拟变量来估计 Translog 函数？</title>
      <link>https://stats.stackexchange.com/questions/648660/is-it-possible-to-estimate-a-translog-function-with-a-dummy-variable</link>
      <description><![CDATA[我想估计一个超对数生产函数，但我的独立变量中有一个虚拟变量。但是，我在这里读到一些评论，本质上，超对数估计中的所有解释变量都必须是对数。真正的答案是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648660/is-it-possible-to-estimate-a-translog-function-with-a-dummy-variable</guid>
      <pubDate>Wed, 05 Jun 2024 06:36:08 GMT</pubDate>
    </item>
    <item>
      <title>为什么需要对比学习？</title>
      <link>https://stats.stackexchange.com/questions/648656/why-contrastive-learning-is-needed</link>
      <description><![CDATA[对比学习是一种自我监督、独立于任务的深度学习技术，它允许模型学习数据，即使没有标签也是如此。
我想知道一个问题，为什么以及如何它比无监督学习更好？]]></description>
      <guid>https://stats.stackexchange.com/questions/648656/why-contrastive-learning-is-needed</guid>
      <pubDate>Wed, 05 Jun 2024 04:13:02 GMT</pubDate>
    </item>
    <item>
      <title>时间序列回归模型是否需要平稳性或一阶协整？</title>
      <link>https://stats.stackexchange.com/questions/648655/is-stationarity-or-co-integration-of-order-one-needed-for-time-series-regression</link>
      <description><![CDATA[在阅读了著名优秀书籍预测原理与实践（作者：Hyndman &amp; Athanasopoulos）的第 7 章时间序列回归模型后，我发现其中没有提到时间序列是否需要平稳，或者如果它们是一阶积分，I(1)，是否需要进行协整检验。我的理解是，如果时间序列不是平稳的（例如，如果它们有趋势），回归模型将是虚假的。
图 7.2 和 7.6 中用作示例的时间序列乍一看似乎是平稳的。因此，该示例无助于阐明我的问题：
时间序列回归模型（无论是否为多变量）是否必须满足所有变量的平稳性或一阶协整才能用于预测？]]></description>
      <guid>https://stats.stackexchange.com/questions/648655/is-stationarity-or-co-integration-of-order-one-needed-for-time-series-regression</guid>
      <pubDate>Wed, 05 Jun 2024 03:45:30 GMT</pubDate>
    </item>
    <item>
      <title>负二项模型的离散度</title>
      <link>https://stats.stackexchange.com/questions/648654/dispersion-of-a-negative-binomial-model</link>
      <description><![CDATA[在 R 的 glm.nb 摘要中，它表示色散参数 $\phi$ 设置为 1。当模型为
$Y \sim \text{Negbin}(\mu,\theta)$
其中 $E(Y)=\mu$ 和 $V(Y)=\mu+\mu^2/\theta$。这里的色散 $\phi$ 是否意味着指数族公式中的 $V(Y)=\phi(\mu+\mu^2/\theta)$？鉴于$\theta$可以自由调整，测试$H_0: \phi=1$是否有意义？我知道负二项式模型可能由于各种原因（例如，许多零和其他值之间的关系）不能很好地拟合数据，但如果我们说它是过度分散，我们还需要考虑正态分布的过度分散，但人们经常说高斯模型中没有过度分散。
set.seed(1)
x &lt;- round(rep(seq(3,30,by=3),each=10))
y &lt;- rnbinom(length(x),mu=exp(1+0.1*x),size=5)

plot(x,y)
library(MASS)
model &lt;- glm.nb(y~x)
r &lt;- resid(model,type=&quot;pearson&quot;)
(phi &lt;- sum(r^2)/(length(x)-3)) #分散

类似帖子：链接]]></description>
      <guid>https://stats.stackexchange.com/questions/648654/dispersion-of-a-negative-binomial-model</guid>
      <pubDate>Wed, 05 Jun 2024 02:46:33 GMT</pubDate>
    </item>
    <item>
      <title>比较匹配的前后李克特量表数据（n = 40）</title>
      <link>https://stats.stackexchange.com/questions/648644/comparing-matched-pre-post-likert-scale-data-n-40</link>
      <description><![CDATA[我有需要分析的前后匹配李克特量表数据（约 20 个问题）。1) 分析这些数据的最佳方法是什么？我最初认为使用均值并进行配对样本 t 检验是可以的，但这似乎不适用于李克特量表数据。配对样本 wilcoxin 合适吗？一些背景信息，这是评估数据，用于查看课程前后学生的知识和技能。]]></description>
      <guid>https://stats.stackexchange.com/questions/648644/comparing-matched-pre-post-likert-scale-data-n-40</guid>
      <pubDate>Tue, 04 Jun 2024 20:53:20 GMT</pubDate>
    </item>
    <item>
      <title>负偏数据的转换[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648633/transformation-of-negatively-skewed-data</link>
      <description><![CDATA[我问了一个问题，感谢您的反馈，我注意到它是多么不具体，没有经过充分考虑。
所以，我试图更具体一点。
我目前正在尝试计算一个调节分析，以愤怒（分数从 5 到 25）作为 IV，男性年龄作为调节因素，IPV 种类作为因变量。DV 描述了伴侣经历过的不同形式的 IPV 的数量。它们可以从 0 到 5。2 表示例如这个人经历了 2 种形式的 IPV，无论具体是哪一种。
我的大多数参与者都经历过所有 5 种形式（值 5）。
现在我发现，使用 ggplot 和平滑“loess”，至少交互图不是线性的（看起来更像三次函数）。
所以我想计算一个非线性模型。
model_gam &lt;- mgcv::gam(ipv_variety ~ s(dar_scaled) + s(age_scaled, k = 12) + ti(dar_scaled, age_scaled), data = merged_all_complete, method = &quot;REML&quot;)
#alternative
gam1 &lt;- lm(ipv_variety ~ ns(dar_scaled, 5) * age_scaled, data=merged_all_complete)

据我所知（我可能不正确），所选的系列取决于 DV 的分布。目前，默认的高斯分布不适合我的数据。
因此，我想知道是否有适合我的数据的系列，或者是否有办法转换我的 DV 以便高斯分布适合。
我比较新，所以如果我忽略了一些关键细节，我深表歉意。
如果还有其他问题，我很乐意回答。
再次感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/648633/transformation-of-negatively-skewed-data</guid>
      <pubDate>Tue, 04 Jun 2024 18:31:19 GMT</pubDate>
    </item>
    <item>
      <title>具有复合因变量和相互作用的因子方差分析</title>
      <link>https://stats.stackexchange.com/questions/648632/factorial-anova-with-composite-dependent-variable-and-interaction</link>
      <description><![CDATA[我进行了一项实验，参与者被随机分配到对照组或治疗组，在这两种条件下，每个参与者都会连续看到三对产品，其中一种产品更具有享乐性，另一种产品更具有实用性。他们必须在三个选择集（1=享乐性，0=实用性）中各选择一个产品，也就是说，他们总共必须做出三个选择。每个选择集都是不同的产品类别。
我将每个参与者的三个二元答案组合起来，形成一个“享乐选择指数”，我想研究该条件对这个选择指数的影响。
但是，我还想检查产品类别的效果是否不同。
我想知道正确的方法是否是像这样运行因子方差分析：
df &lt;- df %&gt;% mutate(across(c(1,2,3,4,5), as.factor))

library(rstatix)
anova_test(data = df, choice_index~condition*product_category1+condition*product_category2+condition*product_category3, effect.size = &quot;pes&quot;)

这是我的数据：
 df &lt;- structure(list(respondent_id = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15、16、17、18、19、20） 
条件 = c（“对照”，“治疗”，“对照”，“治疗”，“对照”，“治疗”，“对照”，“治疗”，“对照”，“治疗”，“对照”，“治疗”，“对照”，“治疗”， 
“对照”，“治疗”，“对照”，“治疗”，“对照”，“治疗”，“对照”，“治疗”，“对照”，“治疗”） 
产品类别 1 = c（0、1、0、1、0、1、0、1、0、1、1、0、0、1、0、1、0、1、 0, 1, 1, 0), 
product_category2 = c(1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0), 
product_category3 = c(0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0),
choice_index = c(1,2, 0, 3, 1, 3, 1, 3, 3, 0, 1, 2, 0, 3, 1, 3, 1, 3, 3, 0)), 
class = &quot;data.frame&quot;,row.names = c(NA, -20L）
]]></description>
      <guid>https://stats.stackexchange.com/questions/648632/factorial-anova-with-composite-dependent-variable-and-interaction</guid>
      <pubDate>Tue, 04 Jun 2024 18:22:47 GMT</pubDate>
    </item>
    <item>
      <title>Python 拟合的 Sigmoid 极值几乎未被使用</title>
      <link>https://stats.stackexchange.com/questions/648607/python-fitted-sigmoid-extreme-values-barely-being-used</link>
      <description><![CDATA[我最初处理的是大量值对。我使用自定义启发式方法从每对值计算得分，并将该集合转换为值数组。我对其进行了排序，并将每个值分配给 x，将其标准化排名（介于 0 和 1 之间，均排除）分配给 y。
这是一个例子：

我尝试拟合 S 型函数，但我认为它被大量居中数据误导，没有考虑到极端值，而我实际上计划使用这个新函数将 0 到 1 之间的得分分配给任何新值。现在，使用该解决方案，任何超过阈值 31 的值的排名都会达到大约 0.93。
如何降低中心点的影响？我考虑过简单地删除一些，但我不知道正确的方法，甚至不知道这是否是正确的方法。
这是我的代码：
import json
import numpy as np
from scipy.optimize import curve_fit
import matplotlib.pyplot as plt

filename = &quot;scores.json&quot;

使用 open(filename, &#39;r&#39;) 作为 f:
data = json.load(f)

x_values = [point[&#39;x&#39;] for point in data]
y_values = [point[&#39;y&#39;] for point in data]

x_data = np.array(x_values)
y_data = np.array(y_values)

def sigmoid(x, L, x0, k):
return L / (1 + np.exp(-k * (x - x0)))

initial_guess = [1, np.median(x_data), 1]

params, covariance = curve_fit(sigmoid, x_data, y_data, p0=initial_guess, maxfev=10000)

L, x0, k = params

print(f&quot;优化参数：L = {L}, x0 = {x0}, k = {k}&quot;)

plt.scatter(x_data, y_data, marker=&#39;+&#39;, label=&#39;Data&#39;)

x_fit = np.linspace(min(x_data), max(x_data), 400)
y_fit = sigmoid(x_fit, *params)
plt.plot(x_fit, y_fit, label=&#39;Fitted Sigmoid&#39;, color=&#39;red&#39;)

plt.legend()
plt.show()

以下是找到的参数：
# 优化参数：L = 0.9305200252602871，x0 = 2.107303517527327，k = 0.24761667539895446
]]></description>
      <guid>https://stats.stackexchange.com/questions/648607/python-fitted-sigmoid-extreme-values-barely-being-used</guid>
      <pubDate>Tue, 04 Jun 2024 12:07:38 GMT</pubDate>
    </item>
    <item>
      <title>如何根据一组百分位数重建正态分布？</title>
      <link>https://stats.stackexchange.com/questions/648589/how-can-i-reconstruct-a-normal-distribution-from-a-set-of-percentiles</link>
      <description><![CDATA[我有一个正态分布变量的第 3、10、50、90 和 97 个百分位数值，我希望生成一个数据集，使我能够查询其他百分位数值（例如，第 67 个百分位数值）。
我（天真地，我敢肯定）尝试了以下操作，但失败了：
underlying_data = np.random.normal(loc=0.0, scale=1.0, size=[1000])

percentiles = np.percentile(underlying_data, [3, 10, 50, 90, 97])

#

generated_data = []

for i in range(3):
generated_data.append(underlying_data[0])

for i in range(7):
generated_data.append(underlying_data[1])

for i in range(80):
generated_data.append(underlying_data[2])

for i in range(7):
generated_data.append(underlying_data[3])

for i in range(3):
generated_data.append(underlying_data[4])

print(&quot;from underground distribution: &quot;, np.percentile(np.array(underlying_data), [67]))
print(&quot;from generated distribution: &quot;, np.percentile(np.array(generated_data), [67]))

输出：
from underground distribution: [0.44470627]
from generated distribution: [-0.73888881]
]]></description>
      <guid>https://stats.stackexchange.com/questions/648589/how-can-i-reconstruct-a-normal-distribution-from-a-set-of-percentiles</guid>
      <pubDate>Tue, 04 Jun 2024 06:25:11 GMT</pubDate>
    </item>
    <item>
      <title>Radon Nikodym 方程的推进测度</title>
      <link>https://stats.stackexchange.com/questions/648564/pushforward-measure-for-radon-nikodym-equation</link>
      <description><![CDATA[考虑概率空间 $(\Omega, \mathcal{A}, \mathbb{P})$ 和同一空间中的另一个概率测度 $\mu$，由以下公式给出
$$\mu(A)=\int_A f(\omega) \mathbb{P}(d\omega)$$
现在让 $X:\Omega \rightarrow \mathcal{X}$ 成为映射到 $(\mathcal{X}, \mathcal{F})$ 的随机变量。
我对推进测度 $\mu_X$ 很感兴趣，并希望用以下公式来表达它前推测度$\mathbb{P}_X$。
从上面的等式中我们知道$\mu \ll \mathbb{P}$。这是否也意味着$\mu_X \ll \mathbb{P}_X$？如果是这样，我们可以再次写出（由于 Radon Nikodym 定理）：
$$\mu_X(F)=\int_F g(x) \mathbb{P}_X(dx)$$
如果所有这些都是可能的，那么$f$和$g$之间会有什么联系？是否也可以通过变量变换公式直接得到第二个方程？]]></description>
      <guid>https://stats.stackexchange.com/questions/648564/pushforward-measure-for-radon-nikodym-equation</guid>
      <pubDate>Mon, 03 Jun 2024 18:55:17 GMT</pubDate>
    </item>
    <item>
      <title>重复测量方差分析问题</title>
      <link>https://stats.stackexchange.com/questions/648560/repeated-measures-analysis-of-variance-question</link>
      <description><![CDATA[我有以下数据集。
My_Data &lt;- data.frame(Sampling_Date = rep(1:4, each = 12), Block = rep(1:3, length.out = 48), Treatment = rep(LETTERS[1:4], each = 3, length.out = 48), Response = abs(rnorm(48, 10, 1)))

我正在做重复测量方差分析。每个区块包含四个图，其中区块中的每个图都接受不同的处理。这些图在一年内被重复采样。我想知道在 R 中对这些数据进行建模的最合适方法是什么。这是我根据所读内容得出的结论。
Model &lt;- aov(Response ~ (Treatment * as.factor(Sampling_Date)) + Error(as.factor(Block) / (Treatment * as.factor(Sampling_Date))), data = My_Data)
summary(Model)

在此模型输出中，每个主效应和交互项都有自己的误差项，这本质上是主效应或感兴趣的交互与阻塞（复制）变量的相互作用。
我有几个问题。
首先，此模型的工作方式是否合适？换句话说，这些误差项是否适用于每个不同的主效应和交互？如果是，那么为什么？
其次，我是否需要考虑混合效应模型，以便可以将块视为随机变量？由于区块本质上只是我们的复制变量，我认为它不应该包含在模型中。
第三，何时以及为什么要考虑球形度？这取决于我们将采样日期视为数字变量还是分类变量吗？
第四，如果我将采样日期视为数字变量，模型将如何变化？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648560/repeated-measures-analysis-of-variance-question</guid>
      <pubDate>Mon, 03 Jun 2024 17:20:53 GMT</pubDate>
    </item>
    <item>
      <title>具有和不具有随机斜率的上下文模型中固定效应的等价性</title>
      <link>https://stats.stackexchange.com/questions/648536/equivalence-of-fixed-effects-in-contextual-models-with-and-without-random-slopes</link>
      <description><![CDATA[根据（心理学）文献（例如，参见 Kreft 等人，1995 年，或 Enders &amp; Tofighi，2007 年），在估计“上下文模型”（即包含第 1 级预测因子及其第 2 级聚类均值的模型）时，固定效应的估计应该不受中心化方案（总体均值中心化，cgm，与组均值中心化，cwc）的影响。
但是，如果我在 R 中使用 lme4 尝试此操作，则这（在数值上）仅当指定模型时没有随机斜率时才成立。
此外，上下文效应（或其变体）的众所周知的关系，$\gamma_{10}^{cgm}+\gamma_{01}^{cgm}=\gamma_{01}^{cwc}$，也仅在这种情况下成立（参见，例如，Enders &amp; Tofighi，2007）。
Enders 和 Tofighi (2007) 写道：
由于估计过程缺乏精度，Kreft 等人提出的代数恒等式。 （1995）在将估计的参数值代入本节概述的方程时可能不完全成立。
我的问题是：

为什么会这样？
为什么只有没有随机斜率的模型才存在不精确性？
这两者中哪一个（cgm 或 cwc）是“更好”的估计？

还请注意，使用 ML 而不是 REML 进行估计时问题仍然存在。
示例代码（示例来自此处）
library(dplyr)
library(lme4)

AMIB &lt;- read.csv(file = url(&quot;https://quantdev.ssri.psu.edu/sites/qdev/files/AMIBshare_daily_2019_0501.csv&quot;), header = TRUE) %&gt;% 
select(id, negaff, pss) %&gt;% 
mutate(stress = 4 - pss) %&gt;% 
mutate(stress_trait = mean(stress, na.rm = TRUE), .by = id) %&gt;% 
mutate(stress_trait_c = stress_trait - mean(stress_trait)) %&gt;% 
mutate(stress_cgm = stress - mean(stress, na.rm = TRUE),
stress_cwc = stress - stress_trait)

ri_cgm &lt;- lmer(negaff ~stress_cgm +stress_trait_c + (1 | id), data = AMIB)
ri_cwc &lt;- lmer(negaff ~stress_cwc +stress_trait_c + (1 | id), data = AMIB)

fixef(ri_cgm)
sum(fixef(ri_cgm)[-1])
fixef(ri_cwc)

rs_cgm &lt;- lmer(negaff ~ stress_cgm + stress_trait_c + (stress_cgm | id), data = AMIB)
rs_cwc &lt;- lmer(negaff ~ stress_cwc + stress_trait_c + (stress_cwc | id), data = AMIB)

fixef(rs_cgm)
sum(fixef(rs_cgm)[-1])
fixef(rs_cwc)

输出：
&gt; fixef(ri_cgm)
(截距)stress_cgmstress_trait_c 
2.4567674 0.8429788 0.1996167 
&gt; sum(fixef(ri_cgm)[-1])
[1] 1.042596
&gt; fixef(ri_cwc)
(截距)stress_cwcstress_trait_c
2.4587394 0.8429788 1.0425955
&gt;
&gt; fixef(rs_cgm)
(截距)stress_cgmstress_trait_c
2.4473444 0.7803662 0.2232565
&gt; sum(fixef(rs_cgm)[-1])
[1] 1.003623
&gt; fixef(rs_cwc)
(截距)stress_cwcstress_trait_c
2.4594740.7757561.019996

文献
Kreft, I. G., De Leeuw, J., &amp; Aiken, L. S. (1995). 不同形式的中心化对分层线性模型的影响。多元行为研究，30(1)，1-21。
Enders, C. K., &amp; Tofighi, D. (2007)。横截面多层模型中的中心预测变量：对一个老问题的新看法。《心理学方法》，12(2)，121。]]></description>
      <guid>https://stats.stackexchange.com/questions/648536/equivalence-of-fixed-effects-in-contextual-models-with-and-without-random-slopes</guid>
      <pubDate>Mon, 03 Jun 2024 10:34:29 GMT</pubDate>
    </item>
    <item>
      <title>（非）线性系数组合的似然比和得分检验</title>
      <link>https://stats.stackexchange.com/questions/648266/likelihood-ratio-and-score-tests-of-a-nonlinear-combination-of-coefficients</link>
      <description><![CDATA[似然比和分数检验通常用于简单的标量假设，例如$\beta_1 = 0$或$\beta_1 = \beta_2 = 0$。如何使用似然比和分数检验来检验系数的线性组合，例如$H_0: \beta_1 + 2 \beta_2 - 7 \beta_3 = 0$？更一般地说，是否可以使用似然比和分数检验来检验系数的非线性组合，例如$H_0: \beta_1 + 2 \exp(\beta_2) = 0$？如何在 R 中实现它们？
这些涉及线性和非线性假设的假设是由对交互项、预测值和效果比较的评估所激发的。它们通常使用 Wald 检验进行测试，非线性假设使用 delta 方法在非线性变换后计算标准误差。然而，在广义线性模型中，似然比检验通常比 Wald 检验提供更准确的 p 值和置信区间。
例如，二元 Logit 回归的估计均值结构为 $\text{logit}(p) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3$。有哪些可行的方法可以检验 $H_0: \beta_1 + 2 \beta_2 - 7 \beta_3 = 0$ 和 $H_0: \beta_1 + 2 \exp(\beta_2) = 0$？样本数据和模型：
data(&quot;mtcars&quot;)
View(mtcars)
summary(Model &lt;- glm(
am ~ mpg + disp + hp, 
family = binomial(), data = mtcars))
&quot; 估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -33.81283 24.17533 -1.399 0.1619 
mpg 1.28498 0.89895 1.429 0.1529 
disp -0.06545 0.04305 -1.520 0.1284 
hp 0.14936 0.07871 1.898 0.0577 .
零偏差：31 个自由度上的 43.230
残差偏差：28 个自由度上的 10.148
AIC：18.148&quot;
]]></description>
      <guid>https://stats.stackexchange.com/questions/648266/likelihood-ratio-and-score-tests-of-a-nonlinear-combination-of-coefficients</guid>
      <pubDate>Thu, 30 May 2024 07:42:58 GMT</pubDate>
    </item>
    </channel>
</rss>