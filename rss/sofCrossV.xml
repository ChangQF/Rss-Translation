<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 12 Dec 2024 12:36:38 GMT</lastBuildDate>
    <item>
      <title>使用 tsfeatures 识别难以预测的时间序列</title>
      <link>https://stats.stackexchange.com/questions/658621/identifying-poorly-forecastable-time-series-using-tsfeatures</link>
      <description><![CDATA[我正在研究一个问题，该问题涉及使用 Rob J. Hyndman 使用 tsfeatures 库提取的特征来识别预测性较差的时间序列。以下是有关我的数据集和方法的关键细节：
数据集：

超过 140,000 个单独的时间序列。

每个时间序列跨越 29 个月，每月一个值。

预测范围：7 个月。


目标：
通过利用提取的特征和评估预测误差来确定哪些时间序列预测性较差。
当前方法
步骤 1：特征提取
使用 tsfeatures 库，我为 140,000 个时间序列中的每一个计算各种统计和时间序列特征。然后将这些特征存储在 DataFrame 中以供进一步分析。
第 2 步：预测
每个时间序列都使用多个模型进行预测：TimesNet、NBEATS、NHITS。
这些模型都经过了优化，我为每个模型计算了预测误差指标：

MSE（事先缩放数据时）。
MAAPE（未缩放数据时）。

我在 DataFrame 中记录了每个时间序列的最低预测误差值（例如 min_maape）。
步骤 3：准备回归数据
DataFrame 现在包含每个时间序列的提取特征和误差指标。
我通过删除不相关或有问题的列来创建特征矩阵 (X_features)，例如：

[&#39;unique_id&#39;, &#39;ds&#39;, &#39;y&#39;, &#39;hurst&#39;, &#39;arch_acf&#39;, &#39;garch_acf&#39;, &#39;arch_r2&#39;, &#39;garch_r2&#39;, &#39;min_maape&#39;, &#39;max_maape&#39;, &#39;TimesNet&#39;, &#39;NHITS&#39;, &#39;NBEATSx&#39;]

目标变量 (y_maape) 包含最小 MAAPE 值：

y_maape = feature_evaluation_merged[&#39;min_maape&#39;]

我执行 80/20 训练-测试分割：
X_train, X_test, y_train, y_test, unique_ids_train, unique_ids_test = train_test_split(
X_features, y_maape, unique_ids, test_size=0.2, random_state=42)


步骤 4：训练回归器
我训练各种回归器，根据提取的特征预测 min_maape。到目前为止，我已经测试过：

随机森林
决策树
梯度提升
结合随机森林、梯度提升和 AdaBoost 的集成模型

训练随机森林回归器的示例：
rf = RandomForestRegressor(
max_depth=9,
min_samples_leaf=10,
min_samples_split=9,
n_estimators=743,
random_state=42
)
rf.fit(X_train_numeric, y_train)
第 5 步：超参数优化
我使用以下方法优化了回归器：

Optuna 框架
GridSearchCV 来自scikit-learn

第 6 步：评估
无论使用何种回归器或优化程度如何，预测值（例如 rf.predict(X_test)）都保持在 0.6 和 1.0 之间。以下是两个示例：
预测值分布：

MAAPE 差异（真实值与预测值）：

问题：

我的方法有意义吗？
尽管进行了超参数优化，但预测值仍然在一个较窄的范围内（0.6–1.0）。我该如何改进？
是否存在方法缺陷、遗漏的步骤或我可以纳入的潜在改进？

提前感谢您的见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/658621/identifying-poorly-forecastable-time-series-using-tsfeatures</guid>
      <pubDate>Thu, 12 Dec 2024 12:00:28 GMT</pubDate>
    </item>
    <item>
      <title>线性回归和岭回归得出相似的系数</title>
      <link>https://stats.stackexchange.com/questions/658617/linear-regression-and-ridge-regression-resulting-in-similar-coefficients</link>
      <description><![CDATA[我从线性回归中获得的系数与岭回归相似。我试图了解我错在哪里，但我无法弄清楚。如果有人能指出我错在哪里，那将非常有帮助。
from sklearn.preprocessing import StandardScaler

ss = StandardScaler()

X_scl = ss.fit_transform(X)
y_scl = ss.fit_transform(y)

sk_lr = LinearRegression()
sk_lr.fit(X_scl,y_scl)

alpha=0.01
sk_ridge = Ridge(alpha=alpha)
sk_ridge.fit(X_scl,y_scl)

x = np.arange(len(X.columns))

plt.figure(figsize=(15,10))

plt.bar(x=x-.2,height=sk_lr.coef_[0],width=0.4)
plt.bar(x=x+.2,height=sk_ridge.coef_[0],width=0.4)

plt.xticks(ticks=x,rotation=90,labels = X.columns)

plt.show()

我使用的数据kc_house_train_data.csv]]></description>
      <guid>https://stats.stackexchange.com/questions/658617/linear-regression-and-ridge-regression-resulting-in-similar-coefficients</guid>
      <pubDate>Thu, 12 Dec 2024 10:54:40 GMT</pubDate>
    </item>
    <item>
      <title>R 中估算和加权数据的汇总患病率（95%CI）估计</title>
      <link>https://stats.stackexchange.com/questions/658616/estimation-of-pooled-prevalence-with-95ci-in-imputed-and-weighted-data-in-r</link>
      <description><![CDATA[我正在尝试估计二元变量“x”的流行程度以及在 R 中多次插补（使用 mice）并应用权重后的置信区间。我使用 Rubin 规则进行估计，但我不确定我是否正确实施了它们。
#### 插补和加权后的流行率 ####
# 通过插补计算加权比例

estimate_prop_x &lt;- imp_long %&gt;%
group_by(.imp) %&gt;%
summary(
prop = sum((x == 1) * weight) / sum(weight), # 加权比例
.groups = &quot;drop&quot;
)

# 使用 Rubin 规则计算整体组合统计数据
estimate_mean_prop_x &lt;-estimate_prop_x %&gt;%
filter(.imp &gt; 0) %&gt;% # 排除具有缺失值的观测数据
summary(
mean_prop =mean(prop),
var_intra =var(prop),
U_bar = mean(var_intra),
m = 15, # 插补次数 
B = sum((prop - mean(prop))^2)/(m-1),
var_comb = U_bar + (1 + 1/m) * B, # 合并方差
) %&gt;%
mutate(
# 计算调整后的自由度
df_adj = (m - 1) * (1 + (var_intra / ((1 + 1/m) * B)))^2,
# 95% 置信区间的临界 t 值
t_value = qt(0.975, df = df_adj),
# 计算置信区间限值
conf_low = mean_prop - t_value * sqrt(var_comb),
conf_high = mean_prop + t_value * sqrt(var_comb)
)

# 显示结果
print(estimate_mean_prop_x)

感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/658616/estimation-of-pooled-prevalence-with-95ci-in-imputed-and-weighted-data-in-r</guid>
      <pubDate>Thu, 12 Dec 2024 10:36:39 GMT</pubDate>
    </item>
    <item>
      <title>因变量值超过 50 个</title>
      <link>https://stats.stackexchange.com/questions/658614/more-than-50-values-for-dependent-variable</link>
      <description><![CDATA[转帖：大家好，非常感谢大家对我之前帖子的回复，我可以在下面找到。这里我提供了一些信息。
a. 这是临床数据，样本量约为 859。
b. 它有 11 列作为输入特征，例如基因组的唯一读取，它是细菌还是病毒类型以及测序报告的病原体。它是分类值和数值的混合。
c. 依赖列有 53 个唯一值（医院检测到的病原体），我的模型将尝试预测这些值。
再次，任何关于如何处理这个问题的建议。
上一篇文章：我正在尝试构建机器学习模型，其中因变量是分类的，并且有超过 60 个值。它们不是序数或遵循任何等级。
任何关于如何处理这个问题的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/658614/more-than-50-values-for-dependent-variable</guid>
      <pubDate>Thu, 12 Dec 2024 10:12:21 GMT</pubDate>
    </item>
    <item>
      <title>如何从多个研究内效应中获取一个研究效应</title>
      <link>https://stats.stackexchange.com/questions/658613/how-to-obtain-one-study-effect-from-several-within-study-effects</link>
      <description><![CDATA[我想进行叙述性回顾（因为无法进行荟萃分析），并且我想根据研究得出预测因子是否显著的结论。但是，研究对每个预测因子都有几种效应大小。例如，我想研究父母的精神病理学作为预测因子，一项研究调查了父母的抑郁症和父母的药物滥用。从这两个指标中，我想要一个结论（针对这项研究）。我如何才能对每个研究得出一个效应大小或结论？
如果两者都不显著，我可以假设父母的精神病理学预测因子也不显著吗？在这种情况下，如果 2 个中有 1 个显著，会怎么样？或者 4 个中有 3 个显著？
我也尝试在一项具有几种效应大小的研究中进行荟萃分析，但我发现这些结果值得怀疑。例如，一项具有 4 个不显著效应大小的研究变得显著：
data &lt;- data.frame(logOR = c(1.41098697371026, 1.14740245283754, 1.61938824328727, 0.470003629245736), #对数转换的优势比
CI.low_log = c(-0.127833371509885, -0.941608539858445, -0.462035459596559, -2.30258509299405), #对数转换的下限
CI.high_log = c(2.95386806945529, 3.23867845216438, 3.69907727909038, 3.27374272630904), # 对数转换的上限
vi = c(0.618029191694011, 1.1372084115782, 1.12679998074128, 2.02359901787885), # 平方标准误差，((data$CI.high_log - data$CI.low_log)/3.92)^2
effect_id = 1:4
)

rma.mv(
yi = logOR, # 对数转换的 OR
V = vi, # 方差
random = list(~ 1 | effect_id), # 随机效应结构
data = data
)

多变量荟萃分析模型 (k = 4; 方法：REML)

方差分量：

估计 sqrt nlvls 固定因子 
sigma^2 0.0000 0.0000 4 无 effect_id 

异质性检验：
Q(df = 3) = 0.4697, p-val = 0.9255

模型结果：

估计 se zval pval ci.lb ci.ub 
1.2790 0.5077 2.5191 0.0118 0.2839 2.2742 * 

---
符号代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
]]></description>
      <guid>https://stats.stackexchange.com/questions/658613/how-to-obtain-one-study-effect-from-several-within-study-effects</guid>
      <pubDate>Thu, 12 Dec 2024 09:44:00 GMT</pubDate>
    </item>
    <item>
      <title>理解平均相对差异（用于 R 中的 all.equal 函数）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658609/understanding-of-mean-relative-difference-used-in-all-equal-function-in-r</link>
      <description><![CDATA[有人能解释一下这个 R 代码的结果吗：
x &lt;- c(1, 0, 1, 0, 0)
y &lt;- c(0, 1, 0, 1, 1)
all.equal(x, y)
[1] &quot;平均相对差异：2.5&quot;

据我理解，平均相对差异定义如下：
$$D = \frac{1}{n} \sum d[i]$$
with
$$d[i] = \frac{|x[i] - y[i]|}{\max\left(|x[i]|, |y[i]|, \text{tolerance}\right)}$$
因此，我期望分母始终为 1：
$$|x[1] - y[1]| = |1-0| = 1$$
$$|x[2] - y[2]| = |0-1| = 1$$
$$|x[3] - y[3]| = |1-0| = 1$$
$$|x[4] - y[4]| = |0-1| = 1$$
$$|x[5] - y[5]| = |0-1| = 1$$
分子也始终为 1：
$$\max\left(|x[1]|, |y[1]|, 0.1e-58\right) = max(1,0,0.1e-58) = 1$$
$$\max\left(|x[2]|, |y[2]|, 0.1e-58\right) = max(0,1,0.1e-58) = 1$$
$$\max\left(|x[3]|, |y[3]|, 0.1e-58\right) = max(1,0,0.1e-58) = 1$$
$$\max\left(|x[4]|, |y[4]|, 0.1e-58\right) = max(0,1,0.1e-58) = 1$$
$$\max\left(|x[5]|, |y[5]|, 0.1e-58\right) = max(0,1,0.1e-58) = 1$$
因此平均相对差异将是：
$$\frac{1}{5}\sum_{i=1}^{5} d[i] = \frac{1}{5} * (\frac{1}{1}+\frac{1}{1}+\frac{1}{1}+\frac{1}{1}+\frac{1}{1}) = 1$$
然而 R 打印的结果却是 2.5。我对平均相对差异的理解哪里错了？还是函数有 bug？]]></description>
      <guid>https://stats.stackexchange.com/questions/658609/understanding-of-mean-relative-difference-used-in-all-equal-function-in-r</guid>
      <pubDate>Thu, 12 Dec 2024 08:11:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么非平稳 AR 过程不能表示为无限 MA 过程？</title>
      <link>https://stats.stackexchange.com/questions/658605/why-cant-a-non-stationary-ar-process-be-represented-as-an-infinite-ma-process</link>
      <description><![CDATA[考虑 AR(1) 过程。如果 $|\phi|&lt;1$，则该过程为平稳过程，我们可以将该级数表示为
$$ Y_t = \epsilon_t + \phi\epsilon_{t-1} + \phi^2\epsilon_{t-2} + \phi^3\epsilon_{t-3} + \cdots $$
我听说只有平稳 AR 过程才能表示为无限 MA 过程，因此以 AR(1) 为例，如果 $|\phi| \geq 1$，为什么这不成立？]]></description>
      <guid>https://stats.stackexchange.com/questions/658605/why-cant-a-non-stationary-ar-process-be-represented-as-an-infinite-ma-process</guid>
      <pubDate>Thu, 12 Dec 2024 00:41:34 GMT</pubDate>
    </item>
    <item>
      <title>指数平滑应用于随机游走时的最佳参数</title>
      <link>https://stats.stackexchange.com/questions/658598/best-parameter-of-exponential-smoothing-when-applied-on-a-random-walk</link>
      <description><![CDATA[假设我有一个随机游走：
$$X_t = X_0 + \sum_{i =1}^t \epsilon_i$$
其中$\epsilon_i \sim \mathcal{N}(0, \sigma^2)$且独立。
那么在窗口$N$的指数移动平均中，哪个平滑因子$\alpha$可以给出$X_{T+1}$的最佳估计？
我觉得它应该取决于$\sigma$。例如，如果 $\sigma$ 很大，我会直观地减少最近值的权重，而如果 $\sigma$ 很小，我会增加最近值的权重。
但是，$\alpha$ 是否存在可以给出最佳估计的封闭形式？]]></description>
      <guid>https://stats.stackexchange.com/questions/658598/best-parameter-of-exponential-smoothing-when-applied-on-a-random-walk</guid>
      <pubDate>Wed, 11 Dec 2024 22:35:53 GMT</pubDate>
    </item>
    <item>
      <title>是否存在一种标准方法，通过纳入第二个协变量来量化和测试一个协变量的好处？</title>
      <link>https://stats.stackexchange.com/questions/658596/is-there-a-standard-way-to-quantify-test-the-benefit-to-one-covariate-by-inclu</link>
      <description><![CDATA[对于线性模型（或 glm），是否有标准统计数据（和相关测试）来量化包含协变量是否会增加另一个协变量与因变量之间的关联强度？
例如，我有两个模型：

Y ~ X1
Y ~ X1 + X2

我知道我可以使用似然比检验来评估模型 2 是否更能解释 Y，但这可能完全由 X2 的独立贡献驱动。是否有“测试”（甚至只是一个可解释的统计数据）来衡量在给定 X2 的情况下 X1 是否能显著（或有意义地）更好地解释 Y？]]></description>
      <guid>https://stats.stackexchange.com/questions/658596/is-there-a-standard-way-to-quantify-test-the-benefit-to-one-covariate-by-inclu</guid>
      <pubDate>Wed, 11 Dec 2024 22:05:08 GMT</pubDate>
    </item>
    <item>
      <title>如果我从数据框中删除一些变量或将因子载荷限制为 0，保留所有变量，为什么两个 CFA 模型不等效？lavaan</title>
      <link>https://stats.stackexchange.com/questions/658595/why-are-two-cfa-models-not-equivalent-if-i-drop-some-variables-from-my-dataframe</link>
      <description><![CDATA[探索嵌套与非嵌套模型时，我对一个奇怪的结果感到惊讶。第一个模型使用我的数据框中的 21 个变量并运行 CFA。第二个模型使用我的数据框中的 28 个变量，但将 7 个变量的因子载荷限制为 0。
mod1 &lt;- &quot;F1 =~ fig_1 + fig_2 + fig_3 + fig_4 + fig_6 + fig_7 + fig_10 + fig_11 + 
fig_12 + fig_13 + fig_14 + fig_15 + fig_17 + fig_18 + fig_19 + fig_20 +
fig_21 + fig_22 + fig_24 + fig_25 + fig_28&quot;

mod2 &lt;- &quot;F1 =~ fig_1 + fig_2 + fig_3 + fig_4 + fig_6 + fig_7 + fig_10 + fig_11 + 
fig_12 + fig_13 + fig_14 + fig_15 + fig_17 + fig_18 + fig_19 + fig_20 +
fig_21 + fig_22 + fig_24 + fig_25 + fig_28 +
0*fig_26 + 0*fig_23 + 0*fig_8 + 0*fig_9 + 0*fig_5 + 0*fig_16 + 0*fig_27&quot;

这两个 CFA 模型是
cfa1 &lt;- cfa(mod1 ,
data = df_mig %&gt;%
select(fig_1:fig_28) %&gt;%
select(-c(fig_26, fig_23, fig_8, fig_9,
fig_5, fig_16, fig_27)),
estimator = &#39;WLSM&#39;,
ordered=TRUE)
cfa2 &lt;- cfa(mod2 ,
data = df_mig %&gt;%
select(fig_1:fig_28), #使用所有列
estimator = &#39;WLSM&#39;,
ordered=TRUE)
因子载荷都相同，但模型拟合度却大不相同。

有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658595/why-are-two-cfa-models-not-equivalent-if-i-drop-some-variables-from-my-dataframe</guid>
      <pubDate>Wed, 11 Dec 2024 21:52:41 GMT</pubDate>
    </item>
    <item>
      <title>如何对两组潜在变量进行 t 检验并比较它们的均值？</title>
      <link>https://stats.stackexchange.com/questions/658587/how-do-i-perform-a-t-test-for-latent-variables-in-two-groups-and-compare-their-m</link>
      <description><![CDATA[我正在尝试对两组潜在变量进行 t 检验。但是，我不确定这是否是合适的方法。
# 加载必要的包（如果尚未加载）
library(readxl)
library(lavaan)
library(semTools)
library(psych)

# 读取数据（根据需要调整文件名和路径）
data &lt;- read_excel(&quot;newpost.xlsx&quot;)

names(data) &lt;- gsub(&quot; &quot;, &quot;_&quot;, names(data))

data$intelligence_score &lt;- rowMeans(data[, c(&quot;intelligent_1&quot;, 
&quot;intelligent_2&quot;, 
&quot;intelligent_3&quot;, 
&quot;intelligent_5&quot;,
&quot;intelligent_6&quot;)],
na.rm = TRUE)

数据$translationgroup &lt;- factor(data$translationgroup, levels = c(0,1), labels = c(&quot;Low_tranlation&quot;, &quot;High_tranlation&quot;))

# 对翻译组的 intelligence_score 执行双样本 t 检验
t_test_result &lt;- t.test(intelligence_score ~ Translationgroup, data = data)

# 打印结果
print(t_test_result)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/658587/how-do-i-perform-a-t-test-for-latent-variables-in-two-groups-and-compare-their-m</guid>
      <pubDate>Wed, 11 Dec 2024 19:21:07 GMT</pubDate>
    </item>
    <item>
      <title>关于 $X^TX$ 的协方差矩阵</title>
      <link>https://stats.stackexchange.com/questions/658584/covariance-matrix-in-terms-of-xtx</link>
      <description><![CDATA[如果我有一个矩阵 $X\in \mathbb{R}^{n\times p}$，那么我可以将协方差写为
$$\text{Cov}(X) = \mathbb{E}[(X-\mu_X)(X-\mu_X)^T]$$
现在，假设数据已居中，则变为 $\text{Cov}(X) = \mathbb{E}[XX^T]$。我见过帖子说协方差是$XX^T$，而其他人提到$X^TX$是协方差。我不太明白这两个是如何得出的。]]></description>
      <guid>https://stats.stackexchange.com/questions/658584/covariance-matrix-in-terms-of-xtx</guid>
      <pubDate>Wed, 11 Dec 2024 18:10:08 GMT</pubDate>
    </item>
    <item>
      <title>如何从具有分类变量的混合模型中估计总体方差？</title>
      <link>https://stats.stackexchange.com/questions/658575/how-to-estimate-population-variance-from-a-mixed-model-with-a-categorical-variab</link>
      <description><![CDATA[我以为这是一个基本问题，但我被它难住了，找不到解决方案。
我有一个数据库，其中包含不同养猪生产阶段（类别）的粪浆干物质含量，并且由不同的操作员（OP）在不同时刻（季节）采集样本。我只是对估计每个类别的平均值和方差总体感兴趣。
为了解决这个问题，我建立了一个线性混合模型，其中对因变量进行了平方变换。在测试了它们的重要性（AIC，BIC）之后，我将 OP 作为随机效应，将 CATEGORY 和 SEASON 作为固定效应。
 fit &lt;- nlme::lme(sqrt(MS) ~ CATEGORY + SEASON, random=~1|OP, data=dat
据我所知，每个 CATEGORY 中的估计平均值是每个固定效应值的对应 LSM。但是我不太清楚如何估计每个类别的方差。简化一下，我读到在一般线性回归中，模型的均方误差用于估计总体的方差，但在混合模型中，对于一些分组变量，我找不到任何关于如何计算它的解释。
也许每个固定效应的标准误差相当于MSE?
summary(fit)
固定效应：sqrt(MS) ~ CATEGORY + SEASON 
值 标准误差 DF t 值 p 值
(截距) 2.0142552 0.1127073 197 17.871557 0.0000
CATEGORYpiglets -0.2367893 0.1400533 197 -1.690708 0.0925
CATEGORYsows -0.8191891 0.1195440 197 -6.852615 0.0000
SEASONspring -0.0280369 0.02811633 194 -0.997177 0.3199
SEASONsummer -0.0126275 0.03969934 194 -0.318078 0.7508
SEASONoutom -0.0884407 0.02879816 194 -3.071054 0.0024

我的最终目标是估算覆盖 75% 人口的干物质含量值。你能帮我解决这个疑问吗？如果有用的话，我正在使用 R 中的 nlme 包。]]></description>
      <guid>https://stats.stackexchange.com/questions/658575/how-to-estimate-population-variance-from-a-mixed-model-with-a-categorical-variab</guid>
      <pubDate>Wed, 11 Dec 2024 13:37:53 GMT</pubDate>
    </item>
    <item>
      <title>MSVAR模型中协方差的标签切换问题</title>
      <link>https://stats.stackexchange.com/questions/658532/label-switching-issue-about-the-covariance-in-msvar-model</link>
      <description><![CDATA[假设我有一个简单的 MSVAR 模型，该模型具有 1 个滞后、2 个变量和 2 个状态，其中 VAR 项与状态无关：
状态 1：
$$y^{1}_t = y^1_{t-1} \cdot \gamma_{0,1} + y^{2}_{t-1} \cdot \gamma_{0,2} + \gamma_{1,1}$$
$$y^{2}_t = y^{1}_{t-1} \cdot \gamma_{0,1} + y^{2}_{t-1} \cdot \gamma_{0,2} + \gamma_{1,2}$$
协方差 1：$\Sigma^1=
\begin{pmatrix}
\Sigma^1_{11} &amp; \Sigma^1_{12} \\
\Sigma^1_{21} &amp; \Sigma^1_{22} 
\end{pmatrix} $
方案 2：
$$y^1_t = y^1_{t-1} \cdot \gamma_{0,1} + y^{2}_{t-1} \cdot \gamma_{0,2} + \gamma_{2,1}$$
$$y^2_t = y^1_{t-1} \cdot \gamma_{0,1} + y^{2}_{t-1} \cdot \gamma_{0,2} + \gamma_{2,2}$$
协方差 2：$\Sigma^2=
\begin{pmatrix}
\Sigma^2_{11} &amp; \Sigma^2_{12} \\
\Sigma^2_{21} &amp; \Sigma^2_{22} 
\end{pmatrix} $
由于我假设制度 1 是衰退，而制度 2 是扩张，根据它们的定义，限制应该是 $\gamma_{1,1} &lt; \gamma_{2,1}$ 和 $\gamma_{1,2} &lt; \gamma_{2,2}$，我认为这应该叫做全序？
有可能，当标签切换时，$\gamma_{1,1}$、$\gamma_{2,1}$和$\gamma_{1,2}$、$\gamma_{2,2}$可能在一次迭代内切换。
我的问题是，如果$\gamma_{1,1}$、$\gamma_{2,1}$和$\gamma_{1,2}$都可能在一次迭代内切换。
我的问题是，如果$\gamma_{1,1}$、$\gamma_{2,1}$和$\gamma_{1,2}$、$\gamma_{2,2}$对调了，我应该把$\Sigma^1$和$\Sigma^2$完全对调，这很容易。
不过我发现，只对调一对也是可以的，比如：
方案1：
\begin{align}
y^1_t &amp; = \text{lag_term} + “\boldsymbol{\gamma_{2,1}}” \\
y^2_t &amp; = \text{lag_term} + \gamma_{1,2}
\end{align&gt;
方案 2：
\begin{align}
y^1_t &amp; = \text{lag_term} + “\boldsymbol{\gamma_{1,1}}” \\
y^2_t &amp; = \text{lag_term} + \gamma_{2,2}
\end{align&gt;
例如，$\gamma_{1,1} &gt; \gamma_{2,1}$ 和 $\gamma_{1,2} &lt; \gamma_{2,2}$，在这种情况下，我认为我应该交换元素 $\Sigma^1_{11}$ 和 $\Sigma^2_{11}$，但我不确定协方差矩阵中的非对角线元素，我应该如何处理 $\Sigma^1_{12}, \Sigma^1_{21}, \Sigma^2_{12}, \Sigma^2_{21}$？
顺便说一句，在实践中，我想也许我可以简单地删除任何违反我的全序的链中的所有迭代？或者，我可以丢弃变量间有冲突的迭代。通过这样做，我可以更容易地实现依赖于后验均值的 DIC？]]></description>
      <guid>https://stats.stackexchange.com/questions/658532/label-switching-issue-about-the-covariance-in-msvar-model</guid>
      <pubDate>Tue, 10 Dec 2024 16:09:35 GMT</pubDate>
    </item>
    <item>
      <title>如何排列 p 值？</title>
      <link>https://stats.stackexchange.com/questions/658523/how-to-permute-p-values</link>
      <description><![CDATA[最近，我的同事在处理一个数据集 df_a 时遇到了一个问题，该数据集包含基因数据。每一行代表一个 基因（通常有数千个，但为了简单起见，我们假设有 1,000 个），列代表不同的样本，这些样本可以分为两组，A 和 B（每组 50 个样本）。
我们使用 t.test 计算每行的 p 值并进行校正。假设我们使用 p.adjust &lt; 0.05 并且得到 30 个阳性结果。
这带来了一个问题：我们如何确保这 30 个结果不是由随机事件产生的？（也许这个问题是一个问题？）
我们设计了一个使用置换检验的流程来解决这个问题。步骤如下：
(1) 对于 df_a，我们随机打乱其列标签，重新计算每行的 p 值和 p.adjust，并计算 p.adjust &lt; 0.05 的行数，记为 Ki。
(2) 重复步骤 1 1,000 次，得到 K1,K2,K3,...,K1000。
(3) 计算大于 30 的 Ki 的数量，记为 n。计算 n/1000。如果该值小于 0.05，我们认为这 30 个结果不是由随机事件产生的。
作为一名程序员，我意识到这在数学上似乎存在问题，但我无法向同事提供严谨的证明来纠正它。希望得到您的帮助。
更新
我想更新的是，我认为这种排列不能提供有意义的附加信息。考虑一下当您对列标签进行混洗时，对于每一行，这相当于将组 A 和 B 混合在一起，然后随机抽取两组 A* 和 B*。基本的统计学原理告诉我们，这两组之间应该没有差异。因此，当您应用 t.test 时，所有 p.values &lt; 0.05 都是假阳性，显著性数字约为 5%。当你对这些数据应用p.adjust（例如使用FDR），并再次控制p.adjust &lt; 0.05时，这里的Ki将（始终）非常小（接近于0），以至于不可能否定任何结果。
我不是数学家，但通过程序模拟很容易看出这一点。我的观点是，当排列数有限（例如：1000）时，Ki的数学期望是一个与行数据相关的常数，并且这个值非常小。
请务必注意我们的步骤与经典排列测试之间的区别，它们非常相似，但存在差异。
我不知道这在数学上是否成立以及如何证明它。]]></description>
      <guid>https://stats.stackexchange.com/questions/658523/how-to-permute-p-values</guid>
      <pubDate>Tue, 10 Dec 2024 14:31:46 GMT</pubDate>
    </item>
    </channel>
</rss>