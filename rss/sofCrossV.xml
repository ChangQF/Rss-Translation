<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 14 Oct 2024 06:25:36 GMT</lastBuildDate>
    <item>
      <title>如何解释自动编码器异常检测的重建误差？</title>
      <link>https://stats.stackexchange.com/questions/655738/how-to-interpret-reconstruction-error-for-anomaly-detection-with-autoencoders</link>
      <description><![CDATA[我有一个基于神经网络的自动编码器。该模型使用 SCADA 数据进行训练。我在异常检测方面取得了不错的结果，主要指标（召回率、准确率、精确率和 F1 分数）约为 85%。
当我开始分析异常期间的重构误差时，我发现对异常贡献最大的参数不一定与其原因有关。
“id”参数对重构误差 (RE) 的贡献约为 50-60%，而应与异常相关的参数对 RE 的贡献仅为 10%。“other”参数表示所有非“id”参数的总和。下图显示了此行为：

此行为不仅出现在此数据集中，还出现在其他异常中。这些数据集相当大，最小的数据集有大约 100 个参数，最大的数据集有 600 个参数，每个数据集都有超过 5 年的数据和 10 分钟的粒度。因此，我认为这不是由于缺乏数据造成的。
我尝试删除“id”参数，但这显著影响了主要指标，使其下降到大约 50-60%。
关于“id”参数，它与时间具有很强的相关性，是一个正的单调序列。
即使模型很好地检测了异常，这种行为是否会使其不可靠？我发现一个可能的解释是，给定输入及其特定条件，自动编码器会为输入预测不同的“id”/时间。我认为该模型可能已经隐式地学习了涡轮机运行的时间特征。结果，它确定给定的条件与预期的时间模式不一致。
这个解释看起来合理吗？我也接受改进模型的建议。
我用不同的数据集验证了模型，尝试用 optuna 超参数优化改进自动编码器，并尝试了不同的数据处理。所有的尝试都导致了相同的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/655738/how-to-interpret-reconstruction-error-for-anomaly-detection-with-autoencoders</guid>
      <pubDate>Mon, 14 Oct 2024 01:38:15 GMT</pubDate>
    </item>
    <item>
      <title>心血管疾病患者中的肥胖悖论可以通过错误控制介质来解释吗？</title>
      <link>https://stats.stackexchange.com/questions/655736/can-obesity-paradox-among-subjects-with-cardiovascular-disease-be-explained-by-i</link>
      <description><![CDATA[鉴于以下因果关系图：
肥胖 -&gt; 心血管疾病 -&gt; 死亡率
肥胖是心血管疾病 (CVD) 的致病因素，那么得出这样的结论是否合理：由于 CVD 是介质，因此对患有 CVD 的受试者进行条件反射会导致治疗效果估计出现偏差？
这可能无法完全解释偏差，但我认为可以解释其中很大一部分。]]></description>
      <guid>https://stats.stackexchange.com/questions/655736/can-obesity-paradox-among-subjects-with-cardiovascular-disease-be-explained-by-i</guid>
      <pubDate>Mon, 14 Oct 2024 00:10:16 GMT</pubDate>
    </item>
    <item>
      <title>当我们将多个参数合并为一个时，这叫什么？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655733/what-is-it-called-when-we-collapse-many-parameters-in-one</link>
      <description><![CDATA[当我们将同一事物的许多参数放在一起产生一个标量值时，我们称该操作为什么？特别是当它不仅涉及参数的简单总结（甚至可能带有权重）时，还涉及更复杂的“合并”时？
例如，当我们考虑某些项目的可排序参数属性，如大小、亮度、光的波长、距离等，然后我们提供对这些属性的偏好，并要求按某些公共值进行排序，这些公共值是这些独立值的一种“总和”。
我想到的是：卷积、合并、组合、降维、“标量化”、投影等。
这有什么通用术语吗？
具体示例

我有一组恒星，它们的距离、年龄、大小、光的波长峰值、距离都是已知的，并且我有自己的观察偏好。现在，我不想根据每个参数单独对它们进行排序，而是根据我的偏好基于所有参数进行排序。

我有由字符编译的单词，我根据字符、使用频率、是否是子序列的一部分、是否位于单词的开头和结尾等来计算单词相似性的不同方面。因此，每个这样的指标都会给出一个值。现在我需要想出一个值作为相似性的答案。我必须将各个（通常是正交的）指标卷积为一个。

]]></description>
      <guid>https://stats.stackexchange.com/questions/655733/what-is-it-called-when-we-collapse-many-parameters-in-one</guid>
      <pubDate>Sun, 13 Oct 2024 21:02:33 GMT</pubDate>
    </item>
    <item>
      <title>似然函数简化的证明[重复]</title>
      <link>https://stats.stackexchange.com/questions/655732/proof-of-the-simplification-of-the-likelihood-function</link>
      <description><![CDATA[许多参考文献都指出，在$x_1,x_2,\ldots x_n$为独立同分布的假设下，似然函数可以简化如下：
$$P(x_1,x_2,\ldots ,x_n|\theta)=P(x_1|\theta)P(x_2|\theta)\ldots P(x_n|\theta)$$
不幸的是，大多数参考文献都认为这种简化是理所当然的，而没有提供任何证明或解释。
上述简化背后的证明是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655732/proof-of-the-simplification-of-the-likelihood-function</guid>
      <pubDate>Sun, 13 Oct 2024 20:33:21 GMT</pubDate>
    </item>
    <item>
      <title>R 与 Python 在学术生物统计学研究中的比较？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655731/r-vs-python-in-academic-biostatistics-research</link>
      <description><![CDATA[我很好奇，想听听你对在学术生物统计学或密切相关领域（例如统计学、生物信息学、数据科学）学习 R 与 Python 的重要性的看法。
背景：

我使用 R 已经超过 10 年了，从未遇到过无法用它解决的问题。我对 R 非常熟练，并且很熟悉。
但是，我想知道学习 Python 对于学术界的职业发展，尤其是在生物统计学领域，有多重要。

问题：

对于像我这样拥有丰富 R 经验的人来说，你认为学习 Python 对于生物统计学或类似领域的学术生涯有多重要？
你是否认为 Python（甚至是 Julia）未来可能会在学术界取代 R？我是否应该担心 R 会随着时间的推移变得不那么重要？

就我个人而言，我更愿意坚持使用 R，因为它目前满足了我所有的需求。但如果这对于保持该领域的竞争力至关重要，我愿意学习新工具。我也很想知道你对精通多种统计编程语言（如 Python 或 Julia）是否具有显著优势的看法。]]></description>
      <guid>https://stats.stackexchange.com/questions/655731/r-vs-python-in-academic-biostatistics-research</guid>
      <pubDate>Sun, 13 Oct 2024 20:04:51 GMT</pubDate>
    </item>
    <item>
      <title>当连续变量等于 0 时创建虚拟变量</title>
      <link>https://stats.stackexchange.com/questions/655727/creating-a-dummy-variable-when-the-continuous-variable-is-equal-to-0</link>
      <description><![CDATA[我实际上是在尝试寻找最佳解释变量，以便估计我的投资组合中交易对手违约的概率。在定义了变量的长列表之后，我正在通过单变量逻辑回归测试每个变量。每个变量的评估都考虑了三个条件：

统计上显著的估计，即 p 值 &lt; 5%；
估计系数的符号（beta 符号）与经济预期一致；
足够的判别力，即 Somers 的 D &gt; 5%

但是，专注于成本变量，首先我尝试通过消除成本量等于零的观察值来考虑该变量。该变量通过了上述所有标准，但 Somer 的 D 较低（30%）。此外，我认为这不是最好的方法，因为零是真正的零，而不是缺失值。因此，我考虑创建一个虚拟变量以保留所有观察值。我创建了一个虚拟变量，如下所示：

当正连续变量等于 0 时，虚拟变量等于 1。
否则为 0。

因此，我执行了以下 logit 回归：
proc logistic data= want plots=ROC;
model perceived_default = Continuous_variable dummy_variable 
run;

根据 Somers 的 $D$ (60%)，结果相当不错，但虚拟变量并不显著（$p$ 值等于 $0.35$）。
我该如何处理这个问题？即使虚拟变量不显著，我是否可以将其保留在模型中？我认为问题出现是因为虚拟变量在构造上与连续变量共线。
最后，在单变量回归之后，我将通过逐步选择来估计多变量回归。]]></description>
      <guid>https://stats.stackexchange.com/questions/655727/creating-a-dummy-variable-when-the-continuous-variable-is-equal-to-0</guid>
      <pubDate>Sun, 13 Oct 2024 16:59:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么自动编码器的潜在空间中不希望有空洞？</title>
      <link>https://stats.stackexchange.com/questions/655726/why-holes-are-not-desirable-in-latent-space-of-autoencoders</link>
      <description><![CDATA[在几项关于自动编码器的研究中，已经指出，普通自动编码器（没有任何正则化的自动编码器）可能会受到潜在空间中空洞的影响。空洞的含义被描述为自动编码器潜在空间中的不连续区域。我无法理解两件事
I) 不连续区域。我认为这意味着将数据映射到潜在空间后获得的流形不连续。
II) 为什么它们不可取？
链接- 在此处输入链接描述（参见第 2 节）]]></description>
      <guid>https://stats.stackexchange.com/questions/655726/why-holes-are-not-desirable-in-latent-space-of-autoencoders</guid>
      <pubDate>Sun, 13 Oct 2024 15:15:51 GMT</pubDate>
    </item>
    <item>
      <title>测量分布均匀性</title>
      <link>https://stats.stackexchange.com/questions/655696/measure-for-distribution-uniformity</link>
      <description><![CDATA[是否有某种度量和计算方法，以区分均匀分布在范围内的值和具有许多峰值（其数量）的值？
例如，区分如下序列：
示例 1：1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2

带有
示例 2：1、1、1、1、1、2、1、2、2、2、2、2、1、2、1、2、1、2、1、1、1、1、 1, 2, 2, 2, 2 

和
示例 3：1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2

我正在寻找一个指标，当值（这里假设为 2）均匀分布在序列中时，该指标接近 0，当所有这些值集中在一个地方时，该指标接近 1；当我有像示例 2 中那样的本地组时，我希望该指标接近 0.5，而在示例 3 中，我希望该指标接近 0.7。这些值只是为了解释逻辑，当然，它们是近似的。
例如，如果问题是关于一个峰值，我会使用平均值和方差。但如果有很多峰值，情况就会有所不同。
是否存在这样的指标（或类似指标）？
一些背景知识
我想要一个度量，它可以说明文本中的特定词素（用数字表示）是否分布均匀（如代词）或这是一个术语（如“排列”），它将倾向于在大型文本库中大量出现数学书籍。]]></description>
      <guid>https://stats.stackexchange.com/questions/655696/measure-for-distribution-uniformity</guid>
      <pubDate>Sat, 12 Oct 2024 16:29:13 GMT</pubDate>
    </item>
    <item>
      <title>回归均值的行为</title>
      <link>https://stats.stackexchange.com/questions/655691/behaviour-of-regression-toward-the-mean</link>
      <description><![CDATA[我有一个包含 801 人（男性和女性）左右脚长度的数据集。据我所知，这是一个教学数据集，没有任何具体问题或特殊之处。
以下是均值和协方差矩阵，单位为厘米：
## 均值
LengthRightFoot LengthLeftFoot 
24.3 24.3 

## 协方差矩阵
LengthRightFoot LengthLeftFoot
LengthRightFoot 6.34 6.08
LengthLeftFoot 6.08 6.31

左脚对右脚的回归表明，与直觉相反，斜率略低于 1，截距高于 0（见下文）。我认为这是由于向均值回归。到目前为止一切顺利，除非你有更好的解释。
令我困惑的是，截距可疑地接近 1（0.99877）。当然，0.99877 是一个和其他数字一样的数字，但我想知道截距几乎正好是 1 的原因是什么。你能解释一下吗？

调用：
lm(formula = LengthLeftFoot ~ LengthRightFoot)

残差：
最小 1Q 中位数 3Q 最大 
-2.254 -0.239 -0.025 0.187 8.823 

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.99877 0.23741 4.21 2.9e-05 ***
LengthRightFoot 0.95891 0.00973 98.50 &lt; 2e-16 ***
---
有效代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：799 个自由度上的 0.693
多重 R 平方：0.924，调整后的 R 平方：0.924
F 统计量：1 和 799 DF 上的 9.7e+03，p 值：&lt;2e-16


此 R 模拟生成一个包含 50000 个观测值的数据集，其协方差矩阵与真实值相似。回归重现了上述发现：
mu &lt;- c(24.3, 24.3)
covmat &lt;- structure(c(6.33766534019975, 6.07723639200999, 
6.07723639200999, 6.3073693196005), dim = c(2L, 2L), 
dimnames = list(c(&quot;LengthRightFoot&quot;, 
&quot;LengthLeftFoot&quot;), c(&quot;LengthRightFoot&quot;, &quot;LengthLeftFoot&quot;)))

sim &lt;- as.data.frame(mvrnorm(n=50000, mu=mu, Sigma=covmat))

模拟数据的回归：
summary(lm(LengthLeftFoot ~ LengthRightFoot, data=sim))
调用：
lm(formula = LengthLeftFoot ~ LengthRightFoot, data = sim)

残差：
最小值 1Q 中位数 3Q 最大值 
-2.9058 -0.4683 -0.0034 0.4622 2.7255 

系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 1.037961 0.030047 34.55 &lt;2e-16 ***
LengthRightFoot 0.957488 0.001231 777.63 &lt;2e-16 ***
---
有效代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：49998 自由度上的 0.6921
多重 R 平方：0.9236，调整后的 R 平方：0.9236
F 统计量：1 和 49998 DF 上的 6.047e+05，p 值：&lt; 2.2e-16
]]></description>
      <guid>https://stats.stackexchange.com/questions/655691/behaviour-of-regression-toward-the-mean</guid>
      <pubDate>Sat, 12 Oct 2024 15:21:33 GMT</pubDate>
    </item>
    <item>
      <title>如何制作两个完全负相关的增长几何布朗运动（GBM）系列？</title>
      <link>https://stats.stackexchange.com/questions/655735/how-to-make-two-perfectly-negatively-correlated-growing-geometric-brownian-motio</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655735/how-to-make-two-perfectly-negatively-correlated-growing-geometric-brownian-motio</guid>
      <pubDate>Fri, 11 Oct 2024 23:13:17 GMT</pubDate>
    </item>
    <item>
      <title>估计概率值大于来自未知分布的 x</title>
      <link>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</link>
      <description><![CDATA[假设我们有 N 个项目的总体，其值从 0 到 6000。
假设总体的平均值是 $\mu$。
我们不知道项目的分布。
我们从这个总体中提取一个项目，我们如何估计 $P(x\geq 2500)$？
同样的问题，假设分布是均匀的。
已编辑：
我们只有关于 $P(x&gt;y)$ 的以下信息：

$x \in [0, 6000]; x \in \Re$
$\mu = 1200$
我们想使用二次损失函数进行估算
]]></description>
      <guid>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</guid>
      <pubDate>Fri, 11 Oct 2024 08:52:55 GMT</pubDate>
    </item>
    <item>
      <title>有人能解释一下为什么“正统统计”需要辅助统计吗？</title>
      <link>https://stats.stackexchange.com/questions/655018/can-someone-explain-why-ancillary-statistic-is-needed-in-orthodox-statistics</link>
      <description><![CDATA[我正在阅读 Jaynes 的《概率论：科学的逻辑》。在第 8 章中，Jaynes 讨论了“正统”环境中的辅助统计问题，他说辅助统计是出于以下原因而需要的：

我对他的说法有点困惑。他说“人们有义务得出结论，无论样本的配置如何，给定估计量的所有估计都具有相同的准确性。”为什么会这样？如果两个数据集具有相同的平均值但不同的方差，那么假设估计量会对“准确性”给出不同的估计值是否很自然？]]></description>
      <guid>https://stats.stackexchange.com/questions/655018/can-someone-explain-why-ancillary-statistic-is-needed-in-orthodox-statistics</guid>
      <pubDate>Fri, 27 Sep 2024 15:33:23 GMT</pubDate>
    </item>
    <item>
      <title>Wald-Wolfowitz 对白噪声进行检验</title>
      <link>https://stats.stackexchange.com/questions/653385/wald-wolfowitz-runs-test-on-white-noise</link>
      <description><![CDATA[我正在寻找方法来检查时间序列是否不同于白噪声 (WN)。我可以直接检查均值是否为零、方差是否为常数以及所有滞后处的自相关是否为零，然后我就会这样做。但除了这些要点之外，应用 Wald-Wolfowitz (WW) 运行检验是否有意义？*我偶然遇到了它（在 R 中的 randtests::runs.test 中实现），并且不确定在这种情况下该如何理解它。
*我的意思是，如果过程是 WN，是否意味着它必须通过 WW 运行检验，前提是具有完美的估计精度（例如来自 WN 的无限样本路径）？]]></description>
      <guid>https://stats.stackexchange.com/questions/653385/wald-wolfowitz-runs-test-on-white-noise</guid>
      <pubDate>Tue, 27 Aug 2024 07:36:53 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 符号秩检验与符号检验假设</title>
      <link>https://stats.stackexchange.com/questions/652389/wilcoxon-signed-rank-test-vs-sign-test-assumptions</link>
      <description><![CDATA[必须检查符号检验的哪些假设？
如果符号检验也无效，那么替代方案是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652389/wilcoxon-signed-rank-test-vs-sign-test-assumptions</guid>
      <pubDate>Tue, 06 Aug 2024 17:16:02 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 cox ph 模型的分数残差？</title>
      <link>https://stats.stackexchange.com/questions/615409/how-to-calculate-score-residual-for-cox-ph-model</link>
      <description><![CDATA[我尝试理解 R 中 cox ph 模型中的“残差得分”。
我使用过一个参考网站。
有人能帮我在 R 中手动（我的意思是使用公式）获取残差得分吗？
library(survival)

cph1 &lt;- coxph(Surv(futime, fustat)~rx+age , data=ovarian)

残差 &lt;- residuals(cph1, type=&quot;score&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/615409/how-to-calculate-score-residual-for-cox-ph-model</guid>
      <pubDate>Wed, 10 May 2023 08:21:39 GMT</pubDate>
    </item>
    </channel>
</rss>