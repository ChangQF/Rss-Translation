<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 31 Oct 2024 09:17:38 GMT</lastBuildDate>
    <item>
      <title>如何计算合并标准误差</title>
      <link>https://stats.stackexchange.com/questions/656530/how-to-compute-a-pooled-standard-error</link>
      <description><![CDATA[我正在 $d$ 个数据集中比较 $m$ 个方法。通过我的实验，我获得了所有方法和所有数据集的平均值、标准差和标准误差，因此我有平均值
$$
\bar x_{1,1}, \dots, \bar x_{1, m},
\\
\vdots
\\
\bar x_{d,1}, \dots, \bar x_{d, m},
$$
和标准误差
$$
\hat s_{1,1}, \dots, \hat s_{1, m},
\\
\vdots
\\
\hat s_{d,1}, \dots, \hat s_{d, m}.
$$
我想针对所有数据集中每个方法做出声明，即我想汇总这两个数量。因此，我非常确定我可以计算每个方法的平均值 $k$，因为
$$
\bar X_k = \frac 1 d \sum_{i=1}^d \bar x_{i, k}
$$
但我该如何处理标准误差？是否可以以类似的方式组合它们，即
$$
\hat S_k = \sqrt{\frac 1 d} \; \sum_{i = 1}^d \hat s_{i, k},
$$
或者我需要以不同的方式处理这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/656530/how-to-compute-a-pooled-standard-error</guid>
      <pubDate>Thu, 31 Oct 2024 08:34:35 GMT</pubDate>
    </item>
    <item>
      <title>是否可以将二阶增长斜率因子建模为另一个二阶增长斜率因子的中介？</title>
      <link>https://stats.stackexchange.com/questions/656529/is-it-possible-to-model-a-second-order-growth-slope-factor-as-a-mediator-of-anot</link>
      <description><![CDATA[我正在运行一个包含三个变量的二阶增长模型。
我的数据涵盖了 7 波数据。我目前正在运行一个多元增长模型，该模型模拟了多个增长因素的关联关系。
我听说，对于是否可以将显示增长因素关联关系的双头箭头改为单头箭头，并没有达成真正的共识，这将更清楚地表明因素之间的关系方向。
无论如何，我想知道是否有办法将我的三个增长因素之一建模为其他两个的中介。因此，
增长斜率因子 A -&gt; 增长斜率因子 B（中介）-&gt; 斜率增长因子 C
这种模型。
如果有人知道这种模型，那将非常有帮助。
感谢您一直以来的支持。]]></description>
      <guid>https://stats.stackexchange.com/questions/656529/is-it-possible-to-model-a-second-order-growth-slope-factor-as-a-mediator-of-anot</guid>
      <pubDate>Thu, 31 Oct 2024 07:39:43 GMT</pubDate>
    </item>
    <item>
      <title>添加或乘以常数时的收敛和有界性</title>
      <link>https://stats.stackexchange.com/questions/656527/convergence-and-boundedness-when-a-constant-is-added-or-multiplied</link>
      <description><![CDATA[已知 $X_{n} = O_p(a_n)$ 和 $Y_n - c = O_p(a_n)$，其中 $a_n$ 是一个趋于零的序列。鉴于此，我想证明 $X_{n}/Y_n = O_p(a_n)$。
由于 $a_n$ 趋于零，我们可以说 $X_{n} = o_p(1)$，类似地 $Y_n - c = o_p(1)$。这反过来意味着 $Y_n - c = O_p(1)$。这里的 c 是一个常数。如果我们说 $Y_n - c$ 是随机有界的，那么我们是否也可以说 $Y_n$ 本身是随机有界的。因此，如果 $X_{n} = o_p(1)$ 或以概率收敛到 0，那么 $X_{n}/Y_n$ 也以概率收敛到 0？此外，我们是否可以说，由于$X_{n} = o_p(1)$，所以$X_{n}/c 也是如此？
我想利用$X_n/Y_n = X_n/c + (X_n/Y_n)(c-Y_n)(1/c)$这一事实来得出所需的结果。如果有更好的方法，请告诉我！谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656527/convergence-and-boundedness-when-a-constant-is-added-or-multiplied</guid>
      <pubDate>Thu, 31 Oct 2024 07:04:37 GMT</pubDate>
    </item>
    <item>
      <title>对回归方程中的术语“固定效应”和向量符号的困惑</title>
      <link>https://stats.stackexchange.com/questions/656526/confusion-over-the-terminology-fixed-effects-and-vector-notation-in-regression</link>
      <description><![CDATA[我无法理解经济学期刊中看到的回归方程，我不确定这是否是我无法理解的符号/惯例，或者是术语“固定效应”，我将其解释为指示函数。下面是一个例子。
$Y_{ijt}=\beta_0 Indicator + \mathbf{\delta}\mathbf{X}_{ijt} + \mathbf{\tau}_{rt}+\epsilon_{ijt}$，其中 $i$、$j$ 和 $t$ 分别代表城市、月份和年份。
作者声称 $\delta$、$\textbf{X}_{ijt}$ 和 $\tau_{rt}$ 是向量，因为它们以粗体显示。在我看来，$\delta\textbf{X}_{ijt}$ 的真正含义是 $\delta$ 和 $\textbf{X}_{ijt}$ 之间的点积，但 $\tau_{rt}$ 怎么会是向量呢？具体来说，作者提到 $\tau_{rt}$ 是区域逐年固定效应，例如 $(region_1 2020, region_1 2021,...)$。我的想法是，作者所说的 $\tau_{rt}$ 实际上是指 $\sum_r f_{rt}$，其中每个 $f_{rt}$ 都是对应于固定区域 $r$ 和年份 $t$ 的指示函数。这种解释正确吗？如果正确，在回归方程中滥用这样的符号/术语是否很常见？]]></description>
      <guid>https://stats.stackexchange.com/questions/656526/confusion-over-the-terminology-fixed-effects-and-vector-notation-in-regression</guid>
      <pubDate>Thu, 31 Oct 2024 03:52:31 GMT</pubDate>
    </item>
    <item>
      <title>一般来说，我们是否应该在 SEM 分析中删除所有不显著的路径？</title>
      <link>https://stats.stackexchange.com/questions/656523/generally-are-we-supposed-to-remove-all-nonsignificant-paths-in-an-sem-analysis</link>
      <description><![CDATA[鉴于我们在科学中主张简约，如果非显著路径不会导致模型拟合度明显下降，我们是否应该删除这些不显著的路径？
在我们删除不显著的路径后，其他路径也变得不显著，我们是否继续删除路径，直到所有路径都具有统计显著性（当然，如果它们不会导致模型拟合度下降）？
如果不是，那么我们如何决定删除哪条路径？]]></description>
      <guid>https://stats.stackexchange.com/questions/656523/generally-are-we-supposed-to-remove-all-nonsignificant-paths-in-an-sem-analysis</guid>
      <pubDate>Thu, 31 Oct 2024 01:41:25 GMT</pubDate>
    </item>
    <item>
      <title>我该如何在这个实验中进行显著性检验？</title>
      <link>https://stats.stackexchange.com/questions/656519/how-do-i-do-significance-testing-in-this-experiment</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656519/how-do-i-do-significance-testing-in-this-experiment</guid>
      <pubDate>Wed, 30 Oct 2024 22:58:18 GMT</pubDate>
    </item>
    <item>
      <title>比较逻辑回归系数</title>
      <link>https://stats.stackexchange.com/questions/656518/comparing-logistic-regression-coefficients</link>
      <description><![CDATA[我有代表个体群体和感兴趣的二元结果的数据。协变量本​​身通常是概率。例如，协变量 1 到 5 是此个体属于组 1（到 5）的概率的估计值。还有其他非概率协变量。
我已选择组 1 作为我的参考组，我很想测试以下假设：“属于组 $j$ 与结果 $d$ 的关联性高于参考组”，其中 $j=2, ..., 5$ 和某个预定阈值 $d$。例如，我的结果可能是“是否被捕”，我的群体成员协变量可能是人口统计估计值，而我的其他协变量可能是涉嫌犯罪的各个方面。如果 $d=0.1$，那么我试图回答这个问题“成为人口统计 $j$ 的成员是否会使一个人的被捕率（与参考人口统计相比）至少增加 10 个百分点？”
我正在使用 statsmodels 在 Python 中运行逻辑回归，我很好奇执行完整分析的正确过程是什么。特别是：

我应该标准化（0 均值，单位标准差）我的数据吗？对于非群体成员协变量，我认为答案是“是”——我并不特别关心那些系数。对于组成员协变量，输出介于 0 和 1 之间（概率）。我的人口分布不均匀：其中一些组成员协变量的均值接近 0.8，而其他均值接近 0.1。

回归后，我是否需要以某种方式转换系数才能进行假设检验？（例如，从对数几率转向……其他东西？）

有了系数后，如何正确地将每个组的结果与参考组的结果加上 $c$ 进行比较？我应该按照 regression_results.wald_test(&quot;(group2 + d = const)&quot;) 的方式运行 Wald 检验（或 F 检验？或 T 检验？或其他东西）吗？我想做一个关于自卑、优越和平等的测试，因为我有三个感兴趣的结果：（a）这个组的结果可能小于参考组的$+d$；（b）这个组的结果可能大于参考组的$+d$；（c）我们不知道哪个更大。


最后一行问题可能有点草率，我很抱歉在假设检验方面没有更好的基础。我来自机器学习领域，我想象用 95% 的置信区间 $\beta_j - const$ 来回答我的问题，其中 $\beta_j$ 是组 $j$ 成员的系数。可视化置信区间，要么整个值小于 $d$，要么整个值大于 $d$，要么它包含 $d$。这些结果中的每一个都会推动不同的决策。对于 (a)，我们可能对所分析的系统感到满意。对于 (b)，我们认为所分析的系统存在需要修复的问题。对于 (c)，我们无法判断是否存在问题，可能需要收集更多数据或采取其他方法。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/656518/comparing-logistic-regression-coefficients</guid>
      <pubDate>Wed, 30 Oct 2024 20:23:17 GMT</pubDate>
    </item>
    <item>
      <title>将 Shapley 值应用于分类</title>
      <link>https://stats.stackexchange.com/questions/656514/applying-shapley-values-to-classification</link>
      <description><![CDATA[根据 Štrumbelj 和 Kononenko (2013) 的定义，Shapley 值是为回归预测而定义的。
然而，当分类器不仅产生类别，而且产生类别概率 $P(\omega_i|x)$ 时，它们也应该适用于分类。问题是，这会为每个特征产生 $C$ 个 Shapley 值，其中 $C$ 是可能的类 $\omega_i$ 的数量。
问题：有没有办法将这些值组合成每个特征的单个值，以表示该特征对决策的贡献？
R 中的示例：一个简单的高斯贝叶斯分类器，也称为“鸢尾花数据集的二次判别分析”，其 Shapley 值由 Kernel SHAP 估计（假设特征独立）：
library(MASS)
library(kernelshap)

# 覆盖预测以返回类概率
mypredict &lt;- function(model, ...) {
res &lt;- MASS:::predict.qda(model, ...)
return(res$posterior)
}

model &lt;- qda(Species ~ ., iris)
s &lt;- kernelshap(model, iris[,-5], pred_fun=mypredict)

# 第一个鸢尾花样本的 Shapley 值
print(lapply(s$S, function(x) {x[1,]}))

返回
$setosa
Sepal.Length Sepal.Width Petal.Length Petal.Width 
-0.01393733 0.01488391 0.43523643 0.23048366 

$versicolor
Sepal.Length Sepal.Width Petal.Length Petal.Width 
-0.02314857 0.01283692 -0.14713220 -0.16850077 

$virginica
萼片长度 萼片宽度 花瓣长度 花瓣宽度 
0.03708591 -0.02772083 -0.28810423 -0.06198289 
]]></description>
      <guid>https://stats.stackexchange.com/questions/656514/applying-shapley-values-to-classification</guid>
      <pubDate>Wed, 30 Oct 2024 16:22:45 GMT</pubDate>
    </item>
    <item>
      <title>从等于两个已知 PDF f(x) 和 g(x) 乘积的 PDF 中采样</title>
      <link>https://stats.stackexchange.com/questions/656469/sampling-from-a-pdf-equal-to-a-product-of-two-known-pdfs-fx-and-gx</link>
      <description><![CDATA[假设我们有两个已知的 PDF $f(x)$ 和 $g(x)$（我们也可以简单地从两个分布中抽样）。
如果相应的 PDF/CDF 无法轻易识别（$k$ 是标准化因子），如何抽样 $k \cdot f \cdot g\,(x)$？具体来说，我正在寻找对 PDF 进行采样，它是 $\mathsf{LogNorm}(\mu_a,\sigma_a)$ 和 $\mathsf{Norm}(\mu_b,\sigma_b)$ 的乘积。
我的目的是应用&quot;weight&quot;使用给定的 $\mathsf{Norm}$ 计算原始 $\mathsf{LogNorm}$ 的概率。
我找到了 Metropolis–Hastings 算法，但我想知道对于 $\mathsf{LogNorm}$ 和 $\mathsf{Norm}$ 分布的乘积的特殊情况，是否有更简单的算法？
一些示例可以澄清我的问题：

这里，有人询问“混合”分布。从呈现的直方图来看，我可以说这可能是我正在寻找的。不幸的是，OP没有说明如何进行采样。
这里，有人谈到“Metropolis-Hastings 算法”对于似乎与我的情况相同的情况的效率。
]]></description>
      <guid>https://stats.stackexchange.com/questions/656469/sampling-from-a-pdf-equal-to-a-product-of-two-known-pdfs-fx-and-gx</guid>
      <pubDate>Tue, 29 Oct 2024 16:23:08 GMT</pubDate>
    </item>
    <item>
      <title>为什么与变量相关的因子得分不等于载荷？</title>
      <link>https://stats.stackexchange.com/questions/656459/why-factor-scores-correlated-with-variables-do-not-equal-loadings</link>
      <description><![CDATA[我试图理解以下内容：
我有三个变量（x1、x2、x3），我在 SPSS 中对它们进行了 PCA 和 EFA（主轴分解）以获得一个成分/因子。
如果我进行 PCA 并计算因子得分（回归方法），我将其称为变量“F”，则：Cor(x1, F)=成分载荷，x2 和 x3 也是如此。
如果我对 PFA 执行相同操作，那么我显然会得到不同的载荷和因子得分，但同时：
Cor(x1, F) 不再等于载荷（但只是近似值）。
有人能解释一下为什么会这样吗？
相关性（n=12）：
x1-x2：0.310

x2-x3：0.153

x1-x3：0.529

输出：
成分载荷（PCA）：

x1：0.863；
x2：0.564；
x3：0.790

Cor(x，成分得分) 准确重现了成分载荷。
因子载荷 (PFA)：

x1：0.956，x2：0.313，x3：0.548

Cor(x，因子得分) 不重现因子载荷，但是：
Cor(x1，F) = 0.998
Cor (x2，F) = 0.327
Cor (x3，F) = 0.573

计算因子载荷时输出 SPSS：“尝试提取 1 个因子。需要超过 25 次迭代（收敛=0,006）。提取已终止”。]]></description>
      <guid>https://stats.stackexchange.com/questions/656459/why-factor-scores-correlated-with-variables-do-not-equal-loadings</guid>
      <pubDate>Tue, 29 Oct 2024 14:09:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么通过 RFE 选择不同百分比的特征进行基于 SVM 的分类时，不同的实验会产生不一致的结果？</title>
      <link>https://stats.stackexchange.com/questions/656331/why-do-results-from-various-experiments-with-different-of-features-selected-th</link>
      <description><![CDATA[我现在对随机森林、梯度提升树和支持向量机等分类器有了基本的了解。我的任务包括对由光学和雷达卫星图像组成的图层堆栈进行分类，其中波段代表特征。目标是区分各种土地利用和土地覆盖类别，例如森林、农业用地、水体等。
我目前的重点是对由光学和雷达卫星图像组成的图层堆栈进行分类，其中各个波段是关键特征。目标是有效区分各种土地利用和土地覆盖类别，例如森林、农业用地、水体等。
我正在分析由代表与特定类别相关的光谱值的样本组成的大量数据集。为了改进模型，我正在对每个分类器的多个场景应用递归特征消除，在再训练过程中利用 70%、80%、90% 和 100% 的特征。初步结果表明，随机森林和梯度提升树的性能基本保持一致，特征的相对重要性在不同场景中表现出稳定性。相比之下，支持向量机的性能则显示出基于场景的特征重要性存在显著差异，凸显出独特的操作动态。欢迎您就这些发现提出任何见解或反馈。
]]></description>
      <guid>https://stats.stackexchange.com/questions/656331/why-do-results-from-various-experiments-with-different-of-features-selected-th</guid>
      <pubDate>Fri, 25 Oct 2024 21:37:52 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 如何保证以牛顿法下降？</title>
      <link>https://stats.stackexchange.com/questions/656049/how-xgboost-guarantees-descend-with-a-newton-step</link>
      <description><![CDATA[我正在阅读有关 XGBoost 的文章，我发现与 Gradient Boosting 相比，每次迭代的步长由牛顿法而不是梯度下降给出。
但是，牛顿法不能保证下降，甚至可能上升。XGBoost 如何保证我们每一步都真正下降？我唯一想到的是，由于常用损失函数（例如 MSE）的性质（凸），迭代将下降。
以下摘录似乎证实了我的直觉，但我不确定。在论文中的公式 2（pdf 的第 2 页）之后，作者指出：

这里 $l$ 是一个可微分凸损失函数，用于测量
预测 $\hat{y}_i$ 和目标 $y_i$ 之间的差异。
]]></description>
      <guid>https://stats.stackexchange.com/questions/656049/how-xgboost-guarantees-descend-with-a-newton-step</guid>
      <pubDate>Sun, 20 Oct 2024 17:58:23 GMT</pubDate>
    </item>
    <item>
      <title>计算多维度的置信区间</title>
      <link>https://stats.stackexchange.com/questions/655904/calculate-confidence-interval-in-multiple-dimensions</link>
      <description><![CDATA[我想计算多维概率向量 X（$p$ 维，r 个实现）的置信区间。我觉得我已经取得了很大进展，但不知何故似乎缺少最后一步。
这里显示，置信区间应该是 $p$ 维空间中的椭圆体。主轴可以通过协方差矩阵 $C=X^T\cdot X/\sqrt{(p-1)}$ 的主成分分析来确定：
$$
C=V\cdot L \cdot V^T
$$
现在 $V$ 的列（特征向量）应为椭球主轴的方向，$L$ 对角线元素的平方根应为它们的长度。$A=V\cdot \sqrt{L}$ 称为载荷。 （从这里我知道如何缩放椭圆体以覆盖一定比例的实现。我还知道如何应用降维。）现在我需要做的就是找到椭圆体与坐标轴相交的点。或者换句话说，哪个主成分对我的向量的哪个条目有贡献。我可以简单地将载荷$A$的行相加吗？我无法理解这样一个事实，即我最终得到了正值和负值，结果似乎不合适。我哪里做错了？
我希望我能够陈述我的问题，并非常感谢您的帮助。
编辑：我添加了一个 2D 草图来显示$p$ 维度所需的内容。要获取置信边界，我需要找到上面插入的蓝色矩形。它代表围绕倾斜椭圆体的最小可能长方体。有没有办法从特征值分解（或任何其他方式）中检索它？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655904/calculate-confidence-interval-in-multiple-dimensions</guid>
      <pubDate>Thu, 17 Oct 2024 14:00:12 GMT</pubDate>
    </item>
    <item>
      <title>自动样条回归</title>
      <link>https://stats.stackexchange.com/questions/655803/automated-spline-regression</link>
      <description><![CDATA[由于一些CV成员偶尔会推荐样条回归，我想知道是否有一种自动算法来选择要应用样条的变量以及节点的数量和位置。类似于分段回归或随机森林的 CART 算法。
我读过 Frank Harrell 的《回归建模策略》一章，其中包含一些经验法则并建议使用 AIC 自动选择节点数，但我的印象是它是一种统计员将其偏见建模到分析中的程序。当然，这是一种有效的方法，但它似乎只适用于具有少量变量的数据，这些变量要么是事先选择的（由于某些专家的偏见），要么是经过某种变量选择算法选择的。
是否有一些严格的样条回归算法，有人将其与 CART 或随机森林进行了比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/655803/automated-spline-regression</guid>
      <pubDate>Tue, 15 Oct 2024 11:33:52 GMT</pubDate>
    </item>
    <item>
      <title>混合效应分析中的 P 值与数据不匹配</title>
      <link>https://stats.stackexchange.com/questions/648086/p-values-not-matching-data-in-mixed-effects-analysis</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648086/p-values-not-matching-data-in-mixed-effects-analysis</guid>
      <pubDate>Mon, 27 May 2024 17:24:20 GMT</pubDate>
    </item>
    </channel>
</rss>