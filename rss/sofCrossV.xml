<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 24 Oct 2024 01:15:41 GMT</lastBuildDate>
    <item>
      <title>实验样本量计算：两个独立组，结果为二元，参与者数量不等，但结果数量相等</title>
      <link>https://stats.stackexchange.com/questions/656232/sample-size-calculation-for-experiment-two-independent-groups-with-binary-outcom</link>
      <description><![CDATA[我正在尝试计算一个实验所需的样本量，该实验有两个独立的研究小组，结果为二分法/二元。结果包括做出选择。第 1 组的参与者数量是第 2 组的三倍；但是，第 2 组的参与者做出的选择是第 2 组的三倍。这导致第 1 组中的选择总数（二分法/二元结果）与第 2 组中的选择总数相同。要计算所需的样本量，我是否应该根据每组的参与者数量或每组做出的选择数量（同样是二分法/二元结果）来确定入学率？]]></description>
      <guid>https://stats.stackexchange.com/questions/656232/sample-size-calculation-for-experiment-two-independent-groups-with-binary-outcom</guid>
      <pubDate>Thu, 24 Oct 2024 00:47:28 GMT</pubDate>
    </item>
    <item>
      <title>这是什么类型的分布？对数正态分布、威布尔分布、伽马分布，还是其他分布？</title>
      <link>https://stats.stackexchange.com/questions/656231/what-type-of-distribution-is-this-log-normal-weibull-gamma-or-something-else</link>
      <description><![CDATA[这些看起来符合对数正态分布，但我尝试将它们转换为 CDF 并进行测试，结果似乎表明它们很可能不是，在 Excel、Python 或其他任何程序中执行此操作的正确程序是什么，这看起来像是伽马分布还是其他什么？

0.017395254
0.580788701
2.244034191
7.116155325
19.0835451
44.22988025
90.1234036
163.7739646
268.7945222
403.0639053
5 58.1949644 721.2332237 877.8496588 1015.64494 1126.371677 1206.604403 1257.103971 1281.485766 1284.787505 1272.313357 1248 .889279 1218.498567
1184.193139 1148.168015 1111.910213 1076.364372 1042.083872 1009.35445 978.2880808 948.890246 921.1057462 894.8484136 870. 0194081 846.5178232
824.246362 803.1140138 783.037009 763.9388577 745.7499466 728.4069606 711.8522682 696.0333321 680.9021736 666.4148936 652 53125 639.2142857 6 26.43 614.1470588 602.3365385 590.9716981 580.0277778 569.4818182 559.3125 549.5 540.0258621 530.8728814 522.025 513.46721 31 505.1854839 497。 1666667 489.3984375 481.8692308 474.5681818 467.4850746 460.6102941 453.9347826 447.45 441.1478873 435.0208333 429.0616438 423.2635135 417.62
412.125 406.7727273 401.5576923 396.4746835 391.51875 386.6851852 381.9695122 377.3674699 372.875 368.4882353 364.2034884 360.0172414 355.926 1364
351.9269663
348.0166667
344.1923077
340.451087
336.7903226
333.2074468
329.7
326.265625
322.9020619
319.6071429
316.3787879
]]></description>
      <guid>https://stats.stackexchange.com/questions/656231/what-type-of-distribution-is-this-log-normal-weibull-gamma-or-something-else</guid>
      <pubDate>Wed, 23 Oct 2024 23:44:56 GMT</pubDate>
    </item>
    <item>
      <title>按给定大小的组进行抽样的术语</title>
      <link>https://stats.stackexchange.com/questions/656229/term-for-sampling-in-groups-of-a-given-size</link>
      <description><![CDATA[假设您想要检查人群中的成员，以查看他们是否具有目标特征。例如，测试人们是否患有某种疾病。
一种可能的方法是取固定大小为 $n$ 的样本，即测试 $n$ 个人，其中 $n$ 是预定义的。另一种方法是顺序抽样：您继续逐一抽样，直到满足停止规则（例如，测试直到找到 $25$ 患有该疾病的人）。
现在假设应用了顺序抽样，但不是逐一。相反，以 $k$ 组为单位进行抽样，并且停止规则决定您观察到多少个这样的组。请注意，感兴趣的特征仍然对应于每个人，而不是组。也就是说，在每个 $k$ 组中，有些人可能患有疾病，而其他人可能没有，并且每个人都单独接受测试。组只是进行抽样的一种方便方式。
对于一个具体的例子，考虑感兴趣的人群是士兵，抽样计划选择 $10$ 个士兵小队。因此样本量将始终是 $10$ 的倍数。
对于大小为 $k$ 的组，正确的统计术语是什么，以便以 $k$ 个单位为单位而不是逐个抽取样本？单词“lot”、“batch”我想到的是“和”群体“，但我认为它们在这里可能有不同的含义。]]></description>
      <guid>https://stats.stackexchange.com/questions/656229/term-for-sampling-in-groups-of-a-given-size</guid>
      <pubDate>Wed, 23 Oct 2024 22:37:11 GMT</pubDate>
    </item>
    <item>
      <title>熊数据集：glm 还是 glmm？</title>
      <link>https://stats.stackexchange.com/questions/656227/bear-data-set-glm-or-glmm</link>
      <description><![CDATA[我有一个数据集，我试图根据熊的性别、年份和季节来确定熊的速度。我的一些熊有多个季节的数据：在 79 只熊中，19 只有两个季节的数据，6 只有三个季节的数据。
我最初考虑使用广义线性模型 (glm) 来模拟熊的速度，如下所示：
速度 = 性别 + 年份 + 性别：季节
但考虑到重复数据的数量，我想知道是否最好使用广义线性混合模型 (glmm)，并将熊 ID 添加为随机效应。
我更愿意保留原始 glm，因为它更易于使用。由于大多数熊只有一个季节的数据，我也不确定这个数据集是否值得添加随机效应，因为这种随机效应的大多数级别都只有一个观察值。然而，我也担心重复数据违反独立性法则。对此有什么看法？]]></description>
      <guid>https://stats.stackexchange.com/questions/656227/bear-data-set-glm-or-glmm</guid>
      <pubDate>Wed, 23 Oct 2024 22:29:52 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 模型的预测区间界限非常大</title>
      <link>https://stats.stackexchange.com/questions/656225/huge-bounds-on-forecast-interval-for-arima-model</link>
      <description><![CDATA[我正在研究财务预测，并尝试使用一个简单的 SARIMA 模型来预测 2025 年。我认为模型的预测值和拟合度都很好，我已经测试了许多不同版本的 SARIMA，我编写的版本具有最佳拟合度指标。就上下文而言，我最终试图预测的值大多在数百万（10^6）的数量级，并且有一些相当大的变化，从 100k-6m。
话虽如此，我对预测区间并不是很熟悉，而且我收到了 95% 预测区间的一些巨大界限。
为了实现平稳性，我正在对响应的自然对数进行一阶差分。我担心我正在进行的反向变换可能会导致我的问题。我像这样转换数据：
net_new &lt;- read.csv(&#39;net_new_arr_monthly.csv&#39;)
net_new$log_net &lt;- log(net_new$net_new_arr)

first.diff &lt;- diff(x = net_new$log_net, lag = 1, 
variations = 1)

并使用以下方法建模：
mod.fit &lt;- arima(x = first.diff, order= c(1,0,0), seasonal= list(order = c(0, 1, 1), period = 12))


我当时想使用模型中残差的 SE 来创建间隔。以下是我如何计算间隔的：
fore.mod &lt;- as.data.frame(predict(object = mod.fit, n.ahead = 15, se.fit = TRUE))

fore.mod$lwr &lt;- fore.mod$pred - qnorm(p = 0.975, mean = 0, sd = sd(mod.fit$residuals))*fore.mod$se
fore.mod$upr &lt;- fore.mod$pred + qnorm(p = 0.975, mean = 0, sd = sd(mod.fit$residuals))*fore.mod$se

pred.trans = data.frame()
for(i in 1:nrow(fore.mod)){
pred.trans[i,&quot;pred&quot;] &lt;- exp(net_new$log_net[nrow(net_new)]+sum(fore.mod$pred[1:i]))
pred.trans[i,&quot;lwr&quot;] &lt;- exp(net_new$log_net[nrow(net_new)]+sum(fore.mod$lwr[1:i]))
pred.trans[i,&quot;upr&quot;] &lt;- exp(net_new$log_net[nrow(net_new)]+sum(fore.mod$upr[1:i]))
}

我猜我想知道我目前的想法是否正确？我是否只需要处理大范围的数据，因为数据的性质？反向转换是否正确完成？任何帮助都值得感激，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656225/huge-bounds-on-forecast-interval-for-arima-model</guid>
      <pubDate>Wed, 23 Oct 2024 21:32:58 GMT</pubDate>
    </item>
    <item>
      <title>对 SVM 上下文中 AUC ROC 阈值的使用感到困惑</title>
      <link>https://stats.stackexchange.com/questions/656224/confused-with-usage-of-auc-roc-thresholds-in-svm-context</link>
      <description><![CDATA[我的工作：我训练一个二分类 SVM 模型。然后我用一些测试数据文件对其进行测试，每个文件包含一段时间的数据。然后，我对每个文件内获得的标签集应用一些领域特定的逻辑方法；并使用另一种逻辑来获得类似的概率，即在 +ve 类测试数据 (TP) 中找到 +ve 类的概率和在 -ve 类测试数据 (FP) 中找到 +ve 类的概率。
然后，我绘制一条 roc 曲线，将这些概率与一组明确定义的阈值范围进行比较。我对不同的训练实验执行此操作，并根据 AUC ROC 即 roc 曲线下的面积判断性能。
我的问题是：
在单个 roc 图中，在 svm 的上下文中，“偏好”某个允许我获得满意 (TP,FP) 的阈值是没有意义的，对吗？因为最终，经过训练的 svm 将在实际应用中对任何新的特征向量表现出应有的表现。
这是否意味着我应该通过查看 roc 曲线中 FP=0 处的 TP 值来判断不同的训练实验？还是我应该查看阈值=0 时的 (TP,FP) 值？
或者我目前只查看总 auc roc 的方法是否足够？当我开始思考检查不同阈值的意义时，我得到了问题 1 和问题 2。]]></description>
      <guid>https://stats.stackexchange.com/questions/656224/confused-with-usage-of-auc-roc-thresholds-in-svm-context</guid>
      <pubDate>Wed, 23 Oct 2024 21:00:54 GMT</pubDate>
    </item>
    <item>
      <title>基线减法何时能提高统计功效？</title>
      <link>https://stats.stackexchange.com/questions/656223/when-does-baseline-subtraction-increase-statistical-power</link>
      <description><![CDATA[假设您有两组受试者（例如安慰剂和药物），每个受试者在治疗前和治疗后都进行了测量。我知道这种设计可以通过多种方式进行分析，例如对前后差异（即 delta）分数进行 t 检验、混合双向方差分析、ANCOVA...
问题：基线减法（delta 分数）方法何时可以提高统计能力，而不是仅比较治疗后分数？这必须取决于分数的相关性，即治疗前与治疗后，我想我在某处读到过这个 Pearson 相关系数必须至少为 0.5。是这样吗，还是取决于情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/656223/when-does-baseline-subtraction-increase-statistical-power</guid>
      <pubDate>Wed, 23 Oct 2024 20:57:29 GMT</pubDate>
    </item>
    <item>
      <title>关于分布矩的有限性</title>
      <link>https://stats.stackexchange.com/questions/656222/on-the-finiteness-of-moments-of-a-distribution</link>
      <description><![CDATA[考虑一个连续随机变量 $X\equiv\log(Y)$，其支持度高达 $+\infty$。假设
$$
E(\exp(\alpha X))&lt; \infty \quad \text{ 其中 $\alpha&gt;0$}
$$
我想了解这个假设对于 $X$ 和 $Y$ 有肥尾的可能性意味着什么。即：

$X$ 可以有帕累托分布吗？
$Y$ 可以有帕累托分布吗？
$X$ 可以有截断正态分布吗？而 $Y$ 可以有对数正态分布吗？

我的想法：

我不确定。

该条件本质上表明
$$
E(Y^\alpha)&lt; \infty \quad \text{ 对于某些 $\alpha&gt;0$}
$$
当 $Y$ 为帕累托分布时，是否有任何 $\alpha$ 满足此条件，并且它与尾部厚度有何关系？

如果 $X$ 为截断正态分布（仅取正值），则 $E(\exp( X))&lt; \infty$。因此，对于 $\alpha=1$，该假设得到满足。因此，$Y$ 可为对数正态分布。

]]></description>
      <guid>https://stats.stackexchange.com/questions/656222/on-the-finiteness-of-moments-of-a-distribution</guid>
      <pubDate>Wed, 23 Oct 2024 20:46:43 GMT</pubDate>
    </item>
    <item>
      <title>条件概率的极限</title>
      <link>https://stats.stackexchange.com/questions/656221/limit-of-a-conditional-probability</link>
      <description><![CDATA[考虑两个连续随机变量 $X$ 和 $Y$，取值范围为 $-\infty$ 至 $+\infty$。考虑以下极限：
$$
\lim_{t\rightarrow \infty} \Pr(X\leq t+a| Y=t) 
$$
我正在研究的证明假设该极限对于每个 $a\in \mathbb{R}$ 都是 $\ell&gt;0$。我不明白为什么这是一个假设，为什么对于任何 $a$，这个极限并不总是等于 1。您能通过回答以下几点来帮助我更好地理解这一点吗？
首先，当 $Y$ 和 $X$ 独立时，我们有
$$
\lim_{t\rightarrow \infty} \Pr(X\leq t+a| Y=t) =\lim_{t\rightarrow \infty} \Pr(X\leq t+a)\approx \Pr(X\leq \infty)=1。
$$
这是正确的吗？
如果上述内容正确，我不明白 $X$ 和 $Y$ 相关的情况会有什么不同。特别是，滥用概率概念（请原谅我将$Y$视为离散随机变量）：
$$
\lim_{t\rightarrow \infty} \Pr(X\leq t+a| Y=t) =\lim_{t\rightarrow \infty} \frac{\Pr(X\leq t+a, Y=t)}{\Pr(Y=t)}\approx\frac{\Pr(X\leq \infty, Y=\infty)}{\Pr(Y=\infty)}=\frac{\Pr(Y=\infty)}{\Pr(Y=\infty)}=1
$$
上述推导有什么问题？我可能搞错了限制，但我看不出在哪里。]]></description>
      <guid>https://stats.stackexchange.com/questions/656221/limit-of-a-conditional-probability</guid>
      <pubDate>Wed, 23 Oct 2024 20:42:44 GMT</pubDate>
    </item>
    <item>
      <title>样本来自时间序列时两样本均值差异检验</title>
      <link>https://stats.stackexchange.com/questions/656220/two-sample-difference-of-mean-test-when-the-samples-come-from-time-series</link>
      <description><![CDATA[我有两组观察值，A 组和 B 组。我可以使用 t 检验来检验 B 组的平均值大于 A 组的假设。但这里的固有假设是两组中的样本是独立的。如果样本来自两个时间序列，情况会怎样？那么，它们是相关的，它们独立的假设不再有效。是否可以修改测试以解释自相关？如果可以以某种方式估计相关系数，则可以调整两个样本 t 检验中使用的方差。我找不到任何好的参考资料。有一些标准测试可以查看其中一个序列是否预测另一个序列，但我找不到任何比较平均值或其他汇总统计数据的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/656220/two-sample-difference-of-mean-test-when-the-samples-come-from-time-series</guid>
      <pubDate>Wed, 23 Oct 2024 20:17:18 GMT</pubDate>
    </item>
    <item>
      <title>具有零膨胀和 zigamma 系列的 GLMM 中的置信水平问题</title>
      <link>https://stats.stackexchange.com/questions/656216/problem-with-confidence-level-in-glmm-with-zero-inflation-and-zigamma-family</link>
      <description><![CDATA[我正在评估哪种处理方法可以在根系生长分析中促进根系更长。我有五种不同的处理方法，每种方法有四个样本，在三个独立实验（N = 540）中进行了九天的评估。我的数据遵循伽马分布；但是，有些根系长度等于零。因此，我考虑使用 zigamma 系列的零膨胀模型。下面是我应用的 glmmTMB 函数：
 model_zi &lt;- glmmTMB(root_length ~ treatment + (1|exp/day),
family = ziGamma(link = &quot;log&quot;),
ziformula = ~treatment, 
data = data_roots)

结果：
Family：Gamma ( log )
公式：root_length ~ treatment + (1 | exp/day)
零通货膨胀：~treatment
数据：data_roots

AIC BIC logLik 偏差 df.resid 
1953.5 2009.3 -963.7 1927.5 527 

随机效应：

条件模型：
组名称方差标准差。
day:exp（截距）7.641e-01 0.8741496
exp（截距）1.749e-07 0.0004182
观察数：540，组：day:exp，27；exp，3

Gamma 系列的离散度估计（sigma^2）：0.326

条件模型：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 0.18322 0.17816 1.028 0.30377 
treatmenttreat2 0.42944 0.08579 5.006 5.57e-07 ***
treatmenttreat3 0.26535 0.08375 3.168 0.00153 ** 
treatmenttreat4 0.83239 0.08415 9.892 &lt; 2e-16 ***
treatmenttreat5 1.03670 0.08146 12.726 &lt; 2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

零通胀模型：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -2.0794 0.3062 -6.791 1.11e-11 ***
treatmenttreat2 0.7723 0.3860 2.001 0.0454 * 
treatmenttreat3 0.2549 0.4137 0.616 0.5378 
treatmenttreat4 0.3302 0.4088 0.808 0.4192 
treatmenttreat5 -1.8909 0.7766 -2.435 0.0149 * 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

我的问题是，一种治疗方法（治疗方法 5）只有两个根长度等于 0，导致这种治疗方法的置信区间非常宽（我应用了 sjPlot 中的 plot_model 进行此分析）您对如何解决这个问题有什么建议吗？我特别感兴趣的是治疗导致根长度为零的概率，这就是为什么我为每种治疗方法选择了零膨胀模型。其他治疗方法中的零数量为：
treat1 - 12;
treat2 - 22;
treat3 - 15;
treat4 - 16;
treat5 - 2。
（考虑到零的数量，我也不明白为什么截距如此接近治疗 5 的系数，但远离治疗 3 的系数。）

我还使用 DHARMa 包中的 mockResiduals 函数进行了残差分析，并且在 K-S 检验中遇到了问题。

我还尝试重写模型如下：
model_zi &lt;- glmmTMB(root_length ~ treatment + (1|exp/day),
family = ziGamma(link = &quot;log&quot;),
ziformula = ~., 
data = data_roots)

但是，在这种情况下残差更糟糕。]]></description>
      <guid>https://stats.stackexchange.com/questions/656216/problem-with-confidence-level-in-glmm-with-zero-inflation-and-zigamma-family</guid>
      <pubDate>Wed, 23 Oct 2024 18:39:50 GMT</pubDate>
    </item>
    <item>
      <title>转换响应和使用非正态分布之间的建模有何差异？</title>
      <link>https://stats.stackexchange.com/questions/656215/difference-in-modelling-between-transforming-the-response-and-using-a-non-normal</link>
      <description><![CDATA[在回归建模中，通过转换响应变量（例如，对 y 应用对数转换）然后将输出反向转换回原始比例来拟合模型，与为响应指定非正态分布（例如，使用对数正态分布）之间有什么区别？
这些方法如何影响模型的解释、准确性和预测？
使用 brms 的示例：
# 对数转换模型
fit_log_transformed &lt;- brm(log(y) ~ x, data = mydata, family = gaussian())
# 然后我们将输出反向转换回原始比例

# 对数正态模型
fit_lognormal &lt;- brm(y ~ x, data = mydata, family = lognormal())
```r
]]></description>
      <guid>https://stats.stackexchange.com/questions/656215/difference-in-modelling-between-transforming-the-response-and-using-a-non-normal</guid>
      <pubDate>Wed, 23 Oct 2024 18:27:52 GMT</pubDate>
    </item>
    <item>
      <title>关于在复杂调查设计中正确使用子集的后续问题</title>
      <link>https://stats.stackexchange.com/questions/656209/follow-up-question-on-the-proper-use-of-subset-in-complex-survey-designs</link>
      <description><![CDATA[我阅读并尝试理解关于复杂调查设计中适当子集的各种贡献，包括：

调查数据的适当子集
在分析之前对调查数据进行子集化何时不是问题？
为什么制作调查设计对象很重要（R 中带有 id 的 svydesign 函数，原始数据和对象中清理数据后，如何从原始数据中提取地层、权重、fpc？
https://notstatschat.rbind.io/2021/07/22/subsets-and-subpopulations-in-survey-inference/

我理解，在 svyby() 中使用 subset() 时，未选定观测值的权重设置为 0，对吗？
我还理解，在构建调查设计对象之前或内进行子集化时，点估计没有差异svyby()，但标准误差和置信区间却如此。
我想我理解或者至少想象这两种方法对整群抽样的影响。如果我们在构建调查设计对象之前删除集群，我们假设删除的集群不存在，剩余的集群代表可能集群的完整范围，而实际上删除的集群也包含重要信息，即它们是空的。我说得对吗？
然而（或者说更糟的是），我很难理解分层抽样的后果。例如，如果我们估计女性的平均值，而忽略男性（即在构建调查设计对象之前选取了一部分女性受访者），我们会错过什么信息。在撰写本文时，我想知道我们是否假设在分层抽样中，男性亚群的方差也提供了有关女性亚群方差的信息？
感谢您的时间；如果我需要提供更多信息，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/656209/follow-up-question-on-the-proper-use-of-subset-in-complex-survey-designs</guid>
      <pubDate>Wed, 23 Oct 2024 16:14:08 GMT</pubDate>
    </item>
    <item>
      <title>理解和报告带有样条项的 Cox 模型</title>
      <link>https://stats.stackexchange.com/questions/656207/understanding-and-reporting-cox-models-with-spline-terms</link>
      <description><![CDATA[我已经用 pspline() 项对连续协变量拟合了一个 Cox 模型。我试图更好地理解如何才能正确报告我的结果。
关于报告，我发现了几个建议（使用 rms 包）。由于我没有使用 rms 包，我正在寻找使用 R 库的替代方案。ggplot(Predict(cph(*))) 和 termplot(coxph(*)) 之间有什么区别？形状相同，但值不同，例如：
library(survival)
library(rms)

# ggplot(Predict(cph(*)))
dd &lt;- datadist(lung)
options(datadist = &quot;dd&quot;)
fit1 &lt;- cph(Surv(time, status) ~ rcs(age, 3) + sex, data = lung)
ggplot(Predict(fit1, age))

# termplot(coxph(*))
fit2 &lt;- coxph(Surv(time, status) ~ rcs(age, 3) + sex, data = lung)
termplot(fit2, term = 1, se = TRUE)



或者使用 pspline() 代替 rcs()：
fit4 &lt;- coxph(Surv(time, status) ~ pspline(age) + sex, data = lung)
termplot(fit4, term = 1, se = TRUE)


无论如何，我并不清楚这些函数实际上起什么作用。如果我理解正确，pspline() 和 rcs() 允许协变量和结果之间的非线性（例如，年龄 = 40 和年龄 = 80 的 HR 不同）。
但是，在绘制 Cox 模型的 pspline() 项的 termplot() 时，我究竟在看什么？例如

如何解释该图？根据第三个图，我们可以说年龄 = 40 时的 HR = exp(-0.2) 和年龄 = 80 时的 HR = exp(0.6) 吗？
我们可以解释曲线的斜率吗？如果没有 pspline()，回归线的斜率对应于完整模型中变量的系数（代码在文章末尾）。
我们可以报告一个平均值吗？

顺便说一句，根据作者和函数的不同，y 轴的标签不同（例如 termplot() 中的“年龄偏向”；rms:::ggplot.Predict() 中的“对数相对风险”；或 样条线小插图中的“相对死亡率”，图2，也这里讨论），这让我更加困惑。

fit3 &lt;- coxph(Surv(time, status) ~ age + sex, data = lung)
age &lt;- termplot(fit3, term = 1, se = TRUE, plot = FALSE)$age
identical(
coef(fit3)[[1]],
(age$y[which.max(age$x)] - age$y[which.min(age$x)]) / (max(age$x) - min(age$x))
)
# [1] TRUE
]]></description>
      <guid>https://stats.stackexchange.com/questions/656207/understanding-and-reporting-cox-models-with-spline-terms</guid>
      <pubDate>Wed, 23 Oct 2024 15:39:56 GMT</pubDate>
    </item>
    <item>
      <title>随着树变得越来越复杂，X-val 相对误差也会增加</title>
      <link>https://stats.stackexchange.com/questions/656206/x-val-relative-error-increases-as-trees-get-more-complex</link>
      <description><![CDATA[我正在使用 rpart 构建 CART 模型。这是我使用的代码：
train_rpart &lt;- rpart(
y ~ x1 + x2 + x3 + x4,
data = train, 
method = &quot;class&quot;, 
control = rpart.control(
minsplit = 20, 
minbucket = 5, 
cp = 0, 
maxdepth = 5, 
xval = 10
),
parms = list(
split = &quot;gini&quot;, 
loss = matrix(c(0, 1, 10, 0), 
byrow = TRUE, 
nrow = 2
)
)

plotcp(train_rpart)

这是我得到的结果：

我知道 x-val 相对误差随着树的大小增加而变大的原因是由于过度拟合。但是，除了我已经做过的事情之外，我不确定我还能做些什么来解决这个问题。我尝试过 SMOTE 来平衡数据集，但仍然没有帮助。我将不胜感激任何帮助和建议。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656206/x-val-relative-error-increases-as-trees-get-more-complex</guid>
      <pubDate>Wed, 23 Oct 2024 15:24:00 GMT</pubDate>
    </item>
    </channel>
</rss>