<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 31 Oct 2024 18:22:45 GMT</lastBuildDate>
    <item>
      <title>如何计算重力负荷？</title>
      <link>https://stats.stackexchange.com/questions/656554/how-to-calculate-g-loading</link>
      <description><![CDATA[# install.packages(&quot;psych&quot;,repos = &quot;https://cloud.r-project.org&quot;)
library(jsonlite)
library(psych)
data_matrix &lt;- fromJSON(&quot;data.json&quot;)
tetra_corr &lt;- tetrachoric(data_matrix)$rho
fa_result &lt;- fa(r = tetra_corr, nfactors = 1, rotate = &quot;varimax&quot;)
print(fa_result)

这给了我一份每个项目的 g 负荷列表，对吗？我如何根据此列表计算测试的总体 g 负荷？
我的 JSON 是一个项目响应数组，其中每个响应都是 0 或 1（不正确或正确）。]]></description>
      <guid>https://stats.stackexchange.com/questions/656554/how-to-calculate-g-loading</guid>
      <pubDate>Thu, 31 Oct 2024 16:58:20 GMT</pubDate>
    </item>
    <item>
      <title>随机森林模型 - 模拟偏差的影响</title>
      <link>https://stats.stackexchange.com/questions/656551/random-forest-model-impact-of-simulated-bias</link>
      <description><![CDATA[作为演示项目的一部分，我们正在使用 IBM 人员流失数据（可从 Kaggle 等网站获取的虚构数据）进行模拟。目的是展示两种效果 -

对于训练和测试数据集，通过曲线下面积测量额外随机噪声对预测的影响。绿色是原始数据集中给出的结果，对于每个模型都是相同的。



额外偏差（转向积极结果）对预测的影响。


每个箱线图来自使用 R 函数 ranger 对随机森林进行的 1,000 次模拟。每个预测都基于对训练或测试数据的预测，并添加了给定水平的随机噪声或偏差，与“真实”结果（流失）或嘈杂/有偏差的结果进行比较。
因此问题

噪声的影响或多或少是我所期望的，我相信预测“真实”结果（数据集中给出的结果）的更好结果反映了“真实”结果与“嘈杂”结果相比的较低可变性。有人可以纠正我，或者让我参考文献中关于这一点的讨论。

偏见的影响不是我所期望的。鉴于这里建模的偏见（随着变量 DistanceFromHome 的值的增加而具有更强的影响）只能增加积极结果的数量，我原本预计“真实”值的预测会比有偏差的值更差。我不明白为什么添加正偏差会以这种方式影响测试数据集的结果。请注意，这个偏差变量在预测集中，但我得到了定性相似的结果，偏差变量的重要性较低，几乎为零。非常欢迎提出想法或参考。

]]></description>
      <guid>https://stats.stackexchange.com/questions/656551/random-forest-model-impact-of-simulated-bias</guid>
      <pubDate>Thu, 31 Oct 2024 16:03:03 GMT</pubDate>
    </item>
    <item>
      <title>无法将 plm 支持 model="between" 与某些权重一起打包吗？</title>
      <link>https://stats.stackexchange.com/questions/656549/cant-package-plm-support-model-between-with-some-weights</link>
      <description><![CDATA[我测试了 plm 的示例，发现 plm 无法处理带权重的“between”模型。
复制了 Baltagi (2013) 表 3.1 中的一些结果
data(&quot;Grunfeld&quot;, package = &quot;plm&quot;)
p &lt;- plm(inv ~ value + capital,
data = Grunfeld, model = &quot;pooling&quot;)

设置“within”模型带权重就可以了
data(&quot;Grunfeld&quot;, package = &quot;plm&quot;)
p &lt;- plm(inv ~ value + capital,
data = Grunfeld, model = &quot;pooling&quot;)

update(p, model = &quot;within&quot;)

模型公式：inv ~ value + capital

系数：
value capital 
0.11012 0.31007 

update(p, model = &quot;within&quot;, weights = 1:200)

模型公式：inv ~ value + capital

系数：
value capital 
0.09545 0.20708 


设置模型 &quot;between&quot;没有权重也可以
update(p, model = &quot;between&quot;) 

模型公式：inv ~ value + capital

系数：
(截距) value capital 
-8.527114 0.134646 0.032031 

但是设置带有权重的模型 &quot;between&quot; 会失败
update(p, model = &quot;between&quot;, weights = 1:10) |&gt; try() 
# 变量长度不同（找到 &#39;(weights)&#39;）

update(p, model = &quot;between&quot;, weights = 1:30) |&gt; try() 
# 变量长度不同（找到 &#39;(weights)&#39;）

update(p, model = &quot;between&quot;, weights = 1:200) |&gt; try() 
# 尺寸 [product 30] 与对象 [200] 的长度不匹配
]]></description>
      <guid>https://stats.stackexchange.com/questions/656549/cant-package-plm-support-model-between-with-some-weights</guid>
      <pubDate>Thu, 31 Oct 2024 15:54:27 GMT</pubDate>
    </item>
    <item>
      <title>多任务逻辑回归中的概率表达</title>
      <link>https://stats.stackexchange.com/questions/656546/probability-expression-in-multi-task-logistic-regression</link>
      <description><![CDATA[我试图理解这篇论文（将患者特定癌症生存分布作为依赖回归量序列进行学习）的作者如何获得第页上观察生存状态序列的概率的一般公式。
显然，R 包 MTLR 基于这种方法。
对于给定的随机变量 $T$，由 $\vec x$ 描述的生物体在 $T\geq t$ 时的存活概率被假定为
$$
P(T&gt;t|\vec x) = \frac{1}{1+ e^{\vec\theta_t\cdot \vec x + b_t}}.
$$
现在假设我们想通过时间序列$\{t_i\}$来研究生存的概率，即我们想计算生物在$T=t\in(t_i,t_i+1)$时死亡的概率。
正如作者所说，最终目标是获得生物的生存时间分布。
我们仍然假设
$$
p_i = P(T&gt;t_i|\vec x) = \frac{1}{1+ e^{\vec\theta_i\cdot \vec x + b_i}}。
$$
作者提出的表达式为
%$$
P(\vec y|\vec x) = \frac{e^{y_1(\vec\theta_1\cdot x+b_1) + \cdots + y_n(\vec\theta_n\cdot x+b_n)}}{e^{\vec\theta_n\cdot\vec x + b_n}+ e ^{\vec\theta_{n-1}\cdot x+b_{n-1} + \vec\theta_n\cdot x+b_n} + \cdots + e^{\vec\theta_1\cdot x+b_1 + \cdots + \vec\theta_n\cdot x+b_n}},
$$
其中$\vec y$ 时间序列中的观察结果：如果生物体仍然活着，则 $y_i = y(t_i) = 0$，否则为 $1$。
我尝试使用不同的 $p_i$ 推导出 $P(\vec y|\vec x)$ 的公式，但没有成功。
公式不是乘积，因为 $p_i$ 取决于 $p_{i-1}$，我不知道它们是如何组合的。
我试图理解最简单的情况 $n=2$ 和 $y=(0,0)$（即生物体始终活着）。
对于这种情况
$$
P = \frac{1}{e^{\vec\theta_2\cdot\vec x + b_2} + e^{\vec\theta_1\cdot\vec x + b_1 + \vec\theta_2\cdot\vec x + b_2}}。
$$
有什么想法吗？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/656546/probability-expression-in-multi-task-logistic-regression</guid>
      <pubDate>Thu, 31 Oct 2024 15:44:27 GMT</pubDate>
    </item>
    <item>
      <title>群体敏感性的超几何近似及其非线性性质</title>
      <link>https://stats.stackexchange.com/questions/656545/hypergeometric-approximation-of-herd-sensitivity-and-its-non-linear-nature</link>
      <description><![CDATA[我最近一直在探索 Cannon 2001 年论文“感觉与敏感性”中描述的方程在群体敏感性方面的应用（我喜欢这个名字）。

我一直在寻找用两种不同的协议测试假设的群体的方法（每种协议都有不同的测试敏感性），然后希望将两种测试协议的结果结合起来得到一个群体敏感性。我计算了两个群体敏感性，然后将它们并行组合起来。我试图理解的一个问题是，我认为我遗漏了一个非线性组件，它会导致群体敏感性的损失超出仅用测试敏感性差异可以解释的范围。我进一步探索了这一点，通过计算测试 100 只动物的 300 只动物群的群体敏感性，然后计算测试 50 只动物（具有相同的测试敏感性）的两个群体敏感性并将它们并行组合。因此，尽管测试了相同数量的动物（100 只）且测试敏感性相同，但我得到的群体敏感性较低。考虑到群体敏感性曲线，我认为这是有道理的。

然而，我正在努力寻找一种方法来量化或估计这种群体敏感性的“损失”，因为了解由于采用不同的不太敏感的测试协议而导致群体敏感性降低的程度会很有用。任何建议或意见都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/656545/hypergeometric-approximation-of-herd-sensitivity-and-its-non-linear-nature</guid>
      <pubDate>Thu, 31 Oct 2024 14:57:33 GMT</pubDate>
    </item>
    <item>
      <title>如何解释简单调节分析中协变量的非显著影响？</title>
      <link>https://stats.stackexchange.com/questions/656542/how-do-i-explain-non-significant-effect-of-covariates-in-simple-moderation-analy</link>
      <description><![CDATA[我正在使用一个独立变量 (IV)、一个调节变量 (M) 和一个因变量 (DV) 进行简单的调节分析。结果发现没有显著的相互作用，这意味着我的 M 不起调节作用。我添加了协变量以查看它是否可以改变相互作用，但我的所有协变量也不显著，相互作用结果保持不变。我如何在报告中解释这一点？如果您有类似的结果/论文可以举例说明，请分享]]></description>
      <guid>https://stats.stackexchange.com/questions/656542/how-do-i-explain-non-significant-effect-of-covariates-in-simple-moderation-analy</guid>
      <pubDate>Thu, 31 Oct 2024 14:28:52 GMT</pubDate>
    </item>
    <item>
      <title>我如何解释简单回归、多元回归、调节和中介的不同结果？</title>
      <link>https://stats.stackexchange.com/questions/656536/how-do-i-interpret-different-results-from-simple-regression-multiple-regression</link>
      <description><![CDATA[我目前正在对灵性和宽恕进行多元线性回归分析，以了解它们如何影响生活满意度。
如果我将 IV 单独放入线性回归中，它们都显示为显著，其中灵性为 &lt;.001，宽恕为 .004。但是，如果我将它们都放入模型中，灵性保持为 0.001，而宽恕则变为 .543。我不太确定如何解释这些结果。
此外，我正在做一个调节分析，看看灵性是否会调节宽恕，结果显示调节作用不显著。
我检查了调节，灵性是宽恕和生活满意度的调节者。结果如下：

宽恕对生活满意度的直接影响不显著

以灵性为中介的间接影响在&lt;.001 时非常显著。


我是否可以正确地假设对此的解释是完全中介，即宽恕只有在通过灵性介导的情况下才会对生活满意度产生显著影响；否则就没有任何显著影响，而且灵性本身也是生活满意度的预测因素？]]></description>
      <guid>https://stats.stackexchange.com/questions/656536/how-do-i-interpret-different-results-from-simple-regression-multiple-regression</guid>
      <pubDate>Thu, 31 Oct 2024 11:31:57 GMT</pubDate>
    </item>
    <item>
      <title>如何计算合并标准误差</title>
      <link>https://stats.stackexchange.com/questions/656530/how-to-compute-a-pooled-standard-error</link>
      <description><![CDATA[我正在 $d$ 个数据集中比较 $m$ 个方法。通过我的实验，我获得了所有方法和所有数据集的平均值、标准差和标准误差，因此我有平均值
$$
\bar x_{1,1}, \dots, \bar x_{1, m},
\\
\vdots
\\
\bar x_{d,1}, \dots, \bar x_{d, m},
$$
和标准误差
$$
\hat s_{1,1}, \dots, \hat s_{1, m},
\\
\vdots
\\
\hat s_{d,1}, \dots, \hat s_{d, m}.
$$
我想针对所有数据集中每个方法做出声明，即我想汇总这两个数量。因此，我非常确定我可以计算每个方法的平均值 $k$，因为
$$
\bar X_k = \frac 1 d \sum_{i=1}^d \bar x_{i, k}
$$
但我该如何处理标准误差？是否可以以类似的方式组合它们，即
$$
\hat S_k = \sqrt{\frac 1 d} \; \sum_{i = 1}^d \hat s_{i, k},
$$
或者我需要以不同的方式处理这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/656530/how-to-compute-a-pooled-standard-error</guid>
      <pubDate>Thu, 31 Oct 2024 08:34:35 GMT</pubDate>
    </item>
    <item>
      <title>是否可以将二阶增长斜率因子建模为另一个二阶增长斜率因子的中介？</title>
      <link>https://stats.stackexchange.com/questions/656529/is-it-possible-to-model-a-second-order-growth-slope-factor-as-a-mediator-of-anot</link>
      <description><![CDATA[我正在运行一个包含三个变量的二阶增长模型。
我的数据涵盖了 7 波数据。我目前正在运行一个多元增长模型，该模型模拟了多个增长因素的关联关系。
我听说，对于是否可以将显示增长因素关联关系的双头箭头改为单头箭头，并没有达成真正的共识，这将更清楚地表明因素之间的关系方向。
无论如何，我想知道是否有办法将我的三个增长因素之一建模为其他两个的中介。因此，
增长斜率因子 A -&gt; 增长斜率因子 B（中介）-&gt; 斜率增长因子 C
这种模型。
如果有人知道这种模型，那将非常有帮助。
感谢您一直以来的支持。]]></description>
      <guid>https://stats.stackexchange.com/questions/656529/is-it-possible-to-model-a-second-order-growth-slope-factor-as-a-mediator-of-anot</guid>
      <pubDate>Thu, 31 Oct 2024 07:39:43 GMT</pubDate>
    </item>
    <item>
      <title>添加或乘以常数时的收敛和有界性</title>
      <link>https://stats.stackexchange.com/questions/656527/convergence-and-boundedness-when-a-constant-is-added-or-multiplied</link>
      <description><![CDATA[已知 $X_{n} = O_p(a_n)$ 和 $Y_n - c = O_p(a_n)$，其中 $a_n$ 是一个趋于零的序列。鉴于此，我想证明 $X_{n}/Y_n = O_p(a_n)$。
由于 $a_n$ 趋于零，我们可以说 $X_{n} = o_p(1)$，类似地 $Y_n - c = o_p(1)$。这反过来意味着 $Y_n - c = O_p(1)$。这里的 c 是一个常数。如果我们说 $Y_n - c$ 是随机有界的，那么我们是否也可以说 $Y_n$ 本身是随机有界的。因此，如果 $X_{n} = o_p(1)$ 或以概率收敛到 0，那么 $X_{n}/Y_n$ 也以概率收敛到 0？此外，我们是否可以说，由于 $X_{n} = o_p(1)$，所以 $X_{n}/c$ 也是如此？
我想利用 $X_n/Y_n = X_n/c + (X_n/Y_n)(c-Y_n)(1/c)$ 这一事实来得出所需的结果。如果有更好的方法，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/656527/convergence-and-boundedness-when-a-constant-is-added-or-multiplied</guid>
      <pubDate>Thu, 31 Oct 2024 07:04:37 GMT</pubDate>
    </item>
    <item>
      <title>一般来说，我们是否应该在 SEM 分析中删除所有不显著的路径？</title>
      <link>https://stats.stackexchange.com/questions/656523/generally-are-we-supposed-to-remove-all-nonsignificant-paths-in-an-sem-analysis</link>
      <description><![CDATA[鉴于我们在科学中主张简约，如果非显著路径不会导致模型拟合度明显下降，我们是否应该删除这些不显著的路径？
在我们删除不显著的路径后，其他路径也变得不显著，我们是否继续删除路径，直到所有路径都具有统计显著性（当然，如果它们不会导致模型拟合度下降）？
如果不是，那么我们如何决定删除哪条路径？]]></description>
      <guid>https://stats.stackexchange.com/questions/656523/generally-are-we-supposed-to-remove-all-nonsignificant-paths-in-an-sem-analysis</guid>
      <pubDate>Thu, 31 Oct 2024 01:41:25 GMT</pubDate>
    </item>
    <item>
      <title>比较逻辑回归系数</title>
      <link>https://stats.stackexchange.com/questions/656518/comparing-logistic-regression-coefficients</link>
      <description><![CDATA[我有代表个体群体和感兴趣的二元结果的数据。协变量本​​身通常是概率。例如，协变量 1 到 5 是此个体属于组 1（到 5）的概率的估计值。还有其他非概率协变量。
我已选择组 1 作为我的参考组，我很想测试以下假设：“属于组 $j$ 与结果 $d$ 的关联性高于参考组”，其中 $j=2, ..., 5$ 和某个预定阈值 $d$。例如，我的结果可能是“是否被捕”，我的群体成员协变量可能是人口统计估计值，而我的其他协变量可能是涉嫌犯罪的各个方面。如果 $d=0.1$，那么我试图回答这个问题“成为人口统计 $j$ 的成员是否会使一个人的被捕率（与参考人口统计相比）至少增加 10 个百分点？”
我正在使用 statsmodels 在 Python 中运行逻辑回归，我很好奇执行完整分析的正确过程是什么。特别是：

我应该标准化（0 均值，单位标准差）我的数据吗？对于非群体成员协变量，我认为答案是“是”——我并不特别关心那些系数。对于组成员协变量，输出介于 0 和 1 之间（概率）。我的人口分布不均匀：其中一些组成员协变量的均值接近 0.8，而其他均值接近 0.1。

回归后，我是否需要以某种方式转换系数才能进行假设检验？（例如，从对数几率转向……其他东西？）

有了系数后，如何正确地将每个组的结果与参考组的结果加上 $d$ 进行比较？我应该按照 regression_results.wald_test(&quot;(group2 + d = const)&quot;) 的方式运行 Wald 检验（或 F 检验？或 T 检验？或其他东西）吗？我想做一个关于自卑、优越和平等的测试，因为我有三个感兴趣的结果：（a）这个组的结果可能小于参考组的$+d$；（b）这个组的结果可能大于参考组的$+d$；（c）我们不知道哪个更大。


最后一行问题可能有点草率，我很抱歉在假设检验方面没有更好的基础。我来自机器学习领域，我想象用 95% 的置信区间 $\beta_j - const$ 来回答我的问题，其中 $\beta_j$ 是组 $j$ 成员的系数。可视化置信区间，要么整个值小于 $d$，要么整个值大于 $d$，要么它包含 $d$。这些结果中的每一个都会推动不同的决策。对于 (a)，我们可能对所分析的系统感到满意。对于 (b)，我们认为所分析的系统存在需要修复的问题。对于 (c)，我们无法判断是否存在问题，可能需要收集更多数据或采取其他方法。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/656518/comparing-logistic-regression-coefficients</guid>
      <pubDate>Wed, 30 Oct 2024 20:23:17 GMT</pubDate>
    </item>
    <item>
      <title>将 Shapley 值应用于分类</title>
      <link>https://stats.stackexchange.com/questions/656514/applying-shapley-values-to-classification</link>
      <description><![CDATA[根据 Štrumbelj 和 Kononenko (2013) 的定义，Shapley 值是为回归预测而定义的。
然而，当分类器不仅产生类别，而且产生类别概率 $P(\omega_i|x)$ 时，它们也应该适用于分类。问题是，这会为每个特征产生 $C$ 个 Shapley 值，其中 $C$ 是可能的类 $\omega_i$ 的数量。
问题：有没有办法将这些值组合成每个特征的单个值，以表示该特征对决策的贡献？
R 中的示例：一个简单的高斯贝叶斯分类器，也称为“鸢尾花数据集的二次判别分析”，其 Shapley 值由 Kernel SHAP 估计（假设特征独立）：
library(MASS)
library(kernelshap)

# 覆盖预测以返回类概率
mypredict &lt;- function(model, ...) {
res &lt;- MASS:::predict.qda(model, ...)
return(res$posterior)
}

model &lt;- qda(Species ~ ., iris)
s &lt;- kernelshap(model, iris[,-5], pred_fun=mypredict)

# 第一个鸢尾花样本的 Shapley 值
print(lapply(s$S, function(x) {x[1,]}))

返回
$setosa
Sepal.Length Sepal.Width Petal.Length Petal.Width 
-0.01393733 0.01488391 0.43523643 0.23048366 

$versicolor
Sepal.Length Sepal.Width Petal.Length Petal.Width 
-0.02314857 0.01283692 -0.14713220 -0.16850077 

$virginica
萼片长度 萼片宽度 花瓣长度 花瓣宽度 
0.03708591 -0.02772083 -0.28810423 -0.06198289 
]]></description>
      <guid>https://stats.stackexchange.com/questions/656514/applying-shapley-values-to-classification</guid>
      <pubDate>Wed, 30 Oct 2024 16:22:45 GMT</pubDate>
    </item>
    <item>
      <title>是否有可能在 GAMM 中包含两个 AR 过程？</title>
      <link>https://stats.stackexchange.com/questions/656510/is-it-possible-to-include-two-ar-process-in-a-gamm</link>
      <description><![CDATA[我试图根据环境变量对物种的存在/不存在进行建模。我的数据集由每小时对 126 只动物的观察和观察时的环境条件组成（产生 300k 行数据集）。
为了对我的动物和环境变量之间的关系进行建模，我使用了 bam() 函数，其中包括时间变量的平滑循环样条（s(time, bs = &quot;cc&quot;)）和 AR1 过程（rho = ...）。这个 AR 过程显著改善了我的残差的分布，但模型仍然呈现出未解决的 12 小时残差周期。


我怀疑这个周期源于我的物种所经历的潮汐周期。模型中包含一个指定涨潮时间的变量，该变量包含一个循环样条线，但它不处理 12 小时周期。我尝试使用 rho = c(AR1, AR12) 包含第二个相关参数，但它返回了一个错误，仅请求一个值。
是否可以包含这个第二个相关参数，如果可以，如何包含？]]></description>
      <guid>https://stats.stackexchange.com/questions/656510/is-it-possible-to-include-two-ar-process-in-a-gamm</guid>
      <pubDate>Wed, 30 Oct 2024 15:02:21 GMT</pubDate>
    </item>
    <item>
      <title>从等于两个已知 PDF f(x) 和 g(x) 乘积的 PDF 中采样</title>
      <link>https://stats.stackexchange.com/questions/656469/sampling-from-a-pdf-equal-to-a-product-of-two-known-pdfs-fx-and-gx</link>
      <description><![CDATA[假设我们有两个已知的 PDF $f(x)$ 和 $g(x)$（我们也可以简单地从两个分布中抽样）。
如果相应的 PDF/CDF 无法轻易识别（$k$ 是标准化因子），如何抽样 $k \cdot f \cdot g\,(x)$？具体来说，我正在寻找对 PDF 进行采样，它是 $\mathsf{LogNorm}(\mu_a,\sigma_a)$ 和 $\mathsf{Norm}(\mu_b,\sigma_b)$ 的乘积。
我的目的是应用&quot;weight&quot;使用给定的 $\mathsf{Norm}$ 计算原始 $\mathsf{LogNorm}$ 的概率。
我找到了 Metropolis–Hastings 算法，但我想知道对于 $\mathsf{LogNorm}$ 和 $\mathsf{Norm}$ 分布的乘积的特殊情况，是否有更简单的算法？
一些示例可以澄清我的问题：

这里，有人询问“混合”分布。从呈现的直方图来看，我可以说这可能是我正在寻找的。不幸的是，OP没有说明如何进行采样。
这里，有人谈到“Metropolis-Hastings 算法”对于似乎与我的情况相同的情况的效率。
]]></description>
      <guid>https://stats.stackexchange.com/questions/656469/sampling-from-a-pdf-equal-to-a-product-of-two-known-pdfs-fx-and-gx</guid>
      <pubDate>Tue, 29 Oct 2024 16:23:08 GMT</pubDate>
    </item>
    </channel>
</rss>