<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 16 Jan 2024 06:18:33 GMT</lastBuildDate>
    <item>
      <title>比较具有不同 Bin 计数的 KDE 发行版</title>
      <link>https://stats.stackexchange.com/questions/636960/comparing-kde-distributions-with-different-bin-count</link>
      <description><![CDATA[我有两个 KDE 发行版，每个发行版都有不同数量的 bin。我想有效地比较它们，我想知道是否有推荐的技术。我应该统一垃圾箱的数量吗？如果是的话，最好的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/636960/comparing-kde-distributions-with-different-bin-count</guid>
      <pubDate>Tue, 16 Jan 2024 05:37:37 GMT</pubDate>
    </item>
    <item>
      <title>A/B 测试所需的最小样本量</title>
      <link>https://stats.stackexchange.com/questions/636959/minimum-sample-size-needed-for-a-b-testing</link>
      <description><![CDATA[我得到了巨大的价值，但不知道为什么。
获得治疗组和对照组所需的最小样本量的快捷公式是：
16*sample_SD^2 / MDE^2

感兴趣的指标是购买次数。
对照组的sample_SD 是 185 次购买。
MDE 是购买量增加 3%。

如果我将这些数字代入，我会得到每组所需的样本数量非常高，超过 6 亿个。我在这里做错了什么？
&lt;前&gt;&lt;代码&gt;sd_sample = 185
平均DE = 0.03
每个组中所需的n_n =（16 * sd_sample ** 2）/（mde ** 2）
每个组中必需的_n_n = 608632862.6163108

]]></description>
      <guid>https://stats.stackexchange.com/questions/636959/minimum-sample-size-needed-for-a-b-testing</guid>
      <pubDate>Tue, 16 Jan 2024 05:33:01 GMT</pubDate>
    </item>
    <item>
      <title>从具有非参数累积分布函数的多元相关数据生成样本</title>
      <link>https://stats.stackexchange.com/questions/636958/generate-samples-from-multivariate-correlated-data-which-have-non-parametric-cum</link>
      <description><![CDATA[我有 40 个样本，其中包含 6 个变量的信息（因此是 40x6 数据矩阵）。每个变量（列）都有一个基于 40 个值的累积分布函数（边际分布），该函数不是高斯分布，而存在将变量相互关联的相关矩阵（我正在使用 Spearsman rho ）。我想做的是为每个变量（1000x6的数据矩阵）生成1000个样本，满足原始采样数据集的相关值，并遵循每个变量的原始40个样本的经验累积分布函数。我的理解是我可以使用 copula 来达到这个目的。所以，我想到的步骤是：
计算每个变量的平均值和标准差，并为给定的相关性 (Spearsman rho) 矩阵生成高斯边缘分布。高斯变量的值不限于[0,1]。
接下来，将每个变量的边际分布转换为单位分布（每个变量的值范围位于 [0,1] 范围内）。这是在不改变数据排序的情况下完成的，因此排名相关系数保持不变。
最后，我使用初始数据集（40x6 数据矩阵）的累积分布函数来生成每个变量的模拟值，特别是通过分位数匹配（对于单位变量的特定值，我假设等于累积分布值（垂直轴），我通过查找与此 cdf 值对应的 x 轴上的值来找到模拟值）。
上述描述准确吗？抱歉，描述很长，我对此很陌生，我不太有信心跳过部分讨论。]]></description>
      <guid>https://stats.stackexchange.com/questions/636958/generate-samples-from-multivariate-correlated-data-which-have-non-parametric-cum</guid>
      <pubDate>Tue, 16 Jan 2024 04:59:40 GMT</pubDate>
    </item>
    <item>
      <title>平面上 N 维高斯边缘化的概率，以及平面上点的可能性</title>
      <link>https://stats.stackexchange.com/questions/636957/probability-of-n-dim-gaussian-marginalized-over-a-plane-and-a-likelihood-of-a-p</link>
      <description><![CDATA[上下文：我想将一系列坐标（每个坐标都有其不确定性）拟合到（超）平面。我试图推导出在平面上观察到的一点的可能性。我需要验证我所做的事情，如果可能的话，我需要一个可以引用的来源。
假设 $\vec{x}$ 位于 $\mathbb{R}^N$ 服从高斯分布，
$$
\vec{x}\sim\mathcal{N}(\vec{\mu},\mathbf{\Sigma})
$$
和空间中的一个平面给出为
$$\hat{n}\cdot\vec{x}=k$$
Q1。如果我对平面上所有点的概率分布进行积分，我将得出点和平面之间的（有符号）距离 $h$，如下
$$
h\equiv\hat{n}\cdot\vec{x}-k\sim \mathcal{N}(-k+\hat{n}\cdot\vec{\mu},\hat{n}\cdot\mathbf {\Sigma}\cdot\hat{n})
$$
这是正确的吗？我使用多元高斯的属性导出它维基百科；对坐标进行仿射变换，使第一个轴的坐标变为 $r$，然后通过与 $\vec{e}_1$。
第二季度。假设概率 $P(h(\vec{x})|\hat{n},k,\vec{\mu},\mathbf{\Sigma})$ Q1 中的  是正确的。在回归的背景下，假设我们观察到 $\vec{\mu}$ 上的一个点，其协方差为 $\mathbf {\Sigma}$。是
$$
P(h(\vec{x})=0|\hat{n},k,\vec{\mu},\mathbf{\Sigma})
$$
确定平面的参数可能性的正确表达式，$\hat{n}, k$？]]></description>
      <guid>https://stats.stackexchange.com/questions/636957/probability-of-n-dim-gaussian-marginalized-over-a-plane-and-a-likelihood-of-a-p</guid>
      <pubDate>Tue, 16 Jan 2024 03:50:37 GMT</pubDate>
    </item>
    <item>
      <title>带有回归边际的参数联结函数</title>
      <link>https://stats.stackexchange.com/questions/636956/parametric-copulas-with-marginals-that-are-regressions</link>
      <description><![CDATA[在《Copulas 依赖建模》（Harry Joe）中，我正在努力解释语句的含义。第5.1章指出：
&lt;块引用&gt;
copula 的参数推理
对于使用联结函数进行依赖建模，最常见的是使用参数联结函数系列。 copula 模型参数推理方法的优点如下。

它们比非参数方法更容易通过数字实现。
它们可以在高维度中使用。
通过使用似然度，连续、离散或混合响应变量的理论相同，并且可以适应删失或缺失的数据。
它们可以适应回归或时间序列模型的单变量边际，或时变依赖性。协变量可以包含在单变量或相关参数中。
它们可以轻松用于比较竞争模型。


我的问题涉及第四点，特别是它们可以适应回归的单变量边距。这似乎意味着联结规范需要一些额外的参数化，因为边际现在是回归，依赖于协变量。
直观上，我可以理解这一点，因为协变量将决定边际的实际分布，因此连接函数也需要对此做出响应。然而，我也可以凭直觉知道，联结已经使用边际回归的数据进行了估计，因此已经从协变量中捕获了这些信息。
也就是说，用于估计 copula 的 $(u,v)$ 已经反映了这些边际分布的协变量。联结规范是否可以不考虑这些协变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/636956/parametric-copulas-with-marginals-that-are-regressions</guid>
      <pubDate>Tue, 16 Jan 2024 03:23:52 GMT</pubDate>
    </item>
    <item>
      <title>为三重交互编写自定义计划对比背后的逻辑</title>
      <link>https://stats.stackexchange.com/questions/636955/logic-behind-writing-custom-planned-contrasts-for-a-triple-interaction</link>
      <description><![CDATA[我有一个具有三重交互作用的模型，涉及两个因素和一个连续变量。
可复制的示例：
# %%%
设置.种子(1234)

make_times &lt;- 函数(n, n_per_group) {
  向量&lt;-c()
  for (i in 1:n) {
    one_increment_sequence &lt;- seq(0, to = n_per_group - 1)
    增量向量 &lt;- c(0, c(runif(n_per_group - 1, 0, 1)))
    向量 &lt;- c(向量, one_increment_sequence +increment_vecor)
  }
  返回（向量）
}

# 定义数据集
数据集 &lt;- data.frame(
  结果 = rnorm(60),
  组＝rep(c(“A”、“B”、“C”)，每个＝20)，
  性别=rep(c(“M”,“F”),每个=15,次=4),
  TimeFromBaseline = make_times(20, 3), # 连续
  Extra = Sample(c(&quot;Foo&quot;, &quot;Bar&quot;), 60, Replace = TRUE) # 固定协变量
）
数据集$Group &lt;-因子(dataset$Group,levels = c(“A”,“B”,“C”,“D”) ）
数据集$Sex &lt;- 因子(dataset$Sex, level = c(&quot;M&quot;, &quot;F&quot;))
数据集$Extra &lt;-因子(dataset$Extra,levels = c(“Foo”,“Bar”))
字符串（数据集）

# 拟合模型
模型 &lt;- lm(结果 ~ 性别 * 组 * TimeFromBaseline + Extra, 数据 = 数据集)
摘要（模型）

# 绘制模型
sjPlot::plot_model(model, type = &quot;pred&quot;, terms = c(&quot;TimeFromBaseline&quot;, &quot;Group&quot;, &quot;Sex&quot;))


模型中有 13 个系数。我的目标是定义长度为 13 的对比向量来测试某些假设。 这是因为我将进行大脑体素分析，并且该软件需要预先手动指定计划的对比
我对 R 默认使用的处理编码方案中每个系数代表的内容有了基本的了解：

Beta0 是参考水平的平均值（在本例中为 A 组，男性，在截距处）
Beta1 是相对于基本参考水平的增量，改变男性 -&gt; 男性。女
等等

因此，大概，测试 A 组男性在零时间（截距）时是否具有非零结果的对比向量将是：
c(1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
或者描述 B 组女性斜率的对比向量为
c(1, 1, 1, 0, 0.04, 0, 1, 0, -1.35, -0.36, 0, 1.86, 0)
对吗？
如果是这样，对我来说困难的是理解如何构建假设检验对比矩阵。
例如，这里的对比矩阵（大概有 13 列）将检验假设：三重相互作用大于零
^ 谁能概述一下如何构造这样的对比矩阵？
为 emmeans 或 lsmeans 或 multcomp 等包提供的对比是短向量，专门针对为其库焦点对象提供的内容就像emmGrid。这不是我要找的。
P.S 如果有一个 R 库可以提供这些“完整”的内容或“先验”。模型中的对比矩阵，例如 model.matrix 如何提供设计矩阵，这会让我很高兴。]]></description>
      <guid>https://stats.stackexchange.com/questions/636955/logic-behind-writing-custom-planned-contrasts-for-a-triple-interaction</guid>
      <pubDate>Tue, 16 Jan 2024 03:16:11 GMT</pubDate>
    </item>
    <item>
      <title>分子的 3 次方互信息真的存在吗？</title>
      <link>https://stats.stackexchange.com/questions/636954/does-mutual-information-by-the-power-of-3-for-the-numerator-really-exist</link>
      <description><![CDATA[我目前正在尝试使用互信息 (MI) 来衡量搭配强度。 MI 为专有和不常见的单词提供了优势。正如 Brezina (2018) 所说，在衡量搭配强度时，可以使用互信息，公式如下：
Log2(O11/E11)，
地点：
O11=搭配频率
E11 = 预期搭配频率
除了上述MI公式外，作者还给出了MI3公式，该公式与MI几乎相似，但它赋予了O11 3的幂。这个公式为排他性和频繁出现的单词提供了优势。公式如下：
Log2(O11^3/E11)
谁能向我解释一下军情三处中的三的幂叫什么？我试图在网上找到确切的公式，但没有找到。这是统计学中的一般做法吗？为什么要给出三的幂来导致这样的变化，即使 MI 对频繁和排他的搭配更加敏感？
我希望我的问题很清楚，提前谢谢！
参考：
布雷齐纳，V. (2018)。语料库语言学统计：实用指南。剑桥大学出版社。]]></description>
      <guid>https://stats.stackexchange.com/questions/636954/does-mutual-information-by-the-power-of-3-for-the-numerator-really-exist</guid>
      <pubDate>Tue, 16 Jan 2024 02:27:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 Z 分数将每周结果与平均值进行比较，然后确定一个人与平均值相比的平均表现如何</title>
      <link>https://stats.stackexchange.com/questions/636953/comparing-weekly-results-to-a-mean-using-z-scores-then-determining-how-well-a-p</link>
      <description><![CDATA[我目前领导着一组传教士，我想了解每位传教士与所在地区的平均水平相比表现如何。每个区域都有其执行情况的历史数据。假设记录的统计数据之一是结识新朋友。我计算过：

在特定区域结识的平均新朋友数量
在特定区域结识的新朋友的标准差
当前传教士在特定区域每周结识的新朋友的 Z 分数，假设呈正态分布

我现在想要计算当前传教士在其特定领域高于或低于平均值的平均表现。我尝试过对传教士的 Z 分数进行平均，但到目前为止我认为它没有给我任何有用的信息。计算传教士对其所在地区的影响的更好方法是什么？也许是 t 检验？]]></description>
      <guid>https://stats.stackexchange.com/questions/636953/comparing-weekly-results-to-a-mean-using-z-scores-then-determining-how-well-a-p</guid>
      <pubDate>Tue, 16 Jan 2024 01:43:49 GMT</pubDate>
    </item>
    <item>
      <title>证明正态分布的可能性不是非凸的</title>
      <link>https://stats.stackexchange.com/questions/636950/proving-that-the-likelihood-of-a-normal-distribution-is-not-non-convex</link>
      <description><![CDATA[作为学习练习（从这里开始为什么可能性是指数族凸函数？），我想尝试证明正态分布的似然函数不是非凸的。
这是正态分布及其（对数）可能性：
$$
f(x; \mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{ -\frac{(x-\mu)^2}{2\sigma^ 2} }
$$
$$
L(\mu, \sigma^2 | x_1, x_2, ..., x_n) = \prod_{i=1}^{n} f(x_i; \mu, \sigma)
$$
$$L(μ, σ^2 | x) = -\frac{n}{2} \log(2π) - \frac{n}{2} \ log(σ^2) - \frac{1}{2σ^2} Σ_{i=1}^{n} (x_i - μ)^2$$
现在，为了证明似然函数不是非凸的，我需要证明其 Hessian 矩阵（二阶导数矩阵）的所有特征值要么全部为正，要么全部为负。如果特征值既为正又为负，则该函数是非凸的。
首先我计算雅可比行列式（一阶导数）：
$$\frac{∂L}{∂μ} = \frac{1}{σ^2} Σ_{i=1}^{n} (x_i - μ)$$
$$\frac{∂L}{∂σ^2} = -\frac{n}{2σ^2} + \frac{1}{2(σ^2)^ 2} Σ_{i=1}^{n} (x_i - μ)^2$$
$$J = [\frac{1}{σ^2} Σ_{i=1}^{n} (x_i - μ), -\frac{n {2σ^2} + \frac{1}{2(σ^2)^2} Σ_{i=1}^{n} (x_i - μ)^2]$$
现在，我计算 Hessian 矩阵：
$$\frac{∂^2L}{∂μ^2} = -\frac{n}{σ^2}$$
$$\frac{∂^2L}{∂(σ^2)^2} = \frac{n}{2(σ^2)^2} - \压裂{1}{(σ^2)^3} Σ_{i=1}^{n} (x_i - μ)^2$$
$$H = [-\frac{n}{σ^2}, 0; 0, \frac{n}{2(σ^2)^2} - \frac{1}{(σ^2)^3} Σ_{i=1}^{n} (x_i - μ)^2 ]$$
从这里，我计算特征值 - 对于矩阵 $A$，特征值由 $det| 给出A-\lambda I|$ 。在 2x2 矩阵（我们的 Hessian 矩阵）中，我们有：
$$
A = \begin{bmatrix}
一个&amp;乙\
和d
\end{b矩阵}
$$
$$
\lambda^2 - \lambda(a+d) + (ad-bc) = 0
$$
此函数将有两个根 $\lambda_1$ 和 $\lambda_2$：
$$
\lambda_1 = -\frac{n}{\sigma^2}, \quad \lambda_2 = \frac{n}{2(\sigma^2)^2} - \frac{1}{(\sigma^2) ^3} \sum_{i=1}^{n} (x_i - \mu)^2
$$
目前尚不清楚 $\lambda_2$ 中的第二项是否大于 $\ 中的第一项lambda_2$。如果第二项确实大于第一项，则 $\lambda_2$ 将为负数。
如果我们使用这样的论点：
$$
s^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2
$$
$$
n s^2 = \sum_{i=1}^{n} (x_i - \mu)^2
$$
$$E(s^2) = \sigma^2$$
然后我们可以说：
$$E[(x_i - μ)^2] = nσ^2$$
$$\lambda_2 = \frac{n}{2(\sigma^2)^2} - \frac{1}{(\sigma^2)^3} n\sigma ^2 = \frac{n}{2(\sigma^2)^2} - \frac{n}{(\sigma^2)^2} = -\frac{n}{2} \frac{1} {(\sigma^2)^2}$$
因此，$\lambda_2$ 近似为负。
因此，我们可以说两个特征值均为负，这表明似然函数是凹的。据我了解，从优化的角度来看，优化凹函数和优化凸函数是一样的。
令人担忧的情况是当特征值既为正又为负时，表明该函数是非凸的（即多个局部最小值）并且是一个潜在的难以优化的问题。
我的分析正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636950/proving-that-the-likelihood-of-a-normal-distribution-is-not-non-convex</guid>
      <pubDate>Tue, 16 Jan 2024 00:48:27 GMT</pubDate>
    </item>
    <item>
      <title>在序数回归累积链接模型中，何时使用尺度效应（与/使用随机截距）</title>
      <link>https://stats.stackexchange.com/questions/636947/in-ordinal-regression-cumulative-link-models-when-to-use-scale-effects-versus</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636947/in-ordinal-regression-cumulative-link-models-when-to-use-scale-effects-versus</guid>
      <pubDate>Tue, 16 Jan 2024 00:14:38 GMT</pubDate>
    </item>
    <item>
      <title>卡方检验的个体预期频率的统计显着性</title>
      <link>https://stats.stackexchange.com/questions/636945/statistical-significance-of-individual-expected-frequencies-with-a-chi-squared-t</link>
      <description><![CDATA[我对 4 个不同组内的人口统计数据进行了卡方检验。我发现每个人口群体（性别：男性、女性；州：加利福尼亚州、华盛顿州等）与总比例显着不同。为了表示这一点，我用箭头指示每个组与预期值的偏差。在这样做的过程中，我发现一些群体非常接近预期值，而另一些群体则与某些人口统计数据的预期值相差很大。我很好奇是否有一种方法可以看出哪些偏差是显着的，以便我可以用双箭头表示那些偏差。]]></description>
      <guid>https://stats.stackexchange.com/questions/636945/statistical-significance-of-individual-expected-frequencies-with-a-chi-squared-t</guid>
      <pubDate>Mon, 15 Jan 2024 23:19:04 GMT</pubDate>
    </item>
    <item>
      <title>每年加权平均值[关闭]</title>
      <link>https://stats.stackexchange.com/questions/636943/weighted-averages-per-year</link>
      <description><![CDATA[我有按年份划分的制造缺陷数据和每年的样本量。我正在尝试创建一个加权 Yes/No ，按 N 加权。
 是 否 N 年
  1402 (92.5%) 114 (7.5%) 1516 2018
  1697 (93.1%) 126 (6.9%) 1823 2019
  1023 (91.5%) 96 (8.5%) 1119 2020
  1302 (92.43%) 108 (7.57%) 1410 2021
  1204 (92.49%) 98 (7.51%) 1302 2022

我知道这就是我们创建权重的方式。
 是 否 N 重量年份
  1402 (92.5%) 114 (7.5%) 1516 1516/7170=0.211 2018
  1697 (93.1%) 126 (6.9%) 1823 1823/7170=0.254 2019
  1023 (91.5%) 96 (8.5%) 1119 1119/7170=0.156 2020
  1302 (92.43%) 108 (7.57%) 1410 1410/7170=0.196 2021
  1204 (92.49%) 98 (7.51%) 1302 1302/7170=0.181 2022

不确定此后如何继续。
数据 &lt;- data.frame(
  是 = c(1402, 1697, 1023, 1302, 1204),
  否 = c(114, 126, 96, 108, 98),
  N = c(1516, 1823, 1119, 1410, 1302),
  年份 = c(2018, 2019, 2020, 2021, 2022)
）

Total_sample_size &lt;- sum(data$N)
数据$权重&lt;-数据$N /total_sample_size

非常感谢任何建议。提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/636943/weighted-averages-per-year</guid>
      <pubDate>Mon, 15 Jan 2024 22:01:26 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.metrics.r2_score vs sklearn.LinearRegression.score [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636933/sklearn-metrics-r2-score-vs-sklearn-linearregression-score</link>
      <description><![CDATA[我正在使用 sklearn 来计算 X（真实年龄）和 Y（预测年龄）之间的决定系数。但是我为两种不同的方法获得了两个不同的值，据我所知，这应该是相同的。
这是带有直线拟合的数据。 （我知道这不太适合，但在研究模型架构之前我正在研究管道）

然后，尝试计算 R2 值，检查两种不同的方法。我做错了什么吗？
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt; Xs
数组([[6.80000000e+001],
       [7.50000000e+001],
       [5.90000000e+001],
       ...,
       [1.15882924e-310]，
       [1.15882924e-310]，
       [1.15882924e-310]]）
&gt;&gt;&gt;&gt;&gt;伊苏
数组([[58.503006],
       [67.75964],
       [63.875973],
       ...,
       [67.37394],
       [67.37394],
       [67.37394]]）
&gt;&gt;&gt;&gt;&gt;回归器=线性回归()
&gt;&gt;&gt;&gt;&gt;回归器.fit(Xs, Ys)
线性回归()
&gt;&gt;&gt;&gt;&gt;回归器.score(Xs, Ys)
0.006946203557267383
&gt;&gt;&gt;&gt;&gt; r2_score(Xs, Ys)
-0.16379061117029314
]]></description>
      <guid>https://stats.stackexchange.com/questions/636933/sklearn-metrics-r2-score-vs-sklearn-linearregression-score</guid>
      <pubDate>Mon, 15 Jan 2024 18:10:07 GMT</pubDate>
    </item>
    <item>
      <title>将中值绝对偏差转换为标准偏差</title>
      <link>https://stats.stackexchange.com/questions/636914/converting-median-absolute-deviation-to-standard-deviation</link>
      <description><![CDATA[我正在从事一些医学研究，我想知道将中位数和中位数绝对偏差 (MAD) 转换为平均值和标准差的最直接方法是什么。
如果有人有任何链接以及我可以引用的来源链接，这将非常有帮助。
我需要转换的原因是因为我正在使用 RevMan 进行基于其他研究的荟萃分析，一些研究具有均值和 SD，而另一些研究具有中位数和 MAD，我希望能够将它们全部包含在一项统计中分析。
我已经看到了一些关于数据是否呈正态分布的事情，不幸的是，我没有原始数据，因为我正在对其他研究进行荟萃分析，所以我不知道我是否可以假设它是正态分布的？]]></description>
      <guid>https://stats.stackexchange.com/questions/636914/converting-median-absolute-deviation-to-standard-deviation</guid>
      <pubDate>Mon, 15 Jan 2024 14:04:44 GMT</pubDate>
    </item>
    <item>
      <title>lme4 中不同变量的多个样条项之间的相互作用如何工作？我的方法/语法有效吗？</title>
      <link>https://stats.stackexchange.com/questions/636867/how-do-interactions-between-multiple-spline-terms-for-different-variables-work-i</link>
      <description><![CDATA[我目前正在分析我进行的一项实验的数据集，在该实验中我研究了不同音调组合对青蛙叫声反应的影响。呈现给青蛙的每个刺激都是 2 个不同频率的音调的组合（即每个单独的刺激由频率 1 和频率 2 组成，但每个刺激都可以采用多个不同的值）。每个刺激中的 2 个音调的强度也不同，我有大量的频率/强度组合 (~450)。对于青蛙对每种刺激的每种反应，我记录了它们是表现出反应 A 还是反应 B。我从 43 只青蛙中得到了约 23,000 个对不同刺激的反应。
因此，我构建了一个混合效应逻辑回归，其中响应 A 或 B 作为结果变量。根据之前对这些青蛙的了解，我预计对不同频率/强度组合的反应将完全相互依赖且特定于上下文，因此我在音调 1 频率、音调 2 频率和音调 1 之间的强度差之间加入了 3 向交互2. 然而，当使用 DHARMa 检查模型假设时，音调 1 频率和结果变量以及音调 2 频率和结果变量之间的非线性关系很明显。使用具有 3 个自由度的自然样条对这两种关系进行建模似乎可以解决这些问题，并且在此之后我的所有 DHARMa 图看起来都很棒。
模型语法：
glmer(frog_response ~ ns(tone_1_Frequency, df = 3) * ns(tone_1_Frequency, df = 3) * Strength_difference +
(1 | block_ID) + (1| block_ID:male_ID), family = 二项式, data = data)

我还包括了我认为重要的其他几个协变量，并包括了数据支持它们的所有变量的随机斜率（没有奇异拟合等），但我没有在上面的示例中包括这些，以便减少视觉混乱。
我的问题是：

像这样包含两个样条项之间的交互作用是否有效？
我意识到样条系数的解释方式与常规系数不同，而是表示应用于某个基函数的权重，那么这些系数之间的相互作用是否以同样的方式有意义？从我的阅读来看，这似乎在数学上是有意义的，但像这样复杂的样条相互作用的最大问题是系数的解释非常具有挑战性。然而，我能够通过 SJPlot 获得这种 3 向交互的良好可视化，它讲述了一个非常清晰、引人注目且合理的故事。因此，从可视化中看，这些青蛙所发生的事情的大致情况是非常明显和有趣的，即使系数本身可能很难从模型汇总表中解释。
那么，这种方法以及我用来执行它的语法看起来有效吗？
如果没有，您会推荐什么？

感谢您的宝贵时间以及您提供的任何信息！]]></description>
      <guid>https://stats.stackexchange.com/questions/636867/how-do-interactions-between-multiple-spline-terms-for-different-variables-work-i</guid>
      <pubDate>Mon, 15 Jan 2024 02:18:48 GMT</pubDate>
    </item>
    </channel>
</rss>