<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 01 Feb 2024 01:00:44 GMT</lastBuildDate>
    <item>
      <title>理解 Word2vec 架构时遇到的问题</title>
      <link>https://stats.stackexchange.com/questions/638250/problems-in-understanding-word2vec-architectures</link>
      <description><![CDATA[我可能有一个非常简单的问题，但我在网络上没有找到任何明确的资源。

首先让我们考虑 Skip-gram 模型，在该模型中，我们尝试根据目标单词预测上下文单词。在这种情况下，输入层是一个大小为 N（词汇表大小）的 one-hot-向量；输出层由 k 个不同的向量组成（其中 k 是窗口的大小）？那么对于每个单词，我们将有 3 种不同的概率出现在目标单词上下文中的 3 个不同位置？

如果我们考虑 CBOW 模型并且 k=3，在这种情况下我们将有 3 个输入单热向量。对于给定的单词 i，单词嵌入是通过对由连接神经元 i 到隐藏层所有神经元的权重组成的 3 个向量进行平均来给出的？&lt; /p&gt;

]]></description>
      <guid>https://stats.stackexchange.com/questions/638250/problems-in-understanding-word2vec-architectures</guid>
      <pubDate>Wed, 31 Jan 2024 23:41:37 GMT</pubDate>
    </item>
    <item>
      <title>当我“想”接受通常的零假设时，我该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/638249/what-do-i-do-when-i-want-to-accept-the-usual-null-hypothesis</link>
      <description><![CDATA[我有来自两个随机变量的样本，并且假设方差相等的正态分布。我想证明分布等于意味着$\mu_1$和$\mu_2$ 。
通常的双尾 t 检验用于相反的情况。也就是说，构建以下内容并希望得到一个足够小的 $p$ 来拒绝 H0。

H0：原假设 $\mu_1 = \mu_2$
H1：备择假设 $\mu_1 \neq \mu_2$

但我想拒绝 H1，并通过统计显着性证明 H0 是正确的。
我可以使用相同的双尾 t 检验并以不同的方式解释结果吗？或者我需要一个完全不同的假设检验吗？
&lt;小时/&gt;
我的第一反应是使用相同的测试，最终得到一个大的 $p$ 而不是一个小的，然后声称 H1 被自信地拒绝$1 - p$。但在弄乱了一些数据之后，我不确定这是否是正确的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/638249/what-do-i-do-when-i-want-to-accept-the-usual-null-hypothesis</guid>
      <pubDate>Wed, 31 Jan 2024 23:40:31 GMT</pubDate>
    </item>
    <item>
      <title>可逆跳跃 MCMC 和泊松过程</title>
      <link>https://stats.stackexchange.com/questions/638246/reversible-jump-mcmc-and-poisson-processes</link>
      <description><![CDATA[假设我们有一个时间间隔 $t \in [0, T]$，其中事件以具有任意时间相关速率的泊松过程发生 $\lambda(t)$。这些事件发生的时间为 $Y=(Y_1, Y_2, \dotso, Y_M)$，时间为 $M$ 事件，其中 $Y$ 和 $M$ 都是随机变量，$0 \leq Y_i \leq T$。 $T$ 已修复。
目标是使用以下方法估计事件数 $M$ 及其时间 $Y$ MCMC。
我们知道 $M$ 服从泊松分布，速率为 $g = \int\limits^T_0 \lambda (s) ds$，因此 $p(M|T) = \frac{e^{-g} g^M}{M!}$.
我认为联合概率密度是：
$$
p(Y,M|T) = p(Y|M,T) p(M|T) = \Big( \prod\limits_{i=1}^M \frac{\lambda(y_i)}{g} \Big) \Big( \frac{e^{-g} g^M}{M!} \Big) = \frac{e^{-g}}{M!} \prod\limits_{i=1} ^M \lambda(y_i)
$$
我已确认，对于 $Y$ 和 $M$&lt;，此积分总和为 1 /span&gt;.
但是，我无法使用 MCMC 从此发行版中采样。目前，我有两个 MCMC 提案，并且在链的每个步骤中以相同的概率选择这些提案。

移动事件。对 $i$ 中的索引之一进行采样Y$ 和示例 $Y_i^\prime \sim \text{U}(0,T)$。黑斯廷斯比率 $\frac{q(M,Y|M^\prime,Y^\prime)}{q(M^\prime,Y^\prime|M,Y )} = \frac{\frac{1}{MT}}{\frac{1}{MT}} = 1$。如果$M=0$提案被拒绝。

创建/销毁事件。
a.以 0.5 的概率创建一个事件。 $M^\prime \leftarrow M+1$。对索引 $i \sim \text{U}(1, \dotso, M)$ 进行采样，并将所有下游索引上移 1：$Y_{i+1}^\prime \leftarrow Y_i, Y_{i+2}^\prime \leftarrow Y_{i+1}, \dotso$。新值统一采样 $Y_i^\prime \sim \text{U}(0, T)$。
b.以 0.5 的概率摧毁一个事件。 $M^\prime \leftarrow M-1$。对索引 $i \sim \text{U}(1, \dotso , M)$ 进行采样并删除它，将所有下游索引向下移动 1：&lt; span class=&quot;math-container&quot;&gt;$Y_{i}^\prime \leftarrow Y_{i+1}, Y_{i+1}^\prime \leftarrow Y_{i+2}, \dotso$。如果$M=0$提案被拒绝。
出生事件的黑斯廷斯比率为 $\frac{q(M,Y|M^\prime,Y^\prime)}{q(M^\prime) ,Y^\prime|M,Y)}=\frac{\frac{1}{2}\frac{1}{M+1}}{\frac{1}{2}\frac{1}{T }} = \frac{T}{M+1}$，以及 $\frac{M}{T}$ 表示死亡事件。&lt; /p&gt;


但是，如上所述，该算法没有对正确的分布进行采样（即，估计的事件数量 $M$ 通常大于预期值 $g$）。我认为问题归结为第二个运算符中使用的雅可比术语，其中涉及维度的变化。因此 MCMC 期间的接受概率为：
$$
\alpha = \min\Big(1, \frac{p(Y^\prime, M^\prime|T) q(M,Y|M^\prime,Y^\prime)}{p(Y, M |T) q(M^\prime,Y^\prime|M,Y)} |J| \Big)
$$
对于一些雅可比$J$。但是 $J$ 是什么？或者也许问题出在其他地方。任何帮助表示赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/638246/reversible-jump-mcmc-and-poisson-processes</guid>
      <pubDate>Wed, 31 Jan 2024 22:09:30 GMT</pubDate>
    </item>
    <item>
      <title>帮助我理解 Z 系数</title>
      <link>https://stats.stackexchange.com/questions/638243/help-me-understand-z-coefficients</link>
      <description><![CDATA[在处理样本大小方程时，使用 Z 系数 Z$\alpha$ 和 &lt; em&gt;Z$\beta$ 这是 I 类和 II 类错误率的 Z 系数。这些系数来自标准正态分布。
如果您正在使用的数据不是正态分布，这有什么关系吗？具体来说，我正在处理 beta 分布的植被数据。我是否需要使用不同分布的系数，或者这与采样数据无关？]]></description>
      <guid>https://stats.stackexchange.com/questions/638243/help-me-understand-z-coefficients</guid>
      <pubDate>Wed, 31 Jan 2024 22:00:52 GMT</pubDate>
    </item>
    <item>
      <title>谁能帮助我找到错误并运行此 R 代码来模拟孟德尔随机化研究中的平衡多效性效应？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638242/could-anyone-help-me-to-locate-error-and-run-this-r-code-to-simulate-for-balance</link>
      <description><![CDATA[参数取值为 NA [请参考图片]。我是否错过了与信息“temp = as.integer(commandArgs(trailingOnly = TRUE))”相关的代码的任何部分
具有平衡多效性和违反 InSIDE 假设的摘要级模拟
rm(列表=ls())
库（数据.表）
图书馆（dplyr）
图书馆（大众）
库（孟德尔随机化）
库（MRMix）
图书馆（拉普斯先生）
库（MRPRESSO）
图书馆（受处罚）
来源（“MR_lasso.R”）
thetavec = c(0.2, 0, -0.2)
θUvec = c(0.3, 0.5)
Nvec = c(5e4, 8e4, 1e5, 1.5e5, 2e5, 5e5, 1e6) # 1:7
prop_invalid_vec = c(0.3, 0.5, 0.7)
temp = as.integer(commandArgs(trailingOnly = TRUE))
theta = thetavec[temp[1]] # 从 X 到 Y 的真实因果效应
thetaU = thetaUx = thetaUvec[temp[2]] # 混杂因素对 Y/X 的影响
N = Nvec[temp[3]] # 曝光 X 的样本大小
prop_invalid = prop_invalid_vec[temp[4]] # 无效 IV 的比例
pthr = 5e-8 # 工具选择的 p 值阈值
NxNy_ratio = 2 # X 和 Y 的样本大小比率
M = 2e5 # 代表基因组中常见变异的独立 SNP 总数
效应大小分布的模型参数
pi1=0.02*(1-prop_invalid); pi3=0.01
pi2=0.02prop_invalid;
sigma2x = sigma2y = 5e-5；西格玛2u = 1e-4; sigma2x_td = sigma2y_td = (5e-5)-thetaUthetaUx*sigma2u
print(paste(“N”, N, “pthr”, pthr, “pi1”, pi1, “theta”, theta, “thetaU”, thetaU, “prop_invalid”, prop_invalid, “ ;NxNy_ratio”,NxNy_ratio))
请指导我同样的事情
谢谢
西尔维娅]]></description>
      <guid>https://stats.stackexchange.com/questions/638242/could-anyone-help-me-to-locate-error-and-run-this-r-code-to-simulate-for-balance</guid>
      <pubDate>Wed, 31 Jan 2024 21:52:24 GMT</pubDate>
    </item>
    <item>
      <title>时间序列交叉验证和避免过度拟合</title>
      <link>https://stats.stackexchange.com/questions/638241/time-series-cross-validation-and-avoidance-of-overfitting</link>
      <description><![CDATA[所以。我正在使用不同类型的分类器（深度学习、基于字典、基于距离、基于间隔、基于特征、卷积）对各种数据集进行时间序列分类。据我所知，k-fold 对于时间序列来说不是一个好的选择，所以我改用了 TimeSeriesSplit。然而，当然，即使进行交叉验证，也不能保证过度拟合。 K-fold 通过洗牌解决了这个问题，但 TimSeriesSplit 没有这样做（实际上，这就是重点）。我会使用 Dropout Layers 或正则化，但这些技术仅适用于深度学习模型，我的目标基本上是比较所有这些算法的结果。在我的例子中，什么是适用于所有类型分类器的好技术？]]></description>
      <guid>https://stats.stackexchange.com/questions/638241/time-series-cross-validation-and-avoidance-of-overfitting</guid>
      <pubDate>Wed, 31 Jan 2024 21:35:56 GMT</pubDate>
    </item>
    <item>
      <title>如何评估事件在群体内的影响</title>
      <link>https://stats.stackexchange.com/questions/638240/how-to-assess-effect-of-event-within-group</link>
      <description><![CDATA[我正在尝试为我的组织对投诉处理系统的变化进行分析，看看它是否对一些人口变量（主要是性别和种族，因为有很多人口统计变量）产生了任何不利影响。其他变量的数据缺失）。
2019 年，我们从一个系统转向了另一个系统。在新系统中，进入组织的所有信息均由 2019 年之前不存在的团队处理。感兴趣的结果是投诉是否已进展到另一个团队，以及投诉是否随后进展到纪律处分（两个投诉流程的每个部分都需要单独分析）。
通过新系统，我们现在记录了更多的投诉，只有一小部分得到了进展，这意味着新系统在任何看待这一问题的模型中都不可避免地会产生相当大的影响。这使得观察干预前和干预后对整个人群来说毫无意义，但在群体内可能会发现一些有趣的趋势，而这正是最令人感兴趣的。
我正在尝试找出最好采取什么方法来测试系统的变化是否对团体产生了任何不利影响。就投诉标记的信息而言，两个系统之间的数据并不完全匹配，这使得只有少数变量可以使用，从而很难控制大量潜在的差异。还有一个问题是同一个人可能会受到多次投诉（这是否会造成面板不平衡？）。
我一直在研究中断时间序列分析，但这似乎更适合在人口水平上观察事物，而不是在群体差异内。差异之差方法也是如此。

我想知道是否有一个基本的逻辑回归模型
虚拟变量与人口变量相互作用后
兴趣可能是出路？这种方法有意义吗？
我怎样才能包含尽可能多的数据，同时还可以控制
某些个体多次出现在数据集中？
是否有一种中断时间序列分析方法，可以对同一群体内的不同组进行逐步回归，然后比较不同组之间的结果？这似乎是最简单的方法，但我还没有找到任何这方面的文献，这让我认为这可能不是可行的方法。
总体上最好采取哪种方法？

我觉得我现在正在创建一个垃圾输入、垃圾输出模型，特别是考虑到缺乏可用的有用变量，并且不知道采取的最佳方法。任何帮助将非常感激。我以前没有做过这么复杂的数据的干预分析，有点力不从心。]]></description>
      <guid>https://stats.stackexchange.com/questions/638240/how-to-assess-effect-of-event-within-group</guid>
      <pubDate>Wed, 31 Jan 2024 21:12:46 GMT</pubDate>
    </item>
    <item>
      <title>零 RE 方差 GLMM 估计</title>
      <link>https://stats.stackexchange.com/questions/638238/zero-re-variance-glmm-estimate</link>
      <description><![CDATA[当使用 R 中的 lme4::glmer() 对二进制结果进行随机截距拟合 GLMM 时，看起来好像是固定效应输出，包括参数和方差估计，与随机截距的方差估计为 0 时的 glm() 完全相同（或至少在 $10^{- 6}$）。基于上一篇文章（尽管数据存在一些变化，但为什么我的混合模型中随机效应的方差为零？），这是由于优化受限（参考 https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html）允许估计达到边界。
它们实际上是为了生产完全相同的合身吗？如果是这样，那么似乎glmer()是先验假设随机截距为0（几乎可以肯定，即方差= 0）；否则，有可能除以 0。]]></description>
      <guid>https://stats.stackexchange.com/questions/638238/zero-re-variance-glmm-estimate</guid>
      <pubDate>Wed, 31 Jan 2024 20:47:57 GMT</pubDate>
    </item>
    <item>
      <title>如何报告论文中从 GLM 中排除的预测变量？</title>
      <link>https://stats.stackexchange.com/questions/638236/how-to-report-predictors-excluded-from-a-glm-in-a-paper</link>
      <description><![CDATA[我是广义线性模型的新手，希望将它们用于我的第四年生态学论文项目。请原谅我的无知，我已经尽力自己研究这个问题，但已经进入了一个死胡同，需要一些帮助。
我有一个 GLM 的解释变量和四个预测变量，并且使用高斯分布。我在 RStudio 中使用不同的预测变量运行了多个 GLM，以获得最佳模型，但是最佳模型（具有最低 AICc 分数）是简化模型，因此仅使用其中两个预测变量。
在我的论文中报告这一点时，我该如何看待模型中未包含的预测变量？
我目前的理解是，我报告最佳模型（仅包含两个预测变量）并声明其他两个已从模型中排除。然后我是否完全忽略其他两个预测变量，或者我应该对它们分别运行不同的统计分析，例如标准线性回归？
我从多元线性回归开始，但遇到了问题，因为系数估计值很大并且调整后的 R 平方很低。我检查了诊断，图看起来非常好，所以我很难理解发生了什么。我认为在这种情况下 GLM 会是一个更好的工具，但我总是发现它们令人生畏。
我通过教程看到，您可以像多元线性回归一样拟合 GLM，但您需要指定族分布。当我对完整模型执行此操作时，系数估计值与绘制的内容不匹配。例如，散点图表明存在正斜率，但估计值返回为 0.003 或高度负斜率。我知道这通常是由于多重共线性造成的，因此我对多重共线性进行了 VIF 检查，并将导致问题的变量集中起来。然后我读到，这通常是因为其他预测变量抑制了主要预测变量，所以我决定运行多个模型。
我使用 AICc 和 ANOVA 比较模型，这很好，现在我有一个运行良好的简化模型，但它去掉了两个预测变量。我的问题是这实际上意味着什么以及我如何报告结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/638236/how-to-report-predictors-excluded-from-a-glm-in-a-paper</guid>
      <pubDate>Wed, 31 Jan 2024 20:37:31 GMT</pubDate>
    </item>
    <item>
      <title>比较和选择模型，构建目标函数（复杂性、参数值分布的先验知识）</title>
      <link>https://stats.stackexchange.com/questions/638235/comparing-and-selecting-models-constructing-objective-function-complexity-pri</link>
      <description><![CDATA[我们有一组模型，这些模型是使用一些拟合例程导出的，这些例程利用给定模型的 $\chi^2$ 来优化参数值。
model1 有 100 个参数，
model2有99个参数，
...
model10 有 10 个参数..
所有参数都是使用回归技术估计的，但模型结构不同（例如，从最大复杂度下降到最低复杂度）。
所有比较模型的数据始终相同。
所有估计的参数值在现实生活中都有一些已知的分布。我们有关于此分布的先验知识，例如，n.d.有一些均值和方差（对于每个参数）。
我们希望将该信息用于两个目的：

用于比较和选择最佳模型（例如，如果我们需要比较给定数据的各种模型，但我们不知道这些模型是如何得出的）。

回归 - 将信息纳入目标函数。
使用有关参数分布的先验知识来选择更可能的参数（在给定数据和参数分布的先验知识的情况下，最大化参数值的可能性）。


这里的问题是：

我们是否可以比较不同复杂度的模型，因为我们可以计算 chi2 值 - 这将是拟合优度，也可能是在给定数据的情况下具有此类参数的可能性或概率度量？或者，如果每个模型具有不同数量的参数，那么从似然/概率函数计算的角度来看，这不是一个正确的公式？

例如，AIC/BIC (c) 使用 $\chi^2$ 值并对参数 k 的数量进行惩罚。尽管如此，它并不关心参数的值（这可能非常不可能，物理约束等）。
在我们的例子中，我们有先验信息。例如，添加如下内容：
$$OF = \chi^2 + 2 * PL$$
其中 PL - 是根据一些先验知识计算得出的术语。
例如，我们可以计算给定数据的模型复杂性概率的某个值和/或具有多个参数值的概率度量...给定参数分布。
注意 - 所有参数都源自相同的数据，但我们不关心它们是如何获得的。我们只关心他们的价值观和合身质量。
因此 PL 必须使用我们关于参数分布的知识来计算。
但是计算 PL 并比较不同模型复杂性的测量值是否正确？这种方法可能存在哪些问题？看来它与贝叶斯推理密切相关..]]></description>
      <guid>https://stats.stackexchange.com/questions/638235/comparing-and-selecting-models-constructing-objective-function-complexity-pri</guid>
      <pubDate>Wed, 31 Jan 2024 20:32:00 GMT</pubDate>
    </item>
    <item>
      <title>我们可以在使用 lavaan 的 SEM 模型中使用多个序数内生变量吗？</title>
      <link>https://stats.stackexchange.com/questions/638234/can-we-use-multiple-ordinal-endogeneous-variables-in-sem-model-using-lavaan</link>
      <description><![CDATA[我有三个内生变量，每个变量都使用 5 点李克特量表进行测量，范围从“非常同意”到“非常不同意”。我想使用 SEM 通过 Lavaan 进行分析。到目前为止，我在教程中遇到的所有示例都有简单的模型。因此，我想知道是否可以使用 lavaan 在 SEM 模型中使用多个有序内生变量，以及是否有任何教程对我有用。]]></description>
      <guid>https://stats.stackexchange.com/questions/638234/can-we-use-multiple-ordinal-endogeneous-variables-in-sem-model-using-lavaan</guid>
      <pubDate>Wed, 31 Jan 2024 20:09:32 GMT</pubDate>
    </item>
    <item>
      <title>bagging成功的说明</title>
      <link>https://stats.stackexchange.com/questions/638231/explanation-for-the-success-of-bagging</link>
      <description><![CDATA[我正在阅读机器学习 - 工程师和科学家的第一门课程。在第 168 页，他们粗略地解释了 bagging 为何有效。我对他们的解释有点困惑。
他们考虑$B$引导数据集的集合$\mathcal{T}^{(b)}$  与 $b=1,2, \ldots, B$。它们表示来自 $b$ 个引导数据集 $\mathcal{T}^{(b)}$ 的预测 （取自原始数据集 $\mathcal{T}$）并在点 $\mathbf 处进行评估{x}_\star$ 为 $\tilde{y}^{(b)}_\star \equiv y(x_\star; \mathcal{T} ^{(b)})$。他们假设这些预测的平均值是
$$ \mathbb{E}[\tilde{y}^{(b)}_\star] = \mu^2$$
方差是
$$ \mathrm{Var}[\tilde{y}^{(b)}_\star] = \sigma^2$$
预测之间的平均相关性是
$$ \text{avg cor}[\tilde{y}^{(b)}_\star] =\frac{1}{B(B-1)}\sum_ {b\ne c}\mathbb{E}[(\tilde{y}^{(b)}_\star-\mu)(\tilde{y}^{(c)}_\star-\mu) ] = \rho \sigma^2$$
他们指出
&lt;块引用&gt;
“所有基础模型及其预测均源自相同的数据 $\mathcal{T}$ （通过引导程序）和 $\tilde{y}^{(b)}_\star$ 因此分布相同但相关。”

他们的解释是这样的：袋装预测的平均值是
$$ \mathbb{E}[\frac1B \sum^B_{b=1}\tilde{y}^{(b)}_\star] = \sigma^2$ $
方差是
$$ \mathrm{Var}[\frac1B \sum^B_{b=1}\tilde{y}^{(b)}_\star] = \frac{1- \rho}{B} \sigma^2+\rho \sigma^2 $$
如果$\rho&lt;1$，则通过增加引导样本来减少方差。
我对他们如何将 $\tilde{y}^{(b)}_\star$ 视为随机变量感到有点困惑，即概率是多少我们对 $\mathbb{E}[\tilde{y}^{(b)}_\star]$ 进行平均分布吗？由于引导过程减少了预期新数据误差的偏差-方差分解中的方差，因此我假设随机性来自原始数据集 $\数学{T}$。但是我们是否假设引导样本的索引是固定的（即 ${\mathcal{T}&#39;}^{(b)}$ 始终是通过取带有索引的数据点 $i \in \lbrace i^{(b)}_1, i^{(b)}_2, \ldots, i^{(b)}_n \rbrace $ 但 ${\mathcal{T}&#39;}^{(b)}$ 是随机的），或者它们在 $\mathcal{T}$ ?
另外，谁能直观地解释一下什么样的数据和模型特征会增加$\rho$？]]></description>
      <guid>https://stats.stackexchange.com/questions/638231/explanation-for-the-success-of-bagging</guid>
      <pubDate>Wed, 31 Jan 2024 19:21:51 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法使用预定义的 GARCH 模型或从 rmgarch 包 R 的 dccspec 中另一个自定义模型过滤的标准偏差值？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638230/is-there-any-way-to-use-a-predefined-garch-model-or-filtered-standard-deviation</link>
      <description><![CDATA[dccspec(uspec = multispec(replicate(10, spec) ),
                            dcc顺序 = c(1,1),
                            分布=“mvnorm”，
                            型号 = &#39;aDCC&#39;)

在 dccspec 的参数中，我想集成定制的 GARCH 模型或至少集成该模型的标准差值，并希望 DCC 模型仅估计相关性。
运行上面的代码会出现以下错误：
h(simpleError(msg, call)) 中的错误：
  在为函数“dccspec”选择方法时评估参数“uspec”时出错：
不是单变量 GARCH 规范的有效列表。
]]></description>
      <guid>https://stats.stackexchange.com/questions/638230/is-there-any-way-to-use-a-predefined-garch-model-or-filtered-standard-deviation</guid>
      <pubDate>Wed, 31 Jan 2024 19:03:38 GMT</pubDate>
    </item>
    <item>
      <title>最小化零一损失与最小化铰链损失何时不同</title>
      <link>https://stats.stackexchange.com/questions/638227/when-is-minimizing-zero-one-loss-different-than-minimizing-hinge-loss</link>
      <description><![CDATA[假设我们使用线性预测器，我试图从概念上理解对于一组点，它如何具有相对较低的 0-1 损失但相对较高的铰链损失。例如，有人告诉我，可以选择一组点，使得所有这些线性预测变量的 0-1 损失最小（即 $p_w(x) = \langle w, x \rangle$），其中 $w$ 位于二维平面中）低于 0.1，但对于同一组点，预测器最小化铰链损失有 0-1 损失，高于某个阈值，例如 $0.5$。也就是说，寻求最小化铰链损失可能会导致同一预测器的 0-1 损失（与具有最佳 0-1 损失的预测器相比）。
针对这个问题，在我看来，学习了SVM之后，一直很难理清0-1损失和铰链损失的概念。我对铰链损失的理解是，随着错误分类的点进一步增加，它会变得更大，但对我来说，“最小化铰链损失”的预测器会带来什么并不直观。对于给定的一组点来说，它看起来像这样，而它是立即的，至少在 $\mathbb{R^2}$ 中，对我来说显然是最小化超平面0-1 输球的样子。谁能帮助我获得一些直觉并理解这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/638227/when-is-minimizing-zero-one-loss-different-than-minimizing-hinge-loss</guid>
      <pubDate>Wed, 31 Jan 2024 18:40:41 GMT</pubDate>
    </item>
    <item>
      <title>稀疏 0,1 数据的分布选择</title>
      <link>https://stats.stackexchange.com/questions/638221/distributional-choices-for-sparse-0-1-data</link>
      <description><![CDATA[我正在使用 GAM 对二元响应变量（0 或 1）与几个连续固定和随机解释变量之间的关系进行建模。看起来二项分布是标准选择，但数据非常稀疏，有 21,000 个 0，只有大约 800 个 1。
我很好奇是否还有其他发行版可以更好地处理这些数据？我对 beta 二项式很​​感兴趣，但据我了解，它适用于 0 到 1 之间的数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/638221/distributional-choices-for-sparse-0-1-data</guid>
      <pubDate>Wed, 31 Jan 2024 17:26:24 GMT</pubDate>
    </item>
    </channel>
</rss>