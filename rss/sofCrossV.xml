<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 02 Nov 2024 12:30:35 GMT</lastBuildDate>
    <item>
      <title>伯努利随机变量的理想假设检验是什么？</title>
      <link>https://stats.stackexchange.com/questions/656637/what-is-the-ideal-hypothesis-test-for-bernoulli-random-variables</link>
      <description><![CDATA[如果您有两台乒乓球输出机，用作伯努利试验。第一台机器给玩家 1000 个球，其中 p=0.7 为红色，0.3 为黄色。第二台机器给玩家 100 个球，伯努利概率未知。可以进行哪些假设检验来检查第一台和第二台机器之间的分布相似性？]]></description>
      <guid>https://stats.stackexchange.com/questions/656637/what-is-the-ideal-hypothesis-test-for-bernoulli-random-variables</guid>
      <pubDate>Sat, 02 Nov 2024 12:16:37 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中执行小鼠实验时，Nelson-Aalen 累积风险导致多重共线性</title>
      <link>https://stats.stackexchange.com/questions/656634/nelson-aalen-cumulative-hazard-causing-multicollinearity-when-performing-mice-in</link>
      <description><![CDATA[我正在执行生存分析，对多重插补还不太熟悉，如果能就此问题提供任何见解/专业知识，我将不胜感激。
我有一个大型数据库，需要插补 2 个变量，其中缺失率为 5%。
总的来说，我的预测矩阵有 12 个协变量，包括事件指标和 Nelson-Aalen 累积风险（根据 Royston &amp; White）。
当我在预测矩阵中使用 Nelson-Aalen 风险运行插补时，我得到了一个记录事件
imp =mice(study_data, method=meth, predictorMatrix=predM, m=2, maxit=10, seed=12345)

head(imp$loggedEvents, 10)
it im dep meth out
1 1 1 smoke pmm cumhaz_prim
2 1 1 bmi_cat pmm cumhaz_prim
3 1 1 edu_cat pmm 所有预测因子都是常数或相关性太高。
4 1 2 smoke pmm cumhaz_prim
5 1 2 bmi_cat pmm cumhaz_prim
6 1 2 edu_cat pmm 所有预测因子都是恒定的或相关性太高。
7 2 1 smoke pmm cumhaz_prim
8 2 1 bmi_cat pmm cumhaz_prim
9 2 1 edu_cat pmm 所有预测因子都是恒定的或相关性太高。
10 2 2 smoke pmm cumhaz_prim

但是，当我运行没有 Nelson-Aalen 风险函​​数的模型时，我的多重插补在没有记录事件的情况下工作正常。
在阅读 Stef Van Buuren 的非常有启发性的书（灵活插补方法）后，我尝试添加岭惩罚=0.01，但这种策略不起作用。
不确定如何进行，因为从我对文献的阅读来看，建议在对生存数据进行多重插补时使用累积风险和事件指标。
谢谢你的帮助。
*注意 - 运行了 2 次插补，因为我只是在测试此代码，但我计划进行 10 次插补。]]></description>
      <guid>https://stats.stackexchange.com/questions/656634/nelson-aalen-cumulative-hazard-causing-multicollinearity-when-performing-mice-in</guid>
      <pubDate>Sat, 02 Nov 2024 11:41:12 GMT</pubDate>
    </item>
    <item>
      <title>生存分析中的一致性指数（Gonen 和 Heller）</title>
      <link>https://stats.stackexchange.com/questions/656632/concordance-index-in-survival-analysis-gonen-and-heller</link>
      <description><![CDATA[我正在开展一个项目，用于外部验证临床预测模型。原始模型系数是使用 Cox 模型估算的。该模型使用基线风险和系数来预测癌症诊断后的生存概率。
我遇到了 Cox 模型的 Gonen 和 Heller 一致性指数。这似乎只使用了模型的预测，而根本没有考虑观察到的数据（事件和时间）。例如，请参阅 R 包 survAUC 中的 GHCI() 函数：
https://search.r-project.org/CRAN/refmans/survAUC/html/GHCI.html
正如所见，这只有一个参数，即模型的预测。如果它完全不考虑观察到的事件或时间，我不明白它如何进行（外部）验证。]]></description>
      <guid>https://stats.stackexchange.com/questions/656632/concordance-index-in-survival-analysis-gonen-and-heller</guid>
      <pubDate>Sat, 02 Nov 2024 11:33:28 GMT</pubDate>
    </item>
    <item>
      <title>多重共线性与相关性估计</title>
      <link>https://stats.stackexchange.com/questions/656631/multi-collinearity-and-estimation-of-correlation</link>
      <description><![CDATA[我有一个 fMRI 数据，其中包含一组大脑各个区域活动的时间序列。有一个概念称为功能连接，它显示了每个区域的活动如何依赖于其他区域。估计连接的一种常用方法是相关性。
我的问题是，如何区分两个区域的直接连接和这些区域通过第三个区域的间接连接。
答案似乎是偏相关性，但这里没有任何控制变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/656631/multi-collinearity-and-estimation-of-correlation</guid>
      <pubDate>Sat, 02 Nov 2024 11:25:14 GMT</pubDate>
    </item>
    <item>
      <title>对狄利克雷过程混合 (DPM) 模型中的聚类数量进行后验推断</title>
      <link>https://stats.stackexchange.com/questions/656630/performing-posterior-inference-on-the-number-of-clusters-in-a-dirichlet-process</link>
      <description><![CDATA[我使用 DPM 模型对我创建的一些数据的聚类数量进行后验推断，并且已知这些数据的“真实”聚类数量 (3)。为了从核参数的后验分布中进行采样，我使用了 Blocked Gibbs 采样器，如 Gelman 等人在第 23 章的《贝叶斯数据分析》中所述。
我注意到的问题是，我的结果对断棍构造的“截断”选择高度敏感，即在构造的哪一步，我将剩余的所有概率质量分配给最后的“棍子”，从而限制可能的最大聚类数量。
似乎发生的情况是，当我允许更多聚类时，聚类数量的经验分布会转向越来越高的值，因为许多聚类只被很少（通常为 1 个）观察值占据，而少数聚类则包含大多数观察值。
我一直在测试的一种尝试解决此问题的方法是不考虑所有聚类的分布，而只考虑那些清除一定最小数量观察值的聚类，但我想知道我是否做错了什么，或者是否有一种不那么随意的方式来做到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/656630/performing-posterior-inference-on-the-number-of-clusters-in-a-dirichlet-process</guid>
      <pubDate>Sat, 02 Nov 2024 11:08:52 GMT</pubDate>
    </item>
    <item>
      <title>如何解释高于和低于零的值的 GAM 图？</title>
      <link>https://stats.stackexchange.com/questions/656629/interpreting-a-gam-plot-for-values-above-and-below-zero</link>
      <description><![CDATA[我在平台上遇到过类似的问题，我觉得对此有不同的看法。由于我是 GAM 新手，我想知道如何正确解释 GAM 图。
当曲线在零以上或零以下的值上向上或向下移动时，这意味着什么？
假设我的 GAM 模型如下所示：
model &lt;- gam(y~s(x), method=&quot;REML&quot;, data=data)


从图中我可以看出，值从 0 到 500 呈上升趋势。然而，在 300 左右，曲线超过零并持续上升直到 500。这是否意味着当 x 从 0 增加到 500 时，y 也会增加？或者对于低于 300 的值，y 随着 x 的增加而增加，但 x 对 y 的总体影响是负面的？
我尝试在不同的平台上寻找答案，但它们让我更加困惑。我现在真的很感激任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/656629/interpreting-a-gam-plot-for-values-above-and-below-zero</guid>
      <pubDate>Sat, 02 Nov 2024 10:35:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么在计算平均值的 Z 间隔时第二个假设（即已知的总体方差）不切实际？</title>
      <link>https://stats.stackexchange.com/questions/656625/why-is-the-second-assumption-i-e-known-population-variance-unrealistic-when</link>
      <description><![CDATA[我正在学习用 Z 间隔计算关于均值的置信区间。讲座中说：

... 关于已知总体方差的第二个假设是不现实的。毕竟，我们什么时候会认为我们会知道总体方差的值，但不知道总体均值？

这是我的问题。虽然直观上看总体方差比总体均值更难知道，但均值和方差应该是分布的两个不同特征吗？为什么我们知道总体方差，但不知道总体均值的情况是不现实的？]]></description>
      <guid>https://stats.stackexchange.com/questions/656625/why-is-the-second-assumption-i-e-known-population-variance-unrealistic-when</guid>
      <pubDate>Sat, 02 Nov 2024 08:29:40 GMT</pubDate>
    </item>
    <item>
      <title>分布的收敛是否意味着 Kolmogorov 距离的收敛？</title>
      <link>https://stats.stackexchange.com/questions/656622/does-convergence-in-distribution-imply-convergence-in-kolmogorov-distance</link>
      <description><![CDATA[我知道这样的结果：柯尔莫哥洛夫距离的收敛意味着逐点分布收敛。除非极限分布是绝对连续的，否则逆向结果通常不成立。
我很好奇，如果我们没有极限分布函数的绝对连续性，并且这个逆向结果仍然成立，是否可以对极限分布施加任何其他严格条件！
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/656622/does-convergence-in-distribution-imply-convergence-in-kolmogorov-distance</guid>
      <pubDate>Sat, 02 Nov 2024 04:54:12 GMT</pubDate>
    </item>
    <item>
      <title>回归参数的最大偏边际似然估计 (MPMLE) 程序</title>
      <link>https://stats.stackexchange.com/questions/656621/program-for-maximum-partial-marginal-likelihood-estimator-mpmle-of-regression</link>
      <description><![CDATA[我有一个概率方程组，看起来像



其中。我想针对 U_1、U_2、U_3 求解上述系统。我想问一下 R 或 Python 中是否有用于这些基于等级的边际似然估计的包？我做了一些调查，但我唯一能找到的是 Minggao Gu、Yueqin Wu 和 Bin Huang 撰写的以下论文，其中提出了一种估算程序来实现这一点：https://www.sciencedirect.com/science/article/pii/S0047259X13001772
如能提供任何帮助，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/656621/program-for-maximum-partial-marginal-likelihood-estimator-mpmle-of-regression</guid>
      <pubDate>Sat, 02 Nov 2024 04:27:46 GMT</pubDate>
    </item>
    <item>
      <title>假设 $X$ 从 $\mathbb{Z}_{q}^{n}$ 中均匀随机抽取，我们如何得到综合征的分布 $a= x_{1}+ 2x_{2}+ \cdots+ nx_{n}\mod qn$</title>
      <link>https://stats.stackexchange.com/questions/656620/let-x-be-sampled-uniformly-at-random-from-mathbbz-qn-how-do-we-get</link>
      <description><![CDATA[
问题。假设 $X$ 从 $\mathbb{Z}_{q}^{n}$ 中均匀随机抽样，我们如何得到分布：
$$a= x_{1}+ 2x_{2}+ \cdots+ nx_{n}\mod qn$$

经过尝试模拟，我得出结论 $\mathbb{P}\left ( a= 0 \right )\geq\mathbb{P}\left ( a= i \right )\geq\mathbb{P}\left ( a= 1 \right ), \forall i\in\mathbb{Z}_{qn}$。
另一种方法是找到$b= x_{1}+ x_{2}+ \cdots+ x_{n}\mod q$ 的等效分布（通过替换技巧），但我不知道 $\mathbb{P}\left ( b= 1 \right )$ 与其他 $\mathbb{P}\left ( b= i \right )$ 相比有多特殊。
我需要你的帮助。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656620/let-x-be-sampled-uniformly-at-random-from-mathbbz-qn-how-do-we-get</guid>
      <pubDate>Sat, 02 Nov 2024 03:12:48 GMT</pubDate>
    </item>
    <item>
      <title>如何评估分类模型对不同类别子集的性能？</title>
      <link>https://stats.stackexchange.com/questions/656619/how-to-evaluate-performance-of-classification-model-for-different-subsets-of-cla</link>
      <description><![CDATA[考虑一个有 N 个类别的分类问题。虽然这看起来很奇怪，但我有一个处理特征的模型，本质上，根据特征评估哪些类别不可能（或几乎不可能）正确分类。因此，我们可以在进行预测时排除这些类别，因为我们已经知道我们在这种情况下会失败（换句话说，量化模型无用的时间）。
我想评估这有多好，但简单地评估准确性并不是一个公平的比较。假设我无法对除 2 个之外的所有类别进行分类，那么我可以比较我“可以分类”和“不能分类”的类别的准确性。但是，在这种情况下，我只需随机猜测，我“可以分类”的类别的准确率将达到 50%。也许，这看起来是一个很好的改进，但随机猜测者的准确率相对于类别的数量来说很高。
可以使用哪些指标来评估这种情况？这种情况必须有一个指标。]]></description>
      <guid>https://stats.stackexchange.com/questions/656619/how-to-evaluate-performance-of-classification-model-for-different-subsets-of-cla</guid>
      <pubDate>Sat, 02 Nov 2024 02:52:32 GMT</pubDate>
    </item>
    <item>
      <title>tm_map 无法工作，请帮忙！[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656617/tm-map-will-not-work-please-help</link>
      <description><![CDATA[我一直收到此错误，但我不知道如何修复它
txt=tm_map(basket,tolower)
txt3= tm_map(txt3,removePunctuation)
txt3=tm_map(txt3,removeNumbers)
txt3=tm_map(txt3,removeWords,stopwords(&quot;english&quot;))
UseMethod(&quot;tm_map&quot;, x) 中的错误：
没有适用于“data.frame”类对象的“tm_map”方法]]></description>
      <guid>https://stats.stackexchange.com/questions/656617/tm-map-will-not-work-please-help</guid>
      <pubDate>Sat, 02 Nov 2024 02:23:22 GMT</pubDate>
    </item>
    <item>
      <title>一维情形的 LDA 估计推导</title>
      <link>https://stats.stackexchange.com/questions/656616/derivation-of-lda-estimates-for-1-dimensional-case</link>
      <description><![CDATA[在统计学习简介第 4.4.1 节中，讨论了用于分类的 LDA，它只是一个贝叶斯分类器，假设每个类的概率密度函数是高斯的并且具有相同的方差（一维情况），但在那本书中它并没有解释 4.20 中的估计值是如何得到的。我们基于哪些假设以及如何得出这些估计值？
$$
\hat \mu_k = \frac{1}{n_k} \sum_i^{n_k} x_{ik} \\[10pt]
\hat \sigma^2 = \frac{1}{n-K} \sum_{k=1}^{K}\sum_{i=1}^{n_k}(x_{ik}- \hat \mu_k)^2
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/656616/derivation-of-lda-estimates-for-1-dimensional-case</guid>
      <pubDate>Sat, 02 Nov 2024 02:19:45 GMT</pubDate>
    </item>
    <item>
      <title>论文讨论 - 汉密尔顿神经网络</title>
      <link>https://stats.stackexchange.com/questions/656626/paper-discussion-hamiltonian-neural-networks</link>
      <description><![CDATA[我正在写一篇关于 Sam Greydanus 等人的发现的论文：https://arxiv.org/abs/1906.01563v1
我想知道是否有人可以帮助我提供一些见解：
他们强调了如何让模型直接预测汉密尔顿量，并从框架公理中推导出梯度 dp/dt 和 dq/dt 得到更好的结果：
[![汉密尔顿动力学关系动量和位置][1]
[1]：https://i.sstatic.net/Im4x43Wk.png
他们确实获得了很好的结果，甚至比直接预测梯度的传统神经网络更好。 HNN 创建的映射正确地保存了理想摆锤等的能量。
我的问题是：为什么这很重要？我们不只是在强化偏见吗？如果我们使用神经网络的目标是模拟复杂系统，为什么要强制执行现有框架？
模型的准确性只能与框架一样，让神经网络自己发现这些框架和映射不是更有趣吗？由于现实世界在某种程度上是可预测的，因此应该有一个底层框架，其映射比人造框架更准确。我们在神经网络中有数百万个参数，而分析/数值解决方案中只有几个参数？
我可能完全偏离了主题（我只是一名工程专业的学生），但我认为在我的论文中讨论这个问题以及实际讨论结果可能是一个很酷的角度。]]></description>
      <guid>https://stats.stackexchange.com/questions/656626/paper-discussion-hamiltonian-neural-networks</guid>
      <pubDate>Thu, 31 Oct 2024 12:19:58 GMT</pubDate>
    </item>
    <item>
      <title>重现期与概率的关系</title>
      <link>https://stats.stackexchange.com/questions/656532/relationship-between-return-period-and-probability</link>
      <description><![CDATA[据我了解，事件（例如地震或洪水）的重现期是该事件连续两次发生之间的平均时间。重现期为 $r$ 的事件发生的概率为 $1/r$。例如，如果强烈地震的重现期为 $10$ 年，则每年发生地震的概率为 $1/10$。
我不太明白为什么发生概率与重现期成倒数。例如，如果某件事通常每 $10$ 年发生一次，为什么它在任何一年发生的概率是 $1/10$？]]></description>
      <guid>https://stats.stackexchange.com/questions/656532/relationship-between-return-period-and-probability</guid>
      <pubDate>Mon, 28 Oct 2024 16:05:02 GMT</pubDate>
    </item>
    </channel>
</rss>