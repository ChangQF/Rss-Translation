<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 10 Jan 2024 06:19:14 GMT</lastBuildDate>
    <item>
      <title>收敛随机变量的条件期望对于任意过滤的收敛</title>
      <link>https://stats.stackexchange.com/questions/636558/convergence-of-conditional-expectation-of-convergent-random-variables-with-respe</link>
      <description><![CDATA[我已经尝试解决以下问题一段时间了，但没有成功：让 $X_1,X_2,\dots \in L_1$ 与 $X_n \uparrow X$ a.s. （和 $X \in L_1$）。表明对于任何过滤 $(F_n)$ 我们都有 $\mathbb{E}[X_n|F_n] \to \ mathbb{E}[X|F_\infty]$ a.s.其中 $F_\infty = \sigma(\bigcup_{n\geq 1} F_n)$
我最初的方法是尝试证明 $\mathbb{E}[X_n|F_n] \leq \mathbb{E}[X_{n+1}|F_{ n+1}]$ 然后应用单调收敛定理，但我一直无法证明它，甚至不知道它是否正确。我知道对于固定的 $m$ 我们有 $\mathbb{E}[X_n|F_m] \leq \mathbb{ E}[X_{n+1}|F_m]$ 但我找不到关联 $\mathbb{E}[X_n|F_n]$&lt; 的方法/span&gt; 和 $\mathbb{E}[X_{n+1}|F_{n+1}]$ 自 $\sigma$-我们所调节的代数正在改变。也许它是一种过滤这一事实在某种程度上有所帮助？但是当 $\sigma$-algebra 随 $ 变化时，我无法找到或证明条件期望的任何收敛结果n$.
我知道这是 Doob Martingales 的一个简单结果，对于固定的 $m$，我们有 $\mathbb{ E}[X_m|F_n] \to \mathbb{E}[X_m|F_\infty]$。此外，对于固定的 $m&#39;$，条件单调收敛定理告诉我们 $\mathbb{E}[X_n| F_{m&#39;}] \到 \mathbb{E}[X|F_{m&#39;}]$。但是我不知道如何同时处理 $n$ 的变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/636558/convergence-of-conditional-expectation-of-convergent-random-variables-with-respe</guid>
      <pubDate>Wed, 10 Jan 2024 06:12:30 GMT</pubDate>
    </item>
    <item>
      <title>0 拟合 Copula 的对数似然</title>
      <link>https://stats.stackexchange.com/questions/636557/log-likelihood-of-0-fitting-copula</link>
      <description><![CDATA[这个问题似乎应该有一个简单的答案，但我在互联网搜索或 ChatGPT 方面没有运气。我正在 Python 中使用统计联结函数，并且在使用 MLE 在二元高斯联结函数中拟合 Q（皮尔逊相关）参数时遇到了问题。
如果需要，我可以发送代码和/或方程，但问题实际上是抽象的。它的工作原理如下：

我正在尝试使用 MLE 找到最适合样本数据集的 Q。
Q = 0 是一个有效的搜索参数，因为它代表了我的数据不具有线性相关性的重要情况。而且，它完全落在相关性的范围内，即 -1 和 1。
但是当检查 Q = 0 的对数似然时，copula 分布是二元均匀的，并且到处都等于 1（单位立方体）。这里没有任何问题——这是预期的。
这会导致对数似然为 0，因为我所有点的 PDF 均为 1 并且 ln(1) = 0。
因为我正在使用 scipy.minimize，所以我必须翻转符号 MINIMIZE the Log Likelihood * -1，但这意味着 0 比任何其他解都小（因为 -1 * Log Likelihood 永远不会为负）。&lt; /里&gt;

那么根据 MLE，Q = 0 总是最优解吗？ ChatGPT 建议单独处理 Q = 0，但我不知道这将如何工作。先验地，Q = 0 仍然是一个有效的搜索参数，我们不能立即丢弃该解决方案。我还想继续使用 MLE，因为我最终会将我的方法推广到其他联结函数。
感谢您的回答，如果需要，我可以再次提供代码/方程。]]></description>
      <guid>https://stats.stackexchange.com/questions/636557/log-likelihood-of-0-fitting-copula</guid>
      <pubDate>Wed, 10 Jan 2024 06:05:55 GMT</pubDate>
    </item>
    <item>
      <title>自举二次抽样分析</title>
      <link>https://stats.stackexchange.com/questions/636552/bootstrapping-subsampling-analysis</link>
      <description><![CDATA[我目前正在开展引导二次抽样分析，旨在使用 PSAboot：使用 R 中的引导进行倾向得分分析，根据阅读成绩得分将阅读障碍组与对照组进行匹配。
这是我用于分析的代码片段：在此处输入图像描述

不幸的是，我遇到了一个错误：“使用 1 种方法得到 100 个引导样本。” Bootstrap 样本大小：处理 = 695 (100%)，无替换。对照=6882（100%），无需更换。 cut.default(ps, quantile(ps, seq(0, 1, 1/nstrata)), include.lowest = TRUE, 中的错误：“中断”不是唯一的&#39;
我尝试了各种方法，例如在 unique() 函数内应用 quantile()、使用 jitter、decile 和 .bincode 函数，但似乎都没有解决问题。如果您有任何建议或见解来帮助我解决这个问题，我将不胜感激。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/636552/bootstrapping-subsampling-analysis</guid>
      <pubDate>Wed, 10 Jan 2024 03:31:19 GMT</pubDate>
    </item>
    <item>
      <title>使用 t 检验来测试效应大小</title>
      <link>https://stats.stackexchange.com/questions/636551/using-a-t-test-to-test-effect-size</link>
      <description><![CDATA[在我的工作中，我使用大数据并经常运行统计测试来比较组之间的差异。我面临的问题是，如果我使用 $t$ 测试来测量任何差异，由于样本量较大，结果几乎总是显着的。&lt; /p&gt;
例如，我希望衡量测试组相对于对照组的效应大小。我的两个样本量都非常大 - 我的测试有 $100,000$ 人，而我的对照有 $11,000$ 人。我的 $t$ 测试值超过 $1$ 万。
为了解释这一点，我提出了将各组的平均差异与基准值进行比较的想法。基准值可以是对照组平均值的 $10$%。因此，我将测试组与对照组之间的平均差异与基准值进行比较。通过这种方式，我可以测试各组之间的差异是否大于对照组的 $10$%，以及是否具有统计显着性。
这是一种有效的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636551/using-a-t-test-to-test-effect-size</guid>
      <pubDate>Wed, 10 Jan 2024 03:17:53 GMT</pubDate>
    </item>
    <item>
      <title>帮助选择可解释的模型来衡量客户旅程接触点对满意度的影响</title>
      <link>https://stats.stackexchange.com/questions/636549/help-selecting-an-interpretable-model-to-measure-the-impact-of-customer-journey</link>
      <description><![CDATA[上下文
我正在开展一个项目，需要了解客户旅程接触点对满意度的影响。我的目标是创建一个可解释的模型，而不是纯粹的预测模型，因为我想了解每个接触点对满意度的重要性，以做出明智的业务决策。
数据
我的输入变量 (X) 是二元的，表示客户是否经历过特定接触点，而我的因变量 (y) 是连续的，范围从 0 到 10。满意度分数的分布不是正态的，在 10 处显着累积，然后快速向 0 下降。在 0 处它再次增加，类似于二项分布或 beta 分布。
类似这样的事情：

问题

您建议使用什么算法或建模方法来构建可解释的模型，以处理二进制输入和非正态分布的连续输出（例如我的满意度得分）？
在创建解释性模型而不是预测性模型时，我是否应该将数据划分为训练集、验证集和测试集？交叉验证适合这种场景吗？或者我只是用所有数据集训练模型？
根据我的目标，您是否建议使用任何特定技术或库来解决模型的可解释性问题？
如何使用所选模型评估各个接触点在影响客户满意度方面的意义或重要性？并解释它？

任何有关算法选择和建模策略的帮助或见解将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/636549/help-selecting-an-interpretable-model-to-measure-the-impact-of-customer-journey</guid>
      <pubDate>Wed, 10 Jan 2024 03:08:37 GMT</pubDate>
    </item>
    <item>
      <title>如何计算点球大战中球队获胜的概率？</title>
      <link>https://stats.stackexchange.com/questions/636548/how-to-calculate-probability-of-a-team-winning-in-penalty-kick</link>
      <description><![CDATA[我在浏览网页时看到了这张图表。我了解处罚规则，但我真的不知道如何计算图表中第一行的数字。
我的想法是将每次射击视为遵循伯努利分布的随机变量，那么成功的次数将是二项式分布。我需要计算 P(A - B) = 1。当我开始这样做时，我发现它很复杂且令人困惑。我相信有更好的方法。
你能对此给出一个想法或提示吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/636548/how-to-calculate-probability-of-a-team-winning-in-penalty-kick</guid>
      <pubDate>Wed, 10 Jan 2024 02:57:06 GMT</pubDate>
    </item>
    <item>
      <title>示例符号：何时使用大写 $N$ 与小写 $n$？</title>
      <link>https://stats.stackexchange.com/questions/636545/sample-notation-when-to-use-capital-n-vs-lowercase-n</link>
      <description><![CDATA[在统计和心理学研究中，大写 $N$ 与小写 $n$ 表示什么？
我从事心理学研究，我看到它们以两种方式使用：

大写 $N$ 代表整个样本，小写 $n$ 代表样本中的组那个样本。例如我们开展了一项 RCT，参与者为 $100$，控制者为 $50$，治疗费用为 50$，因此 $N = 100$ 和 $n = 50$ 在每个组中。
大写字母 $N$ 代表我们从中招募研究样本的人群，小写 n 是我们的研究样本，例如我们从$162$百万选民名册中随机抽取$100$的注册选民，所以 $N = 162,000,000$ 和 $n = 100$（假设我们邀请的每个人都同意参与）&lt; /里&gt;

$N$ 和 $n$ 的常规用法是什么？是否因领域而异？我可以指出哪些资源来阐明每种资源的含义？]]></description>
      <guid>https://stats.stackexchange.com/questions/636545/sample-notation-when-to-use-capital-n-vs-lowercase-n</guid>
      <pubDate>Wed, 10 Jan 2024 02:12:07 GMT</pubDate>
    </item>
    <item>
      <title>$E[W\otimes W]$ 为 Wishart R.V. $W$</title>
      <link>https://stats.stackexchange.com/questions/636544/ew-otimes-w-for-wishart-r-v-w</link>
      <description><![CDATA[Wishart R.V. 的 $E[W\otimes W]$ 的价值是多少？ $W$？
$\otimes$ 指克罗内克乘积
我在Seber矩阵的第467页找到了$E[WAW]$的相关公式handbook，想知道能否从中提取出$E[W\otimes W]$ .
]]></description>
      <guid>https://stats.stackexchange.com/questions/636544/ew-otimes-w-for-wishart-r-v-w</guid>
      <pubDate>Wed, 10 Jan 2024 00:34:51 GMT</pubDate>
    </item>
    <item>
      <title>如何选择同时具有最优值和低方差的点</title>
      <link>https://stats.stackexchange.com/questions/636543/how-to-choose-a-point-that-has-both-optimal-value-and-low-variance</link>
      <description><![CDATA[我有一个高斯过程回归模型，可以对特定过程的成本进行建模。训练完成后，我想找到回归预测成本最低的点 $x$ 对应的点。
简单地选择期望值最低的点$\mu(x)$似乎并不直观，因为如果最低点具有高不确定性（即高方差， $\sigma$) 那么我们最好选择一个稍微次优但不确定性较低的点。
我想提高选择最佳点的可能性，这样当我使用这些参数运行流程时，我的成本是最低的。
一个简单的解决方案可能是考虑预测均值 ($\mu$) 和方差 ( $\sigma$) 而不仅仅是平均值
$\alpha(x) = \mu(x) + \lambda \sigma(x)$
所以现在我找到了一个最佳点 $x$ wrt $\alpha$ 而不是 &lt; span class=&quot;math-container&quot;&gt;$\mu$
我想看看其他人是否能够以不同的方式解决这个问题。我在网上找不到任何类似的作品。]]></description>
      <guid>https://stats.stackexchange.com/questions/636543/how-to-choose-a-point-that-has-both-optimal-value-and-low-variance</guid>
      <pubDate>Wed, 10 Jan 2024 00:16:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 格式化此数据以进行探索性因子分析的最佳方法？</title>
      <link>https://stats.stackexchange.com/questions/636542/best-way-to-format-this-data-for-exploratory-factor-analysis-using-r</link>
      <description><![CDATA[我最初在 StackOverflow 上问过这个问题，但这更多的是一个统计问题，而不是一个编码问题。
我的问题是关于数据格式的。我有这个数据集（嗯，这只是几百行中的前两行）：
df &lt;- 结构(列表(X.Case.ID. = 310:311, 性别 = c(1L, 1L), 年龄 = c(32L,
45L)，就业 = c(1L, 1L)，教育 = c(6L, 6L)，职能 = c(6L,
6L)，A = c(1L, 1L)，部门 = 1:2，员工 = c(567L, 500L)，
    状态 = c(35L, 10L)，区域 = 3:2，收入 = 9:8，Q1 = c(2L,
    2L), Q2 = 2:1, Q3 = 1:2, Q4 = c(1L, 3L), Q5 = 3:2, Q6_C1 = c(0L,
    0L), Q6_C2 = 0:1, Q6_C3 = c(0L, 0L), Q6_C4 = 1:0, Q6_C5 = 0:1,
    Q6_C6 = c(0L, 0L), Q6_C7 = c(0L, 0L), Q6_C8 = c(0L, 0L),
    Q6_C9 = c(0L, 0L), O_Q6_C9 = c(NA, NA), Q7_C1 = 0:1, Q7_C2 = c(0L,
    0L), Q7_C3 = c(0L, 0L), Q7_C4 = c(0L, 0L), Q7_C5 = 1:0, Q7_C6 = 0:1,
    Q7_C7 = c(0L, 0L), Q7_C8 = c(0L, 0L), Q7_C9 = c(0L, 0L),
    Q7_C10 = c(0L, 0L), O_Q7_C9 = c(NA, NA), Q8 = 4:3, Q9_C1 = c(0L,
    0L), Q9_C2 = 0:1, Q9_C3 = c(0L, 0L), Q9_C4 = c(0L, 0L), Q9_C5 = c(1L,
    1L), Q9_C6 = 0:1, Q9_C7 = c(0L, 0L), Q9_C8 = c(0L, 0L), Q9_C9 = c(0L,
    0L), Q10 = c(3L, 1L), Q11_C1 = c(0L, 0L), Q11_C2 = 1:0, Q11_C3 = 0:1,
    Q11_C4 = 0:1, Q11_C5 = 1:0, Q11_C6 = c(0L, 0L), Q11_C7 = c(0L,
    0L)，Q12＝c(34L，15L)，Q13＝c(“99,994”，“700”)，Q14＝1:2，
    Q15 = 1:2，Q16_C1 = c(0L, 0L)，Q16_C2 = c(0L, 0L)，Q16_C3 = c(0L,
    0L), Q16_C4 = c(0L, 0L), Q16_C5 = c(0L, 0L), Q16_C6 = c(0L,
    0L), Q16_C7 = c(0L, 0L), Q16_C8 = c(0L, 0L), Q16_C9 = c(0L,
    0L), Q16_C10 = c(0L, 0L), Q16_C11 = c(0L, 0L), O_Q16_C11 = c(NA,
    NA), Q17_C1 = c(0L, 0L), Q17_C2 = c(0L, 0L), Q17_C3 = c(0L,
    0L), Q17_C4 = c(0L, 0L), Q17_C5 = 1:0, Q17_C6 = 0:1, Q17_C7 = c(0L,
    0L), Q17_C8 = 0:1, Q17_C9 = 0:1, Q17_C10 = 1:0, Q17_C11 = c(0L,
    0L), Q17_C12 = c(0L, 0L), O_Q17_C11 = c(NA, NA), Q18 = c(5L,
    3L), Q19_C1 = 0:1, Q19_C2 = 1:0, Q19_C3 = c(0L, 0L), Q19_C4 = 0:1,
    Q19_C5 = c(0L, 0L), Q19_C6 = c(0L, 0L), Q19_C7 = c(0L, 0L)
    ), Q19_C8 = c(0L, 0L), O_Q19_C7 = c(NA, NA), Q20_M1 = c(7L,
    1L), Q20_M2 = 2:3, Q20_M3 = 3:4, Q20_M4 = 6:5, Q20_M5 = c(5L,
    2L), Q20_M6 = c(4L, 7L), Q20_M7 = c(1L, 6L), YEARSATCOMPANY = c(7L,
    10L)，YEARSINBUS = c(12L, 10L)，办公室 = 3:2，段 = c(“企业”,
    “商业”），DEDICATED_STAFF = c（“&gt;=20”，“&lt;20”），HOURS = c（“&gt;=10000”，
    “&lt;1000”)，易受攻击=c(“易受攻击”，“不易受攻击”)，
    Hours.Adjusted = c(&quot;10000&quot;, &quot;700&quot;), Commercial.or.Enterprise = c(&quot;Enterprise&quot;,
    “商业”），Q13.num = c(99994, 700)，段 = c(2, 1
    )，专职人员 = c(2, 1)，弱势群体 = c(2, 1)，工时 = c(4,
    1)), row.names = 1:2, class = “data.frame”)

我意识到列名称和值不清楚，但我们有一些问题，例如人口统计数据，每个人都有一个单一的答案。
有类似Q1的问题：

还有像 Q6 这样的问题，它有 9 个部分（O_Q6_C9 和其他类似的问题是空的）。为了简洁起见，以下是前 3 部分。

考虑到像 Q6 这样的问题是“长”的。对于宽格式的问题，我们本质上有一对一和一对多的结构，但格式化后都是一对一的。格式化这些数据以进行探索性因素分析的最佳方法是什么？保留宽格式还是长格式会导致一对一变量重复？
我想知道对于像问题 6 这样的问题，它的所有部分都围绕一个共同的概念 - 这会带来问题吗？
我将对所有数据进行数字编码，并且不会使用所有问题。但是，我将混合使用一对一和一对多问题。除了结构的混合之外，没有任何复杂的东西，例如重复测量或复杂采样。]]></description>
      <guid>https://stats.stackexchange.com/questions/636542/best-way-to-format-this-data-for-exploratory-factor-analysis-using-r</guid>
      <pubDate>Tue, 09 Jan 2024 23:53:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的 Mice() 包执行多重插补。执行逻辑回归后无法获得分类变量的常见 p 值</title>
      <link>https://stats.stackexchange.com/questions/636541/performed-multiple-imputation-usig-mice-package-in-r-unable-to-get-the-common</link>
      <description><![CDATA[我使用 R 中的 mice 包对连续变量和分类变量进行了多次插补。我进行了 $5$ 插补和 $10$ 迭代，并使用 with() 运行逻辑回归code&gt; 然后是 pool() 用于结果池。但是，我无法获得分类变量的通用 $p$ 值。我查看了与此相关的不同文章，但没有任何帮助。我还使用了此链接 并遵循相同的步骤。]]></description>
      <guid>https://stats.stackexchange.com/questions/636541/performed-multiple-imputation-usig-mice-package-in-r-unable-to-get-the-common</guid>
      <pubDate>Tue, 09 Jan 2024 23:37:52 GMT</pubDate>
    </item>
    <item>
      <title>当某些协变量高度倾斜时，执行匹配或其他混杂因素控制方法时是否有任何显着影响？</title>
      <link>https://stats.stackexchange.com/questions/636540/are-there-any-notable-implications-when-performing-matching-or-other-confounder</link>
      <description><![CDATA[如果您知道某些协变量存在严重偏差，那么解决该问题的最佳方法是什么？还是说不需要特殊处理，只要按照标准的平衡诊断程序检查匹配的数据是否达到平衡就可以了？我想在更理论的层面上，倾斜的数据是否会使匹配（或其他方法）更困难/更不可靠？
我找不到任何与此相关的阅读材料或问题，所以我很困惑。我正在使用的方法是匹配，但我想这个问题与观察因果推理中的大多数混杂控制方法有关。对于上下文，我通常遵循 MatchIt() 小插图以及小插图中引用的推荐阅读内容。]]></description>
      <guid>https://stats.stackexchange.com/questions/636540/are-there-any-notable-implications-when-performing-matching-or-other-confounder</guid>
      <pubDate>Tue, 09 Jan 2024 23:05:16 GMT</pubDate>
    </item>
    <item>
      <title>检查硬币是否随机翻转，但每次抛掷的面数可能不同</title>
      <link>https://stats.stackexchange.com/questions/636539/check-if-a-coin-flips-randomly-but-it-can-have-a-different-number-of-sides-each</link>
      <description><![CDATA[我想根据观察数据检查硬币是否随机翻转。问题是，硬币可以有两个面，也可以有三个、四个，最多九个。每次观察（每次抛掷）的边数都不同。
我可以生成观察结果，但成本相对较高，因此通常样本量较小，例如 20、30，也许 50，但如果需要，我可能会获取更多样本。
这里要应用什么统计测试？如果有任何棘手的方面，如何应用？
我需要多少观察？我是否正确地认为偏差越明显，检测它所需的观察次数就越少？
编辑回答评论：我知道每次有多少面，我可以在某种程度上控制它。硬币应该是随机翻转的，但我怀疑它不会。如果它确实不是随机翻转的，我想说：“这是可靠的统计证据，表明这枚硬币不是随机翻转的”。像往常一样，p 值可能小于 0.05。
通过“随机”，我的意思是每一方都应该有相同的“出现”概率。 （1/d，d 是边数）。另一种假设是其中一侧（正面，或“第一”面，始终相同，始终存在）具有更高的概率。
TLDR：我认为硬币偏向正面。硬币可以有多个反面，并且反面的数量可以根据观察的不同而变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/636539/check-if-a-coin-flips-randomly-but-it-can-have-a-different-number-of-sides-each</guid>
      <pubDate>Tue, 09 Jan 2024 22:53:13 GMT</pubDate>
    </item>
    <item>
      <title>多项分布中每一类至少有一个元素的概率</title>
      <link>https://stats.stackexchange.com/questions/636538/probability-of-at-least-one-element-for-each-class-in-a-multinomial-distribution</link>
      <description><![CDATA[给定多项分布
$$X \sim MN(n, p_1, \ldots , p_K)$$
如果我知道$p_1 \ldots p_n$，我可以通过从多项分布中重复采样来轻松获得以下概率
$$P( X_1 \geq 1, \ldots X_K \geq 1) \geq 0.95.$$
但是如果我不知道它们的值，但我知道$p_i \geq 0.01 $。我怎样才能证明这一点
$$ Y ~ \sim MN(n, 0.01, 0.01, \ldots 0.01)$$
它成立
$$P( X_1 \geq 1, \ldots X_K \geq 1) \geq P( Y_1 \geq 1, \ldots Y_{100} \geq 1)$$ 
我希望这个结果能够获得第一个概率的下界。我毫不怀疑这是真的，但除了一些蒙特卡洛模拟之外，我没有任何证据。]]></description>
      <guid>https://stats.stackexchange.com/questions/636538/probability-of-at-least-one-element-for-each-class-in-a-multinomial-distribution</guid>
      <pubDate>Tue, 09 Jan 2024 22:41:06 GMT</pubDate>
    </item>
    <item>
      <title>双变量逻辑回归的单变量方法</title>
      <link>https://stats.stackexchange.com/questions/636522/univariate-approach-to-a-bivariate-logistic-regression</link>
      <description><![CDATA[考虑这样一种情况，两个独立的代理（一组许多代理中的一个）查看同一问题并尝试用是/否响应来解决它，获得 $(Y_ {i1},Y_{i2})$ 为 $i \in \{1,\ldots,N\}$。每个特工都经过严格训练，他们经常得出相同的结论。如果我们有一组任务 $X_i$ 的协变量，它们影响我们希望收集信息的每个决策，则可以将其视为同时建模的多变量问题&lt; span class=&quot;math-container&quot;&gt;$(Y_{i2},Y_{i2})$ 使用 logit 或 probit 链接函数。两个代理之间的“协议”可以从两个潜在响应变量之间的协方差矩阵推断出来。在概率示例中，这类似于：
$$(Y_1^*,Y_2^*) \sim MVN((\mu_1,\mu_2),\Sigma)$$
其中 $Y_i = \{1 \text{ if } Y_1^* &gt; 0, \text{ 0 否则}\} $, $\Sigma = \left(\begin{matrix}
  \sigma_1 &amp; \sigma_{12}\\
  \sigma_{12} &amp; \sigma_2
\end{矩阵}\right)$
和 $\mu_i = \beta X_i$。
如果多变量方法由于某种原因不可行（在我的例子中，由于软件与其他建模选择不兼容），是否可以通过组合响应向量对每个决策独立建模来解决问题将 $Y_j$ 转化为 $j \in 1,\ldots,2N$ 响应并使用因子变量来区分两者？例如，概率回归将类似于：
$$\mu_j = \beta_0 + \beta_1 \text{其他决定}_j + \beta_3 \text{第一或第二}_j + \beta X_j$$ 对于 $j \in \{1,\ldots,2N\}$ 使用正态分布。
在这种方法中，$\text{First or secondary}_j$变量有效地模拟了每个代理接受率的不同截距和$\text{其他决策}_j$ 对两个代理之间的协议强度进行建模。我认为它们之间的唯一区别是选择组合或划分方差元素，但我找不到任何关于之前已完成或考虑过的参考。]]></description>
      <guid>https://stats.stackexchange.com/questions/636522/univariate-approach-to-a-bivariate-logistic-regression</guid>
      <pubDate>Tue, 09 Jan 2024 17:18:34 GMT</pubDate>
    </item>
    </channel>
</rss>