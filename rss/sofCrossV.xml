<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 18 Jul 2024 09:16:02 GMT</lastBuildDate>
    <item>
      <title>提取具有最高增长潜力的时间序列</title>
      <link>https://stats.stackexchange.com/questions/651319/extracting-time-series-with-highest-growth-potential</link>
      <description><![CDATA[我有一个包含 20k 种成分的时间序列数据集，包括它们在最热门产品中的包含率，以及这些成分在一段时间内的点赞和点击次数。
我想提取重要的成分，即“后起之秀”，即百分比和价值方面具有最高增长潜力的成分。我想在提取百分比增长率最高但绝对包含率较低的成分与绝对包含率高但百分比增长率较低的成分之间找到平衡。
我之前尝试过的是从时间序列中提取特征并使用 DBSCAN 执行聚类。
为了量化时间序列的增长，我所做的是：

在每个时间序列上拟合三次样条并计算连续点的梯度列表
计算最后三个梯度值的平均值、中位数和平均值（以指示最近的增长）
计算时间序列的汇总统计数据（最大值、最小值、平均值），使聚类算法具有“绝对尺度”的感觉

但是，问题是我没有得到最好的结果。我经常得到增长率高但绝对包含率低的值。因此，我认为提取的特征对于这项任务来说不是很好。
我对时间序列分析还很陌生，很想得到一些关于如何处理这个问题的意见，或者纠正我的一些误解。]]></description>
      <guid>https://stats.stackexchange.com/questions/651319/extracting-time-series-with-highest-growth-potential</guid>
      <pubDate>Thu, 18 Jul 2024 08:31:06 GMT</pubDate>
    </item>
    <item>
      <title>测量不完美分类器的两个模型比较结果的统计显著性</title>
      <link>https://stats.stackexchange.com/questions/651318/measuring-statistical-significance-of-comparison-results-of-two-models-with-an-i</link>
      <description><![CDATA[我有一个准确率为 87% 的分类器，可以确定两个文本生成模型的哪个输出在风格上更接近某个目标作者的另一个示例文本。
使用此分类器，我需要对两个文本生成模型的输出与示例文本进行多少次样本比较才能获得统计显著性，以表明一个生成模型在生成目标作者风格的文本方面优于另一个生成模型？结果是二进制的，其中每次比较 A &gt; B 或 A &lt; B。
举一个具体的例子，使用此分类器的一个结果表明，在 50 次比较中，A 在 60% 的时间内优于 B。在什么显著性水平下我们可以说模型 A 优于模型 B？
我已经向 ChatGPT (GPT-4) 和 Perplexity AI Pro 询问过这个问题，但我得到的所有答案都不一致，我不知道该相信什么。他们要么建议进行单样本比例检验，要么建议进行二项式检验。我认为当我们假设分类器 100% 正确时答案可能非常简单，但不确定如何解释不完美的分类器。]]></description>
      <guid>https://stats.stackexchange.com/questions/651318/measuring-statistical-significance-of-comparison-results-of-two-models-with-an-i</guid>
      <pubDate>Thu, 18 Jul 2024 08:27:43 GMT</pubDate>
    </item>
    <item>
      <title>组合多个零假设检验的方法</title>
      <link>https://stats.stackexchange.com/questions/651316/recipes-for-combining-multiple-null-hypothesis-tests</link>
      <description><![CDATA[我对假设检验有两个问题：

是否有一个或多个通用方法可以将测试组合在一起？一些程序会从两个测试 $T_1$ 和 $T_2$ 中产生一个新的更好的测试 $T_\star$。
当考虑参数测试系列 $a \rightarrow T_a$ 时，是否有方法可以产生一个测试，该测试会根据数据调整参数 $a$，但保持正确的功效？

或者没有通用解决方案，一切都应该以临时方式执行？
问题的背景
这个问题的背景是我的答案这里。上下文是寻找有界变量的平均值的测试，我给出了一组严格测试。
但是，正如 OP 所指出的，我的测试系列在简单情况下可能非常缺乏动力，因为它只查看数据的单一摘要，因此非常短视。
作为一种解决方法，我认为对测试组合进行想象是很自然的，这样一个测试的盲点可能会被另一个测试覆盖。例如，我们可以：

尝试将多个这样的测试组合在一起；
将一个这样的测试与标准学生测试相结合以获得平均值；
根据数据调整我的测试系列的阈值参数 $t$。

这些想法让我想到了我的问题。在这种情况下或一般情况下，是否有进行此类组合的方法？或者必须手动完成所有操作才能显示特定的测试组合具有适当的水平但功效有所提高？
我最初不成功的想法
以下是一些我认为行不通的想法：

基于 Bonferoni 式校正的强力组合，用于多重测试

这是非常悲观的。如果测试确实是互补的，那么它们的最坏情况应该没有重叠。Bonferoni 校正将极其缺乏功效，实际水平将远低于名义水平
我们进行的组合越多，我们就越会破坏组合测试的功效
（注意：回想一下，拒绝率通常是连续的；因此，几乎为零的模型的功效等于水平）


没有校正的简单组合：如果任何测试拒绝，则拒绝零。

这是相反的极端，假设所有测试都以某种方式完美对齐
组合测试将过多地拒绝原假设



总体而言，这两种方法似乎都过于粗糙，无法取得太大的成效。]]></description>
      <guid>https://stats.stackexchange.com/questions/651316/recipes-for-combining-multiple-null-hypothesis-tests</guid>
      <pubDate>Thu, 18 Jul 2024 07:49:33 GMT</pubDate>
    </item>
    <item>
      <title>Stata 中因子分析后的方差</title>
      <link>https://stats.stackexchange.com/questions/651313/variance-after-factor-analysis-in-stata</link>
      <description><![CDATA[我在 Stata 中运行因子分析（-factor- 命令）并获取每个因子的特征值。然后，我进行旋转，表格中显示的不是特征值，而是方差。我有两个问题：

在决定保留哪些因子时，我应该使用特征值（旋转前）还是方差（旋转后）？
如果我应该使用方差，特征值&gt;1 的相同截止作用是否适用于方差（即，我应该只使用方差&gt;1 的因子）。

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651313/variance-after-factor-analysis-in-stata</guid>
      <pubDate>Thu, 18 Jul 2024 06:41:39 GMT</pubDate>
    </item>
    <item>
      <title>在计算平均值之前是否有必要考虑特定的分布？</title>
      <link>https://stats.stackexchange.com/questions/651311/is-considering-a-specific-distribution-necessary-before-computing-an-average</link>
      <description><![CDATA[很多时候，我计算变量的平均值时根本不考虑分布，并且我使用这些计算出的平均值来表示数据中变量的度量，而没有提及特定的分布。
举一个具体的例子，我计算电子商务用户购买的平均购买次数，但我没有考虑该平均值的特定分布。
所以我不知道我做的是对还是错，因为我计算平均值时没有考虑特定的分布，所以我不知道平均值属于哪个分布。
在计算变量的平均值之前，我必须考虑特定的分布吗？或者我可以直接计算平均值并使用它而不考虑任何分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/651311/is-considering-a-specific-distribution-necessary-before-computing-an-average</guid>
      <pubDate>Thu, 18 Jul 2024 05:47:18 GMT</pubDate>
    </item>
    <item>
      <title>关于人类评级和反馈系统最好的书籍有哪些？</title>
      <link>https://stats.stackexchange.com/questions/651309/what-are-the-best-books-about-human-rating-and-feedback-systems</link>
      <description><![CDATA[我正在研究使用 Surge 或 Scale AI 等人类评分平台对 LLM 模型进行评估数据收集和评级评估。我还在研究如何使用 LLM 用户的调查方法来了解更多信息。
关于项目评级和评估统计的最佳书籍是什么，其中一个或多个评分者提供反馈？这似乎在某些方面与调查方法重叠，尽管它们有所不同。这与 RLHF 或奖励模型学习不同。
我在这个网站上看到了其他“什么是最好的书”问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/651309/what-are-the-best-books-about-human-rating-and-feedback-systems</guid>
      <pubDate>Thu, 18 Jul 2024 05:34:49 GMT</pubDate>
    </item>
    <item>
      <title>对置信区间含义的误解</title>
      <link>https://stats.stackexchange.com/questions/651307/misconceptions-about-the-meaning-of-confidence-intervals</link>
      <description><![CDATA[假设我们从样本中创建一个 95% 的 CI，以估计总体平均值。
假设 95% 的 CI 结果是 [34.2, 36.7]
根据频率论者的观点，。
1) 总体平均值是一个固定参数
2) 如果我们要抽取大量相同大小的随机样本并从每个样本中创建 95% 的 CI，则 95% 的 CI 将包含真实的总体平均值。
以下被认为是一种误解。
3) 真实总体平均值出现在上述 95% CI 中的概率为 95%，即 [34.2, 36.7]
频率论者给出了以下两个原因和理由。
a) “一旦计算出 95% 的 CI，它要么包含总体均值，要么不包含。不再有（怀疑）CI 是否包含总体均值的概率”。
我不太理解这个论点。如果总体均值已知，这显然是正确的。
但如果真正的总体均值未知，那么 CI 只有机会（概率）包含总体均值。
b) 这是一个反证法，用​​来证明上面的陈述 3是错误的
假设 CI [34.2, 36.7] 包含总体均值的概率为 95%。
如果我们多次重复抽样过程，我们可以得到一个 CI 在初始 CI 之外的样本。
例如 [36.9, 37.3]
现在，这两个不重叠的 CI 范围都不可能有 95% 的概率包含真实的总体平均值。
但是，我认为我们可以从语句 2 开始并推断出语句 3
让我们这样开始吧。
我们随机抽取样本，创建 95% 的 CI 并将其写在一张纸上。
我们重复这个过程很多次。
现在我们有这么多张纸。
上面的语句 2推断出下面的论点
4) 由 95% 的样本制成的 CI 包含真实的总体平均值。
==&gt;这些纸片中有 95% 包含真实的总体平均值。
==&gt; 任何一张纸片都有 95% 的概率包含真实的总体平均值。
==&gt;任何单个 CI 都有 95% 的概率包含真实的总体平均值。
这本质上就是上面的陈述 3，即“误解”。
那么为什么这种推理是错误的？
更新 1
根据 @Mathemagician777 的反馈，以下陈述是正确的还是误解？
3.5)“区间 [34.2, 36.7] 有 95% 的概率捕捉真实的总体平均值”
更新 2
两位成员建议将以下问题作为可能的答案。
为什么 95% 的置信区间 (CI) 并不意味着包含平均值的概率为 95%？
上述问题和回答都没有回答我提出的问题。我给出了从事实出发并得出误解的推理步骤。我想知道为什么这种推论是错误的。
更新 3
我看到的一个常见回应是“总体平均值是固定的，因此，认为特定 CI 有可能包含总体平均值是错误的”。
让我用掷骰子的例子来反驳。

人 A 掷骰子并向人 B 隐藏结果。现在结果就像总体平均值一样固定了。现在骰子已经归还，在本实验中不再起作用。
B 进行了一系列猜测，每次猜测的数字都在 1 到 6 之间。
这些猜测（置信区间）中的每一个都有 1/6 的概率包含初始掷骰子的结果，而初始掷骰子的结果对 B 来说是隐藏的。
例如，B 说“我猜是 4”并且该猜测有 1/6 的概率正确包含初始掷骰结果。

此示例表明，即使掷骰结果是固定但隐藏的，猜测猜测（包含）隐藏结果的能力仍然存在概率。
在上面的例子中，掷骰结果类似于固定的总体平均值，并且每个猜测类似于从随机样本中得出的 95% CI。
那么，为什么特定的 95% CI 不能有 95% 的概率包含总体平均值？]]></description>
      <guid>https://stats.stackexchange.com/questions/651307/misconceptions-about-the-meaning-of-confidence-intervals</guid>
      <pubDate>Thu, 18 Jul 2024 04:52:01 GMT</pubDate>
    </item>
    <item>
      <title>关系事件建模用于研究社会关系的时间动态</title>
      <link>https://stats.stackexchange.com/questions/651303/relational-event-modeling-to-investigate-temporal-dynamics-of-social-relationshi</link>
      <description><![CDATA[我有一个高分辨率数据集（来自全发生采样），其中包含几种（6）种不同类型的社交互动或事件，例如最近邻居、社交梳理、肩部接触以及几周内鸟类之间发生这些互动的时间戳。有了这些数据，我可以确定二元组之间事件类型的发起时间（第一次观察到每次互动的时间），以及这些配对每次互动的记录（每个事件类型）。
一般来说，我感兴趣的是分析：
(1) 配对之间事件类型的发起顺序，以及
(2) 发起身体接触和未发起身体接触（社交梳理、肩部接触）的配对的最近邻事件的过去活动模式是否不同。
我相信我可以使用 R 包中的 rem.dyad() 函数通过关系事件模型 (REM) 测试我的假设，但我有几个问题/疑虑。我感觉有点力不从心，因为我没有模型拟合经验，而且我很难理解术语和这种方法的一些功能/局限性。

虽然我找到了一些例子（这里）将 REM 应用于类似问题（相同类型交互的事件序列），但我还没有找到一个我可能能够分析不同类型互动的启动顺序（以及这些互动发生速度的潜在差异）。听起来参与转变可能与此相关？

通过对超过 100 对二元组的数据的描述性分析和可视化，我可以看到，通常，最近邻居的关联先于身体接触事件（最近邻居之后发起的身体接触类型可能有所不同，但有些类型比其他类型更常见）。通常，关系会发展，成对的鸟会发起身体接触，尽管有时鸟类被观察为最近邻居，并没有发起身体接触。我想测试持久性（过去的接触倾向于成为未来的接触）或互惠性（A 与 B 的最近邻居以及 B 与 A 的最近邻居）的模式是否能解释未来身体接触的发生。


正如我所提到的，我对行话以及拟合 REM 模型的所有细微差别和潜在陷阱感到有点不知所措。本质上，我想知道这是否是一个合适的分析，以及关于我应该从哪里开始创建更简单的模型以及如何构建复杂性的建议。任何和所有的建议（请不要使用行话！）都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/651303/relational-event-modeling-to-investigate-temporal-dynamics-of-social-relationshi</guid>
      <pubDate>Thu, 18 Jul 2024 02:50:48 GMT</pubDate>
    </item>
    <item>
      <title>具有多个值和评估者的每个项目评估者间信度</title>
      <link>https://stats.stackexchange.com/questions/651302/per-item-inter-rater-reliability-with-multiple-values-and-raters</link>
      <description><![CDATA[我正在尝试找到最佳统计计算方法，以衡量 72 位不同评分者对同一项目的一致性。我的目标是通过统计数据传达评分者对其评分的差异以及是否存在某种共识/一致意见。
数据：我对使用数值（李克特量表 1-6）的 5 个问题调查有 72 个回复。
例如：



评分者
问题 1
问题 2




1
5
4


2
1
2


3
3
2



我想计算他们每项的一致性（因为每个调查问题都是一个完全独立的问题，似乎与你对不同餐厅进行评级的想法不一致 -如果我错了，请纠正我）。其他 IRR 计算似乎对一个项目不太有效，需要多个项目才能发挥作用。
我想我可能应该更多地关注方差，但我不确定。我会很感激任何建议和 Python 实现/库。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651302/per-item-inter-rater-reliability-with-multiple-values-and-raters</guid>
      <pubDate>Thu, 18 Jul 2024 02:16:14 GMT</pubDate>
    </item>
    <item>
      <title>得到的 p 值不显著但效果大小很大我该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/651291/getting-insignificant-p-values-but-large-effect-size-what-should-i-do</link>
      <description><![CDATA[我使用 Qualtrics 进行了一项调查，收到了 700 多份回复。我还收集了人口统计数据，以分解数据并观察各组之间的差异。几个问题使用了显示逻辑，因此这些问题的总回复数量（50-200，取决于问题）低于理想样本量（~300）。我得到的 p 值不显著且大于 0.05，但 Cramer&#39;s V 值也很大。有什么建议可以告诉我下一步该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/651291/getting-insignificant-p-values-but-large-effect-size-what-should-i-do</guid>
      <pubDate>Wed, 17 Jul 2024 21:49:31 GMT</pubDate>
    </item>
    <item>
      <title>Welch t 检验的 p 值对于 N=2 个样本校准不佳</title>
      <link>https://stats.stackexchange.com/questions/651279/welch-t-test-p-values-are-poorly-calibrated-for-n-2-samples</link>
      <description><![CDATA[我正在对非常小的样本量执行大量 Welch t 检验（方差不等的 t 检验），通常每个条件只有两个样本。我发现 p 值校准得不好：模拟分布上的分布不均匀。
问题
对于每个条件 N=2 个样本的 Welch t 检验，是否存在已知的校准？
最小 Python 代码
import numpy as np
import scipy as sp
from matplotlib import pyplot as plt

rng = np.random.default_rng()

X = rng.normal(loc=0, scale=1, size=(2, 1000000))
Y = rng.normal(loc=0, scale=2, size=(2, 1000000))

p = sp.stats.ttest_ind(X, Y, equal_var=False).pvalue
plt.hist(p,
bins=np.linspace(0, 1, 100),
histt​​ype=&#39;step&#39;,
density=True)
plt.axhline(1)
plt.xlabel(&#39;p&#39;)
plt.ylabel(&#39;PDF of p&#39;)

# 统计检验分布不均匀
ks_stat, ks_p_value = sp.stats.kstest(p, &#39;uniform&#39;)
print(&quot;KS Statistic:&quot;, ks_stat)
print(&quot;KS Test p-value:&quot;, ks_p_value)

输出如下。
KS Statistic: 0.03906382636964301
KS Test p-value: 0.0

]]></description>
      <guid>https://stats.stackexchange.com/questions/651279/welch-t-test-p-values-are-poorly-calibrated-for-n-2-samples</guid>
      <pubDate>Wed, 17 Jul 2024 18:56:49 GMT</pubDate>
    </item>
    <item>
      <title>敏感性、检测概率和患病率之间的关系</title>
      <link>https://stats.stackexchange.com/questions/651270/relationship-between-sensitiviy-probability-of-detection-and-prevalence</link>
      <description><![CDATA[各位，我有 3 个问题：

如果我知道对一组患者进行特定测试的检查次数以及测试的敏感度，我是否可以直接估计在每个患者中检测到疾病的总体概率？如果是，则此方法或变量具有特定术语？

接着上一个问题，假设我将估计的检测概率（来自问题 1）与观察到的患病率作图。从理论上讲，这条曲线会增加直到达到稳定点吗？这表明当观察到的患病率等于真实患病率时，我已经检测到了所有病例。

基于前面的问题，如果敏感度和观察到的患病率之间的这种关系成立，我如何确定最低敏感度阈值？该阈值将指示置信度，即当观察到的患病率达到或超过该阈值时，很有可能接近真实患病率。有什么方法可以识别曲线上的这个点吗？


提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651270/relationship-between-sensitiviy-probability-of-detection-and-prevalence</guid>
      <pubDate>Wed, 17 Jul 2024 17:14:09 GMT</pubDate>
    </item>
    <item>
      <title>Cox 回归基线风险和系数解释</title>
      <link>https://stats.stackexchange.com/questions/651254/cox-regression-baseline-risk-and-interpretation-of-coefficients</link>
      <description><![CDATA[我最近遇到了一个与 Cox 回归有关的问题，但找不到答案（如果您知道任何答案，请将我引导至相应的资源）。因此，问题如下：

我有两个不同肿瘤等级（A 和 B）的基因表达数据集。
我想检查基因表达如何根据肿瘤等级影响 HR，以及差异是否具有统计学意义。

问题是我想将基因表达保留为数值，我不想对这些值进行中位数分割或任何其他转换。
我正在使用 R 工作，并使用生存包进行分析。
我在这篇文章中找到了一些非常有用的信息（cox 模型中的分层）但我仍然感到有点迷茫……主要是关于某些模型中的基线风险以及比较模型的正确方法。我研究过几种模型：

分层模型

fit.strat &lt;- summary(coxph(Surv(time, death == 1) ~ gene + strata(grade), data = test))
.            coef        exp(coef)       se(coef)      z      Pr(&gt;|z|) 
gene        0.2636      1.3016           0.1026         2.569     0.0102 *
该模型假设两个等级的基线风险不同（我们不知道差异），并且基因表达的单位增加会使两个等级的 HR 增加 1.3016。

两个模型

fit.grpA &lt;- summary(coxph(Surv(time, death == 1) ~ gene, subset=(grade== &quot;A&quot;), 数据 = 测试))
.          coef         exp(coef)        se(coef)       z      Pr(&gt;|z|) 
gene     0.7343       2.0840            0.1787         4.11     3.96e-05 ***
fit.grpB &lt;- summary(coxph(Surv(time, death == 1) ~ gene, subset=(grade== &quot;B&quot;), data = 测试))
.          coef         exp(coef)        se(coef)     z  Pr(&gt;|z|) 
gene      0.0837      1.0873           0.12020       0.69      0.49
fit.grpA 和 fit.grpB 是两个不同的模型，具有不同的基线风险和基因表达变化的不同影响。
可以使用 ANOVA 检验对这些模型进行比较。

无分层

fit &lt;- summary(coxph(Surv(time, death == 1) ~ grade:gene, data =测试）
. coef      exp(coef)        se(coef)          z             Pr(&gt;|z|) 
gradeA:gene  0.28458    1.32920          0.11894            2.393        0.01673 * 
gradeB:gene  0.27266    1.31346          0.09799            2.783        0.00539 **
这里我们有关于 HR 与基线变化的信息，但基线是什么？基因表达的一些基线水平，没有按年级区分？
是否可以检查基因表达变化的影响在年级之间是否存在统计学差异（如果 2 年级：基因 和 3 年级：基因 结果有显著差异）？]]></description>
      <guid>https://stats.stackexchange.com/questions/651254/cox-regression-baseline-risk-and-interpretation-of-coefficients</guid>
      <pubDate>Wed, 17 Jul 2024 15:03:12 GMT</pubDate>
    </item>
    <item>
      <title>如何证明许多函数（一百、一千）在区间内具有相同的形状和值分布？</title>
      <link>https://stats.stackexchange.com/questions/651231/how-to-show-that-many-functions-a-hundred-a-thousand-have-the-same-shape-an-d</link>
      <description><![CDATA[我有一些函数，它们在迭代间隔 [0,1] 上看起来都像这样：

即它们在 0.4 附近有一个零，从零到 0.4 的导数为正，在 1 附近有一个零或略微为负的导数。
我打算证明它们在这个间隔上实际上都非常相似。我需要对至少数百个这样的分布进行这样的证明。我认为这可以通过对相同参数的函数值进行采样（例如 500 个均匀分布的 x）然后在概率图上绘制其中一个函数作为参考，并在其上添加数百个其他函数 - 应该或多或少是一条直线来直观地完成。
下面是两个此类样本的 qq 图：

有没有更好或更正式的方法来做到这一点 - 你有什么建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/651231/how-to-show-that-many-functions-a-hundred-a-thousand-have-the-same-shape-an-d</guid>
      <pubDate>Wed, 17 Jul 2024 10:34:04 GMT</pubDate>
    </item>
    <item>
      <title>寻找概率密度函数的练习</title>
      <link>https://stats.stackexchange.com/questions/651024/exercise-on-finding-probability-density-function</link>
      <description><![CDATA[设 $Y_1$ 和 $Y_2$ 独立且在区间 (0, 1) 上均匀分布。求 $U = Y_1/Y_2$ 的概率密度：
解决方案：
$F_U(u) = P(U \le u) = P(Y_1/Y_2 \le u)$。看图：

我们可以看到有两个区域：$0 \le u \le 1$ 和 $u \gt 1$。因为 $tan(\alpha) = \frac{1}{u} = \frac{y_2}{y_1}$ 我们看到 $u = y_1$，所以可以说 $F_U(u) = \frac{y_1 y_2}{2} = \frac{u y_2}{2}$，因为 $y_2 = 1$，然后 $F_U(u) = \frac{u}{2}$ 对于 $0 \le u \le 1$。因此，$f_U(u) = \frac{d[F_U(u)]}{du} = \frac{1}{2}$在此范围内。
接下来，我们需要找到当$u \gt 1$时的$f_U(u)$。为此，我们需要找到积分：
$$F_U(u) = \int_0^1 \int_0^{y_1/u}{\frac{1}{(\theta_2 - \theta_1)^2}dy_2 dy_1} = \frac{1}{2u}$$
因为 $\theta_2 = 1$ 且 $\theta_1 = 0$。因此，对其进行微分，得到负结果 $f_U(u) = \frac{-1}{2u^2}$。这看起来是可以解释的，因为 $\frac{1}{2u}$ 是一条双曲线，在 $u \gt 1$ 上它递减一，所以导数是负的，但根据密度函数的定义，它显然不能为负。
对此的答案是：
$$f_U(u) = \frac{1}{2}, 0 \le u \le 1$$
并且
$$f_U(u) = \frac{1}{2u^2}, u \gt 1$$
我不明白 $f_U(u)$ 是如何变成的积极的，请帮忙。]]></description>
      <guid>https://stats.stackexchange.com/questions/651024/exercise-on-finding-probability-density-function</guid>
      <pubDate>Sun, 14 Jul 2024 14:58:38 GMT</pubDate>
    </item>
    </channel>
</rss>