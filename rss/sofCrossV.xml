<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 12 Dec 2024 21:17:10 GMT</lastBuildDate>
    <item>
      <title>“群体间协议”的适当指标</title>
      <link>https://stats.stackexchange.com/questions/658647/appropriate-metrics-for-inter-group-agreement</link>
      <description><![CDATA[我需要比较发给两组不同评分员的问卷结果，并以某种方式量化两组之间的一致性。
问卷中有 12 个问题涉及对某些要求句子的解释，第一组约有 100 名独立评分员回答了这些问题，第二组约有 40 名独立评分员回答了这些问题。
收集的结果数据是无序或无排名的名义数据。
以下是数据摘录：
 V1 V2 V3 V4 V5 
&lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;
1 2 2 3 2 1 
2 2 2 3 2 1 
3 1 4 4 4 1 
4 2 3 3 3 2 
5 1 1 4 2 4 
6 2 2 3 2 2 
7 1 1 3 1 1 
8 2 3 3 2 2 
9 2 2 3 3 3 
10 2 3 3 2 2 

列代表不同的评估者，而每行代表问卷的一个研究对象，可以从 1-3 或 1-4 进行评分（再次，名义数据）。
对于单个评估者组，我可以使用常见的评估者间信度指标（如 Lights&#39; Kappa）轻松计算“组内”一致性水平。
事实上，我已经这样做了，发现第一组 Kappa 为 0.218，第二组 Kappa 为 0.758（使用 R 包 irr 中的 kappam.light 计算）之间存在显著差异。
因此，看起来第二项研究中的组内一致性大幅提高。
但如果评级与第一组中最常见的评级相差很大，这对我没有帮助。
在这种情况下，我将如何计算“组间一致性”的水平。
我能做的就是将第一组的结果与第二组的结果相结合（即合并/连接表格）并计算联合 IRR。这将向我展示整体一致性，同时将两个组视为一个大组。
但这真的能量化第一组与第二组的响应有多接近吗？
如果是，我需要有相等的组大小吗？
或者是否有专门设计用于比较两组之间一致性水平的指标？
我在这里找到了一个类似的问题，但在这种情况下，作者处理的是序数数据。
这里建议计算和比较两组的平均值，然后进行统计显着性检验，这对于名义数据来说可能没有多大意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/658647/appropriate-metrics-for-inter-group-agreement</guid>
      <pubDate>Thu, 12 Dec 2024 21:10:21 GMT</pubDate>
    </item>
    <item>
      <title>重复测量二元变量的 Cohen Kappa</title>
      <link>https://stats.stackexchange.com/questions/658643/cohens-kappa-for-repeated-measures-binary-variables</link>
      <description><![CDATA[我进行了一项实验，展示了两种类型的广告信息：第一种类型具有理性风格，第二种具有感性风格。样本多次接触这些信息（重复测量），每次我都会进行问卷调查，询问这些信息是理性的还是感性的。所以我有一个 2x2 矩阵，其中变量 1 是信息类型（理性/感性），变量 2 是信息的识别（理性/感性）。因此，两个变量都是二元名义分类变量。
我想进行操纵检查，看看受试者是否正确识别了信息风格，我应该使用哪种一致性测试？我考虑过 Cohen 的 kappa，但就我而言，我进行了重复测量，并且我读到这可能不是正确的测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/658643/cohens-kappa-for-repeated-measures-binary-variables</guid>
      <pubDate>Thu, 12 Dec 2024 20:35:46 GMT</pubDate>
    </item>
    <item>
      <title>具有排列标准误差的 Wald 检验？</title>
      <link>https://stats.stackexchange.com/questions/658642/wald-test-with-permutation-standard-error</link>
      <description><![CDATA[许多统计检验都基于 Wald 类 z 统计量：$z = \frac{\hat{\theta}}{\text{SE}(\hat{\theta})}$，其中 $\theta$ 是感兴趣的统计量，SE 是标准误差。然后可以通过将 $z$ 与标准正态 (0,1) 分布进行比较来计算 p 值。
我想知道是否可以基于 $\theta$ 的置换零分布来估计 z 检验中的标准误差？或者 z 检验的标准误差是否应始终在备择假设下计算？
更多上下文：
我知道我可以直接从置换分布计算 p 值，但就我而言，我正尝试进行荟萃分析，这需要每个队列的点估计和标准误差。但是，我使用的统计数据没有封闭形式的标准误差估计，但我已经有了统计数据的置换零分布。我可以只使用置换分布的标准误差进行荟萃分析吗？
我使用的统计数据是来自 GSEA 的“标准化富集分数”(NES)。 NES 没有标准误差公式，而是使用置换检验来计算其 p 值。我想知道是否可以使用置换分布的标准差作为元分析的标准误差估计量。]]></description>
      <guid>https://stats.stackexchange.com/questions/658642/wald-test-with-permutation-standard-error</guid>
      <pubDate>Thu, 12 Dec 2024 20:35:35 GMT</pubDate>
    </item>
    <item>
      <title>多项分布的广义方差</title>
      <link>https://stats.stackexchange.com/questions/658639/generalized-variance-of-a-multinomial-distribution</link>
      <description><![CDATA[标量方差是一个单变量概念，因此广义方差通过取多元分布的协方差矩阵的行列式，对多变量设置进行了概括。
但是，多项分布具有奇异协方差矩阵，因此行列式提供的有关多项分布中变异性的信息最少；每个多项分布都给出相同的广义方差零。
但是，我们可以从多项分布中删除一个类别，并暗示另一个类别会发生什么（在对分类变量进行回归时很常见）。当我们这样做然后计算广义方差时，该值并不总是零。
在进行此实验时，我们放弃哪些类别似乎并不重要。此外，如果我们只是从完整多项分布的协方差矩阵中删除行 $k$ 和列 $k$，行列式似乎并不依赖于 $k$。
set.seed(2024)

# 计算多项分布协方差矩阵的函数 
#
multinomial_cov &lt;- function(n, p){

k &lt;- length(p)

cov_np &lt;- matrix(NA, k, k)
for (i in 1:k){
for (j in 1:k){

if (i == j){
cov_np[i, j] &lt;- n * p[i] * (1 - p[j])
}
if (i != j) {
cov_np[i, j] &lt;- -n * p[i] * p[j]
}
}
}
return(cov_np)
}
#
# 函数结束

R1 &lt;- 25 # 不同多项式参数组合的数量
R2 &lt;- 100 # 确定要删除的索引的次数
dets &lt;- matrix(NA, R1, R2)
for (i in 1:R1){

# 确定分布参数
#
n &lt;- sample(seq(1, 10, 1), 1, replace = F) # 掷骰子次数
k &lt;- sample(seq(3, 25, 1), 1, replace = F) # 有多少个类别，3-25
p &lt;- runif(k, 0, 1); p &lt;- p/sum(p) # 概率参数

for (j in 1:R2){

# 从协方差矩阵中删除一行/列（相同索引）
​​
在计算 n-1 x n-1 矩阵的行列式之前
#
idx &lt;- sort(sample(seq(1, k, 1), k - 1, replace = F))
cov_mat &lt;- multinomial_cov(n, p)
dets[i, j] &lt;- det(cov_mat[idx, idx])
}
}
apply(dets, 1, unique) # 无论删除哪一行/列，行列式都是
# 对于给定的一组多项式参数来说都是相同的

我似乎已经在足够多的设置中这样做了，我可能不是运气好，所以我认为我偶然发现了关于多项式的一个一般事实分布。证明是什么，这种行列式是否是多项分布中变异性的有用描述？]]></description>
      <guid>https://stats.stackexchange.com/questions/658639/generalized-variance-of-a-multinomial-distribution</guid>
      <pubDate>Thu, 12 Dec 2024 18:21:31 GMT</pubDate>
    </item>
    <item>
      <title>4x4 空心矩阵的特征值 [已迁移]</title>
      <link>https://stats.stackexchange.com/questions/658638/eigenvalues-of-4x4-hollow-matrix</link>
      <description><![CDATA[
我正在解决这道练习题，我怀疑这是个插入和吐出问题。矩阵是对称的，而且看起来可能与上下三角有关？维基百科称它为空心矩阵，而 Wolfram alpha 给出了一个奇怪的答案，没有给出任何步骤。我被困在寻找特征值的行列式步骤上，其中 4x4 矩阵看起来太大而无法有效计算行列式。
关于如何继续进行，有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658638/eigenvalues-of-4x4-hollow-matrix</guid>
      <pubDate>Thu, 12 Dec 2024 18:20:16 GMT</pubDate>
    </item>
    <item>
      <title>预处理和模型选择策略</title>
      <link>https://stats.stackexchange.com/questions/658637/preprocessing-and-model-selection-strategies</link>
      <description><![CDATA[我正在研究一个故障检测问题，其中每个样本都是标有特定类型故障的时间序列。我正在使用 CNN 模型和验证集进行超参数调整。目前，我想研究不同预处理技术的影响，例如使用原始信号与应用 DFT。
为了分析这一点，我有以下验证准确度矩阵：
$$
A=\begin{bmatrix}
&amp; \text{hprams}_1 &amp; \text{hprams}_2 &amp; \text{hprams}_3 \cdots &amp; \text{hprams}_n\\
\text{Raw} &amp; \text{acc}_{11} &amp; \text{acc}_{12} &amp; \text{acc}_{13} \ \ \ \ \ \cdots &amp;\text{acc}_{1n}\\
\text{DFT} &amp; \text{acc}_{21} &amp; \text{acc}_{22} &amp; \text{acc}_{23} \ \ \ \ \ \cdots &amp;\text{acc}_{2n} \\
\end{bmatrix}, 
$$
其中每个$\text{hprams}_i$代表特定的超参数配置，每个$\text{acc}_{ij}$表示特定预处理方法和超参数设置的验证准确率。例如，$\text{hprams}_1 = (\text{number of layer}: 4, \text{learning rate}: 0.001)$ 和 $\text{acc}_{11} = 0.87$。
我有两个问题：

我目前的模型选择方法是在所有预处理方法和超参数组合中选择验证准确率最高的配置，$\max(A)$，然后在测试集上评估该模型。这是一种正确的方法吗？

为了比较预处理技术（例如 Raw 与 DFT），我建议为每种预处理方法单独选择最佳超参数配置（即在 $A$ 的每一行中取最大准确度）。然后，我将报告与这些最佳配置相对应的两个模型的测试性能。这是一种合理的方法吗？


在我审阅过的许多论文中，方法各不相同。通常，数据被分成训练集和测试集，学习率和网络架构是固定的。然后使用不同的预处理方法在训练集上训练模型，并记录各个时期的测试准确度。通常会报告最大测试准确度和最终时期准确度。但是，我认为这种方法存在缺陷，因为它缺乏适当的模型选择，可能会导致有偏差的结果。研究人员可能会尝试各种配置，并在事后隐式地选择表现最佳的设置，这可能会使结果无效。
注意：我明白准确度不是一个合适的评分规则，而且交叉验证会更好。但是，为了回答这个问题，我想在当前设置下工作。]]></description>
      <guid>https://stats.stackexchange.com/questions/658637/preprocessing-and-model-selection-strategies</guid>
      <pubDate>Thu, 12 Dec 2024 18:02:39 GMT</pubDate>
    </item>
    <item>
      <title>高斯对数似然值究竟如何计算？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658636/how-is-gaussian-log-likelihood-value-calculated-exactly</link>
      <description><![CDATA[我检查了这些 R 函数 glm.fit() gaussian()$aic stats:::logLik.glm() 和 stats:::logLik.lm()，发现 stats:::logLik.glm() 报告的对数似然值是根据 gaussian()$aic 计算的，其定义为
function (y, n, mu, wt, dev) 
{
nobs &lt;- length(y)
nobs * (log(dev/nobs * 2 * pi) + 1) + 2 - sum(log(wt))
}

stats:::logLik.lm() 报告的对数似然值使用以下公式计算。
0.5 * (sum(log(w)) - N * (log(2 * pi) + 1 - log(N) + 
log(sum(w * res^2))))

这两个公式在高斯家族中得出相同的 logLik 和 AIC。我理解 $AIC = -2 \ln{L} + 2df$ 并且可以重现与基本函数 logLik() 相同的结果，但我不知道为什么要以上述方式计算它们。使用基于经典公式的对数密度值总和，如“正态分布 - 最大似然估计”中所示https://www.statlect.com/fundamentals-of-statistics/normal-distribution-maximum-likelihood，我得到了不同的对数似然值，无法识别我的计算和默认输出之间的关系。请参阅以下最小示例。
Data &lt;- data.frame(
y = c(0.2, 0.2, 0.3), 
n = c(10, 20, 30)
)

# GLS 模型
with(Data, sum(y * n)/sum(n)) # 0.25
summary(Model &lt;- glm(y ~ 1, weights = n, data = Data))
&quot;估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.25000 0.03536 7.071 0.0194 *
(高斯族的分散参数取为 0.075)
零偏差：2 个自由度上的 0.15
残差偏差：2 个自由度上的 0.15
AIC：-5.1731&quot;
with(Model, Prior.weights)
&quot; 1 2 3 
10 20 30 &quot;
with(Model, weights)
&quot; 1 2 3 
10 20 30 相同，无迭代重新加权&quot;

# 默认函数
logLik(Model)
&quot;4.58654 (df=2)&quot;
AIC(模型)
&quot;-5.17308 因为 -2 * 4.58654 + 2 * 2 == -5.17308&quot;
with( # 基于 gaussian()$aic 和 glm.fit()
模型，nobs(模型) * (log(deviance/nobs(模型) * 2 * pi) + 1) + 
2 - sum(log(weights)))
&quot;-7.17308
-7.17308 + 2*1 == -5.17308 是报告的 AIC
logLik 源自 AIC 测量&quot;

# OLS 模型
summary(模型 &lt;- lm(y ~ 1, weights = n, data = Data))
logLik(模型)
&quot;4.58654 (df=2) 与上文相同&quot;
AIC(Model)
&quot;-5.17308 与上文相同&quot;
with(Model, 0.5 * (
sum(log(weights)) - nobs(Model) * (
log(2 * pi) + 1 - log(nobs(Model)) + log(sum(weights * residuals^2)))))
&quot;4.58654 为报告的 logLik&quot;

# 手动计算
with(Model, sum(prior.weights * log(
dnorm(y, mean = coef(Model), sd = sigma(Model)))))
&quot;21.5717&quot;
with(Model, sum(weights) * (-1/2 * log(2 * pi)))
&quot;-55.13631&quot;
带有（模型，总和（权重）*（-1/2 * log（sigma（模型）^2）））
“77.70801”
带有（模型，（-1/（2 * sigma（模型）^2））* 总和（权重*（y - coef（模型））^2））
“-1
-55.13631 + 77.70801 - 1 == 21.5717”
带有（模型，总和（权重*（y - coef（模型））^2））
]]></description>
      <guid>https://stats.stackexchange.com/questions/658636/how-is-gaussian-log-likelihood-value-calculated-exactly</guid>
      <pubDate>Thu, 12 Dec 2024 17:03:36 GMT</pubDate>
    </item>
    <item>
      <title>在拟合模型之前通过统计抽样删除数据？</title>
      <link>https://stats.stackexchange.com/questions/658635/statistical-sampling-to-remove-data-before-fitting-a-model</link>
      <description><![CDATA[在正常情况下，其他条件相同，数据越多越好。
我对以下情况感到疑惑：我有一个非常大的数据集，我想拟合一个统计模型。但是，我的计算机不够强大，无法在整个数据集上拟合模型。
假设每个数据点都同样可靠且具有相同的数据质量，我是否可以考虑使用统计抽样来删除某些数据点，以便模型可以在我的计算机上运行？
我认为这可能相当复杂。正如我们在构建数据集时使用调查权重来确保没有一组观察结果被低估或被高估一样，是否可以使用类似的技术来确保减少数据量不会导致任何组被高估/低估？
我认为需要进行一些逻辑检查，以确保与原始数据相比，缩小后的数据集中不存在高估/低估？例如如果原始数据为（60%-40% 男女），我们希望缩减后的数据集中男女比例也大致有 20% 的差异。但是，这只是一种比较方法（例如，缩减后，男女比例保持不变，但就业与失业比例不保持不变）。也许存在一些通用技术来比较两个数据集（即原始数据集与缩减数据集）联合分布之间的差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/658635/statistical-sampling-to-remove-data-before-fitting-a-model</guid>
      <pubDate>Thu, 12 Dec 2024 16:25:22 GMT</pubDate>
    </item>
    <item>
      <title>如何将多元线性回归结果解释为因变量的百分比变化</title>
      <link>https://stats.stackexchange.com/questions/658632/how-do-i-interpret-multiple-linear-regression-results-as-change-in-dependent-v</link>
      <description><![CDATA[假设我正在解释我的 MLR 并写下我的一个独立变量，它是一个指数 (0-1)，系数为 4.169*。我的因变量以摄氏度为单位。我该如何解释这一点，以便我可以说“这个独立变量的百分比增加对应于因变量的 x% 增加/减少”
我的因变量和独立变量都是线性尺度（即：没有对数）
关于对数尺度执行此操作有很多信息，但我猜它被认为是线性的直观假设？无论如何，帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/658632/how-do-i-interpret-multiple-linear-regression-results-as-change-in-dependent-v</guid>
      <pubDate>Thu, 12 Dec 2024 16:02:42 GMT</pubDate>
    </item>
    <item>
      <title>当我想比较矩阵问题（每行一个答案，5pt 李克特量表，相关样本）的均值时，进行重复测量方差分析是否有效？</title>
      <link>https://stats.stackexchange.com/questions/658631/is-it-valid-to-do-a-repeated-mesure-anova-when-i-want-to-compare-means-of-a-matr</link>
      <description><![CDATA[我们要求参与者对不同的项目进行评分（矩阵问题，12 个项目（行）和 5 分李克特量表（每行一个答案））。调查中的行是随机的。
问题：如何比较项目的平均值？我想知道它们是否比其他项目高/低。
这听起来很简单。如果只有两个平均值，我只需进行 t 检验。但不知何故，我不知道我可以使用什么测试来检查 12 个组织（=我的因变量）之间的平均值是如何不同的。请记住，样本是因变量（我没有 UV/组）。
我想到的是重复测量方差分析......你怎么看？我知道，通常 RM Anova 的示例是“在不同时间点测量相同的因变量”。我有“不同的因变量，在略有不同的时间点进行测量”。
或者你还有其他要检查的吗？
谢谢你的想法！
Manu]]></description>
      <guid>https://stats.stackexchange.com/questions/658631/is-it-valid-to-do-a-repeated-mesure-anova-when-i-want-to-compare-means-of-a-matr</guid>
      <pubDate>Thu, 12 Dec 2024 15:29:06 GMT</pubDate>
    </item>
    <item>
      <title>方差的序贯概率比检验</title>
      <link>https://stats.stackexchange.com/questions/658630/sequential-probability-ratio-test-for-variance</link>
      <description><![CDATA[Hogg 和 McKean 的书《数理统计学导论》中的一道练习题如下
练习 8.4.1. 设 $X$ 为 $N(0,\theta)$，按照本节的符号表示，设 $\theta&#39; = 4,$ $\theta&#39;&#39; = 9,$ $\alpha_a = 0.05,$ 和 $\beta_a = 0.10.$ 证明序贯概率比检验可以基于统计数据 $\sum_{i=1}^n X_i^2.$ 确定 $c_0(n)$ 和 $c_1(n).$
请注意，零假设和备择假设都是简单假设（即 $H_0: \theta = \theta&#39;$ 和 $H_1: \theta = \theta&#39;&#39;$）。
解决方案很简单，我们得到的答案是 $$5.8387n - 32.4186 \leq \sum_{i=1}^n X_i^2 \leq 5.8387n+41.6214$$，因为只要 $\sum_{i=1}^n X_i^2$ 就是这样被限制的。一旦它“逃离”了其中一个界限，我们就会做出决定并停止采集更多样本。
我的问题：下限（所谓的 $c_0(n)$）在 $n=6$ 之前为负！！在采集到第六个样本之前，我们永远无法接受零假设。我对此的第一反应是“这难道不会增加我们拒绝零假设的机会，即使零假设为真？”但随后我还发现上限相当高，并且每增加一个样本，上限就会增加 $5.8387$。
尽管如此，在这种情况下，直到达到一定数量的样本，顺序测试才能确定零假设为真（当零假设实际上为真时）。事实上，我们不妨从 $n=6$ 开始。我的想法正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658630/sequential-probability-ratio-test-for-variance</guid>
      <pubDate>Thu, 12 Dec 2024 15:25:23 GMT</pubDate>
    </item>
    <item>
      <title>不确定要对我的数据使用什么统计检验：方差分析还是卡方</title>
      <link>https://stats.stackexchange.com/questions/658627/unsure-what-stats-test-to-use-for-my-data-anova-or-chi-square</link>
      <description><![CDATA[我有一个由 17 个特征和 9 个组组成的矩阵，其值是该组中出现的每个特征的计数，例如：




Grp1
Grp2
Grp3
Grp4
Grp5
Grp6
Grp7
Grp8
Grp9




F1
2
9
0
1
0
0
1
2&lt; /td&gt;
0


F2
3
4
0
0
0
0
0
3
1


F3
4
3
0
0
0
0
0
8
1


F4
1&lt; /td&gt;
1
8
0
0
0
0
0
0
0


F5
0
1
0&lt; /td&gt;
0
0
0
3
9
1


F6
4
7
1
0
0
0
0
5
0


F7
1
7
0
1
0
0
0
8
2


F8
5
10
1
0
0
0
8
1


F9
1
2
0
0
0
0
0
4
2


F10 
9
5
0
0
1
0
0
6
5


F11
3
6 
0
0
1
0
0
8
3


F12
10
16
0
1
1
0
1
13
3


F13
10
25
1
1
3
0
0
11
10


F14
1
14
0
1
2
0
2&lt; /td&gt;
8
3


F15
11
13
0
0
1
1
0
12
1


F16
8
3
0
0
1
0
0
6
3


F17
5
10
0
0
0
0
0
5
4



我想测试每个特征是否与一个或多个组有显著关联。例如，F1 可能与 Grp1 和 Grp2 关联，而 F4 可能与 Grp3 关联。
如能提供关于使用什么测试以及如何正确格式化分析的任何建议，我将不胜感激。如果您能够提供示例 R 代码，那将非常棒，我们将不胜感激。
编辑：
我写这个是为了开始分析数据。
fisher.groups &lt;- function(mat){
res.mat &lt;- matrix(data = NA, 
nrow = nrow(mat),
ncol = ncol(mat),
dimnames = list(rownames(mat),
colnames(mat)))

for (i in rownames(mat)) {
for (j in colnames(mat)) {
idx &lt;- which(rownames(mat) == i)
jdx &lt;- which(colnames(mat) == j)

tmp.mat &lt;- matrix(c(mat[idx,jdx],
sum(mat[ idx,-jdx]),
sum(mat[-idx, jdx]),
sum(mat[-idx,-jdx])), 
nrow = 2, ncol = 2)

res.mat[i,j] &lt;- fisher.test(tmp.mat, alternative = &quot;greater&quot;)$p.value
}
}
return(res.mat)
}

这有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658627/unsure-what-stats-test-to-use-for-my-data-anova-or-chi-square</guid>
      <pubDate>Thu, 12 Dec 2024 15:06:59 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 中不同类别之间的序列长度不同</title>
      <link>https://stats.stackexchange.com/questions/658623/varying-sequence-lengths-between-classes-in-lstm</link>
      <description><![CDATA[我正在做一个项目，目标是预测在线课程的学生是否会退学。该课程分为 20 个课程周。对于每个课程周，我都有某些类型的数据来表明表现或行为。
已完成全部课程的用户有 20 个课程周中每个课程周的数据。这些是非退学用户。退学用户有较少周的数据，具体取决于他们在退学前学习了多少课程。
我现在想尝试训练一个 LSTM 模型来捕捉几周内的行为和参与模式，并能够预测退学标签（0 表示非退学，1 表示退学）。我的问题是：
退学用户的序列长度比非退学用户短，这重要吗？模型会将较短的序列长度与辍学联系起来吗？
这将是有问题的，因为我最终想将模型部署在目前正在上课的学生数据集上，以预测他们是否会辍学。但当然，这些学生的序列长度也会短于 20。
我考虑过对非辍学用户使用截断版本的数据，即使用用户在某个课程周之前的数据，以模拟辍学用户的不完整数据。然后，模型针对每个序列长度都有辍学用户和非辍学用户的示例。但这是必要的吗？或者我可以使用非辍学用户的完整序列长度，而无需模型将较短的序列长度与辍学联系起来？]]></description>
      <guid>https://stats.stackexchange.com/questions/658623/varying-sequence-lengths-between-classes-in-lstm</guid>
      <pubDate>Thu, 12 Dec 2024 13:38:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么非平稳 AR 过程不能表示为无限 MA 过程？[重复]</title>
      <link>https://stats.stackexchange.com/questions/658605/why-cant-a-non-stationary-ar-process-be-represented-as-an-infinite-ma-process</link>
      <description><![CDATA[考虑 AR(1) 过程。如果 $|\phi|&lt;1$，则该过程为平稳过程，我们可以将该级数表示为
$$ Y_t = \epsilon_t + \phi\epsilon_{t-1} + \phi^2\epsilon_{t-2} + \phi^3\epsilon_{t-3} + \cdots $$
我听说只有平稳 AR 过程才能表示为无限 MA 过程，因此以 AR(1) 为例，如果 $|\phi| \geq 1$，为什么这不成立？]]></description>
      <guid>https://stats.stackexchange.com/questions/658605/why-cant-a-non-stationary-ar-process-be-represented-as-an-infinite-ma-process</guid>
      <pubDate>Thu, 12 Dec 2024 00:41:34 GMT</pubDate>
    </item>
    <item>
      <title>对数逻辑分布中的“对数平均值”参数是什么？</title>
      <link>https://stats.stackexchange.com/questions/658602/what-is-the-mean-of-logarithmic-values-parameter-in-log-logistic-distribution</link>
      <description><![CDATA[我从 mathworks 网站 上读到：

对数逻辑分布使用以下参数。


但是，对数逻辑分布的维基百科页面 表示该分布有两个参数，即尺度和形状。我有点困惑，我想知道“对数值的平均值”是否有一个简称，或者是否可以将其转换为形状参数。我之所以问这个问题，是因为我需要在工作中表达这个参数，但我不知道如何引用它，并将这个值转换为已知的形状参数。]]></description>
      <guid>https://stats.stackexchange.com/questions/658602/what-is-the-mean-of-logarithmic-values-parameter-in-log-logistic-distribution</guid>
      <pubDate>Wed, 11 Dec 2024 23:16:57 GMT</pubDate>
    </item>
    </channel>
</rss>