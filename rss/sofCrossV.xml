<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 15 Sep 2024 03:22:09 GMT</lastBuildDate>
    <item>
      <title>什么是移动平均模型（真的！）</title>
      <link>https://stats.stackexchange.com/questions/654385/what-is-a-moving-average-model-really</link>
      <description><![CDATA[一段时间以来，我一直在尝试理解时间序列环境中的移动平均模型是什么。
我知道它本质上是基于过去预测误差的回归，形式如下：https://otexts.com/fpp3/MA.html（请参阅本文第 3 行）。
我很难理解的是 - 这些过去的预测误差到底是什么？或者更具体地说，这些过去预测误差中的预测元素的性质是什么？例如，它只是目标时间序列到给定点的移动平均值吗？还是别的什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654385/what-is-a-moving-average-model-really</guid>
      <pubDate>Sun, 15 Sep 2024 02:51:16 GMT</pubDate>
    </item>
    <item>
      <title>当似然函数本身是一个猜测时</title>
      <link>https://stats.stackexchange.com/questions/654383/when-the-likeihood-function-is-itself-a-guess</link>
      <description><![CDATA[当存在观测值 x 和相关未知数 $T$，但没有明显的 $f(x \mid T)$ 模型时，贝叶斯会做什么？我举的例子是在商业领域，专家报告了新商业理念未来现金流的当前估值。在硬科学中是否有类似的例子，历史数据允许我们估计不同 $x$ 和 $T$ 的经验似然分布 $f(x \mid T)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/654383/when-the-likeihood-function-is-itself-a-guess</guid>
      <pubDate>Sat, 14 Sep 2024 23:35:47 GMT</pubDate>
    </item>
    <item>
      <title>回归线是否也在更多维度中穿过质心？</title>
      <link>https://stats.stackexchange.com/questions/654378/regression-lilne-goes-through-the-center-of-mass-also-in-more-dimensions</link>
      <description><![CDATA[众所周知，我也找到了证据（比如这里 https://math.stackexchange.com/questions/635670/show-that-the-least-squares-line-must-pass-through-the-center-of-mass），在简单线性回归中，回归线总是经过质心。但我没有找到任何证据将其推广到我们具有一般数量的协变量 $p$ 的情况。
它成立吗？如果成立，有证据吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654378/regression-lilne-goes-through-the-center-of-mass-also-in-more-dimensions</guid>
      <pubDate>Sat, 14 Sep 2024 18:33:35 GMT</pubDate>
    </item>
    <item>
      <title>零假设取决于数据，我可以以某种方式惩罚 p 值吗？</title>
      <link>https://stats.stackexchange.com/questions/654376/null-hypothesis-depend-on-data-can-i-penalize-the-p-value-somehow</link>
      <description><![CDATA[亲爱的 Stack Exchange 社区，
假设我有一个测量值 $k_i$（虽然它是一个整数，但与问题并不真正相关）。我对 $k_i$ 有一个零假设，这是一个依赖于单个参数 $\mu$ 的分布。这样，我就可以为我的观察结果 $k_i$ 计算一个 p 值。
问题在于，参数 $\mu$ 是使用 $k_i$ 以及其他观察结果（即 $\mu(k_1, .., k_i, .., k_n)$）进行估计的。由于使用了其他观测值，我预计 $\mu$ 和 $k_i$ 不会有很强的依赖性，但这样计算出的 p 值仍然不正确，因为零假设本身会（但愿是微弱地）依赖于观测值 $k_i$。
是否存在标准的分析或半分析方法，即使是近似的？我希望找到一种方法，仅使用 $\mu$ 计算 p 值，然后找到一个惩罚它的配方，即使用某个公式来降低它。经过一番研究，我找不到类似的东西。
我知道引导或基于玩具 MC 的方法可能有用，但我正在寻找一种处理这个问题的分析方法。
提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/654376/null-hypothesis-depend-on-data-can-i-penalize-the-p-value-somehow</guid>
      <pubDate>Sat, 14 Sep 2024 18:19:42 GMT</pubDate>
    </item>
    <item>
      <title>R 中具有一个随机截距的线性混合模型的 lme4 结果的数学再现和理解</title>
      <link>https://stats.stackexchange.com/questions/654375/mathematical-reproduction-and-understanding-of-lme4-results-for-linear-mixed-mod</link>
      <description><![CDATA[本文的目的是用数学方法重现 lmer 给出的以下线性混合模型的结果。
假设我们有 $n$ 个测试对象。对于每个测试对象 $i \in \{1, \ldots, n\}$，我们重复测量两个量 $x$ 和 $y$，测量次数为 $j \in \{1, \ldots, n_i\}$ 次。每个这样的测量值用 $y_{ij}$ 和 $x_{ij}$ 表示。我们对每个测试对象执行具有随机截距的线性混合模型：
\begin{equation*}
y_{ij} = \alpha + \beta x_{i,j} + u_i + \epsilon_{i,j}
\end{equation*&gt;
在方程中，像往常一样，$u_i$ 被认为是独立同分布的 $N(0,\sigma_u^2)$ 随机变量，而 $\epsilon_{i,j}$ 是独立同分布的 $N(0,\sigma_{\epsilon}^2)$ 随机变量，与 $u_i$。要估计的未知实参数是 $\alpha$、$\beta$、$\sigma_u$ 和 $\sigma_{\epsilon}$。
目标是使用已知数据 $x_{ij}$ 和 $y_{ij}$ 来估计 ... class=&quot;math-container&quot;&gt;$\sigma_{\epsilon}$。由于我们一直感兴趣的是 $x$ 是否对 $y$ 有影响，因此我们需要对 $\beta = 0$ 是否也进行假设检验。
要以编程方式执行此操作，让我们使用 sleepstudies 数据集，其中 $x_{ij}$ 为数字天数，$y_{ij}$ 为反应。此数据集恰好是平衡的，因此让我们通过删除两行来使其不平衡。这是可运行的代码：（版本无关紧要，但为了完整起见，我们在此处标明 lme4_1.1-34)
library(lme4)

df &lt;- sleepstudy
df$Days &lt;- as.numeric(sleepstudy$Days)
df$Subject &lt;- as.factor(sleepstudy$Subject)
df &lt;- df[-c(50, 100), ]

result &lt;- lmer(Reaction ~ Days + (1 | Subject), df)
print(summary(result))

结果是：
警告消息：
&quot;package &#39;lme4&#39; was Built在 R 版本 4.3.1 下&quot;
加载所需包：Matrix

警告消息：
&quot;包 &#39;Matrix&#39; 是在 R 版本 4.3.1 下构建的&quot;
REML [&#39;lmerMod&#39;] 拟合的线性混合模型
公式：反应 ~ 天数 + (1 | 受试者)
数据：df

收敛时的 REML 标准：1766.5

缩放残差：
最小 1Q 中位数 3Q 最大值
-3.1938 -0.5299 0.0300 0.5329 4.2588

随机效应：
组名称方差标准差
受试者（截距） 1336.0 36.55 
残差 961.7 31.01 
观察数：178，组：受试者，18

固定效应：
估计标准差误差 t 值
（截距）251.9298 9.6343 26.15
天数 10.2705 0.8171 12.57

固定效应相关性：
（截距）
天数 -0.377

通过运行 lm(Reaction ~ Days)，执行普通最小二乘法，我们看到，正如所期望的那样，他们使用普通最小二乘法估计 $\alpha$ 和 $\beta$，其中 $\hat{\alpha} = 251.4051$ 和 $\hat{\beta} = 10.4673$。
现在问题来了。无论我做什么，我都无法找到令人满意的直接数学参考来说明本例中条目 Std. Error 的公式。并且，作为结果或原因，我找不到为什么 $\hat{\sigma_u} = 36.55$ 和 $\hat{\sigma_u} = 31.01$。我尝试计算几个相关的平方误差，但没有一个达到 lmer 提供的值。有哪些数学表达式？]]></description>
      <guid>https://stats.stackexchange.com/questions/654375/mathematical-reproduction-and-understanding-of-lme4-results-for-linear-mixed-mod</guid>
      <pubDate>Sat, 14 Sep 2024 18:09:50 GMT</pubDate>
    </item>
    <item>
      <title>处理训练数据中没有缺失值的特征在测试数据中的缺失值</title>
      <link>https://stats.stackexchange.com/questions/654374/handling-missing-values-of-a-feature-in-test-data-that-had-no-missing-values-in</link>
      <description><![CDATA[Kaggle 上的泰坦尼克号 - 灾难机器学习竞赛数据集中有一个名为“票价”的数字特征。
训练数据中的“票价”没有缺失值，但测试数据中有缺失值。我知道如何处理测试数据中缺失值的特征，这些特征在训练数据中也有缺失值，但这对我来说是第一次，我找不到如何解决的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/654374/handling-missing-values-of-a-feature-in-test-data-that-had-no-missing-values-in</guid>
      <pubDate>Sat, 14 Sep 2024 17:55:31 GMT</pubDate>
    </item>
    <item>
      <title>使用经典的 GOF 测试检查逻辑回归假设</title>
      <link>https://stats.stackexchange.com/questions/654373/checking-the-logistic-regression-assumptions-with-classic-gof-tests</link>
      <description><![CDATA[在寻找在估计系数后检查模型充分性的方法时，我发现我需要 i) 检查逻辑回归假设和 ii) 检查拟合优度。
当我说拟合优度时，我并不是指测试预测能力（我用 McFadden Pseudo R^2 来测试）。我想检查估计值如何很好地表示观察到的数据。
由此得出我的疑问：当 gof 测试告诉你是否可以通过使模型更复杂来做得更好时，实际上是在测试是否存在你遗漏的非线性或相互作用，这是否与测试所有假设相同？简而言之：是否有必要通过使用例如来单独测试假设？低平滑（平滑 y）还是 HL 检验的替代方法测试相同？
因此：对于我的模型，它由一个连续解释变量（和一个二元结果）组成，样本量为 10，哪种检验最合适？由于我的样本量小，标准化 Pearson 不合适。另一个衡量标准可能是 Stukel 检验。很想听听你对此的看法！]]></description>
      <guid>https://stats.stackexchange.com/questions/654373/checking-the-logistic-regression-assumptions-with-classic-gof-tests</guid>
      <pubDate>Sat, 14 Sep 2024 16:35:11 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助理解两个分布的卷积</title>
      <link>https://stats.stackexchange.com/questions/654372/help-needed-in-understanding-the-convolution-of-two-distributions</link>
      <description><![CDATA[我正在阅读 Sheldon Ross 所著的《概率模型导论》第 12 版。第 57 页写道：

当 $X$ 和 $Y$ 独立时，能够根据 $X$ 和 $Y$ 的分布计算出 $X + Y$ 的分布通常很重要。首先假设$X$和$Y$是连续的，$X$的概率密度为$f$，而$Y$的概率密度为$g$。然后，让 $F_{X+Y}(a)$ 成为 $X + Y$ 的累积分布函数，我们有
$$ F_{X+Y}(a) = P(X + Y \leq a) $$
$$ = \int_{x+y \leq a} f(x) g(y) \, dx \, dy $$
$$ = \int_{-\infty}^{\infty} f(x) \left( \int_{-\infty}^{a - x} g(y) \, dy \right) dx $$
$$ = \int_{-\infty}^{\infty} F_Y(a - x) f(x) \, dx $$
累积分布函数 $F_{X+Y}$ 被称为分布 $F_X$ 和 $F_Y$ 的卷积（分别为 $X$ 和 $Y$ 的累积分布函数）。


但是，我们必须注意，$X+Y$ 是一个随机变量。我认为$X+Y$不一定是连续的。它也可能是离散的。设$Z=X+Y.$
如果$Z$是连续的，那么我们假设$f_{Z}$是概率密度函数。在此假设下，我们必须有，$P\{Z\leq a\}=P\{X+Y\leq a\}=\int_{-\infty}^af_Z(z)dz.$
如果$Z$是离散的，那么我们假设$F_Z$和$p_z$分别是$Z$的累积分布函数和概率质量函数。在这个假设下，我们有，$P\{Z\leq a\}=F_Z(a)=\sum_{x\leq a:p(x)&gt;0}p(x).$
但我不明白他们怎么写这个等式，

$$ F_{X+Y}(a) = P(X + Y \leq a) $$
$$ = \int_{x+y \leq a} f(x) g(y) \, dx \, dy $$
$$ = \int_{-\infty}^{\infty} f(x) \left( \int_{-\infty}^{a - x} g(y) \, dy \right) dx $$
$$ = \int_{-\infty}^{\infty} F_Y(a - x) f(x) \, dx $$

你能帮我理解一下，他们是怎么写出上面的等式的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654372/help-needed-in-understanding-the-convolution-of-two-distributions</guid>
      <pubDate>Sat, 14 Sep 2024 16:34:57 GMT</pubDate>
    </item>
    <item>
      <title>最小和过完备指数族</title>
      <link>https://stats.stackexchange.com/questions/654371/minimal-and-overcomplete-exponential-families</link>
      <description><![CDATA[我正在学习 Kevin Murphy 的《概率机器学习：高级主题》，2024 年 6 月 26 日版本。现在，我对指数族的一些概念感到困惑。
定义
考虑一个由 $\mathbf{\eta} \in \mathbb{R}^k$ 参数化的概率分布族，在 $\mathcal{X}^D ⊆ \mathbb{R}^D$ 上有固定支持。如果分布 $p(\mathbf{x}|\mathbf{\eta})$ 的密度可以写成以下形式，则我们称该分布属于指数族：
$$
p(\mathbf{x}|\mathbf{\eta}) = h(\mathbf{x})\exp\left[\mathbf{\eta}^\intercal\mathcal{T}(\mathbf{x}) - A(\mathbf{\eta})\right]
$$
...
正式地，如果不存在 $\mathbf{\eta} \in \mathbb{R}^k，则我们称指数族为 最小 \setminus \\{ 0 \\} $ 使得 $\mathbf{\eta}^\intercal\mathcal{T}(\mathbf{x}) = 0$。
...
然后，书中给出了伯努利分布的一个例子。
伯努利
伯努利分布可以以指数族形式写出如下：
$$
\begin{align}
\mathrm{Ber}(x|\mu) &amp;= \mu^x(1-\mu)^{1-x} \\\ &amp;= \exp[x \log(\mu) + (1 − x) \log(1 − \mu)] \\\ &amp;= \exp[\mathcal{T}(x)^\intercal\mathbf{\eta}]
\end{align}
$$
其中 $\mathcal{T}(x) = [\mathbb{I}(x=1),\mathbb{I}(x=0)]$ 且 $\mathbf{\eta} = [\log(\mu),\log(1-\mu)]$。然而，这是一个过完备的表示，因为特征之间存在线性依赖关系。我们可以看到如下情况：
$$
\mathbf{1}^\intercal\mathcal{T}(x) = \mathbb{I}(x=1) + \mathbb{I}(x=0) = 1
$$
然后，本书继续。如果表示是过完备的，$\mathbf{\eta}$ 就不唯一可识别。通常使用最小表示，这意味着存在与分布相关联的唯一 $\mathbf{\eta}$。
问题
在伯努利情况下，为什么特征 $\mathcal{T}(x)$ 是线性相关的？
是否有 $\mathbf{\eta}$ 的示例，其中它们的表示不是唯一的？
为什么与分布相关联的唯一 $\mathbf{\eta}$ 很重要。]]></description>
      <guid>https://stats.stackexchange.com/questions/654371/minimal-and-overcomplete-exponential-families</guid>
      <pubDate>Sat, 14 Sep 2024 15:14:12 GMT</pubDate>
    </item>
    <item>
      <title>从正态分布尾部抽样</title>
      <link>https://stats.stackexchange.com/questions/654355/sampling-from-tail-of-normal-distribution</link>
      <description><![CDATA[在 Marsaglia 的这篇 1963 年论文中，描述了从正态分布尾部采样的以下方法。有人能帮我从数学上解释一下为什么 U1 的密度在 (1) 条件下是上一段中所述的，以及为什么 X 的密度是标准正态密度的倍数吗？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654355/sampling-from-tail-of-normal-distribution</guid>
      <pubDate>Sat, 14 Sep 2024 09:39:00 GMT</pubDate>
    </item>
    <item>
      <title>关于双重稳健估计的假设</title>
      <link>https://stats.stackexchange.com/questions/654344/assumption-about-doubly-robust-estimator</link>
      <description><![CDATA[设 $X, Y$ 为两个独立的非负连续随机变量。设 $R :=I(X &lt; Y)$。设 $Z$ 为任意随机变量。假设 $X\perp Y \mid Z$。
可以将 $R$ 视为缺失变量指标。如果 $R=1$，即 $I(X &lt; Y) = 1$，我们观察到 $X$，否则我们不会观察到 $X$。
设 $\pi^*(Z) = P(R=1\mid Z)$，且 $h^*(Z) = E(X\mid R=1, Z)$。设 $\pi(Z),h(Z)$ 为 $Z$ 的任意函数。考虑以下数量
$$
E\left(\left\{\frac{R - \pi(Z)}{\pi(Z)}\right\} [X - h(Z)]\right),
$$
众所周知，在条件$X\perp R\mid Z$下，当$\pi(Z) = \pi^*(Z)$或$h(Z) = h^*(Z)$时，该数量等于$0$。
但是，如果我们只有$X\perp Y \mid Z$呢？我们仍然具有相同的属性吗？有一件事我很确定，那就是 $X\perp Y \mid Z$ 并不意味着 $X\perp R\mid Z$。]]></description>
      <guid>https://stats.stackexchange.com/questions/654344/assumption-about-doubly-robust-estimator</guid>
      <pubDate>Fri, 13 Sep 2024 22:28:02 GMT</pubDate>
    </item>
    <item>
      <title>仅具有一个连续预测变量和一个小样本量的二元逻辑回归：如何测试线性？</title>
      <link>https://stats.stackexchange.com/questions/654296/binary-logistic-regression-with-only-one-continious-predictor-and-a-small-sample</link>
      <description><![CDATA[我有一个包含 10 个数据点的拟合二元模型。单个连续变量位于 [2.4, 4.4] 区间，有一个二元输出变量 Y。Y 包含 4 个 Y=1 的事件和 6 个 Y=0 的事件。在避免完全分离的情况下，建模效果很好。我使用了 Python。
我读过许多论文，其中指出需要检查逻辑回归的假设（(1)线性：线性预测器是否正确？，(2) logit 变换是将协变量与条件均值联系起来的正确函数，以及 (3) 方差是伯努利）。
我的问题如下：
只有一个预测器，如果有必要，检查线性的最佳方法是什么？我可以使用经典的 GOF 测试来做到这一点吗？它们基本上只是测试是否存在我遗漏的非线性或相互作用？
如果您需要有关我的模型的更多信息，请告诉我！]]></description>
      <guid>https://stats.stackexchange.com/questions/654296/binary-logistic-regression-with-only-one-continious-predictor-and-a-small-sample</guid>
      <pubDate>Thu, 12 Sep 2024 22:12:20 GMT</pubDate>
    </item>
    <item>
      <title>现实世界中的数据在统计意义上是“抽样的”吗？</title>
      <link>https://stats.stackexchange.com/questions/654255/are-data-in-the-real-world-sampled-in-the-statistical-sense</link>
      <description><![CDATA[在机器学习中，通常假设样本是根据某种概率分布独立同分布生成的。关于独立同分布假设在统计学习中的重要性
基本假设是存在某种分布/pdf/cdf/pmf $f_X$ 并且 $f_X$ 可以采样。
$$X \sim f_X(x)$$
我的问题很简单，即这个数学假设如何模拟我们在现实世界中的经验或数据科学和机器学习中产生的应用。
当我们说样本是从分布中抽取的，这在现实世界中意味着什么？
例如，如果我想对猫和狗的图片进行分类，我会通过拿出我的 iphone 16 并拍摄一些猫和狗的照片来生成我的数据集。
我看不出按下我的 iphone 上的按钮这个简单动作如何等同于从某个概率分布中进行采样的过程。
我可以使用概率分布$f_X$在数学上描述相机的动作吗？不。我甚至梦想写下与猫或狗图像相关的概率密度函数$f_X$吗？不可能。除了最简单/最琐碎的数据集外，概率分布 $f_X$ 的存在对于所有数据集都是可疑的。
那么机器学习中试图建模的抽样假设是什么？为什么不从“假设我们有一些示例的数据集”开始，并省略抽样假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/654255/are-data-in-the-real-world-sampled-in-the-statistical-sense</guid>
      <pubDate>Thu, 12 Sep 2024 09:19:04 GMT</pubDate>
    </item>
    <item>
      <title>通过python进行线性混合效应模型分析</title>
      <link>https://stats.stackexchange.com/questions/654156/linear-mixed-effect-model-analysis-via-python</link>
      <description><![CDATA[我想对我的研究进行线性混合效应分析。我试图了解和比较 3 种不同的干预模式对结果的影响。我对结果有 2 个衡量指标，即事前分析和事后分析。
我使用 Python 代码，但当我将其与 SPSS 结果进行比较时，结果大不相同。我想知道我是否使用了正确的代码。
这是我的变量
DV：ACC
IV：组（3），时间（2）
协变量：性别，年龄，受教育年限。
性别，组和时间是分类变量。
我使用了下面的代码
model = smf.mixedlm(
&quot;ACC ~ C(Time) * C(Group) + Age + C(Sex) + Education years&quot;, 
data, 
groups=data[&quot;ID&quot;]
)
result = model.fit()

您觉得如何？我应该做些改变吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654156/linear-mixed-effect-model-analysis-via-python</guid>
      <pubDate>Tue, 10 Sep 2024 13:34:28 GMT</pubDate>
    </item>
    <item>
      <title>我该如何从“杠杆效应”的角度解释下面的 GJR-GARCH 模型？</title>
      <link>https://stats.stackexchange.com/questions/612999/how-can-i-interpret-the-below-gjr-garch-model-in-terms-of-leverage-effects</link>
      <description><![CDATA[我是这里的新手，很难解释该模型。请用通俗易懂的语言帮助我。
 AR - GJR-GARCH 模型结果 
==================================================================================================
Dep. 变量：GD R 平方：-0.003
均值模型：AR Adj。 R 平方：-0.004
Vol 模型：GJR-GARCH 对数似然：-3572.12
分布：标准化学生 t AIC：7168.24
方法：最大似然 BIC：7236.93
观测数：2261
日期：2023 年 4 月 15 日星期六 Df 残差：2257
时间：07:18:04 Df 模型：4
均值模型
========================================================================================
coef std err t P&gt;|t| 95.0% Conf.整数
-----------------------------------------------------------------------------------------
常数 0.0688 2.281e-02 3.017 2.555e-03 [2.411e-02, 0.114]
GD[1] -0.0134 2.114e-02 -0.635 0.526 [-5.485e-02,2.801e-02]
GD[2] -0.0327 2.011e-02 -1.626 0.104 [-7.210e-02,6.716e-03]
GD[3] 6.0716e-03 1.971e-02 0.308 0.758 [-3.255e-02,4.470e-02]
波动率模型
=====================================================================================
coef std err t P&gt;|t| 95.0% Conf. Int.
-----------------------------------------------------------------------------------------
omega 0.1078 4.361e-02 2.473 1.341e-02 [2.236e-02, 0.193]
alpha[1] 0.0322 1.903e-02 1.691 9.074e-02 [-5.108e-03,6.947e-02]
alpha[2] 4.1672e-14 1.602e-02 2.602e-12 1.000 [-3.139e-02,3.139e-02]
gamma[1] 0.0394 2.891e-02 1.364 0.172 [-1.722e-02,9.611e-02]
gamma[2] 0.1528 3.636e-02 4.202 2.651e-05 [8.151e-02, 0.224]
beta[1] 9.4508e-03 4.481e-02 0.211 0.833 [-7.837e-02,9.727e-02]
beta[2] 0.7992 5.555e-02 14.386 6.313e-47 [ 0.690, 0.908]
分布
===============================================================================
coef std err t P&gt;|t| 95.0% Conf. Int.
------------------------------------------------------------------------------------
nu 5.2877 0.574 9.215 3.121e-20 [ 4.163, 6.412]
===============================================================================

我在网上读了很多文章或论文，得出以下结论。但不确定我是否正确。
这里，gamma[1] 的 p 值为 0.172（大于 0.05），因此 gamma[1] 在统计上不显著，我们无法得出存在显著杠杆效应的结论。
但是，gamma[2] 的 p 值小于 0.05，表明 gamma[2] 具有统计显著性。
因此，我们可以得出结论，该模型已经捕获了显著的杠杆效应。
此外，我想编写一个通用代码，其中包含所有场景，例如，

如果 gamma[1] 为 +ve 而 gamma[2] 为 -ve，该怎么办？
如果模型中有 n 个 Gamma，那么我可以采用相同的方法吗？
如果我们有 n 个 Gamma，并且它们是 +ve 和 -ve 的组合，那么我们如何得出结论？
]]></description>
      <guid>https://stats.stackexchange.com/questions/612999/how-can-i-interpret-the-below-gjr-garch-model-in-terms-of-leverage-effects</guid>
      <pubDate>Sat, 15 Apr 2023 07:48:42 GMT</pubDate>
    </item>
    </channel>
</rss>