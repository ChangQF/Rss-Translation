<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 15 Dec 2024 12:32:49 GMT</lastBuildDate>
    <item>
      <title>箱线图是否假设区间数据？</title>
      <link>https://stats.stackexchange.com/questions/658750/does-a-boxplot-assume-interval-data</link>
      <description><![CDATA[箱线图是否假设区间数据？如果不是，那么使用箱线图来表示李克特量表（序数）数据可以吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658750/does-a-boxplot-assume-interval-data</guid>
      <pubDate>Sun, 15 Dec 2024 11:48:10 GMT</pubDate>
    </item>
    <item>
      <title>如何计算文本 2 中文本 1 的单词出现的次数？</title>
      <link>https://stats.stackexchange.com/questions/658749/how-do-i-count-the-occurrences-of-words-of-text-1-in-text-2</link>
      <description><![CDATA[我是新来的，英语不是我的母语，所以如果造成任何混淆，我提前道歉。
长话短说，我正在做一项关于学校如何传递知识的博士研究，在这个阶段，我试图弄清楚学习教科书如何有助于考试，然后了解为什么有些学生即使花了几个小时学习教科书，成绩仍然很差，以及这种复习方法在哪个年级失效了。
因此，我试图将试卷中的文本与教科书中的文本进行比较。我想知道试卷中有多少单词直接来自教科书，即文本 1 中有多少单词与文本 2 中的单词相同。理想情况下，结果将如下所示：
文本 1 中的单词出现在文本 2 中：
生日——2 次
姐妹——4 次
... 等等。
我以为已经有某种 AI 助手可以完成这样的任务，但到目前为止我的搜索都是徒劳的。所以我想知道是否有任何方法可以进行这样的比较？非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658749/how-do-i-count-the-occurrences-of-words-of-text-1-in-text-2</guid>
      <pubDate>Sun, 15 Dec 2024 11:25:59 GMT</pubDate>
    </item>
    <item>
      <title>具有低 R 平方和负对数似然的 EGARCH 模型</title>
      <link>https://stats.stackexchange.com/questions/658746/egarch-model-with-low-r-squared-and-negative-log-likelihood</link>
      <description><![CDATA[我对编码不是很有经验，一直在研究我在 GitHub 上找到的一个模型，以估计标准普尔 500 指数的波动性。该代码实现了 EGARCH(1,1) 模型，但我注意到 R 平方相当低，对数似然为高度负值，这表明该模型表现不佳。
我想知道是否有人可以帮助改进模型或提供建议以使其更具功能性。具体来说，如果有人能分享更强大的实现或修改来改善模型的性能指标，我将不胜感激。
以下是问题的简要概述：
数据集：标准普尔 500 指数每日回报和 VIX 数据。
问题：R 平方低且对数似然非常负。
目标：增强模型的解释能力和预测准确性。
import pandas as pd
import numpy as np
import yfinance as yf
from arch import arch_model
import statsmodels.api as sm
import matplotlib.pyplot as plt

# 从 Yahoo Finance 下载标准普尔 500 指数和 VIX 数据
sp500 = yf.download(&#39;^GSPC&#39;, start=&#39;2000-01-01&#39;, end=&#39;2021-09-01&#39;, progress=False)
vix = yf.download(&#39;^VIX&#39;, start=&#39;2000-01-01&#39;, end=&#39;2021-09-01&#39;, progress=False)

# 计算标准普尔 500 指数的每日收益
sp500[&#39;SP500_Returns&#39;] = 100 * sp500[&#39;Adj Close&#39;].pct_change().dropna()

# 计算已实现方差（平方收益）
sp500[&#39;Realized_Variance&#39;] = sp500[&#39;SP500_Returns&#39;]**2

# 合并标准普尔 500 收益和 VIX 数据
# 更改为合并 vix 的日期列，而不是索引。重置 vix 的索引以获取日期列。
data = pd.merge(sp500, vix.reset_index()[[&#39;Date&#39;, &#39;Adj Close&#39;]], on=&#39;Date&#39;, how=&#39;inner&#39;)
data.columns = [&#39;Date&#39;, &#39;Open&#39;, &#39;High&#39;, &#39;Low&#39;, &#39;Close&#39;, &#39;Adj Close&#39;, &#39;Volume&#39;, &#39;SP500_Returns&#39;, &#39;Realized_Variance&#39;, &#39;VIX&#39;]

# 将“日期”输入到指数中
data = data.set_index(&#39;Date&#39;)

# data[&#39;VIX&#39;] = data[&#39;VIX&#39;].shift(1) # 使用滞后 VIX
data = data.dropna()
data[&#39;VIX&#39;] = data[&quot;VIX&quot;]**2

# 拟合 EGARCH(1,1) 模型
egarch_model = arch_model(data[&#39;SP500_Returns&#39;], vol=&#39;EGARCH&#39;, p=1, q=1)
egarch_results = egarch_model.fit()

# 获取 EGARCH 方差估计值
data[&#39;EGARCH_Variance&#39;] = egarch_results.conditional_volatility**2

# 将数据拆分为训练集和测试集
train_data = data.iloc[:-150] # 使用除过去 252 天（大约一年）以外的所有数据进行训练
test_data = data.iloc[-150:] # 使用过去 252 天进行测试

# 模型 1：实际方差与 EGARCH 方差
X1_train = train_data[[&#39;EGARCH_Variance&#39;]]
X1_train = sm.add_constant(X1_train)
y_train = train_data[&#39;Realized_Variance&#39;]

model1 = sm.OLS(y_train, X1_train)
results1 = model1.fit()

# 模型 2：实际方差与 EGARCH 方差和 VIX 水平
X2_train = train_data[[&#39;EGARCH_Variance&#39;, &#39;VIX&#39;]]
X2_train = sm.add_constant(X2_train)

model2 = sm.OLS(y_train, X2_train)
results2 = model2.fit()

# 样本外预测
X1_test = test_data[[&#39;EGARCH_Variance&#39;]]
X1_test = sm.add_constant(X1_test)
y_test = test_data[&#39;Realized_Variance&#39;]

X2_test = test_data[[&#39;EGARCH_Variance&#39;, &#39;VIX&#39;]]
X2_test = sm.add_constant(X2_test)

y_pred_model1 = results1.predict(X1_test)
y_pred_model2 = results2.predict(X2_test)

# 绘制样本外预测值与实际实现方差的关系
plt.figure(figsize=(12, 6))
plt.plot(test_data.index, y_test, label=&quot;Realized Variance&quot;, linewidth=2, color=&quot;black&quot;, alpha=0.7)
plt.plot(test_data.index, y_pred_model1, label=&quot;Model 1 (EGARCH Variance)&quot;, linestyle=&quot;--&quot;, linewidth=2, color=&quot;red&quot;)
plt.plot(test_data.index, y_pred_model2, label=&quot;Model 2 (EGARCH Variance + VIX)&quot;, linestyle=&quot;:&quot;, linewidth=2, color=&quot;blue&quot;)

plt.ylabel(&quot;方差&quot;)
plt.legend()
plt.title(&quot;样本外预测与实际实现方差&quot;)
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/658746/egarch-model-with-low-r-squared-and-negative-log-likelihood</guid>
      <pubDate>Sun, 15 Dec 2024 09:28:48 GMT</pubDate>
    </item>
    <item>
      <title>表 2 谬误与变量选择</title>
      <link>https://stats.stackexchange.com/questions/658745/table-2-fallacy-and-choice-of-variables</link>
      <description><![CDATA[我有几个棘手的问题要问您。
我正在开展一项观察性研究，在使用 weighthem 加权我的数据集后，我使用 g 计算估计了平均治疗效果 (ATE)。下面是我使用的代码：
使用的公式：
Treatment_type_tumor_near_gallbladder ~ age_binary + bmi_binary + 
comorbidities + Segments_treated_per_session_binned + Metastasis_size_at_treatment_mm + 
min_distance_gallblad_mm + stage_binary + Metastasis_location_superficial

混杂因素选择比率：(1) 我从数据集中的所有变量中仅选择了具有临床意义的变量，(2) 我仅使用与结果和暴露高度相关的变量（单变量分析中的 alpha&lt;0.2）来计算 PS。

# 在每个估算数据集中执行 IPW
w.out_model1_ATE &lt;- weightthem(formula, 
data = new_amcore_imputed, 
method = &quot;cbps&quot;, # ebal, cbps, glm, gbm, energy, OptWeight, IPT
estimand = &quot;ATE&quot;,
criterion = &quot;smd.mean&quot;, 
) 

在数字 (bal.tab) 和图形 (love.plot) 上检查平衡后，我使用 g 计算方法估计了 ATE：
# 使用逻辑回归 PS 对 ATE 进行 PS 加权
results_all &lt;- with(model_to_use, 
WeightIt::glm_weightit(log_regression_formula, family = quasibinomial, weightit = model_to_use), cluster = FALSE)

# 计算风险比量表上的 ATE
ATE_all &lt;- lapply(results_all$analyses, function(fit) {
marginaleffects::avg_comparisons(fit, variable = predictors_log_regression,
Comparison = &quot;lnratioavg&quot;) # lnratioavg 这将返回风险比量表上的 ATE。要获取比值比量表上的 ATE，请将比较更改为 &quot;lnoravg&quot;。要获取风险差异量表上的 ATE，请删除比较并取指数。
})

# 汇总结果并总结
ATE_results &lt;- ATE_all |&gt; mice::pool() |&gt; summary(exponentiate = TRUE, conf.int = TRUE) |&gt; mutate(across(where(is.numeric), \(x) round(x, digits = 3)))

# 打印结果
ATE_results

在上面的代码中，我还调整了那些在 PS 估计中未使用的临床显著混杂因素，因为它们与暴露或结果 (alpha&gt;0.2) 没有很强的关联，即性别、ASA 状态和之前的化疗治疗 (log_regression_formula: 并发症 ~ 治疗 + 性别 + ASA + 化疗)。“
这些是结果：



term
contrast
estimate
std.error
statistic
df
p.value
2.5 %
97.5 %




ASA_binary
ln(mean(3) /平均值(&lt;=2))
1.609
0.215
2.210
85514.88
0.027
1.055
2.454


Systemic_treatment_prior_local_treatment
ln(平均值(是) /平均值（无））
1.027
0.240
0.113
69958.72
0.910
0.642
1.644


治疗类型_胆囊附近肿瘤
ln(平均值（MWA）/平均值（切除））
0.537
0.233
-2.668
28006.78
0.008
0.340
0.848


性别
ln(平均值（男性）/平均值（女性））
0.788
0.257
-0.929
49753.64
0.353
0.476
1.303



我有两个问题：

使用 glm_weightit 时，在单变量分析中包含未达到 0.2 alpha 阈值的临床显著变量是否合适，还是最好忽略它们？
阅读 WeightIt 文档中的博客文章后（https://ngreifer.github.io/WeightIt/articles/estimating-effects.html#ref-westreichTableFallacyPresenting2013) 和文章 Westreich et al., 2013 (https://doi.org/10.1093/aje/kws412)，我理解，为了避免表 2 谬误，只有治疗的估计值才应被解释和报告为效果。例如，ASA 状态的相对风险 (RR) 不应以与治疗效果相同的方式解释。我的解释正确吗？

提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/658745/table-2-fallacy-and-choice-of-variables</guid>
      <pubDate>Sun, 15 Dec 2024 09:23:45 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn QuantileRegressor 中 L1 正则化的 alpha 参数是什么</title>
      <link>https://stats.stackexchange.com/questions/658748/what-is-the-alpha-parameter-for-l1-normalization-in-scikit-learn-quantileregress</link>
      <description><![CDATA[scikit-learn Quantile Regression 文档中的 示例 展示了一个将参数 alpha 设置为零的示例。默认值为 1。
文档 QuantileRegressor 显示默认值设置为 1.0。它指出这是一个乘以 L1 惩罚项的正则化常数。
我对 Lasso 是什么或 L1 回归的确切含义没有直观的理解。
参数 alpha 与这些事物的关系是否有直观的解释？
有一篇与分位数回归相关的 维基百科文章，非常详细。浏览此文，在正则化参数的选择部分中，alpha 似乎就是 lambda。它在其他地方也可能被称为t。
我的直觉可能是错的。
到目前为止，我的结论是 alpha 可能只在多维（&gt; 1）回归问题中起作用，它可能用于选择维度的子集，即具有最强统计预测能力的最重要维度？]]></description>
      <guid>https://stats.stackexchange.com/questions/658748/what-is-the-alpha-parameter-for-l1-normalization-in-scikit-learn-quantileregress</guid>
      <pubDate>Sun, 15 Dec 2024 08:40:50 GMT</pubDate>
    </item>
    <item>
      <title>小离散值的分布可视化</title>
      <link>https://stats.stackexchange.com/questions/658744/distributional-visualization-of-small-discrete-values</link>
      <description><![CDATA[对于研究对象，每种测量类型我几乎只得到 40 个小整数计数。计数从零开始，分布高度正偏。参见附图。无需赘述，从样本中可以得出结论，经过测试的、非常简单的测试假设可以肯定地被接受。但是，从这种类型的离散小值数据中可视化分布体有什么合适的方法吗？在图像中，我添加了 ggplot2 R 包中的典型 geom_boxplot，没有离群值和晶须，以显示中位数、第一和第三四分位数，以帮助理解分布。如果仅显示单个测量值（沿 y 轴略微抖动以缓解视觉分离），它看起来有点不直观的“空洞”。您是否保持 geom_boxplot 合理，或者您可以提出其他建议？

从这里找到了小提琴图表的提议：分析/可视化紧密分组的离散结果]]></description>
      <guid>https://stats.stackexchange.com/questions/658744/distributional-visualization-of-small-discrete-values</guid>
      <pubDate>Sun, 15 Dec 2024 08:39:49 GMT</pubDate>
    </item>
    <item>
      <title>带条件的多元随机正态分布</title>
      <link>https://stats.stackexchange.com/questions/658734/multivariate-random-normal-distribution-with-conditions</link>
      <description><![CDATA[我正在开发一个模拟模型，该模型将作为对实证考古数据进行分类的基础。我正在使用 R 语言，并使用有界版本的 mvrnorm() 来模拟 8 个抛射点（即箭头/矛头）尺寸（最大长度、轴向长度、最大宽度等），并使用从实证数据集得出的相关矩阵。然后，模拟数据将遵循文化传播规则，并投射到 n 代，以模拟不同社会学习场景的影响。大多数文物尺寸都具有显著相关性，并且有几个必须具有特定的关系，才能使我的模拟文物逼真。例如，轴向长度不能大于最大长度，因为它们是相同的。我尝试通过添加需要满足​​的条件（包括上限和下限）来调整 mvrnorm 函数。我尝试在模拟期间进行拒绝抽样，并在模拟后进行调整。然而，在这两种情况下，Gen 1 的结果协方差矩阵与我试图在 Gen 1 中复制的原始协方差矩阵相差甚远。我希望找到一个解决方案：1）导致 Gen 1 相关矩阵非常接近我在经验数据中看到的矩阵；2）导致模拟测量值落入经验数据集设定的范围内（最小和最大观测值）；并且 3) 满足实际工件测量的条件。
下面是我尝试在模拟后调整记录的一个例子，这似乎是所有方法中问题最少的，但仍然导致 Gen 1 中的协方差矩阵明显不同：
adjust_simulated_data &lt;- function(data,traits,mu,Sigma,bounds,max_iterations = 10) {
n&lt;-nrow(data)
p&lt;-length(traits)

# 定义要检查的条件
check_conditions&lt;-function(row) {
c(
row[&quot;LengthAxial&quot;]&lt;=row[&quot;LengthMax&quot;],
row[&quot;WidthBasal&quot;]&lt;=row[&quot;WidthMax&quot;],
row[&quot;WidthNeck&quot;]&lt;= row[&quot;WidthMax&quot;],
row[&quot;PSA&quot;] &lt;= row[&quot;DSA&quot;]
)
}

# 对违反条件的单个行进行重新采样
for (iteration in 1:max_iterations) {
licences &lt;- logical(n)

# 检查违规情况
for (i in 1:n) {
row &lt;- data[i, ]
conditions &lt;- check_conditions(row)
if (any(!conditions)) {
licences[i] &lt;- TRUE
}
}

# 如果不存在违规情况，则退出循环
if (!any(violations)) {
message(&quot;All conditions satisfaction after &quot;, iteration, &quot; iterations.&quot;)
break
}

# 对违规行进行重新采样
for (i in which(violations)) {
# 保留非特征列
non_trait_columns &lt;- data[i, !(names(data) %in% characters), drop = FALSE]

# 使用 mvrnorm_bounded 和原始 param_list 值对特征进行重新采样
resampled_traits &lt;- mvrnorm_bounded(
n = 1,
mu = mu,
Sigma = Sigma,
bounds = bounds
)

# 使用重新采样的特征更新数据行
data[i, characters] &lt;- resampled_traits
data[i, !(names(data) %in% characters)] &lt;- non_trait_columns
}
}

# 如果达到最大迭代次数，则发出警告
if (any(!violations) &amp;&amp; iteration == max_iterations) {
warning(&quot;已达到最大迭代次数；可能仍违反某些约束。&quot;)
}

return(data)
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/658734/multivariate-random-normal-distribution-with-conditions</guid>
      <pubDate>Sun, 15 Dec 2024 04:27:32 GMT</pubDate>
    </item>
    <item>
      <title>通过微分矩阵形式推导正规方程</title>
      <link>https://stats.stackexchange.com/questions/658732/deriving-the-normal-equations-by-differentiating-the-matrix-form</link>
      <description><![CDATA[因此，如果我们有 $RSS(\beta) = (\mathbf{y}-\mathbf{X}\beta)^T(\mathbf{y}-\mathbf{X}\beta)$ 并根据 $\beta$ 进行区分，并将其设置为零以最小化它，我们如何得到 $\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta)=0$？
我得到的是 $\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta)+(\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta))^T=0$
并且，只有当 $\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta)$ 的转置与其自身相同时，这才是相同的……这意味着 $\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta)$ 必须是对称的。
但是，为什么会这样呢？我知道这是一个经常出现的基本问题，但我认为基于微积分的统计学和使用线性代数之间存在某种飞跃。我学过一些线性代数，但我仍然无法解决这个问题……它更侧重于空间、投影和正交性，而不是区分矩阵……
但是，它怎么会是对称的呢？因为它是一个 p x 1 向量，甚至不是正方形……我的结果没有任何意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/658732/deriving-the-normal-equations-by-differentiating-the-matrix-form</guid>
      <pubDate>Sun, 15 Dec 2024 03:48:25 GMT</pubDate>
    </item>
    <item>
      <title>估计者的期望</title>
      <link>https://stats.stackexchange.com/questions/658727/expectations-of-estimators</link>
      <description><![CDATA[我正在研究一些面板数据计量经济学主题，我遇到了以下渐近性质：$N \to \infty$:
\begin{equation}
\theta^{\ast} \to \frac{\mathbb{E}(​​\beta_i)}{1 - \mathbb{E}(​​\gamma_i)} 
\quad \text{and} \quad 
\bar{\theta} \to \mathbb{E}\left(\frac{\beta_i}{1 - \gamma_i}\right) = \mathbb{E}(​​\theta_i),
\end{equation&gt;
幻灯片指出，除非$\beta_i$ 和 $\gamma_i$ 是独立分布的。为什么会这样？具体来说，为什么比率的期望值不等于期望值的比率？随机参数分布的独立性在这种差异中起什么作用？原因很简单，因为如果 $\beta_i$ 和 $\gamma_i$ 是独立的随机系数，则联合期望为：$\mathbb{E} (\beta_i) \times \mathbb{E}\left(\frac{1}{1-\gamma_i}\right)$?]]></description>
      <guid>https://stats.stackexchange.com/questions/658727/expectations-of-estimators</guid>
      <pubDate>Sat, 14 Dec 2024 22:35:57 GMT</pubDate>
    </item>
    <item>
      <title>我是否正确推导出加权最小二乘的迭代更新？</title>
      <link>https://stats.stackexchange.com/questions/658722/have-i-correctly-derived-the-iterative-updates-for-weighted-least-squares</link>
      <description><![CDATA[我有一项练习，需要从迭代加权最小二乘更新方程 $b^{(m)} = \left( X^\top W^{(m-1)} X \right)^{-1} X^\top W^{(m-1)} z^{(m-1)}$ 中推导出 $w_i^{(m-1)}$ 和 $z_i^{(m-1)}$，其中 BeetleMortality 数据具有概率单位链接 $\phi$。然后我必须在 R 中实现它。据我所知，$w_i^{(m-1)}=\frac{1}{\text{Var}(Y)} (\frac{\partial \mu_i}{\partial \eta_i}) ^2 = \frac{\phi&#39;(\eta_i)^{(m-1)}}{n\mu_i^{(m-1)}(1 - \mu_i^{(m-1)})}$ 和 $z_i^{(m-1)} = \eta_i^{(m-1)} (y_i -\mu_i) \frac{\partial \eta_i}{\partial \mu_i}= \eta_i^{(m-1)} + \frac{y_i + \mu_i^{(m-1)}}{\phi&#39;(\eta_i)^{(m-1)}}$ 其中 $\phi&#39;$ 是正态分布 PDF。我已经在 R 中实现了这一点，我非常确定实现中的所有内容都是正确的。因此，我相信问题在于我如何得出这些值。我犯了什么错误吗？我对这一切还比较陌生，所以很可能是我犯了一些我无法发现的明显错误。任何反馈都值得赞赏！]]></description>
      <guid>https://stats.stackexchange.com/questions/658722/have-i-correctly-derived-the-iterative-updates-for-weighted-least-squares</guid>
      <pubDate>Sat, 14 Dec 2024 16:41:27 GMT</pubDate>
    </item>
    <item>
      <title>包含 4 个变量的等高线图</title>
      <link>https://stats.stackexchange.com/questions/658747/contour-plot-with-4-variables</link>
      <description><![CDATA[我使用 ggplot 包绘制了以下轮廓图
library(ggplot2)
library(reshape2)

f &lt;- function(x, y) { r &lt;- sqrt(x^2+y^2+8^2+8^2); 10 * sin(r)/r }

x = y = seq(-10, 10, length.out = 30)
z = cbind(data.frame(x), as.data.frame(outer(x, y, f))
names(z) = c(&#39;x&#39;, as.character(y))

z1 = melt(z, id.vars = &#39;x&#39;)
names(z1) = c(&#39;x&#39;, &#39;y&#39;, &#39;z&#39;)
z1$y = as.numeric(as.character(z1$y))

ggplot(z1, aes(x, y, z = z)) + geom_contour() + geom_contour_filled()

虽然只有 2 个独立变量（即 x 和 y）就可以了，但我实际上有一个包含 4 个变量的函数，例如以下
f &lt;- function(x, y, p, q) { r &lt;- sqrt(x^2+y^2+p^2+q^2); 10 * sin(r)/r }

您能指导我是否有办法绘制上述函数的轮廓图吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658747/contour-plot-with-4-variables</guid>
      <pubDate>Fri, 13 Dec 2024 21:55:39 GMT</pubDate>
    </item>
    <item>
      <title>Jeffreys 离散参数空间的先验</title>
      <link>https://stats.stackexchange.com/questions/658678/jeffreys-prior-for-a-discrete-parameter-space</link>
      <description><![CDATA[以下问题涉及二项分布，其概率已知$p$，但试验次数未知$n$。
试验次数的二项置信区间
尝试思考如何为这种情况构建贝叶斯区间，我首先进入了思考 Jeffreys 先验的阶段。但是，对于离散参数空间，这没有定义，因为导数不存在。
是否有根据相同想法找到先验的方法？当然，坐标变换下分布的不变性已经过时，因为概率质量函数不会像概率密度函数那样变换。这是 Jeffreys 先验的唯一属性/动机吗，或者还有其他属性可以应用于概率质量函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/658678/jeffreys-prior-for-a-discrete-parameter-space</guid>
      <pubDate>Fri, 13 Dec 2024 16:07:13 GMT</pubDate>
    </item>
    <item>
      <title>当 $X\sim \operatorname{Beta}(\alpha,\beta)$ 时，$Y=-\log(X)$ 的分布</title>
      <link>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</guid>
      <pubDate>Fri, 13 Dec 2024 11:02:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么不采用这种“矩量法”来估计矩阵正态分布？</title>
      <link>https://stats.stackexchange.com/questions/658659/why-the-matrix-normal-distribution-is-not-estimated-with-this-method-of-moments</link>
      <description><![CDATA[根据维基百科页面，随机矩阵$\bf{X}\in \mathbb{R}^{p\times q}$服从矩阵正态分布$\cal{MN}(\bf M, \bf U, \bf V)$，这意味着
$$ \text{vec}(\bf X) \sim \cal N ( \mathrm{vec} (\bf M), \bf V \otimes \bf U),$$
其中$\bf M \in \mathbb{R}^{p\times q}$, $\bf U \in \mathbb{R}^{p\times p}$, 以及 $\bf V \in \mathbb{R}^{q\times q}$.
假设我们观察到矩阵值数据 $\bf X_1, \dots, \bf X_n$，它们被假定为 $\cal{MN}(\bf M, \bf U, \bf V)$ 的 i.i.d. 实现。然后，MLE 具有估计值 $\hat{\bf M}$ 作为通常的样本均值，并且 $\bf U$、$\bf V$ 由以下迭代过程给出：
$$
\begin{aligned}
\hat{\bf U} = \frac{1}{nq} \sum_{i=1}^n (\bf X_i - \bf M) \hat{\bf V}^{-1} (\bf X_i - \bf M)^\top, \\
\hat{\bf V} = \frac{1}{np} \sum_{i=1}^n (\bf X_i - \bf M)^\top \hat{\bf U}^{-1} (\bf X_i - \bf M)。
\end{aligned}
$$
我理解 MLE 框架，但我想知道为什么这种方法不起作用：请注意，从同一个维基百科页面
$$\begin{aligned}
\bf E[(\bf X - \bf M) (\bf X - \bf M)^\top] = \bf U\, \mathrm{tr}(\bf V), \\
\bf E[(\bf X - \bf M)^\top (\bf X - \bf M)] = \bf V\, \mathrm{tr}(\bf U)。
\end{aligned}$$
由于 $\bf U$ 和 $\bf V$ 无法通过缩放因子进行识别，我们提出附加限制 $\mathrm{tr}(\bf V) = q$。那么，我认为可以这样估计：
$$\begin{aligned}
\hat{\bf U} = \frac{1}{nq} \sum_{i=1}^n (\bf X_i - \bf M) (\bf X_i - \bf M)^\top, \\
\hat{\bf V} = \frac{1}{n\operatorname{tr}(\hat{\bf U})} \sum_{i=1}^n (\bf X_i - \bf M)^\top (\bf X_i - \bf M)。
\end{aligned}$$
但是，第二种方法与 MLE 不一致。哪里出了问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658659/why-the-matrix-normal-distribution-is-not-estimated-with-this-method-of-moments</guid>
      <pubDate>Fri, 13 Dec 2024 03:43:57 GMT</pubDate>
    </item>
    <item>
      <title>试验次数的二项置信区间</title>
      <link>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</link>
      <description><![CDATA[我有一个过程，其成功概率为已知$p$，失败概率为$q = 1-p$。该过程重复有限但未知的次数$n$。
给定成功次数$r$（失败次数$n-r$，未知），我们应该如何确定导致$r$次成功的试验次数的置信区间？
举一个简单的例子，一枚公平的硬币总共被抛了$n$次，其中150次正面朝上落地。 $n$ 是如何分布的，其平均值的 95% 置信区间是多少，涵盖 $n$ 最可能的值。最可能的$n$ 为 300，最小的$n$ 为 150，最大的$n$ 为无穷大，但我们如何考虑介于两者之间的一切？
注意：如果分布不对称，间隔不必以平均值为中心。

我一直在研究威尔逊分数和其他二项比例置信区间，它们是相关的，但它们估计的是$p$，而不是$n$。我想知道是否存在类似的方法可以实现我所寻找的目标。
由于缺乏一个封闭的估计​​公式，我只能尝试通过拟合两个高斯分布来找到我的置信区间$(n_{low}, n_{high})$的端点，这两个高斯分布的均值为$n_{low}p$和$n_{high}p$，其中$\hat{n}p$（其中$\hat{n} = r/p$是我估计的$n$）落在其 2.5% 面积尾部边界上，使用表格。]]></description>
      <guid>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</guid>
      <pubDate>Thu, 12 Dec 2024 17:08:40 GMT</pubDate>
    </item>
    </channel>
</rss>