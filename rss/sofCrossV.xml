<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 08 Dec 2024 21:15:23 GMT</lastBuildDate>
    <item>
      <title>ROUGE-L 分数示例和相应的 ROUGE-n，其中 n = 最长公共子串的长度</title>
      <link>https://stats.stackexchange.com/questions/658463/rouge-l-score-example-and-the-corresponding-rouge-n-where-n-length-of-longest</link>
      <description><![CDATA[我正在关注这个关于 ROUGE 乐谱的视频，他讲解了ROUGE-1、ROUGE-2 和 ROUGE-L。我可以计算前两个，并确认视频中的答案，但没有给出 ROUGE-L 的答案。



这是计算 ROUGE-L 的正确方法吗？

precision = 1/3
召回率 = 1/5
ROUGE-L (F1 分数) = (2 * 1/3 * 1/5) / (1/3 + 1/5) = 2/8 = 0.25

（假设上述 ROUGE-L 值正确）由于最长公共子串是二元组，ROUGE-L 与 ROUGE-2 = 0.33（视频中显示）相比如何？哪一个是更好的指标？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658463/rouge-l-score-example-and-the-corresponding-rouge-n-where-n-length-of-longest</guid>
      <pubDate>Sun, 08 Dec 2024 19:53:03 GMT</pubDate>
    </item>
    <item>
      <title>如何在不最大化聚类质心之间距离的情况下执行 k 均值聚类？</title>
      <link>https://stats.stackexchange.com/questions/658461/how-to-perform-k-means-clustering-without-maximising-distance-between-cluster-ce</link>
      <description><![CDATA[K 均值聚类自然地最小化了到每个聚类质心的聚类内距离之和。用过于简单的术语来说，它实现了 $$min \sum_{k=0}^k\sum_{i=0}^n(s_{ik} ) $$，其中 $s_{ik}$ 是从质心 $k$ 到点 $i$ 的距离。

我想引入 $z_k$ 作为聚类质心与假设已知点 Q（标记为紫色）之间的距离，以及 $c$ 作为额外的常数“成本”对于这个距离。

因此，问题变成了 $$min \sum_{k=0}^k\sum_{i=0}^n(s_{ik} + cz_k) $$
我希望 $c$ 充当参数，以调节 k 均值聚类的“不完美”程度。参数越高，聚类质心与 Q 和彼此的距离越近，并且它们与属于这些聚类的点的距离越远。因此，对于非常大的 $c$，我希望质心接近于 Q，而对于非常小的 $c$，我希望质心处于其&quot;正常&quot;聚类平均位置。  如何实现一种通过考虑质心与 Q 之间（或它们之间）的距离来执行不完美聚类的算法？]]></description>
      <guid>https://stats.stackexchange.com/questions/658461/how-to-perform-k-means-clustering-without-maximising-distance-between-cluster-ce</guid>
      <pubDate>Sun, 08 Dec 2024 18:50:18 GMT</pubDate>
    </item>
    <item>
      <title>处理泊松分布中的负数据</title>
      <link>https://stats.stackexchange.com/questions/658460/dealing-with-negative-data-in-a-poisson-distribution</link>
      <description><![CDATA[我正在开发质谱数据缩减软件，在处理泊松分布中的负数据时遇到了问题。
我的主要目标是计算质谱以安培为单位报告的强度测量值$y$的误差。我假设这些误差遵循泊松分布，该分布基于停留时间 $t$ 内计数的电子数 $N$：
$$N = \frac{yt}{q}$$
其中 $q$ 是电子的电荷。
因此，强度 $\sigma_y$ 的误差为
$$\sigma_y = \sqrt{\frac{yq}{t}}$$
计算这些强度的误差应该可以提高曲线拟合的稳健性。
但是，有时 MS 会报告当信号太小而无法测量时，由于放大器偏移，强度会为 负。放大器偏移会从信号中减去，以考虑热噪声、电压漂移等。每个系统的情况都不同。当来自少数计数离子的电流小于放大器偏移时，数据可能会变成非常小的负数（例如 $-1e^{-15}$，其中低信号约为 $1e^{-15}$ 至 $1e^{-12}$，高信号上升至 $1e^{-8}$）。
负数显然与泊松分布不相容，因为您无法计算某事物的负数。虽然这里的理想解决方案显然是修复放大器偏移以不产生负值，但我的软件无论如何都会遇到负强度，因此必须有某种方式来分配它们错误。
纠正放大器偏移是显而易见的解决方案，但是，由于偏移在系统和序列之间有所不同，我不能依赖它。
我看到了一些前进的方法：

为负数据分配 100% 相对误差。感觉很老套。
找到序列中最负的强度，将其值添加到所有其他强度，并将该强度设置为等于机器 epsilon。我过去曾向拒绝这个想法的用户提出过类似的建议（我同意）。因此，我被限制将所有其他强度提高某个数字以强制它们为非负值。

有哪些不同的处理方法可能更强大或数学上更合理？]]></description>
      <guid>https://stats.stackexchange.com/questions/658460/dealing-with-negative-data-in-a-poisson-distribution</guid>
      <pubDate>Sun, 08 Dec 2024 18:43:36 GMT</pubDate>
    </item>
    <item>
      <title>如何分配列中的真实类别以进行分析</title>
      <link>https://stats.stackexchange.com/questions/658453/how-to-assign-the-true-classes-in-a-column-to-proceed-the-analysis</link>
      <description><![CDATA[我想基于两个独立变量 question_type 和 string_lenght 以及一个因变量 response_time 进行双向方差分析。
但我有这个数据集，其中 question_type 列存在问题，我错误地分配了“base_line”值，而不是“sidebyside_base_line”、“sidebyside_color”、“topofeach_color”或“topofeach_base_line”。我该如何解决这个问题，因为您知道唯一可能有帮助的列是 length_string 或 response_time 或 isAnswerCorrect。那么我该如何修复这个问题并分配真实值而不是“base_line”呢？
正如您在图中看到的，每个类别的值数量。

我的目标是用这些行的真实类替换 base_line。 i
我的数据在这里：
https://docs.google.com/spreadsheets/d/16cwLFGaF4KqLvwYNjHIcCyHaWup8vSJpL7gOEqk_XPA/edit?usp=sharing]]></description>
      <guid>https://stats.stackexchange.com/questions/658453/how-to-assign-the-true-classes-in-a-column-to-proceed-the-analysis</guid>
      <pubDate>Sun, 08 Dec 2024 13:59:36 GMT</pubDate>
    </item>
    <item>
      <title>具有多个结果变量的潜在类别线性混合模型与 R 中的 LCMM 的收敛</title>
      <link>https://stats.stackexchange.com/questions/658452/convergence-of-latent-class-linear-mixed-model-with-lcmm-in-r-with-multiple-outc</link>
      <description><![CDATA[我正在寻求帮助，使用 R 中的 LCMM 包 使我的 潜在类别线性混合模型 收敛。
我正在处理一个关于帕金森病认知功能的大型纵向数据集，并试图从 0 到 10 年的数据点中识别认知概况。每年都会进行多项认知测试来评估认知领域。这会产生 8 个独立的结果变量。我的数据集包含 732 名帕金森病患者，其中一些患者在数据点有缺失值。
我正在使用 R 中的 lcmm 包的潜在类别线性混合模型来模拟随时间变化的认知变化。这是模型设置，其中我只包含了 3 个认知变量：
mlclmm_model &lt;- multlcmm(

fixed = DVT_SDM + DVT_TOTAL_RECALL + DVT_SFTANIM ~ YEAR + age,

random = ~ YEAR | PATNO,

subject = &quot;PATNO&quot;,

data = Data_plot,

ng = 1,

maxiter = 200,

link = &quot;linear&quot;

)

这是模型摘要的输出：

一般潜在类混合模型

通过最大似然法拟合

multlcmm(fixed = DVT_SDM + DVT_TOTAL_RECALL + DVT_SFTANIM ~ YEAR +

age, random = ~YEAR | PATNO, subject = &quot;PATNO&quot;, ng = 1, link = &quot;linear&quot;,

data = Data_plot, maxiter = 200)

统计模型：

数据集：Data_plot

受试者数量：732

观察次数：11085

潜在类别数量：1

参数数量：13

链接函数：DVT_SDM 为线性

DVT_TOTAL_RECALL 为线性

DVT_SFTANIM 为线性

迭代过程：

未收敛时达到最大迭代次数

迭代次数：200

收敛标准：参数= 4.8e-08

: 似然= 1.5e-11

: 二阶导数= 1

拟合优度统计：

最大对数似然：-40602.06

AIC：81230.12

BIC： 81289.86 

最大似然估计：

纵向模型中的固定效应：

coef Se Wald p 值

截距（未估计） 0.00000 

YEAR -0.08738 

age -0.02394 

随机效应的方差-协方差矩阵：

（第一个随机效应的方差未估计）

截距 YEAR | PATNOTRUE

截距 1.00000 

YEAR | PATNOTRUE 0.46015 3.24264

DVT_SDM DVT_TOTAL_RECALL DVT_SFTANIM

残差标准误差：1.80111 4.34913 4.04510 

链接函数的参数：

coef Se Wald p 值

DVT_SDM-Linear 1 51.61487 

DVT_SDM-Linear 2 3.70604 

DVT_TOTAL_RECALL-Linear 1 49.70980 

DVT_TOTAL_RECALL-Linear 2 2.37214 

DVT_SFTANIM-Linear 1 55.30213 

DVT_SFTANIM-Linear 2 2.39356

问题：
模型达到了最大迭代次数 (200) 而未收敛。
收敛标准非常小（参数 = 4.8e-8，似然 = 1.5e-11），但仍未实现收敛。
输出报告二阶导数 = 1，这表明可能存在数值稳定性或不可识别性问题。我也尝试过使用更多变量的模型，但这也无法实现收敛。
鉴于我的模型的复杂性，我在收敛方面遇到了困难。此问题的潜在原因可能是什么？是否有任何最佳实践或策略可确保此类模型收敛？我是否应该考虑将参数固定为零（例如样条系数），或者是否有其他方法可以解决这个问题？任何有关提高模型稳定性或改进收敛过程的建议都将不胜感激。我最终想考虑更多的认知变量，而不仅仅是 3 个。]]></description>
      <guid>https://stats.stackexchange.com/questions/658452/convergence-of-latent-class-linear-mixed-model-with-lcmm-in-r-with-multiple-outc</guid>
      <pubDate>Sun, 08 Dec 2024 12:58:50 GMT</pubDate>
    </item>
    <item>
      <title>IV 等级/相关性条件线性代数直觉</title>
      <link>https://stats.stackexchange.com/questions/658451/iv-rank-relevance-condition-linear-algebra-intuition</link>
      <description><![CDATA[考虑以下计量经济模型（IV）：$Y_1 = X&#39;\beta + e$，其中$Y_1 \in \mathbb{R}$是一些感兴趣的结果变量，我们有一组回归量$X = \begin{bmatrix} Z_1 \\ Y_2 \end{bmatrix} \in \mathbb{R}^k$。 ($Z_1 \in \mathbb{R}^{k_1}, Y_2 \in \mathbb{R}^{k_2}, k_1 + k_2 = k \:$) 假设我们可能有一些混杂因素，因此$\mathbb{E}[Xe] \neq 0$。但是假设我们也有一些工具变量$Z=\begin{bmatrix}Z_1\\Z_2 \end{bmatrix} \in \mathbb{R}^{\mathcal{l}}$，使得$\mathbb{E}[Ze] =0, \mathbb{E}[ZZ&#39;]$为psd，并且$\mathbb{E}[ZX&#39;]$的秩为$k$（相关性）。
我对相关性条件很好奇：$\mathbb{E}[ZX&#39;]$的秩必须为$k$。我可以理解这里与 $Cov(X, Z)$ 的联系，但我只是不太清楚为什么秩条件意味着这一点（与 $Z$ 变换对 $X$ 列的作用有关），以及这在某种意义上必须“保留”至少 $X$ 维度才能相关。
此外，在我看来，这似乎与原始 OLS 案例中的秩条件有些相关：$\hat{\beta} = (X&#39;X)^{-1}X&#39;Y_1$，其中秩也必须是 $k$（这次我们希望我们的回归量是线性独立，每个都“提供新的东西”）。这再次将$\beta$的最简单形式概括为$\frac{Cov}{Var}$。（这里的$Var(X)$和$(X&#39;X)$之间有什么联系？）。
总而言之，我缺少一些几何直觉，无法理解这些变换如何告诉我们空间中不同变量的方差/协方差。我一直在尝试复习一些线性代数知识，但还是无法理解。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658451/iv-rank-relevance-condition-linear-algebra-intuition</guid>
      <pubDate>Sun, 08 Dec 2024 11:34:47 GMT</pubDate>
    </item>
    <item>
      <title>一些软件将时间序列数据转换为持久同源性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658450/some-software-s-to-convert-time-series-data-to-persistance-homology</link>
      <description><![CDATA[目前我正在研究拓扑数据分析。我是一个完全的初学者。我正在尝试将时间序列数据转换为持久性同源性和景观。有哪些管道和软件可以做到这一点？
我可以用 python 和 R 做到这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658450/some-software-s-to-convert-time-series-data-to-persistance-homology</guid>
      <pubDate>Sun, 08 Dec 2024 11:32:16 GMT</pubDate>
    </item>
    <item>
      <title>在多输出回归中设置加权 MSE 权重的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/658449/what-is-the-best-way-to-set-weights-for-weighted-mse-in-multi-output-regression</link>
      <description><![CDATA[我正在研究一个回归任务，目标是从给定的输入预测 6 个标量输出值。输入由衰减信号数据组成，输出是信号方程的参数。
最初，我认为这将是一项简单的任务。我的第一种方法是训练一个具有 6 个输出节点的简单 MLP。但是，我遇到了一个问题，即 6 个参数的尺度相差很大。
为了解决这个问题，我尝试使用加权 M​​SE 损失，其中权重设置为标签中每个参数的平均值的倒数。不幸的是，这种方法的表现始终不如为每个参数单独训练 6 个独立的（小得多）网络。当我使用不带权重的标准 MSE 损失时，结果更糟。
我还考虑过根据训练数据集对输出标签进行规范化并将其用于推理。但是，它不是可以推广的（抱歉，找不到更好的词）。
在这种情况下，有什么有效的方法可以尝试吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658449/what-is-the-best-way-to-set-weights-for-weighted-mse-in-multi-output-regression</guid>
      <pubDate>Sun, 08 Dec 2024 11:31:34 GMT</pubDate>
    </item>
    <item>
      <title>即使在标准化之后，K 均值聚类仍然过于强调单个变量：如何纠正？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658448/k-means-clustering-is-giving-too-much-emphasis-on-a-single-variable-even-after-n</link>
      <description><![CDATA[即使在基于两个变量的 z 分数进行聚类的情况下，K 均值聚类的结果也主要基于单个变量。我真的不明白为什么下面散点图右下角的点不属于同一组。
问题是：我应该使用另一种聚类算法，还是应该调整 Kmeans（给我的数据添加一定的权重？怎么做？）？
谢谢，
编辑：聚类数任意高，以查看是否发生沿 zscore(C) 的分区。事实证明，Christian Hennig 是对的，在检查了代码后，问题得到了解决（原始数据仍然在标准化值旁边的向量中，我猜这搞乱了整个过程）。感谢您的回答。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658448/k-means-clustering-is-giving-too-much-emphasis-on-a-single-variable-even-after-n</guid>
      <pubDate>Sun, 08 Dec 2024 11:15:20 GMT</pubDate>
    </item>
    <item>
      <title>如何根据连续性校正的卡方检验计算样本量？</title>
      <link>https://stats.stackexchange.com/questions/658456/how-to-calculate-sample-size-based-on-chi-square-test-with-continuity-correction</link>
      <description><![CDATA[
library(stats)
power.prop.test(p1 = .45, p2 = .25, power = .80, sig.level = 0.05, alternative = c(&quot;two.sided&quot;), strict = FALSE)

双样本比例功效计算比较 

n = 88.0928
p1 = 0.45
p2 = 0.25
sig.level = 0.05
power = 0.8
alternative = two.sided

为什么我的样本量计算与这篇 NEJM 发表的论文中的不同？
为什么 prop.power.test 函数计算功率时没有 Yates 连续性校正？但 prop.test 实现了此校正？

我可以使用这个在线计算器获得与本文相同的结果。可能是什么原因？我可以在 r 中获得这个结果吗？
非常感谢你的帮助！！！！
在线计算器：https://homepage.univie.ac.at/robin.ristl/samplesize.php?test=proptest]]></description>
      <guid>https://stats.stackexchange.com/questions/658456/how-to-calculate-sample-size-based-on-chi-square-test-with-continuity-correction</guid>
      <pubDate>Sun, 08 Dec 2024 09:39:29 GMT</pubDate>
    </item>
    <item>
      <title>我可以在 Cox PH 中使用年龄作为随时间变化的协变量吗？</title>
      <link>https://stats.stackexchange.com/questions/658439/can-i-use-age-as-a-time-varying-covariate-in-a-cox-ph</link>
      <description><![CDATA[我正在研究叛乱团体领导人在被迫下台之前会掌管叛乱团体多长时间。我有领导人年份数据，其中包含以下变量：

groupid = 每个团体的唯一 ID 号
leaderid = 每个领导人的唯一 ID 号
tenure = 领导人首次掌权以来的时间（从 0 开始计数）
forcedexit = 领导人被迫下台时取值为 1，其他年份取值为 0
groupage = 团体成立以来的时间（从 0 开始计数）

我的数据集中，叛乱团体活跃的每一年都有一行。数据通常如下所示：
 groupid leaderid forcedexit tenure groupage
&lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 411 1 0 0 0
2 411 1 0 1 1
3 411 1 0 2 2
4 411 2 1 0 3
5 411 2 0 1 4
6 411 2 0 2 5
7 411 2 0 3 6
8 411 3 0 0 7
9 411 3 0 1 8
10 411 3 0 2 9

请注意，新领导人可以通过强制退出以外的方式上台，因此即使 forcedexit = 0，领导人也可能离职（例如，参见上述数据中的 leaderid = 3）。
我想测试一下在较老的群体中，领导人是否更难被罢免。我的直觉是运行 Cox PH 模型（我使用的是 R）：
mod &lt;- coxph(Surv(tenure, forcedexit) ~ groupage, data = df)
如果我运行这个，我会得到 groupage 系数的负且显著的估计值，这与我的直觉一致。但是，出于两个原因，我对这个结果持谨慎态度。
首先，我可以在 Cox PH 中使用 groupage 作为随时间变化的变量吗？我读过的大多数使用 Cox PH 的医学研究都使用不会随时间变化的年龄变量（例如，试验开始时的年龄）。我的 groupage 变量确实会随时间而变化。
其次，我担心 groupage 和 tenure 变量之间的关系会出现一些问题。某些 tenure 值在 groupage 的某些值下不可能存在。例如，tenure = 5 和 groupage = 0 永远不可能存在，因为组必须存在，领导者才能负责该组。因此，较高的 groupage 值可能与较高的 tenure 值一起机械地出现。如果领导者拥有较大的 tenure，则 groupage 也必须较大。
对这两个问题的任何想法都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658439/can-i-use-age-as-a-time-varying-covariate-in-a-cox-ph</guid>
      <pubDate>Sun, 08 Dec 2024 05:02:32 GMT</pubDate>
    </item>
    <item>
      <title>适合的统计检验</title>
      <link>https://stats.stackexchange.com/questions/658420/suitable-statistical-test</link>
      <description><![CDATA[我有 2 个组 - 曾经在我的网站上活跃的人和从未活跃的人。活动是基于某些操作的指标 - 两组人都访问了网站。
每个组在网站上的第一周使用了一组功能（它是一种平台，人们是用户），我想知道哪些功能与“变得活跃”相关。
例如：
100 个活跃的人中有 20 个在该组中使用了功能 A 100 次，而总共使用了 3000 次功能。
在 50 位从未活跃过的用户中，有 3 位使用了功能 A，总共使用了 1500 次。



曾活跃
功能
使用的帐户
帐户总数
使用的功能
功能总使用量




1
A
20
100
100
3000


0
A
3
50
20
1500



我还可以添加特征使用情况的方差和标准差。
我可以在这里做什么测试来表明使用特征 A 的人与活跃度的相关性明显更高？
此外，它对账户比例本身进行任何测试并使用该测试来声称特征 A 与活跃度显著相关是否有意义？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658420/suitable-statistical-test</guid>
      <pubDate>Sat, 07 Dec 2024 18:45:42 GMT</pubDate>
    </item>
    <item>
      <title>如何计算这个替代方案的密度？</title>
      <link>https://stats.stackexchange.com/questions/658289/how-to-compute-the-density-of-this-alternate-proposal</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658289/how-to-compute-the-density-of-this-alternate-proposal</guid>
      <pubDate>Thu, 05 Dec 2024 00:15:38 GMT</pubDate>
    </item>
    <item>
      <title>具有局部二次估计的函数导数的交叉验证带宽</title>
      <link>https://stats.stackexchange.com/questions/658285/cross-validated-bandwidth-for-the-derivative-of-the-function-with-local-quadrati</link>
      <description><![CDATA[我正在尝试非参数化地估计函数 g(x) 的一阶导数。我正在使用局部多项式（二次）程序估计 $g(x)$。我知道如何计算 $g(x)$ 的留一交叉验证带宽，但是，我想要做的是直接估计 $g’(x)$ 的交叉验证带宽。我的猜测是，导数的最佳带宽不一定与 $g(x)$ 的最佳带宽相同，因此 $g(x)$ 的交叉验证实际上不是我应该做的。但是，我还没有找到任何关于如何对 $g’(x)$ 进行交叉验证带宽的资料，这要困难得多，因为我没有与 $Y_i$ 等效的导数。
有关于如何做到这一点的资源吗？任何 R、Python 或 Stata 中的实现也将不胜感激！
到目前为止，我正在实施 Fan 和 Gijbels (1995) RSC 标准，但感觉它不如适当的交叉验证那么充分（特别是因为从原始带宽到导数带宽的路径仅由预定的调整常数驱动）。也许我可以在交叉验证中使用相同的调整常数？但这感觉“太简单了”。
当我对函数（而不是导数）使用交叉验证或 RSC 或经验法则（来自 Fan 和 Gijbels，1996）时，我得到的带宽通常“太小”，因为导数太不稳定。我尝试了模拟数据，结果总是比建议的带宽大得多。但我想用“科学”标准来证明我的选择，而不是挥手......
PS：我也尝试了 R 中的 locfit 包，默认情况下它实现了自适应带宽（使用最近邻算法，我猜是取 70% 的最近邻居并据此确定自适应带宽，但我不太确定）。如果我也能找到“最佳”的最近邻居数量，我会没问题的。]]></description>
      <guid>https://stats.stackexchange.com/questions/658285/cross-validated-bandwidth-for-the-derivative-of-the-function-with-local-quadrati</guid>
      <pubDate>Wed, 04 Dec 2024 22:47:00 GMT</pubDate>
    </item>
    <item>
      <title>修正二项式 GLMM 以反映物种出现的时间趋势</title>
      <link>https://stats.stackexchange.com/questions/658211/correct-binomial-glmm-for-temporal-trends-in-species-occurrences</link>
      <description><![CDATA[我有一个包含 80 个物种的数据集，这些物种是在两个时间段（历史/最近）从大约 120 个水体中采样的。仅考虑每个水体中物种的存在/不存在。长格式的数据如下所示：
water_no_name 物种 成功时间 
水体 1 物种 A 0 t1 
水体 2 物种 A 0 t1 
水体 3 物种 A 1 t1 
水体 4 物种 A 0 t1 
水体 5 物种 A 0 t1 
水体 1 物种 A 1 t2 
水体 2 物种 A 0 t2 
水体 3 物种 A 0 t2 
水体 4 物种 A 0 t2 
水体 5 物种 A 0 t2 
水体 1 物种 B 1 t1 
水体 2 物种 B 0 t1 
水体 3 物种 B 0 t1 
水体 4 物种 B 1 t1 
水体 5 物种 B 1 t1 
水体 1 物种 B 1 t2 
水体 2 物种 B 0 t2 
水体 3 物种 B 1 t2 
水体 4 物种 B 1 t2 
水体 5 物种 B 0 t2 

我想检查哪些物种的频率随时间显著增加或减少。
因此，我决定使用水体（= 地点）作为随机因素来计算二项式 GLMM，以解释重复测量设计。
我不确定这两种方法中的哪一种更合适：
1) 为每个物种计算单独的 GLMM：
mod &lt;- glmer(success ~ time + (1 | water_no_name), family = binomial)
使用这种方法，我将对物种数量进行 p 值校正 (FDR)。
2) 使用时间和物种之间的相互作用计算所有物种的组合 GLMM：
mod &lt;- glmer(success ~ time * species + (1 | water_no_name), family = binomial)
为了分析相互作用，我将使用这种方法进行事后分析，以查看对比 t1/t2 对哪些物种有意义：
emmeans(mod, pairwise ~ time |物种)
在计算这两种模型时，结果大致相似，但计数较低的物种会有一些差异。
我理解，一个主要的区别是，复杂模型 (2) 对所有物种使用相同的随机位点效应，而使用单独的模型 (1) 我会为每个物种获得不同的随机位点效应（参见 几个单物种 GLMM -&gt; 一个多物种 GLMM（随机效应语法？））
我仍然不确定哪种方法更适合我的情况。我发现更简单的方法 (1) 更直观地解释，也足以回答我的问题。我也不确定是否应该让所有物种都具有随机站点效应。
有人能给我建议我应该选择哪种方法吗？
或者你推荐另一种方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/658211/correct-binomial-glmm-for-temporal-trends-in-species-occurrences</guid>
      <pubDate>Tue, 03 Dec 2024 14:44:29 GMT</pubDate>
    </item>
    </channel>
</rss>