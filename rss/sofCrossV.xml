<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 28 Jun 2024 01:04:33 GMT</lastBuildDate>
    <item>
      <title>3 种随机治疗中的 2 种的混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/650081/mixed-effects-model-for-2-out-of-3-random-treatments</link>
      <description><![CDATA[在我的实验中，同一个参与者正在执行面板 1 和面板 2 的组装任务（复杂程度各不相同），并使用三种信息格式中的两种来执行任务（例如，在 A B 和 C 处理中，面板 1 使用 A，面板 2 使用 C）。我试图拟合一个混合效应模型，其中主题是随机效应，但在 R 中得到了奇异拟合误差。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/650081/mixed-effects-model-for-2-out-of-3-random-treatments</guid>
      <pubDate>Thu, 27 Jun 2024 23:09:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么 LASSO 回归会返回非标准化系数</title>
      <link>https://stats.stackexchange.com/questions/650080/why-does-lasso-regression-return-unstandardized-coefficients</link>
      <description><![CDATA[我还有更多与编码问题无关的一般性问题。
为什么 LASSO 回归需要对预测变量进行标准化，但返回的系数却不是标准化的（glmnet 函数 - https://glmnet.stanford.edu/reference/glmnet.html#:~:text=Logical%20flag%20for%20x%20variable%20standardization%2C%20prior%20to,returned%20on%20the%20original%20scale.%20Default%20is%20standardize%3DTRUE.)?
为什么常规回归 (GLM) 不需要这样的标准化？
如何在回归 (LASSO 或 GLM) 中比较系数？也就是说，我怎么能说 beta 1 明显大于 beta 2？]]></description>
      <guid>https://stats.stackexchange.com/questions/650080/why-does-lasso-regression-return-unstandardized-coefficients</guid>
      <pubDate>Thu, 27 Jun 2024 23:03:14 GMT</pubDate>
    </item>
    <item>
      <title>特征选择后，在零模型下 AUC > 0.5</title>
      <link>https://stats.stackexchange.com/questions/650079/auc-0-5-under-null-model-following-feature-selection</link>
      <description><![CDATA[我一直在研究蒙特卡罗模型的输出，该模型模拟疾病风险作为基因型的函数。在没有疾病风险的零模型下，我们有 1000 个病例和 1000 个对照个体。每个个体有 500 个感兴趣的基因座，根据每个基因座的等位基因频率随机分配一个基因型。在这种情况下，基因型和疾病之间唯一可能的关联将是由于随机误差。
然而，当对疾病与基因型以及其他几种机器学习分类器（朴素贝叶斯、神经网络、随机森林）进行逻辑回归时，我们始终发现该零模型下的 AUC &gt; 0.5。如果我们模拟一个包含更少（200）个个体和 50 个站点的简化数据集，则零模型下的 AUC 甚至更大。
我可以理解过度拟合如何导致 AUC &lt; 0.5，但我无法想到一个合理的场景，可以让这个空模型产生 AUC &gt; 0.5。
另一个奇怪的异常是，在没有特征选择（使用 LASSO）的情况下，所有分类器的空模型下的 AUC 约为 0.5。但是，一旦引入特征选择，我得到的 AUC 对所有分类器都 &gt; 0.5。
是否存在某种现象，即过度拟合的“镜像”可以产生这些结果，如果是这样，为什么我只在特征选择之后的分类器中看到它？
如果这很重要，基因型的随机分配和机器学习分类器是在 Mathematica（同事的旧代码）中实现的，而 Lasso 是在 R（与 Mathematica 交互）中执行的，但这不应该有关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/650079/auc-0-5-under-null-model-following-feature-selection</guid>
      <pubDate>Thu, 27 Jun 2024 22:15:18 GMT</pubDate>
    </item>
    <item>
      <title>（威布尔、威布尔+正态）随机向量和的双变量联合分布函数</title>
      <link>https://stats.stackexchange.com/questions/650078/bivariate-joint-distribution-function-for-the-sum-of-weibull-weibullnormal-ra</link>
      <description><![CDATA[我感兴趣的是，想知道为 (Y,W) 生成双变量 JDF 的“最佳”方法，其中 Y=W+G、W~Weibull(a,b,T) 和 G~Gaussian(m,s)。参数为：a=shape、b=scale、T=threshold、m=E(g)、s=Var(g)。我需要形成 copula 吗？还是有更直接的方法？感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/650078/bivariate-joint-distribution-function-for-the-sum-of-weibull-weibullnormal-ra</guid>
      <pubDate>Thu, 27 Jun 2024 22:05:06 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型随机截距的数学预测</title>
      <link>https://stats.stackexchange.com/questions/650074/mathematical-prediction-of-linear-mixed-models-random-intercept</link>
      <description><![CDATA[给定数据$\{(x_{i,j}, y_{i,j})\} \subset \mathbb{R}^2$，其中$i = 1, \ldots, k$ 个类和$j = 1, \ldots, n_i$。线性混合模型为：
\begin{equation*}
y_{i,j} = a + b x_{i,j} + u_i + \epsilon_{i,j}
\end{equation*&gt;
这里 $a \in \mathbb{R}$、$b \in \mathbb{R}$ 为未知常数。 $u_i$ 和 $\epsilon_{i,j}$ 是独立同分布的正态随机变量，具有 $0$ 均值和未知方差 $\sigma_{\epsilon}^2$ 和 $\sigma_{u}^2$。在我们以任何方式通过 lmer 拟合模型后，我们将得到 $a$、$b$、
$\sigma_{\epsilon}^2$ 和 $\sigma_{u}^2$ 的估计值。
给定 $x \in \mathbb{R}$，其预测的数学公式是什么？predict() Function for lmer Mixed Effects Models 之类的帖子似乎没有给出明确的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/650074/mathematical-prediction-of-linear-mixed-models-random-intercept</guid>
      <pubDate>Thu, 27 Jun 2024 19:28:36 GMT</pubDate>
    </item>
    <item>
      <title>可变加权 PCA</title>
      <link>https://stats.stackexchange.com/questions/650073/variable-weighted-pca</link>
      <description><![CDATA[我见过很多“加权 PCA”，但它们实际上都是关于“观察”的。例如，加权主成分分析，如果您有 K 个变量、N 个观察，则权重是一个长度为 N 的向量。
我想知道是否有办法对变量进行加权？即在长度为 N 的向量中放置权重。
如果我们获得协方差矩阵 $\Sigma$，那么我们执行类似 $W \Sigma W$ 的操作（基本上在运行 PCA 之前设置 $\sigma_i \sigma_j \leftarrow \rho_i \rho_j \sigma_i \sigma_j$，然后我们在特征向量上执行 $W^{-1}$ 以恢复原始主成分，这样可以吗？我基本上想用更大的权重“拟合”变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/650073/variable-weighted-pca</guid>
      <pubDate>Thu, 27 Jun 2024 19:15:36 GMT</pubDate>
    </item>
    <item>
      <title>使用置信区间进行最坏情况分析</title>
      <link>https://stats.stackexchange.com/questions/650062/worst-case-analysis-using-confidence-intervals</link>
      <description><![CDATA[我需要说明具有一定置信度的总体最小预期值，但我不确定我是否正确理解了该过程。
假设我有一个具有严格最小要求值的过程。我对该过程进行抽样并得到以下值
19.7; 20.4; 19.6; 17.8; 18.5; 18.9; 18.3; 18.9; 19.5; 21.95

平均值 (19.355) 的 95% 置信区间为 [18.5; 20.21]。
标准差 (1.188) 的 95% 置信区间为 [0.8172; 2.1688]。
这是否意味着我可以 95% 地确定总体的实际分布在置信区间的整个窗口内？换句话说，“最坏情况”是平均值 = 18.5 和标准差 = 2.1688 的分布，因此我在 95% 值下的最低预期值将是 18.5-2*2.1688 = 14.16？
感觉我不知何故将不确定性计算了两倍，但我搞不清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/650062/worst-case-analysis-using-confidence-intervals</guid>
      <pubDate>Thu, 27 Jun 2024 17:01:50 GMT</pubDate>
    </item>
    <item>
      <title>20 世纪或 21 世纪有哪些著名的统计学家没有接受过正规的统计学培训？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650059/who-are-some-famous-statisticians-from-the-20th-or-21th-century-who-didnt-have</link>
      <description><![CDATA[我正在寻找一些对这个领域做出重要贡献的人的例子，但他们最初的培训不是统计学，他们可能是在“工作中”学习的。我对他们最终如何学习统计学的细节很感兴趣。
我排除了 20 世纪之前的几个世纪，因为我猜这个领域当时没有那么复杂，所以可能更容易做出贡献和研究“唾手可得的成果”（但很高兴在这里得到纠正）。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650059/who-are-some-famous-statisticians-from-the-20th-or-21th-century-who-didnt-have</guid>
      <pubDate>Thu, 27 Jun 2024 16:09:52 GMT</pubDate>
    </item>
    <item>
      <title>随机过程的积分</title>
      <link>https://stats.stackexchange.com/questions/650057/integral-of-stochastic-processes</link>
      <description><![CDATA[假设我有一个随机变量$I(t) = \int_0^{t} N(s) e^{\sigma W(s)} ds$，其中$N(s)$是在时间 s 到达的人数（请注意，这不是到时间 s 为止的总到达人数，只是在 s 到达的人数，因此它在每个时间 s 都遵循$ N(s) \sim Poisson(\lambda) $），并且$W(s)$是维纳过程。 $W(s)$ 和 $N(s)$ 是独立的
有没有办法推导出 $I(t)$ 的解析分布？
我发现获取期望和方差是可行的，因为这两个过程是独立的，我想知道是否有可能推导出所有高阶矩并恢复原始分布，或者是否有其他方法可以获得原始分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/650057/integral-of-stochastic-processes</guid>
      <pubDate>Thu, 27 Jun 2024 14:58:39 GMT</pubDate>
    </item>
    <item>
      <title>R 中带抽样权重的分位数回归</title>
      <link>https://stats.stackexchange.com/questions/650071/quantile-regression-with-sampling-weights-in-r</link>
      <description><![CDATA[我正尝试在 R 中实现带抽样权重的分位数回归以进行分析。我知道在 R 中的 lm() 和 glm() 中，使用选项“weights =”无法准确估计标准误差，因此无法准确估计置信区间，因为它假设了精度权重，而应改用 survey 包。但是，我无法从文档中理解这是否也适用于分位数回归的 rq() 命令，因此无法理解 rq() 中的选项“weights=”是否仅假设精度权重。有人知道吗？
我只找到一个资源，将 R 中的分位数回归应用于调查数据：论文“在随机缺失数据的复杂调查中估计回归分位数：在出生体重决定因素中的应用”。它使用以下代码：
mydesign &lt;- svydesign(ids=~mycluster, strata=~mystrata, fpc=~myfpc, 
data=mydata, nest=TRUE, weights=~myweights)
bootdesign &lt;- as.svrepdesign(mydesign, type=&quot;bootstrap&quot;, replicates=100)
fit &lt;- withReplicates(bootdesign, quote(coef(rq(y ~ x, tau=0.5, weights=.weights, 
method=&quot;fn&quot;))))

得到的拟合对象拟合包含估计的回归系数及其引导方差。然后，可以将此对象传递给以下自定义函数以生成
摘要表，包括 p 值：
format.rq.svy &lt;- function(x, rdf) {
V &lt;- attr(x, &quot;var&quot;)
FLAG &lt;- length(V) == 1
se &lt;- if (FLAG) sqrt(V) else sqrt(diag(V))
val &lt;- cbind(as.matrix(x), se, NA, NA)
if (FLAG) val &lt;- matrix(val, nrow=1)
val[, 3] &lt;- val[, 1]/val[, 2]
val[, 4] &lt;- 2*(1 - pt(abs(val[, 3]), rdf))
colnames(val) &lt;- c(&quot;Value&quot;, &quot;Std. Error&quot;, &quot;t value&quot;, &quot;Pr(&gt;|t|)&quot;)
rownames(val) &lt;- names(x)
return(val)
}

其中参数 &quot;rdf&quot; 指定使用 t 分布进行近似 p 值计算的残差自由度（即 n - q）。
我不确定如何指定残差自由度。有没有办法了解我应该指定多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/650071/quantile-regression-with-sampling-weights-in-r</guid>
      <pubDate>Thu, 27 Jun 2024 14:08:50 GMT</pubDate>
    </item>
    <item>
      <title>测试两个（或更多）不同群体之间二元参数比例/分数与连续参数趋势的差异</title>
      <link>https://stats.stackexchange.com/questions/650048/testing-for-difference-in-trends-of-binary-parameter-proportion-fraction-versus</link>
      <description><![CDATA[我有三个对象样本：样本 X（总数 = 138）、样本 Y（与 X 属于同一基本类别，但位于不同的环境中；总数 = 186）和样本 Z（总数 = 996）。对于每个对象，我都有一个测量的连续参数 M 和一个二项式参数 B（检测到或未检测到）。每个样本都可以被视为来自某个（大得多的）潜在总体的随机样本。
这是 B = 1 的对象分数与 M 的关系图（总体 X = 实心红色方块，总体 Y = 空心红色圆圈，总体 Z = 较小的蓝色圆圈）。使用的箱子纯粹是为了显示目的；正如我所提到的，每个对象都有一个单独的 M 测量值，精确到小数点后两位。

似乎很明显，X 和 Y 群体表现出与 Z 群体不同的趋势，并且 X 和 Y 群体表现出相似（但不相同？）的趋势。
我想知道的是：有没有办法量化不同群体趋势之间明显差异或相似性的统计意义？例如，在两个群体在分数（B）与 M 中具有相同的潜在趋势的零假设下，观察到的差异可以用 $P$ 值来描述...？我可以比较样本 X 和 Y 之间的差异吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650048/testing-for-difference-in-trends-of-binary-parameter-proportion-fraction-versus</guid>
      <pubDate>Thu, 27 Jun 2024 12:59:50 GMT</pubDate>
    </item>
    <item>
      <title>$F_X(t) > F_Y(t)$ 是否是 $\mathbb{P}(X < Y) > 0.5$ 的充分必要条件</title>
      <link>https://stats.stackexchange.com/questions/649996/is-f-xt-f-yt-a-sufficient-and-necessary-condition-of-mathbbpx-y</link>
      <description><![CDATA[我在使用 scipy 实现进行 Mann–Whitney U 检验时提出了这个问题。其中一个单侧检验的零假设是 $F_X(t) &gt; F_Y(t)$，其中 $F$ 表示 CDF。我想知道这是否等同于说 $\mathbb{P}(X &lt; Y) &gt; 0.5$，其中$\mathbb{P}(X &lt; Y)$表示来自$X$的随机样本的概率小于来自$Y$的随机样本的概率。]]></description>
      <guid>https://stats.stackexchange.com/questions/649996/is-f-xt-f-yt-a-sufficient-and-necessary-condition-of-mathbbpx-y</guid>
      <pubDate>Wed, 26 Jun 2024 21:46:51 GMT</pubDate>
    </item>
    <item>
      <title>如何对多重插补数据进行统计分析？</title>
      <link>https://stats.stackexchange.com/questions/649970/how-to-conduct-statistical-analysis-on-multiply-imputed-data</link>
      <description><![CDATA[我有一个名为 mydata 的数据框，它有 6 列：status、times、t1、t2、t3、t4。但是，t1、t2、t3 和 t4 在此数据集中包含缺失值。我打算使用 mice 包估算这些缺失值，然后对估算的数据进行统计分析。我需要对我的数据进行的统计分析包括：

基线特征表：使用 gtsummary 包生成 table1。
生存分析：建立 Cox 回归模型。
ROC 曲线：绘制 ROC 曲线。
生存图：绘制生存曲线。

如果使用原始数据集（插补前），这些统计分析的代码如下：
# 基线特征表
library(gtsummary)

tbl1 &lt;- mydata %&gt;%
tbl_summary(by = status) %&gt;%
add_p()
print(tbl1)

# Cox 回归模型
library(survival)
surv_object &lt;- Surv(mydata$times, mydata$status)
cox_model &lt;- coxph(surv_object ~ t1 + t2 + t3 + t4, data = mydata)
summary(cox_model)

# ROC 曲线
library(pROC)
library(ggplot2)
roc_t1 &lt;- roc(mydata$status, mydata$t1)
roc_t2 &lt;- roc(mydata$status, mydata$t2)
roc_t3 &lt;- roc(mydata$status, mydata$t3)
roc_t4 &lt;- roc(mydata$status, mydata$t4)
ggroc &lt;- ggplot() +
geom_roc(data = roc_t1, aes(color = &quot;t1&quot;)) +
geom_roc(data = roc_t2, aes(color = &quot;t2&quot;)) +
geom_roc(data = roc_t3, aes(color = &quot;t3&quot;)) +
geom_roc(data = roc_t4, aes(color = &quot;t4&quot;)) +
geom_abline(slope = 1, interval = 0, linetype = &quot;dashed&quot;) +
labs(title = &quot;ROC 曲线&quot;, x = &quot;假阳性率&quot;, y = &quot;真阳性率&quot;, color = &quot;预测器&quot;) +
theme_minimal()
print(ggroc)

# 生存图
library(survminer)

surv_fit &lt;- survfit(surv_object ~ 1, data = mydata)

ggsurvplot(surv_fit,
data = mydata,
conf.int = TRUE,
pval = TRUE, 
surv.median.line = &quot;hv&quot;,
risk.table = TRUE,
ggtheme = theme_classic())

使用 mice 包执行多重插补后，我获得了 5 个插补数据集。我应该如何生成表 1、Cox 回归、ROC 曲线和生存曲线？
library(mice)
imp_data &lt;- mice(mydata, m = 5, maxit = 50, method = &quot;pmm&quot;, seed = 500)

# Cox 回归模型
???

# ROC 曲线
???

# 生存图
???


在查看各种来源后，我发现了几种方法：

选择其中一个数据集进行后续分析（不推荐）complete_data &lt;- complete(imp_data, 1)
计算五个数据集中每个观测值的平均值或中位数，以获得最终的数据集进行分析。
使用with() %&gt;% pool()总结模型结果。

哪种方法最合适？如果使用with() %&gt;% pool()进行统计分析，我应该如何调整生成表1、ROC曲线和生存曲线的代码，尤其是表1、ROC曲线和生存曲线？]]></description>
      <guid>https://stats.stackexchange.com/questions/649970/how-to-conduct-statistical-analysis-on-multiply-imputed-data</guid>
      <pubDate>Wed, 26 Jun 2024 16:07:03 GMT</pubDate>
    </item>
    <item>
      <title>解释两阶段统计检验问题的引文</title>
      <link>https://stats.stackexchange.com/questions/649761/citations-explaining-the-problems-with-two-stage-statistical-testing</link>
      <description><![CDATA[我正在写一篇关于分析对数正态分布抽样数据的评论，我想解释一下首先运行正态性检验并使用该结果选择运行哪个检验的问题。
首先运行方差相等性检验并使用该结果选择第二个检验也会出现同样的问题。
这种“两阶段”程序（一定有更好的名称）会扭曲第二次检验的结果。
我要求引用一些论文来解释这个问题并举例说明两阶段测试如何产生误导。]]></description>
      <guid>https://stats.stackexchange.com/questions/649761/citations-explaining-the-problems-with-two-stage-statistical-testing</guid>
      <pubDate>Sun, 23 Jun 2024 20:07:09 GMT</pubDate>
    </item>
    <item>
      <title>时间序列符号的最大似然</title>
      <link>https://stats.stackexchange.com/questions/649755/maximum-likelihood-for-time-series-notation</link>
      <description><![CDATA[我正在查看以下幻灯片，其中时间序列的可能性公式为（第 5 页）：
$f(y) = \prod_{i=2}^{n} f_{y_i|y_{i-}}(y_i|y_{i-}) f_{y_1}(y_1)$

我不太清楚下标 $y_i|y_{i-}$ 和 $y_1$ 的用途。有人能解释一下吗？

从我的角度来看，公式应该是：


$L(y;\theta) = \prod_{i=2}^{n} f_{i}(y_i|y_{i-};\theta) f_{1}(y_1)$。
这看起来合理吗？是否可以假设每个项都有不同的条件分布，并且 MLE 会收敛？]]></description>
      <guid>https://stats.stackexchange.com/questions/649755/maximum-likelihood-for-time-series-notation</guid>
      <pubDate>Sun, 23 Jun 2024 16:51:40 GMT</pubDate>
    </item>
    </channel>
</rss>