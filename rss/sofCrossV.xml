<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 03 Aug 2024 01:06:12 GMT</lastBuildDate>
    <item>
      <title>如何确定或显示线性回归的两个解是否不同</title>
      <link>https://stats.stackexchange.com/questions/652235/how-to-determine-or-show-if-two-solutions-to-linear-regression-are-different</link>
      <description><![CDATA[假设我有一个系统，我可以测量它的输入和输出，并且可以以线性回归的形式制定我想要的解决方案：$A \vec{x}=\vec{b}$。进一步假设我已经测量了 $A$ 和 $\vec{b}$ 两次。第一次我测量了所有的东西，$A_1 \in \mathbb{R}^{450 \times 45}$ 和 $\vec{b}_1 \in \mathbb{R}^{450 \times 1}$。第二次，$A_2 \in \mathbb{R}^{450 \times 45}$ 和 $\vec{b}_2 \in \mathbb{R}^{450 \times 1}$。 $A$ 和 $\vec{b}$ 中的条目并不相同。
我可以求解这两个方程组，得到 $\vec{x}_1$、$\Sigma_{x_1}$、$\vec{x}_2$ 和 $\Sigma_{x_2}$。其中 $\Sigma$ 是解 $\vec{x}$ 的方差-协方差矩阵。我能想到两种方法来论证 $\vec{x}_2$ 可能与 $\vec{x}_1$ 不同。

计算 $\vec{x}_1$ 和 $\vec{x}_2$ 之间的欧几里得距离，然后对距离进行 Welch t 检验。这总是显示出极端显著性。我认为这是维数灾难。

计算从 $\vec{x}_1$（及其 $\Sigma$）定义的分布中抽取 $\vec{x}_2$ 的可能性有多大（不大）。可能性只是所有距离 $\vec{x}_1$ 和 $\vec{x}_2$ 或更远的空间的积分。这似乎是不对称的，因此对从 $\vec{x}_2$ （及其 $\Sigma$）中得出的 $\vec{x}_1$ 执行相同操作并取平均值。这似乎不太可能受到维数灾难的影响，因为我对大部分空间的权重实际上为零。


这两种方法都可以发挥作用，因为我可以逐一计算结果，但我已经临时制定了它们，我想知道是否有更成熟的方法来计算/显示/确定/论证向量$\vec{x}_1$和$\vec{x}_2$在统计意义上是不同的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652235/how-to-determine-or-show-if-two-solutions-to-linear-regression-are-different</guid>
      <pubDate>Fri, 02 Aug 2024 23:46:23 GMT</pubDate>
    </item>
    <item>
      <title>获取 DLNM 相互作用导致的相对超额风险</title>
      <link>https://stats.stackexchange.com/questions/652234/get-relative-excess-risk-do-to-interaction-for-dlnm</link>
      <description><![CDATA[我正在研究与 DLNM 结合的拟泊松模型。
我的目标是计算与相互作用相关的相对超额风险。但是，我在运行 crosspred 函数时收到错误消息。如下所示。我应该怎么做才能继续？我试图更改 df，但没有成功。
我的代码：
crosspred(exposure_cbasis, model) 错误：coef/vcov 与基础矩阵不一致。
maxlag &lt;- 21
varknots &lt;- quantile(data$dust, c(10,75,90)/100, na.rm=T)
lagknots &lt;- logknots(maxlag, 3) 
exposure_cbasis &lt;- crossbasis(data$dust, lag=maxlag, 
argvar=list(fun=&quot;ns&quot;, knots=varknots), # 曝光的非线性函数
arglag=list(fun=&quot;ns&quot;, knots=lagknots))# 滞后的非线性函数

# 为交互项定义 crossbasis
inter_cbasis&lt;-crossbasis(data$hydrate, lag=maxlag, 
argvar=list(fun=&quot;ns&quot;, knots=varknots), # 非线性曝光函数
arglag=list(fun=&quot;ns&quot;, knots=lagknots))# 滞后的非线性函数

model&lt;-glm(cases ~ crossbasis*crossbasis2 ,family=quasipoisson, data)

exp_predictions&lt;- crosspred(exposure_cbasis, model) 
int_predictions&lt;- crosspred(inter_cbasis, model) 

pred_with_interaction &lt;- exp_predictions$allfit
pred_without_interaction &lt;- int_predictions$allfit - predictions$allfit

rer &lt;- (pred_with_interaction - pred_without_interaction) / pred_without_interaction
plot(predictions2$pred, rer, 
xlab = &quot;Exposure （单位）”， 
ylab = “相互作用导致的相对超额风险”， 
main = “相互作用导致的相对超额风险”）
]]></description>
      <guid>https://stats.stackexchange.com/questions/652234/get-relative-excess-risk-do-to-interaction-for-dlnm</guid>
      <pubDate>Fri, 02 Aug 2024 23:30:23 GMT</pubDate>
    </item>
    <item>
      <title>将对数链接应用于分位数回归</title>
      <link>https://stats.stackexchange.com/questions/652233/applying-log-link-to-quantile-regression</link>
      <description><![CDATA[
我正在研究分位数回归，我开始思考如何实现对数链接（因为我使用的是正界数据）。我听说分位数回归在变换下是等变的，所以我开始思考，即使线性回归不是这样，对响应变量进行对数处理是否能产生与对数链接相同的效果？这有效吗？还是我运用了错误的想法？我注意到在 R 中的“rq”函数中似乎没有一种简单的方法来指定对数链接，所以我正在尝试寻找一种解决方法。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652233/applying-log-link-to-quantile-regression</guid>
      <pubDate>Fri, 02 Aug 2024 23:12:23 GMT</pubDate>
    </item>
    <item>
      <title>当我们标准化输出时，损失情况会改变吗？</title>
      <link>https://stats.stackexchange.com/questions/652232/does-the-loss-landscape-change-when-we-standardize-the-output</link>
      <description><![CDATA[假设我们有一个一般的损失函数，它依赖于一些参数$w$（例如神经网络权重）：
$$L_w =\frac{1}{N} \sum_i \ell(\hat{y}_i, y_i)$$
在标准化$y_i$之后，形状以及因此的最优值$w^*$会改变吗？
也就是说，新的损失函数$L_w&#39;$会如何：
$$L_w&#39; =\frac{1}{N} \sum_i \ell\left(\hat{y}_i, \frac{y_i-\bar{y}}{\sigma} \right)$$
与原始（未缩放）$L_w$ 会有所不同吗？
相关问题
我检查了这个问题，其中接受的答案中指出它不应该改变，但没有提供进一步的解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/652232/does-the-loss-landscape-change-when-we-standardize-the-output</guid>
      <pubDate>Fri, 02 Aug 2024 23:09:42 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型中相互作用的功效分析</title>
      <link>https://stats.stackexchange.com/questions/652229/power-analysis-for-interaction-in-linear-mixed-model</link>
      <description><![CDATA[我正在尝试对线性混合模型中的交互作用进行功效分析，以确定所需的样本量。
该模型具有以下结构：
Y ~ C * X + (1|Subject)
Y 和 X 是连续变量，而 C 是两级因子（总和对比编码）且在受试者内。
我知道 X 和 Y 之间主效应的预期效应大小约为 beta = 0.27。现在我想找出不同交互效应大小的样本量（因此基本上进行敏感性分析）。
我知道有讨论说交互效应大小通常需要更大的样本量（https://statmodeling.stat.columbia.edu/2018/03/15/need16/）。但是，这些估计似乎只考虑了学科研究之间的差异。
我也尝试使用 InteractionPoweR 包，但我不确定它是否适用于我的情况。
如能得到任何帮助，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/652229/power-analysis-for-interaction-in-linear-mixed-model</guid>
      <pubDate>Fri, 02 Aug 2024 20:39:25 GMT</pubDate>
    </item>
    <item>
      <title>拟合残差相当于优化全局线性模型吗？</title>
      <link>https://stats.stackexchange.com/questions/652223/fitting-against-residuals-equivalent-to-optimizing-global-linear-model</link>
      <description><![CDATA[假设您正在构建线性模型来针对目标变量$y.$优化$r^2$。您当前有一个模型$m$，并且您正在考虑将许多候选预测因子$x_1, x_2, ..., x_{1000}$添加到该模型中。目标是选择 $x_i$，以 $\beta_m * m + \beta_i * x_i.$ 的形式对当前模型进行最佳补充。这是否等同于选择 $x_i$，使 $y$ 上的单变量 $r^2$ 与当前模型 $m$ 的残差最大化？
从数学角度来看，似乎当你给自己自由参数 $\beta_m$ 时，等价性不再成立。然而，这似乎是梯度提升树等事物中的一种常见技术。我相信典型的随机森林实现会将当前模型的权重固定在$1$，但这似乎是一个重大障碍。如果您不允许自己降低现有模型的权重，那么您对下一个预测因子的搜索似乎会偏离那些强但相关的预测因子，这些预测因子会比弱但不相关的预测因子增加更多价值。]]></description>
      <guid>https://stats.stackexchange.com/questions/652223/fitting-against-residuals-equivalent-to-optimizing-global-linear-model</guid>
      <pubDate>Fri, 02 Aug 2024 19:57:13 GMT</pubDate>
    </item>
    <item>
      <title>调整等效样本量进行研究是自我控制的</title>
      <link>https://stats.stackexchange.com/questions/652222/adjusting-equivalence-sample-size-for-study-is-self-controlled</link>
      <description><![CDATA[我正在尝试获取 DDI 协议的样本量计算，我们正在寻找测试生物等效性假设的方法。我正在使用 FARTSSIE 表，但我担心我高估了我的研究规模，因为它假设了平行研究设计。
我知道这可能是错误的，但如果我的研究是自我控制的，我可以将报告的规模减少一些。
我做了一些谷歌搜索和自我控制，样本量计算似乎总是带来案例研究的内容。
是否有特定的公式或修改可以用于解释自我控制？
我正在寻找有关如何处理这种情况的指示。
提前谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/652222/adjusting-equivalence-sample-size-for-study-is-self-controlled</guid>
      <pubDate>Fri, 02 Aug 2024 19:25:35 GMT</pubDate>
    </item>
    <item>
      <title>VAE：潜在分布。后方崩溃，多重潜在</title>
      <link>https://stats.stackexchange.com/questions/652221/vae-latent-distribution-posterior-collapse-multiple-latents</link>
      <description><![CDATA[在探索 VAE 一段时间后，我有两个问题。在标准 VAE 设置中，我们假设 1 个形状为 (BHWD) 的潜在变量：mu 和 var，以及先验 N(0, I)。

潜在分布：我阅读了一些关于卡方分布的资料，想知道潜在 (B,) 的 L2 范数是否是潜在服从高斯分布的良好指标。在标准 VAE 训练中，我发现它的值稳定在 (D-1)**0.5 附近，这符合中心卡方分布的描述。接下来的问题是，如果 L2 范数不等于预期值，我们可以说潜在分布比高斯分布更复杂吗？

后验崩溃：（1）后验崩溃的症状是什么？它是否必须严格为：mu~0、var~1 和 KL~0？（2）如何解释 var 的平均值。我观察到它也受到 D 的影响。此外，如果极小的 var 表示模型非常确定输入，那么爆炸的 var 会告诉我们编码器缺乏能力吗？一般来说，我们更喜欢较小的 var 还是存在一个理想值。

给定一个图像，我尝试将其转换为 Y/UV 通道并分别学习两组潜在值。具体来说，我对两者应用了标准流程：使用一个/两个编码器为 Y 和 UV 输入生成 mu 和 var，分别计算两个 KL 相对于正常 proir，对两者进行后验采样，在解码之前将它们连接在一起。解码器的工作是重建原始 RGB 图像。
我想象，如果 VAE 能够为图像构建可插值/平滑的潜在空间，它也应该能够处理两个潜在值并使 Y/UV 潜在值紧密对齐。不幸的是，我在实验中没有观察到它。重建很好，但潜在的统计数据（为了方便，我将它们标记为 1 和 2）非常混乱。 (1) 我没有从 mu1 和 mu2 获得太多信息，因为它们的值非常接近 0。但是，我总是能发现 var2 爆炸（请参阅我在第 2 点中提出的问题），可能高达 200。 (2) 通常，var1 看起来更像高斯，因为它的 L2 范数收敛于 (d-1)**0.5，但 var2 的值稍大一些（请参阅我在第 1 点中提出的问题）。 (3) 我还计算了 mu1 和 mu2 之间的 cos 相似度和 L2 距离。它们大多是正交的，这与高维向量自然彼此正交的说法相符。并且 L2(mu1, mu2) 接近 L2(mu2, origin)，后者大于 L1(mu1, origin)。我不知道如何理解这些？或者一般来说，VAE 框架不适合学习两个独立但相关的高斯类潜在变量？


感谢您的任何见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/652221/vae-latent-distribution-posterior-collapse-multiple-latents</guid>
      <pubDate>Fri, 02 Aug 2024 19:20:12 GMT</pubDate>
    </item>
    <item>
      <title>加权最小二乘与对数变换</title>
      <link>https://stats.stackexchange.com/questions/652220/weighted-least-squares-vs-log-transform</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652220/weighted-least-squares-vs-log-transform</guid>
      <pubDate>Fri, 02 Aug 2024 18:38:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 W 或 p 值来确定使用 Shapiro-Wilk 的正态性是否更好？</title>
      <link>https://stats.stackexchange.com/questions/652218/is-it-better-to-use-the-w-or-p-value-to-determine-normality-using-shapiro-wilk</link>
      <description><![CDATA[我读到过，W 值高于 0.9 被认为是正常的。所以我想用它作为正常性的截止值。然而，在运行各种场景后，我得出的结果为 W = 0.888429，p = 0.254888。
显然，这是一个边缘情况。W 小于 0.9，所以我的截止值认为这是非正常的。但是，如果我四舍五入到小数点后一位，它将是 0.9，因此是正常的。此外，p 值表示零假设未被拒绝，即它是正常的。
当我查看直方图时，它严重向左倾斜。
其他人会如何解释这一点？由于 W 小于 0.9，我倾向于采取强硬路线并将其视​​为非正态，但也许其他人会认为 p 值更重要？
数据为：
0.65,
-1.37,
-1.22,
2.2,
0,
-1.5,
1.1,
-1.5,
-0.5]]></description>
      <guid>https://stats.stackexchange.com/questions/652218/is-it-better-to-use-the-w-or-p-value-to-determine-normality-using-shapiro-wilk</guid>
      <pubDate>Fri, 02 Aug 2024 18:22:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么修改后的 z 分数没有发现明显的异常值？</title>
      <link>https://stats.stackexchange.com/questions/652217/why-does-modified-z-score-not-pick-up-an-obvious-outlier</link>
      <description><![CDATA[希望借鉴您对用于检测异常值的修改后的 z 分数的一些见解。
据我从研究中得知，当分布可能不正常（例如偏斜）时，修改后的 z 分数比 z 分数本身更能指示异常值。这是因为，如果分布不为正态分布，则使用中位数而不是均值，中位数是集中趋势的稳健估计量。
我正在针对一个值列表测试这两种算法以及其他一些异常值检测算法，其中我知道一个值是极端异常值。为了帮助我，我创建了一个小型 Python 程序，它根据该列表计算 z 分数和修改后的 z 分数，然后使用它来检查列表中的任何项目是否看起来像异常值。基本上，我检查了这些算法是否能成功检测到我知道存在的极端异常值。
为了检查我的数据的分布，程序创建了一个箱线图，异常值（值 = 200）非常明显。作为参考，该数据集的中位数为 58。

异常值 200 的修改后的 z 分数仅为 2.81，这大大低于被视为异常值的 3.5，因此它不会被标记为异常值。仅供参考，我使用 3.5，因为这似乎是最推荐的截止值。
异常值 200 的 z 分数为 3.40，这高于被视为异常值的 3.0，因此它确实被标记为异常值。仅供参考，我使用 3.0 作为截止值，因为这似乎最受欢迎。
我的问题是，为什么 z 分数算法可以检测到我的数据集中的异常值，而修改后的 z 分数算法却不能？在我看来，这似乎违反直觉，尤其是当异常值从箱线图中显而易见时。
这是我的 Python，以防我犯了错误：
import matplotlib as plt
import numpy as np
from scipy.stats import zscore

def z_score_mod(obs):
med = np.median(obs)
med_abs_dev = np.median(np.abs(obs - med))
z_score_mod = 0.6745 * ((obs - med) / med_abs_dev)
return z_score_mod

# 具有相当大的异常值 = 200 和索引 = 13 的观察值列表
list_of_obs = [58,71,11,18,90,97,15,53,39,22,62,51,10,200,20,64,94,71,73,18,95,96,92,38,26]

# 将观测值列表转换为 numpy 数组
array_of_obs = np.array(list_of_obs)

# 创建箱线图以显示异常值
plt.pyplot.boxplot(array_of_obs)

median = np.median(array_of_obs)

# 计算每个数组项的修改后的 z 分数
array_of_z_score_mod = z_score_mod(array_of_obs)

# 对于生成的修改后的 z 分数，确定是否有任何异常值
array_of_outlier_evals = abs(array_of_z_score_mod) &gt; 3.5

# 索引 = 13 处的观测值 = 200 是否为异常值？
print(&#39;\r&#39;)
print(f&#39;索引位置 13 处的观察值 = {list_of_obs[13]}&#39;)
print(f&#39;修改后的 z 分数值 = {array_of_z_score_mod[13]:.2f}&#39;)
print(f&#39;在修改后的 z 分数阈值 3.5 处，值是否为异常值：{array_of_outlier_evals[13]}&#39;)

# 计算每个数组项的 z 分数
array_of_z_score = zscore(list_of_obs)

# 对于生成的 z 分数，确定是否有任何异常值
array_of_outlier_evals_2 = abs(array_of_z_score) &gt; 3

# 索引 = 13 处的观察值 = 200 是否为异常值？
print(&#39;\r&#39;)
print(f&#39;索引位置 13 处的观察值 = {list_of_obs[13]}&#39;)
print(f&#39;值的 z-score = {array_of_z_score[13]:.2f}&#39;)
print(f&#39;在 z-score 阈值 3.0 处，值是否为异常值：{array_of_outlier_evals_2[13]}&#39;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652217/why-does-modified-z-score-not-pick-up-an-obvious-outlier</guid>
      <pubDate>Fri, 02 Aug 2024 17:17:52 GMT</pubDate>
    </item>
    <item>
      <title>具有外生变量的 ARMA - GARCH 模型的 p 值</title>
      <link>https://stats.stackexchange.com/questions/652216/p-values-for-a-arma-garch-model-with-exogenous-variable</link>
      <description><![CDATA[我正在尝试估计以下 ARMA(1, 2) - GARCH(1, 1) 模型的参数，其中还带有一个外生变量。模型规范如下：
$ x_t = \mu + \beta_Y \cdot y_{t-1} + AR_1\cdot x_{t-1} + MA_1\cdot \epsilon_{t-1} + MA_2 \cdot \epsilon_{t-2} + \epsilon_t$
$\epsilon_t = \sigma_t\cdot z_t $
$ \sigma_t = \sqrt{\omega + \alpha \cdot \epsilon_{t-1}^2 + \beta\cdot \sigma_{t-1}^2}$
$ z_t \sim Normal(0, 1)$ 适用于所有 $t$。这些误差是 iid 的。
模型参数为：$\mu, \beta_Y, AR_1, MA_1, MA_2, \omega, \alpha, \beta$。
我目前正在通过最大化 pytorch 中的对数似然来估计最佳参数。问题：

是否有能够估计这些参数的 python 包？作为双重检查，它将非常有用

是否有一个 python 包能够为估计的参数生成标准错误和 p 值？

如果答案 2 没有这样的包，有没有关于如何生成这些 p 值的提示？


非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652216/p-values-for-a-arma-garch-model-with-exogenous-variable</guid>
      <pubDate>Fri, 02 Aug 2024 17:14:01 GMT</pubDate>
    </item>
    <item>
      <title>核均值嵌入的收敛</title>
      <link>https://stats.stackexchange.com/questions/652212/convergence-of-kernel-mean-embeddings</link>
      <description><![CDATA[令 $k(\cdot,\cdot)$ 为有界核，$\mathcal{H}$ 为其关联的 RKHS。定义核均值嵌入 $\mu=\int k(\cdot,x) \, dP_X(x)$，令 $\hat{\mu}=\frac{1}{n}\sum k(x_i,\cdot)$ 为其样本类似物。两者之间的误差为 $\|\mu-\hat{\mu}\|_{\mathcal{H}}=O(\frac{1}{\sqrt{n}})$。各种结果通过使用希尔伯特空间的伯恩斯坦型不等式来证明这一点。
对我来说，从中心极限定理的角度来看，这感觉很直观。有希尔伯特空间 CLT 吗？是否有可能从 CLT 的应用中显示这种速率？]]></description>
      <guid>https://stats.stackexchange.com/questions/652212/convergence-of-kernel-mean-embeddings</guid>
      <pubDate>Fri, 02 Aug 2024 14:32:18 GMT</pubDate>
    </item>
    <item>
      <title>E-test 值的多重校正</title>
      <link>https://stats.stackexchange.com/questions/652208/multiple-correction-for-e-test-values</link>
      <description><![CDATA[我目前正在执行多个“E-tests”（poisson.mean），并且想知道使用 E-tests 进行多次校正的最合适方法，以及如何在 R 中进行此操作。
我正在计算 7 个不同实验组（2 个对照组，5 个感兴趣的实验组）中某个事件发生的次数（在给定的时间间隔内）。
我选择通过列出 7 个条件组和值来比较各组之间的泊松分布均值，然后以迭代方式执行泊松检验。然后从结果中获取 P 值，例如。
Cond1 &lt;- c(0,0,0,1,1,2,3,3,3)
Cond2 &lt;- c(0,1,1,1,1,1,2,3,3)
Cond3 &lt;- c(0,1,2,3,3,3,3,3,4)
Cond7 &lt;- c(3,3,3,3,4,4,4,5,6)
result1 &lt;- poisson.test(x c(sum(Cond1), sum(Cond2)),
T = c(length(Cond1), length (Cond2)),
alternative = &quot;two.sided&quot;)
result2 &lt;- poisson.test(x c(sum(Cond1), sum(Cond3)),
T = c(length(Cond1), length (Cond3)),
alternative = &quot;two.sided&quot;) 

result20 &lt;- poisson.test(x c(sum(Cond6), sum(Cond7)),
T = c(length(Cond6), length (Cond7)),
alternative = &quot;two.sided&quot;) 
P1 &lt;- result1§p.value 
P2 &lt;- result2§p.value 
P20&lt;- result20§p.value 

从这一点开始，我需要校正多个测试，并希望使用 Benjamini-Hochberg 类型的排序 p 值显著性校正，但我想知道
A) 哪种测试最适合这种分析
B) 如何在 R 中进行此操作]]></description>
      <guid>https://stats.stackexchange.com/questions/652208/multiple-correction-for-e-test-values</guid>
      <pubDate>Fri, 02 Aug 2024 11:36:56 GMT</pubDate>
    </item>
    <item>
      <title>对单个组的样本大小进行论证以获得所需准确度的平均值估计值</title>
      <link>https://stats.stackexchange.com/questions/652201/sample-size-justification-for-single-group-to-get-estimate-of-mean-to-desired-ac</link>
      <description><![CDATA[
我有一个计算机组件样品
这些计算机组件是分批生产的（1 批 = 1 批次），每批 200 个
组件可以单独进行电子测试
然后对该测试结果进行平均，以得出批次级值，以判断整个批次是否通过
我需要知道需要从一批中抽样多少个组件，以便对整个批次进行
准确的测试测量。
有人知道我应该如何证明这一点吗？
例如，测试 10 个组件是否能让我足够准确地估计出整个批次的平均测试结果？

我知道这里有一些未知数，比如“足够准确” - 也许是某种置信区间？
任何帮助都太棒了！
林肯]]></description>
      <guid>https://stats.stackexchange.com/questions/652201/sample-size-justification-for-single-group-to-get-estimate-of-mean-to-desired-ac</guid>
      <pubDate>Fri, 02 Aug 2024 08:15:30 GMT</pubDate>
    </item>
    </channel>
</rss>