<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 08 Dec 2024 06:23:33 GMT</lastBuildDate>
    <item>
      <title>我可以在 Cox PH 中使用年龄作为随时间变化的协变量吗？</title>
      <link>https://stats.stackexchange.com/questions/658439/can-i-use-age-as-a-time-varying-covariate-in-a-cox-ph</link>
      <description><![CDATA[我正在研究叛乱团体领导人在被迫下台之前会掌管叛乱团体多长时间。我有领导人年份数据，其中包含以下变量：

groupid = 每个团体的唯一 ID 号
leaderid = 每个领导人的唯一 ID 号
tenure = 领导人首次掌权以来的时间（从 0 开始计数）
forcedexit = 领导人被迫下台时取值为 1，其他年份取值为 0
groupage = 团体成立以来的时间（从 0 开始计数）

我的数据集中，叛乱团体活跃的每一年都有一行。数据通常如下所示：
 groupid leaderid forcedexit tenure groupage
&lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 411 1 0 0 0
2 411 1 0 1 1
3 411 1 0 2 2
4 411 2 1 0 3
5 411 2 0 1 4
6 411 2 0 2 5
7 411 2 0 3 6
8 411 3 0 0 7
9 411 3 0 1 8
10 411 3 0 2 9

请注意，新领导人可以通过强制退出以外的方式上台，因此即使 forcedexit = 0，领导人也可能离职（例如，参见上述数据中的 leaderid = 3）。
我想测试一下在较老的群体中，领导人是否更难被罢免。我的直觉是运行 Cox PH 模型（我使用的是 R）：
mod &lt;- coxph(Surv(tenure, forcedexit) ~ groupage, data = df)
如果我运行这个，我会得到 groupage 系数的负且显著的估计值，这与我的直觉一致。但是，出于两个原因，我对这个结果持谨慎态度。
首先，我可以在 Cox PH 中使用 groupage 作为随时间变化的变量吗？我读过的大多数使用 Cox PH 的医学研究都使用不会随时间变化的年龄变量（例如，试验开始时的年龄）。我的 groupage 变量确实会随时间而变化。
其次，我担心 groupage 和 tenure 变量之间的关系会出现一些问题。某些 tenure 值在 groupage 的某些值下不可能存在。例如，tenure = 5 和 groupage = 0 永远不可能存在，因为组必须存在，领导者才能负责该组。因此，较高的 groupage 值可能与较高的 tenure 值一起机械地出现。如果领导者拥有较大的 tenure，则 groupage 也必须较大。
对这两个问题的任何想法都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658439/can-i-use-age-as-a-time-varying-covariate-in-a-cox-ph</guid>
      <pubDate>Sun, 08 Dec 2024 05:02:32 GMT</pubDate>
    </item>
    <item>
      <title>标准化回归模型的变量与回归模型中的权重？</title>
      <link>https://stats.stackexchange.com/questions/658437/standardizing-variables-for-a-regression-model-vs-weights-in-a-regression-model</link>
      <description><![CDATA[我在 R 中有一个纵向 GAM（一般加性模型）回归。
以下是模型和数据的一般形式（响应介于 0 和 1 之间）：
gam_model &lt;- gam(
response ~ 
te(time_var, var1) +
te(time_var, var2) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

state time_varpopulation var1 var2 response
state_1 2005-01-01 1000000 500000 10000 0.45
state_1 2005-02-01 1001000 520000 12000 0.47
state_1 2005-03-01 1002001 540000 11000 0.46
state_1 2005-04-01 1003002 560000 13000 0.48
state_2 2005-01-01 200000 100000 2000 0.42
state_2 2005-02-01 200200 105000 2400 0.44
state_2 2005-03-01 200400 110000 2200 0.43
state_2 2005-04-01 200600 115000 2600 0.45

我遇到的问题如下：

数据按州提供（多个州，1 个国家），但每个州的人口不同
这让我认为需要对模型进行一些处理，以防止人口较多的州对响应的影响比人口较少的州更大
我有每个州的人口

我正在考虑使用以下权重公式（我从这里得到这个想法https://www.nature.com/articles/s41598-024-54441-x）：
$$avg\_weight_s = \frac{1}{T}\sum_{t=1}^{T} \frac{\ln(population_{s,t})}{\frac{1}{N}\sum_{i=1}^{N} \ln(population_{i,t})}$$
其中：

$T$ 是时间段的总数
$N$ 是州的总数
$population_{s,t}$ 是 $t$ 时刻 $s$ 州的人口数
$population_{i,t}$ 表示每个州 $i$ 在时间 $t$ 的人口。

这让我考虑不同的模型选项：
# 选项 1：非标准化，无权重

gam_model &lt;- gam(
response ~ 
te(time_var, var1) +
te(time_var, var2) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

# 选项 2：标准化，无权重

gam_model &lt;- gam(
响应 ~ 
te(time_var, var1/population) +
te(time_var, var2/population) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

# 选项 3：未标准化，权重

gam_model &lt;- gam(
响应 ~ 
te(time_var, var1) +
te(time_var, var2) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
weights = avg_weight,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

# 选项 4：标准化，权重

gam_model &lt;- gam(
response ~ 
te(time_var, var1/population) +
te(time_var, var2/population) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
weights = avg_weight,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

我有点困惑，不知道这些选项中哪一个在逻辑上是正确的。我认为其中一些可能有点过度，而另一些则完全不正确。有办法解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658437/standardizing-variables-for-a-regression-model-vs-weights-in-a-regression-model</guid>
      <pubDate>Sun, 08 Dec 2024 04:38:44 GMT</pubDate>
    </item>
    <item>
      <title>带有 Adam 优化器网络的单层/单单元如何工作？</title>
      <link>https://stats.stackexchange.com/questions/658436/how-does-a-single-layer-single-unit-with-adam-optimizer-network-work</link>
      <description><![CDATA[我对 ML 还很陌生，正在尝试使用线性回归。我测试了 sklearn 的 LinearRegression 模型，然后想将结果与一个非常简单的神经网络进行比较。
我创建了一个具有 1 层和 1 个单元的 tensorflow Dense 网络，并带有“线性”激活函数。
我使用了“sgd”和“adam”优化器，并使用 MinMaxScaler 缩放了 x 数据
我得到了与 LinearRegression 模型截然不同的结果（预测和损失）。
我有两个问题：

具有线性激活的 1 层/1 个单元网络是否与 LinearRegression 相同？

SGD 预测非常接近，我正在用房价进行测试，所以我会得到相对接近的结果。目标值在 1000 左右，因此 y_train 数组中的 120,000 美元价格被设置为 120。但是，当我使用 Adam 优化器时，我得到的预测值非常低（不到 20）。我从 100 个 epoch 开始，然后增加到 1000 个，但仍然得到了类似的结果。我是不是在某个地方做错了什么，或者 Adam 优化器是否有限制或某些要求才能正常工作。

]]></description>
      <guid>https://stats.stackexchange.com/questions/658436/how-does-a-single-layer-single-unit-with-adam-optimizer-network-work</guid>
      <pubDate>Sun, 08 Dec 2024 03:47:10 GMT</pubDate>
    </item>
    <item>
      <title>当网络的接近中心性较低时会发生什么 - 外围节点会发生什么</title>
      <link>https://stats.stackexchange.com/questions/658435/what-happens-when-a-network-has-low-closeness-centrality-what-happens-to-nodes</link>
      <description><![CDATA[我有三十九个具有接近中心性得分的节点，但我不知道该如何处理没有得分的外围节点。]]></description>
      <guid>https://stats.stackexchange.com/questions/658435/what-happens-when-a-network-has-low-closeness-centrality-what-happens-to-nodes</guid>
      <pubDate>Sun, 08 Dec 2024 03:05:57 GMT</pubDate>
    </item>
    <item>
      <title>多重比较和交互图</title>
      <link>https://stats.stackexchange.com/questions/658430/multi-comparasion-and-interaction-plot</link>
      <description><![CDATA[我进行了 Kruskal Wallis 检验，以检查 2 个分类变量（独立变量）是否对 1 个连续变量有影响。在获得显著的 p 值后，我进行了事后检验。为了查看两个独立变量对因变量的相互作用，我绘制了相互作用图，但我不确定我的结果是否良好？或者我的策略是否让我得到错误的结果？

这是 colab，您可以在其中查看我的代码：
https://colab.research.google.com/drive/1OlTbHldb3guUTk-LEGRBlriSLi6O8RSw?usp=sharing]]></description>
      <guid>https://stats.stackexchange.com/questions/658430/multi-comparasion-and-interaction-plot</guid>
      <pubDate>Sun, 08 Dec 2024 00:10:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么在无监督学习中损失不被视为“监督信号”？</title>
      <link>https://stats.stackexchange.com/questions/658428/why-the-loss-is-not-considered-as-a-supervisory-signal-in-unsupervised-learnin</link>
      <description><![CDATA[据说监督学习与无监督学习的区别在于“监督信号”的存在，也就是标签。
然而，在这两种情况下，我们都有一个损失函数。损失难道不是一种引导优化和学习过程的“监督信号”吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658428/why-the-loss-is-not-considered-as-a-supervisory-signal-in-unsupervised-learnin</guid>
      <pubDate>Sat, 07 Dec 2024 22:00:31 GMT</pubDate>
    </item>
    <item>
      <title>如何比较两个独立受访者进行的李克特量表调查？</title>
      <link>https://stats.stackexchange.com/questions/658426/how-to-compare-two-likert-scale-surveys-by-independent-respondents</link>
      <description><![CDATA[我需要比较两个（多项）量表的评分。问题是：这两个量表虽然是同一个量表，但却是两组不同的专家。
基本思想：他们是否同意量表的项目。
两组人都看到了不同的文本片段，并且必须根据这些文本填写调查问卷。
文本片段和量表（以 7 点李克特量表测量的多项）对于两个组都是相同的 - 但如上所述，这两个组由不同的人组成。我现在如何比较这两个量表？（超越了对两个组的所有项目进行均值的汇总统计）
简单的相关性不起作用，因为我没有配对结构，对吗？我无法匹配例如第 1 组的受访者 1 和第 2 组的受访者 1，因为他们是不同的人？
ICC 是可行的方法吗？
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/658426/how-to-compare-two-likert-scale-surveys-by-independent-respondents</guid>
      <pubDate>Sat, 07 Dec 2024 21:13:30 GMT</pubDate>
    </item>
    <item>
      <title>适合的统计检验</title>
      <link>https://stats.stackexchange.com/questions/658420/suitable-statistical-test</link>
      <description><![CDATA[我有 2 个组 - 曾经在我的网站上活跃的人和从未活跃的人。活动是基于某些操作的指标 - 两组人都访问了网站。
每个组在网站上的第一周使用了一组功能（它是一种平台，人们是用户），我想知道哪些功能与“变得活跃”相关。
例如：
100 个活跃的人中有 20 个在该组中使用了功能 A 100 次，而总共使用了 3000 次功能。
在 50 位从未活跃过的用户中，有 3 位使用了功能 A，总共使用了 1500 次。



曾活跃
功能
使用的帐户
帐户总数
使用的功能
功能总使用量




1
A
20
100
100
3000


0
A
3
50
20
1500



我还可以添加特征使用情况的方差和标准差。
我可以在这里做什么测试来表明使用特征 A 的人与活跃度的相关性明显更高？
此外，它对账户比例本身进行任何测试并使用该测试来声称特征 A 与活跃度显著相关是否有意义？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658420/suitable-statistical-test</guid>
      <pubDate>Sat, 07 Dec 2024 18:45:42 GMT</pubDate>
    </item>
    <item>
      <title>如果异常值少于数据点的 10％，您可以删除它们吗？</title>
      <link>https://stats.stackexchange.com/questions/658405/can-you-remove-outliers-if-they-are-less-than-10-of-the-datapoints</link>
      <description><![CDATA[我目前正在上我的第一堂数据分析课，我们会做一些简单的假设检验，比如 t 检验等。我们的老师告诉我们，只要异常值不超过样本量 n 的 10%，我们就可以删除它们。这准确吗？在我看来，这太过方法论化了，我不明白为什么我们要这样处理每种情况。一般方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658405/can-you-remove-outliers-if-they-are-less-than-10-of-the-datapoints</guid>
      <pubDate>Sat, 07 Dec 2024 10:22:05 GMT</pubDate>
    </item>
    <item>
      <title>我对计数问题的解答可以被纠正吗？</title>
      <link>https://stats.stackexchange.com/questions/658393/can-my-solution-to-a-counting-problem-be-corrected</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658393/can-my-solution-to-a-counting-problem-be-corrected</guid>
      <pubDate>Fri, 06 Dec 2024 21:51:24 GMT</pubDate>
    </item>
    <item>
      <title>McNemar 检验是否适合分析多种设置中的二元医疗数据？</title>
      <link>https://stats.stackexchange.com/questions/658387/is-mcnemars-test-appropriate-for-analyzing-binary-medical-data-in-multiple-setu</link>
      <description><![CDATA[我正在分析淋巴水肿患者的数据集。每位患者在两种情况下接受相同的检查：

未接受过物理治疗。
检查前立即接受过物理治疗。

对于每位患者和每次检查，我都有 x 个二元标准（0 = 正常结果，1 = 病理结果）。这是我进行的分析

每个标准：为每个标准构建一个 2x2 列联表，并应用 McNemar 检验来检查两种情况之间病理结果的比例是否不同。
每个患者：将每个患者的所有标准汇总到一个列联表中，并再次应用 McNemar 检验。
全局：将所有标准和患者合并到一个列联表中，并应用 McNemar 检验。

我的主要问题是：McNemar 检验是否适用于这三种情况，或者是否有其他统计检验更适合对此类数据进行稳健而全面的分析？
我对解释患者内部或整个数据集内标准之间依赖关系的方法特别感兴趣。如有任何改进我的方法的建议，我将不胜感激。
提前谢谢您！
示例数据：
每位患者在不同条件下接受了两次检查：
未接受物理治疗
接受物理治疗
以下是汇总患者中某一标准结果的列联表示例：
| | 接受物理治疗：阳性(0) | 接受物理治疗：阴性(1) |
|------------------------|-----------------------------------|-----------------------------------|
| 未接受物理治疗：阳性(0) | 5 | 1 |
| 未接受物理治疗：阴性(1) | 2 | 8 |
此表中：

“阳性”表示正常结果。
“阴性”表示病理结果。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658387/is-mcnemars-test-appropriate-for-analyzing-binary-medical-data-in-multiple-setu</guid>
      <pubDate>Fri, 06 Dec 2024 18:38:13 GMT</pubDate>
    </item>
    <item>
      <title>meta 与 metafor 对比例的三级荟萃分析结果不同</title>
      <link>https://stats.stackexchange.com/questions/658385/different-results-meta-vs-metafor-for-three-level-meta-analysis-of-proportions</link>
      <description><![CDATA[R 包“meta”有一个函数“metaprop”，用于对比例进行荟萃分析，参数“cluster”允许进行三级荟萃分析。R 文档（版本 8.0-1）对此进行了如下描述：

如果使用参数 cluster 并且至少一个 cluster 提供多个估计值，则使用三级随机效应荟萃分析模型 (Van den Noortgate et al., 2013)。在内部，调用 rma.mv 进行分析，并使用参数 type = &quot;rowsum&quot; 的 weights.rma.mv 计算随机效应权重。

函数“rma.mv”来自包“metafor”，有更多用于比较子组等的选项。所以我尝试直接在“metafor”中复制结果。虽然我可以复制点估计，但合并标准误差会存在细微差异（因此置信区间也不同）。有人知道是什么导致了这种差异吗？
我在下面提供了一个可重现的示例。
# 加载 R 包
library(meta) #version 8.0-1
library(metafor) #version 4.6-0

# 示例数据集
df &lt;- data.frame(
id = c(1:10),
study = c(&quot;A et al&quot;, &quot;A et al&quot;, &quot;B et al&quot;, &quot;B et al&quot;, &quot;C et al&quot;, &quot;C et al&quot;, 
&quot;D et al&quot;, &quot;D et al&quot;, &quot;E et al&quot;, &quot;E et al&quot;),
n_positive = c(51, 103, 122, 201, 160, 112, 6211, 6187, 2339, 2470),
n_total = c(124, 140, 306, 311, 229, 219, 13597, 12868, 5070, 5809) )
df &lt;- escalc(xi = n_positive, ni = n_total, measure = &quot;PLO&quot;, data = df)

# 使用 metaprop 进行分析
metaprop1 &lt;- metaprop(event = n_positive, n = n_total, cluster = study, data = df)
# 使用 rma.mv 进行分析
rma.mv1 &lt;- rma.mv(yi = yi, V = vi, random = ~ 1 | study/id, data = df)
# 使用 metaprop 进行分析rma.mv &amp; 与 metaprop 中相同的研究权重
rma.mv2 &lt;- rma.mv(yi = yi, V = vi, random = ~ 1 | study/id, data = df, W = metaprop1[[&quot;w.random&quot;]])

# 汇总估计值比较（以 logit 形式）
paste(metaprop1[[&quot;TE.random&quot;]], metaprop1[[&quot;seTE.random&quot;]])
# 0.0899361424942118 0.150816619366075
paste(rma.mv1[[&quot;beta&quot;]], rma.mv1[[&quot;se&quot;]])
# 0.0913959137416219 0.159661208321448
paste(rma.mv2[[&quot;beta&quot;]], rma.mv2[[&quot;se&quot;]])
# 0.0899361424942119 0.159663991953103

# 尽管产生了不同的合并 SE 
# metaprop 和 rma.mv 都使用了相同的研究方差，最多精确到 16 位小数 
summary( round(df$vi, 16) == round(metaprop1[[&quot;seTE&quot;]]^2, 16) )
# 对所有 10 个估计值都为 TRUE

P.S.以下是汇总结果以 95% 置信区间的比例表示。
# 汇总结果转换为具有 95% 置信区间的比例
paste0(
round( logit2p( metaprop1[[&quot;TE.random&quot;]]), 3)*100, &quot;% (&quot;,
round( logit2p( metaprop1[[&quot;TE.random&quot;]] - 1.96*metaprop1[[&quot;seTE.random&quot;]] ), 3)*100, &quot;% to &quot;,
round( logit2p( metaprop1[[&quot;TE.random&quot;]] + 1.96*metaprop1[[&quot;seTE.random&quot;]] ), 3)*100, &quot;%)&quot; )
# &quot;52.2% (44.9% 至 59.5%)&quot;
paste0(
round( logit2p( rma.mv1[[&quot;beta&quot;]]), 3)*100, &quot;% (&quot;,
round( logit2p( rma.mv1[[&quot;beta&quot;]] - 1.96*rma.mv1[[&quot;se&quot;]] ), 3)*100, &quot;% 至 &quot;,
round( logit2p( rma.mv1[[&quot;beta&quot;]] + 1.96*rma.mv1[[&quot;se&quot;]] ), 3)*100, &quot;%)&quot; )
# &quot;52.3% (44.5% 至 60%)&quot;
paste0(
round( logit2p( rma.mv2[[&quot;beta&quot;]]), 3)*100, &quot;% (&quot;,
round( logit2p( rma.mv2[[&quot;beta&quot;]] - 1.96*rma.mv2[[&quot;se&quot;]] ), 3)*100, &quot;% 至 &quot;,
round( logit2p( rma.mv2[[&quot;beta&quot;]] + 1.96*rma.mv2[[&quot;se&quot;]] ), 3)*100, &quot;%)&quot; )
# &quot;52.2% (44.4% 至 59.9%)&quot;
]]></description>
      <guid>https://stats.stackexchange.com/questions/658385/different-results-meta-vs-metafor-for-three-level-meta-analysis-of-proportions</guid>
      <pubDate>Fri, 06 Dec 2024 18:19:37 GMT</pubDate>
    </item>
    <item>
      <title>如何找到山脊“统计上”消散的点？</title>
      <link>https://stats.stackexchange.com/questions/658384/how-to-find-the-point-where-a-ridge-statistically-dissipates</link>
      <description><![CDATA[这是我感兴趣的表面$\mathcal{M}$的图像。

表面是根据一系列曲线$z=f_x(y)$（每条曲线都是某个物体的测量物理轮廓）估计的，并分配了$x$个变量。我对点云$(x, y, f_x(y))$执行了双变量 Nadaraya-Watson 核回归，以获得平滑的$\mathcal{M}$。下面是 $z=f_x(y)$ 曲线的图像。

设 $m_x(y)$ 为 $\mathcal{M}$ 与 $yz$ 平行平面的交点曲线，其坐标为 $x$。 $m_x(y)$ 在较小的 $x$ 上表现出一个显著的峰值（局部最大值），但随着 $x$ 的增加，峰值逐渐消散。下面是两条曲线$m_{x_\mathrm{min}}(y)$和$m_{x_\mathrm{max}}(y)$的图像：

回到$\mathcal{M}$，这个突出的峰值的演化在表面上形成了一条脊线（下图中的绿线）。在某个临界点 $x_\mathrm{min} \leq x^* \leq x_\mathrm{max}$（大致在绿色虚线圆圈内），峰值不再存在，脊线停止。

我认为可以通过在脊线上设置初始点并计算 Hessian 矩阵的特征向量来跟踪连续脊线（绿线）。但我想知道：

我如何从统计学上判断给定$x=x^*$时脊线存在的概率（例如，$x_\mathrm{min}$上的$\sim100\%$和$x_\mathrm{max}$上的$\sim0\%$）？

我的第一个想法是将曲面拟合到参数模型（类似于分段回归）。但如果可能的话，我认为非参数方法会更好。
提前致谢！
（编辑）回答 whuber 和 Tim 的评论。]]></description>
      <guid>https://stats.stackexchange.com/questions/658384/how-to-find-the-point-where-a-ridge-statistically-dissipates</guid>
      <pubDate>Fri, 06 Dec 2024 16:27:10 GMT</pubDate>
    </item>
    <item>
      <title>查找随机过程的方差</title>
      <link>https://stats.stackexchange.com/questions/658243/finding-the-variance-of-a-stochastic-process</link>
      <description><![CDATA[这是该问题的第二部分计算随机过程的均值和方差？
对于 Polya Urn 问题，我试图理解为什么方差的比率是：
$$\operatorname{Var}(X_n) = E[X_n](1-E[X_n]) \left(\frac{d}{w+b+d} - \frac{w+b}{w+b+d}\frac{1}{n}\right).$$
我知道一般方差公式是$E[X_n^2] - (E[X_n])^2$ 并且 $E[X_n] = \frac{w}{w+b}$。我只需要找到 $E[X_n^2]$。
当我们有 $n$ 个球时，如果我们抽出一个白球（概率 $X_{n-1}$），我们会添加 $d$ 个白球。如果我们抽到黑球（概率为$1-X_{n-1}$），我们添加$d$个黑球（$k$是前面步骤中添加的白球数量）。
$$ X_n = \begin{cases}
\frac{w + (k+1)d}{w+b+nd} &amp; \text{如果抽到白球} \\
\frac{w + kd}{w+b+nd} &amp; \text{如果抽出黑球}
\end{cases} $$
使用二阶总期望定律：
$$ E[X_n^2|X_{n-1}] = X_{n-1}\left(\frac{w + (k+1)d}{w+b+nd}\right)^2 + (1-X_{n-1})\left(\frac{w + kd}{w+b+nd}\right)^2 $$
通过扩展和替换：
$$ \left(\frac{w + (k+1)d}{w+b+nd}\right)^2 = \frac{w^2 + 2w(k+1)d + ((k+1)d)^2}{(w+b+nd)^2} $$
$$ \left(\frac{w + kd}{w+b+nd}\right)^2 = \frac{w^2 + 2wkd + (kd)^2}{(w+b+nd)^2} $$
$$ E[X_n^2|X_{n-1}] = X_{n-1}\frac{w^2 + 2w(k+1)d + ((k+1)d)^2}{(w+b+nd)^2} + (1-X_{n-1})\frac{w^2 + 2wkd + (kd)^2}{(w+b+nd)^2} $$
我尝试扩展再次：
$$ \begin{align*}
E[X_n^2|X_{n-1}] &amp;= \frac{X_{n-1}(w^2 + 2w(k+1)d + ((k+1)d)^2)}{(w+b+nd)^2} + \frac{(1-X_{n-1})(w^2 + 2wkd + (kd)^2)}{(w+b+nd)^2} \\
&amp;= \frac{w^2 + 2wkd + (kd)^2}{(w+b+nd)^2} + X_{n-1}\frac{2wd + 2d^2(k+1)}{(w+b+nd)^2}
\end{align*} $$
我知道我需要再次计算期望，这样 $E(E[X_n^2|X_{n-1}]) = E[X_n^2]$
但这就是我陷入困境的地方，不知道如何继续。我感觉自己在兜圈子。有什么想法可以继续吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658243/finding-the-variance-of-a-stochastic-process</guid>
      <pubDate>Wed, 04 Dec 2024 02:04:46 GMT</pubDate>
    </item>
    <item>
      <title>对PCA的质疑：为什么载荷常常被忽视？</title>
      <link>https://stats.stackexchange.com/questions/658157/doubts-about-pca-why-are-loadings-often-overlooked</link>
      <description><![CDATA[我对 PCA 的存在性存有疑虑。我经常看到它用于遗传学，在遗传学中，你研究的基因组可能你并不完全了解它们的功能。在这种情况下，PCA 用于捕获数据集中的潜在变异性并生成新的不相关变量（主成分）。
但是，当将 PCA 应用于具有已知有形变量的数据集时（尤其是当目标是降低维度或可视化异常值时），我注意到很少对这些变量的负载进行后续分析。在我的特定情况下，我使用有形变量，并且我经常有兴趣了解它们之间的关系以及它们在成分中的权重。然而，在大多数研究中，我只发现解释方差的百分比，仅此而已。
这让我很疑惑：为什么不更多地强调解释负载？载荷对于理解原始变量的行为方式和对主成分的贡献是否不重要？对我来说，载荷对于解释变量之间的关系以及确定它们对变异性的影响似乎至关重要。我是否遗漏了什么，或者这只是 PCA 中尚未充分探索的领域？
编辑（07/12）：
感谢 Peter Flom 和 Nick Cox 对本主题的宝贵贡献。我将重点回答您的问题
在我的具体案例中，@Nick Cox，我研究了一组 12 个基因，旨在识别潜在的簇并了解哪些基因占最大变异性。我的项目重点关注三种不同的营养组合及其对基因表达的影响（图 1）。虽然降维有助于简化数据，但我也在探索成分是否与生物功能相关。例如，胆固醇流出相关基因似乎主要对 PC1 有贡献，而葡萄糖代谢可能与 PC2 有关。请注意，这只是推测，并不旨在得出严格的结论——我的目标是探索负荷是否可以提供对这些关联的见解并有助于假设的产生。
鉴于这个目标，我对负荷特别感兴趣，因为它们反映了每个基因对主要成分的贡献。通过分析负荷，我希望确定哪些基因对成分捕获的变异性贡献最大。这些见解可以支持或改进我研究的一些假设。

在这种情况下，一些基因强烈影响 Dim1，对胆固醇相关过程捕获的方差产生积极贡献（如图 2 所示）。这是因为沿 Dim1 聚集的某些基因与这些功能相关。虽然这一观察有助于我更好地理解基因行为，但我承认这是一种过于简单的方法，具有一些局限性。因此，这只是一个探索性工具，而不是得出明确结论的基础。

与这些结果相关的负载如下：

关于参考书目，我支持：
主成分分析，第二版。I.T. Jolliffe
使用 R 进行探索性多元分析示例
@Peter Flom，您说得完全正确，如果主要关注点只是识别异常值或解释方差，则不一定需要加载。但是，此线程的目的就是专门深入探讨加载主题。由于有人问我的意图，所以我分享了我的疑虑。
就我而言，我的目标不仅仅是可视化异常值——我还对识别模式或聚类感兴趣。在这种情况下，我认为加载可以发挥有用的作用。但是，在探索 StatsExchange 上的其他示例后，我注意到加载通常不是 PCA 讨论的中心焦点。尽管如此，我仍然觉得加载对我的分析可能特别重要。
我在这里忽略了什么吗？
可能是我的不确定性源于对加载的几何解释缺乏理解？也许更清晰的几何视角可以帮助我更好地概念化和利用这些结果。你的想法是什么？
提前感谢您的无价贡献]]></description>
      <guid>https://stats.stackexchange.com/questions/658157/doubts-about-pca-why-are-loadings-often-overlooked</guid>
      <pubDate>Mon, 02 Dec 2024 17:07:52 GMT</pubDate>
    </item>
    </channel>
</rss>