<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 06 Feb 2025 21:16:05 GMT</lastBuildDate>
    <item>
      <title>分析不同年份、不同国家和不同疾病的流行病学变量</title>
      <link>https://stats.stackexchange.com/questions/661057/analyzing-epidemiological-variables-across-years-countries-and-diseases</link>
      <description><![CDATA[我有一个包含以下变量的大型数据集：

年份（从 2000 年到 2020 年离散）
国家（~100 个国家）
疾病（~100 种疾病）
以及每个国家和年份的两个独立流行病学变量（连续变量）：
var_a 和 var_b。

我想检查 var_a 如何在所有年份、国家和疾病中反映 var_b。
我应该执行哪种模型？简单的多变量线性模型应该没问题，还是任何多维相关性检验都应该更合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/661057/analyzing-epidemiological-variables-across-years-countries-and-diseases</guid>
      <pubDate>Thu, 06 Feb 2025 21:05:22 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程的后验和后验预测之间的差异</title>
      <link>https://stats.stackexchange.com/questions/661052/difference-between-the-posterior-and-posterior-predictive-of-a-gaussian-process</link>
      <description><![CDATA[这里也有一个类似的问题：高斯过程：后验分布与预测分布，但这个问题从未引起任何关注，因此我再次提出这个问题，尽管我的问题的重点在理解两者之间的差异方面略有不同。特别是，我正在阅读 Rasmussen 和 Williams 的《高斯过程》一书，并试图了解后验分布和后验预测分布有何不同。例如，请参见下图：

从幻灯片中，我了解到后验分布是 $f$ 的条件分布，而后验预测分布是 $x_*$ 位置处未见观测值 $y_*$ 的分布，但 $f$ 和 $y^*$ 直观上有何不同？仅假设没有与 $y_*$ 相同水平的噪声，后验分布是否与 $y_*$ 相同？最让我困惑的是，您经常会看到这样的图：

但我会根据上述后验分布公式假设它只是您观察到数据的分布，但图片到处都有不确定性带（即，对我来说，它感觉像是后验预测的图，因为在您尚未观察到的点处有预测和不确定性带）。任何帮助理解和消除我的困惑的帮助都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661052/difference-between-the-posterior-and-posterior-predictive-of-a-gaussian-process</guid>
      <pubDate>Thu, 06 Feb 2025 18:20:25 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制具有均匀边际的随机样本？</title>
      <link>https://stats.stackexchange.com/questions/661051/how-to-draw-a-random-sample-with-uniform-marginals</link>
      <description><![CDATA[我有一个包含 $k$ 个分类变量的总体。我知道这些类别的分布。我想从我的总体中随机选择一个样本，以便边际分布均匀。我不需要样本中类别的联合分布均匀（事实上，这可能是不可能的，因为某些组合的概率可能是 0），而只需要边际分布。
举例说明：
假设我有一个分类变量，它可以取 3 个不同的值。假设这 3 个类别在总体中的相对频率为 $[r_1, r_2, r_3], \Sigma r_i = 1$。我现在将从我的总体中随机选择一个个体，测量其类别为 $j$，并以 $\frac{1}{3 r_j}$ 的概率保留它（否则丢弃并重试）。然后，抽取具有属性 $j$ 的个体的概率为 $r_j * \frac{1}{3 * r_j} = \frac{1}{3}$。使用这种抽样机制，我可以从我的总体中抽取样本，使我的单个分类变量的分布均匀。
现在假设我有 两个 个分类变量，我想从我的总体中抽取样本，使 每个分类变量 的分布均匀。我该如何实现这一点？我如何将其扩展到 $k$ 个分类变量？假设每个变量总体中的边际概率分布对于每个类别都是 $&gt;0$。]]></description>
      <guid>https://stats.stackexchange.com/questions/661051/how-to-draw-a-random-sample-with-uniform-marginals</guid>
      <pubDate>Thu, 06 Feb 2025 17:43:52 GMT</pubDate>
    </item>
    <item>
      <title>如何获得没有下限的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/661049/how-to-get-a-confidence-interval-without-a-lower-bound</link>
      <description><![CDATA[这些是我想到的一些统计问题，我想问社区。

我想知道在美国历史上有多少人被判处死刑。我编写了一个计算机脚本，该脚本遍历维基百科并识别每个被判处死刑的人的名字。假设所有这些都是准确的，我发现总共有 $n$ 次处决（以及日期）。但是，我仍然相信可能有更多的人被处决但没有记录。但我确信这个数字不会少于记录的数字。我如何根据这些信息估算出真实的数字？

我去了一个小镇，想知道这个小镇在第二次世界大战 (WW2) 期间有多少人死亡。镇上的不同人（即样本）出示了他们祖先的死亡证明/军人信件，我确认所有这些人确实死亡了。最终，我得到了一个包含 $n$ 个独特名字的列表。但是，我相信实际死亡人数可能更多，但不会更少。我如何根据这些信息估算出真实数字？

在同一个城镇，我想知道有多少位美国前总统访问过这个城镇。同样，来自该镇（样本）的不同人带着照片/报纸文章来找我，每个人都告诉我访问过该镇的前总统的名字。当然，其中一些人会重复其他人提到的总统的名字。我得到了一个包含 $n$ 个独特总统名字的列表。但是，我相信实际访问过的总统可能比我被告知的要多，而不是更少。我如何根据这些信息估算出真实数字？


在所有这些问题中，我希望估算值具有可变性，但同时绝不会低于我观察到的数据。例如，X + (2.3% , 3.1%) 更高。即置信区间没有下限。
对于问题 1，我想记录每年发生多少次处决。我怀疑在现代（例如 &gt; 1900 年），数据更可能是完整的，但在此之前，数据更可能是不完整的。所以我会尝试看看是否有加权泊松分布可以支持旧数据.. 但我不确定如何创建置信区间。
我不确定如何回答问题 2 和 3。也许有一些生态/野生动物物种的方法可以提供帮助？也许是贝叶斯方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/661049/how-to-get-a-confidence-interval-without-a-lower-bound</guid>
      <pubDate>Thu, 06 Feb 2025 16:56:57 GMT</pubDate>
    </item>
    <item>
      <title>按时间序列建模百分比增长</title>
      <link>https://stats.stackexchange.com/questions/661046/modelling-percent-growth-in-time-series</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661046/modelling-percent-growth-in-time-series</guid>
      <pubDate>Thu, 06 Feb 2025 15:25:48 GMT</pubDate>
    </item>
    <item>
      <title>主效应显著，交互作用不显著，但其中一个主效应似乎是由事后交互作用比较之一驱动的</title>
      <link>https://stats.stackexchange.com/questions/661045/main-effects-significant-interaction-insignificant-but-one-main-effect-seems-to</link>
      <description><![CDATA[我是一名生态学家，正在运行一个全因子实验，检查两个解释变量对响应变量 (C) 的影响：饥饿（饥饿与不饥饿）和交配地点（食物与非营养物质）。我发现两个主效应都显著，但相互作用不显著。然而，从图形检查来看，主效应（饥饿）的显著性似乎是由不饥饿的个体在食物上的 C 大于饥饿的雄性所驱动的，而两种非营养物质饥饿处理中的 C 均值看起来非常相似。因此，我对相互作用进行了事后检验，并发现了确切的影响：未挨饿的雄性在食物上的 C 高于挨饿的雄性，但饥饿对非营养底物的 C 没有影响。
我之所以仔细研究这个问题，是因为我做了一个后续实验，发现饥饿对 C 没有影响（但这个实验只对非营养物质进行了研究）。
现在，通常情况下，我不会对第一个实验中的相互作用进行事后检验，因为它并不显著，但我想知道是否有任何方法可以协调这两个不同实验的结果？对我来说，它们似乎是内部一致的，但我也同意我本质上是在寻找结果来解释一种模式。在这里应该怎么做？
我的样本量很大，有足够的能力来检测任何相互作用。]]></description>
      <guid>https://stats.stackexchange.com/questions/661045/main-effects-significant-interaction-insignificant-but-one-main-effect-seems-to</guid>
      <pubDate>Thu, 06 Feb 2025 14:59:35 GMT</pubDate>
    </item>
    <item>
      <title>如何使用逆概率加权 (IPW) 解释抽样偏差：协变量选择和处理缺失数据的最佳实践</title>
      <link>https://stats.stackexchange.com/questions/661044/how-to-account-for-sampling-bias-using-inverse-probability-weighting-ipw-best</link>
      <description><![CDATA[我正在分析英国生物库 (UKB) 蛋白质组学数据，其中包括随机选择的参与者子集和非随机子集，例如 UKB-PPP 联盟选择的参与者和 COVID-19 研究的参与者。由于这些非随机选择可能会引入偏差，我正在考虑使用逆概率加权 (IPW)来解释潜在的选择偏差。
问题：

选择用于倾向得分估计的协变量


UKB-PPP 论文 [1] 没有提供有关参与者选择标准的完整详细信息（除非我忽略了某些内容）。由于在充分理解选择过程时 IPW 最有效，那么哪些协变量适合用于估计倾向得分？
在这种情况下，还有其他什么因素可能很重要？


处理蛋白质组学中的缺失数据


由于缺失数据因蛋白质而异，因此每种蛋白质的样本略有不同。是否应该计算蛋白质特异性倾向得分和权重，确保权重反映每个蛋白质具有非缺失数据的个体子集？
或者基于完整蛋白质组样本的一组权重是否更好？

如有任何关于在 UKB（或其他生物库数据）中类似应用 IPW 的建议或参考，我们将不胜感激！
参考文献
[1]Sun, B. B., Chiou, J., Traylor, M., Benner, C., Hsu, Y. H., Richardson, T. G., ... &amp; Whelan, C. D. (2023). Plasma proteomic associations with Genetics and Health in the UK Biobank. Nature, 622(7982), 329-338.]]></description>
      <guid>https://stats.stackexchange.com/questions/661044/how-to-account-for-sampling-bias-using-inverse-probability-weighting-ipw-best</guid>
      <pubDate>Thu, 06 Feb 2025 14:21:27 GMT</pubDate>
    </item>
    <item>
      <title>具有适度的多元回归？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/661043/multivariate-regression-with-moderation</link>
      <description><![CDATA[我希望在 R 中运行两个多元回归（多个 DV）和一个调节多元回归（参见下面的模型）。我对多元调节一无所知，所以我很纠结，非常感谢您的见解。我有以下问题：

我需要检查每个回归的假设是什么？
由于多变量 regs 是综合测试，我如何检查 IV 和每个 DV 之间的关联？
我是否在调节模型中包含所有 DV，还是只包含与我的调节器显着相关的 DV？
我只能运行模型 3 吗（因为它已经完成了 1 和 2 所做的事情）？

H1_reg&lt;-lm(cbind(DV1, DV2, DV3, DV4, DV5) ~
IV1,data=filtered_data)
H2_reg&lt;-lm(cbind(DV1, DV2, DV3, DV4, DV5) ~
IV2,data=过滤数据)
Mod_reg &lt;- lm(cbind(DV1, DV2, DV3, DV4, DV5) ~
IV1 * IV2, 数据 = 过滤数据)]]></description>
      <guid>https://stats.stackexchange.com/questions/661043/multivariate-regression-with-moderation</guid>
      <pubDate>Thu, 06 Feb 2025 13:32:25 GMT</pubDate>
    </item>
    <item>
      <title>书籍推荐：VAR(1)模型中的估计</title>
      <link>https://stats.stackexchange.com/questions/661040/book-recommendation-estimation-in-var1-model</link>
      <description><![CDATA[希望自学时间序列VAR(1)模型的估计方法（例如OLS、MLE）。
我对估计量的一阶（$E|\hat{\theta}_n-\theta|$）和二阶（$E|\hat{\theta}_n-\theta|^2$）收敛性质特别感兴趣。
请推荐一本涵盖这些内容的书。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661040/book-recommendation-estimation-in-var1-model</guid>
      <pubDate>Thu, 06 Feb 2025 12:42:34 GMT</pubDate>
    </item>
    <item>
      <title>安德森-吉尔模型是否严格模拟事件重复发生的风险或事件之间的时间？</title>
      <link>https://stats.stackexchange.com/questions/661025/does-the-andersen-gill-model-strictly-model-the-hazard-of-an-event-recurring-or</link>
      <description><![CDATA[如果我对协变量对复发事件间隔时间的影响感兴趣，也就是说，我想探索特定协变量是否会缩短或延长后续事件之间的间隔，像 Andersen-Gill 模型这样的复发事件 Cox 比例风险模型是否可以做到这一点？或者，这些模型是否严格模拟事件复发的风险，并计算协变量如何增加或减少事件复发的风险？]]></description>
      <guid>https://stats.stackexchange.com/questions/661025/does-the-andersen-gill-model-strictly-model-the-hazard-of-an-event-recurring-or</guid>
      <pubDate>Thu, 06 Feb 2025 02:19:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么 CL% 的 CI 必须正确捕获参数？（证明）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/661020/why-must-a-cl-of-cis-correctly-capture-the-parameter-proof</link>
      <description><![CDATA[据我所知，如果我们取一个样本，我们可以从该样本构建一个置信区间。如果我们从不同的样本中获取许多这样的置信区间，则正确的百分比将等于置信水平。有什么证据表明置信区间公式保证这是正确的？需要说明的是，我主要讨论的是比例。
我使用的公式是：
$$CI = \hat{p} \pm z^\star\sqrt{\frac{(\hat{p})(1-\hat{p})}{n}}$$
其中 $\hat{p}$ = 样本比例
$n$ = 样本大小
$z^\star$ = 置信水平的临界值
$CI$ = 置信区间
我使用了一个简单的随机样本作为样本。]]></description>
      <guid>https://stats.stackexchange.com/questions/661020/why-must-a-cl-of-cis-correctly-capture-the-parameter-proof</guid>
      <pubDate>Thu, 06 Feb 2025 00:12:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么 mgcv GAM 中的 p 值有时正好为零？</title>
      <link>https://stats.stackexchange.com/questions/660994/why-p-values-are-sometimes-exactly-zero-in-mgcv-gam</link>
      <description><![CDATA[我正在使用 GAM 来模拟表型水平如何随时间变化。我们对 4 个时间点进行了表型测量。当时间有显著影响时，时间平滑项的 p 值等于 0。这是一个模拟示例：
d &lt;- data.frame(x = c(rep(1,20), rep(2,20), rep(3,20), rep(4,20)), 
+ y = c(rnorm(20, 0.5, 0.5), rnorm(20, 0.2, 0.5), rnorm(20, -0.2, 0.5), rnorm(20, -0.5, 0.5)))

m &lt;- gam(y ~ s(x, k = 4), data = d, method = &#39;REML&#39;)

数据如下所示：

因此，时间的影响确实不是一条水平线，因此是显著的。我知道 GAM p 值只是近似值，但有人能解释一下为什么在这种特殊情况下无法计算出更精确的 p 值吗？我是不是做错了什么，有没有办法得到一个不同于 0 的值？
（在这个特殊情况下，依赖关系是线性的，我可以使用线性回归，但在我的数据中，我经常有我想研究的非线性关系）。
summary(m) 的输出：
系列：高斯 
链接函数：恒等 
公式：
y ~ s(x, k = 4)
参数系数：
估计标准误差 t 值 Pr(&gt;|t|) 
（截距）0.05883020 0.03378357 1.74139 0.085559 .
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df F p 值 
s(x) 1.000016 1.000031 157.0853 &lt; 2.22e-16 ***
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) = 0.664 偏差解释 = 66.8%
-REML = 21.711 尺度估计 = 0.091306 n = 80

以及平滑项的单独摘要：
s(x) 1.000015629 1.000031257 157.0852647 0

任何帮助都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660994/why-p-values-are-sometimes-exactly-zero-in-mgcv-gam</guid>
      <pubDate>Wed, 05 Feb 2025 14:58:39 GMT</pubDate>
    </item>
    <item>
      <title>引导和选择调整</title>
      <link>https://stats.stackexchange.com/questions/660993/bootstrap-and-adjustment-for-selection</link>
      <description><![CDATA[假设我有许多平均值，$\{ \bar{X}^* \}_{i=1}^m$，每个平均值都是使用 $n$ 个观测值估算的。平均值是位置参数 $\{ \theta \}_{i=1}^m$ 的估计值。我对最大 $\theta$ 感兴趣，我可以使用 bootstrap 构建一个考虑选择的置信区间吗？
我可以想到几种可能的策略，估算所有 $\theta$ 的最大偏差。即，在 bootstrap 样本 $j$ 中获取最大偏差：
$$ B_j = \max_i (\bar{X}^j_i- \bar{X}_i^*), $$
或来自最大估计的偏差，
$$ B_j = \max_i (\bar{X}^j_i - \max_k \bar{X}_k^*). $$
第二个问题是，这是否可用于构建置信区间？任何参考资料都很好。
以下采用了类似的策略（用于子组识别和推断），他们声称即使子组数量无限，它也是可用的。 - Guo X, He X. Inference on selected subgroups in clinical trials.
他们使用了一种更复杂的方法，但本质上他们使用了偏差估计$ B_j = \max_i (\bar{X}^j_i - \max_k \bar{X}_k^*). $（参见论文中的算法 3）。]]></description>
      <guid>https://stats.stackexchange.com/questions/660993/bootstrap-and-adjustment-for-selection</guid>
      <pubDate>Wed, 05 Feb 2025 13:37:29 GMT</pubDate>
    </item>
    <item>
      <title>使用小样本校正对后双套索估计残差进行校正</title>
      <link>https://stats.stackexchange.com/questions/660954/using-small-sample-correction-for-estimated-residuals-in-post-double-lasso</link>
      <description><![CDATA[后双重选择是一种在高维稀疏模型中对低维参数进行推理的方法。原始论文之一由Belloni、Chernozhukov 和 Hansen (2014) 在 ReStud 中撰写。他们考虑了一个部分线性模型：
\begin{align*} 
y_i &amp;= d_i \alpha_0 + g(z_i) + \zeta_i, &amp;E[\zeta_i | z_i, d_i] = 0 \\
d_i &amp;= m(z_i) + \nu_i, &amp;E[\nu_i | z_i] = 0。
\end{align*&gt;
用他们的话来说，该方法可以总结如下：

在第一步中，我们选择一组可用于预测治疗$d_i$的控制变量。此步骤有助于通过查找与治疗密切相关的控制变量（因此可能是重要的混杂因素）来确保模型选择后推断的有效性。
在第二步中，我们通过选择预测$y_i$的控制变量来选择其他变量。此步骤有助于确保我们已捕获感兴趣的方程中的重要元素，理想情况下有助于保持残差方差较小，并提供额外的机会来找到重要的混淆因素。
在最后一步中，我们通过$y_i$对治疗$d_i$的线性回归以及在两个变量选择步骤中选择的变量集的并集来估计感兴趣的治疗效果$\alpha_0$。

他们的主要理论结果如下图所示。这里 $\widehat{s}$ 表示上述算法中回归步骤 3 中包含的回归量的数量（即步骤 1 和 2 的并集）。

可以看出，为了估计估计量的方差，人们使用 $\widehat{\zeta}_i$ 和 $\widehat{\nu}_i$ 来估计残差。为了估计 $\widehat{\zeta}_i$，我们使用了小样本偏差校正，类似于用于估计经典样本方差的偏差校正。这在高维设置中很有意义，因为可以想象 $\widehat{s}$ 可能接近 $n$。当使用$\widehat{s} \geq n$时，甚至可以得到全为零的残差，这将为模型中的真实误差提供非常差的估计。
有谁知道或直觉为什么不应用这种偏差校正$\widehat{\nu}_i$？我们还针对此回归采用了变量选择，并且非零回归量的数量可能相对接近$n$，但为什么每次回归都不同？
我的问题与此帖子有关，但略有不同，因为该问题侧重于特定的 stata 实现，而我的问题是关于不使用偏差校正$\widehat{\nu}_i$背后的直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/660954/using-small-sample-correction-for-estimated-residuals-in-post-double-lasso</guid>
      <pubDate>Tue, 04 Feb 2025 14:07:16 GMT</pubDate>
    </item>
    <item>
      <title>McNemar 检验是否适合前后比较？</title>
      <link>https://stats.stackexchange.com/questions/660806/is-mcnemars-test-suitable-for-before-after-comparisons</link>
      <description><![CDATA[如果我理解正确的话，McNemar 检验通常用于测试两个二元结果之间的依赖关系。Agresti 在《分类数据分析》（我相信是 2002 年版）中给出了两个与环境相关的问题的示例，受试者同时回答这些问题。我提供了我自己的示例，其中的数字被夸大了，以便进行演示：
 Q2
Q1 同意 不同意
同意 945 5
不同意 10 40

在这里，我可以看到 McNemar 的检验是有道理的：大多数人同意这两个陈述，一些人同意其中一个而不同意另一个，还有少数人不同意两者。这听起来很合理。 p 值为 0.2，即两个问题的同意率没有显著差异。
但是，McNemar 检验也用于比较前后结果，如 Agresti 书中早期版本 (1990) 中的示例。因此，让我们使用上述数字，但将它们视为受试者对一个问题的回答，但在两个不同的时间点，$T_1$ 和 $T_2$。在这两个时间点，他们可能“同意”或“不同意”：
 T2
T1 同意 不同意
同意 945 5
不同意 10 40

由于计数的巨大不平衡，我发现 McNemar 检验中暗示的情景难以置信。我们想看看受试者是否会随着时间的推移而改变主意，结果发现一组（$T_1$ 的“同意者”）几乎没有变化（~0.5%），而“不同意者”则发生了很大变化：在 $T_1$ 不同意的受试者中，约有 20% 在 $T_2$ 同意。我认为这是一个“显著”的差异，但由于表中的数字与第一个示例中的数字相同，因此 McNemar 的检验仍然不显著。
在 $H_0$ 下，非对角线单元格中的绝对数字需要相似，而不是百分比。为了得到相似的数字，“T1 同意者”需要以与“不同意者”不同的概率改变主意，但这两个概率必须相关。换句话说，$H_0$ 意味着两组之间存在某种信息交换。或者，换句话说，“非对角线概率之间没有差异”假设可能意味着行概率之间存在相当大且非常精确的差异。这对我来说似乎非常不随机 - 与人们对零假设的期望完全相反。
或者我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660806/is-mcnemars-test-suitable-for-before-after-comparisons</guid>
      <pubDate>Fri, 31 Jan 2025 14:13:43 GMT</pubDate>
    </item>
    </channel>
</rss>