<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 01 Dec 2023 15:14:25 GMT</lastBuildDate>
    <item>
      <title>将一维数据拆分为箱或桶</title>
      <link>https://stats.stackexchange.com/questions/632806/splitting-one-dimensional-data-into-bins-or-buckets</link>
      <description><![CDATA[我有一个一维数据，我的任务是使用它来推断值。
粗略地说，我有回收率，我必须将它们分成多个箱，然后计算每个箱中这些回收率的倒数 (1/R)，然后取它们的平均值，然后我将使用这个平均值来推断预期的回收率对于其他案例，取决于案例属于哪个垃圾箱。
现在，我的数据看起来与此类似：

接近 0 的值将具有非常高的逆值，接近 1 的值将具有非常低的逆值，并且我还必须处理落在此 [0;1] 范围之外的随机异常值。
我尝试了 K 均值，但由于异常值，我最终得到只有一个观测值的簇，我正在考虑使用 K 均值，但每个桶的观测值数量最少，但我首先需要实现它，但我不是确定它是否适合该问题。
我在这里阅读了有关基于 KDE 拆分数据的方法的帖子，但我不相信这对我的情况有帮助，但我可能误解了它。
我应该探索哪些候选的分桶方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/632806/splitting-one-dimensional-data-into-bins-or-buckets</guid>
      <pubDate>Fri, 01 Dec 2023 14:50:48 GMT</pubDate>
    </item>
    <item>
      <title>概率的收敛性和概率相对于样本均值和样本方差的有界性</title>
      <link>https://stats.stackexchange.com/questions/632804/convergence-in-probability-and-boundness-in-probability-with-respect-to-sample-m</link>
      <description><![CDATA[这是一个关于概率收敛和概率有界的问题。
假设 $X_i \overset{\textrm{i.i.d.}}{\sim} (\mu, \sigma^2 )$ 为 $i=1,2, \cdots, n$。
表示 $\overline{X}$ 和 $\hat{{\sigma^{2}}}$  分别作为样本均值和样本方差。
然后证明以下对于每个 $x \in \mathbb{R}$ 成立。
$$\frac{x-\overline{X}}{\hat{\sigma^2}}-\frac{x-\mu}{\sigma^2 } = O_p (n^{-1/2}) $$
中心极限定理、强大数定律、斯卢茨基定理可用。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/632804/convergence-in-probability-and-boundness-in-probability-with-respect-to-sample-m</guid>
      <pubDate>Fri, 01 Dec 2023 14:38:24 GMT</pubDate>
    </item>
    <item>
      <title>如果在参数空间中设置高斯先验，我可以使用方差作为 Hessian 的对角线吗？</title>
      <link>https://stats.stackexchange.com/questions/632803/if-is-set-a-gaussian-prior-in-the-parameter-space-can-i-use-the-variance-as-dia</link>
      <description><![CDATA[假设我有一个神经网络，我在参数上放置了高斯先验 $\theta_i \sim N(\mu_i, \sigma_i^2)$ 和我通过重新参数化技巧 $\mu$ 和 $\sigma$数学容器&quot;&gt;$f = \mu + \epsilon \cdot \sigma$
训练后，我将为每个权重提供相应的 $\mu, \sigma$
我的问题是，我可以将 $sigma$ 视为“代理”吗？为 Hessian 矩阵的对角线？
在我看来，它是有效的，因为 $\sigma &gt;&gt;0$ 意味着该参数对于大的变化相当不变，因此应该有一个相当大的二阶导数，对吧？]]></description>
      <guid>https://stats.stackexchange.com/questions/632803/if-is-set-a-gaussian-prior-in-the-parameter-space-can-i-use-the-variance-as-dia</guid>
      <pubDate>Fri, 01 Dec 2023 14:38:15 GMT</pubDate>
    </item>
    <item>
      <title>求正态分布随机变量的方差</title>
      <link>https://stats.stackexchange.com/questions/632802/finding-variance-of-a-normally-distributed-random-variable</link>
      <description><![CDATA[假设我们有 $n$ 个观测值作为 i.i.d.来自正态分布的样本。我们有共轭先验分布，即真实平均值 $(\mu)$ 的先验分布也是正态分布，先验平均值为 50 且有一些方差。另外，假设我们知道真实均值不能低于 0 或高于 100。最好对真实均值使用先验方差，这样几乎不会出现超出此范围的概率。 $\mu$ 的先验方差为 $(50/2)^2=625$，因此先验概率 $Pr(\mu\notin[0,100])=0.05$。
我不明白为什么先验方差是通过$(\text{priormean}=50/2)^2$计算的？]]></description>
      <guid>https://stats.stackexchange.com/questions/632802/finding-variance-of-a-normally-distributed-random-variable</guid>
      <pubDate>Fri, 01 Dec 2023 14:35:07 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn 高斯过程回归器过度拟合</title>
      <link>https://stats.stackexchange.com/questions/632801/sklearn-gaussian-process-regressor-overfitting</link>
      <description><![CDATA[我正在测试一组回归算法，但在使用 GPR 时遇到了问题。我有一组 60 个观测值 x 101 个变量作为预测变量 (X)，而一组 60 个观测值 x 1 个变量作为响应 (y)。鉴于 X 的 101 个元素代表高光谱数据集的多个波长，我应用 PCA 来减少共线性。
我正在运行以下代码
scaler=preprocessing.StandardScaler().fit(X)
xscaled=scaler.transform(X)
ncomps=2
pca=PCA(n_components=ncomps)
xpca=pca.fit_transform(xscaled)

后来我按如下方式运行 GPR：
kernel=ConstantKernel(1.0) * RBF(1.0)
gpr=GaussianProcessRegressor(kernel=kernel,normalize_y=False).fit(xpca,y)
y_gpr=gpr.预测(xpca)
r2g=r2_score(y,y_gpr)
mseg=均方误差(y,y_gpr)
print(&#39;GPR: R2: %0.4f, MSE: %0.4f&#39; %(r2g,mseg))

打印结果为
探地雷达：R2：1.0000，MSE：0.0000
现在这显然不是一个好的结果，但我不知道如何让它变得更好。任何建议都会非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/632801/sklearn-gaussian-process-regressor-overfitting</guid>
      <pubDate>Fri, 01 Dec 2023 14:33:19 GMT</pubDate>
    </item>
    <item>
      <title>感知目标变量的离群值检测方法</title>
      <link>https://stats.stackexchange.com/questions/632795/outlier-detection-methods-aware-of-target-variable</link>
      <description><![CDATA[我正在尝试根据之前的需求、天气、大型人群聚集和类似的时空因素来预测美国某个城市地区未来一小时的救护车需求。
我注意到一些特征是“平常”的 - 例如阳光明媚、宁静的周日下午，但需求异常高 - 可能是因为一场重大交通事故 - 我没有任何数据。
因此，我决定尝试异常值检测并消除那些目标不依赖于我拥有的数据而是依赖于其他东西的点，例如导致某些人受伤但无法预测的意外火灾.
我不喜欢像 IQR 和 z 分数这样的单变量方法，因为一些高要求实际上可能取决于数据 - 恶劣天气、我有数据的大型聚会等。
另一方面，多变量无监督方法可能会检测到异常恶劣的天气，因为它们不知道目标变量是什么，并与整个数据集一起尝试找到不规则模式。
我无法使用需要“异常值”标签的监督方法，因为我还不知道什么是异常值 - 我需要一个算法，这就是我的实际目标。
我的问题是：是否有异常值检测方法可以知道目标变量是什么？
例如：假设我构建了一个所有阳光明媚、宁静的周日下午的集群，并检查需求。我可能会看到：[1, 2, 0, 2, 1, 11, 2, 0]
那么 11 是一个异常值，因为它属于“常规”周日下午的集合，通常需求约为 1。
是否已经有方法可以做到这一点？
如果没有，您建议我做什么？
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/632795/outlier-detection-methods-aware-of-target-variable</guid>
      <pubDate>Fri, 01 Dec 2023 13:19:41 GMT</pubDate>
    </item>
    <item>
      <title>将中心极限定理应用于分段 PDF</title>
      <link>https://stats.stackexchange.com/questions/632793/applying-the-central-limit-theorem-to-a-piecewise-pdf</link>
      <description><![CDATA[对于大小为 1296 的大样本，我们正在研究由分段概率密度函数定义的独立且同分布的随机变量 $f(x) = \frac{1}{ 3} (I_{(0,1)}(x) + I_{(3,5)}(x))$
(a) 我试图找到 $ Y = |X_1 - 2| 的累积分布函数 (CDF) $。我的方法是用 Y 求出 X，代入 pdf，然后考虑绝对值，在各个区间内对 PDF 进行积分。如果有人能够审查我的方法并纠正任何可能的错误，我将不胜感激。
(b) 对于如此大的样本，我被要求使用中心极限定理来近似 $ P\left(\sum_{i=1}^{1296} X_i \leq 3600\right) $.我知道中心极限定理保证 $X$ 的总和将服从正态分布，但是我如何找到此正态分布的参数：$\mu, \sigma$?]]></description>
      <guid>https://stats.stackexchange.com/questions/632793/applying-the-central-limit-theorem-to-a-piecewise-pdf</guid>
      <pubDate>Fri, 01 Dec 2023 13:15:11 GMT</pubDate>
    </item>
    <item>
      <title>“因果关系、预测和搜索”中的 PC 算法</title>
      <link>https://stats.stackexchange.com/questions/632792/pc-algorithm-in-causation-prediction-and-search</link>
      <description><![CDATA[在《因果关系、预测与搜索》第143页中，为什么如果错误地从初始完整图中删除了边E-D，则边B-D不会被删除。我认为 B-D 是给定 C 的 D 连接，因为 C 是路径 B-C-E-D 中的对撞机。]]></description>
      <guid>https://stats.stackexchange.com/questions/632792/pc-algorithm-in-causation-prediction-and-search</guid>
      <pubDate>Fri, 01 Dec 2023 13:11:20 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 R 通过层次聚类分析确定哪些变量对于定义每个聚类最重要</title>
      <link>https://stats.stackexchange.com/questions/632789/how-to-determine-which-variables-are-the-most-important-to-define-each-cluster-f</link>
      <description><![CDATA[经过几天的搜索、阅读帖子并尝试自己解决此问题后，我认为是时候寻求帮助了。
我正在对一个数据集执行层次聚类分析，其中包括数百个样本和数千个变量。一旦获得最佳聚类数量、图形表示以及包含样本/聚类关系的表格，就可以找出哪些变量对于定义每个聚类最重要。我正在寻找一种方法来获取一个表，其中每个变量都分配给它贡献最大的簇（例如变量 X/簇 N）
你知道任何 R 包或任何代码片段可以让我做到这一点吗？目前，我已使用以下 R 包进行其余的分析（cluster、factoextra、NbClust、caret 和 dendextend），但是，我一直无法找出使用它们来实现最终目标的任何方法。 
任何帮助将不胜感激。
提前致谢。
JL]]></description>
      <guid>https://stats.stackexchange.com/questions/632789/how-to-determine-which-variables-are-the-most-important-to-define-each-cluster-f</guid>
      <pubDate>Fri, 01 Dec 2023 12:53:35 GMT</pubDate>
    </item>
    <item>
      <title>唯一概率密度函数的最大似然估计</title>
      <link>https://stats.stackexchange.com/questions/632787/maximum-likelihood-estimation-for-a-unique-probability-density-function</link>
      <description><![CDATA[在估计一组唯一分布的独立且同分布的随机变量的参数的背景下，我正在检查以下概率密度函数 $ f(x|\theta) = \ frac{3\theta^3}{x^4} \mathbf{1}_{[\theta,\infty)}(x) $ 与 $ \theta &gt; 0 $.
(a) 对于估计，我的任务是根据样本 $ \theta $ 的最大似然估计量 (MLE)数学容器&quot;&gt;$ X_1, \ldots, X_n $。我首先设置似然函数并对 $ \theta $ 求导，但我总是得到  $\hat{\theta} = 0$ 因为：
$$\frac{\partial l(\theta \mid X)}{\partial \theta} = \frac{3n}{\theta}$$
这是正确的吗？
(b) 导出 MLE 后，我需要确定其分布以及估计器对于 $ \theta $ 是否无偏。我知道估计量的无偏性与其等于参数的期望值有关。但是，我很难找到 MLE 的分布，我该怎么做？ MLE 的分布是否有任何定理，或者是否存在隐藏的“提示”？在问题中？]]></description>
      <guid>https://stats.stackexchange.com/questions/632787/maximum-likelihood-estimation-for-a-unique-probability-density-function</guid>
      <pubDate>Fri, 01 Dec 2023 12:38:37 GMT</pubDate>
    </item>
    <item>
      <title>球形假设是否适用于线性混合模型？</title>
      <link>https://stats.stackexchange.com/questions/632786/does-the-sphericity-assumption-apply-to-linear-mixed-models</link>
      <description><![CDATA[我最近被要求检查我的数据的球形度，以确认它满足我生成的线性混合模型的假设（使用 R 中的 lmerTest）。我读过关于球形度是否确实是 LMM 的假设的相互矛盾的信息。 (1) 球形度是 LMM 的假设吗？(2) 如果是，我该如何解决非球形度问题？
我的模型包括连续变量和分类变量，以受试者 ID 作为随机截距，以考虑每个受试者的多个观察结果。
类似于：
y ~ 年龄 + 性别 + (1 | id)]]></description>
      <guid>https://stats.stackexchange.com/questions/632786/does-the-sphericity-assumption-apply-to-linear-mixed-models</guid>
      <pubDate>Fri, 01 Dec 2023 12:36:32 GMT</pubDate>
    </item>
    <item>
      <title>如何估计分类数据 (SEM) 的因子得分？</title>
      <link>https://stats.stackexchange.com/questions/632785/how-are-factor-scores-estimated-for-categorical-data-sem</link>
      <description><![CDATA[在 Mplus 讨论页面上，Muthén 说了以下内容 (2000)：
&lt;块引用&gt;
WLSMV 估计器用于分类结果。不像
连续结果，分类结果为因子得分
系数矩阵不用于生成因子得分。反而，
每个人的因素得分必须通过迭代来估计
技术（请参阅 Mplus 用户指南中的附录 11）。

这个迭代过程需要什么？例如，正在优化什么目标函数（如果有）？
有任何需要研究的文档/文献/论文的指示吗？我找不到所引用的附录（或者我无权访问它），并且我在谷歌上搜索其他有用的参考资料也不是很成功。
请注意，我的目标是了解发生了什么（即如何获得分类数据的因子得分）；我不是在寻找只给出最终结果的一行代码。
也许不相关：假设我通过 DWLS 估计了我的模型。
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/632785/how-are-factor-scores-estimated-for-categorical-data-sem</guid>
      <pubDate>Fri, 01 Dec 2023 12:36:20 GMT</pubDate>
    </item>
    <item>
      <title>请问有人可以解释一下这个多元泰勒展开式的表示法吗？</title>
      <link>https://stats.stackexchange.com/questions/632777/please-can-someone-explain-the-notation-of-this-multivariate-taylor-expansion</link>
      <description><![CDATA[Kamanzi-wa-Binyavanga，2009 年撰写了以下论文：计算泰勒累积量
多元函数的展开：

我感到困惑的是，这种符号的精确程度。我知道我们对 $1$ 之间的某个点（$r,s,t$ 此处）取每个偏导数 和 $p$，这可能是统计设置中回归量的数量。我不明白的是：

为什么我们必须对每个 $r,s,t$ 单独求和？
为什么他对 $z$ 和 $s$ 求和，而不是 $r$ 和 $s$ 进行双重求和
为什么他实际上说这些总和是从 1 到 $p_i$。我是否正确地说，例如，第三个应该看起来像 $\frac{1}{3!}\sum_{r=1}^{p_i}\sum_{s= 1}^{p_i}\sum_{t=1}^{p_i}$。
最后，这可能看起来很简单，但如果我想要整个函数的泰勒展开 $Y$，我只需添加 $c$ 之前的container&quot;&gt;$\sum_{i=1}^{q}$？

任何帮助/澄清将不胜感激。我正在尝试学习在这种情况下使用爱因斯坦表示法，但我需要首先准确理解这种展开式。]]></description>
      <guid>https://stats.stackexchange.com/questions/632777/please-can-someone-explain-the-notation-of-this-multivariate-taylor-expansion</guid>
      <pubDate>Fri, 01 Dec 2023 10:47:35 GMT</pubDate>
    </item>
    <item>
      <title>如何理解计算样本方差有n-1个自由度？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/632769/how-to-understand-that-there-are-n-1-degrees-of-freedom-in-calculating-sample</link>
      <description><![CDATA[根据维基百科：
在统计学中，自由度数是统计数据最终计算中可以自由变化的值的数量。[1]统计参数的估计可以基于不同量的信息或数据。参与参数估计的独立信息的数量称为自由度。一般来说，参数估计的自由度等于进入估计的独立分数的数量减去用作参数本身估计的中间步骤的参数的数量。例如，如果要根据独立分数的随机样本来估计方差，则自由度等于独立分数的数量 (N) 减去作为中间步骤估计的参数数量（一，即样本平均值），因此等于 N-1。[2]
参考：https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)
我很困惑，因为我们知道样本平均值，这意味着 $n$ 观测值已经知道，所以为什么我们可以让 $n-1$ 观察值可以自由变化吗？我查看了一些视频和博客：大多数都通过一个例子解释说，如果我们有 3 个样本并且知道样本均值，则其中两个可以自由变化，而第三个观察值将由样本均值确定。但如果我们已经知道样本意味着为什么其中两个可以自由变化？我认为这三个观察结果是固定的。]]></description>
      <guid>https://stats.stackexchange.com/questions/632769/how-to-understand-that-there-are-n-1-degrees-of-freedom-in-calculating-sample</guid>
      <pubDate>Fri, 01 Dec 2023 07:51:05 GMT</pubDate>
    </item>
    <item>
      <title>作为检验统计量，似然比何时以及为何优于差异？</title>
      <link>https://stats.stackexchange.com/questions/632759/when-and-why-is-a-likelihood-ratio-preferable-to-a-difference-as-a-test-statisti</link>
      <description><![CDATA[我们想知道两个样本集 {x} 和 {y} 是否来自同一分布。原假设 $H_0$ 是的。作为统计学家，我们通过计算 p 值来检验假设：如果零假设正确，则观察到这些样本数据的概率。
作为使用计算机的统计学家，我们可以避免过多思考其分布特征，而只需对我们关心的任何统计数据进行排列测试。嗯，我们之前说过我们关心它们是否不同。所以我想我们必须想出一些 MLE $\hat{\theta}$，然后看看区别： $\hat{\theta_x}-\hat{\theta_y}$，对吗？
但是我们一直在阅读有关似然比检验的所有内容，它有一些不错的功能和区别只是对数空间中的比率，因此：对比率运行排列测试有优势$\frac{\hat{\theta_x}}{\hat{\ theta_y}}$ 而不是差异？ IIUC，通过威尔克斯定理，使用比率让我们陷入一种情况，我们近似 $\chi^2$ 分布。但我们已经决定我们的计算机可以进行排列测试 - 对于小样本量甚至可能是详尽的 - 在实践中这不是比仅渐近正确的封闭式解决方案更可取吗？
或者，如果我们将 LRT 与排列概念结合起来并查看 $\frac{\hat{\theta_{xy}}}{\hat{\ theta_x}\hat{\theta_y}}$？]]></description>
      <guid>https://stats.stackexchange.com/questions/632759/when-and-why-is-a-likelihood-ratio-preferable-to-a-difference-as-a-test-statisti</guid>
      <pubDate>Fri, 01 Dec 2023 01:45:01 GMT</pubDate>
    </item>
    </channel>
</rss>