<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 28 May 2024 21:14:46 GMT</lastBuildDate>
    <item>
      <title>通过肉眼聚类对跨时间重复测量进行 ICC</title>
      <link>https://stats.stackexchange.com/questions/648168/icc-for-repeated-measures-across-time-with-clustering-by-eye</link>
      <description><![CDATA[我试图评估参与者眼睛在 2 个时间点（基线和 2 个月）的测量结果中的 ICC，因此每行代表一只眼睛，有些参与者在研究中包括两只眼睛。
我能够使用 R 中 psych 包中的 ICC() 命令，如下所示：
&gt; head(data1) 

ID eye var_baseline var_2months
1 L 75 63
1 R 56 67
2 L 54 NA
4 L 78 61
4 R 60 65
6 L 80 81

&gt; ICC(data1[,c(&quot;var_baseline&quot;,&quot;var_2months&quot;)], missing=TRUE, alpha=0.05,lmer=TRUE) 

我使用的是 ICC(3,1)，因此假设时间点是固定的，我感兴趣的是这两个时间点之间的测量一致性。
问：如何解释 ICC 估计中眼睛的额外聚类？
在将数据重塑为长格式后，我使用以下公式拟合了一个 lmer 模型，并在 ID 和 eye 中指定了嵌套结构：
formula1 &lt;- var ~ time + (time | ID/eye)

m1 &lt;- 
lmerTest::lmer(
formula = formula1,
data = data.frame(data1),
control = lmerControl(check.nobs.vs.nRE = &quot;ignore&quot;),
na.action = na.exclude
)

我的随机效应如下所示：
随机效应：
组名称方差标准差校正
eye:ID（截距） 25.0782 5.0078 
time1 5.5080 2.3469 0.15
ID（截距） 30.5598 5.5281 
time1 0.3977 0.6307 0.32
残差 6.9562 2.6375 

我不确定是否可以使用提供的方差分量计算 ICC。或者，是否适合使用 lmer 中的以下公式来拟合不以时间作为随机斜率的模型：
var ~ time + (1| ID/eye)

上述模型具有以下随机效应：
随机效应：
组名称方差标准差
eye:ID（截距）23.143 4.811 
ID（截距）31.354 5.600 
残差 9.893 3.145 

是否有一种方法可以计算两次重复测量（在两个时间点）的类内相关系数 (ICC)，同时考虑聚类，例如参与者中有两只眼睛？
谢谢，任何帮助都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/648168/icc-for-repeated-measures-across-time-with-clustering-by-eye</guid>
      <pubDate>Tue, 28 May 2024 20:33:45 GMT</pubDate>
    </item>
    <item>
      <title>单向方差分析是否显著，但其趋势分析是否不显著</title>
      <link>https://stats.stackexchange.com/questions/648167/can-a-one-way-anova-be-significant-but-have-its-trend-analysis-be-non-significan</link>
      <description><![CDATA[假设我们发现单向方差分析具有统计显著性。在运行方差分析之前，我们决定运行趋势分析（H0：没有线性效应 H1：有线性效应）。
会不会是我们的单向方差分析显著但趋势分析不显著？
反之亦然，会不会是我们的方差分析不显著而趋势分析显著？]]></description>
      <guid>https://stats.stackexchange.com/questions/648167/can-a-one-way-anova-be-significant-but-have-its-trend-analysis-be-non-significan</guid>
      <pubDate>Tue, 28 May 2024 20:01:29 GMT</pubDate>
    </item>
    <item>
      <title>如何在三级模型中分析组内方差随时间变化的组间差异？</title>
      <link>https://stats.stackexchange.com/questions/648165/how-to-analyze-between-group-differences-in-within-group-variances-over-time-in</link>
      <description><![CDATA[我使用的数据是在学校的体能监测计划中收集的。在这些学校中，要么没有干预，要么健康生活方式干预，要么健康学校网络干预，要么两种干预都采用。我们根据体重状况将儿童分为 3 组，即体重正常、超重或肥胖的儿童。所包含的体能测试每年在相等的时间间隔（总共 10 个时间点）测量不同的组成部分（例如，跳远、600 米跑、倒退障碍训练等）。因此，在我的研究中，我考虑了随着时间的推移（10 个相等间隔的时间点），组间（即，没有干预、健康生活方式干预、健康学校网络干预、两种干预）组内（体重正常、超重或肥胖的儿童）方差的变化是否可能存在差异。我很难找到合适的方法，因为我不仅对平均值的变化感兴趣，而且对随时间的变化也感兴趣。具体来说，研究问题旨在回答不同的干预措施是否会增加/减少/对按体重状态（体重正常、超重或肥胖的儿童）划分的儿童组之间的体能测试分数差异产生影响。我还掌握了学校层面的信息，所以我想将其考虑在内，并将其表示为一个多级（3 级）模型。
在我的数据中，我对 264 642 名分为两个年龄组（年龄较大和较小，平均分配）的个人进行了 475 155 次观察。在不同的时间点，有这么多的观察结果：0：71033、1：85154、2：85984、3：87332、4：90888、5：96551、6：101337、7：106451、8：104671、9：80931。

第 3 级还有 452 所独特的学校。
我使用 R 中的 nlme 包在 MLM 框架中构建了一个模型（按性别划分），其中包含所有感兴趣的预测因子（时间点是连续的，范围从 0-9；pheight 是身高百分位数，用于解释成熟度差异）：
full_modelboys &lt;- lme(pr600 ~ 1 + (time_point + I(time_point^2))*weight_status*intervention + age_group + pheight,
random = ~ 1 + (time_point + I(time_point^2)) | school/unique_id, 
data = df_boys,
na.action = na.omit,
method = &quot;ML&quot;,
control = lmeControl(opt = &quot;optim&quot;))

提前非常感谢您，即使您只是将问题读到最后，因为我认为我无法将其更复杂化！]]></description>
      <guid>https://stats.stackexchange.com/questions/648165/how-to-analyze-between-group-differences-in-within-group-variances-over-time-in</guid>
      <pubDate>Tue, 28 May 2024 18:57:17 GMT</pubDate>
    </item>
    <item>
      <title>具有 $\sigma^2$ 未知值的简单线性回归的最大似然估计量</title>
      <link>https://stats.stackexchange.com/questions/648163/maximum-liklihood-estimators-for-simple-linear-regression-with-sigma2-unknow</link>
      <description><![CDATA[假设我们有以下形式的简单线性回归模型：
$$Y_i = \beta X_i +\varepsilon_i$$
以下一组“经典假设”成立：

$E(\varepsilon_i)=0$

$Var(\varepsilon_i) = {E}(\varepsilon_i^2)-{E}(\varepsilon_i)^2= {E}(\varepsilon_i^2) = \sigma^2$

$Cov(\varepsilon_i, \varepsilon_j)=0$ 对所有 $i\neq j$

$\varepsilon_i$ 是正态的

$X_i$ 是常数，而不是随机变量。


我想找到 $\sigma^2$ 的最大似然估计量（假设它是未知的），以及 $\beta$ 的最大似然估计量（假设 $\sigma^2$ 是未知的）。
作为背景，假设 $\sigma^2$ 已知，则有以下公式表明 OLS 估计量是 MLE 估计量。
由此，我们可以看出 $\beta$ 的 OLS 估计量是通过求解以下公式得出的：
$$ \text{minimize s.t.} \beta: f(\beta) =\sum (\hat{\varepsilon_i}^2) = \sum (Y_i - \beta X_i)^2$$
我们可以很容易地看出，因为 $\frac{df}{d\beta} = \sum (-2Y_iX_i + \beta^2 X_i^2)$ 和 $\frac{d^2f}{d\beta^2} = 2X_i^2 \geq 0$ 则 $\beta$ 的 OLS 估计量由下式给出：
$$\hat{\beta} = \dfrac{\sum X_iY_i}{\sum X_i^2}$$
我们可以轻松证明这也是最大似然估计量。我们首先查看似然函数，它定义为$Y_i&#39;s$的联合概率密度函数，并回想一下，$\varepsilon_i$为正常的假设意味着$Y_i$为正常的。我们有：
$$L(\beta) = \prod \frac{1}{\sqrt{2\pi\sigma^2}}exp(\frac{-1}{2\sigma^2}(Y_i - \beta X_i)^2)$$
$$ \therefore L(\beta) \frac{1}{(2\pi \sigma^2)^{\frac{N}{2}}} exp (\frac{-1}{2\sigma^2}\sum (Y_i - \beta X_i)^2$$
如果我们考虑对数似然函数，我们得到：
$$l(\beta) = \text{ln} \left [ \frac{1}{(2\pi \sigma^2)^{\frac{N}{2}}} \right ]\frac{-1}{2\sigma^2}\sum (Y_i - \beta X_i)^2$$
这又是一个相当简单的问题，最大化$l(\beta)$，这再次表明$$\hat{\beta} = \frac{\sum Y_iX_i}{\sum X_i^2}$$
这是我有点困惑的地方。我是否应该将最大似然函数视为：
$$L(\beta,\sigma^2) = \prod \frac{1}{\sqrt{2\pi\sigma^2}}exp(\frac{-1}{2\sigma^2}(Y_i - \beta X_i)^2)$$
然后根据 $\sigma^2$ 和 $\beta$ 找到最大值。此外，我不清楚我实际上在哪里使用了 $\sigma^2$ 已知的假设？这在考虑置信区间、假设检验等时显然是相关的。但我不清楚 $\sigma^2$ 已知或未知如何影响上述推导。
谢谢您的帮助，
Hmmm16]]></description>
      <guid>https://stats.stackexchange.com/questions/648163/maximum-liklihood-estimators-for-simple-linear-regression-with-sigma2-unknow</guid>
      <pubDate>Tue, 28 May 2024 18:12:44 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归 - 分类预测因子</title>
      <link>https://stats.stackexchange.com/questions/648162/logistic-regression-categorical-predictors</link>
      <description><![CDATA[我正在寻找有关如何使用 SPSS 执行和解释多元逻辑回归的一般指导资源，使用分类预测因子。我有 2 个分类预测变量。每个分类预测因子都有三个组或类别。（我的结果是二进制的，是或否。）每个预测因子类别都是李克特类型类别。
预测因子 1
不太可能，
既不可能也不可能，
可能
预测因子 2
有点担心，
有点担心，
非常担心]]></description>
      <guid>https://stats.stackexchange.com/questions/648162/logistic-regression-categorical-predictors</guid>
      <pubDate>Tue, 28 May 2024 17:56:46 GMT</pubDate>
    </item>
    <item>
      <title>根据预测变量数量调整的逻辑回归中的 R 平方</title>
      <link>https://stats.stackexchange.com/questions/648160/r-squared-in-logistic-regression-adjusted-for-number-of-predictors</link>
      <description><![CDATA[对于 OLS，我们有一个调整后的 R 平方，它根据模型中包含的预测变量的数量进行调整。
对于逻辑回归，有一些 R 平方类似物（Tjur 的 R 平方、McFadden 的 R 平方、Cox-Snell 的 R 平方和 Nagelkerke 的 R 平方）。但是，是否有一个针对逻辑回归的 R 平方测量，可以根据模型中包含的预测变量的数量进行调整？
这篇关于逻辑回归的 R 平方的帖子没有回答我的问题，因为它没有关于根据模型中的预测变量数量进行调整的 R 平方的信息。&quot;调整&quot;这里提到的是指度量的尺度，上限为 1。这不是我的问题所在。]]></description>
      <guid>https://stats.stackexchange.com/questions/648160/r-squared-in-logistic-regression-adjusted-for-number-of-predictors</guid>
      <pubDate>Tue, 28 May 2024 16:21:54 GMT</pubDate>
    </item>
    <item>
      <title>如何找到具有无限类别评估的线性可分问题的线性决策边界？</title>
      <link>https://stats.stackexchange.com/questions/648159/how-to-find-a-linear-decision-boundary-of-a-linearly-separable-problem-with-unli</link>
      <description><![CDATA[我有一个二元分类问题，我的目标是找到一个线性决策边界（我假设存在）。问题的背景是我有一个迭代优化过程，我需要找到一个约束模型。此约束仅产生二元值（可行或不可行）。为了使我的算法正常工作，我需要找到一个线性决策边界 $\hat{g}: \mathbb{R}^d \to \mathbb{R}$，其中超平面 $\hat{g}(x) = 0$ 对应于可行性边界。
在每次迭代中，我都有一个初始数据集，该数据集由已知正态分布 $\mathcal{N}(m^{(t)}, \textbf{C}^{(t)})$ 生成的点 $\mathbf{X}^{(t)}_{1:\lambda} \in \mathbb{R}^{\lambda \times d}$ 组成。我可以在函数 $g$ 上评估这些点以获得类标签。这个问题的特殊性在于，我可以评估 $g$ 上任意数量的新点 $\mathbf{Y}_{1:n}$ 并获得它们的类标签。
为了使我的算法起作用，我需要有一个非常精确的模型边界，这也适用于下一次迭代的样本，该样本在所有方向上的方差可能较低。请注意，数据集的边际通常非常低。
您对如何解决这个问题有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648159/how-to-find-a-linear-decision-boundary-of-a-linearly-separable-problem-with-unli</guid>
      <pubDate>Tue, 28 May 2024 16:12:33 GMT</pubDate>
    </item>
    <item>
      <title>2SLS：它只是重新调整工具变量吗？</title>
      <link>https://stats.stackexchange.com/questions/648158/2sls-does-it-just-rescale-the-instrument-variable</link>
      <description><![CDATA[我正在研究使用工具变量来纠正我的数据中一些已知的测量误差来源（反映错误/不一致的测量，我们认为这些测量会直接影响我们感兴趣的主要测量）。
我曾尝试手动进行 2SLS 并使用 Linnearmodels IV2SLS。
但是，当我查看 X_hat 变量并将其与工具变量绘制在一起时。所发生的一切只是对仪器进行了重新缩放：
X1 = 我感兴趣的独立变量
DSC_2 = 仪器变量（测量误差源的度量）
res_first = IV2SLS(data[&quot;X1&quot;], data[[&quot;const&quot;, &quot;DSC_2&quot;]], None, None).fit(
cov_type=&quot;unadjusted&quot;
)
print(res_first)
data[&quot;X_hat&quot;] = data.X1 - res_first.resids 


无论我手动使用 2SLS 还是 IV2SLS，结果都是相同的。
我真的不明白这如何改善我们的模型（但我想了解！）。
我是否错误地指定了 2SLS？或者这是重新调整效果？这如何改变事物？2SLS 的“调整”效果只是重新调整到更合适的位置吗？
*有关我的数据的更多信息，请参见此处 评估已知测量误差变量的影响的统计方法是什么？ 。2SLS 遵循了这篇文章中有关结构方程建模的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/648158/2sls-does-it-just-rescale-the-instrument-variable</guid>
      <pubDate>Tue, 28 May 2024 16:11:37 GMT</pubDate>
    </item>
    <item>
      <title>将多变量 PDF 转换为基于异常的风险评分（范围为 0 到 1）</title>
      <link>https://stats.stackexchange.com/questions/648157/convert-multivariate-pdf-to-anomaly-based-risk-score-on-scale-0-to-1</link>
      <description><![CDATA[我已经针对多个风险因素定义了一个多变量正态分布。
目前，风险因素观测值的 PDF 范围从无穷小值到最大值 ~2.1。
虽然较小的 PDF 确实表明观测值的异常程度，但我希望将其放在可解释的“风险尺度”上，从 0 到 1，其中 1 表示高度异常，0 表示符合预期（所有风险因素值均为 0）。
我尝试对 PDF 值使用以下逻辑：
(max_PDF - obs_PDF)/(max_PDF - min_PDF)。
但是这里的问题是，一部分观测值四舍五入为 1 并接近 1，然后急剧下降到 0。换句话说，尺度本身是非线性的（可能是由于正常假设？）。
这里有任何帮助吗非常感谢。提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/648157/convert-multivariate-pdf-to-anomaly-based-risk-score-on-scale-0-to-1</guid>
      <pubDate>Tue, 28 May 2024 15:57:02 GMT</pubDate>
    </item>
    <item>
      <title>3组间的测量不变性和潜在均值比较</title>
      <link>https://stats.stackexchange.com/questions/648155/measurement-invariance-and-latent-mean-comparison-between-3-groups</link>
      <description><![CDATA[我在 R 中执行了探索性因子分析 (EFA)，然后执行了验证性因子分析 (CFA)，成功使用 TLI、CFI、RMSEA 等指标评估了双因子结构的模型拟合度。随后，我将数据分为三个不同的组。然后，我确保这些组之间的测量不变性，从而实现配置、度量和标量不变性。
对于最终分析阶段，我的目标是比较这两个组之间的两个因子的潜在均值。例如，我感兴趣的是确定因子 1 在组 2 中的统计值是否高于组 3。
我的问题是：我应该如何比较两个因子和三个组之间的潜在均值？此外，在进行这些比较时，我应该以标量模型还是配置模型为基础？
这是我的代码：
拟合模型：
odelCFA3_3 &lt;- &#39;
PTSD_stigma_Factor1 =~ PTperstigma_3 + PTperstigma_2

PTSD_stigma_Factor2 =~ PTperstigma_9 + PTperstigma_8 + PTperstigma_6
&#39;

fit &lt;- cfa(modelCFA3_3, data = CFA, missing = &#39;ML&#39;)
summary(fit,fit.measures = TRUE, unified=T)

例如：
fitConfigural_PTSD &lt;- cfa(modelCFA3_3，数据 = mydata，缺失 = “ML”，组 = “Sample_Group”)
summary(fitConfigural_PTSD，fit.measures = TRUE，标准化 = TRUE)
]]></description>
      <guid>https://stats.stackexchange.com/questions/648155/measurement-invariance-and-latent-mean-comparison-between-3-groups</guid>
      <pubDate>Tue, 28 May 2024 15:06:47 GMT</pubDate>
    </item>
    <item>
      <title>只有一个点的 pROC 图形状</title>
      <link>https://stats.stackexchange.com/questions/648170/proc-plot-shape-with-only-one-point</link>
      <description><![CDATA[我用 pROC 画出了这个图
rocobj &lt;- plot.roc(db$IOT, Pred,
main = &quot;Confidence intervals&quot;, 
percent=TRUE,
ci = TRUE, 
print.auc = TRUE) 
ciobj &lt;- ci.se(rocobj, 
specificities = seq(0, 100, 5)) # over a select set of specificities
plot(ciobj, type = &quot;shape&quot;, col = &quot;#1c61b6AA&quot;) 
plot(ci(rocobj, of = &quot;thresholds&quot;, Thresholds = &quot;best&quot;))

我仅用一个点而不是多个点的阶梯曲线得到了这个图，我认为这取决于独立变量是二分的，是吗正确吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648170/proc-plot-shape-with-only-one-point</guid>
      <pubDate>Tue, 28 May 2024 13:34:59 GMT</pubDate>
    </item>
    <item>
      <title>线性混合效应模型，调查数据[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648150/linear-mixed-effect-model-survey-data</link>
      <description><![CDATA[使用调查加权数据的混合效应模型！]]></description>
      <guid>https://stats.stackexchange.com/questions/648150/linear-mixed-effect-model-survey-data</guid>
      <pubDate>Tue, 28 May 2024 13:33:32 GMT</pubDate>
    </item>
    <item>
      <title>xy 的平方和大于 x 的平方和——这是怎么回事？</title>
      <link>https://stats.stackexchange.com/questions/648148/sum-of-squares-of-xy-bigger-than-sum-of-squares-for-x-how-can-that-be</link>
      <description><![CDATA[我按照这个教程来可视化 R 平方。首先，他们定义计算平方和的公式：

然后，他们应用公式来获得 x1 和 y 的平方和：

然后，他们使用欧拉图可视化方差：

在他们的例子中，ss_y 为 400，ss_x1 为 292，ss_both_y_x1 为 82。为了找出 x1 变量中不属于 y 的比例，他们执行 ss_x1 - ss_both_y_x1，即 292 - 82 = 210。
我在 R 中编造了一些数据，如果我用它执行 ss_x1 - ss_both_y_x1，我会得到负值！为什么 x 与 y 共享的变体会大于 x 本身的整个变体？因此，如果我们从上面的屏幕截图中获取数字，则 292 &lt; 82（ss_x1 小于 ss_both_y_x1）。用欧拉图直观地解释这个问题：深灰色区域（上面的 210 区域）的大小对我的数据来说是负数。
这是我在 R 中所做的：
library(magrittr)
set.seed(1)
df &lt;- data.frame(x1= rnorm(n= 1000, mean= 28, sd= 4))
df$y &lt;- 2*df$x1 + 10*rnorm(n= nrow(df), mean= 0, sd= 1)

ss_both_y_x1 &lt;- lm(formula= y ~ x1, data= df)%&gt;% aov() %&gt;% summary() %&gt;% .[[1]] %&gt;% .[&quot;x1&quot;, &quot;Sum Sq&quot;] # 代码与链接端基本相同，但除了 magrittr 之外没有其他包
ss_x1 &lt;- sum((df$x1 - mean(df$x1))^2)
ss_x1 &lt; ss_both_y_x1
# TRUE
]]></description>
      <guid>https://stats.stackexchange.com/questions/648148/sum-of-squares-of-xy-bigger-than-sum-of-squares-for-x-how-can-that-be</guid>
      <pubDate>Tue, 28 May 2024 12:27:13 GMT</pubDate>
    </item>
    <item>
      <title>R 中距离相关的置信区间</title>
      <link>https://stats.stackexchange.com/questions/648169/confidence-intervals-for-distance-correlation-in-r</link>
      <description><![CDATA[我一直在尝试计算两个变量之间的距离相关性 (energy::dcor) 的置信区间及其 p 值。
数据为：
structure(c(-0.300232326122519, -0.548312017606863, 0.463488637846498, 
-0.957754830334244, 0.489005536982273, 1.60039641596019, 0.198325183245884, 
0.955655402059422, -0.0985745060548668, -0.91537165915946, 0.821680161225068, 
-0.276711736364627, -0.145523522598367, 1.00647170925371, 1.47737776565003, 
-0.429641721588158, -0.983271729470019, -0.37651945096644, -0.155999049481896, 
-1.08716422579988, -0.393385723005449, 3.06380556423845, -0.0666207802774695, 
-0.983271729470019, -0.196076257229251, 0.278960662381259, -0.641728987053197, 
-0.121785441763213, 0.261876899264989, -0.682069767363957, -0.285408444947535, 
-0.425293367296704, 0.227926864109709, -1.08716422579988, 0.312910697536539, 
0.68133965466455, 0.13653339873247, 0.484958662776278, 0.109524745220057, 
-0.462267094226346, -1.81263562663225, 1.20651893229729, 0.684989465059371, 
-0.906637989461132, -0.96098206068222, 0.360589246740862, -0.300919230157815,
0.309013933026176, 0.892150734542308, 0.574948993393824, 0.579038741277517, 
0.352878039434503, -0.107402964012698, -0.675502008954803, -0.496565311995179, 
-0.700466752538984, -0.742382241262757, 0.938355977216629, -0.14196287615184, 
0.386721998266575, 0.51643524328218, 0.455222542513213, 0.327148349208276, 
0.747334267020053, 1.93710502202678, -1.19755578540738, -0.722586352547963, 
-1.54719618551513, 0.144258727383104, 0.227261483045605), dim = c(35L, 
2L))

我执行了 energy::dcor.test，结果如下：
数据：索引 1，重复1000
dCor = 0.28877, p 值 = 0.4785
样本估计值：
dCov dCor dVar(X) dVar(Y)
0.1469361 0.2887657 0.5039591 0.5137722
因此我认为相关性并不显著，绘制数据时这一点也很明显。但是，当我尝试获取上述相关性的 95% 自举置信区间时，我得到的是：
boot.dcor &lt;- function(data, i) {
x &lt;- data[i, 1]
y &lt;- data[i, 2]
energy::dcor(x,y)
}

boot.out &lt;- boot(data, statistic = boot.dcor, R = 1000, sim = &quot;balanced&quot;)

boot.ci(boot.out, type = &quot;perc&quot;)

自举置信区间计算
基于 1000 个自举重复
调用：
boot.ci(boot.out = boot.out, type = &quot;perc&quot;)
区间：
级别百分位数
95% ( 0.2961, 0.5380 )
如您所见，置信区间与 0 相差甚远，甚至不包含之前获得的 dcor (0.289)，我不明白为什么。任何帮助都将不胜感激，谢谢
我尝试了使用 bootstrapping 计算置信区间的不同方法，例如更改 boot 中的 sim 参数以获得不同的模拟（排列、对立）。我还尝试了另一种获取 CI 的方法，使用 bcaboot::bcajack(data, B = 1000, func = boot.dcor, alpha = 0.05)。但是，我从未在置信区间中得到 0，我想它会存在，因为相关性不显著。尝试相同的程序，但使用 pearson 或 spearman 相关性，然后我得到的置信区间如预期的那样包含 0，并围绕它分布。该问题似乎确实与距离相关性有关，而且我还找不到 dcor.test 中如何计算 p 值，也不知道除了引导法之外还有哪些其他方法可以得到置信区间。]]></description>
      <guid>https://stats.stackexchange.com/questions/648169/confidence-intervals-for-distance-correlation-in-r</guid>
      <pubDate>Tue, 28 May 2024 10:48:00 GMT</pubDate>
    </item>
    <item>
      <title>在这个具体案例中，我们学到了什么概率分布？</title>
      <link>https://stats.stackexchange.com/questions/648135/what-probability-distribution-is-learned-in-this-specific-case</link>
      <description><![CDATA[我一直在阅读论文和博客文章，其中神经网络的训练被定义为学习数据的一些潜在概率分布。
想象一下你编写的 CNN 输出硬币图像是正面还是反面。
这里学习的概率分布是什么？您能给出其他具体的例子吗？
我想这里有一个例子。
想象一个骰子，其输出取决于输入，因此 P(2|1) 与 P(3|1) 不同。
因此，网络经过训练可以学习 P(X|Y)，但在这种情况下，我们可以很容易地看到每个输入值都有一个潜在的概率分布，并且模型将学习这些概率分布，因为我们借用了该分布中的样本。
因此，我们可以想象在现实世界中，骰子的每个数字都有一个相关的概率分布。
但我无法想象猫的特定图像映射到猫或狗的概率。
我在图像示例中没有看到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/648135/what-probability-distribution-is-learned-in-this-specific-case</guid>
      <pubDate>Tue, 28 May 2024 09:32:22 GMT</pubDate>
    </item>
    </channel>
</rss>