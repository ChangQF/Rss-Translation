<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 03 Jun 2024 01:04:07 GMT</lastBuildDate>
    <item>
      <title>比例数据与分类数据的相关性检验</title>
      <link>https://stats.stackexchange.com/questions/648502/correlation-test-between-proportion-data-and-categorical-data</link>
      <description><![CDATA[我有兴趣测试流感活动与不同时期（不同年代）之间的相关性。我的“流感活动”变量是两个变量的组合：ILI 比例（ILI 病例/总人口）* 实验室阳性率（阳性样本/总样本）。因此，我的变量“流感活动”是两个比例相乘而得到的比例，我的“时期”数据是分类的（时期 A、时期 B 和时期 C）。正如您所假设的，我的流感活动数据不是正态分布的，我想知道哪种相关性测试最适合我的数据性质。值得一提的是，即使“流感活动”条目本质上是成比例的，但它们加起来并不等于一。
Spearnman rho？Kendall tan？拟泊松回归？OLS 回归？
我是统计学的初学者，因此非常感谢您的意见！]]></description>
      <guid>https://stats.stackexchange.com/questions/648502/correlation-test-between-proportion-data-and-categorical-data</guid>
      <pubDate>Sun, 02 Jun 2024 21:38:14 GMT</pubDate>
    </item>
    <item>
      <title>具有异方差的双向方差分析</title>
      <link>https://stats.stackexchange.com/questions/648500/two-way-anova-with-heteroscedasticity</link>
      <description><![CDATA[我尝试运行双向方差分析，但未满足同方差条件。我的分析不平衡，样本中有超过 3000 个观测值。即使类别的方差不相等，也可以继续吗？下面是不同可能组合的箱线图和每个类别的平均值表。这是我运行的代码。有没有办法运行考虑异方差的测试？
reg&lt;-aov(depression~classification+diversityLessThan,data=dataset)
summary(reg)

]]></description>
      <guid>https://stats.stackexchange.com/questions/648500/two-way-anova-with-heteroscedasticity</guid>
      <pubDate>Sun, 02 Jun 2024 20:58:07 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归仅关心预测的 $E[X|Y]$</title>
      <link>https://stats.stackexchange.com/questions/648499/logistic-regression-only-cares-about-the-exy-for-prediction</link>
      <description><![CDATA[我读过这篇博文，其中介绍了逻辑回归和具有高斯特征的朴素贝叶斯如何等效
这让我想到，归根结底，逻辑回归只关心不同类别的$E[X|Y]$之间的差异
事实上，在等价关系中假设$Var[X|Y=y]=\sigma^2,\, \forall y \in Y$，因此如果$E[X|Y=y]=\mu,\, \forall y \in Y$，则 $P(X|Y)=P(X)$，因为它们被假定为高斯分布
但是，我无法用数学来证明这一点；特别是，我想从数学上看到，无论各种特征 $P(X|Y)$ 的底层分布是什么，我们都需要 $E[X|Y=0] \neq E[X|Y=1]$ 才能让逻辑回归“使用”这样的特征
之后，假设不等式成立，理想情况下，显著性应该取决于这些特征的方差，即使没有假设$P(X|Y)$是高斯分布（因为这似乎对这样的模型来说不是必需的，与线性回归、数据转换相关的神话是什么？）
我很确定这与统计测试、中心极限定理和统计学中的一些非常基本的定理有关，但我现在无法完全理解，有什么帮助吗？

某种证明的草图（由法学硕士共同撰写...）：
对数似然函数是$l(\beta_0, \beta) = \sum_{i=1}^{n} \left( y_i (\beta_0 + \beta x_i) - \log(1 + e^{\beta_0 + \beta x_i}) \right)$
其梯度为 $\frac{\partial l(\beta_0, \beta)}{\partial \beta} = \sum_{i=1}^{n} \left( y_i x_i - \frac{x_i e^{\beta_0 + \beta x_i}}{1 + e^{\beta_0 + \beta x_i}} \right)$
简化后可得 $\frac{\partial l(\beta_0, \beta)}{\partial \beta} = \sum_{i=1}^{n} \left( y_i x_i - x_i \sigma(\beta_0 + \beta x_i) \right)$
对数据分布的两边取期望值，我们得到：
$$
E\left[\frac{\partial l(\beta_0, \beta)}{\partial \beta}\right] = \sum_{i=1}^{n} \left( E[y_i x_i] - E[x_i \sigma(\beta_0 + \beta x_i)] \right)
$$
此时，我们假设 $\beta = 0$（因此该特征被模型忽略）

对于第一项，我们使用总期望定律，得到 $E[y_i x_i] = E[Y] c$
对于第二项，再次使用 LTE，$E[x_i \sigma(\beta_0 + \beta x_i)] = E[E[x_i \sigma(\beta_0 + \beta 0) | Y]]$，并且由于 $E[X | Y] = c$，我们有：
$$
E[x_i \sigma(\beta_0 + \beta 0) | Y = y] = c \sigma(\beta_0)
$$

综合以上所有，我们得到：
$$
E\left[\frac{\partial l(\beta_0, \beta)}{\partial \beta}\right] = \sum_{i=1}^{n} \left( E[Y] c - c E[\sigma(\beta_0)] \right)
$$
因此，如果 f $E[Y] = E[\sigma(\beta_0)]$，则 $\beta = 0$ 是有效解，我们可以得出结论，模型将仅预测平均值 $Y$，证明如果$E[X|Y=y]=c,\,\,\forall y \in Y$，则逻辑回归模型无法使用该特征进行预测]]></description>
      <guid>https://stats.stackexchange.com/questions/648499/logistic-regression-only-cares-about-the-exy-for-prediction</guid>
      <pubDate>Sun, 02 Jun 2024 20:58:03 GMT</pubDate>
    </item>
    <item>
      <title>安德森·达林假设检验是如何建立的？</title>
      <link>https://stats.stackexchange.com/questions/648498/how-anderson-darling-hypothesis-test-is-set-up</link>
      <description><![CDATA[我想知道 Anderson Darling 检验背后的假设检验是什么。我知道 H0 表示数据服从分布，H1 表示数据不服从分布。但它在数学上如何写？我猜它使用 A2 值，如 H0：A2 = 0 和 H1：A2 &lt;&gt; 0。这是正确的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648498/how-anderson-darling-hypothesis-test-is-set-up</guid>
      <pubDate>Sun, 02 Jun 2024 20:41:07 GMT</pubDate>
    </item>
    <item>
      <title>根据胜率和游戏数量计算启发式</title>
      <link>https://stats.stackexchange.com/questions/648496/computing-heuristic-from-winrate-and-number-of-games</link>
      <description><![CDATA[我需要根据玩家的表现（以游戏数量和这些游戏的胜率表示）对大量玩家（MOBA 游戏）进行排序。
我使用简单的阈值根据胜率减少了初始玩家组，但玩家仍然太多，所以我需要通过消除“幸运”玩家来找到精英中的精英。玩家（那些胜率高但比赛场次不足以证明他们是促成胜利的主要因素的玩家）。
在这个阶段我不想再使用阈值了，因为我觉得既然我的列表中的玩家现在变少了，他们的排序现在应该是相关的，以便找到精英中的精英。
这是一个真实的样本，用来说明我正在处理的数据类型：

我试过$winrate\times \text{log}(games)$，但即使它对极端值有效（成功将（38, 92）放在顶部，但放置得太多了较低（50, 83）。
直观地说，我会说我正在寻找的启发式方法表明，上一个例子中的最佳球员是（38, 92），（50, 83），（18, 95）......我想你看到了模式。
说到模式，我也试图自己对它们进行排名，以便能够为每个“级别”的表现绘制“回归”线，但最终我变得更加困惑，因为我最终得到了一个非常针对问题的解决方案，因为它适合这组特定的数据点，而我不知道如何概括它。
我不是在这个领域工作，所以我不习惯那种东西，因此自己找不到解决方案，但我想我至少可以理解它，所以如果你有任何关于此类场景的已知技术的参考，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/648496/computing-heuristic-from-winrate-and-number-of-games</guid>
      <pubDate>Sun, 02 Jun 2024 19:05:28 GMT</pubDate>
    </item>
    <item>
      <title>计算两个圆形分布之间的相关系数</title>
      <link>https://stats.stackexchange.com/questions/648495/calculating-correlation-coefficient-between-two-circular-distributions</link>
      <description><![CDATA[我有两个变量 Y1 和 Y2 的记录（假设在两个不同的地理位置测量的温度），每个变量都以不同的罗盘方向（固定且范围从 0 到 360，分辨率为 5 度）记录，相对于距离测量位置 1 公里的中心点。例如，在每个站点，相对于该中心点，温度以不同的方向（例如，北、东、南、西和中间角度）记录。
我想用这些数据计算几件事：
按温度 Y1 和 Y2 加权的平均方向：我想确定最能代表平均温度的方向，考虑到每个站点的所有测量角度。这会让我了解每个地理位置较高温度的主要方向。
不同地理位置的温度-角度分布之间的相关性：我希望计算两个站点的温度分布之间的相关性。但是，我理解 Y1 和 Y2 测量值之间的标准 Pearson 相关性可能不适用，因为数据具有潜在的圆形特性。同样，标准的圆到圆相关方法可能不起作用，因为它们处理的是角度值样本，没有任何温度加权。
因此，我不确定如何使用我的 Y1 和 Y2 值来计算它们之间的相关系数。
进行这些计算的合适方法是什么]]></description>
      <guid>https://stats.stackexchange.com/questions/648495/calculating-correlation-coefficient-between-two-circular-distributions</guid>
      <pubDate>Sun, 02 Jun 2024 18:58:59 GMT</pubDate>
    </item>
    <item>
      <title>诊断生存曲线图中的意外模式</title>
      <link>https://stats.stackexchange.com/questions/648490/diagnosing-an-unexpected-pattern-in-a-survival-curve-plot</link>
      <description><![CDATA[我正在 R 中进行生存分析（使用 Cox 比例风险回归）。我的总体样本死亡率约为 10％，但从我的分析得出的 Kaplan-Meier 生存曲线似乎显示生存率下降了约 40-50％，并且在 4 年左右急剧下降。这并不能反映实际数据集中死亡时间的模式，但我不确定是什么导致了这种差异……有人知道吗？

# 定义绘图的层
strata &lt;- expand.grid(
pression_level = levels(complete_cases_all$depression_level),
sex = levels(complete_cases_all$sex)
)
rownames(strata) &lt;- letters[1:nrow(strata)]

# 定义平均参与者
average_participant &lt;- expand.grid(
pression_level = levels(complete_cases_all$depression_level),
sex = levels(complete_cases_all$sex),
calendar_year = median(complete_cases_all$calendar_year),
age = median(complete_cases_all$age),
education_level = median(complete_cases_all$education_level),
employment = &quot;有竞争力的就业&quot;,
marital_status = &quot;单身&quot;,
rehab_payor_primary_type = &quot;非医疗补助&quot;,
func_score = median(complete_cases_all$func_score),
mental_health_tx_hx = &quot;否认有任何心理健康治疗史&quot;,
psych_hosp_hx = &quot;否认有任何精神病住院史&quot;,
problematic_substance_use = &quot;否&quot;,
suicide_attempt_hx = &quot;否认有任何自杀企图史&quot;
)
rownames(average_participant) &lt;- letters[1:nrow(average_participant)]

# 拟合生存模型
cxsf &lt;- survfit(model_5, newdata = average_participant, conf.type = &quot;none&quot;)
surv_cxsf &lt;- surv_summary(cxsf, data = complete_cases_all) |&gt; # 总结生存模型
tibble()
m_newdat &lt;- average_participant[as.character(surv_cxsf$strata), ] # 将新数据与生存总结层匹配

gg.surv.model5 &lt;- surv_model_5 |&gt;
ggsurvplot_df(
surv.geom = geom_line,
color = &quot;depression_level&quot;,
xlab = &quot;X 之后的时间（年）&quot;,
ylab = &quot;生存概率&quot;,
legend = c(0.175, 0.175),
conf.int = FALSE,
censor = FALSE,
surv.scale = &quot;percent&quot;,
break.time.by = 1,
xlim = c(0, 5), # 将 x 轴限制为 5 年
ylim = c(crop, 1),
palette = c(&quot;#90cbf9&quot;, &quot;#2196f3&quot;, &quot;#114b7a&quot;),
ggtheme = theme_classic(),
) +
labs(linetype = &quot;Sex&quot;, color = &quot;抑郁水平&quot;)

数据基于纵向数据集，并在初始研究登记日期后约 1 年和 4 年进行后续访谈。审查日期由每个审查参与者的最后一次后续访谈日期确定，死亡日期由每个死者官方死亡证明中列出的日期确定。时间 0 对应于每个参与者的研究登记日期，并在随后的 5 年内进行跟踪。
我检查了数据集，发现 4 年后死亡的死者数量异常，但在此期间似乎有合理的死亡频率（总死亡人数的约 23% 发生在 4 至 5 年之间）。我确保我的死亡时间基于日期，而不是（整数）跟踪间隔。最后，我确保受审查的参与者也在 4-5 年的时间范围内贡献数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/648490/diagnosing-an-unexpected-pattern-in-a-survival-curve-plot</guid>
      <pubDate>Sun, 02 Jun 2024 18:03:43 GMT</pubDate>
    </item>
    <item>
      <title>R 中线性混合模型中随机效应结构的澄清</title>
      <link>https://stats.stackexchange.com/questions/648486/clarification-on-random-effects-structure-in-linear-mixed-models-in-r</link>
      <description><![CDATA[我正在使用线性混合模型来分析具有层次结构的数据集，其中随时间变化的测量值（级别 1）聚集在个体内（级别 2），而个体聚集在国家内（级别 3）。我最初在 R 中使用 lme4 包中的以下语法来建模此结构：
model &lt;- lmer(basdai ~ 1 + time + (1|country) + (1|id), data = data, 
REML = FALSE) 

但是，一位审阅者指出，我使用的语法并不代表 3 级模型，而是 2 级模型。他们建议改用以下语法：
model &lt;- lmer(basdai ~ 1 + time + (1|country) + (1|country:id), 
data = data, REML = FALSE)

据我了解，术语 (1|country) 表示每个国家（级别 3）的随机截距，而 (1|id) 表示每个个体（级别 2）的随机截距。
我认为包括这两个术语将解释聚类。
我将不胜感激任何关于这两个模型规范之间的差异的见解或解释，以及我的初始语法是否真正代表了 2 级结构而不是预期的 3 级层次结构。]]></description>
      <guid>https://stats.stackexchange.com/questions/648486/clarification-on-random-effects-structure-in-linear-mixed-models-in-r</guid>
      <pubDate>Sun, 02 Jun 2024 17:13:38 GMT</pubDate>
    </item>
    <item>
      <title>领域知识在聚类中是否需要外部验证？</title>
      <link>https://stats.stackexchange.com/questions/648483/is-domain-knowledge-external-validation-in-clustering</link>
      <description><![CDATA[我有聚类结果，其 Silhuette Width 等值良好。聚类大小为：4998、1、1，这并不好，因为我知道我的客户没有该特定分区（它更平衡）。因此，我忽略了这些聚类结果并得出结论，它很糟糕。这是否意味着我使用了外部验证，因为我得出的聚类不好的结论是基于我的领域知识？]]></description>
      <guid>https://stats.stackexchange.com/questions/648483/is-domain-knowledge-external-validation-in-clustering</guid>
      <pubDate>Sun, 02 Jun 2024 16:08:19 GMT</pubDate>
    </item>
    <item>
      <title>从一副 40 张牌中选出 4 张总点数为 5 的牌的概率</title>
      <link>https://stats.stackexchange.com/questions/648482/probability-of-selecting-4-cards-that-add-up-to-5-from-a-deck-of-40-cards</link>
      <description><![CDATA[假设我们有一副牌，不包括人头牌，也就是从 A 到 10 的牌。
以下哪种方法可以正确计算 4 张随机选择的牌之和等于 5 的概率？
方法 1：
$P(X=5)=\frac{8}{40}\cdot\frac{7}{39}\cdot\frac{6}{38}\cdot\frac{4}{37}$
我的逻辑是，对于第一张牌，有 8 种可能性。4 张 A 和 4 张 2。对于第二张牌，如果第一张牌是一张 A，则有 7 种可能性。3 张 A 和 4 张 2。如果第二张牌是一张 A，则可以从 2 张 A 和 4 张 2 中选择第三张牌。最后，如果第三张牌是 A，那么第四张牌就必须是 2，因此它的样本空间只有 4 张 2。
方法 2：
$P(X=5) = \frac{8}{40}\cdot\frac{4}{39}\cdot\frac{3}{38}\cdot\frac{2}{37}$
与方法 1 一样，第一张牌可以从 4 张 A 和 4 张 2 中选择。不过这次，我们假设第一张牌是 2。根据定义，所有剩余的牌都必须是 A。
方法 3：
$P(X=5)=\frac{4}{40}\cdot\frac{4}{39}\cdot\frac{3}{38}\cdot\frac{2}{37}$
我们知道，为了得到总和 5，我们特别需要 1 张 2 牌和 3 张 A。第一个分数表示选择 2 的概率，其余分数与 A 有关。
我认为方法 3 是所有方法中最合理的，但我仍然觉得它们都是错的，我应该使用超几何公式来找出概率。]]></description>
      <guid>https://stats.stackexchange.com/questions/648482/probability-of-selecting-4-cards-that-add-up-to-5-from-a-deck-of-40-cards</guid>
      <pubDate>Sun, 02 Jun 2024 15:58:08 GMT</pubDate>
    </item>
    <item>
      <title>拒绝怀疑不属于目标人群的样本[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648475/rejection-of-samples-suspected-of-not-coming-of-the-target-population</link>
      <description><![CDATA[假设有一个平稳过程，它应该类似于具有“已知”均值和方差的高斯分布。从中取出三次（或 n 次）Iid 样本。众所周知，一些样本可能会受到污染，即包括来自其他分布（具有不同的形状、均值和/或方差）的观测值。
假设这种污染可以通过产生具有不可思议的高范围的样本来表现出来。血压测量可以作为一个例子。在这种情况下，偶尔会出现不代表被测变量的“奇怪”测量值，虽然它们的起源尚有争议，但它们很容易是测量过程中血压本身偶尔出现的时间波动以及仪器和方法的怪癖的结果。这被认为是污染，因为此类异常值是由测量技术机械引入的，并且与临床无关。
因此，评估每个 n 重样本的范围，并将其与基于假定的“干净”高斯母分布选择的截止值进行比较。如果超出该值，则拒绝该样本，并且不将其纳入分析。
我的问题是（以三次重复为例，假设该程序是可接受的）：以下哪种方法更合适？

如果前两个单独的观察值超出允许的最大范围，则拒绝它们并从下一个观察值开始下一个三次重复样本。

无论如何都要取第三个样本以完成三次采样程序，然后拒绝它。


第一个选项保证（根据上述程序）无论尚未进行的第三次观察如何，样本都将被拒绝，但拒绝标准是基于三次重复的范围，而不是两个相邻测量值之间的差异。
以下是希望可以证明提出这个问题的合理性的背景。再次以血压（BP）测量为例。关于如何进行血压测量有几种标准和建议。分歧的原因在于：a) 血压本身在几个时间尺度上不断变化，b) 大多数测量方法的不确定性与血压短期变化本身相当，c) 就临床实践而言，点测量是目前的标准，d) 必须根据这些点测量做出临床决策，对患者进行治疗或不治疗。
虽然还不完善，但自动示波血压监测仪的普及允许一次进行多次点测量。无论你做什么，它们都会分散（如果你不相信我，可以试试），但如果做得小心，短期分散是有意义的——这是预期的，但如果它超过某些值，则可以合理地假设测量结果可能受到污染（如上所述），因此对诊断没有帮助。但审查过程不应像往常一样任意进行，例如总是丢弃第一个或最高的值，因为它会使测量结果产生偏差，从而导致诊断结果出现偏差。
取三份样本的中位数（而不是平均值）已经具有过滤高值（或低值）的特性。实践表明，即使是经过中值过滤的三份样本也应该被拒绝，因为它们没有意义或不能代表被测量的变量。
所以，这让我回到了最初的问题：假设有效的三份样本测量结果可以建模为具有“已知”方差的高斯分布的 iid 样本，并且可以通过设置此类三份样本的范围限制来检测和拒绝偶尔出现的无效/受污染的样本，与不走捷径（2）并在拒绝之前对三份样本进行完整采样相比，走捷径（1）的后果是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648475/rejection-of-samples-suspected-of-not-coming-of-the-target-population</guid>
      <pubDate>Sun, 02 Jun 2024 13:41:51 GMT</pubDate>
    </item>
    <item>
      <title>使用预测值置信区间来“预测”结果</title>
      <link>https://stats.stackexchange.com/questions/648463/using-predictive-value-confidence-intervals-to-predict-outcomes</link>
      <description><![CDATA[以下是简要版本：
假设我有一个混淆矩阵，其中包含以下数据，这些数据基于预测试的熟练度分数线和课程结果（通过/不通过）。分数线是使用 ROC 曲线确定的。下面的混淆矩阵表示使用 ROC 曲线确定的分数线处的 TP、FP、FN 和 TN。 （以下数据已调整以便于交流。）
TP：550 FP：200
FN：280 TN：825
以下是基于以上数据的统计数据：
敏感度：66.27%
1 - 特异性：19.51%
准确度：74.12%
阳性预测值 (PPV；贝叶斯理论)：73.33% 95% CI (70.64%，75.86%)
1 - 阴性预测值 (1 - NPV)：25.34% 95% CI (23.49%，27.28%)
是否可以在 PPV 置信区间中使用最小值和最大值，在 1 中使用最小值和最大值？ - NPV 置信区间是根据预测试的结果“预测/预期”某个班级中一组学生通过考试的概率值范围？目标是根据学生的预测试分数了解有多少学生将通过/不通过该课程。
例如，根据我们的熟练程度分数线，开学第一天 75% 的学生在预测试中获得了“熟练”的成绩。如果过去的数据（如混淆矩阵所示）表明，如果学生在预测试中表现良好，则通过该课程的概率 (PPV) 为 73.33%，95% CI（70.64%，75.86%），如果学生在预测试中表现不佳，则通过该课程的概率 (1 - NPV) 为 25.34%，95% CI（23.49%，27.28%），我们能否使用两个置信区间的最小值和最大值来表示：
0.7064 * 75 + 0.2349 * 25 [两个置信区间的最小值] = 58.9%
0.7586 * 75 + 0.2728 * 25 [两个置信区间的最大值] = 63.7%
我们预计当前学生群体中会有 58.9% 到 63.7%通过这门课程？
这实际上是使用贝叶斯定理/条件概率，使用过去收集的预测试和课程通过率数据来回答我们的问题。使用置信区间而不是实际条件概率 73.33% 和 25.34% 来执行此操作是否存在问题？当然，这里的“预测”/期望使用得比较宽泛。我们知道现实世界总是有一些有趣的事情在等着我们。 （旁注：我们将来会添加一门必修课程，希望能随着时间的推移提高通过率。）一旦有数据可供在学习本课程之前修读必修课程的学生使用，比较必修课程与无必修课程组的数据、两组在预考中的分数以及课程的通过/不通过率等，看看课程结果实际上如何随时间变化将会很有趣，但就目前而言……
根据过去的数据，根据该课程在预考中的表现，我们是否可以进行上述计算并说，根据该课程在预考中的表现，我们预计当前这组学生中 58.9% 至 63.7% 的学生会通过该课程？]]></description>
      <guid>https://stats.stackexchange.com/questions/648463/using-predictive-value-confidence-intervals-to-predict-outcomes</guid>
      <pubDate>Sun, 02 Jun 2024 04:55:58 GMT</pubDate>
    </item>
    <item>
      <title>中位数的平均值始终不同于中位数</title>
      <link>https://stats.stackexchange.com/questions/648458/mean-of-medians-consistently-differs-from-median</link>
      <description><![CDATA[免责声明：这是我的第一个问题。
问题背景：
我想比较两个分布（n1 ~ 500 和 n2 ~ 700），它们不是正态分布，方差也不同，但大致是单峰分布。我决定使用中位数进行比较统计。
使用（scipy 的）置换检验，我得到了两个中位数观察到的差异的 p 值。使用同样生成的零假设分布，我也能够得到实验的最小可检测效果。
我想估计观察到的差异（中位数）的误差（-&gt; 用于绘图的误差线）。所以我使用 np.random.choice 绘制两个具有相同大小的新分布并重复/替换；但不混合组（即假设效果/观察到的差异是真实的）。我计算了两个新分布的中位数差，并重复了 100000 次。
问题
在所有这些实现中，我计算了平均值和标准差，发现平均值（中位数差）与原始数据中位数差相比始终相差约 13%。
这是错误、测试设计错误还是实际可能的结果？如果是最后一个，为什么？这意味着什么？
代码
# 原始实验数据：A、B
# 绘制新的分布 a、b，不进行混合
a = np.random.choice(A, (100000, len(A), True) 
b = np.random.choice(B, (100000, len(B), True)
med_m = np.mean(np.median(a, axis = 1) - np.median(b, axis = 1))
med_s = np.std(np.median(a, axis = 1) - np.median(b, axis = 1))
med = np.median(A) - np.median(B)

med_m / med
&gt;&gt;&gt; 1.13...
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648458/mean-of-medians-consistently-differs-from-median</guid>
      <pubDate>Sun, 02 Jun 2024 00:57:18 GMT</pubDate>
    </item>
    <item>
      <title>按离散的、不相关的属性进行聚类？</title>
      <link>https://stats.stackexchange.com/questions/648455/clustering-by-discrete-unrelated-properties</link>
      <description><![CDATA[我有大量具有不相关属性的对象，例如

color=yellow
material=stone
is_important=true
等等。

这些属性基本上是随机的，只要用户认为有就好。没有实际的方法可以将这些属性强制转换为具有欧几里得距离的类似物。
我认为，如果不存在某种距离度量，那么从概念上讲，考虑通过这些属性对对象进行聚类是没有意义的（这是正确的吗？），但我希望存在可以产生类似输出的东西
&quot;90% 的 color=yellow 对象也有 material=plastic 和 is_important=false&quot;
除了强制通过数据集之外，还有其他东西可以进行此类分析吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648455/clustering-by-discrete-unrelated-properties</guid>
      <pubDate>Sun, 02 Jun 2024 00:19:01 GMT</pubDate>
    </item>
    <item>
      <title>从统计角度来看，R 中的变换参数在绘制平滑缩放的 Schoenfeld 残差图时起什么作用？</title>
      <link>https://stats.stackexchange.com/questions/648370/what-does-the-transform-argument-in-r-statistically-wise-do-when-plotting-the</link>
      <description><![CDATA[正如标题所示，我旨在解决 R 中的参数 transform = &#39;&#39;，特别是关于用于评估比例风险 (PH) 假设的平滑缩放 Schoenfeld 残差检验/图。
我知道默认值是 transform = &#39;km&#39;，但也有其他可用选项：
transform=&#39;log&#39;
transform=&#39;rank&#39;
transform=&#39;identity&#39;

我相信我已经掌握了每个选项的含义。如果我的理解不正确，请纠正我：
log 用于强调早期事件，因为它为它们分配了更大的权重。
rank 用于突出显示晚期事件，因为它为它们分配了更大的权重。
identity 表示未经任何修改的原始时间数据。
但是，我不确定 km 到底是做什么的。虽然它似乎可以节省时间，但我不确定它的含义。
我的问题：

从统计的角度来看，有人可以详细说明每个转换背后的细节吗？

从统计的角度来看，在哪种情况下我应该使用每个转换来评估 R 中的 cox.zph() 测试/绘图？

每个转换都会为 PH 假设产生不同的 p 值。根据所选的转换，我应该信任哪个 p 值？


编辑：我的问题已关闭，因为它似乎不属于这里，因为它与统计无关。我将尝试澄清，我想从统计的角度而不是编码的角度来理解问题。提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648370/what-does-the-transform-argument-in-r-statistically-wise-do-when-plotting-the</guid>
      <pubDate>Fri, 31 May 2024 12:11:26 GMT</pubDate>
    </item>
    </channel>
</rss>