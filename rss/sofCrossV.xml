<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 09 Jan 2025 06:23:39 GMT</lastBuildDate>
    <item>
      <title>有人可以帮我从 Statista 下载数据吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659740/can-someone-help-me-to-download-data-from-statista</link>
      <description><![CDATA[我现在正在做一个大学项目，但我付不起订阅费。我需要做一个机器学习模型。有人能从 Statista 给我发一份数据吗？
https://www.statista.com/statistics/1251338/share-female-board-directors-it/]]></description>
      <guid>https://stats.stackexchange.com/questions/659740/can-someone-help-me-to-download-data-from-statista</guid>
      <pubDate>Wed, 08 Jan 2025 23:47:17 GMT</pubDate>
    </item>
    <item>
      <title>对于分类变量，PCA、因子分析或其他方法？</title>
      <link>https://stats.stackexchange.com/questions/659739/pca-factor-analysis-or-other-methods-for-categorical-variables</link>
      <description><![CDATA[我有关于公司政治关系的调查数据，分为两个模块，希望您就以下方面提出建议：
1. 模块 1：此模块包含所有分类变量的调查问题。虽然我了解到从技术上讲可以使用 PCA 处理分类变量，但一般不建议这样做。是否有其他方法更适合在此背景下分析分类数据？
2. 模块 2：此模块包含多种变量：2 个是序数变量，1 个是分类变量。PCA 或因子分析能否有效地处理这种组合？
我一直在研究 PCA 和因子分析之间的差异，但仍然不确定哪个更合适。我的直觉是政治联系可能不是潜在的构造，因此 PCA 在概念上似乎更有意义。但是，我想听听您的想法，PCA 或因子分析是否是更好的方法——或者另一种方法是否更合适。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659739/pca-factor-analysis-or-other-methods-for-categorical-variables</guid>
      <pubDate>Wed, 08 Jan 2025 23:40:48 GMT</pubDate>
    </item>
    <item>
      <title>通过中间变量估计干预与结果之间的关系</title>
      <link>https://stats.stackexchange.com/questions/659738/estimating-relationship-between-intervention-and-outcome-through-intermediate-va</link>
      <description><![CDATA[设 $X$ 为实验性疫苗的剂量水平，$Z$ 为二元结果（感染与未感染）。目标是通过随机为参与者接种 $k$ 个不同剂量水平的疫苗，$X_1, ..., X_k$，来估计 $X$ 和 $Z$ 之间的关系。 $n$ 名受试者在每个剂量水平上接种疫苗，因此总共有 $nk$ 名受试者。
通常，$X$ 和 $Z$ 之间的逻辑回归就足够了，但这里的问题是 $X$ 被视为目标剂量水平，并且相同目标剂量水平的每种疫苗中的实际浓度（表示为 $Y$）可能有很大差异。
对 $X$ 和 $Z$ 之间关系进行建模的最佳方法是什么？这看起来像是一系列回归$X-&gt;Y-&gt;Z$，其中$Y$和$Z$通过逻辑模型关联，而$X$和$Y$可以通过线性模型建模？
任何带有参考的建议都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/659738/estimating-relationship-between-intervention-and-outcome-through-intermediate-va</guid>
      <pubDate>Wed, 08 Jan 2025 23:27:39 GMT</pubDate>
    </item>
    <item>
      <title>缩小的整数格点是否可以作为概率单纯形中的无偏样本点？</title>
      <link>https://stats.stackexchange.com/questions/659737/do-scaled-down-integer-lattice-points-serve-as-unbiased-sample-points-in-the-pro</link>
      <description><![CDATA[我一直在努力证明一个看起来直观明显但实际上并不容易严格建立的陈述。
$(n-1)$维概率单纯形$X$是集合
$$
X=\left\{\mathbf{x}\in[0,1]^n:\sum_{i=1}^nx_i=1\right\}。
$$
设 $U$ 为单纯形中按比例缩小的整数格点集：
$$
U=X\cap\frac{\mathbb{Z}^n}s
$$
其中 $s\in\mathbb{Z}^+$。
我的主张是，当 $s\to\infty$ 时，$U$ 可作为 $X$ 中无偏的样本点集。也就是说，对于子集 $P\subseteq X$，其质心（未加权平均值）由
$$
\tag{1}
\bar{\mathbf{p}}=\frac{1}{\int_{P}dV}\int_{P}\mathbf{p}\,dV
$$
其中 $\mathbf{p}\in P$ 和 $dV$ 是 $(n-1)$ 维体积元素，渐近等于
$$
\tag{2}
\bar{\mathbf{u}}=\frac1{\#U}\sum_{i=1}^{\#U}\mathbf{u}_i
$$
其中 $\mathbf{u}_i\in U$，即 $s\to\infty$；即
$$
\tag{3}
\lim_{s\to\infty}\bar{\mathbf{u}}=\bar{\mathbf{p}}。
$$
这里，$(1)$可视为真实均值，$(2)$可视为样本均值，如果集合$U$提供的样本点在极限上无偏，则$(3)$成立。
对于我的具体情况，该语句不必对$X$中的所有子集都成立，而只对这个特定集合成立：
$$
\tag{4}
{P}=\left\{\mathbf{p}\in[0,1]^n: p_1\le p_2\le\cdots\le p_c\ge\cdots\ge p_n\text{ 和} \sum_{i=1}^n p_i=1\right\}\subset X
$$
顺便说一句，它恰好是凸的。
简而言之，我试图证明$(3)$，无论是在一般情况下，还是当$P$给出为$(4)$时。
任何帮助都将不胜感激。指导我任何相关的关键字或书籍也将很棒。]]></description>
      <guid>https://stats.stackexchange.com/questions/659737/do-scaled-down-integer-lattice-points-serve-as-unbiased-sample-points-in-the-pro</guid>
      <pubDate>Wed, 08 Jan 2025 22:56:09 GMT</pubDate>
    </item>
    <item>
      <title>如何更好地测试数据是否接受多参数分布的简化？</title>
      <link>https://stats.stackexchange.com/questions/659732/how-can-i-better-test-whether-the-data-accepts-simplification-of-a-many-paramete</link>
      <description><![CDATA[我有一些数据，它们与特定的五参数分布非常吻合，该分布包括许多常见的 2 和 3 参数分布以及一些四参数分布，作为某些参数的特定值的特殊情况，通常为零或一，作为特殊情况。我一直在尝试看看我是否可以通过使用重采样来获得参数值的经验分布并从经验 CDF 创建置信区间来简化分布，但我怀疑有一些更简单的方法可以做到这一点。（我有很多数据 - 大约 60,000 个观测值）。我对五参数分布的估计方法的优点是易于理解，但计算量非常大。因此，重采样后的重新估计既慢又乏味。有没有一种常规方法来完成这项任务，即查看数据是否接受这些简化中的任何一种，如果可以，它是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659732/how-can-i-better-test-whether-the-data-accepts-simplification-of-a-many-paramete</guid>
      <pubDate>Wed, 08 Jan 2025 19:21:02 GMT</pubDate>
    </item>
    <item>
      <title>FE 解释中的相互作用项</title>
      <link>https://stats.stackexchange.com/questions/659728/interaction-term-in-fe-interpretation</link>
      <description><![CDATA[我正在估算固定效应回归，如下所示：
$$
\text{unemployment}_{ict} \sim b_1 \text{wage}_{ict} + b_2 \text{heat}_{ict} + b_3 \text{wage}_{ict} \times \text{heat}_{ict} + \text{FEc} + \text{error}_{ict}
$$
其中 $i$ 为个人，$c$ 为国家，$t$ 为时间。
假设您获得以下效果：$b_1=0.7$，$b_2=1.2$, $b_3=-0.4$
现在您想要解释交互效应。一种思考方式是边际效应：
这里您已估计出给定工资和热量的失业预期值
$$
E[y|a,b]=0.7a+1.2b-0.4ab
$$
如果对上述表达式求导，求 a 的值：
$$
\frac{d}{d a} E[y|a,b] =0.7-0.4b
$$
此表达式在 $b$（热量）中递减。然后您可以将 b 设置为“有趣”的值以进行解释。通常，这些有趣的值是 $b$ 中样本的平均值。
我想知道这在具有固定效应的应用中是否有意义。国家平均值已从固定效应中移除。在热度水平上评估 b 是否有意义。或者最好以 b 的平均增长率或标准差而不是水平来评估？
如果有人能对此发表评论，非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659728/interaction-term-in-fe-interpretation</guid>
      <pubDate>Wed, 08 Jan 2025 17:35:13 GMT</pubDate>
    </item>
    <item>
      <title>不带 MAR 假设计算临床试验的敏感性和特异性</title>
      <link>https://stats.stackexchange.com/questions/659704/computing-sensitivity-and-specificity-of-a-clinical-test-without-mar-assumption</link>
      <description><![CDATA[如周氏《诊断医学中的统计方法》第 337-338 页所述，假设 $D$ 是一个随机变量，如果受试者患有疾病，则假设其值为 $1$。假设 $T$ 是一个随机变量，如果疾病检测结果为阳性，则假设其值为 $1$。假设 $V$ 是一个随机变量，如果受试者已对该疾病进行了进一步验证，则假设其值为 $1$。给定以下参数的值$\lambda_{11} = P(V=1|T=1,D=1)$, $\lambda_{01} = P(V=1|T=1,D=0)$, $\lambda_{10} = P(V=1|T=0,D=1)$, $\lambda_{00} = P(V=1|T=0,D=0)$, $\phi_1 = P(T=1)$, $\phi_{20} = P(D=1|T=0)$, $\phi_{21} = P(D=1|T=1)$，根据这些参数计算敏感度和特异性的正确方法是什么？例如，我知道敏感度是 $P(T=1|D=1)$，不考虑 $V$，它应该计算为 $P(T=1|D=1)P(D=1)/P(T=1)$，但如果必须考虑随机变量 $V$，公式会如何变化？]]></description>
      <guid>https://stats.stackexchange.com/questions/659704/computing-sensitivity-and-specificity-of-a-clinical-test-without-mar-assumption</guid>
      <pubDate>Wed, 08 Jan 2025 06:29:17 GMT</pubDate>
    </item>
    <item>
      <title>线性回归 - 响应变量为百分比改善或 m/s？</title>
      <link>https://stats.stackexchange.com/questions/659686/linear-regression-response-variable-as-percent-improvement-or-m-s</link>
      <description><![CDATA[我正在尝试对包含 8 种不同跑步距离的数据集进行统计，这些距离在遵循训练方案之前和之后都有时间，并且基于距离对改进进行线性回归（所有完成时间都有所下降）。我不确定是否要转换为百分比改进或使用 m/s 之类的变量，然后减去跑步时间 1 和跑步时间 2，以便能够比较不同的距离组。显然，绝对时间差异并不大，因为更长的距离自然会有更大的改进。但我读到过，不建议将百分比改进转换为线性回归中的响应变量。我该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/659686/linear-regression-response-variable-as-percent-improvement-or-m-s</guid>
      <pubDate>Tue, 07 Jan 2025 21:03:50 GMT</pubDate>
    </item>
    <item>
      <title>何时使用哪种样本方差公式？</title>
      <link>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</link>
      <description><![CDATA[我知道样本方差的公式为
$$s^2 = \frac{\sum (x_i - \bar{x})^2}{n - 1}$$
我还知道样本方差的公式为“均值平方减均值平方”。
在计算给定样本的样本方差时，我使用了这两个公式，但发现它们给出了两个不同的答案，因此我想问，什么时候该使用第一个公式，什么时候该使用第二个公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</guid>
      <pubDate>Tue, 07 Jan 2025 05:32:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么标准差比平均值绝对偏差更受青睐？</title>
      <link>https://stats.stackexchange.com/questions/659643/why-is-standard-deviation-preferred-over-absolute-deviations-from-the-mean</link>
      <description><![CDATA[第一部分
在探索了各种资源和论坛之后，我了解到标准差是一种广泛使用的离散度测量方法，通常比绝对平均偏差更受欢迎（我个人认为后者更简单、更直观），原因如下：
1. 方差的加性：
同意。
2. 平均值最小化平方偏差之和，而中位数（有时不是唯一的）最小化绝对偏差之和：
有点同意，但我不完全理解为什么在这里实现最小值是相关的。有人能解释一下为什么这个属性在选择离散度测量方法时很重要吗？
3.平方偏差在 𝑥 = 0 时可微分，而绝对偏差则不可微分：
有点同意，但我还是不明白为什么可微分性如此重要。这个属性在哪些方面有实际用途？
第二部分
我的独立想法/问题：
方差定义为与平均值的平方偏差的平均值，标准偏差是其平方根（“实际 SD”）。但是，如果标准偏差是平方偏差的平方根的平均值，那不是更有意义吗？ （我提议的是标准差的新定义“建议的 SD”）
(1 / n) * √ Σ((xᵢ - μ)²) 而不是 √(Σ (xᵢ - μ)² / n)

我的理由如下：
平方偏差主要是为了确保：

所有值都是正数。
偏差越大，权重越大。
平均值是使平方偏差之和最小化的数字。

绝对平均偏差达到点 (1)，绝对中位数偏差达到点 (1) 和 (3)。在这些情况下，我们将偏差相加，然后除以 𝑛 得到平均值。
但是，在方差和标准差的情况下，类似的“平均值”就是方差本身。但方差作为一个数字并不能直观地传达分布的扩展。这就是为什么我们要取方差的平方根来得到标准差。
所以，我的问题是：
为什么不使用&quot;建议 SD&quot;作为分散度的度量？
&quot;建议 SD&quot;有什么缺陷？
&quot;实际 SD&quot;为什么比&quot;建议 SD&quot;更适合作为分散度的度量？]]></description>
      <guid>https://stats.stackexchange.com/questions/659643/why-is-standard-deviation-preferred-over-absolute-deviations-from-the-mean</guid>
      <pubDate>Tue, 07 Jan 2025 05:23:59 GMT</pubDate>
    </item>
    <item>
      <title>使用相机陷阱记录动物活动对火灾的反应——缺乏空间独立性的问题以及如何分析</title>
      <link>https://stats.stackexchange.com/questions/658550/fauna-activity-responses-to-fire-with-camera-traps-issues-with-lacking-spatial</link>
      <description><![CDATA[我正在尝试为我的博士论文找出最佳的数据分析方法，但遇到了一些困难。
我从事生态学领域的工作，试图了解火灾前后动物群的反应。我正在使用 BACI 方法，并一直使用相机陷阱来捕捉动物的检测/活动。我遇到的问题是，我正在处理的火灾现场非常小，所以我必须制作一个高密度相机陷阱网格（即每个地点有 6 个相机，4 个监测点，相机间隔约 20 米，非常近）。到目前为止，我已经考虑了 60 分钟内在同一台相机上出现的动物（这是相机陷阱的标准做法，用于考虑可能在 60 分钟内被相机多次捕捉到的个体），但我正在努力解决每个站点的相机之间的空间自相关性 - 即动物可能在彼此相似的时间段内在相机之间移动的现实。
我读到我可以将每个站点视为重复，而不是每个站点内的每个相机，这样即使有动物在相机之间移动，它们在 60 分钟内被多个相机计数也无关紧要。这听起来合理吗？
有人有什么想法可以通过我的分析来解决这个问题吗？为了便于理解，我计划使用 GLMM（同样，许多其他人已经使用过），并且认为也许我可以使用相机编号作为随机效应？想看看是否还有其他人有什么我可以探索的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/658550/fauna-activity-responses-to-fire-with-camera-traps-issues-with-lacking-spatial</guid>
      <pubDate>Tue, 10 Dec 2024 23:13:39 GMT</pubDate>
    </item>
    <item>
      <title>假阳性率是否可能随着患病率的增加而降低？</title>
      <link>https://stats.stackexchange.com/questions/658195/is-it-possible-that-false-positive-rate-decreases-with-increasing-prevalence</link>
      <description><![CDATA[我对患病率对预测性能的影响很感兴趣。Chouldechova (2016) 指出：

[当]在各组再犯患病率不同的人群中使用测试公平 [再犯预测工具] 时，通常再犯患病率较高的组会具有较高的 FPR 和较低的 FNR。

我想知道如果该工具旨在使两组具有相同的准确度，情况是否如此。因此，我推导出一个考虑准确率、FNR 和患病率的 FPR 函数：
$$FPR=\frac{\left(1-ACC-prevalence\cdot FNR\right)}{1-prevalence}$$
这个等式似乎是正确的，因为它给出的结果与通常的 $ FPR=\frac{FP}{FP+TN}$ 相同。
我注意到，如果 $FNR+ACC&lt;1$（即敏感度低于准确率），该等式仅显示患病率与 FPR 之间的正相关关系。请参阅此处。
我的问题是：在实际情况下，患病率和 FPR 之间的关系是否可能为负？或者我是否遗漏了某些东西，可以将可能的值限制在关系为正的范围内？
编辑：可能对偶然发现这一点的其他人有帮助：FPR 可以描述为基准率、准确率和 PPV 的函数。对于 PPV &gt; 0.5，基准率和 FPR 之间的关联将始终为正。对于 0 &lt; 准确率 &lt; 1：fpr = ((base+acc-1)*(ppv-1))/((base-1)*(2*ppv-1))]]></description>
      <guid>https://stats.stackexchange.com/questions/658195/is-it-possible-that-false-positive-rate-decreases-with-increasing-prevalence</guid>
      <pubDate>Tue, 03 Dec 2024 11:09:43 GMT</pubDate>
    </item>
    <item>
      <title>广义特征值、矩阵距离、信息几何的解释</title>
      <link>https://stats.stackexchange.com/questions/651758/interpretation-of-generalized-eigenvalues-matrix-distance-information-geometry</link>
      <description><![CDATA[这个问题是关于两个协方差矩阵的广义特征值与它们相关的高斯分布的可辨别性之间的关系。
两个对称矩阵$(\pmb{A}, \pmb{B})$的广义特征值问题是$\pmb{A}\pmb{\Phi} = \pmb{B}\pmb{\Phi}\pmb{\Lambda}$，其中$\pmb{A}$和$\pmb{B}$是对称的$n \times n$ 个矩阵，$\pmb{\Phi} = [\Phi_1, ..., \Phi_n]$ 是一个 $n \times n$ 矩阵，其列是广义特征向量 $\Phi_i$，而 $\pmb{\Lambda}= \mathrm{diag}(\lambda_1, ..., \lambda_n)$ 是一个具有广义特征值的对角矩阵（其中 $\lambda_i \geq \lambda_{i+1}$）。结果与矩阵 $\pmb{B}^{-1}\pmb{A}$ 的常规特征值和特征向量相同。由于 $\pmb{B}^{-1}\pmb{A}$ 通常不对称（尽管它仍然是正定的），因此特征向量 $\Phi_i$ 不一定是正交的。
广义特征值问题与分布之间的可辨别性有关。假设向量 $\pmb{x}$ 是两个分布的混合，由变量 $y \in \{1, 2\}$ 索引。我们如何才能确定两个分布中的哪一个生成了 $\pmb{x}$ 的实例？我们可以使用由 $(\pmb{v}^T\pmb{x})^2$ 提供的二次特征，其中 $||\pmb{v}||=1$。 $\pmb{v}$ 区分两个分布的能力由预期值的比率来衡量
$$R(\pmb{v}) = \frac{\mathbb{E}\left[ (\pmb{v}^T \pmb{x})^2 | y=1\right]}{\mathbb{E}\left[ (\pmb{v}^T \pmb{x})^2 | y=2\right]} = \frac{\pmb{v}^T\pmb{\Sigma_1}\pmb{v}}{\pmb{v}^T\pmb{\Sigma_2}\pmb{v}}$$
事实证明，最大化$R$的$\pmb{v}$由$(\pmb{\Sigma_1},\pmb{\Sigma_2})$的第一个广义特征向量给出，而$R$的值由其相关的特征值给出（查看上面的参考资料）。因此，广义特征值说明了二次判别器如何判别两个分布。
有趣的是，对于 0 中心高斯分布，分布之间的 Fisher-Rao 距离（其度量衡量分布的局部变化的可判别性）由 $\sum_{i=1}^{i=n} (\log \lambda_i)^2$ 给出，其中 $\lambda_i$ 是广义特征值。这也是对称正定 (SPD) 矩阵流形中的仿射不变距离。
因此，考虑到以上所有情况，我的问题如下。很明显，一对协方差矩阵的各个 $\lambda_i$ 如何反映它们的 0 均值高斯沿相应 $\Phi_i$ 的可辨别性。但是，我不太清楚所有特征值加在一起代表什么。数量 $\sum_{i=1}^{i=n} (\log \lambda_i)^2$ 清楚地概括了一些东西，并且直观地看出它如何将 $\lambda_i$ 与 1 相加。但我还想知道不同的 $\Phi_i$ 不正交是如何解释的。关于一对协方差的广义特征值的完整集合与其可辨别性之间的关系，是否可以说得更严格一些？]]></description>
      <guid>https://stats.stackexchange.com/questions/651758/interpretation-of-generalized-eigenvalues-matrix-distance-information-geometry</guid>
      <pubDate>Thu, 25 Jul 2024 15:35:22 GMT</pubDate>
    </item>
    <item>
      <title>在扩散模型（DDPM）中，如果我们预测总噪声，为什么不直接在一次采样中去除噪声呢？</title>
      <link>https://stats.stackexchange.com/questions/650844/in-diffusion-models-ddpm-if-we-predict-the-total-noise-why-not-just-remove-t</link>
      <description><![CDATA[正如 DDPM 论文所指出的，我们可以选择将均值的预测重新参数化为总噪声的预测“εθ 是一个函数近似器，旨在根据 x 预测 ε”（公式 11）。那么，在采样过程中，我们为什么不直接从最后一步（纯噪声）中去除预测的总噪声，而是逐步采样图像？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650844/in-diffusion-models-ddpm-if-we-predict-the-total-noise-why-not-just-remove-t</guid>
      <pubDate>Thu, 11 Jul 2024 03:07:21 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用 CFA 的原始分数还是 z 分数？</title>
      <link>https://stats.stackexchange.com/questions/650175/should-i-use-raw-score-or-z-score-for-cfa</link>
      <description><![CDATA[我正在运行验证性因子分析，我的变量具有不同的尺度。我想知道我是否应该使用原始分数并报告 std.all 列的因子载荷，或者使用 z 分数来运行 CFA。]]></description>
      <guid>https://stats.stackexchange.com/questions/650175/should-i-use-raw-score-or-z-score-for-cfa</guid>
      <pubDate>Sat, 29 Jun 2024 17:50:59 GMT</pubDate>
    </item>
    </channel>
</rss>