<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 15 Apr 2024 09:13:16 GMT</lastBuildDate>
    <item>
      <title>通过非正态数据的多次实验估计特征排名的置信度</title>
      <link>https://stats.stackexchange.com/questions/645040/estimating-confidence-in-feature-rankings-from-multiple-experiments-with-non-nor</link>
      <description><![CDATA[亲爱的交叉验证社区，您好，
我是一名新的生物信息学博士生，我正在研究一个涉及多个实验的项目，每个实验为 7000 个特征中的每一个生成一个数值结果。
目标是找出所有 7000 个特征中价值最高的 20 个特征。
我们多次重复这些实验，以确保结果得到统计数据的支持。因此，每个特征都由每个实验的该特征的所有数值结果的平均值来表征。根据该均值，对特征进行排序，如上所述，只有具有最高均值的 20 个特征才有意义。每个实验都很昂贵，因此我们希望尽量减少实验数量。
我的重点是确定必须进行多少次这样的实验，直到我们有信心前 20 名的排名不会再改变（所以可以说特征 x 保持在排名 3，特征 y 保持在排名） 4，如果我们做更多的实验，它们就不会交换位置）。
挑战在于每个特征的值不呈正态分布。相反，获得的某些值几乎为零（例如 10^(-6)），而其他值则大得多（例如 0.03）。这种非正态性导致我选择非参数方法进行分析（帖子末尾的一个分布图）
采取的方法：
置信区间的引导方法：
为了评估特征均值的可靠性，我使用引导重采样来计算 99% 置信区间。

重采样：对于每次引导迭代 (n_bootstrap = 10,000)，通过替换对数据进行重采样，以创建与原始数据大小相同的新样本。

均值计算：计算每个重采样数据集的均值。

置信区间确定：通过根据引导平均值计算相关百分位数（具体来说，使用指定置信水平的下限和上限）来确定所需的置信区间（例如 99%）。


成对比较的排列测试：
对于前 20 个特征，根据其平均值，我执行了成对排列检验，以评估其平均值之间差异的统计显着性。对前 20 名中的每一对（例如 1 vs 2、1 vs 3、...、19 vs 20）执行此操作，生成有助于推断特征排名之间显着差异的 p 值。
算法如下：

计算成对比较的两个特征的平均值
计算这两个平均值的差异​
将两组放在一起 --&gt;组成一大群​
对大组进行洗牌（排列），并重新创建两个个体
通过拆分打乱的大组进行分组​
计算各个均值以及均值之间的差异（保持一致
顺序，例如有一组 1 和 2 并给他们他们的
值，并且总是将组 1 的平均值减去组 2 的平均值（所以
这些平均差异也可能是负数）​
重复 10,000 次并记下所有排列均值差异​
p值＝排列均值差异“极值”的比例（大
或更小）比原始组的平均差异（两侧）

问题：
这些方法（用于置信区间的引导程序和用于成对比较的排列测试）是否适合这个问题以及我获得一些指标来告诉我如何“稳定”的具体目标？前 20 个特征的排名是（或者当我们进行更多实验时排名是否会发生变化）？它们是否被统计界接受（因为这些方法可能会发表，并且必须在审稿人面前保留）。
如有任何见解、建议或批评，我们将不胜感激。
非常感谢您的帮助！谢谢！
（如果有什么不清楚的地方，请原谅我。我会尽力让它更清楚）
这里是 20 个实验的一个示例性特征的数据分布（x 轴只是实验 1、2、3 等，抱歉质量较差）。
]]></description>
      <guid>https://stats.stackexchange.com/questions/645040/estimating-confidence-in-feature-rankings-from-multiple-experiments-with-non-nor</guid>
      <pubDate>Mon, 15 Apr 2024 08:48:21 GMT</pubDate>
    </item>
    <item>
      <title>在“差中差”中设置对照组和治疗组</title>
      <link>https://stats.stackexchange.com/questions/645039/setting-up-control-and-treatment-groups-in-difference-in-difference</link>
      <description><![CDATA[我目前正在研究疾病流行情况以及在多个州实施的疫苗的有效性。在 24 个州中，有 10 个州启动了疫苗接种计划作为初步措施。影响疫苗接种的因素有很多，包括疫苗接种的可用性和个人的犹豫不决。我的目的是确定新的疫苗接种是否会随着时间的推移影响疾病患病率的降低。我有两组横截面数据：一组是2010年疫苗接种计划在2012年实施之前的数据，另一组是2013年疫苗接种计划实施后的数据。
在实施该计划的州，覆盖率从 50% 到 10% 不等。现在，我正在努力确定适当的对照组和治疗组，以应用双重差分 (DiD) 方法。在这种场景下应用DiD是否可行？您的见解至关重要，因为这构成了我论文工作的基础。]]></description>
      <guid>https://stats.stackexchange.com/questions/645039/setting-up-control-and-treatment-groups-in-difference-in-difference</guid>
      <pubDate>Mon, 15 Apr 2024 08:42:49 GMT</pubDate>
    </item>
    <item>
      <title>PROC LOGISTIC 中 SCORE 语句的 SAS 对数似然拟合统计量</title>
      <link>https://stats.stackexchange.com/questions/645033/sas-log-likelihood-fit-statistic-from-score-statement-in-proc-logistic</link>
      <description><![CDATA[当在 SAS 的 PROC LOGISTIC 中使用 SCORE 语句时，我可以使用 FITSTAT 获得拟合统计数据。我的响应变量是二进制的。
我想获得对数似然，但查看本文档，我实际上不确定 SAS 是否使用了正确的对数似然公式。
这是 SAS 文档中给出的公式（我的数据没有任何频率或权重列）：
$$
\log L =\sum_i f_i w_i \log(\hat\pi_i)。
$$
特别地，公式中的$\hat\pi_i$被认为是“观测的预测概率”。它们的意思是“校正”概率（即 $y_i$ 的观察结果的预测概率）。请参阅此页面供参考。如果您查看 SAS 记录的二进制 Brier 分数公式，就会特别可疑，该公式似乎表明 $\hat\pi_i$ 不是修正后的概率，而只是$y_i=1$ （但也许我读错了；我不太确定所有 $f_i 、 w_i、n_i$ 和 $ r_i$ 变量）。
我的理解是对数似然应该是：
$$
\sum_i y_i \log(p_i) + (1-y_i)\log(1-p_i)
$$
其中 $p_i$ 是 $y_i=1$ 的预测概率。或者，
$$
\sum_i \log(P_i)
$$
其中 $P_i$ 是“校正”概率（即 $P_i= p_i$ 如果 $y_i=1$ 和 $P_i=1-p_i$ 如果 $y_i =0$。）
所以基本上我不确定我是否信任 SAS。发布此内容后，我将尝试在一个小数据集上进行测试以查看，但如果有任何见解，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/645033/sas-log-likelihood-fit-statistic-from-score-statement-in-proc-logistic</guid>
      <pubDate>Mon, 15 Apr 2024 06:37:42 GMT</pubDate>
    </item>
    <item>
      <title>当开始和结束年份产生重大影响时，从嘈杂的时间序列数据中确定稳健的趋势</title>
      <link>https://stats.stackexchange.com/questions/645031/determine-a-robust-trend-from-noisy-time-series-data-when-start-and-end-years-h</link>
      <description><![CDATA[我有大约20年的数据，每年都有一些观察结果。如果我对数据进行线性趋势，我会得到一个趋势，并且该趋势根据开始年份和结束年份的选择而有所不同，这在某种程度上感觉是任意的。是否有一种既定的方法来估计此类数据的时间趋势，您可以在其中采样几年，估计趋势，重新采样等以得出趋势的分布，从而为趋势提供一些置信区间？
我认为移动窗口回归可能是一种选择，但是什么可以指导窗口的选择呢？以及如何整合所有结果来推断趋势。
引导可能是一种选择。进行抽样的原则性方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/645031/determine-a-robust-trend-from-noisy-time-series-data-when-start-and-end-years-h</guid>
      <pubDate>Mon, 15 Apr 2024 05:02:46 GMT</pubDate>
    </item>
    <item>
      <title>如何分解条件后验概率？</title>
      <link>https://stats.stackexchange.com/questions/645029/how-to-decompose-the-conditional-posterior-prob</link>
      <description><![CDATA[我现在正在学习贝叶斯推理。我经常遇到的一个问题是，当我需要计算或简化后验概率时，我不知道应该如何开始，根据我所拥有的。
例如，假设 $$ y|\mu, \sigma^2 \sim N(\mu, \sigma^2)$$
和 $$ \mu \sim N(\theta, \tau^2) $$
其中 $y_i|\mu,\sigma^2 $ 是 iid，$\mu|\theta, \tau^2 $ 是独立同分布的。
如何分解 $p(\mu |\sigma^2, \tau^2, \theta,y)$ 和 $p(\theta |\sigma^2, \tau^2, \mu,y)$?
如果你想用其他例子来解释分解后验分布的一般方法，那也会有很大帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/645029/how-to-decompose-the-conditional-posterior-prob</guid>
      <pubDate>Mon, 15 Apr 2024 02:41:06 GMT</pubDate>
    </item>
    <item>
      <title>我的 glmer 输出有我的固定效应被分成我的因变量的多个因素，我不知道为什么</title>
      <link>https://stats.stackexchange.com/questions/645028/my-glmer-output-has-my-fixed-effects-are-being-split-into-the-multiple-factors-o</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/645028/my-glmer-output-has-my-fixed-effects-are-being-split-into-the-multiple-factors-o</guid>
      <pubDate>Mon, 15 Apr 2024 02:16:28 GMT</pubDate>
    </item>
    <item>
      <title>跨交叉验证折叠的平均 RMSE 值在数学上是否无效？</title>
      <link>https://stats.stackexchange.com/questions/645027/is-averaging-rmse-values-across-cross-validation-folds-mathematically-invalid</link>
      <description><![CDATA[如果我错了，请纠正我，但似乎 scikit-learn 和 tidymodels 都会对所选指标（RMSE、R2 等）进行平均交叉验证折叠。这些指标将被报告，并将作为选择最终模型的基础。
RMSE 不是累加性的。每个折叠的 RMSE 计算都已经应用了平方根。简单地平均 RMSE 结果是否会导致结果添加不必要的噪声？导致更糟糕的模型选择？
MSE 是累加性的，尽管有时折叠可能具有不同数量的观察值，并且真正严格的 MSE 总结需要对观察值数量进行加权平均值。
交叉验证的更好总结似乎是计算整套验证折叠观察的指标，而不是对各个折叠结果的草率总结。
这种做法是否会全面削弱一点模型性能？]]></description>
      <guid>https://stats.stackexchange.com/questions/645027/is-averaging-rmse-values-across-cross-validation-folds-mathematically-invalid</guid>
      <pubDate>Mon, 15 Apr 2024 01:49:48 GMT</pubDate>
    </item>
    <item>
      <title>回归不连续模型中治疗条件的变化</title>
      <link>https://stats.stackexchange.com/questions/645025/variation-in-treatment-condition-in-regression-discontinuity-model</link>
      <description><![CDATA[我有一个关于回归不连续性模型的实现的概念性问题。我正在写一篇论文，研究一项政策的效果，该政策允许在某个地理区域位于州属沿海地区的情况下提供项目资助；然而，各州沿海地区所包含的具体区域各不相同。也就是说，距海岸的距离因州而异，但通常在 1-3 英里之内。我的想法是，对照组应该是距离州沿海地区边界 1、2 或 3 英里以内的区域。我的问题有两个方面。首先，治疗的具体区域因州而异，这重要吗？其次，如果我对某个政策是否被采用作为结果感兴趣（例如二元结果），这在回归不连续性框架中是否可行？]]></description>
      <guid>https://stats.stackexchange.com/questions/645025/variation-in-treatment-condition-in-regression-discontinuity-model</guid>
      <pubDate>Mon, 15 Apr 2024 01:39:50 GMT</pubDate>
    </item>
    <item>
      <title>布朗运动边界的概率分布</title>
      <link>https://stats.stackexchange.com/questions/645024/probability-distribution-for-boundaries-on-brownian-motion</link>
      <description><![CDATA[让我们假设我们有算术布朗运动，并且为了简单起见 $ \mu = 0$ ，所以：
$$ dX(t) = \sigma dW $$
如果 $ X(t) $ 超出范围 $ a  X(t)＜ b $ 对于任何随机游走，游走都会被缩短，并且它保持在原来的值：
$$ dX(t) = \sigma(X(t), a, b) dW $$
哪里
$$ \sigma(X(t), a, b) = \left\{
\开始{数组}{ll}
      0; &amp;X(t)\leq a \\
      v； &amp; a＜ X(t)＜ b \\ 0; &amp; b\leq X(t) \\ \end{array} \right。
$$
由于 $ v $ 是方差，因此 X(t) 的值将再次停止变化（对于此步行）。
该函数的概率分布是多少。我在某处读到这可能是截断的正态分布，但我不知道这是否可以解释布朗运动提前停止的原因。是否有可能通过分析来解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/645024/probability-distribution-for-boundaries-on-brownian-motion</guid>
      <pubDate>Mon, 15 Apr 2024 01:22:57 GMT</pubDate>
    </item>
    <item>
      <title>SPSS 多重共线性 二元 Logistic</title>
      <link>https://stats.stackexchange.com/questions/645020/spss-multicollinearity-binary-logistic</link>
      <description><![CDATA[简单说一下 - 我正在 SPSS 中运行二元逻辑回归，我想检查 VIF 的多重共线性。当因变量是二元时，如何做到这一点 - 是否只是在线性模型中运行共线性诊断？
此外，我注意到当我使用不同的因变量但相同的自变量运行 VIF 时，它们会发生变化。我想知道为什么会出现这种情况，因为我认为只有后者对 VIF 才重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/645020/spss-multicollinearity-binary-logistic</guid>
      <pubDate>Sun, 14 Apr 2024 23:59:50 GMT</pubDate>
    </item>
    <item>
      <title>从业者什么时候理解 CI 很重要</title>
      <link>https://stats.stackexchange.com/questions/644998/when-is-it-important-for-a-practitioner-to-understand-cis</link>
      <description><![CDATA[我有一位医生朋友，他问我有关统计的问题。他对一些事情感到困惑，例如CI 的定义及其复杂性。例如，他发现以下内容令人困惑：表示感兴趣的参数$\theta$。在绘制数据之前，
$$
\mathbb{P}(\theta \in CI) = 1-\alpha。
$$
但是，一旦提取数据，概率就不再存在，真实参数要么在 CI 内，要么不在 CI 内。
我告诉我的朋友，他认为“参数在 CI 内部的概率为 $1-\alpha$”可能是可以的。但我可能错了。所以我正在寻找一个例子：
对于从业者（在本例中为医生）来说，完全理解 CI 的定义何时很重要。最好举一个误解 CI 可能导致错误临床决策的例子。]]></description>
      <guid>https://stats.stackexchange.com/questions/644998/when-is-it-important-for-a-practitioner-to-understand-cis</guid>
      <pubDate>Sun, 14 Apr 2024 17:41:14 GMT</pubDate>
    </item>
    <item>
      <title>我是否需要模型校准/特征归一化才能在 DNN 模型中实现可靠的路径集成梯度/采样 Shapley 特征归因？</title>
      <link>https://stats.stackexchange.com/questions/645030/do-i-need-model-calibration-feature-normalization-for-reliable-path-integrated-g</link>
      <description><![CDATA[路径积分梯度和基于采样 Shapley 的特征归因分析是否需要模型校准和特征归一化才能在深度神经网络模型中正常工作？
我读到，虽然不是严格强制的，但模型校准和特征标准化大大提高了这些归因方法的可靠性和可解释性。如果没有它们，由于尺度或概率分布不佳而导致的固有模型偏差可能会反映在归因中。
但是，我认为这并不意味着 PIG 或 Sampled Shapley 会使问题恶化，而是它们将忠实地代表模型的决策过程，即使该过程由于缺乏校准或标准化而存在缺陷。&lt; /p&gt;
如果我的目标是了解不可靠的模型如何权衡其特征，我是否可以使用 PIG 或采样 Shapley 并接受它们的结果作为该特定模型如何运行的基本事实？
如果我遗漏了什么，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/645030/do-i-need-model-calibration-feature-normalization-for-reliable-path-integrated-g</guid>
      <pubDate>Sun, 14 Apr 2024 01:57:11 GMT</pubDate>
    </item>
    <item>
      <title>ABC（近似贝叶斯计算）采样，模拟复杂模型中的数据</title>
      <link>https://stats.stackexchange.com/questions/644960/abc-approximate-bayesian-computation-sampling-simulating-data-from-complex-mo</link>
      <description><![CDATA[在 ABC 抽样方法、拒绝、MCMC 和 SMC 中，当我们从先验/提案中抽样潜在参数值时，我们会在模型中使用这些参数并模拟数据值。这可以在不直接评估可能性的情况下完成（这通常很困难、昂贵或不可能），然后我们将这些模拟数据值与观察到的数据值进行比较，看看它们是否“足够接近”，如果是，我们接受建议的参数值。这大致就是这些方法背后的共同思想。
我的问题是，除了具有清晰分布函数的简单模型之外，我们如何实际模拟给定参数的复杂模型中的数据？
例如，如果我们使用 Lotka Volterra、SIR、HMM 或 SDE 模型，直接计算可能性是不切实际的，那么我们如何模拟给定参数的数据？
阅读完此主题后，一些人建议在 ODE 模型中使用数值求解器（例如 Runge Kutta 方法），但这与评估模型不一样吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644960/abc-approximate-bayesian-computation-sampling-simulating-data-from-complex-mo</guid>
      <pubDate>Sun, 14 Apr 2024 01:14:20 GMT</pubDate>
    </item>
    <item>
      <title>显着的 PACF 和不显着的 ACF 图对于自相关意味着什么？</title>
      <link>https://stats.stackexchange.com/questions/644868/what-does-a-significant-pacf-and-insignificant-acf-plot-mean-about-autocorrelati</link>
      <description><![CDATA[我是时间序列分析的新手，一直在尝试了解如何正确识别季节性数据中不同类型的自相关。我已经运行了一个游戏，现在正在查看残差。我有以下 ACF 和 PACF，并且正在努力确定存在哪些自相关。如果 ACF 中没有显着性但在 PACF 中显着，这意味着什么？我在网上找不到任何关于这种情况的信息：
]]></description>
      <guid>https://stats.stackexchange.com/questions/644868/what-does-a-significant-pacf-and-insignificant-acf-plot-mean-about-autocorrelati</guid>
      <pubDate>Fri, 12 Apr 2024 10:34:11 GMT</pubDate>
    </item>
    <item>
      <title>为什么在测试测量不变性时，标量不变性模型的自由度比公制模型的自由度小？</title>
      <link>https://stats.stackexchange.com/questions/644504/why-do-i-get-smaller-degrees-of-freedom-for-the-scalar-invariance-model-than-the</link>
      <description><![CDATA[我正在尝试使用 CFA 测试来测试双因素模型中的测量不变性。我有 23 个二进制问题，编码为“正确”和“不正确”我的数据中有 3 个不同的组。每组的样本量约为 200 个。
为了测试测量不变性，我遵循了 Van de Shoot 等人的方法。 (2012) 逐步比较渐进约束模型的过程。我已经估计了配置模型、公制模型和标量模型。检验统计量、拟合指数和模型结果看起来都很好且合理。然而，当我估计标量模型时，结果给出的自由度比度量模型更小。
这有什么可能的原因吗？尽管我很仔细地寻找，但我在互联网上找不到任何东西。有人可以帮助我找到原因或帮助我找到参考资料以更好地理解吗？
这是我运行的代码。
### 双因素配置模型###

model_mck_bifactor_con_2 &lt;- &#39;MCK =~ Q1+Q2A+Q3B+Q3C+Q5+Q6+Q8A+Q8B+Q8C+Q10+Q12B+Q13A+Q13B+Q13C+Q17A+Q18B+Q19A+Q19B+Q19C+Q19D+Q20A+ Q22+Q23
Q8=~Q8A+Q8B+Q8C； Q13=~Q13A+Q13B+Q13C； Q19=~Q19A+Q19B+Q19C+Q19D；
MCK~~0*Q8; MCK~~0*Q13; MCK~~0*Q19;
Q8~~0*Q13; Q8~~0*Q19; Q13~~0*Q19;
Q3B～Q19A+Q19B+Q19C+Q19D； Q3C～Q19A+Q19B+Q19C+Q19D； Q3B ～ Q3C&#39;
### Q3 和 Q19 理论上是相关的。 ###

cfa.configural.mck.bifactor_2 &lt;- cfa(model_mck_bifactor_con_2, data = data_mck, 估计器 = &quot;WLSMV&quot;,ordered=T, group = &quot;COUNTRY&quot;,
                                     缺失=“成对”，参数化=“增量”）

### 公制模型###
cfa.metric.mck.bifactor &lt;- cfa(model_mck_bifactor_con_2，data = data_mck，估计器 =“WLSMV”，ordered=T，group =“COUNTRY”，missing=“pairwise”，
  参数化=“delta”，group.equal=“载荷”）
摘要（cfa.metric.mck.bifactor，fit.measures = TRUE，标准化 = TRUE）

### 标量模型 ###
cfa.scalar.mck.bifactor &lt;- cfa(model_mck_bifactor_con_2，data = data_mck，估计器 =“WLSMV”，ordered=T，group =“COUNTRY”，missing=“pairwise”，
                               参数化=“delta”，group.equal=c(“载荷”，“阈值”))

下面是compareFit测试结果。如您所见，标量模型的 Df 较小。这会导致模型之间的卡方差异检验计算错误。

提前非常感谢。
埃内斯。]]></description>
      <guid>https://stats.stackexchange.com/questions/644504/why-do-i-get-smaller-degrees-of-freedom-for-the-scalar-invariance-model-than-the</guid>
      <pubDate>Sun, 07 Apr 2024 15:42:13 GMT</pubDate>
    </item>
    </channel>
</rss>