<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 28 Dec 2024 01:14:04 GMT</lastBuildDate>
    <item>
      <title>无意识统计学家的条件密度定律</title>
      <link>https://stats.stackexchange.com/questions/659281/law-of-the-unconscious-statistician-for-conditional-density</link>
      <description><![CDATA[根据这个答案，无意识统计学家定律意味着
$$E[h(X) \mid Z=z]=\int h(x) g(x\mid z) ~\mathrm{d}x.$$
但是
$$E[h(X \mid Y) \mid Z=z]呢？$$
这是真的吗
$$E[h(X \mid Y) \mid Z=z] = \int h(x \mid y) g(x\mid z) ~\mathrm{d}x?$$
我之所以问这个问题，是因为我目前正在研究条件得分函数，$\frac{\partial}{\partial \beta}\log h_{Y \mid X, \mathrm{B}}(y \mid x, \beta)$，当对相关参数$\beta^*$的真实值进行评估时，该函数的均值应为零。]]></description>
      <guid>https://stats.stackexchange.com/questions/659281/law-of-the-unconscious-statistician-for-conditional-density</guid>
      <pubDate>Fri, 27 Dec 2024 23:25:10 GMT</pubDate>
    </item>
    <item>
      <title>“两阶段抽样”：合适的名称？</title>
      <link>https://stats.stackexchange.com/questions/659277/two-stage-sampling-appropriate-name</link>
      <description><![CDATA[假设需要基于二元观测估计给定人群中某些特征发生的概率 $p$。例如，通过选择人群样本，对每个人进行测试以检测该条件的存在与否，可以估计出某人患有某种遗传疾病的概率。
众所周知，获得 $p$ 可靠估计所需的样本量精确取决于 $p$（较小的 $p$ 需要较大的样本量）。考虑以下采样方案 (A)：

采集初始样本（使用预定义的大小或使用顺序停止规则），从中获得 $p$ 的粗略估计值。该估计值用于选择第二阶段采样的适当大小，由此获得$p$的最终估计值。

在我正在撰写的论文中，我想将（A）称为两阶段采样方案（它有两个阶段，我认为这个名字很清晰且具有描述性）。然而，“两阶段抽样”或“两阶段集群抽样”这一名称应用到一种集群抽样形式 (B):

给定一个集群群体，每个集群包含一定数量的个体，第一阶段选择集群的一个子集，第二阶段选择每个集群中的某些个体。

另一方面，我看到了限定词“两阶段”在其他情况下使用，而不仅仅是集群抽样，例如：&quot;自回归两阶段模型&quot;、&quot;两阶段最小二乘法&quot;、&quot;两阶段 PCA&quot;。
我的问题：

将 (A) 称为两阶段抽样是否可以接受？ （具体方法当然会在论文中描述）。或者，考虑到该名称适用于/可能适用于 (B)，这会引起混淆吗？
使用名称“两阶段抽样”来表示 (B) 有多普遍？(B) 最常被称为“两阶段集群抽样”吗？（这将为我打算使用该名称扫清障碍）
(A) 还有其他成熟的名称吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/659277/two-stage-sampling-appropriate-name</guid>
      <pubDate>Fri, 27 Dec 2024 21:49:27 GMT</pubDate>
    </item>
    <item>
      <title>U(0, θ) 中 $\dfrac{θ}{2}$ 的置信区间</title>
      <link>https://stats.stackexchange.com/questions/659276/confidence-interval-for-dfrac%ce%b82-in-u0-%ce%b8</link>
      <description><![CDATA[我试图找到 $\dfrac{\theta}{ 2}$ 的置信区间，置信度为 $1-\alpha$，使用 $p_1 = \alpha$, $p_2 = 1$
因此，我采用 $\dfrac{\hat{\theta}}{2} = \dfrac{X_{(n)}}{2}$ 的无偏估计量
然后根据我们在课堂上学到的知识：$$P(\dfrac{cX_{(n)}}{2\theta}&lt;=q_{p_1})=P(\dfrac{X_{(n)}}{\theta}&lt;=\dfrac{2q_{p_1}}{c})=\alpha=(\dfrac{2q_{p_1}}{c})^n \rightarrow q_{p_1}=\dfrac{c}{2}\alpha^{\dfrac{1}{n}}$$ 而对于 $q_{p_2}$ 进行同样的处理将得到 $$q_{p_2} = \dfrac{c}{2}$$ 因此 $$P(\dfrac{c}{2}\alpha^{\dfrac{1}{n}}&lt;=\dfrac{cX_{(n)}}{\theta}&lt;=\dfrac{c}{2})=P(X_{(n)}&lt;=\dfrac{\theta}{2}&lt;=\dfrac{X_{(n)}}{\alpha^{\dfrac{1}{n}}})=1-\alpha$$ 因此 $$\dfrac{\theta}{2}\in[X_{(n)}, \dfrac{X_{(n)}}{\alpha^{\dfrac{1}{n}}}]$$
这看起来正确吗？还是我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659276/confidence-interval-for-dfrac%ce%b82-in-u0-%ce%b8</guid>
      <pubDate>Fri, 27 Dec 2024 21:45:01 GMT</pubDate>
    </item>
    <item>
      <title>命名和分组嵌套随机效应变量</title>
      <link>https://stats.stackexchange.com/questions/659272/naming-and-grouping-nested-random-effect-variables</link>
      <description><![CDATA[我有一个关于如何为混合效应模型命名和分组嵌套随机效应的问题。
我进行了一个实验室实验，其中有 3 个处理方法，A、B、C。每个处理方法都有一个主水箱，将水送入两个处理水箱 - 一个左水箱和一个右水箱。每个处理水箱中混合了两种物种的 10 个生物。当我在 R 中指定&quot;tank&quot;随机效应变量时，它们的 tankID 应该编码为 left 与 right，还是应该为所有水箱赋予一个唯一标识符，例如：
A_left A_right B_left B_right C_left C_right?
我认为应该是第二个，因为重要的不是左/右指定 - 我真的不希望所有的&quot;left&quot;坦克彼此相似 - 这是 10 个生物被分组在一个单独的坦克中，经历相似的环境，并以独特的方式相互作用的效果。但我只是想确认一下，因为我见过它以另一种方式运行。
此外，如果我对它进行编码，以便所有坦克都有一个唯一的 ID，我是否必须指定坦克在模型中嵌套在治疗下？例如 lme(response ~ treatment * species, random = ~1 | treatment / tankID, data = data)？或者在没有嵌套的情况下运行它可以吗，lme(response ~ treatment * species, random = ~1 | tankID, data = data)？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659272/naming-and-grouping-nested-random-effect-variables</guid>
      <pubDate>Fri, 27 Dec 2024 17:29:49 GMT</pubDate>
    </item>
    <item>
      <title>理解如何找到后验（逻辑回归）的问题</title>
      <link>https://stats.stackexchange.com/questions/659271/problem-in-understanding-how-to-find-posterior-logistic-regression</link>
      <description><![CDATA[我有一个问题，我不知道该如何回答，我想得到一些澄清，或者指出我的理解中的问题所在。
我们有一个逻辑回归问题，我们需要根据测量数据找到一个最佳阈值（高于阈值的产品将得到支持，低于阈值的产品将被放弃）：
随机变量 Z 代表“成功”(1) 和“失败”(0)，数据 ($X$) 被认为来自具有某些给定参数的 Gamma 分布。给定 $X=x$，成功的概率是
$$
\Pr(Z=1 | X=x) = \frac{\exp((x-\mu)e^{-\gamma})}{1+\exp((x-\mu)e^{-\gamma})}
$$
其中 $\mu,\gamma$ 是具有平坦先验的未知参数。
我现在应该找到 $\mu,\gamma$ 后验密度对数的表达式，但我不知道如何做。
我考虑过：
$$
f_{\mu|X=x}(\mu_0) = \frac{f_{X|\mu=\mu_0}(x)f_{\mu}(\mu_0)}{f_X(x)}
$$
并且假设 $\mu$ 的先验是某个常数，并且 $f_X$ 具有伽马密度，则后验应该类似于
$$
\log(\frac{f_{X|\mu=\mu_0}(x)}{f_X(x)}) + C = \log(f_{X|\mu=\mu_0}(x)) - \log(f_X(x)) + C
$$
其中 C 是基于 $\mu$ 先验的某个加法常数。
另一方面，我想说的是 $\mu$ 和 $X$ 是独立的，这使得整个表达式只是一个常数，但我不确定它是否正确。
我有点卡在这里，想了解我遗漏了什么。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659271/problem-in-understanding-how-to-find-posterior-logistic-regression</guid>
      <pubDate>Fri, 27 Dec 2024 15:55:07 GMT</pubDate>
    </item>
    <item>
      <title>多元方差分析，其中一些独立变量是分类变量，一些是区间变量</title>
      <link>https://stats.stackexchange.com/questions/659269/manova-with-some-independent-variables-being-categorial-and-some-being-interval</link>
      <description><![CDATA[MANOVA 测试似乎非常适合以下研究，只是因变量不是所需的间隔，我想研究传统和非传统学习者在两种写作类型上的差异，反映在 1) 总体印象、2) 内容、3) 组织、4) 词汇准确性和 5) 语法准确性上。学习者（传统和非传统）和类型（叙述和论证）是两个独立变量。总体而言，内容和组织按 1 到 5 的等级进行评分，因此这三个因变量是序数，而词汇和语法按百分比计算，因此这两个因变量是间隔。
我的问题是 1) 我还可以使用 MANOVA 吗？2) 如果不能，我可以使用什么其他测试？3) 如果可以，我可以使用哪些修改来使 MANOVA 发挥作用？
我对统计学的了解有限，大多数时候使用 SPSS，但如果其他软件可以更有效地处理这个问题，我愿意尝试它们。非常感谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/659269/manova-with-some-independent-variables-being-categorial-and-some-being-interval</guid>
      <pubDate>Fri, 27 Dec 2024 13:37:14 GMT</pubDate>
    </item>
    <item>
      <title>如何描述大多数观测值接近右边界的数据集？</title>
      <link>https://stats.stackexchange.com/questions/659263/how-to-describe-a-dataset-that-most-observations-are-close-to-right-boundary</link>
      <description><![CDATA[我有一个数据集$(x, y)$，其中$x\geq 0$是以分钟为单位的时间，$y\geq 0$是以点为单位的分数。大多数$x$值都接近右边界（图）。
问题。如何描述关系$y=f(x)$？只能通过散点图？
很明显，我尝试使用线性回归（红线）没有奏效。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659263/how-to-describe-a-dataset-that-most-observations-are-close-to-right-boundary</guid>
      <pubDate>Fri, 27 Dec 2024 08:39:05 GMT</pubDate>
    </item>
    <item>
      <title>塔克 (Tucker) 整体因子载荷一致性系数</title>
      <link>https://stats.stackexchange.com/questions/659260/tuckers-congruence-coefficient-on-entire-factor-loadings</link>
      <description><![CDATA[据我所知，Tucker 一致性系数用于评估样本间因子的一致性。例如，在 R 中对双因子模型执行 EFA 后，使用 fa.congruence() 会得到如下矩阵：
Sample1_Factor1 Sample1_Factor2
S​​ample2_Factor1 a c
Sample2_Factor2 b d

但是，计算样本之间的一致性，而不是因子之间的一致性是否也合理？例如：
样本 1：
 Factor_1 Factor_2
Item1 0.8 0.1 
Item2 0.9 0.1
Item3 0.7 0.2
Item4 0.1 0.8
Item5 0.2 0.7
Item6 0.1 0.8

样本 2：
 Factor_1 Factor_2
Item1 0.6 0.2 
Item2 0.8 0.1
Item3 0.8 0.1
Item4 0.1 0.7
Item5 0.2 0.8
Item6 0.2 0.7

在这种情况下，我们是否可以将每个样本的因子载荷连接成一列，如下所示，然后计算一致性？
样本 1：（0.8、0.9、0.7、0.1、0.2、0.1、0.1、0.1、0.2、0.8、0.7、0.8）
样本 2：（0.6、0.8、0.8、0.1、0.2、0.2、0.2、0.1、0.1、0.7、0.8、0.7）

以这种方式计算一致性以评估样本之间的因子相似性是否有效？
从我在 EFA 论文中看到的内容来看，一些研究似乎以这种方式计算样本之间的因子相似性，但我对确切的方法很好奇（因为这些研究没有显示公式或代码，例如）。
另外，是否可以用类似的方式计算每个项目的一致性？例如：
对于项目 1：使用两个向量 (0.8, 0.1; 样本 1) 和 (0.6, 0.2; 样本 2)，可以计算一致性吗？
如果您知道这方面的任何参考资料，请告诉我？]]></description>
      <guid>https://stats.stackexchange.com/questions/659260/tuckers-congruence-coefficient-on-entire-factor-loadings</guid>
      <pubDate>Fri, 27 Dec 2024 07:21:31 GMT</pubDate>
    </item>
    <item>
      <title>韦斯伯格的平方和性质</title>
      <link>https://stats.stackexchange.com/questions/659255/property-of-sums-of-squares-in-weisberg</link>
      <description><![CDATA[在 Weisberg 所著的《应用线性回归》第 23 页中，我看到了 $S_{xx}$ 的这种关系：
$$
\sum (x_i - \bar{x})^2 = \sum(x_i - \bar{x})x_i
$$
有人能解释一下为什么这个等式成立吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659255/property-of-sums-of-squares-in-weisberg</guid>
      <pubDate>Fri, 27 Dec 2024 05:08:30 GMT</pubDate>
    </item>
    <item>
      <title>根据一组百分位数和标准差估计概率密度函数 (PDF)</title>
      <link>https://stats.stackexchange.com/questions/659241/estimate-probability-density-function-pdf-from-a-set-of-percentiles-and-standa</link>
      <description><![CDATA[我有一个逆向工程问题：一个具有 7 个百分位数 (CDF_7) 的 CDF 作为纯文本，以及一个标准差。我使用 CDF_7 百分位数来计算 PDF。我计算的 PDF（左，绿色）（使用导出的数据 CDF_7，蓝色）与机器中的 PDF（右，红色）不同。理想情况下，PDF 应该相等。

我做错了什么？在下面的函数中，我在百分位数之间插入值。在解决这个问题时，涉及标准差是否有用？有没有想过标准偏差在这里如何有助于制作正确的 PDF？
我的 Python 代码：
 import numpy as np
import matplotlib.pyplot as plt

def epdf_hist(cdf_7pct, pct, bins_std):
&quot;&quot;&quot;基于累积分布函数 (CDF) 的 7 个百分位值制作直方图 - 经验概率密度函数 (PDF)

将 7 个百分位值插值到 100 个值，然后分箱
:parameter
cdf_7pct：包含 7 个值的 1 维数组，从高到低排序
pct：7 个百分位数，通常为 [1,5,10,50,90,95,99]
bins_std：包含箱的一维数组，宽度 = 0.2
:返回
100 个插值、分箱值的 pdf，
bins
100 个插值值
&quot;&quot;&quot;
d_pct = np.diff(pct)
cdf_100pct = [] # 生成 100 个值
# 在给定的百分位数值之间进行插值
for i in range(0, len(d_pct)):
arr = np.linspace(cdf_7pct[i], cdf_7pct[i + 1], num=d_pct[i], end=False) # 最后进行插值
cdf_100pct.extend(arr)
cdf_100pct.extend([cdf_7pct[-1]]) # 添加最后一个
cdf_100pct.extend([min(cdf_7pct)+(min(cdf_7pct) - min(arr))]) # 添加一个额外的
count, bins_count = np.histogram(cdf_100pct, bins=bins_std)
返回 count, bins_count, cdf_100pct

# 累积分布函数 (CDF_7) 导出数据
data = np.array([42.38, 42.31, 42.23, 42.03, 41.83,41.81,41.66])
perc = [1,5,10,50,90,95,99]
stdev = 0.15

# 来自机器的 CDF 值
targetbins = np.array([41.6,41.8, 42.0, 42.2,42.4])
c_targetperc = np.array([100,97,58,12,0])
# 来自机器的 PDF 值
p_targetperc = np.array([3,39,46,12,0])

# 计算
epdf_hist_count, epdf_hist_binscount, cdf_100pct = epdf_hist(data, perc, targetbins)
# 图
fig = plt.figure(figsize=(9, 4), layout=&quot;constrained&quot;)
axs = fig.subplots(1, 2, sharex=True, sharey=True)
axs[0].hist(cdf_100pct,bins=targetbins, density=False, color = &#39;green&#39;, alpha = 0.5, label=&quot;PDF i 计算自 CDF_7&quot;)
axs[1].bar(targetbins,p_targetperc, color=&#39;red&#39;, edgecolor=&#39;black&#39;, width=0.2, align=&#39;edge&#39;, alpha = 0.5，label=&quot;机器中的 PDF&quot;)
axs[1].plot(data,perc, &#39;bo--&#39;, label=&quot;从机器导出：CDF_7&quot;)
fig.suptitle(&quot;分布比较&quot;)
for ax in axs:
ax.grid(True)
ax.legend()
ax.set_xlabel(&quot;dB&quot;)
ax.set_ylabel(&quot;发生概率&quot;)
ax.label_outer()
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/659241/estimate-probability-density-function-pdf-from-a-set-of-percentiles-and-standa</guid>
      <pubDate>Thu, 26 Dec 2024 19:50:59 GMT</pubDate>
    </item>
    <item>
      <title>R 中的固定效应 OLS 估计以及各种规范的含义</title>
      <link>https://stats.stackexchange.com/questions/659233/fixed-effects-ols-estimation-in-r-and-what-various-specifications-mean</link>
      <description><![CDATA[我对 R 中与 feols 相关的面板数据有疑问。
假设我有线性回归模型
y_{it}=a+x_{1it}+x_{2it}+error_{it}

其中 i=1,...,T 是国家指数，t=1,...,T 是时期。
在 R 中，我运行这些模型
 模型 A feols(y~ x1| Country[x2], data = mydata) 
模型 B feols(y~ x1+Country/x2, data = mydata) 
模型 C feols(y~ x1+i(Country,x2), data = mydata) 
模型 D feols(y~ x1+i(Country,x2)|Country, data = mydata)
模型 E feols(y~ x1 |Country^year, data = mydata) 
模型 F feols(y~ x1 |Country^year+c(Country,year), data = mydata) 
模型 G feols(y~ x1 |Country[year]+c(Country,year), data = mydata) 

其中我的数据包含“Country”和“year”列。
这些 R 模型对应的计量经济学规范是什么？
我的尝试：
模型 A：y_{it}=x_{1it}+a_i*x_{2it}+error_{it}，其中 a_i 是特定国家/地区的效应。

模型 B：我读到模型 B 得出的估计结果与模型 A 相同，但它的计量经济学规范是什么？

模型 C：y_{it}=x_{1it}+Country_1*x_{2it}+Country_2*x_{2it}+...+Country_N*x_{2it} +error_{it}

其中 Country_1、...、Country_N 为虚拟变量。

模型 D：y_{it}=a_i+x_{1it}+Country_1*x_{2it}+Country_2*x_{2it}+...+Country_N*x_{2it} +error_{it}

其中 Country_1、...、Country_N 为虚拟变量。

模型 E：y_{it}=a_i*lambda_t+x_{1it} +error_{it}，其中 lambda_t 为时间固定效应
]]></description>
      <guid>https://stats.stackexchange.com/questions/659233/fixed-effects-ols-estimation-in-r-and-what-various-specifications-mean</guid>
      <pubDate>Thu, 26 Dec 2024 16:31:23 GMT</pubDate>
    </item>
    <item>
      <title>从指数函数分布获得幂律的必要充分条件？</title>
      <link>https://stats.stackexchange.com/questions/659182/necessary-and-sufficient-conditions-to-obtain-power-law-from-distribution-over-e</link>
      <description><![CDATA[分布 $p(x)$ 的哪些属性 (1) 是充分的且 (2) 是必要的，以使
$$-\log \Bigg(1 - \int_{x=0}^{x=1} p(x) \, (1-x)^k \, dx \Bigg)$$
导致幂律
$$\propto k^{-b}$$
对于某个常数 $b &gt; 0$？
我有一个隐含的假设，即分布 $p(x)$ &quot; n&quot;在某种意义上，但我不确定这个假设到底是什么。也许是平滑的、连续的，还是类似的东西？
我已经得出 Beta 分布和 Kumaraswamy 分布就足够了。从数值上讲，连续伯努利分布也同样有效。我正在寻找这些分布背后的一般“结构”。]]></description>
      <guid>https://stats.stackexchange.com/questions/659182/necessary-and-sufficient-conditions-to-obtain-power-law-from-distribution-over-e</guid>
      <pubDate>Tue, 24 Dec 2024 23:53:30 GMT</pubDate>
    </item>
    <item>
      <title>神经网络不学习正弦函数参数</title>
      <link>https://stats.stackexchange.com/questions/659180/neural-network-not-learning-sinusoidal-function-parameters</link>
      <description><![CDATA[我有一个如下所示的正弦函数，带有预定义的a、b 和 c参数
def fun_sin(a, b, c, apply_noise=False):
&quot;&quot;&quot;
返回表示带噪声的正弦曲线的函数。

参数：
a：正弦波的振幅。
b：正弦波的频率。
c：正弦波的相移。
&quot;&quot;&quot;
def ann(x):
x = torch.tensor(x, dtype=torch.float32).to(device) if not isinstance(x, torch.Tensor) else x.to(device)
return (a * torch.sin(b * x + c)) + torch.tensor(random_gen.random(x.shape) * 0.2 if apply_noise else 0).to(device)
return ann

fun, a, b, c, learning_rate = fun_sin, 4, 0.1, 2, 0.0001

以下是该函数的曲线示例：

我创建了一个神经网络，给定 X（x 轴上的点）和 Y 值（fun_sin(a, b, c)(X) 的结果），我希望我的网络能够确定生成该曲线的 a, b, c 的位置。为了做到这一点，我让输出层输出 3 个值，并创建一个具有这些参数的函数，如下所示
def loss_fun(label, pred):
return torch.mean((label - pred) ** 2)

...

my_model = nn.Sequential(
nn.Linear(X_length, 32),
nn.ReLU(),
nn.Linear(32, 32),
nn.ReLU(),
nn.Linear(32, 3) # 具有 3 个参数 (a, b, c) 的输出层
)
...

my_model.train()
for i in epochs:
optimizer.zero_grad()
pred_a, pred_b, pred_c = my_model(X)
Y_pred = fun_sin(pred_a, pred_b, pred_c)(X)
loss = loss_fun(Y_label, Y_pred)
loss.backward()
optimizer.step()

所以事情是这样的：如果我给网络提供大约 100 个 X 和 Y 数据条目，我的网络就会相当合理地学习；我能够找到 a、b 和 c 的良好预测，这些预测能够呈现与原始曲线非常相似的正弦曲线。但是，如果我传递更多数据，通过增加 X &amp; Y 长度（分批或不分批），网络将停止给出良好的损失结果。
我尝试了多种方法来改善这种情况：

规范化数据
使用各种学习率和不同的调度程序（LambdaLR、OneCycleLR）
创建不太复杂的网络（更少的神经元、更少的层）
创建更复杂和更深的网络
更改优化器（Adam、SGD 等）
进行随机重启
进行梯度裁剪
进行梯度的批量传播与每个时期进行单次传播
消除我在 fun_sin 中的噪音
检查我传递的额外数据是否都很好（绘制图表并检查平均值/标准差）
尝试了各种不同的损失函数，这些函数会对网络的错误进行更多的惩罚

当我有更多数据时，我就是无法获得合理的损失。我读过这篇文章https://arxiv.org/abs/1906.00425，它讨论了为什么神经网络在频率较高时会出现收敛循环曲线的问题，但在我的例子中，驱动频率的参数b非常低（0.1），所以不要认为这适用于这里（此外，如果我的数据较少，网络学习得很好）。
有人知道我在这里可能遇到什么问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659180/neural-network-not-learning-sinusoidal-function-parameters</guid>
      <pubDate>Tue, 24 Dec 2024 22:52:19 GMT</pubDate>
    </item>
    <item>
      <title>在回归中独立性是否意味着条件独立性？</title>
      <link>https://stats.stackexchange.com/questions/659012/does-independence-imply-conditional-independence-in-regression</link>
      <description><![CDATA[我正在阅读统计学习要素（第 44 页），并看到了这句话：

&quot;从统计学的角度来看，如果训练观测值$(x_i, y_i)$代表从其总体中独立随机抽取的样本，则该标准是合理的。即使 $x_i$ 不是随机抽取的，如果 $y_i$ 在给定输入 $x_i$ 的情况下是条件独立的，则该标准仍然有效。&quot;

为了探索这一点，我考虑了两种情况下的联合似然：

情况 1：$(x_i, y_i)$ 完全独立
如果 $(x_i, y_i)$ 对完全独立，则联合似然为：
$$
P(x_1, y_1, \dots, x_n, y_n \mid \theta) = \prod_{i=1}^n P(y_i \mid x_i, \theta) P(x_i \mid \theta)。
$$

案例 2：给定 $x_i$，$y_i$ 的条件独立性&gt;
如果给定 $x_i$，$y_i$ 是条件独立的，则联合似然为：
$$
P(x_1, y_1, \dots, x_n, y_n \mid \theta) = \left( \prod_{i=1}^n P(y_i \mid x_i, \theta) \right) P(x_1, x_2, \dots, x_n \mid \theta)。
$$



观察：

边际：
在情况 1中，由于独立性假设，输入的边际分布分解为$\prod_{i=1}^n P(x_i \mid \theta)$。
在情况 2中，输入的边际分布写为单个项$P(x_1, x_2, \dots, x_n \mid \theta)$，因为没有假设$x_i$。

条件：
在这两种情况下，除去边际，给定$x_i$的$y_i$的条件分布是相同的：
$$
\prod_{i=1}^n P(y_i \mid x_i, \theta)。
$$


这表明，尽管对边际的假设不同，但条件结构并没有不同。

问题：

两种情况下的联合似然方程是否准确，它们是否正确反映了各自的独立性或条件独立性假设？

如果是这样，那么假设$(x_i, y_i)$完全独立（情况 1）是否意味着在给定$x_i$的情况下，$y_i$具有条件独立性，如观察结果所示？

]]></description>
      <guid>https://stats.stackexchange.com/questions/659012/does-independence-imply-conditional-independence-in-regression</guid>
      <pubDate>Fri, 20 Dec 2024 13:04:15 GMT</pubDate>
    </item>
    <item>
      <title>有目的地将纵向数据建模为 iid？</title>
      <link>https://stats.stackexchange.com/questions/658882/purposefully-modelling-longitudinal-data-as-iid</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658882/purposefully-modelling-longitudinal-data-as-iid</guid>
      <pubDate>Tue, 17 Dec 2024 15:38:22 GMT</pubDate>
    </item>
    </channel>
</rss>