<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 01 Dec 2024 21:15:39 GMT</lastBuildDate>
    <item>
      <title>凸且最优投资组合的存在性</title>
      <link>https://stats.stackexchange.com/questions/658099/convex-and-existence-of-optimal-portfolio</link>
      <description><![CDATA[考虑一个基本的静态投资组合选择问题。投资者选择一个投资组合，即将其固定财富的正部分分配到几项金融资产中。金融资产是取值在 (a,b) 范围内的随机变量。
那么，在三种资产的情况下，投资组合 的一个例子是 (1/2,1/4,1/4)。
现在假设我定义凸性如下。如果投资者更喜欢资产 1 而不是资产 2，那么投资者更喜欢资产 1 和资产 2 的投资组合而不是资产 2。
我的问题是，这种凸性假设是否意味着存在一个独特或表现良好的最佳投资组合。最佳投资组合简单地意味着存在一个最佳投资组合。我的直觉告诉我是这样，但我找不到任何参考资料。如果有人能详细解释这一点并提供一些参考，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658099/convex-and-existence-of-optimal-portfolio</guid>
      <pubDate>Sun, 01 Dec 2024 20:18:21 GMT</pubDate>
    </item>
    <item>
      <title>具有交互作用的线性模型中斜率的置信区间</title>
      <link>https://stats.stackexchange.com/questions/658097/confidence-interval-for-a-slope-in-a-linear-model-with-an-interaction</link>
      <description><![CDATA[lm(y ~ x + gender + x*gender)

假设实验单位为 15 名男性和 17 名女性。看来 R 响应上述命令所做的就是拟合截距、要添加到截距中的两个性别之一的量、与 $x$ 相乘的斜率以及要添加到斜率中的两个性别之一的数字。
现在假设误差是同方差的。并且$$\widehat\sigma^{\,2} = \frac{\text{残差平方和}}{\text{error d.f.}}= \frac{\text{s.s.r.}}{15+17-4}.$$
我们想要一个适用于男性的斜率$\beta$的置信区间。我们知道
$$
\widehat\beta \sim\operatorname N\left( \beta, \frac{\sigma^2}{\sum_{i\,\in\,M} (x_i-\overline x)^2} \right)
$$
其中 $M$ 是对应于男性单位的一组指标，而 $\overline x$ 是仅针对男性的观察平均值。
因此
$$
\frac{\widehat\beta-\beta}{\sigma\left/ \sqrt{\sum_{i\,\in\,M} (x_i-\overline x)^2} \right.} \sim\operatorname N(0,1)。
$$
因此
$$
\frac{\widehat\beta-\beta}{\widehat\sigma\left/ \sqrt{\sum_{i\,\in\,M} (x_i-\overline x)^2} \right.} \sim t_{28}。
$$
因此，置信区间的端点应该是
$$
\widehat\beta\pm A\cdot \frac{\widehat\sigma}{\sqrt{\sum_{i\,\in\,M} (x_i-\overline x)^2}}
$$
其中 $A$ 是 $t_{28}$ 分布的适当分位数。
我的问题是 是否有理由使用仅基于男性单位的标准差估计值，而不是 $\widehat\sigma,$，从而涉及 $t_{13}$ 分布？这两种方法各有利弊吗？假设男性和女性的误差方差不同，上述方法就必须被视为错误。
我可以尝试明智地解决这个问题，而不是在这里询问，也许我会这样做，但在这里询问也可能会发现一些有趣的事情。]]></description>
      <guid>https://stats.stackexchange.com/questions/658097/confidence-interval-for-a-slope-in-a-linear-model-with-an-interaction</guid>
      <pubDate>Sun, 01 Dec 2024 19:09:17 GMT</pubDate>
    </item>
    <item>
      <title>根据相关性手动计算路径系数</title>
      <link>https://stats.stackexchange.com/questions/658096/calculating-path-coefficients-manually-from-correlations</link>
      <description><![CDATA[据我了解，在路径模型中，我们可以使用 Wright 的方法根据变量之间的相关性手动计算（标准化）路径系数。在饱和情况下，我们完美地重现相关性，而在非饱和情况下，我们得到模型隐含相关性与真实相关性之间的潜在差异（如果设置为零的路径实际上不为零）。这是计算“模型拟合度”的基础。
当我在 R 中使用 lavaan 运行路径模型时，程序会经过几次“迭代”以拟合最佳模型。但是，如果我们可以根据相关性手动计算系数，为什么我们需要经过多次迭代的优化程序？如果有人能解释，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658096/calculating-path-coefficients-manually-from-correlations</guid>
      <pubDate>Sun, 01 Dec 2024 18:49:21 GMT</pubDate>
    </item>
    <item>
      <title>如何最好地利用比率数据进行机器学习分类主动学习循环？</title>
      <link>https://stats.stackexchange.com/questions/658093/how-best-to-approach-ml-classification-active-learning-loop-with-ratio-data</link>
      <description><![CDATA[我目前正在进行一个项目，试图研究分子与其相行为（在本例中为二元）之间的结构-性质关系。分子具有主链和任意数量的侧链，并且每个侧链可以具有一系列长度和柔韧性。因此，任何一个分子的数据都是主链长度、主链上侧链所在位置的 1D 数组、指定侧链长度的相同长度的 1D 数组、主链柔韧性的值（10-100，以 10 的倍数表示，从最柔韧性到最不柔韧性），以及给出每个侧链柔韧性的最终数组。还要注意，数据中存在依赖性，即如果主链较长，侧链也可能更长，并且侧链数量可能更多。
我试图将这些特征与我的二元结果联系起来，但标记成本很高，因此我正在进行基于池的主动学习，以尽可能少的数据获得良好的替代模型。在我看来，有两个选项，我不知道哪个最好。按照上述描述顺序的一个分子的示例数据：
10 [2,4,7] [9,1,5] 100 [10,80,40]

我已经知道，我可以通过对每个模型进行短暂模拟计算出的几何描述符与目标（模拟长度约为 30 分钟）有很好的相关性。要获得整个未标记池的这些描述符是不可能的，因为如果我将主链长度从 4 变为 14，并允许所有可能的数量、位置、弯曲和侧链长度，那么分子的总组合将达到数百万。所以我需要从代表总体的搜索空间中抽样，理想情况下最终得到 2000 个或更少的分子。我真的不太确定如何做到这一点，因为它是比率数据，我认为传统的技术（如 PCA）不能很好地处理它。另一个问题是，我需要对更大、更刚性的分子进行过度采样，否则最终会得到不平衡的类别分布。目前，我正尝试根据直觉对一个全面的未标记池进行采样，该池涵盖了分子特征的主要变化，但我想知道是否有更强大的方法。

跳过几何描述符，让代理模型直接使用初始数据中的分子特征。在我的数据上，随机森林效果很好，所以这是代理模型的计划，我知道它可以很好地处理分类数据。但我认为我的数据格式不正确，如果我进行独热编码，我会担心数据稀疏性。我见过有人建议散列，但我需要能够从散列数据中恢复分子，这样我才知道在 AL 循环中标记期间要模拟什么。有一件事是，理想情况下，我希望避免使用 VAE 等无监督技术，因为我遇到了很多与这些技术重建质量有关的问题。理想情况下，我可以通过某种巧妙的方法将数据（甚至是构建数据组合的特征工程）转换为随机森林的输入。


如果有人有任何全面且可实施的方法来实现上述任何一个目标，我们将不胜感激。我目前正在使用 sklearn 和 ALiPy 进行代理和 AL 循环。]]></description>
      <guid>https://stats.stackexchange.com/questions/658093/how-best-to-approach-ml-classification-active-learning-loop-with-ratio-data</guid>
      <pubDate>Sun, 01 Dec 2024 14:57:19 GMT</pubDate>
    </item>
    <item>
      <title>协方差对 Stata 来说意味着什么？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658089/what-does-covariance-mean-to-stata</link>
      <description><![CDATA[
我的问题

我想解释 Stata 给我的 ESS 和 RSS 结果，针对一个解释变量和一个响应变量。

我迄今为止尝试过的方法

我尝试过如何使用术语“协方差”来解释这些值。但是，据我理解，协方差可以有多种含义。我不知道 Stata 使用哪种含义。
我已在 Google 和 Cross Validated 上查找答案，但未找到有关 Stata 的具体答案。

定义

在 Stata 上，当我通过输入以下命令启动回归分析时：
reg 响应变量的名称 解释变量的名称
Stata 显示总平方和以及解释和未解释的平方和。
我的理解方式是：

TSS：最佳拟合线与响应变量均值之间的平方差之和。
ESS：响应变量均值与每个数据点之间的平方差之和。 ESS 是解释平方和。
RSS：最佳拟合线与每个数据点之间的平方差之和。RSS 是未解释平方和。

这里的“解释”是指“协方差”。
我理解协方差的方式如下：

两个变量单调相关的程度。
当一个变量增加时，另一个变量是增加还是减少？


我的问题

我的问题是：协方差对 Stata 意味着什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658089/what-does-covariance-mean-to-stata</guid>
      <pubDate>Sun, 01 Dec 2024 12:39:00 GMT</pubDate>
    </item>
    <item>
      <title>在我的案例中选择正确的统计测试</title>
      <link>https://stats.stackexchange.com/questions/658069/choose-the-right-statistical-test-in-my-case</link>
      <description><![CDATA[我有一个调查数据集，其中每个参与者回答了 20 个独特的问题。我想对数据进行统计分析，但不确定要使用哪种测试：方差分析、重复测量方差分析还是混合效应模型？
我想用于统计测试的数据是问题类型和响应时间。
https://docs.google.com/spreadsheets/d/16cwLFGaF4KqLvwYNjHIcCyHaWup8vSJpL7gOEqk_XPA/edit?usp=sharing
我想测试的假设是问题类型对响应时间有影响吗？
问题时间有 4 种模式，响应时间是以秒为单位的数值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658069/choose-the-right-statistical-test-in-my-case</guid>
      <pubDate>Sat, 30 Nov 2024 14:09:41 GMT</pubDate>
    </item>
    <item>
      <title>无法从分布不同的多台设备的数据中提取模式</title>
      <link>https://stats.stackexchange.com/questions/657979/unable-to-extract-pattern-from-data-from-multiple-devices-with-different-distrib</link>
      <description><![CDATA[我获得了一组以时间序列形式呈现的 3 种不同物联网 (IoT) 设备的电流强度（唯一特征）测量数据集。

每台设备都进行了多次测量，持续时间不同。

每次测量的测量结果均为 csv 格式。

采样频率为 100ms。每个设备的数值范围不同。
我想搜索 IoT 设备运行期间出现的任何模式。显然，具有不同功能的不同设备具有完全不同的行为和分布。
我已经制作了所有测量值的直方图，尽管某些测量值的分布有相似之处，但每个直方图都没有任何共同的特定特征（如有必要，我可以提供图像）。
此外，我已经计算了测量值的相关矩阵，数据之间几乎没有相关性（几乎每种情况下，每个测量值与其他测量值的相关性几乎为 0）。
不用说，在大多数情况下，测量时间序列的图没有任何共同的模式（至少在视觉上）。对于上述所有方法，我都使用了移动平均线来平滑曲线并保持趋势，并使用标准缩放对数据进行规范化。
没有提供有关设备的元数据（例如，设备是 5V 还是 3.3V，其用途是什么等）。我与测量设置和数据收集过程无关。此外，我还没有执行过 ARIMA 或任何其他类似方法。
我的最终目的是构建一个用于异常检测的机器学习系统。
我正在考虑建立一个将用于迁移学习的模型。
我最近还了解了领域泛化和元学习的存在。
您对此类问题有什么建议或经验可以与我分享吗？您能为我的情况提供一些指导吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657979/unable-to-extract-pattern-from-data-from-multiple-devices-with-different-distrib</guid>
      <pubDate>Thu, 28 Nov 2024 13:18:38 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在处理一个重复测量数据集，其中个人/单位/实体代表医疗机构。研究的目的是观察机构特征 (X) 对由于某种医疗状况 (Y) 导致的几家医疗机构的死亡人数的影响。Y 表示在跨越多年的时间段内每周测量的死亡人数。X 表示在整个研究过程中在多个时间点（每周、每季度、研究开始/结束）测量的连续/分类变量。变量 Y 是零膨胀的，并且由于在模型中包含太多预测因子而导致数值问题。
我的一组 X 变量 (u1、u2、...、un) 与一组其他变量 (v1、v2、...、vn) 相关。这使我无法在同一模型中同时建模 U（总共约 50 个）和 V（总共约 5 个）变量。因此，我对 U 变量进行了建模，并选择了对 Y 有显著影响的 U 变量子集。利用这个子集，我执行了 PCA，并在最终模型中将 PCA 分数与 V 变量一起使用。我相信这样做可以让它们（U 变量和 V 变量的 PCA 分数）彼此不相关，同时在估计 V 变量时会纳入 U 变量的净效应。
我的最终目标是获得与时间无关的 V 变量预测。
在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法涉及以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 之间的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除非数字变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不均等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    <item>
      <title>单位根检验的功效</title>
      <link>https://stats.stackexchange.com/questions/657723/power-of-unit-root-tests</link>
      <description><![CDATA[我正在测试基本单位根检验的功效：ADF、PP 和 DFGLS。
具体来说，我正在生成这个序列：
$$y_t = \text{drift} + (\text{trend_coeff} \cdot t) + (\phi \cdot y_{t-1}) + e_t$$
对于 $\phi$ 的范围，介于 0 和 1 之间，包括 0 和 1。
从数学上讲，这从 [0,1) 得出一个趋势平稳过程：

在 $\phi$ = 1 时，它会产生一个具有随机趋势的过程：

对 $\phi = [0,1)$ 执行任何单位根检验都应拒绝零假设并接受平稳性，在 $\phi = 1$ 时，它应接受单位根的零假设。
期望：通过从结果中绘制 p 值，应该期望看到 $\phi = [0,1)$ 低 p 值（至少低于显着性水平），因为这将拒绝单位根检验的零值，并且看到 $\phi = 1$ 大 p 值（至少大于显着性水平），因为这意味着接受零值。
结果：
ADF 和 ADFGLS 都使用“AIC”，PP 使用 Newey-West 估计量进行滞后选择。
样本数量：300
drift=30
trend_coeff=10
sigma=20
模拟次数 = 20

问题：ADF-GLS 返回该钟形曲线的原因可能是什么？它不应该是 ADF 的改进版本吗？
注意：我在 python 中使用 Arch lib 中的 DFGLS。]]></description>
      <guid>https://stats.stackexchange.com/questions/657723/power-of-unit-root-tests</guid>
      <pubDate>Sat, 23 Nov 2024 14:04:38 GMT</pubDate>
    </item>
    <item>
      <title>以不同时间频率收集变量的纵向回归模型？</title>
      <link>https://stats.stackexchange.com/questions/655840/longitudinal-regression-models-with-variables-collected-at-different-time-freque</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655840/longitudinal-regression-models-with-variables-collected-at-different-time-freque</guid>
      <pubDate>Wed, 16 Oct 2024 05:18:50 GMT</pubDate>
    </item>
    <item>
      <title>如果分类变量保留在 R 中的最终模型中，那么为什么事后分析表明水平没有差异？</title>
      <link>https://stats.stackexchange.com/questions/655810/if-the-categorical-variable-is-retained-in-my-final-model-in-r-then-why-does-th</link>
      <description><![CDATA[我正在使用 R 中的 anova() 函数进行模型选择，并且我的分类变量在我的最终模型中得到了保留，但是当我使用 emmeans() 函数进行事后分析时，它告诉我水平没有差异。这是什么意思？
我使用 R 软件，我正在研究一种鱼的身体状况在三种河流中的变化：保护性、轻微城市化和高度城市化。每个类别都有一个重复，这意味着我有 2 条保护性河流、2 条轻微城市化河流和 2 条高度城市化河流，这意味着“河流”是一个随机因素，“城市化类别”是我的固定因素和具有 3 个级别的预测变量。在使用 anova() 函数在 R 中执行模型选择时，分类变量“类别”得到保留：
`#它是一个线性混合模型，因为条件呈正态分布
&gt; lmm.1 &lt;- lmer(条件 ~ 城市化类别 + (1|河流), 数据 = 鱼) 
&gt; lmm.null &lt;- lmer(条件 ~ 1 + (1|河流), 数据 = 鱼) 
&gt; anova(lmm.null, lmm.1)
使用 ML（而不是 REML）重新拟合模型
数据：鱼
模型：
lmm.null：条件 ~ 1 + (1 | 河流)
lmm.1：条件 ~ 城市化类别 + (1 | 河流)
npar AIC BIC logLik 偏差 Chisq Df Pr(&gt;Chisq)
lmm.null 3 -214.42 -205.37 110.21 -220.42
lmm.1 5 -219.80 -204.71 114.90 -229.80 9.3806 2 0.009184 **
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1`

`
我忘记在我的问题中包含我的模型摘要，所以这里是：
&gt; summary(lmm.1)
REML [&#39;lmerMod&#39;] 拟合的线性混合模型
公式：条件 ~ 城市化类别 + (1 | 河流)
数据：鱼

收敛时的 REML 标准：-214.3

缩放残差：
最小 1Q 中位数 3Q 最大
-2.65967 -0.54776 -0.07734 0.56748 2.79995

随机效应：
组名称方差标准差。
河流（截距）0.001965 0.04432 
残差 0.012381 0.11127 
观测数：151，组：河流，6

固定效应：
估计标准差。误差 t 值
（截距） -0.12808 0.04154 -3.084
category.of.urbanizationslightly 0.15972 0.05376 2.971
category.of.urbanizationvery 0.17063 0.05432 3.141

固定效应相关性：
（截距） ctgr.d.rbnzcp
ctgr.d.rbnzcp -0.773 
ctgr.d.rbnzcm -0.765 0.591 

我的 p 值为 0.009184，这意味着城市化类别是一个重要的预测因素，我预计分类变量的至少一个级别会与其他级别不同。然而，当尝试进行事后分析时，我调用了 emmeans() 函数，R 说所有水平都没有差异，因为 p 值都高于 0.05：
`&gt; emmeans(lmm.1，成对 ~ category.of.urbanization)
已注册的 S3 方法被“broom”覆盖：
方法来自 
tidy.glht jtools
tidy.summary.glht jtools
$emmeans
category.of.urbanization emmean SE df lower.CL upper.CL
保留 -0.1281 0.0441 3.42 -0.2592 0.00304
略微城市化 0.0316 0.0341 2.20 -0.1030 0.16632
非常城市化 0.0425 0.0350 2.43 -0.0852 0.17032

自由度方法：kenward-roger
使用的置信度：0.95

$contrasts
对比估计 SE df t.ratio p.value
保留 - 略带城市化 -0.1597 0.0558 2.83 -2.863 0.1324
保留 - 非常城市化 -0.1706 0.0563 2.95 -3.028 0.1123
略带城市化 - 非常城市化 -0.0109 0.0489 2.32 -0.223 0.9733

自由度方法：kenward-roger
P 值调整：用于比较 3 个估计值的 Tukey 方法`

请问，这是什么意思？预测变量如何显著，但水平没有差异？我有 151 条鱼，所以我的数据和观察值数量不是很低。如果我犯了拼写错误，我很抱歉，英语不是我的母语。]]></description>
      <guid>https://stats.stackexchange.com/questions/655810/if-the-categorical-variable-is-retained-in-my-final-model-in-r-then-why-does-th</guid>
      <pubDate>Tue, 15 Oct 2024 13:48:27 GMT</pubDate>
    </item>
    <item>
      <title>证明 $\mathbb{E} (|X-Y|) = 0 \implies X^2 = Y^2$</title>
      <link>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</link>
      <description><![CDATA[$\boxed{\text{设 } X,Y \text{ 为任意随机变量。证明如果 } \mathbb{E}(​​|X-Y|) = 0，\text{则 } X^2 = Y^2。}$
我们有 $\mathbb{E}(​​|X-Y|) = 0$，我认为如果我能以某种方式证明 $X=Y$，那么它直接意味着 $X^2 = Y^2$，但我不知道如何实现。
附言：这不是任何形式的家庭作业，我只是在大学概率课程的往期考试中看到了这个问题，想尝试一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</guid>
      <pubDate>Wed, 09 Oct 2024 19:54:07 GMT</pubDate>
    </item>
    <item>
      <title>从 $N$ 个样本中取出距离平均值最远的 $n$ 个样本与正态分布的近似程度如何？</title>
      <link>https://stats.stackexchange.com/questions/655004/how-well-does-taking-the-n-out-of-n-samples-farthest-from-the-mean-approxima</link>
      <description><![CDATA[从正态分布中抽取 $N$ 次样本。取 $n&lt;N$ 个“最差”样本（即距离平均值最远且最大化 $|x-\mu|$ 的样本）。我推测近似平均值的最佳方法就是取所有这些值的平均值，因为我们预计它们均匀分布在尾部。这个近似值会像取 $n$ 个“最佳”样本一样准确吗？样本（即最小化 $|x-\mu|$ 的样本）或 $n$ 个随机样本？
直观地，我认为从这个过程获得的平均平均值将与采取最佳、最差或随机采样方法无关。但是，如果我们以 $n=7$ 作为最佳样本，我们可能期望得到与 $n=6$ 或 $8$ 类似的近似值，但如果我们以 $7$ 作为最差近似值，我们不能期望其中一个接近平均值，因此我们可能期望它将近似平均值显著地移到一侧。
因此，我可能期望所有这些采样方法的平均平均值相同，但对于“最差样本”方法，此近似值的标准偏差最高？有什么方法可以量化这一点吗？ $n$ 是奇数还是偶数对近似值的影响足够大，以至于例如 $n=6$ 的方差可能低于 $n=7$？]]></description>
      <guid>https://stats.stackexchange.com/questions/655004/how-well-does-taking-the-n-out-of-n-samples-farthest-from-the-mean-approxima</guid>
      <pubDate>Fri, 27 Sep 2024 11:51:54 GMT</pubDate>
    </item>
    <item>
      <title>观测值对的最大似然估计</title>
      <link>https://stats.stackexchange.com/questions/654753/maximum-likelihood-estimation-for-pairs-of-observations</link>
      <description><![CDATA[我有 $n$ 对观测值 $(x_i,y_i)$，其中每个 $y_i$ 都按照 $\text{Pois}(\theta x_i)$ 分布，我希望仅基于这些数据对 $\theta$ 进行最大似然估计。对于 $x_i$，没有已知的分布，因此我认为我无法进行条件最大似然，因为我没有 $x_i$ 的边际概率。
我的方法是找到对数似然函数 $L(\theta x_i)$，然后仅根据 $\theta$ 进行推导，这样我就有了 $\theta$ 的估计量 - 对于这个，我的对数似然函数是
$$\sum[-\theta x_i + y_ilog(\theta x_i) - log(y_i!)],$$
这给了我估计器
$$\hat{\theta} = \frac{\sum y_i}{\sum x_i}.$$
这是一种合适的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654753/maximum-likelihood-estimation-for-pairs-of-observations</guid>
      <pubDate>Mon, 23 Sep 2024 06:08:45 GMT</pubDate>
    </item>
    <item>
      <title>在扩散模型（DDPM）中，如果我们预测总噪声，为什么不直接在一次采样中去除噪声呢？</title>
      <link>https://stats.stackexchange.com/questions/650844/in-diffusion-models-ddpm-if-we-predict-the-total-noise-why-not-just-remove-t</link>
      <description><![CDATA[正如 DDPM 论文所指出的，我们可以选择将均值的预测重新参数化为总噪声的预测“εθ 是一个函数近似器，旨在根据 x 预测 ε”（公式 11）。那么，在采样过程中，我们为什么不直接从最后一步（纯噪声）中去除预测的总噪声，而是逐步采样图像？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650844/in-diffusion-models-ddpm-if-we-predict-the-total-noise-why-not-just-remove-t</guid>
      <pubDate>Thu, 11 Jul 2024 03:07:21 GMT</pubDate>
    </item>
    </channel>
</rss>