<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 01 Jul 2024 21:14:26 GMT</lastBuildDate>
    <item>
      <title>是否可以使用 nlme 在跨多个非线性响应参数的非线性混合效应模型中重用预测器固定参数？</title>
      <link>https://stats.stackexchange.com/questions/650282/is-it-possible-to-reuse-predictor-fixed-parameters-in-a-nonlinear-mixed-effects</link>
      <description><![CDATA[我有数据，我想用这些数据拟合一个模型，因为我知道一个阶段在时间零点的值等于前一个阶段的渐近值。具体来说，我有遵循 R 中的 SSasymp 函数的动力学增长曲线，这样每次改变工艺条件时，预测的非线性参数都会发生变化。有时它们会上升，有时它们会下降。但是，我使用的协议是一致的。
在 nlme 中实现此约束有什么技巧吗？还是我必须使用 saemix 来实现这样的事情？]]></description>
      <guid>https://stats.stackexchange.com/questions/650282/is-it-possible-to-reuse-predictor-fixed-parameters-in-a-nonlinear-mixed-effects</guid>
      <pubDate>Mon, 01 Jul 2024 20:48:33 GMT</pubDate>
    </item>
    <item>
      <title>处理 Cox 回归中的低方差分类变量</title>
      <link>https://stats.stackexchange.com/questions/650280/dealing-with-low-variance-categorical-variables-on-cox-regression</link>
      <description><![CDATA[我正在用时间变量 cox 模型拟合我的生存数据，并从每个类别中删除一个任意分类变量，以创建基线风险。我有一些低方差分类变量。如果我删除它们，它们会增加基线风险吗？我应该如何处理低方差分类变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/650280/dealing-with-low-variance-categorical-variables-on-cox-regression</guid>
      <pubDate>Mon, 01 Jul 2024 20:30:25 GMT</pubDate>
    </item>
    <item>
      <title>网格级空间固定效应（具有时间和季节性）</title>
      <link>https://stats.stackexchange.com/questions/650278/grid-level-spatial-fixed-effects-with-time-and-seasonality</link>
      <description><![CDATA[我是因果推理的新手，希望得到一些关于我的研究设计的指导。
我有面板数据，其中报告了人类与野生动物冲突的日期和网格单元位置：
我试图隔离极端降水和温度对冲突率的影响。我正在考虑使用网格单元和月-年固定效应。控制这些会消除大多数异质性吗，还是我应该包括其他控制变量？空间自相关有什么需要注意的吗？这些显然具有大量的季节性——应该如何将其与月-年固定效应进行比较？非常感谢您对如何制定最佳因果识别策略的见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/650278/grid-level-spatial-fixed-effects-with-time-and-seasonality</guid>
      <pubDate>Mon, 01 Jul 2024 20:03:50 GMT</pubDate>
    </item>
    <item>
      <title>假设样本秩相关完美且无联系，则最小皮尔逊样本相关系数是多少？</title>
      <link>https://stats.stackexchange.com/questions/650277/what-is-the-minimum-pearson-sample-correlation-given-a-perfect-sample-rank-corre</link>
      <description><![CDATA[令 $(X, Y)$ 为有限大小 $n$ 的随机样本，样本来自具有未知参数 $(\rho_{XY},\mu_X,\mu_Y,\sigma_X,\sigma_Y)$ 的二元连续分布。假设观测值为实数，且平局发生的概率为 0。令 $r_P$ 为样本 Pearson 相关系数，令 $r_S$ 为样本 Spearman 等级相关系数。如果 $r_S$ = 1，很容易看出 $r_P$ 不能小于 0。
仅给定上述规范，当 $r_S$ = 1 时，$r_P$ 是否有大于 0 的下限？如果我们添加双变量正态总体和/或正相关参数 $\rho &gt; 0$ 的约束会怎样？
这是一般问题的一个特例：“对于没有平局的固定等级，$r_P$ 的分布是什么？”这也很有趣，但大概没有必要回答我这个更狭隘的问题。不过，如果你能告诉我是否有可能在给定范围内获得 $r_P$ 的所有可能值，我会得到很大的加分。
请注意，我的问题是关于这些统计数据的样本值。我知道 $r_P$ 测量总体关系的线性，而 $r_S$ 测量其单调性。在双变量正态性下，两个参数之间的关系在此处给出，但这并没有回答我关于样本范围的问题。此外，虽然如果对 $\rho$ 或 $n$ 施加极端限制，该问题的答案可能会相对简单，但我正在寻找一个更通用的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/650277/what-is-the-minimum-pearson-sample-correlation-given-a-perfect-sample-rank-corre</guid>
      <pubDate>Mon, 01 Jul 2024 19:43:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么`pROC::roc`默认计算$\max\{AUC, 1 - AUC\}$？</title>
      <link>https://stats.stackexchange.com/questions/650273/why-would-procroc-calculate-max-auc-1-auc-by-default</link>
      <description><![CDATA[R 中的 pROC::roc 函数有一些有趣的行为。
library(pROC)
set.seed(2024)
N &lt;- 100
p &lt;- rbeta(N, 1/2, 1/2)
y &lt;- rbinom(N, 1, p)
r1 &lt;- pROC::roc(y, p)
r2 &lt;- pROC::roc(y, 1 - p)
r1$auc # 我得到 0.8894
r2$auc # 我得到 0.8894

无论我们使用概率（p）还是翻转所有概率（1-p），该函数都会计算相同的面积ROC 曲线。
但这与通常的计算 ROC 曲线的思路不一致，即通过改变截止阈值并计算每个阈值的灵敏度-特异性对。其中一个应该显示接近 1 的相当高的 AUC，而另一个应该显示接近 0 的相当低的 AUC。毕竟，当我们将 p 翻转为 1-p 时，高概率值通常对应于 1 的值，低概率值通常对应于 0 的值，相反，情况正好相反，这会导致可怕的敏感度和特异性值。
library(ModelMetrics)
thresholds &lt;- r1$thresholds
sens1 &lt;- spec1 &lt;- sens2 &lt;- spec2 &lt;- rep(NA, length(thresholds))
yhat1 &lt;- yhat2 &lt;- rep(0, length(thresholds))
for (i in 1:length(thresholds)){

# 我忘了如何以更清晰的方式与阈值进行比较
#
idx1 &lt;- which(p &gt; Thresholds[i])
idx2 &lt;- which(1 - p &gt; 阈值[i])
#
yhat1[idx1] &lt;- 1 
yhat1[-idx1] &lt;- 0 
yhat2[idx2] &lt;- 1 
yhat2[-idx2] &lt;- 0

sens1[i] &lt;- ModelMetrics::sensitivity(y, yhat1)
sens2[i] &lt;- ModelMetrics::sensitivity(y, yhat2)
#
spec1[i] &lt;- ModelMetrics::specificity(y, yhat1)
spec2[i] &lt;- ModelMetrics::specificity(y, yhat2)

}
plot(r1)
points(spec1, sens1, col = &#39;blue&#39;)
points(spec2, sens2, col = &#39;red&#39;)

绘图这样，与 1-p 预测相对应的红色曲线的曲线下面积非常糟糕，正如预期的那样。
因此，我很好奇为什么 pROC::roc 会计算出 AUC 对于如此不同的输入是相同的，一个具有良好的概率值，另一个具有糟糕的概率值。幸运的是，pROC::roc 可以与 direction = &quot;&lt;&quot; 一起运行，以防止函数输出 $\max\{AUC, 1 - AUC\}$，而是返回真实的 AUC 值。但是，这不是默认行为？函数返回 $\max\{AUC, 1 - AUC\}$ 而不是仅仅返回 AUC，这是否有一些统计原因？我想我可以看到一个论点，即$AUC&lt;0.5$意味着对预测值进行简单的转换会给出$AUC&gt;0.5$，但你必须知道要执行这样的校准步骤，否则你会使用可怕的预测值。
由于软件包开发人员是 Cross Validated 的成员，因此我对来自此类来源的答案特别感兴趣。]]></description>
      <guid>https://stats.stackexchange.com/questions/650273/why-would-procroc-calculate-max-auc-1-auc-by-default</guid>
      <pubDate>Mon, 01 Jul 2024 17:47:29 GMT</pubDate>
    </item>
    <item>
      <title>二项式随机变量的期望</title>
      <link>https://stats.stackexchange.com/questions/650271/expectation-of-binomial-random-variable</link>
      <description><![CDATA[最近在一篇论文中读到一些东西，但一直无法理解。
假设我们有 X ~ Binomial(N,p)。论文指出：
$E[X | N,p] = Np$（目前一切顺利）
并且
$E[X] = \mu p$
如果对于 Binomial(N,p)，$\mu$ 定义为 $Np$，那么第二行中的 $p$ 来自哪里？]]></description>
      <guid>https://stats.stackexchange.com/questions/650271/expectation-of-binomial-random-variable</guid>
      <pubDate>Mon, 01 Jul 2024 17:26:16 GMT</pubDate>
    </item>
    <item>
      <title>如何对多个回归模型中的多个系数进行联合显着性检验？</title>
      <link>https://stats.stackexchange.com/questions/650270/how-to-perform-a-joint-significance-test-for-multiple-coefficients-across-severa</link>
      <description><![CDATA[我有 10 个回归模型，每个模型对同一个独立变量 $ x $ 回归不同的因变量 $ y_i $ (对于 $ i = 1, 2, \ldots, 10 $)。每个模型都会产生一个 $ x $ 的系数，我有兴趣测试这 10 个系数的联合重要性。
具体来说，我的模型是：
$ y_1 = \beta_{1x} x + \epsilon_1 $
$ y_2 = \beta_{2x} x + \epsilon_2 $
$ \vdots $
$ y_{10} = \beta_{10x} x + \epsilon_{10} $
我想知道测试所有 $\beta_{ix}$（对于 $ i = 1, 2, \ldots, 10 $）与零的联合显著不同。
背景是，我有一个技术冲击 x，它影响不同的地区，并且随时间变化，预计会影响这些地区的行业 y 的就业。我已经建立了这种联系。但是，为了证明我的冲击与位置级别的其他潜在因素无关，我想表明我的冲击无法预测其他所谓不相关行业的就业。这就是为什么我将这些其他行业作为安慰剂行业。
我的结果变量（不同的 y）代表不同地区不同行业的就业，它们具有不同的量级，因此可能具有不同的方差。我的模型中有区域和时间固定效应，观察单位是位置时间，如果这有帮助的话。
是否有统计方法或特定测试可用于此目的？我熟悉 F 检验，但我的理解是 F 检验用于嵌套模型，而这似乎不是我的情况。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650270/how-to-perform-a-joint-significance-test-for-multiple-coefficients-across-severa</guid>
      <pubDate>Mon, 01 Jul 2024 17:00:03 GMT</pubDate>
    </item>
    <item>
      <title>重复测量分类问题中数据分割的最佳实践</title>
      <link>https://stats.stackexchange.com/questions/650269/best-practices-for-splitting-data-in-a-repeated-measures-classification-problem</link>
      <description><![CDATA[我正在研究一个涉及重复测量的分类问题。我的目标是尽早对阳性患者进行分类。在我的实际应用场景中，一旦患者的目标变为 1，进一步的模型预测对该患者就无关紧要了。在建模方面，特征可能会对目标做出延迟反应，因此当每个患者的目标=1出现时，我不能简单地只保留第一行。数据结构如下：



PatientID
Time
Target
FeatureA




A
2020-01
0
...


A
2020-02
0
...


A
2020-03
1
...


B
&lt; td&gt;2019-12
0
...


B
2020-01
0
...


B
2020-02
1
...


B
2020-03
1
...


B
2020-04
1
...



我正在寻找分割数据集以防止数据泄露的最佳实践。以下是我目前所做的：

患者级别分割：我在患者级别分割数据，以确保每个患者要么在训练集，要么在测试集中，但绝不会同时在两者中。对于交叉验证，我使用 GroupKFold 来保持这种分离。

时间分割问题：我正在考虑时间分割，但我担心潜在的数据泄漏。如果患者同时出现在训练集和测试集中，模型可能会记住患者的目标变为 1。例如，如果患者 B 截至 2020-02 的数据在训练集中，而 2020-03 以后的数据在测试集中，则患者特征中的自相关可能会导致泄漏，因为模型已经从 2020-02 的类似特征值中学习，并且很可能会正确分类 2020-03 以后的数据。在理想情况下，模型只会从其他类似患者身上学习。


问题：

我的担忧有意义吗？
当同一患者出现在两个集合中并且特征具有自相关性时，有没有办法在不引入泄漏的情况下实现时间分割？如果我控制特征自相关性，这个问题会解决吗？
有没有其他交叉验证策略可以更好地解决这个问题？
有没有处理这种类型数据的特定模型？使用时间序列方法有意义吗？

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650269/best-practices-for-splitting-data-in-a-repeated-measures-classification-problem</guid>
      <pubDate>Mon, 01 Jul 2024 16:49:09 GMT</pubDate>
    </item>
    <item>
      <title>lme4 不一致</title>
      <link>https://stats.stackexchange.com/questions/650268/lme4-inconsistency</link>
      <description><![CDATA[我们旨在模拟完全受试者间设计中各组之间的反应时间 (RT) 差异。我们还预计项目难度会影响响应并与组交互。每个受试者 (n=120) 完全嵌套在五个组中的一个中。每个受试者有 200 个观察值，我们计划为每个受试者添加一个随机截距，以解释观察值的不独立性。但是，我们希望这个随机截距能够解释受试者在组内的嵌套，以避免混淆我们的主要固定组效应。每个项目都完全嵌套在一个难度级别中，并且应该遵循相同的嵌套策略。
为了解释这种嵌套，我们使用了以下语法：(1|Group:Subject)。 Robert Long 在此处的回答（交叉和嵌套随机效应组合的 Lmer 模型语法）表明，这种语法不是必需的，而 (1|Subject) 就足够了，因为 R 应该自动知道数据是嵌套的。
但是，如下所示在两个模型中测试这一点会显示不同的结果，请参见下文。
数据和脚本可以在此处找到：https://osf.io/g3wqh/，并且也嵌入在下面。数据结构如下：
Subject Group RT Item Diff
1 A 1547 43 3 
1 A 1432 85 7 
... Etc 
120 C 1048 23 2 

代码如下：
#Packages----
library(lme4)

#Preliminaries----
data &lt;- read.csv(&quot;lme4 data.csv&quot;, header = TRUE)
attach(data)

data$Group &lt;- as.factor(data$Group)
data$Subject &lt;- as.factor(data$Subject)
data$Item &lt;- as.factor(data$Item)
data$Diff &lt;- as.integer(data$Diff)

#Models

Model1 &lt;- lmer(RT~Group*Diff + (1|Diff:Item) + (1|Group:Subject),data=data, lmerControl(optimizer = &quot;bobyqa&quot;), REML=F, na.action=na.omit)
anova(Model1,type=3) 
summary(Model1)

结果：
Factor Pr(&gt;F)
Group 7.643e-05
Diff 1.274e-09
Group:Diff 3.346e-16

Model2 &lt;- lmer(RT~Group*Diff + (1|Item) + (1|Subject),data=data, lmerControl(optimizer = &quot;bobyqa&quot;), REML=F, na.action=na.omit)
anova(Model2,type=3) 
summary(Model2)

结果：
因子 Pr(&gt;F)
Group 8.300e-05
Diff 1.350e-09
Group:Diff 5.308e-06

如您所见，这两个模型产生了不同的结果，尽管它们不应该如此。没有警告消息。lme4 是最新的。非常欢迎任何解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/650268/lme4-inconsistency</guid>
      <pubDate>Mon, 01 Jul 2024 16:10:41 GMT</pubDate>
    </item>
    <item>
      <title>用于测量事件发生随时间变化的适当测试（RStudio）</title>
      <link>https://stats.stackexchange.com/questions/650267/appropriate-test-for-measuring-change-in-event-occurrence-over-time-rstudio</link>
      <description><![CDATA[我想看看为组织提供的降低事件发生率的培训计划是否真的具有减少事件发生率的预期效果。
每个参与研究的组织（理论上）都会让尽可能多的组织成员参加一项调查，要求他们以 1 到 5 的评分自我报告他们的经历。我说理论上是因为并非所有组织每年都进行调查，所以有些组织可能在前两年进行调查，第三年不进行调查，但在第四年再次进行调查，在选择统计测试时可能也需要考虑这一点。对于每个组织，都会计算出该组织中给出 4 或 5 评分的人员百分比的平均值。
然后，我在 RStudio 中对组织进行分组，以获得不同日历年（例如 2015、2016、2017）、注册日期的年份（注册的第一年、第二年、第三年等）和调查编号（第一次、第二次、第三次参加调查，无论他们是否在几年之间休息过等）的平均百分比。
我现在想分析这些平均值，看看这些不同的组的平均百分比是否会随着时间的推移而下降，但我不确定最合适的方法是什么。我附上了一些我制作的示例图：

最明显的方法是进行某种相关性/线性回归分析，但由于调查数字是连续的，因此并非完全独立，我不确定这样做是否正确？
我知道有可能做类似配对/重复测量方差分析的事情，但我只见过最多 3 次时间测量，而我有至少 7 个时间点，所以我不确定是否有硬性数字限制。我也没有多个组来比较平均值，这只是逐年的变化 - 但是因为并非所有组织每年都进行调查，所以我不知道是否也应该进行某种注册年份*调查数量方差分析比较来解释这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/650267/appropriate-test-for-measuring-change-in-event-occurrence-over-time-rstudio</guid>
      <pubDate>Mon, 01 Jul 2024 15:59:41 GMT</pubDate>
    </item>
    <item>
      <title>实践中单位根背后的直觉</title>
      <link>https://stats.stackexchange.com/questions/650263/intuition-behind-unit-roots-in-practice</link>
      <description><![CDATA[单位根在时间序列建模中的应用似乎非常直观的一个领域是气候变化：二氧化碳停留在空气中，因此过去的冲击（流量大小）对股票规模有累积效应，不会随着时间的推移而消失。
另一方面，在 EMH 下，股票市场价格应该被建模为单位根，这似乎也很直观，因为这意味着未来实现底层 DGP 的最佳预测指标是其今天的实现。
这两个都是我们使用单位根的原因。我们能以某种方式将它们背后的原理联系起来吗？例如，有没有办法将持续冲击/存量流量解释与股票市场相匹配？]]></description>
      <guid>https://stats.stackexchange.com/questions/650263/intuition-behind-unit-roots-in-practice</guid>
      <pubDate>Mon, 01 Jul 2024 13:56:46 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据归因</title>
      <link>https://stats.stackexchange.com/questions/650247/imputation-missing-data</link>
      <description><![CDATA[我有一个纵向数据集，其中包含 2 个因变量（一对夫妇）——一对丈夫和一对妻子。丈夫有 2 轮，妻子有 3 轮。由于缺少大量数据，我决定排除所有妻子缺席 1 轮以上和/或丈夫错过 1 次以上预约的参与者。但是，这样我会丢失大量数据。
例如，我有以下情况：妻子参加了每一轮，但丈夫错过了 1 次预约。根据我的规则，我应该排除这对夫妇。
我的考虑是保留这对夫妇，即使丈夫只参加了 1 次预约，但这样就不是纵向样本，结果在归纳后可能会有偏差？]]></description>
      <guid>https://stats.stackexchange.com/questions/650247/imputation-missing-data</guid>
      <pubDate>Mon, 01 Jul 2024 10:36:07 GMT</pubDate>
    </item>
    <item>
      <title>多项逻辑回归 brm 模型的事后检验（分类响应）</title>
      <link>https://stats.stackexchange.com/questions/650248/post-hoc-test-for-multinomial-logistic-regression-brm-model-categorical-respons</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650248/post-hoc-test-for-multinomial-logistic-regression-brm-model-categorical-respons</guid>
      <pubDate>Sun, 30 Jun 2024 09:10:14 GMT</pubDate>
    </item>
    <item>
      <title>平面取向方向统计参考</title>
      <link>https://stats.stackexchange.com/questions/650193/reference-for-directional-statistics-of-plane-orientation</link>
      <description><![CDATA[我正在做一个项目，其中我得到了平面的方向（法线）向量。这些向量都在一个单位半球内，其中$z$坐标严格为正。方向也可以表示为倾角$\theta_{inc}$和方位角$\theta_{azi}$，写为$(\theta_{azi},\theta_{inc})$。这里，$\theta_{inc} \in [0,90^\circ]$ 从 $z$ 轴测量，$\theta_{azi} \in [0,360^\circ)$ 从 $x$ 轴测量。3D 空间中平面的任何方向都可以通过使用该半球上的法向量角度来描述。我想谈谈这些向量的分散程度，因为知道 $xy$ 平面附近的向量会绕回来。在二维中，直线的方向，其法向量为 $v = \langle v_1,v_2\rangle$，其中 $v_1 \geq 0$，可以用一个角度 $\theta = \arctan(v_2/v_1)$ 唯一地描述。然后，这些角度集合的离散度可以量化为双倍角度集合的平均合成长度。换句话说，如果 $\Theta = \{\theta_1,\theta_2,...,\theta_n\}$ 是一组倾斜角度，则平均合成长度为 $$\overline{\Theta} = \frac{1}{n}\sqrt{\left(\sum_{i=1}^n \cos(2\theta_i) \right)^2 + \left(\sum_{i=1}^n \sin(2\theta_i) \right)^2}$$
但是，我不能直接将倾斜角度加倍，因为不同的方向最终会被分配相同的向量。例如，考虑方向 $(0,90^\circ)$、$(120^\circ,90^\circ)$ 和 $(240^\circ,90^\circ)$，它们都相当分散。如果我将倾角加倍，那么所有这些方向的倾角都将为 $180^\circ$。这里，方位角退化，平均合成长度将为 1，表示没有分散。这是一个显而易见的问题，需要一种非常巧妙的方式来描述平面方向的周期性，或者可能需要一种计算分散的替代方法。我尝试在文献中搜索，但却找不到任何讨论此类事情的参考资料，因此非常感激对文章或书籍的推荐（Ley-Verdebout 文本和 Mardia-Jupp 文本似乎都没有帮助）。]]></description>
      <guid>https://stats.stackexchange.com/questions/650193/reference-for-directional-statistics-of-plane-orientation</guid>
      <pubDate>Sun, 30 Jun 2024 04:48:50 GMT</pubDate>
    </item>
    <item>
      <title>实值分布的复杂参数化</title>
      <link>https://stats.stackexchange.com/questions/650178/complex-parameterizations-of-real-valued-distributions</link>
      <description><![CDATA[假设我们有一些随机变量 $X$，其值在 $\mathbb{R}^n$ 中，由 $\theta \in \Theta$ 参数化，其中参数空间 $\Theta$ 是有限维的。
在几乎所有统计应用中，我们采用 $\Theta \subseteq \mathbb{R}^n$ 并对实值参数进行推断。
但是，我知道有一种情况 - McCullagh 对柯西分布的参数化 - 其中取 $\Theta \subseteq \mathbb{C}^n$ 可得出一些有关该分布的有趣见解。
我很好奇人们在工作中是否遇到过这种方法的其他有趣示例。
需要澄清的是，我特别感兴趣的是，在实数上具有支持的参数模型被赋予复值参数空间的情况，结果会出现一些统计上有趣的东西 - 而不是在数学上方便在复平面上工作作为证明的一部分的情况，或涉及复值函数参数的非参数示例。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650178/complex-parameterizations-of-real-valued-distributions</guid>
      <pubDate>Sat, 29 Jun 2024 19:07:13 GMT</pubDate>
    </item>
    </channel>
</rss>