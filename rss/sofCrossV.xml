<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 09 Jan 2025 09:17:46 GMT</lastBuildDate>
    <item>
      <title>交互项是否违反线性回归中的线性和可加性假设？</title>
      <link>https://stats.stackexchange.com/questions/659750/do-interaction-terms-violate-the-linearity-and-additivity-assumptions-in-linear</link>
      <description><![CDATA[在线性回归中，经常讨论的两个关键假设是可加性和线性，如 ISLR（统计学习简介）中所定义：
可加性：预测变量 $𝑋_𝑗$ 和响应 $𝑌$ 之间的关联不依赖于其他预测变量的值。
线性：与 $𝑋_j$ 的一个单位变化相关的 $𝑌$ 的变化是恒定的，无论 $𝑋_𝑗$ 的值如何。
现在考虑具有交互项的线性模型：
$$
𝑌
=
𝛽
0
+
𝛽
1
𝑋
1
+
𝛽
2
𝑋
2
+
𝛽
3
(
𝑋
1
⋅
𝑋
2
)
+
𝜖
$$
这可以重写为：
$$
Y=β 
0
​
+(β 
1
​
+β 
3
​
X 
2
​
)X 
1
​
+β 
2
​
X 
2
​
+ϵ
$$
在此公式中：
$𝑋_1$ 对 $𝑌$ 的影响现在依赖于 $𝑋_2$（即 $𝛽
1
+
𝛽
3
𝑋
2$
​
），这表明可加性假设被违反，因为 $𝑋_1$ 的影响不再独立于 $𝑋_2$。
类似地，线性假设似乎被违反，因为$𝑌$随着$𝑋_1$的一个单位增加而发生的变化不再是恒定的 - 它取决于$𝑋_2$的值。
在一次模拟口语考试中，我被问到当包含交互项时模型是否仍然是线性的。我认为该模型仍然是线性的，因为它在参数$(
𝛽
0
,
𝛽
1
,
𝛽
2
,
𝛽
3​
)$中是线性的，并且包含交互项只是“放松”了假设。但是，我对“放松”含义的解释是假设不明确。
我的问题：

在回归假设的背景下，具有交互项的模型是否仍被视为“线性”？为什么或为什么不？

“放宽”假设是什么意思？放宽假设是否意味着它没有被违反，还是意味着其他什么？

当包含交互项时，您能否阐明如何调和明显的可加性和线性违反？


提前感谢您的见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/659750/do-interaction-terms-violate-the-linearity-and-additivity-assumptions-in-linear</guid>
      <pubDate>Thu, 09 Jan 2025 09:17:01 GMT</pubDate>
    </item>
    <item>
      <title>如何解决损失不收敛的问题？[重复]</title>
      <link>https://stats.stackexchange.com/questions/659748/how-to-troubleshoot-loss-not-converging</link>
      <description><![CDATA[我正在使用 CNN 模型进行二分类任务，总训练数据为 24000 个样本（正样本与负样本比例：1:10）。
CNNDecoder(
(cnn): Sequential(
(0): Conv2d(6144, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(1): ReLU(inplace=True)
(2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
(3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(4): ReLU(inplace=True)
(5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
(6): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(7): ReLU(inplace=True)
(8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
(global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))
(fc): Linear(in_features=128, out_features=1, bias=True)
(sigmoid): Sigmoid()
)

输入特征维度为[B, 24, 256, 32, 64]，由24组256通道特征图，我使用CNN将它们的尺寸降为[B, 512, 32, 64]，然后进行卷积，直到特征图变成[B, 128]，最后输出分类概率。
loss：BceLoss，分别计算正样本和负样本的loss，这样就消除了类别不平衡的影响。
batch size：16 * 32（GPU数量）=512
学习率：1e-4
optimizer：
type：AdamW
lr：
default：1.0e-04
weight_decay：1.0e-05
betas：[0.9, 0.95]
这是我的训练loss和metric。看起来一开始准确率比较高，但是正样本的loss不收敛，而且用Wandb拿到CNN的梯度也没有发现有下降的趋势，请问这种现象最可能的原因是什么？我是否应该降低学习率，或者我的训练数据集中是否存在某种数据噪音？


]]></description>
      <guid>https://stats.stackexchange.com/questions/659748/how-to-troubleshoot-loss-not-converging</guid>
      <pubDate>Thu, 09 Jan 2025 07:27:32 GMT</pubDate>
    </item>
    <item>
      <title>我是否必须获取另一个独立于交叉验证中使用的数据集的单独测试集？</title>
      <link>https://stats.stackexchange.com/questions/659747/do-i-have-to-get-another-separate-test-set-that-is-independent-of-the-dataset-i</link>
      <description><![CDATA[我正在做什么
我正在写一篇关于使用 SVM 进行音频分类的本科论文。我的目标是确定将特征 X 添加到特征矩阵中是否可以提高分类器的性能。
我没有做什么
我没有在交叉验证后进行任何超参数调整。我在网上看到的大多数帖子都说应该有一个单独的测试集，但大多数帖子都提到这是因为使用 CV 的结果进行超参数调整，我认为这不适用于我。 (cmiiw)
我做了什么
（我将稍微简化一下，以便于理解）
我创建了 8 个 SVM 分类器 - 每个内核（线性、多边形、rbf、sigmoid）有 2 个分类器。
使用 sklearn 的 cross_validate 函数，4 个分类器（每个内核一个）与包含特征 X 的特征矩阵进行交叉验证。其他 4 个与不包含特征 X 的特征矩阵进行交叉验证，用作控制/基线。
我计算了每个分类器各个折叠的得分平均值，得到了 8 个平均得分及其派生的标准误差。我比较了 8 个平均分数，同时考虑了标准误差，以确定特征 X 是否确实提高了分类器的性能，以及哪个内核的性能最好。
我想知道什么
我这样做对吗？我不需要另一个单独的测试集吗？我觉得我不需要，但我只是一个新手，我非常怀疑自己。如果我确实需要另一个测试集，当我已经有 cross_validate 函数返回的分数时，我该如何使用它？]]></description>
      <guid>https://stats.stackexchange.com/questions/659747/do-i-have-to-get-another-separate-test-set-that-is-independent-of-the-dataset-i</guid>
      <pubDate>Thu, 09 Jan 2025 07:06:10 GMT</pubDate>
    </item>
    <item>
      <title>有人可以帮我从 Statista 下载数据吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659740/can-someone-help-me-to-download-data-from-statista</link>
      <description><![CDATA[我现在正在做一个大学项目，但我付不起订阅费。我需要做一个机器学习模型。有人能从 Statista 给我发一份数据吗？
https://www.statista.com/statistics/1251338/share-female-board-directors-it/]]></description>
      <guid>https://stats.stackexchange.com/questions/659740/can-someone-help-me-to-download-data-from-statista</guid>
      <pubDate>Wed, 08 Jan 2025 23:47:17 GMT</pubDate>
    </item>
    <item>
      <title>对于分类变量，PCA、因子分析或其他方法？</title>
      <link>https://stats.stackexchange.com/questions/659739/pca-factor-analysis-or-other-methods-for-categorical-variables</link>
      <description><![CDATA[我有关于公司政治关系的调查数据，分为两个模块，希望您就以下方面提出建议：
模块 1：此模块包含所有分类变量的调查问题。虽然我了解到从技术上讲，可以使用 PCA 处理分类变量，但一般不建议这样做。是否有其他方法更适合在此背景下分析分类数据？
模块 2：此模块包含多种变量：2 个是序数变量，1 个是分类变量。PCA 或因子分析能否有效地处理这种组合？
我一直在研究 PCA 和因子分析之间的差异，但仍然不确定哪个更合适。我的直觉是，政治联系可能不是潜在的构造，因此 PCA 在概念上似乎更有意义。但是，我想听听您的想法，PCA 或因子分析是否是更好的方法——或者另一种方法是否更合适。]]></description>
      <guid>https://stats.stackexchange.com/questions/659739/pca-factor-analysis-or-other-methods-for-categorical-variables</guid>
      <pubDate>Wed, 08 Jan 2025 23:40:48 GMT</pubDate>
    </item>
    <item>
      <title>通过中间变量估计干预与结果之间的关系</title>
      <link>https://stats.stackexchange.com/questions/659738/estimating-relationship-between-intervention-and-outcome-through-intermediate-va</link>
      <description><![CDATA[设 $X$ 为实验性疫苗的剂量水平，$Z$ 为二元结果（感染与未感染）。目标是通过随机为参与者接种 $k$ 个不同剂量水平的疫苗，$X_1, ..., X_k$，来估计 $X$ 和 $Z$ 之间的关系。 $n$ 名受试者在每个剂量水平上接种疫苗，因此总共有 $nk$ 名受试者。
通常，$X$ 和 $Z$ 之间的逻辑回归就足够了，但这里的问题是 $X$ 被视为目标剂量水平，并且相同目标剂量水平的每种疫苗中的实际浓度（表示为 $Y$）可能有很大差异。
对 $X$ 和 $Z$ 之间关系进行建模的最佳方法是什么？这看起来像是一系列回归$X-&gt;Y-&gt;Z$，其中$Y$和$Z$通过逻辑模型关联，而$X$和$Y$可以通过线性模型建模？
任何带有参考的建议都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/659738/estimating-relationship-between-intervention-and-outcome-through-intermediate-va</guid>
      <pubDate>Wed, 08 Jan 2025 23:27:39 GMT</pubDate>
    </item>
    <item>
      <title>缩小的整数格点是否可以作为概率单纯形中的无偏样本点？</title>
      <link>https://stats.stackexchange.com/questions/659737/do-scaled-down-integer-lattice-points-serve-as-unbiased-sample-points-in-the-pro</link>
      <description><![CDATA[我一直在努力证明一个看起来直观明显但实际上并不容易严格建立的陈述。
$(n-1)$维概率单纯形$X$是集合
$$
X=\left\{\mathbf{x}\in[0,1]^n:\sum_{i=1}^nx_i=1\right\}。
$$
设 $Y$ 为单纯形中按比例缩小的整数格点集：
$$
Y=X\cap\frac{\mathbb{Z}^n}s
$$
其中 $s\in\mathbb{Z}^+$。
我的主张是，当 $s\to\infty$ 时，$Y$ 可作为 $X$ 中无偏的样本点集。也就是说，对于 $P\subseteq X$ 和 $U=Y\cap P$，$P$ 的质心（未加权平均值）由以下公式给出
$$
\tag{1}
\bar{\mathbf{p}}=\frac{1}{\int_{P}dV}\int_{P}\mathbf{p}\,dV
$$
其中 $\mathbf{p}\in P$ 和 $dV$ 是 $(n-1)$ 维体积元素，并且 $\bar p$ 渐近等于
$$
\tag{2}
\bar{\mathbf{u}}=\frac1{\#U}\sum_{i=1}^{\#U}\mathbf{u}_i
$$
其中 $\mathbf{u}_i\in U$，因为 $s\to\infty$；即
$$
\tag{3}
\lim_{s\to\infty}\bar{\mathbf{u}}=\bar{\mathbf{p}}。
$$
这里，$(1)$可视为真实均值，$(2)$可视为样本均值，如果集合$U$提供的样本点在极限上无偏，则$(3)$成立。
对于我的具体情况，该语句不必对$X$中的所有子集都成立，而只对这个特定集合成立：
$$
\tag{4}
{P}=\left\{\mathbf{p}\in[0,1]^n: p_1\le p_2\le\cdots\le p_c\ge\cdots\ge p_n\text{ 和} \sum_{i=1}^n p_i=1\right\}\subset X
$$
顺便说一句，它恰好是凸的。
简而言之，我试图证明$(3)$，无论是在一般情况下，还是当$P$给出为$(4)$时。
任何帮助都将不胜感激。指导我任何相关的关键字或书籍也将很棒。]]></description>
      <guid>https://stats.stackexchange.com/questions/659737/do-scaled-down-integer-lattice-points-serve-as-unbiased-sample-points-in-the-pro</guid>
      <pubDate>Wed, 08 Jan 2025 22:56:09 GMT</pubDate>
    </item>
    <item>
      <title>FE 解释中的相互作用项</title>
      <link>https://stats.stackexchange.com/questions/659728/interaction-term-in-fe-interpretation</link>
      <description><![CDATA[我正在估算固定效应回归，如下所示：
$$
\text{unemployment}_{ict} \sim b_1 \text{wage}_{ict} + b_2 \text{heat}_{ict} + b_3 \text{wage}_{ict} \times \text{heat}_{ict} + \text{FEc} + \text{error}_{ict}
$$
其中 $i$ 为个人，$c$ 为国家，$t$ 为时间。
假设您获得以下效果：$b_1=0.7$，$b_2=1.2$, $b_3=-0.4$
现在您想要解释交互效应。一种思考方式是边际效应：
这里您已估计出给定工资和热量的失业预期值
$$
E[y|a,b]=0.7a+1.2b-0.4ab
$$
如果对上述表达式求导，则 a：
$$
\frac{d}{d a} E[y|a,b] =0.7-0.4b
$$
此表达式以 $b$（热量）递减。热量值表示温度，例如，范围从 0-40。然后您可以将 b 设置为“有趣”的值以进行解释。通常，这些有趣的值是 $b$ 中样本的平均值。
我的疑问：
在平均热量值处可视化边际效应是否有意义？
由于 FE 模型控制了国家层面的差异，因此它仅估计了国家内部的变化。使用平均热量值（捕获国家间和国家内部的变化）会扭曲解释吗？
我应该使用替代方法吗？
考虑到模型的面板结构，我正在考虑使用诸如热量增长率或其国家内部标准差之类的指标进行可视化。这些反映了模型实际捕获的国家内部变化。这种方法更合适吗？
如果有人可以对此发表评论，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659728/interaction-term-in-fe-interpretation</guid>
      <pubDate>Wed, 08 Jan 2025 17:35:13 GMT</pubDate>
    </item>
    <item>
      <title>不带 MAR 假设计算临床试验的敏感性和特异性</title>
      <link>https://stats.stackexchange.com/questions/659704/computing-sensitivity-and-specificity-of-a-clinical-test-without-mar-assumption</link>
      <description><![CDATA[如周氏《诊断医学中的统计方法》第 337-338 页所述，假设 $D$ 是一个随机变量，如果受试者患有疾病，则假设其值为 $1$。假设 $T$ 是一个随机变量，如果疾病检测结果为阳性，则假设其值为 $1$。假设 $V$ 是一个随机变量，如果受试者已对该疾病进行了进一步验证，则假设其值为 $1$。给定以下参数的值$\lambda_{11} = P(V=1|T=1,D=1)$, $\lambda_{01} = P(V=1|T=1,D=0)$, $\lambda_{10} = P(V=1|T=0,D=1)$, $\lambda_{00} = P(V=1|T=0,D=0)$, $\phi_1 = P(T=1)$, $\phi_{20} = P(D=1|T=0)$, $\phi_{21} = P(D=1|T=1)$，根据这些参数计算敏感度和特异性的正确方法是什么？例如，我知道敏感度是 $P(T=1|D=1)$，不考虑 $V$，它应该计算为 $P(T=1|D=1)P(D=1)/P(T=1)$，但如果必须考虑随机变量 $V$，公式会如何变化？]]></description>
      <guid>https://stats.stackexchange.com/questions/659704/computing-sensitivity-and-specificity-of-a-clinical-test-without-mar-assumption</guid>
      <pubDate>Wed, 08 Jan 2025 06:29:17 GMT</pubDate>
    </item>
    <item>
      <title>线性回归 - 响应变量为百分比改善或 m/s？</title>
      <link>https://stats.stackexchange.com/questions/659686/linear-regression-response-variable-as-percent-improvement-or-m-s</link>
      <description><![CDATA[我正在尝试对包含 8 种不同跑步距离的数据集进行统计，这些距离在遵循训练方案之前和之后都有时间，并且基于距离对改进进行线性回归（所有完成时间都有所下降）。我不确定是否要转换为百分比改进或使用 m/s 之类的变量，然后减去跑步时间 1 和跑步时间 2，以便能够比较不同的距离组。显然，绝对时间差异并不大，因为更长的距离自然会有更大的改进。但我读到过，不建议将百分比改进转换为线性回归中的响应变量。我该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/659686/linear-regression-response-variable-as-percent-improvement-or-m-s</guid>
      <pubDate>Tue, 07 Jan 2025 21:03:50 GMT</pubDate>
    </item>
    <item>
      <title>mgcv::gam 不能正确地从平滑中分解线性分量</title>
      <link>https://stats.stackexchange.com/questions/659680/mgcvgam-does-not-correctly-decompose-the-linear-component-from-the-smooth</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659680/mgcvgam-does-not-correctly-decompose-the-linear-component-from-the-smooth</guid>
      <pubDate>Tue, 07 Jan 2025 18:52:03 GMT</pubDate>
    </item>
    <item>
      <title>何时使用哪种样本方差公式？</title>
      <link>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</link>
      <description><![CDATA[我知道样本方差的公式为
$$s^2 = \frac{\sum (x_i - \bar{x})^2}{n - 1}$$
我还知道样本方差的公式为“均值平方减均值平方”。
在计算给定样本的样本方差时，我使用了这两个公式，但发现它们给出了两个不同的答案，因此我想问，什么时候该使用第一个公式，什么时候该使用第二个公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</guid>
      <pubDate>Tue, 07 Jan 2025 05:32:19 GMT</pubDate>
    </item>
    <item>
      <title>使用相机陷阱记录动物活动对火灾的反应——缺乏空间独立性的问题以及如何分析</title>
      <link>https://stats.stackexchange.com/questions/658550/fauna-activity-responses-to-fire-with-camera-traps-issues-with-lacking-spatial</link>
      <description><![CDATA[我正在尝试为我的博士论文找出最佳的数据分析方法，但遇到了一些困难。
我从事生态学领域的工作，试图了解火灾前后动物群的反应。我正在使用 BACI 方法，并一直使用相机陷阱来捕捉动物的检测/活动。我遇到的问题是，我正在处理的火灾现场非常小，所以我必须制作一个高密度相机陷阱网格（即每个地点有 6 个相机，4 个监测点，相机间隔约 20 米，非常近）。到目前为止，我已经考虑了 60 分钟内在同一台相机上出现的动物（这是相机陷阱的标准做法，用于考虑可能在 60 分钟内被相机多次捕捉到的个体），但我正在努力解决每个站点的相机之间的空间自相关性 - 即动物可能在彼此相似的时间段内在相机之间移动的现实。
我读到我可以将每个站点视为重复，而不是每个站点内的每个相机，这样即使有动物在相机之间移动，它们在 60 分钟内被多个相机计数也无关紧要。这听起来合理吗？
有人有什么想法可以通过我的分析来解决这个问题吗？为了便于理解，我计划使用 GLMM（同样，许多其他人已经使用过），并且认为也许我可以使用相机编号作为随机效应？想看看是否还有其他人有什么我可以探索的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/658550/fauna-activity-responses-to-fire-with-camera-traps-issues-with-lacking-spatial</guid>
      <pubDate>Tue, 10 Dec 2024 23:13:39 GMT</pubDate>
    </item>
    <item>
      <title>假阳性率是否可能随着患病率的增加而降低？</title>
      <link>https://stats.stackexchange.com/questions/658195/is-it-possible-that-false-positive-rate-decreases-with-increasing-prevalence</link>
      <description><![CDATA[我对患病率对预测性能的影响很感兴趣。Chouldechova (2016) 指出：

[当]在各组再犯患病率不同的人群中使用测试公平 [再犯预测工具] 时，通常再犯患病率较高的组会具有较高的 FPR 和较低的 FNR。

我想知道如果该工具旨在使两组具有相同的准确度，情况是否如此。因此，我推导出一个考虑准确率、FNR 和患病率的 FPR 函数：
$$FPR=\frac{\left(1-ACC-prevalence\cdot FNR\right)}{1-prevalence}$$
这个等式似乎是正确的，因为它给出的结果与通常的 $ FPR=\frac{FP}{FP+TN}$ 相同。
我注意到，如果 $FNR+ACC&lt;1$（即敏感度低于准确率），该等式仅显示患病率与 FPR 之间的正相关关系。请参阅此处。
我的问题是：在实际情况下，患病率和 FPR 之间的关系是否可能为负？或者我是否遗漏了某些东西，可以将可能的值限制在关系为正的范围内？
编辑：可能对偶然发现这一点的其他人有帮助：FPR 可以描述为基准率、准确率和 PPV 的函数。对于 PPV &gt; 0.5，基准率和 FPR 之间的关联将始终为正。对于 0 &lt; 准确率 &lt; 1：fpr = ((base+acc-1)*(ppv-1))/((base-1)*(2*ppv-1))]]></description>
      <guid>https://stats.stackexchange.com/questions/658195/is-it-possible-that-false-positive-rate-decreases-with-increasing-prevalence</guid>
      <pubDate>Tue, 03 Dec 2024 11:09:43 GMT</pubDate>
    </item>
    <item>
      <title>广义特征值、矩阵距离、信息几何的解释</title>
      <link>https://stats.stackexchange.com/questions/651758/interpretation-of-generalized-eigenvalues-matrix-distance-information-geometry</link>
      <description><![CDATA[这个问题是关于两个协方差矩阵的广义特征值与它们相关的高斯分布的可辨别性之间的关系。
两个对称矩阵$(\pmb{A}, \pmb{B})$的广义特征值问题是$\pmb{A}\pmb{\Phi} = \pmb{B}\pmb{\Phi}\pmb{\Lambda}$，其中$\pmb{A}$和$\pmb{B}$是对称的$n \times n$ 个矩阵，$\pmb{\Phi} = [\Phi_1, ..., \Phi_n]$ 是一个 $n \times n$ 矩阵，其列是广义特征向量 $\Phi_i$，而 $\pmb{\Lambda}= \mathrm{diag}(\lambda_1, ..., \lambda_n)$ 是一个具有广义特征值的对角矩阵（其中 $\lambda_i \geq \lambda_{i+1}$）。结果与矩阵 $\pmb{B}^{-1}\pmb{A}$ 的常规特征值和特征向量相同。由于 $\pmb{B}^{-1}\pmb{A}$ 通常不对称（尽管它仍然是正定的），因此特征向量 $\Phi_i$ 不一定是正交的。
广义特征值问题与分布之间的可辨别性有关。假设向量 $\pmb{x}$ 是两个分布的混合，由变量 $y \in \{1, 2\}$ 索引。我们如何才能确定两个分布中的哪一个生成了 $\pmb{x}$ 的实例？我们可以使用由 $(\pmb{v}^T\pmb{x})^2$ 提供的二次特征，其中 $||\pmb{v}||=1$。 $\pmb{v}$ 区分两个分布的能力由预期值的比率来衡量
$$R(\pmb{v}) = \frac{\mathbb{E}\left[ (\pmb{v}^T \pmb{x})^2 | y=1\right]}{\mathbb{E}\left[ (\pmb{v}^T \pmb{x})^2 | y=2\right]} = \frac{\pmb{v}^T\pmb{\Sigma_1}\pmb{v}}{\pmb{v}^T\pmb{\Sigma_2}\pmb{v}}$$
事实证明，最大化$R$的$\pmb{v}$由$(\pmb{\Sigma_1},\pmb{\Sigma_2})$的第一个广义特征向量给出，而$R$的值由其相关的特征值给出（查看上面的参考资料）。因此，广义特征值说明了二次判别器如何判别两个分布。
有趣的是，对于 0 中心高斯分布，分布之间的 Fisher-Rao 距离（其度量衡量分布的局部变化的可判别性）由 $\sum_{i=1}^{i=n} (\log \lambda_i)^2$ 给出，其中 $\lambda_i$ 是广义特征值。这也是对称正定 (SPD) 矩阵流形中的仿射不变距离。
因此，考虑到以上所有情况，我的问题如下。很明显，一对协方差矩阵的各个 $\lambda_i$ 如何反映它们的 0 均值高斯沿相应 $\Phi_i$ 的可辨别性。但是，我不太清楚所有特征值加在一起代表什么。数量 $\sum_{i=1}^{i=n} (\log \lambda_i)^2$ 清楚地概括了一些东西，并且直观地看出它如何将 $\lambda_i$ 与 1 相加。但我还想知道不同的 $\Phi_i$ 不正交是如何解释的。关于一对协方差的广义特征值的完整集合与其可辨别性之间的关系，是否可以说得更严格一些？]]></description>
      <guid>https://stats.stackexchange.com/questions/651758/interpretation-of-generalized-eigenvalues-matrix-distance-information-geometry</guid>
      <pubDate>Thu, 25 Jul 2024 15:35:22 GMT</pubDate>
    </item>
    </channel>
</rss>