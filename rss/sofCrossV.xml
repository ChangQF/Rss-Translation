<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 07 Jul 2024 15:15:09 GMT</lastBuildDate>
    <item>
      <title>预测比率的模型建议</title>
      <link>https://stats.stackexchange.com/questions/650637/model-suggestion-to-predict-a-ratio</link>
      <description><![CDATA[我有一个项目，其中有公司数据（一个变量是他们的客户数量以及他们是否有合规性问题）。我试图建立一个模型，以找到给定公司的员工与客户比率，从而最大限度地降低合规性问题的可能性。我拥有的标签属于一种情况（公司有合规性问题），但其余的则没有标签，好像他们没有任何问题，他们可能没事，或者只是尚未发现。我可以采取什么方法来建立一个模型，该模型将公司详细信息提供比率？任何想法或其他可供参考的工作都值得赞赏。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/650637/model-suggestion-to-predict-a-ratio</guid>
      <pubDate>Sun, 07 Jul 2024 14:36:10 GMT</pubDate>
    </item>
    <item>
      <title>使用引导抽样从每日数据中获取月度统计数据</title>
      <link>https://stats.stackexchange.com/questions/650636/bootstrap-sampling-to-get-monthly-statistic-from-daily-data</link>
      <description><![CDATA[我有历史冬季的每日 (iid) 数据：$d:$（价格、价值、温度等）。
“价值”实际上是“价格”和其他协变量的上凹函数。
我感兴趣的是查看一个月的价值，也就是 30 天的“价值”总和。所有数据都是 iid 的，并且每个月出现的可能性相同。
我的想法是从我的每日数据中抽取 10_000 个大小为 30 的样本并计算统计数据，并将其用作分布。我将历史数据用作实际每日分布 F 的离散分布近似值。
我已阅读了一些关于引导估计的证明，大多数都假设引导样本大小等于您的数据样本大小。我知道这对于矩等统计数据来说可能需要，但就我而言，使用这种不同的样本量是否合理？哪里可能出错？]]></description>
      <guid>https://stats.stackexchange.com/questions/650636/bootstrap-sampling-to-get-monthly-statistic-from-daily-data</guid>
      <pubDate>Sun, 07 Jul 2024 14:18:53 GMT</pubDate>
    </item>
    <item>
      <title>关于推导 MAP 估计量的基本问题</title>
      <link>https://stats.stackexchange.com/questions/650635/basic-question-about-deriving-map-estimator</link>
      <description><![CDATA[假设我们有一个随机过程$X(t, u)$，它生成数据$x$。我们对 $u$ 也有一个先验，$p(u)$。
我说得对吗？找到 仅 $t$ 的最大后验 (MAP) 估计的表达式应该是
$$
t_{MAP} = \underset{t}{\operatorname{argmax}} \int p(x | t, u) p(u) du = \underset{t}{\operatorname{argmax}} p(x|t)
$$
也就是说，你会将干扰参数边缘化，对吗？
现在假设 $U\sim \mathcal{N}[\hat{u}, C_u]$ 和 $X \mid u, t \sim \mathcal{N}[M(t) u, C_x]$。
说 $p(x | t)$ 等于 $M(t) U$ 的 pdf 正确吗？也就是说，
$$X \mid t \sim \mathcal{N}[M(t)\hat{u}, M(t)C_uM(t)^\top]$$
换一种说法，更一般地说，推导出 $f(U, t)$ 的分布是否会得到与 $\int p(x|t, u)p(u)du$ 相同的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/650635/basic-question-about-deriving-map-estimator</guid>
      <pubDate>Sun, 07 Jul 2024 12:46:11 GMT</pubDate>
    </item>
    <item>
      <title>评估测试图像的最佳时期是什么时候？</title>
      <link>https://stats.stackexchange.com/questions/650634/what-is-the-best-epoch-to-evaluate-the-test-images</link>
      <description><![CDATA[我为一个图像分类任务创建了一个训练集、一个验证集和一个测试集。然后，我使用训练集进行训练，并对验证集进行评估。因此，下一步是评估测试集，基本上是为了推理。为了选择最佳的 epoch 模型，我通常会检查验证损失。但是，我不确定这种方式是否正确。我将结果添加为图片，并标记了最佳的 train/val 准确率和最低的 train/val 损失。损失函数是 Cross Entrophy。

后面的步骤显然是过度拟合，但训练损失仍然越来越低，直到第 25 个 epoch。如果我只检查 val 损失，我可能会选择第 13 个 epoch。或者最高的验证准确率也可能很重要。
我读过一些文章或论坛问题，比如这个、这个、这个和其他几个，但这个话题没有真正的结论。那么，对于这种情况，有没有通用的解决方案，或者我应该以不同的方式考虑每个分类/对象检测任务并做出相应的决定？]]></description>
      <guid>https://stats.stackexchange.com/questions/650634/what-is-the-best-epoch-to-evaluate-the-test-images</guid>
      <pubDate>Sun, 07 Jul 2024 12:16:32 GMT</pubDate>
    </item>
    <item>
      <title>主观信心作为回归模型中的权重</title>
      <link>https://stats.stackexchange.com/questions/650629/subjective-confidence-as-weights-in-regression-models</link>
      <description><![CDATA[我有数据，其中受试者在某个范围内对数量进行评分（$y$），但也添加了他们对选择的确定程度的主观信心（$w$）。我最初的想法是将$w$作为权重添加到回归模型中（暂时忽略如何对其进行规范化或标准化的问题）。我的上级要求检查$w$与方差之间的关系 - 指出如果它们与方差成反比，则应加入置信度。我们检查了非加权模型的平均绝对残差（作为方差的代理），发现较高置信度的残差与较低置信度的残差大致相同。我的上级得出结论，我们不应该使用置信度评级。
虽然我同意数据和模型似乎没有表明更高的置信度评级与更低的方差相关，但我仍然不相信这是使用权重的唯一原因。如果对某些数据点有很高的置信度，那么与其他置信度较低的数据点相比，它们是否应该有更多发言权来将回归线拉近它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/650629/subjective-confidence-as-weights-in-regression-models</guid>
      <pubDate>Sun, 07 Jul 2024 09:58:56 GMT</pubDate>
    </item>
    <item>
      <title>报告 clmms 中固定效应的重要性 - 何时使用 ANODE 表？</title>
      <link>https://stats.stackexchange.com/questions/650628/reporting-significance-of-fixed-effects-in-clmms-when-to-use-anode-tables</link>
      <description><![CDATA[我正在使用 clmm 研究一些用于序数结果的混合效应模型。我已经确定了最终模型，现在想展示研究结果。阅读后，我看到 ANODE 表既用于模型比较，也用于分解模型中每个固定效应的贡献。我无法找到任何关于这是否与报告相关的指导，以及最佳实践是什么。该模型是使用 R 中的序数包估计的，ANODE 表来自 RVAideMemoire。
实际上，这与模型输出中报告的 z 检验之间的结果几乎没有差异（如下所示）。但是，我想更多地了解两组输出之间的差异。有人可以提出一些建议吗？我可以找到有关模型比较的信息，但找不到关于如何报告最终模型中固定效应的重要性的具体问题的答案。
非常感谢！
 估计误差 z Pr(&gt;|z|)

Var1 -2.966 0.482 -6.152 &lt;0.001

Var2 -2.102 0.486 -4.32 &lt;0.001

Var3 -1.593 0.476 -3.349 0.001

Var4 0.973 0.474 2.051 0.040

Var5 -0.711 0.175 -4.07 &lt;0.001

偏差分析（II 型检验）

LR Chisq Df Pr(&gt;Chisq) 

Var1 29.2981 1 &lt;0.001 ***
Var2 16.2687 1 &lt;0.001 ***
Var3 10.2870 1 0.001 **
Var4 3.9415 1 0.047 *
Var5 14.5733 1 &lt;0.001 ***
]]></description>
      <guid>https://stats.stackexchange.com/questions/650628/reporting-significance-of-fixed-effects-in-clmms-when-to-use-anode-tables</guid>
      <pubDate>Sun, 07 Jul 2024 08:26:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么考虑自相关残差几乎无助于分布滞后模型中的参数估计</title>
      <link>https://stats.stackexchange.com/questions/650626/why-does-accounting-for-autocorrelated-residuals-barely-help-parameter-estimatio</link>
      <description><![CDATA[这个问题困扰了我很长时间。基本上，我有一个分布式滞后模型$$y_t=\sum_{i=0}^{p} \beta_i x_{t-i} + u_t.$$
回归问题有点错误指定，所以我最终得到自相关错误$$u_t=\alpha u_{t-1}+\epsilon_t.$$
由于我的模型中自相关程度很高，$\beta$的估计应该非常低效，但是当我使用 GLS 校正自相关时，我的$\beta$估计没有任何改善。当我的问题略有不同，并且 $$y_t= \sum_{i=1}^p \beta_i x_t^i + u_t,$$ 时，$y$ 只是同时存在的不同 $x$ 的函数，GLS 表现惊人，而最小二乘则举步维艰。
为什么 GLS 在第一个例子中表现如此糟糕，我如何让它表现得更好（我只关心参数估计）？
我在 R 中编写了两个例子：
n_sim&lt;-15
LS_R2&lt;-rep(0,n_sim)
GLS_R2&lt;-rep(0,n_sim)
ar_noise&lt;-0.7
for(sim in 1:n_sim){
n=5000
set.seed(sim)
x_vec&lt;-arima.sim(list(order=c(1,0,0),ar=c(0.5)),n=n,sd=1)
noise&lt;-arima.sim(list(order=c(1,0,0),ar=c(ar_noise)),n=n,sd=1)
y&lt;-rep(0,n)
p&lt;-150
true_beta&lt;-seq(from=5,to=0,length.out=p)+rnorm(p,sd=0.1)
for(i in p:length(y)){
y[i]&lt;-y[i]+sum(x_vec[i:(i-p+1)]*true_beta)
}
y&lt;-y+noise*var(y)/var(noise)/50

#尝试简单最小二乘法（应该非常低效）
Xmat&lt;-matrix(0,ncol = p,nrow = n)
for(i in 1:ncol(Xmat)){
Xmat[,i]&lt;-c(rep(0,i-1),x_vec[1:(length(x_vec)-i+1)])
}

XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
LS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

#尝试广义最小二乘法（应该是最优且有效的）
get_T&lt;-function(ar,N){
i_vec&lt;-c(1:N,2:N)
j_vec&lt;-c(1:N,1:(N-1))
x_vec&lt;-c(sqrt(1-ar^2),rep(1,N-1),rep(-ar,N-1))
sparseMatrix(i = i_vec, j = j_vec, x = x_vec, dims = c(N,N))
}

T1&lt;-get_T(ar_noise,length(y))

Xmat&lt;-T1%*% Xmat
y&lt;-as.numeric(T1%*% matrix(y,ncol=1))

XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
GLS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

}
LS_R2
GLS_R2
mean(LS_R2)
mean(GLS_R2)

and
n_sim&lt;-15
LS_R2&lt;-rep(0,n_sim)
GLS_R2&lt;-rep(0,n_sim)
for(sim in 1:n_sim){
n=5000
set.seed(sim)
noise&lt;-arima.sim(list(order=c(1,0,0),ar=c(ar_noise)),n=n,sd=1)
y&lt;-rep(0,n)
p&lt;-150
Xmat&lt;-matrix(0,ncol = p,nrow = n)
for(i in 1:ncol(Xmat)){
Xmat[,i]&lt;-arima.sim(list(order=c(1,0,0),ar=c(0.5)),n=n,sd=1)
}
true_beta&lt;-seq(from=5,to=0,length.out=p)+rnorm(p,sd=0.1)
for(i in p:length(y)){
y[i]&lt;-y[i]+sum(Xmat[i,]*true_beta)
}
y&lt;-y+noise*sd(y)/sd(noise)

#尝试简单最小二乘法（应该是非常低效的）
XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
LS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

#尝试广义最小二乘法（应该是最优且有效的）
get_T&lt;-function(ar,N){
i_vec&lt;-c(1:N,2:N)
j_vec&lt;-c(1:N,1:(N-1))
x_vec&lt;-c(sqrt(1-ar^2),rep(1,N-1),rep(-ar,N-1))
sparseMatrix(i = i_vec, j = j_vec, x = x_vec, dims = c(N,N))
}

T1&lt;-get_T(ar_noise,length(y))

Xmat&lt;-T1%*% Xmat
y&lt;-as.numeric(T1%*% matrix(y,ncol=1))

XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
GLS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

}
LS_R2
GLS_R2
mean(LS_R2)
mean(GLS_R2)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/650626/why-does-accounting-for-autocorrelated-residuals-barely-help-parameter-estimatio</guid>
      <pubDate>Sun, 07 Jul 2024 07:15:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么逆倾向得分加权有效？</title>
      <link>https://stats.stackexchange.com/questions/650624/why-does-inverse-propensity-score-weighting-work</link>
      <description><![CDATA[假设某些治疗 $D = 0, 1$ 对结果 $Y = 0,1$ 的影响受到性别 $S = 0,1$ 的混淆。对 $D$ 对 $Y$ 的因果影响的无混淆估计将使我们估计层内风险，然后在计算其差异之前根据层的流行程度对这些风险进行加权。从数学上讲，我们会计算
$$ E[Y(D=d)] = \sum_s E[Y \mid D=d, S=s] P(S=s) $$
对每个 $d$ 计算差值。如果简单地写出均值估计量的简单差异，就会发现权重不正确，这是造成混杂的原因
$$ E[Y\mid D=d] = \sum_s E[Y \mid D=d, S=s] P(S=s \mid D=D) $$
请注意，通过贝叶斯规则
$$ P(S=s \mid D=D) = \dfrac{P(D=D \mid S=S) P(S=s)}{P(D=d)} $$
它是倾向得分和正确权重的函数$P(S=s)$。但是，简单地用倾向得分的倒数对 $E[Y \mid D=d]$ 的估计值进行加权，就会在 $E[Y \mid D=d]$ 的表达式中留下一个 $1/P(D=d)$ 因子。
那么，为什么 IPTW 会得出正确的因果对比估计值呢？我希望得到一个符合我在此处所写的期望加权和的答案。特别是，我希望证明 IPTW 会得出一个类似于我提出的第一个方程的表达式。]]></description>
      <guid>https://stats.stackexchange.com/questions/650624/why-does-inverse-propensity-score-weighting-work</guid>
      <pubDate>Sun, 07 Jul 2024 05:59:37 GMT</pubDate>
    </item>
    <item>
      <title>广义策略迭代（GPI）、Actor-Critic 和 Q 学习方法之间有什么关系？</title>
      <link>https://stats.stackexchange.com/questions/650622/whats-the-relation-between-generalized-policy-iteration-gpi-actor-critic-an</link>
      <description><![CDATA[在我看来，广义策略迭代 (GPI) 和 Actor-Critic 是一样的，而 Q-learning 方法则是一类独立的算法。我认为 GPI 和 Actor-Critic 都描述了策略评估 (critic) 和策略改进 (actor) 的迭代过程，而 Q-learning 只是使用贝尔曼最优方程进行引导。
详细阐述我的理解：策略评估 (critic) 是通过蒙特卡洛或时间差分方法完成的，必要时包括函数逼近，策略改进 (actor) 可以通过贪婪 (表格情况) 或使用策略梯度定理 (大状态空间) 来完成。Q-learning 不做任何这些。它只是尝试使用贝尔曼最优方程通过迭代拟合 Q 值的贝尔曼最优方程来估计 $Q^\ast$。
如果有人能确认我的理解是否正确，或者对在线 RL 算法的分类法给出更系统/精确的总结，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650622/whats-the-relation-between-generalized-policy-iteration-gpi-actor-critic-an</guid>
      <pubDate>Sun, 07 Jul 2024 05:24:58 GMT</pubDate>
    </item>
    <item>
      <title>故意发表错误统计方法的著名例子有哪些？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650620/what-are-famous-examples-of-erroneous-statistical-methods-being-deliberately-pub</link>
      <description><![CDATA[是否有著名的错误统计方法发表的例子，作者从一开始就知道他们的方法是错误的，但故意隐瞒它？
例如，我想到的是人们试图测试某些期刊的同行评审过程的可靠性，或者在战争时期，出版物可能旨在鼓励敌人使用错误的方法。但我对其他可能的动机也很感兴趣。促使我提出这个问题的原因是，在社会科学中有几个这样的例子，所以我想知道它是否也发生在统计研究中。
我不认为有很多著名的例子（我从未听说过这样的案例，这就是我问这个问题的原因），因为隐藏方法不正确可能非常困难，所以我想问题的范围不是太广泛。]]></description>
      <guid>https://stats.stackexchange.com/questions/650620/what-are-famous-examples-of-erroneous-statistical-methods-being-deliberately-pub</guid>
      <pubDate>Sun, 07 Jul 2024 04:46:31 GMT</pubDate>
    </item>
    <item>
      <title>策略梯度方法中的目标函数是否正是期望值函数？</title>
      <link>https://stats.stackexchange.com/questions/650615/is-the-objective-function-in-policy-gradient-methods-exactly-the-expected-value</link>
      <description><![CDATA[
我正在阅读 DRL 中的 Spinning Up。我想知道策略梯度算法中的目标 $J_\theta$ 是否正是期望值函数 $E_{S_0}[V^\pi(S_0)]$。我从未见过有人将目标写为 V，但我觉得它们是一样的。有人可以证实这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650615/is-the-objective-function-in-policy-gradient-methods-exactly-the-expected-value</guid>
      <pubDate>Sun, 07 Jul 2024 02:45:34 GMT</pubDate>
    </item>
    <item>
      <title>拆分数据然后进行回归是否合理？</title>
      <link>https://stats.stackexchange.com/questions/650613/is-it-reasonable-to-split-the-data-and-then-perform-the-regression</link>
      <description><![CDATA[有一家商店销售圆珠笔。我已从该商店获取每笔交易的数据，包括交易 ID、颜色、每笔交易的销售数量、总价等。通过将总价除以每笔交易数量，我计算出了每笔交易中每支笔的单价。我认为每支圆珠笔的单价与其颜色和每笔交易中购买的数量有关。因此，我将使用线性回归来检验这一假设：单价 = Alpha1 x 颜色 + Alpha2 x 数量 + Beta。
原始数据图像：

问题是，我可以在执行回归之前拆分这些数据吗？例如，在原始样本数据中，第一笔交易销售了 2 支圆珠笔，因此我将把它拆分为两个条目。拆分数据如下图所示，回归方程不变：单价 = Alpha1 x 颜色 + Alpha2 x 数量 + Beta。
拆分数据图片：

我的问题是：这个操作可以吗？会有什么影响，为什么？有相关参考吗？
我觉得这个操作可能不合理，比如反而增加了蓝色笔的数据权重。但是我对统计学的理解不够，无法清晰的表达出为什么或者怎么不合理。]]></description>
      <guid>https://stats.stackexchange.com/questions/650613/is-it-reasonable-to-split-the-data-and-then-perform-the-regression</guid>
      <pubDate>Sun, 07 Jul 2024 01:30:45 GMT</pubDate>
    </item>
    <item>
      <title>关于测试可靠性对测试组合权重的影响的问题</title>
      <link>https://stats.stackexchange.com/questions/650558/question-on-the-effect-of-test-reliability-on-weighting-of-a-test-battery</link>
      <description><![CDATA[最初，测试组件有 4 个部分：两个 100 项多项选择题测试、一个口语测试和一个论文测试。每个部分测量不同的主题。4 个部分中的每一个权重为 25%。
现在，每个多项选择题测试的测试长度已减少到 60 项（出于实际原因）。每个部分仍占 25%。
如果两个 MC 测试的可靠性降低到零，则两个 MC 测试测量的两个主题的权重将为零。（两个 MC 测试只会产生误差。）实际上，可靠性降低了，但并没有降低到零。
我的问题是，可靠性的变化对两个 MC 测试测量的两个主题的权重有何影响。我如何估计由于变化而导致的权重差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/650558/question-on-the-effect-of-test-reliability-on-weighting-of-a-test-battery</guid>
      <pubDate>Fri, 05 Jul 2024 22:15:38 GMT</pubDate>
    </item>
    <item>
      <title>如何将贝叶斯模型拟合到 Beta、指数和一零膨胀数据的混合中？</title>
      <link>https://stats.stackexchange.com/questions/650533/how-to-fit-a-bayesian-model-to-a-mixture-of-beta-exponential-and-one-zero-infl</link>
      <description><![CDATA[我的数据非常嘈杂，我相信这是通过多个物理过程的相互作用而产生的。在映射 $Y = f(X),$ 中，$Y$ 是一个比率 $[0, 1]$ 和 $X \ge 0.$，而 $Y$ 是 $X,$ 的函数，它也可以取 $0$（更可能在较低的 $X$ 值时）或 $1$（更可能在较高的 $X$ 值时）。 $Y$ 是每个 $X$ 间隔的指数、Beta 和零一膨胀过程的混合。指数部分在 $X$ 值较低时更明显，并随着 $X$ 的增加而缓慢消失。
如何使用贝叶斯方法对此类过程进行建模？我是贝叶斯统计的新手，希望得到任何帮助。我可以拟合零一膨胀的 Beta 模型，但它无法捕捉指数类分量。
模拟真实数据的虚拟数据：
# 设置种子以实现可重复性
set.seed(123)

# 生成 x 值
x &lt;- seq(0, 20, length.out = 1000)

# 为 y 创建非线性函数
y &lt;- 0.15 + 0.005 * x^1.05 + 1 / (2.5 + 2532 * exp(-1.611 * x))

# 添加一些随机噪声
noise_factor &lt;- 0.03
# 使用 beta 噪声创建模型（此处使用正态分布创建）
noisy_y &lt;- rnorm(length(x), mean = 0, sd = noise_factor * sqrt(x))

y &lt;- y + noisy_y

# 向数据添加零个和一个噪声
noisy_indices &lt;- sample(1:length(x), round(0.2 * length(x)))
for (i in noisy_indices) {
if (runif(1) &lt; 1 / (1 + exp(x[i]))) {
y[i] &lt;- 1
} else {
y[i] &lt;- 0
}
}

# 添加指数分布
noisy_indices &lt;- sample(1:length(x), round(0.5 * length(x)))
for (i in noisy_indices) {
if (runif(1) &lt; 100 / (1 + exp(x[i]))) {
y[i] &lt;- rexp(1, rate =4)
} else {
y[i] &lt;- y[i]
}
}

# 创建数据框
data &lt;- data.frame(x = x, y = y) |&gt;
filter(y&lt;=1 &amp; y&gt;=0)

ggplot(data, 
aes(x, y)) +
geom_point() +
xlim(0, 20) + 
ylim(0, 1)

ggplot(data = data, 
aes(x=y))+
geom_histogram()

我正在尝试制定一个将 X 映射到 Y 的函数

整个数据集中 Y 的分布。在原始数据集中，从零（@Y=0）到指数部分（Y ~ 0-0.25）的过渡非常平滑。

我尝试（在原始数据上）在 brms 中使用零一膨胀 Beta 得出此后验预测：
]]></description>
      <guid>https://stats.stackexchange.com/questions/650533/how-to-fit-a-bayesian-model-to-a-mixture-of-beta-exponential-and-one-zero-infl</guid>
      <pubDate>Fri, 05 Jul 2024 14:49:43 GMT</pubDate>
    </item>
    <item>
      <title>当我的因变量在 R 中被分数幂运算时，我应该如何反向变换 beta 系数</title>
      <link>https://stats.stackexchange.com/questions/650513/what-should-i-back-transform-beta-coefficients-when-my-dependent-variable-is-fra</link>
      <description><![CDATA[我有这个混合效应回归模型。为了在连续尺度因变量中创建正态分布，我对其进行了分数指数化：
TB_fract &lt;- TB ^ (1/1.4)

我的以下模型是这样的，其中 period 表示时间的整数值，MRN 表示单个受试者：
lme4::lmer(TB_fract ~ Surg_group_fact + (1 + period|MRN), data = full_patient_data_2, na.action = na.omit)

我的输出是这样的。 time_below_sqrt 是 TB_fract 的 DV 表示：


我显然有负 beta 估计值，这不允许转换为 1.4 次方。如果我的 DV 是具有负 beta 系数的原始值的分数值，那么我该如何解释这些结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/650513/what-should-i-back-transform-beta-coefficients-when-my-dependent-variable-is-fra</guid>
      <pubDate>Fri, 05 Jul 2024 09:14:21 GMT</pubDate>
    </item>
    </channel>
</rss>