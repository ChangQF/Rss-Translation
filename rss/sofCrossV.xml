<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 31 Jan 2024 00:57:53 GMT</lastBuildDate>
    <item>
      <title>知识前测-后测/对照组和治疗组的 Cronbach 阿尔法</title>
      <link>https://stats.stackexchange.com/questions/638153/cronbachs-alpha-for-knowledge-pretest-posttest-control-and-treatment-groups</link>
      <description><![CDATA[我无法找到有关计算克朗巴赫阿尔法的这些具体问题的明确答案。为了我的论文研究，我进行了教学干预。我进行了前测和后测，以调查干预后知识的增长。我开发了测试项目，并且还开发了并行项目以尽量减少测试效果（因此参与者在测试前和测试后没有回答完全相同的问题）。我还有一个对照组，他们没有经历干预。
我使用 alpha 来衡量测试中六个分量表的内部一致性以及整个测试的内部一致性。每个子量表由 8 个多项选择项目组成，这些项目应该衡量我在治疗中教授的一个子主题。这些都是一个更大主题的一部分，这就是为什么我也想查看整个测试的 alpha 版本。
这是我的问题：

我是一起、单独还是仅计算和报告治疗组和对照组的 alpha？看起来预测时将它们结合起来就可以了，但是干预后，既然一组人经历了干预，那么他们不是不同的人群吗？我预计治疗组会有所改善，而对照组则保持不变。 （这就是实际发生的事情。）

我是否在预测和后测时单独、组合、仅后测、仅预测计算和报告 alpha？如果参与者在干预前不知道材料，那么预测试似乎会包含随机猜测。因此，我不确定测试该数据的内部一致性是否有意义。


测试题为知识选择题（不是李克特题）。我已将响应编码为正确或错误。我已经对所有这些不同的可能性进行了阿尔法分析，但我不知道我应该报告什么。我的顾问也不知道。
如果有人有信誉良好的引用，那将是理想的，但我也非常感谢了解您自己的做法和原因。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/638153/cronbachs-alpha-for-knowledge-pretest-posttest-control-and-treatment-groups</guid>
      <pubDate>Wed, 31 Jan 2024 00:38:50 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 中的手动梯度计算和权重更新</title>
      <link>https://stats.stackexchange.com/questions/638152/manual-gradient-computation-and-weight-update-in-pytorch</link>
      <description><![CDATA[我不想使用torch默认的loss.backward函数进行梯度计算。相反，我根据损失函数手动计算梯度（通过 torch.autograd.grad）。但几步之后我的梯度就变为零了。如果我使用 loss.backward 函数，相同的代码可以工作。 torch 是否对引擎盖下的渐变应用了任何隐藏的转换？ （例如裁剪[-1,1]范围内的渐变、分离渐变等）
我采用这样的渐变：
first_gradient=torch.autograd.grad(HSNR,NN.parameters(),retain_graph=True)
以下是我更新权重的方法：
 与 torch.no_grad()：
        对于参数，zip 中的 newgrad(NN.parameters(),final_gradient)：
            param.grad = 新的grad
    
    优化器.step() ```

]]></description>
      <guid>https://stats.stackexchange.com/questions/638152/manual-gradient-computation-and-weight-update-in-pytorch</guid>
      <pubDate>Wed, 31 Jan 2024 00:07:09 GMT</pubDate>
    </item>
    <item>
      <title>想知道对我的地理空间数据运行什么统计测试？ （初学者）</title>
      <link>https://stats.stackexchange.com/questions/638151/wondering-what-statistical-tests-to-run-on-my-geospatial-data-beginner</link>
      <description><![CDATA[我正在为学校进行一个编码项目，您可以在其中选择主题和数据等。我选择的数据似乎很简单，但现在我意识到我实际上不知道要运行哪些分析.
我想看看臭氧水平与我所在城市家庭的种族群体之间是否存在相关性。基本上，我得到的人口普查数据告诉我给定人口普查区域中不同种族群体的家庭数量，因此种族群体是我的列，人口普查区域是我的行。
然后我还找到了每个人口普查区每月平均地面臭氧浓度的数据（因此在这种情况下，每个人口普查区只有一个数字）。
现在我被困住了。我知道如何编码和制作地图和图表，但我从未上过概率或统计课程。只计算到 calc 3。我的老师也是一名编码员，而不是统计学家，所以他也不确定要运行什么测试 - 他建议我谷歌，但谷歌没有帮助；这门课主要是学习绘制地理空间数据，然后制作图表，统计测试部分基本上是我完成之前需要的最后一件事。 Google 没有提供任何帮助，而且我现在已经进入该项目几个月了，无法选择新数据。
如何找到两个因素之间的相关性，同时考虑到不同组的总体数量不同？然后位置方面让我感到困惑？因为我的数据中有大约一千个人口普查区。我想这将是一个针对每个种族群体进行的测试？我真的不知道。或者某种测试或概率测试？
有什么想法吗？
我没有尝试太多，因为我是统计/数据分析/概率方面的初学者。我唯一的想法是我需要找到“相对曝光度”对于每个组，但我一直很困惑这到底意味着什么？考虑将其发布到数学或统计堆栈交换中。我首先在堆栈溢出中发布了这个问题，有人提到了“回归？”他们还建议在这里询问。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/638151/wondering-what-statistical-tests-to-run-on-my-geospatial-data-beginner</guid>
      <pubDate>Wed, 31 Jan 2024 00:01:38 GMT</pubDate>
    </item>
    <item>
      <title>为什么 OpenAI 的缩放定律论文低估了数据在模型缩放中的重要性？</title>
      <link>https://stats.stackexchange.com/questions/638150/why-did-the-openais-scaling-law-paper-underestimate-the-importance-of-data-in-m</link>
      <description><![CDATA[Chinchilla 论文著名地发现，在缩放模型时，您应该大致同等地增加参数数量和数据量，而不是早期的 OpenAI 缩放定律论文，该论文说您应该增加参数数量，其数量应远多于数据量.
在第 3 页，Chinchilla 论文对 OpenAI 论文为何犯此错误给出了以下解释：
&lt;块引用&gt;
首先，作者对所有模型使用固定数量的训练标记和学习率计划；这
阻止他们对这些超参数对损失的影响进行建模。相比之下，我们发现
将学习率计划设置为大致匹配训练令牌结果的数量
无论模型大小如何，都能获得最佳的最终损失——见图 A1。对于固定学习率余弦时间表
对于 130B 代币，中间损失估计（对于 𝐷&#39; &lt;&lt; 130B）因此高估了
丢失使用与 𝐷&#39; 匹配的时间表长度进行训练的模型。使用这些中间损失会导致
低估了在少于 130B 代币的数据上训练模型的有效性，最终
得出这样的结论：随着计算的进行，模型大小应该比训练数据大小增加得更快
预算增加。

但是为什么会这样呢？如果您的学习率计划导致高估了少量训练数据的损失，那么这是否会导致您高估数据对损失的影响，从而建议比参数计数更快地增加数据大小，而不是相反？]]></description>
      <guid>https://stats.stackexchange.com/questions/638150/why-did-the-openais-scaling-law-paper-underestimate-the-importance-of-data-in-m</guid>
      <pubDate>Tue, 30 Jan 2024 23:19:09 GMT</pubDate>
    </item>
    <item>
      <title>将协方差矩阵分解为不相关和相关部分</title>
      <link>https://stats.stackexchange.com/questions/638149/decompose-covariance-matrix-into-uncorrelated-and-correlated-part</link>
      <description><![CDATA[我有一个几乎对角的协方差矩阵，我想将其分解为不相关和相关的部分：
$$
\Sigma = \Sigma_U + \Sigma_C
$$
其中上面的所有矩阵都是协方差矩阵，$\Sigma_U$ 是对角矩阵。
我想这个解决方案不是唯一的，但我希望 $\Sigma_U$ 是“大”，例如具有大的行列式或迹。
这个问题过去被研究过吗？有封闭的解决方案吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638149/decompose-covariance-matrix-into-uncorrelated-and-correlated-part</guid>
      <pubDate>Tue, 30 Jan 2024 23:13:34 GMT</pubDate>
    </item>
    <item>
      <title>消除弱外生性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638148/clearing-up-weak-exogeneity</link>
      <description><![CDATA[用语言来说，E[u_i|x_i] 到底是什么？
我被告知（根据假设），这意味着任何 x 值的误差项的条件均值都等于 0。但在这种情况下，为什么要包含“x_i”符号呢？这是否不会将 x_i 的值限制为仅与 y_i 的 1 个相应观察“i”相关的特定值？在这种情况下，您如何看待这种期望？]]></description>
      <guid>https://stats.stackexchange.com/questions/638148/clearing-up-weak-exogeneity</guid>
      <pubDate>Tue, 30 Jan 2024 22:55:18 GMT</pubDate>
    </item>
    <item>
      <title>来自同一类别的多个观察值的判别分析的后验概率</title>
      <link>https://stats.stackexchange.com/questions/638147/posterior-probabilities-from-a-discriminant-analysis-with-multiple-observations</link>
      <description><![CDATA[假设进行判别分析的目的是找到可能由三个物种之一产生的未来样本的后验概率。但现在假设我有两个未来的观察结果，并且我能够（不仅仅是愿意）假设这两个观察结果属于同一物种。
要使用两个未来观察结果（以及其他方法）获得 3 个物种的一组 3 个后验概率（当然，总和为 1）：

找到第一个未来的第一组后验概率
观察，然后使用这些概率作为先验
第二次未来观察以获得最终的后验集
概率。

求 2 个未来各自的后验概率
观察，然后使用相应的产品
后验概率除以这些乘积的总和。


我的问题是“是否有一种指定的分析技术/模型/软件可以使用指定的模型假设执行此类计算，从而可以解释判别函数构造中的不确定性？”
（在此网站上进行搜索确实发现了 2 个模糊相似的问题，但其中一个没有答案，另一个没有足够详细的答案。）]]></description>
      <guid>https://stats.stackexchange.com/questions/638147/posterior-probabilities-from-a-discriminant-analysis-with-multiple-observations</guid>
      <pubDate>Tue, 30 Jan 2024 22:42:33 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用 glm 重现嵌套 logit 离散选择模型？</title>
      <link>https://stats.stackexchange.com/questions/638146/is-it-possible-to-reproduce-a-nested-logit-discrete-choice-model-with-a-glm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/638146/is-it-possible-to-reproduce-a-nested-logit-discrete-choice-model-with-a-glm</guid>
      <pubDate>Tue, 30 Jan 2024 22:14:29 GMT</pubDate>
    </item>
    <item>
      <title>理解《理解训练深度前馈神经网络的难度》</title>
      <link>https://stats.stackexchange.com/questions/638145/understanding-understanding-the-difficulty-of-training-deep-feedforward-neural</link>
      <description><![CDATA[我正在跟进这个问题，我想对此进行更具体的说明。
我非常熟悉协方差矩阵，它是随机变量（协）方差随机向量的矩阵值推广。然而，在了解训练深度前馈神经网络的难度中，我有点不清楚作者对某些术语的方差的含义，特别是在方程 $(5)$ 中。
看起来方程$(5)$之前的假设段落引入了随机矩阵的权重分布（总计？）$W^{i&#39;}$ 彼此独立且与输入无关。此外，从上下文来看，它们似乎应该以零为中心（我想是从条目角度来看）。对于标量独立零均值 r.v. 的 $u$、$v$ 对我来说很明显$\mathbb{V}(uv) = \mathbb{V}(u) \mathbb{V}(v)$，并根据 $f$ （事实上， $f(x) \approx x$ 作为标量函数或作为坐标-应用向量函数）很明显 $\mathbb{V}(\bf{z}^i) = \mathbb{V}(\bf{z}^{i-1 }W^{i-1})$ - 也就是说，假设在此一般情况下方差呈线性。
由此（或者如果您不想太仔细地阅读我的作品，则可以从基本原理）我们可以获得方程 $(5)$ 吗？方程如下：
$$ \mathbb{V}(\mathbf{z}^i) = \mathbb{V}(\mathbf{x}) \prod_{i&#39; = 0} ^{i-1} n_{i&#39;}\mathbb{V}(\mathbf{W}^{i&#39;})$$]]></description>
      <guid>https://stats.stackexchange.com/questions/638145/understanding-understanding-the-difficulty-of-training-deep-feedforward-neural</guid>
      <pubDate>Tue, 30 Jan 2024 22:02:17 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯伽玛模型的正确设置</title>
      <link>https://stats.stackexchange.com/questions/638144/correct-setup-for-a-bayesian-gamma-model</link>
      <description><![CDATA[我有兴趣了解中心体积如何影响 医疗保健应用。每个项目的绩效都以观察/预期 (O/E) 比率的形式报告，其中预期结果数量是根据多变量模型估计的。 O/E 比率由(O+2)/(E+2) 计算。该比率的分布是使用贝叶斯方法计算的，其中先验分布是形状 = 2 且比率 = 2（平均值 = 1，方差 0.5）的伽玛分布，后验分布是形状 = 2 + 观察到的计数的伽玛分布比率 = 2 + 预期计数。
这是否表明对于一个拥有 50 个观察到的事件和 40 个预期事件的中心：
&lt;前&gt;&lt;代码&gt;心率 = (2+50)/(2+40)
HRprior = 伽马(2,2)
HRposterior = 伽玛(52, 42)

如果不对，请指正。
一些用于思考的 R 代码：
&lt;前&gt;&lt;代码&gt;#比率
  小时 &lt;- 50/40
  hr.prior &lt;- 2/2
  后路 &lt;- (2+50)/(2+40)

#发行版
  hr.prior.dist &lt;- rgamma(10000, 2, 2)
  平均值（hr.prior.dist）#1.002
  var(hr.prior.dist) #0.512
  
  hr.post.dist &lt;- rgamma(10000, 2+50, 2+40)
  平均值（时.后.距离）
  var(hr.post.dist)
]]></description>
      <guid>https://stats.stackexchange.com/questions/638144/correct-setup-for-a-bayesian-gamma-model</guid>
      <pubDate>Tue, 30 Jan 2024 22:02:08 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 R 中“REML 拟合的线性混合模型”的输出？</title>
      <link>https://stats.stackexchange.com/questions/638141/how-to-interpret-the-output-of-linear-mixed-model-fit-by-reml-in-r</link>
      <description><![CDATA[我制作了一个混合模型来研究两种干预措施（力量或耐力）对身体活动的影响。
PA ~ 程序 + 时间 + 程序 * 时间 + (时间 | vnr)

PA = 身体活动
progr = 干预计划（1 = 耐力，2 = 力量）
时间 = 测量时间点（基线、6 周后和 12 周后）

我使用此代码来构建模型：
mix.intslo_PA_2 &lt;- lmer(PA ~ progr + time + progr*time + (time|vnr), data_l)
摘要（mix.intslo_PA_2）

现在，当我得到输出时，我不知道如何解释，因为我找不到任何关于如何执行此操作的明确解释。也许任何人都可以帮助我。提前致谢！
不知道去哪里看。解释什么是重要的？随机效应或固定效应是什么意思？以及如何解释它们？
这是输出：
&lt;前&gt;&lt;代码&gt;&gt;摘要（mix.intslo_PA_2）
REML 拟合线性混合模型。 t 检验使用 Satterthwaite 方法 [&#39;lmerModLmerTest&#39;]
公式：PA ~ progr + time + progr * time + (time | vnr)
   数据：data_l

REML 收敛准则：8772.7

缩放残差：
     最小 1Q 中值 3Q 最大
-1.99644 -0.77989 -0.01227 0.84138 1.88024

随机效果：
 组名称方差标准差科尔
 vnr（拦截）28188.4 167.89
          时 192.5 13.87 -0.54
 剩余 137102.2 370.27
obs 数量：594，组：vnr，198

固定效果：
            估计标准。误差df t值Pr(&gt;|t|)
(截距) 773.982 38.722 196.001 19.988 &lt;2e-16 ***
程序2 -54.241 53.687 196.001 -1.010 0.314
时间 -2.205 4.698 196.002 -0.469 0.639
程序2：时间 2.025 6.514 196.002 0.311 0.756
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应的相关性：
            (Intr) progr2 时间
程序2 -0.721
时间 -0.733 0.529
程序2：时间0.529 -0.733 -0.721
]]></description>
      <guid>https://stats.stackexchange.com/questions/638141/how-to-interpret-the-output-of-linear-mixed-model-fit-by-reml-in-r</guid>
      <pubDate>Tue, 30 Jan 2024 21:43:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么矩量法可以表示为极小化问题？</title>
      <link>https://stats.stackexchange.com/questions/638140/why-can-the-method-of-moments-be-expressed-as-a-minimization-problem</link>
      <description><![CDATA[广义矩法（GMM）估计似乎被称为广义矩法，因为标准矩法（MoM）是一种特殊情况，遵循以下逻辑。

MoM 通过将力矩条件设置为零来求解。

这可以看作是一个最小化问题，其中矩条件向量的 $\ell_2$ 范数被最小化。

在 GMM 中，我们的矩条件可能多于参数，因此仅通过 MoM 求解方程组是不够的。

但是，由于 MoM 具有与最小化问题等效的公式，因此我们可以使用此想法并根据某种“接近”概念找到最接近零的矩条件。


我遵循第一步、第三步和第四步。然而，尚不清楚为什么 MoM 计算可以改写为最小化。为什么会这样？
第二个步骤来自此视频，围绕 3 ：30分。]]></description>
      <guid>https://stats.stackexchange.com/questions/638140/why-can-the-method-of-moments-be-expressed-as-a-minimization-problem</guid>
      <pubDate>Tue, 30 Jan 2024 21:22:55 GMT</pubDate>
    </item>
    <item>
      <title>给定 N 个观察值 - 已知均值的正态分布的未知方差的贝叶斯后验？</title>
      <link>https://stats.stackexchange.com/questions/638137/given-n-observations-bayesian-posterior-for-unknown-variance-of-a-normal-distr</link>
      <description><![CDATA[因此，除了使用 $\mu = 0$ 的高斯试验进行 N 次试验之外，没有任何信息，我想知道未知数的最佳贝叶斯后验方差，$\sigma^2$。
到目前为止，我的方法是假设 $\tau = \frac{1}{\sigma}$ 有一个统一的先验，即标准高斯。除了更直观（对我来说）之外，这也是必要的，因为尝试对 $\sigma$ 或使用统一先验$\sigma^2$ 将导致发散积分。
然后对于 N 个观测值，这会导致后验分布：
$Pr(\tau|x_1,x_2,...,x_n) = \frac{S^{n+1}\tau^n}{\Gamma(\ frac{n+1}{2})2^{\frac{n-1}{2}}}exp(-\frac{\tau^2}{2}S^2)$
其中$S^2 = x_1^2+x_2^2+\cdots+x_n^2$，即观测值的平方和。
如果我们将变量转换为方差，那么我们有：
$Pr(\sigma^2|x_1,x_2,...,x_n) = \frac{(\frac{S^2}{2})^{\ frac{n+1}{2}}}{\Gamma(\frac{n+1}{2})(\sigma^2)^{\frac{n+3}{2}}}exp(-\ frac{S^2}{2}\frac{1}{\sigma^2}) = InvGamma({\sigma^2;\alpha = \frac{n + 1}{2},\beta = \frac{ S^2}{2})}$。
幸运的是，这正是带有参数的逆伽玛分布 $\alpha = \frac{n + 1}{2}, \beta = \frac{S^2 {2}$，与此维基百科页面相当神秘的声明相符=&quot;nofollow noreferrer&quot;&gt;https://en.wikipedia.org/wiki/Inverse-gamma_distribution：
&lt;块引用&gt;
“也许逆伽玛分布的主要用途是
贝叶斯统计，其中分布作为边际出现
正态分布的未知方差的后验分布
分布，如果使用无信息先验的话”

所以我的问题：嗯，这一切都很好，但我还没有在网上其他地方找到类似的分析，这令人担忧。而且，我推导出的后验分布的均值是 $\frac{S^2}{n-1}$，众数是 $\frac{S^2}{n+3}$。我有点怀疑其中至少有一个是 $\frac{S^2}{n}$ 因为我们知道平均值，因此我们在估计方差时不会失去一定的自由度......
帮我指出正确的方向吗？我很困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/638137/given-n-observations-bayesian-posterior-for-unknown-variance-of-a-normal-distr</guid>
      <pubDate>Tue, 30 Jan 2024 19:59:25 GMT</pubDate>
    </item>
    <item>
      <title>站点的不同基线数据[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638135/different-baseline-data-for-sites</link>
      <description><![CDATA[我有 2 种治疗方法和 1 个部位的数据（见图）。我正在尝试使用下面的代码运行混合模型。
模型 &lt;- lmer（产量 ~ 处理 + 品种 +（1 | 站点），数据 = 产量，REML = FALSE）

但是，我有一个困惑。如果你看一下数据，“治疗”就会很明显。 （添加/存在的氮量）具有三个级别，但每个地点的第一个级别不同。因此，当站点的第一级处理不同但随后是类似的第二级和第三级时。您如何考虑模型中的这种变化？
]]></description>
      <guid>https://stats.stackexchange.com/questions/638135/different-baseline-data-for-sites</guid>
      <pubDate>Tue, 30 Jan 2024 19:37:44 GMT</pubDate>
    </item>
    <item>
      <title>这个平方和 beta 之间的比率是分布的吗？</title>
      <link>https://stats.stackexchange.com/questions/638134/is-this-rato-between-sum-of-squares-beta-distributed</link>
      <description><![CDATA[考虑 $x_i \sim N(\mu,\sigma)$ 我对以下统计量的分布感兴趣（来自似然比检验）：
$$
\压裂{
\sum_{n=1}^{n} (x_i - \overline{x})^2
}{
\sum_{n=1}^{n} (x_i - \mu)^2
}
$$
其中 $\overline{x}$ 是样本平均值
通过模拟观察 N 个统计数据的分布后，我注意到它看起来非常像 $Beta(\frac{1}{2}+\frac{n-2} {2},\frac{1}{2})$
以下是针对 n=2,3 和 10 绘制的经验 CDF 和 beta CDF 的样子：



我的猜测正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638134/is-this-rato-between-sum-of-squares-beta-distributed</guid>
      <pubDate>Tue, 30 Jan 2024 19:10:45 GMT</pubDate>
    </item>
    </channel>
</rss>