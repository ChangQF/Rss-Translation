<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 20 Nov 2024 21:16:05 GMT</lastBuildDate>
    <item>
      <title>一组不完整集合中的发生推断/统计</title>
      <link>https://stats.stackexchange.com/questions/657580/occurence-extrapolation-statistics-in-a-set-of-incomplete-collections</link>
      <description><![CDATA[我的统计学课程现在还很遥远（我是一名生物学家）。我的问题可能微不足道，但我不知道从哪里开始。
首先，我检查元素 X 是否存在于 Si 元素的集合 Ci 中。其次，对于一组集合，我得到 X 的出现次数。
问题是每个集合 Ci 中都有 Mi 个缺失值。因此，如果 X 在 Ci 中缺失，可能是因为它实际上不存在，也可能是因为它存在于缺失元素中。但我知道每个集合的完整性（百分比），因此对于每个集合，我都知道已知元素 (Ki)、缺失元素 (Mi) 和总元素 (Si) 的数量。
因此，我低估了整个集合的出现次数。如何推断真实出现次数？有没有办法评估推断或测量出现的稳健性？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657580/occurence-extrapolation-statistics-in-a-set-of-incomplete-collections</guid>
      <pubDate>Wed, 20 Nov 2024 21:07:20 GMT</pubDate>
    </item>
    <item>
      <title>Metropolis-Within-Gibbs 算法的数学参考</title>
      <link>https://stats.stackexchange.com/questions/657579/mathematical-reference-for-metropolis-within-gibbs-algorithm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657579/mathematical-reference-for-metropolis-within-gibbs-algorithm</guid>
      <pubDate>Wed, 20 Nov 2024 21:05:28 GMT</pubDate>
    </item>
    <item>
      <title>DBSCAN 之前数据集中缺少值</title>
      <link>https://stats.stackexchange.com/questions/657578/missing-values-in-data-set-before-dbscan</link>
      <description><![CDATA[我有一个由 4 个表组成的数据集，这 4 个表是从不同的来源收集的。我想使用这 4 个表中的特征组合对这些数据点执行聚类。
但是，通常情况下，用户可能只有来自 1、2 或 3 个来源的数据，而不是全部 4 个来源的数据。我该如何处理此处的缺失数据？
此外，我有大约 500k 个样本，几乎有 100 多个特征。由于每组特征来自不同的表，我应该使用 PCA 来最小化特征数量吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657578/missing-values-in-data-set-before-dbscan</guid>
      <pubDate>Wed, 20 Nov 2024 20:59:44 GMT</pubDate>
    </item>
    <item>
      <title>回归结果 - 解释交互项</title>
      <link>https://stats.stackexchange.com/questions/657576/regression-result-interpretation-interaction-term</link>
      <description><![CDATA[我对如何解释回归结果中的交互项感到困惑。
结果如下：

WorkatHome 是二元变量，当人们在家工作时为 1；否则为 0（在办公室工作）
SingleFamily 也是二元变量，当人们生活在单户住宅中时为 1；否则为 0（住在多户家庭中）

我的解释是“在家工作的人住在单户家庭中时往往比在办公室工作的人有更高的工作满意度”。
我收到一条评论说这种解释是错误的。评论说这种解释应该是与住在多户家庭中的人进行比较。
请帮我理解正确的解释是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/657576/regression-result-interpretation-interaction-term</guid>
      <pubDate>Wed, 20 Nov 2024 20:34:21 GMT</pubDate>
    </item>
    <item>
      <title>我计算统计功效是否错误？为什么？</title>
      <link>https://stats.stackexchange.com/questions/657575/am-i-computing-statistical-power-wrong-why</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657575/am-i-computing-statistical-power-wrong-why</guid>
      <pubDate>Wed, 20 Nov 2024 20:31:45 GMT</pubDate>
    </item>
    <item>
      <title>更多样本的 MLE 是否总是具有较低的风险？</title>
      <link>https://stats.stackexchange.com/questions/657574/does-mle-on-more-samples-always-have-a-lower-risk</link>
      <description><![CDATA[用 $\hat{\theta}_{n} = \arg\max_\theta \prod_{i=1}^n p(x_i; \theta)$ 表示 $n$ 个 i.i.d. 样本的 MLE。我想知道添加更多样本是否总会降低风险，或者至少不会提高风险。具体来说，让 $\theta^\ast$ 为真实参数，$\|\cdot\|_2$ 和 $\|\cdot\|_\infty$ 分别成为 $\ell^2$ 和 $\ell^\infty$ 范数。以下任何陈述是否正确？随意施加一些规律性条件。
$$
\mathbb{E}\|\hat{\theta}_{n+1} - \theta^\ast\|_2 \le \mathbb{E}\|\hat{\theta}_{n} - \theta^\ast\|_2 \\
\mathbb{E}\|\hat{\theta}_{n+1} - \theta^\ast\|_\infty \le \mathbb{E}\|\hat{\theta}_{n} - \theta^\ast\|_\infty
$$
请注意，我问的是风险（即预期误差）；误差$\|\hat{\theta}_{n+1} - \theta^\ast\|$几乎肯定不必小于$\|\hat{\theta}_{n} - \theta^\ast\|$（有关详细信息，请参阅此问题）。
事实上，我关心的确切模型系列是逻辑回归，但我认为应该存在 MLE 的更通用结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/657574/does-mle-on-more-samples-always-have-a-lower-risk</guid>
      <pubDate>Wed, 20 Nov 2024 19:12:36 GMT</pubDate>
    </item>
    <item>
      <title>统计检验两种测量社区组成的方法是否产生相同的分布？</title>
      <link>https://stats.stackexchange.com/questions/657572/statistical-test-for-whether-two-methods-of-measuring-community-composition-prod</link>
      <description><![CDATA[我正在测量 1 个地点的 3 个样本中捕获的 30 个分类群的群落组成（即丰度分布）。对于我的每个样本，我使用两种不同的方法测量了群落组成：DNA 宏条形码，产生约 1M 个读数的分布，以及对在地点拍摄的图像进行注释，产生约 1K 个注释点的分布。我想要一个统计测试来告诉我这两种方法是否产生了有意义的不同结果（因此我需要同时使用这两种方法才能捕获完整的多样性）或者它们是否产生了相同的结果（因此我只能使用其中一种）。
使用哪种测试最好？
我考虑过的测试：

卡方拟合优度检验：我认为两种方法之间的量级差异会是一个问题。
Kolmogorov-Smirnov：需要连续分布，而我在名义类别上有一个离散分布。
PERMANOVA：似乎可以行得通，尽管重复次数太少，功效会很低。
Mantel 测试：似乎可以行得通，尽管重复次数太少，功效会很低。

还有其他想法吗？谢谢！

Mike
]]></description>
      <guid>https://stats.stackexchange.com/questions/657572/statistical-test-for-whether-two-methods-of-measuring-community-composition-prod</guid>
      <pubDate>Wed, 20 Nov 2024 19:02:51 GMT</pubDate>
    </item>
    <item>
      <title>ECM：添加 I(0) 变量</title>
      <link>https://stats.stackexchange.com/questions/657571/ecm-adding-i0-variable</link>
      <description><![CDATA[我有一个 ECM 模型，其中长期关系是 $y$ 和 $x_1$ 之间的关系，它们都是 I(1) 且是协整的，即
$y(t) = a + b.x_1(t) +\epsilon(t)$
对于这个长期关系，我想添加 $x_2$，即 I(0)。将 $x_2$ 添加到短期响应中是没有意义的。业务逻辑表明 $x_2$ 应该影响 $y$，而不是 $\Delta y$。换句话说，如果没有 $x_1$，$y$ 将由 $x_2$ 驱动，在这种情况下 $y$ 将为 I(0)。构建没有 $x_2$ 的模型是没有意义的，而包括 $x_2$ 是短期响应也是没有意义的。直觉是 $x_2$ 影响 $y$。所以我专注于长期方程。
从数学上讲，
$y(t) = a + b.x_1(t) + c.x_2(t) + \mu(t)$
听起来正确。$y$ 和 $x_1$ 是协整的，因此添加 $x_2$ 应该不会产生影响。残差仍为 I(0)。这与教科书/经典 ECM 框架背道而驰，所以我的问题是：

您认为这种类型的方程有什么问题吗？
我在哪里可以找到有关该主题的文献？文献重点关注 I(1) 过程，我找不到有关添加 I(0) 变量的参考资料。
或者，我可以用 $x_1$ 构建 LT，然后将残差 $\epsilon$ 回归到 $x_2$（两者都是 I(0)），然后转到短期分量吗？这样做，什么会是错误的？
您会建议什么替代方法？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657571/ecm-adding-i0-variable</guid>
      <pubDate>Wed, 20 Nov 2024 17:58:00 GMT</pubDate>
    </item>
    <item>
      <title>熵平衡入门</title>
      <link>https://stats.stackexchange.com/questions/657570/primer-on-entropy-balancing</link>
      <description><![CDATA[我搜索了互联网，但无论如何也找不到关于熵平衡的全面入门书。
我目前正在清理数据，以便为队列研究中的那部分人群创建权重，我将对其进行分析。我目前正在玩弄 R 中的 WeightIt 包。小插图包含一些很棒的信息，但我正在寻找更多信息。
我对这个过程有几个一般性的问题，例如：

我的主要“问题”是，我可以访问无数的全民登记数据（教育、社会经济地位、生活条件、精神病诊断、医生就诊等）。所以我不确定最好包括哪些内容以及如何操作变量（以及哪些可能是多余的甚至有害的）。本质上：这里有任何可以指导我的过程的一般技巧吗？

包括许多变量（最终会导致更多具有 NA 的行）和选择较少的变量（许多 NA 似乎会导致权重的方差较大）之间的权衡是什么。

如何交叉验证权重？我正在考虑查看队列样本是否与一系列变量的总体具有相似的相关性。

还有其他方法可以评估权重的表现如何吗？


我知道这些问题最终必须由我在研究的背景下解决，但这就是我寻找一些可以帮助我指导过程的入门知识的原因。
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657570/primer-on-entropy-balancing</guid>
      <pubDate>Wed, 20 Nov 2024 17:39:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么嵌套方差分析之间的 f 统计量会发生变化？</title>
      <link>https://stats.stackexchange.com/questions/657568/why-does-the-f-statistic-change-between-nested-anovas</link>
      <description><![CDATA[我对方差分析表中 p 值的理解是，它给出了在一系列越来越大的模型中附加预测因子的重要性。因此，我期望在具有 2 个预测因子的模型上运行的方差分析表的前 2 行与使用相同数据和第 3 个预测因子运行的方差分析表的前 2 行相同。但是 R 的 anova.lm 做了一些不同的事情：
+ n &lt;- 10
+ y &lt;- rnorm(n)
+ X &lt;- matrix(rnorm(3*n),ncol=3)
+ anova(lm(y~X[,1] + X[,2]))
+ anova(lm(y~X[,1] + X[,2] + X[,3]))
+
方差分析表

响应：y
Df 总和 平方 均值 平方 F 值 Pr(&gt;F)
X[, 1] 1 0.3082 0.3082 0.1901 0.6760
X[, 2] 1 3.3563 3.3563 2.0704 0.1934
残差 7 11.3473 1.6210
&gt; 方差分析表

响应：y
Df 总和 平方 均值 平方 F 值 Pr(&gt;F)
X[, 1] 1 0.3082 0.3082 0.1631 0.7003
X[, 2] 1 3.3563 3.3563 1.7767 0.2309
X[, 3] 1 0.0131 0.0131 0.0069 0.9363
残差 6 11.3342 1.8890

第二张表第二行的 F 统计量来自哪里？平方和与 df 与第一个表中的相同，因此 F 统计量的分母在两个表中必须不同。如果两者都只是在包含 $\beta_0$ 和 $\beta_1$ 的模型中测试 $\beta_2=0$，那为什么会这样呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/657568/why-does-the-f-statistic-change-between-nested-anovas</guid>
      <pubDate>Wed, 20 Nov 2024 17:01:52 GMT</pubDate>
    </item>
    <item>
      <title>从概率密度函数到总体简单线性回归函数的转变[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657566/the-shift-from-the-probability-density-function-to-the-population-simple-linear</link>
      <description><![CDATA[从概率密度函数转换为总体简单线性回归函数时：

β 如何从函数的展开转换为函数的斜率？

x_i 如何从 DV 值集转换为 IV 值集？

α 如何从 PDF 的起点转换为总体简单线性回归函数中的点截距？


注释：

总体简单线性回归函数：
]]></description>
      <guid>https://stats.stackexchange.com/questions/657566/the-shift-from-the-probability-density-function-to-the-population-simple-linear</guid>
      <pubDate>Wed, 20 Nov 2024 16:25:32 GMT</pubDate>
    </item>
    <item>
      <title>这是什么意思：“OLS 比 GLS 更为稳健”？</title>
      <link>https://stats.stackexchange.com/questions/657565/what-does-this-mean-ols-is-more-robust-than-gls</link>
      <description><![CDATA[我正在读一本书，书中写道：

当误差不遵循 OLS 假设时，OLS 是一致的，并且
通常比 GLS 更稳健...&quot;

我知道稳健回归 - 我们抑制异常值影响的回归（通常用于$y$来自重尾分布的情况）。
OLS 比 GLS 更稳健是什么意思？]]></description>
      <guid>https://stats.stackexchange.com/questions/657565/what-does-this-mean-ols-is-more-robust-than-gls</guid>
      <pubDate>Wed, 20 Nov 2024 16:00:57 GMT</pubDate>
    </item>
    <item>
      <title>对于前测/后测设置，我应该使用原始分数、标准分数还是标准分数来进行学生 t 检验？</title>
      <link>https://stats.stackexchange.com/questions/657564/for-a-pre-test-post-test-setting-should-i-use-the-raw-score-the-scaled-score-o</link>
      <description><![CDATA[我有点迷茫。我正在做一个旨在评估教育干预效果的项目。为此，在干预前后对同一组进行标准化测试（前测/后测）。样本很小，只有 35 个人。问题是测试有三种类型的分数：原始分数、量表分数和标准分数（取决于学生的年龄）。我计划进行 Shapiro-Wilk 检验来评估数据的正态性。如果分布为正态，我将使用学生 t 检验来评估干预的有效性，但我不确定我会使用什么分数：原始分数、量表分数还是标准分数？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/657564/for-a-pre-test-post-test-setting-should-i-use-the-raw-score-the-scaled-score-o</guid>
      <pubDate>Wed, 20 Nov 2024 15:31:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 MC 估计得出一个期望大于另一个期望的概率</title>
      <link>https://stats.stackexchange.com/questions/657563/probability-that-one-expectation-is-larger-than-another-expectation-using-mc-est</link>
      <description><![CDATA[考虑一个期望$a=\int f(\boldsymbol{x})p(\boldsymbol{x})d\boldsymbol{x}$和一个期望$b=\int g(\boldsymbol{x})q(\boldsymbol{x})d\boldsymbol{x}$。
对于给定的少量样本$f(\boldsymbol{x}_i), \boldsymbol{x}_i \sim p(\boldsymbol{x})$和$g(\boldsymbol{x}_j), \boldsymbol{x}_j \sim q(\boldsymbol{x})$，是否存在非参数方法来计算概率$P(b&gt;a)$?]]></description>
      <guid>https://stats.stackexchange.com/questions/657563/probability-that-one-expectation-is-larger-than-another-expectation-using-mc-est</guid>
      <pubDate>Wed, 20 Nov 2024 15:10:32 GMT</pubDate>
    </item>
    <item>
      <title>预测多元时间序列的所有特征的多个步骤</title>
      <link>https://stats.stackexchange.com/questions/657540/forecasting-multiple-steps-of-a-multivariate-time-series-for-all-features</link>
      <description><![CDATA[我正在开展一个项目，其中有 100 个长度为 1-10 分钟的多个时间序列（每 0.1 秒采样一次）。每个时间序列都是人类情绪的记录，存储为 7 个特征的向量，每个特征对应于该时间戳所见情绪的百分比（例如 t=4.2 秒，[0.5,0.2,0.1,0,0.2,0,0] 代表 50% 高兴、20% 悲伤、10% 惊讶等）。因此，1 分钟长的时间序列将存储为 600x7 矩阵（600 个时间步长，7 个特征）。
我的目标是设计一个机器学习模型，该模型对我拥有的 100 个时间序列进行训练，并预测接下来 10 秒的情绪（要决定要预测多少秒，但我将在本文中使用 10 秒）。
数据预处理：对 100 个时间序列中的每一个使用不重叠的段来生成我的训练和测试数据（80-20 分割）。因此，每个 xTrain 由 600 个时间步长组成，相应的 yTrain 是接下来的 100 个时间步长。我通过随机分割整个时间序列而不是它们的片段来确保训练集和测试集之间没有数据泄漏。即在 100 个时间序列中，没有一个时间序列具有 xTrain 中的段和 xTest 中的不同段
我想知道哪种类型的机器学习模型最适合用于此目的？
我考虑过 LSTM，但我发现的所有研究论文都只使用 LSTM 来 1. 预测多个特征的下一个值或 2. 预测单个特征未来的多个时间步（通过递归地将单步预测输入模型或一次性输入）——没有一篇 LSTM 论文同时做到了这两者。]]></description>
      <guid>https://stats.stackexchange.com/questions/657540/forecasting-multiple-steps-of-a-multivariate-time-series-for-all-features</guid>
      <pubDate>Wed, 20 Nov 2024 02:41:54 GMT</pubDate>
    </item>
    </channel>
</rss>