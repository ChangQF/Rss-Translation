<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 03 Apr 2024 06:17:41 GMT</lastBuildDate>
    <item>
      <title>这是什么样的图表以及如何阅读它？</title>
      <link>https://stats.stackexchange.com/questions/644158/what-kind-of-chart-is-this-and-how-to-read-it</link>
      <description><![CDATA[我发现了这张既奇怪又有趣的图表。这是关于上述地区产生的一些文学作品。 x 轴是时间，y 轴是百分比。  前面的段落有如何阅读的提示，但我仍然迷失了。

阅读阿拉伯半岛的内容很简单，但是比如说伊拉克或伊朗呢？一个简单的演练将会有很大帮助。
这是标准图表还是作者的发明？]]></description>
      <guid>https://stats.stackexchange.com/questions/644158/what-kind-of-chart-is-this-and-how-to-read-it</guid>
      <pubDate>Wed, 03 Apr 2024 05:56:34 GMT</pubDate>
    </item>
    <item>
      <title>Check_model性能包解释图</title>
      <link>https://stats.stackexchange.com/questions/644155/check-model-performance-package-interpretation-plots</link>
      <description><![CDATA[我对 r 和统计相当陌生，我正在使用包含 57 个观测值和 13 个自变量的数据集构建青蛙占用率和丰度的 GLM。由于某些变量是相关的，全局模型有 7 个参数，但基于 AICc 的最佳模型有 2/3 个参数。我使用二项式来计算占用率，而对于丰富度，我尝试了负二项式和零膨胀负二项式，因为零的数量相对较多（观察到的 23 个，预测的 21 个）。
构建模型后，我使用性能包中的 check_model 函数来评估这些模型，但我有一些疑问。
关于二项式 GLM：

后验预测检查图显示 0 和 1 的预测计数在 y 轴上的观测数据范围内，但为什么 x 轴上存在差异？模型预测数据如何在二项式上超过 1？
关于分箱残差图，所有具有最低 AICc 的模型都有相当多的点（约 50%）超出误差范围。如果点非常接近误差范围，那么情况总是那么糟糕还是没有那么糟糕？我附上了两个模型的图：一个有 50% 的点超出范围，AICc 约为 58，另一个只有一个点，AICc 约为 62。



关于负二项式和零膨胀负二项式：

关于错误指定的离差和零膨胀图，所有模型都具有与下面共享的类似模式，其中观察到的方差和预测的方差在 5 左右之前相似，但随后预测的残差方差增加，而观察到的残差方差略有下降。我尝试在网上搜索，但我很困惑，因为从我读到的残差方差=观察到预测。因此，我期望一条线，而图表显示观察到的残差方差和预测残差方差。
关于零膨胀负二项式的 VIF 图，我想知道当条件下所有值都较低或中等时，零膨胀如何产生如此巨大的 VIF 值 (&gt;3,000)。


]]></description>
      <guid>https://stats.stackexchange.com/questions/644155/check-model-performance-package-interpretation-plots</guid>
      <pubDate>Wed, 03 Apr 2024 04:40:20 GMT</pubDate>
    </item>
    <item>
      <title>PERMANOVA 能否按因素确定空间（纬度/经度）差异</title>
      <link>https://stats.stackexchange.com/questions/644154/can-permanova-determine-spatial-lat-lon-differences-by-factor</link>
      <description><![CDATA[我有一个由许多带有纬度和经度坐标的点组成的数据集。每个点都可以用“月份”因子来表征。
我想测试几个月之间这些点的位置是否存在差异。
使用 adonis2 R 包，我运行了一个 PERMANOVA，如下所示，它使用了由每个点的纬度和经度坐标形成的欧几里得相异矩阵。
&lt;前&gt;&lt;代码&gt;adonis2(
  com_hd.df[ , c(“经度”,“纬度”)] ~ 月,
  数据= com_hd.df，
  方法=“euc”
）

输出：
简化模型下adonis的排列测试
按顺序添加的术语（从第一个到最后一个）
排列：自由
排列数：999

adonis2(公式 = com_hd.df[, c(&quot;经度&quot;, &quot;纬度&quot;)] ~ 月份, 数据 = com_hd.df, 方法 = &quot;euc&quot;)
           Df SumOfSqs R2 F Pr(&gt;F)
第 11 个月 70.72 0.13289 33.437 0.001 ***
剩余 2400 461.49 0.86711
合计 2411 532.22 1.00000
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

这对我来说看起来不错，月份的 sig 效应，数据有很多变化，所以 R2 与残差是有意义的。
问题！！
我找不到任何使用空间数据进行类似测试的示例。我是不是错过了什么？？？这有道理吗？
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/644154/can-permanova-determine-spatial-lat-lon-differences-by-factor</guid>
      <pubDate>Wed, 03 Apr 2024 03:56:53 GMT</pubDate>
    </item>
    <item>
      <title>应该是一个关于熵的简单问题</title>
      <link>https://stats.stackexchange.com/questions/644153/supposed-to-be-a-simple-question-about-entropy</link>
      <description><![CDATA[假设有一个瓮，里面装有不同颜色的球。这是一个众所周知的计算瓮中球的熵的公式：
H = - 总和 Pi*log(Pi)
其中 Pi = Mi/N，其中 Mi - 第 i 种颜色的球的数量，N 是瓮中球的总数。
当每种颜色的球数量相同时，熵值最大；如果所有球颜色相同，则熵值为 0。
这是基本的。
现在假设我们再添加几个骨灰盒。现在如何计算熵？
直观上，如果每个瓮中每种颜色的球数量相同，则熵应该最大。
如果所有瓮都有相同数量的相同颜色的球（并且没有其他球），则熵应为 0。
在这两者之间，如果所有瓮都有相同数量的球，但每个瓮都有自己颜色的球，则存在一些熵；或者如果瓮里的球数量不是偶数或者有些瓮是空的等等。
我们可以使用上面的公式分别计算每个瓮的熵；我们可以使用类似的公式计算瓮之间的熵；我们可以尝试使用算术来组合这些熵，但我觉得一定有一个我很难弄清楚的优雅干净的公式。]]></description>
      <guid>https://stats.stackexchange.com/questions/644153/supposed-to-be-a-simple-question-about-entropy</guid>
      <pubDate>Wed, 03 Apr 2024 03:36:55 GMT</pubDate>
    </item>
    <item>
      <title>如果 ARIMA、AR 和其他模型明显具有滞后依赖性，为什么我们要使时间序列平稳？</title>
      <link>https://stats.stackexchange.com/questions/644142/why-do-we-make-a-time-series-stationary-if-the-arima-ar-and-other-models-are-cl</link>
      <description><![CDATA[当我们运行 AR 模型时，我们使用其滞后的线性组合来预测当前值。所以这意味着滞后彼此相关（至少 t-1、t-2、...、t-n 与 t0 相关）。另一方面，平稳性是指独立性。我不明白为什么会这样，发生了什么。有人可以帮我解释一下这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644142/why-do-we-make-a-time-series-stationary-if-the-arima-ar-and-other-models-are-cl</guid>
      <pubDate>Tue, 02 Apr 2024 22:24:28 GMT</pubDate>
    </item>
    <item>
      <title>如何计算自动归一化重要性采样估计器的偏差</title>
      <link>https://stats.stackexchange.com/questions/644076/how-to-compute-the-bias-of-the-auto-normalized-importance-sampling-estimator</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644076/how-to-compute-the-bias-of-the-auto-normalized-importance-sampling-estimator</guid>
      <pubDate>Tue, 02 Apr 2024 05:04:48 GMT</pubDate>
    </item>
    <item>
      <title>比较“fish”数据集中的两个模型</title>
      <link>https://stats.stackexchange.com/questions/644063/comparing-two-models-from-the-fish-dataset</link>
      <description><![CDATA[数据
我正在使用 fish 数据集构建线性模型“nofollow noreferrer”&gt;此数据具有以下变量：

res_var：响应变量权重
exp_var1：解释变量Length
exp_var2：解释变量物种

库(dplyr)

鱼 &lt;- read_fst(“Fish.csv”)

鱼 &lt;- 鱼 %&gt;%
变异（长度=（长度1+长度2+长度3）/3）


模型 1
我试图了解以下两个模型的系数之间的差异。第一个是具有两个解释变量及其相互作用的模型：
lm(重量 ~ 长度 + 物种 + 物种:长度 + 0, 数据 = 鱼)

输出：
系数：
             长度种类鳊鱼种类鲈鱼种类梭子鱼种类蟑螂长度:种类鲈鱼长度:种类梭子鱼长度:种类蟑螂
             50.869 -1107.791 -640.845 -1560.734 -342.989 -13.979 -0.836 -28.994

模型 2
第二个模型仅包含一个解释变量及其与另一个解释变量的相互作用：
lm(重量 ~ 物种 + 物种:长度 + 0, 数据 = 鱼)

输出：
系数：
       种类鳊鱼种类鲈鱼种类梭子鱼种类蟑螂种类鳊鱼:长度种类鲈鱼:长度种类梭子鱼:长度种类蟑螂:长度
           -1107.79 -640.85 -1560.73 -342.99 50.87 36.89 50.03 21.88

为了理解上面的第二个模型，我首先过滤了每个 Species 的 fish 数据集：
鳊鱼&lt;-鱼%&gt;%
  过滤器（物种==“鳊鱼”）

鲈鱼 &lt;- 鱼 %&gt;%
  过滤器（物种==“鲈鱼”）

梭子鱼 &lt;- 鱼 %&gt;%
  过滤器（物种==“梭子鱼”）

蟑螂 &lt;- 鱼 %&gt;%
  过滤器（物种==“蟑螂”）

然后，我为上面的每个子集数据集构建了一个简单的线性模型：
mdl_bream &lt;- lm（重量 ~ 长度，数据 = 鳊鱼）

mdl_perch &lt;- lm(重量 ~ 长度, 数据 = 栖息处)

mdl_pike &lt;- lm(重量 ~ 长度, 数据 = pike)

mdl_roach &lt;- lm(重量 ~ 长度, 数据 = roach)

然后我查看了它们的系数。
系数(mdl_bream)

系数(mdl_perch)

系数(mdl_pike)

系数(mdl_roach)

输出：
（截距）长度
-1107.79052 50.86892
（截距）长度
 -640.84506 36.89006
（截距）长度
-1560.73352 50.03289
（截距）长度
 -342.98917 21.87535

这些对应于我提到的第二个模型：lm(Weight ~ Length + Species + Species:Length + 0, data = Fish)。
谁能帮我理解第一个模型的系数应该如何解释？]]></description>
      <guid>https://stats.stackexchange.com/questions/644063/comparing-two-models-from-the-fish-dataset</guid>
      <pubDate>Mon, 01 Apr 2024 23:10:20 GMT</pubDate>
    </item>
    <item>
      <title>计算线性混合效应模型中的置信区间</title>
      <link>https://stats.stackexchange.com/questions/643936/calculating-confidence-interval-in-linear-mixed-effect-model</link>
      <description><![CDATA[考虑一个简单的线性混合效应模型 (LMM)
$$Y_{ij}=b_{i}+X_{ij}\beta+\epsilon_{ij},$$
其中 $b_i\sim N(0,\sigma_b^2)$, $\epsilon_{ij}\sim N( 0,\sigma_e^2)$。
通常，可以估计 $\sigma_b^2,\sigma_e^2$，然后使用 Hessian 矩阵计算 $\beta$。
我在想另一种方式，我们可以先计算$\hat{b}_i=E(b_i|\{Y_{ij},X_{ij}\})$  和 $Y^{*}_{ij}=Y_{ij}-\hat{b}_i$。然后，我们基于 $\{X_{ij}\}$&lt; 之间的简单线性回归推断 $\beta$ /span&gt; 和 $\{Y^{*}_{ij}\}$？
我认为这个估计应该是一致的，因为它是基于 EM 算法的自然估计。但我不确定置信区间的有效性。]]></description>
      <guid>https://stats.stackexchange.com/questions/643936/calculating-confidence-interval-in-linear-mixed-effect-model</guid>
      <pubDate>Sun, 31 Mar 2024 01:29:21 GMT</pubDate>
    </item>
    <item>
      <title>具有非负基系数的高斯过程</title>
      <link>https://stats.stackexchange.com/questions/615386/gaussian-process-with-non-negative-basis-coefficients</link>
      <description><![CDATA[我有兴趣向高斯过程添加基函数。特别是，根据拉斯穆森的书的第2节，我有
$$g(x)=f(x) + h(x)^\top\beta,\qquad f(x)\sim\mathcal{GP}\left(0, k\left(x,x&#39;\right)\right).$$
在书中，$\beta\sim\mathcal N\left(b,B\right)$ 因此，一切都可以通过完成平方来很好地导出。
是否有一种稳健的方法可以通过对参数的非负约束来估计此规范？换句话说，使用 $\beta\ge 0$?]]></description>
      <guid>https://stats.stackexchange.com/questions/615386/gaussian-process-with-non-negative-basis-coefficients</guid>
      <pubDate>Wed, 10 May 2023 00:23:48 GMT</pubDate>
    </item>
    <item>
      <title>关于理想数据及其分布</title>
      <link>https://stats.stackexchange.com/questions/568797/about-ideal-data-and-its-distribution</link>
      <description><![CDATA[我只是在考虑理想数据集的属性 $X \in R^{n,d}$ 其中 n 是样本大小， d 代表特征。我认为（或者至少我从阅读课本中了解到）有两件事必须满足：

每个特征 ($d_{i}$) 必须彼此独立，以便特征空间是正定的，进而 $X^{T}X$ 的条件数也接近/等于 1。
必须有足够的样本 ($n$)，以防止数据受到维数灾难

这够了吗？
满足这些要求后，我们是否可以直接推断数据的分布？有什么经验法则吗？例如，如果满足这 2 个（或更多）步骤，则数据必须是高斯分布或其他分布。
我正在尝试填补数据的统计属性和代数属性之间的空白。因此，我对建立他们之间的关系有点困惑。有人可以解释一下我应该在哪里检查建立这种关系的材料吗？或者花点时间给我解释一下？]]></description>
      <guid>https://stats.stackexchange.com/questions/568797/about-ideal-data-and-its-distribution</guid>
      <pubDate>Wed, 23 Mar 2022 08:32:44 GMT</pubDate>
    </item>
    <item>
      <title>PRML - Bishop：加法顺序 - 方差计算</title>
      <link>https://stats.stackexchange.com/questions/567805/prml-bishop-order-of-addition-variance-calculation</link>
      <description><![CDATA[我的问题与第 3.2 节：偏差-方差分解相关。
我的疑问特定于第 150 - 151 页上的方差公式（3.47，如下）。
背景：
方差的一般公式为：
$\begin{align*} 方差 = E_{\mathcal D} [\{y(\mathbf x;\mathcal D) - E_{\mathcal D}[y (\mathbf x; \mathcal D)]\}^2] \end{align*} \tag{3.40}$
地点：

$y(\mathbf x;\mathcal D)$：基于数据集预测模型的输出$\mathcal D \in L \, (one\,of\,100\, datasets)$ $\implies $ 将有 100 个输出，1 个用于每 100 个模型。
$E_{\mathcal D}[y(\mathbf x; \mathcal D)]$：各个数据集的预测平均值$\mathcal D$ $\implies $ 将有 100 个平均值，每个模型 1 个。
$\begin{align*} \{y(\mathbf x;\mathcal D) - E_{\mathcal D} [y(\mathbf x; \mathcal D) ]\}^2 \end{align*}$ ：$\mathcal D$ 的均方差值 $\ 意味着 $ 同样是 100 平方误差。
$E_{\mathcal D} [.]:$所有数据集的平均平方误差$\mathcal D$，如上计算

请。注意：$E$ 代表期望（平均值，概率）。
有 $\mathbf {L=100}$ 个数据集，每个数据集包含 $\mathbf {N=25 } $ 数据点。
第 1 步 - 建模：- 基于对数据集 l 的 n 个数据点的分析，我们对预测公式进行建模$y^{(l)}(.)$ 输出值 - 对于输入 x，基于特定于该数据集的模型。
第 2 步 - 预测（计算跨模型预测的平均值）：对于任何点 x，取预测的平均值  $\bar y$，跨模型：
$\begin{align*} \bar y = \frac {1}{L} \sum_{l=1}^L y^{(l)}(x) \end {对齐*}$
然后，作者继续计算方差：
$\begin{align*} 方差 = \frac {1}{N} \sum_{n=1}^N \frac {1}{L} \sum_{ l=1}^L \{y^{(l)}(x_n) - \bar y(x_n)\}^2 \end{align*} \tag{ 3.47}$
问题：
尽管加法是可交换的，但我的疑问是在与求和顺序相关的概念层面上：
我们是否应该首先从 L（外循环/总和）中选择一个数据集l，然后找到所有数据点的方差 - 均方误差的平均值，n  $\in$ N - 该数据集的（内循环/总和）；即等式不应该是：
$\begin{align*} \frac {1}{L} \sum_{l=1}^L \frac {1}{N} \sum_{n= 1}^N \{y^{(l)}(x_n) - \bar y(x_n)\}^2 \end{align*}$
如果您能在这方面指导我，我将不胜感激。
上述书籍免费提供在 Microsoft 研究门户上。
附注：按照其他学习者的建议，将他的问题从数学转移到交叉验证。]]></description>
      <guid>https://stats.stackexchange.com/questions/567805/prml-bishop-order-of-addition-variance-calculation</guid>
      <pubDate>Tue, 15 Mar 2022 05:28:58 GMT</pubDate>
    </item>
    <item>
      <title>统计学中使用置换群吗？</title>
      <link>https://stats.stackexchange.com/questions/510687/are-permutation-groups-used-in-statistics</link>
      <description><![CDATA[有人告诉我，抽象代数中的概念与统计中的应用之间可能存在联系（也由本网站上的“代数统计”标签证实）。我不知道，所以我很好奇。特别是，我想了解如何使用排列群，因为我相信它们是抽象代数中的一个中心且有趣的概念。
我正在尝试在线研究该理论，但我看到的只是真正的研究文章或其他对我无益的东西的链接...我不是专业人士...如果你能给我一些例子，或者也许有关此类主题的易于理解的资源，我会很高兴。
我对统计和代数有本科的了解，所以尽量不要对数学家这个小蝌蚪使用统计词汇魔法。]]></description>
      <guid>https://stats.stackexchange.com/questions/510687/are-permutation-groups-used-in-statistics</guid>
      <pubDate>Mon, 22 Feb 2021 19:49:27 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分析：乘法模型和数据的季节性调整</title>
      <link>https://stats.stackexchange.com/questions/498670/time-series-analysis-multiplicative-model-and-seasonal-adjustment-of-data</link>
      <description><![CDATA[我正在尝试帮助统计方面的朋友，出现了这个涉及时间序列的问题，我不知道该怎么办。我尝试在不同的堆栈交换论坛中搜索答案，但我相信这可能很基础，因为我找不到答案。现在解决手头的问题：
&lt;小时/&gt;
过去三年中，企业的产品销售额（数十亿瑞典克朗，SEC）如下。
+------+------+--------+--------+--------+
|年份|问：我|问：II |问：III | Q.IV |
+------+------+--------+--------+--------+
| 2012 | 2.4 | 2.4 2.9 | 2.9 2.8 | 2.8 3.8 |
+------+------+--------+--------+--------+
| 2013 | 2.7 | 2.7 3.2 | 3.2 | 4.3 |
+------+------+--------+--------+--------+
| 2014年| 3.2 | 3.7 | 3.7 3.6 | 4.8 |
+------+------+--------+--------+--------+
a) 使用乘法模型对时间序列进行季节性调整。
&lt;小时/&gt;
我很抱歉桌子不好，这是我能做的最好的了。我们如何按季节调整数据？我知道这意味着我们尝试考虑不同季节的变化，但在这个例子中我们如何处理呢？我发现乘法模型是
\begin{align}
\hat{y} = T\cdot S\cdot C\cdot I
\end{对齐}
其中 $T$、$S$、 $C$ 和 $I$ 分别表示趋势、季节性、周期性和不规则分量。那么我该如何计算这些分量呢？ （我在维基百科上找到了这个）。]]></description>
      <guid>https://stats.stackexchange.com/questions/498670/time-series-analysis-multiplicative-model-and-seasonal-adjustment-of-data</guid>
      <pubDate>Mon, 30 Nov 2020 10:30:25 GMT</pubDate>
    </item>
    <item>
      <title>R 中的对比总和和标准误差</title>
      <link>https://stats.stackexchange.com/questions/453642/contr-sum-and-standard-error-in-r</link>
      <description><![CDATA[我想用 R 中的线性模型拟合一个具有 3 个可能级别的分类变量。我的目标是根据全局平均值检查每个级别的效果，因此我使用 contr.sum 作为对比。
当我查看系数时，我可以看到 R 仅返回其中的两个（我想这是因为在内部 3 个级别映射到 2 个虚拟变量）。 
但我有兴趣评估所有级别的效果。现在，我知道缺失水平的影响只是减去其他两个水平的总和，但是标准误差呢？有没有办法获得与缺失系数相关的标准误差？ IE。我怎样才能知道缺失水平和全局平均值之间的估计差异的误差？
附注数据不平衡。]]></description>
      <guid>https://stats.stackexchange.com/questions/453642/contr-sum-and-standard-error-in-r</guid>
      <pubDate>Wed, 11 Mar 2020 11:49:58 GMT</pubDate>
    </item>
    <item>
      <title>如何计算百分比方差？</title>
      <link>https://stats.stackexchange.com/questions/446464/how-do-you-calculate-variance-for-percentages</link>
      <description><![CDATA[我知道这似乎是一个简单的问题，但我正在尝试计算百分比方差（例如 15%、16%）。 
我知道 15% 相当于 0.15，但是当我尝试使用“15”与“0.15”格式计算方差时，我的方差相差 100 倍。我想说这是因为方差是平均值与每个样本之间差异的平方，但是计算百分比方差的正确方法是什么？
例如，假设我的数据集如下：16.34%、16.11%、16.02%、15.32%、18.13%、15.58%、18.17%、19.01%、17.03%、18.79%、17.97%、18.36%
如果我使用“16.34”作为格式，我会得到大约 1.58%，但如果我使用“0.1634”，我会得到 0.0158%。或者我需要做加法转换吗？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/446464/how-do-you-calculate-variance-for-percentages</guid>
      <pubDate>Sun, 26 Jan 2020 05:02:20 GMT</pubDate>
    </item>
    </channel>
</rss>