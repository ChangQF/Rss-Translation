<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 16 Jan 2025 18:21:14 GMT</lastBuildDate>
    <item>
      <title>如何检查分层连续数据水平分布的一致性</title>
      <link>https://stats.stackexchange.com/questions/660121/how-can-i-check-for-consistency-in-the-distribution-of-the-levels-of-stratified</link>
      <description><![CDATA[我在一些食品购买数据中有一个专有的权重特征，有人告诉我应该将其应用于热量含量以“纠正”他们对样本代表性的不确定性。我想分析特定篮子/家庭中出售的食品的类别组成，并拥有这样做所需的识别特征。然而，我担心，如果不应用这些权重，单个篮子/家庭的实际热量含量可能不具有代表性，因为显然，这些权重的必要性意味着他们认为他们需要重新称量所售产品的总量等，以符合整个人口的某种预期。
我的问题有一半是双重的，但我在调查这个问题时遇到了一个主要问题：
我如何评估食品类别的分层分类变量是否对权重的分布有显著影响（这些是数字和连续的，而类别有大约 20 个级别）。我相信我可以进行 Kruskal-Wallis 检验来检查是否存在总体差异（结果显示 p 值非常低），但我主要想检查与特定类别相关的权重是否与总体分布有显著差异，但我不确定如何做到这一点。
此外，我想知道我是否应该只应用权重并忘记这一点，但这样我就失去了谈论篮子具体热量含量的能力，这是一个缺点。
我觉得我可能把事情复杂化了，错过了一个明显的类比或解决这个问题的方法，如果能得到任何帮助，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660121/how-can-i-check-for-consistency-in-the-distribution-of-the-levels-of-stratified</guid>
      <pubDate>Thu, 16 Jan 2025 18:00:11 GMT</pubDate>
    </item>
    <item>
      <title>当其中一个分布比较简单时，使用蒙特卡洛估计 Kullback-Leibler 散度</title>
      <link>https://stats.stackexchange.com/questions/660116/estimate-kullback-leibler-divergence-with-monte-carlo-when-one-of-the-distributi</link>
      <description><![CDATA[我感兴趣的是估算$D_\mathrm{KL}(q \parallel p) = \int q(x) \log \frac{q(x)}{p(x)}\,\mathrm dx$，其中$p$是多元高斯分布，$q$是通过神经网络参数化的隐式分布，例如GAN中的生成器网络。背景：分布是隐式的，这意味着虽然我们可以从分布中抽样，但其密度是难以处理的。
一种直接的估计方法是拟合一个 Logistic 分类器 $f(x)$，将 $q$ 的样本与 $p$ 的样本区分开来，然后通过蒙特卡洛近似 KL 为：$\frac{1}{S}\sum_{j=1}^S \log\frac{\sigma(f(x_j))}{1-\sigma(f(x_j))}$，又名密度比技巧。我们用$\sigma(\cdot)$表示 S 型函数。
这种方法的一个明显缺点，也是我想问这个问题的原因，是我们没有利用$p(x)$的密度是已知且简单的事实，参见这篇文章。我们能做些什么来利用$p(x)$的高斯分布来改进估计吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660116/estimate-kullback-leibler-divergence-with-monte-carlo-when-one-of-the-distributi</guid>
      <pubDate>Thu, 16 Jan 2025 16:12:32 GMT</pubDate>
    </item>
    <item>
      <title>证明 LDA 目标函数 $w^T \Sigma_b w / w^T \Sigma_w w$ 最大化平方配对马哈拉诺比斯距离</title>
      <link>https://stats.stackexchange.com/questions/660113/prove-that-lda-objective-wt-sigma-b-w-wt-sigma-w-w-maximizes-squared-pai</link>
      <description><![CDATA[我们有一个随机变量$x \in \mathbb{R}^n$，它有$k$个类，类均值为$\bar{x}_i$。 线性判别分析找到$w$成分，使类间方差与类内方差的比率最大化，目标如下：
$$\frac{w^T \Sigma_b w}{w^T \Sigma_w w}$$
其中$\Sigma_b = \sum_{i=1}^k \bar{x}_i \bar{x}_i^T$是类间协方差，$\Sigma_w$是类内协方差。
我们可以预测$x$ 放入 $m$ 个第一个 LDA 分量中，得到 $z = W^T x$，其中 $W$ 的列是 LDA 的分量，并且 $z \in \mathbb{R}^m$。
我想表明 LDA 还最大化了 $z$ 空间中类均值之间的成对平方马哈拉诺比斯距离，由以下公式给出：
$$\sum_{i,j} (\bar{z}_i - \bar{z}_j)^T \Sigma_{z,w}^{-1} (\bar{z}_i - \bar{z}_j)$$
其中 $\bar{z}_i$ 是类 $i$ 中变量 $z$ 的平均值，而 $\Sigma_{z,w}$ 是变量 $z$ 的类内协方差。]]></description>
      <guid>https://stats.stackexchange.com/questions/660113/prove-that-lda-objective-wt-sigma-b-w-wt-sigma-w-w-maximizes-squared-pai</guid>
      <pubDate>Thu, 16 Jan 2025 15:25:24 GMT</pubDate>
    </item>
    <item>
      <title>如果需要真实参数的值来确定统计数据是否无偏，那么无偏估计量的意义何在？</title>
      <link>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</link>
      <description><![CDATA[我对无偏估计量的定义是：“如果用于估计参数的统计数据的抽样分布的平均值等于被估计参数的值，则该统计数据是无偏估计量。”
我知道如何确定统计数据是否是无偏估计量，因为我能够基于此解决应用题，但我不明白我们为什么要使用无偏估计量。我的笔记说，您需要使用无偏估计量，以便您的估计更准确。这对我来说很有意义，但为了确定统计数据是否是无偏估计量，您需要知道参数的值，以便将其与抽样分布的平均值进行比较，看看它们是否相等。如果使用无偏估计量来估计参数的值，如果我们已经知道参数的值，使用它有什么意义呢？
我一直在为此绞尽脑汁，但无济于事，如能得到任何帮助我将不胜感激，谢谢。
（我不擅长措辞，如果我听起来很重复或没有意义，请原谅）]]></description>
      <guid>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</guid>
      <pubDate>Thu, 16 Jan 2025 15:06:38 GMT</pubDate>
    </item>
    <item>
      <title>概率分布的均匀性</title>
      <link>https://stats.stackexchange.com/questions/660107/uniformity-of-probability-distribution</link>
      <description><![CDATA[我有一个关于从一组均匀分布的样本中移除样本的问题。
设$E = \{ X_{ij} \}, 1 \leq i &lt; j \leq n$为一组随机变量，其中每个$X_{ij}$在$\sim [0,1]$中是独立同分布的。显然，$|E| = \binom{n}{2}$。这些是完整加权图的权重，其中 $X_{ij}$ 确实是节点 $i$ 和节点 $j$ 之间的权重。
现在，我递归重复以下步骤（例如 $n/2$ 次）：

选择一个顶点 $z \in \{1,n\}$ 来验证以下内容：
存在另外两个顶点，$p, q \in [0,1], g \neq m$ s.t.
\begin{align}
X_{zp} = \arg\min\{ X_{uv} : u=p \text{ 或 } v=p \} \text{ 和 } X_{zq} = \arg\max\{ X_{uv} : u=q \text{ 或 } v=q \}
\end{align
存在另外两个顶点 $p$ 和 $q$ s.t. $z$ 和 $p$ 之间的关联边是 $p$ 所有关联边中的最小值，而 $z$ 和 $q$ 之间的关联边是 $q$ 所有关联边中的最大值，反之亦然。
这里有一个表示


如果是这种情况，则表示 $R = \{ X_{uv} \text{ s.t. } z=u \text{ or } z=v \}$.

设置 $E = E \setminus R$, $n = n-1$.

在每一步，我都会选择一个顶点 $z$ 来验证上述属性。然后我将其连同所有边一起删除，留下一个较小的完全图。
如果根据上述规则从中选取子集并删除它们，$E$ 是否仍是均匀分布的？]]></description>
      <guid>https://stats.stackexchange.com/questions/660107/uniformity-of-probability-distribution</guid>
      <pubDate>Thu, 16 Jan 2025 14:58:53 GMT</pubDate>
    </item>
    <item>
      <title>如果单比例荟萃分析中受异常值影响的数据经过变换后仍然不服从正态分布，该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/660104/what-should-be-done-if-outlier-influenced-data-in-a-single-proportion-meta-analy</link>
      <description><![CDATA[如果单比例荟萃分析中的数据受到异常值的影响，经过变换后仍然不服从正态分布，该怎么办？
我正在进行单比例荟萃分析，在计算合并比例之前，我需要对数据进行变换以达到正态性。我在 R 4.3.3 中尝试了四种不同的变换，即 log、logit、反正弦和 Freeman-Tukey 双反正弦，但数据仍然不服从正态分布。后来我意识到这是由于异常值的影响。我现在考虑的方法是去除这个异常值。这种方法可以接受吗？如果不可以，我可以使用哪些替代方法来处理这个异常值以继续进行荟萃分析？
异常值的比例为 0.8%。如果将其去除，荟萃分析中的合并比例将约为 60%。出版偏见检验显示 p 值 &gt; 0.05，漏斗图呈现对称性。]]></description>
      <guid>https://stats.stackexchange.com/questions/660104/what-should-be-done-if-outlier-influenced-data-in-a-single-proportion-meta-analy</guid>
      <pubDate>Thu, 16 Jan 2025 14:42:27 GMT</pubDate>
    </item>
    <item>
      <title>关于Delta方法的问题</title>
      <link>https://stats.stackexchange.com/questions/660099/question-about-delta-method</link>
      <description><![CDATA[令 $\hat{f}_n$ 为核密度估计量，$f$ 为真实密度，$h$ 为带宽。我在一篇论文中发现，在温和条件下，$\sqrt{nh}(\hat{f}_n-f)$ 在某些函数空间中会收敛到 0。因此，我们可以为 $z\in\mathbb{R}$ 定义一个函数 $$\Phi_z(f)=f(z)$$，然后使用函数 delta 方法。由于 $\Phi_z$ 在 $g$ 方向上的 hadamard 导数就是 $g(z)$，因此使用 delta 方法，我们将得到 $$\sqrt{nh}(\hat{f}_n(z)-f(z))\rightarrow 0$$。但这是不可能的，因为我们知道核密度估计量具有逐点渐近正态性。如果有人能指出我的错误，我将非常感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660099/question-about-delta-method</guid>
      <pubDate>Thu, 16 Jan 2025 13:24:50 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中计算多重插补后合并结果的部分 Eta 平方</title>
      <link>https://stats.stackexchange.com/questions/660097/calculating-partial-eta-squared-for-pooled-results-after-multiple-imputation-in</link>
      <description><![CDATA[我已经为这个问题苦苦挣扎了一段时间，所以任何帮助我都非常感谢！
我正在尝试使用 R 中的 mice 包，使用多重插补后的汇总数据计算 ANCOVA 模型的效应大小（部分 eta 平方或 $\eta^{2}_p$）。ANCOVA 应用于认知测试的变化分数（基线和 12 周随访之间的差异）。这是模型：
results_test &lt;- with(imputed_data, lm((test_12 - test_base) ~ test_base + group + yoe))
pooled_results_test &lt;- pool(results_test)

从汇总结果中，我可以轻松提取组效应的 p 值、调整后的平均差异和置信区间。但是，我想计算一个效应大小的度量，例如 $\eta^{2}_p$。
我的困境
$\eta^{2}_p$ 的计算方法如下：
eta_squared &lt;- ss_effect / (ss_effect + ss_residual)

此处 $SS$ 表示平方和。
现在，如果我针对每个插补数据集分别计算并取插补平均值，我怀疑这可能存在缺陷，因为它是一个比率，而不是线性统计数据。对比率求平均值可能会扭曲真实的汇总效应大小。因此，我没有直接对 $\eta^{2}_p$ 进行平均，而是尝试将所有插补的平方和相加，然后计算合并的 $\eta^{2}_p$，如下所示：
# 计算合并的部分 eta 平方，方法是先对插补的平方和相加，最后在此基础上计算部分 eta 平方：

total_ss_effect &lt;- sum(sapply(1:imputed_data$m, function(i) {
anova(lm((test_12 - test_base) ~ test_base + group + yoe, 
data = complete(imputed_data, i)))[&quot;group&quot;, &quot;Sum Sq&quot;]
}))
total_ss_residual &lt;- sum(sapply(1:imputed_data$m, function(i) {
anova(lm((test_12 - test_base) ~ test_base + group + yoe, 
data = complete(imputed_data, i)))[&quot;Residuals&quot;, &quot;Sum Sq&quot;]
}))
eta_squared_pooled &lt;- total_ss_effect / (total_ss_effect + total_ss_residual)
cat(&quot;\nPooled Partial Eta Squared:&quot;, round(eta_squared_pooled, 3), &quot;\n&quot;)

此方法将组效应和插补残差的 $SS$ 相加，并从中计算 $\eta^{2}_p$总计。这似乎更合适，因为它考虑了插补之间的差异性。
我的问题：

这是一种合理的方法吗？将插补的平方和相加，然后计算部分 eta 平方，这在统计上有意义吗？

在 R 中是否有计算合并部分 eta 平方的标准方法或包？

在合并分析中不报告效应大小是否很常见？我注意到很多文章都没有包括它们，这似乎令人惊讶。


再次感谢你们提供的任何意见。我真的很感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660097/calculating-partial-eta-squared-for-pooled-results-after-multiple-imputation-in</guid>
      <pubDate>Thu, 16 Jan 2025 12:31:47 GMT</pubDate>
    </item>
    <item>
      <title>如何测试具有少量箱体的直方图是否符合正态分布？</title>
      <link>https://stats.stackexchange.com/questions/660096/how-do-i-test-if-a-histogram-with-few-bins-is-obtained-from-a-normal-distributio</link>
      <description><![CDATA[假设我有一个直方图，显示已成功完成 $0, 1, 2, ..., n$ 门课程的学生人数。学生人数较多，但课程数量较少（例如 6 门）。我的零假设 $H_{0}$ 是学生的“能力”是一个具有正态分布的实数（均值和方差未知），学生完成的课程数量为 $\lfloor \text{aptitude} \rfloor$。如何检验备择假设 $H_{1}$“能力分布不正常”？我知道 Jarque-Bera、Lilliefors 或 Anderson-Darling 等正态性检验，但据我所知，它们假设离散化细化程度要高得多，即有更多的箱体，并且它们不包含任何限制假设（即，观测量的最大值和最小值是有限的，尽管底层随机变量不是）。我也在 Cross Validated 上看到了这个问题，其中一个答案建议使用卡方拟合优度检验，但据我所知，您需要指定正态分布的均值和方差才能使用卡方拟合优度检验，而我两者都没有。
附言。由于我发现在教育背景下提出这个问题会引发太多与统计本身无关的问题，因此假设我们讨论的是游戏中给予玩家的随机点数。玩家最多可以购买 $n$ 件物品，每件物品花费 $X$ 点，并且总是会购买尽可能多的物品。通过查看玩家购买的物品数量的分布，我们试图确定给予玩家的点数是否符合正态分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/660096/how-do-i-test-if-a-histogram-with-few-bins-is-obtained-from-a-normal-distributio</guid>
      <pubDate>Thu, 16 Jan 2025 12:31:45 GMT</pubDate>
    </item>
    <item>
      <title>statsmodels ARIMA 结果中的 p 值和临界值存在冲突</title>
      <link>https://stats.stackexchange.com/questions/660086/conflicting-p-value-and-critical-values-in-statsmodels-arima-result</link>
      <description><![CDATA[
如果我理解正确，如果 Z 落在临界值区域之外，则 p 值应该 &lt;0.05。但是，对于我的 ar.L2 特征，z = -0.596，[0.025, 0.075] 区域是 [-0.536, 0.286]。因为 -0.596 &lt; -0.536，所以 z 落在左尾内。但为什么 p 值是 0.552？我读错结果了吗？在 statsmodels 网站上找不到任何文档。]]></description>
      <guid>https://stats.stackexchange.com/questions/660086/conflicting-p-value-and-critical-values-in-statsmodels-arima-result</guid>
      <pubDate>Thu, 16 Jan 2025 09:00:50 GMT</pubDate>
    </item>
    <item>
      <title>排除构成数据结构一部分的相关变量，转而采用生物学上更有意义的变量</title>
      <link>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</link>
      <description><![CDATA[我正在处理从卫星图像 (Sentinel) 捕获的植被覆盖率数据集。数据以季度/季节为间隔捕获。使用 GAM，我正在模拟植被覆盖率如何响应环境变量，降雨量是感兴趣的关键预测变量。但是，降雨量与季度/季节具有合理的相关性，相关系数为 r = -0.73。通常，当两个变量的相关性大于 0.7 时，我会将其中一个排除在分析之外。所以，我的问题是，我可以从分析中排除季度/季节吗？
季度/季节是数据集设计/结构的一部分，通常我的理解是应该在模型中考虑数据结构。但是，从生物学角度来看，连续降雨变量是一个更有趣、更有意义的变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</guid>
      <pubDate>Thu, 16 Jan 2025 03:22:55 GMT</pubDate>
    </item>
    <item>
      <title>在线性误差传播过程中如何选择正确的公式？</title>
      <link>https://stats.stackexchange.com/questions/660052/how-to-choose-the-correct-formula-during-linear-error-propagation</link>
      <description><![CDATA[我正在使用线性误差传播的标准公式（协方差为零）来估计作为平均实验可观测量函数计算的变量中的不确定性（使用标准差作为不确定性估计），但遇到了障碍。例如，考虑一个变量$k$，它可以计算为
$$k = 1-\frac{G\times I}{P} \tag{1}$$
作为可观测量$G$、$I$和$P$的函数。
但是，上述内容可以改写为
$$k = \frac{P-G\times I}{P} \tag{2}$$
但是，与方程 (1) 相关的传播不确定性似乎与方程 (2) 相关的不确定性不同，因为 $P$ 的值在方程 (2) 中出现了两次，而与方程 (1) 中的常数 (&quot;$1$&quot;) 相关的不确定性为零。
我遗漏了什么？在这种情况下，使用错误传播的正确方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660052/how-to-choose-the-correct-formula-during-linear-error-propagation</guid>
      <pubDate>Wed, 15 Jan 2025 09:42:21 GMT</pubDate>
    </item>
    <item>
      <title>重复测量设计中评估基因-代谢物关系的指导</title>
      <link>https://stats.stackexchange.com/questions/659981/guidance-on-evaluating-gene-metabolite-relationships-in-repeated-measures-design</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659981/guidance-on-evaluating-gene-metabolite-relationships-in-repeated-measures-design</guid>
      <pubDate>Mon, 13 Jan 2025 20:11:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 Blackbox 方式查找依赖关系</title>
      <link>https://stats.stackexchange.com/questions/659978/finding-dependencies-in-blackbox-way</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659978/finding-dependencies-in-blackbox-way</guid>
      <pubDate>Mon, 13 Jan 2025 19:28:48 GMT</pubDate>
    </item>
    <item>
      <title>解释线性回归中的数据集不平衡问题</title>
      <link>https://stats.stackexchange.com/questions/659943/accounting-for-dataset-imbalance-in-linear-regression</link>
      <description><![CDATA[我有一组特征 $X$ 和一个因变量 $Y$，我想使用线性回归进行预测。目前，我正在使用普通最小二乘法计算 $\hat{\beta}$ 矩阵。但是，我注意到我的因变量 $Y$ 大约有 30% 的时间设置为零。在其他情况下，它可以取负值或正值。$Y$ 取的值通常在区间 $[-5, 5]$ 内。此外，$Y$ 的值大致呈正态分布，均值为零。
在我正在研究的问题中，当预测值的绝对值超过某个阈值时，我会做出决定。此外，
“错误”的代价比不采取行动的代价更大。换句话说，我希望能够准确预测 $|Y| &gt; 2$ 的情况，而我不太关心 $|Y| \leq 2$ 的情况。
这引出了以下问题：

在解决我的 OLS 解决方案时，我是否应该排除 $|Y| \leq 2$ 的情况？这是某人的建议。但是，我认为答案是否定的（不应该这样做），因为这会使我的结果产生偏差，而且我无法保证真实数据集中的 $|Y| \leq 2$。

还有其他方法可以解释手头的问题吗（尤其是因为大约三分之一的数据中 $Y = 0$）？


谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659943/accounting-for-dataset-imbalance-in-linear-regression</guid>
      <pubDate>Mon, 13 Jan 2025 05:49:06 GMT</pubDate>
    </item>
    </channel>
</rss>