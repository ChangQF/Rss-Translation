<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 08 Aug 2024 09:16:23 GMT</lastBuildDate>
    <item>
      <title>根据删失数据估计对数正态分布的参数以进行模拟</title>
      <link>https://stats.stackexchange.com/questions/652482/estimate-parameters-of-a-log-normal-distribution-from-censored-data-for-simulati</link>
      <description><![CDATA[我有以下模型
$$Y=X_1/c_1+X_2*X_2/c_2+X_3/c_3+X_3*X_4/c_4.$$
我知道 $X_1$ 和 $X_3$ 遵循不同但已知的正态分布，$c_1\dots,c_4$ 是已知常数，而 $X_2,X_4$ 遵循不同的未知对数正态分布。我想进行蒙特卡罗模拟来估计 $Y$ 的分位数。
我有一些数据可以估计 $X_2,X_4$ 的分布，但这些数据是左删失和右删失的。它可能看起来像这样：
$$\begin{matrix} &lt;0.2 &amp; 0.1 &amp; &gt;4 &amp; 0.7 &amp; 0.9 &amp; &lt;0.3 &amp;&gt;0.7 &amp;0.3 &amp;&lt;0.1 \end{matrix}$$
在较好的情况下，我有 60 个数据点，其中 10 个是删失的。在最坏的情况下，我有 21 个数据点，其中 9 个是删失的。
使用删失数据，我可以估计对数正态分布 $X_2,X_4$ 的参数。我使用 R 包 fitdistrplus 执行此操作。对于 $X_3$，我得到例如：
$$\begin{matrix} &amp; \text{estimate} &amp; \text{Std. Error}\\ \text{meanlog} &amp; -1.5&amp; 0.2\\ \text{sdlog} &amp; 1.8 &amp; 0.19 \end{matrix}$$
我想将估计的不确定性纳入我的模型中。有没有自然的方法可以做到这一点？我的想法是根据错误改变对数正态分布的参数。因此，我可以从 $\mathcal{N}(-1.8,0.19^2)$ 中选择不同的 $\text{meanlog}$，用于模拟形式 $\mathcal{N}(-1.5,0.2^2)$ 和 $\text{sdlog}$。但此处选择正态分布似乎有些武断。如果数据没有被审查，则 t 分布和 $\chi^2$ 分布似乎很自然地被选择（如果我是对的？）但这如何处理被审查的数据？我是否应该忽略计算误差并以任何方式使用它们？但自由度是多少？或者这些数据是否足以使用正态近似？或者还有其他方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652482/estimate-parameters-of-a-log-normal-distribution-from-censored-data-for-simulati</guid>
      <pubDate>Thu, 08 Aug 2024 08:53:39 GMT</pubDate>
    </item>
    <item>
      <title>如果不考虑偏度，峰度的定义是不是不太清楚？</title>
      <link>https://stats.stackexchange.com/questions/652480/isnt-kurtosis-poorly-defined-if-it-doesnt-take-into-account-skewness</link>
      <description><![CDATA[提前致歉，我不是统计学家，所以这个问题可能比较幼稚。我的理解如下：
均值是第一个原始矩。
方差是第二个中心矩，即减去第一个原始矩（均值）后得到的。第二个原始矩可能在特定情况下有用，但实际上并没有描述分布或数据集形状的某个方面（不考虑数据集的平均值）。
类似地，偏度是第三个标准化矩，即减去平均值并除以标准差（方差的根）后得到的。
但峰度也是一个标准化矩，即它不考虑偏度。
这对于峰度的解释来说不是有问题吗？如果不是，为什么不是？如果是，那么有没有办法“校正”峰度以将偏度考虑在内？
（我说得对吗？没有一种简单的方法可以“去偏度”，即没有类似于集中化和标准化的简单转换，导致平均值为 0，标准差/方差为 1，偏度为 0？）]]></description>
      <guid>https://stats.stackexchange.com/questions/652480/isnt-kurtosis-poorly-defined-if-it-doesnt-take-into-account-skewness</guid>
      <pubDate>Thu, 08 Aug 2024 08:31:48 GMT</pubDate>
    </item>
    <item>
      <title>使用类似模型生成的标签训练模型：过度拟合？</title>
      <link>https://stats.stackexchange.com/questions/652479/train-model-with-labels-generated-by-similar-model-overfit</link>
      <description><![CDATA[我训练模型来预测航空影像中的一些线性特征。由于参考数据只是线条，我制作了一个简单的缓冲区，以便标签与目标特征的宽度非常接近。它们的宽度从 3 到 15 米不等，因此我将中位数宽度设置为 9 米。UNet 模型很好地预测了它们。事实上，预测比标签更接近现实/图像，因为预测更接近目标特征的边缘，而不是简单的 9 米宽度。但是，准确度指标很差（F1 0.6），因为标签和预测之间的 IoU 很低。所以，我想到我可以将此模型的预测用作改进的训练和测试标签。然后，我将使用改进的训练标签训练另一个模型，并针对改进的测试标签对其进行测试。结果在视觉上相似，但 F1 上升到 0.9。这是过度拟合吗？测试标签显然未用于训练任一模型。
我尝试使用 eCognition 分割整个图像并提取我的目标特征，但这不可行。我的目标特征分割通常非常不准确。]]></description>
      <guid>https://stats.stackexchange.com/questions/652479/train-model-with-labels-generated-by-similar-model-overfit</guid>
      <pubDate>Thu, 08 Aug 2024 07:58:07 GMT</pubDate>
    </item>
    <item>
      <title>对于小样本量、不明确（非正态）分布的适当显着性检验</title>
      <link>https://stats.stackexchange.com/questions/652478/appropriate-significance-test-for-small-sample-size-unclear-non-normal-distri</link>
      <description><![CDATA[给定数据：
30 个数据点，以可用性分数的形式呈现（系统可用性量表）
数据中有 2 个组（组 1：17，组 2：13，独立，大小不等）
目标：
看看这两组的可用性分数之间是否存在统计上的显著差异
问题：
这里研究比较两个独立组的统计显著性的适当方法是什么？
初步想法（基于作为非统计学家的一些研究）：
有些测试对底层数据分布做出假设，有些则不做。通过直方图和箱线图可视化数据，我的第一印象是它不是正态分布的。因此，例如 Mann-Whitney-U 检验可能是一种选择。此外，使用 Shapiro-Wilk 等方法进行正态性测试被认为是无用的，因为其拒绝正态性假设的能力很弱，尤其是在样本量较小的情况下。不过，如果这样的测试拒绝了假设（即：它是正态分布），我们确实可以将其视为非正态性的迹象。
有人可以确认或拒绝我得出的结论吗？根据提供的信息，是否有更好的替代方案？
我正在寻找处理此类数据的最佳实践，并希望听取您的意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/652478/appropriate-significance-test-for-small-sample-size-unclear-non-normal-distri</guid>
      <pubDate>Thu, 08 Aug 2024 07:17:57 GMT</pubDate>
    </item>
    <item>
      <title>SKLearn 如何得出 LASSO 系数？</title>
      <link>https://stats.stackexchange.com/questions/652475/how-does-sklearn-derive-lasso-coefficients</link>
      <description><![CDATA[我正在尝试使用 SciPy 优化来推导 SKLearn 的 LASSO 系数，只是为了了解 SKLearn 的内部工作原理。但是，我无法使参数匹配。
import numpy as np
from sklearn.linear_model import Lasso

from sklearn.datasets import load_iris
iris = load_iris()
X, y = iris.data[:,0:3], iris.data[:,3]

lasso_reg = Lasso(alpha=1)
lasso_reg.fit(X, y)

得出 lasso_reg.coef_ = array([ 0. , -0. , 0.09270611]) 和 lasso_reg.intercept_ = 0.8509437849691903
当我尝试自己推导这些时，我试图最小化：
def lasso_min(params):
return sum((y - params[0] - np.matmul(X, params[1:]))**2) + lam * sum([abs(val) for val in params[1:]])

使用：
lam = 1
from scipy import optimize
sol = optimize.minimize(lasso_min, [0,0,0,0])

这给了我 sol.x = array([-0.29598937, -0.14396059, 0.16120468, 0.49060031])
即使我增加 lam 的值，我也无法将系数正则化为 0。有人能解释一下我在这里做错了什么吗？我认为这是我的代码中一些非常基本的东西，而不是缺乏更深层次的理解？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652475/how-does-sklearn-derive-lasso-coefficients</guid>
      <pubDate>Thu, 08 Aug 2024 03:29:09 GMT</pubDate>
    </item>
    <item>
      <title>生成似然估计误差线的有效方法</title>
      <link>https://stats.stackexchange.com/questions/652473/efficient-methods-for-generating-error-bars-on-likelihood-estimates</link>
      <description><![CDATA[假设我有一些似然函数，我已经将其最大化以获得最有可能生成一些实验数据的参数。我现在想要这些数量的误差线。我有什么选择？
我能想到的一个选择是查看最大似然附近的 Hessian 矩阵，给出一个协方差矩阵，其中我假设似然分布是高斯分布。这可能没问题，但似乎假设太多了。
另一个选择是使用 MCMC 方法对似然函数进行采样，然后分析样本以获得置信区间。这相当严格，但当似然函数的评估成本很高时，计算成本非常高。
在我的似然函数评估成本很高的情况下，还有哪些其他选项可以提供值得信赖的误差线/置信区间？]]></description>
      <guid>https://stats.stackexchange.com/questions/652473/efficient-methods-for-generating-error-bars-on-likelihood-estimates</guid>
      <pubDate>Thu, 08 Aug 2024 01:52:03 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的目标规范化恶化了性能指标</title>
      <link>https://stats.stackexchange.com/questions/652472/target-normalization-on-neural-network-worsens-performance-metrics</link>
      <description><![CDATA[我正在实现一个基于傅里叶神经算子的神经网络来预测几个流体流动变量。这是我的设置：

输入：4 个单值和 1 个 2D 输入（全部连续）
输出：6 个 2D 输出（全部连续）
架构：将 4 个单值参数嵌入 2D 输入，然后是几层傅里叶运算符
损失函数：均方误差 (MSE)
验证：5 倍交叉验证
其他指标：R 平方 (R2)、平均绝对误差 (MAE) 和均方根误差 (RMSE)
输入训练数据是 z 分数标准化的

我观察到以下情况：

对目标进行标准化会显著降低性能指标。
对输入进行标准化似乎不会影响模型的性能。
当我不规范目标时，损失和其他指标似乎有所改善。但是，将目标与模型输出绘制在一起
并没有显示出明显的改善。

问题：

这种行为正常吗？
我以为 R2 是尺度不变的，但当我规范目标时，它也会变得更糟。为什么会发生这种情况？
在这种情况下，我应该使用哪些指标来可靠地衡量模型的性能？

这是训练过程中损失函数和其他指标的样子，粉红线是经过归一化的目标。

这是使用标准化目标时目标与输出的图。

这是在训练中使用非标准化目标的相同图。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652472/target-normalization-on-neural-network-worsens-performance-metrics</guid>
      <pubDate>Thu, 08 Aug 2024 00:32:09 GMT</pubDate>
    </item>
    <item>
      <title>为什么 $\xi X$ 和 $\xi |X|$ 具有相同的分布？</title>
      <link>https://stats.stackexchange.com/questions/652471/why-xi-x-and-xi-x-have-the-same-distribution</link>
      <description><![CDATA[让 $\xi$ 成为 Rademacher 随机变量或对称伯努利随机变量。
让 $X$ 成为另一个独立于 $\xi$ 的随机变量。
我想证明 $\xi X$ 和 $\xi |X|$ 具有相同的分布。
我的第一个尝试是证明它们具有相同的分布函数。事实上，让 $a \geq 0$，
\begin{align}
P(\xi|X| \leq a) &amp;= \frac{1}{2} P(|X| \leq a) + \frac{1}{2}P(|X| \geq - a)\\\\
&amp;= \frac{1}{2}P(|X| \leq a) + \frac{1}{2}\\\\
&amp;= \frac{1}{2}(P(X\leq a) - 1 + P(X \geq -a)) + \frac{1}{2}\\\\
&amp;= \frac{1}{2}P(X \leq a) + \frac{1}{2}P(X \geq - a)\\\\
&amp;= P(\xi X \leq a)
\end{align&gt;
我相信这证明了当 $a$ 为正时的情况。但是，当我尝试 $a &lt; 0$ 时，这种方法没有任何效果。]]></description>
      <guid>https://stats.stackexchange.com/questions/652471/why-xi-x-and-xi-x-have-the-same-distribution</guid>
      <pubDate>Thu, 08 Aug 2024 00:00:31 GMT</pubDate>
    </item>
    <item>
      <title>我需要对 2 Ivs 和 2 DV 进行什么分析？</title>
      <link>https://stats.stackexchange.com/questions/652456/what-analysis-do-i-need-for-2-ivs-and-2-dvs</link>
      <description><![CDATA[我认为我需要 MANOVA，但我可能需要 ANCOVA，然后仅在实验组内进行 ANOVA。
我认为它是干预组内的 2x2 因子独立测量 ANOVA。我没有任何等价的句子可以用于 MANOVA，因为我之前从未写过 MANOVA
我有 2 个 IV：
IV1 有 2 个级别：对照组和干预组
IV2 是干预组中的个性特征，因为这是一个次要假设
我有 2 个相关的 DV：
DV1 是儿童自我评价的幸福感得分随时间的变化（1 个分数在实验开始时，另一个分数在实验结束时）
DV2 儿童父母评价的幸福感得分随时间的变化（1 个分数在实验开始时，另一个分数在实验结束时）
我可以将幸福感得分分为各种不同的子分数（希望、幸福、乐观、价值）
我的假设是：
H0- 实验组和对照组之间的幸福感改善随时间没有显著差异
H1- 与对照组相比，干预组的幸福感得分将显着改善
H2- 干预组的具体幸福感得分显着改善希望、幸福、乐观和价值感
H3- 干预组的改善程度在具有特定人格特质的人中会更高。
我很高兴被告知我完全错了，因为我的论文的分析部分总是花费最长的时间来写，我感到完全迷失了。提前谢谢 :)

Chat GPT 说：
根据您的假设，此分析策略涉及使用 MANOVA、ANCOVA、ANOVA 和回归分析的组合来彻底评估您的干预效果和关于自然相关性的次要假设。
重新审视假设：
H1：使用 MANOVA 评估总体差异并跟进特定 DV 变化的 ANOVA。
H2：使用因子 ANOVA 评估子量表差异。
H3：使用干预组内的方差分析或回归分析自然相关性的影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/652456/what-analysis-do-i-need-for-2-ivs-and-2-dvs</guid>
      <pubDate>Wed, 07 Aug 2024 19:41:25 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用混合逻辑分析 DCE</title>
      <link>https://stats.stackexchange.com/questions/652448/analysing-dce-with-mixed-logit-in-r</link>
      <description><![CDATA[我正在通过调查进行离散选择实验 (DCE)。我的研究基于具有不同属性级别/类型的护肤产品。总共有四个属性（每个属性有 3 个级别/类型），我生成了 81 种不同的产品。我将它们分成 3 个不同的调查（每个调查有 9 个选择集，每个选择集有 3 种产品可供选择，受访者只能选择其中一种）。此外，他们还回答了有关他们的人口统计和对某些品牌（我在产品设计中使用的品牌）的熟悉程度的问题。这些是协变量（年龄组、收入组、居住地区、对 6 个不同品牌的使用熟悉程度）。
我以长格式扩展了数据（总共 2430 行，因为每个受访者考虑了超过 27 种具有不同属性级别的产品，总共有 90 名受访者）。我使用这段代码放入 mlogit 模型中：
expanded_data &lt;- expand_data %&gt;%
mutate(
Age = as.factor(Age),
Income = as.factor(Income),
Region = as.factor(Region),
CeraVe = as.factor(CeraVe),
Maybelline = as.factor(Maybelline),
LOreal = as.factor(LOreal),
LaMer = as.factor(LaMer),
Chanel = as.factor(Chanel),
Dior = as.factor(Dior),
Price = as.factor(Price),
Packaging = as.factor(Packaging),
Quality = as.factor(Quality),
Brand = as.factor(Brand),
ProductChoiceBinary = as.logical(ProductChoiceBinary)
)

mlogit_data &lt;- mlogit.data(expanded_data, 
choice = &quot;ProductChoiceBinary&quot;, 
shape = &quot;long&quot;, 
id.var = &quot;UniqueChoiceID&quot;, 
alt.var = &quot;ProductID&quot;)

complex_model &lt;- mlogit(ProductChoiceBinary ~ 价格 + 包装 + 质量 + 品牌 | 年龄 + 收入 + 地区 + CeraVe + Maybelline + LOreal + LaMer + Chanel + Dior, 
data = mlogit_data, 
random = ~ 价格 + 包装 + 质量 + 品牌 | UniqueChoiceID)

但是这个错误一直出现：“solve.default(H, g[!fixed]) 中的错误：Lapack 例程 dgesv：系统完全是奇异的：U[1,1] = 0”
我已经检查过没有多重共线性，这可能是数据结构的问题。但是，我的时间不多了，我真的需要结果。有人知道哪里出了问题，我该怎么办？
我不确定如何在此处上传我的结构图像。我的数据结构为 2430 行和 19 列（RespondentID、问题、产品、年龄、地区、收入、CeraVe、Maybelline、LOreal、LaMer、Chanel、Dior、ProductChoice、价格、包装、质量、品牌、ProductChoiceBinary、UniqueChoiceID）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652448/analysing-dce-with-mixed-logit-in-r</guid>
      <pubDate>Wed, 07 Aug 2024 14:52:46 GMT</pubDate>
    </item>
    <item>
      <title>Surpyval Weibull 拟合优度</title>
      <link>https://stats.stackexchange.com/questions/652447/surpyval-weibull-goodness-of-fit</link>
      <description><![CDATA[我一直在使用 surpyval 将一些校准数据拟合到威布尔分布。我想评估拟合优度，但我不知道该怎么做。我以前使用过“可靠性”库，它有一个 KS 检验，但我不知道如何在 Surpyval 中执行此操作（可靠性不支持区间删失数据）。代码：
import surpyval as surv
import matplotlib.pyplot as plt
#sample data
Fail = [1,1,3,1,5,1,1,2,1,1,1,1,1]
Type = [1,1,1,2,1,1,2,1,1,2,1,2,1,2,1]
Time = [1820,1987,2176,[2373.0, 2542.0],2373,2731,[2920.0, 3093.0],2920,3279,[3472.0, 3641.0],3472,[3829.0, 4009.0],3829]

model = surv.Weibull.fit(x = Time, c =类型，n = 失败)
model.plot()
plt.show()

libraries:
matplotlib 3.6.0
numpy 1.26.0
scipy 1.14.0
surpyval 0.10.10

包含完整数据集的图。
我的完整数据集有左、右和区间数据。任何其他拟合优度方法/知识都会非常有帮助，并且包括对图像的任何见解。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652447/surpyval-weibull-goodness-of-fit</guid>
      <pubDate>Wed, 07 Aug 2024 14:49:15 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 模型的群体稳定性指数 [重复]</title>
      <link>https://stats.stackexchange.com/questions/652443/population-stability-index-for-xgboost-model</link>
      <description><![CDATA[计算 XGBoost 模型的种群稳定性指数是否有意义？
我将原始值分为 2 到 5 组，并以此方式训练模型。
我认为，如果变量 1 有组 1、组 2 和组 3，一棵树可以拆分为 &gt;组 2，而另一棵树可以拆分为 &gt;**=**组 2。
这样，每棵树都可以对变量 1 进行不同的拆分，并且无法进行 PSI，否则就没有多大意义了。
这样对吗？
编辑：问题没有重复，在这里我问计算 PSI 是否有意义，另一个问题是如何进行计算。]]></description>
      <guid>https://stats.stackexchange.com/questions/652443/population-stability-index-for-xgboost-model</guid>
      <pubDate>Wed, 07 Aug 2024 13:55:48 GMT</pubDate>
    </item>
    <item>
      <title>解释变量高度不平衡的回归</title>
      <link>https://stats.stackexchange.com/questions/652440/regression-with-highly-unbalanced-explanatory-variable</link>
      <description><![CDATA[我有一个回归问题，其中一个解释变量是分类变量，有 2 个类别。我的问题是，一个类别有 90% 的观测值，而第二个类别只有 10% 的观测值。
这种高度不平衡的分类变量的存在是否会对模型系数的统计推断造成任何问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/652440/regression-with-highly-unbalanced-explanatory-variable</guid>
      <pubDate>Wed, 07 Aug 2024 13:20:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么不使用FFT和使用FFT的自相关计算会给出不同的结果？</title>
      <link>https://stats.stackexchange.com/questions/651749/why-are-the-autocorrelation-computations-without-fft-and-with-fft-giving-differe</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651749/why-are-the-autocorrelation-computations-without-fft-and-with-fft-giving-differe</guid>
      <pubDate>Thu, 25 Jul 2024 14:36:20 GMT</pubDate>
    </item>
    <item>
      <title>比较生物样本中预期和观察到的特征组合</title>
      <link>https://stats.stackexchange.com/questions/651588/compare-expected-and-observed-feature-combinations-in-biological-samples</link>
      <description><![CDATA[背景研究：
这里研究的假设是共同选择或交叉耐药性等效应是否对生物样本中观察到的多重耐药性数量有影响。
我有1000个生物样本的分类数据和4 个特征 (A,B,C,D)，它们告诉我样本是否对药物 A,B,C,D 具有耐药性 (R)或易感性 (S)。
在此基础上，我可以计算出所有样本中每种药物耐药性的观察频率：
P(A = &quot;R&quot;) = 0.4
P(B = &quot;R&quot;) = 0.3
P(C = &quot;R&quot;) = 0.3
P(D = &quot;R&quot;) = 0.2

另一方面但我观察到多种药物耐药性，我想找出耐药性组合是否比预期更频繁：
P(observed) = P(A = R + B = R + C = R + D = R) = 0.1
P(expected) = P(A = R)* R(B = R) * P(C = R) * P(D = R) =
0.4*0.3*0.3*0.2

鉴于 P(observed) = 0.1 和 P(expected)=0.0072 之间的巨大差异
我想使用 R 中的 chisq.test 函数来比较这些比率。有没有更好的测试？如何设置列联表？]]></description>
      <guid>https://stats.stackexchange.com/questions/651588/compare-expected-and-observed-feature-combinations-in-biological-samples</guid>
      <pubDate>Tue, 23 Jul 2024 12:14:21 GMT</pubDate>
    </item>
    </channel>
</rss>