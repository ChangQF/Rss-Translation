<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 15 Mar 2024 18:17:30 GMT</lastBuildDate>
    <item>
      <title>人口金字塔的替代方案</title>
      <link>https://stats.stackexchange.com/questions/642714/alternatives-to-population-pyramids</link>
      <description><![CDATA[在与另一个问题相关的评论线程中，尼克·考克斯说：
&lt;块引用&gt;
人口金字塔被高估了。女性比例的微妙变化
对于男性，或其倒数，是重要的、常见的和预期的，但是
很难读出金字塔。 （更大的转变是那些你可以发现的
很容易。）

然后我问他什么是人口金字塔的良好替代方案（我最初的想法是使用具有一定透明度的重叠条）。他回答说：
&lt;块引用&gt;
在同一轴上以点或线的形式绘制男性和女性频率。
对数刻度可选，但与比率的思想一致
两者都是核心利益。

由于这些评论，我学到了一些东西，但现在我还有其他问题：

除了更容易识别微小变化之外，点/线图相对于人口金字塔还有哪些其他优势？

如上所述使用点/线图时，是否存在对数刻度不是一个好主意的情况？

除了点/线图之外，人口金字塔还有哪些其他好的替代方法？


谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/642714/alternatives-to-population-pyramids</guid>
      <pubDate>Fri, 15 Mar 2024 18:01:54 GMT</pubDate>
    </item>
    <item>
      <title>用于估计 SARIMA 订单的 ACF 和 PACF 图</title>
      <link>https://stats.stackexchange.com/questions/642713/acf-and-pacf-plots-to-estimate-sarima-orders</link>
      <description><![CDATA[我有一些数据（特定杂货店特定商品的销售情况），这些数据显示了趋势和季节性。我通过进行以下形式的线性回归来拟合这些趋势和季节性成分
$$
y_t = \beta_0 +\beta_1t + \sum_0^5 \phi_j \cos\left(\frac{(2+i)\pi}{365} t\right) + \psi_j\sin\left(\frac{(2 +i)\pi}{365} t\right)
$$
最终的拟合结果如下所示：

然后我查看了残差的 ACF 和 PACF 图，它们显示出很强的季节性，周期为 7 天。这是有道理的，因为杂货店销售应该有一些可预测的每周波动。


经过一番研究 SARIMA 参数后，我发现 $\operatorname{SARIMA}(1,0,1)(1,0,1,7)$&lt; /span&gt; 效果很好。这是包含 SARIMA 组件后的 PACF：

这引出了我的问题：
有没有办法让我根据这些图猜测这些特定的超参数会做得很好？
另外：奇怪的是，我在滞后 $31$ 处仍然有一个显着的部分自相关，这可能表明我缺少一些每月的季节性。另一个带有 $s=31$ 的 SARIMA 是否可取？]]></description>
      <guid>https://stats.stackexchange.com/questions/642713/acf-and-pacf-plots-to-estimate-sarima-orders</guid>
      <pubDate>Fri, 15 Mar 2024 17:59:06 GMT</pubDate>
    </item>
    <item>
      <title>CLMM 的效应量</title>
      <link>https://stats.stackexchange.com/questions/642712/effect-size-of-clmm</link>
      <description><![CDATA[我正在对 ordinal 包中的 CLMM 模型进行综合分析。我将 CLMM 模型传递给 RVAideMemoire 包中的函数 Anova.clmm()。输出表包括模型参数、相关的 LR 卡方统计数据和 p 值。
有没有办法评估“效应大小”？或“重要性强度”对于此时的每个模型参数？对模型系数求幂不会产生直观的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/642712/effect-size-of-clmm</guid>
      <pubDate>Fri, 15 Mar 2024 17:35:14 GMT</pubDate>
    </item>
    <item>
      <title>可以使用什么测试来确定包含 150 多个组的列联表中各组频率之间的显着性？</title>
      <link>https://stats.stackexchange.com/questions/642711/what-test-can-be-used-to-determine-significance-between-frequencies-of-groups-in</link>
      <description><![CDATA[我有一个包含 150 多个组的列联表，每个组都有通过/失败结果。每组中的计数范围很广，因此我在 R 中使用了 Fisher 精确检验，结果显示了显着性。然而，我质疑在尝试进行事后分析以找到最重要的组时这是否可行，因为成对 p 值中大部分为 NA。有没有针对这样的数据进行测试和事后测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/642711/what-test-can-be-used-to-determine-significance-between-frequencies-of-groups-in</guid>
      <pubDate>Fri, 15 Mar 2024 17:24:58 GMT</pubDate>
    </item>
    <item>
      <title>确定两个变量之间影响的大小</title>
      <link>https://stats.stackexchange.com/questions/642709/determining-the-magnitude-of-influence-between-two-variables</link>
      <description><![CDATA[我试图找出一个变量对另一个变量的影响大小，以及如果我们也以相反的方向分析它会发生多大的变化。本质上，我试图弄清楚变量 A 是否对变量 B 的影响更大，或者相反。我运行了两个简单的线性回归模型并得到了以下结果，尽管我对统计有点陌生，所以我不太确定如何解释它们，或者这种分析方法是否是解决问题的正确方法。任何帮助将不胜感激。谢谢！
]]></description>
      <guid>https://stats.stackexchange.com/questions/642709/determining-the-magnitude-of-influence-between-two-variables</guid>
      <pubDate>Fri, 15 Mar 2024 16:38:02 GMT</pubDate>
    </item>
    <item>
      <title>如何计算非独立随机变量比率的期望？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/642708/how-to-calculate-the-expectancy-of-the-ratio-of-non-independent-random-variables</link>
      <description><![CDATA[我如何计算这个预期：
$$
E \left [ \frac{\sum_{t=1}^T{Z_tX_t}}{\sum_{t=1}^T{Z_t^2}} \right ]
$$
其中 $Z_t$ 和 $X_t$ 是独立的，所有已知时刻均值为零？有什么技巧吗？可能吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642708/how-to-calculate-the-expectancy-of-the-ratio-of-non-independent-random-variables</guid>
      <pubDate>Fri, 15 Mar 2024 16:22:51 GMT</pubDate>
    </item>
    <item>
      <title>优化非标准概率密度函数的参数</title>
      <link>https://stats.stackexchange.com/questions/642705/optimizing-parameters-for-a-non-standard-probability-density-function</link>
      <description><![CDATA[我们有一个非标准多元概率密度函数，P(x | q)，其中 x 是向量，q 是密度参数。我从一个嘈杂的实验中获得事件 X&#39;，我的目标是找到 q 以便 x ~ P(x|q)。由于实验有噪声，这效果不好，因此我们设计了一个可以添加实验噪声的机器学习模型。
我们当前的策略如下

猜测初始 q0
来自 P(x | q0) 的示例 x
将x转换为x&#39;
使用 Wasserstein 距离找出 x&#39; 和 X&#39; 之间的差异。
将此损失与有限差分结合使用，通过数值优化来优化参数。

问题是，正如预期的那样，有限差分的导数非常嘈杂，并且需要更好的方法。我们已经寻找了替代方案，但找不到一个好的起点，并且希望能提供一些有关该领域针对此类问题所做的工作的指导。
我们知道随机样本没有导数，通常，至少在机器学习社区中，重新参数化用于获得高质量的梯度。不幸的是，我们的密度很复杂，因此我们无法更改变量。我们还研究了使用可以表示为密度期望函数的损失函数，在这种情况下我们可以找到梯度，但没有找到合适的解决方案。
我们不能使用像 MLE 这样的东西，因为 x-&gt;x&#39; 的变换在密度级别上很难构造。在样本级别上做起来要简单得多。
欢迎对此问题提供任何帮助或指示！]]></description>
      <guid>https://stats.stackexchange.com/questions/642705/optimizing-parameters-for-a-non-standard-probability-density-function</guid>
      <pubDate>Fri, 15 Mar 2024 16:15:31 GMT</pubDate>
    </item>
    <item>
      <title>通过高斯分类器与逻辑回归进行分类。什么时候选择更间接的回归方法？</title>
      <link>https://stats.stackexchange.com/questions/642702/performing-classification-by-gaussian-classifier-versus-logistic-regression-whe</link>
      <description><![CDATA[假设我们测量一个依赖于二分类的变量 $X|_\text{class}$，其中分布以该类为条件
$$X|_\text{class =1} \sim N(\mu_1,\sigma^2)$$
$$X|_\text{class =2} \sim N(\mu_2,\sigma^2)$$
在这种情况下，我们可以应用逻辑模型，如下所述：

对于二元分类示例，如何证明 LDA 具有与 Logistic 回归类似的形式？
推导出逻辑回归公式

这里的问题是哪种方法可以为分类边界创建最低的均方误差

我们可以根据两个总体拟合正态分布，并用它来计算分类边界。
我们可以执行逻辑回归并用它来计算分类边界。

这些方法不会给出与下面代码所示相同的结果（与拟合逻辑回归模型相比，拟合正态分布更好，与理想边界的偏差更低）。
问题：显然，逻辑回归并不总是表现最好的。是否有系统/方法来决定使用逻辑回归而不是直接拟合正态分布？
set.seed(1)


样本=函数（）{
  n = 30
  x = rnorm(n,0)
  y = rnorm(n,1)
  xy = c(x,y)
  z = 代表(c(0,1), 每个 = n)
  
  mod = glm(z ~xy, 族 = 二项式())
  
  border1 = Mean(c(x,y)) ### 基于组均值之间的平均值的边界
  边界2 = exp(mod$系数[1])
  
  返回（c（边界1，边界2））
}


b = 复制(10^3, 样本())

绘图（b[1，]，b[2，]）
mean((b[1,]-0.5)^2) ### 直接分类的错误 = 0.0166966
Mean((b[2,]-0.5)^2) ### 逻辑回归误差 = 0.02807377
]]></description>
      <guid>https://stats.stackexchange.com/questions/642702/performing-classification-by-gaussian-classifier-versus-logistic-regression-whe</guid>
      <pubDate>Fri, 15 Mar 2024 14:46:44 GMT</pubDate>
    </item>
    <item>
      <title>使用朴素贝叶斯分类器确定集群的混合</title>
      <link>https://stats.stackexchange.com/questions/642701/determining-a-mix-of-clusters-by-using-naive-bayes-classifiers</link>
      <description><![CDATA[我有以下问题，我似乎无法找到简单的答案：鉴于我们有两个组（让我们称它们为 1 和 2），是否可以通过仅训练 1 来确定组的混合百分比和2？
例如，我做了两个这样的集群：
clusterSize = 1000;
% 簇一
cluster1 = randn(clu​​sterSize, 2);
cluster1L = one(clusterSize, 1);
% 聚类二
cluster2 = randn(clu​​sterSize, 2) + 5;
cluster2L = 2 * 个(clusterSize, 1);

然后我可以定义集群 3、4 和 5，这样：

3 是 1 和 2 的 50/50 组合
4 是 1 和 2 的 25/75 组合
5 是 1 和 2 的 75/25 组合

为此，代码如下：
% 簇三
簇3 = 0.5.*簇1 + 0.5.*簇2;
cluster3L = 3 * 个(clusterSize, 1);
% 聚类四
簇4 = 0.25.*簇1 + 0.75.*簇2;
cluster4L = 4 * 个(clusterSize, 1);
% 聚类五
簇5 = 0.75.*簇1 + 0.25.*簇2;
cluster5L = 5 * 个(clusterSize, 1);

然后我将此数据作为表格返回：
&lt;前&gt;&lt;代码&gt;X = [簇1;集群2；集群3；集群4；集群5]；
Y = 字符串([簇1L;簇2L;簇3L;簇4L;簇5L]);
数据=表();
数据.X = X(:,1);
数据.Y = X(:,2);
数据.标签 = Y;

我对数据进行标准化并进行 PCA。我只在集群 1 和 2 上进行训练：
预测器=标准化(Data{:,1:2});
[coeff, 得分, 潜在, tsquared, 解释] = pca(预测变量);
TrainingClustersData = 分数(包含(Data.Label,[“1”,“2”]),:);
TrainingLabels = Data.Label(包含(Data.Label,[“1”,“2”]),:);
MixedClustersData = 分数(~包含(Data.Label,[“1”,“2”]),:);
MixedClustersLabels = Data.Label(~contains(Data.Label,[“1”,“2”]),:);
mdl = fitcnb(TrainingClustersData, TrainingLabels);

这样做，我可以计算簇的后验概率，还可以分散不同的簇以检查它们的位置：
&lt;前&gt;&lt;代码&gt;xMax = 5;
x最小值=-5；
h = 0.05；
[x1Grid,x2Grid] = meshgrid(xMin:h:xMax,xMin:h:xMax);
[~,PosteriorRegion] = 预测(mdl,[x1Grid(:),x2Grid(:)]);
后区域(:,3) = 0;
h = 分散(x1Grid(:),x2Grid(:),1,PosteriorRegion);
xlim([x最小x最大])
ylim([x最小x最大])
坚持，稍等
gscatter(分数(:,1), 分数(:,2), Data.Label)
legend(“位置”,“西北”)

通过检查绘图，我可以看到簇的距离在很大程度上取决于我之前定义的混合，这是合乎逻辑的。

我的问题是，我可以通过这种方法找到这个混合百分比吗？这是可行的吗？可以在可引用的研究中找到吗？在混合数据上使用 mdl.predict 可以得到属于集群 1 或 2 的样本的概率（分数），这也是我在本例中所需要的。我想用这个概率作为混合决定。
我期待任何意见、批评或建议]]></description>
      <guid>https://stats.stackexchange.com/questions/642701/determining-a-mix-of-clusters-by-using-naive-bayes-classifiers</guid>
      <pubDate>Fri, 15 Mar 2024 14:39:53 GMT</pubDate>
    </item>
    <item>
      <title>对加权事件应用负二项分布</title>
      <link>https://stats.stackexchange.com/questions/642700/applying-negative-binomial-distribution-for-weighted-events</link>
      <description><![CDATA[我正在尝试对销售时的库存年龄进行建模，其中一次给定的销售（例如，价值 10,000 美元的特定产品）可能会用 1 个月前的 5,000 美元的库存来完成，即 3,000 美元价值 3 个月的库存和价值 2,000 美元的 7 个月的库存。我有大约 1,000 种产品的数据，库存期限从 0 到 18 个月不等。如果我不必在分析中包含金额，那么这是一个简单的负二项式建模问题，但我不明白如何通过金额对事件进行加权。
（加权）数据如下所示：

有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642700/applying-negative-binomial-distribution-for-weighted-events</guid>
      <pubDate>Fri, 15 Mar 2024 14:28:44 GMT</pubDate>
    </item>
    <item>
      <title>如何从神经网络模型中得出每个预测值的概率得分？</title>
      <link>https://stats.stackexchange.com/questions/642699/how-to-come-up-with-a-probability-score-for-each-predicted-value-from-a-neural-n</link>
      <description><![CDATA[我有一些 python 代码，用于创建和训练神经网络模型来预测“成本”列。它接受大量输入并预测成本。现在，我试图将预测成本转换为概率（更具体地说，遇到此错误的概率（预期成本和预测成本之间的相对差异）或更大）。这就是我所做的：
# Y_Actual 是实际成本（它是一个数组）
# Predictions_array 是来自神经网络模型的成本预测的数组
错误列表 = ((abs(Y_实际 - 预测数组)) / Y_实际) * 100
# 我使用修剪均值和修剪标准差来控制可能的异常值
误差平均值 = 修剪平均值（误差列表，0.05）
trimmed_data = stats.trimboth(error_list, 0.05)
error_sd = np.std(修剪数据)
prob_score_all = []
对于 error_list 中的 i：
    z_score = (i - error_mean) / error_sd
    desiredProb = 1 - stats.norm.cdf(z_score)
    prob_score_all.append(desiredProb)

这通常效果很好。也就是说，例如，如果实际成本为 $3 而预测成本为 $15，则这并不是一个非常显着的差异。但分配给它的概率非常小，因为代码确定预测成本与实际成本相差 5 倍。因此，它最终被分配的概率要小得多。另一方面，如果我的实际成本为 $1,000,000 且预测成本为 $700,000，则与前面的示例相比，其概率要大得多。有什么办法可以解决这个问题吗？我知道这看起来像是一个编程问题，但实际上是一个关于如何将机器学习模型的预测值转换为概率的统计问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/642699/how-to-come-up-with-a-probability-score-for-each-predicted-value-from-a-neural-n</guid>
      <pubDate>Fri, 15 Mar 2024 14:27:13 GMT</pubDate>
    </item>
    <item>
      <title>多元时间序列数据的 Copula</title>
      <link>https://stats.stackexchange.com/questions/642698/copula-for-multivariate-time-series-data</link>
      <description><![CDATA[我的数据包含传感器测量的两个变量（即变量 1 和变量 2）。对于每个变量，测量是在 19 个不同日期的 15 个不同点进行的，因此共有 285 行数据。因此，我相信这是一个多元时间序列数据。
我想通过应用二元联结函数来构建这两个变量之间的联合分布。但是，由于将 copula 应用于时间序列数据的基本假设是时间序列应该是平稳的，因此作为预处理步骤是否足以使每个点的时间序列分别平稳？我想知道应该执行哪些预处理步骤，因为不同点或不同日期的某一点的数据之间可能存在自相关。这让事情变得更加复杂。]]></description>
      <guid>https://stats.stackexchange.com/questions/642698/copula-for-multivariate-time-series-data</guid>
      <pubDate>Fri, 15 Mar 2024 14:20:20 GMT</pubDate>
    </item>
    <item>
      <title>我搞砸了模型选择，但最终得到了一个非常好的模型；我还好吗？</title>
      <link>https://stats.stackexchange.com/questions/642695/i-screwed-up-model-selection-but-ended-up-with-a-very-good-model-am-i-ok</link>
      <description><![CDATA[在最近的一次实验中，我犯了一个疏忽：我将数据分为训练集和测试集，并在应用 Boruta（随机森林的特征重要性）在整个数据集上选择特征后，对模型选择和超参数调整进行了交叉验证训练集。
我想确保我完全掌握与此方法错误相关的风险。在我看来，模型选择在两个方面受到了影响。首先，我认为该错误引入了有利于基于树的方法的选择偏差（导致 XGBoost 成为所选模型），因为最重要的特征集随所选方法的不同而变化。此外，我怀疑由于测试折叠泄漏到特征选择过程中，交叉验证分数存在乐观偏差。
尽管如此，模型对测试数据的评估（假设它具有足够的代表性和规模）应该不受影响。此外，考虑到梯度提升通常非常适合表格数据集，我怀疑实验结果是否存在任何真正的问题，除了可能忽略了一个性能更高的可解释模型。
总之，我相信我搞砸了模型选择，但最终还是得到了一个非常好的模型，所以我应该没问题。你觉得怎么样？]]></description>
      <guid>https://stats.stackexchange.com/questions/642695/i-screwed-up-model-selection-but-ended-up-with-a-very-good-model-am-i-ok</guid>
      <pubDate>Fri, 15 Mar 2024 13:46:51 GMT</pubDate>
    </item>
    <item>
      <title>如何使用小样本计算（偏差校正）几何平均值</title>
      <link>https://stats.stackexchange.com/questions/642689/how-to-calculate-the-bias-corrected-geometric-mean-with-small-sample-sizes</link>
      <description><![CDATA[大多数来源都给出了一个简单的方程来计算样本的几何平均值 (GeoMean)。
GeoMean = exp(m)

其中m是值的自然对数（以e为底）的平均值
偏差校正方程在：Parkin, T. B. &amp; 中给出。 Robinson, J.A. 对数正态分布变量的中值估计量的统计评估。土壤科学。苏克。是。 J. 57, 317–323 (1993)。
GeoMean = exp(m - s^2/2n)

这里，m和s是值的自然对数的平均值和标准差，n是值的数量在样本中。对于较大的n（和/或较小的s），该方程接近更简单、更常用的方程。但对于较小的 n 和/或较大的 s，结果可能会相差很大。
我的问题：

这个偏差校正方程正确吗？我没有在其他地方看到它，并且在谷歌或维基百科中找不到任何提及。应该一直使用它吗？
如果它是正确且值得推荐的，为什么？偏见从何而来？
]]></description>
      <guid>https://stats.stackexchange.com/questions/642689/how-to-calculate-the-bias-corrected-geometric-mean-with-small-sample-sizes</guid>
      <pubDate>Fri, 15 Mar 2024 13:18:52 GMT</pubDate>
    </item>
    <item>
      <title>当多次重复时仅比较两个受试者时，应使用哪个误差线？</title>
      <link>https://stats.stackexchange.com/questions/642683/which-error-bars-to-use-when-compairng-only-two-subjects-when-many-replicates</link>
      <description><![CDATA[我想绘制对两个受试者进行的离散时间测量结果，但每个受试者都观察到许多细胞，一式三份。
我认为实验单位是主题，所以我应该得到每个主题的平均值并绘制它。另一种选择是获取每个单元格三次重复的平均值并绘制它们。
无论如何，我无法判断是否应该使用标准误差或标准差作为误差条。据我了解，标准差适用于不同的样本，我不清楚每个单元格是否应该算作一个样本。另一方面，我一直读到大多数时候你应该使用标准差作为误差条。
编辑：
我正在计算每个受试者在每个时间点的标准偏差和标准误差。我没有考虑到观察结果是一式三份的事实。所以基本上我计算了平均值、SD 和 SE，并简单地绘制了这些值。
我是否应该计算每个一式三份的平均值、SD 和 SE 并绘制它们？也许用黄土画一条穿过它们的平滑线？]]></description>
      <guid>https://stats.stackexchange.com/questions/642683/which-error-bars-to-use-when-compairng-only-two-subjects-when-many-replicates</guid>
      <pubDate>Fri, 15 Mar 2024 10:41:03 GMT</pubDate>
    </item>
    </channel>
</rss>