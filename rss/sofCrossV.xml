<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 02 May 2024 15:15:14 GMT</lastBuildDate>
    <item>
      <title>对多个变量分别进行分层抽样</title>
      <link>https://stats.stackexchange.com/questions/646360/stratified-sampling-across-several-variables-individually</link>
      <description><![CDATA[我对用于聚类验证的分层抽样感兴趣。目的是对数据的子集进行聚类分析，并检查聚类分析中出现的变量的精确分布是否与原始聚类中实际未涉及的子集一致。
假设我根据身高（高或矮）和年龄（年老或年轻）进行分层。据我了解，在传统的监督学习环境中，常见的分层抽样方法可能是通过这些变量的组合（高老、高年轻、矮老、矮年轻）创建阶层，然后从这些阶层中进行抽样适当地。
我想将我的观察结果分为两组，A 和 B，这样 A 和 B 中年轻人与老年人的比例大致相等，矮个子与高个子的比例也大致相等。但我不想强迫这两个群体的高老、高年轻、矮老、矮年轻的比例大致相等。
目前，我计划实现这一目标的方法只是多次随机划分我的观察结果，计算高/矮和年轻/年长的 A 与 B 比例的平方误差之和，以及然后在一天结束时选择误差最低的随机分区。
我的问题是：

我正在尝试做的事情是否有明显荒谬的事情？
是否有更好的方法来进行此类采样？我正在 R 中执行此操作，但也欢迎一般性建议。
这种采样有名称吗？

谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/646360/stratified-sampling-across-several-variables-individually</guid>
      <pubDate>Thu, 02 May 2024 15:06:57 GMT</pubDate>
    </item>
    <item>
      <title>可以对多重回归输出（系数、比率等）进行预测解释吗？</title>
      <link>https://stats.stackexchange.com/questions/646357/can-multiple-regression-output-coefficients-ratios-etc-be-given-a-predictiv</link>
      <description><![CDATA[一般来说，回归输出通常可以为模型中的一个变量给出因果解释（即在没有未观察到的混杂因素的假设下，这并不是说边际效应等的潜在需要）（&lt; a href=&quot;https://academic.oup.com/aje/article/177/4/292/147738?login=false&quot; rel=&quot;nofollow noreferrer&quot;&gt;Westreich 和格陵兰 2013, Keele 等人，2019）。
我认为对回归输出最直观、最保守的解释是描述性解释。然而，我经常看到人们将多元回归中的几个系数、比率等解释为“预测变量”。结果。利用现有的机器学习工具，对模型中的任何系数进行预测解释是否公平？如果您想了解给定变量的原始预测能力，您是否不仅仅为每个预测变量迭代运行各种双变量回归模型并使用一些统计数据来评估其预测能力？如果您只对每个预测变量的预测能力感兴趣，为什么要生成针对其他变量进行调整的估计值？
在我看来，在回归模型中调整其他变量的做法是一种因果努力，如果不满足识别假设，则可能会给出描述性解释。但我对此并不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/646357/can-multiple-regression-output-coefficients-ratios-etc-be-given-a-predictiv</guid>
      <pubDate>Thu, 02 May 2024 14:07:09 GMT</pubDate>
    </item>
    <item>
      <title>为什么 JAGS 模型的 Gelman 图从 1000 开始？</title>
      <link>https://stats.stackexchange.com/questions/646356/why-does-the-gelman-plot-of-a-jags-model-start-at-1000</link>
      <description><![CDATA[我正在使用 R 中的 rjags 查看贝叶斯模型的诊断。特别是，我正在考虑它的 Gelman-Rubin-Brooks 图。与迭代次数无关，尽管我没有使用 burn-in，但图的 x 轴从大于 1000 的数字开始，而不是从 0 开始。这是什么原因造成的？
library(rjags)

data_list &lt;- list(
&quot;nx&quot; = 1, 
&quot;N&quot; = 4
)

model_string &lt;- &quot;
model {
p ~ dbeta(1, 1)
nx ~ dbinom(p, N)
}
&quot;

模型 &lt;- jags.model(
file = textConnection(model_string),
data = data_list,
n.chains = 3
)

samples_small &lt;- coda.samples(
model = model,
variable.names = &quot;p&quot;,
n.iter = 100
)
samples_big &lt;- coda.samples(
model = model,
variable.names = &quot;p&quot;,
n.iter = 5000
)

gelman.plot(samples_small)
gelman.plot(samples_big)

samples_small 的图：

samples_large 的绘图：

PS：虽然这是与代码相关的问题，但它实际上并不是编程问题。因此，在我看来，CrossValidated 似乎是首选论坛。如果我应该切换到 SO，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/646356/why-does-the-gelman-plot-of-a-jags-model-start-at-1000</guid>
      <pubDate>Thu, 02 May 2024 14:01:42 GMT</pubDate>
    </item>
    <item>
      <title>具有不平衡类别和正态性假设的 Kruskal-Wallis</title>
      <link>https://stats.stackexchange.com/questions/646355/kruskal-wallis-with-unbalanced-classes-and-assumption-of-normality</link>
      <description><![CDATA[我想更好地了解如何正确地处理具有很大程度上不平衡类的重要测试。
考虑一下：
在我的例子中，我有一个音节序列的数据集，以及相关的类 - 行为。
这些类在很大程度上是不平衡的 - 最大的类有 140K 数据点，最小的类有 800 个数据点。
序列看起来像这样：(A, B, B), (B,A), (C, C, D, E), ... - 如你所见，它们的长度各不相同 - 并且行为是分类标签。
我想测试子字符串的长度和行为之间是否存在显着差异。
但很高兴也考虑其他测试，着眼于序列音节的特异性，以探索可能标记行为之间差异的其他方面，具体取决于音节。

我应该考虑 Kruskal-Wallis 检验还是其他检验（例如 ANOVA 或多级模型）？
我应该为每个类别抽取相同数量的项目吗？
如果是这样，我应该如何抽样 - 我应该考虑最小类的整个总体，然后随机选择最大类，还是应该根据大小对抽样进行加权？

背景和疑问

对于非常大的类，使用 Kruskal Wallis 或 Anova 之间存在分歧：一个论证遵循非常大的类经历正态性的假设；另一个论证遵循这样的假设：非常大的类经历正态性；另一个是 Kruskal Wallis 确实适合不平衡类别
https://www.researchgate.net/post/Kruskal_Wallis_test_for_unequal_group_size

我知道方差分析假定方差呈正态性和同质性，但根据我所做的分析，我对在何处应用正态性检验感到有点困惑：


我发现所有类别中所有数据点的长度组合符合重尾分布。所以它不是正态分布。
但是，如果我想测试类之间的显着性差异，我认为我应该将每个类的序列群体视为一个独立的群体。虽然正态性应该适用于每个类，但我感到困惑，因为条形图似乎表明它是正态分布，但统计分析却不然，所以我想知道我是否正确地构建了问题和变量。
具体来说：当我绘制分布的长度时，它“似乎”是来近似它（它实际上是一个条形图，因为长度是离散的，中心值为 5 的钟形图是“镜像”极值），但我尝试了 Levene 检验来测试方差的同质性，并尝试了 Shapiro-Wilk 检验来测试正态分布，并且它们都返回 p = 0.0，表明长度不服从正态分布。

该帖子建议使用多级分析，但不确定如何在我的案例中应用它：
Kruskal-Wallis、ANOVA 或其他测试？

如果您能解释如何正确处理问题并明智地应用重要测试，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/646355/kruskal-wallis-with-unbalanced-classes-and-assumption-of-normality</guid>
      <pubDate>Thu, 02 May 2024 13:45:41 GMT</pubDate>
    </item>
    <item>
      <title>对这些数据拟合 S 曲线，可能吗？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/646353/fitting-an-s-curve-to-this-data-is-it-possible</link>
      <description><![CDATA[我有一些数据有点混乱，但我很理解。我正在尝试拟合一条近似的 S 曲线（我知道它不会是完美的，因为它是一个很难建模的关系，而且除了我的 X 变量之外还有其他难以量化的因素）。
为了给出一些上下文，Y 变量是一个 %，因此分别受到上限和下限 1 和 0 的约束，其中，一般来说，X 的任何值  -8 将导致 Y = 0% 且 X &gt; 的任何值-2 将导致 Y = 100%。
因此它的范围是 -8 &lt; X＜ -2 魔法真正发生的地方，X 中的单位差异会产生最大的差异。
我的数据在上限上确实有一个较长的尾部，因为我在数据集中有一些较大的正 X 值，但我确信较大的负值将位于下限上。
基本上，我编写了一些代码来给出一条曲线，但我想调整“a”参数以使曲线变陡。然而，当我在代码中进行此更改时，曲线完全中断，我认为这可能是语法问题，但这就是我真正要问的原因。
这是我正在使用的代码，如果您运行它，您可能会明白为什么我要使曲线变陡：
导入 pandas 作为 pd
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
从 scipy.optimize 导入 curve_fit

def Logistics_function(x, L, k, x0):
    返回 L / (1 + np.exp(-k*(x-x0)))

df = pd.DataFrame({
    &#39;x&#39;: [-4.49,-5.53,-6.66,-4.82,-7.01,-8.62,-9.86,-11.64,-12.41,-3.06,
          -4.48,-7.86,-3.09,-11.21,-2.01,-0.47,-4.60,-1.72,-4.21,-1.04,
          -2.90,-2.47,-4.16,-2.81,-2.62,-2.57,-5.81,-7.34,-5.67,-6.82,-3.63,
          -3.05,3.22,-0.91,-10.40,-3.66,-3.90,-4.69,60.39,-6.88,12.83,22.23,
          12.00,42.54,63.11,30.29,28.07,10.11,-2.99,2.18,1.14,1.49,-9.55],
    &#39;y&#39;: [0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.23,7.01,
          10.00,15.37,16.93,17.79,18.01,18.06,18.61,20.60,21.22,24.40,
          28.09,30.56,34.33,46.07,47.64,51.50,58.96,64.92,68.02,76.65,
          80.39,83.76,85.83,87.03,87.84,88.01,92.55,93.84,95.42,96.10,
          96.19,100.00,100.00,100.00,100.00,100.00,100.00,100.00,100.00,
          100.00,100.00,100.00,100.00]
})

初始猜测 = [100, 0.1, 0]
x_values = df[&#39;x&#39;].values
y_values = df[&#39;y&#39;].values / 100
popt, pcov = curve_fit(logistic_function, x_values, y_values, p0=initial_guess)
L, k, x0 = 波普特

x = np.linspace(最小值(x_值), 最大值(x_值), 100)
y = 逻辑函数(x, L, k, x0) * 100

plt.scatter(x_values, y_values * 100)
plt.plot(x, y, c=&#39;r&#39;)
plt.title(&#39;S 曲线&#39;)
plt.xlabel(&#39;x&#39;)
plt.ylabel(&#39;y&#39;)
plt.show()

我的问题基本上是 - 我是否以正确的方式处理这个问题？是不是应该在下限的尾部添加一些假值，让数据更加对称和全面？我怎样才能找到我的真实参数应该是什么？因为我认为我的“b”也不正确，但我不想告诉代码“b”是什么，我希望它对其进行优化。
抱歉，如果这是一个非常愚蠢的问题]]></description>
      <guid>https://stats.stackexchange.com/questions/646353/fitting-an-s-curve-to-this-data-is-it-possible</guid>
      <pubDate>Thu, 02 May 2024 12:47:34 GMT</pubDate>
    </item>
    <item>
      <title>基于多个变量创建具有相似值的两个组</title>
      <link>https://stats.stackexchange.com/questions/646352/create-two-groups-with-similar-values-based-on-multiple-variables</link>
      <description><![CDATA[我想创建两个大小相等的组。我想根据利润、销售额和收入的类似值对我的 ID 进行分组。
我的数据看起来像这样：
ID周利润销售收入
1 1 50 10 30
1 2 59 15 34
......
2 1 5 1 3
....

如果我想绘制我的两个组（例如绘制收入），则绘图应尽可能相似，可能会重叠。我有 1200 个数据点，数据显示为周 (1-54)。请注意，我不想要只有两个相同规模的组，但就像我所说的在利润、收入和销售额方面类似。我用的是rstudio。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646352/create-two-groups-with-similar-values-based-on-multiple-variables</guid>
      <pubDate>Thu, 02 May 2024 12:18:58 GMT</pubDate>
    </item>
    <item>
      <title>Tweedie 分布的方差分解 – 需要反向变换吗？</title>
      <link>https://stats.stackexchange.com/questions/646344/variance-decomposition-with-tweedie-distribution-back-transform-necessary</link>
      <description><![CDATA[我们正在运行一个分层随机截距模型，其中包含 Tweedie 分布因变量（见下文）和三个层次结构。我们的目标是估计层次结构的每个级别解释了多少总方差（以百分比为单位）。我们通过估计层次结构每个级别的随机截距的方差，然后将其除以总方差来实现此目的。
因变量服从 Tweedie 分布（连续、零膨胀、右偏）。随机截距的先验是正态分布，我们估计其方差。鉴于我们对 DV 使用 Tweedie 分布，我们是否需要对各个随机效应的方差估计进行反向变换或逆变换，以正确估计解释的方差份额，或者不需要反向变换？
请注意，我们没有像 Tweedie 分布中经常使用的那样在模型中使用日志链接函数。 Tweedie 分布的平均值只需添加几个变量即可确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/646344/variance-decomposition-with-tweedie-distribution-back-transform-necessary</guid>
      <pubDate>Thu, 02 May 2024 10:39:20 GMT</pubDate>
    </item>
    <item>
      <title>因素分数解释的方差少于多级 CFA 中项目的含义</title>
      <link>https://stats.stackexchange.com/questions/646343/factor-scores-explain-less-variance-than-item-means-in-a-multilevel-cfa</link>
      <description><![CDATA[我在拉万针对重复测量问卷数据（对旅行量表的满意度）进行了多级 CFA。 42 名参与者在自然多式联运旅行后平均进行了约 9 次测量（不平衡）。
该调查问卷希望将旅行满意度作为一个包含三个子因素的分层模型来衡量：积极停用（高价低唤醒）、积极激活（高价、高唤醒和认知评估）。每个因素在 1 到 3 个项目上进行测量7.
整体模型拟合度不错，所有局部拟合统计数据均显着且令人满意
对于内部模型，潜在变量的层次结构提供了最少的不良拟合
对于中间模型，与 2 或 3 个因素相比，1 个因素结构提供的不良拟合最少，但层次结构没有正确收敛。
我将内部潜在变量解释为对特定旅行的满意度（正如预期的那样，因为因子结构提供了适当的拟合）。
但由于模型之间是一个单因素结构，并且协方差矩阵内部和之间的汇集是独立构建的，因此我会将之间潜在变量解释为整体评级倾向，而不是对旅行的平均/稳定满意度。
我使用 lavpredict() 计算了因子得分之内和之间
支持我的解释，神经质（用 2 个项目测量，bfi10）解释了潜在变量因子得分之间 20% 的方差。
在所有旅行中，旅行持续时间和旅行满意度之间没有显着关系。无论是我们的内部潜在变量分数还是平均项目分数 (n=400)
当我们只考虑路线大致相同的行程时（n=132），这种关系就变得很重要（但非常小）。
但有趣的是，行程持续时间解释了平均项目得分 (R2=.076) 的方差比内部潜在变量得分 (R2=.028) 的方差更大。
我认为随着内部满意度变量的潜在变量得分，这种关系会变得更强。如果我创建一个新变量，在分数之间添加分数，则 R2 变为 0.076，作为平均项目分数。
您如何解释这里发生的事情？我知道这种关系非常小，但是一般评级倾向会增加这种关系是否有意义？旅行持续时间不能解释内部因子得分比项目得分平均值更大的方差，这是一个坏兆头吗？这个话题非常抽象，所以我很想知道对此的不同看法。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646343/factor-scores-explain-less-variance-than-item-means-in-a-multilevel-cfa</guid>
      <pubDate>Thu, 02 May 2024 10:26:18 GMT</pubDate>
    </item>
    <item>
      <title>仅依靠高度不平衡测试集的混淆矩阵来评估模型性能是一个坏主意吗？</title>
      <link>https://stats.stackexchange.com/questions/646341/is-relying-on-just-the-confusion-matrix-for-highly-imbalanced-test-sets-to-evalu</link>
      <description><![CDATA[我有一个二元分类模型，其测试集高度偏斜，多数类 0 比少数类 1 高 22 倍。
这导致我的准确率低，召回率高，但总体 F1 得分很差。只使用混淆矩阵来评估模型的性能可以吗？
根据我所看到的，混淆矩阵上的性能看起来并不差。我使用 BalancedRandomForestClassifier 为我的测试集实现了这些结果：
类 0： 8941 / 11061 预测正确
类 1： 476 / 522 预测正确
如果我增加概率阈值，我可以降低 FP 率，但代价是 FN 略有增加。 我想知道在这种情况下，依赖混淆矩阵是否可以。]]></description>
      <guid>https://stats.stackexchange.com/questions/646341/is-relying-on-just-the-confusion-matrix-for-highly-imbalanced-test-sets-to-evalu</guid>
      <pubDate>Thu, 02 May 2024 09:39:00 GMT</pubDate>
    </item>
    <item>
      <title>回归的选择</title>
      <link>https://stats.stackexchange.com/questions/646347/choice-of-regression</link>
      <description><![CDATA[我正在做一个项目，我正在尝试找出要使用哪种类型的回归。我有一个数据集，其中包含大约 10000 个观察值和 7 个变量。它是客户支付发票时的数据，因此每个观察结果都是一张发票。我有以下变量：
客户姓名
货币
状态
关闭
行业
发票金额
付款条件
除 InvoiceAmount 和 ClosingDate 之外的所有变量都是因子变量。例如，NameOfCustomer可以是“Apple”，货币“Dollar”，州可以是“Alaska”，“Industry”等等。可以是技术，付款期限可以是 15、30 或 60 天。如果发票已在到期日支付，则“已关闭” = 0。如果发票迟付 2 天，则“关闭” = -2 并且如果提前 2 天付款，则“关闭” = 2.我想生成一个模型，其中“Closed”是响应变量，其他是回归变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/646347/choice-of-regression</guid>
      <pubDate>Thu, 02 May 2024 09:02:41 GMT</pubDate>
    </item>
    <item>
      <title>比较离散数据的均值</title>
      <link>https://stats.stackexchange.com/questions/646304/compare-means-for-discrete-data</link>
      <description><![CDATA[我有两组观察结果，分别对应于两位不同希腊作者的短指六音步单词数。直方图具有漂亮的钟形形状，但数据不正常：一首诗中只能有离散数量的单词。它也不是泊松分布：方差小于均值（根据经验，一首诗不少于 4 个单词且不超过 12 个单词）。

有哪些方法可以比较两种均值以确定它们是否显着不同？
我正在考虑使用卡方来比较 2 个分布，但是这样，我们似乎将 5 字行和 6 字行视为分类数据（这并非完全没有意义，但很尴尬）。
另一种选择是计算每 n 行（例如 5 行）的均值，然后应用 z 检验或 t 检验（通过中心极限定理）。
然而，这两种解决方案似乎都有些牵强。有更优雅的解决方案吗？
更新。根据下面评论的建议，我添加了 Shapiro 测试的结果和 qq-plot。
a) Agronautica 样本返回的 Shapiro-Wilk 正态性检验
W = 0.94682，p 值 = 2.056e-12；对于《伊利亚特》样本 -- W = 0.95116，p 值 = 8.582e-12
b) 两个样本的 QQ 图看起来相似：

upd2：添加每个样本的计数表（第一行是一首诗中的单词数）
iliad_sample
4 5 6 7 8 9 10 11 12
13 33 115 128 124 69 13 3 2
argo_样本
4 5 6 7 8 9 10 11
22 67 136 149 85 32 7 2]]></description>
      <guid>https://stats.stackexchange.com/questions/646304/compare-means-for-discrete-data</guid>
      <pubDate>Wed, 01 May 2024 19:07:14 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该将数据解释为噪音</title>
      <link>https://stats.stackexchange.com/questions/646300/should-i-interprete-data-as-noise-or-not</link>
      <description><![CDATA[我正在解决 3 个类别的分类问题。以下是这些类在前两个主轴上的样子。

我对 SVM 模型进行了微调，可实现的最佳性能为 50%。通过始终预测 3 个类别中的一个，我达到了 43%。我的问题是：

因为我（用眼睛）清楚地看到数据是线性可分离的 - 即使有噪音并且 SVM 的性能不再增加，任何其他方法（如 NN 或 Tree）是否可以取得更好的分数？或者即使它们也不会优于 SVM。
如果没有，您认为有没有办法在不修改数据统计属性的情况下减少数据中的噪音？

编辑：在 whuber 回复后，我根据前两个主轴绘制了密度。我注意到这些类在输入空间维度上并不是那么可分离。
]]></description>
      <guid>https://stats.stackexchange.com/questions/646300/should-i-interprete-data-as-noise-or-not</guid>
      <pubDate>Wed, 01 May 2024 18:28:36 GMT</pubDate>
    </item>
    <item>
      <title>变量选择策略</title>
      <link>https://stats.stackexchange.com/questions/646260/variable-selection-strategies</link>
      <description><![CDATA[我想在创建模型的背景下了解有关变量选择的当前最佳实践方法的更多信息。我对套索、引导计算变量包含频率等现代方法没有太多经验，并且一直对使用逐步选择方法感到内疚 - 主要是在预测环境中，但想改变这一点。通过阅读，我得到的总体感觉是，数据驱动的变量选择（有偏差的系数、小 SE/p 值等）引起的所有问题都是因为人们正在测试许多不同的模型而发生的。如果模型是预先指定的并且在评估后没有更改，那么这些不会是问题吗？
如果模型可以大致分为：

解释/因果 - 变量选择应仅由背景知识/理论驱动，并且最好得到有向非循环图的支持。该模型是预先指定的并且不会改变。您希望能够解释所得系数的“效果”。

预测 - 在这里您可以从许多潜在模型中选择一个，因为您只真正关心预测性能，而不关心单个系数。通常，由于这个原因，不会预先指定模型。因此，像套索这样的东西就可以了，因为它提供了一些变量选择元素以及优化预测性能（但我的理解是你不能轻易解释套索系数）。

描述性 - 包含 1. 和 2. 的元素 - 您对预测感兴趣，但也对系数“效果”的解释感兴趣。在这里您还可以从众多潜在模型中选择一种。我有兴趣知道在这种情况下进行变量选择的良好通用指南是什么？我找到的最接近的解决方案是计算引导包含频率并选择那些最常出现（达到某个阈值）的变量。或者这也不能否定问题吗？


任何提示将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/646260/variable-selection-strategies</guid>
      <pubDate>Wed, 01 May 2024 00:35:00 GMT</pubDate>
    </item>
    <item>
      <title>渐近无偏+渐近零方差=一致性？</title>
      <link>https://stats.stackexchange.com/questions/646259/asymptotic-unbiasedness-asymptotic-zero-variance-consistency</link>
      <description><![CDATA[此处，Ben 表明无偏估计量 $\hat渐近方差为零的参数 $\theta$ 的 \theta$ 收敛于 $ 的概率\theta$。也就是说，$\hat\theta$ 是 $\theta$ 的一致估计量。
我们应该能够将条件放宽到渐近无偏性，这是有道理的：$\underset{n\rightarrow\infty}{\lim} \mathbb E\left[\hat\theta_n - \theta\right] = 0$。这似乎符合估计器接近真实参数值的精神......
...但是数学以前就让我感到惊讶。
我们可以将条件放宽到渐近无偏吗？证据是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/646259/asymptotic-unbiasedness-asymptotic-zero-variance-consistency</guid>
      <pubDate>Wed, 01 May 2024 00:32:23 GMT</pubDate>
    </item>
    <item>
      <title>分层分析、dbscan 或 K-means 对两组 GPS 数据进行聚类分析</title>
      <link>https://stats.stackexchange.com/questions/646305/hierarchical-analysis-dbscan-or-k-means-for-cluster-analysis-of-two-groups-of</link>
      <description><![CDATA[我有 400 公顷场地上 2 个不同组的 2 年 GPS 数据，每个不同的“名称”(150) 属于组“a”或“b”，每个名称都有不同数量的 GPS 数据，并且每个组有不同数量的个体。我有属于 a 组或 b 组的不同个体的平均坐标。我有 1 个 df，有 4 列：名称、组、平均纬度、平均经度。

我正在尝试在组 a 和组 b 内找到每个组内的任何集群（以识别任何牛群）。

我还想看看a组和b组之间是否存在聚类，以分析其中是否存在交互。簇大小和距离未知。


R 中的分层分析、dbscan 或 K-means 是否最能帮助我实现这一目标？我是否正确，无论我使用哪种分析，我都会使用每个名称的平均纬度和经度，如下所示？我正在阅读 R 中的 GPSeqClus，它似乎更适合 GPS 数据，但这远远超出了我的范围。
# 选择经度和纬度
坐标 &lt;- 平均值坐标[, c(“长”, “纬度”)]
# 进行层次聚类
hc &lt;- hclust(dist(坐标))

数据示例：
struct(list(name = c(“5002”、“1003”、“1206”、“0044”、“0003”),
               组＝c(“a”、“a”、“a”、“b”、“b”)，
               纬度 = c(50.406116716098, 50.4025135598379, 50.4029167297529,
                        50.409181401875, 50.3945484759622),
               长 = c(-4.89126066209428, -4.88438821091041, -4.88681572688751,
                        -4.84956106473437,-4.88448928953403)),
          row.names = c(1L, 3L, 4L, 5L, 6L), class = &quot;data.frame&quot;)

带时间戳的原始数据
结构(列表(lat = c(50.39761959, 50.39757382, 50.39760433,

50.39742123、50.39768063、50.39740597、50.39757382、50.39769589、
50.39763485, 50.39763485), lng = c(-4.888685435, -4.888639658,
-4.888685435, -4.888746471, -4.88860914, -4.888883803, -4.888670176,
-4.88860914、-4.888563363、-4.888181888), time_stamp = c(“2021年10月15日00:21”,
“2021年10月15日00:50”、“2021年10月15日01:51”、“2021年10月16日02:21”、“2021年10月16日02:51”、
“2021年10月17日03:21”、“2021年10月17日03:51”、“2021年10月16日04:21”、“2021年10月17日04:51”、
“2021 年 10 月 17 日 05:21”)，名称 = c(“5002”，“5002”，“5002”，“5002”，
“1003”、“1003”、“1003”、“0044”、“0044”、“0044”)，
品种 = c(&quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot; ；b”
)), row.names = c(NA, -10L), class = c(“data.table”, “data.frame”
), .internal.selfref = &lt;指针: 0x000001ad71d8aa60&gt;)
很难理解如何解决这个问题！ （完全初学者）。]]></description>
      <guid>https://stats.stackexchange.com/questions/646305/hierarchical-analysis-dbscan-or-k-means-for-cluster-analysis-of-two-groups-of</guid>
      <pubDate>Tue, 30 Apr 2024 20:02:55 GMT</pubDate>
    </item>
    </channel>
</rss>