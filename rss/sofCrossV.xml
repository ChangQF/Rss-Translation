<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 01 Aug 2024 15:16:06 GMT</lastBuildDate>
    <item>
      <title>我可以直接使用模型的估计值而不考虑 p 值吗？</title>
      <link>https://stats.stackexchange.com/questions/652150/can-i-use-the-estimate-of-a-model-directly-without-considering-the-p-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652150/can-i-use-the-estimate-of-a-model-directly-without-considering-the-p-value</guid>
      <pubDate>Thu, 01 Aug 2024 12:43:03 GMT</pubDate>
    </item>
    <item>
      <title>随机森林：MSE 和 R2 较好，但交叉验证结果较差</title>
      <link>https://stats.stackexchange.com/questions/652148/random-forest-good-mse-and-r2-but-poor-cross-validation-results</link>
      <description><![CDATA[我使用标准缩放器构建、预处理和清理（na/0s、winsorise、log 等）一些特征并对其进行标准化。
如果我仅使用平均值计算基线 MSE，我会得到 8.22
简单线性回归的 MSE 为 7.15，R2 为 0.13
具有 20 个估计量的随机森林模型的 MSE 为 3.07，R2 为 0.62 - 这似乎很奇怪。
因此，我尝试使用相同的随机森林模型进行 k 倍交叉验证，并得到了一些非常糟糕的结果：
交叉验证分数：[0.02259823 -0.70599662 -0.12186488 -0.18245173 -0.33035053]
平均 CV 分数：-0.2636131047737679
CV 分数的标准差：0.24849696694857612

在此阶段我应该关注什么来排除模型故障？不确定该走哪条路。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652148/random-forest-good-mse-and-r2-but-poor-cross-validation-results</guid>
      <pubDate>Thu, 01 Aug 2024 12:24:54 GMT</pubDate>
    </item>
    <item>
      <title>对数正态分布和 Galton Watson 过程</title>
      <link>https://stats.stackexchange.com/questions/652147/lognormal-distribution-and-galton-watson-process</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652147/lognormal-distribution-and-galton-watson-process</guid>
      <pubDate>Thu, 01 Aug 2024 12:19:50 GMT</pubDate>
    </item>
    <item>
      <title>生长曲线分析建议</title>
      <link>https://stats.stackexchange.com/questions/652146/growth-curve-analysis-advice</link>
      <description><![CDATA[我对生长曲线模型还不熟悉，需要一些指导。我有大约 50,000 只羊羔的数据，每只羊羔都有出生体重，并在出生后大约 30、60、90 和 120 天进行了两次额外测量。我想应用 Logistic、Gompertz 和 von Bertalanffy 等生长曲线模型。
我有一些顾虑：
我能否同时使用天数和所有动物记录进行生长曲线分析，还是需要计算单个动物的 A 和 K 等参数？
如果需要单独计算，每只动物进行三次测量是否足够？
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/652146/growth-curve-analysis-advice</guid>
      <pubDate>Thu, 01 Aug 2024 12:16:42 GMT</pubDate>
    </item>
    <item>
      <title>寻求最佳统计检验方法建立截止值以过滤 NGS 数据中的假阳性突变</title>
      <link>https://stats.stackexchange.com/questions/652145/seeking-the-best-statistical-test-to-establish-cutoff-for-filtering-false-positi</link>
      <description><![CDATA[我有一个程序，可以调用患者 DNA 序列中的突变。虽然该测试的灵敏度为 100%，但它会产生大量假阳性 (FP)。
我开发了一种使用两个参数识别 FP 突变的方法。为简单起见，我将解释其中一个。
在对 DNA 进行测序时，测序机会产生 DNA 读数。例如：
ATGCATGTCA 是一个包含 10 个碱基的读数。

测序机还为每个碱基提供质量分数 (Q 分数)。 Q 分数以对数形式定义，与碱基调用错误概率 (P) 相关：

Q = − 10 log10 P

例如，如果某个碱基的 Q 分数为 30 (Q30)，则这相当于 1000 次中发生 1 次错误碱基调用的概率。
当与参考基因组相比，有大量碱基支持突变时，即可识别出突变。例如，考虑 10 个读取，其中 5 个读取支持突变，5 个读取支持野生型：
ATGCACGTCA
ATGCACGTCA
ATGCACGTCA
ATGCACGTCA
ATGCACGTCA
ATGCATGTCA
ATGCATGTCA
ATGCATGTCA
ATGCATGTCA
我观察到，在真阳性 (TP) 事件中，支持突变的碱基的平均 Q 分数与支持野生型的碱基的平均 Q 分数非常相似。然而，在 FP 事件中，支持突变的碱基的平均 Q 分数明显低于（由于机器错误）支持参考的碱基的平均 Q 分数。
以下图表说明了这一观察结果：

X 轴：突变频率（支持突变和参考的读数分布）。
Y 轴：平均 Q 分数的差异（REF - ALT）。
（忽略蓝点）。
我需要一个测试来帮助我建立最佳截止值，因为这是我使用训练数据进行的分析，所以我知道哪些是 TP 和 FP，但在实分析中，我不会知道这一点。
我需要一个测试来帮助建立最佳截止值，因为这个分析是使用训练数据进行的，我知道哪些是 TP 和 FP，但在实分析中，我不会有这些信息。
我的方法必须非常保守，因为我想尽可能地减少误报。真正例 (TP) 对我们来说非常重要，我们不想应用任何删除 TP 的方法。
我找到了一个程序，它可以为这个特定的分析计算 Mann-Whitney-Wilcoxon 秩和检验。此处对此进行了解释：GATK 秩和检验。当两个平均值相似时，此 Z 分数返回 0，当支持 ALT 的读数的平均 Q 分数较低时，返回较低的值。但是，这种统计测试对我不起作用。请参阅下一个图：

一些 TP 事件的 Z 分数非常低，我不知道为什么。图中的所有事件至少有 &gt;1000 次读取，这意味着两个组的平均值至少有 500 次事件。 SD 也不能解释这个低 Z 分数。

所以我的问题是，建立截止值并过滤掉 FP 突变的最佳统计测试是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652145/seeking-the-best-statistical-test-to-establish-cutoff-for-filtering-false-positi</guid>
      <pubDate>Thu, 01 Aug 2024 11:48:04 GMT</pubDate>
    </item>
    <item>
      <title>评估已知矩阵近似的成功率</title>
      <link>https://stats.stackexchange.com/questions/652142/estimating-the-success-of-an-approximation-of-a-known-matrix</link>
      <description><![CDATA[我试图用“估计”矩阵$A&#39;$近似已知的$N\times N$矩阵$A$。问题是，如何量化此近似中的误差 - $A$和$A&#39;$之间的差异。
如果$A$和$A&#39;$是单个数字，这个问题就很简单了。但是，当数据为矩阵形式时，误差的含义变得更加模糊。
我知道 RMS 和矩阵范数，但使用它们来量化估计误差存在问题，因为它们取决于数据的动态范围 - 如果矩阵值在 $0-1000$ 范围内，则 RMS 值 $0.5$ 不会说明任何有用信息；无论 RMS 是多少，矩阵元素 $a_{ij}$ 和 $a_{ij}&#39;$ 之间可能存在显著差异。我认为矩阵范数遇到了完全相同的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/652142/estimating-the-success-of-an-approximation-of-a-known-matrix</guid>
      <pubDate>Thu, 01 Aug 2024 10:34:41 GMT</pubDate>
    </item>
    <item>
      <title>规范化（自动缩放规范化、Z 分数规范化）改变相关结果 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/652141/normalization-autoscaling-normalization-z-score-normalization-changes-correla</link>
      <description><![CDATA[我正在尝试执行 Spearman 相关性。我在标准化（自动缩放）之前和之后得到了不同的结果。我读了一些帖子，说标准化不会影响相关性结果。

library(POMA)
library(ggstatsplot)

# 这是标准化之前的示例
ggcorrmat(
data = data.frame(test_Not_Normalized),
colors = c(&quot;#B2182B&quot;, &quot;white&quot;, &quot;#4D4D4D&quot;),
title = &quot;Not Normalized&quot;,
type = &quot;spearman&quot;, # 或 &quot;robust&quot; 用于稳健相关性估计
ggtheme = ggplot2::theme_bw()
)



# 这是标准化之后的示例
normalized &lt;- test_Not_Normalized %&gt;% 
PomaNorm(method = &quot;auto_scaling&quot;)
test_Normalized &lt;- t(as.data.frame(normalized@assays@data@listData))

ggcorrmat(
data = data.frame(test_Normalized),
colors = c(&quot;#B2182B&quot;, &quot;white&quot;, &quot;#4D4D4D&quot;),
title = &quot;Normalized&quot;,
type = &quot;spearman&quot;, # 或 &quot;robust&quot; 用于稳健相关性估计
ggtheme = ggplot2::theme_bw()
)

这里是 link 以获取生成的图表。
我想知道为什么我得到不同的结果，或者哪一个最适合用于下游分析。]]></description>
      <guid>https://stats.stackexchange.com/questions/652141/normalization-autoscaling-normalization-z-score-normalization-changes-correla</guid>
      <pubDate>Thu, 01 Aug 2024 10:13:12 GMT</pubDate>
    </item>
    <item>
      <title>图像分类中的分数级融合</title>
      <link>https://stats.stackexchange.com/questions/652140/score-level-fusion-in-image-classification</link>
      <description><![CDATA[我想使用多数投票和软投票，但我找不到它们的数学方程式。你能帮帮我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652140/score-level-fusion-in-image-classification</guid>
      <pubDate>Thu, 01 Aug 2024 09:51:56 GMT</pubDate>
    </item>
    <item>
      <title>绘制/建模包含大量小值的直方图</title>
      <link>https://stats.stackexchange.com/questions/652139/plotting-modelling-a-histogram-with-large-bins-of-small-values</link>
      <description><![CDATA[我想知道一些最佳实践或方法，例如，如下图所示，低值箱最常见，但您对整个分布感兴趣。
这是原始数据的视觉效果：

当我们采用logy时，我们可以看到在更高的值中存在更多潜在的有趣行为。但现在轴使得解释更加困难。

这是一个相当广泛的问题，但是

我们如何对这样的分布进行建模？
我们可以将多个分布拟合到对数直方图中吗？

原始数据集可以在这里找到：
https://www.kaggle.com/datasets/wilomentena/uk-government-petitions
该图用于未被驳回的请愿]]></description>
      <guid>https://stats.stackexchange.com/questions/652139/plotting-modelling-a-histogram-with-large-bins-of-small-values</guid>
      <pubDate>Thu, 01 Aug 2024 09:47:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么 sem() 与 lavvan 和 lm() 中的线性回归结果不同？</title>
      <link>https://stats.stackexchange.com/questions/652138/why-different-results-for-linear-regression-in-sem-from-lavvan-and-lm</link>
      <description><![CDATA[感谢您阅读本文。
我是一名学生，正在尝试更多地了解社会科学问题的统计数据。我试图在 R 中建立 {lavvan} 中的 sem() 函数和 {stats} 中的 lm() 函数之间的等价性，以进行具有一个结果和一个预测变量的简单线性回归，这两个预测变量都不是潜在变量。但是，即使我可以为模型获得相同的参数估计值，无论我使用哪个估计器，估计的标准误差都会略有不同。下面附上一个例子：
#加载库
library(lavaan)

#创建数据框
set.seed(1231)
n &lt;- 100 #观察值数量

X &lt;- rnorm(n, mean = 50, sd = 10)
Y &lt;- rnorm(n, mean = 65, sd = 8)

df &lt;- data.frame(X, Y)

#使用 lm() 函数
lm &lt;- lm(Y ~ X, data = df)
summary(lm)

#使用 lavaan 的 sem() 函数
model_sem &lt;- &#39;Y~X&#39;
sem &lt;- sem(model_sem, estimator = &quot;ML&quot;, se = &quot;standard&quot;, data = df)
summary(sem, nd = 7)

当前示例的结果：

来自 lm() 输出

 估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 67.30819 4.37739 15.38 &lt;2e-16
X -0.04116 0.08571 -0.48 0.632 


来自 sem() 输出

回归：
估计 Std.Err z 值 P(&gt;|z|)
Y ~ 
X -0.0411622 0.0848524 -0.4851035 0.6276029

参数估计相等，但参数的 SE 和 p 值略有不同。我还使用 {stats4} 中的 vcov() 函数检查了两个模型的方差-协方差矩阵。
vcov(lm)[c(&quot;X&quot;),c(&quot;X&quot;)]
[1] 0.00734687
vcov(sem)[c(&quot;Y~X&quot;),c(&quot;Y~X&quot;)]
[1] 0.007199932

我尝试手动计算 lm() 输出中的方差-协方差矩阵并成功完成。但是，我找不到从 sem() 中提取观察到的（或预期的）信息矩阵或计算 lavaan 文档中使用的对数似然函数的函数。在这种特定情况下，是否有可能实现两者之间的等价性？为什么（我哪里做错了）或者为什么不（有什么区别，是模型估计和规范还是仅仅是因为包）？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652138/why-different-results-for-linear-regression-in-sem-from-lavvan-and-lm</guid>
      <pubDate>Thu, 01 Aug 2024 09:22:58 GMT</pubDate>
    </item>
    <item>
      <title>关于方差公式的澄清[重复]</title>
      <link>https://stats.stackexchange.com/questions/652136/clarification-on-variance-formula</link>
      <description><![CDATA[可以使用两个公式来计算方差。一个是除以 n，另一个是除以 n-1。因此，我的问题是

我们通过除以 (n) 和 (n-1) 得到的结果是否相同？
示​​例]]></description>
      <guid>https://stats.stackexchange.com/questions/652136/clarification-on-variance-formula</guid>
      <pubDate>Thu, 01 Aug 2024 09:02:07 GMT</pubDate>
    </item>
    <item>
      <title>在营养替代分析中，为什么只有两种摄入量，但营养摄入量却以百分比建模？</title>
      <link>https://stats.stackexchange.com/questions/652134/in-nutritional-substitution-analysis-why-is-nutrient-intake-modeled-as-a-percen</link>
      <description><![CDATA[我在下面的文章中看到了营养替代分析的建模方法。
营养流行病学中的替代分析：谨慎行事
简而言之，你可以做下面的建模。这里，α1表示每份A替代B的效果大小。
f(Y)~α1×A＋α2×B＋α3×(A＋B＋C)
我的问题是，如果模型中没有C，即只有两次摄入（当它们互相替代时），这种方法有效吗？
f(Y)~α1×A＋α3×(A＋B)
另一篇论文使用了百分比。它探讨了茶和咖啡的替代。
咖啡还是茶？一项关于咖啡和茶摄入量与男性和女性总体和特定原因死亡率之间关系的前瞻性队列研究
建模为f(Y)~α1×茶/(茶+咖啡)+α3×(茶+咖啡)。也就是说，α1 是茶摄入量占茶和咖啡总摄入量的百分比。
该论文声称，使用百分比而不是连续值的原因是茶和咖啡摄入量是非线性的，而不是传统的负线性相关性。

标准替代分析假设暴露变量与疾病风险/死亡率之间存在线性关系 [18]，因此可以估计等量替代（例如，用一杯咖啡代替一杯茶）的效果。由于与咖啡和茶的关联显着非线性（参见“结果”），因此这里使用的方法是计算茶占每天饮用的咖啡和茶总杯数的百分比。这个变量被分类并用于多变量分析，同时还控制了咖啡和茶的总摄入量。

这里我不太明白，如果只有两次摄入的模型也有效，那么直接建模和百分比之间有什么区别。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652134/in-nutritional-substitution-analysis-why-is-nutrient-intake-modeled-as-a-percen</guid>
      <pubDate>Thu, 01 Aug 2024 07:31:52 GMT</pubDate>
    </item>
    <item>
      <title>对于两个相关性较弱的变量，且简单回归没有显著的预测率，下一步的研究步骤是什么？</title>
      <link>https://stats.stackexchange.com/questions/652092/between-two-variables-with-weak-correlations-and-no-significant-prediction-rate</link>
      <description><![CDATA[我正在努力利用收入等级来确定犯罪率和经济不平等之间的关联。我发现一些犯罪率与不同收入等级家庭的犯罪率相关性很弱，或者几乎中等。我还发现，使用简单线性回归根据不同收入等级家庭的犯罪率（相关值最大）来预测犯罪率并不能显著预测犯罪率。例如，收入在 0-10,000 美元范围内的家庭百分比与入室盗窃的相关值约为 0.32，但该家庭百分比对入室盗窃率的预测值并不显著。下一步的统计研究步骤是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652092/between-two-variables-with-weak-correlations-and-no-significant-prediction-rate</guid>
      <pubDate>Wed, 31 Jul 2024 15:16:14 GMT</pubDate>
    </item>
    <item>
      <title>使用 LME4 建模干预研究，参与者仅嵌套在一个组中的子组中</title>
      <link>https://stats.stackexchange.com/questions/652075/modelling-intervention-study-using-lme4-and-participants-are-nested-in-subgroups</link>
      <description><![CDATA[我们使用以下变量进行了行为改变现场实验：

两个时间点（T0，T1）
两组（干预组与对照组）
个人 ID（第 1 组中 n = 62，第 2 组中 n = 53）
研讨会 ID（8 个研讨会）

我们正在使用此模型分析 lme4 中的数据：
lmer(DV_T1 ~ 1 + group + DV_T0 + (1|workshop_id), data=df)

但是，只有干预参与者嵌套在子组/workshopID 中（而不是对照组参与者），因此为了模拟 workshopID 的随机效应，我们为所有对照组参与者创建了一个假子组。这种随机效应结构（所有对照组参与者都属于同一个“研讨会 ID”）可能会反映出主组效应（干预组与对照组），从而掩盖干预组的部分主效应。
您认为这是一个问题吗？是否有办法以不同的方式对随机子组效应进行建模？]]></description>
      <guid>https://stats.stackexchange.com/questions/652075/modelling-intervention-study-using-lme4-and-participants-are-nested-in-subgroups</guid>
      <pubDate>Wed, 31 Jul 2024 11:22:22 GMT</pubDate>
    </item>
    <item>
      <title>确定两组线（预矢量）的方向是否不同</title>
      <link>https://stats.stackexchange.com/questions/652021/determine-if-two-sets-of-lines-pre-vectors-are-different-in-their-orientation</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652021/determine-if-two-sets-of-lines-pre-vectors-are-different-in-their-orientation</guid>
      <pubDate>Tue, 30 Jul 2024 16:24:44 GMT</pubDate>
    </item>
    </channel>
</rss>