<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 19 Oct 2024 06:21:40 GMT</lastBuildDate>
    <item>
      <title>令人困惑的逻辑回归模型输出</title>
      <link>https://stats.stackexchange.com/questions/655994/confusing-logistic-regression-model-output</link>
      <description><![CDATA[我正在使用加权逻辑回归模型分析来自样本量大（&gt;88,000）的国家数据集的数据，以预测基于各种组成员身份的结果的概率。我想将每个组成员身份与不属于该组的成员进行比较，而不是与定义的参考组进行比较（例如，添加所有虚拟编码变量，而不是忽略参考变量）。对于我研究的大多数健康结果，这种方法效果很好，但其中一个结果返回的结果是，属于每个详尽且互斥的组的成员的 OR 为 &gt;1，CI 不超过零。我的解释是，与不属于该组的成员相比，每个组的几率都更高……这在逻辑上说不通。
我正在使用 SAS 9.4 surveylogistic 程序，并指定 NOMCAR 来解释缺失数据。域、权重、层、集群和模型都经过了三重准确性检查，看起来不错。所有单元格大小均大于 10。模型收敛且无错误。当我看到加权分析的结果时，所有输出看起来都很合理，并且相对接近我作为诊断的一部分运行的未加权分析的结果，尽管其中一个组在未加权分析中并不显著（未加权 OR 1.06；加权 OR 1.80，CI 1.11-2.9）
我试图确定问题是否在于在没有指定参考组的情况下进行比较（如果是这样，我预计会出现脊状误差，但没有发生）或者模型中的权重是否能够以某种方式将事物转移到这个奇怪的结果。或者相反，如果我的解释有问题，而输出没问题。任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655994/confusing-logistic-regression-model-output</guid>
      <pubDate>Sat, 19 Oct 2024 03:13:18 GMT</pubDate>
    </item>
    <item>
      <title>使用列范数限制精度矩阵的谱范数</title>
      <link>https://stats.stackexchange.com/questions/655993/bound-the-spectral-norm-of-the-precision-matrix-using-column-wise-norm</link>
      <description><![CDATA[在本文中，作者获得了关于谱范数的精度矩阵的收敛速度，（定理 1，第 7 页）
$$
\|\hat{\Omega}-\Omega\|_2 \le CM_p s_p\sqrt{\frac{\log p}{n}}
$$
其中$\|\Omega\|_{L1}=\underset{1\le j\le p}{\max}\sum_{i=1}^{p}|\omega_{ij}|\le M_p$ 和 $\underset{1\le j\le p}{\max}\sum_{i=1}^{p}1\left(\omega_{ij}\neq 0\right)\le s_p$。
他们通过控制精度矩阵的列来证明这个定理（第 37 页，不等式 (9)）：
$$
|\hat{\beta}_{S_i}-\omega_{S_i}|\le C\sqrt{\frac{\log p}{n}}
$$
其中 $\hat{\beta}_i$ 是 $\hat{\Omega}$ 的第 i 列。
我们如何使用逐列边界来控制收敛速度？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655993/bound-the-spectral-norm-of-the-precision-matrix-using-column-wise-norm</guid>
      <pubDate>Sat, 19 Oct 2024 02:44:14 GMT</pubDate>
    </item>
    <item>
      <title>二进制时间序列数据的置信带</title>
      <link>https://stats.stackexchange.com/questions/655991/confidence-bands-for-binary-time-series-data</link>
      <description><![CDATA[上下文：我有二进制数据 $x_{it}\in\{0,1\}$，其中 $i\in\{1,...,N\}$ 表示试验索引，而 $t\in\{1,...,T\}$ 表示时间索引（在试验之间独立；不在时间之间独立）。这是我运行的模拟（$N$ 次，每次 $T$ 个周期），我没有对随机过程 $\{x_{\cdot t}\}_{t=1}^T$ 的明确描述。
我的问题：我可视化了 $x_{\cdot,t}$ 在时间 $t$ 之后始终保持在 1 的频率，并绘制了每个 $t$ 的图表。我还想绘制一个“置信区间”，但我不知道如何/是否可以做到这一点。
我目前的工作：对于每个$(i,t)$，$S_{it} = \prod_{\tau=t}^{T}x_{i\tau}$ 编码事件，即对于所有$\tau\geq t$，$x_{i\tau}=1$。我在每个 $t$ 上绘制了 $\frac{1}{N}\sum_{n=1}^N 1\{S_{\cdot t}=1\}$，以可视化 $x_{\cdot t}$ 在 $t$ 时间之后保持为 1 的频率。（这正确吗？）关于可视化置信区间，我曾尝试查找有关如何对“生存曲线”进行可视化的指南（因为我所绘制的内容似乎与此相关），但我不知道它们是否适用（即使如此，我也不完全确定如何将迄今为止找到的方法转化为我的问题）。任何指导都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655991/confidence-bands-for-binary-time-series-data</guid>
      <pubDate>Fri, 18 Oct 2024 22:58:48 GMT</pubDate>
    </item>
    <item>
      <title>高效 Net V2 M ONNX 模型在小输入上的推理速度明显较慢</title>
      <link>https://stats.stackexchange.com/questions/655990/efficient-net-v2-m-onnx-model-infers-significantly-slower-on-small-input</link>
      <description><![CDATA[当我将 Efficient net v2 m 模型从 Pytorch 转换为 Onnx 以适应不同大小的输入时，我注意到一种奇怪且无法解释的行为。我希望从这个社区找到对我的观察的解释。
在我的 RTX 4090 上，1280X1280 大小图像上的 ONNX 模型在 35 毫秒内推断出批处理大小为 1。当我将图像大小缩小到大约 192X192（批处理大小相同为 1）时，运行时间几乎保持不变。这是可以理解的，因为固定开销占主导地位，例如初始化时间、线程池预热、与 GPU 之间的低效数据传输，最重要的是，计算库针对 GPU 上的矢量化和 SIMD 指令进行了优化。
然而，令人困惑的是，一旦我开始将输入图像大小减小到 192X192 以下，运行时间就会急剧增加。对于 64X64 图像，批处理大小为 1 时运行时间为 &gt;100ms。我完全理解为什么在较小的图像上推理不应该更快，但我不明白为什么它会更慢（而且慢得多）。
当我增加较小图像的批处理大小时，每批的运行时间会大幅改善（不仅仅是每幅图像的运行时间）。对于批处理大小为 16 的图像，推理 192X192 图像每批需要 25 毫秒（每幅图像不到 2 毫秒），而批处理大小为 1 时则需要 &gt;100ms。同样，我对此没有任何解释。固定开销和优化的 SIMD 矢量化将决定每幅图像的摊销运行时间应该随着批处理大小的增加而改善。但是，我观察到整个批次的运行时间也得到了改善。
对于较大的图像（例如 1280X1280），增加批次大小会增加每个批次的运行时间（尽管是亚线性的，这是完全可以预料的 - 随着批次大小的增加，每个图像的运行时间仍然会缩短到一定限度，之后，对于几乎无法放入 GPU 内存的更高批次大小，每个图像的运行时间也会增加约 10%）。
但是在 CPU 上运行时，处理时间会随着输入大小的增加而单调增加，正如预期的那样。
当我要求它对所有输入进行处理时，我已经验证了 ONNX 模型在 GPU 上成功运行。事实上，对于小输入，CPU 推理时间比 GPU 更快（这是可以理解的，因为有固定的 I/O 和其他开销）
注意：由于我在整个实验过程中将动态轴设置为 None，因此我为具有不同输入大小的同一 torch 模型保存了多个版本的 ONNX 模型。使用或不使用 onnx-sim 几乎不会对运行时间产生影响（处理速度差异小于 10-15%）。我在 C++ 中以 OrtCUDAProviderOptions 作为执行提供程序运行 onnx 模型，使用或不使用 GraphOptimizationLevel 几乎没有区别。
神经网络的输出对于所有输入都符合预期，因此我不希望我的代码中出现任何错误。
TL;DR我的 ONNX 模型对于中等大小图像的运行速度比 GPU 上的小图像更快。对于较小的图像，增加批次大小会大幅减少每批次的处理时间（而不仅仅是 SIMD 并行化所预期的每张图像的摊销时间）。]]></description>
      <guid>https://stats.stackexchange.com/questions/655990/efficient-net-v2-m-onnx-model-infers-significantly-slower-on-small-input</guid>
      <pubDate>Fri, 18 Oct 2024 21:24:44 GMT</pubDate>
    </item>
    <item>
      <title>从探索性数据分析中得出的特征是否会导致 K 折交叉验证不准确？</title>
      <link>https://stats.stackexchange.com/questions/655988/do-features-derived-from-an-exploratory-data-analysis-lead-to-inaccurate-k-fold</link>
      <description><![CDATA[我对探索性数据分析、特征工程和使用 k 倍交叉验证的特征选择之间的相互作用有些困惑。如果有人能给我一些解释，我将不胜感激。
更具体地说，我想知道我尝试使用探索性数据分析找到合适的线性回归模型的情况。
假设我有一个大小为 n 的样本，每个观察值由 k 个变量组成。作为第一步，我将留出一个测试集进行最终模型评估。然后，为了了解我的反应与其他记录变量之间的关系，我会例如查看相关性，绘制数据以查看是否可能存在任何非线性关系。我还会考虑可能的相互作用。然后，我将根据我之前的观察结果创建不同的特征（多项式、平方根、交互等）。为了查看这些添加的特征是否真的改善了与基线相比的模型，我想对用于探索性数据分析的相同数据（即除先前为最终模型评估预留的观测值之外的所有观测值）执行 k 倍交叉验证。但是，我想知道这种方法是否有缺陷，因为我根据我的观察进行了特征工程，其中已经包括用于 k 倍交叉验证的完整数据，即每个步骤中遗漏的折叠。这不会导致数据泄露吗？因为我犯了一个类似的错误，就像我在对整个数据集执行特征工程时一样，即这通常会导致模型产生良好的 k 倍交叉验证结果，但在测试数据上结果不佳吗？如果是这样，检查我设计的特征是否确实相关的正确方法是什么？留出额外的验证集？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655988/do-features-derived-from-an-exploratory-data-analysis-lead-to-inaccurate-k-fold</guid>
      <pubDate>Fri, 18 Oct 2024 20:54:09 GMT</pubDate>
    </item>
    <item>
      <title>关于运行k均值聚类分析的问题</title>
      <link>https://stats.stackexchange.com/questions/655987/question-about-running-k-means-cluster-analysis</link>
      <description><![CDATA[在之前的分析中，我有 3 组受试者 - 组 x 有 35 名受试者，对照组 y 有 25 名受试者，对照组 z 有 25 名受试者。对于每组，我都有 6 种不同的生物标志物水平（我们可以将它们称为生物标志物 a、b、c、d、e 和 f）。我比较了各组之间每种生物标志物的水平，发现没有显著差异。但是，我有理由相信，组 x 中将存在有意义的受试者亚组，这些亚组的一种或多种代谢物水平将与一个或两个对照组不同。对于所有 85 名参与者，我还有其他数据，我认为这些数据可能与构建亚组有关 - 具体来说，我有 7 种不同类型的智商数据（我们将它们称为智商 a、b、c、d、e、f 和 g），以及两个人口统计变量，具体来说是年龄和受教育年限。现在我想要做的是对组 x 运行 k 均值聚类分析，以找到该组中涉及生物标记的任何有意义的子组 - 例如，我可能会发现两个聚类；一个聚类具有高水平的生物标记 d、低智商 b 和低受教育年限（我们称之为聚类 A），另一个聚类具有低水平的生物标记 e、高智商 f 和高年龄（我们称之为聚类 B）。然后，我们的想法是取每个聚类，并将该聚类中涉及的生物标记水平与两个对照组中这些生物标记的水平进行比较。例如，对于簇 A，我将比较组 x 中的生物标志物 d 水平与两个对照组中每个组的生物标志物 d 水平，如果我发现组 x 的生物标志物 d 水平与其中一个或两个对照组不同，那么我可以说组 x 中有一组受试者的生物标志物 d 水平高、智商 b 低、受教育年限低，其生物标志物 d 水平与其中一个或两个对照组不同。然后，​​对于簇 B，我将比较组 x 中的生物标志物 e 水平与两个对照组中每个组的生物标志物 e 水平，如果我发现组 x 的生物标志物 e 水平与其中一个或两个对照组不同，那么我可以说组 x 中有一组受试者的生物标志物 e 水平低、智商 f 高、年龄大，其生物标志物 e 水平与其中一个或两个对照组不同。
上述聚类分析似乎是一条不错的途径。但是，我对聚类分析完全是新手。有人告诉我，x 组中的 35 名受试者不足以运行 k 均值聚类分析，因为如果我对这么小的组运行它，我得到的任何结果很可能只是噪音。所以我需要更多的受试者才能进行聚类分析。不幸的是，我没有更多的 x 组受试者。所以，我想这样做，我想看看这是否是一种回答我的研究问题的有效方法。为了获得更多数据，我将在聚类分析中不仅包括来自 x 组的受试者，还包括来自对照组 y 和 z 的受试者。这样我就可以总共有 85 名受试者进行聚类分析，我想这应该足够了。然后假设我找到了上面提到的相同的两个簇，但包括了所有三个组的参与者（谁知道是否真的如此，但我们只是假设一个例子） - 假设对于簇 A，我们再次具有高水平的生物标志物 d、低智商 b 和低受教育年限，并且假设簇 A 有 12 个来自 x 组的受试者、2 个来自 y 组的受试者和 1 个来自 z 组的受试者；然后对于簇 B，我们再次具有低水平的生物标志物 e、高智商 f 和高年龄，并且簇 B 有 11 个来自 x 组的受试者、3 个来自 z 组的受试者和 1 个来自 y 组的受试者。然后，我想这样做：对于 A 组，我可以从组 x（n=12）中选取 12 名受试者，并将他们的生物标志物 d 水平与对照组 y（n=25）中的生物标志物 d 水平进行比较，然后将其与对照组 z（n=25）中的生物标志物 d 水平进行比较。同样，对于 B 组，我将从组 x（n=11）中选取 11 名受试者，并将他们的生物标志物 e 水平与对照组 y（n=25）中的生物标志物 e 水平进行比较，然后将其与对照组 z（n=25）中的生物标志物 d 水平进行比较。 所以我的问题是，这是否是一种有效且可行的方法，仍然能够运行聚类分析来回答我的研究问题，即 x 组中是否存在有意义的亚组，这些亚组在一个或多个生物标志物的水平上与一个或两个对照组不同。
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/655987/question-about-running-k-means-cluster-analysis</guid>
      <pubDate>Fri, 18 Oct 2024 20:39:41 GMT</pubDate>
    </item>
    <item>
      <title>两个随机变量之间差异的概率区间</title>
      <link>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</link>
      <description><![CDATA[假设 X1 和 X2 是两个随机变量，其中 X1 有 95% 的概率位于区间 [L1, R1] 内，X2 有 95% 的概率位于区间 [L2, R2] 内。这是否意味着 X1 - X2 之差位于区间 [L1 - R2, R1 - L2] 内的概率将超过 95%？此外，X1 和 X2 可以是相关的，也可以是独立的。有人可以澄清概率界限是否适用于这种情况吗？或者这个说法的反例。]]></description>
      <guid>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</guid>
      <pubDate>Fri, 18 Oct 2024 19:35:37 GMT</pubDate>
    </item>
    <item>
      <title>具有反射的离散布朗运动的表达式</title>
      <link>https://stats.stackexchange.com/questions/655982/expression-for-discrete-brownian-motion-with-reflection</link>
      <description><![CDATA[对于具有吸收状态的离散布朗运动，我们可以将位置分布表示为两个二项分布的线性和，如此处所述，其中 +1 和 -1 步的几率为 1:1，此处所述，用于更一般的几率不相等的情况。
具有反射墙的离散布朗运动的情况如何？
假设我们将时间 $t$ 的位置描述为 $X(t)$，起始位置为 $X(0) = 1$。有概率 $p$ 我们向前迈一步 $X(t+1) = X(t) + 1$ ，有概率 $1-p$ 我们向后迈一步 $X(t+1) = X(t) - 1$ ，除非 $X(t) = 0$ ，在这种情况下我们总是向前迈一步。]]></description>
      <guid>https://stats.stackexchange.com/questions/655982/expression-for-discrete-brownian-motion-with-reflection</guid>
      <pubDate>Fri, 18 Oct 2024 19:26:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 包 marginaleffects 进行编码比较和交互</title>
      <link>https://stats.stackexchange.com/questions/655981/coding-comparisons-and-interactions-with-the-r-package-marginaleffects</link>
      <description><![CDATA[我开始学习如何使用 R 包 marginaleffects，并希望得到一些特定应用方面的帮助。
为了说明，我们使用 afex 包中的数据集。变量 phase 是一个具有三个级别的因子：“fup”、“post”和“pre”。变量 age 是连续的。下面是使用 lme4 拟合的模型：
library(afex); library(lme4); library(phia)
data(obk.long, package = &quot;afex&quot;)
options(contrasts = c(&quot;contr.sum&quot;, &quot;contr.poly&quot;))
fm &lt;- lmer(value ~ phase * age + (1|id), data = obk.long)

我想使用 marginaleffects 复制以下七个比较和交互：

对比因子 phase 的前两个级别（“fup”与“post”）
在 phia 中，这是通过以下方式完成的：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), adjustment = &quot;none&quot;)


对比phase的前两个级别，其中age固定在 5.5
在phia中：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), covariates = c(age = 5.5), adjustment = &quot;none&quot;)


age的斜率（在phase的所有级别上取平均值）
在phia中：
testInteractions(fm, pairwise = NULL, slope = &quot;age&quot;, adjustment = &quot;none&quot;)


前两个级别之间的age斜率差异 (&quot;fup&quot; vs. &quot;post&quot;) 的 phase
在 phia 中：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), slope = &quot;age&quot;, adjustment = &quot;none&quot;)


phase 的三个级别之间的综合对比（例如 &quot;fup&quot; - &quot;pre&quot; 和 &quot;post&quot; - &quot;pre&quot;）
在 phia 中：
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))))


phase 三个级别的综合斜率比较（例如，&quot;fup&quot; 与 &quot;pre&quot; 以及 &quot;post&quot; 与 &quot;pre&quot; 的斜率差异）
在 phia 中：
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))), slope = &quot;age&quot;)


固定年龄的 phase 三个级别的综合对比（例如，&quot;fup&quot; - &quot;pre&quot;和“post” - “pre” 在 age = 5.5)
在 phia:
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))), covariates = c(age = 5.5))



我的问题是：如何使用 marginaleffects 包对这七个效应进行编码？]]></description>
      <guid>https://stats.stackexchange.com/questions/655981/coding-comparisons-and-interactions-with-the-r-package-marginaleffects</guid>
      <pubDate>Fri, 18 Oct 2024 18:51:31 GMT</pubDate>
    </item>
    <item>
      <title>在具有对数链接的泊松 GEE 中对二进制结果进行反转编码时，P 值会发生变化，但逻辑 GEE 或 OLS 则不会</title>
      <link>https://stats.stackexchange.com/questions/655975/p-value-changes-when-invert-coding-of-binary-outcome-in-poisson-gee-with-log-lin</link>
      <description><![CDATA[我们在面板数据上运行具有二元结果（是/否）的回归模型。结果非常常见（93.6%=是，n=4231 个观察值中的 3961 个）。我们使用 GEE 模型来解释每个参与者的多个观察值。
当我们运行具有对数链接的泊松 GEE 模型（每个预测变量一个模型）时，p 值会根据结果是正编码（是=1）还是负编码（否=1）而有很大差异，并且某些结果会根据编码而变得重要。但是，当我们在相同变量上运行逻辑 GEE 模型时，基于正编码和负编码的 p 值没有差异。 （注意：对数二项式模型不收敛，因此我们无法测试这一点）。
如果结果的编码可以改变重要性，我们会担心泊松结果的有效性。
1.) 为什么泊松模型会产生不同的逆编码 p 值，但逻辑编码不会产生不同的 p 值？这是否与结果的普遍程度有关（如果编码为 Yes=1）？
2.) 如果使用一致的编码（例如，所有模型的 Yes=1），是否可以使用泊松 GEE 的结果？
模型的示例编码：
model1.poisson.yes = geeglm(formula = consequence_yes ~ binary_predictor1, 
id = uuid,
family = poisson(&quot;log&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

model1.poisson.no = geeglm(formula = consequence_no ~ binary_predictor1, 
id = uuid,
family = poisson(&quot;log&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

model1.logistic.yes = geeglm(formula = consequence_yes ~ binary_predictor1, 
id = uuid,
family = binomial(&quot;logit&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

model1.logistic.no = geeglm(formula = consequence_no ~ binary_predictor1, 
id = uuid,
family = binomial(&quot;logit&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

]]></description>
      <guid>https://stats.stackexchange.com/questions/655975/p-value-changes-when-invert-coding-of-binary-outcome-in-poisson-gee-with-log-lin</guid>
      <pubDate>Fri, 18 Oct 2024 16:02:55 GMT</pubDate>
    </item>
    <item>
      <title>调整因变量的个别值</title>
      <link>https://stats.stackexchange.com/questions/655970/adjusting-individual-values-of-a-dependent-variable</link>
      <description><![CDATA[我有一个数据集，其中包含 600 个脉搏波速度读数，我需要根据每个参与者的平均动脉血压进行调整。我可以得到这样的结果：
m &lt;- lm(pulse_wave_velocity ~ mean_arterial_bp, data = df)

那么我是否可以使用模型中的残差来计算调整后的脉搏波速度，如果是，是否应该将它们添加到截距中？]]></description>
      <guid>https://stats.stackexchange.com/questions/655970/adjusting-individual-values-of-a-dependent-variable</guid>
      <pubDate>Fri, 18 Oct 2024 14:57:17 GMT</pubDate>
    </item>
    <item>
      <title>负二项回归与普通逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/655965/negative-binominal-regression-vs-ordinary-logistic-regression</link>
      <description><![CDATA[我有选举期间的社交媒体数据，其中包含数千名政治人物在社交媒体上的帖子。数据集有许多控制变量，例如日期、关注者数量、视觉效果的存在、是否是热门演员的转发等。
这项研究本质上是关于语言学的。我的目标是测试隐喻相关指标是否与高参与度（喜欢、分享、评论）相关。由于它是社交媒体数据，因此存在高度过度分散。我确认负二项回归是最佳选择。
在用喜欢计数拟合模型后，我注意到该模型在处理参与度非常高或参与度非常低的帖子时遇到了困难。它似乎也有显著的异常值。




考虑到这是高度密集时期的社交媒体数据，我对模型在某些帖子上遇到困难并不感到惊讶。大多数被低估的帖子都包括特殊/耸人听闻的视觉效果、视频或公告，这些都使它们非常高。
由于它们不是虚假数据并且是社交媒体固有的，所以我没有删除它们。主要目标不是建立一个预测参与度的模型，而是看看隐喻指标是否与参与度呈正相关。
我想知道这是否是正常的，因为数据的性质。此外，NBR 是否对我来说是正确的测试，或者我是否应该在将基于百分位数的参与度数据分解为高、中、低参与度后考虑 OLR。]]></description>
      <guid>https://stats.stackexchange.com/questions/655965/negative-binominal-regression-vs-ordinary-logistic-regression</guid>
      <pubDate>Fri, 18 Oct 2024 14:02:35 GMT</pubDate>
    </item>
    <item>
      <title>疾病建模与微生物组建模：结果应该是哪一个？</title>
      <link>https://stats.stackexchange.com/questions/655941/modeling-disease-vs-microbiome-which-should-be-the-outcome</link>
      <description><![CDATA[我有一个与微生物组研究相关的问题，在这个领域，许多研究人员评估疾病组和对照组之间的分类单元丰度是否不同。我经常看到统计模型，其中分类单元作为结果变量，疾病状态作为解释变量。但是，我想知道这种模型是否更适合评估疾病是否影响微生物组，而不是相反。大多数研究人员的目标是找到微生物组影响疾病的证据。鉴于此，该模型是否不合适，使用分类单元作为解释变量，疾病状态作为结果的模型是否更合适？当使用仅包含数值变量且不涉及协变量的线性模型时，等式中的位置（无论是在左侧还是右侧）可能不太重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/655941/modeling-disease-vs-microbiome-which-should-be-the-outcome</guid>
      <pubDate>Fri, 18 Oct 2024 01:10:05 GMT</pubDate>
    </item>
    <item>
      <title>回归模型中每个变量都需要具有统计显著性吗？</title>
      <link>https://stats.stackexchange.com/questions/655938/does-every-variable-need-to-be-statistically-significant-in-a-regression-model</link>
      <description><![CDATA[我最近拟合了一个回归模型 (ARIMAX)，其中有些变量 (3) 具有统计显著性，有些则不显著 (1)。我删除了统计上不显著的变量并重新拟合模型，现在所有变量都具有统计显著性（即新模型有 3 个变量，旧模型有 4 个变量）。
但是，这个新模型（所有变量都具有统计显著性）的表现比旧模型（并非所有变量都具有统计显著性）更差。也就是说，新模型的预测误差比旧模型更严重。
这是统计学中的常见做法吗？如果所有变量都具有统计显著性，选择性能较差的模型是否更可取，还是最好选择性能较好的模型，即使并非所有变量都具有统计显著性。
我知道过度拟合和交叉验证等概念。我使用除过去 6 个月数据之外的所有可用数据训练了这两个模型。我还让这两个模型预测过去 6 个月的可用数据，并将预测值与实际值进行比较。使用旧模型（即并非所有变量都具有统计显著性的模型）我仍然获得了更好的结果。
即使并非所有变量都具有统计显著性，是否可以采用性能更好的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/655938/does-every-variable-need-to-be-statistically-significant-in-a-regression-model</guid>
      <pubDate>Fri, 18 Oct 2024 01:02:57 GMT</pubDate>
    </item>
    <item>
      <title>转换单位，用 extRemes 拟合极值分布时得到不同的结果</title>
      <link>https://stats.stackexchange.com/questions/655986/convert-units-get-different-results-when-fitting-extreme-value-distribution-wit</link>
      <description><![CDATA[我正在使用 fevd() 和 lr.test() 函数通过 extRemes R 包检查降水量。我的主要问题是，当我使用英寸和毫米作为输入数据时，我会得到不同的结果。其次，有时我会收到警告，我想知道它们是否表示采取了不同的路径来优化参数。
下面是一个示例，展示了乘数如何产生不同的结果。此外，如果我将种子设置为 3，则不会产生任何警告。如果将种子设置为 4，则当我使用 location.fun 参数拟合 fevd() 时会产生警告。
library(extRemes)
set.seed(3)
dat &lt;- data.frame(values = rnorm(30, mean = 3, sd = 1.5),
years = 1990:2019)
dat$values25 &lt;- dat$values*25
dat

gev_fit &lt;- fevd(x = values, data = dat, type = &quot;GEV&quot;)
gev_fit25 &lt;- fevd(x = values25, data = dat, type = &quot;GEV&quot;)
gev_fit
gev_fit25

# 拟合非平稳 GEV 分布
gev_fit_loc &lt;- fevd(x = values, data = dat, location.fun = ~years, type = &quot;GEV&quot;)
gev_fit_loc25 &lt;- fevd(x = values25, data = dat, location.fun = ~years, type = &quot;GEV&quot;)
gev_fit_loc
gev_fit_loc25

lr.test(gev_fit, gev_fit_loc)
lr.test(gev_fit25, gev_fit_loc25)

这是我最关心的问题：
第一个 lr.test() 给出的 p 值为 0.7642，第二个报告的值为 1.0，尽管唯一的区别是第二个 &quot;25&quot; 示例中的输入数据乘以了 25。
有人知道为什么会这样吗？我是否忽略了一些显而易见的东西？
其次，如果我运行上述代码但将种子设置为 4，我会收到此警告：

在 log(z) 中：产生了 NaN

在拟合非平稳 GEV 时，但仅适用于“values”，而不是“values25”。有人能提供一些关于这个警告意味着什么的见解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655986/convert-units-get-different-results-when-fitting-extreme-value-distribution-wit</guid>
      <pubDate>Thu, 17 Oct 2024 14:57:56 GMT</pubDate>
    </item>
    </channel>
</rss>