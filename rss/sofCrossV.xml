<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 04 Jan 2025 12:30:59 GMT</lastBuildDate>
    <item>
      <title>识别与平方根过程相关的随机过程的分布</title>
      <link>https://stats.stackexchange.com/questions/659526/identifying-the-distribution-of-a-random-process-associated-to-the-square-root-p</link>
      <description><![CDATA[让 $x(t)$ 成为遵循以下的随机平方根过程
$$dx(t) = (a + bx(t)) dt + c\sqrt{x(t)} dW(t)$$
其中 $W(t)$ 是某些过滤的标准布朗运动。
它有很多名字，但出于本文的目的，我不会提及它们。如果我们定义
$$ \varphi(u;t,h) = \mathbb E\left( e^{u x(t+h)} \mid x(t) \right); \quad u\in \mathbb C$$
那么我可以证明对于 $\Re(u) \leqslant 0$，我们有
$$
\mathbb E(e^{u x(t+h)} \mid x(t) = x ) = 
\frac{1}{\left(1- 2z(h)u
\right)^{\frac k2}}\exp\left(
\dfrac{\lambda(t)x\cdot z(h)u }{1- 2z(h)u}
\right) $$
其中 $z(h) = q(h)e^{bh}\frac{c^2}{4}$，$q(h) = \dfrac{1-e^{-bh}}{b}$，$\lambda(h) = \frac{4q(h)^{-1}}{c^2}$ 和 $k = \frac{4a}{c^2}$。因此，在 $x(t)$ 条件下，我们有
$$
z(h)^{-1} x(t+h) \sim \chi_k^2(\lambda(h)^{-1}x(t))
$$
其中右边是非中心卡方分布，具有 $k$ 自由度和非中心参数 $\lambda = \lambda(h)^{-1}x(t)$。具体来说，我们可以让 $c=2$ 和 $b\to 0$ 恢复平方贝塞尔过程满足
$$
h^{-1} x(t+h) \sim \chi_k^2(h^{-1}x(t))
$$
这是众所周知的。

现在考虑联合过程 $y(t) = \left( \int_{0}^t x(s)ds, x(t) \right)$。然后，我可以证明联合条件特征函数
$$\varphi(u;t,h) = 
\mathbb E\left( e^{u\cdot y(t+h)}\mid y(t) \right); \quad u\in \mathbb C^2 
$$
对于 $y(t) = (y_1, y_2)$ 等于
$$ \varphi(u;t,h) = \frac1 {\left(1- 2z\right)^{\frac k2}}
\exp\left(\dfrac{ \lambda z}
{1- 2 z}y_2\right)\exp(u_1 y_1 + (ah+1)v(u_1))
$$
其中 $v(u_1)$ 是 $\frac 12 c^2 v^2 + bv = u_1$ 的解，并且
\begin{align*}
z(h,u) &amp;= (u_2 - v(u_1))e^{(b + v(u_1)c^2)h}\lambda^{-1}(h,u) \\
\lambda(h,u) &amp;= \frac{4}{c^2}q_0(h,u)^{-1} \\
q_0(h, u) &amp;= \dfrac{1-e^{-(b + v(u_1)c^2)h}}{b + v(u_1)c^2} 
\end{align*&gt;
但是，我无法识别这个联合分布。我最天真的猜测是，它可能是广义卡方分布，如这里所示，但我没有取得太大进展。
有人知道该怎么做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659526/identifying-the-distribution-of-a-random-process-associated-to-the-square-root-p</guid>
      <pubDate>Sat, 04 Jan 2025 12:28:35 GMT</pubDate>
    </item>
    <item>
      <title>伍德泌乳曲线的等效 GLM 公式</title>
      <link>https://stats.stackexchange.com/questions/659525/equivalent-glm-formulation-of-woods-lactation-curve</link>
      <description><![CDATA[在对生产动物的泌乳曲线进行建模时，通常使用 Wood 模型
$$\begin{aligned}
y &amp;\sim \text{Normal}(\mu_i, \sigma^2) \\
\mu_i &amp; = at^{b}\exp(ct)
\end{aligned}$$
，其中 $a$、$b$ 和 $c$ 为参数，$t$ 为时间，以记录产奶量 $y$ 时动物的产奶天数 (DiM) 来记录。该模型通常使用非线性最小二乘法进行拟合。
但是在阅读变换还是链接？ (Henderson &amp; McCulloch, 1990)时，作者将其重写为等效的 Gamma GLM，将原始方程线性化为
$$\begin{aligned}
y &amp;\sim \text{Gamma}(\mu_i, \phi) \\
\log(\mu_i) &amp; = \log(a) + b \log(t) + ct
\end{aligned}$$
其中 $a$、$b$ 和 $c$ 是参数，$t$ 和之前一样是 时间。该模型具有对数链接和色散参数 $\phi$。
我不太明白的是，为什么作者用 $\log(a)$ 来写？
$a$ 看起来像模型截距，它已经在对数链接的 Gamma GLM 中以对数刻度估算出来了。但是，其他参数 $b$ 和 $c$ 也是如此，但它们在等式中没有以 $\log b$ 等形式出现。
我现在所处的位置，给出以下数据
lactation &lt;- data.frame(
Yield = c(0.31, 0.39, 0.50, 0.58, 0.59, 0.64, 0.68, 0.66, 
0.67, 0.70, 0.72, 0.68, 0.65, 0.64, 0.57, 0.48, 
0.46, 0.45, 0.31, 0.33, 0.36, 0.30, 0.26, 0.34, 
0.29, 0.31, 0.29, 0.20, 0.15, 0.18, 0.11, 0.07,
0.06, 0.01, 0.01),
week = seq_len(35)
)

是
m &lt;- glm(yield ~ log(week) + week, data = lactation, family = Gamma(&quot;log&quot;))

模型摘要是
调用：
glm(formula = Yield ~ log(week) + week, family = Gamma(&quot;log&quot;),
数据 = 哺乳期)

系数：
估计标准误差 t 值 Pr(&gt;|t|)
(截距) -1.38596 0.24259 -5.713 2.49e-06 ***
log(周) 1.16805 0.17048 6.852 9.46e-08 ***
周 -0.15724 0.01436 -10.950 2.35e-12 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（Gamma 家族的分散参数取为 0.117285）

零偏差：34 个自由度上的 21.6796
残差偏差：32 个自由度上的 6.1677
AIC：-38.479

Fisher 评分迭代次数：7

以及估计曲线的快速可视化：
library(&quot;ggplot2&quot;)

哺乳 |&gt;
ggplot(
aes(x = week, y = Yield)
) +
geom_point() +
geom_smooth(
method = &quot;glm&quot;,
se = FALSE,
colour = &quot;#e69f00&quot;,
linewidth = 1.5,
formula = y ~ log(x) + x,
method.args = list(family = Gamma(&quot;log&quot;))
)


系数
&gt; coef(m)
(截距) log(week) week
-1.3859636 1.1680544 -0.1572424

与 Henderson &amp; McCulloch (1990) 中报告的一致，所以我认为我的模型是正确的。但我不太明白为什么。
如果我在 R 中正确编写了 GLM，我会更自然地将模型写为
$$\begin{aligned}
y &amp;\sim \text{Gamma}(\mu_i, \phi) \\
\log(\mu_i) &amp; = \beta_0 + \beta_1 \log(t) + \beta_2 t
\end{aligned}$$
为什么 GLM 形式的方程写成 $\log(a)$，而 $b$ 和 $c$ 却没有写成对数？我这里遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659525/equivalent-glm-formulation-of-woods-lactation-curve</guid>
      <pubDate>Sat, 04 Jan 2025 12:22:48 GMT</pubDate>
    </item>
    <item>
      <title>线性判别分析-有关公式的基本问题</title>
      <link>https://stats.stackexchange.com/questions/659524/linear-discriminant-analysis-basic-question-regarding-the-formulas</link>
      <description><![CDATA[我正在阅读 Hastie 和 Tishbirani 合著的《统计学习导论》。
他们在第 148 页上说，我们寻找使函数最大化的 k：

然后他们说，对于两个类（K=2），如果先验分布相等，我们为类 1 分配观察值，如果：

这导致决策边界：

现在我的代数不收敛到那个。我的不等式导致不同的符号 (mu1^2+mu2^2)。我也不明白最后的结论。你能帮我算一下这里的数学吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659524/linear-discriminant-analysis-basic-question-regarding-the-formulas</guid>
      <pubDate>Sat, 04 Jan 2025 12:14:32 GMT</pubDate>
    </item>
    <item>
      <title>使用哪种统计检验来比较两组各有 30 名参与者的样本......比较 10 个不同时间点的心率？</title>
      <link>https://stats.stackexchange.com/questions/659523/which-statistical-test-to-use-to-compare-two-groups-with-30-participants-each</link>
      <description><![CDATA[我想比较两个不同组（A组和B组）在10个不同时间点的心率。（例如1分钟、5分钟的心率……等等）..每个组包含30名参与者。
我还想找出置信区间和范围...如果可能的话]]></description>
      <guid>https://stats.stackexchange.com/questions/659523/which-statistical-test-to-use-to-compare-two-groups-with-30-participants-each</guid>
      <pubDate>Sat, 04 Jan 2025 09:16:17 GMT</pubDate>
    </item>
    <item>
      <title>分析离散数据的相关性</title>
      <link>https://stats.stackexchange.com/questions/659520/analyzing-correlation-in-discrete-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659520/analyzing-correlation-in-discrete-data</guid>
      <pubDate>Sat, 04 Jan 2025 06:01:42 GMT</pubDate>
    </item>
    <item>
      <title>为每个受试者建模累积率</title>
      <link>https://stats.stackexchange.com/questions/659518/modelling-cumulative-rates-per-subject</link>
      <description><![CDATA[有多个受试者，每个受试者都有多个观察结果（每次测量时都会观察到连续的预测因子，并观察到 ​​0/1 响应）。纵向回归可用于为每个受试者（不断变化的）累积率建模吗？
例如：对于每个受试者 $i$ 和时间点 $t$，观察二元结果 $Y_{it}$（0 或 1）和预测因子向量 $X_{it}$。累积率 $R_{it}$ 是截至时间 $t$ 时，对象 $i$ 的积极响应比例：
$$R_{it} = \frac{\sum_{s=1}^t Y_{is}}{t}$$
基本逻辑回归：
$$\text{logit}(E[R_{it}|X_{it}, b_i]) = X_{it}^\top \beta + b_i$$
其中：

$\beta$ 是固定效应系数
$b_i$ 是主题 $i$ 的随机效应，例如 $b_i \sim N(0, \sigma_b^2)$
主题级别的相关性：$\text{Corr}(R_{it}, R_{is}) = \rho^{|t-s|}$

我想也许可以使用 Beta 分布回归，但它有点超出我的理解范围，我想保持简单。但我认为由于 Beta 分布模拟比例响应，它也可能合适。
有什么想法？]]></description>
      <guid>https://stats.stackexchange.com/questions/659518/modelling-cumulative-rates-per-subject</guid>
      <pubDate>Sat, 04 Jan 2025 03:52:05 GMT</pubDate>
    </item>
    <item>
      <title>样本量问题 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/659509/sample-size-question</link>
      <description><![CDATA[寻求统计帮助：如果我对 22,000 个样本中的 108 个样本进行了调查，并且从这 108 个样本中，我得到的失败率为 31，那么我需要从剩下的 22,000 个样本中抽取多少个样本才能达到 95% 的置信水平和 7.5% 的误差幅度，以达到整个人群的实际失败率？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659509/sample-size-question</guid>
      <pubDate>Fri, 03 Jan 2025 21:55:37 GMT</pubDate>
    </item>
    <item>
      <title>具有一元发射字母表的隐马尔可夫模型有意义吗？</title>
      <link>https://stats.stackexchange.com/questions/659508/do-hidden-markov-models-with-unary-emisson-alphabet-make-sense</link>
      <description><![CDATA[我正在研究一个可以建模为隐马尔可夫模型的系统，其非静默状态都发出相同的符号。因此，该模型只是在一元字母表（或等效地，整数）上生成单词。有没有更简单的替代方法来表示这样的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/659508/do-hidden-markov-models-with-unary-emisson-alphabet-make-sense</guid>
      <pubDate>Fri, 03 Jan 2025 21:54:33 GMT</pubDate>
    </item>
    <item>
      <title>处理一次膨胀计数数据而不是零膨胀计数数据</title>
      <link>https://stats.stackexchange.com/questions/659503/handling-one-inflated-count-data-instead-of-zero-inflated</link>
      <description><![CDATA[处理零膨胀数据时需要零膨胀模型和 Hurdle 模型，或者考虑到研究使用截断泊松或 NB 模型似乎合适。但是，如果数据中不存在 0 计数，而是存在 1 的潜在膨胀，该如何处理？这是否与零膨胀类似，还是事件未在大量观察中发生（零膨胀）的情况是进行调整的具体原因？（也就是说，在建模计数方面，没有零的数据集中的一次膨胀与零膨胀数据集有何不同？）]]></description>
      <guid>https://stats.stackexchange.com/questions/659503/handling-one-inflated-count-data-instead-of-zero-inflated</guid>
      <pubDate>Fri, 03 Jan 2025 18:39:46 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归是不存在过度分散的计数数据的默认模型吗？</title>
      <link>https://stats.stackexchange.com/questions/659502/is-poisson-regression-the-default-model-for-count-data-without-overdispersion</link>
      <description><![CDATA[泊松模型在研究中被广泛用于对计数数据进行建模，但是当存在过度分散时，就会使用其他模型（例如 NB、拟泊松）。如果不存在过度分散且变化与预期相等，您是否默认使用泊松回归模型，还是仍可以根据 gof 进行选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/659502/is-poisson-regression-the-default-model-for-count-data-without-overdispersion</guid>
      <pubDate>Fri, 03 Jan 2025 18:38:33 GMT</pubDate>
    </item>
    <item>
      <title>类别平衡损失中的有效样本数？</title>
      <link>https://stats.stackexchange.com/questions/659479/effective-number-of-samples-in-class-balance-loss</link>
      <description><![CDATA[我偶然看到了这篇论文：基于有效样本数的类平衡损失，但我有些观点不太明白：

(1) 图 1 的含义：这条线是否显示了两个类之间的分类边界？红线是在加权损失中应用 1/n 时，黑线表示无权重，蓝线表示建议的方法。然后我可以看到 1/n 可能会对损失进行过度惩罚，正如论文中的意思：n 个样本集中的数据点之间可能存在一些重叠 -&gt; 真正有意义的数据点小于 n，那么用 1/n 惩罚太难了 -&gt;从图中可以看出，少数类主导多数类，因为它们对梯度的贡献不大，虽然它们有很多样本，但梯度几乎减少了

(2) 方程 (3) 出自哪里？我对这个方程有一点了解，但不知道他们是如何得到这个公式的，他们还提到了 N 中的原型。我只是不明白它们是如何相互关联的。

(3) 我需要将 A 类的数量下采样到 E_n 吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/659479/effective-number-of-samples-in-class-balance-loss</guid>
      <pubDate>Fri, 03 Jan 2025 07:16:36 GMT</pubDate>
    </item>
    <item>
      <title>随着 $p$ 增加的几何分布的期望和方差</title>
      <link>https://stats.stackexchange.com/questions/659457/expectation-and-variance-of-geometric-distribution-with-increasing-p</link>
      <description><![CDATA[考虑这样一种情况，我们从伯努利分布中得出成功概率为$p $（为简单起见，假设$p &lt; \frac{2}{3}$）。每次失败都会使成功概率增加$0.1p$，最大成功概率上限为$1.5p$。实现一次成功所需的试验期望值和方差是多少？
对于恒定的成功概率，这简化为几何分布，其成功率为$p$，预期值$ \mu = \frac{1}{p} $，方差为$ \sigma^2 = \frac{1-p}{p^2} $。因此，解决方案似乎受限于 $ \mu = \left[\frac{1}{1.5p}, \frac{1}{p} \right]$ 和 $ \sigma^2 = \left[\frac{1-1.5p}{(1.5p)^2}, \frac{1-p}{p^2}\right]$。

更新：
这是我得到平均值的方法：
让 $P(X=n)$ 成为 $n$ 次试验后成功的 pmf，然后
$P(X=1)= p$ 
$P(X=2)=(1-P(X=1))1.1p$
$P(X=3)=(1-P(X=1)-P(X=2))1.2p$
$P(X=4)=(1-P(X=1)-P(X=2)-P(X=3))1.3p$
$P(X=5)=(1-P(X=1)-P(X=2)-P(X=3)-P(X=4))1.4p$
$P(X=6)=(1-P(X=1)-P(X=2)-P(X=3)-P(X=4)-P(X=5))1.5p$
$P(X=7)=(1-P(X=1)-P(X=2)-P(X=3)-P(X=4)-P(X=5)-P(X=6))1.5p$
请注意，从第 6 次试验开始，分布遵循几何分布，$p^\prime=1.5p$。
则平均值为：
$\mu=XP(X)=P(X=1)+2P(X=2)+3P(X=3)+4P(X=4)+5P(X=5)+6P(X=6)+\cdots$
$=p+2(1-P(X=1))1.1p+3(1-P(X=1)-P(X=2))1.2p+4(1-P(X=1)-P(X=2)-P(X=3))1.3p+5(1-P(X=1)-P(X=2)-P(X=3)-P(X=4))1.4p+(1-P(X=1)-P(X=2)-P(X=3)-P(X=4)-P(X=5)) \cdot (5+1/1.5p)$
对于 $p=0.1,$，平均值为 $7.535067.$]]></description>
      <guid>https://stats.stackexchange.com/questions/659457/expectation-and-variance-of-geometric-distribution-with-increasing-p</guid>
      <pubDate>Thu, 02 Jan 2025 16:59:23 GMT</pubDate>
    </item>
    <item>
      <title>如何估计两个坐标系之间的旋转？</title>
      <link>https://stats.stackexchange.com/questions/659430/how-can-i-estimate-the-rotation-between-two-cooordinate-frames</link>
      <description><![CDATA[我在两个坐标系（xyz 和 XYZ）中测量了 N 个 3D 点 p：
$$
p_i:\vec{xm_i}, \vec{Xm_i} 
$$
我将测量过程建模为：
$$
\vec{xm_i} = \vec{x_i} + \vec{\epsilon_i}
$$
$$
\vec{Xm_i} = \vec{X_i} + \vec{\epsilon&#39;_i}
$$
其中 $\vec{x_i}$ 和 $\vec{X_i}$ 是实际坐标位置（非随机变量）和$\vec{\epsilon_i} \sim \mathcal{N}(0,\sigma)$和$\vec{\epsilon_i&#39;} \sim \mathcal{N}(0,\sigma)$是测量噪声。
坐标系相对于彼此旋转：
$$
\vec{X_i} = R\vec{x_i} 
$$
其中
$$
\vec{X_i} = 
\begin{bmatrix}X_i\\Y_i\\Z_i\end{bmatrix}
$$
$$
\vec{x_i} = 
\begin{bmatrix}x_i\\y_i\\z_i\end{bmatrix}
$$
并且 $R(\alpha,\beta,\gamma)$ 是 3x3 旋转矩阵：

对于 $\alpha$、$\beta$ 和 $\gamma$ 以及为什么？
到目前为止，我所做的是最小化：
$$
\underset{\alpha,\beta,\gamma}{\mathrm{argmin}} 
\{SE(\alpha,\beta,\gamma) = \Sigma_i |R\vec{xm_i} - \vec{Xm_i}|^2\} 
$$
使用 Levenberg-Marquardt 算法 (scipy.optimize.least_squares)。
但是，我仅考虑了这种方法中的 $\vec{\epsilon&#39;_i}$ 错误。我还想考虑 $\vec{\epsilon_i}$ (总体最小二乘法) 中的错误。
解决这个问题是否只需最小化：
$$
\underset{\alpha,\beta,\gamma}{\mathrm{argmin}} 
\{TSE(\alpha,\beta,\gamma) = \Sigma_i [|R\vec{xm_i} - \vec{Xm_i}|^2 + |R^{-1}\vec{Xm_i} - \vec{xm_i}|^2]\} 
$$
代替？
我创建了一个 pandas 测试数据集。
这里我使用了$\alpha = 1°$、$\beta = 2°$和$\gamma = 3°$，并在$\vec{x}$和$\vec{X}$中添加了$\sigma = 0.01$的噪声。
这是我用Python实现的线性求解器。
它产生了以下输出：
实际旋转矩阵：
[[ 0.9980212 -0.05171974 0.03575975]
[ 0.05230407 0.99850932 -0.01560227]
[-0.0348995 0.01744177 0.99923861]]
估计旋转矩阵：
[[ 1.00228603 -0.06671378 0.0452653 ]
[ 0.04621024 0.97714644 -0.01505205​​]
[-0.02123221 0.01683688 1.00103115]]
alpha: 0.971802, beta: 1.886494, gamma: 3.266041

这里我取了 100 个解决方案的平均值（因为估计值是随机变量）。
结果相当不错，但有一个缺陷：
估计的旋转矩阵不正交。
每行的范数应该是 1，但第一行和最后一行都有元素 &gt; 1。
这是我从 Aksakals 的回答中实现的另一个线性求解器 2。它给出的结果与第一个线性求解器完全相同。
这是用 Python 实现的非线性求解器。
它产生了以下输出：
不对称：alpha：1.382373，beta：1.677021，gamma：3.002319
对称：alpha：1.382373，beta：1.677019，gamma：3.002318

总体最小二乘结果（对称）几乎与最小二乘结果（不对称）完全相同。这里我也取了 100 个解决方案的平均值（因为估计值是随机变量）。]]></description>
      <guid>https://stats.stackexchange.com/questions/659430/how-can-i-estimate-the-rotation-between-two-cooordinate-frames</guid>
      <pubDate>Wed, 01 Jan 2025 22:27:53 GMT</pubDate>
    </item>
    <item>
      <title>VAE 高斯分布的加权融合</title>
      <link>https://stats.stackexchange.com/questions/659124/weighted-fusion-of-vae-gaussian-distributions</link>
      <description><![CDATA[假设您有 4 个不同 VAE 的 4 个堆叠输出向量：$B \times 512 \times 4$
这些 $512$ 个元素对应于四个相互依赖的多元正态分布的 $256 \ \mu$ &amp; $256 \ \ln\sigma^2$（对数方差）。
我的目标是将这四个组合成一个多元正态分布，定义为 $\mu^*$ &amp; $\ln\sigma^{2*}$ 大小为 $B \times 512$，采用加权融合方法。我正在考虑两个想法...

1.简单求和高斯函数
均值总和：$\mu^*=\sum w_i * \mu_i$
对数变量的对数和指数技巧：$\ln\sigma^{2*}=a + \ln ( \sum w_i * e^{\text{logvar}_i - a})$
其中

$w_i$ 是基于 VAE 输出的学习到的注意力权重，其中 $\sum w_i = 1$
$a = \max (\text{logvars})$

在 PyTorch 中实现：
# 加权均值融合
fused_mean = torch.sum(weights * means, dim=-1)

# 对 logvars 进行加权对数和指数融合
max_logvar = torch.max(logvars, dim=-1, keepdim=True)[0] # 元组输出（丢弃索引）
weighted_var = weights * torch.exp(logvars - max_logvar)
sum_weighted_var = torch.sum(weighted_var, dim=-1, keepdim=True)
fused_logvar = max_logvar + torch.log(sum_weighted_var + eps)

返回 fused_mean, fused_logvar.squeeze(dim=-1)

2.混合模型方法
这个有点类似但更复杂，我收集了它考虑了依赖关系 - 但我不是统计学家！
均值总和（与以前的方法相同）：$\mu^*=\sum w_i * \mu_i$
方差：$\sigma^{2*} = [\sum w_i * (\sigma_i^2 * \mu_i^2)] - [\sum w_i * \mu_i]^2$
或使用对数和指数技巧：
$$\ln\sigma^{2*}=a + \ln ([\sum w_i * (e^{\text{logvar}_i - a} + \mu_i^2)] - \mu^{*^{2}})$$
在 PyTorch 中实现：
# 加权均值融合
fused_mean = torch.sum(weights * means, dim=-1, keepdim=True) # (batch_size, latent_dim, 1)

# 带交叉项的加权混合方差
max_logvar = torch.max(logvars, dim=-1, keepdim=True)[0] # (batch_size, latent_dim, 1)
_vars = torch.exp(logvars - max_logvar) # (batch_size, latent_dim, n_views)
fused_var = torch.sum(weights * (_vars + means**2), dim=-1, keepdim=True) - fused_mean**2
fused_logvar = max_logvar + torch.log(fused_var + eps)

return fused_mean.squeeze(dim=-1), fused_logvar.squeeze(dim=-1)


我的问题是：

这两种方法的统计意义是什么，什么时候应该优先选择一种方法？
我的公式/操作是否正确实现？

有关更多上下文，您可以访问这个 repo，我将在这里整理这些内容。简而言之，$x$ 是一个分子，它表示为字符串、图像、图形和指纹，每个都使用单独的 VAE 进行编码，并组合成用于采样和计算 KL 散度的单个多变量正态分布。最终目标实际上是通过减少 (KL) 损失项的数量来简化和稳定训练。]]></description>
      <guid>https://stats.stackexchange.com/questions/659124/weighted-fusion-of-vae-gaussian-distributions</guid>
      <pubDate>Mon, 23 Dec 2024 13:14:30 GMT</pubDate>
    </item>
    <item>
      <title>根据相关数据进行方差估计</title>
      <link>https://stats.stackexchange.com/questions/658200/variance-estimation-from-dependent-data</link>
      <description><![CDATA[我想从形式为 $y_n = u_n x_n$ 的数据中估计零均值正态分布 $x_n \sim \mathcal{N}(0, \sigma^2)$ 的方差，其中输入 $u_n \in [u_{\min}, u_{\max}]$ 可以在每次迭代 $n$ 中主动选择，即 $u_n$ 不是先验固定的，而是高度依赖于先前的选择。
如何估计方差 $\sigma^2$场景？
编辑：更多细节/额外假设

我们可以假设 $0 &lt; u_{\min} &lt; u_{\max}$。
对先前选择的依赖：我感兴趣的是估计 $\sigma^2$，时间序列 $(u_0, y_0)$、$(u_1, y_1)$、... 但是 $u_n$ 的值并不是独立的，而是根据某些决策标准选择的，这些决策标准可能取决于 $\sigma^2$ 的先前估计值
我正在寻找 $\sigma^2$ 的无偏估计量
]]></description>
      <guid>https://stats.stackexchange.com/questions/658200/variance-estimation-from-dependent-data</guid>
      <pubDate>Tue, 03 Dec 2024 12:19:22 GMT</pubDate>
    </item>
    </channel>
</rss>