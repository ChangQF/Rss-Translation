<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 24 Jun 2024 15:16:15 GMT</lastBuildDate>
    <item>
      <title>在实践中（SGD 的收敛），我们多久会得到一次目标函数的 Lipschitz 连续梯度？</title>
      <link>https://stats.stackexchange.com/questions/649817/how-often-do-we-have-lipschitz-continuous-gradients-for-the-objective-function-i</link>
      <description><![CDATA[当我看到随机梯度下降收敛的证明时，通常假设目标函数是 L 平滑的（具有常数 L 的 Lipschitz 连续梯度）。这在实践中是一个合理的假设吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649817/how-often-do-we-have-lipschitz-continuous-gradients-for-the-objective-function-i</guid>
      <pubDate>Mon, 24 Jun 2024 15:07:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 stpm2 函数计算 R 中灵活参数模型的线性预测因子和风险评分</title>
      <link>https://stats.stackexchange.com/questions/649816/calculating-linear-predictor-and-risk-score-for-a-flexible-parametric-model-in-r</link>
      <description><![CDATA[我正在使用 r 中的 stpm2 函数在 R 中开发一个灵活的参数模型，我不确定在开发模型后如何计算我的数据集中每个人的线性预测因子和风险分数
开发模型的代码是
model &lt;- stpm2(Surv(time, status == 1) ~ age + bmi + sex, data = dataset_name)

我想计算每个人 2 年和 5 年的线性预测因子和风险分数。]]></description>
      <guid>https://stats.stackexchange.com/questions/649816/calculating-linear-predictor-and-risk-score-for-a-flexible-parametric-model-in-r</guid>
      <pubDate>Mon, 24 Jun 2024 15:04:26 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的国家年份虚拟变量[关闭]</title>
      <link>https://stats.stackexchange.com/questions/649814/country-year-dummies-in-python</link>
      <description><![CDATA[我目前正在使用 linearmodels 6.0 包进行计量经济学分析。我使用 EntityEffects 和 TimeEffects 包含了区域和时间固定效应，我想知道如何包含国家*年份虚拟变量之类的东西，以及这个变量和固定效应之间的相互作用是什么。
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/649814/country-year-dummies-in-python</guid>
      <pubDate>Mon, 24 Jun 2024 14:46:13 GMT</pubDate>
    </item>
    <item>
      <title>当数据已经标准化时，如何近似相关矩阵的特征分解？</title>
      <link>https://stats.stackexchange.com/questions/649813/how-to-approximate-the-eigendecomposition-of-a-correlation-matrix-when-the-data</link>
      <description><![CDATA[上下文
我正在努力开发一个惩罚回归框架，该框架将扩展到分析具有特定相关结构的高维数据。让$X$表示一个$n \times p$数据矩阵 - 行是观察值，列是特征。为了适应$X$的特征通常处于不同尺度的事实，我将$X$的列居中并缩放以获得$\dot X$。我正在研究的模型需要对相关矩阵$K = \frac{1}{p} \dot X \dot X^\top$进行特征分解，因此我取$\text{eigen}(K) = USU^\top$，并在后续转换中使用$U$和$S$。
当前问题
与当前问题相关：我想进行交叉验证 (CV)，以便为我的模型选择一个调整参数（例如，套索模型的调整参数$\lambda$）。为了确保 CV 实现代表建模过程的每个步骤，我需要在每一折中标准化训练数据 $X^*$。但是，我想避免在每一折中构建 $K^*$ 并采用 $\text{eigen}(K^*)$，因为这会非常昂贵（从计算角度而言）。我想要的是一种相对便宜的方法来近似$U^*, S^*$，即标准化训练数据的相关矩阵的特征向量/特征值。
示例
CV 之前的# --------------------------
n &lt;- 5
p &lt;- 10

X &lt;- matrix(rnorm(n*p), n, p)
std_X &lt;- scale(X)
K &lt;- tcrossprod(std_X)/p # 相关矩阵 
eigen_K &lt;- eigen(K)
U &lt;- eigen_K$vectors
S &lt;- diag(eigen_K$values)

CV 中的# -------------------------------
train &lt;- sample(n, 3) # 训练数据中观测值的索引 
train_X &lt;- std_X[train,] # 折叠子集 
std_train_X &lt;- scale(train_X) # 重新标准化以反映完整模型程序

# 真实分解（我需要的）
star_K &lt;- tcrossprod(std_train_X)/ncol(train_X)
star_eigen_K &lt;- eigen(star_K) # eigen = 昂贵！
star_U &lt;- star_eigen_K$vectors 
star_S &lt;- star_eigen_K$values

# CV subset 
train_U &lt;- U[train,]
train_K &lt;- tcrossprod(train_X)/ncol(train_X)

# ... 但 train_U 和 S 并不代表 star_K 的分解。

有没有办法避免在每次折叠中构建和分解 star_K？具体来说，如何（如果有的话）从训练数据、现有的分解$U, S$以及用于将train_X标准化为std_train_X的中心/缩放值来近似star_U？]]></description>
      <guid>https://stats.stackexchange.com/questions/649813/how-to-approximate-the-eigendecomposition-of-a-correlation-matrix-when-the-data</guid>
      <pubDate>Mon, 24 Jun 2024 14:44:45 GMT</pubDate>
    </item>
    <item>
      <title>去聚类影响、平稳性和离散化</title>
      <link>https://stats.stackexchange.com/questions/649812/declustering-impact-stationarity-and-discretization</link>
      <description><![CDATA[我有一个季节性时间序列，我正在考虑使用运行去聚类对其进行去聚类（在任何其他预处理步骤之前）。如果我观察到极值指数为 1，我可以声称我的数据是 i.i.d.，因此是平稳的吗？这是否允许我避免事先使用非平稳方法？此外，我很好奇运行去聚类时间序列是否类似于离散化，因为我不确定我的去聚类分布是否仍然属于最大吸引域。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/649812/declustering-impact-stationarity-and-discretization</guid>
      <pubDate>Mon, 24 Jun 2024 14:33:04 GMT</pubDate>
    </item>
    <item>
      <title>如何从一组已经组合成多个箱的样本值中找出未知 PDF 的平均值和 SE？</title>
      <link>https://stats.stackexchange.com/questions/649809/how-to-find-the-average-and-se-of-a-un-unknown-pdf-from-a-set-on-sample-values-a</link>
      <description><![CDATA[我有以下数据：

我想知道生成该数据的原始 PDF 的平均值和 SE。作为初步估计，我假设其服从正态分布。
你能帮我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649809/how-to-find-the-average-and-se-of-a-un-unknown-pdf-from-a-set-on-sample-values-a</guid>
      <pubDate>Mon, 24 Jun 2024 13:41:15 GMT</pubDate>
    </item>
    <item>
      <title>实现两个模拟序列之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/649807/implement-correlation-between-two-simulated-series</link>
      <description><![CDATA[给出了初始值$r_0$和$ls_0$。我想模拟两个时间序列，$$R_t = \{ r_0, r_1, \dots, r_t \} \quad \text{where} \quad r_n |r_s \sim \chi^2_d (\lambda_{r_s})$$ 和
$$ LS_t = \{ls_0, ls_1 \dots, ls_t \} $$
其中 $ ls_n = \min (ls_{n-1} + \beta(\ln \tau - ls_{n-1}) + \sigma Z, M) $ 和 $ Z \sim \mathcal{N}(0,1). $
模拟这两个序列本身不是问题，但我希望序列之间存在相关性$\rho$。我研究过 copulas 等，但发现当 $r_{n-1}、r_{n}$ 等不是 IID 时很难实现。
有没有关于如何实现这一点的提示？目标是如果我创建了时间序列，
correlation_matrix = np.corrcoef(time_series_1, time_series_2)
correlation_coefficient = correlation_matrix[0, 1]
print(correlation_coefficient)
&gt; 例如 0.5 或任何我想要的值
]]></description>
      <guid>https://stats.stackexchange.com/questions/649807/implement-correlation-between-two-simulated-series</guid>
      <pubDate>Mon, 24 Jun 2024 13:18:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 RStudio 的 survminer 包进行分析，解决 Kaplan-Meier 生存图中时间点“风险”表中缺失数据显示问题</title>
      <link>https://stats.stackexchange.com/questions/649805/esolving-missing-data-display-issues-in-at-risk-table-at-time-points-in-kaplan</link>
      <description><![CDATA[我尝试使用 RStudio 创建 Kaplan-Meier 曲线和“风险”表，数据包括状态（1 或 0 表示事件存在或不存在）、时间（事件发生时间）和组（两组：A 组或 B 组）。但是，以下代码无法在“风险”表中显示 720 天标记处的数字。您能提供此问题的解决方案吗？
# 加载必要的软件包
install.packages(&quot;survival&quot;)
install.packages(&quot;survminer&quot;)

library(survival)
library(survminer)

# 创建（或加载）数据
data &lt;- data.frame(
status = c(1, 0, 1, 0, 1, 0, 1, 0),
time = c(100, 200, 300, 400, 500, 600, 700, 800),
group = c(&#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;)
)

# 拟合 Kaplan-Meier 模型
fit &lt;- survfit(Surv(time, status) ~ group, data = data)

# 使用“at risk”表绘制 Kaplan-Meier 曲线
ggsurvplot(
fit,
data = data,
risk.table = TRUE,
risk.table.height = 0.25,
xlim = c(0, 800),
xscale = “d”,
break.time.by = 180,
risk.table.y.text.col = TRUE,
risk.table.y.text = FALSE,
risk.table.col = “strata”,
ggtheme = theme_minimal()
)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/649805/esolving-missing-data-display-issues-in-at-risk-table-at-time-points-in-kaplan</guid>
      <pubDate>Mon, 24 Jun 2024 13:11:50 GMT</pubDate>
    </item>
    <item>
      <title>具有相关结构的向量的相关性和 $z$ 变换</title>
      <link>https://stats.stackexchange.com/questions/649804/correlation-and-z-transformation-for-vectors-with-correlation-structure</link>
      <description><![CDATA[考虑一组 $p$ 对 $(x_1,y_1),...,(x_p,y_p)$，样本相关系数为
$$r=\frac{\sum_{i=1}^p (x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^p (x_i-\bar{x})^2} \sqrt{\sum_{i=1}^p (y_i-\bar{y})^2}}$$
在讨论 $z$ 变换时，通常的设置是这样的：假设这些对是 iid 的，并且源自二元正态分布 $F$。在此设置下（并假设 $cor(x_i,y_i)=\rho$），我们得到近似分布
$$z\sim\mathcal{N}\left( \frac{1}{2}\ln\left(\frac{1+\rho}{1-\rho}\right), \frac{1}{\sqrt{p-3}} \right)$$
到目前为止，这很常见。根据 Hawkins (1989)，双变量正态性假设可以放宽为“$F$ 具有有限的前四个矩”。这很好，但对于以下依赖性情况没有多大帮助：

这些对不是 i.i.d，而是具有某种依赖结构（我们可以称之为“通常的依赖性”）。这总体上很有趣，但不是这个问题的重点。

数据不是来自双变量函数的 $p$ 个样本，而是来自 $p$ 维函数的两个样本。也就是说，$x_i$ 项之间可能存在某种相关结构 $\Sigma_{p\times p}$。


后一点可能听起来很奇怪，但可以很容易地举例说明：

给定一个有 $p$ 名学生的班级，数学老师和法语老师需要根据学生的行为对他们进行排名（1=最好，$p$=最差，只有离散值，每个值使用一次）

给定一个有 $p$ 名学生的班级，英语老师和法语老师需要挑选 $k$ 名应该获得津贴（1=有津贴，0=无津贴）

基于相同数据训练的两个线性回归模型（例如 LASSO 和 Ridge）的系数向量


在每种情况下，$x$ 的不同条目之间存在某种关系（在示例 1 中，为 $x_i$ 选取的值会影响 $x_j$ 的可能值；在示例 2 中，$k$ 个“1”条目的选择迫使其余条目为“0”）。我们想通过使用 $z$ 变换对样本相关性进行评估，来评估 $x,y$ 之间的一致性水平。此处的零假设不一定是 $H_0:\rho=0$，而是 $\rho\ge 0.5$（例如）。
在这种设置下，我们对 $z$ 统计量的行为了解多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/649804/correlation-and-z-transformation-for-vectors-with-correlation-structure</guid>
      <pubDate>Mon, 24 Jun 2024 13:07:45 GMT</pubDate>
    </item>
    <item>
      <title>如何处理时间序列预测的 Seq2Seq 模型中未知的未来外生变量？</title>
      <link>https://stats.stackexchange.com/questions/649803/how-to-handle-unknown-future-exogenous-variables-in-seq2seq-models-for-time-seri</link>
      <description><![CDATA[标题：如何处理用于时间序列预测的 Seq2Seq 模型中未知的未来外生变量？
问题：
我正在研究一个序列到序列 (seq2seq) 模型，用于预测金融市场的实际波动率。我的模型有三个主要变量：

实际波动率（目标变量，内生）
虚拟事件变量（外生变量，与预期事件相关，已知未来步骤）
波动率倾斜（外生变量，未知未来步骤）

问题描述：
在任何给定时间 (t)，我的输入序列结束，我需要开始预测未来值。我知道虚拟事件变量的未来值，但我不知道波动率偏差的未来值。
我正在寻找有效的策略来构建我的 seq2seq 模型的解码器输入，而不会导致未来实际值的信息泄露。具体来说：

在准备解码器输入时，我应该如何处理波动性偏差的未知未来值？
在这种情况下，避免信息泄露的常见做法是什么？
这些策略如何影响 seq2seq 模型的整体性能和稳定性？

考虑的方法：

持久性模型：使用波动性偏差的最后观测值（即假设它在未来保持不变）。
简单预测模型：实施基本预测模型（如移动平均线或自回归）来估计波动性偏差的未来值。
零或均值插补：用零或过去值的均值填充未来未知值。
可训练占位符：引入模型可以在训练期间学习适应的占位符。

问题：

上述哪种策略（或任何其他策略）最适合处理此预测环境中波动率偏差的未知未来值？
解码器输入应如何构建，以在避免信息泄露和提供有用的预测信息之间取得平衡？
是否有任何来自类似时间序列预测问题的最佳实践或推荐方法可以指导我有效地构建这些序列？

任何关于这些策略的见解或建议，特别是在金融时间序列预测的背景下，都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/649803/how-to-handle-unknown-future-exogenous-variables-in-seq2seq-models-for-time-seri</guid>
      <pubDate>Mon, 24 Jun 2024 13:06:40 GMT</pubDate>
    </item>
    <item>
      <title>Top-N 推荐系统</title>
      <link>https://stats.stackexchange.com/questions/649802/top-n-recommender-system</link>
      <description><![CDATA[假设中介机构使用两部分推荐模型，试图促进其客户和外部供应商之间的服务：
模型 1：预测供应商竞标客户寻求的给定服务的概率：$\Pr(\text{Bid})$
模型 2：预测供应商在初始出价的情况下成为中标者的概率：$\Pr(\text{Win}|\text{Bid})$
然后预测$\Pr(\text{Bid and Win})$：
$$
\begin{align}
\Pr(\text{Bid and Win}) &amp;= \Pr(\text{Bid}) \times \Pr(\text{Win}|\text{Bid}) \\
&amp;= \text{模型 1 的输出} \times \text{模型 2 的输出}
\end{align}
$$
然后对预测值最高的 $\Pr(\text{Bid and Win})$ 的前 N ​​家供应商进行排序，作为进一步追求的候选者，并尝试满足客户的服务需求。
现在假设施加了外部评估标准，为整个建模框架开绿灯：
建模框架推荐的获胜供应商是否在前 N 中至少有 X% 的时间。（根据测试数据集的评估）。
（确切的百分比在这里无关紧要，可能是 5%，也可能是 95%）
另请注意，前 N 中的位置不重要。重要的是所选供应商位于前 N 名。
问题：获得预测值最高的 $\Pr(\text{Bid and Win})$ 的前 N ​​名是否优化了此外部标准？如果是，如何证明这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/649802/top-n-recommender-system</guid>
      <pubDate>Mon, 24 Jun 2024 12:54:07 GMT</pubDate>
    </item>
    <item>
      <title>通过 SciPy 对有界约束的噪声函数进行非线性优化</title>
      <link>https://stats.stackexchange.com/questions/649801/nonlinear-optimization-of-noisy-functions-w-bound-constraints-via-scipy</link>
      <description><![CDATA[如果我们只有嘈杂的观测数据，我们能否使用 scipy.optimize.minimize 来找到函数 $\mathbf{w} \in \Omega^k$,
$\Omega \subset \mathbb{R}$ 的最佳参数，取决于其他黑盒函数 $f$ $\tilde{f}_i = \tilde{f}(x_i)$，$i=1,\dots,n$？我们没有确切的
$f$（因此 $\nabla f$ 和 $\mathbf{H}_f$）可用，例如 minimize(method=&#39;trust-constr&#39;)。
但是当我运行，比如说，
minimize(g, method=&#39;trust-constr&#39;, bounds=w_bounds, args=X)

scipy 以某种方式设法找到了解决方案，尽管与简单的贪婪搜索相比不是最好的解决方案。minimize 中的任何方法是否真的支持这种情况？
P.S.如果您需要示例用例：$f$ - 机器学习算法，
$g$ - 评分函数，$\mathbf{w}$ - $f$ 上某些元学习器的超参数，
$\mathbf{X} = (\mathbf{x}_i, y_i)_{i=1}^k$ - (验证/测试) 数据集。目前，我没有考虑像 optuna 中那样的常见超参数优化方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/649801/nonlinear-optimization-of-noisy-functions-w-bound-constraints-via-scipy</guid>
      <pubDate>Mon, 24 Jun 2024 12:48:48 GMT</pubDate>
    </item>
    <item>
      <title>比较分布的差分熵</title>
      <link>https://stats.stackexchange.com/questions/649799/differential-entropy-for-comparison-distributions</link>
      <description><![CDATA[我想使用差分熵来比较不同数据集的贝叶斯更新（多维概率分布）的结果。我的参数是不同的物理参数，即具有不同的维度和（非常）不同的绝对值。
现在，我想知道差分熵是否是一种很好的比较方法。
是否会出现这样的情况：例如，差分熵的下降仅仅是因为某个变量（具有高绝对值）变得（稍微）更精确地确定，而另一个变量的定义不太明确，仅仅是因为一个变量具有高绝对值？
在这种情况下，该度量不能很好地描述信息/近似值，因为增加对具有高绝对值的参数的了解似乎会以另一个同样重要但绝对值范围较低的参数为代价来提高对多维分布的了解。]]></description>
      <guid>https://stats.stackexchange.com/questions/649799/differential-entropy-for-comparison-distributions</guid>
      <pubDate>Mon, 24 Jun 2024 12:28:33 GMT</pubDate>
    </item>
    <item>
      <title>$f(a) = EX^{1+a}EX^{-(1+a)}$ 是非减的吗？</title>
      <link>https://stats.stackexchange.com/questions/649797/is-fa-ex1aex-1a-non-decreasing</link>
      <description><![CDATA[$X$ 是一个非负随机变量，$a$ 是一个非负实数。定义
$$f(a)= EX^{1+a}EX^{-(1+a)}.$$
$f(a)$ 是否非递减，且 $a$ 是递减的吗？
原始问题：当我阅读一篇论文时，我遇到了一个未经证实的不等式
$$\frac{\sum_{m=0}^{T-1}E_m^{1+\delta/2}\sum_{m=0}^{T-1}1/E_m^{1+\delta/2}}{T^2}\leq \frac{\sum_{m=0}^{T-1}E_m^{1+\delta_3}\sum_{m=0}^{T-1}1/E_m^{1+\delta_3}}{T^2}
$$
由于 $\delta &lt; \delta_3$。这里 $E_m$ 是非减实数，而 $T$ 是某个正整数。我想证明这个结果的更强版本，但我失败了。我想知道我的猜想是否正确？或者有任何反例吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649797/is-fa-ex1aex-1a-non-decreasing</guid>
      <pubDate>Mon, 24 Jun 2024 12:18:03 GMT</pubDate>
    </item>
    <item>
      <title>正确解读最终满足生存曲线</title>
      <link>https://stats.stackexchange.com/questions/649770/correct-interpretation-of-survival-curves-that-eventually-meet</link>
      <description><![CDATA[我有一些生存数据，我们正在尝试分析和理解这些数据。结果是疾病状态的进展。主要暴露在本质上是随时间变化的 - 最初未暴露，但一旦暴露，我们认为它们会一直保持这种状态，直到进展或审查。所以我们的数据是开始、停止格式 - 一切都很好。
我越来越被使用灵活的参数生存模型所吸引，因为它们使用简单，并且它们可以提供超出 Cox 模型的额外信息。我们最终用于此分析的灵活参数模型在对数累积基线风险的形状方面基本上简化为威布尔，但我们确实为主要暴露纳入了相互作用（时间变系数），因为它被证明具有非比例风险。
因此风险比随时间而变化。
附上随时间变化的 Kaplan Meier 和 HR 图。
生存曲线似乎在大约 17 年后汇合在一起，HR 表明暴露仅在前 5 年左右对结果有保护作用。
正确的解释方式是否类似于暴露在预防结果的短时间内有益处（相对于未暴露），但如果有足够的时间，每个人最终都会有相同程度的残疾？
如果是这样的话，我想你仍然可以合理地认为暴露在临时生活质量方面提供了好处，即使最终的净效应是中立？

]]></description>
      <guid>https://stats.stackexchange.com/questions/649770/correct-interpretation-of-survival-curves-that-eventually-meet</guid>
      <pubDate>Sun, 23 Jun 2024 22:56:43 GMT</pubDate>
    </item>
    </channel>
</rss>