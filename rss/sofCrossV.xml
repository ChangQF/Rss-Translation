<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 15 Dec 2024 15:16:43 GMT</lastBuildDate>
    <item>
      <title>向量的 2 范数的期望是否大于向量期望的 2 范数？</title>
      <link>https://stats.stackexchange.com/questions/658756/is-the-expectation-of-the-2-norm-of-a-vector-larger-than-the-2-norm-of-the-expct</link>
      <description><![CDATA[假设 $X_1, X_2 \sim \text{SomeDistribution}(\mu,\sigma)$，以下不等式成立吗？
$$
\mathbb{E}(​​\sqrt{X_1^2+X_2^2}) \ge \sqrt{\mathbb{E}^2(X_1)+\mathbb{E}^2(X_2)}
$$
如果成立，有简单的证明吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658756/is-the-expectation-of-the-2-norm-of-a-vector-larger-than-the-2-norm-of-the-expct</guid>
      <pubDate>Sun, 15 Dec 2024 15:14:16 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 marginaleffects::comparisons 或 avg_comparisons() [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658754/cannot-use-marginaleffectscomparisons-or-avg-comparisons</link>
      <description><![CDATA[亲爱的边际效应开发者/维护者/社区，
您好！我在使用 avg_comparisons() 时收到错误消息。
具体来说，我拟合了一个 lme4 模型“y ~ 条件 * 试验 + (1 | 参与者)”，其中条件是一个两级因子，试验是一个中心连续变量。交互条件：试验不显著
我现在想使用以下代码获取我的交互条件：试验的效果大小。但我收到了我不明白的错误消息

似乎包“data.table”出了问题。但是，我确认这个软件包版本是 1.14.8。
我现在不知道发生了什么。如果您能看看我的问题并提供反馈，那就太好了。我提前非常感激！
祝好，
Ted]]></description>
      <guid>https://stats.stackexchange.com/questions/658754/cannot-use-marginaleffectscomparisons-or-avg-comparisons</guid>
      <pubDate>Sun, 15 Dec 2024 14:23:42 GMT</pubDate>
    </item>
    <item>
      <title>计算不同大小的文本语料库的卡方</title>
      <link>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</link>
      <description><![CDATA[我偶然发现了一篇论文，它批评了某文本分析软件中用于比较六个大小明显不同的文本语料库中的词频的卡方统计量的计算。该软件采用标准公式：
$$
\chi^2 = \sum_{i=1}^{n} \frac{(O_{i} - E_{i})^2}{E_{i}}
$$
这里，$O_{i}$表示在语料库$i$中观察到的频率，$E_{i}$的计算方法是将一个词在所有六个语料库中的总频率除以所有语料库中的单词总数，然后乘以语料库$i$中的单词数。
本文作者批评了这种方法，陈述：

&quot;运行交叉制表也不能产生有效可靠的评估。 [...] 事实证明，该软件使用非标准化的绝对频率，只有当要比较的文本语料库长度相等时才不会引起问题。&quot;

在这种情况下，作者将$O_{i}$解释为绝对频率，并提出了一种替代的&quot;标准化&quot;过程来计算$O_{i}$和$E_{i}$。这涉及：

选择最小的语料库作为参考。
通过将观察到的所有其他语料库的频率除以各自语料库中的单词总数，然后乘以参考语料库中的单词数，对观察到的所有其他语料库的频率进行归一化。
将预期频率计算为所有语料库（包括参考语料库）的归一化频率之和，除以六（语料库数量）。

问题 1：作者声称该软件使用的公式（如上所述）没有考虑到语料库的各种大小，他是否正确。
问题 2：在这种情况下，这种归一化方法是否适用于卡方计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</guid>
      <pubDate>Sun, 15 Dec 2024 13:37:05 GMT</pubDate>
    </item>
    <item>
      <title>箱线图是否假设区间数据？</title>
      <link>https://stats.stackexchange.com/questions/658750/does-a-boxplot-assume-interval-data</link>
      <description><![CDATA[箱线图是否假设区间数据？如果不是，那么使用箱线图来表示李克特量表（序数）数据可以吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658750/does-a-boxplot-assume-interval-data</guid>
      <pubDate>Sun, 15 Dec 2024 11:48:10 GMT</pubDate>
    </item>
    <item>
      <title>如何计算文本 2 中文本 1 的单词出现的次数？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658749/how-do-i-count-the-occurrences-of-words-of-text-1-in-text-2</link>
      <description><![CDATA[我是新来的，英语不是我的母语，所以如果造成任何混淆，我提前道歉。
长话短说，我正在做一项关于学校如何传递知识的博士研究，在这个阶段，我试图弄清楚学习教科书如何有助于考试，然后了解为什么有些学生即使花了几个小时学习教科书，成绩仍然很差，以及这种复习方法在哪个年级失效了。
因此，我试图将试卷中的文本与教科书中的文本进行比较。我想知道试卷中有多少单词直接来自教科书，即文本 1 中有多少单词与文本 2 中的单词相同。理想情况下，结果将如下所示：
文本 1 中的单词出现在文本 2 中：
生日——2 次
姐妹——4 次
... 等等。
我以为已经有某种 AI 助手可以完成这样的任务，但到目前为止我的搜索都是徒劳的。所以我想知道是否有任何方法可以进行这样的比较？非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658749/how-do-i-count-the-occurrences-of-words-of-text-1-in-text-2</guid>
      <pubDate>Sun, 15 Dec 2024 11:25:59 GMT</pubDate>
    </item>
    <item>
      <title>具有低 R 平方和负对数似然的 EGARCH 模型 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658746/egarch-model-with-low-r-squared-and-negative-log-likelihood</link>
      <description><![CDATA[我对编码不是很有经验，一直在研究我在 GitHub 上找到的一个模型，以估计标准普尔 500 指数的波动性。该代码实现了 EGARCH(1,1) 模型，但我注意到 R 平方相当低，对数似然为高度负值，这表明该模型表现不佳。
我想知道是否有人可以帮助改进模型或提供建议以使其更具功能性。具体来说，如果有人能分享更强大的实现或修改来改善模型的性能指标，我将不胜感激。
以下是问题的简要概述：
数据集：标准普尔 500 指数每日回报和 VIX 数据。
问题：R 平方低且对数似然非常负。
目标：增强模型的解释能力和预测准确性。
import pandas as pd
import numpy as np
import yfinance as yf
from arch import arch_model
import statsmodels.api as sm
import matplotlib.pyplot as plt

# 从 Yahoo Finance 下载标准普尔 500 指数和 VIX 数据
sp500 = yf.download(&#39;^GSPC&#39;, start=&#39;2000-01-01&#39;, end=&#39;2021-09-01&#39;, progress=False)
vix = yf.download(&#39;^VIX&#39;, start=&#39;2000-01-01&#39;, end=&#39;2021-09-01&#39;, progress=False)

# 计算标准普尔 500 指数的每日收益
sp500[&#39;SP500_Returns&#39;] = 100 * sp500[&#39;Adj Close&#39;].pct_change().dropna()

# 计算已实现方差（平方收益）
sp500[&#39;Realized_Variance&#39;] = sp500[&#39;SP500_Returns&#39;]**2

# 合并标准普尔 500 收益和 VIX 数据
# 更改为合并 vix 的日期列，而不是索引。重置 vix 的索引以获取日期列。
data = pd.merge(sp500, vix.reset_index()[[&#39;Date&#39;, &#39;Adj Close&#39;]], on=&#39;Date&#39;, how=&#39;inner&#39;)
data.columns = [&#39;Date&#39;, &#39;Open&#39;, &#39;High&#39;, &#39;Low&#39;, &#39;Close&#39;, &#39;Adj Close&#39;, &#39;Volume&#39;, &#39;SP500_Returns&#39;, &#39;Realized_Variance&#39;, &#39;VIX&#39;]

# 将“日期”输入到指数中
data = data.set_index(&#39;Date&#39;)

# data[&#39;VIX&#39;] = data[&#39;VIX&#39;].shift(1) # 使用滞后 VIX
data = data.dropna()
data[&#39;VIX&#39;] = data[&quot;VIX&quot;]**2

# 拟合 EGARCH(1,1) 模型
egarch_model = arch_model(data[&#39;SP500_Returns&#39;], vol=&#39;EGARCH&#39;, p=1, q=1)
egarch_results = egarch_model.fit()

# 获取 EGARCH 方差估计值
data[&#39;EGARCH_Variance&#39;] = egarch_results.conditional_volatility**2

# 将数据拆分为训练集和测试集
train_data = data.iloc[:-150] # 使用除过去 252 天（大约一年）以外的所有数据进行训练
test_data = data.iloc[-150:] # 使用过去 252 天进行测试

# 模型 1：实际方差与 EGARCH 方差
X1_train = train_data[[&#39;EGARCH_Variance&#39;]]
X1_train = sm.add_constant(X1_train)
y_train = train_data[&#39;Realized_Variance&#39;]

model1 = sm.OLS(y_train, X1_train)
results1 = model1.fit()

# 模型 2：实际方差与 EGARCH 方差和 VIX 水平
X2_train = train_data[[&#39;EGARCH_Variance&#39;, &#39;VIX&#39;]]
X2_train = sm.add_constant(X2_train)

model2 = sm.OLS(y_train, X2_train)
results2 = model2.fit()

# 样本外预测
X1_test = test_data[[&#39;EGARCH_Variance&#39;]]
X1_test = sm.add_constant(X1_test)
y_test = test_data[&#39;Realized_Variance&#39;]

X2_test = test_data[[&#39;EGARCH_Variance&#39;, &#39;VIX&#39;]]
X2_test = sm.add_constant(X2_test)

y_pred_model1 = results1.predict(X1_test)
y_pred_model2 = results2.predict(X2_test)

# 绘制样本外预测值与实际实现方差的关系
plt.figure(figsize=(12, 6))
plt.plot(test_data.index, y_test, label=&quot;Realized Variance&quot;, linewidth=2, color=&quot;black&quot;, alpha=0.7)
plt.plot(test_data.index, y_pred_model1, label=&quot;Model 1 (EGARCH Variance)&quot;, linestyle=&quot;--&quot;, linewidth=2, color=&quot;red&quot;)
plt.plot(test_data.index, y_pred_model2, label=&quot;Model 2 (EGARCH Variance + VIX)&quot;, linestyle=&quot;:&quot;, linewidth=2, color=&quot;blue&quot;)

plt.ylabel(&quot;方差&quot;)
plt.legend()
plt.title(&quot;样本外预测与实际实现方差&quot;)
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/658746/egarch-model-with-low-r-squared-and-negative-log-likelihood</guid>
      <pubDate>Sun, 15 Dec 2024 09:28:48 GMT</pubDate>
    </item>
    <item>
      <title>表 2 谬误与变量选择</title>
      <link>https://stats.stackexchange.com/questions/658745/table-2-fallacy-and-choice-of-variables</link>
      <description><![CDATA[我有几个棘手的问题要问您。
我正在开展一项观察性研究，在使用 weighthem 加权我的数据集后，我使用 g 计算估计了平均治疗效果 (ATE)。下面是我使用的代码：
使用的公式：
Treatment_type_tumor_near_gallbladder ~ age_binary + bmi_binary + 
comorbidities + Segments_treated_per_session_binned + Metastasis_size_at_treatment_mm + 
min_distance_gallblad_mm + stage_binary + Metastasis_location_superficial

混杂因素选择比率：(1) 我从数据集中的所有变量中仅选择了具有临床意义的变量，(2) 我仅使用与结果和暴露高度相关的变量（单变量分析中的 alpha&lt;0.2）来计算 PS。

# 在每个估算数据集中执行 IPW
w.out_model1_ATE &lt;- weightthem(formula, 
data = new_amcore_imputed, 
method = &quot;cbps&quot;, # ebal, cbps, glm, gbm, energy, OptWeight, IPT
estimand = &quot;ATE&quot;,
criterion = &quot;smd.mean&quot;, 
) 

在数字 (bal.tab) 和图形 (love.plot) 上检查平衡后，我使用 g 计算方法估计了 ATE：
# 使用逻辑回归 PS 对 ATE 进行 PS 加权
results_all &lt;- with(model_to_use, 
WeightIt::glm_weightit(log_regression_formula, family = quasibinomial, weightit = model_to_use), cluster = FALSE)

# 计算风险比量表上的 ATE
ATE_all &lt;- lapply(results_all$analyses, function(fit) {
marginaleffects::avg_comparisons(fit, variable = predictors_log_regression,
Comparison = &quot;lnratioavg&quot;) # lnratioavg 这将返回风险比量表上的 ATE。要获取比值比量表上的 ATE，请将比较更改为 &quot;lnoravg&quot;。要获取风险差异量表上的 ATE，请删除比较并取指数。
})

# 汇总结果并总结
ATE_results &lt;- ATE_all |&gt; mice::pool() |&gt; summary(exponentiate = TRUE, conf.int = TRUE) |&gt; mutate(across(where(is.numeric), \(x) round(x, digits = 3)))

# 打印结果
ATE_results

在上面的代码中，我还调整了那些在 PS 估计中未使用的临床显著混杂因素，因为它们与暴露或结果 (alpha&gt;0.2) 没有很强的关联，即性别、ASA 状态和之前的化疗治疗 (log_regression_formula: 并发症 ~ 治疗 + 性别 + ASA + 化疗)。“
这些是结果：



term
contrast
estimate
std.error
statistic
df
p.value
2.5 %
97.5 %




ASA_binary
ln(mean(3) /平均值(&lt;=2))
1.609
0.215
2.210
85514.88
0.027
1.055
2.454


Systemic_treatment_prior_local_treatment
ln(平均值(是) /平均值（无））
1.027
0.240
0.113
69958.72
0.910
0.642
1.644


治疗类型_胆囊附近肿瘤
ln(平均值（MWA）/平均值（切除））
0.537
0.233
-2.668
28006.78
0.008
0.340
0.848


性别
ln(平均值（男性）/平均值（女性））
0.788
0.257
-0.929
49753.64
0.353
0.476
1.303



我有两个问题：

使用 glm_weightit 时，在单变量分析中包含未达到 0.2 alpha 阈值的临床显著变量是否合适，还是最好忽略它们？
阅读 WeightIt 文档中的博客文章后（https://ngreifer.github.io/WeightIt/articles/estimating-effects.html#ref-westreichTableFallacyPresenting2013) 和文章 Westreich et al., 2013 (https://doi.org/10.1093/aje/kws412)，我理解，为了避免表 2 谬误，只有治疗的估计值才应被解释和报告为效果。例如，ASA 状态的相对风险 (RR) 不应以与治疗效果相同的方式解释。我的解释正确吗？

提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/658745/table-2-fallacy-and-choice-of-variables</guid>
      <pubDate>Sun, 15 Dec 2024 09:23:45 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn QuantileRegressor 中 L1 正则化的 alpha 参数是什么</title>
      <link>https://stats.stackexchange.com/questions/658748/what-is-the-alpha-parameter-for-l1-normalization-in-scikit-learn-quantileregress</link>
      <description><![CDATA[scikit-learn Quantile Regression 文档中的 示例 展示了一个将参数 alpha 设置为零的示例。默认值为 1。
文档 QuantileRegressor 显示默认值设置为 1.0。它指出这是一个乘以 L1 惩罚项的正则化常数。
我对 Lasso 是什么或 L1 回归的确切含义没有直观的理解。
参数 alpha 与这些事物的关系是否有直观的解释？
有一篇与分位数回归相关的 维基百科文章，非常详细。浏览此文，在正则化参数的选择部分中，alpha 似乎就是 lambda。它在其他地方也可能被称为t。
我的直觉可能是错的。
到目前为止，我的结论是 alpha 可能只在多维（&gt; 1）回归问题中起作用，它可能用于选择维度的子集，即具有最强统计预测能力的最重要维度？]]></description>
      <guid>https://stats.stackexchange.com/questions/658748/what-is-the-alpha-parameter-for-l1-normalization-in-scikit-learn-quantileregress</guid>
      <pubDate>Sun, 15 Dec 2024 08:40:50 GMT</pubDate>
    </item>
    <item>
      <title>小离散值的分布可视化</title>
      <link>https://stats.stackexchange.com/questions/658744/distributional-visualization-of-small-discrete-values</link>
      <description><![CDATA[对于研究对象，每种测量类型我几乎只得到 40 个小整数计数。计数从零开始，分布高度正偏。参见附图。无需赘述，从样本中可以得出结论，经过测试的、非常简单的测试假设可以肯定地被接受。但是，从这种类型的离散小值数据中可视化分布体有什么合适的方法吗？在图像中，我添加了 ggplot2 R 包中的典型 geom_boxplot，没有离群值和晶须，以显示中位数、第一和第三四分位数，以帮助理解分布。如果仅显示单个测量值（沿 y 轴略微抖动以缓解视觉分离），它看起来有点不直观的“空洞”。您是否保持 geom_boxplot 合理，或者您可以提出其他建议？

从这里找到了小提琴图表的提议：分析/可视化紧密分组的离散结果]]></description>
      <guid>https://stats.stackexchange.com/questions/658744/distributional-visualization-of-small-discrete-values</guid>
      <pubDate>Sun, 15 Dec 2024 08:39:49 GMT</pubDate>
    </item>
    <item>
      <title>估计者的期望</title>
      <link>https://stats.stackexchange.com/questions/658727/expectations-of-estimators</link>
      <description><![CDATA[我正在研究一些面板数据计量经济学主题，我遇到了以下渐近性质：$N \to \infty$:
\begin{equation}
\theta^{\ast} \to \frac{\mathbb{E}(​​\beta_i)}{1 - \mathbb{E}(​​\gamma_i)} 
\quad \text{and} \quad 
\bar{\theta} \to \mathbb{E}\left(\frac{\beta_i}{1 - \gamma_i}\right) = \mathbb{E}(​​\theta_i),
\end{equation&gt;
幻灯片指出，除非$\beta_i$ 和 $\gamma_i$ 是独立分布的。为什么会这样？具体来说，为什么比率的期望值不等于期望值的比率？随机参数分布的独立性在这种差异中起什么作用？原因很简单，因为如果 $\beta_i$ 和 $\gamma_i$ 是独立的随机系数，则联合期望为：$\mathbb{E} (\beta_i) \times \mathbb{E}\left(\frac{1}{1-\gamma_i}\right)$?]]></description>
      <guid>https://stats.stackexchange.com/questions/658727/expectations-of-estimators</guid>
      <pubDate>Sat, 14 Dec 2024 22:35:57 GMT</pubDate>
    </item>
    <item>
      <title>包含 4 个变量的等高线图</title>
      <link>https://stats.stackexchange.com/questions/658747/contour-plot-with-4-variables</link>
      <description><![CDATA[我使用 ggplot 包绘制了以下轮廓图
library(ggplot2)
library(reshape2)

f &lt;- function(x, y) { r &lt;- sqrt(x^2+y^2+8^2+8^2); 10 * sin(r)/r }

x = y = seq(-10, 10, length.out = 30)
z = cbind(data.frame(x), as.data.frame(outer(x, y, f))
names(z) = c(&#39;x&#39;, as.character(y))

z1 = melt(z, id.vars = &#39;x&#39;)
names(z1) = c(&#39;x&#39;, &#39;y&#39;, &#39;z&#39;)
z1$y = as.numeric(as.character(z1$y))

ggplot(z1, aes(x, y, z = z)) + geom_contour() + geom_contour_filled()

虽然只有 2 个独立变量（即 x 和 y）就可以了，但我实际上有一个包含 4 个变量的函数，例如以下
f &lt;- function(x, y, p, q) { r &lt;- sqrt(x^2+y^2+p^2+q^2); 10 * sin(r)/r }

您能指导我是否有办法绘制上述函数的轮廓图吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658747/contour-plot-with-4-variables</guid>
      <pubDate>Fri, 13 Dec 2024 21:55:39 GMT</pubDate>
    </item>
    <item>
      <title>Jeffreys 离散参数空间的先验</title>
      <link>https://stats.stackexchange.com/questions/658678/jeffreys-prior-for-a-discrete-parameter-space</link>
      <description><![CDATA[以下问题涉及二项分布，其概率已知$p$，但试验次数未知$n$。
试验次数的二项置信区间
尝试思考如何为这种情况构建贝叶斯区间，我首先进入了思考 Jeffreys 先验的阶段。但是，对于离散参数空间，这没有定义，因为导数不存在。
是否有根据相同想法找到先验的方法？当然，坐标变换下分布的不变性已经过时，因为概率质量函数不会像概率密度函数那样变换。这是 Jeffreys 先验的唯一属性/动机吗，或者还有其他属性可以应用于概率质量函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/658678/jeffreys-prior-for-a-discrete-parameter-space</guid>
      <pubDate>Fri, 13 Dec 2024 16:07:13 GMT</pubDate>
    </item>
    <item>
      <title>当 $X\sim \operatorname{Beta}(\alpha,\beta)$ 时，$Y=-\log(X)$ 的分布</title>
      <link>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</guid>
      <pubDate>Fri, 13 Dec 2024 11:02:03 GMT</pubDate>
    </item>
    <item>
      <title>试验次数的二项置信区间</title>
      <link>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</link>
      <description><![CDATA[我有一个过程，其成功概率为已知$p$，失败概率为$q = 1-p$。该过程重复有限但未知的次数$n$。
给定成功次数$r$（失败次数$n-r$，未知），我们应该如何确定导致$r$次成功的试验次数的置信区间？
举一个简单的例子，一枚公平的硬币总共被抛了$n$次，其中150次正面朝上落地。 $n$ 是如何分布的，其平均值的 95% 置信区间是多少，涵盖 $n$ 最可能的值。最可能的$n$ 为 300，最小的$n$ 为 150，最大的$n$ 为无穷大，但我们如何考虑介于两者之间的一切？
注意：如果分布不对称，间隔不必以平均值为中心。

我一直在研究威尔逊分数和其他二项比例置信区间，它们是相关的，但它们估计的是$p$，而不是$n$。我想知道是否存在类似的方法可以实现我所寻找的目标。
由于缺乏一个封闭的估计​​公式，我只能尝试通过拟合两个高斯分布来找到我的置信区间$(n_{low}, n_{high})$的端点，这两个高斯分布的均值为$n_{low}p$和$n_{high}p$，其中$\hat{n}p$（其中$\hat{n} = r/p$是我估计的$n$）落在其 2.5% 面积尾部边界上，使用表格。]]></description>
      <guid>https://stats.stackexchange.com/questions/658657/binomial-confidence-interval-over-the-number-of-trials</guid>
      <pubDate>Thu, 12 Dec 2024 17:08:40 GMT</pubDate>
    </item>
    <item>
      <title>权重线性回归中的高斯对数似然值如何计算？</title>
      <link>https://stats.stackexchange.com/questions/658636/how-is-gaussian-log-likelihood-value-calculated-in-weight-linear-regression</link>
      <description><![CDATA[我检查了这些 R 函数 glm.fit() gaussian()$aic stats:::logLik.glm() 和 stats:::logLik.lm()，发现 stats:::logLik.glm() 报告的对数似然值是根据 gaussian()$aic 计算的，其定义为
function (y, n, mu, wt, dev) 
{
nobs &lt;- length(y)
nobs * (log(dev/nobs * 2 * pi) + 1) + 2 - sum(log(wt))
}

stats:::logLik.lm() 报告的对数似然值使用以下公式计算。
0.5 * (sum(log(w)) - N * (log(2 * pi) + 1 - log(N) + 
log(sum(w * res^2))))

这两个公式在高斯家族中得出相同的 logLik 和 AIC。我理解 $AIC = -2 \ln{L} + 2df$ 并且可以重现与基本函数 logLik() 相同的结果，但我不知道为什么要以上述方式计算它们。使用基于经典公式的对数密度值总和，如“正态分布 - 最大似然估计”中所示https://www.statlect.com/fundamentals-of-statistics/normal-distribution-maximum-likelihood，我得到了不同的对数似然值，无法识别我的计算和默认输出之间的关系。请参阅以下最小示例。
Data &lt;- data.frame(
y = c(0.2, 0.2, 0.3), 
n = c(10, 20, 30)
)

# GLS 模型
with(Data, sum(y * n)/sum(n)) # 0.25
summary(Model &lt;- glm(y ~ 1, weights = n, data = Data))
&quot;估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.25000 0.03536 7.071 0.0194 *
(高斯族的分散参数取为 0.075)
零偏差：2 个自由度上的 0.15
残差偏差：2 个自由度上的 0.15
AIC：-5.1731&quot;
with(Model, Prior.weights)
&quot; 1 2 3 
10 20 30 &quot;
with(Model, weights)
&quot; 1 2 3 
10 20 30 相同，无迭代重新加权&quot;

# 默认函数
logLik(Model)
&quot;4.58654 (df=2)&quot;
AIC(模型)
&quot;-5.17308 因为 -2 * 4.58654 + 2 * 2 == -5.17308&quot;
with( # 基于 gaussian()$aic 和 glm.fit()
模型，nobs(模型) * (log(deviance/nobs(模型) * 2 * pi) + 1) + 
2 - sum(log(weights)))
&quot;-7.17308
-7.17308 + 2*1 == -5.17308 是报告的 AIC
logLik 源自 AIC 测量&quot;

# OLS 模型
summary(模型 &lt;- lm(y ~ 1, weights = n, data = Data))
logLik(模型)
&quot;4.58654 (df=2) 与上文相同&quot;
AIC(Model)
&quot;-5.17308 与上文相同&quot;
with(Model, 0.5 * (
sum(log(weights)) - nobs(Model) * (
log(2 * pi) + 1 - log(nobs(Model)) + log(sum(weights * residuals^2)))))
&quot;4.58654 为报告的 logLik&quot;

# 手动计算
with(Model, sum(prior.weights * log(
dnorm(y, mean = coef(Model), sd = sigma(Model)))))
&quot;21.5717&quot;
with(Model, sum(weights) * (-1/2 * log(2 * pi)))
&quot;-55.13631&quot;
带有（模型，总和（权重）*（-1/2 * log（sigma（模型）^2）））
“77.70801”
带有（模型，（-1/（2 * sigma（模型）^2））* 总和（权重*（y - coef（模型））^2））
“-1
-55.13631 + 77.70801 - 1 == 21.5717”
with(Model, sum(weights * (y - coef(Model))^2))

答案和更新
常规高斯密度函数是
$f_a = \frac{1}{\sqrt{2\pi\sigma^2}}\exp{-\frac{(y_i − \hat{y}^2_i)}{2\sigma^2}}$
但当有权重时，它就变成
$f_b = \frac{1}{\sqrt{2\pi\sigma^2/w_i}}\exp{-\frac{(y_i − \hat{y}^2_i)}{2\sigma^2/w_i}}$
这表明底层正态分布的方差为 $\sigma^2/w_i$。直观地看，它类似于计算为$SD/\sqrt{n}$的平均标准误差，这表明组大小（即权重）越大，误差方差$s^2/n$越小。
基于gaussian()$aic的stats:::logLik.lm()和stats:::logLik.glm()都使用$N\sigma^2 = \sum{w_i(y_i - \hat{y}^2_i)}$来取消上面的$\sigma$项。但是，我不明白为什么默认不使用$(N-p)\sigma^2 = \sum{w_i(y_i - \hat{y}^2_i)}$。这就是$\sigma$在lm()和glm()中的导出方式，它对应于残差方差的无偏估计，而不是低估残差方差的最大似然估计量。]]></description>
      <guid>https://stats.stackexchange.com/questions/658636/how-is-gaussian-log-likelihood-value-calculated-in-weight-linear-regression</guid>
      <pubDate>Thu, 12 Dec 2024 17:03:36 GMT</pubDate>
    </item>
    </channel>
</rss>