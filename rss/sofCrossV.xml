<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 26 Nov 2024 03:30:28 GMT</lastBuildDate>
    <item>
      <title>R 最适合拟合正偏指数数据的 glmmTMB 模型系列是什么</title>
      <link>https://stats.stackexchange.com/questions/657842/r-what-is-the-best-glmmtmb-model-family-to-fit-positively-skewed-index-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657842/r-what-is-the-best-glmmtmb-model-family-to-fit-positively-skewed-index-data</guid>
      <pubDate>Tue, 26 Nov 2024 02:34:04 GMT</pubDate>
    </item>
    <item>
      <title>在频率论的背景下，我们如何能够确定零假设为真/假？</title>
      <link>https://stats.stackexchange.com/questions/657840/in-a-frequentist-setting-how-are-we-able-to-condition-on-the-null-hypothesis-be</link>
      <description><![CDATA[引用 Casella 和 Berger (2002) 的话：假设检验由零假设 $H_0: \theta \in \Theta_0 $ 和备择假设 $H_1: \theta \in \Theta_0^c = \bar{H_0}$ 定义，其中 $\Theta$ 是总体参数 $\theta$ 的一组可能值，并且 $\Theta_0^c = \Theta - \Theta_0 $。
在频率论的设定中，$\theta$ 是一个未知但固定的量（也就是说，它是非随机的）。因此，对于给定集合$\Theta_0$，零假设$H_0$严格为真或假（但我们不知道是哪个）。备择假设，即否定，相应地为假或真。
让我们的检验统计量为$\hat{\theta} = f(X_1, ..., X_n)$。我们将拒绝域$RR \subset Range(\hat{\theta})$定义为我们选择拒绝$H_0$的检验统计量$\hat{\theta}$的值集。由于我们的样本 $X_1, ..., X_n$ 是随机的，$\hat{\theta}$ 是一个随机变量，因此数量 $p(\hat{\theta} \in RR)$ 是一个有效概率，类似于更简单的概率，如 $p(X \le 5)$
到目前为止一切顺利。然而，当我们开始定义 I 类错误时，我开始感到困惑。I 类错误是当我们拒绝 $H_0$ 即使它是 True 时。这在数学上定义为：
$$
\alpha = p(\hat{\theta} \in RR | H_0 \text{ is True}) = p(\hat{\theta} \in RR | \theta \in \Theta_0)
$$
这个概率对我来说毫无意义。$\theta$ 不是随机变量，因此 $\theta \in \Theta_0$ 不是概率事件，而是 True 或 False 值。概率框架（据我所知）不允许我们有意义地对实值或布尔值进行条件限制，而只能对事件进行条件限制。
这是怎么回事？我能做出的唯一有意义的解释是$\theta$是否是一个随机变量，这违反了频率统计的核心思想。]]></description>
      <guid>https://stats.stackexchange.com/questions/657840/in-a-frequentist-setting-how-are-we-able-to-condition-on-the-null-hypothesis-be</guid>
      <pubDate>Tue, 26 Nov 2024 01:27:13 GMT</pubDate>
    </item>
    <item>
      <title>理解重复实验中置信区间的解释</title>
      <link>https://stats.stackexchange.com/questions/657838/understanding-the-interpretation-of-confidence-intervals-in-repeated-experiments</link>
      <description><![CDATA[我理解 95% 置信区间 (CI) 的解释是，从长远来看，从重复实验计算出的 95% 的区间将包含真实参数。我还知道 CI 不是关于参数本身的概率陈述 - 我们不能说特定观察到的 CI 有 95% 的概率包含真实值。
但是，我试图理解以下场景：
假设我们运行 100 次实验，每次都计算感兴趣参数的 95% 置信区间。如果我随机选择其中一个 CI，那么说所选区间有 95% 的概率包含真实参数是否正确？
关键区别在于我们不能说相同的固定 CI 在重复实验中将保持 95% 的概率，而是每次新的重复都有新的 CI 值，并且每个新值都有 95% 的概率包含或不包含？]]></description>
      <guid>https://stats.stackexchange.com/questions/657838/understanding-the-interpretation-of-confidence-intervals-in-repeated-experiments</guid>
      <pubDate>Tue, 26 Nov 2024 00:12:44 GMT</pubDate>
    </item>
    <item>
      <title>频率移动平均值</title>
      <link>https://stats.stackexchange.com/questions/657837/moving-average-of-frequency</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657837/moving-average-of-frequency</guid>
      <pubDate>Tue, 26 Nov 2024 00:00:35 GMT</pubDate>
    </item>
    <item>
      <title>非消失步长 Q 学习</title>
      <link>https://stats.stackexchange.com/questions/657836/non-vanishing-stepsize-q-learning</link>
      <description><![CDATA[第一篇关于 q-learning 的论文使用步长 $(\alpha_n)_n\subset (0,1)$，使得
$$
\sum_n \alpha_n = \infty
$$
但
$$
\sum_n \alpha^2_n &lt; \infty。
$$
最近，在浏览 Bertsekas 和 Tsitsiklis 关于命题 $4.4$ 的神经动力学编程书籍时，我看到了以下陈述：
让 $r_t$ 由
$$
r_{t+1}(i) = (1-\alpha_t(i)) r_t(i) + \alpha_t(i) ( (Hr_t)(i)+w_t(i),
$$
其中 $w_t$ 是随机的，并且满足 $E[w_t(i)|\mathcal F_t]=0$ 对所有 $i$ 和 $t$ 和
$$
E[w^2_t(i)|\mathcal F_t \ \leq A + B \| r_t\|^2
$$
对于 $\mathbb R^n$ 上的任何范数。这里我们假设 $H$ 是一个伪收缩，即 $\| Hr - r^* \| \leq \beta \| r- r^* \|$ 对于所有 $r \in \mathbb R^n$ 且某些 $r^*$，其中 $\beta &lt;1$。然后，当 $ \sum_n \alpha_n = \infty$ 和 $\sum_n \alpha^2_n = \infty$ 时，$r_t$ 以概率 $1$ 收敛到 $r^*$ 
这里本质上 $H$ 充当值迭代算法。没有提供任何证据，所以我无法理解他们在哪个阶段使用了 $\sum_n \alpha^2_n = \infty$，但在声明之后提到它将在 $5$ 章中使用。在 $5$ 章中，它仅在命题 $5.5$ 中使用，其中还假设 $\sum_n \alpha^2_n &lt;\infty$。我不确定这里是否是提出这个问题的正确地方，但他们在声明中假设 $\sum_n \alpha^2_n = \infty$ 实际上是拼写错误吗？在此条件下，$Q$-学习是否存在任何已知的收敛条件？我只有这本书的纸质版，因此无法发布实际陈述的截图，对此深表歉意。]]></description>
      <guid>https://stats.stackexchange.com/questions/657836/non-vanishing-stepsize-q-learning</guid>
      <pubDate>Mon, 25 Nov 2024 22:59:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 MatchThem 进行倾向得分匹配 (PSM)</title>
      <link>https://stats.stackexchange.com/questions/657835/propensity-score-matching-psm-using-matchthem</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657835/propensity-score-matching-psm-using-matchthem</guid>
      <pubDate>Mon, 25 Nov 2024 22:53:25 GMT</pubDate>
    </item>
    <item>
      <title>在指数增长的集合中选择相同随机数的概率</title>
      <link>https://stats.stackexchange.com/questions/657833/chances-of-same-random-number-selection-over-an-exponentially-growing-set</link>
      <description><![CDATA[如果我每秒从一组数字中随机选择一个数字，该数字最初是集合 {1-&gt;10^100}，然后每秒大小翻倍，持续 1,000 秒，那么我在此期间两次选择相同两个数字的概率是多少？
1,000,000 秒呢？
1,000,000,000 秒呢？
1,000,000,000,000 秒呢？
当秒数趋于无穷大时，概率会趋于什么？
我之所以问这个问题，是因为我不相信我一直听到物理学家说的话，即如果多元宇宙（由永恒的膨胀创造，包含无限的可观测宇宙，如我们的宇宙）是无限的，那么可以保证有无限的“可观测宇宙”，其中的行星与我一模一样，现在做着和我一样的事情。我认为他们可能忽略了每个“可观测宇宙”的可能性空间无限大这一关键概念，这使得事情不必重复。如果上述数学问题的答案是一个非常低的概率，并且随着秒数趋于无穷大，它趋向于零，那么我觉得这可能支持我的感觉，即物理学家可能是错的。然后，您可以尝试将上述场景中的数字映射到每个“可观测宇宙”中原子的可能组合数，然后询问在无限的宇宙集中找到两个相同宇宙的概率是多少。答案可能是“几乎为零”。也许我问错了问题？想法......？]]></description>
      <guid>https://stats.stackexchange.com/questions/657833/chances-of-same-random-number-selection-over-an-exponentially-growing-set</guid>
      <pubDate>Mon, 25 Nov 2024 22:14:58 GMT</pubDate>
    </item>
    <item>
      <title>对数秩和 Cox 模型的假设类似。请求文章参考</title>
      <link>https://stats.stackexchange.com/questions/657830/similar-assumptions-for-log-rank-and-cox-model-request-for-article-reference</link>
      <description><![CDATA[我理解，具有单个二元预测因子且回归常数等于零的 Cox 模型的得分函数等于对数秩检验的统计数据（数学的简单重写）。因此，这就是对数秩检验和 Cox 模型都假设比例风险的主要论点。
例如，请参阅对数秩检验统计量相当于 Cox 回归的得分。使用对数秩检验比 Cox 回归有什么优势吗？
但是，我找不到任何好的参考资料来添加到肿瘤学中的一篇论文中，我需要在其中证明使用 Cox 而不是对数秩的合理性。实际上，问题在于比例风险检验的 p 值低于 5%（因此实际上我们不能使用其中任何一个）。有些人可能会认为应该使用对数秩检验，因为它“不依赖于任何假设”，这是非统计学家的普遍理解。如上所述，我不同意使用对数秩检验（和 Cox）。不过，我需要一个参考资料（也可以放在我们正在撰写的论文中），我可以将其用作我的论证的一部分，即 Cox 和对数秩的假设实际上是相同的——并不是每个人都能看到数学偏差的美。您能否提供任何与上述问题相关的有用的论文参考资料？我可以在网上找到很多陈述，但我需要一篇文章参考资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/657830/similar-assumptions-for-log-rank-and-cox-model-request-for-article-reference</guid>
      <pubDate>Mon, 25 Nov 2024 21:42:54 GMT</pubDate>
    </item>
    <item>
      <title>概率收敛速度</title>
      <link>https://stats.stackexchange.com/questions/657829/rate-of-convergence-in-probability</link>
      <description><![CDATA[我正在阅读这篇论文
在这篇论文中，他们证明了定理 7，其表述如下

定理 7：让 $p, q, X, Y$ 按照问题 1 中的方式定义，并假设 $0 \leq k(x, y) \leq K$。然后：
$$
\Pr_{X, Y} \left\{ 
\big| \text{MMD}_b[\mathcal{F}, X, Y] - \text{MMD}[\mathcal{F}, p, q] \big| &gt; 2 \left( \left( \frac{K}{m} \right)^{\frac{1}{2}} + \left( \frac{K}{n} \right)^{\frac{1}{2}} \right) + \varepsilon
\right\}
\leq 
2 \exp\left(-\frac{\varepsilon^2 mn}{2K(m+n)}\right),
$$
其中 $Pr_{X, Y}$ 表示 $m$ 个样本 $X$ 和 $n$ 个样本 $Y$ 的概率。

在此之前定理中，作者指出经验 MMD 以 $O((m+n)^{-\frac{1}{2}})$ 的概率收敛到其总体值。我不明白他们是如何得出这个收敛速度的。您能否提醒我一下以速率收敛的概率定义，并解释它与定理 7 有何关联？]]></description>
      <guid>https://stats.stackexchange.com/questions/657829/rate-of-convergence-in-probability</guid>
      <pubDate>Mon, 25 Nov 2024 21:18:24 GMT</pubDate>
    </item>
    <item>
      <title>VAE 为何有效？</title>
      <link>https://stats.stackexchange.com/questions/657828/why-do-vaes-work</link>
      <description><![CDATA[我目前正在阅读《变分自动编码器》，虽然我有点理解原始论文（自动编码变分贝叶斯）中描述的数学背景，但我还是很难理解为什么训练 VAE 会真正起作用。
在训练 VAE 时，我们不会简单地从编码器的输出重建图像，而是从由编码器输出参数化的分布中提取的样本重建图像。在这样做的过程中，我们不仅优化了重建损失，还优化了 KL 正则化项，该项希望后验$q(z|x)$接近$p(z)$，其中$p(z)$是一些简单的预定义分布，如高斯分布。据我所知，KL 散度正则化只会尝试将编码器的平均输出拉向 $\mathbf{0}$ 向量，将方差拉向 $\mathbf{1}$ 向量。当该项变为零时，我们会遇到后验崩溃，因为显然潜在的$z$变得完全随机（即因为$z = \mu + \epsilon \cdot \sigma = \epsilon$并且解码器只是忽略它们。这是我不明白的：如果我们最终得到后验崩溃，如果编码器的输出接近各向同性高斯，为什么从各向同性高斯采样可以生成新图像？
我做了一些挖掘，但找不到任何解释。也许我正在寻找错误的东西，所以如果这是一个重复的或者有其他资源可以解释这一点，我很乐意被指向正确的方向。
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657828/why-do-vaes-work</guid>
      <pubDate>Mon, 25 Nov 2024 20:41:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的回归中的 HAC（Newey-West）标准误差小于普通标准误差？</title>
      <link>https://stats.stackexchange.com/questions/657795/why-are-the-hac-newey-west-standard-errors-smaller-than-the-ordinary-standard</link>
      <description><![CDATA[我用时间序列进行回归分析，然后进行了 Breusch-Godfrey（BG）检验和 White 检验。检验结果表明，自相关和异方差同时存在。因此，我选择使用 HAC（Newey-West）标准误差进行分析。我惊讶地发现，HAC（Newey-West）标准误差比普通标准误差要小。为什么会这样？在这种情况下，我应该使用哪种标准误差？]]></description>
      <guid>https://stats.stackexchange.com/questions/657795/why-are-the-hac-newey-west-standard-errors-smaller-than-the-ordinary-standard</guid>
      <pubDate>Mon, 25 Nov 2024 10:09:08 GMT</pubDate>
    </item>
    <item>
      <title>信息标准相对于交叉验证的优势</title>
      <link>https://stats.stackexchange.com/questions/657772/advantages-of-information-criteria-over-cross-validation</link>
      <description><![CDATA[我理解 AIC 渐近等同于留一法交叉验证，而 BIC 具有与留一法交叉验证类似的渐近等同性。我的问题是，除了计算效率之外，还有什么理由比交叉验证更倾向于使用 AIC/wAIC/BIC 等信息标准？
在生态学文献中，使用 AIC 进行模型选择非常常见。但如果可以进行交叉验证，还有什么理由使用 AIC？]]></description>
      <guid>https://stats.stackexchange.com/questions/657772/advantages-of-information-criteria-over-cross-validation</guid>
      <pubDate>Sun, 24 Nov 2024 17:27:03 GMT</pubDate>
    </item>
    <item>
      <title>求分布未知但均值已知的方差比的置信区间</title>
      <link>https://stats.stackexchange.com/questions/657834/find-the-confidence-interval-of-ratio-of-variance-with-unknown-distribution-but</link>
      <description><![CDATA[根据上一个问题，我将假设对于随机样本 $X_1,X_2,\dots,X_n$ 和 $Y_1,Y_2,\dots,Y_n$，根据中心极限定理和 $\frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}} \xrightarrow{D} N(0,1)$。我原本想用这些定理将其归结为 F 分布，但我不确定你是否能做到这一点，因为它只是在分布上收敛，而不是实际分布。但除此之外，我不知道如何找到它。]]></description>
      <guid>https://stats.stackexchange.com/questions/657834/find-the-confidence-interval-of-ratio-of-variance-with-unknown-distribution-but</guid>
      <pubDate>Sun, 24 Nov 2024 06:07:49 GMT</pubDate>
    </item>
    <item>
      <title>理解合并回归模型的误差协方差</title>
      <link>https://stats.stackexchange.com/questions/657746/understanding-the-error-covariance-of-pooled-regression-model</link>
      <description><![CDATA[我正在阅读格林的《计量经济学分析》（第 7 版，2011 年）。在第 350 页，他讨论了随机效应回归模型：
$$
\begin{aligned}
y_{it} &amp;= x&#39;_{it} \beta + E[z&#39;_i \alpha] + \left[ z&#39;_i \alpha - E[z&#39;_i \alpha]\right] + \varepsilon_{it} \\
&amp;= x&#39;_{it} \beta + a + \varepsilon_{it} + (c_i - E[c_i | X_i]) \\
&amp;= x&#39;_{it} \beta + a + \varepsilon_{it} + u_i \\
&amp;= x&#39;_{it} \beta + a + w_{it}
\end{aligned}
$$
书中接着说未观察到的异质性（即$z&#39;_i\alpha$）会引起自相关：$t \ne s$时，$E[w_{it}w_{is}] = \sigma^2_u$。
我不相信我看到了这一点。如果我们取相对于时间的期望值 $t$，并注意到 $E_t[w_{it}] = \omega_i$
$$
\begin{aligned}
Cov_t(w_{it}, w_{is}) &amp;= E_t [(w_{it} - \omega_i)(w_{is} - \omega_i)]\\
&amp;= E_t(w_{it}w_{is}) + T \omega_i^2 \\
&amp;= E_t[(\varepsilon_{it} + u_i)(\varepsilon_{is} + u_i)] + T \omega_i^2 \\
&amp;= E_t[\varepsilon_{it} \varepsilon_{is}] + E_t[u_i^2] + T \omega_i^2 \\
&amp;= T(u_i^2 + \omega_i^2) \qquad \text{ for } t \ne s
\end{aligned}
$$
显然，从上面可以看出
$$
\begin{aligned}
E_t(w_{it}w_{is}) &amp;= E_t[(\varepsilon_{it} + u_i)(\varepsilon_{is} + u_i)] \\
&amp;= E_t[\varepsilon_{it} \varepsilon_{is}] + E_t[u_i^2] \\
&amp;= Tu_i^2 \qquad \text{ for } t \ne s
\end{aligned}
$$
他们是如何得到$\sigma^2_u$的？]]></description>
      <guid>https://stats.stackexchange.com/questions/657746/understanding-the-error-covariance-of-pooled-regression-model</guid>
      <pubDate>Sat, 23 Nov 2024 23:22:16 GMT</pubDate>
    </item>
    <item>
      <title>对于两个独立的 glmmTMB 模型，sjPlot::tab_model() 中存在相同的随机效应方差值 (sigma^2)，这是 R 的问题</title>
      <link>https://stats.stackexchange.com/questions/657742/r-issue-with-the-same-random-effect-variance-value-sigma2-in-sjplottab-mode</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657742/r-issue-with-the-same-random-effect-variance-value-sigma2-in-sjplottab-mode</guid>
      <pubDate>Sat, 23 Nov 2024 22:13:03 GMT</pubDate>
    </item>
    </channel>
</rss>