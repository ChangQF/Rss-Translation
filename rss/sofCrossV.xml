<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 25 Nov 2024 21:16:04 GMT</lastBuildDate>
    <item>
      <title>VAE 为何有效？</title>
      <link>https://stats.stackexchange.com/questions/657828/why-do-vaes-work</link>
      <description><![CDATA[我目前正在阅读《变分自动编码器》，虽然我有点理解原始论文（自动编码变分贝叶斯）中描述的数学背景，但我还是很难理解为什么训练 VAE 会真正起作用。
在训练 VAE 时，我们不会简单地从编码器的输出重建图像，而是从由编码器输出参数化的分布中提取的样本重建图像。在这样做的过程中，我们不仅优化了重建损失，还优化了 KL 正则化项，该项希望后验$q(z|x)$接近$p(z)$，其中$p(z)$是一些简单的预定义分布，如高斯分布。据我所知，KL 散度正则化只会尝试将编码器的平均输出拉向 $\mathbf{0}$ 向量，将方差拉向 $\mathbf{1}$ 向量。当该项变为零时，我们会遇到后验崩溃，因为显然潜在的$z$变得完全随机（即因为$z = \mu + \epsilon \cdot \sigma = \epsilon$并且解码器只是忽略它们。这是我不明白的：如果我们最终得到后验崩溃，如果编码器的输出接近各向同性高斯，为什么从各向同性高斯采样可以生成新图像？
我做了一些挖掘，但找不到任何解释。也许我正在寻找错误的东西，所以如果这是一个重复的或者有其他资源可以解释这一点，我很乐意被指向正确的方向。
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657828/why-do-vaes-work</guid>
      <pubDate>Mon, 25 Nov 2024 20:41:42 GMT</pubDate>
    </item>
    <item>
      <title>根据独立同分布样本之和推断分布</title>
      <link>https://stats.stackexchange.com/questions/657820/inference-of-distribution-from-sum-of-iid-samples</link>
      <description><![CDATA[假设我们观察到 $M$ 个样本 $S_j$，它们是 $N$ 个 i.i.d. 之和。从目标分布 $p_X(x)$ 中抽取 $X_i$ 样本（对于该分布，我们不能假设其为参数族 但我们可以假设其仅具有正支持），即
$S_j = \sum_{i=1}^{N}X_i$ 。
目标是执行后验$p(x|{S_1,...S_M})$的推断。
我正在尝试使用 Metropolis-Hastings 抽样的 MCMC 方法。由于问题的性质，我必须在每个 MCMC 步骤中提出 N 个样本。我已经尝试对 N 个样本中的每一个进行块更新和组件更新。我还尝试了一种自适应算法，对于块更新方案，多元高斯提议分布$q(\mathbf{x}^*|\mathbf{x})$的协方差矩阵被推向已接受样本的协方差。
但是，到目前为止，这两种方法都没有成功。
MCMC 是这里的正确方法吗？这种推断是否可行？
编辑：澄清问题以涵盖$M$观察总和$S_j$的情况。]]></description>
      <guid>https://stats.stackexchange.com/questions/657820/inference-of-distribution-from-sum-of-iid-samples</guid>
      <pubDate>Mon, 25 Nov 2024 18:30:25 GMT</pubDate>
    </item>
    <item>
      <title>样本均值的中位数顺序</title>
      <link>https://stats.stackexchange.com/questions/657818/order-of-the-median-of-sample-mean</link>
      <description><![CDATA[令 $X_1,\ldots,X_n$ 为具有正中位数的 iid 样本（为简单起见，均值为 0，方差为 1），令 $\overline X_n = 1/n \sum_{i=1}^nX_i$ 为样本均值。
让 $\text{Med}(\overline X_n)$ 成为 $\overline X_n$ 分布的中位数。

对于 $n$ 而言，$\text{Med}(\overline X_n)$ 可能有哪些顺序？

我对非渐近结果感兴趣，但也欢迎渐近结果。
我已经通过实验检查过，似乎对于各种不对称分布，$\text{Med}(\overline X_n)\gtrsim 1/n$ 都成立。
然而，根据切比舍夫不等式，我知道$\text{Med}(\overline X_n) \lesssim 1/\sqrt{n}$。
然而，从CLT来看，不可能有$\text{Med}(\overline X_n) \gtrsim 1/\sqrt{n}$。
尽管如此，我还是想尽可能接近切比舍夫不等式。

对于所有$\varepsilon&gt;0$，是否有可能找到满足$\text{Med}(\overline X_n) \gtrsim 1/n^{1/2+\varepsilon}$的分布？

在中位数定义不明确的情况下，是否有可能找到满足$\mathbb{P}(\overline X_n \lesssim 1/n^{1/2+\varepsilon})\leq 1/2$的分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/657818/order-of-the-median-of-sample-mean</guid>
      <pubDate>Mon, 25 Nov 2024 17:59:42 GMT</pubDate>
    </item>
    <item>
      <title>如何使用最大似然估计从数据中拟合/学习非平稳泊松过程？</title>
      <link>https://stats.stackexchange.com/questions/657816/how-do-you-fit-learn-a-nonstationary-poisson-process-from-data-using-maximum-lik</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657816/how-do-you-fit-learn-a-nonstationary-poisson-process-from-data-using-maximum-lik</guid>
      <pubDate>Mon, 25 Nov 2024 17:34:09 GMT</pubDate>
    </item>
    <item>
      <title>同时使用统计抽样和机器学习？</title>
      <link>https://stats.stackexchange.com/questions/657810/using-statistical-sampling-and-machine-learning-together</link>
      <description><![CDATA[我有带标签 $y_i \in \{0,1\}$ 的数据和一些特征 $x_i$。大多数 $y$ 为 0（例如 99% 到 1%）。我想在这个数据上拟合一个随机森林分类模型。
我想知道这种方法是否用于统计学，以避免数据不平衡的问题（例如装袋和重采样的组合）：

获取所有 $y_i = 1$ 的行（我们称这个集合为 $B$）
从 $y_i = 0$ 行中随机抽样，得到一个与 $B$ 大小相同的集合（称每个样本为 $S_k$）
在 $f_k$ 上训练模型 $f_k$ class=&quot;math-container&quot;&gt;$B \cup S_k$
执行此操作$K$次以获得模型$f_1, f_2, ..., f_K$

然后对于任何新输入$x_{new}$，我们的预测只是平均值：
$$ \text{prediction} = \frac{f_1(x_{new}) + f_2(x_{new}) + ... + f_K(x_{new})}{K} $$
然后：对于任何新观察$x_{new}$，如果我们有$K$ 模型，我们可以将一致性得分 $A(x_{new})$ 定义为：
$$ A(x_{new}) = \max\left(\frac{\sum_{k=1}^K I(f_k(x_{new}) = 0)}{K}, \frac{\sum_{k=1}^K I(f_k(x_{new}) = 1)}{K}\right) $$
这给了我们一个介于 0.5（完全不一致）和 1.0（完全一致）之间的分数。可以选择一个阈值来决定应接受什么级别的一致性作为阈值（例如，看看更高的模型一致性是否与更准确的预测相关）？]]></description>
      <guid>https://stats.stackexchange.com/questions/657810/using-statistical-sampling-and-machine-learning-together</guid>
      <pubDate>Mon, 25 Nov 2024 15:15:34 GMT</pubDate>
    </item>
    <item>
      <title>什么是适当的统计测试来比较 ML 模型与 CV 折叠的性能？</title>
      <link>https://stats.stackexchange.com/questions/657809/what-s-the-appropriate-statistical-test-to-compare-ml-model-performance-over-cv</link>
      <description><![CDATA[我正在使用 MSE 等指标比较 10 个 ML 模型在 15 倍交叉验证中的表现。每个模型的表现按倍数排序，我想确定性能是否存在显著差异。
我正在考虑：
Friedman 检验模型之间的总体差异，然后：

Conover
Nemenyi
Wilcoxon 符号秩检验和多重检验校正（例如 Bonferroni）
]]></description>
      <guid>https://stats.stackexchange.com/questions/657809/what-s-the-appropriate-statistical-test-to-compare-ml-model-performance-over-cv</guid>
      <pubDate>Mon, 25 Nov 2024 15:10:48 GMT</pubDate>
    </item>
    <item>
      <title>Beta 回归中的权重</title>
      <link>https://stats.stackexchange.com/questions/657808/weights-in-beta-regression</link>
      <description><![CDATA[我在 R 中使用 betareg 来评估覆盖时间百分比与年龄和性别等基线特征之间的关系。
结果测量是测试覆盖时间百分比 (PTC)：每个测试覆盖一名参与者 6 个月。如果参与者在研究期间进行了几次测试，则他们的总覆盖时间是所有覆盖时间 (TC) 的总和。PTC 是 TC 除以他们在研究中的总时间 (TT)。由于参与者之间的 TT 不同；范围从 6 个月到几年，我使用权重来更加强调那些在研究中时间较长的人。我检查了两个权重选项：第一个选项是 TT，第二个选项是 TT/SUM(TT)：对于每个参与者，他们的 TT 除以所有参与者的 TT 总和。因此，第二个选项本质上是第一个选项除以一个常数值 (SUM(TT))。
选项 1：
 调用：
betareg(formula = PTC ~ Sex + Age, data = Test, weights = 
Test$TT, link = &quot;logit&quot;)

标准化加权残差 2：
最小值 1Q 中位数 3Q 最大值 
-10.9333 -3.1518 -0.0751 4.8051 18.9835 

系数（带 logit 链接的均值模型）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -0.1771340 0.0281138 -6.301 2.96e-10 ***
性别女性 -0.0323812 0.0114639 -2.825 0.00473 ** 
年龄 0.0169218 0.0004632 36.532 &lt; 2e-16 ***

Phi 系数（带身份链接的精度模型）：
估计标准误差 z 值 Pr(&gt;|z|) 
(phi) 1.94438 0.01234 157.5 &lt;2e-16 ***
---
显著性代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1 &#39; &#39; 1 

估计量类型：ML（最大似然）
对数似然：4 Df 上的 1.267e+04
伪 R 平方：0.01633
迭代次数：17（BFGS）+ 1（Fisher 评分）

选项 2：
 调用：
betareg（公式 = PTC ~ Sex + Age，数据 = Test，权重 = 
Test$TT/T，链接 = &quot;logit&quot;)

标准化加权残差 2：
最小值 1Q 中位数 3Q 最大值 
-0.0548 -0.0158 -0.0004 0.0241 0.0952 

系数（带 logit 链接的均值模型）：
估计标准差误差 z 值 Pr(&gt;|z|)
（截距） -0.17713 5.60469 -0.032 0.975
性别女性 -0.03238 2.28541 -0.014 0.989
年龄 0.01692 0.09234 0.183 0.855

Phi 系数（具有身份链接的精度模型）：
估计标准差。误差 z 值 Pr(&gt;|z|)
(phi) 1.944 2.461 0.79 0.429

估计量类型：ML（最大似然）
对数似然：4 Df 上的 0.3188
伪 R 平方：0.01633
迭代次数：28（BFGS）+ 3（Fisher 评分）
警告消息：
在 betareg.fit(X, Y, Z, weights, offset, link, link.phi, type, 
control) 中：
未找到精度参数的有效起始值，改用 1 


为什么将权重乘以常数会导致结果如此不同？哪一个是正确的？
编辑：我现在明白重新调整权重、重新调整方差，因此也重新调整 p 值。我现在的问题是哪个选项是正确的？我应该标准化权重吗（选项 2）？]]></description>
      <guid>https://stats.stackexchange.com/questions/657808/weights-in-beta-regression</guid>
      <pubDate>Mon, 25 Nov 2024 15:03:37 GMT</pubDate>
    </item>
    <item>
      <title>输入随机数据的随机权重神经网络输出的几何结构</title>
      <link>https://stats.stackexchange.com/questions/657806/geometric-structure-of-the-output-of-a-random-weight-neural-network-fed-with-ran</link>
      <description><![CDATA[采用具有随机权重的模型：
 const create_model = () =&gt; {
const model = tf.sequential();
model.add(tf.layers.dense({ inputShape: [10], unit: 4,activation: &#39;sigmoid&#39; }));
model.add(tf.layers.dense({ inputShape: [10], unit: 16,activation: &#39;sigmoid&#39; }));
model.add(tf.layers.dense({ unit: 2,activation: &#39;sigmoid&#39; })); // 输出层
return model;
};

从正态分布中抽取随机数据并计算随机权重 NN 的输出：
 const size = 25000;

const model = create_model();

const generate_points = async () =&gt;; {
const input = tf.randomNormal([size, 10], 0, 10); 
const output = model.predict(inputs); 
const points = await output.array(); 
input.dispose(); 
output.dispose(); 
r​​eturn points;
};

如果绘制此输出，它将看起来像某种超立方体 2D 投影（请参阅此处的示例 https://imgur.com/a/tBZKeYf）。
为什么超立方体会从随机数据/随机权重中“出现”，什么样的 NN 架构会导致这样的结构？]]></description>
      <guid>https://stats.stackexchange.com/questions/657806/geometric-structure-of-the-output-of-a-random-weight-neural-network-fed-with-ran</guid>
      <pubDate>Mon, 25 Nov 2024 14:10:22 GMT</pubDate>
    </item>
    <item>
      <title>用于计算效应大小方差（平均差异）的相关值</title>
      <link>https://stats.stackexchange.com/questions/657804/correlation-value-for-calculating-the-variance-of-effect-size-mean-differences</link>
      <description><![CDATA[这是统计问题
我目前正在进行一项荟萃分析，主要使用受试者内/重复测量行均值差异作为效应量。
在一项参考研究中，数据和代码用于调查训练干预前后下肢力量的绝对平均差异。
&gt; https://insidethenumbers.netlify.app/post/meta-analysis/
根据我的理解，数据结构是配对的（例如，治疗前后），只有一个治疗组（如果我错了，请纠正我）。要计算配对数据（例如前后分数）中效应量（平均差异）的方差，我们需要前后分数之间的相关值。但是，下面的函数没有输入相关值的选项。
我的问题是：库（meta）中的 metacont 函数可以用于独立样本和配对样本吗？如果可以用于成对样本，为什么没有相关值的输入？*
library(tidyverse)
library(meta)
library(plyr)

set.seed(10)
study &lt;- paste(&quot;Study&quot;, LETTERS[1:12])
post_mean &lt;- round_any(c(rnorm(n = 4, mean = 130, sd = 5),
rnorm(n = 4, mean = 80, sd = 5),
rnorm(n = 4, mean = 110, sd = 10)), 2.5)
post_sd &lt;- round_any(rnorm(n = length(study), mean = 7.5, sd = 2.5), 2.5)
pre_mean &lt;- round_any(c(rnorm(n = 4, 平均值 = 100, sd = 5),
rnorm(n = 4, 平均值 = 110, sd = 5),
rnorm(n = 4, 平均值 = 110, sd = 10)), 2.5)
pre_sd &lt;- round_any(rnorm(n = length(study), 平均值 = 7.5, sd = 2.5), 2.5)
post_n &lt;- round(rnorm(n = length(study), 平均值 = 25, sd = 10))
pre_n &lt;- post_n
method &lt;- rep(c(&quot;方法 1&quot;, &quot;方法 2&quot;, &quot;方法 3&quot;), each = 4)

dat &lt;- data.frame(study, post_mean, post_sd, pre_mean, pre_sd, post_n,
pre_n, method)

dat 

ma &lt;- metacont(post_n,
post_mean,
post_sd,
pre_n,
pre_mean,
pre_sd,
studlab = study,
data = dat,
sm = &quot;MD&quot;,
comb.fixed = FALSE,
comb.random = TRUE,
hakn = TRUE,
method.tau = &quot;DL&quot;,
byvar = method) 

该函数使用随机效应并计算绝对平均差。]]></description>
      <guid>https://stats.stackexchange.com/questions/657804/correlation-value-for-calculating-the-variance-of-effect-size-mean-differences</guid>
      <pubDate>Mon, 25 Nov 2024 13:53:24 GMT</pubDate>
    </item>
    <item>
      <title>观察到的故障发生在个体身上的概率</title>
      <link>https://stats.stackexchange.com/questions/657800/probability-that-the-failure-is-on-the-individual-as-observed</link>
      <description><![CDATA[David Cox 在其论文《回归模型和生命表》中引入了比例风险模型，他指出：

对于时间 $t_{(i)}$ 处的特定失败，在风险集 $\mathscr{R}(t_{(i)})$ 的条件下，观察到的失败发生在个人身上的概率为

$$
\frac{e^{\vec\beta\cdot\vec{z}_{(i)}}}{\sum_{l\in \mathscr{R}(t_{(i)})} e^{\vec{\beta}\cdot\vec{z}_{(l)}}} 。
\tag{$\ast$}
$$
这里 $\mathscr R(t_{(i)})$ 表示集合风险集，定义为 $t -0$ 时刻处于风险中的个体集合。
指数函数是风险函数的一部分。在 Cox 模型中，我们假设
$$
\lambda(t) = \lambda_0(t) e^{\vec\beta\cdot\vec z},
$$
其中 $\lambda_0(t)$ 是一个“通用”未知函数，用于处理风险函数的时间依赖性，$\vec z$ 是每个个体可用的测量值。
正如 Cox 自己提到的，

本文考虑的主要问题是评估故障时间分布与 $\vec z$ 之间的关系。
这将通过一个模型来实现，其中风险为
$$
\lambda(t) = \lambda_0(t) e^{\vec\beta\cdot\vec z},
$$
其中 $\vec\beta$ 是一个未知参数向量，$\lambda_0(t)$ 是一个未知函数
给出标准条件集 $\vec z = \vec 0$ 的风险函数。

对于每个单独的 $\vec{z}$，获得一个风险函数 $\lambda(t,\vec z)$，并且$(\ast)$可以看作
$$
\frac{\lambda(t,\vec{z}_{(i)})}{\sum_{l\in \mathscr{R}(t_{(i)})}\lambda(t,\vec{z}_{(l)})}。
\tag{$\dagger$}
$$
问题。我们在$(\ast)$中计算的概率（以符号表示）是多少，为什么可以使用风险函数来表示，如$(\dagger)$所示？
正如Cox所定义的那样，
$$
\lambda(t) = \lim_{h\to 0} \frac{\mathbf{P}(t\leq T&lt; t+h \mid T\geq t)}{h} = - \frac{S&#39;(t)}{S(t)},
$$
其中$S(t)$表示生存函数。
根据这个定义，我明白没有概率应该用$\lambda$来描述。]]></description>
      <guid>https://stats.stackexchange.com/questions/657800/probability-that-the-failure-is-on-the-individual-as-observed</guid>
      <pubDate>Mon, 25 Nov 2024 11:32:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的回归中的 HAC（Newey-West）标准误差小于普通标准误差？</title>
      <link>https://stats.stackexchange.com/questions/657795/why-are-the-hac-newey-west-standard-errors-smaller-than-the-ordinary-standard</link>
      <description><![CDATA[我用时间序列做了一个回归分析，然后做了 Breusch-Godfrey（BG）检验和 White 检验，检验结果显示既有自相关，又有异方差，因此我选择用 HAC（Newey-West）标准误差来分析。结果让我吃惊的是，HAC（Newey-West）标准误差比普通的标准误差还要小，这是为什么呢？这种情况下，我应该用哪种标准误差呢？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657795/why-are-the-hac-newey-west-standard-errors-smaller-than-the-ordinary-standard</guid>
      <pubDate>Mon, 25 Nov 2024 10:09:08 GMT</pubDate>
    </item>
    <item>
      <title>样本大小为 4 的 Wilcoxon 符号秩检验</title>
      <link>https://stats.stackexchange.com/questions/657792/wilcoxon-signed-rank-test-for-a-sample-size-of-4</link>
      <description><![CDATA[我的项目有 4 对值。具体来说，是处理前后水中重金属的浓度。我被告知要使用 Wilcoxon 符号秩检验，但我发现对于 4 个样本，没有提供临界值，且显著性水平较低。有什么解决办法吗？还有其他测试我可以使用吗？
我们想要测试的主要假设是处理是否有效降低浓度水平。]]></description>
      <guid>https://stats.stackexchange.com/questions/657792/wilcoxon-signed-rank-test-for-a-sample-size-of-4</guid>
      <pubDate>Mon, 25 Nov 2024 09:49:07 GMT</pubDate>
    </item>
    <item>
      <title>信息标准相对于交叉验证的优势</title>
      <link>https://stats.stackexchange.com/questions/657772/advantages-of-information-criteria-over-cross-validation</link>
      <description><![CDATA[我理解 AIC 渐近等同于留一交叉验证。而 BIC 具有与留一交叉验证类似的渐近等同性。我的问题是，除了计算效率之外，还有什么理由比交叉验证更倾向于使用 AIC/wAIC/BIC 等信息标准？
在生态学文献中，使用 AIC 进行模型选择非常普遍。但如果可以进行交叉验证，还有什么理由使用 AIC？]]></description>
      <guid>https://stats.stackexchange.com/questions/657772/advantages-of-information-criteria-over-cross-validation</guid>
      <pubDate>Sun, 24 Nov 2024 17:27:03 GMT</pubDate>
    </item>
    <item>
      <title>理解合并回归模型的误差协方差</title>
      <link>https://stats.stackexchange.com/questions/657746/understanding-the-error-covariance-of-pooled-regression-model</link>
      <description><![CDATA[我正在阅读格林的《计量经济学分析》（第 7 版，2011 年）。在第 350 页，他讨论了随机效应回归模型：
$$
\begin{aligned}
y_{it} &amp;= x&#39;_{it} \beta + E[z&#39;_i \alpha] + \left[ z&#39;_i \alpha - E[z&#39;_i \alpha]\right] + \varepsilon_{it} \\
&amp;= x&#39;_{it} \beta + a + \varepsilon_{it} + (c_i - E[c_i | X_i]) \\
&amp;= x&#39;_{it} \beta + a + \varepsilon_{it} + u_i \\
&amp;= x&#39;_{it} \beta + a + w_{it}
\end{aligned}
$$
书中接着说未观察到的异质性（即$z&#39;_i\alpha$）会引起自相关：$t \ne s$时，$E[w_{it}w_{is}] = \sigma^2_u$。
我不相信我看到了这一点。如果我们取相对于时间的期望值 $t$，并注意到 $E_t[w_{it}] = \omega_i$
$$
\begin{aligned}
Cov_t(w_{it}, w_{is}) &amp;= E_t [(w_{it} - \omega_i)(w_{is} - \omega_i)]\\
&amp;= E_t(w_{it}w_{is}) + T \omega_i^2 \\
&amp;= E_t[(\varepsilon_{it} + u_i)(\varepsilon_{is} + u_i)] + T \omega_i^2 \\
&amp;= E_t[\varepsilon_{it} \varepsilon_{is}] + E_t[u_i^2] + T \omega_i^2 \\
&amp;= T(u_i^2 + \omega_i^2) \qquad \text{ for } t \ne s
\end{aligned}
$$
显然，从上面可以看出
$$
\begin{aligned}
E_t(w_{it}w_{is}) &amp;= E_t[(\varepsilon_{it} + u_i)(\varepsilon_{is} + u_i)] \\
&amp;= E_t[\varepsilon_{it} \varepsilon_{is}] + E_t[u_i^2] \\
&amp;= Tu_i^2 \qquad \text{ for } t \ne s
\end{aligned}
$$
他们是如何得到$\sigma^2_u$的？]]></description>
      <guid>https://stats.stackexchange.com/questions/657746/understanding-the-error-covariance-of-pooled-regression-model</guid>
      <pubDate>Sat, 23 Nov 2024 23:22:16 GMT</pubDate>
    </item>
    <item>
      <title>如何在这个三张牌游戏中最大限度地获胜？</title>
      <link>https://stats.stackexchange.com/questions/657729/how-to-maximize-winning-in-this-3-card-game</link>
      <description><![CDATA[假设您正在玩一个游戏，每轮您需要从三张牌中选择一张：
[1] [2] [3]

其中一张是输，另外两张是赢。每轮都是独立的，每次都会洗牌。因此，每次输的概率都是 $\frac{1}{3}$，赢的概率都是 $\frac{2}{3}$。
当您选择一张牌时，游戏管理员不会向您显示所有牌。他们只会向您显示您选择的牌。例如对于上面的例子，如果你选了 [2] 并且它是一张输牌，你会看到：
[1] [L] [3]

如果你选了 [3] 并且它是一张赢牌，情况也是一样：
[1] [2] [W]

如何选牌才能最大化你获得赢牌的回合数？你应该随机选牌吗？还是总是选相同的牌就可以了？
上一轮结果的知识是否决定了下一轮的选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/657729/how-to-maximize-winning-in-this-3-card-game</guid>
      <pubDate>Sat, 23 Nov 2024 16:12:03 GMT</pubDate>
    </item>
    </channel>
</rss>