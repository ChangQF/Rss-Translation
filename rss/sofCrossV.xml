<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 20 Jun 2024 06:20:24 GMT</lastBuildDate>
    <item>
      <title>使用 PCA 创建索引？</title>
      <link>https://stats.stackexchange.com/questions/649566/creating-an-index-using-pca</link>
      <description><![CDATA[如果这个问题看起来很基础，请原谅——我是 PCA 的新手。在 R 中，我已经弄清楚了如何获得成分载荷和分数。要创建索引，我应该简单地将这些分数加在一起吗？换句话说，这些分数是否已经投射到新空间中？此外，如果我们想使用三个成分，我们是否只需将分数相加，还是需要对它们进行加权？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/649566/creating-an-index-using-pca</guid>
      <pubDate>Thu, 20 Jun 2024 05:42:44 GMT</pubDate>
    </item>
    <item>
      <title>mgcv 中的多项回归拟合错误 -</title>
      <link>https://stats.stackexchange.com/questions/649563/error-with-multinomial-regression-fit-in-mgcv</link>
      <description><![CDATA[数据位于 https://file.io/th7TXDPopc5Y
响应列“y”是多项式，其余的是预测变量。当我尝试拟合以下模型时，我收到错误 --
 &gt; b &lt;- gam(list(y ~ s(dur) + s(gly) + s(bmi) +
+ ti(dur,gly) + ti(dur,bmi) + ti(gly,bmi), ~ -1, ~ -1, ~ -1, ~ -1, ~ -1, ~ -1), 
+ select = TRUE, data=dta_df, family = multinom(K=6), method = &quot;ML&quot;)
gam(list(y ~ s(dur) + s(gly) + s(bmi) + ti(dur, gly) + ti(dur, : 
家庭的线性预测因子数量不正确

我怀疑公式格式不正确。感谢任何帮助。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649563/error-with-multinomial-regression-fit-in-mgcv</guid>
      <pubDate>Thu, 20 Jun 2024 04:57:43 GMT</pubDate>
    </item>
    <item>
      <title>两种实现之间存在数值差异</title>
      <link>https://stats.stackexchange.com/questions/649557/got-numerical-difference-between-two-implementations</link>
      <description><![CDATA[我一直在研究 RetNet（论文：https://arxiv.org/pdf/2307.08621，PyTorch 实现：https://github.com/Jamie-Stirling/RetNet/）。我用 TensorFlow 重写了部分代码：
import tensorflow as tf
from keras import layer
from xpos import XPOS

@tf.keras.utils.register_keras_serializable(&#39;RetNet&#39;)
class SimpleRetention(layers.Layer):
def __init__(self, hidden_​​size, gamma, head_size=None, double_v_dim=False):
super(SimpleRetention, self).__init__()

self.hidden_​​size = hidden_​​size
head_size = head_size if head_size is not None else hidden_​​size
self.head_size = head_size
self.v_dim = head_size * 2 if double_v_dim else head_size
self.gamma = gamma

self.W_Q = layer.Dense(head_size, use_bias=False)
self.W_K =层。密集（头部大小，使用偏差=假）
self.W_V = 层。密集（头部大小，使用偏差=假）

self.xpos = XPOS（头部大小）

def call（self，X）：
Q = self.W_Q（X）
K = self.W_K（X）
V = self.W_V（X）

Q = self.xpos（Q）
K = self.xpos（K，downscale=True）

ret = tf.matmul（Q，K，transpose_b=True）* self._get_D（tf.shape（X）[1]）
return tf.matmul（ret，V）

def call_recurrent（self，x_n，s_n_1，n）：
Q = self.W_Q（x_n）
K = self.W_K（x_n）
V = self.W_V（x_n）

Q = self.xpos(Q, offset=n+1)
K = self.xpos(K, offset=n+1, downscale=True)

s_n = self.gamma * s_n_1 + tf.matmul(K, V, transpose_a=True)
return tf.matmul(Q, s_n), s_n

def _get_D(self, serial_length):
n = tf.range(sequence_length)[:, tf.newaxis]
m = tf.range(sequence_length)[tf.newaxis, :]
D = tf.pow(self.gamma, tf.cast(n - m, dtype=tf.float32))
mask = tf.cast(n &gt;= m, dtype=tf.float32) # 因果掩码
return D * mask

现在我又写了另一个测试用例来验证 call 和 call_recurrent 的输出是否相同，遵循测试用例：
import tensorflow as tf
from retentive import SimpleRetention
import numpy as np
import matplotlib.pyplot as plt

def test_simple():
&quot;&quot;&quot;
验证 SimpleRetention 的三个实现是否相同
&quot;&quot;&quot;
batch_size = 4
sequence_length = 12
hidden_​​size = 6

gamma = 0.9

X = tf.random.uniform((batch_size,sequence_length,hidden_​​size))
sr = SimpleRetention(hidden_​​size,gamma,double_v_dim=True)

Y_parallel = sr(X)

s_n_1 = tf.zeros((batch_size,hidden_​​size,sr.v_dim))
Y_recurrent = []
for i in range(sequence_length):
y_n,s_n = sr.call_recurrent(X[:,i:i+1,:],s_n_1,i)
Y_recurrent.append(y_n)
s_n_1 = s_n

Y_recurrent = tf.concat(Y_recurrent,axis=1)

Yp = Y_parallel.numpy()
Yr = Y_recurrent.numpy()
print(Yp.shape, Yr.shape)

plt.figure()
for i in range(batch_size):
plt.subplot(batch_size // 2, 2, i+1)
error_map = Yp[i] - Yr[i]
plt.imshow(error_map)
plt.title(f&quot;sq error={np.sum(error_map * error_map)}&quot;)
plt.show()

error = np.sum(np.abs(Yp - Yr))
print(f&quot;Error: {error}&quot;)

test_simple()

错误应该非常接近 0.0，但我得到的（绝对）错误相对较大，总体上为 1.27。错误图如下

我不确定这是否是正常情况，如果不是，有人知道可能是什么原因吗？数值差异会损害我的模型的性能吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649557/got-numerical-difference-between-two-implementations</guid>
      <pubDate>Thu, 20 Jun 2024 01:13:47 GMT</pubDate>
    </item>
    <item>
      <title>自治微分方程的解 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649555/solutions-to-autonomous-differential-equations</link>
      <description><![CDATA[我试图理解如何找到这两个自治微分方程的解：
第一个自治微分方程
$\frac{dX}{dt}=aX(1-X)$ 其解应该是：
\begin{align}X_{t}=\frac{X_{0}}{X_{0} + (1 - X_{0})e^{-at}}&amp;\end{align&gt; 假设 $a$ 非常小。
第二个自治微分方程
$\frac{dX}{dt}=aX(X-\frac{1}{2})$ 其解应该是：
\begin{align}X_{t}=\frac{X_{0}}{X_{0} + (1 - X_{0})e^{-at}}&amp;\end{align&gt;解决方案应该是：
\begin{align} X_{t}=\frac{1/2}{1 - (e^{at/2} \cdot (1 - \frac{1}{2X_{0}}))}&amp;\end{align&gt; 假设 $a$ 非常小。
有人可以解释一下获得我提到的解决方案所需的步骤是什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649555/solutions-to-autonomous-differential-equations</guid>
      <pubDate>Thu, 20 Jun 2024 00:33:46 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归分析中，判定系数为 0.99，但残差不呈正态分布。我该如何解释这一点？</title>
      <link>https://stats.stackexchange.com/questions/649554/on-a-linear-regression-analysis-the-determination-coefficient-is-0-99-but-the</link>
      <description><![CDATA[首先我想说的是，这是家庭作业，我不太擅长统计。请像对待 5 岁孩子一样向我解释。而且英语不是我的母语。
因此，家庭作业中有一列是公司在 50 个月期间每月在营销上花费的金额，以及他们在相同 50 个月期间每月的销售额。营销支出是独立变量，销售的产品单位是因变量。使用 excel 上的数据分析选项卡进行回归分析后，显示判定系数为 0.99。根据我上课的笔记，判定系数可以显示模型是否良好，并且越接近数字 1 越好。
但我的笔记还说，如果残差不是正态分布，线性回归不是正确的模型，并且这些残差的平均值必须为 0。在这种情况下，残差不是正态分布的。根据互联网，峰度需要为 3 或更低才能为正态分布，在本例中约为 7。残差的平均值也不为 0。它是 -2.8422E-15，非常接近 0，但实际上并非为 0。
Excel 显示，除第 49 个月（为 -4.39）外，标准化残差都在 -3 和 3 的范围内。帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/649554/on-a-linear-regression-analysis-the-determination-coefficient-is-0-99-but-the</guid>
      <pubDate>Thu, 20 Jun 2024 00:28:48 GMT</pubDate>
    </item>
    <item>
      <title>对模型训练中看到的数据以及新数据进行混合效应模型预测的引导置信度和预测区间</title>
      <link>https://stats.stackexchange.com/questions/649552/bootstrap-confidence-and-prediction-intervals-of-mixed-effect-model-predictions</link>
      <description><![CDATA[假设我使用 lme4 R 库拟合了混合效应模型 mem，并且我想使用 bootMer 函数来计算模型在训练期间看到的一些数据的置信度和预测区间。在这种情况下，我可以包含随机效应（以及固定效应）来计算 mem 的置信度和预测区间，例如 95% 的置信度。
对于预测区间，此 https://www.wavedatalabs.com.au/posts/2023-02-06-prediction-intervals-for-linear-mixed-effects-models/ 源建议定义一个以所有随机效应为条件的预测函数
predfn &lt;- function(.) { predict(., newdata=new, re.form=NULL) }

然后在bootMer 调用，其中 re.form=NULL
boot &lt;- lme4::bootMer(mem, FUN=predfn, nsim=250, re.form=NULL, type=&quot;parametric&quot;)

问题 1) 以上内容正确吗？那么置信区间呢？更具体地说：在 bootMer 中，如何选择 re.form 和 FUN 参数来估计置信区间？
现在让我们假设我们想要计算 mem 对新数据（训练期间未见）的预测的置信度和预测区间，置信度为 95%。在这种情况下，不能考虑随机效应。对于预测区间，我上面链接的同一来源建议定义一个新函数来重新采样来自 mem 的响应（而不是重新采样确定性模型预测）
sfun &lt;- function(.) {
mock(., newdata=new_data, re.form=NULL, allow.new.levels=TRUE)[[1]]
}

然后在 bootMer 调用中使用它
boot &lt;- lme4::bootMer(mem, FUN=sfun, nsim=250, re.form=~0, type=&quot;parametric&quot;, seed=100)

问题 2)：为什么在 sfun 中使用 re.form=NULL？另外：在这种情况下，bootMer 的 re.form 和 FUN 参数的适当选择是什么，以估计 new_data 的置信区间
任何帮助表示感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649552/bootstrap-confidence-and-prediction-intervals-of-mixed-effect-model-predictions</guid>
      <pubDate>Wed, 19 Jun 2024 23:26:22 GMT</pubDate>
    </item>
    <item>
      <title>不同情况下的 LSTM 和 MLP 分布函数[重复]</title>
      <link>https://stats.stackexchange.com/questions/649551/distribution-function-of-lstm-and-mlp-for-different-cases</link>
      <description><![CDATA[我问过这个问题（可以视为案例1），MLP在TEC预测方面不如LSTM。可以观察到，LSTM预测的TEC曲线与观察到的TEC曲线（即ground truth）非常接近，而MLP预测的曲线与ground truth之间存在相当大的差距。
下面还有另外两种TEC曲线的变化：
案例2：从2015/6/18到2015/6/23，TEC的变化非常复杂。除了周期性变化外，在某个时期还存在强烈的扰动。在这种情况下，LSTM 可以捕捉周期性变化，从而给出更好的预测，然而，MLP 的方向完全错误。与 MLP 相比，由于记忆单元的存在，LSTM 具有预测长序列数据的优势。LSTM 可以学习序列数据的长依赖关系，不仅是过去的时刻，而且还考虑了一段历史。而 MLP 不利用历史信息，因此在 TEC 发生动荡的情况下可能会失败。
情况 3：
如果 TEC 突然变化，例如图 6 所示的情况，过去五天观察到的 TEC 峰值很大，而第二天急剧变低。在这种情况下，RMS 误差变得显著。


上面，我们讨论了 TEC 变化的三种情况，其中 LSTM 的表现都优于 MLP。这一成就归功于 LSTM 的特殊设计，因此它可以学习序列数据的长依赖关系。由此可以了解序列数据元素之间的相互作用和关系，从而更好地表示输入数据。
我的问题是：通过查看上述三种情况下的 LSTM 和 MLP 曲线，我们可以说明什么？是否可以根据上述三种情况下的曲线为 LSTM 和 MLP 定义合适的分布函数？三种情况下是否有可能通过分布进行数学表示？]]></description>
      <guid>https://stats.stackexchange.com/questions/649551/distribution-function-of-lstm-and-mlp-for-different-cases</guid>
      <pubDate>Wed, 19 Jun 2024 22:11:19 GMT</pubDate>
    </item>
    <item>
      <title>$\min\{X,Y\}$；其中 $X,Y$ 是几何随机变量</title>
      <link>https://stats.stackexchange.com/questions/649550/min-x-y-where-x-y-are-geometric-random-variables</link>
      <description><![CDATA[
$\min\{X,Y\}$ 是否服从几何分布？$X \sim BN(1,p); Y \sim BN(1,q)$ 独立

$$P(\min\{X,Y \}=k)=P( \min\{X,Y\} \geq k)-P(\min\{X,Y \} \geq k+1)=\sum_{n=k}^{\infty}(1-p)^{n-1}p\sum_{n=k}^{\infty}(1-q)^{n-1}q-\sum_{n=k+1}^{\infty}(1-p)^{n-1}p\sum_{n=k+1}^{\infty}(1-q)^{n-1}q=(1-p)^{k-1}(1-q)^{k-1}-(1-p)^{k}(1-q)^{k}=[(1-p)(1-q)]^{k-1}(1-(1-p)(1-q))$$
因此：
$$\min\{X,Y \} \sim BN(1,1-(1-p)(1-q))$$]]></description>
      <guid>https://stats.stackexchange.com/questions/649550/min-x-y-where-x-y-are-geometric-random-variables</guid>
      <pubDate>Wed, 19 Jun 2024 22:00:26 GMT</pubDate>
    </item>
    <item>
      <title>聚类标准误差-直观解释</title>
      <link>https://stats.stackexchange.com/questions/649547/clustered-standard-error-intuitive-explanation</link>
      <description><![CDATA[我理解标准误差是关于某些参数的抽样分布的标准偏差，例如样本均值或回归模型中的系数。
我还知道，当您的数据不符合独立性假设时，例如随机化单元之间的地理或时间关系，我们需要在满足独立性假设的最低级别“聚类”估计参数的标准误差。
让我们以时间为例。假设我们有 RCT 中各种随机化单元的面板数据。因为 $y_t$ 不独立于 $y_{t-1}$，所以我们不能声称独立。因此，我们的样本量不能是 $NT$，而是 $N$。
我相信我已经牢牢掌握了原因。我挣扎的是如何。在这种情况下，我们如何聚类标准误差？聚类标准误差是合并标准误差的概括，包括几个单位（而不是两个）吗？
我们的方法是否因我们试图推断观察到的参数（例如平均值）与潜在参数（例如回归系数$\beta$）而有所不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/649547/clustered-standard-error-intuitive-explanation</guid>
      <pubDate>Wed, 19 Jun 2024 20:13:06 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 OPLS-DA 中的累计 Q2</title>
      <link>https://stats.stackexchange.com/questions/649541/how-to-calculate-cumulative-q2-in-opls-da</link>
      <description><![CDATA[在SIMCA 用户指南中，$p.450$，累计$Q^2$通过以下方式计算：
$$
Q^2(\text{cum})=1−∏_{a=1}^{N_\text{comp}} \left( \frac{PRESS}{SS} \right)_a \tag{1}
$$
其中$∏_{a=1}^{N_\text{comp}}(PRESS/SS)_a$是每个单独组件 $a$ 的 $PRESS/SS$ 乘积。
这让我很困惑。OPLS 模型表示为（请参阅此处的介绍）：
$$
X=t_1p_1^T+T_OP_O^T+E \tag2
$$
或由 J. Trygg 的论文
$$
X=T_pP_p^T+T_OP_O^T+E \tag3
$$
并且从预测成分中预测出一个新的 $y$。
据我所知，

每个单独的成分 $a$

应该参考预测成分，因为所有预测都应该来自 $X$，并通过正交得分 $T_O$ 和载荷 $P_O$ 进行校正，即，$X_P=X-T_OP_O^T$。交叉验证用于确定正交分量的数量。因此，对于新矩阵$X_\text{new}$，它也由正交分量进行校正，然后用于使用预测分量进行预测。但根据方程$(2)$，预测分量的数量为 1。问题是如何计算每个单独分量$a$的$PRESS/SS$？
如果我错了，我应该尝试使用单个交叉验证循环同时获得正交分量的数量和预测分量的数量。这意味着，对于每个正交分量的数量（例如从 1 到 15），我应该遍历每个预测分量的数量（例如从 1 到 15），以便可以确定正交分量的数量和预测分量的数量（如果正交分量和预测分量的最大数量为 $15$，则在每次交叉验证迭代中应该尝试总共 $15^2=225$ 次循环）。但我不确定这是否正确，因为这个过程有点复杂，我找不到任何提到这方面的材料。
那么如何正确理解这个术语

每个单独的组件$a$

并正确计算$Q^2(\text{cum})$？]]></description>
      <guid>https://stats.stackexchange.com/questions/649541/how-to-calculate-cumulative-q2-in-opls-da</guid>
      <pubDate>Wed, 19 Jun 2024 18:51:47 GMT</pubDate>
    </item>
    <item>
      <title>如何评估多场比赛的结果是否符合各自状态的概率分布</title>
      <link>https://stats.stackexchange.com/questions/649538/how-to-evaluate-whether-the-results-of-multiple-games-conform-to-the-probability</link>
      <description><![CDATA[有n局游戏，每局游戏开始后都有一个状态，根据这个状态可以计算出游戏结果的概率，比如有3种结果，概率分别是p1，p2，p3，但是下一局游戏状态不一样，概率就变了，变成了p4，p5，p6，打n局，就有n个结果，那么如何判断这n个结果整体上是否符合这些概率呢？
我也不知道，也许可以用卡方检验，但是条件好像不满足？]]></description>
      <guid>https://stats.stackexchange.com/questions/649538/how-to-evaluate-whether-the-results-of-multiple-games-conform-to-the-probability</guid>
      <pubDate>Wed, 19 Jun 2024 15:56:07 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测的预言库存在的问题</title>
      <link>https://stats.stackexchange.com/questions/649525/problems-with-prophet-library-for-time-series-forecasting</link>
      <description><![CDATA[我有一个很小的数据框，包含两列：time_key，即日期；value，即衡量超市收入的数值变量。这个数据框定义了一个时间序列，我有 16 个月的数据。我正在尝试获取过去 3 个月的预测。
我正在使用 R 中的 fable 和 fable.prophet 库。虽然这是一个小例子，但这个想法是这个过程将自动执行到几十个类似的数据框，所以我的想法是，对于每个数据框，自动计算、优化和比较不同的模型，并选择最小化准确率的模型。以下是我的数据概览：
sales.ts
time_key 值
1 2020-03-01 292.7846
2 2020-04-01 292.2414
3 2020-05-01 296.0398
4 2020-06-01 286.3656
5 2020-07-01 284.5536
6 2020-08-01 272.8100
7 2020-09-01 272.8052
8 2020-10-01 326.2926
9 2020-11-01 306.6977
10 2020-12-01 370.4489
11 2021-01-01 323.3679
12 2021-02-01 308.2357
13 2021-03-01 346.5880
14 2021-04-01 331.0101
15 2021-05-01 303.5761
16 2021-06-01 204.9440

以下脚本在数据上构建 ARIMA、ETS 和 Prophet 模型并进行比较：
library(tidyverse)
library(tsibble)
library(fable)
library(prophet)
library(fable.prophet)

fit &lt;- sales.ts %&gt;%
mutate(time_key = yearmonth(time_key)) %&gt;% 
as_tsibble(index = time_key) %&gt;%
model(
ets = ETS(value),
arima = ARIMA(value),
prophecy = prophecy(value))

fc &lt;- fit %&gt;% prediction(h = 3)

fc %&gt;% autoplot(sales.ts)

您可以在此处查看结果。

正如您所见，似乎没有什么希望。我的问题是：

prophecy 到底发生了什么？特别是因为如果我调用 fit %&gt;% accuracy() 命令，prophet 会显示错误 0。
您对如何改进这一点有什么建议吗？

我知道可能有很大空间来优化指示趋势和季节性等模式的模型（尽管这些特定数据没有显示太多），但我需要这个过程是自动化的，所以我不能逐个数据集地微调模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/649525/problems-with-prophet-library-for-time-series-forecasting</guid>
      <pubDate>Wed, 19 Jun 2024 13:58:35 GMT</pubDate>
    </item>
    <item>
      <title>高斯图形模型/GLasso 的扩展 BIC 曲线何时看起来不正确？</title>
      <link>https://stats.stackexchange.com/questions/649481/when-does-a-extended-bic-curve-for-a-gaussian-graphical-model-glasso-look-incorr</link>
      <description><![CDATA[我有一个网络模型，我想根据 Foygel and Drton 2010 分析图形套索模型的扩展 BIC 曲线。本文列出了数据/模型的一系列假设，这些假设应满足 EBIC 的所需属性，其中包括边集的可分解性，但我认为我的网络不应该具有这些属性。我的曲线如下所示：

左图为 BIC 曲线，右图为网络中的边数，红点表示与最小 BIC 对应的 lambda 值。我的问题是，曲线的不连续/非常非线性特性是否指向我的代码存在一些问题，或者模型的某个假设不成立？
我的计算代码是：
import numpy as np
from sklearn import covariance

BIC = lambda E, n, Theta, S, alpha, p: -n*(np.linalg.slogdet(Theta)[1] - np.trace(np.matmul(S, Theta))) + np.log(n)*E + 4*E*alpha*np.log(p)

#emp_cov 是经验协方差矩阵
alphaRange=np.linspace(0.00001, 0.0001, 50)
n=50 #样本大小
p = 500 #这是节点/随机变量的数量值向量
bic_values = {}
edge_counts = {}

for alpha in alphaRange:
try: 
graphCov = covariance.graphical_lasso(emp_cov, alpha)
E = (np.count_nonzero(graphCov[1] * ~np.eye(graphCov[1].shape[0], graphCov[1].shape[0], dtype=bool)))/2 
&#39;&#39;&#39;
这会将对角线元素设置为 0，然后计算矩阵中非零元素（边）的数量，并除以 2 bc 对称性
&#39;&#39;&#39;
bic_values[alpha] = BIC(E, n, graphCov[1], emp_cov, alpha, graphCov[1].shape[0])
edge_counts[alpha] = E
except FloatingPointError:
print(f&quot;Failed at alpha={alpha}&quot;)

如能提供任何帮助，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/649481/when-does-a-extended-bic-curve-for-a-gaussian-graphical-model-glasso-look-incorr</guid>
      <pubDate>Tue, 18 Jun 2024 19:33:17 GMT</pubDate>
    </item>
    <item>
      <title>如果不存在显著的依赖关系，我是否不应该使用 copula ？</title>
      <link>https://stats.stackexchange.com/questions/649464/should-i-not-use-copula-if-there-is-no-significant-dependence</link>
      <description><![CDATA[我有两个变量，我想得到它们的联合分布。我想使用 copula 来实现这一点。但是，当我检查它们之间的依赖关系时，我发现没有显著的依赖关系。我使用 R 包 Vinecopula 检查的依赖关系是渐近依赖关系。
独立性检查测试的 p 值基于正态分布，AIC 是使用均方误差计算的。附件是渐近独立性的检验统计量：

我对 copula 的理解是，如果变量之间没有显著的依赖关系，则应使用独立 copula 而不是参数 copula。然而，在检查了独立 copula 和其他参数 copula 的 AIC 后，我发现参数 copula 的 AIC 低于独立 copula。
我的问题是：如果没有显著的依赖关系，我是否应该使用独立 copula，即使它的 AIC 高于其他 copula？还是我应该选择任何具有最低 AIC 的参数 copula？]]></description>
      <guid>https://stats.stackexchange.com/questions/649464/should-i-not-use-copula-if-there-is-no-significant-dependence</guid>
      <pubDate>Tue, 18 Jun 2024 14:55:41 GMT</pubDate>
    </item>
    <item>
      <title>加权线性回归的预测带</title>
      <link>https://stats.stackexchange.com/questions/649463/prediction-bands-for-weighted-linear-regression</link>
      <description><![CDATA[对于 $x_i, y_i,$ 的线性回归，我们知道置信区间为：
$$\hat{y} \pm t \cdot s \sqrt{ \frac{1}{n} + \frac{(x - \bar{x})^2}{\sum (x_i - \bar{x})^2} }$$
和预测带：
$$\hat{y} \pm t \cdot s \sqrt{ 1+ \frac{1}{n} + \frac{(x - \bar{x})^2}{\sum (x_i - \bar{x})^2} }$$
在加权线性回归案例（权重 $w_i$），我们有置信区间：
$$\hat{y} \pm t \cdot s \sqrt{ \frac{1}{\sum w_i} + \frac{(x - \bar{x}_w)^2}{\sum w_i (x_i - \bar{x}_w)^2} }$$
但预测带的公式是什么？
直观地讲，如果我们将权重 $1, 1, 1, 1, \ldots$ 替换为，例如 $0.1, 0.1, 0.1,，预测带应该保持不变0.1, \ldots$ 因此这表明它可能不是：
$$\hat{y} \pm t \cdot s \sqrt{ 1+ \frac{1}{\sum w_i} + \frac{(x - \bar{x}_w)^2}{\sum w_i (x_i - \bar{x}_w)^2}}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/649463/prediction-bands-for-weighted-linear-regression</guid>
      <pubDate>Tue, 18 Jun 2024 14:33:31 GMT</pubDate>
    </item>
    </channel>
</rss>