<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 01 Feb 2025 15:17:23 GMT</lastBuildDate>
    <item>
      <title>更新过程和非齐次泊松过程</title>
      <link>https://stats.stackexchange.com/questions/660845/renewal-process-and-non-homogeneous-poisson-process</link>
      <description><![CDATA[我想知道非齐次泊松过程是否可以看作更新过程的特例？]]></description>
      <guid>https://stats.stackexchange.com/questions/660845/renewal-process-and-non-homogeneous-poisson-process</guid>
      <pubDate>Sat, 01 Feb 2025 13:55:03 GMT</pubDate>
    </item>
    <item>
      <title>样本均值与自举均值相同，但 T 检验拒绝原假设</title>
      <link>https://stats.stackexchange.com/questions/660844/sample-mean-is-same-as-bootstrapped-mean-but-t-test-rejects-null-hypothesis</link>
      <description><![CDATA[我有 2 个样本（每个样本有大约 8500 个数据点）。我进行了引导（有替换）并绘制了平均差异的分布：

然后，我计算了 2 个样本的实际平均差异，结果是-5.53
我的理解表明，这意味着我的样本之间没有显着差异。但是，当我进行 T 检验时，我得到p_value=0.048
有人可以解释这是怎么可能的吗？据我理解，这本质上就是 T 检验所做的工作 - 创建均值差异分布并检查样本之间的实际均值差异在该分布范围内的可能性。
每个样本的原始分布都非常右偏，但我认为 8500 的样本量可以弥补这一点。此外，我进行了 Levene 检验，两个样本之间的方差没有差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/660844/sample-mean-is-same-as-bootstrapped-mean-but-t-test-rejects-null-hypothesis</guid>
      <pubDate>Sat, 01 Feb 2025 11:34:50 GMT</pubDate>
    </item>
    <item>
      <title>选择赔率是多少[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660843/what-are-the-select-odds</link>
      <description><![CDATA[我参加了一场有 150 张彩票的抽奖，我买了 10 张，赢得了前 3 次抽奖，之后又赢得了总共 25 个奖品中的 6 个。几率是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/660843/what-are-the-select-odds</guid>
      <pubDate>Sat, 01 Feb 2025 10:56:13 GMT</pubDate>
    </item>
    <item>
      <title>哪种流行的参数分布（或分布混合）可以很好地模拟人类的死亡年龄？</title>
      <link>https://stats.stackexchange.com/questions/660842/what-popular-parametric-distribution-or-mixture-of-distributions-does-a-good-j</link>
      <description><![CDATA[对于那些不知道的人来说，某人死亡年龄的分布看起来是这样的：

显然，在接近 0 岁时有一个峰值，这可以解释婴儿死亡率。这可以通过以接近 0-1 岁为中心的狄拉克 Delta 或薄伽马分布轻松解释。但对于其余分布，是否有一个流行的参数分布可以很好地捕捉其形状？传统上，人们可能会使用正态分布，或者更好的是伽马分布。但这些都不能解释分布的“尾部”似乎偏左。如果我必须选择一个能够很好地拟合形状的分布，我可能会使用缩放/拉伸的 Beta 分布。但是，虽然它完全符合形状，但似乎没有任何强有力的理论理由来证明它是所使用的分布。是否有另一个参数分布（或分布混合）可以更好地拟合该数据并且具有相当强的理论理由来应用？]]></description>
      <guid>https://stats.stackexchange.com/questions/660842/what-popular-parametric-distribution-or-mixture-of-distributions-does-a-good-j</guid>
      <pubDate>Sat, 01 Feb 2025 10:34:04 GMT</pubDate>
    </item>
    <item>
      <title>当我没有真实标签时，如何评估模型（预先训练的 BERT 和 VADER 进行情绪分析）？</title>
      <link>https://stats.stackexchange.com/questions/660839/how-can-i-evaluate-model-pre-trained-bert-and-vader-for-sentiment-analysis-whe</link>
      <description><![CDATA[我有一个包含文本的数据集，我使用预先训练的 BERT 和 VADER 模型来获取情感标签和情感分数。如果没有真实标签，我不知道如何评估我的模型。我可以使用哪些统计测试？有什么方法可以比较哪个模型更好？目前，我使用 Cohen&#39;s Kappa 来查看分类中的一致性。
此外，我计划对预先训练的 BERT 模型进行超调（仍然没有真实标签），在这种情况下，我如何才能更好地评估我的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/660839/how-can-i-evaluate-model-pre-trained-bert-and-vader-for-sentiment-analysis-whe</guid>
      <pubDate>Sat, 01 Feb 2025 05:14:14 GMT</pubDate>
    </item>
    <item>
      <title>堆叠泛化算法的特征选择</title>
      <link>https://stats.stackexchange.com/questions/660838/feature-selection-for-stacked-generalization-algorithm</link>
      <description><![CDATA[我对机器学习还比较陌生，我偶然发现了一篇我所在领域的论文，其中提出了一种新的集成模型。然而，他们的三个特征输入来自同一个基础模型，包括其预测值、FDR 校正分数以及 p 值校正分数，(score * (1 - x))，如果分数 &gt; 0.5 且 x &gt;= 0.5，其中 x 是 FDR 或 p 值。
我尝试四处寻找，但没有遇到任何类似的例子。这有道理吗？这似乎过分强调单个基础模型，还是“期望”集成模型能够在适当的训练过程中将其过滤掉？
任何链接或资源都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660838/feature-selection-for-stacked-generalization-algorithm</guid>
      <pubDate>Sat, 01 Feb 2025 03:46:46 GMT</pubDate>
    </item>
    <item>
      <title>机器学习算法的度量选择</title>
      <link>https://stats.stackexchange.com/questions/660835/metric-choice-for-machine-learning-algorithm</link>
      <description><![CDATA[我目前正在为二元分类问题构建一个 ML 模型。
我目前正在使用研究论文中提供的精选数据集，该数据集已经完全平衡。但是，众所周知，现实生活中的情况并非如此（负数的数量远高于正数的数量）。
我正在尝试选择一个合适的指标。我在网上读到，平衡的数据集应该选择准确度，而不平衡的数据集将是 F1 或 MCC。但是，考虑到现实世界数据不平衡的事实，我应该选择 MCC 或 F1 而不是准确度吗？或者我的模型应该根据数据集构建并使用准确度？
任何链接或资源都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660835/metric-choice-for-machine-learning-algorithm</guid>
      <pubDate>Sat, 01 Feb 2025 02:18:18 GMT</pubDate>
    </item>
    <item>
      <title>线性回归中 Y 的正态分布和多元正态分布之间的区别？</title>
      <link>https://stats.stackexchange.com/questions/660833/difference-between-normal-and-multivariate-normal-distribution-for-y-in-linear-r</link>
      <description><![CDATA[在线性回归中，我假设当 $y$ 属于正态分布时，是因为只有一个变量，就像一个简单的线性回归，例如 $y = \beta_{0} + \beta_1 x_1 + \epsilon$。当有更多变量时，$y$ 属于多元正态分布，我们讨论的是多元线性回归。
有人可以证实这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660833/difference-between-normal-and-multivariate-normal-distribution-for-y-in-linear-r</guid>
      <pubDate>Sat, 01 Feb 2025 00:07:14 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证来确定因子分析中的因子数量：为什么不是因子越多，可能性就越大？</title>
      <link>https://stats.stackexchange.com/questions/660830/use-cross-validation-to-determine-number-of-factors-in-factor-analysis-why-the</link>
      <description><![CDATA[考虑因素分析模型
\begin{方程*}
\开始{数组}{cccccccccc}
X &amp;=&amp; \mu&amp;+&amp; L&amp;\cdot&amp; f&amp; + &amp;u \\
p\乘以 1 &amp; &amp; p\times 1 &amp;&amp;p\times k&amp; &amp; k\times 1 ＆amp; &amp; p\times 1
\end{array} 
\end{equation*
其中 $\mu$ 为平均值，$L$ 是因子载荷矩阵，$f\sim N(0, I_k)$ 是因子，$u\sim N(0,\Psi)$ 是误差，其中 $\Psi$ 是对角矩阵。
在一些论文中，作者使用交叉验证来确定因子的数量$k$。
我读了代码，发现代码做了如下操作：
(1) 固定一个整数$k$。
&lt; p&gt;(2) 将数据集 $S$ 拆分为 $10$ 折叠，$S_1,\cdots, S_{10}$.
(3) 对于每个 $S_i$，使用$S\backslash S_i$来训练因子分析模型$\mu_i, L_i, \Psi_i$ .
(4) 计算对数似然
\begin{equation*}
f(i,k)= \sum\nolimits_{x\in S_i}\log p(x|\mu_i, L_iL_i^T+\Psi_i)
\end{equation *
其中 $p(x|\mu,\Sigma)$ 是多元正态分布的概率密度函数，其均值为 $\mu$ 和协方差矩阵 $\Sigma$。
在 $f$ 的参数中，$i$ 是测试集的索引，$k$ 是因子的数量。
(5) 计算对数似然的平均值 $\bar f(k)= \frac{1}{10}\sum_{i=1}^{10} f(i,k)$.
乍一看，我怀疑代码可以工作，因为我的直觉告诉我，肯定更大的$k$ 有更大的$\bar f(k)$。
并且，如果 $L$ 是一个 $p\times k$ 矩阵，并且该矩阵与模型拟合得很好，那么$l&gt;k$ 因子也很好地拟合了模型，因为我们可以构造 $p\times l$ 因子载荷矩阵为 $(L&#39;,\mathbf 0)&#39;$。
但当我运行代码时，我发现可能会发生 $\bar f(k)$ 没有增加。
我想知道为什么$\bar f(k)$没有像我直觉所想的那样增加。
举一个数值例子，我将该代码用于一个数据集，其中包含 $156$ 次试验和每次试验 $21$ 个特征。
当 $k=2,3,4,5,6$，对应的$\bar f(k)$为分别
\begin{equation*}
1000\times ( -2.7518, -2.7509, -2.7485, -2.7506, -2.7502 )。
\end{equation*
$k=4$ 具有最大值 $\bar f(k)$ 。
更新：由于我有 21 个特征，如果 $k\le 14$，因子分析才有意义。
有一个图表因子和平均交叉验证对数似然。
（不是我给出的数值示例。我忘了我用哪个数据集给出数值示例。）
许多数据集都遵循这种模式。当因子数接近 $14$，
平均对数似然甚至下降并变低。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660830/use-cross-validation-to-determine-number-of-factors-in-factor-analysis-why-the</guid>
      <pubDate>Fri, 31 Jan 2025 22:47:06 GMT</pubDate>
    </item>
    <item>
      <title>关于通过初始值（高值）和最终值（低值）进行归一化后查找方差的问题</title>
      <link>https://stats.stackexchange.com/questions/660817/question-about-finding-variance-after-normalizing-by-the-initial-high-and-fina</link>
      <description><![CDATA[我有来自许多“个人”的数据；从 0 到 1 的范围内，每个人最初的得分都很高，假设平均得分为 0.8，然后经过多次试验，他们在最后一次试验中的“最终”得分很低，假设平均得分为 0.2。休息一段时间后，他们的分数会有所恢复，假设平均得分为 0.6。
有了这三个平均值，我想计算恢复百分比（即，恢复得分恢复了初始得分和最终得分之间的差异的百分比）。使用这个标准化方程很容易计算：（平均恢复得分 - 平均最终得分/平均初始得分 - 平均最终得分）* 100。结果是 0.6-0.2/0.8-0.2 * 100 = 67%。
太好了。但是，我想用这个来计算统计数据，以比较不同组的数据，为此我需要这个百分比恢复值的方差（在本例中为 67%）。我不确定该怎么做。初始值、最终值和恢复值存在差异，所以我要使用误差传播吗？还是别的什么？如果能澄清这一点，我将不胜感激，我觉得这不是人们所做的非常罕见的规范化，但我还没有在任何地方找到这个特定问题的解决方案 :(]]></description>
      <guid>https://stats.stackexchange.com/questions/660817/question-about-finding-variance-after-normalizing-by-the-initial-high-and-fina</guid>
      <pubDate>Fri, 31 Jan 2025 17:14:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么必须估计线性回归模型中的参数值？</title>
      <link>https://stats.stackexchange.com/questions/660750/why-must-the-values-of-the-parameters-in-a-linear-regression-model-be-estimated</link>
      <description><![CDATA[我不明白为什么在线性回归模型中无法找到参数 α 和 β 的真实值。为什么它们总是需要估计？
我读到它与包含其他变量的误差项有关（$x_2,x_3 ...$），但我并不完全理解。]]></description>
      <guid>https://stats.stackexchange.com/questions/660750/why-must-the-values-of-the-parameters-in-a-linear-regression-model-be-estimated</guid>
      <pubDate>Thu, 30 Jan 2025 04:46:11 GMT</pubDate>
    </item>
    <item>
      <title>对称单峰分布系列，其中峰度与峰值成反比？</title>
      <link>https://stats.stackexchange.com/questions/659400/family-of-symmetric-unimodal-distributions-where-kurtosis-is-inversely-related</link>
      <description><![CDATA[DeCarlo 于 1997 年在著名期刊《心理学方法》上发表了论文《论峰度的意义和用途》。该论文被广泛引用（引用次数超过 1500 次，其中 129 次“极具影响力”），人们仍然在文献和网络内容中频繁引用该论文。然而，摘要的第一句话指出：

对于对称单峰分布，正 [过量] 峰度表示
相对于正态分布，尾部较重且呈尖峰状，而负 [过量] 峰度表示尾部较轻且呈平坦状。

这种说法在尖峰状和平坦状方面是不正确的，并且导致了“尖峰状/平坦状”现象的持续存在尽管最近的研究彻底推翻了峰度可以衡量分布的峰值或平坦度（无论是对称分布还是单峰分布）的观点，但这种误解仍然存在。例如，在《心理学与营销》杂志上发表的一篇 (2025) 文章“如何处理偏度、峰度和异常值的教程”由 Iacobucci、Roman、Moon 和 Rouzies 撰写，声称峰度可以衡量峰值/平坦度，与异常值无关，并引用了 DeCarlo 的解释。具体来说，他们指出：

它 [过量峰度] 反映了分布出现峰值（尖峰，正）或平坦（平峰，负）的程度
（DeCarlo 1997；参见附录中的示例）。

如果给出一组对称单峰分布，其中峰度降低时分布变得更加尖锐，峰度增加时分布变得更加平顶，这将有助于消除这种误解。
（编辑：由于“峰度”定义不明确，出于本练习的目的，可以将其操作为标准化变量分布的高度。）
这种对称单峰族的一个简单示例是$\{F_1, F_2\}$，其中 $F_1$ 和 $F_2$ 在 维基百科页面 中给出：$F_1$ 是参数为 $0.5$ 和 $1$ 的 beta 分布与其关于 $0.0$ 的反射的均等混合，而 $F_2$ 是 $−1$ 和 $1$ 具有 $T(4.0000001)$ 学生 t 分布，混合概率为 $0.999$ 和 $0.001$。这些分布对应的标准化变量的密度函数如下所示：


在这个家族中，较低峰度（和“platykurtic”）分布是“无限峰值”，而较高峰度分布较低，且呈现完美的平顶。
然而，描述一个更传统的无限族$F_{\theta}$将会很有趣，其中$\theta$连续变化，峰度范围从&quot;platykurtic&quot; ($&lt;3$) 到无穷大，并且分布（所有对称和单峰）范围从无限峰值到几乎平顶，因为峰度范围从最小值到无穷大。
有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659400/family-of-symmetric-unimodal-distributions-where-kurtosis-is-inversely-related</guid>
      <pubDate>Tue, 31 Dec 2024 17:07:42 GMT</pubDate>
    </item>
    <item>
      <title>确定嘈杂的医疗保险索赔数据中的政策变化</title>
      <link>https://stats.stackexchange.com/questions/645345/determine-policy-changes-in-noisy-medicare-insurance-claim-data</link>
      <description><![CDATA[我希望这是提出这个问题的正确地方，我不会因为一个糟糕的问题而被指责，但我还是要问。
背景：
我有一个数据库，其中包含五年内提交的所有医疗保险索赔（非个人化）。
该数据库包含 86.8 亿条记录。每条记录都包括提交索赔的日期、索赔金额、索赔是否被批准、金额多少以及何时批准。每条记录还根据适用于该程序/设备的约 22,000 个代码（CPT 代码）之一对索赔进行分类。数据按这些 CPT 代码排序，并在 CPT 代码内按日期排序。
索赔是否受制于影响相关 CPT 代码的各种政策，而我无法访问这些政策。此外，对于我的问题来说，重要的是，适用于 CPT 代码的政策可能会随着时间的推移而发生变化。未涵盖的内容可能会变成涵盖的内容。涵盖的内容可能不再涵盖。甚至可能会出现反复，例如覆盖-未覆盖-覆盖。或者，策略可能在数据库期间永远不会改变。
最后，数据很嘈杂。虽然有些事情通常可以得到保障，但索赔仍可能因各种原因被拒绝，例如提交时间过晚、文件不齐全等。同样，有些事情通常可以得到保障，但索赔仍可能得到保障，例如同情护理。
问题：
有没有一种方法可以从数据本身检测出这些政策变化，这样我就可以这么说，对于给定的 CPT 代码，在某个时间段内批准的索赔百分比是 X，而在另一时间段内批准的索赔百分比是 Y，等等？
另一种说法可能是：面对这些嘈杂的数据，我如何找出合适的窗口和截止百分比来计算平均批准率，以便我可以比较两个时间序列？
需要说明的是，我有软件背景，并准备强行解决问题，即，如果有必要，尝试每一个可能的窗口。]]></description>
      <guid>https://stats.stackexchange.com/questions/645345/determine-policy-changes-in-noisy-medicare-insurance-claim-data</guid>
      <pubDate>Thu, 18 Apr 2024 22:19:23 GMT</pubDate>
    </item>
    <item>
      <title>具有二进制数据的转换器的嵌入/标记器</title>
      <link>https://stats.stackexchange.com/questions/627714/embeddings-tokenizers-for-a-transformer-with-binary-valued-data</link>
      <description><![CDATA[我正在尝试训练一个编码器-解码器转换器模型，以完成二进制值数据。每个输入基本上是一个长度为 n 的位串 $x = (x_1, \dots, x_n) \in \{0,1\}^n$，根据某个概率分布生成，该概率分布在训练期间已被屏蔽以隐藏一个位子集。
我对这种输入/输出数据应使用哪种嵌入感到困惑。在翻译的情况下，人们会将输入文本标记为 $N$ 个标记，然后从 $\{1, \dots, N\} \rightarrow \mathbb{R}^d$ 预训练一个嵌入，当 $N \gg d$ 时，这似乎是合理的。但是对于二进制数据，使用单个位作为标记意味着$N=2$，因此不清楚将如此小的标记字母表嵌入到某个高维空间中有什么优势。
在变压器中使用二进制值数据时，有哪些合理的选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/627714/embeddings-tokenizers-for-a-transformer-with-binary-valued-data</guid>
      <pubDate>Sun, 01 Oct 2023 20:46:30 GMT</pubDate>
    </item>
    <item>
      <title>一匹马领先另一匹马的概率[重复]</title>
      <link>https://stats.stackexchange.com/questions/603527/probability-of-one-horse-finishing-ahead-of-another</link>
      <description><![CDATA[在 5 匹马的比赛中。假设一匹马赢得比赛的概率如下：
马 A ：25%
马 B ：4%
马 C ：35%
马 D ：10%
马 E ：26%
您如何确定马 E 在马 C 之前完成比赛的概率？即（马 E 可能获得第 4 名，马 C 获得第 5 名）。
是否有方法可以根据现有信息确定概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/603527/probability-of-one-horse-finishing-ahead-of-another</guid>
      <pubDate>Sun, 29 Jan 2023 12:13:03 GMT</pubDate>
    </item>
    </channel>
</rss>