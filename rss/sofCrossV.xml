<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Mon, 17 Mar 2025 01:21:45 GMT</lastBuildDate>
    <item>
      <title>计算无监督算法的RMSE的标准偏差</title>
      <link>https://stats.stackexchange.com/questions/662723/calculating-standard-deviation-of-rmse-of-an-unsupervised-algorithm</link>
      <description><![CDATA[如果有ML模型，则可以使用时间序列分配来计算均方根误差（RMSE）的标准偏差（SD），通过将模型拟合在不同的训练集上并在测试集上进行评估。。
但是，我的问题涉及一项任务，其中整个数据集都用于发现隐藏的模式，并以无监督的方式将其与地面真相进行比较。时间序列拆分不适用于我的情况下，因为必须使用整个数据集。我有什么选择报告RMSE的SD？]]></description>
      <guid>https://stats.stackexchange.com/questions/662723/calculating-standard-deviation-of-rmse-of-an-unsupervised-algorithm</guid>
      <pubDate>Sun, 16 Mar 2025 23:29:20 GMT</pubDate>
    </item>
    <item>
      <title>如何处理多站点时间序列预测数据/问题</title>
      <link>https://stats.stackexchange.com/questions/662720/how-to-handle-multi-site-time-series-forecasting-data-problems</link>
      <description><![CDATA[有一个小时的数据集，跨越了1K风力的数年天气参数。对于每个风力，我都有风速（平均/分钟），阵风，空气密度以及静态属性等功能。在其他数据库上，我具有每个风力的静态特征（例如涡轮机，型号，功率容量和功能工程所需的其他细节）。我的目标是所有风力组合的每小时大风产生。
由于我正在考虑构建表格时间序列模型，因此文献建议包含滞后功能。但是，将数据旋转到广泛的格式（每个Windfarm的天气参数 +多个滞后 +其他工程功能）是指成千上万的列，这感觉很笨拙，可能容易过度拟合或巨大的计算开销。&gt;
我的问题：
包括许多功能（1,000多个Windfarms×多个参数×多个滞后），或者我可以考虑使用其他技术来有效地组织我的数据，要当心它是很多数据，因此它会很快变得凌乱（在20s GB INFER ENGENCERERION之后的20s GB）。
人们通常如何在数据结构和模型设计方面处理大规模的多站点时间序列预测？是否有推荐的体系结构（例如，某些类型的梯度提升，神经网络或专门的时间序列模型）可以更优雅地处理高维表数据？
我是否应该考虑替代策略，例如构建单独的模型，然后汇总预测或某种混合方法？我很感谢那些解决了大型，多站点时间序列预测问题的人的见解或经历。]]></description>
      <guid>https://stats.stackexchange.com/questions/662720/how-to-handle-multi-site-time-series-forecasting-data-problems</guid>
      <pubDate>Sun, 16 Mar 2025 20:33:42 GMT</pubDate>
    </item>
    <item>
      <title>ANCOVA可比性的时间序列参数</title>
      <link>https://stats.stackexchange.com/questions/662719/ancova-for-comparability-of-time-series-parameters</link>
      <description><![CDATA[我试图了解是否可以使用ANCOVA分析来测试两个不同的对参数的不同意组的可比性。
详细说明，数据集将由来自两个不同的tea（n = 10）的5个样本组成，这些样本已测试了特定参数（预计会线性地加班）。由于预计会有一种趋势，因此我认为Ancova是可靠的统计工具。但是，我要问的是：
我可以使用1组ANCOVA了解10个样本的行为并评估两组之间的可比性吗？
我应该运行两个单独的ANCOVA，并比较两个结果以评估可比性吗？
另外一个问题是：如果我有一个较小的数据集（例如，随着时间的推移有5个结果）和第二组上的1组和更宽的数据集（例如，10个结果随着时间的推移）？]]></description>
      <guid>https://stats.stackexchange.com/questions/662719/ancova-for-comparability-of-time-series-parameters</guid>
      <pubDate>Sun, 16 Mar 2025 20:11:45 GMT</pubDate>
    </item>
    <item>
      <title>一些有关统计假设检验的书籍</title>
      <link>https://stats.stackexchange.com/questions/662717/some-books-on-statistical-hypothesis-testing</link>
      <description><![CDATA[我是统计学的初学者，对概率，线性回归和估计器的知识。
我想知道一些书籍或学习材料，这些书籍或研究材料可以为我提供制定统计测试的数学证明和直观思想（例如，对于我们如何获得z检验中使用的公式……等等。）。。。]]></description>
      <guid>https://stats.stackexchange.com/questions/662717/some-books-on-statistical-hypothesis-testing</guid>
      <pubDate>Sun, 16 Mar 2025 17:29:55 GMT</pubDate>
    </item>
    <item>
      <title>相关的随机效果和不平衡数据</title>
      <link>https://stats.stackexchange.com/questions/662716/correlated-random-effects-and-unbalanced-data</link>
      <description><![CDATA[我想在假期期间研究政策对特定政策和不施加的州的零售价格的影响。
在我的数据中，有3个状态-CA（4家商店），TX（3家商店），WI（3个商店）。该政策是在CA和TX（当时7家商店）中实施的，而不是在WI中实施的。所有商店在数据中均具有相同的40个项目，并且每周观察到5年的价格。
我感兴趣的主要变量是政策虚拟之间的相互作用（如果该州制定了策略，则= 1，否则为0-时间不变）和假日假人（时间变化）。
我想做一个相关的随机效果模型，因为我也想估算时间不变的策略虚拟。

由于政策中有更多的商店，该政策假人，假日假人及其互动的估计是否会不可靠/膨胀？
我不知道这是正确检查的正确方法，但是我在i）TX和WI和II上进行了模型，所有州都会一起使用 - 除了假期假人外，估计值没有改变，但很少有P -Values。。
我的样本量足够大还是过分？
]]></description>
      <guid>https://stats.stackexchange.com/questions/662716/correlated-random-effects-and-unbalanced-data</guid>
      <pubDate>Sun, 16 Mar 2025 17:23:25 GMT</pubDate>
    </item>
    <item>
      <title>创建每月报告的最佳策略是什么？ [迁移]</title>
      <link>https://stats.stackexchange.com/questions/662713/what-is-the-best-strategy-to-create-a-monthly-report</link>
      <description><![CDATA[背景
我的任务是在志愿者数据库上创建仪表板。所需的信息之一是志愿者的性别比率。该数据库位于Google电子表格中（因为它不到1000人，并且更容易用于数据输入的管理部）。我已经设法将其连接到Looker Studio并为其建立饼图。
现在，他们希望我在一年中每个月制作一个性别比率表。他们也希望它每月用于其他所有参数，例如Active vs总比例，年龄组。
 


 
 Jan 
 feb 
 Mar 
 apr 




男性
 150 
 180 
 200 
 240 


女性
 250 
 220 
 300 
 260 


比率
 38 
 45 
 40 
 48 


 
我意识到这意味着我必须创建另一个表格来存储每个参数的价值：男性“数量”，女性的“数量”，男性与女性比例，“积极的志愿者”数量“数量”，“志愿者总志愿者”，“ QTY qty”
现在，最简单的方法是管理员，每个月的每个末，将此跟踪值的每个数字输入到此跟踪器表中。
我的担忧：

跟踪参数可能会增长，我们需要提供回溯数字（在开始跟踪参数之前）
链接到1，管理员无法跟上需要跟踪多少参数
数据输入错误，因为它是手动完成的

从中，我得出的结论是，我需要每个月进行数据快照，以便管理员进行工作。这将允许在需要时进行回溯（1），并允许审核和修复数值错误（3）。
这是正确的策略吗？我可以从这种策略中改善什么？特别是一个可能有助于（2）的人。
我觉得这是一个基本问题，但是在处理策略和Excel公式方面，我几乎没有经验。如果我的课程正确，我想询问如何自动化Looker中的快照（如果可能的话）并在创建报告时自动使用它。]]></description>
      <guid>https://stats.stackexchange.com/questions/662713/what-is-the-best-strategy-to-create-a-monthly-report</guid>
      <pubDate>Sun, 16 Mar 2025 16:57:19 GMT</pubDate>
    </item>
    <item>
      <title>您如何显示$ \ text {cov}（ε，\ hat {y}）= 0 $？</title>
      <link>https://stats.stackexchange.com/questions/662704/how-would-you-show-that-textcov%ce%b5-haty-0</link>
      <description><![CDATA[我正在努力证明OLS模型中预测错误的分布，但是在试图计算差异时我会卡住
  $$
v（y_ {t+1}  -  \ hat {y} _ {t+1}）= v（y_ {t+1}）
$$  
我正在努力证明上学期是零的，而没有跳过我不了解的任何步骤，你们能帮我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662704/how-would-you-show-that-textcov%ce%b5-haty-0</guid>
      <pubDate>Sun, 16 Mar 2025 12:47:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么在R中未通过Gray的测试来显示结果？</title>
      <link>https://stats.stackexchange.com/questions/662700/why-result-not-shown-with-grays-test-for-competing-risk-analysis-in-r</link>
      <description><![CDATA[我是R的新手，正在试图进行竞争风险生存分析。我有糖尿病患者的纵向注册表，观察时间为3个月至20年。我想检查MI（心肌梗死）的累积发病率功能，考虑到竞争的死亡事件，将生存功能与3个亚组（不同水平的肾脏障碍）之间的灰色测试进行比较。
变量：

 Censortime =最初10年的审查/事件/死亡的时间
竞争Eventvariable_1（0 =审查员，1 = mi，2 =死亡）
 ckdgroup（0 =阶段1-2，1 =阶段3，2 =阶段4-5）

我使用的代码：
 库（cmprsk）

data＆lt;  -  read.csv

cif＆lt;  -  cumINC（ftime = data  $ censortime，fstatus = data $ 竞争竞争eventvariable_1，group = data $ ckdgroup）

打印（CIF）

测试：
         Stat PV DF
1 39.37534044 2.816783E-09 2
2 0.04329214 9.785865E-01 2
估计和差异：
$ est
             5 10 15 20
0 1 0.04067314 0.06681032 0.1114019 0.1114019
1 1 0.12306605 0.16499374 NA NA NA
2 1 0.30696836 0.33649660 NA NA NA
0 2 0.30882668 0.58983415 0.6745582 0.7815781
1 2 0.37169465 0.58390409 NA NA NA
2 2 0 0.31913512 0.54539045 na na na

$ var
               5 10 15 20
0 1 0.0002332107 0.0005655726 0.002558737 0.002558737
1 1 0 0.0009133400 0.0016859920 NA NA NA
2 1 0.0025247772 0.0032571000 NA NA NA
0 2 0.0018516332 0.0029027496 0.005413669 0.014017002
1 2 0.0026193427 0.0055196686 NA NA NA
2 2 2 0.0031152384 0.0049735378 NA NA NA


＆gt;绘图（cif，curvlab = true，xlab =＆quot&#39;time＆quot＆quot ylab =＆quot&#39;累积发病率
     main =“累积发病率功能”

＆gt;摘要（CIF）


      长度类模式   
0 1 3-列表   
1 1 3-列表   
2 1 3-列表   
0 2 3-列表   
1 2 3-列表   
2 2 3-列表   
测试6-无 - 数字

 
它不提供P值？这里有什么问题？谁能帮忙？]]></description>
      <guid>https://stats.stackexchange.com/questions/662700/why-result-not-shown-with-grays-test-for-competing-risk-analysis-in-r</guid>
      <pubDate>Sun, 16 Mar 2025 12:13:27 GMT</pubDate>
    </item>
    <item>
      <title>自变量转换时可以使用AIC吗？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/662697/can-aic-be-used-when-the-independent-variable-is-transformed</link>
      <description><![CDATA[在材料被一个人意外吸入后的多次（t）中测量尿液中的有毒金属的量。药代动力学（PK）模型用于预测金属单位摄入后尿液中尿液中金属（x）的数量（PK模型是t的变换）。如果Y与X的图通过直线通过原点“合理地”拟合，则拟合数据的线的斜率是个人吸入的金属的数量。 PK模型是由普通微分方程系统表示的隔室模型。实际上，通常缺乏拟合度（这是现实世界），并且可以使用多个PK模型。总而言之，在模型之间，因变量y和统计模型（RTO）相同，但PK模型不同，因此自变量x是不同的。说AIC不能用于选择哪种PK模型最适合数据是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/662697/can-aic-be-used-when-the-independent-variable-is-transformed</guid>
      <pubDate>Sun, 16 Mar 2025 10:20:07 GMT</pubDate>
    </item>
    <item>
      <title>用于一般成对比较（GPC； WIN比，WR或净治疗益处，NTB）的样本量计算的模拟？</title>
      <link>https://stats.stackexchange.com/questions/662696/simulation-for-sample-size-calculation-for-a-generalized-pairwise-comparison-gp</link>
      <description><![CDATA[我正在计划一项研究，其中参与者将以1：1的形式将干预组或对照组随机分为1：1。主要结果是在4年的中位随访中的心血管事件的综合。。
我的目标是将全因死亡率，诸如心肌梗塞之类的硬端点以及较软的连续终点（例如增加的蛋白尿）纳入分层模型。为了分析数据，我计划使用广义成对比较分析，将结果报告为净治疗益处（NTB）。但是，我无法确定所需的样本量。
分层结果如下：

全因死亡率，预期的1年发病率为1.2％
对照组和4年后的HR为0.85
干预组
狼牙棒的复合物（心肌梗塞的住院治疗，
中风，TIA，心力衰竭），预期的1年发病率为2％
在对照组和4年后的HR中为0.85
干预组
尿白蛋白/肌酐比率（UACR）增加了≥30％
预期对照组的1年发病率为5％，在
干预组的4年期为0.8 
 UACR增加≥10％，预期的1年发病率在15％
对照组和4年后0.8之后的人力资源
干预组

为简单起见，我假设所有组件之间都有温和的相关性（𝜌 = 0.2），除了结果3和4之间的相关性预计中等相关性（𝜌 = 0.5）。
如何模拟这项研究以估计所需的样本量？]]></description>
      <guid>https://stats.stackexchange.com/questions/662696/simulation-for-sample-size-calculation-for-a-generalized-pairwise-comparison-gp</guid>
      <pubDate>Sun, 16 Mar 2025 09:18:36 GMT</pubDate>
    </item>
    <item>
      <title>当响应变量主观时该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/662693/what-to-do-when-the-response-variable-is-subjective</link>
      <description><![CDATA[
一群研究人员想对“友好”的方式建模答案
医生提供的医疗建议提供。有医疗清单
问题 - 要求每个人都保存答案。这
然后将答案显示给人类列表，这些清单将排名答案
就友善而言（从1到10）。年龄和
每个研究人员的经验都是已知的。

 但是，如果“友好性”，真的可以制作模型。是主观数量吗？ 
我试图阅读有关潜在回归模型和项目响应的信息，以查看在这种情况下是否可以完成某件事。我写道：
The (true) latent response for rater $i$ and answer $j$ is $Y_{ij}^*$ :
  $$ y_ {ij}^* = \ theta_j- \ beta_i + \ epsilon_ {ij} $$ 
 $$ \ beta_i = \ beta_0 + \ beta _ {\ text {age}} \ cdot \ cdot \ text {age} _i + \ beta _ {\ beta _ {\ text}
 $$ y_ {ij}^* = \ theta_j- \ beta_0  -  \ beta _ {\ text {age}} \ cdot \ cdot \ cdot \ cd {age} _i} _i} _i- \ beta _ \ beta _ { \ epsilon_ {ij} $$  
其中：

  $ \ theta_j $ 表示“ true”答案的友善 $ j $  
  $ \ beta_i $ 表示评估者的严重性/宽大处理 $ i $   
  $ \ epsilon_ {ij} $ 是随机变化
  $ \ beta_0 $ 是基线严重性参数
在
在
  $ u_i $ 是单独的随机效果

然后，观察到的等级 $ y_ {ij} $ （以：将值1，2，...，...，...，...，10）连接到潜在响应
  $$ y_ {ij} = k \ text {if} \ gamma_ {k-1}＆lt; y_ {ij}^* \ leq \ gamma_k $$  
   $ i $ 给出答案 $ j $   $ k $ 的额定值是（因为class =“数学 - 范围”&gt; $ f $ 是logistic Distribution  $ f（x）= \ frac {1} {1 + e^{ -  x}}} $ ）：）：）：）
  $$ P（y_ {ij} = k）= P（\ gamma_ {k-1}＆lt; y_ {ij}^* \ leq \ gamma_k）
  $$ P（Y_ {IJ} = K）= P（\ Gamma_ {K-1}＆lt; \ Theta_j- \ \ beta_i + \ epsilon_ {ij}
 $$ = P（\ gamma_ {k -1}  -  \ \ theta_j + \ beta_i＆lt; \ epsilon_ {ij} \ leq \ leq \ gamma_k- \ theta_j + beta_i_j + beta_i_i）
$$ P(Y_{ij} = k) = F(\gamma_k - \theta_j + \beta_i) - F(\gamma_{k-1} - \theta_j + \beta_i) $$
  $$ p（y_ {ij} = k）= \ frac {1} {1 + e^{ - （\ gamma_k- \ theta_j + \ beta_i_i）}}}}}}}}}}}}}}}  -  \ frac {1} {1} {1} {1 + e^_________________（\ k-1（\ k-^{ -  \^thth-a） \ beta_i）}} $$  
  $$ p（y_ {ij} = k）= \ frac {1} {1 + e^{ - （\ gamma_k- \ \ theta_j + \ beta_0 + \ beta_0 + \ beta + \ beta _ { \ beta _ {\ text {exp}} \ cdot \ text {经验} _i + u_i）}}}}}  -  \ frac {1} {1 + e^{ - （\ gamma_ {k -1 {k -1}  - \ text {age} _i + \ beta _ {\ text {exp}} \ cdot \ cdot \ text {axepens} _i + u_i）}}} $$   
通过大量工作，我可以定义可能性并估算参数以估计“ true”。给定答案的友好性...但是，如果真正的友善是从根本上主观的，那么这是否毫无意义（即使使用潜在模型）？像SEM这样的事情更好吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662693/what-to-do-when-the-response-variable-is-subjective</guid>
      <pubDate>Sun, 16 Mar 2025 04:56:49 GMT</pubDate>
    </item>
    <item>
      <title>计算错误项的NLME :: GLS（）的不确定性？</title>
      <link>https://stats.stackexchange.com/questions/662645/calculate-uncertainty-for-nlmegls-of-the-error-terms</link>
      <description><![CDATA[我在这里试图与 nlme :: gls（）一起工作，因为这是我发现的最佳解决方案。我想找到类似的数据：
  stdconc_dil＆lt;  -  1：200
res＆lt;  -  lapply（1：nrep，function（i）{
    响应＆lt;  -  stdconc_dil + rnorm（长度（stdconc_dil），0， 
       0.06*stdconc_dil） + rnorm（长度（stdconc_dil），0，0.4）
    data.frame（stdconc = stdconc_dil，conc = revertmon）
}））

res＆lt;  -  do.call（rbind，res）

GLS（conc〜stdconc-1，data = res， 
  striges = varconstprop（form = 〜StdConc），控制=列表（Sigma = 1））
 
我正在尝试对 2标准偏差项进行不确定性估计，而不是斜率。 （实际上，我正在尝试完全删除坡度，然后直接制作 y〜x + varconstprop（），但我未能找到解决方案。）
如果我可以提取诸如完整协方差矩阵或黑森州之类的东西，则 solve（），它可能会为我做。]]></description>
      <guid>https://stats.stackexchange.com/questions/662645/calculate-uncertainty-for-nlmegls-of-the-error-terms</guid>
      <pubDate>Fri, 14 Mar 2025 21:46:41 GMT</pubDate>
    </item>
    <item>
      <title>将文本可读性指标与主观测量相关联</title>
      <link>https://stats.stackexchange.com/questions/662642/correlating-text-readability-metrics-against-subjective-measurements</link>
      <description><![CDATA[假设我想找出文本的不同可读性指标与文本复杂性的主观测量相关。我要求18个人阅读12条短文，我衡量他们认为每个文本的量表都有5个项目的范围（因此得分为5.0表示高复杂性）。我想尝试找出哪些度量与主观复杂性最有关系。
一种幼稚的方法是从所有参与者中获取每个文本的平均主观得分，并在应用于文本时发现哪种复杂性度量与结果的相关性最强。但是，我认为这将丢失很多信息（例如，如果两个参与者将一些分数换成某些文本片段，那么即使这会影响他们自己的相关性，这也不会影响这种天真的结果）。多级模型会在这里适当吗？
这是我问题的形式化：

我们进行了一个实验 $ n = 18 $ 参与者和 $ m = 12 $ 
短文。每个参与者 $ p \ in \ {1，2，\ dots，18 \} $ 读取每个
text  $ t \ in \ {1，2，\ dots，12 \} $ 并提供了主观的复杂性
评分 $ y_ {p，t} $ 在5分制上，其中 $ 5 $ 表示高
感知的复杂性。请注意，我们可能有一些缺少的数据。
此外，我们有 $ k $ 不同的可读性指标，
  $ m_ {1}（t），\; m_ {2}（t），\; \ ldots，\; m_ {k}（t）$ ，
每个分配数值复杂性（或难度）得分
文本（t）。这些指标在不同的尺度上，不是直接的
彼此或5分参与者评分。
如何计算哪种指标可以最好地预测主观复杂性等级？

评论：这个问题类似于
示例：
一个指标可能将第一个文本的复杂性评为4，第二个文本为6等，而另一个指标将在其自身的尺度上对与10和12相同的文本进行评分。同时，一个参与者关于前两个文本的复杂性的主观得分分别为3和4（满分5）。来自不同量表的数字不是直接可比的。我们只想找出他们与参与者的主观分数有多相关。
可能的多级模型：
  \ begin {align*}
y_ {p，t}＆amp; = \ beta_0 \;+\; \ sum_ {j = 1}^k \ beta_j \，m_j（t）
         \;+\; b_ {0，p} \;+\; b_ {0，t} \;+\; \ varepsilon_ {p，t}，\\
b_ {0，p}＆amp; \ sim \ mathcal {n}（0，\，\ sigma_p^2），\\
b_ {0，t}＆amp; \ sim \ mathcal {n}（0，\，\ sigma_t^2），\\
\ varepsilon_ {p，t}＆amp; \ sim \ mathcal {n}（0，\，\ sigma^2）。
\ end {align*}  
其中
  $ y_ {p，t} $ 是参与者观察到的复杂性评级， $ p $  for text   $ \ beta_0 $ 是全局截距（刻薄）。
  $ \ beta_j $ 是每个可读性度量的固定效应系数
  $ b_ {0，p} $ 是参与者的随机截距 $ p $ ，假定遵循Variance  $ \ sigma_p^2 $  $  $ 
  $ b_ {0，t} $ 是文本的随机拦截 $ t $ ，假定遵循Variance  $ \ sigma_t $ \ sigma_t^2 $  $  $ 
  $ \ varepsilon_ {p，t，t} $ 是剩余错误术语，假定遵循带有方差class  $ \ sigma^$ \ sigma^2 $ 。]]></description>
      <guid>https://stats.stackexchange.com/questions/662642/correlating-text-readability-metrics-against-subjective-measurements</guid>
      <pubDate>Fri, 14 Mar 2025 21:32:21 GMT</pubDate>
    </item>
    <item>
      <title>线性回归后MRI多次测试比较</title>
      <link>https://stats.stackexchange.com/questions/662561/mri-multiple-test-comparisons-after-linear-regression</link>
      <description><![CDATA[我想问如何处理MRI脑图像中的多个测试比较。
我在70个大脑区域和40个功能区域（这是特定大脑区域的总和）进行了110个多个线性回归模型。我的模型控制了5个混杂因素和1个曝光。
这是我对分析暴露的重要p值（＆lt; 0.05）：0.038、0.014、0.014和0.04。
但是，当我应用FDR时，Q值是以下内容：0.00045、0.00091、0.00136、0.00182。
是否有任何方法可以处理这种严格的P值？
可能是Q值限制了我的新发现？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662561/mri-multiple-test-comparisons-after-linear-regression</guid>
      <pubDate>Thu, 13 Mar 2025 10:30:41 GMT</pubDate>
    </item>
    <item>
      <title>Gower距离的聚类分析</title>
      <link>https://stats.stackexchange.com/questions/662431/cluster-analysis-with-gower-distance</link>
      <description><![CDATA[我有一个包括数字和分类变量的数据集，我想执行群集分析。因此，我选择高尔距离作为距离度量。接下来，我使用完整的链接执行集聚聚类（该功能不允许使用Gower距离的病房）。
现在，我的问题是，我可以执行非等级聚类吗？ K-Medoids做了什么，与K均值相似？它是否像k均值一样工作，您将层次聚类的质心用作起点？]]></description>
      <guid>https://stats.stackexchange.com/questions/662431/cluster-analysis-with-gower-distance</guid>
      <pubDate>Mon, 10 Mar 2025 21:35:56 GMT</pubDate>
    </item>
    </channel>
</rss>