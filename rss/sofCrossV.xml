<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 10 Oct 2024 03:21:50 GMT</lastBuildDate>
    <item>
      <title>概率/标准正态分布作业帮助</title>
      <link>https://stats.stackexchange.com/questions/655578/probability-standard-normal-distribution-homework-help</link>
      <description><![CDATA[我在家庭作业中被这个问题难住了，想知道是否有人可以提供一些关于如何解决这个问题的建议？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655578/probability-standard-normal-distribution-homework-help</guid>
      <pubDate>Thu, 10 Oct 2024 01:56:25 GMT</pubDate>
    </item>
    <item>
      <title>二进制数据特征的缩放</title>
      <link>https://stats.stackexchange.com/questions/655575/scaling-for-binary-data-features</link>
      <description><![CDATA[我的目标是对两名选手之间的体育比赛进行二元分类，特别是我关心每位选手获胜的概率。
我当前的数据框具有 [来自选手 A 的属性，来自选手 B 的属性] 的特征值。但是，当我在此特征行上应用缩放时，会出现问题 - 在这种情况下，当我交换特征值的顺序 [来自玩家 B 的属性，来自玩家 A 的属性] 时，缩放是不对称的。
例如：

feature_set_1：[人 A 的身高，人 A 的国家，人 A 的体重，人 B 的身高，人 B 的国家，人 B 的体重，比赛结果]
feature_set_2：[人 B 的身高，人 B 的国家，人 B 的体重，人 A 的身高，人 A 的国家，人 A 的体重，比赛结果]

由于缩放时顺序的重要性，feature_set_1 中人 A 身高的缩放结果将不等于 feature_set_2 中的缩放结果。
这导致在预测概率时出现问题，因为我得到的结果为概率（A 击败 B）+概率（B 击败 A）&gt;1，幅度相当大。此外，相对于这种情况，我们提供属性的顺序（玩家 A 先于玩家 B，或玩家 B 先于 A）应该没有实际影响。
在实践中，这种情况通常是如何解决的？
我想到的一个解决方案是实施特征工程，其中我将特征值改为 [来自玩家 A 的属性 - 来自玩家 B 的属性]。但是，当反转 A 和 B 的顺序时，这会导致负面结果。我不确定这会如何影响概率预测，更重要的是，它是否会保持玩家 A 和玩家 B 获胜（概率总和为 1）之间的互斥性。请注意，我使用的分类器需要缩放（MLP）]]></description>
      <guid>https://stats.stackexchange.com/questions/655575/scaling-for-binary-data-features</guid>
      <pubDate>Thu, 10 Oct 2024 00:22:26 GMT</pubDate>
    </item>
    <item>
      <title>(MacKay) 如何以易于处理的方式在线优化正则化常数？</title>
      <link>https://stats.stackexchange.com/questions/655574/mackay-how-can-regularization-constants-can-be-optimized-on-line-in-a-tractabl</link>
      <description><![CDATA[根据 MacKay 在其著作《信息理论、推理和学习算法》第 44 章“多层网络中的监督学习”（第 531 页）中的说法，他声称贝叶斯优化模型控制参数（尤其是神经网络，例如权重衰减常数）的优势如下：

“正则化常数可以在线优化，即
与普通模型参数的优化同时进行……可以评估证据相对于控制参数的梯度，从而可以同时
优化大量控制参数。”

但是，我看不出如何以易于处理的方式优化控制参数。例如，假设我们正在处理具有权重衰减惩罚的前馈神经网络。令 $\mathcal{D}$ 为数据，$\mathcal{H}_\lambda$ 为假设，即模型权重的先验是具有常数方差 $\lambda^2$ 的多元高斯分布（此处，$\lambda$ 是 MacKay 所说的“控制参数/正则化常数”）。然后通过贝叶斯论证，我们必须选择$\lambda$使得
$$
\begin{align*}
\lambda^* &amp;= \arg \max_{\lambda} \mathbb{P}[\mathcal{D} | \mathcal{H}_{\lambda}] \\
&amp;= \arg \max_\lambda \int_{\mathbb{R}^{d_w}}\mathbb{P}[\mathcal{D} | w, \mathcal{H}_{\lambda}] \mathbb{P}[w|\mathcal{H}_\lambda] dw
\end{align*}
$$
其中 $w\in \mathbb{R}^{d_w}$ 是我们的神经网络中 $d_w$ 权重的向量。
如果我正确理解了 MacKay 的意思，他似乎在说，相对于 $\lambda$ 的积分梯度可以轻松计算，但我不明白为什么会这样。如果我理解正确的话，如果$E(\lambda) = \int_{\mathbb{R}^{d_w}}\mathbb{P}[\mathcal{D} | w, \mathcal{H}_{\lambda}] \mathbb{P}[w|\mathcal{H}_\lambda] dw$，那么
$$
\begin{align*}
\frac{d}{d\lambda} E(\lambda) &amp;= \int_{\mathbb{R}^{d_w}}\mathbb{P}[\mathcal{D} | w, \mathcal{H}_{\lambda}] \frac{d}{d\lambda} \mathbb{P}[w|\mathcal{H}_\lambda] dw \\ 
\end{align*}
$$
虽然积分中的梯度很容易计算，但积分本身感觉很难计算。
鉴于此 - 当 MacKay 写“可以评估证据相对于控制参数的梯度”时他的意思是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655574/mackay-how-can-regularization-constants-can-be-optimized-on-line-in-a-tractabl</guid>
      <pubDate>Wed, 09 Oct 2024 22:40:48 GMT</pubDate>
    </item>
    <item>
      <title>比较不同重叠组中两个变量的相关性</title>
      <link>https://stats.stackexchange.com/questions/655573/comparing-correlations-for-two-variables-in-different-overlapping-groups</link>
      <description><![CDATA[我有一个样本，其中我为同一种疾病应用了五种（差异很大）诊断定义。例如，50% 的诊断定义 1 下的患病病例不是诊断定义 2 下的患病病例，而 10% 的符合定义 2 的病例不是定义 1 下的病例。定义 1 是目前使用最广泛的“标准”，所有其他定义都将与定义 1 进行比较。
我想比较针对每个人测量的两个变量之间的相关性（称为 X 和 Y），看看定义 1 下的患病病例的 cor(X,Y) 是否与定义 2 下的患病病例的 cor(X,Y) 不同（请记住，有些人同时符合两个定义，并将同时属于两个组）。我想要用几对变量来做这个 - 根据具体变量，我可能会使用 Pearson、Spearman 或四分法相关系数。
将样本限制为“符合五个诊断定义中至少一个的人”后我的样本量约为 80,000，所有诊断定义至少产生 30,000 个病例。
我首先想到的方法是使用引导法：

使用“至少符合一个诊断定义的 80,000 人”的整个样本进行替换抽样。
对于五个诊断定义中的每一个，使用符合该定义的引导样本中的观测值计算 cor(X,Y)。
对得到的相关性使用 Fisher 变换，这样减法就合适了。
对于诊断定义 2-5 中的每一个，从定义 1 病例的相关性中减去该组的相关性。 （使用当前引导迭代中的 Fisher 变换相关性。）
重复步骤 1-4 数千次。
取 min(差异百分比 &gt; 0,差异百分比 &lt; 0)，并将该数字乘以 2，得到双尾检验，以确定相关性之间的差异是否不等于 0。

此过程合适吗？它会做我想做的事情吗（测试相关性的差异，同时考虑产生相关性的两个组之间的重叠）？我是否应该考虑使用其他方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655573/comparing-correlations-for-two-variables-in-different-overlapping-groups</guid>
      <pubDate>Wed, 09 Oct 2024 22:02:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在等相关随机向量 MLE 中得到结果 3.56-3,58</title>
      <link>https://stats.stackexchange.com/questions/655572/how-can-we-get-the-result-3-56-3-58-in-the-equal-correlation-random-vector-mle</link>
      <description><![CDATA[
正如问题所发布的那样，我们如何在等相关随机向量 MLE 中得到结果 3.56-3,58]]></description>
      <guid>https://stats.stackexchange.com/questions/655572/how-can-we-get-the-result-3-56-3-58-in-the-equal-correlation-random-vector-mle</guid>
      <pubDate>Wed, 09 Oct 2024 21:59:29 GMT</pubDate>
    </item>
    <item>
      <title>多时间序列的超参数调整</title>
      <link>https://stats.stackexchange.com/questions/655571/hyperparameter-tuning-for-multiple-time-series</link>
      <description><![CDATA[我正在利用 NeuralProphet 开发一个时间序列模型，用于预测每日产品需求。我已根据平均需求、需求标准差和时间序列长度等特征将产品分组为多个集群。
我认为解决此问题的最佳方法是使用全局局部建模为每个集群创建一个模型，并使用该模型为每种产品生成单独的预测。但是，我正在努力弄清楚如何正确调整全局局部模型的超参数。我的目标是创建一个在各个集群中的所有产品上都具有可接受准确度的模型，但我不确定如何在不对每个项目进行试验的情况下做到这一点。
我已经测试使用贝叶斯优化在单个时间序列模型的上下文中调整超参数，并获得了很好的结果，但在多个时间序列模型的情况下，对每个单独的产品进行数十次试验将非常耗时。我曾考虑过从每个集群中抽取样本，但那么我该如何选择样本呢？即使我有集群中每种产品的最佳超参数列表，我如何将它们缩小到整个集群的单个集合？
我将非常感激有关如何解决这个问题的任何建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/655571/hyperparameter-tuning-for-multiple-time-series</guid>
      <pubDate>Wed, 09 Oct 2024 21:26:02 GMT</pubDate>
    </item>
    <item>
      <title>Neal 算法 1 是如何推导出来的？</title>
      <link>https://stats.stackexchange.com/questions/655568/how-is-neals-algorithm-1-derived</link>
      <description><![CDATA[我正在阅读 Neal 的狄利克雷过程混合模型的马尔可夫链抽样方法。我无法理解方程 3.2、3.3 和 3.4 是如何推导出来的。它们直观上是有意义的，但我很难想出一个正式的推导，特别是方程 3.4。
摘自论文：

这是我所得到的（不正确？）
$$\begin{align*}
p(\theta_i|\theta_{-i}, y_i)&amp;\propto p(\theta_i, \theta_{-i}, y_i)\\
&amp;=p(y_i|\theta_i, \theta_{-i})p(\theta_i|\theta_{-i})p(\theta_{-i})\\
&amp;=p(y_i|\theta_i)p(\theta_i|\theta_{-i})p(\theta_{-i}) \quad\text{since}\;{y_i\perp \theta_{-i}|\theta_i}\\
&amp;\propto p(y_i|\theta_i)p(\theta_i|\theta_{-i})
\end{align*}$$
我不确定积分从何而来。]]></description>
      <guid>https://stats.stackexchange.com/questions/655568/how-is-neals-algorithm-1-derived</guid>
      <pubDate>Wed, 09 Oct 2024 20:43:54 GMT</pubDate>
    </item>
    <item>
      <title>证明 $\mathbb{E} (|X-Y|) = 0 \implies X^2 = Y^2$</title>
      <link>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</link>
      <description><![CDATA[$\boxed{\text{设 } X,Y \text{ 为任意随机变量。证明如果 } \mathbb{E}(​​|X-Y|) = 0，\text{则 } X^2 = Y^2。}$
我们有 $\mathbb{E}(​​|X-Y|) = 0$，我认为如果我能以某种方式证明 $X=Y$，那么它直接意味着 $X^2 = Y^2$，但我不知道如何实现。
附言：这不是任何形式的家庭作业，我只是在大学概率课程的往期考试中看到了这个问题，想尝试一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</guid>
      <pubDate>Wed, 09 Oct 2024 19:54:07 GMT</pubDate>
    </item>
    <item>
      <title>所有相关性荟萃分析</title>
      <link>https://stats.stackexchange.com/questions/655563/all-correlations-meta-analysis</link>
      <description><![CDATA[我是 MetaSEM 的新手。我正在尝试进行一个简单的元分析（我只想分析 2 个相关性；见图）。
在这里您可以找到我使用的一些模拟数据的代码，但如果没有回归，我就无法让它工作（除非我添加回归系数，否则它会永远工作下去）。这应该是一个简单的模型，但我被卡住了。我只想要两个协方差，我已经将所有方差固定为一个。换句话说，我只想对 S-D 和 I-D 之间的相关性进行元分析。
S 和 D、S 和 I 以及 D 和 I 之间的相关性存储在此处：
rSD &lt;- c(0.85, 0.8, 0.90, 0.78, 0.70,NA,NA,NA,NA,NA)
rSI &lt;- c(NA,NA,NA,NA,NA,0.85,NA,NA,NA,NA)
rDI &lt;- c(NA,NA,NA,NA,NA,0.60, 0.50, 0.55, 0.60, 0.55)

rSI 可能是 al NA，因为我对这种相关性不感兴趣。
我读过关于 SEM 和 RAM 模型的文章，我认为这个模型是可以识别的，应该很容易拟合。任何帮助和指导都将不胜感激。
library(metaSEM)
source(&quot;http://www.suzannejak.nl/MASEM_functions.R&quot;)

rSD &lt;- c(0.85, 0.8, 0.90, 0.78, 0.70,NA,NA,NA,NA,NA)
rSI &lt;- c(NA,NA,NA,NA,NA,0.85,NA,NA,NA,NA)
rDI &lt;- c(NA,NA,NA,NA,NA,0.60, 0.50, 0.55, 0.60, 0.55)

N &lt;- c(10000,40000, 30000, 10000, 10000,20000,10000, 50000, 10000, 10000 )

数据 &lt;- as.data.frame(cbind(rSD,rSI,rDI, N))

nvar &lt;- 3
varnames &lt;- c(&quot;S&quot;,&quot;D&quot;, &quot;I&quot;)
labels &lt;- list(varnames,varnames)

cormatrices &lt;- readstack(data[,c(2,1,3)], no.var = nvar, var.names = varnames, diag = FALSE)

n &lt;- data$N

pattern.na(cormatrices, show.na=F)
pattern.n(cormatrices, n=n)

my.df &lt;- Cor2DataFrame(cormatrices, n, acov = &quot;weighted&quot;)

## 使用指定模型lavaan 语法
模型 &lt;-
&#39;

# 协方差
D ~~ I
D ~~ S
# 方差

D ~~ 1*D
S ~~ 1*S
I ~~ 1*I
&#39;

RAM1 &lt;- lavaan2RAM(model, obs.variables=varnames)
RAM1

## 创建具有隐式对角线约束的模型隐含相关结构
M0 &lt;- create.vechsR(A0=RAM1$A, S0=RAM1$S)

## 创建异质性方差-协方差矩阵
T0 &lt;- create.Tau2(RAM=RAM1, RE.type=&quot;Diag&quot;, Transform=&quot;expLog&quot;, RE.startvalues=0.05)

## 拟合模型
mx.fit0 &lt;- osmasem(model.name=&quot;No moderator&quot;, Mmatrix=M0, Tmatrix=T0, data=my.df)

## 查看结果
summary(mx.fit0, fitIndices = TRUE)
VarCorr(mx.fit0)

]]></description>
      <guid>https://stats.stackexchange.com/questions/655563/all-correlations-meta-analysis</guid>
      <pubDate>Wed, 09 Oct 2024 19:33:34 GMT</pubDate>
    </item>
    <item>
      <title>在风险函数的定义中，$\leq$ 应该放在哪里？</title>
      <link>https://stats.stackexchange.com/questions/655562/where-should-the-leq-go-in-the-definition-of-the-hazard-function</link>
      <description><![CDATA[我在几本教科书和在线资源中都看到过两种风险函数定义。
定义 1。这里例如。
$$h(t) = \lim_{\epsilon \to 0+}\dfrac{P(t &lt; T \leq t + \epsilon \mid T &gt; t)}{\epsilon},$$
定义 2。这里例如。
$$h(t) = \lim_{\epsilon \to 0+}\dfrac{P(t \leq T &lt; t + \epsilon \mid T \geq t)}{\epsilon}.$$
我推测如果 $T$ 是绝对连续的，那么它们是等价的。但是，是否存在它们不同的情况？如果有，哪一个是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/655562/where-should-the-leq-go-in-the-definition-of-the-hazard-function</guid>
      <pubDate>Wed, 09 Oct 2024 18:40:31 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助理解具有多个随机变量的条件概率分布</title>
      <link>https://stats.stackexchange.com/questions/655561/need-help-with-understanding-conditional-probability-distributions-with-multiple</link>
      <description><![CDATA[我试图理解我正在阅读的一些机器学习讲义中介绍的以下步骤。在这种情况下，我们想要用参数化函数类 $\mathcal{F}(\Theta)$ 中的函数来近似函数 $f^*: \mathcal{X} \to \mathcal{Y}$，其中该类中的每个函数都依赖于一些参数 $\theta \in \Theta$。我们给出了输入 $x_{1:n}$ 和标签 $y_{1:n}$，其中我们使用符号 $x_{1:n} = (x_1, \ldots, x_n)^T$。我们假设标签是独立同分布的，并且 $y_i \sim p( \cdot | x_i, \theta)$ 成立。此外，我们假设参数 $\theta$ 具有先验分布 $p(\theta)$。我们现在希望通过对 $\theta$ 进行条件设定，预测新输入 $x^*$ 时的输出 $y^*$：
$$p(y^* | x^*, x_{1:n}, y_{1:n}) = \int_{\Theta}p(y^*, \theta | x^*, x_{1:n}, y_{1:n}) d\theta = \int_{\Theta}p(y^* | x^*, \theta) \cdot p(\theta | x_{1:n}, y_{1:n})d\theta,$$
根据讲义，第一个等式如下根据求和规则，其表述为
$$p(x_{1:i - 1}, x_{i + 1:n}) = \int_{X_i(\Omega)}p(x_{1:i-1},x_i, x_{i + 1: n}) dx_i,$$
第二个等式根据 $y^* \perp x_{1:n}, y_{1:n} | \theta$ 和乘积规则，其表述为
$$p(x_{1:n}) = p(x_1) \prod_{i = 2}^np(x_i | x_{1: i-1}).$$
我认为我理解第一个等式，因为根据条件概率分布的定义，我们有
$$p(x_{1:i-1}, x_{i+1:n} | y_{1:n}) = \frac{p(x_{1:i-1}, x_{i+1:n}, y_{1:n})}{p(y_{1:n})} = \frac{\int_{X_i(\Omega)}p(x_{1:i-1},x_i, x_{i + 1: n}, y_{1:n}) dx_i}{p(y_{1:n})} = $$
$$ = \frac{\int_{X_i(\Omega)} p(y_{1:n})p(x_{1:i-1},x_i, x_{i + 1: n} | y_{1:n}) dx_i}{p(y_{1:n})} = \int_{X_i(\Omega)}p(x_{1:i-1},x_i, x_{i + 1: n} | y_{1:n}) dx_i.$$
但是，我不明白第二个等式如何从 $y^* \perp 得出x_{1:n}, y_{1:n} | \theta$ 和所述乘积规则。
如能得到任何帮助，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/655561/need-help-with-understanding-conditional-probability-distributions-with-multiple</guid>
      <pubDate>Wed, 09 Oct 2024 18:33:29 GMT</pubDate>
    </item>
    <item>
      <title>寻找使用“求解方程”带宽进行核密度估计的可靠教程</title>
      <link>https://stats.stackexchange.com/questions/655559/looking-for-robust-tutorial-using-solve-the-equation-bandwidth-for-kernel-dens</link>
      <description><![CDATA[我目前正在从事的工作是让我为通过任意有界函数 $z=p(\vec{x})$ 诱导的分布生成 CDF 函数，其中 $p:\mathcal{D} \subset \mathbb{R}^m \to \mathcal{R} \subset \mathbb{R}$，并且 $\mathcal{D}:=\times_{i=1}^m [a_i,b_i]$ 和 $-\infty &lt; a_i &lt; b_i &lt; \infty$。更具体地说，我取随机变量$ \vec{X} \sim \mathcal{U}(\mathcal{D})$，并诱导随机变量$Z = p(\vec{X})$，并使用$n$个样本构建近似值$F_n(z)$，以获得“真实的”（可能/通常不可知的）累积分布函数$F(z)$。我正在使用高斯核的核密度估计构建这个近似值，$K(t) = (2\pi)^{-1/2}\exp(-t^2/2)$，并应用 Silverman 的经验法则来计算带宽的值，$h$。此规则为
$$
h = 0.9 \min\left\{\widehat{\sigma}, \frac{IQR}{1.34} \right\}
$$
（顺序问题，我发现很多不同的规则被称为 Silverman 经验法则，因此这 可能 实际上不是 Silverman 经验法则。请在评论中纠正我，但这最终与我的询问无关）。
我还想使用 Solve-the-Equation（糟糕的品牌名称）带宽计算来估算这一点，但我找不到任何关于如何进行此操作的易于理解的演示文稿/来源/参考资料。如果有人可以指出有关如何为 KDE 进行 Solve-the-Equation 带宽的详尽解释/来源，我将不胜感激。尤其是不会掩盖太多细节的。这种数学不是我的强项。或者，如果网上找不到这样的教程，可以在这里介绍一个强大的教程。此外，请纠正我的术语中的任何错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/655559/looking-for-robust-tutorial-using-solve-the-equation-bandwidth-for-kernel-dens</guid>
      <pubDate>Wed, 09 Oct 2024 18:04:25 GMT</pubDate>
    </item>
    <item>
      <title>创建针对一个主题和每个项目的评分者间信度</title>
      <link>https://stats.stackexchange.com/questions/655556/create-inter-rater-reliability-on-one-subject-and-per-item</link>
      <description><![CDATA[我公司接到一项任务，因为我不太懂统计学，也没有找到解决我的问题的具体方法，所以我想问问你们。
那么我的任务是什么呢？
我们必须每年培训员工。培训如下：
员工们正在观看一个主题的视频，然后他们必须对视频的不同部分进行 1-5 的评分，如果无法评估，则为 0。
目标是评估不同的评分者是否对特定部分给出了相同的评分。例如，可以使用 Landis Koch 基准来评估可靠性。
如果特定部分高于某个阈值，则公司感到满意。如果没有，则必须对员工进行该特定部分的培训。
这意味着我必须为每个部分创建一个可靠性分数，以查看是否需要培训。此外，公式还必须考虑评级是否接近。
这就是为什么例如简单的百分比可靠性不起作用的原因（我认为）
此外，像 Fleiss Kappa 这样的公式也不起作用，因为它无法确定一个主题的单个部件（或项目）的 kappa。
例如，我们有 50 位评分者，并且特定部件的评级为 5 次“0”，5 次“1”，10 次“2”，30 次“3”，其他部件没有投票。还有一个权重也应该计算在内。评级为“1”表示未通过，而“0”表示该部件无法评级。数字上很接近，但对主题来说却是灾难性的。然后，一个评分员给他打了不及格分，另一个评分员给他打了不及格分。
有没有办法计算一个项目的分数、Kappa 值或其他东西，并以某种方式对其进行加权？
正如我所说，我不太喜欢统计，但当我知道要寻找什么时，我认为这会有所帮助。
编辑：我可能必须澄清一下。
整个设置都是法律规定的。因此，员工，即教员，观看视频。他们必须根据不同的能力对视频中的受训者进行评分。他的知识如何，他的领导能力如何等。他们必须用上述等级对每项能力进行评分。目标是确保每个教员的评分几乎相同。因为如果不是这样，受训者在现实生活中将高度依赖他得到的教员。这就是我们需要这个培训计划的原因。我们必须评估我们必须与教员合作的能力。为此，我们需要一个量表。我们收到了一家公司的报价，他们使用 Landis Koch 量表并借助 kappa 进行评估。但他们当然没有告诉我们具体是哪种。我们想重建它，自己在公司内部制造。但我们知道这在某种程度上是可行的。这就是为什么我们需要为每项能力设置一个分数或其他东西。遗憾的是，设置无法更改。]]></description>
      <guid>https://stats.stackexchange.com/questions/655556/create-inter-rater-reliability-on-one-subject-and-per-item</guid>
      <pubDate>Wed, 09 Oct 2024 17:39:48 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归的最大似然估计方法中存在普遍的不一致性</title>
      <link>https://stats.stackexchange.com/questions/655545/widespread-inconsistency-in-maximum-likelihood-estimation-approach-to-logistic-r</link>
      <description><![CDATA[我发现，通过最大似然估计方法得出逻辑回归的损失函数的方式存在一些普遍的不一致之处。
在逻辑回归模型中，我们假设$\Pr[Y = +1| X = x] = \sigma(w^T x)$，其中$\sigma$是逻辑函数，$\sigma(w^T x) = \dfrac{\exp(w^T x)}{1 + \exp(w^T x)}$。类似地，$\Pr[Y = -1| X = x] = 1 - \sigma(w^T x).$
$X, Y$ 具有示例和标签的通常含义。
请注意，$w$ 是一个恒定权重参数（没有假设分布），我们希望对其进行调整。 查找 $w$ 的最常见方法是通过最大条件似然估计。
这就是文献中出现不一致的地方：一些作者假设 $w$ 是我们以此为条件的随机变量，其他作者假设 $w$ 是一个常数参数。
假设 $w$ 为常数的参考文献参数：
https://www.cs.cornell.edu/courses/cs4780/2015fa/web/lecturenotes/lecturenote06.html
请注意，作者使用冒号符号来分隔随机变量和常数参数，即 $p(y|x; w)$
https://web.stanford.edu/class/archive/cs/cs109/cs109.1178/lectureHandouts/220-logistic-regression.pdf
https://cseweb.ucsd.edu/~elkan/250B/logreg.pdf
https://web.engr.oregonstate.edu/~xfern/classes/cs534-18/Logistic-Regression-3-updated.pdf
假设 $w$ 为随机变量的参考文献：
https://www.cs.cmu.edu/~awm/15781/slides/LogRegress-9-29-05.pdf
请注意作者对 $w$ 的条件，即 $p(y|x, w)$
https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf
https://zstevenwu.com/courses/s20/csci5525/resources/slides/lecture05.pdf
https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote06.html
https://svivek.com/teaching/lectures/slides/logistic-regression/logistic-regression.pdf（作者使用两种符号可以互换使用）
本书：https://mml-book.github.io/
我的问题是：

哪种推导是正确的？$w$ 应该被视为常数参数还是随机变量？

只是为了消除一些困惑：

在最大似然估计中，我们总是最大化常数的似然，还是最大化随机变量的似然？

也许 2 的后续问题是，在最大后验估计中，我们总是最大化常数的似然，还是最大化随机变量的似然？]]></description>
      <guid>https://stats.stackexchange.com/questions/655545/widespread-inconsistency-in-maximum-likelihood-estimation-approach-to-logistic-r</guid>
      <pubDate>Wed, 09 Oct 2024 15:14:21 GMT</pubDate>
    </item>
    <item>
      <title>哪项测试用于三组之间的标准化量化数据</title>
      <link>https://stats.stackexchange.com/questions/655540/which-test-for-normalised-quantification-data-between-three-groups</link>
      <description><![CDATA[我想比较三个组（疾病 1、疾病 2 和非疾病）之间的一个变量的数量（分配给念珠菌的读取次数）
当我使用不同的方法进行测试时，结果并不总是相同的。如果我使用钢或 Dunnett 测试（针对控制非疾病），我会得到不同的结果
如果我使用 Mann Whitney，我会得到一个显着的差异，并且通过所有成对比较，我再次得到不同的东西。
我真的不知道该遵循哪一个，有人可以帮忙吗？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/655540/which-test-for-normalised-quantification-data-between-three-groups</guid>
      <pubDate>Wed, 09 Oct 2024 14:26:32 GMT</pubDate>
    </item>
    </channel>
</rss>