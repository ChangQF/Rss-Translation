<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 24 Jun 2024 18:19:41 GMT</lastBuildDate>
    <item>
      <title>时间序列数据中的平台检测</title>
      <link>https://stats.stackexchange.com/questions/649824/plateau-detection-in-time-series-data</link>
      <description><![CDATA[我正在尝试构建一个模型，该模型可以实时检测数据中正在发生的稳定期。我正在查看的数据来自深度传感器，该传感器显示管道中水的深度随时间的变化，并实时更新。有多个管道，每个管道都有自己的数据。当管道中流入的水太多，或者有东西阻碍水流出管道时，就会出现稳定期。我对时间序列不太熟悉，所以我很难创建一个可以很好地预测这种情况的模型。我尝试过简单的时间序列解决方案，如 z 分数、滚动平均值和滚动标准差，但它们实际上只告诉我数据何时高于正常值，而不是稳定期。我只想在深度大于管道直径时检查稳定期，这很容易设置。我也很难准确定义什么是稳定期。我主要使用 2 月初的数据，因为有一场暴风雨在数据中造成了稳定期，但很难区分高水平和实际稳定期之间的区别。以下是水深超过直径的一些示例，如红线所示。


最后一张图片显示了一周的正常数据。我应该使用什么模型来检测这些数据中的稳定期？任何帮助都值得感激，如果需要，我可以澄清任何事情。]]></description>
      <guid>https://stats.stackexchange.com/questions/649824/plateau-detection-in-time-series-data</guid>
      <pubDate>Mon, 24 Jun 2024 18:11:47 GMT</pubDate>
    </item>
    <item>
      <title>PLS 方向最大化 Corr(Y, Xa)^2Var(Xa)</title>
      <link>https://stats.stackexchange.com/questions/649823/pls-directions-maximize-corry-xa2varxa</link>
      <description><![CDATA[ESL 练习 3.15 要求我们证明第 m 个 PLS 方向可解：

maxα Corr(y, Xα)^2Var(Xα)
subject to ||α|| = 1, αT Sϕˆℓ = 0, ℓ = 1, . . . , m − 1.

有人能帮我证明为什么会这样吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649823/pls-directions-maximize-corry-xa2varxa</guid>
      <pubDate>Mon, 24 Jun 2024 18:06:08 GMT</pubDate>
    </item>
    <item>
      <title>每个 ID 有多个案例 - 数据管理</title>
      <link>https://stats.stackexchange.com/questions/649822/multiple-cases-per-id-data-management</link>
      <description><![CDATA[我有一个大型数据集，每个参与者 ID 有多个案例。这些是应用程序上的用户。
我有一个变量，它是分配给每个参与者的唯一 ID，还有一个变量，它是代表应用程序上的新医疗保健请求的唯一 ID。因此，每个参与者可能有一个或多个案例，具体取决于他们的请求数量。
如何选择案例以便只选择第一个请求？我想根据参与者总数而不是案例总数来运行频率。目前，没有单独的变量来表示每个“请求”（即 1、2、3..），所以我无法在 SPSS 上选择案例。]]></description>
      <guid>https://stats.stackexchange.com/questions/649822/multiple-cases-per-id-data-management</guid>
      <pubDate>Mon, 24 Jun 2024 17:42:11 GMT</pubDate>
    </item>
    <item>
      <title>在弹性网络中，λ1 和 λ2 的边界曲线至少为 0 分量，这是什么？</title>
      <link>https://stats.stackexchange.com/questions/649818/what-is-the-boundary-curve-for-%ce%bb1-and-%ce%bb2-that-give-at-least-a-0-component-in-ela</link>
      <description><![CDATA[定义弹性净估计：
$
\hat{\beta}^{\lambda, \alpha} = \arg \min_{\beta \in \mathbb{R}^p} \left( \frac{1}{2n} \| y - X\beta \|_2^2 + \lambda \left( (1 - \alpha) \frac{1}{2} \|\beta \|_2^2 + \alpha \|\beta \|_1 \right) \right)
$
我们知道，对于$\lambda \geq \frac{1}{n} \|X^T y\|_\infty$，套索估计$\hat{\beta}^\lambda = 0$。这意味着 $\lambda_{\max} = \frac{1}{n} \|X^T y\|_\infty$，其中 $\lambda_{\max} = \sup_{\hat{\beta}^\lambda \neq 0} \lambda$，如以下帖子所示：套索线性回归中有多少个零？，在 lasso 中，产生 0 分量的最小 $\lambda$ 是多少？。
请注意，$\lambda_{\max}$ 是 $\hat{\beta}^\lambda$ 的任何分量最初为零的值。
对于弹性网络，$\lambda$ 的闭式解是否能够使 $\hat{\beta}^{\lambda, \alpha}$ 的任何分量最初为零？是否有任何针对 $\lambda$ 的闭式解，可导致完全稀疏和非稀疏模型？

这应该可以在 Stack Overflow 上正确呈现。]]></description>
      <guid>https://stats.stackexchange.com/questions/649818/what-is-the-boundary-curve-for-%ce%bb1-and-%ce%bb2-that-give-at-least-a-0-component-in-ela</guid>
      <pubDate>Mon, 24 Jun 2024 15:20:14 GMT</pubDate>
    </item>
    <item>
      <title>在实践中（SGD 的收敛），我们多久会得到一次目标函数的 Lipschitz 连续梯度？</title>
      <link>https://stats.stackexchange.com/questions/649817/how-often-do-we-have-lipschitz-continuous-gradients-for-the-objective-function-i</link>
      <description><![CDATA[当我看到随机梯度下降收敛的证明时，通常假设目标函数是 L 平滑的（具有常数 L 的 Lipschitz 连续梯度）。这在实践中是一个合理的假设吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649817/how-often-do-we-have-lipschitz-continuous-gradients-for-the-objective-function-i</guid>
      <pubDate>Mon, 24 Jun 2024 15:07:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 stpm2 函数计算 R 中灵活参数竞争风险模型的线性预测因子和风险评分[关闭]</title>
      <link>https://stats.stackexchange.com/questions/649816/calculating-linear-predictor-and-risk-score-for-a-flexible-parametric-competing</link>
      <description><![CDATA[我正在使用 r 中的 stpm2 函数在 R 中开发一个灵活的参数模型，但我不确定在开发模型后如何计算线性预测器以及数据集中每个个体的风险评分
以下是用于开发竞争风险模型的示例数据集和代码
数据
n &lt;- 500
data &lt;- data.frame(
time = rexp(n, rate = 0.1),
status = sample(0:2, n, replace = TRUE),
age = rnorm(n, mean = 50, sd = 10),
sex = sample(0:1, n, replace = TRUE),
bmi = rnorm(n, mean = 28, sd=5)
)


以下是开发的代码模型
library(rstpm2)

fitted_model &lt;- stpm2(Surv(time, status == 1) ~ age + bmi + sex, data = dataset_name)


我想计算模型中的线性预测因子以及每个人 2 年和 5 年的风险分数。通常，生存模型的风险分数计算如下，例如 2 年；
risk_score_at_2yrs = (1-(S2^exp(linear_predictor)))

#其中 S2 是 2 年的基线生存率


我无法计算线性预测因子、基线生存率，因此无法计算使用 R(model) 中的 stpm2 函数开发的竞争风险模型的风险分数]]></description>
      <guid>https://stats.stackexchange.com/questions/649816/calculating-linear-predictor-and-risk-score-for-a-flexible-parametric-competing</guid>
      <pubDate>Mon, 24 Jun 2024 15:04:26 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的国家年份虚拟变量[关闭]</title>
      <link>https://stats.stackexchange.com/questions/649814/country-year-dummies-in-python</link>
      <description><![CDATA[我目前正在使用 linearmodels 6.0 包进行计量经济学分析。我使用 EntityEffects 和 TimeEffects 包含了区域和时间固定效应，我想知道如何包含国家*年份虚拟变量之类的东西，以及这个变量和固定效应之间的相互作用是什么。
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/649814/country-year-dummies-in-python</guid>
      <pubDate>Mon, 24 Jun 2024 14:46:13 GMT</pubDate>
    </item>
    <item>
      <title>当数据已经标准化时，如何近似相关矩阵的特征分解？</title>
      <link>https://stats.stackexchange.com/questions/649813/how-to-approximate-the-eigendecomposition-of-a-correlation-matrix-when-the-data</link>
      <description><![CDATA[上下文
我正在努力开发一个惩罚回归框架，该框架将扩展到分析具有特定相关结构的高维数据。让$X$表示一个$n \times p$数据矩阵 - 行是观察值，列是特征。为了适应$X$的特征通常处于不同尺度的事实，我将$X$的列居中并缩放以获得$\dot X$。我正在研究的模型需要对相关矩阵$K = \frac{1}{p} \dot X \dot X^\top$进行特征分解，因此我取$\text{eigen}(K) = USU^\top$，并在后续转换中使用$U$和$S$。
当前问题
与当前问题相关：我想进行交叉验证 (CV)，以便为我的模型选择一个调整参数（例如，套索模型的调整参数$\lambda$）。为了确保 CV 实现代表建模过程的每个步骤，我需要在每一折中标准化训练数据 $X^*$。但是，我想避免在每一折中构建 $K^*$ 并采用 $\text{eigen}(K^*)$，因为这会非常昂贵（从计算角度而言）。我想要的是一种相对便宜的方法来近似$U^*, S^*$，即标准化训练数据的相关矩阵的特征向量/特征值。
示例
CV 之前的# --------------------------
n &lt;- 5
p &lt;- 10

X &lt;- matrix(rnorm(n*p), n, p)
std_X &lt;- scale(X)
K &lt;- tcrossprod(std_X)/p # 相关矩阵 
eigen_K &lt;- eigen(K)
U &lt;- eigen_K$vectors
S &lt;- diag(eigen_K$values)

CV 中的# -------------------------------
train &lt;- sample(n, 3) # 训练数据中观测值的索引 
train_X &lt;- std_X[train,] # 折叠子集 
std_train_X &lt;- scale(train_X) # 重新标准化以反映完整模型程序

# 真实分解（我需要的）
star_K &lt;- tcrossprod(std_train_X)/ncol(train_X)
star_eigen_K &lt;- eigen(star_K) # eigen = 昂贵！
star_U &lt;- star_eigen_K$vectors 
star_S &lt;- star_eigen_K$values

# CV subset 
train_U &lt;- U[train,]
train_K &lt;- tcrossprod(train_X)/ncol(train_X)

# ... 但 train_U 和 S 并不代表 star_K 的分解。

有没有办法避免在每次折叠中构建和分解 star_K？具体来说，如何（如果有的话）从训练数据、现有的分解$U, S$以及用于将train_X标准化为std_train_X的中心/缩放值来近似star_U？]]></description>
      <guid>https://stats.stackexchange.com/questions/649813/how-to-approximate-the-eigendecomposition-of-a-correlation-matrix-when-the-data</guid>
      <pubDate>Mon, 24 Jun 2024 14:44:45 GMT</pubDate>
    </item>
    <item>
      <title>去聚类影响、平稳性和离散化</title>
      <link>https://stats.stackexchange.com/questions/649812/declustering-impact-stationarity-and-discretization</link>
      <description><![CDATA[我有一个季节性时间序列，我正在考虑使用运行去聚类对其进行去聚类（在任何其他预处理步骤之前）。如果我观察到极值指数为 1，我可以声称我的数据是 i.i.d.，因此是平稳的吗？这是否允许我避免事先使用非平稳方法？此外，我很好奇运行去聚类时间序列是否类似于离散化，因为我不确定我的去聚类分布是否仍然属于最大吸引域。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/649812/declustering-impact-stationarity-and-discretization</guid>
      <pubDate>Mon, 24 Jun 2024 14:33:04 GMT</pubDate>
    </item>
    <item>
      <title>如何从已组合成多个箱的样本值集合中找到未知 PDF 的平均值和 SE？[重复]</title>
      <link>https://stats.stackexchange.com/questions/649809/how-to-find-the-average-and-se-of-a-un-unknown-pdf-from-a-set-on-sample-values-a</link>
      <description><![CDATA[我有以下数据：

我想知道生成该数据的原始 PDF 的平均值和 SE。作为初步估计，我假设其服从正态分布。
你能帮我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649809/how-to-find-the-average-and-se-of-a-un-unknown-pdf-from-a-set-on-sample-values-a</guid>
      <pubDate>Mon, 24 Jun 2024 13:41:15 GMT</pubDate>
    </item>
    <item>
      <title>$f(a) = EX^{1+a}EX^{-(1+a)}$ 是非减的吗？</title>
      <link>https://stats.stackexchange.com/questions/649797/is-fa-ex1aex-1a-non-decreasing</link>
      <description><![CDATA[$X$ 是一个非负随机变量，$a$ 是一个非负实数。定义
$$f(a)= EX^{1+a}EX^{-(1+a)}.$$
$f(a)$ 是否非递减，且 $a$ 是递减的吗？
原始问题：当我阅读一篇论文时，我遇到了一个未经证实的不等式
$$\frac{\sum_{m=0}^{T-1}E_m^{1+\delta/2}\sum_{m=0}^{T-1}1/E_m^{1+\delta/2}}{T^2}\leq \frac{\sum_{m=0}^{T-1}E_m^{1+\delta_3}\sum_{m=0}^{T-1}1/E_m^{1+\delta_3}}{T^2}
$$
由于 $\delta &lt; \delta_3$。这里 $E_m$ 是非减实数，而 $T$ 是某个正整数。我想证明这个结果的更强版本，但我失败了。我想知道我的猜想是否正确？或者有任何反例吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649797/is-fa-ex1aex-1a-non-decreasing</guid>
      <pubDate>Mon, 24 Jun 2024 12:18:03 GMT</pubDate>
    </item>
    <item>
      <title>是否有一个有意义的选项可以计算格兰杰因果关系的效应大小？</title>
      <link>https://stats.stackexchange.com/questions/649791/is-there-a-meaningful-option-to-compute-something-like-an-effect-size-for-grange</link>
      <description><![CDATA[我正在使用 statsmodels.tsa.stattools.grangercausalitytests 在多个时间序列对之间运行 Granger 因果关系 (GC) 分析。
用于 GC 分析的时间序列对都具有相同长度的 n = 720 个数据点，并且它们都使用相同类型的测量。
因此，我获得了时间序列 A) 与时间序列 B) 的 GC 统计数据，时间序列 B) 与时间序列 C) 的 GC 统计数据，依此类推。这些 GC 对产生不同的 p 值，例如在基于 SSR 的卡方检验中。
这是我的问题：我无法使用一对中比另一对中更低的 p 值来推断 GC 在第一对中的效应比在第二对中更高（或更强）。这是因为 p 值主要考虑估计精度，因此弱关系仍然可以产生较低的 p 值。
但是让我们假设一个 GC 对产生的 p 值为 0.005，而另一个 GC 对产生的 p 值为 0.1，在基于 SSR 的卡方检验中。有没有办法进一步证明第一种情况下的 GC 效应高于第二种情况？
在不深入讨论我的分析的所有理论细节的情况下，在我的案例中，“p 值的层次结构”在 GC 对或比较中，结果反映了我理论上的预期。这意味着应该表现出高效应大小的 GC 对也会产生比我预期效应大小较小的 GC 对更低的 p 值。
但我不能使用 p 值来统计地支持我的理论推论，这是我的问题。因此，我正在寻找一种附加组件或额外的方法来以某种方式阐明我的观点。
编辑：我决定在我的问题中添加更多信息。我的主要目的是统计（定量）比较在两个 GC 实例之间的 GC 效应，而不是在一个 GC 对内（即使后者可能是必要的并且允许进行比较）。为了进一步阐明我的意思：想象一下在时间序列 A 和时间序列 B 之间运行 GC，在时间序列 C 和时间序列 D 之间运行另一个 GC 实例。
我要问的问题是，第一次 GC 比较中的效果大小是否高于第二次 GC 比较中的效果大小。
据我现在理解，我可以将只有一个时间序列的无限制 VAR 的 RMSE 与有两个时间序列的 VAR 进行比较。然后，我预计无限制 VAR 中的 RMSE 会更高。
问题：考虑到我上面解释的目标，我是否会比较无限制和标准 VAR RMSE 值之间的差异？更准确地说，我会像刚才所说的那样，先计算没有预测因子时间序列 B 的时间序列 A 的 RMSE，然后再计算有预测因子 B 的时间序列 B 的 RMSE。然后，我可以计算两个 RMSE 值之间的差异。
最后，也是最重要的，我可以对时间序列 C 和 D 重复相同的过程。同样，我在这里获得了 RMSE 的差异，在理想情况下，我预计时间序列 A 和 B 产生的“差异 RMSE”之间的差异低于或高于时间序列 C 和 D 产生的“差异 RMSE”。
例如，我预计“差异 RMSE”如果时间序列 A 和 B 的 GC p 值低于时间序列 C 和 D，则时间序列 A 和 B 的 GC p 值会低得多，而时间序列 C 和 D 的 GC p 值会更高，因此 RMSE 差异也会更高（在它们的受限和标准 VAR 之间）。
我希望这一切听起来不会太令人困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/649791/is-there-a-meaningful-option-to-compute-something-like-an-effect-size-for-grange</guid>
      <pubDate>Mon, 24 Jun 2024 11:10:13 GMT</pubDate>
    </item>
    <item>
      <title>基于多重样本回归的总体参数估计</title>
      <link>https://stats.stackexchange.com/questions/649790/estimation-of-population-parameters-on-the-basis-of-multiple-samples-regressions</link>
      <description><![CDATA[我正在研究大约 100 万个受试者的群体，我对他们的支出 (expend) 进行了重复测量。
我的目标是评估 2 个变量（假设 A 和 B）与支出金额之间的联系。鉴于数据的纵向性质和混杂因素的存在，我无法直接估计这些关联。因此，我承诺使用 R 和 lme4 库进行混合建模。这是我们感兴趣部分的代码。
 glmer(expend ~ A*B + (1|ID), family = Gamma(link = &quot;log&quot;), data = data)
考虑到人口规模，对所有数据进行这种回归显然是不可行的。因此，我承诺使用从总体中抽取的随机样本反复重复此回归模型。
最后，我得到了一个包含 5,000 个模型的样本，显然我有这些模型的参数及其方差的估计量。
我想，仅使用固定效应获得的估计量的分布可以让我估计与它们相关的标准误差，但我更感兴趣的是估计它们在初始总体中的分布，从而获得它们在这个总体中的标准差。
为此，我遵循了以下步骤并使用以下符号：
$ N $ 样本数/回归
$ n_{Ai} $ 样本 i 中具有特征 A 的观测值数量和 $ n_{\overline{A}i} $ 没有特征 A 的观测值数量
$ \beta_{Ai} $ 回归 i 的参数 A 的估计量
1 ：将获得的回归参数居中：$ \beta_{Ai}&#39; = \beta_{Ai} - \frac{\sum{\beta_{Ai}}}{n} $
2 ：乘以每个回归中隐含的观测值均方数：$ \beta_{Ai}&#39;&#39; = \beta_{Ai}&#39; \times \frac{\sum{(\sqrt{n_{Ai}}/2}+\sqrt{n_{\overline{A}i}}/2)}{n} $
3：重新定位参数：$ \beta_{Ai}&#39;&#39;&#39; = \beta_{Ai}&#39;&#39; + \frac{\sum{\beta_{Ai}}}{n} $
4：根据$\beta_{Ai}&#39;&#39;&#39;$的分布估计总体中参数的标准差
为了测试这种方法，我使用已知参数的分布进行了模拟。结果表明，通过我刚刚描述的程序获得的方差总是略微高估了源分布的方差。
如果您能帮助我更好地理解这个问题，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/649790/estimation-of-population-parameters-on-the-basis-of-multiple-samples-regressions</guid>
      <pubDate>Mon, 24 Jun 2024 10:59:26 GMT</pubDate>
    </item>
    <item>
      <title>最小二乘法中协方差矩阵贝叶斯推导的误差</title>
      <link>https://stats.stackexchange.com/questions/649786/error-in-bayesian-derivation-of-covariance-matrix-in-least-squares</link>
      <description><![CDATA[我知道这个问题的变体已经被问过一百万次了，但我不只是问“我如何推导协方差矩阵”，而是请你检查我计算中的错误，因为我被难住了……
我有最小二乘问题
$$\min_p \frac{1}{2}\lVert r(p)\rVert^2,$$
其中$r(p) = W(y-f(p))$是我的残差向量。这里 $y\in \mathbb{R}^{N_y}$ 是观测向量，$f(p)$ 是向量值模型函数，$p \in \mathbb{R}^{N_p}$ 是参数。权重矩阵为 $W=\text{diag}(1/\sigma_1,...,1/\sigma_{N_y})$，其中 $\sigma_j$ 为索引 $j$ 处数据的标准差。
我想做的是推导出 此表达式，用于最佳拟合参数 $p^\dagger$ 的协方差矩阵：
$$C_p = \sigma^2 (J^T J)^{-1}$$
其中 $J$ 是 $r$ 的雅可比矩阵，而 $\sigma^2$ 是
$$\sigma^2 = \frac{\lVert r(p^\dagger)\rVert^2}{N_y-N_p}$$
我尝试的方法
我尝试采用贝叶斯方法，其中最小二乘最小化是从均匀先验下给定观测值的参数的最大后验估计中得出的。我将略过这部分，因为这些都是众所周知的。我很乐意提供澄清。此外，如果我在这里掩盖了错误，我也很高兴。
假设所有$y_i$、$y_j$统计独立，我应该能够将后验写为：
$$P(p|y) = K \exp\left(-\frac{1}{2} \sum_j \frac{(y_j-f_j(p))^2}{\sigma_j^2} \right) = K \exp\left( -\frac{1}{2} \lVert r(p) \rVert^2 \right) = K \exp(-g(p)),$$
其中$K$是积分常数，对于简单来说，我这样写：
$$g(p) := \frac{1}{2} \lVert r(p) \rVert^2$$
然后，我使用 I 泰勒展开式对 $g(p)$ 进行最佳拟合参数 $p^\dagger$ 进行展开，即
$$g(p) \approx g(p^\dagger) + \nabla g(p^\dagger)(p-p^\dagger) + (p-p^\dagger)^T H(p^\dagger) (p-p^\dagger) = g(p^\dagger) + \frac{1}{2}(p-p^\dagger)^T H(p^\dagger) (p-p^\dagger),$$
其中 $H(p^\dagger)$ 是 $r(p)$ 的 Hessian 矩阵，在 $p^\dagger$ 处求值，我利用了梯度在 $p^\dagger$ 处消失的事实（有关公式，请参阅 此处第 3 页）。
现在我可以近似后验as
$$P(p|y) = K^\prime \exp\left( -\frac{1}{2}(p-p^\dagger)^T H(p^\dagger) (p-p^\dagger) \right),$$
其中我已将进一步的常数因子吸收到 $K^\prime$ 中。在我看来，这是一个 多元正态分布，其协方差矩阵为 $H(p^\dagger)^{-1}$。现在我知道我们经常用最小二乘近似法将 Hessian 近似为 $H=J^TJ$，这样我就可以得到协方差矩阵：
$$C_p = (J^T J)^{-1}$$
与我想要导出的表达式相比，这个表达式缺少 $\sigma^2$，我不知道我的逻辑哪里有缺陷。我感谢所有的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/649786/error-in-bayesian-derivation-of-covariance-matrix-in-least-squares</guid>
      <pubDate>Mon, 24 Jun 2024 09:16:27 GMT</pubDate>
    </item>
    <item>
      <title>如何实际使用 BCa 引导区间的经验影响函数？</title>
      <link>https://stats.stackexchange.com/questions/649776/how-to-actually-use-the-empirical-influence-function-for-bca-bootstrap-intervals</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/649776/how-to-actually-use-the-empirical-influence-function-for-bca-bootstrap-intervals</guid>
      <pubDate>Mon, 24 Jun 2024 03:28:34 GMT</pubDate>
    </item>
    </channel>
</rss>