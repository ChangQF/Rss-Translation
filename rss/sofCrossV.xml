<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 16 Dec 2024 18:25:11 GMT</lastBuildDate>
    <item>
      <title>是否可以对使用非概率抽样收集的加权数据进行统计显著性检验方法？</title>
      <link>https://stats.stackexchange.com/questions/658822/can-statistical-significance-testing-methods-be-carried-out-on-weighted-data-tha</link>
      <description><![CDATA[我正在分析使用非概率抽样方法收集的调查数据集。此数据集还包括一个权重字段，允许将调查结果推断到更广泛的人群。
鉴于此权重数据的存在，我是否能够使用传统的统计显着性检验方法，如卡方检验和 t 检验？（我将使用 R 的 survey 和 srvyr 包或 Python 的 samplics 包将权重值合并到我的代码中。或者这些测试是否仍然无效，因为原始数据不是从随机样本中收集的？（如果是这样，我们将非常感激与非概率抽样方法兼容的替代测试的建议。）]]></description>
      <guid>https://stats.stackexchange.com/questions/658822/can-statistical-significance-testing-methods-be-carried-out-on-weighted-data-tha</guid>
      <pubDate>Mon, 16 Dec 2024 17:39:03 GMT</pubDate>
    </item>
    <item>
      <title>在机器/深度学习中，什么才算是“低级”或“高级”特征？</title>
      <link>https://stats.stackexchange.com/questions/658819/what-qualifies-as-low-level-or-high-level-feature-in-machine-deep-learning</link>
      <description><![CDATA[在讨论 CNN 时，通常会出现术语“低级”和“高级”特征。例如：（摘自R 中的统计学习应用简介）

网络首先识别输入图像中的低级特征，
例如小边缘、色块等。然后，将这些低级
特征组合起来形成更高级的特征，例如
耳朵、眼睛等的部分。最终，这些更高级特征的存在或不存在会影响任何给定输出类的概率。

为什么“眼睛”与边缘相比，哪些特征被视为“高级”特征（即更“抽象”的特征）？
在深度学习或机器学习中，对于什么是“低级”特征和“高级”特征，是否存在共识？]]></description>
      <guid>https://stats.stackexchange.com/questions/658819/what-qualifies-as-low-level-or-high-level-feature-in-machine-deep-learning</guid>
      <pubDate>Mon, 16 Dec 2024 17:07:32 GMT</pubDate>
    </item>
    <item>
      <title>多元分布函数示例[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658818/multivariate-distribution-function-examples</link>
      <description><![CDATA[我正在寻找多元分布的累积分布函数 (CDF) 的示例。我在网上搜索过但没有找到。有人能给我提供一些示例吗？我正在寻找一些 $k-$ 维 CDF。]]></description>
      <guid>https://stats.stackexchange.com/questions/658818/multivariate-distribution-function-examples</guid>
      <pubDate>Mon, 16 Dec 2024 16:59:45 GMT</pubDate>
    </item>
    <item>
      <title>统计调查。过度分散问题或大量 0</title>
      <link>https://stats.stackexchange.com/questions/658816/statistical-inquiry-overdispersion-issue-or-abundance-of-0s</link>
      <description><![CDATA[尝试查看一些数据，其中一半存在缺失，而另一半是计数数据。我最近一直在研究的模型是 lmer 和 glmer.nb 的混合，因为这似乎是计数数据的方法。下面是我正在研究的 SEM 的摘要，但它都是 lmer，但我希望其中与 F 相对应的部分是 glmer.nm，或者我应该使用 glmmTMB？整个东西必须是 glmer.nb 或 glmmTMB 吗？我想将另外两个变量添加到模型中，它们是计数数据，但如果我这样做，我会因为过度分散而收到很多警告或错误。 。有一个关于缩放预测变量的警告，但如果我缩放它，它会产生一些负值，我无法使用，这可能是数据集中 0 的结果。看起来卡方和 fishers 的优度对当前这个来说很好，但我想尝试在其中添加另外 2 个东西（我知道 F 是计数数据，可能应该以不同的方式出现在模型中）。这有点太多了吗？有什么建议吗？
df &lt;- psem(
lmer(B ~ N + A + F + (1 | site), data = d8),
#lmer(A ~ F + (1 | site), data = d8),
lmer(A ~ F +(1 | site), data = d8),
lmer(T ~ F + A + (1|site), data = d8),
lmer(S ~ B + F + (1|site), data = d8),
lmer(D ~ A + T + (1|site),data = d8),
lmer(A ~ N + (1|site), data = d8),
lmer(C ~ F + T + S + (1|site), data = d8)
)
df 的结构方程模型
调用：
B ~ N + A + F
A ~ F
T ~ F + A
S ~ B + A
D ~ F + T
F ~ N
C ~ A + T + S
AIC

1852.841

定向分离测试：
 独立声明 测试类型 DF 临界值 P 值 
T ~ N + ... 系数 42.0055 0.1793 0.6741 
S ~ N + ... 系数 37.8295 1.5885 0.2153 
D ~ N + ... 系数 55.9602 1.1410 0.2900 
C ~ N + ... 系数 31.7632 1.5056 0.2288 
A ~ N + ... 系数 46.8297 2.6263 0.1118 
T ~ B + ... 系数 28.2731 0.5232 0.4754 
D ~ B + ... 系数 35.3531 0.0203 0.8875 

C ~ B + ... 系数 29.7178 0.9221 0.3447
S ~ T + ... 系数 46.8141 1.5520 0.2190
D ~ S + ... 系数 54.9386 0.3143 0.5773
A ~ S + ... 系数 55.9466 5.2821 0.0253 *
C ~ D + ... 系数 33.4871 0.0050 0.9442
A ~ D + ... 系数48.2623 0.3947 0.5328
A ~ C + ... 系数 52.9124 0.0062 0.9375
--
整体拟合优度：
卡方 = 11.829，P 值 = 0.893，自由度为 19
Fisher C = 30.515，P 值 = 0.339，自由度为 28

系数：
 响应 预测 估计 标准误差 DF 临界值 P 值 标准估计 
B N 9.7176 1.0037 46.0216 91.5297 0.0000 0.9343 ***
B A -0.1836 0.0421 43.7463 18.7062 0.0001 -0.3859 ***
B F 0.0020 0.0005 41.9443 16.0755 0.0002 0.3260 ***
A F 0.0060 0.0013 53.6423 21.5820 0.0000 0.4709 ***
T F -0.0018 0.0006 56.5517 8.6751 0.0047 -0.4254 **
T A 0.1209 0.0506 48.7150 5.2512 0.0263 0.3557 *
S B 0.1892 0.0449 55.4474 16.8407 0.0001 0.4623 ***
S F -0.0009 0.0002 50.4275 14.3701 0.0004 -0.3607 ***
D F 0.0007 0.0003 50.4177 6.9658 0.0110 0.2295 *
D T 0.2084 0.0660 51.4101 9.5847 0.0032 0.2801 **
F N -701.2503 250.3729 49.6386 7.1996 0.0099 -0.4094 **
C A 0.0007 0.0006 48.6534 1.2172 0.2753 0.1311 
C T 0.6899 0.1468 50.4268 20.1428 0.0000 0.5521 ***
C S -0.5645 0.2596 40.3871 4.3953 0.0423 -0.2589 *

显著性。代码：0 &#39;&#39; 0.001 &#39;&#39; 0.01 &#39;&#39; 0.05

个人 R 平方：
 响应方法 边际 条件
B 无 0.30 0.95
B 无 0.22 0.66
T 无 0.15 0.40
S 无 0.24 0.77
D 无 0.13 0.76
A 无 0.14 0.51
C 无 0.32 0.49
]]></description>
      <guid>https://stats.stackexchange.com/questions/658816/statistical-inquiry-overdispersion-issue-or-abundance-of-0s</guid>
      <pubDate>Mon, 16 Dec 2024 16:36:48 GMT</pubDate>
    </item>
    <item>
      <title>条件多元正态分布的 Cholesky 因式分解</title>
      <link>https://stats.stackexchange.com/questions/658815/cholesky-factorization-of-a-conditional-multivariate-normal-distribution</link>
      <description><![CDATA[令 $X$ 为具有多元正态分布的随机向量：$X\sim \mathcal{N}(\mu,\Sigma)$。
让 $L$ 成为 $\Sigma$ 的 Cholesky 因式分解：$\Sigma = LL&#39;$，这样我们就可以写出
$$X=L X_0 +\mu,$$
其中 $X_0\sim \mathcal{N}(0,I)$。
如果我们将 $X$ 拆分为两个向量 $X=(X_1,X_2)$，我们知道
$$X_1|X_2\sim\mathcal{N}(\mu_{1|2},\Sigma_{1|2}),$$
其中 $\mu_{1|2}=\mu_1 + \Sigma_{12}\Sigma_{22}^{-1}(X_2-\mu_2)$ 和 $\Sigma_{1|2}=\Sigma_{11}-\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}$，
其中 $\mu=(\mu_1,\mu_2)$ 和 $\Sigma_{1/2,1/2}$ 对应于 $\Sigma$。
是否有一个公式可以直接从 $L$ 或 $L$ 的一些子矩阵获得 $\Sigma_{1|2}$ 的 Cholesky 因式分解？
我问这个问题是因为我想从 $L$ 模拟条件分布 $X_1|X_2$，同时避免计算矩阵的某些逆，例如 $\Sigma_{22}^{-1}$。]]></description>
      <guid>https://stats.stackexchange.com/questions/658815/cholesky-factorization-of-a-conditional-multivariate-normal-distribution</guid>
      <pubDate>Mon, 16 Dec 2024 16:14:12 GMT</pubDate>
    </item>
    <item>
      <title>在深度学习图像分割中：为 N 个类别训练 N 个模型是否比为 N 个类别训练一个模型更好</title>
      <link>https://stats.stackexchange.com/questions/658814/in-deep-learning-image-segmentation-is-it-better-to-train-n-models-for-n-class</link>
      <description><![CDATA[我想知道您是否有任何最近的出版物参考资料或有关“为 N 个类别训练 N 个模型还是为 N 个类别训练一个模型更好”问题的经验？
我知道这取决于主干、数据类型等......但我找不到有关这个问题的任何最新、可靠和稳健（论文类型）的内容。
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658814/in-deep-learning-image-segmentation-is-it-better-to-train-n-models-for-n-class</guid>
      <pubDate>Mon, 16 Dec 2024 15:42:59 GMT</pubDate>
    </item>
    <item>
      <title>使用 SMOTEENN 后数据不平衡 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658812/imbalanced-data-after-using-smoteenn</link>
      <description><![CDATA[我正在研究分类问题，我的初始数据不平衡。我使用 SMOTE + ENN 算法来修改数据。应用 SMOTE 后，数据变得平衡，但应用 ENN 后，数据再次变得不平衡。我该怎么办？
我知道 ENN 用于删除异常数据点，但我不知道在 SMOTE 之后是否应该使用 ENN]]></description>
      <guid>https://stats.stackexchange.com/questions/658812/imbalanced-data-after-using-smoteenn</guid>
      <pubDate>Mon, 16 Dec 2024 14:43:56 GMT</pubDate>
    </item>
    <item>
      <title>AB 测试中是否应使用重采样？[重复]</title>
      <link>https://stats.stackexchange.com/questions/658810/should-resampling-be-used-in-an-ab-test</link>
      <description><![CDATA[我有 14,000 个用户的样本，其中 7,000 个为对照组，7,000 个为实验组。所讨论的指标是数值。两个组都呈伯努利分布的右偏态。
虽然一种可能的解决方案是使用 t 检验替代方案，但由于非正态性，这是一个下游决策，因此从程序上讲，执行重新采样的决定应该在决定使用哪种测试之前进行。我将完全忽略要使用的测试类型。
相反，这个问题涉及是否执行重新采样的初步经验法则。是否应该将重新采样应用于此 AB 测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/658810/should-resampling-be-used-in-an-ab-test</guid>
      <pubDate>Mon, 16 Dec 2024 13:05:14 GMT</pubDate>
    </item>
    <item>
      <title>Cox 回归假设</title>
      <link>https://stats.stackexchange.com/questions/658802/cox-regression-assumptions</link>
      <description><![CDATA[我正在分析血浆生物标志物与疾病发病率之间的关联，这些关联是通过年度问卷自我报告的。总样本量为 824，其中 65 人报告了至少一个事件（我不考虑多个事件）。除了事件发生之外，所有其他变量都是在基线测量的。我会使用 Cox 比例风险回归模型，但我不熟悉这个模型，并且对我获得的假设图感到很困惑。
我的完全调整模型如下所示：
assumpt.cox &lt;- coxph(Surv(time, event) ~ contvar1 + 
contvar2 + catvar1 + catvar2 + 
catvar3 + contvar3 + catvar4 + contvar4 + contvar5, data = data_assumpt.cox)

其中 contvar 是连续变量，catvar 是分类变量。我主要关注的是 contvar1。
我检查了 PH 假设，它没有表明违反（所有变量和全局变量的 p&gt;0.05）。
对于有影响的点，我检查了偏差并注意到所有报告事件的参与者都聚集在图表的顶部，而没有报告事件的参与者则聚集在底部。此外，平均偏差不为 0。但我不清楚我应该怎么做。
ggcoxdiagnostics(assumpt.cox, type = &quot;deviance&quot;,
linear.predictions = FALSE, ggtheme = theme_bw()) 


对于线性，我发现了两种主要方法来检查这个假设。

使用空模型：

 ggcox functional(Surv(time, event) ~ contvar1 + I(contvar1)^2 + log(contvar1) + 
sqrt(contvar1), data = data_assumpt.cox)



使用完全调整的模型：

data_assumpt.cox %&gt;% 
ggplot(aes(x=contvar1, y=residuals(assumpt.cox, type=&quot;martingale&quot;))) + 
geom_point() + 
geom_hline(yintercept = 0, color=&quot;blue&quot;) +
geom_smooth(color=&quot;red&quot;) +
theme_bw()



我明白，在第一组图中，我应该看到数据点和残差线之间有很好的相关性，而在第二组图中，红线应该（大部分）在 0 处笔直。但总的来说，它们应该告诉我同样的事情。这是正确的吗，还是应该优先考虑其中一个？
从这些图中，我得出结论，线性假设被违反了。
但如果是这样，我该怎么办，因为转换似乎没有帮助？我也试图排除 contvar1 中的两个极端值（一个有事件，一个没有事件），但效果只略有改善。
抱歉发了这么长的帖子，我希望至少能说清楚。
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658802/cox-regression-assumptions</guid>
      <pubDate>Mon, 16 Dec 2024 09:44:18 GMT</pubDate>
    </item>
    <item>
      <title>在回归模型中意外地两次包含同一个变量？</title>
      <link>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</link>
      <description><![CDATA[我在 R (mgcv) 中有这种混合效应 GAM 回归：
library(mgcv)
gam_beta &lt;- gam( 
y ~ te(time, x1) + te(time, x2) + s(time, by = city) + s(city, bs = &quot;re&quot;), 
data = my_data,
method = &quot;REML&quot;, 
family = betar(link = &quot;logit&quot;)
)

我尝试为该模型编写方程（基于我对 mgcv 中张量积函数 te 的理解 https://www.rdocumentation.org/packages/mgcv/versions/1.9-1/topics/te):
$$ y_{ij} \sim \text{Beta}(\mu_{ij}\phi, (1-\mu_{ij})\phi) $$
$$\mu_{ij} = \frac{1}{1+e^{-\eta_{ij}}}$$
$$ \text{logit}(\mu_{ij}) = \eta_{ij}= \beta_0 + f_{12}(time_{ij}, x1_{ij}) + f_{34}(time_{ij}, x2_{ij}) + h_i(time_{ij}) + b_i $$
我尝试将其进一步扩展：
$$ \eta_{ij} = \underbrace{\sum_{k=1}^{K_1} \hat{\gamma}_{1k}f_{1k}(time_{ij}) + \sum_{l=1}^{L_1} \hat{\gamma}_{2l}g_{1l}(x1_{ij}) + \sum_{k=1}^{K_1}\sum_{l=1}^{L_1} \hat{\gamma}_{3kl}f_{1k}(time_{ij})g_{1l}(x1_{ij})}_{\text{first te(): time and x1 term}} + $$
$$ \underbrace{\sum_{m=1}^{M_1} \hat{\gamma}_{4m}f_{2m}(time_{ij}) + \sum_{n=1}^{N_1} \hat{\gamma}_{5n}g_{2n}(x2_{ij}) + \sum_{m=1}^{M_2}\sum_{n=1}^{N_2} \hat{\gamma}_{6mn}f_{2m}(time_{ij})g_{2n}(x2_{ij})}_{\text{second te(): time and x2 term}} + $$
$$ \underbrace{\sum_{p=1}^P \hat{\alpha}_{ip}h_p(time_{ij})}_{\text{city-specific smooth}} + \underbrace{\hat{b}_i}_{\text{random effect}} $$
我的问题如下：我知道 mgcv 中的 te 函数包含主效应和交互效应 (GAM 回归：交互与主效应？)。但这是否意味着某个术语存在被重复计算并在 GAM 方程中出现两次的风险？
例如，我有 te(time,x1) 和 te(time,x2)。这是因为我想在我的模型中包含与协变量 x1 和 x2 的时间交互。但这是否会导致时间的主效应被包含两次？或者 mgcv 会识别这一点并且只包含一次？]]></description>
      <guid>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</guid>
      <pubDate>Mon, 16 Dec 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>数据分类</title>
      <link>https://stats.stackexchange.com/questions/658795/data-categorization</link>
      <description><![CDATA[我已将我的教育数据集分类以供以下分析。但是，我遇到过一位受访者就读于一所传教学校，我不知道其水平，也不确定将他们放在何处。我应该将他们排除在外吗？我的决定基于什么依据？
教育 是 否 总计
高等教育 22 13 35
中学 144 47 191
小学 103 52 155
未受过教育 23 13 36
]]></description>
      <guid>https://stats.stackexchange.com/questions/658795/data-categorization</guid>
      <pubDate>Mon, 16 Dec 2024 06:47:39 GMT</pubDate>
    </item>
    <item>
      <title>用于 AB 测试的测试类型，非正态分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658765/the-type-of-test-to-use-for-an-ab-test-non-normal-distribution</link>
      <description><![CDATA[在此示例中，假设我想执行 t 检验来确定两组用户之间的差异，其中一组用户看到的是登录页面 A，另一组用户看到的是登录页面 B。我跟踪指标“网站停留时间”。数据看起来不错，但我意识到它不是正态分布。
在将数据输入单向独立样本 t 检验之前，我是否应该使用重采样来规范化这些数据？原因如下：

它实现了正态性，这（至少在视觉上）与我的最终决策标准一致
得到的标准化曲线使假设检验的结果易于理解。即，我的结果是 _ 与我所测试样本的平均值的标准差；这个的 p 值为 p，所以我们接受/拒绝零假设
它只是与我们对问题的解决方案更加一致

反对的理由：

它改变了数据的分布，我不确定这会对我的 AB 测试的“正确性”产生什么影响。
它可能是“过度工程”问题
t 检验可以接受非正态数据，无论 t 检验中仍然使用的正态曲线的视觉效果如何（见下图）。


请注意，我描述的是重新采样，即创建许多平均值的采样分布，而不是简单地采样，即选择随机指标并使用该组作为分布。简而言之，在每个分布上调用 mean() 并将一组均值输入到我的 AB 测试中。
我应该为 AB 测试重新采样吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658765/the-type-of-test-to-use-for-an-ab-test-non-normal-distribution</guid>
      <pubDate>Sun, 15 Dec 2024 16:53:45 GMT</pubDate>
    </item>
    <item>
      <title>使用简单泊松近似泊松混合的有效性</title>
      <link>https://stats.stackexchange.com/questions/658764/validity-of-approximating-a-poisson-mixture-with-a-simple-poisson</link>
      <description><![CDATA[已编辑：
我正在考虑使用一个简单的泊松分布来模拟一个过程，其中事件的瞬时速率（用 $\lambda$ 表示）不是恒定的。相反，$\lambda$ 取决于复杂底层系统的当前状态，该系统具有许多相互作用的因素，这些因素会随着时间的推移而快速变化。
由于系统的复杂性，我正在探索使用简单泊松分布近似该过程的可能性，其中速率参数 $\lambda$ 设置为波动瞬时速率的时间平均值 $\mu_\pi$。我主要关心的是了解$\lambda$的波动时间如何影响此近似值。
虽然我没有底层系统动态的精确模型，但我知道影响$\lambda$的因素在整个过程期间会多次变化，从而提供瞬时速率分布的良好样本。但是，我不确定连续事件之间的这些变化的数量是否也起着至关重要的作用。
具体来说，我感兴趣的是了解连续事件之间$\lambda$波动的频率/速度如何影响简单泊松近似的准确性。如果
$\lambda$ 在整个过程中波动多次（从而提供瞬时速率分布的良好样本，我将其表示为 $\pi$），但连续事件之间的波动次数相对较少，这会影响泊松近似的质量吗？
根据维基百科（链接至混合泊松分布），混合泊松分布的方差由以下公式给出：$\operatorname{Var}(X) = \mu_\pi+\sigma_\pi^2$ 其中 $\mu_\pi$ 和 $\sigma_\pi^{2}$ 分别是 $\pi$ 的均值和方差。根据此公式，只要 $\lambda$ 的波动足够大，可以提供 $\pi$ 的良好样本，人们可能就会预期混合过程的方差接近该理论值，而不管各个事件之间的波动是多是少。但是，我进行了一些数值模拟，似乎表明波动频率对方差也起着重要作用（可能是我的代码中存在一些错误？）。
似乎近似值系统地高估了方差，是否引入了其他偏差？]]></description>
      <guid>https://stats.stackexchange.com/questions/658764/validity-of-approximating-a-poisson-mixture-with-a-simple-poisson</guid>
      <pubDate>Sun, 15 Dec 2024 16:51:48 GMT</pubDate>
    </item>
    <item>
      <title>计算不同大小的文本语料库的卡方</title>
      <link>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</link>
      <description><![CDATA[我偶然发现了一篇论文，它批评了某文本分析软件中用于比较六个大小明显不同的文本语料库中的词频的卡方统计量的计算。该软件采用标准公式：
$$
\chi^2 = \sum_{i=1}^{n} \frac{(O_{i} - E_{i})^2}{E_{i}}
$$
这里，$O_{i}$表示在语料库$i$中观察到的频率，$E_{i}$的计算方法是将一个词在所有六个语料库中的总频率除以所有语料库中的单词总数，然后乘以语料库$i$中的单词数。
本文作者批评了这种方法，陈述：

&quot;运行交叉制表也不能产生有效可靠的评估。 [...] 事实证明，该软件使用非标准化的绝对频率，只有当要比较的文本语料库长度相等时才不会引起问题。&quot;

在这种情况下，作者将$O_{i}$解释为绝对频率，并提出了一种替代的&quot;标准化&quot;过程来计算$O_{i}$和$E_{i}$。这涉及：

选择最小的语料库作为参考。
通过将观察到的所有其他语料库的频率除以各自语料库中的单词总数，然后乘以参考语料库中的单词数，对观察到的所有其他语料库的频率进行归一化。
将预期频率计算为所有语料库（包括参考语料库）的归一化频率之和，除以六（语料库数量）。

问题 1：作者声称该软件使用的公式（如上所述）没有考虑到语料库的各种大小，他是否正确。
问题 2：在这种情况下，这种归一化方法是否适用于卡方计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</guid>
      <pubDate>Sun, 15 Dec 2024 13:37:05 GMT</pubDate>
    </item>
    <item>
      <title>带条件的多元随机正态分布</title>
      <link>https://stats.stackexchange.com/questions/658734/multivariate-random-normal-distribution-with-conditions</link>
      <description><![CDATA[我正在开发一个模拟模型，该模型将作为对实证考古数据进行分类的基础。我正在使用 R 语言，并使用有界版本的 mvrnorm() 来模拟 8 个抛射点（即箭头/矛头）尺寸（最大长度、轴向长度、最大宽度等），并使用从实证数据集得出的相关矩阵。然后，模拟数据将遵循文化传播规则，并投射到 n 代，以模拟不同社会学习场景的影响。大多数文物尺寸都具有显著相关性，并且有几个必须具有特定的关系，才能使我的模拟文物逼真。例如，轴向长度不能大于最大长度，因为它们是相同的。我尝试通过添加需要满足​​的条件（包括上限和下限）来调整 mvrnorm 函数。我尝试在模拟期间进行拒绝抽样，并在模拟后进行调整。然而，在这两种情况下，Gen 1 的结果协方差矩阵与我试图在 Gen 1 中复制的原始协方差矩阵相差甚远。我希望找到一个解决方案：1）导致 Gen 1 相关矩阵非常接近我在经验数据中看到的矩阵；2）导致模拟测量值落入经验数据集设定的范围内（最小和最大观测值）；并且 3) 满足实际工件测量的条件。
下面是我尝试在模拟后调整记录的一个例子，这似乎是所有方法中问题最少的，但仍然导致 Gen 1 中的协方差矩阵明显不同：
adjust_simulated_data &lt;- function(data,traits,mu,Sigma,bounds,
max_iterations = 10) {
n&lt;-nrow(data)
p&lt;-length(traits)

# 定义要检查的条件
check_conditions&lt;-function(row) {
c(
row[&quot;LengthAxial&quot;]&lt;=row[&quot;LengthMax&quot;],
row[&quot;WidthBasal&quot;]&lt;=row[&quot;WidthMax&quot;],
row[&quot;WidthNeck&quot;] &lt;= row[&quot;WidthMax&quot;],
row[&quot;PSA&quot;] &lt;= row[&quot;DSA&quot;]
)
}

# 对违反条件的单个行进行重新采样
for (iteration in 1:max_iterations) {
licences &lt;- logical(n)

# 检查违规
for (i in 1:n) {
row &lt;- data[i, ]
conditions &lt;- check_conditions(row)
if (any(!conditions)) {
licences[i] &lt;- TRUE
}
}

# 如果不存在违规，则退出循环
if (!any(violations)) {
message(&quot;All conditions satisfied after &quot;, iteration, 
&quot; iterations.&quot;)
break
}

# 对违规行进行重新采样
for (i in which(violations)) {
# 保留非特征列
non_trait_columns &lt;- data[i, !(names(data) %in% characters), 
drop = FALSE]

# 使用 mvrnorm_bounded 和原始 param_list 值对特征进行重新采样
resampled_traits &lt;- mvrnorm_bounded(
n = 1,
mu = mu,
Sigma = Sigma,
bounds = bounds
)

# 使用重新采样的特征更新数据行
data[i, characters] &lt;- resampled_traits
data[i, !(names(data) %in% characters)] &lt;- non_trait_columns
}
}

# 如果达到最大迭代次数，则发出警告
if (any(!violations) &amp;&amp; iteration == max_iterations) {
warning(&quot;已达到最大迭代次数；可能仍违反某些约束。&quot;)
}

return(data)
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/658734/multivariate-random-normal-distribution-with-conditions</guid>
      <pubDate>Sun, 15 Dec 2024 04:27:32 GMT</pubDate>
    </item>
    </channel>
</rss>