<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 16 Dec 2024 09:20:30 GMT</lastBuildDate>
    <item>
      <title>多个非独立同分布 beta 素数变量之和</title>
      <link>https://stats.stackexchange.com/questions/658799/the-sum-of-multiple-non-i-i-d-beta-prime-variables</link>
      <description><![CDATA[假设 $X_1$,$X_2$,$X_3$ 是独立同分布的。伽马随机变量，则$\frac{X_1}{X_2}$、$\frac{X_2}{X_3}$、$\frac{X_3}{X_1}$服从 beta 素数分布且相互关联。
那么，$\frac{X_1}{X_2}+\frac{X_2}{X_3}+\frac{X_3}{X_1}$的分布是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658799/the-sum-of-multiple-non-i-i-d-beta-prime-variables</guid>
      <pubDate>Mon, 16 Dec 2024 08:29:57 GMT</pubDate>
    </item>
    <item>
      <title>在回归模型中意外地两次包含同一个变量？</title>
      <link>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</link>
      <description><![CDATA[我在 R (mgcv) 中有这种混合效应 GAM 回归：
library(mgcv)
gam_beta &lt;- gam( 
y ~ te(time, x1) + te(time, x2) + s(time, by = city) + s(city, bs = &quot;re&quot;), 
data = my_data,
method = &quot;REML&quot;, 
family = betar(link = &quot;logit&quot;)
)

我尝试为该模型编写方程（基于我对 mgcv 中张量积函数 te 的理解 https://www.rdocumentation.org/packages/mgcv/versions/1.9-1/topics/te):
$$ y_{ij} \sim \text{Beta}(\mu_{ij}\phi, (1-\mu_{ij})\phi) $$
$$\mu_{ij} = \frac{1}{1+e^{-\eta_{ij}}}$$
$$ \text{logit}(\mu_{ij}) = \eta_{ij}= \beta_0 + f_{12}(time_{ij}, x1_{ij}) + f_{34}(time_{ij}, x2_{ij}) + h_i(time_{ij}) + b_i $$
我尝试将其进一步扩展：
$$ \eta_{ij} = \underbrace{\sum_{k=1}^{K_1} \hat{\gamma}_{1k}f_{1k}(time_{ij}) + \sum_{l=1}^{L_1} \hat{\gamma}_{2l}g_{1l}(x1_{ij}) + \sum_{k=1}^{K_1}\sum_{l=1}^{L_1} \hat{\gamma}_{3kl}f_{1k}(time_{ij})g_{1l}(x1_{ij})}_{\text{first te(): time and x1 term}} + $$
$$ \underbrace{\sum_{m=1}^{M_1} \hat{\gamma}_{4m}f_{2m}(time_{ij}) + \sum_{n=1}^{N_1} \hat{\gamma}_{5n}g_{2n}(x2_{ij}) + \sum_{m=1}^{M_2}\sum_{n=1}^{N_2} \hat{\gamma}_{6mn}f_{2m}(time_{ij})g_{2n}(x2_{ij})}_{\text{second te(): time and x2 term}} + $$
$$ \underbrace{\sum_{p=1}^P \hat{\alpha}_{ip}h_p(time_{ij})}_{\text{city-specific smooth}} + \underbrace{\hat{b}_i}_{\text{random effect}} $$
我的问题如下：我知道 mgcv 中的 te 函数包含主效应和交互效应 (GAM 回归：交互与主效应？)。但这是否意味着某个术语存在被重复计算并在 GAM 方程中出现两次的风险？
例如，我有 te(time,x1) 和 te(time,x2)。这是因为我想在我的模型中包含与协变量 x1 和 x2 的时间交互。但这是否会导致时间的主效应被包含两次？或者 mgcv 会识别这一点并且只包含一次？]]></description>
      <guid>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</guid>
      <pubDate>Mon, 16 Dec 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>数据分类</title>
      <link>https://stats.stackexchange.com/questions/658795/data-categorization</link>
      <description><![CDATA[我已将我的教育数据集分类以供以下分析。但是，我遇到过一位受访者就读于一所传教学校，我不知道其水平，也不确定将他们放在何处。我应该将他们排除在外吗？我的决定基于什么依据？
教育 是 否 总计
高等教育 22 13 35
中学 144 47 191
小学 103 52 155
未受过教育 23 13 36
]]></description>
      <guid>https://stats.stackexchange.com/questions/658795/data-categorization</guid>
      <pubDate>Mon, 16 Dec 2024 06:47:39 GMT</pubDate>
    </item>
    <item>
      <title>需要有共同原因的因果调整公式</title>
      <link>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</link>
      <description><![CDATA[
在上述因果模型中，计算$P(X=x \mid \text{do}(Y=y))$时，是否需要使用因果调整公式$\sum_c P(X=x \mid Y=y, C=c) P(C=c)$？一旦我们$\text{do}(Y=y)$，$Y$的生成过程是否就独立于$X$的生成过程，因此$P(X=x \mid \text{do}(Y=y)) = P(X=x)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</guid>
      <pubDate>Mon, 16 Dec 2024 06:30:13 GMT</pubDate>
    </item>
    <item>
      <title>无线通信中的超几何函数：寻求性能分析的指导</title>
      <link>https://stats.stackexchange.com/questions/658788/hypergeometric-functions-in-wireless-communication-seeking-guidance-for-perform</link>
      <description><![CDATA[我正在从纯数学转向无线通信，对分析 Nakagami-m 衰落信道的数学挑战特别感兴趣。这些信道广泛用于模拟无线环境，中断概率和遍历容量等性能指标通常涉及超几何函数、Meijer G 函数和渐近分析等高级工具。
我一直在阅读有关如何应用这些工具的文章，但仍在努力确定它们背后更深层次的数学结构。
我的核心问题是：
在分析 Nakagami-m 衰落信道的性能指标（例如中断概率、容量）时，尤其是在 RIS 辅助或多天线系统中，关键的数学方法或未解决的问题是什么？
虽然我知道一些标准结果，但我渴望了解该领域是否存在任何未探索的挑战或创新的数学方法。
我需要你的帮助。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658788/hypergeometric-functions-in-wireless-communication-seeking-guidance-for-perform</guid>
      <pubDate>Mon, 16 Dec 2024 01:16:25 GMT</pubDate>
    </item>
    <item>
      <title>我该如何解释成对 Wilcoxon 检验的结果来识别“更好”的组？</title>
      <link>https://stats.stackexchange.com/questions/658785/how-do-i-interpret-pairwise-wilcoxon-test-results-to-identify-the-better-group</link>
      <description><![CDATA[在 Kruskal-Wallis 检验中发现显著结果后，我进行了成对 Wilcoxon 秩和检验。如果存在显著差异，我该如何根据检验结果确定哪组表现更好？我应该依靠中位数还是其他指标来得出结论？]]></description>
      <guid>https://stats.stackexchange.com/questions/658785/how-do-i-interpret-pairwise-wilcoxon-test-results-to-identify-the-better-group</guid>
      <pubDate>Mon, 16 Dec 2024 00:17:21 GMT</pubDate>
    </item>
    <item>
      <title>关于配对样本的一个问题</title>
      <link>https://stats.stackexchange.com/questions/658780/a-question-about-the-paired-samples</link>
      <description><![CDATA[我正在审查几篇医学文章，其中由于缺乏正态性，Wilcoxon 符号秩检验 用于配对样本。但是，结果是基于平均值和标准差以及计算出的 p 值呈现的。考虑到使用了 Wilcoxon 符号秩检验（而不是配对 t 检验），我想知道这种呈现结果的方式是否正确。此外，Wilcoxon 符号秩检验似乎不用于比较中位数。您能解释一下与此测试相对应的假设吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658780/a-question-about-the-paired-samples</guid>
      <pubDate>Sun, 15 Dec 2024 22:07:47 GMT</pubDate>
    </item>
    <item>
      <title>如何在面板数据分析中测试和实施行业和年份固定效应与 POLS？</title>
      <link>https://stats.stackexchange.com/questions/658777/how-to-test-and-implement-industry-and-year-fixed-effects-vs-pols-in-panel-data</link>
      <description><![CDATA[我是计量经济学建模的新手。
我正在处理跨越 8 年的面板数据，包括分布在 8 个不同行业的 155 个单位（REIT）。我的目标是应用行业固定效应和年份固定效应，但不应用实体固定效应。如何在 R 中正确实现这一点？
在测试是否使用固定效应或合并最小二乘法时，我应该如何设置我的 POLS 模型？我是否应该在 POLS 模型中包含因子（年份）和因子（行业）来测试 POLS 是否优于 FE，或者是否应该为此目的不包括这些？
下面，我概述了我目前正在使用的模型。但是，我不确定我是否在正确测试并以正确的方式进行。我如何确定是否应该使用行业固定效应而不是实体固定效应？
FE_model_H1TSR &lt;- plm(TSR ~ LOG_ESG + LOG_TA + GTA + LOG_AGE, data = pdata, model = &quot;within&quot;, index= c(&quot;INDUSTRY&quot;,&quot;YEAR&quot;), effects = &quot;twoway&quot;)
Pols_model_H1TSR &lt;- plm(TSR ~ LOG_ESG + GTA + LOG_AGE + LOG_TA + factor(YEAR) + factor(INDUSTRY) , data = pdata, model = &quot;pooling&quot;)]]></description>
      <guid>https://stats.stackexchange.com/questions/658777/how-to-test-and-implement-industry-and-year-fixed-effects-vs-pols-in-panel-data</guid>
      <pubDate>Sun, 15 Dec 2024 21:12:18 GMT</pubDate>
    </item>
    <item>
      <title>重新采样进行 AB 测试，以实现 CLT 下的正态分布 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658765/resampling-for-ab-test-to-achieve-normal-distribution-under-the-clt</link>
      <description><![CDATA[是否应在 AB 测试中应用重采样？
在此示例中，假设我想执行 t 检验来确定两组用户之间的差异，其中一组用户看到的是登录页面 A，另一组用户看到的是登录页面 B。我跟踪指标“网站停留时间”。数据看起来不错，但我意识到它不是正态分布。
在将数据输入单向独立样本 t 检验之前，我是否应该使用重采样来规范化这些数据？原因如下：

它实现了正态性，这（至少在视觉上）与我的最终决策标准一致
得到的标准化曲线使假设检验的结果易于理解。即，我的结果是 _ 与我所测试样本的平均值的标准差；这个的 p 值为 p，所以我们接受/拒绝零假设
它只是与我们对问题的解决方案更加一致

反对的理由：

它改变了数据的分布，我不确定这会对我的 AB 测试的“正确性”产生什么影响。
它可能是“过度工程”问题
t 检验可以接受非正态数据，无论 t 检验中仍然使用的正态曲线的视觉效果如何（见下图）。


请注意，我描述的是重新采样，即创建许多平均值的采样分布，而不是简单地采样，即选择随机指标并使用该组作为分布。简而言之，在每个分布上调用 mean() 并将一组均值输入到我的 AB 测试中。
我应该为 AB 测试重新采样吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658765/resampling-for-ab-test-to-achieve-normal-distribution-under-the-clt</guid>
      <pubDate>Sun, 15 Dec 2024 16:53:45 GMT</pubDate>
    </item>
    <item>
      <title>向量的期望 $L^2$ 范数是否大于向量元素期望的 $L^2$ 范数？</title>
      <link>https://stats.stackexchange.com/questions/658756/is-the-expected-l2-norm-of-a-vector-larger-than-the-l2-norm-of-the-vector</link>
      <description><![CDATA[假设随机变量 $X_1, X_2$ 是独立的。以下不等式是否成立？
$$
\mathbb{E}(​​\sqrt{X_1^2+X_2^2}) \ge \sqrt{\mathbb{E}^2(X_1)+\mathbb{E}^2(X_2)}
$$
如果成立，有简单的证明吗？

请注意，这不是 Jensen 不等式！
（$\sqrt{\mathbb{E}(​​X_1^2+X_2^2)} \ge \mathbb{E}(​​\sqrt{X_1^2+X_2^2})$）]]></description>
      <guid>https://stats.stackexchange.com/questions/658756/is-the-expected-l2-norm-of-a-vector-larger-than-the-l2-norm-of-the-vector</guid>
      <pubDate>Sun, 15 Dec 2024 15:14:16 GMT</pubDate>
    </item>
    <item>
      <title>计算不同大小的文本语料库的卡方</title>
      <link>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</link>
      <description><![CDATA[我偶然发现了一篇论文，它批评了某文本分析软件中用于比较六个大小明显不同的文本语料库中的词频的卡方统计量的计算。该软件采用标准公式：
$$
\chi^2 = \sum_{i=1}^{n} \frac{(O_{i} - E_{i})^2}{E_{i}}
$$
这里，$O_{i}$表示在语料库$i$中观察到的频率，$E_{i}$的计算方法是将一个词在所有六个语料库中的总频率除以所有语料库中的单词总数，然后乘以语料库$i$中的单词数。
本文作者批评了这种方法，陈述：

&quot;运行交叉制表也不能产生有效可靠的评估。 [...] 事实证明，该软件使用非标准化的绝对频率，只有当要比较的文本语料库长度相等时才不会引起问题。&quot;

在这种情况下，作者将$O_{i}$解释为绝对频率，并提出了一种替代的&quot;标准化&quot;过程来计算$O_{i}$和$E_{i}$。这涉及：

选择最小的语料库作为参考。
通过将观察到的所有其他语料库的频率除以各自语料库中的单词总数，然后乘以参考语料库中的单词数，对观察到的所有其他语料库的频率进行归一化。
将预期频率计算为所有语料库（包括参考语料库）的归一化频率之和，除以六（语料库数量）。

问题 1：作者声称该软件使用的公式（如上所述）没有考虑到语料库的各种大小，他是否正确。
问题 2：在这种情况下，这种归一化方法是否适用于卡方计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</guid>
      <pubDate>Sun, 15 Dec 2024 13:37:05 GMT</pubDate>
    </item>
    <item>
      <title>箱线图是否假设区间数据？</title>
      <link>https://stats.stackexchange.com/questions/658750/does-a-boxplot-assume-interval-data</link>
      <description><![CDATA[箱线图是否假设区间数据？如果不是，那么使用箱线图来表示李克特量表（序数）数据可以吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658750/does-a-boxplot-assume-interval-data</guid>
      <pubDate>Sun, 15 Dec 2024 11:48:10 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn QuantileRegressor 中 L1 正则化的 alpha 参数是什么</title>
      <link>https://stats.stackexchange.com/questions/658748/what-is-the-alpha-parameter-for-l1-normalization-in-scikit-learn-quantileregress</link>
      <description><![CDATA[scikit-learn Quantile Regression 文档中的 示例 展示了一个将参数 alpha 设置为零的示例。默认值为 1。
文档 QuantileRegressor 显示默认值设置为 1.0。它指出这是一个乘以 L1 惩罚项的正则化常数。
我对 Lasso 是什么或 L1 回归的确切含义没有直观的理解。
参数 alpha 与这些事物的关系是否有直观的解释？
有一篇与分位数回归相关的 维基百科文章，非常详细。浏览此文，在正则化参数的选择部分中，alpha 似乎就是 lambda。它在其他地方也可能被称为t。
我的直觉可能是错的。
到目前为止，我的结论是 alpha 可能只在多维（&gt; 1）回归问题中起作用，它可能用于选择维度的子集，即具有最强统计预测能力的最重要维度？]]></description>
      <guid>https://stats.stackexchange.com/questions/658748/what-is-the-alpha-parameter-for-l1-normalization-in-scikit-learn-quantileregress</guid>
      <pubDate>Sun, 15 Dec 2024 08:40:50 GMT</pubDate>
    </item>
    <item>
      <title>纳入因变量的下限是否可以改善估计？</title>
      <link>https://stats.stackexchange.com/questions/658703/does-incorporating-lower-bound-on-dependent-variable-improve-estimation</link>
      <description><![CDATA[假设我们抛硬币 $n$ 次，其中 如果正面，则 $Z_k = 1$，否则为 0，$Y = \sum_{k=1}^{n} Z_k$ 是正面的总数。硬币有两种类型：银币和金币，我们可以观察到用 $X$ 表示。此外，给定硬币的类型，我们知道正面的概率：
$$ P(Z_k|X) =: p(X) = \begin{cases} 0.8 &amp; X = 金币 \\ 0.5 &amp; X = 银币 \end{cases} $$
目标是根据硬币类型预测正面的硬币数量。

由于我们知道 $Y|X$ 的分布，第一种方法是条件均值估计量：
$$ \hat{\theta}(X) = \mathbb{E}[Y|X] $$
这是 $L^2$ 意义上的最佳估计量。在这种情况下，因为我们知道$Y|X \sim Binom(n, p(X))$，所以我们有一个闭式解
$$ \hat{\theta}(X) = np(X) = \begin{cases} 0.8n &amp; X = Gold \\ 0.5n &amp; X = Silver \end{cases} $$

现在问题如下。假设在$n$次翻转之前的任何时间点，我们都可以暂停游戏，优化我们的模型，并恢复其余的翻转。我们能改进之前的估计器吗？
请注意，对于给定的实现 $X_i$，目标是预测 $Y_i$。Oracle 估计器会设置 $\hat{Y}_i = Y_i$ 和 $MSE(Y_i, \hat{Y}_i) = 0$，但这显然是不可能的，因为我们实际上并不知道结果是什么。然而，随着每次抛硬币，我们都会收集更多关于 $Y_i$ 下限的信息。更准确地说，如果我们暂停翻转并观察到有 $c$ 次正面，那么我们就知道
$$ Y_i \geq c $$
这就会激发“增强”估计量：
$$ \hat{\theta}^{aug}(X; c) = \mathbb{E}[Y|X, Y\geq c] = \frac{ \int_{c}^{n} y \ dP_{Y|X}}{\int_{c}^{n} dP_{Y|X}}$$
其中条件均值估计量是 $c = 0$ 的一个特例。有没有办法正式证明增强估计量在某种意义上“更好”？
可能，一种方法是将条件设置为过滤序列，我们观察到越来越多有关由$Y$生成的$\sigma$-代数的信息。或者，也许我们可以将其视为
$$ Y = \mathbb{E}[Y|X] + \epsilon $$
随着翻转次数的增加，我们观察到一些关于$\sigma(\epsilon)$的部分知识。

我使用$n=10$进行了数值模拟，并得到了一些有趣的结果。这里的 x 轴是让 $c = pY$ 满足 $p \in [0,1]$。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658703/does-incorporating-lower-bound-on-dependent-variable-improve-estimation</guid>
      <pubDate>Sat, 14 Dec 2024 05:37:35 GMT</pubDate>
    </item>
    <item>
      <title>对数秩和 Cox 模型的假设类似。请求文章参考</title>
      <link>https://stats.stackexchange.com/questions/657830/similar-assumptions-for-log-rank-and-cox-model-request-for-article-reference</link>
      <description><![CDATA[我理解，具有单个二元预测因子且回归常数等于零的 Cox 模型的得分函数等于对数秩检验的统计数据（数学的简单重写）。因此，这就是对数秩检验和 Cox 模型都假设比例风险的主要论点。
例如，请参阅对数秩检验统计量相当于 Cox 回归的得分。使用对数秩检验比 Cox 回归有什么优势吗？
但是，我找不到任何好的参考资料来添加到肿瘤学中的一篇论文中，我需要在其中证明使用 Cox 而不是对数秩的合理性。实际上，问题在于比例风险检验的 p 值低于 5%（因此实际上我们不能使用其中任何一个）。有些人可能会认为应该使用对数秩检验，因为它“不依赖于任何假设”，这是非统计学家的普遍理解。如上所述，我不同意使用对数秩检验（和 Cox）。不过，我需要一个参考资料（也可以放在我们正在撰写的论文中），我可以将其用作我的论证的一部分，即 Cox 和对数秩的假设实际上是相同的——并不是每个人都能看到数学偏差的美。您能否提供任何与上述问题相关的有用的论文参考资料？我可以在网上找到很多陈述，但我需要一篇文章参考资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/657830/similar-assumptions-for-log-rank-and-cox-model-request-for-article-reference</guid>
      <pubDate>Mon, 25 Nov 2024 21:42:54 GMT</pubDate>
    </item>
    </channel>
</rss>