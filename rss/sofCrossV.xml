<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 14 May 2024 09:15:27 GMT</lastBuildDate>
    <item>
      <title>是否可以仅通过了解我的组的平均值和样本量来进行统计分析？</title>
      <link>https://stats.stackexchange.com/questions/647193/is-it-possible-to-do-statistic-analysis-from-only-knowing-my-groupss-means-and</link>
      <description><![CDATA[我正在写一个我的同事（在人类健康领域）认为不可能解决的问题，但我想相信数学有答案。我被告知不可能对下述实验进行统计分析：
我们有 32 只个体，我们认为它们最初是相同的（来自同一批次的小鼠），并将它们分为 8 组，每组 4 只。每组都接受不同的治疗。
然后，在两个不同的时间点，我们对每组的 4 个人进行血液采样，汇集血液，然后对汇集的血液进行分析。我们获得的数据是我们混合的血液样本中不同细胞类型（例如：淋巴细胞）的数量。
我想知道是否可以确定我们合并的血液样本中的淋巴细胞数量是否存在统计差异。
下一个层次是了解同一组的两个时间点的汇集血液样本是否存在统计差异。
在互联网上，我查找了诸如“Aspin-Welch t 检验”之类的测试，这些测试似乎很有希望，但看起来我们仍然需要能够提供我们所缺乏的 SD 值？
如果有人能提供帮助，我将不胜感激。
祝你有美好的一天！]]></description>
      <guid>https://stats.stackexchange.com/questions/647193/is-it-possible-to-do-statistic-analysis-from-only-knowing-my-groupss-means-and</guid>
      <pubDate>Tue, 14 May 2024 08:35:21 GMT</pubDate>
    </item>
    <item>
      <title>GAMLSS - 如何调整 AIC 以进行变量的对数转换</title>
      <link>https://stats.stackexchange.com/questions/647188/gamlss-how-to-adjust-aic-for-log-transformation-of-variables</link>
      <description><![CDATA[我有一个 GAMLSS 模型，其中自变量和因变量均处于自然尺度，以及第二个模型，其中两个变量都已进行对数转换。如何调整对数转换模型的 AIC 以便可以比较两个模型？
（这对于回答问题可能并不重要，但如果您想知道，我正在将测量值的 CV 建模为其真实值的函数。我有几千个未知的真实值，并且每个测量值都有两个测量值他们。
在自然尺度模型中，我使用两次测量的平均值（作为真值的估计量）作为自变量，并将样本 SD 作为因变量。 GAMLSS 模型得到的 mu 是对受抚养群体 SD 的估计，然后可用于计算受抚养群体 CV。
然后，我使用对数转换测量值的平均值作为因变量，将其 SD 作为因变量，从而直接估计相关群体 CV。）
这是一个例子：
库（matrixStats）
图书馆（gamss）

设置.seed(0)

# 模拟数据
x_mu &lt;- rGB2(5000, 2.7, 8.6, 0.13, 1.28)
x_mu &lt;- x_mu[x_mu &gt; .5]

cv &lt;- 函数(x) .03 * exp(-1 * x) + .01

# 假装你不知道数据是由 rlnorm() 生成的
dat &lt;- as.data.frame(矩阵(
  rlnorm(2 * 长度(x_mu), log(x_mu), cv(x_mu)),
  ncol = 2
））

# 假设误差服从正态分布
dat_normal &lt;- 数据
dat_normal$mean &lt;- rowMeans(dat_normal)
dat_normal$sd &lt;- rowSds(as.matrix(dat_normal[, 1:2]))

model_normal &lt;- gamlss(sd ~ pbm(mean, mono = “up”),
                     〜意思是，
                     数据 = dat_normal,
                     家庭 = GG(),
                     控制 = gamlss.control(n.cyc = 50))

# 假设误差服从对数正态分布
dat_lognormal &lt;- log(dat)
dat_lognormal$logmean &lt;- rowMeans(dat_lognormal)
dat_lognormal$logsd &lt;- rowSds(as.matrix(dat_lognormal[, 1:2]))

model_lognormal &lt;- gamlss(logsd ~ pbm(logmean, mono = “向下”),
                        〜对数平均值，
                        数据 = dat_lognormal,
                        家庭 = GG(),
                        控制 = gamlss.control(n.cyc = 50))

x_compare &lt;- c(.5, 1, 2, 4)
比较 &lt;- data.frame(
  x = x_比较，
  true = cv(x_compare),
  model_normal = exp(预测(model_normal, newdata = data.frame(mean = x_compare))) / x_compare,
  model_lognormal = exp(预测(model_lognormal, newdata = data.frame(logmean = log(x_compare))))
）

回合（比较，4）
x true model_normal model_lognormal
0.5 0.0282 0.0303 0.0295
1.0 0.0210 0.0215 0.0215
2.0 0.0141 0.0146 0.0146
4.0 0.0105 0.0112 0.0099

AIC（模型_正态，模型_对数正态）

                df AIC
模型对数正态 6.141213 -28058.55
模型正常 8.663739 -24779.60
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/647188/gamlss-how-to-adjust-aic-for-log-transformation-of-variables</guid>
      <pubDate>Tue, 14 May 2024 07:43:41 GMT</pubDate>
    </item>
    <item>
      <title>在观察性因果研究中，匹配何时会产生 ATE 与 ATT 的结果？</title>
      <link>https://stats.stackexchange.com/questions/647187/when-does-matching-result-in-an-ate-vs-att-on-observational-causal-studies</link>
      <description><![CDATA[我读到匹配几乎总是产生 $ATT$ 效果，但子分类匹配可以产生 $ATE $。因此，我想知道什么是启发式来确定哪种匹配导致 $ATE$ 与 $ATT$ 效果？例如，精确匹配、倾向得分匹配或基因匹配会给出什么结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/647187/when-does-matching-result-in-an-ate-vs-att-on-observational-causal-studies</guid>
      <pubDate>Tue, 14 May 2024 07:32:37 GMT</pubDate>
    </item>
    <item>
      <title>多级模型中分类变量的效应大小/功效分析</title>
      <link>https://stats.stackexchange.com/questions/647186/effect-size-power-analysis-of-categorical-variable-in-multilevel-model</link>
      <description><![CDATA[如何确定传销中具有多个级别（例如三级或四级）的分类变量的效应大小？
以及如何使用模拟（或其他）方法计算这些变量的功效？]]></description>
      <guid>https://stats.stackexchange.com/questions/647186/effect-size-power-analysis-of-categorical-variable-in-multilevel-model</guid>
      <pubDate>Tue, 14 May 2024 07:20:40 GMT</pubDate>
    </item>
    <item>
      <title>数据建模作为表面</title>
      <link>https://stats.stackexchange.com/questions/647185/data-modelling-as-a-surface</link>
      <description><![CDATA[我想使用容器中的数据对城市中的废物产生进行建模。我有每个容器随时间变化的位置和填充水平。我的想法是使用每天每个容器中的平均垃圾量，并在城市上空创建某种表面，该表面可以告诉容器如果放置在这些坐标中将包含的平均垃圾量。我的第一个想法是使用 3d 空间中的点（纬度、经度、平均值）来插值表面，但我认为这不会给出可靠的结果。
我不确定这是否是一个好方法。我希望得到关于为此使用什么类型的模型以及是否有更好的方法的建议。我的想法是使用 python 对其进行编码，因此也欢迎任何有关此的提示。]]></description>
      <guid>https://stats.stackexchange.com/questions/647185/data-modelling-as-a-surface</guid>
      <pubDate>Tue, 14 May 2024 06:50:35 GMT</pubDate>
    </item>
    <item>
      <title>二维图中的强度异常值</title>
      <link>https://stats.stackexchange.com/questions/647184/intensity-outliers-in-2d-plot</link>
      <description><![CDATA[我想知道使用哪种方法更好地查看二维图 z 值的异常值。例如，我测量的 x 和 y 值均在 1 到 16 范围内，步长为 1。接下来，我计算每对 x 和 y (x_n, y_n) 有多少个观测值。这给了我一个 16 x 16 的网格，每对 (z) 的观测值数量。因为 x 和 y 是相关的，所以我们期望看到一些模式 - 某些点组比其他点更频繁地出现。
有时，在很少有观察结果的领域，可以提出许多观察结果。这是由于设备错误造成的。传感器一次又一次地错误地标记某些值。在大数据中查找这些错误的最佳方法是什么？如果网格不是 16 x 16 而是 9000 x 9000。也可以使用原始数据 - 重复的 x 和 y 观察（在 KDE 的情况下）。
这是一些硬编码的沙箱示例：
导入 pandas 作为 pd
随机导入
将 matplotlib.pyplot 导入为 plt
# 让我们制作数据 x、y、z。
# x和y是类似于矩阵坐标的坐标
x = [i 对于范围 (1, 17) 内的 i 对于范围 (16) 内的 j]
y = 列表(范围(1, 17)) * 16


# z 是某个范围内的一组随机整数值
def r_num(基值: int, n_numbers: int):
    返回 [random.randint(base_value, base_value + 700) for i in range(n_numbers)]

def z_make():
    _z = ((r_num(2000, 16)) +
         (r_num(2000, 16)) +
         (r_num(2000, 2) + r_num(5000, 12) + r_num(2000, 2)) +
         (r_num(2000, 2) + r_num(5000, 12) + r_num(2000, 2)) +
         (r_num(2000, 2) + r_num(5000, 2) + r_num(7000, 8) + r_num(5000, 2) + r_num(2000, 2)) +
         (r_num(2000, 2) + r_num(5000, 2) + r_num(7000, 1) + r_num(9000, 6) + r_num(7000, 1) + r_num(5000, 2) + r_num(2000, 2)) +
         (r_num(2000, 2) + r_num(5000, 2) + r_num(7000, 1) + r_num(9000, 1) + r_num(10000, 4) + r_num(9000, 1) + r_num(7000, 1) + r_num(5000, 2) + r_num(2000, 2)) +
         (r_num(2000, 2) + r_num(5000, 2) + r_num(7000, 1) + r_num(9000, 1) + r_num(10000, 1) + r_num(16000, 2) + r_num(10000, 1) + r_num(9000, 1) + r_num(7000, 1) + r_num(5000, 2) + r_num(2000, 2)))
    返回_z


z1 = z_make()
z2 = z_make()
z2.reverse()
z = z1 + z2

对于 [&#39;x&#39;,&#39;y&#39;,&#39;z&#39;] 中的 i：
    print(&#39;i 的长度：&#39;, len(eval(i)))

df = pd.DataFrame({&#39;x&#39;: x, &#39;y&#39;: y, &#39;z&#39;: z})

# 设置一些异常值和异常值附近的缺失值
df.loc[(df[&#39;x&#39;] == 2) &amp; (df[&#39;y&#39;] == 6), &#39;z&#39;] = 15875
df.loc[(df[&#39;x&#39;] == 15) &amp; (df[&#39;y&#39;] == 2), &#39;z&#39;] = 14999
df.loc[(df[&#39;x&#39;] == 2) &amp; (df[&#39;y&#39;] == 7), &#39;z&#39;] = 无

plt.scatter(df.x, df.y, c=df.z, cmap=&#39;viridis&#39;, s=100, alpha=0.7)

# 添加颜色条
plt.colorbar(label=&#39;强度&#39;)

# 设置标签和标题
plt.xlabel(&#39;X 标签&#39;)
plt.ylabel(&#39;Y 标签&#39;)
plt.show()


所以我正在寻找绘图一侧的两个黄点。相邻点的 z 值低于异常值。在一种情况下，邻居甚至失踪了。
我一直在研究 KDE、轮廓和局部离群因子 (LOF)，但没有成功。我也问了类似的问题&lt; /a&gt; 在 Stack 中，但我想知道 CV 社区是否可以提出更好的解决方案。
实际上 KDE 工作得还不错，但带宽极大地影响了异常值的检测。我需要在大型散点图中找到 z 值与其邻居的 z 值不同的点（坐标）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647184/intensity-outliers-in-2d-plot</guid>
      <pubDate>Tue, 14 May 2024 06:50:16 GMT</pubDate>
    </item>
    <item>
      <title>韦尔奇方差分析背后的直觉</title>
      <link>https://stats.stackexchange.com/questions/647183/intuition-behind-welchs-anova</link>
      <description><![CDATA[我运行了一些模拟，自然地，与经典方差分析相比，韦尔奇的不等方差方差分析非常好，而且似乎没有缺点。然而，我仍然不明白它为什么有效。准确地说，为什么当我们使用与方差成反比的权重时，我们设法将假阳性率和假阴性率保持在名义值，以及为什么我们使用这些权重计算的平方和模型遵循 Chi2分配。这个属性是如何产生的？
我不是数学家，但我尝试在每个概念背后建立直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/647183/intuition-behind-welchs-anova</guid>
      <pubDate>Tue, 14 May 2024 06:37:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么将 IQR 数据分为 4 个部分，而不是每个部分 20 或 10 个百分比？</title>
      <link>https://stats.stackexchange.com/questions/647182/why-divide-data-into-4-parts-for-iqr-and-not-into-parts-of-20-or-10-percentages</link>
      <description><![CDATA[为什么将数据分为 4 个部分以进行 IQR，而不是分成更多部分，例如每个部分 20% 或 10%？
我知道四分位距的定义是 25%，但这不是我的问题。
我认为丢弃 IQR 的 50% 数据来删除异常值太浪费数据了。但总得有个理由吧？]]></description>
      <guid>https://stats.stackexchange.com/questions/647182/why-divide-data-into-4-parts-for-iqr-and-not-into-parts-of-20-or-10-percentages</guid>
      <pubDate>Tue, 14 May 2024 06:25:10 GMT</pubDate>
    </item>
    <item>
      <title>对于什么样的分布，联合分布可以由边际分布和相关性唯一确定？</title>
      <link>https://stats.stackexchange.com/questions/647179/for-what-kind-of-distributions-the-joint-distribution-could-be-determined-uniqu</link>
      <description><![CDATA[假设 $X$ 和 $Y$ 来自同一分布$P$ 和 $\rho = \frac{Cov(X,Y)}{\sqrt{Var(x)Var(Y)}} $ 是固定的。对于什么样的$P$我们可以唯一确定$X,Y$的联合分布？&lt; /p&gt;
我知道两个具有上述属性的分布，即

$P = N(\mu,\sigma^2)$，即正态分布
$P = Ber(p)$，即伯努利分布

此列表中还有其他发行版吗？或者我们可以用这个属性来描述分布吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647179/for-what-kind-of-distributions-the-joint-distribution-could-be-determined-uniqu</guid>
      <pubDate>Tue, 14 May 2024 01:35:06 GMT</pubDate>
    </item>
    <item>
      <title>缩减长轴回归是总最小二乘法的特例吗？</title>
      <link>https://stats.stackexchange.com/questions/647178/is-reduced-major-axis-regression-a-special-case-of-total-least-squares</link>
      <description><![CDATA[我正在阅读https://influenceialpoints.com/训练/errors-in-variables_regression-principles-properties-assections.htm
这表示总最小二乘法有以下解决方案：

然而，后来似乎表明，当两个方差之间的比率为 $\lambda = V_{x}/V_{ 时，减少的长轴回归是这种情况的特殊情况y}$。具体来说，它说

但是，它随后给出以下公式作为 $\beta_{1}$ 的解：

但是，当 $\lambda = V_{x}/V_{y}$ 时，我无法确定这实际上是上面更通用的解决方案的特殊情况。当我尝试将此比率插入 $\lambda$ 时，我无法将其简化为标准差之比，而这应该是解决方案。
我还有两个问题。首先，从概念上讲，为什么减少垂直残差平方和水平残差平方的加权和会得到与减少水平残差和垂直残差的乘积相同的答案并不明显，我相信这就是 RMA（减少长轴）回归应该做的做。
其次，共识似乎是 RMA 不能用于测试 $H_{null}:Beta_{1}=0$。但我猜想可以用总最小二乘法来检验这个假设。那么为什么 $\lambda = V_{x}/V_{y}$ 的这种特殊情况会使 $beta_{1 }=0$ 无法测试？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647178/is-reduced-major-axis-regression-a-special-case-of-total-least-squares</guid>
      <pubDate>Tue, 14 May 2024 01:31:00 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 符号秩检验可以用于 4 个配对数据集的样本量吗？</title>
      <link>https://stats.stackexchange.com/questions/647177/can-wilcoxon-signed-rank-test-be-used-with-sample-size-of-4-paired-data-sets</link>
      <description><![CDATA[我的项目除了测试前和过去测试的李克特量表之外，还比较测试前和测试后的比率。我计划使用 Wilcoxon 签名等级。我的样本量只有 4。我还可以使用 Wilcoxon 还是有其他合适的测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/647177/can-wilcoxon-signed-rank-test-be-used-with-sample-size-of-4-paired-data-sets</guid>
      <pubDate>Tue, 14 May 2024 00:40:28 GMT</pubDate>
    </item>
    <item>
      <title>何时需要显着性或零假设检验的基本原理</title>
      <link>https://stats.stackexchange.com/questions/647167/the-rationale-for-when-significance-or-null-hypothesis-testing-is-needed</link>
      <description><![CDATA[我想知道为什么有时人们声称效果如此巨大且“明显”，即使样本量不大，也不能保证计算出任何推论统计数据。
这来自生物/医学领域，主要来自实验室设计的实验。
实验示例此处。这些是平均值+标准差。他们通常会得出“差异太明显，无需测试”的结论。在计算样本 CI 之前。
有人可以分享一些关于此事的参考资料吗？
非常感谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/647167/the-rationale-for-when-significance-or-null-hypothesis-testing-is-needed</guid>
      <pubDate>Mon, 13 May 2024 19:49:07 GMT</pubDate>
    </item>
    <item>
      <title>时间点 lsmeans 事后均值比较</title>
      <link>https://stats.stackexchange.com/questions/647165/timepoint-lsmeans-post-hoc-mean-comparisons</link>
      <description><![CDATA[谁能建议哪个是最合适的测试？
我的 Y 轴上的基线（包括基线在内的 4 个时间点）和 X 轴上的时间点相比发生了变化，4 次治疗。我想看看治疗中不同时间点是否存在显着差异。使用 Tukey 调整进行 lsmeans 测试是否合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/647165/timepoint-lsmeans-post-hoc-mean-comparisons</guid>
      <pubDate>Mon, 13 May 2024 19:19:07 GMT</pubDate>
    </item>
    <item>
      <title>序列相关性如何使 OLS 保持无偏（即使在横截面数据中）</title>
      <link>https://stats.stackexchange.com/questions/647155/how-does-serial-correlation-cause-ols-to-remain-unbiased-even-in-cross-section</link>
      <description><![CDATA[为了使系数估计量在 OLS 中保持无偏，给定回归量的条件误差期望必须为零，$E(u_i |x_i )=0$.
但是，如果我们在误差项中具有序列相关性，这是否不会使误差产生偏差，从而使误差的条件期望不再为零？
例如，如果错误存在序列相关性，那么我们可以拟合方程 $u_i = \phi_i * u_j + \epsilon_i $，则不会这意味着 $u_i$ 现在偏向于具有非零条件均值（因为 $\epsilon_i $ 是 i.i.d)？
例如，如果我们固定了 $x_i$，则更改 $u_j$ 会影响 &lt; span class=&quot;math-container&quot;&gt;$u_i$ 给定 $x_i$？
如果序列相关性被破坏，这是否会违反 OLS 的无偏性？]]></description>
      <guid>https://stats.stackexchange.com/questions/647155/how-does-serial-correlation-cause-ols-to-remain-unbiased-even-in-cross-section</guid>
      <pubDate>Mon, 13 May 2024 16:35:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么 1/SE 或 1/方差通常用作回归中的权重？</title>
      <link>https://stats.stackexchange.com/questions/647146/why-are-1-se-or-1-variance-commonly-used-as-weights-in-regressions</link>
      <description><![CDATA[我第一次尝试进行荟萃分析，将简单实验处理的测量结果与多个物种的对照进行比较。我首先将混合效应模型拟合到从一组已发表的研究中收集的平均值。这工作得很好，但它当然忽略了一个事实，即平均值是用不同的精度水平估计的。听起来这是一个应该通过适当加权手段来解决的问题。其中几项研究发布了标准误差或其原始数据，因此我可以使用 SE 进行加权。
我的问题是：1/SE（或 1/ σ2）有什么特别之处？为什么不使用 2/SE、10/SE 或任何其他此类加权因子？
我很想问这个问题，因为由于一些研究使用了极其精确的仪器，SE 相差几乎两个数量级。精度越高显然越好，但对我来说，这些精确估计值与 100 次精确估计值相比并不明显。 （加权在拟合模型时还引入了一些算法问题，但这可能是可以解决的，我对概念论证更感兴趣）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647146/why-are-1-se-or-1-variance-commonly-used-as-weights-in-regressions</guid>
      <pubDate>Mon, 13 May 2024 14:37:12 GMT</pubDate>
    </item>
    </channel>
</rss>