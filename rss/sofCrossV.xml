<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 09 Sep 2024 12:32:05 GMT</lastBuildDate>
    <item>
      <title>如何计算平均差异的标准差？</title>
      <link>https://stats.stackexchange.com/questions/654092/how-to-calculate-standard-deviation-of-mean-difference</link>
      <description><![CDATA[我有一篇论文，其中报告了参与者的反应时间任务数据。任务条件有两种：“一致”和“不一致”。还有另一种任务时间操纵，有 4 个级别（0、100、200、600）。这两个都是参与者内部变量。
不一致平均值 (sd)：



时间
RT




0
559 (103)


100
538 (106)


200
523 (102)


600
516 (102)



一致平均值 (sd)：



时间
RT




0
543 (104)


100
508 (106)


200
503 (95)


600
514 (100)



我想跨时间折叠以计算不一致和一致条件之间的 RT 平均差异。因此，我得到了以下每个组的平均值和 SD。
不一致：534 (103.26)
一致：517 (101.34)

这里的 SD 是通过对每个 SD 求平方，除以 4 并取平方根来计算的。

因此，平均差异为 534-517=17。
如何计算标准差？
我发现了以下内容，但不确定样本大小 n 指的是什么：
样本均值差异的标准差 (σd) 大约等于：
σd = sqrt( σ12 / n1 + σ22 / n2 )]]></description>
      <guid>https://stats.stackexchange.com/questions/654092/how-to-calculate-standard-deviation-of-mean-difference</guid>
      <pubDate>Mon, 09 Sep 2024 12:09:37 GMT</pubDate>
    </item>
    <item>
      <title>双样本 KS 显著，但双样本 AD 不显著</title>
      <link>https://stats.stackexchange.com/questions/654090/two-sample-ks-significant-but-two-sample-ad-not-significant</link>
      <description><![CDATA[介绍。从2 Sample Kolmogorov-Smirnov vs. Anderson-Darling vs Cramer-von-Mises，我们可以读到以下内容：
(1) 来自@Adam Przedniczek

Anderson-Darling 检验对分布的尾部更敏感，而 Kolmogorov-Smirnov 检验对分布的中心更敏感分布。

(2) 来自 @glen_b

Anderson-Darling 检验对肥尾的功效比指定的要好，而 Kolmogorov-Smirnov 检验对中间偏差的功效更大

问题。 KS 和 AD 测试相同的分布相等性零假设，如果我们将两个分布相互比较（通过这些测试），KS 显著性的解释是什么（即两个分布不同）并且 AD 不显著（即我们无法拒绝原假设）？
如果我们阅读 @Adam Przedniczek 和 @glen_b 的答案，我们是否应该将 KS 显著而 AD 不显著解释为分布中心的差异，而没有证据表明分布尾部存在差异？
附带问题。我没有找到关于“Kolmogorov-Smirnov 对中间偏差具有更强的效力”或“Kolmogorov-Smirnov 检验更了解分布中心”的参考资料，只是 KS 对分布的一般形状很敏感。非常欢迎提供关于 KS 对分布中心部分的敏感性的参考资料！]]></description>
      <guid>https://stats.stackexchange.com/questions/654090/two-sample-ks-significant-but-two-sample-ad-not-significant</guid>
      <pubDate>Mon, 09 Sep 2024 11:28:29 GMT</pubDate>
    </item>
    <item>
      <title>逐步回归 $R^2$：它有偏差还是不一致？</title>
      <link>https://stats.stackexchange.com/questions/654089/stepwise-regression-r2-is-it-biased-or-inconsistent</link>
      <description><![CDATA[在 Frank Harrell 对逐步回归的歪曲中，他提到通常的$R^2$ 有较高的偏差（我假设当它被计算为通常调整的$R^2$ 时，参数数量设置为逐步选择中幸存的参数数量）。
这听起来很糟糕，但我们一直使用有偏差的估计量。例如，岭回归会导致有偏的参数估计，希望方差的减少足以使均方误差更低，尽管存在偏差。
因此，有偏估计量并不是一个交易破坏者。
但是，如果逐步回归$R^2$估计收敛到高偏差值，那么这种不一致似乎是一个交易破坏者。
那么逐步回归$R^2$估计只是有偏的还是也不一致？]]></description>
      <guid>https://stats.stackexchange.com/questions/654089/stepwise-regression-r2-is-it-biased-or-inconsistent</guid>
      <pubDate>Mon, 09 Sep 2024 11:13:08 GMT</pubDate>
    </item>
    <item>
      <title>一种方法或测试，用于了解 Kolmogorov–Smirnov (KS) 检验检测到的差异是否具有位置或形状起源</title>
      <link>https://stats.stackexchange.com/questions/654087/a-way-or-test-to-understand-if-the-differences-detected-by-the-kolmogorov-smirno</link>
      <description><![CDATA[在@Single Malt 的大样本的 Kolmogorov-Smirnov 检验统计解释 回答中，我们读到：

Kolmogorov–Smirnov 检验对位置和形状的差异很敏感，这是它的优势之一，从某种意义上说，它是一种整体测量，而不仅仅是采用位置等单一指标。但这意味着K-S 统计量 (D_n) 可能会为由位置或形状引起的差异给出高值，并且不会区分两者，

是否有方法或额外的（非参数）测试 - 在 KS 测试之后执行 - 来区分 KS 测试检测到的差异是否具有“位置”或“形状”起源/原因？]]></description>
      <guid>https://stats.stackexchange.com/questions/654087/a-way-or-test-to-understand-if-the-differences-detected-by-the-kolmogorov-smirno</guid>
      <pubDate>Mon, 09 Sep 2024 10:31:09 GMT</pubDate>
    </item>
    <item>
      <title>聚类数据时的直觉编码</title>
      <link>https://stats.stackexchange.com/questions/654086/encodeing-intuition-when-clustering-data</link>
      <description><![CDATA[我有以下数据：
 准确度 头部弯曲 躯干弯曲 完成次数 ffb-mot
0 0.977172 11.163064 4.882548 3.0 23
1 0.953535 22.496640 9.426914 3.5 25
2 0.998149 9.477726 3.349048 8.0 27
3 0.718329 6.071332 5.859465 8.5 28
4 0.834607 17.200119 7.098477 3.5 24
5 0.984841 9.830395    4.302155 4.0 24 6 0.993825 10.192271 5.164420 3.5 32 7 0.937636 22.077398 8.879587 7.5 24 8 0.939631 13.325315 6.146577 4. 0 29 9 0.986393 19.091837 7.585588 7.5 25 10 0.964553 12.169396 4.895954 5.0 23 11 0.903640 30.373535 7.441938 4.5 28 12 0.962311 15.627187 6.098659 6.0 24
13 0.994823 15.510419 5.742348 7.0 31

我现在想根据对技能的直观理解对这些数据进行聚类。也就是说，更高的准确率、更多的完成率和更高的 ffb-mot 分数应该反映出更高的技能。头部和躯干弯曲程度越高，技能越低。具有相似技能的数据项应该聚类在一起。我不知道聚类的数量。
我尝试了许多聚类算法，它们都使用欧几里得距离作为距离度量。但结果并不太令人信服，也就是说，它们与我刚才给出的直觉不符。
我也尝试在聚类之前应用 PCA，但这并没有真正改善结果。
我如何将我的直觉编码到数据中，以便算法“理解”我想要什么？什么是适合这项任务的算法？]]></description>
      <guid>https://stats.stackexchange.com/questions/654086/encodeing-intuition-when-clustering-data</guid>
      <pubDate>Mon, 09 Sep 2024 10:30:09 GMT</pubDate>
    </item>
    <item>
      <title>通过逐步消除具有“不显著”系数的预测因子来简化线性回归中的模型</title>
      <link>https://stats.stackexchange.com/questions/654085/model-reduction-in-linear-regression-by-stepwise-elimination-of-predictors-with</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654085/model-reduction-in-linear-regression-by-stepwise-elimination-of-predictors-with</guid>
      <pubDate>Mon, 09 Sep 2024 10:21:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 cloglog 进行二项回归（模拟、功效、样本大小）</title>
      <link>https://stats.stackexchange.com/questions/654084/binomial-regression-with-cloglog-simulation-power-sample-size</link>
      <description><![CDATA[我希望这个问题不会从网站上删除。我真的需要一些帮助来模拟离散时间生存模型（包括时间相关的二元协变量（感兴趣的协变量）和年龄）以计算所需的样本量。我对模拟一无所知，因此任何建议和帮助（例如，用 R 编码，参考，参考）都将不胜感激。
我有以下来自以前出版物的信息：
power=0.8*
风险比= 5.05
风险率=0.8
事件率：0.6
每月间隔的时间点 0、3、6、9、12、15、18、21、24
I 型错误率=0.05

我知道二项回归与 glm 函数和 link=cloglog 可用于离散时间生存模型。但我不知道如何模拟和生成数据以及如何查看功效、样本量之间的关系
我有一项研究，患者每三个月到两年来医院检查一次。T0（手术前一周）、T3（手术后三个月）、T6（手术后六个月）到T24（手术后两年）。事件有两个级别（癌症稳定或癌症恶化）]]></description>
      <guid>https://stats.stackexchange.com/questions/654084/binomial-regression-with-cloglog-simulation-power-sample-size</guid>
      <pubDate>Mon, 09 Sep 2024 10:17:14 GMT</pubDate>
    </item>
    <item>
      <title>卷积神经网络和基于 Transformer 的模型之间有什么联系？</title>
      <link>https://stats.stackexchange.com/questions/654082/what-is-connection-between-convolutional-neural-networks-and-transformer-based-m</link>
      <description><![CDATA[我目前的概念差距在于，基于 Transformer 的架构是基于 CNN 的增强架构还是完全不同的东西。
我读过《注意力就是你所需要的一切》，发现通过他们的图表我可以看到 Transformer 架构本质上是一个带有额外预处理（称为注意力）的多层感知器。所以从某种意义上说，Transformer 类似于 CNN，因为 CNN 是一个通过卷积进行特征提取的多层感知器。
所以我目前的理解是，早期的 Transformer（MLP + 注意力）本质上与 CNN（MLP + 卷积）相似但不相同。我的理解正确吗？
但我的差距在于 Transformer 的较新变体。我没有跟上文献的步伐，似乎还有数百甚至数千种架构。毫无疑问，在一些较新的架构中，Transformer 与 CNN 相结合。有没有基于 Transformer 的架构的突出模型，将 CNN 作为内部组件之一？]]></description>
      <guid>https://stats.stackexchange.com/questions/654082/what-is-connection-between-convolutional-neural-networks-and-transformer-based-m</guid>
      <pubDate>Mon, 09 Sep 2024 09:54:43 GMT</pubDate>
    </item>
    <item>
      <title>将样本分成两个子样本，同时确保子样本中的受试者不相关</title>
      <link>https://stats.stackexchange.com/questions/654081/split-up-sample-into-two-sub-samples-while-ensuring-that-subjects-in-sub-samples</link>
      <description><![CDATA[我有一个样本，我想将其分成两个大小大致相等的子样本。这些子样本在定义的一组变量（例如年龄、性别、动作等）方面应该相似。通常，人们可能只使用多元距离测量来计算每对受试者之间的某种距离测量，然后可以使用该距离测量来分割样本。
但就我而言，我还有两个问题：
1. 我还需要考虑分割样本时的分类变量（例如性别）。经典距离测量仅适用于连续变量（例如年龄）。我已经有想法是否可以在这里使用 Gower 距离？
2. 我有一个额外的限制。一些受试者来自同一个家族。因为我必须假设这些受试者形成聚类（对于未观察到的协变量也是如此），所以我想确保结果子样本中没有一个包含来自同一家族的受试者。如果来自同一家族的受试者超过三个，这当然意味着必须删除一个或多个受试者（即他们没有被分配到两个子样本中的任何一个）。
考虑这个例子给你一个更好的直觉：



主题
家庭
年龄
性别
动作




1
a
24
1
0.75


2
a
12
0
0.32


3
a
23
1
0.87


4
b
13
1
0.65


5
b
40
0
0.11


6
c
23
1
0.2



如您所见，三个受试者来自家庭“a”，两个受试者来自家庭“b”，一个受试者来自家庭“c”。对于家庭“a”，我们可能希望选择受试者 1 作为第一个子样本，受试者 3 作为第二个子样本，并删除受试者 2。受试者 4 和 5 也必须分配给每个子样本，因为它们来自同一个家庭“b”。最后，主题 6 与样本中的任何人都不相关，因此我们可以自由地将其分配给任何子样本。]]></description>
      <guid>https://stats.stackexchange.com/questions/654081/split-up-sample-into-two-sub-samples-while-ensuring-that-subjects-in-sub-samples</guid>
      <pubDate>Mon, 09 Sep 2024 09:47:23 GMT</pubDate>
    </item>
    <item>
      <title>结构向量自回归：$(𝐾^2−𝐾)/2$限制和可识别性的证明？</title>
      <link>https://stats.stackexchange.com/questions/654080/structural-vector-autoregression-proof-of-the-2%e2%88%92-2-restrictions-and-id</link>
      <description><![CDATA[我目前正在使用 Kevin Kotzé 的结构向量自回归模型来学习向量自回归。其中一点如下：

我们需要施加的限制数量相当于 B 矩阵下三角（或上三角）中的项数，即 $(K^2-K)/2$

其中我们的模型是以下 VAR(1)（$y_t$ 是变量的 K 维向量）：
$B y_t = \Gamma_0 + \Gamma_1 y_{t-1} + \varepsilon_t$，这导致以下简化形式的 VAR：
$y_t = A_0 + A_1 y_{t-1} + u_t$
在双变量情况下，这似乎是有意义的，因为 $K=2$，我们可以轻松求解方程组并找到所有结构 VAR 参数。但是，这对我来说并不完全明显：
a) 为什么 $(K^2-K)/2$ 是允许我们推断结构参数的神奇数字 - 我理解它相当于 B 的上三角。
b) 我们如何知道，给定这么多限制，我们总能求解所有结构参数。我手工计算并能够说服自己$K=2$，但目前还不清楚更高的维度是否会有类似的结果。
我想知道是否有任何证据或更严格的说明来说明为什么这个结果对所有$K$都成立。
另请参阅我在 Economics Stack Exchange 上得到的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/654080/structural-vector-autoregression-proof-of-the-2%e2%88%92-2-restrictions-and-id</guid>
      <pubDate>Mon, 09 Sep 2024 09:43:28 GMT</pubDate>
    </item>
    <item>
      <title>条件逻辑模型与时间离散生存模型</title>
      <link>https://stats.stackexchange.com/questions/654078/a-conditional-logistic-model-vs-time-discrete-survival-model</link>
      <description><![CDATA[我认为，当时间具有离散格式时，条件逻辑模型和 Cox 比例风险之间存在区别。但是，根据 R 中的 coxph {survival} 和以下出版物，他们似乎认为这两种方法是等效的。如果您能对此作出澄清，我将不胜感激。
Lachin，JM 使用**条件逻辑（离散 Cox PH）**回归模型的评分检验对多重匹配病例对照研究进行样本量评估。Stat Med。2008 

此外，在 R 中的生存包中，提到
使用“精确偏似然”方法，Cox 偏似然等同于匹配逻辑回归的偏似然。 （clogit 函数使用 coxph 代码进行拟合。）当时间尺度是离散的并且只有几个唯一值时，它在技术上是合适的，一些
包将此称为“离散”选项。还有一个由 Prentice 提出的“精确边际似然”，但这里没有实现。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654078/a-conditional-logistic-model-vs-time-discrete-survival-model</guid>
      <pubDate>Mon, 09 Sep 2024 08:46:14 GMT</pubDate>
    </item>
    <item>
      <title>当相关固定效应不显著时，随机斜率是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/654075/is-random-slope-meaningful-when-the-relevant-fixed-effect-is-not-significant</link>
      <description><![CDATA[我正在使用以下语法构建一个线性混合模型：
y ~ run + (1 + run |subjects)

摘要如下：

run的固定效应不显著。
我想知道不同受试者的run的随机斜率是否有意义。我想利用不同受试者的这些斜率来与其他受试者的特征相关联。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654075/is-random-slope-meaningful-when-the-relevant-fixed-effect-is-not-significant</guid>
      <pubDate>Mon, 09 Sep 2024 08:08:54 GMT</pubDate>
    </item>
    <item>
      <title>估计 OLS 回归中的相关特征</title>
      <link>https://stats.stackexchange.com/questions/654074/estimating-correlated-features-in-ols-regression</link>
      <description><![CDATA[我获得了由其他人拟合的以下 OLS 的相当大的 $y$ 和 ${\beta}_{i}$ 样本集：
$y$ = $\sum({\beta}_{i} x_i)$ + α + ε
我想估计 $x_i$（例如 $\hat{x_i}$）。假设原始模型的作者在拟合上述模型方面做得不错，我是否正确地使用以下方法估计$\hat{x_i}$：
$\hat{x_i}$ = $\frac{Cov({\beta}_{i}, y)}{Var({\beta}_{i})}$
如果有人告诉我，对于所有i, j，$Corr(x_i,x_j) \neq 0$，即$\hat{x_i}$ 是有偏差的，即存在多重共线性class=&quot;math-container&quot;&gt;$x_i$。如果这是有偏差的，那么获得 $\hat{x_i}$ 的最佳方法是什么？
如果 $mean(\alpha) = 0$（或不）会发生什么？
可以安全地假设不存在缩放问题，即 x 和 y 在同一尺度上。然而，它们是肥尾的。]]></description>
      <guid>https://stats.stackexchange.com/questions/654074/estimating-correlated-features-in-ols-regression</guid>
      <pubDate>Mon, 09 Sep 2024 07:42:02 GMT</pubDate>
    </item>
    <item>
      <title>分位数回归用于比较不同时间点的两个群体</title>
      <link>https://stats.stackexchange.com/questions/654073/quantile-regression-to-compare-two-populations-at-different-time-points</link>
      <description><![CDATA[我试图比较两个不同人群（例如 2001 年和 2011 年）在同一变量上的表现。它们是不同的、独立的人群（这不是纵向研究；而是代表该人群的两个横断面研究）。我们已经计算了适用于两个样本的抽样权重。
我想知道我的方法是否正确：我想使用分位数回归检查我的变量是否从 2001 年到 2011 年在不同百分位数上发生了变化。
我的问题如下：

使用 R，我可以在分位数回归中使用这些预先计算的样本权重变量吗？

如果我根据性别对样本进行分层，我不再需要在回归模型中控制性别？


提前非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654073/quantile-regression-to-compare-two-populations-at-different-time-points</guid>
      <pubDate>Mon, 09 Sep 2024 07:24:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么较小的权重有助于泛化？</title>
      <link>https://stats.stackexchange.com/questions/654067/why-does-having-a-smaller-set-of-weight-help-with-generalization</link>
      <description><![CDATA[当我第一次学习机器学习时，我了解到我们需要使用 l2 正则化来提高泛化能力。原因基于 Chris Bishop 教科书中的多项式回归实验，作者展示了过度拟合的多项式的权重具有较大的权重，这将对测试数据产生错误的预测（这里的论点是，较大的权重将与数据相乘得到一个较大的预测）。正则化将降低权重的大小。
但是，这种（较小的权重 = 更好的泛化）见解是否真的可以推广到多项式回归的范围之外？例如，具有较小权重的神经网络必须表现更好吗？即使在多项式回归的背景下，我也不太确定。例如，我想将百万富翁的年龄与他们的收入联系起来。我的权重必须很大。小权重在这里实际上没有意义。
同样的论点出现在关于双下降和隐式正则化的文献中。据说双下降法有效，因为 SGD 隐式地在过度参数化的状态下找到了最小范数权重。但问题又来了：为什么小的权重集可以转化为更好的泛化？
有人可以对此发表意见吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654067/why-does-having-a-smaller-set-of-weight-help-with-generalization</guid>
      <pubDate>Mon, 09 Sep 2024 02:07:10 GMT</pubDate>
    </item>
    </channel>
</rss>