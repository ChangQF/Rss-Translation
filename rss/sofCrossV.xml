<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 15 Sep 2024 06:21:41 GMT</lastBuildDate>
    <item>
      <title>如果误差是同质的但非正态的，那么线性估计量可以是蓝色吗？</title>
      <link>https://stats.stackexchange.com/questions/654388/if-the-errors-are-homogenous-but-non-normal-can-the-linear-estimator-be-blue</link>
      <description><![CDATA[在高斯-马尔可夫假设下，OLS 为 BLUE 的要求是：

线性：估计量必须是数据的线性函数
无偏性：估计量的预期值应等于总体参数
同方差性：误差方差为常数
无完美多重共线性：解释变量不应完全共线。
外生性：误差应为零均值，且与解释变量不相关。

这是否意味着只要满足这些假设，无论误差分布如何，OLS 估计量都是 BLUE？
我有时读到误差必须呈正态分布才能为 BLUE。我有时读到如果不是，也没关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/654388/if-the-errors-are-homogenous-but-non-normal-can-the-linear-estimator-be-blue</guid>
      <pubDate>Sun, 15 Sep 2024 06:12:25 GMT</pubDate>
    </item>
    <item>
      <title>理解简单线性回归误差方差与 Y 的比较符号</title>
      <link>https://stats.stackexchange.com/questions/654387/understanding-notation-of-simple-linear-regression-error-variance-compared-with</link>
      <description><![CDATA[在简单线性回归中，不假设条件形式，我们说$Var(\epsilon) = \sigma^2$，因为误差方差是同质的。
但我不明白为什么会这样。
$Var(\epsilon) = E[Y - \beta x] = E[Y - \hat{Y}]$
但这似乎不等于 Y 的方差。
这只是符号上的差异吗？误差方差是 Y 中无法解释的方差。Y 的方差是无法解释和解释的方差的总和。
那么我们是不是只想说误差项与 $Y$ 中的方差成比例，因为这个方差是导致误差围绕 $\beta x$ 的因素？]]></description>
      <guid>https://stats.stackexchange.com/questions/654387/understanding-notation-of-simple-linear-regression-error-variance-compared-with</guid>
      <pubDate>Sun, 15 Sep 2024 04:32:29 GMT</pubDate>
    </item>
    <item>
      <title>什么是移动平均模型（真的！）</title>
      <link>https://stats.stackexchange.com/questions/654385/what-is-a-moving-average-model-really</link>
      <description><![CDATA[一段时间以来，我一直在尝试理解时间序列环境中的移动平均模型是什么。
我知道它本质上是基于过去预测误差的回归，形式如下：https://otexts.com/fpp3/MA.html（请参阅本文第 3 行）。
我很难理解的是 - 这些过去的预测误差到底是什么？或者更具体地说，这些过去预测误差中的预测元素的性质是什么？例如，它只是目标时间序列到给定点的移动平均值吗？还是别的什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654385/what-is-a-moving-average-model-really</guid>
      <pubDate>Sun, 15 Sep 2024 02:51:16 GMT</pubDate>
    </item>
    <item>
      <title>当似然函数本身是一个猜测时</title>
      <link>https://stats.stackexchange.com/questions/654383/when-the-likeihood-function-is-itself-a-guess</link>
      <description><![CDATA[当存在观测值 x 和相关未知数 $T$，但没有明显的 $f(x \mid T)$ 模型时，贝叶斯会做什么？我举的例子是在商业领域，专家报告了新商业理念未来现金流的当前估值。在硬科学中是否有类似的例子，历史数据允许我们估计不同 $x$ 和 $T$ 的经验似然分布 $f(x \mid T)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/654383/when-the-likeihood-function-is-itself-a-guess</guid>
      <pubDate>Sat, 14 Sep 2024 23:35:47 GMT</pubDate>
    </item>
    <item>
      <title>回归线是否也在更多维度中穿过质心？</title>
      <link>https://stats.stackexchange.com/questions/654378/regression-lilne-goes-through-the-center-of-mass-also-in-more-dimensions</link>
      <description><![CDATA[众所周知，我也找到了证据（比如这里 https://math.stackexchange.com/questions/635670/show-that-the-least-squares-line-must-pass-through-the-center-of-mass），在简单线性回归中，回归线总是经过质心。但我没有找到任何证据将其推广到我们具有一般数量的协变量 $p$ 的情况。
它成立吗？如果成立，有证据吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654378/regression-lilne-goes-through-the-center-of-mass-also-in-more-dimensions</guid>
      <pubDate>Sat, 14 Sep 2024 18:33:35 GMT</pubDate>
    </item>
    <item>
      <title>零假设取决于数据，我可以以某种方式惩罚 p 值吗？</title>
      <link>https://stats.stackexchange.com/questions/654376/null-hypothesis-depend-on-data-can-i-penalize-the-p-value-somehow</link>
      <description><![CDATA[亲爱的 Stack Exchange 社区，
假设我有一个测量值 $k_i$（虽然它是一个整数，但与问题并不真正相关）。我对 $k_i$ 有一个零假设，这是一个依赖于单个参数 $\mu$ 的分布。这样，我就可以为我的观察结果 $k_i$ 计算一个 p 值。
问题在于，参数 $\mu$ 是使用 $k_i$ 以及其他观察结果（即 $\mu(k_1, .., k_i, .., k_n)$）进行估计的。由于使用了其他观测值，我预计 $\mu$ 和 $k_i$ 不会有很强的依赖性，但这样计算出的 p 值仍然不正确，因为零假设本身会（但愿是微弱地）依赖于观测值 $k_i$。
是否存在标准的分析或半分析方法，即使是近似的？我希望找到一种方法，只使用 $\mu$ 计算 p 值，然后找到一个惩罚它的配方，即使用某个公式来降低它。经过一番研究，我找不到类似的东西。
我知道引导或基于玩具 MC 的方法可能有用，但我正在寻找一种处理这个问题的分析方法。
提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/654376/null-hypothesis-depend-on-data-can-i-penalize-the-p-value-somehow</guid>
      <pubDate>Sat, 14 Sep 2024 18:19:42 GMT</pubDate>
    </item>
    <item>
      <title>R 中具有一个随机截距的线性混合模型的 lme4 结果的数学再现和理解</title>
      <link>https://stats.stackexchange.com/questions/654375/mathematical-reproduction-and-understanding-of-lme4-results-for-linear-mixed-mod</link>
      <description><![CDATA[本文的目的是用数学方法重现 lmer 给出的以下线性混合模型的结果。
假设我们有 $n$ 个测试对象。对于每个测试对象 $i \in \{1, \ldots, n\}$，我们重复测量两个量 $x$ 和 $y$，测量次数为 $j \in \{1, \ldots, n_i\}$ 次。每个这样的测量值用 $y_{ij}$ 和 $x_{ij}$ 表示。我们对每个测试对象执行具有随机截距的线性混合模型：
\begin{equation*}
y_{ij} = \alpha + \beta x_{i,j} + u_i + \epsilon_{i,j}
\end{equation*&gt;
在方程中，像往常一样，$u_i$ 被认为是独立同分布的 $N(0,\sigma_u^2)$ 随机变量，而 $\epsilon_{i,j}$ 是独立同分布的 $N(0,\sigma_{\epsilon}^2)$ 随机变量，与 $u_i$。要估计的未知实参数是 $\alpha$、$\beta$、$\sigma_u$ 和 $\sigma_{\epsilon}$。
目标是使用已知数据 $x_{ij}$ 和 $y_{ij}$ 来估计 ... class=&quot;math-container&quot;&gt;$\sigma_{\epsilon}$。由于我们一直感兴趣的是 $x$ 是否对 $y$ 有影响，因此我们需要对 $\beta = 0$ 是否也进行假设检验。
要以编程方式执行此操作，让我们使用 sleepstudies 数据集，其中 $x_{ij}$ 为数字天数，$y_{ij}$ 为反应。此数据集恰好是平衡的，因此让我们通过删除两行来使其不平衡。这是可运行的代码：（版本无关紧要，但为了完整起见，我们在此处标明 lme4_1.1-34)
library(lme4)

df &lt;- sleepstudy
df$Days &lt;- as.numeric(sleepstudy$Days)
df$Subject &lt;- as.factor(sleepstudy$Subject)
df &lt;- df[-c(50, 100), ]

result &lt;- lmer(Reaction ~ Days + (1 | Subject), df)
print(summary(result))

结果是：
警告消息：
&quot;package &#39;lme4&#39; was Built在 R 版本 4.3.1 下&quot;
加载所需包：Matrix

警告消息：
&quot;包 &#39;Matrix&#39; 是在 R 版本 4.3.1 下构建的&quot;
REML [&#39;lmerMod&#39;] 拟合的线性混合模型
公式：反应 ~ 天数 + (1 | 受试者)
数据：df

收敛时的 REML 标准：1766.5

缩放残差：
最小 1Q 中位数 3Q 最大值
-3.1938 -0.5299 0.0300 0.5329 4.2588

随机效应：
组名称方差标准差
受试者（截距） 1336.0 36.55 
残差 961.7 31.01 
观察数：178，组：受试者，18

固定效应：
估计标准差误差 t 值
（截距）251.9298 9.6343 26.15
天数 10.2705 0.8171 12.57

固定效应相关性：
（截距）
天数 -0.377

通过运行 lm(Reaction ~ Days)，执行普通最小二乘法，我们看到，正如所期望的那样，他们使用普通最小二乘法估计 $\alpha$ 和 $\beta$，其中 $\hat{\alpha} = 251.4051$ 和 $\hat{\beta} = 10.4673$。
现在问题来了。无论我做什么，我都无法找到令人满意的直接数学参考来说明本例中条目 Std. Error 的公式。并且，作为结果或原因，我找不到为什么 $\hat{\sigma_u} = 36.55$ 和 $\hat{\sigma_u} = 31.01$。我尝试计算几个相关的平方误差，但没有一个达到 lmer 提供的值。有什么数学表达式？]]></description>
      <guid>https://stats.stackexchange.com/questions/654375/mathematical-reproduction-and-understanding-of-lme4-results-for-linear-mixed-mod</guid>
      <pubDate>Sat, 14 Sep 2024 18:09:50 GMT</pubDate>
    </item>
    <item>
      <title>处理训练数据中没有缺失值的特征在测试数据中的缺失值</title>
      <link>https://stats.stackexchange.com/questions/654374/handling-missing-values-of-a-feature-in-test-data-that-had-no-missing-values-in</link>
      <description><![CDATA[Kaggle 上的泰坦尼克号 - 灾难机器学习竞赛数据集中有一个名为“票价”的数字特征。
训练数据中的“票价”没有缺失值，但测试数据中有缺失值。我知道如何处理测试数据中缺失值的特征，这些特征在训练数据中也有缺失值，但这对我来说是第一次，我找不到如何解决的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/654374/handling-missing-values-of-a-feature-in-test-data-that-had-no-missing-values-in</guid>
      <pubDate>Sat, 14 Sep 2024 17:55:31 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助理解两个分布的卷积</title>
      <link>https://stats.stackexchange.com/questions/654372/help-needed-in-understanding-the-convolution-of-two-distributions</link>
      <description><![CDATA[我正在阅读 Sheldon Ross 所著的《概率模型导论》第 12 版。第 57 页写道：

当 $X$ 和 $Y$ 独立时，能够根据 $X$ 和 $Y$ 的分布计算出 $X + Y$ 的分布通常很重要。首先假设$X$和$Y$是连续的，$X$的概率密度为$f$，而$Y$的概率密度为$g$。然后，让 $F_{X+Y}(a)$ 成为 $X + Y$ 的累积分布函数，我们有
$$ F_{X+Y}(a) = P(X + Y \leq a) $$
$$ = \int_{x+y \leq a} f(x) g(y) \, dx \, dy $$
$$ = \int_{-\infty}^{\infty} f(x) \left( \int_{-\infty}^{a - x} g(y) \, dy \right) dx $$
$$ = \int_{-\infty}^{\infty} F_Y(a - x) f(x) \, dx $$
累积分布函数 $F_{X+Y}$ 被称为分布 $F_X$ 和 $F_Y$ 的卷积（分别为 $X$ 和 $Y$ 的累积分布函数）。


但是，我们必须注意，$X+Y$ 是一个随机变量。我认为$X+Y$不一定是连续的。它也可能是离散的。设$Z=X+Y.$
如果$Z$是连续的，那么我们假设$f_{Z}$是概率密度函数。在此假设下，我们必须有，$P\{Z\leq a\}=P\{X+Y\leq a\}=\int_{-\infty}^af_Z(z)dz.$
如果$Z$是离散的，那么我们假设$F_Z$和$p_z$分别是$Z$的累积分布函数和概率质量函数。在这个假设下，我们有，$P\{Z\leq a\}=F_Z(a)=\sum_{x\leq a:p(x)&gt;0}p(x).$
但我不明白他们怎么写这个等式，

$$ F_{X+Y}(a) = P(X + Y \leq a) $$
$$ = \int_{x+y \leq a} f(x) g(y) \, dx \, dy $$
$$ = \int_{-\infty}^{\infty} f(x) \left( \int_{-\infty}^{a - x} g(y) \, dy \right) dx $$
$$ = \int_{-\infty}^{\infty} F_Y(a - x) f(x) \, dx $$

你能帮我理解一下，他们是怎么写出上面的等式的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654372/help-needed-in-understanding-the-convolution-of-two-distributions</guid>
      <pubDate>Sat, 14 Sep 2024 16:34:57 GMT</pubDate>
    </item>
    <item>
      <title>关于双重稳健估计量的假设</title>
      <link>https://stats.stackexchange.com/questions/654344/assumption-about-doubly-robust-estimator</link>
      <description><![CDATA[设 $X, Y$ 为两个独立的非负连续随机变量。设 $R :=I(X &lt; Y)$。设 $Z$ 为任意随机变量。假设 $X\perp Y \mid Z$。
可以将 $R$ 视为缺失变量指标。如果 $R=1$，即 $I(X &lt; Y) = 1$，我们观察到 $X$，否则我们不会观察到 $X$。
设 $\pi^*(Z) = P(R=1\mid Z)$，且 $h^*(Z) = E(X\mid R=1, Z)$。设 $\pi(Z),h(Z)$ 为 $Z$ 的任意函数。考虑以下数量
$$
E\left(\left\{\frac{R - \pi(Z)}{\pi(Z)}\right\} [X - h(Z)]\right),
$$
众所周知，在条件$X\perp R\mid Z$下，当$\pi(Z) = \pi^*(Z)$或$h(Z) = h^*(Z)$时，该数量等于$0$。
但是，如果我们只有$X\perp Y \mid Z$呢？我们仍然具有相同的属性吗？有一件事我很确定，那就是 $X\perp Y \mid Z$ 并不意味着 $X\perp R\mid Z$。]]></description>
      <guid>https://stats.stackexchange.com/questions/654344/assumption-about-doubly-robust-estimator</guid>
      <pubDate>Fri, 13 Sep 2024 22:28:02 GMT</pubDate>
    </item>
    <item>
      <title>现实世界中的数据在统计意义上是“抽样的”吗？</title>
      <link>https://stats.stackexchange.com/questions/654255/are-data-in-the-real-world-sampled-in-the-statistical-sense</link>
      <description><![CDATA[在机器学习中，通常假设样本是根据某种概率分布独立同分布生成的。关于独立同分布假设在统计学习中的重要性
基本假设是存在某种分布/pdf/cdf/pmf $f_X$ 并且 $f_X$ 可以采样。
$$X \sim f_X(x)$$
我的问题很简单，即这个数学假设如何模拟我们在现实世界中的经验或数据科学和机器学习中产生的应用。
当我们说样本是从分布中抽取的，这在现实世界中意味着什么？
例如，如果我想对猫和狗的图片进行分类，我会通过拿出我的 iphone 16 并拍摄一些猫和狗的照片来生成我的数据集。
我看不出按下我的 iphone 上的按钮这个简单动作如何等同于从某个概率分布中进行采样的过程。
我可以使用概率分布$f_X$在数学上描述相机的动作吗？不。我甚至梦想写下与猫或狗图像相关的概率密度函数$f_X$吗？不可能。除了最简单/最琐碎的数据集外，概率分布 $f_X$ 的存在对于所有数据集都是可疑的。
那么机器学习中试图建模的抽样假设是什么？为什么不从“假设我们有一些示例的数据集”开始，并省略抽样假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/654255/are-data-in-the-real-world-sampled-in-the-statistical-sense</guid>
      <pubDate>Thu, 12 Sep 2024 09:19:04 GMT</pubDate>
    </item>
    <item>
      <title>通过python进行线性混合效应模型分析</title>
      <link>https://stats.stackexchange.com/questions/654156/linear-mixed-effect-model-analysis-via-python</link>
      <description><![CDATA[我想对我的研究进行线性混合效应分析。我试图了解和比较 3 种不同的干预模式对结果的影响。我对结果有 2 个衡量指标，即事前分析和事后分析。
我使用 Python 代码，但当我将其与 SPSS 结果进行比较时，结果大不相同。我想知道我是否使用了正确的代码。
这是我的变量
DV：ACC
IV：组（3），时间（2）
协变量：性别，年龄，受教育年限。
性别，组和时间是分类变量。
我使用了下面的代码
model = smf.mixedlm(
&quot;ACC ~ C(Time) * C(Group) + Age + C(Sex) + Education years&quot;, 
data, 
groups=data[&quot;ID&quot;]
)
result = model.fit()

您觉得如何？我应该做些改变吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654156/linear-mixed-effect-model-analysis-via-python</guid>
      <pubDate>Tue, 10 Sep 2024 13:34:28 GMT</pubDate>
    </item>
    <item>
      <title>我该如何从“杠杆效应”的角度解释下面的 GJR-GARCH 模型？</title>
      <link>https://stats.stackexchange.com/questions/612999/how-can-i-interpret-the-below-gjr-garch-model-in-terms-of-leverage-effects</link>
      <description><![CDATA[我是这里的新手，很难解释该模型。请用通俗易懂的语言帮助我。
 AR - GJR-GARCH 模型结果 
==================================================================================================
Dep. 变量：GD R 平方：-0.003
均值模型：AR Adj。 R 平方：-0.004
Vol 模型：GJR-GARCH 对数似然：-3572.12
分布：标准化学生 t AIC：7168.24
方法：最大似然 BIC：7236.93
观测数：2261
日期：2023 年 4 月 15 日星期六 Df 残差：2257
时间：07:18:04 Df 模型：4
均值模型
========================================================================================
coef std err t P&gt;|t| 95.0% Conf.整数
-----------------------------------------------------------------------------------------
常数 0.0688 2.281e-02 3.017 2.555e-03 [2.411e-02, 0.114]
GD[1] -0.0134 2.114e-02 -0.635 0.526 [-5.485e-02,2.801e-02]
GD[2] -0.0327 2.011e-02 -1.626 0.104 [-7.210e-02,6.716e-03]
GD[3] 6.0716e-03 1.971e-02 0.308 0.758 [-3.255e-02,4.470e-02]
波动率模型
=====================================================================================
coef std err t P&gt;|t| 95.0% Conf. Int.
-----------------------------------------------------------------------------------------
omega 0.1078 4.361e-02 2.473 1.341e-02 [2.236e-02, 0.193]
alpha[1] 0.0322 1.903e-02 1.691 9.074e-02 [-5.108e-03,6.947e-02]
alpha[2] 4.1672e-14 1.602e-02 2.602e-12 1.000 [-3.139e-02,3.139e-02]
gamma[1] 0.0394 2.891e-02 1.364 0.172 [-1.722e-02,9.611e-02]
gamma[2] 0.1528 3.636e-02 4.202 2.651e-05 [8.151e-02, 0.224]
beta[1] 9.4508e-03 4.481e-02 0.211 0.833 [-7.837e-02,9.727e-02]
beta[2] 0.7992 5.555e-02 14.386 6.313e-47 [ 0.690, 0.908]
分布
===============================================================================
coef std err t P&gt;|t| 95.0% Conf. Int.
------------------------------------------------------------------------------------
nu 5.2877 0.574 9.215 3.121e-20 [ 4.163, 6.412]
===============================================================================

我在网上读了很多文章或论文，得出以下结论。但不确定我是否正确。
这里，gamma[1] 的 p 值为 0.172（大于 0.05），因此 gamma[1] 在统计上不显著，我们无法得出存在显著杠杆效应的结论。
但是，gamma[2] 的 p 值小于 0.05，表明 gamma[2] 具有统计显著性。
因此，我们可以得出结论，该模型已经捕获了显著的杠杆效应。
此外，我想编写一个通用代码，其中包含所有场景，例如，

如果 gamma[1] 为 +ve 而 gamma[2] 为 -ve，会怎样？
如果模型中有 n 个 gamma，那么我可以采用相同的方法吗？
如果我们有 n 个 gamma，并且它们是 +ve 和 -ve 的组合，那么我们如何得出结论？
]]></description>
      <guid>https://stats.stackexchange.com/questions/612999/how-can-i-interpret-the-below-gjr-garch-model-in-terms-of-leverage-effects</guid>
      <pubDate>Sat, 15 Apr 2023 07:48:42 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何测试可以检查时间序列中的方差平稳性？</title>
      <link>https://stats.stackexchange.com/questions/585189/is-there-any-test-to-check-variance-stationarity-in-time-series</link>
      <description><![CDATA[问题很简单：是否有任何测试可以检查时间序列中的方差平稳性（同方差性）？
如果存在，其在 R 或 Python 中的实现是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/585189/is-there-any-test-to-check-variance-stationarity-in-time-series</guid>
      <pubDate>Thu, 11 Aug 2022 14:44:59 GMT</pubDate>
    </item>
    <item>
      <title>将来自不同交叉验证轮次的样本外预测堆叠起来可以吗？</title>
      <link>https://stats.stackexchange.com/questions/579007/is-it-o-k-to-stack-out-of-sample-predictions-from-separate-cross-validation-rou</link>
      <description><![CDATA[我正在应用 Lasso 回归和 R 函数 glmnet::cv.glmnet() 来获得基于 90% 数据的预测模型。我已将 10% 留作保留集，并获得保留集的预测概率。我对我的数据的每个 90%-10% 分割重复此操作（10 倍交叉验证）。这为我提供了数据中每个观察值的预测值。每个预测值都是使用训练数据从模型拟合中获得的，其中不包括该观察值。
我运行 20 次 10 倍交叉验证，以获得每个观察值的 20 个样本外预测值。换句话说，我有 20 个预测值向量，每个向量的长度与数据中的观察值数量相同。
这样可以吗？将这 20 个向量对应的预测误差（或每个观测值的 20 个预测值的平均值和标准差）与某些特征变量（例如年龄）绘制在一起，以展示我的模型对不同年龄段的人的新数据的预期预测性能？这可能表明老年人的预测更不确定。我觉得这非常有用，但我在文章中没有看到过这样的图表吗？
如果我将来自几个单独的交叉验证轮次的预测组合起来并将它们堆叠在一起，如上所述，我是否可能忽略了一些微妙的重要问题？我会假设来自同一交叉验证拆分的预测是相关的，但我不确定是否需要考虑这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/579007/is-it-o-k-to-stack-out-of-sample-predictions-from-separate-cross-validation-rou</guid>
      <pubDate>Thu, 16 Jun 2022 12:55:04 GMT</pubDate>
    </item>
    </channel>
</rss>