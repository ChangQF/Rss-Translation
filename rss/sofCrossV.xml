<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 14 Jan 2025 15:17:04 GMT</lastBuildDate>
    <item>
      <title>对随机截距多层模型进行独立性卡方检验</title>
      <link>https://stats.stackexchange.com/questions/660013/running-a-chi-square-of-independence-test-preliminary-to-the-random-intercept-mu</link>
      <description><![CDATA[我执行了随机截距多级模型，并遇到了以下问题：
优化器 (Nelder_Mead) 收敛代码：4（10000 次评估中无法收敛）
无法评估缩放梯度
模型无法收敛：退化 Hessian 具有 2 个负特征值
10000 次评估中无法收敛

进一步检查后，它们包括多重共线性和异常值问题，我相信在模型之前运行独立卡方将有助于解决这些问题。我正在尝试修复模型，并认为在模型之前运行独立卡方可能有助于解决与上述相关的一些问题。之前我问过二进制是否需要这样做，并被告知在二进制之前不需要运行它。然而，Beacom 2023 强调，在二元逻辑之前运行独立卡方有助于研究人员识别关联，并且只在模型中包含具有关联的变量，而如果包含这些变量，则可能导致数学上不稳定的结果。
例如，我遇到过一些预测因子只有一个响应的情况，因此我怀疑部分原因（多重共线性和异常值）。我相信它们没有任何影响，因此不应该成为模型的一部分，而运行卡方有助于解决这个问题。因此，问题是在 MLM 之前运行卡方检验是否可以接受？]]></description>
      <guid>https://stats.stackexchange.com/questions/660013/running-a-chi-square-of-independence-test-preliminary-to-the-random-intercept-mu</guid>
      <pubDate>Tue, 14 Jan 2025 14:39:22 GMT</pubDate>
    </item>
    <item>
      <title>通过 RKHS 实现的 SVM 解决方案的平滑度</title>
      <link>https://stats.stackexchange.com/questions/660011/smoothness-of-svm-solution-via-rkhs</link>
      <description><![CDATA[我试图将 RKHS 的 SVM 视图与 SVM 解决方案的平滑性联系起来：
经典原始函数由以下公式给出：
\begin{aligned}
\text{最小化} \quad &amp; \frac{1}{2} \|\mathbf{w}\|^2, \quad \mathbf{w} \in \mathbb{R}^d, \, b \in \mathbb{R}, \\
\text{受制于} \quad &amp; y_i (\mathbf{w}^\top \mathbf{x}_i + b) \geq 1, \quad i = 1, \dots, n, \\
&amp; \mathbf{x}_i \in \mathbb{R}^d, \, y_i \in \{-1, 1\}。
\end{aligned&gt;
我们知道：
$\mathbf{w} = \sum_{i=1}^n \alpha_i y_i \mathbf{x}_i$
现在使用内核 $k$ 和一些相关特征图 $\phi(x$) 进行重构
$\mathbf{w} = \sum_{i=1}^n \alpha_i y_i \phi(\mathbf{x}_i)$
$\|\mathbf{w}\|^2 = \mathbf{w}^\top \mathbf{w} = \sum_i \sum_j \alpha_i \alpha_j y_i y_j \phi(\mathbf{x}_i)^\top \phi(\mathbf{x}_j)
= \sum_i \sum_j \alpha_i \alpha_j y_i y_j k(\mathbf{x}_i, \mathbf{x}_j)
= \|f\|^2_{H}.$
因此最小化 $||\mathbf{w}||$ 与最小化 $||f||_H$ 相同。
并且由于对于任何 $f \in H$ 和任意对 $x,x&#39; \in X$
$
|f(\mathbf{x}) - f(\mathbf{x}&#39;)| = |\langle f, K_{\mathbf{x}} - K_{\mathbf{x}&#39;} \rangle_{H}|
\leq \|f\|_{H} \cdot \|K_{\mathbf{x}} - K_{\mathbf{x}&#39;}\|_{H}
= \|f\|_{H} \cdot d_K(\mathbf{x}, \mathbf{x}&#39;),
$
$||f||_H$ 在某种程度上控制了平滑度。那么，这是否是 SVM 优化平滑解决方案的一个论点？]]></description>
      <guid>https://stats.stackexchange.com/questions/660011/smoothness-of-svm-solution-via-rkhs</guid>
      <pubDate>Tue, 14 Jan 2025 14:11:39 GMT</pubDate>
    </item>
    <item>
      <title>带有附加预测因子的 OLS 问题，比较系数</title>
      <link>https://stats.stackexchange.com/questions/660010/ols-question-with-additional-predictor-compare-coefficients</link>
      <description><![CDATA[给定$Corr(Y, X_1) &gt; 0$，$Corr(Y, X_2) = 0$，$Corr(X_1, X_2) &gt; 0$。考虑 2 个回归：
$Y = a X_1 + \epsilon$
$Y = b_1 X_1 + b_2 X2 + \epsilon$
$a$ 和 $b_1$ 哪个更大？
我的工作：我通过正则方程进行计算，得到 $b_1 = \frac{a}{1-Corr(X_1,X_2)}$，这意味着 $b_1$ 应该更大（这是假设每个变量都以 0 为中心并且方差为 1）。
但这似乎违反直觉，我预计会变成由于 $X_2$ 没有添加有关 $Y$ 的（线性）信息，因此结果相同。
有人可以提供解决方案并解释我上述哪些矛盾方法是错误的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660010/ols-question-with-additional-predictor-compare-coefficients</guid>
      <pubDate>Tue, 14 Jan 2025 14:00:03 GMT</pubDate>
    </item>
    <item>
      <title>CDC 称女性的平均性伴侣数量为 4.3。这是怎么回事？[重复]</title>
      <link>https://stats.stackexchange.com/questions/660008/cdc-says-median-number-of-sexual-partners-a-woman-has-is-4-3-how-can-this-be</link>
      <description><![CDATA[https://www.cdc.gov/nchs/nsfg/key_statistics/n-keystat.htm
根据 CDC 的数据，女性性伴侣数量的中位数为 4.3。但这怎么可能呢？中位数可以是 4、5 或 4.5，但怎么会是 4.3？CDC 搞错了吗？还是他们对中位数使用了不同的估计量？如果是这样，他们使用的是什么估计量？]]></description>
      <guid>https://stats.stackexchange.com/questions/660008/cdc-says-median-number-of-sexual-partners-a-woman-has-is-4-3-how-can-this-be</guid>
      <pubDate>Tue, 14 Jan 2025 13:43:50 GMT</pubDate>
    </item>
    <item>
      <title>对序数、相关特征进行降维，并附加连续特征</title>
      <link>https://stats.stackexchange.com/questions/660005/dimension-reduction-on-ordinal-related-features-with-additional-continuous-feat</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660005/dimension-reduction-on-ordinal-related-features-with-additional-continuous-feat</guid>
      <pubDate>Tue, 14 Jan 2025 13:26:13 GMT</pubDate>
    </item>
    <item>
      <title>例如，I(X;Y|Z) < I(X;Y)</title>
      <link>https://stats.stackexchange.com/questions/660001/example-where-ixyz-ixy</link>
      <description><![CDATA[我问自己是否有可能$I(X;Y|Z)&lt;I(X;Y)$。起初这看起来很奇怪，因为知道$Z$的值怎么会导致$Y$提供的$X$信息比$Z$未知时提供的少。
然后我进入维基百科，我发现这是可能的。 $I(X;Y|Z)$ 可以等于、小于或大于 $I(X;Y)$。$I(X;Y|Z)&lt;I(X;Y)$ 背后的直觉是 $Z$ 解释了 $X$ 和 $Y$ 之间相关性的部分原因。
但是，我很难想出一个简单的例子来说明这一点。维基百科中没有数值示例，我在这个网站上也没有找到。]]></description>
      <guid>https://stats.stackexchange.com/questions/660001/example-where-ixyz-ixy</guid>
      <pubDate>Tue, 14 Jan 2025 10:01:13 GMT</pubDate>
    </item>
    <item>
      <title>对于“平均值分布”的直觉？</title>
      <link>https://stats.stackexchange.com/questions/659998/intuition-for-the-mean-value-distribution</link>
      <description><![CDATA[维基百科页面均值定理分享了这一结果：

设$X$和$Y$为非负随机变量，满足$\mathbb{E}[X] &lt; \mathbb{E}[Y] &lt; \infty$和$X \leq_{\text{st}} Y$，其中$\leq_{\text{st}}$为通常的随机顺序。然后存在一个绝对连续非负随机变量$Z$，其概率密度函数为$$f_Z(x) = \frac{\Pr [Y &gt; x] - \Pr [X &gt; x]}{\mathbb{E}[Y] - \mathbb{E}[X]}$$，其中$x \geq 0$。

维基百科文章确实引用了一篇文章，但不幸的是，我这次无法访问它。给出的证明简图如下：

设 $g$ 为可测且可微函数，使得 $\mathbb{E}[g(X)] &lt; \infty$ 和 $\mathbb{E}[g(Y)] &lt; \infty$，并设其导数 $g^{\prime}$ 在区间 $[x,y]$ 上对所有 $y \geq x \geq 0$ 可测且可黎曼积分。 $\mathbb{E}[g^{\prime}(Z)]$ 是有限的，并且 $$\mathbb{E}[g(Y)] - \mathbb{E}[g(X)] = \mathbb{E}[g^{\prime}(Z)] \left( \mathbb{E}[Y] - \mathbb{E}[X] \right).$$

我可以识别诸如 $\mathbb{E}[g^{\prime}(Z)] = f_Z(x)$、$\mathbb{E}[g(Y)] = \Pr [Y &gt; x]$，且$\mathbb{E}[g(X)] = \Pr [X &gt; x]$。
但无论$g$是什么，它都不是$\mathbb{I}[X &gt; x]$或$\mathbb{I}[Y &gt; x]$。此类指示函数并不平滑，但我们上面假设 $g$ 至少有一个一阶导数。
同样，我也不确定该如何评论或思考 $Z$。
类似于混合分布，它们是分布的函数（特别是凸组合），有一个直观的解释，除了将结果作为两个分布的函数这一简单陈述之外，我们还能对 $g$ 或 $Z$ 有更深入的理解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659998/intuition-for-the-mean-value-distribution</guid>
      <pubDate>Tue, 14 Jan 2025 04:13:41 GMT</pubDate>
    </item>
    <item>
      <title>通过置信区间计算来确定数据收集停止是否“可以”？</title>
      <link>https://stats.stackexchange.com/questions/659962/is-it-ok-to-determine-data-collection-stopping-with-confidence-interval-calcul</link>
      <description><![CDATA[我有一枚加重硬币，正面朝上的概率为 $p$。我可以随意抛这枚硬币并观察结果；我想知道 $p$ 的值是多少。我还想知道我应该抛硬币多少次才能对概率有一个合理准确的估计。
（我的问题的实际“现实世界”背景有点愚蠢——我试图确定视频游戏中某个动作成功或失败的概率；我有理由相信它是伯努利分布，我认为$p \approx 0.15$是一个非常粗略的概念。我的初始样本表明它可能低至~$0.10$或高达~$0.20$。然而，我认为“加权硬币”设置会让它更容易理解，而不会陷入游戏的细节。）
我想做的是计算威尔逊得分区间，这样我就有了一个区间，在这个区间内，我可以有 95% 的信心相信 $p$ 是在这个区间内的。然后，继续抛硬币，直到这个区间“足够窄”（实际上，我更喜欢 $p \pm 0.025$ 或更窄的区间）。
但是，我不确定反复计算这个区间并在区间窄时停止是否在统计上有效。我的数学背景相当不错，但统计是我的弱点。
有人可以澄清这是否是一种有效的方法吗？ （此外，如果我在这里提交了一个 xy 问题，并且有更好的方法来确定我需要收集多少个样本才能获得一定宽度的置信区间，我也很乐意听到这个消息！）]]></description>
      <guid>https://stats.stackexchange.com/questions/659962/is-it-ok-to-determine-data-collection-stopping-with-confidence-interval-calcul</guid>
      <pubDate>Mon, 13 Jan 2025 15:21:47 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 a/b/c 检验中的样本量（均匀和不均匀样本量分布）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659945/how-to-calculate-a-sample-size-in-a-b-c-test-equally-and-unequally-sample-size</link>
      <description><![CDATA[我正在计划进行 a/b/c 测试，以了解 ctr 参数的含义（卡方检验）。
我需要计算此测试所需的时间，我需要知道样本量。
如何计算 a/b/c 测试中的样本量：

均等样本量分布 (33,33,33)
不均等样本量分布 (50,25,25)
]]></description>
      <guid>https://stats.stackexchange.com/questions/659945/how-to-calculate-a-sample-size-in-a-b-c-test-equally-and-unequally-sample-size</guid>
      <pubDate>Mon, 13 Jan 2025 08:53:11 GMT</pubDate>
    </item>
    <item>
      <title>这个问题只能用贝叶斯来解决吗？</title>
      <link>https://stats.stackexchange.com/questions/659942/can-this-problem-only-be-solved-using-bayesian</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659942/can-this-problem-only-be-solved-using-bayesian</guid>
      <pubDate>Mon, 13 Jan 2025 04:46:48 GMT</pubDate>
    </item>
    <item>
      <title>测度论和统计学有什么联系？</title>
      <link>https://stats.stackexchange.com/questions/659932/what-is-the-connection-between-measure-theory-and-statistics</link>
      <description><![CDATA[我最近一直在温习概率和测度理论。所以我理解测度理论如何在样本空间上定义 sigma 代数，然后“测度”为 sigma 代数中的集合分配数值。但是，我很难理解概率空间中的 sigma 代数与统计学中的回归模型和回归变量之间的联系。实际上，在查看测度理论文本（如 Axler 或 Billingsly）时，作者以概率分配结束，但没有讨论统计学与测度理论的联系。
但我试图记住测度理论/概率如何正式连接到统计模型。我记得研究生院的 CLT 概念是随机变量之和为正态的，以及抽样的概念。但我正在寻找一种更数学或更正式的理解，以了解概率如何与特定的统计模型联系起来。
让我更精确一点。因此，在 sigma 代数的概念中，我们有一个集合，其中包含样本空间中的所有可能结果，以及这些结果的补集，以及可数的并集和交集。现在，在线性回归中，我们有回归变量。我只是想从精确的数学意义上理解 sigma 代数中的元素如何与回归中的回归变量相关，或者是否存在任何关系？
在线性回归中，我们的模型如下所示：
$$
\bf{Y} = XB + \epsilon 
$$
其中 $\bf{Y}$ 是结果向量，$\bf{X}$ 是包含回归变量的设计矩阵，$\bf{B}$ 是系数向量，$\bf{\epsilon}$ 是观察级误差向量。
因此，从数学意义上讲，测度论中的 sigma 代数与 $\bf{X}$ 中的变量相关，还是仅与误差项 $\bf{\epsilon}$ 相关？]]></description>
      <guid>https://stats.stackexchange.com/questions/659932/what-is-the-connection-between-measure-theory-and-statistics</guid>
      <pubDate>Sun, 12 Jan 2025 21:44:18 GMT</pubDate>
    </item>
    <item>
      <title>解决这些问题的预期方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/659930/what-is-the-expected-method-of-solving-for-these-questions</link>
      <description><![CDATA[我刚刚参加了康奈尔机器学习预测试，但以下三个问题我没有答对。
基本概率
使用你对基本概率论的了解来回答以下问题。如果你需要复习这些主题中的任何一个，请随时在互联网上搜索参考资料和示例视频。
对于问题 1-3，你将使用以下概率及其各自的标签：



特征 1
特征 2
特征3
标签




0.27
0.50
0.33
蓝色


0.33
0.65
0.10
红色
&lt; /tr&gt;

0.25
0.30
0.35
黄色


0.10
0.10
0.85
紫色



您还将假设测试点具有以下形式的特征向量：
x = [特征 1、特征 2、特征 3]
如果存在，则每个特征值等于 1，如果不存在，则等于 0。例如，根据表格，27% 的带有蓝色标签的数据具有特征 1，问题 1 可以重新表述为：给定具有特征 1 和 3 但不具有特征 2 的数据，最可能的标签是什么？
问题
1.
特征向量为 x = [1, 0, 1] 的测试点的预测标签是什么？
（提示：对存在的特征使用概率链式法则。）
您的答案：紫色
正确答案：蓝色

2.
特征向量为 x = [0, 0, 0] 的测试点的预测标签是什么？
（提示：对存在的特征使用概率链式法则。）
您的答案：黄色
正确答案：无法根据给定的数据进行预测

3.
特征向量为 x = [1, 0, 0] 的测试点的预测标签是什么？
（提示：对存在的特征使用概率链式法则。）
您的答案：黄色
正确答案：红色
我尝试解决
我假设我必须根据特征是否存在将每个特征的概率相乘，然后为每个标签乘以这个概率，然后从该过程中返回最可能的标签。例如，对于第一个具有特征向量 $(1, 0, 1)$ 的问题，我将获得：
$$ P(red) = .33 \times (1 - .65) \times .10 $$
这显然不起作用，但我不确定这里的预期是什么。提示提到了概率方法，但我不确定如何在此处应用它。从预期的答案来看，它让我认为对于任何设置为 0 的特征，它应该在计算中被忽略，即只乘以设置为 1 的特征，例如对于向量 $(1, 0, 1)$:
$$ P(red) = .33 \times .10 $$
（这种思路似乎得到了 ChatGPT 的分析支持。）
结论
解决这些问题的预期方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659930/what-is-the-expected-method-of-solving-for-these-questions</guid>
      <pubDate>Sun, 12 Jan 2025 21:06:09 GMT</pubDate>
    </item>
    <item>
      <title>最大熵是我所寻找的解决方案吗（熵的表征是否最适合我的情况）？</title>
      <link>https://stats.stackexchange.com/questions/659197/is-maximum-entropy-the-solution-i-am-looking-for-is-the-characterization-of-ent</link>
      <description><![CDATA[我的最终目标是后验预测。我讨厌做假设，也讨厌为了“稳健性”而丢弃/过滤/浪费数据。
为此，我需要弄清楚我的可能性模型。我认为最大熵原理类似于无差异原理。因为我什么都不知道，所以我不想把我的偏见放在我的模型上。
我不太喜欢做假设，但我更讨厌 Winsorizing 等。
例如，我正在计算一个班级的后验预测，这个班级参加了一场有 25 道多项选择题的考试（有些缺席），我想知道缺席者在同一场考试中的得分如何（我也想了解考试是容易还是困难，老师做得好不好，班级是聪明还是有挑战性的，评分是马虎、宽松、严格还是公正）。
支持度 (Ω) 为 0、1、2..... 25。我最确定的是学生的分数呈正相关。他们知道考试即将来临，所以自信的人会去参加考试，他们都有同一位老师，所以如果老师很优秀（一个好的指标就是考试成绩好），所有人的分数都会提高。出于各种原因，我相信它们是正相关的（如果我知道一个人做得很好，我相信其他人做得比我原本相信的要好），但我无法量化这种信念（我不知道这种关系是线性的、指数的、二次的、三次的等等）。
我希望能够使用具有不同支持（不同的测试分数范围或不同的目的）的相同方法。
后验预测将是
$$p(x_{\text{new}} | x_{\text{old}}) = \sum_{\mu} \sum_{\sigma} p(x_{\text{new}} | \mu, \sigma, x_{\text{old}}) \cdot p(\mu, \sigma | x_{\text{old}})$$
其中
$$p(\mu, \sigma | x_{\text{old}})$$
如果我们假设独立性，则将是 μ 和 σ 后验的乘积（我宁愿不假设参数独立性，但这是我最不担心的。我最担心的是观测的独立性$x_{\text{old}}$
对于 μ，我对连续截断正态分布和连续均匀分布 [0-25] 没有任何疑虑
μ 的可能性将是$$\frac{\phi\left(\frac{x - \mu}{\sigma}\right)}{\sigma \left( \Phi\left(\frac{25 - \mu}{\sigma}\right) - \Phi\left(\frac{0 - \mu}{\sigma}\right)\right)}$$ 而先前的平原将只是一个统一的 U[0,25]
我对 σ 的可能性有疑问，它应该是从 0 到无穷大的截断正态分布还是伽马？至于先验，它将是一个平坦的非信息先验（从 0 到无穷大的退化均匀分布）。
真正的问题是 $$p(x_{\text{new}} | \mu, \sigma, x_{\text{old}})$$
我知道支持，并且它应该是离散的，例如可能性 $$P(X = x\vert \mu,\sigma,\Omega) = \frac{e^{-\frac{(x-\mu)^2}{2\sigma^2}}}{\sum_{y \in \Omega} e^{-\frac{(y-\mu)^2}{2\sigma^2}}}$$ 具有我想要的支持，但它似乎没有捕捉到与旧观察的相关性，它似乎需要具有 $x_{\text{old}}$ 作为变量，但事实并非如此。
我应该使用什么可能性作为形状参数？
来自均匀变量的样本方差的抽样分布由伽马分布给出（我的 μ 具有单边截断可能性，并且我倾向于离散正态分布以进行观察），但似乎最大熵（具有更大的自由度，因为如果截断正态分布恰好具有相同的参数，那么它就是与伽马分布相同的分布，截断正态分布似乎是更普遍的情况）是截断正态分布。
理论会建议我使用从 0 到无穷大的截断正态分布或伽马分布作为形状参数吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659197/is-maximum-entropy-the-solution-i-am-looking-for-is-the-characterization-of-ent</guid>
      <pubDate>Wed, 25 Dec 2024 15:23:50 GMT</pubDate>
    </item>
    <item>
      <title>我该如何从“杠杆效应”的角度解释下面的 GJR-GARCH 模型？</title>
      <link>https://stats.stackexchange.com/questions/612999/how-can-i-interpret-the-below-gjr-garch-model-in-terms-of-leverage-effects</link>
      <description><![CDATA[我是这里的新手，很难解释该模型。请用通俗易懂的语言帮助我。
 AR - GJR-GARCH 模型结果 
================================================================================================
Dep. 变量：GD R 平方：-0.003
均值模型：AR Adj。 R 平方：-0.004
Vol 模型：GJR-GARCH 对数似然：-3572.12
分布：标准化学生 t AIC：7168.24
方法：最大似然 BIC：7236.93
观测数：2261
日期：2023 年 4 月 15 日星期六 Df 残差：2257
时间：07:18:04 Df 模型：4
均值模型
=======================================================================================
coef std err t P&gt;|t| 95.0% Conf.整数
-----------------------------------------------------------------------------------------
常数 0.0688 2.281e-02 3.017 2.555e-03 [2.411e-02, 0.114]
GD[1] -0.0134 2.114e-02 -0.635 0.526 [-5.485e-02,2.801e-02]
GD[2] -0.0327 2.011e-02 -1.626 0.104 [-7.210e-02,6.716e-03]
GD[3] 6.0716e-03 1.971e-02 0.308 0.758 [-3.255e-02,4.470e-02]
波动率模型
=====================================================================================
coef std err t P&gt;|t| 95.0% Conf. Int.
-----------------------------------------------------------------------------------------
omega 0.1078 4.361e-02 2.473 1.341e-02 [2.236e-02, 0.193]
alpha[1] 0.0322 1.903e-02 1.691 9.074e-02 [-5.108e-03,6.947e-02]
alpha[2] 4.1672e-14 1.602e-02 2.602e-12 1.000 [-3.139e-02,3.139e-02]
gamma[1] 0.0394 2.891e-02 1.364 0.172 [-1.722e-02,9.611e-02]
gamma[2] 0.1528 3.636e-02 4.202 2.651e-05 [8.151e-02, 0.224]
beta[1] 9.4508e-03 4.481e-02 0.211 0.833 [-7.837e-02,9.727e-02]
beta[2] 0.7992 5.555e-02 14.386 6.313e-47 [ 0.690, 0.908]
分布
==============================================================================
coef std err t P&gt;|t| 95.0% Conf. Int.
------------------------------------------------------------------------
nu 5.2877 0.574 9.215 3.121e-20 [ 4.163, 6.412]
==============================================================================

我在网上读了很多文章或论文，得出以下结论。但不确定我是否正确。
这里，gamma[1] 的 p 值为 0.172（大于 0.05），因此 gamma[1] 在统计上不显著，我们无法得出存在显著杠杆效应的结论。
但是，gamma[2] 的 p 值小于 0.05，表明 gamma[2] 具有统计显著性。
因此，我们可以得出结论，该模型已经捕获了显著的杠杆效应。
此外，我想编写一个通用代码，其中包含所有场景，例如，

如果 gamma[1] 为 +ve 而 gamma[2] 为 -ve，该怎么办？
如果模型中有 n 个 Gamma，那么我可以采用相同的方法吗？
如果我们有 n 个 Gamma，并且它们是 +ve 和 -ve 的组合，那么我们如何得出结论？
]]></description>
      <guid>https://stats.stackexchange.com/questions/612999/how-can-i-interpret-the-below-gjr-garch-model-in-terms-of-leverage-effects</guid>
      <pubDate>Sat, 15 Apr 2023 07:48:42 GMT</pubDate>
    </item>
    <item>
      <title>如何证明当 $\Omega$ 是有限的，$\{N(\theta,1):\theta \in \Omega\}$ 不是完整的分布族？</title>
      <link>https://stats.stackexchange.com/questions/612049/how-to-show-that-n-theta-1-theta-in-omega-is-not-a-complete-family-of</link>
      <description><![CDATA[考虑$\{N(\theta,1):\theta \in \Omega\}$分布系列，其中$\Omega=\{-1,0,1\}$。我试图表明这不是一个完整的系列。也就是说，如果 $X\sim N(\theta,1)$，我需要找到一个非零函数 $g$，对于每个 $\theta \in \mathbb \Omega$，$E_{\theta}[g(X)]=0$。
现在，
$$E_{\theta}[g(X)]=0,~~\forall\,\theta \iff \int_{-\infty}^\infty g(x)e^{-(x-\theta)^2/2}\,dx=0,~~\forall\, \theta.$$
但是我能想到的任何 $g$ 都依赖于 $\theta$。我意识到 $g$ 必须以这样的方式选择，即 $\Omega$ 的元素位于方程 $E_{\theta}[g(X)]=0$ 的解之中。如何从上述方程中得出 $g$ 的适当选择？如果有提示就更好了。
问题的根源是本笔记中的练习 21（第 23 页），我在其中修改了参数空间，使事情稍微简单一些。]]></description>
      <guid>https://stats.stackexchange.com/questions/612049/how-to-show-that-n-theta-1-theta-in-omega-is-not-a-complete-family-of</guid>
      <pubDate>Wed, 05 Apr 2023 22:28:48 GMT</pubDate>
    </item>
    </channel>
</rss>