<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 21 Sep 2024 21:14:00 GMT</lastBuildDate>
    <item>
      <title>为问题和答案生成上下文</title>
      <link>https://stats.stackexchange.com/questions/654708/generating-context-for-questions-and-answers</link>
      <description><![CDATA[一般问题概述：
我需要微调问答模型，以便从约 5 页的文档中提取问题的答案，但我只有问题和答案的对，没有上下文。
这些文档是非结构化的文本，每个文档包含约 20 个问题的答案 + 一些不重要的文本。所有文档都有非常相似的主题（它们都是数据管理计划）。问题和答案通常至少有一句话长。
问题和答案示例：

问：项目将生成/收集哪些类型和格式的数据？


答：因此，生成的数据类型和格式列表很长，包括但不限于：格式化/未格式化的文本 Mov MP4 二进制 HDF5 Xlsx Jpg VTK PDB PSF PRMTOP XTC PDF PNG EPS DICOM C3D VTK



问：数据的来源是什么？


答：数据来自许多不同的来源。非模拟数据通常用于构建模型，可以源自临床数据管理系统或 DICOM 图像存储。&quot;


查看更多问题此处（不仅仅是这些问题，但都与此类似）。
可用数据
我的数据集由问题和答案组成（大约 1 万对），我需要生成上下文来微调问答模型。
我还有大约 1000 份未标记的文档，每个文档都有自由文本，每个文本包含大约 20 个问题的答案。我的目标是训练模型，以便从此类文档中提取答案（我有一些带标签的文档，将用于评估，但不足以进行训练）。
问题：
如何通过将我的答案作为输入并用类似于我的目标文档的文本围绕它来生成上下文，同时仍然知道答案在哪里。]]></description>
      <guid>https://stats.stackexchange.com/questions/654708/generating-context-for-questions-and-answers</guid>
      <pubDate>Sat, 21 Sep 2024 20:07:09 GMT</pubDate>
    </item>
    <item>
      <title>将无偏相关/独立估计量与未知方差相结合的最佳方法[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654705/the-best-way-to-combine-unbiased-correlated-independent-estimators-with-unknown</link>
      <description><![CDATA[我有一组某个物理量的无偏估计量，我想将它们组合起来。我通过求解噪声方程来获得这些估计量。
我知道它们是相关的，但我不知道它们是如何相关的（不知道协方差矩阵）。此外，我甚至不知道这些估计量的方差，但我想将它们组合起来以获得更好的估计量。（得到的估计量的方差应该低于我已经拥有的所有估计量）
最好的方法是什么？为什么？现在我想到的是整个估计量的平均值或中位数，但这可能不是最好的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/654705/the-best-way-to-combine-unbiased-correlated-independent-estimators-with-unknown</guid>
      <pubDate>Sat, 21 Sep 2024 17:36:00 GMT</pubDate>
    </item>
    <item>
      <title>测试时间序列信号的预测能力</title>
      <link>https://stats.stackexchange.com/questions/654703/testing-the-predictive-power-of-a-time-series-signal</link>
      <description><![CDATA[给定一个来自未知来源的信号和一些财务收盘价数据，有哪些直接的方法来测试信号的预测能力？在进行任何类型的回归/相关性分析之前，我需要使两个序列都平稳吗？
我想到的一个潜在方法是将调整收盘价转换为收益，并通过差分转换信号以使两个序列都平稳，然后在今天的差分信号（T - (T-1)）上回归第二天的收益（T+1）——不确定这是否正确，以及与我仅将第二天的收益（T+1）回归今天的信号（T）相比，这有什么不同。非常感谢大家对此的建议！
还有什么其他方法可以完成这样的任务？
信号数据：

收盘价数据：
]]></description>
      <guid>https://stats.stackexchange.com/questions/654703/testing-the-predictive-power-of-a-time-series-signal</guid>
      <pubDate>Sat, 21 Sep 2024 16:46:12 GMT</pubDate>
    </item>
    <item>
      <title>解释蒙特卡洛抽样的参数分布和 95% 置信区间</title>
      <link>https://stats.stackexchange.com/questions/654701/interpreting-parameter-distributions-and-95-confidence-intervals-from-monte-car</link>
      <description><![CDATA[我用一个模型（多参数生化网络模型）拟合了两个数据集，这些拟合给出了许多参数的估计值，包括一个我称之为 A 的参数。使用数据集 1 和数据集 2 时，参数 A 的最佳拟合值完全不同，但我想了解我对这些参数拟合的信心程度。我使用了蒙特卡罗抽样方法，其中我根据相关的测量误差估计值随机改变这两个数据集中的输入数据。这为我提供了使用数据集 1 或 2 得到的参数 A 值的两个分布。这些分布高度重叠（例如，数据集 1 的第 2.5 和第 97.5 四分位数为 [0.01,1.5]，数据集 2 的第 2.5 和第 97.5 四分位数为 [0.7,8]）。在我这个非常小众的领域中，其他人经常使用这种间隔的重叠作为缺乏统计显著差异的证据。
但是，如果我应用类似 z 检验的方法询问参数 A 在拟合数据集 1 或数据集 2 时的平均估计值是否彼此不同，结果就会显示统计显著。这似乎是合理的，因为我认为虽然在将我的模型拟合到数据集 1 或 2 时 A 的真实值存在很大的潜在不确定性，但考虑到我使用的蒙特卡洛抽样样本量很大，我可以非常有信心，平均值是精确估计的，并且彼此不同。
将参数 A 的平均估计值的这种统计显著差异解释为（在 alpha 为 0.05 时）当模型拟合到数据集 2 时参数 A 的值大于拟合到数据集 1 时的证据，我错了吗？我的分析是否犯了某种基本的逻辑错误？]]></description>
      <guid>https://stats.stackexchange.com/questions/654701/interpreting-parameter-distributions-and-95-confidence-intervals-from-monte-car</guid>
      <pubDate>Sat, 21 Sep 2024 15:32:04 GMT</pubDate>
    </item>
    <item>
      <title>缺少预测因子的外部验证预测模型</title>
      <link>https://stats.stackexchange.com/questions/654700/external-validation-prediction-model-with-missing-predictor</link>
      <description><![CDATA[我计划使用来自另一个国家的健康登记数据对一个国家开发的临床预测模型进行外部验证。直到最近，登记数据才包含使用该模型进行预测所需的所有预测变量（以便对其进行验证）。但是，该模型最近进行了更新，包含了一个我们没有的变量（即吸烟史作为二元变量）。
我们仍然可以验证旧版本的模型（仍在广泛使用），但我们还有什么方法可以验证新模型吗？我正在考虑在验证之前使用吸烟的代理变量（例如肺癌诊断或归因等）来预测该变量。这比根本不验证它要好吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654700/external-validation-prediction-model-with-missing-predictor</guid>
      <pubDate>Sat, 21 Sep 2024 14:51:16 GMT</pubDate>
    </item>
    <item>
      <title>使用 2 参数分布时的 3 个参数的 MLE</title>
      <link>https://stats.stackexchange.com/questions/654697/mle-of-3-parameters-when-using-a-2-parameter-distribution</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654697/mle-of-3-parameters-when-using-a-2-parameter-distribution</guid>
      <pubDate>Sat, 21 Sep 2024 13:16:39 GMT</pubDate>
    </item>
    <item>
      <title>离散随机变量的 CDF 分段常数？</title>
      <link>https://stats.stackexchange.com/questions/654695/cdf-of-a-discrete-random-variable-piecewise-constant</link>
      <description><![CDATA[在我的脚本中，它说：

给定$X$是一个离散随机变量，$\Bbb P(X\in D)=1,D=\{a_1,a_2,\ldots\},p_i:=\Bbb P_X(\{a_i\})&gt;0,\forall i\ge1,$我们有$F_X(x)=\sum\limits_{a_i\le x}p_i,$这意味着离散随机变量的CDF是分段常数。

我的想法
假设$X:\Omega\to\Bbb R$是一个离散随机变量，其中$\Bbb P_X(\{q_i\})=\frac1{2^i}&gt;0,$，其中$\{q_i\}_{i\in\Bbb N}$是$\Bbb Q.$的枚举，因为$\Bbb Q$是稠密的，所以对于每两个$x_1,x_2\in\Bbb R,x_1&lt;x_2,$，存在某个$q_j\in(x_1,x_2)$，意味着$q_j\in(x_1,x_2)$ class=&quot;math-container&quot;&gt;$F_X(x_1)&lt;F(x_2).$ 因此，这似乎与 $F_X$ 是分段常数的说法相矛盾，这让我怀疑如果该说法成立，我的随机变量 $X$ 是否存在。
问题：任何离散随机变量的 CDF 确实是分段常数吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654695/cdf-of-a-discrete-random-variable-piecewise-constant</guid>
      <pubDate>Sat, 21 Sep 2024 13:03:38 GMT</pubDate>
    </item>
    <item>
      <title>如何计算多个参与者和观察员的单一变异系数？</title>
      <link>https://stats.stackexchange.com/questions/654676/how-do-i-calculate-a-single-coefficient-of-variation-with-multiple-participants</link>
      <description><![CDATA[我通常会使用 ICC 作为评分者信度的指标。但是，有期刊希望我使用变异系数来做到这一点。我认为变异系数是单个变量的指标，而不是面板的指标，那么生物统计学中在面板上计算此指标的惯例是什么？
设置是，我有 n 名观察员，他们都对 m 名患者进行测量，因此我有 nxm 个数据点需要汇总为单个指标。我见过其他论文这样做，但没有解释他们如何进行计算。]]></description>
      <guid>https://stats.stackexchange.com/questions/654676/how-do-i-calculate-a-single-coefficient-of-variation-with-multiple-participants</guid>
      <pubDate>Fri, 20 Sep 2024 15:37:41 GMT</pubDate>
    </item>
    <item>
      <title>非正态分布的中位数相等性检验</title>
      <link>https://stats.stackexchange.com/questions/654644/median-equality-test-for-non-normal-distributions</link>
      <description><![CDATA[尽管许多文章都肯定，当违反正态性假设时，我们可以使用 Wilcoxon-Mann-Whitney 检验来比较中位数，但 Wilcoxon-Mann-Whitney 检验不会比较非正态分布之间的中位数：

Wilcoxon 检验有时被称为测试中位数相等，这里有一个证明它不是这样做的
Wilcoxon-Mann-Whitney 检验不比较中位数
对Mann-Whitney(-Wilcoxon) 𝑈 检验作为中位数差异、平均差异或位置偏移（选择您的解释）的检验，其结果来自两个额外的（严格）假设：(i) A 组和 B 组的分布具有相同的形状，(ii) A 组和 B 组的分布具有相同的方差。

如果我们不能使用 Wilcoxon-Mann-Whitney 检验来比较非正态分布的中位数，那么我们可以使用哪种检验来检验非正态分布（具有不同的方差或不同的形状，或两者不同）之间的中位数相等性？]]></description>
      <guid>https://stats.stackexchange.com/questions/654644/median-equality-test-for-non-normal-distributions</guid>
      <pubDate>Fri, 20 Sep 2024 10:27:17 GMT</pubDate>
    </item>
    <item>
      <title>在加法和乘法生存模型之间进行选择</title>
      <link>https://stats.stackexchange.com/questions/654533/choosing-between-additive-and-multiplicative-survival-model</link>
      <description><![CDATA[我正在使用生存模型对住房建设时机进行研究。我现在面临的问题是选择加法生存模型还是乘法生存模型。在两者之间进行选择时我应该考虑什么，是否有任何测试统计数据可以帮助做出此决定？]]></description>
      <guid>https://stats.stackexchange.com/questions/654533/choosing-between-additive-and-multiplicative-survival-model</guid>
      <pubDate>Wed, 18 Sep 2024 07:33:59 GMT</pubDate>
    </item>
    <item>
      <title>最大对数似然拟合中优化参数的置信区域</title>
      <link>https://stats.stackexchange.com/questions/654427/confidence-regions-of-optimized-parameters-in-maximum-log-likelihood-fits</link>
      <description><![CDATA[我正在使用数值优化算法来最大化对数似然函数，$\mathcal{L}$。对数似然函数具有固定数量的参数，$\{\theta_i\}$。这些参数通过优化算法进行优化，以最大化对数似然函数，从而获得参数$\theta_i$值的最佳估计值。
我知道可以推导或计算$\Delta \mathcal{L}$的一些临界值，这些临界值可用于获取参数$\theta_i$的置信区域。
但是，我不知道如何找到这些信息，或者在哪里可以找到这些信息。
我浏览了Casella和Berger的统计推断，希望找到$\Delta \mathcal{L}$的值表，或者某种计算此类值表的方法。我期望在区间估计一章中找到它，但没有。如果信息在那里，那么我不明白我在读什么，因此它超出了我的理解范围。
有人能指出我正确的方向吗？
以下是一些进一步的信息：

由于$\mathcal{L}$是参数$\theta_i$的函数，通过改变$\theta_i$的值，我们也会改变$\mathcal{L}$的值。
参数$\hat{\theta}_i$的最佳估计值是通过最大化$\mathcal{L}$。
如果我们想要估计与 $\theta_i$ 相关的置信区域，我们可以改变 $\theta_i$ 的其中一个值，直到对数似然函数 $\mathcal{L}$ 的值改变某个临界值 $\Delta \mathcal{L}$。
$\Delta \mathcal{L}$ 的值取决于参数 $i$ 的数量和目标置信水平。
例如，置信度越大，该值越大带。
如果我们想要 99% CL，那么所需的 $\Delta \mathcal{L}$ 值将大于我们估计 95% CL 区域时的值。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654427/confidence-regions-of-optimized-parameters-in-maximum-log-likelihood-fits</guid>
      <pubDate>Mon, 16 Sep 2024 13:03:01 GMT</pubDate>
    </item>
    <item>
      <title>距离加权平均值 - 如何处理同一位置的样本</title>
      <link>https://stats.stackexchange.com/questions/654264/distance-weighted-mean-how-to-handle-samples-at-the-same-location</link>
      <description><![CDATA[在 R 中，我正在计算某个区域中多个样本的社区组成差异。为了全面衡量社区的差异，我希望对距离较近的样本赋予比距离较远的样本更大的权重。为此，我有一个包含样本间差异的矩阵：
&gt; dissimilarity_m
1 2
2 0.7258861 
3 0.9378651 0.9253090

以及显示空间距离的矩阵：
&gt; dist_m
1 2
2 0.000000000 
3 0.009437432 0.009437432

但是，我现在正在努力寻找如何最好地计算加权平均值。到目前为止，我已经使用了
dist_mean_weighed &lt;- weighted.mean(dissimilarity_m, w = 1/dist_m)

但我想知道反距离 1/w 是否是一个很好的近似值。此外，如果两个样本位于同一位置且 w = 0（我的所有样本都使用坐标记录，这些坐标不是米级分辨率，因此几个样本的距离为零），这当然不起作用。
R 中是否有更好的近似值或更有用的函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/654264/distance-weighted-mean-how-to-handle-samples-at-the-same-location</guid>
      <pubDate>Thu, 12 Sep 2024 09:41:10 GMT</pubDate>
    </item>
    <item>
      <title>现实世界中的数据在统计意义上是“抽样的”吗？</title>
      <link>https://stats.stackexchange.com/questions/654255/are-data-in-the-real-world-sampled-in-the-statistical-sense</link>
      <description><![CDATA[在机器学习中，通常假设样本是根据某种概率分布独立同分布生成的。关于独立同分布假设在统计学习中的重要性
基本假设是存在某种分布/pdf/cdf/pmf $f_X$ 并且 $f_X$ 可以采样。
$$X \sim f_X(x)$$
我的问题很简单，即这个数学假设如何模拟我们在现实世界中的经验或数据科学和机器学习中产生的应用。
当我们说样本是从分布中抽取的，这在现实世界中意味着什么？
例如，如果我想对猫和狗的图片进行分类，我会通过拿出我的 iphone 16 并拍摄一些猫和狗的照片来生成我的数据集。
我看不出按下我的 iphone 上的按钮这个简单动作如何等同于从某个概率分布中进行采样的过程。
我可以使用概率分布$f_X$在数学上描述相机的动作吗？不。我甚至梦想写下与猫或狗图像相关的概率密度函数$f_X$吗？不可能。除了最简单/最琐碎的数据集外，概率分布 $f_X$ 的存在对于所有数据集都是可疑的。
那么机器学习中试图建模的抽样假设是什么？为什么不从“假设我们有一些示例的数据集”开始，并省略抽样假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/654255/are-data-in-the-real-world-sampled-in-the-statistical-sense</guid>
      <pubDate>Thu, 12 Sep 2024 09:19:04 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中进行数据拟合时，如何处理区间数据（具有无限上限）？</title>
      <link>https://stats.stackexchange.com/questions/654300/how-do-i-deal-with-interval-data-having-infinite-upper-limit-when-doing-data-f</link>
      <description><![CDATA[我从一份政府报告中提取了住房建筑面积（​​平方米 (sqm.)）的数据。第一类指建筑面积低于 5 平方米，最后一类指建筑面积为 200 平方米或以上。
鉴于下限和上限有点模糊，我怀疑在进行数据拟合时这些会产生重大影响。实际上，没有零平方米甚至 1 平方米的房屋；此外，人们可以拥有非常宽敞的地板面积，但在给定的数据中，超过 200 平方米的面积限制并没有得到很好的确定。
category &lt;- c(&quot;&lt; 5&quot;, &quot;5 - 9&quot;, &quot;10 - 19&quot;, &quot;20 - 29&quot;, &quot;30 - 49&quot;, 
&quot;50 - 69&quot;, &quot;70 - 89&quot;, &quot;90 - 119&quot;, &quot;120 - 149&quot;, &quot;150 - 199&quot;, 
&quot;&gt; 200&quot;)
count &lt;- c(13676, 48589, 111144, 174631, 203851, 124424, 82277, 
54410, 31702, 16239, 14516)

对于数据拟合，我尝试生成 Cullen 和 Frey 图。我假设我无法处理区间数据，因此我将区间转换为中点。请注意，对于下限和上限，我只是假设它们是 5 平方米。和 200 平方米，虽然我不确定这是否是一个合理的假设，因为概率分布在稍后模拟时会产生误导，即会产生零或接近零的值或远远超过 200 的值。
# 步骤 1：安装必要的软件包
install.packages(&quot;fitdistrplus&quot;)
install.packages(&quot;moments&quot;)

# 步骤 2：加载软件包
library(fitdistrplus)
library(moments)

# 步骤 3：准备数据
类别 &lt;- c(&quot;&lt; 5&quot;, &quot;5 - 9&quot;, &quot;10 - 19&quot;, &quot;20 - 29&quot;, &quot;30 - 49&quot;, 
&quot;50 - 69&quot;, &lt;70 - 89&quot;, &lt;90 - 119&quot;, &lt;120 - 149&quot;, &lt;150 - 199&quot;, 
&gt; 200&quot;)
count &lt;- c(13676, 48589, 111144, 174631, 203851, 124424, 82277, 
54410, 31702, 16239, 14516)

# 使用中点近似
中点 &lt;- c(5, (5+9)/2, (10+19)/2, (20+29)/2, (30+49)/2, (50+69)/2, 
(70+89)/2, (90+119)/2, (120+149)/2, (150+199)/2, 200)

# 根据计数值重复中点
data &lt;- rep(midpoints, count)

# 步骤 4：Cullen 和 Frey 图测试
descdist(data, discrep = FALSE, boot = 1000)

Cullen 和 Frey 图测试表明分布为 Beta。本能地，我认为楼面面积的概率分布最有可能是对数正态的。不确定的上限和下限是否可能影响 Cullen 和 Frey 图的结果？
总结：
当我有区间数据并且想要找到给定数据集的最佳拟合概率分布时，我该如何处理不确定的上限和下限？]]></description>
      <guid>https://stats.stackexchange.com/questions/654300/how-do-i-deal-with-interval-data-having-infinite-upper-limit-when-doing-data-f</guid>
      <pubDate>Thu, 12 Sep 2024 00:26:16 GMT</pubDate>
    </item>
    <item>
      <title>R 调查包与 R 统计包中的 AIC 不同</title>
      <link>https://stats.stackexchange.com/questions/654245/different-aic-in-r-survey-package-vs-r-stats-package</link>
      <description><![CDATA[使用 svyglm()$aic 而不是使用 stats::AIC(model) 时，我得到的 AIC 值不同。我知道这个话题之前已经在这里讨论过了。但是，没有详细解释这种差异 — “仅”建议使用一种方法而不是另一种方法。我怀疑这与这个有关，但不幸的是我的统计数据不够强大，无法完全理解并得出结论。
如果有人能帮我一下，告诉我哪种方法是正确的（如果有的话）以及原因，我将不胜感激。如下例所示，这两种方法可以产生截然不同的结果，甚至改变对哪种模型似乎更合适的解释。
最小示例：
library(survey)

df &lt;- data.frame(
y = c(1.2, 2.4, 3.1, 4.5, 5.6, 6.3, 8.6),
a = c(0.5, 1.3, 1.7, 2.2, 3.1, 3.8, 4.0),
b = c(2.1, 2.7, 3.3, 3.8, 4.2, 4.5, 5.1),
weights = c(0.7, 1.4, 0.9, 1.1, 1.0, 0.8, 1.2)
)

weighted &lt;- svydesign(ids = ~1，数据 = df，权重 = ~weights)

A &lt;- svyglm(y ~ a + b，设计 = 加权，系列 = &quot;gaussian&quot;)

B &lt;- svyglm(y ~ a，设计 = 加权，系列 = &quot;gaussian&quot;)

AIC(A,B)[,2]
[1] 19.29119 17.03959
&gt; c(A$aic,B$aic)
[1] 15.06302 17.45406

我使用的是 R 4.4.1 和 survey 4.4-2]]></description>
      <guid>https://stats.stackexchange.com/questions/654245/different-aic-in-r-survey-package-vs-r-stats-package</guid>
      <pubDate>Wed, 11 Sep 2024 16:18:26 GMT</pubDate>
    </item>
    </channel>
</rss>