<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 08 Jun 2024 03:16:11 GMT</lastBuildDate>
    <item>
      <title>尽管 Resnet50 的测试和训练准确率很高，但 F1 分数却很低</title>
      <link>https://stats.stackexchange.com/questions/648855/resnet50-low-f1-score-despite-high-testing-and-training-accuracy</link>
      <description><![CDATA[我目前正在使用 Resnet50 在 Amazon Berkley Objects 数据集上进行图像分类，我一直面临 F1 分数低的问题，我确保训练和测试样本中的类别相等（总共约 50k 张图像），尽管它不会超过 10%（我知道图像显示的是第 7 个 epoche，但我不会让步直到运行结束），有什么建议吗？
预处理步骤主要是过滤、数据增强、重新缩放、基本数据准备，数据分为 80 20。]]></description>
      <guid>https://stats.stackexchange.com/questions/648855/resnet50-low-f1-score-despite-high-testing-and-training-accuracy</guid>
      <pubDate>Sat, 08 Jun 2024 00:43:40 GMT</pubDate>
    </item>
    <item>
      <title>适合 MLP 和 LSTM 的分布</title>
      <link>https://stats.stackexchange.com/questions/648854/appropriate-distribution-for-mlp-and-lstm</link>
      <description><![CDATA[我总共有 6300 个样本，其中 5800 个是训练数据，500 个是测试数据。我们在训练过程、预测精度和学习能力方面比较了 LSTM 和具有一个隐藏层的多层感知器 (MLP) 的性能。
在下图中，横坐标和纵坐标分别是迭代次数和 MSE 误差。它们的学习曲线如图所示。观察图，很明显 LSTM 的学习曲线比 MLP 的学习曲线衰减得更快。此外，LSTM 的收敛曲线比其他曲线更稳定。此外，LSTM 的损失 (RME 误差) 始终小于 MLP。LSTM 的 RMS 误差为 3.47998，MLP 为 5.02391。
我的问题是如何为 LSTM 和 MLP 找到/定义合适的分布？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/648854/appropriate-distribution-for-mlp-and-lstm</guid>
      <pubDate>Sat, 08 Jun 2024 00:37:30 GMT</pubDate>
    </item>
    <item>
      <title>使用二元结果的功率计算（使用 R 包和手动模拟）</title>
      <link>https://stats.stackexchange.com/questions/648852/power-calculation-with-a-binary-outcome-using-a-r-package-manual-simulation</link>
      <description><![CDATA[我试图在相同的设置下比较三种不同的功效计算方法。虽然我理解由于随机性，每种方法的功效估计不可能完全相同，但我预计它们会非常相似。然而，我观察到功效估计略有不同。
基本设置如下：

结果：二进制（成功 1；失败 0）
要比较的两组：G1 vs G2
G1：样本数 - 150；成功率为 0.2
G2：样本数 - 30；成功率为 0.4
显著性水平为 0.2（不是通常的 0.05）

也就是说，
p1 &lt;- 0.2
p2 &lt;- 0.4

n1 &lt;- 150
n2 &lt;- 30

我使用的三种方法是：

使用 pwr 包中的 pwr.2p2n.test 函数。
使用 prop.test 函数进行模拟。
使用 fisher.test 函数进行模拟

### -------------------------------- ###
### --- 版本 1：pwr.2p2n.test --- ###
### -------------------------------- ###
library(pwr)
pwr.2p2n.test(h = ES.h(p1 = p1, p2 = p2), 
n1 = n1, n2 = n2,
sig.level = 0.20,
alternative = &quot;less&quot;)

# power = 0.9145152

### ---------------------------- ###
### --- 版本 2：Prop 测试 --- ###
### ---------------------------- ###
nreps &lt;- 10000
y1 &lt;- rbinom(n = nreps, size = n1, p = p1)
y2 &lt;- rbinom(n = nreps, size = n2, p = p2)

pval &lt;- rep(NA, nreps)
for(i in 1:nreps) {
pval[i] &lt;- prop.test(c(y1[i], y2[i]), 
n= c(n1, n2), 
alternative = &quot;less&quot;,
p = NULL, correct = TRUE)$p.value
}

power &lt;- sum(pval &lt; 0.20) / nreps 
power # [1] 0.8756

### -------------------------------------- ###
### --- 版本 3：Fisher 精确检验 --- ###
### -------------------------------------- ###
pval.fin &lt;- c()
for(i in 1:nreps){
y1 &lt;- rbinom(n1, size = 1, p = p1)
y2 &lt;- rbinom(n2, size = 1, p = p2)
dat.comb &lt;- rbind(data.frame(res = y1, group = &quot;G1&quot;),
data.frame(res = y2, group = &quot;G2&quot;))
tab &lt;- table(dat.comb$group, dat.comb$res)
test.res &lt;- fisher.test(tab, alternative = &#39;less&#39;)
pval.fin[i] &lt;- test.res$p.value
}
mean(pval.fin&lt;0.2) # [1] 8e-04

我注意到了以下两点：

第三种方法使用 Fisher 精确检验，其幂为 8e-0.4。但是，如果我将“替代”选项从“less”更改为“greater”，幂将变为 0.8811，这与我们从第一种方法和第二种方法中获得的结果相似。但是第一种方法和第二种方法使用了“less”的“替代”选项……我不明白是什么导致了如此巨大的差异。

版本 1 和版本 2 的幂估计也有点偏差。我不太清楚是什么导致了这种差异。


有人能帮我理解为什么即使设置相同，我也没有获得类似的功率吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648852/power-calculation-with-a-binary-outcome-using-a-r-package-manual-simulation</guid>
      <pubDate>Fri, 07 Jun 2024 22:15:04 GMT</pubDate>
    </item>
    <item>
      <title>对于缺少很多天的时间序列，最好的输入选择是什么</title>
      <link>https://stats.stackexchange.com/questions/648849/what-are-the-best-options-for-imputing-time-series-that-is-missing-lots-of-days</link>
      <description><![CDATA[我有好几个月的温度数据，大约每十分钟记录一次。除非它有间隙。如果间隙为一小时左右，我可以线性插值，但如果间隙为几天，这显然行不通。
我目前所做的是取每日平均值，然后进行样条拟合以获得每天的平均值。我还从每天中减去平均值，以计算数据随时间变化的滚动平均值，按小时计算。然后，我可以用每小时滚动偏移量填充缺失的天数，偏移量为插值样条拟合的平均值。
它有点用，但你可以看到我拼接的地方。例如，连接处的梯度不连续。我想我可以通过每天对总变化进行每日估计，然后将其插入间隙来改进，但是......
这肯定应该是机器学习的一个很棒的应用？我正在摆弄一些 scikit-learn 包，但它们似乎都希望在学习之前删除 NaN。
如能提供任何指点，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/648849/what-are-the-best-options-for-imputing-time-series-that-is-missing-lots-of-days</guid>
      <pubDate>Fri, 07 Jun 2024 20:38:31 GMT</pubDate>
    </item>
    <item>
      <title>SVRG 与完全梯度下降</title>
      <link>https://stats.stackexchange.com/questions/648848/svrg-vs-full-gradient-descent</link>
      <description><![CDATA[随机梯度下降法让我们能够避免计算全梯度，但代价是引入收敛噪声底限。为了降低此噪声底限，SGD 需要减小步长，这会导致在强凸情况下失去线性收敛。 SVRG（随机方差降低梯度）允许我们返回这种线性收敛，但我看不出这在计算上比简单的全梯度下降有什么好处。
SVRG 在外循环的每次迭代中对完整梯度进行采样，然后执行形式为 $w_t = w_{t-1} - \eta \left(\nabla f_{i_t}(w_{t-1})-\nabla f_{i_t}(\hat{w}) + \nabla f(\hat{w})\right)$ 的内循环步骤，其中 $\hat{w}$ 是当前外循环值。我们的想法是利用梯度之间的正相关性来减少估计量中的方差。在强凸情况下，论文中的分析会选择这些内循环子步骤中的一个随机步骤作为我们的下一个外循环步骤。然后他们继续将其呈现为返回 GD 的线性收敛，但收敛程度取决于我们运行的外循环步骤数。这些外循环步骤中的每一个都在计算一个完整的梯度，那么这是否不是在进行完整的梯度下降加上这些内循环步骤的一些额外工作 - 所有这些都是为了实现与 GD 相同的收敛？]]></description>
      <guid>https://stats.stackexchange.com/questions/648848/svrg-vs-full-gradient-descent</guid>
      <pubDate>Fri, 07 Jun 2024 20:06:54 GMT</pubDate>
    </item>
    <item>
      <title>比较两个随着时间的推移而不平等的群体？</title>
      <link>https://stats.stackexchange.com/questions/648846/comparing-two-unequal-groups-over-time</link>
      <description><![CDATA[我对 rstudio 和统计学还不熟悉，所以请耐心等待。我试图比较两个不同变量随时间的变化，但它们来自非常不同的样本量。
我正在研究现场样本测量值和实验室样本测量值之间的差异。它们以不同的单位测量，但应该是相关的，因为它们本质上测量的是同一件事。
我有一个数据集“Probe”，其中测量了感兴趣的变量“value”。
这应该与我的其他数据集“Field”中的“value”变量相关。
哪种统计测试可以给我我想要的分析？我想看看“Field”值的峰值是否与“Probe”值的峰值相关，依此类推。我试图随着时间的推移跟踪它们是否显示出相似的趋势。我想做一些类似相关性的事情，但不能，因为“Probe”数据由 1606 个观测值组成，而“现场”数据由 197 个观测值组成，因此它们的长度不同，并且无法关联（据我迄今为止的研究所知）。]]></description>
      <guid>https://stats.stackexchange.com/questions/648846/comparing-two-unequal-groups-over-time</guid>
      <pubDate>Fri, 07 Jun 2024 19:59:43 GMT</pubDate>
    </item>
    <item>
      <title>寻找在线性回归中非线性组合特征的最佳方法</title>
      <link>https://stats.stackexchange.com/questions/648845/finding-the-best-way-for-combining-features-non-linearly-within-a-linear-regress</link>
      <description><![CDATA[问题陈述
我有一组两个特征，$X_1$ 和 $X_2$，我将它们组合起来尝试预测以下形式的回归中的目标变量：$ Y_0 = \frac{X_1 - X_2}{X_1 + X_2} $。您可以将其视为两者之间的插值，将差异标准化为所有数据点的$[-1, 1]$之间的差异。
$X_1, X_2$受到其他一些特征的非线性影响：$Z_1, Z_2$。
我正在尝试找到一种方法来改进原始回归$Y_0$，使用某个函数$f$，以便$Y_1 = \frac{f(X_1, Z_1) - f(X_2, Z_2)}{f(X_1, Z_1) + f(X_2, Z_2)} $改进$Y_0$。
我很清楚要从哪个类的函数开始。但我意识到，理想情况下，我希望针对我的具体问题调整我使用的任何函数。因此，如果我使用指数函数：$f(X_i, Z_i) = X_i * e^{Z_i} $，我希望找到最佳参数 lambda，其中 $f(X_i, Z_i, \lambda) = X_i * e^{\lambda * Z_i} $ 提供最佳拟合。 （$\lambda$ 是所有数据点的固定值）

具体示例
我认为用一个例子来说明会更容易。假设我们正试图通过进行许多平衡实验来预测跷跷板的倾斜角度。$Y=1$ 表示 $X_1$ 重（无限），跷跷板在那一侧接触地板。类似地，$Y=-1$ 表示 $X_2$ 重无限，跷跷板在相应的一侧接触地板。在理想情况下，这个目标变量恰好由两者的相对质量决定。这是之前的初始简单回归，$Y_0$。
但现在我们有一个未知的力作用在每个物体上：$Z_1$ 和 $Z_2$。我们有一个作用在每一侧的力的值，但我们不知道它如何准确地影响不平衡。把它想象成外星引力。下面是我所说的这一切的粗略图表，希望它能有所帮助。 
但现在我们有了这种奇怪的力量，我们想找到一种完美的建模方法。
实际数据不同，因此请在此示例中允许一些创造性想象力 :)

我的进度：
我尝试回归 $Y = \beta_1 X_1 + \beta_2 X_2 + \alpha$，按 $Z_1$ 和 $Z_2$ 的每个十分位数细分，然后绘制系数与十分位数的关系。我发现，随着 $Z_1$ 的增加，$X_1$ 的系数以指数方式增加，$X_2$ 和 $Z_2$ 的系数也以相同的方式（但为负）增加。因此，这表明我假设存在指数关系可能是正确的。

我的问题：
&quot;以指数方式&quot; 非常不切实际。我希望对这个建模过程有一个合理的方法。我需要找到最佳 lambda，并确认指数拟合是最佳选择。不太确定该怎么做。

我尝试过的方法
我尝试将指数曲线拟合到系数与十分位数图，这为 lambda 提供了一些值。但问题是，当我进行完全回归时，这种方法不起作用？只尝试一堆 lambda 值听起来也不对，感觉像是过度拟合。我这样做了，最佳 lambda 与我从另一种方法中获得的完全不同。所以我现在完全迷路了。

任何关于如何开始解决或查找此问题的指导都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/648845/finding-the-best-way-for-combining-features-non-linearly-within-a-linear-regress</guid>
      <pubDate>Fri, 07 Jun 2024 19:51:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的风险比系数在 Coxph 回归中这么大或这么小？</title>
      <link>https://stats.stackexchange.com/questions/648843/why-are-my-hazard-ratio-coefficients-so-large-or-small-in-coxph-regression</link>
      <description><![CDATA[我有一些我工作的机构中特定子群体的成绩数据，并将其与一段时间内的留校情况进行比较。下面的第一个表格是 R 中 coxph 回归的一些风险比，使用 D&amp;F GPA 学生作为比较组。这是一个通常会离开我们机构去另一所机构的子群体，所以我希望看到 A（学术货币）与离开与留下有关。
时间单位基于学分数量。

我的解释是，获得 A 的学生离开的可能性大约是平均成绩为 D 或 F 的学生的 15 倍。作为一项健全性检查，我想检查一下汇总的原始数据：

我很困惑，因为这个值比两组之间的比例要高得多。我是否应该进行更好的比较来计算“原始”数据？从汇总数据透视表值中得出风险比？
另一个示例是下面比较学生程序的输出（程序 3 是参考组）。

与原始数据相比，这里的比例似乎也不支持风险比。程序是分析中最具预测性的变量。

为了进一步参考，我附上了一份 Kaplan Maier 成绩生存图，该图似乎并未表明如此大的 coxph 系数。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648843/why-are-my-hazard-ratio-coefficients-so-large-or-small-in-coxph-regression</guid>
      <pubDate>Fri, 07 Jun 2024 19:36:29 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯法比尼·托内利</title>
      <link>https://stats.stackexchange.com/questions/648839/bayesian-fubini-tonelli</link>
      <description><![CDATA[我正在研究一个贝叶斯框架，其中我在函数$f\sim GP$上放置了一个高斯过程，并且有数据$D^n=\{(X_i,Z_i,W_i)\}^n$。
然后我得到了后验测量$\mu(f|D^n)$。后验均值估计量由 $\hat{f}=\int fd\mu(f|D^n)$ 给出。
我现在感兴趣的是找到另一个估计量的误差，我将其定义为：
\begin{align*}
\beta(x,z) &amp;=E_W[\hat{f}(x,z,W)]\\
&amp;=\int_\mathcal{W}\hat{f}(x,z,W)dP(W)\\
&amp;=\int_\mathcal{W}\int_\mathcal{F}f(x,z,W)d\mu(f|D^n)dP(W)
\end{align*&gt;
我现在想知道是否可以调用 Fubini Tonelli 来切换积分顺序 $\int_\mathcal{W}\int_\mathcal{F}f(x,z,W)d\mu(f|D^n)dP(W)=\int_\mathcal{F}\int_\mathcal{W}f(x,z,W)dP(W)d\mu(f|D^n)$.
我猜我的疑惑来自于这样一个事实：我没有针对整个数据分布$P(X,Z,W)$进行积分，并且测量$\mu$依赖于数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/648839/bayesian-fubini-tonelli</guid>
      <pubDate>Fri, 07 Jun 2024 16:33:20 GMT</pubDate>
    </item>
    <item>
      <title>李克特量表和样本量</title>
      <link>https://stats.stackexchange.com/questions/648828/likert-scale-and-sample-size</link>
      <description><![CDATA[我想研究母亲收到论文或网站信息的满意度。我至少会问 5 个问题，每个问题都使用李克特量表（5 分）。
样本量：

我是否应该使用调查的样本量公式进行计算（从 $y$ 中抽取 $x$ 名女性）？
我是否应该根据我预期的最重要的问题的李克特量表之间的差异来计算样本量？
我是否应该调整问题数量？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648828/likert-scale-and-sample-size</guid>
      <pubDate>Fri, 07 Jun 2024 14:57:59 GMT</pubDate>
    </item>
    <item>
      <title>估计样本的概率密度</title>
      <link>https://stats.stackexchange.com/questions/648819/estimating-probability-density-for-sample</link>
      <description><![CDATA[我有一个包含 20,000 多个样本的数据集。这里的目标是为样本定义一个分布，以便我可以绘制所有可能的结果。但是，我无法找到可用于估计概率密度的适当分布。我尝试使用正态分布、柯西分布、拉普拉斯分布、学生 T 分布和威布尔分布来测试样本。在所有情况下，Kolmogorov-Smirnov 检验都拒绝了我的样本遵循上述任何分布的可能性。我也尝试使用 KDE 进行估计，但结果并不理想。我尝试使用 KS 检验来检查 KDE 和我的样本之间的相似性，但即使在这里相似性也被拒绝了。我不知道下一步该怎么做才能估算出概率密度。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648819/estimating-probability-density-for-sample</guid>
      <pubDate>Fri, 07 Jun 2024 13:27:34 GMT</pubDate>
    </item>
    <item>
      <title>离散时间生存中的审查类型</title>
      <link>https://stats.stackexchange.com/questions/648701/type-of-censoring-in-discrete-time-survival</link>
      <description><![CDATA[*我有一个前瞻性纵向研究。在这项研究中，患者每三个月来医院检查一次。T0（手术前一周）、T3（手术后三个月）、T6（手术后六个月）、T9、T12、、、、、、T24（手术后 24 个月）。所以有 9 个时间点。
我们对预测性 Cox 回归感兴趣，其中包括二元时间相关协变量和连续自变量。在事件发生前退出、完成无事件随访（T24）或在研究结束时显示特定水平的时间相关协变量的病例是审查者。
*似乎在计数过程方法中，只有右审查者。并且为了使用离散时间生存，必须满足以下条件（如果我说得不对，请纠正我）

所有患者的时间间隔相同
时间点数量有限
区间审查*

1. 我不确定我的研究中的审查类型。如果研究中同时有右审查和区间审查，我们可以使用离散时间生存方法吗？
2. 如果研究允许患者在错过一个间隔点后重新加入试验（一个时间段内的所有观察数据都缺失），我想知道我们应该如何评估他们。当有缺失信息时，我们还能使用离散时间生存分析吗？例如，患者没有出席 T6 预约（手术后六个月），但他在 T9 时返回学习。
有关研究的更多信息
事件变量是疾病进展（是-否），主要协变量（时间相关变量-感兴趣的变量）是智力（是-否）。我们正在调查改变智力状态是否可以预测疾病的增加。]]></description>
      <guid>https://stats.stackexchange.com/questions/648701/type-of-censoring-in-discrete-time-survival</guid>
      <pubDate>Wed, 05 Jun 2024 19:03:51 GMT</pubDate>
    </item>
    <item>
      <title>计算 Cox-Snell Rsquared 的值</title>
      <link>https://stats.stackexchange.com/questions/648684/calculating-the-value-of-cox-snell-rsquared</link>
      <description><![CDATA[我想计算前瞻性纵向研究的最小样本量（使用 cox 回归 - 该项目的目的是进行预测）。可以使用 R 中 pmsampsize 包中的以下函数 pmsampsize 进行计算（基于以下出版物；开发具有连续、二元或生存（事件发生时间）结果的模型的最小样本量。Riley 等人（2018））。要运行以下函数，我们需要输入 csrsquared 的值，即新模型的 Cox-Snell Rsquared 值。
pmsampsize(type = &quot;s&quot;, csrsquared = , parameters = , rate = ,timepoint = , meanfup = )

如果在类似的研究中没有试验数据，也没有伪 R2 的报告值，那么如何定义 csrsquared 的值以使用此函数进行计算？
2. 假设伪 R2 的值可用，如何估计 Cox-Snell R 平方的值。。
我的模型中有一个二元时间相关协变量，只有 9 个时间点。因此，当 cox 模型包含时间相关协变量和离散生存时间时，我认为上述函数不可用于样本量计算。 但我仍然想知道在没有试验数据的情况下如何预测伪 R2，假设我们有连续的生存时间并且所有协变量都是时间独立的。
在我的研究中，患者每两个月来医院检查一次。T0（手术前一周）、T1（手术后两个月）、T2（手术后 4 个月）直至 T9（手术后 18 个月）。有一个二元时间相关协变量和一个连续独立变量。 在事件发生前退出、完成无事件随访（T9）的病例被审查。]]></description>
      <guid>https://stats.stackexchange.com/questions/648684/calculating-the-value-of-cox-snell-rsquared</guid>
      <pubDate>Wed, 05 Jun 2024 13:08:22 GMT</pubDate>
    </item>
    <item>
      <title>t 代之后回归的方差是多少？</title>
      <link>https://stats.stackexchange.com/questions/648671/what-is-the-variance-of-a-regression-after-t-generations</link>
      <description><![CDATA[假设我们有一个回归：
$$x_{t+1} = b x_t + e_t.$$
取每边的方差，我们得到
$$\operatorname{Var}(x_{t+1}) = b^2 \operatorname{Var}(x_t) + \operatorname{Var}(e_t)。 $$
现在假设 $\operatorname{Var}(e_t) = \sigma^2$ 是所有 $t$ 的常数。
然后我们有一个一阶递归关系，因此我们可以明确地解决：
$$\operatorname{Var}(x_t) = \frac{\sigma^2 (1 - b^{2t})}{(1-b^2)}。$$
不幸的是，我正在阅读的书 Gregory Clark 的《儿子也复活了》给出的方差为 $\sigma^2 (1 - b^{2t})$。我的推导正确吗？
（注意：对于拥有这本书的人来说，页码是 297。这不是打字错误，后续文本已明确指出。）]]></description>
      <guid>https://stats.stackexchange.com/questions/648671/what-is-the-variance-of-a-regression-after-t-generations</guid>
      <pubDate>Wed, 05 Jun 2024 10:18:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么要正式检验工具变量的相关性假设？</title>
      <link>https://stats.stackexchange.com/questions/648577/why-can-we-formally-test-the-relevance-assumption-of-instrument-variable</link>
      <description><![CDATA[我在我以前的关于 IV 的幻灯片中看到，教授说我们无法测试 IV 的排除假设，但我们可以测试 IV 的相关性假设。他关于无法测试排除的论据是：

$y=\beta_1 x_1 +\beta_2 x_2+\gamma z + u$如果 z 不独立于 u，那么您无法通过执行此回归来测试排除要求，并与 $\gamma=0$ 争论，因为 $cov(z,u)\ne 0$ 会使 $\gamma$ 的估计产生偏差

同时，他说您可以通过以下方式测试相关性假设：

$x_1=\eta x_2+\lambda z+v$，如果 $\eta $ 与 0 显著不同，我们满足相关性要求

但是，第二个不是也存在内生性问题吗？因此，如果 z 不独立于 v，但与 x_2 相关，则 $\eta $ 会有偏差。如果我们观察到非零 gamma，则可能存在向上偏差，如果没有偏差，z 本身与 x 没有任何关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/648577/why-can-we-formally-test-the-relevance-assumption-of-instrument-variable</guid>
      <pubDate>Mon, 03 Jun 2024 21:57:36 GMT</pubDate>
    </item>
    </channel>
</rss>