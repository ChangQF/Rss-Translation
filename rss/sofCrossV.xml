<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Thu, 27 Feb 2025 06:26:55 GMT</lastBuildDate>
    <item>
      <title>计算平均测试统计量的差异</title>
      <link>https://stats.stackexchange.com/questions/661909/computing-the-variance-of-a-mean-test-statistic</link>
      <description><![CDATA[给定我有两个示例 $ s_x $ 和 $ s_y $ ，其中 $ s_x $ 从 $ s_y $ 是从 $ p_y $ 中绘制的。以下方式创建了两个样本之间的测试统计量：

我们将这两个样本修复到具有相同大小的 $ nk $ 。
对于每个样本，我将它们分组为 $ n $ 相等尺寸的批量 $ k $   - 我们表示 $ s_ {x_1}，\ dots，s_ {x_n} $ ，我们用 $ s_y $  as 我们以以下方式将批次配对： $（s_ {x_1}，s_ {y_1}），\ dots，（s_ {x_n}，s_ {y__n}，s_ {y_n}）
对于每对，我们计算地球移动距离（又称wasserstein-1距离），并将其表示为 $ d_1，\ dots，\ dots，d_n $ 。。
测试统计 $ \ bar {d} $ 是通过取用 $ d_1，\ dots，d_n $ 。。

 问题：修复总尺寸 $ nk $ ，我想知道 $ k $ 的大小如何变化class =“ Math-Container”&gt; $ \ bar {d} $ 。是否可以为 $ \ bar {d} $ 获得接近表单方差公式？我怀疑主要问题可能是距离度量 - 例如，如果我用估计的最大平均差异（MMD）替换距离度量，那么我将允许我获得 $ \ bar {d} $ 的方差公式？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661909/computing-the-variance-of-a-mean-test-statistic</guid>
      <pubDate>Thu, 27 Feb 2025 05:31:32 GMT</pubDate>
    </item>
    <item>
      <title>固定效应和跨越随机效应结构的模型选择</title>
      <link>https://stats.stackexchange.com/questions/661905/model-selection-for-fixed-effect-and-crossed-random-effect-structure-in-glmer</link>
      <description><![CDATA[我是（广义）线性混合效应模型的新手。任何帮助将不胜感激！
以下是我的研究设计，其中包含虚拟数据。我正在探索我在第1场比赛中操纵的参数对连续游戏2中参与者行为的影响。游戏1的刺激有所不同。
从图像中看到：

 para1和para2是一个概率的中位数和平均值
发生的刺激，在用户行为的运行时计算
第一场比赛和时间，来自Sigmoid功能。
 v1和v2是固定的，用于定义Sigmoid函数并在游戏1中编码条件。
 d1和d2是游戏1的每个块中发生的刺激数量。
第1场中的每个街区随后进行了4场比赛的4次试验，这些试验呈现给
参与者。第2场比赛中的每个试验都略有不同，以试验_id表示。因此，每4行代表第1场比赛中的一个街区和第2场比赛的四个不同试验。

   
有48名参与者（ID），每个参与者都经历了所有24个试验。因此，这是一项对重复措施的受试者内部研究。
我想适合第2游戏中的用户行为的binary_outcome的回归模型，而不是游戏1中的操作。但是，我不确定哪些因素可以最好地代表我在第1场比赛中的操纵，因为它们在用户行为和时间方面是动态计算的。 para1，para2，d1，d2高度相关（＆gt; 0.5）。
我做到了：
 ＃首先，测试不同的随机效果结构
m1＆lt;  -  glmer（binary_outcome〜1 +（1 | id），data = mydata，family = binorial）
m2＆lt;  -  glmer（binary_outcome〜1 +（1 | id） +（1 | trial_id），data = mydata，family = biinasial）

＃M2具有较低的AIC，然后添加固定效果，使用Para1（中位数），因为它显示出比平均值更广泛的分布，并给出更多的“粒度”。
complex_m1＆lt;  -  glmer（binary_outcome〜para1 +（1 | id） +（1 | trial_id），data = mydata，family = biinal = binomial）
complex_m2＆lt;  -  glmer（binary_outcome〜para1 + d1 + d1 + d2 +（1 | id） +（1 | tration_id），data = mydata，family = birneper = binorial）

＃与试验的测试互动效果，更改了优化器，因为该模型无法收敛
complex_m3＆lt;  -  glmer（binary_outcome〜（para1 + d1 + d2） *试验_num +（1 | id） +（1 | tration_id），data = mydata，family，family = binomial，
                     控制= glmercontrol（优化器=; bobyqa; quot））
complex_m4＆lt;  -  glmer（binary_outcome〜para1 + d1 + d1 + d2 + trial_num +（1 | id） +（1 | tration_id），data = mydata，family = binorial = binomial，
                     控制= glmercontrol（优化器=; bobyqa; quot））

＃将试验大致编码为难度条件，省略了试验的变化
complex_m5＆lt;  -  glmer（binary_outcome〜条件 *试验_num +（1 | id） +（1 | tration_id），data = mydata，family，family = binomial，control = glmercontrol（optimizer = optimizer =; nloptwrap; nloptwrap; quot; quot; quot;

＃测试试验的主要效果
mod_tn＆lt;  -  update（complex_m3，。〜。-trial_num）
＃para1
mod_median＆lt;  -  update（complex_m3，。〜。 -para1）
＃Para1 D1 D2的主要效果
mod_three_factors＆lt;  -  update（complex_m3，。〜。 -para1 -d1 -d2）

#Compare模型AIC
AICCTAB（complect_m1，complex_m2，complex_m3，complex_m4，complex_m5，mod_tn，mod_three_factors，mod_median，mnames = model_names = model_names，base = true，striges = true，loglik = true，loglik = true）
                  
 
我得到了结果：
  complex_m3获得最低的AIC，我可以选择此模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661905/model-selection-for-fixed-effect-and-crossed-random-effect-structure-in-glmer</guid>
      <pubDate>Thu, 27 Feb 2025 02:19:26 GMT</pubDate>
    </item>
    <item>
      <title>LAVAAN SEM模型：如何使用三级IV和R中的两级主持人建模2×3阶乘设计？</title>
      <link>https://stats.stackexchange.com/questions/661903/lavaan-sem-model-how-to-model-a-2%c3%973-factorial-design-with-a-three-level-iv-and</link>
      <description><![CDATA[我有一个2×3的阶乘设计：
•因子1（主持人）：源文本复杂性（2级：低，高）
•因子2（iv）：翻译质量（3级：坏，好，人）
我使用虚拟变量来编码三个翻译级别，但是我注意到在我的Lavaan SEM模型中，虚拟编码仅允许比较：
•人与坏
•好与坏
该模型永远不会直接比较良好与人。
  data  $ good_translation＆lt;  -  ifelse（数据$  three thr_level_dummy_translation == 2，1，1，0）
数据 $ human_translation＆lt;  -  ifelse（数据$  three&gt; three_level_dummy_translation == 3，1，0）

＃创建与主持人“ sourceGroup”的互动术语“
数据 $ good_translation_complexity＆lt;  - 数据$  good_translation * data  $ sourcegroup
数据$  human_translation_complexity＆lt;  - 数据 $ human_translation * data $  sourceGroup

＃指定简化的SEM模型（无信任）
模型＆lt;  - &#39;
  ＃潜在变量
  智能= 〜Intelligent_1 + impelligent_2 + impellent_3 + implity_5 + implactent_6
  personificaiton =〜personificaiton1 + personificaiton2 + personificaiton3 + personificaiton4

  ＃直接对感知智能的影响（有节制）
  智能〜A1*good_translation + a2*human_translation +
                a3*good_translation_complexity + a4*human_translation_complexity

  ＃直接影响感知的人格化（适度）
  ＃控制智力
  personificaiton〜B1*智能 +
                    a5*good_translation + a6*human_translation +
                    A7*good_translation_complexity + a8*human_translation_complexity

    ＃直接差异的定义参数：
  diff_intelligence：= a2 -a1＃对智能的影响差异（人类与良好）
  diff_personification：= a6 -a5＃直接影响拟人化的差异（人与良好）

  ＃定义的适度参数（交互）差异：
  diff_mod_intelligence：= a4 -a3＃适度效果对智能的差异
  diff_mod_personification：= a8 -a7＃适度效果对人格化效果的差异

  ＃通过智能从IV到人格化的调解（间接）影响：
  indirect_good：= a1 * b1＃良好翻译的中介效果
  indirect_human：= a2 * b1＃人类翻译的中介效果

  ＃针对拟人化的调解差异的定义参数：
  diff_med_personification：= indirect_human- indirect_good
&#39;
``
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661903/lavaan-sem-model-how-to-model-a-2%c3%973-factorial-design-with-a-three-level-iv-and</guid>
      <pubDate>Thu, 27 Feb 2025 01:24:03 GMT</pubDate>
    </item>
    <item>
      <title>log-transforming响应变量有助于创建均质的残差，但它会产生0 <x <1的不良值</title>
      <link>https://stats.stackexchange.com/questions/661899/log-transforming-response-variable-helps-create-homoscedastic-residuals-but-it</link>
      <description><![CDATA[我正在尝试建模我的模型预测误差（计算为测量的绝对值 - 预测）与省份的年平均温度，作为随机效应，并具有以下模型：
态
由于采用绝对值，错误响应变量始终为正。值通常范围从0.1（表明与测量值非常好的仿真一致）到100（表明模拟精度非常差）。 
当我建模这种关系时，我会得到非常异性的残差：
 如果我首先将响应变量登录，则会获得更多均匀的残差。但是，在模型一致性确实良好且错误在0到1之间的情况下，对数转换数据会导致较大的负值：
 这是一个很好的实例，我应该在其中进行日志（x+1）？这个论坛上的许多人都不同意这种做法（例如这是残留方差，其响应变量由log（x+1）转换：
 &lt;img alt =“在此处输入图像描述”]]></description>
      <guid>https://stats.stackexchange.com/questions/661899/log-transforming-response-variable-helps-create-homoscedastic-residuals-but-it</guid>
      <pubDate>Thu, 27 Feb 2025 00:12:59 GMT</pubDate>
    </item>
    <item>
      <title>Fisher信息的重新聚集</title>
      <link>https://stats.stackexchange.com/questions/661896/reparameterization-of-the-fisher-information</link>
      <description><![CDATA[  大家好，
我不明白为什么我们为什么有 $ l _ {\ phi}（\ phi）= l _ {\ theta}（h^{ -  1}（\ phi）（\ phi））$ span $不应该是或如何 $ l _ {\ theta}（h^{ -  1}（\ phi）（\ phi）= l _ {\ phi}（\ phi}（\ phi}（\ theta））也许下标使我在这里感到困惑。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661896/reparameterization-of-the-fisher-information</guid>
      <pubDate>Wed, 26 Feb 2025 22:08:26 GMT</pubDate>
    </item>
    <item>
      <title>早期培训中的班级预测分布不平吗？</title>
      <link>https://stats.stackexchange.com/questions/661895/is-uneven-class-prediction-distribution-in-early-training-beneficial</link>
      <description><![CDATA[我正在用平衡的数据集编写一个模型，以解决图像分类问题。我注意到，随着培训的进展，我的模型似乎首先预测了几个课程，然后再扩展到培训结束时再次扩展到更均匀的预测分布。这种行为叫什么，这是有益的吗？它使我想起了课程学习的目标，或者据我所知，这是在这里独自发生的，而没有任何故意促进这种行为的情况。
这是三个图的图片，显示了我所指的行为：
 左图是在训练的最新开始，并且预测在所有类之间都非常均匀地分布。中间图是中间训练，显示出更不平衡的分布。右图显示了在训练结束时分布的样子，并且更甚至是。]]></description>
      <guid>https://stats.stackexchange.com/questions/661895/is-uneven-class-prediction-distribution-in-early-training-beneficial</guid>
      <pubDate>Wed, 26 Feb 2025 22:04:40 GMT</pubDate>
    </item>
    <item>
      <title>随机效应建模与Stouffer的荟萃分析方法</title>
      <link>https://stats.stackexchange.com/questions/661894/random-effects-modeling-vs-stouffers-method-in-meta-analysis</link>
      <description><![CDATA[假设两个点估计值及其相应的 $ z $ 统计值可用于荟萃分析。随机效应模型通常被认为是适当的方法，因为它涉及研究内和研究之间的变异性。但是，如果Stouffer的方法专门用于 $ z $ 统计学，是否会导致低估或高估荟萃分析的统计强度？例如，一种方法可以产生重大结果，而另一种方法没有？如果是这样，是否存在模拟案例或现有文献来说明此类偏见？]]></description>
      <guid>https://stats.stackexchange.com/questions/661894/random-effects-modeling-vs-stouffers-method-in-meta-analysis</guid>
      <pubDate>Wed, 26 Feb 2025 22:04:26 GMT</pubDate>
    </item>
    <item>
      <title>从山脊回归中的重要特征相互矛盾的特征 - 如何解释？</title>
      <link>https://stats.stackexchange.com/questions/661893/conflicting-feature-importance-from-ridge-regression-how-to-interpret</link>
      <description><![CDATA[我正在使用多种方法来得出具有相关功能的数据集的特征重要性：
我正在为以下模型使用模型系数：
山脊，套索和弹性净回归
此外，我还将置换重要性用于随机森林模型，XGBoost模型的平均增益用于分析特征重要性。
这些方法中的大多数在最重要的特征中表现出合理的一致性，但是脊回归侧重于不同的特征。处理相关功能时，这是一种适当的方法吗？
编辑：我要解决的具体问题是预测某些（生理化学）特性，以及哪些特征对于预测它们最重要。山脊回归具有溶解度为最重要的特征（根据特征系数），其他模型却没有。]]></description>
      <guid>https://stats.stackexchange.com/questions/661893/conflicting-feature-importance-from-ridge-regression-how-to-interpret</guid>
      <pubDate>Wed, 26 Feb 2025 22:04:03 GMT</pubDate>
    </item>
    <item>
      <title>SVD的行告诉我们有关PCA的什么？</title>
      <link>https://stats.stackexchange.com/questions/661892/what-do-the-rows-of-svd-tell-us-about-pca</link>
      <description><![CDATA[If we have a matrix $X\in\mathbb{R}^{n\times p}$ with SVD $X = UDV^T$, we can say for example that the columns of $V$ are the principal directions and  $ ud $ 的列是主要组件（请参阅此答案）。）。）。）。
我们可以就PCA的这些行做出任何有趣的陈述吗？一位同事告诉我， $ v $ 的行与功能对每个主要组件的贡献相对应，但是我无法在此上找到任何证据或文献。]]></description>
      <guid>https://stats.stackexchange.com/questions/661892/what-do-the-rows-of-svd-tell-us-about-pca</guid>
      <pubDate>Wed, 26 Feb 2025 21:59:12 GMT</pubDate>
    </item>
    <item>
      <title>有关跨尺度探索性结构方程建模（ESEM）的问题</title>
      <link>https://stats.stackexchange.com/questions/661890/question-about-cross-scale-exploratory-structural-equation-modeling-esem</link>
      <description><![CDATA[我正在研究一个正在使用探索性结构方程建模（ESEM）的项目。我通常会看到ESEM用于范围内的文章。您可以做ESEM，其中不仅在尺度上而且在尺度之间存在互载吗？
例如，假设您有2个量表，每个量表有3个因素，12个问题（每个因素4个问题）我可以在比例项内和比例项之间的每个项目交叉载荷吗？之间？
该项目的上下文，我的量表是我的理论化（和先前的研究）测量全球潜在特征。我试图将论点定位为“这些”正在测量同一件事。
如果您能提供任何有助于此询问的文章，我将非常感谢它！]]></description>
      <guid>https://stats.stackexchange.com/questions/661890/question-about-cross-scale-exploratory-structural-equation-modeling-esem</guid>
      <pubDate>Wed, 26 Feb 2025 21:51:52 GMT</pubDate>
    </item>
    <item>
      <title>选择一种重复测量的统计测试方法，以确定测量值是否存在趋势</title>
      <link>https://stats.stackexchange.com/questions/661888/selecting-a-statistical-test-method-for-repeated-measurements-to-determine-if-th</link>
      <description><![CDATA[这可能是一个简单的问题，但是...
我与之合作的城市有一个固定墙，显示了装饰性面部的一些裂缝。我们无法判断这是否只是需要修复的面孔，还是墙壁实际移动（那将是不好的）。  从现场观测来看，我们看不到任何其他证据表明墙壁运动（例如墙后的土壤或墙壁倾斜的土壤 - 所以，这很好）。  我们已经使用了调查设备来测量8个不同位置的墙壁顶部（通常在发生裂缝的位置上）。  我们从8月底开始了测量结果，并每月（一周内+/-）与相同的设备和操作员进行了相同的位置。  我们对每个位置都有6个观察结果。  测量误差的设备为+/- 0.03英尺。  数据是北向和朝东的坐标对（北方的坐标就像y柱，朝东是x柱子）。  我不知道的一件事是，季节性天气是否会引起墙壁的某些自然运动，我们只衡量了大约半年 - 我们从夏天开始，现在已经低于零，地面被冻结了 - 因此，如果有一些自然运动，我不会感到惊讶。我确定我还没有足够的数据来回答这个问题。
无论如何，我想分析我必须查看一个方向上是否存在趋势（墙正在移动），或者是移动和观察错误或多或少是随机的，或者有足够的数据要说，我们需要继续测量。  我的直觉告诉我，这并没有显着移动，但是我希望以某种方式以某种程度的概率进行中间分析。
我首先想到按位置对数据进行线性回归分析，以查看 $ r^{2} $ 表示线性性，但是我认为如果墙壁只是来回振荡，这可能会显示出线性模式，尽管不是一个方向。  我想到了北向的T测试和t的t测试，以为如果动作是随机的，它将聚集在某个中心点周围（正常分布？也许？），但我并没有真正比较两个数据集的平均值。我正在比较随着时间的推移在同一位置进行的测量。  假设我的比较样本为零，我考虑了T测试，但这似乎也不正确。我有点狡猾，可以使用一些指导，将我指向正确的方向进行适当的测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/661888/selecting-a-statistical-test-method-for-repeated-measurements-to-determine-if-th</guid>
      <pubDate>Wed, 26 Feb 2025 21:42:01 GMT</pubDate>
    </item>
    <item>
      <title>GLMMTMB订购Beta回归问题 - 模型收敛和NAN产生</title>
      <link>https://stats.stackexchange.com/questions/661881/glmmtmb-ordered-beta-regression-issue-model-convergence-and-nans-produced</link>
      <description><![CDATA[我有一个响应变量的蜗牛消耗，这是一个比例（蜗牛死亡的数量/每介子的蜗牛总数）。我有一些使所有蜗牛死亡或没有死亡的中焦（因此，介于两者之间的0s和1s）。）。
我一直在研究可以处理0s和1s的模型，从我的研究中，听起来好像是我的订单beta回归可能是我的最佳选择（ https://www.robertkubinec.com/post/limited_dvs/ ）。我（到目前为止）对贝叶斯统计数据并不熟悉或解释输出，因此我很高兴发现我可以在GLMMTMB软件包中进行有序的beta回归，而我更熟悉的输出。我的模型如下，没有随机效果：
  m3＆lt;  -  glmmtmb（snail_consumption〜处理，data = nail_surv， 
              family = odbeta）
 
当我运行时，我会得到此警告：
 警告消息： 
在finalizetmb（tmbstruc，obj，fit，h，data.tmb.old）中：  
模型收敛问题；奇异收敛（7）。看  
    Vignette（“故障排除”），帮助（“诊断”）
 
这就是我在诊断功能中得到的：
 诊断（M3）
异常大的系数（| x |＆gt; 10）：
（截距）处理13处理24处理5处理21处理1 
    治疗19
-48.16492 48.5203​​8 50.42512 47.99970 49.47301 49.30457 86.22261
较低的截止
-22.41878

ZI（零通气的log-odds）中的大型负系数，  
    分散或随机
效果（对数标准偏差）提出不必要的组件  
    （在
受限的量表）；大的负面和/或正组件  
    二项式或泊松
有条件参数建议（准）完全分离。大的  
    NBINOM2的值  
分散表明您应该使用泊松模型。
 
这就是我的模型摘要Nans所得到的，我认为这确实有一个融合问题：
 ＆gt;摘要（M3）
 家庭：Ordbeta（Logit）
配方：蜗牛_CHIMPOMPTION〜处理
数据：Snail_SURV2

     AIC BIC LOGLIK偏差DF。 
    45.3 62.7 -12.7 25.3 32 

Ordbeta家族的分散参数（）：3.29 

条件模型：
            估计标准。错误z值pr（＆gt; | z |）
（截距）-48.16 Nan Nan Nan
治疗13 48.52 Nan Nan Nan
处理24 50.43 Nan Nan Nan
处理5 48.00 Nan Nan Nan
处理21 49.47 Nan Nan Nan
治疗1 49.30 Nan Nan Nan
处理19 86.22 Nan Nan Nan
 
转换我的数据，因此没有0和1确实使模型起作用：
 ＃略微转换数据，因此不是1或0
n＆lt;  -  nrow（snail_surv2）
snail_surv2 $ snail_consumption＆lt;  - （snail_surv2 $ snail_cummumption *（n -1） + 
                                        0.5） /n
 
，但从我的阅读中，这已经不再是一种建议的实践了。有人对为什么该模型不运行以及我能做什么来修复它有任何洞察力？]]></description>
      <guid>https://stats.stackexchange.com/questions/661881/glmmtmb-ordered-beta-regression-issue-model-convergence-and-nans-produced</guid>
      <pubDate>Wed, 26 Feb 2025 17:51:27 GMT</pubDate>
    </item>
    <item>
      <title>卡方功率分析</title>
      <link>https://stats.stackexchange.com/questions/661880/chi-square-power-analysis</link>
      <description><![CDATA[我正在尝试确定我是否有足够的功率和/或大型样本量，可以通过我的数据进行卡方分析。当使用SPSS以1个样本人口比例运行功率分析时，它要求人口比例和无效价值。当我尝试估计功率或样本量时，我不知道该盒子放入这些框中。我正在寻找.8功率，样本量为44。]]></description>
      <guid>https://stats.stackexchange.com/questions/661880/chi-square-power-analysis</guid>
      <pubDate>Wed, 26 Feb 2025 17:21:43 GMT</pubDate>
    </item>
    <item>
      <title>自相关和信息丢失</title>
      <link>https://stats.stackexchange.com/questions/661879/autocorrelation-and-loss-of-information</link>
      <description><![CDATA[当我们想在样本上训练ML模型时，最好拥有I.I.D培训样本。如果样本是自相关的，我们需要更多数据才能实际训练模型。
直觉上，这很有意义，因为当示例为i.i.d时，每个新数据点都会添加“信息”。 （我们更好地理解分布 $ \ Mathbb {p} _x $ ）。当数据自动相关时，很难理解 $ \ MATHBB {p} _x $ 由于每个数据点没有添加太多信息，我们总是会看到几乎相同的数据点。
我的第一个问题是：有没有一种方法可以实际量化“信息”的概念。数学上？因此，表明当数据自动相关时，我们会丢失有关分布的信息，因此需要更多的数据点。
我的第二个问题是：要使模型了解数据是自动关节的，因此它实际上并不能代表 $ x $ 的真实分布，我们经常考虑datapoints： $ x_t-$ x_t-\ sum \ \ \ alpha_i x_i x_i x_i $ x_i $ 。现在我的问题是：如果我们观察到数据的转换版本，我们仍然可以收敛到密度 $ \ Mathbb {p} _x $ ，此转换后的收敛速度有多慢？]]></description>
      <guid>https://stats.stackexchange.com/questions/661879/autocorrelation-and-loss-of-information</guid>
      <pubDate>Wed, 26 Feb 2025 16:45:58 GMT</pubDate>
    </item>
    <item>
      <title>左截断和间隔审查的数据使用特恩布尔提出的自符敏感算法</title>
      <link>https://stats.stackexchange.com/questions/661848/left-truncated-and-interval-censored-data-using-the-self-consistency-algorithm-p</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661848/left-truncated-and-interval-censored-data-using-the-self-consistency-algorithm-p</guid>
      <pubDate>Tue, 25 Feb 2025 18:29:13 GMT</pubDate>
    </item>
    </channel>
</rss>