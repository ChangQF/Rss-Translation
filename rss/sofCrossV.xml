<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 02 Jun 2024 09:15:46 GMT</lastBuildDate>
    <item>
      <title>如何将“最大值”作为未知值来规范化自定义范围？</title>
      <link>https://stats.stackexchange.com/questions/648467/how-to-normalize-a-custom-range-with-max-being-the-unknown</link>
      <description><![CDATA[要对范围进行归一化，我们应用以下变换：
$$
\frac{x_i - \min(x)}{\max(x) - \min(x)}
$$
要将归一化调整为首选范围，其中 b=max_target 和 a=min_target：
$$
\text{norm}_i \cdot (b - a) + a
$$
如果我们希望调整后的范围之和等于 1，b 将是一个未知数，求解如下：
$$
\left( \frac{1 - n \cdot a}{\sum \text{norm}_i} \right) + a
$$
但是，当 n &gt; 9 时，查找 b 会失败。例如，假设我想规范化一个分布，其中 b=x 和 a=0.1：



标签
频率
adj_norm




1
7
0.35


2
10
0.55


3
3
0.10






标签
频率
adj_norm




1
7
0.09...


2
&lt; td&gt;10
0.08...


3
3
0.09...


4
5
0.09...


5
9
0.08... 


6
4
0.09...


7
6
0.09...


8
8
0.08...


9 
1
0.10


10
2
0.09...


11
20
0.07...



请注意，在第一个表中，频率最低的标签被正确识别为最小值，而频率最高的标签具有正确的最大值，使得数组等于 1。但是，在第二个表中，最大值被错误分类...
关于如何更正 n &gt; 9 的公式，您有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648467/how-to-normalize-a-custom-range-with-max-being-the-unknown</guid>
      <pubDate>Sun, 02 Jun 2024 06:14:01 GMT</pubDate>
    </item>
    <item>
      <title>对顺序数据的依赖性是什么？</title>
      <link>https://stats.stackexchange.com/questions/648464/what-is-dependency-on-sequential-data</link>
      <description><![CDATA[我们知道，只要数据集中的点依赖于数据集中的其他点，数据就被称为顺序数据。
一个常见的例子是时间序列，例如天气数据。

我的问题是“依赖”一词是什么意思？在上面的例子中，数据点如何相互依赖？]]></description>
      <guid>https://stats.stackexchange.com/questions/648464/what-is-dependency-on-sequential-data</guid>
      <pubDate>Sun, 02 Jun 2024 05:33:05 GMT</pubDate>
    </item>
    <item>
      <title>使用预测值置信区间来“预测”结果</title>
      <link>https://stats.stackexchange.com/questions/648463/using-predictive-value-confidence-intervals-to-predict-outcomes</link>
      <description><![CDATA[以下是简要版本：
假设我有一个混淆矩阵，其中包含以下数据，这些数据基于预测试的熟练程度分数线和课程结果（通过/不通过）。
TP：550 FP：200
FN：280 TN：825
以下是一些统计数据：
敏感度：66.27%
1 - 特异性：19.51%
准确度：74.12%
阳性预测值 (PPV；贝叶斯理论)：73.33% 95% 可信区间 (70.64%，75.86%)
1 - 阴性预测值 (NPV)：25.34% 95% 可信区间 (23.49%， 27.28%)
是否可以将 PPV 置信区间中的最小值和最大值与 1 - NPV 置信区间中的最小值和最大值结合使用，根据预测试的结果“预测”某个班级中一组学生通过考试的概率范围？目标是了解预测试结果对学生在课堂上的成功有多“预测”。
例如，根据我们的熟练程度分数线，开学第一天 75% 的学生在预测试中获得了“熟练”的成绩。如果过去的数据（如混淆矩阵所示）表明，如果学生在预测试中表现良好，则通过该课程的概率（PPV）为 73.33%，95% CI（70.64%，75.86%），如果学生在预测试中表现不佳，则通过该课程的概率（NPV）为 25.34%，95% CI（23.49%，27.28%），我们能否使用两个置信区间的最小值和最大值来表示：
0.7064 * 75 + 0.2349 * 25 [两个置信区间的最小值] = 58.9%
0.7586 * 75 + 0.2728 * 25 [两个置信区间的最大值] = 63.7%
我们预计当前学生群体中 58.9% 至 63.7% 的学生将通过课程？
这实际上是使用贝叶斯定理/条件概率，使用过去收集的预测试和课程通过率数据来回答我们的问题。使用置信区间而不是实际条件概率 73.33% 和 25.34% 来执行此操作是否存在问题？当然，这里的“预测”是宽泛的说法。我们知道现实世界总是有一些有趣的事情在等着我们。（旁注：我们将在未来增加一门先修课程，希望随着时间的推移提高通过率。）看看事情如何随着时间的推移而变化，并比较参加先修课程和未参加先修课程的学生的数据以及两组在预测试中的熟练程度等，这将很有趣，但就目前而言……
是否可以进行上述计算并说，根据过去的数据，我们预计当前学生群体中 58.9% 到 63.7% 的学生通过课程？]]></description>
      <guid>https://stats.stackexchange.com/questions/648463/using-predictive-value-confidence-intervals-to-predict-outcomes</guid>
      <pubDate>Sun, 02 Jun 2024 04:55:58 GMT</pubDate>
    </item>
    <item>
      <title>中位数的平均值始终不同于中位数</title>
      <link>https://stats.stackexchange.com/questions/648458/mean-of-medians-consistantly-differs-from-median</link>
      <description><![CDATA[免责声明：这是我的第一个问题。
问题背景：
我想比较两个分布（n1 ~ 500 和 n2 ~ 700），它们不是正态分布，方差也不同，但大致是单峰分布。我决定使用中位数进行比较统计。
使用（scipy 的）置换检验，我得到了两个中位数观察到的差异的 p 值。使用同样生成的零假设分布，我也能够得到实验的最小可检测效果。
我想估计观察到的差异（中位数）的误差（-&gt; 用于绘图的误差线）。所以我使用 np.random.choice 绘制两个具有相同大小的新分布并重复/替换；但不混合组（即假设效果/观察到的差异是真实的）。我计算了两个新分布的中位数差，并重复了 100000 次。
问题
在所有这些实现中，我计算了平均值和标准差，发现平均值（中位数差）与原始数据中位数差相比始终相差约 13%。
这是错误、测试设计错误还是实际可能的结果？如果是最后一个，为什么？这意味着什么？
代码
# 原始实验数据：A、B
# 绘制新的分布 a、b，不进行混合
a = np.random.choice(A, (100000, len(A), True) 
b = np.random.choice(B, (100000, len(B), True)
med_m = np.mean(np.median(a, axis = 1) - np.median(b, axis = 1))
med_s = np.std(np.median(a, axis = 1) - np.median(b, axis = 1))
med = np.median(A) - np.median(B)

med_m / med
&gt;&gt;&gt; 1.13...
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648458/mean-of-medians-consistantly-differs-from-median</guid>
      <pubDate>Sun, 02 Jun 2024 00:57:18 GMT</pubDate>
    </item>
    <item>
      <title>按离散的、不相关的属性进行聚类？</title>
      <link>https://stats.stackexchange.com/questions/648455/clustering-by-discreet-unrelated-properties</link>
      <description><![CDATA[我有大量具有不相关属性的对象，例如

color=yellow
material=stone
is_important=true
等等。

这些属性基本上是随机的，只要用户认为有就好。没有实际的方法可以将这些属性强制转换为具有欧几里得距离的类似物。
我认为，如果不存在某种距离度量，那么从概念上讲，考虑通过这些属性对对象进行聚类是没有意义的（这是正确的吗？），但我希望存在可以产生类似输出的东西
&quot;90% 的 color=yellow 对象也有 material=plastic 和 is_important=false&quot;
除了强制通过数据集之外，还有其他东西可以进行此类分析吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648455/clustering-by-discreet-unrelated-properties</guid>
      <pubDate>Sun, 02 Jun 2024 00:19:01 GMT</pubDate>
    </item>
    <item>
      <title>量化（观察到的）空间聚类？</title>
      <link>https://stats.stackexchange.com/questions/648453/quantifying-observed-spatial-clustering</link>
      <description><![CDATA[我正在寻找一些有关空间统计的建议。
我有一个大型数据集，其中包含 5 种不同条件下的多个样本。每个样本由 2D 空间中的不同点类型组成。例如：
样本 1，条件 1：
X，Y，类型
1，1，A
5，3，A
11，2，B
6，22，L
...

我们注意到，对于某些条件，某些点类型（我们分别称它们为 A 和 B，红色和蓝色）显示不同的分布。在大多数情况下（“通常模式”），A 类与其他 A 类点聚类，B 类与其他 B 类点聚类；每种类型的簇在视觉上彼此不同（参见图像，右侧子图，“通常模式”）。但是，在某些条件下，我们注意到 A 和 B 的簇彼此混合更多； As 可能仍然与 As 聚类（多于 Bs），但 As 和 Bs 的聚类/合并在一起（见图像，左侧子图，“观察到的模式”）。
捕捉和量化这种观察到的现象的最佳方法是什么？（完整披露：我是空间统计的新手）。

到目前为止，我们已经研究了不同条件之间的香农熵（跨所有点类型，例如 A-M），以检查在感兴趣的条件下点类型分布是否存在更多异质性（但似乎没有显着差异）。我们还研究了中心性度量以及邻域丰富度（我们对所有点类型，即 A-M 进行了这些研究）。最近，我们尝试了 DBSCAN（仅关注点类型 A 和 B），希望能够证明结果簇大小存在差异（尽管我个人不确定这是否是解决问题的正确方法）。我们可能尚未令人满意地调整模型参数，但到目前为止，它似乎还没有解决问题。我还担心，虽然它可能有助于探索性数据分析，但我们不太可能使用 DBSCAN 输出来有意义地比较不同条件下的结果。
直观地讲，我认为答案可能在于网络分析和研究几个节点之外的聚类行为（而不是仅仅研究直接邻居，这可能是邻域富集分析对我们不起作用的原因）。
展示和量化观察到的聚类现象的最佳方法是什么？理想情况下，我们需要一种允许比较不同条件的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/648453/quantifying-observed-spatial-clustering</guid>
      <pubDate>Sat, 01 Jun 2024 23:50:11 GMT</pubDate>
    </item>
    <item>
      <title>我们可以使用 CDF 而不是 PDF 来表达无意识统计学家的定律吗？</title>
      <link>https://stats.stackexchange.com/questions/648452/can-we-express-the-law-of-the-unconscious-statistician-using-the-cdf-instead-of</link>
      <description><![CDATA[我只见过LOTUS以密度形式给出
$$\mathbb{E}[g(X)] = \int g(x) f(x) dx$$
或以勒贝格-斯蒂尔杰斯积分形式给出
$$\mathbb{E}[g(X)] = \int g(x) dF_X(x).$$
我还见过这篇文章，其中展示了如何使用 CDF 而不是PDF：

与计算这些矩类似，有没有办法使用 CDF 而不是 PDF 来编写 LOTUS？]]></description>
      <guid>https://stats.stackexchange.com/questions/648452/can-we-express-the-law-of-the-unconscious-statistician-using-the-cdf-instead-of</guid>
      <pubDate>Sat, 01 Jun 2024 22:37:36 GMT</pubDate>
    </item>
    <item>
      <title>为什么建议在对 lmer 模型进行参数引导时保留 use.u=T（在 bootMer 中）？</title>
      <link>https://stats.stackexchange.com/questions/648440/why-is-it-recommended-to-keep-use-u-t-in-bootmer-when-doing-parametric-bootstr</link>
      <description><![CDATA[我正在执行参数引导，目的是使用模拟值为混合模型中的系数创建置信区间。我看到通常建议在 R 的 lme4 包中的 bootMer 函数中设置 use.u=T，我想知道为什么？我认为重新采样随机效应是有意义的，以便捕获完整的不确定性。
需要澄清的是，如果我要在最近收集的数据集上重新运行模型，实际级别（或类别）将相同，只是值会有所不同。
如果有更多资源/论文涉及这一点，那将会很有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/648440/why-is-it-recommended-to-keep-use-u-t-in-bootmer-when-doing-parametric-bootstr</guid>
      <pubDate>Sat, 01 Jun 2024 19:04:25 GMT</pubDate>
    </item>
    <item>
      <title>特征提取和降维是一种压缩吗？</title>
      <link>https://stats.stackexchange.com/questions/648437/is-feature-extraction-and-dimensionality-reduction-a-kind-of-compression</link>
      <description><![CDATA[我很难理解这些术语的共同点：

特征提取
特征选择
压缩
降维

相关地，我们数据中的信息/熵应该始终保持不变，那么我们实际上在添加/减少什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648437/is-feature-extraction-and-dimensionality-reduction-a-kind-of-compression</guid>
      <pubDate>Sat, 01 Jun 2024 15:31:36 GMT</pubDate>
    </item>
    <item>
      <title>什么是协同过滤？</title>
      <link>https://stats.stackexchange.com/questions/648424/what-defines-collaborative-filtering</link>
      <description><![CDATA[协同过滤的定义特征是什么？
如果您采用两个嵌入向量（一个用于用户，一个用于项目），您可以进行点积并将结果传递给 S 型函数来预测 CTR。这是协同过滤吗？
或者，您可以在每个嵌入上放置多个 FC 层，然后进行点积。这是协同过滤吗？
您还可以将多个离散和连续特征连接到每个嵌入，然后将它们传递给 FC 层并进行 S 型函数。这是协同过滤吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648424/what-defines-collaborative-filtering</guid>
      <pubDate>Sat, 01 Jun 2024 09:23:06 GMT</pubDate>
    </item>
    <item>
      <title>两组时间序列之间的假设检验</title>
      <link>https://stats.stackexchange.com/questions/648405/hypothesis-testing-between-two-sets-of-time-series</link>
      <description><![CDATA[我想通过比较在不同时间捕获的两组时间序列来验证捕获方法的可重复性。
让我们考虑两组时间序列$A=(tsa_1,\dots,tsa_n)$和$B=(tsb_1,\dots,tsb_m)$，其中$n,m &gt;&gt; 100$。
我们还定义$H_0$=两个数据集彼此一致，并且$H_a$=两个数据集显示出显着差异。
测试这些假设的经典方法是什么？
我想出了基于距离的方法，但我想探索统计方法来进行比较。我读过关于统计测试的文章，但找不到太多关于处理时间序列的信息。任何帮助或资源指导都值得赞赏。
为了论证的目的，我们可以考虑类似于下图的数据。这些是围绕预定义模式用正常噪声生成的合成数据，但实际捕获的数据预计具有相同的属性。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648405/hypothesis-testing-between-two-sets-of-time-series</guid>
      <pubDate>Fri, 31 May 2024 18:00:19 GMT</pubDate>
    </item>
    <item>
      <title>条件 Logit 模型 - 效用结构估计 - 元分析</title>
      <link>https://stats.stackexchange.com/questions/648401/conditional-logit-model-utility-structural-estimation-meta-analysis</link>
      <description><![CDATA[我正在使用 McFadden (2001) 框架（参见参考资料）对多个数据库（来自不同的文章）中的效用函数进行结构估计。
每篇文章的数据库包含 N 个主题、J 个选项，从而给出 J x N 行。每个主题都选择了 J 个选项中的一个。数据还包括一些特定于选择的特征。
使用此数据结构，我通过条件逻辑模型 (CLM) 以两种方式估计效用参数：
一般估计：我对整个数据集运行了一个唯一的 CLM。请注意，J 可以在不同文章中变化
逐篇文章估计：我对每篇文章运行一个 CLM，并对结果估计进行平均
但是，这两种方法给出的结果截然不同。
有谁知道哪种程序（如果有的话）最适合提供这些参数的元估计？
谢谢！
参考文献：McFadden，D.（2001）。经济选择。美国经济评论，91(3)，351-378。]]></description>
      <guid>https://stats.stackexchange.com/questions/648401/conditional-logit-model-utility-structural-estimation-meta-analysis</guid>
      <pubDate>Fri, 31 May 2024 16:58:04 GMT</pubDate>
    </item>
    <item>
      <title>随机效应模型：理解与、之间和上下文效应</title>
      <link>https://stats.stackexchange.com/questions/648373/random-effect-models-understanding-with-between-and-contextual-effect</link>
      <description><![CDATA[为了更好地理解和更有效地应用随机/固定效应和聚类标准误差，我一直在努力理解“内部”、“之间”和“上下文”效应这些术语。

据我所知，我们只能在没有上下文效应的情况下应用随机效应模型 - 否则随机效应假设不成立。对吗？这是否也意味着在这种情况下，组内和组间效应是相同的？

请看以下示例：



数据：汇总的横断面调查数据，其中各个受访者嵌套在各个国家/地区，并且调查多年来在每个国家/地区进行多次
研究问题旨在找出国家级变量（例如 GDP）是否影响受访者回答有关生活满意度的问题的方式
感兴趣的影响：GDP 对生活满意度的总体影响

我感兴趣的是哪种影响：组内、组间还是上下文？这样的研究是否需要随机效应模型？或者聚类标准误差就足够了？]]></description>
      <guid>https://stats.stackexchange.com/questions/648373/random-effect-models-understanding-with-between-and-contextual-effect</guid>
      <pubDate>Fri, 31 May 2024 12:58:22 GMT</pubDate>
    </item>
    <item>
      <title>在绘制平滑缩放的 Schoenfeld 残差图时，R 中的 transform="" 到底起什么作用？</title>
      <link>https://stats.stackexchange.com/questions/648370/what-does-transform-in-r-exactly-do-when-plotting-the-smoothed-scaled-schoenf</link>
      <description><![CDATA[编辑：“我的问题已被关闭，因为它似乎不属于这里，因为它与统计无关。我不同意这个决定，感谢@J-J-J 在这方面对我的支持。我会尝试澄清，我想从统计的角度而不是编码的角度来理解以下问题。我有 4 个问题。我删除了第四个，因为那是唯一一个与编码有关的问题。所以这是我的责任，但我希望有人能帮助我理解其他三个问题。提前谢谢您！”
正如标题所示，我旨在解决 R 中的参数 transform = &#39;&#39;，特别是关于用于评估比例风险 (PH) 假设的平滑缩放 Schoenfeld 残差检验/图。
我知道默认是 transform = &#39;km&#39;，但还有其他可用选项：
transform=&#39;log&#39;
transform=&#39;rank&#39;
transform=&#39;identity&#39;

我相信我了解每个选项的含义。如果我的理解不正确，请纠正我：
log 用于强调早期事件，因为它为它们分配了更大的权重。
rank 用于突出显示晚期事件，因为它为它们分配了更大的权重。
identity 表示未经任何修改的原始时间数据。
但是，我不确定 km 到底是做什么的。虽然它似乎可以缩短时间，但我不确定它的含义。
我的问题：

我应该何时使用每个转换来评估 R 中的 cox.zph() 测试/绘图？（编辑：从统计角度来看，我应该在什么情况下使用它？）

它们为 PH 假设产生不同的 p 值。根据所选的转换，我应该信任哪个 p 值？（编辑：再次从统计角度）

虽然我理解 transform = &#39;&#39; 参数的总体目的，但我仍然不确定在哪些情况下应该选择每个参数。（编辑：从统计角度来看，有人可以澄清何时使用每个转换吗？）

]]></description>
      <guid>https://stats.stackexchange.com/questions/648370/what-does-transform-in-r-exactly-do-when-plotting-the-smoothed-scaled-schoenf</guid>
      <pubDate>Fri, 31 May 2024 12:11:26 GMT</pubDate>
    </item>
    <item>
      <title>小样本与大样本的因果效应和外生性</title>
      <link>https://stats.stackexchange.com/questions/648335/causal-effect-and-exogeneity-in-small-samples-vs-in-large-samples</link>
      <description><![CDATA[这个标题下有两个问题。
在 Y 对 X 和控制 Z 的回归中，随机误差为 e，

在小样本中，如果满足严格外生性，即 E(e|X,Z)=0，是否意味着 X 的系数具有因果关系的意义？
在大样本中，严格外生性的条件是否可以放宽为不相关，即 Cov(e,X)=0 和 Cov(e,Z)=0，以描述因果关系？如果答案是肯定的，请用公式推导原因。

我发现很多书和论文（例如关于 IV）讨论的是相关性而不是外生性。我查过一些教科书，它们只解释了从小样本的无偏变为大样本的一致性的性质，这与因果关系无关。]]></description>
      <guid>https://stats.stackexchange.com/questions/648335/causal-effect-and-exogeneity-in-small-samples-vs-in-large-samples</guid>
      <pubDate>Fri, 31 May 2024 03:26:25 GMT</pubDate>
    </item>
    </channel>
</rss>