<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 05 Sep 2024 21:15:17 GMT</lastBuildDate>
    <item>
      <title>基于上下文词的词语相似度公式</title>
      <link>https://stats.stackexchange.com/questions/653937/words-similarity-formula-based-on-the-context-words</link>
      <description><![CDATA[我正在研究我的词嵌入计算算法，但遇到了一个相似度公式。
我认为这可以通过统计和概率轻松地正式推导出来，但我做不到。你能帮忙吗？
给定
词素（我们将其命名为并置词素或colex）在文本中（在不同位置）紧接着感兴趣的词素，我们将它们称为lex1和lex2*。
我知道：

lex1跟随colex的次数（Lex1FollowCount）。
lex2跟随colex的次数（Lex2FollowCount）。
对于每个lex1、lex2、colex，我知道它们在文本中出现的次数（*InText）。

目标
根据以上信息，我想计算一些值（最好在[0,1] 范围）反映了词法单元 lex1 和 lex2 的相似程度。我正在寻找概率论的正式推导。包括，我试图解决什么样的概率论任务，我缺少什么以及如何解决它。更正式一点，当所有 colex 词法单元以相同的概率与 lex1 和 lex2 搭配时，两个词法单元是相似的（相似度 = 1）。
有一件事让它变得更难。我理解至少应该有两个结果：相似性和置信度，最后一个应该基于考虑的搭配的数量，但目前我想将它们打包成一个结果，即相似性。
因此，如果对于大文本，我有一个完美的搭配（如上例所示），这种搭配在文本中很少发生（Lex1FollowCount = 3，Lex2FollowCount=5，等等），我希望相似度的值仍然很低。因此，只有在文本中多次出现确认匹配度高的情况下，最终相似度才会很高。
我的最佳猜测
我确信该公式可以正式推导，但我没有这样做，所以我目前使用了我最好的猜测：
$$ P_{lex1} = \frac{ Lex1FollowCount }{ Lex1InText } $$
$$ P_{lex2} = \frac{ Lex2FollowCount }{ Lex2InText } $$
$$ P_{correlated} = P_{lex1} * P_{lex2} $$
$$ 相似度 = P_{correlated} * min(Lex1InText, Lex2InText ) $$
实际上，它有效并且给出了“足够好”的结果，但如果使用更好的公式，仍然可以改进。
我的公式存在问题以及需要考虑的问题
这个公式很难规范化。
在实际文本中，两种项目没有太大帮助：（a）稀有项目，这由最后一个公式中的乘法处理；稀有项目的结果较少；（b）非常频繁的项目（如“and”、“or”等），它们有很多含义，但在大多数语言中对词语相似度计算没有帮助。因此，如果最常见项目的“权重”也很低，那就太好了。
我尝试了几十个受量化词袋的相似性和类似算法启发的公式，但似乎我的任务要简单得多，最终可以形式化。如果不是，请帮助我找到我所遇到的真正问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/653937/words-similarity-formula-based-on-the-context-words</guid>
      <pubDate>Thu, 05 Sep 2024 20:53:48 GMT</pubDate>
    </item>
    <item>
      <title>使用外生变量进行时间序列预测的困难</title>
      <link>https://stats.stackexchange.com/questions/653934/difficulties-in-using-exogenous-variables-for-time-series-forecasting</link>
      <description><![CDATA[在使用外生变量进行时间序列建模时，我有点困惑。假设我正在建模房价，我的一个外生变量是“房屋类型”，其值为“单元”或“房屋”。当预测未来时，预测的值显然是房价。
我该如何确定未来房屋类型的价值？我是否应该为每种房屋类型训练 2 个单独的模型并完全丢弃变量？或者我只是不尝试假设“房屋类型”的值是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/653934/difficulties-in-using-exogenous-variables-for-time-series-forecasting</guid>
      <pubDate>Thu, 05 Sep 2024 19:16:36 GMT</pubDate>
    </item>
    <item>
      <title>ARCH 模型是否对之前的时间序列值或其残差进行回归？</title>
      <link>https://stats.stackexchange.com/questions/653932/is-an-arch-model-regressed-over-previous-time-series-values-or-their-residuals</link>
      <description><![CDATA[假设我们有一个时间序列$\{y_t\}$，我们希望使用 ARCH 或 GARCH 模型对其进行建模。也就是说，我们假设时间序列可以写成以下形式：
$$y_t = \mu_t + \epsilon_t$$
其中 $\mu_t$ 是时间 $t$ 的条件均值，可以通过例如 ARMA 模型和 $\epsilon_t \sim \mathcal{D}(0, \sigma_t^2)$ 估计，其中 $\mathcal{D}$ 为任意分布。
ARCH 和 GARCH 模型的要点都是对条件方差 $\sigma_t^2$ 进行建模。如果我们使用 ARCH 模型，那么我们的想法是使用 AR 模型对 $\sigma_t^2$ 进行建模。这意味着，对于 ARCH(1) 模型：
$$\sigma_t = \alpha_0 + \alpha_1 y_{t-1}。 \tag{1}$$
但是其他来源，例如维基百科，指出我们不对滞后$y_t$项进行回归，而是对滞后残差$\epsilon_t$进行回归：
$$\sigma_t = \alpha_0 + \alpha_1 \epsilon_{t-1} \tag{2}.$$
对于任一模型，都可以使用 OLS 找到参数。
我对上述内容有两个问题：

哪个是正确的 ARCH 模型，(1) 还是 (2)？换句话说，我们应该回归之前的时间序列值$y_t$还是残差$\epsilon_t$？
$\epsilon_t$是不可观察的创新。我读到，在实践中，如果我们使用模型 (2)，那么我们可以将$\epsilon_{t-1}$估计为$\hat{y}_{t-1} - y_{t-1}$。这是真的吗？如果是，有什么理由这样做？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653932/is-an-arch-model-regressed-over-previous-time-series-values-or-their-residuals</guid>
      <pubDate>Thu, 05 Sep 2024 18:47:01 GMT</pubDate>
    </item>
    <item>
      <title>基于 eviews 的货币政策 ARDL 模型研究</title>
      <link>https://stats.stackexchange.com/questions/653931/ardl-model-on-monetary-policy-study-on-eviews</link>
      <description><![CDATA[我实际上正在撰写关于货币政策传导的硕士论文，我对我的 ARDL 方法的结果表示怀疑。我有 4 个模型（1 个基准和 3 个替代方案）
有人可以看一下吗？！！
我的导师说没问题，但他实际上并没有读过。

[
]]></description>
      <guid>https://stats.stackexchange.com/questions/653931/ardl-model-on-monetary-policy-study-on-eviews</guid>
      <pubDate>Thu, 05 Sep 2024 18:45:28 GMT</pubDate>
    </item>
    <item>
      <title>KS 检验与最大似然拟合相矛盾</title>
      <link>https://stats.stackexchange.com/questions/653930/ks-test-contradicts-maximul-likely-hood-fitting</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653930/ks-test-contradicts-maximul-likely-hood-fitting</guid>
      <pubDate>Thu, 05 Sep 2024 18:21:03 GMT</pubDate>
    </item>
    <item>
      <title>参数数量与数据维数关系的来源</title>
      <link>https://stats.stackexchange.com/questions/653929/source-of-the-relationship-between-the-number-of-parameters-and-data-dimensional</link>
      <description><![CDATA[人们普遍认为，在经典统计模型中，观测值的数量应至少等于参数的数量，以确保这些参数的可估计性，例如，如果我们想要获得 MLE。否则，某些参数是不可估计的。当然，在神经网络等中情况并非如此。
我曾从秩的角度看到过线性回归或线性代数的解释。
我想问一下，是否有人可以在更通用的设置中找到这个的来源。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653929/source-of-the-relationship-between-the-number-of-parameters-and-data-dimensional</guid>
      <pubDate>Thu, 05 Sep 2024 18:06:20 GMT</pubDate>
    </item>
    <item>
      <title>出版物中的 Microsynth“可行模型”示例在我的 R 安装中返回不可行模型[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653927/microsynth-feasible-model-example-from-publication-returns-infeasible-models-i</link>
      <description><![CDATA[我正在尝试重新运行 microsynth 包出版物中提供的示例，该示例估计干预（DMI）对四种犯罪结果（i_felony、i_misdemea、i_drugs、any_crime）的影响。该示例应该生成可行的模型，但在我的 R 安装中，它始终返回不可行的模型。
以下是示例中的代码：
data(&quot;seattledmi&quot;)

match.out &lt;- c(&quot;i_felony&quot;, &quot;i_misdemea&quot;, &quot;i_drugs&quot;, &quot;any_crime&quot;)
cov.var &lt;- c(&quot;TotalPop&quot;, &quot;BLACK&quot;, &quot;HISPANIC&quot;, &quot;Males_1521&quot;, &quot;HOUSEHOLDS&quot;, 
&quot;FAMILYHOUS&quot;, &quot;FEMALE_HOU&quot;, &quot;RENTER_HOU&quot;, &quot;VACANT_HOU&quot;)

sea2 &lt;- microsynth(seattledmi, idvar = &quot;ID&quot;, timevar = &quot;time&quot;,
intvar = &quot;Intervention&quot;, start.pre = 1, end.pre = 12, end.post = 16,
match.out = match.out, match.covar = cov.var, result.var = match.out,
test = &quot;lower&quot;, n.cores = 10, check.feas = TRUE, use.backup = TRUE)

问题是 R 始终报告前两个模型不可行：
计算权重...
第一个模型不可行：时间 = 0.81
第二个模型不可行：时间 = 0.25
将使用第三个模型。
为合成控制创建了主权重：时间 = 1.45

即使它最终继续使用第三个模型，但情况不应该如此，因为来自 microsynth 出版物的示例应该是可行的。我在 R 安装中尝试运行的所有模型都出现了这个问题，这让我相信我的设置存在问题。
有人遇到过类似的问题吗？我的 R 配置可能出了问题，还是我应该使用特定的软件包版本？]]></description>
      <guid>https://stats.stackexchange.com/questions/653927/microsynth-feasible-model-example-from-publication-returns-infeasible-models-i</guid>
      <pubDate>Thu, 05 Sep 2024 16:46:25 GMT</pubDate>
    </item>
    <item>
      <title>这是什么设计：重复、嵌套、其他？</title>
      <link>https://stats.stackexchange.com/questions/653923/what-design-is-this-repeated-nested-other</link>
      <description><![CDATA[我得到了一个有点奇怪的数据集，乍一看，它看起来就像重复测量。我希望弄清楚这是否是一种更常见模型类型的特殊类别（例如重复测量、嵌套、交叉）或者术语是什么，以便我可以阅读它以确保我正确地分析它。
在这项研究中，同一单元的观察结果会随时间推移而发生，但治疗并非全部在时间 = 0 时应用，样本单元的治疗随时间推移而应用，而不是在开始时应用。无论样本单元如何，治疗都会同时应用，但要等到特定时间点才会应用。
例如，如果有 3 种治疗方法，A、B 和 C，并在 T1、T2、T3、T4 处重复测量。 A 在 T1 之前应用，B 在 T1 之后但在 T2 之前应用，C 在 T2 之后但在 T3 之前应用，应用的处理为 A、B、C、A+B、A+B+C、B+C 和对照。似乎处理 B、C 和 B+C 在 T2 之前测量时都是有效对照，而 C 是 T2 之前的对照。
这有专门的术语吗？这不是一个明确的重复测量，因为处理随时间而变化，而且它看起来也不像是交叉。我知道这是某种随机效应模型，但我不太确定是否需要嵌套任何东西，或者如果应该嵌套任何东西，应该嵌套什么。我是不是想太多了？]]></description>
      <guid>https://stats.stackexchange.com/questions/653923/what-design-is-this-repeated-nested-other</guid>
      <pubDate>Thu, 05 Sep 2024 15:38:04 GMT</pubDate>
    </item>
    <item>
      <title>具有极不平衡随机变量的混合方差分析</title>
      <link>https://stats.stackexchange.com/questions/653922/mixed-anova-with-extremely-unbalanced-random-variable</link>
      <description><![CDATA[我有一个因变量 y（浓度）、一个独立分类变量（菌株）和一个随机变量（日期）。
当我运行简单的单向方差分析时，我的独立变量菌株不显著（pval=0.3），我的 AIC=158。
当我在模型中添加日期作为随机效应（R 中 lmer 函数中的 +(1|日期)）时，菌株似乎很显著（pval=0.013），随机效应日期也很显著（使用 R 中的 ranova，pval=0.008），但 AIC 更高（160）。
我有两个问题：

我应该考虑 ranova 的 p 值（0.008）并保留模型中的随机效应还是考虑到 AIC 将其删除？
我的随机效应极其不平衡（见下图，颜色代表不同的菌株y 是浓度）。对于某些日期，我只有一个菌株，或者某些菌株只有一个值。对于大多数日期，我只有 5 个菌株中的 3 个。这是个问题吗？


我找不到关于非常不平衡的随机变量是否是个问题的明确答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/653922/mixed-anova-with-extremely-unbalanced-random-variable</guid>
      <pubDate>Thu, 05 Sep 2024 15:24:26 GMT</pubDate>
    </item>
    <item>
      <title>这是维基百科中有关标准差的一个错误吗？</title>
      <link>https://stats.stackexchange.com/questions/653921/is-this-a-mistake-on-wikipedia-on-standard-deviation</link>
      <description><![CDATA[在维基百科页面中，关于标准差的部分，在“估计”部分，它说

与估计总体均值的情况不同，样本均值是一个具有许多理想属性（无偏、有效、最大似然）的简单估计量，而标准差没有一个具有所有这些属性的单一估计量……

然而，我认为样本均值不总是总体均值的最大似然估计量。例如，如果我们知道总体具有对数正态分布，那么它就不起作用。
这是维基百科上的错误吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653921/is-this-a-mistake-on-wikipedia-on-standard-deviation</guid>
      <pubDate>Thu, 05 Sep 2024 15:11:29 GMT</pubDate>
    </item>
    <item>
      <title>如何判断一名玩家在多人游戏中是否表现更佳？</title>
      <link>https://stats.stackexchange.com/questions/653918/how-to-tell-if-one-player-is-significantly-better-at-a-multi-player-game</link>
      <description><![CDATA[我构建了一个扑克模拟，并让 6 个机器人互相玩了很多游戏（随机就座，始终是相同的六个），您如何确定一个玩家是否明显优于其他玩家？
https://www.science.org/doi/10.1126/science.aay2400 使用 T 检验，但我对两件事有点困惑：
需要独立……玩家不是高度依赖于其他玩家的表现吗？所以我需要进行配对 T 检验，对吗（论文中没有说明）？
假设我想比较前两名玩家。这是否只是在配对 T 检验中比较每个玩家的问题？我举了一个例子来说明在 Python 中这可能是什么样子：
import pandas as pd
import numpy as np
from scipy import stats

##### 可重复性的种子
np.random.seed(42)

##### 游戏数量
n_games = 20

##### 创建一个空的 DataFrame
data = {
&#39;game&#39;: range(1, n_games + 1),
&#39;good&#39;: [0] * n_games,
&#39;bad&#39;: [0] * n_games,
&#39;random_1&#39;: [0] * n_games,
&#39;random_2&#39;: [0] * n_games,
&#39;random_3&#39;: [0] * n_games,
&#39;random_4&#39;: [0] * n_games,
}

df = pd.DataFrame(data)

##### 每场比赛随机选择一名获胜者
winners = np.random.choice([&#39;good&#39;, &#39;bad&#39;, &#39;random_1&#39;, &#39;random_2&#39;, &#39;random_3&#39;, &#39;random_4&#39;], size=n_games)

##### 为每场比赛指定获胜者
for i in range(n_games):
df.loc[i, winnings[i]] = 1

##### 在“好”和“坏”之间执行配对 t 检验
t_stat, p_value = stats.ttest_rel(df[&#39;good&#39;], df[&#39;bad&#39;])

##### 显示 DataFrame 和测试结果
print(df)
print(f&quot;t-statistic: {t_stat}, p-value: {p_value}&quot;)

```]]></description>
      <guid>https://stats.stackexchange.com/questions/653918/how-to-tell-if-one-player-is-significantly-better-at-a-multi-player-game</guid>
      <pubDate>Thu, 05 Sep 2024 14:48:26 GMT</pubDate>
    </item>
    <item>
      <title>如何解释统计上不显著的估计并排除较大的影响？</title>
      <link>https://stats.stackexchange.com/questions/653890/how-to-interpret-statistically-non-significant-estimates-and-rule-out-large-effe</link>
      <description><![CDATA[我正在做回归分析，并获得了一个统计上不显著的点估计。从经济角度来看，不显著的结果在我的语境中是有意义的，但我想确保这一发现不是由于缺乏效力。相反，我想确认这种影响确实接近于零，而不仅仅是统计上不显著。
我的目标是做出这样的陈述：“...从置信区间来看，我们可以排除大于 1-1.4 个月的预期寿命增加的影响”，正如 Meghir、Palme 和 Simeonova (2018) 所做的那样，或者“这些影响通常可以限制在零附近的一个狭窄区间内”，正如 Cesarini 等人 (2016) 所提到的那样。
根据我的点估计及其置信区间，我如何自信地解释结果以做出类似的陈述？具体来说，我该如何量化估计的精度以排除较大的影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/653890/how-to-interpret-statistically-non-significant-estimates-and-rule-out-large-effe</guid>
      <pubDate>Thu, 05 Sep 2024 07:29:33 GMT</pubDate>
    </item>
    <item>
      <title>simr 模拟是否需要响应变量/因变量数据？</title>
      <link>https://stats.stackexchange.com/questions/653886/is-response-variable-dependent-variable-data-required-for-simr-simulation</link>
      <description><![CDATA[我正在使用 simr 进行线性混合效应模型的功效分析。我见过的大多数示例都使用来自试点研究的数据进行模拟，但我还没有任何数据。我的问题是：

使用 simr 进行功效分析时，因变量/响应变量的数据是否必要？
我尝试使用没有因变量的数据集运行模拟，似乎有效。这种方法有效吗？
如果因变量/响应变量的数据确实是必要的，我应该生成随机值吗？如果是这样，我应该如何处理？

以下是我当前的代码，以防有帮助。
library(dplyr)
library(tidyr)
library(simr)

# 设置参数
n_subjects &lt;- 100
n_events &lt;- 24

# 检索架构的平衡 &amp;平衡频率的条件
counterbal &lt;- read.csv(&quot;counterbalance.csv&quot;)
conditions &lt;- expand.grid(
distance = c(&quot;close&quot;, &quot;far&quot;),
direction = c(&quot;antecedent&quot;, &quot;consequence&quot;)
)

# 随机将平衡组分配给参与者
get_subj_data &lt;- function(subj_id) {
temp &lt;- data.frame(subject = rep(subj_id, n_events))
temp$event &lt;- 1:n_events
counter &lt;- sample(1:4, 1)
temp$conditions &lt;- counterbal[[paste0(&quot;Counter&quot;, counter)]]
temp$distance &lt;- conditions$distance[temp$conditions]
temp$direction &lt;- conditions$direction[temp$conditions]
return(temp)
}

df &lt;- data.frame()

for (i in 1:n_subjects) {
subj_data &lt;- get_subj_data(i)
df &lt;- rbind(df, subj_data)
}

# H1 - 主效应 T(consq) &gt; T(ante)
# 此处指定效应大小！不是系数！
fixed &lt;- c(0.5, 0.5, 0.5, 0.5)
rand &lt;- list(0.2, 0.1) # 不确定这是什么
res &lt;- 2

model &lt;- makeLmer(latency ~ direction * distance + (1|subject) + (1|event),
fixef=fixed, VarCorr=rand, sigma=res, data=df)
model

# 方向模拟？
sim_direction &lt;- powerSim(model, nsim=100, test = fcompare(~ distance))
sim_direction

这给了我以下输出：
&gt; sim_direction
模型比较的功效，（95% 置信区间）：
100.0% (96.38, 100.0)

测试：似然比
与 ~distance + [re] 的比较

基于 100 次模拟，（0 个警告，0 个错误）
alpha = 0.05，nrow = 2400

已用时间：0 小时 0 分 12 秒
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/653886/is-response-variable-dependent-variable-data-required-for-simr-simulation</guid>
      <pubDate>Thu, 05 Sep 2024 03:38:48 GMT</pubDate>
    </item>
    <item>
      <title>简单的卡方无法解决</title>
      <link>https://stats.stackexchange.com/questions/653861/simple-chi-squared-impossible-to-solve</link>
      <description><![CDATA[向两个独立的人群提出了一个“是/否”问题。
A 组：N=20，是=6，否=14。
B 组：“58% 回答是”。
我认为如果不知道（此处）B 组的总 N，就无法进行卡方检验——但我被告知可以这样做。我迷茫了，所以我去寻找信息的原始来源，发现
B 组：N=12，是=7（58%），否=5。
使用此信息，我使用方法（行 x 列）/总 N 生成了预期频率。 （在本例中为 20+12=32。）
我计算出的卡方值为 2.5。
但是，他们给出的答案是“(c^2 = 7.51; p=0.0058)”。
我绞尽脑汁试图理解这一点。不，我不认为答案是打字错误。
可能是我不知道正在执行哪种卡方。我不知道“c^2”是什么。可能是“B 组 58% 是”需要的 N 与 12 完全不同（即使它确实是之前未公开的 N），但是当我对这个 N 进行逆向工程时，代数很复杂，而且 N 似乎非常大。
我做错了什么吗？这太令人抓狂了。]]></description>
      <guid>https://stats.stackexchange.com/questions/653861/simple-chi-squared-impossible-to-solve</guid>
      <pubDate>Wed, 04 Sep 2024 15:27:19 GMT</pubDate>
    </item>
    <item>
      <title>双样本 Kolmogorov-Smirnov、双样本 Anderson-Darling 和（双样本）Wilcoxon 秩和检验的零假设</title>
      <link>https://stats.stackexchange.com/questions/653837/null-hypotheses-of-two-sample-kolmogorov-smirnov-two-sample-anderson-darling-a</link>
      <description><![CDATA[据我所知，双样本 Kolmogorov-Smirnov (KS) 检验和双样本 Anderson-Darling (AD) 检验的零假设 $H_0$ 是相同的，即两个样本来自同一分布/总体。
我们可以说（双样本）Wilcoxon 秩和 (WRS) 检验的零假设 $H_0$ 与 KS 和 AD 检验的零假设相同，只是“附加条件”是两个样本的中位数应该相同吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653837/null-hypotheses-of-two-sample-kolmogorov-smirnov-two-sample-anderson-darling-a</guid>
      <pubDate>Wed, 04 Sep 2024 09:23:39 GMT</pubDate>
    </item>
    </channel>
</rss>