<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 11 Dec 2024 09:19:56 GMT</lastBuildDate>
    <item>
      <title>构建统计合理的机器学习模型</title>
      <link>https://stats.stackexchange.com/questions/658563/building-a-statistically-sound-ml-model</link>
      <description><![CDATA[统计子堆栈中的沉默读者。我了解到的一件事是，许多“默认”机器学习实践由于基本的统计错误而受到挑战。这很有启发，但也有点让人不知所措。
我正在寻找一个资源或示例，以说明几乎“理想”的数据科学工作流程 - 特别是用于创建分类模型 - 即使是统计专家也几乎不会发现任何问题。
方法的多样性令人着迷，但也可能令人困惑。就上下文而言，我正在为医疗保健/制药领域开展多类分类项目。但是，凭借我获得的新知识，我现在在每一步都对我的 ML 管道进行二次猜测。
我非常感谢任何建议或指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/658563/building-a-statistically-sound-ml-model</guid>
      <pubDate>Wed, 11 Dec 2024 09:06:24 GMT</pubDate>
    </item>
    <item>
      <title>如何用不准确的评估器计算置信区间？</title>
      <link>https://stats.stackexchange.com/questions/658562/how-to-compute-a-confidence-interval-with-an-inacurate-evaluator</link>
      <description><![CDATA[我有一个大型语言模型，它根据系统和用户提示生成输出，我想评估此系统提示的准确性。为此，我创建了一个 LLM-as-a-judge 作为评估者。
通过抽样并将评估者的评估与我的评估进行比较，我可以说我的评估者的准确率为 79%。
在评估我的评估者之后，我希望它评估包含 5421 个项目的整个数据集。我的评估者评估成功率为 87.12%。
我对这个结果有多大信心？是否有可能计算出它的置信区间？如何计算？
注意：我是统计学新手，如果这个问题之前已经回答过，请原谅。我发现很难理解一些现有的问题和答案。请保持你的答案简单。]]></description>
      <guid>https://stats.stackexchange.com/questions/658562/how-to-compute-a-confidence-interval-with-an-inacurate-evaluator</guid>
      <pubDate>Wed, 11 Dec 2024 08:23:24 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用多元线性回归来隔离每个独立变量的影响吗？</title>
      <link>https://stats.stackexchange.com/questions/658560/can-i-isolate-the-effect-of-each-independent-variable-by-using-multiple-linear-r</link>
      <description><![CDATA[我用python对因变量Y和自变量（预测变量）X1和X2进行了多元线性回归。
它们都是时间序列数据，我用MLR的结果重建了Y时间序列。
重建的Y = b1 * X1 + b2 * X2 +残差
那么，我可以通过排除另一个变量来隔离每个独立变量的影响吗？例如，Y&#39; = b1 * X1。（系数值来自使用X1和X2的MLR。）
这合理吗？我想逐一查看X1或X2的影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/658560/can-i-isolate-the-effect-of-each-independent-variable-by-using-multiple-linear-r</guid>
      <pubDate>Wed, 11 Dec 2024 07:36:29 GMT</pubDate>
    </item>
    <item>
      <title>GAM 回归：相互作用与主效应？</title>
      <link>https://stats.stackexchange.com/questions/658558/gam-regression-interactions-vs-main-effects</link>
      <description><![CDATA[我有一个 GAM 回归模型（响应介于 0 和 1 之间）：
$$ g(\mathbb{E}[Y_i]) = \beta_0 + f_1(t_i, x1_i) + f_2(t_i, x2_i) $$

$g(\cdot)$ 是 logit 链接函数 $g(p) = \log(\frac{p}{1-p})$
$Y_i$ 是 Beta 分布：$Y_i \sim \text{Beta}(\alpha, \beta) $
$\beta_0$ 是截距
$f_1$ 和 $f_2$ 是以下相互作用的平滑函数：($t$ 和 $x_1$)
和 ($t$ 和 $x_2$)

以下是该模型的 R 代码：
library(mgcv)
gam_model &lt;- gam(
y_scaled ~ te(t, x1) + te(t, x2),
data = sim_data,
family = betar(link = &quot;logit&quot;)，
方法 = &quot;REML&quot;
)

我的主要兴趣是研究$X_1$对$Y$的影响以及$X_2$对$Y$在不同时间段的影响。
从这个模型来看，在我看来，这个模型中只有交互效应。
根据这个讨论，在我看来这可能是一个问题，似乎不建议使用包含交互但不包含主效应的回归模型：
在模型中包含交互但不包含主效应模型。
但当我尝试阅读有关 te 函数的更多信息时，例如 https://r.qcbs.ca/workshop08/book-en/changing-the-basis-function.html ，它指出：

当变量不在同一尺度上，并且交互作用包括主效应时，函数 te() 很有用。函数 ti() 最适合
对不包含主效应的交互曲面进行建模。

这让我感到疑惑：

在 GAM 回归中，如果包含交互，是否也必须包含主效应？
R 中的 mgcv::te() 函数是否默认在模型中包含交互和主效应？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658558/gam-regression-interactions-vs-main-effects</guid>
      <pubDate>Wed, 11 Dec 2024 04:12:36 GMT</pubDate>
    </item>
    <item>
      <title>glmnet多任务回归优化问题中的下标“F”定义什么？</title>
      <link>https://stats.stackexchange.com/questions/658556/what-does-the-subscript-f-in-the-glmnet-multi-task-regression-optimization-pro</link>
      <description><![CDATA[我计划使用 ElasticNet 多目标回归的 glmnet 实现。我正在检查文档，以便在我正在撰写的手稿中准确描述该技术。
ElasticNet 模型的优化问题定义为：
$
\min_{(\beta_0, \beta) \in \mathbb{R}^{(p+1) \times K}} \frac{1}{2N} \sum_{i=1}^N \|y_i - \beta_0 - \beta^T x_i\|_F^2 + \lambda \left[ (1 - \alpha) \frac{\|\beta\|_F^2}{2} + \alpha \sum_{j=1}^p \|\beta_j\|_2 \right]
$
这是glmnet 文章，我在该文章中获得了该定义。
下标“F”表示什么？它出现在 L2 正则化项和 MSE 项的定义中。]]></description>
      <guid>https://stats.stackexchange.com/questions/658556/what-does-the-subscript-f-in-the-glmnet-multi-task-regression-optimization-pro</guid>
      <pubDate>Wed, 11 Dec 2024 02:29:06 GMT</pubDate>
    </item>
    <item>
      <title>处理具有大量缺失值的特征</title>
      <link>https://stats.stackexchange.com/questions/658555/handling-a-very-informative-feature-with-significant-missing-values</link>
      <description><![CDATA[我有一个机器学习模型，其目标是在回归背景下进行预测。
对于我感兴趣的指标，有一个特征非常有用，但有显著的缺失值。仅使用此特征的简单变换来计算指标会产生非常好的结果，因此将其合并到模型中会产生很好的结果。
但是，此功能仅适用于上个月的最近观察结果，数据集可以追溯到几年前。此功能有接近 98% 的缺失值，但不是随机缺失的 - 它只是在上个月之前没有收集到。
关于如何处理此设置，有什么想法？
我正在考虑是仅使用一个月的数据对该特征进行训练，还是排除该特征并使用完整（大得多）的数据集。但这感觉像是两个极端，应该有更好的方法来整合这两种信息来源。
编辑：为了简化设置，我们假设缺失的特征是$Z = Y + \epsilon$，所以我们可以将其视为结果的嘈杂版本。在模型中包含$Z$当然对于预测$Y$非常有用，但我们只观察到$Z$约占数据集的2％。
半监督学习的文献允许缺少标签，并提出了整合这些数据以提高下游监督学习任务性能的方法。有没有办法在缺少关键特征的情况下使用类似的逻辑？]]></description>
      <guid>https://stats.stackexchange.com/questions/658555/handling-a-very-informative-feature-with-significant-missing-values</guid>
      <pubDate>Wed, 11 Dec 2024 02:22:20 GMT</pubDate>
    </item>
    <item>
      <title>使用相机陷阱记录动物活动对火灾的反应——缺乏空间独立性的问题以及如何分析</title>
      <link>https://stats.stackexchange.com/questions/658550/fauna-activity-responses-to-fire-with-camera-traps-issues-with-lacking-spatial</link>
      <description><![CDATA[我正在尝试为我的博士论文找出最佳的数据分析方法，但遇到了一些困难。
我在生态学领域工作，试图了解火灾前后动物群的反应。我正在使用 BACI 方法，并一直使用相机陷阱来捕捉动物的检测/活动。我遇到的问题是，我正在处理的火灾现场非常小，所以我不得不制作一个高密度相机陷阱网格（即每个地点有 6 个相机，4 个监测点，相机间隔约 20 米，非常近）。到目前为止，我已经考虑了 60 分钟内出现在同一个相机上的动物（相机陷阱的标准做法，以考虑可能在 60 分钟内多次被相机捕捉到的个体），但我正在努力解决每个地点相机之间的空间自相关性 - 即动物可能在彼此相似的时间段内在不同相机之间移动的现实。我读到过，我可以将每个站点视为一个副本，而不是每个站点内的每个摄像机，这样即使有动物在摄像机之间移动，在 60 分钟内对它们进行多台摄像机计数也无关紧要。这听起来合理吗？
有人有什么想法可以通过我的分析来解决这个问题吗？为了便于理解，我计划使用 GLMM（同样，许多其他人也使用过），并且认为也许我可以使用摄像机编号作为随机效应？想看看是否有其他人有什么我可以探索的想法。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658550/fauna-activity-responses-to-fire-with-camera-traps-issues-with-lacking-spatial</guid>
      <pubDate>Tue, 10 Dec 2024 23:13:39 GMT</pubDate>
    </item>
    <item>
      <title>三向重复方差分析中协变量与 IV 之间的相互作用</title>
      <link>https://stats.stackexchange.com/questions/658549/interaction-between-covariate-and-iv-in-three-way-repeated-ancova</link>
      <description><![CDATA[我进行了三向重复 ANCOVA，设计为 432。没有主效应。但是，我发现我的协变量和其中一个 IV 之间存在交互作用。我如何检查哪些 IV 水平受到我的协变量的影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/658549/interaction-between-covariate-and-iv-in-three-way-repeated-ancova</guid>
      <pubDate>Tue, 10 Dec 2024 22:29:53 GMT</pubDate>
    </item>
    <item>
      <title>确定时间序列关系中有多少是由周期性与日期关系驱动的？</title>
      <link>https://stats.stackexchange.com/questions/658548/determining-how-much-timeseries-relationships-are-driven-by-periodicity-versus-d</link>
      <description><![CDATA[假设三个月度数据的时间序列均于 2024 年 11 月 30 日结束（A 开始于 2023 年 12 月 31 日，B 开始于 2024 年 3 月 31 日，C 开始于 2024 年 9 月 30 日），可以将时间序列表示为 1) 根据周期对齐（将 A 的周期 0 2023 年 12 月 31 日与 B 的周期 0 2024 年 3 月 31 日对齐）或 2) 根据日期对齐（将 A 的周期 3 2024 年 3 月 31 日与 B 的周期 0 2024 年 3 月 31 日对齐）。是否有公认的统计技术可以根据周期性而不是日期来衡量时间序列相关性的“驱动因素”？]]></description>
      <guid>https://stats.stackexchange.com/questions/658548/determining-how-much-timeseries-relationships-are-driven-by-periodicity-versus-d</guid>
      <pubDate>Tue, 10 Dec 2024 21:12:24 GMT</pubDate>
    </item>
    <item>
      <title>布拉德利的自由主义标准</title>
      <link>https://stats.stackexchange.com/questions/658538/bradleys-liberal-criterion</link>
      <description><![CDATA[我正在阅读一篇文章，其中作者利用 Bradley 的自由标准来估计事后检验中 F 统计量的稳健性。
这里的问题是他们说了以下内容：
“根据 Bradley 的自由标准，当 I 类错误接近 5% 时，估计者检测组间统计差异的能力更好（参见 Pedrosa 等人，2015 年的类似方法），根据该标准，高于 5.25 的 I 类错误率被认为是保守的，低于 4.75 的 I 类错误率被认为是自由的（Bradley，1978 年）。&quot;
但是当我阅读 Bradley 的论文时，他提出的自由标准指出 p 介于 0.5 * alpha 和 1.5 * alpha 之间（alpha 为 0.05 时为 0.025 和 0.075），这是一个更宽的范围。此外，第一篇论文的作者说“当 I 类错误率高于 5.25 时被认为是保守的，低于 4.75 时被认为是自由的”，但对我来说恰恰相反（如果我拒绝 H0，而它是正确的，那么我就是自由的，如果我拒绝的程度低于我应该的，那么我就是保守的）。
我不知道是我遗漏了什么，还是作者犯了错误。但我需要帮助来理解这一点。
该论文的 doi 是 https://doi.org/10.5964/meth.11721
Bradley 论文：https://doi.org/10.1111/j.2044-8317.1978.tb00581.x]]></description>
      <guid>https://stats.stackexchange.com/questions/658538/bradleys-liberal-criterion</guid>
      <pubDate>Tue, 10 Dec 2024 17:21:08 GMT</pubDate>
    </item>
    <item>
      <title>逻辑链接的边际效应是否也在 0-1 之间？</title>
      <link>https://stats.stackexchange.com/questions/658530/will-marginal-effects-for-a-logit-link-also-be-between-0-1</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658530/will-marginal-effects-for-a-logit-link-also-be-between-0-1</guid>
      <pubDate>Tue, 10 Dec 2024 16:00:11 GMT</pubDate>
    </item>
    <item>
      <title>p值如何排列</title>
      <link>https://stats.stackexchange.com/questions/658523/how-to-permutation-of-pvalue</link>
      <description><![CDATA[最近，我的同事在处理一个数据集 df_a 时遇到了一个问题，该数据集包含基因数据。每一行代表一个 基因（通常有数千个，但为了简单起见，我们假设有 1,000 个），列代表不同的样本，这些样本可以分为两组，A 和 B（每组 50 个样本）。
我们使用 t.test 计算每行的 p 值并进行校正。假设我们使用 p.adjust &lt; 0.05 并且得到 30 个阳性结果。
这带来了一个问题：我们如何确保这 30 个结果不是由随机事件产生的？（也许这个问题是一个问题？）
我们设计了一个使用置换检验的流程来解决这个问题。步骤如下：
(1) 对于 df_a，我们随机打乱其列标签，重新计算每行的 p 值和 p.adjust，并计算 p.adjust &lt; 0.05 的行数，记为 Ki。
(2) 重复步骤 1 1,000 次，得到 K1,K2,K3,...,K1000。
(3) 计算大于 30 的 Ki 的数量，记为 n。计算 n/1000。如果该值小于0.05，我们认为这30个结果不是由随机事件产生的。
作为一名程序员，我意识到数学上似乎存在问题，但我无法向同事提供严格的证明来纠正它。希望得到您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/658523/how-to-permutation-of-pvalue</guid>
      <pubDate>Tue, 10 Dec 2024 14:31:46 GMT</pubDate>
    </item>
    <item>
      <title>如何理解一致中心极限定理</title>
      <link>https://stats.stackexchange.com/questions/658487/how-to-understand-the-uniform-central-limit-theorem</link>
      <description><![CDATA[在 Nickl 的一篇 论文 中，我发现了一个具有中心极限定理形式的定理（定理 4）
$$\sqrt{n}(P_n-P)\rightarrow G$$
在 $l^\infty(F)$ 中，其中 $P$ 是 $\mathbb{R}$ 上的一条定律，$F$ 是一类函数，$G$ 是高斯过程由 $f\in F$ 索引。但我熟悉的中心极限定理的形式为：
$$\sqrt{n}(f_n-f)\rightarrow G$$
其中 $G$ 由 $x\in\mathbb{R}$ 索引。
我正在寻求帮助以理解第一个版本，也想知道是否可以将其转换为第二个版本？在第二个版本中要求 $f\in F$ 是否正确？非常感谢任何提示！]]></description>
      <guid>https://stats.stackexchange.com/questions/658487/how-to-understand-the-uniform-central-limit-theorem</guid>
      <pubDate>Mon, 09 Dec 2024 13:32:48 GMT</pubDate>
    </item>
    <item>
      <title>如何从 softmax 输出计算没有基本事实的模型的置信度和不确定性？</title>
      <link>https://stats.stackexchange.com/questions/658468/how-to-compute-confidence-and-uncertainity-of-model-without-ground-truth-from-so</link>
      <description><![CDATA[假设我有 3 个类 A、B、C。
执行：
y_pred = model.predict(X) # 假设 X 只有两个样本

返回长度为 2 的向量，即形状 (2,3)，仍为概率格式（无 argmax）。
y_pred -&gt; [
{A:0.2, B:0.3, C:0.5}, 
{A:0.7, B:0.2, C:0.1}
]

我将定义模型，而不是置信度，即模型预测的类返回置信度值更接近 1/N，其中 N 是类的数量（因为它既不是真也不是假，它不是断言假即零，也不是断言真即一）。但也许，还有另一个比我的更好的定义。我仍然希望它返回不确定性和置信度的标量值。
如果我的定义是最好的，那么我想使用我的定义将模型预测的总体置信度摘要转换为标量值。
那么，有什么操作或聚合技术可以获取预测的置信度和不确定性，其幅度范围为$[0,1]$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658468/how-to-compute-confidence-and-uncertainity-of-model-without-ground-truth-from-so</guid>
      <pubDate>Mon, 09 Dec 2024 02:06:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么在用偏移量 = log(population) 计数的拟泊松 GLM 拟合之前对数据进行分组时会得到不同的标准误差？</title>
      <link>https://stats.stackexchange.com/questions/658361/why-do-i-get-different-standard-errors-when-i-group-the-data-before-fitting-a-qu</link>
      <description><![CDATA[在拟合拟泊松之前对数据进行分组在理论上是否正确，还是我应该不进行分组？
评论以及 R 代码示例发布如下。
我注意到，在拟合肿瘤计数的拟泊松 GLM 之前对数据进行分组时，我得到了不同的标准误差，偏移量 = log(Population)。如果我使用泊松系列而不是拟泊松系列，就不会发生这种情况，所以我很惊讶。
以下是 R 代码和示例数据，说明了我的问题：
## 创建分组和未分组数据集，其中按 Psych.Profile 和 Cig 分组时，肿瘤和人口的总和相同
## 分组数据
data_grouped &lt;- data.frame(Tumor = c(45,77,95,92,103,12,29,31,43,56,30,36,62,57,71)
,Pop = c(24795,32125,34706,23440,14133,11946,22781,14566,15654,10097,50711,35332,41707,26319,22978)
,Psych.Profile = factor(c(&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;), levels = c(&quot;C&quot;, &quot;B&quot;, &quot;A&quot;))
,Cig = c(0,0.5,1,1.5,2,0,0.5,1,1.5,2,0,0.5,1,1.5,2))

## 未分组数据。这个分组数据的第一行被分成 45 行，每行 1 个肿瘤，人口 = 24795/45 = 551
data_ungrouped &lt;- data.frame(Tumor = c(rep(1,45),77,95,92,103,12,29,31,43,56,30,36,62,57,71)
,Pop = c(rep(551,45),32125,34706,23440,14133,11946,22781,14566,15654,10097,50711,35332,41707,26319,22978)
,Psych.Profile = factor(c(rep(&#39;A&#39;,45),&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;), levels = c(&quot;C&quot;, &quot;B&quot;, &quot;A&quot;))
,Cig = c(rep(0,45),0.5,1,1.5,2,0,0.5,1,1.5,2,0,0.5,1,1.5,2))

## 将拟泊松模型拟合到每个数据集
model_grouped &lt;- glm(Tumor ~ Cig + Psych.Profile, family = quasipoisson((link = &quot;log&quot;)), offset = log(Pop), data = data_grouped)
model_ungrouped &lt;- glm(Tumor ~ Cig + Psych.Profile, family = quasipoisson((link = &quot;log&quot;)), offset = log(Pop), data = data_ungrouped)

&gt; coef(summary(model_grouped))
估计标准差。误差 t 值 Pr(&gt;|t|)
(截距) -7.3071846 0.09242152 -79.06367 1.649769e-16
Cig 0.7661623 0.05563362 13.77157 2.791780e-08
Psych.ProfileB 0.3887326 0.10225686 3.80153 2.935492e-03
Psych.ProfileA 0.7645370 0.08235288 9.28367 1.545673e-06

&gt; coef(summary(model_ungrouped))
估计标准差误差 t 值 Pr(&gt;|t|)
(截距) -7.3071846 0.04133216 -176.79175 1.814343e-77
Cig 0.7661623 0.02488011 30.79417 2.303794e-36
Psych.ProfileB 0.3887326 0.04573066 8.50048 1.343316e-11
Psych.ProfileA 0.7645370 0.03682933 20.75892 1.081513e-27

## 系数的标准误差下降。例如Cig 从 0.05563362 降至 0.02488011


对数据进行分组的一个动机是，我可以显著减少行数并更轻松地处理更大的数据集。]]></description>
      <guid>https://stats.stackexchange.com/questions/658361/why-do-i-get-different-standard-errors-when-i-group-the-data-before-fitting-a-qu</guid>
      <pubDate>Fri, 06 Dec 2024 04:01:11 GMT</pubDate>
    </item>
    </channel>
</rss>