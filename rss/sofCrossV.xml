<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 16 Jan 2025 15:16:57 GMT</lastBuildDate>
    <item>
      <title>我不明白为什么要使用无偏估计量</title>
      <link>https://stats.stackexchange.com/questions/660108/i-dont-understand-why-unbiased-estimators-would-be-used</link>
      <description><![CDATA[我对无偏估计量的定义是：“如果用于估计参数的统计数据的抽样分布的平均值等于被估计参数的值，则该统计数据是无偏估计量。”
我知道如何确定统计数据是否是无偏估计量，因为我能够基于此解决应用题，但我不明白我们为什么要使用无偏估计量。我的笔记说，您需要使用无偏估计量，以便您的估计更准确。这对我来说很有意义，但为了确定统计数据是否是无偏估计量，您需要知道参数的值，以便将其与抽样分布的平均值进行比较，看看它们是否相等。如果使用无偏估计量来估计参数的值，如果我们已经知道参数的值，使用它有什么意义呢？
我一直在为此绞尽脑汁，但无济于事，如能得到任何帮助我将不胜感激，谢谢。
（我不擅长措辞，如果我听起来很重复或没有意义，请原谅）]]></description>
      <guid>https://stats.stackexchange.com/questions/660108/i-dont-understand-why-unbiased-estimators-would-be-used</guid>
      <pubDate>Thu, 16 Jan 2025 15:06:38 GMT</pubDate>
    </item>
    <item>
      <title>概率分布的均匀性</title>
      <link>https://stats.stackexchange.com/questions/660107/uniformicity-of-probability-distribution</link>
      <description><![CDATA[我有一个关于从一组均匀分布的样本中移除样本的问题。
设$E = \{ X_{ij} \}, 1 \leq i &lt; j \leq n$为一组随机变量，其中每个$X_{ij}$在$\sim [0,1]$中是独立同分布的。显然，$|E| = \binom{n}{2}$。这些是完整加权图的权重，其中 $X_{ij}$ 确实是“节点 $i$ 和节点 $j$ 之间的权重”。
现在，我递归重复以下步骤（例如 $n/2$ 次）：

选择一个 $i \in \{1,n\}$ 来验证以下内容：
$\exists j \neq k \neq i$ s.t.
\begin{align}
X_{ij} = \arg\min\{ X_{uv} : u=j \text{ 或 }v=j \} \text{ 和 } X_{ik} = \arg\max\{ X_{uv} : u=k \text{ 或 }v=k \}
\end{align
存在另外两个顶点 $j$ 和 $k$ s.t. $i$ 和 $j$ 之间的入射边是 $j$ 所有入射边中的最小值，而 $i$ 和 $k$ 之间的入射边是 $k$ 所有入射边中的最大值，反之亦然。
如果是这种情况，则表示 $R = \{ X_{uv} \text{ s.t. } i=u \text{ 或 } j=v \}$。
设置 $E = E \setminus R$，$n = n-1$。

如果根据上述规则从 $E$ 中选取子集并将其删除，它是否仍是均匀分布的？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660107/uniformicity-of-probability-distribution</guid>
      <pubDate>Thu, 16 Jan 2025 14:58:53 GMT</pubDate>
    </item>
    <item>
      <title>如果单比例荟萃分析中受异常值影响的数据经过变换后仍然不服从正态分布，该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/660104/what-should-be-done-if-outlier-influenced-data-in-a-single-proportion-meta-analy</link>
      <description><![CDATA[如果单比例荟萃分析中的数据受到异常值的影响，经过变换后仍然不服从正态分布，该怎么办？
我正在进行单比例荟萃分析，在计算合并比例之前，我需要对数据进行变换以达到正态性。我在 R 4.3.3 中尝试了四种不同的变换，即 log、logit、反正弦和 Freeman-Tukey 双反正弦，但数据仍然不服从正态分布。后来我意识到这是由于异常值的影响。我现在考虑的方法是去除这个异常值。这种方法可以接受吗？如果不可以，我可以使用哪些替代方法来处理这个异常值以继续进行荟萃分析？
异常值的比例为 0.8%。如果将其去除，荟萃分析中的合并比例将约为 60%。出版偏见检验显示 p 值 &gt; 0.05，漏斗图呈现对称性。]]></description>
      <guid>https://stats.stackexchange.com/questions/660104/what-should-be-done-if-outlier-influenced-data-in-a-single-proportion-meta-analy</guid>
      <pubDate>Thu, 16 Jan 2025 14:42:27 GMT</pubDate>
    </item>
    <item>
      <title>关于Delta方法的问题</title>
      <link>https://stats.stackexchange.com/questions/660099/question-about-delta-method</link>
      <description><![CDATA[令 $\hat{f}_n$ 为核密度估计量，$f$ 为真实密度，$h$ 为带宽。我在一篇论文中发现，在温和条件下，$\sqrt{nh}(\hat{f}_n-f)$ 在某些函数空间中会收敛到 0。因此，我们可以为 $z\in\mathbb{R}$ 定义一个函数 $$\Phi_z(f)=f(z)$$，然后使用函数 delta 方法。由于 $\Phi_z$ 在 $g$ 方向上的 hadamard 导数就是 $g(z)$，因此使用 delta 方法，我们将得到 $$\sqrt{nh}(\hat{f}_n(z)-f(z))\rightarrow 0$$。但这是不可能的，因为我们知道核密度估计量具有逐点渐近正态性。如果有人能指出我的错误，我将非常感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660099/question-about-delta-method</guid>
      <pubDate>Thu, 16 Jan 2025 13:24:50 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中计算多重插补后合并结果的部分 Eta 平方</title>
      <link>https://stats.stackexchange.com/questions/660097/calculating-partial-eta-squared-for-pooled-results-after-multiple-imputation-in</link>
      <description><![CDATA[我已经为这个问题苦苦挣扎了一段时间，所以任何帮助都非常感谢！
我正在尝试使用 R 中的 mice 包，使用经过多次插补后的汇总数据计算 ANCOVA 模型的效应大小（部分 eta 平方或 n^2）。ANCOVA 应用于认知测试的变化分数（基线和 12 周随访之间的差异）。这是模型：
results_test &lt;- with(imputed_data, lm((test_12 - test_base) ~ test_base + group + yoe))
pooled_results_test &lt;- pool(results_test)

从汇总结果中，我可以轻松提取组效应的 p 值、调整后的平均差异和置信区间。但是，我想计算一个效应大小的度量，例如 n^2。
我的困境
n^2 的计算方法如下：
eta_squared &lt;- ss_effect / (ss_effect + ss_residual)

此处 SS 指的是平方和。
现在，如果我针对每个插补数据集分别计算并取插补平均值，我怀疑这可能存在缺陷，因为它是一个比率，而不是线性统计数据。对比率求平均可能会扭曲真实的汇总效应大小。因此，我没有直接对 n^2 求平均值，而是尝试将所有插补的平方和相加，然后计算合并的 n^2，如下所示：
# 首先对插补的平方和相加，最后在此基础上计算部分 eta 平方，从而计算合并的部分 eta 平方：

total_ss_effect &lt;- sum(sapply(1:imputed_data$m, function(i) {
anova(lm((test_12 - test_base) ~ test_base + group + yoe, 
data = complete(imputed_data, i)))[&quot;group&quot;, &quot;Sum Sq&quot;]
}))
total_ss_residual &lt;- sum(sapply(1:imputed_data$m, function(i) {
anova(lm((test_12 - test_base) ~ test_base + group + yoe, 
data = complete(imputed_data, i)))[&quot;Residuals&quot;, &quot;Sum Sq&quot;]
}))
eta_squared_pooled &lt;- total_ss_effect / (total_ss_effect + total_ss_residual)
cat(&quot;\nPooled Partial Eta Squared:&quot;, round(eta_squared_pooled, 3), &quot;\n&quot;)

此方法将跨插补的组效应和残差的 SS 相加，并从总数中计算出 n^2。它似乎更合适，因为它考虑了跨插补的可变性。
我的问题：

这是一种合理的方法吗？将插补的平方和相加，然后计算部分 eta 平方，这在统计上有意义吗？

在 R 中是否有计算合并部分 eta 平方的标准方法或包？

在合并分析中不报告效应大小是否很常见？我注意到许多文章都没有包括它们，这似乎令人惊讶。


再次感谢你们提供的任何意见。我非常感激！
祝一切顺利！]]></description>
      <guid>https://stats.stackexchange.com/questions/660097/calculating-partial-eta-squared-for-pooled-results-after-multiple-imputation-in</guid>
      <pubDate>Thu, 16 Jan 2025 12:31:47 GMT</pubDate>
    </item>
    <item>
      <title>如何测试具有少量箱体的直方图是否符合正态分布？</title>
      <link>https://stats.stackexchange.com/questions/660096/how-do-i-test-if-a-histogram-with-few-bins-is-obtained-from-a-normal-distributio</link>
      <description><![CDATA[假设我有一个直方图，显示已成功完成 $0, 1, 2, ..., n$ 门课程的学生人数。学生人数较多，但课程数量较少（例如 6 门）。我的零假设 $H_{0}$ 是学生的“能力”是一个具有正态分布的实数（均值和方差未知），学生完成的课程数量为 $\lfloor \text{aptitude} \rfloor$。如何检验备择假设 $H_{1}$“能力分布不正常”？我知道 Jarque-Bera、Lilliefors 或 Anderson-Darling 等正态性检验，但据我所知，它们假设离散化细化程度要高得多，即有更多的箱体，并且它们不包含任何限制假设（即，观测量的最大值和最小值是有限的，尽管底层随机变量不是）。我也在 Cross Validated 上看到了这个问题，其中一个答案建议使用卡方拟合优度检验，但据我所知，您需要指定正态分布的均值和方差才能使用卡方拟合优度检验，而我两者都没有。
附言。由于我发现在教育背景下提出这个问题会引发太多与统计本身无关的问题，因此假设我们讨论的是游戏中给予玩家的随机点数。玩家最多可以购买 $n$ 件物品，每件物品花费 $X$ 点，并且总是会购买尽可能多的物品。通过查看玩家购买的物品数量的分布，我们试图确定给予玩家的点数是否符合正态分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/660096/how-do-i-test-if-a-histogram-with-few-bins-is-obtained-from-a-normal-distributio</guid>
      <pubDate>Thu, 16 Jan 2025 12:31:45 GMT</pubDate>
    </item>
    <item>
      <title>是否可以将元分析 SMD（例如，Cohen's d）转换为两种条件之间的百分比变化？</title>
      <link>https://stats.stackexchange.com/questions/660092/is-it-possible-to-convert-the-meta-analytic-smd-e-g-cohens-d-to-the-percent</link>
      <description><![CDATA[是否可以将随机效应荟萃分析的平均汇总效应（以 Cohen&#39;s d 的形式）转换为两种条件之间的百分比变化。
例如：X 的 Cohen&#39;s d 对应于 Y 的百分比变化。
我知道 CLES 以及如何将 Cohen&#39;s d 转换为原始平均差异，然后再转换为百分比变化，但我想知道当我只有荟萃分析的结果时是否可行。]]></description>
      <guid>https://stats.stackexchange.com/questions/660092/is-it-possible-to-convert-the-meta-analytic-smd-e-g-cohens-d-to-the-percent</guid>
      <pubDate>Thu, 16 Jan 2025 11:08:42 GMT</pubDate>
    </item>
    <item>
      <title>统计功效分析：p 值较小的 power.t.test 结果不一致</title>
      <link>https://stats.stackexchange.com/questions/660091/statistical-power-analysis-power-t-test-inconsistent-results-for-small-p-values</link>
      <description><![CDATA[我不确定这是否是提出这个问题的正确 StackExchange，因为它也是程序化的。我愿意从 power.t.test 执行显着性水平的估计，使用非常小的 p 值（由 Bonferroni 校正为多重测试）。我面临这个问题。以下 R 代码几乎始终返回我提供的相同 P 值：
reference_sample_size &lt;- 250;
reference_pval_thres &lt;- 0.01;
ref.d &lt;- 0.8;
factor &lt;- 1;
ref.pwr &lt;- power.t.test(n=reference_sample_size, delta=ref.d, power=NULL, sig.level=reference_pval_thres/factor, type=&quot;two.sample&quot;, alternative=&quot;two.sided&quot;)$power;
power.t.test(delta=ref.d,n=reference_sample_size,sig.level=NULL, type=&quot;two.sample&quot;, alternative=&quot;two.sided&quot;, power=ref.pwr)$sig.level * factor

例如，我给它的 p 值为 0.01，我得到的 p 值为 0.009974294，考虑到算术精度，这是预期结果。但是，如果我将因子设置为 1000，则结果将完全错误，返回 p 值为 0.1220204。
有人可以解释原因并提供可能的解决方案吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660091/statistical-power-analysis-power-t-test-inconsistent-results-for-small-p-values</guid>
      <pubDate>Thu, 16 Jan 2025 10:49:39 GMT</pubDate>
    </item>
    <item>
      <title>如何在倾向匹配数据中对组 x 时间交互进行建模</title>
      <link>https://stats.stackexchange.com/questions/660088/how-to-model-group-x-time-interaction-in-propensity-matched-data</link>
      <description><![CDATA[我正在帮助某人进行分析，他们已经对一系列具有纵向结果（每年测量 10 年）的基线变量进行了倾向得分匹配。他们使用了 matchit 与最近邻居和 2:1 匹配率。我认为他们感兴趣的估计量是 group * time 交互效应，他们没有考虑到这一点。
然而，我对倾向得分没有做太多研究，我想知道如何对此进行建模。我们是否只获取匹配的数据并运行具有交互作用的标准混合模型 - 即类似于（在 R 中）：
lmer(y ~ group * time + (1|id), data = dat)

或者还有更多内容？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660088/how-to-model-group-x-time-interaction-in-propensity-matched-data</guid>
      <pubDate>Thu, 16 Jan 2025 09:28:31 GMT</pubDate>
    </item>
    <item>
      <title>F1-score、IOU 和 Dice Score 的实现</title>
      <link>https://stats.stackexchange.com/questions/660087/implementation-of-f1-score-iou-and-dice-score</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660087/implementation-of-f1-score-iou-and-dice-score</guid>
      <pubDate>Thu, 16 Jan 2025 09:19:55 GMT</pubDate>
    </item>
    <item>
      <title>statsmodels ARIMA 结果中的 p 值和临界值存在冲突</title>
      <link>https://stats.stackexchange.com/questions/660086/conflicting-p-value-and-critical-values-in-statsmodels-arima-result</link>
      <description><![CDATA[
如果我理解正确，如果 Z 落在临界值区域之外，则 p 值应该 &lt;0.05。但是，对于我的 ar.L2 特征，z = -0.596，[0.025, 0.075] 区域是 [-0.536, 0.286]。因为 -0.596 &lt; -0.536，所以 z 落在左尾内。但为什么 p 值是 0.552？我读错结果了吗？在 statsmodels 网站上找不到任何文档。]]></description>
      <guid>https://stats.stackexchange.com/questions/660086/conflicting-p-value-and-critical-values-in-statsmodels-arima-result</guid>
      <pubDate>Thu, 16 Jan 2025 09:00:50 GMT</pubDate>
    </item>
    <item>
      <title>回归分析中总体模型和样本模型的形式区别？</title>
      <link>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</link>
      <description><![CDATA[术语“样本回归模型”在回归分析中究竟指什么？假设我们有一个数据集$\{(\mathbf{x}_i,\mathbf{y}_i)\}$，我们假设一个底层回归模型形式为
$$
\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon},
$$
其中$\boldsymbol{\theta}$是真实总体参数（频率学派观点）和$\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\Sigma)$。我们所说的样本回归模型到底是什么意思？
以下是我正在探索的一些可能性：

拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}})$，从某种意义上说，我们已经选择了一个估计值$\hat{\boldsymbol{\theta}}$;
拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}}) + \hat{\boldsymbol{\epsilon}}$，其中我们有一个估计值$\hat{\boldsymbol{\theta}}$ 而且 $\hat{\boldsymbol{\epsilon}} \sim \mathcal{N}(\mathbf{0},\hat{\Sigma})$;
从字面上看，人口模型 $\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon}$，但现在以样本指数的形式写出：$\mathbf{y}_i = f(\mathbf{x}_i;\boldsymbol{\theta}) + \boldsymbol{\epsilon}_i$ 使得 $\boldsymbol{\epsilon}_i$ 是观测值，而不是随机向量。
关系 $\mathbf{y}_i = f(\mathbf{x}_i;\hat{\boldsymbol{\theta}}) + \mathbf{e}_i$，其中 $\mathbf{e}_i = \mathbf{y}_i - \hat{\mathbf{y}}_i$ 是残差。

如能提供严格说明，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</guid>
      <pubDate>Thu, 16 Jan 2025 07:27:25 GMT</pubDate>
    </item>
    <item>
      <title>排除构成数据结构一部分的相关变量，转而采用生物学上更有意义的变量</title>
      <link>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</link>
      <description><![CDATA[我正在处理从卫星图像 (Sentinel) 捕获的植被覆盖率数据集。数据以季度/季节为间隔捕获。使用 GAM，我正在模拟植被覆盖率如何响应环境变量，降雨量是感兴趣的关键预测变量。但是，降雨量与季度/季节具有合理的相关性，相关系数为 r = -0.73。通常，当两个变量的相关性大于 0.7 时，我会将其中一个排除在分析之外。所以，我的问题是，我可以从分析中排除季度/季节吗？
季度/季节是数据集设计/结构的一部分，通常我的理解是应该在模型中考虑数据结构。但是，从生物学角度来看，连续降雨变量是一个更有趣、更有意义的变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</guid>
      <pubDate>Thu, 16 Jan 2025 03:22:55 GMT</pubDate>
    </item>
    <item>
      <title>GLM 与 XGB 对零膨胀计数数据的比较</title>
      <link>https://stats.stackexchange.com/questions/660077/comparison-of-glm-xgb-for-zero-inflated-count-data</link>
      <description><![CDATA[我最近才接触 XGB，目前正在做一个项目，为特定保险环境建模索赔数量，并比较 GLM 和 XGB。
首字母缩略词：

GLM - 广义线性模型；

XGB - 极端梯度提升；

ZIP/ZINB - 零膨胀泊松/零膨胀负二项式。


问题：

由于我正在处理 GLM 和 XGB，因此我想在建模之前假设一个分布，以便我可以根据该分布的偏差比较两个模型。例如：如果索赔计数的数据具有泊松分布，则使用泊松偏差。

但是，由于明显的零通货膨胀（索赔为 0 的观测值占总观测值的 70% 以上，占总风险暴露的 70% 以上），我被迫使用 ZIP、拟泊松 GLM、NB GLM 或 ZINB。泊松分布被证实不合适。

另一方面，对于 XGB，我只能对离散计数响应变量使用 count:poisson，它基于泊松偏差。即使通过定制用于 XGB 的损失函数，我也会遇到另一个问题：拟泊松偏差依赖于色散参数，而 NegBinomial 依赖于第二个参数。除非我从一开始就假设它们是恒定的，否则无法为 XGB 实现这些。这意味着，随着 xgb 模型的发展和树的增加，偏差将基于那些恒定的初始假设参数进行计算。甚至 GLM 也会在模型优化时针对 Quasi-Poisson 和 NegBinomial 更新这些参数。对于 XGB 的 ZI 偏差，我无法将这些偏差与梯度和 hessian 拟合到 XGB 的定制目标中。我甚至不认为可以在 XGB 中对零膨胀模型假设发生的产生过量零的单独过程进行建模。

我几乎没有找到针对此类问题的研究或实例。


问题：
(A) 由于 GLM 和 XGB 建模存在这些差异，哪个是比较这两个模型的最合适的指标？
(B) 或者甚至是最好的方法？或者最实用的？
我的建议：

获取最适合 GLM 的模型，并使用默认 count:poisson 偏差获得 XGB，使用具有常数参数 (r) 的 NegBinomial 偏差获得另一个，并在几个偏差下比较所有偏差：
1.1. Poisson 偏差
1.2. NegBinomial 偏差
1.3. 我不明白即使在模型完成后如何找到用于 XGB 模型评估的 ZIP 或 ZINB 偏差。
1.4. 使用加权基尼规范了解哪些模型可以更好地对不同风险进行分类。

]]></description>
      <guid>https://stats.stackexchange.com/questions/660077/comparison-of-glm-xgb-for-zero-inflated-count-data</guid>
      <pubDate>Thu, 16 Jan 2025 00:45:20 GMT</pubDate>
    </item>
    <item>
      <title>在线性误差传播过程中如何选择正确的公式？</title>
      <link>https://stats.stackexchange.com/questions/660052/how-to-choose-the-correct-formula-during-linear-error-propagation</link>
      <description><![CDATA[我正在使用线性误差传播的标准公式（协方差为零）来估计作为平均实验可观测量函数计算的变量中的不确定性（使用标准差作为不确定性估计），但遇到了障碍。例如，考虑一个变量$k$，它可以计算为
$$k = 1-\frac{G\times I}{P} \tag{1}$$
作为可观测量$G$、$I$和$P$的函数。
但是，上述内容可以改写为
$$k = \frac{P-G\times I}{P} \tag{2}$$
但是，与方程 (1) 相关的传播不确定性似乎与方程 (2) 相关的不确定性不同，因为 $P$ 的值在方程 (2) 中出现了两次，而与方程 (1) 中的常数 (&quot;$1$&quot;) 相关的不确定性为零。
我遗漏了什么？在这种情况下，使用错误传播的正确方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660052/how-to-choose-the-correct-formula-during-linear-error-propagation</guid>
      <pubDate>Wed, 15 Jan 2025 09:42:21 GMT</pubDate>
    </item>
    </channel>
</rss>