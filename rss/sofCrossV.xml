<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 26 Jan 2024 15:13:48 GMT</lastBuildDate>
    <item>
      <title>甜甜圈爱好者的贝叶斯估计</title>
      <link>https://stats.stackexchange.com/questions/637823/bayesian-estimation-of-donut-lovers</link>
      <description><![CDATA[我发布了这个问题贝叶斯概率估计甜甜圈爱好者的百分比，它被关闭了。我想也许我可以简化这个问题（这是我从头到尾研究过的第一个贝叶斯问题）：

假设 2020 年有 100 人：A 组 75 人 ($N_{A,2020}$)，B 组 25 人 ($N_{A,2020}$)数学容器&quot;&gt;$N_{B,2020}$)。
A 组中有 83% 的人喜欢甜甜圈 ($ p_{A,2020}$)，但我们不知道 B 组中有多少人喜欢甜甜圈像甜甜圈 ($p_{B,2020}$)。不过，我们认为 B 组中超过 83% 的人不太可能喜欢甜甜圈。
到 2021 年，将出现 150 人的全新人口（即 2020 年没有人）（我们认为他们可能与 2020 年人口有类似的甜甜圈偏好）。但是，我们不知道 2021 年人口中 A 组的比例是多少，B 组的比例是多少。
问题：我们能否估算出 2021 年可能喜欢甜甜圈的总百分比？
为了让问题更简单，我假设人口比例和甜甜圈偏好之间独立

第 1 部分：先验分布和可能性

A 组甜甜圈爱好者的可能性（二项式）：

$$
P(D_{A,2020} | p_{A,2020}, N_{A,2020}) = \binom{N_{A,2020}}{D_{A,2020}} p_{A,2020}^{ D_{A,2020}} (1-p_{A,2020})^{N_{A,2020}-D_{A,2020}}
$$

A 组 Donut Lovers（测试版）优先级：

$$ P(p_{A,2020}) \sim Beta(\alpha_{A,2020}, \beta_{A,2020}) = \frac{p_{ A,2020}^{\alpha_{A,2020}-1} (1-p_{A,2020})^{\beta_{A,2020}-1}}{B(\alpha_{A,2020}, \beta_{A,2020})}$$

B 组甜甜圈爱好者 (Beta) 的先验：我不知道如何编写此内容，以便先验尊重 0.83 约束（截断/不完整的 Beta 截断的非标准 beta 分布的平均值）。我认为这个 Beta 先验的参数应该以某种方式选择，使得先验变得“更宽”。与 A 组相比，我们对 B 组的甜甜圈偏好信心不足？

$$ P(p_{B,2020}) \sim Beta(\alpha_{B,2020}, \beta_{B,2020}) = \frac{p_{ B,2020}^{\alpha_{B,2020}-1} (1-p_{B,2020})^{\beta_{B,2020}-1}}{B(\alpha_{B,2020}, \beta_{B,2020})}$$

比率计数的可能性（多项式）：

$$
P(N_{A,2020}, N_{B,2020} | x_{A,2020}, x_{B,2020}) \propto x_{A,2020}^{N_{A,2020}} x_{B ,2020}^{N_{B,2020}}
$$

先验比率（狄利克雷）：

$$
P(x_{A,2020}, x_{B,2020}) = \frac{1}{B(3, 1)} N_{A,2020}^{2}
$$
第 2 部分：后验分布
$$
P(p_{A,2020} | D_{A,2020}, N_{A,2020}) \sim Beta(\alpha_{A,2020} + D_{A,2020}, \beta_{A,2020} + N_{A,2020} - D_{A,2020})
$$
$$
P(p_{B,2020} | D_{B,2020}, N_{B,2020}) \sim Beta(\alpha_{B,2020} + D_{B,2020}, \beta_{B,2020} + N_{B,2020} - D_{B,2020})
$$
$$
P(N_{A,2020}, N_{B,2020} | N_{A,2020}, N_{B,2020}) \sim Dirichlet(N_{A,2020} + 2, N_{B,2020})
$$
因此，如果您知道 2021 年的总人数 - 通过后验地图，我们可以估计 A:B 中的预期人口比例……然后估计 A 喜欢甜甜圈的百分比并估计B 中喜欢甜甜圈的百分比。
我在这里感到有点迷失，我认为我以错误的方式解决了这个问题。有人可以指导我如何挽救我的分析吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637823/bayesian-estimation-of-donut-lovers</guid>
      <pubDate>Fri, 26 Jan 2024 14:50:12 GMT</pubDate>
    </item>
    <item>
      <title>求 Y = min(Ui) 1<=k<=N 的 CDF，其中 N 是均值为 1/ε 的几何 R.V，Ui 是均匀分布 (0,1) 的独立同分布 R.V，ε ->0</title>
      <link>https://stats.stackexchange.com/questions/637822/find-the-cdf-of-y-minui-1-k-n-where-n-is-a-geometric-r-v-with-mean-1-%ce%b5-and</link>
      <description><![CDATA[我做了一些计算，发现 0&lt;=y&lt;=1 的分布为 Fy = 1-(1 - ey)^N，其中 N 是几何 R.V 但我不知道如何继续。我们知道 N 独立于所有 Ui。]]></description>
      <guid>https://stats.stackexchange.com/questions/637822/find-the-cdf-of-y-minui-1-k-n-where-n-is-a-geometric-r-v-with-mean-1-%ce%b5-and</guid>
      <pubDate>Fri, 26 Jan 2024 14:43:35 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用模拟（引导重采样）A/A 测试来估计混杂因素影响治疗效果测量的程度？</title>
      <link>https://stats.stackexchange.com/questions/637821/is-it-possible-to-use-simulated-bootstrap-resampling-a-a-tests-to-estimate-the</link>
      <description><![CDATA[我最近与一位同事进行了交谈，他提出了一种策略来衡量混杂因素对 A/B 测试历史结果的影响程度。
为了使用 t 检验确定混杂因素对之前 A/B 测试结果准确性的影响程度，我的同事建议我们可以使用历史数据来重复运行模拟 A/A 测试：

对治疗组进行替换抽样
计算自举样本与整体治疗组样本之间的转化差异

并使用这些差异来衡量“混杂因素造成的差异”。
根据我的理解，这是没有意义的，因为以这种方式对治疗组进行随机抽样只会提供有关随机抽样导致的治疗转化率固有变异性的信息（即有关转化率抽样分布方差的信息） ）并且没有提及治疗组中由于混杂而存在的任何固有偏差，因为系统偏差将被随机抽样所掩盖，因为中心极限定理告诉我们来自同一群体的 2 个随机样本之间的差异将收敛于 0 并且当然没有告诉我们有关对照组的任何信息。也就是说，混杂是测量中的偏差，而不是测量中的变异性。
我用下面的Python代码进一步说明了我的观点。
问题：是否可以使用模拟（引导重采样）A/A 测试来估计混杂因素影响治疗效果测量的程度？
将 numpy 导入为 np
将 pandas 导入为 pd

n = 10000
x = np.random.normal(0.1, 0.06, n) # 转换倾向
confounding = np.clip(np.random.logistic(.6 * x, scale = 0,size = n),0,1) #与 x 创建混淆
t = np.random.binomial(1, confounding, n) # 治疗组指标

# 使用 x &amp; 计算转换概率t 并确保 p 保持在 [0, 1] 范围内
p = np.clip(x + t * 0.02, 0, 1) # 转换概率（假设处理效果均匀）
conv = np.random.binomial(1, p, n) # 实际转换

df = pd.DataFrame({&#39;t&#39;: t, &#39;conv&#39;: conv})
处理 = df.query(&#39;t == 1&#39;)

差异 = []
p1 = 处理[&#39;conv&#39;].mean()

对于 _ 在范围内（1000）：
    样本=处理过的.样本（1000，替换= True）
    p2 = 样本[&#39;conv&#39;].mean()
    差异.append(p1 - p2)

np.mean(diffs), np.std(diffs) # 这不会直接反映混杂的方差
]]></description>
      <guid>https://stats.stackexchange.com/questions/637821/is-it-possible-to-use-simulated-bootstrap-resampling-a-a-tests-to-estimate-the</guid>
      <pubDate>Fri, 26 Jan 2024 14:28:47 GMT</pubDate>
    </item>
    <item>
      <title>（基本假设检验）找到备择假设</title>
      <link>https://stats.stackexchange.com/questions/637820/basic-hypothesis-testing-find-the-alternative-hypothesis</link>
      <description><![CDATA[我正在处理以下问题：
&lt;块引用&gt;
经过变更管理，一位生产商声称他的防弹衣只有不到 5% 存在生产缺陷。随机抽取了 200 件防弹衣样本，其中 5 件展示了生产型防弹衣。数据是否支持生产者声称的内容？ （使用 $\alpha=0,05$）。

我正在努力寻找测试的正确替代假设。由于他声称“低于 5%”，那么我推断我应该测试：
\begin{align}
H_0:p=0,05\\
H_1:p&lt;0,05
\end{对齐}
在这种情况下，如果我拒绝零假设，数据将支持生产者的主张。
我说得对吗？
如果有任何反馈，我将不胜感激。
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637820/basic-hypothesis-testing-find-the-alternative-hypothesis</guid>
      <pubDate>Fri, 26 Jan 2024 14:25:46 GMT</pubDate>
    </item>
    <item>
      <title>对比和数值协变量的线性混合模型输出</title>
      <link>https://stats.stackexchange.com/questions/637819/linear-mixed-model-output-of-contrasts-and-numerical-covariates</link>
      <description><![CDATA[我想同时获得设计对比和数值协变量的线性混合模型 (lme4::lmer) 的模型输出。
模型方程为：
new_model &lt;- lmer(Body_temp_morning_max ~ Shadow_condition + DIM + (1|period) + (1|exp_day)+ (1|Animal), data=data_daily)
Shadow_condition 是一个 3 级因子变量，DIM 是一个数值变量。
我计算了 Shadow_condition 的两个对比
contr &lt;- rbind(“close-dist” = c(1, -0.5, -0.5), “dist_shade(exit)-dist_water(exit)” = c(0, 1, -1) ）
并得到对比的 p 值，如下所示：
summary(glht(new_model, linfct = mcp(Shadow_condition = contr), test = adjustment(“none”)))
同时，我需要 F 检验结果，包括我通常从以下位置获得的 DIM p 值：
car::Anova(new_model, test=&quot;F&quot;, type=&quot;III&quot;)
是否可以选择同时获取所有测试结果（以避免多重比较问题）？或者我应该稍后更正 p 值（Bonferroni 或其他；如果是：如何？）？
提前谢谢您！
干杯
安娜]]></description>
      <guid>https://stats.stackexchange.com/questions/637819/linear-mixed-model-output-of-contrasts-and-numerical-covariates</guid>
      <pubDate>Fri, 26 Jan 2024 14:11:11 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程分类的条件方差公式</title>
      <link>https://stats.stackexchange.com/questions/637817/conditional-variance-formula-for-gaussian-process-classification</link>
      <description><![CDATA[我试图理解 scikit learn 背后的数学 高斯流程分类器。有一个到该算法的书的链接。这有点涉及，并且有一个特定的公式这里，我不明白。即：
$$\mathbb{V}_q[f_*| X,y,x_*] = \mathbb{E}_{p(f_*|X,x_*,f)}[(f_*-\mathbb{E}[f_*|X,x_*,f]) ^2]+\mathbb{E}_{q(f|X,y)}[(\mathbb{E}[f_*|X,x_*,f]-\mathbb{E}[f_*|X, y,x_*])^2]$$
如果我写下条件方差的定义，我会得到：
$$\mathbb{V}_q[f_*| X,y,x_*] = \mathbb{E}_q\left((f_*-\mathbb{E}_q(f_*|X,y,x_*))^2|X,y,x_*\right )$$ 但我不知道如何获得公式。另外，符号 $\mathbb{E}_{p(f_*|X,x_*,f)}(\cdot)$ 到底是什么意思？ p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/637817/conditional-variance-formula-for-gaussian-process-classification</guid>
      <pubDate>Fri, 26 Jan 2024 14:04:14 GMT</pubDate>
    </item>
    <item>
      <title>错误的时间序列检测</title>
      <link>https://stats.stackexchange.com/questions/637815/wrong-time-series-detection</link>
      <description><![CDATA[我有问题，需要帮助。
我有一个时间序列，我需要知道数据是否正确。让我用一个例子来解释一下。假设我有大气压力传感器生成的数据。数据总数为100个，其中90个等于0，其余为1000 hPa左右的概略值。
在这种情况下，很可能由于某些错误，传感器记录的值为 0。如果对异常值进行研究，则正确的值很可能是检测到的值异常值。
对于这个例子，很容易知道如果我测量大气压力，0 的值是不正确的。问题是我有几个时间序列，每个时间序列代表来自不同测量的数据。
我需要进行一项分析，以便确定时间序列中何时出现错误值，并且该分析独立于所做的测量。
我很欣赏任何想法。
注意：我`正在使用 PySpark]]></description>
      <guid>https://stats.stackexchange.com/questions/637815/wrong-time-series-detection</guid>
      <pubDate>Fri, 26 Jan 2024 13:15:19 GMT</pubDate>
    </item>
    <item>
      <title>训练损失达到零，然后突然增加，然后减少到零</title>
      <link>https://stats.stackexchange.com/questions/637814/training-loss-reach-to-zero-then-suddenly-increases-then-decreases-to-zero</link>
      <description><![CDATA[在使用默认 Adam 和默认学习对某些合成数据进行均方误差损失训练多层感知器时，我得到以下损失行为。 （我正在处理 1 维数据）
我使用训练数据==验证数据，因为我希望我的模型能够在国际范围内过度拟合：
我没有使用批量归一化和丢失
]]></description>
      <guid>https://stats.stackexchange.com/questions/637814/training-loss-reach-to-zero-then-suddenly-increases-then-decreases-to-zero</guid>
      <pubDate>Fri, 26 Jan 2024 11:50:52 GMT</pubDate>
    </item>
    <item>
      <title>将离散优化问题转化为连续优化问题</title>
      <link>https://stats.stackexchange.com/questions/637812/transforming-discrete-optimisation-problem-into-continuous-optimisation-problem</link>
      <description><![CDATA[在稀疏希尔伯特-施密特独立准则回归中（Poignard 和 Yamada，AISTATS 2020 ），作者考虑了一种通过采用特征子集来执行特征选择的方法，该子集最大化每个特征与目标变量之间的依赖关系之和减去每个特征之间的成对依赖关系之和。这是一个离散优化问题，对应于第 2.2 节中的方程 (1)，为了方便起见，我将其重现如下：
&lt;块引用&gt;
$ \hat{\mathcal{S}} = \text{argmax}_{\mathcal{S}}\left[
\frac{1}{|\mathcal{S}|} \sum_{k \in \mathcal{S}}
\text{D}\left(\text{X}^{(k)}, \text{Y} \right) -
\frac{1}{|\mathcal{S}|^2} \sum_{k \in \mathcal{S}} \sum_{j \in
\mathcal{S}} \text{D}\left(\text{X}^{(k)}, \text{X}^{(j)} \right)
\right]~~~ (A)$

其中 argmax 取自完整特征集的子集，D 是依赖性的度量。作者选择使用经验 HSIC 作为依赖性 D 的度量，我对此没有任何问题。
该优化问题是一个离散优化问题。离散优化问题通常很难解决。
在第 2.4 节中，作者将离散优化问题转化为连续优化问题。首先，他们以严格等效的形式 (B) 重写原始问题 (A)：
&lt;块引用&gt;
$\text{argmax}_{\beta \in \{0, 1\}^d} \left[ \frac{1}{\beta^T \mathbf {1}} \sum_{k=1}^d \beta_k \text{D}\left(\text{X}^{(k)}, \text{Y} \right) - \frac{1}{ \left(\beta^T \mathbf{1}\right)^2} \sum_{k=1}^d \sum_{j=1}^d \beta_k \beta_j \text{D}\left(\text {X}^{(k)}, \text{X}^{(j)} \right)\right] ~~~~ (B)$。

到目前为止一切顺利，(A) 和 (B) 只是表达同一件事的两种方式。然而，作者随后“放松”了。 $\beta$ 在连续空间上进行优化，从而导致连续优化问题 (C)：
&lt;块引用&gt;
$\text{argmax}_{\theta \in [0, \infty[^d} \left[\sum_{k=1}^d \theta_k \text {D}\left(\text{X}^{(k)}, \text{Y} \right) - \frac{1}{2} \sum_{k=1}^d \sum_{j=1 }^d \theta_k \theta_j \text{D}\left(\text{X}^{(k)}, \text{X}^{(j)} \right) - \lambda ||\theta|| _1\right]~~~~ (C)$.

从直觉上来说，这个连续公式 (C) 对我来说是有意义的。然而，我的脑海中我无法提出一个正式的论据，为什么进行这种放松并考虑连续优化问题（C）而不是离散优化问题（B）是有效的。 p&gt;
有人可以解释一下将离散优化问题替换为连续优化问题的有效性条件吗？该技术有具体名称吗？欢迎参考文献！]]></description>
      <guid>https://stats.stackexchange.com/questions/637812/transforming-discrete-optimisation-problem-into-continuous-optimisation-problem</guid>
      <pubDate>Fri, 26 Jan 2024 10:52:13 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑回归中添加和解释协变量</title>
      <link>https://stats.stackexchange.com/questions/637804/adding-and-interpreting-covariates-in-logistic-regression</link>
      <description><![CDATA[我有一个数据集，我想在连续变量“A”和“A”之间进行逻辑回归。以及分类变量“B”。然而，我还想包括“年龄”和“性”在我的统计分析中，变量是混杂因素。你能解释一下我该如何在 R 中做到这一点吗？另外，如何在考虑协变量的影响的同时获得每个变量的调整后优势比？
这是正确的统计分析吗？我还应该包括这些变量之间的相互作用吗？
模型 &lt;- glm(B ~ A + 年龄 + 性别，数据 = 数据，家庭 = 二项式())

那我该如何正确解读呢？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/637804/adding-and-interpreting-covariates-in-logistic-regression</guid>
      <pubDate>Fri, 26 Jan 2024 08:32:45 GMT</pubDate>
    </item>
    <item>
      <title>先前实验的贝叶斯使用</title>
      <link>https://stats.stackexchange.com/questions/637781/bayesian-use-of-previous-experiments</link>
      <description><![CDATA[假设我有两项研究，例如 $\mathcal{S}_1$ 和 $\mathcal{S}_2 $，带有各自的数据集$\mathcal{D}_1，\mathcal{D}_2$，参数 $\theta^{(1)}、\theta^{(2)}$ 和响应变量 $y, z$。我有以下问题：

如果我有兴趣使用第一项研究的响应 $y$ 作为第二项研究的协变量，这是推荐的方式我可以继续吗？对后验预测进行正态逼近并计算均值和方差并将其用作与协变量 $y$ 相关的参数的先验是否有意义，在第二项研究中，比如说$\theta_y^{(2)}$？我遇到的主要问题是我的后验分布看起来并不正态。

此外，假设 $\mathcal{D}_2$ 有一组出现在  中的协变量$\mathcal{D}_1$。如果我想在第二个研究 $\theta^{(1)}$ 子集的后验信息，建议采用哪种方式进行class=&quot;math-container&quot;&gt;$\mathcal{S}_2$？

]]></description>
      <guid>https://stats.stackexchange.com/questions/637781/bayesian-use-of-previous-experiments</guid>
      <pubDate>Thu, 25 Jan 2024 21:50:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Harrell 主张“在数据缩减过程中忽略 Y”？</title>
      <link>https://stats.stackexchange.com/questions/637773/why-does-harrell-argue-for-ignoring-y-during-data-reduction</link>
      <description><![CDATA[在回归建模策略第 79 页（4.7 数据缩减）中写道：
&lt;块引用&gt;
数据缩减的目的是减少模型中要估计的参数数量，而不扭曲参数的统计推断。这是通过在数据缩减期间忽略 Y 来实现的。无监督学习中对 X 的操作可能会导致预测 Y 的信息丢失，但当信息丢失很小时，功效的增益和过拟合的减少足以抵消损失

无监督学习不会增加丢弃相关变量的风险吗？您如何向没有统计背景的研究人员/PI 争论，失去这些数据足以被功效的增加和过度拟合的缓解所抵消？
最后是否存在这种交易不值得的情况？如果研究人员主要关心的是找出“正确的”例如，变量。
我相信文本的建议是合理的，但我想充分理解它，以便我可以向持怀疑态度的外行观众解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/637773/why-does-harrell-argue-for-ignoring-y-during-data-reduction</guid>
      <pubDate>Thu, 25 Jan 2024 20:30:40 GMT</pubDate>
    </item>
    <item>
      <title>用于电价预测的神经网络（顺序：LSTM 和密集） - 代码审查和有效性检查 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637765/neural-network-sequential-lstm-dense-for-electricity-price-prediction</link>
      <description><![CDATA[亲爱的交叉验证社区，
我目前正在尝试建立一个神经网络，可以在一定程度上准确地预测电价。但是，我不确定下面的代码是否会产生有效的预测，或者只是看起来如此。因此，如果对这些模型有更深入了解的人能够对此设置提供意见，我将不胜感激。现在只需将所述代码复制到 .py 文件中并在几秒钟内运行即可。对于严肃的预测，我计划在 price_data 中使用至少 1000 个值，大约 70 test_hours。
最诚挚的问候，并对未能首先提供功能代码表示歉意，
马蒂亚斯:)
导入 pandas 作为 pd
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
导入数学
从 sklearn.preprocessing 导入 MinMaxScaler
导入keras
从 keras 导入层

Price_data = np.array([ 1.006e+01, -4.081e+00, -9.911e+00, -7.417e+00, -1.255e+01,
       -1.727e+01、-1.527e+01、-4.932e+00、-6.336e+00、-4.938e+00、
        4.501e-01、1.204e-01、-2.003e-02、0.001e+00、-3.002e-02、
        1.973e+00、9.061e+00、7.003e-02、-4.971e+00、-6.983e+00、
       -2.494e+01、-4.872e+00、-2.898e+01、-3.359e+01、-4.591e+01、
       -4.827e+01、-4.497e+01、-4.894e+01、-2.992e+01、-1.002e-02])

价格数据 = 价格数据[:,无]
标量 = MinMaxScaler(feature_range=(0,1))
缩放价格数据 = 标量.fit_transform(价格数据)

Training_len = math.ceil(len(price_data)*0.8)
测试时间 = 5

训练价格数据 = 缩放价格数据[0:训练长度]
x_训练 = []
y_训练 = []
对于范围内的 i(test_hours, len(training_price_data)) ：
    x_training.append(training_price_data[i - test_hours: i])
    y_training.append(training_price_data[i])

x_training, y_training = np.array(x_training), np.array(y_training)
x_training = np.reshape(x_training, (x_training.shape[0], x_training.shape[1], 1))

模型 = keras.Sequential(
    [
        LSTM(32, return_sequences=True, input_shape=(x_training.shape[1],1)),
        层.LSTM(32, return_sequences=False),
        层.密集（16，激活=“relu”），
        层.密集(1)
    ]
）
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)
model.fit（x_training，y_training，batch_size = 1，epochs = 10）

test_price_data = scaled_price_data[training_len - test_hours:, :]
x_测试 = []
y_test = Price_data[training_len:, :]
对于范围内的 i（test_hours，len（test_price_data））：
    x_test.append(test_price_data[i-test_hours:i])

x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

预测 = model.predict(x_test)
预测 = scalar.inverse_transform(预测)

火车 = 价格数据[: 训练长度]
有效=价格数据[训练长度：]

有效 = np.concatenate((训练,预测))
plt.figure(figsize=(16,8))
plt.title(&#39;使用 LSTM/Dense 进行预测&#39;)
plt.xlabel(&#39;日期&#39;)
plt.ylabel(&#39;价格&#39;)
plt.plot(价格数据)
plt.plot（有效）
plt.plot(火车)
plt.legend([&#39;实际价格数据&#39;,&#39;预测&#39;,&#39;训练数据&#39;])
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/637765/neural-network-sequential-lstm-dense-for-electricity-price-prediction</guid>
      <pubDate>Thu, 25 Jan 2024 18:54:30 GMT</pubDate>
    </item>
    <item>
      <title>帕累托分布的数值求积[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637740/numerical-quadrature-for-pareto-distribution</link>
      <description><![CDATA[当在任何给定点评估 $f(x)$ 时，我想对以下类型的积分进行数值计算：
$$
\int_{x_m}^\infty x^{-\alpha}f(x) \, dx, \quad \alpha &gt; 1, x_m &gt; 0。
$$
我的问题是，最好的方法是什么。或者，是否有一些标准方法可以解决此类问题。我们可以假设 $f(x)$ 是全局有界的。
我想到的两个可能的选择是使用（i）高斯-勒让德求积并更改变量来更改 $[x_m, \infty]$ 的积分限制 到 $[-1,1]$ 或 (ii) 高斯-拉盖尔求积分 $g( x) = x^{-\alpha}e^x f(x)$。
但是，我对这些正交方案在变量更改后的稳定性（和其他）属性一无所知。例如，使用高斯拉盖尔求积，上面定义的 $g(x)$ 不会是全局有界的，我怀疑可能不会产生积分的良好近似值。 
因此，我想知道，对于此类具有多项式衰减权重的积分是否存在某种标准求积方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/637740/numerical-quadrature-for-pareto-distribution</guid>
      <pubDate>Thu, 25 Jan 2024 13:33:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中提取 DCC-GARCH 模型的标准化残差并运行诊断测试？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637724/how-to-extract-standardized-residuals-of-a-dcc-garch-model-in-r-and-run-diagnost</link>
      <description><![CDATA[考虑在 R 中估计的 DCC-GARCH 模型。诸如多元 Ljung-Box 统计之类的诊断测试需要模型的残差。如何从 DCC-GARCH 模型中提取残差？下面的命令正确吗？
res=residuals(dcc.fit)

此外，R 中用于序列相关的 Ljung-Box 统计和 DCC-GARCH 模型的 ARCH 测试统计的命令是什么？以下命令正确吗？
mq(res,lag=10,adj=0)
ArchTest(res)
]]></description>
      <guid>https://stats.stackexchange.com/questions/637724/how-to-extract-standardized-residuals-of-a-dcc-garch-model-in-r-and-run-diagnost</guid>
      <pubDate>Thu, 25 Jan 2024 08:14:05 GMT</pubDate>
    </item>
    </channel>
</rss>