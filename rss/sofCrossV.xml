<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 16 Nov 2024 12:31:28 GMT</lastBuildDate>
    <item>
      <title>`sklearn.datasets.make_regression` 中 `n_informative` 参数的具体含义是什么？</title>
      <link>https://stats.stackexchange.com/questions/657350/what-is-the-exact-meaning-of-n-informative-parameter-in-sklearn-datasets-make</link>
      <description><![CDATA[sklearn 的官方文档指出

[sklearn.datasets.make_regression] 的输出是通过将具有 n_informative 非零回归量的（可能有偏差的）随机线性回归模型应用于先前生成的输入和一些具有可调比例的高斯中心噪声而生成的。

我很难理解这些词的确切含义。“n_informative 非零回归量”的数学模型是什么？这是否意味着我们生成 n_informative 系数 $w_{k}$，形式为 $w_{0}+\sum_{k=1}^{\text{n_informative}-1}w_{k}x_{k}$，并将其与一些随机噪声一起应用于 n_features 随机字符串以生成初始数据？我们是否生成随机 n_informative$\times$n_features 矩阵？我们如何生成 y 列？]]></description>
      <guid>https://stats.stackexchange.com/questions/657350/what-is-the-exact-meaning-of-n-informative-parameter-in-sklearn-datasets-make</guid>
      <pubDate>Sat, 16 Nov 2024 05:29:38 GMT</pubDate>
    </item>
    <item>
      <title>是否应将规范化应用于交互特征</title>
      <link>https://stats.stackexchange.com/questions/657349/should-normalization-be-applied-on-interaction-feature</link>
      <description><![CDATA[我正在机器学习模型中使用交互特征，通过将数值变量与编码分类特征相乘来创建新特征。我的问题是：
是否应该对这些交互项应用规范化？
如果是，那么规范化不会改变交互项的含义吗？具体来说，当我先对数值特征进行归一化，然后创建交互项时，交互项是否仍表示其最初要捕获的关系？
如果在创建交互项之前对数值变量进行归一化，交互项是否会失去其真实比例或含义？
例如，如果我将归一化数值特征与分类变量（可以是独热编码）相乘，我是否会扭曲数值特征与类别之间的原始关系？
我希望澄清交互项是否应进行归一化或保持原样，尤其是在交互项在捕获特定关系中起关键作用的情况下。
谢谢！
我尝试了什么：
我尝试在创建交互项之前对数值特征进行归一化。具体来说，我先对数值变量进行归一化，然后将其与编码的分类特征相乘。我还尝试在不先对数值变量进行归一化的情况下创建交互特征，以比较这两种方法。
我期望什么？
我希望了解在创建交互项之前对数值特征进行归一化是否会影响模型捕捉数值和分类特征之间预期关系的能力。我还很好奇，由于数值特征的归一化，交互项的含义是否会保留或扭曲。我希望了解归一化是否会导致交互项失去其原始规模和重要性，或者它是否有利于模型收敛和性能。]]></description>
      <guid>https://stats.stackexchange.com/questions/657349/should-normalization-be-applied-on-interaction-feature</guid>
      <pubDate>Sat, 16 Nov 2024 04:02:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么机器学习不会遭受维数灾难？</title>
      <link>https://stats.stackexchange.com/questions/657344/why-doesnt-ml-suffer-from-curse-of-dimensionality</link>
      <description><![CDATA[免责声明：我三天前在 Data Science Stack Exchange 上问过这个问题，但至今没有得到回复。也许这不是正确的网站。我希望在这里得到更多积极的参与。
这个问题困扰了我很久。我是一名训练有素的统计学家，我知道有些事情在高维度上是无法做到的（或者至少你不会得到你想要的，但你可能会得到其他东西）。
有维数灾难的概念。例如，密度估计在高维度上非常慢，因为核密度估计的收敛速度是 $𝑛^{−2/(2+𝑑)}$
。显然，当 𝑑→∞
时，这个速率基本上表现得像一个常数，因此在高维度上进行密度估计基本上是不可能的。但我们经常看到在高维度中使用扩散模型和其他方法。我在这里并不是真正谈论理论；相反，它们用于稳定扩散、Dall-E 等，效果很好！
然后是高维分类中的可分离性概念。逻辑回归通常用作许多神经网络的顶层。随着数据维数的增加，类别变得越来越分离。因此，分类在高维中几乎是微不足道的。但这也意味着逻辑 MLE 不存在，因为可以有无限多个分类器。所以，我们得到了一个分类器，但我们得到了我们想要的吗？
传统知识提供的内容与 ML 所实现的内容之间似乎存在差异。我的问题是关于这种差异的。传统理论家错过了什么？有明显的陷阱，但不知何故 ML 似乎并没有陷入其中。我们得到的是不是我们真正想要的东西，而只是因为最终产品“看起来”很好，我们认为这就是我们一直想要的？
有人知道可能的原因是什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657344/why-doesnt-ml-suffer-from-curse-of-dimensionality</guid>
      <pubDate>Sat, 16 Nov 2024 00:56:40 GMT</pubDate>
    </item>
    <item>
      <title>如果 alpha = 0.05 时 p 值为 0.0503，我们是否拒绝原假设？如果有的话，用什么方法可以验证拒绝？</title>
      <link>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</link>
      <description><![CDATA[我知道它大于 0.05，但我只是想知道，因为将其四舍五入到小数点后两位会得到 0.05。我只是想确保我没有错误地接受零假设。有没有办法说，即使这个值接近 alpha，也有足够的证据拒绝零假设？
另外，我知道我不应该这样做，但在进行事后分析后，我得到了不同治疗之间的均值结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</guid>
      <pubDate>Fri, 15 Nov 2024 17:58:11 GMT</pubDate>
    </item>
    <item>
      <title>泛化误差与模型复杂度呈 U 形曲线（偏差方差权衡）</title>
      <link>https://stats.stackexchange.com/questions/657317/generalization-error-as-u-shape-curve-with-respect-to-model-complexity-bias-var</link>
      <description><![CDATA[是否有任何数学著作严格证明某些学习问题的泛化误差随模型复杂度（偏差方差权衡）呈现 U 形曲线？有任何参考资料吗]]></description>
      <guid>https://stats.stackexchange.com/questions/657317/generalization-error-as-u-shape-curve-with-respect-to-model-complexity-bias-var</guid>
      <pubDate>Fri, 15 Nov 2024 15:41:58 GMT</pubDate>
    </item>
    <item>
      <title>在几乎为零的数据中寻找异常值</title>
      <link>https://stats.stackexchange.com/questions/657310/finding-outliers-in-mostly-zero-data</link>
      <description><![CDATA[背景
我正在研究一种算法，用于在长 DNA 序列中查找短的 DNA 序列片段。我不会详细介绍它的实际工作原理，但让我更正式地说明它以提供足够的背景信息。每个 DNA 序列只是字母表 ATGC 中的一个字符串。给定参考 r，我们沿着参考 r 移动窗口 w。例如，如果参考 r 是 ATGCA 且 w=3，我们将生成窗口 ATG、TGC、GCA。然后将每个窗口与每个查询进行比较以生成计数 c，该计数类似于它们的匹配程度。从而基本上生成一个矩阵，其中列是 r 中的窗口起始位置，行是每个查询的每个窗口的计数。根据实验数据，我们预计在参考的左侧和右侧会看到计数峰值。但是，这并不能保证，左侧、右侧或两个峰值可能都不存在，并且每侧（甚至中间）可能有多个峰值。
图
颜色代表不同的查询，但省略了图例，因为它占用了太多空间
示例 1。大多数窗口实际上与查询不匹配，因此零占主导地位（参见底部面板，不确定为什么绘图库将条形图放在 0 旁边，但第一个条形图是零）。但是，左右两侧的两个蓝绿色峰值明显突出，计数超过 20。

示例 2
与示例 1 类似，但是左侧峰值不太明显。从视觉上看，我认为蓝色仍然高于“平均”水平它不像橙色那么明显。

示例 3
这是一个单侧有多个峰值的示例：

问题
我的第一直觉是使用 z 分数、百分位数或 IQR 之类的东西来选择这些高值。但是由于零占主导地位，计数 3 或 5 实际上也被视为“异常值”，但这不是我感兴趣的。我真的很想知道如何“自动”检测出如此高的异常值。主要目的只是尽量减少用户输入，因为设置最小计数并不直观。此外，当我设置最小 z 分数时，例如，一个峰值会通过，但另一个不会，等等。虽然从视觉上看它们似乎很明显，但我找不到一种方法来巧妙地检测它们。
好奇地想看看回复！]]></description>
      <guid>https://stats.stackexchange.com/questions/657310/finding-outliers-in-mostly-zero-data</guid>
      <pubDate>Fri, 15 Nov 2024 12:03:04 GMT</pubDate>
    </item>
    <item>
      <title>在 Kruskal-Wallis 之后，通过使用 Wilcoxon 进一步比较各组来获取更多信息？（当无法进行双向方差分析时）</title>
      <link>https://stats.stackexchange.com/questions/657307/gaining-additional-information-after-kruskal-wallis-by-further-comparing-groups</link>
      <description><![CDATA[我有以下实验设置，数字是六组中的个体：



场景
治疗 1
治疗 2
治疗 3




A
28
27
27


B
28
28
28



已经测量过一次的是基于两种治疗方法的小鼠移动距离不同场景。所有个体都是独一无二的，在各组之间不会重复。
研究问题是三种治疗方法在移动距离上是否会有所不同。为了增加另一层，我们在两种不同的场景中对其进行了测试，以查看这是否对治疗方法有影响。
不幸的是，我们无法进行双向方差分析来测试交互作用。相反，我们针对每种情况分别进行了 Kruskal-Wallis (KW)，然后如果显著则进行 Dunn 的事后检验。

问题 1。在 A 和 B 中的治疗 1 之间进行 Wilcoxon 检验，然后在 A 和 B 中的治疗 2 之间进行另一次 Wilcoxon 检验，最后在 A 和 B 中的治疗 3 之间进行一次 Wilcoxon 检验，这在统计上合理吗？
问题 2。同样，在场景 A 和 B 之间进行 Wilcoxon 检验听起来是否合理？

我的理由是，对于 Q1，我将根据场景查看治疗之间是否存在差异。但与此同时，我知道这不是双向方差分析相互作用效应的适当替代品。如果我发现治疗 1 在 A 和 B 之间存在显著性，但其余治疗没有显著性，那么解释起来会很困难。因此，我认为 Q2 会更合理，因为它至少可以表明这两个场景作为一个整体是否有影响。
我知道 p-hacking，这是我希望避免的事情。但如果可以从实验中获得更多信息，那就太好了，这就是我希望得到答案的原因！此外，如果其中任何一个可行，我需要考虑哪些调整？]]></description>
      <guid>https://stats.stackexchange.com/questions/657307/gaining-additional-information-after-kruskal-wallis-by-further-comparing-groups</guid>
      <pubDate>Fri, 15 Nov 2024 10:51:11 GMT</pubDate>
    </item>
    <item>
      <title>证明 $(X, Y, Z)$ 相互独立意味着给定 $Z$，$X$ 和 $Y$ 也独立</title>
      <link>https://stats.stackexchange.com/questions/657266/proving-mutual-independence-of-x-y-z-implies-independence-of-x-and-y-g</link>
      <description><![CDATA[我想证明或反驳以下结果：
设$(\Omega, \mathcal F, \mathbb P)$为概率空间，且$X, Y, Z : \Omega \to \mathbb R$为相互独立的、$(\mathcal F, \mathcal B(\mathbb R))$-可测随机变量；那么 $X$ 和 $Y$ 在给定 $Z$ 的情况下是独立的。
我读到了以下问题的答案：在给定 Z 的情况下，X、Y、Z 的相互独立性是否意味着 X 和 Y 的条件独立性，然而在我看来，它假设 $X$、$Y$ 和 $Z$ 具有密度（相对于同一测量）。这不是我希望做出的假设。
我想使用的条件独立性、概率和独立性的特征如下（如果它们不正确，请告知）：

$X$ 和 $Y$ 是独立的，给定 $Z$，如果 $\mathbb P((X, Y) \in A \times B | Z) = \mathbb P(X \in A | Z) \mathbb P(Y \in B | Z)$ 对每对 borelian 集 $(A, B)$ 成立；
$\mathbb P(Y \in A | Z) = \mathbb E[\boldsymbol 1_{A} \circ Y | Z]$ 对于每个 borelian 集 $A$;
$\mathbb E[U | Z]$ 对于一个$(\mathcal F, \mathcal B(\mathbb R))$-可测变量，定义为唯一（几乎处处相等）$(\sigma(Z), \mathcal B(\mathbb R))$-可测随机变量，满足$\int_\Omega \boldsymbol (1_A \circ U)\ U \text d\mathbb P = \int_\Omega \mathbb E[U | Z] \boldsymbol 1_A \circ U \text d \mathbb P$ 对于每个 borelian 集 $A \subseteq \mathbb R$。

我仍然对所有这些符号感到困惑，并希望正式推导结果，尽可能合理地使用测度理论符号而不是概率符号。
我的问题是：

结果在一般情况下仍然正确吗？
我给出的预期期望定义是否正确（它应该是将我的教科书中给出的定义翻译成测度理论语言，但我可能遗漏了一些东西）？
这种表征是证明结果的合理起点吗？
我应该如何开始？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657266/proving-mutual-independence-of-x-y-z-implies-independence-of-x-and-y-g</guid>
      <pubDate>Thu, 14 Nov 2024 18:11:34 GMT</pubDate>
    </item>
    <item>
      <title>以不同时间频率收集变量的纵向回归模型？</title>
      <link>https://stats.stackexchange.com/questions/655840/longitudinal-regression-models-with-variables-collected-at-different-time-freque</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655840/longitudinal-regression-models-with-variables-collected-at-different-time-freque</guid>
      <pubDate>Wed, 16 Oct 2024 05:18:50 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型是否有类似间隔重复学习的东西？</title>
      <link>https://stats.stackexchange.com/questions/624601/is-there-anything-like-spaced-repetition-learning-for-machine-learning-models</link>
      <description><![CDATA[我想知道是否存在类似间隔重复的方法，但这种方法可以帮助机器学习模型学习。
间隔重复是一种人类学习抽认卡的方法，算法会尝试在学习者可能忘记之前展示抽认卡。
例如，如果抽认卡正确，你会在一天内再次看到它。如果再次正确，你会在两天后看到它，然后是四天，依此类推。如果你做错了，你的记忆时间就会降到零天，你必须重新做一遍。它基于赫尔曼·艾宾浩斯对遗忘曲线的发现。从 1880 年到 1885 年，他通过记忆一种假语言的单词对自己进行了实验（因为没有其他人愿意这样做）。这使他无法将已知单词与他试图记忆的单词联系起来，因此他可以获得更好的原始记忆数据。如今，确定等待时间的算法稍微复杂一些，但基本思想仍然适用。（如果您有兴趣尝试，请谷歌搜索“anki”）

将这个想法应用于机器学习会产生任何好处吗？或者已经存在类似的东西？基本上是相同的想法，但使用时期而不是天来管理何时应该进行审查。我知道灾难性遗忘是一种现象，但如果以类似于间隔重复的方式进行训练，也许有一些架构会保留在记忆中。这个想法让我想到了批处理，有时如果你不同时关注所有示例的梯度，你就可以摆脱局部最小值。
还有一些细节：你如何判断模型是否“正确”？例如，假设你正在训练一个分类模型，当它对正确类别有 90% 的确定性时，它是否正确？也许你可以随着每张卡片的训练而将正确所需的百分比降低到更高的水平，以将其引入 99.99% 的领域？也许有一种更好的通用方法可以根据该卡片的确定性历史来确定何时进行审查？使用这种方法是否存在偏见的危险？ （即：它会对有困难的练习进行更艰苦的训练，因此它会变得更好，但在它认为容易的练习上却变得更糟，并且来回反复？）在开启间隔重复之前，你是否必须进行一段时间的定期训练才能使其发挥作用？
谢谢阅读。]]></description>
      <guid>https://stats.stackexchange.com/questions/624601/is-there-anything-like-spaced-repetition-learning-for-machine-learning-models</guid>
      <pubDate>Tue, 22 Aug 2023 13:24:04 GMT</pubDate>
    </item>
    <item>
      <title>如何测试离散特征中的系统发育信号（即寄生虫数量）</title>
      <link>https://stats.stackexchange.com/questions/604797/how-can-i-test-for-phylogenetic-signal-in-a-discrete-trait-i-e-counts-of-para</link>
      <description><![CDATA[我正在 R 中运行具有泊松误差分布的 PGLMM，以评估社会性（二项式）对寄生虫负荷的影响。我想测试离散数据中的系统发育信号（例如鸟类寄生虫数量）。但是，我发现了几种在连续数据（phytools::phylosig ..pagel&#39;s, K, ）和分类数据（data ape::delta）中测试系统发育信号的方法，但在离散数据（计数数据）中测试系统发育信号的方法并不多。任何想法都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/604797/how-can-i-test-for-phylogenetic-signal-in-a-discrete-trait-i-e-counts-of-para</guid>
      <pubDate>Thu, 09 Feb 2023 01:51:14 GMT</pubDate>
    </item>
    <item>
      <title>如果我只能计算 $g(X)$ 的平均值，那么 LOTUS 的意义何在？</title>
      <link>https://stats.stackexchange.com/questions/602510/what-is-the-point-of-lotus-if-i-can-just-compute-the-average-of-gx</link>
      <description><![CDATA[无意识统计学家定律 (LOTUS) 是一条定理，用于计算随机变量 $X$ 的函数 $g(X)=Y$ 的期望值，当人们知道 $X$ 的概率分布，但不知道 $g(X)$ 的分布时。
如果 LOTUS 的目的是找到期望值 $E[g(X)]$，那么该定理建议使用 $X$ 的概率密度和 $g(X)$ 的值：
$$E[g(X)]=\sum_x\,g(x)f_X(x),\;\text{(discrete)}$$
或
$$E[g(X)]=\int_{-\infty}^{\infty}\,g(x)f_X(x)\,dx,\;\text{(continuous).}$$
但是，这是我的问题：如果我们知道并且可以访问所有实现$y=g(x)$，那么为什么我们不计算$g$的平均值呢？为什么我要涉及$X$的 PDF/PMF？]]></description>
      <guid>https://stats.stackexchange.com/questions/602510/what-is-the-point-of-lotus-if-i-can-just-compute-the-average-of-gx</guid>
      <pubDate>Thu, 19 Jan 2023 13:00:49 GMT</pubDate>
    </item>
    <item>
      <title>时间序列是 ML 模型的几个输入之一</title>
      <link>https://stats.stackexchange.com/questions/599307/time-series-as-one-of-several-inputs-to-ml-model</link>
      <description><![CDATA[我有一个看似相对简单的问题，尽管搜索了很长时间，却仍无法找到令人满意的答案：
分析时间序列数据的经典方法似乎是 RNN 的某种形式。但是，我见过的大多数示例都使用单个时间序列作为 RNN 的输入。我的应用程序需要稍微复杂一点的架构 - 给定推理的输入将是几个短时间序列以及几个单独参数的组合。在视觉形式中，这可能看起来像以下内容：

这里有两个主要问题：

我如何处理这里有两种不同类型的时间序列这一事实 - 它们不能轻易地堆叠并输入到同一个 RNN 中（或者可以吗？）
我如何处理所涉及的参数在时间序列过程中不会改变这一事实？我是否只需将这些参数中的每一个添加到时间序列的每个时间步上，还是做其他事情？

现在，我正在考虑尝试做一些 hacky Concatenate layer 的东西，但似乎像这样的常见情况需要更优雅的解决方案。
我发现了一些相关问题：这个，它提到了我几乎完全相同的问题，但从未得到答案，这个，它具有可变数量的输入时间序列并希望对它们执行一些特定操作，以及本教程讨论了串联。]]></description>
      <guid>https://stats.stackexchange.com/questions/599307/time-series-as-one-of-several-inputs-to-ml-model</guid>
      <pubDate>Sat, 17 Dec 2022 00:32:48 GMT</pubDate>
    </item>
    <item>
      <title>对两个样本进行双尾检验：我们可以说一个平均值/比例大于另一个吗？</title>
      <link>https://stats.stackexchange.com/questions/535142/two-tailed-test-for-two-samples-can-we-say-that-one-mean-proportion-greater-t</link>
      <description><![CDATA[当我们进行双尾检验（比例的 z 检验、t 检验甚至 bootstrap）时，零假设是没有差异或样本来自相同分布，而备择假设是有差异或样本来自不同分布。
从技术上讲，在双尾检验的情况下，p 值是两个均值/比例之间的差异大于或等于我的实验中当前差异的概率，即零假设为真。并且这个差异可以出现在两边，它是一个绝对差异。所以基本上双尾检验并没有说明哪个均值/比例更大。它没有显示方向。它只是说有差异。
我知道有一个单尾检验。但这对我来说没有意义：当我使用单尾检验时，我得到显著结果的次数是原来的两倍。而且我也知道实际上使用单尾检验几乎从来都不合适。而在日常生活中，比如说 A/B 测试，我们总是使用双尾检验。我个人从未在商业实践中见过单尾检验。
我的问题是，在双侧检验之后如何做出决策，例如在 A/B 测试的情况下，如何判断一组中的平均值/比例大于另一组？测试没有显示差异的方向，但我们说一个大于另一个并做出决定。我遗漏了什么吗？）]]></description>
      <guid>https://stats.stackexchange.com/questions/535142/two-tailed-test-for-two-samples-can-we-say-that-one-mean-proportion-greater-t</guid>
      <pubDate>Mon, 19 Jul 2021 12:49:49 GMT</pubDate>
    </item>
    <item>
      <title>如何解释密度图中负值的概率</title>
      <link>https://stats.stackexchange.com/questions/508357/how-to-interpret-the-probability-of-a-negative-value-in-a-density-plot</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/508357/how-to-interpret-the-probability-of-a-negative-value-in-a-density-plot</guid>
      <pubDate>Sat, 06 Feb 2021 20:54:54 GMT</pubDate>
    </item>
    </channel>
</rss>