<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 01 Dec 2024 01:40:32 GMT</lastBuildDate>
    <item>
      <title>随机森林 R 帮助</title>
      <link>https://stats.stackexchange.com/questions/658084/random-forest-r-help</link>
      <description><![CDATA[我在 R 中有一个数据框，随机分为训练集 (779) 和测试集 (326)，两者都不平衡。在训练集中，我有 31% 的事件（我想要预测的事件）。我应用了 5 倍交叉验证。这是我使用的方法。有人能告诉我这是否是正确的方法吗（就 summaryfunction 而言，考虑不平衡等）？如何调整超参数？我读到 method=ranger 中不考虑 ntress。我该怎么办？
&lt;&quot;&quot;control &lt;- trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, summaryFunction = prSummary)
#根据类别不平衡定义类别权重
class_weights &lt;- c(&quot;No&quot; = 1, &quot;Yes&quot; = 535 / 244) print(class_weights)
#使用 ROC 作为权重度量来训练随机森林模型
#定义类别权重
class_weights &lt;- c(&quot;No&quot; = 1, &quot;Yes&quot; = nrow(train_data) / (2 * sum(train_data$Predictor== &quot;Yes&quot;)))
#默认模型----
set.seed(123) rf_default &lt;- train(Predictor ~ ., data = train_data[, c(features, &quot;Predictor&quot;)], method = &quot;ranger&quot;, metric = &quot;AUC&quot;, trControl = control, weights = ifelse( train_data$RECIST_first_progressors == &quot;Yes&quot;, class_weights[&quot;Yes&quot;], class_weights[&quot;No&quot;] # 为类别不平衡分配权重 ))
# 访问交叉验证结果
cv_results &lt;- rf_default$resample
# 打印每个折叠的结果
print(cv_results)
# 计算汇总统计数据
summary_stats &lt;- cv_results %&gt;%
summarise(
Mean_AUC =平均值（AUC），
SD_AUC = sd（AUC），
平均值_Precision = 平均值（Precision），
SD_Precision = sd（Precision），
平均值_Recall = 平均值（Recall），
SD_Recall = sd（Recall），
平均值_F1 = 平均值（F），
SD_F1 = sd（F）
）
#打印摘要统计信息
print(summary_stats)&quot;&quot;
我从交叉验证中获得了 77% 的平均 AUC，因此我认为该模型在训练中不能完美预测（我喜欢这一点，因为它可能意味着没有过度拟合）。但是，当我在完整的数据框（训练+测试）上训练模型以评估在训练测试中预测结果的差异（基本上是用条形图绘制）时，预测是完美的。怎么可能呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/658084/random-forest-r-help</guid>
      <pubDate>Sat, 30 Nov 2024 22:38:54 GMT</pubDate>
    </item>
    <item>
      <title>ADF 检验中 Rho 和 Tau 统计量的差异</title>
      <link>https://stats.stackexchange.com/questions/658081/difference-between-rho-and-tau-statistics-in-adf-test</link>
      <description><![CDATA[我需要使用ADF 检验，滞后 = 2检查几个利率时间序列的平稳性。
SAS 输出生成三种类型的检验统计数据：Rho、Tau 和 F.，用于三种类型的检验（趋势、单一均值和零均值）。我想问几个问题，因为它们在我的案例中显示的结果不同。

有人知道我应该如何选择使用哪种类型的检验，趋势、单一均值还是零均值？查看图表，我的时间序列没有强烈的趋势，但有一些时期有趋势。
更重要的是，Rho 和 Tau 统计数据有什么区别？如果它们相矛盾该怎么办？
对于滞后 2 的单一均值类型 ADF，应该使用什么？如果是趋势类型，该怎么办？

附言。
本文旨在解释这种差异
（Dickey, D. A. (2005). “时间序列模型中的平稳性问题。”）。
因此，据我了解，Rho 是标准化偏差检验。]]></description>
      <guid>https://stats.stackexchange.com/questions/658081/difference-between-rho-and-tau-statistics-in-adf-test</guid>
      <pubDate>Sat, 30 Nov 2024 21:10:05 GMT</pubDate>
    </item>
    <item>
      <title>计算仪器变化后的置信区间</title>
      <link>https://stats.stackexchange.com/questions/658079/calculating-confidence-intervals-with-a-change-in-the-instrument</link>
      <description><![CDATA[在工具变量研究中，我有结果（健康结果）的点估计和相应的置信区间。我还有工具的平均值和范围（给定人群一年内医务人员的就诊次数）。我必须计算如果工具发生变化，置信区间将如何变化。也就是说，如果医务人员的就诊次数发生变化，健康结果将如何变化。有人可以指导我如何计算吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658079/calculating-confidence-intervals-with-a-change-in-the-instrument</guid>
      <pubDate>Sat, 30 Nov 2024 20:17:53 GMT</pubDate>
    </item>
    <item>
      <title>无论参数如何，OCTMNIST 上的 T-SNE 都会产生糟糕的结果</title>
      <link>https://stats.stackexchange.com/questions/658076/t-sne-on-octmnist-gives-bad-results-no-matter-the-parameters</link>
      <description><![CDATA[我正在尝试在 OCTMNIST 上实现 T-SNE。无论我如何尝试更改参数，我都无法获得良好的结果。这是我的代码
tsne_ft = TSNE(
n_components=2, # 嵌入的维度
perplexity=40, # 根据数据集大小进行调整
learning_rate=300, # 尝试使用 10 到 1000 的值
max_iter=1500, # 增加以获得更好的优化
init=&#39;pca&#39;, # 尝试使用 &#39;pca&#39; 以获得更好的初始化
random_state=42 # 确保可重复性
)

运行 10k 随机平衡样本得到以下图表：

我有然而，我看到一些论文的输出结果要好得多 graph

虽然我知道整个 OCTMNIST 并不平衡，但正如我所拥有的，它难道不应该表现得更好一点吗？我尝试过删除和添加 PCA 初始化、调整学习率、夸大、困惑度、max_iter，但似乎没有任何效果。任何想法都是无价的！]]></description>
      <guid>https://stats.stackexchange.com/questions/658076/t-sne-on-octmnist-gives-bad-results-no-matter-the-parameters</guid>
      <pubDate>Sat, 30 Nov 2024 19:34:42 GMT</pubDate>
    </item>
    <item>
      <title>基于相关性的特征消除的优化算法</title>
      <link>https://stats.stackexchange.com/questions/658075/optimized-algorithms-for-correlation-based-feature-elimination</link>
      <description><![CDATA[我有一个包含近一百万行和 2000 列的大型数据框。我正在尝试使用变量之间的相关性进行特征消除。当然，问题在于，对于一​​组 n 个特征，我们需要 nC2 或 n*(n-1)/2 个组合之间的相关性，这本身就是一种 O(n^2) 操作。
所以我想知道我们是否可以使用一些分而治之的策略来优化它，如下所示：

计算 20 个批次（每个批次 100 列）之间的相关性
消除高度相关的特征（阈值 &gt; 95%）
组合剩余的特征（大约 1000 个），再次分成 20 个批次
重复上述过程，直到达到固定的列阈值（我们可以一起处理，比如 200 个）
从中计算最后一次相关性并删除相关特征

我想知道这种方法是否有效，或者我们是否可以使用进一步优化的方法这个目的。我还想知道这是否适用于不同类型的相关性，如斯皮尔曼、肯德尔等。
这种方法做出了这个重要的假设：

如果 f1 和 f2 的相关度 &gt;95%，f2 和 f3 的相关度也 &gt;95%，那么我们假设 f1 和 f3 的相关度也 &gt;95%。

我不确定这是否有具体的理论基础，想听听你对如何证明不同类型的相关性的看法。]]></description>
      <guid>https://stats.stackexchange.com/questions/658075/optimized-algorithms-for-correlation-based-feature-elimination</guid>
      <pubDate>Sat, 30 Nov 2024 19:29:22 GMT</pubDate>
    </item>
    <item>
      <title>从 50 个数字中抽取多少次才能达到平均 25</title>
      <link>https://stats.stackexchange.com/questions/658073/how-many-draws-from-50-numbers-to-average-25</link>
      <description><![CDATA[问题是，我需要从 50 个编号球中抽取多少次才能得到平均值 25。
在某些运动中，起始位置由抽签决定。在一个赛季中，一些参赛者的平均数字较低，而另一些参赛者的平均数字较高。
参赛者需要抽取多少次才能得到平均值 25 或 25 +/- 2 或 25 +/- 3。
这是一个抽签公平性的问题。
戴夫]]></description>
      <guid>https://stats.stackexchange.com/questions/658073/how-many-draws-from-50-numbers-to-average-25</guid>
      <pubDate>Sat, 30 Nov 2024 18:18:13 GMT</pubDate>
    </item>
    <item>
      <title>针对机器学习问题预处理两种不同类型的数据集</title>
      <link>https://stats.stackexchange.com/questions/658072/preprocess-two-different-kind-of-datasets-for-a-machine-learning-problem</link>
      <description><![CDATA[我正在研究两个与健康相关的数据集。我使用 Python。

一个表格数据集（称为 A）包含患者级信息（按 ID）和一堆我已经转换和清理过的其他特征。这个数据集有大约 3000 行。数据集包含分类问题的标签 (y)。
其他数据是数据框的集合。每个数据框代表特定患者的时间序列数据（也按 ID）。大约有 1000 个数据框（只有 1000 名患者有关于此时间序列数据的可用信息）。

我迄今为止的方法：

对于数据框集合，对于每个数据框/患者 ID，我仅选择每列的平均值、中位数、最大值和最小值。然后将数据框转换为单行数据：例如：“patient_id”、“min_X”、“max_X”、“median_X”、“mean_X”，而不是冗长的时间步长级数据框。您认为这是保留时间序列数据关键信息的好主意吗？否则，我会考虑使用机器学习模型来选择时间序列特征，但不确定该怎么做。
现在，我将拥有这个患者级时间序列数据的单个数据框（称为 B），并希望将其与第一个清理后的数据框（A）连接起来，但行不匹配。也就是说，A 有 3000 行，但 B 只有 1000 行。B 的患者 ID 是 A 患者 ID 的子集。我不知道该如何处理这个问题。我正在考虑只使用 B 中的 1000 行并左连接 A，但这会造成大量数据丢失吗？或者用有意义的值（例如，总体平均值或中位数）或单独的类别“无时间序列数据”来填补 B 中的缺失行。

任何建议/想法都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/658072/preprocess-two-different-kind-of-datasets-for-a-machine-learning-problem</guid>
      <pubDate>Sat, 30 Nov 2024 17:39:36 GMT</pubDate>
    </item>
    <item>
      <title>SPSS 中的 Kaplan Meier 图表上有 95％ 的 CI [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658070/kaplan-meier-in-spss-with-95-ci-on-graph</link>
      <description><![CDATA[我正在做一个项目，需要绘制两种不同类型的骨科植入物的存活曲线，并且需要在图表上显示 95% 的置信区间。有没有办法在 SPSS 中做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/658070/kaplan-meier-in-spss-with-95-ci-on-graph</guid>
      <pubDate>Sat, 30 Nov 2024 14:17:01 GMT</pubDate>
    </item>
    <item>
      <title>在我的案例中选择正确的统计测试[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658069/choose-the-right-statistical-test-in-my-case</link>
      <description><![CDATA[我有一个调查数据集，其中每个参与者回答了 20 个独特的问题。我想对数据进行统计分析，但不确定要使用哪种测试：方差分析、重复测量方差分析还是混合效应模型？
我想用于统计测试的数据是问题类型和响应时间。
https://docs.google.com/spreadsheets/d/16cwLFGaF4KqLvwYNjHIcCyHaWup8vSJpL7gOEqk_XPA/edit?usp=sharing
我想测试的假设是问题类型对响应时间有影响吗？
问题时间有 4 种模式，响应时间是以秒为单位的数值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658069/choose-the-right-statistical-test-in-my-case</guid>
      <pubDate>Sat, 30 Nov 2024 14:09:41 GMT</pubDate>
    </item>
    <item>
      <title>我应该对凝聚层次聚类 (AHC) 的数据进行平均吗？</title>
      <link>https://stats.stackexchange.com/questions/658068/should-i-average-data-for-agglomerative-hierarchical-clustering-ahc</link>
      <description><![CDATA[我正在进行一项实验，测量小麦品种对病原体接种的反应。实验重复了三次，每次重复两次。始终测量两个疾病参数。我想执行 AHC 以根据品种的反应水平将它们分成几组，但我的问题是：在执行 AHC 之前，是否应该对所有重复的数据进行平均，只留下两个数据集（每个疾病参数一个）？]]></description>
      <guid>https://stats.stackexchange.com/questions/658068/should-i-average-data-for-agglomerative-hierarchical-clustering-ahc</guid>
      <pubDate>Sat, 30 Nov 2024 14:02:23 GMT</pubDate>
    </item>
    <item>
      <title>不同打印方法导致的方差解释差异</title>
      <link>https://stats.stackexchange.com/questions/658082/discrepancies-in-explained-variance-depending-on-the-print-method</link>
      <description><![CDATA[在执行探索性因子分析时，我想查看因子的解释方差。这很简单，我打印了fa()方法的输出。可以得到与$loadings输出相同的汇总表，如下所示。问题是两个表中的解释方差有偏差。这是什么原因，是 psych 包中的错误吗？哪个输出是正确的？
library(psych)

fa_results &lt;- fa(df_sq1sq9, nfactors = 5, rotate = &quot;oblimin&quot;)
print(fa_results)
fa_results$loadings

请注意，我不是在谈论因子载荷，而是在下表中谈论 Cumulative var 行。差异出现在正交和斜向旋转的情况下，并且在斜向旋转的情况下，两个输出的偏差更大。因此，该示例以斜交旋转显示。
斜交旋转：
&gt;print(fa_results)

[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.45 1.50 1.07 1.05 0.60
比例方差 0.27 0.17 0.12 0.12 0.07
累积方差 0.27 0.44 0.56 0.68 0.74
解释比例 0.37 0.22 0.16 0.16 0.09
累积比例 0.37 0.59 0.75 0.91 1.00

因子相关性为 
MR1 MR3 MR5 MR2 MR4
MR1 1.00 0.59 0.64 -0.01 0.30
MR3 0.59 1.00 0.33 0.12 0.21
MR5 0.64 0.33 1.00 0.28 0.11
MR2 -0.01 0.12 0.28 1.00 -0.17
MR4 0.30 0.21 0.11 -0.17 1.00

斜轴旋转：
&gt;fa_results$loadings
[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.310 1.350 0.975 1.038 0.563
比例方差 0.257 0.150 0.108 0.115 0.063
累计Var 0.257 0.407 0.515 0.630 0.693

我也在 https://stats.stackexchange.com/questions/657692/exploratory-factor-analysis-oblique-rotation-variance-explained 中提出了这个问题作为更新]]></description>
      <guid>https://stats.stackexchange.com/questions/658082/discrepancies-in-explained-variance-depending-on-the-print-method</guid>
      <pubDate>Sat, 30 Nov 2024 11:55:31 GMT</pubDate>
    </item>
    <item>
      <title>如何区分互动与中介？</title>
      <link>https://stats.stackexchange.com/questions/658060/how-to-distinguish-interaction-from-mediation</link>
      <description><![CDATA[我一直在思考我作为一项随机临床试验的一部分进行的分析。这项研究包括三次重复测量，每个个体被跟踪三次。然而，我的问题不是关于模型的纵向方面，而是关于所涉及的理论和统计概念。
具体来说，我分析了一个感兴趣的生物标记，它可能受到参与者体重的影响。在我的模型中，我测试了性别和体重之间的相互作用，以及其他协变量。以下是模型设置：
#sexo_s1:sex
#i_huleptin: 感兴趣的生物标志物
# peso1:weight
#grupo_int_v00: 临床试验组

lme_leptin &lt;- lme(i_huleptin ~ sexo_s1*peso1 + edad_s1 + poly(time, 2)*grupo_int_v00 + p17_total, 
random = ~ poly(time, 2)|paciente, control=lmeControl(opt=&quot;optim&quot;),
data = dat_longer, subset = !is.na(i_huleptin))
summary(lme_leptin)
res_lme_leptin &lt;- as.data.frame(coef(summary(lme_leptin)))

现在，这就是我感到困惑的地方：我对中介分析了解一点，中介解释了 X（独立变量）影响 Y（结果）的机制或途径。然而，从概念上讲，中介和交互对我来说似乎很相似。例如，在交互中，我们测试 X1 和 Y 之间的关系是否取决于
X2。从统计上讲，我知道这两种分析是不同的，但我不确定何时应用中介分析而不是交互分析。
更复杂的是，我的研究涉及重复测量，我不确定中介是否适用于这种情况。这可能是一个单独的问题，但我非常感谢您对这些观点的任何见解或指导。
非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/658060/how-to-distinguish-interaction-from-mediation</guid>
      <pubDate>Sat, 30 Nov 2024 08:22:14 GMT</pubDate>
    </item>
    <item>
      <title>包括两组用于元分析池的后测设计研究？</title>
      <link>https://stats.stackexchange.com/questions/658055/include-two-groups-post-test-design-study-for-meta-analysis-pool</link>
      <description><![CDATA[我是荟萃分析的新手，目前正在尝试寻找干预对服务用户的影响。
我发现的大多数研究都是 RCT 或准实验研究，采用 2 组事前事后测试设计。但是，有几项研究是 2 组事后测试设计，没有可用的事前测试数据。我想知道我是否可以将这个事后测试设计研究纳入荟萃分析池？或者只是将事后测试设计研究排除在荟萃分析之外？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658055/include-two-groups-post-test-design-study-for-meta-analysis-pool</guid>
      <pubDate>Sat, 30 Nov 2024 05:04:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的方差参数不会在 Metropolis-Hastings 采样器中收敛？</title>
      <link>https://stats.stackexchange.com/questions/658046/why-wont-my-variance-parameter-converge-in-my-metropolis-hastings-sampler</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658046/why-wont-my-variance-parameter-converge-in-my-metropolis-hastings-sampler</guid>
      <pubDate>Fri, 29 Nov 2024 20:22:02 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在研究一个重复测量数据集。该研究的目的是观察机构特征 (X) 对由于某种医疗状况 (Y) 导致的几家医疗机构的死亡人数的影响。Y 表示在跨越多年的时间段内每周测量的死亡人数。X 表示在整个研究过程中在多个时间点（每周、每季度、研究开始/结束）测量的连续/分类变量。变量 Y 是零膨胀的，并且由于在模型中包含太多预测因子而导致数值问题。
我的一组 X 变量 (u1、u2、...、un) 与一组其他变量 (v1、v2、...、vn) 相关。这使我无法在同一模型中同时建模 U（总共约 50 个）和 V（总共约 5 个）变量。因此，我对 U 变量进行了建模，并选择了对 Y 有显著影响的 U 变量子集。对于这个子集，我执行了 PCA，并在最终模型中使用了 PCA 分数和 V 变量。我相信这样做可以让它们（U 变量和 V 变量的 PCA 分数）彼此不相关，同时在估计 V 变量时会纳入 U 变量的净效应。
我的最终目标是获得与时间无关的 V 变量预测。
在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法涉及以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 之间的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除非数字变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不均等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    </channel>
</rss>