<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Dec 2024 06:26:43 GMT</lastBuildDate>
    <item>
      <title>在因子分析中，删除唯一性较低的变量后的新模型对原始模型有何影响？</title>
      <link>https://stats.stackexchange.com/questions/658250/in-factor-analysis-what-does-the-new-model-with-a-variable-with-low-uniqueness</link>
      <description><![CDATA[我正在使用 R 中的 factanal 进行因子分析模型：
$$X=Lf+\mathcal E. $$
当将因子设置为相对较大时，
我收到一个错误，即变量的唯一性（即 $E(\epsilon_i^2)$ 的估计值）接近于零。
虽然我可以通过设置非常小的lower值来解决这个问题，但是这篇文章说这会导致问题。
按照这篇文章的建议，我尝试删除唯一性较低的变量$Y_i$，然后模型就可以正常工作了。
但是，我想问一下，删除$Y_i$后的新模型对原始模型意味着什么？
例如，如果在新模型中，$p$ 个因素拟合良好，我们能否断言在原始模型中$p+1$ 个因素拟合良好？]]></description>
      <guid>https://stats.stackexchange.com/questions/658250/in-factor-analysis-what-does-the-new-model-with-a-variable-with-low-uniqueness</guid>
      <pubDate>Wed, 04 Dec 2024 05:51:04 GMT</pubDate>
    </item>
    <item>
      <title>我可以在使用组学数据的两阶段研究的两个阶段中使用 FDR 进行多重校正吗？</title>
      <link>https://stats.stackexchange.com/questions/658248/can-i-use-fdr-for-multiple-correction-in-both-stages-of-a-two-stage-study-using</link>
      <description><![CDATA[请问我是否可以在使用组学数据的两阶段研究的两个阶段中使用 FDR 进行多重校正。例如，基于 RNA-seq 数据，我想识别 20 名患者和 20 名健康受试者之间基因表达差异的基因。我正在考虑一个两阶段的研究设计。首先，将对 10,000 个基因进行学生 t 检验作为发现阶段（我知道可以使用 edgeR 或其他分析方法，但由于这个问题是关于多重比较的，我将使用 t 检验）。获得的 P 值会根据错误发现率 (FDR) 进行校正，q 值 &lt; 0.05 被认为是显著的。结果，50 个基因显示出显著差异。作为下一个阶段，我在与 RNA-seq 测量的样本不同的样本中验证这 50 个基因。另外 20 名患者和 20 名健康受试者通过 RNA-seq 以外的方法进行测量，并通过 t 检验再次进行比较。因此，测试了 50 次（50 个基因），所以我必须进行多次校正。我可以在这里再次调整 FDR 并假设 q 值 &lt; 0.05 是显著的吗？或者我应该在此阶段对 Bonferro 应用校正并将显著性水平设置为 P 值 &lt; 0.05/50（=0.001）？如果您能启发我，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658248/can-i-use-fdr-for-multiple-correction-in-both-stages-of-a-two-stage-study-using</guid>
      <pubDate>Wed, 04 Dec 2024 05:00:39 GMT</pubDate>
    </item>
    <item>
      <title>XGboost 分类特征影响预测的顺序</title>
      <link>https://stats.stackexchange.com/questions/658246/xgboost-classification-order-of-features-influencing-predictions</link>
      <description><![CDATA[我正在使用 xgboost 分类创建一个 UFC 比赛预测模型，该模型在包含 2 名战士的统计数据和比赛结果的数据集上进行训练。在训练模型后，我定义了一个函数，我只需输入战士姓名，它就会从战士统计数据数据集中获取他们的统计数据，并将其输入到模型中以预测谁将获胜。但是，当尝试进行新的预测时（例如：xgb_ufc(&quot;Vicente Luque&quot;, &quot;Themba Gorimbo&quot;) 和 xgb_ufc(&quot;Themba Gorimbo&quot;, &quot;Vicente Luque&quot;)），预测结果不同（在这两种情况下，第一个战士都被选为&quot;获胜&quot;））。我尝试过减少过度拟合的方法，但似乎输入比赛统计数据/特征的顺序仍然会影响预测。有人知道这是为什么以及如何解决它吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658246/xgboost-classification-order-of-features-influencing-predictions</guid>
      <pubDate>Wed, 04 Dec 2024 04:06:09 GMT</pubDate>
    </item>
    <item>
      <title>查找随机过程的方差</title>
      <link>https://stats.stackexchange.com/questions/658243/finding-the-variance-of-a-stochastic-process</link>
      <description><![CDATA[这是该问题的第二部分计算随机过程的均值和方差？
对于 Polya Urn 问题，我试图理解为什么方差的比率是：
$$\operatorname{Var}(X_n) = E[X_n](1-E[X_n]) \left(\frac{d}{w+b+d} - \frac{w+b}{w+b+d}\frac{1}{n}\right).$$
我知道一般方差公式是$E[X_n^2] - (E[X_n])^2$ 并且 $E[X_n] = \frac{w}{w+b}$。我只需要找到 $E[X_n^2]$。
当我们有 $n$ 个球时，如果我们抽出一个白球（概率 $X_{n-1}$），我们会添加 $d$ 个白球。如果我们抽到黑球（概率为$1-X_{n-1}$），我们添加$d$个黑球（$k$是前面步骤中添加的白球数量）。
$$ X_n = \begin{cases}
\frac{w + (k+1)d}{w+b+nd} &amp; \text{如果抽到白球} \\
\frac{w + kd}{w+b+nd} &amp; \text{如果抽出黑球}
\end{cases} $$
使用二阶总期望定律：
$$ E[X_n^2|X_{n-1}] = X_{n-1}\left(\frac{w + (k+1)d}{w+b+nd}\right)^2 + (1-X_{n-1})\left(\frac{w + kd}{w+b+nd}\right)^2 $$
通过扩展和替换：
$$ \left(\frac{w + (k+1)d}{w+b+nd}\right)^2 = \frac{w^2 + 2w(k+1)d + ((k+1)d)^2}{(w+b+nd)^2} $$
$$ \left(\frac{w + kd}{w+b+nd}\right)^2 = \frac{w^2 + 2wkd + (kd)^2}{(w+b+nd)^2} $$
$$ E[X_n^2|X_{n-1}] = X_{n-1}\frac{w^2 + 2w(k+1)d + ((k+1)d)^2}{(w+b+nd)^2} + (1-X_{n-1})\frac{w^2 + 2wkd + (kd)^2}{(w+b+nd)^2} $$
我尝试扩展再次：
$$ \begin{align*}
E[X_n^2|X_{n-1}] &amp;= \frac{X_{n-1}(w^2 + 2w(k+1)d + ((k+1)d)^2)}{(w+b+nd)^2} + \frac{(1-X_{n-1})(w^2 + 2wkd + (kd)^2)}{(w+b+nd)^2} \\
&amp;= \frac{w^2 + 2wkd + (kd)^2}{(w+b+nd)^2} + X_{n-1}\frac{2wd + 2d^2(k+1)}{(w+b+nd)^2}
\end{align*} $$
我知道我需要再次计算期望，这样 $E(E[X_n^2|X_{n-1}]) = E[X_n^2]$
但这就是我陷入困境的地方，不知道如何继续。我感觉自己在兜圈子。有什么想法可以继续吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658243/finding-the-variance-of-a-stochastic-process</guid>
      <pubDate>Wed, 04 Dec 2024 02:04:46 GMT</pubDate>
    </item>
    <item>
      <title>当系数 < 1 时，解释对数转换结果回归中的指数系数</title>
      <link>https://stats.stackexchange.com/questions/658242/interpreting-an-exponentiated-coefficient-from-a-regression-of-a-log-transformed</link>
      <description><![CDATA[网上有很多资料（请参阅此处和此处），关于对结果进行对数变换时该做什么（指数回归系数）以及如何解释系数（1-系数*100 = 预测变量一个单位变化的百分比变化/差异）。
我无法找到如何解释小于 1 的系数。如果它是来自二项回归中，指数对数几率系数例如 0.57 表示 (1-0.57)/0.57 = 0.75 = 预测变量每增加 1 个单位，结果几率就会降低 75%。
我的问题是 我可以用同样的方式解释对数转换结果的回归系数吗？ 0.57 的系数是否也表示预测变量水平下降了 75%。]]></description>
      <guid>https://stats.stackexchange.com/questions/658242/interpreting-an-exponentiated-coefficient-from-a-regression-of-a-log-transformed</guid>
      <pubDate>Wed, 04 Dec 2024 01:59:24 GMT</pubDate>
    </item>
    <item>
      <title>三个相关伯努利随机变量之和的分布，所有变量均具有相同的相关性</title>
      <link>https://stats.stackexchange.com/questions/658241/the-distribution-of-the-sum-of-three-dependent-bernoulli-random-variables-all-w</link>
      <description><![CDATA[$\mathbb{P}(X+Y+Z=z)=\text{?}$
$X,Y,Z\sim \text{Bernoulli}(p)$，并且 $\text{Cor}(X,Y)=\text{Cor}(X,Z)=\text{Cor}(Y,Z)=\rho~, 0&lt;\rho&lt;1$。]]></description>
      <guid>https://stats.stackexchange.com/questions/658241/the-distribution-of-the-sum-of-three-dependent-bernoulli-random-variables-all-w</guid>
      <pubDate>Wed, 04 Dec 2024 01:41:00 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制 sem() 的结果？</title>
      <link>https://stats.stackexchange.com/questions/658240/how-to-plot-results-from-sem</link>
      <description><![CDATA[我使用 lavaan 包中的 sem() 函数建立了以下 SEM 模型。
这是我的 SEM 代码：
sem.model &lt;- &#39;
#潜在变量
latent_edu =~ 教育

#观察变量
latent_edu ~ Sexuality_Straight + Racialized_Minority + Age.in.years + Gender_Women + Gender_Minority

Recruit_Online ~ latent_edu + Age.in.years + Sexuality_Straight + Income

Income ~ Gender_Women + Gender_Minority + Sexuality_Straight + Age.in.years + Racialized_Minority

Aware_Yes ~ Age.in.years + Recruit_Online + Sexuality_Straight + Racialized_Minority

Test_Yes ~ Age.in.years + Recruit_Online + Sexuality_Straight + Racialized_Minority

#Covariances
Gender_Women ~~ Sexuality_Straight
Gender_Minority ~~ Sexuality_Straight
Sexuality_Straight ~~ Racialized_Minority

&#39;
fit &lt;- sem(sem.model, data = imputed_data, ordered = c(&quot;Education&quot;, &quot;Income&quot;))
summary(fit)

当我尝试使用 semPaths() 函数绘制上述方程时，出现以下错误：
&gt; semPlot::semPaths(fit, what = &quot;path&quot;, layout = &quot;tree&quot;)
dimnames(x) 中的错误 &lt;- dn: 
&#39;dimnames&#39; [2] 的长度不等于数组范围

这是我的数据结构：
 $ Income : num 5 5 2 1 2 5 4 1 2 5 ...
$ Age.in.years : int 43 39 27 30 24 25 28 34 28 38 ...
$ Education : num 3 3 3 2 3 3 3 2 2 3 ...
$ Racialized_Minority : num 0 0 1 0 0 0 1 0 0 1 ...
$ White : num 1 1 0 1 1 1 0 1 1 0 ...
$ Recruit_Online ：数量 0 0 0 0 0 0 0 0 0 0 ...
$ Recruit_InPersonPaper ：数量 1 1 1 1 1 1 1 1 1 1 ...
$ Gender_Men ：数量 1 0 0 0 1 0 0 0 0 0 ...
$ Gender_Women ：数量 0 1 1 1 0 1 1 0 0 1 ...
$ Gender_Minority ：数量 0 0 0 0 0 0 0 1 1 0 ...
$ Sexuality_Straight ：数量 1 0 1 0 0 0 1 0 0 1 ...
$ Sexuality_Minority ：数量 0 1 0 1 1 1 0 1 1 0 ...
$ Aware_Yes : num 0 0 1 0 1 0 0 1 1 1 ...
$ Aware_No : num 1 1 0 1 0 1 1 0 0 0 ...
$ Test_Yes : num 0 0 0 0 0 0 0 1 1 0 ...
$ Test_No : num 1 1 1 1 1 1 1 1 0 0 1 ...

我不知道是什么原因导致了这个错误，我正在寻找导致它发生的指导。 sem() 工作正常，并且计算系数没有错误，所以当 semPaths() 抛出这个错误时，我不知道为什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/658240/how-to-plot-results-from-sem</guid>
      <pubDate>Wed, 04 Dec 2024 00:21:07 GMT</pubDate>
    </item>
    <item>
      <title>UMAP、t-SNE 或 PCA 我该选择哪一个？</title>
      <link>https://stats.stackexchange.com/questions/658239/umap-t-sne-or-pca-which-do-i-choose</link>
      <description><![CDATA[我有从健康和患病植物样本（包括玉米、水稻和小麦）中获得的约 64 个基因（列）的微阵列数据。对于某些基因，数据分布在样本之间有所不同，要么呈正态分布（例如，健康玉米中的基因 1），要么呈非正态分布（例如，患病玉米中的基因 1）。哪种降维算法最适合识别区分植物的基因？PCA、UMAP 还是 t-SNE？我知道 PCA 适用于正态分布，而 t-SNE 可以处理非参数数据，但如果是混合数据，t-SNE 可以应用吗？UMAP 呢？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658239/umap-t-sne-or-pca-which-do-i-choose</guid>
      <pubDate>Wed, 04 Dec 2024 00:04:53 GMT</pubDate>
    </item>
    <item>
      <title>探索逻辑回归中的所有选项</title>
      <link>https://stats.stackexchange.com/questions/658233/exploring-all-options-in-a-logistic-regression</link>
      <description><![CDATA[这组代码相当简单，使用了在线教程中的一些示例
# 导入并重命名数据集
library(kmed)
dat &lt;- heart
library(dplyr)

# 重命名变量
dat &lt;- dat |&gt;
重命名（
胸痛 = cp，
最大心率 = thalach，
心脏病 = 类
）

# 重新编码性别
dat$sex &lt;- factor(dat$sex，
levels = c(FALSE, TRUE)，
labels = c(&quot;female&quot;, &quot;male&quot;)
)

# 重新编码胸痛
dat$chest_pain &lt;- factor(dat$chest_pain，
levels = 1:4，
labels = c(&quot;典型心绞痛&quot;, &quot;非典型心绞痛&quot;, &quot;非心绞痛&quot;, &quot;无症状&quot;)
)

# 将心脏病重新编码为 2 个类别
dat$heart_disease &lt;- ifelse(dat$heart_disease == 0,
0,
1
)

m3 &lt;- glm(heart_disease ~ .,
data = dat,
family = &quot;binomial&quot;
)

# 打印结果
summary(m3)

但是，如果我想自动运行 dat 中所有列的预测变量，或者自动寻找最高的 AIC 模型，我应该用什么呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/658233/exploring-all-options-in-a-logistic-regression</guid>
      <pubDate>Tue, 03 Dec 2024 21:08:08 GMT</pubDate>
    </item>
    <item>
      <title>哪个伪 R 平方值最适合 GLS 模型？</title>
      <link>https://stats.stackexchange.com/questions/658232/which-pseudo-r-squared-value-is-best-for-gls-models</link>
      <description><![CDATA[我需要帮助来理解一些统计数据。我是初学者。
我应用了 GLS 模型（具有空间相关结构，例如 CorExp）。对于我的 GLS 模型，我使用 R 中的 nagelkerke 函数计算了伪 R 平方值。此函数生成三种类型的伪 R 平方值：1. McFadden，2. Cox 和 Snell (ML)，3. Nagelkerke (Cragg 和 Uhler)。
这些值中的每一个在我的结果中都有很大的不同。我不知道哪一个最适合在 GLS 模型的特定环境中使用（以及我应该在结果中报告哪一个）。
感谢您的阅读，
L。]]></description>
      <guid>https://stats.stackexchange.com/questions/658232/which-pseudo-r-squared-value-is-best-for-gls-models</guid>
      <pubDate>Tue, 03 Dec 2024 20:28:26 GMT</pubDate>
    </item>
    <item>
      <title>给定许多图游走的总成本，如何估算每条边的成本？</title>
      <link>https://stats.stackexchange.com/questions/658217/given-the-total-cost-of-many-graph-walks-how-to-estimate-the-cost-of-each-edge</link>
      <description><![CDATA[我有一个实际问题，其中我有一个节点及其边的集合。这个集合由数百个节点和数千个连接组成。然后我有大约 10 K 个数据点，每个数据点代表此图中采用的一条路径和每条路径的总成本（每条路径中经过的边的成本总和）。我正在寻找一个函数，给定路径，估算每条边的成本。
现实世界的情况有点复杂，因为模型需要考虑其他特征，例如一天中的时间，以及每个节点的输入/输出，所以我猜它需要一些强化学习管道，但任何时候的任务主要取决于我上面定义的算法，而且它看起来相当简单。
这个问题容易解决吗？文献中是否有任何算法可以解决它？因为我在整整一天的研究中都没有找到一个。]]></description>
      <guid>https://stats.stackexchange.com/questions/658217/given-the-total-cost-of-many-graph-walks-how-to-estimate-the-cost-of-each-edge</guid>
      <pubDate>Tue, 03 Dec 2024 15:58:08 GMT</pubDate>
    </item>
    <item>
      <title>统计/概率瓮模型在课堂之外还有其他应用吗？</title>
      <link>https://stats.stackexchange.com/questions/658212/do-statistical-probability-urn-models-have-any-applications-beyond-the-classroom</link>
      <description><![CDATA[我正在学习 Polya Urn 问题（例如 https://en.wikipedia.org/wiki/Urn_problem）。在我看来，这类问题对于教授学生概率非常有用。但我只是想知道这些问题在现实世界中是否有任何应用？
例如，我们学习回归模型，回归模型也用于医学界和经济学。
但这些类型的 Urn 模型是否出现过？我们是否曾经将任何东西建模为瓮？它们是否在其他一些模型的背景中使用（例如：用于从后验分布中抽取样本）？或者它们只是纯粹的理论教学示例？]]></description>
      <guid>https://stats.stackexchange.com/questions/658212/do-statistical-probability-urn-models-have-any-applications-beyond-the-classroom</guid>
      <pubDate>Tue, 03 Dec 2024 14:50:21 GMT</pubDate>
    </item>
    <item>
      <title>解释 A/B 测试结果中的 p 值</title>
      <link>https://stats.stackexchange.com/questions/658204/interpret-p-value-in-a-b-test-results</link>
      <description><![CDATA[我需要解释 A/B 测试结果。因此，我有一个名为 Baseline 的控制队列，还有另外两个名为 NewFTUE 和 AppReopenFS 的队列。
此 AB 测试数据的最大问题是 NewFTUE 的 p 值几乎等于 1，而 AppReopenFS 的 P 值要低得多。
我无法理解两件事：

据我所知，如果平均差异较大且
标准差较小，则 p 值应该变得更小，即零假设应该更容易被拒绝。但我们可以
在这里看到，对于较大的标准差和较小的均值差，p 值要小得多（0.187 vs 0.991）
第二件我无法理解的事情是 95% CI（正如仪表板上所解释的那样，这是“95% 可能包含均值真实差异的值范围”。）。因此，正如您所看到的，对于 NewFTUE，均值差异的置信区间完全位于 0 的左侧。即我们有 95% 的信心，无论我们采用什么样本（对于相同的样本量），与 Baseline 相比，我们都会得到更差的结果。

那么为什么 NewFTUE 的 p 值为 0.991 并且大于 AppReopenFS 的 0.187 值？

编辑：添加以下 p 值的描述：和 这里是文档页面。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658204/interpret-p-value-in-a-b-test-results</guid>
      <pubDate>Tue, 03 Dec 2024 13:44:27 GMT</pubDate>
    </item>
    <item>
      <title>倾向得分匹配：如何决定优先考虑平衡还是样本量</title>
      <link>https://stats.stackexchange.com/questions/657980/propensity-score-matching-how-to-decide-if-prioritise-balance-or-sample-size</link>
      <description><![CDATA[我尝试使用 MatchThem 包以不同的方法（最近或无放回法、最优法、完全法、遗传法）在两组之间执行 PSM。最终，我确定了两个表现良好的模型：一个模型中所有变量都是平衡的，但排除了一些情况；另一个（完整模型）中一个变量略微不平衡，但所有情况都保留。
NEAREST LOGIT
# 在每个插补数据集中执行匹配
m.out_model1 &lt;- matchthem(formula, 
data = new_df_imputed, 
method = &quot;nearest&quot;, 
distance = &quot;logit&quot;,
replace = TRUE,
ratio = 3,
caliper = 0.2)

输出：
所有插补的平衡摘要
Type Max.Diff.Adj M.Threshold
distance Distance 0.0130 Balanced, &lt;0.1
Metastasis_size_at_treatment_mm Contin. 0.0136 平衡，&lt;0.1
Segments_treated_per_session 持续。 0.0336 平衡，&lt;0.1
Metastasis_location_superficial_Yes 二进制 0.0089 平衡，&lt;0.1

平衡平均差异计数
count
平衡，&lt;0.1 4
不平衡，&gt;0.1 0

具有最大平均差异的变量
Variable Max.Diff.Adj M.Threshold
Segments_treated_per_session 0.0336 平衡，&lt;0.1

插补的平均样本大小
0 1
全部 53. 77
匹配（ESS） 26.96 75
匹配（未加权） 45. 75
不匹配 8. 2

完整方法
m.out_full &lt;- matchthem(formula,
data = new_df_imputed,
method = &quot;full&quot;,
distance = &quot;mahalanobis&quot;)

输出：
所有插补的平衡摘要
类型 Max.Diff.Adj M.Threshold
Metastasis_size_at_treatment_mm Contin. 0.0477 平衡，&lt;0.1
Segments_treated_per_session Contin. 0.1179 不平衡，&gt;0.1
Metastasis_location_superficial_Yes 二进制 0.0260 平衡，&lt;0.1

平衡平均差异计数
count
平衡，&lt;0.1 2
不平衡，&gt;0.1 1

具有最大平均差异的变量
Variable Max.Diff.Adj M.Threshold
Segments_treated_per_session 0.1179 不平衡，&gt;0.1

插补的平均样本大小
0 1
全部 53. 77
匹配（ESS） 27.47 77
匹配（未加权） 53. 77

如果我使用第一个模型，我会失去能力（而且我的队列已经很小）。另一方面，选择第二个模型允许我保留整个人群，但这两个群体略微不平衡。但是，我可以通过多变量逻辑回归中包含不平衡变量来解释这一点。
我的问题是：有没有办法确定哪个模型是最佳选择？计算与每个匹配数据集相关的功效以评估使用哪个模型在方法论上是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/657980/propensity-score-matching-how-to-decide-if-prioritise-balance-or-sample-size</guid>
      <pubDate>Thu, 28 Nov 2024 13:21:04 GMT</pubDate>
    </item>
    <item>
      <title>数字列表的百分位数</title>
      <link>https://stats.stackexchange.com/questions/613336/percentile-of-list-of-numbers</link>
      <description><![CDATA[假设我有一个数字列表，例如 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]。这些数字是随机变量 $X$ 的实现，我对它的分布感兴趣。
假设我想估计此分布的第 5 个百分位数（以形成 $X$ 的置信区间）。直观地讲，我会取最小的数字（即 1）作为我的估计值，因为 90% 的数字高于这个数字，而 0% 低于这个数字（在某种意义上“平均”为所需的 5%！）但是，当我使用 numpy.percentile（使用默认设置）时，它建议的估计值为 1.45。哪个估计更好，为什么？
更新：澄清一下，我的目标是估计区间 $I=[x,y]$，其中 $y &gt; x$，使得 $\mathbb{P}(X \in I)=0.95$。数字 $x$ 和 $y$ 分别是 $X$ 分布的第 5 个百分位数和第 95 个百分位数。]]></description>
      <guid>https://stats.stackexchange.com/questions/613336/percentile-of-list-of-numbers</guid>
      <pubDate>Tue, 18 Apr 2023 13:57:24 GMT</pubDate>
    </item>
    </channel>
</rss>