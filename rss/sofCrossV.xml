<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 15 Oct 2024 15:18:40 GMT</lastBuildDate>
    <item>
      <title>对于 X 连续随机变量和 $Y=X^{-1}$，如何推导出 $(X,Y)$ 的 Copula？</title>
      <link>https://stats.stackexchange.com/questions/655808/how-to-derive-the-copula-of-x-y-for-x-continuous-random-variable-and-y-x</link>
      <description><![CDATA[我在考试中没有解决它们，我仍然无法弄清楚如何正确解决它。

对于$X\sim U(-1,1)$和$Y=\frac{1}{X}$，推导出$(X,Y)$的Copula，以及它的唯一性是什么。
对于$X\sim N(0,1)$和$Y=\frac{1}{X}$，推导出$(X,Y)$的Copula。

在这两种情况下，我们的$X$ 是连续的，可以取 $0$ 作为其值，而 Y 不连续似乎是一个问题。不能直接使用公式
$$C(u_1,\dots,u_d)=F(F_1^{-1}(u_1),\dots,F_d^{-1}(u_d)) $$
其中 $F$ 是 $d$ 维的。具有连续边际 c.d.f.s $F_i$ 和 C 的分布函数由该公式唯一确定。
但是我不知道如何处理 $X$ 取值 $0$ 且 $Y=\frac{1}{0}$ 的情况。
我想知道我们是否可以构造函数 $f(x)=x$ 非递减和 $g(x)=\frac{1}{x}$ 非递增，使得 $(X,Y)=(f(X),g(X))$ 在分布中，然后使用反单调性 Copula，但没有奏效。
有人能提示一下或者指出我理解错误的地方吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655808/how-to-derive-the-copula-of-x-y-for-x-continuous-random-variable-and-y-x</guid>
      <pubDate>Tue, 15 Oct 2024 14:20:38 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程的相关性</title>
      <link>https://stats.stackexchange.com/questions/655807/correlation-of-gaussian-processes</link>
      <description><![CDATA[假设我使用高斯过程生成 n 个长度为 T 的序列 $\{X_1, X_2, X_3,X_4,\cdots,X_n\}$。这相当于从维度为 T 的多元高斯分布中采样 n 个点。

如果我使用此定义找到任意两个序列之间的互相关，它应该与组件之间的相关性相同。例如，在时间步骤 i 和 j 之间，相关性只是协方差矩阵中的 $\Sigma_{i,j}$ 个元素除以 $\sqrt(\Sigma_{ii}\Sigma_{jj})$
如果我将其转换为从多元高斯分布中采样维度为 nT 的点，该分布的协方差矩阵只是块对角矩阵，每个块都是原始协方差矩阵（即 $\Sigma_{nT \times nT} = diag(\Sigma, \Sigma,\cdots \text{n times})$。如何使用这种构造来找到相关值？

我在某个地方犯了一个严重的错误，我不知道我错在哪里。如果有人能指出来，我将不胜感激出。]]></description>
      <guid>https://stats.stackexchange.com/questions/655807/correlation-of-gaussian-processes</guid>
      <pubDate>Tue, 15 Oct 2024 14:04:20 GMT</pubDate>
    </item>
    <item>
      <title>如果分类变量保留在 R 中的最终模型中，那么为什么事后分析表明水平没有差异？</title>
      <link>https://stats.stackexchange.com/questions/655810/if-the-categorical-variable-is-retained-in-my-final-model-in-r-then-why-does-th</link>
      <description><![CDATA[我正在使用 R 中的 anova() 函数进行模型选择，并且我的分类变量在我的最终模型中得到了保留，但是当我使用 emmeans() 函数进行事后分析时，它告诉我水平没有差异。这是什么意思？
我使用 R 软件，我正在研究一种鱼的身体状况在三种河流中的变化：保护性、轻微城市化和高度城市化。每个类别都有一个重复，这意味着我有 2 条保护性河流、2 条轻微城市化河流和 2 条高度城市化河流，这意味着“河流”是一个随机因素，“城市化类别”是我的固定因素和具有 3 个级别的预测变量。在使用 anova() 函数在 R 中执行模型选择时，分类变量“类别”得到保留：
`#它是一个线性混合模型，因为条件呈正态分布
&gt; lmm.1 &lt;- lmer(条件 ~ 城市化类别 + (1|河流), 数据 = 鱼) 
&gt; lmm.null &lt;- lmer(条件 ~ 1 + (1|河流), 数据 = 鱼) 
&gt; anova(lmm.null, lmm.1)
使用 ML（而不是 REML）重新拟合模型
数据：鱼
模型：
lmm.null：条件 ~ 1 + (1 | 河流)
lmm.1：条件 ~ 城市化类别 + (1 | 河流)
npar AIC BIC logLik 偏差 Chisq Df Pr(&gt;Chisq)
lmm.null 3 -214.42 -205.37 110.21 -220.42
lmm.1 5 -219.80 -204.71 114.90 -229.80 9.3806 2 0.009184 **
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1`

`
我的 p 值为 0.009184，这意味着城市化类别是一个重要的预测因素，我预计分类变量中至少有一个级别与其他级别不同。但是，在尝试进行事后分析时，我调用了 emmeans() 函数，R 表示所有级别均无差异，因为 p 值均高于 0.05：
`&gt; emmeans(lmm.1，成对 ~ category.of.urbanization)
已注册的 S3 方法被“broom”覆盖：
方法来自 
tidy.glht jtools
tidy.summary.glht jtools
$emmeans
category.of.urbanization emmean SE df lower.CL upper.CL
保留 -0.1281 0.0441 3.42 -0.2592 0.00304
略微城市化 0.0316 0.0341 2.20 -0.1030 0.16632
非常城市化 0.0425 0.0350 2.43 -0.0852 0.17032

自由度方法：kenward-roger
使用的置信度：0.95

$contrasts
对比估计 SE df t.ratio p.value
保留 - 略带城市化 -0.1597 0.0558 2.83 -2.863 0.1324
保留 - 非常城市化 -0.1706 0.0563 2.95 -3.028 0.1123
略带城市化 - 非常城市化 -0.0109 0.0489 2.32 -0.223 0.9733

自由度方法：kenward-roger
P 值调整：用于比较 3 个估计值的 Tukey 方法`

请问，这是什么意思？预测变量如何显著，但水平没有差异？我有 151 条鱼，所以我的数据和观察值数量不是很低。如果我犯了拼写错误，我很抱歉，英语不是我的母语。]]></description>
      <guid>https://stats.stackexchange.com/questions/655810/if-the-categorical-variable-is-retained-in-my-final-model-in-r-then-why-does-th</guid>
      <pubDate>Tue, 15 Oct 2024 13:48:27 GMT</pubDate>
    </item>
    <item>
      <title>如何使用去偏套索处理不平衡数据的混合效应模型中的单一观测？</title>
      <link>https://stats.stackexchange.com/questions/655806/how-to-handle-single-observations-in-mixed-effects-modeling-with-debiased-lasso</link>
      <description><![CDATA[我有一个从数百名具有不同临床状况的人那里收集的样本数据集。该数据集非常不平衡。例如，样本数量因受试者而异。整个数据集的约 20% 由单个样本组成。5% 由 2 个样本组成，其余由 3 到 15 个样本组成。还有与这些样本相对应的微生物组数据。
我对研究微生物组的中介效应很感兴趣。
由于微生物组数据是高维的，我想使用套索正则化技术来处理多重共线性。我计划使用去偏套索来消除套索估计中的偏差。我也有来自个人的多个观察结果，因此我将使用混合效应模型，将个人的 ID 作为随机效应。
我的问题是：由于我将在中介分析中使用模型的结果，我应该如何处理来自个人的单个观察结果，以便它们继续对整体模型做出贡献？]]></description>
      <guid>https://stats.stackexchange.com/questions/655806/how-to-handle-single-observations-in-mixed-effects-modeling-with-debiased-lasso</guid>
      <pubDate>Tue, 15 Oct 2024 13:35:20 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归与线性回归中省略的变量偏差[重复]</title>
      <link>https://stats.stackexchange.com/questions/655805/omitted-variable-bias-in-poisson-vs-linear-regression</link>
      <description><![CDATA[我正在研究泊松模型，其中真实关系是：
$$E(y \mid x,z)=exp(b x+cx \times z+f(x))$$
其中 x 和 z 是独立变量，f(x) 是 x 的某个确定性非线性函数（具体而言，$f(x)=\log(\Phi(kx))$，$\Phi()$ 标准正态分布 CDF）。
我认为省略 f(x) 不会对类似线性模型中交互项的估计系数造成偏差
$$E(y \mid x,z)=b x+cx \times z+f(x)$$
因为$x \times z$无法解释$f(x)$的变化，而$x$无法解释这种变化。
然而，模拟表明，交互系数的估计在泊松回归中是不一致的。您能否提供一些见解来解释为什么会出现这种情况？
（此处提出了一个相关问题，但考虑到确定性函数，我认为它不应该是答案的核心。
更详细地说，我相信链接的答案强烈表明$b$系数的估计将不一致，但它并没有解释为什么$c$可能不一致。上面我论证了在类似的 OLS 情况下$c$可能会被一致地估计，因此泊松的一些额外属性可能是造成这种情况的原因，而链接的答案并未讨论这一点。）]]></description>
      <guid>https://stats.stackexchange.com/questions/655805/omitted-variable-bias-in-poisson-vs-linear-regression</guid>
      <pubDate>Tue, 15 Oct 2024 12:26:51 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost - 预测多个时间范围</title>
      <link>https://stats.stackexchange.com/questions/655804/xgboost-predict-multiple-time-horizons</link>
      <description><![CDATA[我需要帮助来理解如何对 h 未来一段时间进行预测，特别是这会如何影响我的特征创建和目标。
我有每周销售数据，最初的计划是预测下周的销量。目标是每位客户每周订购的总销量。我使用短期和长期滞后 [1,2,3,4,15,20,25,30]，计算滚动统计数据和许多其他特征。每个特征都偏移 1 周，这样我就不会引入数据泄漏，因此为了预测 t 周的目标，我的所有特征都计算为 t - 1。现在我的要求发生了变化，我需要提前 4 周和 6 周进行预测。我的问题是：

我现在预测的目标是t + h
我需要调整特征计算方式吗？
我是否需要为每个视界h创建单独的数据集并进行特征计算
]]></description>
      <guid>https://stats.stackexchange.com/questions/655804/xgboost-predict-multiple-time-horizons</guid>
      <pubDate>Tue, 15 Oct 2024 12:06:44 GMT</pubDate>
    </item>
    <item>
      <title>自动样条回归</title>
      <link>https://stats.stackexchange.com/questions/655803/automated-spline-regression</link>
      <description><![CDATA[由于一些CV成员偶尔会推荐样条回归，我想知道是否有一种自动算法来选择要应用样条的变量以及节点的数量和位置。类似于分段回归或随机森林的 CART 算法。
我读过 Frank Harrell 的“回归建模策略”一章，其中包含一些经验法则并建议使用 AIC 自动选择节点数，但我的印象是它适用于统计学家将其偏见建模到分析中的程序。当然，这是一种有效的方法，但它似乎只适用于具有少量变量的数据，这些变量要么是事先选择的（由于某些专家的偏见），要么是经过某种变量选择算法选择的。
是否有一些严格的样条回归算法，有人将其与 CART 或随机森林进行了比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/655803/automated-spline-regression</guid>
      <pubDate>Tue, 15 Oct 2024 11:33:52 GMT</pubDate>
    </item>
    <item>
      <title>心血管疾病患者中的肥胖悖论可以通过错误控制介质来解释吗？</title>
      <link>https://stats.stackexchange.com/questions/655736/can-obesity-paradox-among-subjects-with-cardiovascular-disease-be-explained-by-i</link>
      <description><![CDATA[鉴于以下因果关系图：
肥胖 -&gt; 心血管疾病 -&gt; 死亡率
肥胖是心血管疾病 (CVD) 的致病因素，那么得出这样的结论是否合理：由于 CVD 是介质，因此对患有 CVD 的受试者进行条件反射会导致治疗效果估计出现偏差？
这可能无法完全解释偏差，但我认为可以解释其中很大一部分。]]></description>
      <guid>https://stats.stackexchange.com/questions/655736/can-obesity-paradox-among-subjects-with-cardiovascular-disease-be-explained-by-i</guid>
      <pubDate>Mon, 14 Oct 2024 00:10:16 GMT</pubDate>
    </item>
    <item>
      <title>比较不同重叠组中两个变量的相关性</title>
      <link>https://stats.stackexchange.com/questions/655573/comparing-correlations-for-two-variables-in-different-overlapping-groups</link>
      <description><![CDATA[我有一个样本，其中我为同一种疾病应用了五种（差异很大）诊断定义。例如，50% 的诊断定义 1 下的患病病例不是诊断定义 2 下的患病病例，而 10% 的符合定义 2 的病例不是定义 1 下的病例。定义 1 是目前使用最广泛的“标准”，所有其他定义都将与定义 1 进行比较。
我想比较针对每个人测量的两个变量之间的相关性（称为 X 和 Y），看看定义 1 下的患病病例的 cor(X,Y) 是否与定义 2 下的患病病例的 cor(X,Y) 不同（请记住，有些人同时符合两个定义，并将同时属于两个组）。我想要用几对变量来做这个 - 根据具体变量，我可能会使用 Pearson、Spearman 或四分法相关系数。
将样本限制为“符合五个诊断定义中至少一个的人”后我的样本量约为 80,000，所有诊断定义至少产生 30,000 个病例。
我首先想到的方法是使用引导法：

使用“至少符合一个诊断定义的 80,000 人”的整个样本进行替换抽样。
对于五个诊断定义中的每一个，使用符合该定义的引导样本中的观测值计算 cor(X,Y)。
对得到的相关性使用 Fisher 变换，这样减法就合适了。
对于诊断定义 2-5 中的每一个，从定义 1 病例的相关性中减去该组的相关性。 （使用当前引导迭代中的 Fisher 变换相关性。）
重复步骤 1-4 数千次。
取 min(差异百分比 &gt; 0,差异百分比 &lt; 0)，并将该数字乘以 2，得到双尾检验，以确定相关性之间的差异是否不等于 0。

此过程合适吗？它会做我想做的事情吗（测试相关性的差异，同时考虑产生相关性的两个组之间的重叠）？我是否应该考虑使用其他方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655573/comparing-correlations-for-two-variables-in-different-overlapping-groups</guid>
      <pubDate>Wed, 09 Oct 2024 22:02:40 GMT</pubDate>
    </item>
    <item>
      <title>DHARMa 残差模式</title>
      <link>https://stats.stackexchange.com/questions/655401/dharma-residual-pattern</link>
      <description><![CDATA[我正在尝试使用具有 beta 分布的 glmmTMB 来建模行为（如另一篇文章中所建议的那样）。我的模型由几个固定因素和两个随机效应（物种和个体）组成。我已经通过使用以下方法转换因变量解决了 0-1 问题：
参考文献：Smithson, M., &amp; Verkuilen, J. 更好的柠檬榨汁机？具有 beta 分布因变量的最大似然回归。心理学方法，11，54–71（2006 年）。DOI：10.1037/1082-989X.11.1.54
在使用 DHARMa 检查残差后，我注意到以下模式。我正在建模几种行为，并为每种行为获得类似的模式。我还对二分变量运行了二项式 GLMM，没有遇到任何问题。

我的问题是：

我该如何解决残差中的这些模式？
我对图的解释正确吗？根据我的理解，该模型低估了低预测值的残差，而高估了高预测值的残差，这意味着它无法准确地模拟因变量的低值和高值。我是对的，还是我完全误解了这一点？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655401/dharma-residual-pattern</guid>
      <pubDate>Sun, 06 Oct 2024 15:30:48 GMT</pubDate>
    </item>
    <item>
      <title>建模干预前/后纵向数据</title>
      <link>https://stats.stackexchange.com/questions/649438/modelling-longitudinal-pre-post-intervention-data</link>
      <description><![CDATA[我拥有一些患者的纵向数据，在治疗前几年和治疗后较短的一段时间（几个月）内，以不定期的时间间隔测量了一些生物标志物。我感兴趣的是找出治疗前和治疗后阶段的生物标志物进展率（斜率）是否存在显著差异
我目前的方法包括一个单一的线性混合效应模型，该模型考虑了数据的基本层次结构（每个患者、每只眼睛的估计值），适用于两个时间段（治疗前/治疗后），由二元变量“pre_Treatment”表示。通过这样做，我对结果的解释是，变量“时间”的估计值代表生物标志物治疗前的变化率（或斜率）（因为这是参考），而时间和治疗前相互作用分别给出了治疗前到治疗后斜率变化的估计值：
lmer(Biomarker ~ Time:(pre_Treatment) + Time:(post_Treatment) + 
(Time*pre_Treatment| PatientID:Laterality) + 
(Time*post_Treatment| PatientID:Laterality)

这个框架似乎非常适合对这种情况进行建模，但我注意到人们通常还使用两个单独的模型，一个用于估计治疗前的斜率，另一个用于对治疗后的斜率进行建模。

这种建模方法有什么缺点我应该注意吗/还有什么我应该注意的吗合并？
是否有充分的理由说明为什么两个模型都很好/足够好，或者将两者整合到一个模型中是正确的做法？
是否有一些普遍接受的“黄金标准”方法来处理这种情况？


一个主要问题是我的数据集不平衡，因为虽然我在治疗前有长达 5 年的随访，但治疗后的随访却少得多。在某些情况下只有两个数据点。这最初是我选择混合模型的原因，因为它允许从同一分布中得出斜率，从而可以使用来自所有患者/眼睛的信息来改进每个患者/眼睛的参数估计。
但是，我注意到每个治疗阶段（治疗前和治疗后）斜率的两个分布可能也会相互影响。由于我有更多的治疗前随访数据，因此治疗后阶段的斜率估计受到了影响。具体来说，与我在两个单独的混合模型（一个用于治疗前，一个用于治疗后阶段）中分别估计两个斜率相比，治疗后的斜率与治疗前的斜率更相似。]]></description>
      <guid>https://stats.stackexchange.com/questions/649438/modelling-longitudinal-pre-post-intervention-data</guid>
      <pubDate>Tue, 18 Jun 2024 10:49:17 GMT</pubDate>
    </item>
    <item>
      <title>观察 X 变化和 Y 变化之间的关联的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/647687/what-is-the-best-approach-to-look-at-association-between-change-in-x-and-change</link>
      <description><![CDATA[通过两次同步重复测量分析两个变量变化之间的关联，正确的方法是什么？
我计算了变量 X 和 Y 的增量变化分数，两次测量一次，一次在基线，然后 1 年后再次测量（例如，ΔX = X_year1 - X_baseline 和 ΔY = Y_year1 - Y_baseline），然后查看这些变化分数之间的相关性。但是，我的结果显示的关联与我的假设相反。我怀疑回归均值可能会影响我的结果，但我没有找到太多关于这种影响如何影响两个变量变化之间关联的信息。
更好的方法是使用线性模型的残差来计算“变化”，例如 X_year1 ~ X_baseline。这种方法还允许我通过将协变量添加到线性模型中来调整协变量。
具体问题：

回归均值如何影响变化分数之间的相关性？
使用线性模型的残差（例如，X_time2 ~ X_time1）是分析变量变化的更合适方法吗？
在控制基线值和潜在协变量的同时，还有哪些其他推荐方法可以准确评估两个变量变化之间的关联？
如果有三个时间点而不是两个时间点，正确的方法是否会改变？

任何想法或相关文献的引用都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/647687/what-is-the-best-approach-to-look-at-association-between-change-in-x-and-change</guid>
      <pubDate>Tue, 21 May 2024 12:02:45 GMT</pubDate>
    </item>
    <item>
      <title>当基线值不一致时，干预研究中相互作用（时间 x 干预）的解释</title>
      <link>https://stats.stackexchange.com/questions/629262/interpretation-of-interaction-time-x-intervention-in-an-intervention-study-whe</link>
      <description><![CDATA[我偶然发现了一项干预研究，该研究测量了特定治疗组的显著下降。但是起始条件并不相同，并且类似于*：

因此，a 组和 b 组之间存在差异，但在干预之前，两组之间存在差异。
我认为这种交互“效应”可能类似于回归均值，并且假设零假设为真，当起始条件不同时，更有可能观察到效应（因为变化与起始条件相关，因此起始值越高，下降的可能性就越大）。
因此，我基于所有四个组都相同的零假设，为 2x2 设计模拟了一万个数据集。我计算了两个 t 检验的 p 值。

一个表示起始条件的差异。
一个表示时间点 $0$ 和 $1$ 之间变化的差异。

我创建了一个散点图，以第一个 t 检验的 p 值为条件，表示第二个 t 检验的 p 值（我使用了第二个 t 检验的平均值，以第一个 t 检验的分箱 p 值为条件）。

并且看来，我们观察到的交互效应 p 值较低，而起始条件的 t 检验的 p 值已经很低了。
如果起始条件不同，那么我们更有可能观察到显著的交互效应（假设零假设为真）。
问题：是否有方法（除了在分配治疗/干预措施时确保起始条件相等外）可以纠正这种回归均值现象？是否有假设检验等分析类型的例子可以解释这种影响？例如，贝叶斯方法可能不太受起始条件差异的影响？

*：此处的示例经过简化。具体数据和研究来自 Trouwborst 等人的研究 &quot;饮食干预后心脏代谢健康的改善是由组织特异性胰岛素抵抗表型驱动的：精准营养试验&quot; 的补充信息中的图 2S 和 3S。 al.
**: 图像代码
set.seed(1)

sim = function(n=10) {
y0a = rnorm(n,2)
y0b = rnorm(n,2)
y1a = rnorm(n,2)
y1b = rnorm(n,2)

p_start = t.test(y0a,y0b)$p.value
p_exp = t.test(y1a-y0a,y1b-y0b)$p.value

return(c(p_start, p_exp))
}

p = replicate(10^4,sim())

pc = seq(0,1,0.05)
k = length(pc)-1 ### 数量箱
conditional_p = rep(0,k)
p_condition = (pc[-1]+pc[-(k+1)])/2

for (ki in 1:k) {
sel = which((p[1,]&gt;pc[ki])*(p[1,]&lt;pc[ki+1]) == 1)
conditional_p[ki] = mean(p[2,sel])
}

plot(p_condition, conditional_p, 
main = &quot;模拟 10 000 项干预研究&quot;,
xlab = &quot;起始条件 t 检验的 p 值&quot;,
ylab = &quot;干预 t 检验的 p 值&quot; )

### 交叉效应描述 
plot(c(0,1,0,1),c(1,1,1.2,1.01), pch=20, col = c(1,1,2,2), xaxt=&quot;n&quot;,
ylim = c(0,1.5), xlab = &quot;time&quot;,
ylab = &quot;value of interest&quot;)
lines(c(0,1),c(1,1))
lines(c(0,1),c(1.2,1.01), col = 2)
axis(1,at =c(0,1))

text(0.5,1.1, &quot;group B&quot;, col = 2, pos = 3)
text(0.5,1, &quot;group A&quot;, col = 1, pos = 1)
]]></description>
      <guid>https://stats.stackexchange.com/questions/629262/interpretation-of-interaction-time-x-intervention-in-an-intervention-study-whe</guid>
      <pubDate>Fri, 20 Oct 2023 12:59:37 GMT</pubDate>
    </item>
    <item>
      <title>如何估计时间序列数据中的季节性程度？</title>
      <link>https://stats.stackexchange.com/questions/579879/how-do-you-estimate-the-magnitude-of-seasonality-in-time-series-data</link>
      <description><![CDATA[我有一些时间序列数据，显示每月的住院人数。它既有长期趋势（增加），也有季节性（夏季最高）。我正在尝试测量季节性的幅度（即夏季的入学率比冬季高多少？）。
以下是一些示例数据（这是 R 代码）：
ts &lt;- structure(list(year = c(2010L, 2010L, 2010L, 2010L, 2010L, 2010L, 
2010L, 2010L, 2010L, 2010L, 2010L, 2010L, 2010L, 2011L, 2011L, 2011L, 
2011L, 2011L, 2011L, 2011L, 2011L, 2011L, 2011L, 2011L, 2011L, 
2012L, 2012L, 2012L, 2012L, 2012L, 2012L, 2012L, 2012L, 
2012L, 2012L, 2012L, 2013L, 2013L, 2013L, 2013L, 2013L, 
2013L, 2013L, 2013L, 2013L, 2013L, 2013L, 2014L, 2014L, 
2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L), 月份 = 结构(c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L、2L、3L、4L、5L、6L、7L、8L、9L、10L、11L、12L、1L、2L、3L、4L、5L、6L、7L、8L、9L、10L、11L、12L、1L、2L、3L、4L、 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L), .Label = c(&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, 
&quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;), class = &quot;factor&quot;), period = 1:60, N = c(539L, 528L, 584L, 628L, 644L, 670L, 
657L, 680L, 629L, 660L, 614L, 606L、564L、699L、623L、621L、692L、683L、644L、715L、639L、646L、625L、609L、547L、594L、653L、682L、724L、737L、671L、 7L、698L、688L、621L、643L、573L、643L、675L、722L、669L、659L、737L、692L、647L、701L、653L、603L、564L、638L、 657L, 681L, 720L, 713L, 674L, 788L, 
697L, 717L, 680L, 648L)), row.names = c(NA, -60L), class = &quot;data.frame&quot;)

我们可以拟合有或没有季节性的泊松模型，并绘制预测值：
model1 &lt;- glm(N ~ period, family = &#39;poisson&#39;, data = ts)
model2 &lt;- glm(N ~ period + month, family = &#39;poisson&#39;, data = ts)

ts$pred1 &lt;- predict(model1, newdata = ts, type = &#39;response&#39;)
ts$pred2 &lt;-预测（model2，newdata = ts，type = &#39;response&#39;）

plot（1，type = &#39;n&#39;，xlim = c（0，60），ylim = c（0，max（ts$N）* 1.2），xlab = &#39;time&#39;，ylab = NA）
with（ts，{
points（period，N）
lines（period，pred1，col = &#39;blue&#39;）
lines（period，pred2，col = &#39;red&#39;）
})


显然有强有力的季节性证据：
anova(model1, model2, test = &#39;LRT&#39;)

偏差表分析

模型 1：N ~ 周期
模型 2：N ~ 周期 + 月
残差 Df 残差 Df 偏差 Pr(&gt;Chi) 
1 58 202.753 
2 47 62.334 11 140.42 &lt; 2.2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

但是，我们如何衡量这种季节性的幅度（而不是季节性的统计证据或模型的拟合优度）？
我的第一个想法是通过在模型中添加季节性项来计算残差减少的程度，与数据进行比较。
# 计算残差：
ts$resid1 &lt;- ts$pred1 - ts$N
ts$resid2 &lt;- ts$pred2 - ts$N

# 计算与数据相比残差的减少量数据
(sum(abs(ts$resid1)) - sum(abs(ts$resid2))) / sum(ts$N)

这表明此数据存在 2.7% 的季节性。这有意义吗？是否有解决此问题的标准方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/579879/how-do-you-estimate-the-magnitude-of-seasonality-in-time-series-data</guid>
      <pubDate>Fri, 24 Jun 2022 12:16:04 GMT</pubDate>
    </item>
    <item>
      <title>对于排列/随机化/改组在两个群体之间的排列测试中的作用存在分歧</title>
      <link>https://stats.stackexchange.com/questions/561466/disagreement-regarding-the-role-of-permutation-randomization-shuffling-in-permua</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/561466/disagreement-regarding-the-role-of-permutation-randomization-shuffling-in-permua</guid>
      <pubDate>Sat, 22 Jan 2022 14:21:06 GMT</pubDate>
    </item>
    </channel>
</rss>