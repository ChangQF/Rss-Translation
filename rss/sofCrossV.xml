<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 09 Apr 2024 09:14:13 GMT</lastBuildDate>
    <item>
      <title>是否有相当于 Stata 的“ifplot”的 R 命令用于网络元分析？</title>
      <link>https://stats.stackexchange.com/questions/644622/is-there-an-r-command-equivalent-to-statas-ifplot-for-network-meta-analysis</link>
      <description><![CDATA[我正在寻找一种方法来评估 R 网络元分析中的循环不一致性，并使用比较级别的数据。到目前为止，我只找到了“local.ict” “NMA”的命令包（ https://www.ism.ac.jp/~ noma/file/software/NMA.r ），从示例来看，
&lt;块引用&gt;
hf2 &lt;- setup(study=study,trt=trt,d=d,n=n,measure=“OR”,ref=“Placebo”,data=heartfailure)”

需要手臂级别的数据。
我正在寻找的是在Stata中通过“ifplot”执行的： https://www.stata-journal.com/article.html?article=st0411
有没有办法在 R 中获得相同的效果？]]></description>
      <guid>https://stats.stackexchange.com/questions/644622/is-there-an-r-command-equivalent-to-statas-ifplot-for-network-meta-analysis</guid>
      <pubDate>Tue, 09 Apr 2024 09:07:14 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中比较两个列表的元素（就整体相似性和顺序而言）？</title>
      <link>https://stats.stackexchange.com/questions/644619/how-can-i-compare-the-elements-of-two-lists-in-terms-of-overall-similarity-and</link>
      <description><![CDATA[我有一个“实际”前 25 位作者的列表，我想将其与预测的前 25 位作者的列表进行比较（我有 5 次重复的预测列表）。我想根据与“实际”作者相同的预测作者的比例以及列表的顺序来比较实际和预测。最好的方法是什么？
下面的示例数据：
actual_authors &lt;- list(&quot;Tom&quot;, &quot;Dick&quot;, &quot;Harry&quot;, &quot;Edward&quot;, &quot;Fred&quot;)

Predicted_authors &lt;- list(“伊恩”、“利亚姆”、“哈利”、“托比”、“汤姆”)

总体而言，预测列表包含实际列表的 40%，但是我还想查看列表的顺序 - Harry 和 Tom 都在预测列表中，但他们的位置与实际位置不同列表。最好给出平均％相似度（在将实际值与每个预测值进行比较之后）和 p 值。
最好的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644619/how-can-i-compare-the-elements-of-two-lists-in-terms-of-overall-similarity-and</guid>
      <pubDate>Tue, 09 Apr 2024 08:55:32 GMT</pubDate>
    </item>
    <item>
      <title>拟合级别的 ARIMA 模型与 R 中一阶差分的 ARMA 模型时的不同结果</title>
      <link>https://stats.stackexchange.com/questions/644618/different-results-when-fitting-arima-model-for-levels-vs-arma-model-for-first-di</link>
      <description><![CDATA[在下面的代码中，我展示了当对生成的 AR(2) 模型的累积和拟合 ARIMA(2,1,0) 与对 AR(2,0) 拟合 ARMA(2,0) 时，我得到不同的预测（ 2）本身。谁能指出我犯的错误？
库（预测）

# 构建系列
iN = 2000
vAR2 = 代表(NA, iN)
Φ1 = 0.2
Φ2 = 0.3
vAR2[1] = rnorm(1)
vAR2[2] = phi1 * vAR2[1] + rnorm(1)
for(i in 1 : (iN - 2)){
  vAR2[i + 2] = phi1 * vAR2[i + 1] + phi2 * vAR2[i] + rnorm(1)
}
绘图（vAR2，类型=“l”）
vLevels = cumsum(vAR2)
绘图（vLevels，类型=“l”）
  
# 为级别拟合 ARIMA
iMW = iN / 2
iNOut = iN - iMW
vLevelsPred = 代表（NA，长度（vLevels））

for(i in 1 : iNOut){
  oARIMA = arima(x = vLevels[i : (iMW + i - 1)], order = c(2, 1, 0))
  vLevelsPred[iMW + i] = 预测(oARIMA, h = 1)$mean[1]
}

绘图（vLevels，类型=“l”）
行（vLevelsPred，col =“红色”）

# 拟合 ARMA 以获得一阶差分
vAR2Pred = 代表（NA，长度（vAR2））

for(i in 1 : iNOut){
  oARIMAar = arima(x = vAR2[i : (iMW + i - 1)], 阶 = c(2, 0, 0))
  vAR2Pred[iMW + i] = 预测(oARIMAar, h = 1)$mean[1]
}

# 重建关卡
vAR2Pred[iMW] = vLevels[iMW]
vAR2Pred[is.na(vAR2Pred)] = 0
vLevelsRecPred = cumsum(vAR2Pred)
vLevelsRecPred[vLevelsRecPred == 0] = 不适用

情节（vLevels）
行（vLevelsPred，col =“红色”）
行（vLevelsRecPred，col =“蓝色”）
]]></description>
      <guid>https://stats.stackexchange.com/questions/644618/different-results-when-fitting-arima-model-for-levels-vs-arma-model-for-first-di</guid>
      <pubDate>Tue, 09 Apr 2024 08:39:31 GMT</pubDate>
    </item>
    <item>
      <title>分割稀疏数据集时生成没有数据的集合的概率</title>
      <link>https://stats.stackexchange.com/questions/644617/probability-of-making-a-set-with-no-data-when-splitting-a-sparse-dataset</link>
      <description><![CDATA[假设您有一个包含稀疏数据列的 $N \times M$ 数据集。
每行中至少有一个数据点（即至少一个$M$属性具有数据）。
但是，每列中数据点的数量 $n$（每个属性的数据点计数）变化很大，可能会因接近 $N$ 到几乎 $0$ （但不完全是 $0$)。
您想要随机将数据集（按行）拆分为子集，例如$10:90$，或$20:80$，或 $20:20:20:20:20$（作为百分比，例如 $10:90$ 将是 $0.1 \cdot N$ 行 $:$&lt; /span&gt; $0.9 \cdot N$ 行，或最接近的整数）。
我试图回答的问题是：对于给定属性（列），其总数据点中有 $n$ 个数据点 $N$ 行，通过随机分割 $N$ 形成至少一个空集（没有数据的集合）的概率是多少 行分成指定大小的子集？
我以为我已经用超几何概率密度破解了它。
在 $10:90$ 拆分中，我（错误地）推理了，我只需要知道较小集合为空的频率，所以这就是从 $N$ 池中准确挑选 $0.1 \cdot N$ 个空项目的概率$N-n$ 项为空。
我认为这同样适用于多个（非两倍）分割，始终关注较小的集合。
从数值测试来看，事实证明我错了。
例如在 R 中，想象从一组 $N = 10$ 记录开始，其中 $2$ 有数据：
&lt;前&gt;&lt;代码&gt;要求（组合）

l &lt;- permn(c(rep(0, 8),rep(1, 2)))

N_at_least_one_empty = 0

对于（l中的li）{
  if ((sum(li[1:1]) == 0) + (sum(li[2:10]) == 0) &gt; 0) N_at_least_one_empty = N_at_least_one_empty + 1
}

print(paste0(&quot;1:9 分割中至少一组为空的概率 = &quot;, N_at_least_one_empty / length(l)))
打印(paste0(“dhyper =”, dhyper(1, 8, 2, 1)))

#[1]“在 1:9 分割中至少一组为空的概率 = 0.8”
#[1]“dhyper = 0.8”

但是已经有了 $20:80$ 分割，这个逻辑就崩溃了：
&lt;前&gt;&lt;代码&gt;N_at_least_one_empty = 0

对于（l中的li）{
  if ((sum(li[1:2]) == 0) + (sum(li[3:10]) == 0) &gt; 0) N_at_least_one_empty = N_at_least_one_empty + 1
}

#[1]“2:8 分割中至少一组为空的概率 = 0.644444444444444”
#[1]“dhyper = 0.6222222222222222”

我想这是因为在某些情况下，带有数据的两条记录最终会出现在较小的集合中，因此较大的记录可能为空。
更糟糕的是，在 $20 \times 5$ 分割中，显然实际上不可能没有空集。
但我使用的超几何公式无法捕捉到这一点。
我可以想象一种解决方案是考虑所有交互。
所以例如$20:80$ 分割：
$P(至少\一个\空) = P(较小\空) + P(较大\空) = 8/10 \cdot 7/9 + 8/10 \cdot 7/9 \cdot ... \cdot 1/3 \约 0.6222 + 0.0222 = 0.6444$
这个仍然可以写成超几何密度的简单总和。
但是将 $20%$ 分成 5 倍呢？
我尝试用$P(至少\一个\空) = 1 - P(全部\与\至少\一个\数据\点)$来思考，但这似乎并没有让我更接近解决方案。
有什么建议吗？
是否有任何已知的公式/原则来解决这种情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/644617/probability-of-making-a-set-with-no-data-when-splitting-a-sparse-dataset</guid>
      <pubDate>Tue, 09 Apr 2024 07:57:09 GMT</pubDate>
    </item>
    <item>
      <title>机器学习实践中的最大后验概率 (MAP)</title>
      <link>https://stats.stackexchange.com/questions/644615/maximum-a-posteriori-map-in-practice-for-machine-learning</link>
      <description><![CDATA[我是机器学习的初学者，我有一些关于 MAP 的问题。
根据我有限的理解，在我看来，贝叶斯方法，特别是 MLE 方法在为机器学习模型构建损失函数（负对数、交叉熵、elbo 等）时非常有用。

我想知道是否有任何使用 MAP 构建损失函数的实际示例。我能找到的唯一例子是 L1 和 L2 正则化，其中 L1 正则化项可以从拉普拉斯先验导出，L2 正则化项可以从高斯先验导出。

从直观的角度来看，先验具有高斯分布或拉普拉斯分布意味着什么？例如，先验分布是否不太可能具有指数分布？

其他正则化技术（例如 dropout 和批量归一化）是否具有像 L1 和 L2 正则化那样的 MAP 解释？根据我的理解，dropout 和批量归一化不会影响损失函数，所以我猜情况并非如此。

]]></description>
      <guid>https://stats.stackexchange.com/questions/644615/maximum-a-posteriori-map-in-practice-for-machine-learning</guid>
      <pubDate>Tue, 09 Apr 2024 07:05:10 GMT</pubDate>
    </item>
    <item>
      <title>样条线：统一的结位置</title>
      <link>https://stats.stackexchange.com/questions/644614/splines-uniform-knot-positions</link>
      <description><![CDATA[假设我们有 8 个均匀分布的插值点
&lt;前&gt;&lt;代码&gt;x = 1 2 3 4 5 6 7 8

并且想要定义阶数为 k=5 的 bspline 曲线，因此结向量有 8+5=13 个元素。
通常，第一个和最后一个结重复 k 次，因此结向量看起来像
&lt;前&gt;&lt;代码&gt;t = 1 1 1 1 1 3.5 4.5 8 8 8 8 8

在末端不再均匀，而插值点是均匀的。两个内部结点是内部插值点的平均值，这似乎是一种常见的方法。
也就是说，定义统一的结向量不是很常见吗？或者由于某些条件而根本不可能？]]></description>
      <guid>https://stats.stackexchange.com/questions/644614/splines-uniform-knot-positions</guid>
      <pubDate>Tue, 09 Apr 2024 06:47:24 GMT</pubDate>
    </item>
    <item>
      <title>如何计算二元分类概率[关闭]</title>
      <link>https://stats.stackexchange.com/questions/644612/how-to-calculate-binary-classification-probabilites</link>
      <description><![CDATA[我正在研究一些基于数值特征的二元分类问题，例如预测维护、信用卡欺诈、心脏病等。我通常喜欢使用随机森林，因为它用途广泛、稳健且可以获得高指标。
除了预测1或0之外，我还想预测获得1的概率（在0.00到1.00之间浮动）。如何在代码中实现这一点？
我使用了随机森林分类器的predict_proba()方法。然而，它主要产生极值（0.00 - 0.10 和 0.90 - 1.00）。我使用了 SVM 分类器的 decision_function() 方法，但 SVM 似乎不太通用。因此我正在寻找一种不同的方法。
我更喜欢与 RF 分类器相关的方法，但我对其他方法持开放态度。]]></description>
      <guid>https://stats.stackexchange.com/questions/644612/how-to-calculate-binary-classification-probabilites</guid>
      <pubDate>Tue, 09 Apr 2024 06:14:39 GMT</pubDate>
    </item>
    <item>
      <title>巢式病例对照研究中代谢组学特征的样本量计算</title>
      <link>https://stats.stackexchange.com/questions/644611/sample-size-calculation-for-metabolomic-profiles-in-a-nested-case-control-study</link>
      <description><![CDATA[我想计算嵌套病例对照研究的样本量。
结果是心血管疾病的发病率。暴露量是根据十年前采集的冷冻血清样本测得的代谢组学特征。
我们正在使用核磁共振来测量代谢组学特征，产生大约 250 个因子（其中约 40 个已经过临床验证）。
我们计划使用逻辑回归来分析代谢组学特征与心血管疾病之间的关联，并调整其他混淆因素。
由于预算有限，我无法测量大量样品。因此，我想知道最小样本量。但是，我不确定计算如此多曝光的样本量的适当方法。
这项研究与我们想要进行的研究类似，尽管我们可能无法测量如此大的样本量。
https://pubmed.ncbi.nlm.nih.gov/29420958/&lt; /p&gt;
如有任何建议，我们将不胜感激。
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644611/sample-size-calculation-for-metabolomic-profiles-in-a-nested-case-control-study</guid>
      <pubDate>Tue, 09 Apr 2024 06:00:56 GMT</pubDate>
    </item>
    <item>
      <title>分布常数的平均绝对偏差 (AAD) 和标准偏差有何区别？</title>
      <link>https://stats.stackexchange.com/questions/644610/what-makes-the-difference-between-the-mean-absolute-deviation-aad-and-standard</link>
      <description><![CDATA[我们可以在正态分布中很好地看到，平均绝对偏差和标准偏差之间的关系是 sqrt(2/pi) 的常数因子。是什么赋予了分布在这两个度量之间具有恒定因子差异的特征？对称吗？
这个问题的动机是，听说平均绝对偏差比标准偏差更稳健并且对异常值更不敏感（当然总是较小，但如果它总是相同的尺度，那么这并不是真正的“处理” ；异常值），如果这种关系始终是一个常数因子，那么对我来说没有多大意义，因此它不一定适用于所有分布。因此，我很好奇，我们如何判断其他分布是否存在常数因子差异？

https://en.wikipedia.org/wiki/Average_absolute_deviation]]></description>
      <guid>https://stats.stackexchange.com/questions/644610/what-makes-the-difference-between-the-mean-absolute-deviation-aad-and-standard</guid>
      <pubDate>Tue, 09 Apr 2024 05:10:48 GMT</pubDate>
    </item>
    <item>
      <title>使用NBEATS预测需求时如何处理零？</title>
      <link>https://stats.stackexchange.com/questions/644607/how-to-deal-with-zeros-when-using-nbeats-to-forcast-demand</link>
      <description><![CDATA[因此，我正在使用按层次结构组织的 NBEATS 来预测酒店的需求。但是，我面临底部时间序列数据（房间号）的问题，因为它们充满了零，我不确定如何解决这个问题。我已经成功地捕捉到了主要趋势，但它在有效处理峰值方面遇到了困难。我接触过克罗斯顿模型，但我并不是在寻找平均值；而是在寻找平均值。相反，我想预测某一天想要特定房间的人数。虽然我有添加更多层的想法，但我很犹豫，因为这可能会使事情进一步复杂化。我考虑过的一个概念是在使用 NBEATS 进行预测后使用 XGBoost，这有助于预测峰值和其他细微差别。

]]></description>
      <guid>https://stats.stackexchange.com/questions/644607/how-to-deal-with-zeros-when-using-nbeats-to-forcast-demand</guid>
      <pubDate>Tue, 09 Apr 2024 03:49:01 GMT</pubDate>
    </item>
    <item>
      <title>广义渐进混合审查方案类型 1 和 Muth 分布</title>
      <link>https://stats.stackexchange.com/questions/644594/generalized-progressive-hybrid-censoring-scheme-type-1-and-muth-distribution</link>
      <description><![CDATA[我有有关钠硫电池故障的数据，其数值如下：76,82,210,315,385,412,491,504,522,646+,678,775,884,1131,1446,1824,1827,2248,2385,3077。
本文提供了该数据集，请参阅此处链接 [https://www.sciencedirect.com/science/article/pii/S1687850723001024][1]
它代表 20 个细胞的失败，其中一个细胞被右删失 (646+)。
建议的分析遵循 GPHCS I 型：r=7、m=10 和 n=20（总样本量）
文中提出了3种方案进行分析。
第一个是：7个失败项目，其时间如下（0.076，.315，.385，.415，.522，.678，.775），预定时间确定为0.5结束研究，移除项目如下如下：第一次失败时删除 9 个项目，然后每次失败时删除 0 个项目，表示为 (9, 0^9)。
第二个方案是：8个失败项目，其时间如下（0.076，.082，.21，.315，.385，.775，.884，1.131），确定结束研究的前缀时间为1.3，并且删除项目如下：在第一次、第二次、第三次和第四次失败时删除零个项目，然后在第五次失败时删除 5 个项目，在第六次失败时删除 4 个项目，并在随后的每个失败时间删除零个项目，即 (0^4,5 ,4,0^4)。
第三种方案是：10个失败的项目，带有时间（.076,.082,.21,.315,.385,.412,.491,.504,.522,.678）和前缀时间来结束学习时间为 0.9，放学时间安排在 (0^9, 9)。
论文提出数据遵循 muth 分布。使用对数似然法获得参数的 Mle，如论文中的方程 8 所示。解析求解很困难，使用 MCMC 是一种替代方法。这对于贝叶斯和非贝叶斯方法都可以完成。
我的问题是如何使用 R 来做到这一点。
如何在R中用不同的方案表示数据？
为此需要哪些软件包？
您能给我提供一个代码示例吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644594/generalized-progressive-hybrid-censoring-scheme-type-1-and-muth-distribution</guid>
      <pubDate>Mon, 08 Apr 2024 21:43:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么因子在 2 向方差分析中显得显着，但通过检查（均值 +sd 或箱线图）却不显着？</title>
      <link>https://stats.stackexchange.com/questions/644574/why-does-factor-appear-significant-in-2-way-anova-but-not-by-inspection-mean-s</link>
      <description><![CDATA[我对双向方差分析的结果感到困惑。这些因素是分类因素和非随机因素，所使用的平方和是受约束的 III 型因素（不过，分类因素或 SS 类型的选择似乎对结果并不重要）。
数据由 50 次测量组成，一个因素有 2 个水平，另一个因素有 5 个水平，每个处理有 5 个重复。
下面的误差图说明了各个治疗的平均值 +/- 标准偏差，根据因子 #2 进行阻止（有两个水平，-/+）。

在上述处理中，1-5 和 6-10 对应于因子 #2 的两个水平 (-/+)，而处理 1-5 与因子 #1 不同（水平与 6-10 匹配）。
从检查来看，因素 #1 有影响，但很难说因素 #2 也有影响。
我在 MATLAB 中运行分析
[p,tbl,model] = anovan(msmnt,{var1,var2},“模型”,“交互”,&#39;varnames&#39;,{&#39;var 1&#39;,&#39;var 2&#39;}) ; %双因素方差分析
这是输出表：

&lt;标题&gt;

来源
平方和
d.f.
平均平方
F
问题&gt;F


&lt;正文&gt;

因子 1
612.97
4
153.242
56.86
0


因子 2
22.445
1
22.445
8.33
0.0063


因子 1:因子 2
12.53
4
3.132
1.16
0.3418


错误
107.8
40
2.695




总计
755.745
49






由于这两个因素（并且没有交互作用），似乎存在显着影响（95% 置信度）。
我手动计算了一些方差分析项，它们（嗯，我的计算）似乎是正确的。
但是，如果您查看因素 #2 的两个水平中每个水平的均值：

&lt;标题&gt;

事实#2 级别
平均
示例标准开发


&lt;正文&gt;

-
15.35
4.50


+
16.68
3.34



误差图（简单检查）和平均值表明这不是显着差异（由于因素 #2 没有影响），但方差分析表似乎另有说明。
这种相互矛盾的解释令人困惑。我的分析中遗漏了什么？方差分析是否看到了我没有看到的东西？
（我怀疑原因是治疗内方差相对较小。但是，如果这是真的，我如何确定各个对（例如 1-6、2-7 等）是否显着不同？） ]]></description>
      <guid>https://stats.stackexchange.com/questions/644574/why-does-factor-appear-significant-in-2-way-anova-but-not-by-inspection-mean-s</guid>
      <pubDate>Mon, 08 Apr 2024 16:01:53 GMT</pubDate>
    </item>
    <item>
      <title>R 问题：一旦 ncol > nrow，lm() 就会打印行的 NA</title>
      <link>https://stats.stackexchange.com/questions/644616/r-issue-lm-is-printing-nas-for-rows-once-ncol-nrow</link>
      <description><![CDATA[作为网络分析的一部分，我正在滞后变量上运行 lm()，并具有以下维度：
&lt;前&gt;&lt;代码&gt;暗淡（最终）
[1]197277

暗淡（最终滞后）
[1]197831

最终数据集包含非滞后变量（每行是一个日期，每列是一个公司）。 Final_lag 数据集包含每个公司的 3 个滞后（因此 277 个公司的 197 天 x 3 个滞后）。我正在尝试运行以下命令：
权重 &lt;-matrix(ncol = ncol(final), nrow=ncol(final_lag))

  for(i in 1:ncol(final)){
    #OLS 的 Beta 估计
    权重[,i] &lt;- coef(lm(final[,i] ~scale(final_lag)))[-1]
    打印（一）
  }

但是，在我的权重结果矩阵（831 x 277）中，我只有第 1-196 行的系数，而第 197-831 行都是 NA。如果我更改 Final 中的行数，那么我会再次获得数字系数，直到达到 nrow(final) 为止。有人知道如何解决这个问题/为什么会发生这种情况？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644616/r-issue-lm-is-printing-nas-for-rows-once-ncol-nrow</guid>
      <pubDate>Mon, 08 Apr 2024 10:53:42 GMT</pubDate>
    </item>
    <item>
      <title>使用指定的协方差矩阵和分布进行采样</title>
      <link>https://stats.stackexchange.com/questions/644558/sampling-with-specified-covariance-matrix-and-distribution</link>
      <description><![CDATA[给定一个正半定 $n\times n$ 矩阵 $C$ 我想要构造从 $n$ 随机变量 $X_1,\dots,X_n$ math-container&quot;&gt;$n$ 固定分布，使得 $\mathrm{corr}(X_i,X_j) = C_{ij}$。我对 $X_i$ 从具有不同参数的三角分布中提取的情况特别感兴趣。
我读过两种方法

Cholesky 分解：这似乎适合从不相关样本转换为相关样本。然而，三角形分布的线性组合不再是三角形
使用 cdf 将分布转换为均匀分布或正态分布，但这似乎并不能保留相关性

有没有什么方法可以将这些方法结合起来以保证随机变量既服从相关性又服从分布条件？也欢迎使用 python 实现的建议]]></description>
      <guid>https://stats.stackexchange.com/questions/644558/sampling-with-specified-covariance-matrix-and-distribution</guid>
      <pubDate>Mon, 08 Apr 2024 10:33:25 GMT</pubDate>
    </item>
    <item>
      <title>比较非嵌套 SEM 模型的回归系数 (Lavaan)</title>
      <link>https://stats.stackexchange.com/questions/644086/comparing-regression-coefficients-across-non-nested-sem-models-lavaan</link>
      <description><![CDATA[我对 Lavaan 的 SEM 有疑问，我似乎无法通过任何谷歌论坛或我的旧讲座幻灯片来理解它......我希望使用几个变量（CR1/CR2，代表不同的认知储备）来解释认知措施）但在单独的模型中。这些模型是非嵌套的，它们具有相同的潜在结果变量，但具有不同的预测变量来预测结果（在我的情况下是认知） - 像这样：
&lt;前&gt;&lt;代码&gt;model_CR1 &lt;- &#39;
认知=~x1+x2+x3
CR1 =~ y2
认知~CR1
&#39;

还有这个：
&lt;前&gt;&lt;代码&gt;model_CR2 &lt;- &#39;
认知=~x1+x2+x3
CR2 =~ y1+y3+y4
认知~CR2
&#39;

看看 CR1 和 CR2 变量如何具有完全不同的观测变量，其中一个仅包含 1 个观测变量，而另一个则基于 3 个观测变量。我意识到我无法比较完整的模型指数（如 AIC 或 RMSEA），因为这些模型是非嵌套的并且具有不同的 DF，但是我可以使用标准化系数直接比较认知 ~ CR1 / 认知 ~ CR2 的回归变量吗？这也太不合适了吧？
非常感谢您的建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/644086/comparing-regression-coefficients-across-non-nested-sem-models-lavaan</guid>
      <pubDate>Tue, 02 Apr 2024 09:32:45 GMT</pubDate>
    </item>
    </channel>
</rss>