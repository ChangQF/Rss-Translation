<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 20 Apr 2024 06:16:38 GMT</lastBuildDate>
    <item>
      <title>神经网络的输入可以通过其权重和输出唯一标识吗？</title>
      <link>https://stats.stackexchange.com/questions/645430/can-the-input-of-a-neural-network-be-uniquely-identified-by-its-weights-and-outp</link>
      <description><![CDATA[如果我们知道神经网络的输入和权重，就可以唯一计算出输出。反之，如果我们知道神经网络的输出和权值，那么一般情况下输入是否可以被唯一标识呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/645430/can-the-input-of-a-neural-network-be-uniquely-identified-by-its-weights-and-outp</guid>
      <pubDate>Sat, 20 Apr 2024 03:52:10 GMT</pubDate>
    </item>
    <item>
      <title>伪反演给出了较差的预测，以较小的矩阵收敛</title>
      <link>https://stats.stackexchange.com/questions/645429/pseudoinversion-giving-poor-predictions-converges-with-smaller-matrix</link>
      <description><![CDATA[我遇到一个问题，即运行伪反转作为使用甲基化数据预测某些表型值的方法会给出非常大的数字，非常池化地预测所述值，除非矩阵被显着减少。
具体来说，我有两个初始矩阵：trait_data 和 meth_data。我选择每个部分的一个部分作为测试动物。然后，我利用伪反演生成特征数据的预测，如下所示。当处理大约 20 个特征时，预测是相当准确的。但是，在处理 ~ 40 个特征时，我实际上得到了数十亿的数字，其值应该在 1 左右。我该如何解决这个问题，或者这是使用这种方法所期望的？我的这种方法基于论文“颊上皮细胞的甲基化组受年龄、性别和生理特性的影响”
&#39;&#39;&#39;
 #省略一只动物
    train_trait = np.delete(trait_data, n, 0)
    train_meth = np.delete(meth_data, n, 0)
    
    测试特征 = 特征数据[n]
    测试方法=方法数据[n]

    train_trait_pinv = np.linalg.pinv(train_trait)

    site_coef = np.dot(train_trait_pinv, train_meth) #系数 = Pinv(Trait_Train) * Meth_Train
    coef_pinv = np.linalg.pinv(site_coef)

    pred_trait = np.dot(test_meth, coef_pinv) #Trait_Pred = Meth_Test * Pinv(站点 Coef)

&#39;&#39;&#39;]]></description>
      <guid>https://stats.stackexchange.com/questions/645429/pseudoinversion-giving-poor-predictions-converges-with-smaller-matrix</guid>
      <pubDate>Sat, 20 Apr 2024 03:26:15 GMT</pubDate>
    </item>
    <item>
      <title>结构混乱的测量</title>
      <link>https://stats.stackexchange.com/questions/645426/measurement-of-construct-confusion</link>
      <description><![CDATA[测量结构有哪些不同的方法？我有一个构造的三个项目。这三个问题源自文章，通常用作衡量变量的项目。我将进一步使用这个构造进行 OLS 回归。那么，我如何获取变量的值呢？我可以检查 Cronbach&#39;s alpha 吗？如果它的值大于 0.7，是否可以计算这三个项目的平均值并在回归中使用该值？]]></description>
      <guid>https://stats.stackexchange.com/questions/645426/measurement-of-construct-confusion</guid>
      <pubDate>Sat, 20 Apr 2024 01:28:53 GMT</pubDate>
    </item>
    <item>
      <title>当同一物理量的同时测量结果不同时对时空数据进行平整的方法</title>
      <link>https://stats.stackexchange.com/questions/645424/methods-to-level-spatiotemporal-data-when-simultaneous-measurements-of-the-same</link>
      <description><![CDATA[我有三颗不同卫星对大气中电离臭氧密度含量（模拟）测量的数据。具体来说，我对每颗卫星 S1、S2、S3 (3N &gt; 每个时间戳的总观测值。所有三个卫星观测都是时间同步的，并且在观测的每个时间步长期间大致出现在相同的纬度/经度区域。我想弄清楚如何在同一时间对同一区域的观测进行“平衡”（我希望这是正确的术语）。
我的问题明确表述如下：
假设在时间戳T卫星S1在纬度和经度坐标（L1，L2）处测量到电离臭氧密度为3。 S2和S3在经纬度坐标（L1+k1，L2+k2）和（L1+k3，L2+k4）处测量臭氧密度分别为4和1其中 k1、k2、k3、k4 是 L1 和 L2 的小偏移（~0.2 度）。假设我知道S1的测量是“最准确的”（也许它直接从头顶飞过）。如何估计可以添加到 4 和 1（S2 和 S3e1 和 e2） strong&gt; 的测量）以使这些观察结果与 S1 观察到的结果更加“一致”？事实上，修改S1的观察也是允许的，但从某种意义上说，它应该被修改得最少。请注意，我们并不真正了解导致这些电离臭氧密度的物理过程，因此我们无法将对物理的任何理解纳入此估计中。
我很迷茫，不知道从哪里开始。任何帮助将不胜感激，即使是最简单的方法也可以！]]></description>
      <guid>https://stats.stackexchange.com/questions/645424/methods-to-level-spatiotemporal-data-when-simultaneous-measurements-of-the-same</guid>
      <pubDate>Sat, 20 Apr 2024 00:49:17 GMT</pubDate>
    </item>
    <item>
      <title>结合百分比来估计新的百分比</title>
      <link>https://stats.stackexchange.com/questions/645420/combining-percentages-to-estimate-new-percentage</link>
      <description><![CDATA[我正在尝试根据其居住州来估计在大学第一年选择本科级别大学专业的真正新生群体（首次入学、全日制、攻读学位）的比例。举例来说：对于从 X 州高中毕业并于明年上大学的学生，这些学生中有多少比例是全日制攻读学位的学生，并声明了所希望的大学专业。我没有直接获得这些数据，但有一些数据可以用来进行估计。以下是可用数据：

本科生总数（所有即将入学的本科生）
即将入学的全日制、首次攻读学位的本科生人数
过去 12 个月内高中毕业的首次攻读学位的本科生人数（因此，这里基本上也是第一次），按其被录取时的居住州划分
选择相关专业的全日制一年级攻读学位本科生的人数。

正如您所看到的，每个数据源涉及的学生类型都存在一些问题。来源 3 在计数中没有寻求程度，而来源 4 有。有谁知道我如何能够有效地组合这些数据来创建相关的估计？我可以假设进入真正的新生的家乡州的分布在整体队列和大学专业队列之间是相同的，以及你们可能会看到的我可能需要做出的其他假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/645420/combining-percentages-to-estimate-new-percentage</guid>
      <pubDate>Fri, 19 Apr 2024 20:39:20 GMT</pubDate>
    </item>
    <item>
      <title>链式法则条件熵</title>
      <link>https://stats.stackexchange.com/questions/645419/chain-rule-conditional-entropy</link>
      <description><![CDATA[在我正在阅读的教科书中，它指出 $H(X,Y)=H(X)+H(Y|X)$，其中$H(X,Y)$ 是随机变量的联合熵 $X,Y$, &lt; span class=&quot;math-container&quot;&gt;$H(X)$ $X$ 和 $H(Y|X)$ 是条件熵。然后它继续说，以类似的方式，可以显示
$H(X,Y|Z)=H(X|Z)+H(Y|X,Z)$。我很困惑如何解释左侧的术语。是否意味着被解释为 $X$ 分布和 $Y$&lt; 条件分布的交叉熵/span&gt; 以 $X$ 为条件，或者被解释为 $ 联合分布的条件熵X$ 和 $Y$，以 $Z$ 为条件？]]></description>
      <guid>https://stats.stackexchange.com/questions/645419/chain-rule-conditional-entropy</guid>
      <pubDate>Fri, 19 Apr 2024 20:29:19 GMT</pubDate>
    </item>
    <item>
      <title>实验中缺失数据，MIPO、MIPO|X 与 MCAR、MAR、MNAR</title>
      <link>https://stats.stackexchange.com/questions/645417/missing-data-in-experiments-mipo-mipox-vs-mcar-mar-mnar</link>
      <description><![CDATA[您好，我正在阅读艾伦·格伯和唐纳德·格林的《现场实验》，并向我介绍了独立于潜在结果的缺失 (MIPO) 的概念。当您以协变量为条件时，MIPO|X 与缺失无关。我接受的关于失踪的大部分教育都是关于 MCAR、MAR、MNAR 以及是否进行估算。
MIPO 定义为
$$
Y_i(z) \perp\!\!\!\!\perp R_i(z)
$$
MIPO|X 定义为
$$
\{Y_i(z) \perp\!\!\!\!\perp R_i(z)\}|\mathbf{X}_i = \mathbf{x} \text{ 对于所有 } \mathbf{x}
$$
$R_i(z)$ 是治疗 $z$ 的潜在反应。
$Y_i(z)$ 是治疗的潜在结果$z$
据我所知，MIPO 关注的是治疗效果是否公正或仍然有因果依据，而 MCAR、MAR、MNAR 更关注是否可以在没有缺失的情况下对完整样本进行推论，这是正确的吗？&lt; /p&gt;
我很好奇不同的思维方式如何影响分析以及这些想法来自哪里以供进一步阅读？]]></description>
      <guid>https://stats.stackexchange.com/questions/645417/missing-data-in-experiments-mipo-mipox-vs-mcar-mar-mnar</guid>
      <pubDate>Fri, 19 Apr 2024 20:13:30 GMT</pubDate>
    </item>
    <item>
      <title>移动块引导程序以获得趋势的一阶导数的 CI</title>
      <link>https://stats.stackexchange.com/questions/645416/moving-block-bootstrap-to-get-ci-arou-d-first-derivative-of-trend</link>
      <description><![CDATA[我有一个时间序列，我想知道非线性趋势分量的变化率。为此，我想获取趋势的一阶导数，但我需要围绕它的置信区间。我认为一种方法可能是执行 STL，然后在残差上使用移动块引导程序来生成引导时间序列，对每个重复分解并每次计算趋势的导数 - 让我可以围绕衍生品？
这是一个合理的方法吗？注意我不关心预测，只关心历史数据 - 引导在这里仍然有用吗？如果是这样，多少个引导程序合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/645416/moving-block-bootstrap-to-get-ci-arou-d-first-derivative-of-trend</guid>
      <pubDate>Fri, 19 Apr 2024 19:32:54 GMT</pubDate>
    </item>
    <item>
      <title>如何选择将分布放在 KL 散度的右侧或左侧？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/645409/how-do-you-choose-to-put-a-distribution-on-the-right-or-left-of-kl-divergence</link>
      <description><![CDATA[我一直认为 KL 散度是分布之间的距离度量，很像 Earth-Movers 距离。但我不能再忽视这种不对称性。真实距离度量是对称的。
我应该如何解释这种不对称性？如果我有两个分布，我想测量它们之间的 KL，我该如何决定是将一个分布放在 KL[Q||P] 的右侧参数还是左侧参数中？]]></description>
      <guid>https://stats.stackexchange.com/questions/645409/how-do-you-choose-to-put-a-distribution-on-the-right-or-left-of-kl-divergence</guid>
      <pubDate>Fri, 19 Apr 2024 17:34:13 GMT</pubDate>
    </item>
    <item>
      <title>秩约束矩阵乘积的 Frobenius 范数有界</title>
      <link>https://stats.stackexchange.com/questions/645341/frobenius-norm-of-rank-constrained-matrix-product-is-bounded</link>
      <description><![CDATA[假设我有三个矩阵 $\mathbf{W} \in \mathbb{R}^{p \times m}$ 和 $\mathbf{A}, \mathbf{B} \in \mathbb{R}^{m \times n}$ 与 $\operatorname{ rank}(\mathbf{A}) \leq r$ 和 $\mathbf{B}$ 在等级上不受限制。我还假设所有这些都在 Frobenius 范数中受到某个数字的限制，比如 $\Vert\mathbf{W}\Vert_F, \Vert\mathbf{A}\Vert_F, \Vert\ mathbf{B}\Vert_F \leq \kappa$
我试图表明 $ \sup \Vert\mathbf{WA} \Vert_F \leq \sup \Vert\mathbf{WB}\Vert_F$ ( sup 是在三个矩阵上）
我的想法是混合 SVD 分解，事实上矩阵的 Frobenius 范数是奇异值的平方，因此 LHS 将被裁剪为仅 $r$ 奇异值值将有助于总和。但我不能让它变得正式。您对如何进行有任何提示吗？
——编辑帖子@whuber评论！
好的。抱歉，这个问题实际上根本没有正确提出。我所寻找的并不是简单地表明 $ \sup \Vert\mathbf{WA} \Vert_F \leq \sup \Vert\mathbf{WB}\Vert_F$ 而是根据排序 (A) 与满排序 (B) 约束来查找分离因子。所以基本上看起来像这样的结果；
$$
\sup \Vert\mathbf{WA} \Vert_F \leq \textrm{某个函数} (r, \kappa)
\\ \sup \Vert\mathbf{WB} \Vert_F \leq \textrm{} (m, \kappa) 的某个函数
$$
很高兴得到任何指点！再次感谢:)]]></description>
      <guid>https://stats.stackexchange.com/questions/645341/frobenius-norm-of-rank-constrained-matrix-product-is-bounded</guid>
      <pubDate>Thu, 18 Apr 2024 21:29:13 GMT</pubDate>
    </item>
    <item>
      <title>事后观察到的效应大小是否与 p 值冗余，就像事后观察到的功效一样？</title>
      <link>https://stats.stackexchange.com/questions/645269/is-the-post-hoc-observed-effect-size-redundant-with-the-p-value-just-like-post</link>
      <description><![CDATA[为了简单起见，假设我们正在对 2 个正态分布总体进行 2 样本 t 检验，从中收集 2 个 i.i.d 样本。 （首先；我们可以稍后扩展到更复杂的情况）。我们知道，一项研究的事后观察功效完全由观察到的 p 值决定。请参阅此处，或此处，以及此网站上的多个参考。
然后，事后我们得到了计划的 $\alpha$ （传统上为 0.05），实际样本大小 $N $ 和 p 值 $p$。但是从 $p$ 我们可以得到观察到的幂 ($1-\beta&#39;$)，如下显示在链接中。我们有观察到的标准差 ($sd$)。我可以计算观察到的效果 ($\delta=(xbar_1-xbar_2)/sd$)。
让我知道用 2 个新样本重复此操作（相同的样本大小、相同的正态分布、相同的方差，但不同的“真实”效果）。我得到了不同的 p 值、观察到的功效 $(1-\beta$) 和观察到的效果 $\delta$&lt; /跨度&gt;。我多次重复同样的事情。
认为 $\delta$ 值与 p 值存在单调递减函数的观点是否正确？ （正如功率与 p 的链接所示）。或者事后效应大小是一个随机变量吗？在这种情况下，它的分布可能是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/645269/is-the-post-hoc-observed-effect-size-redundant-with-the-p-value-just-like-post</guid>
      <pubDate>Thu, 18 Apr 2024 01:40:12 GMT</pubDate>
    </item>
    <item>
      <title>英文文本中每个单词有多少知识点？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/645182/how-many-bits-of-knowledge-are-there-in-english-text-per-word</link>
      <description><![CDATA[人们常说，典型的英语文本可以最佳地压缩到每个单词 12 位左右。
然而，由于陈述相同事实的方式有很多种，因此典型文本中传达的事实知识每个字少于 12 位。我正在阅读的一篇 ML 论文提到了一个数值估计：
&lt;块引用&gt;
[4]
截至 2024 年 2 月 1 日，英语维基百科总共包含 45 亿个单词，请参阅 https://en.wikipedia。 org/wiki/Wikipedia:Size_of_Wikipedia#Size_of_the_English_Wikipedia_database，访问于 2024 年 3 月。
据估计，英语教科书的非重叠内容总共不到160亿字，参见
备注 G.1。这总计 205 亿个单词，但我们认为它们包含的知识不到 140 亿位。

但没有提供参考资料，因此我的问题是：
英文文本中每个单词有多少知识点？
&lt;小时/&gt;
对版主和反对者的回应：
一位版主坚持认为，提及“知识（文本）”的帖子必须被禁止。给出它的定义。
这对我来说似乎很奇怪，因为“知识”一词是在我看来。在NLP、信息抽取、知识抽取等领域已经被普遍理解。否则，他们想抽取什么？
当然，这个术语很难甚至不可能精确定义。但“图书馆”这个词也不是。你需要有多少本书才能成为一个“图书馆”？一把“椅子”也没有明确定义，但我打赌你仍然可以在你的房子里数它们。
定义“知识”作为“文本中的有用信息”只会把责任推给“有用”。
虽然我无法给出“知识”的清晰定义，但允许它被量化，我可以尝试对其进行上限和下限：

下限：知识（文本形式）是被提取到图形结构（例如 Google 的知识图谱）中的信息。这是一个下限，因为现有的方法可能会遗漏一些东西。
上限：知识（文本形式）是翻译中保留的信息。这是一个上限，因为其他一些内容会被保留（文档的整体结构等）

与其他信息一样，这两者都是可量化的。]]></description>
      <guid>https://stats.stackexchange.com/questions/645182/how-many-bits-of-knowledge-are-there-in-english-text-per-word</guid>
      <pubDate>Tue, 16 Apr 2024 21:31:36 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程回归在哪些方面是参数和非参数的？</title>
      <link>https://stats.stackexchange.com/questions/645170/in-what-ways-is-gaussian-process-regression-both-parametric-and-non-parametric</link>
      <description><![CDATA[高斯过程回归被认为是“非参数”回归。模型。然而，术语“非参数”是指术语“非参数”。通常不精确地用来表示不同的事物，导致 关于什么是非参数的问题。这种混淆在“非参数统计”部分中得到了强调。维基百科文章，讨论了“非参数”的两种解释：
&lt;块引用&gt;

不依赖属于任何特定概率分布参数族的数据的技术。这些可以由无分布方法组成，其中数据不需要从“参数族”中提取。概率分布或由定义为样本函数的统计数据组成，不依赖于参数。
不假设模型结构是固定的技术。通常，模型的大小会增加以适应数据的复杂性。在这些技术中，通常假设各个变量属于参数分布，并且还对变量之间的关联类型做出假设。例如，非参数回归，即以非参数方式处理变量之间关系结构的建模，但仍然可能存在关于模型残差分布的参数假设。


问题：
鉴于此，高斯过程回归在哪些方面是参数化的，在哪些方面是非参数化的？
回答问题的其他帮助
虽然为什么高斯过程模型被称为非参数模型？ 
是一个类似的问题，该问题和接受的答案仅（不精确地）解决在非参数的一种定义下如何将 GP 视为非参数，而不是上述（非）参数模型的不同定义。
理想的答案应该足够精确，至少可以讨论以下内容：

有关核、协方差结构和函数的假设。
参数随 N 增长
优先于函数而不是具体参数
]]></description>
      <guid>https://stats.stackexchange.com/questions/645170/in-what-ways-is-gaussian-process-regression-both-parametric-and-non-parametric</guid>
      <pubDate>Tue, 16 Apr 2024 19:42:57 GMT</pubDate>
    </item>
    <item>
      <title>如何确定足够的功效所需的样本量来比较混合模型中固定效应的水平？</title>
      <link>https://stats.stackexchange.com/questions/632974/how-to-determine-sample-size-needed-for-sufficient-power-to-compare-between-leve</link>
      <description><![CDATA[我对受试者内部实验进行了一项试点研究，其中感兴趣的固定效应是分类的，有 4 个级别。研究问题涉及比较该 IV 的哪些水平在统计上可以被视为相似与不同。
这是一个简化的示例。假设对于 A、B、C、D 级，这些条件下的平均反应时间为 1000 毫秒、1100 毫秒、1150 毫秒和 1175 毫秒。通过轮换参照组，我们确定：(1) A B 和 C 水平在统计上均不同，(2) D 水平与 A 和 B 不同，但 (3) C 和 D 相当。
如上所述，我有试点数据，并且也很乐意进行基于模拟的分析。但我发现的所有工具似乎都在告诉我检测固定效应效果所需的样本量，这显然不足以实现我的实际目标。例如，simR 确信我只需要大约 12 名参与者即可获得 80% 的功效，尽管效果大小不同且每个条件的试验规模较小 (30)。
我也尝试过仅基于数据子集运行 simR（例如，仅比较级别 2 和 3 或 3 和 4），但当然这是非常有缺陷的（例如，级别 3 和 4 突然变得显着不同） ）此外，我知道我需要更大的样本来解释实际分析中的额外水平。所以这种方法没有真正的实用性。
请注意，在我的领域，我使用混合效应模型是一个强烈的惯例，这也是项目预注册分析计划中记录的内容。如果可能的话，请不要只是告诉我切换到[在此处插入您最喜欢的分析方法]会更容易。]]></description>
      <guid>https://stats.stackexchange.com/questions/632974/how-to-determine-sample-size-needed-for-sufficient-power-to-compare-between-leve</guid>
      <pubDate>Sun, 03 Dec 2023 23:31:17 GMT</pubDate>
    </item>
    <item>
      <title>如果变量似乎没有太大影响，是否应该删除偏移量？</title>
      <link>https://stats.stackexchange.com/questions/619782/should-an-offset-be-removed-if-the-variable-doesnt-seem-to-have-much-influence</link>
      <description><![CDATA[这是一个与主题专家的联合项目，我是统计学家。我不会解释背景并简化统计问题，因为背景相当复杂。我们实际拟合的模型是负二项式混合效应 GLM，但问题可以使用泊松回归来解释。
假设我们有一个响应变量 $Y$，它是一个计数，按照某些变量 $X_1 的解释进行建模， \ldots,X_p$。还有一个变量 $P$ 是“人口规模”。与 $Y$ 存在某种联系，因此对于我的专家来说，最初对 $Y/ 建模似乎是个好主意P$，即“$Y$（按人口成员）”而不是 $Y$。我应该补充一点，从变量的主题信息/含义来看，情况并不是很清楚，我的意思是，这有点合理，但并不完全明显 $Y$应由 $P$ 标准化。一些 X 变量也由 P 标准化，而另一些则不然，这一事实增加了复杂性。这也是有原因的，但它们也“有些合理，但并不完全明显”。
使用具有对数链接的泊松回归来建模 $Y/P$ 的方法是在模型中包含一个偏移量，即项 $\log(P)$ 具有固定的回归系数 1。我将此模型称为 M1。出于好奇，我们还查看了模型 M2，其中没有偏移，但包含 $\log(P)$ 作为另一个预测变量。拟合模型 M2，$\log(P)$ 变量的估计系数接近于零并且（不是边界）微不足道。 （如果 $\log(P)$ 替换为 $P$，这和我后面写的内容不会发生实质性变化。）
在 X 变量中，有一些与 $\log(P)$ 相关（不是非常强；相关性高达 0.4）。在我看来，这解释了 M1 中的估计系数及其 p 值与 M2 有很大不同，以至于两个预测变量具有相反的符号，但在两个模型中都非常显着，而另一个预测变量似乎非常强在M1中但在M2中微不足道。
现在我的问题是微不足道和“接近零”是否是事实？ M2 中 $\log(P)$ 的状态实际上是争论不应该使用 M1 的有力理由（并且应该从 M2 解释估计量和 p 值）不管它们在 M1 中是否有如此不同）。如果确实是“真实的”。 M2 中 $\log(P)$ 的系数为零，这意味着（给定其他变量）$Y $ 不会被 $P$ 所困扰，因此对 $Y$&lt; 建模似乎是有意义的M2 中的 /span&gt; 而不是 M1 中的 $Y/P$ 。当然，$\log(P)$ 的估计系数（如果为零）将比像偏移量那样将此系数固定为 1 更好地拟合数据（ AIC等更喜欢M2）。另一方面，人们可能怀疑 $Y$ 由 $P$ 标准化仍然可能是正确的（考虑到“合理的”主题论据），只有在M2中它的影响被“接管”了。由其他变量影响，并解释 M2 中其他变量的结果系数可能无法正确代表情况。
这里的目的是分析历史情况，解释变量的影响和重要性。预测与本分析的目的无关。
有什么见解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/619782/should-an-offset-be-removed-if-the-variable-doesnt-seem-to-have-much-influence</guid>
      <pubDate>Mon, 26 Jun 2023 15:36:52 GMT</pubDate>
    </item>
    </channel>
</rss>