<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 07 Aug 2024 09:17:13 GMT</lastBuildDate>
    <item>
      <title>某个因素的主要影响是什么？</title>
      <link>https://stats.stackexchange.com/questions/652428/whats-the-main-effect-for-a-factor</link>
      <description><![CDATA[这是我在这里的第一个问题。补充一点背景信息：我正在研究实验设计，在因子主效应部分遇到了麻烦。我了解到，如果您有 $k$ 个因子，每个因子有 $2$ 个级别，例如0 和 1，重复 $n$ 次，那么因子 $A$ 的主效应为
$$
\delta A = \frac{[A1]-[A0]}{4}
$$
其中 $[A1]$ 是 $A=1$ 等情况下的结果总和。
第一个问题是为什么？我的意思是为什么是这样而不是相反？喜欢
$$
\delta A = \frac{[A0]-[A1]}{4}
$$
第二个问题是，当一个因子有两个以上的水平时，它的主要影响是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652428/whats-the-main-effect-for-a-factor</guid>
      <pubDate>Wed, 07 Aug 2024 09:09:59 GMT</pubDate>
    </item>
    <item>
      <title>用于评估特征解释力的逻辑回归——分数和置信度的解释</title>
      <link>https://stats.stackexchange.com/questions/652427/logistic-regression-for-evaluating-explanatory-power-of-features-interpretatio</link>
      <description><![CDATA[我需要帮助来确定我的分析是否合理。
我的目标是评估一组特定特征对于二元分类问题的解释力。
我目前的策略是：

选择不相关且具有统计意义的特征（t 检验）
使用这些特征拟合逻辑回归模型 (sklearn)
通过查看系数来比较特征的强度
通过从决策函数中获取置信度值和分数来评估这些特征的解释力 - 在训练数据上测试模型。

这是我不确定的地方。我的直觉告诉我，在训练数据上进行测试总是错误的（呃）。但我的大脑告诉我，在这种情况下这样做是有意义的。我想知道根据我的特征提供的信息，有多少数据点是可以区分的 - 而不是它对看不见的数据会做出什么反应。
大致来说，这是我的思考过程：

高置信度，高分 =&gt; 特征很好
高置信度，低分 =&gt; 特征具有误导性
低置信度，高分 =&gt; 特征具有信息性但不是那么强
低置信度，低分 =&gt; 特征没有信息性

这个分析方案合理吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652427/logistic-regression-for-evaluating-explanatory-power-of-features-interpretatio</guid>
      <pubDate>Wed, 07 Aug 2024 08:51:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAM 调查多个时期之间的受试者内部差异</title>
      <link>https://stats.stackexchange.com/questions/652425/using-gam-to-investigate-the-within-subject-variation-between-several-periods</link>
      <description><![CDATA[我的研究问题是分析个体内（受试者内）接触模式的异质性，并确定封锁前和封锁期间稳定接触行为的决定因素。由于接触模式与参与者的年龄和接触地点有关，因此下图显示了研究人群的接触模式。

如图所示，由于按位置分层的联系人数和年龄之间的关联似乎遵循不同的模式，因此联系数据按位置分层。并根据不同的地点建立模型。
首先我建立一个初步模型来估计theta
prelim_model &lt;- gam(n ~ s(age, by = period, k = 5) + 
s(token, bs = &quot;re&quot;) + s(Bundesland, bs = &quot;re&quot;), 
data = data_education, 
family = nb())

theta_est &lt;- prelim_model$family$getTheta(TRUE) 
theta_est 

因为我想根据period和within-subject考察变量对接触人数的影响，在比较了AIC和BIC之后，最终的模型是这样的：
gam(n ~ s(age, by = period, k = 3) + period * sex + s(hh_size, by = period, k = 3) + 
period * employment_2cat + period * education_2cat + period * marital_2cat + 
period * weekend + period * region + period * Transportation_2cat + period + 
s(token, bs = &quot;re&quot;) + s(Bundesland, bs = &quot;re&quot;), 
data = data_education, 
family = nb(theta = theta_est)) # 使用我从初步模型中获得的 theta



从结果来看：

婚姻状况在统计上不显著
两个交互项在统计上都不显著
年龄对联系人数量有显著的非线性影响
家庭规模仅在第 3 期对联系人数量有显著的非线性影响
个人行为对联系次数有很大影响。

我使用 DHARMa 残差和 gam.check 来检查模型


我的问题如下：

我按照位置划分数据集，然后单独建立模型，这种方法合理吗？
我已经尝试过其他方法，包括泊松分布的GLMM，ng分布的GLMM，ng分布的零膨胀模型。当我使用 DHARMa 残差检查模型时，结果更糟糕。
由于分析结果中截距、周期 2、周期 3 的标准误差较大，且与 QQ 图残差存在显著差异，并且如 gam.check 的结果所示，我应该如何改进模型？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652425/using-gam-to-investigate-the-within-subject-variation-between-several-periods</guid>
      <pubDate>Wed, 07 Aug 2024 08:36:29 GMT</pubDate>
    </item>
    <item>
      <title>聚类后​​我可以使用方差分析吗？</title>
      <link>https://stats.stackexchange.com/questions/652423/can-i-use-anova-after-clustering</link>
      <description><![CDATA[我正在帮助某人分析植物物种的数据。他们将一个城镇划分为大小相等的方块，并收集每个方块中生长的杂草物种的数据。我使用聚类分析 (Ward.D2) 根据物种组成对方块进行分组。结果看起来很合理。有关于大多数物种生态特征的数据（埃伦伯格值等）。我现在可以进行第二次分析，将埃伦伯格值应用于每个聚类中的物种，并使用方差分析来查看哪些埃伦伯格值（例如氮、pH）在划分方块时最重要吗？或者还有其他方法可以做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/652423/can-i-use-anova-after-clustering</guid>
      <pubDate>Wed, 07 Aug 2024 08:28:23 GMT</pubDate>
    </item>
    <item>
      <title>如何测试“无显着差异”？ [重复]</title>
      <link>https://stats.stackexchange.com/questions/652420/how-to-test-for-no-significant-difference</link>
      <description><![CDATA[我的公司从事游戏开发。我们正在尝试测试在特定位置添加更多广告是否会对玩家参与度产生不利影响（减少游戏时间、留存率等）。
你们能就如何进行和分析 A/B 测试给我一些建议吗？通常，我们测试并使用 t 检验来分析显著差异，而不是反过来，所以我在这里有点困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/652420/how-to-test-for-no-significant-difference</guid>
      <pubDate>Wed, 07 Aug 2024 06:52:33 GMT</pubDate>
    </item>
    <item>
      <title>寻求使用二元中介进行多级中介分析的 R 包推荐</title>
      <link>https://stats.stackexchange.com/questions/652417/seeking-recommendations-for-r-packages-for-multilevel-mediation-analysis-with-bi</link>
      <description><![CDATA[我正在开展一项研究，旨在调查青少年饮食习惯（独立变量）和学业成绩（因变量）之间的关系，其中课外活动参与是中介变量。
以下是我研究的具体内容：
结果（因变量）：学业成绩（连续）[以学术分数衡量]
暴露（独立变量）：饮食习惯[饮食质量、进餐频率]分为三组（低、中、高）
中介变量：课外活动参与[活动运动、活动艺术]（二进制：是[1]/否[0]）
协变量：年龄、BMI、社会经济地位 (SES)、睡眠时间 (sleep_duration)、调查波 (survey_wave)
级别：调查波和学区
子组：我特别感兴趣的是分别检查男孩（性别=1）和女孩（性别=2）的模型。
研究问题：课外活动参与是否会减弱青少年饮食习惯和学业成绩之间的关系？
鉴于我的中介变量是二元变量，并且模型包括多个层次（调查波和学区），我正在寻求有关可以使用二元中介变量进行多级中介分析的适当 R 包的建议。
有人可以建议用于这种分析的最佳 R 包或方法吗？具体来说，我需要：
在多级中介框架中容纳二元中介变量。
分别分析不同子组（男孩和女孩）的数据。
正确考虑协变量和数据的层次结构。
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/652417/seeking-recommendations-for-r-packages-for-multilevel-mediation-analysis-with-bi</guid>
      <pubDate>Wed, 07 Aug 2024 04:44:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的不相关回归量的回归中存在遗漏变量偏差？</title>
      <link>https://stats.stackexchange.com/questions/652416/why-is-there-omitted-variable-bias-in-my-regression-of-uncorrelated-regressors</link>
      <description><![CDATA[我正在对伯努利不相关变量运行 LASSO 回归，即每个变量都有 $\frac{1}{2}$ 的概率取值为 0 或 1。我的理解是，在这种情况下不应该有遗漏的变量偏差。但是，当我省略一些变量时，剩余的回归量之一似乎会随着其他变量的省略而不断变大。这个回归量恰好是迄今为止系数最大的回归量。
有人能帮我理解为什么在这种情况下会有遗漏的变量偏差吗？我能想到的唯一其他会使模型无效的原因是假设残差与回归量不相关。这也许是在省略其他变量时最大系数持续变大的原因吗？
或者原因更可能与 LASSO 正则化有关？我的理解是，LASSO 将小系数缩小到 0，但可以通过使大系数更大来进行“补偿”。那么这也适用于省略的变量偏差吗？即，在套索回归中，如果我们删除一些具有大系数的回归量，正则化是否会导致剩余的一些系数按比例变大？
编辑：
我尝试运行没有 LASSO 正则化的回归，当省略一些变量时，我仍然看到该首项系数中的偏差。所以我认为它一定来自与残差的相关性？
保罗]]></description>
      <guid>https://stats.stackexchange.com/questions/652416/why-is-there-omitted-variable-bias-in-my-regression-of-uncorrelated-regressors</guid>
      <pubDate>Wed, 07 Aug 2024 02:57:16 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 nmol/g 土壤中的 PLFA 数据？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652415/how-to-calculate-plfa-data-in-nmol-g-soil</link>
      <description><![CDATA[我得到了一个包含 PLFA 数据的 Excel 表；单个 PLFA 值以百分比形式给出，并且还提供许多其他信息。我不知道如何计算 nmol/g 土壤中的单个 PLFA 值。]]></description>
      <guid>https://stats.stackexchange.com/questions/652415/how-to-calculate-plfa-data-in-nmol-g-soil</guid>
      <pubDate>Wed, 07 Aug 2024 02:53:34 GMT</pubDate>
    </item>
    <item>
      <title>时间序列帮助：使用不同频率的变量:)</title>
      <link>https://stats.stackexchange.com/questions/652414/time-series-help-working-with-variables-with-different-frequencies</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652414/time-series-help-working-with-variables-with-different-frequencies</guid>
      <pubDate>Wed, 07 Aug 2024 02:07:21 GMT</pubDate>
    </item>
    <item>
      <title>当 f 不服从正态分布时，误差传播的方差公式是否有用？</title>
      <link>https://stats.stackexchange.com/questions/652401/is-the-variance-formula-for-error-propagation-useful-when-f-is-not-normally-dist</link>
      <description><![CDATA[我对不同的属性进行了 n 次测量。例如，物体的重量和体积 (n=2)。
由于测量结果存在不确定性，我将其建模为
n 个独立随机变量 $X_i$，它们呈正态分布，未知 $\mu_i$。然而，不确定性是由我的仪器决定的。例如，我的体重可能只能精确到克。
在这种情况下，我会说不确定性是 $\pm 0.5 g$。
因此，我假设 $\sigma_i = 0.25 g$，因为这意味着有 95% 的置信度
$$ 
\mu_i - 2\sigma_i &lt;= xi &lt;= \mu_i + 2\sigma_i
$$
其中 $\mu_i$ 是实际重量，$x_i$ 是测量重量。
我有一个函数 f，它是 $X_i$ 的非线性组合。
例如$f=密度 = 重量/体积$。
方差公式 (1) 指出：
$$
\sigma_f^2 \approx \Sigma_{i=1}^N (\frac{\partial f}{\partial X_i}\sigma_i)^2 
$$
假设 f 的泰勒展开式收敛。
但是由于 f 通常不是正态分布，$\sigma_f$ 有多大用处？
当然，我可以找到范围：
$$
-2\sigma_f &lt;= f &lt;= 2\sigma_f
$$
但我不知道这是 95% 还是 5% 的置信区间。
1 不确定性传播]]></description>
      <guid>https://stats.stackexchange.com/questions/652401/is-the-variance-formula-for-error-propagation-useful-when-f-is-not-normally-dist</guid>
      <pubDate>Tue, 06 Aug 2024 21:13:07 GMT</pubDate>
    </item>
    <item>
      <title>方程数多于解的线性方程组</title>
      <link>https://stats.stackexchange.com/questions/652385/system-of-linear-equations-with-more-equations-than-solutions</link>
      <description><![CDATA[如何确定方程数多于解数的线性方程组的解？
例如，我有产品 A、B 和 C，以及同事数 D。每天 n_D 个同事会生产 n_A 份产品 A、n_B 份产品 B 和 n_C 份产品 C。每件产品的生产需要时间 t_A、t_B 和 t_C。一天的时间是 t_D。
因此，搜索的方程式是 n_A * t_A + n_B * t_B + n_C * t_C = n_D * t_D。
我有数千行，其中包含 n_A、n_B、n_C 和 n_D 的条目。时间 t_D 是常数（一天）。如何计算时间 t_A...t_C？如果我的数据表恰好有三行，我就可以精确地解方程式。如果有更多行，我应该能够以某种方式计算每个的平均值和标准差，对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652385/system-of-linear-equations-with-more-equations-than-solutions</guid>
      <pubDate>Tue, 06 Aug 2024 15:51:51 GMT</pubDate>
    </item>
    <item>
      <title>通过优化拟合优度参数设置数据过滤器[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652380/setting-data-filters-by-optimizing-on-goodness-of-fit-parameter</link>
      <description><![CDATA[我不是数学家、统计学家或数据科学家，但我是一个试图将时间序列分析应用到我的科学领域的人。所以请原谅我的问题中的任何无知：D
数据和统计模型
我有一个性能数据的时间序列，其中包含季节性成分、大量噪音和我们想要提取的趋势信号。趋势信号通常被认为是线性的，尽管众所周知这通常是一种简化。在我的领域，已经测试了各种统计模型来提取线性趋势信号。最常用的方法之一是同比 (YoY) 方法，它本质上考虑了数据的季节性。
过滤的必要性
为了减少噪音以帮助确定潜在的趋势信号，可能需要应用各种数据过滤器。在这个研究领域，还没有一种既定的方法来设置这些参数，到目前为止，这都取决于分析师的判断，尽管过滤可能会显著影响最终的估计值。所需的过滤器还取决于获取性能数据的系统；不同的系统有不同的噪声源等。过滤通常是在 5 分钟、15 分钟或每小时分辨率的原始数据上进行的，然后再汇总为每日、每周或每月的值，然后对其应用 YoY。
我的方法
目前，我正在研究一种通过最小化/最大化可以从数据集中提取的一些参数来设置过滤器参数的方法；与目前最先进的方法相比，这种方法可能更具可重复性、自动化和独立于分析师。这构成了一个多维优化问题，我借助贝叶斯优化解决了这个问题。
问题
我现在试图找出选择应用于数据的过滤器和过滤器参数的最佳优化参数是什么。由于历史原因，我首先最小化置信区间（通过引导法在 YoY 方法中确定）。即算法搜索给出最低置信区间的过滤器/过滤器值组合，并将此过滤器组合的趋势估计作为最佳估计。然而，置信区间不是准确度的度量，而准确度是我的主要目标。相反，我现在正在考虑将以下内容作为替代优化参数：

R 平方（计算 YoY 与过滤数据相比的最佳趋势线）- 在我看来，与作为精度度量的置信区间相比，R 平方是拟合精度的更直接度量。
调整后的 R 平方 - 应该比 R 平方有所改进，因为它会惩罚过于激进的过滤，这会导致 YoY 方法只留下很少的数据点，从而可以防止过度拟合数据子集。
赤池信息准则 - 我的理解是，这应该能够给出给定数据集的不同统计模型的相对质量，我认为这相当于评估相同数据的不同过滤变体的相同统计模型的相对质量（？）。使用 AICc 而不是 AIC 似乎适合惩罚激进的过滤。
某种形式的交叉验证。虽然我相信这可能是合适的，但我想知道这对这个问题来说是否太复杂了（？）。

所以，我当然可以测试所有这些，看看哪个看起来效果最好。但在我开始之前，我想从任何真正精通数据科学和统计学的人那里得到以下方面的意见
问题
从理论或根本原因来看，所提出的任何参数对于当前的问题来说是否更好或更坏？为什么？
如果您需要更多信息来了解我的问题和/或对我的问题提供意见，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/652380/setting-data-filters-by-optimizing-on-goodness-of-fit-parameter</guid>
      <pubDate>Tue, 06 Aug 2024 13:00:29 GMT</pubDate>
    </item>
    <item>
      <title>添加虚拟变量/控制变量的回归导致独立变量不显著</title>
      <link>https://stats.stackexchange.com/questions/652373/regression-with-dummy-control-variables-added-leading-to-insignificant-independe</link>
      <description><![CDATA[我需要对我的硕士论文进行一些修改。其中之一是添加虚拟变量和控制变量，因为我也在研究人口统计数据。
我有 5 个独立变量，这些变量之前被证明与客户满意度有关。其中 4/5 是显著的。我现在添加了年龄、性别和教育。但是，4 个显著的独立变量中的一个变得不显著。
在检查了虚拟变量和独立变量之后，只用独立变量重新进行回归是否有意义？似乎只使用主要变量更可靠，也更简单。这里的最佳做法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652373/regression-with-dummy-control-variables-added-leading-to-insignificant-independe</guid>
      <pubDate>Tue, 06 Aug 2024 11:41:51 GMT</pubDate>
    </item>
    <item>
      <title>从固定大小的样本集中合并新数据并删除旧数据会产生什么影响？</title>
      <link>https://stats.stackexchange.com/questions/652359/what-are-the-implications-of-incorporating-new-data-and-removing-old-data-from-a</link>
      <description><![CDATA[我有一个设备，每 15 秒读取一次传感器读数。当样本大小达到 10,001 时，设备会删除最旧的读数。这样样本大小就保持在 10,000。到目前为止，对数据的分析显示读数遵循标准分布。示例：
级别：6，样本量：10000
平均值：911 最小值：892 最大值：939 众数：911 标准差：4.2
读数与 2 标准差之和：9516 范围：(903-920) - 95.2%

我以这种方式管理样本量是否会对我的计算产生偏差或影响。此外，任何关于理解我的数据的建议都将不胜感激。
我迄今为止收集的数据：

3 平均值：477 最小值：462 最大值：502 众数：477 标准差：3.9 样本量：3124
4 平均值：632 最小值：610 最大值：657 众数：632 标准差：4.2 样本量：7446
5 平均值：796 最小值：777 最大值：820 众数：796 标准差：4.2 样本量：10000
6 平均值：911 最小值：892 最大值：939 众数：911 标准差：4.2 样本量：10000
7平均值：1021 最小值：1006 最大值：1023 众数：1021 标准差：2.3 样本量：2744
]]></description>
      <guid>https://stats.stackexchange.com/questions/652359/what-are-the-implications-of-incorporating-new-data-and-removing-old-data-from-a</guid>
      <pubDate>Mon, 05 Aug 2024 22:09:54 GMT</pubDate>
    </item>
    <item>
      <title>John A.Rice 著作《数理统计与数据分析》中的练习 39</title>
      <link>https://stats.stackexchange.com/questions/652424/exercise-39-of-john-a-rice-book-mathematical-statistics-and-data-analysis</link>
      <description><![CDATA[我正在学习 John A. Rice 的《数理统计与数据分析》一书。在第 4 章中，我遇到了一个很难解决的练习，如果能给我一点提示，我将不胜感激。
练习 39：
假设要对长度为 $N = 1,000,000$ 的 DNA 片段进行散弹枪测序，片段长度为 $L_F = 1000$。

a. 需要多少个片段才能使单个位点被覆盖的概率大于 0.99？
b.有了这种选择，您预计会错过多少个站点？

让 $x$ 为片段数。我相信我应该根据 $x$ 估计站点至少出现在一个片段中的概率。如果站点 $s$ 位于前 $10^6 - 10^3$ 个位置内，则左端点位于 $s-1000$ 和 $s$ 之间的所有片段都将包含站点 $s$，右端点位于 $s + 1$ 和 $s + 1000$ 之间的所有片段也将包含站点。但是，我不确定如何对这些片段端点的分布进行建模。如能提供任何指导，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/652424/exercise-39-of-john-a-rice-book-mathematical-statistics-and-data-analysis</guid>
      <pubDate>Mon, 05 Aug 2024 19:12:37 GMT</pubDate>
    </item>
    </channel>
</rss>