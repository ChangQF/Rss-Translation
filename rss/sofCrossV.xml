<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 01 Dec 2024 12:33:00 GMT</lastBuildDate>
    <item>
      <title>帮助使用简单的 NN 模型</title>
      <link>https://stats.stackexchange.com/questions/658087/help-with-simple-nn-model</link>
      <description><![CDATA[我一直在为 MONKS 数据集问题 1 开发神经网络，我想寻求一些建议。
我的神经网络架构包括：
2 个隐藏层：64 个神经元和 32 个神经元
批次大小：16 或 32 或 64，epoch 100 或 200，学习率：0.01 或 0.001
我使用了张量流，其中有 2 个 relu 隐藏层和一个带有 2 个单元的 softmax 输出层（每个类一个），损失函数是 categorical_crossentropy。
我使用了张量流
我也尝试使用网格搜索来优化超参数（尝试不同的配置），但我一直面临一个问题，即损失和验证损失曲线非常不稳定。每次运行模型时结果都会发生变化，并且曲线看起来不平滑或不一致。有时，即使我使用相同的超参数多次运行模型，它们也会显示出很大的波动。
我似乎无法获得像样的损失曲线或验证损失曲线，而且我不确定是什么导致了不稳定。我想知道这是否与模型的具体配置、数据有关，或者我是否可能在优化过程中忽略了某些东西。
有没有人遇到过类似的问题或对可以改进的地方有什么建议？任何建议都将不胜感激！
我如何才能找到完美的超参数？
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658087/help-with-simple-nn-model</guid>
      <pubDate>Sun, 01 Dec 2024 10:51:31 GMT</pubDate>
    </item>
    <item>
      <title>基于样本的矩估计</title>
      <link>https://stats.stackexchange.com/questions/658085/moment-estimate-based-on-sample</link>
      <description><![CDATA[
我试过这个问题，但很难解决积分以找到前两个矩。积分越来越大，所以我认为可能有更好的方法，一些属性可以用来快速解决问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/658085/moment-estimate-based-on-sample</guid>
      <pubDate>Sun, 01 Dec 2024 02:30:45 GMT</pubDate>
    </item>
    <item>
      <title>随机森林 R 帮助</title>
      <link>https://stats.stackexchange.com/questions/658084/random-forest-r-help</link>
      <description><![CDATA[我在 R 中有一个数据框，随机分为训练集 (779) 和测试集 (326)，两者都不平衡。在训练集中，我有 31% 的事件（我想要预测的事件）。我应用了 5 倍交叉验证。这是我使用的方法。有人能告诉我这是否是正确的方法吗（就 summaryfunction 而言，考虑不平衡等）？如何调整超参数？我读到 method=ranger 中不考虑 ntress。我该怎么办？
&lt;&quot;&quot;control &lt;- trainControl(method = &quot;cv&quot;, number = 5, classProbs = TRUE, summaryFunction = prSummary)
#根据类别不平衡定义类别权重
class_weights &lt;- c(&quot;No&quot; = 1, &quot;Yes&quot; = 535 / 244) print(class_weights)
#使用 ROC 作为权重度量来训练随机森林模型
#定义类别权重
class_weights &lt;- c(&quot;No&quot; = 1, &quot;Yes&quot; = nrow(train_data) / (2 * sum(train_data$Predictor== &quot;Yes&quot;)))
#默认模型----
set.seed(123) rf_default &lt;- train(Predictor ~ ., data = train_data[, c(features, &quot;Predictor&quot;)], method = &quot;ranger&quot;, metric = &quot;AUC&quot;, trControl = control, weights = ifelse( train_data$RECIST_first_progressors == &quot;Yes&quot;, class_weights[&quot;Yes&quot;], class_weights[&quot;No&quot;] # 为类别不平衡分配权重 ))
# 访问交叉验证结果
cv_results &lt;- rf_default$resample
# 打印每个折叠的结果
print(cv_results)
# 计算汇总统计数据
summary_stats &lt;- cv_results %&gt;%
summarise(
Mean_AUC =平均值（AUC），
SD_AUC = sd（AUC），
平均值_Precision = 平均值（Precision），
SD_Precision = sd（Precision），
平均值_Recall = 平均值（Recall），
SD_Recall = sd（Recall），
平均值_F1 = 平均值（F），
SD_F1 = sd（F）
）
#打印摘要统计信息
print(summary_stats)&quot;&quot;
我从交叉验证中获得了 77% 的平均 AUC，因此我认为该模型在训练中不能完美预测（我喜欢这一点，因为它可能意味着没有过度拟合）。但是，当我在完整的数据框（训练+测试）上训练模型以评估在训练测试中预测结果的差异（基本上是用条形图绘制）时，预测是完美的。怎么可能呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/658084/random-forest-r-help</guid>
      <pubDate>Sat, 30 Nov 2024 22:38:54 GMT</pubDate>
    </item>
    <item>
      <title>ADF 检验中 Rho 和 Tau 统计量的差异</title>
      <link>https://stats.stackexchange.com/questions/658081/difference-between-rho-and-tau-statistics-in-adf-test</link>
      <description><![CDATA[我需要使用ADF 检验，滞后 = 2检查几个利率时间序列的平稳性。
SAS 输出生成三种类型的检验统计数据：Rho、Tau 和 F.，用于三种类型的检验（趋势、单一均值和零均值）。我想问几个问题，因为它们在我的案例中显示的结果不同。

有人知道我应该如何选择使用哪种类型的检验，趋势、单一均值还是零均值？查看图表，我的时间序列没有强烈的趋势，但有一些时期有趋势。
更重要的是，Rho 和 Tau 统计数据有什么区别？如果它们相矛盾该怎么办？
对于滞后 2 的单一均值类型 ADF，应该使用什么？如果是趋势类型，该怎么办？

附言。
这篇论文本应解释这种差异
（Dickey, D. A. (2005). “时间序列模型中的平稳性问题。”）。
因此，据我了解，Rho 是标准化偏差检验。]]></description>
      <guid>https://stats.stackexchange.com/questions/658081/difference-between-rho-and-tau-statistics-in-adf-test</guid>
      <pubDate>Sat, 30 Nov 2024 21:10:05 GMT</pubDate>
    </item>
    <item>
      <title>计算仪器变化后的置信区间</title>
      <link>https://stats.stackexchange.com/questions/658079/calculating-confidence-intervals-with-a-change-in-the-instrument</link>
      <description><![CDATA[在工具变量研究中，我有结果（健康结果）的点估计和相应的置信区间。我还有工具的平均值和范围（给定人群一年内医务人员的就诊次数）。我必须计算如果工具发生变化，置信区间将如何变化。也就是说，如果医务人员的就诊次数发生变化，健康结果将如何变化。有人可以指导我如何计算吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658079/calculating-confidence-intervals-with-a-change-in-the-instrument</guid>
      <pubDate>Sat, 30 Nov 2024 20:17:53 GMT</pubDate>
    </item>
    <item>
      <title>不同打印方法导致的方差解释差异</title>
      <link>https://stats.stackexchange.com/questions/658082/discrepancies-in-explained-variance-depending-on-the-print-method</link>
      <description><![CDATA[在执行探索性因子分析时，我想查看因子的解释方差。这很简单，我打印了fa()方法的输出。可以得到与$loadings输出相同的汇总表，如下所示。问题是两个表中的解释方差有偏差。这是什么原因，是 psych 包中的错误吗？哪个输出是正确的？
library(psych)

fa_results &lt;- fa(df_sq1sq9, nfactors = 5, rotate = &quot;oblimin&quot;)
print(fa_results)
fa_results$loadings

请注意，我不是在谈论因子载荷，而是在下表中谈论 Cumulative var 行。差异出现在正交和斜向旋转的情况下，并且在斜向旋转的情况下，两个输出的偏差更大。因此，该示例以斜交旋转显示。
斜交旋转：
&gt;print(fa_results)

[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.45 1.50 1.07 1.05 0.60
比例方差 0.27 0.17 0.12 0.12 0.07
累积方差 0.27 0.44 0.56 0.68 0.74
解释比例 0.37 0.22 0.16 0.16 0.09
累积比例 0.37 0.59 0.75 0.91 1.00

因子相关性为 
MR1 MR3 MR5 MR2 MR4
MR1 1.00 0.59 0.64 -0.01 0.30
MR3 0.59 1.00 0.33 0.12 0.21
MR5 0.64 0.33 1.00 0.28 0.11
MR2 -0.01 0.12 0.28 1.00 -0.17
MR4 0.30 0.21 0.11 -0.17 1.00

斜轴旋转：
&gt;fa_results$loadings
[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.310 1.350 0.975 1.038 0.563
比例方差 0.257 0.150 0.108 0.115 0.063
累计Var 0.257 0.407 0.515 0.630 0.693

我也在 https://stats.stackexchange.com/questions/657692/exploratory-factor-analysis-oblique-rotation-variance-explained 中提出了这个问题作为更新]]></description>
      <guid>https://stats.stackexchange.com/questions/658082/discrepancies-in-explained-variance-depending-on-the-print-method</guid>
      <pubDate>Sat, 30 Nov 2024 11:55:31 GMT</pubDate>
    </item>
    <item>
      <title>对于满足 LLN 和 CLT 的非 IID 数据，EDF 是否收敛？</title>
      <link>https://stats.stackexchange.com/questions/657989/does-the-edf-converge-for-non-iid-data-that-satisfy-lln-and-clt</link>
      <description><![CDATA[对于 IID 数据，经验分布函数 (EDF) 已知会收敛，这是由于 Glivenko-Cantelli 定理，该定理保证 EDF 均匀收敛到真实累积分布函数 (CDF)。
如果数据是非 IID 的但仍满足大数定律 (LLN) 和中心极限定理 (CLT)：

EDF 还会收敛吗？
如果会，在什么类型的收敛下（例如，在概率上，弱收敛）？

寻找将 EDF 收敛推广到满足 LLN 和 CLT 的非 IID 数据的见解或参考。]]></description>
      <guid>https://stats.stackexchange.com/questions/657989/does-the-edf-converge-for-non-iid-data-that-satisfy-lln-and-clt</guid>
      <pubDate>Thu, 28 Nov 2024 16:28:34 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在研究一个重复测量数据集。该研究的目的是观察机构特征 (X) 对由于某种医疗状况 (Y) 导致的几家医疗机构的死亡人数的影响。Y 表示在跨越多年的时间段内每周测量的死亡人数。X 表示在整个研究过程中在多个时间点（每周、每季度、研究开始/结束）测量的连续/分类变量。变量 Y 是零膨胀的，并且由于在模型中包含太多预测因子而导致数值问题。
我的一组 X 变量 (u1、u2、...、un) 与一组其他变量 (v1、v2、...、vn) 相关。这使我无法在同一模型中同时建模 U（总共约 50 个）和 V（总共约 5 个）变量。因此，我对 U 变量进行了建模，并选择了对 Y 有显著影响的 U 变量子集。对于这个子集，我执行了 PCA，并在最终模型中使用了 PCA 分数和 V 变量。我相信这样做可以让它们（U 变量和 V 变量的 PCA 分数）彼此不相关，同时在估计 V 变量时会纳入 U 变量的净效应。
我的最终目标是获得与时间无关的 V 变量预测。
在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法涉及以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 之间的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除非数字变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不均等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    <item>
      <title>计算事件总数的置信区间</title>
      <link>https://stats.stackexchange.com/questions/657232/calculating-a-confidence-interval-for-a-sum-of-events</link>
      <description><![CDATA[我有一个包含一组事件的试验，很多次都没有发生任何事件。每个事件都有一定的量级，但事件的量级遵循合理的分布（正态分布）。
我拥有的：

使用比例检验发现事件发生的概率，置信区间（事件率）为 95%
使用 t 检验对所有事件得出的事件量级的 95% 置信区间

我想要找到的

在规模为 n 的试验中，所有事件总和的 95% 置信区间。

示例：
假设我试图估计如果有 n 位顾客进来，商店将赚多少钱。我收集了有关客户购买任何东西的可能性的数据，以及任何一次购买的平均金额的数据。
因为购买金额的分布极其不正常（你有一群客户如果商店没有购买任何东西，则对所有客户进行 t 检验或 z 检验会违反正态性假设。更糟糕的是，商店很小，因此购买的数量很少（~10），而客户数量较大，但仍然不多（~50）。
如果有 n 个客户进来，有没有办法获得产生的收入的 95% 置信区间？
更新：
使用 MATLAB 代码更新。
我能够使用以下参数运行一些模拟
购买概率 25% STD 0.05
平均购买金额 100 STD 10
客户：50
模拟 50,000 次后，每位客户的收入的 95% 置信区间为 12.41 至 38.65。

代码：
rng(&#39;default&#39;) % 可重复性
numberofTrials = 50000;
trialSize = 50;
means = zeros(1,numberofTrials);
prob = normrnd(.25,0.05,[1,numberofTrials]);

parfor meanindex = 1:试验次数
valuepool = normrnd(100,10,[1,trialSize]);
trial = zeros(1,trialSize);
currentValIndex = 1; 
for eventindex = 1:trialSize
cause = rand(1);
if cause &lt; prob(meanindex)
trial(eventindex) = valuepool(currentValIndex);
currentValIndex = currentValIndex + 1;
end
end
means(meanindex) = mean(trial);
end
means = rot90(means);
%pd = fitdist(means, &#39;Rayleigh&#39;)
%pd = fitdist(means, &#39;kernel&#39;)
%pd = fitdist(means, &#39;Normal&#39;)
%qqplot(means, pd)
hist = histogram(means);
histfit(means, hist.NumBins, &#39;Normal&#39;)
ylabel(&quot;频率&quot;)
xlabel(&quot;平均购买金额&quot;)
quantile(means,[.05, .95])
]]></description>
      <guid>https://stats.stackexchange.com/questions/657232/calculating-a-confidence-interval-for-a-sum-of-events</guid>
      <pubDate>Thu, 14 Nov 2024 02:17:22 GMT</pubDate>
    </item>
    <item>
      <title>以不同时间频率收集变量的纵向回归模型？</title>
      <link>https://stats.stackexchange.com/questions/655840/longitudinal-regression-models-with-variables-collected-at-different-time-freque</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655840/longitudinal-regression-models-with-variables-collected-at-different-time-freque</guid>
      <pubDate>Wed, 16 Oct 2024 05:18:50 GMT</pubDate>
    </item>
    <item>
      <title>如果分类变量保留在 R 中的最终模型中，那么为什么事后分析表明水平没有差异？</title>
      <link>https://stats.stackexchange.com/questions/655810/if-the-categorical-variable-is-retained-in-my-final-model-in-r-then-why-does-th</link>
      <description><![CDATA[我正在使用 R 中的 anova() 函数进行模型选择，并且我的分类变量在我的最终模型中得到了保留，但是当我使用 emmeans() 函数进行事后分析时，它告诉我水平没有差异。这是什么意思？
我使用 R 软件，我正在研究一种鱼的身体状况在三种河流中的变化：保护性、轻微城市化和高度城市化。每个类别都有一个重复，这意味着我有 2 条保护性河流、2 条轻微城市化河流和 2 条高度城市化河流，这意味着“河流”是一个随机因素，“城市化类别”是我的固定因素和具有 3 个级别的预测变量。在使用 anova() 函数在 R 中执行模型选择时，分类变量“类别”得到保留：
`#它是一个线性混合模型，因为条件呈正态分布
&gt; lmm.1 &lt;- lmer(条件 ~ 城市化类别 + (1|河流), 数据 = 鱼) 
&gt; lmm.null &lt;- lmer(条件 ~ 1 + (1|河流), 数据 = 鱼) 
&gt; anova(lmm.null, lmm.1)
使用 ML（而不是 REML）重新拟合模型
数据：鱼
模型：
lmm.null：条件 ~ 1 + (1 | 河流)
lmm.1：条件 ~ 城市化类别 + (1 | 河流)
npar AIC BIC logLik 偏差 Chisq Df Pr(&gt;Chisq)
lmm.null 3 -214.42 -205.37 110.21 -220.42
lmm.1 5 -219.80 -204.71 114.90 -229.80 9.3806 2 0.009184 **
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1`

`
我忘记在我的问题中包含我的模型摘要，所以这里是：
&gt; summary(lmm.1)
REML [&#39;lmerMod&#39;] 拟合的线性混合模型
公式：条件 ~ 城市化类别 + (1 | 河流)
数据：鱼

收敛时的 REML 标准：-214.3

缩放残差：
最小 1Q 中位数 3Q 最大
-2.65967 -0.54776 -0.07734 0.56748 2.79995

随机效应：
组名称方差标准差。
河流（截距）0.001965 0.04432 
残差 0.012381 0.11127 
观测数：151，组：河流，6

固定效应：
估计标准差。误差 t 值
（截距） -0.12808 0.04154 -3.084
category.of.urbanizationslightly 0.15972 0.05376 2.971
category.of.urbanizationvery 0.17063 0.05432 3.141

固定效应相关性：
（截距） ctgr.d.rbnzcp
ctgr.d.rbnzcp -0.773 
ctgr.d.rbnzcm -0.765 0.591 

我的 p 值为 0.009184，这意味着城市化类别是一个重要的预测因素，我预计分类变量的至少一个级别会与其他级别不同。然而，当尝试进行事后分析时，我调用了 emmeans() 函数，R 说所有级别都没有差异，因为 p 值都高于 0.05：
`&gt; emmeans(lmm.1，成对 ~ category.of.urbanization)
已注册的 S3 方法被“broom”覆盖：
方法来自 
tidy.glht jtools
tidy.summary.glht jtools
$emmeans
category.of.urbanization emmean SE df lower.CL upper.CL
保留 -0.1281 0.0441 3.42 -0.2592 0.00304
略微城市化 0.0316 0.0341 2.20 -0.1030 0.16632
非常城市化 0.0425 0.0350 2.43 -0.0852 0.17032

自由度方法：kenward-roger
使用的置信度：0.95

$contrasts
对比估计 SE df t.ratio p.value
保留 - 略带城市化 -0.1597 0.0558 2.83 -2.863 0.1324
保留 - 非常城市化 -0.1706 0.0563 2.95 -3.028 0.1123
略带城市化 - 非常城市化 -0.0109 0.0489 2.32 -0.223 0.9733

自由度方法：kenward-roger
P 值调整：用于比较 3 个估计值的 Tukey 方法`

请问，这是什么意思？预测变量如何显著，但水平没有差异？我有 151 条鱼，所以我的数据和观察值数量不是很低。如果我犯了拼写错误，我很抱歉，英语不是我的母语。]]></description>
      <guid>https://stats.stackexchange.com/questions/655810/if-the-categorical-variable-is-retained-in-my-final-model-in-r-then-why-does-th</guid>
      <pubDate>Tue, 15 Oct 2024 13:48:27 GMT</pubDate>
    </item>
    <item>
      <title>证明 $\mathbb{E} (|X-Y|) = 0 \implies X^2 = Y^2$</title>
      <link>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</link>
      <description><![CDATA[$\boxed{\text{设 } X,Y \text{ 为任意随机变量。证明如果 } \mathbb{E}(​​|X-Y|) = 0，\text{则 } X^2 = Y^2。}$
我们有 $\mathbb{E}(​​|X-Y|) = 0$，我认为如果我能以某种方式证明 $X=Y$，那么它直接意味着 $X^2 = Y^2$，但我不知道如何实现。
附言：这不是任何形式的家庭作业，我只是在大学概率课程的往期考试中看到了这个问题，想尝试一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</guid>
      <pubDate>Wed, 09 Oct 2024 19:54:07 GMT</pubDate>
    </item>
    <item>
      <title>按分布和收敛顺序收敛</title>
      <link>https://stats.stackexchange.com/questions/567308/converge-in-distribution-and-order-of-convergence</link>
      <description><![CDATA[我读过一本关于“分布收敛”的计量经济学教科书，发现了以下句子。
\begin{equation}
Z_{N} \xrightarrow{d} Z\implies Z_{N} = {O_p}(1) 
\end{equation&gt;
也就是说，如果一个随机变量$Z_n$在分布上收敛到$Z$，$Z_N$的概率是有界的。
教科书上说这很容易验证。但是，我现在还搞不清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/567308/converge-in-distribution-and-order-of-convergence</guid>
      <pubDate>Thu, 10 Mar 2022 04:23:40 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 GLM 中的条件平均值？</title>
      <link>https://stats.stackexchange.com/questions/552908/how-to-compute-conditional-mean-in-glm</link>
      <description><![CDATA[我已经了解了 GLM 的基本知识。我知道为什么 GLM 由预测器、链接函数和分布组成。但我不知道条件均值如何与分布联系起来。
以泊松回归为例，我们有 $\log(\mu_i) = \beta_0 + \beta_1x_i$，其中 $\mu_i$ 是条件均值。
如何根据观测值 $y_i$ 和泊松分布计算出 $\mu_i$？
此外，泊松分布中的参数 $\lambda$ 是如何计算的？]]></description>
      <guid>https://stats.stackexchange.com/questions/552908/how-to-compute-conditional-mean-in-glm</guid>
      <pubDate>Fri, 19 Nov 2021 18:38:24 GMT</pubDate>
    </item>
    <item>
      <title>使用随机森林中的交叉验证进行超参数调整——测试集 AUC 高于交叉验证 AUC</title>
      <link>https://stats.stackexchange.com/questions/542117/hyper-parameter-turning-using-cross-validation-in-random-forest-test-set-auc</link>
      <description><![CDATA[我正在训练一个随机森林模型来预测某个结果。
我将数据分成 80% 的训练集和 20% 的测试集。在训练数据中，我使用网格搜索来选择最佳超参数，基于哪些超参数在此训练集中产生最高的 5 倍交叉 AUC。
然后，我使用这些超参数在训练集上训练模型，并确定测试集上的 AUC。
我还有第二个外部验证集，我也在其上确定了 AUC。
以下是我的结果：
80% 训练集 AUC：89（95% CI：85-92）
80% 训练集中的 5 倍交叉验证 AUC：64
20% 测试集 AUC：80（95% CI：71-89）
外部测试集 AUC：70（95% CI：54-85）
我担心的是 5 倍交叉验证在训练集中的 AUC 比其他 AUC 低得多。我查看了几种资源，它们都表明交叉验证 AUC 应该仅用于选择超参数，而不是用于模型评估。
我应该担心/不信任这些结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/542117/hyper-parameter-turning-using-cross-validation-in-random-forest-test-set-auc</guid>
      <pubDate>Wed, 01 Sep 2021 01:46:20 GMT</pubDate>
    </item>
    </channel>
</rss>