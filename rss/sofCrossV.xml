<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 17 Jan 2025 21:14:21 GMT</lastBuildDate>
    <item>
      <title>如何根据诊断图改进线性模型</title>
      <link>https://stats.stackexchange.com/questions/660185/how-to-improve-linear-model-based-on-diagnostic-plots</link>
      <description><![CDATA[我一直在处理包含五个变量和一个响应的数据集，如下所示：
.CSV 文件
使用 Python，我从以下代码开始：
import statsmodels.api as sm
import numpy as np
X = subset[[&#39;X1&#39;, &#39;X2&#39;, &#39;X3&#39;, &#39;X4&#39;]]
y = subset[&#39;Y&#39;]
X = sm.add_constant(X)
model = sm.OLS(y, X)
result = model.fit()
plt.figure(figsize=(8, 6))
plt.scatter(fitted_values, residuals, color=&#39;blue&#39;, edgecolors=&#39;k&#39;, alpha=0.7)
plt.axhline(y=0, color=&#39;red&#39;, linestyle=&#39;--&#39;)
plt.title(&#39;残差 x 预测值&#39;)
plt.xlabel(&#39;预测值&#39;)
plt.ylabel(&#39;残差&#39;)
plt.show()

给出模型摘要：

我不知道如何处理“残差 x 预测图”的结果。在探索性分析过程中，我发现这些变量与 Y 有中等相关性，因此我选择它们来构建初始模型。从该图中，我们可以说方差不是恒定的吗？此外，从这种模式中，我们可以获得有关如何改进模型的任何见解吗？

我尝试对 X 变量应用对数或 box-cox 变换，但它并没有改变变量散点图的可视化。我考虑过应用加权最小二乘法，例如，对 Y 大于 100 的位置赋予较低的权重，但图并没有改善，模式几乎相同。或者如果它真的是一个非线性问题，我想如果一些机器学习方法在这里可以更好地发挥作用，但我首先想尝试基本方法。
如果有人能提供一些想法/代码来处理这种情况，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660185/how-to-improve-linear-model-based-on-diagnostic-plots</guid>
      <pubDate>Fri, 17 Jan 2025 20:39:09 GMT</pubDate>
    </item>
    <item>
      <title>评估混合模型聚类和分类的准确性</title>
      <link>https://stats.stackexchange.com/questions/660184/evaluating-accuracy-of-mixture-model-clustering-and-categorisation</link>
      <description><![CDATA[我正在运行混合模型，我没有自由参数，我只是让它评估给定数据点属于一个集群的可能性。另外，我有一个关于这些值的基本事实，但模型从未见过。我想测试模型是否成功预测了数据点集群的可能性。您建议哪些指标最适合此目的？
交叉熵 RMSE MAE 和其他指标是好的指标吗？
（我知道经典模型比较 - 例如，BIC、AIC、WAIC CV_LOO 等等，但我不是在测试我的模型是否是最佳模型，而是在测试它是否能够预测聚类）]]></description>
      <guid>https://stats.stackexchange.com/questions/660184/evaluating-accuracy-of-mixture-model-clustering-and-categorisation</guid>
      <pubDate>Fri, 17 Jan 2025 19:23:57 GMT</pubDate>
    </item>
    <item>
      <title>帮助理解吉布斯采样问题？</title>
      <link>https://stats.stackexchange.com/questions/660183/help-understanding-gibbs-sampling-problem</link>
      <description><![CDATA[我正在努力理解一个特定的问题，并设计了一个类似的场景
如果我要分析三组就读寄宿学校的学生，每组学生分别在两个教室中的一个，并住在三个宿舍中的一个，那么这些数据可以可视化为如下所示的有向无环图。
如果一名教职员工试图找出每个组、房间和宿舍对特定学生结果的影响，他们将如何做，以及可以以何种确定性收集这些信息？
假设成绩遵循某种偏态分布$P(\Theta_G = \theta_G, \Theta_R = \theta_R, \Theta_D = \theta_D)$其中$\theta_G\in\{1,2,3\}$
这个过程中边际是如何计算的，是否必须使用吉布斯抽样，还是可以通过代数过程，如何完成？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660183/help-understanding-gibbs-sampling-problem</guid>
      <pubDate>Fri, 17 Jan 2025 18:53:38 GMT</pubDate>
    </item>
    <item>
      <title>季节性虚拟变量回归。为什么我们要在这个回归中使用时间趋势？或者说，在什么情况下我们应该使用时间趋势？</title>
      <link>https://stats.stackexchange.com/questions/660180/regression-with-seasonal-dummies-why-do-we-use-time-trend-in-this-regression-o</link>
      <description><![CDATA[我的导师希望我用季节性虚拟变量进行回归分析。
我有 DPPI 指数（土耳其国内生产者价格指数），这是月度数据。
首先，我需要用截距项和 11 个虚拟变量进行回归分析。
其次，我需要用 12 个虚拟变量进行不带截距项的回归分析。
在这两种情况下，我都应该包括时间趋势项吗？在哪种情况下，或者为什么包括时间趋势项？
或者，我应该同时使用和不使用时间趋势项进行这两个回归分析吗？
我的最后一个问题是我需要分析残差。为此，我应该对残差应用哪些测试或图？
请与我分享您的想法。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660180/regression-with-seasonal-dummies-why-do-we-use-time-trend-in-this-regression-o</guid>
      <pubDate>Fri, 17 Jan 2025 18:42:39 GMT</pubDate>
    </item>
    <item>
      <title>在高斯 - 马尔可夫假设中，给定预测变量的误差条件期望等于协方差[重复]</title>
      <link>https://stats.stackexchange.com/questions/660178/conditional-expectation-of-errors-given-predictors-equals-covariance-in-gauss-ma</link>
      <description><![CDATA[在此视频的 2:08 处，谈到 OLS 中的高斯-马尔可夫假设，Ben Lambert 说$\mathbb{E}(​​u_i|x_i)=0$ 等同于$Cov(u_i, x_i)=0$，用数学符号表示为$\mathbb{E}(​​u_i|x_i)=0 \Leftrightarrow Cov(u_i, x_i)=0$。
这是为什么？
你如何证明这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/660178/conditional-expectation-of-errors-given-predictors-equals-covariance-in-gauss-ma</guid>
      <pubDate>Fri, 17 Jan 2025 18:35:59 GMT</pubDate>
    </item>
    <item>
      <title>使用对数链接解释 GLM 模型中的系数</title>
      <link>https://stats.stackexchange.com/questions/660177/interpretation-of-the-coefficients-in-a-glm-model-using-the-log-link</link>
      <description><![CDATA[当在 GLM 设置中使用对数链接时，目标均值和线性预测器通过以下方式关联：
$$
\mu = e^{\beta_0}\prod_{i=1}^p e^{\beta_i X_i}
$$
我的学习手册说，当 $X_j$ 是具有系数 $\beta_j$ 的数字预测器时，我们可以用以下方式描述 $X_j$ 和 $\mu$ 之间的关联

当所有其他变量保持不变时，$X_j$ 的单位增加与乘法增加相关目标均值增加 $e^{\beta_j}$ 倍，即
$$
\text{new} \ \mu = e^{\beta_j} \times \ \text{old} \ \mu \tag{1}
$$

我不确定作者是如何得出这个解释的。我认为这个过程看起来像是这样的
$$
\frac{\partial \mu}{\partial X_j} = \beta_j \times e^{\beta_0}\prod_{i=1}^p e^{\beta_i X_i} = \beta_j \times \text{old} \ \mu \tag{2}
$$
所以
$$
\text{new} \ \mu = \text{old} \ \mu + \frac{\partial \mu}{\partial X_j} = \text{old} \ \mu + \beta_j \times \text{old} \ \mu = (\text{old} \ \mu )(1 + \beta_j) \tag{3}
$$
显然，$(1)$ 和 $(3)$ 完全不同，所以我不确定我的错误是什么。我在 $(2)$ 或 $(3)$ 中的工作是否不正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/660177/interpretation-of-the-coefficients-in-a-glm-model-using-the-log-link</guid>
      <pubDate>Fri, 17 Jan 2025 18:31:37 GMT</pubDate>
    </item>
    <item>
      <title>条件与边际：概率、可能性和模型</title>
      <link>https://stats.stackexchange.com/questions/660175/conditional-vs-marginal-probability-likelihood-and-models</link>
      <description><![CDATA[我很难理清这些想法。
1) 条件概率与边际概率：这是我最了解的一个，它依赖于概率的基本定律。
如果我们有两个连续随机变量 $X$ 和 $Y$。
$X$ 的边际概率密度函数，表示为 $f_X(x)$，是通过对 $Y$ 所有可能值的联合 PDF 进行积分获得的：
$$f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) dy$$
给定 $Y=y$，$X$ 的条件概率密度函数：
$$f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}$$
$$f_{X|Y}(x|y) = \frac{f_{Y|X}(y|x)f_X(x)}{f_Y(y)}$$
到目前为止一切正常。
2) 条件似然与边际似然：这个我也理解，因为它是一个第一部分的扩展。
我可以定义一个联合似然函数$L(\theta, \phi|X)$为：
$$L(\theta, \phi|X) \propto f_X(X|\theta, \phi)$$
从这里，边际似然和条件似然可以写成：
$$L_M(\theta|X) = \int_{-\infty}^{\infty} L(\theta, \phi|X) d\phi$$
$$L_C(\theta|X,\phi) = L(\theta, \phi|X)$$
3) 条件模型与边际模型（第 1 部分） 事情开始让我感到困惑。我以前听说过“条件和边际”这两个术语用于混合效应回归模型。例如，在纵向/聚类模型的背景下，我听说过以下内容：

像 GEE（一般估计方程）这样的回归框架被称为边际模型，因为它们估计整个总体的边际平均值。虽然 GEE 能够在估计阶段使用数据中存在的聚类级相关性，但最终模型无法在聚类级别提供任何统计推断。 GEE 只能描述整个人口层面上正在发生的事情。

$$ \text{logit}(P(Y_{ij} = 1|X_{ij})) = X_{ij}\beta^* $$

另一方面，混合/随机效应等回归框架被称为条件模型，因为它们可以通过其随机效应结构在集群级别提供统计推断。举例来说，聚类级别均值可以看作是条件均值（即以聚类为条件）。

$$ \text{logit}(P(Y_{ij} = 1|X_{ij}, b_i)) = X_{ij}\beta + b_i $$
我认为在我看来这一切都是合理的。
4) 条件模型与边际模型（第 2 部分）：我感到困惑的根源来自这里：https://en.wikipedia.org/wiki/Conditional_logistic_regression。虽然我并没有完全理解这一点，但这似乎是一种固定效应回归，我们不再对估计集群级别效应感兴趣。相反，我们似乎根据某些集群级别信息集来匹配人员，以避免变量混淆。这是维基百科上关于条件逻辑回归的一个示例 - 这次我们不是估计聚类级别的影响（就像在随机影响中所做的那样），而是对它们进行匹配以控制它们的影响：
$$P(Y_{i1}=1, Y_{i2}=0|X_{i1},X_{i2}, Y_{i1}+Y_{i2}=1) = \frac{\exp(\beta^TX_{i1})}{\exp(\beta^TX_{i1}) + \exp(\beta^TX_{i2})}$$
因此，似乎在所有这些情况下，被条件化的术语及其条件化方式都会发生变化。
我说得对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660175/conditional-vs-marginal-probability-likelihood-and-models</guid>
      <pubDate>Fri, 17 Jan 2025 17:36:04 GMT</pubDate>
    </item>
    <item>
      <title>采用交错干预且无对照组的混合效应中断时间序列分析</title>
      <link>https://stats.stackexchange.com/questions/660174/mixed-effects-interrupted-time-series-analysis-with-staggered-intervention-and-n</link>
      <description><![CDATA[我有在不同时间点在不同县（集群）实施的干预措施的数据。我该如何评估干预措施的影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/660174/mixed-effects-interrupted-time-series-analysis-with-staggered-intervention-and-n</guid>
      <pubDate>Fri, 17 Jan 2025 17:20:45 GMT</pubDate>
    </item>
    <item>
      <title>如何用 SE 和 P 值计算每 100,000 个比率之间的差异</title>
      <link>https://stats.stackexchange.com/questions/660173/how-to-calculate-the-difference-between-2-rates-per-100-000-with-se-and-p-value</link>
      <description><![CDATA[我有一个数据集，其中包含每年记录的每 100,000 人口年龄调整后的死亡率及其针对特定疾病的标准误差 (SE)。从 CDC Wonder 数据库 中提取。
我旨在通过计算差异、构建置信区间 (CI) 和确定此差异的 p 值来比较两个特定年份之间的死亡率。
此外，我旨在通过以下方式计算相对变化率：
相对变化 = (Rate_year_2 - Rate_year_1) / Rate_year_2
这在统计上合适吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660173/how-to-calculate-the-difference-between-2-rates-per-100-000-with-se-and-p-value</guid>
      <pubDate>Fri, 17 Jan 2025 16:46:06 GMT</pubDate>
    </item>
    <item>
      <title>伪似然与似然的比较</title>
      <link>https://stats.stackexchange.com/questions/660172/pseudolikelihood-compared-to-likelihood</link>
      <description><![CDATA[假设我们有一个离散多元概率分布，其密度$f_{\theta}(X=(x_1,\ldots,x_n))=\frac{g_{\theta}(X=(x_1,\ldots,x_n))}{Z}$取决于某个参数$\theta$。我特意以这种形式将其写出，以表示 Z 是难以计算的归一化常数（它也可能依赖于$\theta$）。这种分布的伪似然函数（为简单起见，针对单个数据点）是否定义为：
$$
PL_{\theta}(X=(x_1,\ldots,x_n)) = \prod_{i}f_{\theta}(X_i=x_i | X_j=x_j, i \neq j)
$$
如果是这样，则由此得出的公式在我看来有点奇怪，因为：
$$
= \prod_{i}\frac{g_{\theta}(X)}{\sum_{X_i=a}g_{\theta}(X_1=x_1,\ldots,X_i=a,\ldots)}
$$
调用分母 $Z_i(X)$ 可得到：
$$
\log(PL_{\theta}(X=(x_1,\ldots,x_n))) = n \log(g_{\theta}(X)) - \sum_i \log( Z_i(a))
$$
而真实可能性为
$$
\log(L_{\theta}(X=(x_1,\ldots,x_n))) = \log(g_{\theta}(X)) - \log(Z)
$$
我不知道为什么伪对数可能性可以替代对数可能性。我确实知道计算起来比可能性容易得多，但我无法理解为什么这是一个可接受的估计值。原始文章（格点数据的统计分析）在这方面没有太大帮助，维基百科上的文章也很简短。我知道现在人们可能更喜欢蒙特卡洛方法，但我仍然想了解一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/660172/pseudolikelihood-compared-to-likelihood</guid>
      <pubDate>Fri, 17 Jan 2025 16:25:55 GMT</pubDate>
    </item>
    <item>
      <title>t 检验/z 检验的分布假设是什么？是关于总体、样本、样本均值还是检验统计量？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660170/what-are-the-distributional-assumptions-of-t-test-z-test-pertaining-to-is-it-ab</link>
      <description><![CDATA[我一直认为，t 检验、z 检验和一般线性模型的正态性假设与残差的正态性有关，不一定与样本的正态性有关。
但是，我最近听到几个人保证，由于中心极限定理，A/B 测试中的大多数数值结果都可以在样本量 (N) 足够大的情况下用 t 检验建模。我理解 CLT 与样本均值的抽样分布有关，在足够高的 N 下接近正态性，所以我认为在足够大的 N 下使用 t 检验是没有道理的，因为这是为样本建模的，我认为 t 检验的正态性分布假设与残差有关。但是，我听说 t 检验在足够大的 N 下可以很稳健。
我还知道 Z 检验通常用于比较比例。我理解这也是由于 CLT，因为虽然比例是二项式数据的平均值，但如果您抽样足够多的比例，它将接近正态性。但是，此数据的样本分布和总体分布（例如点击率）将是二项式的。 Z 检验如何适用于二项式样本数据？
同时，网上关于 t 检验对正态性的假设的描述到处都是：

样本数据呈正态分布
样本数据呈正态分布
样本均值呈正态分布
样本数据呈正态分布
样本均值呈正态分布
我也读过检验统计量的正态性，但我认为这相当于指样本的正态性均值。

这让我有几个问题：

t 检验/z 检验的假设是否与样本正态性、总体正态性或样本均值/检验统计量的正态性有关？
如果 t 检验的假设也与上述之一有关，那么它是否也与残差的正态性有关？
如何证明 Z 检验用于比较二项分布或比例？样本数据和总体数据呈二项分布，但根据 CLT，样本均值将接近正态性。我认为应该对此类数据使用二项逻辑回归，因为它是二项数据。
t 检验是一般线性模型的一个特例。我一直认为线性模型的假设是关于残差的正态性，而不是其他东西。如果 t 检验涉及样本均值/检验统计量的正态性，这是否也意味着在足够大的 N 下，一般线性模型对于非正态分布的样本也是合理的（例如，点击次数、任务时间等）？
如果 Z 检验或 T 检验是关于样本均值的正态性，那么在足够大的 N 下进行 Z 检验或 T 检验的合理性对我来说仍然很困惑。如果样本 N 很大，那么它就是一个均值。但 CLT 不是关于对样本均值的重复抽样吗？在抽取超过 1,000 或 1,000,000 个样本均值后，无论原始总体样本分布如何，抽样分布都会近似为正态分布？我不清楚更高的样本量如何确保你可以对非正态样本数据进行 t 检验或 z 检验。

感谢您的任何见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/660170/what-are-the-distributional-assumptions-of-t-test-z-test-pertaining-to-is-it-ab</guid>
      <pubDate>Fri, 17 Jan 2025 16:06:56 GMT</pubDate>
    </item>
    <item>
      <title>一致性检验：p 值较低是否正常？[重复]</title>
      <link>https://stats.stackexchange.com/questions/660168/consistency-check-is-it-normal-to-have-a-low-p-value</link>
      <description><![CDATA[我正在使用 kruskal-wallis 检验来检查不同类型的群体之间是否存在差异，在获得显著结果后，我进行了事后检验并获得了较低的 p 值。关于每个组的样本是这样的：


我的问题是，得到这些低 p 值是正常的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660168/consistency-check-is-it-normal-to-have-a-low-p-value</guid>
      <pubDate>Fri, 17 Jan 2025 14:56:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Mercer 定理总是被引用于核学习而不是 Moore-Aronszajn</title>
      <link>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</link>
      <description><![CDATA[为什么在大多数关于核技巧的解释中，Mercer 定理都用作依据？
我们能否用 Moore-Aronszajn 来证明这一点，该定理不将紧致性假设置于 $X$ 和 $k$ 连续性上？
编辑：
那么，核技巧背后的想法是，我们能够计算某个希尔伯特空间 $H$ 中的内积，而不必将数据嵌入该空间，因为 $k(x,x&#39;) = \langle \phi(x), \phi(x&#39;) \rangle_{H}$，对于某个 $\phi : X \mapsto H$
现在，经常引用 mercer 定理来证明这样的 $\phi$ 存在。然而，通过 Moore-Aronszajn 定理，我们知道对于 p.d. 核 $k$，特征图 $\phi_{H_k}: X \mapsto H_k = \mathbb{R}^X$，其中 $\phi_{H_k}(x) = k(x,\cdot)$ 满足 $k(x,x&#39;) = \langle \phi(x)_{H_k}, \phi_{H_k}(x&#39;) \rangle_{H_k}$。那么，为什么 Mercer 经常被引用呢？此外，有些 p.d. 核不是连续的，因此无法通过 Mercer 定理进行论证。]]></description>
      <guid>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</guid>
      <pubDate>Fri, 17 Jan 2025 11:39:14 GMT</pubDate>
    </item>
    <item>
      <title>变换与顺序有关的分布</title>
      <link>https://stats.stackexchange.com/questions/660157/transforming-a-distribution-where-the-order-matters</link>
      <description><![CDATA[我有一组 $E = \{X_{ij}\}$，其中 $1 \leq i &lt; j \leq n$，s.t. $|E| = \binom{n}{2}$。$X_{ij}$ 在 $\sim [0,1]$ 内都是独立同分布的。这些是完全加权图的边。
假设我选择一个顶点$z$并根据此处中描述的规则将其与相关边一起移除，从而获得一个较小的$E&#39;$。为了提供更多背景信息，我删除了 $n-1$ 条边，其中 2 条边取决于图的其余部分（删除顶点 $p$ 和 $q$ 的最小值和最大值 此处 会更改这两个顶点的新的最小值和最大值）。因此，$E&#39;$ 取决于所选的顶点，并且分布会因此而改变。
由于我有兴趣保留这些值的顺序（该属性在后续步骤中保持其顺序是充分且必要的），我可以放宽这种依赖关系并使用此处描述的参数对剩余值应用非线性单调变换，并得出结论 $E&#39;$ 仍将呈均匀分布吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660157/transforming-a-distribution-where-the-order-matters</guid>
      <pubDate>Fri, 17 Jan 2025 11:37:35 GMT</pubDate>
    </item>
    <item>
      <title>日食是否减少了新冠肺炎死亡人数？</title>
      <link>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</link>
      <description><![CDATA[我在 R 中模拟了一些现实数据，这些数据显示了 Covid-19 死亡人数随时间的变化情况，以及日食（2024 年 4 月 8 日）发生前的天数：

如果有人不太了解，仅从数据来看，可能会认为日食是降低 Covid 死亡人数的原因。此外，有人可以拟合回归模型，该模型甚至可能很好地拟合数据。
我读到过，我们在统计学中拥有所有这些复杂的技术，例如差异-差异、回归不连续性、合成控制、工具变量、倾向得分匹配等 - 所有这些方法旨在在某种程度上找出我们是否能够真正得出结论，统计模型的结果忠实地代表了自然（例如因果关系与联想关系）。
但在某种程度上，我们在决定将哪些变量纳入统计模型时是否只是使用常识？]]></description>
      <guid>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</guid>
      <pubDate>Fri, 17 Jan 2025 05:13:01 GMT</pubDate>
    </item>
    </channel>
</rss>