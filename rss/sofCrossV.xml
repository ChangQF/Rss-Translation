<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 02 May 2024 09:14:53 GMT</lastBuildDate>
    <item>
      <title>纵向设计中的加权程序</title>
      <link>https://stats.stackexchange.com/questions/646336/weighting-procedure-in-longitudinal-design</link>
      <description><![CDATA[我目前正在尝试弄清楚该怎么做，但似乎找不到合适的解决方案。我的问题如下：我有纵向设计。对于每一天，我都有一个变量说明事件是否发生（1）或未发生（0），以及一个以 5 点李克特量表回答的变量。该评估主要通过电话完成（生态瞬时评估）。不幸的是，有时手机坏了，参与者用纸笔表格填写不同的变量。这意味着现在我只对少数参与者进行了几天的评估，没有电话，只有纸质评估。我想看看是否可以将这些评估方法合并到 1 个数据集中。这意味着：根据评估方法，问题的答案是否有所不同？但我有几个困难：首先，我的纸质评估屈指可数。其次，我有 4 个组，它们的评估期长度不同（有些有 16 天，有些有 24 天）。第三，我为参与者安排了不同的缺席天数。有的电话评估只缺失一两天，有的甚至更长。当手机丢失时，只有少数人有纸质表格，因此该时期的纸质表格也不完整。
我想看看逆概率加权是否可行。我知道，在对合并样本进行加权后，我可以使用一般线性模型（当我计算所有天的概率或平均值时）或广义估计方程（当每天都有单个条目时）。
我想知道这是否正确，以及在使用加权程序时是否有其他可能性来比较评估方法。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646336/weighting-procedure-in-longitudinal-design</guid>
      <pubDate>Thu, 02 May 2024 09:00:25 GMT</pubDate>
    </item>
    <item>
      <title>模拟随机过程以检查平稳性</title>
      <link>https://stats.stackexchange.com/questions/646335/simulation-of-random-processes-to-check-stationarity</link>
      <description><![CDATA[我想知道这是否是一种有效的方法：
我想通过模拟验证某些随机过程不是弱平稳的（恒定均值、协方差取决于滞后、有限方差）；不一定采用非常严格的程序，但至少可以建立直觉。
我知道使用像 ADF 这样的单位根检验，我不确定它是否一定是平稳性的综合检验。
python 中的 Statsmodel 具有允许您为 arma 模型提供参数并生成时间序列的函数。对于每个过程，我想生成 10,000 个长度为 1000 的时间序列，季节性较短，例如每 5 个点。
（这是否是查看随机过程属性、从生成器生成集合并查看其属性的有效起点？）
我正在尝试的一些过程包括

纯季节性 ARMA（无单位根）
混合季节性 ARMA（无单位根）
从 ARMA 生成确定性正弦波和一系列，将它们相加。
从 ARMA 生成确定性正弦波和一系列，将它们相乘。

然后我可以进行集合均值计算以查看均值是否恒定；如果不是恒定的，则可能不是弱平稳的。
如果均值看起来是恒定的，那么我会查看自协方差；但我不确定这将如何运作。 计算序列自协方差的公式似乎取决于序列弱平稳的假设，但这正是我试图证明的。

回到均值，我确实看了一些例子：
对于确定性正弦波+平稳 AR(1) 的情况，集合均值往往看起来像这样，这显然不是整个时间的恒定均值。


但对于没有单位根的纯季节性 ARMA；
如果我有
$x_{t}=0.7x_{t-5}+w_{t}, \sigma=1$
或
$x_{t}=0.7x_{t-7}+w_{t}, \sigma=1$
集合均值看起来像下面的图表，看起来好像在变化，但值非常小；有没有什么办法可以判断呢？

]]></description>
      <guid>https://stats.stackexchange.com/questions/646335/simulation-of-random-processes-to-check-stationarity</guid>
      <pubDate>Thu, 02 May 2024 08:22:33 GMT</pubDate>
    </item>
    <item>
      <title>如何在统计检验中进行 p 调整？</title>
      <link>https://stats.stackexchange.com/questions/646333/how-do-i-do-the-p-adjustement-in-statistical-tests</link>
      <description><![CDATA[背景：一项关于哪种类型的面包和/或馅料最吸引蚂蚁的研究
我有一个包含 3 列的表格：吸引的蚂蚁数量、面包类型、馅料类型。问题是：做测试看看蚂蚁的数量是否存在差异。
所以首先我做了一些预测试来检查正态性，然后检查方差相等性。然后用单向方差分析来检查一般差异，填充组有显着差异，为了看看精确度，我做了成对 t 检验。
所以问题是：这就足够了吗？如果是，我该如何进行 p 调整？
额外问题：测试应该针对自变量，对吗？因为在一个步骤中，我只是比较面包类型，然后只是比较馅料类型。]]></description>
      <guid>https://stats.stackexchange.com/questions/646333/how-do-i-do-the-p-adjustement-in-statistical-tests</guid>
      <pubDate>Thu, 02 May 2024 07:28:16 GMT</pubDate>
    </item>
    <item>
      <title>如何轻松地将频率数据转换为原始数据（大数据集）进行t检验？</title>
      <link>https://stats.stackexchange.com/questions/646328/how-to-easily-convert-frequency-data-into-raw-data-large-dataset-for-t-test</link>
      <description><![CDATA[统计目标：确定两个数据集之间的差异是否具有统计显着性。
数据集描述：数据以每个样本的颗粒尺寸（毫米）与颗粒计数（频率）的形式提供。
示例：

问题：我想通过 t 检验比较两个样品中观察到的粒度分布。但是，我无法使用频率值进行 t 检验。我尝试将频率值转换为 Excel 中的原始数据（使用 https://real-statistics.com/real-statistics-environment/data-conversion/Frequency-table-conversion/）。然而，使用 Excel 转换大型数据集比较混乱且容易出错。数据集中列出的粒径数量为 802，因此，原始数据（即具有重复粒径的数据）具有 &gt;802 个数据点。
可能的解决方案：我的知识仅限于统计软件附带的绘图工具（即 Excel、SigmaPlot、OriginPro），但我对 Python 或 R 解决方案持开放态度，它们允许我（ a) 将频率数据转换为原始数据 (b) 轻松进行 t 检验。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646328/how-to-easily-convert-frequency-data-into-raw-data-large-dataset-for-t-test</guid>
      <pubDate>Thu, 02 May 2024 04:31:47 GMT</pubDate>
    </item>
    <item>
      <title>风险价值预测的盈利能力</title>
      <link>https://stats.stackexchange.com/questions/646327/profitability-on-value-at-risk-forecasting</link>
      <description><![CDATA[我正在使用 GARCH 等波动率模型进行与风险价值预测相关的研究。我的预测在某些模型上得到了很好的结果。有没有办法利用这些预测？例如，使用 VaR 预测作为输入的交易策略，那么我的盈利能力取决于我的 VaR 预测有多准确？也许有选项？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646327/profitability-on-value-at-risk-forecasting</guid>
      <pubDate>Thu, 02 May 2024 04:22:17 GMT</pubDate>
    </item>
    <item>
      <title>具有不同程度（大）压缩的 BHT 样本复杂度</title>
      <link>https://stats.stackexchange.com/questions/646326/sample-complexity-of-bht-with-varying-degrees-of-large-compression</link>
      <description><![CDATA[在通信约束假设检验中：
最优性、鲁棒性和逆向数据处理不等式，建立了以下内容（经过一些轻微的编辑以突出我的问题）。
&lt;块引用&gt;
推论 3.4（Hellinger 距离保持）。对于任意 $D\geq 2$、$p,q\in\Delta_k$，存在 &lt; span class=&quot;math-container&quot;&gt;$T:[k]\to[D]$ 使得以下内容成立：
$$
1 \leq \inf_A\frac{H^2(p,q)}{H^2(A(p),A(q))} \leq 1800\max(1,\frac{\min(k,k) &#39;)}{D}),
$$
其中 $k′ = \log (4/H^2(p,q))$。

这里，$\Delta_k$是具有$k$元素的有限集上的概率单纯形。
$H^2(\vec p, \vec q) :=\frac{1}{2}\sum_{i\in[k]}(\sqrt{p_i}- \sqrt{q_i})^2$ 是（平方）Hellinger 距离。
符号 $[k] := \{0,1,\dots,k-1\}$。
上面还有一个密封性证明
&lt;块引用&gt;
引理3.6。存在正常数 $c_1,\dots,c_6$ 使得对于 $\rho\in(0,c_6)$  和 $D\geq 2$，存在 $k\in[c_2\log(1/\ rho),c_3\log(1/\rho)]$ 和 $\vec p, \vec q$ 上的两个分布 $\vec p, \vec q$ math-container&quot;&gt;$[k]$ 使得 $H^2(\vec p, \vec q)\in [c_4\rho, c_5\rho] $ 和
$$
\inf_{A:[k]\to[D]} \frac{H^2(\vec p, \vec q)}{H^2(A(\vec p), A(\vec q))} \geq c_6 \frac{\max(k,k&#39;)}{D}
$$

上述内容可用于推断二元假设检验的样本复杂性，其中得到压缩样本$A(x_i)$ 而不是未压缩 $x_i$。
这是因为众所周知 $\Theta(1/H^2(\vec p, \vec q))$ 捕获了上述样本复杂性。
例如。 “无压缩”的二元假设检验的成本与“some（由 $D$ 参数化）”相比压缩。
我很好奇不同压缩级别的成本。
具体来说，设置两个常量$D_1 \leq D_2$，并比较比率
$$
\frac{H^2(A_1(\vec p), A_2(\vec q))}{H^2(A_2(\vec p), A_2(\vec q))},
$$
其中 $A_1 : [k]\to[D_1]$ 和 $A_2: [k]\to [D_2] $。
人们可以利用推论 3.4 来获得界限
$$
1 \leq \frac{H^2(A_1(\vec p), A_1(\vec q)}{H^2(A_2(\vec p), A_2(\vec q))} \leq 1800 \max( 1,\frac{\min(k,k&#39;)}{D_2})
$$
我不清楚如何在这种情况下获得引理 3.6 的类似物，例如如果进行二元假设检验，其中严重压缩输入（例如设置 $D_1 = 2$ 和 $D_2 = 3$ span&gt;) 的成本基本相同，或者是否存在一些“阈值行为”。
这是已知的（或者可以很容易地从上述引理 3.6 推导出来吗？）]]></description>
      <guid>https://stats.stackexchange.com/questions/646326/sample-complexity-of-bht-with-varying-degrees-of-large-compression</guid>
      <pubDate>Thu, 02 May 2024 01:41:50 GMT</pubDate>
    </item>
    <item>
      <title>一个随机变量与两个随机变量乘积的协方差</title>
      <link>https://stats.stackexchange.com/questions/646325/covariance-of-one-random-variable-with-the-product-of-two-random-variables</link>
      <description><![CDATA[设 $X\sim \mathrm{Bin}(p_x,1)$ , $Y\sim \mathrm {Bin}(p_y,1)$ 和 $V\sim \mathrm{Bin}(p_v,1)$ 是三个二项式随机变量，即彼此并不独立。请注意，$X$ 和 $Y$ 是从相同的二项分布$\mathrm{Bin}(p_x,1)={Bin}(p_y,1)$。我的目标是找到协方差的表达式 \begin{align}\operatorname{Cov}(XY,V)&amp;\end{align}
来自相关随机变量乘积的协方差和等式。 12 in https://www.jstor.org/stable/2286081 （关于精确协方差随机变量的乘积），我了解到这个协方差可以表示为：
\begin{align}\operatorname{Cov}(XY,V)&amp;=\operatorname{E}(X)\operatorname{Cov}(Y,V) + \operatorname{ E}(Y)\operatorname{Cov}(X,V) + \operatorname{E}[(\Delta_Y)(\Delta_X)(\Delta_V)]&amp;\end{align}
其中 $\Delta_X = X - \mathbb E[X]$，$\Delta_Y = Y - \mathbb E[Y]$ 和 $\Delta_Z = Z - \mathbb E[Z]$。
请注意，如果三个随机变量呈正态分布，则第三矩消失（Anderson，1958）。所以我确实想知道二项式随机变量会发生什么。另外，请记住，可以对该变量进行归一化以获得均值 0 和方差 1。
同样，我有兴趣找到以下表达式：
\begin{align}\operatorname{Cov}(X^2,V)&amp;\end{align}
因此，在这种情况下，我们将协方差表达式表示为：
\begin{align}\operatorname{Cov}(X^2,V)&amp;=\operatorname{E}(X)\operatorname{Cov}(X,V) + \运算符名称{E}(X)\运算符名称{Cov}(X,V) + \运算符名称{E}[(\Delta_X)(\Delta_X)(\Delta_V)]= 2\运算符名称{E}(X)\运算符名称{ Cov}(X,V) + \operatorname{E}[(\Delta_X)^2(\Delta_V)]&amp;\end{align}
也许在二次形式的协方差和 $\mathbf{G}\ 类型的随机向量中提出了类似的问题,\mathbf{y}$ 但我不确定。
Anderson, T. W. 多元统计分析简介。纽约：约翰·威利父子公司，1958 年。]]></description>
      <guid>https://stats.stackexchange.com/questions/646325/covariance-of-one-random-variable-with-the-product-of-two-random-variables</guid>
      <pubDate>Thu, 02 May 2024 01:23:22 GMT</pubDate>
    </item>
    <item>
      <title>具有不同大小的向量列表/系列/链输入的模型</title>
      <link>https://stats.stackexchange.com/questions/646324/model-with-inputs-of-a-list-series-chain-of-vectors-with-varying-size</link>
      <description><![CDATA[我正在尝试创建一个模型，其中输入数据表示每个元素从 point_A 到 point_B 所采取的路径...
假设我拥有每个元素的所有地理位置数据，如何格式化输入数据以表示每个元素从 point_A 到 point_B 所采取的路径？
我基本上希望输入数据是各种大小的向量列表/系列/链 - 而不添加向量（并丢失其间步骤的数据）
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646324/model-with-inputs-of-a-list-series-chain-of-vectors-with-varying-size</guid>
      <pubDate>Thu, 02 May 2024 00:27:57 GMT</pubDate>
    </item>
    <item>
      <title>在变压器 LLM 中，正弦位置编码相对于二进制位置编码有什么优势？</title>
      <link>https://stats.stackexchange.com/questions/646323/what-advantage-do-sinusoidal-positional-encodings-have-over-binary-positional-en</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/646323/what-advantage-do-sinusoidal-positional-encodings-have-over-binary-positional-en</guid>
      <pubDate>Thu, 02 May 2024 00:17:10 GMT</pubDate>
    </item>
    <item>
      <title>比较离散数据的均值</title>
      <link>https://stats.stackexchange.com/questions/646304/compare-means-for-discrete-data</link>
      <description><![CDATA[我有两组观察结果，分别对应于两位不同希腊作者的短指六音步单词数。直方图具有漂亮的钟形形状，但数据不正常：一首诗中只能有离散数量的单词。它也不是泊松分布：方差小于均值（根据经验，一节经文不少于 4 个单词且不超过 12 个单词）。

有哪些方法可以比较两种均值以确定它们是否显着不同？
我正在考虑使用卡方来比较 2 个分布，但是这样，我们似乎将 5 字行和 6 字行视为分类数据（这并非完全没有意义，但很尴尬）。
另一种选择是计算每 n 行（例如 5 行）的均值，然后应用 z 检验或 t 检验（通过中心极限定理）。
然而，这两种解决方案似乎都有些牵强。有更优雅的解决方案吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646304/compare-means-for-discrete-data</guid>
      <pubDate>Wed, 01 May 2024 19:07:14 GMT</pubDate>
    </item>
    <item>
      <title>CFA 测量不变性 - 弱不变性对于配置不变性是否显着，但对于强不变性则不显着？</title>
      <link>https://stats.stackexchange.com/questions/646271/cfa-measurement-invariance-can-weak-invariance-be-significant-with-the-configu</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/646271/cfa-measurement-invariance-can-weak-invariance-be-significant-with-the-configu</guid>
      <pubDate>Wed, 01 May 2024 08:38:52 GMT</pubDate>
    </item>
    <item>
      <title>神经网络图中的随机变量</title>
      <link>https://stats.stackexchange.com/questions/646270/random-variables-in-the-neural-net-diagrams</link>
      <description><![CDATA[当我查看有关线性回归的讨论时：
什么是随机变量以及什么是随机变量回归模型中没有
它说：
如果我们有总体回归函数：
$$Y_i = \beta_0 + \beta_1X_i + \epsilon_i$$
$Y_i$ 是 RV，$X_i$ 可以是 RV 也可以是固定的，具体取决于数据的收集方式和假设，
$\beta_0$、$\beta_1$ 是固定的（在频率假设下）
但是我们的估计器 $\hat{\beta_0}$ 和 $\hat{\beta_1}$ 通常是随机变量；尽管在我们估计它们之后，它们就被修复了。
所以现在我想看看 MLP、vanilla RNN 和 LSTM，假设用于回归
MLP：
输入X，“重量”矩阵 W1,W2,输出 Y

&lt;小时/&gt;
RNN：
输入X，“重量”矩阵，隐藏状态 H

LSTM：
输入X，权重矩阵，隐藏状态H，单元状态C

&lt;小时/&gt;
所以我想知道如何根据“随机变量”与“RV 的固定/实例”来思考输入、权重矩阵、隐藏状态和单元状态。我确实注意到机器学习文献的作者通常不会尝试区分这两者。
但是从线性回归中采用相同的约定是否准确？
群体回归函数：权重矩阵、隐藏状态和单元状态固定，输入和输出为随机变量。
样本回归模型：权重矩阵、隐藏状态和单元状态将由估计器估计，它们构成了我们的预测器（因此估计器是随机变量）
估计后：我们估计的权重矩阵、隐藏状态和单元状态是固定的。
如果这些都是真的，并且我随机查看一篇论文并看到一个绘制出来的架构，那么它会指的是什么？有什么可能吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646270/random-variables-in-the-neural-net-diagrams</guid>
      <pubDate>Wed, 01 May 2024 08:19:27 GMT</pubDate>
    </item>
    <item>
      <title>是否应该对假性缺席进行替换采样？</title>
      <link>https://stats.stackexchange.com/questions/646267/should-pseudoabsences-ever-be-sampled-with-replacement</link>
      <description><![CDATA[我对使用替换数据采样构建模型的有效性有疑问。我的空间模型根据每个地图像素中是否存在动物的二元来预测动物栖息地的适宜性。由于目击事件仅记录存在情况（如果没有看到野兽，则不会进行记录），因此通常的做法是从整个研究区域进行“伪缺失”采样，捕获动物可能存在的可用环境范围。 &gt; 占据。
编辑更多关于伪缺席及其处理方式的信息：使用二进制响应变量，记录存在“1”，这些伪缺席每个都分配一个响应“0” 。然后我们可能会拟合逻辑回归之类的东西。 “伪”描述符是因为我们并不真正知道该动物不存在于这些地方。这限制了我们如何解释响应的预测值；它被解释为栖息地适宜性的相对排名。 &lt;- 编辑结束。
此类研究的数据来源之一是公共目击事件数据库，但动物目击事件偏向于人多的地方。为了纠正存在数据中的这种采样偏差，我计划以相同的（独立估计的）偏差对假缺失进行采样。通常在这种类型的建模中，会在没有替换的情况下绘制伪缺席，并且每个伪缺席都有相同的采样机会。在施加采样权重时，我遇到了这样的问题：人们经常使用的像素会很快从可用于采样的池中提取出来。这意味着人类游客很少的像素最终在假缺席样本中被过度代表，因此可以预测研究物种与城镇的虚假关联。
一种解决方案可能是通过替换来绘制伪缺失（但请注意，无论动物在那里被发现多少次，每个像素只记录一次存在，以提高空间独立性）。另一种解决方案可能是分配模型权重，以便在模型估计中降低远离城镇的位置的伪缺勤的权重。这些方法理论上有哪些优缺点，或者是否有其他方法可以调整采样偏差的伪缺席？]]></description>
      <guid>https://stats.stackexchange.com/questions/646267/should-pseudoabsences-ever-be-sampled-with-replacement</guid>
      <pubDate>Wed, 01 May 2024 06:38:48 GMT</pubDate>
    </item>
    <item>
      <title>渐近无偏 + 渐近零方差 = 一致？</title>
      <link>https://stats.stackexchange.com/questions/646259/asymptotic-unbiasedness-asymptotic-zero-variance-consistent</link>
      <description><![CDATA[此处，Ben 表明无偏估计量 $\hat渐近方差为零的参数 $\theta$ 的 \theta$ 收敛于 $ 的概率\theta$。也就是说，$\hat\theta$ 是 $\theta$ 的一致估计量。
我们应该能够将条件放宽到渐近无偏性，这是有道理的：$\underset{n\rightarrow\infty}{\lim} \mathbb E\left[\hat\theta_n - \theta\right] = 0$。这似乎符合估计器接近真实参数值的精神......
...但是数学以前就让我感到惊讶。
我们可以将条件放宽到渐近无偏吗？证据是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/646259/asymptotic-unbiasedness-asymptotic-zero-variance-consistent</guid>
      <pubDate>Wed, 01 May 2024 00:32:23 GMT</pubDate>
    </item>
    <item>
      <title>是否可以根据现实世界的观测数据评估因果算法？</title>
      <link>https://stats.stackexchange.com/questions/646243/is-it-possible-to-evaluate-causal-algorithms-on-real-world-observational-data</link>
      <description><![CDATA[很多时候，我被要求使用因果算法（例如估计干预结果的算法，或一般的因果推理算法），并将它们与现实世界观测数据的非因果预测算法进行比较，而无需任何额外的知识。是否可以对真实数据进行定量评估（例如评估拟合的 $R^2$）因果算法？比较因果算法与非因果算法有意义吗？您能否提供或指出一个示例（也可以是合成的，可能包含连续数据）来支持您的答案？
&lt;小时/&gt;
剧透：这里按照我的想法作为正确答案，但我仍然希望得到确认或证明我错了。
我对此的想法如下：我认为这是不可能的，因为我们要么需要因果 DAG 的知识，要么我们需要干预数据，而不是观察数据。因此，我认为评估因果算法与非因果算法的唯一方法是基于合成数据，并且一旦合成示例被证明可以在因果模型中工作，而不是在非因果模型中工作。然后，唯一要做的就是为手头的任务使用正确的算法：“假设”的因果算法或干预场景，非因果场景用于简单预测场景。我还认为，如果根据非因果度量进行评估，例如 $R^2$ 评估，非因果模型在大多数情况下会过度执行因果模型一些预测的拟合度，因为它们是专门为此设计和优化的。]]></description>
      <guid>https://stats.stackexchange.com/questions/646243/is-it-possible-to-evaluate-causal-algorithms-on-real-world-observational-data</guid>
      <pubDate>Tue, 30 Apr 2024 20:42:22 GMT</pubDate>
    </item>
    </channel>
</rss>