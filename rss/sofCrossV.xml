<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 19 Jan 2024 15:15:06 GMT</lastBuildDate>
    <item>
      <title>使用 Segneigh 方法查找显着变化点</title>
      <link>https://stats.stackexchange.com/questions/637234/finding-significant-changepoints-using-segneigh-method</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637234/finding-significant-changepoints-using-segneigh-method</guid>
      <pubDate>Fri, 19 Jan 2024 14:51:54 GMT</pubDate>
    </item>
    <item>
      <title>推导对数模型中精确的百分比变化公式</title>
      <link>https://stats.stackexchange.com/questions/637233/deriving-the-exact-percentage-change-formula-in-logarithmic-models</link>
      <description><![CDATA[我一直在回归分析的背景下研究对数变化和百分比变化之间的关系。据我所知，当处理小的变化时，变量对数的变化可以近似为变量本身的百分比变化。但是，我现在正在研究对数回归模型背景下的确切百分比变化，并且我正在尝试掌握以下方程的推导，该方程计算预测结果的确切百分比变化：
估计模型为：
$$\widehat{\log(y)} = \hat{\beta}_0 + \hat{\beta}_1 \log(x_1) + \hat{\beta}_2 x_2$$
在添加额外的自变量并修复后，我们考虑进行以下更改：
$$ \Delta \widehat{\log(y)} = \hat{\beta}_2 \Delta x_2
$$
使用指数函数和对数函数的简单代数属性，文本指出这会导致预测 y 的精确百分比变化如下：
$$ \% \Delta\hat{y} = 100 \cdot [\exp(\hat{\beta}_2 \Delta x_2) - 1] $$&lt; /p&gt;
但是，我不确定我们如何从日志中进行更改
$\widehat{\log(y)}$ 为上述百分比变化公式。谁能解释方程 6.8 的推导过程或提供任何完成此计算的资源？
为了进一步了解背景，所讨论的方程和模型取自 Jeffrey M. Wooldridge 的“计量经济学导论 7e”的第 6 章，特别是第 6-2 节。]]></description>
      <guid>https://stats.stackexchange.com/questions/637233/deriving-the-exact-percentage-change-formula-in-logarithmic-models</guid>
      <pubDate>Fri, 19 Jan 2024 14:47:21 GMT</pubDate>
    </item>
    <item>
      <title>广义非中心卡方分布的估计</title>
      <link>https://stats.stackexchange.com/questions/637231/estimation-of-a-generalized-noncentral-chi-square-dsitribution</link>
      <description><![CDATA[根据 Mathai A、Provost S：随机变量中的二次形式：理论与应用，1992 年，正态变量的二次形式具有广义非中心卡方分布（或广义卡方分布） wiki 中的分布 https://en.wikipedia.org/wiki/Generalized_chi-squared_distribution ）。
即：
$Y = (U+b)^TΛ(U+b)=\sum\limits_{j=1}^{n}λ_j(U_j+b_j)^2 $
其中 $U$ 是一个标准法向量，元素为 $U_j$，$b$ 是一个向量，包含元素 $b_j$、$λ_j$&lt; /span&gt; 表示二角矩阵 $Λ$ 的元素。
现在，我有 $Y$ 的样本，并且我知道它们遵循广义非中心卡方分布。
如何从样本中估计 $λ_j,b_j$，甚至 $n$？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/637231/estimation-of-a-generalized-noncentral-chi-square-dsitribution</guid>
      <pubDate>Fri, 19 Jan 2024 14:40:27 GMT</pubDate>
    </item>
    <item>
      <title>关于堆叠两个神经网络的几个全连接层的论文的问题</title>
      <link>https://stats.stackexchange.com/questions/637229/question-on-a-paper-which-talks-about-stacking-several-fully-connected-layers-of</link>
      <description><![CDATA[因此，作为序言，我对神经网络的了解非常有限，并且我很难理解 本文。
我的背景是数学，我创建了连续小波 CNN 和 LSTM 模型，但是我对方程 15 和 16 中使用的内容感到困惑。它看起来只是一个 sigmoid 函数，我连接两个数组（我假设我在这里扩展了 $m_{i,j,t}$ 数组），然后创建一个训练函数来估计权重和偏见，但感觉就像我跳过了一些重要的事情。
如果我只是使用 sigmoid 函数，我计划使用 维基百科上的这一部分按照论文的建议创建神经网络并进行训练，但是如果能做一些澄清就更好了。正如我所说，我对神经网络的了解非常初级，所以我基本上在这里做出有根据的猜测。]]></description>
      <guid>https://stats.stackexchange.com/questions/637229/question-on-a-paper-which-talks-about-stacking-several-fully-connected-layers-of</guid>
      <pubDate>Fri, 19 Jan 2024 14:27:29 GMT</pubDate>
    </item>
    <item>
      <title>仿真参数的主动学习</title>
      <link>https://stats.stackexchange.com/questions/637227/active-learning-for-simulation-parameters</link>
      <description><![CDATA[假设我们正在训练一个神经网络（或者更一般地说，您最喜欢的非参数模型）$f: \mathbb{R}^k \to \mathbb{R}$ 来解决回归问题。为了清楚起见，$k$ 的顺序是 $\sim10$。每个训练数据点的形式为 $(x_1,\dots,x_k,y),$ ，损失为  $L = \sum_i d(f(\mathbf{x}_i),y_i),$ 其中 $d(y,y&#39;)$ 是$y$ 和 $y&#39;$ 之间偏差的一些正定度量，以及索引 &lt; span class=&quot;math-container&quot;&gt;$i$ 指样本。
训练数据是通过后处理从（昂贵的）模拟中事后提取的，每个模拟提供数千个数据点。至关重要的是，对于给定的一组模拟参数（例如初始条件），特征空间中的数据分布很难预测。我想实现一个主动学习协议，选择新的模拟参数集来探索特征空间的新区域，从而获得 $f$ 的最佳估计同时最大限度地减少所需的模拟次数。
换句话说，我可以轻松找出特征空间的哪些区域需要更多探索，但模拟参数与这些区域之间的对应关系尚不清楚。我们可以说每组参数 $\theta$ 对应于特征空间中的未知数据密度 $p(\mathbf {x} | \theta)$。有哪些工具可用于执行选择新仿真参数的任务？有没有办法将其转化为贝叶斯优化问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/637227/active-learning-for-simulation-parameters</guid>
      <pubDate>Fri, 19 Jan 2024 13:58:27 GMT</pubDate>
    </item>
    <item>
      <title>如何计算单尾配对 t 检验所需的最小样本量，测试差异是否大于 5？</title>
      <link>https://stats.stackexchange.com/questions/637226/how-can-i-calculate-the-minimum-required-sample-size-for-a-one-tailed-paired-t-t</link>
      <description><![CDATA[此交叉验证答案指出，通过更改指定值进行配对 t 检验来测试差异是否大于某个值（例如 5）是有效的零/备择假设中的 𝜇 。我的问题是：如何计算此测试所需的最小样本量？
我已经知道在测试差异是否大于零时计算样本量的方法（例如此资源）但是在零/替代假设中使用不同的 𝜇 值时会如何变化？我对最小可检测效应大小（例如 1.5）和我们正在测试的效应大小 (5) 之间感到困惑]]></description>
      <guid>https://stats.stackexchange.com/questions/637226/how-can-i-calculate-the-minimum-required-sample-size-for-a-one-tailed-paired-t-t</guid>
      <pubDate>Fri, 19 Jan 2024 13:56:50 GMT</pubDate>
    </item>
    <item>
      <title>排名之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/637223/correlations-among-rankings</link>
      <description><![CDATA[在我的研究中，参与者对几种选择的偏好进行了排名。由于向上移动一个选项必然意味着向下移动一个或多个选项，因此几乎所有相关性（Pearson r）都是负的。我的感觉是，这也夸大了系数的大小。
本质上，变量不是独立的，据我了解，这不是 Pearson r 的要求，但这似乎仍然有问题。
我可以转换我的变量来消除这个问题吗？或者进行不同类型的分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/637223/correlations-among-rankings</guid>
      <pubDate>Fri, 19 Jan 2024 12:43:35 GMT</pubDate>
    </item>
    <item>
      <title>$\bar{X}-X_i$ 的分布</title>
      <link>https://stats.stackexchange.com/questions/637221/distribution-of-barx-x-i</link>
      <description><![CDATA[令 $X_1, \ldots, X_n$ 为独立同分布。标准正态分布的随机变量，令 $\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i$ 为他们的样本平均值。
我对 $Y_i = \bar{X}-X_i$ 的分布感兴趣。具体来说，假设存在一个 $p(\varepsilon)$ 使得对于任何 $i$
$$\mathbb{P}(|Y_i|\le\varepsilon) \le p(\varepsilon),$$
我试图将 $\mathbb{P}(\max_i|Y_i|\le\varepsilon)$ 绑定为 $p(\epsilon)$ 和 $n$。
如果 $Y_i$ 是独立的，我们可以很容易地写
$$\mathbb{P}(\max_i|Y_i|\le\varepsilon) = \prod_{i=1}^n \mathbb{P}(|Y_i|\le\ varepsilon) \le p(\varepsilon)^n.$$
不幸的是， $Y_i$ 不是独立的。我尝试了另一种方法，我想知道它是否正确。
第 1 步。
$Y_i$ 呈联合正态分布，且均独立于 $\bar{X}$。 
第 2 步。
因此，给定 $\bar{X}$ 时，$Y_i$ 的条件概率分布等于其无条件分布，因此 $\mathbb{P}(|Y_i|\le\varepsilon) = \mathbb{P}(|Y_i|\le\varepsilon \mid \bar{X }=\bar{x})$。
第 3 步。
当 $\bar{X}=\bar{x}$ 固定时， $Y_i = \bar{X} - X_i = \bar{x} - X_i$ 并且由于 $X_i$ 是独立的，因此 $Y_i给定 $\bar{X}$ 时，$ 都是相互条件独立的。
所以，
$$\mathbb{P}(\max_i|Y_i|\le\varepsilon \mid \bar{X}=\bar{x}) = \prod_{i=1}^ n \mathbb{P}(|Y_i|\le\varepsilon \mid \bar{X}=\bar{x}).$$
在我看来，通过结合步骤 1-3 我们可以得出结论
$$\mathbb{P}(\max_i|Y_i|\le\varepsilon) = \mathbb{P}(\max_i|Y_i|\le\varepsilon \mid \bar{X }=\bar{x}) = \prod_{i=1}^n \mathbb{P}(|Y_i|\le\varepsilon \mid\bar{X}=\bar{x})= \prod_{i =1}^n \mathbb{P}(|Y_i|\le\varepsilon) \le p(\varepsilon)^n.$$
我发现这个结果“好得令人难以置信”因为这就是如果 $Y_i$ 独立的话我们会得到的结果。有人可以确认一下上面的推理是否正确，如果不正确，请指出错误所在？]]></description>
      <guid>https://stats.stackexchange.com/questions/637221/distribution-of-barx-x-i</guid>
      <pubDate>Fri, 19 Jan 2024 12:23:03 GMT</pubDate>
    </item>
    <item>
      <title>“加权”是什么意思？我正在尝试学习逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/637218/what-does-the-weighted-mean-im-trying-to-learn-logistic-regression</link>
      <description><![CDATA[
饮食失调 &lt;- c(0, 0, 0, 0, 1, 1, 1, 1)
性别 &lt;- c(0, 0, 1, 1, 0, 0, 1, 1)
应力 &lt;- c(0, 1, 0, 1, 0, 1, 0, 1)
加权 &lt;- c(3, 2, 4, 1, 5, 5, 9, 17)
y &lt;- c(3, 2, 4, 1, 5, 3, 5, 6)
AnxietyTreatment &lt;- data.frame(eating_disorder, 性别, 压力, 加权, y)
z &lt;- y / 加权
适合 &lt;- glm(z ~ 饮食失调 + 性别 + 压力, 家庭 = 二项式,
           权重 = 加权，数据 = 焦虑治疗）
总结（适合）

请帮忙，这些是我用来分析数据的 r 代码，但结果显示“eating_disorder”=11084.3781 的标准错误极高，对我来说看起来不正确。我是否在治疗“加权”？正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637218/what-does-the-weighted-mean-im-trying-to-learn-logistic-regression</guid>
      <pubDate>Fri, 19 Jan 2024 11:52:33 GMT</pubDate>
    </item>
    <item>
      <title>预测力为零情况下的精确率和召回率</title>
      <link>https://stats.stackexchange.com/questions/637217/precision-and-recall-in-the-case-of-null-predictive-power</link>
      <description><![CDATA[对于多类分类问题，如果它是完美预测的，则预测类 $P(j|i)$ -container&quot;&gt;$j$ 对于真实类 $i$ 为 1，当 $j=1$ 时 ，否则为 0。在这种情况下，每个类别的精度为 1，每个类别的召回率为 1
当系统完全不可预测时，精确度和召回率会怎样？我想这相当于说 $P(j|i)$ 不依赖于真正的类 $i$&lt; /span&gt;，但实际上我不知道在这种情况下任何为零的指标。]]></description>
      <guid>https://stats.stackexchange.com/questions/637217/precision-and-recall-in-the-case-of-null-predictive-power</guid>
      <pubDate>Fri, 19 Jan 2024 11:16:52 GMT</pubDate>
    </item>
    <item>
      <title>导出连续变量截止值的方法[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637214/methods-to-derive-cut-offs-for-continuous-variables</link>
      <description><![CDATA[我正在开展一个项目，以确定更好地预测二元结果的变量。现在，我想确定连续变量的截止值，这有助于预测结果。您能建议一下这样做的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637214/methods-to-derive-cut-offs-for-continuous-variables</guid>
      <pubDate>Fri, 19 Jan 2024 10:29:53 GMT</pubDate>
    </item>
    <item>
      <title>不拟合边缘分布的 Copula 函数</title>
      <link>https://stats.stackexchange.com/questions/637207/copula-functions-without-fitting-marginal-distributions</link>
      <description><![CDATA[我正在使用 MvCAT 工具箱，它适合不同的 copula 系列以适应导入的数据并确定哪个 copula 函数表现最好（请注意，它仅适用于两个变量）。我在使用此工具箱时面临的一个问题是，对数据经验概率的拟合边际分布是不可接受的（尽管 MvCAT 尝试了大约 20 个已知的 CDF 函数并优化了它们的参数）。
我想知道是否存在其他方法来拟合 copula，而无需对我的数据拟合边际分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/637207/copula-functions-without-fitting-marginal-distributions</guid>
      <pubDate>Fri, 19 Jan 2024 06:32:45 GMT</pubDate>
    </item>
    <item>
      <title>nlme 包中 PGLS anova 的平方和</title>
      <link>https://stats.stackexchange.com/questions/637185/sum-of-squares-for-pgls-anova-from-package-nlme</link>
      <description><![CDATA[有人可以帮我解决以下问题吗？如何从 nlme 包中获取 PGLS 方差分析的平方值之和（SStotal、SS Between、SSwithin）？这是一个示例模型：
图书馆(ape)
图书馆（nlme）

Barbet &lt;- read.csv(“http://www.phytools.org/Cordoba2017/data/Barbetdata.csv”，header = TRUE，row.names = 1)
Barbet$species &lt;- row.names(Barbet)

树 &lt;- read.nexus(“http://www.phytools.org/Cordoba2017/data/BarbetTree.nex”)

pgls.model &lt;- gls(Lnote ~ Lnalt + wing, 数据 = Barbet, 相关性 = corPagel(值 = 1, 形式 = ~ 物种, phy = 树))
方差分析（pgls.model）

提前感谢您的回答！]]></description>
      <guid>https://stats.stackexchange.com/questions/637185/sum-of-squares-for-pgls-anova-from-package-nlme</guid>
      <pubDate>Thu, 18 Jan 2024 19:23:55 GMT</pubDate>
    </item>
    <item>
      <title>python中STL分解和查找异常值的问题</title>
      <link>https://stats.stackexchange.com/questions/637143/problems-with-stl-decomposition-and-finding-outliers-in-python</link>
      <description><![CDATA[这是我正在制作的一个示例系列，旨在探讨异常值检测主题。我是一名开发人员，不是统计学家。
我的目标是使用 STL 来消除趋势并淡化我的系列。这样我就可以开始分析异常值的残余分量。
我的分解问题是时间步 15 处的异常值成为季节性分量的一部分。这意味着对于剩余部分来说，第一年会出现下降，而不是第二年会出现峰值。
我读过并且已经被告知使用平均值和标准差可能不是最佳的。但这不是这里的主要问题。

我的思维过程有缺陷吗？
您建议我做什么来开始异常值检测领域？
有没有可以推荐的异常值检测方法？
我应该使用哪些指标来代替均值和标准差来检测残差中的异常值？
数据：
&lt;代码&gt;[0, 2, 5, 8, 12, 15, 18, 22, 25, 28, 20, 10, 0, 2, 5, 18, 12, 15, 18, 22, 25, 28 , 20, 10]
代码：
def detector_outliers(timeseries):
    timeseries_values = timeseries[&#39;prognosebasis&#39;].values

    stl = STL(timeseries_values, 周期=12, 稳健=True)
    stl_fit = stl.fit()
    绘图组件（stl_fit）

    resid_mean = stl_fit.resid.mean()
    resid_std = stl_fit.resid.std()

    下=残差平均值 - (3*残差标准差)
    上层 = 残差平均值 + (3*残差标准差)

    异常值 = np.where((stl_fit.resid &gt; upper) | (stl_fit.resid &lt; lower))
    返回异常值

24 年 1 月 19 日更新：
我选择了具有 3 个完整季节周期的时间序列并重新进行了实验。我很惊讶地发现在第三个系列中，异常值没有被正确识别。

我还尝试了 statsmodels season_decompose 进行比较：

关于为什么 STL 以这种方式解释第三个异常值有任何线索吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637143/problems-with-stl-decomposition-and-finding-outliers-in-python</guid>
      <pubDate>Thu, 18 Jan 2024 09:50:05 GMT</pubDate>
    </item>
    <item>
      <title>调整多个模型的实验错误率的置信区间</title>
      <link>https://stats.stackexchange.com/questions/637118/adjusting-confidence-intervals-for-the-experimentwise-error-rate-across-multiple</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637118/adjusting-confidence-intervals-for-the-experimentwise-error-rate-across-multiple</guid>
      <pubDate>Thu, 18 Jan 2024 01:58:39 GMT</pubDate>
    </item>
    </channel>
</rss>