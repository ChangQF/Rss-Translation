<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 20 Apr 2024 00:59:07 GMT</lastBuildDate>
    <item>
      <title>当同一物理量的同时测量结果不同时对时空数据进行平整的方法</title>
      <link>https://stats.stackexchange.com/questions/645424/methods-to-level-spatiotemporal-data-when-simultaneous-measurements-of-the-same</link>
      <description><![CDATA[我有三颗不同卫星对大气中电离臭氧密度含量（模拟）测量的数据。具体来说，我对每颗卫星 S1、S2、S3 (3N &gt; 每个时间戳的总观测值。所有三个卫星观测都是时间同步的，并且在观测的每个时间步长期间大致出现在相同的纬度/经度区域。我想弄清楚如何在同一时间对同一区域的观测进行“平衡”（我希望这是正确的术语）。
我的问题明确表述如下：
假设在时间戳T卫星S1在纬度和经度坐标（L1，L2）处测量到电离臭氧密度为3。 S2和S3在经纬度坐标（L1+k1，L2+k2）和（L1+k3，L2+k4）处测量臭氧密度分别为4和1其中 k1、k2、k3、k4 是 L1 和 L2 的小偏移（~0.2 度）。假设我知道S1的测量是“最准确的”（也许它直接从头顶飞过）。如何估计可以添加到 4 和 1（S2 和 S3e1 和 e2） strong&gt; 的测量）以使这些观察结果与 S1 观察到的结果更加“一致”？事实上，修改S1的观察也是允许的，但从某种意义上说，它应该被修改得最少。请注意，我们并不真正了解导致这些电离臭氧密度的物理过程，因此我们无法将对物理的任何理解纳入此估计中。
我很迷茫，不知道从哪里开始。任何帮助将不胜感激，即使是最简单的方法也可以！]]></description>
      <guid>https://stats.stackexchange.com/questions/645424/methods-to-level-spatiotemporal-data-when-simultaneous-measurements-of-the-same</guid>
      <pubDate>Sat, 20 Apr 2024 00:49:17 GMT</pubDate>
    </item>
    <item>
      <title>结合百分比来估计新的百分比</title>
      <link>https://stats.stackexchange.com/questions/645420/combining-percentages-to-estimate-new-percentage</link>
      <description><![CDATA[我正在尝试根据其居住州来估计在大学第一年选择本科级别大学专业的真正新生群体（首次入学、全日制、攻读学位）的比例。举例来说：对于从 X 州高中毕业并于明年上大学的学生，这些学生中有多少比例是全日制攻读学位的学生，并声明了所希望的大学专业。我没有直接获得这些数据，但有一些数据可以用来进行估计。以下是可用数据：

本科生总数（所有即将入学的本科生）
即将入学的全日制、首次攻读学位的本科生人数
过去 12 个月内高中毕业的首次攻读学位的本科生人数（因此，这里基本上也是第一次），按其被录取时的居住州划分
选择相关专业的全日制一年级攻读学位本科生的人数。

正如您所看到的，每个数据源涉及的学生类型都存在一些问题。来源 3 在计数中没有寻求程度，而来源 4 有。有谁知道我如何能够有效地组合这些数据来创建相关的估计？我可以假设进入真正的新生的家乡州的分布在整体队列和大学专业队列之间是相同的，以及你们可能会看到的我可能需要做出的其他假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/645420/combining-percentages-to-estimate-new-percentage</guid>
      <pubDate>Fri, 19 Apr 2024 20:39:20 GMT</pubDate>
    </item>
    <item>
      <title>链式法则条件熵</title>
      <link>https://stats.stackexchange.com/questions/645419/chain-rule-conditional-entropy</link>
      <description><![CDATA[在我正在阅读的教科书中，它指出 $H(X,Y)=H(X)+H(Y|X)$，其中$H(X,Y)$ 是随机变量的联合熵 $X,Y$, &lt; span class=&quot;math-container&quot;&gt;$H(X)$ $X$ 和 $H(Y|X)$ 是条件熵。然后它继续说，以类似的方式，可以显示
$H(X,Y|Z)=H(X|Z)+H(Y|X,Z)$。我很困惑如何解释左侧的术语。是否意味着被解释为 $X$ 分布和 $Y$&lt; 条件分布的交叉熵/span&gt; 以 $X$ 为条件，或者被解释为 $ 联合分布的条件熵X$ 和 $Y$，以 $Z$ 为条件？]]></description>
      <guid>https://stats.stackexchange.com/questions/645419/chain-rule-conditional-entropy</guid>
      <pubDate>Fri, 19 Apr 2024 20:29:19 GMT</pubDate>
    </item>
    <item>
      <title>实验中缺失数据，MIPO、MIPO|X 与 MCAR、MAR、MNAR</title>
      <link>https://stats.stackexchange.com/questions/645417/missing-data-in-experiments-mipo-mipox-vs-mcar-mar-mnar</link>
      <description><![CDATA[您好，我正在阅读艾伦·格伯和唐纳德·格林的《现场实验》，并向我介绍了独立于潜在结果的缺失 (MIPO) 的概念。当您以协变量为条件时，MIPO|X 与缺失无关。我接受的关于失踪的大部分教育都是关于 MCAR、MAR、MNAR 以及是否进行估算。
MIPO 定义为
$$
Y_i(z) \perp\!\!\!\!\perp R_i(z)
$$
MIPO|X 定义为
$$
\{Y_i(z) \perp\!\!\!\!\perp R_i(z)\}|\mathbf{X}_i = \mathbf{x} \text{ 对于所有 } \mathbf{x}
$$
$R_i(z)$ 是治疗 $z$ 的潜在反应。
$Y_i(z)$ 是治疗的潜在结果$z$
据我所知，MIPO 关注的是治疗效果是否公正或仍然有因果依据，而 MCAR、MAR、MNAR 更关注是否可以在没有缺失的情况下对完整样本进行推论，这是正确的吗？&lt; /p&gt;
我很好奇不同的思维方式如何影响分析以及这些想法来自哪里以供进一步阅读？]]></description>
      <guid>https://stats.stackexchange.com/questions/645417/missing-data-in-experiments-mipo-mipox-vs-mcar-mar-mnar</guid>
      <pubDate>Fri, 19 Apr 2024 20:13:30 GMT</pubDate>
    </item>
    <item>
      <title>移动块引导程序以获得趋势的一阶导数的 CI</title>
      <link>https://stats.stackexchange.com/questions/645416/moving-block-bootstrap-to-get-ci-arou-d-first-derivative-of-trend</link>
      <description><![CDATA[我有一个时间序列，我想知道非线性趋势分量的变化率。为此，我想获取趋势的一阶导数，但我需要围绕它的置信区间。我认为一种方法可能是执行 STL，然后在残差上使用移动块引导程序来生成引导时间序列，对每个重复分解并每次计算趋势的导数 - 让我可以围绕衍生品？
这是一个合理的方法吗？注意我不关心预测，只关心历史数据 - 引导在这里仍然有用吗？如果是这样，多少个引导程序合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/645416/moving-block-bootstrap-to-get-ci-arou-d-first-derivative-of-trend</guid>
      <pubDate>Fri, 19 Apr 2024 19:32:54 GMT</pubDate>
    </item>
    <item>
      <title>色散和相关参数之间的 Beta 二项式关系</title>
      <link>https://stats.stackexchange.com/questions/645415/beta-binomial-relationship-between-dispersion-and-correlation-parameters</link>
      <description><![CDATA[上下文：我已经使用 glmmTMB 包中的 glmmTMB() 创建了一个 beta-二项式模型，现在我正在尝试使用  模拟 beta-二项式结果&gt;pbetabinom() 来自 VGAM 包。每个包中方差的参数化是不同的。 此处 28 显示 glmmTMB 包中的 beta 二项式方差为 V = $\mu$(1-$\mu$)(n($\phi$+n)/($ \phi$+1)) 和此处&lt; /a&gt; 对于 VGAM 包显示为 V = $\mu$(1- $\mu$)(1+(n-1)$\rho$)/n。如何将 $\phi$ 关联到 $\rho$？
pbetabinom() 使用 $\rho$ 参数，它称为相关参数，定义在 0 和1. 但是这个$\rho$并没有在glmmTMB()的输出中给出，而是我们得到了一个色散参数，$\phi$。
我想根据我的模型输出进行模拟，但我正在努力如何将 $\phi$ 与 $ 关联起来\rho$。设置方差相等，并隔离 $\rho$，我的代数让我：
$\rho$=(n*n($\phi$+n)-( $\phi$+1))/((n-1)($\phi$+1 ））。
我尝试过简化这个过程，但无法从方程中得到“n”。我还可以看到，假设 $\phi$ 具有正值，则 $\rho$ 不会绑定在 0 和 1 之间，根据 VGAM 详细信息，它应该是这样。
所以，我的问题是：如何使用由 glmmTMB() 输出给出的色散参数 $\phi$ 到模拟需要相关参数 $\rho$ （由 VGAM 的 pbetabinom() 定义）的 beta 二项式结果？我在处理两个给定的方差方程时哪里出错了？]]></description>
      <guid>https://stats.stackexchange.com/questions/645415/beta-binomial-relationship-between-dispersion-and-correlation-parameters</guid>
      <pubDate>Fri, 19 Apr 2024 19:00:32 GMT</pubDate>
    </item>
    <item>
      <title>如何选择将分布放在 KL 散度的右侧或左侧？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/645409/how-do-you-choose-to-put-a-distribution-on-the-right-or-left-of-kl-divergence</link>
      <description><![CDATA[我一直认为 KL 散度是分布之间的距离度量，很像 Earth-Movers 距离。但我不能再忽视这种不对称性。真实距离度量是对称的。
我应该如何解释这种不对称性？如果我有两个分布，我想测量它们之间的 KL，我该如何决定是将一个分布放在 KL[Q||P] 的右侧参数还是左侧参数中？]]></description>
      <guid>https://stats.stackexchange.com/questions/645409/how-do-you-choose-to-put-a-distribution-on-the-right-or-left-of-kl-divergence</guid>
      <pubDate>Fri, 19 Apr 2024 17:34:13 GMT</pubDate>
    </item>
    <item>
      <title>系统 GMM 对于任何加权矩阵都会产生相同的结果</title>
      <link>https://stats.stackexchange.com/questions/645362/system-gmm-yields-identical-results-for-any-weighting-matrix</link>
      <description><![CDATA[我正在估计 R 中看似不相关的回归 (SUR) 系统。每个方程都有一个唯一的回归量和一个公共回归量。我正在使用 gmm::sysGmm 并尝试不同的权重矩阵。我得到了相同的结果（点估计、标准误差和我能看到的任何其他结果 - 除了 $J$ 的值 -测试），无论权重矩阵如何。我认为这是不正确的。
无论我使用哪种类型的协方差矩阵估计器，这种现象都会持续存在：MDS、CondHom 或 HAC。无论我使用无限制估计还是限制其中一个系数在方程中相等，它都仍然存在。
问题：为什么系统 GMM 通过 gmm::sysGmm 对于任何加权矩阵都会产生相同的结果？
库(gmm)
库（系统适配）

# 生成并准备数据
n &lt;- 1000 # 样本量
m＜-100#“第二部分”的长度样本的
N &lt;- 3 # 方程数
设置.种子(321); x &lt;- 矩阵(rnorm(n*N),ncol=N); colnames(x) &lt;-paste0(“x”,1:N) # 生成回归量
dummy &lt;- c(rep(0,n-m),rep(1,m))#生成一个公共回归器
x &lt;- cbind(x,dummy) # 包含公共回归器和其余回归器
设置.种子(123); y &lt;- 矩阵(rnorm(n*N),ncol=N); colnames(y) &lt;- Paste0(“y”,1:N) # 因变量的占位符
for(i in 1:N){
 y[,i] &lt;- i + sqrt(i)*x[,i] - i*虚拟 + y[,i]*15*sqrt(i)
 # y[,i] 是 x[,i] 和虚拟变量的线性函数，
 # 加上一个带有方程特定方差的误差项
}
data1 &lt;- as.data.frame(cbind(y,x)) # 创建所有数据（y 和 x）的数据框

# 创建模型方程和力矩条件
eqSystem_g = eqSystem_h &lt;- list()
for(i in 1:N){
 eqSystem_g[[i]] &lt;- as.formula(assign(paste0(&quot;eq&quot;,i), value=paste0(&quot;y&quot;,i,&quot; ~ x&quot;,i,&quot; + dummy&quot;) )) # 定义 SUR 的线性方程
 eqSystem_h[[i]] &lt;- as.formula(assign(paste0(&quot;eq&quot;,i), value=paste0( &quot;~ x&quot;,i,&quot; + dummy&quot;))) # 定义矩条件对于高斯模型
}

# 估计 WLS 类型的权重矩阵，用作 GMM 中用户指定的权重矩阵
m0 &lt;- systemfit(公式=eqSystem_g，方法=“OLS”，数据=data1)
OLSmat &lt;- diag(diag(m0$residCov)); Wmat &lt;- 求解(OLSmat)

# 选择GMM中协方差矩阵的类型
vc1＜-“MDS”
vc1＜-“CondHom”
vc1＜-“HAC”
#vc1 &lt;-“TrueFixed”

# 在限制估计和非限制估计之间进行选择
cec1=NULL # 无限制
cec1=3 # 限制虚拟变量的系数在方程中相等

# 使用不同的权重矩阵“sysGmm”估计模型：identity、“optimal”并手动指定
m1a &lt;- sysGmm(g=eqSystem_g, h=eqSystem_h, wmatrix=“ident” ,weightsMatrix=NULL, vcov=vc1, crossEquConst=cec1, data=data1);摘要(m1a)
m1b &lt;- sysGmm(g=eqSystem_g, h=eqSystem_h, wmatrix=“最佳”,weightsMatrix=NULL, vcov=vc1, crossEquConst=cec1, data=data1);摘要(m1b)
m1c &lt;- sysGmm(g=eqSystem_g, h=eqSystem_h,weightsMatrix=Wmat, vcov=vc1, crossEquConst=cec1, data=data1);摘要(m1c)

相关：
* 通过 systemfit 与 sysGmm 估计的 SUR：不同的标准误差 
* 为什么 systemfit 对于 OLS 和 WLS 会产生相同的结果？  
* 为什么在交叉方程限制下，systemfit 会产生不同的 OLS 和 WLS 结果？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/645362/system-gmm-yields-identical-results-for-any-weighting-matrix</guid>
      <pubDate>Fri, 19 Apr 2024 07:51:09 GMT</pubDate>
    </item>
    <item>
      <title>秩约束矩阵乘积的 Frobenius 范数有界</title>
      <link>https://stats.stackexchange.com/questions/645341/frobenius-norm-of-rank-constrained-matrix-product-is-bounded</link>
      <description><![CDATA[假设我有三个矩阵 $\mathbf{W} \in \mathbb{R}^{p \times m}$ 和 $\mathbf{A}, \mathbf{B} \in \mathbb{R}^{m \times n}$ 与 $\operatorname{ rank}(\mathbf{A}) \leq r$ 和 $\mathbf{B}$ 在等级上不受限制。我还假设所有这些都在 Frobenius 范数中受到某个数字的限制，例如 $||\mathbf{W}||_F, ||\mathbf{A}||_F, | |\mathbf{B}||_F \leq \kappa$
我试图证明 $ \sup ||\mathbf{WA} ||_F \leq \sup ||\mathbf{WB}||_F$（sup 是在三个矩阵上）
我的想法是混合 SVD 分解，事实上矩阵的 Frobenius 范数是奇异值的平方，因此 LHS 将被裁剪为仅 $r$ 奇异值值将有助于总和。但我不能让它变得正式。您对如何进行有任何提示吗？
谢谢:)
——编辑帖子@whuber评论！
好的。抱歉，这个问题实际上根本没有正确提出。我所寻找的并不是简单地表明 $ \sup ||\mathbf{WA} ||_F \leq \sup ||\mathbf{WB}||_F$&lt; /span&gt; 而是根据排名 (A) 与满排名 (B) 约束来查找分离因子。所以基本上看起来像这样的结果；
$$
\sup ||\mathbf{WA} ||_F \leq \textrm{} (r, \kappa) 的某个函数
\\ \sup ||\mathbf{WB} ||_F \leq \textrm{} (m, \kappa) 的某个函数
$$
很高兴得到任何指点！再次感谢:)]]></description>
      <guid>https://stats.stackexchange.com/questions/645341/frobenius-norm-of-rank-constrained-matrix-product-is-bounded</guid>
      <pubDate>Thu, 18 Apr 2024 21:29:13 GMT</pubDate>
    </item>
    <item>
      <title>比值比悖论？合并 OR 与子组 OR 不一致</title>
      <link>https://stats.stackexchange.com/questions/645304/odds-ratios-paradox-pooled-or-inconsistent-with-subgroup-ors</link>
      <description><![CDATA[我有两个组（A 和 B），每个组的 OR 分别为 1.44 和 1.50。但是，如果我将两个组的频率组合起来创建一个合并数据集，则 OR 值为 1.40。
我知道这不会是一个很好的简单加权平均值或任何东西，但我预计合并的 OR 至少会落在两个 OR 的范围内。经过几天的苦苦思索试图找出原因后，我放弃了，转而求助于这里的集体智慧。
这是我的数据：
A 组频率

&lt;标题&gt;


控制
测试


&lt;正文&gt;

低
1374
1422


高
4759
7062



产生 1.44 的 OR 
B 组频率

&lt;标题&gt;


控制
测试


&lt;正文&gt;

低
825
534


高
4033
3914



产生 1.50 的 OR
合并频率

&lt;标题&gt;


控制
测试


&lt;正文&gt;

低
2199
1956


高
8792
10976



产生 1.40 的 OR
对这里发生的事情有什么想法吗？我使用这两个组来显示模式，但我的数据实际上分为更多组。
我将其称为悖论，因为如果我包括所有组，尽管事实上几乎所有组都产生 1.2-1.8 范围内的 OR（有几个组产生 0.95-1.0 范围内的 OR） ），池化版本基本上变为空（OR = 1.00）。感觉就像存在某种辛普森悖论。
编辑：根据下面的@COOLSerdash，本文&lt; /a&gt; 解释了“不可折叠性” OR 的数量。经过一番尝试后，我们发现，如果较大的组的 RR 与其他组的 RR 非常不同，那么它就会产生强烈的“扭曲”效果。效果。]]></description>
      <guid>https://stats.stackexchange.com/questions/645304/odds-ratios-paradox-pooled-or-inconsistent-with-subgroup-ors</guid>
      <pubDate>Thu, 18 Apr 2024 13:07:54 GMT</pubDate>
    </item>
    <item>
      <title>事后观察到的效应大小是否与 p 值冗余，就像事后观察到的功效一样？</title>
      <link>https://stats.stackexchange.com/questions/645269/is-the-post-hoc-observed-effect-size-redundant-with-the-p-value-just-like-post</link>
      <description><![CDATA[为了简单起见，假设我们正在对 2 个正态分布总体进行 2 样本 t 检验，从中收集 2 个 i.i.d 样本。 （首先；我们可以稍后扩展到更复杂的情况）。我们知道，一项研究的事后观察功效完全由观察到的 p 值决定。请参阅此处，或此处，以及此网站上的多个参考。
然后，事后我们得到了计划的 $\alpha$ （传统上为 0.05），实际样本大小 $N $ 和 p 值 $p$。但是从 $p$ 我们可以得到观察到的幂 ($1-\beta&#39;$)，如下显示在链接中。我们有观察到的标准差 ($sd$)。我可以计算观察到的效果 ($\delta=(xbar_1-xbar_2)/sd$)。
让我知道用 2 个新样本重复此操作（相同的样本大小、相同的正态分布、相同的方差，但不同的“真实”效果）。我得到了不同的 p 值、观察到的功效 $(1-\beta$) 和观察到的效果 $\delta$&lt; /跨度&gt;。我多次重复同样的事情。
认为 $\delta$ 值与 p 值存在单调递减函数的想法是否正确？ （正如功率与 p 的链接所示）。或者事后效应大小是一个随机变量吗？在这种情况下，它的分布可能是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/645269/is-the-post-hoc-observed-effect-size-redundant-with-the-p-value-just-like-post</guid>
      <pubDate>Thu, 18 Apr 2024 01:40:12 GMT</pubDate>
    </item>
    <item>
      <title>英文文本中每个单词有多少知识点？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/645182/how-many-bits-of-knowledge-are-there-in-english-text-per-word</link>
      <description><![CDATA[人们常说，典型的英语文本可以最佳地压缩到每个单词 12 位左右。
然而，由于陈述相同事实的方式有很多种，因此典型文本中传达的事实知识每个字少于 12 位。我正在阅读的一篇 ML 论文提到了一个数值估计：
&lt;块引用&gt;
[4]
截至 2024 年 2 月 1 日，英语维基百科总共包含 45 亿个单词，请参阅 https://en.wikipedia。 org/wiki/Wikipedia:Size_of_Wikipedia#Size_of_the_English_Wikipedia_database，访问于 2024 年 3 月。
据估计，英语教科书的非重叠内容总共不到160亿字，参见
备注 G.1。这总计 205 亿个单词，但我们认为它们包含的知识不到 140 亿位。

但没有提供参考资料，因此我的问题是：
英文文本中每个单词有多少知识点？
&lt;小时/&gt;
对版主和反对者的回应：
一位版主坚持认为，提及“知识（文本）”的帖子必须被禁止。给出它的定义。
这对我来说似乎很奇怪，因为“知识”一词是在我看来。在NLP、信息抽取、知识抽取等领域已经被普遍理解。否则，他们想抽取什么？
当然，这个术语很难甚至不可能精确定义。但“图书馆”这个词也不是。你需要有多少本书才能成为一个“图书馆”？一把“椅子”也没有明确定义，但我打赌你仍然可以在你的房子里数它们。
定义“知识”作为“文本中的有用信息”只会把责任推给“有用”。
虽然我无法给出“知识”的清晰定义，但允许它被量化，我可以尝试对其进行上限和下限：

下限：知识（文本形式）是被提取到图形结构（例如 Google 的知识图谱）中的信息。这是一个下限，因为现有的方法可能会遗漏一些东西。
上限：知识（文本形式）是翻译中保留的信息。这是一个上限，因为其他一些内容会被保留（文档的整体结构等）

与其他信息一样，这两者都是可量化的。]]></description>
      <guid>https://stats.stackexchange.com/questions/645182/how-many-bits-of-knowledge-are-there-in-english-text-per-word</guid>
      <pubDate>Tue, 16 Apr 2024 21:31:36 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程回归在哪些方面是参数和非参数的？</title>
      <link>https://stats.stackexchange.com/questions/645170/in-what-ways-is-gaussian-process-regression-both-parametric-and-non-parametric</link>
      <description><![CDATA[高斯过程回归被认为是“非参数”回归。模型。然而，术语“非参数”是指术语“非参数”。通常不精确地用来表示不同的事物，导致 关于什么是非参数的问题。这种混淆在“非参数统计”部分中得到了强调。维基百科文章，讨论了“非参数”的两种解释：
&lt;块引用&gt;

不依赖属于任何特定概率分布参数族的数据的技术。这些可以由无分布方法组成，其中数据不需要从“参数族”中提取。概率分布或由定义为样本函数的统计数据组成，不依赖于参数。
不假设模型结构是固定的技术。通常，模型的大小会增加以适应数据的复杂性。在这些技术中，通常假设各个变量属于参数分布，并且还对变量之间的关联类型做出假设。例如，非参数回归，即以非参数方式处理变量之间关系结构的建模，但仍然可能存在关于模型残差分布的参数假设。


问题：
鉴于此，高斯过程回归在哪些方面是参数化的，在哪些方面是非参数化的？
回答问题的其他帮助
虽然为什么高斯过程模型被称为非参数模型？ 
是一个类似的问题，该问题和接受的答案仅（不精确地）解决在非参数的一种定义下如何将 GP 视为非参数，而不是上述（非）参数模型的不同定义。
理想的答案应该足够精确，至少可以讨论以下内容：

有关核、协方差结构和函数的假设。
参数随 N 增长
优先于函数而不是具体参数
]]></description>
      <guid>https://stats.stackexchange.com/questions/645170/in-what-ways-is-gaussian-process-regression-both-parametric-and-non-parametric</guid>
      <pubDate>Tue, 16 Apr 2024 19:42:57 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中的贝叶斯相关性中很难获得贝叶斯因子（来自 BayesFactor 的 correlationBF）</title>
      <link>https://stats.stackexchange.com/questions/644203/difficulty-obtaining-bayesfactor-in-baysian-correlation-in-r-correlationbf-from</link>
      <description><![CDATA[我对贝叶斯分析相对较新，目前正在计算数据集 (df_clean) 中两个情感极化测量值（val_pvv 和 ther_pvv）之间的贝叶斯相关性。目标是定量地证明它们的高度相似性。
我的方法是使用 BayesFactor 包中的 correlationBF 函数，如下所示：
cor_pvv_ther_val &lt;-correlationBF(df_clean$val_pvv, df_clean$ther_pvv)

这会导致以下警告：
警告消息：在 genhypergeo_series_pos(U = c((n - 1)/2, (n - 1)/2) 中，L = ((n + : 系列未收敛。

尽管有此警告，describe_posterior 函数仍提供后验分布的摘要，但它不包括贝叶斯因子 (BF)：
&lt;前&gt;&lt;代码&gt;describe_posterior(cor_pvv_ther_val)

后验分布总结

参数|中位数 | 95% CI | PD |绳索 | % 绳索 | BF |事先的
-------------------------------------------------- ---------------------------------------
罗| 0.92 | 0.92 [0.90, 0.93] | 100% | [-0.05, 0.05] | 0% | |贝塔 (3 +- 3)

也可以在这里看到：
&lt;前&gt;&lt;代码&gt;&gt; extractBF(cor_pvv_ther_val)
          bf错误时间码
替代，r=1 NA 0 2024 年 4 月 3 日星期三 16:54:41 1f88c5878bf

鉴于中位数较高，我怀疑 BF 计算的问题可能与极端相关值有关，可能导致 BF 计算出现一些问题。虽然零模型的显着相关性和低概率是显而易见的（并且其他输出也非常清楚），但获得 BF 必须在我的分析报告中保持一致。我在修改 rscale 参数（例如，wide 或 ultrawide）时遇到同样的问题。
如果您能获得有关该警告的更多信息以及有关如何解决该问题的一些建议，我将非常高兴。
提前非常感谢您！
&lt;小时/&gt;
非常感谢您的宝贵建议！这是有道理的，数值精度问题与非常大的数字有关，我能够获得您的示例的 BF，但在运行我的代码时仍然无法获得 BF：
cor_pvv_ther_val &lt;-correlationBF(x = df_clean$val_pvv, y = df_clean$ther_pvv, 迭代 = 999999)

举一个可重现的例子，在这种情况下我也无法获得贝叶斯因子：
correlationBF(c(1,2,3,4,5,6,7,8,9), c(0.7, 2.3, 2.5, 3.8, 5.2, 5.8, 7.5, 8.4, 8.8),迭代次数 = 99999999)

我知道贝叶斯因子并没有真正提供额外的信息，并且在所描述的上下文中可能被认为是无用的证据，但我有必要在结果描述中保持一致。]]></description>
      <guid>https://stats.stackexchange.com/questions/644203/difficulty-obtaining-bayesfactor-in-baysian-correlation-in-r-correlationbf-from</guid>
      <pubDate>Wed, 03 Apr 2024 15:07:40 GMT</pubDate>
    </item>
    <item>
      <title>如何确定足够的功效所需的样本量来比较混合模型中固定效应的水平？</title>
      <link>https://stats.stackexchange.com/questions/632974/how-to-determine-sample-size-needed-for-sufficient-power-to-compare-between-leve</link>
      <description><![CDATA[我对受试者内部实验进行了一项试点研究，其中感兴趣的固定效应是分类的，有 4 个级别。研究问题涉及比较该 IV 的哪些水平在统计上可以被视为相似与不同。
这是一个简化的示例。假设对于 A、B、C、D 级，这些条件下的平均反应时间为 1000 毫秒、1100 毫秒、1150 毫秒和 1175 毫秒。通过轮换参照组，我们确定：(1) A B 和 C 水平在统计上均不同，(2) D 水平与 A 和 B 不同，但 (3) C 和 D 相当。
如上所述，我有试点数据，并且也很乐意进行基于模拟的分析。但我发现的所有工具似乎都在告诉我检测固定效应效果所需的样本量，这显然不足以实现我的实际目标。例如，simR 确信我只需要大约 12 名参与者即可获得 80% 的功效，尽管效果大小不同且每个条件的试验规模较小 (30)。
我也尝试过仅基于数据子集运行 simR（例如，仅比较级别 2 和 3 或 3 和 4），但当然这是非常有缺陷的（例如，级别 3 和 4 突然变得显着不同） ）此外，我知道我需要更大的样本来解释实际分析中的额外水平。所以这种方法没有真正的实用性。
请注意，在我的领域，我使用混合效应模型是一个强烈的惯例，这也是项目预注册分析计划中记录的内容。如果可能的话，请不要只是告诉我切换到[在此处插入您最喜欢的分析方法]会更容易。]]></description>
      <guid>https://stats.stackexchange.com/questions/632974/how-to-determine-sample-size-needed-for-sufficient-power-to-compare-between-leve</guid>
      <pubDate>Sun, 03 Dec 2023 23:31:17 GMT</pubDate>
    </item>
    </channel>
</rss>