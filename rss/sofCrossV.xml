<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 16 Jul 2024 15:13:37 GMT</lastBuildDate>
    <item>
      <title>我是否正确构建了 Neyman 正交分数？</title>
      <link>https://stats.stackexchange.com/questions/651159/have-i-constructed-the-neyman-orthogonal-score-correctly</link>
      <description><![CDATA[我正在尝试使用 Chernozhukov 等人 (2018) 的 2.2 节为泊松 m 估计量构建一个 Neyman 正交分数。我做对了吗？如果是这样，有人能帮我展示/证明它在分析上是 Neyman 正交的吗？
考虑一个一般的指数模型
\begin{equation}
\mathbb{E}[y_{ijt} | x_{ijt}, \alpha_{it}, \gamma_{jt}, \eta_{ij}] = \exp(x_{ijt} \beta + \alpha_{it} + \gamma_{jt} + \eta_{ij}),
\end{equation&gt;
以及最大化问题
\begin{equation}
\max_{\beta \in \mathcal{B}, \theta \in \Theta} \mathbb{E} [l(y; \beta, \theta)],
\end{equation&gt;
其中我将回归量拆分为感兴趣的参数$x_{ijt}&#39; \beta$和固定效应（或干扰参数），$z_{ijt}&#39; \theta$。泊松
（伪）对数似然函数由以下公式给出：
\begin{equation}
l(y; \beta, \theta) = \sum_{i=1}^n \left( y_{ijt} (x_{ijt}&#39; \beta + z_{ijt}&#39; \theta) - \exp(x_{ijt}&#39; \beta + z_{ijt}&#39; \theta) - \ln \Gamma (y_{ijt} + 1) \right)。
\end{equation
奈曼正交分数
现在考虑新的分数函数，我们将其称为奈曼正交分数，
\begin{equation}
\psi(y; \beta, \eta) = \partial_\beta l(y; \beta, \theta) - \mu \partial_\theta l(y; \beta, \theta),
\end{equation
其中 $\mu$ 是 $d_\beta \times d_\theta$ 正交化参数矩阵，其真实值 $\mu_0$ 可解方程
$
J_{\beta\theta} - \mu J_{\theta\theta} = 0
$
对于
$
J = 
\begin{pmatrix}
J_{\beta \beta} &amp; J_{\beta \theta}\\
J_{\theta \beta} &amp; J_{\theta \theta}
\end{pmatrix}
$
并且当$J_{\theta \theta}$可逆时，有唯一解
$
\mu_0 = J_{\beta\theta} J_{\theta \theta}^{-1}。
$
偏导数
给定对数似然函数，我们有关于$\beta$的偏导数：
\begin{equation}
\partial_\beta l(y; \beta, \theta) = X&#39; \left( Y - \exp(X \beta + Z \theta) \right),
\end{equation&gt;
以及关于$\theta$的偏导数：
\begin{equation}
\partial_\theta l(y; \beta, \theta) = Z&#39; \left( Y - \exp(X \beta + Z \theta) \right),
\end{equation
其中 $\exp(X \beta + Z \theta)$ 是一个 $n \times 1$ 列向量，需要将其对角化为 $n \times n$ 矩阵才能进一步求导，我们将其称为 $D$。
矩阵 $J$ 的元素
我们计算 $J_{\beta \theta}$ 如下：
\begin{equation}
J_{\beta \theta} = \mathbb{E}\left[ -\partial_\beta \partial_\theta l(y; \beta, \theta) \right] = \mathbb{E}\left[ X&#39; D Z \right],
\end{equation&gt;
并计算 $J_{\theta \theta}$ 如下：
\begin{equation}
J_{\theta \theta} = \mathbb{E}\left[ -\partial_\theta^2 l(y; \beta, \theta) \right] = \mathbb{E}\left[ Z&#39; D Z \right].
\end{equation
计算$\mu_0$
假设$J_{\theta \theta}$可逆，我们计算$\mu_0$：
$
\mu_0 = J_{\beta\theta} J_{\theta\theta}^{-1} = \mathbb{E}\left[ X&#39; D Z \right] \left(\mathbb{E}\left[ Z&#39; D Z \right]\right)^{-1}。
$
Neyman 正交得分
最后，我们构建 Neyman 正交得分函数：
$
\psi(y; \beta, \eta) = \partial_\beta l(y; \beta, \theta) - \mu \partial_\theta l(y; \beta, \theta)
$
用 $\partial_\beta l(y; \beta, \theta)$、$\partial_\theta l(y; \beta, \theta)$ 和 $\mu_0$ 的表达式代入：
\begin{equation}
\psi(y; \beta, \eta) = X&#39; \left( Y - \exp(X \beta + Z \theta) \right) - \left( \mathbb{E}\left[ X&#39; D Z \right] \left( \mathbb{E}\left[ Z&#39; D Z \right] \right)^{-1} \right) Z&#39; \left( Y - \exp(X \beta + Z \theta) \right)。
\end{equation&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/651159/have-i-constructed-the-neyman-orthogonal-score-correctly</guid>
      <pubDate>Tue, 16 Jul 2024 15:10:17 GMT</pubDate>
    </item>
    <item>
      <title>理解可忽略性和混杂变量</title>
      <link>https://stats.stackexchange.com/questions/651158/understanding-ignorability-and-confounding-variables</link>
      <description><![CDATA[我正在阅读使用回归和分层模型进行数据分析，对可忽略性的概念感到困惑。书中的描述似乎说了不同的事情。

换句话说，
我们不一定期望任何两个（学校）班级有相同的概率
接受补充版本的治疗。但是，我们预期任何两个（学校）班级在混杂协变量（即治疗前变量；在我们的例子中，是平均预测试分数）水平相同的情况下，接受补充版本的治疗的概率相同。


思考可忽略性假设的第三种方式是，它要求我们控制所有混杂协变量，即与治疗和结果相关的预处理变量。

对我来说，第一个陈述似乎表明，在任何给定的混杂变量水平内（例如，对于具有低/中/高预测试分数的学生），治疗与控制的分布应该大致相等。也就是说，如果预测试分数低的学生接受治疗的概率与不接受治疗的概率相同，那么接受治疗的预测试分数低的学生人数应该大致等于不接受治疗的人数。但是，这通常（几乎按照定义？）不适用于混杂变量。在大多数情况下，混杂变量之所以混杂，是因为在某些混杂因素水平上接受治疗的单位多于其他水平。那么，如果存在任何混杂变量，即使它们受到控制，可忽略性又如何能得到满足呢？
在书中，他们还写道：

这表明，一旦我们以混杂协变量 X 为条件，潜在结果 (y0, y1) 的分布在治疗变量 T 的各个水平上都是相同的。

这 ^ 似乎与 此处的解释 非常吻合。鉴于此定义，我想知道，是否真的可以确定可忽略性是否得到满足？有哪些方法可以确定是否满足？]]></description>
      <guid>https://stats.stackexchange.com/questions/651158/understanding-ignorability-and-confounding-variables</guid>
      <pubDate>Tue, 16 Jul 2024 15:09:39 GMT</pubDate>
    </item>
    <item>
      <title>当计数主要为零时，标准负二项回归？</title>
      <link>https://stats.stackexchange.com/questions/651155/standard-negative-binomial-regression-when-counts-are-mainly-zeros</link>
      <description><![CDATA[这个问题肯定已经被问过很多次了，但我找不到答案。
我对何时使用零膨胀负二项回归与标准负二项回归感到非常困惑。
我正在比较两组受试者生病的次数。零是真正的零，因为我们设计的实验使我们拥有所有相关数据。然而，大约三分之二的人在测量期间没有生病，这意味着有“过多的零”。
我现在已经阅读了很多资料，这些资料说零膨胀负二项回归用于“过多的零计数”，但它也适用于数据生成过程意味着它们不是真正的零（或者零不可能是零以外的任何东西）的模型。我的实验不是这种情况。因此，我不确定我是否可以使用常规负二项回归。有人可以建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651155/standard-negative-binomial-regression-when-counts-are-mainly-zeros</guid>
      <pubDate>Tue, 16 Jul 2024 14:19:10 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯 MCMC 和一次仅更新部分变量</title>
      <link>https://stats.stackexchange.com/questions/651152/bayesian-mcmc-and-only-updating-some-variables-at-a-time</link>
      <description><![CDATA[我想在高斯混合模型上进行贝叶斯 MCMC。但是，我想更新与其他组件不同的单个组件的均值、权重和协方差矩阵。是否存在变量更新不够频繁的问题？例如，如果我有四个组件，那么每个变量最多只能每四次迭代更新一次。但话又说回来，我看不出这会如何影响细节平衡。有这方面的文献吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651152/bayesian-mcmc-and-only-updating-some-variables-at-a-time</guid>
      <pubDate>Tue, 16 Jul 2024 13:08:57 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯中介分析</title>
      <link>https://stats.stackexchange.com/questions/651151/bayesian-mediation-analysis</link>
      <description><![CDATA[我有：

1 个二元结果 (0, 1)
1 个连续定量中介变量
1 个连续定量预测变量

我想用 Liu et al. (2023) 方法计算贝叶斯中介分析。公式为 

我将两条路径的先验概率值指定为默认值 1 (Liu et al., 2023)
对于一条路径，我已经使用默认 JZS beta 先验执行了贝叶斯线性回归。因此，我有一个 BF10 路径。
对于 b 路径，我使用默认 CH 先验 (1, n, 0) 执行了贝叶斯逻辑回归。因此，我有一个 BF10 路径。

然后只需在公式中应用这些值并计算 BFmed 即可？这样对吗？还是我需要进行修改，因为在我的情况下结果是二进制的，因此 BFa 和 BFb 来自两个不同的分析？
感谢您的帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/651151/bayesian-mediation-analysis</guid>
      <pubDate>Tue, 16 Jul 2024 12:48:26 GMT</pubDate>
    </item>
    <item>
      <title>在 Gradient Bandit 算法推导中添加 Baseline 参数</title>
      <link>https://stats.stackexchange.com/questions/651145/adding-of-baseline-parmter-in-derivation-of-gradient-bandit-algorithm</link>
      <description><![CDATA[在 Sutton 和 Barto 所著的强化学习一书第 2.8 章中，在梯度赌博机算法的推导中，他们引入了一个基线项 $B_t$，我似乎无法理解添加这样一个项的直觉。我理解它如何影响数学，以及方程式如何由于它的添加而保持不变。是否有数学逻辑主张添加这样的项？随意添加任何常量参数似乎不直观




]]></description>
      <guid>https://stats.stackexchange.com/questions/651145/adding-of-baseline-parmter-in-derivation-of-gradient-bandit-algorithm</guid>
      <pubDate>Tue, 16 Jul 2024 11:02:47 GMT</pubDate>
    </item>
    <item>
      <title>Geom_smooth 预测计数警告[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651143/geom-smooth-of-predicted-count-warnings</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651143/geom-smooth-of-predicted-count-warnings</guid>
      <pubDate>Tue, 16 Jul 2024 10:48:15 GMT</pubDate>
    </item>
    <item>
      <title>稳定逆概率加权 (IPW) 的夹心方差估计量或基于引导的方差</title>
      <link>https://stats.stackexchange.com/questions/651142/sandwich-variance-estimator-or-bootstrap-based-variance-for-stabilized-inverse-p</link>
      <description><![CDATA[多篇已发表的论文将 IPW 描述为类似于拥有多个相同个体副本的种群。因此，在提供权重的后续分析中，应使用夹心方差估计量或基于 bootstrap 的方差来计算和校正相关性。老实说，我不相信这一点，因为它是一个伪种群，而不是实际种群。
对于稳定的二元暴露 IPTW 权重，总样本量与预加权相同（即没有人为地增加样本量）。这是否意味着不需要使用夹心方差估计量或基于 bootstrap 的方差？如果是，二元结果是否需要它？]]></description>
      <guid>https://stats.stackexchange.com/questions/651142/sandwich-variance-estimator-or-bootstrap-based-variance-for-stabilized-inverse-p</guid>
      <pubDate>Tue, 16 Jul 2024 10:39:54 GMT</pubDate>
    </item>
    <item>
      <title>rms::val.surv 函数对所有情况估计了相同的生存概率</title>
      <link>https://stats.stackexchange.com/questions/651141/rmsval-surv-function-estimated-the-same-survival-probability-for-all-cases</link>
      <description><![CDATA[我已经拟合了一个 cox 回归模型，并使用 val.surv 函数绘制校准图，以比较观察到的生存概率和预测的生存概率。
model &lt;- cph(Surv(Time, status) ~ variable, data = data, surv = T, x = T, y = T, time.inc = 5)
obs_test &lt;- Surv(Time, status)
pred_test &lt;- survest(model, newdata = test_data, times = 5)$surv

val_ests &lt;- val.surv(est.surv = pred_test, S = obs_test, u = 5, fun = function(p)log(-log(p)), pred = sort(runif(100,0,1)))

但是，从 val_ests 中，我看到 val_ests$actual 对所有样本的概率相同。所以校准图显示的是一条平线。
请问这是否主要是由于样本量小？以至于在根据时间和状态估计生存概率时，不足以区分不同的生存概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/651141/rmsval-surv-function-estimated-the-same-survival-probability-for-all-cases</guid>
      <pubDate>Tue, 16 Jul 2024 10:21:10 GMT</pubDate>
    </item>
    <item>
      <title>Lavaan 估算器</title>
      <link>https://stats.stackexchange.com/questions/651139/lavaan-estimator</link>
      <description><![CDATA[我做了一个三波研究，对每波进行了重复测量。我有两个问题：
我正在为一个配置模型做 CFA（在 3 个时间点测试我的模型中每个变量的时间不变性）。
configural_model &lt;- &#39;
# 时间 1
Bullying_1 =~ a1_bul_1 + a1_bul_2 + a1_bul_3 + a1_bul_4 + a1_bul_5 + a1_bult_6

# 时间 2
Bullying_2 =~ a2_bul_1 + a2_bul_2 + a1_bul_3 + a2_bul_4 + a2_bul_5 + a2_bul_6

# 时间 3
Bullying_3 =~ a3_bul_1 + a3_bul_2 + a3_bul_3 + a1_bul_4 + a3_bul_5 + a3_bul_6
&#39;
# 拟合配置模型
fit_configural &lt;- cfa(configural_model, data = df, std.lv = TRUE, estimator = &quot;MLR&quot;)

# 总结配置模型拟合
summary(fit_configural, fit.measures = TRUE, unified = TRUE)

问题

我正在使用 Lavaan，我的数据是非正态的（右偏）且很小（每次 90 个观测值）。
我应该使用 MLR 还是 MLM 估计器？
我问这个问题是因为我用 MLM 得到了更好的结果，尽管我认为 MLR 更常用。
我曾尝试用我的模型的几个变量一次一个地测试配置模型，而且我总是得到糟糕的 RMSEA 值，即使我得到了良好的 CFI、TLI 或 RSMR。如果是一个变量的话，我可以理解，但对于所有变量，我觉得这很奇怪。
]]></description>
      <guid>https://stats.stackexchange.com/questions/651139/lavaan-estimator</guid>
      <pubDate>Tue, 16 Jul 2024 09:56:45 GMT</pubDate>
    </item>
    <item>
      <title>如何处理具有单个控制组的元分析中的依赖效应大小？</title>
      <link>https://stats.stackexchange.com/questions/651138/how-to-handle-dependent-effect-sizes-in-meta-analysis-with-a-single-control-grou</link>
      <description><![CDATA[我正在开展荟萃分析，需要有关从多个治疗组与单个对照组进行比较的研究中提取效应量的建议。具体来说，我正在处理三种不同药物剂量的标准均值差异 (Hedge&#39;s g)，但只有一个载体（对照组）。我想提取给药后 30 分钟的效应量。
鉴于这三个效应量并不独立（因为它们共享同一个对照组），在这种情况下应遵循的最佳策略是什么？我如何在荟萃分析中准确解释这些效应大小之间的依赖关系？
如能提供任何可有效处理此问题的指导或相关方法的参考，我们将不胜感激。
]]></description>
      <guid>https://stats.stackexchange.com/questions/651138/how-to-handle-dependent-effect-sizes-in-meta-analysis-with-a-single-control-grou</guid>
      <pubDate>Tue, 16 Jul 2024 09:55:04 GMT</pubDate>
    </item>
    <item>
      <title>检验组间经验累积分布函数的差异</title>
      <link>https://stats.stackexchange.com/questions/651134/test-for-differences-in-empirical-cumulative-distribution-functions-between-grou</link>
      <description><![CDATA[我可以使用什么测试来测试两个或多个组之间的经验累积分布函数的差异？请注意，我不是在寻找比较两个 ecdf 的测试（例如 Kolmogorov-Smirnov 测试），而是寻找两个/几个组，其中有几个样本，每个样本都有自己的 ecdf。例如，在下图中，两个组之间是否存在显着差异，每个组包含三个样本？附加问题：这些组在整个 ecdf 曲线上存在差异还是仅在部分曲线上存在差异，如果是，是哪一部分？非常感谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/651134/test-for-differences-in-empirical-cumulative-distribution-functions-between-grou</guid>
      <pubDate>Tue, 16 Jul 2024 09:32:44 GMT</pubDate>
    </item>
    <item>
      <title>同一 IV 的不同变换 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/651131/different-transformation-of-the-same-iv</link>
      <description><![CDATA[假设我有一个包含 2 个段的面板数据。我想运行合并 OLS 回归。我正在分别对每个段进行数据转换。假设对于段 A，我正在进行对数转换，而对于段 B，我正在对同一变量进行平方根转换。这可能吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651131/different-transformation-of-the-same-iv</guid>
      <pubDate>Tue, 16 Jul 2024 08:12:42 GMT</pubDate>
    </item>
    <item>
      <title>多个样本的最小值或最大值的中值是多少？</title>
      <link>https://stats.stackexchange.com/questions/651122/what-is-the-median-of-the-minimum-or-maximum-of-multiple-samples</link>
      <description><![CDATA[假设我有一个已知分布的变量，假设我对该变量进行 k 次采样并记录最小值。如果我重复多次，最小值的中位数是否会收敛到一个可预测的值？如果会，这个值是多少？
我的直觉告诉我，中位数将收敛到累积概率为 1/(k+1) 的值，但我无法证实这一点。
请注意，我找到了一个关于正态分布样本的最大值预期值的讨论：正态分布样本的最大值预期值。但是，该讨论没有提到中位数，我认为中位数应该更简单。]]></description>
      <guid>https://stats.stackexchange.com/questions/651122/what-is-the-median-of-the-minimum-or-maximum-of-multiple-samples</guid>
      <pubDate>Tue, 16 Jul 2024 01:41:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 xgboost 的 Logloss 比随机猜测更差</title>
      <link>https://stats.stackexchange.com/questions/651120/logloss-worse-than-random-guessing-with-xgboost</link>
      <description><![CDATA[我有一个二元分类问题，目前正尝试使用 xgboost 解决。这是一个处理时间序列的低信噪比情况。我的样本外 AUC 为 0.65，这还算可以（比随机猜测的结果好，后者会给出 0.5）。但是，我的对数损失非常高，大约为 0.68。看看这个答案二元分类器的“愚蠢”对数损失，考虑到我有 20% 的正样本，我预计对数损失会低于
0.2*log(0.2) + 0.8*np.log(0.8) = 0.5

但是，我的对数损失看起来相当糟糕，但同时，AUC 看起来还可以。 F1 也还好，大约为 0.35（以 20% 的概率猜测 1 的随机分类器将实现 F1=0.2）。
我主要困惑于我如何得到如此高的对数损失，是我做错了什么，还是我误解了什么？即使我的特征是纯噪音（我不认为它们是），xgboost 怎么不能得到较低的对数损失？
注意：我上面使用和报告的 AUC 来自 sklearn.metrics.roc_auc_score，其他所有指标也是如此。]]></description>
      <guid>https://stats.stackexchange.com/questions/651120/logloss-worse-than-random-guessing-with-xgboost</guid>
      <pubDate>Tue, 16 Jul 2024 00:54:34 GMT</pubDate>
    </item>
    </channel>
</rss>