<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 19 May 2024 21:13:48 GMT</lastBuildDate>
    <item>
      <title>需要帮助：使用外生变量和小样本量进行销售预测</title>
      <link>https://stats.stackexchange.com/questions/647569/help-needed-sales-forecasting-with-exogenous-variables-and-small-sample-size</link>
      <description><![CDATA[我正在撰写一篇论文，使用 Google 趋势数据来预测零售环境中的销售收入。我仅使用指数平滑和 SARIMA 作为销售数据的单变量基线模型。对于 Google 趋势搜索词的多元部分，我尝试过 SARIMAX 和 XGBoost。
但是，由于样本量较小（68 个每月观察值），我面临着挑战。我将数据分成 12 个月的训练/测试集，这留下了有限的训练数据。销售数据还受到电晕和通货膨胀等外部因素的影响。虽然数据每天都可用，但由于 Google 趋势仅提供五年以上的每月数据，因此我必须将其汇总到每月。我有超过 50 个不同的 Google 趋势搜索词，并使用 LASSO 执行特征选择。我知道推断存在问题。
小样本能否有效支持SARIMAX和XGBoost模型？使用 LASSO 进行特征选择是正确的方法吗？还是您会推荐其他方法？此外，尽管 Google 趋势存在聚合问题，是否有办法利用每日数据？
任何建议或见解将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/647569/help-needed-sales-forecasting-with-exogenous-variables-and-small-sample-size</guid>
      <pubDate>Sun, 19 May 2024 20:34:09 GMT</pubDate>
    </item>
    <item>
      <title>混淆矩阵在深度学习中的含义与在假设检验中的含义相同吗？</title>
      <link>https://stats.stackexchange.com/questions/647567/is-the-confusion-matrix-meaning-the-same-within-deep-learning-than-within-hypoth</link>
      <description><![CDATA[混淆矩阵在深度学习中的含义与在假设检验中的含义相同吗？
我已经阅读了矩阵是什么以及如何获取值。但以深度学习分类为例，
我们知道真实的值（至少是由人类指定的。）
而且我不确定这种情况是否有任何假设。
另一方面，在进行假设检验时，大多数时候你不会知道真正的答案，而且在我看来，问题的构建方式似乎完全不同。
在这些情况下混淆矩阵是否有不同的解释？]]></description>
      <guid>https://stats.stackexchange.com/questions/647567/is-the-confusion-matrix-meaning-the-same-within-deep-learning-than-within-hypoth</guid>
      <pubDate>Sun, 19 May 2024 20:16:11 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯统计与频率统计对于无信息统一先验的影响</title>
      <link>https://stats.stackexchange.com/questions/647565/bayesian-statistics-vs-frequentist-statistics-for-uninformative-uniform-priors</link>
      <description><![CDATA[我有一个关于贝叶斯统计的非常基本的问题。
假设您有一个无信息先验，您知道该先验来自均匀分布。在频率统计中使用贝叶斯方法与使用 MLE 方法相比有什么好处吗？您不会得到类似的结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647565/bayesian-statistics-vs-frequentist-statistics-for-uninformative-uniform-priors</guid>
      <pubDate>Sun, 19 May 2024 18:58:30 GMT</pubDate>
    </item>
    <item>
      <title>H0 和 H1 图中的 alpha 和 beta 的解释是什么？</title>
      <link>https://stats.stackexchange.com/questions/647564/what-is-the-interpretation-of-alpha-and-beta-within-the-plots-of-a-h0-and-h1</link>
      <description><![CDATA[阅读统计功效时，他们画出了这个：

并说：

给定零假设（抽样分布 1）和备择假设（抽样分布 2），说明统计检验的功效和显着性水平。

我不明白$\alpha$和$\beta$与图表相关。您能给我一些提示吗？

这些高斯概率分布曲线（可能是任何其他曲线）是否分别针对一组人 - 比如身高，或者它们是许多组人的均值分布？（仅以均值为例。）
]]></description>
      <guid>https://stats.stackexchange.com/questions/647564/what-is-the-interpretation-of-alpha-and-beta-within-the-plots-of-a-h0-and-h1</guid>
      <pubDate>Sun, 19 May 2024 18:42:42 GMT</pubDate>
    </item>
    <item>
      <title>对比例数据使用方差分析</title>
      <link>https://stats.stackexchange.com/questions/647563/using-anova-with-proportional-data</link>
      <description><![CDATA[我知道这个问题已经在多个问题中进行了讨论，但我还没有得出结论。
以下场景：
我有两组：干预组和对照组。两者都会进行某种预测试，测量的指标是正确交叉元素的百分比，其中每个主题的交叉元素总数可能会有所不同，因为有时间限制。干预后进行相同的测试。当然，我想检查干预是否提高了正确交叉元素的平均百分比。
我的第一反应是进行双向重复测量方差分析，可能随后进行适当的事后测试。但当我想到百分比时，我认为有些事情可能很可疑。快速检查方差的正态性和同质性表明这些条件不满足。所以我考虑转换我的数据。一种有用的变换是幂变换（经常使用的反正弦变换没有帮助）。根据 shapiro-wilks 检验和 QQ 图，残差现在可以接受正态分布，并且所有水平上的方差是均匀的。
我是否走在正确的道路上，或者正如我在各种帖子中读到的那样，这是否有问题？感谢您的澄清！]]></description>
      <guid>https://stats.stackexchange.com/questions/647563/using-anova-with-proportional-data</guid>
      <pubDate>Sun, 19 May 2024 18:01:54 GMT</pubDate>
    </item>
    <item>
      <title>负多项式 CDF 实现与仿真不匹配</title>
      <link>https://stats.stackexchange.com/questions/647561/negative-multinomial-cdf-implementation-does-not-match-simulation</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647561/negative-multinomial-cdf-implementation-does-not-match-simulation</guid>
      <pubDate>Sun, 19 May 2024 17:20:28 GMT</pubDate>
    </item>
    <item>
      <title>VGAM/VGLM 与多个 GAM/GLM</title>
      <link>https://stats.stackexchange.com/questions/647560/vgams-vglms-vs-multiple-gams-glms</link>
      <description><![CDATA[我正在自学向量广义线性/加性模型（主要是），通过 Yee, T. W. (2015)“向量广义线性和加性模型：R 中的实现”。
我认为我误解了该主题的一些非常基本的内容。在我看来，术语“向量”是指“向量”。只是意味着有多个输出需要预测——每个输出本质上都有自己的广义线性/加性模型。但根本没有理由添加该描述符。您只是构建多个广义线性/加性模型。
在关于向量模型的第一章（第 3 章：VGLM）的介绍中，Yee 说“人们可能会松散地将 VGLM 视为多元 GLM，然而，这只是部分正确，因为 GLM 与指数族交织在一起。 ”这似乎有点模糊，他并没有对此进行太多扩展。也许随着我进一步深入本书，这一点会得到澄清，但我主要是在寻找一个示例，其中使用 VGLM/VGAM 与使用多个 GLM/GAM 不同且更好。
这样的例子存在吗？我错过了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647560/vgams-vglms-vs-multiple-gams-glms</guid>
      <pubDate>Sun, 19 May 2024 16:42:38 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们需要使用协方差矩阵来计算PCA中的特征向量和特征值[重复]</title>
      <link>https://stats.stackexchange.com/questions/647558/why-we-need-use-covarience-matrix-to-calculate-eigenvectors-and-eigenvalues-in-p</link>
      <description><![CDATA[我坚持理解使用协方差矩阵来计算特征向量和特征值并选择具有最高特征值的特征向量背后的想法]]></description>
      <guid>https://stats.stackexchange.com/questions/647558/why-we-need-use-covarience-matrix-to-calculate-eigenvectors-and-eigenvalues-in-p</guid>
      <pubDate>Sun, 19 May 2024 16:05:11 GMT</pubDate>
    </item>
    <item>
      <title>原假设是否需要是无差异的陈述？</title>
      <link>https://stats.stackexchange.com/questions/647557/does-the-null-hypothesis-need-be-a-statement-of-no-difference</link>
      <description><![CDATA[我只是想自学统计学的基础知识。而且我不完全理解零假设与备择假设。
我不明白的是：原假设可以是有方向性的陈述，还是必须始终是无差异的陈述？
例如，假设我们有组 1 和组 2：
$$H_0: \mu_1 = \mu 2$$
$$H_1: \mu_1 \neq \mu 2$$
与不同的声明
$$H_0: \mu_1 \leq \mu 2$$
$$H_1: \mu_1 \gt \mu 2$$
这两个语句都有效，因此 $H_0$ 可以具有方向性吗？
我已经与 ChatGPT 讨论过这个问题，但它出现了明显的矛盾。]]></description>
      <guid>https://stats.stackexchange.com/questions/647557/does-the-null-hypothesis-need-be-a-statement-of-no-difference</guid>
      <pubDate>Sun, 19 May 2024 15:53:10 GMT</pubDate>
    </item>
    <item>
      <title>如何使用多元线性回归来预测有意义的值</title>
      <link>https://stats.stackexchange.com/questions/647535/how-to-use-a-multi-linear-regression-to-forecast-meaningful-values</link>
      <description><![CDATA[我构建了一个基于两个预测变量 $P_1$ 和 $P_2$ 的多线性回归模型预测$Q$：
$$
q = A + Bx_1 + Cx_2 + Dx_1^2 + Ex_2^2 + Fx_1*x_2
$$
其中 $x_1$ 和 $x_2$ 是原始预测变量的标准化和去趋势版本 &lt; span class=&quot;math-container&quot;&gt;$P_1$ 和 $P_2$ ($P_1$ span&gt; 和 $P_2$ 有趋势）。我假设 $q$ 是 $Q$ 的预测标准化/去趋势值。回归模型对于我的需要具有统计显着性。
问题：如何使用上面的 MLR 来估计 $Q$ 的值？换句话说，如何从 $q$ 返回到 $Q$ ？如果是这样，我是否需要对我的预测变量进行标准化和去趋势化？
说明：去趋势是指删除了 $P_1$ 和 $P_2f 的线性趋势，标准化表示减去平均值并除以各自的标准差。例如：
$$
x1 = P1 - 均值(P1)/sd(P1) - 线性趋势(P1)
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/647535/how-to-use-a-multi-linear-regression-to-forecast-meaningful-values</guid>
      <pubDate>Sun, 19 May 2024 00:48:55 GMT</pubDate>
    </item>
    <item>
      <title>存在最小足够统计数据的参考请求</title>
      <link>https://stats.stackexchange.com/questions/647503/reference-request-for-the-existence-of-minimal-sufficient-statistics</link>
      <description><![CDATA[我想要一篇最近的论文或书籍来说明在什么条件下我们可以保证最小的充分统计数据的存在。
我知道论文“充分性和统计决策函数&quot; （作者：R.R. Bahadur）和“完整性、相似区域和无偏估计：第一部分” ; （莱曼和谢夫）。但这些论文使用了奇怪的符号，因此很难理解。因此，我想要一篇关于最少的足够统计数据的存在的最新论文或书籍。
感谢您的关注！
&lt;小时/&gt;
我知道有些统计模型没有足够的统计数据，正如您在论文“最小足够 $\sigma$ - 字段和最小充分统计量。两个反例”。
我想知道的是保证存在最低限度的足够统计数据的一些条件。]]></description>
      <guid>https://stats.stackexchange.com/questions/647503/reference-request-for-the-existence-of-minimal-sufficient-statistics</guid>
      <pubDate>Sat, 18 May 2024 14:30:45 GMT</pubDate>
    </item>
    <item>
      <title>无意识统计学家的条件期望定律和条件分布的前推测度</title>
      <link>https://stats.stackexchange.com/questions/647498/law-of-the-unconscious-statistician-for-conditional-expectation-and-pushforward</link>
      <description><![CDATA[设 $(\Omega, \mathcal{A}, \mathbb{P})$ 为概率空间，$X:(\Omega,\mathcal{A})\rightarrow(\mathcal{X}, \mathcal{F})$ 和 $Z:(\ Omega, \mathcal{A}) \rightarrow (\mathcal{Z}, \mathcal{G})$ 两个随机变量。无意识统计学家定律的无条件版本是
$$\mathbb{E}[g(X)]=\int_{\Omega}g(X)(\omega)\mathbb{P}(d\omega)=\ int_{\mathcal{X}}g(x)\mathbb{P}_X(dx)$$
1.) 条件情况看起来如何：
$$\mathbb{E}[g(X)|Z]=\int_{\mathcal{X}}g(x)\mathbb{P}_{X|Z} (dx)$$
2.) 当我们修复一个事件 $z$ 时，情况看起来如何：
$$\mathbb{E}[g(X)|Z=z]=\int_{\mathcal{X}}g(x)\mathbb{P}_{X| Z=z}(dx)$$
也就是说，我想要找到的是这些条件期望与域 $\Omega$ 上的集成的表达式。
这里的根本问题是：什么是条件分布 $\mathbb{P}_{X|Z}$ （以及 $\mathbb{P}_{X|Z=z}$) 的前推度量？
编辑： $\mathbb{P}_{X|Z}$ 是来自 $( \Omega, \sigma(Z))$ 转换为 $(\mathcal{X}, \mathcal{F})$，而 $\mathbb{P}_{X|Z=\cdot}$ 是来自 $(\mathcal{Z}, \mathcal{G})$ 到 $(\mathcal{X}, \mathcal{F})$。
现在，这是正确的吗？
$$\mathbb{E}[g(X)|Z](\omega)=\int_{\mathcal{X}}g(x)\mathbb{P}_{ X|Z}(dx)(\omega)=\int_{\Omega} g(X(\omega&#39;))\mathbb{P}(d\omega&#39;|\sigma(Y))(\omega),$ $
其中 $\mathbb{P}_{X|Z}(F)=\mathbb{P}(X^{-1}(F)|\sigma(Z))$ ，即条件前推度量，并且 $\mathbb{P}(A|\sigma(Y))$ 被假定为常规条件概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/647498/law-of-the-unconscious-statistician-for-conditional-expectation-and-pushforward</guid>
      <pubDate>Sat, 18 May 2024 13:04:36 GMT</pubDate>
    </item>
    <item>
      <title>将质量体积解释为无监督异常检测的评估标准</title>
      <link>https://stats.stackexchange.com/questions/647349/interpreting-mass-volume-as-an-evaluation-criterion-for-unsupervised-anomaly-det</link>
      <description><![CDATA[我找到了这篇论文如何评估无监督异常检测算法的质量？经过
Nicolas Goix 讨论了通过使用作者所说的质量体积和过量质量来评估无监督异常评分函数。我还从这里的论文中找到了代码，这相当不错便利。我专注于 M-V，并试图解释其含义以及为什么它有意义。
质量-体积描述如下：
$$
MV_{s}(\alpha) = \inf_{u \geq 0} Leb(s(\mathbf{U}) \geq u) ~~~ s.t. ~~~ \mathbb{P}(s((\mathbf{X})) \geq u) \geq \alpha
$$
哪里
$\alpha$ 是累积质量
$s$ 是一些异常评分函数
$\mathbf{X}$ 是我们的特征集，维度为 (N,M)
$\mathbf{U}$ 是一个随机生成的多元均匀变量，以下边界 $\inf(\mathbf{ X})$ 和上限 $\sup(\mathbf{X})$。这本质上创建了一个从最小特征值到最大特征值的矩形。
$u$ 是我们评估勒贝格度量的分位数，表示为 $Leb$。
在 Python 中的实现中，如下所示：
clf = SomeAnomalyScoringModel()


阿尔法最小值 = 0.9
阿尔法最大值 = 0.999
axis_alpha = np.arange(alpha_min, alpha_max, 0.0001)


lim_inf = X.min(轴=0)
lim_sup = X.max(轴=0)
n_生成 = 100000
unif = np.random.uniform(lim_inf, lim_sup,
                            大小=（n_生成，n_特征））
Volume_support = (lim_sup - lim_inf).prod()


s_unif = clf.decision_function(unif)
s_x = clf.decision_function(X)


def 质量体积（axis_alpha、volume_support、s_unif、s_X、n_generate）：
    n_samples = s_X.shape[0]
    s_X_argsort = s_X.argsort()
    质量 = 0
    点 = 0
    u = s_X[s_X_argsort[-1]]
    mv = np.zeros(axis_alpha.shape[0])
    对于范围内的 i(axis_alpha.shape[0])：
        而质量&lt; axis_alpha[i]：
            #在这里找你
            cpt += 1
            u = s_X[s_X_argsort[-cpt]]
            质量 = 1./ n​​_samples * cpt # sum(s_X &gt; u)
        mv[i] = float((s_unif &gt;= u).sum()) / n_ generated * volume_support
    返回 auc(axis_alpha, mv), mv

我对这里发生的事情有一个大概的了解。通过对 $s(x)$ 进行排序，我们正在寻找给定 $u$ =&quot;math-container&quot;&gt;$\alpha$ 通过添加 $mass$ 直到达到所需的  $\alpha$-质量。完成后，我们停止，因为我们已经达到约束 $\mathbf{P}(s(\mathbb{X})\geq q) \geq \alpha$&lt; /跨度&gt;。此时，我们计算 $Leb(s(\mathbf{U})\geq u)$。我们对所有所需的 $\alpha$ 级别重复此操作。
这里有两个问题：
我们如何解释这一点？我最好的解释是，我们将评分函数 $s$ 视为均匀分布（由设计没有离群值），并在到达真实得分分布的尾部后测量其累积密度，以勒贝格测量为代表（因此，在本例中只是面积）。但这如何表明 $s$ 是一个好模型呢？
为什么 Lebesgue 定义为 float((s_unif &gt;= u).sum()) / n_generate *volume_support？
当统一变量大于$u$时，这相当于矩形盒子的体积，那么它是二元累积密度吗？这是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647349/interpreting-mass-volume-as-an-evaluation-criterion-for-unsupervised-anomaly-det</guid>
      <pubDate>Thu, 16 May 2024 09:45:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 sigmoid 函数进行线性逻辑回归 - 为什么需要对预测 y 进行转换？</title>
      <link>https://stats.stackexchange.com/questions/647197/making-linear-to-logistic-regression-with-sigmoid-function-why-is-a-transforma</link>
      <description><![CDATA[编辑
我所做的是：

对 y ~ x 运行逻辑回归，其中 y 是二进制，x 是连续随机变量。
使用我在步骤 1 中收到的模型对 x 范围内的 logits (y_logit) 进行预测。
应用逆 logit 将步骤 2 中的 y_logit 值转换为概率 (y_prob)：y_prob &lt;- 1 / (1 + exp(-y_logit))。

之后我开始使用 OLS：

对 y ~ x 运行 OLS 线性回归。
对 y 进行预测x 的范围与我在步骤 4 中收到的模型系数：y_pred &lt;- b0 + b1* x。
运行 OLS，其中我将步骤 2 中的预测 logits y_logit 回归到步骤 5 中的预测 y (y_pred)：y_logit ~ y_pred。这是一个完美的线性拟合。
将步骤 5 中预测的 y_pred 值与步骤 6 中模型的系数进行转换：y_transformed &lt;- b0&#39; + b1&#39;*y_pred。
对步骤 7 中的 y_transformed 应用 S 型函数：y_prob_lm &lt;- 1/ (1 + e^(-y_transformed))。
比较逻辑回归从步骤 3 收到的概率 y_prob 是否与 OLS 从步骤 8 收到的 y_prob_lm 概率相同：是的，它们是相同的。 y_prob = y_prob_lm。

我以为我可以从步骤 5 跳到步骤 8，即我以为我可以直接将 S 型函数应用于 OLS 的预测 y 值。但我必须提前对它们进行转换（步骤 6 和 7）。为什么在使用 OLS 预测概率时，我们需要在应用 S 型函数之前转换预测的 y 值？

R 的整个故事。在执行步骤 1 到 9 之前，我们需要生成数据：
library(magrittr)
# 生成数据
# 使其可重现
set.seed(1)
# 观察次数。
n &lt;- 100000
# 随机 x 变量。
x &lt;- rnorm(n, 50, 10)
# 系数。
b0 &lt;- log(.001)
b_x &lt;- log(1.2)
b_noise &lt;- log(.9)
# 公式。
z &lt;- b0 + b_x* x + b_noise* rnorm(n, 0, 1)
# y。
y &lt;- {1/ (1 + exp(-z))} %&gt;%
rbinom(n= n, size= 1, prob= .) %&gt;%
as.logical()

# 使其成为数据框。
df &lt;- data.frame(x, y, y_num= as.numeric(y) - 1) 

以下是逻辑回归的第 1 至 3 步：
# 拟合模型（步骤 1）。
mod_log &lt;- glm(formula= y ~ x, family= binomial(link=&quot;logit&quot;), data= df)

# 预测哪些值。
df_pred &lt;- data.frame(x= seq(0, max(x), .1))

# 预测。
# logit 预测（步骤 2）
df_pred$log_logit &lt;- predict(mod_log, newdata= df_pred)
# 应用逆 logit 转换为概率（步骤 3）
df_pred$log_prob &lt;- 1 / (1 + exp(-df_pred$log_logit))

plot(df_pred$x, df_pred$log_prob)
# 这会产生一个看似合理的图表。

步骤 4 至 9：
# 运行线性模型 (步骤 4)
mod_lm &lt;- lm(formula= y_num ~ x, data= df)
# 使用线性模型拟合预测 y (步骤 5)
df_pred$lm_y &lt;- coef(mod_lm)[1] + coef(mod_lm)[2] *df_pred$x
# 变换 y。
df_pred$lm_y_transformed &lt;- data.frame(lm_y= df_pred$lm_y, log_logit= df_pred$log_logit) %&gt;%
lm(log_logit ~ lm_y, .) %&gt;% # (步骤 6)
coef() %&gt;%
{.[1] + .[2] *df_pred$lm_y} # (步骤 7)
# 对 y 应用 S 型函数 (步骤 8)
df_pred$lm_prob &lt;- 1/(1 + exp(-df_pred$lm_y_transformed))
# 测试概率是否相同 (步骤 9)。
all.equal(df_pred$log_prob, df_pred$lm_prob)
# 正确！
]]></description>
      <guid>https://stats.stackexchange.com/questions/647197/making-linear-to-logistic-regression-with-sigmoid-function-why-is-a-transforma</guid>
      <pubDate>Tue, 14 May 2024 09:42:09 GMT</pubDate>
    </item>
    <item>
      <title>用于条件概率建模的自回归模型</title>
      <link>https://stats.stackexchange.com/questions/589635/autoregressive-models-for-modeling-conditional-probabilities</link>
      <description><![CDATA[我正在阅读 Tomczak 的深度生成建模。当作者讨论自回归模型时，他提到我们对数据 $p(\mathbf{x})$ 的概率分布进行建模-container&quot;&gt;$\mathbf{x}$ 为 $$p(\mathbf{x}) = p(x_1)\prod_{d=2}^Dp (x_d|\mathbf{x}_{其中 $D$ 是特征维度（例如，图像）和 $\mathbf{x}_{。然后他提到我们可以通过假设“有限内存”来简化这个模型。即 $p(x_d|\mathbf{x}_{，我们假设 $x_d$ 仅取决于前两个特征的值。最后，他解释说，在实践中，我们可以将其建模为以下 MLP（假设我们正在处理图像和像素）：
$$[x_{d-1}, x_{d-2}] \rightarrow \text{线性(2, M)} \rightarrow \text{ReLU} \rightarrow \text {Linear}(M, 256) \rightarrow \text{softmax} \rightarrow \theta_d$$ 其中 $M$ 是隐藏维度，$\theta_d$ 是像素 $d$ 在 256 个可能值中的概率分布。我的问题是关于这样一个模型的训练过程。您是否不需要“逐像素”地训练这个模型？因为对下一个像素的预测取决于前两个像素的值，所以这将是一个效率很低的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/589635/autoregressive-models-for-modeling-conditional-probabilities</guid>
      <pubDate>Wed, 21 Sep 2022 23:56:15 GMT</pubDate>
    </item>
    </channel>
</rss>