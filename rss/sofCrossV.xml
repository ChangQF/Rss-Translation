<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 02 Dec 2024 03:35:44 GMT</lastBuildDate>
    <item>
      <title>在查看数据之前建立模型是否（总是）更好？</title>
      <link>https://stats.stackexchange.com/questions/658116/is-it-always-better-to-build-a-model-prior-to-viewing-the-data</link>
      <description><![CDATA[在数据探索方面，除了检查异常值（人为错误）、相关协变量和缺失值之外，在构建统计模型之前查看响应变量与候选协变量之间的关系是否有缺点？
我听说最好在查看任何关系之前构建模型（基于经过充分研究的背景信息或专业知识），因为此类模型容易出现偏差。这种说法合理吗？我不记得我在哪里听过这个，但我对此有点困惑，因为自从大学以来，我就一直接受训练，根据我在探索数据时观察到的模式来构建模型。
我知道在选择协变量时要非常谨慎（不要一次拟合所有内容，让 AIC 决定保留哪些内容），但了解响应中是否存在非线性模式不是很有用吗，而不是，比如说...从 glm 开始，然后经历检查残差中的模式的整个过程等？]]></description>
      <guid>https://stats.stackexchange.com/questions/658116/is-it-always-better-to-build-a-model-prior-to-viewing-the-data</guid>
      <pubDate>Mon, 02 Dec 2024 01:50:37 GMT</pubDate>
    </item>
    <item>
      <title>您每天花多少时间在社交媒体上？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658115/how-many-hours-do-you-spend-on-social-media-everyday</link>
      <description><![CDATA[您每天花多少小时在社交媒体上？]]></description>
      <guid>https://stats.stackexchange.com/questions/658115/how-many-hours-do-you-spend-on-social-media-everyday</guid>
      <pubDate>Mon, 02 Dec 2024 01:04:05 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们不能使用联合高斯分布直接从维纳过程采样实现？</title>
      <link>https://stats.stackexchange.com/questions/658114/why-cant-we-directly-sample-realizations-from-a-wiener-process-using-its-joint</link>
      <description><![CDATA[我试图理解维纳过程联合分布的采样与过程定义属性之间的关系。以下是我所知道的：

维纳过程$W_t$定义为高斯过程，其具有：
$$
W_0 = 0, \quad W_t \sim \mathcal{N}(0, t), \quad \text{and} \quad \mathrm{Cov}(W_t, W_s) = \min(t, s)。
$$
此外，它具有独立的增量，这意味着：
$$
W_{t+\Delta t} - W_t \sim \mathcal{N}(0, \Delta t),
$$
并且此增量与 $W_t$ 无关。

在任何一组有限的时间点 $t_1, t_2, \ldots, t_n $ 的 $W_t$ 的联合分布是具有协方差矩阵的多元高斯分布：
$$
K_{ij} = \min(t_i, t_j)。
$$
此协方差结构对时间点之间的所有依赖关系进行编码。

鉴于上述情况，理论上应该能够直接从多元高斯联合分布$ \mathcal{N}(0, K) $中进行采样，以获得当时过程的实现。


这是我的困惑：

为什么直接从$ \mathcal{N}(0, K) $中进行采样不完全符合维纳过程定义？具体来说，联合分布不是已经考虑了所有依赖关系，包括独立增量属性吗？

如果联合分布是正确的，是什么阻止它强制执行增量结构？例如，维纳过程要求：
$$
W_{t+\Delta t} - W_t \quad \text{独立于} \quad W_t，
$$
但这难道不是已经编码在 $ K $ 中了吗？

为什么维纳过程不能像高斯过程那样支持直接采样？高斯过程允许一步从其协方差结构中采样完整的实现，而无需迭代采样。


我怀疑这与“过程的实现”与维纳过程的具体构造之间的差异有关，但我很难理解为什么。有人可以澄清区别并解释为什么迭代采样对于维纳过程至关重要，即使联合分布已知？]]></description>
      <guid>https://stats.stackexchange.com/questions/658114/why-cant-we-directly-sample-realizations-from-a-wiener-process-using-its-joint</guid>
      <pubDate>Mon, 02 Dec 2024 00:57:51 GMT</pubDate>
    </item>
    <item>
      <title>不确定 GAM 中适当的转换/链接函数</title>
      <link>https://stats.stackexchange.com/questions/658112/unsure-of-appropriate-transformation-link-function-in-gam</link>
      <description><![CDATA[我正在处理一个具有某种奇怪特征的响应变量，根据我使用 gam.check() 获得的诊断图，我不确定我的模型的适当转换和/或链接函数。
响应变量是混合相对热阻 (RTRM)，这是一个无量纲指数，可用于量化湖泊或池塘分层的程度。RTRM 是两层水之间的密度差 ÷ 4ºC 和 5ºC 时水之间的密度差。这意味着它是一个连续变量，其方差随着值的增加而增加，但从技术上讲它不受零的限制，其实际下限略低于零（我的数据中的最低值约为 -.03）。我正在尝试找出一个使用天气变量为小池塘确定这一点的模型。
这是我正在处理的数据的时间序列和直方图，因此您可以更好地了解这个变量的行为方式。

我对 GAM 并不陌生，但我也没有特别丰富的经验，因此任何建议都将不胜感激。
这是我正在使用的模型公式。独立变量包括温度、风向（圆形）和风速（仅包括与风向的相互作用），所有变量相对于 RTRM 均滞后一天：
Weather.limno%&gt;%
gam(daily.rtrm~ s(temp.lag1)+
ti(wind.dir.lag1, bs = &quot;cc&quot;)+ 
ti(wind.dir.lag1,wind.sp.lag1,
bs = c(&quot;cc&quot;,&quot;ts&quot;)),family = &quot;gaussian&quot;, data = .,
knots=list(wind.dir.lag1=c(0,360)))

当不对 RTRM 进行任何变换时，Q-Q 图和直方图实际上看起来不错，但上面提到的异方差是显而易见且突出的。
  
我尝试全面添加 .05（这在我的数据规模上可以忽略不计）并对 RTRM 值进行对数转换，同时将模型保持在高斯族中。这解决了异方差问题，但残差有点不稳定。我知道我的数据并不是真正的泊松分布，但平方根转换也会发生同样的事情。这些图来自与上述相同的模型，只是响应为 log(daily.rtrm+.05)。
 
高斯家族中的对数链接并不能真正解决这两个问题。残差保持异方差，分布上有较长的右尾。
如果我切换到 tweedie 系列，对数链接和 sqrt 链接（以 daily.rtrm +.05 作为响应）在异方差方面看起来都很好，但残差分布左偏。然而，偏斜程度并不像高斯系列中具有链接函数的模型那么严重。这里只是残差直方图，所以我不会再用图表来堵塞这篇文章。第一个来自 family = tw(link = &quot;log&quot;) 模型，第二个来自 family = tw(link = &quot;sqrt&quot;) 模型。
 
之后，我真的不知道该怎么做了。我是否应该考虑其他分布或链接函数，或者我是否应该选择一个不完美但足够好的函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/658112/unsure-of-appropriate-transformation-link-function-in-gam</guid>
      <pubDate>Mon, 02 Dec 2024 00:49:38 GMT</pubDate>
    </item>
    <item>
      <title>$\text{E}[\mathbf{\varepsilon}\mathbf{\varepsilon}'\mid\mathbf{X}]=\sigma^2\mathbf{I}\implies\text{Var}[\mathbf{\ varepsilon}]=\sigma^2\mathbf{I}$?</title>
      <link>https://stats.stackexchange.com/questions/658111/texte-mathbf-varepsilon-mathbf-varepsilon-mid-mathbfx-sigma2-math</link>
      <description><![CDATA[我正在自学一些计量经济学/线性回归模型。在文中（Greene 2018），假设$\text{E}[\mathbf{\varepsilon}\mathbf{\varepsilon}&#39;\mid \mathbf{X}]=\sigma^2\mathbf{I}$。然后书中指出，通过使用方差分解公式，我们发现
$$
\text{Var}[\mathbf{\varepsilon}] = \text{E}[\text{Var}[\mathbf{\varepsilon}\mid\mathbf{X}]] + \text{Var}[\text{E}[\mathbf{\varepsilon}\mid\mathbf{X}]] = \sigma^2\mathbf{I}。
$$
这里，$\mathbf{\varepsilon}$ 是 $n\times1$ 扰动列向量，$\mathbf{X}$ 是 $n\times K$ 数据矩阵。
我不明白如何得出相等性。有人能帮我解释一下吗？提前谢谢了。]]></description>
      <guid>https://stats.stackexchange.com/questions/658111/texte-mathbf-varepsilon-mathbf-varepsilon-mid-mathbfx-sigma2-math</guid>
      <pubDate>Sun, 01 Dec 2024 23:54:00 GMT</pubDate>
    </item>
    <item>
      <title>如何确定配对调查中混杂因素/介质/风险因素/效应修饰因素的强度和方向变化的统计意义？</title>
      <link>https://stats.stackexchange.com/questions/658108/how-to-establish-statistical-significance-of-changes-in-strength-direction-of</link>
      <description><![CDATA[首先，我是生物统计学的新手（一年多前上过一门生物统计学入门课），所以请耐心等待 :-) ...
我在疫情之前（F0 调查）和疫情之后（F2 调查）进行了配对调查。我有兴趣研究疫情对一个序数依赖结果：工作尊重（或 RS）和两个独立序数变量：工作满意度（或 JS）和离职意向工作场所（或 ITL）之间的关系的影响？
我还在研究几个疫情前/疫情后协变量（即混杂因素、介质、风险因素和效应调节因素）可能对上述关系产生的影响。这些变量是序数、名义、连续和二元的。现在，我有以下零假设。
1) 疫情没有导致 RS 和 JS 之间的关系发生变化
2) 疫情没有导致 RS 和 ITL 之间的关系发生变化。
3) 疫情没有导致混杂因素、
介质、风险因素和效应修饰因子的强度和方向发生变化。
我相信我可以使用非参数配对序数的 Wilcoxon 符号秩检验来确定前两个零假设的统计显着性 (SS)（正确吗？）。但我如何对第三个假设做同样的事情？我可能有几种选择：
A) 将配对协变量视为独立变量，并对配对变量类型进行适当的测试以建立 SS。这是有效的吗？
 ... 或 ...

B) 确定协变量前后有序回归系数的变化（对于 RS 和 JS 以及 RS 和 ITL）并以某种方式确定这些变化的 SS？这些变化是否与混杂因素、介质、风险因素和效应调节剂的变化直接相关？
此外，我不确定要对带有协变量的 SS 执行哪组测试。
ChatGPT 一直建议对混杂因素使用混合效应模型或广义估计方程 (GEE)。使用交叉滞后面板模型等技术对中介变量进行时变中介分析，在回归模型中加入效应调节器的交互项等，这些内容相当复杂，坦率地说，远远超出了我的理解范围。
不确定建议的信息有多准确，因为 ChatGPT 有时会撒谎或在回应中“非常热情”……谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658108/how-to-establish-statistical-significance-of-changes-in-strength-direction-of</guid>
      <pubDate>Sun, 01 Dec 2024 23:07:34 GMT</pubDate>
    </item>
    <item>
      <title>如果对于任何 $v_i$，$\operatorname{var}\left(\sum_{ij}A_{ij}v_{i}v_{j}\right)=0$，那么 $\operatorname{var}(A_{ij})=0$？</title>
      <link>https://stats.stackexchange.com/questions/658101/if-operatornamevar-left-sum-ija-ijv-iv-j-right-0-for-any-v-i-t</link>
      <description><![CDATA[设 $A_{ij}$ 为一个随机矩阵，满足 $A_{ii}=0$ 和 $A_{ij}=A_{ji}$。假设我们知道对于任意向量 $v_i$，$\operatorname{var}\left(\sum_{ij}A_{ij}v_{i}v_{j}\right)=0$。关于条目 $A_{ij}$ 的统计数据，我们能说些什么呢？
这个问题的标题仅作为一个例子：是否得出 $\operatorname{var}(A_{ij})=0$ ？如果这不是真的，我仍然对从这个假设中可以得出对$A_{ij}$分布的何种约束感兴趣。
我们知道
$$\operatorname*{var}\left( \sum_{ij}v_{i}v_{j}A_{ij} \right) = \sum_{ij}\sum_{i&#39;j&#39;} v_{i}v_{j} v_{i&#39;}v_{j&#39;} \operatorname*{cov}(A_{ij},A_{i&#39;j&#39;}) = 0$$
对于任何$v_i$。这必须对条目$A_{ij}$的分布施加一些约束。但是我不确定这个等式是否足以得出这样的结论：$\operatorname*{cov}(A_{ij},A_{i&#39;j&#39;}) = 0$。]]></description>
      <guid>https://stats.stackexchange.com/questions/658101/if-operatornamevar-left-sum-ija-ijv-iv-j-right-0-for-any-v-i-t</guid>
      <pubDate>Sun, 01 Dec 2024 21:21:17 GMT</pubDate>
    </item>
    <item>
      <title>凸且最优投资组合的存在性</title>
      <link>https://stats.stackexchange.com/questions/658099/convex-and-existence-of-optimal-portfolio</link>
      <description><![CDATA[考虑一个基本的静态投资组合选择问题。投资者选择一个投资组合，即将其固定财富的正部分分配到几项金融资产中。金融资产是取值在 (a,b) 范围内的随机变量。
那么，在三种资产的情况下，投资组合 的一个例子是 (1/2,1/4,1/4)。
现在假设我定义凸性如下。如果投资者更喜欢资产 1 而不是资产 2，那么投资者更喜欢资产 1 和资产 2 的投资组合，而不是资产 2。注意：我还假设投资者总是能够分辨出她在两种资产之间的偏好。假设资产 1 优于资产 2，资产 2 优于资产 3。那么资产 2 和 3 的投资组合也优于资产 3。
我的问题是，这种凸性假设是否意味着存在唯一或区间最优的投资组合。最优投资组合只是意味着存在一个优于任何其他投资组合的投资组合。我的直觉告诉我是这样，但我找不到任何参考资料。如果有人能详细解释这一点并提供一些参考资料，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658099/convex-and-existence-of-optimal-portfolio</guid>
      <pubDate>Sun, 01 Dec 2024 20:18:21 GMT</pubDate>
    </item>
    <item>
      <title>具有交互作用的线性模型中斜率的置信区间</title>
      <link>https://stats.stackexchange.com/questions/658097/confidence-interval-for-a-slope-in-a-linear-model-with-an-interaction</link>
      <description><![CDATA[lm(y ~ x + gender + x*gender)

假设实验单位为 15 名男性和 17 名女性。看来 R 响应上述命令所做的就是拟合截距、要添加到截距中的两个性别之一的量、与 $x$ 相乘的斜率以及要添加到斜率中的两个性别之一的数字。
现在假设误差是同方差的。并且$$\widehat\sigma^{\,2} = \frac{\text{残差平方和}}{\text{error d.f.}}= \frac{\text{s.s.r.}}{15+17-4}.$$
我们想要一个适用于男性的斜率$\beta$的置信区间。我们知道
$$
\widehat\beta \sim\operatorname N\left( \beta, \frac{\sigma^2}{\sum_{i\,\in\,M} (x_i-\overline x)^2} \right)
$$
其中 $M$ 是对应于男性单位的一组指标，而 $\overline x$ 是仅针对男性的观察平均值。
因此
$$
\frac{\widehat\beta-\beta}{\sigma\left/ \sqrt{\sum_{i\,\in\,M} (x_i-\overline x)^2} \right.} \sim\operatorname N(0,1)。
$$
因此
$$
\frac{\widehat\beta-\beta}{\widehat\sigma\left/ \sqrt{\sum_{i\,\in\,M} (x_i-\overline x)^2} \right.} \sim t_{28}。
$$
因此，置信区间的端点应该是
$$
\widehat\beta\pm A\cdot \frac{\widehat\sigma}{\sqrt{\sum_{i\,\in\,M} (x_i-\overline x)^2}}
$$
其中 $A$ 是 $t_{28}$ 分布的适当分位数。
我的问题是 是否有理由使用仅基于男性单位的标准差估计值，而不是 $\widehat\sigma,$，从而涉及 $t_{13}$ 分布？这两种方法各有利弊吗？假设男性和女性的误差方差不同，上述方法就必须被视为错误。
我可以尝试明智地解决这个问题，而不是在这里询问，也许我会这样做，但在这里询问也可能会发现一些有趣的事情。]]></description>
      <guid>https://stats.stackexchange.com/questions/658097/confidence-interval-for-a-slope-in-a-linear-model-with-an-interaction</guid>
      <pubDate>Sun, 01 Dec 2024 19:09:17 GMT</pubDate>
    </item>
    <item>
      <title>根据相关性手动计算路径系数</title>
      <link>https://stats.stackexchange.com/questions/658096/calculating-path-coefficients-manually-from-correlations</link>
      <description><![CDATA[据我了解，在路径模型中，我们可以使用 Wright 的方法根据变量之间的相关性手动计算（标准化）路径系数。在饱和情况下，我们完美地重现相关性，而在非饱和情况下，我们得到模型隐含相关性与真实相关性之间的潜在差异（如果设置为零的路径实际上不为零）。这是计算“模型拟合度”的基础。
当我在 R 中使用 lavaan 运行路径模型时，程序会经过几次“迭代”以拟合最佳模型。但是，如果我们可以根据相关性手动计算系数，为什么我们需要经过多次迭代的优化程序？如果有人能解释，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658096/calculating-path-coefficients-manually-from-correlations</guid>
      <pubDate>Sun, 01 Dec 2024 18:49:21 GMT</pubDate>
    </item>
    <item>
      <title>在我的案例中选择正确的统计测试</title>
      <link>https://stats.stackexchange.com/questions/658069/choose-the-right-statistical-test-in-my-case</link>
      <description><![CDATA[我有一个调查数据集，其中每个参与者回答了 20 个独特的问题。我想对数据进行统计分析，但不确定要使用哪种测试：方差分析、重复测量方差分析还是混合效应模型？
我想用于统计测试的数据是问题类型和响应时间。
https://docs.google.com/spreadsheets/d/16cwLFGaF4KqLvwYNjHIcCyHaWup8vSJpL7gOEqk_XPA/edit?usp=sharing
我想测试的假设是问题类型对响应时间有影响吗？
问题时间有 4 种模式，响应时间是以秒为单位的数值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658069/choose-the-right-statistical-test-in-my-case</guid>
      <pubDate>Sat, 30 Nov 2024 14:09:41 GMT</pubDate>
    </item>
    <item>
      <title>不同打印方法导致的方差解释差异</title>
      <link>https://stats.stackexchange.com/questions/658082/discrepancies-in-explained-variance-depending-on-the-print-method</link>
      <description><![CDATA[在执行探索性因子分析时，我想查看因子的解释方差。这很简单，我打印了fa()方法的输出。可以得到与$loadings输出相同的汇总表，如下所示。问题是两个表中的解释方差有偏差。这是什么原因，是 psych 包中的错误吗？哪个输出是正确的？
library(psych)

fa_results &lt;- fa(df_sq1sq9, nfactors = 5, rotate = &quot;oblimin&quot;)
print(fa_results)
fa_results$loadings

请注意，我不是在谈论因子载荷，而是在下表中谈论 Cumulative var 行。差异出现在正交和斜向旋转的情况下，并且在斜向旋转的情况下，两个输出的偏差更大。因此，该示例以斜交旋转显示。
斜交旋转：
&gt;print(fa_results)

[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.45 1.50 1.07 1.05 0.60
比例方差 0.27 0.17 0.12 0.12 0.07
累积方差 0.27 0.44 0.56 0.68 0.74
解释比例 0.37 0.22 0.16 0.16 0.09
累积比例 0.37 0.59 0.75 0.91 1.00

因子相关性为 
MR1 MR3 MR5 MR2 MR4
MR1 1.00 0.59 0.64 -0.01 0.30
MR3 0.59 1.00 0.33 0.12 0.21
MR5 0.64 0.33 1.00 0.28 0.11
MR2 -0.01 0.12 0.28 1.00 -0.17
MR4 0.30 0.21 0.11 -0.17 1.00

斜轴旋转：
&gt;fa_results$loadings
[...]
MR1 MR3 MR5 MR2 MR4
SS 载荷 2.310 1.350 0.975 1.038 0.563
比例方差 0.257 0.150 0.108 0.115 0.063
累计Var 0.257 0.407 0.515 0.630 0.693

我也在 https://stats.stackexchange.com/questions/657692/exploratory-factor-analysis-oblique-rotation-variance-explained 中提出了这个问题作为更新]]></description>
      <guid>https://stats.stackexchange.com/questions/658082/discrepancies-in-explained-variance-depending-on-the-print-method</guid>
      <pubDate>Sat, 30 Nov 2024 11:55:31 GMT</pubDate>
    </item>
    <item>
      <title>倾向得分匹配：如何决定优先考虑平衡还是样本量</title>
      <link>https://stats.stackexchange.com/questions/657980/propensity-score-matching-how-to-decide-if-prioritise-balance-or-sample-size</link>
      <description><![CDATA[我尝试使用 MatchThem 包以不同的方法（最近或无放回法、最优法、完全法、遗传法）在两组之间执行 PSM。最终，我确定了两个表现良好的模型：一个模型中所有变量都是平衡的，但排除了一些情况；另一个（完整模型）中一个变量略微不平衡，但所有情况都保留。
NEAREST LOGIT
# 在每个插补数据集中执行匹配
m.out_model1 &lt;- matchthem(formula, 
data = new_df_imputed, 
method = &quot;nearest&quot;, 
distance = &quot;logit&quot;,
replace = TRUE,
ratio = 3,
caliper = 0.2)

输出：
所有插补的平衡摘要
Type Max.Diff.Adj M.Threshold
distance Distance 0.0130 Balanced, &lt;0.1
Metastasis_size_at_treatment_mm Contin. 0.0136 平衡，&lt;0.1
Segments_treated_per_session 持续。 0.0336 平衡，&lt;0.1
Metastasis_location_superficial_Yes 二进制 0.0089 平衡，&lt;0.1

平衡平均差异计数
count
平衡，&lt;0.1 4
不平衡，&gt;0.1 0

具有最大平均差异的变量
Variable Max.Diff.Adj M.Threshold
Segments_treated_per_session 0.0336 平衡，&lt;0.1

插补的平均样本大小
0 1
全部 53. 77
匹配（ESS） 26.96 75
匹配（未加权） 45. 75
不匹配 8. 2

完整方法
m.out_full &lt;- matchthem(formula,
data = new_df_imputed,
method = &quot;full&quot;,
distance = &quot;mahalanobis&quot;)

输出：
所有插补的平衡摘要
类型 Max.Diff.Adj M.Threshold
Metastasis_size_at_treatment_mm Contin. 0.0477 平衡，&lt;0.1
Segments_treated_per_session Contin. 0.1179 不平衡，&gt;0.1
Metastasis_location_superficial_Yes 二进制 0.0260 平衡，&lt;0.1

平衡平均差异计数
count
平衡，&lt;0.1 2
不平衡，&gt;0.1 1

具有最大平均差异的变量
Variable Max.Diff.Adj M.Threshold
Segments_treated_per_session 0.1179 不平衡，&gt;0.1

插补的平均样本大小
0 1
全部 53. 77
匹配（ESS） 27.47 77
匹配（未加权） 53. 77

如果我使用第一个模型，我会失去能力（而且我的队列已经很小）。另一方面，选择第二个模型允许我保留整个人群，但这两个群体略微不平衡。但是，我可以通过多变量逻辑回归中包含不平衡变量来解释这一点。
我的问题是：有没有办法确定哪个模型是最佳选择？计算与每个匹配数据集相关的功效以评估使用哪个模型在方法论上是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/657980/propensity-score-matching-how-to-decide-if-prioritise-balance-or-sample-size</guid>
      <pubDate>Thu, 28 Nov 2024 13:21:04 GMT</pubDate>
    </item>
    <item>
      <title>无法从分布不同的多台设备的数据中提取模式</title>
      <link>https://stats.stackexchange.com/questions/657979/unable-to-extract-pattern-from-data-from-multiple-devices-with-different-distrib</link>
      <description><![CDATA[我获得了一组以时间序列形式呈现的 3 种不同物联网 (IoT) 设备的电流强度（唯一特征）测量数据集。

每台设备都进行了多次测量，持续时间不同。

每次测量的测量结果均为 csv 格式。

采样频率为 100ms。每个设备的数值范围不同。
我想搜索 IoT 设备运行期间出现的任何模式。显然，具有不同功能的不同设备具有完全不同的行为和分布。
我已经制作了所有测量值的直方图，尽管某些测量值的分布有相似之处，但每个直方图都没有任何共同的特定特征（如有必要，我可以提供图像）。
此外，我已经计算了测量值的相关矩阵，数据之间几乎没有相关性（几乎每种情况下，每个测量值与其他测量值的相关性几乎为 0）。
不用说，在大多数情况下，测量时间序列的图没有任何共同的模式（至少在视觉上）。对于上述所有方法，我都使用了移动平均线来平滑曲线并保持趋势，并使用标准缩放对数据进行规范化。
没有提供有关设备的元数据（例如，设备是 5V 还是 3.3V，其用途是什么等）。我与测量设置和数据收集过程无关。此外，我还没有执行过 ARIMA 或任何其他类似方法。
我的最终目的是构建一个用于异常检测的机器学习系统。
我正在考虑建立一个将用于迁移学习的模型。
我最近还了解了领域泛化和元学习的存在。
您对此类问题有什么建议或经验可以与我分享吗？您能为我的情况提供一些指导吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657979/unable-to-extract-pattern-from-data-from-multiple-devices-with-different-distrib</guid>
      <pubDate>Thu, 28 Nov 2024 13:18:38 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在处理一个重复测量数据集，其中个人/单位/实体代表医疗机构。研究的目的是观察机构特征 (X) 对由于某种医疗状况 (Y) 导致的几家医疗机构的死亡人数的影响。Y 表示在跨越多年的时间段内每周测量的死亡人数。X 表示在整个研究过程中在多个时间点（每周、每季度、研究开始/结束）测量的连续/分类变量。变量 Y 是零膨胀的，并且由于在模型中包含太多预测因子而导致数值问题。
我的一组 X 变量 (u1、u2、...、un) 与一组其他变量 (v1、v2、...、vn) 相关。这使我无法在同一模型中同时建模 U（总共约 50 个）和 V（总共约 5 个）变量。因此，我对 U 变量进行了建模，并选择了对 Y 有显著影响的 U 变量子集。利用这个子集，我执行了 PCA，并在最终模型中将 PCA 分数与 V 变量一起使用。我相信这样做可以让它们（U 变量和 V 变量的 PCA 分数）彼此不相关，同时在估计 V 变量时会纳入 U 变量的净效应。
我的最终目标是获得与时间无关的 V 变量预测。
在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法涉及以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 之间的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除非数字变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不均等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    </channel>
</rss>