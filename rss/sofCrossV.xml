<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 14 Jan 2024 12:23:52 GMT</lastBuildDate>
    <item>
      <title>使用多项研究时在荟萃分析中测试发表偏倚和异质性</title>
      <link>https://stats.stackexchange.com/questions/636822/testing-publication-bias-and-heterogeneity-in-meta-analysis-when-using-multiple</link>
      <description><![CDATA[我正在进行一项荟萃分析，并试图确定如何测试发表偏倚和异质性。
但是，我使用了多个数据集来计算效果大小，因此我不确定如何解决这个问题。
例如，在比较动物园和野生动物分类目偶蹄类动物的运动行为时，我取了 11 项野外研究和 7 项动物园研究中运动行为的平均值，以计算效应大小（Hedges&#39; g）。
据我了解，发表偏倚要求我计算每项单独研究的效应大小，但当每项单独的研究都着眼于野外或动物园而不是两者的行为时，这是不可能的。
据我所知，使用 Cochran 的 Q 检验异质性需要比较相同大小的样本，这对于该数据来说当然是不可能的，因为行为表现来自不同的研究。
因此，我什至不确定是否可以测试发表偏倚或异质性。任何有关此问题的帮助将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/636822/testing-publication-bias-and-heterogeneity-in-meta-analysis-when-using-multiple</guid>
      <pubDate>Sun, 14 Jan 2024 10:51:40 GMT</pubDate>
    </item>
    <item>
      <title>具有观察到的数据子集的逆 Wishart 分布的后验</title>
      <link>https://stats.stackexchange.com/questions/636819/posterior-of-inverse-wishart-distribution-with-a-subset-of-data-observed</link>
      <description><![CDATA[假设：
\begin{方程}
x_1\in \mathbb{R}^{p_1}\\
x_2\in \mathbb{R}^{p_2}
\end{方程}
这样
\begin{方程}
x \sim \mathcal{N}(
\开始{b矩阵}
x_1\\
x_2
\end{b矩阵};
\开始{b矩阵}
\mu_1\\
\mu_2
\结束{b矩阵}，
\开始{b矩阵}
\Sigma_{11}\Sigma_{12}\\
\西格玛_{21}\西格玛_{22}
\end{b矩阵})
\end{方程}
其中 $(\mu, \Sigma)$ 具有逆 Wishart-共轭先验：
\begin{方程}
p(\mu, \Sigma) = \mathcal{N}(
\开始{b矩阵}
\mu_1\\
\mu_2
\end{b矩阵};
\开始{b矩阵}
M_1\\
M_2
\结束{b矩阵}，
\kappa
\开始{b矩阵}
\Sigma_{11}\Sigma_{12}\\
\西格玛_{21}\西格玛_{22}
\end{b矩阵})
\mathcal{IW}(
\开始{b矩阵}
\Sigma_{11}\Sigma_{12}\\
\西格玛_{21}\西格玛_{22}
\end{b矩阵};
\开始{b矩阵}
\Psi_{11}\Psi_{12}\\
\Psi_{21}\Psi_{22}
\end{b矩阵}, v)
\end{方程}
$\mu$ 的边际和 $x$ 的后验预测可以在这里找到： https://www.cs.ubc.ca/~murphyk/Papers/ bayesGauss.pdf 方程（256 和 258）
条件分布 $p(x_1 | x_2)$ 也可以使用 $T$ 的条件来求解-分布。
https://en.wikipedia.org/wiki/Multivariate_t-distribution
最后，$p(\mu_1 | x_1$) 的后验也可以使用正态和逆威沙特的边缘以及遵循 Murphy 的文本找到 (等式256）。
但是，我正在努力寻找：
\begin{方程}
p(\mu_2 | x_1)
\end{方程}]]></description>
      <guid>https://stats.stackexchange.com/questions/636819/posterior-of-inverse-wishart-distribution-with-a-subset-of-data-observed</guid>
      <pubDate>Sun, 14 Jan 2024 07:32:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么指数族的似然函数是凸的？</title>
      <link>https://stats.stackexchange.com/questions/636815/why-are-likelihood-functions-from-exponential-family-convex</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636815/why-are-likelihood-functions-from-exponential-family-convex</guid>
      <pubDate>Sun, 14 Jan 2024 05:10:40 GMT</pubDate>
    </item>
    <item>
      <title>对均值未知的两个分布进行 A/B 测试</title>
      <link>https://stats.stackexchange.com/questions/636814/a-b-test-from-two-distributions-with-unknown-means</link>
      <description><![CDATA[我将运行一个实验来检查给定的更改是否在用户交互中具有一定的意义。我有两组，从两组中采样，一组称为 control，用于计算对照组中 30 个采样用户的交互次数，而我有 treatment，用于计算对照组中 30 个采样用户的交互次数。 30 个样本用户与测试功能的交互。它们在下面的 Python 代码中给出
将 numpy 导入为 np

控制 = np.array([1, 0, 1, 3, 2, 1, 0, 1, 3, 2, 1, 0, 1, 3, 2, 1, 0, 1, 3, 2, 1, 0 , 1, 3, 2, 1, 0, 1, 3, 2])
治疗 = np.array([0, 1, 3, 2, 1, 2, 1, 3, 2, 1, 0, 2, 3, 2, 1, 0, 2, 3, 2, 1, 0, 2 , 3, 2, 1, 0, 2, 3, 2, 4])

对于此测试，我将使用以下参数
实际重要边界：$d_{min} = 0.05$
显着性水平$\alpha = 0.05$
d_min = 0.05
阿尔法 = 0.05

我想检查平均两组之间的使用情况是否存在差异。然后我将原假设陈述为
$H_0: \mu_t == \mu_c \implies d = 0$
其中 $\mu$ 是对照组 (c) 或治疗组 (t) 和 $d 的平均值$ 差异 $d = \mu_t - \mu_c$。
mu_c = control.mean()
mu_t = 治疗.mean()
d = mu_t - mu_c

根据数据的特点，我将使用t检验进行评估。我假设两组之间的方差相同，这将为我提供以下计算来测试统计数据。
n_c = len(control) # 控制中的样本数
n_t = len(treatment) # 处理中的样本数

df = n_c - 1 + n_t - 1 # 自由度

# 对照组误差的平方和
SS_c = np.sum((控制 - mu_c)**2)

# 治疗组的误差平方和
SS_t = np.sum((治疗 - mu_t)**2)

# 合并标准误
S_pool = np.sqrt((SS_c + SS_t)/df)

# 测试 t 分布的统计量
TS = d / (S_pool * np.sqrt(1/n_c + 1/n_t))

现在我将验证测试是否证实或拒绝原假设。为此，我计算了具有 58 个自由度的 t_alpha，
导入 scipy.stats 作为统计数据

t_alpha = stats.t.ppf(1-alpha/2, df)

TS&gt; t_alpha或TS＜ -t_alpha
# 返回真

由于 TS 超出了 t_alpha 的边界，我们可以拒绝原假设。
现在我将验证结果是否实际上显着，即包括标准误差的置信区间是否与显着性区域相交。为此，我需要估计保证金误差 ($m$)，然后根据&lt;计算置信区间 span class=&quot;math-container&quot;&gt;$d \pm m$
m = t_alpha * S_pool
ci = np.array([d - m, d + m])

提醒一下，d 是两组（对照组和治疗组）平均值之间的差异。
为了可视化，我们可以构建给定的绘图。
导入 matplotlib.pyplot 作为 plt
图 = plt.figure(figsize=(10, 3))
斧头 = 图.add_subplot(111)
ax.vlines(0, -1, 1)
ax.vlines([-d_min, d_min], -1, 1, linestyles=&#39;虚线&#39;, label=“重要边界”);
ax.plot(d, 0,&#39;b.&#39;, label=“中心置信区间”);
ax.hlines(0, *ci, &#39;b&#39;, label=&quot;置信区间&quot;);
ax.set_title(“意义”);
plt.图例();


由于置信区间与显着边界（完全）重叠，甚至跨越$0$，我不能假设这个测试具有实际意义，因此我会&lt;强&gt;拒绝它。
问题是：我没想到间隔这么大。也许我只是使用了错误的边距误差公式，但它似乎是正确的。欢迎任何有助于推进此事的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/636814/a-b-test-from-two-distributions-with-unknown-means</guid>
      <pubDate>Sun, 14 Jan 2024 04:32:55 GMT</pubDate>
    </item>
    <item>
      <title>“似然性”是否适用于“非似然解”？</title>
      <link>https://stats.stackexchange.com/questions/636811/do-likelihood-properties-apply-to-non-likelihood-solutions</link>
      <description><![CDATA[如果$X$是PDF中的随机变量$f(x;\Theta)$ ，那么我们将似然函数定义为：
$$L(\Theta; x) = f(x;\Theta)$$
据我了解，我们说 $\Theta^*$ 是真正的 MLE 估计器，如果 $\Theta^ *$满足以下条件
$$\Theta^* = \arg\max_{\Theta} L(\Theta; x)$$
因此，MLE 估计器具有以下所需属性：

渐近正态性（对于创建置信区间很有用）
最小方差（Cramer-Rao 界，即 ML 估计器在任何类似估计器中具有尽可能低的方差）
一致性（样本量较大的 ML 估计器更接近真实值的概率更高）
变换下的不变性

从实际角度来看，我们尝试通过数值确定$\Theta^*$。尽管在许多流行的情况下，确定 $\Theta^*$ 的问题是凸优化问题（即我听说概率分布中的所有似然函数都属于指数家庭是凸的），我确信还有其他此类问题，但问题不一定是凸的（我猜测是在层次回归模型或混合模型中）。
我的意思是，有时近似数值解 $\Theta^{**}$ 不可避免地不等于真正的机器学习解$\Theta^*$。在这种情况下，我有兴趣知道：

期望 $\Theta^{**}$ 渐近正态、最小方差、一致且不变是否仍然合理？
假设两个不同的人尝试以两种不同的方式优化似然函数（例如两种不同的数值算法、两种不同的似然函数参数化等）并得出估计值 $\Theta^{***}$ 和 $\Theta^{****}$，而真正的机器学习解决方案是 $\Theta^*$。可以说 $|\Theta^{***} - \Theta^*| &lt; |\Theta^{****} - \Theta^*|$。换句话说，与 $\Theta 相比，$\Theta^{***}$ 更接近真正的机器学习解决方案^{***}$。如果 $\frac{\Theta^{***}}{\Theta^{****}} = a$，我们可以说 $\Theta^{***}$ 更渐近正态（即需要更小的 $n$ 才正常） ，比 $\Theta^ 更一致（即需要更小的 $n$ 来更接近真实值）和更小的方差{****}$ 乘以 $a$？
]]></description>
      <guid>https://stats.stackexchange.com/questions/636811/do-likelihood-properties-apply-to-non-likelihood-solutions</guid>
      <pubDate>Sun, 14 Jan 2024 02:48:35 GMT</pubDate>
    </item>
    <item>
      <title>如何定义不可数样本空间的概率函数的定义域和余域？</title>
      <link>https://stats.stackexchange.com/questions/636809/how-to-define-the-domain-and-codomain-for-the-probability-function-of-an-uncount</link>
      <description><![CDATA[离散样本空间的概率函数的域和余域可以定义为...
定义域：样本空间的幂集
共域：$y \in [0, 1]$
如何为不可数样本空间定义域和辅域？我应该在哪里寻找更多信息？]]></description>
      <guid>https://stats.stackexchange.com/questions/636809/how-to-define-the-domain-and-codomain-for-the-probability-function-of-an-uncount</guid>
      <pubDate>Sun, 14 Jan 2024 02:17:33 GMT</pubDate>
    </item>
    <item>
      <title>线性回归中残差的期望</title>
      <link>https://stats.stackexchange.com/questions/636807/expectation-of-residuals-in-linear-regression</link>
      <description><![CDATA[考虑线性回归模型
$$ Y=X\beta + \epsilon, $$
其中 $Y\in R^n$，$X = (x_1,...,x_n)^T\in R^{n\times p}$ 是 i.i.d. $p$ 维观测值、$\beta\in R^p$ 和 $\epsilon = (\epsilon_1,...,\epsilon_n)\in R^n$ 是独立同分布的。令 $\hat\beta$ 为 $\beta$ 的估计量。那么残差为 $\hat\epsilon = (\hat\epsilon_1,...,\hat\epsilon_n)= Y - X\hat\beta = X(\beta-\ hat\beta) + \epsilon$。我们认为 $X$ 和 $\epsilon$ 都是随机的。这是正确的吗
$$ E(\hat\epsilon_1) = \cdots = E(\hat\epsilon_n) = E\left(\frac{1}{n}\sum_{i=1} ^n \hat\epsilon_i \right)? $$]]></description>
      <guid>https://stats.stackexchange.com/questions/636807/expectation-of-residuals-in-linear-regression</guid>
      <pubDate>Sun, 14 Jan 2024 01:47:44 GMT</pubDate>
    </item>
    <item>
      <title>spss中李克特量表的检验</title>
      <link>https://stats.stackexchange.com/questions/636806/tests-for-likert-scale-in-spss</link>
      <description><![CDATA[这是我第一次使用李克特量表，我需要帮助在 SPSS 中选择合适的测试。
我有一个李克特陈述，想看看是否存在基于年龄（18-25）和25-30）和性别（女性、男性、其他，而不是说）的差异（如果有，它们之间有什么差异）。对此最好的测试是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/636806/tests-for-likert-scale-in-spss</guid>
      <pubDate>Sun, 14 Jan 2024 01:42:55 GMT</pubDate>
    </item>
    <item>
      <title>测试确实检查复杂变量的循环性</title>
      <link>https://stats.stackexchange.com/questions/636805/a-test-do-check-the-circularity-of-a-complex-variable</link>
      <description><![CDATA[我需要一种方法来测量复杂随机变量的循环性。当复数随机变量的 PDF 仅取决于其大小而不取决于其角度时，该变量是圆形的。
例如，$z$是一个复杂的随机变量$z=x+iy$，其中$i=\sqrt{-1}$ 和 $x$ 和 $y$ 是真正的随机变量 $z$ 的 PDF ($f(z) $) 只能写在 $|z|$ 的函数中，如果 $z$是圆形的。
一些论文使用由变量的方差（$\phi_z$）归一化的伪方差来判断变量是否是循环的：
$$\phi_z=\frac{E[z^2]}{E[zz^*]}$$
因为 $\phi_z=0$ 如果 $z$ 是循环的，但是复数变量可以具有 $\phi_z=0$ 并且如果其实部和虚部正交，则不是循环。如下非循环变量样本实部和虚部散点图所示，其中 $\phi_z=0$：

很明显，概率密度不仅仅随着样本大小的变化而变化。
由于 PDF 不依赖于角度，因此在圆形变量中，样本必须均匀分布在所有角度间隔上（即 $-\pi$到 $\pi$）。下图显示了圆形随机变量的示例以及使用直方图估计的样本角度的 PDF：


因此，我想到了执行假设检验来检查变量的循环性的想法，其中：
$H_0$：可变角度的PDF是统一的
$H_1$：可变角度的PDF不均匀
因此$H_0$对应于循环的变量
这个测试有效吗？有论文提出该测试吗？有没有更好的方法来检查复杂随机变量的循环性？]]></description>
      <guid>https://stats.stackexchange.com/questions/636805/a-test-do-check-the-circularity-of-a-complex-variable</guid>
      <pubDate>Sun, 14 Jan 2024 01:38:01 GMT</pubDate>
    </item>
    <item>
      <title>证明后验不依赖于数据分解</title>
      <link>https://stats.stackexchange.com/questions/636802/proof-that-posterior-does-not-depend-on-data-breakdown</link>
      <description><![CDATA[假设根据先验计算某个参数 $P(\theta\mid x)$ 的后验分布。现在假设我们将该数据分为两部分，例如 $x = x_1 \cup x_2$。直观地说，在给定相同先验的情况下，分解数据必然会导致相同的后验，即 $$P(\theta\mid x) = P(\theta\mid x_1, x_2)$ $
但是，从贝叶斯定律来看，这并不明显是正确的。
有哪些方法可以正式证明这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/636802/proof-that-posterior-does-not-depend-on-data-breakdown</guid>
      <pubDate>Sun, 14 Jan 2024 00:02:05 GMT</pubDate>
    </item>
    <item>
      <title>Welch t 检验是否应该使用无偏标准差估计来计算自由度？</title>
      <link>https://stats.stackexchange.com/questions/636793/should-welch-t-test-use-unbiased-standard-deviation-estimates-to-compute-degrees</link>
      <description><![CDATA[此答案建议我们应该（如果可能）更正 Satterthwaite 方程 计算自由度 $\nu$ t 检验。 评论不同意。 p&gt;
当然，只有当我们使用非常小的样本量时，这才有意义，并且只有当我们能够找到标准偏差估计的修正项时才实用。
如果我们假设随机变量呈正态分布，那么我们可以通过应用 修正系数 $c_G(n) = \sqrt{\frac{N-1}{2}}\,\,\frac{\Gamma\left (\frac{N-1}{2}\right)}{\Gamma\left(\frac{N}{2}\right)}$。
如果变量是正态的，那么合并该校正因子是否会改善我们的计算？
&lt;小时/&gt;
我试图通过对独立正态变量 X、Y 的均值差异进行一系列模拟实验来回答这个问题；使用 $\nu$ 计算有或没有校正因子的差异的置信区间 (CI)；并计算 CI 内真实差异的频率。 （Python 代码如下。）但是，即使使用小至 4 的样本大小 n 进行 100,000 次迭代，我也找不到任何导致 CI​​ 覆盖率超出所需置信度 1% 的模拟参数，两个公式的 CI 覆盖率差异绝不会超过 0.3%。因此，如果存在差异，我还没有通过这种方法成功找到它。
# 模拟检查估计平均值差异的置信区间
导入数学
将 numpy 导入为 np
从 scipy.stats 导入 t
nsim = 100_000 # 要运行的模拟次数
# 用于模拟的随机变量参数：
nX, nY = (8, 4)
X 平均值、Y 平均值 = (1, 2)
sigmaX, sigmaY = (1, .3)

gamma = 0.9 # 置信区间覆盖范围

定义 cG(n):
    返回 math.exp(math.lgamma((n-1)/2) - math.lgamma(n/2) - math.log(math.sqrt(2/(n-1))))
cGx = cG(nX)
cGy = cG(nY)

count_contains_true = 0 # 基础 CI 包含真实差异 (meanX-meanY) 的模拟次数
count_ Corrected_contains_true = 0 # 相同，但使用无偏标准差计算 CI
对于我在范围内（nsim）：
    x = np.random.normal(大小=nX, loc=meanX, 尺度=sigmaX)
    y = np.random.normal(大小=nY, loc=meanY, 尺度=sigmaY)
    muX = np.mean(x)
    muY = np.mean(y)
    varX = np.var(x, ddof=1)
    varY = np.var(y, ddof=1)
    eX = varX / nX
    eY = varY / nY
    nu = (eX + eY)**2 / (eX**2 / (nX-1) + eY**2 / (nY-1))
    CI = t.interval(gamma, df=nu, loc=(muX - muY), scale=np.sqrt(eX+eY))
    如果 CI[0] &lt;平均X-平均Y＜ CI[1]:
        count_contains_true += 1

    # 使用校正因子计算 nu
    eXc = cGx**2 * eX
    eYc = cGy**2 * eY
    nu = (eXc + eYc)**2 / (eXc**2 / (nX-1) + eYc**2 / (nY-1))
    CI = t.interval(gamma, df=nu, loc=(muX - muY), scale=np.sqrt(eX+eY))
    如果 CI[0] &lt;平均X-平均Y＜ CI[1]:
        count_ Corrected_contains_true += 1

print(f&#39;在 {nsim:,} 模拟 {gamma:.0%} 置信区间包含真实参数:\n&#39;
      基础 CI 的 f&#39;\t\t{count_contains_true / nsim:.1%}\n&#39;
      f&#39;\t\t{count_ Corrected_contains_true / nsim:.1%} 的无偏 CI 时间&#39;
）
]]></description>
      <guid>https://stats.stackexchange.com/questions/636793/should-welch-t-test-use-unbiased-standard-deviation-estimates-to-compute-degrees</guid>
      <pubDate>Sat, 13 Jan 2024 21:21:09 GMT</pubDate>
    </item>
    <item>
      <title>LOOCV：要报告哪些性能指标聚合？</title>
      <link>https://stats.stackexchange.com/questions/636784/loocv-which-aggregation-of-the-performance-metric-to-report</link>
      <description><![CDATA[目标变量是收入，有 81 个观测值和 10 个特征。
目标分布是这样的：标准对数变换不会产生近似正态分布，但收入**(1/4) 会产生近似正态分布。预期模型根据转换后的目标进行训练，但根据反向转换的预测值进行评估。
我选择 RMSLE 作为我的性能指标，因为它是一种相对度量，对低估的惩罚高于对高估的惩罚。
LOOCV 用于超参数调整、模型选择和最终模型验证。
但是要开始做出决策，我需要选择一种聚合方法。下面显示的是 RMSLE 分数分布的示例：

我的理解是，平均值通常是针对 LOOCV 报告的。但是，考虑到这种分布，使用/报告中位数或几何平均值更合适吗？
编辑：
一位评论者指出，嵌套简历在这里更合适。我相信我正在这样做（很抱歉没有更具描述性），但我可能是错的：
从 sklearn.linear_model 导入 Ridge

alpha_range = np.logspace(-2,2,20,base=10,endpoint=True)
rmsle_df_ridge = pd.DataFrame(columns=list(map(str, alpha_range)))

对于 i，枚举（kf.split（X））中的（train_index，test_index）：
    X_train = X.iloc[train_index]
    X_test = X.iloc[test_index]
    y_train = y.iloc[train_index]
    y_test = y.iloc[test_index]
    对于 alpha_range 中的 alpha：
        山脊 = 山脊(alpha=alpha)
        col_tf = make_column_transformer((StandardScaler()，scaler_cols)，余数=&#39;passthrough&#39;)
        pip_dt = make_pipeline(col_tf, ridge)
        pip_dt.fit(X_train, y_train)
        y_pred = pip_dt.predict(X_test)
        均方根误差=mean_squared_log_error(y_test**4, y_pred**4)**0.5
        rmsle_df_ridge.loc[i, str(alpha)] = rmsle

然后绘图是通过以下方式生成的：
sns.lineplot(x=np.log10(alpha_range),y=rmsle_df_ridge.mean(axis=0))
plt.title(&#39;LOOCV Ridge&#39;)
plt.ylabel(&#39;RMSLE_mean&#39;)
plt.show()
plt.clf()
print(&#39;RMSLE_mean: &#39;,np.min(rmsle_df_ridge.mean(axis=0)))


因此 RMSLE 值存储在 n x m 矩阵中，其中 n = # rev_obs = 81 且 m = len(alpha_range)，其中 RMSLE (i,j) 表示通过排除第 i 个观察值进行训练然后对 i 进行测试而获得的 RMSLE，同时使用 j 作为岭回归的超参数 alpha。然后，我使用每列的算术平均值进行聚合，以获得 mx2 矩阵 RMSLE_agg，其行对应于 (alpha, RMSLE_mean_LOOCV)。
如有不正确之处，请指教。
无论如何，鉴于 RMSLE 分数的分布如上所示，我仍然不知道用算术平均值（而不是中位数或几何平均值）进行聚合是否最合适。]]></description>
      <guid>https://stats.stackexchange.com/questions/636784/loocv-which-aggregation-of-the-performance-metric-to-report</guid>
      <pubDate>Sat, 13 Jan 2024 18:14:26 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 R 中的 SEM 输出（1x IV；2x 中介器；2x DV）</title>
      <link>https://stats.stackexchange.com/questions/636773/how-to-interpret-my-sem-output-in-r-1x-iv-2x-mediators-2x-dv</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636773/how-to-interpret-my-sem-output-in-r-1x-iv-2x-mediators-2x-dv</guid>
      <pubDate>Sat, 13 Jan 2024 15:55:29 GMT</pubDate>
    </item>
    <item>
      <title>显着的曼·惠特尼 (Mann Whitney) 和显着的 t 检验，但方向相反</title>
      <link>https://stats.stackexchange.com/questions/636755/significant-mann-whitney-and-significant-t-test-but-in-the-other-direction</link>
      <description><![CDATA[我想知道是否有可能有 2 个样本（A 和 B），其中 A 随机支配 B（通过 Mann Whitney 或 Kruskal Wallis），但相反，B 的均值显着高于 A（通过2 样本韦尔奇检验）。
A 和 B 不可能是对称的，而且可能也不具有相同的形状。 A 和 B 也不会是正态的，但 t 检验根据 CLT 有效（例如样本量为 30 或 40）。对于单面测试来说，这种情况可能比双面测试更有可能发生。我尝试了各种方法，但到目前为止还没有成功......
是否存在这样的反例，或者如果A对B占主导地位，那么A的均值在统计上永远不会劣于B的均值（可能不会在统计上显着优于B，但不能劣于）。
也就是说，MW 和韦尔奇都很重要，但方向相反。]]></description>
      <guid>https://stats.stackexchange.com/questions/636755/significant-mann-whitney-and-significant-t-test-but-in-the-other-direction</guid>
      <pubDate>Sat, 13 Jan 2024 02:19:46 GMT</pubDate>
    </item>
    <item>
      <title>有关 Wold 分解的确定性部分的更多信息</title>
      <link>https://stats.stackexchange.com/questions/636434/more-about-the-deterministic-part-of-wold-decomposition</link>
      <description><![CDATA[这是我的这个问题的后续。 Wold 表示定理 指出每个协方差平稳时间序列$\{Y_t\}$ 可以写成两个时间序列的总和，一个是确定性的，一个是随机性的：
$$
Y_t = \mu_t + \sum_{j=0}^\infty b_j\varepsilon_{t-j}
$$
其中 $\{\mu_t\}$ 是确定性的。根据汉森“计量经济学” (2022) p. 472、$\mu_t$是$Y_t$在无限过去的历史上的投影：$\mu_t=\lim_{m\rightarrow\infty} \mathcal{P}_{t-m}(Y_t)$。例如，它可以是
$$
\mu_t = \left\{ \matrix{ (-1)^t \ \ \ \ \text{概率为 1/2} \\ (-1)^{t+1} \ \text{概率为 1/2 } } \正确的\}。
$$
现在，如果我们只观察随机过程的单个路径，我们只会面临两种情况之一，即 $\mu_t=(-1)^{t}$或$\mu_t=(-1)^{(t+1)}$。如果没有额外的信息，我们可能会将该组件建模为确定性的，认为 $\{Y_t\}$ 不是静止的，而是 $\{Y_t-\mu_t\}$ 是。我认为这不会给建模和预测该路径中的未来元素带来任何麻烦，尽管它会扰乱关于随机过程本身的推断及其其他路径的预测。
回想我最初的问题（从一开始就有链接），我可以说，如果 Wold 分解的所有实例都这么好就好了！也许是吗？或者是否存在 $\{\mu_t\}$ 在单个路径内不完全确定的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/636434/more-about-the-deterministic-part-of-wold-decomposition</guid>
      <pubDate>Mon, 08 Jan 2024 17:48:09 GMT</pubDate>
    </item>
    </channel>
</rss>