<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 14 Oct 2024 12:33:32 GMT</lastBuildDate>
    <item>
      <title>如果模型的最大似然估计出现错误收敛，如何比较具有不同预测因子的模型？</title>
      <link>https://stats.stackexchange.com/questions/655750/how-to-compare-models-with-different-predictors-if-maximum-likelihood-estimates</link>
      <description><![CDATA[我有一个完整模型和几个部分 GLS 模型，我想使用 AIC 或 BIC 进行比较，以选择要包含在最终模型中的因素。我使用 ML 来拟合每个模型，然后再比较它们各自的 AIC 或 BIC。但是，ML 估计器在几个模型中呈现了假收敛。在这种情况下，我是否应该求助于使用 REML 来拟合模型（在我的情况下它确实适合模型）？哪种方法才是解决这个问题的正确方法？
致以最诚挚的问候并提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/655750/how-to-compare-models-with-different-predictors-if-maximum-likelihood-estimates</guid>
      <pubDate>Mon, 14 Oct 2024 11:25:07 GMT</pubDate>
    </item>
    <item>
      <title>其中一个二元类别的样本量较小</title>
      <link>https://stats.stackexchange.com/questions/655748/low-sample-size-in-one-of-the-binary-classes</link>
      <description><![CDATA[我有一个包含 86 个观测值的数据集，我想基于 10 个具有 22 个级别的分类协变量进行推断，这将产生一个包含截距的 12 列的模型矩阵。
我的问题是结果变量是二元的，其中一个类只有 9 个观测值，而另一个类有 77 个。因此，在我天真地拟合逻辑回归模型之前，我很确定该模型是不稳定的，其中一个类只有 9 个观测值，然后将它们拆分为各种协变量。因此，我考虑了诸如 Lasso 或 bootstrap 之类的技术。
Lasso 需要交叉验证才能找到惩罚参数 $\lambda$，而我的观测值太少，无法进行交叉验证。
关于 bootstrap，我只在计算样本统计数据（例如中位数或其他数据）时使用了 bootstrap 技术。我还没有用这种方法来综合创建更大的数据集。
有人能给我一些建议吗？或者有人能解决我该怎么做？
我的目标是进行推断，并确定包含最多信息的协变量，并将其解释为二元结果的预测因子。
最好]]></description>
      <guid>https://stats.stackexchange.com/questions/655748/low-sample-size-in-one-of-the-binary-classes</guid>
      <pubDate>Mon, 14 Oct 2024 11:13:02 GMT</pubDate>
    </item>
    <item>
      <title>贸易数据中缺失数据插补的最佳实践（线性插值和随机量）</title>
      <link>https://stats.stackexchange.com/questions/655747/best-practices-for-imputing-missing-data-in-trade-data-linear-interpolation-and</link>
      <description><![CDATA[我正在处理一个包含交易数据的数据集，我的目标是填补大约 24 小时的缺失数据。以下是我正在处理的交易数据示例：



timestamp
symbol
price
quantity
isBuyerMaker




1727682228788
&lt; td&gt;BNBUSDT
582.55000
1.32
真


1727682228837
NEIROUSDT
0.00103
470374.00
假


1727682228982
NEIROUSDT
0.00103
1374.00
真


1727682229035
NEIROUSDT
0.00103
4975 0.00
真


1727682229035
NEIROUSDT
0.00103
20877.00
真



不幸的是，我丢失了近 24 小时的交易记录。虽然我可以从原始来源获取缺失的交易，但目的不是使用实际值，而是估算缺失的数据。
以下是估算前的数量和价格示例图：

为了估算缺失的数据，我使用了线性插值。
估算数据的频率基于交易的平均频率，不包括任何较大的时间间隔。
数量是从现有交易量中随机选择的。
这是填充缺失数据后的图表：

我的问题：
这种方法（使用线性插值计算价格并随机选择交易量）是处理交易数据集中缺失数据的有效方法吗？您是否建议使用任何改进或替代技术，使估算更加现实并反映实际市场行为？]]></description>
      <guid>https://stats.stackexchange.com/questions/655747/best-practices-for-imputing-missing-data-in-trade-data-linear-interpolation-and</guid>
      <pubDate>Mon, 14 Oct 2024 10:28:48 GMT</pubDate>
    </item>
    <item>
      <title>R 中三级多级模型的功率分析</title>
      <link>https://stats.stackexchange.com/questions/655744/poweranalysis-for-three-level-multilevel-models-in-r</link>
      <description><![CDATA[对于社会科学环境中的一项研究 - 大量参与者不易获得 - 我正在尝试对三级多级设计进行功效分析。
很少有可用于两级多级功效分析的软件包，例如 simr 或 MLPowSim。这些软件包有一些优势，例如简单的模拟设计和详尽的教程，但是，这些软件包专注于两级多级设计。三级设计是不可能的。
我想要使用的模型具有更复杂的结构。
精简版可能看起来像这样。其中，我在第 2 级有随机截距和斜率，在第 3 级有随机截距。X 表示第 1 级预测因子，W 表示第 2 级预测因子，Z 表示第 3 级预测因子。
第 1 级（个体级）：
Y_ijk = β_0jk + β_1jk*X_ijk + r_ijk

第 2 级（群体级）：
β_0jk = γ_00k + γ_01k*W_jk + u_0jk
β_1jk = γ_10k + γ_11k*W_jk + u_1jk

第 3 级（更高群体级）：
γ_00k = δ_000 + δ_001*Z_k + v_00k
γ_01k = δ_010 + δ_011*Z_k
γ_10k = δ_100 + δ_101*Z_k
γ_11k = δ_110 + δ_111*Z_k

组合模型（带交互作用）：
Y_ijk = (δ_000 + δ_001*Z_k + v_00k) + (δ_010 + δ_011*Z_k)*W_jk + u_0jk +
((δ_100 + δ_101*Z_k) + (δ_110 + δ_111*Z_k)*W_jk + u_1jk)*X_ijk + r_ijk


我的最终模型包含更多预测因子，并且稍微复杂一些。
我该如何对这样的模型进行功效分析？
自定义模拟是否是最佳方法？有人有这种功效分析的经验吗？
Arend, Matthias G. 和 Thomas Schäfer。“两级模型中的统计功效：基于蒙特卡罗模拟的教程”。《心理学方法》24，第 1 期（2019 年 2 月）：1-19。https://doi.org/10.1037/met0000195。]]></description>
      <guid>https://stats.stackexchange.com/questions/655744/poweranalysis-for-three-level-multilevel-models-in-r</guid>
      <pubDate>Mon, 14 Oct 2024 06:56:11 GMT</pubDate>
    </item>
    <item>
      <title>概括一个实验，在给定扰动均匀采样访问的情况下，以给定范围内的概率从集合中选择一个元素</title>
      <link>https://stats.stackexchange.com/questions/655743/generalizing-an-experiment-to-pick-an-element-from-a-set-with-probability-in-a-g</link>
      <description><![CDATA[这个问题是我尝试概括我在 MSE 上发表的一个有趣观察的衍生问题。为了完整起见，我将从上下文开始，然后提出我的问题。
上下文
设 $X$ 为有限集，其中 $|X|=t$。假设我们想从 $X$ 中抽取点，方法是遍历每个点并以概率 $p$ 拾取它们，而不是以概率 $1-p$ 不拾取它们。那么，特定点 $x_0$ 被拾取的概率是多少？显然它只是 $p$。
但这很耗时，所以我们应该尝试以预期速度稍快一点的速度进行模拟。我们所做的是从 $\text{Binomial}(t,p)$ 中采样一个数字 $N$。然后我们从 $X$ 中均匀且独立地拾取元素，直到我们有 $N$ 个不同的元素（基本上是无替换采样）。现在 $x_0$ 被拾取的概率是多少？
好吧，假设我们拾取 $k$ 个点。基本概率表明$$\mathbb P(\text{$x_0$ pick}\mid N=k)=\frac{k}{t}$$，因此根据全概率定律，我们得到\begin{align*}\mathbb P(x_0\text{ pick})&amp;=\sum_{k=0}^t\mathbb P(\text{$x_0$ pick}\mid N=k)\mathbb P(N=k)\\&amp;=\sum_{k=0}^t\frac{k}{t}\binom{t}{k}p^k(1-p)^{t-k}\\&amp;=\frac1t\sum_{k=0}^tk\binom{t}{k}p^k(1-p)^{t-k}\\&amp;=\frac1tpt\\&amp;=p\end{align*&gt; 瞧！这个实验实际上模拟了我们想要做的事情！

泛化问题
上述方法有效，因为我们假设我们可以从 $X$ 中均匀采样。但假设我们不能。相反，我们可以从 $X$ 中抽样，遵循 $\mathcal D$ 上的分布，保证对于所有 $x\in X$ 和某些 $\epsilon\ge 0$，$$\mathcal D(x)\in\left(\frac{(1-\epsilon)}t,\frac{(1+\epsilon)}t\right)$$。请注意，$\epsilon=0$ 是统一情况。
问题是，我们能否按照上述精神进行一些实验，以便我们得到 $$\mathbb P(x_0\text{ picked})\in\left((1-\epsilon)p,(1+\epsilon)p\right)$$

简单的尝试
我尝试以与之前相同的方式计算它。为简单起见，让 $\mathcal D(x)=p_x$。 $x_0$ 在第一次挑选中未被选中的概率是 $$1-p_{x_0}=\sum_{i_1\ne 0}p_{x_{i_1}}$$ 而它在第二次挑选中再次未被选中的概率是 $$\sum_{i_1,i_2\ne 0}\frac{p_{x_{i_2}}}{1-p_{x_{i_2}}}$$，这是在我们选中 $x_{i_1}\ne x_0$ 之后重新调整概率而得出的。继续下去，我们最终得到 \begin{align}\mathbb P(x_0\text{ not picking}\mid N=k)&amp;=\sum_{i_1\ne 0}p_{x_{i_1}}\sum_{i_1,i_2\ne 0}\frac{p_{x_{i_2}}}{1-p_{x_{i_2}}}\sum_{i_1,i_2,i_3\ne 0}\frac{p_{i_3}}{1-(p_{x_1}+p_{x_2})}\cdots\sum_{i_1,i_2,\dots,i_k\ne 0}\frac{p_{i_k}}{1-(p_{x_1}+p_{x_2}+\cdots p_{k-1})}\\&amp;=\sum_{i_1\ne 0}\sum_{i_1,i_2\ne 0}\cdots\sum_{i_1,i_2,\dots,i_k\ne 0}\prod_{j=1}^{k}\frac{p_{x_{i_j}}}{1-\sum_{\ell=1}^{j}p_{i_\ell}}\end{align&gt;
希望最后一个等式是正确的（如果我错了，请纠正我）。无论如何，从 $1$ 中减去这个数，我们就可以得到所需的概率。
现在，我们希望先限制这个数，然后再将其代入总概率定律中。这就是我的问题开始的地方。我尝试通过为分子和分母设置 $p_{i_j}$ 的上限来计算上限，但在某些情况下，上限变为负数/未定义（因为除以 $0$）。继续往前走，将其代入全概率定律公式中，结果得到负数/未定义值，这实际上不是一件好事。
我们可能可以使用有放回的抽样来降低这个下限，但我不知道这有多大帮助。也许这种天真地尝试相同算法的方法实际上不起作用。

那么我们到底能做什么？这真的可行吗？
任何意见都值得赞赏！]]></description>
      <guid>https://stats.stackexchange.com/questions/655743/generalizing-an-experiment-to-pick-an-element-from-a-set-with-probability-in-a-g</guid>
      <pubDate>Mon, 14 Oct 2024 06:32:20 GMT</pubDate>
    </item>
    <item>
      <title>如何解释自动编码器异常检测的重建误差？</title>
      <link>https://stats.stackexchange.com/questions/655738/how-to-interpret-reconstruction-error-for-anomaly-detection-with-autoencoders</link>
      <description><![CDATA[我有一个基于神经网络的自动编码器。该模型使用 SCADA 数据进行训练。我在异常检测方面取得了不错的结果，主要指标（召回率、准确率、精确率和 F1 分数）约为 85%。
当我开始分析异常期间的重构误差时，我发现对异常贡献最大的参数不一定与其原因有关。
“id”参数对重构误差 (RE) 的贡献约为 50-60%，而应与异常相关的参数对 RE 的贡献仅为 10%。“other”参数表示所有非“id”参数的总和。下图显示了此行为：

此行为不仅出现在此数据集中，还出现在其他异常中。这些数据集相当大，最小的数据集有大约 100 个参数，最大的数据集有 600 个参数，每个数据集都有超过 5 年的数据和 10 分钟的粒度。因此，我认为这不是由于缺乏数据造成的。
我尝试删除“id”参数，但这显著影响了主要指标，使其下降到大约 50-60%。
关于“id”参数，它与时间具有很强的相关性，是一个正的单调序列。
即使模型很好地检测了异常，这种行为是否会使其不可靠？我发现一个可能的解释是，给定输入及其特定条件，自动编码器会为输入预测不同的“id”/时间。我认为该模型可能已经隐式地学习了涡轮机运行的时间特征。结果，它确定给定的条件与预期的时间模式不一致。
这个解释看起来合理吗？我也接受改进模型的建议。
我用不同的数据集验证了模型，尝试用 optuna 超参数优化改进自动编码器，并尝试了不同的数据处理。所有的尝试都导致了相同的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/655738/how-to-interpret-reconstruction-error-for-anomaly-detection-with-autoencoders</guid>
      <pubDate>Mon, 14 Oct 2024 01:38:15 GMT</pubDate>
    </item>
    <item>
      <title>当连续变量等于 0 时创建虚拟变量</title>
      <link>https://stats.stackexchange.com/questions/655727/creating-a-dummy-variable-when-the-continuous-variable-is-equal-to-0</link>
      <description><![CDATA[我实际上是在尝试寻找最佳解释变量，以便估计我的投资组合中交易对手违约的概率。在定义了变量的长列表之后，我正在通过单变量逻辑回归测试每个变量。每个变量的评估都考虑了三个条件：

统计上显著的估计，即 p 值 &lt; 5%；
估计系数的符号（beta 符号）与经济预期一致；
足够的判别力，即 Somers 的 D &gt; 5%

但是，专注于成本变量，首先我尝试通过消除成本量等于零的观察值来考虑该变量。该变量通过了上述所有标准，但 Somer 的 D 较低（30%）。此外，我认为这不是最好的方法，因为零是真正的零，而不是缺失值。因此，我考虑创建一个虚拟变量以保留所有观察值。我创建了一个虚拟变量，如下所示：

当正连续变量等于 0 时，虚拟变量等于 1。
否则为 0。

因此，我执行了以下 logit 回归：
proc logistic data= want plots=ROC;
model perceived_default = Continuous_variable dummy_variable 
run;

根据 Somers 的 $D$ (60%)，结果相当不错，但虚拟变量并不显著（$p$ 值等于 $0.35$）。
我该如何处理这个问题？即使虚拟变量不显著，我是否可以将其保留在模型中？我认为问题出现是因为虚拟变量在构造上与连续变量共线。
最后，在单变量回归之后，我将通过逐步选择来估计多变量回归。]]></description>
      <guid>https://stats.stackexchange.com/questions/655727/creating-a-dummy-variable-when-the-continuous-variable-is-equal-to-0</guid>
      <pubDate>Sun, 13 Oct 2024 16:59:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么自动编码器的潜在空间中不希望有空洞？</title>
      <link>https://stats.stackexchange.com/questions/655726/why-holes-are-not-desirable-in-latent-space-of-autoencoders</link>
      <description><![CDATA[在几项关于自动编码器的研究中，已经指出，普通自动编码器（没有任何正则化的自动编码器）可能会受到潜在空间中空洞的影响。空洞的含义被描述为自动编码器潜在空间中的不连续区域。我无法理解两件事
I) 不连续区域。我认为这意味着将数据映射到潜在空间后获得的流形不连续。
II) 为什么它们不可取？
链接- 在此处输入链接描述（参见第 2 节）]]></description>
      <guid>https://stats.stackexchange.com/questions/655726/why-holes-are-not-desirable-in-latent-space-of-autoencoders</guid>
      <pubDate>Sun, 13 Oct 2024 15:15:51 GMT</pubDate>
    </item>
    <item>
      <title>Nate Silver 的 p(doom) 计算</title>
      <link>https://stats.stackexchange.com/questions/655697/nate-silvers-pdoom-calculation</link>
      <description><![CDATA[在他的最新著作《边缘》中，Nate Silver 概述了一种“贝叶斯”计算方法，用于计算核战争的概率，其前提是自 1946 年以来我们从未目睹过核武器的使用。我发现他的设置和解决方案有点模糊，我想遵循他的逻辑。
他写道：

自 1945 年以来，核武器从未在冲突中使用过，我们应该对此感到多么欣慰？假设在 1946 年 1 月 1 日，你召集了一个由三位专家组成的小组来预测再次发生核爆炸的可能性。Peter Pessimist 告诉你，每年使用核武器的可能性为 10%。Ollie Optimist 说可能性只有 0.1%。而 Mary Middleground 估计可能性为 1%。由于没有真正的证据，你只能将他们的预测平均下来，得出每年 3.7% 的概率。这令人恐惧：这意味着在未来二十年内，核武器被使用的可能性更大。这有助于解释为什么冯·诺依曼等人在二战后认为文明可能不会再存在太久。但在 78 年（1946 年至 2023 年）没有使用核武器之后，我们可以更新我们分配给每个分析师的估计的权重；这是贝叶斯定理的直接应用。例如，我们可以说彼得·佩西米斯特可能是错的。如果真的有 10% 的年核战争概率，那么我们迄今为止仅凭运气就避免核战争的概率不到 1/3,000。然而，我们没有足够的证据来对玛丽·米德尔格兰特的估计做出太多评论。她说每年发生核战争的概率是1/100，而我们只有七十八年的数据来反驳她。 （没错，一个好的贝叶斯主义者会稍微降低她的预测，同时增加我们对 Ollie Optimist 的理论的信任度。）在长崎核爆 78 年后，我们修订后的贝叶斯估计是每年发生核战争的可能性约为 0.35%。&quot;

他附上了一张我一直试图重现的图表：

我对 Nate 的步骤有点困惑，以为我可能想太多了。他似乎在更新他的先验，即三位“专家”的平均值((乐观派 0.1% + 中间派 1.0% + 悲观派 10%)/3 = 3.7%)，通过对随后 78 年内事件结果的观察，对每位专家（称他们为$p_1, p_2, p_3$）进行加权。也就是说，$p$（$n$ 年内未发生的事件 | 事件概率）= $(1-{p_i})^n$
为了复制此结果，我为每个 $n$ 从 0 到 $N$=78 的专家计算了新的权重：
\begin{align}
p&#39;(n) &amp;= \sum_{i=1}^3\frac{p_i(1-p_i)^n}{Z(n)} \\
Z(n) &amp;= \sum_{i=1}^3(1-p_i)^n
\end{align&gt;
然而，这与 Nate 的情节不太相符：

由于我的信封背面没有起作用，我想知道我是不是走运了，Nate 是否对此进行了更复杂的建模？我很想让这个解决方案更加正式，并使这些线条相匹配。欢迎任何意见！谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655697/nate-silvers-pdoom-calculation</guid>
      <pubDate>Sat, 12 Oct 2024 16:57:55 GMT</pubDate>
    </item>
    <item>
      <title>回归均值的行为</title>
      <link>https://stats.stackexchange.com/questions/655691/behaviour-of-regression-toward-the-mean</link>
      <description><![CDATA[我有一个包含 801 人（男性和女性）左右脚长度的数据集。据我所知，这是一个教学数据集，没有任何具体问题或特殊之处。
以下是均值和协方差矩阵，单位为厘米：
## 均值
LengthRightFoot LengthLeftFoot 
24.3 24.3 

## 协方差矩阵
LengthRightFoot LengthLeftFoot
LengthRightFoot 6.34 6.08
LengthLeftFoot 6.08 6.31

左脚对右脚的回归表明，与直觉相反，斜率略低于 1，截距高于 0（见下文）。我认为这是由于向均值回归。到目前为止一切顺利，除非你有更好的解释。
令我困惑的是，截距可疑地接近 1（0.99877）。当然，0.99877 是一个和其他数字一样的数字，但我想知道截距几乎正好是 1 的原因是什么。你能解释一下吗？

调用：
lm(formula = LengthLeftFoot ~ LengthRightFoot)

残差：
最小 1Q 中位数 3Q 最大 
-2.254 -0.239 -0.025 0.187 8.823 

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.99877 0.23741 4.21 2.9e-05 ***
LengthRightFoot 0.95891 0.00973 98.50 &lt; 2e-16 ***
---
有效代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：799 个自由度上的 0.693
多重 R 平方：0.924，调整后的 R 平方：0.924
F 统计量：1 和 799 DF 上的 9.7e+03，p 值：&lt;2e-16


此 R 模拟生成一个包含 50000 个观测值的数据集，其协方差矩阵与真实值相似。回归重现了上述发现：
mu &lt;- c(24.3, 24.3)
covmat &lt;- structure(c(6.33766534019975, 6.07723639200999, 
6.07723639200999, 6.3073693196005), dim = c(2L, 2L), 
dimnames = list(c(&quot;LengthRightFoot&quot;, 
&quot;LengthLeftFoot&quot;), c(&quot;LengthRightFoot&quot;, &quot;LengthLeftFoot&quot;)))

sim &lt;- as.data.frame(mvrnorm(n=50000, mu=mu, Sigma=covmat))

模拟数据的回归：
summary(lm(LengthLeftFoot ~ LengthRightFoot, data=sim))
调用：
lm(formula = LengthLeftFoot ~ LengthRightFoot, data = sim)

残差：
最小值 1Q 中位数 3Q 最大值 
-2.9058 -0.4683 -0.0034 0.4622 2.7255 

系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 1.037961 0.030047 34.55 &lt;2e-16 ***
LengthRightFoot 0.957488 0.001231 777.63 &lt;2e-16 ***
---
有效代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：49998 自由度上的 0.6921
多重 R 平方：0.9236，调整后的 R 平方：0.9236
F 统计量：1 和 49998 DF 上的 6.047e+05，p 值：&lt; 2.2e-16
]]></description>
      <guid>https://stats.stackexchange.com/questions/655691/behaviour-of-regression-toward-the-mean</guid>
      <pubDate>Sat, 12 Oct 2024 15:21:33 GMT</pubDate>
    </item>
    <item>
      <title>如何制作两个完全负相关的增长几何布朗运动（GBM）系列？</title>
      <link>https://stats.stackexchange.com/questions/655735/how-to-make-two-perfectly-negatively-correlated-growing-geometric-brownian-motio</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655735/how-to-make-two-perfectly-negatively-correlated-growing-geometric-brownian-motio</guid>
      <pubDate>Fri, 11 Oct 2024 23:13:17 GMT</pubDate>
    </item>
    <item>
      <title>多元高斯累积分布函数关于 Sigma 矩阵元素的导数</title>
      <link>https://stats.stackexchange.com/questions/655720/derivative-of-multivariate-gaussian-cdf-with-respect-to-elements-of-sigma-matrix</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655720/derivative-of-multivariate-gaussian-cdf-with-respect-to-elements-of-sigma-matrix</guid>
      <pubDate>Fri, 11 Oct 2024 13:47:04 GMT</pubDate>
    </item>
    <item>
      <title>估计概率值大于来自未知分布的 x</title>
      <link>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</link>
      <description><![CDATA[假设我们有 N 个项目的总体，其值从 0 到 6000。
假设总体的平均值是 $\mu$。
我们不知道项目的分布。
我们从这个总体中提取一个项目，我们如何估计 $P(x\geq 2500)$？
同样的问题，假设分布是均匀的。
已编辑：
我们只有关于 $P(x&gt;y)$ 的以下信息：

$x \in [0, 6000]; x \in \Re$
$\mu = 1200$
我们想使用二次损失函数进行估算
]]></description>
      <guid>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</guid>
      <pubDate>Fri, 11 Oct 2024 08:52:55 GMT</pubDate>
    </item>
    <item>
      <title>诺贝尔物理学奖获奖感言中提到，Hopfield 和 Hinton 的哪些工作使得利用神经网络进行机器学习成为可能？</title>
      <link>https://stats.stackexchange.com/questions/655502/what-are-the-works-of-hopfield-and-hinton-that-enable-machine-learning-with-neur</link>
      <description><![CDATA[今天，诺贝尔基金会宣布 2024 年诺贝尔物理学奖，获奖理由如下：

表彰那些使机器学习和人工神经网络成为可能的基础性发现和发明

我的问题是：J. Hopfield 和 G. E. Hinton 的工作究竟是如何使机器学习和 ANN 成为可能的？
（最初发表于 AI，经修改）]]></description>
      <guid>https://stats.stackexchange.com/questions/655502/what-are-the-works-of-hopfield-and-hinton-that-enable-machine-learning-with-neur</guid>
      <pubDate>Wed, 09 Oct 2024 00:53:52 GMT</pubDate>
    </item>
    <item>
      <title>Wald-Wolfowitz 对白噪声进行检验</title>
      <link>https://stats.stackexchange.com/questions/653385/wald-wolfowitz-runs-test-on-white-noise</link>
      <description><![CDATA[我正在寻找方法来检查时间序列是否不同于白噪声 (WN)。我可以直接检查均值是否为零、方差是否为常数以及所有滞后处的自相关是否为零，然后我就会这样做。但除了这些要点之外，应用 Wald-Wolfowitz (WW) 运行检验是否有意义？*我偶然遇到了它（在 R 中的 randtests::runs.test 中实现），并且不确定在这种情况下该如何理解它。
*我的意思是，如果过程是 WN，是否意味着它必须通过 WW 运行检验，前提是具有完美的估计精度（例如来自 WN 的无限样本路径）？]]></description>
      <guid>https://stats.stackexchange.com/questions/653385/wald-wolfowitz-runs-test-on-white-noise</guid>
      <pubDate>Tue, 27 Aug 2024 07:36:53 GMT</pubDate>
    </item>
    </channel>
</rss>