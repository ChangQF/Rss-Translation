<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 25 Jan 2025 21:14:01 GMT</lastBuildDate>
    <item>
      <title>类别不平衡问题</title>
      <link>https://stats.stackexchange.com/questions/660541/imbalanced-classes-problem</link>
      <description><![CDATA[我之所以寻求帮助，是因为我面临。我有要预测的类别，但它们高度不平衡。有时我有一个只出现一次的类别，但这很关键，因为它可能会导致完全关闭。我尝试了贝叶斯网络，但它们不起作用。我也尝试了焦点损失和条件 GAN。我仍在试验，但使用 GAN，我最终会得到负值。如果我更改激活函数以消除负值，则所有内容都会变成零。
值得一提的是，我的数据是数字的，我的数据集中没有任何负值。你还有其他建议吗？我已经尝试了所有方法一段时间了，但复制数据并没有给出任何有意义的结果。
你有什么建议或推荐吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660541/imbalanced-classes-problem</guid>
      <pubDate>Sat, 25 Jan 2025 21:11:02 GMT</pubDate>
    </item>
    <item>
      <title>这个问题的概率</title>
      <link>https://stats.stackexchange.com/questions/660540/probability-of-this-question</link>
      <description><![CDATA[一盒鸡蛋的平均数量为 39。其中鸡蛋数量多于 58 颗但少于 75 颗的概率是多少？本题服从泊松分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/660540/probability-of-this-question</guid>
      <pubDate>Sat, 25 Jan 2025 21:01:01 GMT</pubDate>
    </item>
    <item>
      <title>如何指定 R 中的分层预测的分组结构以协调[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660539/how-to-specify-the-grouping-structure-of-hierarchical-forecasts-in-r-to-reconcil</link>
      <description><![CDATA[我正尝试使用 R 中的 hts 包协调我的分组预测。但是，由于预测模型是非标准的，我无法在计算预测之前将我的数据框转换为 gts 矩阵。我已将我的预测转换为 ts 矩阵，但这已经包含不同的聚合，因此我不确定如何在此阶段添加分组。它需要知道哪些列是聚合才能使用 minT 进行协调，但我不知道如何输入它。有办法做到这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660539/how-to-specify-the-grouping-structure-of-hierarchical-forecasts-in-r-to-reconcil</guid>
      <pubDate>Sat, 25 Jan 2025 20:34:13 GMT</pubDate>
    </item>
    <item>
      <title>使用面板数据确定广义最小二乘协方差矩阵</title>
      <link>https://stats.stackexchange.com/questions/660538/determining-generalised-least-square-covariance-matrix-with-panel-data</link>
      <description><![CDATA[我有一些面板数据（3k 个日期 - 每个日期 40 个观测值），我在每个日期都对这些数据进行线性回归，因为我对这个回归的参数随时间的变化很感兴趣。但是，由于残差的结构（异方差和相关性），我想使用 GLS。
我应该如何确定 FGLS 中使用的协方差矩阵？
-我应该在所有回归中使用唯一的协方差矩阵吗？
-这个唯一的矩阵可以简单地使用跨时间的残差来计算吗？或者我应该简单地使用跨时间的残差来更好地理解这个协方差矩阵是什么样子？]]></description>
      <guid>https://stats.stackexchange.com/questions/660538/determining-generalised-least-square-covariance-matrix-with-panel-data</guid>
      <pubDate>Sat, 25 Jan 2025 19:12:52 GMT</pubDate>
    </item>
    <item>
      <title>生存分析审查 - 已知事件日期，未知开始日期，已知下限，具有随时间变化的协变量</title>
      <link>https://stats.stackexchange.com/questions/660537/survival-analysis-censoring-known-event-date-unknown-start-date-known-lower</link>
      <description><![CDATA[我正在对持续时间数据进行分析，其中生存分析似乎很合适。
我的数据是收容所里狗及其寿命的集合。目标是估计收容所狗的寿命。对于其中许多狗，我有出生日期和死亡日期（如果它们已经死亡）。对于这些动物来说，在截至今天没有死亡的情况下进行右删失很简单。
但是，我有一些狗，我有死亡日期，但没有记录的出生日期——我所拥有的只是兽医对狗死亡时年龄的“估计下限”。例如，狗昨天死了，兽医根据尸检说它们至少有 8 岁。
所讨论的数据可能看起来像这样——第一行是“完整”的记录和第二个可能存在问题的记录。



出生日期
死亡日期
死亡年龄




2020 年 1 月 1 日
2025 年 1 月 1 日
5 年


NA
2025 年 1 月 1 日
8+ 年



一方面，我可以把这些狗当作是经过右审查的，因为我知道在这个例子中，至少到 8 岁时它们还活着。但是，对于这些狗，我也有它们在特定日期接受治疗的医疗记录，在分析中使用这些记录（和其他随时间变化的协变量）会很有帮助。如果没有出生日期，我很难找到如何包含任何随时间变化的协变量。
这似乎不是区间审查或左审查，我很难找到任何具有类似情况的文献 - 这是我们可以在生存模型中处理的问题吗？还是我们需要决定是丢弃这些特定狗的数据还是将分析限制为不使用随时间变化的协变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/660537/survival-analysis-censoring-known-event-date-unknown-start-date-known-lower</guid>
      <pubDate>Sat, 25 Jan 2025 19:07:19 GMT</pubDate>
    </item>
    <item>
      <title>做微积分和选择偏差</title>
      <link>https://stats.stackexchange.com/questions/660536/do-calculus-and-selection-bias</link>
      <description><![CDATA[在这篇论文中，我对选择偏差的分类及其与 Pearl 的do-calculus的联系感到困惑。
按照论文的符号，让$E$表示二元曝光，D表示二元结果，$L1$表示协变量向量，$S$表示选择。$D^e$表示潜在结果。我们的目标是瞄准真正的 ATE，定义为 $P(D^1=1)-P(D^0=1)$
他们将第 1 类选择偏差 (SB) 定义为没有内部有效性但具有外部有效性，即

$P(D=1|E=1,S=1)-P(D=1|E=0,S=1) \ne P(D^1=1|S=1)-P(D^0=1|S=1)$
但是，$P(D^1=1|S=1)-P(D^0=1|S=1)=P(D^1=1)-P(D^0=1)$

他们将第 2 类 SB 定义为它不具有外部有效性，但具有内部有效性，即

$P(D=1|E=1,S=1)-P(D=1|E=0,S=1) = P(D^1=1|S=1)-P(D^0=1|S=1)$
但是，$P(D^1=1|S=1)-P(D^0=1|S=1) \ne P(D^1=1)-P(D^0=1)$

他们提供了以下 DAG 并解释说这是类型 1 SB 的示例。

当我在 DAG 上执行 Pearl 的 do-calculus 规则时，我没有得到这个。如果我要将上面的没有 SB 转化为足够的动作语句，我相信对于 $e=1,0$，我需要以下内容：

$p(d|e,s) = p(d|do(e),s)$
$p(d|do(e),s) = p(d|do(e))$

第一个项目符号是动作/观察（规则 2）。为此，我需要，$D \perp E | S$ 在从 E 中删除所有箭头后出现在 DAG 中。因此这似乎成立（因为它删除了 S 作为对撞机）。
第二个项目符号是插入/删除（规则 1）。为此，我需要 $D \perp S|E$ 在从 E 中删除所有箭头后出现在 DAG 中 - 在这种情况下，DAG 保持不变（如果存在混淆，则会删除箭头）。无论如何，这仍然有一条从 D 到 L1 再到 S 的后门路径。因此这似乎被违反了。因此，基于这些规则，我认为它最坏的情况是 2 型 SB。
正如他们在论文中所说，对 L1 进行条件化使我们能够治愈此 DAG 呈现的选择偏差。但是，这似乎解决了问题 2，因为现在我们有 $p(d| do(e),s,l1) = p(d|do(e),l1)$，因为一旦我也以 $L1$ 为条件，上述后门路径就会被阻止。从随机化/可忽略性来看，标准化允许识别。
除了基于直觉的答案之外，为什么这种 do-calculus 方法不正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/660536/do-calculus-and-selection-bias</guid>
      <pubDate>Sat, 25 Jan 2025 18:53:38 GMT</pubDate>
    </item>
    <item>
      <title>如何推导出 HMM 中的一步预测似然？</title>
      <link>https://stats.stackexchange.com/questions/660535/how-to-derive-the-1-step-ahead-predictive-likelihood-in-hmm</link>
      <description><![CDATA[摘自 BILLIO 等人撰写的论文“使用贝叶斯面板马尔可夫切换 VAR 模型分析欧元区与美国繁荣与萧条之间的相互联系”，其想要比较 2 种制度或 3 种制度模型是否最佳，因此它计算了 1 步预测密度进行比较。但是，我很难推导出$p(y_{t+1}|y_{t})$的数学表达式

基于预测可能性的贝叶斯因子$BF = p(y|K=3)/p(y|K=2)$来确定，以及$p(y|K=3)=\prod^{T-1}_{t=1} \prod^{N}_{i=1} p(y_{it+1}|y_{it}, K=3)$和$p(y_{it+1}|y_{it}, K=3)$的一步预测密度$y_{t+1}$ 取决于截至时间 t 的信息和 $K=3$ 个制度。

其中 $i$ 是单位数，因为它是面板模型，而 $K$ 是制度数。
如果为了简单起见忽略 $i$，我认为我的步骤是：
$p(y_{t+1}|y_{t}) = p(y_{t+1},y_{t})/p(y_{1:t})$
$=[p(y_{t+1}|y_{t}, Z_t)*p(Z_t|y_{1:t})*p(y_{1:t})]/p(y_{1:t})$
不确定 $=\sum^{K}_{k=1} p(y_{t+1}|Z_{t+1}=k)*p(Z_{t}=k|y_{1:t})$
其中，$p(y_{t+1}|Z_{t+1}=k)$ 是 $t+1$ 处的观测似然，并且 $p(Z_{t}=k|y_{1:t})$ 是归一化的前向概率 $\alpha_t$。
但是，根据我的教学，这个预测密度在前向计算步骤中应该相似，其中涉及

转换矩阵，$Q_t[i, j]$ 从 $t-1$ 处的 $i$ 转换到 $t$ 处的 $j$ 

原始前向概率，$\alpha_t$

观测可能性，$obslik_{t+1}$


例如：
$p(y_{t+1}|y_{t})[j]=\sum^{K}_{i=1} Q_{t+1}[i, j] * \alpha_{t}[i] * obslik_{t+1}[j]$，对于 $j=1:K$，
并且 $p(y_{t+1}|y_{t})=\sum^{K}_{j=1} p(y_{t+1}|y_{t})[j]$。我不确定错误发生在哪里。]]></description>
      <guid>https://stats.stackexchange.com/questions/660535/how-to-derive-the-1-step-ahead-predictive-likelihood-in-hmm</guid>
      <pubDate>Sat, 25 Jan 2025 18:14:28 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何重新网格化对数尺度函数？</title>
      <link>https://stats.stackexchange.com/questions/660533/how-should-i-regrid-a-log-scale-function</link>
      <description><![CDATA[我有一个通常以对数刻度绘制的分布函数，但支撑是不规则的。我想将其重新网格化到规则网格上。
最简单的方法是取原始数据的加权直方图，即
$
\overline{f}(x_i)=\frac1N\sum_{&lt;i&gt;}f
$
其中下标$i$表示第 i 个规则箱，求和是箱内所有点的总和。因此，此计算只是对数据 $f$ 进行算术平均。
但最近，我意识到，由于数据通常以对数刻度绘制和分析，也许我应该这样做
$
\overline{f}(x_i) = \exp\left(\frac1N\sum_{&lt;i&gt;}\ln f\right)
$
而不是？因此，操作从使用算术平均值变为几何平均值。我什么时候应该做其中一个？]]></description>
      <guid>https://stats.stackexchange.com/questions/660533/how-should-i-regrid-a-log-scale-function</guid>
      <pubDate>Sat, 25 Jan 2025 16:30:47 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 GAMM mgcv::gam.vcomp() 输出中的大间隔？</title>
      <link>https://stats.stackexchange.com/questions/660532/how-to-interpret-large-intervals-in-gamm-mgcvgam-vcomp-output</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660532/how-to-interpret-large-intervals-in-gamm-mgcvgam-vcomp-output</guid>
      <pubDate>Sat, 25 Jan 2025 16:04:08 GMT</pubDate>
    </item>
    <item>
      <title>不存在对称性时的条件期望</title>
      <link>https://stats.stackexchange.com/questions/660531/conditional-expectation-when-there-are-no-symmetries</link>
      <description><![CDATA[当没有对称性时，如何计算条件期望？例如：
如何证明$E[Y\mid S]=S/3$，其中$(X,Y,Z)$是一个三维变量，其密度函数为$f(x,y,z)=(x+2y+3z)/3$，位于$0&lt;x,y,z&lt;1$和$S=X+Y+Z$上？]]></description>
      <guid>https://stats.stackexchange.com/questions/660531/conditional-expectation-when-there-are-no-symmetries</guid>
      <pubDate>Sat, 25 Jan 2025 14:34:11 GMT</pubDate>
    </item>
    <item>
      <title>是否可以从分级反应模型推断出莫肯量表的存在？</title>
      <link>https://stats.stackexchange.com/questions/660530/can-the-presence-of-a-mokken-scale-be-inferred-from-a-graded-response-model</link>
      <description><![CDATA[能否从分级响应模型（序数指标的 CFA）的结果推断出 Mokken 量表的存在？我的直觉如下：我将分级响应模型拟合到 5 个二分式量表项目。如果这 5 个项目的项目截距现在彼此明显不同并且可以按层次排列（这样项目 1 的阈值小于项目 2 的阈值，项目 2 的阈值小于项目 3 的阈值等），这些结果是否可以解释为表明 (a) 项目的难度是按层次排列的，以及 (b) “正确”回答例如项目 4 的受访者也会正确回答项目 3？]]></description>
      <guid>https://stats.stackexchange.com/questions/660530/can-the-presence-of-a-mokken-scale-be-inferred-from-a-graded-response-model</guid>
      <pubDate>Sat, 25 Jan 2025 14:16:45 GMT</pubDate>
    </item>
    <item>
      <title>非劣效性临床试验的主要结果</title>
      <link>https://stats.stackexchange.com/questions/660527/primary-outcomes-in-a-non-inferiority-clinical-trial</link>
      <description><![CDATA[在非劣效性临床试验中，有可能出现 2 个主要结果吗？如果我们为两个结果定义了相同的非劣效性边界，则根据最大的结果选择样本量。例如，一种可以减轻疼痛和炎症的药物。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/660527/primary-outcomes-in-a-non-inferiority-clinical-trial</guid>
      <pubDate>Sat, 25 Jan 2025 13:40:39 GMT</pubDate>
    </item>
    <item>
      <title>对于 PCA 和 SVD，数据是否应采用不同的权重 ($\cos(\text{latitude})$ 或 $ \sqrt{\cos(\text{latitude})}$)</title>
      <link>https://stats.stackexchange.com/questions/660526/should-data-be-weighted-differently-for-pca-vs-svd-cos-textlatitude-or</link>
      <description><![CDATA[背景
我正在分析纬度-经度网格上的数据，并希望考虑由地球曲率（极点附近的数据密度较高）引起的地理扭曲。为了纠正这个问题，我计划应用基于$\cos(\text{X.latitude})$的权重，即$X*\cos(\text{X.latitude})$。
我理解，对于PCA，当使用协方差矩阵（$X^T X$）时，通常应用$\sqrt{\cos(\text{X.latitude})} $作为权重。这确保了方差贡献按$\cos(\text{X.latitude})$缩放，因为协方差计算有效地对权重进行了平方。我发现（有些激烈 :D）支持这种方法的讨论在这里：

McIntyre：Lambert 论平方根余弦纬度
ScienceBlogs 论平方根加权

（使用 $\cos(\text{latitude})$ 作为权重的理由也在 此 xarray 教程。）
问题
如果我不使用 PCA，而是直接在数据矩阵 $X$ 上使用 SVD，我应该：

直接使用 $\cos(\text{X.latitude})$ 作为权重，因为 SVD 期间不会发生平方？
或者仍然使用 $\sqrt{\cos(\text{X.latitude})}$，类似于 PCA，即使协方差矩阵没有明确计算？

我引用的是这个 Stats Exchange 上有关 PCA 和 SVD 的帖子，其中强调了这两种方法之间的密切关系。但是，我不清楚在使用 SVD 处理地理数据时，这种关系如何影响权重的选择。
如果能澄清 SVD 与 PCA 正确加权方案背后的数学原理，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660526/should-data-be-weighted-differently-for-pca-vs-svd-cos-textlatitude-or</guid>
      <pubDate>Sat, 25 Jan 2025 13:25:35 GMT</pubDate>
    </item>
    <item>
      <title>预先注册的假设是否需要进行多重比较校正？</title>
      <link>https://stats.stackexchange.com/questions/660522/do-pre-registered-hypotheses-need-a-correction-for-multiple-comparisons</link>
      <description><![CDATA[我最近偶然发现一个说法，研究人员只需预先注册他们将要执行的每项可能测试的假设，就可以避免使用校正进行多重比较。这是正确的吗？该声明没有引用任何参考文献，老实说，我以前没有在其他地方明确读到过这一点。如果能提供相关文献或任何形式的评论，我将不胜感激。谢谢！
编辑：错别字]]></description>
      <guid>https://stats.stackexchange.com/questions/660522/do-pre-registered-hypotheses-need-a-correction-for-multiple-comparisons</guid>
      <pubDate>Sat, 25 Jan 2025 12:14:46 GMT</pubDate>
    </item>
    <item>
      <title>两种在零和一相等的数组中查找 1 的位置的算法的比较</title>
      <link>https://stats.stackexchange.com/questions/660516/comparison-of-two-algorithms-for-finding-a-position-of-1-in-an-array-with-equal</link>
      <description><![CDATA[给定一个包含一半零和一半一的数组 𝑎[1..𝑛]，我们需要在 𝑎 中找到一个包含值 1 的位置。考虑以下两种算法：
算法 1
i = 1
while a[i] != 1:
i += 1
return i

算法 2
while True:
i = random(1, n)
if a[i] == 1:
return i

函数 random(1, n) 返回 1 和 𝑛 之间的随机整数。
a) 比较这两种算法。
b) 哪种算法更好？
这是我的解决方案部分 (a)：：
算法 1（线性搜索）：
优点：

如果存在，保证找到 1。
易于实现。

缺点：

最坏情况下的时间复杂度为 O(n)，其中 n 是数组的大小。
如果数组的前半部分只包含零，则可能会很慢。

算法 2（随机搜索）：
优点：

如果早点找到 1，则可能会非常快。

缺点：

无法保证在有限的步骤中找到 1。
最坏情况在理论上是无限的。
平均时间复杂度更难分析，但通常比算法 1效率低。

这是我对部分 (b) 的解决方案：

一般而言，算法 1（线性搜索）通常被认为更好。
保证成功：它在有限的步骤内提供保证的解决方案。
可预测的性能：其最坏情况的时间复杂度是已知且有界的。
当算法 2 可能更可取（在非常特殊的情况下）：如果数组非常大，并且早期找到 1 的概率非常高（例如，如果数组几乎完全由 1 填充），算法 2 可能会更快。但是，这是一个非常特殊且不太可能的情况。

在大多数实际情况下，算法 1（线性搜索）是更可靠且通常更有效的选择。
目前，我不知道如何从理论上分析这个问题并使用蒙特卡洛方法进行模拟，所以我希望有人能支持我解决这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/660516/comparison-of-two-algorithms-for-finding-a-position-of-1-in-an-array-with-equal</guid>
      <pubDate>Sat, 25 Jan 2025 06:30:52 GMT</pubDate>
    </item>
    </channel>
</rss>