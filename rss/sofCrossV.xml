<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 23 Oct 2024 12:32:58 GMT</lastBuildDate>
    <item>
      <title>控制由诱导矩阵 $L_1$ 范数衡量的估计误差</title>
      <link>https://stats.stackexchange.com/questions/656194/control-the-estimation-error-measured-by-induced-matrix-l-1-norm</link>
      <description><![CDATA[当我使用套索法逐列估计矩阵（例如 $A$）时，我观察到在数值实验中估计误差 $\|\hat{A}-A\|_{L_1}=\underset{1\le j \le p}{\max}|\hat{a}_{\cdot j}-a_{\cdot j}|_1$ 似乎受 $cM_p$ 限制，其中 $\|A\|_{L_1}=M_p$ 且 c 为常数。
我不确定这个观察结果是否正确。我知道 $\|\hat{A}-A\|_{L_1}$ 可以被 $s\|\hat{A}-A\|_{\max}$ 所限制，其中 $s $ 表示列中非零元素的数量，但数值实验的结果似乎有所不同。
这是正确的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656194/control-the-estimation-error-measured-by-induced-matrix-l-1-norm</guid>
      <pubDate>Wed, 23 Oct 2024 12:18:51 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 p 值的逆概率？</title>
      <link>https://stats.stackexchange.com/questions/656193/how-to-calculate-the-inverse-probability-of-a-p-value</link>
      <description><![CDATA[我理解，如果零假设为真，p 值就是获得数据（或更多极端值）的概率。
然而，研究人员真正想知道的是，在给定数据的情况下，零假设为真的概率。
因此，需要计算逆概率，该逆概率基于对零假设基本概率的估计，并对诸如“获得数据的总概率”之类的内容进行加权。
我可以使用贝叶斯推理，结合测试的敏感度、基准率和阳性总数：
P（患病|阳性）= P（阳性|患病）* P（患病）/ P（阳性）
例如，如果一种疾病影响 100 人中的 1 人，测试的敏感度为 99%，我随机测试 100 人，我会得到两个阳性（一个真，一个假），逆概率~0.5：
0.99 * 0.01 / ~0.02 = ~0.5
现在，我的问题是，我应该如何使用贝叶斯推理来计算 p 值的逆概率？
例如，我对 H0 没有任何先验知识，因此假设 P(H0) = 0.5，然后我得到一个显著性检验，假设 p 值 = 0.01。我想知道在这种情况下 P(positif) 对应的是什么：
P(H0|data) = P(data|H0) * P(H0) / P(of what?) = 0.01 * 0.5 / 具体是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/656193/how-to-calculate-the-inverse-probability-of-a-p-value</guid>
      <pubDate>Wed, 23 Oct 2024 12:13:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么大学统计课上仍然教授变量的逐步选择？</title>
      <link>https://stats.stackexchange.com/questions/656192/why-is-stepwise-selection-of-variable-still-taught-in-university-statistics-clas</link>
      <description><![CDATA[我不止一次碰到最近出版的教科书和课程，它们教授使用分步法构建模型。考虑到这种方法带来的问题，为什么还要这样做呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/656192/why-is-stepwise-selection-of-variable-still-taught-in-university-statistics-clas</guid>
      <pubDate>Wed, 23 Oct 2024 12:01:59 GMT</pubDate>
    </item>
    <item>
      <title>如何根据数据估计平均值和方差？</title>
      <link>https://stats.stackexchange.com/questions/656191/how-do-i-estimate-the-mean-and-variance-from-data</link>
      <description><![CDATA[我有一些 1D 数据，想估计它的均值和方差。我没有底层模型，也没有真实值/目标值可以比较。为了进行比较，我该如何估计数据的偏差和方差。
例如，

此处的橙色和蓝色曲线表示经过后处理的相同数据集，但更改了变量。如何确保偏差和方差最小？]]></description>
      <guid>https://stats.stackexchange.com/questions/656191/how-do-i-estimate-the-mean-and-variance-from-data</guid>
      <pubDate>Wed, 23 Oct 2024 11:44:32 GMT</pubDate>
    </item>
    <item>
      <title>当协方差矩阵非正定义时如何处理VAR模型？</title>
      <link>https://stats.stackexchange.com/questions/656185/how-to-deal-with-var-model-when-covariance-matrix-is-not-positive-define</link>
      <description><![CDATA[当我尝试将 VAR 模型应用于多变量时间序列时，我遇到了一些复杂情况。
数据集：数据集由来自多个用户的时间序列数据组成。对于每个用户，我都有许多特征（例如 F1、F2、...F32），其中一个是预测的目标特征，例如F29.
training_set：它通过 90 天的滑动时间窗口构建，为每个用户生成不同的块，例如，对于用户 i，Xi=[&lt;day1,...day89&gt;, &lt;day2,...day90&gt;,...] Yi=[, , ,...]
Python 代码（经过规范化并使每个特征平稳，最多二阶导数）：
 try: 
model: VAR(training_set) 
x = model.select_order(maxlags=90) 
print(x.summary()) 
except Exception as error: 
print(error)

问题 1：对于大多数用户，我得到：“数组的第 17 或第 31t 个前导子项不是正定的。”
问题 2：对于那些我能够无错误地运行上述代码的用户，当分析 F29（目标变量）的结果时，结果发现，p 值 &lt;= 0.05 与不同用户的不同滞后有关，对应于同一特征。例如，对于特征 F20，用户 3 的滞后为 10，用户 4 的滞后为 12。
关于问题 1，我搜索了一下，似乎“当协方差矩阵在数值上不呈正定时，就会发生错误。”。由此，我了解到在对应于协方差计算时存在相反的信号特征。您知道如何解决这个问题吗？
关于问题 2：我找不到任何有用的方法来解决它。有什么想法或帮助吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656185/how-to-deal-with-var-model-when-covariance-matrix-is-not-positive-define</guid>
      <pubDate>Wed, 23 Oct 2024 10:01:11 GMT</pubDate>
    </item>
    <item>
      <title>使用单向受试者间 MANOVA 与裂区重复测量 ANOVA 相比有哪些优点和缺点？</title>
      <link>https://stats.stackexchange.com/questions/656184/what-are-the-advantages-and-disadvantages-of-using-a-one-way-between-subjects-ma</link>
      <description><![CDATA[例如，我想分析三个物种（猫、狗和老鼠）的心率、呼吸频率、身高、体重和毛发数量的差异。这当然是一个荒谬的例子，但进行单向受试者间 MANOVA 与进行裂区方差分析相比有什么优势呢？
对于 MANOVA，受试者间因子将是物种，DV 如上所述。
对于裂区方差分析，受试者间因子将是物种，受试者内因子的每个级别将是不同的 DV。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656184/what-are-the-advantages-and-disadvantages-of-using-a-one-way-between-subjects-ma</guid>
      <pubDate>Wed, 23 Oct 2024 09:59:24 GMT</pubDate>
    </item>
    <item>
      <title>回归汇总数据（beta系数）的元分析</title>
      <link>https://stats.stackexchange.com/questions/656182/meta-analysis-about-regression-summary-databeta-coefficient</link>
      <description><![CDATA[关于元分析，如果我有三项研究都使用线性回归模型来分析收入和支出之间的关系，但每项研究使用的协变量都不同——第一项研究包括年龄和教育，第二项研究包括年龄和性别，第三项研究包括教育、税率和是否有孩子——考虑到这些具有不同协变量的模型，我还能进行元分析吗？
对于这种类型的研究，我考虑过以下策略：使用元回归，将 beta 系数视为因变量，将协变量的存在与否视为虚拟变量。例如，回归模型是否包含教育（是 = 1；否 = 0）等。我想知道这种方法是否合适，或者有更好的建议吗？
$BETA_i = constant + b_1*EDU + e_i$
哪个EDU是虚拟的[0或1]。
我主要关心的是确保beta系数不受协变量的影响，或者协变量对荟萃分析可能根本不重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/656182/meta-analysis-about-regression-summary-databeta-coefficient</guid>
      <pubDate>Wed, 23 Oct 2024 09:26:29 GMT</pubDate>
    </item>
    <item>
      <title>对于时间序列来说，样本外验证是否也应该超出时间范围？</title>
      <link>https://stats.stackexchange.com/questions/656180/should-out-of-sample-validation-also-be-out-of-time-for-time-series</link>
      <description><![CDATA[简介
在训练模型时，“样本”通常是指用于拟合模型的数据，因此...
样本：用于训练模型的数据
样本外：未用于训练模型的数据
超出时间：未用于训练模型的数据，晚于用于训练模型的数据
有时规定必须对模型进行“样本外”和“超出时间”验证。但不清楚“超出时间”是什么意思，已经是“样本外”了。我认为“样本外”可以解释为对不属于训练“样本”的客户的验证。
解释 1
这里的解释是进行两次独立的验证运行：

对“及时”的“样本外”数据进行验证
对同样“样本外”的“时间外”数据进行验证


我认为这里最大的缺陷是“样本外”验证将是“及时的”，因此绩效指标可能会被夸大。例如，如果“及时”期间是在 covid 期间，那么您将获得“样本外”验证结果，表明您在这些未见过的客户上做得很好，而实际上，该模型在生产环境中对未见过的客户表现会很糟糕（这是超时的）。
解释 2
这里的解释是，报告“及时”和“样本外”数据中的任何数字都没有意义，因为这些数字实际上并没有说明现实世界的表现。相反，向监管机构报告的所有验证数字都是超时的。

仅对“样本外”数据进行“超时”验证。这是对现实世界表现最保守的估计。它也是通用性的最佳指标。这里的“样本外”是指甚至没有“及时”进入训练样本的客户。
对所有“超出时间”的客户进行验证数据，因为这是对近期业绩的最佳估计，因为客户群在近期（例如未来 2-3 年）通常相当稳定。


根据这种解释，您报告的最保守的数字很可能最能反映现实世界的表现并反映普遍性（例如对未见过的客户）。
问题
您会使用哪种解释？您认为这两种解释同样有效吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656180/should-out-of-sample-validation-also-be-out-of-time-for-time-series</guid>
      <pubDate>Wed, 23 Oct 2024 07:39:33 GMT</pubDate>
    </item>
    <item>
      <title>逆协方差估计的样本要求</title>
      <link>https://stats.stackexchange.com/questions/656179/sample-requirements-for-inverse-covariance-estimation</link>
      <description><![CDATA[我有一个输入信号矩阵 $X$，其形状为 4 x N，每行包含相同的信号，但具有恒定的时间延迟（与阵列信号处理相关）
$$X[i, :] = X(t-i\tau)$$
我的目标是找到信号的逆协方差矩阵，
$$ R^{-1} = (XX^H)^{-1}$$
我想知道的是，是否有任何统计方法可以找到使矩阵可逆所需的最小时间样本和最大样本，直到信号不再平稳。
该应用是无线通信，因此在基带，$\mu_i = 0$ 或接近于零，因此被忽略。]]></description>
      <guid>https://stats.stackexchange.com/questions/656179/sample-requirements-for-inverse-covariance-estimation</guid>
      <pubDate>Wed, 23 Oct 2024 06:37:14 GMT</pubDate>
    </item>
    <item>
      <title>关于多元密度函数的估计</title>
      <link>https://stats.stackexchange.com/questions/656177/on-estimation-of-multivariate-density-function</link>
      <description><![CDATA[设 $(X,Y)$ 为非负绝对连续随机向量，概率密度函数为 $f(x,y)$。随机样本 $\{X_{1i},X_{2i}\}$ 也为独立同分布。然后 $f$ 的核密度估计量由以下公式给出
$$\widehat{f}(x,y)=\frac{1}{nh_xh_y}\sum_{i=1}^n k\left(\frac{x-x_i}{h_x},\frac{y-y_i}{h_y}\right)=\frac{1}{nh_xh_y}\sum_{i=1}^n k\left(\frac{x-x_i}{h_x}\right)k\left(\frac{y-y_i}{h_y}\right),$$
其中 $h_x$ 和 $h_y$ 表示带宽参数，$K$ 是核。
使用一些数据，我估算了核密度估计：
library(ks)

# 您对 X 和 Y 的缩放数据
X &lt;- c(0.95230999, 0.00596125, 0.00298063, 0.89716841, 0.16244411, 0.01490313, 
0.1609538, 0.16244411, 0.29508197, 0.05812221, 0.5633383, 0.60804769, 
0.05365127, 0.30849478, 1, 0.04023845, 0.12965723, 0.37853949, 0, 0.57824143)

Y &lt;- c(0.01195652, 0.27318841, 0.21557971, 0.12318841, 0.21630435, 0.22572464, 
0.03550725, 0.32971014, 0.13007246, 0.22644928, 0.22427536, 0, 
1, 0.54311594, 0.36775362, 0.18152174, 0.0884058, 0.19565217, 
0.08514493, 0.0807971)

# 将 X 和 Y 组合成一个矩阵
data_matrix &lt;- cbind(X, Y)

# 使用插件方法 (Hpi) 进行带宽选择
H &lt;- Hpi(x = data_matrix) # 插件带宽选择方法
print(H)
kde_result &lt;- kde(x = data_matrix, H = H)
plot(kde_result, cont = c(50, 75, 95)) # 50%、75% 和 95% 水平的轮廓

我的问题是“我们如何估计$$G(x,t)=\frac{\partial}{\partial x} F(x,t),$$ 其中 $F$ 是联合分布函数，$t$ 是某个正实数。
$G(x,t)$ 的核估计如下
$$\widehat{G}(x,t)=\frac{1}{nh_xh_y}\sum_{i=1}^n k\left(\frac{x-x_i}{h_x}\right)K\left(\frac{y-y_i}{h_y}\right),$$
其中 $$K(z)=\int_0^z k(x)dx.$$ 有关更多详细信息，请参见此处。]]></description>
      <guid>https://stats.stackexchange.com/questions/656177/on-estimation-of-multivariate-density-function</guid>
      <pubDate>Wed, 23 Oct 2024 06:20:09 GMT</pubDate>
    </item>
    <item>
      <title>如果包含两个变量之间的相互作用，是否也需要单独包含这两个变量？[重复]</title>
      <link>https://stats.stackexchange.com/questions/656176/if-you-include-an-interaction-between-two-variables-do-you-need-to-include-the</link>
      <description><![CDATA[假设我有：

模型 1：具有交互作用和主效应的回归模型：
$$ Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3(X_1 \times X_2) + \epsilon $$

模型 2：仅具有交互作用的相同回归模型：
$$ Y = \beta_0 + \beta_3(X_1 \times X_2) + \epsilon $$


使用模型 2（即忽略主效应）是否合适？我从未见过这种情况，所以我猜不合适 - 这样做有什么原因吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656176/if-you-include-an-interaction-between-two-variables-do-you-need-to-include-the</guid>
      <pubDate>Wed, 23 Oct 2024 05:44:00 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 Arima 函数错误地包含了一个额外的 MA 项</title>
      <link>https://stats.stackexchange.com/questions/656174/arima-function-in-r-incorrectly-including-an-additional-ma-term</link>
      <description><![CDATA[在拟合 ARIMA 模型时（使用来自预测包的 Arima 函数），有一个额外的隐藏 MA 项。
library(astsa)
library(forecast)
set.seed(99)
simul_sarima &lt;- 5 + sarima.sim(ar=0.0, d=0, ma=-.3, sar=0.8, D=0, sma=-.2, S=12, n=1200)
fit_sarima &lt;- Arima(simul_sarima, order=c(0,0,1), seasonal=c(1,0,1))
summary(fit_sarima)
print(fit_sarima$model$phi)
print(fit_sarima$model$theta)

ARIMA(0,0,1)(1,0,1)[12] 具有非零均值 

ma1 sar1 sma1 均值
-0.2904 0.7911 -0.234 4.9963

Phi:
0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.7911284

Theta:
-0.29039562 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 -0.23395825 0.06794045

Phi 正常：
AR12 = 0.7911284
Theta 有：
MA1 = -0.29039562;
MA12 = -0.23395825;
MA13 = 0.06794045
为什么是 MA13 项？
我手动计算了预测。他们正在考虑这个最后的 MA13 任期。]]></description>
      <guid>https://stats.stackexchange.com/questions/656174/arima-function-in-r-incorrectly-including-an-additional-ma-term</guid>
      <pubDate>Wed, 23 Oct 2024 03:39:13 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中对二维数据进行聚类[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656145/clustering-two-dimensional-data-in-r</link>
      <description><![CDATA[我在一个数据框中有 35 个线性模型（b 是截距，a 是系数）：
xy &lt;- structure(list(b = c(2045.08, 2045.58, 2045.33, 2045.29, 2045.39, 
1991.67, 2053.54, 2048.3, 2049.76, 2003.74, 2021.51, 1984.74, 
2038.64, 2053.64, 2011.17, 2039.31, 1891.7, 1745.42, 1712.83, 
1119.93, 1097.59, 1629.34, 1638.34, 1038.81, 1673.84, 1663.97, 
784.72, 885.24, 1800.33, 1723.93, 1017.47, 1014.38, 1651.5, 2969.72, 
3254.87), a = c(2.48, 2.36, 2.42, 2.43, 2.4, 3.67, 2.29, 2.41, 
2.38, 2.69, 2.55, 2.84, 2.47, 2.35, 2.68, 2.52, 3.4, 4.33, 4.53, 
8.05, 8.18, 4.94, 4.89, 8.51, 4.7, 4.76, 9.94, 9.36, 4.04, 4.48, 
8.63, 8.19, 4.82, -1.94, -2.52)), row.names = c(NA, -35L), class = &quot;data.frame&quot;)

其中一些非常相似，我想通过聚类来减少模型数量。

数据看起来高度相关。
我尝试过 kmeans()，但它会为密集的点云生成许多聚类，并为视觉上分离的点生成一个聚类points.
kmeans(xy, 12)$centers |&gt; points(pch = 3, col = &quot;red&quot;)


可以看出，所有小于 1500 的 b 值都只有一个聚类。两个高 b 值也是如此。而 2000 左右的 b 值在视觉上密集的云被分成了几个聚类。
还有其他方法可以对此类数据进行聚类吗？
编辑：在我的情况下，3 个聚类是不够的。我的目标不是平均数据，而是丢弃相似的数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/656145/clustering-two-dimensional-data-in-r</guid>
      <pubDate>Tue, 22 Oct 2024 14:53:15 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何加权分位数回归中不确定性未知的点？</title>
      <link>https://stats.stackexchange.com/questions/656053/how-should-i-weight-points-for-which-the-uncertainties-are-unknown-in-a-quantile</link>
      <description><![CDATA[背景
我正在尝试分析来自不同实验研究的汇编数据，并希望得到有关如何在分位数回归中思考加权点的建议。
我并不是想做经典的荟萃分析。相反，我想对响应 $Y$ 执行分位数回归，该回归是两个连续预测变量 $X_1$ 和 $X_2$（均在实验中操纵）的函数。我的目标是获得 $X_1$ 和 $X_2$ 对 $Y$ 的 ~90 分位数的影响的最佳参数估计值（平均值/中位数不具有科学意义）。
但是，在某些情况下，我只能访问每个治疗的平均值（不是原始数据），因此我认为我需要加权点。我对加权最小二乘法的经验有限，在分位数回归方面则一无所知。我理解，在更简单的回归中，典型的方法是仅用 1/方差加权均值。但是，这并非适用于所有情况。
问题

在仅报告均值的研究中，约 1/3 没有报告相关的不确定性（SD/SE/方差）。我应该如何权衡这些点？
许多研究使用没有重复的回归设计。这在科学和统计上是合理的，但同样：我应该如何权衡这些点？
第二个问题，输入会很好但不是必需的：当我计算所有报告具有不确定性的平均值的案例的 1/方差时，我得到的值相差 2-3 个数量级。我认为这大大低估了权重较高的案例中的不确定性，可能是因为方差通常是从很少的测量中估计出来的。

解决这些问题的最佳方法是什么？在分位数回归的背景下，是否存在任何其他复杂因素？
可能不相关，但有其他背景
理想情况下，实验将使用回归设计，并在 $X_1$ 和 $X_2$ 的一致值范围内测量 $Y$。但是，实验不仅在 $X_1$ 和 $X_2$ 的值方面存在很大差异，而且在级别数量方面也存在很大差异 - 有些实验仅使用 1 或 2 个级别的 $X_1$ 和 $X_2$。
此外，理想情况下，人们应该考虑研究和物种层面的变化。我在这里完全忽略了这些，因为我认为它们不是那么重要的问题。但我很高兴在混合/分层模型的背景下也回答了这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/656053/how-should-i-weight-points-for-which-the-uncertainties-are-unknown-in-a-quantile</guid>
      <pubDate>Sun, 20 Oct 2024 19:06:46 GMT</pubDate>
    </item>
    <item>
      <title>Python 中 1：1 比率的二项式检验[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656037/binomial-test-in-python-for-11-ratio</link>
      <description><![CDATA[我收集了如下的性别比例数据：
 公司 A 公司 B 公司 C
部门 女性 男性 女性 男性 女性 男性
艺术 98 2 95 5 80 20
工程 2 98 30 70 10 90
家政 100 0 90 10 70 30

现在，我的老师要求我做一个二项式检验（然后是卡方检验），以确定性别比例是否与 1:1 有统计学上的显著差异。我该如何在 Python 中做到这一点？
我尝试在这里阅读有关这个​​概念的内容：
https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/hypothesis-testing/hypothesis-testing-with-the-binomial-distribution.html
但我不确定如何具体实现它以及在哪里使用哪些变量。因为我有 3 个不同的变量：性别、公司名称和部门。或者我应该跳过部门，对不同公司进行一般比例比较？
我猜这里可能有几种不同的方法，所以我愿意听取建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/656037/binomial-test-in-python-for-11-ratio</guid>
      <pubDate>Sun, 20 Oct 2024 13:39:34 GMT</pubDate>
    </item>
    </channel>
</rss>