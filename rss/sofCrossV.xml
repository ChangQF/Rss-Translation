<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 22 Sep 2024 21:14:29 GMT</lastBuildDate>
    <item>
      <title>如何使用生存分析对不同期限的分期付款进行建模？</title>
      <link>https://stats.stackexchange.com/questions/654738/how-to-model-installment-payments-with-different-durations-using-survival-analys</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654738/how-to-model-installment-payments-with-different-durations-using-survival-analys</guid>
      <pubDate>Sun, 22 Sep 2024 19:55:11 GMT</pubDate>
    </item>
    <item>
      <title>均值较小的逆高斯分布具有不可靠的样本均值</title>
      <link>https://stats.stackexchange.com/questions/654737/inverse-gaussian-with-small-mean-has-unreliable-sample-mean</link>
      <description><![CDATA[考虑一个平均值为$\mu$（如$0.001$）的逆高斯分布，我们将其方差固定为一个较大的值$\sigma^2$，比如说$0.5$。然后，如果我从该分布中抽取 $N$ 次样本，我预计样本平均值约为 $\mu$，但除非 $N$ 的值非常大，否则这种情况不会发生。
import scipy as sp

N = 1_000 # 我们至少需要使用 10_000_000，否则它会非常小，比如 1e-6 
mean = 0.001
var = 0.5
lmbda = mean**3 / var

print(f&quot;样本平均值：{sp.stats.invgauss.rvs(mu=(mean/lmbda), loc=0, scale=lmbda, size=N).mean()}&quot;)

如果您运行此脚本N 等于 1000、10_000、1_000_000，您将得到大约 1e-6，其数量级与均值的平方相同。

为什么会出现这种情况，我该如何避免？即，我可以从均值较小、方差相对较大的逆高斯中采样，而不会产生数值问题吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/654737/inverse-gaussian-with-small-mean-has-unreliable-sample-mean</guid>
      <pubDate>Sun, 22 Sep 2024 19:23:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么 VAE 损失中的期望项在实际中没有实现？</title>
      <link>https://stats.stackexchange.com/questions/654736/why-expectation-term-in-vae-loss-not-implemented-in-practical</link>
      <description><![CDATA[根据 VAE 论文：https://arxiv.org/pdf/1906.02691（等式 2.10，第 21 页）
VAE 损失包含期望项。如果我理解正确的话，我们需要从输入 x 中抽取超过 1 个结果并平均其损失以满足期望项。但我发现许多实现只抽取一个结果，但为什么呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/654736/why-expectation-term-in-vae-loss-not-implemented-in-practical</guid>
      <pubDate>Sun, 22 Sep 2024 18:52:47 GMT</pubDate>
    </item>
    <item>
      <title>损失函数——在一个数据点还是所有数据点上计算？</title>
      <link>https://stats.stackexchange.com/questions/654735/loss-function-computed-on-one-data-point-or-on-all-data-points</link>
      <description><![CDATA[我正在尝试阅读 Jerome H. Friedman 关于梯度提升决策树的讲座。不幸的是，我对统计学和数学的理解非常肤浅，我感到很困惑，所以我希望这里有人能帮忙。
Friedman 谈到了似乎在单个数据点上评估的损失函数。在他的符号中，训练样本是集合 $\{ (\vec{x_1},y_1),(\vec{x_2},y_2),...,(\vec{x_N},y_N)\}$。每个 $\vec{x_i}$ 都是一组输入值，每个 $y_i$ 都是一个标量，即相应的输出值（他实际上将该集合缩写为 $\{y_i,\vec{x_i}\}_1^N$）。
然后他将损失函数定义为 $L(y,F(\vec{x}))$。具体来说，$y$ 未标记为向量，因此我认为他谈论的是单个标量值。 $F(\vec{x})$ 也可以解释为标量，因为 $F(\vec{x})$ 表示模型 $F$ 的输出，我们用它来近似数据集的真实样本。我们将单个数据点输入到这个模型中，得到标量输出。
因此，根据 Friedman 的说法，损失函数似乎是在每个数据点上单独计算的。
但在大多数地方，损失函数被定义为所有输入和输出的函数。例如，均方误差 (MSE) 定义为：
MSE = $\frac{1}{n}\sum_{i=1}^n (Y_i-\hat{Y}_i)^2$ 这里 $\hat{Y_i}$ 对应于弗里德曼的 $F(\vec{x_i})$。
因此，很明显，MSE 是针对所有输入和所有输出定义的。
Friedman 继续声明，拟合模型是通过操纵 F 来计算 $E_{y,\vec{x}}(L(y,F(\vec{x}))$ 的最小值的过程。这是对所有可能的输入和输出的损失函数的期望。
具体来说：$F^{*}=argmin_{F} E_{y,\vec{x}}(L(y,F(\vec{x}))$
但实际上，我们优化的是最小 MSE。
这是对同一事物的离散/连续解释吗？还是我读错了？]]></description>
      <guid>https://stats.stackexchange.com/questions/654735/loss-function-computed-on-one-data-point-or-on-all-data-points</guid>
      <pubDate>Sun, 22 Sep 2024 18:30:02 GMT</pubDate>
    </item>
    <item>
      <title>用于近似离散随机变量分布的 KL 散度误差的量化</title>
      <link>https://stats.stackexchange.com/questions/654734/quantification-of-kl-divergence-error-for-approximating-a-distribution-over-disc</link>
      <description><![CDATA[我想知道以下已在某些文献中提及但从未明确证明的内容
考虑一个由长度为 n 的随机变量的二进制向量组成的设置，例如 $\vec{v}=(v_0,v_1,v_2....v_n)$，其中每个 $v_i \in \{1,-1\}$。让我们定义一个任意分布，该分布定义在 $2^n$ 个随机 $\vec{v}$ 向量的支持上，即 $P(\vec{v}): \{-1,1\}^n \mapsto \{0,1\}$。声明是，总是可以将 $P(\vec{v})$ 近似表示为 k 次多线性多项式的指数，如下所示
\begin{equation}
P(\vec{v}) \approx e^{A(\vec{v})}
\end{equation
其中
\begin{equation}
A(\vec{v}) = a_0 + \sum_i c_i v_i + \sum_{i,j, i\ne j} K_{ij} v_i v_j + \sum_{i,j,p, i\ne j\ne p} H_{ijp} v_i v_jv_p + .....\sum_{i,j,p,q.... i\ne j\ne p\ne q ....} G_{ijpq....k} v_i v_jv_pv_q....v_k
\end{equation
and a_0, $\vec{c}$, $\vec{K}$, $\vec{H}$,...$\vec{G}$ 都是在实数域上定义的。这个说法总是正确的吗？如何证明它？如何量化第一个方程的 RHS 和 LHS 之间的 KL 散度误差？任何正式的证明、参考文献、证明草图都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654734/quantification-of-kl-divergence-error-for-approximating-a-distribution-over-disc</guid>
      <pubDate>Sun, 22 Sep 2024 18:24:33 GMT</pubDate>
    </item>
    <item>
      <title>如何使用自动编码器提取图像特征？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654730/how-to-extract-features-of-images-using-autoencoders</link>
      <description><![CDATA[我想使用自动编码器计算输入图像的特征。代码如下：
import keras
from keras import layer

input_img = keras.Input(shape=(28, 28, 1))

x = layer.Conv2D(16, (3, 3),activation=&#39;relu&#39;, padding=&#39;same&#39;)(input_img)
x = layer.MaxPooling2D((2, 2), padding=&#39;same&#39;)(x)
x = layer.Conv2D(8, (3, 3),activation=&#39;relu&#39;, padding=&#39;same&#39;)(x)
x = layer.MaxPooling2D((2, 2), padding=&#39;same&#39;)(x)
x = layer.Conv2D(8, (3, 3),activation=&#39;relu&#39;, padding=&#39;same&#39;)(x)
encoded = layer.MaxPooling2D((2, 2), padding=&#39;same&#39;)(x)

# 此时表示为 (4, 4, 8)，即 128 维

x = layer.Conv2D(8, (3, 3),activation=&#39;relu&#39;, padding=&#39;same&#39;)(encoded)
x = layer.UpSampling2D((2, 2))(x)
x = layer.Conv2D(8, (3, 3),activation=&#39;relu&#39;, padding=&#39;same&#39;)(x)
x = layer.UpSampling2D((2, 2))(x)
x = layer.Conv2D(16, (3, 3),activation=&#39;relu&#39;)(x)
x = layer.UpSampling2D((2, 2))(x)
decoded = layer.Conv2D(1, (3, 3),activation=&#39;sigmoid&#39;, padding=&#39;same&#39;)(x)

autoencoder = keras.Model(input_img，已解码)
autoencoder.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;)

从 keras.datasets 导入 mnist
将 numpy 导入为 np

(x_train, _), (x_test, _) = mnist.load_data()

x_train = x_train.astype(&#39;float32&#39;) / 255.
x_test = x_test.astype(&#39;float32&#39;) / 255.
x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))
x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))

从 keras.callbacks 导入 TensorBoard

autoencoder.fit(x_train, x_train,
epochs=50,
batch_size=128,
shuffle=True,
validation_data=(x_test, x_test),
callbacks=[TensorBoard(log_dir=&#39;/tmp/autoencoder&#39;)])

我想提取图像的特征。要提取图像的特征，我需要访问编码器的输出。如何编写 Python 代码来提取输入图像的特征？]]></description>
      <guid>https://stats.stackexchange.com/questions/654730/how-to-extract-features-of-images-using-autoencoders</guid>
      <pubDate>Sun, 22 Sep 2024 14:19:25 GMT</pubDate>
    </item>
    <item>
      <title>哪种条件交叉制表解释是合适的？</title>
      <link>https://stats.stackexchange.com/questions/654729/which-conditional-cross-tabulation-interpretation-is-appropriate</link>
      <description><![CDATA[假设是老年人不太可能说外语。
交叉表结果如下：

我的问题是：在下面的解释中，哪一个是正确的，为什么另一个是错误的？
解释 1：接受假设是因为在回答“是”的人中，37.3% 的人年龄在 30 岁以下，18.7% 的人年龄在 30-39 岁之间，17.5% 的人年龄在 40-49 岁之间，11.6% 的人年龄在 50-59 岁之间，只有 15% 的人年龄在 30 岁以上60.
解释 2：接受假设，因为在回答“是”的人中，70.8% 的人年龄在 30 岁以下，39.6% 的人年龄在 30-39 岁之间，42.1% 的人年龄在 40-49 岁之间，27.5% 的人年龄在 50-59 岁之间，19.3% 的人年龄在 60 岁以上。]]></description>
      <guid>https://stats.stackexchange.com/questions/654729/which-conditional-cross-tabulation-interpretation-is-appropriate</guid>
      <pubDate>Sun, 22 Sep 2024 14:13:19 GMT</pubDate>
    </item>
    <item>
      <title>我们可以手动对每个学生进行 t 检验吗？还是我应该在干预之前和之后对所有学生进行 t 检验？</title>
      <link>https://stats.stackexchange.com/questions/654724/can-we-make-a-t-test-manually-to-each-student-or-should-i-take-all-the-students</link>
      <description><![CDATA[我有一个行动研究，我应该测试干预前后学生的成绩，我的研究仅基于 6 名患有注意力缺陷多动障碍的学生。我想做一个 t 检验，看看结果是否显著为正。我有 5 个测试，一个在干预前，三个在干预中，一个在干预后，我该如何进行 t 检验呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/654724/can-we-make-a-t-test-manually-to-each-student-or-should-i-take-all-the-students</guid>
      <pubDate>Sun, 22 Sep 2024 10:45:01 GMT</pubDate>
    </item>
    <item>
      <title>如何解释具有多个变量和单个变量的 GAM？</title>
      <link>https://stats.stackexchange.com/questions/654727/how-to-interpret-gams-with-multiple-vs-single-variables</link>
      <description><![CDATA[因此，我一直在尝试使用 GAM 来观察总体经济损失（由于某个事件）与各种因素之间的关系，包括事件总数、受影响的总人数、基础设施发展水平等。
以下是我迄今为止尝试过的方法：
library(mgcv)

model1 &lt;-gam(total_damages ~ s(total_events) + s(total_affected) + 
s(coastlines) + s(total_gdp, k=1) + s(urban_landarea) + 
s(infrastructure_index), tw(link=&quot;log&quot;))

我使用了 tw(link=&quot;log&quot;)，因为 total_damages 不是正态分布的。我绘制了一个直方图来检查。我还注意到这个变量的方差比它的平均值大得多。但是，如果在这里使用 tweedie 是错误的，请告诉我。
此外，我不太确定是否应该对所有独立变量使用平滑函数。我注意到 total_gdp 与 total_damages 呈线性关系，所以我设置了 k=1。但是，我不太确定对这么多变量使用平滑函数是否会产生任何影响。
我想向您展示我从这个模型中获得的结果。
summary(model1)


我认为 p 值在这种情况下用处不大。我想知道 R-sq.-adj 和“偏差解释”值在这里是否有价值。如果它们在 GAM 中具有重要意义，请告诉我。
我想在此处显示其中一个图表：
plot(model1)


该图显示了独立变量 (infrastructure_index) 和平滑 s(infrastructure_index) 之间的图。该线看起来有点直，但查看系数 (coef(model1)) 告诉我它们经常在负值和正值之间波动。我认为这意味着 infrastructure_index 和 total_damages 之间存在不规则关系？
我尝试对另一个 GAM 进行建模，但这次，我只专注于使用 1 个独立变量“infrastructure_index”。
model2 &lt;- gam(total_damages ~ s(infrastructure_index))

以下是模型摘要：

R-sq-adj 和 Deviance Explained 值下降下降。但情节变得更加清晰，我觉得我对基础设施指数和总损害之间的关系有了更清晰的理解：


具有多个变量的 GAM 模型是否是理解独立变量与总损害之间关系的更好工具？

具有单个变量的 GAM 是否不太有用？为什么这两个图表相差这么大？

我什么时候应该使用具有多个变量而不是单个变量的 GAM？

]]></description>
      <guid>https://stats.stackexchange.com/questions/654727/how-to-interpret-gams-with-multiple-vs-single-variables</guid>
      <pubDate>Sun, 22 Sep 2024 10:23:32 GMT</pubDate>
    </item>
    <item>
      <title>比较 R 中的单变量线性模型</title>
      <link>https://stats.stackexchange.com/questions/654721/comparing-single-variable-linear-model-in-r</link>
      <description><![CDATA[我有一个包含 6 个特征的数据集，并且每次使用一个特征构建简单线性回归。我考虑了调整后的 R 平方值和 p 值来比较并确定这些模型中最佳的简单线性回归模型。
# Model-1
M1X1 &lt;- lm(YHousePriceOfUnitArea~X1TransactionDate, data=rev_data_clean)
summary(M1X1)

M1X2 &lt;- lm(YHousePriceOfUnitArea~X2HouseAge, data=rev_data_clean)
summary(M1X2)

M1X3 &lt;- lm(YHousePriceOfUnitArea~X3distanceToTheNearestMRTstation, data=rev_data_clean)
summary(M1X3)

M1X4 &lt;- lm(YHousePriceOfUnitArea~X4NumberOfConvenienceStores, data=rev_data_clean)
summary(M1X4)

M1X5 &lt;- lm(YHousePriceOfUnitArea~X5Latitude, data=rev_data_clean)
summary(M1X5)

M1X6 &lt;- lm(YHousePriceOfUnitArea~X6Longitude, data=rev_data_clean)
summary(M1X6)

# 比较模型 1 的最佳版本
summary(M1X1)$adj.r.squared
summary(M1X2)$adj.r.squared
summary(M1X3)$adj.r.squared
summary(M1X4)$adj.r.squared
summary(M1X5)$adj.r.squared
summary(M1X6)$adj.r.squared

# 版本的 p 值model-1
summary(M1X1)$coefficients[2, 4]
summary(M1X2)$coefficients[2, 4]
summary(M1X3)$coefficients[2, 4]
summary(M1X4)$coefficients[2, 4]
summary(M1X5)$coefficients[2, 4]
summary(M1X6)$coefficients[2, 4]

控制台输出：
# 比较 model-1 的最佳版本
&gt; summary(M1X1)$adj.r.squared
[1] 0.005246001
&gt; summary(M1X2)$adj.r.squared
[1] 0.04201891
&gt; summary(M1X3)$adj.r.squared
[1] 0.4524284
&gt; summary(M1X4)$adj.r.squared
[1] 0.3244108
&gt; summary(M1X5)$adj.r.squared
[1] 0.2967482
&gt; summary(M1X6)$adj.r.squared
[1] 0.2720662
&gt; 
&gt; # 模型 1 版本的 p 值
&gt; summary(M1X1)$coefficients[2, 4]
[1] 0.07537113
&gt; summary(M1X2)$coefficients[2, 4]
[1] 1.560426e-05
&gt; summary(M1X3)$coefficients[2, 4]
[1] 4.639825e-56
&gt; summary(M1X4)$coefficients[2, 4]
[1] 3.413483e-37
&gt; summary(M1X5)$coefficients[2, 4]
[1] 1.387761e-33
&gt; summary(M1X6)$coefficients[2, 4]
[1] 1.765191e-30

我的比较：如果调整后的 R 平方值较大且 p 值较小，则该模型较好。在这种情况下，具有较高调整 R 平方值和较低 p 值的 M1X3 模型似乎是最好的。
我想确认我的比较是对还是错。]]></description>
      <guid>https://stats.stackexchange.com/questions/654721/comparing-single-variable-linear-model-in-r</guid>
      <pubDate>Sun, 22 Sep 2024 04:37:21 GMT</pubDate>
    </item>
    <item>
      <title>离散随机变量的 CDF 分段常数？</title>
      <link>https://stats.stackexchange.com/questions/654695/cdf-of-a-discrete-random-variable-piecewise-constant</link>
      <description><![CDATA[在我的脚本中，它说：

给定$X$是一个离散随机变量，$\Bbb P(X\in D)=1,D=\{a_1,a_2,\ldots\},p_i:=\Bbb P_X(\{a_i\})&gt;0,\forall i\ge1,$我们有$F_X(x)=\sum\limits_{a_i\le x}p_i,$这意味着离散随机变量的CDF是分段常数。

我的想法
假设$X:\Omega\to\Bbb R$是一个离散随机变量，其中$\Bbb P_X(\{q_i\})=\frac1{2^i}&gt;0,$，其中$\{q_i\}_{i\in\Bbb N}$是$\Bbb Q.$的枚举，因为$\Bbb Q$是稠密的，所以对于每两个$x_1,x_2\in\Bbb R,x_1&lt;x_2,$，存在某个$q_j\in(x_1,x_2)$，意味着$q_j\in(x_1,x_2)$ class=&quot;math-container&quot;&gt;$F_X(x_1)&lt;F(x_2).$ 因此，这似乎与 $F_X$ 是分段常数的说法相矛盾，这让我怀疑如果该说法成立，我的随机变量 $X$ 是否存在。
问题：任何离散随机变量的 CDF 确实是分段常数吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654695/cdf-of-a-discrete-random-variable-piecewise-constant</guid>
      <pubDate>Sat, 21 Sep 2024 13:03:38 GMT</pubDate>
    </item>
    <item>
      <title>基于汇总数据的平均差异</title>
      <link>https://stats.stackexchange.com/questions/654693/mean-difference-based-on-summary-data</link>
      <description><![CDATA[我遇到了以下问题：我想评估 5 个平衡组的平均差异，但我只有可用的汇总数据（平均值、标准差和样本大小），以及汇总数据基于正态分布数据的信息。
我愿意听取有关如何进行的建议。
这是一些示例数据（编辑：更新的数据）
data &lt;- data.frame(
group = c(&quot;probe_a&quot;, &quot;probe_b&quot;, &quot;probe_c&quot;, &quot;probe_d&quot;, &quot;control&quot;),
n = c(10, 10, 10, 10, 10), # 每组样本大小
means = c(57.6, 95.9, 102.9, 69.6, 73.8), # 组平均值
sd = c(4.2, 4.0, 2.7, 7.6, 3.6) # 每组标准差
)

我的方法包括使用 Welch 方差分析 来解释方差不等的情况（如果 Hartley 的 Fmax 表明存在这种情况），然后进行事后 Games-Howell 检验（我需要对几个数据框进行此检验，其中一些数据框的方差不等，但我不想在传统方差分析和 Welch 方差分析之间切换，因此我坚持使用更为稳健的方法）。由于我无法直接检查残差，因此我根据汇总数据和正态性假设对残差进行了模拟，并使用引导来评估是否满足正态分布残差和同方差性的假设，使用Shapiro-Wilk 和 Levene 检验。在 5% 的置信水平下，蒙特卡洛 p 值未超过此阈值，这意味着我拒绝了正态性和同方差性的零假设。这表明残差违反了 Welch 方差分析的假设。由于我的猜测不支持这些假设，我得出结论，Welch 方差分析的 p 值具有探索性，而事后结果是精确的。
编辑：澄清了步骤

检验各组间方差不等：

fmax &lt;- max(sd^2)/min(sd^2)
df &lt;- 5
k &lt;- 9

Hartley 的 Fmax 为 7.9，小于表中的临界 Fmax 值（p &lt; 0.05），表明各组间的方差不同

Welch 的方差分析

准确（Welch）方差分析结果的假设是残差呈正态分布且方差同。但是，由于无法访问基础数据，我无法直接评估残差，因此我模拟了基础数据。

使用蒙特卡罗模拟测试残差

我模拟了 5 个与我的数据汇总统计数据相匹配的正态分布组。使用这些模拟数据，我计算了残差并使用 Shapiro-Wilk 和 Levene 检验对其进行了评估。蒙特卡洛 p 值被确定为这些检验中 p 值不超过我选择的显著性水平的比例
# 相关代码片段
set.seed(578)
for (i in 1:n_sim) {
# 使用 rnorm() 为每个组生成模拟数据
simulated_data_list &lt;- lapply(1:length(means), function(j) {
stats::rnorm(n = n[j], mean = means[j], sd = sd[j])
})

# 通过减去组均值来计算残差
means_of_groups &lt;- sapply(simulated_data_list, mean)
residuals_list &lt;- mapply(function(data, mean) data - mean,
simulated_data_list, means_of_groups,
SIMPLIFY = FALSE)

# 执行正态性和同方差检验
sw_pval[i] &lt;- shapiro_wilk_test(residuals_list)
l_pval[i] &lt;- 同方差检验(residuals_list)
}
normality_prop &lt;- mean(sw_pval &lt; 0.05)
homoscedasticity_prop &lt;- mean(l_pval &lt; 0.05)

Shapiro-Wilk 检验 p 值 &lt; 0.05（表明残差非正态分布）的模拟比例：
0.29（n_sim = 5000）
Leven-Test p 值 &lt; 的模拟比例0.05（表明非同方差残差）：
0.49（n_sim = 5000）
我的问题：

这是一种有效的方法吗？
是否有更稳健的方法来获得精确的 p 值，因为蒙特卡罗模拟表明（Welch）方差分析假设被违反（例如通过模拟基础数据进行置换检验）
]]></description>
      <guid>https://stats.stackexchange.com/questions/654693/mean-difference-based-on-summary-data</guid>
      <pubDate>Sat, 21 Sep 2024 11:32:47 GMT</pubDate>
    </item>
    <item>
      <title>构建具有不同和未知方差的 $\mu_X-\mu_Y$ 的置信区间</title>
      <link>https://stats.stackexchange.com/questions/654688/construct-confidence-interval-for-mu-x-mu-y-with-different-and-unknown-varia</link>
      <description><![CDATA[我正在自学统计学课程，以前的考试试卷中也出现过这个问题（没有解决方案）。
问题：
给定$X_1,\ldots,X_n$是从$N(\mu_X,\sigma_X^2)$中抽取的独立随机样本，$Y_1,\ldots,Y_m$是从$N(\mu_Y,\sigma_Y^2)$中抽取的独立随机样本，假设这两个随机样本是独立的。同时给定$$U=\frac{\overline{X}-\overline{Y}-(\mu_X-\mu_Y)}{\sqrt{\frac{\sigma_X^2}{n}+\frac{\sigma_Y^2}{m}}}\sim N(0,1)$$和$$V_1=\frac{n S_X^2}{\sigma_X^2}\sim\chi_{n-1}^2,V_2=\frac{mS_Y^2}{\sigma_Y^2}\sim \chi_{m-1}^2,V=V_1+V_2$$为$90\%$找到一个置信区间class=&quot;math-container&quot;&gt;$\mu_X-\mu_Y$ 假设 $U$ 和 $V$ 是独立的，$\frac{\sigma_X^2}{\sigma_Y^2}=d$ 其中 $d$ 为某个常数。
我的尝试：
如果 $\sigma_X^2=\sigma_Y^2$，则可以轻松构造区间，因此考虑 $Z_i=\frac{X_i}{\sqrt{d}}\sim N(\frac{\mu_X}{\sqrt{d}},\sigma_Y^2)$。然后我得到了 $$U=\frac{\sqrt{d}\cdot\overline{Z}-\overline{Y}-(\mu_X-\mu_Y)}{\sqrt{\frac{d\cdot\sigma_Y^2}{n}+\frac{\sigma_Y^2}{m}}}\sim N(0,1)$$$$V_1=\frac{nS_Z^2}{\sigma_Y^2}\sim\chi^2_{n-1}$$但是我被卡住了，因为我想不出任何办法摆脱 $\overline{Z}$ 和 分母为$d$。
我的最后一个问题：由于我是 Cross Validated 的新手，有没有可以帮助我搜索问题的网站？（例如 Math Stack Exchange 的 Approach0）。]]></description>
      <guid>https://stats.stackexchange.com/questions/654688/construct-confidence-interval-for-mu-x-mu-y-with-different-and-unknown-varia</guid>
      <pubDate>Sat, 21 Sep 2024 09:35:07 GMT</pubDate>
    </item>
    <item>
      <title>当使用 hayes 过程宏（用于 R）测试并行中介模型时，如何纠正多重测试？</title>
      <link>https://stats.stackexchange.com/questions/654651/how-can-i-correct-for-multiple-testing-when-testing-a-parallel-mediation-model-u</link>
      <description><![CDATA[我知道有多种方法可以校正多重测试（例如 holm bonferroni、bonferroni 方法），但是当我使用 Hayes PROCESS 宏测试并行中介模型时，我不确定如何执行此操作。我是否需要在 PROCESS 之外单独重建回归模型，如果需要，您知道我该怎么做吗？并行中介模型包括 5 个预测因子（一个主要 IV，4 个并行中介因子）和结果变量。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654651/how-can-i-correct-for-multiple-testing-when-testing-a-parallel-mediation-model-u</guid>
      <pubDate>Fri, 20 Sep 2024 13:23:50 GMT</pubDate>
    </item>
    <item>
      <title>当每个数据点都带来一个置信区间时，如何在两个或多个组之间进行检验？</title>
      <link>https://stats.stackexchange.com/questions/654615/how-to-run-a-test-between-two-or-more-groups-when-each-data-point-brings-a-confi</link>
      <description><![CDATA[我最近开始研究一个数据集，但作为一名应届毕业生，我的经验有限，这阻碍了我取得进展。在执行了项目所需的稀疏化之后，我现在有一个包含 24 个物种多样性指数的数据框，每个指数都伴随着由随机稀疏化过程生成的置信区间。
这 24 个多样性指数属于 2 个不同的非独立组，我需要进行比较。如果没有置信区间，我只能使用均值，我会使用配对 t 检验。
为了解释通过稀疏化获得的置信区间，我尝试使用从区间得出的方差执行加权 t 检验。但是，我对我的方法没有信心，也找不到任何支持这种方法的在线文章。
这是我的数据框：
size1 &lt;- c(32.67256,30.59280,33.56214,30.15552,29.02073,24.92427,34.79967,34.26559,29.33457,25.75716,27.91638,33.87884)
size2 &lt;-c(34.18847,30.94369,37.38462,22.96785,27.98805,31.39834,30.26401,33.59788,36.19856,31.19667,21.27245,28.87137)
尺寸 &lt;-c(尺寸1，尺寸2)
尺寸1CI05 &lt;-c(29.50177,26.23491,29.60487,25.94388,24.48941,21.78924,29.24082,28.09738,25.20056,21.21051,24.40705,30.08490)
size2CI05 &lt;-c(29.51654,23.75201,31.29203,17.60071,21.92296,26.38236,23.69115,26.15880,26.44932,26.72620,17.48761,23.76434)
sizeCI05 &lt;-c(size1CI05,size2CI05)
size1CI95 &lt;-c(35.84336,34.95070,37.51941,34.36716,33.55205,28.05929,40.35851,40.43380,33.46857,30.30381,31.42571,37.67278) 
size2CI95 &lt;-c(38.86039,38.13538,43.47722,28.33500,34.05315,36.41432,36.83687,41.03696,45.94780,35.66713,25.05730,33.97840)
sizeCI95 &lt;-c(size1CI95,size2CI95)
group &lt;- c(c(rep(&quot;1&quot;, 12), rep(&quot;2&quot;, 12))
df &lt;- data.frame(size, sizeCI05, sizeCI95, group)

我还按照要求添加了 dput 输出：
df &lt;-结构（列表（大小 = c（32.67256, 30.5928, 33.56214, 30.15552, 
29.02073, 24.92427, 34.79967, 34.26559, 29.33457, 25.75716, 27.91638, 
33.87884, 34.18847, 30.94369, 37.38462, 22.96785, 27.98805, 31.39834, 
30.26401, 33.59788, 36.19856, 31.19667, 21.27245, 28.87137), 
size05CI = c(29.5017662019491, 26.2349058385758, 29.6048735822698, 
25.9438818737996, 24.4894140422372, 21.7892435074709, 29.2408246478003, 
28.097376313181, 25.2005633026381, 21.2105115402011, 24.4070457401779, 
30.0849045894848, 29.5165407340379, 23.7520071901393, 31.2920265619889, 
17.6007091843407, 21.9229562124319, 26.3823600157115, 23.6911524798744, 
26.158796800294, 26.4493176960902, 26.7262037524753, 17.4876088906701, 
23.7643440166671), size95CI = c(35.8433590913617, 34.9506991382152、37.5194133001315、34.3671592174968、33.5520534941053、28.0592932279925、40.3585126169722、40.43380327644 11、33.4685713521404、30.303809204322、31.4257104335821、37.6727751129716、38.8603902871733、38.1353758799793、 
43.4772171945701, 28.3349990423006, 34.0531465846994, 36.4143170389483, 
36.8368654619253, 41.0369594182707, 45.9478039221974, 35.6671344715295, 
25.0572999101401, 33.9783955274194), group = c(&quot;1&quot;, &quot;1&quot;, 
&quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;2&quot;, &quot;2&quot;, 
&quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;)), class = &quot;data.frame&quot;, row.names = c(NA, 
-24L))

这是我尝试做的：
install.packages(&quot;weights&quot;, dependency=TRUE)
library(weights)
SE1 &lt;- (size1CI95-size1CI05)/3.919928
SE2 &lt;- (size2CI95-size2CI05)/3.919928
sizepaired &lt;- size1-size2
combSE &lt;- sqrt(SE1^2+SE2^2)
weights &lt;- 1/combSE^2
wtd.t.test(x=sizepaired, y=0, weight=weights)

我的方法是使用加权测试来考虑由于测试中的稀疏性而产生的置信区间（即标准偏差），其中权重来自标准偏差。但是，我不确定这是否是一种有效的方法，而且我还没有找到任何涉及此方法的科学文章。我的同事有些怀疑，不愿意使用“实验性”方法。
此外，我目前正在使用参数检验，但在我的数据中（我没有在这里包括），有些数据不遵循正态分布。因此，我应该考虑如何进行加权配对非参数检验]]></description>
      <guid>https://stats.stackexchange.com/questions/654615/how-to-run-a-test-between-two-or-more-groups-when-each-data-point-brings-a-confi</guid>
      <pubDate>Thu, 19 Sep 2024 16:36:06 GMT</pubDate>
    </item>
    </channel>
</rss>