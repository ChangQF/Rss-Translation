<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 15 Oct 2024 21:26:24 GMT</lastBuildDate>
    <item>
      <title>平滑阈值损失函数</title>
      <link>https://stats.stackexchange.com/questions/655825/smooth-thresholding-a-loss-function</link>
      <description><![CDATA[假设我们有一个具有固定“阈值”$\delta &gt; 0$的目标函数，例如
$$ L(y_i, \hat{y}_i) = \begin{cases} (y_i - \hat{y}_i)^2 &amp; if \ |\epsilon_i|:= |y_i - \hat{y}_i |\leq \delta \\ \delta^2 &amp; if \ |\epsilon_i| &gt; \delta \end{cases} $$
这里的直觉是，如果预测偏离很远（超过$\delta$），那么这是一个糟糕的估计，我们对糟糕的估计和极糟糕的估计无动于衷。 （这不是一个很好的例子，但让我们假设它是这样的。一个示例应用可能是，如果我们评估来自不同模型的预测并分配一个分数。）
当我们使用基于梯度的方法进行优化时，我们通常想要一个良好的平滑函数，因此我们可能会对上述示例使用可微分代理，例如标准 MSE。否则，如果 $|\epsilon_i| &gt; \delta$，则梯度为零，这可能会妨碍训练。然而，这样做的缺点是，当我们不关心非常差的估计时，我们会惩罚它们。

在上面的示例图中，$y_i = 2, \delta=2$。真正的目标在右侧，带有阈值，平滑代理在左侧。
当$|\epsilon_i|时，创建“平滑阈值”的更好方法是什么？这样$L(y_i, \hat{y}_i)$近似为常数。 &gt; \delta$，但仍然依赖于$\epsilon_i$，使得它是可微的并且具有非零梯度？]]></description>
      <guid>https://stats.stackexchange.com/questions/655825/smooth-thresholding-a-loss-function</guid>
      <pubDate>Tue, 15 Oct 2024 19:43:49 GMT</pubDate>
    </item>
    <item>
      <title>独立同分布随机变量乘积矛盾[重复]</title>
      <link>https://stats.stackexchange.com/questions/655823/product-of-iid-random-variables-contradiction</link>
      <description><![CDATA[我正在研究一些计量经济学问题，我的教授使用了 iid 随机变量的乘积是 iid 的结果，但我看到一些帖子，情况可能并非总是如此。
我的教授：考虑线性模型：$y = \textbf{x}&#39;\boldsymbol{\beta} + e, y \in \mathbb{R}, \textbf{x} \in \mathbb{R}^n, \textbf{z} \in \mathbb{R}^n$，其中$\{y_i, \textbf{x}_i, \textbf{z}_i\}$ 是 iid。因此，乘积 $\textbf{z}_i \textbf{x}_i, \textbf{z}_i y_i$ 是 iid。这是因为我们在某种意义上“将它们画在一起”吗？（即括号周围的 iid）。
这里有什么区别？每个结果在什么情况下适用或具有误导性？]]></description>
      <guid>https://stats.stackexchange.com/questions/655823/product-of-iid-random-variables-contradiction</guid>
      <pubDate>Tue, 15 Oct 2024 18:41:08 GMT</pubDate>
    </item>
    <item>
      <title>$p(1-p)$ 的伯努利工厂</title>
      <link>https://stats.stackexchange.com/questions/655820/bernoulli-factory-for-p1-p</link>
      <description><![CDATA[考虑一个伯努利变量 $X_i$ 的 i.i.d. 序列，其参数 $p \in (0,1)$ 为 未知。也就是说，$X_i$ 以 $p$ 的概率取值 $1$，而 $0$ 以 $1-p$ 的概率取值。使用这些变量中可能随机的 $n$ 个变量作为输入，我想要生成一个伯努利变量 $Y$，其参数为 $p(1-p)$。请注意，这是伯努利工厂的一个特例。我的目标是使 $\mathrm E[n]$ 尽可能小。

一种显而易见的方法是观察 $n=2$ 个输入并生成输出 $Y$ 作为 $X_1(1-X_2)$。

这可以通过“短路”来改进乘积：（i）如果 $X_1 = 0$，则无需观察 $X_2$（结果无论如何都是 $0$）。这给出 $\mathrm E[n] = 1+p$。或者，(ii) 如果首先观察到 $X_2$，并且仅在需要时观察到 $X_1$，则 $\mathrm E[n] = 2-p$。

如果以相等的概率选择 2.(i) 和 2.(ii) 中的一种，则 $\mathrm E[n] = 3/2$ 独立于 $p$。

如果要重复该过程以产生许多独立的输出，则根据观察到的输入，可以很好地猜测 $p \leq 1/2$ 或不是，并据此分别选择 2.(i) 或 2.(ii)。从长远来看，这将使 $\mathrm E[n] \approx 1+\min\{p, 1-p\}$。


我不知道如何进一步减少 $\mathrm E[n]$。
另一方面，无论是从熵的考虑还是从 Cramér-Rao 界限（应用于 $Y$ 作为 $p(1-p)$ 的无偏估计量），似乎有可能实现更小的 $\mathrm E[n]$，甚至小于 $1$（但随后我不确定这些界限是否考虑到了$p$是未知的事实。
是否有任何方法可以实现比我描述的更小的$\mathrm E[n]$？]]></description>
      <guid>https://stats.stackexchange.com/questions/655820/bernoulli-factory-for-p1-p</guid>
      <pubDate>Tue, 15 Oct 2024 17:55:59 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归、自然对数变换的连续 IV、相互作用和 RCS 以及绘制 OR 作为连续 IV 的函数</title>
      <link>https://stats.stackexchange.com/questions/655819/logistic-regression-natural-log-transformed-continuous-iv-interaction-and-rcs</link>
      <description><![CDATA[我正在对逻辑回归模型中的二元结果进行差异暴露效应分析。
我的模型参数包括：
 二元结果 (y)
主要二元暴露 (x)
另一个连续独立变量 (a)
二元协变量 (b)
二元协变量 (c)

协变量“a”是我感兴趣的标记，我想将其作为二元暴露的效应修正器进行评估。
最后补充一些信息：我不确定交互的真实形式，因此我使用受限三次样条函数和效应修正器，经过一番考虑后使用了 4 个结。
如果在 R 中编码，我的模型是：
 mod1=glm(y~x*rcs(a,4)+b+c,data=myDataset, family=binomial(link=&quot;logit&quot;))

然后我使用块检验来测试我的三个交互和样条项之间的整体交互。
我的最后练习也是通过对比包，估计差异治疗效果、模型后拟合、在合理的生物标志物“a”值范围内，并将该效果绘制为生物标志物“a”的函数。
生物标志物“a”值的范围
 a_val=seq(1,1000, length=200)

所以，像这样：
 rms::contrast(list(x=1,a=a_val,b=1,c=1), list(x=0,a=a_val,b=1,c=1))

然后我在下一步中绘制 x 的效果（指数化等以获得 OR（95% CI））对所有 a_val 值的影响（未显示，但显示了非常漂亮、平滑的曲线）。
我还在调整后的模型中检查了标记“a”的线性，在成分+残差图中没有交互项，并进行了后检查，并进行了一些额外的考虑，决定对我的上述模型中的标记“a”进行自然对数变换，以更好地处理右尾中的几个极值。我重新拟合，与上面唯一的不同是标记“a”经过了自然对数变换，然后重新绘制。
我有一个可能非常简单的问题是：当我使用与上面完全相同的模型重新估计对比度时，使用自然对数变换的协变量“a”，而不是自然的“a”：
 rms::contrast(list(x=1,a=a_val,b=1,c=1),list(x=0,a=a_val,b=1,c=1)) 

***我的 a_val 序列也应该采用自然对数尺度吗？换句话说，当我估计曝光对比度时，a_val 序列是否也会进行自然对数变换？我认为也可以在自然尺度中使用 a_val，然后在估计我的暴露效应（指数化我的对数 OR）后，我可以使用轴上的自然对数尺度进行绘图（一个用于 OR（95% CI），一个用于 a_val 的范围）。
但是，有人建议，由于我的第二个模型在自然对数空间中使用了协变量“a”，因此我还应该对对比语句中 a_val 的值进行自然对数变换，然后重新绘图。但是，当我采用他们的建议时，绘图对我来说并没有真正意义，我认为我最初的直觉是正确的。但是，我似乎无法根据他们的建议定量合理化我的方法，任何帮助都会很棒。***
再次感谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/655819/logistic-regression-natural-log-transformed-continuous-iv-interaction-and-rcs</guid>
      <pubDate>Tue, 15 Oct 2024 17:54:01 GMT</pubDate>
    </item>
    <item>
      <title>正在做一个 VARMA 模型，但遇到了 ECCM 和不可逆矩阵的一些问题</title>
      <link>https://stats.stackexchange.com/questions/655816/doing-a-varma-model-but-ran-into-some-issues-with-eccm-and-non-invertible-matric</link>
      <description><![CDATA[我使用 MTS 包，因为我以 Tsay (2014) 为基础。我试图用墨西哥失业率和 CPI 拟合一个模型。执行 eccm 后我得到：




0
1
2
3
4
5
6




0
0.0000
0.0052
0.0560
0.0616
0.0276
0.0 129
0.1035


1
0.0000
0.0000
0.5188
0.0659
0.0003
0.0022
0.6971


2
0.0003
0.0261
0.0001
0.0005
0.0000
0.0101
0.2774


3
0.0015
0.0408
0.0448
0.0010
0.0022
0.0161
0.1256


4
0.0037
0.0160
0 .1507
0.7338
0.0768
0.4615
0.3397


5
0.0650
0.2512
0.3963
0.8729
0.8839
0.6567
0.9994



所以我认为 VARMA(1,2)、VARMA(2,1) 是不错的选择。问题是 R 告诉我，当他们尝试解决矩阵时，他们会得到 NaN。但如果我执行 VARMA(2,0)，则不会出现任何问题。
我的选择正确吗？如果正确，我该怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/655816/doing-a-varma-model-but-ran-into-some-issues-with-eccm-and-non-invertible-matric</guid>
      <pubDate>Tue, 15 Oct 2024 17:02:39 GMT</pubDate>
    </item>
    <item>
      <title>根据具有可能模式的历史数据预测下一个事件的时间戳？</title>
      <link>https://stats.stackexchange.com/questions/655815/predicting-the-next-events-timestamp-based-on-historical-data-with-possible-pat</link>
      <description><![CDATA[我正在做一个个人项目，目的是根据一系列历史时间戳预测下一个事件的时间。我拥有的数据集包含大约 40 万个过去事件的时间戳。
在分析数据时，我注意到事件之间的时间似乎在一天中的不同时段有所变化（例如，夜间时间间隔会增加，因为人们可能在睡觉），也可能在周末（人们可能在度假）有所变化。这些模式可能对建模有用，尽管我并不完全确定如何有效地将它们结合起来。
为了提供更多背景信息，我附上了两个图表：

第一个图表显示连续事件之间的时间差异：


第二个图表显示时间戳随时间的变化情况：



我的主要目标是建立一个模型，根据最近的时间戳（或者可能是之前的几个时间戳）预测下一个事件的时间戳。
我可以在以下情况下使用您的指导：

对于这种下一个事件时间预测，传统的统计方法是什么（例如时间序列模型）？是否有一种首选方法来处理随时间变化的模式，例如每日或每周的季节性？
是否有机器学习方法可以很好地发挥作用？我想知道训练神经网络（例如 RNN、LSTM）是否有用，尤其是当我给它输入最新的时间戳和最近的时间差时。
您会建议使用哪些技术来检测时间差中的模式并提高预测准确性，无论是经典方法还是机器学习？

我确信以前已经解决过类似的问题，但我不知道从哪里开始。我非常感谢任何建议，包括关于特定模型、架构甚至我可以查看的现有实验的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/655815/predicting-the-next-events-timestamp-based-on-historical-data-with-possible-pat</guid>
      <pubDate>Tue, 15 Oct 2024 16:34:20 GMT</pubDate>
    </item>
    <item>
      <title>对于 X 连续随机变量和 $Y=X^{-1}$，如何推导出 $(X,Y)$ 的 Copula？</title>
      <link>https://stats.stackexchange.com/questions/655808/how-to-derive-the-copula-of-x-y-for-x-continuous-random-variable-and-y-x</link>
      <description><![CDATA[我在考试中没有解决它们，我仍然无法弄清楚如何正确解决它。

对于$X\sim U(-1,1)$和$Y=\frac{1}{X}$，推导出$(X,Y)$的Copula，以及它的唯一性是什么。
对于$X\sim N(0,1)$和$Y=\frac{1}{X}$，推导出$(X,Y)$的Copula。

在这两种情况下，我们的$X$ 是连续的，可以取 $0$ 作为其值，而 Y 不连续似乎是一个问题。不能直接使用公式
$$C(u_1,\dots,u_d)=F(F_1^{-1}(u_1),\dots,F_d^{-1}(u_d)) $$
其中 $F$ 是 $d$ 维的。具有连续边际 c.d.f.s $F_i$ 和 C 的分布函数由该公式唯一确定。
但是我不知道如何处理 $X$ 取值 $0$ 且 $Y=\frac{1}{0}$ 的情况。
我想知道我们是否可以构造函数 $f(x)=x$ 非递减和 $g(x)=\frac{1}{x}$ 非递增，使得 $(X,Y)=(f(X),g(X))$ 在分布中，然后使用反单调性 Copula，但没有奏效。
有人能提示一下或者指出我理解错误的地方吗？
更新：
对于第一个，我得到了 $C(u_1,u_2)=u_1+u_2-1$，但我不确定它是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/655808/how-to-derive-the-copula-of-x-y-for-x-continuous-random-variable-and-y-x</guid>
      <pubDate>Tue, 15 Oct 2024 14:20:38 GMT</pubDate>
    </item>
    <item>
      <title>如果分类变量保留在 R 中的最终模型中，那么为什么事后分析表明水平没有差异？</title>
      <link>https://stats.stackexchange.com/questions/655810/if-the-categorical-variable-is-retained-in-my-final-model-in-r-then-why-does-th</link>
      <description><![CDATA[我正在使用 R 中的 anova() 函数进行模型选择，并且我的分类变量在我的最终模型中得到了保留，但是当我使用 emmeans() 函数进行事后分析时，它告诉我水平没有差异。这是什么意思？
我使用 R 软件，我正在研究一种鱼的身体状况在三种河流中的变化：保护性、轻微城市化和高度城市化。每个类别都有一个重复，这意味着我有 2 条保护性河流、2 条轻微城市化河流和 2 条高度城市化河流，这意味着“河流”是一个随机因素，“城市化类别”是我的固定因素和具有 3 个级别的预测变量。在使用 anova() 函数在 R 中执行模型选择时，分类变量“类别”得到保留：
`#它是一个线性混合模型，因为条件呈正态分布
&gt; lmm.1 &lt;- lmer(条件 ~ 城市化类别 + (1|河流), 数据 = 鱼) 
&gt; lmm.null &lt;- lmer(条件 ~ 1 + (1|河流), 数据 = 鱼) 
&gt; anova(lmm.null, lmm.1)
使用 ML（而不是 REML）重新拟合模型
数据：鱼
模型：
lmm.null：条件 ~ 1 + (1 | 河流)
lmm.1：条件 ~ 城市化类别 + (1 | 河流)
npar AIC BIC logLik 偏差 Chisq Df Pr(&gt;Chisq)
lmm.null 3 -214.42 -205.37 110.21 -220.42
lmm.1 5 -219.80 -204.71 114.90 -229.80 9.3806 2 0.009184 **
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1`

`
我的 p 值为 0.009184，这意味着城市化类别是一个重要的预测因素，我预计分类变量中至少有一个级别与其他级别不同。但是，在尝试进行事后分析时，我调用了 emmeans() 函数，R 表示所有级别均无差异，因为 p 值均高于 0.05：
`&gt; emmeans(lmm.1，成对 ~ category.of.urbanization)
已注册的 S3 方法被“broom”覆盖：
方法来自 
tidy.glht jtools
tidy.summary.glht jtools
$emmeans
category.of.urbanization emmean SE df lower.CL upper.CL
保留 -0.1281 0.0441 3.42 -0.2592 0.00304
略微城市化 0.0316 0.0341 2.20 -0.1030 0.16632
非常城市化 0.0425 0.0350 2.43 -0.0852 0.17032

自由度方法：kenward-roger
使用的置信度：0.95

$contrasts
对比估计 SE df t.ratio p.value
保留 - 略带城市化 -0.1597 0.0558 2.83 -2.863 0.1324
保留 - 非常城市化 -0.1706 0.0563 2.95 -3.028 0.1123
略带城市化 - 非常城市化 -0.0109 0.0489 2.32 -0.223 0.9733

自由度方法：kenward-roger
P 值调整：用于比较 3 个估计值的 Tukey 方法`

请问，这是什么意思？预测变量如何显著，但水平没有差异？我有 151 条鱼，所以我的数据和观察值数量不是很低。如果我犯了拼写错误，我很抱歉，英语不是我的母语。]]></description>
      <guid>https://stats.stackexchange.com/questions/655810/if-the-categorical-variable-is-retained-in-my-final-model-in-r-then-why-does-th</guid>
      <pubDate>Tue, 15 Oct 2024 13:48:27 GMT</pubDate>
    </item>
    <item>
      <title>如何使用去偏套索处理不平衡数据的混合效应模型中的单一观测？</title>
      <link>https://stats.stackexchange.com/questions/655806/how-to-handle-single-observations-in-mixed-effects-modeling-with-debiased-lasso</link>
      <description><![CDATA[我有一个从数百名具有不同临床状况的人那里收集的样本数据集。该数据集非常不平衡。例如，样本数量因受试者而异。整个数据集的约 20% 由单个样本组成。5% 由 2 个样本组成，其余由 3 到 15 个样本组成。还有与这些样本相对应的微生物组数据。
我对研究微生物组的中介效应很感兴趣。
由于微生物组数据是高维的，我想使用套索正则化技术来处理多重共线性。我计划使用去偏套索来消除套索估计中的偏差。我也有来自个人的多个观察结果，因此我将使用混合效应模型，将个人的 ID 作为随机效应。
我的问题是：由于我将在中介分析中使用模型的结果，我应该如何处理来自个人的单个观察结果，以便它们继续对整体模型做出贡献？]]></description>
      <guid>https://stats.stackexchange.com/questions/655806/how-to-handle-single-observations-in-mixed-effects-modeling-with-debiased-lasso</guid>
      <pubDate>Tue, 15 Oct 2024 13:35:20 GMT</pubDate>
    </item>
    <item>
      <title>正态分布中的$ E(M(\sum{X_i)})$ 是什么？$M$ 是中位数</title>
      <link>https://stats.stackexchange.com/questions/655794/what-is-em-sumx-i-in-normal-distribution-m-is-median</link>
      <description><![CDATA[如果 $X_{1},\ldots,X_{n}$ 是标准正态分布的随机样本，并且 $M$ 是该样本的中位数。$E(M(\sum_{i=1}^{n}X_{i}))$ 是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/655794/what-is-em-sumx-i-in-normal-distribution-m-is-median</guid>
      <pubDate>Tue, 15 Oct 2024 09:25:52 GMT</pubDate>
    </item>
    <item>
      <title>A/B 资源建议</title>
      <link>https://stats.stackexchange.com/questions/655785/a-b-resources-suggestions</link>
      <description><![CDATA[我正在尝试更深入地了解 A/B 测试的统计知识。我对基础知识有一个很好的了解，但是，我很难找到合适的资源来讨论所有的数学技术细节并正确证明公式和方法。我一直在 YouTube 视频和推荐的行业书籍之间寻找，但没有一个能提供我想要的深度，有些甚至在细节上给出了不同或矛盾的信息。
我想知道是否有人可以推荐一些可靠的免费资源，这些资源可以全面深入地讨论 A/B 测试的统计知识，或者是否有人愿意对这个主题进行全面分析。如果有人对我如何更好地学习这些材料有任何建议，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655785/a-b-resources-suggestions</guid>
      <pubDate>Tue, 15 Oct 2024 02:44:58 GMT</pubDate>
    </item>
    <item>
      <title>应如何指定双因子 SEM，其中一个因子只有一个项目？</title>
      <link>https://stats.stackexchange.com/questions/655767/how-should-you-specify-a-bifactor-sem-where-one-factor-only-has-one-item</link>
      <description><![CDATA[我正在尝试使用 lavaan 包在 R 中重新指定 SEM，以改善模型拟合度。在检查标准化残差后，我注意到项目 injnorm2 以连词形式制定（即使用 would），而其他用于范数因子的项目则不是。我怀疑这可以解释一些残差，所以我决定创建一个 con 因子，并让 injnorm2 加载到 norm 和 con 上。为了确保模型仍然与单个项目因子相关联，我使用公式残差方差 = (1 - 可靠性)*项目方差和来自先前研究的 injnorm2 可靠性指定了 injnorm2 的残差方差。
代码如下所示：
tpb_cfa_re &lt;- &#39;att =~itude1 +itude2 + Attitude
norm =~ injnorm1 + injnorm2 + injnorm3
pbcon =~ pbc2 + pbc3
redint =~ intent1 + intent2 + intent3

con =~ injnorm2
con ~~ 0*norm
injnorm2 ~~ 0.259*injnorm2
&#39;
fit_tbp_cfa_re &lt;- cfa(model = tpb_cfa_re,
data = Indikatoren,
effect.coding = &quot;loadings&quot;, # Coding Effects Method Constraints
estimator = &quot;MLR&quot;,
missing &quot; &quot;FIML&quot;)

我想知道这种方法是否合适，因为我为 injnorm2 指定的方差取决于此项目在先前研究中对norm的可靠性。然而，injnorm2的可靠性对于con来说可能要低得多。如果我想自由估计injnorm2的方差，我假设我必须设置con的因子方差，以便模型仍然被识别。
因此我的问题是：这种设置injnorm2残差方差的方法有效吗？如果不是，是否有合适的方法来猜测con的因子方差是多少，以便可以设置它？]]></description>
      <guid>https://stats.stackexchange.com/questions/655767/how-should-you-specify-a-bifactor-sem-where-one-factor-only-has-one-item</guid>
      <pubDate>Mon, 14 Oct 2024 17:25:39 GMT</pubDate>
    </item>
    <item>
      <title>仅使用信息几何即可访问的统计问题示例</title>
      <link>https://stats.stackexchange.com/questions/655817/examples-of-problems-in-statistics-accessible-only-using-information-geometry</link>
      <description><![CDATA[我只是好奇，统计中是否存在一些问题示例，这些问题确实可以使用信息几何来访问，而完全避免几何的证明尚不清楚。换句话说，通过将问题中的统计模型$\mathcal{P}$视为统计流形，然后使用微分几何中的结果来解决，而尚未发现真正使用流形结构的证明。
交叉验证https://stats.stackexchange.com/questions/655707/examples-of-problems-in-statistics-accessible-only-using-information-geometry上的相同问题，但到目前为止没有收到任何回复。]]></description>
      <guid>https://stats.stackexchange.com/questions/655817/examples-of-problems-in-statistics-accessible-only-using-information-geometry</guid>
      <pubDate>Mon, 14 Oct 2024 13:55:40 GMT</pubDate>
    </item>
    <item>
      <title>检测时间序列中的波动率聚类，特别是股票回报率（%）</title>
      <link>https://stats.stackexchange.com/questions/655829/detecting-volatility-clusters-in-time-series-stock-returns-in-particular</link>
      <description><![CDATA[我的主要目标是检测金融时间序列中是否存在波动性集群，特别是股票收益（%）。因此，它可以转化为检测股票收益（%）本身的“条件异方差性”；但不是检测模型残差中的“条件异方差性”。
在这种情况下，哪种统计检验合适？
如果有合适的检验，零假设和备择假设是什么？我认为有一组假设可以评估波动性集群、条件异方差的存在与否，这一点很重要。
“Engle 的 ARCH 检验”是否适合我的目的：检测波动性集群？或者它旨在测试残差的统计属性，而不是时间序列本身的波动性？]]></description>
      <guid>https://stats.stackexchange.com/questions/655829/detecting-volatility-clusters-in-time-series-stock-returns-in-particular</guid>
      <pubDate>Mon, 14 Oct 2024 05:22:46 GMT</pubDate>
    </item>
    <item>
      <title>测量分布均匀性</title>
      <link>https://stats.stackexchange.com/questions/655696/measure-for-distribution-uniformity</link>
      <description><![CDATA[是否有某种度量和计算方法，以区分均匀分布在范围内的值和具有许多峰值（其数量）的值？
例如，区分如下序列：
示例 1：1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2

带有
示例 2：1、1、1、1、1、2、1、2、2、2、2、2、1、2、1、2、1、2、1、1、1、1、 1, 2, 2, 2, 2 

和
示例 3：1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2

我正在寻找一个指标，当值（这里假设为 2）均匀分布在序列中时，该指标接近 0，当所有这些值集中在一个地方时，该指标接近 1；当我有像示例 2 中那样的本地组时，我希望该指标接近 0.5，而在示例 3 中，我希望该指标接近 0.7。这些值只是为了解释逻辑，当然，它们是近似的。
例如，如果问题是关于一个峰值，我会使用平均值和方差。但是如果有多个峰值，情况就会有所不同。
是否存在这样的指标（或类似指标）？
一些背景知识
我想要一个度量，它可以说明文本中的特定词素（由数字表示）是否分布均匀（如代词）或这是一个术语（如“排列”），它将倾向于在大型文本库中大量出现在数学书中。
更新
供未来研究使用。四分位距 (IQR) 可能会有所帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655696/measure-for-distribution-uniformity</guid>
      <pubDate>Sat, 12 Oct 2024 16:29:13 GMT</pubDate>
    </item>
    </channel>
</rss>