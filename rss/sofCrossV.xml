<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 20 Dec 2023 03:12:19 GMT</lastBuildDate>
    <item>
      <title>对多级模型的残差进行建模意味着什么？</title>
      <link>https://stats.stackexchange.com/questions/635312/what-it-means-to-model-the-residuals-of-a-multilevel-model</link>
      <description><![CDATA[我有一个高度倾斜的数据集。但是，与残差未建模的其他模型相比，我选择的下面的模型显示出显着改进的正态分布残差（和预测值）。
两个问题：
1- 下面的模型是否假设我每个主题的数据都来自正常群体，其方差在X1_categorical级别之间也不相等也是 X2_numeric 变量的幂函数？
2- 残差分布（下面）是否告诉我们有关数据任何部分的分布（例如每个主题的数据，或边际分布）涵盖所有科目等）
hist(resid(MODEL, type = “标准化”))

 模型 &lt;- nlme::lme(y ~ X1_categorical + X2_numeric,
         随机 = ~1|主题，
         数据=数据，
         相关性 = corSymm(~1|主题),
         权重 = varComb(varIdent(form = ~ 1 | X1_categorical ),
                                          varPower(form = ~ X2_numeric )))
]]></description>
      <guid>https://stats.stackexchange.com/questions/635312/what-it-means-to-model-the-residuals-of-a-multilevel-model</guid>
      <pubDate>Wed, 20 Dec 2023 01:45:58 GMT</pubDate>
    </item>
    <item>
      <title>用于同时比较多个参数的贝叶斯 ROPE（实际等效区域）？</title>
      <link>https://stats.stackexchange.com/questions/635309/bayesian-rope-region-of-practical-equivalence-for-simultaneous-comparison-of-m</link>
      <description><![CDATA[我非常喜欢 ROPE（实际等效区域）的想法（例如，参见 此处），您可以在其中计算给定参数位于先前范围（算作“小”）的后验概率。在学科领域方面。 （这不是假设拒绝程序问题的替代品；在我正在研究的特定上下文中，作者希望专门测试等效性。）
正如我所见，ROPE 是一个单变量过程，即测试某些特定参数的边际后验分布。是否存在关于多元版本的讨论？我可以想到一些粗略的方法（例如，测试一堆单变量 ROPE 的同时满足程度 - 位于指定“矩形”区域内的概率 - 或某种平方和/马哈拉诺比斯变体），但我希望不要这样做重新发明任何轮子。]]></description>
      <guid>https://stats.stackexchange.com/questions/635309/bayesian-rope-region-of-practical-equivalence-for-simultaneous-comparison-of-m</guid>
      <pubDate>Wed, 20 Dec 2023 01:27:23 GMT</pubDate>
    </item>
    <item>
      <title>寻找泊松分布之间的相关性的适当归一化是什么？</title>
      <link>https://stats.stackexchange.com/questions/635305/what-is-the-appropriate-normalization-for-finding-correlations-between-poisson-d</link>
      <description><![CDATA[我有兴趣使用这个算法，glm-pca，来找到一个较低的维度嵌入时间序列数据，特别是神经元尖峰数据，这是泊松分布的。我看过一些关于查找两个泊松分布的协方差的帖子 https://math.stackexchange.com/questions/3707140/joint-distribution-and-covariance-of-poisson-process-and-waiting-time 我只是好奇如果有标准化的话会怎样应该应用于我的数据。基本上这将是一个非常稀疏的计数时间序列。我可能会减小窗口大小以减小矩阵的大小并加快计算速度。]]></description>
      <guid>https://stats.stackexchange.com/questions/635305/what-is-the-appropriate-normalization-for-finding-correlations-between-poisson-d</guid>
      <pubDate>Tue, 19 Dec 2023 23:45:02 GMT</pubDate>
    </item>
    <item>
      <title>排列测试图分析[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635304/permutation-test-graph-analyse</link>
      <description><![CDATA[我需要将来自矩阵引导的值与原始的唯一值进行比较，但我不知道如何对我的数据执行此操作。
为了我需要做：
测量原始网络上的目标变量并保存它洗牌我的原始数据（相关矩阵） - 随机（100x）创建测量该随机网络的目标变量的图表保存循环结束的数据比较分布随机目标变量，并在请求时保存原始变量。那么如果原始数据在随机变量的 95% 分布范围之外，则意味着它是显着的（随机数与原始变量不同）。
我在 R 中使用了 t.teste 这种形式。
pval_eq[k] &lt;- t.test(rand, mu = obs)$p.value
我如何无法进行统计来比较这些数据：观察值以及该值的排列。
我可以使用这种形式来计算 p 值：大于或等于观察值的值（统计量）的数量，然后除以值的数量。在代码中，pval = sum(s &gt;= s0)/N;
我在互联网上找到了其他几个公式。但基本上总的来说，我只是想知道一个正确的公式来计算 p 的值，考虑到我想比较原始值和该值的排列 100x]]></description>
      <guid>https://stats.stackexchange.com/questions/635304/permutation-test-graph-analyse</guid>
      <pubDate>Tue, 19 Dec 2023 22:37:17 GMT</pubDate>
    </item>
    <item>
      <title>采样：如果多个样本产生一个输出，我实际上需要处理多少个样本？</title>
      <link>https://stats.stackexchange.com/questions/635303/sampling-if-multiple-samples-produce-one-output-how-many-samples-do-i-actually</link>
      <description><![CDATA[解释一下，假设我根据 $n$ 个连续的现实世界样本计算单个测试统计数据。想象一下，我在实验过程中总共获得了 $m \gg n$ 个真实世界样本。
我是否有 $m$ 或 $m \over n$ 个样本用于假设测试？
&lt;小时/&gt;
作为随机性测试的一部分，我测试均匀分布的示例：假设随机样本总大小为 5120 字节。我的测试统计量是处理窗口为 512 字节的快速傅立叶变换的峰值。因此 512 个字节被处理后产生一个浮点数。我想这意味着我只有 10 次 KS 均匀性测试试验...
就上下文而言，我正在考虑以下声明，摘自采样有关：如果一个样本产生多个输出，我实际上需要工作多少个样本与？ 但它完全相反。]]></description>
      <guid>https://stats.stackexchange.com/questions/635303/sampling-if-multiple-samples-produce-one-output-how-many-samples-do-i-actually</guid>
      <pubDate>Tue, 19 Dec 2023 22:36:54 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯深度学习中学习损失衰减的损失函数的推导</title>
      <link>https://stats.stackexchange.com/questions/635300/derivations-of-loss-functions-for-learning-loss-attenuation-in-bayesian-dl</link>
      <description><![CDATA[我对贝叶斯深度学习相当陌生，如果这是一个愚蠢的问题，我很抱歉。
我正在尝试实现本文中的工作：我们在计算机视觉的贝叶斯深度学习中需要哪些不确定性？

在整篇论文中，他们给出了最小化目标，使模型能够学习任意不确定性，但他们没有给出任何关于它们来自何处的正式推导。它们不是临时构造，因此必须有一种方法来派生它们。
哪里可以找到推导？
$$
\大的
\mathcal{L}(\theta,p) = -\frac{1}{N} \sum_{i=1}^N
 \text{log} \hspace{1 mm} p(\text{y}_i|\text{f}^\widehat{\text{W}_i}(x_i)) + \frac{1-p}{2N }||\theta||^2
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/635300/derivations-of-loss-functions-for-learning-loss-attenuation-in-bayesian-dl</guid>
      <pubDate>Tue, 19 Dec 2023 22:26:42 GMT</pubDate>
    </item>
    <item>
      <title>预先登记已收集的数据</title>
      <link>https://stats.stackexchange.com/questions/635298/pre-registration-of-data-that-is-already-collected</link>
      <description><![CDATA[我在 2018 年底到 2019 年中期收集了调查数据。由于疫情和其他项目，我除了输入数据之外没有时间做任何事情。我还没有分析数据，甚至没有查看基本的描述或相关性。我确实有 2018 年产生的假设和理论。
现在预注册研究是否太晚了？当我收集数据时，预注册还不是主流做法。遗憾的是，我当时没有预先注册。]]></description>
      <guid>https://stats.stackexchange.com/questions/635298/pre-registration-of-data-that-is-already-collected</guid>
      <pubDate>Tue, 19 Dec 2023 21:58:57 GMT</pubDate>
    </item>
    <item>
      <title>测量程序的标准误差（SEM）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635297/standard-error-of-measurement-procedure-sem</link>
      <description><![CDATA[在同一尺度上计算不同重量的 SEM 是否正确？例如，比较 10 公斤的所有测量值，然后比较 20 公斤的所有测量值...并取平均值 SEM？或者应该单独报告每个重量的 SEM？]]></description>
      <guid>https://stats.stackexchange.com/questions/635297/standard-error-of-measurement-procedure-sem</guid>
      <pubDate>Tue, 19 Dec 2023 21:45:42 GMT</pubDate>
    </item>
    <item>
      <title>如何计算标准。 Logit 模型的优势比的估计误差和 95% 置信区间？</title>
      <link>https://stats.stackexchange.com/questions/635295/how-to-calculate-the-std-error-of-estimates-and-95-confidence-interval-of-the</link>
      <description><![CDATA[对于简单的数据集：
anthers.sum &lt;- 结构(列表(存储 = c(1, 2), n = c(309, 247), y = c(164,
155)), row.names = c(NA, -2L), 类 = &quot;data.frame&quot;)
logit_model &lt;- glm(cbind(y, n-y) ~ 存储, data=anthers.sum, family=binomial(link=&#39;logit&#39;))
摘要（logit_model）

&lt;前&gt;&lt;代码&gt;调用：
glm(公式 = cbind(y, n - y) ~ 存储，族 = 二项式(link = &quot;logit&quot;),
    数据 = 花药.sum)

系数：
            估计标准。误差z值Pr(&gt;|z|)
（截距）-0.2754 0.2632 -1.046 0.2955
存储 0.3985 0.1741 2.289 0.0221 *
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（二项式族的色散参数取1）

    零偏差：1 自由度上为 5.2790e+00
残余偏差：-3.7748e-14（0 自由度）
工商登记号码：16.079

Fisher 评分迭代次数：2

如何手动计算标准。这个 Logit 模型的估计有误吗？
比值比：
x &lt;- anthers.sum$storage
#Logit 模型优势比常数
exp(系数(summary(logit_model))[“(截距)”,1]+系数(summary(logit_model))[“存储”,1]*x[1])
#Logit 模型比值比治疗与对照
exp(系数(summary(logit_model))[“存储”,1]*(x[2]-x[1]))

&lt;前&gt;&lt;代码&gt;[1] 1.131034
[1]1.489594

questionr::odds.ratio(logit_model, level=0.95)

正在等待分析完成...
                 或 2.5% 97.5% p
（截距）0.75929 0.45311 1.2725 0.29553
存储 1.48959 1.06015 2.0989 0.02209 *
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

当我计算优势比的 95% 置信区间时：
#95% CI 常数
exp(系数(summary(logit_model))[“(截距)”,1]*qnorm(c(0.025,0.975))*系数(summary(logit_model))[“(截距)”,2]+系数(summary(logit_model))[“存储”,1]*x[1]*qnorm(c(0.025,0.975))*系数(summary(logit_model))[“存储”,2])
#95% 治疗组与恒定组的 CI
exp(系数(summary(logit_model))[“存储”,1]*(x[2]-x[1])*qnorm(c(0.025,0.975))*系数(summary(logit_model))[&quot;存储”,2])

&lt;前&gt;&lt;代码&gt;[1] 1.0061048 0.9939322
[1] 0.8728501 1.1456720

它们无法匹配questionr::odds.ratio的结果]]></description>
      <guid>https://stats.stackexchange.com/questions/635295/how-to-calculate-the-std-error-of-estimates-and-95-confidence-interval-of-the</guid>
      <pubDate>Tue, 19 Dec 2023 20:54:46 GMT</pubDate>
    </item>
    <item>
      <title>我可以将大型 SEM 模型拆分为较小的 SEM 模型吗？</title>
      <link>https://stats.stackexchange.com/questions/635281/am-i-able-to-split-up-a-large-sem-model-into-smaller-sem-models</link>
      <description><![CDATA[我在 SPSS AMOS 中有一个 SEM 模型，正在测试信息共享对可信度（能力、诚信和仁慈）三个维度与创新之间关系的中介作用。下图描绘了我的 SEM 模型。

当我在 SPSS AMOS 上运行完整的结构模型时，结果不是我所期望的，并且几乎所有我的假设都没有得到支持。然而，当我将大型模型分成 3 个较小的模型来运行 SEM 分析（如下所示）时，大多数结果都支持我的假设。我是否可以将大型模型拆分为 3 个独立的较小模型？在什么条件下可以将大型模型拆分为较小的模型？除了进行 3 个单独的测试之外，将较大的模型拆分为三个较小的模型是否有任何缺点？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635281/am-i-able-to-split-up-a-large-sem-model-into-smaller-sem-models</guid>
      <pubDate>Tue, 19 Dec 2023 18:06:58 GMT</pubDate>
    </item>
    <item>
      <title>比较两个样本的第 90 个百分位数（置信区间、检验）</title>
      <link>https://stats.stackexchange.com/questions/635097/compare-90th-percentiles-of-two-samples-confidence-interval-test</link>
      <description><![CDATA[我有一个质量改进更改前后的救护车响应时间数据集。我想看看更改前后的响应时间是否有差异。具体来说，我试图报告两组（之前和之后）中的第 90 个百分位数值、两个第 90 个百分位数之间的差异、$95$% 置信区间（ CI) 围绕这个差异，以及一个 $p$ 值。
在 R 中，数据集可能如下所示：
set.seed(123)
数据 &lt;- data.frame(
  组=样本（c（“之前”，“之后”），100，替换= TRUE），
  响应时间 = rnorm(100, 平均值 = c(10, 15), sd = 2)
）

我可以使用 t.test 函数轻松测试均值差异：
t.test(data$ResponseTime[data$Group == “之前”],
       数据$ResponseTime[数据$Group ==“之后”])

我还可以像这样计算第 90 个百分位数：
之前 &lt;- 分位数(a$ResponseTime[a$Group==“之前”], probs = 0.9, na.rm = T)
&lt;- 分位数（a$ResponseTime[a$Group==“之后”]，probs = 0.9，na.rm = T）

但我不知道如何比较两者。
我的问题：

这有意义吗？
如果确实有意义，我会使用什么测试来比较第 90 个百分位数？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635097/compare-90th-percentiles-of-two-samples-confidence-interval-test</guid>
      <pubDate>Sun, 17 Dec 2023 02:55:47 GMT</pubDate>
    </item>
    <item>
      <title>比率的自然对数和双向固定效应模型偏差</title>
      <link>https://stats.stackexchange.com/questions/634967/natural-log-of-ratios-and-two-way-fixed-effects-model-bias</link>
      <description><![CDATA[Bartlett 和 Partnoy (BP) (2020) 表明具有比率的自然对数因变量的 OLS 必须在 RHS 上包含 $\ln(denominator)$ 以避免偏差（请参阅第 24-28 页），除非假设 $\ln(denominator)$ 的斜率为 $1$ 且 $\ln(分子)$。这是因为 $\ln(ratio)$，例如 $\ln(\frac{GDP_{it}} {population_{it}})$ 相当于 $\ln(GDP_{it})-\ln(population_{it})$。因此，任何在 LHS 上具有 $\ln(\frac{GDP_{it}}{population_{it}})$ 的 OLS 模型都隐式假设：
$$\ln(GDP_{i})= \beta_0 + X_i + 1\ln(population_{i}) + \epsilon_{i}
\tag{E1}$$
解决方案是在 RHS 上包含 $\ln(denominator)$，就像在 TWFE 5 中一样。他们不会在面板上下文中讨论这些问题具有双向固定效应 (TWFE) 的数据，如 (E2)。
问题
在 OLS 背景下是否有任何理由怀疑 BP？ (E2) 和模型 TWFE 5 是否低于正确的模型来识别 TWFE 面板环境中治疗的无偏效应？ TWFE 2 模型确实给出了治疗的有偏系数吗？是否有任何方法文献讨论 OLS 或 TWFE 上下文中 $\ln(ratio)$ 的问题？
在模型 TWFE 5 中，$\beta_2$ 并不接近 $1$，而是 $0.92$ 在 没有单位 FE 的模型的 OLS 版本。在单位固定效应的背景下，我如何理解 BP 关于 $\ln(\frac{numerator}{denominator})$ 之间线性的观点？
下面的模型 TWFE 4 方程修正了线性假设的偏差：
$$
\ln(\frac{GDP_{it}}{population_{it}}) = \beta_1 治疗_{it} + \beta_2 \ln(population_{it}) + \lambda_{t} + \alpha_i + \epsilon_{it }
\标签{E2}
$$
双向固定效应模型：
&lt;前&gt;&lt;代码&gt;============================================== ==================================
                                     因变量：
                 -------------------------------------------------- ---------
                  log_gdp log_gdp_pc (log_gdp-log_pop) log_gdp log_gdp_pc
                  TWFE 1 TWFE 2 TWFE 3 TWFE 4 TWFE 5
-------------------------------------------------- --------------------------
处理 -0.025 -0.025 0.059*** 0.059***
                            (0.028) (0.028) (0.020) (0.020)
                                                                            
log_pop -0.264*** -0.281*** -1.281***
                  (0.041) (0.042) (0.042)
                                                                            
-------------------------------------------------- --------------------------
TWFE 是 是 是 是 是
观察次数 1,155 1,155 1,155 1,155 1,155
R2 0.712 0.508 0.508 0.714 0.750
=================================================== =========================
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/634967/natural-log-of-ratios-and-two-way-fixed-effects-model-bias</guid>
      <pubDate>Fri, 15 Dec 2023 03:57:04 GMT</pubDate>
    </item>
    <item>
      <title>C 统计量和测量多级逻辑回归中的上下文效应</title>
      <link>https://stats.stackexchange.com/questions/633717/c-statistic-and-measuring-the-contextual-effect-in-multilevel-logistic-regressio</link>
      <description><![CDATA[我有一个两级逻辑回归模型，其结果是“InfectedqPCR” （通过 qPCR 确定是否感染疟原虫）在个体水平上。
我有一系列个人和家庭层面的变量。
家庭是分组结构。
我一直在阅读 Austin 和 Merlo (2017) 的“多级逻辑回归分析中的中级和高级主题”生物统计学教程 - 医学统计 - 关于使用c-统计量作为一般情境效应大小的度量。
按照他们的方法，我尝试解释以下三个模型的 c 统计输出：
model1 &lt;- glm(Infected_qPCR ~ Sex + Age_Band_Years, family=“二项式”, data=Data_Model_In_Adults)
Cstat(x = 预测(模型1),
      resp = model.response(model.frame(model1))) # 0.653
              # 仅包含固定效应 - 无随机效应结构
Cstat(x = 预测(Mod_MAd_Indi),
      resp = model.response(model.frame(Mod_MAd_Indi))) # 0.823
              # 包含相同的固定效应（Sex 和 Age_Band_Years）和家庭聚类随机效应
Cstat(x = 预测(Mod_MAd_Comb_Vil),
      resp = model.response(model.frame(Mod_MAd_Comb_Vil))) # 0.771
              # 包含相同的个体固定效应（Sex和Age_Band_Years）和各种家庭因素以及家庭聚类随机效应

因此，据此，我认为 c 统计量从仅具有固定效应且无随机效应结构的 model1 到包含随机效应结构的 Mod_MAd_Indi 的变化为 0.17。
在 Austin 和 Merlo 的论文中，他们的示例的 c 统计量发生了 0.004 的变化，这表明“一般上下文效应较弱”。
问题 1：
那么，如果 0.004 很弱，那么如果我的上下文效果是 0.17，我能说什么？这是中等的情境效应还是强烈的效应？有这方面的任何指南或参考吗？
问题2：
Austin 和 Merlo 的论文还强调，“向包含特定簇随机效应的模型添加簇特征不能增加仅包含特定簇随机效应的模型的 c 统计量。”那么，c 统计量的 0.17 变化是否是最大可能变化（Austin 和 Merlo 所说的“上限”）？这就是我添加家庭变量 (Mod_MAd_Comb_Vil) 导致 c 统计量较低的原因吗？它可能相同或更低，但绝对不会更高 - 这就是奥斯汀和梅洛的意思吗？
这是根据 Eric Ruzek 在下面的评论中提供的有用意见进行的补充：
在进一步的系列模型中，我的 C 统计量有所增加，仅在小数点后第二位，但尽管如此，在模型中包含家庭层面的变量后，它还是有所增加。

在个体（和随机效应）模型中，该值为 0.880
在家庭和个人（和随机效应）模型中，该值为 0.892。

这似乎违背了所有统计直觉，但以下内容可以解释这一点吗？
**个别型号如下：**

Mod_Indi_Child_0.05_Apriori &lt;- glmer(Infected_qPCR ~ 1 + Age_Band_Years + Work_Place_Nearby_Forest + Bednet_last_night +
                               (1 | Household_ID.x)，数据 = Data_Model_In_Child，家庭 = 二项式，glmerControl(optimizer = “bobyqa”))

**组合模型如下：**

Mod_Comb_Child_Apriori &lt;- glmer(Infected_qPCR ~ 1 + Age_Band_Years + Work_Place_Nearby_Forest + Bednet_last_night + 规模(Persons_living_in_house_count，center = TRUE，scale = FALSE) +
                          (1 | Household_ID.x)，数据 = Data_Model_In_Child，家庭 = 二项式，glmerControl(optimizer = “bobyqa”))

两种模式的区别在于增加了“家庭级”功能。组合模型中的因素（房屋计数中的人数）。该模型比仅个人模型具有更高的 C 统计量的原因可能是因为该“家庭水平”水平因子实际上也包含个体水平的信息？我的意思是，因为变量是“住在房子里的人数”，所以该个人是该房屋计数的一部分，因此该模型正在处理该“房屋计数”的至少一部分。作为个人层面的变量，因此 C 统计量有所上升。
这是对我所得到的不寻常结果的可能解释，还是我抓住了救命稻草？]]></description>
      <guid>https://stats.stackexchange.com/questions/633717/c-statistic-and-measuring-the-contextual-effect-in-multilevel-logistic-regressio</guid>
      <pubDate>Tue, 12 Dec 2023 12:47:45 GMT</pubDate>
    </item>
    <item>
      <title>您可以使用来自单独模型输出的回归贝塔/系数来运行 t 检验吗？</title>
      <link>https://stats.stackexchange.com/questions/630630/can-you-run-a-t-test-with-regression-betas-coefficients-from-the-output-of-separ</link>
      <description><![CDATA[用外行的话来说，如果各个模型中包含的所有协变量都相同，那么运行 t 检验来比较感兴趣的变量（例如年龄）的系数是否公平，我想在其中比较效果网络 A 中的大脑区域与 B、C 等区域的年龄更大，并且它们都作为单独的模型进行研究，但构造相似。]]></description>
      <guid>https://stats.stackexchange.com/questions/630630/can-you-run-a-t-test-with-regression-betas-coefficients-from-the-output-of-separ</guid>
      <pubDate>Tue, 07 Nov 2023 05:14:56 GMT</pubDate>
    </item>
    <item>
      <title>使用逻辑序数回归分析具有重复测量的 Likert 型项目数据</title>
      <link>https://stats.stackexchange.com/questions/549839/analyzing-a-likert-type-item-data-with-repeated-measures-with-logistic-ordinal-r</link>
      <description><![CDATA[我正在为我的论文分析一些李克特类型的项目。经过快速研究后，我发现，与传统方式使用最小二乘回归不同，logit 或概率序数回归模型将是最佳选择（请参阅 Liddell 和 Kruschke，2018：https://www.sciencedirect.com/science/article/pii/S0022103117307746?via%3Dihub ）。由于重复测量，我不得不使用分层回归模型。我能找到的所有论文都使用贝叶斯方法来分析分层序数数据（例如 Liddell 和 Kruschke，2018）。我不太熟悉贝叶斯统计，所以我想知道是否有任何频率论方法可以进行这种分析。
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/549839/analyzing-a-likert-type-item-data-with-repeated-measures-with-logistic-ordinal-r</guid>
      <pubDate>Tue, 26 Oct 2021 13:47:05 GMT</pubDate>
    </item>
    </channel>
</rss>