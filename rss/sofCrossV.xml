<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 10 Aug 2024 09:16:06 GMT</lastBuildDate>
    <item>
      <title>聚类和样本加权（使用 GEE）</title>
      <link>https://stats.stackexchange.com/questions/652584/clustering-and-samples-weighting-using-gee</link>
      <description><![CDATA[我目前正在使用 GEE 模型分析与欧洲国家传染病流行相关的社会因素。我的数据基于特定健康保险覆盖的患者，这引发了对外部有效性的担忧。具体而言，由于不同族群在受保人群中所占比例过高，患病率可能会出现偏差。
我是否应该调整模型中每个族群（来自整个国家人口）的比例，使用这些比例作为加权因子，或考虑按族群进行聚类以解决潜在的偏差？确保我的结果更适用于总体人群的最佳方法是什么？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652584/clustering-and-samples-weighting-using-gee</guid>
      <pubDate>Sat, 10 Aug 2024 08:50:58 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用哪种回归来估计协方差？</title>
      <link>https://stats.stackexchange.com/questions/652583/which-regression-should-i-use-to-estimate-the-covariance</link>
      <description><![CDATA[我使用以下代码生成了一些合成数据。我想仅使用 (X, Z, Y) 中的信息推断 U。例如，泊松回归估计 U 的平均值，但不提供有关其协方差的信息。哪种回归模型合适？
# 加载必要的包
library(lme4)
library(MASS)

# 设置种子
set.seed(123)

# 生成 X
X &lt;- 1 + rnorm(10000, 0, 1)
beta &lt;- 0.5

# 生成 Z
Z &lt;- 0.2 * matrix(rnorm(20000), ncol = 2)

# 均值向量和协方差矩阵
mean &lt;- c(-0.5, 1)
covariance_matrix &lt;- matrix(c(1.0, 0.5, 0.5, 1.5), nrow = 2)

# 从多元正态分布中抽样
U &lt;- mvrnorm(10000, mu = mean, Sigma = covariance_matrix)

#计算线性组合
linear &lt;- X * beta + rowSums(Z * U)

# 从泊松分布中抽样
rate &lt;- exp(linear)
Y &lt;- rpois(10000, lambda = rate)

# 组织成数据框
data &lt;- data.frame(X = X, Z1 = Z[,1], Z2 = Z[,2], Y = Y)

example_model = glm(Y ~ 0 + X + Z1 + Z2, data = data, family =toxic)

我的尝试：
data$id = 1:nrow(data)
model = glmer(Y ~ 0 + X + Z1 + Z2 + (0 + Z1 + Z2 | id), data = df, family = poisson,
control=glmerControl(check.nobs.vs.nlev = &quot;ignore&quot;,
check.nobs.vs.rankZ = &quot;ignore&quot;,
check.nobs.vs.nRE=&quot;ignore&quot;))

虽然这个方法有效，但整体质量并不好。有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652583/which-regression-should-i-use-to-estimate-the-covariance</guid>
      <pubDate>Sat, 10 Aug 2024 07:52:35 GMT</pubDate>
    </item>
    <item>
      <title>表明“二分”连续结果变量会降低标准化效应大小</title>
      <link>https://stats.stackexchange.com/questions/652582/show-that-dichotomizing-a-continuus-outcome-variable-reduces-the-standardized</link>
      <description><![CDATA[我们一直在教授两组 A 和 B 的比较的样本量计算。我被要求提供一个数学解释，说明为什么通过选择截止值 $C$ 并将比例与 $Y &gt; C$ 进行比较，将连续结果变量 $Y$ “二分化”会降低功效。这足以表明，平均值的 z 检验比较的标准化效应大小将始终大于相应比例的 z 检验比较的标准化效应大小。我可以假设 Y 服从正态分布，方差为 $\sigma^2 = 1$。
假设：
$$\text{A 组均值} = 0$$
$$\text{B 组均值} = E$$
均值的 z 检验比较的标准化效应大小为：
$$
\text{效应大小} = \frac{\text{B 组均值} - \text{A 组均值}}{\sqrt{\sigma^2}} = \frac{E - 0}{1} = E
$$
现在，假设我们将连续变量 $Y$ 二分为阈值$C$。A 组中$Y &gt; C$的个体比例由以下公式给出：
$$
p_A = 1 - \Phi(C)
$$
类似地，B 组中$Y &gt; C$的个体比例由以下公式给出：
$$
p_A = 1 - \Phi(C)
$$ C$ 是：
$$
p_B = 1 - \Phi(C - E)
$$
$\Phi(\cdot)$ 表示标准正态分布的 CDF。

两组之间的比例差异是：
$$
D = p_B - p_A = \left[1 - \Phi(C - E)\right] - \left[1 - \Phi(C)\right] = \Phi(C) - \Phi(C - E)
$$
这个差异的方差是：
$$
V = p_A(1 - p_A) + p_B(1 - p_B)
$$
因此，差异的标准差是：
$$
S = \sqrt{V}
$$
最后，二分法后的标准化差异（效应大小）是：
$$
\text{标准化差异} = \frac{D}{S}
$$
如果我到目前为止的推理是正确的，我只需要证明，对于任意的 C 和 E，两者 &gt; 0，
\begin{align*}
E &amp;&gt; \frac{D}{S} \\
&amp;&gt; \frac{\Phi(C) - \Phi(C - E)}{\sqrt{\Phi(C)( 1 - \Phi(C)) + \Phi(C - E)(1 - \Phi(C - E))}}
\end{align*&gt;
根据实验，我认为不等式右边的表达式在 C = 0 时最大，并且始终小于 E。我无法证明表达式在 C = 0 时最大，也无法证明它始终 &lt; E。有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652582/show-that-dichotomizing-a-continuus-outcome-variable-reduces-the-standardized</guid>
      <pubDate>Sat, 10 Aug 2024 06:32:09 GMT</pubDate>
    </item>
    <item>
      <title>时变马尔可夫切换AR模型的自协方差和谱密度</title>
      <link>https://stats.stackexchange.com/questions/652580/autocovariance-and-spectral-density-of-time-varying-markov-switching-ar-model</link>
      <description><![CDATA[我想知道如何计算时变马尔可夫切换 AR 模型在频率 = 0 处的自协方差和谱密度，该模型如下所述

祝好，
温迪]]></description>
      <guid>https://stats.stackexchange.com/questions/652580/autocovariance-and-spectral-density-of-time-varying-markov-switching-ar-model</guid>
      <pubDate>Sat, 10 Aug 2024 05:06:41 GMT</pubDate>
    </item>
    <item>
      <title>混合模型（随机效应）与具有聚类 SE 的池化 OLS</title>
      <link>https://stats.stackexchange.com/questions/652578/mixed-model-random-effects-vs-pooled-ols-with-clustered-se</link>
      <description><![CDATA[我有一个国家/年份数据集。我想了解某个特定群体（例如欧盟）的成员资格是否对结果（例如 GDP）产生影响。
在我的初始模型中，我估计了一个合并 OLS 模型，其中二元指标（固定效应）分配给 年份 和 欧盟，稳健（异方差一致）标准误差按国家/地区聚类。国家/地区 FE 未包含在此模型中，因为时间不变的 欧盟 FE 会从模型中退出。
有人建议我应该估计一个混合模型，除了原始 FE 之外，还将随机效应分配给 国家。我无法询问更多详细信息。
您能否帮助我解释一下添加国家/地区随机效应的目的是什么？我阅读了一些相关内容，我了解到它可以解释国家/地区层面的随机变化。这是正确的吗？添加它是否会冒着在我的模型中引入偏差的风险，或者它是否总是比不控制对国家层面的任何影响要好？]]></description>
      <guid>https://stats.stackexchange.com/questions/652578/mixed-model-random-effects-vs-pooled-ols-with-clustered-se</guid>
      <pubDate>Sat, 10 Aug 2024 03:02:03 GMT</pubDate>
    </item>
    <item>
      <title>ELBO 和“向后” KL 散度参数顺序</title>
      <link>https://stats.stackexchange.com/questions/652577/elbo-backwards-kl-divergence-argument-order</link>
      <description><![CDATA[在维基百科上，它说：“对 P 与 Q 的 KL 散度的简单解释 [即 D_KL(P||Q)] 是当实际分布为 P 时，使用 Q 代替 P 作为模型所产生的预期超额惊喜&amp;quot;
然而在维基百科 ELBO 页面上 &amp;在Bayes-by-backprop 的高引用论文中，它展示了使用 KL“反向”的 ELBO （即真实分布是第二个参数）：

更让我困扰的是，即使您没有对前一项使用反向 KL，您实际优化的成本函数（如下）似乎也会起作用（更好？）...并且定期使用 KL 对于该项在计算上同样可行，尽管我不知道 ELBO 推导的理论含义...

变分推理为什么以这种方式工作？使用 ELBO=KL[P(w)||q(w|θ)]+NLL 的理论含义是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652577/elbo-backwards-kl-divergence-argument-order</guid>
      <pubDate>Sat, 10 Aug 2024 02:03:37 GMT</pubDate>
    </item>
    <item>
      <title>排除“极端”异常值的方法</title>
      <link>https://stats.stackexchange.com/questions/652572/method-for-excluding-extreme-outliers</link>
      <description><![CDATA[我正在用 Python 编写残余气体分析质谱数据缩减软件。该软件需要一种基于尖峰强度的自动异常值检测方法，但我无法找到正确的方法和阈值。
上下文

质谱仪在测量比率方面比测量绝对强度更准确。我们使用氦-3 作为参考尖峰来测量氦-4，但是，由于氢氘干扰等原因导致的错误尖峰强度会使分析无效。
由于恒容源罐和移液器，我们的尖峰气体会随着时间的推移逐渐耗尽。这种消耗遵循指数衰减$y=ae^{bx}$，但是，这种趋势在单个序列中实际上是线性的（消耗因子为$e^b \approx 0.999$）。

挑战

由于消耗，强度实际上并没有形成围绕平均值的正态分布，因此强度的标准偏差和平均值不适合异常值检测。
由于质谱对原始强度的可靠性不如比率，并且由于光束抑制等影响，预计散射量相当高。以下是合法测量的示例序列，没有任何异常值或问题：


在这种情况下，$x$轴上的“氦数”可以读作“分析数”，并且每个分析都是尖峰源耗尽的一个实例。
因此，我的目标是开发一种识别 3He 尖峰强度“极端”异常值的方法。对于上述示例，异常值可能是 7E-10 A 或 2E-11 A - 距离太远，以至于基本上破坏了其余图的可见性。
虽然我可以简单地指定异常值是任何发生在 10$\varepsilon$ 之外的值，但这感觉有点武断和不令人满意。当然，有一种统计方法可以识别我所说的“极端”异常值？]]></description>
      <guid>https://stats.stackexchange.com/questions/652572/method-for-excluding-extreme-outliers</guid>
      <pubDate>Fri, 09 Aug 2024 21:37:10 GMT</pubDate>
    </item>
    <item>
      <title>在模型选择中执行内部 CV 的“元”学习器的性能如何？</title>
      <link>https://stats.stackexchange.com/questions/652525/what-is-the-performance-of-a-meta-learner-that-performs-internally-cv-for-mode</link>
      <description><![CDATA[我试图理解证明，即在模型选择期间将 CV 性能报告为性能估计存在乐观偏差。证明步骤如下：

设 $p_i, \pi_i$ 为样本真实表现 $\forall i$（每个 $i$ 对应一个配置，又称学习器，例如 $C=1$ 的 SVM、$C=10$ 的 SVM 等）
$\mathbb{E}[p_i] = \pi_i, \forall i$（无偏估计）
我们返回估计值 $\max(p_1, \ldots, p_n)$
我们平均回报$\mathbb{E}[\max(p_1, \ldots, p_n)]$
真正的最佳表现$\max(\pi_1, \ldots, \pi_n) =
\max(\mathbb{E}[p_1], \ldots, \mathbb{E}[p_n])$ 为什么？

\begin{align*}
&amp;\mathbb{E}[\max(p_1, \ldots, p_n)]
\geq
\max(\mathbb{E}[p_1], \ldots, \mathbb{E}[p_n])
\\
&amp;\therefore \text{Overestimation}
\end{align*&gt;
我不明白为什么内部执行 CV 的学习者的真实表现必须是 $\max(\pi_1, \ldots, \pi_n)$。
为了获得这个“元”的表现学习器，我们需要以下内容：

将数据集拆分为训练和测试
在训练中通过 CV 调整超参数
估计测试集中最佳选定模型的性能
对不同的数据集重复 1-3 的所有步骤，并平均步骤 3 的性能（这应该是期望等于“元”学习器的真实性能）

有人能证明为什么这个性能必须等于 $\max(\pi_1, \ldots, \pi_n)$ 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652525/what-is-the-performance-of-a-meta-learner-that-performs-internally-cv-for-mode</guid>
      <pubDate>Fri, 09 Aug 2024 09:20:53 GMT</pubDate>
    </item>
    <item>
      <title>双极李克特量表的适当编码[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651714/appropriate-coding-for-bipolar-likert-scale</link>
      <description><![CDATA[对于我的一个变量，我正在用双极李克特量表测量情感。问题是“你对活动有什么感觉？”回答的范围是

担心
有点担心
中立
有点兴奋
兴奋。

我相信这个回答范围对我的研究问题很有意义，但我发现很难找到编码方法，并且通常很难证明以这种特定方式使用它的合理性。我最初的想法是为每个参与者取一个平均值（他们对七种类型的活动进行情感评级），然后将它们分为两个因素（负面影响/无负面影响），这样我就可以将其作为多元回归方程中的分类预测因子输入。有没有办法做到这一点（找到以这种方式评级的类别的平均值，并根据他们的平均分数将每个人归入一个类别），在这种情况下应该使用什么编码？如果此方法存在任何其他缺陷或逻辑错误，请告诉我:)]]></description>
      <guid>https://stats.stackexchange.com/questions/651714/appropriate-coding-for-bipolar-likert-scale</guid>
      <pubDate>Thu, 25 Jul 2024 00:07:46 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 tidymodels 从 last_fit XGBoost 模型中检索测试和训练对数损失？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651703/how-do-i-retrieve-the-testing-and-training-logloss-from-a-last-fit-xgboost-model</link>
      <description><![CDATA[我试图使用来自模型训练和测试的评估日志为我的 XGBoost 模型绘制一个图（使用 r），但我只能在执行 last_fit（拟合训练以在测试集上测试）后绘制训练评估日志。我发现可以使用 model.evals_result() 在 python 中计算“学习曲线”，但我不知道这在 r 中对应什么。有人知道如何从 last_fit XGBoost 模型中检索训练和测试评估日志吗？
我可以绘制训练和测试对数损失的唯一方法是仅拟合测试集（fit() 测试与 last_fit() 相结合）。我不确定这是不是正确的做法。任何想法或帮助都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/651703/how-do-i-retrieve-the-testing-and-training-logloss-from-a-last-fit-xgboost-model</guid>
      <pubDate>Wed, 24 Jul 2024 21:06:31 GMT</pubDate>
    </item>
    <item>
      <title>调整 VAR 系数进行模拟</title>
      <link>https://stats.stackexchange.com/questions/651684/adjusting-var-coefficients-for-simulation</link>
      <description><![CDATA[我正在估算一个 VAR 模型，然后将其用于蒙特卡罗模拟。但是，对于某些变量，数据中存在明显的下降趋势，我们不想将其包含在模拟中。我的同事建议我可以在模拟中将趋势系数设置为零以获得正确的结果。但是，我想知道在这种情况下这样做是否可以，或者由于 VAR 模型中系数的相互依赖性，它会破坏所有其他系数。
此外，当我将趋势设置为零时，我需要调整平均值的系数，使其与估计期结束时接近平均值的值对齐，而不是整体平均值。因此，我们希望以特定的几何平均值为目标。为了实现这些愿望，改变我的模型的最佳方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/651684/adjusting-var-coefficients-for-simulation</guid>
      <pubDate>Wed, 24 Jul 2024 14:00:40 GMT</pubDate>
    </item>
    <item>
      <title>执行 BSTS 分析时如何处理缺失数据</title>
      <link>https://stats.stackexchange.com/questions/651677/how-to-deal-with-missing-data-when-performing-a-bsts-analysis</link>
      <description><![CDATA[数据描述
我使用的数据来自世界银行收集的全球治理指标 (WGI)。该数据集是来自不同来源的多个指标的组合，每个指标都有自己的测量技术。分数是按每个国家每年收集的，并通过最小-最大方法标准化为 0-1 的范围。以下是我的 Excel 文件的屏幕截图

我有国家名称、年份的列以及与我的研究相关的每个指标的一列。从屏幕截图中可以看出，有相当多的缺失值。这是有道理的，因为并非所有国家每年都会在每个指标上获得分数。这就是我的问题所在，稍后我会讨论这个问题。
总体目标
基于上述数据，我想在 R 中制作自己的综合指标。我的想法是，对于 WGI 使用的指标子集，我创建一个加权平均值，其中权重由贝叶斯结构时间序列模型确定，具体使用趋势和斜率分量（局部线性趋势）。这样做的想法是，由于测量方法不同，得分并不相等。虽然两个指标的得分可能都在 1-10 的范围内，但一个指标可能使用整个范围，而另一个指标可能不使用。在这种情况下，如果分配的分数为 8，则不清楚相对于其他分数，这是否是一个好分数。
我选择贝叶斯方法是因为我想将其中一个指标作为先验知识，因为它代表了数据集（即覆盖最大的国家组并具有代表性样本）。我曾考虑使用频率论方法的未观测成分模型 (UCM)，但我仍在考虑是否使用，因为我无法估计哪种方法更适合我的数据。但是，在了解到 BSTS 更擅长处理缺失值后，这是我的第一选择。
问题
我的问题是，在计算 BSTS 时，如何才能最好地处理缺失值。具体来说，我注意到预测变量（即先验知识、代表性指标）中的任何 NA 值似乎都会破坏 BSTS。此外，尽管代表性指标在大多数国家都有得分，但必然会出现代表性指标没有得分而另一个指标得分的情况，这意味着没有预测。
但是，我无法估算缺失值，因为这与数据的性质不符。因此，我面临一个问题。有人有什么想法、技巧等吗？或者，如果您有一个很好的资源可以讨论这个问题，那也非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/651677/how-to-deal-with-missing-data-when-performing-a-bsts-analysis</guid>
      <pubDate>Wed, 24 Jul 2024 12:54:41 GMT</pubDate>
    </item>
    <item>
      <title>有哪些情况我们需要避免使用 IQR？</title>
      <link>https://stats.stackexchange.com/questions/633392/are-there-cases-where-we-need-to-avoid-the-usage-of-iqr</link>
      <description><![CDATA[让我们考虑一下四分位距 (IQR)、标准差 (SD) 和平均绝对差 (MAD)。我们知道&quot;最常见的稳健尺度测量之一是四分位距 (IQR)&quot;，而&quot;标准差受异常值的影响很大&quot;，其&quot;崩溃点为 0&quot;。此外，“平均绝对偏差是比标准偏差更稳健的离散度度量”。
当我在近似对称或中度偏斜的分布（没有异常值）中计算 IQR、SD 和 MAD 时，SD 和 MAD 给出的值相似（MAD 返回的值比 SD 略低），并且它们始终低于 IQR 值，并且与 IQR 值相对较远。
可能保留 IQR、SD 和 MAD 并没有什么错，因为它们只是“离散度”一词的不同定义，但如果一个人需要依赖一个数字来表示数据的离散度并问，“该分布的离散度是多少？”，我们应该说出 IQR、SD 和 MAD 的所有值吗？
或者我们应该 - 例如 - 丢弃 IQR，因为它离 SD 和 MAD 相当远，而只传达 SD 或 MAD，因为它们彼此相当接近？
从这个案例中，我会概括并问：是否存在我们需要避免使用 IQR 的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/633392/are-there-cases-where-we-need-to-avoid-the-usage-of-iqr</guid>
      <pubDate>Fri, 08 Dec 2023 11:24:41 GMT</pubDate>
    </item>
    <item>
      <title>报告 GLMER 的结果</title>
      <link>https://stats.stackexchange.com/questions/623851/reporting-results-from-a-glmer</link>
      <description><![CDATA[我已建立了广义线性混合模型 (GLMM)。有关输出，请参见下文。通常（报告方差分析结果时），我会这样写：$F(1, 116) = 6.09$，$p = .015$，$η2 = .04$。但是，在报告以下结果时（根据 APA），我应该使用哪些统计参数（例如 $\beta$，...）？
 747.5 788.7 -364.7 729.5 711 

缩放残差：
最小值 1Q 中位数 3Q 最大值 
-4.4527 -0.4184 0.2273 0.4934 2.0564 

随机效应：
组名称 方差 标准差
id（截距） 3.006 1.734 
观察数：720，组：id，120

固定效应：
估计标准差误差 z 值 Pr(&gt;|z|) 
(截距) -9.985e-01 5.763e-01 -1.733 0.0832 . 
风险评估 1.351e+00 7.763e-01 1.740 0.0819 . 
图标 -7.898e-01 7.961e-01 -0.992 0.3211 
位置 -8.368e-07 1.183e-01 0.000 1.0000 
风险评估：图标 -9.109e-02 1.141e+00 -0.080 0.9364 
风险评估：位置 3.297e-01 1.659e-01 1.987 0.0469 * 
图标：位置 7.937e-01 1.822e-01 4.357 1.32e-05 ***
风险评估：图标：位置 -4.527e-01 2.673e-01 -1.694 0.0903 . 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应相关性：
（内部）Rskdrs 图标位置 Rskd：I Rskd：P Icn：Ps
Rskdrstllng -0.746 
图标 -0.712 0.529 
位置 -0.718 0.533 0.520 
Rskdrstll：I 0.502 -0.675 -0.698 -0.363 
Rskdrstll：P 0.502 -0.700 -0.371 -0.713 0.480 
图标：位置 0.446 -0.325 -0.719 -0.649 0.495 0.477 
Rskdrst:I:P -0.312 0.435 0.490 0.443 -0.719 -0.620 -0.670 ```

I
]]></description>
      <guid>https://stats.stackexchange.com/questions/623851/reporting-results-from-a-glmer</guid>
      <pubDate>Sat, 12 Aug 2023 23:41:10 GMT</pubDate>
    </item>
    <item>
      <title>Hessian 的一些特征值为正是什么意思？如何解决？</title>
      <link>https://stats.stackexchange.com/questions/597563/what-does-mean-some-eigenvalues-of-the-hessian-are-positive-how-to-fix-it</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/597563/what-does-mean-some-eigenvalues-of-the-hessian-are-positive-how-to-fix-it</guid>
      <pubDate>Thu, 01 Dec 2022 06:55:44 GMT</pubDate>
    </item>
    </channel>
</rss>