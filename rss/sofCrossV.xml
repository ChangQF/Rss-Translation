<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 08 Jun 2024 06:19:04 GMT</lastBuildDate>
    <item>
      <title>我们可以在误差估计之间绘制多少个协方差来使用 AMOS 修改 CFA 的假设模型？</title>
      <link>https://stats.stackexchange.com/questions/648858/how-many-covariances-can-we-draw-between-error-estimates-to-modify-the-hypothesi</link>
      <description><![CDATA[我在 AMOS 中运行了验证性因子分析，模型拟合所需的指标值低于所需值，因此我绘制了误差项之间的协方差来修改模型。我想问的问题是，是否有任何参考资料可以指导我们可以绘制多少协方差来拟合模型？如果有，请指导我。由于我是第一次学习 AMOS，所以我对 AMOS 了解不多。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/648858/how-many-covariances-can-we-draw-between-error-estimates-to-modify-the-hypothesi</guid>
      <pubDate>Sat, 08 Jun 2024 05:44:08 GMT</pubDate>
    </item>
    <item>
      <title>线性回归：当结果变量是计数数字时，用百分比变化来解释系数</title>
      <link>https://stats.stackexchange.com/questions/648857/linear-regression-interpret-coefficient-in-terms-of-percentage-change-when-the</link>
      <description><![CDATA[我有一个线性回归，其中 Y 是一个计数数字。
Y = a + b1X1 + b2X2

我知道我们可以将 b1 解释为：X1 增加一个单位将使 Y 改变 b1。但我如何以百分比的形式解释它？我知道当 Y 是计数数字时我可以使用泊松。但仅给出线性回归，有没有办法将 b1 解释为百分比值？]]></description>
      <guid>https://stats.stackexchange.com/questions/648857/linear-regression-interpret-coefficient-in-terms-of-percentage-change-when-the</guid>
      <pubDate>Sat, 08 Jun 2024 04:31:37 GMT</pubDate>
    </item>
    <item>
      <title>回归方法之间的差异</title>
      <link>https://stats.stackexchange.com/questions/648856/difference-between-regression-methods</link>
      <description><![CDATA[在给定数据的统计建模中，何时使用逻辑回归，何时使用 beta 回归？如何知道它们之间的区别？什么时候我可以只拟合线性回归，而不必担心数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/648856/difference-between-regression-methods</guid>
      <pubDate>Sat, 08 Jun 2024 03:50:36 GMT</pubDate>
    </item>
    <item>
      <title>尽管 Resnet50 的测试和训练准确率很高，但 F1 分数却很低</title>
      <link>https://stats.stackexchange.com/questions/648855/resnet50-low-f1-score-despite-high-testing-and-training-accuracy</link>
      <description><![CDATA[我目前正在使用 Resnet50 在 Amazon Berkley Objects 数据集上进行图像分类，我一直面临 F1 分数低的问题，我确保训练和测试样本中的类别相等（总共约 50k 张图像），尽管它不会超过 10%（我知道图像显示的是第 7 个 epoche，但我不会让步直到运行结束），有什么建议吗？
预处理步骤主要是过滤、数据增强、重新缩放、基本数据准备，数据分为 80 20。]]></description>
      <guid>https://stats.stackexchange.com/questions/648855/resnet50-low-f1-score-despite-high-testing-and-training-accuracy</guid>
      <pubDate>Sat, 08 Jun 2024 00:43:40 GMT</pubDate>
    </item>
    <item>
      <title>适合 MLP 和 LSTM 的分布</title>
      <link>https://stats.stackexchange.com/questions/648854/appropriate-distribution-for-mlp-and-lstm</link>
      <description><![CDATA[我总共有 6300 个样本，其中 5800 个是训练数据，500 个是测试数据。我们在训练过程、预测精度和学习能力方面比较了 LSTM 和具有一个隐藏层的多层感知器 (MLP) 的性能。
在下图中，横坐标和纵坐标分别是迭代次数和 MSE 误差。它们的学习曲线如图所示。观察图，很明显 LSTM 的学习曲线比 MLP 的学习曲线衰减得更快。此外，LSTM 的收敛曲线比其他曲线更稳定。此外，LSTM 的损失 (RME 误差) 始终小于 MLP。LSTM 的 RMS 误差为 3.47998，MLP 为 5.02391。
我的问题是如何为 LSTM 和 MLP 找到/定义合适的分布？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/648854/appropriate-distribution-for-mlp-and-lstm</guid>
      <pubDate>Sat, 08 Jun 2024 00:37:30 GMT</pubDate>
    </item>
    <item>
      <title>使用二元结果的功率计算（使用 R 包和手动模拟）</title>
      <link>https://stats.stackexchange.com/questions/648852/power-calculation-with-a-binary-outcome-using-a-r-package-manual-simulation</link>
      <description><![CDATA[我试图在相同的设置下比较三种不同的功效计算方法。虽然我理解由于随机性，每种方法的功效估计不可能完全相同，但我预计它们会非常相似。然而，我观察到功效估计略有不同。
基本设置如下：

结果：二进制（成功 1；失败 0）
要比较的两组：G1 vs G2
G1：样本数 - 150；成功率为 0.2
G2：样本数 - 30；成功率为 0.4
显著性水平为 0.2（不是通常的 0.05）

也就是说，
p1 &lt;- 0.2
p2 &lt;- 0.4

n1 &lt;- 150
n2 &lt;- 30

我使用的三种方法是：

使用 pwr 包中的 pwr.2p2n.test 函数。
使用 prop.test 函数进行模拟。
使用 fisher.test 函数进行模拟

### -------------------------------- ###
### --- 版本 1：pwr.2p2n.test --- ###
### -------------------------------- ###
library(pwr)
pwr.2p2n.test(h = ES.h(p1 = p1, p2 = p2), 
n1 = n1, n2 = n2,
sig.level = 0.20,
alternative = &quot;less&quot;)

# power = 0.9145152

### ---------------------------- ###
### --- 版本 2：Prop 测试 --- ###
### ---------------------------- ###
nreps &lt;- 10000
y1 &lt;- rbinom(n = nreps, size = n1, p = p1)
y2 &lt;- rbinom(n = nreps, size = n2, p = p2)

pval &lt;- rep(NA, nreps)
for(i in 1:nreps) {
pval[i] &lt;- prop.test(c(y1[i], y2[i]), 
n= c(n1, n2), 
alternative = &quot;less&quot;,
p = NULL, correct = TRUE)$p.value
}

power &lt;- sum(pval &lt; 0.20) / nreps 
power # [1] 0.8756

### -------------------------------------- ###
### --- 版本 3：Fisher 精确检验 --- ###
### -------------------------------------- ###
pval.fin &lt;- c()
for(i in 1:nreps){
y1 &lt;- rbinom(n1, size = 1, p = p1)
y2 &lt;- rbinom(n2, size = 1, p = p2)
dat.comb &lt;- rbind(data.frame(res = y1, group = &quot;G1&quot;),
data.frame(res = y2, group = &quot;G2&quot;))
tab &lt;- table(dat.comb$group, dat.comb$res)
test.res &lt;- fisher.test(tab, alternative = &#39;less&#39;)
pval.fin[i] &lt;- test.res$p.value
}
mean(pval.fin&lt;0.2) # [1] 8e-04

我注意到了以下两点：

第三种方法使用 Fisher 精确检验，其幂为 8e-0.4。但是，如果我将“替代”选项从“less”更改为“greater”，幂将变为 0.8811，这与我们从第一种方法和第二种方法中获得的结果相似。但是第一种方法和第二种方法使用了“less”的“替代”选项……我不明白是什么导致了如此巨大的差异。

版本 1 和版本 2 的幂估计也有点偏差。我不太清楚是什么导致了这种差异。


有人能帮我理解为什么即使设置相同，我也没有获得类似的功率吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648852/power-calculation-with-a-binary-outcome-using-a-r-package-manual-simulation</guid>
      <pubDate>Fri, 07 Jun 2024 22:15:04 GMT</pubDate>
    </item>
    <item>
      <title>对于缺少很多天的时间序列，最好的选择是什么[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648849/what-are-the-best-options-for-imputing-time-series-that-is-missing-lots-of-days</link>
      <description><![CDATA[我有好几个月的温度数据，大约每十分钟记录一次。除非它有间隙。如果间隙为一小时左右，我可以线性插值，但如果间隙为几天，这显然行不通。
我目前所做的是取每日平均值，然后进行样条拟合以获得每天的平均值。我还从每天中减去平均值，以计算数据随时间变化的滚动平均值，按小时计算。然后，我可以用每小时滚动偏移量来填充缺失的天数，该偏移量由插值样条拟合所表示的平均值应为的值决定。
这有点用，但你可以看到我拼接的地方。例如，连接处的梯度不连续。我想我可以通过每天对总变化进行每日估计，然后将其插入间隙来改进，但是......
这肯定应该是机器学习的一个很棒的应用？我正在摆弄一些 scikit-learn 包，但它们似乎都希望在学习之前删除 NaN。
如能提供任何指点，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/648849/what-are-the-best-options-for-imputing-time-series-that-is-missing-lots-of-days</guid>
      <pubDate>Fri, 07 Jun 2024 20:38:31 GMT</pubDate>
    </item>
    <item>
      <title>SVRG 与完全梯度下降</title>
      <link>https://stats.stackexchange.com/questions/648848/svrg-vs-full-gradient-descent</link>
      <description><![CDATA[随机梯度下降法让我们能够避免计算全梯度，但代价是引入收敛噪声底限。为了降低此噪声底限，SGD 需要减小步长，这会导致在强凸情况下失去线性收敛。 SVRG（随机方差降低梯度）允许我们返回这种线性收敛，但我看不出这在计算上比简单的全梯度下降有什么好处。
SVRG 在外循环的每次迭代中对完整梯度进行采样，然后执行形式为 $w_t = w_{t-1} - \eta \left(\nabla f_{i_t}(w_{t-1})-\nabla f_{i_t}(\hat{w}) + \nabla f(\hat{w})\right)$ 的内循环步骤，其中 $\hat{w}$ 是当前外循环值。我们的想法是利用梯度之间的正相关性来减少估计量中的方差。在强凸情况下，论文中的分析会选择这些内循环子步骤中的一个随机步骤作为我们的下一个外循环步骤。然后他们继续将其呈现为返回 GD 的线性收敛，但收敛程度取决于我们运行的外循环步骤数。这些外循环步骤中的每一个都在计算一个完整的梯度，那么这是否不是在进行完整的梯度下降加上这些内循环步骤的一些额外工作 - 所有这些都是为了实现与 GD 相同的收敛？]]></description>
      <guid>https://stats.stackexchange.com/questions/648848/svrg-vs-full-gradient-descent</guid>
      <pubDate>Fri, 07 Jun 2024 20:06:54 GMT</pubDate>
    </item>
    <item>
      <title>比较两个随着时间的推移而不平等的群体？</title>
      <link>https://stats.stackexchange.com/questions/648846/comparing-two-unequal-groups-over-time</link>
      <description><![CDATA[我对 rstudio 和统计学还不熟悉，所以请耐心等待。我试图比较两个不同变量随时间的变化，但它们来自非常不同的样本量。
我正在研究现场样本测量值和实验室样本测量值之间的差异。它们以不同的单位测量，但应该是相关的，因为它们本质上测量的是同一件事。
我有一个数据集“Probe”，其中测量了感兴趣的变量“value”。
这应该与我的其他数据集“Field”中的“value”变量相关。
哪种统计测试可以给我我想要的分析？我想看看“Field”值的峰值是否与“Probe”值的峰值相关，依此类推。我试图随着时间的推移跟踪它们是否显示出相似的趋势。我想做一些类似相关性的事情，但不能，因为“Probe”数据由 1606 个观测值组成，而“现场”数据由 197 个观测值组成，因此它们的长度不同，并且无法关联（据我迄今为止的研究所知）。]]></description>
      <guid>https://stats.stackexchange.com/questions/648846/comparing-two-unequal-groups-over-time</guid>
      <pubDate>Fri, 07 Jun 2024 19:59:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的风险比系数在 Coxph 回归中这么大或这么小？</title>
      <link>https://stats.stackexchange.com/questions/648843/why-are-my-hazard-ratio-coefficients-so-large-or-small-in-coxph-regression</link>
      <description><![CDATA[我有一些我工作的机构中特定子群体的成绩数据，并将其与一段时间内的留校情况进行比较。下面的第一个表格是 R 中 coxph 回归的一些风险比，使用 D&amp;F GPA 学生作为比较组。这是一个通常会离开我们机构去另一所机构的子群体，所以我希望看到 A（学术货币）与离开与留下有关。
时间单位基于学分数量。

我的解释是，获得 A 的学生离开的可能性大约是平均成绩为 D 或 F 的学生的 15 倍。作为一项健全性检查，我想检查一下汇总的原始数据：

我很困惑，因为这个值比两组之间的比例要高得多。我是否应该进行更好的比较来计算“原始”数据？从汇总数据透视表值中得出风险比？
另一个示例是下面比较学生程序的输出（程序 3 是参考组）。

与原始数据相比，这里的比例似乎也不支持风险比。程序是分析中最具预测性的变量。

为了进一步参考，我附上了一份 Kaplan Maier 成绩生存图，该图似乎并未表明如此大的 coxph 系数。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648843/why-are-my-hazard-ratio-coefficients-so-large-or-small-in-coxph-regression</guid>
      <pubDate>Fri, 07 Jun 2024 19:36:29 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯法比尼·托内利</title>
      <link>https://stats.stackexchange.com/questions/648839/bayesian-fubini-tonelli</link>
      <description><![CDATA[我正在研究一个贝叶斯框架，其中我在函数$f\sim GP$上放置了一个高斯过程，并且有数据$D^n=\{(X_i,Z_i,W_i)\}^n$。
然后我得到了后验测量$\mu(f|D^n)$。后验均值估计量由 $\hat{f}=\int fd\mu(f|D^n)$ 给出。
我现在感兴趣的是找到另一个估计量的误差，我将其定义为：
\begin{align*}
\beta(x,z) &amp;=E_W[\hat{f}(x,z,W)]\\
&amp;=\int_\mathcal{W}\hat{f}(x,z,W)dP(W)\\
&amp;=\int_\mathcal{W}\int_\mathcal{F}f(x,z,W)d\mu(f|D^n)dP(W)
\end{align*&gt;
我现在想知道是否可以调用 Fubini Tonelli 来切换积分顺序 $\int_\mathcal{W}\int_\mathcal{F}f(x,z,W)d\mu(f|D^n)dP(W)=\int_\mathcal{F}\int_\mathcal{W}f(x,z,W)dP(W)d\mu(f|D^n)$.
我猜我的疑惑来自于我没有对整个数据分布$P(X,Z,W)$进行积分，并且测量$\mu$依赖于数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/648839/bayesian-fubini-tonelli</guid>
      <pubDate>Fri, 07 Jun 2024 16:33:20 GMT</pubDate>
    </item>
    <item>
      <title>李克特量表和样本量</title>
      <link>https://stats.stackexchange.com/questions/648828/likert-scale-and-sample-size</link>
      <description><![CDATA[我想研究母亲收到论文或网站信息的满意度。我至少会问 5 个问题，每个问题都使用李克特量表（5 分）。
样本量：

我是否应该使用调查的样本量公式进行计算（从 $y$ 中抽取 $x$ 名女性）？
我是否应该根据我预期的最重要的问题的李克特量表之间的差异来计算样本量？
我是否应该调整问题数量？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648828/likert-scale-and-sample-size</guid>
      <pubDate>Fri, 07 Jun 2024 14:57:59 GMT</pubDate>
    </item>
    <item>
      <title>估计样本的概率密度</title>
      <link>https://stats.stackexchange.com/questions/648819/estimating-probability-density-for-sample</link>
      <description><![CDATA[我有一个包含 20,000 多个样本的数据集。这里的目标是为样本定义一个分布，以便我可以绘制所有可能的结果。但是，我无法找到可用于估计概率密度的适当分布。我尝试使用正态分布、柯西分布、拉普拉斯分布、学生 T 分布和威布尔分布来测试样本。在所有情况下，Kolmogorov-Smirnov 检验都拒绝了我的样本遵循上述任何分布的可能性。我也尝试使用 KDE 进行估计，但结果并不理想。我尝试使用 KS 检验来检查 KDE 和我的样本之间的相似性，但即使在这里相似性也被拒绝了。我不知道下一步该怎么做才能估算出概率密度。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648819/estimating-probability-density-for-sample</guid>
      <pubDate>Fri, 07 Jun 2024 13:27:34 GMT</pubDate>
    </item>
    <item>
      <title>计算 Cox-Snell Rsquared 的值</title>
      <link>https://stats.stackexchange.com/questions/648684/calculating-the-value-of-cox-snell-rsquared</link>
      <description><![CDATA[我想计算前瞻性纵向研究的最小样本量（使用 cox 回归 - 项目的目的是预测）。 R 中 pmsampsize 包中的以下函数 pmsampsize 可用于计算（基于以下出版物；用于开发具有连续、二元或生存（事件发生时间）结果的模型的最小样本量。 Riley 等人（2018 年））。运行以下函数，我们需要输入 csrsquared 的值，即新模型的 Cox-Snell Rsquared 值。
pmsampsize(type = &quot;s&quot;, csrsquared = , parameters = , rate = ,timepoint = , meanfup = )

如果没有试验数据，在类似的已建立的研究中也没有报告的伪 R2 值，那么如何定义 csrsquared 的值以使用此函数进行计算？
2. 假设伪 R2 的值可用，如何估计 Cox-Snell R 平方的值。
我的模型中有一个二元时间相关协变量，只有 9 个时间点。因此，当 cox 模型包含时间依赖性协变量和离散生存时间时，我认为上述函数不可用于样本量计算。 但我仍然想知道在没有试验数据的情况下如何预测伪 R2，假设我们有连续的生存时间并且所有协变量都是时间独立的。
在我的研究中，患者每两个月来医院检查一次。T0（手术前一周）、T1（手术后两个月）、T2（手术后 4 个月）直至 T9（手术后 18 个月）。有一个二元时间依赖性协变量和一个连续独立变量。 在事件发生前退出、完成无事件随访（T9）的病例被审查。]]></description>
      <guid>https://stats.stackexchange.com/questions/648684/calculating-the-value-of-cox-snell-rsquared</guid>
      <pubDate>Wed, 05 Jun 2024 13:08:22 GMT</pubDate>
    </item>
    <item>
      <title>非平稳时间序列：按层次而不是差异进行分析有什么优势？</title>
      <link>https://stats.stackexchange.com/questions/646849/non-stationary-time-series-what-are-the-advantages-of-doing-analysis-in-levels</link>
      <description><![CDATA[假设我们要分析一些非平稳时间序列 x(t) 和 y(t)。为简单起见，假设它们是 I(1)。我们可以在水平上（使用协整检验）或差异上分析它们。使用协整检验有什么优势？特别是，如果目标是根据 x(t) 预测 y(t)，那么使用水平是否有特定优势？
我记得听说过差分会导致丢失“高频”，但我不知道这意味着什么，无论是在理论上还是在实践中。]]></description>
      <guid>https://stats.stackexchange.com/questions/646849/non-stationary-time-series-what-are-the-advantages-of-doing-analysis-in-levels</guid>
      <pubDate>Wed, 08 May 2024 20:19:53 GMT</pubDate>
    </item>
    </channel>
</rss>