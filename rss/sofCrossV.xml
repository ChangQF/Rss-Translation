<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 31 Dec 2024 03:20:44 GMT</lastBuildDate>
    <item>
      <title>线性 PDF 近似</title>
      <link>https://stats.stackexchange.com/questions/659391/linear-pdf-approximation</link>
      <description><![CDATA[我有一个不完整的数据向量（即缺失数据）。我知道整个数据集遵循帕累托分布，但由于我有缺失数据，因此很难拟合 PDF 并恢复分布的形状参数 alpha（这是我需要的）。
但是，帕累托分布的特征意味着如果我们对 PDF 的 x 和 y 取 log10，结果将是完全线性的。这条线的斜率为 = -(alpha + 1)，所以如果我能找出这条线与我的不完整数据集的关系，我就可以抓住斜率并计算 alpha。
不幸的是，我们无法将“线性分布”拟合到 log10（我的数据），因为线性分布实际上并不存在，违反了 PDF 要求，即分布线下的所有内容都必须 = 1。
是否有可能做这样的事情，可能通过限制线性“分布”来实现到最小值（我的数据）-最大值（我的数据）并标准化为 1？我也尝试了另一种方法，即使用 R 的密度函数进行平滑，并将 y 乘以我拥有的数据点总数（近似“丰度”，见下文），但我想这似乎有点...不雅致。我很感激您对改进或其他前进道路的建议。


# 数据的核密度估计
kde &lt;- density(observed_dbhs, bw = &quot;nrd0&quot;) # 根据需要调整带宽
xmin&lt;-min(observed_dbhs)
kde &lt;- list(
x = kde$x[kde$x &lt;= max(observed_dbhs) &amp; kde$x&gt;=xmin],
y = kde$y[kde$x &lt;= max(observed_dbhs) &amp; kde$x&gt;=xmin]
)

# 过滤 KDE 结果以仅保留接近观察数据的值
filtered_kde &lt;- data.frame(
x = kde$x,
y = kde$y
) %&gt;%
rowwise() %&gt;%
filter(any(abs(x - perceived_dbhs) &lt;= 0.5)) %&gt;%
ungroup()

# 使用过滤值更新 kde$x 和 kde$y
kde &lt;- list(
x = adopted_kde$x,
y = adopted_kde$y
)

# 观察到的总数据
total&lt;- length(observed_dbhs)

# 通过将密度乘以树木总数来估计丰度
estimated_abundance &lt;- kde$y * total

# 应用 log10 转换
log_x &lt;- log10(kde$x) 
log_y &lt;- log10(estimated_abundance)

# 创建一个带有对数转换值的数据框
df &lt;- data.frame(x = log_x, y = log_y) %&gt;%
filter(is.infinite(y) == FALSE)

]]></description>
      <guid>https://stats.stackexchange.com/questions/659391/linear-pdf-approximation</guid>
      <pubDate>Tue, 31 Dec 2024 02:55:47 GMT</pubDate>
    </item>
    <item>
      <title>统计学中帽子符号的混淆</title>
      <link>https://stats.stackexchange.com/questions/659390/confusion-on-the-hat-symbol-in-statistics</link>
      <description><![CDATA[学习统计学中的不同符号让我感到困惑。
在基本的线性回归中，我们写：
$$Y = \beta_0 + \beta_1 X + \epsilon$$
$$\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 X$$
$$\hat{\epsilon} = y - \hat{y}$$
这是因为误差仅存在于理论模型中，上限位于估计值之上，而残差（$\hat{\epsilon}$）取决于估计量，因此它有一个上限。
除此之外，我越来越困惑。
例如，关于 $Y$ 的边际分布，这两个陈述是否正确？

$$Y \sim N(X^T \beta, \sigma^2) \implies E(Y) = X^T \beta$$
$$Y \sim N(X^T \hat{\beta}, \hat{\sigma}^2) \implies E(Y) = X^T \beta$$

关于 $Y$ 的条件分布，这两个陈述是否正确？

$$E(Y \mid X) = \beta_0 + \beta_1 X$$
$$E(Y \mid X, \beta, \sigma^2) = \beta_0 + \beta_1 X$$
$$E(Y \mid X, \hat{\beta}, \hat{\sigma}^2) = \beta_0 + \beta_1 X$$

一般来说，我知道一旦你对左边的某个东西取期望，右边就会失去帽子。但我想知道，也许这些陈述中的一些实际上是等价的，只是陈述 1)（在条件和边际陈述中）是简写符号，而其他陈述实际上等同于 1)？
如能帮助澄清有关帽子符号和期望的困惑，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659390/confusion-on-the-hat-symbol-in-statistics</guid>
      <pubDate>Tue, 31 Dec 2024 02:39:46 GMT</pubDate>
    </item>
    <item>
      <title>分层简单随机抽样推断</title>
      <link>https://stats.stackexchange.com/questions/659388/inference-of-stratified-simple-random-sampling</link>
      <description><![CDATA[我想使用分层随机抽样来估计总体概率 $p$，因为我的数据由许多层 $h$ 组成。
在这种情况下，如果我们选择总共 $n$ 个样本，则每层的最佳样本数 $n_h$ 优化如下
$n_h = n\cdot \sqrt{T_h} /(\sum_h \sqrt{T_h})$
其中 $T_h$ 如下
$T_h = (N_h/N)^2({{N_h}\over{N_h -1}}p_h(1-p_h))$
其中 $N$ 为总人口，$N_h$ 为各层的数量。因此，在使用分层随机抽样确定各层 $h$ 的最佳样本数量 $n_h$ 时，假设各层 $p_h$ 的真实概率已经已知。实际上它取决于层大小$N_h$和概率$p_h$，因此如果$N_h$很大，我们就会进行更多抽样。此外，如果$p_h$在0.5左右，换句话说，如果方差很大，我们就会抽样更多。
那么我想知道使用分层简单随机抽样进行抽样和推断有什么意义？既然我们假设我们知道总体中各层的概率，以便确定最佳样本数，那么是否可以使用$p_h$找出总体的概率？
所以我自己想..我们不假设我们确切地知道$p_h$，但我们几乎知道（可能误差在5％左右？），并使用抽样来计算总体。]]></description>
      <guid>https://stats.stackexchange.com/questions/659388/inference-of-stratified-simple-random-sampling</guid>
      <pubDate>Tue, 31 Dec 2024 01:10:11 GMT</pubDate>
    </item>
    <item>
      <title>通过比较 R 中的两个热图来计算 Earth Mover 距离得分的 p 值？</title>
      <link>https://stats.stackexchange.com/questions/659384/compute-p-value-of-earth-movers-distance-score-comparing-two-heatmaps-in-r</link>
      <description><![CDATA[我试图比较两个热图，但找不到获得具有统计意义的值的方法。
这里是我的问题：我测量了对 5 种药物的单一反应。单个细胞属于两种条件 A 和 B。基于单细胞反应的总体收集，我生成了这些反应的聚类并确定了“10”个反应概况（此处称为“聚类”）。
为了评估条件 A 和 B 之间的差异，我为每种条件生成了一个热图，表示与每种聚类相关的每种药物作用的细胞比例。
这在某种程度上代表了每种条件对药物组的细胞反应的足迹。我看到模式中存在明显差异，想知道是否有办法定义在接受各种处理的两组中是否分布。
在网上查找，我找到了有关地球移动距离 (EMD) 的信息，并使用 emddist R 包比较两个矩阵。我获得了一个值（如果我理解正确的话），它在某种程度上是我的两个热图之间的差异指数。
现在，我想知道是否有办法将这个值的显著 p 值关联起来？
我如何得出结论，两个热图/分布都“显著”不同（或相同）？
对于我最初的问题，即比较细胞对不同药物的反应分布，我是否走在正确的道路上？
实例胜于文字，因此请在此处找到我当前问题的最小可重现示例：
set.seed(123)
mat1 &lt;- matrix(rnorm(50, 2), 10, 5)
mat1 &lt;- apply(mat1,2, function(x) x/sum(x))
mat1

mat2 &lt;- matrix(rnorm(50, 2), 10, 5)
mat2 &lt;- apply(mat2,2, function(x) x/sum(x))
mat2

这里是生成“足迹”的代码每种情况：
library(ComplexHeatmap)
HT1 &lt;- Heatmap(mat1, cluster_rows = FALSE, cluster_columns = FALSE, name = &quot;matrix1&quot;,column_title = &quot;Condition A&quot;,
column_labels = paste0(&quot;Drug &quot;,1:5), row_labels = paste0(&quot;Cluster &quot;,1:10))
HT2 &lt;- Heatmap(mat2, cluster_rows = FALSE, cluster_columns = FALSE, name = &quot;matrix2&quot;,column_title = &quot;Condition B&quot;,
column_labels = paste0(&quot;Drug &quot;,1:5), row_labels = paste0(&quot;Cluster &quot;,1:10))
HT1 + HT2

最后，我目前尝试的 EMD 计算：
library(emddist)
&gt; emd2d(mat1,mat2)
[1] 0.42168


注意：我正在使用 R，因此非常感谢您提供解决方案或暗示 R 包的建议]]></description>
      <guid>https://stats.stackexchange.com/questions/659384/compute-p-value-of-earth-movers-distance-score-comparing-two-heatmaps-in-r</guid>
      <pubDate>Mon, 30 Dec 2024 22:31:04 GMT</pubDate>
    </item>
    <item>
      <title>在处理现实世界数据时，统计推断中关于总体分布存在的错误假设的后果</title>
      <link>https://stats.stackexchange.com/questions/659382/consequences-of-the-false-assumption-about-the-existence-of-a-population-distrib</link>
      <description><![CDATA[统计推断方法，例如统计假设检验，假设观察到的数据是从总体分布中抽样的。对于现实世界的数据，这是一个很大的简化。例如，imdb.com 上特定电影的评分不是从任何分布中抽样的。相反，它们是多种因素的组合，如演员阵容、演技、声音、观众的情绪等。
据我所知，只要我们能够评估这些假设引入了什么错误，对数据做出错误的假设是完全可以的。例如，我们在机器学习中有一个朴素贝叶斯模型，它假设在给定目标类的情况下，特征是条件独立的。对于许多数据集来说，这是错误的。但我们有一个测试集，即整个数据集的一部分，它使我们能够评估建立在错误假设基础上的这种模型的错误。
在统计假设检验的情况下，我们没有提供评估此类错误的方法。据我所知，当测试集缺失时，统计推断方法的任何结果（例如拒绝零假设）都会受到未知大小的误差的影响，从而使结果完全无用。
我大胆地说统计假设检验对现实世界数据无用，对吗？还是我在这里遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659382/consequences-of-the-false-assumption-about-the-existence-of-a-population-distrib</guid>
      <pubDate>Mon, 30 Dec 2024 21:21:18 GMT</pubDate>
    </item>
    <item>
      <title>哪个包适用于有序 probit 模型（Polr 还是 Odinal）？</title>
      <link>https://stats.stackexchange.com/questions/659381/which-package-to-apply-for-ordered-probit-model-polr-or-odinal</link>
      <description><![CDATA[我正在开发一个有序 probit 模型。我很好奇应该使用哪个包。我正在研究 R 中 MASS 包中的 polr 函数和 ordinal 包中的 clm 函数。考虑到我的研究目标，这两个模型的输出系数水平都是可以解释的。
我想知道研究人员如何决定使用哪个包。]]></description>
      <guid>https://stats.stackexchange.com/questions/659381/which-package-to-apply-for-ordered-probit-model-polr-or-odinal</guid>
      <pubDate>Mon, 30 Dec 2024 20:24:13 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯 VAR 样本内 h 天预测</title>
      <link>https://stats.stackexchange.com/questions/659376/bayesian-var-in-sample-h-days-ahead-forecasts</link>
      <description><![CDATA[参考 Afonso 等人 (2023) “稀缺、丰富还是充足？
储备需求曲线的时间变模型”。我遇到了一个令人困惑的说法。论文链接
参考第 33 页的公式 9，其中说“其中 T1、T2 和 T3 代表 2010-2014 年、2015-2020 年 3 月 9 日和 2020 年 3 月 16 日至 2021 年 12 月 29 日； i=
1,...,N 是从我们的双变量时变 VAR 模型（6）中抽取的联邦基金-IORB 利差（p）和正则化准备金（q）的样本内五天联合后验分布。22 我们每五天生成一次这些预测，并设置 N = 100。为了提高效率和可靠性，我们还为优化算法提供了目标函数的解析梯度。”
样本内 5 天预测是什么意思？如果我使用截至时间 (t) 的信息来预测未来 5 天，这不就是 OOS 预测的定义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659376/bayesian-var-in-sample-h-days-ahead-forecasts</guid>
      <pubDate>Mon, 30 Dec 2024 18:27:07 GMT</pubDate>
    </item>
    <item>
      <title>Rstudio 中的核密度估计器。为什么我的带宽为 NA [关闭]</title>
      <link>https://stats.stackexchange.com/questions/659372/kernel-density-estimator-in-rstudio-why-do-i-have-na-for-bandwidth</link>
      <description><![CDATA[我正在使用核密度分析一些动物的活动范围，但在确定我的数据集的 h（或带宽）值时遇到了问题。我的代码使用 loess 模型来预测 h 值。我的大多数个体都运行正常，并且每个个体都给出了 h 值，但有三个个体的 h 值为 NA。这可能是什么原因造成的？
我将提供我的代码示例。这是我现在正在使用的一位前员工创建的代码，所以我并不完全理解它的全部内容（它基于 James Patterson jhttps://jamesepaterson.github.io/jamespatersonblog/06_trackingworkshop_reptilekernels 的代码）。
为所有动物创建带有 MCP 区域对象的数据框
tracking.mcp &lt;- mcp(trackingdatasp, percent = 50)@data
将参考带宽 &amp;放入向量中
href &lt;- c()
hpred &lt;- c()
对每个个体进行循环
 for(i in 1:length(unique(trackingdatasp$ID))){

定义空间点
ID &lt;- sort(unique(trackingdatasp@data$ID))[i]
ID.datasp &lt;- trackingdatasp[trackingdatasp$ID == ID,]

# 为个体定义 href
kernel.ref &lt;- kernelUD(ID.datasp, h = &quot;href&quot;)
href[i] &lt;- kernel.ref[[1]]@h$h

# 定义 h 的尝试限制
htry &lt;- seq(1, href[i] + 20, by = 2.5) 

# 制作一个数据框来保存区域
areatoh.df &lt;- data.frame()

# 现在对每个 htry 执行内核主范围
# tryCatch 确保如果出现错误，循环不会停止
for(k in 1:length(htry)){
kernel.try &lt;- tryCatch(kernelUD(ID.datasp, h = htry[k]), error=function(err) NA)
areatoh.df[k, 1] &lt;- htry[k]
areatoh.df[k, 2] &lt;- tryCatch(getverticeshr(kernel.try, percent = 50)$area, error=function(err) NA)

}

names(areatoh.df) &lt;- c(&quot;h&quot;, &quot;area&quot;)

# 首先摆脱低平滑度下的任何不稳定值（曲线）因子
if(sum(is.na(areatoh.df$area)) &gt; 0){
last.h &lt;- max(areatoh.df$h[is.na(areatoh.df$area)])
areatoh.df$area[areatoh.df$h &lt; last.h + 20] &lt;- NA
}

# 尝试通过扩展网格来修复 NA 值
for(l in 1:length(htry)){
if(is.na(areatoh.df[l, 2])){
# 定义网格
# 这避免了“网格太小，无法估计家域大小”的问题（R 中最常见的内核问题）
x &lt;- seq(min(ID.datasp@coords[,1]) - 2000,
max(ID.datasp@coords[,1]) + 2000,
by = 10.) # 分辨率是您想要的像素大小
y &lt;- seq(min(ID.datasp@coords[,2]) - 2000,
max(ID.datasp@coords[,2]) + 2000,
by = 10.)
xy &lt;- expand.grid(x = x, y = y)
coordinates(xy) &lt;- ~ x + y
gridded(xy) &lt;- TRUE

kernel.try &lt;- tryCatch(kernelUD(ID.datasp, h = htry[l], grid = xy), error = function(err) NA) 
areatoh.df[l, 2] &lt;- tryCatch(getverticeshr(kernel.try, percent = 50)$area, error = function(err) NA)
}
}
# 构建一个 loess 模型，根据 h 预测面积
x &lt;- areatoh.df$area[!is.na(areatoh.df$h) &amp; !is.na(areatoh.df$area)]
y &lt;- areatoh.df$h[!is.na(areatoh.df$h) &amp; !is.na(areatoh.df$area)]
area.h.loess &lt;- loess(y~x)

# 预测正确的 h
hpred[i] &lt;- predict(area.h.loess, newdata = tracking.mcp[i,]$area)
print(hpred[i])
}
return(hpred)
}

reptile50.kd.homerange.fn 50% 的 Homerange 轮廓
 reptile50.kd.homerange.fn &lt;- function(trackingdatasp, hvector){
newkernel.poly &lt;- list()
for(i in 1:length(unique(trackingdatasp@data$ID))){
# 为单个 ID 定义空间点层 &lt;- sort(unique(trackingdatasp@data$ID))[i]
ID.datasp &lt;- trackingdatasp[trackingdatasp$ID == ID, &quot;ID&quot;]

#创建新内核
newkernel &lt;- tryCatch(kernelUD(ID.datasp, h = hvector[i]), error = function(err) NA)
# 从多边形列表中提取顶点
newkernel.poly[[i]] &lt;- tryCatch(getverticeshr(newkernel, percent = 50), error = function(err) NA)
if(is.na(newkernel.poly[i])){
# 定义网格
# 这样可以避免&quot;网格太小，无法估计家域大小&quot; 的问题（R 中最常见的内核问题）
x &lt;- seq(min(ID.datasp@coords[,1]) - 2000,
max(ID.datasp@coords[,1]) + 2000,
by = 10.) # 分辨率是您想要的像素大小
y &lt;- seq(min(ID.datasp@coords[,2]) - 2000,
max(ID.datasp@coords[,2]) + 2000,
by = 10.)
xy &lt;- expand.grid(x = x, y = y)
coordinates(xy) &lt;- ~ x + y
gridded(xy) &lt;- TRUE
#创建新内核
newkernel &lt;- tryCatch(kernelUD(ID.datasp, h = hvector[i], grid = xy), error = function(err) NA)
# 提取多边形列表内的顶点
newkernel.poly[[i]] &lt;- tryCatch(getverticeshr(newkernel, percent = 50), error = function(err) NA)
}
}
return(newkernel.poly)
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/659372/kernel-density-estimator-in-rstudio-why-do-i-have-na-for-bandwidth</guid>
      <pubDate>Mon, 30 Dec 2024 16:30:31 GMT</pubDate>
    </item>
    <item>
      <title>“AUROC 曲线”这个术语实际上是否正确且有意义？</title>
      <link>https://stats.stackexchange.com/questions/659370/is-the-term-auroc-curve-actually-correct-or-meaningful</link>
      <description><![CDATA[15 年前，当我进入机器学习领域时，我了解到 AUC 代表“曲线下面积”，即“ROC 曲线下面积”，而 ROC 是“接收者操作特性”。
现在我自己在指导学生，（当然）他们有时会根据他们首先阅读的文献和资料使用不同的术语。我听说过 AUROC，根据这里的一些观点，它比 AUC 更好，因为后者没有指定指的是哪条曲线，而且除了 ROC 之外还有其他可能。
但后来我读到 AUROC 曲线，它在很多层面上听起来都是错误的。 （我不是以英语为母语的人。）
您指的是曲线下的面积，即 AUC 或 AUROC，或曲线本身，即ROC 曲线，因此 AUROC 曲线对我来说真的没有意义。但是，通过 CV 搜索我发现它被使用了几次，但从未被更正或解决，例如

为什么 ROC 曲线和 AUC 值并不总是相关的？
如何解释抵押贷款拒绝/批准的 AUROC 曲线？
如何解释 AUROC分数？

所以，我的问题是：我在这里是对的还是过于迂腐？还是忽略了一些显而易见的东西？]]></description>
      <guid>https://stats.stackexchange.com/questions/659370/is-the-term-auroc-curve-actually-correct-or-meaningful</guid>
      <pubDate>Mon, 30 Dec 2024 15:26:49 GMT</pubDate>
    </item>
    <item>
      <title>SPSS中Fisher精确检验的2*3的奇怪结果</title>
      <link>https://stats.stackexchange.com/questions/659363/weird-results-of-23-of-fishers-exact-test-in-spss</link>
      <description><![CDATA[我有两个分类变量：年龄组（4岁，8岁）和干预措施（低，中，高）。我想检查两个年龄组之间的干预措施差异，因为期望值小于5个单元格。我在SPSS 27中执行了Fisher检验，并通过了z检验（Bonferroni校正）。
1、结果似乎很奇怪。从图表中我们可以看到，在4岁组中，有11个孩子选择了“低”，有15个孩子选择了“中”，这些单元格的下标分别为“a”和“b”。这表明4岁的孩子倾向于喜欢“中”而不是“低”。然而，让我感到困惑的是，只有4个孩子选择了“高”选择“中”的儿童有15人，但这两个单元格的下标“b”相同，说明两种干预方式对4岁儿童的选择没有显著差异。为什么呢？从比例上看，选择“中”和“高”的儿童人数差异显然更大。
2、我用R语言对我的数据进行了多项逻辑回归分析，结果显示，在4岁儿童中，选择“中”的儿童多于选择“高”，但“低”和“中”之间以及“低”和“高”之间没有差异。这两种方法得到的结果不一致，让人很困惑。为什么？
我查阅了相关资料，发现Fisher精确检验可能更适合小样本，而logistic回归更适合大样本。由于我的样本只有60个，我推测Fisher精确检验可能更适合我的分析（我不确定这是否正确）。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659363/weird-results-of-23-of-fishers-exact-test-in-spss</guid>
      <pubDate>Mon, 30 Dec 2024 09:41:21 GMT</pubDate>
    </item>
    <item>
      <title>如果我们知道总体分布不正常，那么创建参考 Z 分布的置信区间是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/659299/does-it-make-sense-to-create-a-confidence-interval-referencing-the-z-distributio</link>
      <description><![CDATA[我正在学习生物学学位的入门统计学课程，在学习生成总体均值的置信区间时，我开始怀疑，如果我们知道原始总体不服从正态分布，这样做是否有意义。据我所知，CLT 在这种情况下没有任何效用，因为我们关心的是创建一个置信区间，其假定机会与原始概率分布（即总体的概率分布）一致。
我遗漏了什么吗？如果没有，评估引用此类理论分布来构建置信区间的正确性的程序是什么？
澄清编辑：
我不是在问 CLT 对抽样分布及其估计量的影响，而是在我们知道总体根本不服从正态分布的情况下，使用渐近正态抽样分布对总体参数进行推断的效用。因此，我的问题是：当抽样分布具有如此不同的分布概率，以至于两个分布看起来完全不同时，我们如何使用正态抽样分布来尝试估计非正态总体的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/659299/does-it-make-sense-to-create-a-confidence-interval-referencing-the-z-distributio</guid>
      <pubDate>Sat, 28 Dec 2024 15:19:07 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SPSS 对重复测量方差分析中的两个受试者内因素进行事后分析</title>
      <link>https://stats.stackexchange.com/questions/659256/how-to-perform-post-hoc-analysis-of-interactions-in-repeated-measures-anova-with</link>
      <description><![CDATA[我目前正在对两个受试者内因素进行重复测量方差分析。分析结果显示存在显著的相互作用，我添加了以下命令进行事后分析：
/EMMEANS=TABLES(IV1*IV2) COMPARE(IV1) ADJ(BONFERRONI)
虽然结果显示存在显著影响，但我对分析结果存有疑虑，因此寻求建议。
当我将此命令的结果与配对 t 检验（未校正）的结果进行比较时，配对 t 检验的值与 SPSS 命令生成的结果相同。这让我怀疑 Bonferroni 校正可能未正确应用。
我使用的命令可能存在问题？如果存在，那么在 SPSS 中正确应用 Bonferroni 校正的正确命令是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659256/how-to-perform-post-hoc-analysis-of-interactions-in-repeated-measures-anova-with</guid>
      <pubDate>Fri, 27 Dec 2024 05:17:56 GMT</pubDate>
    </item>
    <item>
      <title>ELI5：PCA 和时间序列（股票）数据以及分数和载荷的含义 [重复]</title>
      <link>https://stats.stackexchange.com/questions/659204/eli5-pca-and-timeseries-stock-data-and-the-meanings-of-scores-and-loadings</link>
      <description><![CDATA[我尝试使用 PCA 对时间序列数据（一段时间内的股票收盘价）进行聚类。到目前为止，我所做的是：

获取大量股票的数据（每列代表一只股票，每行代表一个观察值）
规范化数据
获取系数矩阵
对矩阵进行 pca

我现在的步骤是了解结果，尤其是分数和载荷，并使用它来对股票进行聚类，而不是对观察值进行聚类。
虽然我读了很多书，也和 chatGPT 讨论了很多这个话题，但我就是搞不懂在这种情况下载荷和分数的含义，以及这些值中的哪些可以帮助我进行聚类。一旦我得到这个，我就可以简单地使用像 k-means 聚类这样的聚类机制来完成最后的实际步骤。
所以基本上我的问题是：你能解释一下我的例子中分数和负载的含义以及它们的用途吗？
编辑：读了你的评论后，我清楚地意识到，我缺乏对分数的一般了解。遗憾的是，即使阅读了其他帖子的建议答案，我还是无法理解，所以我只会展示我的问题，并希望有人能直接解释它
使用正常数据的 PCA 结果：

基本上，我对我的时间序列数据进行了 pca（每列包含 1 股的时间序列数据）并得到了这个结果。对我来说，载荷（左侧）完全没问题，但显示分数的图表显示的是每个观察值，而不是每个份额
使用转置数据的 PCA 结果：

在这里，我对转置数据做了同样的事情，因此每行都包含有关份额的时间序列信息。因此，载荷是针对每个观察值进行的，但分数图向我展示了每个份额。
由于我的目标是对份额（而不是观察值）进行聚类，并分析结果，因此我想要载荷和份额的分数图。
那么，ELI5，请问这有什么数学原因吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659204/eli5-pca-and-timeseries-stock-data-and-the-meanings-of-scores-and-loadings</guid>
      <pubDate>Wed, 25 Dec 2024 21:28:19 GMT</pubDate>
    </item>
    <item>
      <title>当结果是二进制时，我们是否可以在双重机器学习的第一阶段使用分类器来估计结果？</title>
      <link>https://stats.stackexchange.com/questions/623586/are-we-allowed-to-use-classifiers-to-estimate-the-outcome-in-the-first-stage-of</link>
      <description><![CDATA[当结果是连续时，我很清楚该如何进行，因为 EconML 和我查阅的所有其他参考资料都适用于这种类型的例子（连续结果情况）。我们只需应用回归量来估计它。但是当结果是二进制时，我们应该/可以使用分类器吗？
当处理是离散的时，似乎，是的，我们是允许的，因为这正是 EconML 文档中 LinearDML 类的默认选项。

model_t（估计器或“自动”，默认“自动”）- 用于将处理拟合到特征的估计器。如果是估计器，它必须实现拟合和预测方法；如果是‘auto’，LogisticRegressionCV 将用于离散处理，而 WeightedLassoCV/WeightedMultiTaskLassoCV 将用于连续处理。

然而，第一阶段的结果模型却并非如此。如果我们不允许使用分类器，那么根本原因是什么？我将非常感激有关这个主题的参考资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/623586/are-we-allowed-to-use-classifiers-to-estimate-the-outcome-in-the-first-stage-of</guid>
      <pubDate>Wed, 09 Aug 2023 13:03:22 GMT</pubDate>
    </item>
    <item>
      <title>使用引导法评估模型稳定性</title>
      <link>https://stats.stackexchange.com/questions/613924/evaluating-model-stability-using-bootstrapping</link>
      <description><![CDATA[我需要以下方面的帮助。
使用我们为外部客户提供的替代数据，我们建立了一个识别欺诈客户（分类）的模型。
我们使用自动机器学习包得出最佳模型，并通过对没有目标的客户保留数据进行评分来返回结果。
现在，客户希望我们通过执行 50 次引导来检查模型稳定性，我们不确定如何在引导后对稳定性进行基准测试。
任何有关此方面的指导都将不胜感激。
注意：客户来自一家银行机构。]]></description>
      <guid>https://stats.stackexchange.com/questions/613924/evaluating-model-stability-using-bootstrapping</guid>
      <pubDate>Mon, 24 Apr 2023 10:55:29 GMT</pubDate>
    </item>
    </channel>
</rss>