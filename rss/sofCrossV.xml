<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 15 Jan 2024 21:14:01 GMT</lastBuildDate>
    <item>
      <title>构建 MLE 渐近方差的估计量并找出其渐近分布</title>
      <link>https://stats.stackexchange.com/questions/636938/construct-an-estimator-for-the-asymptotic-variance-of-the-mle-and-nd-its-asympto</link>
      <description><![CDATA[
这是我在学习统计推断和数据分析时遇到的一个问题。
我想我已经能够解决问题（a）和（b）了。
我的解决方案是：
$$
\hat{p}_{MLE} = \frac{n}{n + \sum_{i=1}^n x_i} = \frac{1}{1+\bar{x}_n}
$$
$$
\sqrt{n}(\hat{p}_{MLE} - p) \rightarrow N(0,\frac{1}{I_n(p)})
$$
和
$$
I_n(p) = \frac{1}{p^2(1-p)}
$$
但是，我不知道如何解决问题（c）和（d）。
有人可以帮我解决这个问题吗？
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/636938/construct-an-estimator-for-the-asymptotic-variance-of-the-mle-and-nd-its-asympto</guid>
      <pubDate>Mon, 15 Jan 2024 20:55:00 GMT</pubDate>
    </item>
    <item>
      <title>如何将仪器的质量与 OLS 结果进行比较？我们应该关心什么？尺寸、标志等[关闭]</title>
      <link>https://stats.stackexchange.com/questions/636935/how-to-compare-the-quality-of-an-instrument-wrt-to-the-ols-results-what-should</link>
      <description><![CDATA[我想知道如何比较乐器的质量。我们是否应该关心大小、符号等？
谁能告诉我 IV 和 OLS 之间的比较如何帮助了解 IV 的质量？]]></description>
      <guid>https://stats.stackexchange.com/questions/636935/how-to-compare-the-quality-of-an-instrument-wrt-to-the-ols-results-what-should</guid>
      <pubDate>Mon, 15 Jan 2024 18:27:16 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.metrics.r2_score 与 sklearn.LinearRegression.score</title>
      <link>https://stats.stackexchange.com/questions/636933/sklearn-metrics-r2-score-vs-sklearn-linearregression-score</link>
      <description><![CDATA[我正在使用 sklearn 来计算 X（真实年龄）和 Y（预测年龄）之间的决定系数。但是我为两种不同的方法获得了两个不同的值，据我所知，这应该是相同的。
这是直线拟合的数据。 （我知道这不太适合，但在研究模型架构之前我正在研究管道）

然后，尝试计算 R2 值，检查两种不同的方法。我做错了什么吗？
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt; Xs
数组([[6.80000000e+001],
       [7.50000000e+001],
       [5.90000000e+001],
       ...,
       [1.15882924e-310]，
       [1.15882924e-310]，
       [1.15882924e-310]]）
&gt;&gt;&gt;&gt;&gt;伊苏
数组([[58.503006],
       [67.75964],
       [63.875973],
       ...,
       [67.37394],
       [67.37394],
       [67.37394]]）
&gt;&gt;&gt;&gt;&gt;回归器=线性回归()
&gt;&gt;&gt;&gt;&gt;回归器.fit(Xs, Ys)
线性回归()
&gt;&gt;&gt;&gt;&gt;回归器.score(Xs, Ys)
0.006946203557267383
&gt;&gt;&gt;&gt;&gt; r2_score(Xs, Ys)
-0.16379061117029314
]]></description>
      <guid>https://stats.stackexchange.com/questions/636933/sklearn-metrics-r2-score-vs-sklearn-linearregression-score</guid>
      <pubDate>Mon, 15 Jan 2024 18:10:07 GMT</pubDate>
    </item>
    <item>
      <title>Keras 中一个二元向量与另一个二元向量的回归</title>
      <link>https://stats.stackexchange.com/questions/636928/regression-of-a-binary-vector-from-another-binary-vector-in-keras</link>
      <description><![CDATA[我正在尝试在 Keras 中建立 X 和 Y 之间的关系，其中 X= (1,30) 和 Y= (1, 10) .
我制作了模型，从X预测Y。我在生物学领域工作，我想通过预测Y的二元向量X 准确度 (90%)。
我将解释模式：X 是长度为 n 的二进制向量（例如，X(1,:) = [0/1, 0/1, ..., 0 /1]）。
Y 是长度为 m 的二元向量，其中 m  n（例如，Y(1,:) = [0/1, 0/1, ..., 0/1]）。
对于每个 X =&gt;是
数据是这样的：例如样本：
X = [1,0,1,1,1,0,1,0,1,0,1,1,0,1] 及其 Y=[0,1,1,1, 1,0,1]

我的目标是开发一种机器学习模型 M，它可以根据向量 X 预测向量 Y，准确度高于 90%。我只接受 1 位错误！不多了。
我的问题，我应该使用的最佳成本函数和损失函数是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/636928/regression-of-a-binary-vector-from-another-binary-vector-in-keras</guid>
      <pubDate>Mon, 15 Jan 2024 17:06:33 GMT</pubDate>
    </item>
    <item>
      <title>基于直方图的数据驱动的分箱条件方法</title>
      <link>https://stats.stackexchange.com/questions/636923/data-driven-approach-to-binning-conditions-based-on-a-histogram</link>
      <description><![CDATA[（请注意，目前这都是假设，数据细节应该不那么重要）。
假设我有一个数据集，其中参与者花费了一定的时间来完成任务（下面的 x 轴）。这些参与者自然地大致分为两组：用时约 4 秒的组和用时约 11 秒的组。如果我想将参与者标记为“慢”或“慢”或“快”，我怎样才能合理地做到这一点？这种分箱方式叫什么？我应该从阅读哪些论文开始？等等
就这个问题而言，假设分组是有意义的，并且我很清楚导致它的原因。
]]></description>
      <guid>https://stats.stackexchange.com/questions/636923/data-driven-approach-to-binning-conditions-based-on-a-histogram</guid>
      <pubDate>Mon, 15 Jan 2024 16:07:43 GMT</pubDate>
    </item>
    <item>
      <title>什么时候应该控制协变量？</title>
      <link>https://stats.stackexchange.com/questions/636922/when-should-one-control-for-covariates</link>
      <description><![CDATA[假设要估计下面因果图中 X 对 Y 的影响

是否应该将 Z 作为协变量（以及为什么/为什么不？）
例如，假设有人想要估计性别对力量的影响。为了举例说明，我们假设男性平均身高高于女性。
在估计性别对力量的影响时是否应该使用身高作为协变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/636922/when-should-one-control-for-covariates</guid>
      <pubDate>Mon, 15 Jan 2024 16:04:10 GMT</pubDate>
    </item>
    <item>
      <title>SEM，无潜变量的路径分析</title>
      <link>https://stats.stackexchange.com/questions/636919/sem-path-analysis-without-latent-variables</link>
      <description><![CDATA[如果中介分析仅包括观察到的变量，是否有必要在路径分析之前测试测量模型并进行 CFA？
除了假设之外，是否建议在路径分析本身之前进行其他分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/636919/sem-path-analysis-without-latent-variables</guid>
      <pubDate>Mon, 15 Jan 2024 15:24:35 GMT</pubDate>
    </item>
    <item>
      <title>分类变量的假设检验</title>
      <link>https://stats.stackexchange.com/questions/636915/hypothesis-testing-of-categorical-variable</link>
      <description><![CDATA[我从一份关于影响年轻毕业生就业能力的因素的调查问卷中提取了数据。问卷是由我班的学生回答的，所以我提取了他们的年龄、专业以及他们对我所做的一堆陈述的同意程度。将excel数据表中的数据导入R后，我进行了编码（将一致性程度转换为李克特量表），现在我想测试一些假设。
因此，在答案的数据框中，我们有这些成员代表与引号之间的每个命题的一致程度：
X1 =“缺乏专业经验是年轻毕业生就业的主要障碍。”
X2 =“年轻毕业生更有可能面临失业、不稳定和就业市场歧视。”
X3 =“就业市场在不断发展，新工作的出现和其他工作的消失。”
X4 =“年轻毕业生必须能够适应这些变化并培养满足就业市场需求所需的技能。”
X5 =“人口统计数据的变化将对就业市场产生重大影响。”
Y1 =“软技能对于年轻毕业生的专业融入至关重要。”
Y2 =“软技能包括沟通、协作、解决问题、批判性思维、适应能力和复原力。”
Y3 =“拥有软技能的年轻毕业生更有可能在工作和职业生涯中取得成功。”
Y4 =“雇主正在寻找能够团队合作、解决问题并适应变化的员工。”
Y5 =“软技能可以随着时间的推移而发展和提高。”
Z1 =“年轻毕业生的专业融入是摩洛哥的一项重大挑战。”
Z2 =“有利于年轻毕业生融入的因素包括经济增长、教育水平提高以及公共政策的实施。”
Z3 =“不利于年轻毕业生融入的因素包括失业率高、竞争加剧以及缺乏合适的培训。”
Z4 = “对于那些准备充分并具备必要技能的年轻毕业生来说，融入是可能的。”
Z5 =“激烈的竞争以及教育与就业之间的不匹配是摩洛哥年轻毕业生融入社会的具体挑战。”
我试图检验的假设如下：
H1：认识到软技能在专业整合背景下的重要性是一个重要的认识。
H2：激烈的竞争以及教育与就业的不匹配是年轻毕业生融入社会的挑战。
H3：专业经验是就业的重大障碍。
我的问题是，同时我没有二分变量“可以使用”的数据集，我该使用什么类型的统计模型来完成我的工作？我可以使用什么类型的测试来检查我的假设的有效性？
谢谢大家！]]></description>
      <guid>https://stats.stackexchange.com/questions/636915/hypothesis-testing-of-categorical-variable</guid>
      <pubDate>Mon, 15 Jan 2024 14:27:46 GMT</pubDate>
    </item>
    <item>
      <title>将中值绝对偏差转换为标准偏差[关闭]</title>
      <link>https://stats.stackexchange.com/questions/636914/converting-median-absolute-deviation-to-standard-deviation</link>
      <description><![CDATA[我正在从事一些医学研究，我想知道将中位数和中位数绝对偏差 (MAD) 转换为平均值和标准差的最直接方法是什么。
如果有人有任何链接以及我可以引用的来源链接，这将非常有帮助。
我需要转换的原因是因为我正在使用 RevMan 进行基于其他研究的荟萃分析，一些研究具有均值和 SD，而另一些研究具有中位数和 MAD，我希望能够将它们全部包含在一项统计中分析。
我已经看到了一些关于数据是否呈正态分布的事情，不幸的是，我没有原始数据，因为我正在对其他研究进行荟萃分析，所以我不知道我是否可以假设它是正态分布的？]]></description>
      <guid>https://stats.stackexchange.com/questions/636914/converting-median-absolute-deviation-to-standard-deviation</guid>
      <pubDate>Mon, 15 Jan 2024 14:04:44 GMT</pubDate>
    </item>
    <item>
      <title>Filter_values 参数 - R 中的拓扑数据分析</title>
      <link>https://stats.stackexchange.com/questions/636889/filter-values-argument-topological-data-analysis-in-r</link>
      <description><![CDATA[我最近一直在尝试在 R 中使用一些 TDA（拓扑数据分析），但我发现的一个限制是“filter_values”的选择。论证。
我的理解是，他们通常使用 X 轴（或 Y 轴）的范围作为“filter_values”。争论，但我没有成功。
这是一个已发布的示例：
devtools::install_github(“paultpearson/TDAmapper”)
devtools::install_github(“christophergandrud/networkD3”)

库（TDAmapper）
图书馆（igraph）

＃数据

n_x &lt;- c(rep(-.5,101),0.01*(-50:50),rep(.5,101))
n_y &lt;- c(0.02*(-50:50),-0.02*(-50:50),0.02*(-50:50))

d_x &lt;- c(代表(-0.9,101),0.02*(-50:25),0.02*(-50:25),
         0.4+sqrt(0.5^2-(0.01*(-50:50))^2))
d_y &lt;- c(0.01*(-50:50),rep(0.5,76),rep(-0.5,76),
         0.01*(-50:50))

nd &lt;- data.frame(x=c(n_x,d_x),y=c(n_y,d_y))
情节（nd）

#MAPPER 示例 - 过滤值参数

m &lt;-mapper1D(
     距离矩阵 = dist(nd),
     过滤值 = c(n_x,d_x),
     间隔数 = 10,
     重叠百分比 = 50,
     num_bins_when_clustering = 10)


但是，我想知道是否有人可以帮助我在概念上选择 filter_values 参数，例如下面所示的试验数据？
因此，正如@Whuber 所强调的那样。我的担忧是概念性的。 TDA 中选择 filter_values 的通用经验规则可能适用于下面的玩具数据集。
玩具数据集的数据范围是 1:3（并且更符合我自己的数据特征）。
将不胜感激。
x1 = 重复(1:3, 次数 = 100)
x2 = 重复(1:3, 次数 = 100)
x3 = 重复次数(1:3, 次数 = 100)
x4 = 重复(1:3, 次数 = 100)
x5 = 重复(1:3, 次数 = 100)

DAT &lt;- data.frame(x1, x2,x3,x4,x5)

非常感谢。
链接
https://www.justinmath.com/mapper-software- tdamapper 演示/
https://tianshufeng.github.io/STA/index.html ]]></description>
      <guid>https://stats.stackexchange.com/questions/636889/filter-values-argument-topological-data-analysis-in-r</guid>
      <pubDate>Mon, 15 Jan 2024 10:06:05 GMT</pubDate>
    </item>
    <item>
      <title>验证二维正态分布的均值和协方差估计量</title>
      <link>https://stats.stackexchange.com/questions/636875/verifying-mean-and-covariance-estimators-of-a-two-dimensional-normal-distributio</link>
      <description><![CDATA[在这里，我尝试验证二维正态分布的均值和协方差矩阵的估计量 $N(\mu, A)$ 和 $\mu=[-2,3]^T$ 和 $A=\begin{pmatrix}
5&amp; 11\\
11&amp; 25
\end{pmatrix}$.
设 $\{x_i\}_{i=1}^n$ 为独立同分布。来自 $N(\mu, A)$ 的样本。这里我的估计量由 $\hat{\mu}=\sum_{i=1}^n x_i/n$ 和 $\hat{A}=\sum_{i=1}^n(x_i- \hat \mu)(x_i-\hat \mu)^T/(n-1)$。。 p&gt;
我的问题是我的结果与真实值相差很大...这是正常现象吗？
这是我的代码和输出：
将 numpy 导入为 np
np.随机.种子(123)
定义数据（n）：
  mu=np.array([-2.0,3.0])
  A=np.array([[1.0,2.0],[3.0,4.0]])
  X=np.random.normal(大小=n*2)
  X=X.reshape((n,2))
  X=(X+mu).点(A)
  返回(X.T)

数据 = 数据(10000)

mu_hat = np.mean(数据, 轴=1)
sigma_hat = np.cov（数据）

输出如下：
mu_hat=[7.02352613 8.04361423]

&lt;前&gt;&lt;代码&gt;A_hat=[[10.11067835 14.20627231]
 [14.20627231 20.35677073]]

我还检查了 MSE，如下所示：
平均值的 MSE：53.43103419753712
协方差矩阵的 MSE：17.05974388551374
]]></description>
      <guid>https://stats.stackexchange.com/questions/636875/verifying-mean-and-covariance-estimators-of-a-two-dimensional-normal-distributio</guid>
      <pubDate>Mon, 15 Jan 2024 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>我的线性混合效应模型应该是什么样子？</title>
      <link>https://stats.stackexchange.com/questions/636855/how-my-linear-mixed-effect-model-should-look-like</link>
      <description><![CDATA[我想要使用名为“PhiPS2”的响应变量以及栖息地、季节和物种等自变量来拟合线性混合效应模型。但是，我不确定这些自变量中的哪一个应该是随机效应。
实验设计如下 - PhiPS2 在来自不同栖息地的不同植物中进行测量。不同的栖息地有不同的物种，但很少有物种出现在多个栖息地。我总共有 310 株植物，包括来自 5 个不同栖息地的 10 个物种。 10 个物种中有 3 个出现在多个栖息地（10 个物种，5 个重复，5 个栖息地类型，4 次（6 月至 9 月 = 季节））。不存在伪复制，因为每次都是从同一栖息地测量不同的植物个体。
我希望找到以下问题的答案：

PhiPS2 值如何随栖息地季节性变化（我认为应考虑物种变异，因为它解释了很大一部分变异。
不同栖息地的每个物种的 PhiPS2 值随季节变化的情况。

也许存在部分交叉随机效应。没有把握。请建议该模型拟合的 R 代码。以下是一些候选模型：
第一个模型
M1 &lt;- lmer(PhiPS2 ~ 栖息地 + 季节 + (1|物种)，REML = F，数据 = phyio2)

第二个模型
M2 &lt;- lmer(PhiPS2 ~ 栖息地 * 季节 + (1|物种)，REML = F，数据 = phyio2)

第三种模型
M3 &lt;- lmer(PhiPS2 ~ 栖息地 * 季节 + (1 + 物种|栖息地), REML = F, 数据 = phyio2)
]]></description>
      <guid>https://stats.stackexchange.com/questions/636855/how-my-linear-mixed-effect-model-should-look-like</guid>
      <pubDate>Sun, 14 Jan 2024 20:53:28 GMT</pubDate>
    </item>
    <item>
      <title>使用预定义系数拟合 glmmTMB 模式</title>
      <link>https://stats.stackexchange.com/questions/636792/fitting-a-glmmtmb-mode-with-pre-defined-coefficients</link>
      <description><![CDATA[我正在开展一项分析，其中使用 glmmTMB 进行多模型推理和模型平均，我将其用于有序 beta 分布，并且我想坚持使用。我挖掘了全局模型，采用了 95% 的置信度集，并计算了每个预测变量的平均系数。然而现在，我想弄清楚这个平均模型对数据的解释效果如何。有没有办法用预定义的系数制作或拟合模型对象？然后我会在 k 折交叉验证和/或 Performance::r2 中使用它，但无论哪种方式我都需要一个模型对象。
这是一个例子：
数据 = data.frame(响应 = c(0.5, 0.2, 0, 1, 0.75),
         varA = c(0, 0.2, 0.4, 1, 0.8),
         varB = c(-0.4, -1.3, 0.3, 1.6, 0.8),
         varC = c(-1.2, -0.1, 0.5, 1.2, -0.3))

模型 &lt;- glmmTMB(响应 ~ varA + varB + varC,
                 family = glmmTMB::ordbeta(link = &quot;logit&quot;),
                 数据=数据）

model_dredge &lt;- MuMIn::dredge(模型)

#找到 95% 置信度的截止值
值 &lt;- 0

for (i in 1:nrow(model_dredge)){
  如果（值&lt;0.95）{
    值 &lt;- 值 + as.numeric(model_dredge$weight[i])
    model_cutoff &lt;- i
  } 别的 {}
}

conf_set &lt;- model_dredge[1:model_cutoff, ]

varA_coeff &lt;- stats::weighted.mean(conf_set$`cond(varA)`,
                               conf_set$权重，
                                   na.rm = T)
varB_coeff &lt;- stats::weighted.mean(conf_set$`cond(varB)`,
                               conf_set$权重，
                                   na.rm = T)
varC_coeff &lt;- stats::weighted.mean(conf_set$`cond(varC)`,
                               conf_set$权重，
                                   na.rm = T)

最终，我得到了一组与我的全局模型相似但不同的系数。我考虑进入全局模型对象并手动覆盖对象中的可变系数（例如， model$fit$par[1] 是截距，model$fit$par[2 ] 是 varA，等等。）但是，还有其他参数我不知道如何在不使用新平均系数重新拟合模型的情况下获得，其中一个标记为“betad”和两个标记为“psi”的。
有人可以建议 a) 如何使用 varA_coeff、varB_coeff 和 varC_coeff 拟合模型，b) 如何计算出“betad”和“psi”无需重新拟合模型，或者 c) 评估平均模型拟合度的替代方法？
真诚的，
科琳娜]]></description>
      <guid>https://stats.stackexchange.com/questions/636792/fitting-a-glmmtmb-mode-with-pre-defined-coefficients</guid>
      <pubDate>Sat, 13 Jan 2024 21:19:04 GMT</pubDate>
    </item>
    <item>
      <title>如何对重复测量的数据进行混合效应模型？</title>
      <link>https://stats.stackexchange.com/questions/636649/how-to-perform-mixed-effect-model-for-data-with-repeated-measurements</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636649/how-to-perform-mixed-effect-model-for-data-with-repeated-measurements</guid>
      <pubDate>Thu, 11 Jan 2024 14:09:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么线性和样条项估计如此不同？</title>
      <link>https://stats.stackexchange.com/questions/636570/why-are-linear-and-spline-term-estimates-so-different</link>
      <description><![CDATA[我正在流行病学环境中进行建模。我想估计一次暴露（空气污染）和两个事件结果之间的关联。为了实现这一目标，我使用了具有时变暴露的 Cox PH 模型（我使用 R 中的survival 包）。
我定义了两个主要模型：

线性：coxph(Surv(time1, time2, event) ~ 协变量 + 曝光)
样条线：coxph(Surv(time1, time2, event) ~ 协变量 + pspline(exposure, df=4))

线性模型的估计关联通过暴露量增加 5 个单位来显示：

结果 1：HR= 1.21（95% 置信区间 = 1.03-1.43）
结果 2：HR= 1.22（95% 置信区间 = 1.00-1.50）

样条模型的估计关联如下所示，使用暴露的最低值（图中的 x）作为参考。

我不明白为什么尽管线性模型中的 HR 非常相似，但它们的曲线在样条模型中却如此不同。特别是，对于结果 1，我不明白当曲线大部分低于 1.00 时，线性 HR 为何会是 1.22，直到曝光量约为 12 (x $\approx$ 12)
HR 样条图的代码（由 Terry Therneau 简化和启发 教程）：
#数据提取
mod &lt;- coxph(Surv(time1, time2, event) ~ 协变量 + pspline(曝光, df=4), data=df)
pmterm &lt;- termplot(mod,terms = which(mod$pterms == 1),
                 se=真，图=假）
dtplot&lt;- list(pmterm = pmterm[[&quot;曝光&quot;]], 曝光 = df$曝光)

 
#数据格式化
 中心 &lt;- with(dtplot$spline, y[x==min(x)])
 ytemp &lt;- dtplot$样条$y + 外部(dtplot$样条$se, c(0, -1.96, 1.96), &#39;*&#39;)
 ytemp &lt;- exp(ytemp - center) #此行针对对数危险图进行了注释
 datspline &lt;- data.frame(cbind(dtplot$样条$x,ytemp))
 datexp&lt;- data.frame(dtplot$exp)
 名称(dat)&lt;-c(“exp”、“HR”、“低”、“上”)
 
#绘图
 ggplot(datspline, aes(x = exp)) +
 geom_line(aes(y=HR)) + geom_ribbon(aes(ymin=低, ymax=上),alpha = .1) +
 geom_histogram(aes(x=exp, y=10*(after_stat(密度))), binwidth=1,
        线宽=0，颜色=“firebrick3”，填充=“firebrick3”，alpha = 0.25，
        data=datexp) + #GEOM_HISTOGRAM 被排除在日志危险图之外
labs(title=paste0(“结果”,i), x = “暴露”, y = “HR (95% CI)”) + #y=“对数危险”对于对数危险图
主题_经典() +
geom_hline(yintercept = 1, lty = 2) + coord_cartesian(ylim = c(0,2.5)) #ylim=c(-0.5,0.5) 用于对数危险图
]]></description>
      <guid>https://stats.stackexchange.com/questions/636570/why-are-linear-and-spline-term-estimates-so-different</guid>
      <pubDate>Wed, 10 Jan 2024 11:29:09 GMT</pubDate>
    </item>
    </channel>
</rss>