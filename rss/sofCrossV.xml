<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 07 Jul 2024 21:15:00 GMT</lastBuildDate>
    <item>
      <title>ICC 和 Pearson r 相关性的解释</title>
      <link>https://stats.stackexchange.com/questions/650644/interpretation-of-icc-and-pearsons-r-correlation</link>
      <description><![CDATA[我正在计算两个不同时间点的响应值的组内相关系数 (ICC) 值。我还使用 Pearson&#39;s r 对不同时间点的响应值进行关联。得出的值几乎相同。这在概念上有意义吗？
TIA！]]></description>
      <guid>https://stats.stackexchange.com/questions/650644/interpretation-of-icc-and-pearsons-r-correlation</guid>
      <pubDate>Sun, 07 Jul 2024 21:08:28 GMT</pubDate>
    </item>
    <item>
      <title>混合模型中日期作为随机效应会极大地改变系数估计</title>
      <link>https://stats.stackexchange.com/questions/650642/date-as-random-effect-in-mixed-model-strongly-changes-coefficient-estimates</link>
      <description><![CDATA[我正在努力弄清使用 lme4 运行的混合模型的结构。
我测量了一种行为（比如说反应时间）和另一个可能影响它的变量（我们称之为“情绪”，以 0 到 1 的尺度来衡量）。我在大约 4 个月的时间内每四天对 10 个人进行一次测量。所有个人每天都进行测量（几乎如此 - 只是有些人比其他人更早退出）。而且它不仅仅是每个 ID/每天一个数据点，而是实际上几百个数据点，因为它是通过连续监测获得的。
我并没有真正期望时间（日期）的影响，但无论如何倾向于“控制”其中的一些变化，这就是为什么我尝试将其添加为随机效应。
现在发生的事情让我意想不到，情绪对反应时间的影响最初非常强烈，但当我添加日期时完全消失了。我从未见过随机效应会如此大地改变系数的估计值，我真的很难理解为什么会发生这种情况。
不幸的是，我无法分享数据，因此现在细节是编造的，但我正试图使用​​ sleepstudy 数据来说明我的模型结构。
#将情绪变量添加到其中：
sleepstudy$mood &lt;- rnorm(180, mean=0.6, sd=0.15)
#还拟合二次关系
sleepstudy$mood &lt;- sleepstudy$mood^2

#拟合模型：
model &lt;-lmer(Reaction ~ mood + mood2 + (1|Subject) + (1|Days), data=sleepstudy)

因此，当我用实际数据（那里的变量）拟合此模型时重命名以适合示例），这是我得到的没有天数随机效应的模型的输出：
REML 拟合的线性混合模型。t 检验使用 Satterthwaite 的方法 [&#39;lmerModLmerTest&#39;]
公式：反应 ~ 情绪 + 情绪 2 + (1 | 主题)
数据：studyData

收敛时的 REML 标准：1049575

缩放残差：
最小 1Q 中位数 3Q 最大值
-3.8816 -0.6241 -0.0833 0.5268 8.1988

随机效应：
组名称方差标准差
受试者（截距）111.8 10.57 
残差 675.7 25.99 
观察数：112205，组：受试者，9

固定效应：
估计标准误差 df t 值 Pr(&gt;|t|) 
（截距）12.844 3.651 9.158 3.518 0.00637 ** 
情绪 77.045 3.263 112198.749 23.613 &lt; 2e-16 ***
情绪2 -53.922 2.687 112197.946 -20.065 &lt; 2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应的相关性：
（内部）情绪
情绪 -0.256
情绪2 0.246 -0.988

当我添加天数时，它变成了这样：
REML 拟合的线性混合模型。 t 检验使用 Satterthwaite 的方法 [&#39;lmerModLmerTest&#39;]
公式：反应 ~ 情绪 + 情绪 2 + (1 | 受试者) + (1 | 天数)
数据：studyData
收敛时的 REML 标准：1018994
缩放残差：
最小值 1Q 中位数 3Q 最大值
-3.8348 -0.6387 -0.1259 0.4744 9.4342
随机效应：
组名称方差标准差
天数（截距）265.58 16.297
受试者（截距）92.37 9.611
残差 513.64 22.664
观察次数：112205，组：天数，26；主题，9

固定效应：
估计标准误差 df t 值 Pr(&gt;|t|) 
(截距) 37.6287 4.6169 26.0857 8.150 1.22e-08 ***
mood 2.3961 3.0378 112183.5499 0.789 0.430 
mood2 -0.7413 2.4628 112180.6597 -0.301 0.763 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应的相关性：
（内部）情绪
情绪 -0.192
情绪2 0.185 -0.988

所以我的问题是，什么可能导致这种强烈的变化，我可以做些什么来进一步探索它，最重要的是，哪个是模型的正确版本？
我确实绘制了随时间变化的变量，但我没有发现明显的趋势。任何帮助都将不胜感激。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/650642/date-as-random-effect-in-mixed-model-strongly-changes-coefficient-estimates</guid>
      <pubDate>Sun, 07 Jul 2024 19:14:33 GMT</pubDate>
    </item>
    <item>
      <title>一组可能相关的随机变量的平均值的方差是否小于它们各自方差的平均值？</title>
      <link>https://stats.stackexchange.com/questions/650638/is-the-variance-of-the-mean-of-a-set-of-possibly-dependent-random-variables-less</link>
      <description><![CDATA[一组可能相关的随机变量的均值的方差是否小于或等于它们各自方差的平均值？
从数学上讲，给定可能相关的随机变量$X_1, X_2, ..., X_n$：
设$\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i$为这些随机变量的均值。
以下说法是否正确：
$$\text{Var}(\bar{X}) \leq \frac{1}{n}\sum_{i=1}^n \text{Var}(X_i)$$
我知道对于独立随机变量，我们有以下等式：
$$\text{Var}(\bar{X}) = \frac{1}{n^2}\sum_{i=1}^n \text{Var}(X_i)$$
这显然满足不等式。但是，我不确定这是否适用于因变量。
如果这个不等式成立，是否有证明或直观的解释？
如果它并非总是成立，那么在哪些条件下它成立？以下不等式呢？
$$\text{Var}(\bar{X}) \leq \text{Max}_{i=1}^n \text{Var}(X_i)$$
任何见解、证明或反例都将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650638/is-the-variance-of-the-mean-of-a-set-of-possibly-dependent-random-variables-less</guid>
      <pubDate>Sun, 07 Jul 2024 15:39:10 GMT</pubDate>
    </item>
    <item>
      <title>预测比率的模型建议</title>
      <link>https://stats.stackexchange.com/questions/650637/model-suggestion-to-predict-a-ratio</link>
      <description><![CDATA[我有一个项目，其中有公司数据（一个变量是他们的客户数量以及他们是否有合规性问题）。我试图建立一个模型，以找到给定公司的员工与客户比率，从而最大限度地降低合规性问题的可能性。我拥有的标签属于一种情况（公司有合规性问题），但其余的则没有标签，好像他们没有任何问题，他们可能没事，或者只是尚未发现。我可以采取什么方法来建立一个模型，该模型将公司详细信息提供比率？任何想法或其他可供参考的工作都值得赞赏。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/650637/model-suggestion-to-predict-a-ratio</guid>
      <pubDate>Sun, 07 Jul 2024 14:36:10 GMT</pubDate>
    </item>
    <item>
      <title>通过引导抽样从每日数据中获取月度统计数据</title>
      <link>https://stats.stackexchange.com/questions/650636/bootstrap-sampling-to-get-monthly-statistic-from-daily-data</link>
      <description><![CDATA[我有历史冬季的每日 (iid) 数据：$d:$（价格、价值、温度等）。
“价值”实际上是“价格”和其他协变量的上凹函数。
我感兴趣的是查看一个月的价值，也就是 30 天的“价值”总和。所有数据都是 iid 的，并且每个月出现的可能性相同。
我的想法是从我的每日数据中抽取 10_000 个大小为 30 的样本并计算统计数据，并将其用作分布。我将历史数据用作实际每日分布 F 的离散分布近似值。
我已阅读了一些关于引导估计的证明，大多数都假设引导样本大小等于您的数据样本大小。我知道这对于矩等统计数据来说可能是必要的，但就我而言，使用这种不同的样本量是否合理？哪里可能出错？]]></description>
      <guid>https://stats.stackexchange.com/questions/650636/bootstrap-sampling-to-get-monthly-statistic-from-daily-data</guid>
      <pubDate>Sun, 07 Jul 2024 14:18:53 GMT</pubDate>
    </item>
    <item>
      <title>关于推导 MAP 估计量的基本问题</title>
      <link>https://stats.stackexchange.com/questions/650635/basic-question-about-deriving-map-estimator</link>
      <description><![CDATA[假设我们有一个随机过程$X(t, u)$，其由$t$和$u$参数化，并生成数据$x$。我们对 $u$ 也有一个先验，$p(u)$。
我说得对吗？找到 仅 $t$ 的最大后验 (MAP) 估计的表达式应该是
$$
t_{MAP} = \underset{t}{\operatorname{argmax}} \int p(x | t, u) p(u) du = \underset{t}{\operatorname{argmax}} p(x|t)
$$
也就是说，你会将干扰参数边缘化，对吗？
现在假设 $U\sim \mathcal{N}[\hat{u}, C_u]$ 和 $X \mid u, t \sim \mathcal{N}[M(t) u, C_x]$。
说 $p(x | t)$ 等于 $M(t) U$ 的 pdf 正确吗？也就是说，
$$X \mid t \sim \mathcal{N}[M(t)\hat{u}, M(t)C_uM(t)^\top]$$
换一种说法，更一般地说，推导出 $f(U, t)$ 的分布是否会得到与 $\int p(x|t, u)p(u)du$ 相同的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/650635/basic-question-about-deriving-map-estimator</guid>
      <pubDate>Sun, 07 Jul 2024 12:46:11 GMT</pubDate>
    </item>
    <item>
      <title>评估测试图像的最佳时期是什么时候？</title>
      <link>https://stats.stackexchange.com/questions/650634/what-is-the-best-epoch-to-evaluate-the-test-images</link>
      <description><![CDATA[我为图像分类任务创建了一个训练集、一个验证集和一个测试集。然后，我使用训练集进行训练，并对验证集进行评估。因此，下一步是评估测试集，基本上是为了推理。为了选择最佳的 epoch 模型，我通常会检查验证损失。但是，我不确定这种方式是否正确。我将结果添加为图片，并标记了最佳的 train/val 准确率和最低的 train/val 损失。损失函数是交叉熵。

后面的步骤显然是过度拟合，但训练损失仍然越来越低，直到第 25 个 epoch。如果我只检查 val 损失，我可能会选择第 13 个 epoch。或者最高的验证准确率也可能很重要。
我读过一些文章或论坛问题，比如这个、这个、这个和其他几个，但这个话题没有真正的结论。那么，对于这种情况，有没有通用的解决方案，或者我应该以不同的方式考虑每个分类/对象检测任务并做出相应的决定？]]></description>
      <guid>https://stats.stackexchange.com/questions/650634/what-is-the-best-epoch-to-evaluate-the-test-images</guid>
      <pubDate>Sun, 07 Jul 2024 12:16:32 GMT</pubDate>
    </item>
    <item>
      <title>主观信心作为回归模型中的权重</title>
      <link>https://stats.stackexchange.com/questions/650629/subjective-confidence-as-weights-in-regression-models</link>
      <description><![CDATA[我有数据，其中受试者在某个范围内对数量进行评分（$y$），但也添加了他们对选择的确定程度的主观信心（$w$）。我最初的想法是将$w$作为权重添加到回归模型中（暂时忽略如何对其进行规范化或标准化的问题）。我的上级要求检查$w$与方差之间的关系 - 指出如果它们与方差成反比，则应加入置信度。我们检查了非加权模型的平均绝对残差（作为方差的代理），发现较高置信度的残差与较低置信度的残差大致相同。我的上级得出结论，我们不应该使用置信度评级。
虽然我同意数据和模型似乎没有表明更高的置信度评级与更低的方差相关，但我仍然不相信这是使用权重的唯一原因。如果对某些数据点有很高的置信度，那么与其他置信度较低的数据点相比，它们是否应该有更多发言权来将回归线拉近它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/650629/subjective-confidence-as-weights-in-regression-models</guid>
      <pubDate>Sun, 07 Jul 2024 09:58:56 GMT</pubDate>
    </item>
    <item>
      <title>故意发表错误统计方法的著名例子有哪些？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650620/what-are-famous-examples-of-erroneous-statistical-methods-being-deliberately-pub</link>
      <description><![CDATA[是否有著名的错误统计方法发表的例子，作者从一开始就知道他们的方法是错误的，但故意隐瞒它？
例如，我想到的是人们试图测试某些期刊的同行评审过程的可靠性，或者在战争时期，出版物可能旨在鼓励敌人使用错误的方法。但我对其他可能的动机也很感兴趣。促使我提出这个问题的原因是，在社会科学中有几个这样的例子，所以我想知道它是否也发生在统计研究中。
我不认为有很多著名的例子（我从未听说过这样的案例，这就是我问这个问题的原因），因为隐藏方法不正确可能非常困难，所以我想问题的范围不是太广泛。]]></description>
      <guid>https://stats.stackexchange.com/questions/650620/what-are-famous-examples-of-erroneous-statistical-methods-being-deliberately-pub</guid>
      <pubDate>Sun, 07 Jul 2024 04:46:31 GMT</pubDate>
    </item>
    <item>
      <title>拆分数据然后进行回归是否合理？</title>
      <link>https://stats.stackexchange.com/questions/650613/is-it-reasonable-to-split-the-data-and-then-perform-the-regression</link>
      <description><![CDATA[有一家商店销售圆珠笔。我已从该商店获取每笔交易的数据，包括交易 ID、颜色、每笔交易的销售数量、总价等。通过将总价除以每笔交易数量，我计算出了每笔交易中每支笔的单价。我认为每支圆珠笔的单价与其颜色和每笔交易中购买的数量有关。因此，我将使用线性回归来检验这一假设：单价 = Alpha1 x 颜色 + Alpha2 x 数量 + Beta。
原始数据图像：

问题是，我可以在执行回归之前拆分这些数据吗？例如，在原始样本数据中，第一笔交易销售了 2 支圆珠笔，因此我将把它拆分为两个条目。拆分数据如下图所示，回归方程不变：单价 = Alpha1 x 颜色 + Alpha2 x 数量 + Beta。
拆分数据图片：

我的问题是：这个操作可以吗？会有什么影响，为什么？有相关参考吗？
我觉得这个操作可能不合理，比如反而增加了蓝色笔的数据权重。但是我对统计学的理解不够，无法清晰的表达出为什么或者怎么不合理。]]></description>
      <guid>https://stats.stackexchange.com/questions/650613/is-it-reasonable-to-split-the-data-and-then-perform-the-regression</guid>
      <pubDate>Sun, 07 Jul 2024 01:30:45 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 GMM 估计</title>
      <link>https://stats.stackexchange.com/questions/650611/gmm-estimation-in-r</link>
      <description><![CDATA[我正在尝试执行 GMM 估计，但在 R 中。在我的上下文中，我做了几个协方差限制。举一个简单的例子：$Var(y)=a$ 和 $Cov(y, Ly))=b$。现在的问题是，对于任何给定的数据集，可以制作这些样本等价物的观察次数对于两个矩将有所不同 () 通常，STATA 和 R 都会采用样本矩矩阵并通过除以 1/NT 或 1/N(T-1) 来找到平均值，但在这种情况下，这将不起作用！但是，在 STATA 中，可以使用 nocommonesample 选项来解决这个问题。我的问题是，R 中可用的等效选项或方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/650611/gmm-estimation-in-r</guid>
      <pubDate>Sat, 06 Jul 2024 23:46:26 GMT</pubDate>
    </item>
    <item>
      <title>解释交互术语</title>
      <link>https://stats.stackexchange.com/questions/650598/interpreting-interaction-term</link>
      <description><![CDATA[假设我有兴趣估计一种治疗（相对于对照）的效果，完全且有条件地基于基线特征（例如收入水平）的不同水平（例如 3）。我会进行如下回归（T 是治疗，I 是收入水平 1-3）：
$Y = a + b_1T + b_2T(x=1) + b_3T(x=2) + b_4T(x=3) + e$
我不确定我是否理解了三个交互项是与什么进行比较的：是“纯对照”还是 b1？换句话说，我们是否使用来自对照组的收入水平数据来运行此回归？或者我们只是将 b2、b3 和 b4 的结果与 b1 的结果进行比较？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650598/interpreting-interaction-term</guid>
      <pubDate>Sat, 06 Jul 2024 15:42:26 GMT</pubDate>
    </item>
    <item>
      <title>关于测试可靠性对测试组合权重的影响的问题</title>
      <link>https://stats.stackexchange.com/questions/650558/question-on-the-effect-of-test-reliability-on-weighting-of-a-test-battery</link>
      <description><![CDATA[最初，测试组件有 4 个部分：两个 100 项多项选择题测试、一个口语测试和一个论文测试。每个部分测量不同的主题。4 个部分中的每一个权重为 25%。
现在，每个多项选择题测试的测试长度已减少到 60 项（出于实际原因）。每个部分仍占 25%。
如果两个 MC 测试的可靠性降低到零，则两个 MC 测试测量的两个主题的权重将为零。（两个 MC 测试只会产生误差。）实际上，可靠性降低了，但并没有降低到零。
我的问题是，可靠性的变化对两个 MC 测试测量的两个主题的权重有何影响。我如何估计由于变化而导致的权重差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/650558/question-on-the-effect-of-test-reliability-on-weighting-of-a-test-battery</guid>
      <pubDate>Fri, 05 Jul 2024 22:15:38 GMT</pubDate>
    </item>
    <item>
      <title>当我的因变量在 R 中被分数幂运算时，我应该如何反向变换 beta 系数</title>
      <link>https://stats.stackexchange.com/questions/650513/what-should-i-back-transform-beta-coefficients-when-my-dependent-variable-is-fra</link>
      <description><![CDATA[我有这个混合效应回归模型。为了在连续尺度因变量中创建正态分布，我对其进行了分数指数化：
TB_fract &lt;- TB ^ (1/1.4)

我的以下模型是这样的，其中 period 表示时间的整数值，MRN 表示单个受试者：
lme4::lmer(TB_fract ~ Surg_group_fact + (1 + period|MRN), data = full_patient_data_2, na.action = na.omit)

我的输出是这样的。 time_below_sqrt 是 TB_fract 的 DV 表示：


我显然有负 beta 估计值，这不允许转换为 1.4 次方。如果我的 DV 是具有负 beta 系数的原始值的分数值，那么我该如何解释这些结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/650513/what-should-i-back-transform-beta-coefficients-when-my-dependent-variable-is-fra</guid>
      <pubDate>Fri, 05 Jul 2024 09:14:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么从后验抽样可以很好地估计似然值，而从先验抽样却不好？</title>
      <link>https://stats.stackexchange.com/questions/650506/why-sampling-from-the-posterior-is-a-good-estimate-for-the-likelihood-but-sampli</link>
      <description><![CDATA[在变分自动编码器 (VAE) 中，我们有：
$$
\log p_\theta(x) = \log \left[ \int p_\theta(x \mid z)p(z) \, dz \right]
$$
其中 $ p_\theta(x \mid z) = \mathcal{N}(x; \mu_\theta(z), I) $ 和 $ p(z) = \mathcal{N}(0, I)$。当推导证据下界 (ELBO) 时，通过 Jensen 等式，我们得到：
$$
\log p_\theta(x) \geq \int \log [p_\theta(x \mid z)] p(z) \, dz
$$
据称该积分难以估计，因为 $z$ 是高维的。但是，通过使用重要性抽样和变分分布 $q_\phi(z \mid x)$，ELBO 变为：
$$
\log p_\theta(x) \geq \int \log [p_\theta(x \mid z)] q_\phi(z \mid x) \, dz - \text{KL}(q_\phi(z \mid x) \parallel p(z))
$$
Kullback-Leibler (KL) 散度具有封闭形式，因为 $ q_\phi(z \mid x) = \mathcal{N}(z; \mu_\phi(x), \sigma_\phi(x) I) $。这应该使估计变得容易处理。这怎么可能呢？$p(z) $ 和 $q_\phi(z \mid x)$ 是高斯分布，易于采样。我猜这一切都归结为估计积分所需的样本数量。我认为 $L_2\gg L_1$ 必须具有相似的准确性？如果是这样，为什么会这样？
$$
\mathbb{E}_{q_\phi(x|z)} [p_\theta(x|z)] \approx \frac{1}{L_1} \sum_{l=1}^{L_1} \log p_\theta(x \mid z^{(l)}), \quad z^{(l)} \sim q_\phi(z \mid x) \rightarrow \text{好的估计？}
$$
$$
\mathbb{E}_{p(z)} [p_\theta(x|z)] \approx \frac{1}{L_2} \sum_{l=1}^{L_2} \log p_\theta(x \mid z^{(l)}), \quad z^{(l)} \sim p(z) \rightarrow \text{估计错误？}
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/650506/why-sampling-from-the-posterior-is-a-good-estimate-for-the-likelihood-but-sampli</guid>
      <pubDate>Fri, 05 Jul 2024 00:09:57 GMT</pubDate>
    </item>
    </channel>
</rss>