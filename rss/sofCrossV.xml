<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 14 Oct 2024 03:25:36 GMT</lastBuildDate>
    <item>
      <title>如何解释自动编码器异常检测的重建误差？</title>
      <link>https://stats.stackexchange.com/questions/655738/how-to-interpret-reconstruction-error-for-anomaly-detection-with-autoencoders</link>
      <description><![CDATA[我有一个基于神经网络的自动编码器。该模型使用 SCADA 数据进行训练。我在异常检测方面取得了不错的结果，主要指标（召回率、准确率、精确率和 F1 分数）约为 85%。
当我开始分析异常期间的重构误差时，我发现对异常贡献最大的参数不一定与其原因有关。
“id”参数对重构误差 (RE) 的贡献约为 50-60%，而应与异常相关的参数对 RE 的贡献仅为 10%。“other”参数表示所有非“id”参数的总和。下图显示了此行为：

此行为不仅出现在此数据集中，还出现在其他异常中。这些数据集相当大，最小的数据集有大约 100 个参数，最大的数据集有 600 个参数，每个数据集都有超过 5 年的数据和 10 分钟的粒度。因此，我认为这不是由于缺乏数据造成的。
我尝试删除“id”参数，但这显著影响了主要指标，使其下降到大约 50-60%。
关于“id”参数，它与时间具有很强的相关性，是一个正的单调序列。
即使模型很好地检测了异常，这种行为是否会使其不可靠？我发现一个可能的解释是，给定输入及其特定条件，自动编码器会为输入预测不同的“id”/时间。我认为该模型可能已经隐式地学习了涡轮机运行的时间特征。结果，它确定给定的条件与预期的时间模式不一致。
这个解释看起来合理吗？我也接受改进模型的建议。
我用不同的数据集验证了模型，尝试用 optuna 超参数优化改进自动编码器，并尝试了不同的数据处理。所有的尝试都导致了相同的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/655738/how-to-interpret-reconstruction-error-for-anomaly-detection-with-autoencoders</guid>
      <pubDate>Mon, 14 Oct 2024 01:38:15 GMT</pubDate>
    </item>
    <item>
      <title>心血管疾病患者中的肥胖悖论可以通过错误控制介质来解释吗？</title>
      <link>https://stats.stackexchange.com/questions/655736/can-obesity-paradox-among-subjects-with-cardiovascular-disease-be-explained-by-i</link>
      <description><![CDATA[鉴于以下因果关系图：
肥胖 -&gt; 心血管疾病 -&gt; 死亡率
肥胖是心血管疾病 (CVD) 的致病因素，那么得出这样的结论是否合理：由于 CVD 是介质，因此对患有 CVD 的受试者进行条件反射会导致治疗效果估计出现偏差？
这可能无法完全解释偏差，但我认为可以解释其中很大一部分。]]></description>
      <guid>https://stats.stackexchange.com/questions/655736/can-obesity-paradox-among-subjects-with-cardiovascular-disease-be-explained-by-i</guid>
      <pubDate>Mon, 14 Oct 2024 00:10:16 GMT</pubDate>
    </item>
    <item>
      <title>当我们将多个参数合并为一个时，这叫什么？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655733/what-is-it-called-when-we-collapse-many-parameters-in-one</link>
      <description><![CDATA[当我们将同一事物的许多参数放在一起产生一个标量值时，我们称该操作为什么？特别是当它不仅涉及参数的简单总结（甚至可能带有权重）时，还涉及更复杂的“合并”时？
例如，当我们考虑某些项目的可排序参数属性，如大小、亮度、光的波长、距离等，然后我们提供对这些属性的偏好，并要求按某些公共值进行排序，这些公共值是这些独立值的一种“总和”。
我想到的是：卷积、合并、组合、降维、“标量化”、投影等。
这有什么通用术语吗？
具体示例

我有一组恒星，它们的距离、年龄、大小、光的波长峰值、距离都是已知的，并且我有自己的观察偏好。现在，我不想根据每个参数单独对它们进行排序，而是根据我的偏好基于所有参数进行排序。

我有由字符编译的单词，我根据字符、使用频率、是否是子序列的一部分、是否位于单词的开头和结尾等来计算单词相似性的不同方面。因此，每个这样的指标都会给出一个值。现在我需要想出一个值作为相似性的答案。我必须将各个（通常是正交的）指标卷积为一个。

]]></description>
      <guid>https://stats.stackexchange.com/questions/655733/what-is-it-called-when-we-collapse-many-parameters-in-one</guid>
      <pubDate>Sun, 13 Oct 2024 21:02:33 GMT</pubDate>
    </item>
    <item>
      <title>似然函数简化的证明[重复]</title>
      <link>https://stats.stackexchange.com/questions/655732/proof-of-the-simplification-of-the-likelihood-function</link>
      <description><![CDATA[许多参考文献都指出，在$x_1,x_2,\ldots x_n$为独立同分布的假设下，似然函数可以简化如下：
$$P(x_1,x_2,\ldots ,x_n|\theta)=P(x_1|\theta)P(x_2|\theta)\ldots P(x_n|\theta)$$
不幸的是，大多数参考文献都认为这种简化是理所当然的，而没有提供任何证明或解释。
上述简化背后的证明是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655732/proof-of-the-simplification-of-the-likelihood-function</guid>
      <pubDate>Sun, 13 Oct 2024 20:33:21 GMT</pubDate>
    </item>
    <item>
      <title>R 与 Python 在学术生物统计学研究中的比较？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655731/r-vs-python-in-academic-biostatistics-research</link>
      <description><![CDATA[我很好奇，想听听你对在学术生物统计学或密切相关领域（例如统计学、生物信息学、数据科学）学习 R 与 Python 的重要性的看法。
背景：

我使用 R 已经超过 10 年了，从未遇到过无法用它解决的问题。我对 R 非常熟练，并且很熟悉。
但是，我想知道学习 Python 对于学术界的职业发展，尤其是在生物统计学领域，有多重要。

问题：

对于像我这样拥有丰富 R 经验的人来说，你认为学习 Python 对于生物统计学或类似领域的学术生涯有多重要？
你是否认为 Python（甚至是 Julia）未来可能会在学术界取代 R？我是否应该担心 R 会随着时间的推移变得不那么重要？

就我个人而言，我更愿意坚持使用 R，因为它目前满足了我所有的需求。但如果这对于保持该领域的竞争力至关重要，我愿意学习新工具。我也很想知道你对精通多种统计编程语言（如 Python 或 Julia）是否具有显著优势的看法。]]></description>
      <guid>https://stats.stackexchange.com/questions/655731/r-vs-python-in-academic-biostatistics-research</guid>
      <pubDate>Sun, 13 Oct 2024 20:04:51 GMT</pubDate>
    </item>
    <item>
      <title>当连续变量等于 0 时创建虚拟变量</title>
      <link>https://stats.stackexchange.com/questions/655727/creating-a-dummy-variable-when-the-continuous-variable-is-equal-to-0</link>
      <description><![CDATA[由于我有很多真零（所以它们不是缺失值而是真正的零），我创建了一个虚拟变量，使得：

当正连续变量等于 0 时，虚拟变量等于 1。
否则为 0。

因此我执行了以下 logit 回归：
proc logistic data= want plots=ROC;
model perceived_default = Continuous_variable Dummy_variable 
run;

根据 Somers 的 $D$ (60%)，结果相当不错，但虚拟变量并不显著（$p$ 值等于 $0.35$）。
我该如何处理这个问题？即使虚拟变量不显著，我是否可以将其保留在模型中？我认为问题出现是因为虚拟变量在构造上与连续变量共线。]]></description>
      <guid>https://stats.stackexchange.com/questions/655727/creating-a-dummy-variable-when-the-continuous-variable-is-equal-to-0</guid>
      <pubDate>Sun, 13 Oct 2024 16:59:47 GMT</pubDate>
    </item>
    <item>
      <title>测量分布均匀性</title>
      <link>https://stats.stackexchange.com/questions/655696/measure-for-distribution-uniformity</link>
      <description><![CDATA[是否有某种度量和计算方法，以区分均匀分布在范围内的值和具有许多峰值（其数量）的值？
例如，区分如下序列：
示例 1：1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2、1、2

带有
示例 2：1、1、1、1、1、2、1、2、2、2、2、2、1、2、1、2、1、2、1、1、1、1、 1, 2, 2, 2, 2 

和
示例 3：1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2

我正在寻找一个指标，当值（这里假设为 2）均匀分布在序列中时，该指标接近 0，当所有这些值集中在一个地方时，该指标接近 1；当我有像示例 2 中那样的本地组时，我希望该指标接近 0.5，而在示例 3 中，我希望该指标接近 0.7。这些值只是为了解释逻辑，当然，它们是近似的。
例如，如果问题是关于一个峰值，我会使用平均值和方差。但如果有很多峰值，情况就会有所不同。
是否存在这样的指标（或类似指标）？
一些背景知识
我想要一个度量，它可以说明文本中的特定词素（用数字表示）是否分布均匀（如代词）或这是一个术语（如“排列”），它将倾向于在大型文本库中大量出现数学书籍。]]></description>
      <guid>https://stats.stackexchange.com/questions/655696/measure-for-distribution-uniformity</guid>
      <pubDate>Sat, 12 Oct 2024 16:29:13 GMT</pubDate>
    </item>
    <item>
      <title>回归均值的行为</title>
      <link>https://stats.stackexchange.com/questions/655691/behaviour-of-regression-toward-the-mean</link>
      <description><![CDATA[我有一个包含 801 人（男性和女性）左右脚长度的数据集。据我所知，这是一个教学数据集，没有任何具体问题或特殊之处。
以下是均值和协方差矩阵，单位为厘米：
## 均值
LengthRightFoot LengthLeftFoot 
24.3 24.3 

## 协方差矩阵
LengthRightFoot LengthLeftFoot
LengthRightFoot 6.34 6.08
LengthLeftFoot 6.08 6.31

左脚对右脚的回归表明，与直觉相反，斜率略低于 1，截距高于 0（见下文）。我认为这是由于向均值回归。到目前为止一切顺利，除非你有更好的解释。
令我困惑的是，截距可疑地接近 1（0.99877）。当然，0.99877 是一个和其他数字一样的数字，但我想知道截距几乎正好是 1 的原因是什么。你能解释一下吗？

调用：
lm(formula = LengthLeftFoot ~ LengthRightFoot)

残差：
最小 1Q 中位数 3Q 最大 
-2.254 -0.239 -0.025 0.187 8.823 

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.99877 0.23741 4.21 2.9e-05 ***
LengthRightFoot 0.95891 0.00973 98.50 &lt; 2e-16 ***
---
有效代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：799 个自由度上的 0.693
多重 R 平方：0.924，调整后的 R 平方：0.924
F 统计量：1 和 799 DF 上的 9.7e+03，p 值：&lt;2e-16


此 R 模拟生成一个包含 50000 个观测值的数据集，其协方差矩阵与真实值相似。回归重现了上述发现：
mu &lt;- c(24.3, 24.3)
covmat &lt;- structure(c(6.33766534019975, 6.07723639200999, 
6.07723639200999, 6.3073693196005), dim = c(2L, 2L), 
dimnames = list(c(&quot;LengthRightFoot&quot;, 
&quot;LengthLeftFoot&quot;), c(&quot;LengthRightFoot&quot;, &quot;LengthLeftFoot&quot;)))

sim &lt;- as.data.frame(mvrnorm(n=50000, mu=mu, Sigma=covmat))

模拟数据的回归：
summary(lm(LengthLeftFoot ~ LengthRightFoot, data=sim))
调用：
lm(formula = LengthLeftFoot ~ LengthRightFoot, data = sim)

残差：
最小值 1Q 中位数 3Q 最大值 
-2.9058 -0.4683 -0.0034 0.4622 2.7255 

系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 1.037961 0.030047 34.55 &lt;2e-16 ***
LengthRightFoot 0.957488 0.001231 777.63 &lt;2e-16 ***
---
有效代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：49998 自由度上的 0.6921
多重 R 平方：0.9236，调整后的 R 平方：0.9236
F 统计量：1 和 49998 DF 上的 6.047e+05，p 值：&lt; 2.2e-16
]]></description>
      <guid>https://stats.stackexchange.com/questions/655691/behaviour-of-regression-toward-the-mean</guid>
      <pubDate>Sat, 12 Oct 2024 15:21:33 GMT</pubDate>
    </item>
    <item>
      <title>在所有数据集中确定正确的输出，其中我们只知道错误率，并且输出具有不均匀分布，这是实际工程问题</title>
      <link>https://stats.stackexchange.com/questions/655687/determining-the-correct-output-among-all-data-set-where-we-only-know-error-rate</link>
      <description><![CDATA[我遇到了一个工程问题，但我没有高级统计背景。让我试着解释一下我的情况。
假设我有一台机器，它接受输入并在内部进行一些计算后给出输出。
机器的属性：

机器总是接受完全相同的输入（我们不知道输入）。

我们的机器也有 30% 的错误率

输出具有非均匀分布。

当我们运行我们的机器时，它有时会给出错误的输出，正如我所说，这些错误的输出可能非常不同，但只有一个正确的输出。在这里，我们不知道输入，只看到机器的输出，并且有信息表明机器也有 30% 的错误率，并且输出具有非均匀分布。

我们可以随心所欲地运行机器。


我想用最少的试验来确定正确的输出。所以我在研究一种在向最终用户提供正确输出之前要执行的技术。

例如，假设我的机器进行 4+6 的计算，那么它的输出可能是 560,11,26,3,1563567,67,9,10,34 ... 我写这个例子是因为即使它有 30% 的错误率，第一个输出可能直到某个时候才包含正确的输出。更重要的是，这是非常低的概率，但一些不正确的输出可能会重复并欺骗我们相信它是正确的。然而，这是最糟糕的情况。

当我在互联网上进行研究时，我遇到了 Walds 的序贯概率比检验，但我不确定它是否是解决我的问题的正确工具。更重要的是，我无法理解如何应用该技术。您能否与我分享您的知识来解决我的问题？统计学中是否有任何方法可以将其应用于我的问题。如果 SPRT 是正确的，那么请帮助我应用它

我的想法：为了应用 SPRT，我需要一个假设。我认为假设可以是关于特定值是否是正确的输出。
1.步骤-) 运行机器，直到获得两个相同的输出。当您获得 $2$ 相同的输出时，停止机器。说它可能是正确的。
2.Step-) 假设我们正确输出的候选是 $8$。
$H_0:$ $8$ 不是正确的输出
$H_1:$ $8$ 是正确的输出
3.Step-) 我想要确保我的输出尽可能高，所以我想要 $99$ 百分比置信区间。这里 $\alpha=0.01$ 和 $\beta=0.01$
所以，我的边界点可以是 $$A=log \bigg(\frac{1-\beta}{\alpha}\bigg)=1.995 , B=log \bigg(\frac{\beta}{1-\alpha}\bigg)=-1.995$$
4.Step-) $$L(x_i)=\frac{P(x_i|H_1)}{P(x_i|H_0)} \rightarrow L(8)= \frac{0.7}{0.3}=2.333=log(2.333)=0.368$$
5.Step-) $S_n=S_{n-1}+log(L(x_i))$
在这里，我们在再次运行机器后更新每个输出的 $S_n$ 中的值。如果我们看到可能的正确输出 $8$，我们将添加 $0.368$，但如果我看到任何其他输出，我不知道该怎么做。我被困在这里。如果我的和超过 $1.995$，那么我会推断 $8$ 是正确的，置信度为 $99$，但如果低于 $-1.995$，我会拒绝 $H_1$。
我不确定对于“不正确”的输出我应该怎么做。我认为它们必须对和产生负面影响。不确定。
当和介于 $-1.995$ 和 $1.995$ 之间时，我会继续输出]]></description>
      <guid>https://stats.stackexchange.com/questions/655687/determining-the-correct-output-among-all-data-set-where-we-only-know-error-rate</guid>
      <pubDate>Sat, 12 Oct 2024 13:07:12 GMT</pubDate>
    </item>
    <item>
      <title>如何制作两个完全负相关的增长几何布朗运动（GBM）系列？</title>
      <link>https://stats.stackexchange.com/questions/655735/how-to-make-two-perfectly-negatively-correlated-growing-geometric-brownian-motio</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655735/how-to-make-two-perfectly-negatively-correlated-growing-geometric-brownian-motio</guid>
      <pubDate>Fri, 11 Oct 2024 23:13:17 GMT</pubDate>
    </item>
    <item>
      <title>估计概率值大于来自未知分布的 x</title>
      <link>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</link>
      <description><![CDATA[假设我们有 N 个项目的总体，其值从 0 到 6000。
假设总体的平均值是 $\mu$。
我们不知道项目的分布。
我们从这个总体中提取一个项目，我们如何估计 $P(x\geq 2500)$？
同样的问题，假设分布是均匀的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</guid>
      <pubDate>Fri, 11 Oct 2024 08:52:55 GMT</pubDate>
    </item>
    <item>
      <title>有人能解释一下为什么“正统统计”需要辅助统计吗？</title>
      <link>https://stats.stackexchange.com/questions/655018/can-someone-explain-why-ancillary-statistic-is-needed-in-orthodox-statistics</link>
      <description><![CDATA[我正在阅读 Jaynes 的《概率论：科学的逻辑》。在第 8 章中，Jaynes 讨论了“正统”环境中的辅助统计问题，他说辅助统计是出于以下原因而需要的：

我对他的说法有点困惑。他说“人们有义务得出结论，无论样本的配置如何，给定估计量的所有估计都具有相同的准确性。”为什么会这样？如果两个数据集具有相同的平均值但不同的方差，那么假设估计量会对“准确性”给出不同的估计值是否很自然？]]></description>
      <guid>https://stats.stackexchange.com/questions/655018/can-someone-explain-why-ancillary-statistic-is-needed-in-orthodox-statistics</guid>
      <pubDate>Fri, 27 Sep 2024 15:33:23 GMT</pubDate>
    </item>
    <item>
      <title>Wald-Wolfowitz 对白噪声进行检验</title>
      <link>https://stats.stackexchange.com/questions/653385/wald-wolfowitz-runs-test-on-white-noise</link>
      <description><![CDATA[我正在寻找方法来检查时间序列是否不同于白噪声 (WN)。我可以直接检查均值是否为零、方差是否为常数以及所有滞后处的自相关是否为零，然后我就会这样做。但除了这些要点之外，应用 Wald-Wolfowitz (WW) 运行检验是否有意义？*我偶然遇到了它（在 R 中的 randtests::runs.test 中实现），并且不确定在这种情况下该如何理解它。
*我的意思是，如果过程是 WN，是否意味着它必须通过 WW 运行检验，前提是具有完美的估计精度（例如来自 WN 的无限样本路径）？]]></description>
      <guid>https://stats.stackexchange.com/questions/653385/wald-wolfowitz-runs-test-on-white-noise</guid>
      <pubDate>Tue, 27 Aug 2024 07:36:53 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 符号秩检验与符号检验假设</title>
      <link>https://stats.stackexchange.com/questions/652389/wilcoxon-signed-rank-test-vs-sign-test-assumptions</link>
      <description><![CDATA[必须检查符号检验的哪些假设？
如果符号检验也无效，那么替代方案是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652389/wilcoxon-signed-rank-test-vs-sign-test-assumptions</guid>
      <pubDate>Tue, 06 Aug 2024 17:16:02 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 cox ph 模型的分数残差？</title>
      <link>https://stats.stackexchange.com/questions/615409/how-to-calculate-score-residual-for-cox-ph-model</link>
      <description><![CDATA[我尝试理解“分数残差”来自 R 中的 cox ph 模型。
我使用过一个参考网站。
https://www.mayo.edu/research/documents/biostat-58pdf/doc-10027288
有人能帮我在 R 中手动（我的意思是使用公式）获取分数残差吗？
提前谢谢大家。
[R 代码]
library(survival)
cph1 &lt;- coxph(Surv(futime, fustat)~rx+age , data=ovarian)
residual &lt;- residuals(cph1,类型=“分数”）]]></description>
      <guid>https://stats.stackexchange.com/questions/615409/how-to-calculate-score-residual-for-cox-ph-model</guid>
      <pubDate>Wed, 10 May 2023 08:21:39 GMT</pubDate>
    </item>
    </channel>
</rss>