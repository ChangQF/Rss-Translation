<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 21 Apr 2024 03:14:11 GMT</lastBuildDate>
    <item>
      <title>OLS - 如何创建一个好的功能</title>
      <link>https://stats.stackexchange.com/questions/645481/ols-how-to-create-a-good-feature</link>
      <description><![CDATA[我正在尝试根据内部买卖量（1 级数据）来预测股票的下一个价格，并且我想创建一个对这种不平衡进行建模的功能。我正在使用基本 OLS
我脑子里有两个想法，但我不确定哪个更好，或者如何评估两者的优点。
假设内部买价量为 $b$，内部卖价量为 $a$ 
第一个方程：
$\frac{b}{b+a}$
第二个方程：
$\frac{b-a}{b+a}$
&lt;小时/&gt;
现在显然第二个方程只是另一个方程的线性变换 (1-X)，所以我不能同时使用两个方程。
我的问题是：我使用哪个重要吗？在我看来，后者更好，因为它的范围是 [-1,1]，而第一个范围是 [0,1]。在单变量回归中，偏差项负责处理差异。但这适用于多元吗？
我正在尝试了解为什么会有差异或不会有差异，因此我们将不胜感激:)]]></description>
      <guid>https://stats.stackexchange.com/questions/645481/ols-how-to-create-a-good-feature</guid>
      <pubDate>Sun, 21 Apr 2024 02:50:04 GMT</pubDate>
    </item>
    <item>
      <title>如何使 GLMM 适合多层嵌套</title>
      <link>https://stats.stackexchange.com/questions/645475/how-to-fit-a-glmm-with-multiple-levels-of-nesting</link>
      <description><![CDATA[我目前正在努力处理一些数据。我已经开始使用广义线性混合模型 (GLMM)，但我很难理解它。
我有一个大型数据集，由特定毒素的浓度测量值组成。这些测量是在我的有机体的所有三种类型的组织中进行的（牡蛎：肠道、鳃、“其他所有组织”）。测量值不呈正态分布。例如，从我的样本区域的两个不同地点收集了 30 个牡蛎。另外 30 个是在每年的第二个时间收集的。我将其视为嵌套在季节中嵌套的站点中的个人。
我正在尝试了解季节、地点或组织类型是否对浓度测量有影响。
假设季节和组织肯定会，而且我相信该网站也会。所以，我试图构建一个模型来展示这一点，但我完全一片空白。我认为为了确定季节的影响，我需要尝试比较两个不同季节从同一地点采集的相同组织。
为了弄清楚地点的影响，我需要比较不同地点同一季节的相同组织。为了弄清楚组织的影响，我需要比较同一地点和季节的不同组织。
不过，我不确定接下来该去哪里。
我的 R 代码是：
glmer(BoxCox ~ 1 + 组织 + 站点 + 季节 + (1 | 站点) + (1 | 季节), 数据 = 数据, 控制 = lmerControl(优化器 = “bobyqa”))

有人有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645475/how-to-fit-a-glmm-with-multiple-levels-of-nesting</guid>
      <pubDate>Sat, 20 Apr 2024 22:43:10 GMT</pubDate>
    </item>
    <item>
      <title>使用背景减法来识别连续帧图像中的某些对象以开始标记对象进行 YOLO 训练是否合理？</title>
      <link>https://stats.stackexchange.com/questions/645474/is-it-reasonable-to-use-background-subtraction-to-identify-some-objects-in-seque</link>
      <description><![CDATA[我知道背景减除并不是对象检测的完整解决方案，但我已经尝试过用它来识别固定背景相机场景中出现的潜在新对象（需要解析数百万张图像以进行手动标记）。这个想法是使用背景减法来在原始数据中找到至少一个初始对象样本，以开始为训练集（一种样本启发式）进行标记，并开始迭代训练 YOLO 模型。尽管最初存在局限性，这种方法有什么问题吗？与使用模拟数据开始相比如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/645474/is-it-reasonable-to-use-background-subtraction-to-identify-some-objects-in-seque</guid>
      <pubDate>Sat, 20 Apr 2024 22:22:01 GMT</pubDate>
    </item>
    <item>
      <title>在 g 计算中包含权重与插件双鲁棒估计器不同吗？</title>
      <link>https://stats.stackexchange.com/questions/645472/is-including-weights-in-g-computation-not-the-same-as-a-plug-in-doubly-robust-es</link>
      <description><![CDATA[在 WeightIt() 的 R 包插图中，在“建模结果”一节中，它解释说（假设我读得正确）在通过治疗模型（例如 IPTW）创建权重后应用 g 计算的目的不是得到双重稳健估计量。我对此感到困惑，因为在Robin 和 Hernan 的因果推理 What If: Fine Point 13.2 中，它解释了双重稳健插件估计量就是这样；对数据应用 g 计算以及加权生成的权重会得出因果效应的双重稳健估计。
我假设这个“矛盾”可能实际上不是矛盾，实际上只是我对文本的误解，但我很难弄清楚并希望得到一些帮助。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/645472/is-including-weights-in-g-computation-not-the-same-as-a-plug-in-doubly-robust-es</guid>
      <pubDate>Sat, 20 Apr 2024 21:08:49 GMT</pubDate>
    </item>
    <item>
      <title>截断正态分布方差齐性的 F 检验</title>
      <link>https://stats.stackexchange.com/questions/645462/f-test-for-equality-of-variance-for-truncated-normal-distributions</link>
      <description><![CDATA[我对假设检验相当陌生。我读到方差齐性的 F 检验对于非正态分布效果不佳。当截断分布是对称的情况下，此测试是否适用于截断正态分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/645462/f-test-for-equality-of-variance-for-truncated-normal-distributions</guid>
      <pubDate>Sat, 20 Apr 2024 18:22:30 GMT</pubDate>
    </item>
    <item>
      <title>非正态性下最小二乘法和最大似然估计的不同估计</title>
      <link>https://stats.stackexchange.com/questions/645434/different-estimates-of-least-squares-and-maximum-likelihood-estimates-under-non</link>
      <description><![CDATA[据说，如果基础数据非正态，则最小二乘估计将与最大似然估计不同。这应该就是为什么 LS 估计可以用于线性回归，而对于广义线性模型，参数则来自 ML 估计。尽管我读过很多次，但我从未见过它的实际应用。因此，我想知道是否可以在 R 中提供一个示例，其中使用两种方法的估计明显彼此偏离。]]></description>
      <guid>https://stats.stackexchange.com/questions/645434/different-estimates-of-least-squares-and-maximum-likelihood-estimates-under-non</guid>
      <pubDate>Sat, 20 Apr 2024 07:54:40 GMT</pubDate>
    </item>
    <item>
      <title>伪反演给出了较差的预测，以较小的矩阵收敛</title>
      <link>https://stats.stackexchange.com/questions/645429/pseudoinversion-giving-poor-predictions-converges-with-smaller-matrix</link>
      <description><![CDATA[我遇到一个问题，即运行伪反转作为使用甲基化数据预测某些表型值的方法会给出非常大的数字，非常池化地预测所述值，除非矩阵被显着减少。
具体来说，我有两个初始矩阵：trait_data 和 meth_data。我选择每个部分的一个部分作为测试动物。然后，我利用伪反演生成特征数据的预测，如下所示。当处理大约 20 个特征时，预测是相当准确的。但是，在处理 ~ 40 个特征时，我实际上得到了数十亿的数字，其值应该在 1 左右。我该如何解决这个问题，或者这是使用这种方法所期望的？我的这种方法基于论文“颊上皮细胞的甲基化组受年龄、性别和生理特性的影响”
&#39;&#39;&#39;
 #省略一只动物
    train_trait = np.delete(trait_data, n, 0)
    train_meth = np.delete(meth_data, n, 0)
    
    测试特征 = 特征数据[n]
    测试方法=方法数据[n]

    train_trait_pinv = np.linalg.pinv(train_trait)

    site_coef = np.dot(train_trait_pinv, train_meth) #系数 = Pinv(Trait_Train) * Meth_Train
    coef_pinv = np.linalg.pinv(site_coef)

    pred_trait = np.dot(test_meth, coef_pinv) #Trait_Pred = Meth_Test * Pinv(站点 Coef)

&#39;&#39;&#39;
编辑：这是数组大小
train_trait.shape = (45, 55)
train_meth.shape = (45, 284381)
test_trait.shape = (55,)
test_meth.shape = (284381,)
]]></description>
      <guid>https://stats.stackexchange.com/questions/645429/pseudoinversion-giving-poor-predictions-converges-with-smaller-matrix</guid>
      <pubDate>Sat, 20 Apr 2024 03:26:15 GMT</pubDate>
    </item>
    <item>
      <title>余弦相似度与替代点积缩放</title>
      <link>https://stats.stackexchange.com/questions/645343/cosine-similarty-vs-alternative-dot-product-scaling</link>
      <description><![CDATA[假设我有一个特定的度量存储在两个向量a和b中，我使用余弦相似度来度量两个向量之间的相似度。
形式上，余弦相似度表示为：
$$ \cos\theta =\frac{a\cdot b}{\|a\|\|b\|}= \frac{\sum_{i=1}^{ n}{a_i b_i}}{\sqrt{\sum_{i=1}^{n}a_i^2} \cdot\sqrt{\sum_{i=1}^{n}b_i^2}}$$&lt; /跨度&gt;
在阅读时，我发现了一篇帖子 关于两个向量之间的相似性。一个答案如下：
&lt;块引用&gt;
我在比较 2 个向量（速度）时遇到了类似的问题。我目前使用两个向量的点积除以最大向量长度的平方。这样做的优点是，在测量“相似性”时还考虑了方向和大小。该公式给出 -1 到 +1 之间的数字。如果向量相同，您将获得 +1。如果方向相差超过 180 度，结果为负。

这被指定为：相似度 = dotproduct(a, b) / max(norm(a),norm(b))^2
因此，在上面的符号中，可以表示为：
$$ = \frac{\sum_{i=1}^{n}{a_i b_i}}{\max\left(\sqrt{\sum_{i=1) }^{n}a_i^2},\sqrt{\sum_{i=1}^{n}b_i^2}\right)^2}$$
考虑到正则余弦相似度也在区间 $[-1,1 中，与正则余弦相似度相比，这种点积的替代缩放有什么优点]$？这是点积的标准缩放吗？如果是，这种方法通常被称为什么？最后，使用一些示例数据，与余弦相似度相比，替代点积缩放似乎会导致相似度稍低（请参见下面的代码示例），这告诉我什么？
&lt;小时/&gt;
&lt;前&gt;&lt;代码&gt;n &lt;- 10

设置.种子(123)
a &lt;- rnorm(n)
b &lt;- rnorm(n)

余弦 &lt;- 函数(a, b) {
  总和（a * b）/（sqrt（总和（a * a））* sqrt（总和（b * b）））
}

替代&lt;-函数（a，b）{
  sum(a*b) / max(sqrt(sum(a*a)), sqrt(sum(b*b)))^2
}

余弦（a，b）
[1] 0.5801971

替代方案（a，b）
[1] 0.5232835
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/645343/cosine-similarty-vs-alternative-dot-product-scaling</guid>
      <pubDate>Thu, 18 Apr 2024 22:05:19 GMT</pubDate>
    </item>
    <item>
      <title>这种机制设计环境中过度拟合的直观感觉是否体现了偏差-方差权衡？</title>
      <link>https://stats.stackexchange.com/questions/645153/does-the-intuitive-sense-of-overfitting-in-this-mechanism-design-context-exempli</link>
      <description><![CDATA[假设社会中每个人的（可以说是一致的）偏好是选择出行道路，95%的权重放在最小化出行时间的目标上，剩下的5%的权重放在最大化审美愉悦的目标上源于道路的风景。为了回应与这些偏好相关的布雷斯悖论，中央计划者破坏了最优的初始道路集的子集。然后，作为一种独立的、外生的变化，社会将每周工作时间从 40 小时减少到 20 小时，随后导致偏好一致降低对旅行时间最小化的权重，并增加对风景质量最大化的权重。显然，哪些道路被摧毁不再是最佳决策，因为目标偏好已经发生变化，但更麻烦的是，如果变化足够大，我们可能期望当前的道路子集能够执行比初始设置更糟糕，因为布雷斯悖论源于旅行时间最小化组件，而对于风景质量组件，破坏道路只会伤害事物，因为给个人提供了更少的选择来最大化（风景质量）被认为与流量分布无关）。
我们还可以修改上述内容以包括对两个以上优化目标的偏好、作为优化目标非线性函数的偏好（例如由替代和补充效应引起的偏好）、由道路破坏而不是外生引起的偏好变化、多个优化目标由此出现了布雷斯悖论的竞争实例，要求相互不一致的道路子集等。我们不仅可以考虑道路子集与个人实际偏好的不匹配，还可以考虑与如果道路没有被破坏，它们就会形成（也许那些从未经历过风景质量最高的被破坏道路的人不知道他们错过了什么）。 p&gt;
直观上，我认为破坏道路的决定可能过度拟合初始偏好，而中央规划者的目标是优化初始偏好，同时忽略个人选择较少的观察结果如果偏好随着最小化偏差而忽略方差而发生变化，那么优化往往会产生更糟糕的结果。正如积极地将回归多项式拟合到训练数据可能会使其对其他数据的泛化效果不佳一样，将道路子集积极地拟合到观察到的偏好可能会导致动作空间对其他偏好的泛化效果较差。然而，我看不到这种背景下明显的随机采样过程，所以我不确定这里是否确实存在某种减少或同构。以下是我迄今为止的尝试...
偏差$\ =\ \sum_{所有\个体}(u_{NE}(G_1) - u_{NE}(G_0))$
方差$\ =\ \sum_{所有\个体}(v_{NE}(G_0) - v_{NE}(G_1))$
...其中 $u_{NE}()$ 是个人的初始纳什均衡效用，作为可用道路的函数， $v_{NE}()$ 是个人的纳什均衡效用，作为可用道路的函数在改变偏好后，$G_0$ 是初始道路集，$G_1$ 是  的子集$G_0$ 根据 $u$ 描述的偏好生成最优纳什均衡效用（中央规划者无法预见  $v$）。为了便于概念化，我假设每个纳什均衡都是独特的，以固定偏好和可用道路为条件。
对于随机抽样部分，也许中央规划者无法预见从 $u$ 到  的转变$v$ 是否有足够的不确定性来扮演这个角色？当然可以引入偏好转变的随机生成，但这感觉比设置的自然部分更强制。
这种情况是否符合偏差-方差权衡？如果是这样，那么到目前为止我还缺少哪一块拼图？如果不是，那么是否存在偏差-方差权衡的泛化，超出了随机采样的范围，包括随机采样和这个？]]></description>
      <guid>https://stats.stackexchange.com/questions/645153/does-the-intuitive-sense-of-overfitting-in-this-mechanism-design-context-exempli</guid>
      <pubDate>Tue, 16 Apr 2024 17:29:12 GMT</pubDate>
    </item>
    <item>
      <title>连续均匀随机变量比较的最佳策略/获胜概率</title>
      <link>https://stats.stackexchange.com/questions/645014/optimal-strategy-win-probability-for-sequential-uniform-random-variable-comparis</link>
      <description><![CDATA[假设您按顺序呈现 $n$ 个随机变量，$x_1, x_2, \dots, x_n$&lt; /span&gt;，均取自 U(0,1)。提供每个变量 $x_i$ 后，您必须声明该数字在所有 $ 的有序列表中的位置x_1$ 到 $x_n$ （即最大、第二大、最小等）。声明相对位置的最佳策略是什么以及成功的概率是多少（所有 $x_i$ 中没有错误答案）。
对于$n=3$，我认为算法应该如下

$x_1$

最大如果 $x_1 &gt; 2/3$
min if $x_1 &lt; 1/3$
中，如果 $1/3 &lt; x_1 &lt; 2/3$


$x_2$

如果 $x_1$ 为最大值

如果 $x_2 &gt; x_1$，$x_2$ 是最大值（我们输了游戏）
如果 $x_2 &lt; 0.5$，$x_2$ 分钟
如果 $0.5 &lt; x_2 &lt; x_1$，$x_2$ 处于中间


如果 $x_1$ 为最小值，我们的操作类似于 $x_1$ 为最大值
如果 $x_1$ 为中间

如果$x_1 &lt; x_2 &lt; 0.5$ 或 $0.5 &lt; x_2 &lt; x_1$，$x_2$ 处于中间位置（我们输了）
如果 $x_2 &gt; x_1 \land x_2 &gt; 0.5$，$x_2$ 为最大值
如果 $x_2 &lt; x_1 \land x_2 &lt; 0.5$，$x_2$ 分钟




$x_3$

与 $x_1$ 和 $x_2$ 进行简单比较以查看位置并声明为最小值/中值/max相应


]]></description>
      <guid>https://stats.stackexchange.com/questions/645014/optimal-strategy-win-probability-for-sequential-uniform-random-variable-comparis</guid>
      <pubDate>Sun, 14 Apr 2024 22:21:15 GMT</pubDate>
    </item>
    <item>
      <title>如何测试均值相等的二元正态样本中的均等分布？</title>
      <link>https://stats.stackexchange.com/questions/644739/how-to-test-for-equal-spread-in-bivariate-normal-samples-with-equal-means</link>
      <description><![CDATA[我正在处理从二元正态分布中获取的样本，其中均值的差异并不相关，因为无论如何所有样本都缩放为均值（0,0），并且我试图记住如何测试空值假设两个样本来自同一分布。换句话说，假设我从 $(x_{a,1}, ..., x_{a,n})$ 中抽取 n 个样本math-container&quot;&gt;$X_a \sim N((0,0), \Sigma_a)$ 和 n 个样本 $(x_{b,1}, ... , x_{b,n})$ 来自 $X_b \sim N((0,0), \Sigma_b)$。如何检验原假设 $H_o: \Sigma_a = \Sigma_b$？
我认为这将是单变量情况下的 F 检验，但自从我进行统计以来已经很长时间了，而且我在弄清楚多变量泛化方面遇到了困难。]]></description>
      <guid>https://stats.stackexchange.com/questions/644739/how-to-test-for-equal-spread-in-bivariate-normal-samples-with-equal-means</guid>
      <pubDate>Wed, 10 Apr 2024 17:25:04 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归中的双峰残差——是什么原因导致的，这是坏消息吗？可以采取什么措施？</title>
      <link>https://stats.stackexchange.com/questions/644725/bimodal-residuals-in-logistic-regression-what-causes-it-is-it-bad-news-and-w</link>
      <description><![CDATA[我正在处理带有二进制响应变量的大型数据集 - 这里有一个链接，指向简化的随机数据样本。
对其拟合二项式广义线性模型 (GLM)，我们发现残差基于响应变量呈双峰分布：
dat &lt;- read.csv(&quot;sampledat.csv&quot;, colClasses=c(rep(&quot;numeric&quot;,4),&quot;factor&quot;))
mod &lt;- glm(响应 ~ x1 + x2 + x3, data=dat, family=“二项式”)
绘图（mod$residuals ~ mod$fitted.values，col=1+dat$response）


无论我的哪个预测变量都是如此（$x_1$; $x_2$;我包含的示例数据集中的 $x_3$），尽管当我添加更多预测变量时距离似乎会缩小。
模型诊断图看起来也相应混乱：
&lt;前&gt;&lt;代码&gt;情节（mod）


我的问题如下：

我的残差是双峰分布的解释是否正确，因为我的响应变量中仍然存在许多无法解释的变化？

这看起来是否会影响模型的可靠性，或者是否在您对逻辑回归的预期范围内？我在网上看到一些意见，大意是这些残差图对于二项式响应没有意义，或者至少不应该以与连续响应变量相同的方式进行解释。

如果这影响我的模型的可靠性，有什么办法可以解决吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/644725/bimodal-residuals-in-logistic-regression-what-causes-it-is-it-bad-news-and-w</guid>
      <pubDate>Wed, 10 Apr 2024 13:33:23 GMT</pubDate>
    </item>
    <item>
      <title>如何将成对相异矩阵转换为 R 中的连续预测器</title>
      <link>https://stats.stackexchange.com/questions/644710/how-to-convert-pairwise-dissimilarity-matrix-into-continues-predictor-in-r</link>
      <description><![CDATA[我从 25 个不同的地点收集了植物物种数据和 AGB，我想对 Beta 多样性（即 25 个地点之间的差异）作为预测变量和 AGB 作为响应变量进行回归分析。我使用 Beta.part 包对 25 个站点之间的物种组成进行了 Jaccard 差异分析。但是，我得到一个相异矩阵，但我想将相异数据矩阵转换为连续预测器，以便在 R 中进行回归分析。如何将成对相异矩阵转换为连续预测器？我们将非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/644710/how-to-convert-pairwise-dissimilarity-matrix-into-continues-predictor-in-r</guid>
      <pubDate>Wed, 10 Apr 2024 09:39:40 GMT</pubDate>
    </item>
    <item>
      <title>基于偏差解释的 GAM 模型中的手动变量选择</title>
      <link>https://stats.stackexchange.com/questions/644136/manual-variable-selection-in-gam-model-based-in-deviance-explained</link>
      <description><![CDATA[我正在拟合广义加性模型 (GAM) 来预测公司制造流程中的瓶颈。他们拥有制造热钢卷过程中出现的瓶颈的数据。瓶颈仅出现在两个地方，因此我正在拟合逻辑 GAM 模型。我有很多变量，我想知道哪些变量对于瓶颈的发生很重要。我的程序基于逐一添加变量并查看解释偏差的百分比如何变化，因为对于某些变量，解释偏差的百分比实际上保持不变，只有某些变量这个百分比才会上升一点。这是正确的方法吗？
PD：我选择GAM模型是因为流程专家告诉我，这个流程中存在非线性关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/644136/manual-variable-selection-in-gam-model-based-in-deviance-explained</guid>
      <pubDate>Tue, 02 Apr 2024 20:35:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 AutoARIMA 处理多维时间序列预测中的平稳性的方法</title>
      <link>https://stats.stackexchange.com/questions/639887/approach-to-handling-stationarity-in-multi-dimensional-time-series-forecasting-w</link>
      <description><![CDATA[我正在为在多个城市运营的送餐服务开展时间序列预测项目。该公司在这些城市设有多个履行中心，用于向客户发送餐食订单。我的目标是开发一个需求预测模型来预测每个运营中心未来几周的订单数量。
数据集包含有关订单数量的信息，以及中心 ID、餐食 ID、城市和地区等其他功能。由于每个中心处理多个餐食ID并且在不同的城市和地区运营，我理解平稳性对于准确预测的重要性。以下是示例数据


我计划使用 Python 中 statsmodels 库中的 ARIMA 模型进行预测，并使用 center_id、city_code、region_code、center_type 作为额外的回归量。然而，考虑到数据集的多维性质（多个中心、膳食 ID、城市和地区），我不确定如何实现平稳性。
在应用 ARIMA 之前，我是否应该分别固定每个中心、餐食 ID、城市和地区？或者使整个数据静止？如果我让每个中心、餐食 ID、城市和地区分别固定，我会迷失，那么我将如何决定 AR、MA 参数？有77个中心和55个餐点。
分别实现每个维度的平稳性的最佳方法是什么？
任何有关如何在这种情况下处理平稳性的见解或建议，特别是使用 statsforecast 方法，我们将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/639887/approach-to-handling-stationarity-in-multi-dimensional-time-series-forecasting-w</guid>
      <pubDate>Thu, 22 Feb 2024 05:09:20 GMT</pubDate>
    </item>
    </channel>
</rss>