<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 06 Nov 2024 12:33:21 GMT</lastBuildDate>
    <item>
      <title>逻辑回归后需要进行后续分析吗？</title>
      <link>https://stats.stackexchange.com/questions/656829/need-for-post-analysis-after-logistic-regression</link>
      <description><![CDATA[我正在研究一组 3200 名患者，他们存在许多术后并发症的风险因素。我在 R 中进行了逻辑回归，并使用 step() 函数改进了回归。因此，我确定了几个非常重要的风险因素。其中之一就是液体平衡。众所周知，液体过多和过少都可能促进并发症，但我从 R 中得到的是，每增加 100 毫升液体，并发症的可能性就会增加 0.03（估计值）。P=0.001。
我需要对此进行某种事后分析吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656829/need-for-post-analysis-after-logistic-regression</guid>
      <pubDate>Wed, 06 Nov 2024 12:00:05 GMT</pubDate>
    </item>
    <item>
      <title>样本量越大，错误拒绝 0 假设的风险是否会越大？</title>
      <link>https://stats.stackexchange.com/questions/656828/does-the-risk-of-incorrectly-rejecting-the-0-hypothesis-increase-with-a-large-sa</link>
      <description><![CDATA[我经常看到类似这样的话：“如果样本量足够大，较小的效应量可以产生显著的结果”。我不太明白这一点。
对我来说，这听起来是这样的：增加样本量，你最终肯定会拒绝 0 假设（也就是说，如果你将样本量增加到一定大小，你 100% 肯定会拒绝 0 假设）。
重新阅读此主题。据我所知，鉴于我在统计学方面的经验，0 假设被正确拒绝。
决定在 ttest_1samp 测试的代码中检查这一点，使 popmean=15.03 与样本 (mean=15) 的差异非常小。滑块选择 N - 样本，分布实时重新绘制，垂直条是上限值（蓝色）和 p_value（橙色）。
在大约 N - 4000 之后，在大多数情况下，零假设被拒绝。更不清楚的是，在 popmean=15 时，有时也会拒绝零假设（即均值相等）。
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import t, norm, ttest_1samp
from matplotlib.widgets import Slider

fig, ax = plt.subplots()
fig.subplots_adjust(bottom=0.25)

ax_n = fig.add_axes([0.25, 0.15, 0.65, 0.03])
s_n = Slider(ax_n, &quot;N&quot;, valmin=15, valmax=16000,valinit=30, valstep=1)

rng = np.random.default_rng(1)

def更新（val）：
N = s_n.val
rvs = np.sort（norm.rvs（loc=15，scale=1，size=N，random_state=rng））
mu，std = np.mean（rvs），np.std（rvs）
z_statistic =（rvs - mu）/ std
df = N - 1
pdf = t.pdf（rvs，loc=mu，scale=std，df=df）
p_value = ttest_1samp（rvs，popmean=15.03）[1]
ax.clear()
ax.plot（z_statistic，pdf，lw=2，color=“red”）
ax.axvline（x=t.ppf（0.975，df=df），linestyle=“--”， color=&quot;蓝色&quot;)
ax.axvline(x=t.ppf(1 - 0.975, df=df), linestyle=&quot;--&quot;, color=&quot;蓝色&quot;)
ax.axvline(x=t.ppf(p_value/2, df=df), linestyle=&quot;--&quot;, color=&quot;橙色&quot;)
ax.axvline(x=-t.ppf(p_value/2, df=df), linestyle=&quot;--&quot;, color=&quot;橙色&quot;)
ax.text(0, (np.max(pdf) + np.min(pdf))/2, &quot;p_value =&quot; + str(round(p_value, 4)), fontsize=12)

s_n.on_changed(update)
update(0)

plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/656828/does-the-risk-of-incorrectly-rejecting-the-0-hypothesis-increase-with-a-large-sa</guid>
      <pubDate>Wed, 06 Nov 2024 11:43:12 GMT</pubDate>
    </item>
    <item>
      <title>使用无模型参考模型的 Heidke 技能得分名称</title>
      <link>https://stats.stackexchange.com/questions/656822/name-for-heidke-skill-score-with-model-free-reference-model</link>
      <description><![CDATA[Heidke 技能得分是一种常用的量化预测技能的方法。它遵循技能得分 (SS) 的一般定义：
$$SS = \frac{l_m-l_r}{l_p-l_r},$$
其中 $l_p$ 表示完美模型的损失（通常为零），$l_m$ 表示模型损失，$l_r$ 表示某些参考模型的损失。给出以下列联表惯例：

摘自 Appelman 1960，$l_m = \frac{b+c}{T}$ 和 $l_r = \frac{(a+c)(a+b) + (b+d)(c+d)}{T^2}$。因此，参考模型是一个随机猜测模型，其成功概率与模型预测相同。这导致 Heidke 技能得分为 $HSS = \frac{2(ad-bc)}{(a+b)(b+d) +(a+c)(c+d)}$。这种选择让参考模型依赖于预测模型。
作为替代方案，Appelman 1960 提出了一个确定性参考模型，预测“是”如果 $X&gt;Y$，则为“否”，否则为“否”。这导致技能得分为 $\frac{d-b}{c+d}$。
我的问题是关于这两者之间的折衷，即成功概率为 $X/T$ 的随机猜测模型，因此仅基于 观察，而不会像 Appleman 技能得分的选择那样偏斜。该参考模型的损失为 $l_r = 2\frac{(b+d)(a+c)}{T^2}$，技能得分为 $\frac{(a+c)(d-c)+(b+d)(a-b)}{2(b+d)(a+c)}$。我在文献中找不到这个技能得分，它曾经被使用过或命名过吗？为什么没有？]]></description>
      <guid>https://stats.stackexchange.com/questions/656822/name-for-heidke-skill-score-with-model-free-reference-model</guid>
      <pubDate>Wed, 06 Nov 2024 10:08:54 GMT</pubDate>
    </item>
    <item>
      <title>理解广义加性模型中相似平滑函数的含义</title>
      <link>https://stats.stackexchange.com/questions/656821/understanding-the-implications-of-similar-smooth-functions-in-generalised-additi</link>
      <description><![CDATA[我对 GAM 模型有疑问。
如果我拟合两个 GAM 模型，一个包含所有变量，另一个每次添加一个变量，并且得到的平滑函数相似，这意味着什么？
为了非常清楚，我提供了一个例子：
假设我们正在使用广义加性模型 (GAM) 分析温度、湿度和风速对能源消耗的影响。我决定拟合两个模型：
模型 A：我同时包括所有预测因子（温度、湿度和风速）。
模型 B：我每次拟合多个具有一个预测因子的模型，因此您可以分别观察每个变量的平滑函数的影响。
如果模型 A 和模型 B 中各个模型的预测因子（例如湿度）的平滑函数看起来非常相似，这表明什么？
我认为存在：
变量之间的独立性：独立变量彼此之间没有很强的相关性，因此每个变量都解释了因变量中不同部分的变化。因此，每个变量的贡献在两种类型的模型中都以类似的方式表示，不受其他变量存在或不存在的影响。
共线性程度低：共线性程度低意味着变量在它们带给模型的信息方面没有太多重叠。这使得每个变量在模型中保持稳定的贡献，并且当包含或排除其他变量时，与每个变量相关的平滑函数不会发生显着变化。
这是正确的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656821/understanding-the-implications-of-similar-smooth-functions-in-generalised-additi</guid>
      <pubDate>Wed, 06 Nov 2024 09:48:05 GMT</pubDate>
    </item>
    <item>
      <title>电子商务中的 AB 测试设计 - 按用户分组并按商品统计汇总</title>
      <link>https://stats.stackexchange.com/questions/656820/ab-test-design-in-ecommerce-group-split-per-user-and-statistic-aggregation-per</link>
      <description><![CDATA[运行 A/B 测试（其中 A/B 组按用户划分，然后按项目汇总统计数据）在统计上是否正确/可行？
让我们将问题缩小到一个具体示例：

设置：一家在线商店，多家公司发布用户可以购买的商品。公司可以购买可提升网站上商品排名的插件。
目标：增加达到特定插件点击目标的商品比例（例如 5%）
测试：我们正在处理二项分布，因此选择了 Fisher 精确检验。尤其是没有那么多项目，因此测试不应该在计算上耗费精力

示例数据：
插件点击率目标：5%




计数达到目标的项目
计数未达到目标的项目




组 A
5216
1295


组 B
5558
953



Fisher 精确p 值小于 0.0001 -&gt; 结果在 alpha=0.05 时具有统计学意义。
我担心的是，这种方法（按用户分组，按项目聚合）违反了 AB 测试设计和理论的一些假设。我们运行了 500 次 AA Fisher 精确测试，alpha=0.05，在这 500 次模拟中，只有 0.012 次具有统计学意义。
我尝试在线查找采用这种方法的文章，但由于“AB 测试教程”泛滥，我无法找到相关来源（也许我的搜索技巧很差）。我问过 GenAI，模型似乎对这种方法没有问题，但是……它是 GenAI。
有人可以详细说明一下吗？有任何相关来源或链接吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656820/ab-test-design-in-ecommerce-group-split-per-user-and-statistic-aggregation-per</guid>
      <pubDate>Wed, 06 Nov 2024 08:32:55 GMT</pubDate>
    </item>
    <item>
      <title>关于自动编码器的泛化我们了解多少？</title>
      <link>https://stats.stackexchange.com/questions/656817/what-is-known-about-the-generalization-of-autoencoders</link>
      <description><![CDATA[泛化被定义为“模型正确适应新的、以前未见过的数据的能力，这些数据来自与用于创建模型的分布相同的分布。”该模型从用于训练机器学习算法的历史数据中学习模式。
关于自动编码器或其变体的泛化的现有结果是什么？我对了解原理上的泛化很感兴趣。是否有任何定理或引理可以说明自动编码器的泛化？]]></description>
      <guid>https://stats.stackexchange.com/questions/656817/what-is-known-about-the-generalization-of-autoencoders</guid>
      <pubDate>Wed, 06 Nov 2024 06:20:30 GMT</pubDate>
    </item>
    <item>
      <title>在回归分析中将累积响应作为预测因子？是否违反？</title>
      <link>https://stats.stackexchange.com/questions/656816/including-a-cumulative-response-as-a-predictor-in-a-regression-violation-or-no</link>
      <description><![CDATA[我想制作一个纵向回归模型，它看起来类似这样：

主题 i @ 时间 t：y 的变化百分比 (t,t-1) ~ f[ x 的变化百分比 (t,t-1)]

我有这样的想法，也许我可以包含所有响应的累积总和，例如

主题 i @ 时间 t：y 的变化百分比 (t,t-1) ~ f[ x 的变化百分比 (t,t-1)，来自 (t0,t-1) 的所有 y 的总和]

我认为这样做将作为参考，表明 y 的变化百分比取决于 y 已经发生的程度。例如，如果我们知道一年中通常降雨量为 100 毫米，而现在已经下了 90 毫米的雨——这取决于一年中的什么时间，未来降雨的可能性可能会更大或更小，这取决于已经下了多少雨。或者，接种新冠疫苗的人口比例增加对群体免疫的影响可能会更大或更小，这取决于已经接种疫苗的人口数量。
在回归模型中，可以将累积反应作为预测因子纳入吗？还是这违反了假设？我这样说是因为我知道将滞后反应作为预测因子绝对违反了统计假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/656816/including-a-cumulative-response-as-a-predictor-in-a-regression-violation-or-no</guid>
      <pubDate>Wed, 06 Nov 2024 05:56:33 GMT</pubDate>
    </item>
    <item>
      <title>我如何才能正确地进行前后分析来确定投票率的相关性？</title>
      <link>https://stats.stackexchange.com/questions/656815/how-can-i-properly-set-up-a-before-and-after-analysis-to-determine-a-correlation</link>
      <description><![CDATA[就我个人而言，我感兴趣的是分析在不同的城镇，某个特定行业的游说活动增加或减少是否会导致某个政党的投票率增加或减少。
为了正确分析这一点，我需要编制哪些统计数据，此外，我需要遵循哪些程序来确定相关性或对推论有 95% 的信心？这可能看起来很模糊，但我正在寻求指导，关于我如何进行这项工作，因为这些信息可能来自数百个城市。]]></description>
      <guid>https://stats.stackexchange.com/questions/656815/how-can-i-properly-set-up-a-before-and-after-analysis-to-determine-a-correlation</guid>
      <pubDate>Wed, 06 Nov 2024 04:45:58 GMT</pubDate>
    </item>
    <item>
      <title>估计一个向量 $\beta=\underbrace{\beta_1}_{\text{sparse}}+\underbrace{\beta_2}_{\text{dense}}$</title>
      <link>https://stats.stackexchange.com/questions/656812/estimate-a-vector-beta-underbrace-beta-1-textsparse-underbrace-beta</link>
      <description><![CDATA[在高维设置中，我们使用依赖于稀疏性假设的套索方法解​​决线性回归，
$$
\hat{\beta}=\underset{\beta\in \mathbb{R}^{p}}{\arg \min}\|Y-X\beta\|_2^2+\lambda\|\beta\|_1 。
$$
现在我对一个新模型感兴趣，其中$\beta$分解为一个稀疏向量和一个密集向量
$$
\beta=\underbrace{\beta_1}_{\text{sparse}}+\underbrace{\beta_2}_{\text{dense}},\\
Y=X\beta_1+X\beta_2+\epsilon,
$$
并获得估计量
$$
\left(\hat{\beta}_1,\hat{\beta}_2\right)=\underset{\beta_1,\beta_2}{\arg \min}\|Y-X\left(\beta_1+\beta_2\right)\|_2^2+\lambda_1\|\beta_1\|_a+\lambda_2\|\beta_2\|_b
$$
其中$\|\cdot\|_a$和$\|\cdot\|_b$鼓励估计量稀疏和密集。
我猜这个模型已经得到很好的研究了。现在这个模型的最佳结果是什么？你能给我提供一些相关的论文吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656812/estimate-a-vector-beta-underbrace-beta-1-textsparse-underbrace-beta</guid>
      <pubDate>Wed, 06 Nov 2024 02:42:52 GMT</pubDate>
    </item>
    <item>
      <title>变分自动编码器 - 手工制作的示例</title>
      <link>https://stats.stackexchange.com/questions/656806/variational-autoencoders-handcrafted-example</link>
      <description><![CDATA[在学习变分自动编码器 (VAE) 时，我想提出一个手工制作的小例子来帮助彻底理解它们。为此，假设我知道我的样本来自五维高斯$\mathbf{X}=(X_1,\dots,X_5)$，其中$X_2\sim\mathcal{N}(1,1)$和$X_5\sim\mathcal{N}(-1,4)$是独立的，并且$X_1=X_2$，$X_3=X_5$和$X_4=X_2+X_5$。进一步假设我们即将学习的 VAE 具有两个潜在维度。在这种情况下（如果我错了请纠正我），我预计潜在空间$\mathbf{Z}$实际上只是二维高斯$(X_2,X_5)$，因为观测数据中的所有其他随机变量完全依赖于这两个变量，并且它们是独立的。
$\textbf{Question(s) (1):}$我是否正确地认为，给定一些样本$\mathbf{x}=(x_2,x_5)$，我们理想情况下会得到$\mathbf{Z}|\mathbf{x}$只是$(x_2,x_5)$本身？例如，一个学习良好的编码器是否会产生一些结果，当从非常接近$(x_2,x_5)$的样本中进行采样时？
我不确定，因为我认为$\mathbf{Z}|\mathbf{x}$应该是一个分布，并且为了“保证”输出$(x_2,x_5)$，我们可能需要类似$p(\mathbf{Z}|\mathbf{x})=\delta(z_1-x_2)\delta(z_2-x_5)$的东西，其中$\delta$是狄拉克函数。我对这里的严格细节有点困惑，所以非常感谢您的帮助。
$\textbf{问题 (2):}$ 在实践中，我理解 $\mathbf{Z}|\mathbf{x}$ 由某个正态分布近似，其参数由某个神经网络（编码器）输出。我想在这种情况下，一个“好的”编码器输出一个正态分布的参数是有意义的，该正态分布的均值以 $(x_2,x_5)$ 为中心，协方差矩阵是对角线，对角线元素相对较小（例如 $0.01$ 左右）。这种直觉是否正确，是否符合学习编码器在实践中的表现？
$\textbf{Note:}$ 在我的屏幕上，正态分布的“\mathcal{N}”显示为方框。如果读者您也遇到同样的情况，请知道每个方框实际上都是与正态分布有关的通常“N”符号。]]></description>
      <guid>https://stats.stackexchange.com/questions/656806/variational-autoencoders-handcrafted-example</guid>
      <pubDate>Tue, 05 Nov 2024 21:59:13 GMT</pubDate>
    </item>
    <item>
      <title>联合检验复合零假设</title>
      <link>https://stats.stackexchange.com/questions/656789/jointly-testing-a-composite-null</link>
      <description><![CDATA[假设我们有一个 GLM，其 $g^{-1}(\mathbb{E}[y|x]) = \beta_0+x_A\beta_A+x_b\beta_B$。我想检验以下假设：$H_0:\beta_A \leq 0 \cup\beta_B\leq0$ $H_1:\beta_A&gt;0\cap \beta_B&gt;0$。有人能指点我如何构建一个检验方法，在这些情况下得出有效的 p 值吗？如果我没错的话，我正在检验两个复合零假设，但我不知道还能用这些信息做什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/656789/jointly-testing-a-composite-null</guid>
      <pubDate>Tue, 05 Nov 2024 14:01:25 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分解论证</title>
      <link>https://stats.stackexchange.com/questions/656666/time-series-decomposition-justification</link>
      <description><![CDATA[问题的背景。
有一条沃尔德定理，称任何协方差平稳随机过程都可以写成无限阶移动平均模型和确定性分量的总和，它是随机的，但完全确定为其过去值的线性组合。
这是一个定理，因为它可以被证明，证明可以在 Brockwell 和 Davis 的书《时间序列：理论与方法》中找到。
然而，我注意到使用以下事实非常普遍：
时间序列$\{Y_t\}_{t \in T}$可以写成因为
$$Y(t) = Y_{\text{stationary}} + f_{\text{trend}}(t) + f_{\text{periodic}}(t) + \epsilon(t)\, ,$$

$Y_{\text{stationary}}$ 是一个弱平稳过程，其中
$\mathbb{E}[Y_{\text{stationary}}] = 0$;

$f_{\text{trend}}$ 是一个趋势分量，建模为确定性
低次多项式，即 $f_{\text {trend}}(t)\sim \sum _ k c_ kt^
k$;

$f_{\text {periodic}}(t)$ 是周期分量，建模为
确定性的有限谐波和，即 $f_{\text {periodic}}(t)
\sim \sum _ k a_ k \sin (\theta _ k t)+ b_ k \cos (\theta _ k t)$。

$\epsilon (t)$ 是白噪声，即 $\epsilon (t)$独立同分布于
所有$t$，期望值为$\mathbb E[\epsilon (t)]=0$，方差为
$\mathbb E[(\epsilon (t)^2]=\sigma (t)$，且独立于其他
成分。


有多种表达方式，虽然维基百科使用不同的形式，但我更喜欢坚持使用这种形式，因为它与我在笔记中遇到的形式相匹配。我将这种分解称为“时间序列”分解”。
问题。
时间序列分解能否被证明或至少被陈述为定理，并明确规定其限制？我很惊讶我找不到任何关于它证明的参考资料。
我也不明白它与沃尔德定理有什么关系，因为这里右边可能有非平稳部分$f_{\text{trend}}(t) + f_{\text{periodic}}(t)$，而我的调查显示，没有任何关于$Y(t)$平稳性的假设。起初，我认为这应该是沃尔德定理的推论，但现在在我看来，这个定理实际上是一个更普遍事实的具体情况。
我想，即使这是一个经验法则，也应该有正式的数学推理。任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/656666/time-series-decomposition-justification</guid>
      <pubDate>Sun, 03 Nov 2024 11:50:07 GMT</pubDate>
    </item>
    <item>
      <title>多项式回归中数据中心化和标准化的正确方法</title>
      <link>https://stats.stackexchange.com/questions/656248/correct-way-of-centering-and-standardizing-data-in-polynomial-regression</link>
      <description><![CDATA[我想使用套索回归建立一个回归模型。我的理解是，我应该首先缩放和集中我的数据（例如，如此处所问：回归中需要集中和标准化数据）。
但是，我想在模型中包含测量数据的交互和二次项（因此，如果我的数据包含 A 和 B，我还想在我的模型中包含 A^2、A*B 和 B^2 作为预测因子。
我的问题是，是否先计算交互和二次项（因此先构建 X），然后独立标准化每一列，还是先标准化 A 和 B，然后从这些标准化值构建 X。
对于正态最小二乘回归，这没有什么区别，因为多项式回归模型在线性变换下不变，当且仅当多项式是“分层良好公式化”的。因此，使用任一方法的模型所做的预测都是相同的（就像它们对非标准化数据所做的预测一样）。但每个系数的值和符号可能不同（事实上，该值几乎肯定会不同），并且由于 Lasso 会规范系数的大小，因此它应该得出不同的结论。
我找不到关于哪种操作顺序更好的确切答案。一方面，在构建 X 之后进行第二次标准化将确保所有预测因子具有相同的比例并正确居中，这在直觉上是合理的。但另一方面，您会失去这些术语之间的数学联系，其中 (A^2)_scaled 不会是 A_scaled 的平方。首先缩放也是我在一些统计软件中看到的方法（尽管对于普通最小二乘回归来说，这并不重要），并且由于套索回归不一定是“层次良好地制定的”，所以我不确定它是否有效。
我很感激任何关于为什么这种方式更好/正确的建议或解释。最好有一些参考资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/656248/correct-way-of-centering-and-standardizing-data-in-polynomial-regression</guid>
      <pubDate>Thu, 24 Oct 2024 11:52:06 GMT</pubDate>
    </item>
    <item>
      <title>在弹性网络中，$λ_1$ 和 $λ_2$ 的边界曲线至少为 0 分量，这是什么？</title>
      <link>https://stats.stackexchange.com/questions/649818/what-is-the-boundary-curve-for-%ce%bb-1-and-%ce%bb-2-that-give-at-least-a-0-component</link>
      <description><![CDATA[定义弹性净估计：
$
\hat{\beta}^{\lambda_1, \lambda_2} = \arg \min_{\beta \in \mathbb{R}^p} \left( \frac{1}{2n} \| y - X\beta \|_2^2 + \lambda_1 \ \frac{1}{2} \|\beta \|_2^2 + \lambda_2 \|\beta \|_1 \right) 
$
对于套索，当$\lambda_1 = 0$时，我们可以计算$\lambda_2$的最小值，其中至少一个系数非零，以及所有系数都非零的 $\lambda_2$ 的最小值，如以下帖子所示：套索线性回归中有多少个零？，在套索中给出 0 分量的最小 $\lambda$ 是多少？。
对于弹性网络，我们可以将稀疏和非稀疏解之间的边界视为值 $\lambda_1, \lambda_2$

能否找到 $\lambda_1 \neq 0, \lambda_2$ 的闭式解，其中 $\hat{\beta}^{\lambda_1, \lambda_2}$ 的任何分量都为零？
能否找到 $\lambda_1 \neq 0, \lambda_2$ 的闭式解，其中所有分量都为零？
]]></description>
      <guid>https://stats.stackexchange.com/questions/649818/what-is-the-boundary-curve-for-%ce%bb-1-and-%ce%bb-2-that-give-at-least-a-0-component</guid>
      <pubDate>Mon, 24 Jun 2024 15:20:14 GMT</pubDate>
    </item>
    <item>
      <title>不同大小样本的统计检验</title>
      <link>https://stats.stackexchange.com/questions/619762/statistic-test-for-samples-with-different-sizes</link>
      <description><![CDATA[我应该使用什么统计测试来比较不同大小的样本？
我正在使用 DataSUS 的公共数据集，我想看看不同医院同一类型手术的平均值/中位数之间是否存在差异。
手术数量按年份分布：
对于手术类型 1，医院 x 从 2011 年到 2021 年的样本量为 653，医院 y 在同一时期的样本量为 4502（我也有每年的数字）
那么考虑到我想测试同一时期和医院的其他 4 种类型的手术，我应该使用什么测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/619762/statistic-test-for-samples-with-different-sizes</guid>
      <pubDate>Mon, 26 Jun 2023 11:12:41 GMT</pubDate>
    </item>
    </channel>
</rss>