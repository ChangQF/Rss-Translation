<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 17 Apr 2024 18:17:32 GMT</lastBuildDate>
    <item>
      <title>通过“谱分解”使用岭回归缩小系数[关闭]</title>
      <link>https://stats.stackexchange.com/questions/645248/shrinking-coefficients-using-ridge-regression-through-spectral-decomposition</link>
      <description><![CDATA[我有一个关于如何使用 SVD 技术在岭回归中计算系数 $\hat{\beta}$ 的问题。基于链接，我们可以将 $\hat{\beta}$ 编写如下：
\begin{aligned}\hat\beta_R &amp;= (X^\prime X + \lambda)^{-1}X^\prime y \\
&amp;= (VD^2V^\prime + \lambda\,1_p)^{-1}VDU^\prime y \\
&amp;= (VD^2V^\prime + \lambda V V^\prime)^{-1}VDU^\prime y \\
&amp;= (V(D^2 + \lambda)V^\prime)^{-1} VDU^\prime y \\
&amp;= V(D^2+\lambda)^{-1}V^\prime V DU^\prime y \\
&amp;= V(D^2 + \lambda)^{-1} D U^\prime y.\end{对齐}
关于这个，我有几个问题：

既然我们有项 $\frac{D}{D^2 + \lambda I }$ ，我们可以说更高的特征值，$d_i$，会导致系数降低吗？

我可以从 $U&#39;y$ 解释什么

$V$ 的效果如何。


我发现将较高的系数分配给较低的特征值有点违反直觉。虽然我认识到 $U^\prime y$ 和 $V$ 在这个框架中的作用，但我努力掌握潜在的直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/645248/shrinking-coefficients-using-ridge-regression-through-spectral-decomposition</guid>
      <pubDate>Wed, 17 Apr 2024 17:23:38 GMT</pubDate>
    </item>
    <item>
      <title>当两个泊松或伽玛过程一起触发时，交错概率是多少？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/645247/what-is-the-interleaved-probability-like-when-two-poisson-or-gamma-processes-fir</link>
      <description><![CDATA[假设在两个独立的泊松过程之后触发相同的信号
$Pois(\lambda_1)$ 和 $Pois(\lambda_2)$ 且无法区分信号由哪个过程引起的。在观察信号的发射速率时，两个参数 $\lambda_1$ 和 $\lambda_2$ 是否可以分别估算？组合模式仍然遵循泊松分布吗？两个伽玛过程怎么样？
直观上，两个进程的启动时间是否一致并不重要。但在特殊情况下，当 $\lambda_1=\lambda_2=\lambda$ 时，信号触发事件的平均速率是否为 $\frac{\lambda}{2}$?这就像两个鼓手一起敲击，在给定的固定时间间隔内，发出的节拍数应该是一个鼓手的两倍，因为由于独立性，他们同时发出的概率应该为零。]]></description>
      <guid>https://stats.stackexchange.com/questions/645247/what-is-the-interleaved-probability-like-when-two-poisson-or-gamma-processes-fir</guid>
      <pubDate>Wed, 17 Apr 2024 17:23:10 GMT</pubDate>
    </item>
    <item>
      <title>如何模拟非标准化人工数据进行逻辑回归？</title>
      <link>https://stats.stackexchange.com/questions/645246/how-to-simulate-non-standardized-artificial-data-for-logistic-regression</link>
      <description><![CDATA[我想使用原始规模的预测变量来模拟逻辑回归的数据。
当然，之前还有一连串类似的问题（例如，此处，此处和此处）。但我的问题集中在反向链接函数的操作上。
原始（未居中且未缩放）X
将原始规模的预测变量与标准反向链接函数相结合会产生阻止总体 beta 值恢复的结果。当然，我知道这个特定问题主要是反向链接函数与 xb 不匹配，因此生成的 p 值始终几乎或实际上等于 1。例如：
set.seed(42)

n &lt;- 10000

贝塔 &lt;- c(1, 2, 3)

数据 &lt;- data.frame(
  x1 = 样本(c(0,1), 大小 = n, 替换 = TRUE),
  x2 = 轮(runif(n, 18, 80)),
  x3 = rnorm(n, 100, 10)
）

# 在第二个示例中取消注释
#data$x2 &lt;- 比例(data$x2)
#data$x3 &lt;- 比例(data$x3)

x &lt;- as.matrix(数据)

xb &lt;- x %*% 贝塔
p &lt;- 1 / (1 + exp(-xb))
数据$y &lt;- rbinom(n, 1, p)

glm(y ~ -1 + x1 + x2 + x3, data = data, family = “二项式”) |&gt;
  系数()
#&gt;警告：glm.fit：算法未收敛
#&gt;警告：glm.fit：出现数字 0 或 1 的拟合概率
#&gt; x1 x2 x3
#&gt; 0.68776594 0.04537462 0.27567873

创建于 2024 年 4 月 17 日，使用 reprex v2.1.0
缩放（居中并缩放）X
但是，首先缩放连续预测变量可以防止此问题。例如：
set.seed(42)

n &lt;- 10000

贝塔 &lt;- c(1, 2, 3)

数据 &lt;- data.frame(
  x1 = 样本(c(0,1), 大小 = n, 替换 = TRUE),
  x2 = 轮(runif(n, 18, 80)),
  x3 = rnorm(n, 100, 10)
）

数据$x2 &lt;- 比例(data$x2)
数据$x3 &lt;- 比例(data$x3)

x &lt;- as.matrix(数据)

xb &lt;- x %*% 贝塔
p &lt;- 1 / (1 + exp(-xb))
数据$y &lt;- rbinom(n, 1, p)

glm(y ~ -1 + x1 + x2 + x3, data = data, family = “二项式”) |&gt;
  系数()
#&gt; x1 x2 x3
#&gt; 0.9732245 1.9205790 2.8166412

创建于 2024 年 4 月 17 日，使用 reprex v2.1.0
我尝试过的

将总体截距设置为 xb 的负均值
居中和缩放xb
将反向链接函数以 xb 的平均值为中心
根据 xb 上计算的各种统计数据对反向链接函数进行居中和缩放

但是，这些方法都不允许我生成一个模拟数据集，其中包含原始规模的预测变量以及可以通过逻辑回归轻松直接建模的响应变量。
我想要什么
我想了解如何利用截距和/或修改标准形式的反向链接函数，而不是缩放，以便生成 p 值的分布，然后导致 y 值允许恢复总体贝塔值。我想我更感兴趣的是了解如何操纵反向链接函数来“自动”操作。生成具有所需属性的 p 值。]]></description>
      <guid>https://stats.stackexchange.com/questions/645246/how-to-simulate-non-standardized-artificial-data-for-logistic-regression</guid>
      <pubDate>Wed, 17 Apr 2024 17:13:30 GMT</pubDate>
    </item>
    <item>
      <title>计算贝叶斯模型平均后验</title>
      <link>https://stats.stackexchange.com/questions/645245/computing-bayesian-model-averaged-posteriors</link>
      <description><![CDATA[给定训练数据$y$，贝叶斯模型对新数据$\tilde{y}$进行平均后验预测分布，跨一组 $M$ 模型 $\mathcal{D} = \{D_{1} , ..., D_{M}\}$，定义为：
\begin{方程}
\tag{BMA 后验}
p(\tilde{y} \mid y) = \sum_{m=1}^{M} \int_{\theta} p(\tilde{y} \mid \theta_m, D_{m}) p(\theta_ {m} \mid D_{m}, y) p(D_{m} \mid y) d \theta_{m}
\end{方程}
上述积分的第一部分以模型 $D_m$ 为条件，通常近似于 $S$&lt; /span&gt; MCMC 绘制为：
\begin{方程}
p(\tilde{y} \mid y, D_m) \approx \frac{1}{S} \sum_{s=1}^{S} p(\tilde{y} \mid \theta_{m}^{ s}，D_{m})
\end{方程}
其中 $\theta_{m}^{s}$ 是第 $s$ 个样本来自模型 $D_m$ 的后验分布，$p(\theta_m \mid y, D_m)$ .
在计算模型平均后验分布时，我们采用 $p(\tilde{y} \mid y, D_m 的期望值是否正确)$，然后使用 $p(D_{m} \mid y)$ 的完整后验对这些单个值进行加权？或者上面的等式一表明我们也取权重的平均值？
一个简单的例子：
S = 100
中号=3
softmax = 函数(x) exp(x) / sum(exp(x))

后验预测 = 矩阵(c(rnorm(S), rnorm(S), rnorm(S)), nrow=S, ncol=M)
权重=矩阵（
    sapply(1:S, 函数(i) softmax(样本(M))),
    n行=S，
    ncol=M,
    拜罗=T
）

# p(y_tilde | y, D_m)
p_y_tilde_m = apply(posterior_predictive, 2, 平均值)
p_y_tilde = p_y_tilde_m %*% t(权重)

不幸的是，这似乎产生了一个看起来不正确的分布。然而，如果我绘制
posterior_predictive %*% t(权重)

直接，甚至
# 样本分类模型索引
m = 应用(权重, 1, 函数(p) 样本(1:M, 1, prob=p))
绘图（密度（postterior_predictive[，m]））

那么结果就更符合我的预期了。
我想我知道在实践中该怎么做，但是上面等式的数学计算并不能清楚地说明何时将期望值置于边际之上。
谁能解释一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645245/computing-bayesian-model-averaged-posteriors</guid>
      <pubDate>Wed, 17 Apr 2024 17:07:19 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何分析成对且重复测量的数据？</title>
      <link>https://stats.stackexchange.com/questions/645244/how-should-i-analyze-data-that-is-paired-and-also-repeatedly-measured</link>
      <description><![CDATA[我在 11 天内从同一受试者 (n=10) 收集数据，每天在两种条件下进行测量：训练后立即 (D0) 和训练后 30 分钟 (D30)。数据是有序的，范围从 1 到 10。我想了解训练后立即进行的测量和训练后 30 分钟进行的测量之间是否存在差异。我应该如何分析这些数据，我应该使用哪种测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/645244/how-should-i-analyze-data-that-is-paired-and-also-repeatedly-measured</guid>
      <pubDate>Wed, 17 Apr 2024 17:06:04 GMT</pubDate>
    </item>
    <item>
      <title>重复性系数和测量标准误差</title>
      <link>https://stats.stackexchange.com/questions/645243/repeatability-coefficient-and-standard-error-of-measurement</link>
      <description><![CDATA[重复性系数 (CR) (Bland Altman) 用于报告可重复性，可理解为在短时间内比较同一受试者、同一观察者的测量结果的指数。
测量的标准误差用于报告仪器或秤的可靠性。也就是说，使用一种秤或仪器对多个受试者进行多次测量。
两者都是绝对测量值，支持其实际用途。
但这两个结果如何结合起来解释呢？我在 CR 中得到了不好的结果，但在 SEM 中得到了良好的可靠性。
也许我应该将 SEM 调整为 SEM95，因为 CR 本质上有这种调整？
实验如下：10名受试者在相同条件下连续测量4次。这在 5 个不同的位置重复 4 次。
重复性系数 (CR) 的计算方法为每个位置 4 次测量的标准差乘以 2.77，因此每个受试者有 4 个 CR。我们根据首选报告所有值或最大值和最小值。
测量标准误差 (SEM) 计算为所有受试者的所有数据的平方 (1-ICC) 的 SD，并且我们仅报告一个可靠性值。]]></description>
      <guid>https://stats.stackexchange.com/questions/645243/repeatability-coefficient-and-standard-error-of-measurement</guid>
      <pubDate>Wed, 17 Apr 2024 16:07:30 GMT</pubDate>
    </item>
    <item>
      <title>图像分类指标</title>
      <link>https://stats.stackexchange.com/questions/645241/image-classification-metrics</link>
      <description><![CDATA[我一直在使用 CNN 进行图像分类任务，并得到了一些令人费解的结果。
我的训练、验证和测试损失随着时间的推移不断下降，并且具有可比性。所以这可能表明没有过度拟合。
但训练准确率高于测试和验证准确率（训练集为 98%，测试集和验证集均为 92%）。
这让我有点困惑，因为通常我会看到过度拟合时验证损失和准确性都会下降。
我已检查以确保没有数据泄漏。我还确保了训练数据的洗牌（我通过 ImageDataGenerator 传递）。
我能想到的一种可能性是，模型对正确的预测越来越有信心，从而减少了损失，但其余的预测却始终错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/645241/image-classification-metrics</guid>
      <pubDate>Wed, 17 Apr 2024 15:55:37 GMT</pubDate>
    </item>
    <item>
      <title>具有 Matérn 核的高斯过程均方可微分的标准</title>
      <link>https://stats.stackexchange.com/questions/645240/criteria-for-mean-square-differentiability-of-gaussian-processes-with-a-mat%c3%a9rn-k</link>
      <description><![CDATA[我正在阅读 Stein，《空间数据插值》，1999 年，内容涉及具有 Matérn 协方差函数的高斯过程的均方 (MS) 可微性
\begin{方程*}
K( t) =\frac{\pi ^{1/2} \phi }{2^{\nu -1} \Gamma \left( \nu +\frac{1}{2}\right) \alpha ^ {2\nu }}( \alpha |t|)^{\nu } K_{\nu }( \alpha |t|),
\end{方程*}
其中 $\displaystyle \phi 、\ \alpha 、\ \nu $ 都是正参数。据说，对于 $\displaystyle \nu &gt;m$，高斯过程是 $\displaystyle m$ 倍 MS 可微分（斯坦因，第 31 页）。同时，如果协方差 $\displaystyle K( t)$ 在 $\displaystyle t=0$（Stein，第 21 页）。通过扩展，平稳高斯过程是 $\displaystyle m$ 倍可微的，如果 $\displaystyle K( t)$ 在 $\displaystyle t=0$ 处可微分 $\displaystyle 2m$ 倍。
Matérn 内核有一个因子 $\displaystyle |t|^{\nu }$ 和 $\displaystyle 2m $次导数
\begin{方程*}
\frac{\partial ^{2m}}{\partial t^{2m}}| t| ^{\nu } \varpropto \frac{| t| ^{\nu}}{t^{2m}} ,
\end{方程*}
在 $\displaystyle t=0$ 处爆炸，除非 $\displaystyle \nu \geq 2m$。因此 $\displaystyle m$ 乘以 MS 可微性的标准不应该是 $\displaystyle \nu \geq 2m$&lt; /跨度&gt;？]]></description>
      <guid>https://stats.stackexchange.com/questions/645240/criteria-for-mean-square-differentiability-of-gaussian-processes-with-a-mat%c3%a9rn-k</guid>
      <pubDate>Wed, 17 Apr 2024 15:45:57 GMT</pubDate>
    </item>
    <item>
      <title>多元阈值自回归模型的解释与分析</title>
      <link>https://stats.stackexchange.com/questions/645239/interpretation-and-analysis-of-a-multivariate-threshold-autoregressive-model</link>
      <description><![CDATA[我正在研究市场利率的不对称影响，就像联邦基金利率对利率的影响一样。换句话说，我想研究利率调整在不同市场利率环境——联邦基金利率上升环境和联邦基金利率下降环境下的反应。我的因变量是单一利率，我的自变量是联邦基金利率。我想探索使用多元阈值自回归模型。我选择这个模型是因为我可以通过对变量的状态进行建模来捕获变量之间的非线性关系。另外，我相信这个模型可以清楚地解释模型结果。
我使用 tsDyn 包中的 TVAR 函数在 R 中设置此模型。在对两个变量进行第一个差异后，我运行了模型，结果如下。我查看了文档，但找不到哪组方程属于阈值哪一侧的实际定义，但根据结果，我可以假设第一组是大于阈值的一侧，第二组是大于阈值的一侧设置小于阈值。我的问题是我对这些结果的解释是否正确。根据回归结果，我将等式 dIntRate 中的 dFedFunds 系数相加，并将系数之和解释为利率因利率变化而做出的调整。联邦基金利率。对于第 1 组，该数字为 0.71，对于第 2 组，该数字为 0.25。这本质上意味着在联邦基金利率上升的环境中，利率调整更有可能快速调整（0.71），而不是在联邦基金利率下降的环境中调整速度要慢得多（0.25）。我对这些系数的解释正确吗？
具有 1 个阈值的模型 TVAR

完整样本数量：240 最终样本数量：234
变量数量：2 估计参数数量：52 + 1
AIC -6397.454 BIC -6214.322 SSR 0.0004651241

[[1]]
                   拦截 dIntRate -1 dFedFunds -1 dIntRate -2 dFedFunds -2 dIntRate -3 dFedFunds -3
公式 dIntRate 0.0001(0.0003) 0.1103(0.1676) 0.3872(0.0981)*** -0.0772(0.1626) 0.1174(0.0818) -0.1248(0.1414) 0.0741(0.0867)
方程 dFedFunds -0.0003(0.0003) 0.3383(0.2037)。 0.1786(0.1192) -0.2581(0.1975) -0.0892(0.0994) -0.0723(0.1718) 0.0030(0.1053)
                   dIntRate -4 dFedFunds -4 dIntRate -5 dFedFunds -5 dIntRate -6 dFedFunds -6
公式 dIntRate -0.0047(0.1439) -0.1076(0.1048) 0.0945(0.1338) 0.5039(0.2227)* 0.2175(0.1696) -0.2611(0.2493)
方程 dFedFunds -0.1882(0.1749) -0.0835(0.1273) -0.2987(0.1626)。 1.1127(0.2706)*** -0.3076(0.2060) 0.7855(0.3029)*

[[2]]
                   拦截 dIntRate -1 dFedFunds -1 dIntRate -2 dFedFunds -2 dIntRate -3 dFedFunds -3
公式 dIntRate 3.6e-05(7.9e-05) -0.0311(0.0906) 0.0601(0.0778) 0.1203(0.0808) 0.2373(0.1035)* 0.1788(0.0831)* 0.0759(0.1015)
公式 dFedFunds -8.3e-06(9.6e-05) -0.0037(0.1101) 0.6435(0.0945)*** -0.1158(0.0982) 0.0259(0.1258) -0.0880(0.1010) 0.4964(0.1234)***
                   dIntRate -4 dFedFunds -4 dIntRate -5 dFedFunds -5 dIntRate -6 dFedFunds -6
方程 dIntRate -0.1564(0.0848)。 0.0244(0.0867) 0.0985(0.0895) -0.0460(0.0696) 0.0505(0.0753) 0.0497(0.0622)
方程 dFedFunds -0.2375(0.1031)* -0.2602(0.1054)* 0.1008(0.1088) 0.1491(0.0846)。 0.1282(0.0916)-0.0095(0.0756)

---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

阈值：-5e-04
每个制度中的观察百分比： 17.5% 82.5%
]]></description>
      <guid>https://stats.stackexchange.com/questions/645239/interpretation-and-analysis-of-a-multivariate-threshold-autoregressive-model</guid>
      <pubDate>Wed, 17 Apr 2024 15:38:41 GMT</pubDate>
    </item>
    <item>
      <title>两个随机变量乘积的期望</title>
      <link>https://stats.stackexchange.com/questions/645238/expectation-of-the-product-of-two-random-variables</link>
      <description><![CDATA[我最近尝试推导出一个我在论文中看到的公式。场景如下：
让 $X\in\lbrace 0,1\rbrace $ 作为。是二元随机变量， $Y$ 是连续随机变量。让 $a,b\in\mathbb{R}$。 $X$ 和 $Y$ 相关。对于公式的一部分，我必须计算 $$\mathbb{E}[a^X\mathbb{I}(Y\geq t)b^{1-X}] $$
其中 $\mathbb{I}(Y\geq t)=1$，如果 $Y\geq t$ span&gt; 和 $0$ 否则。
由于我不是 100% 确定，我想知道以下使用条件期望的方法是否正确：
$$\mathbb{E}[a^X\mathbb{I}(Y\geq t)b^{1-X}]=\mathbb{E}\left[a ^X\mathbb{I}(Y\geq t)b^{1-X}|X=0\right]\cdot\mathbb{P}(X=0)+\mathbb{E}\left[a^ X\mathbb{I}(Y\geq t)b^{1-X}|X=1\right]\cdot\mathbb{P}(X=1) $$
$$=b\cdot\mathbb{P}(Y\geq t)\mathbb{P}(X=0)+a\mathbb{P}(Y\geq t) \mathbb{P}(X=1) $$]]></description>
      <guid>https://stats.stackexchange.com/questions/645238/expectation-of-the-product-of-two-random-variables</guid>
      <pubDate>Wed, 17 Apr 2024 15:36:37 GMT</pubDate>
    </item>
    <item>
      <title>了解具有分类交互作用和不同预测变量范围的 GAM 效果图</title>
      <link>https://stats.stackexchange.com/questions/645237/understanding-effect-plots-of-gam-with-categorical-interactions-and-differing-ra</link>
      <description><![CDATA[我正在尝试对与两个分类变量相互作用的连续预测变量的复杂关系进行建模。我的样本存在偏差，因为每个分类组合都有不同的预测变量范围，如下图所示：

如果我现在用 mgcv::gam 对此进行建模
mod&lt;-gam(y ~ s(x, by=interaction(Type,ID)) + ID + Type, data=dat, method=&#39;REML&#39;)
绘图（mod，页数=1，比例=0，阴影=T）

生成的效果图如下所示：

因此，对于每个分类组合，效果图显示了整个合并预测变量范围的拟合度和范围，例如：

我想知道我是否可以做到这一点，或者是否需要在我的模型中包含一些内容来控制这一点。也许，我只需要适应许多单一模型？因为据我了解，目前，它与并不总是存在的数据之间的拟合关系可能会导致虚假的拟合和重要性？例如，x:A:3 非常显着，但如果我在头脑中从一开始就排除了该组合的下降，而该组合不存在任何数据，我会看到一条基本平坦的线...
此外，我是否需要担心每个类别组合的样本量差异很大？
我知道为了纯粹的可视化，我可以提取用于创建效果图的底层数据并重新绘制它们，同时排除每个组合范围之外的数据。但我想确保我的模型方法是正确的并且结果有效。这是一个简化版本，用于说明包含其他预测变量的更复杂模型。此外，虽然ID是一个经典的阻塞变量，但不同类型的影响可能会相互影响，这让我觉得我真的不应该为每个类型拟合单独的模型单独的 Type:ID 组合，但预测变量范围不同的问题仍然存在。]]></description>
      <guid>https://stats.stackexchange.com/questions/645237/understanding-effect-plots-of-gam-with-categorical-interactions-and-differing-ra</guid>
      <pubDate>Wed, 17 Apr 2024 15:20:25 GMT</pubDate>
    </item>
    <item>
      <title>是否有某种多级 KNN/ML 模型可以用来确定哪些用户会购买特定产品？</title>
      <link>https://stats.stackexchange.com/questions/645235/is-there-some-sort-of-multilevel-knn-ml-model-i-can-use-to-figure-out-which-user</link>
      <description><![CDATA[我想知道是否有某种多层次模型可以用来识别特定产品的可能买家或创建相似的受众群体。
问题是我有 1000 种产品和大约 100 万用户。为每种产品创建一个模型在计算上是不可行的。
我想到的结构是第一级是产品，下一级是数据库中的所有用户。
我可以使用某种机器学习算法来实现这一目标吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645235/is-there-some-sort-of-multilevel-knn-ml-model-i-can-use-to-figure-out-which-user</guid>
      <pubDate>Wed, 17 Apr 2024 15:01:00 GMT</pubDate>
    </item>
    <item>
      <title>关于包含自变量的问题</title>
      <link>https://stats.stackexchange.com/questions/645233/question-about-including-an-independent-variable</link>
      <description><![CDATA[我正在寻求有关是否在我的分析中包含自变量“吸烟”（是/否）的建议。
目标是研究 COVID-19 对女性建筑工人的影响。结果变量是受试者（女性建筑工人）在 COVID-19 期间是否受雇（是/否）。
该数据集包含来自美国 13 个随机招募地点的数据，全部由女性组成。
事实上，变量“吸烟状况”（是/否）高度不平衡（90% 否，10% 是）。在进行简单的吸烟状况与工作地点（美国 13 个地点）的双变量分析时，地点与吸烟的交叉表显示，大多数女性（与 10 个地点相关）对吸烟表示“不”，只有随机变化其余 3 个站点中女性的回答。
理论上，在新冠肺炎期间吸烟与就业之间存在密切关系（是/否）。然而，鉴于该变量高度不平衡的性质，我正在考虑是否在我的分析中包含变量“吸烟状况”。
非常感谢您的意见或建议。提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/645233/question-about-including-an-independent-variable</guid>
      <pubDate>Wed, 17 Apr 2024 14:37:31 GMT</pubDate>
    </item>
    <item>
      <title>如何计算出有多少项目会超出错误阈值？</title>
      <link>https://stats.stackexchange.com/questions/645225/how-do-i-figure-out-how-many-items-i-should-expect-to-exceed-my-error-threshold</link>
      <description><![CDATA[让我解释一下我正在使用哪些数字，然后我会解释问题。

我计算了一家商店去年所有商品的第 99 个百分位预测误差阈值。
然后，我报告过去两周内错误大于该阈值的项目数。 （无论是一天还是十四天，如果预测误差大于阈值，就会被标记。）

好的，就这样了。问题是，我想知道，在统计上，如何在给定计算方法的一般细节的情况下计算将标记的预期项目数量，以便我可以看到何时出现偏差。
我想到了泊松，因为这基本上是一个到达率问题，但这在我的脑海中感觉是循环的，因为 λ 是我开始想要的，而且我不确定我会使用什么无论如何，对于其余参数。
我的经理认为会是 1%，但我认为这是天真的地将一年内计算的 99% 的交易预测为未来 2 周内的到达率。如果这是真的，你会期望 1% 的物品会触发一天、一周、一个月，这显然是不可能的，对吧？时间越长，触发的项目就越多，时间越短，触发的项目就越少。我不确定这两周时间是否是用于计算阈值的数据的一部分是否相关？
我可以通过什么统计方法来确定预期比例？
澄清编辑：我已经在我的数据上运行了这个，所以我知道我的具体案例的基线是什么。但我不知道如何计算一般情况下触发的预期项目数。我只是想知道你会如何做到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/645225/how-do-i-figure-out-how-many-items-i-should-expect-to-exceed-my-error-threshold</guid>
      <pubDate>Wed, 17 Apr 2024 12:59:24 GMT</pubDate>
    </item>
    <item>
      <title>OLS 与 ARCH 对条件平均参数的不同估计</title>
      <link>https://stats.stackexchange.com/questions/645224/different-estimates-of-conditional-mean-parameters-from-ols-vs-arch</link>
      <description><![CDATA[考虑安全性的市场模型$i$：
$$
R_{i,t}=\alpha_i + \beta_i R_{m,t} + e_{i,t}。
$$
我用OLS方法估计了参数。
 coef std err t P&gt;|t| [0.025 0.975]
-------------------------------------------------- ----------------------------
常量 0.0219 0.040 0.548 0.584 -0.056 0.100
指数 1.2734 0.028 44.718 0.000 1.218 1.329

不过，对于每日频率，误差项显示 ARCH 效应，因此我使用 GARCH(1,1) 模型。
garch = arch_model(Y, X,mean=“LS”, vol=“GARCH”, p=1, q=1, dist=“t”, rescale=False)
results_garch = garch.fit()

输出：
 coef std err t P&gt;|t| 95.0% 浓度国际。
-------------------------------------------------- ---------------------------
常量 -0.0240 2.971e-02 -0.809 0.418 [-8.226e-02,3.418e-02]
指数 1.2203 4.473e-02 27.284 6.517e-164 [ 1.133, 1.308]
                              波动率模型
=================================================== =========================
                 coef std err t P&gt;|t| 95.0% 浓度国际。
-------------------------------------------------- ------------------------
欧米茄 0.4857 0.267 1.816 6.935e-02 [-3.847e-02, 1.010]
α[1] 0.1344 5.834e-02 2.304 2.123e-02 [2.007e-02, 0.249]
贝塔[1] 0.6634 0.155 4.275 1.913e-05 [ 0.359, 0.968]

$\hat\beta_{\text{ARCH}}$（系统风险，1.2203）低于$\hat\beta_{\text{OLS}}$ (1.2734) 具有相同的安全性？我认为它只是改变了标准错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/645224/different-estimates-of-conditional-mean-parameters-from-ols-vs-arch</guid>
      <pubDate>Wed, 17 Apr 2024 12:49:25 GMT</pubDate>
    </item>
    </channel>
</rss>