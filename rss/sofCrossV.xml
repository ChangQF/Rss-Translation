<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 19 Oct 2024 03:21:29 GMT</lastBuildDate>
    <item>
      <title>令人困惑的逻辑回归模型输出</title>
      <link>https://stats.stackexchange.com/questions/655994/confusing-logistic-regression-model-output</link>
      <description><![CDATA[我正在使用加权逻辑回归模型分析来自样本量大（&gt;88,000）的国家数据集的数据，以预测基于各种组成员身份的结果的概率。我想将每个组成员身份与不属于该组的成员进行比较，而不是与定义的参考组进行比较（例如，添加所有虚拟编码变量，而不是忽略参考变量）。对于我研究的大多数健康结果，这种方法效果很好，但其中一个结果返回的结果是，属于每个详尽且互斥的组的成员的 OR 为 &gt;1，CI 不超过零。我的解释是，与不属于该组的成员相比，每个组的几率都更高……这在逻辑上说不通。
我正在使用 SAS 9.4 surveylogistic 程序，并指定 NOMCAR 来解释缺失数据。域、权重、层、集群和模型都经过了三重准确性检查，看起来不错。所有单元格大小均大于 10。模型收敛且无错误。当我看到加权分析的结果时，所有输出看起来都很合理，并且相对接近我作为诊断的一部分运行的未加权分析的结果，尽管其中一个组在未加权分析中并不显著（未加权 OR 1.06；加权 OR 1.80，CI 1.11-2.9）
我试图确定问题是否在于在没有指定参考组的情况下进行比较（如果是这样，我预计会出现脊状误差，但没有发生）或者模型中的权重是否能够以某种方式将事物转移到这个奇怪的结果。或者相反，如果我的解释有问题，而输出没问题。任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655994/confusing-logistic-regression-model-output</guid>
      <pubDate>Sat, 19 Oct 2024 03:13:18 GMT</pubDate>
    </item>
    <item>
      <title>使用列范数限制精度矩阵的谱范数</title>
      <link>https://stats.stackexchange.com/questions/655993/bound-the-spectral-norm-of-the-precision-matrix-using-column-wise-norm</link>
      <description><![CDATA[在本文中，作者获得了关于谱范数的精度矩阵的收敛速度，（定理 1，第 7 页）
$$
\|\hat{\Omega}-\Omega\|_2 \le CM_p s_p\sqrt{\frac{\log p}{n}}
$$
其中$\|\Omega\|_{L1}=\underset{1\le j\le p}{\max}\sum_{i=1}^{p}|\omega_{ij}|\le M_p$ 和 $\underset{1\le j\le p}{\max}\sum_{i=1}^{p}1\left(\omega_{ij}\neq 0\right)\le s_p$。
他们通过控制精度矩阵的列来证明这个定理（第 37 页，不等式 (9)）：
$$
|\hat{\beta}_{S_i}-\omega_{S_i}|\le C\sqrt{\frac{\log p}{n}}
$$
其中 $\hat{\beta}_i$ 是 $\hat{\Omega}$ 的第 i 列。
我们如何使用逐列边界来控制收敛速度？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655993/bound-the-spectral-norm-of-the-precision-matrix-using-column-wise-norm</guid>
      <pubDate>Sat, 19 Oct 2024 02:44:14 GMT</pubDate>
    </item>
    <item>
      <title>二进制时间序列数据的置信带</title>
      <link>https://stats.stackexchange.com/questions/655991/confidence-bands-for-binary-time-series-data</link>
      <description><![CDATA[上下文：我有二进制数据 $x_{it}\in\{0,1\}$，其中 $i\in\{1,...,N\}$ 表示试验索引，而 $t\in\{1,...,T\}$ 表示时间索引（在试验之间独立；不在时间之间独立）。这是我运行的模拟（$N$ 次，每次 $T$ 个周期），我没有对随机过程 $\{x_{\cdot t}\}_{t=1}^T$ 的明确描述。
我的问题：我可视化了 $x_{\cdot,t}$ 在时间 $t$ 之后始终保持在 1 的频率，并绘制了每个 $t$ 的图表。我还想绘制一个“置信区间”，但我不知道如何/是否可以做到这一点。
我目前的工作：对于每个$(i,t)$，$S_{it} = \prod_{\tau=t}^{T}x_{i\tau}$ 编码事件，即对于所有$\tau\geq t$，$x_{i\tau}=1$。我在每个 $t$ 上绘制了 $\frac{1}{N}\sum_{n=1}^N 1\{S_{\cdot t}=1\}$，以可视化 $x_{\cdot t}$ 在 $t$ 时间之后保持为 1 的频率。（这正确吗？）关于可视化置信区间，我曾尝试查找有关如何对“生存曲线”进行可视化的指南（因为我所绘制的内容似乎与此相关），但我不知道它们是否适用（即使如此，我也不完全确定如何将迄今为止找到的方法转化为我的问题）。任何指导都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655991/confidence-bands-for-binary-time-series-data</guid>
      <pubDate>Fri, 18 Oct 2024 22:58:48 GMT</pubDate>
    </item>
    <item>
      <title>高效 Net V2 M ONNX 模型在小输入上的推理速度明显较慢</title>
      <link>https://stats.stackexchange.com/questions/655990/efficient-net-v2-m-onnx-model-infers-significantly-slower-on-small-input</link>
      <description><![CDATA[当我将 Efficient net v2 m 模型从 Pytorch 转换为 Onnx 以适应不同大小的输入时，我注意到一种奇怪且无法解释的行为。我希望从这个社区找到对我的观察的解释。
在我的 RTX 4090 上，1280X1280 大小图像上的 ONNX 模型在 35 毫秒内推断出批处理大小为 1。当我将图像大小缩小到大约 192X192（批处理大小相同为 1）时，运行时间几乎保持不变。这是可以理解的，因为固定开销占主导地位，例如初始化时间、线程池预热、与 GPU 之间的低效数据传输，最重要的是，计算库针对 GPU 上的矢量化和 SIMD 指令进行了优化。
然而，令人困惑的是，一旦我开始将输入图像大小减小到 192X192 以下，运行时间就会急剧增加。对于 64X64 图像，批处理大小为 1 时运行时间为 &gt;100ms。我完全理解为什么在较小的图像上推理不应该更快，但我不明白为什么它会更慢（而且慢得多）。
当我增加较小图像的批处理大小时，每批的运行时间会大幅改善（不仅仅是每幅图像的运行时间）。对于批处理大小为 16 的图像，推理 192X192 图像每批需要 25 毫秒（每幅图像不到 2 毫秒），而批处理大小为 1 时则需要 &gt;100ms。同样，我对此没有任何解释。固定开销和优化的 SIMD 矢量化将决定每幅图像的摊销运行时间应该随着批处理大小的增加而改善。但是，我观察到整个批次的运行时间也得到了改善。
对于较大的图像（例如 1280X1280），增加批次大小会增加每个批次的运行时间（尽管是亚线性的，这是完全可以预料的 - 随着批次大小的增加，每个图像的运行时间仍然会缩短到一定限度，之后，对于几乎无法放入 GPU 内存的更高批次大小，每个图像的运行时间也会增加约 10%）。
但是在 CPU 上运行时，处理时间会随着输入大小的增加而单调增加，正如预期的那样。
当我要求它对所有输入进行处理时，我已经验证了 ONNX 模型在 GPU 上成功运行。事实上，对于小输入，CPU 推理时间比 GPU 更快（这是可以理解的，因为有固定的 I/O 和其他开销）
注意：由于我在整个实验过程中将动态轴设置为 None，因此我为具有不同输入大小的同一 torch 模型保存了多个版本的 ONNX 模型。使用或不使用 onnx-sim 几乎不会对运行时间产生影响（处理速度差异小于 10-15%）。我在 C++ 中以 OrtCUDAProviderOptions 作为执行提供程序运行 onnx 模型，使用或不使用 GraphOptimizationLevel 几乎没有区别。
神经网络的输出对于所有输入都符合预期，因此我不希望我的代码中出现任何错误。
TL;DR我的 ONNX 模型对于中等大小图像的运行速度比 GPU 上的小图像更快。对于较小的图像，增加批次大小会导致每批次的处理时间大幅减少（而不仅仅是 SIMD 并行化所预期的每张图像的摊销时间）。]]></description>
      <guid>https://stats.stackexchange.com/questions/655990/efficient-net-v2-m-onnx-model-infers-significantly-slower-on-small-input</guid>
      <pubDate>Fri, 18 Oct 2024 21:24:44 GMT</pubDate>
    </item>
    <item>
      <title>从探索性数据分析中得出的特征是否会导致不准确的 K 折交叉验证？</title>
      <link>https://stats.stackexchange.com/questions/655988/do-features-derived-from-an-exploratory-data-analysis-lead-to-inaccurate-k-fold</link>
      <description><![CDATA[我对探索性数据分析、特征工程和使用 k 倍交叉验证的特征选择之间的相互作用有些困惑。如果有人能给我一些解释，我将不胜感激。
更具体地说，我想知道我尝试使用探索性数据分析找到合适的线性回归模型的情况。
假设我有一个大小为 n 的样本，每个观察值由 k 个变量组成。作为第一步，我将留出一个测试集进行最终模型评估。然后，为了了解我的反应与其他记录变量之间的关系，我会例如查看相关性，绘制数据以查看是否可能存在任何非线性关系。我还会考虑可能的相互作用。然后，我将根据我之前的观察结果创建不同的特征（多项式、平方根、交互等）。为了查看这些添加的特征是否真的改善了与基线相比的模型，我想对用于探索性数据分析的相同数据（即除先前为最终模型评估预留的观测值之外的所有观测值）执行 k 倍交叉验证。但是，我想知道这种方法是否有缺陷，因为我根据我的观察进行了特征工程，其中已经包括用于 k 倍交叉验证的完整数据，即每个步骤中遗漏的折叠。这不会导致数据泄露吗？因为我犯了一个类似的错误，就像我在对整个数据集执行特征工程时一样，即这通常会导致模型产生良好的 k 倍交叉验证结果，但在测试数据上结果不佳吗？如果是这样，检查我设计的特征是否确实相关的正确方法是什么？留出额外的验证集？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655988/do-features-derived-from-an-exploratory-data-analysis-lead-to-inaccurate-k-fold</guid>
      <pubDate>Fri, 18 Oct 2024 20:54:09 GMT</pubDate>
    </item>
    <item>
      <title>关于运行k均值聚类分析的问题</title>
      <link>https://stats.stackexchange.com/questions/655987/question-about-running-k-means-cluster-analysis</link>
      <description><![CDATA[在之前的分析中，我有 3 组受试者 - 组 x 有 35 名受试者，对照组 y 有 25 名受试者，对照组 z 有 25 名受试者。对于每组，我都有 6 种不同的生物标志物水平（我们可以将它们称为生物标志物 a、b、c、d、e 和 f）。我比较了各组之间每种生物标志物的水平，发现没有显著差异。但是，我有理由相信，组 x 中将存在有意义的受试者亚组，这些亚组的一种或多种代谢物水平将与一个或两个对照组不同。对于所有 85 名参与者，我还有其他数据，我认为这些数据可能与构建亚组有关 - 具体来说，我有 7 种不同类型的智商数据（我们将它们称为智商 a、b、c、d、e、f 和 g），以及两个人口统计变量，具体来说是年龄和受教育年限。现在我想要做的是对组 x 运行 k 均值聚类分析，以找到该组中涉及生物标记的任何有意义的子组 - 例如，我可能会发现两个聚类；一个聚类具有高水平的生物标记 d、低智商 b 和低受教育年限（我们称之为聚类 A），另一个聚类具有低水平的生物标记 e、高智商 f 和高年龄（我们称之为聚类 B）。然后，我们的想法是取每个聚类，并将该聚类中涉及的生物标记水平与两个对照组中这些生物标记的水平进行比较。例如，对于簇 A，我将比较组 x 中的生物标志物 d 水平与两个对照组中每个组的生物标志物 d 水平，如果我发现组 x 的生物标志物 d 水平与其中一个或两个对照组不同，那么我可以说组 x 中有一组受试者的生物标志物 d 水平高、智商 b 低、受教育年限低，其生物标志物 d 水平与其中一个或两个对照组不同。然后，​​对于簇 B，我将比较组 x 中的生物标志物 e 水平与两个对照组中每个组的生物标志物 e 水平，如果我发现组 x 的生物标志物 e 水平与其中一个或两个对照组不同，那么我可以说组 x 中有一组受试者的生物标志物 e 水平低、智商 f 高、年龄大，其生物标志物 e 水平与其中一个或两个对照组不同。
上述聚类分析似乎是一条不错的途径。但是，我对聚类分析完全是新手。有人告诉我，x 组中的 35 名受试者不足以运行 k 均值聚类分析，因为如果我对这么小的组运行它，我得到的任何结果很可能只是噪音。所以我需要更多的受试者才能进行聚类分析。不幸的是，我没有更多的 x 组受试者。所以，我想这样做，我想看看这是否是一种回答我的研究问题的有效方法。为了获得更多数据，我将在聚类分析中不仅包括来自 x 组的受试者，还包括来自对照组 y 和 z 的受试者。这样我就可以共有 85 名受试者进行聚类分析，我想这应该足够了。然后假设我找到了上面提到的相同的两个簇，但包括了所有三个组的参与者（谁知道是否真的如此，但我们只是假设一个例子） - 假设对于簇 A，我们再次具有高水平的生物标志物 d、低智商 b 和低受教育年限，并且假设簇 A 有 12 个来自 x 组的受试者、2 个来自 y 组的受试者和 1 个来自 z 组的受试者；然后对于簇 B，我们再次具有低水平的生物标志物 e、高智商 f 和高年龄，并且簇 B 有 11 个来自 x 组的受试者、3 个来自 z 组的受试者和 1 个来自 y 组的受试者。然后，我想这样做：对于 A 组，我可以从组 x（n=12）中选取 12 名受试者，并将他们的生物标志物 d 水平与对照组 y（n=25）中的生物标志物 d 水平进行比较，然后将其与对照组 z（n=25）中的生物标志物 d 水平进行比较。同样，对于 B 组，我将从组 x（n=11）中选取 11 名受试者，并将他们的生物标志物 e 水平与对照组 y（n=25）中的生物标志物 e 水平进行比较，然后将其与对照组 z（n=25）中的生物标志物 d 水平进行比较。 所以我的问题是，这是否是一种有效且可行的方法，仍然能够运行聚类分析来回答我的研究问题，即 x 组中是否存在有意义的亚组，这些亚组在一个或多个生物标志物的水平上与一个或两个对照组不同。
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/655987/question-about-running-k-means-cluster-analysis</guid>
      <pubDate>Fri, 18 Oct 2024 20:39:41 GMT</pubDate>
    </item>
    <item>
      <title>两个随机变量之间差异的概率区间</title>
      <link>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</link>
      <description><![CDATA[如果 X1​ 在区间 [L1, R1] 内的概率为 95%，X2 在区间 [L2, R2] 内的概率为 95%，这是否意味着 X1−X2 在区间 [L1−R2, R1−L2] 内的概率将超过 95%？X1 和 X2 可能是相关的，也可能是独立的。
有人能为此提供证据或反例吗？
我很感激任何帮助解决问题的人！]]></description>
      <guid>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</guid>
      <pubDate>Fri, 18 Oct 2024 19:35:37 GMT</pubDate>
    </item>
    <item>
      <title>具有反射的离散布朗运动的表达式</title>
      <link>https://stats.stackexchange.com/questions/655982/expression-for-discrete-brownian-motion-with-reflection</link>
      <description><![CDATA[对于具有吸收状态的离散布朗运动，我们可以将位置分布表示为两个二项分布的线性和，如此处所述，其中 +1 和 -1 步的几率为 1:1，此处所述，用于更一般的几率不相等的情况。
具有反射墙的离散布朗运动的情况如何？
假设我们将时间 $t$ 的位置描述为 $X(t)$，起始位置为 $X(0) = 1$。有概率 $p$ 我们向前迈一步 $X(t+1) = X(t) + 1$ ，有概率 $1-p$ 我们向后迈一步 $X(t+1) = X(t) - 1$ ，除非 $X(t) = 0$ ，在这种情况下我们总是向前迈一步。]]></description>
      <guid>https://stats.stackexchange.com/questions/655982/expression-for-discrete-brownian-motion-with-reflection</guid>
      <pubDate>Fri, 18 Oct 2024 19:26:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 包 marginaleffects 进行编码比较和交互</title>
      <link>https://stats.stackexchange.com/questions/655981/coding-comparisons-and-interactions-with-the-r-package-marginaleffects</link>
      <description><![CDATA[我开始学习如何使用 R 包 marginaleffects，并希望得到一些特定应用方面的帮助。
为了说明，我们使用 afex 包中的数据集。变量 phase 是一个具有三个级别的因子：“fup”、“post”和“pre”。变量 age 是连续的。下面是使用 lme4 拟合的模型：
library(afex); library(lme4); library(phia)
data(obk.long, package = &quot;afex&quot;)
options(contrasts = c(&quot;contr.sum&quot;, &quot;contr.poly&quot;))
fm &lt;- lmer(value ~ phase * age + (1|id), data = obk.long)

我想使用 marginaleffects 复制以下七个比较和交互：

对比因子 phase 的前两个级别（“fup”与“post”）
在 phia 中，这是通过以下方式完成的：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), adjustment = &quot;none&quot;)


对比phase的前两个级别，其中age固定为 5.5
在phia中：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), covariates = c(age = 5.5), adjustment = &quot;none&quot;)


age的斜率（phase所有级别的平均值）
在phia中：
testInteractions(fm, pairwise = NULL, slope = &quot;age&quot;, adjustment = &quot;none&quot;)


前两个级别之间的age斜率差异 (&quot;fup&quot; vs. &quot;post&quot;) 的 phase
在 phia 中：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), slope = &quot;age&quot;, adjustment = &quot;none&quot;)


phase 的三个级别之间的综合对比（例如 &quot;fup&quot; - &quot;pre&quot; 和 &quot;post&quot; - &quot;pre&quot;）
在 phia 中：
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))))


phase 三个级别的综合斜率比较（例如，&quot;fup&quot; 与 &quot;pre&quot; 以及 &quot;post&quot; 与 &quot;pre&quot; 的斜率差异）
在 phia 中：
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))), slope = &quot;age&quot;)


固定年龄的 phase 三个级别的综合对比（例如，&quot;fup&quot; - &quot;pre&quot;和“post” - “pre” 在 age = 5.5)
在 phia:
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))), covariates = c(age = 5.5))



我的问题是：如何使用 marginaleffects 包对这七个效应进行编码？]]></description>
      <guid>https://stats.stackexchange.com/questions/655981/coding-comparisons-and-interactions-with-the-r-package-marginaleffects</guid>
      <pubDate>Fri, 18 Oct 2024 18:51:31 GMT</pubDate>
    </item>
    <item>
      <title>我们如何模拟在多层次/混合效应设置中在不同层次上变化的相关随机变量？</title>
      <link>https://stats.stackexchange.com/questions/655980/how-can-we-simulate-correlated-random-variables-that-vary-at-different-levels-in</link>
      <description><![CDATA[我非常熟悉从多元正态分布中生成相关随机变量。
这个问题是关于在多级设置中执行此操作，其中变量仅在分组变量的特定级别上变化。
假设我们有一个分组因子 - group，我们希望模拟 2 个随机变量，x1 和 x2，其中 x1 在较低级别变化，x2 在较高级别变化。假设下层有 100 个（n1 = 100）观测值，上层有 20 个不同的观测值（n2 = 20，但显然每个值都重复 5 次，因此组大小都相等（即每组 5 个）。
我们如何模拟 x1 和 x2，使得 sd(x1) = 5 和 sd(x2) = 3 以及 Cov(x1,x2) = 2？
我不需要任何代码。我有一些代码，但希望得到一些关于该方法的反馈，如下所示：
在这种模拟两级分层模型数据的方法中，我们旨在生成两个随机变量，x1 和x2，其中 x1 在较低（个体）水平上变化，而 x2 在较高（组）水平上变化。关键目标是确保 x1 和 x2 的标准差分别指定为 5 和 3，并且 x2 的扩展版本（在组内个体之间复制）和 x1 之间的协方差设置为 2（出于此模拟的目的）。该过程首先在组级别生成 x2，其中包含 20 个组的 20 个不同值，每个值的标准差为 3。然后，这些组级别值在每个组内的个体之间复制，以创建扩展的 x2。为了实现 x1 和 x2 之间所需的协方差，我们计算一个将 x1 与扩展的 x2 相关联的共享分量。此共享分量来自协方差公式，将所需的协方差除以扩展的 x2 的方差。然后，我们通过向共享分量添加独立噪声来生成 x1，确保 x1 的整体方差等于 5。此方法尝试允许跨层次结构级别控制相关数据的生成，从而确保正确的标准差和协方差。这是我实现此功能的代码。
# 参数
n1 &lt;- 1000 # 1 级（个体级）的观察总数
n2 &lt;- 200 # 2 级（组级）的组总数
group_size &lt;- n1 / n2 # 每个组的大小

# 所需的标准差和协方差
sd_x1 &lt;- 5
sd_x2 &lt;- 3
cov_x1_x2 &lt;- 2

# 模拟次数
n_sim &lt;- 100

vec_sd_1 &lt;- numeric(n_sim)
vec_sd_2 &lt;- numeric(n_sim)
vec_cov &lt;- numeric(n_sim)

set.seed(15)

for (i in 1:n_sim) {

# 1. 生成组级变量 x2（sd = 3）
x2_group &lt;- rnorm(n2, mean = 0, sd = sd_x2)

# 2. 为组中的每个个体复制 x2（扩展 x2）
x2 &lt;- rep(x2_group, each = group_size) # 这使得 x2 长度为 n1

# 3. 根据扩展的 x2 计算正确的共享组件
shared_component &lt;- cov_x1_x2 / var(x2) # 与扩展的 x2 相关的 x1 部分

# 4. 生成个体级随机变量 x1
x1 &lt;- x2 * shared_component + rnorm(n1, mean = 0, sd = sqrt(sd_x1^2 - shared_component^2 * var(x2)))

# 检查结果
group &lt;- rep(1:n2, each = group_size)

# 带有模拟数据的数据框
data &lt;- data.frame(group = factor(group), x1 = x1, x2 = x2)

vec_sd_1[i]&lt;- sd(data$x1)
vec_sd_2[i] &lt;- sd(data$x2)
vec_cov[i] &lt;- cov(data$x1, data$x2) 

}

mean(vec_sd_1) 
mean(vec_sd_2)
mean(vec_cov)

结果如下：
&gt;平均值（vec_sd_1） 
[1] 4.990359
&gt; 平均值（vec_sd_2）
[1] 2.994848
&gt; 平均值（vec_cov）
[1] 2.003473

看起来不错，任何反馈都会很感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/655980/how-can-we-simulate-correlated-random-variables-that-vary-at-different-levels-in</guid>
      <pubDate>Fri, 18 Oct 2024 18:23:10 GMT</pubDate>
    </item>
    <item>
      <title>在具有对数链接的泊松 GEE 中对二进制结果进行反转编码时，P 值会发生变化，但逻辑 GEE 或 OLS 则不会</title>
      <link>https://stats.stackexchange.com/questions/655975/p-value-changes-when-invert-coding-of-binary-outcome-in-poisson-gee-with-log-lin</link>
      <description><![CDATA[我们在面板数据上运行具有二元结果（是/否）的回归模型。结果非常常见（93.6%=是，n=4231 个观察值中的 3961 个）。我们使用 GEE 模型来解释每个参与者的多个观察值。
当我们运行具有对数链接的泊松 GEE 模型（每个预测变量一个模型）时，p 值会根据结果是正编码（是=1）还是负编码（否=1）而有很大差异，并且某些结果会根据编码而变得重要。但是，当我们在相同变量上运行逻辑 GEE 模型时，基于正编码和负编码的 p 值没有差异。 （注意：对数二项式模型不收敛，因此我们无法测试这一点）。
如果结果的编码可以改变重要性，我们会担心泊松结果的有效性。
1.) 为什么泊松模型会产生不同的逆编码 p 值，但逻辑编码不会产生不同的 p 值？这是否与结果的普遍程度有关（如果编码为 Yes=1）？
2.) 如果使用一致的编码（例如，所有模型的 Yes=1），是否可以使用泊松 GEE 的结果？
模型的示例编码：
model1.poisson.yes = geeglm(formula = consequence_yes ~ binary_predictor1, 
id = uuid,
family = poisson(&quot;log&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

model1.poisson.no = geeglm(formula = consequence_no ~ binary_predictor1, 
id = uuid,
family = poisson(&quot;log&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

model1.logistic.yes = geeglm(formula = consequence_yes ~ binary_predictor1, 
id = uuid,
family = binomial(&quot;logit&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

model1.logistic.no = geeglm(formula = consequence_no ~ binary_predictor1, 
id = uuid,
family = binomial(&quot;logit&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

]]></description>
      <guid>https://stats.stackexchange.com/questions/655975/p-value-changes-when-invert-coding-of-binary-outcome-in-poisson-gee-with-log-lin</guid>
      <pubDate>Fri, 18 Oct 2024 16:02:55 GMT</pubDate>
    </item>
    <item>
      <title>调整因变量的个别值</title>
      <link>https://stats.stackexchange.com/questions/655970/adjusting-individual-values-of-a-dependent-variable</link>
      <description><![CDATA[我有一个数据集，其中包含 600 个脉搏波速度读数，我需要根据每个参与者的平均动脉血压进行调整。我可以得到这样的结果：
m &lt;- lm(pulse_wave_velocity ~ mean_arterial_bp, data = df)

那么我是否可以使用模型中的残差来计算调整后的脉搏波速度，如果是，是否应该将它们添加到截距中？]]></description>
      <guid>https://stats.stackexchange.com/questions/655970/adjusting-individual-values-of-a-dependent-variable</guid>
      <pubDate>Fri, 18 Oct 2024 14:57:17 GMT</pubDate>
    </item>
    <item>
      <title>负二项回归与普通逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/655965/negative-binominal-regression-vs-ordinary-logistic-regression</link>
      <description><![CDATA[我有选举期间的社交媒体数据，其中包含数千名政治人物在社交媒体上的帖子。数据集有许多控制变量，例如日期、关注者数量、视觉效果的存在、是否是热门演员的转发等。
这项研究本质上是关于语言学的。我的目标是测试隐喻相关指标是否与高参与度（喜欢、分享、评论）相关。由于它是社交媒体数据，因此存在高度过度分散。我确认负二项回归是最佳选择。
在用喜欢计数拟合模型后，我注意到该模型在处理参与度非常高或参与度非常低的帖子时遇到了困难。它似乎也有显著的异常值。




考虑到这是高度密集时期的社交媒体数据，我对模型在某些帖子上遇到困难并不感到惊讶。大多数被低估的帖子都包括特殊/耸人听闻的视觉效果、视频或公告，这些都使它们非常高。
由于它们不是虚假数据并且是社交媒体固有的，所以我没有删除它们。主要目标不是建立一个预测参与度的模型，而是看看隐喻指标是否与参与度呈正相关。
我想知道这是否是正常的，因为数据的性质。此外，NBR 是否对我来说是正确的测试，或者我是否应该在根据百分位数将参与度数据分解为高、中、低参与度后考虑 OLR。]]></description>
      <guid>https://stats.stackexchange.com/questions/655965/negative-binominal-regression-vs-ordinary-logistic-regression</guid>
      <pubDate>Fri, 18 Oct 2024 14:02:35 GMT</pubDate>
    </item>
    <item>
      <title>回归模型中每个变量都需要具有统计显著性吗？</title>
      <link>https://stats.stackexchange.com/questions/655938/does-every-variable-need-to-be-statistically-significant-in-a-regression-model</link>
      <description><![CDATA[我最近拟合了一个回归模型 (ARIMAX)，其中有些变量 (3) 具有统计显著性，有些则不显著 (1)。我删除了统计上不显著的变量并重新拟合模型，现在所有变量都具有统计显著性（即新模型有 3 个变量，旧模型有 4 个变量）。
但是，这个新模型（所有变量都具有统计显著性）的表现比旧模型（并非所有变量都具有统计显著性）更差。也就是说，新模型的预测误差比旧模型更严重。
这是统计学中的常见做法吗？如果所有变量都具有统计显著性，选择性能较差的模型是否更可取，还是最好选择性能较好的模型，即使并非所有变量都具有统计显著性。
我知道过度拟合和交叉验证等概念。我使用除过去 6 个月数据之外的所有可用数据训练了这两个模型。我还让这两个模型预测过去 6 个月的可用数据，并将预测值与实际值进行比较。使用旧模型（即并非所有变量都具有统计显著性的模型）我仍然获得了更好的结果。
即使并非所有变量都具有统计显著性，是否可以采用性能更好的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/655938/does-every-variable-need-to-be-statistically-significant-in-a-regression-model</guid>
      <pubDate>Fri, 18 Oct 2024 01:02:57 GMT</pubDate>
    </item>
    <item>
      <title>解释“百分比增加/减少”中的逻辑回归系数</title>
      <link>https://stats.stackexchange.com/questions/655930/interpreting-logistic-regression-coefficients-in-percentage-increase-decrease</link>
      <description><![CDATA[我理解，从逻辑回归来看（假设有两个预测因子）
$$\log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1x_1 + \beta_2 x_2$$
并且当 $x_1$ 为二进制时，可以按如下方式解释
$e^{\hat\beta_1} = \frac{odds(p|x_1 = 1)}{odds(p|x_1 = 0)}$
我读过一篇利用逻辑线性回归的论文，结果如下。
$$\log\left(\frac{p}{1-p}\right) = -1.86-0.15\times x_1 + 0.33\times x_2$$
$x_1$ 是连续变量，而 $x_2$ 是二进制变量。
据我所知，以下是作者对结果的解释。

$x_1$ 相对于均值每增加一个单位，$p$ 的概率就会下降 13%。
$x_2 = 1$ 对应于 $p$ 相对于 $x_2 = 0$ 增加 34%&gt;

我可以根据比值比来解释系数，但在讨论 p 的百分比增加/减少时，这个数字是如何得出的？
我已经努力理解了好几个小时，所以我真的需要一些帮助！提前谢谢您。
此外，有关该论文的更多信息，请访问https://www.jstor.org/stable/2657467。]]></description>
      <guid>https://stats.stackexchange.com/questions/655930/interpreting-logistic-regression-coefficients-in-percentage-increase-decrease</guid>
      <pubDate>Thu, 17 Oct 2024 20:02:14 GMT</pubDate>
    </item>
    </channel>
</rss>