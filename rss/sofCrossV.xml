<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 18 Jan 2025 09:15:16 GMT</lastBuildDate>
    <item>
      <title>计算有条件计分的积分制游戏中的概率和预期回合数</title>
      <link>https://stats.stackexchange.com/questions/660191/calculating-probability-and-expected-rounds-in-a-point-based-game-with-condition</link>
      <description><![CDATA[Ann 和 Ben 正在玩一个由多轮组成的游戏。第一个达到 $10$ 分的人将赢得游戏。每轮只有一名获胜者。假设各轮是独立的，Ann 赢得每轮的概率为 $0.6$。
a) 如果每轮获胜者获得 $2$ 分，则计算 Ann 赢得比赛的概率。
b) 与 (a) 相同，但如果获胜者还赢得了上一轮，则他们将获得额外的 $1$ 分。
c) 计算在场景 (a) 和 (b) 中 Ann 获胜所需的预期轮数。
以下是我对 (a) 部分的解决方案：
Ann 的第一个获胜配置是 AAAAA，表示 Ann 连续在所有 $5$ 轮中获胜。显然，这种情况的概率是 $0.6^5$。
Ann 的下一个获胜配置是五个 $6$ 轮 BAAAAA、ABAAAA、AABAAA、AAABAA、AAAABA。它们代表所有 $6$ 个字母的组合，其中只有一个 B，最后一个字母是 A。这五种情况的概率为 $5*0.6^5*0.4$。
Ann 的下一个获胜配置都是 $(6*5)/2 = 3*5 = 15$ 个七个字母的组合，字母 A 和 B，其中 $2$ B 和 $5$ A 的顺序任意，但最后一个字母是 A。这五种情况的概率为 $15*0.6^5*0.4^2$。
系数 $(6*5)/2 = 15$ 是将 $2$ 个字母 B 放置在 $6$ 个可能位置上的数量。
Ann 的下一个获胜配置是所有 $8$ 个字母的单词，字母 A 和 B 分别为 $5$ 个 A 和 $3$ 个 B，其中 A 位于最后一个位置。他们会为这些场景添加概率${7\choose 3}*0.6^5*0.4^3 = 35*0.6^5*0.4^3$。这里 ${7\choose 3} = 35$ 是将 $3$ 个字母 B 放置在 $7$ 个可能位置上的数量。
Ann 的下一个获胜配置是所有 $9$ 个字母的单词，字母 A 和 B 分别为 $5$ 个 A 和 $4$ 个 B，其中 A 位于最后一个位置。他们会为这些场景添加概率${8\choose 4}*0.6^5*0.4^4 = 70*0.6^5*0.4^4$。这里 ${8\choose 4} = 70$ 是将 $4$ 个字母 B 放置在 $8$ 个可能位置上的数量。
现在最后一个计算是计算 $5$ 个加数的总和
$P = 0.6^5 + 5*0.6^5*0.4 + 15*0.6^5*0.4^2 + 35*0.6^5*0.4^3 + 70*0.6^5*0.4^4 = 0.6^5*(1 + 5*0.4 + 15*0.4^2 + 35*0.4^3 + 70*0.4^4) = 0.73343232$。
目前，我没有任何解决部分 (b) 和 (c) 的想法，所以我希望有人能支持我找到这些问题的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/660191/calculating-probability-and-expected-rounds-in-a-point-based-game-with-condition</guid>
      <pubDate>Sat, 18 Jan 2025 07:42:24 GMT</pubDate>
    </item>
    <item>
      <title>季节性虚拟变量回归。为什么我们要在这个回归中使用时间趋势？或者说，在什么情况下我们应该使用时间趋势？</title>
      <link>https://stats.stackexchange.com/questions/660180/regression-with-seasonal-dummies-why-do-we-use-time-trend-in-this-regression-o</link>
      <description><![CDATA[我的导师希望我用季节性虚拟变量进行回归分析。
我有 DPPI 指数（土耳其国内生产者价格指数），这是月度数据。
首先，我需要用截距项和 11 个虚拟变量进行回归分析。
其次，我需要用 12 个虚拟变量进行不带截距项的回归分析。
在这两种情况下，我都应该包括时间趋势项吗？在哪种情况下，或者为什么包括时间趋势项？
或者，我应该同时使用和不使用时间趋势项进行这两个回归分析吗？
我的最后一个问题是我需要分析残差。为此，我应该对残差应用哪些测试或图？
请与我分享您的想法。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660180/regression-with-seasonal-dummies-why-do-we-use-time-trend-in-this-regression-o</guid>
      <pubDate>Fri, 17 Jan 2025 18:42:39 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SE 和 P 值计算每 100,000 个比率之间的差异</title>
      <link>https://stats.stackexchange.com/questions/660173/how-to-calculate-the-difference-between-2-rates-per-100-000-with-se-and-p-value</link>
      <description><![CDATA[我有一个数据集，其中包含每年记录的每 100,000 人口年龄调整死亡率及其针对特定疾病的标准误差 (SE)。数据来自 CDC Wonder 数据库。
我旨在通过计算差异、构建置信区间 (CI) 和确定此差异的 p 值来比较两个特定年份之间的死亡率。
此外，我旨在通过以下方式计算相对比率变化：
$$
\text{相对变化} = \frac{(\text{第 2 年比率} - \text{第 1 年比率})}{\text{第 2 年比率}}
$$
这在统计上合适吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660173/how-to-calculate-the-difference-between-2-rates-per-100-000-with-se-and-p-value</guid>
      <pubDate>Fri, 17 Jan 2025 16:46:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Mercer 定理总是被引用于核学习而不是 Moore-Aronszajn</title>
      <link>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</link>
      <description><![CDATA[为什么在大多数关于核技巧的解释中，Mercer 定理都用作依据？
我们能否用 Moore-Aronszajn 来证明这一点，该定理不将紧致性假设置于 $X$ 和 $k$ 连续性上？
编辑：
那么，核技巧背后的想法是，我们能够计算某个希尔伯特空间 $H$ 中的内积，而不必将数据嵌入该空间，因为 $k(x,x&#39;) = \langle \phi(x), \phi(x&#39;) \rangle_{H}$，对于某个 $\phi : X \mapsto H$
现在，经常引用 mercer 定理来证明这样的 $\phi$ 存在。然而，通过 Moore-Aronszajn 定理，我们知道对于 p.d. 核 $k$，特征图 $\phi_{H_k}: X \mapsto H_k = \mathbb{R}^X$，其中 $\phi_{H_k}(x) = k(x,\cdot)$ 满足 $k(x,x&#39;) = \langle \phi(x)_{H_k}, \phi_{H_k}(x&#39;) \rangle_{H_k}$。那么，为什么 Mercer 经常被引用呢？此外，有些 p.d. 核不是连续的，因此无法通过 Mercer 定理进行论证。]]></description>
      <guid>https://stats.stackexchange.com/questions/660158/why-mercers-theorem-is-always-cited-for-kernel-learning-and-not-moore-aronszajn</guid>
      <pubDate>Fri, 17 Jan 2025 11:39:14 GMT</pubDate>
    </item>
    <item>
      <title>加权交叉熵的理论依据</title>
      <link>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</link>
      <description><![CDATA[假设我们正在构建一个二元分类模型，可以将其视为学习函数
$$ p : X \mapsto [0, 1] $$
其中$p(X) := \mathbb{P}(Y=1|X)$，而$\hat{p}$是某种机器学习模型（例如神经网络）。
常用的损失函数是最小化$p$和$\hat{p}$之间的负交叉熵：
$$ l(p, \hat{p}) = -y\log \hat{p}(x) - (1-y)\log(1-\hat{p}(x))$$
这当然相当于模型$Y|X \sim Bernoulli(p(X))$的最大似然估计。
在某些情况下，结果高度不平衡，这使得训练在实践中变得困难。例如，如果数据是垃圾邮件分类，其中只有 1% 的结果是垃圾邮件，那么很容易收敛到一个简单的解决方案/局部最优，它只为每个观察设置$p(X) \approx 0$。理论上，在大样本量和全局最优的情况下，这不是问题 - 但在实践中，这可能是一个大问题。
解决这个问题的一种常见方法是使用“加权交叉熵”损失，其中权重与观察到的频率成比例。例如，
$$w_0 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=0\}}, w_1 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=1\}} $$
损失为
$$ l^{weighted}(p, \hat{p}) = -w_1y\log\hat{p}(x) - w_0(1-y)\log(1-\hat{p}(x)) $$
其中直觉是稀有类别的权重更高，因此模型“更加关注”对这些观察结果。

通过最小化这个加权损失函数找到的最优函数 $\hat{p}^{weighted}$ 是否有任何已知的理论性质，或者它是否纯粹是启发式的？在全局最优值中，最优 $\hat{p}$ 和 $\hat{p}^{weighted}$ 相比如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</guid>
      <pubDate>Fri, 17 Jan 2025 09:25:45 GMT</pubDate>
    </item>
    <item>
      <title>日食是否减少了新冠肺炎死亡人数？</title>
      <link>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</link>
      <description><![CDATA[我在 R 中模拟了一些现实数据，这些数据显示了 Covid-19 死亡人数随时间的变化情况，以及日食（2024 年 4 月 8 日）发生前的天数：

如果有人不太了解，仅从数据来看，可能会认为日食是降低 Covid 死亡人数的原因。此外，有人可以拟合回归模型，该模型甚至可能很好地拟合数据。
我读到过，我们在统计学中拥有所有这些复杂的技术，例如差异-差异、回归不连续性、合成控制、工具变量、倾向得分匹配等 - 所有这些方法旨在在某种程度上找出我们是否能够真正得出结论，统计模型的结果忠实地代表了自然（例如因果关系与联想关系）。
但在某种程度上，我们在决定将哪些变量纳入统计模型时是否只是使用常识？]]></description>
      <guid>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</guid>
      <pubDate>Fri, 17 Jan 2025 05:13:01 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归中的虚拟变量与虚拟变量交互作用</title>
      <link>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</link>
      <description><![CDATA[我正在 R 中进行泊松回归，以估计按年龄组和病毒分类的死亡人数，其中相互作用的项是因子：
model &lt;- glm(death_count ~ strain * cohort + age + year,
family = poisson(link = &quot;log&quot;),
offset = log(exposure),
data = df)

我的 df 是面板数据，其中包含每年特定年龄的死亡人数。每年都以特定病毒为特征，每个年龄分配一个群体。我试图找出以病毒 C 为特征的年份中死亡人数减少的统计意义。以下是简化的回归输出：
 估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -15.39575 0.07621 -202.012 &lt; 2e-16 ***
病毒A -1.29389 0.08358 -3.516 0.000437 ***
病毒B 2.80059 0.06230 12.851 &lt; 2e-16 ***
病毒C 4.22142 0.05298 60.800 &lt; 2e-16 ***
群组X -2.99472 0.02494 -39.890 &lt; 2e-16 ***
群组Y -1.76074 0.02747 -27.691 &lt; 2e-16 ***
群组Z -1.31331 0.03499 -8.953 &lt; 2e-16 ***
病毒A：群组X 1.39666 0.07366 5.385 7.24e-08 ***
病毒B：群组X 1.21714 0.05685 3.820 0.000134 ***
病毒C：群组X -3.97906 0.03390 -28.883 &lt; 2e-16 ***
病毒A：队列Y 1.24520 0.10246 2.393 0.016701 * 
病毒B：队列Y 1.05056 0.07980 0.634 0.526360 
病毒C：队列Y -1.43923 0.03422 -12.836 &lt; 2e-16 ***
virusA:cohortZ 0.12472 0.13408 0.930 0.352274 
virusB:cohortZ -0.33748 0.11851 -2.848 0.004404 ** 
virusC:cohortZ -1.13441 0.04187 -3.210 0.001327 ** 

我知道没有交互项的系数是与参考组相比的，但我听说在泊松回归中，交互项并不那么简单。
我有兴趣解释为什么与队列 Y 和 Z 相比，队列 X 感染病毒 C 的死亡率减少幅度最大。我不太明白如何理解交互系数，我也不明白为什么截距为负。如果没有偏移量，截距 = 0.18252，我无法理解这一点，因为我认为添加偏移量会将 DV 变成速率。]]></description>
      <guid>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</guid>
      <pubDate>Fri, 17 Jan 2025 00:16:33 GMT</pubDate>
    </item>
    <item>
      <title>在 Anderson-Gill 模型中，tstart 和 tstop 可以相同吗？</title>
      <link>https://stats.stackexchange.com/questions/660134/can-tstart-and-tstop-be-the-same-in-an-anderson-gill-model</link>
      <description><![CDATA[我正在处理事件发生时间数据，并使用 R 中生存包的 coxph() 函数中实现的 Anderson-Gill 模型。在此模型中，时间间隔由 tstart（开始时间）和 tstop（停止时间）定义，我需要了解如何处理 tstart == tstop 的间隔。
具体来说，我想知道：
在 Anderson-Gill 模型中，tstart 和 tstop 相同是否有效？
如果不是，零长度间隔的含义是什么，应该如何处理？
例如，考虑以下数据集：



id
tstart
tstop
event




1
0
10
1


1
10
10
1


2
5
5
1



当我尝试使用 coxph(Surv(tstart, tstop, event) ~ 1, data = my_data)，我收到有关 tstart == tstop 的警告。我理解零长度间隔并不代表有意义的风险时间，但我想确认解决这种情况的最佳方法。
我应该如何处理这些情况？我应该：排除 tstart == tstop 的行？为 tstop 添加一个小值（例如，tstop = tstart + 1e-5）？还有其他推荐的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660134/can-tstart-and-tstop-be-the-same-in-an-anderson-gill-model</guid>
      <pubDate>Thu, 16 Jan 2025 23:19:41 GMT</pubDate>
    </item>
    <item>
      <title>进行缺失数据插补是否会导致观测值之间的依赖性？</title>
      <link>https://stats.stackexchange.com/questions/660127/does-doing-missing-data-imputation-lead-to-dependency-between-observations</link>
      <description><![CDATA[当对数据集的所有观测值进行插补时，这是否会导致观测值之间的依赖性？那么假设观测值是独立的统计模型是否不够充分？
我理解，在观测值中的变量之间当然存在关系/依赖性。我对观测值之间的依赖性很好奇。
两个观测值$y_i$和$y_j$，它们是独立随机抽样的，因此$y_i \perp\!\!\perp y_j$。 $y_i$ 缺失，并且使用 $y_j$ 或更多观测值的函数来输入 $y_i$
例如，$K$ 个最近邻域。根据不缺失的 $X$ 找到 $K$ 个最近的观测值，然后将其归结为 $y_i = 1/K\sum_j^K y_j$。
$y_i$ 是 $K$ 个观测值 $y$ 变量的函数，这是否意味着 $y_i$ 和 $K$ 个观测值 $y$ 是相关的？]]></description>
      <guid>https://stats.stackexchange.com/questions/660127/does-doing-missing-data-imputation-lead-to-dependency-between-observations</guid>
      <pubDate>Thu, 16 Jan 2025 20:41:13 GMT</pubDate>
    </item>
    <item>
      <title>连续随机变量的充分统计因式分解定理</title>
      <link>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics-in-case-of-continuous-random-var</link>
      <description><![CDATA[根据因式分解定理 (Fisher-Neyman)，我们得到一个统计量 $ T(X) $ 充分当且仅当存在因式分解：$ f(x\mid \theta) = g(T(x)\mid \theta)h(x) $。符号遵循 Casella/Berger 第页。 276.
Casella/Berger 在离散情况下给出了证明，指出具体分解的形式如下：$$ P(X=x \mid {\theta}) = P(T(X) = T(x) \mid {\theta})P(X=x \mid T(X) = T(x)) $$
我的问题是：我们能否将这种解释应用于连续情况，并且它总是成立吗？因此：$ f(x\mid \theta) = f(T(x)\mid \theta)f(x\mid T(x)) $ 其中 $f$ 表示相应的 pdf？]]></description>
      <guid>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics-in-case-of-continuous-random-var</guid>
      <pubDate>Mon, 13 Jan 2025 22:52:25 GMT</pubDate>
    </item>
    <item>
      <title>对称单峰分布系列，其中峰度与峰值成反比？</title>
      <link>https://stats.stackexchange.com/questions/659400/family-of-symmetric-unimodal-distributions-where-kurtosis-is-inversely-related</link>
      <description><![CDATA[DeCarlo 于 1997 年在著名期刊《心理学方法》上发表了论文《论峰度的意义和用途》。该论文被广泛引用（引用次数超过 1500 次，其中 129 次“极具影响力”），人们仍然在文献和网络内容中频繁引用该论文。然而，摘要的第一句话指出：

对于对称单峰分布，正 [过量] 峰度表示
相对于正态分布，尾部较重且呈尖峰状，而负 [过量] 峰度表示尾部较轻且呈平坦状。

这种说法在尖峰状和平坦状方面是不正确的，并且无疑导致了“尖峰状/平坦状”现象的持续存在尽管最近的研究彻底推翻了峰度可以衡量分布的峰值或平坦度（无论是对称分布还是单峰分布）的观点，但这种误解仍然难以消除。
如果给出一组对称单峰分布，其中峰度降低时分布变得更加尖锐，峰度增加时分布变得更加平顶，这将有助于消除这种误解。
（编辑：由于“峰值”定义不明确，因此出于本练习的目的，可以将其操作为标准化变量分布的高度。）
这种对称单峰族的一个简单示例是$\{F_1, F_2\}$，其中$F_1$ 和 $F_2$ 在 维基百科页面 中给出：$F_1$ 是参数为 $0.5$ 和 $1$ 的 beta 分布与其关于 $0.0$ 的反射的均等混合，而 $F_2$ 是 $−1$ 和 $1$ 具有 $T(4.0000001)$ 学生 t 分布，混合概率为 $0.999$ 和 $0.001$。这些分布对应的标准化变量的密度函数如下所示：


在这个家族中，较低峰度（和“platykurtic”）分布是“无限峰值”，而较高峰度分布较低，且呈现完美的平顶。
然而，描述一个更传统的无限族$F_{\theta}$将会很有趣，其中$\theta$连续变化，峰度范围从&quot;platykurtic&quot; ($&lt;3$) 到无穷大，并且分布（所有对称和单峰）范围从无限峰值到几乎平顶，因为峰度范围从最小值到无穷大。
有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659400/family-of-symmetric-unimodal-distributions-where-kurtosis-is-inversely-related</guid>
      <pubDate>Tue, 31 Dec 2024 17:07:42 GMT</pubDate>
    </item>
    <item>
      <title>尺度参数的可能性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659197/likelihood-of-scale-parameter</link>
      <description><![CDATA[我在这里要问的唯一问题是我不知道如何为比例参数建模可能性。我应该使用伽马还是截断法线？]]></description>
      <guid>https://stats.stackexchange.com/questions/659197/likelihood-of-scale-parameter</guid>
      <pubDate>Wed, 25 Dec 2024 15:23:50 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯模型的特征数量先验</title>
      <link>https://stats.stackexchange.com/questions/659049/prior-on-the-number-of-features-for-a-bayesian-model</link>
      <description><![CDATA[我正在训练一个贝叶斯模型来预测二元结果（病例/对照）。有数百个特征可以纳入其中，这些特征之前使用不相关的程序进行了排序。但是，我不知道其中哪些是相关的，哪些是不相关的。因此，我可以用 $5, 6, 7, \dotsc n$ 个特征来训练模型。
我目前选择特征数量的方法是使用交叉验证 - 具有最佳 AUC 的模型被视为最佳模型。这是一种频率学派的做法，我想用完全贝叶斯方法来补充它，比较具有不同参数数量的模型的证据。这需要选择特征数量的先验 - 假设具有更多特征的模型的可能性较小...
此类案例的标准先验是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659049/prior-on-the-number-of-features-for-a-bayesian-model</guid>
      <pubDate>Sat, 21 Dec 2024 08:39:11 GMT</pubDate>
    </item>
    <item>
      <title>非正态数据变换</title>
      <link>https://stats.stackexchange.com/questions/658975/non-normal-data-transformation</link>
      <description><![CDATA[我目前正在尝试转换我的非正态数据，以便我可以运行 glmm 模型进行一些研究。我的数据与行为有关，因此没有任何与此相关的内容是正态分布的，但我目前不知道下一步如何转换我的数据。到目前为止，我已经尝试了 sqrt 和 log10，但当我测试均匀性时，图表仍然显示它们不正常。我的数据也非常零膨胀。我对 R studio 还不熟悉，所以我只知道这么多，但我能以某种方式使用负二项式系列吗？
为了澄清我的数据，我从事行为生物学工作，所以我的数据以秒为单位。我正在研究身体压力和居住状态如何影响领土行为。对于下面的图表，我还将覆盖对象类型作为随机变量。在底部的代码中，治疗只是意味着有压力或无压力，状态是居民或入侵者。我的试验总共 10 分钟，所以我记录了 8 种不同的行为，但我的模型一次只列出一种，以避免过度复杂化。每个行为的最短时间可以是 0，最长可以是 600 秒。我对 r studio 还很陌生，尤其是转换数据，所以我希望这些信息足够，因为我需要尽可能多的帮助！
我在一位教授的建议下进行了 log10 和 sqrt。同一位教授建议我用数据运行一般线性混合模型，而不是我最初使用的曼-惠特尼检验。
这些是我在尝试任何转换之前的图表：


关于我应该如何转换数据以便可以运行 glmm 的任何建议都是如此有帮助！
我尝试了 sqrt 和 log10 转换。我相信它们部分有效，但不能解决数据的所有问题。
这是我的 log10 图表：这是在我的模型上使用 log10 变换得到的 零通胀与 log10 变换


这是我的 sqrt 图表：sqrt 变换 sqrt 零通胀


此外，这里是我用来获取这些图表和模型的代码。我研究蝾螈，所有这些数据都与它们的攻击性行为有关。
SimOutput.sallys &lt;- glmmTMB(sqrt(ATR + .1) ~ Treatment * Status + 
(1 | CoverObj), data = sallys) 
SQRTsimulationoutput1 &lt;- mockResiduals(SimOutput.sallys, n = 1000, 
plot = TRUE)
plot(SQRTsimulationoutput1) 
testUniformity(simulationOutput = SQRTsimulationoutput1) 
testDispersion(SQRTsimulationoutput1) 
testZeroInflation(SQRTsimulationoutput1)
]]></description>
      <guid>https://stats.stackexchange.com/questions/658975/non-normal-data-transformation</guid>
      <pubDate>Thu, 19 Dec 2024 17:03:10 GMT</pubDate>
    </item>
    <item>
      <title>具有相关随机变量的 $E[X\mid U,V]$ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</link>
      <description><![CDATA[设 $(X,Y,Z)$ 为三维随机变量，其密度函数为 $f(x,y,z)=\frac{2}{3}(x+y+z)$ 在 $0&lt;x,y,z&lt;1$ 上，$U=\min(X,Y,Z)$，$V=\max(X,Y,Z)$。计算$E[X\mid U,V]$。
我认为答案是$\frac{14U^2+26UV+14V^2}{27(U+V)}$，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</guid>
      <pubDate>Thu, 13 Jun 2024 05:43:04 GMT</pubDate>
    </item>
    </channel>
</rss>