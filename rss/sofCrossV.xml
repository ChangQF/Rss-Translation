<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 18 Apr 2024 09:14:12 GMT</lastBuildDate>
    <item>
      <title>优效性/劣效性检验的置信区间</title>
      <link>https://stats.stackexchange.com/questions/645287/confidence-interval-for-superiority-inferiority-tests</link>
      <description><![CDATA[我正在研究优效性/非劣效性检验，我的理解是优效性检验的零假设是
$$
H_{0}: \epsilon \leq \delta
$$
其中 $\delta \geq 0$ 和 $\epsilon$ 是真实效果大小。 
我觉得我看到的很多文章都报告了此类测试的两侧置信区间（例如 此处或此处）。它是否正确？置信区间方法的选择（在本例中是两侧与左侧有界的单侧）与我们是否对 $H_{0} 感兴趣无关: \epsilon = 0$ 与 $H_{0}: \epsilon \leq 0$?]]></description>
      <guid>https://stats.stackexchange.com/questions/645287/confidence-interval-for-superiority-inferiority-tests</guid>
      <pubDate>Thu, 18 Apr 2024 08:10:40 GMT</pubDate>
    </item>
    <item>
      <title>基于概率分布而非数据集的 k 均值聚类</title>
      <link>https://stats.stackexchange.com/questions/645286/k-means-clustering-on-a-probability-distribution-instead-of-a-dataset</link>
      <description><![CDATA[通常，聚类算法（例如 $k$-means）在数据集上定义如下：if $ D$ 是一个数据集，将 $D$ 划分为集合 $\{S_1, \dots , S_n\}$ 最小化 $$\sum_{i=1}^n |S_i| 给出的簇内平方和\text{Var} (S_i) = \sum_{i=1}^n \frac{1}{|S_i|} \sum_{x, y\in S_i}\lVert x-y\rVert.$$我想知道是否可以参考概率分布定义 $k$-means 算法 $\mu$  而不是数据集 $D$。例如，假设我们的数据集仅由根据以下概率分布分布的二维点的集合组成：

然后，如果我们使用 $k$ - 表示有 2 个簇的聚类，我们将得到一个以 -1 为中心的簇，另一个以 1 为中心的簇。我想知道我们是否可以只需在分布本身上定义聚类算法，并将输入空间分割为 Voronoi cells 而不需要引用到一个数据集。这样做的目的是提供一种方法来量化 $k$ 的适用性 - 对于给定的理论输入分布。例如，如果将聚类作为分类任务，则可以计算出簇内距离的预期总和以及预期错误率等数量。]]></description>
      <guid>https://stats.stackexchange.com/questions/645286/k-means-clustering-on-a-probability-distribution-instead-of-a-dataset</guid>
      <pubDate>Thu, 18 Apr 2024 08:06:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么在交叉方程限制下，“systemfit”对于 OLS 和 WLS 会产生不同的结果？</title>
      <link>https://stats.stackexchange.com/questions/645285/why-does-systemfit-yield-different-results-for-ols-and-wls-under-cross-equatio</link>
      <description><![CDATA[我正在跟进问题“为什么systemfit对OLS和WLS产生相同的结果？” ”。它涉及估计线性方程组，其中每个方程都有一个唯一的回归量和一个公共回归量。估计是使用 R 中的 systemfit 包通过 OLS 和 WLS 完成的。
事实证明，点估计是相等的，$\hat\beta_\text{OLS}=\hat\beta_\text{WLS}$
估计的系数协方差矩阵也相同， $\widehat{\text{Cov}}_\text{OLS}(\hat\beta) = (X&#39;\hat\ Omega_\text{OLS}^{-1}X)^{-1} =(X&#39;\hat\Omega_\text{WLS}^{-1}X)^{-1} = \widehat{\text{ Cov}}_\text{WLS}(\hat\beta)$ 因为估计误差协方差矩阵相同，$\hat\Omega_\text{OLS}= \hat\Omega_\text{WLS}$（除非方程之间的误差方差相等是由 control = systemfit.control(singleEqSigma = FALSE) 强加的，但这不是默认选项） .
然而，在有限的估计下情况会发生变化。例如。如果我们强制方程中的某些系数相等，systemfit 会报告 OLS 和 WLS 的不同点估计和估计系数协方差矩阵。这是令人费解的，考虑到包的 小插图。在那里，OLS 和 WLS 估计器使用完全相同的方程。唯一可能不同的是 $\hat\Omega_{\text{OLS}}$ 与 $\hat \Omega_{\text{WLS}}$，但我们了解到它们是相同的。那么，systemfit 生成的实际数字对于 OLS 和 WLS 为何不同？
库(systemfit)

# 生成并准备数据
n &lt;- 50#样本量
m＜-10#“第二部分”的长度样本的
N &lt;- 3 # 方程数
设置.种子(321); x &lt;- 矩阵(rnorm(n*N),ncol=N); colnames(x) &lt;-paste0(“x”,1:N) # 生成回归量
dummy &lt;- c(rep(0,n-m),rep(1,m))#生成一个公共回归器
x &lt;- cbind(x,dummy) # 包含公共回归器和其余回归器
设置.种子(123); y &lt;- 矩阵(rnorm(n*N),ncol=N); colnames(y) &lt;- Paste0(“y”,1:N) # 因变量的占位符
for(i in 1:N){
 y[,i] &lt;- i + sqrt(i)*x[,i] - i*虚拟 + y[,i]*15*sqrt(i)
 # y[,i] 是 x[,i] 和虚拟变量的线性函数，
 # 加上一个带有方程特定方差的误差项 - 这正是 WLS 的用途
}
data1 &lt;- as.data.frame(cbind(y,x)) # 创建所有数据（y 和 x）的数据框

# 创建模型方程
eqSystem &lt;- 列表()
for(i in 1:N){
 eqSystem[[i]] &lt;- as.formula(assign(paste0(&quot;eq&quot;,i), value=paste0(&quot;y&quot;,i,&quot; ~ x&quot;,i,&quot; + dummy&quot;) )) # 定义 SUR 的线性方程
}

# 使用 `method=&quot;OLS&quot;` 和 `method=&quot;WLS&quot;` 估计模型
m1 &lt;- systemfit(公式=eqSystem, 方法=“OLS”, 数据=data1)
m2 &lt;- systemfit(公式=eqSystem, 方法=“WLS”, 数据=data1)
#m3 &lt;- systemfit(公式=eqSystem, 方法=“SUR”, 数据=data1)
摘要（m1，residCov=FALSE，方程=FALSE）
摘要（m2，residCov=FALSE，方程=FALSE）
#summary(m3, residCov=FALSE, 方程=FALSE)

# 系数的协方差矩阵：OLS 和 WLS 相等
圆(m1$coefCov,4)
圆(m2$coefCov,4)
#round(m3$coefCov,4)
m1$coefCov/m2$coefCov

# 残差的协方差矩阵：全部相等
圆（m1$residCov,4）
回合（m2$residCov,4）
#round(m3$residCov,4)
m1$residCov/m2$residCov

# 两步估计器中的权重矩阵：OLS 为 NULL，WLS 和 SUR 不同
m1$residCovEst
回合(m2$residCovEst,4)
#round(m3$residCovEst,4)

# 当模型对来自不同方程的系数有线性限制时，OLS 和 WLS 会有所不同
Rmat0 &lt;- 矩阵(0, nrow=N-1, ncol=N*3) # nrow ~ 限制数，ncol ~ unrestr 数。系数
for(i in 1:(N-1)) Rmat0[i, c(3*i,3*(i+1))] &lt;- c(1,-1)
qvec0 &lt;-rep(0,nrow(Rmat0))
m1rest &lt;- systemfit(formula=eqSystem, method=“OLS”, restrict.matrix=Rmat0, restrict.rhs=qvec0, data=data1) # 受限模型
m2rest &lt;- systemfit(formula=eqSystem, method=“WLS”, restrict.matrix=Rmat0, restrict.rhs=qvec0, data=data1) # 受限模型
摘要（m1rest，residCov=FALSE，方程=FALSE）
摘要（m2rest，residCov=FALSE，方程=FALSE）
]]></description>
      <guid>https://stats.stackexchange.com/questions/645285/why-does-systemfit-yield-different-results-for-ols-and-wls-under-cross-equatio</guid>
      <pubDate>Thu, 18 Apr 2024 08:00:29 GMT</pubDate>
    </item>
    <item>
      <title>调理一次还是两次？</title>
      <link>https://stats.stackexchange.com/questions/645284/conditioning-once-or-twice</link>
      <description><![CDATA[假设我们有两个随机变量 $Z \in \mathcal{Z}$ 和 $X \in \ mathcal{X}$ 与相对于基本度量的联合密度 $p_{Z,X}(z,x)$ 。假设密度因子为
$$ p_{Z,X}(z,x) = p_Z(z) p_{X|Z}(x|z),$$
其中 $p_Z$ 是 $Z$ 和 $p_{X|Z}$ $X|Z$ 的条件密度。我们还表示 $p_X$ 的密度 $X$。
现在，假设我们有兴趣计算 $X | 的分布X \in A$ ，其中 $A \subset \mathcal{X}$。有两种计算密度的方法听起来都很合理：
$$ p_1(x) = \int_{Z} p_Z(z | X \in A) p_{X|Z}(x|z, X \in A) dz$$ 
和
$$ p_2(x) = \int_{Z} p_Z(z ) p_{X|Z}(x|z, X \in A) dz$$&lt; /p&gt;
它们等价吗？有没有反例表明它们不是？
一方面， $p_1$ 似乎更正确，但可能没有必要过滤掉 $A$。]]></description>
      <guid>https://stats.stackexchange.com/questions/645284/conditioning-once-or-twice</guid>
      <pubDate>Thu, 18 Apr 2024 07:49:21 GMT</pubDate>
    </item>
    <item>
      <title>是什么导致 beta 回归中的参数 phi（精度）非常小（通过 R 中的 betareg）？</title>
      <link>https://stats.stackexchange.com/questions/645283/what-causes-the-parameter-phi-precision-to-be-very-small-in-beta-regression-b</link>
      <description><![CDATA[我尝试对受年龄和亲密关系影响的变量进行 beta 回归，但效果不佳。通过最大似然法估计的phi（精度）值非常小，当我实际绘制估计分布时，我认为它建模得不好。可能是什么原因？或者还有其他更好的回归模型吗？
我想也许是因为解释变量的变化太少，但我不确定。
这是我的试验总结。
数据（n=128）：
y：因变量
x_1：“年龄组”的解释变量
x_2：“亲密程度”的解释变量
（完整数据显示在底部）
代码：
betareg(y ~ x_1 + x_2, data = data)
结果：
Mu 系数（带有 logit 链接的平均模型）：

&lt;标题&gt;


估计


&lt;正文&gt;

（拦截）
-3.17


x_1
1.12


x_2
0.12



Phi 系数（具有恒等链接的精确模型）：

&lt;标题&gt;


估计


&lt;正文&gt;

（phi）
0.74



数据（完整）：
&lt;前&gt;&lt;代码&gt; y x_1 x_2
1 0.999 4 0
2 0.999 4 0
3 0.500 4 0
4 0.999 4 0
5 0.999 4 0
6 0.999 4 0
7 0.999 4 0
8 0.999 4 0
9 0.999 4 0
10 0.999 4 0
11 0.500 4 0
12 0.999 4 0
13 0.999 4 0
14 0.999 4 0
15 0.500 4 0
16 0.500 4 0
17 0.999 4 1
18 0.999 4 1
19 0.500 4 1
20 0.999 4 1
21 0.999 4 1
22 0.999 4 1
23 0.999 4 1
24 0.999 4 1
25 0.999 4 1
26 0.999 4 1
27 0.999 4 1
28 0.999 4 1
29 0.999 4 1
30 0.999 4 1
31 0.500 4 1
32 0.999 4 1
33 0.500 3 1
34 0.999 3 1
35 0.001 3 1
36 0.999 3 1
37 0.999 3 1
38 0.001 3 1
39 0.999 3 1
40 0.999 3 1
41 0.500 3 1
42 0.500 3 1
43 0.500 3 1
44 0.500 3 1
45 0.999 3 1
46 0.500 3 1
47 0.001 3 1
48 0.500 3 1
49 0.500 3 1
50 0.999 3 1
51 0.500 3 1
52 0.999 3 1
53 0.999 3 1
54 0.001 3 1
55 0.999 3 1
56 0.999 3 1
57 0.500 3 1
58 0.500 3 1
59 0.999 3 1
60 0.999 3 1
61 0.999 3 1
62 0.999 3 1
63 0.001 3 1
64 0.999 3 1
65 0.001 2 1
66 0.500 2 1
67 0.001 2 1
68 0.001 2 1
69 0.001 2 1
70 0.001 2 1
71 0.500 2 1
72 0.001 2 1
73 0.001 2 1
74 0.001 2 1
75 0.001 2 1
76 0.001 2 1
77 0.001 2 1
78 0.001 2 1
79 0.001 2 1
80 0.001 2 1
81 0.001 2 1
82 0.500 2 1
83 0.001 2 1
84 0.001 2 1
85 0.001 2 1
86 0.001 2 1
87 0.500 2 1
88 0.001 2 1
89 0.001 2 1
90 0.001 2 1
91 0.001 2 1
92 0.001 2 1
93 0.001 2 1
94 0.001 2 1
95 0.001 2 1
96 0.001 2 1
97 0.001 1 1
98 0.500 1 1
99 0.001 1 1
100 0.001 1 1
101 0.001 1 1
102 0.001 1 1
103 0.001 1 1
104 0.001 1 1
105 0.001 1 1
106 0.001 1 1
107 0.001 1 1
108 0.001 1 1
109 0.001 1 1
110 0.001 1 1
111 0.001 1 1
112 0.001 1 1
113 0.001 1 1
114 0.500 1 1
115 0.001 1 1
116 0.001 1 1
117 0.001 1 1
118 0.001 1 1
119 0.001 1 1
120 0.001 1 1
121 0.001 1 1
122 0.001 1 1
123 0.001 1 1
124 0.001 1 1
125 0.001 1 1
126 0.001 1 1
127 0.001 1 1
128 0.001 1 1
]]></description>
      <guid>https://stats.stackexchange.com/questions/645283/what-causes-the-parameter-phi-precision-to-be-very-small-in-beta-regression-b</guid>
      <pubDate>Thu, 18 Apr 2024 06:46:28 GMT</pubDate>
    </item>
    <item>
      <title>比较股票的基本面分析和技术分析[关闭]</title>
      <link>https://stats.stackexchange.com/questions/645279/compare-fundamental-analysis-and-technical-analysis-of-stocks</link>
      <description><![CDATA[我必须为大学的一门课程做作业。我必须找到技术分析和基本面分析的股票评估结果不同的公司。我的教授向我展示了如何使用基本分析，即使用移动平均线，看看应该在哪几天使用 50 和 200 平均线买入或卖出股票。然后用基本面分析来看看该股票是否应该出售？但我不明白如何使用基本面分析来查看股票一天的市盈率、市盈率等数值。谁能给我解释一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645279/compare-fundamental-analysis-and-technical-analysis-of-stocks</guid>
      <pubDate>Thu, 18 Apr 2024 05:52:01 GMT</pubDate>
    </item>
    <item>
      <title>改进逻辑回归，其中多个信号分别产生相同的精度，并且将它们组合起来不会改进模型</title>
      <link>https://stats.stackexchange.com/questions/645277/improving-a-logistic-regression-where-multiple-signals-separately-yield-the-same</link>
      <description><![CDATA[我有一个逻辑回归来估计事件发生的概率。大约有 10,000 个数据点，大约有 20 个模型特征。模型特征各不相同；它们的成对相关性大致在 [-0.5, 0.5] 范围内。
如果我分别对 20 个特征中的每一个特征进行逻辑回归建模，则其中 15 个特征的准确度约为 64-66%，并且具有相似的 BCE。对于其他 5 个，单个模型的准确率较低。
当我将所有 20 个特征组合到一个模型中时，准确性和 BCE 并没有提高。
这对我来说是违反直觉的 - 我希望将这些特征组合成一个更大的模型会提高准确性，因为特征之间的相互作用或创建更精确的“过滤器”的能力（例如，如果两个特征都意味着事件应该发生）。我还尝试过更复杂的模型，例如神经网络或基于 CART 的模型，但准确性仍然没有提高。
我想知道根本解释可能是什么，我如何进一步调试，以及我可以采取哪些步骤来尝试改进我的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/645277/improving-a-logistic-regression-where-multiple-signals-separately-yield-the-same</guid>
      <pubDate>Thu, 18 Apr 2024 05:48:14 GMT</pubDate>
    </item>
    <item>
      <title>确定逻辑回归中数字 x 变量和二元 y 标签的优势比在组之间是否不同（即性别或种族）[重复]</title>
      <link>https://stats.stackexchange.com/questions/645275/determining-if-odds-ratio-for-a-numerical-x-variable-and-binary-y-label-in-logis</link>
      <description><![CDATA[我见过人们问过类似的问题，但我仍然不太清楚最好的建议是什么 - 我正在查看一个二元因变量和多个自变量（其中一些是分类变量，例如种族或性别或其他人口统计变量，其中一些是数字的）。如何确定数值变量 x1 和二进制 y 之间的关联/优势比在不同性别群体或不同种族群体之间是否不同。我很好奇看一下简单逻辑回归（仅将 x1 作为依赖项）和多重逻辑回归（使用 x 以及其他已进行单热编码的分类/数字人口统计变量）的区别以每个变量中最大的类别作为参考）。
分析这个问题的最佳方法是什么？将人群分为几组（即女性患者与男性患者，或白人患者与黑人患者与亚洲患者）并为每个组运行逻辑回归来比较优势比是一个坏方法吗？卡方检验？其他的？非常感谢任何建议/解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/645275/determining-if-odds-ratio-for-a-numerical-x-variable-and-binary-y-label-in-logis</guid>
      <pubDate>Thu, 18 Apr 2024 05:02:14 GMT</pubDate>
    </item>
    <item>
      <title>为什么多元线性回归在预测时间方面比单层神经网络表现更好？</title>
      <link>https://stats.stackexchange.com/questions/645274/why-multiple-linear-regression-perform-better-than-single-layer-neural-network-i</link>
      <description><![CDATA[我正在研究预测机器组件的故障时间。
响应是机器部件的故障时间，输入是位置信息（由整数组成）。
我将神经网络模型拟合为具有 100 个节点的一个线性层。此外，我还拟合了多元线性回归并预测了故障时间。
基于多元线性回归的MSE为0.43，基于神经网络的MSE为0.64-0.67。然而，神经网络有更多的参数，可以捕获更复杂的数据信息，它应该比线性回归更好，不是吗？
完整样本量为19319，训练量为14489，测试量为4830。
在将输入输入神经网络之前，我对输入进行了标准化。神经网络模型的详细内容如下。
类 Net(torch.nn.Module):
  def __init__(self, n_feature, size_hidden, n_output):
    超级（网络，自我）.__init__()
    self.hidden = torch.nn.Linear(cols, size_hidden)
    self.predict = torch.nn.Linear(size_hidden, n_output)

def 前向（自身，x）：
    输出 = self.predict(self.hidden(x))
    返回输出

列=7
n_输出=1
净=净（列，100，n_output）.cuda（）

优化器= torch.optim.RAdam（net.parameters（），lr = 0.001，betas =（0.9，0.999），eps = 1e-08，weight_decay = 0.9，foreach =无）
优化器 = torch.optim.Adam(net.parameters(), lr=0.001)

标准 = torch.nn.MSELoss(size_average=True)

批量大小 = 200 或 500 或 1000 或 3000 或 5000

我尝试了 Adam、RAdam、SGD 等各种学习率 0.001 和 0.01 的优化器。如果学习率为0.01，则不收敛。
此外，对于所有不同的批量大小，性能相似。]]></description>
      <guid>https://stats.stackexchange.com/questions/645274/why-multiple-linear-regression-perform-better-than-single-layer-neural-network-i</guid>
      <pubDate>Thu, 18 Apr 2024 04:48:01 GMT</pubDate>
    </item>
    <item>
      <title>多层次混合模型</title>
      <link>https://stats.stackexchange.com/questions/645259/multi-level-mixed-models</link>
      <description><![CDATA[我有一个模型，在该模型中，我从 3 个不同的农场收集了每个农场在几个不同星期内的信息。这些周并不完全相同，因此农场 1 的第 1 周与农场 2 的第 1 周并不相同。它总是在一周内采样新元素。
我应用了以下语法：
glmer(PCR ~ 样本 + (1 | 农场/周) , family = 二项式(link=&quot;logit&quot;),
            数据=数据）

我不知道如何插入随机组件。因为我想知道某种样本的 PCR 呈阳性的概率是多少。
我需要控制农场内一周的影响 - 以便模型具有样本相关结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/645259/multi-level-mixed-models</guid>
      <pubDate>Wed, 17 Apr 2024 19:00:35 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何分析配对且重复测量的数据？</title>
      <link>https://stats.stackexchange.com/questions/645244/how-should-i-analyze-data-that-is-paired-and-also-repeatedly-measured</link>
      <description><![CDATA[我在 11 天内从同一受试者 (n=10) 收集数据，每天在两种条件下进行测量：训练后立即 (D0) 和训练后 30 分钟 (D30)。数据是有序的，范围从 1 到 10。我想了解训练后立即进行的测量和训练后 30 分钟进行的测量之间是否存在差异。我应该如何分析这些数据，我应该使用哪种测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/645244/how-should-i-analyze-data-that-is-paired-and-also-repeatedly-measured</guid>
      <pubDate>Wed, 17 Apr 2024 17:06:04 GMT</pubDate>
    </item>
    <item>
      <title>重复性系数和测量标准误差</title>
      <link>https://stats.stackexchange.com/questions/645243/repeatability-coefficient-and-standard-error-of-measurement</link>
      <description><![CDATA[重复性系数 (CR) (Bland Altman) 用于报告可重复性，可理解为在短时间内比较同一受试者、同一观察者的测量结果的指数。
测量的标准误差用于报告仪器或秤的可靠性。也就是说，使用一种秤或仪器对多个受试者进行多次测量。
两者都是绝对测量值，支持其实际用途。
但这两个结果如何结合起来解释呢？我在 CR 中得到了不好的结果，但在 SEM 中得到了良好的可靠性。
也许我应该将 SEM 调整为 SEM95，因为 CR 本质上有这种调整？
实验如下：10名受试者在相同条件下连续测量4次。这在 5 个不同的位置重复 4 次。
重复性系数 (CR) 的计算方法为每个位置 4 次测量的标准差乘以 2.77，因此每个受试者有 4 个 CR。我们根据首选报告所有值或最大值和最小值。
测量标准误差 (SEM) 的计算方法为所有受试者的所有数据的平方 (MSe)，并且我们仅报告一个可靠性值。
如果我们将其与数字联系起来，我们的 CR 范围为 0.036 到 0.003。 SEM 为 0.004。
我们如何得出结论？是否有可能有一个程序，在单独的测量中不是非常可重复，但在不同的条件下仍然可以复制，如本例中的可靠性（SEM）所示？]]></description>
      <guid>https://stats.stackexchange.com/questions/645243/repeatability-coefficient-and-standard-error-of-measurement</guid>
      <pubDate>Wed, 17 Apr 2024 16:07:30 GMT</pubDate>
    </item>
    <item>
      <title>显示有偏见的 CRB 的标准做法</title>
      <link>https://stats.stackexchange.com/questions/645202/standard-practice-to-show-biased-crbs</link>
      <description><![CDATA[我在四参数估计方面遇到问题。我使用蒙特卡罗模拟（数值模拟）导出了估计参数的方差，并使用费舍尔信息矩阵的逆矩阵导出了理论参数的方差。
理论值和数值值存在差异。对于某些参数，数值方差可能比理论方差更小。我怀疑原因是估计量的偏差。我想计算有偏差的 CRB，以便它们可以进行公平的比较。最重要的是，我需要显示一些具有这些差异的参数扫描。
有偏差的CRB可以通过以下公式找到。
$$ \text{CRB}(\theta) = \text{diag}\{ \left[\mathbf{1} + \nabla_\theta \mathbb{B} (\theta) \right] \mathbf{I}^{-1}(\theta) \left[\mathbf{1} + \nabla_\theta \mathbb{B}(\theta) \right]^\text{ T}\}，$$
其中 $\mathbf{1}$ 是单位矩阵，$\mathbf{I}$ 是 Fisher 信息矩阵。 $\mathbb{B}(\theta)$ 是偏差向量，但 $\nabla_\theta \mathbb{B }(\theta)$ 是偏差梯度矩阵。
偏差可能来自以下因素：对数似然涉及的积分样本量不足 ($N$)、参数空间受限、优化器错误、对于我的问题，我认为我拥有所有这些，特别是 $N$ 不足和空间有限。 $\nabla_\theta \mathbb{B}(\theta)$ 的函数形式几乎是不可能的。然而，我可以看到有一些贝叶斯推理技术可以计算有偏差的 CRB，例如[1]。这超出了我的理解范围，而且有点复杂。
我想我可以使用数值偏差通过蒙特卡罗模拟获得偏差梯度。然而，它的计算成本非常昂贵。由于梯度是相对于参数的，并且我想要进行一些参数扫描，因此我需要对 $M^4 \times M_c$ 计算执行蒙特卡罗模拟优化器的参数，其中 $M$ 是一次参数扫描中的值数量，$M_c$ 是蒙特卡洛运行的次数。为每种情况准备模拟测量也需要一些时间。我使用 MATLAB 进行编码，并且只能并行化这些扫描之一。
是否有更聪明的方法来从概念上或通过编程策略获取有偏差的 CRB？我将不胜感激任何形式的帮助。
[1] C. L. Matson 和 A. Haji，“不平等约束估计量的有偏 Cramér-Rao 下界计算”，J. Opt。苏克。是。 A，卷。 23、没有。 11，第 2702–2713 页，2006 年，doi：10.1364/josaa.23.002702。]]></description>
      <guid>https://stats.stackexchange.com/questions/645202/standard-practice-to-show-biased-crbs</guid>
      <pubDate>Wed, 17 Apr 2024 08:24:28 GMT</pubDate>
    </item>
    <item>
      <title>为什么“systemfit”对 OLS 和 WLS 产生相同的结果？</title>
      <link>https://stats.stackexchange.com/questions/645173/why-does-systemfit-yield-identical-results-for-ols-and-wls</link>
      <description><![CDATA[我正在使用 R 中的 systemfit 包估计一个看似不相关的回归 (SUR) 系统。每个方程都有一个唯一的回归量和一个公共回归量。我使用两种替代估计方法：普通最小二乘 OLS (method=“OLS”) 和加权最小二乘 WLS (method=“WLS”)，如下所示在 &lt; 的第 2.1 节（第 3-4 页）中讨论代码&gt;systemfit小插图。我从两者中得到相同的点估计和标准误差。系数的协方差矩阵也相同。这让我很困惑。标准误差和更一般地说，系数的协方差矩阵不应该有所不同吗？
问题：为什么 systemfit 对 method=&quot;OLS&quot; 和 method=&quot;WLS&quot;&lt; 产生相同的结果/代码&gt;？
库(systemfit)

# 生成并准备数据
n &lt;- 1000 # 样本量
m＜-100#“第二部分”的长度样本的
N &lt;- 3 # 方程数
设置.种子(321); x &lt;- 矩阵(rnorm(n*N), ncol=N); colnames(x) &lt;-paste0(“x”, 1:N) # 生成回归量
dummy &lt;- c(rep(0, n-m), rep(1, m)) # 生成一个公共回归器
x &lt;- cbind(x, dummy) # 包含公共回归器和其余回归器
设置.种子(123); y &lt;- 矩阵(rnorm(n*N), ncol=N); colnames(y) &lt;- Paste0(“y”, 1:N) # 因变量的占位符
for (i in 1:N) {
  y[, i] &lt;- i + sqrt(i)*x[, i] - i*虚拟 + y[, i]*15*sqrt(i)
  # y[, i] 是 x[, i] 和虚拟变量的线性函数，
  # 加上一个带有方程特定方差的误差项 - 这正是 WLS 的用途
}
data1 &lt;- as.data.frame(cbind(y, x)) # 创建所有数据（y和x）的数据框

# 创建模型方程
eqSystem &lt;- 列表()
for (i in 1:N) {
  eqSystem[[i]] &lt;-
    as.formula(分配(paste0(“eq”, i),
                      value=paste0(&quot;y&quot;, i, &quot;~ x&quot;, i, &quot;+ dummy&quot;))) # 定义 SUR 的线性方程
}

# 使用 `method=&quot;OLS&quot;` 和 `method=&quot;WLS&quot;` 估计模型
m1 &lt;- systemfit(公式=eqSystem, 方法=“OLS”, 数据=data1)
m2 &lt;- systemfit(公式=eqSystem, 方法=“WLS”, 数据=data1)
摘要（m1，residCov=FALSE，方程=FALSE）
摘要（m2，residCov=FALSE，方程=FALSE）
m1$coefCov # 系数的协方差矩阵
m2$coefCov # 系数的协方差矩阵

后续问题：“为什么 systemfit 在交叉条件下 OLS 和 WLS 产生不同的结果-方程限制？”]]></description>
      <guid>https://stats.stackexchange.com/questions/645173/why-does-systemfit-yield-identical-results-for-ols-and-wls</guid>
      <pubDate>Tue, 16 Apr 2024 19:57:43 GMT</pubDate>
    </item>
    <item>
      <title>具有省略变量的非参数回归</title>
      <link>https://stats.stackexchange.com/questions/644924/non-parametric-regression-with-an-omitted-variable</link>
      <description><![CDATA[假设我们使用核回归估计器$$\hat{m}(c)=\frac{\sum_{i=1}^n K\left(\frac{ x_i-c}{h}\right)y_i}{\sum_{i=1}^n K\left(\frac{x_i-c}{h}\right)}$$
其中 $h\to 0$ 和 $nh\to \infty$ 为 $n\to \infty$。
真正的 DGP 的形式为 $$y_i=\alpha +\beta x_i +\gamma z_i+\varepsilon_i$$
我假设 $\{(y_i,x_i,z_i)\}$ 是独立同分布的。并且所有变量都是绝对连续的，具有有限的二阶矩，并且在整个实线上具有正密度。我假设两个变量都具有严格的外生性，即 $\mathbb{E}[\varepsilon_i|x_i;z_i]=0$，并且 $x_i$ 和 $z_i$ 彼此独立。
我想知道 $\hat{m}(c)$ 收敛到什么对象。
为此，定义 $\hat{g}(c)=\frac{1}{nh}\sum_{i=1}^n K\left(\ frac{x_i-c}{h}\right)y_i$ 和 $\hat{f}(c)=\frac{1}{nh}\sum_{ i=1}^n K\left(\frac{x_i-c}{h}\right)$ 使得 $\hat{m}(c)= \hat{g}(c)/\hat{f}(c)$。很容易显示 $\hat{f}(c)\xrightarrow{p} f(c)$ 其中  $f(c)$ 是 $x$ 的 pdf。现在，让 $p(z)$ 为 $z$ 的 pdf，\begin{align*}
\mathbb{E}[\hat{g}(c)]
&amp;= \mathbb{E}\left[\frac{1}{nh}\sum_{i=1}^nK\left(\frac{x_i-c}{h}\right)y_i\right] \\
&amp;= \frac{1}{h}\mathbb{E}\left[K\left(\frac{x_i-c}{h}\right)y_i\right] \\
&amp;=\frac{1}{h}\mathbb{E}\left[K\left(\frac{x_i-c}{h}\right)(\alpha +\beta x_i +\gamma z_i+\varepsilon_i) \正确的] \\
&amp;=\frac{1}{h}\mathbb{E}\left[K\left(\frac{x_i-c}{h}\right)(\alpha +\beta x_i +\gamma z_i)\right ] \\
&amp;= \frac{1}{h}\int_\Omega K\left(\frac{x-c}{h}\right)(\alpha +\beta x +\gamma z) \, d\mathbb{P} \\
&amp;=\frac{1}{h}\iint K\left(\frac{x-c}{h}\right)(\alpha +\beta x +\gamma z)f(x)p(z) \, dx \, dz \\
&amp;=\iint K(u)(\alpha +\beta (uh+c) +\gamma z) f(uh+c)p(z) \, du \, dz \\
&amp;= (\alpha + \beta c+\gamma \mathbb{E}[z])f(c) +o(1) \\
&amp;\xrightarrow{n\to \infty} (\alpha + \beta c+\gamma \operatorname{\mathbb{E}}[z])f(c)
\end{对齐*}
我还可以显示 $\mathbb{V}[\hat{g}(c)]\to 0$ 显示 $\hat{g}(c)\xrightarrow{p} (\alpha + \beta c+\gamma \operatorname{\mathbb{E}}[z])f(c)$.因此，我认为 $$\hat{m}(c)\xrightarrow{p}\alpha + \beta c+\gamma \operatorname{\mathbb{E}}[z]$ $
但是，我正在学习的课程的助教提到 $\hat{m}(c)$ 应该收敛到 $c$ 我显然没有得到。我认为原因可能是我假设 $x_i$ 和 $z_i$ 是独立的。但是，如果没有这个假设，我不确定如何找到 $\hat{m}(c)$ 的概率极限。
有人可以指出我工作中出错的地方，或者解释如何在不假设独立的情况下找到限制吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644924/non-parametric-regression-with-an-omitted-variable</guid>
      <pubDate>Sat, 13 Apr 2024 08:13:14 GMT</pubDate>
    </item>
    </channel>
</rss>