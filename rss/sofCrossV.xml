<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 22 Jan 2025 09:17:46 GMT</lastBuildDate>
    <item>
      <title>两个嘈杂位置测量对应于同一位置的概率是多少？</title>
      <link>https://stats.stackexchange.com/questions/660363/what-is-the-probability-of-two-noisy-position-measurements-corresponding-to-the</link>
      <description><![CDATA[我对车辆进行了连续的噪声位置测量，每个测量都以方差的形式存在不确定性。我使用卡尔曼滤波器将这些测量结果组合起来，该滤波器将模型状态输出为正态分布（位置、速度和协方差）。虽然卡尔曼滤波器对移动物体很有效，但由于噪声测量，它也开始预测静态物体的速度。
如何使用两个连续的位置估计及其方差来计算物体保持在同一位置的概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/660363/what-is-the-probability-of-two-noisy-position-measurements-corresponding-to-the</guid>
      <pubDate>Wed, 22 Jan 2025 08:56:23 GMT</pubDate>
    </item>
    <item>
      <title>如果余弦表示相似度，那么欧几里得距离、曼哈顿距离和量级差异又如何呢？</title>
      <link>https://stats.stackexchange.com/questions/660359/if-cosine-represents-similarity-then-how-about-euclidean-distance-manhattan-di</link>
      <description><![CDATA[我正在谈论机器学习中指标的实用见解，特别是在 LLM 上下文中的高维嵌入向量。
例如，两个向量（两个词）之间的余弦表示相似性，但它忽略了两个向量的大小。
另一件事的见解怎么样，例如：

欧几里得距离

曼哈顿距离

幅度差异


它代表什么？
对于幅度差异，可以通过绝对减法（定义 1）或比率（定义 2）来定义。
例如，如果使用第一个定义，两个向量之间的幅度差异将导致 $0$，并且 $1$ 否则。它只是像下图这样计算红线和蓝线：

因此，幅度差异也期望与余弦相似度相同的参数。]]></description>
      <guid>https://stats.stackexchange.com/questions/660359/if-cosine-represents-similarity-then-how-about-euclidean-distance-manhattan-di</guid>
      <pubDate>Wed, 22 Jan 2025 06:31:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的二元变量进行探索性因子分析和中介分析</title>
      <link>https://stats.stackexchange.com/questions/660356/exploratory-factor-analysis-and-mediation-analysis-with-binary-variables-in-r</link>
      <description><![CDATA[我的项目重点是使用电子病历数据探索疾病 A 的癌前合并症模式。在之前的项目中，我们根据诊断/实验室测试/药物信息确定了大约 30 种合并症。在这个项目中，我们旨在使用探索性因子分析（通过 psych 包）分析这些合并症如何聚类，并检查疾病 B 在疾病 A 发展中的中介作用（使用 lavaan 包）。我目前有以下主要问题：

数据显示 KMO 值较低（约为 0.2）。我们删除了共现率为零的变量对，这改善了 KMO，但导致一些变量丢失。我们是否应该继续使用低 KMO，因为我们更愿意保留这些变量？

对于包含所有二元变量的探索性因子分析，我可以使用四分相关（wls 估计量）吗？

A 和 B 是二元变量。对于中介分析，我可以使用对 A 和 B 进行排序的 lavaan 包（wls 估计器）吗？


非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/660356/exploratory-factor-analysis-and-mediation-analysis-with-binary-variables-in-r</guid>
      <pubDate>Wed, 22 Jan 2025 05:10:03 GMT</pubDate>
    </item>
    <item>
      <title>您能拥有在集群中变化的 2 级变量吗？</title>
      <link>https://stats.stackexchange.com/questions/660355/can-you-have-a-level-2-variable-that-varies-in-a-cluster</link>
      <description><![CDATA[我正在尝试创建一个包含 1 级和 2 级预测因子的 2 级回归模型。但是，我的一个预测因子是非自均值变量。
这个非自均值的解释：假设它与回答“是”的问题数量有关（总共 5 个问题，因此范围是 0-5），我们将其命名为“N_Yes”。对于集群 A，假设我们有 n 个参与者。我会将这 n 个人的 N_Yes 加起来，得到 S_Yes = sum(N_Yes)（对于整个集群来说，这是相同的）。然后，对于这个集群中的每个参与者，他们的非自均值 = (S_Yes - N_Yes)/(n-1)。因此，基本上，这会导致集群中所有人的平均值，不包括该参与者本人。
所以我的问题是，您能否将这个非自身平均值作为 2 级回归模型中的 2 级预测变量（如 R 中的 lme4 或类似模型）？到目前为止，我看到的所有内容都表明 2 级变量不应该在集群内变化。如果模型可以在 2 级使用此变量运行，它会正常运行，还是会成为您不想做的事情？您将如何处理这种情况？
使用这种奇怪方法的理由：我想调查一些问题的“同伴效应”，这涉及估计一个人周围环境的平均水平，不包括自己。这对于大型集群来说可能微不足道，但对于少于 15 个且有异常值的集群，它可能很有意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/660355/can-you-have-a-level-2-variable-that-varies-in-a-cluster</guid>
      <pubDate>Wed, 22 Jan 2025 04:42:19 GMT</pubDate>
    </item>
    <item>
      <title>我可以在显性分析中使用虚拟交互变量吗？如何解释交互的结果？</title>
      <link>https://stats.stackexchange.com/questions/660354/can-i-use-dummy-interaction-variables-in-dominance-analysis-how-to-interpret-th</link>
      <description><![CDATA[我目前正在进行一项研究，研究社会经济因素和金融包容性如何影响家庭层面的清洁水和卫生设施的获取。以下是我使用的变量列表：
因变量：

改善水质
改善卫生设施
（它们是虚拟变量，1=改善，0=未改善）

自变量：

储蓄（虚拟变量，hhh 是否有储蓄）
信贷（虚拟变量，hhh 户主是否有信贷）
发展区域（虚拟变量，家庭是否居住在快速发展的地区）
4-9。社会经济因素（女性、家庭规模、城市等）

在本研究中，我想了解基于发展区域的金融包容性如何影响两种访问。因此，我将金融包容性的 2 个独立变量与发展区域进行交互，这样就有了 2 个新变量：
10. 储蓄发展状态
11. 信贷发展状态
我的讲师建议查看每个变量的贡献/主导性，所以我需要进行主导性分析。但我很困惑，如果模型中有交互变量，这种分析是否是一种好方法？如果可能，我该如何解释结果？
例如，如果储蓄*发展的标准化主导性分析为 12%，在 15 个变量中排名第 5，这意味着什么？与没有交互的单独储蓄变量排名有什么区别？]]></description>
      <guid>https://stats.stackexchange.com/questions/660354/can-i-use-dummy-interaction-variables-in-dominance-analysis-how-to-interpret-th</guid>
      <pubDate>Wed, 22 Jan 2025 03:18:54 GMT</pubDate>
    </item>
    <item>
      <title>处理 glm.nb 模型中的残差分析</title>
      <link>https://stats.stackexchange.com/questions/660349/deal-with-residual-analysis-in-glm-nb-models</link>
      <description><![CDATA[编辑 2025 年 1 月 22 日：我上传了数据分布的正确数字。现在数据可能看起来没有那么零膨胀了。
我有以下数据框，代表一个物种的丰度、所有物种的总丰度以及每株植物存在的物种数量
&#39;data.frame&#39;: 474 obs. 5 个变量中的 5 个：
$ 年份：因子，具有 2 个水平“2016”，“2023”：2 2 2 2 2 2 2 2 2 2 ...
$ Tot_O_nubilalis_plant：数字 13 13 13 11 11 11 5 5 5 12 ...
$ Tot_individuals_plant：数字 20 20 20 21 21 21 11 11 11 23 ...
$ N_species_plant：因子，具有 4 个水平“0”、“1”、“2”、“3”：3 3 3 4 4 4 4 4 4 3 ...
$ Gregariousness_O_nubilalis_plant：具有 4 个水平“Doubleton”、“Four or more”的因子，...：2 2 2 2 2 2 2 2 2 2 ...

由于我正在处理计数数据，因此我选择使用以下模型。我首先尝试仅对数据子集（仅 2023 年）进行测试
glm_nb_model &lt;- glm.nb(Tot_O_nubilalis_plant ~ Tot_individuals_plant + 
N_species_plant + Gregariousness_O_nubilalis_plant , 
data = data_unique, 
control = glm.control(maxit = 100))

结果如下：
调用：
glm.nb(formula = Tot_O_nubilalis_plant ~ Tot_individuals_plant + 
N_species_plant + Gregariousness_O_nubilalis_plant, data = data_unique, 
control = glm.control(maxit = 100), init.theta = 43.81661505, 
link = log)

系数：
估计标准差。误差 z 值
（截距） 0.614298 0.723111 0.850
Tot_individuals_plant 0.039424 0.004091 9.638
N_species_plant2 -0.252128 0.769732 -0.328
N_species_plant3 -0.437599 0.763584 -0.573
Gregariousness_O_nubilalis_plant四个或更多 1.092309 0.247407 4.415
Gregariousness_O_nubilalis_plantSingleton -0.599964 0.519276 -1.155
Gregariousness_O_nubilalis_plantTripleton 0.398485 0.297288 1.340
Pr(&gt;|z|) 
(截距) 0.396 
Tot_individuals_plant &lt; 2e-16 ***
N_species_plant2 0.743 
N_species_plant3 0.567 
Gregariousness_O_nubilalis_plantFour 或更多 1.01e-05 ***
Gregariousness_O_nubilalis_plantSingleton 0.248 
Gregariousness_O_nubilalis_plantTripleton 0.180 
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（负二项分布（43.8166）系列的分散参数取为 1）

零偏差：145 个自由度上的 354.94
残差偏差：139 个自由度上的 113.19
（12 个观察值消除了价值损失的原因）
AIC：690.41

Fisher 评分迭代次数：1

Theta：43.8
标准差。错误：28.7 

2 x 对数似然：-674.412 

残差分析对我来说似乎相当不错：

当我包含 2016 年的数据（或仅分析 2016 年的数据）时，我无法获得如此好的残差分析。我确实认为问题在于数据在不同年份的分布不同（见图）。2016 年，我有许多采样植物没有个体。
我尝试了许多其他模型和数据转换，但没有得到好的结果。如何处理残差分析问题？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660349/deal-with-residual-analysis-in-glm-nb-models</guid>
      <pubDate>Tue, 21 Jan 2025 22:54:50 GMT</pubDate>
    </item>
    <item>
      <title>给定时间序列数据集中，输出与输入相比时间偏移不规则</title>
      <link>https://stats.stackexchange.com/questions/660346/irregular-time-shifts-of-output-compared-to-inputs-in-given-time-series-data-set</link>
      <description><![CDATA[我有一些具有多个特征的时间序列数据。输出发生了偏移（我的意思是输出值与相应输入偏移的时间是不规则的）。我对偏移量有一些了解，但并不准确。有没有办法使用长短期记忆 (LSTM) 神经网络来考虑这些不规则的偏移？或者在训练 LSTM 模型之前可以进行任何预处理。]]></description>
      <guid>https://stats.stackexchange.com/questions/660346/irregular-time-shifts-of-output-compared-to-inputs-in-given-time-series-data-set</guid>
      <pubDate>Tue, 21 Jan 2025 21:56:41 GMT</pubDate>
    </item>
    <item>
      <title>N=2 个样本的 Welch t 检验 p 值的潜在精确解</title>
      <link>https://stats.stackexchange.com/questions/660339/potential-exact-solution-to-welch-t-test-p-values-for-n-2-samples</link>
      <description><![CDATA[前段时间，我发帖称现有软件包（例如 scipy.stats.ttest_ind 和 equal_var=False）仅给出了 Welch t 检验的 p 值的近似结果，特别是对于 $N=2$ 样本。我认为我已经找到了一种贝叶斯方法，该方法在假设均值的先验均匀和 Jeffery 对正态分布的标准差$\sigma$的先验均匀的情况下，可以产生相对容易计算的检验，但我希望在完成这一推理时能得到反馈。
考虑从两个正态分布$x_1, x_2\sim \mathcal{N}(\mu_x, \sigma_x)$和$y_1, y_2\sim \mathcal{N}(\mu_y, \sigma_y)$中各抽取两个样本。如果我们对 $\mu_x, \mu_y$ 使用均匀先验，对 $\sigma_x^2,\sigma_y^2$ 使用 Jeffery 先验，这样 $p(\mu, \sigma^2) \propto 1/\sigma^2$，则 $\mu_x$ 的边际后验分布（在 $\sigma_x$ 上积分后）是 $N=2$ 的柯西分布，
$$P(\mu_x | x_1, x_2) = \mathrm{Cauchy}\left(\bar x, d_x\right) $$
对于 $P(\mu_y|y_1, y_2)$ 也类似，其中 $\bar x = \frac{x_1+x_2}{2}$ 和 $d_x = \frac{|x_1-x_2|}{2}$。要执行单侧检验 $\mu_x&gt;\mu_y$，我们可以直接对 $\mu_x &gt; 的这些概率进行积分\mu_y$，所以
$$P(\mu_x &gt; \mu_y|x_1,x_2,y_1,y_2) = \int_{\mu_y&gt;\mu_x} P(\mu_x|x_1, x_2) P(\mu_y | y_1, y_2) = \frac{1}{2} + \frac{1}{\pi}\arctan \left( \frac{\bar x - \bar y}{d_x + d_y} \right)$$
是的，chatgpt 帮助了积分和数学。我可以将其解释为建议检验统计量吗？
$$S=\frac{\bar x-\bar y}{d_x + d_y}$$
在零假设 $\mu_x &gt; \mu_y$ 下，考虑单侧贝叶斯后验概率 $p=\frac{1}{2} + \frac{1}{\pi} \arctan S$ 是否合理？如果 $p &lt; \alpha$ 为典型 $\alpha=0.05$，声称显著性是否合适？如果是这样，这似乎是一个相当简单的表达式。从评论和答案中，我意识到我不应该将其称为适当的 p 值，但我想知道的是它是否是一个合法的统计检验。
编辑：重写了核心问题，使检验统计量和零假设更加清晰，清理了一些表达式，在此过程中学习了更多统计学知识。]]></description>
      <guid>https://stats.stackexchange.com/questions/660339/potential-exact-solution-to-welch-t-test-p-values-for-n-2-samples</guid>
      <pubDate>Tue, 21 Jan 2025 20:16:04 GMT</pubDate>
    </item>
    <item>
      <title>如何比较组内前后的比例？</title>
      <link>https://stats.stackexchange.com/questions/660338/how-to-compare-proportions-for-before-after-within-groups</link>
      <description><![CDATA[我有 4 个阵列，每个阵列有多个站点，我们在每个阵列的 100 个点中收集了主要基质类型（SS 或 LL）。因此，我在每个站点内标记为每种基质的 100 个点中都有一定比例。
我们进行了两次测试（一次是在 1990 年代，一次是今年）。我想测试每个阵列（多个站点）中每种土壤类型的比例在不同年份（1990 年代与今天）之间是否不同。考虑到每个阵列内都有成对（前后站点），我不确定我是否应该使用卡方检验或其他方法？



数组
站点
基底
percsub
时间




AC
1
LL
0.6
今天


AC
1
SS
0.4
今天


AC
2
LL
0.6
今天


AC
2
SS
0.4
今天


AC
3
LL
0. 7
今天


AC
3
SS
0.1
今天


LC
5
LL
0.91
今天


LC
8
LL
0.84
至天


LC
8
SS
0.1
今天


LC
14
LL
0.94
今天


LC
15
LL
0.87
今天


LC
16
LL
0.89
今天


LC
17
LL
0.84
今天


LC
17
SS
0.15
今天


SJHW
14
LL
0.95
今天


SJHW
14
SS
0.05
今天


SJHW
16
LL
0.77
今天


SJHW
16
SS
0.23
今天


SJHW
17
LL
0.91
今天


SJHW
17
SS
0.08
今天


WC 
11
LL
0.58
今天


WC
11
SS
0.37
今天


WC
12
LL
0.6
今天


WC
 12
SS
0.38
今天


AC
1
LL
0.7
1990 年代


AC
1
SS
0.3
1990 年代


AC
2
LL 
0.39
1990 年代


AC
2
SS
0.61
1990 年代


AC
3
LL
0.25
1990 年代


AC
3
SS
0. 75
1990 年代


LC
5
LL
0.35
1990 年代


LC
8
LL
0.59
1990 年代


LC
8
SS
0.38
 1990 年代


LC
14
LL
0.6
1990 年代


LC
15
LL
0.39
1990 年代


LC
16
LL
0.5
1990 年代


LC
17
LL
0.63
1990 年代


LC
17
SS
0.3
1990 年代


SJHW
14
LL
0.87
1990 年代


SJHW
14
SS
0.13
1990 年代


SJHW
16
LL
0.71
1990 年代


SJHW
16
SS
0.29
1990 年代


SJHW
17
LL
0.8
1990 年代


SJHW
17
SS
0.13
1990 年代


WC
11
LL
0.46
1990 年代


WC 
11
SS
0.4
1990 年代


WC
12
LL
0.49
1990 年代


WC
12
SS
0.2
1990 年代


]]></description>
      <guid>https://stats.stackexchange.com/questions/660338/how-to-compare-proportions-for-before-after-within-groups</guid>
      <pubDate>Tue, 21 Jan 2025 19:43:41 GMT</pubDate>
    </item>
    <item>
      <title>是否可以汇总 AIC/BIC 值以进行参与者级模型比较？</title>
      <link>https://stats.stackexchange.com/questions/660262/is-it-possible-to-aggregate-aic-bic-values-for-participant-level-model-compariso</link>
      <description><![CDATA[我有一个数据集，其中包含来自数百名参与者的情绪时间序列数据，他们每个人都参加了生态瞬时评估 (EMA) 研究。由于每个参与者的事件时间完全不同，我决定使用 R 中的药代动力学建模包 (mrgsolve) 生成的复杂非线性模型分别拟合每个参与者的数据。
我使用 nloptr 根据从先验知识得出的初步猜测来推导参数。由于呈现的模型数量庞大，手动优化每个模型的参数并不切实际。相反，我使用合理但未优化的参数值运行这些模型，这实际上效果很好，因为每个参与者对事件的情绪反应模式大致相似。
对于每个模型，我的零假设是数据纯粹由噪声组成。我的备选假设是，药代动力学衍生的模型在模拟参与者的情绪反应方面优于噪声模型。到目前为止，药代动力学模型似乎在几乎（但不是所有）情况下都产生了更优的 RSS 和 AIC/BIC 值。
有没有办法批量测试药代动力学建模方法产生更优的建模结果的假设，表明其所基于的模型优于噪声的零假设？例如，如果 95%（或其他百分比）的药代动力学模型产生比基于噪声的模型更优的拟合结果，这可以用来证明统计意义吗？或者是否有另一种基于指标的方法来测试这个假设，例如比较每个参与者的每个模型之间的 AIC 和 BIC 值，并将这些值汇总到所有参与者中？]]></description>
      <guid>https://stats.stackexchange.com/questions/660262/is-it-possible-to-aggregate-aic-bic-values-for-participant-level-model-compariso</guid>
      <pubDate>Mon, 20 Jan 2025 08:21:49 GMT</pubDate>
    </item>
    <item>
      <title>哈默斯利·克利福德定理的两个版本</title>
      <link>https://stats.stackexchange.com/questions/660224/two-versions-of-the-hammersley-clifford-theorem</link>
      <description><![CDATA[在学习蒙特卡罗方法时，我了解到完整条件$P(x_j \mid x_1, \ldots, x_{j-1}, x_{j+1}, \ldots, x_p)$在某些条件下确定联合分布。这个结果是使用书中所谓的 Hammersley-Clifford 定理（如下所述）证明的，但我注意到他们使用的形式与我在马尔可夫网络背景下熟悉的形式非常不同。

Hammersley-Clifford 定理（来自书中）
让 $(X_1, \ldots, X_p)$ 满足正性条件并具有联合密度 $f(x_1, \ldots, x_p)$。然后，对于所有 $(\xi_1, \ldots, \xi_p) \in \operatorname{supp}(f)$:
$$
f(x_1, \ldots, x_p) \propto \prod_{j=1}^p \frac{f_{X_j \mid X_{-j}}(x_j \mid x_1, \ldots, x_{j-1}, \xi_{j+1}, \ldots, \xi_p)}{f_{X_j \mid X_{-j}}(\xi_j \mid x_1, \ldots, x_{j-1}, \xi_{j+1}, \ldots, \xi_p)}。
$$

Hammersley-Clifford 定理（针对马尔可夫网络）
设 $P$ 为 $\mathcal{X}$ 上的正分布，$\mathcal{H}$ 为 $\mathcal{X}$ 上的马尔可夫网络图。如果 $\mathcal{H}$ 是 $P$ 的 I-map（即 $\mathcal{H}$ 的马尔可夫独立性作为 $P$ 中的概率独立性成立），则 $P$ 是对 $\mathcal{H}$ 进行因式分解的吉布斯分布。
因式分解意味着 $P$ 是通过因子 $\Phi = \{\phi_1(\boldsymbol{D}_1), \ldots, 参数化的吉布斯分布\phi_K(\boldsymbol{D}_K)\}$:
$$
P_{\Phi}(X_1, \ldots, X_n) = \frac{1}{Z} \prod_{k=1}^K \phi_k(\boldsymbol{D}_k),
$$
其中 $Z$ 是规范化常数，每个 $\boldsymbol{D}_k$ 对应于 $\mathcal{H}$ 的一个完全子图（团）。

我的问题是：Hammersley-Clifford 定理的这两个陈述如何联系在一起？它们是具有相同名称但本质上不同的定理吗，或者是否有办法从另一个定理中证明一个定理（尤其是从第二个定理中证明第一个定理）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660224/two-versions-of-the-hammersley-clifford-theorem</guid>
      <pubDate>Sun, 19 Jan 2025 04:44:17 GMT</pubDate>
    </item>
    <item>
      <title>r 匹配倾向得分和最近邻</title>
      <link>https://stats.stackexchange.com/questions/660146/r-matching-propensity-scores-and-nearest-neighborhood</link>
      <description><![CDATA[我对匹配过程有理论上的理解，但我不明白 MatchThem 库中是如何实现的。
我像这样指定模型
 matchthem( treatment ~ x1 + x2, x3, 
data = df,
method = &quot;nearest&quot;,
distance = &quot;glm&quot;,
link = &quot;logit&quot;
)

当使用 bal.tab 函数检查余额时，我看到
 Mean.Diff.Unmatch Mean.Diff.Adj
distance 1.087 0.715


我的问题是，Mean.Diff.Unmatched (distance) 1.087 是多少？由于 matchtem 函数估计倾向得分，距离不应该小于 1 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660146/r-matching-propensity-scores-and-nearest-neighborhood</guid>
      <pubDate>Fri, 17 Jan 2025 05:40:43 GMT</pubDate>
    </item>
    <item>
      <title>检查平均值和估计标准差的正确程序</title>
      <link>https://stats.stackexchange.com/questions/660353/correct-procedure-to-check-mean-and-estimate-standard-deviation</link>
      <description><![CDATA[这可能很简单，但我希望确认一下推理过程。
假设 X 是随机变量，并且通过一些理论程序，我们已经找到了它的预期值。假设我们能够执行相当大的模拟来找到 X 的样本。

有什么有效的方法可以用经验数据来检查我们对预期值的理论计算是否正确？

X 标准差的合理估计应该是多少？


大约 1，我可能会这样做。首先，选择一个较大的 N（例如 5000 万），并抽取长度为 N 的 X 样本。由此，我们可以计算样本均值和样本标准差（从样本均值开始，因此使用贝塞尔校正 N-1）。然后，利用 CLT，我们可以使用正态分布（近似 t 分布）计算置信区间（假设置信度为 95%）。这样，我们有 95% 的信心认为预期值将位于区间内。想象一下，一个肯定的答案是不够的，所以这应该重复“很多次”(?)
关于 2：此时，我已经发现了一个标准差，它实际上是有偏差的。但如果在第一点我确信我的预期值的理论竞争是正确的，那么我可以再次计算样本的标准差，这次使用实际预期值，而无需使用贝塞尔校正。
所有这些都是进行我的调查的合理方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660353/correct-procedure-to-check-mean-and-estimate-standard-deviation</guid>
      <pubDate>Mon, 13 Jan 2025 22:46:03 GMT</pubDate>
    </item>
    <item>
      <title>线性回归 - 响应变量为百分比改善或 m/s？</title>
      <link>https://stats.stackexchange.com/questions/659686/linear-regression-response-variable-as-percent-improvement-or-m-s</link>
      <description><![CDATA[我正在尝试对包含 8 种不同跑步距离的数据集进行统计，这些距离在遵循训练方案之前和之后都有时间，并且基于距离对改进进行线性回归（所有完成时间都有所下降）。我不确定是否要转换为百分比改进或使用 m/s 之类的变量，然后减去跑步时间 1 和跑步时间 2，以便能够比较不同的距离组。显然，绝对时间差异并不大，因为更长的距离自然会有更大的改进。但我读到过，不建议将百分比改进转换为线性回归中的响应变量。我该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/659686/linear-regression-response-variable-as-percent-improvement-or-m-s</guid>
      <pubDate>Tue, 07 Jan 2025 21:03:50 GMT</pubDate>
    </item>
    <item>
      <title>具有相关随机变量的 $E[X\mid U,V]$</title>
      <link>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</link>
      <description><![CDATA[设 $(X,Y,Z)$ 为三维随机变量，其密度函数为 $f(x,y,z)=\frac{2}{3}(x+y+z)$ 在 $0&lt;x,y,z&lt;1$ 上，$U=\min(X,Y,Z)$，$V=\max(X,Y,Z)$。计算$E[X\mid U,V]$。
我认为答案是$\frac{14U^2+26UV+14V^2}{27(U+V)}$，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/649158/ex-mid-u-v-with-dependent-random-variables</guid>
      <pubDate>Thu, 13 Jun 2024 05:43:04 GMT</pubDate>
    </item>
    </channel>
</rss>