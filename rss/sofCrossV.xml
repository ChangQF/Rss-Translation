<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 09 Oct 2024 18:22:25 GMT</lastBuildDate>
    <item>
      <title>寻找使用“求解方程”带宽进行核密度估计的可靠教程</title>
      <link>https://stats.stackexchange.com/questions/655559/looking-for-robust-tutorial-using-solve-the-equation-bandwidth-for-kernel-dens</link>
      <description><![CDATA[我目前正在从事的工作是让我为通过任意有界函数 $z=p(\vec{x})$ 诱导的分布生成 CDF 函数，其中 $p:\mathcal{D} \subset \mathbb{R}^m \to \mathcal{R} \subset \mathbb{R}$，并且 $\mathcal{D}:=\times_{i=1}^m [a_i,b_i]$ 和 $-\infty &lt; a_i &lt; b_i &lt; \infty$。更具体地说，我取随机变量$ \vec{X} \sim \mathcal{U}(\mathcal{D})$，并诱导随机变量$Z = p(\vec{X})$，并使用$n$个样本构建近似值$F_n(z)$，以获得“真实的”（可能/通常不可知的）累积分布函数$F(z)$。我正在使用高斯核的核密度估计构建这个近似值，$K(t) = (2\pi)^{-1/2}\exp(-t^2/2)$，并应用 Silverman 的经验法则来计算带宽的值，$h$。此规则为
$$
h = 0.9 \min\left\{\widehat{\sigma}, \frac{IQR}{1.34} \right\}
$$
（顺序问题，我发现很多不同的规则被称为 Silverman 经验法则，因此这 可能 实际上不是 Silverman 经验法则。请在评论中纠正我，但这最终与我的询问无关）。
我还想使用 Solve-the-Equation（糟糕的品牌名称）带宽计算来估算这一点，但我找不到任何关于如何进行此操作的易于理解的演示文稿/来源/参考资料。如果有人可以指出有关如何为 KDE 进行 Solve-the-Equation 带宽的详尽解释/来源，我将不胜感激。尤其是不会掩盖太多细节的那种。这种数学不是我的强项。或者，如果网上找不到这样的教程，可以在这里介绍一个强大的教程。此外，请纠正任何]]></description>
      <guid>https://stats.stackexchange.com/questions/655559/looking-for-robust-tutorial-using-solve-the-equation-bandwidth-for-kernel-dens</guid>
      <pubDate>Wed, 09 Oct 2024 18:04:25 GMT</pubDate>
    </item>
    <item>
      <title>线性变换后计算 RBF 核矩阵的有效方法</title>
      <link>https://stats.stackexchange.com/questions/655558/efficient-way-to-compute-rbf-kernel-matrix-after-linear-transformation</link>
      <description><![CDATA[我有一个点数据集$\{\mathbf{x}_i | \mathbf{x}_i \in \mathbb{R}^n\}$ 和一个线性变换矩阵 $\mathbf{F} \in \mathbb{R}^{n \times m}$，使得 $\mathbf{y}_i = \mathbf{F}^T \mathbf{x}_i$，其中 $\mathbf{y}_i \in \mathbb{R}^m$ $m&lt;n$。
矩阵 $\mathbf{F}$ 是可学习的，可能带有约束，例如每列具有单位范数，和/或列是正交的。我想计算点 $\mathbf{y}_i$ 上的径向基函数核矩阵，也就是说，对于每个 $i,j$，计算 $\exp\left(\|\mathbf{y}_i - \mathbf{y}_j\|^2\right/2\sigma^2)$。
由于 $\mathbf{F}$ 会更新，我想知道是否有某种有效的方法可以在每次 $\|\mathbf{y}_i - \mathbf{y}_j\|^2$ 之后重新计算或近似距离 $\|\mathbf{y}_i - \mathbf{y}_j\|^2$ class=&quot;math-container&quot;&gt;$\mathbf{F}$ 更新。]]></description>
      <guid>https://stats.stackexchange.com/questions/655558/efficient-way-to-compute-rbf-kernel-matrix-after-linear-transformation</guid>
      <pubDate>Wed, 09 Oct 2024 18:04:09 GMT</pubDate>
    </item>
    <item>
      <title>向线性回归模型添加更多回归量与模型的 F 统计量之间的关系</title>
      <link>https://stats.stackexchange.com/questions/655557/relationship-between-adding-more-regressors-to-a-linear-regression-model-and-the</link>
      <description><![CDATA[我在思考当我们添加更多回归量时对线性回归模型中不同参数的影响，但我不太确定 F 统计量会发生什么。
我知道对于 $Y=\beta_0+\beta_1 x_1 +...+\beta_p x_p$，我们有 $({\rm Explained}\ SS/p)/({\rm Residual}\ SS/n-p-1) \sim F_{p,n-p-1}$，并且当我们在模型中添加更多回归量时，${\rm Residual}\ SS$ 将减少，而 ${\rm Explained}\ SS$ 将增加。对我来说，这应该意味着 $F$ 统计量应该增加，但在运行一些方差分析测试后，情况似乎不一定如此。
我的想法是否正确，即 $F$ 统计量应该增加？或者我的初步测试是否正确，并且 $F$ 统计量的值将无法确定？]]></description>
      <guid>https://stats.stackexchange.com/questions/655557/relationship-between-adding-more-regressors-to-a-linear-regression-model-and-the</guid>
      <pubDate>Wed, 09 Oct 2024 17:46:42 GMT</pubDate>
    </item>
    <item>
      <title>创建针对一个主题和每个项目的评分者间信度</title>
      <link>https://stats.stackexchange.com/questions/655556/create-inter-rater-reliability-on-one-subject-and-per-item</link>
      <description><![CDATA[我公司接到一项任务，因为我不太懂统计学，也没有找到解决我的问题的具体方法，所以我想问问你们。
那么我的任务是什么呢？
我们必须每年培训员工。培训如下：
员工们正在观看一个主题的视频，然后他们必须对视频的不同部分进行 1-5 的评分，如果无法评估，则为 0。
目标是评估不同的评分者是否对特定部分给出了相同的评分。例如，可以使用 Landis Koch 基准来评估可靠性。
如果特定部分高于某个阈值，则公司感到满意。如果没有，则必须对员工进行该特定部分的培训。
这意味着我必须为每个部分创建一个可靠性分数，以查看是否需要培训。此外，公式还必须考虑评级是否接近。
这就是为什么例如简单的百分比可靠性不起作用的原因（我认为）
此外，像 Fleiss Kappa 这样的公式也不起作用，因为它无法确定一个主题的单个部件（或项目）的 kappa。
例如，我们有 50 位评分者，并且特定部件的评级为 5 次“0”，5 次“1”，10 次“2”，30 次“3”，其他部件没有投票。还有一个权重也应该计算在内。评级为“1”表示未通过，而“0”表示该部件无法评级。数字上很接近，但对主题来说却是灾难性的。然后，一个评分员给他打了不及格分，而另一个评分员给他打了不及格分。
有没有办法计算一个项目的分数、Kappa 值或其他东西，并以某种方式对其进行加权？
正如我所说，我不太喜欢统计学，但当我知道要寻找什么时，我认为这会有所帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655556/create-inter-rater-reliability-on-one-subject-and-per-item</guid>
      <pubDate>Wed, 09 Oct 2024 17:39:48 GMT</pubDate>
    </item>
    <item>
      <title>线性回归中的标准差方差</title>
      <link>https://stats.stackexchange.com/questions/655554/variance-of-standard-deviation-in-linear-regression</link>
      <description><![CDATA[考虑线性回归设置$$y=X\beta+\epsilon$$，其中$\epsilon\sim N(0,\sigma)$，因此$y|X\sim N(X,\sigma I)$。让 $X$ 为 $n\times p$，并且 $Y$ 为 $n\times 1$。
我理解 $\sigma$ 的无偏估计量是 $\hat{\sigma}=\frac{1}{n-p}||y-X\hat{\beta}||_2^2$，并且我知道一些方法可以证明这一点，例如 这里。
问题：我不确定下面概述的方法出了什么问题，该方法表明$\hat{\sigma} = 1/n ||y-X\hat{\beta}||_2^2$是一个无偏估计量。希望有人指出我的错误：
$$\mathbb{E}(​​||y-X\hat{\beta}||_2^2)=\mathbb{E}(​​\sum_{n} (y_i-\sum_p x_{ij} \beta_j)^2)$$
然后从上面的$y|X$分布，我们得到$y_i|X\sim N(\sum_p x_{ij} \beta_j,\sigma)$，因此这通过线性减少到
$$\sum_n \mathbb{V}(y_i|X) = n\sigma$$
因此可以看出 $\hat{\sigma}=1/n ||y-X\hat{\beta}||_2^2$ 是一个无偏估计量。$X$ 的排名 $p$ 在哪里发挥作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/655554/variance-of-standard-deviation-in-linear-regression</guid>
      <pubDate>Wed, 09 Oct 2024 16:53:58 GMT</pubDate>
    </item>
    <item>
      <title>Diaconis 关于一副牌洗 3 次的论点</title>
      <link>https://stats.stackexchange.com/questions/655549/diaconis-argument-for-3-shuffles-in-a-deck</link>
      <description><![CDATA[我记得听过伟大的概率论者 Persi Diaconis 说过，三次洗牌就足以得到一副充分洗过的牌。我想知道这一说法是否有原始参考，或者是否有令人信服的标准或假设来证明这一说法。]]></description>
      <guid>https://stats.stackexchange.com/questions/655549/diaconis-argument-for-3-shuffles-in-a-deck</guid>
      <pubDate>Wed, 09 Oct 2024 16:04:36 GMT</pubDate>
    </item>
    <item>
      <title>当将一个向量中的某些值切换为零时的相关行为</title>
      <link>https://stats.stackexchange.com/questions/655548/correlation-behaviour-when-switching-some-values-in-one-vector-to-zero</link>
      <description><![CDATA[如果我们将第二个变量中的某些值切换为零，那么两个变量之间的相关性是否存在系统性行为？
这里有一个例子：
# 样本数量
n &lt;- 1000

# 生成相关的连续变量
Sigma &lt;- matrix(c(1, 0.2, 0.2, 1), 2, 2)
continuous_vars &lt;- MASS::mvrnorm(n, mu = c(0, 0), Sigma = Sigma)

# 对连续变量进行二值化
x &lt;- as.numeric(continuous_vars[, 1] &gt; quantile(continuous_vars[, 1], probs = 0.8))
y &lt;- as.numeric(continuous_vars[, 2] &gt; quantile(continuous_vars[, 2], probs = 0.8))
z &lt;- x*y # &lt;- 这会将许多 1 变成零

paste0(&quot;sum(x) = &quot;, sum(x) )
paste0(&quot;sum(y) = &quot;, sum(y) )
paste0(&quot;sum(z) = &quot;, sum(z) )

[1] &quot;sum(x) = 200&quot;
[1] &quot;sum(y) = 200&quot;
[1] &quot;sum(z) = 54&quot;
paste0(&quot;cor(x,y) = &quot;, round(cor(x, y), digits = 2))
paste0(&quot;cor(x,z) = &quot;, round(cor(x, z), digits = 2))

[1] &quot;cor(x,y) = 0.09&quot;
[1] &quot;cor(x,z) = 0.48&quot;
在此示例中，一旦我们将第二个变量中的某些 1 切换为 0，相关性就会增加。
是否存在特定设置，在将某些 y 值切换为 0 时，我们期望相关性始终更高？]]></description>
      <guid>https://stats.stackexchange.com/questions/655548/correlation-behaviour-when-switching-some-values-in-one-vector-to-zero</guid>
      <pubDate>Wed, 09 Oct 2024 15:37:03 GMT</pubDate>
    </item>
    <item>
      <title>交互绘图</title>
      <link>https://stats.stackexchange.com/questions/655547/interaction-plotting</link>
      <description><![CDATA[如何绘制研究文章中的交互图。我试图绘制连续响应变量上的连续预测变量和二元交互变量的交互图。例如，$Y=β+β1X1+β2X2+β3X1*X2$，其中$X1$是连续的，$X2$是二元的，$Y$是连续的。经过回归分析，我发现响应变量存在正交互作用。我想用图形支持这些发现。我看到很多研究论文都这样做。但在 x 轴的图形中，我看到方程的连续预测变量分为低和高。当变量是连续变量时，如何进行这种分类？
所以我找到了如何使用 interaction.plot() 函数在 R 中绘图的方法。但我的图表看起来像这样。有人能解释一下为什么吗？

我使用的代码：
interaction.plot(x.factor = Data_cleaningsave$IExM,
trace.factor = Data_cleaningsave$Stlog, 
response = Data_cleaningsave$logres1,fun = median,xlab=&quot;IM&quot;, 
ylab=&quot;RM&quot;, trace.label=&quot;ST&quot;)



@Shawn 收到您的评论后，我修改了代码。图表与上图类似]]></description>
      <guid>https://stats.stackexchange.com/questions/655547/interaction-plotting</guid>
      <pubDate>Wed, 09 Oct 2024 15:33:25 GMT</pubDate>
    </item>
    <item>
      <title>什么原因导致测试损失始终优于评估损失？</title>
      <link>https://stats.stackexchange.com/questions/655546/what-could-be-causing-test-loss-to-consistently-outperform-eval-loss</link>
      <description><![CDATA[我正在训练许多不同的模型，它们都是 XGBoost/LightGBM 类型的模型，因此它们需要一个评估集来进行提前停止。
尽管如此，除非我在进行训练-评估-测试拆分时做了一些粗心的事情，否则我预计停止时的评估损失将非常接近测试损失。一般的想法是，我会选择在停止时对其评估集表现最好的模型并将其放入生产中，如果我需要报告我期望模型在生产中的表现如何，则检查其测试损失。
虽然我们不希望测试和评估损失有很大差异，假设我在 MaxDepth 值的网格上对 xgboost 进行了网格搜索，并选择了以最佳评估损失退出的那个，在某种程度上，我选择了“走运”的组合对于此训练-评估组合，我们可能预计测试损失会略差。
但是，我发现我的测试损失明显好于获胜模型的评估损失（交叉熵的第二位小数点改进）。因此，我回过头来查看了我的所有模型（在 maxDepth 上对 XGB 模型进行网格搜索，在 NumLeaves 上对 lightgbm 模型进行网格搜索），在每种情况下，模型的测试损失都明显好于评估损失。
除了“你搞砸了你的训练-评估-测试分割”或“这是一个统计伪影，如果你重新采样，你会得到不同的结果”之外，有人能想到为什么会发生这种情况吗？
分割细节
我的数据集包含具有 ParticipantId 的“参与者”，可以将其视为 customerId。每个参与者可能有许多与之相关的行。虽然我们不会将参与者 ID 作为特征，但有足够多的连续特征，某些特征组合完全有可能让我们唯一地识别参与者，从而促进过度拟合。因此，我对参与者 ID 进行了哈希修改，然后分层，以便与参与者相关的所有行最终进入训练、评估或测试。
数据非常大（评估集是最小的，其约 1500 万行），因此我可以轻松证明这些差异不是由于抽样误差造成的。有可能（测试成本高），此过程中的方差比标准误差所暗示的要大得多（如果我进行了完全随机的训练-评估-测试分割，则可能归因于简单的抽样误差）。如果某些参与者有很多属于他们的行，并且他们的行为不同（目标基准率非常不同），那么我想他们最终进入哪个集合可能很重要。这是我现在最好的假设，但检查这一点会非常耗时且成本高昂，所以在我用 5 种不同的哈希函数运行整个过程 5 次之前，我想看看是否有人有其他想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/655546/what-could-be-causing-test-loss-to-consistently-outperform-eval-loss</guid>
      <pubDate>Wed, 09 Oct 2024 15:28:01 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归的最大似然估计方法中存在普遍的不一致性</title>
      <link>https://stats.stackexchange.com/questions/655545/widespread-inconsistency-in-maximum-likelihood-estimation-approach-to-logistic-r</link>
      <description><![CDATA[我发现，通过最大似然估计方法得出逻辑回归的损失函数的方式存在一些普遍的不一致之处。
在逻辑回归模型中，我们假设$\Pr[Y = +1| X = x] = \sigma(w^T x)$，其中$\sigma$是逻辑函数，$\sigma(w^T x) = \dfrac{\exp(w^T x)}{1 + \exp(w^T x)}$。类似地，$\Pr[Y = -1| X = x] = 1 - \sigma(w^T x).$
$X, Y$ 具有示例和标签的通常含义。
请注意，$w$ 是一个恒定权重参数（没有假设分布），我们希望对其进行调整。 查找 $w$ 的最常见方法是通过最大条件似然估计。
这就是文献中出现不一致的地方：一些作者假设 $w$ 是我们以此为条件的随机变量，其他作者假设 $w$ 是一个常数参数。
假设 $w$ 为常数的参考文献参数：
https://www.cs.cornell.edu/courses/cs4780/2015fa/web/lecturenotes/lecturenote06.html
请注意，作者使用冒号符号来分隔随机变量和常数参数，即 $p(y|x; w)$
https://web.stanford.edu/class/archive/cs/cs109/cs109.1178/lectureHandouts/220-logistic-regression.pdf
https://cseweb.ucsd.edu/~elkan/250B/logreg.pdf
https://web.engr.oregonstate.edu/~xfern/classes/cs534-18/Logistic-Regression-3-updated.pdf
假设 $w$ 为随机变量的参考文献：
https://www.cs.cmu.edu/~awm/15781/slides/LogRegress-9-29-05.pdf
请注意作者对 $w$ 的条件，即 $p(y|x, w)$
https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf
https://zstevenwu.com/courses/s20/csci5525/resources/slides/lecture05.pdf
https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote06.html
https://svivek.com/teaching/lectures/slides/logistic-regression/logistic-regression.pdf（作者使用两种符号可以互换使用）
本书：https://mml-book.github.io/
我的问题是：

哪种推导是正确的？$w$ 应该被视为常数参数还是随机变量？

只是为了消除一些困惑：

在最大似然估计中，我们总是最大化常数的似然，还是最大化随机变量的似然？

也许 2 的后续问题是，在最大后验估计中，我们总是最大化常数的似然，还是最大化随机变量的似然？]]></description>
      <guid>https://stats.stackexchange.com/questions/655545/widespread-inconsistency-in-maximum-likelihood-estimation-approach-to-logistic-r</guid>
      <pubDate>Wed, 09 Oct 2024 15:14:21 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 MLPE 的估计？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/655544/c%c3%b3mo-interpretar-los-estimados-de-un-mlpe</link>
      <description><![CDATA[我使用 MLPE 来评估环境变量（amt、ap、pcq、pwq、i）和形态变量（SVL）对歌曲变化（音符、音符和歌曲的持续时间、频率）的影响青蛙的公告我的问题是预测变量和响应变量是否暗示着一种关系（？），指的是估计的符号，以了解关系的走向。
例如，频率模型使用 SVL、amt 和 ap 作为预测变量。 SVL 估计值为正，据我了解，这表明如果 SVL 增加，频率也应该增加（急性频率）。但在相同数据的描述性统计中，其关系是负的，即SVL增大，则频率降低（严重频率）。
我很困惑，因为在建立模型时，预测变量 (SVL) 的符号表明了我的数据在频率方面的性质以外的东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/655544/c%c3%b3mo-interpretar-los-estimados-de-un-mlpe</guid>
      <pubDate>Wed, 09 Oct 2024 15:12:13 GMT</pubDate>
    </item>
    <item>
      <title>使用 sklearn 对 100% 数据集进行最终预测</title>
      <link>https://stats.stackexchange.com/questions/655543/make-a-final-prediction-with-100-of-dataset-with-sklearn</link>
      <description><![CDATA[我使用以下步骤验证模型以进行分类：

选择 75% 的数据集使用 train_test_split 进行训练
SequentialFeatureSelector 获取最佳特征
RandomForest 进行分类
AdaBoost 改进分类

我的分数不错，但现在我想使用 100% 的数据进行最终分类。
我有几种选择可以将 100% 的数据用于训练：

创建一个包含 100% 数据的新模型进行训练（只需用 100% 的数据重新拟合模型？）

为每个折叠创建一个包含 n 个模型的交叉预测，并将它们与 VotingClassifier 结合起来

直接将 cross_val_predict 与第一个模型一起使用，但具体如何操作？


您认为最合适、最公平的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655543/make-a-final-prediction-with-100-of-dataset-with-sklearn</guid>
      <pubDate>Wed, 09 Oct 2024 14:49:43 GMT</pubDate>
    </item>
    <item>
      <title>如何为我们的数据选择最合适的分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655542/how-to-choose-most-suitable-distribution-for-our-data</link>
      <description><![CDATA[我们想对我们的数据进行一些回归分析。我们的数据可能是依赖的，并且是时间序列（数据 - 狍子种群、年份和气候变化指数）。我们想看看这个指数对狍子种群的影响。我们还想使用 R。我们也不知道如何计算 lambda。]]></description>
      <guid>https://stats.stackexchange.com/questions/655542/how-to-choose-most-suitable-distribution-for-our-data</guid>
      <pubDate>Wed, 09 Oct 2024 14:36:45 GMT</pubDate>
    </item>
    <item>
      <title>R 中泊松回归的替代脚本[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655541/alternative-script-of-poisson-regression-in-r</link>
      <description><![CDATA[我正在 R 中编写另一个版本的泊松回归。在“身份”中案例，使用 glm 函数的代码
y = c(2,3,5,4) # 因变量
x = c(1,2,3,4) # 解释变量

# 标准编码 (link=&quot;identity&quot;)
res &lt;- glm(y ~ x, family=poisson(link=&quot;identity&quot;))
res$coef
#(Intercept) x 
# 1.2783528 0.8886589 

与下面的代码相同。
# 替代编码 (link=&quot;identity&quot;)
w = c(1,1,1,1) # 初始权重值 
for (i in 1:10) { 
r = lm(y ~ x, weights=w)
lambda = predict(r)
print(c(as.numeric(r$coef), -sum(y*log(lambda)-lambda)))
w = 1 / lambda
}
r$coef
#(Intercept) x 
# 1.2783467 0.8886613 

但是，我不确定“log”情况的替代编码。我怎样才能用下面的代码得到相同的结果？
# 标准情况 (link=&quot;log&quot;)
res &lt;- glm(y ~ x, family=poisson(link=&quot;log&quot;))
res$coef
# (截距) x 
# 0.6392647 0.2320399 

下面的代码不一样... .
w = c(1,1,1,1)
for (i in 1:10) { 
r = lm(log(y) ~ x, weights=w)
lambda = exp(predict(r))
print(c(as.numeric(r$coef), -sum(y*log(lambda)-lambda)))
w = 1 / lambda
}
r$coef
#(截距) x 
# 0.4684634 0.2938401 

我需要替代编码的原因是我面临标准情况的非收敛问题。因此，我只是尝试对其进行编码并寻找替代方法与标准方法相同的原因。此外，我也不确定如何向替代情况添加偏移项。]]></description>
      <guid>https://stats.stackexchange.com/questions/655541/alternative-script-of-poisson-regression-in-r</guid>
      <pubDate>Wed, 09 Oct 2024 14:36:38 GMT</pubDate>
    </item>
    <item>
      <title>哪项测试用于三组之间的标准化量化数据</title>
      <link>https://stats.stackexchange.com/questions/655540/which-test-for-normalised-quantification-data-between-three-groups</link>
      <description><![CDATA[我想比较三个组（疾病 1、疾病 2 和非疾病）之间的一个变量的数量（分配给念珠菌的读取次数）
当我使用不同的方法进行测试时，结果并不总是相同的。如果我使用钢或 Dunnett 测试（针对控制非疾病），我会得到不同的结果
如果我使用 Mann Whitney，我会得到一个显着的差异，并且通过所有成对比较，我再次得到不同的东西。
我真的不知道该遵循哪一个，有人可以帮忙吗？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/655540/which-test-for-normalised-quantification-data-between-three-groups</guid>
      <pubDate>Wed, 09 Oct 2024 14:26:32 GMT</pubDate>
    </item>
    </channel>
</rss>