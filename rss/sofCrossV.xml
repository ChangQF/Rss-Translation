<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 10 Feb 2024 18:15:46 GMT</lastBuildDate>
    <item>
      <title>调整神经网络参数的分步指南</title>
      <link>https://stats.stackexchange.com/questions/639015/step-by-step-guide-to-tuning-parameters-of-a-neural-network</link>
      <description><![CDATA[在调整神经网络时，有很多设计选项：

优化器
学习率
激活函数
隐藏层数量
每个隐藏层中的节点/神经元数量
正则化，例如提前停止
批量大小

我知道一般原则是从简单开始，逐渐增加复杂性。但是，我不知道该按什么顺序进行。
假设我从一个小型全连接网络开始，该网络具有单个隐藏层、SGD 优化器、批量大小为 32 和 ReLU 激活。我应该首先改变/探索什么？然后呢？所有的设计选择似乎都是相互影响的，所以我正在努力找出一种系统的方法。
有人可以提供分步指南以及所提议订单的理由吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639015/step-by-step-guide-to-tuning-parameters-of-a-neural-network</guid>
      <pubDate>Sat, 10 Feb 2024 18:09:32 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在 KDE 的一类分类中容纳多个名义数据集？</title>
      <link>https://stats.stackexchange.com/questions/639008/is-there-a-way-to-accommodate-multiple-nominal-datasets-in-one-class-classificat</link>
      <description><![CDATA[我有 50 组时间序列数据，这些数据是从制造过程的 50 次“良好”运行中收集的，我想利用所有这些标称数据集来训练我的模型。
根据我`的了解，在 KDE 中，仅使用单个标称数据集即可估计基础标称概率分布。有没有什么方法可以让我使用所有可用的标称数据而不仅仅是一次运行？]]></description>
      <guid>https://stats.stackexchange.com/questions/639008/is-there-a-way-to-accommodate-multiple-nominal-datasets-in-one-class-classificat</guid>
      <pubDate>Sat, 10 Feb 2024 16:39:43 GMT</pubDate>
    </item>
    <item>
      <title>非随机样本的统计检验？</title>
      <link>https://stats.stackexchange.com/questions/639007/statistical-testing-on-non-random-sample</link>
      <description><![CDATA[我正在观察性研究中使用非随机样本，但希望进行统计测试以显示某些趋势和过程。 统计测试假设随机抽样，这在我的实验中没有得到满足，所以我担心我的结果（或解释？）是无效的。我有什么选择？例如。我应该在解释时格外小心吗？我应该删除所有有关统计测试的文本吗？
以及上下文：
我正在学科 A 中进行科学计量/文献计量分析。学科 A 相对较新，但人们的共识是，它在过去 3 年左右的时间里凭借自身的优点发展成为一门学科。我根据其他科学计量研究和大量文献确定了一定数量的期刊，并认为这些期刊构成了学科 A 的大部分。这个列表可以说不是精确的科学，并且是主观的。我认为对识别期刊的问题进行了描述、解释和论证。
然后，我会获取这份期刊列表并分析趋势，例如一段时间内的出版量、贡献国家等，以便我可以深入了解期刊特征或学科（即所有样本期刊的总和）。当然，样本不是随机的，但它仍然提供了对该学科的见解。
假设我想检查一个县的经济活动（以人均 GPD 衡量），并且我拟合了一个线性回归模型，该模型表明该关系具有统计显着性。我该怎么办？我是否根本不包括统计测试，或者我只是明确表示我们所看到的内容是指选定的一组期刊（即整个群体）。
我担心是，基于我抽样的期刊与学科之间的差异（即更大），但我不确定如何解决想要提供统计测试支持的见解与过程中抽样缺陷之间的冲突。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/639007/statistical-testing-on-non-random-sample</guid>
      <pubDate>Sat, 10 Feb 2024 16:26:35 GMT</pubDate>
    </item>
    <item>
      <title>这些简单的期望会评估什么？</title>
      <link>https://stats.stackexchange.com/questions/639005/what-do-these-simple-expectations-evaluate-to</link>
      <description><![CDATA[我在一项复习作业中遇到了一个（看似简单的）问题。
假设我有常量 $a$ 和 $b$ 以及连续&lt; /em&gt; 随机变量 $X$.
我被要求评估：$\mathbb{E}[ b | X＞ a]$, $\mathbb{E}[ X | X＞ a]$ 及其所得产品。

这样说是否准确：$$\mathbb{E}[ b | X＞ a] = b \cdot \mathbb{P}(X &gt; a)$$
（或者考虑到 $b$ 是常数，它是否等于 $b$？恒定的答案对我来说更有意义，因为无论概率背景如何， $b$ 的值总是相同的，但我不确定）

更进一步，这样说是否准确：$$\mathbb{E}[ X | X＞ a] = \dfrac{\mathbb{E}[X]}{\mathbb{P}(X &gt; a)}$$


如果我给出的答案是正确的，他们的产品很简单，$$b \cdot \mathbb{E}[X]$$
但我觉得这太“简单”或太好了，令人难以置信。我在评估这些方程时是否遗漏了一些东西？]]></description>
      <guid>https://stats.stackexchange.com/questions/639005/what-do-these-simple-expectations-evaluate-to</guid>
      <pubDate>Sat, 10 Feb 2024 15:37:42 GMT</pubDate>
    </item>
    <item>
      <title>渐近标准误差与精确标准误差</title>
      <link>https://stats.stackexchange.com/questions/639003/asymptotic-standard-errors-vs-exact-standard-errors</link>
      <description><![CDATA[我对 OLS 估计器 $\widehat{\beta}$ 的标准误差的推导感到困惑。我已经看到两种不同的方法来导出标准误差：（i）从 $\widehat{\beta}$ 的精确协方差矩阵以回归矩阵 $X$ 和 (ii) $\widehat{\beta}$ 渐近分布的近似值。虽然从渐近分布的推导对我来说完全有意义，但从条件协方差矩阵的推导尚不清楚。我明白那个：
$$\text{Var}\left[\widehat{\beta} | X \right] = \left(X&#39;X \right)^{-1} \text{E}\left[uu&#39; | X \right] = \left(X&#39;X \right)^{-1} \text{E}\left[uu&#39; | X \right] \left(X&#39;X \right)^{-1},$$ 其中 $\text{E}\left[uu&#39; | X \right] \left(X&#39;X \right)^{-1},$$ X \right] = \text{Var}\left(u | X \right)$，即误差项的协方差矩阵，通常是 $ 的函数X$（异方差）。然后，我的教科书声称通过替换 $\text{E}\left[ 的对角线上的每个元素 $i$呃| X \right]$ 与残差平方 $\widehat{u}^2_i$ 我们获得了 $\widehat{\beta}$。然而，据我了解，我们获得的只是 $\widehat{\beta}$ conditional 在 $X$，仍然取决于 $X$，因此这没有说明无条件 strong&gt;估计器的协方差矩阵。
另一方面，当我们估计渐近标准误差时，我们能够近似 OLS 估计器的无条件协方差矩阵。据我了解，谈论“条件标准错误”是没有意义的，因为在实际应用中我们关心的是“无条件标准错误”。]]></description>
      <guid>https://stats.stackexchange.com/questions/639003/asymptotic-standard-errors-vs-exact-standard-errors</guid>
      <pubDate>Sat, 10 Feb 2024 15:25:58 GMT</pubDate>
    </item>
    <item>
      <title>错误传播。更简单的平均误差</title>
      <link>https://stats.stackexchange.com/questions/639002/error-propagation-simpler-average-errors</link>
      <description><![CDATA[我正在设计一个实验室实习来研究错误传播。假设我将测量 $x \pm\varepsilon_x$ 和 $y \pm \varepsilon_y$，其中$\varepsilon_x = \varepsilon_y = \varepsilon$ 为简单起见。这两个变量都与数学表达式相关：
$z=c \frac{x}{y}$，其中 $c$ 是一个常数。
我想确定错误 $\delta z$ 以获得 $z \pm \delta z$跨度&gt;，所以：
$\delta z = |\frac{\partial z}{\partial x}|\varepsilon+|\frac{\partial z}{\partial y}|\varepsilon = c\varepsilon ({ \frac{1}{y}+\frac{x}{y^2}})$。
测量三次 $x$ 和 $y$，最终得到三个值： $z_1 \pm \delta z_1$、$z_2 \pm \delta z_2$ 和 $z_3 \pm \delta z_3$。我想获得平均值。下面的计算是否正确？
$\bar{z} \pm \delta z = \frac{z_1 + z_2 + z_3}{3}\pm \frac{\delta z_1 +\delta z_2 + \delta z_3}{3}$
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/639002/error-propagation-simpler-average-errors</guid>
      <pubDate>Sat, 10 Feb 2024 15:02:02 GMT</pubDate>
    </item>
    <item>
      <title>当测量误差本来就很高时进行比较测试？</title>
      <link>https://stats.stackexchange.com/questions/639000/comparison-test-when-measurement-error-is-inherently-high</link>
      <description><![CDATA[相关问题。
注意：我认为这个问题与其他问题足够不同，值得单独询问。
我的问题：
我需要确定一台设备的性能是否等于或不差于另一台设备的性能。我计划进行配对 T 测试，直接在实验室测试中比较这两个设备。我做了一个初步实验，设置类似于交叉规格 R&amp;R 研究，以评估我的实验室测试中的误差来源。我发现测量间方差远大于我想要检测的组间最小差异。另一方面，我的设备间差异非常低 - 比我想要检测的差异小得多。
我有充分的理由怀疑测量误差是被测量事物的本质所固有的，并且该误差无法进一步减小。 （测试涉及将一袋粘性液体拉过狭窄处；液体在袋内移动的方式以及袋子折叠的方式存在固有的可变性，我无法控制，但会影响袋子移动的阻力通过狭窄）。
当我使用实验中的标准差对配对 T 检验进行功效/样本量计算时，我发现需要 约 25,000 个观察值才能有 90% 的功效来检测组之间的合理差异。即使我将功率降低到 80%，我仍然需要约 10,000 次观察，而且我无法测试那么多设备（这是多年生产的价值）。实际上，测试超过 15 或 20 个单独的设备是令人望而却步的，但在同一设备上重复测量既便宜又容易，而且数据并不表明测量之间的依赖性（即回归分析的残差没有显示任何迹象）时间依赖性）。尽管如此，10,000 个重复样本仍然需要很长时间，而且不切实际。我想说，总共 200 个观察值大约是我实际上可以做的最大值。
我的问题：
在样本间方差较低但测量方差本质上较高的情况下，可以考虑哪些其他类型的比较测试？或者我可以采用哪些技术来帮助解决此测量错误（即转换、附加测试、研究设计等）
注意：
从我提出的问题类型中可以明显看出，但我是一名工程师，而不是统计学家。当然愿意花时间去理解和学习新概念，但请尽量让外行人可以理解的答案:)]]></description>
      <guid>https://stats.stackexchange.com/questions/639000/comparison-test-when-measurement-error-is-inherently-high</guid>
      <pubDate>Sat, 10 Feb 2024 14:03:21 GMT</pubDate>
    </item>
    <item>
      <title>当对连续值应用 QWK 时，SPSS 会计算什么？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638998/what-does-spss-calculate-when-applying-qwk-for-continuous-values</link>
      <description><![CDATA[即使您插入的变量是连续变量而不是有序变量，SPSS 也允许您直接计算 QWK。我很好奇SPSS内部是如何实现的。我想知道是否有一种方法可以在不分类的情况下计算QWK。
在我的实验中，我尝试使用从 0 到 10 的变量，并尝试创建变量的不同分区（3 路、5 路、10 路、等距值），并根据分区数越大，QWK 值与 SPSS 使用连续变量计算的值越趋近。
我的具体问题是，考虑到变量分类的结果与分 3 部分或分 10 部分相比变化很大，这里最好的近似值是什么？ （我提到SPSS的做法是因为它似乎是通过创建大量分区或直接使用连续变量进行一些计算来实现的）。]]></description>
      <guid>https://stats.stackexchange.com/questions/638998/what-does-spss-calculate-when-applying-qwk-for-continuous-values</guid>
      <pubDate>Sat, 10 Feb 2024 12:14:19 GMT</pubDate>
    </item>
    <item>
      <title>计算$E[(\sum X_i)^4]$</title>
      <link>https://stats.stackexchange.com/questions/638992/calculating-e-sum-x-i4</link>
      <description><![CDATA[尝试找出以下内容中的错误所在。我的目标是使用 $E[(\bar X_n)^4 计算 var$(\bar X_n^2)$ ]=\frac{1}{n^4}E[(\sum X_i)^4]$ 鉴于 $X_1,...X_n$ 与 $EX_1=\mu, E[(X_1-\mu)^k]=\alpha_k$ 独立同分布。
$$E\left[\left(\sum X_i\right)^4\right]=E\left[\sum_i X_i\sum_jX_j\sum_kX_k\sum_lX_l\right]=\sum_ {i,j,k,l}E(X_iX_jX_kX_l)$$
现在，我根据索引 $i,j,k,l$ 将其分为 5 类。

全部不同。 $${n\选择 4}E^4(X_1)=\frac{n(n-1)(n-2)(n-3)}{24}\mu ^4$$
一对。 $${3\选择 1}{n\选择 3}E(X_1^2)E^2(X_1)=\frac{n(n-1)(n-2) )}{2}\mu^2\left[E(X_1-\mu)^2+\mu^2+2\mu E(X_1-\mu)\right]\\=\frac{n(n- 1)(n-2)}{2}\mu^2\left[\alpha_2+\mu^2\right]\\=\frac{n(n-1)(n-2)}{2}\mu ^2\alpha_2+\frac{n(n-1)(n-2)}{2}\mu^4$$
两对。 $${n \选择 2}E^2(X_1^2)=\frac{n(n-1)}{2}(\alpha_2+\mu^2)^2 \\=\frac{n(n-1)}{2}\alpha_2^2+n(n-1)\mu^2\alpha_2+\frac{n(n-1)}{2}\mu^4 $$
三个一样。 $${3\选择 1}{n\选择 2}E(X_1)E(X_1^3)=\frac{3n(n-1)}{2}\mu [E(X_1-\mu)^3+\mu^3+3\mu E(X_1-\mu)^2]\\=\frac{3n(n-1)}{2}\mu\alpha_3+\压裂{9n(n-1)}{2}\mu^2\alpha_2+\frac{3n(n-1)}{2}\mu^4$$
都是一类。 $$nE(X_1^4)=n[E(X_i-\mu)^4+\mu^4+4\mu E(X_i-\mu)^3+6 \mu^2 E(X_i-\mu)^2]\\=n\alpha_4+4n\mu\alpha_3+6n\mu^2\alpha_2+n\mu^4$$

我知道最后一个更简单的形式，但事情并没有那么好。如有错误请指出。
编辑。更多相关背景信息。我按照此处提到的方法获取$$\text{var}(\bar X_n^2)=\frac{4\mu^2\alpha_2}{n}+\frac{4\mu\alpha_3}{n^2}+\frac{\ alpha_4}{n^3}+(\frac{2}{n^2}-\frac{3}{n^3})\alpha_2^2$$ 与所需的表达式 $$\text{var}(\bar X_n^2)=\frac{4\mu^2\alpha_2}{n}+\frac{4\mu\alpha_3}{n^2 }+\frac{\alpha_4}{n^3}$$
（参考 The Jackknife &amp; Bootstap，Jun Shao）。这种强力表达式在简化后也有所不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/638992/calculating-e-sum-x-i4</guid>
      <pubDate>Sat, 10 Feb 2024 07:58:27 GMT</pubDate>
    </item>
    <item>
      <title>是否有必要从随机森林分类模型中删除冗余变量？</title>
      <link>https://stats.stackexchange.com/questions/638965/is-it-necessary-to-remove-redundant-variables-from-a-random-forest-classificatio</link>
      <description><![CDATA[我正在以下变量中运行随机森林模型（附后）：

是否有必要使用随机森林分类器来删除高度相关的变量，还是应该保留模型不变？如果我要删除“冗余变量”，最好的方法是什么？
我目前的工作流程是：
计算皮尔逊相关系数

评估变量重要性图表，系统地逐一删除重要变量的相关变量，然后运行模型并观察性能。
一旦 OA、CA、UA 减少，我将停止删除变量。
我正在做的另一种方法是逐个删除最不重要的变量并运行模型，但皮尔逊相关系数可能是一种更可靠的方法。

谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/638965/is-it-necessary-to-remove-redundant-variables-from-a-random-forest-classificatio</guid>
      <pubDate>Fri, 09 Feb 2024 18:52:44 GMT</pubDate>
    </item>
    <item>
      <title>在不会或不能重复的研究中计算置信区间的理由是什么？</title>
      <link>https://stats.stackexchange.com/questions/638934/what-is-the-rationale-for-computing-a-confidence-interval-in-a-study-that-wont</link>
      <description><![CDATA[据我了解，当我们计算置信区间（例如 $95$% CI）时，我们对程序有信心，而不是对当前的结果有信心。我们拥有的数据（作为 $95$% CI 意味着为许多其他计算的置信区间的 $95$%假设样本将包含总体中的真实值）。
因此仅凭我们收集的样本，无法知道我们看到的当前区间是否包含真实值，即使区间非常小。
所以我想知道：在一项不会或不能精确重复的研究中计算置信区间是否有（科学）原理？或者说在这种情况下计算 CI 是没有用的吗？我也非常感谢有关此特定主题的任何参考资料或论文。]]></description>
      <guid>https://stats.stackexchange.com/questions/638934/what-is-the-rationale-for-computing-a-confidence-interval-in-a-study-that-wont</guid>
      <pubDate>Fri, 09 Feb 2024 12:03:39 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯非线性回归中的双峰后验</title>
      <link>https://stats.stackexchange.com/questions/638912/bimodal-posteriors-in-bayesian-non-linear-regression</link>
      <description><![CDATA[我将在序言中感谢您阅读本文，并且任何评论者都应该随意批评您认为天真或无知的建模规范或工作流程的任何方面。
我正在模拟这个双 S 形曲线过程中的两个组：
$$ y = \frac{y_{\text{mid}}}{1 + e^{-(a \cdot \text{time} + b)}} + \frac{y_{\text{max}}}{1 + e^{-(c \cdot \text{时间} + d)}}, \quad 0 \leq y \leq 100, \quad \text{时间} \in [0, 300]
$$
在brms中使用以下代码：
sw_dbl_log &lt;- 函数（a、b、c、d、时间）{
  ((50)/(1+exp(-a*时间 + b)))+((50)/(1+exp(-c*时间 + d)))
}

神经网络 = 300
原始 &lt;- tibble(n = 1:(nn*2),
              组=rep(c(“对照”，“实验”)，每个=nn)，
              a = c(rnorm(nn, 0.1, 0.01),
                    rnorm(nn, 0.1, 0.01)),
              b = c(rnorm(nn, 5, 0.01),
                    rnorm(nn, 5, 0.01)),
              c = c(rnorm(nn, 0.1, 0.01),
                    rnorm(nn, 0.1, 0.002)),
              d = c(rnorm(nn, 5, 0.01),
                    rnorm(nn, 25, 0.01))
) %&gt;%
  tidyr::expand(嵌套(n,组,a,b,c,d),
                时间 = seq(0, 300, by = 10)) %&gt;%
  突变（y = sw_dbl_log（a，b，c，d，时间））

正如预期的那样，这会为每个组的参数 (a:d) 生成高斯分布，而对照组的时间序列类似于具有一个生长阶段的单个 sigmoid。正如预期的那样，实验组的时间序列有两个增长阶段。我利用这个规范是因为每个参数都给出了清晰可解释的输出，即 a 和 c 代表增长率，b 代表每个生长阶段的拐点时间点。

我的适配过程如下：
公式 &lt;- bf(y ~ (50/(1+exp(-a*Time + b))) + (50/(1+exp( -c*时间 + d))),
              a + b + c + d ~ 0 + 组，
              set_rescor(FALSE),
              nl = 真）

先验 1 &lt;- c(
  先验（正常（0.1，0.1），nlpar =“a”，lb = 0），
  先验（正常（5, 2），nlpar =“b”，lb = 0，ub = 10），
  先验（正常（0.1，0.1），nlpar =“c”，lb = 0），
  先验(正常(25, 5), nlpar = “d”, coef = “组实验”),
  先验（正常（5, 2），nlpar =“d”，coef =“GroupControl”）
）

拟合 &lt;-brm(公式,
           数据=原始数据，
           先验=先验1，
           控制=列表（adapt_delta = 0.95，max_treedepth = 15），
           迭代= 10000，
           预热= 5000，
           核心 = 3,
           链 = 3)

我在上面的代码中省略了之前的拟合和预测检查，但目视检查看起来不错。
我目前遇到的这个问题是模型拟合很差，即 Rhat 和 ESS 数字太低，这主要是由于任一组（有时是 Control）参数后验分布的双峰性有时是实验性的，这会导致链不收敛。因此，对于某些拟合，按组（例如“b_a_GroupExperimental”）的 a、b、c、d 的任何或所有后验分布将是双峰的。
我似乎无法定义为什么模型拟合不佳并导致这种双峰性。我的第一个猜测是先验导致了问题，但是，根据我天真的理解，先验是围绕原始模拟分布非常紧密地指定的，所以我不明白为什么它们可能会导致问题。我必须承认，这个结论可能会暴露我对这个主题的无知，这导致我无法解决适合问题。
我应该更改先验、模型、规定初始值还是只是运行更多迭代？任何帮助将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/638912/bimodal-posteriors-in-bayesian-non-linear-regression</guid>
      <pubDate>Fri, 09 Feb 2024 03:36:53 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归和 Logit 离散选择模型之间有什么根本区别？</title>
      <link>https://stats.stackexchange.com/questions/638667/what-is-fundamentally-different-between-a-logistic-regression-and-a-logit-discre</link>
      <description><![CDATA[我试图理解两者之间的区别。我知道离散选择建模中有一个背景随机效用理论，但在我读到的内容中，我无法查明 logit 选择模型（有时称为条件 logit 选择模型，以区别于嵌套选择）之间的区别模型）。
也许这与似然方程有关，但我希望获得更多技术说明。]]></description>
      <guid>https://stats.stackexchange.com/questions/638667/what-is-fundamentally-different-between-a-logistic-regression-and-a-logit-discre</guid>
      <pubDate>Tue, 06 Feb 2024 13:14:26 GMT</pubDate>
    </item>
    <item>
      <title>在 GAMM 中保持“低”基础维度的含义</title>
      <link>https://stats.stackexchange.com/questions/638343/implications-of-keeping-a-low-basis-dimension-in-gamm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/638343/implications-of-keeping-a-low-basis-dimension-in-gamm</guid>
      <pubDate>Thu, 01 Feb 2024 19:31:15 GMT</pubDate>
    </item>
    <item>
      <title>伯努利试验的成功具有不同的概率，但概率只有在成功后才会改变</title>
      <link>https://stats.stackexchange.com/questions/638175/success-of-bernoulli-trials-with-different-probabilities-but-a-probability-is-o</link>
      <description><![CDATA[我想计算不同概率的伯努利试验，但概率只有在成功后才会改变。
比如这里，所有概率p在每个状态s下都是不同的，如下图所示； s: (0, 1, ..., m)。
该图是伯努利试验的示意图。

审判将从状态 (0) 开始。
那么，$p_0$ 就是一个问题。状态 (0) 成功。
如果我们成功，那么 $p_1$ 将用于下一次试验。
这里，随机变量 $X_k$ 表示 k 次试验的成功次数。
如何以更简单的方式导出$Pr[X_k=i]$？
我指的是泊松二项分布，但似乎有点不同。
i 是 k 次试验的成功结果。
目前，我得出如下。
$Pr[X_k=0] = p_0^0 \times (1-p_0)^{(k-0)}$。
也就是说，成功次数为零，因此每次 $k$ 试验都会失败，即在所有 $k$ 试验。
$Pr[X_k=1] = p_0^1 \times (\text{所有失败组合的总和，$1-p_0$, $1-p_1$ k-1 次试验}) $。
此处，成功次数为 1，因此它在状态 (0) 成功一次，并在 $k-1$ 次试验中失败。
实际上，我的目标是导出
$Pr[X_k，这是未能达到状态（m）的概率。

上图来自论文（M. Kleinbort、K. Solovey、Z. Littlefield、K. E. Bekris 和 D. Halperin，“RRT for Geometric and Kinodynamic Planning With Forward Propagation 的概率完整性”&quot;) 但我自己以不同的概率修改了它。
]]></description>
      <guid>https://stats.stackexchange.com/questions/638175/success-of-bernoulli-trials-with-different-probabilities-but-a-probability-is-o</guid>
      <pubDate>Wed, 31 Jan 2024 08:52:15 GMT</pubDate>
    </item>
    </channel>
</rss>