<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 03 Jun 2024 06:20:59 GMT</lastBuildDate>
    <item>
      <title>基于伯努利 (p) 样本的无偏估计量</title>
      <link>https://stats.stackexchange.com/questions/648518/unbiased-estimator-based-on-a-sample-from-bernoullip</link>
      <description><![CDATA[设 X1、X2、X3、...... Xn 为服从 Ber(p) 的总体中的随机样本。给出 (1+p)^n 的无偏估计量。
提示：
(1+p)^n = C0 + C1.p + C2.p^2 + C3.p^3 ........ Cn.p^n，
且 p 的估计量为均值（Xi 的估计量）。]]></description>
      <guid>https://stats.stackexchange.com/questions/648518/unbiased-estimator-based-on-a-sample-from-bernoullip</guid>
      <pubDate>Mon, 03 Jun 2024 05:52:17 GMT</pubDate>
    </item>
    <item>
      <title>根据训练数据，惩罚 Ridge/Lasso 回归中的斜率会产生不利影响吗？</title>
      <link>https://stats.stackexchange.com/questions/648515/does-penalizing-the-slope-in-ridge-lasso-regression-has-adverse-effect-based-on</link>
      <description><![CDATA[我刚刚开始学习岭回归和套索回归。据我所知，这些回归与线性回归类似，但我们用系数$\lambda$惩罚较高的斜率以减少过度拟合。对于双变量情况，我们希望通过岭回归最小化$\sum_{i=1}^n(y_i-\hat y)^2+\lambda(\text{slope of the line})^2$。
但让我们假设在下图中，红色圆圈是我的训练数据，蓝色圆圈是我的测试数据。假设在惩罚斜率后，最佳拟合线是绿线，这样线性模型的性能就会变差。（另一方面，如果蓝色圆圈是训练数据，则拟合线会减少过度拟合问题）。我想知道在这种情况下 Ridge（或 Lasso 回归）如何减少过度拟合，因为降低斜率会导致直线拟合不良。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648515/does-penalizing-the-slope-in-ridge-lasso-regression-has-adverse-effect-based-on</guid>
      <pubDate>Mon, 03 Jun 2024 04:38:56 GMT</pubDate>
    </item>
    <item>
      <title>负二项模型中的有偏 MLE</title>
      <link>https://stats.stackexchange.com/questions/648514/biased-mles-in-negative-binomial-models</link>
      <description><![CDATA[我发现负二项模型的最大似然参数是有偏的。下面提供了一个示例代码。这是正常的吗？有没有办法获得无偏估计？
&gt; set.seed(3)
&gt; z &lt;- 2
&gt; a &lt;- 100
&gt; b &lt;- 100
&gt; theta &lt;- 15
&gt; 
&gt; negloglik &lt;- function(p,x,y){
+ if(any(p&lt;=0)) return(NA)
+ a &lt;- p[1]
+ b &lt;- p[2]
+ z &lt;- p[3]
+ theta &lt;- p[4]
+ -sum(dnbinom(y,mu=(a*x^z)/(b+x^z),size=theta,log=T))
+ }
&gt; 
&gt; nsim &lt;- 1000
&gt; ppp &lt;- matrix(NA,nsim,4)
&gt; for(i in 1:nsim){
+ x &lt;- round(rep(seq(3,30,by=5),each=5))
+ y &lt;- rnbinom(length(x),mu=((a*x^z)/(b+x^z)),size=theta)
+ ppp[i,] &lt;- optim(c(a,b,z,theta),negloglik,x=x,y=y)$par
+ }
&gt; 
&gt; # MLE（预期）
&gt; apply(ppp,2,mean)
[1] 105.135854 123.325672 2.054681 19.150245
&gt; 
&gt; # 偏差
&gt; 应用（ppp，2，平均值）-c（a，b，z，theta）
[1] 5.13585361 23.32567187 0.05468069 4.15024470
]]></description>
      <guid>https://stats.stackexchange.com/questions/648514/biased-mles-in-negative-binomial-models</guid>
      <pubDate>Mon, 03 Jun 2024 04:32:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么 PySpark `BinaryClasssificationEvaluator` 指标 `areaUnderROC` 在同一数据集上的多次评估中返回的结果略有不同？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648513/why-pyspark-binaryclasssificationevaluator-metric-areaunderroc-returns-sligh</link>
      <description><![CDATA[我在 Pyspark 中使用 BinaryClasssificationEvaluator 来计算 AUC，但是我发现对同一数据集进行多次评估后返回的 auc 不同（在相同的开发环境下，只需在 jupyter 中多次单击此单元格即可）。这意味着，我无法保证结果的重复性。
由于隐私问题，我无法发布数据集 data_sample_full_w_target_subexample_pd 的内容，但它的形状是 234225，其中“bad”为 0/1，“probability”为是 [0, 1] 内的双精度数。
以下是代码
从 pyspark.ml.evaluation 导入 BinaryClassificationEvaluator
从 pyspark.ml.classification 导入 RandomForestClassifier
从 pyspark.ml.feature 导入 VectorAssembler

导入 pyspark.sql.functions 作为 F
导入 pyspark.sql.types 作为 T

# 假设我有一个 pandas 数据框 `data_sample_full_w_target_subexample_pd`，其中列“bad”是 y_true 和“prob”是 y_pred 概率

# 对其进行排序以避免排名不确定性
data_sample_full_w_target_subexample_pd_sorted = data_sample_full_w_target_subexample_pd[[&quot;bad&quot;, &quot;prob&quot;]].sort_values(by=[&quot;prob&quot;, &quot;bad&quot;], accending=[False, True])

# pyspark 计算 auc
prediction = spark.createDataFrame(data_sample_full_w_target_subexample_pd_sorted)
prediction = prediction.withColumnRenamed(&quot;bad&quot;,&quot;label&quot;)

evaluator = BinaryClassificationEvaluator(
labelCol=&quot;label&quot;, 
metricName=&quot;areaUnderROC&quot;)
evaluator.setRawPredictionCol(&quot;prob&quot;)
areaUnderROC = evaluator.evaluate(prediction)

# pandas 计算 auc
# RF_pred = prediction.select(&#39;label&#39;, &#39;prob&#39;).toPandas()
RF_pred = prediction.toPandas() 
probRF=[]
for i in range(prediction.count()):
probRF.append(RF_pred[&#39;prob&#39;][i]) # 它只取标签 1 的概率 

auc = roc_auc_score(RF_pred[&#39;label&#39;], probRF) # 这将始终返回 0.9683804033270174

# auc 和 areaUnderROC 应该相同！
print(areaUnderROC)
print(auc)


但是，无论我运行多少次，pandas 版本都可以产生相同的 auc 结果。
我相信 BinaryClassificationEvaluator 中一定发生了什么，但从其文档来看，其参数中没有提到随机性。
有什么见解吗？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648513/why-pyspark-binaryclasssificationevaluator-metric-areaunderroc-returns-sligh</guid>
      <pubDate>Mon, 03 Jun 2024 04:31:18 GMT</pubDate>
    </item>
    <item>
      <title>拟合超几何分布需要非整数参数吗？</title>
      <link>https://stats.stackexchange.com/questions/648512/fitting-hypergeometric-distribution-requires-non-integer-arguments</link>
      <description><![CDATA[我有一个观测向量（长度为 s），x 是类“0”，s-x 是类“1”，并且来自大小为 N 的总体。因此，它们遵循超几何分布：
$$H(x| p,s,N) = \frac{ {pN \choose x} {N-pN \choose s-x} }{ {N \choose s} }$$
我对这个向量进行子采样（使用 $j$ 刀切间隔）以获得比例直方图（$O$），其中箱体 $x \in [0, js]$ 与频率相关。人口规模$N$和比例$p$未知，我需要根据观察结果推断它们。
为了解决这个问题，我想使用最小二乘法拟合超几何分布直方图（$O$）。我计划使用 Newton-Raphson (NR) 方法来查找 $p$ 和 $N$ 的值，以使 $L = \sum_x (O-H)^2$ 最小化。
我的理由是，我需要使用具有非整数参数的二项式系数，使用有限差分以数值方式计算 $L$ 的导数，但我发现这会导致 $H$ 出现负值。
请给我一些反馈。这种方法是否正确，或者我应该如何推断 $N$ 和 $p$ 的值？我正在研究别人的工作，所以我无法选择彻底改变方法（即我不能使用贝叶斯推理）。]]></description>
      <guid>https://stats.stackexchange.com/questions/648512/fitting-hypergeometric-distribution-requires-non-integer-arguments</guid>
      <pubDate>Mon, 03 Jun 2024 03:01:20 GMT</pubDate>
    </item>
    <item>
      <title>Scipy 的高斯 KDE 积分令人困惑[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648510/scipys-gaussian-kde-integration-is-confusing</link>
      <description><![CDATA[这是一个简单的问题，但我需要澄清。
在Scipy Docs中，用于积分多元高斯 KDE 的函数有一个可选参数，表示最大点数，默认值为 None。
那么...默认情况下，它实际上使用多少个点进行积分？这是否取决于拟合数据的大小和形状，即这是否以某种方式作为准确度和运行时间之间的权衡而进行了优化？
当您声明最大点数时，这是每个维度的还是总数的，即如果它是二维分布，10,000 个点是否意味着它在 100x100 或 10,000x10,000 网格上积分？]]></description>
      <guid>https://stats.stackexchange.com/questions/648510/scipys-gaussian-kde-integration-is-confusing</guid>
      <pubDate>Mon, 03 Jun 2024 01:42:19 GMT</pubDate>
    </item>
    <item>
      <title>演员-评论家和广义策略迭代（GPI）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648508/actor-critic-generalized-policy-iteration-gpi</link>
      <description><![CDATA[它们是同一个概念吗？或者，actor-critic 是 GPI 的一个“特殊情况”（即，我们仅将策略梯度类型的方法称为“actor-critic”）？这两个概念似乎都有“评估/评论家”和“改进策略/actor”部分。]]></description>
      <guid>https://stats.stackexchange.com/questions/648508/actor-critic-generalized-policy-iteration-gpi</guid>
      <pubDate>Mon, 03 Jun 2024 01:25:12 GMT</pubDate>
    </item>
    <item>
      <title>如何用 R 语言对评级数据进行（线性）混合效应模型的拟合和诊断</title>
      <link>https://stats.stackexchange.com/questions/648507/how-to-fit-and-perform-diagnostics-for-linear-mixed-effects-models-on-rating-d</link>
      <description><![CDATA[我进行了一项实验，其中 143 名测试对象（访谈）对 20 个刺激集（刺激）进行评分，评分范围从 0 到 100。从 80 个刺激集（分为两个类别，轴心国和同盟国，每个类别抽取 10 个）中随机抽取每个参与者的刺激集。首先在短时间曝光（Gist）条件下呈现并评分该组刺激，然后在长时间曝光（LE）条件下获得第二组评分。综上所述，我们让不同的受试者对不同的刺激集进行评分，每个受试者对每个刺激进行两次评分。
两种观看条件的评分分别记录在两个单独的列中，RatingGist 和 RatingLE，第三列为 RatingDELTA，其中添加了从 -100 到 +100 的刻度，表示受试者对同一刺激的 LE 和 Gist 评分之间的差异。
除了评分之外，我的数据集还包含在参与者级别（Sex、PolNum）和刺激级别（Semiotics）记录的其他变量，其中 PolNum 是参与者的政治倾向，以连续的左右刻度（-3 到 +3）记录，而符号学（虚拟编码）表示政治符号在给定的刺激中是否可见。
我的目标是调查政治倾向、刺激类别和图像内容是否可用于预测长时间曝光下的收视率和/或观看条件之间的收视率变化 (RatingDELTA)。
我的想法是拟合三个独立的模型：

RatingLE 作为因变量，RatingGist 作为基线

RatingDELTA 作为因变量，RatingGist 作为基线

RatingGist 作为因变量，假设在短时间曝光下，不会从刺激中提取政治信息，并且可能根据语义内容改变图像感知的认知过程不会启动。


现在，在拟合 LMM 方面，我首先定义我的随机效应结构并拟合一个没有固定效应预测因子的零模型：
delta_0 &lt;- lmer(RatingDELTA ~ 1 + (1 |访谈) + (1 | 刺激)

LE_0 &lt;- lmer(RatingLE ~ 1 + (1 | 访谈) + (1 | 刺激)

Gist_0 &lt;- lmer(RatingGist ~ 1 + (1 | 访谈) + (1 | 刺激)

然后我继续逐步添加固定效应，一次添加一个预测因子，在迭代之间比较拟合指数 (AIC、对数似然和伪$R^2$)，直到我得到现在的完整模型：
delta_6 &lt;- lmer(RatingDELTA ~ RatingGist + PolNum*Publisher + Sex + Semiotics*PolNum + (1 + RatingGist + Publisher | 访谈) + (1 | 刺激), data = dfx, REML = FALSE)

LE_6 &lt;- lmer(RatingLE ~ RatingGist + PolNum*Publisher + Sex + Semiotics*PolNum + (1 + RatingGist + Publisher | Interview) + (1 | Stimulus), data = dfx, REML = FALSE)

（我在这里省略了 Gist 模型，因为之前使用的任何预测因子都没有改善该模型 - 但是，对于具有转换后的 DV（重新缩放为 0.0001–0.9999）和 beta-link 函数的 GLMM，它们确实改善了模型）。
每个预测因子和交互项的包含都显著改善了 LE 和 Delta 模型的拟合度，但我很难确定模型是否首先正确指定。我一直在使用 DHARMa 进行诊断，但我根本没有统计知识，也没有充分评估它们的经验（delta_6 模型的残差诊断图如下所示）。

首先，我不确定 LMM 是否可以直接拟合评级本身，因为它们的尺度是双重边界的，而且残差图中确实似乎存在轻微的模式（如下所示）。

我曾使用 glmmTMB 尝试过 Gist 和 LE 模型的 beta 混合回归和零膨胀 beta 混合回归模型，但我不知道如何正确设置 DHARMa 来运行诊断以及要查找什么。
如果有人能为我的 LMM 推荐一种全面的诊断策略，以及如何在 LMM 或具有特定链接函数的 GLMM 之间做出选择，我将不胜感激。如果需要，我也可以提供原始数据，尽管超过 2000 个观测值，数据量还是有点大。]]></description>
      <guid>https://stats.stackexchange.com/questions/648507/how-to-fit-and-perform-diagnostics-for-linear-mixed-effects-models-on-rating-d</guid>
      <pubDate>Mon, 03 Jun 2024 01:13:39 GMT</pubDate>
    </item>
    <item>
      <title>比例变量与分类变量之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/648502/correlation-between-proportion-variable-and-categorical-variable</link>
      <description><![CDATA[我有兴趣测试流感活动与不同时期（不同年代）之间的相关性。变量流感活动是两个变量的组合：ILI 比例（ILI 病例/总人口）$\times$实验室阳性率（阳性样本/总样本）。因此，它是两个比例的乘积。变量时期是分类的（时期 A、时期 B 和时期 C）。此外，流感活动不是正态分布的，即使其因子在本质上是成比例的，但它们加起来也不等于一。考虑到这些数据的性质，我想知道哪种相关性测试最合适：Spearman rho？Kendall tau？拟泊松回归？OLS 回归？
我是统计学的初学者，因此很感谢您的意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/648502/correlation-between-proportion-variable-and-categorical-variable</guid>
      <pubDate>Sun, 02 Jun 2024 21:38:14 GMT</pubDate>
    </item>
    <item>
      <title>具有异方差的双向方差分析</title>
      <link>https://stats.stackexchange.com/questions/648500/two-way-anova-with-heteroscedasticity</link>
      <description><![CDATA[我尝试运行双向方差分析，但未满足同方差条件。我的分析不平衡，样本中有超过 3000 个观测值。即使类别的方差不相等，也可以继续吗？下面是不同可能组合的箱线图和每个类别的平均值表。这是我运行的代码。有没有办法运行考虑异方差的测试？
reg&lt;-aov(depression~classification+diversityLessThan,data=dataset)
summary(reg)

]]></description>
      <guid>https://stats.stackexchange.com/questions/648500/two-way-anova-with-heteroscedasticity</guid>
      <pubDate>Sun, 02 Jun 2024 20:58:07 GMT</pubDate>
    </item>
    <item>
      <title>安德森·达林假设检验是如何建立的？</title>
      <link>https://stats.stackexchange.com/questions/648498/how-anderson-darling-hypothesis-test-is-set-up</link>
      <description><![CDATA[我想知道 Anderson Darling 检验背后的假设检验是什么。我知道 H0 表示数据服从分布，H1 表示数据不服从分布。但它在数学上如何写？我猜它使用 A2 值，例如 H0：$A^2 = 0$ 和 H1：$A^2 \gtrless 0$。这是正确的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648498/how-anderson-darling-hypothesis-test-is-set-up</guid>
      <pubDate>Sun, 02 Jun 2024 20:41:07 GMT</pubDate>
    </item>
    <item>
      <title>诊断生存曲线图中的意外模式</title>
      <link>https://stats.stackexchange.com/questions/648490/diagnosing-an-unexpected-pattern-in-a-survival-curve-plot</link>
      <description><![CDATA[我正在 R 中进行生存分析（使用 Cox 比例风险回归）。我的总体样本死亡率约为 10%，但从我的分析得出的 Kaplan-Meier 生存曲线似乎显示生存率下降了约 40-50%，并在 4 年左右急剧下降。这并不能反映实际数据集中死亡时间的模式，但我不确定是什么导致了这种差异……有人知道吗？

# 定义绘图的层
strata &lt;- expand.grid(
pression_level = levels(complete_cases_all$depression_level),
sex = levels(complete_cases_all$sex)
)
rownames(strata) &lt;- letters[1:nrow(strata)]

# 定义平均参与者
average_participant &lt;- expand.grid(
pression_level = levels(complete_cases_all$depression_level),
sex = levels(complete_cases_all$sex),
calendar_year = median(complete_cases_all$calendar_year),
age = median(complete_cases_all$age),
education_level = median(complete_cases_all$education_level),
employment = &quot;有竞争力的就业&quot;,
marital_status = &quot;单身&quot;,
rehab_payor_primary_type = &quot;非医疗补助&quot;,
func_score = median(complete_cases_all$func_score),
mental_health_tx_hx = &quot;否认有任何心理健康治疗史&quot;,
psych_hosp_hx = &quot;否认有任何精神病住院史&quot;,
problematic_substance_use = &quot;否&quot;,
suicide_attempt_hx = &quot;否认有任何自杀企图史&quot;
)
rownames(average_participant) &lt;- letters[1:nrow(average_participant)]

# 拟合生存模型
cxsf &lt;- survfit(model_5, newdata = average_participant, conf.type = &quot;none&quot;)
surv_cxsf &lt;- surv_summary(cxsf, data = complete_cases_all) |&gt; # 总结生存模型
tibble()
m_newdat &lt;- average_participant[as.character(surv_cxsf$strata), ] # 将新数据与生存总结层匹配

gg.surv.model5 &lt;- surv_model_5 |&gt;
ggsurvplot_df(
surv.geom = geom_line,
color = &quot;depression_level&quot;,
xlab = &quot;X 之后的时间（年）&quot;,
ylab = &quot;生存概率&quot;,
legend = c(0.175, 0.175),
conf.int = FALSE,
censor = FALSE,
surv.scale = &quot;percent&quot;,
break.time.by = 1,
xlim = c(0, 5), # 将 x 轴限制为 5 年
ylim = c(crop, 1),
palette = c(&quot;#90cbf9&quot;, &quot;#2196f3&quot;, &quot;#114b7a&quot;),
ggtheme = theme_classic(),
) +
labs(linetype = &quot;Sex&quot;, color = &quot;抑郁水平&quot;)

数据基于纵向数据集，并在初始研究登记日期后约 1 年和 4 年进行后续访谈。审查日期由每个审查参与者的最后一次后续访谈日期确定，死亡日期由每个死者官方死亡证明中列出的日期确定。时间 0 对应于每个参与者的研究登记日期，并在随后的 5 年内进行跟踪。
我检查了数据集，发现 4 年后死亡的死者数量异常，但在此期间似乎有合理的死亡频率（总死亡人数的约 23% 发生在 4 至 5 年之间）。我确保我的死亡时间基于日期，而不是（整数）跟踪间隔。最后，我确保受审查的参与者也在 4-5 年的时间范围内贡献数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/648490/diagnosing-an-unexpected-pattern-in-a-survival-curve-plot</guid>
      <pubDate>Sun, 02 Jun 2024 18:03:43 GMT</pubDate>
    </item>
    <item>
      <title>R 中线性混合模型中随机效应结构的澄清</title>
      <link>https://stats.stackexchange.com/questions/648486/clarification-on-random-effects-structure-in-linear-mixed-models-in-r</link>
      <description><![CDATA[我正在使用线性混合模型来分析具有层次结构的数据集，其中随时间变化的测量值（级别 1）聚集在个体内（级别 2），而个体聚集在国家内（级别 3）。我最初在 R 中使用 lme4 包中的以下语法来对此结构进行建模：
model &lt;- lmer(basdai ~ 1 + time + (1|country) + (1|id), data = data, 
REML = FALSE) 

但是，一位审阅者指出，我使用的语法并不代表 3 级模型，而是 2 级模型。他们建议改用以下语法：
model &lt;- lmer(basdai ~ 1 + time + (1|country) + (1|country:id), 
data = data, REML = FALSE)

据我了解，术语 (1|country) 表示每个国家（级别 3）的随机截距，而 (1|id) 表示每个个体（级别 2）的随机截距。
我认为包括这两个术语将解释聚类。
我将不胜感激任何关于这两个模型规范之间的差异的见解或解释，以及我的初始语法是否真正代表了 2 级结构而不是预期的 3 级层次结构。]]></description>
      <guid>https://stats.stackexchange.com/questions/648486/clarification-on-random-effects-structure-in-linear-mixed-models-in-r</guid>
      <pubDate>Sun, 02 Jun 2024 17:13:38 GMT</pubDate>
    </item>
    <item>
      <title>如果 $T\gg N$，则 $O_p(N^{-1/2}) + O_p(T^{-1/2}) = O_p(N^{-1/2})$ 的数学推导 [已迁移]</title>
      <link>https://stats.stackexchange.com/questions/648485/mathematical-derivation-of-why-o-pn-1-2-o-pt-1-2-o-pn-1-2-i</link>
      <description><![CDATA[我会尽量简单。假设我们有一系列随机变量，$X_{NT}$，其边界表达式为：$X_{NT} = O_p(N^{-1/2}) + O_p(T^{-1/2})$。现在，这意味着如果 $T\gg N$，则 $X_{NT} = O_p(N^{-1/2})$，因为在这种情况下，$N^{-1/2}$ 占主导地位。使用$O_p(\cdot)$的定义，我们可以看到，对于每个$\varepsilon&gt;0$，存在一个常数$M$和$N_0$，使得
$$ P\left( \left|\frac{X_{NT}}{N^{-1/2} + T^{-1/2}} \right| &gt; M \right) &lt; \varepsilon $$
对于 $NT\geq N_0.$ 如果我犯了错误，请纠正我。
一般来说，这意味着 $O_p(N^{-1/2}) + O_p(T^{-1/2}) = O_p(C^{-1}_{NT})$，其中 $C_{NT} = \min(\sqrt{T},\sqrt{N}).$
你能更严格地向我展示这一点吗？如果你能从概念上解释一下，我将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648485/mathematical-derivation-of-why-o-pn-1-2-o-pt-1-2-o-pn-1-2-i</guid>
      <pubDate>Sun, 02 Jun 2024 16:54:29 GMT</pubDate>
    </item>
    <item>
      <title>如何规范化以“最大值”为未知数的自定义范围？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648467/how-to-normalize-a-custom-range-with-max-being-the-unknown</link>
      <description><![CDATA[要对范围进行规范化，我们应用以下变换：
$$
\frac{x_i - \min(x)}{\max(x) - \min(x)}
$$
要将规范化调整为首选范围，其中 b=max_target 和 a=min_target：
$$
\text{norm}_i \cdot (b - a) + a
$$
如果我们希望调整后的规范化数组的总和等于 1，b 将是一个未知数，可通过以下方式求解：
$$
\left( \frac{1 - n \cdot a}{\sum \text{norm}_i} \right) + a
$$
但是，当 n &gt; 9 时，查找 b 会失败。例如，假设我想规范化一个分布，其中 b=x 和 a=0.1：



标签
频率
adj_norm




1
7
0.35


2
10
0.55


3
3
0.10






标签
频率
adj_norm




1
7
0.09...


2
&lt; td&gt;10
0.08...


3
3
0.09...


4
5
0.09...


5
9
0.08... 


6
4
0.09...


7
6
0.09...


8
8
0.08...


9 
1
0.10


10
2
0.09...


11
20
0.07...



请注意，在第一个表中，频率最低的标签被正确识别为最小值，而频率最高的标签具有正确的最大值，使得数组等于 1。但是，在第二个表中，最大值被错误分类...
关于如何更正 n &gt; 9 的公式，您有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648467/how-to-normalize-a-custom-range-with-max-being-the-unknown</guid>
      <pubDate>Sun, 02 Jun 2024 06:14:01 GMT</pubDate>
    </item>
    </channel>
</rss>