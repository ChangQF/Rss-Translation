<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 31 Jan 2025 15:15:59 GMT</lastBuildDate>
    <item>
      <title>哪种统计检验？ - 重复双向方差分析有效吗？</title>
      <link>https://stats.stackexchange.com/questions/660811/which-statistical-test-does-repeated-two-way-anova-work</link>
      <description><![CDATA[我不确定要对我的数据使用哪种统计检验？
我考虑过使用重复双向方差分析，但我不确定。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660811/which-statistical-test-does-repeated-two-way-anova-work</guid>
      <pubDate>Fri, 31 Jan 2025 14:59:45 GMT</pubDate>
    </item>
    <item>
      <title>根据回归分位数生成响应变量的条件分布</title>
      <link>https://stats.stackexchange.com/questions/660810/generating-a-conditional-distribution-of-a-response-variable-from-regression-qua</link>
      <description><![CDATA[在 R 中，我使用 quantreg 包生成回归分位数，以检查响应变量的完整条件分布。散点图呈楔形（非负且具有异方差性）。正如预期的那样，由于响应的这种形状，斜率系数会增加，并在上分位数范围（大于条件中位数）中变得具有统计意义。我想使用回归分位数来估计独立变量特定输入处响应的条件分布。但是，由于下分位数（小于条件中位数）回归不具有统计意义，我想知道如何在结合回归分位数的不确定性的同时估计独立变量输入处的条件分布？通常，我从一系列回归分位数中获取拟合值，并使用几种参数（对数正态）和非参数（核密度和对数样条）方法来生成条件分布。如果您能提供关于如何将拟合值（或其他方法）的不确定性纳入条件分布的任何意见，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660810/generating-a-conditional-distribution-of-a-response-variable-from-regression-qua</guid>
      <pubDate>Fri, 31 Jan 2025 14:58:55 GMT</pubDate>
    </item>
    <item>
      <title>SMAPE 的替代品叫什么名字？</title>
      <link>https://stats.stackexchange.com/questions/660809/what-is-the-name-of-this-alternative-to-smape</link>
      <description><![CDATA[我的一位同事要求我提供准确度测量。过去我被教导使用绝对百分比误差 (ape) ... 实际上是补充 (1 - ape)。这样，数字越大越好。
这很有效，但预测值是实际值的 2 倍时除外。他提出了另一种方法。min(a,f)/max(a,f)，其中 a 是实际值，f 是预测值。
起初我建议使用 1 - 对称绝对百分比误差 (1 - (abs(a - f)/ (abs(a) + abs(f))))。SMAPE 是一种经过充分研究的指标。我从未见过他建议的指标，所以一开始我很犹豫。
与另一位数据科学家交谈后，生成了以下图表。它表明 min(a,f)/max(a,f) 具有与 smape 准确度相同/相似的属性，同时更简单。

这个指标有名字吗？
这个指标如何存在无法预见的缺陷？

对我来说，这看起来像是一个很好的错误指标，但我是一名实践者，而不是学者。我肯定我遗漏了一些东西。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660809/what-is-the-name-of-this-alternative-to-smape</guid>
      <pubDate>Fri, 31 Jan 2025 14:54:54 GMT</pubDate>
    </item>
    <item>
      <title>McNemar 检验是否适合前后比较？</title>
      <link>https://stats.stackexchange.com/questions/660806/is-mcnemars-test-suitable-for-before-after-comparisons</link>
      <description><![CDATA[如果我理解正确的话，McNemar 检验通常用于测试两个二元结果之间的依赖关系。Agresti 在《分类数据分析》（我相信是 2002 年版）中给出了两个与环境相关的问题的示例，受试者同时回答这些问题。我提供了我自己的示例，其中的数字被夸大了，以便进行演示：
 Q2
Q1 同意 不同意
同意 945 5
不同意 10 40

在这里，我可以看到 McNemar 的检验是有道理的：大多数人同意这两个陈述，一些人同意其中一个而不同意另一个，还有少数人不同意两者。这听起来很合理。 p 值为 0.2，即两个问题的同意率没有显著差异。
但是，McNemar 检验也用于比较前后结果，如 Agresti 书中早期版本 (1990) 中的示例。因此，让我们使用上述数字，但将它们视为受试者对一个问题的回答，但在两个不同的时间点，$T_1$ 和 $T_2$。在这两个时间点，他们可能“同意”或“不同意”：
 T2
T1 同意 不同意
同意 945 5
不同意 10 40

由于计数的巨大不平衡，我发现 McNemar 检验中暗示的情景难以置信。我们想看看受试者是否会随着时间的推移而改变主意，结果发现一组（$T_1$ 的“同意者”）几乎没有变化（~0.5%），而“不同意者”则发生了很大变化：在 $T_1$ 不同意的受试者中，约有 20% 在 $T_2$ 同意。我认为这是一个“显著”的差异，但由于表中的数字与第一个示例中的数字相同，因此 McNemar 的检验仍然不显著。
在 $H_0$ 下，非对角线单元格中的绝对数字需要相似，而不是百分比。为了得到相似的数字，“T1 同意者”需要以与“不同意者”不同的概率改变主意，但这两个概率必须相关。换句话说，$H_0$ 意味着两组之间存在某种信息交换。或者，换句话说，“非对角线概率之间没有差异”假设可能意味着行概率之间存在相当大且非常精确的差异。这对我来说似乎非常不随机 - 与人们对零假设的期望完全相反。
或者我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660806/is-mcnemars-test-suitable-for-before-after-comparisons</guid>
      <pubDate>Fri, 31 Jan 2025 14:13:43 GMT</pubDate>
    </item>
    <item>
      <title>结构共线性</title>
      <link>https://stats.stackexchange.com/questions/660805/structural-collinearity</link>
      <description><![CDATA[我很难理解这些数据如何显示结构共线性？
这是否与在同一天在每个房间内进行测量有关？

每个星期一星期二都是新的一周，但每周一星期二都会进行两次测量，等等。]]></description>
      <guid>https://stats.stackexchange.com/questions/660805/structural-collinearity</guid>
      <pubDate>Fri, 31 Jan 2025 14:13:14 GMT</pubDate>
    </item>
    <item>
      <title>如何在 K 均值聚类中聚类/处理 B 样条线的不同长度系数向量</title>
      <link>https://stats.stackexchange.com/questions/660803/how-to-cluster-handle-different-length-coefficient-vectors-of-b-splines-in-k-mea</link>
      <description><![CDATA[我想根据在 3 或 4 个时间点进行的血压 (BP) 测量对数据集进行聚类。为此，我使用二次 B 样条（通过 scipy.interpolate.splrep）对每个人的血压轨迹进行建模，然后使用 k 均值 (sklearn.cluster.KMeans) 对得到的样条系数进行聚类。我采用了以下论文 https://ieeexplore.ieee.org/document/8031156 中的方法。
但是，对于有 4 个测量值的人，这会生成长度为 4 的（非零）样条系数向量，而对于缺少一个时间点的人，则会生成长度为 3 的样条系数向量。这会导致执行 k 均值聚类时出现问题，因为需要向量具有相同的维度。
在这里，我想避免多重插补并将我的分析限制在完整的案例中。然后我偶然发现了这篇论文 https://www.sciencedirect.com/science/article/pii/S1532046421002185#b0025，其中写道
&quot;Luong 和 Chandola（上述论文）提出了一种使用数据的 B 样条基础表示来学习具有 k 均值聚类的单个轨迹聚类的方法。这种方法允许不同的向量长度和缺失数据，而无需插补或分配零。它假设集群内的时间序列可以使用样条函数或多项式函数集合的加权和来近似”。我没有完全理解它们如何处理不同长度的系数向量。任何指导或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660803/how-to-cluster-handle-different-length-coefficient-vectors-of-b-splines-in-k-mea</guid>
      <pubDate>Fri, 31 Jan 2025 13:24:05 GMT</pubDate>
    </item>
    <item>
      <title>聚合序数数据=</title>
      <link>https://stats.stackexchange.com/questions/660802/aggregate-ordinal-data</link>
      <description><![CDATA[在我的研究中，我正在研究人工智能标签（带或不带）对各种品牌认知和行为意图的影响。具体来说，我分析了刺激（IV，2 个子组中的 4 个刺激）如何影响品牌可信度（DV，2 个维度）、在线参与意愿（DV1）和购买意向（DV2）。对人工智能和品牌透明度的态度起着调节作用，而品牌可信度则充当对其他变量影响的中介。
样本量约为 248 名参与者（每组约 120 名），所有结构均采用 5 点李克特量表进行测量，我使用 Jamovi 进行统计分析。
起初，我认为通过计算项目的平均值将有序测量的量表聚合为连续变量是完全没问题的。然而，我意识到将序数尺度聚合为均值可能会有问题，因为序数尺度中类别之间距离相等的假设并不总是成立。这让我重新考虑了我的方法。
在认识到这个问题之后，我质疑以这种方式聚合是否真正有效。事实证明，序数数据的均值聚合在实践中经常使用，并且通常被认为是有效的，尤其是在内部一致性很高的情况下，就像我的情况一样。虽然这一发现提供了一些保证，但我仍然不确定正态性假设和类别之间的距离会如何影响结果。
对于分析，我使用了非参数检验并应用了引导法。然而，这里的问题是，我使用连续聚合变量作为测试的基础，这并不理想，因为这些测试通常用于序数数据。
为了调查调节因素和中介作用，我测试了对人工智能和品牌透明度的态度作为调节因素，并在我的分析中将品牌可信度视为中介因素（使用 Jamovi 中的 MedMod）。
最后，我考虑对年龄、购买者身份和性别等控制变量进行序数逻辑回归。然而，我意识到因变量现在被认为是连续聚合的，这使得这种方法存在问题。这就提出了一个问题，我是否可以对项目均值进行四舍五入，再次将变量视为序数，并应用非参数检验，但这会导致精度损失。考虑到变量的测量水平不同，我正在考虑使用 MANCOVA，但我也面临着违反正态性的挑战。
我听说我可以使用中位数将序数数据聚合到一个构造中？或者可能是 IQR？救命！！！]]></description>
      <guid>https://stats.stackexchange.com/questions/660802/aggregate-ordinal-data</guid>
      <pubDate>Fri, 31 Jan 2025 12:52:29 GMT</pubDate>
    </item>
    <item>
      <title>当比例风险假设不成立时，如何用重复测量来模拟事件发生时间</title>
      <link>https://stats.stackexchange.com/questions/660801/how-to-model-time-to-event-with-repeated-measures-when-proportional-hazards-assu</link>
      <description><![CDATA[我的数据：
我每天对两个连续变量进行测量，直到他们移民或死亡。
我的目标：
我想使用我的两个每日指标来预测移民时间。
我的模型：
我已经对预测因子进行了 Box Cox 转换和缩放。我已对状态 = 1 的死亡个体和状态 = 2 的移民个体进行了编码。days 是从研究开始到死亡或移民之间的天数。
例如：



ID
metric1
metric2
days
status




A
0.428
-1.42
267
2


A
0.204
-1.97
267
2


A
0.168
-2.65
267
2



我已经开始使用简单的 CoxPH 模型：
coxph(Surv(days, status) ~ metric1 = metric2, data=df)

测试比例风险假设会返回一个显著的全局 p 值。我只能假设这与我的度量随着时间的推移逐渐增加到渐近线有关，而随着年龄的增长，移民的可能性会更大，但死亡的可能性会更小。
我的下一步努力：
我发现了许多处理随时间变化数据的建议方法。这些包括使用tt()拟合时间变换，在coxme中添加随机效应，将预测因子与时间相互作用，使用联合建模，以及添加层或集群。
我的问题：
因为似乎有有如此多的选择被平等地提倡，我正在寻求建议，看是否存在“最佳”选择，如果有的话，对我来说哪个是最佳选择。]]></description>
      <guid>https://stats.stackexchange.com/questions/660801/how-to-model-time-to-event-with-repeated-measures-when-proportional-hazards-assu</guid>
      <pubDate>Fri, 31 Jan 2025 11:37:17 GMT</pubDate>
    </item>
    <item>
      <title>无法理解本文使用的评估方法</title>
      <link>https://stats.stackexchange.com/questions/660799/cant-understand-the-evaluation-approach-used-in-this-paper</link>
      <description><![CDATA[在这篇论文中，提出了两种深度学习模型：Hybrid-AttUnet++ 和 EH-AttUnet++。第一个模型 Hybrid-AttUnet++ 只是一个经过修改的 U-net 模型，第二个模型是五种不同的 Hybrid-AttUnet++ 模型的集成方法，如论文中所述（第 7 页）：

为了提高系统的性能和稳健性，我们提出了一种由五个 Hybrid-AttUnet++ 模型组成的集成方法，如图 9 所示。为了确保模型多样性（这对集成性能至关重要），我们使用了 k 倍交叉验证技术，其中 k（折叠数）设置为 5。为了创建分区，我们首先将数据集随机分成五个折叠。在这些折叠中，一个用于验证，其余四个用于训练。然后，我们创建了五个具有不同训练/验证子集的分割。对于这五个分割中的每一个，Hybrid-AttUnet++ 都从头开始训练。训练后，使用这些模型进行单独的预测。然后，使用集成方法对五个训练模型的预测取平均值。

因此，他们简单地使用了 5 倍交叉验证，并从 5 个模型中分别创建一个 Hybrid-AttUnet++ 基线模型。我不明白的是评估过程。第 8 页：

为了评估我们的方法，我们使用 80% 的组合数据集作为训练数据，其余数据集作为测试数据，执行 5 倍交叉验证。然后计算五倍交叉验证的平均结果，并在表 3 中总结。

因此，这意味着对 80% 的数据集执行了 5 倍交叉验证，其余 20% 用作测试集。因此，我期望找到一个表格来展示在 20% 测试集上取得的结果，但是，本文有三个表格来展示结果：

表 3 展示了两种模型在 5 倍交叉验证上取得的结果：Hybrid-AttUnet++ 和集成方法 EH-AttUnet++，这对我来说很奇怪，因为 EH-AttUnet++ 已经是从 5 倍交叉验证中开发的，那么它们如何在 5 倍交叉验证上再次进行评估，作者是否只是使用了两次 5 倍交叉验证，一次开发基线模型，另一次重新训练每个分割的集成方法（我不这么认为，因为重新训练整个模型（集成方法）是没有意义的）？

表 4 再次与 5 倍交叉验证相关。

表 5 说明了每次折叠的性能指标仅适用于 EH-AttUnet++，而不适用于 Hybrid-AttUnet++。


总结一下，我的问题如下：
1- 他们的评估方法有 20% 的测试集，在这个测试集上究竟取得了什么结果？还是我遗漏了什么？
2- 集成方法 EH-AttUnet++ 是使用 5 倍交叉验证开发的，其中为每个分割创建了一个基线 Hybrid-AttUnet++。在表 3-5 中，使用 5 倍交叉验证评估了这种集成模型的性能，这对我来说没有意义，因为他们是如何做到的？他们是否再次使用了 5 倍交叉验证，但每个分割都使用了整个 EH-AttUnet++（因此他们每个分割再次重新训练 5 个模型）？我认为最好的方法是使用 20% 的测试集来评估它？]]></description>
      <guid>https://stats.stackexchange.com/questions/660799/cant-understand-the-evaluation-approach-used-in-this-paper</guid>
      <pubDate>Fri, 31 Jan 2025 11:24:49 GMT</pubDate>
    </item>
    <item>
      <title>如果 BatchNorm 的主要好处是损失景观平滑，那么为什么我们使用 z 分数标准化而不是最小-最大？</title>
      <link>https://stats.stackexchange.com/questions/660796/if-the-main-benefit-of-batchnorm-is-loss-landscape-smoothing-why-do-we-use-z-sc</link>
      <description><![CDATA[根据最近的论文，BatchNorm 之所以有效的主要原因是它可以平滑损失景观。因此，如果主要的好处是平滑损失景观，那么我们为什么需要均值减法呢？也许方差正则化为损失景观的好处做了大部分繁重的工作？为什么不使用其他类型的正则化，因为它们可以达到相同的效果，比如最小-最大正则化。请注意，如果内部协变量偏移是主要问题，我理解为什么我们需要 z 分数正则化。]]></description>
      <guid>https://stats.stackexchange.com/questions/660796/if-the-main-benefit-of-batchnorm-is-loss-landscape-smoothing-why-do-we-use-z-sc</guid>
      <pubDate>Fri, 31 Jan 2025 10:00:40 GMT</pubDate>
    </item>
    <item>
      <title>重新缩放特征增加了其进入 LASSO 模型的机会</title>
      <link>https://stats.stackexchange.com/questions/660795/rescaling-feature-increases-its-chances-to-be-in-lasso-model</link>
      <description><![CDATA[假设我们将 LASSO 回归拟合到一个数据集，该数据集具有 $100$ 个特征 $(X_1, \dots X_{100})$。现在，我们通过乘以 $10$（例如 $X_1$）来重新缩放其中一个特征，然后使用相同的正则化参数重新拟合 LASSO 回归。 $X_1$ 是否更有可能被纳入模型？
考虑到以下情况，我猜答案是否定的，但由于不太正式，我不确定

当将 $X_1$ 乘以 $10$ 时，我们将其在 OLS 中的系数除以 $10$。从示意图上看，LASSO 是通过最小化目标函数直到它达到 L1 范数的界限而获得的。我想到这种情况，其中 $\beta_{\text{LASSO}}$ 首先接近（$0.5,0.5$）。实际上，确切的值并不重要，但很明显 $X_1$ 将包含在模型中。然而，在将 $X_1$ 的 OLS 系数除以 10 后，相同的过程将不可避免地将新的 $\beta_{\text{LASSO}}$ 带到 $\approx(0,1)$，它将不会被包括在内。]]></description>
      <guid>https://stats.stackexchange.com/questions/660795/rescaling-feature-increases-its-chances-to-be-in-lasso-model</guid>
      <pubDate>Fri, 31 Jan 2025 09:55:29 GMT</pubDate>
    </item>
    <item>
      <title>李克特类型调查和深度学习</title>
      <link>https://stats.stackexchange.com/questions/660794/likert-type-survey-and-deep-learning</link>
      <description><![CDATA[我是数据新手。我有一个问题，我研究过但找不到明确的答案。我有使用各种李克特类型收集的调查数据，我想将深度学习应用于这些调查数据。但我应该以李克特形式原封不动地使用这些数据，还是应该使用简单平均值等方法将其连续化并以此方式进行分析？据我所知，在经典分类算法中使用李克特类型不是问题，但我不确定深度学习。如果你能帮助我，我会非常高兴。]]></description>
      <guid>https://stats.stackexchange.com/questions/660794/likert-type-survey-and-deep-learning</guid>
      <pubDate>Fri, 31 Jan 2025 09:31:25 GMT</pubDate>
    </item>
    <item>
      <title>在估算缺失值时，变量之间的时间关系重要吗？</title>
      <link>https://stats.stackexchange.com/questions/660792/does-the-temporal-relationship-between-variables-matter-when-imputing-missing-va</link>
      <description><![CDATA[我现在的情况是，我有多个变量，包含缺失值，在时间 $t0$ 测量，还有一些变量在时间 $t1$ 测量，这可能是几年后。
我需要在 $t0$ 时估算变量中的缺失值，为此我将使用当时可用的任何信息。是否还应该使用时间上在之后出现的变量的信息？我知道关于是否包括响应变量的讨论，但在这种情况下，变量之间的关系具有明显的方向性。目标（下游分析）是估计时间 0 时某些暴露对时间 1 时某些结果的因果影响。结果在估算过程中用于估算其他变量，但本身不会被估算。]]></description>
      <guid>https://stats.stackexchange.com/questions/660792/does-the-temporal-relationship-between-variables-matter-when-imputing-missing-va</guid>
      <pubDate>Fri, 31 Jan 2025 08:07:24 GMT</pubDate>
    </item>
    <item>
      <title>测试两个 AUC 之间的差异</title>
      <link>https://stats.stackexchange.com/questions/660793/testing-the-difference-between-two-aucs</link>
      <description><![CDATA[测试两个 AUC 之间的差异似乎很简单。有一些相关来源，例如这个和其中的链接。
我有一个非常简单的两个 ROC 案例，类似于此示例：
。
使用梯形规则计算 AUC 非常容易。但是，差异检验假设计算了方差，我无法理解如何做到这一点。方差是什么？我拥有的数据就是这样（当然，数据是聚合的）：
命中 FalseAlarms
0.0 0.0
0.9 0.3
1.0 1.0

如何使用上述输入数据在 R 中解决这个问题？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660793/testing-the-difference-between-two-aucs</guid>
      <pubDate>Fri, 31 Jan 2025 06:19:27 GMT</pubDate>
    </item>
    <item>
      <title>解析简单门控 RNN 随时间反向传播的解法</title>
      <link>https://stats.stackexchange.com/questions/660789/analytically-solving-backpropagation-through-time-for-a-simple-gated-rnn</link>
      <description><![CDATA[考虑以下简单的门控 RNN：
\begin{aligned}
c_{t} &amp;= \sigma\bigl(W_{c}\,x_{t} + W_{z}\,z_{t-1}\bigr)
\\[6pt]
z_{t} &amp;= c_{t} \,\odot\, z_{t-1} \;\;+\;\; 
(1 - c_{t}) \,\odot\,\bigl(W_{x}\,x_{t}\bigr)。
\end{aligned&gt;
这里，
$$
x_{t}\in \mathbb{R}^{n}, \quad
z_{t}\in \mathbb{R}^{m}, \quad
c_{t}\in \mathbb{R}^{m}, 
$$
和
$$
W_{c}\in \mathbb{R}^{m\times n},\, 
W_{z}\in \mathbb{R}^{m\times m},\,
W_{x}\in \mathbb{R}^{m\times n}。
$$
门$c_{t}=\sigma(\cdot)$是元素级 S 型函数。
我们让损失为
$$
\ell \;=\;\sum_{t=1}^{K}\;\ell_{t}\,\bigl(z_{t}\bigr)
$$
因此每个$z_{t}$都对$\ell$有贡献。
我们试图在给定$\frac{\partial \ell_t}{\partial z_t}$的情况下找到$\frac{\partial \ell}{\partial W_x}$。我们可以从以下公式开始：
$$
\frac{\partial \ell}{\partial W_{x}} =
\sum_{t=1}^{K} \left(\frac{\partial \ell_t}{\partial z_{t}} \cdot
\frac{\partial z_{t}}{\partial W_{x}} \right)
$$
并且我们必须找到$\frac{\partial z_{t}}{\partial W_{x}}$。为了方便起见，我们可以将每个 $z_t$ 视为多个变量的函数 $f$：
$$
f(U, z_{\text{prev}}, c_t, x_t) = c_t \odot z_{\text{prev}} + (1 - c_t)\,\odot\,(U \, x_t)
$$
然后
$$
z_t = f(W_x, z_{t-1}, c_t, x_t)
$$
然后我们有
$$
\frac{\partial z_t}{\partial W_x} = \underbrace{\Bigl(\frac{\partial f}{\partial U}\Bigr)}_{\text{direct}} + 
\Bigl(\frac{\partial f}{\partial z_{\text{prev}}}\Bigr)
\frac{d\,z_{t-1}}{d W_x} + 
\Bigl(\frac{\partial f}{\partial c_t}\Bigr) \frac{\partial c_t}{\partial W_x}
$$
我在此处的公式下添加了注释“direct”，以强调 $W_x$ 影响 $z_t$ 的两种方式：

存在直接影响，因为 $W_x$ 明确出现在 $z_t$
存在间接影响，因为 $W_x$ 还会影响 $z_{t-1}$ 和 $c_t$ 的值，而这会影响 $z_t$

让我们定义
\begin{align*}
\varepsilon_t &amp;= \frac{\partial f}{\partial U}(W_x, z_{t-1}, c_t, x_t) \\
\delta_t &amp;= \frac{\partial \ell}{\partial z_t} 
\end{align*&gt;
如何我如何证明以下说法？
\begin{align*}
\frac{\partial \ell}{\partial W_{x}} = \sum_{t=1}^{K} \delta_t \varepsilon_t
\end{align*&gt;
我可以使用 PyTorch 验证它，但我正在寻找分析证明。]]></description>
      <guid>https://stats.stackexchange.com/questions/660789/analytically-solving-backpropagation-through-time-for-a-simple-gated-rnn</guid>
      <pubDate>Fri, 31 Jan 2025 03:12:00 GMT</pubDate>
    </item>
    </channel>
</rss>