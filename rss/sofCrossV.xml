<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 23 Dec 2024 09:17:53 GMT</lastBuildDate>
    <item>
      <title>单因素方差分析对比</title>
      <link>https://stats.stackexchange.com/questions/659115/contrasts-in-one-way-anova</link>
      <description><![CDATA[我正在观看一场关于方差分析的讲座，讲师给出了 3 个可能的数据假设示例：

对于假设 3 (mu2 = mu1 - 3*mu3)，对比度系数总和不为零 (-1 + 1 + 3 != 0)。在这种情况下，我们可以说它是对比度吗？如果不是，那它是什么？在这种情况下，我们可以检查第三个假设与假设 1 的正交性，就像幻灯片上所做的那样 (a * c)？]]></description>
      <guid>https://stats.stackexchange.com/questions/659115/contrasts-in-one-way-anova</guid>
      <pubDate>Mon, 23 Dec 2024 05:03:38 GMT</pubDate>
    </item>
    <item>
      <title>简单线性回归中的 F 检验</title>
      <link>https://stats.stackexchange.com/questions/659114/f-test-in-simple-linear-regression</link>
      <description><![CDATA[我试图理解 F 检验对简单线性回归模型有效性的检验，但我对此有几个问题：

为什么我们要用 SSR 除以独立变量的数量，用 SSE 除以自由度的数量？为什么不用它们都除以独立变量的数量，这样我们就可以计算出每个独立变量对应的平均解释/未解释变异性？

在 $\beta_1 = 0$ 的零假设下，检验统计量的 F 是如何分布的？

]]></description>
      <guid>https://stats.stackexchange.com/questions/659114/f-test-in-simple-linear-regression</guid>
      <pubDate>Mon, 23 Dec 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以计算/指定 SEM 全项目分割方法中的误差方差？</title>
      <link>https://stats.stackexchange.com/questions/659112/where-do-i-compute-specify-error-variance-in-sem-all-item-parceling-approach</link>
      <description><![CDATA[我是 SEM 和 lavaan 的新手。我创建了一个模型，需要为其运行 SEM。由于样本量极小且模型参数很多，我需要采用全项目包裹方法进行 SEM 和 ML 估计，尽管我知道包裹是有争议的。
先前的文献表明，如果我要为某个因子包裹所有项目，则需要计算误差方差。

有趣的是，此处引用的作为全项目包裹方法示例的四项研究使用了略有不同的方程来计算误差方差 (θε)。 Holbert (2005) 和 Theiss
and Solomon (2006) 使用了 Bollen (1989) 的程序（即 θε = [1 − α] × s2），而其他两项研究的作者修改了该方程：Dillard 和 Shen (2005) 将每个构造的误差方差固定为“1 − α2 乘以其方差”（第 156 页）（即 θε = [1 − α2] × s2）；另一方面，在 Pfau 等人（2004 年，第 341 页）的研究中，“误差项设置为每个变量的方差乘以 1 减去该变量可靠性估计的平方根”（即 θε = [1 − α1/2] × s2）。鉴于 α ≤ 1.0 且 s2 &gt; 0，
与 Bollen 的原始公式相比，
对 alpha 求平方会使误差方差增大，而对 alpha 求平方根会使误差方差减小。
所有这些作者都引用了 Bollen 作为计算过程的来源。
（Matsunaga，2014；DOI：10.1080/19312450802458935）

我的问题是，在 R 中使用 lavaan 时，如何以及在哪里指定/计算此误差方差？我想出了以下语法，它正确吗（尤其是使用 ~~）？误差方差已通过以下公式计算：θε = [1 − α] × s2
model &lt;- &#39;
Institutional_Support =~ 1*INSPT_COMP
Lesson_Preparation_Time =~ 1*LPT_COMP
Access_Use_Technology =~ 1*TECH_COMP
Self_Efficacy =~ 1*SEFF_COMP
Orchestration_Load =~ 1*TLX_COMP

# 结构模型：以 SHT 为观察变量的经验
Orchestration_Load ~ Institutional_Support + Lesson_Preparation_Time + EXP1

# 为每个地块指定固定方差
INSPT_COMP ~~ error_variances_INSPT
LPT_COMP ~~ error_variances_LPT
TECH_COMP ~~ error_variances_TECH
SEFF_COMP ~~ error_variances_SEFF
TLX_COMP ~~ error_variances_TLX
&#39;

# 使用 ML 估计量和 bootstrap 标准误差拟合 SEM 模型
fit_ml &lt;- sem(
model,
data = my_data,
estimator = &quot;ML&quot;,
se = &quot;bootstrap&quot;, # 使用 bootstrap 标准误差
bootstrap = 1000 # bootstrap 样本数
)

&#39;&#39;&#39;]]></description>
      <guid>https://stats.stackexchange.com/questions/659112/where-do-i-compute-specify-error-variance-in-sem-all-item-parceling-approach</guid>
      <pubDate>Mon, 23 Dec 2024 00:21:23 GMT</pubDate>
    </item>
    <item>
      <title>线性混合效应模型对不平衡聚类是否具有鲁棒性？</title>
      <link>https://stats.stackexchange.com/questions/659110/are-linear-mixed-effects-model-robust-to-unbalanced-clusters</link>
      <description><![CDATA[我们已拟合以下模型：
m = lmer(y ~ time + event + time_since_event + (time|id), data = df)

有些集群有 1000 多个数据点，而其他集群则少于 10 个。
lmer 模型是否考虑了这种集群大小不平衡？即使存在这种不平衡，time、event 和 time_since_event 的 $p$ 值是否可靠？
是否有必要使用 clubSandwich 之类的包来实现聚类稳健标准误差：
coef_test(m, vcov = &quot;CR2&quot;, cluster = df$id)

我们询问的原因是从 coef_test 获得的 $p$ 值无法支持我们的假设，而从 lmer 模型获得的 $p$ 值则支持我们的假设。不确定哪个是正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/659110/are-linear-mixed-effects-model-robust-to-unbalanced-clusters</guid>
      <pubDate>Sun, 22 Dec 2024 22:26:49 GMT</pubDate>
    </item>
    <item>
      <title>元分析中嵌套数据的模型简化</title>
      <link>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</link>
      <description><![CDATA[我正在对子组中不同程度的异质性进行荟萃分析。由于数据结构是嵌套的（效应大小嵌套在研究中），我通过添加研究的随机效应和研究内的效应大小来考虑这一点。轮廓似然图在其估计值处达到峰值。
比较具有不同程度异质性的模型和具有共同异质性估计值的模型的似然比检验是显著的。然而，在获得 $ \tau^2_\text{between} $ 和 $ \tau^2_\text{within} $ 的置信区间 (CI) 后，除了一个之外，$ \tau^2_\text{within} $ 的所有 CI 的下限均为零。一个显著的估计值仍然是适中的。
在这种情况下，将模型简化为标准（两级）随机效应模型，仅考虑研究之间的差异是否合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</guid>
      <pubDate>Sun, 22 Dec 2024 20:41:46 GMT</pubDate>
    </item>
    <item>
      <title>R 边际效应包：估计中断时间序列中预测的减去反事实的绝对/相对变化的 95% 置信区间</title>
      <link>https://stats.stackexchange.com/questions/659105/r-marginaleffects-package-estimate-95-ci-for-predicted-minus-counterfactual-ab</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659105/r-marginaleffects-package-estimate-95-ci-for-predicted-minus-counterfactual-ab</guid>
      <pubDate>Sun, 22 Dec 2024 20:40:03 GMT</pubDate>
    </item>
    <item>
      <title>输入目的二分变量和序数变量之间的差异</title>
      <link>https://stats.stackexchange.com/questions/659103/difference-between-dichotomous-and-ordinal-variable-for-inputation-purposes</link>
      <description><![CDATA[我正在阅读 Amelia R 包的文档。
在文档的序数部分中，写到序数变量包括二分变量，其中一个例子是性别，它应该被视为序数变量，如果 0 表示男性，1 表示女性，则输入值 0.79 是完全可以接受的。
但是在名义部分中，它说另一个名为 signed 的变量，如果一个国家在当年签署了 IMF 协议，则该变量为 1如果没有，则为 0，应将其视为名义变量，并且只接受 0 和 1 值。浮点变量不可接受。
为什么性别可以被视为序数，而有符号则不能？
输入的签名值为 0.79 有什么问题，这意味着该国签署协议的概率为 79%？
相关：我们可以将性别视为序数变量吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659103/difference-between-dichotomous-and-ordinal-variable-for-inputation-purposes</guid>
      <pubDate>Sun, 22 Dec 2024 20:10:12 GMT</pubDate>
    </item>
    <item>
      <title>去趋势波动分析</title>
      <link>https://stats.stackexchange.com/questions/659102/detrended-fluctuation-analysis</link>
      <description><![CDATA[在 R 中，我尝试实现中描述的 DFA 时间序列分析算法
https://en.wikipedia.org/wiki/Detrend_fluctuation_analysis
和
https://www.kubios.com/blog/hrv-analysis-方法/
对于运动/训练教练朋友。有运动生理学研究建议使用 RR 间隔心跳时间序列（约 200 次心跳窗口）作为 DFA 低 n 系列 alpha 系数的输入，作为个人维持最佳心脏努力量的指导，而不是分配每个人在锻炼的某些部分都有相同的功率或心率目标（大致如下：&gt;~1.2 锻炼不够努力 &lt;~0.5 锻炼太努力。
为了测试我的 R 实现，我构建了白噪声使用 R 的 rnorm 函数对序列进行分析。但是，为了获得白噪声的 ~0.5 alpha 和随机游走的 ~1.5 alpha，我必须将每个的累积和输入到算法中。
此外，对于实际锻炼数据，我还需要输入 RR 锻炼系列的累计总和，以获得与 Garmin 应用程序针对相同锻炼的 alpha 输出相匹配的结果。
目前，我让我的朋友使用并相信我的 R 例程输出，输入 RR 系列和额外的累积和。但我担心我遗漏了一些基本的东西。我认为我遗漏的概念与我的白噪声系列有关，从任意开始（不一定是相等/离散时间）采样...在某种程度上，类似于心跳 RR 系列采样创建的时间尺度，由运动员的神经系统告诉身体下一次跳动的时间控制...但是我找不到任何关于 DFA 的在线讨论或参考文献中关于这个细微差别的讨论。我读到的所有内容似乎都表明你应该输入采样的白噪声流或原始 RR 流，而不是它们的累积和（因为第一步算法是另一个减去平均值的累积和，看起来累积和开始加起来了。）
有什么见解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659102/detrended-fluctuation-analysis</guid>
      <pubDate>Sun, 22 Dec 2024 19:53:36 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据插补生成方法背后的直觉</title>
      <link>https://stats.stackexchange.com/questions/659075/intuition-behind-generative-methods-for-imputing-missing-data</link>
      <description><![CDATA[我正在学习不同的方法来估算混合连续和分类变量的表格数据集，并且假设数据完全随机缺失。我使用频率编码器转换了分类数据，因此所有内容都是数字或 NaN。
我认为平均值、中位数等估算过于简单且容易产生偏差。我正在考虑更复杂的方法，例如确定性和生成性。
对于确定性，我尝试了 LightGBM，它非常直观。我喜欢它。基本上，对于每个具有缺失数据的特征，其非缺失数据作为对其他特征的回归，然后预测/估算缺失数据。很棒。
现在我尝试使用深度学习方法，例如 AE 或 GAN。通过查阅文献，这似乎非常可行且非常有效。但黑匣子很难理解。例如，对于 VAE，我们是否只是简单地基于整个表格数据构建一个 VAE 模型，然后“以某种方式”预测/生成/估算缺失数据？
我仍在研究这个问题以获得更清晰的解释，但我希望也尝试过估算表格数据的人可以分享一些经验。]]></description>
      <guid>https://stats.stackexchange.com/questions/659075/intuition-behind-generative-methods-for-imputing-missing-data</guid>
      <pubDate>Sun, 22 Dec 2024 01:27:59 GMT</pubDate>
    </item>
    <item>
      <title>在评估 GLM 模型时，AIC 值或预测显著性的 p 值更重要吗？</title>
      <link>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</guid>
      <pubDate>Sat, 21 Dec 2024 15:14:21 GMT</pubDate>
    </item>
    <item>
      <title>利用二进制数据的 MSE 进行快速搜索</title>
      <link>https://stats.stackexchange.com/questions/659043/exploiting-mse-of-binary-data-for-fast-search</link>
      <description><![CDATA[我有一个巨大的二进制向量数据库。给定一个传入向量，我想在数据库中找到 MSE 最接近的向量并返回 MSE 分数。到目前为止，我一直在手动进行此搜索，但花费的时间太长了。
我可以利用 MSE 与二进制向量一起使用时的特性来加快搜索速度吗？
更多详细信息：我正在寻找。我可以利用的 MSE 或二进制向量或数据稀疏性的属性来显着加快搜索速度！我的数据集有大约 400 万个高维（~4000）二进制向量，其中大部分是稀疏的（包含大量零）。我有一个循环，逐个遍历 400 万个向量并返回 MSE 分数最低的向量。我不能使用任何其他指标，并且在考虑是否可以利用 MSE 的任何属性来加快搜索速度。即使可以使用使用 MSE 的 ML 模型，它也会很完美]]></description>
      <guid>https://stats.stackexchange.com/questions/659043/exploiting-mse-of-binary-data-for-fast-search</guid>
      <pubDate>Sat, 21 Dec 2024 01:58:16 GMT</pubDate>
    </item>
    <item>
      <title>如何应用对系数有约束的 OLS 并使输出规模与目标变量对齐？</title>
      <link>https://stats.stackexchange.com/questions/658907/how-to-apply-ols-with-constraints-on-coefficients-and-align-the-output-scale-wit</link>
      <description><![CDATA[我正在研究一个 OLS 回归问题，其中：
因变量（目标）的范围从 1 到 6（步长为 1）。
独立变量的范围从 1 到 10（步长为 0.5）。
我想要设置模型，使得：
没有截距。
所有系数的总和（β）等于 1。
输出与因变量的尺度一致（1 到 6）。
但是，当所有独立变量都达到其最大值 10 时，模型输出将扩大到 10，这超出了目标范围。我无法缩放独立变量。我可以缩放因变量。因此，它是 1 到 10。下面是我用来缩放因变量的映射。



原始比例
新scale




1
1


2
2.8


3
4.6


4
6.4


5
8.2


6
10



但是还有其他方法吗？我如何调整我的 OLS 设置？
如果您能提供任何关于如何实施的指导或建议，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658907/how-to-apply-ols-with-constraints-on-coefficients-and-align-the-output-scale-wit</guid>
      <pubDate>Wed, 18 Dec 2024 07:41:36 GMT</pubDate>
    </item>
    <item>
      <title>McNemar 检验为 z 检验或卡方检验</title>
      <link>https://stats.stackexchange.com/questions/657582/mcnemar-test-as-z-test-or-chi-squared-test</link>
      <description><![CDATA[我是统计学入门课的助教。我们正​​在向学生介绍 McNemar 检验，以比较相关样本上的两个比例。我注意到教科书中，我们将 McNemar 检验定义为遵循 z 分布的 z 统计量：
$$
z = \frac{b-c}{\sqrt{b+c}}
$$
而其他来源，例如维基百科，将检验统计量定义为遵循卡方分布
$$
\chi_1^2 = \frac{(b-c)^2}{b+c}
$$
我从数理统计中得知，z 统计量的平方服从自由度为 1 的卡方分布。
有人知道为什么人们可能更喜欢将一种框架作为 z 检验或将另一种框架作为 z 检验吗？我认为这两个统计数据会产生相同的推论。我怀疑如果学生决定自己阅读这个主题，他们可能会感到困惑。
将测试框架为 z 检验确实允许计算与卡方框架无关的标准误差。]]></description>
      <guid>https://stats.stackexchange.com/questions/657582/mcnemar-test-as-z-test-or-chi-squared-test</guid>
      <pubDate>Wed, 20 Nov 2024 21:28:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么指数平滑预测是预测密度的中值？</title>
      <link>https://stats.stackexchange.com/questions/654766/why-is-exponential-smoothing-forecast-the-median-of-the-forecast-density</link>
      <description><![CDATA[我正在阅读 Hyndman &amp; Athanasopoulos 的《预测：原理与实践》第二版 (FPP2)。（我知道有第三版。）在关于指数平滑的章节中，第 7.7 节讨论了使用指数平滑状态空间模型进行预测，并说道：

ETS 点预测等于预测分布的中位数。对于仅具有加性成分的模型，预测分布为正态分布，因此中位数和均值相等。对于具有乘性误差或乘性季节性的 ETS 模型，点预测将不等于预测分布的均值。
（重点是我加的）

我对第一句话感到疑惑。状态空间模型中是否存在某种固有的东西使得点预测成为中位数？或者这仅仅是 ETS 方法作者的选择？由于状态空间模型无缝地（？）生成密度预测，因此用户（例如作者）可以选择分布的任何派生特征作为点预测，中位数就是其中之一。]]></description>
      <guid>https://stats.stackexchange.com/questions/654766/why-is-exponential-smoothing-forecast-the-median-of-the-forecast-density</guid>
      <pubDate>Mon, 23 Sep 2024 09:17:04 GMT</pubDate>
    </item>
    <item>
      <title>交付预测模型中实现 ETA 平稳过渡的最佳方法</title>
      <link>https://stats.stackexchange.com/questions/652343/best-approach-to-smooth-eta-transitions-in-delivery-prediction-models</link>
      <description><![CDATA[我正在使用随时间演变的预测模型来显示物品交付的 ETA（预计到达时间）。我面临的问题涉及平滑初始和后续 ETA 预测之间的过渡。
问题描述
初始预测准确度：该模型最初提供的 ETA 非常不准确（附图中的星号代表此初始预测）。随着时间的推移和更多信息的出现，ETA 预测变得更加准确。这可能导致第一次和第二次预测之间出现较大的差距（20-30 分钟）。
稳定预测：第二次预测后，ETA 通常会在一段时间内保持不变，然后最终更新。例如，在提供的图中，ETA 从 17:31 到 17:37 保持在 10 分钟，然后开始略微下降。
当前方法
我正在使用简单的指数加权移动平均线平滑 ETA 值以处理从初始不准确预测到更准确的后续预测的过渡。
问题：
处理大差距：有哪些有效的技术可以平滑或减轻初始和第二个 ETA 预测之间的 20 分钟差距？（这是我主要关心的问题）
解决稳定的 ETA 值：应该如何处理 ETA 几分钟内不变的问题？是否有基于用户体验的理由来调整此行为，或者是否可以接受？
附加上下文：
我不确定简单地将平滑函数应用于 ETA 值是否是最佳解决方案，或者是否有更复杂的方法来有效地处理这两个问题。任何有关改进 ETA 预测显示的见解或建议都将不胜感激]]></description>
      <guid>https://stats.stackexchange.com/questions/652343/best-approach-to-smooth-eta-transitions-in-delivery-prediction-models</guid>
      <pubDate>Mon, 05 Aug 2024 16:00:39 GMT</pubDate>
    </item>
    </channel>
</rss>