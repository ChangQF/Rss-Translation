<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 15 Nov 2024 03:29:18 GMT</lastBuildDate>
    <item>
      <title>“完美”数据的标准误差太小</title>
      <link>https://stats.stackexchange.com/questions/657299/standard-error-is-too-small-on-perfect-data</link>
      <description><![CDATA[在学习线性回归时，我遇到了这种奇怪的情况。
我正在将数据拟合到线性模型$\beta_0 + \beta_1 x$，并运行 Wald 检验来检查是否$H_0: \beta_0 = 0$。这是一个简单的 Python 函数，它返回 $\hat{\beta_0}$、$\mathrm{se}(\hat{\beta_0})$ 和 $p$-score:
import numpy as np
from scipy.stats import norm

np.random.seed(0)

def test_regress(x, y):
X = np.vstack([np.ones_like(x), x]).T
params = np.linalg.lstsq(X, y)[0]

residuals = y - X @ params
n, p = X.shape
var = np.sum(residuals**2) / (n - p)
cov = var * np.linalg.inv(X.T @ X)
se = np.sqrt(np.diag(cov))

w = (params[0]) / se[0]
p = 2 * norm.cdf(-np.abs(w))
return params[0], se[0], p

这适用于具有 i.i.d 残差的数据：
&gt;&gt;&gt; x = np.arange(1000)
&gt;&gt;&gt; y = x + np.random.normal(size=1000)
&gt;&gt;&gt; test_regress(x, y)
(np.float64(-0.035945884568210226),
np.float64(0.06244021277994775),
np.float64(0.5648282169352368))

p 值很大，因此不能拒绝零假设。
但是，它在完全没有残差的数据上失败了：
&gt;&gt;&gt; x = np.arange(1000)
&gt;&gt;&gt; y = x
&gt;&gt;&gt; test_regress(x, y)
(np.float64(1.5683571961333255e-13),
np.float64(1.1045055269032826e-14),
np.float64(9.209482575035801e-46))

$\beta_0$ 几乎为零，但标准误差太小，因此 p 值极小。
结果并不令人惊讶，而且在现实世界中确实不太可能发生。但理论上，我该如何处理这种情况？我是否需要先测试不可忽略的 $\hat{se}$？]]></description>
      <guid>https://stats.stackexchange.com/questions/657299/standard-error-is-too-small-on-perfect-data</guid>
      <pubDate>Fri, 15 Nov 2024 02:28:49 GMT</pubDate>
    </item>
    <item>
      <title>阶梯楔形设计的协变量约束随机化：R 或 SAS 实现</title>
      <link>https://stats.stackexchange.com/questions/657296/covariate-constrained-randomization-for-stepped-wedge-design-r-or-sas-implement</link>
      <description><![CDATA[我目前正在研究一个涉及 28 个集群和 12 个时间段的阶梯式楔形设计 (SWD)，并且在实施协变量约束随机化 (CCR) 方面遇到了困难。
我需要有关可以处理阶梯式楔形设计的协变量约束随机化的任何 R 或 SAS 包的建议。我将不胜感激任何有关如何在 R 或 SAS 中实现这一点的示例代码或指导，或任何有关如何在将集群分配给干预期时确保协变量平衡的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/657296/covariate-constrained-randomization-for-stepped-wedge-design-r-or-sas-implement</guid>
      <pubDate>Fri, 15 Nov 2024 01:55:33 GMT</pubDate>
    </item>
    <item>
      <title>RMSE 的替代方法来评估稳定分布参数的拟合优度</title>
      <link>https://stats.stackexchange.com/questions/657293/alternatives-for-rmse-to-eavluate-goodness-of-fit-for-stable-distribution-parame</link>
      <description><![CDATA[我正在估计稳定分布的参数（alpha、beta、gamma、delta） 来自数值数据列表。我使用了一个包来从一种稳定分布（特别是标准 Levy 分布）生成数据。
if (!require(&quot;stable&quot;)) {
install.packages(&quot;stable&quot; , repos = &quot;http://R-Forge.R-project.org&quot;)
library(stable)
}

# 设置可重复性的种子
set.seed(123)

# 从标准 Lévy 分布生成 100 个点
levy_data &lt;- rstable （n = 100，alpha = 0.5，beta = 1，gamma = 1，delta = 0，pm = 0）

之后，我使用简单的 MLE 方法来找到四个参数.
# 执行最大似然估计 (MLE) 来估计参数
levy_fit &lt;- stable.fit(levy_data, method = 1) # 使用 method = 1 进行 MLE

# 打印估计的参数
print(levy_fit)


现在，由于对于实际数据集，我们不知道参数。因此，我们需要一种方法来衡量我们获得的理论分布与数据的拟合优度。我的教授建议使用 RMSE 来评估拟合优度，类似于机器学习模型评估。然而，由于没有依赖变量和 RMSE 比较预测值与实际观测值，我质疑它是否适合这项任务。
我相信对数似然法可能更适合在这种情况下评估优劣，我正在研究其他方法以及。我很感激任何关于以下方面的见解：

为什么 RMSE 可能不适合概率分布拟合。
测量稳定分布拟合优度的替代方法。&lt; /li&gt;
]]></description>
      <guid>https://stats.stackexchange.com/questions/657293/alternatives-for-rmse-to-eavluate-goodness-of-fit-for-stable-distribution-parame</guid>
      <pubDate>Fri, 15 Nov 2024 00:34:22 GMT</pubDate>
    </item>
    <item>
      <title>分层测试集引导法用于度量 UQ 的缺点</title>
      <link>https://stats.stackexchange.com/questions/657292/drawbacks-of-stratified-test-set-bootstrapping-for-metric-uq</link>
      <description><![CDATA[我正在使用测试集（百分位数）引导来量化各种模型性能指标（例如 AUROC、AUPR 等）的不确定性。
为避免混淆，方法很简单：

引导测试集
计算每个引导测试集上的目标指标，为我提供指标值的分布
计算指标分布的百分位数，为我提供 CI。

（是的，我知道对于各种特定指标，有更有效的方法来获取 CI；我在工具箱中使用它作为一种万能的 UQ 方法，适用于我可以向其抛出的任何/所有指标。）
现在回答我的问题：特别是在较小的测试集或类别不平衡性很强的情况下，在自举样本中，经常出现没有正值或负值的现象，从而导致各种指标除以零。
解决这个问题的一种方法是简单地使用分层自举法，即在整个自举样本中保持正值的数量（或指标分母中的相关数字）不变，这种方法有什么重要的缺点吗？为什么这不是默认方法？或者它是？]]></description>
      <guid>https://stats.stackexchange.com/questions/657292/drawbacks-of-stratified-test-set-bootstrapping-for-metric-uq</guid>
      <pubDate>Fri, 15 Nov 2024 00:06:39 GMT</pubDate>
    </item>
    <item>
      <title>在 LongituRF 中使用混合效应随机森林 (MERF) 时遇到的错误</title>
      <link>https://stats.stackexchange.com/questions/657289/error-experienced-when-using-mixed-effects-random-forest-merf-in-longiturf</link>
      <description><![CDATA[我一直在使用 LongituRF 运行混合效应随机森林模型，并且对 predict.longituRF() 函数有疑问。
我使用训练数据 (n = 222) 创建了一个 MERF，并且想使用此模型拟合来预测子集（测试数据，n = 75）。但是，当我使用代码时：
predictions_merf_df &lt;-
predict(
object = MERF_bird_Shannon,
X = data.frame(Test_list$X),
id = Test_list$id,
Z = Test_list$Z,
time = Test_list$time)

我收到错误：
Ypred[w] 中的错误 &lt;- f[w] + Z[w, , drop = FALSE] %*% object$random_effects[k, :
replacement 的长度为零

我遇到了一些困难，如果有人愿意分享见解，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657289/error-experienced-when-using-mixed-effects-random-forest-merf-in-longiturf</guid>
      <pubDate>Thu, 14 Nov 2024 22:47:43 GMT</pubDate>
    </item>
    <item>
      <title>auto.arima 中非平稳模型的拟合值</title>
      <link>https://stats.stackexchange.com/questions/657285/fitted-values-in-auto-arima-for-non-stationary-models</link>
      <description><![CDATA[如果我理解正确的话，在 R 预测包的 auto.arima 中返回的拟合值是模型在估计参数（使用所有训练数据）后给出的一步预测。
假设我已拟合非平稳 ARIMA 模型，例如航空公司模型 $(0,1,1)(0,1,1)_{12}$。在这种情况下，如何计算前 $13$ 个拟合值？由于我们没有关于该系列初始状态的信息，我们如何计算第一个时期的一步预测？请注意，这种情况与平稳情况完全不同，在平稳情况下，我们可以使用平稳均值和方差作为初始状态。
我已经看到 auto.arima 依赖于 stats 包中的 arima 函数，所以我想问题也可以改写为：在非平稳情况下，arima 函数如何计算前几个时期的残差？
提前非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657285/fitted-values-in-auto-arima-for-non-stationary-models</guid>
      <pubDate>Thu, 14 Nov 2024 21:32:15 GMT</pubDate>
    </item>
    <item>
      <title>如何将从 flexsurv 包获得的回归系数的标准误差转换为来自 survivor 包的标准误差？</title>
      <link>https://stats.stackexchange.com/questions/657281/how-to-convert-the-standard-errors-of-regression-co-efficients-obtained-from-the</link>
      <description><![CDATA[我理解 flexsurv 包中使用的参数化与 survival 包中的参数化不同。我使用这两个包拟合了相同的对数正态回归模型。flexsurvreg 的文档提到，它只是 survreg 的包装器，用于对数正态分布，并且它只将结果转换为 flexsurvreg 中使用的参数化。我想了解如何对回归系数标准误差进行转换。输出中的点估计匹配，但回归系数的标准误差不匹配。 （请注意，Scale 的标准误差（在 survival 包中）与 flexsurvreg 中 sdlog 的标准误差相匹配。只是回归系数的标准误差不同）数据可在此处获得，其中独立变量 Stress box cox 已用 lambda = -2 进行变换。
输出自survival:
&gt; para_fit_logNormal.lambda &lt;- survivor::survreg(Surv(Cycles, delta) ~ Stress.boxCox, data = sheets, dist = &quot;lognormal&quot;)
&gt; 
&gt; summary(para_fit_logNormal.lambda)

调用:
survival::survreg(formula = Surv(Cycles, delta) ~ Stress.boxCox, 
data = sheets, dist = &quot;lognormal&quot;)
Value Std.误差 z p
（截距） 8.10e+05 1.76e+04 46.0 &lt;2e-16
Stress.boxCox -1.62e+06 3.52e+04 -46.0 &lt;2e-16
Log（尺度） -7.16e-01 6.69e-02 -10.7 &lt;2e-16

尺度= 0.489 

对数正态分布
Loglik（模型）= -889.6 Loglik（仅截距）= -1065.1
Chisq= 350.97，自由度为 1，p= 2.6e-78 
Newton-Raphson 迭代次数：7 
n= 125 

输出自flexsurvreg:
&gt; (para_fit_logNormal.lambda.flexsurv &lt;- flexsurv::flexsurvreg(Surv(Cycles, delta) ~ Stress.boxCox, data = sheets = LaminatePanel, dist = &quot;lnorm&quot;))
调用:
flexsurv::flexsurvreg(formula = Surv(Cycles, delta) ~ Stress.boxCox, 
data = sheets = LaminatePanel, dist = &quot;lnorm&quot;)

估计值: 
数据平均值估计 L95% U95% 
meanlog NA 8.10e+05 8.10e+05 8.10e+05
sdlog NA 4.89e-01 4.29e-01 5.57e-01
Stress.boxCox 5.00e-01 -1.62e+06 -1.62e+06 -1.62e+06
se exp(est) L95% U95% 
meanlog 2.92e+01 NA NA NA
sdlog 3.26e-02 NA NA NA
Stress.boxCox 5.85e+01 0.00e+00 0.00e+00 0.00e+00

N = 125，事件：115，删失：10
总风险时间：684875.4
对数似然 = -889.6152，df = 3
AIC = 1785.23

]]></description>
      <guid>https://stats.stackexchange.com/questions/657281/how-to-convert-the-standard-errors-of-regression-co-efficients-obtained-from-the</guid>
      <pubDate>Thu, 14 Nov 2024 21:02:08 GMT</pubDate>
    </item>
    <item>
      <title>我们可以用引导回归系数来代替数据吗？</title>
      <link>https://stats.stackexchange.com/questions/657271/can-we-bootstrap-regression-coefficients-instead-of-data</link>
      <description><![CDATA[我对在传统 bootstrap 方法可能很复杂（例如纵向/聚类数据、不规则参数，例如两个边际效应估计值的比率等）的情况下使用 bootstrap 有疑问（例如边际效应比率的置信区间？（GAM 回归））。
以下是我对传统 bootstrap 的解释：

原始模型：$y_i = X_i\beta + \epsilon_i$
原始估计：$\hat{\beta}$ 从拟合模型到 $(y_i, X_i)$，其中 $i=1,...,n$
对于 bootstrap 迭代 $b = 1,...,B$:

从 $(y_i, X_i)$ 重新取样，得到 $(y_i^{(b)}, X_i^{(b)})$
通过将模型拟合到每个 bootstrap 样本，得到 $\hat{\beta}^{(b)}$


Bootstrap 分布来自 $\{\hat{\beta}^{(1)},...,\hat{\beta}^{(B)}\}$

我在想，当这种传统的引导方法可能无法实现时，也许我们可以使用参数估计的渐近方差性质来推导引导估计？

例如，假设我对某些数据拟合回归模型。使用渐近方差性质，我知道（对于特定类型的模型）：
$$ 
\begin{pmatrix} \hat{\beta}_1 \\ \hat{\beta}_2 \end{pmatrix} \sim N\left(\begin{pmatrix} \beta_1 \\ \beta_2 \end{pmatrix}, \begin{pmatrix} \sigma_{11} &amp; \sigma_{12} \\ \sigma_{12} &amp; \sigma_{22} \end{pmatrix}\right)
$$

现在，对于$s = 1,...,S$，我从多元正态分布中抽取样本分布：

生成：
$$\begin{pmatrix} \beta_1^{(s)} \\ \beta_2^{(s)} \end{pmatrix} \sim N\left(\begin{pmatrix} \hat{\beta}_1 \\ \hat{\beta}_2 \end{pmatrix}, \begin{pmatrix} \hat{\sigma}_{11} &amp; \hat{\sigma}_{12} \\ \hat{\sigma}_{12} &amp; \hat{\sigma}_{22} \end{pmatrix}\right)$$




假设我是对某个依赖于 $\hat{\beta_1}$ 和 $\hat{\beta_2}$ 的数量 $\hat{\theta}$ 感兴趣，例如 $\hat{\theta} = \hat{\beta_1} / \hat{\beta_2}$。这是一个不规则参数，根据模型推导方差的分析公式可能非常复杂。


我现在计算比率 $\theta^{(s)} = \beta_1^{(s)}/\beta_2^{(s)}$

并且 $\theta$ 的分布来自 $\{\theta^{(1)},...,\theta^{(S)}\}$


当无法使用引导方法时，这是一种获得置信区间的统计有效方法吗？也就是说，是否有可能引导回归系数（通过模拟它们的联合分布）而不是引导数据？

注意：需要特别注意确定回归系数的正确联合概率分布。
]]></description>
      <guid>https://stats.stackexchange.com/questions/657271/can-we-bootstrap-regression-coefficients-instead-of-data</guid>
      <pubDate>Thu, 14 Nov 2024 18:40:16 GMT</pubDate>
    </item>
    <item>
      <title>二项式模型与 GLM 偏移泊松模型之间的区别是什么</title>
      <link>https://stats.stackexchange.com/questions/657270/whats-the-difference-between-binomial-model-versus-poisson-model-with-an-offset</link>
      <description><![CDATA[我正在处理由 $( i = 1, \ldots, n )$ 索引的分箱数据，其中对于每个箱 $i$，我有：

$( X_i )$：成功次数
$( N_i )$：总试验次数

我想对每个箱内的成功比例进行建模，并且我正在尝试决定是使用 二项式 还是 泊松 广义线性模型 (GLM)。
当前方法：
我的理解是，我可以用二项式的最大似然估计来定义成功比例数据为：
\begin{align}
p_i = \frac{X_i}{N_i}
\end{align&gt;
一种常见的方法是使用二项式 GLM 对 $ p_i $ 进行建模：
\begin{align}
\text{logit}\left( E(p_i) \right) = \beta_0 + \beta_1 x_{1,i} + \dots + \beta_{p-1} x_{p-1,i}
\end{align&gt;
或者，我可以使用带有偏移的 泊松模型 直接对计数 $ X_i $ 进行建模：
\begin{align}
\log\left(E(X_i)\right) = \beta_0 + \beta_1 x_{1,i} + \dots + \beta_{p-1} x_{p-1,i} + \log(N_i)
\end{align&gt;
因为我们可以将其重写为：
\begin{align}
\log\left(E(X_i)\right) - \log(N_i) = \log\left(\frac{E(X_i)}{N_i}\right),
\end{align&gt;
这有效地模拟了相对于总试验次数的成功率（或比例）。
问题：
鉴于我的主要兴趣是模拟相对于总试验次数的成功发生率每个箱子（即每个空间/时间箱子 $ i $ 中的成功比例 $ \frac{X_i}{N_i} $），我应该支持哪种模型：二项式 GLM 还是带偏移的泊松 GLM？
具体来说：

是否存在一种模型比另一种模型更合适的情况？
选择是否取决于我的数据的属性（例如，$ N_i $ 在箱子之间的分布或比例的变化）？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657270/whats-the-difference-between-binomial-model-versus-poisson-model-with-an-offset</guid>
      <pubDate>Thu, 14 Nov 2024 18:33:43 GMT</pubDate>
    </item>
    <item>
      <title>证明 (X, Y, Z) 相互独立意味着在给定 Z 的情况下 X 和 Y 是独立的</title>
      <link>https://stats.stackexchange.com/questions/657266/proving-mutual-independence-of-x-y-z-implies-independence-of-x-and-y-given-z</link>
      <description><![CDATA[我想证明或反驳以下结果：
设$(\Omega, \mathcal F, \mathbb P)$为概率空间，且$X, Y, Z : \Omega \to \mathbb R$为相互独立的、$(\mathcal F, \mathcal B(\mathbb R))$-可测随机变量；那么 $X$ 和 $Y$ 在给定 $Z$ 的情况下是独立的。
我读到了以下问题的答案：在给定 Z 的情况下，X、Y、Z 的相互独立性是否意味着 X 和 Y 的条件独立性，然而在我看来，它假设 $X$、$Y$ 和 $Z$ 具有密度（相对于同一测量）。这不是我希望做出的假设。
我想使用的条件独立性、概率和独立性的特征如下（如果它们不正确，请告知）：

$X$ 和 $Y$ 是独立的，给定 $Z$，如果 $\mathbb P((X, Y) \in A \times B | Z) = \mathbb P(X \in A | Z) \mathbb P(Y \in B | Z)$ 对每对 borelian 集 $(A, B)$ 成立；
$\mathbb P(Y \in A | Z) = \mathbb E[\boldsymbol 1_{A} \circ Y | Z]$ 对于每个 borelian 集 $A$;
$\mathbb E[U | Z]$ 对于一个$(\mathcal F, \mathcal B(\mathbb R))$-可测变量，定义为唯一（几乎处处相等）$(\sigma(Z), \mathcal B(\mathbb R))$-可测随机变量，满足$\int_\Omega \boldsymbol (1_A \circ U)\ U \text d\mathbb P = \int_\Omega \mathbb E[U | Z] \boldsymbol 1_A \circ U \text d \mathbb P$ 对于每个 borelian 集 $A \subseteq \mathbb R$。

我仍然对所有这些符号感到困惑，并希望正式推导结果，尽可能合理地使用测度理论符号而不是概率符号。
我的问题是：

结果在一般情况下仍然正确吗？
我给出的预期期望定义是否正确（它应该是将我的教科书中给出的定义翻译成测度理论语言，但我可能遗漏了一些东西）？
这种表征是证明结果的合理起点吗？
我应该如何开始？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657266/proving-mutual-independence-of-x-y-z-implies-independence-of-x-and-y-given-z</guid>
      <pubDate>Thu, 14 Nov 2024 18:11:34 GMT</pubDate>
    </item>
    <item>
      <title>证明 $X=Y$ 几乎肯定 $\implies E[X] = E[Y]$</title>
      <link>https://stats.stackexchange.com/questions/657263/prove-x-y-almost-surely-implies-ex-ey</link>
      <description><![CDATA[我不太确定我们如何从概率得到期望。以下是我目前所得到的：

几乎肯定地假设 $X=Y$。根据定义，$P(X=Y)=1 \implies P(X-Y=0)=1$;
设 $Z=X-Y$，则 $P(Z=0)=1$;
（一些中间步骤）
$E(Z) = 0 \implies E[X] = E[Y]$。
]]></description>
      <guid>https://stats.stackexchange.com/questions/657263/prove-x-y-almost-surely-implies-ex-ey</guid>
      <pubDate>Thu, 14 Nov 2024 17:47:04 GMT</pubDate>
    </item>
    <item>
      <title>生物标志物发现中的事后多重比较调整</title>
      <link>https://stats.stackexchange.com/questions/657261/post-hoc-multiple-comparisons-adjustment-in-biomarker-discovery</link>
      <description><![CDATA[我有一个数据集，其中包含 3 个组中脑脊液 (CSF) 和血清中测试的 10 种生物标志物。我想在组对之间事后比较 6 种分析物（其水平升高）。此外，患有炎症的患者更有可能同时出现多种分析物升高。我需要调整 p 值以进行多重比较，但我不确定最佳方法。
以下是我的具体问题：
1. Holm-Bonferroni 与 FDR：鉴于我正在进行事后比较并控制多重比较，哪种调整方法更适合我的情况？
2. 由于我同时拥有 CSF 和血清测量值，在应用 p 值调整时，我是否可以考虑分别测试它们（生物学上不同的行为），或者将它们视为一组比较会更好？
3. 要调整哪些测试？：我正在比较组对之间的 6 种分析物（那些水平升高的分析物）。我应该仅根据这 6 种分析物调整 p 值，还是应该针对所有 10 种生物标志物进行调整（即使只有 6 种升高）？
4. 多重共线性：鉴于炎症患者往往会同时出现多种分析物升高，我担心多重共线性。我应该如何解决这个问题？
我很感激任何指导或建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/657261/post-hoc-multiple-comparisons-adjustment-in-biomarker-discovery</guid>
      <pubDate>Thu, 14 Nov 2024 17:03:05 GMT</pubDate>
    </item>
    <item>
      <title>比较幸存和未幸存的一组个体的不同时间点的测量值（1、2、3、4）</title>
      <link>https://stats.stackexchange.com/questions/657254/comparing-different-timepoints-of-measurments-1-2-3-4-for-a-group-of-individua</link>
      <description><![CDATA[希望您能帮上忙！？在大多数情况下，我们会对一组从疾病中幸存或未幸存（生存）的个体（重复测量）进行基于时间序列的测量（CD8T）。基于时间点的测量部分不完整，因为缺少数据，这就是为什么有时系列不完整（Time_Point）。我们想知道成分（CD8T）随时间的变化是否对生存有影响。此外，我们希望根据年龄和性别进行校正。您会建议什么模型？非常感谢任何帮助和设计、对比和在 R 中应用的代码。期待您的建议。希望您能为我指明正确的方向。
提前致谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/657254/comparing-different-timepoints-of-measurments-1-2-3-4-for-a-group-of-individua</guid>
      <pubDate>Thu, 14 Nov 2024 15:07:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的累积链接混合模型的阈值系数看起来很大？</title>
      <link>https://stats.stackexchange.com/questions/657284/why-are-the-threshold-coefficients-of-my-cumulative-link-mixed-model-seemingly-v</link>
      <description><![CDATA[我正在使用 ordinal 包拟合累积链接混合模型。数据是重复测量（在三个时间点进行的调查）。该模型收敛没有问题，估计值在我看来是合理的，但阈值系数似乎非常夸大，我很想知道潜在原因和后果（即，该模型是否仍然可能提供信息）。
library(ordinal)
data(q1_data)

head(q1_data)

id day response sex glp weight1 weight2
&lt;dbl&gt; &lt;fct&gt; &lt;ord&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 1 day7 5 m 100. -1.40 -1.45
2 1 day2 4 m 100. -1.40 -1.45
3 1 day0 3 m 100. -1.40 -1.45
4 2 day7 5 f 97.8 -1.10 -1.55
5 2 day2 5 f 97.8 -1.10 -1.55
6 2 day0 6 f 97.8 -1.10 -1.55

运行模型：
q1_clmm &lt;- clmm(response ~ day + weight1 * weight2 + glp + (1 | id),
data = q1_data,
link = &quot;logit&quot;,
nAGQ = 5)
summary(q1_clmm)

不确定我应该粘贴多少，但要给出完整的上下文：
 累积链接混合模型采用自适应高斯-埃尔米特 
具有 5 个求积点的求积近似 

公式：响应 ~ day + weight1 * weight2 + glp + (1 | id)

数据：q1_data

链接阈值 nobs logLik AIC niter max.grad cond.H 
logit 灵活 159 -219.91 465.82 793(3020) 4.28e-04 6.3e+06

随机效应：
组名称方差标准差
id（截距）1.194 1.093 
组数：id 53 

系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
dayday2 -0.59368 0.37344 -1.590 0.11189 
dayday7 -0.07920 0.38261 -0.207 0.83602 
weight1 -1.41946 0.46628 -3.044 0.00233 **
weight2 0.39884 0.16354 2.439 0.01473 * 
glp 0.06027 0.02302 2.618 0.00884 **
weight1:weight2 -0.50004 0.17551 -2.849 0.00438 **
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

阈值系数：
估计标准误差 z 值
0|1 -0.2991 2.4189 -0.124
1|2 0.8646 2.2783 0.379
2|3 2.2481 2.2304 1.008
3|4 3.4143 2.2253 1.534
4|5 5.1067 2.2478 2.272
5|6 7.2607 2.3074 3.147

我担心的是阈值估计值和 SE 非常高。越来越高的值也与我预期的方向相反，因为数据在 1-3 左右有点稀疏，而在 4-6 左右响应频率较高。我的理解是，这些是 logdds，指数结果为 1423 的 OR 和 5|6 截止值的上限 OR 为 131018。
我推测这是一个问题？这是否意味着模型很难准确地建模数据？我的建模过程出了什么问题？过度拟合的可能性（性能指标似乎合理，例如，R2 cond 为 0.4，RMSE = 4.34，并且这些值不会因进一步简化模型而发生显着改变）？
如果需要其他信息，请告诉我，我会更新此 OP。]]></description>
      <guid>https://stats.stackexchange.com/questions/657284/why-are-the-threshold-coefficients-of-my-cumulative-link-mixed-model-seemingly-v</guid>
      <pubDate>Thu, 14 Nov 2024 08:16:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么高斯过程回归（GPR）是非参数的？</title>
      <link>https://stats.stackexchange.com/questions/657239/why-gaussian-process-regression-gpr-is-non-parametric</link>
      <description><![CDATA[鉴于高斯过程 (GP) 回归依赖于具有特定超参数的核来控制点之间的关系和平滑度，GP 回归真的可以被视为非参数技术吗？我有以下几点。

GP 的行为在很大程度上取决于核的参数结构，这限制了函数形式与某些假设（例如平滑度、周期性）的一致性。这使其成为由超参数控制的确定性过程，而不是固有灵活的无参数模型。

与任何参数技术（例如 DFT 或 AR 模型）一样，随着数据量的增长，GP 可以更精确地估计更适合数据的超参数。这种数据改进可以被认为类似于减少参数估计中的次优性，而不是反映开放的无参数结构。此外，从后验分布中绘制多个函数的能力（如使用抽样或引导方法的参数模型）并不意味着非参数模型。

虽然每个 GP 实现都代表一个潜在函数，但它们都遵循由内核建立的底层规则，该规则有效地控制了样本拟合观察到的数据的方式。因此，仅仅因为函数形式不是完全可预测而将 GP 标记为非参数可能是不准确的，因为内核参数化并限制了 GP 灵活性。


总之，由于内核作为指导模型行为的明确参数化结构的作用，GP 回归不应该被视为参数方法吗？在我看来，它确实是一个参数核估计器，当与贝叶斯框架一起使用时，会产生后验预测。]]></description>
      <guid>https://stats.stackexchange.com/questions/657239/why-gaussian-process-regression-gpr-is-non-parametric</guid>
      <pubDate>Thu, 14 Nov 2024 06:48:07 GMT</pubDate>
    </item>
    </channel>
</rss>