<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 27 Dec 2024 09:17:15 GMT</lastBuildDate>
    <item>
      <title>获取图表中特定转换的频率</title>
      <link>https://stats.stackexchange.com/questions/659265/get-frequency-of-specific-transition-in-graph</link>
      <description><![CDATA[链中有 3 种不同的状态：ST、GRC_i 和 GRC_j。
状态之间存在以下边：
EDGES = [
# 源、目标、名称
(&#39;ST&#39;, &#39;GRC_i&#39;, &#39;TDL_i&#39;),
(&#39;ST&#39;, &#39;GRC_j&#39;, &#39;TDL_j&#39;),
(&#39;GRC_i&#39;, &#39;GRC_j&#39;, &#39;RVL_j&#39;),
(&#39;GRC_j&#39;, &#39;GRC_i&#39;, &#39;RVL_i&#39;),
(&#39;GRC_j&#39;, &#39;ST&#39;, &#39;SUL_i&#39;),
(&#39;GRC_i&#39;, &#39;ST&#39;, &#39;SUL_j&#39;),

]

图表如下所示：

已知TDL_i、TDL_i、RVL_i 和 RVL_j 的值。
链始终从 ST 开始。
如果 RVL_i = RVL_j = 0，则 SUL_i 等于 max(0, TDL_i - 1)。
是否可以推断其他场景的 SUL_i 和 SUL_j？]]></description>
      <guid>https://stats.stackexchange.com/questions/659265/get-frequency-of-specific-transition-in-graph</guid>
      <pubDate>Fri, 27 Dec 2024 09:15:19 GMT</pubDate>
    </item>
    <item>
      <title>变量误差的线性回归模型</title>
      <link>https://stats.stackexchange.com/questions/659264/linear-regression-model-to-errors-in-variables</link>
      <description><![CDATA[我制作了一个这样的回归模型：
$\mathbf{U}=\mathbf{A}\mathbf{X}+\boldsymbol{\varepsilon}$。这里，$\mathbf{A}$ 是一个未知的 $d_u$ × $d_x$ 矩阵，$\boldsymbol{\varepsilon}$ 是一个 $d_u$ × 1 个随机向量，$\mathbf{U}$ 是一个 $d_u$ × $1$ 随机向量。这里，$\mathbf{U}$ 和 $\mathbf{X}$ 是协变量。有了这个回归模型约束，我想在变量模型中制造误差：
$$\tilde{\mathbf{U}}_i=\mathbf{U}_i+\tilde{\boldsymbol{\varepsilon}}_i $$
对于 $i=1, \cdots n$，其中 $\tilde{\mathbf{U}}:=\mathbf{AX}$ 和 $\tilde{\boldsymbol{\varepsilon}}:=-\boldsymbol{\varepsilon}$。对于变量设置中的常见错误，我想假设 $\mathbf{U}_i \in [0,1]^{d_u}$ 和 $\mathbf{U}_i$ 和 $\tilde{\boldsymbol{\varepsilon}}_i$ 是独立的。这样假设可以吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659264/linear-regression-model-to-errors-in-variables</guid>
      <pubDate>Fri, 27 Dec 2024 09:08:09 GMT</pubDate>
    </item>
    <item>
      <title>如何描述大多数观测值接近右边界的数据集？</title>
      <link>https://stats.stackexchange.com/questions/659263/how-to-describe-a-dataset-that-most-observations-are-close-to-right-boundary</link>
      <description><![CDATA[我有一个数据集$(x, y)$，$x, y \geq 0$并且大多数$x$值都接近右边界（图）。
问题。如何描述关系$y=f(x)$？只能通过直方图？
很明显，我尝试使用线性回归（红线）没有奏效。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659263/how-to-describe-a-dataset-that-most-observations-are-close-to-right-boundary</guid>
      <pubDate>Fri, 27 Dec 2024 08:39:05 GMT</pubDate>
    </item>
    <item>
      <title>塔克 (Tucker) 整体因子载荷一致性系数</title>
      <link>https://stats.stackexchange.com/questions/659260/tuckers-congruence-coefficient-on-entire-factor-loadings</link>
      <description><![CDATA[据我所知，Tucker 一致性系数用于评估样本间因子的一致性。例如，在 R 中对双因子模型执行 EFA 后，使用 fa.congruence() 会生成如下矩阵：
 Sample1_Factor1 Sample1_Factor2
S​​ample2_Factor1 a c
Sample2_Factor2 b d

但是，计算样本之间的一致性，而不是因子之间的一致性是否也合理？例如：
样本 1：
 Factor_1 Factor_2
Item1 0.8 0.1 
Item2 0.9 0.1
Item3 0.7 0.2
Item4 0.1 0.8
Item5 0.2 0.7
Item6 0.1 0.8

样本 2：
 Factor_1 Factor_2
Item1 0.6 0.2 
Item2 0.8 0.1
Item3 0.8 0.1
Item4 0.1 0.7
Item5 0.2 0.8
Item6 0.2 0.7

在这种情况下，我们是否可以将每个样本的因子载荷连接成一列，如下所示，然后计算一致性？
样本 1：（0.8、0.9、0.7、0.1、0.2、0.1、0.1、0.1、0.2、0.8、0.7、0.8）
样本 2：（0.6、0.8、0.8、0.1、0.2、0.2、0.2、0.1、0.1、0.7、0.8、0.7）
以这种方式计算一致性来评估样本之间的因子相似性是否有效？
从我在 EFA 论文中看到的内容来看，一些研究似乎以这种方式计算样本之间的因子相似性，但我对确切的方法感到好奇（因为这些研究没有显示公式或代码；例如：）。
此外，是否可以以类似的方式计算每个项目的一致性？例如：
对于项目 1：使用两个向量（0.8，0.1；样本 1）和（0.6，0.2；样本 2），可以计算一致性吗？
如果您知道这方面的任何参考资料，请告诉我？]]></description>
      <guid>https://stats.stackexchange.com/questions/659260/tuckers-congruence-coefficient-on-entire-factor-loadings</guid>
      <pubDate>Fri, 27 Dec 2024 07:21:31 GMT</pubDate>
    </item>
    <item>
      <title>编码器式 NN 收敛到常数值</title>
      <link>https://stats.stackexchange.com/questions/659257/encoder-style-nn-converging-to-constant-value</link>
      <description><![CDATA[我正在开发一个用于物理模拟的神经网络，它基本上可以归结为接收 3x3 矩阵序列（代表一些物理量）并输出另一个序列。
我首先尝试专门针对序列长度为 9 的情况进行操作，在这种情况下，我只是将整个数组展平并将其馈送到多层感知器，它工作正常。
但是，现在我试图扩展到更大的序列，并且由于矩阵可以相互影响，我决定使用注意机制。本质上，我在预处理期间将每个 3x3 矩阵展平为 9x1 向量，然后先将其通过注意层，然后再通过前馈网络。以下是我的模型现在的样子（我使用的是 PyTorch）：
class miniTransformer(nn.Module):

# 初始化神经网络层
def __init__(self, num_heads = 1, dim_feedforward = 32, dropout = 0.1):
super().__init__()
self.attention = nn.MultiheadAttention(embed_dim=9, num_heads=num_heads, batch_first=True, dropout=dropout)
self.MLP = nn.Sequential(
nn.Linear(9, dim_feedforward),
nn.GELU(),
nn.Linear(dim_feedforward, 9),
)
self.norm1 = nn.LayerNorm(9)
self.norm2 = nn.LayerNorm(9)
self.dropout1 = nn.Dropout(dropout)
self.dropout2 = nn.Dropout(dropout)

def forward(self, src):
# 运行注意头
src2, _ = self.attention(src, src, src)
src = self.norm1(src + self.dropout1(src2))

# 运行多层感知器
src2 = self.MLP(src)
src = self.norm2(src + self.dropout2(src2))
return src

这是我的超参数（批量大小为 64）：
# 实例化模型
model = miniTransformer(num_heads=1, dim_feedforward=128, dropout=0.0)
model.apply(init_weights)

# 损失函数和优化器
loss_fn = nn.MSELoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)

但是，当我尝试在我的数据集上训练新模型时，由于某种原因，它一直收敛到一个常数值（我假设这是平均值）。我的数据集有 100K 个输入/输出序列，我能够在少得多的数据上训练简单的 MLP，所以我认为这不是问题所在。
到目前为止，我已经尝试过：

将输入序列标准化为零均值和单位方差
使用 Xavier 初始化初始化权重以避免梯度消失
剪切梯度以避免梯度爆炸

我能想到的唯一另一件事是网络中的神经元可能不够，所以我应该像在 transformer 中一样添加更多的交替注意/MLP 层吗？
除此之外，我不知道该怎么做，但我的模型仍然收敛到一个常数值，所以我非常感谢你的帮助！
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659257/encoder-style-nn-converging-to-constant-value</guid>
      <pubDate>Fri, 27 Dec 2024 05:26:36 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SPSS 对重复测量方差分析中的两个受试者内因素进行事后分析</title>
      <link>https://stats.stackexchange.com/questions/659256/how-to-perform-post-hoc-analysis-of-interactions-in-repeated-measures-anova-with</link>
      <description><![CDATA[我目前正在对两个受试者内因素进行重复测量方差分析。分析结果显示存在显著的相互作用，我添加了以下命令进行事后分析：
/EMMEANS=TABLES(IV1*IV2) COMPARE(IV1) ADJ(BONFERRONI)
虽然结果显示存在显著影响，但我对分析结果有些怀疑，因此寻求建议。
当我将此命令的结果与配对 t 检验（未校正）的结果进行比较时，配对 t 检验的值与 SPSS 命令生成的结果相同。这让我怀疑 Bonferroni 校正可能未正确应用。
我使用的命令可能存在问题？如果是这样，在 SPSS 中正确应用 Bonferroni 校正的正确命令是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659256/how-to-perform-post-hoc-analysis-of-interactions-in-repeated-measures-anova-with</guid>
      <pubDate>Fri, 27 Dec 2024 05:17:56 GMT</pubDate>
    </item>
    <item>
      <title>位于 Weisburg 的 Sxx 物业</title>
      <link>https://stats.stackexchange.com/questions/659255/property-of-sxx-in-weisburg</link>
      <description><![CDATA[在 Weisburg 所著的《应用线性回归》第 23 页中，我看到了 $S_{xx}$ 的这种关系

有人能解释一下为什么这个等式成立吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659255/property-of-sxx-in-weisburg</guid>
      <pubDate>Fri, 27 Dec 2024 05:08:30 GMT</pubDate>
    </item>
    <item>
      <title>与平方偏差和相关的关系</title>
      <link>https://stats.stackexchange.com/questions/659253/relationship-related-to-sum-of-squared-deviations</link>
      <description><![CDATA[我试图在线性回归的背景下证明这个等式：
$$
\frac{\sum x_i^2}{n S_{xx}} = \frac{1}{n} + \frac{\bar{x}^2}{S_{xx}}
$$
其中
$$
S_{xx} = \sum (x_i - \bar{x})^2
$$
我的推导让我得出：
LHS：
$$
\frac{\sum x_i^2}{n \sum x_i^2 - n^2 \bar{x}^2}
$$
RHS：
$$
\frac{1}{n} + \frac{\bar{x}^2}{\sum x_i^2 - n\bar{x}^2}
$$
使分母相同，我们得到它们的相等性。
但是，我觉得可能有一个更简单的解决方案和推导，或者可以利用一个众所周知的关系来推导这一点。有人可以告诉我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659253/relationship-related-to-sum-of-squared-deviations</guid>
      <pubDate>Fri, 27 Dec 2024 03:41:21 GMT</pubDate>
    </item>
    <item>
      <title>混合模型的贝叶斯模型比较</title>
      <link>https://stats.stackexchange.com/questions/659250/bayesian-model-comparison-for-mixed-models</link>
      <description><![CDATA[如果想要获得每个参数的贝叶斯因子，我们应该使用哪种方法？
a) 定义复杂度不断增加的模型
m0 &lt;- brm(Sepal.Length ~ (1 | Species), data = iris)
m1 &lt;- brm(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
m2 &lt;- brm(Sepal.Length ~ Petal.Length + (Petal.Length | Species), data = iris)
m3 &lt;- brm(Sepal.Length ~ Petal.Length + Petal.Width + (Petal.Length | Species), data = iris)
m4 &lt;- brm(Sepal.Length ~ Petal.Length * Petal.Width + (Petal.Length | Species), data = iris)

b) 排除以下参数兴趣
m0 &lt;- brm(Sepal.Length ~ 0 + Petal.Length * Petal.Width + (Petal.Length | 种类), 数据 = iris)
m1 &lt;- brm(Sepal.Length ~ Petal.Length + Petal.Length :Petal.Width + (Petal.Length | 种类), 数据 = iris)
m2 &lt;- brm(Sepal.Length ~ Petal.Width + Petal.Length :Petal.Width + (Petal.Length | 种类), 数据 = iris)
m3 &lt;- brm(Sepal.Length ~ Petal.Length + Petal.Width + (Petal.Length |物种), 数据 = iris)
m4 &lt;- brm(Sepal.Length ~ Petal.Length * Petal.Width + (Petal.Length | 物种), 数据 = iris)

如果第一种方法是正确的，那么如何处理多个主效应和相互作用？
例如，如果有 4 个主效应及其相应的相互作用怎么办？
模型 &lt;- brm(Sepal.Length ~ z*x*c*v + (1 | 物种), 数据 = iris)

我们需要按照复杂程度增加的顺序拟合哪些模型？我认为很容易预测每个主效应，但那么我们是否需要分别对每个主效应和每个单独的交互项进行处理，然后将所有内容放在一起？
我不能使用 Savage-Dickey 密度比，因为我们使用的是未知的先验，因为我们决定在频率论模型之后运行这些，所以我们不想让结果偏向与频率论结果一致。]]></description>
      <guid>https://stats.stackexchange.com/questions/659250/bayesian-model-comparison-for-mixed-models</guid>
      <pubDate>Fri, 27 Dec 2024 01:43:42 GMT</pubDate>
    </item>
    <item>
      <title>在解释结果时，我应该按原样报告回归中二次项的系数还是报告平方根？</title>
      <link>https://stats.stackexchange.com/questions/659248/when-interpreting-results-should-i-report-the-coefficient-for-the-quadratic-ter</link>
      <description><![CDATA[关于 CV 相关主题的问题有很多（例如这里），但我似乎找不到我的确切问题的答案。我以为我知道这一点，但最近我对我的知识产生了怀疑，想核实一下。
假设我对预测变量 X 进行标准高斯回归，其中线性和二次项。我们将结果称为 Y。线性系数为 4，二次系数为 -2。为简单起见，我省略了截距、方差等。我想用一个句子来解释结果。
这样说是否正确：“X 每增加 1 个单位，Y 估计就会增加 4 个单位，但 X 每增加 1 个单位，Y 的增长率就会降低 2 个单位。”
...或者我在解释二次方程时应该取二次系数的平方根（即“X 每增加 1 个单位，Y 的增长率就会降低 1.41 个单位”）？]]></description>
      <guid>https://stats.stackexchange.com/questions/659248/when-interpreting-results-should-i-report-the-coefficient-for-the-quadratic-ter</guid>
      <pubDate>Fri, 27 Dec 2024 00:19:47 GMT</pubDate>
    </item>
    <item>
      <title>有人能给我答案吗？我只是想核对一下 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/659246/can-anyone-please-just-give-me-tge-answer-i-just-want-to-crosscheck</link>
      <description><![CDATA[某大学药学系有两个细胞培养实验室，按天出租。每天的需求数量可以用均值为 2 的泊松分布建模。在 100 个工作日内，您预计有多少次 a) 两个实验室都没有使用？b) 一些实验室请求必须被拒绝/]]></description>
      <guid>https://stats.stackexchange.com/questions/659246/can-anyone-please-just-give-me-tge-answer-i-just-want-to-crosscheck</guid>
      <pubDate>Thu, 26 Dec 2024 23:09:13 GMT</pubDate>
    </item>
    <item>
      <title>根据给定的累积分布 (CDF) 生成概率密度函数 (PDF)</title>
      <link>https://stats.stackexchange.com/questions/659241/make-a-probability-density-function-pdf-from-a-given-cumulative-distribution</link>
      <description><![CDATA[我有一个逆向工程问题：一台机器导出纯文本、具有 7 个百分位数 (CDF_7) 的 CDF 和一个标准差。
我使用 CDF_7 百分位数来计算 PDF。
我计算的 PDF（左，绿色）（使用导出数据 CDF_7，蓝色）与机器中的 PDF（右，红色）不同。理想情况下，PDF 应该相等。

我做错了什么？在下面的函数中，我在百分位数之间插入值。在解决这个问题时，使用标准差有用吗？有没有想过标准差在这里有什么用处？
换句话说：stdev 如何有助于生成正确的 pdf。
我的 Python 代码：
 import numpy as np
import matplotlib.pyplot as plt

def epdf_hist(cdf_7pct, pct, bins_std):
&quot;&quot;&quot;基于累积分布函数 (CDF) 的 7 个百分位值制作直方图 - 经验概率密度函数 (PDF)

将 7 个百分位值插值到 100 个值，然后分箱
:parameter
cdf_7pct：包含 7 个值的 1 维数组，按从高到低排序
pct：7 个百分位数，通常为 [1,5,10,50,90,95,99]
bins_std：包含箱体的 1 维数组，宽度 = 0.2
:returns
100 个插值、分箱值的 pdf，
bins
100 个插值
&quot;&quot;&quot;
d_pct = np.diff(pct)
cdf_100pct = [] # 生成 100 个值
# 在给定的百分位数值之间进行插值
for i in range(0, len(d_pct)):
arr = np.linspace(cdf_7pct[i], cdf_7pct[i + 1], num=d_pct[i], end=False) # 最后进行插值
cdf_100pct.extend(arr)
cdf_100pct.extend([cdf_7pct[-1]]) # 添加最后一个
cdf_100pct.extend([min(cdf_7pct)+(min(cdf_7pct) - min(arr))]) # 添加一个额外的
count, bins_count = np.histogram(cdf_100pct, bins=bins_std)
返回 count, bins_count, cdf_100pct

# 累积分布函数 (CDF_7) 导出数据
data = np.array([42.38, 42.31, 42.23, 42.03, 41.83,41.81,41.66])
perc = [1,5,10,50,90,95,99]
stdev = 0.15

# 来自机器的 CDF 值
targetbins = np.array([41.6,41.8, 42.0, 42.2,42.4])
c_targetperc = np.array([100,97,58,12,0])
# 来自机器的 PDF 值
p_targetperc = np.array([3,39,46,12,0])

# 计算
epdf_hist_count, epdf_hist_binscount, cdf_100pct = epdf_hist(data, perc, targetbins)
# 图
fig = plt.figure(figsize=(9, 4), layout=&quot;constrained&quot;)
axs = fig.subplots(1, 2, sharex=True, sharey=True)
axs[0].hist(cdf_100pct,bins=targetbins, density=False, color = &#39;green&#39;, alpha = 0.5, label=&quot;PDF i 计算自 CDF_7&quot;)
axs[1].bar(targetbins,p_targetperc, color=&#39;red&#39;, edgecolor=&#39;black&#39;, width=0.2, align=&#39;edge&#39;, alpha = 0.5，label=&quot;机器中的 PDF&quot;)
axs[1].plot(data,perc, &#39;bo--&#39;, label=&quot;从机器导出：CDF_7&quot;)
fig.suptitle(&quot;分布比较&quot;)
for ax in axs:
ax.grid(True)
ax.legend()
ax.set_xlabel(&quot;dB&quot;)
ax.set_ylabel(&quot;发生概率&quot;)
ax.label_outer()
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/659241/make-a-probability-density-function-pdf-from-a-given-cumulative-distribution</guid>
      <pubDate>Thu, 26 Dec 2024 19:50:59 GMT</pubDate>
    </item>
    <item>
      <title>离策略 TD(0) 推导</title>
      <link>https://stats.stackexchange.com/questions/659222/off-policy-td0-derivation</link>
      <description><![CDATA[在 Sutton 和 Barto 的 RL 书中，它说

比率 $\rho_{t:T-1}$ 将回报转换为正确的预期值：
$$\mathbf{E}[\rho_{t:T-1} G_t | S_t = s] = v_\pi (s).\tag{5.4}$$

书中只提到了这么多，但我想要一个不太复杂的证明，维基百科关于重要性抽样的文章对我来说太抽象了。
在此之后，书中还要求我们

$\textit{练习 6.7 }$ 设计一个 TD(0) 更新的离策略版本，可以与任意目标策略 $\pi$ 和覆盖行为策略 $b$ 一起使用，在每个步骤 $t$ 使用重要性抽样率 $\rho_{t:t}$ $(5.3)$。

我在网上找到了一个解决方案，这也让我感到困惑。特别是有人能否使用总结和基本定义来详细说明练习和方程 5.4 是如何得出的。]]></description>
      <guid>https://stats.stackexchange.com/questions/659222/off-policy-td0-derivation</guid>
      <pubDate>Thu, 26 Dec 2024 12:08:20 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何解释行业驱动数据集中的高 Pearson 相关性但低 Spearman 相关性？[重复]</title>
      <link>https://stats.stackexchange.com/questions/659214/how-should-i-interpret-high-pearson-but-low-spearman-correlations-in-an-industry</link>
      <description><![CDATA[我有一个来自工业锅炉的数据集，我正在分析二氧化碳。我们想了解哪些特征表现出与二氧化碳行为密切相关的趋势。
有趣的是，我发现一些特征与二氧化碳的 Pearson 相关性非常高，但 Spearman 相关性非常低。我应该如何解释这些情况？当一个特征（如 xi）与二氧化碳的 Pearson 相关性很高但 Spearman 相关性很低时，这意味着什么？通常情况下，较高的 Pearson 相关性不是也意味着较高的 Spearman 相关性吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659214/how-should-i-interpret-high-pearson-but-low-spearman-correlations-in-an-industry</guid>
      <pubDate>Thu, 26 Dec 2024 08:42:42 GMT</pubDate>
    </item>
    <item>
      <title>当仅提供数据平均值、样本大小和 t 检验时，如何计算标准差？</title>
      <link>https://stats.stackexchange.com/questions/659205/how-to-calculate-standard-deviation-when-only-mean-of-the-data-sample-size-and</link>
      <description><![CDATA[我发现一项研究报告了两组以下数据：
平均值（7.5 和 8.68）
每组的样本量（26 和 22）
独立单尾 t 检验的 P 值（0.055）
是否有计算标准差的公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/659205/how-to-calculate-standard-deviation-when-only-mean-of-the-data-sample-size-and</guid>
      <pubDate>Wed, 25 Dec 2024 22:33:00 GMT</pubDate>
    </item>
    </channel>
</rss>