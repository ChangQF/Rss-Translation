<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 22 Aug 2024 15:18:44 GMT</lastBuildDate>
    <item>
      <title>为什么每个回归系数的线性条件无偏估计量都可以写成独立变量的加权和？</title>
      <link>https://stats.stackexchange.com/questions/653173/why-can-every-linear-conditionally-unbiased-estimator-of-the-regression-coeffici</link>
      <description><![CDATA[我正在学习 Stock 和 Watson 的《计量经济学导论》，刚刚看到他们讨论高斯-马尔可夫定理的部分。他们的说法很容易接受，但我很难找到正式的论证。
就上下文而言，我们讨论的是简单线性回归 $Y_i = \beta_0 +\beta_1 X_i + u_i$。该语句为：“如果 $\tilde{\beta_1}$ 是线性估计量，那么它可以写成 $\widetilde{\beta}_1=\sum_{i=1}^n a_i Y_i,\text { 其中权重 } a_1, \ldots, a_n \text { 可以依赖于 } X_1, \ldots, X_n \text { 但不依赖于 } Y_1, \ldots, Y_n \text {。 }$
我知道这是一个愚蠢的问题，但有人能解释一下为什么线性估计量必须在独立变量上是线性的，而不是在独立变量和因变量上都是线性的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653173/why-can-every-linear-conditionally-unbiased-estimator-of-the-regression-coeffici</guid>
      <pubDate>Thu, 22 Aug 2024 14:37:34 GMT</pubDate>
    </item>
    <item>
      <title>AIC、BIC 或两者 [重复]</title>
      <link>https://stats.stackexchange.com/questions/653171/aic-bic-or-both</link>
      <description><![CDATA[我正在使用多元线性回归来控制混杂变量。我已经使用贝叶斯信息准则分析了我的数据。使用赤池信息准则是否有优势，也许可以作为稳健性检验（我认识到 AIC 和 BIC 都有各自的问题和局限性）。]]></description>
      <guid>https://stats.stackexchange.com/questions/653171/aic-bic-or-both</guid>
      <pubDate>Thu, 22 Aug 2024 13:44:52 GMT</pubDate>
    </item>
    <item>
      <title>确保三个时间序列预测的总和等于 100</title>
      <link>https://stats.stackexchange.com/questions/653170/making-sure-that-the-sum-of-three-time-series-forecasts-equals-100</link>
      <description><![CDATA[这与昨天的这个问题类似为时间序列预测添加约束
我有 3 个变量：$X_t$、$Y_t$、$Z_t$。
我想要制作 2 个模型：

模型 1：为 $W_t = X_t + Y_t + Z_t$ 创建时间序列模型？
模型 2：$W_t$ 的百分之多少是 $X_t$，$W_t$ 的百分之多少是 $Y_t$，$W_t$ 的百分之多少是 $Z_t$？

我是时间序列建模的新手。我想到这个主意：

为$X_t$、$Y_t$、$Z_t$创建单独的时间序列模型。
使用这些模型获取$X_t$、$Y_t$、$Z_t$的预测。
添加这些预测以获得预测的$W_t$，然后同时获得每个变量的相对百分比。
重复此过程多次，查看$W_t$如何变化以获得预测的 $W_t$ 的引导置信区间

这种方法有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653170/making-sure-that-the-sum-of-three-time-series-forecasts-equals-100</guid>
      <pubDate>Thu, 22 Aug 2024 13:38:29 GMT</pubDate>
    </item>
    <item>
      <title>仅根据比值比和样本总量计算比值比的置信区间</title>
      <link>https://stats.stackexchange.com/questions/653167/calculating-confidence-intervals-for-odds-ratios-based-only-on-odds-ratio-and-to</link>
      <description><![CDATA[我正在运行荟萃分析，许多研究仅报告总样本量和优势比，这使计算抽样方差变得复杂。我可以使用优势比、总样本量和 p 值来确定抽样方差（conv.wald 函数）。但是，这些研究要么没有报告 p 值，要么只提供近似值。
有没有办法仅使用 OR 和总样本来计算置信区间？
我已经编写了下面的函数，但我不完全确定假设 se_or &lt;- sqrt(1/n) 是否正确。
my_func &lt;- function(or, n) {
log_or &lt;- log(or)
se_or &lt;- sqrt(1/n)
z &lt;- qnorm((1 + .95)/2)
log_or_ci_lower = log_or - z*se_or
log_or_ci_upper = log_or + z*se_or
ci_lower = exp(log_or_ci_lower)
ci_upper = exp(log_or_ci_upper)
返回（列表（或，ci_lower，ci_upper））
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/653167/calculating-confidence-intervals-for-odds-ratios-based-only-on-odds-ratio-and-to</guid>
      <pubDate>Thu, 22 Aug 2024 11:59:48 GMT</pubDate>
    </item>
    <item>
      <title>在扑克中，为什么同花比顺子好？</title>
      <link>https://stats.stackexchange.com/questions/653166/in-poker-why-do-flushes-overtake-straights</link>
      <description><![CDATA[5 张牌的扑克牌更有可能是顺子而不是同花。
但 13 张牌的桥牌牌更有可能包含 5 张牌的同花而不是 5 张牌的顺子（来源：我在网上某处读到的）。
对于为什么添加牌会导致同花超过顺子，最直观、最令人信服的解释是什么？
很明显，同花必须在第 17 张牌之前超过顺子，因为不可能有 17 张牌而没有同花，但我更感兴趣的是为什么前几张额外的牌对同花比顺子更有利。我猜答案将涉及争论为什么顺子比同花更具相关性（这意味着你更有可能拿到一手牌，其中许多不同的 5 张牌子集是顺子，这必须与你更有可能拿到一手牌，其中没有 5 张牌子集是顺子来平衡）。]]></description>
      <guid>https://stats.stackexchange.com/questions/653166/in-poker-why-do-flushes-overtake-straights</guid>
      <pubDate>Thu, 22 Aug 2024 11:23:08 GMT</pubDate>
    </item>
    <item>
      <title>手动计算拟合模型的对数似然</title>
      <link>https://stats.stackexchange.com/questions/653165/manually-calculate-loglikelihood-of-fitted-model</link>
      <description><![CDATA[我的目标是计算拟合模型对一些未见数据的对数似然。
为此，我定义了一个函数，用于手动计算一些新数据的对数似然。但是，作为健全性检查，我将新定义函数的结果与现有 logLik() 函数的结果进行了比较，结果不匹配。有人能解释一下我哪里出错了吗？
library(&quot;lme4&quot;)
# 创建数据集
set.seed(123)
n &lt;- 20000

TRT &lt;- rnorm(n, mean = 336.59, sd = 244.09)
zipf &lt;- rnorm(n, mean = 5.83, sd = 1.22)
word_length &lt;- rnorm(n, mean = 4.69, sd = 2.31)
surprisal &lt;- rnorm(n, mean = 5.04, sd = 2.92)
word_sent_index &lt;- as.factor(sample(2:26, n, replace = TRUE))
participant_ID &lt;- as.factor(sample(1:40, n, replace = TRUE))
word_token &lt;- as.factor(sample(1:828, n, replace = TRUE))

df &lt;- data.frame(TRT, zipf, word_length, word_sent_index, surprisal, party_ID, word_token)

# 将数据集拆分为训练集和测试集
Nfolds &lt;- 5
df$folds &lt;- sample(1:Nfolds, size = nrow(df), replace = TRUE)
fold = 5

train_data &lt;- df[df$folds != fold, ]
test_data &lt;- df[df$folds == fold, ]

# 使用拟合 lme4 模型计算新数据集的对数似然函数。
logLik_test &lt;- function(lm, test_X, test_y) {
predictions &lt;- predict(lm, test_X, re.form = ~(1 | contestant_ID) + (1 | word_token), allow.new.levels = TRUE)
stdev &lt;- sigma(lm)
loglik &lt;- sum(dnorm(test_y, predictions, stdev, log=TRUE))
return(loglik)
}

接下来，我在 train_data 上拟合一个混合效应模型，并将 logLik 函数的输出与之前定义的 logLik_test() 进行比较，并使用 train_data 评估拟合度。
TRT_surprisal &lt;- lmer(TRT ~
1 + zipf + word_length + word_sent_index + surprisal +
(1 | contestant_ID) + (1 | word_token), train_data, REML = FALSE)
logLik(TRT_surprisal)
[1] &#39;log Lik.&#39; -111093 (df=31)

logLik_test(TRT_surprisal, train_data, train_data$TRT)
[1] -111063.7

这两个值不匹配，我不知道为什么。
我也尝试了这个问题的答案，但仍然得到两个不同的结果。欢迎任何帮助。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653165/manually-calculate-loglikelihood-of-fitted-model</guid>
      <pubDate>Thu, 22 Aug 2024 10:00:58 GMT</pubDate>
    </item>
    <item>
      <title>交叉熵预测概率</title>
      <link>https://stats.stackexchange.com/questions/653162/cross-entropy-predicted-probability</link>
      <description><![CDATA[在交叉熵中，预测概率分布的总和不需要为 1 吗？
我最近查看了这个视频 https://www.youtube.com/watch?v=ErfnhcEV1O8，其中提到预测概率分布的总和不为 1。]]></description>
      <guid>https://stats.stackexchange.com/questions/653162/cross-entropy-predicted-probability</guid>
      <pubDate>Thu, 22 Aug 2024 09:21:11 GMT</pubDate>
    </item>
    <item>
      <title>MCMC 中离散参数的收敛诊断</title>
      <link>https://stats.stackexchange.com/questions/653161/convergence-diagnostics-for-discrete-parameters-in-mcmc</link>
      <description><![CDATA[我为有限混合模型生成了 MCMC 样本。这包括潜在类别，它们不仅是离散的，而且缺乏排序。
现在我正在尝试评估算法的收敛性。虽然轨迹图有意义，但我不确定自相关或 Rhat 是否有意义。对于 Rhat 统计量，我使用的是 Vehtari 等人于 2019 年新提出的统计量。它可以方便地在 R 中的“后验”包中实现。
我的第一个问题是，哪些指标（如 Rhat）适用于潜在类别等因子变量。（或者也许 Rhat 已经是了，但我忽略了一些东西。）其次，这是否可以在任何地方方便地实现。我在这个项目上的时间表有点紧张。]]></description>
      <guid>https://stats.stackexchange.com/questions/653161/convergence-diagnostics-for-discrete-parameters-in-mcmc</guid>
      <pubDate>Thu, 22 Aug 2024 09:16:18 GMT</pubDate>
    </item>
    <item>
      <title>在定义一致的情况下，如何调和统计和机器学习中偏差和效率/方差术语的混淆示例</title>
      <link>https://stats.stackexchange.com/questions/653158/how-to-reconcile-confusing-examples-of-bias-and-efficiency-variance-terminology</link>
      <description><![CDATA[如果统计学和机器学习领域确实就估计偏差和方差/效率的定义达成一致，那么如何调和 stackexchange 上讨论的术语使用中令人困惑和看似不同的问题？
据我所知，这两个领域一致认为，略有偏差且非常有效的估计量可能比无偏差且效率低下的估计量更受欢迎。因此，复杂性和准确性之间需要权衡。然而我感到困惑：

在机器学习中，低偏差通常被描述为最小化残差，或过度拟合训练数据，导致测试数据/额外样本的方差更大或拟合度更差。
在统计学中，低偏差是指估计量以较小的系统偏差近似一个感兴趣的未知参数，最终可能在额外样本/测试数据中显示出来。

例如，一个完美拟合的估计量是否可以表示 1) 内生性偏差（如统计学中），或 2) 低偏差但可能高方差（如机器学习中）？
SE 上的来源：

统计学和机器学习中的偏差是否意味着一样吗？
“偏见”一词的不同用法在统计/机器学习中
名称的含义：偏差（截距）
效率 - 偏差权衡
机器学习中的偏差和方差是什么？
两种文化，偏差
有偏估计量的方差是否总是小于无偏估计量的方差？
偏差-方差：它真的是一种“权衡”吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653158/how-to-reconcile-confusing-examples-of-bias-and-efficiency-variance-terminology</guid>
      <pubDate>Thu, 22 Aug 2024 08:11:18 GMT</pubDate>
    </item>
    <item>
      <title>贝塔回归模型参数估计值的解释</title>
      <link>https://stats.stackexchange.com/questions/653143/interpretation-of-parameter-estimates-from-a-beta-regression-model</link>
      <description><![CDATA[我在 R 中使用 beta 回归模型。我将用模拟数据进行说明，以便理解解释。假设结果变量称为 outcome，其范围在 0 和 1 之间。我还有两个协变量：treatment，其有 3 个类别（A、B 和 C）和使用标准正态分布模拟的 iq。我的目标是调查结果和协变量之间是否存在关联。
用于模拟数据的 R 代码：
set.seed(1)
mydata = data.frame(outcome=runif(100),treatment = factor(sample(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;),100,replace=TRUE)),iq=rnorm(100))

然后我们可以使用 betareg 函数拟合 beta 回归模型。
library(betareg)
library(tidyverse)
library(dplyr)
library(marginaleffects)
library(ggeffects)
library(ordbetareg)
library(knitr)
library(parameters)

model_beta = betareg(outcome~factor(treatment)+iq | factor(treatment)+iq,
data=mydata,link=&quot;logit&quot;)
summary(model_beta)

模型摘要如下。我理解有两个不同的部分：一个用于均值模型，另一个用于精度模型。由于我们使用了 logit 链接，因此估计值是对数几率估计。
第一个问题：我可以从以下输出中做出推断吗？我可以解释为“如果 iq 增加 1 个单位，则 .......
调用：
betareg(formula = consequence ~ factor(treatment) + iq | factor(treatment) + iq, data = mydata, link = &quot;logit&quot;)

标准化加权残差 2：
最小值 1Q 中位数 3Q 最大值 
-2.5729 -0.5849 0.0389 0.6002 2.0709 

系数（带 logit 链接的均值模型）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -0.02176 0.17159 -0.127 0.899 
因子(治疗)B -0.13444 0.26595 -0.506 0.613 
因子(治疗)C 0.24357 0.26630 0.915 0.360 
iq -0.19714 0.11071 -1.781 0.075 .

Phi 系数（带对数链接的精度模型）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 0.99059 0.20671 4.792 1.65e-06 ***
因子(治疗)B -0.68443 0.28269 -2.421 0.0155 * 
因子(治疗)C -0.12546 0.31100 -0.403 0.6867 
iq 0.07665 0.11955 0.641 0.5214 
---
有效代码: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 

估计量类型：ML（最大似然）
对数似然：8 Df 上的 6.014
伪 R 平方：0.04711
迭代次数：30（BFGS）+ 1（Fisher 评分）

但是，我也遇到了类似以下的输出（概率差异）。
 #get difference
avg_comparisons(model_beta)%&gt;%
kable()

输出如下。
|term |contrast |estimate|std.error|statistic|p.value|s.value|conf.low|conf.high|predicted_lo|predicted_hi|predicted|
|:---------|:-----------------|-----------:|---------:|-----------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|
|iq |平均值(+1) | -0.0483355| 0.0264920| -1.8245311| 0.0680718| 3.8767987| -0.1002589| 0.0035879| 0.4774381| 0.4286290| 0.4774381|
|治疗 |平均值(B) - 平均值(A) | -0.0332144| 0.0656963| -0.5055740| 0.6131557| 0.7056745| -0.1619768| 0.0955481| 0.5110320| 0.4774381| 0.4774381|
|treatment |mean(C) - mean(A) | 0.0600606| 0.0653734| 0.9187318| 0.3582359| 1.4810184| -0.0680689| 0.1881902| 0.5110320| 0.5714338| 0.4774381|

第二个问题：我可以使用上述输出进行推断吗？我理解上表中的估计值是概率的差异。我可以说以下吗？

如果 iq 增加 1 个单位，则在保持其他变量不变的情况下，结果的概率会降低 4.83%。
在保持其他变量不变的情况下，治疗 = C 与治疗 = A 的结果概率增加 6%。

第三个问题：还有其他简单的解释吗？
第四个问题：如果我的数据中 结果 变量中有 0 和 1，该怎么办？我发现我们可以使用零一膨胀贝塔回归模型？任何有关 R 的帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653143/interpretation-of-parameter-estimates-from-a-beta-regression-model</guid>
      <pubDate>Wed, 21 Aug 2024 21:23:33 GMT</pubDate>
    </item>
    <item>
      <title>为时间序列预测添加约束</title>
      <link>https://stats.stackexchange.com/questions/653126/adding-a-constraint-to-time-series-forecasts</link>
      <description><![CDATA[我有 3 个变量：$X_t$、$Y_t$、$Z_t$
在我的原始数据中，对于所有 $t$：$Z_t$&gt; $Y_t$&gt; $X_t$
我想制作 3 个基本时间序列模型来预测这些变量中的每一个。
但是，在预测中，我想确保（即约束）在每个预测点 $t$，预测的 $Z_t$ 总是大于预测的 $Yt$ ，并且预测的 $Y_t$ 总是大于预测的 $X_t$。
我目前正在做一些这样的基本方法：
library(stats)
library(forecast)
library(ggplot2)

n &lt;- 100

var3 &lt;- rnorm(n, 平均值 = 10, sd = 2)
var2 &lt;- rnorm(n, 平均值 = var3 - 2, sd = 1.5)
var1 &lt;- rnorm(n, 平均值 = var2 - 2, sd = 1)

df &lt;- data.frame(var1 = var1, var2 = var2, var3 = var3, time = 1:n)

arima_var1 &lt;- auto.arima(df$var1)
arima_var2 &lt;- auto.arima(df$var2)
arima_var3 &lt;- auto.arima(df$var3)

forecast_var1 &lt;- Forecast(arima_var1, h = 12)
forecast_var2 &lt;- 预测(arima_var2, h = 12)
forecast_var3 &lt;- 预测(arima_var3, h = 12)

但是，我注意到在预测中，有时不遵守此约束。是否有某种方法可以强制预测遵守此约束？]]></description>
      <guid>https://stats.stackexchange.com/questions/653126/adding-a-constraint-to-time-series-forecasts</guid>
      <pubDate>Wed, 21 Aug 2024 15:28:37 GMT</pubDate>
    </item>
    <item>
      <title>根据样本预测唯一观测值总数 - R</title>
      <link>https://stats.stackexchange.com/questions/653120/predict-total-unique-observations-based-on-sample-r</link>
      <description><![CDATA[我有一组包含 N 个唯一元素的数据，这些元素可以重复任意次以得到 X 个总元素。
N 和 X 的值未知。
我有此数据的样本，并计算了样本总大小和样本中唯一元素总数。
为了了解样本的结构，我以一系列样本大小重复进行了子样本抽样，没有进行替换，并计算了唯一元素。
绘制在此处：

（红色 = 总样本，黑色 = 下采样。每个可见黑点实际上是 20 个重复）。
由此，我想在 R 中拟合一条超出 x 的观测值的曲线，以预测 y 的最大值（例如：数据集中唯一元素的总数，N）。
样本中的元素总数：185718411
样本中的唯一元素总数：51588754
下采样数据：
x=c(1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 2.5e+07, 2.5e+07, 2.5e+07, 
2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 
2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 
2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 
5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 
5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 
1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 
1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1.25e+08, 1.25e+08, 
1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08,
1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 
1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.5e+08, 1.5e+08, 
1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 
1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08 , 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 
1.75e+08, 1.75e+08) y=c(8879407L, 8882853L, 8879146L, 8879963L, 8879973L, 8877565L, 8879535L, 8879441L, 8881377L, , 8880186L, 8879063L, 8881647L, 8879511L, 8881403L, 8878382L, 8879544L, 8881002L, 8880604L, 8880240L, 18927193L, 18924435L、18923731L、18920494L、18923974L、18923199L、18923360L、18923648L、18923131L、18922984L、18926592L、18924276L、1 8923680L、18923344L、18926252L、18921600L、18924428L、18928711L、18925935L、18922126L、30157610L、30155501L、30158640L、 30159612L, 30158025L, 30157679L, 
30154834L, 30159222L, 30160493L, 30157565L, 30158045L, 30157807L, 
30155821L, 30155840L, 30158622L, 30159742L, 30161088L, 30158046L, 
30159089L, 30155885L, 37409984L, 37400952L, 37402514L, 37408682L, 
37404248L, 37403547L、37401649L、37407739L、37405915L、37407328L、37402003L、37408206L、37398749L、37406762L、37401890L、37406383L、3 7404693L、37409054L、37403259L、37405316L、42387997L、42386810L、42386963L、42390976L、42390837L、42387186L、42387391L、 42385265L、42383010L、42392749L、42390451L、42390822L、42389636L、42389803L、42385593L、42390989L、42386302L、42389008L、4 2390049L、42386454L、45991832L、45992758L、45991351L、45993242L、45993277L、45990663L、45992366L、45992018L、45994867L、 45996211L、45992212L、45991838L、45991638L、45992517L、45993411L、45993444L、45992878L、45993934L、45993354L、45993045L、4 8707677L、48710261L、48705408L、48705354L、48706640L、48708658L、48708765L、48708926L、48707986L、48709516L、48705780L、 48708451L, 48707766L, 48711356L, 48708200L, 48707612L, 
48708961L, 48707509L, 48708770L, 48706288L, 50821205L, 50820451L, 
50819444L, 50821245L, 50821327L, 50820153L, 50819789L, 50821493L, 
50821043L, 50819115L, 50821689L, 50821538L, 50821014L, 50819974L, 
50821665L, 50819515L, 50820771L, 50819985L, 50820110L, 50819491L, 
51588754L)

我认为曲线的形状符合渐近回归，我研究过各种拟合方法，但我认为这并不是我想要的。
我知道对样本进行下采样并不等同于重复采样 - 但这是我所能获得的全部。因此，我必须基于（有效）假设，即考虑到样本的大小和重复的一致性，样本可以代表整个数据集。
我想对许多不同的数据集重复此操作，因此正在寻找一种可以一致应用的方法。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653120/predict-total-unique-observations-based-on-sample-r</guid>
      <pubDate>Wed, 21 Aug 2024 14:21:44 GMT</pubDate>
    </item>
    <item>
      <title>使用 CVXPY 解决逻辑回归问题</title>
      <link>https://stats.stackexchange.com/questions/652935/solving-logistic-regression-using-cvxpy</link>
      <description><![CDATA[我正在尝试使用 CVXPY 库编写逻辑回归模型。到目前为止，我编写的代码“有效”，因为它可以执行，不会产生任何错误消息并提供解决方案。但是，此解决方案与 scikit-learn 逻辑回归实现提供的解决方案不匹配。
我知道 scikit-learn 实现默认包含 L2 惩罚，在下面的代码示例中，您将看到我将其更改为 None。我还从 sklearn 模型中删除了截距。但解决方案仍然不匹配：
import cvxpy as cp
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression

X, y = make_classification(n_features=10, random_state=42)

sk = LogisticRegression(penalty=None, fit_intercept=False)
sk.fit(X, y)
print(sk.coef_)

这将产生输出：
[[-13.46939518 -7.09935934 19.41989522 -10.36990818 3.76335965
2.84616038 3.32474461 -2.84162961 3.13246888 1.08887971]]

现在，cvxpy 实现：
beta = cp.Variable(X.shape[1])
log_likelihood = cp.sum(cp.multiply(y, X @ beta) - cp.logistic(X @ beta))
problem = cp.Problem(cp.Maximize(log_likelihood/X.shape[0]))
problem.solve()
beta = beta.value
print(beta)

产生解决方案：
[-31.38130594 -10.72178524 44.07489985 -34.06127916 8.01950276
5.96941765 9.6143194 -7.88785049 12.96349703 -0.13264449]

编辑：
我的代码正在解决的对数似然公式是
$$
\ell(\beta)=\sum_{i=1}^m y_i \beta^T x_i-\log \left(1+\exp \left(\beta^T x_i\right)\right)
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/652935/solving-logistic-regression-using-cvxpy</guid>
      <pubDate>Fri, 16 Aug 2024 17:28:02 GMT</pubDate>
    </item>
    <item>
      <title>用于建模财务回报的 AR(1) 过程的时间缩放</title>
      <link>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</link>
      <description><![CDATA[过程：
考虑一个均值为零的 AR(1) 过程，*
$\lambda_t = \kappa \cdot \lambda_{t-1} + \omega_t$，
其中 $\kappa = 0.9$，$\omega \sim N(0, \sigma_{\omega}^2)$，并且 $\sigma_{\omega}^2 = 0.00027$。 $\lambda_0$ 的初始值取自平稳分布 $N \left(0, \frac{\sigma_{\omega}^2}{(1-\kappa^2)} \right)$
我使用此过程生成长度为 $T=672$ 的样本。
* 我知道，对于股票收益建模而言，均值为零是不现实的，但我的问题并不取决于此选择。

上述时间序列应解释为每月收益（以百分点表示），即 672 个月的观测值。
问题：
什么是合适的参数值生成总共 14,112 个每日观测值（即$672 \times 21$，如果我们假设一个月内有 21 个交易日）以符合上述（每月）流程？月回报率是给定月份内所有 21 天回报率的累计乘积。
尝试（在 R 中）：
DAYS &lt;- 21
T &lt;- 672
kappa &lt;- 0.9
variance_omega &lt;- 0.00027

get_init_lambda &lt;- function(variance) return(rnorm(n = 1, mean = 0, sd = sqrt(variance / (1-(kappa)^2))))

#### 月度分析

set.seed(1234)

lambda_T &lt;- vector(mode = &quot;numeric&quot;, length = T)

lambda_shock &lt;- rnorm(T, mean = 0, sd = sqrt(variance_omega))

lambda_T[1] &lt;- kappa * get_init_lambda(variance_omega) + lambda_shock[1]
for(i in 2:T) lambda_T[i] &lt;- kappa * lambda_T[i-1] + lambda_shock[i]

acf(lambda_T)$acf[2]
# [1] 0.9064949 # 符合预期

var(lambda_T)
# [1] 0.001547795

#### 每日分析

set.seed(1234)

kappa_daily &lt;- 0.90 # ??? 如何设置 kappa_daily，使月收益 AC = 0.9？

lambda_T_daily &lt;- vector(mode = &quot;numeric&quot;, length = T * DAYS)

lambda_shock_daily &lt;- rnorm(T * DAYS, mean = 0, sd = sqrt(variance_omega / DAYS))

lambda_T_daily[1] &lt;- kappa_daily * get_init_lambda(variance_omega / DAYS) + lambda_T_daily[1]
for(i in 2:(T * DAYS)) lambda_T_daily[i] &lt;- kappa_daily * lambda_T_daily[i-1] + lambda_shock_daily[i]

# 检索月末指数；假设每个月有 21 个交易日
begin_month &lt;- seq(1, T * DAYS, 21)
end_month &lt;- c(tail(begin_month, -1) - 1, T * DAYS)

lambda_monthly_aggregate &lt;- vector(mode = &quot;numeric&quot;, length = T)

for(i in 1:T){
month_ind &lt;- (begin_month[i]):(end_month[i])

daily_ret_within_month &lt;- 0.01*lambda_T_daily[month_ind] # 收益以 % 表示
monthly_return &lt;- 100*(cumprod(1+daily_ret_within_month) - 1) # 累计每日收益

lambda_monthly_aggregate[i] &lt;- monthly_return[DAYS] # 检索累计。 21 天后返回
}

# 与上述值不相同：自相关性太低，mth 方差返回值太高！
&gt; acf(lambda_monthly_aggregate)$acf[2]
[1] 0.2988249

var(lambda_monthly_aggregate)
[1] 0.01494742

]]></description>
      <guid>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</guid>
      <pubDate>Wed, 14 Aug 2024 16:01:50 GMT</pubDate>
    </item>
    <item>
      <title>正态分布概率密度函数与累积分布函数之比</title>
      <link>https://stats.stackexchange.com/questions/652176/ratio-of-normal-pdf-to-cdf</link>
      <description><![CDATA[我想证明
$$\Bigl\lvert \frac{\phi(a)}{\Phi(a)} - \frac{\phi(b)}{\Phi(b)} \Bigr\rvert \leq |a-b|$$
其中 $\phi$ 是标准正态 pdf，而 $\Phi$ 是标准正态 cdf。]]></description>
      <guid>https://stats.stackexchange.com/questions/652176/ratio-of-normal-pdf-to-cdf</guid>
      <pubDate>Thu, 01 Aug 2024 20:06:38 GMT</pubDate>
    </item>
    </channel>
</rss>