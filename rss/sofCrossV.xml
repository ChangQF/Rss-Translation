<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 01 Jan 2024 18:17:19 GMT</lastBuildDate>
    <item>
      <title>将常数与特征相乘对回归系数的影响</title>
      <link>https://stats.stackexchange.com/questions/635968/effect-on-regression-coefficients-by-multiplying-a-constant-to-a-feature</link>
      <description><![CDATA[我在 Coursera 上解决一个测验问题，发现了一个有趣的问题。
&lt;块引用&gt;
如果将给定特征的值加倍（即特定列）
特征矩阵），最小二乘估计会发生什么
其他每个特征的系数？ （假设你没有其他
依赖于加倍特征的特征，即没有交互
条款）。

我的问题是：

我认为，其他系数将保持不变。如果是这样，有人可以告诉我其背后的逻辑解释吗？
缩放后的特征的系数怎么样？假设我们将功能加倍且现有权重为 $m$，它是否等于 $m/2$ ？
如果还包含交互术语怎么办？那里会发生什么？

因此，总的来说，我可以说回归系数与原点的变化无关，但与规模无关。这是正确的吗？如果我们移动，系数保持不变。然而，当我们缩放系数时，系数会改变吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635968/effect-on-regression-coefficients-by-multiplying-a-constant-to-a-feature</guid>
      <pubDate>Mon, 01 Jan 2024 16:43:10 GMT</pubDate>
    </item>
    <item>
      <title>如何处理缺失的纵向结果和纵向协变量？</title>
      <link>https://stats.stackexchange.com/questions/635967/how-to-deal-with-missing-longitudinal-outcome-and-longitudinal-covariate</link>
      <description><![CDATA[我有具有连续纵向结果的数据，其中一个协变量是分类纵向变量。两者皆有失踪，同时被收集。因此，这意味着如果结果缺失，协变量也会缺失。
我的问题如下：

如果协变量存在缺失，直接似然是否仍然无偏？
如果我使用链式方程（SAS 中的 fcs 或 R 中的 mouse）进行多重插补，我是否应该在纵向结果之前首先插补缺失的纵向协变量？这样做可以吗？还是一次性将它们归结到一起更好？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635967/how-to-deal-with-missing-longitudinal-outcome-and-longitudinal-covariate</guid>
      <pubDate>Mon, 01 Jan 2024 16:31:36 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的梯度下降（反向传播）实际上是如何工作的？</title>
      <link>https://stats.stackexchange.com/questions/635966/how-does-gradient-descentback-propagation-in-neural-networking-actually-work</link>
      <description><![CDATA[我绝对是这个领域的初学者。目前正在Andrew Ng的指导下学习Course时代的监督机器学习。我已经进入该续集第二门课程的第二周了。
我实际上对反向传播感到困惑。我了解反向传播的理论知识，它基本上是微分的链式法则，并存储中间导数以查找先验导数，与传统过程相比，这节省了很多迭代和时间。但我无法完全理解反向传播如何集成到梯度下降中。
让我详细阐述一下我的困惑，然后我希望你能明白我所陷入的困境。
假设网络中有 1 个隐藏层。所以总共有 3 层：初始层、隐藏层和最终层。我知道这里我们分配随机权重和偏差。但是我们如何评估梯度下降呢？我的意思是，在线性回归的情况下，我们已经看到权重和偏差随着学习率和成本函数导数相对于权重/偏差的关联而变化。$$w_1 = w_1- \alpha*\frac{d}{dw_1}J$$ 其中 J 是成本函数。神经网络也会发生同样的事情吗？
我的意思是 $$w^3 = w^3 - \alpha*\frac{d}{dw^3}J$$$$w^2_n = w^2_ n - \alpha*\frac{d}{dw^2_n}J$$ 其中 $w^ 3=&gt;$第三层的权重和$w^2_n=&gt;$第二层第n个单元的权重]]></description>
      <guid>https://stats.stackexchange.com/questions/635966/how-does-gradient-descentback-propagation-in-neural-networking-actually-work</guid>
      <pubDate>Mon, 01 Jan 2024 15:58:27 GMT</pubDate>
    </item>
    <item>
      <title>使用对数正态分布拟合数据（最大似然估计）</title>
      <link>https://stats.stackexchange.com/questions/635963/fitting-the-data-using-lognormal-distribution-maximum-likelihood-estimation</link>
      <description><![CDATA[我正在尝试编写一个代码，使用最大似然估计对数正态分布的参数（平均值，标准差）。
我的目标是给定xdata，对数正态分布应该具有给定数组ydata的概率。
我相信我在定义似然函数时犯了一些错误。
这是我现在使用的代码：
ydata = np.array([0.03, 0.832])
xdata = np.array([0.5, 0.7])
im_log = np.log(xdata)

# 打印结果的格式
FORMAT_STRING = “{:&lt;20}{:&lt;20}{:&lt;20}”
打印（FORMAT_STRING.format（“sigma”，“beta”，“log_likelihood_sum”））

def neg_log_likelihood_sum(params, im_l):
    西格玛, 贝塔 = 参数

    # 计算正态分布的累积分布函数（CDF）
    fragility_curve = stats.norm(np.log(sigma), beta).cdf(im_l)

    # 计算可能性
    可能性 = ydata-fragility_curve

    # 计算对数似然
    log_likelihood = np.log(可能性)

    # 计算负对数似然
    neg_log_likelihood = np.sum(log_likelihood)

    print(f&quot;sigma: {sigma}, beta: {beta}, neg_log_likelihood_sum: {neg_log_likelihood}&quot;)
    返回-neg_log_likelihood

# 使用partial修复im_l参数
neg_log_likelihood_sum_partial = 部分(neg_log_likelihood_sum, im_l=im_log)

# 显式使用优化模块
res = optimize.minimize(neg_log_likelihood_sum_partial, x0=(1.3, 0.4), method=“Nelder-Mead”)

打印（解析）
x = np.linspace(0, 10, 100)
y = stats.norm(np.log(res[&quot;x&quot;][0]), res[&quot;x&quot;][1]).cdf(np.log(x))
# 绘制数据、拟合曲线和分布
plt.plot(xdata, ydata, &#39;go&#39;, label=&#39;数据&#39;)
plt.plot(x, y, label=&#39;脆弱性曲线（估计参数）&#39;)
plt.图例()
plt.xlabel(&#39;输入变量&#39;)
plt.ylabel(&#39;输出变量&#39;)
plt.title(&#39;拟合曲线和脆性曲线&#39;)
plt.show()
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/635963/fitting-the-data-using-lognormal-distribution-maximum-likelihood-estimation</guid>
      <pubDate>Mon, 01 Jan 2024 14:15:27 GMT</pubDate>
    </item>
    <item>
      <title>pinouin 库中两个样本 t 检验允许的最大样本量是多少？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/635959/what-is-the-maximum-allowed-sample-size-for-two-sample-t-test-in-pingouin-librar</link>
      <description><![CDATA[我目前正在运行测试来比较新旧机器的性能时间。处理大量数据集（超过 50,000 条记录），这使得新机器速度更快。此前，我进行过类似的测试，但在某些技术方面缺乏清晰度。因此，我选择了曼惠特尼 U 检验，为假设得出二元结果。
我投入了专门的时间来学习和更好地理解基础知识，因此我正在使用不同时期的相同数据集重新进行测试。这次我的目标是通过考虑新机器相对于旧机器的百分比改进，并考虑数据的规模和特征来执行更稳健的分析。我正在考虑使用 Pingouin 库中的双样本 t 检验，该库以其输出中提供置信区间而闻名，并且适合中心极限定理下的大样本量。
我发现的信息表明，虽然 t 检验适合较小的样本量（例如 30 个或更少），但 z 检验更适合较大的样本（例如 30 个或更多）。但是，我不确定这是否适用于 Pingouin 中如此大的样本的 ttest 函数，因为该库没有 ztest 函数。如何知道我是否可以自信地利用 Pinouin 的 ttest 来处理如此大的样本量？任何意见、建议、推荐都会非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/635959/what-is-the-maximum-allowed-sample-size-for-two-sample-t-test-in-pingouin-librar</guid>
      <pubDate>Mon, 01 Jan 2024 13:26:30 GMT</pubDate>
    </item>
    <item>
      <title>ADI 和 CoV - 根据数据集移动阈值？</title>
      <link>https://stats.stackexchange.com/questions/635954/adi-and-cov-move-thresholds-based-on-dataset</link>
      <description><![CDATA[我目前正在从事需求预测工作。在网上研究期间，我了解到用于需求分类的方法，这有助于我们专注于具有更好预测能力的系列等。因此，需求的分类主要基于变异系数（CoV）、平均需求间隔（ADI） ）。这引导我们进行 ABC XYZ 细分等分析和需求分类，例如 - 间歇性、块状、不稳定、平滑等。
只有当它们具有固定的阈值（就像我经常在网上看到的那样）并且它们都使用相同的阈值截止值（至少基于我在网上曝光的文章）时，上述所有方法才有意义吗？您可以参考 此处和此处
1.需求平稳（ADI &lt; 1.32 且 CV² &lt; 0.49）
2.间歇性需求（ADI≥1.32且CV²＜0.49）
3.需求不稳定（ADI&lt;1.32且CV²&gt;=0.49）
4.块状需求（ADI &gt;= 1.32 且 CV² &gt;= 0.49）
所以，我的问题，
a) 是否应该提醒这些阈值以反映我们的数据集？例如：我可以在 CV 上运行 1D-Kmeans 聚类并识别数据中的自然中断，以提​​出 XYZ 分割或需求分类 ADI 或 CV**2
b) 我们是否应该仅考虑活跃期（非零销售时间段）或完整时间段（使用客户不活跃的时间段）来计算平均销售额]]></description>
      <guid>https://stats.stackexchange.com/questions/635954/adi-and-cov-move-thresholds-based-on-dataset</guid>
      <pubDate>Mon, 01 Jan 2024 12:16:42 GMT</pubDate>
    </item>
    <item>
      <title>我试图理解一篇研究论文，但我无法理解 https://ieeexplore.ieee.org/document/9527655 中方程的工作原理 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635947/im-trying-to-understand-a-research-paper-but-i-couldnt-understand-the-working</link>
      <description><![CDATA[在本文中，他们使用模型方程在未标记的目标数据集中学习，如图所示，方程的工作原理对我来说并不清楚，而且第一次馈送是如何进行的对源数据进行 resnet，然后分别定位数据，帮助模型提高其性能。当他们尝试拉出训练图像中的每个图像时，他们会将所有图像彼此分开，然后使相似的图像更接近。我已经理解他们想要做什么，但无法理解图像中显示的数学公式。我会建议那些给出答案的人请浏览一次研究论文。我无法理解用于在类上进行分配的函数的工作原理。]]></description>
      <guid>https://stats.stackexchange.com/questions/635947/im-trying-to-understand-a-research-paper-but-i-couldnt-understand-the-working</guid>
      <pubDate>Mon, 01 Jan 2024 09:06:37 GMT</pubDate>
    </item>
    <item>
      <title>了解蒙特卡罗积分中的重要性采样</title>
      <link>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</guid>
      <pubDate>Mon, 01 Jan 2024 05:16:12 GMT</pubDate>
    </item>
    <item>
      <title>帮助理解 Cohen's D 在 lme 中进行成对比较</title>
      <link>https://stats.stackexchange.com/questions/635928/help-understanding-cohens-d-for-pairwise-comparisons-in-lme</link>
      <description><![CDATA[审稿人要求我提供成对、计划比较的效果大小。在实验设计中，我有一个固定因素和三个条件（一致性）。通道&amp;主题是随机效应。我想报告 Cohen 的 D 三个计划比较（一致性 1 - 一致性 2；一致性 1 - 一致性 3；一致性 2 - 一致性 3）。然而，当我计算 Cohen&#39;s D 时，我得到两个效应大小，一个标记为一致性 2 (d = .732)，另一个标记为一致性 3 (d = .296)。首先，我不确定这些效果大小指的是哪些比较，并且输出仅提供两种效果大小。其次，我怎样才能得到第三次比较的科恩 D 值？
这是我的代码：
PdatFIN$RT_target &lt;- as.numeric(PdatFIN$RT_target)
PdatFIN$一致性 &lt;- as.factor(PdatFIN$一致性)
str(PdatFIN)
m &lt;- lmer(RT_target ~ 一致性 + (1 | 主题) + (1 | 段落), PdatFIN);摘要(m)；方差分析(米)
lme.dscore(m,数据=PdatFIN,类型=“lme4”)
m.contrasts &lt;- emmeans(m,“一致性”)
对(m.contrasts)

这是我的输出：
&lt;前&gt;&lt;代码&gt;组：1
             vars n 均值 SD 中值 修剪疯狂最小值 最大范围 偏斜峰度 se
RT_目标 1 148 1709.04 527.09 1631 1697.14 650.12 846 2974 2128 0.22 -1.06 43.33
组别：2人
             vars n 均值 SD 中值 修剪疯狂最小值 最大范围 偏斜峰度 se
RT_目标 1 162 2137.73 741.01 2056.5 2081.52 717.58 897 4414 3517 0.70 0.34 58.22
组别：3人
             vars n 均值 SD 中值 修剪疯狂最小值 最大范围 偏斜峰度 se
RT_目标 1 166 1888.73 736.85 1740 1811.35 708.68 750 4318 3568 1.01 0.83 57.19

REML [&#39;lmerMod&#39;] 拟合线性混合模型
公式：RT_target ~ 一致性 + (1 | 主题) + (1 | 段落)
   数据：PdatFIN

REML 收敛准则：7314.2

缩放残差：
    最小 1Q 中值 3Q 最大
-2.0682 -0.6320 -0.1771 0.5346 4.1376

随机效果：
 组名称方差标准差
 主题（拦截）203923 451.6
 通过（拦截）23091 152.0
 剩余 239054 488.9
obs 数量：476，组：受试者，30；通道，18

固定效果：
             估计标准。误差t值
（拦截）1711.58 98.75 17.333
一致性2 427.71 56.19 7.612
一致性3 173.18 55.99 3.093

固定效应的相关性：
            (Intr) Cnsst2
一致性2 -0.301
稠度3 -0.303 0.532
偏差表分析（II 型 Wald 卡方检验）

响应：RT_target
             Chisq Df Pr(&gt;Chisq)
稠度 59.216 2 1.385e-13 ***
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
&gt; #科恩斯d
&gt; lme.dscore(m,数据=PdatFIN,类型=“lme4”)
                    t df d
一致性2 7.612028 432.5373 0.7320127
一致性3 3.092820 434.6247 0.2967068
&gt; m.contrasts &lt;- emmeans(m,“一致性”)
&gt;对(m.contrasts)
 对比估计 SE df t.ratio p.value
 一致性 1 - 一致性 2 -428 56.2 432 -7.607 &lt;.0001
 一致性 1 - 一致性 3 -173 56.1 434 -3.090 0.0060
 一致性2 - 一致性3 255 54.3 429 4.688 &lt;.0001

自由度方法：kenward-roger
P 值调整：用于比较 3 个估计值的 tukey 方法

我非常感谢您的帮助和指导。我是 LME 的新手，试图解释我的输出是一个挑战。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/635928/help-understanding-cohens-d-for-pairwise-comparisons-in-lme</guid>
      <pubDate>Sun, 31 Dec 2023 17:49:27 GMT</pubDate>
    </item>
    <item>
      <title>经验分布（直方图箱）的比率是否显示出它们的差异？</title>
      <link>https://stats.stackexchange.com/questions/635918/does-taking-the-ratio-of-empirical-distributions-histogram-bins-show-their-dif</link>
      <description><![CDATA[背景
我有两个经验分布，均来自社交媒体数据。
第一个代表约 480 万个帖子的广泛样本以及每个帖子作者拥有的关注者数量。分布如下：

第二个是专门向我推荐的 1020 个帖子的较小样本。分布如下：

从目视检查中可以明显看出，如果忽略尺度并对分布进行归一化，它们将彼此非常不同。
我已经对这些分布进行了标准化，并采用了推荐分布与广泛分布的比率。我所说的比率是指将推荐故事的 bin 值除以广泛故事的 bin 值。我将结果绘制为散点图：
$$ R_i = \frac{r_i}{b_i}$$
其中 $R_i$ 是为 bin 位置 $i$ 计算的比率，$r_i$ 是推荐故事分布的 bin 位置 $i$ 中故事的标准化数量，并且 $b_i$ 是广泛故事分布的 bin 位置 $i$ 中故事的标准化数量。
它显示了一个有趣的模式。该比率随着追随者数量的增加而增加。由此，我推断，当您获得更多关注者时，您被推荐的机会就会增加。我预料到了我找到的结果，但我不知道它是否有意义。
问题
如果您有经验分布（定义为具有相同组箱的直方图），那么采用它们的箱的比率是否可以让您了解它们之间的差异？特别是关于管理每个创建的可能行为？]]></description>
      <guid>https://stats.stackexchange.com/questions/635918/does-taking-the-ratio-of-empirical-distributions-histogram-bins-show-their-dif</guid>
      <pubDate>Sun, 31 Dec 2023 14:13:58 GMT</pubDate>
    </item>
    <item>
      <title>神经网络与线性回归内联执行，我该如何改进它？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/635741/neural-net-performs-inline-with-linear-regression-how-can-i-improve-it</link>
      <description><![CDATA[我有一个回归问题，涉及大约 100 万个样本和 400 个特征（有些特征不太有意义和/或冗余）和 1 个目标变量。我一直在努力设计一种神经网络架构，在验证数据中击败线性回归（通过正则化），但到目前为止我得到的只是与线性回归一致，并没有明显更好。
我主要关注添加了一些复杂性的前馈网络，例如：

多个密集层（对单元数量、标准化、激活、丢失等有不同的选择）。
有或没有残余连接。
具有某些门控的并行网络，这取决于功能的子集。类似于分层线性回归。
首先训练自动编码器以降低输入维度，然后执行上述所有操作。
短暂尝试过 CNN 和其他更复杂的层，但这不是我的重点。

它们的表现与线性回归差不多，甚至更差。对我来说有点奇怪的是，为什么打败线性回归如此困难，我认为向基线线性模型添加一个小的非线性至少应该有一点帮助。
我的问题是，除了上述之外，高级 ML 从业者还会尝试什么？任何对标准方法或开箱即用的想法的指导都将受到高度赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/635741/neural-net-performs-inline-with-linear-regression-how-can-i-improve-it</guid>
      <pubDate>Wed, 27 Dec 2023 23:46:56 GMT</pubDate>
    </item>
    <item>
      <title>如果 Cov(X,Y)=Var(Y)，X 和 Y 之间的依赖关系是什么？</title>
      <link>https://stats.stackexchange.com/questions/635725/if-covx-y-vary-what-is-the-dependence-between-x-and-y</link>
      <description><![CDATA[在一个问题中我发现
$$Cov(X,Y)=Var(Y),$$
其中 $X$ 和 $Y$ 是随机变量。
关于 $X$ 和 $Y$ 之间的线性相关性我可以得出什么结论？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635725/if-covx-y-vary-what-is-the-dependence-between-x-and-y</guid>
      <pubDate>Wed, 27 Dec 2023 19:05:08 GMT</pubDate>
    </item>
    <item>
      <title>如何识别样本正态分布的直方图</title>
      <link>https://stats.stackexchange.com/questions/635958/how-to-recognize-my-histogram-chart-for-normal-distribution-of-samples</link>
      <description><![CDATA[我完成了一个行动研究项目，并使用 DART 提高了学生的阅读理解能力。我只是为了结果而比较手段。现在我要写一篇文章，我将应用 $t$ 测试以获得更好的结果。我正在使用 Google Sheets 检查样本的正态分布。我制作了一个图表，但不明白。
我把全班分成了两组，即对照组（不进行治疗）和实验组（进行治疗）。我制作了图表只是为了检查对照组的结果，但我无法理解分布是否正常。查看下图，请说明它是否显示正态分布。
我上传了一张图像，仅显示对照组的结果：
]]></description>
      <guid>https://stats.stackexchange.com/questions/635958/how-to-recognize-my-histogram-chart-for-normal-distribution-of-samples</guid>
      <pubDate>Mon, 25 Dec 2023 11:08:59 GMT</pubDate>
    </item>
    <item>
      <title>如何仅使用因变量的滞后值来实施动态回归预测</title>
      <link>https://stats.stackexchange.com/questions/635236/how-to-implement-dynamic-regression-forecasting-using-only-lagged-values-of-the</link>
      <description><![CDATA[据我了解，Arima 误差回归（也称为动态回归）通常使用外生变量来实现，是否可以仅使用内生变量来实现动态回归？这将如何实施？
以下是使用外生变量（自变量）的回归方程
\begin{align}y_t = \beta_0 + \beta_1 x_{1,t} + \dots + \beta_k x_{k,t} + \varepsilon_t \hspace{1.5厘米}(1.1)\结束{对齐}
下面是动态回归方程，其中 $\eta_t$ 是 ARIMA(1,1,1) 过程。
\begin{align*}
  y_t &amp;= \beta_0 + \beta_1 x_{1,t} + \dots + \beta_k x_{k,t} + \eta_t,\hspace{1.25cm} (2.1) \\
      &amp; (1-\phi_1B)(1-B)\eta_t = (1+\theta_1B)\varepsilon_t,
\hspace{1cm} (2.2)
\end{对齐*}
$\eta_t$ 是如何计算的？因为如果我将后移符号转换为方程 2.2 中的形式，我应该得到以下结果：
\begin{align}\eta_t = \varepsilon_t + \theta_1\varepsilon_{t-1} + \eta_{t-1} + \phi_1(\eta_{t- 1} - \eta_{t-2}) \hspace{0.36cm} (2.3)\end{align}
是否可以将方程 2.1 转换为使用内生变量（因变量），如下所示：
\begin{align}y_t = \beta_0 + \beta_1 y_{t-1} + \dots + \beta_k y_{t-k} + \eta_t \hspace{1.2cm} (3.1)\end{对齐}
问题：

除了将所有外生变量替换为内生变量之外，3.1 的实施方式与 1.1 有何不同？
公式 2.3 中所示的 ARIMA(1,1,1) 多项式表示法正确吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635236/how-to-implement-dynamic-regression-forecasting-using-only-lagged-values-of-the</guid>
      <pubDate>Tue, 19 Dec 2023 08:10:46 GMT</pubDate>
    </item>
    <item>
      <title>“统计模型”这个概念与（监督）机器学习无关吗？</title>
      <link>https://stats.stackexchange.com/questions/621152/is-the-concept-statistical-model-irrelevant-in-supervised-machine-learning</link>
      <description><![CDATA[在监督机器学习中，我们得到一组数据
$\{x_i\}_{i=1}^N$ 其中每个数据都与一个标签关联 $\{ y_i\}_{i = 1}^N$。
我们希望创建/训练函数 $f$ 来完成几件事。

创建一条最佳拟合曲线：$f: x_i \to y_i$，以使指标（训练误差）最小化。

回归：为新数据分配实际值

分类：为新数据分配离散标签


这些是监督机器学习最常见的任务。深度神经网络是最常用的通用函数形式 $f$ ，可以完成这些任务（封装了线性、逻辑、多类逻辑、概率回归）等等。
请注意我的描述中的一件关键事情：我没有提及任何有关“统计模型”存在的内容。许多机器学习作者在教科书中讨论了这一点。
&lt;小时/&gt;
通过统计模型，我引用了第一句中描述的数据集和标签之间的一些规定关系。
例如：根据https://statmath.wu.ac。在/courses/heather_turner/glmCourse_001.pdf
线性模型为： $y_i = \beta_0 + \beta_1^T x_i + \epsilon_i$ 其中 $\ epsilon_i$ 是一个噪声项。
一般的线性模型是： $y_i = \beta_0 + \beta_1^T x_{1i} + \ldots + \beta_p^T x_{pi} + \epsilon_i$&lt; /跨度&gt;
逻辑回归模型为：$\log(y_i) = \beta_0 + \beta_1^T x_{i} + \epsilon_i$
还有非参数、半参数模型，均遵循以下形式 $y_i = m(x_i) + \epsilon_i$ 其中 $m$ 是一些函数。
&lt;小时/&gt;
我很困惑为什么需要对统计模型进行讨论，特别是在作者试图使用这些统计模型本质上做与机器学习模型相同的事情的情况下。
以下是一些相关问题：

直观上，在现实世界中我们不知道什么是
标签和数据之间的关系。那么为什么要费心创建一个
他们之间的关系？

不属于现代机器学习的一部分
训练/验证/测试例程我们是否需要假设
$x_i$ 和 $y_i$ 之间的关系清晰。它确实没有
向我们提供任何其他信息。

在现代深度监督机器学习中，模型的概念甚至没有被提及。例如，诸如“GoogLeNet 的统计模型是什么”或“LSTM 的统计模型是什么”这样的说法似乎没有意义。我的意思是， $m$ 的函数形式和 $\epsilon_i$ 上的噪声假设是什么，&lt; span class=&quot;math-container&quot;&gt;$y_i = m(x_i) + \epsilon_i$ 用于 DenseNet 或 U-Net 等？


有人可以帮我理解这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/621152/is-the-concept-statistical-model-irrelevant-in-supervised-machine-learning</guid>
      <pubDate>Tue, 11 Jul 2023 23:54:54 GMT</pubDate>
    </item>
    </channel>
</rss>