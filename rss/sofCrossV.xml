<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 02 Aug 2024 18:20:49 GMT</lastBuildDate>
    <item>
      <title>为什么修改后的 z 分数没有发现明显的异常值？</title>
      <link>https://stats.stackexchange.com/questions/652217/why-does-modified-z-score-not-pick-up-an-obvious-outlier</link>
      <description><![CDATA[希望借鉴您对用于检测异常值的修改后的 z 分数的一些见解。
据我从研究中得知，当分布可能不正常（例如偏斜）时，修改后的 z 分数比 z 分数本身更能指示异常值。这是因为，如果分布不为正态分布，则使用中位数而不是均值，中位数是集中趋势的稳健估计量。
我正在针对一个值列表测试这两种算法以及其他一些异常值检测算法，其中我知道一个值是极端异常值。为了帮助我，我创建了一个小型 Python 程序，它根据该列表计算 z 分数和修改后的 z 分数，然后使用它来检查列表中的任何项目是否看起来像异常值。基本上，我检查了这些算法是否能成功检测到我知道存在的极端异常值。
为了检查我的数据的分布，程序创建了一个箱线图，异常值（值 = 200）非常明显。作为参考，该数据集的中位数为 58。

异常值 200 的修改后的 z 分数仅为 2.81，这大大低于被视为异常值的 3.5，因此它不会被标记为异常值。仅供参考，我使用 3.5，因为这似乎是最推荐的截止值。
异常值 200 的 z 分数为 3.40，这高于被视为异常值的 3.0，因此它确实被标记为异常值。仅供参考，我使用 3.0 作为截止值，因为这似乎最受欢迎。
我的问题是，为什么 z 分数算法可以检测到我的数据集中的异常值，而修改后的 z 分数算法却不能？在我看来，这似乎违反直觉，尤其是当异常值从箱线图中显而易见时。
这是我的 Python，以防我犯了错误：
import matplotlib as plt
import numpy as np
from scipy.stats import zscore

def z_score_mod(obs):
med = np.median(obs)
med_abs_dev = np.median(np.abs(obs - med))
z_score_mod = 0.6745 * ((obs - med) / med_abs_dev)
return z_score_mod

# 具有相当大的异常值 = 200 和索引 = 13 的观察值列表
list_of_obs = [58,71,11,18,90,97,15,53,39,22,62,51,10,200,20,64,94,71,73,18,95,96,92,38,26]

# 将观测值列表转换为 numpy 数组
array_of_obs = np.array(list_of_obs)

# 创建箱线图以显示异常值
plt.pyplot.boxplot(array_of_obs)

median = np.median(array_of_obs)

# 计算每个数组项的修改后的 z 分数
array_of_z_score_mod = z_score_mod(array_of_obs)

# 对于生成的修改后的 z 分数，确定是否有任何异常值
array_of_outlier_evals = abs(array_of_z_score_mod) &gt; 3.5

# 索引 = 13 处的观测值 = 200 是否为异常值？
print(&#39;\r&#39;)
print(f&#39;索引位置 13 处的观察值 = {list_of_obs[13]}&#39;)
print(f&#39;修改后的 z 分数值 = {array_of_z_score_mod[13]:.2f}&#39;)
print(f&#39;在修改后的 z 分数阈值 3.5 处，值是否为异常值：{array_of_outlier_evals[13]}&#39;)

# 计算每个数组项的 z 分数
array_of_z_score = zscore(list_of_obs)

# 对于生成的 z 分数，确定是否有任何异常值
array_of_outlier_evals_2 = abs(array_of_z_score) &gt; 3

# 索引 = 13 处的观察值 = 200 是否为异常值？
print(&#39;\r&#39;)
print(f&#39;索引位置 13 处的观察值 = {list_of_obs[13]}&#39;)
print(f&#39;值的 z-score = {array_of_z_score[13]:.2f}&#39;)
print(f&#39;在 z-score 阈值 3.0 处，值是否为异常值：{array_of_outlier_evals_2[13]}&#39;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652217/why-does-modified-z-score-not-pick-up-an-obvious-outlier</guid>
      <pubDate>Fri, 02 Aug 2024 17:17:52 GMT</pubDate>
    </item>
    <item>
      <title>具有外生变量的 ARMA - GARMA 模型的 p 值</title>
      <link>https://stats.stackexchange.com/questions/652216/p-values-for-a-arma-garma-model-with-exogenous-variable</link>
      <description><![CDATA[我正在尝试估计以下 ARMA(1, 2) - GARCH(1, 1) 模型的参数，其中还带有一个外生变量。模型规范如下：
$ x_t = \mu + \beta_Y \cdot y_{t-1} + AR_1\cdot x_{t-1} + MA_1\cdot \epsilon_{t-1} + MA_2 \cdot \epsilon_{t-2} + \epsilon_t$
$\epsilon_t = \sigma_t\cdot z_t $
$ \sigma_t = \sqrt{\omega + \alpha \cdot \epsilon_{t-1}^2 + \beta\cdot \sigma_{t-1}^2}$
$ z_t \sim Normal(0, 1)$ 适用于所有 $t$。这些误差是 iid 的。
模型参数为：$\mu, \beta_Y, AR_1, MA_1, MA_2, \omega, \alpha, \beta$。
我目前正在通过最大化 pytorch 中的对数似然来估计最佳参数。问题：

是否有能够估计这些参数的 python 包？作为双重检查，它将非常有用

是否有一个 python 包能够为估计的参数生成标准错误和 p 值？

如果答案 2 没有这样的包，有没有关于如何生成这些 p 值的提示？


非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652216/p-values-for-a-arma-garma-model-with-exogenous-variable</guid>
      <pubDate>Fri, 02 Aug 2024 17:14:01 GMT</pubDate>
    </item>
    <item>
      <title>如何读取实验设计的事后（Tukey HSD）输出？</title>
      <link>https://stats.stackexchange.com/questions/652215/how-do-you-read-post-hoc-tukey-hsd-outputs-for-experimental-designs</link>
      <description><![CDATA[我目前正在学习统计学课程中的实验设计，我对事后分析结果的解读方式感到十分困惑。
在我的家庭作业中，我对三个不同快递员的平均送货时间差异进行了事后/Tukey HSD 测试。我为此使用的测试统计量是随机区组设计。我的因变量是运输时间，而我的分类变量是发货批次和快递员。当我通过 Statistica 软件运行数据时，我得到了 1-5 批发货的一列，以及每个 {1}、{2}、{3}、{4} 和 {5} 的一列。
为了直观起见，这是 Statistica 给我的结果。请注意，我只填写了前两行：



装运批次
{1&gt;
{2&gt;
{3&gt;
{4&gt;
{5&gt;




1

0.017177
0.005775
0.94846
0.000722


2
0.017177

0.893692
0.043908
0.090739


3







4








5








在每个 {1}、... {5}（在同一个标​​题块中）下，还标明了该特定货件的平均交货时间。
看到（我认为是）行和列都是货件批次时，我真的很困惑，因为我有兴趣测试快递员之间的平均交货时间差异。
为什么货件是表格中显示的唯一分类变量？我测试运行不正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652215/how-do-you-read-post-hoc-tukey-hsd-outputs-for-experimental-designs</guid>
      <pubDate>Fri, 02 Aug 2024 17:13:44 GMT</pubDate>
    </item>
    <item>
      <title>对于重复测量的分类数据应使用什么模型或方法？</title>
      <link>https://stats.stackexchange.com/questions/652214/what-model-or-method-to-use-for-categorical-data-with-repeated-measures</link>
      <description><![CDATA[我正在尝试分析我的数据，它由 2 个独立分类变量（4 种纹理和 4 种撞击声音 - 将它们混合和匹配可以给我展示每个人的 16 种不同条件）和 1 个因变量分类变量（为显示的刺激选择的选项 - 4 个潜在选项）组成。我绘制了图表并对结果有所了解，但需要证明其统计意义。
我不完全确定如何做到这一点，所以我正在考虑多项逻辑回归 - 我可以使用该模型来验证我们看到的结果不是随机的而是实际的模式。我的理解是我们可以根据模型的 p 值来验证这一点。如果我错了，请随时纠正我。
但我的数据也有重复测量......我该如何解释这一点？多项逻辑回归是否已经考虑到了这一点？或者我应该着眼于混合效应逻辑回归？python 支持吗？我似乎找不到任何支持或代码示例。
我曾考虑将我的多项式数据拆分为 4 个不同的二项式混合回归模型，但我似乎再次找不到有关混合效应逻辑回归的任何内容 - 只有 Python 中的混合效应线性回归。我可以使用线性混合效应模型获得正确的结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652214/what-model-or-method-to-use-for-categorical-data-with-repeated-measures</guid>
      <pubDate>Fri, 02 Aug 2024 15:44:18 GMT</pubDate>
    </item>
    <item>
      <title>核均值嵌入的收敛</title>
      <link>https://stats.stackexchange.com/questions/652212/convergence-of-kernel-mean-embeddings</link>
      <description><![CDATA[设 $k(\cdot,\cdot)$ 为丰富核，$\mathcal{H}$ 为其相关 RKHS。定义核均值嵌入 $\mu=\int k(\cdot,x)dP_X(x)$，设 $\hat{\mu}=\frac{1}{n}\sum k(x_i,\cdot)$ 为其样本模拟。两者之间的误差 $||\mu-\hat{\mu}||_{\mathcal{H}}=O(\frac{1}{\sqrt{n}})$。各种结果通过使用希尔伯特空间的伯恩斯坦型不等式来证明这一点。
对我来说，从中心极限定理的角度来看，这感觉很直观。有希尔伯特空间 CLT 吗？是否有可能从 CLT 的应用中显示这种速率？]]></description>
      <guid>https://stats.stackexchange.com/questions/652212/convergence-of-kernel-mean-embeddings</guid>
      <pubDate>Fri, 02 Aug 2024 14:32:18 GMT</pubDate>
    </item>
    <item>
      <title>软问题：统计学硕士（计算统计学专业）与计算机科学硕士（数据科学专业）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652211/soft-question-ms-in-statistics-computational-statistics-specialisation-vs-ms</link>
      <description><![CDATA[问题：我打算在美国/欧洲的一所顶尖大学攻读机器学习/深度学习博士学位。我应该选择印度统计研究所的统计硕士还是计算机科学硕士来加强我的博士申请和研究基础？
背景：我拥有纯数学学士-硕士学位，希望在申请博士学位之前打下坚实的基础。我对计算统计和数据科学同样感兴趣。印度统计研究所的统计课程备受推崇，但计算机科学课程则不那么受推崇。我寻求建议，看看哪个硕士学位对博士委员会更有吸引力，并能更好地为机器学习/深度学习方面的有影响力的研究做好准备。
感谢您的见解。
PS：如果这个问题不适合在这里提出，请告诉我合适的平台，我会在那里发布它。感谢您的耐心。对造成的麻烦深表歉意。]]></description>
      <guid>https://stats.stackexchange.com/questions/652211/soft-question-ms-in-statistics-computational-statistics-specialisation-vs-ms</guid>
      <pubDate>Fri, 02 Aug 2024 12:38:05 GMT</pubDate>
    </item>
    <item>
      <title>计算不同统计检验的效应大小、统计功效和置信区间</title>
      <link>https://stats.stackexchange.com/questions/652209/calculation-of-effect-size-statistical-power-and-confidence-interval-for-diffe</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652209/calculation-of-effect-size-statistical-power-and-confidence-interval-for-diffe</guid>
      <pubDate>Fri, 02 Aug 2024 11:41:26 GMT</pubDate>
    </item>
    <item>
      <title>E-test 值的多重校正</title>
      <link>https://stats.stackexchange.com/questions/652208/multiple-correction-for-e-test-values</link>
      <description><![CDATA[我目前正在执行多个“E-tests”（poisson.mean），并且想知道使用 E-tests 进行多次校正的最合适方法，以及如何在 R 中进行此操作。
我正在计算 7 个不同实验组（2 个对照组，5 个感兴趣的实验组）中某个事件发生的次数（在给定的时间间隔内）。
我选择通过列出 7 个条件组和值来比较各组之间的泊松分布均值，然后以迭代方式执行泊松检验。然后从结果中获取 P 值，例如。
Cond1 &lt;- c(0,0,0,1,1,2,3,3,3)
Cond2 &lt;- c(0,1,1,1,1,1,2,3,3)
Cond3 &lt;- c(0,1,2,3,3,3,3,3,4)
Cond7 &lt;- c(3,3,3,3,4,4,4,5,6)
result1 &lt;- poisson.test(x c(sum(Cond1), sum(Cond2)),
T = c(length(Cond1), length (Cond2)),
alternative = &quot;two.sided&quot;)
result2 &lt;- poisson.test(x c(sum(Cond1), sum(Cond3)),
T = c(length(Cond1), length (Cond3)),
alternative = &quot;two.sided&quot;) 

result20 &lt;- poisson.test(x c(sum(Cond6), sum(Cond7)),
T = c(length(Cond6), length (Cond7)),
alternative = &quot;two.sided&quot;) 
P1 &lt;- result1§p.value 
P2 &lt;- result2§p.value 
P20&lt;- result20§p.value 

从这一点开始，我需要校正多个测试，并希望使用 Benjamini-Hochberg 类型的排序 p 值显著性校正，但我想知道
A) 哪种测试最适合这种分析
B) 如何在 R 中进行此操作]]></description>
      <guid>https://stats.stackexchange.com/questions/652208/multiple-correction-for-e-test-values</guid>
      <pubDate>Fri, 02 Aug 2024 11:36:56 GMT</pubDate>
    </item>
    <item>
      <title>复高斯分布和瑞利分布之间存在可互换性吗？</title>
      <link>https://stats.stackexchange.com/questions/652207/does-an-interchangeability-exist-between-complex-gaussian-distribution-and-rayle</link>
      <description><![CDATA[假设，一个复杂的高斯分布由以下公式给出：
$$N\sim\mathcal{CN}(0,1)$$
它也可以写成：
$$N=X+jY$$其中$X\sim\mathcal{N}(0,1/2)$和$Y\sim\mathcal{N}(0,1/2)$，$X$和$Y$都是正态分布的，并且彼此独立。
现在，我们知道对于独立的高斯分布随机变量$X$和$ class=&quot;math-container&quot;&gt;$Y$，$|r|=\sqrt{X^2+Y^2}$ 服从瑞利分布，而 $\theta=\tan^{-1}\frac{y}{x}$ 服从均匀分布。
问题：

复高斯和瑞利分布是否服从？均匀分布分别是同一量的笛卡尔形式和极坐标形式，即$N=X+jY=|r|\exp{(j\theta)}$?

我们能用$f_{R,\theta}(r,\theta)$的联合分布代替复杂的高斯分布吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/652207/does-an-interchangeability-exist-between-complex-gaussian-distribution-and-rayle</guid>
      <pubDate>Fri, 02 Aug 2024 11:11:32 GMT</pubDate>
    </item>
    <item>
      <title>适应数字跟踪数据的序列分析（应用程序跟踪）</title>
      <link>https://stats.stackexchange.com/questions/652206/adaptation-of-sequence-analysis-for-digital-trace-data-app-tracking</link>
      <description><![CDATA[我是一名通信科学家，对 TraMineR 和序列分析完全是新手。我有一个（相对较大）的数据集，其中包括研究参与者的应用程序使用情况。我的目标是识别连续使用的应用程序类别序列。
原始数据集如下所示：



参与者 ID
会话 ID
使用的应用程序类别
开始时间（实际上是 unix 时间）
结束时间（实际上是 unix 时间）




0001
0001_1
通信
2021-03-02 10:05:02
2021-03-02 10:05:09


0001
0001_1
社交媒体
2021-03-02 10:05:09
2021-03-02 10:07:09


0002
0002_1
游戏
2021-03-02 14:36:07
2021-03-02 14:36:07


...
...
...
...
...



因此，我有两个分析层次：(1) 一方面是参与者，另一方面是 (2) 会话。
第一步，我的目标是确定连续使用的应用程序类别序列。会话是打开和关闭智能手机屏幕之间的连贯使用序列。该数据集包含近 400 名参与者，每个参与者有大约 2000-5000 个会话（整个数据集约 140 万个会话）。
我已经首次尝试使用子样本，并遇到了两个问题：

我已将拼写格式的数据放入 seqdef 函数中。这是最佳时间格式的问题。这里有经验吗？我目前使用的是 unix-time，但我觉得单位太细了。

更新：我不得不意识到只有白天的时间才是相关的，而不是与确切日期相关的时间。具体来说，我们感兴趣的是序列是否发生在早上，但它是否真的发生在 3 月 12 日星期二并不重要。如果我理解正确的话，重新编码时间也应该减少 STS 序列中的变量数量。目前，序列由约 660k 个变量组成。
labels = seqstatl(sample$app_category)
states = 1:length(labels)

session_seq = seqdef(data = sample, 
var = c(&quot;session&quot;, &quot;begin&quot;, &quot;end&quot;, &quot;app_category&quot;), 
informat = &quot;SPELL&quot;,
states = states,
labels = labels,
process = FALSE)

print(session_seq[1:15, ], format = &quot;SPS&quot;)


第二个问题与所需的计算资源有关。即使是子样本，我也需要相对大量的计算能力。是否可以使计算更节省资源？是否可以选择拆分数据集，然后合并序列距离（批处理），或者这会扭曲我的结果？

我计划按如下方式进行：首先创建一个序列对象（使用 seqdef），然后根据序列对象计算序列成本，之后计算序列距离（“OM”）并使用聚类算法将结果聚类为类型。
我也很高兴收到有关阅读和阅读目标的更多提示。TraMineR 用户指南已经帮了我很多。]]></description>
      <guid>https://stats.stackexchange.com/questions/652206/adaptation-of-sequence-analysis-for-digital-trace-data-app-tracking</guid>
      <pubDate>Fri, 02 Aug 2024 10:45:01 GMT</pubDate>
    </item>
    <item>
      <title>将分数改变为预测变量</title>
      <link>https://stats.stackexchange.com/questions/652205/change-score-as-predictor</link>
      <description><![CDATA[我想看看独立变量（T2-T1）的变化是否能预测 T2 时的另一个变量。例如，痴呆症患者在 1 年内认知障碍的增加幅度越大，预示着生活质量越低。
我的问题是：我需要控制基线生活质量（因变量）吗？
我已经读到我应该控制 IV，但不确定 DV。]]></description>
      <guid>https://stats.stackexchange.com/questions/652205/change-score-as-predictor</guid>
      <pubDate>Fri, 02 Aug 2024 10:42:34 GMT</pubDate>
    </item>
    <item>
      <title>弗里德曼、皮萨尼和普维斯书中的辛普森悖论</title>
      <link>https://stats.stackexchange.com/questions/652195/simpsons-paradox-in-freedman-pisani-and-purves-book</link>
      <description><![CDATA[本书中有一个研究生录取性别歧视的例子。



专业
男性

女性






申请人数
录取率
申请人数
%录取


A
825
62
108
82


B
560
63
25
68


C
325
37
593
34


D
417
33
375
35


E
191
28
393
24


F
373
6
341
7


总计
2691
45
1835
30



申请人总数只是上述条目的总和。录取的总百分比为男性 45%，为
$$ \frac{62\cdot825 }{2691} + \cdots + \frac{6\cdot373}{2691}$$
女性也是如此。
然后作者提出统计学家会做以下事情的论点：



专业
申请人总数




A
933 = 825 + 108


B
585


C
918


D
792


E
584


F
714 = 373 + 341


总计
4526



然后他们指出男性的加权平均录取率为：
$$ \frac{62\cdot933}{4526} + \cdots + \frac{6\cdot714}{4526} \approx 39 $$
对于女性来说也是如此：
$$ \frac{82\cdot933}{4526} + \cdots + \frac{7\cdot714}{4526} \approx 43 $$
我很难解释最后一对计算“男女加权平均录取率”。
他们说：

加权平均值控制了混杂因素——专业选择。这些平均值表明，如果有的话，录取过程对男性存在偏见。

在这种情况下，39% 和 43% 的加权平均值究竟意味着什么？如何正确解释这些数字？原始百分比 45% 和 30% 似乎对我来说更容易理解和解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/652195/simpsons-paradox-in-freedman-pisani-and-purves-book</guid>
      <pubDate>Fri, 02 Aug 2024 05:33:00 GMT</pubDate>
    </item>
    <item>
      <title>该图显示的是异方差性还是同方差性？</title>
      <link>https://stats.stackexchange.com/questions/652188/does-this-graph-show-heteroscedasticity-or-homoscedasticity</link>
      <description><![CDATA[因此，我正在使用大约 13 年期间某些股票的股票数据，现在我想在 stata 上检查异方差和自相关性。残差与拟合值如下所示。


该图是否暗示异方差？

如果该图不够充分，我可以使用什么测试？潜在的自相关性可能会影响 Beusch-pagan 或怀特检验的结果，以确定异方差

]]></description>
      <guid>https://stats.stackexchange.com/questions/652188/does-this-graph-show-heteroscedasticity-or-homoscedasticity</guid>
      <pubDate>Fri, 02 Aug 2024 01:11:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么 glmnet 不像 lm 那样处理丢失数据？</title>
      <link>https://stats.stackexchange.com/questions/652183/why-doesnt-glmnet-handle-missing-data-the-way-lm-does</link>
      <description><![CDATA[在 R 中进行计算时，我有一些玩具数据，并尝试使用 glmnet 来拟合弹性网络模型。我注意到，即使只有一个缺失值，算法也不会执行，建议事先估算缺失值。
# 设置可重复性的种子
set.seed(123)

# 生成一个 100x5 的随机数矩阵
data_matrix &lt;- matrix(rnorm(100*5), nrow=100, ncol=5)
data_df &lt;- as.data.frame(data_matrix)
data_df[1:1, 3] &lt;- NA # 单个缺失值
# 生成一个包含 100 个观测值的向量 Y，每个观测值为 1、2 或 3
Y &lt;- sample(1:3, 100, replace=TRUE)
glmnet::cv.glmnet(x = as.matrix(data_df),
y = as.matrix(Y),
alpha = 0.5,
family = &quot;multinomial&quot;)
glmnet(x, y, weights = weights, offset = offset, lambda = lambda, 中的错误：
x 有缺失值；考虑使用 makeX() 来估算它们

从算法上讲，当有缺失值时，是什么原因导致弹性网络不适合？相反，当使用 lm 并且有缺失值时，
ctl &lt;- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,NA)
trt &lt;- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group &lt;- gl(2, 10, 20, labels = c(&quot;Ctl&quot;,&quot;Trt&quot;))
weight &lt;- c(ctl, trt)
lm.D9 &lt;- lm(weight ~ group)

代码运行无任何错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/652183/why-doesnt-glmnet-handle-missing-data-the-way-lm-does</guid>
      <pubDate>Thu, 01 Aug 2024 21:42:45 GMT</pubDate>
    </item>
    <item>
      <title>什么是最好的统计分析方法来分析不同代谢物随时间（时间 0、24 和 48 小时）的显著差异</title>
      <link>https://stats.stackexchange.com/questions/652164/what-is-the-best-statistical-analysis-to-analyse-significant-differences-in-diff</link>
      <description><![CDATA[我有 40 种不同的代谢物，我测量了它们在 0、24 和 48 小时时的浓度。我想知道每种代谢物是否随着时间的推移存在显著差异。我对代谢物之间是否存在差异并不感兴趣。我考虑对每种代谢物进行单向 Anova 重复测量 + Tukey 检验。所以最后我会得到 40 种不同的分析（Anova + Tukey）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652164/what-is-the-best-statistical-analysis-to-analyse-significant-differences-in-diff</guid>
      <pubDate>Thu, 01 Aug 2024 17:05:23 GMT</pubDate>
    </item>
    </channel>
</rss>