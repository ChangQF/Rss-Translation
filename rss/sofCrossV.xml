<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 08 Jun 2024 21:13:11 GMT</lastBuildDate>
    <item>
      <title>贝叶斯状态空间建模</title>
      <link>https://stats.stackexchange.com/questions/648882/bayesian-state-space-modelling</link>
      <description><![CDATA[频率派和贝叶斯派状态空间建模方法的主要区别是什么？它们都假设初始状态参数遵循随机游走吗？
此外，根据我的理解，贝叶斯状态空间建模使用 MCMC 方法来更新初始状态参数。如果这是真的，频率派方法是否假设时变系数模型的分布是固定的？]]></description>
      <guid>https://stats.stackexchange.com/questions/648882/bayesian-state-space-modelling</guid>
      <pubDate>Sat, 08 Jun 2024 21:03:16 GMT</pubDate>
    </item>
    <item>
      <title>三次拟合的误差与 y 数据的数量级有关，而不是与拟合质量有关</title>
      <link>https://stats.stackexchange.com/questions/648881/errors-on-cubic-fits-are-relative-to-the-order-of-magnitude-of-the-y-data-not-f</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648881/errors-on-cubic-fits-are-relative-to-the-order-of-magnitude-of-the-y-data-not-f</guid>
      <pubDate>Sat, 08 Jun 2024 21:00:05 GMT</pubDate>
    </item>
    <item>
      <title>如何处理固定效应和随机效应之间的方差竞争？</title>
      <link>https://stats.stackexchange.com/questions/648880/how-to-deal-with-competition-for-variance-between-a-fixed-and-random-effect</link>
      <description><![CDATA[我正在对数据进行分析，其中 X（预测变量）和 Y（响应）在广泛范围内存在假设关系，但由于预测变量的局部混合，在观察组中是随机的（无关系）。一个有趣的类比可能是餐厅里的杂烩碗，每个碗里都有不同数量的扇贝，从 10 到 100 个不等（大碗）。一碗杂烩包含未知数量的扇贝（非常大的碗）。这是一种浓稠的杂烩，因此您只能用大勺“品尝”，大勺平均能舀出与碗中扇贝总数成比例的扇贝。您还可以用勺子品尝杂烩 - 扇贝密度越高，味道越浓。此外，整个碗的味道混合均匀。我们想要确定勺子上的扇贝数量和勺子上杂烩汤的味道之间的关系（我们假设味道是由碗决定的，而不是勺子上的扇贝）。我们从每个碗中取出几把勺子（忽略消耗 - 大碗）。我们想应用一个混合模型，以味道强度作为预测因子（OK 风味浓度），勺子上的扇贝数量作为响应，碗作为随机效应的分组变量。理想情况下，我们希望定义整个餐厅的味道和数量之间的关系。我们可以轻松地汇总每个碗中的味道和计数并获得整体关系 - 但这并不能解释碗内计数的变化。当应用混合模型时，随机效应似乎解释了所有的计数变化，而预测因子（味道）并不显着。有没有比“汇总”更好的方法？在混合模型框架内如何理解这种关系？
之前有人问过类似的问题（当固定和随机效应重叠时会发生什么？），但没有得到回答。我在本文末尾添加了一个简单的模拟来说明这个问题（遗憾的是我没有添加任何杂烩）。感谢您的考虑。
干杯，Darren
#
# 固定和随机效应方差竞争
#
library(mgcv)
# 模拟一些包含 8 个组的数据
slope = 1
sY = 1 # 组内变异性
sYbar = 0.2 # 组关系变异性

# 潜在关系
grpX &lt;- c(1,1,2,2,4,4,6,6) # 每组平均 X
grpYbar &lt;- slope*grpX + rnorm(length(grpX))*sYbar
plot(grpX,grpYbar)
cor(grpX,grpYbar)^2

# 执行 500 次模拟
#
# 每组模拟 5 个响应
grp &lt;- c(1,2,3,4,5,6,7,8)
replicate &lt;- c(1,2,3,4,5)
# 要保存在向量中的值
Xp &lt;- as.numeric(NULL)
Sp &lt;- as.numeric(NULL)
Bx &lt;- as.numeric(NULL)
#
for (dups in 1:500) {
#
simData &lt;- as.data.frame(list(grp=as.numeric(NULL),
replicate=as.numeric(NULL),
X=as.numeric(NULL),
Y=as.numeric(NULL)))
for (i in grp) {
for (j in replicate) {
g &lt;- grp[i]
r &lt;- replicate[j]
X &lt;- grpX[i] + rnorm(1)
Y &lt;- grpYbar[i] + rnorm(1)*sY
simData &lt;- rbind(simData,list(grp=g,
replicate=r,
X=X,
Y=Y))
}
}
#
s1 &lt;- gam(Y ~ X + s(grp, bs = &#39;re&#39;),
data=simData,method=&quot;REML&quot;)
#
Xp &lt;- c(Xp,summary(s1)$p.table[2,4])
Sp &lt;- c(Sp,summary(s1)$s.table[1,4])
Bx &lt;- c(Bx,summary(s1)$p.table[2,1])
#
}

# 绘制重要性
par(mfrow=c(2,2))
hist(Xp,main = &quot;斜率 p 值&quot;)
abline(v=0.05,lty=2,col=&quot;red&quot;)
hist(Sp,main = &quot;随机效应 p 值&quot;)
abline(v=0.05,lty=2,col=&quot;red&quot;)
plot(Xp,Sp)
hist(Bx)

# 显著斜率
sum(Xp&lt;0.05)
# 显著 RE
sum(Sp&lt;0.05)
# 显著斜率(行) 按 RE(col)
Xsig &lt;- Xp&lt;0.05
Ssig &lt;- Sp&lt;0.05
sigTableData &lt;- as.data.frame(list(Xsig=Xsig,
Ssig=Ssig))
table(sigTableData)
]]></description>
      <guid>https://stats.stackexchange.com/questions/648880/how-to-deal-with-competition-for-variance-between-a-fixed-and-random-effect</guid>
      <pubDate>Sat, 08 Jun 2024 20:13:46 GMT</pubDate>
    </item>
    <item>
      <title>高度相关的 IV 之间不存在共线性</title>
      <link>https://stats.stackexchange.com/questions/648878/no-muticollinearity-between-highly-correlated-ivs</link>
      <description><![CDATA[假设我正在构建一个多元回归模型，其中 y 为因变量，X1、X2、...、Xn 为自变量。我遇到过 2 个自变量之间存在高度相关性的情况，例如 X1 和 X2 相关性为 0.81，但这两个驱动因素的 VIF 均小于 2。
有人可以解释为什么这是可能的吗？普遍的理解是高相关性导致多重共线性，正如这篇文章所解释的那样。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648878/no-muticollinearity-between-highly-correlated-ivs</guid>
      <pubDate>Sat, 08 Jun 2024 19:16:59 GMT</pubDate>
    </item>
    <item>
      <title>我的新个体内变异统计数据有意义吗？</title>
      <link>https://stats.stackexchange.com/questions/648877/are-my-new-intraindividual-variability-statistics-sensical</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648877/are-my-new-intraindividual-variability-statistics-sensical</guid>
      <pubDate>Sat, 08 Jun 2024 18:05:17 GMT</pubDate>
    </item>
    <item>
      <title>两个国家死亡率的最佳测试</title>
      <link>https://stats.stackexchange.com/questions/648876/best-test-for-mortality-rate-in-two-countries</link>
      <description><![CDATA[我们试图比较两个不同国家 20 年内的死亡率。Mann Whitney u 检验法是否最适合使用？我们不清楚数据是否被假定为正态分布，因为这些数字只是每年的死亡人数。]]></description>
      <guid>https://stats.stackexchange.com/questions/648876/best-test-for-mortality-rate-in-two-countries</guid>
      <pubDate>Sat, 08 Jun 2024 17:21:58 GMT</pubDate>
    </item>
    <item>
      <title>构建变量选择的子组比较</title>
      <link>https://stats.stackexchange.com/questions/648874/constructing-subgroup-comparisons-for-variable-selection</link>
      <description><![CDATA[我正尝试根据以下描述构建一个协变量：

在构建协变量以测量子组效应时，我们生成协变量来捕获给定子组中给定变量的因果效应。协变量的构建方式是，在每个子组中，治疗组和对照组形成对比；在子组之外，协变量设置为零。
此协变量的构建方式是，回归此协变量的结果的系数给出该子组中均值的差异。它通过将子组的观察值归零来实现这一点，但在该子组中创建治疗组和对照组之间的对比。请注意，可以构建此协变量来将治疗条件 k 中的那些与其他条件进行对比。该协变量将除 k 之外的所有治疗水平视为

基线，因此该协变量的系数应解释为

给定治疗与该变量的所有其他治疗水平的平均值之间的平均差异。

Ratkovic, M. (2021)。子组分析：陷阱、承诺和诚实。在 J. N. Druckman &amp; D. P. Green (Eds.) 中，实验政治科学进展 (第 271-288 页)。剑桥大学出版社。
我不确定如何构建这些子组协变量。这些协变量的目的是将它们中的许多变量包含在套索模型中以选择最重要的变量。由于我们有兴趣发现治疗效果的异质性，因此协变量应该代表子组内治疗和对照之间的均值差异（或如最后一句所述，总和对比差异）。如果协变量或相互作用意味着其他东西，那么您将调整错误的效应。
这些协变量应该如何编码？我在想也许可以将子组内控制编码为 -0.5，将子组内治疗编码为 0.5，将子组外的所有其他内容编码为 0。但您仍然必须在套索模型中排除一个类别，对吗？
我说得对，简单的治疗 x 子组方法不行吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648874/constructing-subgroup-comparisons-for-variable-selection</guid>
      <pubDate>Sat, 08 Jun 2024 16:43:55 GMT</pubDate>
    </item>
    <item>
      <title>假设残差在模型构建时与预测变量不相关，何时违反 E[Xi*ui]=0？</title>
      <link>https://stats.stackexchange.com/questions/648873/when-is-exiui-0-violated-given-that-the-residuals-are-by-construction-of-the</link>
      <description><![CDATA[首先：我知道“误差项”和“残差”是两个不同的概念。但是，我很难理解它们对（多元）线性回归和线性投影模型的影响。
在我的课堂上，我们为任何 PRF（不一定是线性）引入了一个线性投影模型，其中一个关键概念是正交性：
E[Xi*ui)=0（其中 0 是 (k+1)*1 向量）。
如果模型中有一个常数，则 Xi 和 ui 不相关。假设这里的 ui 是误差项，我不明白如果误差项和预测因子有任何关联，那么该属性（无关联）如何成立。

我不明白如何识别 E[Xi * ui]。如果 Xi 和 ui 相关，那么 Xi 和残差在构造上仍然不相关，我假设我们将使用残差来识别 E[Xi * ui]，因为我们无法观察到 ui。

如果 Xi 和 ui 相关，这是否意味着 E[Xi *ui) 不等于零？

何时违反 E[Xi * ui]= 0？我们如何识别任何违规行为？


我希望我的问题有意义，提前谢谢您 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/648873/when-is-exiui-0-violated-given-that-the-residuals-are-by-construction-of-the</guid>
      <pubDate>Sat, 08 Jun 2024 16:34:09 GMT</pubDate>
    </item>
    <item>
      <title>Cholesky 分解和 OLS 比较方法 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648872/cholesky-decomposition-and-comparing-methods-for-ols</link>
      <description><![CDATA[我一直在比较各种方法的速度和准确性，以找到最小二乘解。

$\beta = (X^TX)^{-1}X^Ty$
$R\beta = Q^Ty$ 和使用正向/反向替换进行 QR 因式分解求解
$\beta = V\Sigma^{-1}U^Ty$ 使用 SVD
$\beta = R^{-1}Q^Ty$
$L = Chol(X^TX)$，正向求解 $Z$：$LZ = X^Ty$，反向求解 $\beta$：$L^T\beta = Z$
$LU = X^TX$，正向求解 $Z$：$LZ = X^Ty$，反向求解 $\beta$：$U\beta = Z$

但是，$LU$ 和 Cholesky 得出的 MSE 比其他方法高得多。我的数据的条件数并不高，为 1.14，并且分解没有明显的精度损失。
L = np.linalg.cholesky(df.T.dot(df))
np.power(df.T.dot(df) - pd.DataFrame(L@L.T), 2).sum().sum() 
7.722374477305186e-22

结果：
QR w Triang Solve；平均时间=0.505；标准时间=0.307；MSE = 25.075
Numpy Inverse；平均时间=0.108；标准时间=0.035；MSE = 25.075
SVD Inverse；平均时间=0.353；标准时间=0.128；MSE = 25.075
R 的 QR 逆变换；平均时间=0.32；标准时间=0.115；MSE = 25.075
Cholesky；平均时间=0.064；标准时间=0.007；MSE = 46.143
LU；平均时间=0.109；标准时间=0.018； MSE = 46.143
问题：

我是否正确地执行了 Cholesky 和 ​​LU？
如果我做得正确，为什么 MSE 相对于其他方法如此之高？
为什么 numpy inverse 比其他方法（如 QR）快得多？我认为逆运算应该是昂贵的。

import time
import scipy
import numpy as np
import pandas as pd
from numba import jit

def print_info(method, times, mse):
print(f&quot;{method}; mean time={round(np.mean(times), 3)}; std time = {round(np.std(times), 3)}; MSE = {round(mse, 3)}&quot;)

np.random.seed(17)
ITERS = 10
SAMPLES = 20000
FEATURES = 100
df = pd.DataFrame(np.random.normal(size=(SAMPLES, FEATURES)))
df[&quot;intercept&quot;] = 1
BETA = np.random.normal(3, 10, size=FEATURES+1)
y = df.dot(BETA) + np.random.normal(0, 5, size=SAMPLES)

times = []
for i in range(ITERS):
start = time.time()
Q, R = np.linalg.qr(df)
beta = scipy.linalg.solve_triangular(R, Q.T.dot(y), check_finite=False)
times.append(time.time()-start)
print_info(&quot;QR w Triang Solve&quot;, times, np.mean((y-df.dot(beta))**2))

times = []
for i in range(ITERS):
start = time.time()
beta = np.linalg.inv(df.T.dot(df)).dot(df.T).dot(y)
times.append(time.time()-start)
print_info(&quot;Numpy Inverse&quot;, times, np.mean((y-df.dot(beta))**2))

times = []
for i in range(ITERS):
start = time.time()
U, s, Vh = np.linalg.svd(df, full_matrices=False)
beta = ((y.T@U)@np.diag(1/s))@Vh
times.append(time.time()-start)
print_info(&quot;SVD Inverse&quot;, times, np.mean((y-df.dot(beta))**2))

times = []
for i in range(ITERS):
start = time.time()
Q, R = np.linalg.qr(df)
beta = np.linalg.inv(R).dot(Q.T).dot(y)
times.append(time.time()-start)
print_info(&quot;QR Inv of R&quot;, times, np.mean((y-df.dot(beta))**2))

times = []
for i in range(ITERS):
start = time.time()
L = np.linalg.cholesky(df.T.dot(df))
Z = scipy.linalg.solve_triangular(L, df.T.dot(y), check_finite=False)
beta = scipy.linalg.solve_triangular(L.T, Z, check_finite=False)
times.append(time.time()-start)
print_info(&quot;Cholesky&quot;, times, np.mean((y-df.dot(beta))**2))

times = []
for i in range(ITERS):
start = time.time()
L, P, U = scipy.linalg.lu(df.T.dot(df), permute_l=False)
Z = scipy.linalg.solve_triangular(L, df.T.dot(y), check_finite=False)
beta = scipy.linalg.solve_triangular(U, Z, check_finite=False)
times.append(time.time()-start)
print_info(&quot;LU&quot;, times, np.mean((y-df.dot(beta))**2))

]]></description>
      <guid>https://stats.stackexchange.com/questions/648872/cholesky-decomposition-and-comparing-methods-for-ols</guid>
      <pubDate>Sat, 08 Jun 2024 16:19:45 GMT</pubDate>
    </item>
    <item>
      <title>在什么条件下，省略变量的回归的其余系数会相对于完整回归中的系数进行“缩放”？</title>
      <link>https://stats.stackexchange.com/questions/648871/under-what-conditions-are-the-remaining-coefficients-of-a-regression-with-a-vari</link>
      <description><![CDATA[我正在阅读这篇文章讨论了从回归方程中省略变量的影响，并分析了它将产生的影响。
这是他们使用的一些符号：给定一个数据矩阵$X$，响应变量$y$，我们有回归系数的正态方程：
$$\widehat{\beta} = (X&#39;X)^{-1}X&#39;y$$
现在假设我们省略了一些变量 z。如果我们重新运行包含该变量的回归，我们将得到新的回归系数$\beta, \gamma$，这样
$$y \sim X\beta + z\gamma$$
然后，他们给出了带有省略变量的回归系数的方程，该方程是完整回归系数的方程：
$$\widehat{\beta} = (X&#39;X)^{-1}X&#39;y=(X&#39;X)^{-1}X&#39;(X\beta + z\gamma + \epsilon)$$
$$=(X&#39;X)^{-1}X&#39;X\beta +(X&#39;X)^{-1}X&#39;z\gamma + (X&#39;X)^{-1}X&#39;\epsilon $$
在我的特定情况下，X 中的每个回归变量都是随机（不相关）伯努利变量，取值范围为 $\{0,1\}$，因此它们都具有相同的均值和方差，没有协方差。
我试图使用上述分析来理解以下条件成立的条件：当我们省略一个变量时，其余系数都会按比例缩放，因此当所有系数都设置为 1 时，预测值与之前保持不变。
换句话说，假设当完整回归中的所有回归变量都设置为 1（即所有回归变量的总和）：
$$C=\widehat{\beta}\mathbf{1}+\gamma$$
在什么条件下$$\widehat{\beta} = \frac{\beta}{C-\gamma}成立？$$
我的直觉是，在我的特殊情况下应该是这种情况，我正在尝试证明它是否正确。我认为它应该是真的的原因是，当你省略变量时，所有回归变量设置为 1 时的预测会太低，需要扩大。由于所有变量都具有相同的方差且没有相关性，我认为它们都应该按相同的比例增加。
有人能帮我证明这个说法吗？或者根据我的特殊情况的限制，证明另一个同样简单但实际上正确的说法？
不幸的是，从上面的数学运算来看，由于$X$和$z$中的每个回归量都是不相关的，$X&#39;z=0$，因此不完全回归中的回归系数不应出现预期的“膨胀”。但这似乎不正确……
谢谢，
保罗]]></description>
      <guid>https://stats.stackexchange.com/questions/648871/under-what-conditions-are-the-remaining-coefficients-of-a-regression-with-a-vari</guid>
      <pubDate>Sat, 08 Jun 2024 16:05:55 GMT</pubDate>
    </item>
    <item>
      <title>Kendall 的 tau 和 Spearman 函数用于混合 copula</title>
      <link>https://stats.stackexchange.com/questions/648870/kendalls-tau-and-spearman-for-mixture-copulas</link>
      <description><![CDATA[我对混合 copula 模型很感兴趣。我读过（本文第 1694 页）
&quot;Spearman 凸组合 copula 的 $\rho$ 等于单个 Spearman 凸组合的 $\rho$。&quot; 然而，Kendall 的 tau 并非如此。
我的问题是：
假设我对计算混合 copula 凸组合的相关性感兴趣。根据上述论文的研究结果，使用 Spearman 的 rho 比使用 Kendall 的 tau 更好吗？还是我需要在这里理解一些东西？]]></description>
      <guid>https://stats.stackexchange.com/questions/648870/kendalls-tau-and-spearman-for-mixture-copulas</guid>
      <pubDate>Sat, 08 Jun 2024 14:39:31 GMT</pubDate>
    </item>
    <item>
      <title>Mplus 中的两级多组模型</title>
      <link>https://stats.stackexchange.com/questions/648864/twolevel-multgroup-model-in-mplus</link>
      <description><![CDATA[我想使用 Mplus 运行具有两个组的两级多组模型（例如用户指南中的示例 9.11）。
我的问题：我有一个独立变量 X，该变量在 A 组中仅在 2 级单位之间变化，即 X 是 A 组中的仅间变量。
因此，我将 X 指定为“between=”变量。然而，在 B 组中，相同的独立变量 X 在组间和组内都变化。是否有可能估计这样的模型 - 如果可以，如何估计？]]></description>
      <guid>https://stats.stackexchange.com/questions/648864/twolevel-multgroup-model-in-mplus</guid>
      <pubDate>Sat, 08 Jun 2024 10:22:41 GMT</pubDate>
    </item>
    <item>
      <title>线性回归：当结果变量是计数数字时，用百分比变化来解释系数</title>
      <link>https://stats.stackexchange.com/questions/648857/linear-regression-interpret-coefficient-in-terms-of-percentage-change-when-the</link>
      <description><![CDATA[我有一个线性回归，其中 Y 是一个计数数字。
Y = a + b1X1 + b2X2

我知道我们可以将 b1 解释为：X1 增加一个单位将使 Y 改变 b1。但我如何以百分比的形式解释它？我知道当 Y 是计数数字时我可以使用泊松。但仅给出线性回归，有没有办法将 b1 解释为百分比值？]]></description>
      <guid>https://stats.stackexchange.com/questions/648857/linear-regression-interpret-coefficient-in-terms-of-percentage-change-when-the</guid>
      <pubDate>Sat, 08 Jun 2024 04:31:37 GMT</pubDate>
    </item>
    <item>
      <title>回归方法之间的差异</title>
      <link>https://stats.stackexchange.com/questions/648856/difference-between-regression-methods</link>
      <description><![CDATA[在给定数据的统计建模中，何时使用逻辑回归，何时使用 beta 回归？如何知道它们之间的区别？什么时候我可以只拟合线性回归，而不必担心数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/648856/difference-between-regression-methods</guid>
      <pubDate>Sat, 08 Jun 2024 03:50:36 GMT</pubDate>
    </item>
    <item>
      <title>使用二元结果的功率计算（使用 R 包和手动模拟）</title>
      <link>https://stats.stackexchange.com/questions/648852/power-calculation-with-a-binary-outcome-using-a-r-package-manual-simulation</link>
      <description><![CDATA[我试图在相同的设置下比较三种不同的功效计算方法。虽然我理解由于随机性，每种方法的功效估计不可能完全相同，但我预计它们会非常相似。然而，我观察到功效估计略有不同。
基本设置如下：

结果：二进制（成功 1；失败 0）
要比较的两组：G1 vs G2
G1：样本数 - 150；成功率为 0.2
G2：样本数 - 30；成功率为 0.4
显著性水平为 0.2（不是通常的 0.05）

也就是说，
p1 &lt;- 0.2
p2 &lt;- 0.4

n1 &lt;- 150
n2 &lt;- 30

我使用的三种方法是：

使用 pwr 包中的 pwr.2p2n.test 函数。
使用 prop.test 函数进行模拟。
使用 fisher.test 函数进行模拟

### -------------------------------- ###
### --- 版本 1：pwr.2p2n.test --- ###
### -------------------------------- ###
library(pwr)
pwr.2p2n.test(h = ES.h(p1 = p1, p2 = p2), 
n1 = n1, n2 = n2,
sig.level = 0.20,
alternative = &quot;less&quot;)

# power = 0.9145152

### ---------------------------- ###
### --- 版本 2：Prop 测试 --- ###
### ---------------------------- ###
nreps &lt;- 10000
y1 &lt;- rbinom(n = nreps, size = n1, p = p1)
y2 &lt;- rbinom(n = nreps, size = n2, p = p2)

pval &lt;- rep(NA, nreps)
for(i in 1:nreps) {
pval[i] &lt;- prop.test(c(y1[i], y2[i]), 
n= c(n1, n2), 
alternative = &quot;less&quot;,
p = NULL, correct = TRUE)$p.value
}

power &lt;- sum(pval &lt; 0.20) / nreps 
power # [1] 0.8756

### -------------------------------------- ###
### --- 版本 3：Fisher 精确检验 --- ###
### -------------------------------------- ###
pval.fin &lt;- c()
for(i in 1:nreps){
y1 &lt;- rbinom(n1, size = 1, p = p1)
y2 &lt;- rbinom(n2, size = 1, p = p2)
dat.comb &lt;- rbind(data.frame(res = y1, group = &quot;G1&quot;),
data.frame(res = y2, group = &quot;G2&quot;))
tab &lt;- table(dat.comb$group, dat.comb$res)
test.res &lt;- fisher.test(tab, alternative = &#39;less&#39;)
pval.fin[i] &lt;- test.res$p.value
}
mean(pval.fin&lt;0.2) # [1] 8e-04

我注意到了以下两点：

第三种方法使用 Fisher 精确检验，其幂为 8e-0.4。但是，如果我将“替代”选项从“less”更改为“greater”，幂将变为 0.8811，这与我们从第一种方法和第二种方法中获得的结果相似。但是第一种方法和第二种方法使用了“less”的“替代”选项……我不明白是什么导致了如此巨大的差异。

版本 1 和版本 2 的幂估计也有点偏差。我不太清楚是什么导致了这种差异。


有人能帮我理解为什么即使设置相同，我也没有获得类似的功率吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648852/power-calculation-with-a-binary-outcome-using-a-r-package-manual-simulation</guid>
      <pubDate>Fri, 07 Jun 2024 22:15:04 GMT</pubDate>
    </item>
    </channel>
</rss>