<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 08 Sep 2024 06:20:57 GMT</lastBuildDate>
    <item>
      <title>处理回归问题中的噪声</title>
      <link>https://stats.stackexchange.com/questions/654026/handling-noise-in-regression-problem</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654026/handling-noise-in-regression-problem</guid>
      <pubDate>Sun, 08 Sep 2024 05:53:11 GMT</pubDate>
    </item>
    <item>
      <title>矩阵范数的次梯度</title>
      <link>https://stats.stackexchange.com/questions/654025/subgradient-of-the-matrix-norm</link>
      <description><![CDATA[当我想要获得矩阵变量套索方法的统计特性时，例如，
$$
\hat{X}=\underset{X\in \mathbb{R}^{n\times n}}{\arg \min}\mathcal{L}\left(X\right)+\lambda_n \|X\|_1,
$$
其中 $\mathcal{L}$ 是损失函数，$\|X\|_1=\sum_{i,j}|X_{ij}|$。我总是从其方向导数的角度关注 KKT 条件。因此，我有
$$
\mathcal{L}^{\prime}\left(\hat{X}\right)+\lambda_n Z,
$$
其中$Z\in \partial\|\hat{X}\|_1$且$\|Z\|_{\max}=\underset{i,j}{\max}|Z_{ij}|\le 1$。
我们能否限制$Z$的谱范数？我了解到，如果 $Z$ 是核范数的次梯度，则 $Z$ 的谱范数小于 1。逐元素 1 范数是否具有类似的性质？]]></description>
      <guid>https://stats.stackexchange.com/questions/654025/subgradient-of-the-matrix-norm</guid>
      <pubDate>Sun, 08 Sep 2024 04:56:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 svd 进行连续平方和</title>
      <link>https://stats.stackexchange.com/questions/654024/sequential-sum-of-squares-with-svd</link>
      <description><![CDATA[我正在研究一些确定线性回归系数的方法，并且我想知道如何找到连续平方和，或者显示anova(lm)的 ANOVA 表的第二列。如果我们使用 $\boldsymbol{Q} \boldsymbol{R}$，则连续平方和由
\begin{align*}
(\boldsymbol{Q}^T \boldsymbol{X})^2 
\end{align*&gt;
在 Cholesky 中，我们必须求解 $\boldsymbol{L} \ell = \boldsymbol{X}^T \boldsymbol{Y}$ , $\boldsymbol{L}^T \boldsymbol{\beta} = \ell$，并且连续平方和由
\begin{align*}
\ell^2 
\end{align*&gt;
但是那 SVD 呢？我还没有找到任何使用分解 $\boldsymbol{X} =\boldsymbol{U} \boldsymbol{D} \boldsymbol{V}^T $ 来确定连续平方和的方法，

我也没有找到任何关于此内容的参考资料或书籍。任何形式的帮助我都会很感激。问候]]></description>
      <guid>https://stats.stackexchange.com/questions/654024/sequential-sum-of-squares-with-svd</guid>
      <pubDate>Sun, 08 Sep 2024 03:17:27 GMT</pubDate>
    </item>
    <item>
      <title>过度拟合时间序列</title>
      <link>https://stats.stackexchange.com/questions/654023/overfitting-time-series</link>
      <description><![CDATA[我只有一个时间序列$(y_0, t_0), (y_1,t_1), \ldots, (y_n, t_n)$，其中$y_i \in \mathbb{R}$和$t_0 &lt; \cdots &lt; t_n$。人们相信这些是函数 $f(t; \mu)$ 上的点，其中 $\mu \in \mathbb{R}^d$ 是可学习参数，从某种意义上说，$y_i$ 是 $Y_i$ 的实现，如下所示：
\begin{equation*}
Y_i = f(t_i;\mu) + \epsilon_i
\end{equation*&gt;
这里 $\epsilon_i$ 是独立同分布的误差项，即正态分布，均值为 $0$，方差有一定差异。
假设我们是频率论者。我们使用最小二乘法等方法来估计$\hat{\mu}$并进行推断。
问题是，在$d$和$n$方面，是否存在任何经验法则，适用于大类函数$f$，可以让人判断是否存在过度拟合。我对两种情况特别感兴趣。第一种是（非线性回归情况）平滑单峰（即只有一个峰值）函数$f$，我的时间序列就是这样的。第二种是多项式（甚至是多项式的非线性函数，如机器学习中的高斯多项式），这是我们经常遇到的。]]></description>
      <guid>https://stats.stackexchange.com/questions/654023/overfitting-time-series</guid>
      <pubDate>Sun, 08 Sep 2024 01:13:19 GMT</pubDate>
    </item>
    <item>
      <title>岭回归与在正则化共线性时强制系数符号</title>
      <link>https://stats.stackexchange.com/questions/654021/ridge-regression-vs-enforcing-coefficient-signs-when-regularizing-colinearity</link>
      <description><![CDATA[处理多重共线性问题时，一个标准解决方案是运行岭回归。因此，当$x_1$和$x_2$高度相关时，我们避免拟合$y = 10000 x_1 - 9999 x_2 $。
我想知道为什么强制回归系数的符号在文献中没有得到很好的讨论？例如，我们对$\text{min} || y - \sum \beta_i x_i ||^2$进行优化，但要满足$\beta_i \geq 0$。我们可以强制 $x_i$ 和 $y$ 的相关性始终为正（通过在回归之前翻转 $x_i$ 的符号）
我只是觉得那将是一个更好的解决方案，因为它不涉及在岭回归中选择神奇的收缩参数 $\lambda$。我们的解决方案没有太大偏差。强制符号有什么缺点？]]></description>
      <guid>https://stats.stackexchange.com/questions/654021/ridge-regression-vs-enforcing-coefficient-signs-when-regularizing-colinearity</guid>
      <pubDate>Sat, 07 Sep 2024 23:27:30 GMT</pubDate>
    </item>
    <item>
      <title>除了过度拟合之外，概括的统计历史先例是什么？</title>
      <link>https://stats.stackexchange.com/questions/654020/whats-the-statistical-historical-precedence-for-generalisation-beyond-overfitti</link>
      <description><![CDATA[最近的一项研究表明，对于过度参数化的系统，泛化超越了过度拟合 [*]。统计文献中是否有先例，或者这是深度学习的新现象？
[*] Grokking：在小型算法数据集上超越过度拟合的泛化
arXiv:2201.02177]]></description>
      <guid>https://stats.stackexchange.com/questions/654020/whats-the-statistical-historical-precedence-for-generalisation-beyond-overfitti</guid>
      <pubDate>Sat, 07 Sep 2024 23:15:10 GMT</pubDate>
    </item>
    <item>
      <title>使用蒙特卡洛实验验证异方差和自相关稳健 SE 的一致性</title>
      <link>https://stats.stackexchange.com/questions/654007/verifying-consistency-of-heteroscedasticity-and-autocorrelation-robust-ses-with</link>
      <description><![CDATA[我试图通过蒙特卡洛实验证明 R 的 sandwhich 包中给出的默认 HAC 标准误差的一致性。我使用的线性模型定义为 $Y = X + \varepsilon$，其中 $X_i \sim N(1,1)$，$X\perp\varepsilon$，以及 $\varepsilon \sim N(\mathbf 0, \Sigma)$，其中
$ \boldsymbol\Sigma_{ij} = \rho^{|i-j|}$，其中 $\rho \in (-1,1)$。如果 $\hat{\beta}$ 是 OLS 估计量，我们可以将其渐近方差简化如下：
$$ \text{Avar}(\hat {\beta}) = \text{E}[X&#39;X]^{-1}X&#39;\Sigma X(X&#39;X)^{-1} = \frac{1}{2n(1-\rho)} - \frac{\rho(1-\rho^n)}{2n^2(1-\rho)^2}.$$
我已经通过以下蒙特卡洛实验验证了这个数学公式：
library(mvnfast)
library(tidyverse)
library(sandwich)

set_Sigma_ij &lt;- function(i, j, rho){
rho^abs(i-j)
}

generate_Sigma &lt;- function(rho, n){
expand_grid(i = 1:n, j = 1:n) %$% 
map2_dbl(i, j, \(i,j) set_Sigma_ij(i,j, rho)) %&gt;% 
matrix(nrow = n) 
}

draw_ols_realization &lt;- function(n, rho){
eps &lt;- rmvn(
n = 1, 
mu = rep(0, n), 
sigma = generate_Sigma(rho = rho, n = n)
) %&gt;% 
as.numeric()
X &lt;- rnorm(n = n, mean = 1, sd = 1)
Y &lt;- X + eps
lm(Y ~ X - 1) %&gt;% 
coef()
}

true_avar_ols &lt;- function(n, rho){
(1/(2*n*(1-rho))) - (rho*(1-rho^n)) / (2*n^2 * (1-rho)^2)
}

numerical_avar_ols &lt;- function(N, n, rho){
1:N %&gt;% 
map_dbl(\(t) draw_ols_realization(n, rho)) %&gt;% 
var()
}

# 插入几个值以确认（对于足够大的 n）
true_avar_ols(n = 140, rho = 0.8)
numerical_avar_ols(N = 1e4, n = 140, rho = 0.8)

当我确认 HAC 标准误差（或者更确切地说是相应的协方差矩阵）始终估计 $\text{Avar}(\hat {\beta})$ 时，结果没有多大意义。这是我的代码：
estimate_avar_beta &lt;- function(n, rho, X, Y){
estimate_model &lt;- lm(Y[1:n] ~ X[1:n] - 1) 
tibble(
standard = as.numeric(vcov(estimated_model)),
HAC = as.numeric(vcovHAC(estimated_model)),
sample_size = n
)
}

# 估计固定 (Y, X) 的 Avar(OLS)，同时让 n 增长
estimate_avar_beta_over_n &lt;- function(n_vals, rho){
eps &lt;- rmvn(
n = 1, 
mu = rep(0, max(n_vals)), 
sigma = generate_Sigma(rho = rho, n = max(n_vals))
) %&gt;% 
as.numeric()
X &lt;- rnorm(n = max(n_vals), mean = 1, sd = 1)
Y &lt;- X + eps
n_vals %&gt;% 
map_df(\(n) HAC_SEs(n, rho, X, Y))
}

# 现在执行此操作 N 次 
draw_N_estimates_avar_beta_over_n &lt;- function(N, n_vals, rho){
1:N %&gt;% 
map_df(\(t) draw_HAC_SEs_over_n(n_vals, rho))
}

结果 &lt;- draw_N_estimates_avar_beta_over_n(
N = 1e2, 
n_vals = (1:10)*100, 
rho = 0.9
)

vcovHAC 给出的估计值似乎不一致。
我在这里做错了吗？如果是，是什么？ n = 1000 的样本量是否太小？我对 $\text{Avar}(\hat {\beta})$ 的表达是否不正确？我是不是犯了一个愚蠢的错误，盯着这个看了一个多小时后才发现？提前谢谢大家！]]></description>
      <guid>https://stats.stackexchange.com/questions/654007/verifying-consistency-of-heteroscedasticity-and-autocorrelation-robust-ses-with</guid>
      <pubDate>Sat, 07 Sep 2024 16:51:28 GMT</pubDate>
    </item>
    <item>
      <title>关于随机森林回归中的 R 平方</title>
      <link>https://stats.stackexchange.com/questions/654002/about-r-squared-in-random-forest-regression</link>
      <description><![CDATA[假设我有三个特征[x1, x2, x3]和一个目标变量y1用于随机森林回归模型。我有两个数据集：df1，它仅包含相关特征 [x1, x2, x3]，以及 df2，它除了 [x1, x2, x3] 之外还包含其他不相关的列（例如，x4、x5）。
现在，我想仅使用特征 [x1, x2, x3] 和目标 y1 对 df1 和 df2 运行随机森林回归，如下所示。
使用 train_test_split 函数将数据集拆分为训练集和测试集。训练集用于拟合 RandomForestRegressor 模型，测试集用于评估模型的性能。在训练数据 (X_train, y_train) 上训练模型后，将对测试集 (X_test) 进行预测。
通过使用 r2_score 函数比较测试集 (y_pred) 上的预测与实际测试集值 (y_test)，计算出 $R^2$ 分数作为样本外性能衡量标准。
两个数据集的 $R^2$ 值是否相同？为什么或为什么不相同？]]></description>
      <guid>https://stats.stackexchange.com/questions/654002/about-r-squared-in-random-forest-regression</guid>
      <pubDate>Sat, 07 Sep 2024 14:54:08 GMT</pubDate>
    </item>
    <item>
      <title>混合效应逻辑回归模型中的膨胀固定效应</title>
      <link>https://stats.stackexchange.com/questions/653977/inflated-fixed-effects-in-mixed-effects-logistic-regression-model</link>
      <description><![CDATA[我有一个数据集，每个 ID 有多个观测值，并且有一个二元结果。我试图拟合混合效应逻辑回归，但是，截距的固定效应估计值与我的预期相比非常大。无论我使用的是哪个统计软件包或 R 版本，这都是正确的：
library(lme4)
library(glmmTMB)
library(brms)

fit_lme4 &lt;- glmer(outcome ~ (1 | ID), data = data, family = &quot;binomial&quot;)
fit_TMB &lt;- glmmTMB(outcome ~ (1 | ID), data = data, family = &quot;binomial&quot;)
fit_brm &lt;- brm(outcome ~ (1 | ID), data = data, family = bernoulli(link=&quot;logit&quot;))

mean(data$outcome) # 0.7371429
plogis(fixef(fit_lme4)) # 0.9993405
plogis(fixef(fit_lme4)$cond) # 0.9993405
plogis(summary(fit_brm)$fixed[[1]]) # 0.9452537

以下是用于重现上述脚本的 data 的内容。
我怀疑这可能是因为许多 ID 总是有相同的结果（例如，对于 ID 1，结果始终为 1），但我不确定。
对此有什么潜在的解决方案？]]></description>
      <guid>https://stats.stackexchange.com/questions/653977/inflated-fixed-effects-in-mixed-effects-logistic-regression-model</guid>
      <pubDate>Fri, 06 Sep 2024 16:43:55 GMT</pubDate>
    </item>
    <item>
      <title>做t检验时，样本标准差应该用样本均值减去原假设均值来估计吗？</title>
      <link>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</link>
      <description><![CDATA[以 t 检验为例，检验实数样本$x_i$是否来自均值为 0 的分布（$H_0:\mu=0, H_a:\mu \neq 0$）。检验统计量将是$t=\frac{\bar{x}}{s/\sqrt{n}}$。
我的问题是$s^2=\frac{\sum_i(x_i - \bar{x})^2}{n-1}$还是$s^2=\frac{\sum_i x_i^2}{n}$。
在大多数文本中我看到的是前者，但在财务数据中我有时看到后者。两者似乎也都说得通，前者使用正态样本标准差公式，后者使用零假设，也不再需要贝塞尔校正。
两者的优缺点是什么，有没有更合适的方法？
编辑：总结一下，看起来，通过适当的处理来获得任一检验统计量的分位数，检验是等效的。但只有前者遵循 t 分布。最后，它们都渐近地接近同一件事。]]></description>
      <guid>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</guid>
      <pubDate>Thu, 05 Sep 2024 10:20:49 GMT</pubDate>
    </item>
    <item>
      <title>在轮盘赌中，出现长红色序列的频率是否低于出现短红色序列的频率？</title>
      <link>https://stats.stackexchange.com/questions/653816/in-roulette-is-the-frequency-of-getting-long-sequences-of-reds-lower-than-that</link>
      <description><![CDATA[在一场无限期的轮盘游戏中，与连续 10 次出现红色相比，连续 100 次出现红色的概率（可能每百万次旋转才出现一次）要小得多，这样说对吗？
如果出现一长串红色的概率会随着序列变长而降低，那么为什么认为在一长串红色之后出现黑色的可能性更大会被视为赌徒谬误？如果 101 次出现红色的序列比 100 次出现红色的序列出现的可能性更小，那么为什么认为当前序列更有可能是 100 次出现红色并因此下一轮旋转将是黑色是错误的？
编辑：
我知道这些都是独立事件，概率没有记忆，因此必须保持不变。我在问，这一事实如何与较长序列出现频率较低的说法相一致。
此外，我并不是说根据大数定律，它应该平衡，因此下一次旋转更有可能是黑色。我是说，我们更有可能处于 100 个红色的序列而不是 101 个红色的序列，因为它发生的频率更高，并且如果更有可能假设现在是较短的序列而不是较长的序列，那么从逻辑上讲，下一次旋转更有可能是黑色不是吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653816/in-roulette-is-the-frequency-of-getting-long-sequences-of-reds-lower-than-that</guid>
      <pubDate>Tue, 03 Sep 2024 23:44:05 GMT</pubDate>
    </item>
    <item>
      <title>仅包含负值的相关性热图？</title>
      <link>https://stats.stackexchange.com/questions/632218/a-correlation-heatmap-with-only-negative-values</link>
      <description><![CDATA[撇开这些总体上相当弱的相关性不谈，这张由不同用户使用的产品的相关性热图（只有负值）对任何人来说是否都很奇怪？
我对这种分析还不熟悉，但其中有些东西似乎很奇怪：当所有东西的价值上升都与其他所有东西的价值下降相关时。我猜可能是使用一种东西意味着不使用另一种东西，但这似乎有点“零和”。
我是不是想太多了？
]]></description>
      <guid>https://stats.stackexchange.com/questions/632218/a-correlation-heatmap-with-only-negative-values</guid>
      <pubDate>Fri, 24 Nov 2023 11:54:35 GMT</pubDate>
    </item>
    <item>
      <title>如何处理 LASSO 中的序数预测变量/独立变量？</title>
      <link>https://stats.stackexchange.com/questions/599631/how-to-handle-ordinal-predictors-independent-variables-in-lasso</link>
      <description><![CDATA[您好：我想使用 LASSO 从 150 个列表中选择独立变量。大多数独立变量都采用李克特量表 (1-非常不同意，...，5-非常同意)。最好使用这些独立变量的序数性质，而不是将它们视为名义独立变量。
我查看了两个相关帖子：

逻辑回归和序数独立变量

正如 @Scortchi 所说，“您可以使用正交多项式来扩展这个想法，以编码序数预测器。” （Agresti 的书，第 5.4.6 节）。

如何将序数分类变量处理为独立变量

这两篇文章非常有帮助。
不过，对于我的研究，我想使用具有许多序数预测因子/独立变量的 LASSO。
那么我该怎么办？我可以在 LASSO 中应用正交多项式吗（例如，在帖子 1 中，gung - 恢复 Monica 所示的正交多项式。我想知道 LASSO 是否理解输出中的“ord.x.L、ord.x.Q、ord.x.C、ord.x^4”）？或者采取一种简单的方法，例如在 LASSO 中将序数预测变量视为连续预测变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/599631/how-to-handle-ordinal-predictors-independent-variables-in-lasso</guid>
      <pubDate>Tue, 20 Dec 2022 16:00:22 GMT</pubDate>
    </item>
    <item>
      <title>岭回归，较大的 lambda 会导致训练数据的 RMSE 较小</title>
      <link>https://stats.stackexchange.com/questions/596879/ridge-regression-large-lambda-results-in-smaller-rmse-of-the-training-data</link>
      <description><![CDATA[我正在使用闭式解法对一天的传感器数据进行岭回归训练，其中
$$ \beta=(X^TX+\lambda*I)^{-1}X^TY $$ 和 Matlab。
$X$ 是 15 个多项式时间矩阵。我创建了一个循环，其中在岭回归中使用了不同的 lambda，然后将此模型应用于训练集，然后使用从上述方程中获得的 $\beta$ 计算预测结果的 RMSE。
随着 lambda 的增加，RMSE 会随着较小的 lambda 值而减小，然后增加，这是意料之外的。我预计，随着约束的增加，RMSE 会随着 lambda 值的增加而保持增加趋势。只是为了澄清一下，我理解 RMSE 预计会先下降，然后对于测试集增加。但是，当我仅针对训练数据集测试模型时，就会发生此问题。
我不明白是什么原因导致了这个问题。有人能帮我解决这个问题吗？非常感谢。
注意：

我意识到我的时间数组没有标准化，这个问题只发生在时间数组被随机缩放因子缩放时。但我不明白为什么缩放会导致这个问题。PS。我在岭回归之前已经标准化了 x 矩阵。RMSE 随着 lambda 的增加而增加。然而，RMSE 的梯度随着 lambda 的增加而减小，这与没有标准化的情况不同。有没有具有高级数学背景的人可以对此提供任何评论？哪种梯度变化对你来说更有意义？



带有 lambda 的 RSE 图如下所示：


更新说明：根据下面 Edm 的评论，这可能是由于 x 值较大导致的机器数值误差。因此，我计算了具有不同多项式次数的 RMSE 与 lambda 的图。图表如下所示。问题发生在多项式次数约为 15 左右的地方。此外，30 次多项式的 x 矩阵中最大值为 2e^103。根据我的知识，matlab 可以处理比这大得多的数字，最高可达 1e^1023 左右？任何有关此问题的评论都值得赞赏！


抱歉，我无法提供数据集。但下面是我的 matlab 代码，如果有帮助的话？


%load the data
load xxx.mat

pm2d5= data.pm2d5;
time = data.time;
warning (&#39;off&#39;,&#39;all&#39;);

fig = figure(&#39;Position&#39;, [0,0,850,1100]);
t_num=[1:59:60*5-1];%缩放因子

for iii=1:length(t_num)
%如果更改为秒单位，再乘以 60，结果会发生变化。
time_num = (datenum(time)-floor(datenum(time)))*24*t_num(iii); %时间改为秒并应用缩放因子

%设置 xmatrix，15 度多项式 
dim=15;
x_matrix=ones(length(time_num),dim+1);
for i=1:dim+1
x_matrix(:,i)=time_num.^(dim+1-i);
end
dim=size(x_matrix,2);

%计算 Ridge 方法不同 lambda 的 RSE
num=0:0.001:3;
for ii=1:length(num)
lambda=num(ii);
theta=((x_matrix.&#39;*x_matrix)+lambda*eye(dim))\(x_matrix.&#39;)*pm2d5;
yfit=x_matrix(:,1:end-1)*theta(1:end-1);
intercept=theta(end);
RSE(ii,iii)=sqrt(mse(yfit+intercept,pm2d5));
end
plot(num, RSE(:,iii),&#39;DisplayName&#39;,num2str(t_num(iii)))
hold on
end
legend
xlabel(&#39;lambda&#39;)
ylabel(&#39;RSE&#39;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/596879/ridge-regression-large-lambda-results-in-smaller-rmse-of-the-training-data</guid>
      <pubDate>Thu, 24 Nov 2022 19:23:57 GMT</pubDate>
    </item>
    <item>
      <title>多个 Mann-Whitney 检验的 P 值校正，其中一些是依赖的</title>
      <link>https://stats.stackexchange.com/questions/577624/p-value-correction-for-multiple-mann-whitney-tests-some-of-them-being-dependent</link>
      <description><![CDATA[我使用 Mann-Whitney U 检验进行了多次比较，并希望校正 p 值以了解哪些结果值得报告。数据结构如下：
2 个实验，其中在 Z 个个体中随时间（Y 个时间步长）测量了 X 个不同的指标。
目标是了解 2 个实验中的个体在指标上是否不同。由于每个组中的测量值对于 Mann-Whitney 来说都是独立的，因此每个时间步长都会运行一次测试。这就是为什么我想知道校正是否应该考虑到一些测试是相互关联的（同一测量的不同时间步骤），如果是，我该怎么做？
我打算在测试表明有显著差异时绘制数据，以检查效果是否真的存在，并且可能只有当检测到同一指标的几个时间步骤在各组之间存在差异时才会得出有力的结论。
我还想知道我执行的初步步骤是否有效：

测量的指标有时会低​​于检测限（LOD），因此这些都将被 Mann-Whitney 视为平局。因此，我排除了先验比较，其中每个组中超过检测限的测量值少于 5 个（如果一个组只有 LOD 的测量值，而另一个组有许多高于 LOD 的测量值，我认为运行测试就足够了）。
在剩余的比较中，我使用 Levene 检验来测试方差是否相等。我排除了方差不等的比较（阈值为 5%，我在此步骤中不校正 p 值）。在这里，一个组只有 LOD 的测量值，而另一个组显示变化的情况最终被排除在外……
我对剩余的比较运行 Mann-Whitney 检验。
]]></description>
      <guid>https://stats.stackexchange.com/questions/577624/p-value-correction-for-multiple-mann-whitney-tests-some-of-them-being-dependent</guid>
      <pubDate>Fri, 03 Jun 2022 14:01:55 GMT</pubDate>
    </item>
    </channel>
</rss>