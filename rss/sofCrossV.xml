<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 04 Jan 2024 03:15:46 GMT</lastBuildDate>
    <item>
      <title>在给定 phi 和 theta 的情况下调整 ARMA(1,1) 模拟的 sd</title>
      <link>https://stats.stackexchange.com/questions/636106/adjusting-sd-for-an-arma1-1-simulation-given-phi-and-theta</link>
      <description><![CDATA[我想生成一个均值为零、标准差为 sigma 的 ARMA(1,1) 过程模型，其中我指定 ARMA 参数 phi 和 theta。如何调整高斯分布中的 sigma 值，以便输出具有正确的标准差？在 AR(1) 模型中，对 sd 参数的调整为：
# 所需的 AR1 系数
Φ &lt;- 0.7
# y 中所需的西格玛
西格玛 &lt;- 0.5
# 调整 sigma 以考虑 phi
sigmaAdjusted &lt;- sqrt(sigma^2*(1-phi^2))
n &lt;- 500
y &lt;- arima.sim(model = list(order = c(1,0,0), ar = phi),n = n, sd=sigmaAdjusted)

如何使用 MA1 项调整模型中的 sd 参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/636106/adjusting-sd-for-an-arma1-1-simulation-given-phi-and-theta</guid>
      <pubDate>Thu, 04 Jan 2024 01:48:27 GMT</pubDate>
    </item>
    <item>
      <title>θ、θ星、θ帽子有什么区别和联系？</title>
      <link>https://stats.stackexchange.com/questions/636105/whats-the-difference-and-relationship-between-theta-theta-star-and-theta-hat</link>
      <description><![CDATA[我知道 $\theta$ 是真正的分布参数（这里有很好的解释）。我还知道 $\hat\theta$ 是真实 $\theta$ 的估计器（所以例如，MLE 是 $\hat\theta$ 的示例。
但有时，我也会看到$\theta^*$。它表示什么，与 $\theta$ 和 $\hat\theta$ 的关系是什么？

在搜索过程中，我发现了这个麻省理工学院讲座，似乎对三种类型的 theta 赋予了不同的含义，但我无法真正理解其中的关系。该讲座的幻灯片示例（可在 25:50 上查看）： 


]]></description>
      <guid>https://stats.stackexchange.com/questions/636105/whats-the-difference-and-relationship-between-theta-theta-star-and-theta-hat</guid>
      <pubDate>Thu, 04 Jan 2024 00:50:08 GMT</pubDate>
    </item>
    <item>
      <title>估计不良行为者的数量</title>
      <link>https://stats.stackexchange.com/questions/636104/estimate-number-of-bad-actors</link>
      <description><![CDATA[这可能是一个愚蠢的问题，但它让我难住了。我正在尝试估计系统中不良行为者的数量。
假设我们有 100 个用户，其中一定比例的用户是不良行为者。在我们的系统中，用户正在生成剪辑，假设每个人平均生成 100 个剪辑。不良演员在一定比例的情况下会生成不良剪辑。我想知道有多少坏人。
从我们的数据库中采样剪辑以估计有多少不良演员的最有效方法是什么？我可以随机抽取 100 个剪辑并计算出不良演员的百分比吗？
&lt;小时/&gt;
我已经尝试过这个问题好几次了，但我总是被这样一个事实所困扰：你不知道坏演员会生成的剪辑的分布。我不知道如何克服这个问题并通过采样生成准确的估计。您是否首先需要找到不良演员，并计算他们可能生成的不良剪辑的百分比？]]></description>
      <guid>https://stats.stackexchange.com/questions/636104/estimate-number-of-bad-actors</guid>
      <pubDate>Thu, 04 Jan 2024 00:37:47 GMT</pubDate>
    </item>
    <item>
      <title>WLS 回归的预测区间公式</title>
      <link>https://stats.stackexchange.com/questions/636103/prediction-interval-formula-for-wls-regression</link>
      <description><![CDATA[我一直无法找到非矩阵符号公式来计算加权最小二乘回归的预测区间。对于 OLS，我有
$$y = \hat y \pm t\times \sqrt{\left(\textrm{MSE}\times(1 + 1/n + (x-\bar) x)^2/\sum (x_i-\bar x)^2)\right) }。 $$
我什至有 R 的预测区间值，但似乎无法重现它们。 R 的输出包括SE.fit 和residual.scale 但我不知道如何使用它们。请注意，权重因子未标准化。我尝试过很多事情，包括
y = yhat +/-t* SQRT(MSE*(1/WF + 1/(SUM WFi) + WF*(x-xwbar)^2/SUM(WFi*(xi-xwbar)^2)) ）
其中WF是x估计的权重因子，MSE是R的residual.scale的平方。我也尝试过
y = yhat +/- t* SQRT(MSE + se.fit^2) 使用 R 输出中的 MSE 和 se.fit。
没有任何东西可以再现 R 输出中的预测区间。我将不胜感激任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/636103/prediction-interval-formula-for-wls-regression</guid>
      <pubDate>Wed, 03 Jan 2024 23:42:47 GMT</pubDate>
    </item>
    <item>
      <title>从 GLMER 模型计算标准化回归系数</title>
      <link>https://stats.stackexchange.com/questions/636101/calculating-standardised-regression-coefficients-from-glmer-model</link>
      <description><![CDATA[我有三个独立的 glmer 模型，调查三个不同空间位置的个人和家庭层面的疟疾感染风险因素：1) 森林外，2) 森林边缘，3) 森林内。
我想要对不同空间位置的系数的相对重要性进行粗略比较，即系数的排名。
我一直在阅读《计算标准化Logistic回归系数的六种方法》梅纳德（2004）。 美国统计学家，卷。 58号第3号，其中明确指出，对于系数的简单排序（和比较），文中提到的任何方法都是可以接受的。因此，最简单的方法是将非标准化系数乘以该系数所指的预测变量的标准差。
但是，我不知道如何从 lmer 输出中提取系数的标准差。谁能给点建议吗？
其次，我在另一个论坛上读到了一篇未引用的帖子，其中提到一种可接受的、快速且肮脏的比较方法是对汇总输出中的 Wald 卡方求和，然后取每个变量的 Wald 卡方并将其除以总和。这是可以接受的措施吗？如果有的话，有什么参考资料吗？
我更喜欢前一种方法，但我需要帮助提取标准差。]]></description>
      <guid>https://stats.stackexchange.com/questions/636101/calculating-standardised-regression-coefficients-from-glmer-model</guid>
      <pubDate>Wed, 03 Jan 2024 23:05:57 GMT</pubDate>
    </item>
    <item>
      <title>具有不变浓度函数但不是平移不变的均值参数化模型？</title>
      <link>https://stats.stackexchange.com/questions/636099/mean-parameterizable-models-that-have-invariant-concentration-functions-but-tha</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636099/mean-parameterizable-models-that-have-invariant-concentration-functions-but-tha</guid>
      <pubDate>Wed, 03 Jan 2024 22:36:28 GMT</pubDate>
    </item>
    <item>
      <title>p>>>n 问题如何导航？</title>
      <link>https://stats.stackexchange.com/questions/636098/pn-problem-how-to-navigate</link>
      <description><![CDATA[我有 32 个样本的 DNA 甲基化数据。对于每个样品，我具有大于10000个cpg碱基（即DNA上的C核苷酸）的DNA甲基化。我还有基因表达数据，从中我估计了每个样本的肿瘤比例。我正在尝试根据 DNA 甲基化位点回归肿瘤比例。我想找出哪些DNA甲基化位点可以很好地预测肿瘤比例。
当我着手解决这个问题时，我认为线性回归将是解决这个问题的最直接的方法。只是意识到我的数据存在 p&gt;&gt;&gt;n 问题，因为我只有 32 个样本（因此只有 32 个观察值的肿瘤比例）。
如果我使用所有 DNA 甲基化位点信息，它会给我垃圾输出，并使模型仅来自具有非常高截距值的 16 个 DNA 甲基化位点。
我想知道是否值得对这个问题进行回归。以及如何去做。这个社区的人们将如何解决这个问题。是否有关于变量选择（应用）的详尽文本可以供我参考。
归根结底，我所需要的只是 DNA 甲基化位点，它是肿瘤比例的最佳预测因子。
这个问题的一个多变量变体是，如果我有多种细胞类型的比例，并且我试图预测如何解决它。]]></description>
      <guid>https://stats.stackexchange.com/questions/636098/pn-problem-how-to-navigate</guid>
      <pubDate>Wed, 03 Jan 2024 22:06:28 GMT</pubDate>
    </item>
    <item>
      <title>仅使用两侧置信区间的一侧</title>
      <link>https://stats.stackexchange.com/questions/636096/using-only-one-side-of-a-two-sided-confidence-interval</link>
      <description><![CDATA[假设我计算了双边置信区间。例如，假设我计算显着性水平 $\alpha$ 的二项式比例的置信区间为
下，上=conf_interval(count=95，试验=100，重要性=$\alpha$)
如果我只使用下界，我可以调用
较低，_ = conf_interval(count=95，试验=100，显着性=$2\alpha$)
如果我只使用上限，则类似。
现在，假设我正在计算一个函数
out = f(下、上)
其中输出保证等于 out = f(lower, 1) 或 out = f(0, upper) 但我事先不知道它是两者中的哪一个。换句话说，函数的输出与使用下限或上限相同。
在这种情况下我是否仍然可以使用 $2\alpha$ 因为我的函数永远不会“使用”下层和上层同时进行？]]></description>
      <guid>https://stats.stackexchange.com/questions/636096/using-only-one-side-of-a-two-sided-confidence-interval</guid>
      <pubDate>Wed, 03 Jan 2024 20:51:41 GMT</pubDate>
    </item>
    <item>
      <title>使用没有 OTU 关联信息的丰富度表计算特定分类水平的多样性指数</title>
      <link>https://stats.stackexchange.com/questions/636093/calculating-diversity-indices-at-a-specific-taxonomic-level-using-richness-table</link>
      <description><![CDATA[我有一个关于使用特定级别的丰富度表在特定分类级别（例如科级别）计算指数的问题，例如香农指数、逆辛普森指数等。例如，如果我们有一个计数表，其中行代表主题，列代表家庭，那么我们如何导出行为主题、列为家庭的香农索引表？
据我所知，我只知道根据属于该家族的OTU计算指数的公式。但是，我当前的数据集缺乏指示哪个 OTU 属于哪个家族的信息。
有人可以指导我解决这个问题吗？或者，如果您有任何关于此的论文，可以与我分享吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636093/calculating-diversity-indices-at-a-specific-taxonomic-level-using-richness-table</guid>
      <pubDate>Wed, 03 Jan 2024 20:22:09 GMT</pubDate>
    </item>
    <item>
      <title>使用蒙特卡罗模拟进行 Skip-Bo 博弈分析 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636089/skip-bo-game-analysis-using-monte-carlo-simulation</link>
      <description><![CDATA[我正在开展一个项目，探索纸牌游戏 Skip-Bo 中机会与技巧的影响。具体来说，我有兴趣了解玩家牌堆的大小如何影响游戏的结果。我的假设是，牌堆越小（例如，每个玩家 3 张牌），游戏就越依赖机会，这对于不同技能水平的玩家来说更加公平。相反，对于更大的牌堆，我怀疑技能和策略发挥更大的作用，可能有利于更有经验的玩家。
为了研究这个问题，我开始用 Python 编写蒙特卡罗模拟。这是我目前的方法：
随机导入

defsimulate_skip_bo（num_games，pile_size，skilled_player_advantage）：
    win_counts = {&#39;熟练玩家&#39;：0，&#39;新手玩家&#39;：0}

    对于 _ 在范围内（num_games）：
        熟练玩家堆 = 堆大小
        新手玩家堆 = 堆大小

        而 Skilled_player_pile &gt; 0 和 novice_player_pile &gt; 0:
            如果 random.random() &lt;熟练玩家优势：
                熟练玩家堆 -= 1
            别的：
                新手玩家堆 -= 1

        如果熟练玩家堆== 0：
            win_counts[&#39;熟练玩家&#39;] += 1
        别的：
            win_counts[&#39;新手玩家&#39;] += 1

    返回获胜次数

# 模拟参数
游戏数量 = 10000
小堆大小 = 3
熟练玩家优势 = 0.6

# 模拟小桩游戏
small_pile_results=simulate_skip_bo(num_games,small_pile_size,skilled_player_advantage)
打印（小堆结果）

我很确定代码没有回答问题，但我也不知道如何解决它。我该如何解决这个问题？
编辑
玩法如下：

设置：每位玩家都会收到一堆 30 张牌（“库存牌”）。该叠牌的顶牌翻面朝上。剩余的牌在游戏区域的中心形成抽牌堆。

目标：目标是成为第一个耗尽库存的玩家。这是通过将库存牌、手牌或弃牌堆中的牌打到中央游戏区的建筑牌堆上来实现的。

游戏玩法：

在每回合开始时，玩家从中央抽牌堆中抽牌，以拥有五张牌。
玩家可以将手牌、库存堆或弃牌堆中的牌打到中心的四个建筑堆中的任意一个上。
构建牌堆必须从“1”牌或 Skip-Bo（百搭）牌开始，然后按顺序构建到“12”。
如果玩家无法打出任何牌，则必须将一张牌丢弃到其四个个人弃牌堆之一中。


建造桩：

中央建筑桩由所有玩家共享。
每堆必须以“1”或 Skip-Bo 卡开始，用作通配符。
玩家按升序添加到牌堆中，直到达到“12”。
已完成的桩（达到“12”）将从中心区域移走，为新桩腾出空间。


丢弃一堆：

每个玩家最多可以拥有四个弃牌堆。
废弃的牌稍后可以打到中央建筑堆上。
策略对于决定丢弃哪张牌非常重要。


获胜：第一个成功打出库存中所有牌的玩家将赢得游戏。当这种情况发生时，无论其他玩家的位置如何，游戏都会立即结束。

]]></description>
      <guid>https://stats.stackexchange.com/questions/636089/skip-bo-game-analysis-using-monte-carlo-simulation</guid>
      <pubDate>Wed, 03 Jan 2024 19:25:43 GMT</pubDate>
    </item>
    <item>
      <title>因子载荷是回归权重还是相关性？ （正交旋转 EFA）</title>
      <link>https://stats.stackexchange.com/questions/636045/are-factor-loadings-regression-weights-or-correlations-orthogonal-rotatet-efa</link>
      <description><![CDATA[“因子载荷”是否是“因子载荷”？探索性因素分析 (EFA) 中的（正交旋转）
相关性或标准化回归权重？
例如，在 r 中，如果变量的相关性很强（但与二元相关性不完全相同），则因子载荷非常高，并且标准化回归权重非常小。
图书馆(tidyverse)

数据 &lt;- tibble(id = 1:200) |&gt;;
变异（z1 = rnorm（200，均值 = 0，sd = 1），
      z2 = rnorm(200, 均值 = 0, sd = 1)) |&gt;
变异（v1_1 = z1 + rnorm（200，均值 = 0，sd = .1），
      v2_1 = z1 + rnorm(200, 平均值 = 0, sd = .1),
      v3_1 = z1 + rnorm(200, 平均值 = 0, sd = .1),
      v1_2 = z2 + rnorm(200, 均值 = 0, sd = .1),
      v2_2 = z2 + rnorm(200, 平均值 = 0, sd = .1),
      v3_2 = z2 + rnorm(200, 平均值 = 0, sd = .1)) |&gt;
 选择（-c（z1，z2））

fa &lt;-factanal(数据，因素= 2，分数=“回归”，旋转=“最大方差”)

F A

data_fa &lt;- cbind(数据, fa$scores)

科尔（数据_fa）

拟合 &lt;- lm(因子1 ~ v1_1 + v2_1 + v3_1 + v1_2 + v2_2 + v3_2, data = data_fa)

总结（适合）

负载：
     因素1 因素2
ID
v1_1 0.993
v2_1 0.995
v3_1 0.996
v1_2 0.994
v2_2 0.994
v3_2 0.992

相关性：
             因素1 因素2
编号 0.0568848249 0.0071987895
v1_1 0.9948765006 -0.0044600395
v2_1 0.9968916461 0.0119593283
v3_1 0.9975826189 0.0054520197
v1_2 0.0628987259 0.9952432981
v2_2 0.0607294808 0.9958072362
v3_2 0.0569253903 0.9936277082
系数1 1.0000000000 0.0002178429
因子2 0.0002178429 1.0000000000


标准化回归权重：
lm(公式 = 因子1 ~ v1_1 + v2_1 + v3_1 + v1_2 + v2_2 + v3_2,
    数据 = 数据_fa)

系数：
              估计标准。误差t值Pr(&gt;|t|)
（截距）-4.286e-02 1.348e-05 -3180.341 &lt;2e-16 ***
v1_1 2.506e-01 1.026e-04 2442.716 &lt;2e-16 ***
v2_1 3.587e-01 1.133e-04 3166.710 &lt;2e-16 ***
v3_1 4.233e-01 1.194e-04 3544.716 &lt;2e-16 ***
v1_2 -1.085e-03 1.085e-04 -9.992 &lt;2e-16 ***
v2_2 -1.888e-03 1.140e-04 -16.560 &lt;2e-16 ***
v3_2 -1.977e-03 9.964e-05 -19.845 &lt;2e-16 ***
]]></description>
      <guid>https://stats.stackexchange.com/questions/636045/are-factor-loadings-regression-weights-or-correlations-orthogonal-rotatet-efa</guid>
      <pubDate>Wed, 03 Jan 2024 10:05:32 GMT</pubDate>
    </item>
    <item>
      <title>statsmodels 中的移动平均模型使用什么数学公式？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636035/what-math-formula-is-utilized-in-statsmodels-for-the-moving-average-model</link>
      <description><![CDATA[从维基百科，我检查了移动平均模型定义和方程。

我知道这与移动平均线不同。
我尝试检查 statsmodels 的移动平均模型的实现，以查看是否使用了上述数学方程。
https://github.com/statsmodels /statsmodels/blob/main/statsmodels/tsa/statespace/sarimax.py
但是，很难检查使用什么方程来计算移动平均系数。我相信我对移动平均模型的了解还不够。
有人知道这个吗？预先感谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/636035/what-math-formula-is-utilized-in-statsmodels-for-the-moving-average-model</guid>
      <pubDate>Wed, 03 Jan 2024 06:15:29 GMT</pubDate>
    </item>
    <item>
      <title>ADI 和 CoV - 根据数据集移动阈值？</title>
      <link>https://stats.stackexchange.com/questions/635954/adi-and-cov-move-thresholds-based-on-dataset</link>
      <description><![CDATA[我目前正在从事需求预测工作。在网上研究期间，我了解到用于需求分类的方法，这有助于我们专注于具有更好预测能力的系列等。因此，需求的分类主要基于变异系数（CoV）、平均需求间隔（ADI） ）。这引导我们进行 ABC XYZ 细分等分析和需求分类，例如 - 间歇性、块状、不稳定、平滑等。
只有当它们具有固定的阈值（就像我经常在网上看到的那样）并且它们都使用相同的阈值截止值（至少基于我在网上曝光的文章）时，上述所有方法才有意义吗？您可以参考 此处和此处
1.需求平稳（ADI &lt; 1.32 且 CV² &lt; 0.49）
2.间歇性需求（ADI≥1.32且CV²＜0.49）
3.需求不稳定（ADI&lt;1.32且CV²&gt;=0.49）
4.块状需求（ADI &gt;= 1.32 且 CV² &gt;= 0.49）
所以，我的问题，
a) 是否应该提醒这些阈值以反映我们的数据集？例如：我可以在 CV 上运行 1D-Kmeans 聚类并识别数据中的自然中断，以得出 XYZ 分割或需求分类 ADI 或 CV**2？例如，我得到 0.95、2.6 和 3.31 作为 X、Y 和 Z 的 CoV 值限制。平均 CoV 为 1.67。这是正确的做法还是我应该遵守网上给出的固定限制？
b) 我们是否应该仅考虑活跃期（非零销售时间段）或完整时间段（使用客户不活跃的时间段）来计算平均销售额]]></description>
      <guid>https://stats.stackexchange.com/questions/635954/adi-and-cov-move-thresholds-based-on-dataset</guid>
      <pubDate>Mon, 01 Jan 2024 12:16:42 GMT</pubDate>
    </item>
    <item>
      <title>具有强凸损失的在线学习L1范数</title>
      <link>https://stats.stackexchange.com/questions/635751/online-learning-with-strongly-convex-loss-w-r-t-l1-norm</link>
      <description><![CDATA[考虑一个在线学习问题，其中算法在 $t$ 时刻观察到的损失函数可以写为
$$
f_t(\lambda) = \langle V_t, w \rangle + \mu \sum \lambda_i \log \lambda_i
$$
对于某些 $\mu\geq 0$，$V_t\in [0, L]^d$并且 $\lambda$ 处于概率单纯形中。
很容易看出 $f_t(\lambda)$ 是 $\mu$- L1-范数强凸。我想知道是否有任何在线学习算法可以快速给出定义为的后悔
$$
遗憾 = \sum_{t=1}^T f_t(\lambda_t) - \min_{\lambda\in \Delta} \sum_{t=1}^T f_t(\lambda)
$$
其中 $\Delta$ 是维度 $d$ 上的概率单纯形，即 $\Delta = [p\in [0,1]^d | \sum p_i =1]$.]]></description>
      <guid>https://stats.stackexchange.com/questions/635751/online-learning-with-strongly-convex-loss-w-r-t-l1-norm</guid>
      <pubDate>Thu, 28 Dec 2023 06:41:58 GMT</pubDate>
    </item>
    <item>
      <title>如何计算比例的 MDE？</title>
      <link>https://stats.stackexchange.com/questions/623502/how-to-calculate-mde-for-proportions</link>
      <description><![CDATA[在进行 AB 测试时，我们使用功效分析来计算样本大小以及 alpha、功效和 MDE（最小可检测效应）参数。
连续变量的平均 MDE 似乎很直观：使用 Cohen&#39;s D 计算标准化平均差 = (M1-M2)/合并 SD
如果我有比例，计算 MDE 的好方法是什么？考虑到我们想要检测 5% MDE，如何以相反的方式知道如何将其转化为实际的相对变化？
例如。基线转化率为 10%，我们想要检测相对 10% 的提升（又名 10% *1.1 = 11% 转化率），什么是 MDE？如果我们想检测 5% MDE，我们可以检测到基线转化率的相对变化是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/623502/how-to-calculate-mde-for-proportions</guid>
      <pubDate>Tue, 08 Aug 2023 15:06:11 GMT</pubDate>
    </item>
    </channel>
</rss>