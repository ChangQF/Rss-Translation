<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 26 Jan 2024 06:17:27 GMT</lastBuildDate>
    <item>
      <title>一个受试者可以在重复事件分析的风险集中多次出现吗？</title>
      <link>https://stats.stackexchange.com/questions/637801/can-a-subject-appear-multiple-times-in-a-risk-set-in-recurrent-event-analyses</link>
      <description><![CDATA[为了使 Cox 模型适合重复事件数据 (Andersen &amp; Gill)，使用 R 生存包，需要用户将数据转换为计数过程格式（请参阅 [1]）。
对于重复事件分析，一个主题可以在此数据集中出现多次。
我理解这是一种编程技巧，允许人们通过 cox 比例风险模型来拟合第一个事件时间的循环模型（可能使用三明治方差估计器，以补偿事件中的受试者内相关性）次）。
在首次事件发生时间的设置下，cox 模型的部分可能性可以用风险集来表示。在这种编程技巧下，如何在重复事件场景中填充风险集？计数过程格式是否会用于转移时间，将一个受试者的多个危险期视为实际上具有重叠危险期的多个受试者？
例如，假设某个主题在计数过程格式中出现 3 次，(0,15]、(15,40] 和 (40,100])，并且在每次间隔结束时都发生一个事件。
该数据是否会被拟合为三个不同的受试者，首次事件的时间分别为 15、25 和 60，并且在时间 15 时，受试者实际上在风险集中出现了 3 次？同样，相关性是通过分组折刀法或稳健的三明治方差估计来补偿的吗？
我试图以编程方式和直观地理解这一点，上面的间隔数据框会发生什么，将使用哪些转换以编程方式将其视为首次事件模型的时间？凭直觉，为什么它会这样工作？
谢谢。
[1] https://cran.r- project.org/web/packages/survival/vignettes/timedep.pdf]]></description>
      <guid>https://stats.stackexchange.com/questions/637801/can-a-subject-appear-multiple-times-in-a-risk-set-in-recurrent-event-analyses</guid>
      <pubDate>Fri, 26 Jan 2024 05:22:36 GMT</pubDate>
    </item>
    <item>
      <title>如何对提高里程时间所需的平均练习次数进行建模？</title>
      <link>https://stats.stackexchange.com/questions/637800/how-to-model-average-number-of-practice-runs-needed-to-improve-ones-mile-time</link>
      <description><![CDATA[假设我们的朋友想要提高他的里程时间。他跑了一英里 $n$ 次，然后根据他记录的 $n$ 英里时间构建了一个经验累积分布函数 (CDF)并发现他的 $0.7$ 分位数估计为 8 分钟。他现在想再跑一英里 $k$ 次。我们的朋友问：$k$ 的平均值是多少，以便在 $0.7$ 的情况下发生改进所有 $n+k$ 英里时间的分位数现在是 6 分钟？
这个问题实用吗？我们是否需要知道他的第一个 $n$ 英里时间的分布？我们是否通过建议他在第一次 $n$ 试验（或者可能在任何试验之后）后有所改善来引入依赖性？如果我们能够访问他的第一个 $n$ 英里时间，我们该如何解决这个问题？他的进步率必须是对数的，这样在足够的练习后 $0.7$ 分位数就不会变成 1 分钟。
感谢您的阅读！我感谢任何帮助:)]]></description>
      <guid>https://stats.stackexchange.com/questions/637800/how-to-model-average-number-of-practice-runs-needed-to-improve-ones-mile-time</guid>
      <pubDate>Fri, 26 Jan 2024 05:09:06 GMT</pubDate>
    </item>
    <item>
      <title>用于估计甜甜圈爱好者百分比的贝叶斯概率</title>
      <link>https://stats.stackexchange.com/questions/637799/bayesian-probabilities-for-estimating-the-percentage-of-donut-lovers</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637799/bayesian-probabilities-for-estimating-the-percentage-of-donut-lovers</guid>
      <pubDate>Fri, 26 Jan 2024 05:02:54 GMT</pubDate>
    </item>
    <item>
      <title>为什么BERT权重初始化的标准差默认为0.02</title>
      <link>https://stats.stackexchange.com/questions/637798/why-the-standard-deviation-of-the-bert-weight-initialization-is-0-02-by-default</link>
      <description><![CDATA[神经网络中权重初始化的目的是使各层计算输出的方差保持在1.0，这取决于各层所涉及的计算。
使用Xavier初始化初始化权重W对于 Transformer Architecture 中的自注意力矩阵乘法 X@W.T 将使用标准差 $\frac{1}{\sqrt{D}}$ 从 $N(\ mu=0,\sigma=\frac{1}{\sqrt{D}})$ 以便 假设 X 和 W 的维度均为 D 并且 X 服从正态分布，则乘积的方差为 1.0。
基于 Transformer 的 BERT 的维度 D 为 768，因此 $\sigma$ 预计为0.036。但 BertConfig 表示它正在使用 0.02。 0.02 来自哪里？

BertConfig

&lt;块引用&gt;
initializer_range（浮点型，可选，默认为 0.02）— 用于初始化所有权重矩阵的 truncated_normal_initializer 的标准差。
]]></description>
      <guid>https://stats.stackexchange.com/questions/637798/why-the-standard-deviation-of-the-bert-weight-initialization-is-0-02-by-default</guid>
      <pubDate>Fri, 26 Jan 2024 04:48:53 GMT</pubDate>
    </item>
    <item>
      <title>系统性风险检测的可解释模型的局限性</title>
      <link>https://stats.stackexchange.com/questions/637797/limitations-of-explainable-models-for-systemic-risk-detection</link>
      <description><![CDATA[与 2008 年金融危机之前使用的黑盒模型相比，我试图了解当代可解释的风险评估模型的功能和局限性。
许多人指责复杂的黑匣子模型未能发现导致 2008 年危机的系统性风险。然而，当前的最佳实践要求使用可解释的模型，通常基于线性回归或截尾的正态分布。这些模型通常根据有限的近期历史数据进行训练，例如落后当前时期一年或更长时间的 6-12 个月的数据。
我的问题是：考虑到这些限制，与 2008 年之前的黑盒模型相比，可解释的建模技术在检测多年来积累的系统性风险方面是否会明显更好？具体来说：
由于只能访问一年左右的历史数据，他们如何检测长期积累的风险？
由于分布中的尾部被截断，他们如何预测尾部事件和危机？
如果唯一的区别是可解释性，那么与黑盒模型相比，这如何改进样本外系统性风险检测？
我并不是要指责，而是要了解可解释的模型是否与危机前在给定典型数据约束的情况下进行风险检测的模型具有相同的概念限制。可解释建模中是否存在可以克服这些限制的最佳实践或技术？感谢引用该领域的研究。]]></description>
      <guid>https://stats.stackexchange.com/questions/637797/limitations-of-explainable-models-for-systemic-risk-detection</guid>
      <pubDate>Fri, 26 Jan 2024 02:10:19 GMT</pubDate>
    </item>
    <item>
      <title>R 中的中介 - 解释总效应、ACME 和 ADE（二元暴露、中介和结果）的绝对值</title>
      <link>https://stats.stackexchange.com/questions/637796/mediation-in-r-interpretating-the-absolute-value-of-total-effect-acme-and-ad</link>
      <description><![CDATA[我是中介分析的初学者。在我的研究中，暴露、中介和结果是二元的（0：否，1：是）。数据按单元聚类。我拟合了中介模型（M ~ E）和结果模型（O ~ E+M），并使用‘mediate’命令进行中介分析。然而，我发现自己很难解释结果。


“总效应”、“ACME（平均）”和“ADE（平均）”的绝对值的含义是什么？这些值的指数不太可能是总效应、间接效应和直接效应的 OR。
是否可以根据中介的输出来估计总效应、间接效应和直接效应的 OR（95%CI）？

提前非常感谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/637796/mediation-in-r-interpretating-the-absolute-value-of-total-effect-acme-and-ad</guid>
      <pubDate>Fri, 26 Jan 2024 01:29:15 GMT</pubDate>
    </item>
    <item>
      <title>函数积分 微分熵</title>
      <link>https://stats.stackexchange.com/questions/637795/integral-over-functions-differential-entropy</link>
      <description><![CDATA[假设有一些功能：
\begin{方程}
f(t) = p(x)
\end{方程}
其中 $p(x)$ 是 $x$ 的 PDF，位于 $t$。一些示例是具有误差范围的线性回归或高斯过程（通常 $p(x)$ 是高斯分布），例如：

如何量化 $x \sim f(t) \ \ st. 的微分熵。 \ \t_1 &lt; t &lt; t_2$？
直觉上我希望执行以下操作：
\begin{方程}
   \mathcal{H}(f(t) | t_1 &lt; t &lt; t_2) = \int_{t_1}^{t_2} H(f(t)) \; dt
\end{方程}
其中 $H(f(t))$ 是 $x$ 处的微分熵$t$。
如果我的表述不清楚。我希望量化 $x$ 在 $t$ 区间内的不确定性。这个有名字吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637795/integral-over-functions-differential-entropy</guid>
      <pubDate>Fri, 26 Jan 2024 01:09:44 GMT</pubDate>
    </item>
    <item>
      <title>层次逻辑回归总结的解释</title>
      <link>https://stats.stackexchange.com/questions/637794/interpretation-of-summary-of-a-hierarchical-logistic-regression</link>
      <description><![CDATA[我想知道我对此摘要的解释是否正确。
这是我用混合模型制作的分层逻辑回归，用于分析泛化梯度。我有固定效果和随机效果。
变量如下：
a) 组：组 CONTROL 为截距。另一组是 INTERV。它是一个 FACTOR 变量。
b) TIME：TIME = 1 是截距，是第一次收集数据的时间。另一个时间是 TIME = 2。它是一个 FACTOR 变量。
c) 相似性：它是一个数字变量。这是一种刺激与另一种刺激的相似性。
d) CHOICE：它是一个 INTEGER 变量。 “选择”是指可以是 0 或 1。
e) id：研究中每个受试者的标识号。这是一个因素。
我在R中使用的代码和总结：
模型 &lt;- glmer(选择 ~ (1+相似度|id) + 组*时间*相似度，
                   数据=数据，
                   家庭=二项式（链接=“logit”），
                   控制= glmerControl（优化器=“bobyqa”），
                   nAGQ = 1)

概括：
                                 估计标准。误差z值Pr(&gt;|z|)
（截距）0.7344 0.3534 2.078 0.037666 *
组INTERV -2.3423 0.5218 -4.489 7.15e-06 ***
时间 0.2049 0.1018 2.012 0.044191 *
相似度 0.3790 0.1882 2.013 0.044063 *
组INTERV：时间 1.3925 0.2018 6.902 5.14e-12 ***
groupINTERV：相似度 -0.6144 0.2996 -2.050 0.040316 *
时间：相似度 0.3519 0.1056 3.332 0.000862 ***
组INTERV：时间：相似度 0.2337 0.1976 1.183 0.236840


在 TIME = 1、SIMILARITY = 0 的情况下，INTERV 组的 CHOICE 大于 CONTROL 组。

对照组的选择受到时间的积极影响（当 SIMILARITY = 0 时）

对于 CONTROL 组，在 TIME = 1 时，SIMILARITY 越大，CHOICE 越大。换句话说：对于控制组，在 TIME = 1 时，SIMILARITY 对 CHOICE 产生积极影响。

INTERV 组比 CONTROL 组更受 CHOICE 中时间的积极影响。

在 TIME = 1 时，CONTROL 组中的 SIMILARITY 效果大于 INTERV 组中的效果。

在两组中，时间的增加增加了相似度对选择的影响。

]]></description>
      <guid>https://stats.stackexchange.com/questions/637794/interpretation-of-summary-of-a-hierarchical-logistic-regression</guid>
      <pubDate>Fri, 26 Jan 2024 00:51:53 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法对累积发生率曲线进行多重比较？</title>
      <link>https://stats.stackexchange.com/questions/637793/is-there-a-way-to-do-multiple-comparisons-of-cumulative-incidence-curves</link>
      <description><![CDATA[我有一个包含 5 条累积发生率曲线的图，我想知道哪些曲线彼此不同。现在我有一个来自 Gray 测试的 p 值 (p&lt;0.001)，它同时测试了所有曲线。
我考虑一次只绘制两条曲线并计算 p 值，但这没有针对多次测试的修正。
自从我了解 pairwise_survdiff( ) 来自 R 的 survminer 包的函数。它不适用于我的数据集，因为我的状态变量有 3 个级别（0-审查、1-死亡、2-竞争事件）而不是 2 个级别（仅审查和死亡）。我正在寻找可用于竞争风险数据的类似函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/637793/is-there-a-way-to-do-multiple-comparisons-of-cumulative-incidence-curves</guid>
      <pubDate>Fri, 26 Jan 2024 00:42:48 GMT</pubDate>
    </item>
    <item>
      <title>对于多个自变量和多重处理使用什么样的回归</title>
      <link>https://stats.stackexchange.com/questions/637789/what-kind-of-regression-to-use-for-multiple-independent-variables-and-multiple-t</link>
      <description><![CDATA[我对统计数据是全新的，并试图根据工作中提供的现有数据集运行我的第一次回归，并且我需要一些帮助来指明正确的方向。我是自学成才的，所以提前道歉，因为我对这个主题的知识和词汇非常零散！
在调查中，参与者接受了某个主题的测试，我们想了解他们的 1) 年龄、2) 先前对主题的熟悉程度以及 3) 日常新闻消费习惯如何影响他们的表现。参与者被问到是/否问题，因此他们的回答被记录为 0（不正确）或 1（正确）。
我们希望根据三个自变量确定参与者整体表现的影响，并在检查每个变量时控制其他两个变量。测试中还有四个子主题（治疗？），我们还想单独评估三个自变量的影响。
我认为应该运行多项逻辑回归，因为其中两个自变量是分类的，并且因为我可以通过将其分为四个年龄组来将年龄分类。但是，如何在一个回归中分析多个“治疗”/子主题的三个自变量？我可以吗？
我只是不知道足够的词汇来理解关于回归模型类型和多种“治疗”要求要查找的内容，所以我有点卡住了。任何有关直接前往的见解或建议将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/637789/what-kind-of-regression-to-use-for-multiple-independent-variables-and-multiple-t</guid>
      <pubDate>Thu, 25 Jan 2024 23:07:18 GMT</pubDate>
    </item>
    <item>
      <title>如何为裂区设计 (ANOVA) 编写 lme、lmer 或 glmer 模型？</title>
      <link>https://stats.stackexchange.com/questions/637788/how-to-code-a-lme-lmer-or-glmer-model-for-a-split-plot-design-anova</link>
      <description><![CDATA[我进行了一项研究，在第 0 年测量了幼苗的初始高度，并在施用处理后 11 年再次测量，并记录了高度的净变化。
我的裂区设计如下：

治疗（全图因子，4 个水平：TMT1、TMT2、TMT3、CONTROL）
单元（处理重复，总共 20 个：每个处理 5 个，tmts 随机分配给单元）
水分（裂区因子，3 个级别：每个单元内的低、中、高）
绘图（每个湿度水平内 2 个重复绘图）
团体（5 个级别：OAKS、PINES、MAPLES、ELMS、OTHER 等）
ID（幼苗的标签号）
HeightChg（响应变量，连续）

我想知道：

处理类型对苗高变化的影响是否显着？
水分对苗高变化的影响是否显着？
物种组对播种高度变化的影响是否显着？

它不是传统意义上的块设计，因为所有处理都不包含在某个单元中。相反，每个单元都包含相同的三个抽象湿度水平（每个单元会有所不同），但处理方法在开始时是随机分配到整个单元的。即：治疗&lt;单位&lt;水分含量&lt;情节&lt;身份证号
这是我到目前为止的模型：
library(lmerTest) #加载包
mod1 = lmer(HeightChg ~ 处理 * 水分 * 组 + (1|单位), mydata) #11 年身高差

但是，当我绘制模型的 Q-Q 图时，两端都有肥尾：

这是高度变量变化的绘制分布：

我的同事建议一种可能性是转换高度变量的变化，因为数据集中的极值，如枯死（异常大的高度损失）和快速生长（异常大的高度变化），导致了分布的峰度。&lt; /p&gt;
他还说，在转换数据以获得更线性的拟合之前，我应该尝试在代码中正确定义误差矩阵和随机效应。我在网上搜索了具有可变嵌套的相同设计，并找到了一些很好的信息，但还没有找到精确反映我的示例。
说实话，幼苗高度在不同的时间间隔内被多次测量，但我还没有找到适合我的裂区设计的正确代码，更不用说整合不平衡的重复高度测量了，所以我取了 11 年之间的差异测量和 0 年测量以保持简单。
如果您能提供如何使用 lme、lmer 或 glmer 来正确构建适用于此特定设计（加法、乘法、误差项、嵌套等）的模型，我们将不胜感激！我计划在 anova(mod1) 正确后运行它并尝试计算 p 值。]]></description>
      <guid>https://stats.stackexchange.com/questions/637788/how-to-code-a-lme-lmer-or-glmer-model-for-a-split-plot-design-anova</guid>
      <pubDate>Thu, 25 Jan 2024 22:44:02 GMT</pubDate>
    </item>
    <item>
      <title>eta 平方的分布</title>
      <link>https://stats.stackexchange.com/questions/637787/distribution-of-eta-squared</link>
      <description><![CDATA[我正在尝试找到 eta 平方统计量的分布及其抽样分布的推导。
一篇较旧的论文 Murray, L. W., &amp;多瑟，D.A.（1987）。显着性差异有多显着？影响程度测量的问题。咨询心理学杂志。 https://psycnet.apa.org/journals/cou/34/1/ 68 声称它是 beta 分发的，并引用了一篇提交发表的论文，但我找不到该论文的踪迹。
有人有这方面的指点吗？我知道它当然可以模拟，但我更喜欢分析推导。]]></description>
      <guid>https://stats.stackexchange.com/questions/637787/distribution-of-eta-squared</guid>
      <pubDate>Thu, 25 Jan 2024 22:41:09 GMT</pubDate>
    </item>
    <item>
      <title>先前实验的贝叶斯使用</title>
      <link>https://stats.stackexchange.com/questions/637781/bayesian-use-of-previous-experiments</link>
      <description><![CDATA[假设我有两项研究，例如 $\mathcal{S}_1$ 和 $\mathcal{S}_2 $，带有各自的数据集$\mathcal{D}_1，\mathcal{D}_2$，参数 $\theta^{(1)}、\theta^{(2)}$ 和响应变量 $y, z$。我有以下问题：

如果我有兴趣使用第一项研究的响应 $y$ 作为第二项研究的协变量，这是推荐的方式我可以继续吗？对后验预测进行正态逼近并计算均值和方差并将其用作系数的先验是否有意义，例如 $\theta_y^{(2)}$ ，在第二项研究中？我遇到的主要问题是我的后验分布看起来并不正态。

此外，假设 $\mathcal{D}_2$ 有一组出现在  中的协变量$\mathcal{D}_1$。如果我想在第二项研究 $\theta_1$ 中包含有关 $\theta_1$ 子集的后验信息，建议采用哪种方式进行&quot;&gt;$\mathcal{S}_2$？

]]></description>
      <guid>https://stats.stackexchange.com/questions/637781/bayesian-use-of-previous-experiments</guid>
      <pubDate>Thu, 25 Jan 2024 21:50:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Harrell 主张“在数据缩减过程中忽略 Y”？</title>
      <link>https://stats.stackexchange.com/questions/637773/why-does-harrell-argue-for-ignoring-y-during-data-reduction</link>
      <description><![CDATA[在回归建模策略第 79 页（4.7 数据缩减）中写道：
&lt;块引用&gt;
数据缩减的目的是减少模型中要估计的参数数量，而不扭曲参数的统计推断。这是通过在数据缩减期间忽略 Y 来实现的。无监督学习中对 X 的操作可能会导致预测 Y 的信息丢失，但当信息丢失很小时，功效的增益和过拟合的减少足以抵消损失

无监督学习不会增加丢弃相关变量的风险吗？您如何向没有统计背景的研究人员/PI 争论，失去这些数据足以被功效的增加和过度拟合的缓解所抵消？
最后，是否存在这种交易不值得的情况？如果研究人员主要关心的是找出“正确的”例如，变量。
我相信文本中的建议是合理的，但我想充分理解它，以便我可以向持怀疑态度的外行观众解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/637773/why-does-harrell-argue-for-ignoring-y-during-data-reduction</guid>
      <pubDate>Thu, 25 Jan 2024 20:30:40 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何结合“典型”和“昨天”的自我报告？</title>
      <link>https://stats.stackexchange.com/questions/637708/how-should-i-combine-typical-and-yesterday-self-reports</link>
      <description><![CDATA[我继承了一项长期调查，其中包含两种个人行为衡量标准。
编辑：澄清这与饮酒行为无关；事实并非如此，我只是用它来尝试和说明。它应该适用于每天/每周时间范围内的任何行为，例如回收、在壁炉中燃烧木材、看电影等。
好的，开始解决问题。

在调查中，有一个问题可以引出“典型”行为的特征：您通常每周有多少天做 X（喝酒、烧柴、看电影等）？&lt; /p&gt;

接下来的问题是，你昨天做了X吗？

还有一个问题是获取参与者的邮政编码。


之前的分析师拟合了如下逻辑模型：
X_yesterday ~ X_per_week

其中，X_yesterday 是二进制，X_per_week 是 1、2、... 或 7 天/周。 （回答“从不”的人被排除在回归之外，因为超过一半的人表示“从不”。）
然后，分析师使用拟合值进行后续分析，包括按其他数量进行缩放，然后进行 ZIP 级别聚合。
这似乎很有用，因为主要目标是估计邮政编码级别的比率，包括没有受访者报告昨天做过 X 的邮政编码（大约为邮政编码的 20%）。
这似乎也很有用，因为将“昨天”的问题作为衡量的黄金标准，结果表明人们夸大了他们做 X 的典型频率，大约为 10-30% .
我想了解更多关于以这种方式校准典型行为的自我报告的信息。您能推荐一些好的例子或参考资料吗？如果不明显，我不是统计学家，但我精通 R。玩具问题很好，尽管我很乐意提供更多详细信息，如果它有助于识别更接近真实本质的现实世界应用程序以及该数据集的规模。诊断提示也将受到欢迎。值得注意的是，之前的分析师没有以任何方式利用空间相关性（邮政编码）。
* 简化，因为它实际上是一组问题，但最终结果是估计的频率/比例（每周天数）。还有一个类似于“当你做 X 时，你做了多少 X”的问题，但我们暂时先把它放在一边？]]></description>
      <guid>https://stats.stackexchange.com/questions/637708/how-should-i-combine-typical-and-yesterday-self-reports</guid>
      <pubDate>Thu, 25 Jan 2024 02:34:46 GMT</pubDate>
    </item>
    </channel>
</rss>