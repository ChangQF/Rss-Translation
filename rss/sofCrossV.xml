<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 25 May 2024 21:12:54 GMT</lastBuildDate>
    <item>
      <title>确定强制选择绩效有效性测试的机会水平</title>
      <link>https://stats.stackexchange.com/questions/647986/determining-chance-level-for-forced-choice-performance-validity-tests</link>
      <description><![CDATA[心理学家，尤其是神经心理学家，使用表现有效性测试 (PVT) 来检测可能故意在能力测试（例如记忆测试）中表现不佳的个人，因为诊断出的认知缺陷可能会导致期望的结果（从考生的角度来看），例如残疾赔偿金。
假设您有一个包含 60 项的强制选择 PVT。无精神疾病的人的中位错误分数为 1，而患有严重精神障碍（例如精神分裂症）的人的中位错误分数为 5。根据交叉验证的研究，指定 9 或更高的分数来识别掩饰，即可能是假装。当然，心理学家不应仅根据一项 PVT 分数就得出此人装病的结论。
但是，如果错误分数如此之高，以至于偶然获得分数的几率非常低怎么办？换句话说，这个人必须非常努力才能反复给出错误的答案。
示例：申请残疾福利的受试者的错误分数为 39。
仅通过掷硬币，在我们假设的 60 项强制选择 PVT 中，您产生 39 或更高错误分数的几率有多大？]]></description>
      <guid>https://stats.stackexchange.com/questions/647986/determining-chance-level-for-forced-choice-performance-validity-tests</guid>
      <pubDate>Sat, 25 May 2024 20:52:48 GMT</pubDate>
    </item>
    <item>
      <title>我的 Python 代码不适用于 Lin (1989) 的高斯 CDF 近似</title>
      <link>https://stats.stackexchange.com/questions/647982/my-python-code-is-not-working-for-lins-1989-approximation-to-the-gaussian-cdf</link>
      <description><![CDATA[我的 Python 代码不适用于高斯 CDF 的 Lin (1989) 近似值（如《国际科学与工程研究杂志》第 6(4) 期，2015 年 4 月 ISSN 2229-5518 号，Ramu Yerukala 和 Naveen Kumar Boiroju 撰写的标准正态分布函数近似值中所述）
def lin_phi(x, mu=0, sigma=1):
z = (x - mu) / sigma
if z &gt;= 0:
return 1 - 0.5 * math.exp(-0.72 * z - 0.42 * z * z)
else:
return 0.5 * math.exp(0.72 * abs(z) + 0.42 * z * z)

当我运行它时，低于平均值的结果是错误的（方式太大):
for x in range(20):
print(f&quot;x = {x-10:3} cdf = {round(lin_phi(x-10, mu=0,sigma=3),3)}&quot;)

x = -10 cdf = 586.117
x = -9 cdf = 189.967
x = -8 cdf = 67.594
x = -7 cdf = 26.404
x = -6 cdf = 11.323
x = -5 cdf = 5.331
x = -4 cdf = 2.755
x = -3 cdf = 1.563
x = -2 cdf = 0.974
x = -1 cdf = 0.666
x = 0 cdf = 0.5
x = 1 cdf = 0.625
x = 2 cdf = 0.743
x = 3 cdf = 0.84
x = 4 cdf = 0.909
x = 5 cdf = 0.953
x = 6 cdf = 0.978
x = 7 cdf = 0.991
x = 8 cdf = 0.996
x = 9 cdf = 0.999

我尝试了多种变体，但均未成功。
仅供参考：这是 Mac/OS 上的 Python 3.13。但我认为这与此无关。]]></description>
      <guid>https://stats.stackexchange.com/questions/647982/my-python-code-is-not-working-for-lins-1989-approximation-to-the-gaussian-cdf</guid>
      <pubDate>Sat, 25 May 2024 20:13:10 GMT</pubDate>
    </item>
    <item>
      <title>有人可以帮我用数学公式表达以下内容，并将其链接到参考材料吗？</title>
      <link>https://stats.stackexchange.com/questions/647981/can-someone-please-help-me-formulate-the-following-mathematically-and-link-it-t</link>
      <description><![CDATA[如果有人能够“识别”以下所暗示的统计学中的既定观点，并帮助我以标准方式表述它，并为我研究这个确切的主题提供参考，我将不胜感激。
想象一下解决这个问题：
&lt;块引用&gt;
让我们假设，根据一些消息来源，美国黑人的平均预期寿命为 72.8 岁，白人的平均预期寿命为 76.4 岁。确定哪些现实因素导致了这种差异。

&lt;小时/&gt;
在我看来，解决这个问题的一个好方法是在制定实际模型之前制定一个理想模型。
通过理想模型，我的意思是，通过分析和逻辑思维，它似乎代表了情况的逻辑现实。
我所说的实用模型是指第二阶段的独立问题，即找到一种策略来可接受地接近构建理想的逻辑模型。
我个人认为这是一个很好的策略，因为理想的模型可以让您清楚地概念性地理解逻辑上正确的答案会是什么样子。在我们探索在实践层面上与理想模型的距离有多近之前，我们应该对此充满信心。
如果我们不这样做，我们就会冒着以临时方式工作的风险，在这种方式下，我们建立了一个模型，用于对世界做出新的推论，但我们没有理由解释为什么它在认识论上代表了世界。世界，而不是一个“随机”模型，其推论对世界做出了错误的判断。
&lt;小时/&gt;
下一个问题是“因果关系”的本质。我一直倾向于一种逻辑模型，其中“现实世界因果关系”相当于“逻辑蕴涵”。
例如，假设黑人的肾脏疾病发病率相对较高。
有必要建立一个本体论，以便逻辑地表达诸如“人体存在一种可界定的状态，称为‘患有肾脏疾病’；在任何特定时刻，平均而言，比白人更多的黑人‘患有肾脏疾病’。”
也许不可避免地要用到概率的概念。我认为如果概率总是可以从非概率事实计算出来那就太酷了 - 有点像拉普拉斯守护进程，如果世界模型足够详细，我们可以做出一系列推论，例如，“与人 P 相关的方面 X左肾的值为 V1。根据[在此插入物理定律]，人 P 的某些方面的属性 Y 在时间 t 将具有值 V2。”然后我们可以使用这些事实来计算一个事物的状态数量，以反映该事物的实例将继续具有该状态的“概率”。
理想的模型基本上是世界的形式逻辑模型。
&lt;小时/&gt;
一旦我们理解了理想模型，就应该更容易认识到需要了解哪些偶然事实，以便逻辑地计算我们世界中的其他一些偶然价值。例如，假设我们世界中的某个物理定律是固定的，因此必然是正确的。然而，存在一个可能的世界，其中黑人的平均预期寿命是71.3岁，另一个可能的世界是85岁，等等。为了计算我们这个世界的预期寿命，我们希望能看到哪些参数值该计算取决于使用我们理想模型的形式。
&lt;小时/&gt;
最后，我们开始思考如何实际获取这些数据。我们的逻辑模型旨在从全知的角度来代表世界。我们可能不会是无所不知的，因此我们必须评估给定的数据对我们的模型的各种值的支持程度。
最后，我们可以用一个代数公式，根据我们无法获得的某些数据值来明确预期寿命，而不是完美地计算预期寿命。对于我们确实获得的数据，我们可以将其代入这些变量进行计算。
&lt;小时/&gt;
但是，我们想向后执行上述操作。找出黑人与白人的预期寿命很容易。我们想要推断本体中的哪些因素会发挥作用，然后通过替换经验数据来更新模型，从而获得相关事物的值。通过这种方式，我们能够更接近地了解哪些偶然因素（例如社会压力水平、平均收入、医疗机构的治疗）与解释观察到的预期寿命差异更相关。
如果有我可以阅读的文本来查看此统计策略的示例，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/647981/can-someone-please-help-me-formulate-the-following-mathematically-and-link-it-t</guid>
      <pubDate>Sat, 25 May 2024 19:03:16 GMT</pubDate>
    </item>
    <item>
      <title>简单 KL 散度最小化的失败示例</title>
      <link>https://stats.stackexchange.com/questions/647979/failing-example-of-simple-kl-divergence-minimization</link>
      <description><![CDATA[我正在尝试培养对 KL 散度及其在 ML 中的应用的直觉。但不知何故，我似乎无法使一个简单的示例发挥作用。下面给出了一个用于最小化 KL 散度的简单 Python 程序，但不知何故它从未收敛到正确的参数。我在这里不明白什么？
import torch
from torch.distributions import Normal
import matplotlib.pyplot as plt

# 从真实分布中抽取 1000 个样本
num_samples = 1000
true_mu, true_sigma = 4.0, 2.0
samples = Normal(true_mu, true_sigma).sample((num_samples,))

# 变分参数（初始猜测）
guess_mu = torch.tensor(0.0, require_grad=True)
guess_sigma = torch.tensor(1.0, require_grad=True)

# 优化器
optimizer = torch.optim.Adam([guess_mu, guess_sigma], lr=0.001)

# 用于最小化 KL 散度的训练循环
for step in range(20000):
optimizer.zero_grad()

# 定义变分分布
q = Normal(guess_mu, guess_sigma)

# 计算对数概率
log_q = q.log_prob(samples)
log_p = Normal(true_mu, true_sigma).log_prob(samples)

# KL 散度
# KL(q || p) = ∫q log(q/p) = E_q[log(q) - log(p)] = ∑q (log(q) - log(p))
kl_div = torch.sum(torch.exp(log_q) * (log_q - log_p))

# 反向传播
kl_div.backward()
optimizer.step()

# 确保 sigma 保持正值
with torch.no_grad():
guess_sigma.clamp_(min=1e-6)

# 打印每 100 步进展一次
if step % 100 == 0:
print(f&quot;步骤 {step}, KL 散度：{kl_div.item()}, mu：{guess_mu.item()}, sigma：{guess_sigma.item()}&quot;)

print(f&quot;最终 KL 散度：{kl_div.item()}&quot;)
print(f&quot;优化均值：{guess_mu.item()}&quot;)
print(f&quot;优化 sigma：{guess_sigma.item()}&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/647979/failing-example-of-simple-kl-divergence-minimization</guid>
      <pubDate>Sat, 25 May 2024 18:43:31 GMT</pubDate>
    </item>
    <item>
      <title>在 XGBoost 或随机森林中强制“矢量袋”数据对称 - 用于说明的地理数据示例</title>
      <link>https://stats.stackexchange.com/questions/647977/enforcing-symmetries-for-bag-of-vector-data-in-xgboost-or-random-forest-geod</link>
      <description><![CDATA[我将给出一个具体的玩具问题，然后就我关心的抽象类型给出一些评论。
玩具问题：我的数据集中的每个人 $i$ 都有一部手机，每隔一段时间手机就会记录一次地点。然后我看到位置的无序列表 $\{ (x^{(i)}_{j}, y^{(i)}_{j}\}_ {j=1}^{N}$。我想学习一个分类器，告诉我哪些人属于某个休闲足球联赛，该联赛在城市的几个足球场举行，我想使用类似的东西。 XGBoost 进行分类。
一些观察：

如果我不限制自己使用 XGBoost 这样的通用分类器，我应该能够从此类数据中学习此类分类器。例如，我可以寻找联盟内的人常见的位置，但联盟外的人不常见的位置。因此，这并不是试图解决一个明显不可能的问题 - 我只是不知道如何使用已经实现的算法来解决它。
开箱即用时，XGBoost 在这方面会做得很糟糕，因为它不明白我的位置列表大部分是无序的（x 坐标和 y 坐标的排序是有意义的）。特别是，我认为它应该沿着“是否有任何观察结果落在点 p 附近”的思路来考虑决策规则，但在实现时，我认为它只能学习“索引 j 处的观察是否落在点 p 附近”的决策规则。原则上你可以从后者转向前者，但这非常困难。
如果城市很小，我当然可以对空间离散化进行 one-hot 编码。我想避免使用这种解决方案，因为它不能很好地概括我关心的大多数实际问题。

感谢您的任何想法！理想情况下，有人会告诉我，有人已经实施了我在 (2) 中提到的决策规则 - 这似乎是一件非常普遍的事情，这只是我第一次碰巧遇到它！ p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/647977/enforcing-symmetries-for-bag-of-vector-data-in-xgboost-or-random-forest-geod</guid>
      <pubDate>Sat, 25 May 2024 18:11:24 GMT</pubDate>
    </item>
    <item>
      <title>Polya-Aeppli 分布的 MLE</title>
      <link>https://stats.stackexchange.com/questions/647972/mles-of-polya-aeppli-distribution</link>
      <description><![CDATA[有人可以解释一下如何导出 Polya-Aeppli 分布的两个参数的正态方程吗？
Johnson、Kemp、Kotz，单变量离散分布，第 413 页，方程 9.147 和 9.148]]></description>
      <guid>https://stats.stackexchange.com/questions/647972/mles-of-polya-aeppli-distribution</guid>
      <pubDate>Sat, 25 May 2024 17:05:47 GMT</pubDate>
    </item>
    <item>
      <title>如何汇总许多预测的不确定性？</title>
      <link>https://stats.stackexchange.com/questions/647969/how-to-aggregate-the-uncertainty-around-many-predictions</link>
      <description><![CDATA[我预测了数百个时间序列的趋势。每个趋势预测在每个时间步都有自己的上限和下限。我想汇总这些趋势并报告它们。取预测的平均值对于聚合趋势本身来说很简单，并且平均值在我的例子中效果很好。但是，我不确定如何适当聚合平均预测的上限和下限。
简单地取边界的平均值可能并不准确。另一种选择是采用范围（例如，上限的最大值和下限的最小值），但这可能会导致不切实际的高不确定性。这是因为，即使个别趋势估计的不确定性较低，时间序列之间的方差也可能很高，并且在不考虑这种变化的情况下，该范围将反映总体不确定性。
有人可以解释一种数学上合理的方法来汇总这些预测的不确定性吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647969/how-to-aggregate-the-uncertainty-around-many-predictions</guid>
      <pubDate>Sat, 25 May 2024 16:00:36 GMT</pubDate>
    </item>
    <item>
      <title>预测已知曲线的模拟数据</title>
      <link>https://stats.stackexchange.com/questions/647960/predicting-simulated-data-for-a-known-curve</link>
      <description><![CDATA[我在研究问题上遇到了障碍，确实需要利用您的专业知识。
我有一条通过推断已知拟合实验数据创建的预先存在的曲线。如下所示，x 轴是给予样品的热量，y 轴是热量与响应的响应概率。

我有另一个数据集，我必须估计其衰减函数。对于样品“i”，总热量定义为
$$
H_{i} = H_{0}\exp^{-kt} + H_{已知} \quad{(1)}
$$
其中 $H_{0}$、t 和 $H_{known}$ 是已知的条款。 “k”是指是未知术语
从等式 1 生成的 $H_{i}$ 及其所有样本的已知二元响应然后进行分箱以获得 H 和响应概率。
下面，我展示了一个示例图，其中绿点作为新数据，并带有随机选取的“k”点。价值。绿色模拟数据

我的问题是未知“k”的估计在公式 1 中，它最小化了绿点和蓝色曲线之间的差异。
有人可以建议一种理想的方法来估计“k”]]></description>
      <guid>https://stats.stackexchange.com/questions/647960/predicting-simulated-data-for-a-known-curve</guid>
      <pubDate>Sat, 25 May 2024 13:34:44 GMT</pubDate>
    </item>
    <item>
      <title>学习《统计学家的实函数分析》的参考资料</title>
      <link>https://stats.stackexchange.com/questions/647956/references-to-learn-real-and-functional-analysis-for-statisticians</link>
      <description><![CDATA[我正在寻找一本介绍实分析要素的书籍，用于数理统计和计量经济理论等。
我计划使用以下三本关于高级统计理论的教科书：

Jacod 和 Protter 的《概率论要点》
Keener Robert 的《理论统计学：核心课程主题》
邵俊的《数理统计学》

但是，尽管它们都对测度论概率进行了介绍，但它们对实分析的重视程度相当高，所以我缺少实分析作为入门教材。我有经济学背景（欧洲 LMD 系统 3 级执照），所以即使我做过一些微积分、线性代数、初等概率和统计学，我也绝不是数学家，我也不认为我是一个“基于证明”的数学家。
我做了一些研究，找到了这些书：

Corbae、Stinchcombe 和 Zeman 合著的《经济理论和计量经济学的数学分析导论》。
A. Efe 合著的《经济应用的实分析》
Giulio Bottazzi 合著的《经济学和金融的高等微积分：理论与方法》

但我认为最好还是请教一些权威人士，确保万无一失，不要把时间浪费在对我来说太难或对邵军这种类型来说不完整的东西上书。
你们中有人有适合经济学家、工程师等自学实分析的好参考书吗？
谢谢，抱歉我的英语不好。]]></description>
      <guid>https://stats.stackexchange.com/questions/647956/references-to-learn-real-and-functional-analysis-for-statisticians</guid>
      <pubDate>Sat, 25 May 2024 13:05:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 convLSTM2D 对可变输入形状进行训练？</title>
      <link>https://stats.stackexchange.com/questions/647949/how-to-train-with-convlstm2d-on-variable-input-shape</link>
      <description><![CDATA[我正在使用 4 过滤器对 72x72 图像的时间序列进行分类（就像 RGB）。如果我的所有样本都具有相同的时间步长（或纪元数），那么事情就会很好地进行。然而，实际上我每个样本都有不同数量的时间步长。 （这是在天文学中，我无法随意获取数据。）但是当我尝试包含不同的时间步长时，我收到错误。请查看 MWC。
N=2000
train_data_arr=np.random.rand(N, 11, 72, 72, 4)
train_label=np.repeat(np.random.randint(2,size=N)[:, np.newaxis], 11,axis=1)
Ntot,dum=train_label.shape;打印(Ntot,dum)

#===可变数据形状====
def select_random_time_epochs(数据、标签、max_time_steps=11):
    变量数据 = []
    变量标签 = []
    对于 zip（数据，标签）中的 d、l：
        #时间步数 = 11
        time_steps = np.random.randint(1, max_time_steps + 1)
        variable_data.append(d[:time_steps])
        variable_labels.append(l[:time_steps])
    返回变量数据、变量标签
train_data_var, train_label_var = select_random_time_epochs(train_data_arr, train_label)

#====数据生成器======
def make_generator（数据，标签）：
    def 生成器():
        对于 zip（数据，标签）中的 d、l：
            产量 d, l
    返回发电机

train_ds = tf.data.Dataset.from_generator(
    生成器=make_generator(train_data_var, train_label_var),
    输出类型=（tf.float32，tf.int32），
    output_shapes=(tf.TensorShape([无, 72, 72, 4]), tf.TensorShape([无]))
）
批量大小 = 32
train_ds = train_ds.batch(batch_size)

#===型号===
输入形状 = (无, 72, 72, 4)  
模型 = tf.keras.Sequential()
model.add(输入(形状=input_shape))
model.add(ConvLSTM2D(32, (9, 9), 激活=&#39;relu&#39;, padding=&#39;valid&#39;, return_sequences=True, data_format=&#39;channels_last&#39;))
model.add(BatchNormalization())
model.add(TimeDistributed(MaxPooling2D((2, 2), data_format=&#39;channels_last&#39;)))
model.add(TimeDistributed(Flatten()))
model.add(TimeDistributed(Dense(64,activation=&#39;relu&#39;)))
model.add(TimeDistributed(Dense(1,activation=&#39;sigmoid&#39;)))
model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])
模型.summary()

model.fit(train_ds, epochs=20)

如果我将时间步长固定为 11（在函数 select_random_time_epochs() 中），则一切正常。但是当我使用可变数量的时间步长时，我收到错误：
无法批处理组件 0 中具有不同形状的张量。第一个元素的形状为 [3,72,72,4]，元素 3 的形状为 [6,72,72 ,4]。

我知道它无法处理 32 个批次内的可变时间步长。实际上，当我设置 batch_size = 1 时，上面的代码可以工作，但这需要太多时间，而且很可能永远不会融合到真实的用例场景中。
所以我的问题如下。

假设我完全不需要任何填充。当批次内的样本具有不同形状时，是否有更快的方法来实现 model.fit() ？否则，我可以动态批处理具有相同时间步长的样本吗？这是唯一的方法吗？评估可能不遵循同一批次分布的测试数据时会出现问题吗？

现在来到 padding 选项：tensorflow.keras.layers.Masking 是否真的能够处理我在缺失时期放置的“坏图像” ？换句话说，Masking 或其他东西可以完全使填充值变得无关吗？


重要的一点：我必须使用生成器来避免立即在 GPU 上加载数据，因为我的实际数据很大（字面上是天文数字）。
另外，以下线程讨论了 LSTM 的变量输入，但我的用例稍微复杂一些。
https://stackoverflow.com/questions/63663399/how -处理lstm的可变长度数据
https://stackoverflow.com /questions/38189070/how-do-i-create-a-variable-length-input-lstm-in-keras]]></description>
      <guid>https://stats.stackexchange.com/questions/647949/how-to-train-with-convlstm2d-on-variable-input-shape</guid>
      <pubDate>Sat, 25 May 2024 08:54:08 GMT</pubDate>
    </item>
    <item>
      <title>如何估计很小比例的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/647947/how-to-estimate-the-confidence-interval-of-a-very-small-proportion</link>
      <description><![CDATA[我想估计很小比例的置信区间。假设我有 1000 人的简单随机样本，有 4 个人回答了“是”这个问题。人们可能想利用正态性假设并使用基本公式计算置信区间
CI ± z * sqrt(p^ * (1-p^)/n))
然而，要使这一点成立，通常会施加 n * p ≥ 5 且 n * (1-p) ≥ 5 的限制，在本例中违反了这一限制。
因此，我的问题是：如果我想说：“在 95% 的置信度下，回答“是”的人数比例小于 x%”。我如何找到x？]]></description>
      <guid>https://stats.stackexchange.com/questions/647947/how-to-estimate-the-confidence-interval-of-a-very-small-proportion</guid>
      <pubDate>Sat, 25 May 2024 08:51:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么信度是真实得分方差与总得分方差的比率，而不是真实得分与总得分的比率？</title>
      <link>https://stats.stackexchange.com/questions/647917/why-is-reliability-a-ratio-of-true-score-variance-to-total-score-variance-inste</link>
      <description><![CDATA[可靠性由下式给出：
$r_{xx} = \frac{Var(T)}{Var(X)}$
其中 $T$ 是真实分数，$X$ 是总分。
为什么可靠性不简单：
$r_{xx} = \frac{T}{X}$
其中 $T$ 是所有个人真实分数的总和，$X$ 是是所有个人总分的总和吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647917/why-is-reliability-a-ratio-of-true-score-variance-to-total-score-variance-inste</guid>
      <pubDate>Fri, 24 May 2024 19:14:38 GMT</pubDate>
    </item>
    <item>
      <title>导出贝叶斯线性模型中数据的条件联合概率模型</title>
      <link>https://stats.stackexchange.com/questions/647915/deriving-a-conditional-joint-probability-model-for-the-data-in-a-bayesian-linear</link>
      <description><![CDATA[我一直在阅读 Tony Lancaster 于 2004 年出版的《现代贝叶斯计量经济学导论》。在第 116-117 页，Lancaster 使用 $X$ 和残差 $p(\epsilon, X)$ 的联合分布，为线性模型 $y=X\boldsymbol{\beta}+\epsilon$ 的数据 $p(y,X|\boldsymbol{\beta})$ 推导出条件联合分布。但他在推导结果过程中使用的替换似乎并不总是合理的。它们合理吗？
他从目标开始：给定 $X$ 和 $y$，使用贝叶斯定理对 $\boldsymbol{\beta}$ 进行后验推断
$$p(\boldsymbol{\beta}|y,X)\propto p(y,X|\boldsymbol{\beta})p(\boldsymbol{\beta})$$
这需要为数据推导一个条件联合分布
$$p(y,X|\boldsymbol{\beta})$$
他的策略是首先获得 $\epsilon$ 和 $X$，假设 $\epsilon$ 和 $X$ 是独立的，而不仅仅是不相关的
$$p(\epsilon, X)=p_{\epsilon}(\epsilon)p(X)$$
他的下一步是使用 $y=X\boldsymbol{\beta}+\epsilon$ 对该联合分布进行代换，然后以 $\boldsymbol{\beta}$ 为条件，得出所需的条件联合分布
$$p(y,X|\boldsymbol{\beta})=p_{\epsilon}(y-X\boldsymbol{\beta})p(X|\boldsymbol{\beta})$$
我理解这个结果的右侧，只需使用 $\epsilon=y-X\boldsymbol{\beta}$。但左侧呢？它不能简单地替换为 $y=\epsilon$，因为那没有意义。有人能帮助我更好地理解这个结果是如何合理的吗？我是否遗漏了一些基本的东西？]]></description>
      <guid>https://stats.stackexchange.com/questions/647915/deriving-a-conditional-joint-probability-model-for-the-data-in-a-bayesian-linear</guid>
      <pubDate>Fri, 24 May 2024 18:09:37 GMT</pubDate>
    </item>
    <item>
      <title>我试图根据对数奇数比计算标准误差，这个计算正确吗？</title>
      <link>https://stats.stackexchange.com/questions/647902/i-was-trying-to-calculate-standard-error-from-log-odd-ratio-is-this-calculation</link>
      <description><![CDATA[我有两个数据集。第一个数据集具有奇数比、95% 置信区间、p 值和 2x2 表。而第二个数据集只有奇数比、95% 置信区间和 p 值，没有 2x2 表。我正在尝试对这些数据进行荟萃分析，但我需要从两个数据集计算对数（奇数比）的标准误差。因此，我尝试使用从此威胁.
可用数据：
研究 p 值 奇数比 log(奇数比) 95% CI
1 0.009 2.560 0.408 1.260-5.200
2 0.648 1.056 0.228 0.840-1.324

第一个数据集的表 2x2：
               曝光 (Y) 曝光 (N)
事件（Y）34 19
事件（中）35 50

这样，我计算了两个数据集的 z。对于 p = 0.009（两条尾），则 z = 2.612。对于 p = 0.648（两条尾），即 z= 0,456。因此 SE=log(OR)/z，第一个数据集的 SE = 0.156，第二个数据集的 SE = 0.500。
然后，使用 Revman 5.4.1，我得到：

我的问题是：

这是正确的吗？
不知何故，荟萃分析前后的置信区间不同，这正常吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/647902/i-was-trying-to-calculate-standard-error-from-log-odd-ratio-is-this-calculation</guid>
      <pubDate>Fri, 24 May 2024 14:31:06 GMT</pubDate>
    </item>
    <item>
      <title>以西格玛代数为条件的期望，它指的是什么期望？</title>
      <link>https://stats.stackexchange.com/questions/647779/expectation-conditional-on-a-sigma-algebra-what-expectation-does-it-refer-to</link>
      <description><![CDATA[在像$\sigma$-algebra条件期望的直觉这样的问题中，像$E[X|\sigma(Y)]$，我对这实际上是什么类型的变量感到困惑。
假设我们有一个概率空间 $(\Omega,\mathcal{F},P)$ ，其中包含样本空间、事件空间和概率测度：
$$\begin{array}{rcl}
\欧米茄&amp;=&amp; \lbrace 1,2,3\rbrace\\
\mathcal{F} &amp;=&amp; \lbrace \emptyset, \{1\},\{2\},\{3\},\{1,2\}, \{1,3\},\{2,3\},\{1 ,2,3\}\r大括号\\
p(\omega) &amp;=&amp; 1/3
\end{数组}$$
假设，我们考虑以下两个变量，它们将每个元素 $\omega$ 映射到 $\Omega$ span&gt; 为实际值。
$$\begin{array}{rcl}
X(\omega) &amp;=&amp; \欧米伽\
Y(\omega) &amp;=&amp; \textbf{1}_{\omega &gt; 1}\end{数组}$$
然后对于 $E[X|\sigma(Y)]$ 我可以想象两种不同的方法来计算条件变量

$X$ 的条件值对于 $Y$ 的每个值，例如 &lt; span class=&quot;math-container&quot;&gt;$$\begin{array}{}
E[X|Y = 0] &amp;=&amp; 1\\
E[X|Y = 1] &amp;=&amp; 2.5\\
\end{数组}$$
这个案例对我来说似乎非常直观。现在期望可以写成 $\omega$, $$E[X|\sigma(Y) 的函数](\omega) = \begin{cases} 1 &amp;\quad \omega \in \{1\} \\
2.5 &amp;\quad \omega \in \{2,3\}
\end{cases}$$ 但它并不以 sigma 代数中的所有事件为条件。例如 $E[X|Y = 1 \lor Y = 0] $ 怎么样？

给定 $\sigma(Y)$&lt; 中每个可能事件的 $X$ 的条件值/span&gt; 就像 $$\begin{array}{}
E[X|Y = 0] &amp;=&amp; 1\\
E[X|Y = 1] &amp;=&amp; 2.5\\
E[X|Y = 1 \或 Y = 0] &amp;=&amp; 2\\
E[X|\emptyset] &amp;=&amp; \点\\
\end{array}$$ 但在这种情况下，它使得 $E[X|\sigma(Y)]$ 不是一个变量样本函数 $\omega$。


当人们谈论 $E[X|\sigma(Y)]$ 时，这两者中的哪一个是指的？]]></description>
      <guid>https://stats.stackexchange.com/questions/647779/expectation-conditional-on-a-sigma-algebra-what-expectation-does-it-refer-to</guid>
      <pubDate>Wed, 22 May 2024 17:22:51 GMT</pubDate>
    </item>
    </channel>
</rss>