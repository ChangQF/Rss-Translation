<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 20 Jan 2025 15:17:44 GMT</lastBuildDate>
    <item>
      <title>样品去除的独立性</title>
      <link>https://stats.stackexchange.com/questions/660271/independency-in-samples-removal</link>
      <description><![CDATA[我正在研究以下子问题。我得到了一个完全加权图，$G = (V,E)$。$1 \leq u &lt; v \leq n$ 的边集 $E = \{X_{uv}\}$ 是一组随机变量，其中每个 $X_{uv} \sim U(0,1)$。
让 $i \in [1,n]$ 成为该图的一个顶点。如果存在另外两个顶点 $j \neq k$，s.t。 $j,k \in [1,n]$ 且 $j,k \neq i$ 使得
$X_{ij} = \min\{ X_{uv} \text{ s.t. } u=j \text{ 或 }v=j \}$ 且 $X_{ik} = \max\{ X_{uv} \text{ s.t. } u=k \text{ 或 }v=k \}$
即，$i$ 与 $j$ 之间的边是 $j$ 的边中的最小值，而 $i$ 与 $k$ 之间的边是 $i$ 与 $k$ 的边中的最大值（或反之亦然），则我将表示 $R = \{ X_{uv} \text{ s.t. } u=i \text{ 或 } v=i \}$。
因此，我将通过获取 $G&#39;= (V&#39;, E&#39;)$ 来缩小我的图，其中 $V&#39; = V \setminus \{i\}$ 和 $E&#39;= E \setminus R$。
现在，我能够计算出找到具有这种属性的顶点 $i$ 的概率，因为我的所有边都是 r.v。$U(0,1)$。 $P[i \in V \text{ has property above}] = 1-e^{-1}$。但是，由于我需要递归执行此过程，并且由于集合 $R$ 的特定选择，我会说 $E&#39;$ 取决于选择 $i$，并且 $E&#39;$ 的值不再是 i.i.d。因此我很想说
$P[i&#39; \in V&#39; \text{ has property above}] \neq 1-e^{-1}$ 因为 $R$ 中的边的移除可能会增加/减少连续顶点 $i&#39; \in V&#39;$ 上的属性。
您认为有办法打破这种依赖关系吗？我可以假设（并以某种方式证明）$E&#39;$ 再次由所有 i.i.d. 随机变量组成，这样我就可以再次应用我在开始时找到的概率（$1-e^{-1}$）吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660271/independency-in-samples-removal</guid>
      <pubDate>Mon, 20 Jan 2025 13:36:19 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法将标准化逻辑回归系数转换为相关性？</title>
      <link>https://stats.stackexchange.com/questions/660270/is-there-a-way-to-convert-a-standardized-logistic-regression-coefficient-into-a</link>
      <description><![CDATA[我正在对皮尔逊相关性 (Rs) 进行荟萃分析。我正在将其他相关性度量转换为 Rs（如果两个度量都是分类的，则可能在计算它们之后进行转换），并使用有关均值和标准差的信息来估计科恩的 d，然后将其转换为 R。
然而，有两篇论文，其中一个度量是连续的，另一个是二元的，并且只有比值比及其置信区间可用。我可以计算标准化（对数）比值比，因为我有连续预测变量的标准差，但是，有没有办法将其转换为相关性？当预测变量也是二元时，我已经找到了很多关于这种转换的资料，但没有关于预测变量是连续的情况的资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/660270/is-there-a-way-to-convert-a-standardized-logistic-regression-coefficient-into-a</guid>
      <pubDate>Mon, 20 Jan 2025 13:02:46 GMT</pubDate>
    </item>
    <item>
      <title>测试一系列点偏离给定线/水平的概率/重要性</title>
      <link>https://stats.stackexchange.com/questions/660269/test-the-probability-significance-that-a-sequence-of-points-will-deviate-from-a</link>
      <description><![CDATA[我想评估后续$n$ 个点（总共 $N$ 个）偏离（即其误差线不涵盖）某个任意水平/线/模型/等的概率（或者，更好的是，如果发生这种情况，其重要性）。在下面的草图中，用红色圈出的三个连续点偏离了蓝色水平/线。在这里，连续性至关重要，我对其他两个偏离点（紫色框中）不感兴趣。
我可能会天真地根据二项分布得出某些东西，但我想知道

是否有一些（或多或少复杂的）机制、统计工具、实现或类似的东西可以解决这个问题，并且
考虑这种序列作为偏差的重要性是否可能/有意义？

请注意，我不想对黑点进行任何拟合 - 我只想判断一些离散点集与预定义的任意线（无论这条线是什么）偏离的概率/重要性。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660269/test-the-probability-significance-that-a-sequence-of-points-will-deviate-from-a</guid>
      <pubDate>Mon, 20 Jan 2025 12:51:52 GMT</pubDate>
    </item>
    <item>
      <title>包含许多零的计数数据的 GLM 类型</title>
      <link>https://stats.stackexchange.com/questions/660267/type-of-glm-for-count-data-with-many-zeros</link>
      <description><![CDATA[我有一个非常大的数据集，其中统计了因某些原因（某种疾病）而入院的人数，并且该数据集的观测值是 5 年内每天的数据。除了变量入院之外，我还有 120 个其他变量，用于研究它们与因该原因入院的关系。
我的变量入院具有以下分布：60% 的天数为零人次入院，30% 的天数为一人次入院，其余 10% 的天数为2 至 4人次，范围类似（只有 5 天为4人次入院）。
我也有来自不同医院的数据，其中一些医院的零比例甚至更大。
至于我的响应变量，我控制的是季节性和长期趋势以及星期几。其余变量是连续的气象变量，其中大多数变量重复一定次数并有滞后，因为这些变量对独立变量的影响可能会随时间滞后。例如，heat 变量重复 5 次：heat1、heat2、heat3、heat4 和 heat5，每个变量都比前一个变量滞后 1 天。
admissions 的均值和方差几乎相同（~0.02（0.515, 0.535）的差异），因此我倾向于使用泊松回归而不是负二项回归进行建模。使用此方法建模后，我使用逐步向后消元法得到最终模型，因此我最终得到一个包含 27 个响应变量的模型。
R 中使用的代码如下：
modelP &lt;- glm(admissions ~ ., data = hospital, family = poisson(link = &quot;log&quot;))
我尝试使用拟泊松回归建模来比较方法，但此方法未定义 AIC，因此我无法执行向后消元法并比较两者。
modelQP &lt;- glm(admissions ~ ., data = hospital, family = quasipoisson(link = &quot;log&quot;))
使用此类数据执行泊松回归是否正确？大量变量会造成任何麻烦吗？我是否应该寻找其他类型的模型，例如 NB 或零膨胀模型？
我还想最终计算出起作用的重要变量的归因风险。]]></description>
      <guid>https://stats.stackexchange.com/questions/660267/type-of-glm-for-count-data-with-many-zeros</guid>
      <pubDate>Mon, 20 Jan 2025 11:37:12 GMT</pubDate>
    </item>
    <item>
      <title>我的 EM 算法中的对数似然没有增加（R）</title>
      <link>https://stats.stackexchange.com/questions/660265/my-log-likelihood-does-not-increase-in-my-em-algorithm-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660265/my-log-likelihood-does-not-increase-in-my-em-algorithm-r</guid>
      <pubDate>Mon, 20 Jan 2025 09:53:37 GMT</pubDate>
    </item>
    <item>
      <title>R 中的生存回归问题：处理非删失数据和模型收敛问题</title>
      <link>https://stats.stackexchange.com/questions/660263/issues-with-survival-regression-in-r-handling-non-censored-data-and-model-conve</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660263/issues-with-survival-regression-in-r-handling-non-censored-data-and-model-conve</guid>
      <pubDate>Mon, 20 Jan 2025 09:37:55 GMT</pubDate>
    </item>
    <item>
      <title>是否可以汇总 AIC/BIC 值以进行参与者级模型比较？</title>
      <link>https://stats.stackexchange.com/questions/660262/is-it-possible-to-aggregate-aic-bic-values-for-participant-level-model-compariso</link>
      <description><![CDATA[我有一个数据集，其中包含来自数百名参与者的情绪时间序列数据，他们每个人都参加了生态瞬时评估 (EMA) 研究。由于每个参与者的事件时间完全不同，我决定使用 R 中的药代动力学建模包 (mrgsolve) 生成的复杂非线性模型分别拟合每个参与者的数据。
我使用 nloptr 根据从先验知识得出的初步猜测来推导参数。由于呈现的模型数量庞大，手动优化每个模型的参数并不切实际。相反，我使用合理但未优化的参数值运行这些模型，这实际上效果很好，因为每个参与者对事件的情绪反应模式大致相似。
对于每个模型，我的零假设是数据纯粹由噪声组成。我的备选假设是，药代动力学衍生的模型在模拟参与者的情绪反应方面优于噪声模型。到目前为止，药代动力学模型似乎在几乎（但不是所有）情况下都产生了更优的 RSS 和 AIC/BIC 值。
有没有办法批量测试药代动力学建模方法产生更优的建模结果的假设，表明其所基于的模型优于噪声的零假设？例如，如果 95%（或其他百分比）的药代动力学模型产生比基于噪声的模型更优的拟合结果，这可以用来证明统计意义吗？或者是否有另一种基于指标的方法来测试这个假设，例如比较每个参与者的每个模型之间的 AIC 和 BIC 值，并将这些值汇总到所有参与者中？]]></description>
      <guid>https://stats.stackexchange.com/questions/660262/is-it-possible-to-aggregate-aic-bic-values-for-participant-level-model-compariso</guid>
      <pubDate>Mon, 20 Jan 2025 08:21:49 GMT</pubDate>
    </item>
    <item>
      <title>《危险边缘》玩家的贝叶斯分析</title>
      <link>https://stats.stackexchange.com/questions/660260/bayesian-analysis-of-jeopardy-players</link>
      <description><![CDATA[这是我的一个想法。
有一个著名的电视智力竞赛节目叫做Jeopardy。玩家回答琐事问题并相互竞争。这个游戏有一个速度元素——虽然多个玩家可能知道同一个问题的答案，但更快响铃的玩家将优先回答问题。
我很好奇，想估计一下节目中玩家的“真实知识”。我天真地以为玩家可以大致分为 4 类：

第 1 组：回答很多问题且经常正确的玩家
第 2 组：回答很多问题且经常错误的玩家
第 3 组：回答不多但经常正确的玩家
第 4 组：回答不多且经常错误的玩家

我在 R 中模拟了一些数据，以直观地展示其可能的样子：

当我们拥有关于玩家的更多数据（即第 1 组和第 2 组）时，这样做是有道理的玩家知道多少的歧义应该更少。但是，对于数据较少的玩家（即第 3 组和第 4 组），这些玩家可能实际上知道的比数据显示的要多（例如，如果他们参加有相同问题的笔试，他们的表现会与他们在智力竞赛节目中的表现不同）。这似乎应该受到他们在智力竞赛节目中回答的问题数量的影响。
贝叶斯方法（例如标准贝叶斯、经验贝叶斯）可用于尝试估计“修正”这些玩家的得分比例是多少？
这是我的想法。

标准贝叶斯：对于每个玩家$i$：


$\theta_i$是他们正确回答问题的真实概率
$n_i$是他们尝试的问题数量
$y_i$是正确答案的数量

每个玩家的似然函数遵循二项分布：
$$y_i|\theta_i \sim \text{Binomial}(n_i, \theta_i)$$
$$\theta_i \sim \text{Beta}(\alpha, \beta)$$
$$\theta_i|y_i \sim \text{Beta}(\alpha + y_i, \beta + n_i - y_i)$$
$$E[\theta_i|y_i] = \frac{\alpha + y_i}{\alpha + \beta + n_i}$$
我不确定经验贝叶斯在这里会如何使用。这些方法对这个问题有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660260/bayesian-analysis-of-jeopardy-players</guid>
      <pubDate>Mon, 20 Jan 2025 04:23:31 GMT</pubDate>
    </item>
    <item>
      <title>第二部分：为什么生存函数总是随着时间的推移而减少？</title>
      <link>https://stats.stackexchange.com/questions/660258/part-2-why-does-the-survival-function-always-decrease-with-time</link>
      <description><![CDATA[我发布了这个问题为什么生存函数总是随着时间的推移而减少？，我得到了一个非常好的答案（https://stats.stackexchange.com/a/660245/455511）解释了为什么生存函数总是随着时间的推移而减少：

是的，随着时间的推移，幸存疾病的概率会增加，
但这不是生存函数。生存函数
会每次告诉你在指定的较早时间患有该疾病的人中有多少人仍然存活下来。

我可以看到风险函数可以随时间增加和减少。例如，对于对数正态分布，风险函数可以随时间增加和减少（对数正态风险的公式是什么？）。我可以在这里看到这一点（https://devinincerti.com/2019/06/18/parametric_survival.html）。
我想知道：即使生存函数本身总是随着时间的推移而减少，生存模型（例如 AFT、Cox-PH）是否可以表明，患病后存活的概率实际上可能（暂时）随着时间的推移而增加？
例如，想象一种疾病通常会在第一年杀死人（即死亡概率很高），但如果它没有杀死你，那么身体就会适应变得更有弹性，因此死亡的概率就会降低……而死亡的概率只有在多年后才会再次增加。我理解风险函数可能能够更自然地捕捉这种行为，但我想知道生存模型是否可以通过概率而不是风险来描述这种现象？
我认为这也许可以使用条件生存概率来实现？典型的生存函数是存活超过一定时间$t$的概率，即$S(t) = P(T &gt; t)$。但由于条件生存概率定义为：
$$P(T &gt; t | T &gt; s) = \frac{S(t)}{S(s)}$$
我们可以看到，条件生存概率不会随着时间的推移而减少（即查看分数）。这意味着，如果我有一个生存模型（例如 AFT），我可以用它来估计条件生存概率，并在理论上捕捉到这种生存概率随时间增加/减少的现象：
$$S(t|x) = S_0(\exp(-\beta^Tx)t)$$
$$P(T &gt; t | T &gt; s, x) = \frac{S(t|x)}{S(s|x)} = \frac{S_0(\exp(-\beta^Tx)t)}{S_0(\exp(-\beta^Tx)s)}$$
这是正确的吗？


条件生存的推导概率：

$$P(T &gt; t|T &gt; s) = \frac{P(T &gt; t \cap T &gt; s)}{P(T &gt; s)}$$
$$P(T &gt; t \cap T &gt; s) = P(T &gt; t) \quad \text{when } t &gt; s$$
$$P(T &gt; t|T &gt; s) = \frac{P(T &gt; t \cap T &gt; s)}{P(T &gt; s)} = \frac{P(T &gt; t)}{P(T &gt; s)}$$
由于 $S(t) = P(T &gt; t)$，因此：
$$P(T &gt; t|T &gt; s) = \frac{S(t)}{S(s)}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660258/part-2-why-does-the-survival-function-always-decrease-with-time</guid>
      <pubDate>Mon, 20 Jan 2025 03:47:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Jaynes 对他的 $A_p$ 分布使用均匀先验？</title>
      <link>https://stats.stackexchange.com/questions/660257/why-does-jaynes-use-a-uniform-prior-for-his-a-p-distribution</link>
      <description><![CDATA[上下文：在《概率论：科学的逻辑》第 18 章中，Jaynes 引入了 $A_p$ 分布的概念。基本思想是，我们感兴趣的是 $A$ 事件，该事件可能为真或为假。然后，$A_p$ 是语句
$$
A_p \equiv \begin{cases}
\small \text{不管您可能已经被告知了什么，$A$ 的概率为 $p$。 }
\end{cases}
$$
给定一些关于语句 $A$ 的先验信息 $X$，我们可以在给定 $X$ 的情况下引入 $A_p$ 的概率密度，Jaynes 将其写为 $(A_p | X)$。那么 $A$ 发生的概率就是 $A_p$ 分布的第一矩​​：
$$
\begin{aligned}
\text{P}(A|X) &amp;= \int_0^1 \text{P}(A | A_p X) (A_p | X) \, dp \\
&amp;= \int_0^1 p \cdot (A_p | X) \, dp
\end{aligned}
$$
假设信息 $X$ 并未提及 $A$，只是表示它可能为真或为假。 Jaynes 声称，根据此信息，$A_p$ 分布应该是均匀的。也就是说，
$$(A_p | X) = 1$$
问题：为什么 Jaynes 在这里假设均匀分布？
我至少可以明白为什么 $A_p$ 分布的一阶矩应该是 $1/2$。由于 $X$ 并未指定 $A$ 是否应为真或为假，最大熵原理表明，我们应将 $1/2$ 指定为 $A$ 为真。但指定整个分布比仅指定其第一矩更有力。
Jaynes 说他通过遵循第 12 章中的“完全无知的人群”来做到这一点。我认为这是指第 12.4.3 节，他从中得出成功概率 $\theta$ 的无知先验。但在这种情况下，导出的先验$f(\theta)$不是均匀的：
$$
f(\theta) = \frac{\text{const.}}{\theta(1-\theta)}
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660257/why-does-jaynes-use-a-uniform-prior-for-his-a-p-distribution</guid>
      <pubDate>Mon, 20 Jan 2025 02:20:23 GMT</pubDate>
    </item>
    <item>
      <title>谁首先注意到 AR1 OLS 系数有偏差？</title>
      <link>https://stats.stackexchange.com/questions/660256/who-first-noted-that-ar1-ols-coefficients-are-biased</link>
      <description><![CDATA[我并不是在问 AR1 过程中 OLS 系数的偏差（例如，请参见为什么 AR(1) 系数的 OLS 估计量有偏差？）。
我问的是谁应该因这一观察而获得荣誉。
欢迎指点。]]></description>
      <guid>https://stats.stackexchange.com/questions/660256/who-first-noted-that-ar1-ols-coefficients-are-biased</guid>
      <pubDate>Mon, 20 Jan 2025 01:57:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们不屏蔽 Transformer 中除了多头注意力之外的其他层？</title>
      <link>https://stats.stackexchange.com/questions/660247/why-we-dont-mask-other-layers-besides-the-multihead-attention-in-transformers</link>
      <description><![CDATA[通常在训练 NLP 任务时，我们需要将序列填充到 max_len，以便可以以批处理方式高效处理它们。但是，这些填充的标记不应影响训练（模型参数的更新），因为它们是“虚构的”。
每个人都在谈论掩盖注意力操作的必要性。这是有道理的，因为有效标记不应该关注虚拟标记。但是，我们仍然需要考虑到所有其他层（例如 FF 中的线性层、规范化层等）不受填充的影响。
为简单起见，考虑单个 Transformer-Encoder 层：

从图中可以清楚地看出，FF 和最后的规范化层将填充的标记作为其他每个标记进行处理（即相同且独立）。为了正确屏蔽所有层，我们应该屏蔽损失吗？
例如，假设我们想使用 Transformer 编码器对序列进行分类。我们传递一个形状为 (B, N, E) 的输入 x，其中 B 是批量大小，N 是最大序列长度，E 是嵌入维度。输出具有相同的形状，我们将使用它进行分类。我们可以通过为每个序列提取一个“全局”向量来实现，然后将其传递给特定于任务的头部，如下所示：
x =coder_layer(x)
x = x.mask_fill(mask, -torch.inf) # 在最大操作期间屏蔽填充。
x = torch.max(x, dim=1)[0] # 忽略索引，简化为形状 (B, E)。
loss = loss_fn(cls_head(x), y)

由于 max 操作对任何未选定元素返回 0 梯度，因此所有参数都不会受到填充的影响。我的理解正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660247/why-we-dont-mask-other-layers-besides-the-multihead-attention-in-transformers</guid>
      <pubDate>Sun, 19 Jan 2025 18:58:05 GMT</pubDate>
    </item>
    <item>
      <title>哈默斯利·克利福德定理的两个版本</title>
      <link>https://stats.stackexchange.com/questions/660224/two-versions-of-the-hammersley-clifford-theorem</link>
      <description><![CDATA[在学习蒙特卡罗方法时，我了解到完整条件$P(x_j \mid x_1, \ldots, x_{j-1}, x_{j+1}, \ldots, x_p)$确定联合分布（在某些条件下）。这个结果是使用书中所谓的 Hammersley-Clifford 定理（如下所述）证明的，但我注意到他们使用的形式与我在马尔可夫网络背景下熟悉的形式非常不同。

Hammersley-Clifford 定理（来自书中）
让 $(X_1, \ldots, X_p)$ 满足正性条件并具有联合密度 $f(x_1, \ldots, x_p)$。然后，对于所有 $(\xi_1, \ldots, \xi_p) \in \operatorname{supp}(f)$:
$$
f(x_1, \ldots, x_p) \propto \prod_{j=1}^p \frac{f_{X_j \mid X_{-j}}(x_j \mid x_1, \ldots, x_{j-1}, \xi_{j+1}, \ldots, \xi_p)}{f_{X_j \mid X_{-j}}(\xi_j \mid x_1, \ldots, x_{j-1}, \xi_{j+1}, \ldots, \xi_p)}。
$$

Hammersley-Clifford 定理（针对马尔可夫网络）
设 $P$ 为 $\mathcal{X}$ 上的正分布，$\mathcal{H}$ 为 $\mathcal{X}$ 上的马尔可夫网络图。如果 $\mathcal{H}$ 是 $P$ 的 I-map（即 $\mathcal{H}$ 的马尔可夫独立性作为 $P$ 中的概率独立性成立），则 $P$ 是对 $\mathcal{H}$ 进行因式分解的吉布斯分布。
因式分解意味着 $P$ 是通过因子 $\Phi = \{\phi_1(\boldsymbol{D}_1), \ldots, 参数化的吉布斯分布\phi_K(\boldsymbol{D}_K)\}$:
$$
P_{\Phi}(X_1, \ldots, X_n) = \frac{1}{Z} \prod_{k=1}^K \phi_k(\boldsymbol{D}_k),
$$
其中 $Z$ 是规范化常数，每个 $\boldsymbol{D}_k$ 对应于 $\mathcal{H}$ 的一个完全子图（团）。

我的问题是：Hammersley-Clifford 定理的这两个陈述如何联系在一起？它们是具有相同名称但本质上不同的定理吗，或者是否有办法从另一个定理中证明一个定理（尤其是从第二个定理中证明第一个定理）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660224/two-versions-of-the-hammersley-clifford-theorem</guid>
      <pubDate>Sun, 19 Jan 2025 04:44:17 GMT</pubDate>
    </item>
    <item>
      <title>用于样本量估计的 Bootstrap。序数尺度。分布远离正态</title>
      <link>https://stats.stackexchange.com/questions/660200/bootstrap-for-sample-size-estimation-ordinal-scale-distribution-far-from-norma</link>
      <description><![CDATA[我们经常在约 100 个句子的测试翻译上比较人工翻译或机器翻译系统（每次实验中为 2 到 4 个）。
每个句子的翻译都由一名称职的翻译人员进行评分，通常为 5 分制，有时为 10 分制（分数通常为整数，但可以包括中点，例如 3.5），费用昂贵。这是我们的黄金标准，尽管不同评分者之间的结果并非 100% 一致。这意味着我正在寻找经验法则，而不是最严格的方法。
量表由口头描述定义（“小幅编辑”、“严重改变含义”等）。因此它们本质上是有序的，通常是倾斜的，有时是双峰的。
如果有两种翻译，则使用 Wilcoxon 检验来评估结果，如果有两种以上的翻译，则使用 Friedman 检验来评估结果。
如果我们无法拒绝原假设，我们可能想看看更大的样本是否有帮助。下面是我想要使用的算法。

从原始样本中生成引导样本。使用 Wilcoxon/Friedman 检验评估每个样本，并计算我们可以拒绝原假设的样本比例。这是我们估计的功效。

通过从原始样本中重复抽样来生成更大的样本，但这次取的项目要多于原始样本量。按照与上述第 (1) 点相同的方式估计检验功效。

不断增加生成的样本量，直到达到所需功效或样本量变得过大。


从实际角度来看，这有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660200/bootstrap-for-sample-size-estimation-ordinal-scale-distribution-far-from-norma</guid>
      <pubDate>Sat, 18 Jan 2025 12:37:22 GMT</pubDate>
    </item>
    <item>
      <title>回归分析中总体模型和样本模型的区别是什么？</title>
      <link>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</link>
      <description><![CDATA[术语“样本回归模型”在回归分析中究竟指什么？假设我们有一个数据集$\{(\mathbf{x}_i,\mathbf{y}_i)\}$，我们假设一个底层回归模型形式为
$$
\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon},
$$
其中$\boldsymbol{\theta}$是真实总体参数（频率学派观点）和$\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\Sigma)$。我们所说的样本回归模型到底是什么意思？
以下是我正在探索的一些可能性：

拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}})$，从某种意义上说，我们已经选择了一个估计值$\hat{\boldsymbol{\theta}}$;
拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}}) + \hat{\boldsymbol{\epsilon}}$，其中我们有一个估计值$\hat{\boldsymbol{\theta}}$ 而且 $\hat{\boldsymbol{\epsilon}} \sim \mathcal{N}(\mathbf{0},\hat{\Sigma})$;
从字面上看，人口模型 $\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon}$，但现在以样本指数的形式写出：$\mathbf{y}_i = f(\mathbf{x}_i;\boldsymbol{\theta}) + \boldsymbol{\epsilon}_i$ 使得 $\boldsymbol{\epsilon}_i$ 是观测值，而不是随机向量。
关系 $\mathbf{y}_i = f(\mathbf{x}_i;\hat{\boldsymbol{\theta}}) + \mathbf{e}_i$，其中 $\mathbf{e}_i = \mathbf{y}_i - \hat{\mathbf{y}}_i$ 是残差。

如能得到严格澄清，我们将不胜感激。

编辑：这个问题被认为不清楚，因此这里进行澄清。
问题：术语“样本回归模型”是指什么？
动机：术语“样本回归模型”用于回归分析文献中。例如，Montgomery、Peck 和 Vining 所著的《线性回归分析导论》第六版就使用了该术语。使用 Google 的“图书”标签搜索“样本回归模型”（带引号）也会产生大量结果。但是，我很难理解该术语的正式含义，这就是我提出这个问题的原因。从我目前所见，似乎确实存在对该术语的混淆，因为许多人都在使用该术语，但一些知识渊博的人似乎并不熟悉它。因此，我认为在论坛中回答这个问题是有价值的。]]></description>
      <guid>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</guid>
      <pubDate>Thu, 16 Jan 2025 07:27:25 GMT</pubDate>
    </item>
    </channel>
</rss>