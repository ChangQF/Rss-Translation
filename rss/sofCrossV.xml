<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 25 Jun 2024 21:14:04 GMT</lastBuildDate>
    <item>
      <title>信息不对称的竞价博弈</title>
      <link>https://stats.stackexchange.com/questions/649902/bidding-game-with-asymmetric-information</link>
      <description><![CDATA[
玩家 $A,B$ 正在竞标 200 次抛硬币的结果 $X\sim Bin(200,1/2)$。
获胜的玩家将获得 $X$ 减去其出价。
玩家 $B$ 的优势在于知道 20 个随机选择的硬币的结果。 （我们称这个数字为 $K\sim Bin(20,1/2)$）
在出价相等的情况下，随机选出获胜者。


在同时出价的情况下，最佳策略/期望是什么？

我的尝试：
将自己限制在纯策略中。

$A$ 的策略配置文件只是他们的出价 $a\in[0,99]$

$B$ 的策略配置文件是一组（可能不减少的）分配 $b(k)\colon k\to \left[0,\dfrac{180}{2}+k-1\right]$

A 对 $b(k)$ 的最佳回应：
$$\begin{align*}BR_A(b(k)) &amp;=\text{argmax}_a\,\, E_{k\sim K} \,\, \begin{cases}\left(k +\dfrac{180}{2}-a\right) &amp; \text{if }a&gt;b(k) \\ \dfrac{1}{2} \left(k +\dfrac{180}{2}-a\right) &amp; \text{if }a=b(k)\\ 0 &amp;\text{else}\end{cases}\\
&amp;=\text{argmax}_a \left[
\mathbf 1_{a=b(T)} P(K=T) \dfrac{1}{2}\left(k +\dfrac{180}{2}-a\right) + \sum_{k&lt;T}P(K=k) \left(k+\dfrac{180}{2}-a\right)\right]\end{align*}$$
其中 $T(b(k),a)$ (表示&quot;阈值&quot;) 定义为 $T:=\min_k \colon b(k)\geq a$。换句话说，给定$B$的出价曲线$b(k)$，$A$必须确定可能的$K$值的上限$k^*$，他们想要出价高于$B$。一旦决定了 $k^*$，实际出价 $a^*$ 就是 $b(k^*-1)+1$

$B$ 对 $a$ 的最佳回应是 $a+1$，只要 $$\dfrac{180}{2}+k - (a+1)&gt;0\iff a &lt; \dfrac{180}{2}+k-1 \iff k&gt;a+1 -\dfrac{180}{2}$$，否则保持退出。这相当于 $T(a)=a+1 -(180/2)$

我不确定这是否是正确的做法，但我不得不将这个 $T(a)$ 代入 $A$ 的最佳响应中，并找到最大化的 $a$。感觉 $B$ 想要出价高于 $A$ 的 $k$ 值的范围应该符合 $A$ 想要出价高于 $B$ 的 $k$ 值的范围，否则就有套利。



如果 $B$ 出价，并且 $A$ 可以看到，会发生什么，我将不胜感激。这似乎是一个更难的问题，因为它为$B$开辟了混合虚张声势的策略。
]]></description>
      <guid>https://stats.stackexchange.com/questions/649902/bidding-game-with-asymmetric-information</guid>
      <pubDate>Tue, 25 Jun 2024 20:54:22 GMT</pubDate>
    </item>
    <item>
      <title>澄清包括时变协变量的 GEE 模型</title>
      <link>https://stats.stackexchange.com/questions/649900/clarification-on-a-gee-model-including-time-varying-covariates</link>
      <description><![CDATA[我想知道 GEE 方法是否可以用于随时间变化的协变量？我有一项纵向研究，其中包括时间相关的协变量，我不确定是否仍可以使用 GEE 模型
根据以下出版物 https://support.sas.com/resources/papers/proceedings15/3252-2015.pdf
似乎 GEE 方法在使用时间相关的协变量时不能保证具有一致的估计量，同样在以下链接 https://mbounthavong.com/blog/tag/time-varying+covariates 中，提到“执行的传统方法纵向数据分析（例如线性混合效应模型和广义估计方程模型）能够处理随时间变化的协变量。然而，对于随时间变化的元素，治疗暴露的概率总是随时间而不同，这需要在分析单位上应用随时间变化的权重&#39;`*]]></description>
      <guid>https://stats.stackexchange.com/questions/649900/clarification-on-a-gee-model-including-time-varying-covariates</guid>
      <pubDate>Tue, 25 Jun 2024 20:13:18 GMT</pubDate>
    </item>
    <item>
      <title>神经网络如何区分输出 0 的神经元和丢失的神经元？</title>
      <link>https://stats.stackexchange.com/questions/649899/how-does-a-neural-network-differentiate-between-a-neuron-that-outputs-0-and-a-dr</link>
      <description><![CDATA[网络如何区分输出为 0 的神经元和丢失的神经元（该神经元可能输出非零值，但由于丢失而输出 0）？]]></description>
      <guid>https://stats.stackexchange.com/questions/649899/how-does-a-neural-network-differentiate-between-a-neuron-that-outputs-0-and-a-dr</guid>
      <pubDate>Tue, 25 Jun 2024 19:59:58 GMT</pubDate>
    </item>
    <item>
      <title>关于 OLS 估计量的问题（BLUE 证明）</title>
      <link>https://stats.stackexchange.com/questions/649896/question-about-ols-estimator-blue-proof</link>
      <description><![CDATA[我们知道$\beta$的 OLS 估计量是唯一的 BLUE。
证明如下。考虑一般线性估计量
$$\hat{\boldsymbol{\beta}}_\mathbf{A} 
= \hat{\boldsymbol{\beta}}_\text{OLS} + \mathbf{A} \mathbf{Y}
= \bigl[(\mathbf{x}^\text{T} \mathbf{x})^{-1} \mathbf{x}^\text{T} + \mathbf{A}\bigr] \mathbf{Y}$$
$\hat{\boldsymbol{\beta}}_\mathbf{A}$ 的偏差为 $$\begin{align}\mathbb{E}\bigl[\hat{\boldsymbol{\beta}}_\mathbf{A}-\beta\,\vert \mathbf{x}\bigr]&amp;=
\mathbb{E}\bigl[\hat{\boldsymbol{\beta}}_\mathbf{A}-\beta\,\vert \mathbf{x}\bigr] \\[6pt]
&amp;= \mathbb{E}\bigl[\hat{\boldsymbol{\beta}}_\text{OLS} + \mathbf{A} \mathbf{Y} - \boldsymbol{\beta}\bigr\vert \mathbf{x}] \\[6pt]
&amp;= \boldsymbol{\beta} + \mathbf{A} \mathbf{x} \boldsymbol{\beta} - \boldsymbol{\beta} \\[6pt]
&amp;= \mathbf{A} \mathbf{x} \boldsymbol{\beta}, \\[6pt]
\end{align}$$ 因此，$\hat{\boldsymbol{\beta}}_\mathbf{A}$ 的无偏性要求是
$$\mathbf{Ax}\beta=0$$
现在证明说我们可以假设 $\mathbf{Ax}=0$ 并从这里开始。无论如何，其余的证明对我来说都很清楚。
我不清楚为什么这里$\mathbf{Ax}\beta=0\implies \mathbf{Ax}=0$。
我只能说$\mathbf{Ax}\beta=0\implies \mathbf{x}\beta\in\mathrm{Ker}(\mathbf{A})$，这是一个较弱的条件。
换句话说，为了使 $\hat{\boldsymbol{\beta}}_\mathbf{A}$ 不偏不倚，为什么我们要要求 $\mathbf{A}$ 的 Ker 包含整个子空间 $\mathrm{span}(\mathbf{x}_1,\dots,\mathbf{x}_K)$（维度 K），而不仅仅是子空间 $\mathrm{span}(\mathbf{x}\beta)$（维度 1）？
对此的一个可能答案是，出于某种原因，需要条件 $\mathbf{Ax}\beta=0$对所有 $\beta\in\mathbb{R}^K$ 都成立。但我不明白为什么我们应该对所有 $\beta\in\mathbb{R}^K$ 假设这个条件，因为 $\beta$ 这里有一个未知的常数因子，它取决于特定的回归问题。
这个论点有什么问题？任何有关这方面的帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/649896/question-about-ols-estimator-blue-proof</guid>
      <pubDate>Tue, 25 Jun 2024 19:07:56 GMT</pubDate>
    </item>
    <item>
      <title>优化无法收敛到零膨胀贝塔二项分布的已知参数</title>
      <link>https://stats.stackexchange.com/questions/649895/optimization-fails-to-converge-on-known-parameters-for-zero-inflated-beta-binomi</link>
      <description><![CDATA[我尝试使用 R 中 VGAM 提供的分布来拟合模拟的零膨胀 beta 二项式数据。
当我对我编写的似然函数使用 optim 时，优化不会收敛到我用来模拟数据的参数上。收敛的值也会根据我输入的初始值而变化。示例：
library(VGAM)

# 模拟数据
num_obs &lt;- 1e5; num_visits &lt;- 20; alpha &lt;- 0.8; beta &lt;- 0.8; psi_0 &lt;- 0.1
sim_zoibb &lt;- rzoibetabinom.ab(
n = num_obs, size = num_visits, shape1 = alpha, shape2 = beta, pstr0 = psi_0)
hist(sim_zoibb, breaks = -0.5 : (num_visits + 0.5))

# 似然函数
nll &lt;- function(params, num_visits, data) {
alpha &lt;- params[1]; beta &lt;- params[2]; psi_0 &lt;- params[3]
return(-1 * sum(dzoibetabinom.ab(
x = data, size=num_visits, shape1=alpha, shape2=beta, pstr0=psi_0, log = TRUE)))
}

# 尝试最大似然优化
out &lt;- optim(
par = c(0.5, 0.5, 0.5), fn=nll,
num_visits=num_visits, data=sim_zoibb,
control=list(maxit=1e6))

Optim 似乎收敛得很快（例如 out$counts[1] = 150-350）。在 c(0.5, 0.5, 0.5) 的初始值下，它会产生参数估计值 0.62、0.77、7.38e-09。当我使用与我用来模拟数据的参数 c(0.8, 0.8, 0.1) 相同的初始值时，它会估计 0.71、0.94、5.82e-09。它似乎总是将 pstr0（结构性零/零膨胀的概率）估计得非常低/接近 0。
我尝试使用不同的优化方法：BFGS 和 CG 会产生误差 非有限有限差分值，L-BFGS-B 会产生误差 L-BFGS-B 需要“fn”的有限值。 SANN 可以工作，但它收敛速度不快，我让它运行的迭代次数越多，它估计的 pstr0 就越低（例如，10 次迭代时为 0.022，100 次迭代时为 0.0012，1000 次迭代时为 0.00085）。
我也尝试过使用 VGAM 本身来拟合数据，但似乎找不到正确的零膨胀 beta 二项分布。当我尝试使用没有零膨胀的分布时，我收到以下错误：
&gt; vgam(sim_zoibb ~ 1, family=betabinomialff(ishape1 = 0.5, ishape2=0.5))
eval(binomialff()@initialize) 中的错误：
响应值“y”必须为 0 或 1

我不确定哪里出了问题 - 我编写的似然函数中是否存在错误？我是否完全误解了优化过程？]]></description>
      <guid>https://stats.stackexchange.com/questions/649895/optimization-fails-to-converge-on-known-parameters-for-zero-inflated-beta-binomi</guid>
      <pubDate>Tue, 25 Jun 2024 18:53:51 GMT</pubDate>
    </item>
    <item>
      <title>纵向数据的多层模型中的中心变量</title>
      <link>https://stats.stackexchange.com/questions/649893/centering-variables-in-multilevel-models-with-longitudinal-data</link>
      <description><![CDATA[Enders 和 Tofighi 2007 讨论了用户在多级模型中以变量为中心的各种方式以及每种情况的适用情况。虽然他们主要将评论集中在横截面案例上，但他们写道：

&quot;在 [纵向 MLM] 等情况下，1 级预测因子……通常以固定值为中心，而不是以平均值为中心……在纵向研究中以固定时间点为中心可能比在横截面背景下决定使用 CGM（以总平均值为中心）或 CWC（以集群为中心）要简单得多。&quot;

在纵向/面板背景下，以时间段为中心变量的理由是什么？为什么它比 CGM 或 CWC 更常见？最后，在实践中，围绕给定时间点集中变量是什么样的？]]></description>
      <guid>https://stats.stackexchange.com/questions/649893/centering-variables-in-multilevel-models-with-longitudinal-data</guid>
      <pubDate>Tue, 25 Jun 2024 18:31:50 GMT</pubDate>
    </item>
    <item>
      <title>a) 多层次建模和 b) 向多元回归添加分类 IV 之间有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/649892/what-is-the-difference-between-a-multilevel-modelling-and-b-adding-a-categoric</link>
      <description><![CDATA[我见过的多层级建模示例相当于将组视为多元回归中的额外分类 IV。例如，如果将儿童分为 N 个类别，则可以将“类别”添加为额外 IV，然后将其虚拟编码到 N-1 个二进制变量中以运行实际回归。
我相信多层级建模远不止这些——关于它的书籍很多，而且关于固定、随机和混合效应的内容也很多。请问我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/649892/what-is-the-difference-between-a-multilevel-modelling-and-b-adding-a-categoric</guid>
      <pubDate>Tue, 25 Jun 2024 17:41:38 GMT</pubDate>
    </item>
    <item>
      <title>重复测量不等样本量的统计检验（非参数）</title>
      <link>https://stats.stackexchange.com/questions/649891/statistical-test-for-unequal-sample-sizes-of-repeated-measures-non-parametric</link>
      <description><![CDATA[我希望了解各种来源（50）之间的差异，这些来源基于 8 个序数尺度（从 2 到 4 个值不等）评估事件，这些尺度与 0 到 10 之间的离散分数相关联，步长为 0.1。大约有 25 万个事件。一些来源评估了几乎所有事件，而其余来源的评估则比较稀疏。我的目标是了解以下内容：（1）来源之间的独立性，（2）哪些尺度是独立的，以及（3）哪些尺度导致离散分数一致性的差异。
关于 (1) 的想法：我最初想到对每对来源使用 Wilcoxon 符号秩检验，并对评估相同事件的来源进行子集化，然后根据此查看有多少来源是独立的。但是，这并不能回答第二和第三个问题。我也觉得比较每对似乎不正确，但我不确定。我知道使用 Friedman 检验不起作用，因为大多数来源都是稀疏的。
对 (2) 的想法：我想我会将来源视为随机效应，但我不确定要使用什么检验。
对 (3) 的想法：如果我只有两个来源，我会做一个有序回归，比较两个来源之间每个事件的差异，以分数作为因变量，但我不确定这对多个来源是否有效。
所以我的问题是：

Wilcoxon 符号方法是否适用于回答 (1)？
回答 (2) 的好方法是什么？
回答 (3) 的好方法是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/649891/statistical-test-for-unequal-sample-sizes-of-repeated-measures-non-parametric</guid>
      <pubDate>Tue, 25 Jun 2024 17:27:44 GMT</pubDate>
    </item>
    <item>
      <title>何时在 Python 中使用 posthoc_ttest、posthoc_mannwhitney 和 posthoc_wilcoxon 检验？</title>
      <link>https://stats.stackexchange.com/questions/649890/when-to-use-posthoc-ttest-posthoc-mannwhitney-and-posthoc-wilcoxon-test-in-pyt</link>
      <description><![CDATA[请参阅本文和随附代码。
现在，对于 Q2、Q4 和 Q7，初步发现至少有一组具有不同的平均值。然后，为了找出哪个或哪些组导致了差异，进行了事后检验/成对比较。
上述内容的摘要信息如下：

我的问题是，我们如何决定何时使用哪种事后检验/成对比较检验？
相应的文档在scikit_posthocs.posthoc_ttest，scikit_posthocs.posthoc_mannwhitney、scikit_posthocs.posthoc_wilcoxon虽然提供了一些基本的使用信息，但在指出使用场景方面却不太明确。
如果我们决定使用上表（正态性、方差信息）作为指南，我们可以注意到仍然缺少一个组合（均为否）。
请提供何时使用哪一种的权威指南测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/649890/when-to-use-posthoc-ttest-posthoc-mannwhitney-and-posthoc-wilcoxon-test-in-pyt</guid>
      <pubDate>Tue, 25 Jun 2024 17:08:50 GMT</pubDate>
    </item>
    <item>
      <title>根据数据来决定使用参数检验还是非参数检验不是很有问题吗？</title>
      <link>https://stats.stackexchange.com/questions/649886/isnt-it-problematic-to-look-at-the-data-to-decide-to-use-a-parametric-vs-non-p</link>
      <description><![CDATA[我见过一些人提到，使用参数方法还是非参数方法可以通过查看数据来决定。例如这个问题：非参数与参数
这难道不是分叉路径问题的一个例子吗？
具体来说，查看数据来决定测试是否会影响类型 1 和类型 2 错误？那么S 型和 M 型错误呢？
如果这是一个问题，有什么理由可以证明这样查看数据是合理的，因为这似乎是一种常见的做法？除了不查看数据来决定测试之外，还有其他方法可以解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649886/isnt-it-problematic-to-look-at-the-data-to-decide-to-use-a-parametric-vs-non-p</guid>
      <pubDate>Tue, 25 Jun 2024 15:55:18 GMT</pubDate>
    </item>
    <item>
      <title>EfficientNetV2-B2 的详细架构</title>
      <link>https://stats.stackexchange.com/questions/649884/the-detailed-architecture-of-efficientnetv2-b2</link>
      <description><![CDATA[我目前正在研究不同的神经网络架构，我对 EfficientNetV2-B2 特别感兴趣。我知道这个模型是原始 EfficientNet 的改进版本，结合了 Fused-MBConv 层和其他增强功能。但是，我正在寻找其架构的详细细分。
以下是我目前所知道的：
EfficientNetV2 模型旨在加快训练速度并提高性能。
它们使用 Fused-MBConv 和 MBConv 层的组合。
该架构采用更灵活的复合缩放方法。
具体来说，我想了解：

每个阶段的确切配置，包括层的类型、块的数量、过滤器的数量和步幅。

Fused-MBConv 层与标准 MBConv 层的区别。

任何提供清晰架构视觉表示的图表或资源。

]]></description>
      <guid>https://stats.stackexchange.com/questions/649884/the-detailed-architecture-of-efficientnetv2-b2</guid>
      <pubDate>Tue, 25 Jun 2024 15:15:28 GMT</pubDate>
    </item>
    <item>
      <title>泊松模型解释[关闭]</title>
      <link>https://stats.stackexchange.com/questions/649883/poisson-model-interpretation</link>
      <description><![CDATA[我在解释泊松回归模型时遇到了问题，需要一些帮助。我的回归确定了摊贩类型和饮食多样性之间的关系。因变量是饮食多样性 (MFD)，独立变量是“摊贩类型”、“收入地区”和“食物空间”。
poismodel&lt;-glm(MFD~ RegoupVenType+Income_type+food_space,
data=MFDnew,family=poisson)

summary(poismodel)
exp(poismodel$coefficients)

这是我尝试解释它的方式，但我不知道它是否正确：
熟食街头摊贩的数量每增加一个单位，估计的 MFD 将增加 1.61 个单位。同样，售货亭和夫妻店/谷物店的数量每增加一个单位，估计的 MFD 将分别增加 2.33 和 2.49。现代餐厅/快餐店/面包店的数量每增加一个单位，MFD 估计将增加 2.59，而批发商的数量每增加一个单位，MFD 将增加 1.15。大卖场/超市和台式/妈妈汉堡每增加一个单位，MFD 分别增加 4.19 和 2.37。
例如，大卖场/超市的估计市场食品多样性比流动摊贩/街头小贩/流动摊贩高 3.68。同样，熟食街头摊贩/路边餐饮、售货亭/杜卡和夫妻店/谷物店的估计 MFD 分别比流动摊贩高 1.53、2.28 和 2.41。对于现代餐馆/快餐店，估计的 MFD 与流动摊贩的 MFD 差异为 2.22。桌面摊贩和批发商与流动摊贩/街头小贩/流动摊贩之间的估计 MFD 差异分别为 2.28 和 1.42。]]></description>
      <guid>https://stats.stackexchange.com/questions/649883/poisson-model-interpretation</guid>
      <pubDate>Tue, 25 Jun 2024 15:11:05 GMT</pubDate>
    </item>
    <item>
      <title>测量值表示时间序列中的范围</title>
      <link>https://stats.stackexchange.com/questions/649879/measured-value-represents-range-in-timeseries</link>
      <description><![CDATA[我的数据集由测量点（测量 m）、景观/区域（x 和 y）和时间（t）组成。问题在于，测量实际上是在一段时间内进行的，例如一个月。在月底，我们会对采样器进行分析，并收到该时间段的单个测量值。目前，我们取采样器进行测量期间的中点，或者取平均值，以代表整个月的测量值。希望所附图片也有助于解释。线条通过中点绘制，而点（如此接近以至于看起来像水平线）显示全范围。采样器以恒定速率进行测量，因此我认为很难描述该模式。
编辑 #1：问题是我如何适当地对这些数据进行建模，考虑到虽然我只有一个 m 值，但它代表了一个时间跨度？我热衷于建立一个统计模型，以便（希望）更好地理解位置和月份等之间的模式/差异，并可能预测前向/超空间。
我觉得可能有更好的方法来做到这一点 - 或者可能没有。我花了一些时间搜索和使用我以前的知识，但我目前没有主意了。在理想情况下，建议的方法也能够适应包括空间信息（x 和 y）并在 R 中运行。提前致谢！

用于制作该图的虚拟数据（如果有用）：
set.seed(123)

series_A &lt;- 50 + 10*sin(2*pi*time/12) + rnorm(12, 0, 5)
series_B &lt;- 50 + 10*sin(2*pi*time/12 + pi/6) + rnorm(12, 0, 5)
series_C &lt;- 50 + 10*sin(2*pi*time/12 + pi/3) + rnorm(12, 0, 5)

日期 &lt;- seq(as.Date(&quot;2024-01-01&quot;), by = &quot;month&quot;, length.out = 12)

start_dates &lt;- rep(dates, 3) + sample(c(0, 1, 3, 6, 10), 
length(dates), replace = TRUE)
end_dates &lt;- start_dates + 14
mid_date &lt;- start_dates
month &lt;- lubridate::month(start_dates, label = TRUE)

mid_dates &lt;- c()
for(i in 1:length(start_dates)){

mid_dates &lt;- c(mid_dates, seq(start_dates[i], end_dates[i], 
by = &#39;days&#39;)[floor(length(seq(start_dates[i], end_dates[i], 
by = &#39;days&#39;))/2)])

}

data &lt;- data.frame(start_time = start_dates,
end_dates = end_dates, 
mid_dates = as.Date(mid_dates),
month = month,
location = rep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), each = 12),
measurement = c(series_A, series_B, series_C))

out &lt;- list()

for(i in 1:length(start_dates)){

pnt_dates &lt;- seq(start_dates[i], end_dates[i], by = &#39;days&#39;)
#out[[i]] &lt;- data[rep(data[i,], each = length(pnt_dates)), ] 
#out[[i]]$pnt_dates &lt;- pnt_dates

out[[i]] &lt;- split(data, rep(i, length(pnt_dates)))
out[[i]]$pnt_dates &lt;- pnt_dates

}

data2 &lt;- do.call(rbind, out)

ggplot(data, aes(x = mid_dates, y = measure, color = location, 
group = location)) +
geom_line() +
geom_point(data = data2, aes(x = pnt_dates)) +
labs(title = &quot;Three具有季节性模式的时间序列”,
x = “月份”,
y = “值”,
color = “时间序列”）
]]></description>
      <guid>https://stats.stackexchange.com/questions/649879/measured-value-represents-range-in-timeseries</guid>
      <pubDate>Tue, 25 Jun 2024 14:32:53 GMT</pubDate>
    </item>
    <item>
      <title>对不同层次的数据执行 PCA</title>
      <link>https://stats.stackexchange.com/questions/649877/performing-a-pca-on-data-of-different-hierarchical-levels</link>
      <description><![CDATA[我（新手）计划对几个不同的、相关的、即非正交的问卷测量使用 PCA。这些测量具有综合分数（项目总和等），其中一些具有子方面。此外，一些单项变量可能比综合分数更适合我的研究问题。因此，我希望将项目级数据输入 PCA，理想情况下，不会丢失信息。我可以将综合测量（问卷/方面级别）和项目级测量输入到同一个 PCA 中，即数据的不同层次级别吗？
此外，我如何追溯结果的主成分由哪些输入变量组成，即它们对相应成分贡献了多少方差？这是否与仅查看每个变量的因子载荷相同？
是否有一些聚类方法可以用来进一步了解我的数据中存在哪些模式？
非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/649877/performing-a-pca-on-data-of-different-hierarchical-levels</guid>
      <pubDate>Tue, 25 Jun 2024 13:24:46 GMT</pubDate>
    </item>
    <item>
      <title>对因变量中含有大量零的数据进行 PLS 回归</title>
      <link>https://stats.stackexchange.com/questions/649875/pls-regression-on-data-with-high-number-of-zeros-in-dependent-variable</link>
      <description><![CDATA[我想对来自光谱图像 (NIRS) 的数据集执行 PLS 回归。我的目标是将不同的光谱与化合物的总量联系起来。为此，我有一个包含数千个样本的数据集，其中该化合物的量从 0 到 25 左右不等。
但是，如附图所示，有大量样本没有可检测到的该化合物量或根本没有产生该化合物。在分类问题的情况下，这可能会因类别之间的不平衡而引发问题，但是，我不知道在回归中是否会出现这种情况。我一直在阅读有关使用 0 膨胀的数据的 Hurdle 模型，但是，我不确定如何进行，因为最终目标是选择与化合物总量最相关的光谱带。有什么建议吗？提前致谢。

编辑：我想到 PLS 回归，因为它是通过 NIRS 获得的光谱确定化合物浓度的常用技术。由于独立变量（光谱）的数量约为 4200，并且正在寻找有关处理此类数据的信息，我在网络上找到了参考。作者通过双循环选择了与化合物量最相关的光谱带，其中他首先优化了用于转换数据的组件数量，然后通过拟合多个模型选择了适当数量的光谱带，其中 MSE 最低。最初，这种方法对我来说似乎很合适，尽管由于数据中零的分布很高，我不确定如何继续。]]></description>
      <guid>https://stats.stackexchange.com/questions/649875/pls-regression-on-data-with-high-number-of-zeros-in-dependent-variable</guid>
      <pubDate>Tue, 25 Jun 2024 13:00:30 GMT</pubDate>
    </item>
    </channel>
</rss>