<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 14 Jan 2025 18:21:44 GMT</lastBuildDate>
    <item>
      <title>合成控制中的缩放</title>
      <link>https://stats.stackexchange.com/questions/660020/scaling-in-synthetic-controls</link>
      <description><![CDATA[我正在设计一个营销测试，计划在一个国家（“测试国家”）开展一项活动，并使用其他国家作为控制对象来估计活动的影响。为此，我采用了合成控制方法。
我面临的挑战是 KPI 量在不同国家之间存在很大差异。具体来说，测试国家的 KPI 量远高于任何潜在的控制国家。这种差异使得很难找到合适的合成控制拟合，因为合成控制权重被限制在 0 到 1 之间。
为了解决这个问题，我通过将 KPI 除以每个国家的最大 KPI 值（即每个国家/地区的 KPI / max(KPI)）来缩放 KPI。我的理由是合成控制主要侧重于匹配趋势和增长模式，因此缩放 KPI 不会带来问题。
但是，我想确保这种方法在统计上是合理的。具体来说：

在综合控制的背景下，以这种方式扩展 KPI 是否会从统计角度引入任何偏差或问题？
是否有替代方法或最佳实践来处理测试和控制单元之间的 KPI 水平差异很大的情况？

任何见解或相关文献的参考都将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660020/scaling-in-synthetic-controls</guid>
      <pubDate>Tue, 14 Jan 2025 18:12:51 GMT</pubDate>
    </item>
    <item>
      <title>使用倾向评分匹配和复合协变量评估生存结果的治疗效果</title>
      <link>https://stats.stackexchange.com/questions/660018/estimating-treatment-effects-with-survival-outcomes-with-propensity-score-matchi</link>
      <description><![CDATA[我正在研究两种抗凝剂是否能改善一组肝硬化患者的生存结果。目前尚不清楚哪种药物更好（临床均势）。
让 $Y$ 表示生存数据，$A$ 表示治疗（$A=0$ 表示药物 1，$A=1$ 表示药物 2）。$A=0$ 有 300 个观察值，$A=1$ 有 100 个观察值。 $X_1, X_2, ..., X_{80}$ 是协变量集，其中 $X_1, ..., X_5$ 是连续的，其余的是二进制的。
值得注意的是，还有另一个协变量 $X_C$，定义为 $X6, ..., X_{10}$ 至少两次门诊就诊或一次住院就诊的综合。
我对 $X_1, X_2, ..., X_{80}$ 运行了一些最近邻匹配，具有不同的比率和卡尺尺寸。我发现，在 PS 的 logit 上，使用 caliper $0.1* SD(logit PS)$ 的 3:1 近邻无替换匹配效果最佳。
mod &lt;- matchit(A~X1+X2+...+X65, 
data = df, 
method = &#39;nearest&#39;,
ratio = 3, 
caliper = 0.1, 
link = &#39;linear.logit&#39;,
distance = &#39;glm&#39;,
replace.= F)

bal &lt;- bal.tab(mod, un = T, s.d.denom = &quot;pooled&quot;, addl = ~Xc)

如您所见，$X_C$ 并未包含在 PS 模型本身中，但我将其传递了bal.tab() 检查其平衡性。所有 $X_1、X_2、...、X_{80}$ 都是平衡的，但 $X_c$ 不平衡，比赛后原始比例差异为 0.1，标准化差异为 0.24。
比赛后样本量减少到治疗组 200 个，对照组 100 个。

这里的估计量是什么？由于一些治疗观察结果被丢弃，ATT 似乎不是正确的选择？我读到估计量是重叠度量 (ATO)，但 MatchIt 中的 估计量 参数似乎没有 &quot;ATO&quot; 选项&gt;
除了尝试其他匹配方法外，我该如何处理 $X_C$ 中的残差不平衡？我最初的想法是在 Cox 模型中包含 $X_C$：$Y$~$A+X_C$，但似乎这样做会导致条件 HR，而不是边际 HR，因为 HR 是不可折叠的。 还是因为 $X_C$ 未包含在 PS 匹配中，$Y$~$A+X_C$ 仍然可以代表边际 HR？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660018/estimating-treatment-effects-with-survival-outcomes-with-propensity-score-matchi</guid>
      <pubDate>Tue, 14 Jan 2025 17:48:16 GMT</pubDate>
    </item>
    <item>
      <title>是否有可以在 R 中使用的统计分析来评估曲线区域之间的显著差异？</title>
      <link>https://stats.stackexchange.com/questions/660017/is-there-a-statistical-analysis-that-can-be-used-in-r-to-assess-significant-diff</link>
      <description><![CDATA[我想知道是否有统计分析可以确定两种处理中曲线/回归的区域之间的差异。我知道有几种统计分析可以确定两个回归/曲线之间是否存在变量差异，但我不知道有任何一种可以识别区域差异。
假设 X = Light_uE，Y = CellspermL，物种是处理条件（应用于生成两个不同的图）。我如何判断 Light_uE (X) 条件下的曲线之间是否存在显着差异，从 10-20 或 20-30 在物种之间？同样，如果曲线整体不同，则不是。 这个问题似乎与我所寻求的类似，只是它检查的是整个数据集而不是一小部分，并且使用多项式函数而不是分段回归。（我也不认为 ANOVA 适合这种情况，如果可能的话，我希望坚持使用 ggplot。）
我提供了一个可重现的数据框，以及绘制此数据的代码（如果您想将其可视化）。感谢您的帮助。
example_curves &lt;- data.frame(
Light_uE = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 
10, 20, 30, 40, 50, 60, 70, 80, 90, 100),
CellspermL = c(1000000, 2000000, 3000000, 4000000, 5000000, 
4000000, 3000000, 2000000, 1000000, 500000,
2000000, 2500000, 3500000, 3600000, 4000000, 
3900000, 3000000, 2000000, 1000000, 500000),
物种 = c(&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, 
&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, 
&quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, 
&quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;))

print(example_curves)

# 分段绘图
library(segmented)
library(gridExtra)
library(ggplot2)

create_piecewise_plot &lt;- function(data, title, initial_psi) {
# 拟合线性模型
lm_model &lt;- lm(CellspermL ~ Light_uE, data = data)

# 应用分段函数并手动指定初始断点
seg_model &lt;- fragmented(
lm_model, 
seg.Z = ~Light_uE, 
psi = initial_psi, # 手动指定起点
control = seg.control(display = FALSE) # 禁用额外输出
)

data$fitted_values &lt;- fitted(seg_model)

p &lt;- ggplot(data, aes(x = Light_uE, y =每毫升细胞数)) +
geom_point() +
geom_line(aes(y = fitted_values), color = &#39;blue&#39;) +
labs(
title = title,
x = &quot;Light (uE)&quot;,
y = &quot;每毫升细胞数&quot;
) +
theme_minimal()

return(p)
}

# 按物种创建两个不同的图
data_species_a &lt;- subset(example_curves, Species == &quot;A&quot;)
data_species_b &lt;- subset(example_curves, Species == &quot;B&quot;)

range_a &lt;- range(data_species_a$Light_uE)
range_b &lt;- range(data_species_b$Light_uE)

# 确保 initial_psi 值在范围内
plot_species_a &lt;- create_piecewise_plot(data_species_a, &quot;Species A&quot;, initial_psi = 50) # 在 range_a 内选择一个有效值
plot_species_b &lt;- create_piecewise_plot(data_species_b, &quot;Species B&quot;, initial_psi = 50) # 在 range_b 内选择一个有效值

# 使用 grid.arrange 水平排列图
grid.arrange(plot_species_a, plot_species_b, ncol = 2)
]]></description>
      <guid>https://stats.stackexchange.com/questions/660017/is-there-a-statistical-analysis-that-can-be-used-in-r-to-assess-significant-diff</guid>
      <pubDate>Tue, 14 Jan 2025 17:04:03 GMT</pubDate>
    </item>
    <item>
      <title>如何避免在该回归模型中引入内生性？</title>
      <link>https://stats.stackexchange.com/questions/660016/how-to-avoid-introducing-endogeneity-in-this-regression-model</link>
      <description><![CDATA[我有一份关于人们一生中何时去医院的数据集 (R)。我们假设数据集中患者的第一个条目代表他们一生中第一次去医院：
library(tidyverse)
set.seed(123)

n_people &lt;- 300
n_years &lt;- 10
base_rate &lt;- 0.5
age_effect &lt;- 0.1

people_df &lt;- data.frame(
person_id = 1:n_people,
first_visit_age = sample(20:60, n_people, replace = TRUE)
)

generate_visits &lt;- function(age, base_rate, age_effect) {
lambda &lt;- base_rate * (age^1.2) / (age + 20)
rnbinom(1, mu = lambda, size = 3)
}

hospital_data &lt;- expand_grid(
person_id = 1:n_people,
year = 0:n_years
) %&gt;%
left_join(people_df, by = &quot;person_id&quot;) %&gt;%
mutate(
age = first_visit_age + year,
new_visits = case_when(
year == 0 ~ 1,
year &gt; 0 ~ mapply(generate_visits, age, base_rate, age_effect)
)
) %&gt;%
group_by(person_id) %&gt;%
range(person_id, age) %&gt;%
mutate(
cumulative_visits = cumsum(new_visits)
) %&gt;%
ungroup()


我想建立一个回归模型来回答以下问题：是什么原因导致有些人比其他人更频繁地去医院？例如，那些在生命早期第一次去医院的人，一生中去医院的频率更高——这些人是否更有可能在以后的生活中继续去医院？
我想到的基本思想是混合效应回归模型，例如这两个模型中的一个（$Y_{it}$ 是人 $i$ 在时间 $t$ 的新医院就诊次数和 $u_i \sim N(0, \sigma^2_u)$):
$$\log(E[Y_{it}]) = \beta_0 + \beta_1\text{FirstVisitAge}i + \beta_2\text{CurrentAge}{it} + \beta_3(\text{CurrentAge}_{it} - \text{FirstVisitAge}i) + u_i + \epsilon{it}$$
$$\log(E[Y_{it}]) = \beta_0 + \beta_1\text{FirstVisitAge}_i + \beta_2\text{CurrentAge}_{it} + \beta_3(\text{CurrentAge}_{it} - \text{FirstVisitAge}_i) + \beta_4(\text{FirstVisitAge}_i \times (\text{CurrentAge}_{it} - \text{FirstVisitAge}_i)) + u_i + \epsilon_{it}$$
但是，我怎样才能让这个回归模型考虑以前的住院情况而不引入内生性呢？我很想为迄今为止的累计住院次数添加一个滞后变量，但我知道这会引入内生性。
我认为自回归误差项也许可以部分解释以前住院的影响：
$$\log(E[Y_{it}]) = \beta_0 + \beta_1\text{FirstVisitAge}i + \beta_2\text{CurrentAge}{it} + \beta_3(\text{CurrentAge}_{it} - \text{FirstVisitAge}i) + u_i + \nu{it}$$
$$\nu_{it} = \rho\nu_{i,t-1} + \epsilon_{it}$$
$$\epsilon_{it} \sim N(0, \sigma^2_\epsilon)$$
但是，是否可以添加一些东西来明确模拟先前住院的影响，而不会引入内生性？]]></description>
      <guid>https://stats.stackexchange.com/questions/660016/how-to-avoid-introducing-endogeneity-in-this-regression-model</guid>
      <pubDate>Tue, 14 Jan 2025 16:48:50 GMT</pubDate>
    </item>
    <item>
      <title>应该使用什么正确的测试来计算所需样本量（微生物水污染）？</title>
      <link>https://stats.stackexchange.com/questions/660015/what-would-be-the-correct-test-to-use-to-calculate-required-sample-size-microbi</link>
      <description><![CDATA[我提议进行一项实验，比较动物直接使用过的水样、暴露在空气中相同时间但被关在笼子里以避免动物直接使用的水样以及基线（实验开始时采集的样本）中微生物病原体的存在情况。我不确定计算所需样本量的适当方法是什么——希望试点数据可以表明效果大小，但目前我想考虑一个范围内的要求。假设动物饮用/洗澡时微生物污染最高。
取样将来自每种条件下的不同水碗；可能每种情况下两个，一次放出。我可以多次进行实验。我还不确定从每个碗中采集多个样本的利弊——了解这对样本量意味着什么会很有帮助。我知道这可以帮助理解水碗内的变化 + 可能更具代表性，但我需要考虑来自同一碗的样本之间的相关性？
我计划同时进行总活菌计数和目标病原体（沙门氏菌、假单胞菌、金黄色葡萄球菌）的二元存在/不存在。
最小功率应为 80%，alpha 误差 == 0.05。]]></description>
      <guid>https://stats.stackexchange.com/questions/660015/what-would-be-the-correct-test-to-use-to-calculate-required-sample-size-microbi</guid>
      <pubDate>Tue, 14 Jan 2025 16:23:02 GMT</pubDate>
    </item>
    <item>
      <title>二项式结果的等效性检验</title>
      <link>https://stats.stackexchange.com/questions/660014/equivalency-testing-for-binomial-outcome</link>
      <description><![CDATA[假设我有由三个治疗水平产生的数据。结果变量是二项式（存在/不存在）。我如何测试两个水平与“标准”水平的“治疗”之间的相等？
这是否适合 TOST？如果是，我将使用哪种 TOST 方法？
我可以比较贝叶斯后验吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660014/equivalency-testing-for-binomial-outcome</guid>
      <pubDate>Tue, 14 Jan 2025 15:54:17 GMT</pubDate>
    </item>
    <item>
      <title>对随机截距多层模型进行独立性卡方检验</title>
      <link>https://stats.stackexchange.com/questions/660013/running-a-chi-square-of-independence-test-preliminary-to-the-random-intercept-mu</link>
      <description><![CDATA[我执行了随机截距多层模型，遇到了以下问题：
优化器 (Nelder_Mead) 收敛代码：4（10000 次评估中无法收敛）
无法评估缩放梯度
模型无法收敛：退化 Hessian 具有 2 个负特征值
10000 次评估中无法收敛

进一步检查后，我发现它们包括多重共线性和异常值问题，我相信在模型之前运行卡方独立性检验将有助于解决这些问题。我正在尝试修复模型，并认为在模型之前运行卡方独立性检验可能有助于解决与上述相关的一些问题。之前我问过二进制是否需要这样做，并被告知在二进制之前不需要运行它。然而，Beacom 2023 强调，在二元逻辑回归之前运行独立性卡方检验可以帮助研究人员识别关联，并仅将与结果相关的预测因子纳入模型中。
例如，我遇到过一些预测因子只有一个响应的情况，因此我怀疑部分原因是上述原因（多重共线性和异常值）。我认为它们没有任何影响，因此不应该成为模型的一部分，而运行卡方有助于解决这个问题。因此，问题是，在拟合 MLM 之前运行卡方检验是否可以接受？]]></description>
      <guid>https://stats.stackexchange.com/questions/660013/running-a-chi-square-of-independence-test-preliminary-to-the-random-intercept-mu</guid>
      <pubDate>Tue, 14 Jan 2025 14:39:22 GMT</pubDate>
    </item>
    <item>
      <title>通过 RKHS 实现的 SVM 解决方案的平滑度</title>
      <link>https://stats.stackexchange.com/questions/660011/smoothness-of-svm-solution-via-rkhs</link>
      <description><![CDATA[我试图将 RKHS 的 SVM 视图与 SVM 解决方案的平滑性联系起来：
经典原始函数由以下公式给出：
\begin{aligned}
\text{最小化} \quad &amp; \frac{1}{2} \|\mathbf{w}\|^2, \quad \mathbf{w} \in \mathbb{R}^d, \, b \in \mathbb{R}, \\
\text{受制于} \quad &amp; y_i (\mathbf{w}^\top \mathbf{x}_i + b) \geq 1, \quad i = 1, \dots, n, \\
&amp; \mathbf{x}_i \in \mathbb{R}^d, \, y_i \in \{-1, 1\}。
\end{aligned&gt;
我们知道：
$\mathbf{w} = \sum_{i=1}^n \alpha_i y_i \mathbf{x}_i$
现在使用内核 $k$ 和一些相关特征图 $\phi(x$) 进行重构
$\mathbf{w} = \sum_{i=1}^n \alpha_i y_i \phi(\mathbf{x}_i)$
$\|\mathbf{w}\|^2 = \mathbf{w}^\top \mathbf{w} = \sum_i \sum_j \alpha_i \alpha_j y_i y_j \phi(\mathbf{x}_i)^\top \phi(\mathbf{x}_j)
= \sum_i \sum_j \alpha_i \alpha_j y_i y_j k(\mathbf{x}_i, \mathbf{x}_j)
= \|f\|^2_{H}.$
因此最小化 $||\mathbf{w}||$ 与最小化 $||f||_H$ 相同。
并且由于对于任何 $f \in H$ 和任意对 $x,x&#39; \in X$
$
|f(\mathbf{x}) - f(\mathbf{x}&#39;)| = |\langle f, K_{\mathbf{x}} - K_{\mathbf{x}&#39;} \rangle_{H}|
\leq \|f\|_{H} \cdot \|K_{\mathbf{x}} - K_{\mathbf{x}&#39;}\|_{H}
= \|f\|_{H} \cdot d_K(\mathbf{x}, \mathbf{x}&#39;),
$
$||f||_H$ 在某种程度上控制了平滑度。那么，这是否是 SVM 优化平滑解决方案的一个论点？]]></description>
      <guid>https://stats.stackexchange.com/questions/660011/smoothness-of-svm-solution-via-rkhs</guid>
      <pubDate>Tue, 14 Jan 2025 14:11:39 GMT</pubDate>
    </item>
    <item>
      <title>带有附加预测因子的 OLS 问题，比较系数</title>
      <link>https://stats.stackexchange.com/questions/660010/ols-question-with-additional-predictor-compare-coefficients</link>
      <description><![CDATA[给定$Corr(Y, X_1) &gt; 0$，$Corr(Y, X_2) = 0$，$Corr(X_1, X_2) &gt; 0$。考虑 2 个回归：
$Y = a X_1 + \epsilon$
$Y = b_1 X_1 + b_2 X2 + \epsilon$
$a$ 和 $b_1$ 哪一个更大？
我的工作：我通过正则方程进行了计算，得到了 $b_1 = \frac{a}{1-Corr(X_1,X_2)}$，这意味着 $b_1$ 应该更大（这是假设每个变量都以 0 为中心并且具有方差1)。
但这似乎是违反直觉的，我预计结果会是一样的，因为$X_2$没有添加有关$Y$的（线性）信息。
有人可以提供解决方案并解释我上面哪些矛盾的方法是错误的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660010/ols-question-with-additional-predictor-compare-coefficients</guid>
      <pubDate>Tue, 14 Jan 2025 14:00:03 GMT</pubDate>
    </item>
    <item>
      <title>CDC 表示，女性的平均性伴侣数量为 4.3。这是怎么回事？</title>
      <link>https://stats.stackexchange.com/questions/660008/cdc-says-median-number-of-sexual-partners-a-woman-has-is-4-3-how-can-this-be</link>
      <description><![CDATA[https://www.cdc.gov/nchs/nsfg/key_statistics/n-keystat.htm
根据 CDC 的数据，女性性伴侣数量的中位数为 4.3。但这怎么可能呢？中位数可以是 4、5 或 4.5，但怎么会是 4.3？CDC 搞错了吗？还是他们对中位数使用了不同的估计量？如果是这样，他们使用的是什么估计量？]]></description>
      <guid>https://stats.stackexchange.com/questions/660008/cdc-says-median-number-of-sexual-partners-a-woman-has-is-4-3-how-can-this-be</guid>
      <pubDate>Tue, 14 Jan 2025 13:43:50 GMT</pubDate>
    </item>
    <item>
      <title>对序数、相关特征进行降维，并附加连续特征</title>
      <link>https://stats.stackexchange.com/questions/660005/dimension-reduction-on-ordinal-related-features-with-additional-continuous-feat</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660005/dimension-reduction-on-ordinal-related-features-with-additional-continuous-feat</guid>
      <pubDate>Tue, 14 Jan 2025 13:26:13 GMT</pubDate>
    </item>
    <item>
      <title>例如，I(X;Y|Z) < I(X;Y)</title>
      <link>https://stats.stackexchange.com/questions/660001/example-where-ixyz-ixy</link>
      <description><![CDATA[我问自己是否有可能$I(X;Y|Z)&lt;I(X;Y)$。起初这看起来很奇怪，因为知道$Z$的值怎么会导致$Y$提供的$X$信息比$Z$未知时提供的少。
然后我进入维基百科，我发现这是可能的。 $I(X;Y|Z)$ 可以等于、小于或大于 $I(X;Y)$。$I(X;Y|Z)&lt;I(X;Y)$ 背后的直觉是 $Z$ 解释了 $X$ 和 $Y$ 之间相关性的部分原因。
但是，我很难想出一个简单的例子来说明这一点。维基百科中没有数值示例，我在这个网站上也没有找到。]]></description>
      <guid>https://stats.stackexchange.com/questions/660001/example-where-ixyz-ixy</guid>
      <pubDate>Tue, 14 Jan 2025 10:01:13 GMT</pubDate>
    </item>
    <item>
      <title>如何比较多层模型中固定效应和随机效应之间的贡献？</title>
      <link>https://stats.stackexchange.com/questions/659976/how-to-compare-the-contribution-between-a-fixed-effect-and-a-random-effect-in-a</link>
      <description><![CDATA[假设我有一个包含三个变量的数据集：$y$，我想要了解的结果；$x$，与$x$共变的变量，但我们可以假设它是完美测量的；$g$，分组变量，用于标识测量所属的多个群集（例如，主题）之一。我用多级（分层）回归模型拟合数据，形式为
$$y_i = (\beta_0 + b_{0,g[i]}) + (\beta_1 + b_{1, g[i]})x_i + \varepsilon_i$$
其中 $i = 1, \ldots, n$ 索引数据集中的观测值，$g[i]$ 是观测值 $i$ 的变量 $g$ 的值。
在 lme4 表示法中，该模型为 y ~ 1 + x + (1 + x | g)，允许每个簇有自己的斜率和截距，同时计算总斜率和截距。
我想用这个模型回答的问题是对于解释结果变量，哪个更重要：$x$ 的影响还是聚类间变异性？
我认为回答这个问题的一个实用方法可能是划分方差（如果这很重要，可以假设误差分布是正态的），但我真的不知道该怎么做。我知道，如果我拟合一个非分层模型，即 y ~ 1 + x，方差可以划分为回归可以解释的部分和不能解释的部分。
我还知道，当我拟合模型 y ~ 1 + x + (1 + x | g) 时，我会估计由按 g 分组的随机效应解释的方差分量。从这个模型中，是否可以将方差分解为由固定效应解释的部分、由随机效应解释的部分和残差变异性？如果可以，我该怎么做？
有没有更好的方法来回答这个问题？我认为对解释方差进行划分是一种直观的方式，可以说明一个变量“更重要”比其他的要好，但如果有更好的衡量标准，那也是可以的。
举一个具体的例子，我在 R 中模拟了一个遵循此模型的数据集，并且所有模型参数都是可估计的。
set.seed(101)
n_subjects &lt;- 20
x_values_per_subject &lt;- c(0.1, 0.25, 0.5, 0.75)
x &lt;- rep(x_values_per_subject, times = n_subjects)
g &lt;- rep(1:n_subjects, each = length(x_values_per_subject))
global_b0 &lt;- 5
individual_b0 &lt;- rnorm(n_subjects, global_b0, 5)
global_b1 &lt;- -2
individual_b1 &lt;- rnorm(n_subjects, global_b1, 3)
residual_variance &lt;- 1
mu &lt;- global_b0 + individual_b0[g] +
(global_b1 + individual_b1[g]) * x
error_variate &lt;- rnorm(length(mu), 0, residual_variance)
y &lt;- mu + error_variate
observed_data &lt;- data.frame(x, g, y)

此外，这里有一些简单的代码来可视化组级轨迹。
plot(
NULL, NULL,
xlim = range(x_values_per_subject),
ylim = range(observed_data$y),
xlab = &quot;x&quot;, ylab = &quot;y&quot;
)
for (i in unique(observed_data$g)) {
this_g &lt;- subset(observed_data, g == i)
lines(this_g$x, this_g$y, type = &quot;b&quot;)
}

拟合这两个模型都很容易。
library(lme4)
simple_model &lt;- lm(y ~ 1 + x, data = perceived_data)
multilevel_model &lt;- lme4::lmer(y ~ 1 + x + (1 + x | g), data = perceived_data, REML = FALSE)

当我比较这两个模型时，我发现这两个模型对固定效应的点估计值相同，尽管由于我们已经考虑了聚类的额外变化，x 固定效应的标准误差要小得多。如果我们使用 ANOVA 或 AIC 来比较模型，多层级模型显然要好得多。
summary(simple_model)
summary(multilevel_model)
anova(multilevel_model, simple_model)

因此，给定这两个模型，我如何确定 x 的固定效应是否比集群间变异更重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/659976/how-to-compare-the-contribution-between-a-fixed-effect-and-a-random-effect-in-a</guid>
      <pubDate>Mon, 13 Jan 2025 19:01:20 GMT</pubDate>
    </item>
    <item>
      <title>通过置信区间计算来确定数据收集停止是否“可以”？</title>
      <link>https://stats.stackexchange.com/questions/659962/is-it-ok-to-determine-data-collection-stopping-with-confidence-interval-calcul</link>
      <description><![CDATA[我有一枚加重硬币，正面朝上的概率为 $p$。我可以随意抛这枚硬币并观察结果；我想知道 $p$ 的值是多少。我还想知道我应该抛硬币多少次才能对概率有一个合理准确的估计。
（我的问题的实际“现实世界”背景有点愚蠢——我试图确定视频游戏中某个动作成功或失败的概率；我有理由相信它是伯努利分布，我认为$p \approx 0.15$是一个非常粗略的概念。我的初始样本表明它可能低至~$0.10$或高达~$0.20$。然而，我认为“加权硬币”设置会让它更容易理解，而不会陷入游戏的细节。）
我想做的是计算威尔逊得分区间，这样我就有了一个区间，在这个区间内，我可以有 95% 的信心相信 $p$ 是在这个区间内的。然后，继续抛硬币，直到这个区间“足够窄”（实际上，我更喜欢 $p \pm 0.025$ 或更窄的区间）。
但是，我不确定反复计算这个区间并在区间窄时停止是否在统计上有效。我的数学背景相当不错，但统计是我的弱点。
有人可以澄清这是否是一种有效的方法吗？ （此外，如果我在这里提交了一个 xy 问题，并且有更好的方法来确定我需要收集多少个样本才能获得一定宽度的置信区间，我也很乐意听到这个消息！）]]></description>
      <guid>https://stats.stackexchange.com/questions/659962/is-it-ok-to-determine-data-collection-stopping-with-confidence-interval-calcul</guid>
      <pubDate>Mon, 13 Jan 2025 15:21:47 GMT</pubDate>
    </item>
    <item>
      <title>解决这些问题的预期方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/659930/what-is-the-expected-method-of-solving-for-these-questions</link>
      <description><![CDATA[我刚刚参加了康奈尔机器学习预测试，但以下三个问题我没有答对。
基本概率
使用你对基本概率论的了解来回答以下问题。如果你需要复习这些主题中的任何一个，请随时在互联网上搜索参考资料和示例视频。
对于问题 1-3，你将使用以下概率及其各自的标签：



特征 1
特征 2
特征3
标签




0.27
0.50
0.33
蓝色


0.33
0.65
0.10
红色
&lt; /tr&gt;

0.25
0.30
0.35
黄色


0.10
0.10
0.85
紫色



您还将假设测试点具有以下形式的特征向量：
x = [特征 1、特征 2、特征 3]
如果存在，则每个特征值等于 1，如果不存在，则等于 0。例如，根据表格，27% 的带有蓝色标签的数据具有特征 1，问题 1 可以重新表述为：给定具有特征 1 和 3 但不具有特征 2 的数据，最可能的标签是什么？
问题
1.
特征向量为 x = [1, 0, 1] 的测试点的预测标签是什么？
（提示：对存在的特征使用概率链式法则。）
您的答案：紫色
正确答案：蓝色

2.
特征向量为 x = [0, 0, 0] 的测试点的预测标签是什么？
（提示：对存在的特征使用概率链式法则。）
您的答案：黄色
正确答案：无法根据给定的数据进行预测

3.
特征向量为 x = [1, 0, 0] 的测试点的预测标签是什么？
（提示：对存在的特征使用概率链式法则。）
您的答案：黄色
正确答案：红色
我尝试解决
我假设我必须根据特征是否存在将每个特征的概率相乘，然后为每个标签乘以这个概率，然后从该过程中返回最可能的标签。例如，对于第一个具有特征向量 $(1, 0, 1)$ 的问题，我将获得：
$$ P(red) = .33 \times (1 - .65) \times .10 $$
这显然不起作用，但我不确定这里的预期是什么。提示提到了概率方法，但我不确定如何在此处应用它。从预期的答案来看，它让我认为对于任何设置为 0 的特征，它应该在计算中被忽略，即只乘以设置为 1 的特征，例如对于向量 $(1, 0, 1)$:
$$ P(red) = .33 \times .10 $$
（这种思路似乎得到了 ChatGPT 的分析支持。）
结论
解决这些问题的预期方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659930/what-is-the-expected-method-of-solving-for-these-questions</guid>
      <pubDate>Sun, 12 Jan 2025 21:06:09 GMT</pubDate>
    </item>
    </channel>
</rss>