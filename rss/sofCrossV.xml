<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 22 Mar 2025 01:18:49 GMT</lastBuildDate>
    <item>
      <title>我应该如何在多级建模中选择随机效应和协方差结构？</title>
      <link>https://stats.stackexchange.com/questions/662964/how-should-i-select-random-effects-and-covariance-structures-in-multilevel-model</link>
      <description><![CDATA[我正在使用R中的NLME软件包构建多级模型，并想澄清选择随机效果及其协方差结构的适当步骤。
这是我目前的理解，我感谢任何更正或详细说明：
我考虑的步骤：
从简单的随机效应结构开始，例如，仅随机截距，最简单的协方差矩阵（身份矩阵）。
逐步添加随机斜率，并使用似然比测试（LRT）或AIC/BIC比较嵌套模型并评估是否合理。
比较不同的协方差结构：
身份（pdident） - 假定没有相关性和相等的方差。
对角线（PDDIAG） - 假定没有相关性，但允许不平等的方差。
可交换（PDCOMPYMM） - 假定恒定相关。
非结构化（PDSYM） - 允许完整的方差矩阵。]]></description>
      <guid>https://stats.stackexchange.com/questions/662964/how-should-i-select-random-effects-and-covariance-structures-in-multilevel-model</guid>
      <pubDate>Sat, 22 Mar 2025 01:17:34 GMT</pubDate>
    </item>
    <item>
      <title>模型类别在Adaboosting中的作用</title>
      <link>https://stats.stackexchange.com/questions/662959/the-role-of-class-of-models-in-adaboosting</link>
      <description><![CDATA[  adaboost的伪代码 
初始化：分配每个观察值（i）重量
 $ d_i^{（1）} = \ frac {1} {n} $ 。
 for  $ t = 1 $  to  $ t $ ：

使用由 $ d_i^{（t）} $ 。这会产生一个弱分类器 $ h_t（x）$ 。
计算加权错误：
 $ \ text {error} _t = \ sum_ {i = 1}^{n} d_i^{（t）} \，\ Mathbf {1} \ bigl（h_t（x_i）\ neq y__i \ bigr）。
选择系数：
 $ \ alpha_t = \ frac {1} {2} {2} \ ln \！\ bigl（\ frac {1  -  \ text {error} _t _t} _t} _t} {\ text {error}
更新权重：
 $ d_i^{（t+1）} 
  = \ frac {d_i^{（t）} \ exp \ bigl（ -  \ alpha_t \，y_i \，h_t（x_i）\ bigr）}
         {z_t}，$ 
其中 $ z_t $ 是一个归一化因素
 $ \ sum_ {i = 1}^{n} d_i^{（t+1）} =1。$  

  $ h（x）= \ text {sign} \ bigl（\ sum_ {t = 1}^t \ alpha_t \，h_t（x）\ bigr）。
模型类别（ $ f $ ）如何在提升中发挥作用？由于我的分类器也可能很弱，因为我可能有一个限制性 $ f $ （例如，仅查看线性分类器）。所以我对角色有点困惑 $ f $ 在提升中播放。]]></description>
      <guid>https://stats.stackexchange.com/questions/662959/the-role-of-class-of-models-in-adaboosting</guid>
      <pubDate>Fri, 21 Mar 2025 19:07:08 GMT</pubDate>
    </item>
    <item>
      <title>手动反向倾向得分重新加权与加权OLS回归之间的等效性</title>
      <link>https://stats.stackexchange.com/questions/662957/equivalence-between-manual-inverse-propensity-score-reweighting-and-a-weighted-o</link>
      <description><![CDATA[假设 $ y_i $ 是结果， $ d_i $ 是一种二进制处理， $ x_i $ 是covariate。将倾向分数表示为 $ p（x_i）= e [d_i | x_i] $ 。。
我们可以使用以下方式使用逆倾向评分来恢复平均治疗效果（ATE）：
 $$
ate = e \ left [\ frac {y_ {y} \ cdot d_i} {p（x__ {i}）} \ right]  -  e \ left [\ frac {y_ {y} {i} \ cdot（1- d_i）}
$$  
实际上，这通常是通过估计加权OLS回归来实现的：
 $$
y_i = \ alpha + \ beta d_i + \ varepsilon_it
$$ 
由 $ \ omega $ 其中 $ \ omega = 1/p（x_i）$ 用于处理的观察值和 $ \ omega = 1/（for for for for for for ome omega）
我有两个问题：

有人可以为为什么这两个程序产生相同的治疗效果提供正式论证吗？使用加权回归的定义的东西将非常有用。
两个程序都会产生相同的标准错误吗？要么正确吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/662957/equivalence-between-manual-inverse-propensity-score-reweighting-and-a-weighted-o</guid>
      <pubDate>Fri, 21 Mar 2025 18:38:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么term.plot（mod，什么=“ mu”）以gamlss为中心？</title>
      <link>https://stats.stackexchange.com/questions/662956/why-is-term-plotmod-what-mu-centered-around-0-in-gamlss</link>
      <description><![CDATA[我正在使用 family = nbi（）和建模 $ \ mu $ $  and  $ \ sigma $ “ Math-Container”&gt; $ X $ X $ x $ x $ x $ x $  $ \ mu $ 的真实数据生成过程 $ \ mu = \ exp（1 + 0.3x）$  term.plot（mod，what =; mu quot;）时，y轴值的中心为0，而不是0到3，正如我所期望的那样，基于转换示例代码
 库（gamlss）

set.seed（123）
N＆lt; -5000
x＆lt;  -  runif（n，0，10）
Mu＆lt;  -  Exp（1 + 0.3 * x）
Sigma＆lt;  -  0.5
y＆lt;  -  rnbi（n，mu = mu，sigma = sigma）

mod＆lt;  -  gamlss（y〜pb（x），sigma.formula = 〜pb（x），family = nbi（））

term.plot（mod，什么=; mu quot; mu quot;）＃为什么左右以0为中心？
摘要（mod）＃iThercept = 1
 
由于摘要（mod）给出 $ \ beta_0 = 1 $ ，我期望 term.plot（mod，what =; mu quot; mu qod;） display  $ f（x） class =“数学 - 容量”&gt; $ f（x）= 0.3x + 1 $ 包括截距。）相反，该范围似乎为-1.5至1.5。
  问题：

为什么term.plot（）将效果置于0左右而不是显示 $ f（x）= 0.3x $ 
直接？
 gamlss在内部中心平稳功能，如果是，我该如何正确解释结果？
]]></description>
      <guid>https://stats.stackexchange.com/questions/662956/why-is-term-plotmod-what-mu-centered-around-0-in-gamlss</guid>
      <pubDate>Fri, 21 Mar 2025 18:33:24 GMT</pubDate>
    </item>
    <item>
      <title>如何在面板数据回归中最好地添加横截面变量</title>
      <link>https://stats.stackexchange.com/questions/662954/how-to-best-add-a-cross-sectional-variable-in-panel-data-regression</link>
      <description><![CDATA[我想看看治疗如何影响某些结果。假设我有100个人和5个时期，所有个人中有一半接受治疗，一半是对照。该处理是在第2期进行的。
治疗效果可能取决于个人的异质特征，例如财富。但是我只能观察1。的财富。
 r 中的数据是这样的
  dt＆lt;  -  data.frame（frame（
  y = rnorm（500），
  id = rep（1：100，每个= 5），
  处理= rep（c（0，1），每个= 250），
  财富= rep（rnorm（100，平均= 100，sd = 100），每个= 5）
）
 
我知道要控制它，我可以只使用ID固定效果，但我也想在事件研究设置中直接具有其动态效果。我还可以看到这里是否有趋势。
了解初始财富如何影响治疗效果的最佳方法是什么？
非常感谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/662954/how-to-best-add-a-cross-sectional-variable-in-panel-data-regression</guid>
      <pubDate>Fri, 21 Mar 2025 18:30:02 GMT</pubDate>
    </item>
    <item>
      <title>在我的数据中搜索将其分成最大统计学上显着不同的组是否有效？</title>
      <link>https://stats.stackexchange.com/questions/662953/is-it-valid-to-search-for-a-threshold-in-my-data-that-splits-it-into-maximally-s</link>
      <description><![CDATA[我的数据给出了：
参与者，主动时间，得分
在其中“主动时间”是参与者在几秒钟内积极参加研究活动和“得分”的时间。是他们在活动中的总分。
我仅通过查看我的数据就注意到，在这项活动上花费更多时间的参与者似乎的分数较低。我想看看在我们的参与者分为两组的活跃时间上是否有最佳阈值 - 积极时间高于阈值及以下的参与者，其中两组之间的平均得分差异最大，两组之间的平均得分之间的平均得分差异是统计学意义的。  
因此，我进行了一个简单的搜索，更改阈值并计算两个人群的平均值和p值。每当p值大于0.05时，我都会拒绝该阈值。对于P＆Lt的所有门槛； 0.05，我选择了平均值最高差异的一个。我最终确实找到了最佳分裂，两组的n = 39（高于阈值）和n = 183（下图），因此参与者的数量不像一组为5或10，其余的则不像5或10。
但是，在这里有些困扰我 - 感觉就像我正在搜索我的数据以验证我的假设，并将其操纵直到做到。另一方面，显然可以将我的数据分为这两个组，并具有统计学意义。那么我在这里犯了任何分析错误吗？实际上，我可以声称“证据拒绝零假设”。感觉就像我测试了许多假设，并选择了我最喜欢的假设，这就是为什么我担心的原因。]]></description>
      <guid>https://stats.stackexchange.com/questions/662953/is-it-valid-to-search-for-a-threshold-in-my-data-that-splits-it-into-maximally-s</guid>
      <pubDate>Fri, 21 Mar 2025 18:29:43 GMT</pubDate>
    </item>
    <item>
      <title>什么时候应该将级别3变量添加到NLME多级模型中的2级随机效应中？</title>
      <link>https://stats.stackexchange.com/questions/662952/when-should-a-level-3-variable-be-added-to-a-level-2-random-effect-in-an-nlme-mu</link>
      <description><![CDATA[我正在使用R中的NLME软件包使用三级分层模型。我的数据结构如下：
级别1：个人观察（例如，学生）
级别2：小组（例如学校）
级别3：高级集群（例如，地区）
将级别3变量添加到2级随机效应会产生多重共线性或可识别性的问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/662952/when-should-a-level-3-variable-be-added-to-a-level-2-random-effect-in-an-nlme-mu</guid>
      <pubDate>Fri, 21 Mar 2025 18:25:33 GMT</pubDate>
    </item>
    <item>
      <title>标准化数据集以使其差异可比性？</title>
      <link>https://stats.stackexchange.com/questions/662951/normalizing-datasets-to-make-their-variance-comparable</link>
      <description><![CDATA[我正在努力处理各种不同的数据系列，每个数据系列都是数字列表。  我的一些系列范围从-1到1，有些从0.0001到0.0002，有些从200万到300万。  每个系列都标有几个标签之一。  我的最终目标是计算每个数据序列的方差度量，然后按标签平均在一起，以便我可以分辨出不同的标签对方差有什么影响（如果有）。
由于我的数据范围是如此多样化，所以我不能简单地计算标准偏差或中值绝对偏差，然后平均在一起。  到目前为止，我一直在使用stddev/Mean（变异系数，CV）来解决此问题。
不幸的是，对于我的某些数据集的范围非常接近0，CV变得非常大，因为平均值非常小。  这与我的平均简历度量混乱，使我质疑我在做什么的有效性。
作为对此的潜在解决方案，我正在考虑将所有数据序列归一化，并将它们归一化为0到100（通过将最小值转移到零，然后将所有点乘以100/最大值），然后仅计算标准偏差或中位数绝对偏差，然后平均这些值。。。。
我正在寻找理智检查这种方法是否有意义，或者是否还有其他统计工具我应该在这里部署。]]></description>
      <guid>https://stats.stackexchange.com/questions/662951/normalizing-datasets-to-make-their-variance-comparable</guid>
      <pubDate>Fri, 21 Mar 2025 18:20:52 GMT</pubDate>
    </item>
    <item>
      <title>R在R中的rm（）中的事后测试，数字和多个分类变量之间具有显着相互作用</title>
      <link>https://stats.stackexchange.com/questions/662955/post-hoc-test-in-r-for-lm-with-significant-interaction-between-numeric-and-mul</link>
      <description><![CDATA[我对两个特征之间的关系（特质1和特征2）之间的关系感兴趣，在组（a和b）和处理（C和T）之间有所不同。具体来说，我想知道特质1和特质2之间的关系在治疗之间以及组之间的每种治疗方法之间是否有所不同。因此，将c和t之间的a之间的性状关系，c和t之间的b进行比较，a和b之间的c和t之间的c和t之间的c。之间的t。
我的模型是 lm（trait1〜特征2：组：处理），因为我不在乎任何主要影响。
这告诉我三种相互作用是否显着，我能够获得四个组/治疗组合的斜率。我想知道是否有某种类似于Tukey测试的测试形式，然后告诉我哪些组彼此不同。我知道我能做的一件事是子集（例如 lm（trait1〜特征2：处理）    lm（trait1〜trait2：grout2：group2：group）每次治疗），但我想知道是否有更简单的方法。
事先感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/662955/post-hoc-test-in-r-for-lm-with-significant-interaction-between-numeric-and-mul</guid>
      <pubDate>Fri, 21 Mar 2025 18:00:09 GMT</pubDate>
    </item>
    <item>
      <title>在约束性因素分析中的单个负载在统计学上没有显着意义</title>
      <link>https://stats.stackexchange.com/questions/662950/a-single-loading-in-a-confimatory-factor-analysis-is-not-statistically-significa</link>
      <description><![CDATA[我对CFA和其他SEM拟合度进行了出色的心理测试测试。
其他项目也很棒，但是该量表的因素之一具有高于.05 的显着水平。
有没有解决心理测量结构的解决方案？我试图在明确的项目中添加协方差，但情况变得更糟
  &lt;img alt =“ enter apt =” enter Image Description在此处src =“]]></description>
      <guid>https://stats.stackexchange.com/questions/662950/a-single-loading-in-a-confimatory-factor-analysis-is-not-statistically-significa</guid>
      <pubDate>Fri, 21 Mar 2025 17:47:08 GMT</pubDate>
    </item>
    <item>
      <title>R [闭合]中的一般动态主成分</title>
      <link>https://stats.stackexchange.com/questions/662949/general-dynamic-principal-components-in-r</link>
      <description><![CDATA[我正在尝试使用 gdppc软件包。我正在努力计算来自加载和输入系列的软件包提供的PC1。我想构建一个代表每个组件系列对PC1变化的贡献的图表。有人知道该怎么做吗？为了更加清楚：我有Betea和Alpha矩阵和输入系列，但我无法获得程序为PC1提供的结果（函数的F输出）]]></description>
      <guid>https://stats.stackexchange.com/questions/662949/general-dynamic-principal-components-in-r</guid>
      <pubDate>Fri, 21 Mar 2025 17:33:23 GMT</pubDate>
    </item>
    <item>
      <title>统计分布的历史</title>
      <link>https://stats.stackexchange.com/questions/662946/history-of-statistical-distributions</link>
      <description><![CDATA[我正在寻找有关统计分布的历史，其起源，作者和背景的书籍或藏书的收藏。有人知道这样的资源吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662946/history-of-statistical-distributions</guid>
      <pubDate>Fri, 21 Mar 2025 16:31:23 GMT</pubDate>
    </item>
    <item>
      <title>解释coxme在r中的结果</title>
      <link>https://stats.stackexchange.com/questions/662937/interpreting-results-of-coxme-in-r</link>
      <description><![CDATA[ **编辑** 
如此好点！我不知道为什么我将性作为随机效果而不是固定效果！代码已更新以反映更改。也许我应该将性作为互动术语，因为它现在表现出重要性？
我是一个相对较新的生存分析用户，只是对自己解释我的结果有一些疑问。我将生存和暴露与早期事件进行比较。我正在基于先前的研究使用代码，以查看类似的变量。我的代码如下：
  surv_object2＆lt;  -  surv（time = fu_time，event = fu_status，data = efulte_survival）

model3＆lt;  -  coxme（surv_object2〜CAT3 +性别 +
                          （1 | mom_id）， 
                        数据=成人_Survival）

摘要（模型3）

cox.zph（model3）
 
 结果如下： 
 混合效果coxme模型
 公式：surv_object2〜CAT3 +性 +（1 | MOM_ID） 
    数据：成人_SURVIVAL 

  事件，n = 90，170

随机效果：
                  chisq df p aic bic
集成Loglik 20.32 3.00 1.456E-04 14.32 6.82
 惩罚Loglik 68.32 22.15 1.332E -06 24.01 -31.37

固定效果：
                        COEF EXP（COEF）SE（COEF）Z P
CAT3NO已知暴露0.5852 1.7953 0.2495 2.35 0.01901
SEXM 0.7381 2.0920 0.2402 3.07 0.00212
       chisq df p
CAT3 0.281 1 0.60
性别2.451 1 0.12
全球2.924 2 0.23
 
据我了解，这意味着那些没有已知暴露的人与暴露年龄相比，在给定年龄的死亡风险增加了1.8倍。基本上，接触是降低风险的。我只是在努力了解一致性值在哪里，以及0.23的全局p值对模型的重要性意味着什么。此外，是否有任何可以在此输出中获得置信区间？
这是我第一次使用coxme模型而不是coxph，所以我只想确保我正确解释结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/662937/interpreting-results-of-coxme-in-r</guid>
      <pubDate>Fri, 21 Mar 2025 14:00:15 GMT</pubDate>
    </item>
    <item>
      <title>泰勒系列的使用近似于未定义的平均值</title>
      <link>https://stats.stackexchange.com/questions/662929/use-of-taylor-series-to-approximate-undefined-mean</link>
      <description><![CDATA[我需要您的帮助才能理解适合使用泰勒系列时的信息。
说我有2个正态分布变量（x，y）。我知道他们的评分（x/y）将遵循 cauchy-distribution  [https://en.wikipedia.org/wiki/wiki/cauchy_distribution]，它具有   ne new new sean Mean 。因此，我不应该计算此分布的平均值。
同时，我可以使用 taylor序列扩展到近似G（x，x，y）= x/y函数的平均值（来源： https://www.stat.rice.edu/~dobelman/notes_papers/math/taylorappdeltamethod.pdf ）
我不确定如何解决这一明显的矛盾。我认为，即使可以应用Taylor系列，如果某些条件不满足，它可能会返回不可靠的结果（如果Y的平均值接近0，并且与平均值相比，Y的差异很大，可能会成为一个坏主意）。
我在这里错过了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662929/use-of-taylor-series-to-approximate-undefined-mean</guid>
      <pubDate>Fri, 21 Mar 2025 09:49:03 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归的粗略比率与优势比的缺点？</title>
      <link>https://stats.stackexchange.com/questions/662917/drawbacks-of-crude-odds-ratio-vs-odds-ratio-from-logistic-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662917/drawbacks-of-crude-odds-ratio-vs-odds-ratio-from-logistic-regression</guid>
      <pubDate>Fri, 21 Mar 2025 02:28:34 GMT</pubDate>
    </item>
    </channel>
</rss>