<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 06 Aug 2024 18:21:50 GMT</lastBuildDate>
    <item>
      <title>目标值非常接近 0 的损失函数</title>
      <link>https://stats.stackexchange.com/questions/652391/loss-functions-for-target-values-very-close-to-0</link>
      <description><![CDATA[我目前正在构建一个回归 MLP 模型来预测 [0,3] 之间的目标变量。目标变量的分布大部分为正态分布，略有左偏。我的模型在预测值 &gt;.1 时非常出色，几乎 100% 的预测都在 5% 的可容忍范围内，但对于值 &lt;.1，模型会突然下降到 ~60% 在 5% 以内。我尝试对数据进行加法移位，例如添加 1，这样我的新范围就是 [1,4]，模型能够非常好地拟合，但当我转换回原始比例时，我陷入了性能不佳的困境。我尝试使用 MAPE、SMAPE、MSE、MAE、Huber、MSLE，但在低值区域没有重大改进。为什么 MLP 很难预测非常小的值，我可以对我的架构/损失函数/数据进行哪些潜在更改以正确拟合原始比例？]]></description>
      <guid>https://stats.stackexchange.com/questions/652391/loss-functions-for-target-values-very-close-to-0</guid>
      <pubDate>Tue, 06 Aug 2024 18:13:02 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在保持标准差的同时对数据进行标准化？</title>
      <link>https://stats.stackexchange.com/questions/652390/is-there-any-way-to-normalize-data-while-keeping-standard-deviation</link>
      <description><![CDATA[我有两个实验组，每个实验组由 3 个独立实验组成。我想分析它们在给定特征上的差异，但我想通过标准化结果但保持标准差来实现。有什么办法吗？或者可能是我没有想到的另一种解决方案。
让我举个例子来说明。假设我的 A 组和 B 组显示以下结果：
组 A：100、130、135
组 B：84、100、110
（这里我以这种格式呈现结果：组 X：实验 1、实验 2、实验 3）。
当我运行非配对 t 检验时，A 组和 B 组之间没有显着差异。我当时想做一个标准化，这样我就可以量化每个组之间的倍数变化。此外，我认为这种标准化是合适的，因为试剂批次会导致一些实验变异。因此，我认为标准化如下：
组 A：1、1、1
组 B：0.84、0.77、0.81
在这里，我只是为每个实验划分了组 A/组 A 和组 B/组 A。
问题是：我不知道这是否是正确的做法。此外，我想保留组 A 的标准差，但每个实验之间没有差异，因此也没有 SD。
有什么办法可以解决这个问题吗？有什么方法可以解决或帮助我解决这个问题吗？
提前致谢！
附注：我已经使用 Shapiro-Wilk 检验对我的数据集进行了正态性测试，A 组和 B 组都是正态的，所以我要做非配对 t 检验。]]></description>
      <guid>https://stats.stackexchange.com/questions/652390/is-there-any-way-to-normalize-data-while-keeping-standard-deviation</guid>
      <pubDate>Tue, 06 Aug 2024 17:19:36 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 符号秩检验与符号检验假设</title>
      <link>https://stats.stackexchange.com/questions/652389/wilcoxon-signed-rank-test-vs-sign-test-assupmtions</link>
      <description><![CDATA[我有一组离散（李克特）配对数据，其中有许多 0 差异/平局（之后 - 之前），差异的分布不对称。 Wilcoxon 符号秩检验有效吗？或者符号检验是更安全的选择？
符号检验必须检查哪些假设？
如果符号检验也无效，那么在这种情况下哪种检验有效？]]></description>
      <guid>https://stats.stackexchange.com/questions/652389/wilcoxon-signed-rank-test-vs-sign-test-assupmtions</guid>
      <pubDate>Tue, 06 Aug 2024 17:16:02 GMT</pubDate>
    </item>
    <item>
      <title>回归树的提升——算法解释</title>
      <link>https://stats.stackexchange.com/questions/652386/boosting-for-regression-trees-explanation-of-the-algorithm</link>
      <description><![CDATA[我正在阅读 James 等人 (2013) 所著的《统计学习导论》一书中的回归树提升算法 - 第 322 页。我真的很难一步一步理解这个算法。
“设置 $\hat{f}(x)=0$ 和 $r_{i} = y_{i}$”是什么意思？据我所知，$\hat{f}(x)$ 是给定 $x$ 值的预测因子。但是使用什么模型？回归树还是线性回归？如何使后者等于 0？我不理解第一步，因此也不理解接下来的步骤。
有人可以指导我完成这个过程的每个步骤，并为每个步骤提供简要说明吗？或者，如果您可以推荐此信息的其他来源（任何阅读材料），那将会很有帮助。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652386/boosting-for-regression-trees-explanation-of-the-algorithm</guid>
      <pubDate>Tue, 06 Aug 2024 16:10:09 GMT</pubDate>
    </item>
    <item>
      <title>方程数多于解的线性方程组</title>
      <link>https://stats.stackexchange.com/questions/652385/system-of-linear-equations-with-more-equations-than-solutions</link>
      <description><![CDATA[如何确定方程数多于解数的线性方程组的解？
例如，我有产品 A、B 和 C，以及同事数 D。每天 n_D 个同事会生产 n_A 份产品 A、n_B 份产品 B 和 n_C 份产品 C。每件产品的生产需要时间 t_A、t_B 和 t_C。一天的时间是 t_D。
因此，搜索的方程式是 n_A * t_A + n_B * t_B + n_C * t_C = n_D * t_D。
我有数千行，其中包含 n_A、n_B、n_C 和 n_D 的条目。我如何计算 t_A...t_D。如果我只有三行，我就可以精确地解方程式。如果有更多，我应该能够以某种方式计算每个方程式的平均值和标准差，对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652385/system-of-linear-equations-with-more-equations-than-solutions</guid>
      <pubDate>Tue, 06 Aug 2024 15:51:51 GMT</pubDate>
    </item>
    <item>
      <title>调整样本标准差后的分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652384/distribution-after-adjusting-sample-standard-deviation</link>
      <description><![CDATA[假设您对每个观察值重复测量连续值 3 次，并且您有 10000 个不同的观察值。对于每个观察值，您确定平均值和样本标准差 (std)
由于您只有 3 次重复测量，因此确定的标准差不是太强（请原谅我缺乏适当的语言）。因此，我们可以通过对平均值和标准差进行建模来调整标准差。例如，我们在平均值和标准差之间拟合一条曲线。然后，对于每个观察值，我们根据曲线调整它们的标准差。
在我看来，t 分布是测量值较少的最佳代表性分布。调整标准差后，t 分布仍然是最佳代表性分布吗？或者我们应该使用正态分布？
此外，从一开始就调整标准差可以吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652384/distribution-after-adjusting-sample-standard-deviation</guid>
      <pubDate>Tue, 06 Aug 2024 15:49:07 GMT</pubDate>
    </item>
    <item>
      <title>在多变量数据集中检测随时间变化的模式</title>
      <link>https://stats.stackexchange.com/questions/652383/detect-paterns-over-time-in-multivariate-dataset</link>
      <description><![CDATA[我有一个数据集，表示某家商店几天的库存情况。每天，我都会按小时盘点商店中的物品。有些产品已售出，而其他产品可能会暂时消失（例如，移至后店）。因此，库存中的物品数量每小时都在波动。每件物品还具有多个属性，例如其位置、检测质量等。
示例数据集：

我有表明实际库存的真实数据。我的主要目标是：
预测库存：每个小时，我都想预测一个物体是否在库存中，并使这个预测的库存与实际库存相比尽可能准确。
对物体进行分类：根据它们的行为，我想对物体进行分类。
挑战：
模式检测和预测：

我观察到 24 小时内库存水平的重复模式。
我考虑训练一个 LSTM 来预测未来的行为，但这很复杂，因为：
由于数千个物体之间行为差异很大，模型很难学习。
每个时间步骤中的物体数量并不固定。
由于大量的物体，为每个物体训练一个单独的 LSTM 是不可行的对象。

行为分类：

我尝试使用 K-means 和类似的聚类方法，但这些方法只能对特定时间的对象进行分类，这对我的时间数据没有帮助。
我需要根据对象在 24 小时内的行为对其进行分类。

问题：
考虑到对象的多变性和大量性，我如何推广 LSTM 或任何其他方法以有效地从数据中学习？
根据对象在 24 小时内的行为对其进行分类的合适方法是什么？
如能提供任何有关如何解决这些问题的指导或建议，我们将不胜感激。提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/652383/detect-paterns-over-time-in-multivariate-dataset</guid>
      <pubDate>Tue, 06 Aug 2024 15:33:53 GMT</pubDate>
    </item>
    <item>
      <title>二项分布中的高 SE [重复]</title>
      <link>https://stats.stackexchange.com/questions/652382/high-se-in-binomial-distribution</link>
      <description><![CDATA[这可能是一个愚蠢的问题，但我正在研究与不同治疗相关的家蝇死亡率，并试图使用二项分布进行方差分析来比较这些治疗方法。
问题是，我有一种治疗方法可以杀死我重复中的所有苍蝇（我的所有数据都是 1），当我运行分析时，它显示了一个高标准错误（并将我的治疗方法与所有其他治疗方法分组）。
我认为我做错了什么，因为我的逻辑告诉我，在重复过程中没有变化，标准错误应该很低（同样，我执行了 ANOVA 转换数据，其中该治疗方法的 SE 很低）。
这是我的脚本：
library(lme4)
y &lt;- cbind(binomial$muertas, binomial$vivas)
m1 &lt;- glm(y ~ cepa, data = binomial, family = binomial(link = logit))
summary(m1)

我的控制台显示以下内容（我删除了无关紧要的处理）：
系数：
估计标准误差 z 值 Pr(&gt;|z|)

（截距）0.4520 0.2162 2.090 0.0366

cepa1740 18.6846 914.5296 0.020 0.9837

（二项式系列的分散参数取为 1）

如果您需要更多信息，请告诉我，我对统计学了解不多]]></description>
      <guid>https://stats.stackexchange.com/questions/652382/high-se-in-binomial-distribution</guid>
      <pubDate>Tue, 06 Aug 2024 14:39:12 GMT</pubDate>
    </item>
    <item>
      <title>通过优化拟合优度参数设置数据过滤器[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652380/setting-data-filters-by-optimizing-on-goodness-of-fit-parameter</link>
      <description><![CDATA[我不是数学家、统计学家或数据科学家，但我是一个试图将时间序列分析应用到我的科学领域的人。所以请原谅我的问题中的任何无知：D
数据和统计模型
我有一个性能数据的时间序列，其中包含季节性成分、大量噪音和我们想要提取的趋势信号。趋势信号通常被认为是线性的，尽管众所周知这通常是一种简化。在我的领域，已经测试了各种统计模型来提取线性趋势信号。最常用的方法之一是同比 (YoY) 方法，它本质上考虑了数据的季节性。
过滤的必要性
为了减少噪音以帮助确定潜在的趋势信号，可能需要应用各种数据过滤器。在这个研究领域，还没有一种既定的方法来设置这些参数，到目前为止，这都取决于分析师的判断，尽管过滤可能会显著影响最终的估计值。所需的过滤器还取决于获取性能数据的系统；不同的系统有不同的噪声源等。过滤通常是在 5 分钟、15 分钟或每小时分辨率的原始数据上进行的，然后再汇总为每日、每周或每月的值，然后对其应用 YoY。
我的方法
目前，我正在研究一种通过最小化/最大化可以从数据集中提取的一些参数来设置过滤器参数的方法；与目前最先进的方法相比，这种方法可能更具可重复性、自动化和独立于分析师。这构成了一个多维优化问题，我借助贝叶斯优化解决了这个问题。
问题
我现在试图找出选择应用于数据的过滤器和过滤器参数的最佳优化参数是什么。由于历史原因，我首先最小化置信区间（通过引导法在 YoY 方法中确定）。即算法搜索给出最低置信区间的过滤器/过滤器值组合，并将此过滤器组合的趋势估计作为最佳估计。然而，置信区间不是准确度的度量，而准确度是我的主要目标。相反，我现在正在考虑将以下内容作为替代优化参数：

R 平方（计算 YoY 与过滤数据相比的最佳趋势线）- 在我看来，与作为精度度量的置信区间相比，R 平方是拟合精度的更直接度量。
调整后的 R 平方 - 应该比 R 平方有所改进，因为它会惩罚过于激进的过滤，这会导致 YoY 方法只留下很少的数据点，从而可以防止过度拟合数据子集。
赤池信息准则 - 我的理解是，这应该能够给出给定数据集的不同统计模型的相对质量，我认为这相当于评估相同数据的不同过滤变体的相同统计模型的相对质量（？）。使用 AICc 而不是 AIC 似乎适合惩罚激进的过滤。
某种形式的交叉验证。虽然我相信这可能是合适的，但我想知道这对这个问题来说是否太复杂了（？）。

所以，我当然可以测试所有这些，看看哪个看起来效果最好。但在我开始之前，我想从任何真正精通数据科学和统计学的人那里得到关于以下问题的意见：

从理论或根本原因来看，所提出的任何参数对于当前的问题来说是否更好或更坏？为什么？
与更简单的参数相比，使用或不使用交叉验证的理由是什么？
有没有我还没有考虑过的更好的参数？
有人知道文献中与我的问题类似的问题吗？我可以从中学习吗？非常感谢能提供具体论文的参考。

如果您需要更多信息来了解我的问题和/或解答我的问题，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/652380/setting-data-filters-by-optimizing-on-goodness-of-fit-parameter</guid>
      <pubDate>Tue, 06 Aug 2024 13:00:29 GMT</pubDate>
    </item>
    <item>
      <title>SLOPE 与 Benjamini-Hochberg 程序之间的联系</title>
      <link>https://stats.stackexchange.com/questions/652379/the-link-between-slope-and-the-benjamini-hochberg-procedure</link>
      <description><![CDATA[假设我们正在执行 $m$ 测试，该测试生成 $m$ 个 p 值 $p_1 \leq \ldots \leq p_m$（按索引排序）。 BH 程序如下：

对于给定的 $\alpha$（所需的 FDR 水平），找到最大的 $k$，使得 $p_k \leq \frac{k}{m}\alpha$。
对所有 $i\leq k$，拒绝零假设 $H_i$。

现在，我已经阅读了一些关于基于此的 Sorted L-One Penalized Estimation (SLOPE) 模型，但我很难看出确切的联系。在 SLOPE 论文 中，BH 程序描述如下（并且该公式用于推导 SLOPE 惩罚序列）：
对于回归模型 $y = X\beta + z,$，其中 $z \sim N(0,\sigma^2)$ 和正交矩阵 $X^TX = I$，将 $\tilde{y} = X^Ty$ 的条目排序为 $|y|_{(1)} \geq \ldots \geq |y|_{(m)}$ 和拒绝所有假设 $H_i$ 其中 $i\leq k_\text{BH}$ 其中
$$k_\text{BH} = \max\left\{k:
\frac{|\tilde{y}|_{(k)}}{\sigma} \geq \Phi^{(-1)}\left(1-\frac{k\alpha}{2m}\right)\right\}.$$
现在，我想知道这两者之间有什么联系以及分位数是如何使用的。我猜想这与我们在 SLOPE 中使用 $y$ 而不是 p 值有关，我们需要以某种方式将其转换为与 p 值比较相同的比例。]]></description>
      <guid>https://stats.stackexchange.com/questions/652379/the-link-between-slope-and-the-benjamini-hochberg-procedure</guid>
      <pubDate>Tue, 06 Aug 2024 12:44:45 GMT</pubDate>
    </item>
    <item>
      <title>这是关于线性回归的[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652378/this-is-on-linear-regression</link>
      <description><![CDATA[如果我计算 yt，得到预测值的负数答案 (-1.23)，而使用多项式回归变换 x 得到的观察值为 (2.34)。我可以假设它为零，因为它很接近吗？使用 SPSS 进行计算。]]></description>
      <guid>https://stats.stackexchange.com/questions/652378/this-is-on-linear-regression</guid>
      <pubDate>Tue, 06 Aug 2024 12:41:51 GMT</pubDate>
    </item>
    <item>
      <title>采用梯度下降和平方损失的最大似然估计</title>
      <link>https://stats.stackexchange.com/questions/652377/maximum-likelihood-estimation-with-gradient-descent-and-squarred-loss</link>
      <description><![CDATA[我的目标是使用梯度下降法学习单变量高斯分布的参数 $\mu$ 和 $\sigma$，通过从头推导所有公式来验证我对算法的理解。此外，我尝试使用平方损失代替对数似然来查看该概念是否有效（即使不如对数似然本身那么理想）。然而，根据经验评估，该概念不起作用，甚至给出一个简单的例子。这表明我在思考本例中的 GD 时犯了一些微不足道的错误。您能否验证/纠正我对下面介绍的算法的理解？
让 $x_1 \in R$ 成为特征，让 $y_1 \in R$ 成为目标。
我们使用单变量高斯分布$f(x, \mu, \sigma)$来模拟某个数据分布过程。目标是学习参数$\mu$和$\sigma$。此外，让$\eta &gt; 0$ 为学习率。

初始化随机 $\mu$ 和 $\sigma$。
$\hat{y}$ = $(y - \hat{y})^2$
$\nabla_{\mu} = 2(y - \hat{y}) * \frac{(x - \mu)exp(- \frac{(x-\mu)^2}{2\sigma^2})}{\sigma^2 \sqrt{2\pi \sigma^2}}$
$\nabla_{\sigma} = 2(y - \hat{y}) * (\frac{(x - \mu)^2exp(- \frac{(x-\mu)^2}{2\sigma^2})}{\sigma^3 \sqrt{2\pi \sigma^2}} - \frac{\sigma exp(- \frac{(x-\mu)^2}{2\sigma^2}))}{\sigma^2 \sqrt{2 \pi \sigma^2}})$
$\mu = \mu - \eta * \nabla_{\mu}$
$\sigma = \sigma - \eta * \nabla_{\sigma}$

该过程持续到收敛。这不是学习参数 $\mu$ 和 $\sigma$ 的最优方法 - 我很清楚这一点 - 但这是我得出的应该有效的基线。除非我犯了一些微不足道的错误，表明我对算法的某些元素缺乏理解。第 3 行和第 4 行基于链式法则 - 我认为我在这里犯了一个错误。但是，偏导数是正确的，所以错误一定出在链式法则本身的应用中。我可以请你验证一下算法吗？我正在努力巩固我对基于 SGD 的学习的理解，这个错误让我无法继续下去。非常感谢你的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/652377/maximum-likelihood-estimation-with-gradient-descent-and-squarred-loss</guid>
      <pubDate>Tue, 06 Aug 2024 12:41:14 GMT</pubDate>
    </item>
    <item>
      <title>方差分析的序贯概率比检验</title>
      <link>https://stats.stackexchange.com/questions/652374/sequential-probability-ratio-test-of-anova</link>
      <description><![CDATA[我正在运行一个连续实验，该实验由三个治疗组 60 个单位组成，因此每个组有 20 个单位。我们可以假设在每个组中，每个单位记录的值呈正态分布。
每个单位都会随着时间的推移而“增长”，我希望检测是否有证据表明每个组的平均值不同。我想在实验的每个小时都进行某种方差分析。
以下是部分数据的样子：

我研究过序贯概率比检验 (SPRT) 背后的理论，但我认为经典 SPRT 与我的设置有几个不同之处：

SPRT 假设新的观察结果（在新的单元上）会随着时间的推移而出现，而我随着时间的推移会观察相同的单元
SPRT 假设我们正在比较两个简单的假设，而我只想拒绝相等的零假设意味着

我尝试绘制方差分析的 p 值随时间的变化（它会减小），以及全线性模型与仅具有截距的模型随时间的变化的对数似然比（它要么保持在 0 左右平稳，要么无限增长）。
我读过以下论文：

序贯方差分析：提高假设检验的效率
最大化序贯概率比检验用于药物和疫苗安全监测

但似乎没有一个适用于我的情况。
有人能告诉我进行这个连续测试的正确方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652374/sequential-probability-ratio-test-of-anova</guid>
      <pubDate>Tue, 06 Aug 2024 11:43:11 GMT</pubDate>
    </item>
    <item>
      <title>硕士论文回归分析添加了虚拟/控制变量，导致独立变量不显著，我该如何处理？请帮忙 :)</title>
      <link>https://stats.stackexchange.com/questions/652373/masters-thesis-regression-with-dummy-control-variables-added-leading-to-insignif</link>
      <description><![CDATA[我的论文需要做一些修改。其中之一是添加虚拟变量和控制变量，因为我也在研究人口统计数据。所以我添加了年龄、性别和教育。但是，我的独立变量 A 变得不重要。
在检查虚拟变量和独立变量后，仅使用独立变量重新进行回归是否有意义？这里的最佳做法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652373/masters-thesis-regression-with-dummy-control-variables-added-leading-to-insignif</guid>
      <pubDate>Tue, 06 Aug 2024 11:41:51 GMT</pubDate>
    </item>
    <item>
      <title>将梯度提升树应用于标签的线性组合</title>
      <link>https://stats.stackexchange.com/questions/652357/applying-gradient-boosted-trees-to-a-linear-combination-of-labels</link>
      <description><![CDATA[给定一组特征$X$和三组标签$y_1, y_2$和$y_1+y_2$，我们在训练数据上拟合 3 个梯度提升回归器，得到函数$f_1, f_2$和$f_3$。$f_1(X)+f_2(X) = f_3(X)$是否成立，或者等式是否在非常小的误差下成立？由于 GBM 将标签值分解为更小的值，并且更简单的树会预测每个部分，然后最终结果是这些较小部分的预测总和，因此人们可以预期这种等式可能普遍成立。 （但当然这个论点没有提供任何证据。）
另一种重新表述问题的实用方法是，假设模型 $f_1$ 和 $f_2$ 是非常好模型，可以很好地推广到测试集，这是否意味着 $f_3$ 也应该是一个好模型？是否有可能得到 $f_1$ 和 $f_2$ 的好模型，但 $f_3$ 的模型却很糟糕，不能很好地推广？]]></description>
      <guid>https://stats.stackexchange.com/questions/652357/applying-gradient-boosted-trees-to-a-linear-combination-of-labels</guid>
      <pubDate>Mon, 05 Aug 2024 20:06:43 GMT</pubDate>
    </item>
    </channel>
</rss>