<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 07 Apr 2024 18:15:47 GMT</lastBuildDate>
    <item>
      <title>附加到原始样本的子样本的样本平均值</title>
      <link>https://stats.stackexchange.com/questions/644517/sample-mean-of-subsample-appended-to-original-sample</link>
      <description><![CDATA[从 $SRSWOR(n)$ 中提取 $N$ 个单位，一个 $SRSWOR(n_1)$ 子样本已抽取
并添加到原始样本中。显示基于 $(n + n_1)$ 单位的样本平均值
是总体均值的无偏估计量。获取估计量的方差。
将此与基于开始时绘制的 $n$ 单位的估计器进行比较。
任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/644517/sample-mean-of-subsample-appended-to-original-sample</guid>
      <pubDate>Sun, 07 Apr 2024 17:57:16 GMT</pubDate>
    </item>
    <item>
      <title>2x2 研究意味着有 4 个组还是 2 个组？</title>
      <link>https://stats.stackexchange.com/questions/644516/does-a-2x2-study-mean-there-are-4-groups-or-2</link>
      <description><![CDATA[我的书房是 2x2 设计。
有 2 个 IV：
IV1 = 性别（男/女）；
IV2 = 对照组/实验组。
这是否意味着我有 2 个组，因此将使用独立的 T 检验，或者我有 4 个组，因此将使用单向独立方差分析？或者，因为有多个 IV，这是否会导致阶乘独立测量方差分析？
非常感谢任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/644516/does-a-2x2-study-mean-there-are-4-groups-or-2</guid>
      <pubDate>Sun, 07 Apr 2024 17:44:48 GMT</pubDate>
    </item>
    <item>
      <title>相关后验的 MCMC</title>
      <link>https://stats.stackexchange.com/questions/644515/mcmc-for-correlated-posterior</link>
      <description><![CDATA[我正在使用 MCMC（DREAM 算法）模拟（看起来）高度相关的后验分布的后验。
我的设置是有 7 个参数，其中 x1/x3 和 x2/x4 高度相关，这是物理逻辑的。
但是，在运行过程中，x3 或 x4 会向下边界推动，即向零推动。但是，我不能允许负值，因为这在物理上是不可能的，并且评估会失败。所以，我认为问题是算法性质的。
附上参数散点图。在这里，x4 总是推到不切实际的低值。
谁能给我一个提示，如何防止 MCMC 算法的这种行为？
重新参数化是一种选择吗？如何做到这一点？
非常感谢！

]]></description>
      <guid>https://stats.stackexchange.com/questions/644515/mcmc-for-correlated-posterior</guid>
      <pubDate>Sun, 07 Apr 2024 17:42:45 GMT</pubDate>
    </item>
    <item>
      <title>Casella 和 Berger 中估计量的方差</title>
      <link>https://stats.stackexchange.com/questions/644513/variance-of-estimator-in-casella-and-berger</link>
      <description><![CDATA[嗨，我正在尝试阅读卡塞拉和伯杰的作品。
在第 345 页的示例 7.3.21 中，他们考虑分布族 Uniform($\theta$, $\ theta +1$）并提出基于单个观察的 theta 估计量。他们声称很容易看出估计器 $X - \frac12 + \sin(2\pi X) / (2\pi)$ 的方差为 0.71 (重点是，这小于明显估计量的方差 $X- \frac12$)。
但是，当我进行计算时，我似乎无法得到这一点。
\begin{align}
Var_\theta(X - \frac12 + \sin(2\pi X) / (2\pi))
&amp;= \int_\theta^{\theta+1} (x - \frac12 + \sin(2\pi x) / (2\pi) -\theta)^2 dx \\
&amp;= (3 + 2 π^2 - 12 \cos(2 π \theta))/(24 π^2) \\
&amp;\大约 0.0959985 - 0.0506606 \cos(2\pi \theta)
\end{对齐}
我错过了一些非常简单的事情吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644513/variance-of-estimator-in-casella-and-berger</guid>
      <pubDate>Sun, 07 Apr 2024 17:25:01 GMT</pubDate>
    </item>
    <item>
      <title>因变量应接受多小的变异系数？它如何影响线性回归？</title>
      <link>https://stats.stackexchange.com/questions/644510/how-small-coefficient-of-variation-should-be-accepted-for-dependent-variable-and</link>
      <description><![CDATA[我想知道如果 $Y$ 变量的变异系数很小，线性回归模型会发生什么。另外，什么被认为是“简历太小”？最低接受阈值是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/644510/how-small-coefficient-of-variation-should-be-accepted-for-dependent-variable-and</guid>
      <pubDate>Sun, 07 Apr 2024 16:39:39 GMT</pubDate>
    </item>
    <item>
      <title>电磁约束下优化几何形状的最佳优化方法</title>
      <link>https://stats.stackexchange.com/questions/644508/best-optimization-method-for-optimizing-geometry-under-electromagnetic-constrain</link>
      <description><![CDATA[我正在为我的项目解决优化问题。
我基本上有一个由 25 个参数表征的形状。在电磁学中，可以通过两次FDTD模拟（伴随法）来获得梯度图。每次模拟大约需要20秒。
然后用梯度图计算参数的梯度。不幸的是，每个参数大约需要 6 秒。没有办法改善这一点。
该区域是高度非凸的。我目前正在使用 LBFGS，但遇到了局部最小值问题。
我首先想知道，LBFGS 是最好的方法吗？如果没有，我可以用什么方法代替。有没有什么方法可以通过组合方法来提高优化效果。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/644508/best-optimization-method-for-optimizing-geometry-under-electromagnetic-constrain</guid>
      <pubDate>Sun, 07 Apr 2024 16:16:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么在测试测量不变性时，标量不变性模型的自由度比公制模型的自由度小？</title>
      <link>https://stats.stackexchange.com/questions/644504/why-do-i-get-smaller-degrees-of-freedom-for-the-scalar-invariance-model-than-the</link>
      <description><![CDATA[我正在尝试使用 CFA 测试来测试双因素模型中的测量不变性。我有 23 个二进制问题，编码为“正确”和“不正确”我的数据中有 3 个不同的组。每组的样本量约为 200 个。
为了测试测量不变性，我遵循了 Van de Shoot 等人的方法。 (2012) 逐步比较渐进约束模型的过程。我已经估计了配置模型、公制模型和标量模型。检验统计量、拟合指数和模型结果看起来都很好且合理。然而，当我估计标量模型时，结果给出的自由度比度量模型更小。
这有什么可能的原因吗？尽管我很仔细地寻找，但我在互联网上找不到任何东西。有人可以帮助我找到原因或帮助我找到参考资料以更好地理解吗？
这是我运行的代码。
### 双因素配置模型###

model_mck_bifactor_con_2 &lt;- &#39;MCK =~ Q1+Q2A+Q3B+Q3C+Q5+Q6+Q8A+Q8B+Q8C+Q10+Q12B+Q13A+Q13B+Q13C+Q17A+Q18B+Q19A+Q19B+Q19C+Q19D+Q20A+ Q22+Q23
Q8=~Q8A+Q8B+Q8C； Q13=~Q13A+Q13B+Q13C； Q19=~Q19A+Q19B+Q19C+Q19D；
MCK~~0*Q8; MCK~~0*Q13; MCK~~0*Q19;
Q8~~0*Q13; Q8~~0*Q19; Q13~~0*Q19;
Q3B～Q19A+Q19B+Q19C+Q19D； Q3C～Q19A+Q19B+Q19C+Q19D； Q3B ～ Q3C&#39;
### Q3 和 Q19 理论上是相关的。 ###

cfa.configural.mck.bifactor_2 &lt;- cfa(model_mck_bifactor_con_2, data = data_mck, 估计器 = &quot;WLSMV&quot;,ordered=T, group = &quot;COUNTRY&quot;,
                                     缺失=“成对”，参数化=“增量”）

### 公制模型###
cfa.metric.mck.bifactor &lt;- cfa(model_mck_bifactor_con_2，data = data_mck，估计器 =“WLSMV”，ordered=T，group =“COUNTRY”，missing=“pairwise”，
  参数化=“delta”，group.equal=“载荷”）
摘要（cfa.metric.mck.bifactor，fit.measures = TRUE，标准化 = TRUE）

### 标量模型 ###
cfa.scalar.mck.bifactor &lt;- cfa(model_mck_bifactor_con_2，data = data_mck，估计器 =“WLSMV”，ordered=T，group =“COUNTRY”，missing=“pairwise”，
                               参数化=“delta”，group.equal=c(“载荷”，“阈值”))

下面是compareFit测试结果。如您所见，标量模型的 Df 较小。这会导致模型之间的卡方差异检验计算错误。

提前非常感谢。
埃内斯。]]></description>
      <guid>https://stats.stackexchange.com/questions/644504/why-do-i-get-smaller-degrees-of-freedom-for-the-scalar-invariance-model-than-the</guid>
      <pubDate>Sun, 07 Apr 2024 15:42:13 GMT</pubDate>
    </item>
    <item>
      <title>手动指定节点与分段回归的 bs()</title>
      <link>https://stats.stackexchange.com/questions/644503/manual-specification-of-knots-vs-bs-for-piecewise-regression</link>
      <description><![CDATA[我正在学习如何指定和绘制分段回归，并且遇到了令人困惑的情况。也就是说，我使用两种方法指定了分段回归的结：(1) 手动和 (2) 使用 library(splines) 中的 bs() 函数。有两个令人困惑的理由：

两种方法提供完全不同的系数集
在 ggplot() 的 geom_smooth(method = lm, Formula = ...) 的 formula 参数中指定时，这两种方法提供相同的平滑线条

参见下面的图表：

为什么这两种方法会产生不同的系数？具有不同系数的 2 个模型如何在 ggplot() 中生成相同的 geom_smooth 线？
凭直觉，我知道手册规范是正确的。但是，我想了解这里发生了什么，以便将来可以更好地利用 bs() 函数来指定分段模型。
数据和模型代码：
&lt;前&gt;&lt;代码&gt;&gt;数据船
    成本零件
1 11.95 225
2 14.13 350
3 8.93 150
4 10.98 200
5 10.03 175
6 10.13 180
7 13.75 325
8 13.30 290
9 15.00 400
10 7.97 125

&gt; # 手动方法
&gt; lm(成本 ~ 零件 + I((零件 - 250)* (零件 &gt;= 250)), data_ship)$coef
                  （截取）第 I 部分（（部分 - 250）*（部分 &gt;= 250））
                   3.21392570 0.03845992 -0.02477335
&gt;
&gt; #bs()方法
&gt; lm(成本 ~ bs(零件, 结 = c(250), 度 = 1), data_ship)$coef
                           （截距） bs(零件，结 = c(250)，度 = 1)1 bs(零件，结 = c(250)，度 = 1)2
                              8.021416 4.807491 6.860476


图表代码：
# 1.手动方法
coef.manual &lt;- lm(成本 ~ 零件 + I((零件 - 250)* (零件 &gt;= 250)), data_ship)$coef
coef.manual &lt;-signif(coef.manual, 5)

fx.manual &lt;- bquote(Cost == .(coef.manual[1]) + .(coef.manual[2])~ 部分 -
                      .(abs(coef.manual[3]))(零件 - 250)~X[1])

库（ggplot2）

plt.1 &lt;-
  ggplot(data_ship, aes(x = 零件, y = 成本)) +
  几何点（）+
  geom_smooth(方法 = lm, 公式 = y ~ x + I((x - 250)* (x &gt;= 250)),
              颜色 =“firebrick2”，se = F) +
  geom_smooth(方法 = lm, 颜色 = &quot;firebrick4&quot;, 线型 = &quot;虚线&quot;, se = F) +
  labs(title = “拟合线图”, subtitle = fx.manual,
       y =“成本（1000 美元）”，
       标题 =“公式 = y ~ x + I((x - 250)* (x &gt;= 250))”)


# 2.bs()方法
库（样条线）

coef.bs &lt;- lm(成本 ~ bs(零件, 结 = c(250), 度 = 1), data_ship)$coef
coef.bs &lt;-signif(coef.bs, 5)

fx.bs &lt;- bquote(Cost == .(coef.bs[1]) + .(coef.bs[2])~ 部分 -
                  .(abs(coef.bs[3]))(零件 - 250)~X[1])

plt.2 &lt;-
  ggplot(data_ship, aes(x = 零件, y = 成本)) +
  几何点（）+
  geom_smooth(方法 = lm, 公式 = y ~ bs(x, 结 = c(250), 度 = 1),
              颜色 =“firebrick2”，se = F) +
  geom_smooth(方法 = lm, 颜色 = &quot;firebrick4&quot;, 线型 = &quot;虚线&quot;, se = F) +
  labs(title = “拟合线图”, subtitle = fx.bs,
       y =“成本（1000 美元）”，
       标题=“公式= y〜bs（x，结= c（250），度= 1）”）


# 3. 编译绘图
图书馆（网格）
库（网格额外）

grid.arrange(plt.1, plt.2, nrow = 1)

如果这看起来“基本”，我衷心致歉]]></description>
      <guid>https://stats.stackexchange.com/questions/644503/manual-specification-of-knots-vs-bs-for-piecewise-regression</guid>
      <pubDate>Sun, 07 Apr 2024 15:41:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 t 检验比较 bootstrap auc 置信区间</title>
      <link>https://stats.stackexchange.com/questions/644501/compare-bootstrap-auc-confidence-interval-using-t-test</link>
      <description><![CDATA[为了在特征数为5时的机器学习模型和特征数为6时的机器学习模型之间进行选择，我想引导模型的auc以获得置信区间并比较是否存在是有区别的。
执行 t 检验时，我应该测试引导结果的正态性和等方差吗？我知道引导假设正常。那么不需要进行任何特殊测试吗？
我想在 Python 中使用以下代码进行比较。
导入 pingouin 作为 pg
将 numpy 导入为 np，将 statsmodels.stats.api 导入为 sms
cm = sms.CompareMeans(sms.DescrStatsW(t_5), sms.DescrStatsW(t_6))
print(cm.tconfint_diff(usevar=&#39;不平等&#39;))

“t_5”和“t_6”是“feature = 5”时模型和“feature = 6”时模型的auc自引导2000次的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/644501/compare-bootstrap-auc-confidence-interval-using-t-test</guid>
      <pubDate>Sun, 07 Apr 2024 15:16:14 GMT</pubDate>
    </item>
    <item>
      <title>在没有 X_test 的情况下预测 RNN 和 LSTM</title>
      <link>https://stats.stackexchange.com/questions/644499/forecasting-rnn-and-lstm-without-x-test</link>
      <description><![CDATA[亲爱的 StackExchange 社区，
我的数据仅由 1 个时间序列变量（资产的股票价格）组成
我已将其拆分为训练和测试子集。
我已经使用 X_train 和 Y_train 训练了 RNN 和 LSTM 模型。
我使用的资源（书籍、课程和博客）建议使用 X_test 进行预测。 RMSE 预测好得令人难以置信。我想这是因为我使用与 Y_test 相同的数据集（X_test）进行预测。
您建议我使用什么书、课程、博客来预测未来价值而不使用 X_test。（我认为多步前进？）
致以诚挚的问候]]></description>
      <guid>https://stats.stackexchange.com/questions/644499/forecasting-rnn-and-lstm-without-x-test</guid>
      <pubDate>Sun, 07 Apr 2024 14:43:58 GMT</pubDate>
    </item>
    <item>
      <title>帮助计算 PLS 检测限</title>
      <link>https://stats.stackexchange.com/questions/644497/help-with-calculation-of-pls-limit-of-detection</link>
      <description><![CDATA[我正在尝试根据 Allegrini 和 Olivieri 论文（[https://pubs.acs.org/doi/epdf/10.1021/ac501786u]）计算 PLS 模型检测上限和下限，但不知道如何这样做（对我来说太数学解释了）。
如何解方程 12 和 13？我究竟需要向其中输入什么？
编辑：添加论文中的屏幕截图

公式 12 和 13：


SEN参数：


var(x) 是仪器信号的方差

h0min 和 h0max 参数：


]]></description>
      <guid>https://stats.stackexchange.com/questions/644497/help-with-calculation-of-pls-limit-of-detection</guid>
      <pubDate>Sun, 07 Apr 2024 14:26:35 GMT</pubDate>
    </item>
    <item>
      <title>动量 SGD：特征值 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/644491/sgd-with-momentum-eigenvalues</link>
      <description><![CDATA[我正在阅读《动量如何真正发挥作用》一文（https://distill.pub/2017/momentum/），我很困惑点：

我正在尝试从以下方程推导出动量的收敛速度：

&lt;块引用&gt;
$\min_{\alpha, \beta}\max\lbrace \parallel \begin{pmatrix}
\beta &amp; \lambda_1 \\
-\alpha\beta &amp; 1-\alpha\lambda_1
\end{pmatrix} \parallel, ..., \parallel \begin{pmatrix}
\beta &amp; \lambda_n \\
-\alpha\beta &amp; 1-\alpha\lambda_n
\end{pmatrix} \并行\rbrace$

$\parallel\parallel$ 这里表示最大特征值的大小，当对极值对应的矩阵重复特征多项式的根时出现特征值。所以我们知道 R 的特征值：
$\sigma_i =\frac{1}{2}(1-\alpha\lambda+\beta\pm\sqrt{(-\alpha\lambda+\beta+1) ^2-4\测试版})$
但不知何故，我不知道如何在这里进行代数。首先，我想知道等于特征值是否正确（一个用 $\lambda_1$ 表示，另一个用 $\lambda_n$) 然后你需要找到 alpha 和 beta 的解决方案？然后我真的不知道该应用哪种技巧来使代数用 alfa 来写？]]></description>
      <guid>https://stats.stackexchange.com/questions/644491/sgd-with-momentum-eigenvalues</guid>
      <pubDate>Sun, 07 Apr 2024 10:08:17 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯观点中的“数据是固定的”和频率论观点中的“数据是随机的”在数学上谈论的是同一件事吗？</title>
      <link>https://stats.stackexchange.com/questions/644489/are-data-are-fixed-in-bayesian-viewpoint-and-data-are-random-in-frequentist</link>
      <description><![CDATA[在我看来，在贝叶斯推理和频率推理中，观测数据$x$被建模为随机变量的观测值$X$ 遵循一定的概率分布。因此，当我遇到这两个语句时 - “数据已固定”从贝叶斯观点来看，“数据是随机的”。从频率论的角度来看，我发现它们很难理解，因为它似乎表明对数据概念的解释存在差异。
读了一些资料后，似乎“数据是固定的”是指观察到的数据$x$是固定的，“数据是随机的”是指随机变量&lt; span class=&quot;math-container&quot;&gt;$X$ 是随机的。这两个陈述中的“数据”所指的并不是同一件事。不确定我的解释是否正确。欢迎您的建议。如果我的解释是正确的，那么这两个陈述是否多余/令人困惑？]]></description>
      <guid>https://stats.stackexchange.com/questions/644489/are-data-are-fixed-in-bayesian-viewpoint-and-data-are-random-in-frequentist</guid>
      <pubDate>Sun, 07 Apr 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>使用回归似然从回归中复制 t 或 F 检验</title>
      <link>https://stats.stackexchange.com/questions/644482/replicate-t-or-f-test-from-regression-using-regression-likelihoods</link>
      <description><![CDATA[我听说我们用来获取回归结果显着性的 t 检验和 F 检验是从似然比检验得出的，但我在复制 t/F 的 p 值时遇到了麻烦对回归似然进行似然比检验的检验
使用底部的数据集，
在 R 中运行这三个回归：
withCov&lt;-lm(Y~X)
logLik(withCov) # &#39;log Lik。&#39; -61.98043（df=3）
与Int&lt;-lm(Y~1)
logLik(withInt) # &#39;log Lik.&#39; -63.18456（df=2）
有无&lt;-lm(Y~0)
logLik(withNone) # &#39;log Lik.&#39; -65.32909（df=1）

例如，当我对 beta_1 的显着性进行似然比检验时，我得到
1-pchisq(2*(logLik(withCov)-logLik(withInt)),df = 1)
# 0.1206958
＃ 相比于
摘要（withCov）
称呼：
lm(公式 = Y ~ X)

残差：
     最小 1Q 中值 3Q 最大
-1.98508 -0.44415 -0.02294 0.59907 1.66593

系数：
            估计标准。误差t值Pr(&gt;|t|)
（截距）-0.2568 0.1206 -2.129 0.0384 *
X -0.2045 0.1329 -1.53​​9 0.1304
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残余标准误差：48 自由度上为 0.8531
多重 R 平方：0.04702，调整 R 平方：0.02717
F 统计量：1 和 48 DF 上为 2.369，p 值：0.1304

虽然值很接近，但 0.1304 显然与 0.1206958 不同。
对于似然比检验的所有 6 种组合，我无法从 lm 恢复任何 p 值。
我做错了什么？谢谢！
下面的 R 代码设置 X 和 Y 变量：
&lt;预&gt;&lt;代码&gt;X&lt;-c(0.147462983739098,-0.552822250273655,0.0791413008277721,1.64705442993914,0.68248797132517,-0.315633973636888,1. 40047872456033,0.776033233883272,-0.343689753439294,-0.526351059575156,0.275611183793461,1.7751174954305,-0.932913434395753,0 .163895795533468,-1.00807323166609,-0.434797856886559, 0.112072003876197,-0.319445372479459,1.6989373340732,0.639738727242407,0.02980494131095,0.564230726111237,1.61191604859755, -0.474733281647485,-1.46213462226689,-1.33823497263023,0.0771907623203949,-0.698998017227839,-0.775816444324552,1.46468840793 603,-0.0940659257837727,-1.85718512842644,0.109762500597346,0.293088069440979,-1.33774986808507,0.804321505460817,1.246387803 51287 ,-1.66909878637454,-0.107871283787089,-0.286526054190293,-1.30268476505327,0.241186917275982,0.0941940655245403,0.426156461 908492,-0.951908401332523,-0.782389908678191,0.436387212517629,0.491981905432585,0.863964246361868,-0.715853080383197)
Y＜-c(0.123592053622774，-0.156626343170975，-1.00704515111936，-0.333485064105835，0.539121555715671，0.0827543989201612，-1.381 38102448818,-0.510996824863877,1.40679987755037,-0.289587787513398,-1.00983646108717,0.20397559183913,-1.53​​795623798144,-0.37 4138120013244,0.753381985793875,-0.195106670583694,-0.395410227522805, 0.314058948313302,-0.567075906102368,-0.823999734395967,0.334195737940288,-0.382748868492066,-1.1924589353617,-2.1447830778 6596,0.198528331051895,0.616636192164357,-1.66623239116232,0.906880778089087,0.663909698659448,-0.96026161021686,-0.028951352 9973109,0.103477089026045,-0.517840007699842,-1.42770065687853,-1.18735568345121,0.441872906307648,- 0.814014579874374,-0.96658546843308,0.474244931448731,-0.975319336891573,-0.0672523439350411,-0.743286641930158,0.788159757 412595,1.23723123779866,-0.508581741865352,0.220065470600985,0.822051420773978,-0.383737198032438,-2.04890944754108,1.5555393 999865)
]]></description>
      <guid>https://stats.stackexchange.com/questions/644482/replicate-t-or-f-test-from-regression-using-regression-likelihoods</guid>
      <pubDate>Sun, 07 Apr 2024 01:59:46 GMT</pubDate>
    </item>
    <item>
      <title>解释流行病学模型的泊松 GAM</title>
      <link>https://stats.stackexchange.com/questions/644475/interpreting-poisson-gam-for-epidemiological-model</link>
      <description><![CDATA[我正在开展一个项目，调查 PM2.5（一种污染形式）与缺血性中风住院治疗（即每天收集的住院总人数）之间的关系。我的模型如下所示，结果图也是如此：
&lt;前&gt;&lt;代码&gt;库(mgcv)
gam_model &lt;- gam(行程 ~ s(PM2.5) +
        因素（地区）+
        ns(日期, df= 7) +
        偏移量（日志（人口）），
                 数据=区域数据，
                 家庭=泊松（链接=“日志”））

绘图（gam_model，trans = exp，xlab =“PM2.5”，ylab =“相对风险”，rug = TRUE）


因为我想根据相对风险（相对于零基线 PM2.5 水平）来解释模型，所以我设置了 trans = exp。然而，我不明白如何解释结果，该结果表明，PM2.5 时，因缺血性中风住院的相对风险较低 $\approx 20$ 比 0 低。我犯错了吗？
如果这是一个愚蠢的问题，我很抱歉，我对这一切都很陌生。]]></description>
      <guid>https://stats.stackexchange.com/questions/644475/interpreting-poisson-gam-for-epidemiological-model</guid>
      <pubDate>Sat, 06 Apr 2024 22:31:38 GMT</pubDate>
    </item>
    </channel>
</rss>