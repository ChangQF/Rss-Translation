<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 20 Jul 2024 06:21:17 GMT</lastBuildDate>
    <item>
      <title>平均值的假设检验 - z 检验和 t 检验统计量的分布推导</title>
      <link>https://stats.stackexchange.com/questions/651439/hypothesis-tests-for-averages-derivation-of-distribution-of-z-test-and-t-test</link>
      <description><![CDATA[在测试平均值时，z 检验和 t 检验都具有相同形式的检验统计量 $T$:
$$T = \frac{\bar{X} - \mu_0}{\text{se}(\bar{X})}$$
在前者中，已知的总体标准偏差 $\sigma$ 用作分母，而在后者中，标准误差 $S = \hat{\sigma}/\sqrt{n}$ 与 $\hat{\sigma} = \sqrt{\frac{1}{n-1}\sum_{i\leq 一起使用N}(x-\bar{x})^2}$。z 检验统计量的分布为：$T_z \sim \Phi(0, 1)$，t 检验统计量的分布为：$T_t \sim t_{n-1}$
有没有推导为什么除以标准误差会得到 t 分布，而除以标准差会得到正态分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/651439/hypothesis-tests-for-averages-derivation-of-distribution-of-z-test-and-t-test</guid>
      <pubDate>Sat, 20 Jul 2024 06:08:32 GMT</pubDate>
    </item>
    <item>
      <title>成对回归与个体回归之间的关系</title>
      <link>https://stats.stackexchange.com/questions/651437/relationship-between-pairwise-regression-vs-individual-regression</link>
      <description><![CDATA[我想在成对回归和线性回归之间建立联系。我将在下面用一个例子解释成对回归和线性回归的含义，但这个例子只是为了解释我想做什么。
考虑这样一个场景：一所高中有 5 个教室，每个教室有 10 名学生。为简单起见，假设同一个教室里的每个人都互相认识，但不认识其他教室里的任何人。当学生毕业时，他们会决定去哪个州上大学。
我感兴趣的是，在同一个教室里的学生是否更有可能去同一个州上大学。为此，我为所有 50 名学生创建了一个学生对，结果有 50C2 = 1225 对。对于每一对，我可以构建一个指示变量 classmate，如果该对中的两个学生在同一个班级，则该变量等于 1；如果两个学生都去同一个州上大学，则该变量等于 1。
然后，我可以运行回归分析，将 same_college 与 classmate 进行回归，并将 comove 前面的系数解释为同学们去同一个州上大学的额外倾向。这就是我所说的成对回归。
但请注意，50 名学生创建了 1225 对。当样本变大时，这种情况很快就会失控。此外，我没有通过将数据集从个人级别转换为成对级别来插入任何新数据；这只是数据集的转换。**此外，这只研究一个学生如何影响该对中的另一个学生。它忽略了 3 组或更多组学生可能对决策产生不同于仅构建学生对的任何可能性。
问题：我想知道我是否可以从成对回归中检索相同的系数，而无需将数据集转换为成对级别。我很难弄清楚我可以在个体级别上运行的回归是什么，它将与成对级别的系数相匹配。
** 我相信这是一个双射变换，但如果不是，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/651437/relationship-between-pairwise-regression-vs-individual-regression</guid>
      <pubDate>Sat, 20 Jul 2024 02:47:30 GMT</pubDate>
    </item>
    <item>
      <title>分类独立变量</title>
      <link>https://stats.stackexchange.com/questions/651435/categorical-independent-variables</link>
      <description><![CDATA[我正在开展一项回顾性研究，有一些分类独立变量，我的结果变量也是分类变量。我想知道具有多个分类独立变量的卡方检验是否是最佳模型。你能帮助我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651435/categorical-independent-variables</guid>
      <pubDate>Sat, 20 Jul 2024 02:22:18 GMT</pubDate>
    </item>
    <item>
      <title>如何计算所需样本量以实现所需的假阴性率</title>
      <link>https://stats.stackexchange.com/questions/651434/how-to-calculate-required-sample-size-for-desired-false-negative-rate</link>
      <description><![CDATA[我正在尝试设计一个进行二元分类的系统。假阴性的成本很高，所以我想确保我已经进行了足够彻底的测试，以尽量减少这种可能性。我希望系统的假阴性率小于 1%，确定性为 95%。如果我预计真阳性率很小（大约 2%），我应该如何计算达到这一置信度所需的人口规模？ 单侧检验程序是此处适用的正确方程吗？
$$
N \geq \left ( \frac{z_{1-\alpha} \sqrt{p_0(1-p_0)} + z_{1-\beta} \sqrt{p_1(1-p_1)}}{p_1-p_0} \right ) ^2
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/651434/how-to-calculate-required-sample-size-for-desired-false-negative-rate</guid>
      <pubDate>Sat, 20 Jul 2024 01:48:58 GMT</pubDate>
    </item>
    <item>
      <title>在 FDR 之前过滤单侧检验</title>
      <link>https://stats.stackexchange.com/questions/651432/filter-one-sided-tests-before-fdr</link>
      <description><![CDATA[在这篇博文中，作者展示了一个“奇怪”的例子p 值直方图（“场景 C”）：

一种解释是，进行了单侧检验，而效果相反的检验给出的 p 值接近 1。他的建议是在计算 FDR 之前根据效果方向过滤掉检验。
但是，我知道，如果过滤方式不正确，在计算 FDR 之前进行预过滤可能会出现问题，例如讨论过的那样这里，当我们查看结果时，感觉按效果方向过滤是“作弊”。
现在，如果我在 R 中运行快速模拟（如下所示），过滤会导致 p 值分布在 0 到 0.5 之间，因此 p 值在 0 和 1 之间均匀的假设不再有效。那么，在计算 FDR 之前根据效果方向进行过滤是否正确？
此外，从经验上看我模拟中的 FDR 和功效，如果我在 p.adjust() 中指定测试总数，似乎我可以保持正确的 FDR 控制，同时仍获得一点功效。这是正确的做法吗？
模拟
set.seed(1)

## 生成数据 ----
real_means &lt;- c(
rep(0, 1000), # 无影响
runif(200, -1, 0), # 减少
runif(200, 0, 1) # 增加
)
labels &lt;- c(
rep(&quot;none&quot;, 1000),
rep(&quot;decreased&quot;, 200),
rep(&quot;increased&quot;, 200)
)

samples &lt;- lapply(real_means, \(mu) rnorm(30, mu, sd = 1))

## 计算 p 值和 fdr ----
p_values &lt;- sapply(samples, \(x) t.test(x, alternative = &quot;greater&quot;)$p.value )
p_values &lt;- setNames(p_values, labels)

hist(p_values, breaks = 70)




fdr &lt;- p.adjust(p_values, method = &quot;BH&quot;)

## 检查结果 ----
false_positives &lt;- sum( fdr[names(fdr) != &quot;increased&quot;] &lt; 0.05 )
predicted_positives &lt;- sum( fdr &lt; 0.05 )
true_positives &lt;- sum( fdr[names(fdr) == &quot;increased&quot;] &lt; 0.05 )
positives &lt;- sum( names(fdr) == &quot;increased&quot; )

# 错误发现率
false_positives / predicted_positives
#&gt; [1] 0.01234568

# 真正率
true_positives / positives
#&gt; [1] 0.4

## 带过滤 ----

direction_increasing &lt;- sapply(samples, \(x) mean(x) &gt;= 0 )

filtered_p_values &lt;- p_values[ direction_increasing ]

hist(filtered_p_values)



filt_fdr &lt;- p.adjust(filtered_p_values, method = &quot;BH&quot; )

false_positives &lt;- sum(filt_fdr[names(filt_fdr) != &quot;increased&lt;] &lt; 0.05 )
predicted_positives &lt;- sum(filt_fdr &lt; 0.05 )
true_positives &lt;- sum(filt_fdr[names(filt_fdr) == &quot;increased&lt;] &lt; 0.05 )
positives &lt;- sum(names(filt_fdr) == &quot;increased&lt; )

# 错误发现率
false_positives / predicted_positives
#&gt; [1] 0.04301075

# 真正率
true_positives / positives
#&gt; [1] 0.4863388

## 带过滤，但指定测试总数 ----

filt_fdr_with_n &lt;- p.adjust(filtered_p_values, method = &quot;BH&quot;, n = length(p_values) )

false_positives &lt;- sum( filt_fdr_with_n[names(filt_fdr_with_n) != &quot;increased&quot;] &lt; 0.05 )
predicted_positives &lt;- sum( filt_fdr_with_n &lt; 0.05 )
true_positives &lt;- sum( filt_fdr_with_n[names(filt_fdr_with_n) == &quot;increased&quot;] &lt; 0.05 )
positives &lt;- sum( names(filt_fdr_with_n) == &quot;increased&quot; )

# 错误发现率
false_positives / predictive_positives
#&gt; [1] 0.01234568

# 真阳性率
true_positives / positives
#&gt; [1] 0.4371585

于 2024-07-19 使用 reprex v2.1.0 创建]]></description>
      <guid>https://stats.stackexchange.com/questions/651432/filter-one-sided-tests-before-fdr</guid>
      <pubDate>Fri, 19 Jul 2024 22:21:49 GMT</pubDate>
    </item>
    <item>
      <title>证明 $T$ 是一个完全统计量，并找到 $p$ 的 UMVUE [重复]</title>
      <link>https://stats.stackexchange.com/questions/651430/prove-that-t-is-a-complete-statistic-and-find-a-umvue-for-p</link>
      <description><![CDATA[在准备预赛时，我遇到了这个问题：
设$X_1, X_2,\cdots, X_n$为伯努利试验序列，$n \geq 4.$已知，$X_1,X_2,X_3 \stackrel{\text{i.i.d.}}{\sim} Ber(\frac12),$且对于$4\leq i \leq n,$ $P(X_i=X_{i-1}|X_1,\cdots,X_{i-1})=1-p,$ $p \in (0,1).$ 考虑 $T:=\sum_{i=4}^n |X_i-X_{i-1}|$。$T$ 是否完整？因此（否则），找到 $p$ 的 UMVUE。
到目前为止，我所能证明的只是 $S:=\frac{T}{n-3}$ 对于 $p$ 是无偏的。如果我能进一步证明 $T$ 对于 $p$ 是完全充分的，那么 $S$ 将是 UMVUE，由 Lehmann-Scheffe 提出。我如何证明 $T$ 是完全的？我没能找到 $E[f(T)],$ 的简洁表达式，其中 $f$ 是 Borel 可测的。]]></description>
      <guid>https://stats.stackexchange.com/questions/651430/prove-that-t-is-a-complete-statistic-and-find-a-umvue-for-p</guid>
      <pubDate>Fri, 19 Jul 2024 20:46:19 GMT</pubDate>
    </item>
    <item>
      <title>有人可以给我举一个概率分布的例子及其符号吗？[重复]</title>
      <link>https://stats.stackexchange.com/questions/651429/can-someone-give-me-an-example-of-what-a-probability-distribution-looks-like-and</link>
      <description><![CDATA[随机变量 X 的概率分布是什么？概率分布的典型符号是什么？
有人能给我举个概率分布的例子吗？它的符号是什么样的？]]></description>
      <guid>https://stats.stackexchange.com/questions/651429/can-someone-give-me-an-example-of-what-a-probability-distribution-looks-like-and</guid>
      <pubDate>Fri, 19 Jul 2024 20:45:09 GMT</pubDate>
    </item>
    <item>
      <title>xtreg 和 reghdfe 之间的区别</title>
      <link>https://stats.stackexchange.com/questions/651427/difference-between-xtreg-and-reghdfe</link>
      <description><![CDATA[当我尝试在 Stata 中使用以下命令设置面板数据时
xtset familyid MatricYear

我收到以下错误
面板内重复的时间值
r(451);

但是当我直接运行 reghdfe 时，没有错误。所以我的问题是，我将在 xtset 之后使用 xtreg 进行固定效应回归。但它不会运行，因为我无法设置 xtset。但 reghdfe 完全忽略了这一点。为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/651427/difference-between-xtreg-and-reghdfe</guid>
      <pubDate>Fri, 19 Jul 2024 20:15:18 GMT</pubDate>
    </item>
    <item>
      <title>皮尔逊卡方和相关性</title>
      <link>https://stats.stackexchange.com/questions/651426/pearson-chi-square-and-correlation</link>
      <description><![CDATA[我的数据是有序的
Pearson 卡方检验值为 4.664
并且不对称 sig 为 0.97，因此数据是独立的
但是 pearson 的 R =-0.309
并且近似 sig=0.037
它们可以同时独立和负相关吗]]></description>
      <guid>https://stats.stackexchange.com/questions/651426/pearson-chi-square-and-correlation</guid>
      <pubDate>Fri, 19 Jul 2024 20:13:56 GMT</pubDate>
    </item>
    <item>
      <title>模型具有更高的（且更接近 1）$\beta$，但 $R^2$ 和相关性相似</title>
      <link>https://stats.stackexchange.com/questions/651423/model-has-higher-and-closer-to-1-beta-but-similar-r2-and-correlation</link>
      <description><![CDATA[我有一个模型，它产生预测$\hat{y_1}$，后来我又想出了一个新模型，它产生预测$\hat{y_2}$。我有基本事实$y$。 这些模型不是基于回归的，但它们是线性的，我想在回归指标中对它们进行评估。
如果我运行$y \sim \beta_1 \hat{y_1}$、$y \sim \beta_2 \hat{y_2}$，我会看到$\beta_2 \sim 1$和$\beta_1 \sim 0.8$。我认为这意味着我的模型 2 “缩放得更好”。
但如果我直接计算 $R2(y, \hat{y_1}) = 1- \frac{\sum (y_t - \hat{y_1}_t )^2 }{\sum y_t^2}$ 和 $R2(y, \hat{y_2}) = 1- \frac{\sum (y_t - \hat{y_2}_t )^2 }{\sum y_t^2}$（因为我不会尝试重新运行回归 $y \sim \beta_1 \hat{y_1}$ 并得到回归 R2。我只是直接计算 $R2(y, \hat{y_1}) = 1- \frac{\sum (y_t - \hat{y_1}_t )^2 }{\sum y_t^2}$)。我发现它们大致相等。
当我计算 $y$ 和 $\hat{y_1}$ 之间的相关性以及 $y$ 和 $\hat{y_2}$ 之间的相关性时，我发现它们也几乎相等。请注意，这里的相关性可能不是 R2 的平方根，因为我的模型不是基于回归的。
它告诉了我关于预测的什么？我觉得有点惊讶。我认为“更好的规模”预测因子应该出现在回归指标的某个地方吗？为什么“更好的尺度”回归没有给我更好的 R2？]]></description>
      <guid>https://stats.stackexchange.com/questions/651423/model-has-higher-and-closer-to-1-beta-but-similar-r2-and-correlation</guid>
      <pubDate>Fri, 19 Jul 2024 19:10:07 GMT</pubDate>
    </item>
    <item>
      <title>分位数函数容易求解但 CDF 难以求解的分布示例</title>
      <link>https://stats.stackexchange.com/questions/651421/examples-of-distributions-with-easily-solvable-quantile-functions-but-hard-to-so</link>
      <description><![CDATA[我对概率分布的例子很感兴趣，其中分位数函数 $F^{-1}(p)$ 以闭式存在或易于计算，但累积分布函数 (CDF) $F(x)$ 不以闭式存在。特别是分位数函数易于求解但 CDF 难以求解或无法求解的例子，尤其是当分布用于实际应用时。任何例子都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/651421/examples-of-distributions-with-easily-solvable-quantile-functions-but-hard-to-so</guid>
      <pubDate>Fri, 19 Jul 2024 18:14:59 GMT</pubDate>
    </item>
    <item>
      <title>以和为条件的 iid 平方的期望值</title>
      <link>https://stats.stackexchange.com/questions/651402/expected-value-of-iid-squared-conditioned-on-sum</link>
      <description><![CDATA[我有兴趣找到以下表达式的值：
$$\mathbb{E}[X_k^2\mid S_N]$$
其中 $X_k$ 是 iid 随机变量，$\mathbb{E}[X_k]=\mu$ 和 $\operatorname{Var}[X_k]=\sigma^2$，$N$ 是确定性常数，并且：
$$S_N=\sum_{i=1}^N X_i$$
我尝试使用
$$\mathbb{E}[S_N^2]=N\mathbb{E}[X_k^2 \mid S_N]+N(N-1)\mathbb{E}[X_i X_j\mid S_N]$$
其中 $i\neq j$。然而，即使不同的 $X_k$ 是独立的，它们也不一定满足 $\mathbb{E}[X_i X_j\mid S_N]=\mathbb{E}[X_i\mid S_N]^2$]]></description>
      <guid>https://stats.stackexchange.com/questions/651402/expected-value-of-iid-squared-conditioned-on-sum</guid>
      <pubDate>Fri, 19 Jul 2024 13:00:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的卡方检验的 p 值这么高？</title>
      <link>https://stats.stackexchange.com/questions/651374/why-is-my-pvalue-for-chisquared-test-so-high</link>
      <description><![CDATA[我从值 = [0, 1] 中抽样，概率 = [.25, .75]。
我得到 25019 个零和 74981 个一。然而，通过卡方检验结果如下：
statistic=0.0196，pvalue=0.889
这似乎与我的直觉不符。
也许这是使用 Fisher 精确检验的原因？我应该使用 KS 测试来获取频率吗？
这是我的代码
N = 100000
values = [np.random.choice([0, 1], p=[.25, .75]) for _ in range(N)]
one_count = sum(values)
zero_count = len(values) - one_count
test_stat = (N*.75 - one_count)**2/(N*.75) + (N*.25 - zero_count)**2/(N*.25)
print(test_stat, 1 - stats.chi2.cdf(test_stat, 1))
]]></description>
      <guid>https://stats.stackexchange.com/questions/651374/why-is-my-pvalue-for-chisquared-test-so-high</guid>
      <pubDate>Thu, 18 Jul 2024 22:58:01 GMT</pubDate>
    </item>
    <item>
      <title>预测区间准确度与均方误差之间的权衡</title>
      <link>https://stats.stackexchange.com/questions/651367/tradeoff-between-prediction-interval-accuracy-mean-squared-error</link>
      <description><![CDATA[我的目标是量化气候协变量与 GDP 回归模型中的预测不确定性。我从一个模型开始，该模型以温度作为三次多项式，国家固定效应（$\alpha_i$}，年份固定效应（$\theta_t$）和国家增量时间趋势（$\gamma_i$）。
$$ 
GDP_{it} = \beta_1 * Temp_{it} + \beta_2 * Temp^2_{it} + \beta_3 * Temp^3_{it} + \alpha_i + \theta_t + \gamma_i
$$
我使用一些保留数据来收集上述模型的样本外均方误差。我还使用样本外预测的标准误差来构建 95% 的预测间隔，然后检查实际 Y（GDP）值在这些间隔内的实际百分比作为预测间隔准确度。
样本外 MSE：0.017
样本外预测间隔准确度：0.577

为了使预测间隔准确度更接近 95% 的目标，我尝试了一个具有更高次数多项式时间趋势的不同模型，如下所示：
$$ 
GDP_{it} = \beta_1 * Temp_{it} + \beta_2 * Temp^2_{it} + \beta_3 * Temp^3_{it} + \alpha_i + \theta_t + \gamma_i + \gamma^2_i + \gamma^3_i
$$
样本外 MSE： 0.018
样本外预测区间准确度：0.722

由于预测区间更宽，预测区间准确度大大提高，这可能是因为模型在训练数据中纳入了更多方差。但是，可能由于额外的模型复杂性导致过度拟合，第二个模型的 MSE 高于第一个模型。
我的问题与这个特定示例关系不大，而是与我普遍观察到的这种现象关系更大。我想知道：

是否存在一个单一的潜在现象，可以解释为什么增加模型复杂度会导致样本外预测区间更接近 95% 的目标，同时增加模型的样本外 MSE，或者这些本质上是独立的观察结果？

如果我的目标是尽可能量化模型不确定性，那么如何正确考虑以更高质量（在这种情况下意味着更宽）的样本外预测区间换取随后的样本外 MSE 增加？

]]></description>
      <guid>https://stats.stackexchange.com/questions/651367/tradeoff-between-prediction-interval-accuracy-mean-squared-error</guid>
      <pubDate>Thu, 18 Jul 2024 20:44:03 GMT</pubDate>
    </item>
    <item>
      <title>Ornstein–Uhlenbeck 过程最小值的 MLE</title>
      <link>https://stats.stackexchange.com/questions/651345/mle-for-a-minimum-of-ornstein-uhlenbeck-process</link>
      <description><![CDATA[使用 MLE 来估计一维 Ornstein–Uhlenbeck 过程的参数是众所周知的。但是，是否已经对以下形式的过程进行了类似的研究
\begin{equation}
X_t = \min \left( \int_0^t \theta (X_t - \mu) \, dt + \int_0^t \sigma \, dB_t , \alpha\right) \text{?}
\end{equation&gt;
这是在上限均值反转过程的背景下。即，给定该过程的数据，MLE 是什么样子来估计参数$\Theta = (\theta, \mu, \sigma)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/651345/mle-for-a-minimum-of-ornstein-uhlenbeck-process</guid>
      <pubDate>Thu, 18 Jul 2024 14:38:01 GMT</pubDate>
    </item>
    </channel>
</rss>