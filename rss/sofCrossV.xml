<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 21 Aug 2024 21:15:11 GMT</lastBuildDate>
    <item>
      <title>最大化某个平均值机会的最小数字</title>
      <link>https://stats.stackexchange.com/questions/653138/minimum-number-to-maximize-the-chance-of-a-certain-average</link>
      <description><![CDATA[解决以下问题的方法是什么。
在测试中，每个问题的答案都会得到 0 到 100 之间的分数（含 0 和 100）。从长远来看，我的平均成绩是 60，这是既定事实。如果测试包含无数个问题，我的平均成绩将接近 60。对于给定的问题，我可能会得到 0 到 100 之间的任何分数。
问题 1：假设出于某种原因我需要 70 的平均成绩。要使我的平均成绩达到 70，最少需要回答多少个问题？
问题 2：第一个问题我的得分是 20。现在，要使我的平均成绩达到 70，最少需要回答多少个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/653138/minimum-number-to-maximize-the-chance-of-a-certain-average</guid>
      <pubDate>Wed, 21 Aug 2024 19:40:35 GMT</pubDate>
    </item>
    <item>
      <title>GraphPad Prism 中的 Friedman 检验存在问题</title>
      <link>https://stats.stackexchange.com/questions/653137/issue-with-friedman-test-in-graphpad-prism</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653137/issue-with-friedman-test-in-graphpad-prism</guid>
      <pubDate>Wed, 21 Aug 2024 19:39:49 GMT</pubDate>
    </item>
    <item>
      <title>R lmer 帮助理解我的混合模型输出</title>
      <link>https://stats.stackexchange.com/questions/653130/r-lmer-help-understanding-my-mixed-model-output</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653130/r-lmer-help-understanding-my-mixed-model-output</guid>
      <pubDate>Wed, 21 Aug 2024 15:49:36 GMT</pubDate>
    </item>
    <item>
      <title>确定多个分析的样本大小</title>
      <link>https://stats.stackexchange.com/questions/653129/determine-the-sample-size-for-multiple-analyses</link>
      <description><![CDATA[我无法确定样本量。
在时间 1 和时间 2，我有一个治疗组和一个对照组。
变量 A = 其子集 A1、A2、A3 和 A4 的平均值。
变量 B = 其子集 B1、B2 和 B3 的平均值。
对于我的第一次分析（时间 1），我想查看 9 个变量（A 和 B 及其子集）之间的相关性。我认为我应该使用（精确：相关性：双变量正态模型）运行 G*Power。
对于我的第二次分析（时间 1），我想查看 A 的哪些子集可以预测 B，基本上是一个回归模型。我认为我应该使用 (t 检验：线性双变量回归：两组，截距之间的差异) 运行 G*Power。
对于我的第三个分析（时间 1 和时间 2），我想看看我的治疗组与我的对照组相比从时间 1 到时间 2 的 B 是否有所改善。我认为我应该使用 G*Power，使用 (F 检验：ANOVA：重复测量，组内-组间相互作用)。
对于我的最后一个分析（时间 1 和时间 2），我只想查看我的治疗组，即在治疗 A 之后，A1、A2、A3 和 A4 的增益如何导致 B 的增益。我正在考虑 delta delta 分析，所以我不确定这个。
我的问题：

您认为我对这四个分析的选择有意义吗？您有什么建议吗？
我将为这四个 G*Power 获取不同的样本量，但如何确定我研究的最终样本量？我假设是最大的数字，但我不确定。

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653129/determine-the-sample-size-for-multiple-analyses</guid>
      <pubDate>Wed, 21 Aug 2024 15:38:18 GMT</pubDate>
    </item>
    <item>
      <title>使用引导法比较两种治疗方法时 P 值为 0</title>
      <link>https://stats.stackexchange.com/questions/653127/p-value-of-0-when-comparing-two-treatments-using-bootstrap-method</link>
      <description><![CDATA[我正在比较两种治疗方法，并进行 t 检验或 Wilcoxon 检验，我得到的 p 值 为 2.2e-16。
我想尝试引导，因为样本很大（超过 1000 个样本）并且长度不相等（300 个样本差异）。但是，当我尝试在 Rstudio 中运行此代码时，我将得到 p 值 为 0。这难道不是表明没有大于观察到的差异的值吗？这是否在告诉我，两种治疗方法是如此不同，以至于我甚至无法从比较中获得 p 值？
这是我正在运行的脚本的示例，数据集是虚拟数据，而不是实际数据，但它将导致相同的 p 值=0
set.seed(123)

# 虚拟数据集
dataset1 &lt;- rnorm(100, mean = 10, sd = 2)
dataset2 &lt;- rnorm(100, mean = 15, sd = 2)

combined_df &lt;- data.frame(
value = c(dataset1, dataset2),
group = factor(c(rep(&quot;Group1&quot;, length(dataset1)), rep(&quot;Group2&quot;, length(dataset2))))
)

# 数量观察值
n &lt;- length(combined_df$value)
# bootstrap 迭代次数
B &lt;- 10000

# Bootstrap
variable &lt;- combined_df$value
boots &lt;- matrix(sample(variable, size=n*B, replace=TRUE), nrow=n, ncol=B)

bootstat1 &lt;- numeric(B) # 表示平均差异
bootstat2 &lt;- numeric(B) # 表示中位数差异

# 观察到的差异
observed_means_diff &lt;- abs(mean(dataset1) - mean(dataset2))
observed_medians_diff &lt;- abs(median(dataset1) - median(dataset2))

# 循环计算 bootstrap 统计数据
for (i in 1:B) {
boot_sample &lt;- boots[, i]
bootstat1[i] &lt;- abs(mean(boot_sample[1:100]) - mean(boot_sample[101:200]))
bootstat2[i] &lt;- abs(median(boot_sample[1:100]) - median(boot_sample[101:200]))
}

# 计算 p 值
p_value_mean &lt;- mean(bootstat1 &gt;= perceived_means_diff)
p_value_median &lt;- mean(bootstat2 &gt;= perceived_medians_diff)

非常感谢您帮助我了解这里发生的事情]]></description>
      <guid>https://stats.stackexchange.com/questions/653127/p-value-of-0-when-comparing-two-treatments-using-bootstrap-method</guid>
      <pubDate>Wed, 21 Aug 2024 15:31:32 GMT</pubDate>
    </item>
    <item>
      <title>为时间序列预测添加约束</title>
      <link>https://stats.stackexchange.com/questions/653126/adding-a-constraint-to-time-series-forecasts</link>
      <description><![CDATA[我有 3 个变量：$X_t$、$Y_t$、$Z_t$
在我的原始数据中，对于所有 $t$：$Z_t$&gt; $Y_t$&gt; $X_t$
我想制作 3 个基本时间序列模型来预测这些变量中的每一个。
但是，在预测中，我想确保（即约束）在每个预测点 $t$，预测的 $Z_t$ 总是大于预测的 $Yt$ ，并且预测的 $Y_t$ 总是大于预测的 $X_t$。
我目前正在做一些这样的基本方法：
library(stats)
library(forecast)
library(ggplot2)

n &lt;- 100

var3 &lt;- rnorm(n, 平均值 = 10, sd = 2)
var2 &lt;- rnorm(n, 平均值 = var3 - 2, sd = 1.5)
var1 &lt;- rnorm(n, 平均值 = var2 - 2, sd = 1)

df &lt;- data.frame(var1 = var1, var2 = var2, var3 = var3, time = 1:n)

arima_var1 &lt;- auto.arima(df$var1)
arima_var2 &lt;- auto.arima(df$var2)
arima_var3 &lt;- auto.arima(df$var3)

forecast_var1 &lt;- Forecast(arima_var1, h = 12)
forecast_var2 &lt;- 预测(arima_var2, h = 12)
forecast_var3 &lt;- 预测(arima_var3, h = 12)

但是，我注意到在预测中，有时不遵守此约束。是否有某种方法可以强制预测遵守此约束？]]></description>
      <guid>https://stats.stackexchange.com/questions/653126/adding-a-constraint-to-time-series-forecasts</guid>
      <pubDate>Wed, 21 Aug 2024 15:28:37 GMT</pubDate>
    </item>
    <item>
      <title>如何正确报告交叉验证的结果，特别是标准差</title>
      <link>https://stats.stackexchange.com/questions/653125/how-to-properly-report-results-from-cross-validation-specifically-standard-devi</link>
      <description><![CDATA[这似乎是一个标准问题，但不幸的是，我还没有找到任何好的解释资源。
所以，我的情况如下。我想评估一个机器学习模型并报告其对未见数据的准确性。由于我的数据集非常小，我采用交叉验证。
一旦我获得了所有折叠的准确度值，我想报告这些值的平均值和标准差。
但是，互联网上的几个来源并不直接报告标准差。相反，他们倾向于先将标准差除以折叠数的平方根。
我没有找到任何关于为什么这样做的理由。]]></description>
      <guid>https://stats.stackexchange.com/questions/653125/how-to-properly-report-results-from-cross-validation-specifically-standard-devi</guid>
      <pubDate>Wed, 21 Aug 2024 15:27:19 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试寻找基线变化的标准差</title>
      <link>https://stats.stackexchange.com/questions/653122/i-am-trying-to-look-for-the-standard-deviation-of-change-from-baseline</link>
      <description><![CDATA[因此，我目前正在进行荟萃分析，需要找到与基线相比变化的标准差，因为我纳入的大多数研究都没有给出标准差。
我有基线和终点的平均值和标准差。
根据我在 Cochrane 上得到的信息，我需要估算相关系数才能找到变化的标准差，但我的量表在不同研究之间有所不同。
我的导师建议我做一个基线和终点的汇总标准差。
我应该按照导师的建议去做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653122/i-am-trying-to-look-for-the-standard-deviation-of-change-from-baseline</guid>
      <pubDate>Wed, 21 Aug 2024 14:38:15 GMT</pubDate>
    </item>
    <item>
      <title>多元成分数据模型之后该做什么？</title>
      <link>https://stats.stackexchange.com/questions/653121/what-to-do-after-the-multivariate-model-for-compositional-data</link>
      <description><![CDATA[我有一个简单的组合数据集（3 个测量值，必须加起来为 100%）。我知道如何进行 ILR 转换，然后我可以对治疗进行简单的多元回归。但接下来呢？据我所知，没有简单的方法可以将 ILR 转换矩阵与原始测量值关联起来。例如，我如何知道给定的治疗是否最终有利于结果 A 相对于结果 B 和 C 的相对优势？对于该领域的从业者来说，这种说法是合理的，而不仅仅是说治疗彼此不同。有没有一种方法可以将多元结果与原始组合集中的相对水平联系起来，这种方式比回归和回归不能准确描述的三重图更严格？]]></description>
      <guid>https://stats.stackexchange.com/questions/653121/what-to-do-after-the-multivariate-model-for-compositional-data</guid>
      <pubDate>Wed, 21 Aug 2024 14:26:24 GMT</pubDate>
    </item>
    <item>
      <title>根据样本预测唯一观测值总数 - R</title>
      <link>https://stats.stackexchange.com/questions/653120/predict-total-unique-observations-based-on-sample-r</link>
      <description><![CDATA[我有一组包含 N 个唯一元素的数据，这些元素可以重复任意次以得到 X 个总元素。
N 和 X 的值未知。
我有此数据的样本，并计算了样本总大小和样本中唯一元素总数。
为了了解样本的结构，我以一系列样本大小重复进行了子样本抽样，没有进行替换，并计算了唯一元素。
绘制在此处：

（红色 = 总样本，黑色 = 下采样。每个可见黑点实际上是 20 个重复）。
由此，我想在 R 中拟合一条超出 x 的观测值的曲线，以预测 y 的最大值（例如：数据集中唯一元素的总数，N）。
样本中的元素总数：185718411
样本中的唯一元素总数：51588754
下采样数据：
x=c(1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 1e+07, 2.5e+07, 2.5e+07, 2.5e+07, 
2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 
2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 
2.5e+07, 2.5e+07, 2.5e+07, 2.5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 
5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 
5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 
7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 7.5e+07, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 
1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 
1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1.25e+08, 1.25e+08, 
1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08,
1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 
1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.25e+08, 1.5e+08, 1.5e+08, 
1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 
1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.5e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08 , 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 1.75e+08, 
1.75e+08, 1.75e+08) y=c(8879407L, 8882853L, 8879146L, 8879963L, 8879973L, 8877565L, 8879535L, 8879441L, 8881377L, , 8880186L, 8879063L, 8881647L, 8879511L, 8881403L, 8878382L, 8879544L, 8881002L, 8880604L, 8880240L, 18927193L, 18924435L、18923731L、18920494L、18923974L、18923199L、18923360L、18923648L、18923131L、18922984L、18926592L、18924276L、1 8923680L、18923344L、18926252L、18921600L、18924428L、18928711L、18925935L、18922126L、30157610L、30155501L、30158640L、 30159612L, 30158025L, 30157679L, 
30154834L, 30159222L, 30160493L, 30157565L, 30158045L, 30157807L, 
30155821L, 30155840L, 30158622L, 30159742L, 30161088L, 30158046L, 
30159089L, 30155885L, 37409984L, 37400952L, 37402514L, 37408682L, 
37404248L, 37403547L、37401649L、37407739L、37405915L、37407328L、37402003L、37408206L、37398749L、37406762L、37401890L、37406383L、3 7404693L、37409054L、37403259L、37405316L、42387997L、42386810L、42386963L、42390976L、42390837L、42387186L、42387391L、 42385265L、42383010L、42392749L、42390451L、42390822L、42389636L、42389803L、42385593L、42390989L、42386302L、42389008L、4 2390049L、42386454L、45991832L、45992758L、45991351L、45993242L、45993277L、45990663L、45992366L、45992018L、45994867L、 45996211L、45992212L、45991838L、45991638L、45992517L、45993411L、45993444L、45992878L、45993934L、45993354L、45993045L、4 8707677L、48710261L、48705408L、48705354L、48706640L、48708658L、48708765L、48708926L、48707986L、48709516L、48705780L、 48708451L, 48707766L, 48711356L, 48708200L, 48707612L, 
48708961L, 48707509L, 48708770L, 48706288L, 50821205L, 50820451L, 
50819444L, 50821245L, 50821327L, 50820153L, 50819789L, 50821493L, 
50821043L, 50819115L, 50821689L, 50821538L, 50821014L, 50819974L, 
50821665L, 50819515L, 50820771L, 50819985L, 50820110L, 50819491L, 
51588754L)

我认为曲线的形状符合渐近回归，我研究过各种拟合方法，但我认为这并不是我想要的。
我知道对样本进行下采样并不等同于重复采样 - 但这是我所能获得的全部。因此，我必须基于（有效）假设，即考虑到样本的大小和重复的一致性，样本可以代表整个数据集。
我想对许多不同的数据集重复此操作，因此正在寻找一种可以一致应用的方法。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653120/predict-total-unique-observations-based-on-sample-r</guid>
      <pubDate>Wed, 21 Aug 2024 14:21:44 GMT</pubDate>
    </item>
    <item>
      <title>因变量零值，数据正确结构，零膨胀模型</title>
      <link>https://stats.stackexchange.com/questions/653115/zero-values-in-dependent-variable-correct-structure-of-the-data-zero-inflate</link>
      <description><![CDATA[我想了解宏观经济变量与特定基金（二级基金）募资量之间的关系。
我得到了以下数据集（假设一个表格：
1.
基金名称：
Abbott Secondary Opportunities III LP
募资日期：
06/2024
基金规模：
6200 万
2.
基金名称：
ABS Ventures VI, L.P.
募资日期：
01/2004
基金规模：
6400 万
...
我得到了 2000 年至 2024 年之间的 200 只其他基金。
作为独立变量，我选择了特定时期的利率水平、通货膨胀率、GDP 指数、IPO 数量和 sp500 指数。例如，我查找了 2024 年 6 月和 2004 年 1 月的利率水平以及另外 200 只基金的利率水平2000 年至 2024 年之间。
现在我不知道应该使用哪种类型的回归以及如何构建我的回归。
如果我进行月度回归，我将有 150 个零观测值作为因变量，因为根据数据，每个月都没有筹款，而有些基金在同一时期正在筹集资金。例如，对于 2024 年 6 月，我的因变量将是 6200 万，但对于 2024 年 5 月可能为零……
我可以删除零吗？我可以使用零膨胀模型吗？但我不知道您是否将这些数据视为计数数据？
或者建议使用以下结构？
我只包括获得筹款信息的月份（筹款&gt; 0），因此在这种情况下，我会直接从 06/2024 跳到 01/2004，因为在这两者之间它将是零（当然这个例子是夸张的，这两者之间有资金但不是每个月......）]]></description>
      <guid>https://stats.stackexchange.com/questions/653115/zero-values-in-dependent-variable-correct-structure-of-the-data-zero-inflate</guid>
      <pubDate>Wed, 21 Aug 2024 13:07:38 GMT</pubDate>
    </item>
    <item>
      <title>当风险差异如此容易解释时，为什么 Cohen's h 对于比较比例有用？</title>
      <link>https://stats.stackexchange.com/questions/653098/why-is-cohens-h-useful-to-compare-proportions-when-risk-difference-is-so-interp</link>
      <description><![CDATA[当风险差异如此易于解释时，为什么 Cohen&#39;s h 可用于比较比例？
我认为这与标准化不同比例量级的比较有关（例如，当 $p_{1}$ 和 $p_{2}$ 分别接近 0、接近 0.5 和接近 1 时，$p_{1}-p_{2}$）。
但我很难在脑海中将其形式化。]]></description>
      <guid>https://stats.stackexchange.com/questions/653098/why-is-cohens-h-useful-to-compare-proportions-when-risk-difference-is-so-interp</guid>
      <pubDate>Wed, 21 Aug 2024 05:46:44 GMT</pubDate>
    </item>
    <item>
      <title>计算 ED50 困难</title>
      <link>https://stats.stackexchange.com/questions/653100/difficulty-calculating-ed50</link>
      <description><![CDATA[我正在运行剂量探索研究分析，我们采用有偏差的上下硬币法来计算 ED50 和 ED90。由于某种原因，我无法计算 ED50，因为它显示为 NA。不过，我得到了 ED90 和 ED95 的值。
有什么建议吗？
我正在复制下面的代码
library(cir)
doseSequence&lt;- c(16.5, 16.5, 16.5, 16.5, 16.5, 18, 18, 18, 18, 18, 18, 18, 19.5, 19.5, 19.5, 19.5, 19.5, 19.5, 19.5, 19.5, 19.5, 19.5, 19.5, 21, 21, 21, 21, 21, 21, 21, 21, 22.5, 22.5, 22.5, 22.5, 22.5, 24, 24, 24, 25.5, 25.5, 25.5, 25.5)
responseSequence&lt;- c(1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1)
ed50&lt;- quickInverse(responseSequence, x=doseSequence, target = 0.5)
ed50

目标点 lower90conf upper90conf
1 0.5 NA -Inf Inf
]]></description>
      <guid>https://stats.stackexchange.com/questions/653100/difficulty-calculating-ed50</guid>
      <pubDate>Tue, 20 Aug 2024 05:32:12 GMT</pubDate>
    </item>
    <item>
      <title>纪元 (epoch) 与数据复制相同吗？</title>
      <link>https://stats.stackexchange.com/questions/653012/are-epochs-the-same-as-data-duplication</link>
      <description><![CDATA[时期，即对原始数据重复训练的次数，对于神经网络来说是绝对必要的，因为神经网络的参数通常比原始实例多得多。
对于具有许多参数的其他 ML 方法，使用时期的方法论地位是什么？它们是否用于（我称之为）类技术，如随机森林？通过“方法论地位”，我隐藏了我的真实意图。也就是说，为什么不将时期用于普通的逻辑回归或决策树？为什么不将每个额外的时期视为数据增强，但使用相同的实例？如果建议重复数据以减少偏差，我觉得任何统计学家都会感到恶心。 ML 建模者会毫不犹豫地无限期地增加 epoch，直到训练/测试准确率开始变差（甚至可能到那时也不会变差！）。
那么

在传统预测模型中使用 epoch（基本重复实例）可以吗（只要考虑到过度拟合？
另一方面，一个 epoch 是否应该成为 NN 训练的标准，或者更确切地说，使用重复数据作为增强技术是否存在各种统计问题？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653012/are-epochs-the-same-as-data-duplication</guid>
      <pubDate>Mon, 19 Aug 2024 14:12:29 GMT</pubDate>
    </item>
    <item>
      <title>回归中的独立指标变量在改变类别数量时变得显著</title>
      <link>https://stats.stackexchange.com/questions/653011/independent-indicator-variable-in-regression-becomes-significant-when-changing-t</link>
      <description><![CDATA[我正在使用二元响应变量运行逻辑回归。无论是否使用家庭作为指示变量，家庭本身都会产生微小的正向但不显著的影响。
当将家庭规模视为具有 3 个级别的分类变量（单户、中型或大型家庭）来检查其是否有影响时，与排除的类别（单户）相比，两个包含的虚拟变量都具有很强的显著性和正向性。为什么会这样？
假设不仅家庭本身会对结果产生积极影响，而且家庭规模也会产生积极影响。我将家庭规模也视为分类，因为它在数据集中只能采用 7 个不同的值。
（数据集包含 425 000 个个体，每个个体没有重复测量，但不幸的是总共只有 7 个预测因子。但感兴趣的结果（编码为 1，另一个类别为 0）是罕见事件（仅 0.3%），因此数据严重不平衡。
425 000 人中有 43% 属于一个家庭。但家庭户主导了感兴趣的结果案例 - 属于结果 = 1 的 69% 属于家庭户。
在 3 个类别中；数据集中所有 425 000 人中有 243 000 人属于单个家庭（57%），30% 属于中型家庭，只有 13% 属于大家庭。
然而，在属于感兴趣的现金结果的人群中，大家庭现在占32%，中等家庭占 37%，单身占 31%。）
Family_account 的系数为 0.2221，但 p 值为 0.29。
相比之下，在使用家庭规模的模型中，Medium_Family 的系数为 0.4366，Large_family 的系数为 1.6255 - 两者的 p 值均小于 0.000。
非常感谢您的帮助，br]]></description>
      <guid>https://stats.stackexchange.com/questions/653011/independent-indicator-variable-in-regression-becomes-significant-when-changing-t</guid>
      <pubDate>Mon, 19 Aug 2024 13:47:05 GMT</pubDate>
    </item>
    </channel>
</rss>