<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 29 Jan 2024 21:12:01 GMT</lastBuildDate>
    <item>
      <title>显示分层和回归之间等效性的示例</title>
      <link>https://stats.stackexchange.com/questions/638058/example-showing-equivalence-between-stratification-and-regression</link>
      <description><![CDATA[在回归中使用对照来估计治疗对结果的影响背后的直觉的一种方式是分层。当控制 Z 时，我们会查看具有相似 Z 水平的观测值之间 X 和 Y 之间的关系，如 此处
&lt;块引用&gt;
最简单的方法（也是您提出的）是对数据进行分层，以便获得具有相似特征的子组 - 然后可以使用一些方法将这些结果汇总在一起以获得单个“答案”。如果您想要控制的变量数量非常少，那么这种方法是有效的，但正如您所正确发现的那样，当您将数据分割成越来越小的块时，这种方法很快就会崩溃......一种更常见的方法是包括您想要在回归模型中控制的变量...您将得到的估计...将是其他协变量水平内不耐烦的影响 - 回归允许您基本上平滑没有太多数据的地方（分层方法的问题），尽管应该谨慎行事。

我一直在努力使用模拟数据在 R 中设计一个示例，以显示分层和回归之间的等价性。也就是说，您可以得到相同的答案，要么控制 Z，要么仅在 Z = 0 或 Z = 1 之间拟合 X 和 Y 之间的模型（另一个问题：这会产生两个估计；如何组合？）
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/638058/example-showing-equivalence-between-stratification-and-regression</guid>
      <pubDate>Mon, 29 Jan 2024 20:50:18 GMT</pubDate>
    </item>
    <item>
      <title>独立条件下 Kendall tau 的精确采样分布（无关系情况）</title>
      <link>https://stats.stackexchange.com/questions/638057/exact-sampling-distribution-of-kendalls-tau-under-independence-no-ties-case</link>
      <description><![CDATA[我正在寻找一个 R 包，用于在独立性零假设下计算样本 Kendall&#39;s tau (*) 的 CDF 和逆 CDF，没有关系的情况下。
(*) 需要明确的是，我指的是测量随机样本的一致性或单调相关性的统计 $\hat{\tau}$ &lt;双变量连续随机变量的 span class=&quot;math-container&quot;&gt;$\{(X_1, Y_1), \dots, (X_n,Y_n)\}$ $ (X,Y)$，假设 $X$ 和 $Y$ 是独立的.
到目前为止我找到的唯一包是SuppDists。它提供了函数dKendall、pKendall、qKendall和rKendall。在文档中，它说：
&lt;块引用&gt;
计算值对于 $n &lt;&lt; 13$，此后使用埃奇沃斯展开。

更准确地说，对于 $n$ 的小值，似乎精确的计算是按照 Hajek &amp;西达克（1967，第 140 页）。我通过阅读底层 C 代码发现了这一点。如果我没记错的话，它引用了一个递归公式（我没有 1967 年的版本，但有更新的版本）。
无论如何，有人知道有一个包可以实现样本 Kendall tau 的 CDF 和逆 CDF 的精确计算，以获取 $n$?
&lt;小时/&gt;
参考文献
哈耶克·J、西达克·Z (1967)。等级检验理论。学术出版社，纽约。]]></description>
      <guid>https://stats.stackexchange.com/questions/638057/exact-sampling-distribution-of-kendalls-tau-under-independence-no-ties-case</guid>
      <pubDate>Mon, 29 Jan 2024 20:48:45 GMT</pubDate>
    </item>
    <item>
      <title>即使在高n时也记录所有影响因素？</title>
      <link>https://stats.stackexchange.com/questions/638056/record-all-influential-factors-even-at-high-n</link>
      <description><![CDATA[我的任务是评估鱼类捕食者（水獭）对自然水体中鱼类丰度的影响。虽然该国部分地区的水獭数量已经非常丰富，但预计整个地区的数量很快就会迅速扩大。理想情况下，我希望通过在许多不同水体中进行电捕鱼，以标准化方式监测目前未受水獭影响的鱼类种群，同时监测水獭的存在，并持续几年，直到水獭到达所有（或大多数）水体。所以我会得到很好的前后数据，甚至可能是控​​制。然而，财务限制不允许此类数据。
相反，我想到招募钓鱼者来提供全国不同地区的渔获量和努力量数据。理想情况下，假设来自不同地点的 100 名钓鱼者提供以下数据：
名称、水体、日期、水獭的存在、捕捞时间、捕获的鱼数量。
然后我可以应用 GLMM，如下所示：
捕获的鱼数 ~ 水獭的存在 + 偏移量（捕捞小时数）+ (1|水体) + (1|日期) + (1|名称)
然而，我没有考虑到这样一个事实：还有许多其他因素影响着我的渔获量（我的丰度指标）：在某些水体中，每年的鱼类放养数量各不相同。然后可能还有其他捕食者影响鱼类的丰度。洪水或热浪会对鱼类丰度产生负面影响。虽然我无法记录所有水体的所有这些指标。
我的问题如下：
假设只要调查的水体数量很高（假设 n = 50），并且没有理由假设影响鱼类丰度的任何其他变量（其他捕食者、高温、洪水、放养……）是否合适？ ）与水獭的存在系统地共同变化，因此可能不需要记录它们，并且仍然能够就水獭单独的影响得出结论？
非常感谢您对我的问题提供反馈😊
菲尔]]></description>
      <guid>https://stats.stackexchange.com/questions/638056/record-all-influential-factors-even-at-high-n</guid>
      <pubDate>Mon, 29 Jan 2024 20:45:44 GMT</pubDate>
    </item>
    <item>
      <title>Bootstrap 置信区间：证明正确性</title>
      <link>https://stats.stackexchange.com/questions/638053/bootstrap-confidence-intervals-proving-correctness</link>
      <description><![CDATA[我正在研究使用引导技术来计算感兴趣参数的置信区间。
设 $\textbf{Z}_1, ... \textbf{Z}_n\in\mathbb{R}^d$ 为 (iid)随机抽样。从这个随机样本中，我们计算 $\hat{\theta}$ 参数（很难明确地表达）。我想获取此参数的 CI。
我使用基本的引导技术。这涉及从我们的随机样本中进行随机抽样和替换，以生成多个引导样本，每个样本都与原始数据集的大小相匹配。对于每个引导样本，我计算统计量 $\hat{\theta}^\star$ 的估计值。随后，我们确定重新采样统计数据的 $95%$ 分位数，以得出置信区间。我想证明他们的渐近正确性。有一些我可以使用的一般结果吗？我只发现使用 Berry-Essen 定理对 $\theta$=mean 进行理论论证，但我的统计 $\theta$&lt; /span&gt; 要复杂得多。
总之，我想证明这样的事情：
定理
令 $\hat{\theta}$ 为估计量（来自样本大小 $n$） $\theta$ 并让 $\mathbb{E}||\textbf{Z}||^2&lt;\infty $.
将原始样本的重采样表示为 $(\textbf{Z}^\star_{1,1}, \dots \textbf{Z}^\star_{1, n}),\dots, (\textbf{Z}^\star_{B,1}, \dots, \textbf{Z}^\star_{B,n})$，以及相应的估计值 $\hat{\theta}_1^\star, \dots, \hat{\theta}_B^\star$ 为 $ B\in\mathbb{N}$。
让 $U:=\hat{\theta}_{(\alpha)}^\star$ 代表 $B(1-\alpha)$ $\hat{\theta}_1^\star、\dots、\hat{\theta}_B 中的最大值^\star$.
那么，
$$\lim_{n\to\infty}\lim_{B\to\infty}P(\hat{\theta}]]></description>
      <guid>https://stats.stackexchange.com/questions/638053/bootstrap-confidence-intervals-proving-correctness</guid>
      <pubDate>Mon, 29 Jan 2024 20:23:03 GMT</pubDate>
    </item>
    <item>
      <title>BERT 的均值池化是否需要使用注意力掩模？</title>
      <link>https://stats.stackexchange.com/questions/638049/is-it-necessary-to-use-attention-mask-for-mean-pooling-for-bert</link>
      <description><![CDATA[我正在开展一个项目，涉及使用“emilyalsentzer/Bio_ClinicalBERT”分析临床文本。来自 Hugging Face 变形金刚库的模型。我的目标是从模型中提取有意义的句子嵌入以用于下游任务。我知道 BERT 嵌入的几种池化策略，但我不确定哪种策略对我的特定用例最有效。
普遍的方法是使用 CLS 令牌进行嵌入。然而，受到最近一篇使用均值池和最佳层选择算法的论文的启发，我&#39;一直在考虑最后一个隐藏状态层的平均池化。许多存储库的常见做法是直接计算最后一层的平均值。但我相信，这可能会忽略一个关键方面：注意力面具。
直观上，在池化之前，首先将最后一个隐藏状态与注意掩码相乘，有效地过滤掉填充序列似乎更准确。根据我的理解，这将确保只有重要的令牌嵌入才会对平均值做出贡献。
这种将注意力掩模纳入均值池的修改方法是否比典型的直接均值计算更有效？我正在寻求有关此方法是否提高下游应用程序嵌入质量的见解。代码示例
导入 torch.nn 作为 nn
从 Transformer 导入 AutoModel、AutoTokenizer

项目_dim = 512
bert_model = AutoModel.from_pretrained(“emilyalsentzer/Bio_ClinicalBERT”，output_hidden_​​states=True)
tokenizer = AutoTokenizer.from_pretrained(“emilyalsentzer/Bio_ClinicalBERT”)
tokenizer.model_max_length = 256
projection_head = nn.Linear(768, proj_dim)

defmean_pooling(model_output,attention_mask):
    token_embeddings = model_output[0] # model_output 的第一个元素包含所有 token 嵌入
    input_mask_expanded=attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    返回 torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)

# 用法示例
输出= bert_model（input_ids=input_ids，attention_mask=attention_mask）
嵌入=mean_pooling（输出，attention_mask）
]]></description>
      <guid>https://stats.stackexchange.com/questions/638049/is-it-necessary-to-use-attention-mask-for-mean-pooling-for-bert</guid>
      <pubDate>Mon, 29 Jan 2024 19:58:48 GMT</pubDate>
    </item>
    <item>
      <title>仅一组的线性混合效应模型的截距的解释是什么</title>
      <link>https://stats.stackexchange.com/questions/638048/whats-the-interpretation-of-the-intercept-of-a-linear-mixed-effect-model-with-o</link>
      <description><![CDATA[我试图理解线性混合模型中截距项的含义。这里需要注意的是，LME 所基于的数据集将仅包含来自单个类别（组）的受试者。所有科目都会有技术重复，有些比其他更多。因此，公式如下：
$y = B0 + (1|\text{subject})$
主题是随机效应（考虑主题内方差），y 是响应变量，B0 是截距。我在进行一些先前搜索时的理解是，这可以被解释为“平均模型”，其中“平均”是一个“平均模型”。是B0。然而，这是在线性模型的背景下，而不是线性混合效应模型。
因此，我想知道是否有人可以帮助阐明 B0 在这种情况下的含义（特别是考虑到数据集仅由来自一个类（组）的受试者组成这一事实），以及它是否是一种有效的方法获得“群体代表值”。例如，我在两个单独的组（组 $A$ 和组 $B$）上运行上述 LME这样我现在就有了
$B_{0_A} $ 和 $B_{0_B} $
考虑到上述组代表值没有通过经典平均方法进行量化，那么使用上述组代表值进行统计测试是否有效？为了澄清起见，我还将使用所用算法的 B0_A 和 B0_B 的标准误差（MATLAB 中的 fitlme）]]></description>
      <guid>https://stats.stackexchange.com/questions/638048/whats-the-interpretation-of-the-intercept-of-a-linear-mixed-effect-model-with-o</guid>
      <pubDate>Mon, 29 Jan 2024 19:54:18 GMT</pubDate>
    </item>
    <item>
      <title>如何计算伽马分布的分位数？</title>
      <link>https://stats.stackexchange.com/questions/638047/how-to-calculate-quantiles-for-a-gamma-distribution</link>
      <description><![CDATA[我想计算伽马分布的分位数。我发现了一个所谓的示例此处给出为
$$\text{分位数}(a, b, p) = \frac{\gamma^{-1}(a, \Gamma(a) p )}{ b}$$
其中 $\gamma^{-1}$ 是下不完全伽玛函数的反函数，$\Gamma $是伽马函数。
在 SciPy 中尝试这一点，我发现对于许多值，我得到了 nan，这表明数字出现了问题。
from scipy.special import (gammaincinv, gamma as gamma_function)

def gamma_quantile_function(a, b, p):
    
    返回 gammaincinv(a, gamma_function(a) * p) / b

gamma_quantile_function(3.8756542398707046, 5349.756221, 0.99) # 返回 `nan`

只是我的实现有问题，还是数学错误？]]></description>
      <guid>https://stats.stackexchange.com/questions/638047/how-to-calculate-quantiles-for-a-gamma-distribution</guid>
      <pubDate>Mon, 29 Jan 2024 19:36:42 GMT</pubDate>
    </item>
    <item>
      <title>如何控制社区数据的 permanova 中的随机效应（如受试者）</title>
      <link>https://stats.stackexchange.com/questions/638046/how-to-control-for-random-effects-like-subject-in-permanova-for-community-data</link>
      <description><![CDATA[抱歉，如果这是一个重复的问题。我找不到这个问题的答案。
我有一些布雷-柯蒂斯、未加权 unifrac 和加权 unifrac 的微生物群落数据。我的实验包括两个时间点，一个安慰剂和一个治疗。这是一项交叉研究，因此每个参与者都有两个样本，一个安慰剂，一个治疗。我想看看治疗组和安慰剂组在β多样性方面是否存在差异。为此，我有一个这样的模型-
permanova &lt;- adonis2(bray_curtis_dist ~ 治疗+序列+治疗:序列+年龄+BMI，排列= 999，层=受试者，
方法=“布雷”）
我使用分层来控制主体是否正确？通常在混合模型中，我会将 subject 作为随机效应包括在内，但 permanova 不包括这些（至少据我所知）。如果我包括 strata=Subject，我会得到显着的结果。如果不这样做，我得到的 p 值为 0.98。有人能解释一下它在做什么吗？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/638046/how-to-control-for-random-effects-like-subject-in-permanova-for-community-data</guid>
      <pubDate>Mon, 29 Jan 2024 19:15:54 GMT</pubDate>
    </item>
    <item>
      <title>Cronbach alpha - 描述性统计</title>
      <link>https://stats.stackexchange.com/questions/638045/cronbach-alpha-descriptive-statistics</link>
      <description><![CDATA[我根据斯滕伯格的投资理论研究了思维方式。我使用了 TSI 问卷来衡量思维方式的偏好。问题是我在某些类型的思维方式上的克伦巴赫阿尔法得分很低。例：思维方式的局部类型，包含六项，为0,545；君主风格 (7 项) 0,638;寡头 (6 项) 0,636;无政府主义 (7 项) 0,647; global ( 6 项) 0, 648。共有 13 个量表，其中 6 个量表的 Cronbach α 系数较低。
我该怎么办？这该如何解释呢？这是否意味着我的研究结果无效？
我使用Pearson&#39;s r来计算量表之间的相关性，它显示了量表之间良好的相关性。我该如何解释这些结果？
我希望我说得足够清楚，因为我的英语不太好。 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/638045/cronbach-alpha-descriptive-statistics</guid>
      <pubDate>Mon, 29 Jan 2024 19:11:59 GMT</pubDate>
    </item>
    <item>
      <title>我应该在数据开始时表明实验运行“成功”吗？</title>
      <link>https://stats.stackexchange.com/questions/638044/should-i-indicate-success-of-an-experimental-run-at-the-beginning-of-the-data</link>
      <description><![CDATA[因为我就是那个人，所以我想对一些实验的结果进行一些统计分析；具体来说，我想跟踪回合制策略游戏 The Battle of Polytopia 的不同运行进度完美模式，以尝试开发预测模型。
在完美模式下，您有 30 个回合的时间来获得最高分。在游戏的任何时刻，你的分数都是已知的，所以我的想法是，在每个回合结束时，我将跟踪：

哪个回合结束
我控制了多少个城市
我有多少积分
我将在下一回合开始时获得多少颗星星（货币单位）

暂时搁置收集足够的数据以建立有价值的模型所需的时间，我的问题是：除了获取不断变化的逐向数据之外，我还将跟踪我正在使用哪个部落，以及在特定运行结束时我的分数是否超过二进制编码值的特定值（50,000、75,000 和 100,000 分）（0 表示没有，1 表示做过）；作为健全性检查，那些不变的值在每次运行开始时应该是相同的，是吗？比如，对于分数检查数据列，它们不应该是 0，直到超过特定分数，然后切换到 1，对吗？
我觉得这有点简单，但我只需要进行健全性检查。]]></description>
      <guid>https://stats.stackexchange.com/questions/638044/should-i-indicate-success-of-an-experimental-run-at-the-beginning-of-the-data</guid>
      <pubDate>Mon, 29 Jan 2024 18:57:44 GMT</pubDate>
    </item>
    <item>
      <title>调解包：如何更改[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638039/mediation-package-how-to-change</link>
      <description><![CDATA[遵循中介包中的小插图 ,
我的目标是计算不同的兴趣对比。（参见3.3.非二元治疗变量中的示例）。
我想知道如何更改“control.value”的值和“treat.value”选项：
med.fit &lt;- lm(MIST_3 ~ CONDITION2，数据 = 条目)
out.fit &lt;- glm(CAP1 ~ MIST_3, 数据 = 条目)
med.out &lt;- mediate(med.fit, out.fit, treat = “CONDITION2”, mediator = “MIST_3”,
control.value =“条件2” == &#39;2&#39;, treat.value = &quot;CONDITION2&quot;; ==&#39;3&#39;，模拟= 100）

变量“CONDITION2”有 3 个级别（1、2、3）。示例脚本尝试将级别“2”与级别“2”进行比较。和“3”。但我收到以下错误：
[.data.frame(y.data, , treat) 中出现错误：选择了未定义的列
数据结构：
]]></description>
      <guid>https://stats.stackexchange.com/questions/638039/mediation-package-how-to-change</guid>
      <pubDate>Mon, 29 Jan 2024 17:41:43 GMT</pubDate>
    </item>
    <item>
      <title>测试面板数据的序列相关性</title>
      <link>https://stats.stackexchange.com/questions/638038/test-serial-correlation-for-panel-data</link>
      <description><![CDATA[我有一组面板数据（包括变量 X1、X2、X3. 和 N=193；T=22），这些变量在模型中用作自变量。我想检查每个变量的自相关性（例如：变量X在研究期间是否具有序列相关性？），我应该使用什么方法？可以使用ARMA方法吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/638038/test-serial-correlation-for-panel-data</guid>
      <pubDate>Mon, 29 Jan 2024 17:32:17 GMT</pubDate>
    </item>
    <item>
      <title>Cox 多状态模型 - 置信区间</title>
      <link>https://stats.stackexchange.com/questions/638037/cox-multi-state-model-confidence-intervals</link>
      <description><![CDATA[是否可以获得survival::coxph多状态模型的置信区间？
此代码生成累积发生函数，但没有选项来获取置信区间：
图书馆（生存）

# 0 = 审查，1 = 复发，2 = 死亡
鹿特丹$status = ifelse(鹿特丹$recur == 1, 1,
                          ifelse(鹿特丹$death == 1, 2, 0))
鹿特丹$时间 = pmin(鹿特丹$rtime, 鹿特丹$dtime)

# 竞争风险 Cox 模型
m = coxph(Surv(时间, as.factor(状态)) ~ 激素, 数据 = 鹿特丹, id = pid)

# 绘制未接受激素替代治疗的患者的 CIF
s = survfit(m, newdata = data.frame(激素 = c(0)))
plot(s) # 绘制 s$pstate[, 1, ] 与时间的关系图


如果需要的话，我很乐意使用不同的包，但它必须是 Cox 模型&amp;不是细灰色模型。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/638037/cox-multi-state-model-confidence-intervals</guid>
      <pubDate>Mon, 29 Jan 2024 17:25:07 GMT</pubDate>
    </item>
    <item>
      <title>抽样误差和测量误差有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/638036/what-is-the-difference-between-sampling-error-and-measurement-error</link>
      <description><![CDATA[统计领域中的术语“抽样误差”和“测量误差”非常相关，对于数据分析和报告至关重要。]]></description>
      <guid>https://stats.stackexchange.com/questions/638036/what-is-the-difference-between-sampling-error-and-measurement-error</guid>
      <pubDate>Mon, 29 Jan 2024 17:20:00 GMT</pubDate>
    </item>
    <item>
      <title>功效和效应大小如何帮助我解释 A/B 测试结果？</title>
      <link>https://stats.stackexchange.com/questions/638032/how-can-power-and-effect-size-help-me-interpret-my-a-b-test-results</link>
      <description><![CDATA[为了了解我的用例，我使用两个样本 t 检验来执行 A/B 测试，以比较对照样本和处理样本之间的平均值。
我设置了$\alpha=0.05$。我设置效果大小 $d=0.01$ 和 power=0.80。然后，使用幂求解器，我得到 $n=156978$。我了解功效、效果和 Alpha 可以帮助我定义样本大小。
然后，我收集数据并计算 p 值。现在我可以做出决定：如果 p-value&lt;$\alpha$，那么我可以拒绝 $H_{0} $；如果不是，那么我无法拒绝 $H_{0}$。显然，$\alpha$ 有一个目的：决定我的测试结果。
但是，功效和效果大小的目的是什么？
功效和效应大小不会影响 p 值：我可以任意增加或减少功效和效应大小（并保持恒定 $n$）；它不会改变 p 值，因此对测试结果没有影响。
所以也许他们可以帮助解释测试结果（例如，给我一些测试正确的概率或其他什么？）。 power=0.80 告诉我，假设我选择的效应大小是真实的效应大小，则拒绝 $H_{0}$ 的概率为 80%。但在现实生活中，我们永远无法知道情况是否如此（如果我们知道我们一开始就不会进行测试），那么它有什么帮助呢？
问题：我很难理解如何根据我选择的功效和效果大小来解释我的测试结果。除了“我需要它们插入我的电源解算器”之外。事实上，它们可以帮助我以某种方式解释我的测试结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/638032/how-can-power-and-effect-size-help-me-interpret-my-a-b-test-results</guid>
      <pubDate>Mon, 29 Jan 2024 16:26:12 GMT</pubDate>
    </item>
    </channel>
</rss>