<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 11 Oct 2024 12:32:34 GMT</lastBuildDate>
    <item>
      <title>有效影响功能的干预措施取决于暴露的自然价值</title>
      <link>https://stats.stackexchange.com/questions/655646/efficient-influence-function-with-interventions-that-depend-on-the-natural-value</link>
      <description><![CDATA[图 A1 显示了 SWIG，其中 L 是暴露 X 和结果 Y 之间关联的混杂因素。

我正在处理对 X 的干预，该干预根据其自然值对其进行修改（例如，不是每个人都设置为 1 的确定性静态方案）。例如，如果 X 的自然值为 2，则将其降低为 1，否则保持原样。感兴趣的因果效应（g 公式）定义如下（为了便于表示，我将干预节点表示为 $\tilde{x}$，而不是用红色标记）：
\begin{equation}
\Psi = \sum_{l, x, \tilde{x}} E \left[ Y | X = \tilde{x}, L=l \right] p \left( X = \tilde{x} | X=x, L=l \right) p \left( X=x | L=l \right) p(l)。
\label{eq:swig_1e1t_n}
\end{equation&gt;
我想构建一个双重稳健估计量，特别是增强逆概率加权 (AIPW) 估计量。因此，我想写下我的因果参数的有效影响函数 (EIF)。我遵循 Kennedy 2023 中的提示（此处）。为了便于表示，我将定义 $\mu(x,l) = E \left[ Y | X=x, L=l \right]$ 和 $\pi(x|l) = p \left( X=x | L=l \right)$。 EIF ($\mathbb{IF}$) 可以写成如下形式：
\begin{align}
\mathbb{IF}{(\Psi)} &amp;= \sum_{l, x, \tilde{x}} \mathbb{IF}{\left\{ \mu(\tilde{x},l) \right\}} p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) p(l) + \mu(\tilde{x},l) p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) \mathbb{IF}{\left\{ p(l) \right\}}.
\label{eq:swig_1e1t_n_eif}
\end{align&gt;
对于 EIF 求和中的第一个项，我们有：
\begin{align}
\mathbb{IF}{(\Psi)}_1 &amp;= \sum_{l, x, \tilde{x}} \frac{\mathbb{1}(X=\tilde{x}, L=l)}{p(X=\tilde{x}, L=l)} \left\{ Y^{\tilde{x}} - \mu(\tilde{x},l) \right\} p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) p(l) \nonumber \\
&amp;= \sum_{x} \frac{p \left( \tilde{X} | X=x, L \right) \pi(x|L)}{\pi(\tilde{X} | L)} \left\{ Y^{\tilde{x}} - \mu(\tilde{X},L) \right\}。
\end{align&gt;
对于 EIF 求和中的第二项，我们有：
\begin{align}
\mathbb{IF}{(\Psi)}_2 &amp;= \sum_{l, x, \tilde{x}} \mu(\tilde{x},l) p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) \left\{ \mathbb{1}(L=l) - p(l) \right\} \nonumber \\
&amp;= \sum_{x, \tilde{x}} \mu(\tilde{x},L) p \left( X = \tilde{x} | X=x, L \right) \pi(x|L) - \sum_{l, x, \tilde{x}} \mu(\tilde{x},L=l) p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) p(L=l) \nonumber \\
&amp;= \sum_{x, \tilde{x}} \mu(\tilde{x},L) p \left( X = \tilde{x} | X=x, L \right) \pi(x|L) - \Psi.
\end{align&gt;
将它们放在一起，我们得到：
\begin{equation}
\mathbb{IF}{(\Psi)} + \Psi = \sum_{x} \frac{p \left( \tilde{X} | X=x, L \right) \pi(x|L)}{\pi(\tilde{X} | L)} \left\{ Y^{\tilde{x}} - \mu(\tilde{X},L) \right\} + \sum_{x, \tilde{x}} \mu(\tilde{x},L) p \left( X = \tilde{x} | X=x, L \right) \pi(x|L)。
\label{eq:swig_1e1t_n_eif_derived}
\end{equation&gt;
Kennedy 2023 的评论中没有类似的例子，最接近的是随机干预。我正在将获得的 EIF 与此处找到的 EIF 进行比较，特别是第 15 页最后一段中写的 EIF：
\begin{equation}
r(A,L) (Y - m(A,L)) + m(\mathbb{d}(A,L), L) - \theta,
\end{equation&gt;
其中 $\theta$ 是感兴趣的参数，$r$ 是第 15 页顶部定义的密度比，$m$ 是给定暴露和混杂因素的预期结果。作者使用函数 $\mathbb{d}$ 来定义暴露干预。很明显，我的 EIF 和他们的并不相同，尽管相似。一个关键的区别是，在我的密度比（EIF 总和中的第一个项）中，$\tilde{X}$ 同时存在于分子和分母中。我不确定 EIF 的推导中是否存在错误，还是 g 公式本身存在错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/655646/efficient-influence-function-with-interventions-that-depend-on-the-natural-value</guid>
      <pubDate>Fri, 11 Oct 2024 11:34:19 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中拟合一个分布，平均值是一些变量的线性组合</title>
      <link>https://stats.stackexchange.com/questions/655644/fit-a-distribution-in-r-with-the-mean-as-a-linear-combination-of-some-variable</link>
      <description><![CDATA[我想将 PDF 拟合到我的数据（最好是 Gamma），但我想使形状 $k$（或比例 $\theta$）线性依赖于某个外部变量 $t$：$k=a+bt$，其中 $a, b$ 系数待定。
奇怪的是，我知道如何使用 extRemes 对极值分布执行此操作，但我不知道如何在更一般的环境中执行此操作。也许这很简单，我不知道，我对 R 还比较陌生。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655644/fit-a-distribution-in-r-with-the-mean-as-a-linear-combination-of-some-variable</guid>
      <pubDate>Fri, 11 Oct 2024 11:17:10 GMT</pubDate>
    </item>
    <item>
      <title>从未知分布估计概率值大于 x</title>
      <link>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknow-distribution</link>
      <description><![CDATA[假设我们有 N 个项目的总体，其值从 0 到 6000。
假设总体的平均值是 $\mu$。
我们不知道项目的分布。
我们从这个总体中提取一个项目，我们如何估计 $P(x\geq 2500)$？
同样的问题，假设分布是均匀的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknow-distribution</guid>
      <pubDate>Fri, 11 Oct 2024 08:52:55 GMT</pubDate>
    </item>
    <item>
      <title>使用高斯过程生成的二进制序列之间的相关性度量</title>
      <link>https://stats.stackexchange.com/questions/655641/measure-of-correlation-between-binary-sequences-that-were-generated-using-a-gaus</link>
      <description><![CDATA[为了进行实验，我需要构建一个长度为 T 的 n 个二进制序列集合。
n=3 且 T=20 的示例：
$
\begin{bmatrix}
0&amp;1&amp;1&amp;0&amp;0&amp;1&amp;0&amp;1&amp;1&amp;0&amp;1&amp;0&amp;0&amp;1&amp;1&amp;0&amp;0&amp;1&amp;1&amp;0&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0&amp;1&amp;0&amp;1 \\
0&amp;1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;1&amp;0&amp;0&amp;1&amp;0&amp;0&amp;1 \\
1&amp;0&amp;1&amp;0&amp;0&amp;1&amp;1&amp;0&amp;0&amp;1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0
\end{bmatrix}
$
我使用高斯过程创建了上述序列，每个序列都有一个唯一的协方差矩阵。然后，我根据预定的 1 百分比（每个序列可能有所不同）确定了一个阈值。现在，我想找到这三个（或 n 个）序列之间的互相关。我的目的是使用具有类似核函数的高斯过程从 n 个序列中创建 x 个序列以产生相关性。拥有互相关度量将有助于我注意到在每个序列上运行时某种算法的行为。]]></description>
      <guid>https://stats.stackexchange.com/questions/655641/measure-of-correlation-between-binary-sequences-that-were-generated-using-a-gaus</guid>
      <pubDate>Fri, 11 Oct 2024 08:29:40 GMT</pubDate>
    </item>
    <item>
      <title>聚类数据的 BCa Bootstrap 置信区间</title>
      <link>https://stats.stackexchange.com/questions/655640/bca-bootstrap-confidence-intervals-for-clustered-data</link>
      <description><![CDATA[我想计算机器学习模型在测试数据上对血细胞进行分类的 F1 分数的置信区间。数据是聚类的，因为我每个病人都有多个细胞。我的计划是计算偏差校正和加速 (BCa) 引导置信区间。为此，我需要

引导测试数据
使用折刀法计算加速因子

我的问题是：在引导和折刀法期间，我应该在哪个级别重新采样数据？
以下是我正在考虑的选项：

患者级别：引导患者；为刀切法留出一名患者
细胞级别：在观察级别上通常使用引导/刀切法
患者级别和细胞级别：引导患者，对于每个引导患者，从该患者中引导细胞；对于刀切法，这种方法似乎不切实际，因为它会简化为通常的刀切法（留出一个观察值）。

我的直觉建议在患者级别重新采样，以避免低估测试数据的方差。但是，我正在寻找可靠的参考或论据来支持这一选择，尤其是对于刀切法。
有人可以提供指导或文献参考，说明为什么在患者级别重新采样可能是更好的选择，尤其是对于刀切法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655640/bca-bootstrap-confidence-intervals-for-clustered-data</guid>
      <pubDate>Fri, 11 Oct 2024 08:09:39 GMT</pubDate>
    </item>
    <item>
      <title>如何对 4(1 + x2)−1/π, 0<x<1 进行逆变换以实现重要性采样</title>
      <link>https://stats.stackexchange.com/questions/655632/how-to-inverse-transform-41-x2%e2%88%921-%cf%80-0x1-for-importance-sampling</link>
      <description><![CDATA[示例 5.10 使用 R (Rizzo) 进行统计计算 
使用重要性抽样估计以下内容 
$$\int_{0}^{1}\frac{e^{-x}}{1+x^2}$$
u &lt;- runif(m) #f4，逆变换方法
x &lt;- tan(pi * u / 4)
fg &lt;- g(x) / (4 / ((1 + x^2) * pi))
theta.hat &lt;- mean(fg)
se &lt;- sd(fg)

\begin{align}f_4(x)&amp;=\frac{4(1+x^2)^{-1}}{\pi},&amp;&amp; 0&lt;x&lt;1\\
u&amp;=\frac{4(1+x^2)^{-1}}{\pi}\\
u\pi&amp;=\frac{4}{(1+x^2)}\\
u\pi(1+x^2)&amp;=4\\
1+x^2&amp;=\frac{4}{u\pi}\end{align&gt;
1 去哪儿了？ tan 如何将 $x^2=\frac{4}{u\pi}$ 转换为 $x=tan\left(\frac{u\pi}{4}\right)$]]></description>
      <guid>https://stats.stackexchange.com/questions/655632/how-to-inverse-transform-41-x2%e2%88%921-%cf%80-0x1-for-importance-sampling</guid>
      <pubDate>Fri, 11 Oct 2024 03:48:09 GMT</pubDate>
    </item>
    <item>
      <title>如何对 e^-x / (1-e^-1) 进行逆变换，0<x<1 以实现重要性采样</title>
      <link>https://stats.stackexchange.com/questions/655631/how-to-inverse-transform-e-x-1-e-1-0x1-for-importance-sampling</link>
      <description><![CDATA[示例 5.10 使用 R (Rizzo) 进行统计计算 
使用重要性抽样估计以下内容 
$$\int_{0}^{1}\frac{e^{-x}}{1+x^2}$$
$f_3(x)=\frac{e^{-x}}{1-e^{-1}}, 0&lt;x&lt;1$
u &lt;- runif(m) #f3，逆变换方法
x &lt;- - log(1 - u * (1 - exp(-1)))
fg &lt;- g(x) / (exp(-x) / (1 - exp(-1)))
theta.hat &lt;- mean(fg)
se &lt;- sd(fg)

$u=\frac{e^{-x}}{1-e^{-1}}$ 
$u(1-e^{-1})=e^{-x}$ 
$\log\left(u(1-e^{-1})\right)=-x$ 
$-\log\left(u(1-e^{-1})\right)=x$ 
$-\log\left(1 - u(1-e^{-1})\right)=x$ 从何而来？如果 U 和 (1-U) 应该是相同的分布，那么为什么当我使用 x &lt;- - log(u * (1 - exp(-1))) 时会得到错误的输出？]]></description>
      <guid>https://stats.stackexchange.com/questions/655631/how-to-inverse-transform-e-x-1-e-1-0x1-for-importance-sampling</guid>
      <pubDate>Fri, 11 Oct 2024 03:06:15 GMT</pubDate>
    </item>
    <item>
      <title>选择零值计数数据进行组间显著性差异的统计检验</title>
      <link>https://stats.stackexchange.com/questions/655609/selecting-statistical-test-for-significant-difference-between-groups-from-count</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655609/selecting-statistical-test-for-significant-difference-between-groups-from-count</guid>
      <pubDate>Thu, 10 Oct 2024 15:41:21 GMT</pubDate>
    </item>
    <item>
      <title>标准化 beta 强度有一般解释吗？</title>
      <link>https://stats.stackexchange.com/questions/655605/is-there-a-general-interpretation-for-standardized-beta-strentgh</link>
      <description><![CDATA[运行线性回归模型后，我得到了 beta 作为效果大小。此线性回归模型在 r 中使用 geeglm 函数运行，指定 family= &quot;gaussian&quot;。该模型包括组状态（3 个级别）作为预测因子、结果和可交换相关结构，以解释数据集中的熟悉度（兄弟姐妹）。
例如：geeglm(educational_level ~ group_status, family = &quot;gaussian&quot;, id = ID, data = data, corstr = &quot;exchangeable&quot;)
通过标准化我的结果变量并运行相同的分析，我假设得到标准化 beta 而不是 beta 作为输出。
有了标准化 beta，我想评论一下我的关联的强度。我明白标准化 beta 值越高，关联越强。但是，是否有标准/通用的方法来解释标准化 beta 强度？就像解释 r 系数（皮尔逊相关系数）或 Cohen&#39;s D 的经验法则一样。]]></description>
      <guid>https://stats.stackexchange.com/questions/655605/is-there-a-general-interpretation-for-standardized-beta-strentgh</guid>
      <pubDate>Thu, 10 Oct 2024 14:08:20 GMT</pubDate>
    </item>
    <item>
      <title>R 中许多类别测试的 caret 和 pROC 结果之间的敏感性和特异性差异</title>
      <link>https://stats.stackexchange.com/questions/655442/difference-in-sensitivity-and-specificity-between-caret-and-proc-results-for-man</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655442/difference-in-sensitivity-and-specificity-between-caret-and-proc-results-for-man</guid>
      <pubDate>Mon, 07 Oct 2024 15:06:39 GMT</pubDate>
    </item>
    <item>
      <title>用概率测量参数的不确定性</title>
      <link>https://stats.stackexchange.com/questions/655179/measuring-a-parameters-uncertainty-with-probability</link>
      <description><![CDATA[在《Statistical Rethinking》第 58 页，Richard McElreath 指出

... 严格的非贝叶斯推理禁止使用概率来衡量参数的不确定性……

我理解他强调频率论推理依赖于重复，但抽样分布不是统计的概率分布吗？
他这句话是什么意思？]]></description>
      <guid>https://stats.stackexchange.com/questions/655179/measuring-a-parameters-uncertainty-with-probability</guid>
      <pubDate>Tue, 01 Oct 2024 16:54:07 GMT</pubDate>
    </item>
    <item>
      <title>蒙特卡洛积分方法利用黑匣子给出的一组代表点[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653676/monte-carlo-integration-methods-utilizing-a-set-of-representative-points-given-b</link>
      <description><![CDATA[考虑对多峰分布的函数进行积分的任务。假设我获得了一组来自目标分布众数的“黑盒样本”，但没有其他信息。*例如，假设我的目标分布是均值为 $-10$ 和 $10$ 的高斯混合，并且两者的方差均为单位。混合比例为 $0.5$。例如，“黑盒样本”$X$ 将是 $X=(-9.1, -11, -10.3, -10.1, -9.9, 9.8, 12, 11)$。样本来自分布的众数，但不一定以正确的比例出现。
蒙特卡罗方法中是否有一个研究领域旨在通过收敛保证来校正这些样本？有哪些方法？这里的“收敛保证”是指该方法的估计量是一致的或无偏的。
如果它有助于回答或简化问题，可以进一步假设：

可以从这个黑匣子中抽取更多样本，并且
多峰分布是离散的（有限支持）。

*也就是说，它们不是来自目标分布的样本，但恰好聚集在众数周围。更正式地说，这个代表集所来自的底层分布的密度是未知的。一个设想的场景是模式搜索算法，保证从分布的精确模式中采样。
例如，Metropolis-Hastings 肯定可以从这样的初始化中受益。
一个非示例是重要性采样，因为我们无法获得此类样本集的密度。
类似地，并行回火也可以从概率上获益，但顺序蒙特卡洛采样器则不行。
简而言之，我有来自分布（目标）众数的样本，但它们不是按比例从目标分布中抽取的。我如何校正样本以反映目标分布，使得期望的样本近似值不偏不倚？（或在某些计算极限内一致）]]></description>
      <guid>https://stats.stackexchange.com/questions/653676/monte-carlo-integration-methods-utilizing-a-set-of-representative-points-given-b</guid>
      <pubDate>Sat, 31 Aug 2024 17:40:22 GMT</pubDate>
    </item>
    <item>
      <title>统计学再思考 - 配对数据分析</title>
      <link>https://stats.stackexchange.com/questions/653502/statistical-rethinking-paired-data-analysis</link>
      <description><![CDATA[我想扩展“统计反思”（第 2 版第 170 页）一书中“6.2 治疗后偏差”示例的模型，以解释不同的操作员。
这是一个配对数据（治疗前/治疗后 - $y_0/y_1$）的情况，它基于以下想法：$p = \frac{y_1}{y_0}$ 中治疗前/治疗后的比例。因此，不是进行配对 t 检验（得到差值 $y_0 - y_1$），而是进行 Solomon Kurz 在此处 提出的分析
$$\begin{align*}
h_{1i} &amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i &amp; = h_{0i} \times p \\
p &amp; \sim \operatorname{Log-Normal}(0, 0.25) \\
\sigma &amp; \sim \operatorname{Exponential}(1).
\end{align*}$$
现在，假设$y_0 \&amp; y_1$由不同的操作员（或设备等）测量，我想用模型$y \sim 1 (1|operator) $来量化这个错误
主要的假设是预处理中的操作员没有经过培训，所以我想单独量化操作员的影响，即$y_0 \sim 1 (1|operator) $和$y_1 \sim 1 (1|operator)$
我想到的方法如下。这两个不同的模型通过比率 $p$ 连接起来，该比率应该在 1 左右（并且肯定大于 0）
$$
\mu_0 = 1 + (1|operator) \\
\mu_1 = 1 + (1|operator) \\
p\sim LogN(\frac{\mu_1}{\mu_0}, \sigma)\\
y_0 \sim N(\mu_0, \sigma_0) \\
y_1 \sim N(\mu_1, \sigma_1) \\
$$
但这有意义吗？如何更好地扩展统计反思模型并分别量化操作者在治疗前/治疗后的效果？
（*通过将数据转换为长格式，多级模型可以完成这项工作。但由于多级模型应该有（1 |主题）项（考虑配对数据 -主题），这会增加参数的数量。相反，示例 6.2 看起来非常优雅）
更新
我想制作一个 DAG，看看它会带我去哪里。
现在我把它作为一个潜在变量模型，如下所示，
$$
\mu_0 = 1 + y_L + (1|operator) \\
\mu_1 = 1 + y_L + (1|operator) \\
y_L \sim N(\mu_L, \sigma_L) \\
y_0 \sim N(\mu_0, \sigma_0) \\
y_1 \sim N(\mu_1, \sigma_1) \\
$$
因此，不要试图估计比率 $y_0 \&amp; y_1$ (p) 我必须估计 $y_L$ 哪个是差值（我希望如此）。
DAG 应该看起来像这样

dag {
bb=&quot;0,0,1,1&quot;
mu_0 [pos=&quot;0.464,0.365&quot;]
mu_1 [pos=&quot;0.240,0.354&quot;]
y0 [pos=&quot;0.462,0.465&quot;]
y1 [adjusted,pos=&quot;0.243,0.467&quot;]
y_L [pos=&quot;0.354,0.466&quot;]
mu_0 -&gt; y0
mu_1 -&gt; y1
y_L -&gt; y0
y_L -&gt; y1
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/653502/statistical-rethinking-paired-data-analysis</guid>
      <pubDate>Wed, 28 Aug 2024 19:16:22 GMT</pubDate>
    </item>
    <item>
      <title>设计一个神经网络，利用游戏状态信息预测 2D 格斗游戏中玩家的输入</title>
      <link>https://stats.stackexchange.com/questions/652711/designing-a-neural-network-to-predict-a-players-input-in-a-2d-fighting-game-usi</link>
      <description><![CDATA[我目前正在尝试设计一个神经网络，目的是广泛模仿特定 2D 格斗游戏中某些玩家的行为。
该游戏会记录每场游戏的“重播”，从而创建一个庞大的数据库。这些重播不仅包含每帧的游戏状态（例如位置值、动作状态等），还包含玩家输入的按钮。
NN 的输入数据将是游戏状态（或一系列游戏状态），并输出该游戏状态的预测输入。
我已经在 PyTorch 中为这个问题设置了一个通用 MLP，其架构如下，将其视为一个多标签问题，其中每个按钮输入都是一个要预测的标签：
class BaseModel(nn.Module):
def __init__(self, input_size, output_size):
super(BaseModel, self).__init__()
self.block_1 = nn.Sequential(
nn.Linear(input_size, 256),
nn.ReLU(),
nn.Linear(256,128),
nn.ReLU(),
)
self.dropout = nn.Dropout(p=0.3)
self.block_2 = nn.Sequential(
nn.Linear(128,64),
nn.ReLU()
)
self.bn = nn.BatchNorm1d(64)
self.block_3 = nn.Sequential(
nn.Linear(64,32),
nn.ReLU(),
nn.Linear(32,output_size)
)

def forward(self, x):
x = self.block_1(x)
x = self.dropout(x)
x = self.block_2(x)
x = self.bn(x)
x = self.block_3(x)
return x


此问题的数据来自重播。
输入数据首先被转换成人类可读的映射（例如 {&quot;HP&quot;: 10000, &quot;x&quot;:645.4273, &quot;y&quot;:0.0000, &quot;super_meter&quot;:32.6345, etc.&gt;），然后转换成一维张量形式的数值格式（例如 [10000, 645.4273, 0.0000, 32.6345, etc.]）。
同样，按钮输入首先从重放中转换为人类可读的映射（{&quot;A&quot;: 0, &quot;B&quot;: 1, &quot;up&quot;: 0, &quot;down​​&quot;:0, &quot;left&quot;:1, etc.&gt;），然后转换为一维张量，用作训练的真值标签，也仅使用映射的值。
目前，我使用的损失函数是二元交叉熵，优化器是 Adam。输出通过 S 型函数传递，如果值超过某个阈值，则按钮被解释为按下。
当前实现效果相当差。由于大多数按钮输入对于每个游戏状态都是 0，因此模型通过预测每帧每个按钮的 0 来非常快速地实现低损失。
我应该尝试哪些架构更改来提高模型的性能/处理模型很容易实现低损失的问题？
请注意，这样做的目的是模仿玩家行为，而不是“学习”如何玩游戏。如果使用重播数据训练模型的玩家什么都不做，只是一直按下一个按钮，那么模型应该反映这种行为。类似地，如果输入的玩家是职业玩家，其动作要复杂得多，则模型也应该表示这种行为。]]></description>
      <guid>https://stats.stackexchange.com/questions/652711/designing-a-neural-network-to-predict-a-players-input-in-a-2d-fighting-game-usi</guid>
      <pubDate>Tue, 13 Aug 2024 10:37:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么逆扩散过程不是高斯分布？</title>
      <link>https://stats.stackexchange.com/questions/647213/why-reverse-diffusion-process-is-not-a-gaussian-distribution</link>
      <description><![CDATA[从 $x_t$ 到 $x_{t+1} $ 的前向扩散过程是高斯的，这非常合理，因为我们通过添加随机高斯噪声进入下一个状态。但是，我不明白为什么该过程的反向（从 $x_{t+1} $ 到 $x_t $）不是高斯的。]]></description>
      <guid>https://stats.stackexchange.com/questions/647213/why-reverse-diffusion-process-is-not-a-gaussian-distribution</guid>
      <pubDate>Tue, 14 May 2024 12:27:17 GMT</pubDate>
    </item>
    </channel>
</rss>