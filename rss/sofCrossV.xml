<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 20 Aug 2024 09:17:34 GMT</lastBuildDate>
    <item>
      <title>远端结果的多级潜在类别分析中的 3 级聚类</title>
      <link>https://stats.stackexchange.com/questions/653039/3-level-clustering-in-multilevel-latent-class-analysis-of-distal-outcomes</link>
      <description><![CDATA[我正在根据 PISA 数据（横断面、连续的“远端结果”和类别的分类序数指标）研究学生经历的潜在类别（也汇总在学校层面）与学生成绩之间的关系。我打算使用多级潜在类别分析，这样我就可以在学生层面和学校层面对关系进行建模。但是，我很担心，因为学生数据不仅嵌套在学校中，还嵌套在国家/地区中（有 60 多个国家/地区）。由于我对国家/地区的影响不感兴趣，只想考虑国家/地区内的聚类，有没有办法进行这样的调整？我可以使用 Mplus 或 R。您有什么建议吗？或者您会推荐任何资源，其中有人使用这种 3 级聚类的 MLCA 来预测远端结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/653039/3-level-clustering-in-multilevel-latent-class-analysis-of-distal-outcomes</guid>
      <pubDate>Tue, 20 Aug 2024 09:03:44 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯方法：模型比较</title>
      <link>https://stats.stackexchange.com/questions/653037/bayesian-approach-models-comparison</link>
      <description><![CDATA[我有两组配对样本，每组包含 3,000 个数据点。这些样本中的每个值代表特定模型的输出。

第一个模型作为验证参考，基于具有已知预测因子的现场测量，由于其理论假设，误差幅度为 10-20%。

第二个模型基于估计测量，误差幅度为 10%，但预测因子未知。


此外，两个样本都不是正态分布的。
我希望使用贝叶斯方法评估第二个模型的预测性能，而不考虑预测因子的贡献。
有人可以推荐使用贝叶斯方法解决这个问题的参考资料吗？R 中的示例将非常有帮助。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653037/bayesian-approach-models-comparison</guid>
      <pubDate>Tue, 20 Aug 2024 07:25:47 GMT</pubDate>
    </item>
    <item>
      <title>t 检验的多维变体</title>
      <link>https://stats.stackexchange.com/questions/653035/multi-dimensional-variant-of-a-t-test</link>
      <description><![CDATA[我需要比较多个维度上的多个分布的平均值，我将维度限制为 3，以尽可能避免维度问题。
用于此类比较的最佳统计测试是什么？理想情况下，我希望在 Python statsmodels 或 scipy 库中提供一些可用的东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/653035/multi-dimensional-variant-of-a-t-test</guid>
      <pubDate>Tue, 20 Aug 2024 00:12:35 GMT</pubDate>
    </item>
    <item>
      <title>任何时间序列模型是否实际上都假设严格的平稳性？</title>
      <link>https://stats.stackexchange.com/questions/653034/do-any-time-series-models-actually-assume-strict-stationarity</link>
      <description><![CDATA[我正在学习时间序列课程，我们已经讨论了平稳性的主题。给出以下定义：

严格平稳性：
如果对于任何有限的时间点集$\{t_1, t_2, \ldots,
t_n\} \subset T$和任何时间移位$h$，
$(X_{t_1}, X_{t_2}, \ldots, X_{t_n})$的联合分布与
$(X_{t_1+h}, X_{t_2+h}, \ldots, X_{t_n+h})$。
弱平稳性：
如果满足以下条件，则随机过程 $\{X_t\}_{t \in T}$ 被称为弱平稳（或广义平稳）：

均值函数 $\mu(t) = E[X_t]$ 是常数，不依赖于时间 $t$。

自协方差函数 $\gamma(t,t+h)$ 仅依赖于 $h$但不是在$t$上。

方差是有限的。



然后指出，许多时间序列模型（例如 ARMA）假设弱平稳性。此外，任何时候“平稳”被使用时，我们应该假设讲师的意思是“弱平稳性”。
我的问题是：是否有任何时间序列模型实际上假设严格平稳性？

引入严格平稳性，然后立即忽略它而支持弱平稳性，这似乎不寻常。
严格平稳性是否只是作为弱平稳性的教学垫脚石来教授，还是在现实生活中有实际用例？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653034/do-any-time-series-models-actually-assume-strict-stationarity</guid>
      <pubDate>Mon, 19 Aug 2024 22:29:32 GMT</pubDate>
    </item>
    <item>
      <title>关于具有协变量的时间序列微生物组数据的统计建模的问题</title>
      <link>https://stats.stackexchange.com/questions/653032/question-on-statistical-modeling-for-time-series-microbiome-data-with-covariates</link>
      <description><![CDATA[我是一名硕士生，正在研究一个由 NSF 资助的项目，研究人类访问对岛屿生态系统的影响。我们的研究涉及三个岛屿，人类访问程度各不相同：高、中、低。主要重点是了解受游客影响的饮食与微生物组组成之间的关系。
我们从每个岛屿上的多个宿主收集了近 200 个 16S rRNA 样本和一套全面的生理数据（血细胞计数、免疫指标、能量指标、代谢组谱等）。样本每年采集一次（连续 3 年，每年一次），但我不确定各季节是否一致。
我的研究问题是：

受不同程度的人类访问影响，饮食是否与微生物组组成的变化相关？
哪些生理因素（例如血细胞计数、免疫指标）与微生物组变化最密切相关？
每个岛屿的微生物组组成每年如何变化？
不同游客率的岛屿之间的微生物组组成是否存在显着差异？

我需要你的帮助

推荐用于分析微生物组数据并将其与生理因素关联的统计方法。

还值得一提的是，我不确定哪种方法通常更有效理想。在 qiime2 中将所有数据 y1vsy2vsy3 一起处理是否更明智，还是分别处理 y1vsy2 和 y2vsy3 更好。

]]></description>
      <guid>https://stats.stackexchange.com/questions/653032/question-on-statistical-modeling-for-time-series-microbiome-data-with-covariates</guid>
      <pubDate>Mon, 19 Aug 2024 21:30:19 GMT</pubDate>
    </item>
    <item>
      <title>在变分推理和神经网络取得最新进展之后，密集贝叶斯或马尔可夫网络的推理难题是否得到了解决？</title>
      <link>https://stats.stackexchange.com/questions/653031/is-the-inferential-challenge-of-dense-bayesian-or-markov-networks-solved-after-c</link>
      <description><![CDATA[我正在尝试更多地了解图形模型，现在对基础知识有了合理的掌握。
2000 年代中期的许多论文甚至 Koller 的教科书中反复出现的一个问题是，我们希望图形模型具有稀疏性，以加快推理速度。因此，密集图形模型或“宽”图形模型使团树信念传播等方法非常缓慢。事实上，Koller 认为，贝叶斯网络结构学习的挑战之一是结构学习通常会产生密集模型，这些模型很难运行精确和近似推理算法。
然而，两项创新似乎改变了这些密集模型的演算。首先，通过变分推理，我们实际上能够离线训练推理模型。因此，我们学习模拟完整贝叶斯网络的变分分布的参数。变分分布计算速度很快，并能为提交给网络的查询提供近似答案。
其次，神经网络——即使是小型神经网络——也可以学会从密集或宽模型的精确推理中近似得出结果。同样，在离线设置中，我们可以为贝叶斯网络或马尔可夫网络生成随机查询，并计算查询的精确推理。然后这将构建一个数据集，用于训练神经网络来回答这些查询。
当然，这些方法中也有一些实际的考虑，例如对原始模型的精确或近似推理的准确性进行基准测试。但这些似乎是可以解决的问题。
因此，我的问题是，既然变分方法和神经网络方法很容易实现，这是否意味着贝叶斯或马尔可夫网络的密集性不再是使用这些模型的障碍？或者还有其他我遗漏的问题？
另外需要注意的是，当然，有些情况下变分推理或神经网络可能不起作用。在这些情况下，就需要其他算法。但从实际角度来看，我不确定变分推理或神经网络学习失败的频率有多高。因此，再次看来，可能失败的情况可能只是一类相对较少且特定的情况。]]></description>
      <guid>https://stats.stackexchange.com/questions/653031/is-the-inferential-challenge-of-dense-bayesian-or-markov-networks-solved-after-c</guid>
      <pubDate>Mon, 19 Aug 2024 21:19:53 GMT</pubDate>
    </item>
    <item>
      <title>违反莱德曼界限以下因子模型的识别</title>
      <link>https://stats.stackexchange.com/questions/653029/violation-of-the-identification-of-factor-model-below-ledermann-bound</link>
      <description><![CDATA[在Bekker 和 ten Berge, 1997中，据说当因子数量低于 ledermann 界限时，独立误差$\Sigma$的方差几乎肯定是唯一确定的。
在该定理证明的第 3 部分中，他们使用了以下内容

我想知道在什么情况下雅可比矩阵没有满行排名？]]></description>
      <guid>https://stats.stackexchange.com/questions/653029/violation-of-the-identification-of-factor-model-below-ledermann-bound</guid>
      <pubDate>Mon, 19 Aug 2024 21:01:14 GMT</pubDate>
    </item>
    <item>
      <title>处理稀疏分类数据以进行贝叶斯优化</title>
      <link>https://stats.stackexchange.com/questions/653027/handling-sparse-categorical-data-for-bayesian-optimization</link>
      <description><![CDATA[我正在使用贝叶斯优化。在使用它来指导我的现实世界湿实验室化学实验的选择过程之前，我将拥有更大的灵活性，我想评估它在先前训练数据集上的有效性，在该数据集中，我追溯使用贝叶斯优化来评估它将如何导航景观。但是，由于以下原因，此训练数据集不是贝叶斯优化的典型用例：

一些变量是分类的；为了更好地表示分类变量而不是简单的独热编码，我在 tSNE 中提供了嵌入以更好地捕获相对差异。但是，该模型最终仍应建议提供的离散类别之一。

它是稀疏的。对于上下文，每行代表不同的化学混合物，其中为每种混合物测量单个功能目标值（即“target_value”）。我总共有 7 个不同的变量需要学习，即

component1_structure（3 个 tSNE 维度，但实际上是分类的）

component1_ratio（1 维，连续）

component1_weight（1 维，连续）

component2_structure（2 个 tSNE 维度，但实际上是分类的）

component2_ratio（1 维，连续）

component3_ratio（1 维，连续）

component4_ratio（1 维，连续）


这个组合空间理论上非常大。但是，我只有 1801 种不同的混合物（即这些变量的组合）具有功能数据；我希望模型严格探索/建议我拥有功能数据的这 1801 种混合物。

与顺序优化不同，每轮实验将有多种（即 10 种）不同的混合物需要测试。因此，正如本文所述，我采用了克里金信度算法。
我的目标是证明使用贝叶斯优化搜索这些训练数据是有效的；因此，最终激励将其动态地用于实际的真实世界数据集（幸运的是，上面描述的第二个约束不适用）。尽管如此，我想设想一种方法来针对这些预先存在的训练数据使用贝叶斯优化。


这是 Colab 上的一个实现示例：https://colab.research.google.com/drive/19cY54d6M7jYl1fRDpL7oGVPF832JU247?usp=sharing
正如您在 Colab 上看到的，我目前的策略是使用加权距离度量来基本上识别最接近模型建议的唯一点（在 1801 个尚未选择的点中）。然而，我怀疑这是否是一个合理的方法。
关于如何改进此策略和/或代码实现的建议将非常有帮助。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653027/handling-sparse-categorical-data-for-bayesian-optimization</guid>
      <pubDate>Mon, 19 Aug 2024 20:50:56 GMT</pubDate>
    </item>
    <item>
      <title>比较记录的频率</title>
      <link>https://stats.stackexchange.com/questions/653023/compare-the-frequency-of-records</link>
      <description><![CDATA[我有如下记录：
\begin{array}{}
\hline
\textrm{2024-07-27 21:52:39} \\
\textrm{2024-07-27 21:54:15} \\
\textrm{...} \\
\textrm{2024-07-28 21:58:44} \\
\textrm{2024-07-28 22:01:15} \\
\textrm{...} \\
\textrm{...} \\
\hline
\end{array&gt;
我想比较这些记录在工作日和周末的频率。
这是我的方法：

设置一个间隔 - 对于现在 15 分钟并计算这些间隔内的记录
分成两组 a) 工作日，b) 周末
结果数据如下：

\begin{array}{c}
\hline
间隔 &amp; 计数 \\ 
\hline
\textrm{00:00:00} &amp; 3450 \\
\textrm{00:15:00} &amp; 2144 \\
\textrm{...} \\
\textrm{23:45:00} &amp; 4712 \\
\hline
\end{array&gt;
工作日和周末
现在我的问题是：

我应该“规范化”吗？数据，例如将工作日的计数除以 5，将周末的计数除以 2，因为现在收集的数据涵盖不同的天数？或者可能是不同天数的总数（我总是有一整天），例如，如果只是从星期二到星期日，那么我会将其除以 4（工作日总数）和 2（周末天数总数）？
我被建议使用双样本 Kolmogorov-Smirnov 检验来确定分布是否相同，那么使用如下方法是否正确？：

weekdays = [3450, 2144, ..., 4712]
weekends = [2147, 1544, ..., 3894]

_, p_value = scipy.stats.ks_2samp(weekends, weekdays)
if p_value &lt; 0.05:
print(&quot;工作日和周末的分布不一样。&quot;)
else:
print(&quot;分布相同&quot;)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/653023/compare-the-frequency-of-records</guid>
      <pubDate>Mon, 19 Aug 2024 19:16:51 GMT</pubDate>
    </item>
    <item>
      <title>纪元 (epoch) 与数据复制相同吗？</title>
      <link>https://stats.stackexchange.com/questions/653012/are-epochs-the-same-as-data-duplication</link>
      <description><![CDATA[时期，即对原始数据重复训练的次数，对于神经网络来说是绝对必要的，因为神经网络的参数通常比原始实例多得多。
对于具有许多参数的其他 ML 方法，使用时期的方法论地位是什么？它们是否用于（我称之为）类技术，如随机森林？通过“方法论地位”，我隐藏了我的真实意图。也就是说，为什么不将时期用于普通的逻辑回归或决策树？为什么不将每个额外的时期视为数据增强，但使用相同的实例？如果建议重复数据以减少偏差，我觉得任何统计学家都会感到恶心。 ML 建模者会毫不犹豫地无限期地增加 epoch，直到训练/测试准确率开始变差（或者甚至到那时也不会变差！）。
那么

在传统预测模型中使用 epoch（基本重复实例）可以吗（只要考虑到过度拟合？
另一方面，一个 epoch 是否应该成为 NN 训练的标准，或者更确切地说，使用重复数据作为增强技术是否存在各种统计问题？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653012/are-epochs-the-same-as-data-duplication</guid>
      <pubDate>Mon, 19 Aug 2024 14:12:29 GMT</pubDate>
    </item>
    <item>
      <title>回归中的独立指标变量在改变类别数量时变得显著</title>
      <link>https://stats.stackexchange.com/questions/653011/independent-indicator-variable-in-regression-becomes-significant-when-changing-t</link>
      <description><![CDATA[我正在使用二元响应变量运行逻辑回归。无论是否使用家庭作为指示变量，家庭本身都会产生微小的正向但不显著的影响。
当将家庭规模视为具有 3 个级别的分类变量（单户、中型或大型家庭）来检查其是否有影响时，与排除的类别（单户）相比，两个包含的虚拟变量都具有很强的显著性和正向性。为什么会这样？
假设不仅家庭本身会对结果产生积极影响，而且家庭规模也会产生积极影响。我将家庭规模也视为分类，因为它在数据集中只能采用 7 个不同的值。
（数据集包含 425 000 个个体，每个个体没有重复测量，但不幸的是总共只有 7 个预测因子。但感兴趣的结果（编码为 1，其他类别为 0）是罕见事件（仅 0.3%），因此数据严重不平衡。
425 000 个个体中有 43% 属于一个家庭，即 243 000 个个体。但家庭户主导了感兴趣的结果案例 - 属于结果 = 1 的 69% 属于家庭户。
在 3 个类别中；数据集中所有 425 000 人中有 243 000 人属于单个家庭（57%），30% 属于中型家庭，只有 13% 属于大家庭。
然而，在那些属于结果是现金利息大家庭现在占 32%，中等家庭占 37%，单身家庭占 31%。）
Family_account 的系数为 0.2221，但 p 值为 0.29。
相比之下，在使用家庭规模的模型中，Medium_Family 的系数为 0.4366，Large_family 的系数为 1.6255 - 两者的 p 值均小于 0.000。
任何帮助都非常感谢，br]]></description>
      <guid>https://stats.stackexchange.com/questions/653011/independent-indicator-variable-in-regression-becomes-significant-when-changing-t</guid>
      <pubDate>Mon, 19 Aug 2024 13:47:05 GMT</pubDate>
    </item>
    <item>
      <title>包含一些随机和固定效应因素的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/653005/linear-mixed-models-with-some-factors-included-as-both-random-and-fixed-effects</link>
      <description><![CDATA[我目前正在分析一项实地试验的数据，该试验最初设计用于双向方差分析。该试验涉及两个因素——土壤（2 个级别）和植物（2 个级别），在区块设计中重复 6 次。该试验包括三个采样时间和两个土壤深度的数据。
考虑到随时间和不同深度重复测量，我担心双向方差分析所需的独立性假设。虽然对每个采样和深度进行单独的双向方差分析是一种选择，但它会导致统计能力的损失，并阻碍不同采样和深度之间的交叉比较，这对我的研究至关重要。
为了应对这些挑战，我正在考虑使用具有以下结构的线性混合模型：
soil_carbon ~ (SOIL*PLANT*DEPTH*SAMPLING) + 
(1|BLOCK) + (1|PLOT) + (1|PLOT:SAMPLING) + (1|PLOT:DEPTH)

模型说明：

(SOIL*PLANT*DEPTH*SAMPLING)：该术语表示研究的固定效应之间的相互作用。
(1|BLOCK)：阻塞
1|PLOT)：不同图的随机效应
(1|PLOT:SAMPLING)：嵌套在 PLOT 中的 SAMPLING。考虑到采样总是在同一个图中完成的事实。
(1|PLOT:DEPTH)：嵌套在 PLOT 中的 DEPTH。考虑到在每个图中采样的深度不同。

具体问题：
a) 鉴于随机效应中的 SAMPLING 和 DEPTH 嵌套在 PLOT 中，这些因素是否也可以作为固定效应包含在模型中？我的目标是比较不同级别的深度和采样。它们应该同时包含在随机效应和固定效应中，还是只包含在随机效应中？
b) 为了检验固定效应的显著性，我正在考虑使用似然比检验来简化模型。这种方法是否适用于线性混合模型？
如果您对分析这些数据有任何其他建议或推荐，我将非常感谢您的见解。
编辑：我在其中一个描述中错误地命名了 SAMPLING。现在应该没问题了。]]></description>
      <guid>https://stats.stackexchange.com/questions/653005/linear-mixed-models-with-some-factors-included-as-both-random-and-fixed-effects</guid>
      <pubDate>Mon, 19 Aug 2024 11:21:13 GMT</pubDate>
    </item>
    <item>
      <title>使用通过降维变换观察到的样本计算或从后验中进行采样</title>
      <link>https://stats.stackexchange.com/questions/653004/computing-or-sampling-from-a-posterior-with-samples-observed-through-a-dimension</link>
      <description><![CDATA[设 $\boldsymbol \theta$ 为参数向量，已知先验 $\pi(\boldsymbol \theta)$。
设 $\boldsymbol x_1,...,\boldsymbol x_n$ 为 i.i.d. 样本，已知 $\boldsymbol x|\boldsymbol \theta$。
问题是我们观察的不是 $\boldsymbol x_i$，而是 $\boldsymbol g(\boldsymbol x_i)$。这里$\boldsymbol g$是一个降维变换。如何用数值方法计算后验$\pi(\boldsymbol \theta | \boldsymbol g(\boldsymbol x_1),...,g(\boldsymbol x_n))$或高效地从中采样？
这里有一个简单的例子。对于一个矩形，宽度$w\sim {\rm Uniform}(0, a)$和长度$l\sim {\rm Uniform}(0,b)$，并且$(a,b)$遵循已知的先验。
但是我们无法观察到$(w,l)$。相反，我们可以观察面积$s = w\cdot l$。
如何用数字方式计算后验$\pi(a,b|s)$或从中抽样？]]></description>
      <guid>https://stats.stackexchange.com/questions/653004/computing-or-sampling-from-a-posterior-with-samples-observed-through-a-dimension</guid>
      <pubDate>Mon, 19 Aug 2024 10:18:07 GMT</pubDate>
    </item>
    <item>
      <title>如果获得的样本量比功效分析中显示的大得多，该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</link>
      <description><![CDATA[老实说，我们没想到这一点——毕竟我们一切都是按照剧本做的。
我们计划对一些心理问题进行研究，我们将问卷输入到 Qualtrics，在 G*Power 的帮助下，我们进行了功效分析以获得最小样本量，最后我们在互联网上发布了该研究的链接。然后样本量激增。几天后，我们检查了我们设法收集了多少观察结果，结果发现数量增加了四倍（所以我们匆忙停止收集数据）。功效分析表明 N = 500，我们得到了 N = 2000（当然是 2000 多）。开心吗？不，我们离幸福还很远。
问：现在我们有一个问题，如何处理超大样本（记住超强研究）。
想法是：

在第 500 次观察时截断——丢弃其余数据（听起来像是在浪费数据）
在第 500 次观察时截断，使用其余数据作为复制研究（听起来很狡猾，我们实际上没有进行复制研究，数据来自原始研究）
从我们的大数据（N = 2000）中抽取样本 - 不放回抽样，样本由N = 500 次观察组成（并丢弃休息）。
... 大家还有其他想法吗？你们遇到过这种情况吗？你们做了什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</guid>
      <pubDate>Sun, 18 Aug 2024 14:54:41 GMT</pubDate>
    </item>
    <item>
      <title>McNemar 检验 1 个科目与 3 个科目需要多次测试校正吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652765/mcnemar-test-1-subject-versus-3-subjects-need-multiple-testing-correction</link>
      <description><![CDATA[我向不同的人询问特定跑步者马拉松的持续时间。我想将 1 个人（人 A）的估计值与 3 个预测模型（模型 B、C 和 D）进行比较，如下所示：
我会问

人 A 跑步者是否需要：&lt;= 2 小时，&gt; 2 &lt;= 3 小时，&gt; 3 &lt;= 4 小时或 &gt; 4 小时

模型 B 是否需要 &gt; 2 小时

模型 C 是否需要 &gt; 3 小时

模型 D 是否需要 &gt; 4 小时


由于涉及相同的跑步者，我想进行 McNemar 检验并比较 A 与 B、A 与 C 和 A 与 D。从 A 的 1 个估计中，我可以推断出 3 个估计。我们这样做是因为人类估计的数量是有限的。例如，如果 A 的估计是跑步将花费 &gt;3 &lt;= 4 小时。我可以说 A 对 &gt;2 小时说的是假的，对超过 3 小时说的是真的，对 &gt;4 小时说的是假的。这样，我可以针对 B、C 和 D 的估计值制作 3 个列联表。
我担心的是，如果我的研究问题是 A 的表现优于 B、C 和 D，
这些测试将需要进行多重检验校正，因为我对来自 A 的 1 个估计值进行了 3 次测试。
如果我的研究问题是 A 的表现是否优于 B、C 或 D，那么 McNemar 检验可能不需要进行多重检验校正。
我很想听听你对此的看法。]]></description>
      <guid>https://stats.stackexchange.com/questions/652765/mcnemar-test-1-subject-versus-3-subjects-need-multiple-testing-correction</guid>
      <pubDate>Wed, 14 Aug 2024 07:26:44 GMT</pubDate>
    </item>
    </channel>
</rss>