<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 19 Aug 2024 03:17:26 GMT</lastBuildDate>
    <item>
      <title>具有约束损失变分自动编码器的词嵌入</title>
      <link>https://stats.stackexchange.com/questions/652993/word-embeddings-with-a-constrained-loss-variational-autoencoder</link>
      <description><![CDATA[我在复习有关 CBOW 和 Skip-Gram 的一些知识时有了一个想法。我想在这里发帖接受一些批评，也许还能学到一些新东西。
这个想法是使用一个基本的变分自动编码器，它一次接受一个标记作为输入 - 但有一个额外的损失函数，它表示每个标记向量表示应该是窗口内之前出现的标记的向量和（添加每个组件），即：三个之前的标记。
作为一个玩具示例，假设它将具有二维嵌入。这意味着潜在空间将有两个 z 均值的节点（最终的平均值将是我们的嵌入）。
继续这个例子，训练数据点将是电影评论数据集中的这句话：
sample_text = &quot;对于一部不受尊重的电影，肯定有很多令人难忘的名言为这部珍品列出。&quot; 

如果窗口设置为 3，则

&quot;for&quot; 没有先前的标记
&quot;a&quot; 应等于 &quot;for&quot;
&quot;movie&quot; 应为 &quot;for&quot; + &quot;a&quot;
&quot;that&quot; 应为 &quot;for&quot; + &quot;a&quot; + &quot;movie&quot;
&quot;gets&quot; 应为 &quot;a&quot; + &quot;movie&quot; + “that”，等等。

因此，对于训练句子/段落数据中的每个标记，我们在损失中有三个项：kl、重构和向量加法项​​ i, j，因为我们只有两个维度。
经过几个时期后，上述句子的图如下所示：

正如我所料，像“a”、“for”、“there”这样很常见的词将具有非常小的值，因为它们不能解释太多内容 - 但其他词如“gem”或“quotes”具有更高的值。因此，虽然约束可能非常简单，但看起来它在某种程度上是有效的。此外，可能可以通过不同的维度添加不同的约束，等等。
我很乐意听到任何意见或批评 - 或者如果有人知道任何实际的类似工作。我不是研究人员 - 只是一个爱好者。]]></description>
      <guid>https://stats.stackexchange.com/questions/652993/word-embeddings-with-a-constrained-loss-variational-autoencoder</guid>
      <pubDate>Mon, 19 Aug 2024 02:24:25 GMT</pubDate>
    </item>
    <item>
      <title>Cox 模型中时间依赖的协变量</title>
      <link>https://stats.stackexchange.com/questions/652991/time-dependent-covariates-in-cox-model</link>
      <description><![CDATA[我正在研究如何处理长期随访时的生存数据。当我进行长期随访时，Cox 模型中 HR 比例假设往往会失败，因为协变量会随时间而变化。为了处理 Cox 模型中的时间依赖性协变量，可以尝试将随访时间分成几个间隔。然后，计算每个间隔的 Cox 模型。
现在假设我有一个没有事件的间隔，可能是因为间隔太短，结果很少见。在这种情况下，我想这种策略无法应用。我说得对吗？
此外，使用这种策略我得到了许多风险比（每个间隔一个 HR），所以我必须计算总 HR。我相信这个总 HR 应该计算为时间间隔 HR 的加权平均值。每个间隔的权重是如何分配的？我找不到任何迹象。
谢谢你的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/652991/time-dependent-covariates-in-cox-model</guid>
      <pubDate>Mon, 19 Aug 2024 00:32:49 GMT</pubDate>
    </item>
    <item>
      <title>如果我们对 PDF 或 CDF 都不了解，是否有可能找到它们？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652988/is-it-possible-to-find-pdf-or-cdf-if-we-dont-know-about-either-of-them</link>
      <description><![CDATA[我知道 PDF 是 CDF 的导数，而 CDF 是 PDF 的反导数。但是如果我们不知道它们中的任何一个，该怎么办？那么，我们如何找到 CDF 或 PDF。]]></description>
      <guid>https://stats.stackexchange.com/questions/652988/is-it-possible-to-find-pdf-or-cdf-if-we-dont-know-about-either-of-them</guid>
      <pubDate>Sun, 18 Aug 2024 22:32:46 GMT</pubDate>
    </item>
    <item>
      <title>将可预测的连续误差组合成单个误差项</title>
      <link>https://stats.stackexchange.com/questions/652981/combining-predictable-sequential-errors-into-a-single-error-term</link>
      <description><![CDATA[简短解释
如何将连续和可预测的误差组合成单个误差项，以求得多次测量的平均值？在我的例子中，每次测量都是移液器输送的气体体积，其中体积随着每次注射而减少，根据已知的指数衰减函数。每次测量的误差也是可预测的，并且随着每次注射略有增加。我需要计算几次此类测量的平均值的组合误差。最好的方法是什么？
详细解释
我正在为测量氦-4 的真空系统编写质谱数据缩减软件。该系统包含带有移液器的标准罐，移液器可提供已知数量的氦-4 作为未知体积的参考。移液器的每次输送事件称为“注射”。给定射击的体积估算如下：
$$V_\text{std} = V_\text{cal}D\!F^{\Delta Q}$$
其中：

$V_\text{cal}$ 是在给定射击次数下根据外部标准进行的工厂校准体积输送。
$D\!F$ 是消耗因子，即每次射击时罐中气体消耗的因子。这也是容器和移液器之间的体积比。
$\Delta Q$ 是自 $V_\text{cal}$ 确定以来的注射次数。

鉴于 $\Delta Q$ 是已知值，误差项为：
$$\begin{equation}
\varepsilon _{V_\text{std}} = \sqrt{{\left(\frac{\partial V_\text{std}}{\partial V_{\mathrm{cal}}} \varepsilon_{V_{\mathrm{cal}}}\right)}^2 + {\left(\frac{\partial V_\text{std}}{\partial \mathit{D\!F}} \varepsilon_{\mathit{D\!F}}\right)}^2}
\end{equation}$$
其中$\varepsilon$表示每个项的误差。
因为$V_\text{cal}$、$D\!F$及其误差是常数，$V_\text{std}$和$\varepsilon_{V_\text{std}}$仅相差$\Delta Q$，而$\Delta Q$没有误差。因此，$V_\text{std}$ 的值及其误差是完全可预测的，并形成平缓的指数衰减趋势，误差随着每次射击而缓慢增加。
为了计算未知气体量，我使用几个标准射击的平均值，$\bar{V}_\text{std}$。为了传播未知气体量的误差，我需要将 $V_\text{std}$ 的误差减少为单个值，$\varepsilon_{\bar{V}_\text{std}}$。考虑到这些值是可预测和连续的，并且没有正态分布，实现此目的的最佳方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652981/combining-predictable-sequential-errors-into-a-single-error-term</guid>
      <pubDate>Sun, 18 Aug 2024 17:27:51 GMT</pubDate>
    </item>
    <item>
      <title>平均预测和边际效应相互作用之间的差异</title>
      <link>https://stats.stackexchange.com/questions/652978/difference-between-average-predictions-and-interactions-in-marginal-effects</link>
      <description><![CDATA[我有一个固定效应模型，其中我对分类变量随时间变化的边际效应感兴趣。以下是一个示例，说明我正在做什么：
library(fixest)
library(marginaleffects)
library(ggplot2)

# 设置可重复性的种子
set.seed(123)

# 观察次数
n &lt;- 500 # 10 个时间点，每个时间点 50 次观察

# 模拟数据
data &lt;- data.frame(
ID = 1:n,
Time = factor(rep(1:10, each = 50)), # 10 个时间点，每个时间点 50 次观察
Category = factor(rep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), length.out = n)), # 3 级分类独立变量
Control1 = rnorm(n, mean = 50, sd = 10), # 具有一定变化的连续控制变量
Control2 = sample(0:1, n, replace = TRUE) # 具有随机分配的二元控制变量
)

# 二元结果变量，设计为随类别和时间变化
data$Outcome &lt;- rbinom(n, 1, prob = plogis(0.5 + 0.3 * as.numeric(data$Category) - 0.2 * as.numeric(data$Time) + 0.05 * data$Control1 - 0.1 * data$Control2))

# 使用固定效应拟合模型
model &lt;- feglm(
Outcome ~ Category + Control1 + Control2 |时间，
数据 = 数据，
家庭 = 二项式 (&quot;logit&quot;)
)

# 模型摘要
summary(model)

# 按类别和时间获取平均预测
预测 &lt;- avg_predictions(model, by = c(&quot;类别&quot;, &quot;时间&quot;))

# 显示预测
print(predictions)

# 绘制带有置信区间的预测
ggplot(predictions, aes(x = 时间, y = 估计, 颜色 = 类别, 组 = 类别)) +
geom_line(size = 1) +
geom_point(size = 2) +
geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = 类别), alpha = 0.2, 颜色 = NA) +
labs(title = &quot;按类别随时间变化的预测概率&quot;,
x = &quot;时间&quot;,
y = &quot;预测概率&quot;) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))

我有两个问题：

预测数据框中的值与时间和类别变量相互作用的模型有何不同？我理解，包括交互作用会假设效果可能会受到时间的影响，但如果数据表明如此，边际效应方法不会显示相同的结果吗？例如，如果时间 =3 类别 A 的结果可能性明显高于基线，即使没有交互项，这也可能会反映在数据中，对吗？
无论是否添加交互项（类别*时间），逐步分析每个类别的时间条件效应的正确方法是什么？例如，如果我想确定时间 =3、类别 A、时间=4、类别= A、时间= 5、类别的值，以与上一次相比估计的变化为准
]]></description>
      <guid>https://stats.stackexchange.com/questions/652978/difference-between-average-predictions-and-interactions-in-marginal-effects</guid>
      <pubDate>Sun, 18 Aug 2024 16:47:17 GMT</pubDate>
    </item>
    <item>
      <title>帮助解答有关概率的教科书问题：50 岁以上男性吸烟、饮酒和肺癌</title>
      <link>https://stats.stackexchange.com/questions/652977/help-with-texbook-question-on-probabilities-smoking-drinking-and-lung-cancer</link>
      <description><![CDATA[我需要帮助解决这个关于概率的问题。。。我被第一个问题难住了

男性人口的年龄服从正态分布，算术平均值为 39 岁，标准差为 17 岁。最近一项关于 50 岁以上男性吸烟的研究表明，每天吸烟超过 10 支（平均一包）的人中有 38% 死于肺癌，而吸烟量少于该数量的人中只有 5% 死于同一原因。在任何年龄段的男性代表组中，发现 31% 的人吸烟，37% 的人经常饮用酒精饮料，40% 的人两者都不喝。考虑到只有 6% 的吸烟者每天吸烟超过半包…… 1. 一名 50 岁以上的男性也吸烟和喝酒的概率是多少？ 2. 在 1200 名 50 岁以上的男性吸烟者中，超过 60 人死于肺癌的概率是多少？

我能够使用 excel 函数 1-DISTR.NORM.N(50;39;17;TRUE) 计算年龄超过 50 岁的概率，该函数返回 0.26，以及吸烟的概率（0.60 * 0.31=0.19），饮酒的概率（0.37 * 0.0.60=0.22），饮酒和吸烟的概率为 0.22 * 0.19= 0.04，但我无法回答这些问题。据说，一个男人年龄超过 50 岁并且吸烟和喝酒的概率为 0.0206，而第二个问题的概率为 0.0041，我不知道它们从何而来。有人能帮忙吗这个？]]></description>
      <guid>https://stats.stackexchange.com/questions/652977/help-with-texbook-question-on-probabilities-smoking-drinking-and-lung-cancer</guid>
      <pubDate>Sun, 18 Aug 2024 16:25:18 GMT</pubDate>
    </item>
    <item>
      <title>如果获得的样本量比功效分析中显示的大得多，该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</link>
      <description><![CDATA[老实说，我们没想到这一点——毕竟我们一切都是按照剧本做的。
我们计划对一些心理问题进行研究，我们将问卷输入到 Qualtrics，在 G*Power 的帮助下，我们进行了功效分析以获得最小样本量，最后我们在互联网上发布了该研究的链接。然后样本量激增。几天后，我们检查了我们设法收集了多少观察结果，结果发现数量增加了四倍（所以我们匆忙停止收集数据）。功效分析表明 N = 500，我们得到了 N = 2000（当然是 2000 多）。开心吗？不，我们离幸福还很远。
问：现在我们有一个问题，如何处理超大样本（记住超强研究）。
想法是：

在第 500 次观察时截断——丢弃其余数据（听起来像是在浪费数据）
在第 500 次观察时截断，使用其余数据作为复制研究（听起来很狡猾，我们实际上没有进行复制研究，数据来自原始研究）
从我们的大数据（N = 2000）中抽取样本 - 不放回抽样，样本由N = 500 次观察组成（并丢弃休息）。
... 大家还有其他想法吗？你们遇到过这种情况吗？你们做了什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</guid>
      <pubDate>Sun, 18 Aug 2024 14:54:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么通过残差估计的数据与原始数据相比对重要性有 50/50 的影响？</title>
      <link>https://stats.stackexchange.com/questions/652971/why-estimates-of-data-via-residuals-has-50-50-effect-on-significance-compared-to</link>
      <description><![CDATA[我根据以下模型生成数据

在实际数据集中，变量 I 未知，目标是研究 I 和 D、B11 之间的关系，看它是否显著非零。为此，在已知 I 的模拟数据中，将使用 I 值的方法与使用其通过 G ~ B 残差的估计值的方法进行比较。换句话说，将 I ~ D 与 ([G ~ B] 的残差) ~ D 进行比较。根据下面的 R 代码，在中位数上，两个显着性检验是相同的，而在平均数上，直接使用 I 略胜一筹。
对此的解释是什么，为什么不是“显而易见的”认为因为残差只是变量 I 的估计值而不是真实变量，所以它总是给出更不可靠的结果？相反，只有一半的时间给出更糟糕的结果？而另一半则更好？
# Part A:
set.seed(0); n&lt;-40; numSims&lt;-10000; ronDsigs&lt;-c(); IonDsigs&lt;-c()
B8s&lt;-B9s&lt;-B10s&lt;-B11s&lt;-B12s&lt;-c()
for (index1 in 1:numSims) {
B&lt;-rnorm(n); I&lt;-rnorm(n); J&lt;-rnorm(n)
B8&lt;-rnorm(1); B9&lt;-rnorm(1); B10&lt;-rnorm(1); B11&lt;-rnorm(1); B12&lt;-rnorm(1)
B8s&lt;-c(B8s,B8); B9s&lt;-c(B9s,B9); B10s&lt;-c(B10s,B10); B11s&lt;-c(B11s,B11);
B12s&lt;-c(B12s,B12)
G&lt;-B*B8+I*B10; D&lt;-B*B9+I*B11+J*B12
GonB&lt;-lm(G~B)
GonBresiduals&lt;-GonB$residuals
GonBresidualsonD&lt;-lm(GonBresiduals~D)
IonD&lt;-lm(I~D)
ronDsigs&lt;-c(ronDsigs,summary(GonBresidualsonD)$coefficients[[8]])
IonDsigs&lt;-c(IonDsigs,summary(IonD)$coefficients[[8]])
}
rminI&lt;-ronDsigs-IonDsigs
summary(rminI)

# B 部分：与 A 部分完全相同的重复，但有一点不同B8,B9,B10,B11,B12
# 这次都是常量值。
set.seed(0); n&lt;-40; numSims&lt;-10000; ronDsigs&lt;-c(); IonDsigs&lt;-c()
B8s&lt;-B9s&lt;-B10s&lt;-B11s&lt;-B12s&lt;-c()
for (index1 in 1:numSims) {
B&lt;-rnorm(n); I&lt;-rnorm(n); J&lt;-rnorm(n)
B8&lt;-3; B9&lt;-1; B10&lt;-2; B11&lt;-11; B12&lt;-19
B8s&lt;-c(B8s,B8); B9s&lt;-c(B9s,B9); B10s&lt;-c(B10s,B10); B11s&lt;-c(B11s,B11);
B12s&lt;-c(B12s,B12)
G&lt;-B*B8+I*B10; D&lt;-B*B9+I*B11+J*B12
GonB&lt;-lm(G~B)
GonBresiduals&lt;-GonB$residuals
GonBresidualsonD&lt;-lm(GonBresiduals~D)
IonD&lt;-lm(I~D)
ronDsigs&lt;-c(ronDsigs,summary(GonBresidualsonD)$coefficients[[8]])
IonDsigs&lt;-c(IonDsigs,summary(IonD)$coefficients[[8]])
}
rminI&lt;-ronDsigs-IonDsigs
summary(rminI)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652971/why-estimates-of-data-via-residuals-has-50-50-effect-on-significance-compared-to</guid>
      <pubDate>Sun, 18 Aug 2024 13:52:56 GMT</pubDate>
    </item>
    <item>
      <title>当线性回归的结果作为基于排名的算法的输入时，线性回归的假设</title>
      <link>https://stats.stackexchange.com/questions/652970/assumptions-of-linear-regression-when-its-results-are-input-for-a-ranking-based</link>
      <description><![CDATA[我运行了一个线性表达式，其中基因表达是解释变量。表达该基因的细胞的两个特征（数据是单细胞数据）是预测因子。大约有 300 个细胞，我分别对每个基因运行回归分析。
接下来，我想看看变化的模式。为此，我使用预先排序的 GSEA，它将基因的排序列表作为输入，并计算基因集在此列表顶部或底部的过度表达分数。对于两者中更有趣的预测因子，我的排名是 sign(log2FC) * -log10(pvalue)。
问题：
关于线性假设 - 是否应该检查它是否适用于所有基因？如果它不成立，它是否会偏向不仅单个基因估计，而且偏向其 p 值的等级？
注意：
如果同源性假设为假，那么（据我所知）功效很低，但结果没有偏差（对于单个基因的线性回归）。
已编辑 - 应要求提供更多详细信息：
预测因子之一是细胞来源的单个动物的年龄。有四种不同的年龄，我已将年龄转换为连续的。我没有非常精确地观察按年龄分布的情况，但似乎每个年龄的细胞数量大致相等。另一个预测因子是细胞的连续质量。
我有几种细胞类型，对每一种细胞类型分别重复分析，数量略有不同。通常，在仅选择在至少 30% 的细胞中表达量高于零的基因后，我得到了 ~3000 个基因。
我完全分开执行了回归分析。如果查看单个基因，我会调整多重比较（但这与 GSEA 无关）。
对于其中一种细胞类型，我将线性回归的结果与 limma 进行了比较（只需对由 Seurat 标准化的计数进行 lmFit 和 eBayes），结果几乎相同（就重要基因而言）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652970/assumptions-of-linear-regression-when-its-results-are-input-for-a-ranking-based</guid>
      <pubDate>Sun, 18 Aug 2024 12:49:01 GMT</pubDate>
    </item>
    <item>
      <title>DiD 设计中的横截面数据？</title>
      <link>https://stats.stackexchange.com/questions/652967/cross-sectional-data-in-a-did-design</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652967/cross-sectional-data-in-a-did-design</guid>
      <pubDate>Sun, 18 Aug 2024 09:33:22 GMT</pubDate>
    </item>
    <item>
      <title>R 中的多个时间点的元分析</title>
      <link>https://stats.stackexchange.com/questions/652985/meta-analysis-of-multiple-time-points-in-r</link>
      <description><![CDATA[我有许多研究报告了患者在特定时间点测量的生理参数（平均值、标准差）。
鉴于这些数据不是独立的；在 R 中，我如何使用这些数据进行荟萃分析，以查明时间 t1 时参数的汇总值是否与 t0 时的值不同？
我尝试使用 dosresmeta 包来构建汇总线性和非线性模型；但我无法证实该包实际上适用于配对（多个时间点）数据。
我正在考虑方差分析，但我不知道如何汇总配对数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/652985/meta-analysis-of-multiple-time-points-in-r</guid>
      <pubDate>Sun, 18 Aug 2024 00:31:33 GMT</pubDate>
    </item>
    <item>
      <title>了解何时使用负二项式 GLMM</title>
      <link>https://stats.stackexchange.com/questions/652909/understanding-when-to-use-a-negative-binomial-glmm</link>
      <description><![CDATA[我有 16 只鸟（191978、191984、191977、191980、191986、201446、191983、201447、211598、211590、211595、191981、211591、201441、201445、211592）。其中有 6 只雄性和 10 只雌性。数据集名为 Gbirds_sex。我有它们重访释放地点的次数（visitIdx）。我还有（timeInside）列来显示在释放地点内的停留时间。我想在 R 中进行统计分析，看看性别是否会影响重访次数 (visitIdx) 和停留时间 (timeInside)。我不知道哪种测试效果最好，以及它的 R 代码是什么。LLM，GLM。我应该使用随机截距吗？
我试过这些：
#1
#visitIdx 是一个计数变量，因此
# 用泊松分布拟合 GLMM
library(lme4)
model_glmm &lt;- glmer(visitIdx ~ sex + (1 | id), family =
poisson(), data = Gbirds_sex)
summary(model_glmm)
#2
#residenceTime 是连续的 - 使用高斯族。
# 使用高斯响应分布和随机 
# 截距拟合每个个体的 GLMM
model_timeInside_Gaussian &lt;- lm(timeInside ~ sex, data = 
Gbirds_sex)
summary(model_timeInside_Gaussian)

但是，分散度很高 (2.8)
我现在应该使用：
library(glmmTMB)
model_glmm_nb &lt;- glmmTMB(visitIdx ~ sex + (1 | id), 
family = nbinom2(), data = Gbirds_sex)
summary(model_glmm_nb)

关于 timeInside：
首先，我运行了一个 GLM：
拟合使用高斯族对“timeInside”进行 GLM，以“性别”作为预测因子
glm_timeInside &lt;- glm(timeInside ~ sex, data = Gbirds_sex)
summary(glm_timeInside)

其次，我检查了过度分散：
residual_deviance &lt;- deviance(glm_timeInside)
df_residual &lt;- df.residual(glm_timeInside)

计算过度分散统计量
overdispersion_statistic &lt;- residual_deviance / df_residual
print(overdispersion_statistic)

第三，由于分散度较高（7），我运行了 GLMM， timeInside 作为响应变量，sex 作为固定效应，id 作为随机效应
glmm_timeInside &lt;- lmer(timeInside ~ sex + (1|id), data = Gbirds_sex)
summary(glmm_timeInside)

这不适合

边界（奇异）拟合：请参阅 help(&#39;isSingular&#39;)

下一步是准高斯 GLM 吗？它不提供 AIC 值（“NA”）可以吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652909/understanding-when-to-use-a-negative-binomial-glmm</guid>
      <pubDate>Fri, 16 Aug 2024 03:05:07 GMT</pubDate>
    </item>
    <item>
      <title>在 Cholesky SVAR 中，为什么 B 矩阵的主对角线总是具有相同的 z 分数？</title>
      <link>https://stats.stackexchange.com/questions/652878/in-a-cholesky-svar-why-does-the-main-diagonal-of-the-b-matrix-always-have-ident</link>
      <description><![CDATA[例如，查看此处第 8 页的 B 矩阵的 z 统计信息...
https://www.stata.com/manuals/tsvarsvar.pdf
...或此处第 98 页...
https://www.eviews.com/StructVAR/structvar.pdf
...或此处 10:58：
https://www.youtube.com/watch?v=MSygD2SG_kM]]></description>
      <guid>https://stats.stackexchange.com/questions/652878/in-a-cholesky-svar-why-does-the-main-diagonal-of-the-b-matrix-always-have-ident</guid>
      <pubDate>Thu, 15 Aug 2024 15:37:29 GMT</pubDate>
    </item>
    <item>
      <title>用于建模财务回报的 AR(1) 过程的时间缩放</title>
      <link>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</link>
      <description><![CDATA[过程：
考虑一个均值为零的 AR(1) 过程，*
$\lambda_t = \kappa \cdot \lambda_{t-1} + \omega_t$，
其中 $\kappa = 0.9$，$\omega \sim N(0, \sigma_{\omega}^2)$，并且 $\sigma_{\omega}^2 = 0.00027$。 $\lambda_0$ 的初始值取自平稳分布 $N \left(0, \frac{\sigma_{\omega}^2}{(1-\kappa^2)} \right)$
我使用此过程生成长度为 $T=672$ 的样本。
* 我知道，对于股票收益建模而言，均值为零是不现实的，但我的问题并不取决于此选择。

上述时间序列应解释为每月收益（以百分点表示），即 672 个月的观测值。
问题：
什么是合适的参数值生成总共 14,112 个每日观测值（即$672 \times 21$，如果我们假设一个月内有 21 个交易日）以符合上述（每月）流程？月回报率是给定月份内所有 21 天回报率的累计乘积。
尝试（在 R 中）：
DAYS &lt;- 21
T &lt;- 672
kappa &lt;- 0.9
variance_omega &lt;- 0.00027

get_init_lambda &lt;- function(variance) return(rnorm(n = 1, mean = 0, sd = sqrt(variance / (1-(kappa)^2))))

#### 月度分析

set.seed(1234)

lambda_T &lt;- vector(mode = &quot;numeric&quot;, length = T)

lambda_shock &lt;- rnorm(T, mean = 0, sd = sqrt(variance_omega))

lambda_T[1] &lt;- kappa * get_init_lambda(variance_omega) + lambda_shock[1]
for(i in 2:T) lambda_T[i] &lt;- kappa * lambda_T[i-1] + lambda_shock[i]

acf(lambda_T)$acf[2]
# [1] 0.9064949 # 符合预期

var(lambda_T)
# [1] 0.001547795

#### 每日分析

set.seed(1234)

kappa_daily &lt;- 0.90 # ??? 如何设置 kappa_daily，使月收益 AC = 0.9？

lambda_T_daily &lt;- vector(mode = &quot;numeric&quot;, length = T * DAYS)

lambda_shock_daily &lt;- rnorm(T * DAYS, mean = 0, sd = sqrt(variance_omega / DAYS))

lambda_T_daily[1] &lt;- kappa_daily * get_init_lambda(variance_omega / DAYS) + lambda_T_daily[1]
for(i in 2:(T * DAYS)) lambda_T_daily[i] &lt;- kappa_daily * lambda_T_daily[i-1] + lambda_shock_daily[i]

# 检索月末指数；假设每个月有 21 个交易日
begin_month &lt;- seq(1, T * DAYS, 21)
end_month &lt;- c(tail(begin_month, -1) - 1, T * DAYS)

lambda_monthly_aggregate &lt;- vector(mode = &quot;numeric&quot;, length = T)

for(i in 1:T){
month_ind &lt;- (begin_month[i]):(end_month[i])

daily_ret_within_month &lt;- 0.01*lambda_T_daily[month_ind] # 收益以 % 表示
monthly_return &lt;- 100*(cumprod(1+daily_ret_within_month) - 1) # 累计每日收益

lambda_monthly_aggregate[i] &lt;- monthly_return[DAYS] # 检索累计。 21 天后返回
}

# 与上述值不相同：自相关性太低，mth 方差返回值太高！
&gt; acf(lambda_monthly_aggregate)$acf[2]
[1] 0.2988249

var(lambda_monthly_aggregate)
[1] 0.01494742

]]></description>
      <guid>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</guid>
      <pubDate>Wed, 14 Aug 2024 16:01:50 GMT</pubDate>
    </item>
    <item>
      <title>纵向多组增长模型的不变性检验。是否需要对所有时间点进行组不变性检验？</title>
      <link>https://stats.stackexchange.com/questions/652704/invariance-test-for-a-longitudinal-multi-group-growth-model-is-a-group-invarian</link>
      <description><![CDATA[我有 7 波数据，用于包含来自两个不同国家样本的构造。作为增长曲线分析的初步步骤，已经进行了纵向不变性测试，并支持部分强不变性。我的问题是，是否需要对我拥有的所有时间点进行组不变性测试？我计划在我的增长曲线模型中将国家变量指定为时间不变协变量。
此外，如果有关于需要保持“未释放”多少项目才能保持不变性的文献，那将非常有帮助。
感谢大家的支持]]></description>
      <guid>https://stats.stackexchange.com/questions/652704/invariance-test-for-a-longitudinal-multi-group-growth-model-is-a-group-invarian</guid>
      <pubDate>Tue, 13 Aug 2024 09:17:42 GMT</pubDate>
    </item>
    </channel>
</rss>