<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 12 May 2024 09:13:48 GMT</lastBuildDate>
    <item>
      <title>对于两个概率密度函数 $\rho_1(x,t)$ 和 $\rho_2(x,t)$，$\log[\rho_1(x,t)]-v*\log[\rho_2(x) 是多少,t)]$？ $(0<v<1/2)$</title>
      <link>https://stats.stackexchange.com/questions/647074/for-two-probability-density-functions-rho-1x-t-and-rho-2x-t-what-is</link>
      <description><![CDATA[
有什么区别吗$\log[\rho_1(x,t)]-\log[\rho_2(x,t)]$ 类似于似然比？

差异的名称是什么 (ii) $\log[\rho_1(x,t)]-v*\log[\rho_2(x,t) )]$，其中 $0？它的性质与 (i) 有何关系？例如，(i) 的方差是多少，(ii) 的方差是多少？

]]></description>
      <guid>https://stats.stackexchange.com/questions/647074/for-two-probability-density-functions-rho-1x-t-and-rho-2x-t-what-is</guid>
      <pubDate>Sun, 12 May 2024 09:00:05 GMT</pubDate>
    </item>
    <item>
      <title>顺序更新与边缘化更新</title>
      <link>https://stats.stackexchange.com/questions/647073/sequential-updating-vs-marginalized-updating</link>
      <description><![CDATA[假设我需要对后验 $\pi(\theta|D)$ 进行采样，其分析形式不易处理（甚至达不到标准化常数） 。然而，我以某种方式设法获得了增强的后部 $\pi(\theta,z|D)$。
我的问题是：如果我按如下方式进行顺序（吉布斯）更新：

使用 $z&#39;\sim\pi(z|\ 更新 $z\leftarrow z&#39;$ θ,D)$;

使用 $\theta&#39;\sim\pi( 更新 $\theta\leftarrow\theta&#39;$ \theta|z&#39;,D)$;

循环


然后，如果我丢弃 $z$ 的样本，只保留 $\theta$ 的样本， $\theta$ 的这些样本是否相当于 $\pi(\theta|D):=\int 中的样本\pi(\theta,z|D){\rm d}z$？谢谢！
请注意，我所说的等效性是指 2 个比较样本以相同的速率收敛进行分析。此外，“更新”可能不是直接从分布中采样，而是使用某种 MCMC 方法（例如 Langevin 动力学）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647073/sequential-updating-vs-marginalized-updating</guid>
      <pubDate>Sun, 12 May 2024 08:16:58 GMT</pubDate>
    </item>
    <item>
      <title>是否可以训练神经网络以输入随机森林分类器或任何其他类型的分类器（例如 XGBoost 或决策树）？</title>
      <link>https://stats.stackexchange.com/questions/647072/is-it-possible-to-train-a-neural-network-to-feed-into-a-random-forest-classifier</link>
      <description><![CDATA[我想创建一个模型架构来预测未来的股价走势，如下所示：

该模型的目标是预测未来 3 个月内价格是上涨还是下跌。
我尝试了一些模型，例如逻辑回归、神经网络、XGBoost 等。我收到了一些不错的结果。通过使用随机森林分类器，到目前为止我收到了最好的结果。我收到了一些关于使用自动编码器然后将编码数据输入决策树的建议。我对这种方法的唯一问题是，我希望编码数据具有来自神经网络的附加值，而不仅仅是数据的压缩版本。所以我的问题是：如何使用神经网络对数据进行编码，然后将这些值传递给随机森林分类器进行分类，而不是使用如图所示的 sigmoid 函数的最终输出层（使用 Python、Keras、和 SKlearn）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647072/is-it-possible-to-train-a-neural-network-to-feed-into-a-random-forest-classifier</guid>
      <pubDate>Sun, 12 May 2024 08:06:56 GMT</pubDate>
    </item>
    <item>
      <title>包含不同分布的独立样本之和的随机变量是否遵守中心极限定理？</title>
      <link>https://stats.stackexchange.com/questions/647071/does-a-random-variable-that-includes-the-summation-of-independent-samples-from-d</link>
      <description><![CDATA[
我正在学习sheldon M ross的统计学书籍，这是一本很棒的书。然而，我遇到了一个小问题，这本书未能解决我的问题。 A根据 CLT ，当 n 足够大时，无论各个随机变量的基本分布如何，随机变量的总和都是正态的。 现在我的问题是这些单独的随机变量是否一定必须具有相同（相同）分布才能使中心极限定理成立。假设我从一个正态分布中选择某些样本 ，另一个来自指数和其他几个来自二项式并将它们相加，只要它们是独立的，它们的总和是否仍然服从正态分布？
就像X= X1+X2+X3+......+Xn
其中 X1,X2,X3 服从正态分布
X4,X5,X6 来自二项式分布
X7,X8, ..来自指数分布等等。
我的意思只是这些随机变量来自不同的分布，并不相同。金额也会正常吗？
我尝试使用Python代码进行模拟，发现结果很正常。概括这个结果可以吗？还是太天真了？
 将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

＃ 参数
lam = 2 # 指数分布的 Lambda 参数



列表1=[]
对于范围（10000）内的 i：
  Normal_samples = np.random.normal(4,9,5)
  exponential_samples = np.random.exponential(scale=1/lam, size=3)
  binomial_samples = np.random.binomial(100, 0.1, 3)

  sum_exponential=np.sum(exponential_samples)
  sum_random=np.sum(normal_samples)
  sum_binomial=np.sum(binomial_samples)

  # 计算随机变量的总和
  sum_X = np.sum(sum_exponential+sum_random+sum_binomial)
  list1.append(sum_X)

  # 绘制直方图
  
plt.hist(list1, bins=100, 密度=True, alpha=0.6, color=&#39;g&#39;)
打印（列表1）


plt.show()

]]></description>
      <guid>https://stats.stackexchange.com/questions/647071/does-a-random-variable-that-includes-the-summation-of-independent-samples-from-d</guid>
      <pubDate>Sun, 12 May 2024 07:51:30 GMT</pubDate>
    </item>
    <item>
      <title>模型（约束）房产销售概率</title>
      <link>https://stats.stackexchange.com/questions/647070/model-constraint-sale-probability-of-properties</link>
      <description><![CDATA[我正在尝试根据价格、房产特征（质量、大小等）、空间和时间对（度假租赁）房产的销售概率进行建模。我每天都会这样做，并获得合理的 F1 分数。
唉，这最终产生了乐观的估计，因为我猜它假设存在不受限制的需求，并且在单位级别而不是在每日“单位类型”级别上真正起作用。有什么我可以做的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647070/model-constraint-sale-probability-of-properties</guid>
      <pubDate>Sun, 12 May 2024 07:12:23 GMT</pubDate>
    </item>
    <item>
      <title>如何将多元 DKW 不等式排列到 n 的上限？</title>
      <link>https://stats.stackexchange.com/questions/647066/how-to-arrange-multivariate-dkw-inequality-to-a-upper-bound-on-n</link>
      <description><![CDATA[多元 DKW 不等式 给出
$$\Pr \left[ \sup_{t \in \mathbb{R}^k} \left| F_n(t) - F(t) \right| &gt; \epsilon \right] \leq (n+1)k e^{-2n\epsilon^2},$$
其中 $F_n(t)$ 是 eCDF，$F(t)$ 是总体 CDF、$\epsilon \in \mathbb{R}_{&gt;0}$ 和 $n,k \in \mathbb{N}$。
我想要找到的是给定其他输入的 $n$ 的上限。我尝试使用 Lambert $W$ 函数&lt; /a&gt; 但我未能成功地将事物安排成正确的形式来应用它。]]></description>
      <guid>https://stats.stackexchange.com/questions/647066/how-to-arrange-multivariate-dkw-inequality-to-a-upper-bound-on-n</guid>
      <pubDate>Sun, 12 May 2024 05:30:17 GMT</pubDate>
    </item>
    <item>
      <title>带约束和加权最小二乘的矩阵分解</title>
      <link>https://stats.stackexchange.com/questions/647065/matrix-decomposition-with-constraints-and-weighted-least-squares</link>
      <description><![CDATA[我们有一个矩阵，$\mathbf{X}$，包含 6 个不同结果之间的概率分布，因此每行 $\mathbf{x}_i$ 总和为 1。我们想要执行降维，以便每一行都是两个分量的线性插值，$\mathbf{f }$ 和 $\mathbf{g}$，也是概率分布。换句话说，每一行 $\mathbf{x}_i$ 都有一个潜在变量 $c_i$ 所以$\mathbf{x}_i \sim c_i \mathbf{f} + (1 - c_i) \mathbf{g}$。此外，我们还有以下限制：

组件中的某些概率为 0：

$\mathbf{f}$ 的形式为 $(f_0, 0, f_2, f_3, f_4, f_5)$。
$\mathbf{g}$ 的形式为 $(0, g_1, g_2, g_3, g_4, 0)$.


作为概率分布，$\mathbf{f}$ 和 $\mathbf{g}$总和也为 1。

此外，对于准确估计，某些结果比其他结果更重要，因此我们希望对最小二乘误差进行加权：让行的估计 $x_i$为 $\hat{x}_i = c_i \mathbf{f} + (1 - c_i) \mathbf{g}$。我们希望最小化残差平方的加权和 $$\sum_{j=0}^{5} w_j (x_j - \hat{x}_j)^2.$ $
我目前正在使用 Python，但愿意使用其他工具来解决这个问题。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/647065/matrix-decomposition-with-constraints-and-weighted-least-squares</guid>
      <pubDate>Sun, 12 May 2024 03:45:08 GMT</pubDate>
    </item>
    <item>
      <title>条件模型中的 VIF 较低，但零膨胀模型中的 VIF 较高</title>
      <link>https://stats.stackexchange.com/questions/647064/low-vif-in-conditional-model-but-high-in-zero-inflated-model</link>
      <description><![CDATA[我正在使用 glm ZINB 制作模型，根据 57 个地点的观察结果预测青蛙的丰度。我使用了性能包中的 check_model 函数，它显示最佳模型在条件模型中具有较低的 vif（vif&lt;5），但在零膨胀模型中具有较高的 vif（最多 50）（我在下面附上了图片） 。我是统计领域的新手，我想知道应该如何处理这些结果。我知道 vif&gt;5 的变量不应在 glms 中组合，但我不确定它如何适用于零膨胀 glms 中的两个模型。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647064/low-vif-in-conditional-model-but-high-in-zero-inflated-model</guid>
      <pubDate>Sun, 12 May 2024 03:16:44 GMT</pubDate>
    </item>
    <item>
      <title>使用 fpp3 的 R 中的 SEATS 和 X-11 分解模型结果不一致</title>
      <link>https://stats.stackexchange.com/questions/647062/inconsistent-results-with-seats-and-x-11-decomposition-models-in-r-using-fpp3</link>
      <description><![CDATA[在使用 fpp3 包在 R 中应用时间序列分解模型时，我遇到了不一致的行为，并且需要一些指导。
我有来自巴西中央银行的广泛全国消费者价格指数 (IPCA)（每月变化百分比）的时间序列，我已成功将其转换为 tsibble 对象。当我应用 X-11 分解模型时，它运行得很好，但我遇到了 SEATS 模型的问题。
&lt;前&gt;&lt;代码&gt;库(rbcb)
库（fpp3）

ipc_pre = get_series(433, start_date=&#39;2007-02-01&#39;, end_date=&#39;2017-01-01&#39;)
ipca &lt;- ts(ipc_pre$`433`, start=c(2007,02), freq=12)
# 将 ts 对象转换为 tsibble 以与 fpp3 一起使用
ipca_tsibble &lt;- as_tsibble(ipca)

# 应用 X-11 分解模型，没有任何问题：
ipca_x11_dcmp &lt;- ipca_tsibble |&gt;;
  模型（x11 = X_13ARIMA_SEATS（值〜x11（）））|&gt;
  成分（）

自动绘图（ipca_x11_dcmp）+
  labs(title = “使用 X-11 进行 IPCA 分解。”)

# 应用SEATS模型时遇到错误：
ipca_seats_dcmp &lt;- ipca_tsibble |&gt;;
  模型（座位= X_13ARIMA_SEATS（值〜座位（）））|&gt;
  成分（）

错误消息是：
SEATS 中使用的模型不同：(0 2 2)
`transmute()` 中的错误：
ℹ 在参数中：`cmp = map(.fit, elements)`。
由 `mutate()` 中的错误引起：
ℹ 在参数中：`seasonal = dcmp[, &quot;adjustfac&quot;]`。
由 `dcmp[, &quot;adjustfac&quot;]` 中的错误引起：
！限制论坛指数
运行 rlang::last_trace() 查看错误发生的位置。

在第二次尝试时，SEATS 模型在没有 Components() 函数的情况下执行，但我不确定为什么第一次尝试失败。
我很困惑为什么 X-11 模型可以无缝运行，而 SEATS 模型却不能。 Components() 函数是否存在问题，或者是否还有其他原因？对于这两个模型之间的不同结果的任何见解或解释，我将不胜感激。
更新
我进行了一些可能有帮助的分析。
图书馆（季节性）
检查X13()

（调整&lt;-海洋（ipca））
SEATS 中使用的模型不同：(0 2 2)

称呼：
海洋(x = ipca)

系数：
         恒定 AR-非季节性-01 AR-非季节性-02 MA-非季节性-01 MA-季节性-12
           0.4899 0.2852 0.1895 -0.4120 -0.2848

和
摘要（调整）

称呼：
海洋(x = ipca)

系数：
                  估计标准。误差z值Pr(&gt;|z|)
常数 0.48993 0.05807 8.437＜ 2e-16 ***
AR-非季节性-01 0.28515 0.85572 0.333 0.73896
AR-非季节性-02 0.18951 0.57508 0.330 0.74176
MA-非季节性-01 -0.41203 0.83793 -0.492 0.62292
MA-季节性-12 -0.28481 0.09321 -3.056 0.00225 **
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

座位调整。 ARIMA：(2 0 1)(0 0 1) 观察值：120 变换：无
AICc：-42.99，BIC：-27.01 QS（最终没有季节性）：5.008。
Box-Ljung（无自校正）：25.29 Shapiro（正态性）：0.9849
X-13 生成的消息：
警告：
- 无法对零值或负值的序列进行自动转换选择。
- 在一个或多个估计光谱中发现了视觉上显着的季节性和交易日峰值。

笔记：
- 用于 SEATS 分解的模型与 regARIMA 建模模块中估计的模型不同
  X-13ARIMA-座位。

尝试绘制 SEATS 模型调整图
情节（调整）


qs(调整)
                  qs p-值
索里 5.00792 0.08176
qsorievadj 5.00792 0.08176
qsrsd 0.00000 1.00000
qssadj 5.00792 0.08176
qssadjevadj 5.00792 0.08176
qsir 1.57514 0.45495
qsirrevadj 1.57514 0.45495
索里 4.76131 0.09249
qssorievadj 4.76131 0.09249
qssrsd 0.02985 0.98519
qsssadj 4.76131 0.09249
qsssadjevadj 4.76131 0.09249
qssirr 1.60777 0.44759
qssirrevadj 1.60777 0.44759

终于
# 月图遇到错误
月图（调整，col.base = 1，lty.base = 2，标签=month.abb，lwd.base = 2）
Monthplot.seas 中的错误（ajuste，col.base = 1，lty.base = 2，labels = Month.abb，：
  模型没有季节性成分

尽管 SEATS 模型摘要中存在显着的季节性 MA 成分，但月图函数表明不存在季节性成分。这种矛盾令人费解，我正在寻求深入了解为什么会发生这种情况。]]></description>
      <guid>https://stats.stackexchange.com/questions/647062/inconsistent-results-with-seats-and-x-11-decomposition-models-in-r-using-fpp3</guid>
      <pubDate>Sun, 12 May 2024 02:01:59 GMT</pubDate>
    </item>
    <item>
      <title>如何处理极小的训练数据？</title>
      <link>https://stats.stackexchange.com/questions/647061/how-to-deal-with-extremely-small-training-data</link>
      <description><![CDATA[我有大约 100 行带有标签的数据
国家/地区 |类别 |标签
-----------+----------------+--------------------
[美国、英国、日本] |电子| 1
[美国] |体育 | 1
[台湾、英国] |杂货| 2
[日本] |预订 | 3

大约 900 行没有标签的数据
国家/地区 |类别
-----------+--------------
[美国、英国] |运动的
[台湾] |运动的
[美国] |杂货店
[日本] |电子的

使用这么小的数据集做分类模型可以吗？如果是这样，我该如何编码Country？或者是否有任何其他聚类/数学方法可以用来处理这种情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/647061/how-to-deal-with-extremely-small-training-data</guid>
      <pubDate>Sun, 12 May 2024 01:44:33 GMT</pubDate>
    </item>
    <item>
      <title>用两个变量相乘来优化目标？</title>
      <link>https://stats.stackexchange.com/questions/647060/optimizing-objective-with-two-variables-multiplied-with-each-other</link>
      <description><![CDATA[假设您想要优化以下目标函数：
$$\min_{a,b} \Vert ab - W \Vert_2^2$$
$$\min_{a,b} \Vert (ab) \cdot W \Vert_2^2 \quad\quad\text{(阿达玛积)}$$
$$\min_{a,b} \Vert abW^T \Vert_2^2$$
$$\min_{a,b} \Vert ab + Wb^T \Vert_2^2$$
其中 $a \in \mathbb{R}^{m,n}$ 和 $b \in \ mathbb{R}^{n,p}$ 是可学习矩阵，$W \in \mathbb{R}^{m,p}$ 是给你的一些常数矩阵。
由于 $a$ 和 $b$ 通过某些操作错综复杂地链接在一起（可以是，例如，乘法、除法、哈达玛积等），有哪些方法可以优化这些类型的多元目标函数？
普通梯度下降有效吗？我认为我的理解还不足以肯定地说。
经过初步研究，我们似乎可以进行贪婪搜索：在每次迭代中，按住 $a$ （或 $b$) 常量，然后仅针对单个变量进行优化 $b$ （或 $a$ ）通过梯度下降。每次迭代后，交替变量。
贪婪搜索听起来与坐标下降类似，我想知道是否有其他方法在整体上更加稳健并且不易出现局部极小值。
似乎有另一种方法称为 EM（期望最大化算法），它假设 $a$ 或 $b $ 是一个潜在变量，但除此之外，感觉它在做与贪婪搜索相同的事情，只是在随机设置中。
除了贪婪搜索之外，还有哪些其他优化算法可以处理复杂链接的多个变量（通过乘法、除法等）？]]></description>
      <guid>https://stats.stackexchange.com/questions/647060/optimizing-objective-with-two-variables-multiplied-with-each-other</guid>
      <pubDate>Sun, 12 May 2024 00:51:01 GMT</pubDate>
    </item>
    <item>
      <title>样本量和变异系数</title>
      <link>https://stats.stackexchange.com/questions/647058/sample-size-and-coefficient-of-variation</link>
      <description><![CDATA[我想知道样本量和变异系数 (CV) 之间的关系。 CV 定义为标准差与平均值的比率。我们是否可以说“样本量越小，CV 越大，因此关系呈负相关”？
库(dplyr)
库（r样本）

cv &lt;- 函数(x){返回(sd(x)/mean(x))}
sim &lt;- data.frame(id=1:100000,
                变量=rpois(100000, 5),
                group10=样本(1:10,100000,替换=TRUE),
                group100=样本(1:100,100000,替换=TRUE),
                group1000=样本(1:1000,100000,替换=TRUE),
                group10000=样本(1:10000,100000,替换=TRUE)
                ）
AA &lt;- NULL
G &lt;- c(10,100,1000,10000)
for(k in 1:4){
  for(j in 1:G[k]){

  如果（k==1）{
    A &lt;- dplyr::filter(sim, group10==j)
  }否则如果(k==2){
    A &lt;- dplyr::filter(sim, group100==j)
  }否则如果(k==3){
    A &lt;- dplyr::filter(sim, group1000==j)
  }否则如果(k==4){
    A &lt;- dplyr::filter(sim, group10000==j)
  }
  
  AA &lt;- rbind(AA, c(G[k],
                    j,
                    n行(A),
                    平均值（A  $变量），
                var(A$变量),
                    sd(A$变量),
                简历（A$变量）
                    ）
              ）
  }
}
AA &lt;- as.data.frame(AA)
colnames(AA)＜-c(“组”、“组N”、“N”、“平均值”、“Var”、“SD”、“CV”)
头(AA)
尾部(AA)

AA10 &lt;- AA %&gt;% 过滤器(组==10)
AA100 &lt;- AA %&gt;% 过滤器(组==100)
AA1000 &lt;- AA %&gt;% 过滤器(组==1000)
AA10000 &lt;- AA %&gt;% 过滤器(组==10000)

(简历(sim$变量))

par(mfrow = c(1, 4))
图(AA10$N,AA10$CV, ylim=c(0,1.2), ylab=“CV”,xlab=“样本大小”,
     主=“10组”）
abline(h=cv(sim$variable),col=&quot;red&quot;)
绘图(AA100$N,AA100$CV, ylim=c(0,1.2), ylab=&quot;CV&quot;,xlab=&quot;样本大小&quot;,
 主要=“100组”）
abline(h=cv(sim$变量),col=“红色”)
绘图(AA1000$N,AA1000$CV, ylim=c(0,1.2), ylab=“CV”,xlab=“样本大小”,
     main=“1,000 组”）
abline(h=cv(sim$variable),col=&quot;red&quot;)
绘图(AA10000$N,AA10000$CV, ylim=c(0,1.2), ylab=&quot;CV&quot;,xlab=&quot;样本大小&quot;,
 主要=“10,000组”）
abline(h=cv(sim$变量),col=“红色”)
dev.off()

]]></description>
      <guid>https://stats.stackexchange.com/questions/647058/sample-size-and-coefficient-of-variation</guid>
      <pubDate>Sun, 12 May 2024 00:00:18 GMT</pubDate>
    </item>
    <item>
      <title>“随机变量的置信区间”是不正确的术语吗？</title>
      <link>https://stats.stackexchange.com/questions/647022/is-it-incorrect-terminology-to-say-confidence-interval-of-a-random-variable</link>
      <description><![CDATA[我见过“总体参数不是随机变量”的说法。在讨论置信区间时。
例如此处
&lt;块引用&gt;
请务必注意，总体参数不是随机变量。

在频率论解释的背景下，我毫不犹豫地接受这一说法。根据这种解释，总体参数是固定的，但未知。它们不是随机变量。
但是术语置信区间是否也带有特定的解释？或者它只是数学函数（如 wiki 所示）：
&lt;块引用&gt;


例如，假设我认为 𝜃（总体参数）是随机变量，X 是随机样本。考虑到它们的联合分布，我计算函数：
P( u(x) &lt; 𝜃 &lt; v(x)) = c ∀ 𝜃
看起来像下图中的红线：

（图借自此处）
现在，我将红线称为“随机变量的置信区间”是错误的吗？ 𝜃？]]></description>
      <guid>https://stats.stackexchange.com/questions/647022/is-it-incorrect-terminology-to-say-confidence-interval-of-a-random-variable</guid>
      <pubDate>Sat, 11 May 2024 10:12:44 GMT</pubDate>
    </item>
    <item>
      <title>生物神经元的多向传播 - 我们可以/应该重新创建它，例如与关节分布神经元？</title>
      <link>https://stats.stackexchange.com/questions/646959/multidirectional-propagation-of-biological-neurons-could-should-we-recreate-it</link>
      <description><![CDATA[虽然人工神经网络经过相当多的单向传播训练，但生物神经元中的动作电位传播是对称的，例如“动作电位的轴突传播在两个方向上发生的情况并不少见”（摘自“轴突中信号传播和碰撞的动力学&quot; PRE)。由于可能，它们应该针对这种多向传播进行进化优化，这可能是至关重要的，例如对于学习（目前还不太理解），意识（？）
是否考虑过以多向方式运行的人工神经元？
一种方法是以某种方式包含联合分布模型的表示，例如$\rho(x,y,z)$，它允许通过替换一些变量并标准化来找到任何方向的条件分布 - 下面是来自 &lt; 的廉价实际实现a href=&quot;https://arxiv.org/pdf/2405.05097&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://arxiv.org/pdf/2405.05097 ，允许许多额外的训练方法 - 生物学可以使用一些其中？
有不同的方法吗？研究这个方向？
多向传播对于（例如学习）生物神经网络重要/关键吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/646959/multidirectional-propagation-of-biological-neurons-could-should-we-recreate-it</guid>
      <pubDate>Fri, 10 May 2024 04:53:45 GMT</pubDate>
    </item>
    <item>
      <title>最大似然法是否必须应用于简单随机样本或实现？</title>
      <link>https://stats.stackexchange.com/questions/646815/must-maximum-likelihood-method-be-applied-on-a-simple-random-sample-or-on-a-real</link>
      <description><![CDATA[我想我的麻烦不是一个大问题，但问题是：当一个人应用最大似然时，他考虑实现$(x_1, \dots, x_n)$ 简单随机样本 (SRS)，从而得出 ML估计。但如果有人想谈论偏差、一致性等问题，就必须提到估计器，对吗？
例如，在这个维基百科示例中，考虑正常示例，他们最终得到 $\hat{\mu}=\bar{x}$ ，然后写入 $\mathbb{E }(\hat{\mu})=\mu$ 这可以说有点草率，因为获取确定性数量的期望值并没有多大意义。
因此，我的问题是为什么通常（我的意思是，大多数来源：维基百科、教科书等）MLE 是基于实际数据（即基于 SRS 的实现）而不是基于 SRS 构建的（也就是说，随机变量的集合 $(X_1, \dots, X_n)$)，提供了计算期望值等有意义的估计器？我想这是一种虚假的微妙之处，没有什么实际意义，因为它足以“大写字母化”。估计得到相应的估计器，但我还是想问。]]></description>
      <guid>https://stats.stackexchange.com/questions/646815/must-maximum-likelihood-method-be-applied-on-a-simple-random-sample-or-on-a-real</guid>
      <pubDate>Wed, 08 May 2024 12:55:10 GMT</pubDate>
    </item>
    </channel>
</rss>