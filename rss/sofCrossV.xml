<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 12 Jun 2024 12:28:07 GMT</lastBuildDate>
    <item>
      <title>逻辑模型 - 劳动概率（优势比）</title>
      <link>https://stats.stackexchange.com/questions/649098/logit-model-labor-probabilityodds-ratio</link>
      <description><![CDATA[给出的逻辑回归模型如下：
$$
\text{劳动概率} = \alpha + \beta_1 * \text{收入} + \beta_2 * 年龄 + \beta_3 * \text{教育} + \beta_4 * \text{幼儿} + \beta_5 * \text{老年} + \beta_6 * \text{外国} + \beta_7 * \text{年龄}^2
$$
我想知道当逻辑回归模型中其他变量固定为平均值，而教育变量从 9 增加到 12 时，如何计算比值比的变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/649098/logit-model-labor-probabilityodds-ratio</guid>
      <pubDate>Wed, 12 Jun 2024 11:25:03 GMT</pubDate>
    </item>
    <item>
      <title>当 p>n 时自动变量选择的动机</title>
      <link>https://stats.stackexchange.com/questions/649094/motivation-for-automated-variable-selection-in-case-of-pn</link>
      <description><![CDATA[我写了下面的文字，作为在变量数 (p) 大于观测数 (n) 的情况下使用自动变量选择的动机。但是，当 n &lt; p 时，我对使用 t 检验进行变量选择并不完全有信心，然后争辩说它在这种情况下的不可靠性证明了需要使用自动变量选择方法。
有人能对这种方法提出建议或意见吗？有没有更好的方法来激励在 p &gt; 的情况下使用自动变量选择？ n 场景？

考虑标准线性设置，


$\underset{(n \times 1)}{y} = \underset{(n \times k)}{x} \ \underset{(k \times 1)}{\beta} + \underset{(n \times 1)}{u} \ \text{with} \ t = 1, \ldots, n$


只要参数数量 $ k $ 小于，$ \hat{\beta} = (X&#39;X)^{-1}X&#39;Y $ 就可以轻松使用平方损失函数得出观测值的数量 $ n $。根据高斯-马尔可夫假设，$ \hat{\beta} $ 将 $ Y $ 投射到 $ X $ 上，而 $ X $ 与 $ U $ 正交。在这种情况下，选择相关变量将是一个简单的问题，因为可以使用简单的 t 检验来消除无法拒绝 t 检验的零假设的无关变量。但是，只要 $ k \geq n $，此设置就不再起作用。对于 $ k = n $，估计结果完美拟合，残差方差为 0，使得 t 检验不切实际。而对于 $ k &gt; n ，\text{rank}(X) = \text{rank}(X&#39;X) \leq n &lt; k $，因此，$ X&#39;X $ 不可逆，导致无法识别估计值。
]]></description>
      <guid>https://stats.stackexchange.com/questions/649094/motivation-for-automated-variable-selection-in-case-of-pn</guid>
      <pubDate>Wed, 12 Jun 2024 09:57:03 GMT</pubDate>
    </item>
    <item>
      <title>OLS 加权平均值是什么？</title>
      <link>https://stats.stackexchange.com/questions/649093/what-weighted-average-is-ols</link>
      <description><![CDATA[我们如何从拟合最小二乘法的线性回归中找到协变量的加权平均值？
考虑模型
$$
Y = \beta_0 + \beta_1 \tau + \beta_2 X_1 + \epsilon
$$
其中 $Y$ 是连续变量，$\tau$ 是二元变量 {0, 1}，$x_1$ 是分类变量。如果我们感兴趣的对象是 $\tau$ 的系数，我们可能对 $X_1$ 中每个因子的相对贡献感兴趣。
众所周知，$\beta_1$ 是一个加权平均值，其中 $X_1$ 中的每个因子 $j$ 都获得以下权重。
$$
\tag{1}
\frac{w(j)}{\sum{w(j{})}} 
$$
其中

$w(j) = q(j) \cdot e(j) \cdot (1 - e(j))$ 和
$q(j) = \frac{N(j)}{N}$ 是每个因子中单位的比例
$e(j) = \frac{N_{\tau = 1}(j)}{N(j)}$ 是每个因子中 $\tau = 1$ 的单位的比例。

现在考虑添加一个额外的协变量
$$
Y = \beta_0 + \beta_1 \tau + \beta_2 X_1 + \beta_3 X_2 + \epsilon
$$
其中 $X_2$ 是一个连续变量。当 $X_2$ 独立于 $Y$ 时，(渐近地) (1) 仍然成立。那么当 $X_2$ 不独立于 $Y$ 时，情况又如何呢？是否有可能找到一个像 (1) 这样的方程，我们可以将 $X_1$ 中每个因素的单独贡献分解为 $\beta_1$ 的加权平均值？是否有办法使用 Frisch-Waugh-Lovell 定理来找到这些权重？]]></description>
      <guid>https://stats.stackexchange.com/questions/649093/what-weighted-average-is-ols</guid>
      <pubDate>Wed, 12 Jun 2024 09:46:46 GMT</pubDate>
    </item>
    <item>
      <title>有限窗口的数据</title>
      <link>https://stats.stackexchange.com/questions/649092/data-with-a-limited-window</link>
      <description><![CDATA[我目前正在写我的硕士论文，但我有点卡住了。
对于我的论文，我做了一个问题，关于人们对某种产品的渴望程度以及哪些因素对他们的渴望程度起着最大的作用，数据如下：
想要的产品因素 1 - 因素 2 - 因素 3 - .... - 因素 10
50 人给出了每个因素 + 想要的产品分数（满分 5 分）（所以他们不对其进行排名，每个人的答案都可以是 5）。
我尝试使用普通的 lm(Want.the.product~factor 1 - factor 2 - factor 3 - .... - factor 10)
但没有意义，我认为这是因为数据从 1 到 5，但我没有办法以不同的方式分析它。
希望你能帮忙。]]></description>
      <guid>https://stats.stackexchange.com/questions/649092/data-with-a-limited-window</guid>
      <pubDate>Wed, 12 Jun 2024 09:28:40 GMT</pubDate>
    </item>
    <item>
      <title>多个二项分布的结果分布</title>
      <link>https://stats.stackexchange.com/questions/649090/distribution-of-outcomes-of-multiple-binomial-distributions</link>
      <description><![CDATA[我有 50 名受试者的样本，其中每个受试者完成一项具有两种可能结果（左手或右手使用，概率为 50%）的任务 30 次。在个人层面上，这导致每个受试者的结果呈二项分布，其中可以计算每个受试者的 z 分数，以查看手的使用距离预期的 50%（15 个左手和右手使用）水平有多远。根据 z 分数，我们将那些大于 1.96（›1.96）的值视为右撇子，那些低于 -1.96（‹-1.96）的值视为左撇子，那些介于两者之间（-1.96‹‹1.96）的值视为双侧。
问题：在我的 50 名受试者样本中，z 分数的预期比率（或 z 分数的分布）是多少？这是否与个人层面的情况相同，即双侧利手的可能性为 95%，左撇子或右撇子的可能性为 2.5-2.5%？]]></description>
      <guid>https://stats.stackexchange.com/questions/649090/distribution-of-outcomes-of-multiple-binomial-distributions</guid>
      <pubDate>Wed, 12 Jun 2024 09:07:47 GMT</pubDate>
    </item>
    <item>
      <title>如何在 lavaan/semTools 中获取蒙特卡洛方法的间接效应标准化系数？</title>
      <link>https://stats.stackexchange.com/questions/649088/how-to-get-standardized-coefficients-of-monte-carlo-method-for-indirect-effects</link>
      <description><![CDATA[我使用 semTools 运行了路径分析。我有兴趣测试间接影响。我想报告基于蒙特卡罗置信区间的结果。但是，代码 monteCarloCI(output, unified = TRUE) 无法生成系数的标准化估计，因为根据 semTools 手册，standardized = TRUE 仅适用于 lavaan 类，而不适用于 lavaan.mi。我使用了 runMi 函数，因为我有多个插补数据集，所以我有 lavaan.mi 对象。
我读过这篇文章 如何使用带有 semTools / Lavaan R 包的完全标准化解决方案的probe2WayMC()？。建议的解决方案是将所有变量标准化，使 SD = 1，然后再次运行分析。标准化估计值将仅仅是与非标准化估计值及其检验一起报告的效应大小。
我的模型中的所有变量都是可观察的（没有潜在变量），并且是连续的。
我的问题是 - 此方法是否也适用于使用蒙特卡洛方法获得间接效应的标准化估计值？我只对获得间接效应系数的标准化估计值感兴趣，但如果此方法也可用于生成标准化蒙特卡洛置信区间，那就太好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/649088/how-to-get-standardized-coefficients-of-monte-carlo-method-for-indirect-effects</guid>
      <pubDate>Wed, 12 Jun 2024 08:42:23 GMT</pubDate>
    </item>
    <item>
      <title>偏回归图和偏依赖图有什么联系？</title>
      <link>https://stats.stackexchange.com/questions/649087/what-is-the-connection-of-a-partial-regression-plot-and-a-partial-dependence-plo</link>
      <description><![CDATA[我们有一个偏回归图，定义如下：https://en.m.wikipedia.org/wiki/Partial_regression_plot

它的实用性在添加变量图（偏回归图）在多元回归中解释了什么？中进行了讨论，本质上，即使某个特征与其他特征相关，它也可以看到该特征的效果。
现在还有偏依赖图的概念https://scikit-learn.org/stable/modules/partial_dependence.html
当我们想要查看随机治疗时，这似乎很有用（与其他特征无关 =&gt; 部分依赖图允许调查平均治疗效果：https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7597863/ )
在我看来，偏回归图是偏依赖图的扩展（考虑相关特征）。不幸的是，我没有找到明确的文献。有人能证实这种联系或强调重要的区别吗？
在治疗不是随机分配的环境中（即不在随机研究中），我可以通过查看偏回归图来获得平均治疗效果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649087/what-is-the-connection-of-a-partial-regression-plot-and-a-partial-dependence-plo</guid>
      <pubDate>Wed, 12 Jun 2024 08:38:38 GMT</pubDate>
    </item>
    <item>
      <title>因子分析中直接效应和相关性有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/649086/what-is-the-difference-between-direct-effect-and-correlation-in-factor-analysis</link>
      <description><![CDATA[我正在阅读因子分析的短期课程材料：
https://www.hsph.harvard.edu/wp-content/uploads/sites/59/2016/10/harvard-lecture-series-session-4_Factor-analysis.pdf#page=38.00

这里，作者提到有一种倾斜的情况，其中载荷的解释将不同于正交情况：
因子载荷的解释不再是 Y 和 F 之间的相关性；而是 F 对 Y 的直接影响。
它与 DAG 有关吗？例如 F1&gt;F2&gt;Y2，因此 F1 的一些间接影响可能无法在载荷中测量？]]></description>
      <guid>https://stats.stackexchange.com/questions/649086/what-is-the-difference-between-direct-effect-and-correlation-in-factor-analysis</guid>
      <pubDate>Wed, 12 Jun 2024 07:45:15 GMT</pubDate>
    </item>
    <item>
      <title>与 Wilcoxon 和 ANOVA 不同的 p 值</title>
      <link>https://stats.stackexchange.com/questions/649077/different-p-value-from-wilcoxon-and-anova</link>
      <description><![CDATA[我从 Wilcoxon 检验和 ANOVA 检验中获得了不同的 $p$ 值。当我使用 Wilcoxon 检验时，$p$ 值小于 $0.05$:
treatmentA &lt;- drug$weight[treatment == &quot;A&quot;]
treatmentB &lt;- drug$weight[treatment == &quot;B&quot;]

wilcox.test(treatmentA, treatmentB, paired = F)

如果运行 ANOVA，$p$ 值大于 $0.05$:
aov(weight~treatment, data = drug)

有 $2$ 个独立样本（比较来自处理 A 和 B))，样本中超过 $100$ 人，数据缺失，权重呈偏态分布。
我应该用什么？结果是因为缺失值吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649077/different-p-value-from-wilcoxon-and-anova</guid>
      <pubDate>Tue, 11 Jun 2024 23:17:47 GMT</pubDate>
    </item>
    <item>
      <title>泊松减去一个常数仍然是泊松吗？</title>
      <link>https://stats.stackexchange.com/questions/649069/is-a-poisson-minus-a-constant-still-a-poisson</link>
      <description><![CDATA[我正在处理一个过程，其中我期望我的变量服从泊松分布。但是，由于与比例有关的原因，我获得的值的最小值为 11。
我注意到，当我使用 R 函数（例如 fitdistrplus::fitdist）估计我的数据与泊松分布的拟合度时，我的数据最适合泊松分布（遵循 AIC 值），但只有当我从观测向量中减去最小值 11 时（这样做的理由是泊松中的值从零开始）。
例如，以下内容与泊松分布的拟合度很差：
obs &lt;- c(15, 15, 13, 14, 13, 12, 12, 14, 14, 12, 11, 13, 11, 12, 12, 
13, 14, 14, 13, 11, 12, 14, 17, 12, 14, 12, 12, 12, 12, 
13, 16, 15, 15, 17, 13, 13, 13, 13, 14, 14, 13, 15)
fitdist(obs, &quot;pois&quot;)

但减去最小值后，拟合效果更好。
fitdist(obs-11, &quot;pois&quot;)

然而，这当然会改变 lambda 参数，在泊松分布中，我相信这也会改变分布的形状。我不仅不确定我的转换是否正确，而且如果不正确，为什么拟合度会提高。
有人可以指出关于这个主题的参考资料，以了解我的转换是否正确吗？即泊松减常数是否仍以泊松分布？
编辑：为了澄清起见，我处理的变量是基因组中新生突变的发生率。这些是罕见事件，通常被建模为泊松过程。在每个单倍体基因组和代的突变数量尺度上，每个单倍体基因组和代（obs向量）观察到几十个突变。这就是最小值为 11 的原因。但是，请注意，这里有尺度的影响。在二倍体基因组的尺度上，obs 中的值将会翻倍，而在每个核苷酸位点（而不是每个基因组）的尺度上，obs 中的值都会非常小（例如 ~6*10e-8），以至于会四舍五入为零。]]></description>
      <guid>https://stats.stackexchange.com/questions/649069/is-a-poisson-minus-a-constant-still-a-poisson</guid>
      <pubDate>Tue, 11 Jun 2024 22:57:56 GMT</pubDate>
    </item>
    <item>
      <title>P 值不显著，但蒙特卡洛置信区间不包含间接效应的零</title>
      <link>https://stats.stackexchange.com/questions/649058/p-values-non-significant-but-monte-carlo-confidence-interval-does-not-contain-ze</link>
      <description><![CDATA[我使用 semTools 进行了路径分析。我有兴趣测试间接效应。所有间接效应的 p 值都不显著，但其中一些的蒙特卡洛置信区间不包含零。
我的问题是 - 仅使用蒙特卡洛置信区间而不使用 p 值来报告和解释结果是否合适？
我在网上搜索了一下，但恐怕信息有限。我看到了这篇文章：p 值不显著但 CI 不包含 0，但答案谈到了引导法。在我的研究中，我使用了多重插补来处理缺失数据，因此引导法不合适。
以下是一些显示冲突结果的代码。由于我的模型代码很长，因此我没有在下面显示它。我已显示与我的问题相关的代码。下面的间接效应 19 和 20 具有不显著的 p 值，但蒙特卡洛 CI 不包含零。
我看到一些人说他们不会相信 p 值，因为它们是在假设 Z 统计量来自标准正态分布（因此可能有利于蒙特卡洛 CI）的情况下计算的。但我也看到一些人说 p 值和 CI（虽然不是蒙特卡洛特有的）应该彼此一致。如果它们不一致，我不应该拒绝零假设。有人能解释一下吗？
output &lt;- runMI(model, data=data3c.mi.1, fun=&quot;sem&quot;, estimator = &quot;MLR&quot;, se = &quot;robust.huber.white&quot;)

估计 Std.Err t 值 df P(&gt;|t|) ci.lower ci.upper Std.lv Std.all
indirect19 0.118 0.074 1.593 1563.011 0.111 -0.027 0.264 0.119 0.008
indirect20 0.090 0.055 1.639 1924.600 0.101 -0.018 0.198 0.091 0.009
indirect21 0.146 0.126 1.152 714.059 0.250 -0.102 0.393 0.147 0.010
indirect22 0.112 0.097 1.147 664.112 0.252 -0.080 0.303 0.112 0.011

monteCarloCI（输出，标准化 = TRUE）

est ci.lower ci.upper
indirect19 0.119 0.001 0.297
indirect20 0.091 0.001 0.215
indirect21 0.147 -0.059 0.393
indirect22 0.112 -0.044 0.303
]]></description>
      <guid>https://stats.stackexchange.com/questions/649058/p-values-non-significant-but-monte-carlo-confidence-interval-does-not-contain-ze</guid>
      <pubDate>Tue, 11 Jun 2024 18:30:05 GMT</pubDate>
    </item>
    <item>
      <title>为嵌套模型选择正确的 R LME4 语法 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649052/selecting-the-correct-r-lme4-syntax-for-nested-models</link>
      <description><![CDATA[我们寻求有关在 R lme4 包中嵌套随机效应的正确语法的建议。
我们旨在模拟完全受试者间设计中各组之间的反应时间 (RT) 差异。每个受试者 (n=120) 完全嵌套在三个组之一中。每个受试者有 200 个观察值，我们计划为每个受试者包含一个随机截距，以解释观察的非独立性。但是，我们希望这个随机截距能够解释组内受试者的嵌套，以避免混淆我们的主要固定组效应。
根据各种帖子和论文，我们认为以下是正确的语法：
model1 &lt;- lmer(RT ~ Group + (1|Group:Subject), data=df)
有人可以验证一下吗？值得注意的是，该模型产生的结果与以下模型非常相似但又不同：
model2 &lt;- lmer(RT ~ Group + (1|Subject), data=df)
Robert Long 在此处的回答（交叉和嵌套随机效应组合的 Lmer 模型语法）表明我们的模型 1 和模型 2 应该相同，但结果存在差异。
如果有人能提供任何帮助，我将不胜感激]]></description>
      <guid>https://stats.stackexchange.com/questions/649052/selecting-the-correct-r-lme4-syntax-for-nested-models</guid>
      <pubDate>Tue, 11 Jun 2024 16:11:40 GMT</pubDate>
    </item>
    <item>
      <title>面板数据逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/649047/panel-data-logistic-regression</link>
      <description><![CDATA[我正在处理一个面板数据集，该数据集将公司代码描述为 ID 变量，将财政年度描述为时间变量（2013 年至 2022 年的 1500 家公司）。因变量是二进制的。首先，我使用 STATA 中的 vif 检查了多重共线性：
regress 因变量 独立变量 控制变量

vif 

之后，我做了以下事情：
xtlogit 因变量 独立变量 控制变量 i.year, fe
估计值 存储 fe
xtlogit 因变量 独立变量 控制变量 i.year, re
估计值 存储 re
hausmann fe re

p 值小于 0.05，因此我选择条件固定效应逻辑回归。
为了解释预测变量对二元结果可能性的影响，我使用了比值比：
xtlogit 因变量 独立变量 控制变量 i.year, fe 或
这个过程正确吗？但是，如果我使用固定效应的条件逻辑回归，观测值的数量就会从 7500 个减少到 2500 个。这有问题吗？
非常感谢您的帮助和想法！]]></description>
      <guid>https://stats.stackexchange.com/questions/649047/panel-data-logistic-regression</guid>
      <pubDate>Tue, 11 Jun 2024 15:55:40 GMT</pubDate>
    </item>
    <item>
      <title>如何用外行人能理解的术语解释风险比</title>
      <link>https://stats.stackexchange.com/questions/649029/how-to-explain-hazard-ratio-in-laypersons-terms</link>
      <description><![CDATA[在 Cox 回归分析中，我最近听到有人说“两个治疗组之间的风险比为 0.70，这表明在整个随访期间，对照组中发生事件的 100 人中，只有干预组中的 70 人发生事件”。这是对 HR 的有效简化，还是还有其他非技术性的解释？]]></description>
      <guid>https://stats.stackexchange.com/questions/649029/how-to-explain-hazard-ratio-in-laypersons-terms</guid>
      <pubDate>Tue, 11 Jun 2024 11:46:22 GMT</pubDate>
    </item>
    <item>
      <title>如果 Bland-Altman 分析显示方法 A 和方法 B 之间的差异与平均值之间存在近乎完美的相关性，那么如何改进测试方法 B？</title>
      <link>https://stats.stackexchange.com/questions/649018/how-to-improve-testing-method-b-if-bland-altman-analysis-show-a-near-perfect-co</link>
      <description><![CDATA[我有两组测量结果（两种不同的方法），A 和 B。
测量结果之间的相关性很小。

因此，我想知道测量程序（一个或两个）中是否存在一些固有偏差。
绘制 Bland-Altman 图后，我惊讶地发现相关性非常显著（见图）。

这种相关性似乎意味着这些方法测量的不是同一种现象。

这是对的吗？
这些信息可以用来改进其中一种方法（即廉价方法）吗？我想到了一个对数变换...
在差异和平均值之间的这种相关性中是否确实隐藏着更多“信息”？
]]></description>
      <guid>https://stats.stackexchange.com/questions/649018/how-to-improve-testing-method-b-if-bland-altman-analysis-show-a-near-perfect-co</guid>
      <pubDate>Tue, 11 Jun 2024 08:10:46 GMT</pubDate>
    </item>
    </channel>
</rss>