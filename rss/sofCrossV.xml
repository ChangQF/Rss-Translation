<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 09 Oct 2024 09:19:01 GMT</lastBuildDate>
    <item>
      <title>倾向评分匹配的局限性</title>
      <link>https://stats.stackexchange.com/questions/655519/limitations-of-propensity-score-matching</link>
      <description><![CDATA[在研究倾向得分匹配时，我突然想到了以下想法：
当我们运行逻辑回归模型通过某种形式的参数化来估计$p(Z=1∣X)$并且我们没有进行精确匹配时，我们如何确定我们最终匹配的是相似的协变量？一般来说，我们会期望这一点。然而，偶然地，非常不同的协变量可能具有相似的倾向得分，可能是因为它们都不太可能接受治疗。在这种情况下，当我们匹配它们时，我们实际上是在匹配非常不同的协变量。有人可以澄清这是否是一个普遍问题吗？如果是，我们通常会怎么做 - 例如匹配后协变量检查？]]></description>
      <guid>https://stats.stackexchange.com/questions/655519/limitations-of-propensity-score-matching</guid>
      <pubDate>Wed, 09 Oct 2024 09:10:17 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归：共线性或接近共线性的参数的部分效应解释</title>
      <link>https://stats.stackexchange.com/questions/655518/multiple-linear-regression-partial-effects-interpretation-of-parameters-at-near</link>
      <description><![CDATA[我正在看一个最简单的多元线性回归模型示例：
\begin{equation}\label{linreg}
Y = \beta_1 X_1 + \beta_2 X_2 + \varepsilon,
\end{equation&gt;
我对当 $X_1=X_2$（共线性）或 $\text{cor}(X_1, X_2)$ 非常高（可能是 $\text{cor}(X_1, X_2)&gt;0.999$）时获得的参数估计值（同时估计）感兴趣。
回归系数的标准解释是偏效应：$\beta_1$ 是 $X_1$ 增加一个单位时 $Y$ 的变化，同时控制所有其他变量（此处仅 $X_2$）。但是，如果 $X_1=X_2$，则一旦我们控制了 $X_2$，$X_1$ 显然无法再解释 $Y$ 中的任何变化。基于此推理，我期望得到估计值$\hat\beta_1=0$，并且基于相同推理，我期望得到$\hat\beta_2=0$。
但是，如果我估计回归模型（在完全共线情况下使用贝叶斯模型，或在近共线情况下使用贝叶斯/频率论），我会得到 beta 系数，其总和等于真实参数的总和$\beta_1+\beta_2$。从优化的角度来看，这也是有道理的，因为如果 $X_1=X_2$，则上述模型的 RHS 可以重写为 $(\beta_1+\beta_2)X_1 + \varepsilon$，这也说明了为什么模型无法识别。
基于上述内容，似乎 $\beta_1, \beta_2$ 的部分效应解释与我在（近）共线情况下得到的结果不一致。显然，我犯了一个推理错误，我希望有人能指出这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/655518/multiple-linear-regression-partial-effects-interpretation-of-parameters-at-near</guid>
      <pubDate>Wed, 09 Oct 2024 08:49:59 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中模拟随时间变化的响应数据</title>
      <link>https://stats.stackexchange.com/questions/655516/how-to-simulate-response-data-that-varies-over-time-in-r</link>
      <description><![CDATA[我正在使用 R 模拟一些数据以进行功效分析，我们将在实验环境中测试儿童的反应时间，看看这是否能预测以后的语言技能。儿童将根据第三个变量分组（此处为 Group）。我们将使用的统计模型如下所示：语言 ~ RT * 时间点 + Group。
我在创建 RT 变量时遇到了一些困难，因此它随着时间的推移而变化，并且与受试者相关。它应该随着时间的推移而增加，效果为 0.2，但当然这会因参与者而异，有些人的增幅较大，有些人的增幅较小（假设抖动效果为 0.1）。类似地，有些参与者的总体观察时间会更长，有些则更短。
我们目前的代码大致如下：
 SimulatedData &lt;- function(
MeanIntrpct = 37.5, # 基线语言分数
MeanSlope = 14.63, # 组对语言分数的总体影响
Group = 0.39, # 组对语言分数的估计影响
time_slope = .2, # 时间点对反应时间的估计影响
n_subjects = 60,
n_timepoints = 3, 
RandIntrpct_subjects = 0.2, # 受试者的随机截距
RandSlope_subjects = 0.2, # 受试者的随机斜率
Randslope_subject_time = 0.1 # 受试者之间时间的抖动效应
){

# 模拟受试者

SimulatedSubjects &lt;- faux::rnorm_multi(
n = n_subjects, 
mu = 0, 
sd = c(RandIntrcpt_subjects, RandSlope_subjects, Randslope_subject_time), 
varnames = c(&quot;RandIntrcpt_subjects_StdDev&quot;, &quot;RandSlope_subjects_StdDev&quot;, 
&quot;RandSlope_subjects_time_StdDev&quot;)) %&gt;%
mutate(ChildID = faux::make_id(nrow(.), &quot;S_&quot;),
RT = runif(n_subjects, min = -0.5, max = 0.5), # 创建标准化 RT
Group = sample(c(1, 2), 60, replace= T)) # 将一半参与者分配到组 1/组 2

# 创建时间点

timepoints &lt;- data.frame(Timepoint = seq_len(n_timepoints))

# 创建组合数据框 - 模拟受试者与时间点交叉

SimulatedSubjectsAndStimuli &lt;- crossing(SimulatedSubjects, timepoints)}
SimulatedData &lt;- SimulatedData()

此输出基本上看起来符合我们的预期，只是 RT 变量对于三个时间点的每个孩子都是相同的。我们如何在模拟数据中改变它以表示我们预期的随时间变化类型（即总体上更长的观察时间，这与受试者相关）？]]></description>
      <guid>https://stats.stackexchange.com/questions/655516/how-to-simulate-response-data-that-varies-over-time-in-r</guid>
      <pubDate>Wed, 09 Oct 2024 08:09:21 GMT</pubDate>
    </item>
    <item>
      <title>偏最小二乘法与典型相关分析之间的差异</title>
      <link>https://stats.stackexchange.com/questions/655514/difference-between-partial-least-squares-and-canonical-correlation-analysis</link>
      <description><![CDATA[据我所知，典型相关分析 (CCA) 和偏最小二乘 (PLS) 旨在识别空间中的一组投影，其中样本具有最大相关性（在 CCA 中）或协方差（在 PLS 中）。
因此，从本质上讲，在 CCA 中，我们忽略了协方差矩阵的非对角线元素。这对我来说很有意义，因为（我猜）我们不关心已识别投影之间的相互关系。事实上，我们不希望它们相关（否则它们会相同），所以我想我们希望非对角线为零。
我的问题是：

为什么我们要在 PLS 中最大化非对角线？
如果我们在 PLS 中最大化协方差（因此我们最终得到相关的投影），那么我们最终会不会得到重复的（无信息的）投影？
维基百科似乎表明优化是成对的。但如果是这样的话，我们最终会得到 CCA，不是吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655514/difference-between-partial-least-squares-and-canonical-correlation-analysis</guid>
      <pubDate>Wed, 09 Oct 2024 06:39:08 GMT</pubDate>
    </item>
    <item>
      <title>规范化计数数据的最佳实践</title>
      <link>https://stats.stackexchange.com/questions/655511/best-practice-for-normalizing-count-data</link>
      <description><![CDATA[在规范化数据计数方面，最佳做法是什么？我觉得对数据的解释最能表达数据结构和我想要规范化的内容。
我有一个基本函数，它将生成 10,000 个值
def output_vector()
ran_array = np.rand.random(100)
return ran_array

我所做的是计算有多少个值高于截止值（假设为 0.5）。然后计算这个数字，并重复该过程 x 次。这将产生一个计数数据框，其范围从 0 到返回向量的长度。
0 1 2 3 4 ... n
35 38 32 28 23 ... m 

我使用这些数据的目的是查看生成的计数是否导致正态分布。但是，由于数据最终可能会偏向 0，因此我觉得在执行任何偏度测试之前，我应该先对数据进行标准化。
由于这种数据不是连续的，是否可以对这种类型的数据进行标准化？]]></description>
      <guid>https://stats.stackexchange.com/questions/655511/best-practice-for-normalizing-count-data</guid>
      <pubDate>Wed, 09 Oct 2024 04:47:15 GMT</pubDate>
    </item>
    <item>
      <title>余弦相似度对连续变量的有用性</title>
      <link>https://stats.stackexchange.com/questions/655510/cosine-similarity-usefulness-for-continuous-variables</link>
      <description><![CDATA[有人要求我识别与产品 A 相似的“同类”产品，有人建议我识别一组相关特征并计算每个可能相似的产品与产品 A 之间的余弦相似度。我将使用的特征主要是数字，尽管我也会包含一些离散变量。
这引出了一个关于余弦相似度何时有用的一般问题。例如，如果我有两个向量：
p1 = [10, 20, 40]

p2 = [1000, 2000, 4000]

在这种情况下，cosine_sim(p1, p2) = 1。
但是，如果虽然向量彼此成比例，但每个向量值的幅度差异是有意义的，该怎么办？例如，如果我考虑的特征之一是产品 A 和产品 B 的平均产品增长加速度，那么 10% 和 1000% 的加速度是有显著差异的。对于离散值，我更了解为什么这种度量有意义，但很难理解它对连续变量的用处。
我应该使用不同的相似性度量吗？我的想法正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655510/cosine-similarity-usefulness-for-continuous-variables</guid>
      <pubDate>Wed, 09 Oct 2024 03:36:30 GMT</pubDate>
    </item>
    <item>
      <title>我们可以在受限似然函数上使用费舍尔评分吗？</title>
      <link>https://stats.stackexchange.com/questions/655508/can-we-use-fisher-scoring-on-a-restricted-likelihood-function</link>
      <description><![CDATA[我有一个关于如何在混合效应回归模型中优化 RMLE 的问题。
从混合效应模型开始：
$$y = X\beta + Zu + e$$
$$u \sim N(0, G), \quad e \sim N(0, R)$$
其中：

$y$ 是 $n \times 1$ 观测向量
$X$ 是 $n \times p$ 固定效应设计矩阵
$\beta$ 是 $p \times 1$ 固定效应向量
$Z$ 是 $n \times q$ 随机效应设计矩阵
$u$ 是 $q \times 1$ 随机效应向量
$e$ 是 $n \times 1$ 残差向量

$y$ 的边际分布为（其中 $V = ZGZ^T + R$):
$$y \sim N(X\beta, V)$$
如果我们定义 $K = I - X(X^TX)^{-1}X^T$ 和 $y^* = Ky$。 $y^*$ 的分布为：
$$y^* \sim N(0, KVK^T)$$
$y^*$ 的对数似然为（注意：RMLE 中没有固定效应项，只有混合效应项，即方差）：
$$\begin{align*}
L(\theta) &amp;= -\frac{1}{2}\log|KVK^T| - \frac{1}{2}y^{*T}(KVK^T)^{-1}y^* \\
&amp;= -\frac{1}{2}\log|KVK^T| - \frac{1}{2}y^TK^T(KVK^T)^{-1}Ky
\end{align*}$$
再进行一些代数运算，我们得到 RMLE 对数似然的最终形式：
$$L(\theta) = -\frac{1}{2}\log|V| - \frac{1}{2}\log|X^TV^{-1}X| - \frac{1}{2}y^TPy + \text{constant}$$
我们通常如何优化上述 RMLE？我认为可以使用一些拟牛顿技术（例如 BFGS），但我想知道是否仍然可以计算 RMLE 的预期 Fisher 信息并在此使用 Fisher 评分，或者只是使用实际的 hessian 执行类似迭代重加权最小二乘的操作？]]></description>
      <guid>https://stats.stackexchange.com/questions/655508/can-we-use-fisher-scoring-on-a-restricted-likelihood-function</guid>
      <pubDate>Wed, 09 Oct 2024 02:40:14 GMT</pubDate>
    </item>
    <item>
      <title>为什么简单回归中的最小二乘估计量的方差取决于预测变量？</title>
      <link>https://stats.stackexchange.com/questions/655507/why-variance-of-least-square-estimator-in-simple-regression-is-conditional-on-pr</link>
      <description><![CDATA[我是统计学新手，现在正在阅读 Sanford Weisberg 的《应用线性回归》一书。我可能问了一个无意义的问题，但为什么简单回归中的最小二乘估计量$\hat{\beta_0}$和$\hat{\beta_1}$的方差是$Var(\hat{\beta_0} |X)$和$Var(\hat{\beta_1} |X)$，而不是$Var(\hat{\beta_0})$和$Var(\hat{\beta_0})$？
假设我们有随机变量$X$和$Y$；并且我们有实现$x_i$和$y_i$。我使用样本预测器$\mathbf{x} = (x_1,x_2,...x_n)$和响应$\mathbf{y} = (y_1,y_2,...y_n)$估计了这些参数$\beta_0$和$\beta_1$。因此，我认为 $\hat{\beta_0}$ 和 $\hat{\beta_1}$ 的变异性应该来自于从 $X$ 中抽样加上以 $X$ 为条件的 $Y$ 的随机误差。然而，使用$Var(\hat{\beta_0} |X)$和$Var(\hat{\beta_1} |X)$表明变异性仅来自$Y$的随机误差。
同样的问题也出现在估计量$\hat{\beta_0}$和$\hat{\beta_1}$的无偏性的证明上。本书证明了$E(\hat{\beta_0}|X)=\beta_0$和$E(\hat{\beta_1}|X)=\beta_1$，但我认为目标应该是$E(\hat{\beta_0})$和$E(\hat{\beta_1})$。]]></description>
      <guid>https://stats.stackexchange.com/questions/655507/why-variance-of-least-square-estimator-in-simple-regression-is-conditional-on-pr</guid>
      <pubDate>Wed, 09 Oct 2024 02:24:46 GMT</pubDate>
    </item>
    <item>
      <title>我们如何阻止贝叶斯估计过度自信？</title>
      <link>https://stats.stackexchange.com/questions/655504/how-do-we-stop-bayesian-estimates-from-being-overconfident</link>
      <description><![CDATA[我今天发布了一个关于小样本回归策略的问题。我认为贝叶斯回归可能是一个不错的选择：用于校正小样本的贝叶斯回归
有一件事我很好奇，我读到贝叶斯推理的优势在于它可以防止在我们对数据没有信心或样本量较小的情况下估计值出现非常大的方差。在这种情况下，与数据相比，估计值可以向先验收缩，从而与非贝叶斯方法相比，降低了参数估计值的方差。
我只是想知道，我们如何防止/我们如何知道贝叶斯方差的减少不是明显低估方差？在我看来，唯一要做的就是选择一个非常大的先验（例如非信息先验）来反映我们的不确定性，然而这样做似乎会将方差拉回到非贝叶斯方向。除此之外，听起来没有免费的午餐，而且贝叶斯推理只有在你真正对自己的先验选择有信心的情况下才有优势？]]></description>
      <guid>https://stats.stackexchange.com/questions/655504/how-do-we-stop-bayesian-estimates-from-being-overconfident</guid>
      <pubDate>Wed, 09 Oct 2024 01:10:00 GMT</pubDate>
    </item>
    <item>
      <title>如何实现和记录二维矩阵到三维张量的复制/变换以及三维张量到二维矩阵的求和/变换？</title>
      <link>https://stats.stackexchange.com/questions/655503/how-to-implement-and-notate-the-replication-transformation-of-a-2d-matrix-to-a-3</link>
      <description><![CDATA[背景：
我有一个模型，其维度为 $T$，代表 $time$；维度为 $N$，代表 $technologies$；维度为 $P$，代表 $prices$。在此模型中进行计算时，我想添加 $T$ 维度（为每个时间步骤复制数据），并删除 $N$ 维度（总和 N）。
我必须在 numpy 中实现此模型，并以数学方式记录它。我如何

实现并记录 2D 矩阵到 3D 张量的复制/转换？
实现并记录 3D 张量到 2D 矩阵的求和/转换？

一方面，符号应使用尽可能接近使用的 numpy 操作的数学运算符/操作，但也要保持数学文档的正确性，让没有数学学位的用户（比如我）也能读懂。另一方面，使用的 numpy 操作应该可以用数学运算符/概念来表达。
有时不同的数学运算似乎具有相同的数学符号。在其他情况下，在我看来，一个数学运算可以用不同的运算符表示，在某些情况下，一个数学运算似乎有许多可能的 numpy 实现。
如果没有正确或错误的答案，我会对意见、惯例或最佳实践感兴趣。我不确定这是否更适合 stack exchange 数学、stackoverflow 或此平台。

复制维度
从 1D 到 2D：我有一个行向量 $A \in \mathbb{R}^{1 \times P}$。现在，我想将此向量复制到矩阵 $C \in \mathbb{R}^{N \times P}$，例如，每种技术应该具有相同的价格。我考虑过用一个向量来表示这个克罗内克积：
$C^{N \times P} = 1^{N \times 1} \otimes A^{1 \times P}$
C_NxP = np.kron(one_Nx1, A_1xP)

从 2 D 到 3D：现在，我想将这个 $C^{N \times P}$ 矩阵转换为 $D \in \mathbb{R}^{T \times N \times P}$ 张量，例如，每个时间步骤都具有相同的技术和价格。我考虑将其表示为张量积，其符号似乎与克罗内克积相同
$D^{T \times N \times P} = 1^{T \times 1} \otimes C^{N \times P}$
D_Tx1xNxP = np.tensordot(One_Tx1, C_NxP, axis=0) # 错误：返回 Tx1xNxP

但如果 $1^{T \times 1}$ 是实际的 numpy 列向量（形状为 Tx1），则相应的 numpy 操作将返回错误的形状，并且我更希望不要明确地将 2D numpy 向量重塑为 1D numpy 向量。但是，使用 np.einsum 可以工作：
D_TxNxP = np.einsum(&#39;io,jk-&gt;ijk&#39;, One_Tx1, C_NxP)

因此，将其表示为 $T_{ijk} = D_{i1} \cdot C_{jk}$ 是否更好？这里的 Tensorproduct 和 Einstein sum 是否相同？如果是，我可以将其表示为 Tensorproduct 吗？

求和/减少维度：
从 2D 到 1D：我有 $G \in \mathbb{R}^{T \times N}$，我想按时间步长对技术求和。我认为将其表示为矩阵乘法：
$E^{T \times 1} = C^{T \times N} * 1^{N \times 1}$
E_Tx1 = G_TxN @ 1_Nx1

从 3D 到 2D：现在，我想将其应用于张量 $D \in \mathbb{R}^{T \times N \times P}$ 并求和每个价格水平 p 的技术值，例如求和“内部”矩阵 ${N \times P}$ 维度为 N。看来爱因斯坦求和约定又起作用了。
$M_{tp} = B_{tnp} \, C_n$
M_TxP = np.einsum(&#39;tnp,n-&gt;tp&#39;, B_TxNxP, C_Nx1) 

但据我所知，我也可以将其表示为 n 模乘积，这对我来说看起来更具可读性：
$M^{T \times P} = B^{T \times N \times P} \times_{\!N}\, C^{N \times 1}$
这样对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655503/how-to-implement-and-notate-the-replication-transformation-of-a-2d-matrix-to-a-3</guid>
      <pubDate>Wed, 09 Oct 2024 00:58:41 GMT</pubDate>
    </item>
    <item>
      <title>2024 年诺贝尔物理学奖获奖声明不正确吗？</title>
      <link>https://stats.stackexchange.com/questions/655502/is-the-nobel-prize-in-physics-2024-statement-of-merit-incorrect</link>
      <description><![CDATA[今天，诺贝尔基金会宣布 2024 年诺贝尔物理学奖，获奖理由如下：

表彰那些使机器学习和人工神经网络成为可能的基础性发现和发明

我的问题是：J. Hopfield 和 G. E. Hinton 的工作是否真的使机器学习和人工神经网络成为可能？
（最初发表于 AI，经修改）]]></description>
      <guid>https://stats.stackexchange.com/questions/655502/is-the-nobel-prize-in-physics-2024-statement-of-merit-incorrect</guid>
      <pubDate>Wed, 09 Oct 2024 00:53:52 GMT</pubDate>
    </item>
    <item>
      <title>马尔可夫状态 GBM 的最大似然</title>
      <link>https://stats.stackexchange.com/questions/655501/max-likelihood-of-gbm-with-markov-state</link>
      <description><![CDATA[考虑随机过程
$$dX_t = \mu_{\epsilon_t}X_tdt + \sigma_{\epsilon_t}X_tdW_t$$
其中$W_t$是标准布朗运动。过程$X_t$是几何布朗运动，其均值和方差取决于具有状态空间$\{H,L\}$的独立两状态马尔可夫链。因此，我们有四个参数

$\mu_H$：状态 $H$ 的平均漂移
$\mu_H$：状态 $L$ 的平均漂移
$\sigma_H$：状态 $H$ 的标准差
$\sigma_L$：状态 $L$ 的标准差

马尔可夫过程有自己的转移矩阵：

$p_H$ 是从状态 $L$ 跳转到状态 $H$ 的条件概率

$p_L$ 是从状态 $H$ 跳转到状态 $L$ 的条件概率


总体而言，该模型有六个参数。请注意，马尔可夫过程并非隐藏的，并且假定是可观察的。

问题：如果 $X_t$ 是具有对数正态分布的标准几何布朗运动，我可以根据 $X_t$ 的实现时间序列，找到 $\mu$ 和 $\sigma$ 的简单最大似然估计量。但在更一般的设置中该怎么做？具有状态切换的 $X_t$ 是否也具有已知的 MLE？]]></description>
      <guid>https://stats.stackexchange.com/questions/655501/max-likelihood-of-gbm-with-markov-state</guid>
      <pubDate>Wed, 09 Oct 2024 00:24:00 GMT</pubDate>
    </item>
    <item>
      <title>Newey-West 误差的具体滞后</title>
      <link>https://stats.stackexchange.com/questions/655499/specific-lag-for-newey-west-errors</link>
      <description><![CDATA[
我目前正在进行一个关于股票收益的研究项目，但我真的不知道该如何进行。我已经在 STATA 上生成了残差的相关图，以了解自相关结构，如图所示。但我真的不知道如何在这种情况下应用 Newey-West 误差，因为它要求我为回归指定特定的截断滞后，而自相关结构无处不在。我真的不确定 newey-west 经验法则 $q=4(T/100)^{2/9}$ 是否合适或是否应该在这里使用，或者是否应该指定其他滞后长度。如果有人能帮助我，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655499/specific-lag-for-newey-west-errors</guid>
      <pubDate>Tue, 08 Oct 2024 22:36:33 GMT</pubDate>
    </item>
    <item>
      <title>在 10 个样本中，从 21 个列表中选择少于 4 个唯一数字的概率（有放回）</title>
      <link>https://stats.stackexchange.com/questions/655485/probability-of-selecting-less-than-4-unique-numbers-from-a-list-of-21-in-10-samp</link>
      <description><![CDATA[我有一份包含 21 个数字的列表，编号为 0 到 20（或 1 到 21，无所谓）。我随机挑选 10 次，每次都使该选择可用于下一次选择。这 10 次选择中唯一数字少于 4 个的概率是多少？
我用一个我认为正确的公式来解决组合问题，但是当我在电子表格上模拟该过程时，我得到了一个非常不同的结果：请问​​正确的公式是什么？以下是我对如何获得公式和模拟结果的解释。
选择少于 4 个唯一数字的概率是始终选择相同数字的概率 + 选择 2 个不同数字的概率 + 选择 3 个不同数字的概率。
$$P(&lt;4) = P(1) + P(2) +P(3)$$
我第一次从 10 个数字中挑选出一个独特的数字。第二次挑选时，我可以选择相同的数字，概率为 $\frac1{21}$，也可以选择不同的数字，概率为 $\frac{20}{21}$。在第一次选择之后的 9 次选择中始终选择相同数字的概率为
$$P(1) = \left(\frac1{21}\right)^9$$
在第二次选择之后，我选择了一个与第一次不同的数字，然后我还有第三次选择，我可以选择前 2 个数字中的一个，概率为 $\frac2{21}$，或者选择第三个不同的数字，概率为 $\frac{19}{21}$。在前 2 个数字之后，我在剩余的 8 次选择中继续选择相同的 2 个数字的概率为
$(\frac{2}{21})^8$，因此
$$P(2) = \frac{20}{21}\left(\frac{2}{21}\right)^8$$
继续同样的思路，在第 4 次选择时，我可以选择之前选择的 3 个数字之一，概率为 $\frac3{21}$，或者选择第 4 个不同的数字，概率为 $\frac{18}{21}$。在前 3 个数字之后，我在剩余的 7 次选择中继续选择相同的 3 个数字的概率为
$(\frac{3}{21})^7$，因此
$$P(3) = \frac{20}{21}\frac{19}{21}\left(\frac3{21}\right)^7$$
将三项相加
$$P(&lt;4) = \left(\frac1{21}\right)^9 + \frac{20}{21}\left[\left(\frac{2}{21}\right)^8 + \frac{19}{21}\left(\frac3{21}\right)^7\right] = $$
这给了我大约 $P(&lt;4) = 0.00011\%$
当我尝试通过在 Google 表格中模拟该过程来验证结果时，我无法模拟足够的试验进行计算；上面的概率意味着大约 909,000 次试验的平均值是 1，但我发现 Google 表格允许我模拟大约 47,500 次试验。因此，我将问题从 10 次选择缩减为 8 次选择，通过归纳法获得
$$P(&lt;4) = \left(\frac1{21}\right)^7 + \frac{20}{21}\left[\left(\frac{2}{21}\right)^6 + \frac{19}{21}\left(\frac3{21}\right)^5\right] = 0.0052\%$$
但是当我模拟它时，我得到 $P(&lt;4) = 0.016\%$
我用来模拟上述结果的 Google Sheets 公式是
=countif( byrow( map(RANDarray(55000, 8), lambda(x, int(x*21))), lambda(trial,COUNTUNIQUE(trial)) ), &quot;&lt;4&quot;) / 55000
]]></description>
      <guid>https://stats.stackexchange.com/questions/655485/probability-of-selecting-less-than-4-unique-numbers-from-a-list-of-21-in-10-samp</guid>
      <pubDate>Tue, 08 Oct 2024 18:49:31 GMT</pubDate>
    </item>
    <item>
      <title>因果推理中两种潜在结构的等价性</title>
      <link>https://stats.stackexchange.com/questions/655478/equivalence-of-two-latent-structures-in-causal-inference</link>
      <description><![CDATA[这是 Judea Pearl 教授在其经典专著因果关系：模型、推理和推论（第 2.1 节脚注 5）中提出的主张。对于下面的两个因果结构（其中“$(*)$”表示具有任意数量状态的隐藏变量），作者指出

为了验证 (a) 和 (b) 是否等价，我们注意到，如果我们让链接 $a \leftarrow *$ 在两个变量之间施加相等性，则 (b) 可以模仿 (a)。相反，(a) 可以模仿 (b)，因为它能够生成具有 (b) 所包含的独立性的每个分布。


我很难验证这个论点的“相反”方向。它似乎意味着以下等式对任何 r.v 都成立。 $u$（假设图中的所有 r.v. 都是离散的）：
\begin{align*}
p(a)p(b)p(c|a, b)p(d|c) = \sum_u p(u)p(a|u)p(c|u, b)p(d|c),
\end{align*&gt;
或
\begin{align*}
p(b)p(c|a, b) = \sum_u p(u|a)p(c|u, b) \tag{1}\label{1}
\end{align*&gt;
但是，$\eqref{1}$ 确实很难证明（如果我的理解正确的话），或者我误解了以下结构的定义偏好？？

定义 2.3.3（结构偏好） 一个潜在结构 $L = \langle D, O \rangle$ 优于另一个 $L&#39; = \langle D&#39;, O\rangle$（写为 $L \preceq L&#39;）$，当且仅当 $D&#39;$ 能够模仿 $D$ 超过 $O$——也就是说，当且仅当对于每个 $\Theta_D$ 都存在一个 $\Theta_{D&#39;}&#39;$ 使得 $P_{[O]}(\langle D&#39;, \Theta_{D&#39;}&#39;\rangle) = P_{[O]}(\langle D, \Theta_{D}\rangle)$。两个潜在结构等价，写为 $L \equiv L&#39;$，当且仅当 $L \preceq L&#39;$ 和 $L \succeq L&#39;$。
]]></description>
      <guid>https://stats.stackexchange.com/questions/655478/equivalence-of-two-latent-structures-in-causal-inference</guid>
      <pubDate>Tue, 08 Oct 2024 15:58:15 GMT</pubDate>
    </item>
    </channel>
</rss>