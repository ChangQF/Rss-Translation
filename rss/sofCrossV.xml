<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 09 May 2024 06:19:56 GMT</lastBuildDate>
    <item>
      <title>对于这种情况最好的模型是什么</title>
      <link>https://stats.stackexchange.com/questions/646873/what-is-the-best-model-for-this-case</link>
      <description><![CDATA[“我们可以获得一个关于人们软饮料消费的数据集，涵盖 300 名受试者。仅使用 Excel 表格和绘图功能：

提出一项研究计划，以经济计量方式评估与软饮料消费相关的因素。您的研究计划：
必须给出分步估算策略
每一步都必须以初步的表格/图形分析为依据

然后，使用“数据”&gt;“数据分析”中提供的回归工具，估计并报告您的模型。

性别（0：男，1：女）
城市虚拟变量（1：城市，0：农村）
农村虚拟变量（1：农村，0：城市）
年龄
收入（美元）
缺点2：每月软饮料的消费量——因变量”

我考虑使用以下模型，然后对 beta 进行系数测试：
cons2 = b0 + b1* 性别 + b2* 城市 + b3* 农村+b4* 年龄+b5* 收入
但是，由于多重共线性，回归在此模型中不起作用。为了进行这些测试，构建另一个有意义的模型是什么？
此外，通过使用每个自变量的简单线性回归，如果我们这样做，我们可以推断出什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/646873/what-is-the-best-model-for-this-case</guid>
      <pubDate>Thu, 09 May 2024 00:58:55 GMT</pubDate>
    </item>
    <item>
      <title>病例对照设计中逻辑回归的预测概率是否有效？</title>
      <link>https://stats.stackexchange.com/questions/646870/are-predicted-probabilities-from-logistic-regression-in-a-case-control-design-va</link>
      <description><![CDATA[我一直在阅读和学习如何从逻辑回归中获取预测概率，如果需要的话，将其转换为风险比。但我突然想到，不同研究设计的二元结果显然不同。我是否正确地认为，只有当研究是队列（前向）设计而不是病例对照设计时，从逻辑模型计算概率才有意义，因为在后者中，“风险”并不代表人群，因为你选择了结果吗？因此，在病例对照设计中，在报告和描述结果方面，人们应该停留在比值比上，不再继续下去吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646870/are-predicted-probabilities-from-logistic-regression-in-a-case-control-design-va</guid>
      <pubDate>Wed, 08 May 2024 23:36:56 GMT</pubDate>
    </item>
    <item>
      <title>回归的可能性有多大？</title>
      <link>https://stats.stackexchange.com/questions/646868/what-is-the-likelihood-of-a-regression</link>
      <description><![CDATA[我知道线性回归本身就有可能性。这仅仅是错误发生的可能性吗？我认为这是给定 X 时 Y 的数据的可能性。换句话说， $Lik(Y$~$X )=Lik(Y|X)$ 使得 $$Lik((X,Y))=Lik(Y|X)Lik(X)=Lik(X |Y)Lik(Y)=(proportionality.constant)probability(X,Y).$$ 换句话说，我们可以重建联合分布的可能性。但只有当 X 和 Y 来自相同的分布时，这似乎才是正确的。我想我已经做了一个反例，表明当 X 和 Y 的两个边际分布不同时，它是不正确的。我已经用 R 代码实现了它：
# 创建简单数据集
XData&lt;-c(-0.402103,-4.628608,2.731303,-1.041853)
YData&lt;-c(-2.1607852,-0.3150687,-2.1435201,-0.2779723)
# 我知道 X 和 Y 的分布是
# 多元正态分布如下所述
# 方差-协方差矩阵
# XMat 具有非零的非对角线条目
XMat&lt;-矩阵(c(4,2,0,0,
               2,4,0,0,
               0,0,4,1,
               0,0,1,4),nrow=4,ncol=4)
# YMat 沿非对角线条目全为零。
YMat&lt;-diag(4,nrow=4,ncol=4)
# 首先我将展示 ln(Lik(Y~X))+ln(Lik(X))
# =ln(Lik(X~Y))+ln(Lik(Y))=ln(Lik(X,Y))
# 当两个矩阵相同时为真
#（在这种情况下，两者都全为零
# 非对角线条目）。
XonYResultA&lt;-lm(XData~YData)
logLik(XonYResultA)
#&#39;记录喜欢。&#39; -7.830222（df=3）
YonXResultA&lt;-lm(YData~XData)
“记录力克。” -3.686896 (df=3)
Xnorm&lt;-MASS::fitdistr(XData,“正常”)
Ynorm&lt;-MASS::fitdistr(YData,“正常”)
logLik(Xnorm)
#&#39;记录喜欢。&#39; -9.519879 (df=2)
logLik(Ynorm)
#&#39;记录喜欢。&#39; -5.376553 (df=2)
# 这样你就可以看到
logLik(Xnorm)+logLik(YonXResultA)
#&#39;记录喜欢。&#39; -13.20678（df=2）
logLik(Ynorm)+logLik(XonYResultA)
#&#39;记录喜欢。&#39; -13.20678（df=2）
# 给出相同的可能性。
# 但当我将 X 建模为来自
# 与 Y 不同的分布：
##### 首先，为了运行不同的特殊回归
##### 分布，我需要找到正确的平均值：
findXMean&lt;-函数（par）{
  return(-mvtnorm::dmvnorm(XData-par[1],sigma=XMat,log=TRUE)) #negative ln(lik) 因为 subplex 最小化函数以找到最佳值。
}
subplexResult1&lt;-subplex::subplex(par=c(1),fn=findXMean)
XMean&lt;-subplexResult1$par
XlnLik&lt;- -subplexResult1$value #-10.71792
findYMean&lt;-函数(par){
  return(-mvtnorm::dmvnorm(YData-par[1],sigma=YMat,log=TRUE)) #negative ln(lik) 因为 subplex 最小化函数以找到最佳值。
}
subplexResult2&lt;-subplex::subplex(par=c(1),fn=findYMean)
YMean&lt;-subplexResult2$par
YlnLik&lt;- -subplexResult2$value #-6.878869
##### 现在我可以找到 Y ~ X 和 X ~ Y 的可能性：
#####
XDelta&lt;-XData-XMean
YDelta&lt;-YData-YMean
findYonX&lt;-函数（pars）{
  贝塔=pars[1]; EVar&lt;-pars[2]
  残差&lt;-YDelta-beta*XDelta
  返回（-mvtnorm :: dmvnorm（残差，sigma = EVar * YMat，log = TRUE））
}
subplexResult3&lt;-subplex::subplex(par=c(1,1),fn=findYonX)
LikYGivenX&lt;- -subplexResult3$value #-3.695906
LikJointYonXPlusX&lt;-LikYGivenX+XlnLik #-14.41383
findXonY&lt;-函数（pars）{
  贝塔=pars[1]; EVar&lt;-pars[2]
  残差&lt;-XDelta-beta*YDelta
  返回（-mvtnorm :: dmvnorm（残差，sigma = EVar * XMat，log = TRUE））
}
subplexResult4&lt;-subplex::subplex(par=c(1,1),fn=findXonY)
LikXGivenY&lt;- -subplexResult4$value
LikJointXonYPlusY&lt;-LikXGivenY+YlnLik #-13.90974

因此，您可以在上面的代码中看到 LikJointYonXPlusX 和 LikJointXonYPlusY 给出不同的值，这意味着它们不能同时代表联合的可能性
数据 X 和 Y。
我想我的问题是我是否通过说residuals&lt;-YDelta-beta*XDelta正确地实现了回归，如果我这样做了，那么为什么回归的可能性等于当两个分布相同时给定自变量的因变量，而不是当两个分布不同时给定自变量的因变量？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/646868/what-is-the-likelihood-of-a-regression</guid>
      <pubDate>Wed, 08 May 2024 22:55:19 GMT</pubDate>
    </item>
    <item>
      <title>如何训练连续时间归一化流模型？</title>
      <link>https://stats.stackexchange.com/questions/646867/how-to-train-a-continuous-time-normalizing-flow-model</link>
      <description><![CDATA[我对如何真正训练连续时间归一化流模型感到困惑。离散时间（原始）标准化流有两个用例，我试图概述如何使用连续时间流来处理这两种情况。你能帮我解决这个问题吗？ 每个部分的问题都以粗体显示。
我将让 $f_\phi(t, z_t)$ 成为我的神经网络，这样我们就有了  $z_t = z_0 + \int_0^t f(\tau, z) d\tau$，我们有 $\log p_t(z_t) = \log p_0( z_0) - \int_0^t Tr(D_z f)$。
我假设我有一些 ODE 求解器，当我使用它时，它可以跟踪 $f_\phi$ 的梯度。它应该接受参数 $z_0, dz/dt, \log p_0(z_0), t_0 = 0, t_1 = 1$ 并输出 $z_1, \log p_1(z_1)$ （并跟踪梯度$D_\phi f_\phi$）。请注意，我们不需要传输 $\log p_0$，我们可以只计算数据的传输 $ z_1$。
我将使用 $u = z_0$ 来表示 $t = 0$ 上的变量NF 的（基）侧和输出侧的 $x = z_1$，$t = 1$.
我的基本密度将始终为 $p_u = p_0 = N(0,I)$。

第一个用例是当我们有一个数据集 $\{x_i\}$ 时，我们假设它们是来自未知密度的 IID 样本$p_x^*$。在这种情况下，为了训练 NF，我认为我们希望最大化数据的可能性。我能弄清楚如何做到这一点的唯一方法是向后使用 ODE 求解器（并跟踪梯度），因此我们让 $z_1 = x_i$ 并调用
ode_solver(x_i, f, ???, t_0 = 1, t_1 = 0)。 我的第一个问题是我不知道将 $p_x(x) 放入 ode 求解器中。这里有什么？请注意，在代码 [此处][1] 中，第 139 行显示它们传入了 $\log p_x=0$，这对我来说毫无意义。

假设我们忽略这一点并仅对数据使用 ODE 求解器。它将提供 $z_0 = u_i$。然后我可以写 $\sum \log p_0(u_i)$ (b/c $p_0 = N(0,I )$，并且由于 $u_i$ 取决于 $\phi$ 我们可以最大化但我认为这不是一个好的损失函数，因为它忽略了概率密度的传输。
有人可以帮助我了解如何训练它吗？请注意，在上面链接的代码库中，您从我提到的损失中减去传输的概率 $\log p_u$ （在 ode 求解器之前以全 0 开头）（行186）。为什么？

第二个用例是当我们可以计算一些棘手的密度（的对数）$p^*_x$直到一个常数时（我们可以计算$\log(p_x^*(x)) + C$ 对于任何 $x$，我们希望所以我的计划是最小化 $KL(p_x, p_x^*)$ 其中 $p_u^*$  是我的未知密度的回拉，为了执行此操作，我将采样 $u_i~p_u = N(0,I)$ 并计算 &lt; span class=&quot;math-container&quot;&gt;$w_i = \log p_u(u_i)$。我会将这些传递给 ODE 求解器的前向传递，

ode_solver(u_i, f, w_i, t_0 =0, t_1 = 1) 并取出 $x_i = z_1$ 和$\log p_x(x_i)$。然后我可以将 $KL(p_x, p_x^*)$ 的蒙特卡罗模拟写为我的损失：
$$L(\phi) = -\tfrac{1}{n}\sum_i \log p_x(x_i) - \log p_x^*(x_i)$$&lt; /span&gt; （两个日志项都取决于 $\phi$。
这看起来对吗？
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/646867/how-to-train-a-continuous-time-normalizing-flow-model</guid>
      <pubDate>Wed, 08 May 2024 22:34:45 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 randomForest 模型过度拟合，为什么？</title>
      <link>https://stats.stackexchange.com/questions/646866/overfitting-in-randomforest-model-in-r-why</link>
      <description><![CDATA[我正在尝试在 R 中训练随机森林模型以进行情感分析。该模型使用 tf-idf 矩阵，并从中学习如何对评论进行正面或负面分类。
正的被分类为标签1，负的被分类为标签0。
我在 R 中创建了一个代码，其逻辑是训练一个模型，将给定的 2 个标签转换为因子，然后将数据库划分为训练数据集和测试数据集。
矩阵的尺寸为 502 x 5477。
该模型所做的也是 mtry = 5477。
我得到的代码输出为 Accuracy = 1，这很奇怪。是代码逻辑的问题，还是应该添加参数来限制mtry等？
# 加载必要的库
库（随机森林）
库（readxl）
库（插入符号）
图书馆(e1071)

# 加载带有标签的原始DataFrame
df &lt;- read_excel(&#39;~/Downloads/tfidf_r.xlsx&#39;)
df$label...2 &lt;- as.factor(df$label...2)

# 将数据分为训练集和测试集
设置.种子(42)
train_indices &lt;- createDataPartition(df$review_id, p = 0.7, list = FALSE)
train_data &lt;- df[train_indices, ]
test_data &lt;- df[-train_indices, ]

# 使用正则化初始化并训练随机森林分类器
random_forest_model &lt;- train(label...2 ~ ., data = train_data, method = &quot;rf&quot;,
                             trControl = trainControl(方法 = &quot;cv&quot;, 数量 = 10))

# 打印模型
打印（随机森林模型）

# 对测试数据进行预测
y_pred &lt;- 预测（random_forest_model，newdata = test_data）

在这里您可以看到输出：
准确度：1
                 95% 置信区间：(0.9757, 1)
    无信息率：0.6067
    P值[Acc&gt; NIR]：&lt; 2.2e-16
]]></description>
      <guid>https://stats.stackexchange.com/questions/646866/overfitting-in-randomforest-model-in-r-why</guid>
      <pubDate>Wed, 08 May 2024 21:59:10 GMT</pubDate>
    </item>
    <item>
      <title>d 维立方体的覆盖数</title>
      <link>https://stats.stackexchange.com/questions/646864/the-covering-number-of-a-d-dim-cube</link>
      <description><![CDATA[在 Martin Wainwright 的教科书中，方程 (5.5) 指出 d 维立方体的 $\delta$ 覆盖数满足
$$
\log N(\delta; [0,1]^d) \asymp d \log(\frac{1}{\delta}),
$$
对于足够小的 $\delta$，$N(\delta,A)$ 是 $\delta$ - 覆盖集合$A$的数量。
我的问题是，这里的 $\asymp$ 到底是什么意思？
谁能给我提供 $A \asymp B$ 的示例以及 $\asymp$ 的定义？
不幸的是，温赖特在他的书中没有包含符号表。]]></description>
      <guid>https://stats.stackexchange.com/questions/646864/the-covering-number-of-a-d-dim-cube</guid>
      <pubDate>Wed, 08 May 2024 21:53:41 GMT</pubDate>
    </item>
    <item>
      <title>列联表测试的顺序概率比测试的下限阈值</title>
      <link>https://stats.stackexchange.com/questions/646862/lower-threshold-for-sequential-probability-ratio-test-on-contingency-table-testi</link>
      <description><![CDATA[为了测试骰子是否公平，我们有对数似然比：
$$
\Lambda = \frac{1}{2} \sum_{i} \mathrm{观测值}_i \log\left(\frac{\mathrm{观测值}_i}{\mathrm{预期}_i}\right)。
$$
假设我想将 Wald 的顺序概率比测试 (SPRT) 应用于这种情况，滚动骰子几次并根据观察到的 $\Lambda$。据我所知，SPRT 的保守界限是继续掷骰子当且仅当
$$
a \le \Lambda \le b,
$$
其中 $$a = \log\left(\frac{\beta}{1-\alpha}\right),\quad b=\log\left(\frac{1- \beta}{\alpha}\right)$$ 和 $\alpha, \beta$ 是 I 类和 II 类比率。
然而，当没有指定替代方案时，当我们看到完全公平的结果时，我们总是有 $\Lambda \ge 0$ 具有相等性频率相同）。因此我们永远观察不到$\Lambda &lt;一个&lt;典型 I 类和 II 类费率为 0 美元。也就是说，SPRT 将永远终止以接受空值。
$a$ 是否存在满足 I 类和 II 类比率的已知正值？]]></description>
      <guid>https://stats.stackexchange.com/questions/646862/lower-threshold-for-sequential-probability-ratio-test-on-contingency-table-testi</guid>
      <pubDate>Wed, 08 May 2024 21:24:23 GMT</pubDate>
    </item>
    <item>
      <title>重复测量的 GLM 二项式回归能否被视为生存分析的可靠替代方案？</title>
      <link>https://stats.stackexchange.com/questions/646860/can-a-glm-binomial-regression-on-repeated-measures-be-seen-as-a-trustworthy-alte</link>
      <description><![CDATA[我正在开展一个精算项目，以估计某人每月残疾的概率。
我们有多种格式的可用数据。例如，以下几行是数据的一部分：

&lt;标题&gt;

政策编号
性别
年龄残疾
职业类别
残疾时间


&lt;正文&gt;

001
男性
40年
1
2个月


002
女性
30年
2
3个月



直观上，我们将使用生存分析方法（例如，比例风险模型或加速故障时间模型）对此进行建模，变量 TimetoDisabilty 为残疾发生之前的时间，Gender、AgeatDisability 和 OccupationClass 为协变量。
数据包括右删失观察结果。
最近，一位顾问提出了以下（替代）建模方法：
宽数据首先转换为长数据格式，其中每行根据变量 TimetoDisabilty 进行复制。例如，上表中的第一行转换为 2 行，因为需要 2 个月才能禁用。最后一行的变量 Disability 的值为 1，因为残疾发生在第 2 个月。类似地，上表中的第二行转换为 3 行，因为需要 3 个月才能成为残疾。最后一行的变量 Disability 的值为 1，因为残疾发生在第 3 个月。变量 AgeatDisability 转换为变量 Age，现在表示该月的年龄：

&lt;标题&gt;

政策编号
性别
年龄
职业类别
持续时间
残疾


&lt;正文&gt;

001
男性
39年11个月
1
1
0


001
男性
40年
1
2
1


002
女性
29年10个月
2
1
0


002
女性
29年11个月
2
2
0


002
女性
30年
2
3
1



正确的删失观察结果仍在数据中，行数等于观察窗口的长度，并且“残疾”列中全为零，因为未观察到残疾时刻。
尽管新数据现在具有嵌套在同一个人内的多个观察结果（重复测量），但顾问建议进行 GLM 二项式回归分析，其中以“残疾”变量作为响应变量，以“性别”、“年龄”、“职业类别”和“持续时间”作为协变量。从统计角度来看，我们知道 GLM 模型会将所有数据线视为独立的观察结果，并且不会考虑可用的正确审查制度。
问题：假设 - 由于实际/技术原因 - 只能执行 GLM 二项式回归。考虑到新数据的结构（即重复测量、多条线之间的依赖性），我们是否可以将 GLM 二项式回归分析的结果视为值得信赖的结果？这是生存分析的有效替代方案吗？或者我们可以理论上期望估计的概率小于或大于通过生存分析获得的概率吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646860/can-a-glm-binomial-regression-on-repeated-measures-be-seen-as-a-trustworthy-alte</guid>
      <pubDate>Wed, 08 May 2024 21:10:35 GMT</pubDate>
    </item>
    <item>
      <title>基于其参数，负二项式分布的中位数是否存在已知界限？</title>
      <link>https://stats.stackexchange.com/questions/646851/are-there-known-bounds-for-the-median-of-a-negative-binomial-distribution-based</link>
      <description><![CDATA[这对我来说似乎是一个天真的问题，但当我进行一些挖掘时，我找不到满意的答案。二项分布有一个封闭形式的中位数，泊松分布有一组简单的非常严格的界限，这些都很容易追踪，例如在维基百科上。如果我尝试（也许愚蠢地）绘制与连续分布的相似之处，我可以想象二项式与正态分布（具有简单的封闭形式中位数），泊松与指数（具有简单的封闭形式中位数）对，并且负二项式与伽玛配对。从我在维基百科关于伽马分布的文章中可以看出，它的中值很难确定——有多种方法可以达到近似值和界限，但没有一种方法是同时简单、紧凑的，并始终工作。伽玛的这种困难是否揭示了负二项式的类似挑战？关于这个问题是否有任何关键研究/是否是一个活跃的研究领域？
编辑：重新阅读本文后，几乎可以肯定，在我上面的离散连续类比中，泊松应该被替换为几何......]]></description>
      <guid>https://stats.stackexchange.com/questions/646851/are-there-known-bounds-for-the-median-of-a-negative-binomial-distribution-based</guid>
      <pubDate>Wed, 08 May 2024 20:44:24 GMT</pubDate>
    </item>
    <item>
      <title>具有部分优势的序数 Logistic 回归的序数自变量中优势比的解释</title>
      <link>https://stats.stackexchange.com/questions/646847/interpretation-of-odds-ratios-in-the-ordinal-independent-variables-of-an-ordinal</link>
      <description><![CDATA[在序数逻辑回归中，我有一个因变量 GEG，其类别为“无”、“小”、“中等”、“高”和“高”。和“非常高”。
在构建模型时，我发现不满足平行线的假设，因此我拟合了具有部分赔率的序数逻辑回归。
相关变量是性别（满足平行线假设）和 VIO（这是一个类别为“空”、“低”、“中”的序数变量）。和“高”。
mod =clm(GEG~Sex, 名义=~VIO, 数据=数据)
该模型满足所有假设并且表现相当良好。
我遇到的问题是，由于变量 VIO 是序数，因此考虑了多项式对比矩阵。
&lt;前&gt;&lt;代码&gt; .L .Q .C

[1,]-0.6708204 0.5 -0.2236068

[2，]-0.2236068 -0.5 0.6708204

[3,] 0.2236068 -0.5 -0.6708204

[4、]0.6708204 0.5 0.2236068

为了找到 logit 表达式的系数，我针对因变量水平的每个变化，在对比矩阵的行与模型输出的 alpha 系数之间执行了标量积。因此，对于第一个 Logit，不满足平行线假设的序数变量的 alpha 系数为
无|小VIO.L =0.20

无|小VIO.Q =0.75

无|小VIO.C =1.00

log[P(y≤无)/P(y&gt;无)]=-3.14+ 0.354 男性+0.021 VIOnull
+0.251 VIO低-1.0 VIO中+0.733VIO高

我遇到的问题是我不知道如何解释序数变量的优势比；因为由于对比度是多项式，所以我没有参考类别。
例如，如果我为 VIOnull 指出，当从空类别移动到低类别时，由于相关的优势比为 e^0.021=1.021，因此它将表明具有总体影响的累积优势为无与大于无，从 VIO 变量的空类别移动到低类别时增加 2.1%。
您如何解释 VIOhigh(0.733)，因为高是最高类别，并且您无法从高移动到更高类别，那么解释与此 logit 相对应的优势比的正确方法是什么，特别是在与序数 VIO 变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/646847/interpretation-of-odds-ratios-in-the-ordinal-independent-variables-of-an-ordinal</guid>
      <pubDate>Wed, 08 May 2024 19:58:30 GMT</pubDate>
    </item>
    <item>
      <title>条件概率，谁是对的？</title>
      <link>https://stats.stackexchange.com/questions/646828/conditional-probability-whos-right</link>
      <description><![CDATA[我需要数学问题的帮助。我和至少两位老师都做过，并得到了不同的结果，所以现在向互联网上的智者寻求帮助解决这个争论。
问题来了
“问题6
通过光纤电缆，信息以比特的形式发送，比特的值可以是 0 或 1。
但线路上存在噪声，使得发送的0在传输过程中有1/10的概率变成1。
发送的 1 在传输过程中有 1/5 的概率变成 0。
发送随机选择的比特值为 0 的概率为 2/3
接收到一个值为 0 的位
a) 接收到的比特以 0 值发送的概率是多少？
接收到一个值为 1 的位
b) 接收到的比特以值 1 发送的概率是多少？”
当前答案是

a) = 9/13 和 b) = 4/13
a) = 9/10 和 b) = 4/5
a) = 9/10 和 b) = 2/5

哪个是正确的？为什么？预先感谢您的任何帮助。
好的，亚历克西斯和展雄在这里关注工作。第一个是我的工作，另外两个是老师的工作。希望它有帮助:)
它也不是多项选择，尽管从丹麦语翻译成英语，但我还是按照书面形式添加了整个问题。
1)


说

P(U0)=2/3 P(U1)=1/3
P(M1|U0)=1/10 P(M0|U0)=9/10
P(M0|U1)=1/5 且 P(M1|U1)=4/5

对于 b)

和3)
P(A1)=2/3 P(A2)=1/3
P(B0|A1)=0.9 P(B0|A2)=0.2
P(B1|A1)=0.1 且 P(B1|A2)=0.8
对于 a) P(A1|B0) = (P(B1|A1)P(A1)) / (P(B1|A1)P(A1)+P(B0|A2) P(A2)) 则为 (0.9(2/3)) / (0.9(2/3)+0.2(1/3)) = 0.9&lt; /p&gt;
对于 b)
P(A2|B1) = (P(B1|A2)P(A2)) / (P(B1|A1)P(A1)+P(B0|A2)P(A2) ））
则为 (0.8(1/3)) / (0.9(2/3)+0.2(1/3)) = 0.4]]></description>
      <guid>https://stats.stackexchange.com/questions/646828/conditional-probability-whos-right</guid>
      <pubDate>Wed, 08 May 2024 16:32:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 Fixst 进行标准错误的集群引导</title>
      <link>https://stats.stackexchange.com/questions/646872/cluster-bootstrap-for-standard-errors-using-fixest</link>
      <description><![CDATA[我正在尝试使用 fixest 包中的 feols 估计具有固定效应的模型。由于我只有几个集群，因此我想获得引导式集群 SE。有谁知道可以做到这一点的包吗？还是我应该自己实现它？
我从 plm 切换到 fixest，因为我有每日数据（pdata.frame，索引为“运动员”和“日期”），但想要年份固定效应，而 plm 总是计算每日固定效应。
有包 fwildbootstrap，但它不返回标准错误，并且 vcovBS 不适用于使用 feols 估计的模型。
使用的代码：
t &lt;- feols(TotalN ~ factor(Conditions) + i(Sex, Age) + i(Sex, I(Age^2)) + 
factor(Month) + Total.Climb + excl:after_excl | Athlete +季节，
数据 = simple_excl)

vcovBS(t, cluster=~Athlete)

# model.frame.default 中的错误：变量长度不同
]]></description>
      <guid>https://stats.stackexchange.com/questions/646872/cluster-bootstrap-for-standard-errors-using-fixest</guid>
      <pubDate>Wed, 08 May 2024 09:26:54 GMT</pubDate>
    </item>
    <item>
      <title>为什么某些采样算法比其他算法更好？</title>
      <link>https://stats.stackexchange.com/questions/646776/why-are-some-sampling-algorithms-better-than-others</link>
      <description><![CDATA[我们到底如何证明某些采样算法在某些类型的情况下比其他算法表现得更好？
在我的计算统计研讨会上，我们介绍了以下从概率分布模拟随机数据的统计方法：

接受-拒绝方法：可以模拟任何分布的数据，并且不涉及取分布的逆。它使用目标分布与某些候选分布的比率来从目标分布中进行采样。不过据说有时效果不是很好（例如多次被拒绝，没有充分探索样本空间），但我不知道为什么。


选择 $c$ 的值，使得对于所有 $x$ ，以下情况成立: $c \cdot g(x) \geq f(x)$ （此处 $g(x)$ 是提案分布，$f(x)$ 是目标分布）
根据已知分布$g(x)$生成提案$x$。
根据 $[0, 1]$ 上的均匀分布生成随机数 $u$ .
如果$u \leq \frac{f(x)}{c \cdot，则接受提案$x$ g(x)}$，其中 $f(x)$ 是目标分布，$c$  是一个常量，使得 $c \cdot g(x) \geq f(x)$ 对于所有  $x$。如果提案未被接受，请返回第 2 步。


Metropolis-Hastings (MCMC)：也可以模拟任何分布的数据，但在某种程度上比接受-拒绝方法更好，但我不知道为什么。


从初始点开始$x_0$。
对于每个步骤，从分布 $Q(x&#39;|x)$ 生成提案 $x&#39;$ ，取决于当前位置$x$。
计算接受率$r = \frac{f(x&#39;)/Q(x&#39;|x)}{f(x)/Q(x|x&#39;) }$，其中 $f(x)$ 是目标分布。
以 $\min(1, r)$ 的概率接受提案 $x&#39;$。如果提案未被接受，则留在当前位置$x$。

是否有任何数学直觉（例如一些虚拟问题）让我们可以看到一个数学问题来证明为什么在某些分布中，与接受-拒绝方法相比，Metropolis-Hastings 会更有效（例如更少的拒绝，更少的卡住） ？
我正在寻找一些数学示例，例如他们教授优化时的示例。例如。我们正在尝试使用许多鞍点和局部最小值来优化一些数学函数。一阶优化方法会错误地认为它已经找到最优点（由于其停止条件）并停止，而二阶优化方法将能够识别这不是最优点并继续前进。
回复：托马斯关于为什么在后验分布的分母未知（由于复杂的积分）的贝叶斯情况下接受-拒绝采样变得困难的观点。这是我的猜测：
对于后验分布 $f(\theta | x)$，似然函数 $L(\theta | x) )$ 和先验分布 $h(\theta)$，我们可以使用贝叶斯定律来写：
$$f(\theta | x) = \frac{L(\theta | x) \cdot h(\theta)}{\int L(\theta | x) ) \cdot h(\theta) d\theta}$$
在确定比率$c$时，保证这种不等式对于所有$x$&lt; /span&gt; 变得不可能，因为不完全知道 $f(x)$ （即，不知道 $f(x) 的分母就不可能）：
$$f(x) \leq c \cdot g(x)$$
$$c \geq \frac{f(x)}{g(x)}$$
因此，在这种情况下，接受-拒绝抽样方法变得不可能。]]></description>
      <guid>https://stats.stackexchange.com/questions/646776/why-are-some-sampling-algorithms-better-than-others</guid>
      <pubDate>Wed, 08 May 2024 04:08:13 GMT</pubDate>
    </item>
    <item>
      <title>F 检验用于比较方差。如何计算 ncp 以获得 alt 假设下的 F 分布？</title>
      <link>https://stats.stackexchange.com/questions/646774/f-test-to-compare-variances-how-is-ncp-calculated-to-obtain-the-f-distribution</link>
      <description><![CDATA[最近我需要进行功效分析，以便与 F 检验进行方差比较。
过去我使用的是 Edwin Crow 的《统计手册》中的 OC 曲线。图八获得测试版。 https://apps.dtic.mil/sti/tr/pdf/AD0149334。 pdf
例如 lambda = sd1/sd2 = 3，n=7 两组，表示图表上的 beta ~0.2（功效 = 80%）。文字
使用 pwrss 包：
power.f.test(ncp = 3, df1 = 6, df2 = 6, alpha = 0.05)


&lt;标题&gt;

功率
ncp.alt
ncp.null
阿尔法
df1
df2
f.crit


&lt;正文&gt;

0.11191
3
0
0.05
6
6
4.2838



即 beta ~0.89
假设备择假设的 ncp 不是 sd1/sd2。 var1/var2 将为 9：
power.f.test(ncp = 9, df1 = 6, df2 = 6, alpha = 0.05)


&lt;标题&gt;

功率
ncp.alt
ncp.null
阿尔法
df1
df2
f.crit


&lt;正文&gt;

0.26454
9
0
0.05
6
6
4.2838



即贝塔值~0.74
...那么 sd1 和 sd2 中的 ncp 是什么？我在 t 检验和 Hotelling T2 检验中使用了 ncp，其中参数有详细记录，但我只找到了一些在方差分析计算中估计功效的情况下使用 ncp 的示例。
我确实找到了这个页面：Stats Kingdom，这似乎是一个闪亮的应用程序。这里，Ha 看起来是 df(x/(var1/var2), df1, df2)，尽管 H0 pdf 的曲线下面积 =1，但 Ha (var1/var2) 曲线下面积显然 &gt;1。&lt; /p&gt;
感谢您提供更多文档的提示或指示。
这就是这份出版物，尽管它有点难。 Ali Baharev、Hermann Schichl 和 Endre Rév2，在保证精度的情况下计算非中心 F 分布和 F 检验的功效。 https://www.ncbi.nlm.nih.gov/pmc/articles /PMC7010373/]]></description>
      <guid>https://stats.stackexchange.com/questions/646774/f-test-to-compare-variances-how-is-ncp-calculated-to-obtain-the-f-distribution</guid>
      <pubDate>Wed, 08 May 2024 03:10:11 GMT</pubDate>
    </item>
    <item>
      <title>在训练逻辑回归以预测未来结果时如何分割和采样“面板数据”</title>
      <link>https://stats.stackexchange.com/questions/646624/how-to-split-and-sample-panel-data-when-training-a-logistic-regression-to-pred</link>
      <description><![CDATA[简介
我有面板数据，可以观察一段时间内的客户行为。对于给定参考日期的每个客户，我有 12 个月的回顾窗口用于生成功能，以及 12 个月的展望窗口用于识别结果，例如取消订阅、默认或类似操作。

每个客户按月存在于我的数据集中，方式如下：

现在我想训练逻辑回归来预测二元结果，这就是我有很多问题的地方。我大多只能找到有关时间序列验证的博客和书籍，但找不到有关面板数据的博客和书籍。但以下是我的想法，我想提出意见。
拆分的最佳实践是什么？
我需要将数据集分成训练/有效/测试，其中训练/有效将用于训练逻辑回归和对抗模型（验证数据用于超参数调整和早期停止），以及测试数据将用于最终评估。
由于模型必须随着时间的推移以及新客户的表现而变化，我想做两种类型的“样本外”测试：验证：1）时间验证（过时）以确保它适用于未来未见的数据，2）“外部验证”，以便训练数据、验证数据和数据中不存在相同的客户测试数据。

什么是“最佳实践”？用于拆分面板数据？
大多数博客文章都提到做“不合时宜”的事情。验证，但没有人真正提到对训练数据中不存在的样本进行验证。最后一部分没有必要吗？
如何处理“串行相关性”？
在逻辑回归中，观察之间的独立性假设通常很重要。让同一客户在训练数据中多次出现（可能具有相关变量和结果）违反了这一假设，因为他们的每月观察并不真正独立。这可能会导致低估标准误差和过度自信的预测，因为该模型不会考虑受试者内的相关性。
什么是“最佳实践”？用于处理这些“序列相关性”？
我处理这个问题的一些想法：

数据中仅保留单个客户一次

一个潜在的问题是，我可能会丢失重要分段和二进制结果上的太多数据


使用聚集标准错误

对非独立观察结果（客户）进行聚类，并计算修正的标准误差以考虑客户内的相关性。


使用广义估计方程 (GEE)

我对这些不太熟悉，但他们应该能够根据数据中的相关结构调整模型指标



您将如何验证模型的时间方面？
我希望模型能够随着时间的推移尽可能保持高性能，但它需要在为测试留出多少时间方面进行权衡。已经充分证明，“最近的过去”已经过去了。比“遥远的过去”更好地预测未来。但我正在考虑这样的事情，我在 2 年的评估期内每月单独评估模型，有或没有校准（将预测率调整为过去一年的观察率）。
整个“校准”的原因是步骤是我们期望模型的排名性能随着时间的推移而保持一致，而总体结果率预计会随着时间的推移而变化。
什么是“最佳实践”？获得最“值得信赖”的随着时间的推移有效的评估指标？

您还有其他很酷的提示和技巧吗？
这里可能缺少很多东西，所以请随时提供其他建议和最佳实践。]]></description>
      <guid>https://stats.stackexchange.com/questions/646624/how-to-split-and-sample-panel-data-when-training-a-logistic-regression-to-pred</guid>
      <pubDate>Mon, 06 May 2024 15:13:32 GMT</pubDate>
    </item>
    </channel>
</rss>