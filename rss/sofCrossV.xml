<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 30 Jul 2024 15:16:22 GMT</lastBuildDate>
    <item>
      <title>基于子组的功效计算</title>
      <link>https://stats.stackexchange.com/questions/652011/power-calculations-based-on-a-subgroup</link>
      <description><![CDATA[我正在设计一项 RCT，研究膳食补充剂对血压的影响。这种补充剂的性质是它对血压正常者和高血压患者都具有吸引力，因此，尽管这种补充剂在降低高血压患者血压方面可能更有效，但我不想将血压正常者排除在招募范围之外。但是，包括血压测量范围广泛的个体会使可能的标准差非常高，因此需要检测统计上显着变化的参与者非常高。
根据高血压患者进行功效计算并在主要结果分析中使用这些患者，但仍然接受血压正常的患者进入试验并将他们纳入更大的事后分析，这在统计上是否可以接受，或者这被认为是不好的做法？
感谢您的帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/652011/power-calculations-based-on-a-subgroup</guid>
      <pubDate>Tue, 30 Jul 2024 14:07:54 GMT</pubDate>
    </item>
    <item>
      <title>输电系统概率模型</title>
      <link>https://stats.stackexchange.com/questions/652010/transmission-system-probability-model</link>
      <description><![CDATA[我正在做一个关于输电系统的项目。根据不同的发电水平，电网中的某些线路可能会有太多的流量，从而变得“受限”。使用发电水平的历史数据以及当线路受限时，我可以查看哪些潜在模型来生成线路受限或不受限的概率？我对建模有点陌生，所以了解不多。我想到的是逻辑回归，但这是一个二元分类器。似乎计算某些东西完全不适用或完全适用可能会有缺点，而具有更细粒度概率的东西可能会产生更好的性能。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/652010/transmission-system-probability-model</guid>
      <pubDate>Tue, 30 Jul 2024 13:28:09 GMT</pubDate>
    </item>
    <item>
      <title>运行单独的 Tukey 测试是否会有所不同，或者我应该将我的简单测试视为仅在一次 Tukey 测试中的多重比较？</title>
      <link>https://stats.stackexchange.com/questions/652009/does-running-individual-tukey-tests-makes-a-difference-or-should-i-treat-my-simp</link>
      <description><![CDATA[嗨，我需要运行 Tukey 分析来比较使用 3 种不同类型的水解（比如水解 A、B 和 C）对 30 种代谢物的定量。所以我想运行 30 个单独的 Tukey 测试（将每种代谢物与水解 A、B 和 C 进行比较）。我的问题是，如果我的 Ho 对 30 种代谢物相同，我应该运行 30 个单独的 Tukey 测试还是应该在仅 1 个 Tukey 测试中比较所有 30 种代谢物以比较 3 种水解类型？
我并不想知道所有代谢物之间是否存在差异，而只想找出每种代谢物的水解类型之间的差异]]></description>
      <guid>https://stats.stackexchange.com/questions/652009/does-running-individual-tukey-tests-makes-a-difference-or-should-i-treat-my-simp</guid>
      <pubDate>Tue, 30 Jul 2024 13:14:14 GMT</pubDate>
    </item>
    <item>
      <title>无法在命令行中运行 MPlus [关闭]</title>
      <link>https://stats.stackexchange.com/questions/652007/cannot-run-mplus-in-command-line</link>
      <description><![CDATA[我刚刚安装了最新版本的 MPlus demo，想通过 Mac 上的终端运行它。但是，当我运行 mpdemo 命令时，找不到它。而且，当我说“哪个 mpdemo”时，我得到的回复是“未找到 mpdemo”。有人遇到过这个问题吗？
谢谢，
Kenny]]></description>
      <guid>https://stats.stackexchange.com/questions/652007/cannot-run-mplus-in-command-line</guid>
      <pubDate>Tue, 30 Jul 2024 13:09:34 GMT</pubDate>
    </item>
    <item>
      <title>独立随机向量函数</title>
      <link>https://stats.stackexchange.com/questions/652005/functions-of-independent-random-vectors</link>
      <description><![CDATA[假设独立随机变量/向量的函数也是独立的，假设我有一系列独立的随机向量$(X_1,Y_1),(X_2,Y_2)...$，每个向量都有不同的分布。
每个向量$i$的联合分布和条件分布的函数分别由$p_{X_i,Y_i}$和$p_{Y_i|X_i}$给出。

那么每个随机向量的联合分布函数彼此独立：
$$ p_{X_i,Y_i} \mathrel{\unicode{x2AEB}} p_{X_i,Y_j}, \forall j \neq i $$

并且每个随机向量内的条件分布彼此独立：
$$ p_{Y_i|X_i} \mathrel{\unicode{x2AEB}} p_{Y_j|X_j}, \forall j \neq i $$


以上两个陈述都准确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652005/functions-of-independent-random-vectors</guid>
      <pubDate>Tue, 30 Jul 2024 12:51:11 GMT</pubDate>
    </item>
    <item>
      <title>涅斯捷罗夫加速梯度的两种变体：它们是等效的吗？</title>
      <link>https://stats.stackexchange.com/questions/652004/two-variants-of-nesterov-accelerated-gradient-are-they-equivalent</link>
      <description><![CDATA[我很困惑地发现 Paperswithcode 上对 Nesterov 加速梯度的描述，即：
$v_t = \beta * v_{t-1} \color{red}{+} \eta * ∇ J(\theta \color{red}{-} \beta * v_{t-1})$
$\theta_t = \theta_{t-1} + v_t$
与原始 Sutskever 等人的论文，第 3 页，或在他的博士学位论文中，(7.12) 和 (7.13) 页。 75（也用在这里）：
$v_t = \beta * v_{t-1} \color{red}{-} \eta * ∇ J(\theta \color{red}{+} \beta * v_{t-1})$
$\theta_t = \theta_{t-1} + v_t$
在软弱的时刻，我问你知道是谁，他给出了一个这样的答案前瞻和后瞻，但我无法验证这一点。
这些表述是否等同，或者其中一些是拼写错误？如果是这样，该如何证明这一点？

注意：第一个变体甚至还有一个附加版本，其中减去了 $v_t$，在 Ruder 著名的摘要页面中：
$v_t = \beta * v_{t-1} + \eta * ∇ J(\theta - \beta * v_{t-1})$
$\theta_t = \theta_{t-1} \color{red}{-} v_t$]]></description>
      <guid>https://stats.stackexchange.com/questions/652004/two-variants-of-nesterov-accelerated-gradient-are-they-equivalent</guid>
      <pubDate>Tue, 30 Jul 2024 12:44:27 GMT</pubDate>
    </item>
    <item>
      <title>对 p 值和 Cohen's d 感到困惑</title>
      <link>https://stats.stackexchange.com/questions/652003/confused-about-the-p-value-and-cohens-d</link>
      <description><![CDATA[我有以下代码，用于计算 p 值和 cohen 距离。
import numpy as np
from scipy.stats import ttest_ind

# 计算 Cohen 的 d
def calculate_cohens_d(group1, group2):
mean_group1 = np.mean(group1)
mean_group2 = np.mean(group2)
std_group1 = np.std(group1, ddof=1)
std_group2 = np.std(group2, ddof=1)
n_group1 = len(group1)
n_group2 = len(group2)
pooled_std = np.sqrt(((n_group1 - 1) * (std_group1 ** 2) + (n_group2 - 1) * (std_group2 ** 2)) / (n_group1 + n_group2 - 2))
cohen_d = (mean_group1 - mean_group2) / pooled_std
return cohen_d

# 模拟数据并执行 t 检验和 Cohen&#39;s d 计算的函数
def perform_experiment():
# 模拟数据
group1_EXP = np.random.normal(80, 10, 10)
group2_EXP = np.random.normal(81, 10, 10)

# 执行多重 t 检验
_, p_value_EXP = ttest_ind(group1_EXP, group2_EXP)
cohen_d_EXP = calculate_cohens_d(group1_EXP, group2_EXP)

return p_value_EXP, cohen_d_EXP


如果我使用给定的种子运行代码两次：
# 可重复性的种子
np.random.seed(42)

# 执行 2 次实验
p_value_EXP, cohen_d_EXP = perform_experiment()
print(f&#39;p-value: {p_value_EXP:.4f}, Cohen\&#39;s d: {cohen_d_EXP:.4f}&#39;)

p_value_EXP, cohen_d_EXP = perform_experiment()
print(f&#39;p-value: {p_value_EXP:.4f}, Cohen\&#39;s d: {cohen_d_EXP:.4f}&#39;)

我得到：
p-value: 0.0029， Cohen 的 d：1.5402
p 值：0.9792，Cohen 的 d：-0.0118

因此可以说，第一个实验的 p 值为 0.0029，Cohen 距离“较大”，是显著的。
相比之下，我会说第二个实验并不那么重要。
现在，如果我运行 1,000 次模拟
# 执行 1000 次实验

n_simulations = 1000

p_values_EXP = np.zeros(n_simulations)

cohen_ds_EXP = np.zeros(n_simulations)

for i in range(n_simulations):
p_values_EXP[i], cohen_ds_EXP[i] = perform_experiment()

# 计算 p 值 &gt; 的比例0.05
prop_p_value_EXP_greater_0_05 = np.mean(p_values_EXP &gt; 0.05)

print(&quot;Proportion of p-values &gt; 0.05:&quot;, prop_p_value_EXP_greater_0_05)

我得到
Proportion of p-values &gt; 0.05: 0.951

这意味着更有可能观察到不显著的结果。但前 2 个实验显示相反的结果。
因此，我不确定在这种情况下 Cohen 距离的用处。]]></description>
      <guid>https://stats.stackexchange.com/questions/652003/confused-about-the-p-value-and-cohens-d</guid>
      <pubDate>Tue, 30 Jul 2024 12:20:20 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 SYSTEMFIT 如何工作（从统计角度来看）？</title>
      <link>https://stats.stackexchange.com/questions/652002/how-does-systemfit-from-r-work-from-statistical-perspective</link>
      <description><![CDATA[在 R 中，有一个使用 OLS 估计方程组的包，称为 SYSTEMFIT。最初，这个包似乎并没有增加太多的价值，因为我实际上可以通过 OLS 分别估计每个方程（多次使用函数“lm()”）......除了一种情况，当我需要对方程进行限制时，这是我无法通过单独估计方程来做到的......这让我意识到我甚至无法想象这个包是如何工作的以及如何将多个方程作为一个系统来估计。

所以，首先：我们有两个方程A和B。
\begin{align}
\text{A)} \qquad y_1 &amp; = \alpha_0 + \alpha_1 x_1 + \alpha_2 x_2 + \alpha_3 x_3 + u \\
\text{B)} \qquad y_1 &amp; = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + v \\
\end{align&gt;
现在，我可以通过 $\boldsymbol{\hat\beta} = \left(\mathbf{X}&#39; \mathbf{X} \right)^{-1} \mathbf{X}&#39; \mathbf{Y}$ 分别估计两个方程，或者通过 SYSTEMFIT 将其作为一个系统估计，并得到相同的结果。
现在，如果我有一个单方程假设，即 $\alpha_2 = 1$，我可以用两种方式简单地解决这个问题，使用两个方程的单独估计：
案例 1：我只需在方程中代入正确的值，相应地移动它，然后通过 OLS 估算新方程：
$$
y_1 - 1 \cdot x_2= \alpha_0 + \alpha_1 x_1 + \alpha_3 x_3 + u
$$
案例 2：或者，我可以提出一个限制矩阵 $\boldsymbol{R} = [0,0,1,0]$，右侧向量 $r = [1]$，然后将新模型参数估算为 $\boldsymbol{\hat\beta}_p = \boldsymbol{\hat\beta} - \left(\mathbf{X}&#39; \mathbf{X} \right)^{-1} \boldsymbol{R}&#39;\boldsymbol{R} \left(\mathbf{X}&#39; \mathbf{X} \right)^{-1} \boldsymbol{R}&#39; ( \boldsymbol{R} \boldsymbol{\hat\beta} - r )$

尽管如此，如果我想将其应用于跨方程假设即$\alpha_2 = \beta_2$，我不知道该怎么做。案例 1 和案例 2 在该场景中均不适用。我只能通过 SYSTEMFIT 编写代码，它的语法相对简单。但是我没有看到代码内部。
所以，问题是：SYSTEMFIT 如何将两个方程作为一个系统进行估算，以及如何根据限制进行调整；或者，我们一般如何做到这一点（我们应该使用哪个方程）？]]></description>
      <guid>https://stats.stackexchange.com/questions/652002/how-does-systemfit-from-r-work-from-statistical-perspective</guid>
      <pubDate>Tue, 30 Jul 2024 11:50:06 GMT</pubDate>
    </item>
    <item>
      <title>控制变量时的多重共线性</title>
      <link>https://stats.stackexchange.com/questions/652000/multicollinearity-when-controlling-for-a-variable</link>
      <description><![CDATA[我对数据中的多重共线性有几个问题：我正在查看 MRI 扫描中发现的某种类型的病变；对于每位患者，我都知道这些病变的体积以及捕捉其分布模式的指标。我对模式指标对临床评分的影响感兴趣，而不仅仅是体积的影响。然而，模式指标与体积高度相关（r = 0.7），这是事物的本质，因为病变在大脑中覆盖的面积越大，它们就越成为一个有凝聚力的区域的一部分，而不是单独的斑点。这让我想知道一些事情：

在像临床评分 ~ 模式 + 体积这样的回归中是否存在多重共线性问题？缓解这样的问题似乎违背了我想要看到的目的。
模式指标已根据体积进行了校正，即每个人的指标已除以该人的病变体积。如果体积已经以某种方式纳入，我是否仍需要在回归中考虑体积？
如果我想进行相关性而不是回归，那么 a) 考虑体积后临床评分和模式指标的偏相关性与 b) 临床评分和残差模式指标的相关性（在将模式指标回归到体积后）之间有什么区别？
当我计算临床评分和残差模式指标的相关性时，相关性高于残差之前，这是正常观察结果吗？我注意到临床评分和体积的相关性为负，而临床评分和模式的相关性为正，鉴于模式和体积的相关性为正且很大，我不确定这是否表明出了问题。也许这就是为什么残差化后与临床评分的相关性更高的原因？有没有更深入的分析方法？

提前谢谢您！
]]></description>
      <guid>https://stats.stackexchange.com/questions/652000/multicollinearity-when-controlling-for-a-variable</guid>
      <pubDate>Tue, 30 Jul 2024 11:23:33 GMT</pubDate>
    </item>
    <item>
      <title>在一个非常简单的情况下解释由 R acf 函数计算的自相关[重复]</title>
      <link>https://stats.stackexchange.com/questions/651999/interpreting-autocorrelation-as-computed-by-r-acf-function-in-a-very-simple-case</link>
      <description><![CDATA[我曾经以为我知道自相关是什么，并且 R 中的 acf 函数会产生我所理解的自相关函数，但我一定遗漏了一些细节，因为结果不是我所期望的。
我的理解是，自相关是一系列与自身的相关性，并移开了一些滞后。例如，如果 x=1:10，则存在自相关：
&gt; # lag 0
&gt; cor(1:10, 1:10)
[1] 1
&gt; # lag 1
&gt; cor(1:9,2:10)
[1] 1
&gt; # lag 2
&gt; cor(1:8,3:10)
[1] 1

也就是说，对于线性序列，任何滞后时间的自相关都应该为 1。
但是，这不是 acf 函数的结果：
acf(1:10)

&gt; acf(1:10)[0:9]

序列‘1:10’的滞后自相关

0 1 2 3 4 5 6 7 8 9 
1.000 0.700 0.412 0.148 -0.079 -0.258 -0.376 -0.421 -0.382 -0.245 

这显然不同于我通过滞后序列计算出的自相关。
我猜 acf 函数在某种程度上校正了样本大小，因为当样本大小没有太大变化时差异较小（例如，使用 1:1000 而不是 1:10）。此外，我预计图中的蓝色虚线显著性会随着样本量的减少而向外扩展，但它被绘制为一条水平线，因此由于阈值没有向外扩展，因此向内校正相关性以保持阈值的显著性不变是合理的。
那么问题是：

acf 是否校正了样本量？如果答案是肯定的，它如何校正样本量？
该校正是否解释了通过滞后序列计算出的相关性与 acf 函数的结果之间的差异？
如果不是，我对自相关是什么以及 acf 的作用的理解是否错误？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651999/interpreting-autocorrelation-as-computed-by-r-acf-function-in-a-very-simple-case</guid>
      <pubDate>Tue, 30 Jul 2024 11:15:48 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用嵌套交叉验证中的投票来获得估计量吗？</title>
      <link>https://stats.stackexchange.com/questions/651998/can-i-use-voting-in-nested-cross-validation-to-obtain-estimator</link>
      <description><![CDATA[新手警告：首次发帖，所以请保持温柔 :-)
我研究过嵌套交叉验证（例如在这篇 Medium 文章中）。我知道我能够从外循环中获得平均分数，并且这些分数应该比从任意训练/测试分割中获得的分数更好地估计泛化能力。
获得模型的性能很棒，但最终不是我的目标。我想要的是做出预测，比如在二元分类问题中。理想情况下，我希望估算器的表现与我从嵌套交叉验证中获得的平均分数一样。
因此，我所做的是在外循环中对从估算器获得的预测实施一个简单的投票机制。
来自 sklearn.model_selection 导入 cross_val_score
来自 sklearn.ensemble 导入 RandomForestClassifier
来自 sklearn.model_selection 导入 GridSearchCV、KFold
来自 sklearn.metrics 导入 roc_auc_score
来自 sklearn.datasets 导入 make_classification

# 示例数据集
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)

# 要调整的超参数
param_grid = {
&#39;n_estimators&#39;: [50, 100],
&#39;max_depth&#39;: [None, 10, 20],
}
# 用于超参数调整的内部 CV
grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, verbose=1,scoring=&#39;roc_auc&#39;)
# 用于模型评估的外部 CV
outer_cv = KFold(n_splits=5)
results = cross_validate(grid_search, X, y, cv=outer_cv,scoring=&#39;roc_auc&#39;,return_estimator=True)
y_predictions = np.ndarray((len(results[&#39;estimator&#39;]), len(X), 2))
estimators = results[&#39;estimator&#39;]
for i, estimator in enumerate(estimators):
# 现在我们需要对每个样本进行投票
y_pred = estimator.predict_proba(X)
y_predictions[i] = y_pred

# 现在我们可以计算平均预测
y_pred = y_predictions.mean(axis=0)
# 并使用 argmax 获得最可能的类
y_pred = np.argmax(y_pred, axis=1)

print(&quot;ROC AUC: &quot;, roc_auc_score(y, y_pred))
print(classification_report(y, y_pred))

但是，这个估计器的性能接近完美，显然表明过度拟合。
我的假设错了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651998/can-i-use-voting-in-nested-cross-validation-to-obtain-estimator</guid>
      <pubDate>Tue, 30 Jul 2024 10:53:32 GMT</pubDate>
    </item>
    <item>
      <title>温度矩阵的比较-统计结果不是实际情况？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/651993/comparison-of-temperature-matrix-statistical-result-not-practical-reality</link>
      <description><![CDATA[我遇到了以下问题：我想在 Python 中比较热图像（数据以大矩阵/每个像素一个值的形式存在，50x300，数字介于 800 和 1000,0 摄氏度之间）并确定它们是否不同。只有在实际发生相关变化时，图片才应该传输到服务器。因此，比较的是新图片和前一张图片。我想找到一种自动执行此过程的方法/算法。
我有几个数据集，并且知道其中一些数据应该在测试中被视为不同，而另一些数据则被视为相似（由专家事先评估）。我尝试了配对 t 检验、Wilcoxon 检验，并对图片中的不同感兴趣区域进行检验。结果总是图像明显不同。这不是实际情况。有些图片实际上没有区别。
是否有其他未考虑的测试/修改测试的方法？统计测试不适合这个问题吗？有什么建议我可以继续吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651993/comparison-of-temperature-matrix-statistical-result-not-practical-reality</guid>
      <pubDate>Tue, 30 Jul 2024 09:28:46 GMT</pubDate>
    </item>
    <item>
      <title>参考请求：柯西分布随机变量族在线性分式变换下封闭的历史</title>
      <link>https://stats.stackexchange.com/questions/651982/reference-request-history-of-the-fact-that-the-family-of-cauchy-distributed-ran</link>
      <description><![CDATA[我在 MathOverflow 上询问了这个问题，但几乎没有人关注，也没有人回答。
假设一个位置尺度概率分布族具有这样的属性：如果随机变量 $X$ 的分布属于该族，并且 $a,b,c,d\in \mathbb R$ 和 $ad-bc\ne0$ 则 $(aX+b)/(cX+d)$ 的分布也属于该族。那么这就是柯西分布族。这在 Frank B. Knight 的《柯西型的特征》中得到了证明，Proc. Amer. Math. Soc. 55 (1976), 130–135.
一个更简单的结果是其逆命题：柯西型分布族在该运算下是封闭的。
应该引用哪些书籍或论文来表明这个更简单的命题，即 Knight 论文所说的逆命题，已经存在了一段时间？]]></description>
      <guid>https://stats.stackexchange.com/questions/651982/reference-request-history-of-the-fact-that-the-family-of-cauchy-distributed-ran</guid>
      <pubDate>Tue, 30 Jul 2024 02:57:46 GMT</pubDate>
    </item>
    <item>
      <title>假设 $E[\{g(X) - \hat{g}(X)\}^2]$ 为 $O(a_n)$，​​且 $Y$ 为二进制。$(\hat{f}(X)-Y)(g(X)-\hat{g}(X))^2$ 的 $O_p$ 是多少？</title>
      <link>https://stats.stackexchange.com/questions/651980/suppose-e-gx-hatgx-2-is-oa-n-and-y-is-binary-whats-the</link>
      <description><![CDATA[假设 $E[\{f(X) - \hat{f}(X)\}^2]$ 和 $E[\{g(X) - \hat{g}(X)\}^2]$ 是 $O(a_n)$。假设 $Y_i$ 是二进制 0/1 随机变量，$f(\cdot)$ 介于 -1 和 1 之间，$g(\cdot)$ 介于 0 和 1 之间。对于，$O_p$ 的最大值是多少
$$\frac{1}{n}\sum_{i=1}^n [(f(X_i) - \hat{f}(X_i))g(X_i) + (\hat{f}(X_i) - Y_i)(g(X_i) - \hat{g}(X_i))]^2?$$
展开平方，我们得到一个和3 个项的和：
\begin{align*}
&amp;\frac{1}{n}\sum_{i=1}^n [(f(X_i) - \hat{f}(X_i))g(X_i) + (\hat{f}(X_i) - Y_i)(g(X_i) - \hat{g}(X_i))]^2\\
&amp;=\frac{1}{n}\sum_{i=1}^n \{f(X_i) - \hat{f}(X_i)\}^2g^2(X_i)+2(f(X_i) - \hat{f}(X_i))g(X_i)(\hat{f}(X_i) - Y_i)(g(X_i) - \hat{g}(X_i)) + (\hat{f}(X_i) - Y_i)^2(g(X_i) - \hat{g}(X_i))^2
\end{align*&gt;
项 1：$\frac{1}{n}\sum_{i=1}^n \{f(X_i) - \hat{f}(X_i)\}^2g^2(X_i)$
由于 $g(X_i)$ 有界，且 $E[\{f(X)-\hat{f}(X)\}^2]$ 为 $O(a_n)$，因此 项 1 为 $O(a_n)$.
项 2：$\frac{2}{n}\sum_{i=1}^n (f(X_i) - \hat{f}(X_i))g(X_i)(\hat{f}(X_i) - Y_i)(g(X_i) - \hat{g}(X_i))$
因为 $g(X_i) \leq 1$ 且 $|\hat{f}(X_i) - Y_i| \leq 2$，则我们有
\begin{align*}
&amp;\frac{2}{n}\sum_{i=1}^n (f(X_i) - \hat{f}(X_i))g(X_i)(\hat{f}(X_i) - Y_i)(g(X_i) - \hat{g}(X_i))\\ &amp;\leq C \sqrt{\left(\frac{1}{n}\sum_{i=1}^n \{f(X_i)-\hat{f}(X_i)\}^2\right)\left(\frac{1}{n}\sum_{i=1}^n \{g(X_i) - \hat{g}(X_i)\}^2\right)}\\
&amp;= O_p(a_n)
\end{align*&gt;
其中 $C$ 是某个正常数，不等式由柯西-施瓦茨定理成立。
第 3 项：$\frac{1}{n}\sum_{i=1}^n (\hat{f}(X_i) - Y_i)^2(g(X_i) - \hat{g}(X_i))^2$
因为 $|\hat{f}(X_i) - Y_i| \leq 2$
$$\frac{1}{n}\sum_{i=1}^n (\hat{f}(X_i) - Y_i)^2(g(X_i) - \hat{g}(X_i))^2 \leq \frac{4}{n}\sum_{i=1}^n (g(X_i) - \hat{g}(X_i))^2 = O_p(a_n)$$
总之，我们有
\begin{align*}
&amp;\frac{1}{n}\sum_{i=1}^n [(f(X_i) - \hat{f}(X_i))g(X_i) + (\hat{f}(X_i) - Y_i)(g(X_i) - \hat{g}(X_i))]^2\\ &amp;= O_p(a_n) + O_p(a_n) + O_p(a_n)\\
&amp;= O_p(a_n)
\end{align*&gt;
我上面的工作正确吗？我不确定第 2 项和第 3 项。具体来说，虽然$|\hat{f}(X_i) - Y_i|$的上限为 2，但考虑到它涉及估计量$\hat{f}(X_i)$，可以将其取出吗？提前谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/651980/suppose-e-gx-hatgx-2-is-oa-n-and-y-is-binary-whats-the</guid>
      <pubDate>Tue, 30 Jul 2024 02:22:39 GMT</pubDate>
    </item>
    <item>
      <title>简单随机抽样是对抽象概率测度空间中的概率测度的假设吗？</title>
      <link>https://stats.stackexchange.com/questions/651959/is-simple-random-sampling-an-assumption-on-the-probability-measure-in-the-abstra</link>
      <description><![CDATA[我想知道我对简单随机抽样含义的直觉是否正确。
假设我们有一个抽象概率测度空间$(\Omega, \mathcal{A}, \mathbb{P})$，
某个可测空间$(\mathbb{R}, \mathcal{B}(\mathbb{R}))$，以及一个映射$X$，它是一个有效的随机变量，写为$X : \Omega \rightarrow \mathcal{B}(\mathbb{R})$。然后，$\mathbb{P}_{X}$ 是由 $X$ 引起的 $\mathbb{P}$ 的 前推测度，它是概率测度 $\mathbb{P}_{X} : \mathcal{B}(\mathbb{R}) \rightarrow [0, 1]$。因此，$\mathbb{P}_{X}$ 是 $X$ 的 概率分布测度，而
$(\mathbb{R}, \mathcal{B}(\mathbb{R}), \mathbb{P}_{X})$ 是 具体 的概率测度空间（即，如下所示）。

这样说对吗即：

我们为 $\mathbb{P}_{X}$ 选择的函数形式是我们对总体（即样本空间 $\Omega$）中测量值 $X$ 分布的假设？

简单随机抽样机制（即均匀分布）是我们对 $\{\omega\}$ 元素（例如，人）在 $\Omega$ 中的概率的假设？换句话说，我们是否假设$\mathbb{P}$是有限总体的均匀分布，即$\mathbb{P}(\{\omega\}) = \frac{1}{|\Omega|}$？


我的背景是心理学，在我的阅读中，我没有遇到任何作者描述与我上面的第二个问题一致的简单随机抽样——重点似乎在$\mathbb{P}_{X}$上。假设上面的第二个问题是正确的，这不就等于说

事件$\{\omega\} \in \mathcal{A}$的发生（即，无论它对一个人意味着什么...）与其被选为样本$\{\omega_{1}, \omega_{2}, \omega_{3}, ...\} \subseteq \Omega$的一部分的概率相同吗？

我希望这是有道理的，我将不胜感激任何意见和直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/651959/is-simple-random-sampling-an-assumption-on-the-probability-measure-in-the-abstra</guid>
      <pubDate>Mon, 29 Jul 2024 17:45:24 GMT</pubDate>
    </item>
    </channel>
</rss>