<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 13 Aug 2024 18:21:03 GMT</lastBuildDate>
    <item>
      <title>需要对我的混合效应模型算法有一些了解</title>
      <link>https://stats.stackexchange.com/questions/652730/need-some-insight-on-my-mixed-effect-model-algorithm</link>
      <description><![CDATA[我只是有一个一般性的问题，我已经搜索了许多资料，但仍然觉得有点困惑。这是关于我何时需要包含一个随机变量。
我有蜜蜂数据，其中包括体型作为我的响应变量（连续值），我正在测试的解释变量是年份和城市强度。我想看看不同年份（这将与以后的气候联系起来）和不同城市化水平的采样是否会影响蜜蜂体型。我有不同蜜蜂物种的数据，也有关于个体性别、饮食偏好、筑巢偏好和社会性的数据。
现在，对于蜜蜂来说，存在明确的身体二态性——雌性比雄性大。此外，蜜蜂物种肯定会影响体型，某些物种天生就比其他物种大。我很困惑，我是否应该按这些类别拆分数据，然后运行我的模型，或者我应该将它们作为随机变量，然后一次运行所有蜜蜂。
这是我使用 lme4 包的 R 代码：
&gt; mod &lt;- lmer(Head.Width ~ Urban.Intensity + (1|Species) + (1|Sex), data=data); summary(mod); Anova(mod)

Response: Head.Width
Chisq Df Pr(&gt;Chisq)
Urban.Intensity 3.208 2 0.2011

在这方面，如果我将物种和性别作为随机效应，城市强度不会影响蜜蜂的体型。然而，蜜蜂的功能性状也与物种有关，但也会影响体型，例如饮食偏好。我不确定这些是否应作为随机变量包括在内，还是也应作为固定效应包括在内？或者这在很大程度上取决于我自己的问题，并且真的可以双向进行？
&gt; mod1 &lt;- lmer(Head.Width ~ Urban.Intensity*Diet + (1|Species) + (1|Sex), data=data); summary(mod1); Anova(mod1)

Response: Head.Width
Chisq Df Pr(&gt;Chisq)
Urban.Intensity 3.2022 2 0.2017
Diet 1.0897 1 0.2965
Urban.Intensity:Diet 3.5031 2 0.1735

&gt; mod2 &lt;- lmer(Head.Width ~ Urban.Intensity + (1|Diet) + (1|Species) + (1|Sex), data=data); summary(mod2); Anova(mod2)

响应：Head.Width
Chisq Df Pr(&gt;Chisq)
Urban.Intensity 3.2077 2 0.2011

&gt;mod3 &lt;- lmer(Head.Width ~ Urban.Intensity + (1|Sociality) + (1|Diet) + (1|Genus) + (1|Sex), data=df); summary(mmod3); Anova(mod3)

响应：Head.Width
Chisq Df Pr(&gt;Chisq)
Urban.Intensity 3.2061 2 0.2013

当我不将饮食或社交作为随机效应时，mod2 和 mod3 为何会给出与mod 算法相同的输出？因此，我的问题是，我是否需要将所有变量都作为随机效应包括在内？如果一个变量在某种程度上与我标记为随机效应的另一个变量相关，那么它是否就变得可以忽略不计了？
相反，如果我按蜜蜂种类和性别分开数据，我可以得到非常不同的结果，但我不确定这是否是强制结果。对我来说，按物种/性别分开数据更有意义，因为这样我就可以充分测试城市强度是否只对某些蜜蜂物种和某些性别产生影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/652730/need-some-insight-on-my-mixed-effect-model-algorithm</guid>
      <pubDate>Tue, 13 Aug 2024 17:16:41 GMT</pubDate>
    </item>
    <item>
      <title>具有非连续间隔的生存分析中的计数过程方法？</title>
      <link>https://stats.stackexchange.com/questions/652728/counting-process-approach-in-survival-analysis-with-non-contiguous-intervals</link>
      <description><![CDATA[我正在 R 中建立一个 Cox 比例风险模型，以分析复发事件发生前的生存时间。每个案例都可能经历多次复发事件，因此我决定采用计数过程方法，记录每个“生存”间隔的 time_start 和 time_stop。
在复发事件生存分析的计数过程方法中，我能找到的所有示例都记录了给定主题中第一次事件的时间，然后数据集直接在此时间点继续记录直到第二次事件发生的时间段。
例如，time_start_1 = 0 --&gt; time_stop_1 = 3 个月；time_start_2 = 3 个月 --&gt; time_stop_2 = 7 个月，依此类推。
但是，如果我的复发事件本身涵盖了某个时间段，因此第二个间隔的开始时间不再与第一个间隔的停止时间相同，这对统计分析来说是一个问题吗？
即 time_start_1 = 0 --&gt; time_stop_1 = 3 个月；time_start_2 = 6 个月 --&gt; time_stop_2 = 9 个月。
非常感谢任何指导！]]></description>
      <guid>https://stats.stackexchange.com/questions/652728/counting-process-approach-in-survival-analysis-with-non-contiguous-intervals</guid>
      <pubDate>Tue, 13 Aug 2024 16:55:40 GMT</pubDate>
    </item>
    <item>
      <title>成分比率方差的近似值</title>
      <link>https://stats.stackexchange.com/questions/652727/approximations-for-variance-of-ratio-of-compositions</link>
      <description><![CDATA[我对以下任一等效表达式中以均值和方差表示的任何近似值或界限感兴趣：
$$
D = \sum_i^n x_i \cdot \left(\frac{y_i}{x_i} - 1\right)^2
$$
或
$$
D = \sum_i^n \frac{(y_i - x_i)^2}{x_i}
$$
其中 $0 &lt; x_i \le 1$; $\sum_i^n x_i = 1$ 和 $0 \le y_i &lt;= 1$，$\sum_i^n y_i = 1$。
第一个表达式具有加权方差的形式；第二个表达式具有卡方统计量的形式。尽管如此，这两个表达式是等效的。
我所知道的：因为这些是组合，所以我知道 $x$ 和 $y$ 的平均值必须是 $\frac{1}{n}$。
我还知道 $x$ 和 $y$ 的方差。
我不知道 $x$ 和 $y$ 的具体值（否则我只会计算表达式）。我也不知道 $x$ 和 $y$ 之间的协方差（但它可能是正的）。
我还对 $x$ 和 $y$ 之间给定协方差的界限或近似值感兴趣。
我不确定如何施加额外的分布
假设。虽然这些变量是比例，但将它们建模为独立的 Beta 分布忽略了这样一个事实：鉴于这些是组合，投票份额加权平均比率 $x_i (y_i/x_i)$ 必须是 1。将它们建模为狄利克雷变量需要我指定完整的集中向量。
上下文：上面的两个表达式是 Sainte-Laguë 指数 的表达式，该指数是衡量选举不成比例的指标。在此上下文中，$x$ 和 $y$ 分别是选票份额和席位份额的向量。如果所有政党都赢得一些选票，$x$ 严格大于零；但由于某些政党可能无法赢得席位，$y$ 仅大于或等于零。
我尝试按照 https://www.stat.cmu.edu/~hseltman/files/ratio.pdf 中给出的步骤使用泰勒展开式计算比率的方差，但这给我的应用程序带来了非常糟糕的结果，可能是因为我的表达式是加权方差而不是简单方差。]]></description>
      <guid>https://stats.stackexchange.com/questions/652727/approximations-for-variance-of-ratio-of-compositions</guid>
      <pubDate>Tue, 13 Aug 2024 16:54:59 GMT</pubDate>
    </item>
    <item>
      <title>在分组条形图之间添加更多空格[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652726/adding-more-spaces-between-grouped-barcharts</link>
      <description><![CDATA[我想绘制一个分组条形图，并确保每个组之间有足够的空间。
这是我尝试过的方法和结果：
import matplotlib.pyplot as plt
import numpy as np

datasets = [&#39;20news&#39;, &#39;NYTimes&#39;, &#39;Grolier&#39;]
metrics = [&#39;C_P&#39;, &#39;C_A&#39;, &#39;NPMI&#39;, &#39;UCI&#39;]
percentages = [&#39;50 %&#39;, &#39;70 %&#39;, &#39;90 %&#39;, &#39;100 %&#39;]
models = [&#39;Gaussian-BAT&#39;, &#39;BAT&#39;, &#39;ATM&#39;, &#39;LDA&#39;, &#39;GSM&#39;, &#39;ProdLDA&#39;, &#39;NVLDA&#39;, &#39;NVDM&#39;, &#39;VaGTM-IP&#39;, &#39;GD&#39;]

# 生成随机样本数据
np.random.seed(0)
data = np.random.rand(len(metrics), len(datasets), len(percentages), len(models)) - 0.5

# 绘图
fig,axes = plt.subplots(len(datasets), len(metrics),figsize=(20, 10))
fig.tight_layout(pad=4.0)

for i,dataset in enumerate(datasets):
for j,metric in enumerate(metrics):
ax =axes[i,j]
for k,model in enumerate(models):
ax.bar(np.arange(len(percentages)) + k * 0.1,data[j,i,:,k],width=0.1,label=model)

ax.set_title(f&#39;{metric} on {dataset}&#39;)
ax.set_xticks(np.arange(len(percentages)) + 0.4)
ax.set_xticklabels(percentages)

axes[0, 0].legend(loc=&#39;lower center&#39;, bbox_to_anchor=(2.38, -3.6), ncol=len(models))

plt.show()

绘图输出：

问题：如何增加分组条之间的空间，使其看起来像下面的示例？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652726/adding-more-spaces-between-grouped-barcharts</guid>
      <pubDate>Tue, 13 Aug 2024 16:52:54 GMT</pubDate>
    </item>
    <item>
      <title>按一周中的每一天进行直接多步预测？</title>
      <link>https://stats.stackexchange.com/questions/652724/direct-multi-step-forecasting-by-each-day-of-the-week</link>
      <description><![CDATA[我希望针对特定领域问题创建每日 7 天预测。
目前我有一个递归解决方案，但效果不太好。
我也研究过直接预测方法。但如果我的预测是在一周中的不同日子运行的，那么这如何工作呢？我问这个问题是因为我的数据有一些很强的每周季节性。
周一到周日，每周的每一天都有一个模型（即 LightGBM）是否有意义？但是，如果我在一周中的不同日子运行预测，我发现这会在推理时引起问题，特别是试图弄清楚一组一致的输入特征会是什么样子。
附言：我对使用 ML 很感兴趣，因为我想对跨多个位置的大量项目进行建模，同时对其他因素（天气、事件等）的影响进行建模。
提前谢谢 😊]]></description>
      <guid>https://stats.stackexchange.com/questions/652724/direct-multi-step-forecasting-by-each-day-of-the-week</guid>
      <pubDate>Tue, 13 Aug 2024 16:46:59 GMT</pubDate>
    </item>
    <item>
      <title>值得聚类的点的最少数量是多少？</title>
      <link>https://stats.stackexchange.com/questions/652722/whats-the-minimum-number-of-points-worth-clustering</link>
      <description><![CDATA[我正在使用 HDBSCAN 对句子的向量嵌入进行聚类。嵌入是从不断更新的在线 SQL 表中提取的。在高峰时段，这意味着每小时有 1,000 个嵌入，但至少有 10 个。
我想每小时进行一次聚类，但我担心 10 个嵌入会产生一组毫无意义、可能错误的聚类。这让我很担心，因为我想跟踪聚类的质心以及它们随时间的变化。
要形成有意义的聚类，所需的点数是否有下限？]]></description>
      <guid>https://stats.stackexchange.com/questions/652722/whats-the-minimum-number-of-points-worth-clustering</guid>
      <pubDate>Tue, 13 Aug 2024 16:06:47 GMT</pubDate>
    </item>
    <item>
      <title>我应该计算所有值的平均值还是每个时间点的平均值来分析？</title>
      <link>https://stats.stackexchange.com/questions/652720/should-i-calculate-the-average-over-all-values-or-at-each-point-in-time-to-analy</link>
      <description><![CDATA[我正在尝试分析不同车型汽车在一段时间内的维护成本。我有很多模型。某个模型的一些示例数据如下所示。例如，这可能全部用于福特汽车，并且每个 Car ID 可能代表福特汽车的特定型号。



汽车年龄（年）
维护成本（美元）
汽车ID




1
62
A


2
22
A


3
235
A


4
228
A


5
403
A


1
36
B


2
130
B


3
89
B


4
30
B


5
25
B


1
59
C


2
168
C


3
118
C


4
72
C


5
471
C


1
51
D


2
126
D


3
201
D


4
92
D


5
302
D



我想了解维护成本。具体来说，我想显示某个特定的 Car ID 相对于同类产品（即其他 Car ID）的成本是高很多还是低很多。
我想要做的是计算出平均成本和标准差，以便绘制异常值。假设任何高于或低于 3 个标准差（或可能是 2 个）的值。
问题：
我是否应该计算每年的平均值和标准差，即对于第 1 年，我将平均 62、36、59、51，并计算出这些数字的标准差，然后根据此确定异常值？
或
我是否应该计算整个数据集的平均值/标准差？
我不太确定这两个选项之间的区别是什么。当然，前者的平均线和平均值 +- 2 * s.d 将不是直线，而后者则是直线。
我之前见过一些统计过程控制图，它们具有平坦的平均线和平坦的上/下控制限（平均值 +- s.d 的倍数），但鉴于我有多个 Car ID，而不仅仅是查看一个 Car ID，我想知道我是否应该计算每年每个点的平均值。
我主要感兴趣的是与同一品牌的其他车型相比，哪些车型最贵或最便宜。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652720/should-i-calculate-the-average-over-all-values-or-at-each-point-in-time-to-analy</guid>
      <pubDate>Tue, 13 Aug 2024 14:58:09 GMT</pubDate>
    </item>
    <item>
      <title>根据先前研究的项目参数计算新样本的 IRT 量表分数</title>
      <link>https://stats.stackexchange.com/questions/652718/computing-irt-scale-scores-for-new-samples-based-on-item-parameters-from-previou</link>
      <description><![CDATA[我一直想问一个问题，但由于表达不清楚而失败了——所以我会再试一次——有没有人用 R 写过一个程序，从以前的研究中获取 IRT 项目参数，以便能够为新样本计算新的 IRT 量表分数——或者可以给我指出一个资源
提前谢谢——我对 chatGPT 之类的东西没有信心 :-)]]></description>
      <guid>https://stats.stackexchange.com/questions/652718/computing-irt-scale-scores-for-new-samples-based-on-item-parameters-from-previou</guid>
      <pubDate>Tue, 13 Aug 2024 14:35:37 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归 - 使用偏移和权重</title>
      <link>https://stats.stackexchange.com/questions/652731/poisson-regression-using-offset-and-weights</link>
      <description><![CDATA[我看过几篇关于使用偏移量与使用权重的帖子，但我找不到任何关于使用这两个功能的信息。
问题如下：我模拟了发生事件的数量 (k)。在数据中，除了协变量之外，我还有一些预期事件的数量 (e) 和曝光单位的数量 (n)。
我希望模型是泊松回归的形式（伪代码）：
log(k) ~ offset(e) + 协变量
...换句话说，发生 (k) 将按预期 (e) 乘以一些系数进行建模。
但是，由于上述模型不使用有关曝光单位的任何信息，因此我还在 R 的 glm 函数中加入了术语：weights=n。在我看来，这很合理，因此 1000 次曝光和 1 个事件的观察结果与 10 次曝光和 1 个事件的观察结果的处理方式不同。
问题就在这里：如果我拟合这样的模型并尝试预测训练数据上的事件，我不会得到总 k。只有当我不使用权重时，我才能得到这个数字。
我的方法有什么错误？我应该放弃泊松回归的权重，还是应该继续使用它们并“接受”总预测数的差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/652731/poisson-regression-using-offset-and-weights</guid>
      <pubDate>Tue, 13 Aug 2024 10:28:11 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测中的神经网络：使用前一个网络作为下一个时间间隔的起点[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652708/neural-net-in-time-series-forecasting-the-use-of-previous-net-as-a-staring-poin</link>
      <description><![CDATA[我使用 NN 进行时间序列预测，其中我使用的序列和特征非常嘈杂。我使用前 T 个输入训练网络并获得了不错的结果：网络从随机初始化的权重开始学习效果很好。然后我转到下一个估计点，例如使用移动窗口，它将是间隔 [T+1,2T] 或扩展窗口 [1,2T]。如果我从随机初始化的权重开始，网络将再次学习。但是，由于我预计分布不会发生很大变化，因此我开始从上一步获得的网络进行训练，但损失在学习周期内未能改善。 我理解这是可能的，因为分布变化不大，而且几乎没有什么新东西需要学习。但是，我想知道这个问题是否可能是由于我学习的权重偏离了目标而导致的，而它们的统计特性使它们成为一个糟糕的起点？]]></description>
      <guid>https://stats.stackexchange.com/questions/652708/neural-net-in-time-series-forecasting-the-use-of-previous-net-as-a-staring-poin</guid>
      <pubDate>Tue, 13 Aug 2024 10:07:34 GMT</pubDate>
    </item>
    <item>
      <title>“添加”多个估计的置信区间</title>
      <link>https://stats.stackexchange.com/questions/652706/adding-confidence-intervals-of-multiple-estimations</link>
      <description><![CDATA[我有救护服务每季度接诊的受伤人数估计值以及置信区间。我想添加这些估计值以检索救护车接诊的年度总受伤人数估计值。如何计算这个总数的置信区间？
每个季度，每个救护服务都会进行 N 次接诊。从 N 中抽取 +-1000 个病例样本 (n)。对于此样本中的每个病例，确定该接诊是否与受伤有关 (1) 或无关 (0；即与疾病等有关)。这意味着我可以计算样本中受伤的比例：p̂ = n1/ntotal。为了估算受伤人数（我们称该统计数据为“x”），我将 p̂ 与 N 相乘。
但是，我想考虑随机抽样引入的不确定性，因此我使用 R 中的 stats::binom.test() 函数估算 p̂ 周围的置信区间 (CI)，并将找到的下限和上限乘以 N 以检索 x 周围的 CI。
因此，现在我对每项救护服务和每个季度（x1、x2、… xn）都有 x 的估算值，我可以将其相加得到年度全国估算值。但是，我不确定如何“添加”置信区间。我非常确定取和将产生过于悲观的区间。
我找到了这篇文章，它似乎表明我可以对 CIs 半径的平方和取平方根，因为我假设一年内的救护服务和季度之间存在统计独立性。但我不确定这是否正确。我正在考虑的另一种方法是将每个服务和季度的所有数据堆积起来，并使用它来计算 p̂ 和 CIs。然而，众所周知，受伤比例在服务（和季度）之间以及总乘车次数（N）之间存在显着差异。我不确定这种方法是否也会产生悲观的 CI。
那么，我如何使用数据来计算全年估计的 CI？]]></description>
      <guid>https://stats.stackexchange.com/questions/652706/adding-confidence-intervals-of-multiple-estimations</guid>
      <pubDate>Tue, 13 Aug 2024 09:34:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么卡方检验的 p 值和 KS 检验的 p 值之间差异很大？</title>
      <link>https://stats.stackexchange.com/questions/652702/why-do-i-get-a-large-difference-between-the-p-value-of-a-chi-square-test-and-the</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652702/why-do-i-get-a-large-difference-between-the-p-value-of-a-chi-square-test-and-the</guid>
      <pubDate>Tue, 13 Aug 2024 09:08:18 GMT</pubDate>
    </item>
    <item>
      <title>时间序列季节性分析-评分方法</title>
      <link>https://stats.stackexchange.com/questions/652698/time-series-seasonality-analysis-scoring-method</link>
      <description><![CDATA[我正在研究时间序列中的季节性搜索，并希望使用序列中的符号来自动化该过程，而无需手动检查曲线。我建议评估季节性的三个分数是：
季节性强度：使用 Python 的 STL 分解 (LOESS) 后，我恢复了三个组成部分：趋势、季节性和残差。我测量了季节性成分相对于噪声的方差比例。我使用 STL 参数“周期”的不同值进行迭代。
季节性相似性：使用季节性成分，我比较季节性子周期以检查从一个时期到另一个时期的模式一致性。
季节性模式：分析季节性成分子周期之间模式（上升/下降）的重复性，以评估季节性的稳定性。
我将这 3 个分数与 python 的分解 STL（来自 statsmodels.tsa.seasonal 导入 STL）结合使用，并使用参数“period”定义季节性周期，然后我检索分数。
您认为这些符号与自动搜索季节性一致吗？您知道其他有效的方法吗？也许是分类方法？我希望能够从不同的数据细分（每周、每月、每季度）中了解每个细分中最大的季节性周期。]]></description>
      <guid>https://stats.stackexchange.com/questions/652698/time-series-seasonality-analysis-scoring-method</guid>
      <pubDate>Tue, 13 Aug 2024 08:33:48 GMT</pubDate>
    </item>
    <item>
      <title>“正弦”激活对于重建/隐式映射以外的任务有用吗？</title>
      <link>https://stats.stackexchange.com/questions/652669/are-sine-activations-useful-for-tasks-other-than-reconstruction-implicit-map</link>
      <description><![CDATA[这篇文章询问了在神经网络中使用sine激活的问题。
2020 年的一篇有趣的论文 (SIREN)使用激活来完成一些任务。本网站中也有作者编写的节选版。
据我所知，这些是重建任务，即不是标准计算机视觉、NLP 等任务。
我的理解也基于Reddit 上的这条评论。
显然，该领域被称为隐式神经表征，它们对单个信号样本进行了过度拟合；例如将图像中的 x,y 坐标映射到像素，这是 隐式 部分。
由此，它们将有助于重建图像或音频的部分，或任何输入信号？作者似乎表明他们可以对输入进行编码（以过度拟合的方式）。

对此的解释是否正确？
如前所述，正弦激活实际上并未用于/用于标准机器学习任务，对吗？

PS：有趣的论文解决了其中一些问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/652669/are-sine-activations-useful-for-tasks-other-than-reconstruction-implicit-map</guid>
      <pubDate>Mon, 12 Aug 2024 16:46:24 GMT</pubDate>
    </item>
    <item>
      <title>根据删失数据估计对数正态分布的参数以进行模拟</title>
      <link>https://stats.stackexchange.com/questions/652482/estimate-parameters-of-a-log-normal-distribution-from-censored-data-for-simulati</link>
      <description><![CDATA[我有以下模型
$$Y=X_1/c_1+X_1*X_2/c_2+X_3/c_3+X_3*X_4/c_4.$$
我知道 $X_1$ 和 $X_3$ 遵循不同但已知的正态分布，$c_1\dots,c_4$ 是已知常数，而 $X_2,X_4$ 遵循不同的未知对数正态分布。我想进行蒙特卡罗模拟来估计 $Y$ 的分位数。
我有一些数据可以估计 $X_2,X_4$ 的分布，但这些数据是左删失和右删失的。它可能看起来像这样：
$$\begin{matrix} &lt;0.2 &amp; 0.1 &amp; &gt;4 &amp; 0.7 &amp; 0.9 &amp; &lt;0.3 &amp;&gt;0.7 &amp;0.3 &amp;&lt;0.1 \end{matrix}$$
在较好的情况下，我有 60 个数据点，其中 10 个是删失的。在最坏的情况下，我有 21 个数据点，其中 9 个是删失的。
使用删失数据，我可以估计对数正态分布 $X_2,X_4$ 的参数。我使用 R 包 fitdistrplus 执行此操作。对于 $X_2$，我得到例如：
$$\begin{matrix} &amp; \text{estimate} &amp; \text{Std. Error}\\ \text{meanlog} &amp; -1.5&amp; 0.2\\ \text{sdlog} &amp; 1.8 &amp; 0.19 \end{matrix}$$
我想将估计的不确定性纳入我的模型中。有没有自然的方法可以做到这一点？我的想法是根据错误改变对数正态分布的参数。因此，我可以从 $\mathcal{N}(-1.8,0.19^2)$ 中选择不同的 $\text{meanlog}$，用于模拟形式 $\mathcal{N}(-1.5,0.2^2)$ 和 $\text{sdlog}$。但此处选择正态分布似乎有些武断。如果数据没有被审查，则 t 分布和 $\chi^2$ 分布似乎很自然地被选择（如果我是对的？）但这如何处理被审查的数据？我是否应该忽略计算误差并以任何方式使用它们？但自由度是多少？或者这些数据是否足以使用正态近似？或者还有其他方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652482/estimate-parameters-of-a-log-normal-distribution-from-censored-data-for-simulati</guid>
      <pubDate>Thu, 08 Aug 2024 08:53:39 GMT</pubDate>
    </item>
    </channel>
</rss>