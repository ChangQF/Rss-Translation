<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 21 Jun 2024 21:15:27 GMT</lastBuildDate>
    <item>
      <title>我想了解一下我在这里从事的工作</title>
      <link>https://stats.stackexchange.com/questions/649690/i-would-like-some-insight-into-what-i-have-been-working-on-here</link>
      <description><![CDATA[我从事屋顶销售工作，入门级需要上门推销。我们分行的 GroupMe 聊天中会打印每日数据。我主动对这些数字进行了一些分析。有敲门、谈话、走访和偶发事件（达成的交易）。
我不会向你介绍我所做的一切，但我会告诉你，我发现敲门次数和偶发事件之间的相关性为 -0.41，这意味着我们敲的门越多，达成的交易就越少；上门推销的差异也很大，远远超出了每日数字的范围。我对此非常感兴趣，因为销售工作几乎总是“数字游戏”，这意味着他们使用平均法则 - 如果你敲了很多门，最终你就会达成交易。
我告诉领导层这件事，他们给了我“焚书”式的回应。他们告诉我不要分享任何“负面”信息或者告诉人们不要为了赚更多的钱而努力工作；我放弃了和他们讨论这个问题，而是自己深入研究它。
首先，我计算了平均每敲 100 扇门，有多少个意外事件被签署。它是 ~2.59。我用它作为二项分布函数中的“假定概率”，并绘制了每次敲门（0 - 100）的销售概率。我发现，最有可能产生 ~2.59 笔销售，2 笔销售的概率约为 25% 左右。负相关性告诉我，收益递减点已经存在，所以我仍然不相信越多越好。
其次，我决定对每 100 扇门进行预期值计算。当然，每扇门 2.59% 的销售概率保持不变；但是，惩罚（使用的资源，如汽油和时间等）确实会随着每扇门而增加。我称之为每扇门 1 美元的汽油，因为这就是我所花费的。这告诉我，在 52 次敲门后，你真的没有什么可获得的了。这让我意识到二项分布概率会随着试验次数的变化而变化……
第三，我回到电子表格并将试验次数改为 52；这表明最有可能的结果是 1 次销售，概率略高于 33%（这大于 100 次试验中 2 次销售的约 25% 的概率）。
由于这一切都基于我们分行的实际绩效数据，我觉得我已经证明（至少在统计上）我已经解释了负相关性，并证明了“上升和磨砺”每天尽可能多地敲门是一种策略，但这种策略会适得其反，导致销售代表产生不一致的数字（解释了高方差）。
我现在的假设是，如果所有销售代表每个周期（一天、一周或其他时间段）敲门 52 次，方差将更接近于零或至少在数据范围内，销售额将会增加，相关性可能会显示敲门次数和意外事件之间存在正相关关系，因为敲门次数通常会较低，意外事件的数量会较高。
我希望从更有经验的人那里了解我的发现是否有价值，或者我是否遗漏了什么。在非正式场合，我很乐意编写 Python 代码来绘制所有这些。]]></description>
      <guid>https://stats.stackexchange.com/questions/649690/i-would-like-some-insight-into-what-i-have-been-working-on-here</guid>
      <pubDate>Fri, 21 Jun 2024 21:04:41 GMT</pubDate>
    </item>
    <item>
      <title>与三元变量进行 3 次比较</title>
      <link>https://stats.stackexchange.com/questions/649689/making-3-comparisons-with-a-ternary-variable</link>
      <description><![CDATA[我有一项研究，我想研究三元变量 x 与二元变量 y 交互的影响。三元变量是分类变量，出于某些原因，我想对 3 个组进行 3 次比较。
我明白要进行一次比较，我必须进行 2 次对比。例如，如果我对组 1 与组 3 感兴趣，我定义 C1= (-1,0,1) 和 C2=(-1,2,-1)。如果我想测试所有的比较，那么我应该做 6 次对比吗？在这种情况下，回归量不是共线的吗？有没有更简单的方法可以做到这一点？
谢谢你的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/649689/making-3-comparisons-with-a-ternary-variable</guid>
      <pubDate>Fri, 21 Jun 2024 20:51:47 GMT</pubDate>
    </item>
    <item>
      <title>解释 SPSS PROCESS 输出的二分法 Y 值资源</title>
      <link>https://stats.stackexchange.com/questions/649687/resources-for-interpreting-spss-process-output-with-a-dichotomous-y</link>
      <description><![CDATA[我目前正在使用 SPSS 中的 PROCESS 宏扩展进行中介分析。我最近了解到，此扩展中可以使用二分 Y。话虽如此，使用逻辑回归可以改变输出。有人知道任何使用二分 Y 解释 PROCESS 宏输出的资源吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649687/resources-for-interpreting-spss-process-output-with-a-dichotomous-y</guid>
      <pubDate>Fri, 21 Jun 2024 20:39:42 GMT</pubDate>
    </item>
    <item>
      <title>RCT 的线性混合模型中的插补</title>
      <link>https://stats.stackexchange.com/questions/649686/imputation-in-a-linear-mixed-model-for-rct</link>
      <description><![CDATA[我有一项研究，其中参与者被随机分配到两种条件之一（参与者条件）。他们在测试前和测试后都完成了调查。我想看看条件和时间之间是否存在显著的相互作用，看看一种条件是否比另一种条件导致 DV 从测试前到测试后的变化更大。数据是长格式。
数据也被输入了 50 次，并存储在以下 mids 对象中：impmids。
有人可以确认这是否是测试所提研究问题的正确代码吗：
library(mice)
library(lme4)

P.eddi &lt;- with(impmids, lmer(EDDI_Total ~ ParticipantCondition * Time + (1|Participant_ID_New)))
BP.eddi.pooled &lt;- pool(BP.eddi)
summary(BP.eddi.pooled)

谢谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/649686/imputation-in-a-linear-mixed-model-for-rct</guid>
      <pubDate>Fri, 21 Jun 2024 19:47:04 GMT</pubDate>
    </item>
    <item>
      <title>使用什么指标来丢弃与所有其他注释者具有较低 IAA（注释者间一致性）的注释者？</title>
      <link>https://stats.stackexchange.com/questions/649685/what-is-the-best-metric-to-use-to-discard-annotators-with-low-iaa-inter-annotat</link>
      <description><![CDATA[此问题特定于在李克特量表上收集的序数数据
丢弃与其他人的注释者之间注释者一致性 (IAA) 较低的注释者的最佳指标是什么？例如，Cohen 的 Kappa、Fleiss 的 Kappa、Krippendorff 的 Alpha
是成对计算每对注释者之间的注释者一致性更好，还是可以对 1 个注释者与其他注释者进行比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/649685/what-is-the-best-metric-to-use-to-discard-annotators-with-low-iaa-inter-annotat</guid>
      <pubDate>Fri, 21 Jun 2024 19:19:02 GMT</pubDate>
    </item>
    <item>
      <title>GAM 分析有两种方式：使用正态分布作为生存百分比，使用二项分布作为存活/死亡，但得到的结果截然不同</title>
      <link>https://stats.stackexchange.com/questions/649684/gam-analysis-two-ways-as-percent-survival-using-normal-dist-and-as-alive-dead-u</link>
      <description><![CDATA[我的问题与鲑鱼种群数据有关。我想了解海洋变量如何影响鲑鱼的回归。我用两种不同的方法分析了数据。第一个响应变量是返回鲑鱼数量与外出鲑鱼数量的百分比，但这是有问题的，因为我们将每年数千个数据点压缩成一个数字。
gam_hatcherySAR_cuti &lt;- gam(sar ~ s(CUTI), data = hatcherySAR, method = &quot;REML&quot;)

 out_yr SAR CUTI
1 2008 0.003664542 -0.03291667
2 2009 0.010083530 -0.04575000
3 2010 0.005462051 -0.29100000
4 2011 0.004414756 -0.12783333
5 2012 0.002900364 -0.20225000
6 2013 0.005570978 0.09850000
7 2014 0.012547544 -0.07283333
8 2015 0.006963657 0.07700000
9 2016 0.004722142 -0.04975000
10 2017 0.002127052 -0.00575000
11 2018 0.007220002 0.03550000`

因此，我想通过另一种方式对其进行分析，即使用逻辑回归方法将响应变量视为存活与死亡。
gam_hatcherySARbin_cuti &lt;- gam(cbind(hatcherySARbin$alive,hatcherySARbin$dead) ~ s(CUTI), data=hatcherySARbin,family=binomial(),method = &quot;REML&quot;)

 年份 存活 死亡 剪切
[19,] &quot;2008&quot; &quot;15750&quot; &quot;4282232&quot; &quot;-0.032916667&quot;
[20,] &quot;2009&quot; “42239” “4146665” “-0.04575” 
[21,] “2010” “23290” “4240634” “-0.291” 
[22,] “2011” “16367” “3682322” “-0.127833333” 
[23,] “2012” “11699” “4021761” “-0.20225” 
[24,] “2013”​​ “18701” “3338073” &quot;0.0985&quot; 
[25,] &quot;2014&quot; &quot;48229&quot; &quot;3795423&quot; &quot;-0.072833333&quot;
[26,] &quot;2015&quot; &quot;20134&quot; &quot;2870199&quot; &quot;0.077&quot; 
[27,] &quot;2016&quot; &quot;13130&quot; &quot;2786228&quot; &quot;-0.04975&quot; 
[28,] &quot;2017&quot; &quot;6219&quot; &quot;3032885&quot; &quot;-0.00575&quot; 
[29,] &quot;2018&quot; &quot;18603&quot; &quot;2558000&quot; &quot;0.0355&quot;

但是，这两种分析方法的结果截然不同，即 CUTI 在上述高斯示例中不是一个重要的预测因子，而二项式示例则非常重要。我还看到我评估过的许多其他海洋变量也有类似的结果。显然，考虑到不同的分布，我预期的结果会略有不同，但不会像我看到的那么大。有人能帮我理解这是为什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649684/gam-analysis-two-ways-as-percent-survival-using-normal-dist-and-as-alive-dead-u</guid>
      <pubDate>Fri, 21 Jun 2024 19:10:08 GMT</pubDate>
    </item>
    <item>
      <title>导致非线性回归引导问题的“重要”数据点</title>
      <link>https://stats.stackexchange.com/questions/649683/important-data-points-causing-problems-with-nonlinear-regression-bootstrapping</link>
      <description><![CDATA[我正在尝试模拟行星表面的雷达反向散射。散射回仪器的功率取决于它观察表面的角度。由此产生的功率与角度曲线的形状由表面的特性决定。
这是我的所有数据的图表，其中包含一个 5 参数模型。

上图中的每个点都显示为单个点，但这只是为了显示。这些点中的每一个实际上都是由包含数千个像素的雷达图像组成的，其中每个像素都有指定的角度和功率。
以下是实际拟合的完整数据：

请注意，每个像素在图像的平均功率附近都是嘈杂的 - 这部分是由于雷达图像固有的“斑点噪声”，并且是乘性噪声。这意味着功率测量值越大，噪声就越大。 （这不是很明显，因为绘图是以 dB 为单位的，这是一个对数刻度。）
使用 MATLAB 的 fit 函数将表面模型拟合到所有数据，对 5 个模型参数给出了非常非常严格的限制。例如，它估计表面的介电常数为 1.329（1.326, 1.332）。对于数据的稀疏性和噪声性来说，这是一个不切实际的置信度，尤其是在第一张图中看到数据点的“真实”分布时。
我尝试使用引导法获得更准确的拟合参数不确定性。我尝试的第一件事是通过从 500,000 个像素池中进行 500,000 次替换采样来创建引导样本。每个引导拟合的结果实际上与第一次拟合完全相同，拟合参数的分布同样很小（+- 0.01）。我可以理解为什么会这样（我认为）。通过选择这么多像素，每个雷达图像的分布基本上完全重建，并且最终的拟合不会改变。
然后我认为我应该将大约 30 张雷达图像中的每一个都视为一个测量值，并通过从图像集中进行替换选择来制作引导样本。如果选择了图像，则将其所有像素都包含在拟合向量中，而不仅仅是其平均值。我这样做是因为我认为像素分布中有重要的角度信息，尤其是在斜率陡峭的低角度。
但是，当我使用此方法时，控制低角度行为的参数是极其双峰的。结果几乎完全取决于引导样本中是否包含 0 度和 5 度左右的图像。如果包括它们，则有一个拟合，如果不包括它们，则有另一个拟合。在低入射角时会出现指数衰减，因此包含/排除这几个点对于模拟该行为非常重要。


我应该如何处理这个问题？这几个重要的点决定了模型该状态的行为，因此我的参数估计中的不确定性更多地与“是否包含该点”有关比任何东西都重要，这似乎在科学上没有什么用。不幸的是，我可用的数据非常有限，特别是在低入射角的情况下。
在这种情况下，引导法是否是我获取参数不确定性的正确方法？我也研究了引导残差，但我认为它无效，因为散斑噪声是乘性的，并且取决于观察的功率。统计学的这个领域对我来说很新，所以任何帮助都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649683/important-data-points-causing-problems-with-nonlinear-regression-bootstrapping</guid>
      <pubDate>Fri, 21 Jun 2024 18:50:21 GMT</pubDate>
    </item>
    <item>
      <title>这些是从我的代码生成的所谓的特征图吗？</title>
      <link>https://stats.stackexchange.com/questions/649680/are-these-generated-from-my-code-the-so-called-feature-maps</link>
      <description><![CDATA[我假设人们构建激活函数来检测图像中的特定部分的方式是通过执行网络并在每一层提取结果；当输出来自卷积层时，它被称为特征图（据我所知）。
我的问题是，实际上说这是一个特征图是否正确，这是每次运行网络到特定深度的结果（除了我丢弃的层）。
我生成的图像（这个问题是关于的。）在底部。
我是否正确地假设这里的layer.output是一个KerasTensor，它可以记住到那时为止的所有变换（和权重）？
所以它在这里并不是一个真正的符号张量。
如果你想运行它，基于 keras 文档的代码，在笔记本中作为示例执行此操作，代码如下：
!pip install tensorflow[and-cuda]==2.16.1 keras==3.3.3

import os
os.environ[&quot;KERAS_BACKEND&quot;] = &quot;tensorflow&quot;

导入 numpy 作为 np
导入 tensorflow 作为 tf
导入 keras
从 keras 导入 o​​ps
从 keras 导入层
导入 imageio 作为 iio
从 PIL 导入图像
导入 matplotlib.pyplot 作为 plt
# 检索 vgg19
vgg19 = keras.applications.VGG19()

# 获取张量，可能还有历史记录
features_list = [layer.output for layer in vgg19.layers]

# 我不确定 keras 如何解释列表，但似乎
# 它将包含所有操作
feat_extraction_model = keras.Model(inputs=vgg19.input, output=features_list)

# 在互联网上的图像上进行测试（a狗。)
img=iio.imread(&quot;https://images.squarespace-cdn.com/content/v1/54822a56e4b0b30bd821480c/29708160-9b39-42d0-a5ed-4f8b9c85a267/labrador+retriever+dans+pet+care.jpeg?format=1500w&quot;)
img = Image.fromarray(img).resize((224, 224))
plt.imshow(img)

# print(img.shape)
img = tf.image.convert_image_dtype(image=img, dtype=&quot;float32&quot;)
img = tf.expand_dims(img,axis=0)
img = img.numpy().astype(&quot;float32&quot;)

extracted_features = feat_extraction_model(img)

fig = plt.figure(figsize=(20, 20))
columns = 4
rows = 7

for i, v in enumerate(extracted_features):
f = tf.squeeze(extracted_features[i])
if len(f.shape) != 3:
continue
if f.shape[-1] &gt; 3：
print(f.shape)
f = f[:,:,0:3] # 使用 3 个通道以便我们可以绘图
pil_img = keras.preprocessing.image.array_to_img(f)
fig.add_subplot(rows, columns, i+1)
plt.imshow(pil_img)
# time.sleep(10)
plt.show()


我得到了这个：
]]></description>
      <guid>https://stats.stackexchange.com/questions/649680/are-these-generated-from-my-code-the-so-called-feature-maps</guid>
      <pubDate>Fri, 21 Jun 2024 17:44:37 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑回归中交换预测变量和结果变量会有什么变化</title>
      <link>https://stats.stackexchange.com/questions/649678/what-changes-in-swapping-predictor-and-outcome-variables-in-logistic-regression</link>
      <description><![CDATA[我有一个数据集，其中包含一个表示细菌分离源的变量，该变量有 2 个因子，以及多个其他二进制变量，表示该细菌是否对某些抗生素具有耐药性（是或否）。
我一直在进行逻辑回归，最初将分离源视为预测因子。
glm &lt;- glm(antibiotic1 ~ source, data = df, family = binomial()) 
但是，我正在考虑将分离源视为结果的可能性。这样，我可以使用多个抗生素耐药性变量作为预测因子，让我可以对一些抗生素进行分组并进行多元逻辑回归，看看它是否能产生更好的见解。
glm &lt;- glm(source ~ antibiotic1 + antibiotic2, data = df, family = binomial()) 
这种方法可行吗？在可解释性方面会发生什么变化？以这种方式进行是否可取？]]></description>
      <guid>https://stats.stackexchange.com/questions/649678/what-changes-in-swapping-predictor-and-outcome-variables-in-logistic-regression</guid>
      <pubDate>Fri, 21 Jun 2024 17:12:15 GMT</pubDate>
    </item>
    <item>
      <title>重复测量的二元分类模型</title>
      <link>https://stats.stackexchange.com/questions/649673/binary-classification-model-with-repeated-measures</link>
      <description><![CDATA[我有一个模型，可以预测某人是否执行特定操作（即二元结果）。他们不“转换”的情况多于没有转换的情况。数据设置为一行按 ID 和按月份，然后加上其他特征（模型中不包括 ID 和月份）。我想知道如何处理那些没有转换的人 - 是否最好对数据进行建模，以便我们按 ID 获得最后一个条目，因此单一条目（最小化数据量）或者对于像随机森林和 XG boost 这样的算法，是否有更好的方法来转换数据（即将多个条目保留为重复测量并以另一种方式处理它们）。
我对单一条目的问题是，所有转换的 ID 可能在不同时间转换，而 0 的 ID 都来自最新日期（即现在），因此如果存在季节性影响，则无法处理。
多个条目的问题是数据中有集群。]]></description>
      <guid>https://stats.stackexchange.com/questions/649673/binary-classification-model-with-repeated-measures</guid>
      <pubDate>Fri, 21 Jun 2024 16:07:06 GMT</pubDate>
    </item>
    <item>
      <title>相关伯努利变量的成功次数</title>
      <link>https://stats.stackexchange.com/questions/649672/number-of-successes-for-correlated-bernoulli-variables</link>
      <description><![CDATA[大家早上好！给定一组独立伯努利随机变量的成功次数由二项分布描述。但是，我想知道如果伯努利变量是相关的，会怎么说。例如，在不重新插入的情况下进行采样，则成功次数由超几何分布描述，但这是一种特殊情况（相当于从瓮中取出球而不重新插入它们）。您能否推荐一些文本，其中以更通用的方式解决了相关伯努利变量的总成功次数问题？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649672/number-of-successes-for-correlated-bernoulli-variables</guid>
      <pubDate>Fri, 21 Jun 2024 15:46:52 GMT</pubDate>
    </item>
    <item>
      <title>计算由 a/b 组成的比率的百分比变化的贡献</title>
      <link>https://stats.stackexchange.com/questions/649671/calculate-the-contributions-of-percentage-change-of-a-ratio-compossed-by-a-b</link>
      <description><![CDATA[我想知道如何计算对比率 a/b 的变化贡献，其中 b 等于 a 加上其他变量：b = a + c+ d + e + f
我在几个地方看到了对 GDP 增长的常见贡献，但这些方法没有捕捉到对每个组成部分份额比率的贡献变化。我的意思是，a/b 比率可能会因为 a 的变化或因为组成 b 的其他成分而发生变化。
我提到的其他来源是：
https://math.stackexchange.com/questions/33889/calculate-relative-contribution-to-percent-change
https://www.linkedin.com/pulse/calculating-contribution-percent-change-jay-sumners-mia-lssgb/]]></description>
      <guid>https://stats.stackexchange.com/questions/649671/calculate-the-contributions-of-percentage-change-of-a-ratio-compossed-by-a-b</guid>
      <pubDate>Fri, 21 Jun 2024 15:13:39 GMT</pubDate>
    </item>
    <item>
      <title>心率测量 (bpm) 的 Bland-Altman 图遵循某些“线”模式</title>
      <link>https://stats.stackexchange.com/questions/649670/bland-altman-plot-for-heart-rate-measurements-bpm-follow-certain-line-patter</link>
      <description><![CDATA[我正在比较不同设备在不同活动期间（5 分钟休息、5 分钟锻炼和 5 分钟恢复）的心率测量值。
为了分析设备之间的一致性，我想制作 Bland Altman 图（使用极坐标 H10 作为黄金标准）。
但是，在使用所有参与者的数据制作 H10 与 Vantage V3 的 Bland Altman 图时，我注意到图中有一些奇怪的线条图案，我不完全确定为什么会出现这些图案/这意味着什么？

我还为每个参与者制作了图，如下所示：

创建 Bland Altman 图时对于此参与者，出现了以下线条模式：

在某种程度上，这些线条对我来说是有意义的，因为您可以清楚地看到，当开始锻炼时，平均心率会增加，设备之间的差异也会变大。而当完成锻炼时，平均心率以及差异会再次下降。
然而，在我读过的所有论文中，我都没有看到出现如此精确的线条模式，这让我怀疑我是否在这里做错了什么？
例如，我是否需要排除某些数据点，或者首先进行一些标准化？
任何想法或帮助，都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/649670/bland-altman-plot-for-heart-rate-measurements-bpm-follow-certain-line-patter</guid>
      <pubDate>Fri, 21 Jun 2024 15:06:25 GMT</pubDate>
    </item>
    <item>
      <title>特定事件发生时间对响应的影响</title>
      <link>https://stats.stackexchange.com/questions/649668/impact-of-time-to-particular-event-on-response</link>
      <description><![CDATA[我正在尝试评估哪些变量会对结果产生影响。我的临床团队想检查特定事件发生的时间是否会影响结果。如果发生了特定事件，那么发生该事件的时间就很明显了，但如果没有发生该事件，该如何设置发生特定事件的时间。如果我将发生特定事件的时间设置为没有发生事件的患者接受治疗的最大时间，那么我会自动发现存在影响]]></description>
      <guid>https://stats.stackexchange.com/questions/649668/impact-of-time-to-particular-event-on-response</guid>
      <pubDate>Fri, 21 Jun 2024 14:42:32 GMT</pubDate>
    </item>
    <item>
      <title>不同长度合规率（按时间段）的单因素方差分析</title>
      <link>https://stats.stackexchange.com/questions/649647/one-way-anova-on-compliance-rates-by-time-period-with-different-lengths</link>
      <description><![CDATA[我对此有点困惑，因为在我的统计课上，我们很好地打包了数据，其中包含易于理解的良好、正常数据！如果这看起来太明显，请原谅。
我的数据是几个审计期 (AP) 中几类员工的一系列合规率。我们会说他们应该执行的操作是上班时刷卡。当然，合规率是他们实际刷卡的次数/他们预期刷卡的次数。
我有三个日期组要比较，但它们的长度各不相同，因为我们试图展示 COVID 期间和之后的合规性。每四个月测量一次数据，因此一年有三个 AP，从 11 月开始：

AP 1：11 月 1 日至 3 月 31 日
AP 2：4 月 1 日至 6 月 30 日
AP 3：7 月 1 日至 10 月 31 日

我正在观察 2018 年 11 月至 2022 年 10 月的数据，拆分如下：
日期组 1（COVID 之前，基线/对照）：

AP-1，2018 年 11 月 - 2019 年 3 月 31 日
AP-2，2019 年 4 月 1 日 - 2019 年 6 月 30 日
AP-3，2019 年 7 月 1 日 - 2019 年 10 月 31 日
AP-1，11 月 1 日2019 年 - 2020 年 3 月 31 日 [12 个月，共 4 个时间段]

日期组 2 (COVID)：

AP-2，2020 年 4 月 1 日 - 2020 年 6 月 30 日
AP-3，2020 年 7 月 1 日 - 2020 年 10 月 31 日
AP-1，2020 年 11 月 1 日 - 2021 年 3 月 31 日
AP-2，2021 年 4 月 1 日 - 2021 年 6 月 30 日
AP-3，2021 年 7 月 1 日 - 2021 年 10 月 31 日 [20 个月，共 5 个时间段]

日期组 3 (后疫情时代)：

AP-1，2020 年 11 月 1 日2021 - 2022 年 3 月 31 日
AP-2，2022 年 4 月 1 日 - 2022 年 6 月 31 日
AP-3，2022 年 7 月 1 日 - 2022 年 10 月 31 日 [9 个月，共 3 个时期]

所有类别员工的数据合计如下。



组
AP 代码
刷卡
总计条目
合规性




1
2019-1
1019
1231
0.790


1
2019-2
782
878
0.788


1
2019-3
934
1132
0.793


1
2020-1
973
1151
0.821


2
2020-2
640
749
0.834


2
2020-3
901
1075
0. 810


2
2021-1
952
1122
0.816


2
2021-2
674
807
0.800


2
2021-3
841
1001
0.804


&lt; td&gt;3
2022-1
727
857
0.820


3
2022-2
733
887
0.784


3
2022-3
868
1041
0.801



我想要使用方差分析来查看日期组 1（COVID 之前）与日期组 2 和 3（COVID 和 COVID 之后）之间的合规率是否存在显著差异。使用单向方差分析是解决方案吗？询问是因为我不习惯处理费率，而是“这是花瓣的长度”。如果有帮助的话，使用 R 工作。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649647/one-way-anova-on-compliance-rates-by-time-period-with-different-lengths</guid>
      <pubDate>Fri, 21 Jun 2024 08:33:58 GMT</pubDate>
    </item>
    </channel>
</rss>