<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 06 Jan 2025 12:34:05 GMT</lastBuildDate>
    <item>
      <title>auto_arima() 可以在行为不良的时间序列中使用吗？</title>
      <link>https://stats.stackexchange.com/questions/659612/can-auto-arima-be-used-in-badly-behaved-time-series</link>
      <description><![CDATA[也许我无法正确配置它，但是当将 Python 模块 pmdarima 的 auto_arima() 函数应用于表现不佳的时间序列（例如来自加密货币的 OHLC 数据的时间序列）时，我遇到了非常糟糕的体验。
您能否为我提供使用它的指南？由于 pmd_arima 大量借鉴了 Hyndman 在 R 中的 forecast 代码，我阅读了它的 vignette，似乎整个算法最适合 (p, d, q) 分量的低值。]]></description>
      <guid>https://stats.stackexchange.com/questions/659612/can-auto-arima-be-used-in-badly-behaved-time-series</guid>
      <pubDate>Mon, 06 Jan 2025 12:11:24 GMT</pubDate>
    </item>
    <item>
      <title>解释 R 中零膨胀模型的均值预测：为什么零膨胀均值与原始均值不同？</title>
      <link>https://stats.stackexchange.com/questions/659607/interpreting-mean-predictions-from-zero-inflated-models-in-r-why-do-zi-adjusted</link>
      <description><![CDATA[我使用以下代码在 R 中拟合零膨胀模型：glmmTMB(score ~ year - 1 + (1 | farm), ziformula = ~ year - 1, data = data, family = &quot;nbinom2&quot;)
为了提取我的分数的平均预测值，我使用以下方法：

对于&quot;true&quot;零：exp(fe_mod4$cond)
包括零膨胀公式：exp(fe_mod4$cond) * (1 - plogis(fe_mod4$zi))
直接从样本计算的原始均值，没有任何模型。

结果均值如下：
年份 原始均值 均值（不含 ZI） 均值（含 ZI）
1 0.5 1.1 0.4
2 0.9 1.6 0.6
3 0.6 1.4 0.4
4 0.4 1.2 0.4
5 0.5 1.5 0.4

问题：

为什么用零膨胀 (ZI) 公式计算的均值与原始均值非常相似样本均值？
为什么使用 ZI 公式和不使用 ZI 公式计算出的均值之间存在很大差异？这是否表明背景效应导致模型（不使用 ZI）没有考虑到过多的零值？
为什么我们对没有零膨胀 (ZI) 部分的结果感兴趣？
如果 ZI 调整后的预测与原始数据均值非常相似，那么我们为什么需要这个模型，使用 ZI 公式进行预测的目的是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/659607/interpreting-mean-predictions-from-zero-inflated-models-in-r-why-do-zi-adjusted</guid>
      <pubDate>Mon, 06 Jan 2025 09:09:38 GMT</pubDate>
    </item>
    <item>
      <title>估计量的偏差是否取决于观测值的数量？预期值的实际解释</title>
      <link>https://stats.stackexchange.com/questions/659603/can-the-bias-of-an-estimator-depend-on-the-number-of-observations-practical-int</link>
      <description><![CDATA[这里表示
$\hat{\theta}=\frac{1}{n} \sum x_i + \frac{1}{n}$
是样本均值的有偏估计量。
我们来看看：
\begin{align}
\mathbb{E}(​​\hat{\theta}) &amp;= \frac{1}{n} \sum \mathbb{E}(​​x_i) + \frac{1}{n} \\
&amp;= \frac{1}{n} \sum \mu + \frac{1}{n} \\
&amp;= \frac{n \cdot \mu}{n} + \frac{1}{n} \\
&amp;= \mu + \frac{1}{n} \\
\end{align&gt;
因此偏差是观察次数的函数。
我觉得这很奇怪。
以下是我对如何计算$\mathbb{E}(​​\hat{\theta})$的直觉。
我们从总体中抽取一个大小为$n_1$的样本。称之为$x^{(1)} \in \mathbb{R}^{n_1}$。
我们应用函数来计算平均值$\hat{\theta}^{(1)}$的估计值。
在这种情况下$\hat{\theta}^{(1)}=\frac{1}{n} \sum x^{(1)}_i + \frac{1}{n}$。
我们从总体中抽取另一个样本，大小为$n_2$。称之为$x^{(2)} \in \mathbb{R}^{n_2}$。
我们应用我们的函数来计算平均值$\hat{\theta}^{(2)}$的估计值。
我们从总体中抽取另一个样本，大小为$n_3$。称之为$x^{(3)} \in \mathbb{R}^{n_3}$。
我们应用我们的函数来计算平均值$\hat{\theta}^{(3)}$的估计值。
我们以此方式进行无数次。
然后我们取所有这些估计值的平均值（期望值）。
$\mathbb{E}(​​\hat{\theta}) = (\hat{\theta}^{(1)}+\hat{\theta}^{(2)}+\hat{\theta}^{(3)}+\cdots+\hat{\theta}^{(N)})/N$
根据这种解释，期望值取决于观察次数似乎很奇怪。
观察次数是多少？我是否必须有同样大小的样本？
编辑：我发现，由于我的估计量本身是观察次数的函数，因此其预期值是观察次数的函数也就不足为奇了。然后我必须固定 $n$，因此样本大小相同（也就是说，更改 $n$ 会改变估计量）。
不过，由于我进行了无限次采样，因此预期值取决于样本大小感觉很奇怪。]]></description>
      <guid>https://stats.stackexchange.com/questions/659603/can-the-bias-of-an-estimator-depend-on-the-number-of-observations-practical-int</guid>
      <pubDate>Mon, 06 Jan 2025 07:53:24 GMT</pubDate>
    </item>
    <item>
      <title>$|μ| \gg σ$ 的 Delta 方法近似条件</title>
      <link>https://stats.stackexchange.com/questions/659598/condition-for-delta-method-approximation-for-%ce%bc-gg-%cf%83</link>
      <description><![CDATA[我试图理解当 $|μ|$ 远大于 $σ.$ 时 Delta 方法近似的数学依据。具体来说，我正在寻找以下公式的证明：
$$ E[g(X)] \approx g(\mu) + \frac{1}{2}g&#39;&#39;(\mu)\sigma^2 $$
$$ \operatorname{Var}[g(X)] \approx (g&#39;(\mu))^2\sigma^2 $$
其中 $X$ 是均值为 $μ$ 的随机变量和标准偏差 $σ,$ 和 $g$ 是一种变换。
我不确定获取这些简化形式所涉及的具体步骤和假设。
我有一些问题：
条件 $|μ| \gg σ$ 是如何正式定义或量化的？我的讲义中提到了这个条件。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659598/condition-for-delta-method-approximation-for-%ce%bc-gg-%cf%83</guid>
      <pubDate>Mon, 06 Jan 2025 03:46:26 GMT</pubDate>
    </item>
    <item>
      <title>减少 MLP 过度拟合以提高特征重要性</title>
      <link>https://stats.stackexchange.com/questions/659597/reducing-mlp-overfitting-for-feature-importance</link>
      <description><![CDATA[我正在一个数据集上训练 MLP，数据集的特征数量 &gt;&gt; 样本数量。出于某些原因，至少有一个隐藏层的 MLP 是我唯一考虑的架构。毫不奇怪，即使是最简单的 MLP，我也会出现严重的过度拟合（训练 AUROC 很快达到 1）。
我的 Xs 也不太能描述 ys：即使我有无限数量的样本，我也不会期望超过测试 AUROC ~0.7。
我的目标不是训练一个好的预测模型，而是训练最好的模型，然后在下游分析中研究最重要的特征。由于我正在处理特征重要性，因此对我来说，尽可能减少过度拟合至关重要。
问题是：l1/l2 正则化和 dropout 等标准技术是否允许尽可能减少过度拟合，还是它们的能力有限？我不介意包含具有非常高丢失概率的丢失层，但我真的想避免必须考虑更少的特征。我知道提前停止，但我真的不想在一个时期后停止。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659597/reducing-mlp-overfitting-for-feature-importance</guid>
      <pubDate>Mon, 06 Jan 2025 03:13:45 GMT</pubDate>
    </item>
    <item>
      <title>除了单纯形之外，狄利克雷分布还有哪些其他支持的推广形式？</title>
      <link>https://stats.stackexchange.com/questions/659565/is-there-any-generalization-of-the-dirichlet-distribution-to-supports-other-than</link>
      <description><![CDATA[让我们考虑$(\theta_1,\theta_2,\ldots,\theta_k) \sim \operatorname{Dirichlet}(a_1,a_2,\ldots,a_k)$。我想知道我们是否还有$\theta_1 &gt; \varepsilon_1, \theta_2 &gt; \varepsilon_2,\ldots,\theta_k &gt; \varepsilon_k,$ 其中 $\varepsilon_i \geq 0, \forall i \in \{1,2,\ldots,k\}$ 是已知常数。
是否有任何已知的分布或封闭的解析形式？
我曾尝试通过条件概率计算来发展这个想法，但这有点具有挑战性。]]></description>
      <guid>https://stats.stackexchange.com/questions/659565/is-there-any-generalization-of-the-dirichlet-distribution-to-supports-other-than</guid>
      <pubDate>Sun, 05 Jan 2025 14:41:16 GMT</pubDate>
    </item>
    <item>
      <title>加权可能性间接模拟可靠性？</title>
      <link>https://stats.stackexchange.com/questions/659550/weighted-likelihood-to-indirectly-model-reliability</link>
      <description><![CDATA[对于纵向回归问题，我可能认为，与信息较少的受试者相比，我观察到的具有更多观察结果的受试者的数据更可靠（情况可能并非总是如此，但假设如此）。这里，可以使用回归权重，以便在模型中考虑到这种感知可靠性吗？

这是针对$i^{th}$主题的基本纵向/随机效应模型：
$$y_{ij} = X_{ij}\beta + u_i + \epsilon_{ij}$$
$$u_i \sim N(0, \sigma^2_u)$$
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon)$$
我看到这种权重格式经常用于最小二乘回归（$n_i$ 是受试者 $i$ 的测量次数，$N$ 是受试者总数):
$$w_i = \frac{n_i}{\sum_{k=1}^N n_k}$$
最后，修改似然函数以包含权重（我不确定哪个更好 - 单个受试者级别权重或单个观察级别权重）：
$$L(\beta, \sigma^2_u, \sigma^2_\epsilon) = \prod_{i=1}^N f(y_i|\beta, \sigma^2_u, \sigma^2_\epsilon)^{w_i}$$
$$L(\beta, \sigma^2_u, \sigma^2_\epsilon) = \prod_{i=1}^N \prod_{j=1}^{n_i} f(y_{ij}|\beta, \sigma^2_u, \sigma^2_\epsilon)^{w_i}$$
从这个来看，似乎即使有了这些权重，这些权重似乎也不会影响方差。使用多层次建模/随机效应中采用的一般方法，也许可以将方差修改为（$I$ 是一个单位矩阵，而$J$ 是一个 1 的矩阵 - 这意味着单个受试者的方差取决于所有受试者的未加权方差加上基于该受试者测量次数的单个受试者的加权方差）。这样做，我们实际上在个体层面上将随机效应引入模型：
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon / n_i)$$
$$Var(y_i) = \sigma^2_u J_{n_i} + (\sigma^2_\epsilon/n_i) I_{n_i}$$
$$Y_i \sim MVN(X_i\beta, V_i)$$
这现在使得可能性（更复杂 - 但最小二乘解可用于固定效应估计）：
$$f(y_i|\beta, \sigma^2_u, \sigma^2_\epsilon) = (2\pi)^{-n_i/2}|V_i|^{-1/2}\exp\left(-\frac{1}{2}(y_i - X_i\beta)^T V_i^{-1}(y_i - X_i\beta)\right)$$
$$\ell(\beta, \sigma^2_u, \sigma^2_\epsilon) = -\frac{1}{2}\sum_{i=1}^N \left[n_i\log(2\pi) + \log|V_i| + (y_i - X_i\beta)^T V_i^{-1}(y_i - X_i\beta)\right]$$
$$\hat{\beta} = \left(\sum_{i=1}^N X_i^T V_i^{-1} X_i\right)^{-1} \left(\sum_{i=1}^N X_i^T V_i^{-1} y_i\right)$$
我可以看到，在这个最终设置中，固定效应估计和方差都受到每个受试者可用的观察次数的影响。 （下一部分超出了我的理解范围，但我听说随机效应是使用 RMLE 估计的）

假设数学是正确的，在纵向研究中，基于每个受试者可用的测量次数的权重可以用来隐式地解释可靠性？
结束语：最后，看起来只需使用基本的多级建模方法就可以解决所有问题，并根据每个受试者的观察次数间接地考虑他们的贡献……]]></description>
      <guid>https://stats.stackexchange.com/questions/659550/weighted-likelihood-to-indirectly-model-reliability</guid>
      <pubDate>Sun, 05 Jan 2025 03:44:55 GMT</pubDate>
    </item>
    <item>
      <title>识别与平方根过程相关的随机过程的分布</title>
      <link>https://stats.stackexchange.com/questions/659526/identifying-the-distribution-of-a-random-process-associated-to-the-square-root-p</link>
      <description><![CDATA[让 $x(t)$ 成为遵循以下的随机平方根过程
$$dx(t) = (a + bx(t)) \, dt + c\sqrt{x(t)} \, dW(t)$$
其中 $W(t)$ 是某些过滤的标准布朗运动。
它有很多名字，但出于本文的目的，我不会提及它们。如果我们定义
$$ \varphi(u;t,h) = \mathbb E\left( e^{u x(t+h)} \mid x(t) \right); \quad u\in \mathbb C$$
那么我可以证明对于 $\Re(u) \leqslant 0$，我们有
$$
\mathbb E(e^{u x(t+h)} \mid x(t) = x ) = 
\frac{1}{\left(1- 2z(h)u
\right)^{\frac k2}}\exp\left(
\dfrac{\lambda(t)x\cdot z(h)u }{1- 2z(h)u}
\right) $$
其中 $z(h) = q(h)e^{bh}\frac{c^2}{4}$，$q(h) = \dfrac{1-e^{-bh}}{b}$，$\lambda(h) = \frac{4q(h)^{-1}}{c^2}$ 和 $k = \frac{4a}{c^2}$。因此，在 $x(t)$ 条件下，我们有
$$
z(h)^{-1} x(t+h) \sim \chi_k^2(\lambda(h)^{-1}x(t))
$$
其中右边是非中心卡方分布，具有 $k$ 自由度和非中心参数 $\lambda = \lambda(h)^{-1}x(t)$。具体来说，我们可以让 $c=2$ 和 $b\to 0$ 恢复平方贝塞尔过程满足
$$
h^{-1} x(t+h) \sim \chi_k^2(h^{-1}x(t))
$$
这是众所周知的。

现在考虑联合过程$y(t) = \left( \int_0^t x(s) \, ds, x(t) \right)$。然后，我可以证明联合条件特征函数
$$\varphi(u;t,h) = 
\mathbb E\left( e^{u\cdot y(t+h)}\mid y(t) \right); \quad u\in \mathbb C^2 
$$
对于 $y(t) = (y_1, y_2)$ 等于
$$ \varphi(u;t,h) = \frac1 {\left(1- 2z \right)^{\frac k2}}
\exp\left(\dfrac{ \lambda z}
{1- 2 z}y_2 + v y_2\right)\exp(u_1 y_1 + ah v(u_1))
$$
其中 $v(u_1)$ 是 $\frac 12 c^2 v^2 + bv = u_1$ 的解，并且
\begin{align*}
z(h,u) &amp;= (u_2 - v(u_1))e^{(b + v(u_1) c^2)h} \lambda^{-1}(h,u) \\
\lambda(h,u) &amp;= \frac{4}{c^2}q_0(h,u)^{-1} \\
q_0(h, u) &amp;= \dfrac{1-e^{-(b + v(u_1)c^2)h}}{b + v(u_1)c^2} 
\end{align*&gt;
一个明显的检查是，如果 $u_1=0$ 那么我们可以连续选取 $v(u_1)=0$ 并且那么特征函数就是 $x(t)$，正如它应该的那样。
但是，我无法识别这个联合分布。我最天真的猜测是，它可能是广义卡方分布，如这里，但我没有取得太大进展。
有人知道该怎么做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659526/identifying-the-distribution-of-a-random-process-associated-to-the-square-root-p</guid>
      <pubDate>Sat, 04 Jan 2025 12:28:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 GEE 和 GLMM 分析离散数据中的相关性</title>
      <link>https://stats.stackexchange.com/questions/659520/analyzing-correlation-in-discrete-data-with-gee-and-glmm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659520/analyzing-correlation-in-discrete-data-with-gee-and-glmm</guid>
      <pubDate>Sat, 04 Jan 2025 06:01:42 GMT</pubDate>
    </item>
    <item>
      <title>为每个受试者建模累积率</title>
      <link>https://stats.stackexchange.com/questions/659518/modelling-cumulative-rates-per-subject</link>
      <description><![CDATA[有多个受试者，每个受试者都有多个观察结果（每次测量时都会观察到连续的预测因子，并观察到 ​​0/1 的响应）。纵向回归可用于对每个受试者的（演变）累积率进行建模吗？

例如：对于每个受试者 $i$ 和时间点 $t$，观察一个二元结果 $Y_{it}$（0 或 1）和一个预测因子向量 $X_{it}$。累积率 $R_{it}$ 是截至时间 $t$，对于主题 $i$，积极响应的比例：
$$R_{it} = \frac{\sum_{s=1}^t Y_{is}}{t}$$
基本逻辑回归：
$$\text{logit}(E[R_{it}|X_{it}, b_i]) = X_{it}^\top \beta + \gamma t + b_i$$
其中：

$\beta$是固定效应系数
$b_i$ 是主题 $i$ 的随机效应，例如 $b_i \sim N(0, \sigma_b^2)$
主题级别的相关性：$\text{Corr}(R_{it}, R_{is}) = \rho^{|t-s|}$

我想也许可以使用 Beta 分布回归，但它有点超出我的理解范围，我想保持简单。但我认为由于 Beta 分布模拟比例响应，它也可能合适。
有什么想法？]]></description>
      <guid>https://stats.stackexchange.com/questions/659518/modelling-cumulative-rates-per-subject</guid>
      <pubDate>Sat, 04 Jan 2025 03:52:05 GMT</pubDate>
    </item>
    <item>
      <title>理解因果关系中的定义 2.7.3（虚假关联）——Judea Pearl</title>
      <link>https://stats.stackexchange.com/questions/659424/understanding-definition-2-7-3-spurious-association-in-causality-by-judea-pear</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659424/understanding-definition-2-7-3-spurious-association-in-causality-by-judea-pear</guid>
      <pubDate>Wed, 01 Jan 2025 19:41:38 GMT</pubDate>
    </item>
    <item>
      <title>“AUROC 曲线”这个术语实际上是否正确且有意义？</title>
      <link>https://stats.stackexchange.com/questions/659370/is-the-term-auroc-curve-actually-correct-or-meaningful</link>
      <description><![CDATA[15 年前，当我进入机器学习领域时，我了解到 AUC 代表“曲线下面积”，即“ROC 曲线下面积”，而 ROC 是“接收者操作特性”。
现在我自己在指导学生，（当然）他们有时会根据他们首先阅读的文献和资料使用不同的术语。我听说过 AUROC，根据这里的一些观点，它比 AUC 更好，因为后者没有指定指的是哪条曲线，而且除了 ROC 之外还有其他可能。
但后来我读到 AUROC 曲线，它在很多层面上听起来都是错误的。 （我不是以英语为母语的人。）
您指的是曲线下的面积，即 AUC 或 AUROC，或曲线本身，即ROC 曲线，因此 AUROC 曲线对我来说真的没有意义。但是，通过 CV 搜索我发现它被使用了几次，但从未被更正或解决，例如

为什么 ROC 曲线和 AUC 值并不总是相关的？
如何解释抵押贷款拒绝/批准的 AUROC 曲线？
如何解释 AUROC分数？

所以，我的问题是：我在这里是对的还是过于迂腐？还是忽略了一些显而易见的东西？
澄清：
似乎我的问题含糊不清，我应该澄清：
我的问题是使用术语“AUROC 曲线”来表示曲线，而不是值，例如

对于随机分类器，AUROC 曲线将是一条从 [0,0] 到 [1,1] 的对角线
]]></description>
      <guid>https://stats.stackexchange.com/questions/659370/is-the-term-auroc-curve-actually-correct-or-meaningful</guid>
      <pubDate>Mon, 30 Dec 2024 15:26:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 G*Power 进行样本量估计</title>
      <link>https://stats.stackexchange.com/questions/654196/sample-size-estimation-using-gpower</link>
      <description><![CDATA[我正在尝试使用 G*Power 为一个我打算做的项目计算先验样本量。我将在两个时间点（T1、T2）收集两组参与者的反应时间数据。实验将是一个简单的非语言 Stroop 任务，包含三个实验条件（带有情绪面孔 - 快乐、愤怒、中性）和一个控制条件（无情绪面孔）。将在 T1 和 T2 时比较各组，并在两个时间点进行组内比较。将在 T1 和 T2 时比较各组，并在两个时间点进行组内比较。
我如何估计每个组的样本量？在这种情况下，组数和测量次数是多少？
G*Power 能够进行这种估计吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654196/sample-size-estimation-using-gpower</guid>
      <pubDate>Wed, 11 Sep 2024 08:48:36 GMT</pubDate>
    </item>
    <item>
      <title>“不可预测”的定义</title>
      <link>https://stats.stackexchange.com/questions/620271/definition-of-unpredictable</link>
      <description><![CDATA[在点和密度预测的情况下，我们如何严格定义术语“不可预测”？
术语“不可预测”用于各种上下文，例如

“抛一枚公平硬币的结果是不可预测的”，
“随机游走的增量是不可预测的”或
“在信息有效的市场中，价格变化是不可预测的”。

这些陈述并非完全正确，因为人们总是可以提供预测，无论预测多么不准确。我可以做出点数预测（硬币将出现正面；增量为 0.18879；价格变化为 0.12 英镑）或密度预测（$P(\text{heads})=0.51$，增量为 N(0,0.4)，价格变化为 ...）。
直观地说，“不可预测”意味着“无法比一些简单/朴素/自然的基准更准确地预测”，例如“抛硬币的最佳密度预测是 $P(\text{heads})=0.5$”。但随后我们需要定义“最佳”的含义在评估密度预测时。
那么，我们如何严格定义“不可预测”一词？
关键词：不可预测、不可预测、可预测性、可预测性。]]></description>
      <guid>https://stats.stackexchange.com/questions/620271/definition-of-unpredictable</guid>
      <pubDate>Sat, 01 Jul 2023 18:56:43 GMT</pubDate>
    </item>
    <item>
      <title>具有拟二项分布的 GLM 的样本大小</title>
      <link>https://stats.stackexchange.com/questions/593304/sample-size-for-glm-with-quasi-binomial-distribution</link>
      <description><![CDATA[我的数据表示具有催化活性的总酶的百分比。类似于总量的相对单位。数据中填充了零（即未检测到活性）
我有 4 组，每组 6 名患者。（即总共有 24 个观察值，其中活性酶的百分比）
我发现对于百分比数据，我可以使用具有拟二项分布的 GLM，并根据年龄、性别等校正分析。
我担心样本量太小或每组只有 6 个观察值？
在这种情况下，可以使用具有拟二项分布的 GLM 吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/593304/sample-size-for-glm-with-quasi-binomial-distribution</guid>
      <pubDate>Sun, 23 Oct 2022 14:50:34 GMT</pubDate>
    </item>
    </channel>
</rss>