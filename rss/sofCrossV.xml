<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 26 Dec 2023 15:13:42 GMT</lastBuildDate>
    <item>
      <title>使用核密度估计来估计分布之间的距离</title>
      <link>https://stats.stackexchange.com/questions/635658/the-usage-of-kernel-density-estimate-for-distance-between-distributions</link>
      <description><![CDATA[Scipy 的 kde 对象允许集成一个函数乘以另一个 KDE。我认为这意味着用于估计两个分布之间的距离。据我了解，为了保持一致的度量，在积分之前需要平方根，类似于巴塔查里亚距离的定义。那么，这个输出是什么？我可以用它来测量分布之间的距离吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635658/the-usage-of-kernel-density-estimate-for-distance-between-distributions</guid>
      <pubDate>Tue, 26 Dec 2023 14:21:51 GMT</pubDate>
    </item>
    <item>
      <title>排除和不排除单个观测值的 OLS 解</title>
      <link>https://stats.stackexchange.com/questions/635657/solution-of-ols-with-and-without-excluding-a-single-observation</link>
      <description><![CDATA[在普通最小二乘法 (OLS) 中，输入矩阵 $X$ 的最佳拟合解（大小 $p \次 N$ -- N 个样本和 p 个特征）和输出向量 $y$ （大小为 $N $) 是
$\hat \beta = (X^T X)^{-1} X^T y$。
现在假设我从矩阵 $X$ 中排除行 i 以及相应的 $y $，即从观察结果中排除一个样本。我们将新数量称为 $X_{-i}$ 和 $y_{-i}$ 并求解再次求解 OLS 问题，并类似地将新解决方案命名为 $\hat \beta _{-i}$。
我的问题是这两个解决方案之间是否有任何关系？我可以从 $\hat \beta $ 到 $\hat \beta _{-i}$ 通过某个公式？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/635657/solution-of-ols-with-and-without-excluding-a-single-observation</guid>
      <pubDate>Tue, 26 Dec 2023 13:20:08 GMT</pubDate>
    </item>
    <item>
      <title>为什么数据中的不同值会极大地影响PCA和模型的训练</title>
      <link>https://stats.stackexchange.com/questions/635653/why-different-values-in-the-data-greatly-affect-the-pca-and-the-training-of-the</link>
      <description><![CDATA[我有与目标关联的稀疏数据，这是模拟数据的代码
make_feature &lt;- function(target, null_var=0){
  v &lt;-rep(null_var, length(target))
  j &lt;- 样本（长度（目标），1）
  v[j] &lt;- 目标[j]
  v
}

库（矩阵）
库（随机森林）
设置.种子(2)

目标 &lt;- 样本(c(1,2),50,替换 = T)
数据 &lt;- sapply(1:200,\(x) make_feature(target))

稀疏数据&lt;-矩阵（数据，稀疏= TRUE）

...
&lt;前&gt;&lt;代码&gt;稀疏数据

[42，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[43，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[44，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 2. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[45，]。 。 。 。 。 。 。 1. 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[46，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[47，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 2. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[48，]。 。 。 。 。 2. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[49，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 2. 。 。 。 2. 。 。 。 ......
[50，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......

然后我进行 PCA 并训练模型
pca_sparse_data &lt;- prcomp(sparse_data)$x

时间 &lt;- 1:40
时间 &lt;- 41:50

rf &lt;- randomForest(as.factor(target[tr])~., data=pca_sparse_data[tr,], ntree=100)

模型运行良好
cbind.data.frame(orig = target[ts],
                  pred = 预测(rf, pca_sparse_data[ts,]))


   原始预测
1 1 1
2 1 1
3 1 1
4 2 2
5 1 1
6 1 1
7 2 2
8 2 2
9 2 2
10 1 1

但是当我稍微用其他值替换数据中的值时，模型就会停止工作
new_sparse_data &lt;-稀疏数据

new_sparse_data[sparse_data==1] &lt;- -1
new_sparse_data[sparse_data==2] &lt;- 1

..
&lt;前&gt;&lt;代码&gt;new_sparse_data

[42，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 -1。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[43，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[44，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[45，]。 。 。 。 。 。 。 -1。 。 。 。 。 -1。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[46，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[47，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[48，]。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[49，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 1. 。 。 。 ......
[50，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 -1。 。 。 。 。 。 。 。 -1。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......

训练新模型
new_pca_sparse_data &lt;- prcomp(new_sparse_data)$x
 new_rf &lt;- randomForest(as.factor(target[tr])~., new_pca_sparse_data[tr,], ntree=100)
 cbind.data.frame(orig = target[ts],
                  pred = 预测(new_rf, new_pca_sparse_data[ts,]))


   原始预测
1 1 1
2 1 1
3 1 2
4 2 2
5 1 1
6 1 2
7 2 2
8 2 1
9 2 2
10 1 2

为什么新模型的表现如此差？]]></description>
      <guid>https://stats.stackexchange.com/questions/635653/why-different-values-in-the-data-greatly-affect-the-pca-and-the-training-of-the</guid>
      <pubDate>Tue, 26 Dec 2023 11:45:53 GMT</pubDate>
    </item>
    <item>
      <title>OLS 估计量中受控变量的确切含义</title>
      <link>https://stats.stackexchange.com/questions/635649/exact-meaning-of-controlled-variables-in-terms-of-the-ols-estimators</link>
      <description><![CDATA[考虑一个二回归量线性回归模型：
$$Y=\beta_0+\beta_1X+\beta_2D+u$$
其中 $X$ 是连续的，$D$ 是二进制的。
在这种情况下，我们说我们已经控制了$D$。
在这里，我想知道“控制”的确切含义。
在提出我的想法之前，请考虑三个估计器。
首先，让 $\widehat{\beta}_1$ 为使用上述二回归模型的 OLS 估计器。
其次，让 $\widehat{\beta}_{11}$ 和 $\widehat{\beta} _{10}$ 是仅使用 $D=1$ 和 $D 样本的 OLS 估计器=0$，分别基于
$$Y=\alpha_0+\alpha_1X+e$$
如果 $\widehat{\beta}_1$ 是 $\widehat{\beta}_ 的加权平均值{11}$ 和 $\widehat{\beta}_{10}$，术语“受控”非常有效，因为 $\widehat{\beta}_{11}$ 和 $\widehat{\beta}_{ 10}$ 是在控制 $D$ 时估算的。
但是，我不确定这个想法是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/635649/exact-meaning-of-controlled-variables-in-terms-of-the-ols-estimators</guid>
      <pubDate>Tue, 26 Dec 2023 10:33:53 GMT</pubDate>
    </item>
    <item>
      <title>使用 t 统计量调查​​高于机会的测试性能</title>
      <link>https://stats.stackexchange.com/questions/635645/investigating-above-chance-test-performance-using-t-statistics</link>
      <description><![CDATA[我正在阅读一篇研究论文，遇到一种情况，研究人员调查参与者的测试表现是否高于偶然性。我很好奇如何以及为何进行这种类型的分析，如果有人能提供一些解释，我将不胜感激。
在这种情况下，126 名参与者被分为两组。每个小组都接受不同类型的语言训练。然后，两组完成相同的后测试，其中包括六个目标测试项目（加上一些干扰项）。对于每个目标测试项目，参与者看到两张图片，他们必须选择与测试者所说的句子相匹配的图片。测试者说出的六个句子中，三个句子包含训练中出现的动词，另外三个句子包含新动词。参与者完成此后测试两次，或分两个部分（训练课程 1 —&gt; 后测试 1 —&gt; 培训课程 2 —&gt; 后测试 2）。然后将测试分数提交给 2x2x2 方差分析，将训练条件作为主体间因素，将动词类型（训练与新颖）和块（1 与 2）作为主体变量内的变量。
在描述方差分析结果后，研究人员报告说，对于包含块一中两个条件的训练动词的句子，参与者选择的目标图片明显多于预期，t(120) = 3.7, p &lt; .001，块 2，t(120) = 8.5，p &lt; .001.此外，对于新颖的句子，这两个条件的表现均高于第二个块中的机会水平，t(120) = 4.1，p &lt; 4.1。 .001，但不在第一个块中，t(120) = 1.8，p = .07。
研究人员表示，上述几率大于 50%。
我的问题是：

如何对这样的超概率测试性能进行分析？我猜研究人员使用了 SPSS，尽管没有直接说明。我是否需要在 SPSS 中输入任何值，或者是否需要选择特定命令来对 8 个条件 (2x2x2) 中的每一个执行此类分析？

鉴于已经使用方差分析分析了感兴趣的变量（训练类型、动词类型和块）对分数的影响，调查测试表现是否高于机会的目的可能是什么像这样的研究吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/635645/investigating-above-chance-test-performance-using-t-statistics</guid>
      <pubDate>Tue, 26 Dec 2023 09:20:10 GMT</pubDate>
    </item>
    <item>
      <title>当基于树的模型通常比线性模型效果更好时，为什么我们要使用线性模型？</title>
      <link>https://stats.stackexchange.com/questions/635642/why-do-we-use-linear-models-when-tree-based-models-often-work-better-than-linear</link>
      <description><![CDATA[在监督机器学习中，特别是在 Kaggle 中，通常会发现树模型通常优于线性模型。即使在基于树的模型中，通常 XGBoost 的性能也优于 RandomForest，而 RandomForest 的性能又优于 DecisionTrees。
如果这不是真的，那么请随时纠正这个假设。
这些只是我的观察，不知何故，很多人都同意这个观点。
为什么我们应该使用线性模型，例如线性回归或逻辑回归？具体来说，什么时候它们的性能不如基于树的模型，并且比基于树的模型有更多的要求？
对于基于树的模型，可以提出关于使用 DecisionTrees 而不是 RandomForest 或 XGBoost 的类似问题。
在某些情况下应该首选线性模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635642/why-do-we-use-linear-models-when-tree-based-models-often-work-better-than-linear</guid>
      <pubDate>Tue, 26 Dec 2023 06:59:42 GMT</pubDate>
    </item>
    <item>
      <title>相关系数公式是怎么推导出来的？</title>
      <link>https://stats.stackexchange.com/questions/635637/how-was-the-correlation-coefficient-formula-derived</link>
      <description><![CDATA[免责声明：我不是数学家或统计学家，但我现在正在学习统计学，而且我只有大学代数背景。
相关系数公式如何生成 -1 到 1 之间的值，给我留下了深刻的印象，并且想知道这个方程是如何导出的。怎么有人坐下来说“我只想要 -1 到 1 之间的值”？并得出这个方程（或者什么样的数学逻辑序列可以使最终形式变得明显）。
我理解方程的每个单独组成部分，并且我有一种直觉，答案在于分子和分母项之间的运算顺序（例如，在分子求和之前发生的项相乘），但是我真是难住了。]]></description>
      <guid>https://stats.stackexchange.com/questions/635637/how-was-the-correlation-coefficient-formula-derived</guid>
      <pubDate>Tue, 26 Dec 2023 05:18:21 GMT</pubDate>
    </item>
    <item>
      <title>阐明称为“内核”或“贝叶斯”的各种回归方法之间的差异</title>
      <link>https://stats.stackexchange.com/questions/635574/clarifying-the-difference-between-various-regression-methods-called-kernel-or</link>
      <description><![CDATA[我想了解四种回归类型之间的成对关系：贝叶斯线性回归、高斯过程回归、核回归 (Nadaraya-Watson) 和核岭回归。我在阅读机器学习的高斯过程这本书时遇到了所有这些问题，并且想要一种清晰简洁的方法来区分它们。
这是我目前的理解，欢迎指正。贝叶斯线性回归处理 $\hat{\beta}$ 回归系数（通常设置为 OLS 最优估计器 $\hat{\beta}= (X^TX)^{-1}X^T y$) 作为随机变量，其分布是先验（我们选择的）的函数，并且数据（这鼓励它采用上面的 OLS 形式，如果这是我们的损失函数）。高斯过程回归只是贝叶斯线性回归，其中函数的先验是高斯过程（它是由均值函数和协方差函数定义的函数空间上的分布）。
然后，我对核回归的理解是，核是一个“相似度函数”。数据点之间，因此形式为 $\hat{y}(x) = \frac{\sum_i K(x, x_i)y_i}{\sum_i K(x, x_i)}$ 作为加权平均值似乎使用起来很直观。但是内核 ridge 回归给出了形式为 $K_{x, X}(K_{X,X} + \lambda I)^{- 的估计量1}y$。这似乎与带有岭罚分的传统核回归（N-W 类型）不同。此外，我看到高斯过程回归输出与其“后验平均值”相同的估计量。现在 $K$ 是协方差内核，因此 GPR（这是 BLR 的特殊情况？）相当于 KRR？
这四个简单方法之间的关系我不清楚。非常感谢一些澄清，谢谢。技术细节越多越好。]]></description>
      <guid>https://stats.stackexchange.com/questions/635574/clarifying-the-difference-between-various-regression-methods-called-kernel-or</guid>
      <pubDate>Sun, 24 Dec 2023 08:26:18 GMT</pubDate>
    </item>
    <item>
      <title>曼惠特尼测试中获得 U 的概率证明</title>
      <link>https://stats.stackexchange.com/questions/635572/proof-of-probability-of-obtaining-u-in-mann-whitney-test</link>
      <description><![CDATA[我试图了解 U 的概率公式是如何计算的 论文，第 4 节中的公式 1。

详情：
假设我们有两组 A 和 B，每组分别包含 m 和 n 个样本。 U 计算 A 中的成员领先于 B 中的成员（排名高于）的次数。 $\bar{p}_{\text{nm}}(U)$ 是其中有 m 个 A 和 n 个 B 的序列数，其中每个 A 的成员先于（排名高于）B 的成员 U 次。那么 $\bar{p}_{\text{nm}}(U)$ 的递归公式如下：

1]有人可以帮我推导出上述内容吗？
此外，在比较A和B是否表现相同的测试时，获得$\bar{p}_{\text{nm}}(U)的概率$ 在 A 和 B 表现相同的原假设下由 ${p}_{\text{nm}}(U)$ 给出，其中其递归公式如下：

2]有人可以帮我推导出上述内容吗？
谢谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/635572/proof-of-probability-of-obtaining-u-in-mann-whitney-test</guid>
      <pubDate>Sun, 24 Dec 2023 06:33:31 GMT</pubDate>
    </item>
    <item>
      <title>什么是样品近似硬度的度量？</title>
      <link>https://stats.stackexchange.com/questions/635494/what-is-a-measure-of-hardness-of-approximation-by-samples</link>
      <description><![CDATA[假设有一个很大的实数向量$\mathbf{x}$，我想估计某个聚合函数$f(\mathbf{x})$ 通过从总体中抽取一小部分样本$\mathbf{x}$。我想知道需要多少样本才能获得给定大小（例如 1%）的 95% 置信区间。样本数量可能取决于函数 $f$：较大的数字表示 $f$ 是“通过采样更难近似”。这个样本数的术语是什么？在哪里可以找到有关哪些函数 $f$ 更容易/更难近似的数据？
我想到的一个术语是样本复杂性，但从我看来，它不一样：它测量从给定的函数类别中学习函数所需的训练样本数量。就我而言，函数是固定且给定的，我想知道将函数值估计到给定精度所需的样本数。]]></description>
      <guid>https://stats.stackexchange.com/questions/635494/what-is-a-measure-of-hardness-of-approximation-by-samples</guid>
      <pubDate>Fri, 22 Dec 2023 12:09:45 GMT</pubDate>
    </item>
    <item>
      <title>$E[X|X^3-3X]=0$ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635492/exx3-3x-0</link>
      <description><![CDATA[用 $f(x) 证明 $E[X|X^3-3X]=0$ =\frac{|x^2-1|}{4}$ 是区间 $X$ 的密度函数数学容器&quot;&gt;$[-2,2]$。
我的尝试：
设 $Y=X^3-3X$ 和 $x_1, x_2, x_3$ $x^3-3x=y$ 的根。
\begin{聚集*}
P_{X\circ Y}(A\times B)=P_\Omega(X\in A\cap Y\in B)=\int_{Y\in B}I_A(x)f(x)dx=\\
=\int_B\sum_{i=1}^3I_A(x_i)f(x_i)/|3x_i^2-3|dy=\int_B\frac{\sum I_A(x_i)f(x_i)/|3x_i^2- 3|}{\sum f(x_i)/|3x_i^2-3|}dP_Y
\end{聚集*}
从哪里：
$$P_{X/Y}(y)(A)=P_\Omega[X\in A|Y=y]=\frac{1}{3}\sum I_A (x_i)$$
所以：
$$E[X|Y=y]=\frac{1}{3}\sum x_i=0$$]]></description>
      <guid>https://stats.stackexchange.com/questions/635492/exx3-3x-0</guid>
      <pubDate>Fri, 22 Dec 2023 11:30:22 GMT</pubDate>
    </item>
    <item>
      <title>您是否应该模拟混杂因素对其他混杂因素的影响来测试估计器？</title>
      <link>https://stats.stackexchange.com/questions/635194/should-you-simulate-the-effect-of-confounders-on-other-confounders-to-test-an-es</link>
      <description><![CDATA[想象一下，我正在尝试模拟数据生成过程，其中我对 $Y$ 做出以下假设：
$Y$ = $X$(0.15) + $Z_1$(0.23) + $Z_2$(0.08) + $Z_3$(0.19) + $Z_4$(0.05) + 错误
此外，考虑到我对几个估计器感兴趣，并且我正在尝试找出哪个估计器恢复了 0.15 的定义治疗效果最好。然而，$X$ 被几个变量混淆，所以我相应地调整它们。
我很清楚的是，对于我认为是混杂因素的变量，我需要模拟每个混杂因素对治疗和结果的影响大小。例如，如果 $Z_1$ 对 $Y$ 的影响为 0.23，我还需要在 $X$ 上模拟 0.04 的效果，否则，它不会是一个混杂因素。
然而，在更复杂的数据生成过程中，混杂因素可能会影响其他混杂因素本身的价值。也就是说，将每个混杂因素定义为与其他感兴趣的混杂因素完全外生的分布可能是不合适的。
例如，不要说 $Z_1$ 只是一个平均值为 $\mu 的正态分布变量$ 和标准差 $\sigma$，我也可以说 $Z_2$ 对 $Z_1$ 的影响为 0.33，$Z_3$ 对 $Z_3$ 的影响为 0.07 span class=&quot;math-container&quot;&gt;$Z_1$。
为了实现这个假设模拟的目标（测试不同的估计器，看看哪个估计器能最好地恢复治疗效果），是否有必要定义每个混杂因素对另一个混杂因素的影响？或者，只要我指定每个混杂因素对结果和治疗的影响，模拟分析就可以进行了吗？
一方面，我看到了全面详细说明系统中所有变量的假设数据生成过程的好处。然而，另一方面，我发现我将进一步的假设嵌入到对不感兴趣的效应大小的分析中存在问题（即我没有实际兴趣了解/思考如何 $ Z_3$ 可能会影响 $Z_1$、$Z_2$、$Z_4$ 等）。]]></description>
      <guid>https://stats.stackexchange.com/questions/635194/should-you-simulate-the-effect-of-confounders-on-other-confounders-to-test-an-es</guid>
      <pubDate>Mon, 18 Dec 2023 15:08:33 GMT</pubDate>
    </item>
    <item>
      <title>经验基函数</title>
      <link>https://stats.stackexchange.com/questions/623344/empirical-basis-functions</link>
      <description><![CDATA[初步
考虑 $n$ 个个体，每个个体都有观察到的数据$ Z_i, i = 1, \ldots, n$。对于每个单独的 $i$，纵向预测变量 $Z_i = \{Z_i(t_{i1}), \ldots, Z_i(t_{i,R_i})\}$ 是在有限数量的观测次数下测量的 $t_i = (t_{i1}, \ldots, t_{i ,R_i})$。我们可以将有限网格定义为 $\bigcup_{i=1}^{n} t_i$，覆盖样本的所有唯一观察时间，其中 $\tau = \max (\bigcup_{i=1}^{n} t_i)$。
文章说：
从任意一组平滑基函数开始 $\psi_1(t), \ldots, \psi_K(t)$ 来表征函数预测器，其中 &lt; span class=&quot;math-container&quot;&gt;$K$ 表示基函数的总数。该基函数集合可以是例如通过传统FPCA方法估计的经验基函数，但可以灵活地扩展到其他基函数。然后，函数数据可以用矩阵表示法重写为 $(Z_1(t), \ldots, Z_n(t))^T = \bf{\lambda}\bf{\psi }(t)$，其中 $\bf{\lambda} = (\lambda_1, \ldots, \lambda_n)^T$，其中 $\lambda_i = (\lambda_{i,1}, \ldots, \lambda_{i,K})^T$ 和 $\bf{\psi}(t) = (\psi_1(t), \ldots, \psi_K(t))^T$, $t \in [0，\tau]$。
$\bf{M}$ 的维度为 $K \times K$，其中$(k, k&#39;)$ 条目为 $\langle \psi_k(t), \psi_{k&#39;} ( t) \rangle$ 为 $k, k&#39; \in K$，$t \in [0 , \tau]$.
我的问题：
如您所见，$Z_{i}$ 是不规则且稀疏的。所以，如果我们用矩阵表示法来写它，那么里面就会有 NA。例如，
&lt;前&gt;&lt;代码&gt; ####
  设置.种子(123)
  # 观察数量
  n &lt;- 10
  # 底层函数
  f &lt;- 函数(t) {
    罪恶(t)
  }
  # 生成不规则且稀疏的函数数据
    Z &lt;- 矩阵(NA, nrow = n, ncol = 11)
    for (i in 1:n) {
    # 生成随机观察时间
    R &lt;- 样本（3:10，大小 = 1）
    t &lt;- 排序（样本（0:10，大小=R））
    # 在这些时间对函数进行采样
    y &lt;- f(t) + rnorm(length(t), sd = 0.1) # 添加一些噪音
    
    ＃ 返回
    Z[i, 匹配(t, c(0:10))] &lt;- y
    }
    列名(Z) &lt;- 0:10

所以，我的理解 $\bf{\lambda}$ 是一个矩阵 $n \times K$&lt; /span&gt; 和 $\bf{M}$ 是 $K \times K$。所以，传统 FPCA 方法估计的经验基函数就是特征函数，但如果是这样，我就不能有 $K$ 特征函数随后无法获得系数矩阵 $\bf{\lambda}$ （或分数）即 $n \times K $]]></description>
      <guid>https://stats.stackexchange.com/questions/623344/empirical-basis-functions</guid>
      <pubDate>Sun, 06 Aug 2023 20:56:16 GMT</pubDate>
    </item>
    <item>
      <title>函数主成分分析 - 解释函数主成分分数</title>
      <link>https://stats.stackexchange.com/questions/623201/functional-principal-component-analysis-explaining-functional-principal-compon</link>
      <description><![CDATA[我想知道是否有人可以帮助解释功能主成分分数？
我正在使用一个数据集，该数据集反映了减肥管理试验的参与者（纵向数据）。该数据集包含 1139 名参与者和四个体重观察值（稀疏数据）。整理了四天不同天的体重观察结果。我工作的目标是将函数主成分分析应用于数据集，以揭示体重变化的不同轨迹（轨迹建模）。重量的四次测量被视为功能数据。
在建模过程中，我发现了四种不同的轨迹。 FPC1 占解释方差的 96.59%。 FPC2、2.25% 和 FPC3/FPC4 合计产生 1.15% 的方差。 FPC1 呈现出向上的轨迹，这表明试验期间体重增加。平均函数反映了试验中最初的体重减轻，随后体重持续恢复。下图是主要成分 FPC1 的特征函数图。

观察平均值、相关系数和 FPC 负载，我可以看到平均权重随着时间的推移而增加。相关系数在试验结束时变得更加紧密，并且在 FPC1 中，FPC 负载随着时间的推移而增加。因此，我们可以确定，在试验后期，体重变化造成的变异程度更大。因此表明在试验后期体重会增加。

除此之外，我还为 FPC1 制作了参与者级别的 FPC 分数。这些分数表明参与者水平对 FPC1 中的方差或模式的贡献。在此，我们看到每个参与者的强正分和强负分的证据，从而表明参与者对组件中的模式做出了强烈、积极的贡献。

以参与者 1180 为例，他们在 FPC1 中获得了强正 FPC 分数。这表明它们与 FPC1 中发现的模式密切相关或有贡献。然而，观察它们的功能数据，它们的模式表现出与组件不同的模式。
我对此的评论是，参与者可能在给定组件中得分强烈的积极或消极，但是，如果他们的功能数据与组件的模式不同，这表明个体变异性（独特性）未被变异、异常值、可能的样本量问题和其他问题。我对 FPC 分数的理解是否正确，或者是否有更好的方法来解释强积极参与者和组件模式之间的模式差异？
]]></description>
      <guid>https://stats.stackexchange.com/questions/623201/functional-principal-component-analysis-explaining-functional-principal-compon</guid>
      <pubDate>Fri, 04 Aug 2023 15:18:07 GMT</pubDate>
    </item>
    <item>
      <title>Python 统计模型 logit nan p 值（与 glm 模型相比）</title>
      <link>https://stats.stackexchange.com/questions/611302/python-statsmodel-logit-nan-p-value-vs-glm-model</link>
      <description><![CDATA[我正在使用 Python statsmodel 进行逻辑回归。我正在尝试他们的 glm(family=sm.families.Binomial()) 和 logit() 模型。如果我错了，请纠正我，但从技术上讲，它们应该是相同的型号。
以下是完整的示例代码供参考
glm_model = sm.formula.glm(&quot;Y ~ X1 + X2 + ... + Xn&quot;, family=sm.families.Binomial(), data=df_train).fit()


logit_model = sm.formula.logit(&quot;Y ~ X1 + X2 + ... + Xn&quot;, data=df_train).fit()


所以有两件事

为什么两个模型之间的系数相反？我认为 logit 模型更有意义（在训练数据的背景下），但我很好奇 glm() 函数中是否有我缺少的参数

为什么 logit 模型中的某些系数具有 nan p 值，而 glm 模型则没有？


感谢您的帮助！我通常使用 R，但现在正在转向 Python。如果我在 R 中复制它，它确实会模仿此处 logit 模型的结果，但没有 nan p 值。]]></description>
      <guid>https://stats.stackexchange.com/questions/611302/python-statsmodel-logit-nan-p-value-vs-glm-model</guid>
      <pubDate>Thu, 30 Mar 2023 18:27:44 GMT</pubDate>
    </item>
    </channel>
</rss>