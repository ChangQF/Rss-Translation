<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 19 Apr 2024 00:58:56 GMT</lastBuildDate>
    <item>
      <title>似然比检验的拒绝区域（均匀分布）</title>
      <link>https://stats.stackexchange.com/questions/645350/rejection-region-for-the-likelihood-ratio-test-uniform-distribution</link>
      <description><![CDATA[让 $x_1 ... x_n$ 从均匀分布中采样 $f(x;&amp;theta ;) = (1/θ;), θ; &gt;0, x in [0,θ]$
找到假设的似然函数后：
$H_0 : &amp;theta; = &amp;theta;_0 与 H_A : &amp;theta; \neq &amp;theta;_0$
到目前为止我发现比率测试是
$Λ_θ = (\bar{X}/θ_0)^n$ 其中 $\bar{X}$ 是 x 采样的最大值。
如果我不尝试定义拒绝区域，我会稍微迷失，我是否定义与此比率测试相关的 c 或将其定义为 X 估计值的函数？我仍然对统计数据有疑问，在此先感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/645350/rejection-region-for-the-likelihood-ratio-test-uniform-distribution</guid>
      <pubDate>Fri, 19 Apr 2024 00:12:00 GMT</pubDate>
    </item>
    <item>
      <title>如何解释特征样本和基于先验分布的技术来估计后验似然？</title>
      <link>https://stats.stackexchange.com/questions/645348/how-to-interpret-a-feature-sample-and-prior-distribution-based-technique-to-esti</link>
      <description><![CDATA[我试图理解实验方法背后的数学原理，该方法基于使用先验分布权衡实时观察。例如，考虑包含某个关键字（例如 Alexa）的音频波形数据集，目标是在知道关键字结束位置的情况下找到关键字的起始位置。
如果关键字结束帧是 $n$ 则起始帧 $s \in [n-k-w, n-k]$ 。利用这些先验知识，我使用误差平方和方法在直方图样本之上拟合多个连续分布 $f_S(s)$ 来找到最佳拟合。
现在，对于具有关键字和结束帧的给定新波形，我计算 $[n-k-w, n-k]$ 范围内的帧的梅尔能量。然后，我使用 $f_S(s)$ 权衡此能量，并选择得分最高的帧作为 $s$。这种方法给出了良好的结果，但我很难将其形式化。
该方法似乎与 MAP 类似，但我没有在以下等式中明确计算 $P(O|S=s)$：
$P(S|O) \propto P(O|S) \times P(S)$
其中 $(O=o)$ 是观测到的倒谱系数能量。
这种方法有什么理论依据吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645348/how-to-interpret-a-feature-sample-and-prior-distribution-based-technique-to-esti</guid>
      <pubDate>Thu, 18 Apr 2024 23:38:47 GMT</pubDate>
    </item>
    <item>
      <title>如何检查匹配病例对照研究中的组间相似性？</title>
      <link>https://stats.stackexchange.com/questions/645347/how-to-check-for-group-similarity-in-matched-case-control-studies</link>
      <description><![CDATA[我正在开展一项病例对照 (1:2) 临床研究，其中根据大量变量（性别、年龄、一些考虑风险、活动能力、认知能力的数字变量......）对患者进行匹配。 ）。我想评估病例和对照之间的相似性。
尽管我发现文献和讨论中缺乏一些一致性，但我认为样本是独立的，因为它们没有自然配对；我认为匹配过程是为了保证组之间的相似性。因此，我对独立样本进行统计检验。
为了评估两组是否相似，我独立测试了所有上述变量（例如性别的卡方、年龄的曼-惠特尼 U 等）。
这种方法正确吗？我可以从不同的、也许更正式的方法中受益吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645347/how-to-check-for-group-similarity-in-matched-case-control-studies</guid>
      <pubDate>Thu, 18 Apr 2024 22:40:02 GMT</pubDate>
    </item>
    <item>
      <title>识别分层簇的最佳方法</title>
      <link>https://stats.stackexchange.com/questions/645346/best-method-to-identify-layered-clusters</link>
      <description><![CDATA[问题
大家好。我正在使用一个数据集，该数据集包含 15300 个样本，每个样本有 49 个特征，均匀分布在三个类别中。我使用 TSNE 将特征空间的维度减少到二维，以更好地可视化数据的分布，并发现一些有点奇怪的东西（至少对我来说）。这些类似乎是相互叠加的。
嵌入数据分布

欧几里德距离

余弦相似度

我知道这些图表很恶心，对此感到抱歉。无论如何，是否有一种聚类算法可以正确识别这些类别？我听说谱聚类方法非常擅长识别非凸簇，但它们的空间和计算复杂度非常高，这不太好，因为我仅限于 16GB RAM。是否有一种迭代方法可以逼近传统谱聚类方法（图拉普拉斯特征分解）提供的解？]]></description>
      <guid>https://stats.stackexchange.com/questions/645346/best-method-to-identify-layered-clusters</guid>
      <pubDate>Thu, 18 Apr 2024 22:23:44 GMT</pubDate>
    </item>
    <item>
      <title>确定嘈杂的医疗保险索赔数据中的政策变化</title>
      <link>https://stats.stackexchange.com/questions/645345/determine-policy-changes-in-noisy-medicare-insurance-claim-data</link>
      <description><![CDATA[我希望这是问这个问题的正确地方，我不会因为一个糟糕的问题而受到批评，但这里是。
背景：
我有一个包含五年内提交的所有医疗保险索赔（非个性化）的数据库。
该数据库由 8.68B 条记录组成。每条记录都包括提交索赔的日期、索赔金额、索赔是否获得批准、索赔金额以及何时获得批准。每条记录还通过适用于程序/设备的约 22,000 个代码（CPT 代码）之一对索赔进行分类。数据按这些 CPT 代码排序，并在 CPT 代码内按日期排序。
是否涵盖索赔取决于影响我无权访问的相关 CPT 代码的各种政策。此外，对于我的问题来说，重要的是，适用于 CPT 代码的政策可能会随着时间的推移而发生变化。一些没有被覆盖的东西可能会变得如此。曾经被覆盖的东西可能不再被覆盖。甚至可能会来来回回，例如，覆盖-不覆盖-覆盖。或者，该策略在数据库期间可能永远不会改变。
最后，数据是有噪音的。虽然某些内容通常会被承保，但索赔仍可能因各种原因被拒绝，例如，提交晚、未提供所需文件等。同样，某些内容通常会被拒绝，但它仍然可能被承保，例如，同情心护理。&lt; /p&gt;
问题：
有没有一种方法可以从数据本身检测这些保单变化，这样我就可以说，对于给定的 CPT 代码，一个时期内批准的索赔百分比是 X，而在不同时期是 Y等等？
另一种说法可能是：面对这些嘈杂的数据，我如何找出适当的窗口和截止百分比来计算平均批准率，以便我可以比较两个时间序列？ 
需要明确的是，我有软件背景，并准备好进行暴力破解，即，如有必要，尝试所有可能的窗口。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/645345/determine-policy-changes-in-noisy-medicare-insurance-claim-data</guid>
      <pubDate>Thu, 18 Apr 2024 22:19:23 GMT</pubDate>
    </item>
    <item>
      <title>余弦相似度的缩放</title>
      <link>https://stats.stackexchange.com/questions/645343/scaling-of-cosine-similarty</link>
      <description><![CDATA[假设我有一个特定的度量存储在两个向量a和b中，我使用余弦相似度来度量两个向量之间的相似度。
形式上，余弦相似度表示为：
$$ \cos\theta =\frac{a\cdot b}{\|a\|\|b\|}= \frac{\sum_{i=1}^{ n}{a_i b_i}}{\sqrt{\sum_{i=1}^{n}a_i^2} \cdot\sqrt{\sum_{i=1}^{n}b_i^2}}$$&lt; /跨度&gt;
在阅读时，我发现了一篇帖子 关于两个向量之间的相似性。一个答案如下：
&lt;块引用&gt;
我在比较 2 个向量（速度）时遇到了类似的问题。我目前使用两个向量的点积除以最大向量长度的平方。这样做的优点是，在测量“相似性”时还考虑了方向和大小。该公式给出 -1 到 +1 之间的数字。如果向量相同，您将获得 +1。如果方向相差超过 180 度，结果为负。

指定如下：相似度 = dotproduct(a, b) / max(norm(a),norm(b))^2
因此，在上面的符号中，可以表示为：
$$ = \frac{\sum_{i=1}^{n}{a_i b_i}}{\max\left(\sqrt{\sum_{i=1) }^{n}a_i^2},\sqrt{\sum_{i=1}^{n}b_i^2}\right)^2}$$
考虑到正则余弦相似度也在区间内 $[-1,1]$？这是余弦相似度的标准缩放吗？如果是，这种方法通常被称为什么？最后，使用一些示例数据，似乎替代缩放会导致相似度稍低（请参阅下面的代码示例），这告诉我什么？
&lt;小时/&gt;
&lt;前&gt;&lt;代码&gt;n &lt;- 10

设置.种子(123)
a &lt;- rnorm(n)
b &lt;- rnorm(n)

余弦 &lt;- 函数(a, b) {
  总和（a * b）/（sqrt（总和（a * a））* sqrt（总和（b * b）））
}

cosine_norm &lt;- 函数(a, b) {
  sum(a*b) / max(sqrt(sum(a*a)), sqrt(sum(b*b)))^2
}

余弦（a，b）
[1]0.5801971

余弦范数（a，b）
[1] 0.5232835
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/645343/scaling-of-cosine-similarty</guid>
      <pubDate>Thu, 18 Apr 2024 22:05:19 GMT</pubDate>
    </item>
    <item>
      <title>秩约束矩阵乘积的 Frobenius 范数有界</title>
      <link>https://stats.stackexchange.com/questions/645341/frobenius-norm-of-rank-constrained-matrix-product-is-bounded</link>
      <description><![CDATA[假设我有三个矩阵 $\mathbf{W} \in \mathbb{R}^{p \times m}$ 和 $\mathbf{A}, \mathbf{B} \in \mathbb{R}^{m \times n}$ 与 $\operatorname{ rank}(\mathbf{A}) \leq r$ 和 $\mathbf{B}$ 在等级上不受限制。我还假设所有这些都在 Frobenius 范数中受到某个数字的限制，例如 $||\mathbf{W}||_F, ||\mathbf{A}||_F, | |\mathbf{B}||_F \leq \kappa$
我试图证明 $ \sup ||\mathbf{WA} ||_F \leq \sup ||\mathbf{WB}||_F$（sup 是在三个矩阵上）
我的想法是混合 SVD 分解，事实上矩阵的 Frobenius 范数是奇异值的平方，因此 LHS 将被裁剪为仅 $r$ 奇异值值将有助于总和。但我不能让它变得正式。您对如何进行有任何提示吗？
谢谢:)]]></description>
      <guid>https://stats.stackexchange.com/questions/645341/frobenius-norm-of-rank-constrained-matrix-product-is-bounded</guid>
      <pubDate>Thu, 18 Apr 2024 21:29:13 GMT</pubDate>
    </item>
    <item>
      <title>在独立同分布上应用确定性算子来自相同概率分布的随机变量 - 什么是保守的？</title>
      <link>https://stats.stackexchange.com/questions/645339/applying-deterministic-operators-on-i-i-d-random-variables-from-the-same-probab</link>
      <description><![CDATA[我有一组 i.i.d.随机变量 xi，从相同的（可能未知的）概率分布中采样，比如 P。现在我对这些独立同分布应用确定性算子。随机变量，例如范数算子，比如 F。
我相信现在 F(xi) 再次独立同分布。从相同（可能未知且可能与 P 不同）概率分布中采样的随机变量。我的信念是否正确？如果是，我想通过参考来支持它。]]></description>
      <guid>https://stats.stackexchange.com/questions/645339/applying-deterministic-operators-on-i-i-d-random-variables-from-the-same-probab</guid>
      <pubDate>Thu, 18 Apr 2024 20:45:44 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAM 建模时空数据（第二部分）</title>
      <link>https://stats.stackexchange.com/questions/645330/modelling-spatiotemporal-data-with-gams-part-ii</link>
      <description><![CDATA[这篇文章是我之前关于使用 GAMS 建模时空数据的问题的延续：
使用 GAM 建模时空数据
简而言之，我目前正在对房价数据集进行建模，其中一些重要的协变量是房屋坐标 (x,y) 和房屋销售日期 t。根据上一篇文章的建议，我尝试了不同的 GAM 规范来建模时空组件。下面我描述了每一个以及获得的 RMSE 训练误差：
1) 基于 mgcv 中默认薄板平滑的三变量样条：
model1 &lt;- mgcv::gam(价格 ~ s(x, y, t, k = 1500),
                    数据=数据，
                    家庭=伽玛（链接=日志），
                    方法=“REML”）

rmse &lt;- sqrt(mean((model1$fitted.values - model1$y)**2))

打印（均方根误差）
[1]3495.282


&lt;强&gt;2。上一篇文章中建议的张量积样条：
model2 &lt;- mgcv::gam(price ~ te(x, y, t, d = c(2,1), k = c(500, 5), bs = c(“tp”) ;,“cr”)),
                    数据=数据，
                    家庭=伽玛（链接=日志），
                    方法=“REML”）

rmse &lt;- sqrt(mean((model2$fitted.values - model2$y)**2))

打印（均方根误差）
[1]3745.546


&lt;强&gt;3。空间和时间分量之间没有交互的模型：
model3 &lt;- mgcv::gam(价格 ~ s(x, y, k = 500) +
                    s(t, k = 3),
                    数据=数据，
                    家庭=伽玛（链接=日志），
                    方法=“REML”）

rmse &lt;- sqrt(mean((model3$fitted.values - model3$y)**2))

打印（均方根误差）
[1]3771.286


&lt;强&gt;4。将交互建模为单独的张量积样条的模型：
model4 &lt;- mgcv::gam(价格 ~ s(x, y, k = 500) +
                    s(t, k = 3) +
                    ti(x, y, t, d = c(2,1), k = c(500, 5), bs = c(“tp”, “cr”)),
                    数据=数据，
                    家庭=伽玛（链接=日志），
                    方法=“REML”）

rmse &lt;- sqrt(mean((model4$fitted.values - model4$y)**2))

打印（均方根误差）
[1]3753.491


现在，我对这些结果感到相当困惑。如果分析有意义，则结论是模型 1 中的各向同性三变量平滑效果最好。但这直接与我上一篇文章中的答案相矛盾，该文章指出默认的 s() 错误地假设空间和时间方向上具有相同的摆动度。上述型号规格是否存在明显错误？或者我对训练 RMSE 的比较没有意义？如果是后者，那么比较模型准确性的最佳方法是什么？我还检查了样本外测试集的 RMSE 错误，结论是相同的，因此这不是训练/测试错误的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/645330/modelling-spatiotemporal-data-with-gams-part-ii</guid>
      <pubDate>Thu, 18 Apr 2024 17:32:27 GMT</pubDate>
    </item>
    <item>
      <title>事后观察到的效应大小是否与 p 值冗余，就像事后观察到的功效一样？</title>
      <link>https://stats.stackexchange.com/questions/645269/is-the-post-hoc-observed-effect-size-redundant-with-the-p-value-just-like-post</link>
      <description><![CDATA[为了简单起见，假设我们正在对 2 个正态分布总体进行 2 样本 t 检验，从中收集 2 个 i.i.d 样本。 （首先；我们可以稍后扩展到更复杂的情况）。我们知道，一项研究的事后观察功效完全由观察到的 p 值决定。请参阅此处，或此处，以及此网站上的多个参考。
然后，事后我们得到了计划的 $\alpha$ （传统上为 0.05），实际样本大小 $N $ 和 p 值 $p$。但是从 $p$ 我们可以得到观察到的幂 ($1-\beta&#39;$)，如下显示在链接中。我们有观察到的标准差 ($sd$)。我可以计算观察到的效果 ($\delta=(xbar_1-xbar_2)/sd$)。
让我知道用 2 个新样本重复此操作（相同的样本大小、相同的正态分布、相同的方差，但不同的“真实”效果）。我得到了不同的 p 值、观察到的功效 $(1-\beta$) 和观察到的效果 $\delta$&lt; /跨度&gt;。我多次重复同样的事情。
认为 $\delta$ 值与 p 值存在单调递减函数的想法是否正确？ （正如功率与 p 的链接所示）。或者事后效应大小是一个随机变量吗？在这种情况下，它的分布可能是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/645269/is-the-post-hoc-observed-effect-size-redundant-with-the-p-value-just-like-post</guid>
      <pubDate>Thu, 18 Apr 2024 01:40:12 GMT</pubDate>
    </item>
    <item>
      <title>多层次混合模型</title>
      <link>https://stats.stackexchange.com/questions/645259/multi-level-mixed-models</link>
      <description><![CDATA[我有一个模型，在该模型中，我从 3 个不同的农场收集了每个农场在几个不同星期内的信息。这些周并不完全相同，因此农场 1 的第 1 周与农场 2 的第 1 周并不相同。它总是在一周内采样新元素。
我应用了以下语法：
glmer(PCR ~ 样本 + (1 | 农场/周) , family = 二项式(link=&quot;logit&quot;),
            数据=数据）

我不知道如何插入随机组件。因为我想知道某种样本的 PCR 呈阳性的概率是多少。
我需要控制农场内一周的影响 - 以便模型具有样本相关结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/645259/multi-level-mixed-models</guid>
      <pubDate>Wed, 17 Apr 2024 19:00:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么即使对于 IID 随机变量我们也能得到更好的渐近全局估计量？</title>
      <link>https://stats.stackexchange.com/questions/645203/why-can-we-get-better-asymptotic-global-estimators-even-for-iid-random-variables</link>
      <description><![CDATA[设 $X_1,...,X_N$ 为从参数化分布中采样的 IID 随机变量 $p_\theta $，并假设我的目标是从这些样本中检索 $\theta$。
我们知道 MLE 在渐近状态下提供了一种有效的无偏估计，这意味着它将是渐近无偏的，并且方差（渐近）饱和 Cramer-Rao 界。
另一方面，我们也知道，即使在单次状态下，即在一次观察之后，我们也可以找到一个有效的局部无偏估计量，该估计量的主要警告通常只是local（这意味着它取决于有关 $\theta$ 的一些先验知识）。
相比之下，MLE 是无偏且有效的（尽管只是渐近），不需要参数的先验知识来进行估计。
为了用一个明确的玩具示例来具体化讨论，假设我们要从伯努利过程中估计 $p^2$，$X_i\sim\operatorname{伯尔尼}(p)$。
标准计算将显示此问题的 MLE 为
$$\hat p_N^2 = \left(\frac{\sum_{i=1}^N X_i}{N}\right)^2,
\\ \mathbb{E}[\hat p_N] = p^2 + \frac{p(1-p)}{N},
\\ \operatorname{Var}[\hat p_N] = \frac{4p^3(1-p)}{N} + O(1/N^2).$$
另一方面，局部围绕参数值 $p^2$ 饱和 Cramer-Rao 边界的单次估计量为
$$\hat f_{p^2}(X) = -p^2 + 2p X.$$
此处显示了 MLE 的计算例如，而局部有效估计器的计算此处。
因此，这两个估计量具有渐近相同的方差（取较大 $N$ 的局部估计量的平均值），但 MLE 的一大优势是非局部，即不是要估计的参数的函数。
我的问题是：是否有任何直觉可以理解为什么会发生这种情况？由于我们正在讨论 IID 变量，因此一系列观察中的信息不应比每个单独观察中的信息多。如果 $X_i,X_j$ 相关，我会理解需要使用同时对完整统计数据进行操作的估计器，但为什么会出现这样的情况当单个样本是 IID 时有用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645203/why-can-we-get-better-asymptotic-global-estimators-even-for-iid-random-variables</guid>
      <pubDate>Wed, 17 Apr 2024 08:42:08 GMT</pubDate>
    </item>
    <item>
      <title>我应该什么时候进行标准化，在回归之前还是之后？</title>
      <link>https://stats.stackexchange.com/questions/645188/when-should-i-standardize-before-or-after-a-regression</link>
      <description><![CDATA[我有一个面板数据集，我的因变量是长期合同农场工人的 Logit 转换比例。我对两个变量的影响特别感兴趣，即农业中的田园重点（以变量“田园”为代表）和马的存在（以“马”为代表）。这些变量的影响随着时间的推移而变化，我运行一个带有交互项的模型：
模型 &lt;- lm(logitshare ~ 田园 + 田园:因子(年份) + 马 + 马:因子(年份) +
其他变量，数据= mydata）
我需要比较变量的相对重要性并使用两种方法，在运行回归之前或之后进行标准化。结果明显不同。
。
“模型”列显示了对非标准化系数运行回归并使用 lm.beta 进行事后标准化的情况。 ModelST 在使用 R 尺度函数转换的系数上运行。哪种方法更可靠？]]></description>
      <guid>https://stats.stackexchange.com/questions/645188/when-should-i-standardize-before-or-after-a-regression</guid>
      <pubDate>Tue, 16 Apr 2024 23:50:11 GMT</pubDate>
    </item>
    <item>
      <title>双面 t 检验：如果您的估计已经告诉您要查看哪条尾部，为什么我们需要进行双面检验？</title>
      <link>https://stats.stackexchange.com/questions/645128/two-sided-t-tests-why-do-we-need-to-test-two-sided-if-your-estimate-is-telling</link>
      <description><![CDATA[想象一下以下场景：
H0：镇上的孩子平均睡眠 7 小时 (mu= 7)
HA：城镇里的孩子平均睡眠时间不足 7 小时 (mu=!7)
然后你收集城镇孩子的样本，得到平均值的估计值：7.8 小时，标准差为 1.0 小时。
现在，我真的不明白为什么我们要执行双边 t 检验。
双边检验似乎给出了以下问题的答案：“获得 x 距离且远离假定 (H0) 均值的结果的机会有多大？”。因此，在我们的例子中：7.8 小时及以上的机会 + 6.2 小时及以下的机会。
我不明白为什么我们对“6.2及以下”感兴趣部分。假设 H0 为真，为什么我们不想知道我们得到的结果以及更极端的结果的机会有多大？
在互联网上搜索答案后，我读到“你不能从双边 t 检验切换到单边 t 检验，因为那是作弊”。我还是不太明白为什么。到目前为止我所理解的是“如果你根据数据选择测试，你可能最终会“过度拟合”对您的数据进行测试”。但我不确定这种与统计模型的类比是否正确。
非常感谢您的阅读！]]></description>
      <guid>https://stats.stackexchange.com/questions/645128/two-sided-t-tests-why-do-we-need-to-test-two-sided-if-your-estimate-is-telling</guid>
      <pubDate>Tue, 16 Apr 2024 11:39:49 GMT</pubDate>
    </item>
    <item>
      <title>连续均匀随机变量比较的最佳策略/获胜概率</title>
      <link>https://stats.stackexchange.com/questions/645014/optimal-strategy-win-probability-for-sequential-uniform-random-variable-comparis</link>
      <description><![CDATA[假设您按顺序呈现 $n$ 个随机变量，$x_1, x_2, \dots, x_n$&lt; /span&gt;，均取自 U(0,1)。提供每个变量 $x_i$ 后，您必须声明该数字在所有 $ 的有序列表中的位置x_1$ 到 $x_n$ （即最大、第二大、最小等）。声明相对位置的最佳策略是什么以及成功的概率是多少（所有 $x_i$ 中没有错误答案）。
对于$n=3$，我认为算法应该如下

$x_1$

最大如果 $x_1 &gt; 2/3$
min if $x_1 $x_1 &lt; 1/3$
中，如果 $1/3 &lt; x_1 &lt; 2/3$


$x_2$

如果 $x_1$ 为最大值

如果 $x_2 &gt; x_1$，$x_2$ 是最大值（我们输了游戏）
如果 $x_2 &lt; 0.5$，$x_2$ 分钟
如果 $0.5 &lt; x_2 &lt; x_1$，$x_2$ 处于中间


如果 $x_1$ 为最小值，我们的操作类似于 $x_1$ 为最大值
如果 $x_1$ 为中间

如果$x_1 &lt; x_2 &lt; 0.5$ 或 $0.5 &lt; x_2 &lt; x_1$，$x_2$ 处于中间位置（我们输了）
如果 $x_2 &gt; x_1 \land x_2 &gt; 0.5$，$x_2$ 为最大值
如果 $x_2 &lt; x_1 \land x_2 &lt; 0.5$，$x_2$ 分钟




$x_3$

与 $x_1$ 和 $x_2$ 进行简单比较以查看位置并声明为最小值/中值/max相应


]]></description>
      <guid>https://stats.stackexchange.com/questions/645014/optimal-strategy-win-probability-for-sequential-uniform-random-variable-comparis</guid>
      <pubDate>Sun, 14 Apr 2024 22:21:15 GMT</pubDate>
    </item>
    </channel>
</rss>