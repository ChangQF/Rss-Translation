<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 29 Mar 2025 18:21:56 GMT</lastBuildDate>
    <item>
      <title>从专家那里寻求时间序列的预测建模[关闭]</title>
      <link>https://stats.stackexchange.com/questions/663280/seeking-advice-on-time-series-predictive-modeling-from-experts</link>
      <description><![CDATA[我希望从4年开始识别每小时DHW点数（家用热水）中的异常值（传感器数据故障）。
我和我有4年的每小时天气数据非常准确，大多数QDHW数据也是好数据（不是离群值），有没有一种方法可以将天气数据与QDHW数据结合使用，以帮助过滤出异常值QDHW数据？？]]></description>
      <guid>https://stats.stackexchange.com/questions/663280/seeking-advice-on-time-series-predictive-modeling-from-experts</guid>
      <pubDate>Sat, 29 Mar 2025 17:08:53 GMT</pubDate>
    </item>
    <item>
      <title>了解卷积层中的反向传播</title>
      <link>https://stats.stackexchange.com/questions/663279/understanding-backpropagation-in-convolutional-layer</link>
      <description><![CDATA[我需要帮助理解卷积层中的反向传播。
据我所知，远期阶段如下：
  在其中，张量 $ a_ {3 \ times3 \ times1} $ 是指上一层中的特征映射，
张量 $ W_ {2 \ times2 \ times3} $ 是指当前层中的内核。
 $ a*w $ 在这种情况下，会导致张量 $ z_ {2 \ times2 \ times2 \ times3} $ 。然后，将偏差术语添加到每个通道，应用激活，然后将其转发到下一层。
这是向后阶段。我必须计算 $ \ nabla_w c $ 和 $ \ nabla_b c $ 。
根据链条规则：
 \ begin {align*}
\ frac {\ partial c} {\ partial w} =
\ frac {\ partial c} {\ partial a}
\ frac {\ partial a} {\ partial z}
\ frac {\ partial z} {\ partial w}
\ end {align*} 
在这一点上，我们知道卷积层是一个隐藏的层。因此，传播错误 $ \ frac {\ partial c} {\ partial z} $ 是传播的，我只需要计算 $ \ frac {\ frac {\ partial z}}
对于第一个频道，表示为 $ z^1 $ ，我们知道：
 \ begin {align*}
z_1＆amp; = w_1a_1+w_2a_2+w_3a_4+w_4a_5+b_1 \\
z_2＆amp; = w_1a_2+w_2a_3+w_3a_5+w_4a_6+b_1 \\
z_3＆amp; = w_1a_4+w_2a_5+w_3a_7+w_4a_8+b_1 \\
Z_4＆amp; = W_1A_5+W_2A_6+W_3A_8+W_4A_9+B_1
\ end {align*}  
因此，对于 $ \ frac {\ partial z^1} {\ partial w} $ ：
 \ begin {align*}
\ frac {\ partial z_1} {\ partial w}＆amp; =
\ begin {bmatrix}
\ frac {\ partial z_1} {\ partial w_1}＆amp;
\ frac {\ partial z_1} {\ partial w_2} \\
\ frac {\ partial z_1} {\ partial w_3}＆amp;
\ frac {\ partial z_1} {\ partial w_4}
\ end {bmatrix} \\＆amp; =
\ begin {bmatrix}
A_1＆amp; a_2 \\
A_4＆amp; A_5
\ end {bmatrix}
\ end {align*} 
同样适用于其他人。所以：
 \ begin {align*}
\ frac {\ partial z^1} {\ partial w} =
\ begin {bmatrix}
\ begin {bmatrix}
A_1＆amp; a_2 \\
A_4＆amp; A_5
\ end {bmatrix}＆amp;
\ begin {bmatrix}
A_2＆amp; a_3 \\
A_5＆amp; A_6
\ end {bmatrix} \\
\ begin {bmatrix}
A_4＆amp; A_5 \\
A_7＆amp; A_8
\ end {bmatrix}＆amp;
\ begin {bmatrix}
A_5＆amp; a_6 \\
A_8＆amp; A_9
\ end {bmatrix}
\ end {bmatrix}
\ end {align*} 
还适用于通道，结果是：
   这是我困惑的。，如果我们直接计算 $ \ frac {\ partial c} {\ partial z} \ frac {\ frac {\ partial z} {\ partial z} {\ partial w} $  $ 2 \ times2 \ times2 \ times2 \ times3 $ ，它不匹配 $ w $ 的形状。我想念什么？我真的很想直观地理解这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/663279/understanding-backpropagation-in-convolutional-layer</guid>
      <pubDate>Sat, 29 Mar 2025 17:08:23 GMT</pubDate>
    </item>
    <item>
      <title>是否有人试图将VAE作为经验贝叶斯估计器实施？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/663278/has-anyone-attempted-to-to-implement-a-vae-as-an-empirical-bayes-estimator</link>
      <description><![CDATA[是否有人试图将纸质变性自动编码器作为
经验贝叶斯（Wang and Blei 2019）是从某种分布中重新创建预定义的先验？我已经尝试过，但是我似乎总是从VAE输出数据本身的分布，而不是先前。
纸在这里 -   https://projecteuclid.org/journals/statistic-science/volume-34/sissue-2/comment-comment-variational-autoencoders-autoencoders-as-as-pircirical-bayes/10.1214/1214/19-sts710.10.10.full  &gt; &gt;&gt;&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/663278/has-anyone-attempted-to-to-implement-a-vae-as-an-empirical-bayes-estimator</guid>
      <pubDate>Sat, 29 Mar 2025 16:03:36 GMT</pubDate>
    </item>
    <item>
      <title>使用longnet [封闭]时选择时间序列分析（TSA）的时间范围的最佳实践</title>
      <link>https://stats.stackexchange.com/questions/663277/best-practices-for-choosing-the-time-range-in-time-series-analysis-tsa-when-us</link>
      <description><![CDATA[我目前正在从事一个时间序列分析项目，在该项目中，我使用Longnet预测巴黎温度。我正在考虑为数据集使用每日时间窗口。将6年的历史时期用作输入窗口是一个合理的选择吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663277/best-practices-for-choosing-the-time-range-in-time-series-analysis-tsa-when-us</guid>
      <pubDate>Sat, 29 Mar 2025 15:30:40 GMT</pubDate>
    </item>
    <item>
      <title>我如何在R中完善我的ARX模型</title>
      <link>https://stats.stackexchange.com/questions/663276/how-do-i-go-about-refining-my-arx-model-in-r</link>
      <description><![CDATA[我遇到了一些问题，即我试图预测我的因变量y。我有6个不同的独立外部变量，其中一个是因变量y的滞后（1）。我将所有值差异1差异1，以确保它们是固定的。并意识到，在我不同的独立外部变量中，它们的尺度大不相同，有些是从0到2，有些是-1000到200。它们是十年来的每月数据。因此，我的第一个问题是使我对独立外部变量的差异值归一化是否有意义。
下一个挑战是，由于我在进行ARX预测模型，因此我目前有2015年至2025年的数据。但是我想预测到2028年，我了解到我需要对这些变量进行预测我的独立外部变量，但我是否在归一化的数据或差异值上这样做？  ？]]></description>
      <guid>https://stats.stackexchange.com/questions/663276/how-do-i-go-about-refining-my-arx-model-in-r</guid>
      <pubDate>Sat, 29 Mar 2025 14:02:55 GMT</pubDate>
    </item>
    <item>
      <title>流动不足的激活，带有浮子的梯度下降[闭合]</title>
      <link>https://stats.stackexchange.com/questions/663275/underflowing-activations-gradient-descent-with-floats</link>
      <description><![CDATA[这是成本函数行为的延续。
首先，我想指出我没有遇到编码错误，在网上找到的逻辑回归例程也会发生同样的问题。
话虽如此，我相信我确定了这个问题：在培训过程中，大约700次迭代， $ \ sigma（wx+b）$  $ 太接近1（即 $ | | \ sigma-sigma-1 |＆lt; sigma-1 |＆lt; 10^^$  nogers and Inder and and and and and and and and and and and and of nog;  $（1-y）\ log（1- \ sigma）= 0 \ times \ times \ infty $ 。
（这并不能完全解释为什么以后再迭代。我猜 $ w $  and  $ b $ 仍然表现得很好，即使 $ \ \ sigma（w x+b）
我如何克服这一点？使用长似乎没有解决此问题。 Clearly I could just halt the training, but I&#39;ve checked that the accuracy on the testing set is still going up, so it feels like I&#39;m leaving money on the table (and also I would guess it is not computationally wise to check, on every iteration, whether any component of $\sigma-1$ underflowed, especially with an eye to neural networks).这是一个已知问题吗？是否有一种解决方案的标准方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/663275/underflowing-activations-gradient-descent-with-floats</guid>
      <pubDate>Sat, 29 Mar 2025 13:53:15 GMT</pubDate>
    </item>
    <item>
      <title>多级模型：量化自变量的组级效应</title>
      <link>https://stats.stackexchange.com/questions/663272/multilevel-model-quantifying-group-level-effects-of-an-independent-variable</link>
      <description><![CDATA[我是新来的，正在尝试弄清楚我可以使用多级模型可以做什么，或者我需要如何指定它以获取我想要的见解。
我正在进行社会科学研究，并通过调查数据构建了一个多层次的逻辑回归模型。我有两个级别（个人嵌套在国家 /地区），因变量是虚拟的，独立变量是标准控制变量（年龄，性别，教育等）以及对调查项目的响应（通常以0-10的比例出现，而我在不这样做的情况下将它们恢复到该范围）。我构建的模型（在R中使用GLMMTMB）现在具有随机的截距，并且针对三个选定的自变量的随机斜率。
在模型输出中，我看到给定变量不是整个模型中的重要预测因子。但是，绘制随机斜率在各个国家 /地区（无论是大小还是标志）都显示出很大的差异。我附加了一个插图的图，其中只包括一个国家以说明原则。。
  这使我怀疑该变量很可能与我国家的一些结果显着相关，但却相反。我想测试/调查。 I searched here on this board and found this post that basically asked the question I initially had, namely how to test for the significance of a random effect.看来这是一个错误的思考随机效果的方式，但我不确定如何从那里走得更远。
我知道我可以执行一项似然比测试，以查看让斜率变化是否会大大增加模型的拟合度。但是，有多种场景可以产生这种结果。例如，在所有国家 /地区，变量的斜率都是正的，但是幅度差异很大，以至于让斜率变化是正确的选择。但是我要表明的是，效应的方向在各个国家之间有所不同，并且这种观察到的效果的分歧不太可能是由于偶然的。 
我需要做什么（在我的模型中提取估计值以进行计算，或者在修改模型以产生所需结果的方面）以回答我的问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/663272/multilevel-model-quantifying-group-level-effects-of-an-independent-variable</guid>
      <pubDate>Sat, 29 Mar 2025 13:04:27 GMT</pubDate>
    </item>
    <item>
      <title>这种最终方法是否严格？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/663271/does-this-final-methodology-have-rigour</link>
      <description><![CDATA[请告诉我这种方法是否严格：H1：较高水平的人力资本增强了外国直接投资的能力推动结构转化：B3＆gt; 0
H1替代方案：较高水平的人力资本不会增强外国直接投资对结构转化的积极影响B3＆lt; 0 
 H2：政治腐败越高，人力资本有效吸收FDI的能力越低。
H2：替代方案：政治腐败不会削弱外国直接投资对结构转型的影响
B6＆gt; 0 
与国家假人的pooeld ols：巴西== 1和韩国== 0 
之后，我的回归是：recress_v_added_pct_gdp fdi hc hc hc hc hc_fdi v2x_pubcorr gross_capital_capital_capital_capital_pct_gdp_gdp brazil_dumm_dumm_dummy fdiummy fdi_brazil fdi_brazil hc_brazil hc_fdi_brazil，robust robust 
回归制造_v_added_pct_gdp fdi hc hc hc hc hc hc hc hc hc hc hc hc hc hc hc hc hc hc hc hc hc gross_capital_capital_capital_capital_formation_pct_gdp export_goods_goods_services_services_prct_gdp_gdp _gdp brazil_dummy fdiummy fdimy_brazil fdi_brazil hc_brazil hc_brazil hc_brazil hc_fdi 之后，我使用ESTAT hettest检查了我检查的异性恋 - 不存在
多重共线性 - 这是Vif＆gt; 10的存在，但通过平均居中来解释
自相关存在，这是通过Wooldridge测试对此进行了测试的，为此解释了我包括FDI和HC的滞后，但是纠正了这一点 - 但是我是否应该包括仅FDI/HC的滞后或两者兼而有之吗？这会检验我的假设吗？肯定会添加这些滞后会减少我的样本量，到目前为止，我已经为FDI和HC添加了2个滞后。 HC滞后并不重要。
我的目的是比较两国，还要检查FDI和HC之间的反向因果关系，由于数据限制，我选择了滞后，而不是IV，并且还被告知不要由于小样本而不会将错误集群，此外，我选择了FE模型，因为它只能在国家差异中解释FE模型。我错过了什么吗？
  &lt;img alt =“在此处输入图像描述” src =“ https://i.sstatic.net/7osskr7e.pn/7osskr7e.png”]]></description>
      <guid>https://stats.stackexchange.com/questions/663271/does-this-final-methodology-have-rigour</guid>
      <pubDate>Sat, 29 Mar 2025 12:58:13 GMT</pubDate>
    </item>
    <item>
      <title>球形点拾取，密度增加在六个八分之一的顶点</title>
      <link>https://stats.stackexchange.com/questions/663269/spherical-point-picking-with-increased-density-at-six-octant-vertices</link>
      <description><![CDATA[下面是一组点神经网络反操作的结果 - 问题是我使用均匀的点拾取了球（通过 https://mathworld.wolfram.com/spherepointpicking.html ），经过中介计算后，八分位顶点是没有代表的。。
如何生成一组随机点，该点更好地表示以下密度，以便我可以获得更好的训练数据？
这一切都与我试图找到一种数值方法来求解Dixon Ellipticals的逆函数（请参阅链接），牢记我只对特定情况真正感兴趣，并且没有数学学位（因此要查看NN解决方案）&gt; &gt;
  https://math.stackexchange.com/questions/5049279/5049279/conformally-mapply-mapping-an-equileral-triangle-on-the-complex-plane-plane-plane-plane-the-complex  
  https://math.stackexchange.com/questions/questions/5049065/dixon-dixon-elliptic-series-coeeies-coeries-pcffffffffficficeient
  https://gis.stackexcexchange.com/questions/questions/491255/cohill-conformal-conformal-conformal-conformal-algorital-algorithm  
这最后显示了我最初用于前向功能的训练集。然后，我在立体图投影中使用了四分之一圈 - 但是它似乎仍然没有到达边缘 - 但是，网络能够可视化逆函数（这是下面所示的内容，以及使用的源数据）。）。&gt; 。
因此，下面的描述是通过使用正向函数（将球体映射到三角形的）。正如很容易注意到的那样，训练在八分之一的顶点是最错误的。
    &lt;img alt =“ nn nn inverse dody src =” src =“ https://i.sstatic.net/b7f8osur.pnosur.pn.]]></description>
      <guid>https://stats.stackexchange.com/questions/663269/spherical-point-picking-with-increased-density-at-six-octant-vertices</guid>
      <pubDate>Sat, 29 Mar 2025 11:34:40 GMT</pubDate>
    </item>
    <item>
      <title>PR模型中的微积分怀疑（1987）证明</title>
      <link>https://stats.stackexchange.com/questions/663267/calculus-doubts-in-pr-model-1987-proof</link>
      <description><![CDATA[这是一个基本的行业平衡模型，其中 $ y $ 是输出， $ r $ 是收入， $ c $ c $ 是成本。  $ r_y $ 是 $ r $ 和 $ c_y $ 的部分导数。  $ n $ 是行业中的公司数量， $ \ tilde {x} _i（y，\ mathbf {w，w，t}）
鉴于此，有人可以告诉我：

方程式（13）是如何产生的？
如果（13）是正确的（16）如何转（17）？更具体地说，c_y是如何来自 $ \ sum w_i（\ partial \ tilde x_i/\ partial y）$ ？

  以防有人想访问原始文章以获取更多上下文： https://doii.org/10.2307/2098582 
（我无法链接PDF）
 P.S。我想要一个字面的逐步推导，因为我想知道到底在哪里。]]></description>
      <guid>https://stats.stackexchange.com/questions/663267/calculus-doubts-in-pr-model-1987-proof</guid>
      <pubDate>Sat, 29 Mar 2025 09:20:31 GMT</pubDate>
    </item>
    <item>
      <title>使用不同先验的贝叶斯推断估算硬币的偏见</title>
      <link>https://stats.stackexchange.com/questions/663264/estimating-a-coins-bias-using-bayesian-inference-with-different-priors</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/663264/estimating-a-coins-bias-using-bayesian-inference-with-different-priors</guid>
      <pubDate>Sat, 29 Mar 2025 05:20:20 GMT</pubDate>
    </item>
    <item>
      <title>跨不同组的塑造值</title>
      <link>https://stats.stackexchange.com/questions/663261/shap-values-across-different-groups</link>
      <description><![CDATA[ i通过随机森林，支持向量机，逻辑回归和XGBoost（TidyModels R软件包）算法开发并比较了四个ML模型，并使用年龄组分层的数据进行了数据。因此，我有一个全部数据，因为我的数据集没有很多观察结果。
之后，我估计了每个模型的形状值（Dalex R软件包）。为此，我从每个年龄类别（18-64; 65-74; 75岁或以上）中随机选择一个观察结果，以检查每个年龄段的最重要特征（rf; lr; svm; svm; svm; xgboost）。需要这种方法，因为某些功能对每个特定年龄段都很重要。最小和最大的人在糖尿病预测的健康和生物条件方面可能有所不同，我的结果变量。
我想知道这个策略是否正确，也就是说，仅使用每个年龄段的塑形值来解释我的模型。
我担心，通过将数据除以年龄并按年龄类别开发模型，我对每个年龄段的观察结果很少，并且性能可能会受到很大影响，并且该模型可能无法正确解释每个重要的预测指标。。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/663261/shap-values-across-different-groups</guid>
      <pubDate>Sat, 29 Mar 2025 01:30:22 GMT</pubDate>
    </item>
    <item>
      <title>最小二乘的历史</title>
      <link>https://stats.stackexchange.com/questions/663255/history-of-least-squares</link>
      <description><![CDATA[我正在阅读试图将理想化曲线（如椭圆形）适合天文数据的历史。当时（1700年代至1800年代）已经存在各种方法。一个这样的例子是一种简单的平均方法，在该方法中，您将过度确定的线性系统添加成组，直到解决。还存在其他方法，例如用于最小化最大偏差的算法（以及最小化总偏差）。
 Legendre的最小二乘方法是什么使它成为最受欢迎的方法？仅仅是因为它比其他方法容易得多？更具体地说，使用最小二乘有几乎是自动的答案，而要最大程度地减少最大偏差需要一种费力的算法（当时是手工完成的）。
最小二乘作为mle或蓝色等的理由，所有这些都在很久以后发生。但是在早期，在1700年代至1800年代之间，与其他现有方法相比，最小二乘的拟合只是最简单的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663255/history-of-least-squares</guid>
      <pubDate>Fri, 28 Mar 2025 18:55:18 GMT</pubDate>
    </item>
    <item>
      <title>终身估计是自上次次要事件以来的时间（几乎是泊松过程）</title>
      <link>https://stats.stackexchange.com/questions/663245/lifetime-estimates-conditional-on-time-since-last-secondary-event-almost-poisso</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/663245/lifetime-estimates-conditional-on-time-since-last-secondary-event-almost-poisso</guid>
      <pubDate>Fri, 28 Mar 2025 15:21:08 GMT</pubDate>
    </item>
    <item>
      <title>香草方差分析的用法和哲学</title>
      <link>https://stats.stackexchange.com/questions/663242/usage-and-philosophy-of-vanilla-anova</link>
      <description><![CDATA[我没有统计背景，所以请耐心等待。我试图理解简单的一种方差分析布局。特别是我
有一个疑问对用F检验检验的零假设的疑问，这似乎是ANOVA   $$ H_0：\ MU_1 = \ MU_2 =…= \ MU_K $$ $  
这个假设对我来说似乎很奇怪，因为它没有说什么是最好的治疗方法。为什么不直接估计效应大小，例如直接 $ \ mu_i $ 或 $ \ mu_i- \ mu_j $ ？我给自己的答案是这个。当我们没有足够的数据将每种治疗与彼此进行比较时（因为单独的每种治疗都有很少的样本，这可能会导致错误低估和误报），但是我们有足够的数据回答 $ h_0 $ 。如果 $ h_0 $ 被拒绝，那么我们可以：

 收集更多样本以回答有关个人治疗的更多特定问题或 

 更多地相信ANOVA后完成的效应大小分析的结果（从这个意义上讲，我们构建了一个组合模型）。


从这个意义上讲，方差分析是避免误报或指导实验选择的初步测试。
这真的是ANOVA NULL假设背后的哲学吗？还是我误会了和缺少其他无用的方式或需要的其他方式？
我很抱歉，如果已经解决了这个基本问题。如果我将删除此。]]></description>
      <guid>https://stats.stackexchange.com/questions/663242/usage-and-philosophy-of-vanilla-anova</guid>
      <pubDate>Fri, 28 Mar 2025 13:52:35 GMT</pubDate>
    </item>
    </channel>
</rss>