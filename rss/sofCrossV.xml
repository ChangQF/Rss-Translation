<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 02 Oct 2024 06:24:26 GMT</lastBuildDate>
    <item>
      <title>无线电定位信息的统计分析</title>
      <link>https://stats.stackexchange.com/questions/655204/statistical-analysis-of-radiolocational-information</link>
      <description><![CDATA[让我们考虑以下系统：
用于跟踪移动目标的雷达站。
传感器设备，允许在必要时测量其位置、速度和其他参数。

有趣的是：是否对测量的雷达信息进行了统计处理，为此使用了哪些方法，以及可以使用辐射定位信息的统计处理提取哪些有用信息（例如，在误差或机动等方面）？
这个问题很紧急。如果有人能回答，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655204/statistical-analysis-of-radiolocational-information</guid>
      <pubDate>Wed, 02 Oct 2024 04:09:01 GMT</pubDate>
    </item>
    <item>
      <title>年份固定效应 vs 一年虚拟变量下降</title>
      <link>https://stats.stackexchange.com/questions/655202/year-fixed-effects-vs-dropping-one-year-dummy</link>
      <description><![CDATA[我正在运行具有年份固定效应的回归分析，但我的一个协变量是年龄，它与年份完全共线。我注意到有些论文包括年份虚拟变量，但删除了一年以允许年龄出现在结果中。你能解释一下这种方法的优缺点吗？这两种方法都有明显的优势吗，或者普遍认为哪一种方法更好？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655202/year-fixed-effects-vs-dropping-one-year-dummy</guid>
      <pubDate>Wed, 02 Oct 2024 02:28:31 GMT</pubDate>
    </item>
    <item>
      <title>解释因素间相关矩阵</title>
      <link>https://stats.stackexchange.com/questions/655199/interpreting-inter-factor-correlation-matrix</link>
      <description><![CDATA[根据理论（即假设因子相关），我对四个因子进行了 EFA 的斜向旋转。我得到的因子相关性范围从 0.10 到 0.59。我使用了 R 中的 psych::fa() 函数。
我不确定如何解释这些，例如，这些相关性是否具有统计显著性？
有没有办法找出与每个因子相关性相关的 p 值？]]></description>
      <guid>https://stats.stackexchange.com/questions/655199/interpreting-inter-factor-correlation-matrix</guid>
      <pubDate>Tue, 01 Oct 2024 23:50:47 GMT</pubDate>
    </item>
    <item>
      <title>线性概率模型：对数分类变量的解释</title>
      <link>https://stats.stackexchange.com/questions/655198/linear-probability-model-interpretation-of-a-logged-categorical-variable</link>
      <description><![CDATA[基于这个 SO问题，我有一个关于当对数变量为分类变量时线性对数模型的解释的问题。
如果我的模型是$y = b0 + b1*log(x1)$，其中$y$是分类变量，log是自然对数，$x1$是连续变量，那么$x1$增加 1% 会导致$y$的概率改变$\frac{b1}{100}$个百分点， $x1$ 增加 10% 会导致 $y$ 发生 $b1*log(1.10)$ 个百分点的变化。
但是，如果 $x1$ 是离散的，即子女数量或被解雇的次数，那么了解 $x1$ 增加 1% 会如何改变 $y$ 的概率就不如了解增加一个子女或再次被解雇会如何增加 $y$ 的概率那么现实、重要或具有指导意义。我该如何计算这种情况的概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/655198/linear-probability-model-interpretation-of-a-logged-categorical-variable</guid>
      <pubDate>Tue, 01 Oct 2024 23:27:56 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以找到样本大小/功效计算的方差估计值</title>
      <link>https://stats.stackexchange.com/questions/655197/where-to-find-variance-estimates-for-sample-size-power-calculations</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655197/where-to-find-variance-estimates-for-sample-size-power-calculations</guid>
      <pubDate>Tue, 01 Oct 2024 23:27:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么相关系数被解释为给定 $x$ 一个标准差时 $y$ 的标准差数，反之亦然？</title>
      <link>https://stats.stackexchange.com/questions/655196/why-is-the-correlation-coefficient-interpreted-as-the-number-of-standard-deviati</link>
      <description><![CDATA[我在这个问题的答案中看到，$X$和$Y$之间的相关系数被解释为当$X$改变一个标准差时，$Y$改变的标准差数，反之亦然。这来自以下公式：
$$\frac{cov(x, y)}{\sqrt{var(x)*var(y)}}$$
我知道这应该反映 $x$ 和 $y$ 之间关联的标准化测量，但我不知道为什么。如果 ${\sqrt{var(x)*var(y)}}$ 应该是 $cov(x, y)$ 的标准差，我不知道如何。]]></description>
      <guid>https://stats.stackexchange.com/questions/655196/why-is-the-correlation-coefficient-interpreted-as-the-number-of-standard-deviati</guid>
      <pubDate>Tue, 01 Oct 2024 23:07:35 GMT</pubDate>
    </item>
    <item>
      <title>您能将具有不同机会水平的两个二进制分数相加吗？</title>
      <link>https://stats.stackexchange.com/questions/655194/can-you-sum-two-binary-scores-with-different-chance-levels</link>
      <description><![CDATA[我设计了一个实验，结果由 2 个任务来衡量。

在第一个任务中，参与者选择两个选项中哪一个是正确的。
在第二个任务中，他们选择三个选项中哪一个是正确的。

两个任务都采用二进制评分：选择正确选项得 1 分，选择其他选项得 0 分。
两个任务都涉及相同的概念变量，因此我想创建一个总分（任务 1 + 任务 2），作为结果的单一衡量标准。但我被警告说，对具有不同机会水平的二进制分数进行求和可能是错误的。如果是这样，我该怎么办？
如果这是一个问题，这两个分数的平均值（约 0.4）和标准差（约 0.5）相似。
（我尝试搜索相关问题，但没有找到。我提前为重复发帖道歉！）]]></description>
      <guid>https://stats.stackexchange.com/questions/655194/can-you-sum-two-binary-scores-with-different-chance-levels</guid>
      <pubDate>Tue, 01 Oct 2024 22:42:17 GMT</pubDate>
    </item>
    <item>
      <title>韦尔奇·萨特斯韦特自由度（间接比较的组合规则）</title>
      <link>https://stats.stackexchange.com/questions/655193/welch-satterthwaite-degrees-of-freedom-combining-rule-for-indirect-comparison</link>
      <description><![CDATA[在网络分析中，间接比较不同研究中的治疗“A”和“B”与共同参考治疗“C”之间的平均差异。计算公式为：
$$
间接 MD(AvsB) = 直接 MD(AvsC) - 直接 MD(BvsC)
$$
其中 MD = 平均差
间接汇总效应的 95% 置信区间由以下公式构建：
$$
[间接 MD(AvsB) ± 1.96 \sqrt{(方差[间接 MD(AvsB)])}]
$$
其中
$$
方差[间接 MD(AvsB)] = 方差[直接 MD(AvsC)] +方差[directMD(BvsC)]
$$
问题：现在，如果我们想应用 Welch-Satterthwaite 校正和 t 分布来构建平衡情况（样本大小相等）的置信区间，方差和自由度 (df) 的组合规则是什么？
自由度：
$$
\frac{(variance_{AvsC} + variance_{BvsC})^2}{\left(\frac{(variance_{AvsC})^2}{n_{C} - 1}\right) + \left(\frac{(variance_{BvsC})^2}{n_{C} - 1}\right)}
$$
其中
$$
variance_{AvsC} = \frac{sd_A^2}{n_A} + \frac{sd_{\text{c}}^2}{n_{\text{c}}}
$$
and
$$
variance_{BvsC} = \frac{sd_B^2}{n_B} + \frac{sd_{\text{c}}^2}{n_{\text{c}}}
$$
找不到任何来源...]]></description>
      <guid>https://stats.stackexchange.com/questions/655193/welch-satterthwaite-degrees-of-freedom-combining-rule-for-indirect-comparison</guid>
      <pubDate>Tue, 01 Oct 2024 22:32:57 GMT</pubDate>
    </item>
    <item>
      <title>置信区间和置信区间之间的差异</title>
      <link>https://stats.stackexchange.com/questions/655191/difference-between-confidence-bands-and-confidence-intervals</link>
      <description><![CDATA[我已阅读此 stackexchange 上关于此主题的其他答案，但我有几个问题想澄清一下：
置信带通常被视为整个回归过程中由置信区间形成的连接线（“带”）。这让我相信（可能不正确）置信带只是整个回归过程中的置信区间的“系列”（即以置信度 $1-\alpha$ % 包裹回归线的线
我的抱怨（这让我对上述推论感到困惑）是，计算置信带的公式使用了 Working-Hotelling 常数，这会导致区间比给定点的置信区间更宽（例如在 SLR 中）：
$
\begin{align}
C.B = \hat y_{i} \pm W \cdot se(\hat y_{i})
\end{align}
$
在与观察值相关的 $x$ 值处 $i$
那么我关于置信区间的结论是否不正确？它们与置信区间的关系是什么？为什么我们使用 $F$ 分布而不是 $t$ 分布？任何帮助都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/655191/difference-between-confidence-bands-and-confidence-intervals</guid>
      <pubDate>Tue, 01 Oct 2024 21:27:42 GMT</pubDate>
    </item>
    <item>
      <title>Neyman 关于零假设的定义以及“接受 H0”与“不拒绝 H0”的等价性</title>
      <link>https://stats.stackexchange.com/questions/655183/neyman-on-definition-of-null-hypothesis-and-equivalence-of-accepting-h0-and-n</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655183/neyman-on-definition-of-null-hypothesis-and-equivalence-of-accepting-h0-and-n</guid>
      <pubDate>Tue, 01 Oct 2024 18:33:08 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中标准化回归系数</title>
      <link>https://stats.stackexchange.com/questions/655181/standardizes-regression-coefficients-in-r</link>
      <description><![CDATA[这是 BETA（标准化回归系数）的公式：
\begin{align}
\text{BETA}_2 &amp; = \frac{r_{y2}-r_{23}r_{y3}}{(1-R_{2.3}^2)}
\end{align&gt;
mtcars |&gt;
select(hp, drat, wt) |&gt;
cor()

当我采用这些相关系数并在 R 中计算 BETA_hp_wt 时：
BETA_hp_wt &lt;- (.66 - (-.45 * -.71))/(1 - -.45^2)

BETA_hp_wt # BETA_hp_wt = 0.28

该值要低得多，因此与拟合 lm.beta 完全不同：
fit &lt;- lm(wt ~ hp + drat, data = mtcars) 

fit_s &lt;- lm.beta::lm.beta(fit)

summary(fit_s) # BETA_hp_wt = 0.42

为什么？！]]></description>
      <guid>https://stats.stackexchange.com/questions/655181/standardizes-regression-coefficients-in-r</guid>
      <pubDate>Tue, 01 Oct 2024 17:08:20 GMT</pubDate>
    </item>
    <item>
      <title>倾向得分匹配后的统计分析 - Kaplan-Meier/置信区间 - 是否需要调整？</title>
      <link>https://stats.stackexchange.com/questions/655178/statistical-analyses-after-propensity-score-matching-kaplan-meier-confidence</link>
      <description><![CDATA[为了分析一个数据集，我应用了倾向得分匹配（R 中的 matchit，5:1 无替换），结果非常好 - 我没有丢失太多样本，并从中获得了平衡的数据集。
但是，我想知道匹配是否会影响我进一步的分析？对于匹配的样本，我随后进行了一些测试，例如，应用 Greenwood 公式计算了 Kaplan Meier 曲线的置信区间。我发现匹配本身会在估计中产生一些额外的“错误” - 所以我是否必须在任何时候以某种方式调整之前的匹配程序（我读到过稳健标准错误）？
我搜索了文献，但没有找到明确的建议。如果我理解正确的话，我可以向 survfit 对象添加权重、cluster 和 robust=TRUE，以考虑对数秩检验和 KM 曲线的调整版本？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655178/statistical-analyses-after-propensity-score-matching-kaplan-meier-confidence</guid>
      <pubDate>Tue, 01 Oct 2024 16:03:20 GMT</pubDate>
    </item>
    <item>
      <title>是否可以获得顺序统计量的中位数或众数？</title>
      <link>https://stats.stackexchange.com/questions/655162/can-median-or-mode-of-the-order-statistics-be-obtained</link>
      <description><![CDATA[假设 $X_1, X_2,\cdots, X_n$ 是来自连续概率分布的随机样本，大小为 $n$，该分布具有累积分布函数 (CDF) $F(x)$ 和概率密度函数 (PDF) $f(x)$。令 $X_{(1:n)}\leq X_{(2:n)}\leq\cdots\leq X_{(n:n)}$ 表示相应的顺序统计量。 $r^{th}$ 阶统计量 $X_{r:n}$ 的 PDF 由以下公式给出；
$$f_{r:n}(x)=\frac{n!}{(n-r)!(r-1)!}[F(x)]^{r-1}[1-F(x)]^{n-r}f(x)$$
而相应的 $r^{th}$ 阶统计量的 $1^{st}$ 阶矩由以下公式给出；
$$E(X_{r:n})=\mu_{r:n}=\frac{n!}{(n-r)!(r-1)!}\int_{-\infty}^{\infty}x[F(x)]^{r-1}[1-F(x)]^{n-r}f(x)dx$$
已证明，只要 $E(X)$ 存在，$\mu_{r:n}$ 也存在。
现在，在柯西分布、log-t 分布和逆威布尔分布等许多分布中，有限矩并不存在。在这种情况下，我们能得到 $X_{r:n}$ 的中位数或众数吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655162/can-median-or-mode-of-the-order-statistics-be-obtained</guid>
      <pubDate>Tue, 01 Oct 2024 10:25:29 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 秩和检验 W=0 但 p<0.05？</title>
      <link>https://stats.stackexchange.com/questions/655159/wilcoxon-rank-sum-test-w-0-but-p0-05</link>
      <description><![CDATA[在 R 中执行 Wilcoxon 秩和检验时，我有时会得到 0 的 W 值，但 p 值却很显著。由于 R 计算 W 的方式是将一个组的秩和减去预期的秩和，我不明白为什么这个结果会是 0，但仍然拒绝零假设。如果其中一个组的秩和等于预期的，那么另一个组的秩和不应该也等于预期的，因此没有差异，即零假设成立？
非常感谢，
Ser
PS 我是新手，我不知道如何交叉引用另一篇文章，但 R 计算 W 的方式在一篇名为“Wilcoxon 秩和检验正确向量顺序”的文章中得到了很好的解释]]></description>
      <guid>https://stats.stackexchange.com/questions/655159/wilcoxon-rank-sum-test-w-0-but-p0-05</guid>
      <pubDate>Tue, 01 Oct 2024 09:20:18 GMT</pubDate>
    </item>
    <item>
      <title>条件概率分布的建模方法，应用于 IPW 的倾向得分估计（因果推断）</title>
      <link>https://stats.stackexchange.com/questions/655154/modeling-approaches-for-conditional-probability-distribution-applied-to-propens</link>
      <description><![CDATA[我正在尝试理解并理想地实施逆概率加权方法来估计因果关系。到目前为止，我的资源是 Pearl 的 Primer 和《假如？》一书。
对于二元处理，似乎一种常见的方法是简单的逻辑回归。对于非二元处理，我不太确定。可以使用线性模型或 GAM 来模拟 $$W^A=\frac{1}{f(A|Y)}.$$ 中的条件分布
然而，这似乎对模型的选择很敏感。对我来说，使用机器学习或神经网络来计算这些权重似乎非常有吸引力。目前，我真的不知道如何使用任何因果推理包或它们是如何工作的。对条件分布进行建模比使用机器学习对条件期望进行通常的建模要困难一些，但我已尝试研究现有的方法。似乎可以使用分位数回归，只需修改损失函数，然后计算分位数网格即可。我还听说过其他方法，如 VAE、正则化流或贝叶斯神经网络（我对后两种方法的工作原理一无所知）。
您将如何解决这个问题？哪种方法可行？当前的统计软件做了什么？我还希望得到有关 R/python 是否更适合使用统计库的建议。目前，我一直在尝试用 Python 实现一些理论，但这个领域很大，我有点迷茫。
非常感谢您的任何回答。]]></description>
      <guid>https://stats.stackexchange.com/questions/655154/modeling-approaches-for-conditional-probability-distribution-applied-to-propens</guid>
      <pubDate>Tue, 01 Oct 2024 07:47:46 GMT</pubDate>
    </item>
    </channel>
</rss>