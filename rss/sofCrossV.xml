<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 11 Apr 2024 06:18:47 GMT</lastBuildDate>
    <item>
      <title>基于缺失数据模式组合回归模型</title>
      <link>https://stats.stackexchange.com/questions/644774/combining-regression-models-based-on-missing-data-patterns</link>
      <description><![CDATA[我有一个数据集，其中包含一些缺失模式。对于这个数据集，我有一个完整的训练集，包含所有输入特征。我的测试集对因变量有完整的观察结果，但输入特征存在一些缺失数据的模式。下面我举一个例子：
示例数据集
# 生成缺少数据模式的假测试
subset1 &lt;- data.frame(yield = rnorm(500, 1000, 100)) %&gt;%
  变异(var1 = 产量 * rnorm(500, 100, 5))

subset2 &lt;- data.frame(yield = rnorm(500, 1000, 100)) %&gt;%
  变异(var2 = 产量 * rnorm(500, 100, 10),
         var3 = -产量 * rnorm(500, 100, 4))

subset3 &lt;- data.frame(yield = rnorm(500,1000,100)) %&gt;%
  变异(var1 = 产量 * rnorm(500, 100, 5),
         var3 = -产量 * rnorm(500, 100, 4))

测试 &lt;- plyr::rbind.fill(subset1,subset2,subset3)

# 训练集有完整的观察结果
训练 &lt;- data.frame(yield = rnorm(500,1000,100)) %&gt;%
  变异(var1 = 产量 * rnorm(500, 100, 5),
         var2 = 产量 * rnorm(500, 100, 10),
         var3 = -产量 * rnorm(500, 100, 4))

md.pattern(plyr::rbind.fill(测试，训练))


缺失数据模式
注意第一行是训练集，其他行是测试集

我想对此数据集执行回归，但我对使用插补持谨慎态度，除非我有充分的理由。当然，我可以只删除包含丢失数据的行，但这将删除数据集的很大一部分。我遇到过简化建模的概念，它标识了测试集中缺失数据的不同模式，基于完整的子集训练单独的模型。根据我对这个概念的理解，这就是我尝试过的：
# 查看测试集上缺失的数据模式
模式 &lt;- 小鼠::md.pattern(test,plot=F)

# 启动一个列表以将子集放入其中
model_list &lt;- 列表()

for (i in 1:(nrow(pattern) - 1)) {
  # 获取缺失的数据模式
  cols_with_no_missing &lt;- 名称(which(pattern[i, -ncol(pattern)] == 1))

  # 根据此模式对数据集进行子集化
  subset_df &lt;- 测试 %&gt;%
    选择（all_of（cols_with_no_missing））％&gt;％
    na.省略()

  # 仅使用这些列训练模型
  数据 &lt;- 训练 %&gt;%
    选择（all_of（cols_with_no_missing））
  
  mod &lt;- 训练（产量 ~ .,
               数据=数据，
               方法 = &#39;lm&#39;,
               trControl = trainControl(方法 = &#39;repeatedcv&#39;,
                                        数量 = 10,
                                        重复次数 = 10))
  
  # 获取一些模型统计数据
  obspred &lt;- data.frame(obs=subset_df$yield,
                        pred = 预测(mod,newdata =subset_df))
  
  n_obs &lt;- nrow(obspred)
  rsq &lt;- 摘要(mod)$r.squared
  
  # 创建一个情节
  plt &lt;- obspred %&gt;%
    ggplot(aes(x = obs, y = pred)) +
    几何点() +
    geom_abline(斜率 = 1) +
    注释（“文本”，x = -Inf，y = Inf，
             标签=粘贴(粘贴(&#39;n&#39;,n_obs,sep=&#39;=&#39;),
                           粘贴（&#39;R²&#39;，圆形（rsq，2），sep =&#39;=&#39;），
                           粘贴（&#39;产量&#39;，粘贴（cols_with_no_missing[-1]，折叠=&#39;+&#39;），sep=&#39;〜&#39;），
                           九月=&#39;\n&#39;),
             hjust = -0.1，vjust = 1，大小 = 4)

  model_list[[i]] &lt;- plt
}

# 比较模型测试性能
图书馆（拼凑而成）
包裹图（模型列表）+情节布局（轴=&#39;收集&#39;）


测试性能

我的问题

我想知道使用这种方法会产生什么后果，或者是否有更合适的方法来做类似的事情？
您能否创建某种集成模型，根据可用功能选择适当的子模型？如果是这样，您将如何将不断变化的准确性（根据可用功能而变化）纳入其中？

我的实际数据集比这个示例大得多（约 90,000 个观测值），具有 25 个特征，因此实际上我将使用随机森林回归，但（我认为？？）原理应该类似。]]></description>
      <guid>https://stats.stackexchange.com/questions/644774/combining-regression-models-based-on-missing-data-patterns</guid>
      <pubDate>Thu, 11 Apr 2024 04:01:55 GMT</pubDate>
    </item>
    <item>
      <title>关于分层对数秩检验的最早论文</title>
      <link>https://stats.stackexchange.com/questions/644772/earliest-paper-on-stratified-log-rank-test</link>
      <description><![CDATA[最早提出对数秩检验的分层版本的论文是什么？
不幸的是，在教科书中查找既定统计程序的引文/参考文献很困难。]]></description>
      <guid>https://stats.stackexchange.com/questions/644772/earliest-paper-on-stratified-log-rank-test</guid>
      <pubDate>Thu, 11 Apr 2024 03:24:52 GMT</pubDate>
    </item>
    <item>
      <title>使用论文中的 GEE 重现简单交叉试验的分析</title>
      <link>https://stats.stackexchange.com/questions/644771/reproduce-an-analysis-of-a-simple-crossover-trial-using-gee-from-a-paper</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644771/reproduce-an-analysis-of-a-simple-crossover-trial-using-gee-from-a-paper</guid>
      <pubDate>Thu, 11 Apr 2024 02:18:08 GMT</pubDate>
    </item>
    <item>
      <title>如何计算下面的Dirichlet分布和Beta分布的期望？</title>
      <link>https://stats.stackexchange.com/questions/644769/how-to-calculate-the-expectation-of-the-following-dirichlet-distribution-and-bet</link>
      <description><![CDATA[这是我研究中的一个问题，涉及基于 LDA 的模型的平均场假设的变分 EM 算法的推导。$$E_{q(\psi, \boldsymbol{\varphi} \mid \boldsymbol{\lambda}, \boldsymbol{\mu})}[\log{((1-\psi)\cdot \varphi_{v} +\psi)}]$$&lt; /跨度&gt;
其中 $\psi$ 和 $\boldsymbol{\varphi}$ 是独立的， $\psi \sim \mathrm{Beta}(\lambda_1, \lambda_2), \boldsymbol{\varphi} = (\varphi_1, \varphi_2,\cdots, \varphi_V) \sim \mathrm{Dir} (\boldsymbol{\mu})$]]></description>
      <guid>https://stats.stackexchange.com/questions/644769/how-to-calculate-the-expectation-of-the-following-dirichlet-distribution-and-bet</guid>
      <pubDate>Thu, 11 Apr 2024 02:03:03 GMT</pubDate>
    </item>
    <item>
      <title>如何确定时间序列和预测的统计显着性？</title>
      <link>https://stats.stackexchange.com/questions/644762/how-to-determine-statistical-significance-for-a-time-series-and-forecasts</link>
      <description><![CDATA[通过一个简单的死亡率示例和基本的三年平均基线：
df &lt;- tibble(
  年份 = 2017:2022,
  实际 = c(904, 889, 839, 913, 835, 836)
）
df$预测 &lt;- 代表(平均值(df$实际), 6)
df$diff &lt;- df$实际 - df$预测
df
# 小题：6 × 4
# 年实际预测差异
# ;   
#1 2017 904 869. 34.7
#2 2018 889 869. 19.7
#3 2019 839 869。-30.3
#4 2020 913 869. 43.7
#5 2021 835 869。-34.3
#6 2022 836 869。-33.3

确定值 2020:2022 本身是否以及累计代表统计数据的正确方法是什么。符号。与之前的观察值（即预测）相比有何变化？]]></description>
      <guid>https://stats.stackexchange.com/questions/644762/how-to-determine-statistical-significance-for-a-time-series-and-forecasts</guid>
      <pubDate>Wed, 10 Apr 2024 23:08:37 GMT</pubDate>
    </item>
    <item>
      <title>逻辑多项式模型的对数似然的详细推导</title>
      <link>https://stats.stackexchange.com/questions/644756/detailed-derivation-for-the-log-likelihood-of-a-logistic-multinomial-model</link>
      <description><![CDATA[我正在开发一些涉及逻辑正态多项式模型的贝叶斯模型。但是，我对如何表达多项式部分感到很困惑。
传统上，多项式逻辑回归的完全似然可以通过所有个体（i）和所有类别（j）上的softmax函数来表达，例如：
$$
P(y | X\beta) = \prod_i \prod_j \frac{\exp(x_i \beta_j)}{\sum_j \exp(x_i \beta_j)}^{y_{ij}}
$$
对数似然为
$$
\sum_i \sum_j y_{ij}x_i \beta_j - \sum_i \sum_j y_{ij}\log(\sum_j \exp(x_i \beta_j))
$$
我在几个资源中发现最后一个数量可以表示为：
$$
\sum_i \sum_j y_{ij}x_i \beta_j - \sum_i \log(\sum_j \exp(x_i \beta_j))
$$
但是目前尚不清楚作者是如何获得最后一个表达式的。我觉得我错过了一些假设或技巧。
有人可以解释一下如何获取最后的数量或指向相关资源吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644756/detailed-derivation-for-the-log-likelihood-of-a-logistic-multinomial-model</guid>
      <pubDate>Wed, 10 Apr 2024 22:10:52 GMT</pubDate>
    </item>
    <item>
      <title>一致性证明中的随机有界性</title>
      <link>https://stats.stackexchange.com/questions/644755/stochastic-boundedness-in-consistency-proof</link>
      <description><![CDATA[我正在阅读Knight 和 Fu (2000)，套索渐近-类型估计器，我不明白为什么 (6) 和 (7) 暗示定理 1 的一致性（在下面复制并粘贴）。
我熟悉标准的 Newey 和 McFadden 一致性条件 - $Q_n$ 到 $Q_0$（这是公式 6），$Q_0$ 的连续性，以及 $Q_0 $ 有一个独特的最大化器 - 我知道它们可以被大大削弱。但我从未在 $Q_n$ 的最大化器上见过类似 (7) 的条件。
]]></description>
      <guid>https://stats.stackexchange.com/questions/644755/stochastic-boundedness-in-consistency-proof</guid>
      <pubDate>Wed, 10 Apr 2024 22:10:19 GMT</pubDate>
    </item>
    <item>
      <title>当所有变量都是因子时，残差在逻辑回归中重要吗？</title>
      <link>https://stats.stackexchange.com/questions/644737/are-residuals-important-in-logistic-regression-when-all-variables-are-factors</link>
      <description><![CDATA[我有一个关于逻辑回归模型中残差的概念性问题。
据我所知，对于线性回归，残差代表观察值和拟合值之间的差异。线性回归模型可以根据拟合值与观测值的偏差（偏差）来评估，并且有各种统计数据使用偏差来评估拟合优度，例如众多 R2 统计数据之一的 AIC。&lt; /p&gt;
我可以看到逻辑回归中的情况是这样的，其中至少一个变量（响应变量或解释变量）是连续的。
我不太清楚的是，当所有变量都是因子时，残差的作用。
假设我有一个模型，试图预测结果 A 对结果 B 的选择，并且解释变量都是二元的，或者具有阶乘水平“是、否”。或“选项 1、选项 2、选项 3”。
在这种情况下，残差代表什么？其实，“距离”并不大。之间的价值观对吗？对我来说似乎有点抽象。
我读过的有关逻辑回归的大多数资源都涉及至少包含一个连续变量的示例，很少涉及所有变量都是阶乘的情况。
我读到的一个来源表明，对于这些情况，像 Nagelkerke psuedo-R2 这样的统计数据是因为总方差的比例“概念上不太清晰”。
我认为人们可以为 AIC 提出同样的理由。
所以我的总体问题是，如果残差是确定回归模型拟合优度的关键因素，但它们在逻辑回归模型中并不那么相关，那么如何评估模型中的拟合优度纯阶乘变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/644737/are-residuals-important-in-logistic-regression-when-all-variables-are-factors</guid>
      <pubDate>Wed, 10 Apr 2024 17:05:12 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中实现 Newey-West 标准错误？</title>
      <link>https://stats.stackexchange.com/questions/644765/how-to-implement-newey-west-standard-errors-in-r</link>
      <description><![CDATA[我正在尝试实施 newey-west 标准错误来纠正我在使用 OLS 进行回归时遇到的自相关问题。
但是这些严重的错误只会让我的结果变得不那么重要。
我已经对一个常数进行了仅因变量的回归。
我得到了输出并检查了残差的自相关性，结果表明存在自相关性。
然后我应该使用 newey-west 标准错误重新运行回归。我使用命令：
robust_se &lt;- vcovHAC（模型，类型 =“HC”，滞后 = 4）
输出 &lt;- coeftest(模型, vcov.=robust_se)
打印（输出）

但是根据这些结果，当纽维-韦斯特误差应该起到相反的作用时，我的系数现在变得不那么重要了。
我的 t-stat 值从 1.716 降到了大约 0.9
我真的不明白这是怎么回事。这段代码有问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644765/how-to-implement-newey-west-standard-errors-in-r</guid>
      <pubDate>Wed, 10 Apr 2024 12:56:58 GMT</pubDate>
    </item>
    <item>
      <title>分割稀疏数据集时生成没有数据的集合的概率</title>
      <link>https://stats.stackexchange.com/questions/644617/probability-of-making-a-set-with-no-data-when-splitting-a-sparse-dataset</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644617/probability-of-making-a-set-with-no-data-when-splitting-a-sparse-dataset</guid>
      <pubDate>Tue, 09 Apr 2024 07:57:09 GMT</pubDate>
    </item>
    <item>
      <title>相等样本量与相等样本密度的相对重要性</title>
      <link>https://stats.stackexchange.com/questions/644586/relative-importance-of-equal-sample-size-vs-equal-sample-density</link>
      <description><![CDATA[我正在对规定火灾的影响进行植被研究。我有一个将被烧毁的实验区和一个不会被烧毁的对照区。实验区域存在三种类型的植被，因此我根据每种植被类型的相对大小（面积）成比例对调查位置进行分层。对照区存在相同的三种植被类型，但每种植被类型的相对比例与实验区不同，尽管总面积（面积）非常相似。该计划是使用方差分析进行分析，查看火灾前后的数据。
我的问题是，保持相等的样本量与相等的样本密度的相对重要性是什么？
换句话说，我应该在每个控制层中采样与其等效实验层相同数量的点数，还是应该以与其等效实验层相同的密度对控制层进行采样？在第二个选项中，由于总体区域相同，因此总体样本量将相同，但控制区和实验区之间各个地层的样本量会不同。
在线搜索显示了几乎无穷无尽的有关样本大小的信息，但有关样本密度的信息较少，而且我没有找到任何对两者进行比较的信息。
注意：从技术上讲，我相信这里只有一个样本大小，因为处理（火）仅应用于一个区域。我所说的样本实际上是重复的，因为它们并不相互独立，但我认为想法是相同的，并且我认为讨论样本会引起更广泛的受众的兴趣。]]></description>
      <guid>https://stats.stackexchange.com/questions/644586/relative-importance-of-equal-sample-size-vs-equal-sample-density</guid>
      <pubDate>Mon, 08 Apr 2024 19:30:07 GMT</pubDate>
    </item>
    <item>
      <title>Gompertz AFT 模型中误差项的分布是怎样的？</title>
      <link>https://stats.stackexchange.com/questions/644010/what-is-the-distribution-of-error-term-in-gompertz-aft-model</link>
      <description><![CDATA[给定 AFT 模型 $\ln(T)=\beta+\sigma\times W$， 的分布$T$ 取决于随机项 $W$。如果 $T$ 遵循具有形状和速率的 Gompertz 分布，我如何导出 $\sigma$&lt; 的值/span&gt; 和 $\beta$ 的形状和速率？我想首先我需要知道 $W$ 的分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/644010/what-is-the-distribution-of-error-term-in-gompertz-aft-model</guid>
      <pubDate>Mon, 01 Apr 2024 08:20:34 GMT</pubDate>
    </item>
    <item>
      <title>数据与信息。这两个术语有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/618396/data-vs-information-what-s-the-difference-between-these-two-terms</link>
      <description><![CDATA[以下是“代表性”的定义：我读过无数关于数据与信息的文章，但对它们却无话可说。谁能强调一下这两者，以便我更好地理解统计科学？
数据是单个事实或统计数据的原始形式的表示。由于数据仅包含数字和数字，因此在研究人员对其进行分析或背景化之前，它没有任何意义。例如，数据可以表示有关物体价格、测试分数或当前室外温度的基本数字。信息是对数据的解释，研究人员根据原始数据识别模式并得出结论。使用数据，研究人员可以就他们想要的主题得出有意义的结论。根据上下文，信息也具有不同的含义。例如，数据告诉您室外温度。一个人可能得出结论认为温度很高，而另一个人则认为温度很低。当有人描述气温很高时，他们正在提供有关他们对天气的解释的信息。
我发现的另一个例子：分析师进行需要数据和信息的市场研究。假设他们追踪 2018 年 18 岁至 24 岁的消费者在护发产品上花费的金额（代表数据）。这些信息包括该数字与前几年的比较以及对其变化原因的解释。在营销行业中，数据和解释使专业人士能够监控消费者购买行为的趋势以及产品在市场上的表现。
此电子表格中的数据是什么，信息是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/618396/data-vs-information-what-s-the-difference-between-these-two-terms</guid>
      <pubDate>Sat, 10 Jun 2023 09:58:33 GMT</pubDate>
    </item>
    <item>
      <title>如何将具有双季节性的 GAM 拟合到每日时间序列？ （mgcv 包）</title>
      <link>https://stats.stackexchange.com/questions/612312/how-to-fit-a-gam-with-double-seasonality-to-a-daily-time-series-mgcv-package</link>
      <description><![CDATA[我正在尝试将广义加法模型调整为每日时间序列。我的目标是对我所在城市的天然气需求进行短期预测。我有 2015 年以来的数据，包括有关天气的信息（最低和最高温度）。我正在处理的数据是每日数据，并且由于我有很多年前的信息，所以我有双重季节性：每年和每周。
这是多年来历史数据的图像。我们可以看到，每年冬季（五月、六月、七月、八月、九月）需求都会增加：

这是每周数据的图像。我们可以看到，在周末，需求下降：

真正的问题如下：当尝试从 Rstudio 中的 mgcv 包调整 gam() 模型时，考虑这两个季节性因素的正确语法是什么？
我知道它应该是这样的：
&lt;前&gt;&lt;代码&gt;库(mgcv)
gam_1 &lt;- gam(gas_demand ~ s(x1, bs = &quot;cr&quot;, k = 7) +
               s(x2, bs = “ps”, k = 365),
             数据 = df,
             家庭=高斯）
#这只是一个例子，x1和x2还没有定义，他们
#应该是模型的协变量
#每日数据应存储在数据框“df”中
#我试图预测的响应变量是“gas_demand”


我是否应该在数据框中创建一个从 1 到 7 的列，具体取决于观察一周中的哪一天，以考虑到每周的季节性？
对于每年的季节性，我应该创建一个值为 1 到 365 的列（取决于一年中的日期）吗？或者值从 1 到 12 的列（具体取决于一年中的月份）？我不确定什么是正确的方法。
我的最后一个问题：对于每种类型的季节性，建议使用哪种类型的基函数？
我真的非常渴望得到答复，因为我正在努力寻找适用于这种确切类型的数据的示例。提前致谢！ :)]]></description>
      <guid>https://stats.stackexchange.com/questions/612312/how-to-fit-a-gam-with-double-seasonality-to-a-daily-time-series-mgcv-package</guid>
      <pubDate>Sat, 08 Apr 2023 01:17:19 GMT</pubDate>
    </item>
    <item>
      <title>准确率、精确率和召回率的置信区间</title>
      <link>https://stats.stackexchange.com/questions/604597/confidence-interval-for-accuracy-precision-and-recall</link>
      <description><![CDATA[分类准确率或分类误差是比例或比率。它描述了模型做出的正确或错误预测的比例。每个预测都是一个二元决策，可能是正确的，也可能是错误的，这是伯努利试验。
伯努利试验中的比例服从二项分布。对于较大的样本量（例如超过 30），我们可以用高斯分布来近似。
我们可以使用比例的高斯分布假设来计算准确度的 95% 置信区间：
半径 = z * sqrt((精度 * (1 - 精度)) / n)
其中 n 是数据集的大小，z 是高斯分布的标准差数（95% 区间的 z = 1.96）。
我们是否可以使用相同的方法来计算精度和召回率，最终也基于正确预测的比例？]]></description>
      <guid>https://stats.stackexchange.com/questions/604597/confidence-interval-for-accuracy-precision-and-recall</guid>
      <pubDate>Tue, 07 Feb 2023 17:05:36 GMT</pubDate>
    </item>
    </channel>
</rss>