<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 08 Mar 2024 21:12:44 GMT</lastBuildDate>
    <item>
      <title>负二项式回归与调查权重的交互作用的事后检验？</title>
      <link>https://stats.stackexchange.com/questions/642186/post-hoc-tests-of-interaction-for-a-negative-binomial-regression-with-survey-wei</link>
      <description><![CDATA[我使用 R 包 survey 和函数 svyglm() 运行了带有调查权重的负二项式回归，并观察到了显着的交互效应（woohoo！）。现在我想使用事后测试来了解交互。我尝试使用包 emmeans 但出现错误。有什么想法如何做这种事情（最好是在 R 中，尽管手动/准手动或其他软件系统也很好）？下面是 MWE。
install.packages(c(“调查”, “emmeans”))
图书馆（调查）
图书馆（emmeans）

# 模拟一些数据
设置.种子(123)
n &lt;- 200
df &lt;- data.frame(
  y = rpois(n, lambda = 2), # 模拟计数数据
  预测器1 =因子（样本（c（“A”，“B”，“C”），n，替换= TRUE）），
  预测器2 =因子（样本（c（“X”，“Y”），n，替换= TRUE）），
  weights = runif(n, 0.5, 2), # 模拟权重
  cluster = Factor(rep(1:20,each = 10)), # 模拟的簇ID
  地层 = 因子(rep(1:4,each = 50)) # 模拟地层
）

# 创建调查设计
des &lt;- svydesign(ids = ~cluster, 层 = ~strata, 权重 = ~weights, 数据 = df)

# 拟合模型
模型 &lt;- svyglm(响应 ~ 预测器 1 * 预测器 2, 设计 = 设计, 系列 = quasipoisson())

# 估计交互项的边际均值
emm_interaction &lt;- emmeans(模型, ~预测器1 * 预测器2)

# 交互项的成对比较
pairs_interaction &lt;-pairs(emm_interaction)

# 比较总结
摘要（pairs_interaction）

当我执行 emm_interaction &lt;- emmeans(model, ~ Predictor1 * Predictor2) 时，我收到以下错误消息。
ref_grid(object, ...) 中的错误：我们无法重建数据。
需要的变量是：
    预测器 1 预测器 2
这些实际上是常数吗？ （通过“params=”指定）
 尝试使用 &#39;data = &quot;&lt;数据集名称&gt;&quot;&#39; 重新运行
]]></description>
      <guid>https://stats.stackexchange.com/questions/642186/post-hoc-tests-of-interaction-for-a-negative-binomial-regression-with-survey-wei</guid>
      <pubDate>Fri, 08 Mar 2024 20:37:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么直观上标准差是获得中心极限定理的正确尺度？</title>
      <link>https://stats.stackexchange.com/questions/642185/why-intuitively-is-standard-deviation-the-correct-thing-to-scale-to-get-central</link>
      <description><![CDATA[首先我要说的是，我已经知道了所有严格的公式，但让我解释一下为什么我仍然感觉我的理解中缺少一些东西。没有必要 &gt; 对于任何答案，例如i.i.d 之和的方差计算随机变量！这不是这个问题的目的。
基本上，这可以归结为@whuber的惊人答案中的这个问题https://stats.stackexchange.com/a/ 3904/264044：
&lt;块引用&gt;

这个总和有什么特别之处？为什么我们没有其他数字数学组合（例如它们的乘积或最大值）的中心极限定理？ （事实证明我们确实如此，但它们并不那么普遍，也不总是有如此清晰、简单的结论，除非它们可以简化为 CLT。） $m_n 的序列$ 和 $s_n$ 并不唯一，但它们几乎是唯一的，因为最终它们必须逼近期望$n$ 票的总和以及总和的标准差分别...

标准差是衡量值分布的一种方法，但它绝不是唯一的方法，也不是最“自然”的方法。无论是历史上还是许多应用程序。 （例如，许多人会选择与中位数的中值绝对偏差之类的值。 ）

为什么 SD 以如此重要的方式出现？



更严格地说：我们有 $S_n$ i.i.d 总和。 $X_n$。例如，我们可以绘制二项式系数（伯努利/拉德马赫的 i.i.d. 和），并注意到它们似乎具有“相同的形状” --- 事实上，一旦缩放$\tilde S_n:=\frac{S_n-m_n}{s_n}$，就越来越像同一个形状。找到 $m_n$ 很容易：这是一个线性转变，并且期望是线性的，一切都很好。我们假设 $X_n$ 被转换为平均值 $0$。
但现在我们必须弄清楚是什么$s_n$“保持形状”。我们的想法是“接近某种极限形状”。当然是关于分布收敛的陈述，分布收敛意味着特别是所有时刻都会收敛/稳定到某个值，事实上更一般地说，所有 $\mathbb E[f (\tilde S_n)]$ 应该收敛/稳定到某个值。
不知何故，在 $f$ 的所有这些选择中，我们选择 $ f(x)=x^2$，并且由于一些代数奇迹，事情完美地进行，我们看到 $s_n$ 必须是（或至少收敛到 $n\to\infty$) 的某个常数倍数 $\sqrt n$ .
所以基本上，从这个角度来看，我们看到 $s_n$ 在某种意义上是非常基本/普遍的（正是这些价值观使得 $\mathbb E[f(\tilde S_n)]$ 对所有“nice”稳定 $f$)，但只是由于对于一些代数奇迹来说，只有对于 $f(x)=x^2$ ，我们才能显式计算 $s_n$。所以它几乎看起来像“2”。 $s_n \asymp n^{1/2}$ 的性质是偶然的，但“通用性”却是偶然的。另一方面，$s_n$ 的结果告诉我们，这并非偶然——这是完全不可避免的。
&lt;块引用&gt;
问题：有人可以阐明为什么 $s_n \asymp n^{1/2}$ 的更深层次原因吗？也许即使可以使用不同的 $f$ 进行计算，并看到仍然 $n^{1/2 }$ 弹出，这会很有洞察力吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/642185/why-intuitively-is-standard-deviation-the-correct-thing-to-scale-to-get-central</guid>
      <pubDate>Fri, 08 Mar 2024 20:24:58 GMT</pubDate>
    </item>
    <item>
      <title>当数据集是配对和未配对的组合时要执行哪种假设检验？</title>
      <link>https://stats.stackexchange.com/questions/642184/which-hypothesis-testing-to-perform-when-dataset-is-combination-of-paired-and-un</link>
      <description><![CDATA[我希望得到您的帮助，了解为以下问题选择哪种假设检验方法。
这是我的数据集的示例。
12月份，我们收集了超过90公里/小时的车速数据。有约1200辆车。我们实施了一些可能（也可能不会）影响速度的措施。然后在二月份再次收集数据。车辆数量可能会有所不同，可能会添加一些新车辆，也可能会删除一些新车辆。我想了解一下我们采取的措施对速度有没有影响。
我采取的方法是统计每天车辆超速超过 90 公里/小时的情况。因此，12 月有 31 个数据点，2 月有 20 个数据点。
我有点困惑数据集是否应该被视为配对或不配对。我们可能会记录相同车辆的速度，也可能不同。请参阅下面的示例。
如果有任何关于选择哪种方法的建议，我将不胜感激。或者也许我应该采取不同的方法。
12月份初始数据

转换为

二月份也是如此。
谢谢
摩恩]]></description>
      <guid>https://stats.stackexchange.com/questions/642184/which-hypothesis-testing-to-perform-when-dataset-is-combination-of-paired-and-un</guid>
      <pubDate>Fri, 08 Mar 2024 20:20:57 GMT</pubDate>
    </item>
    <item>
      <title>回归中的虚拟变量</title>
      <link>https://stats.stackexchange.com/questions/642183/dummy-variable-in-regression</link>
      <description><![CDATA[我有一个国家数据集。一个变量被编码为 0、1、2 或 3。对于一个国家，该变量的值为 0、1 和 2（即不存在 3）。我为此变量创建了三个虚拟对象（而不是四个），并使用一个作为省略的类别。我想知道这是否正确？同样，对于另一个变量值为 0 和 1 的国家，这里使用两个虚拟变量合适吗？非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/642183/dummy-variable-in-regression</guid>
      <pubDate>Fri, 08 Mar 2024 20:17:33 GMT</pubDate>
    </item>
    <item>
      <title>构建负二项式分布联合概率的单边假设检验</title>
      <link>https://stats.stackexchange.com/questions/642182/constructing-a-one-sided-hypothesis-test-for-joint-probabilties-of-negative-bino</link>
      <description><![CDATA[我正在研究苹果蠹蛾种群/陷阱捕捉模型。最终目标是建立一个假设检验模型，该模型将提供数据是否（在某种显着性水平$\alpha$）支持飞蛾捕获总数一代要高于一定的阈值。与我合作的种植者根据经验，能够设定“最大可容忍阈值”。为捕获总数。他们可能根据经验知道，捕获超过 700 只飞蛾的年份需要使用杀虫剂，而少于该值的年份则不需要。
首先，我有一个 Johnson-SB 分布模型（通过前几年的数据收集），该模型列出了给定热量积累量（本质上是时间）的总飞蛾捕获量的预期比例。简而言之，我有一个 CDF，它告诉我在某个时间 $x$ 平均而言，我期望捕获 $y$ 占我捕获的飞蛾总数的百分比。然后，我可以将此分布乘以某个最大值，以获得我将在陷阱中观察到的飞蛾的具体数量的期望。例如，如果我要捕获的飞蛾总数为 700 只，那么在时间 $x=150$ 时，我预计会观察到累计捕获的 $y=42$ 飞蛾。这使我能够计算任意热量累积量 $x 的预期累积捕获值 $\overline{y}_x$ $.
其次，Johnson-SB 模型列出了期望值，而负二项式模型则列出了实际观察到给定数量的累积飞蛾的某个期望值的概率密度。例如，虽然我期望在 $x=150 捕获 $y=42$ 飞蛾$，我实际上可能只捕获$y=30$，或$y=60$ 等，负二项式模型允许我构建给定期望值的 PDF。
第三，我有一组关于热量积累和累积捕获的 $n$ 观测值，我将其称为 分别为 $X$ 和 $Y$。
我最初的想法是为集合 $X$ 的真实期望值创建一个联合概率，我将其标记为 $\mu_x$，小于模型预期$\overline{y}_x$：
$$ \prod\limits_{i=1}^n P[Y_i | \mu_{X_i}\le \overline{y}_{X_i}]$$
其中，如果真实期望值小于模型期望，则观察 $Y_i$ 的概率是使用上面指定的负二项式分布的 CDF 计算的。这是我的空分布。
然而，这有一个问题，因为它是联合分布，所以当我添加新的观察结果时，它总是会变小，因为我本质上是在询问越来越具体的场景的概率。因此我需要找到某种方法来标准化这个联合概率。我的想法是创建零分布及其补集的比率，我相信它是：
$$ \frac{\prod\limits_{i=1}^n P[Y_i | \mu_{X_i}\le \overline{y}_{X_i}]}{\prod\limits_{i=1}^n 1-P[X_i | \mu_{Y_i}\le \overline{y}_{X_i}]}$$
但我不知道如何通过置信区间或 p 值来评估这个比率。我研究了似然比检验并通读了此 页面和这个文档，但我觉得我我缺乏对它的理解，无法与我一起了解我将如何使用这种方法（如果我应该的话）来解决我的问题。
您认为我目前用于解决此问题的方法是否正确？如果是，我将如何解释该比率以帮助我的种植者做出明智的管理决策？]]></description>
      <guid>https://stats.stackexchange.com/questions/642182/constructing-a-one-sided-hypothesis-test-for-joint-probabilties-of-negative-bino</guid>
      <pubDate>Fri, 08 Mar 2024 19:51:09 GMT</pubDate>
    </item>
    <item>
      <title>负 KL 散度估计</title>
      <link>https://stats.stackexchange.com/questions/642180/negative-kl-divergence-estimates</link>
      <description><![CDATA[我正在探索 KL 散度，并发现了一些有关从样本计算它的研究。在 stack-exchange 上，我发现 最小化 KL 散度相当于最小化线性回归中的平方和。
为了进一步探索这一点，我尝试为波士顿住房数据集实现 OLS 和 Ridge 回归模型，并计算论文中提到的 KL 散度。这给了我无法解释的结果。
首先，来自连续分布的 Kullback-Leibler 散度估计的估计器的 KL 散度为负。而且，与实际响应的 OLS 拟合相比，它不是负值，而对于地面实况的岭拟合来说，它是负值，这与理论情况相反。（我将负 KL 散度解释为拟合值非常好，以至于估计器只给出负值，如果我有实际的分布而不是其中的样本，则会给出零）。
有没有明确的解释为什么会发生这种情况？
PS：为了探索估计器的多维功能，我还传递了整个数据矩阵，并附加了响应/拟合值，而不仅仅是对 KL 散度估计器的响应。
这使得估计器的其余 4 个实现来自
根据我的理解，这假设存在一个潜在的概率分布，它生成协变量和响应的所有值，并且我们计算这些分布之间的 KL 散度。我认为这不应该改变任何东西，因为如果我们回到 OLS 和 KL 散度之间的等价性，我想在总和上添加一堆零并不会产生任何影响。
尽管如此，这个实验导致 GitHub 链接中估计器的所有四个实现都出现了负值。
因此，回到之前提出的问题，我如何解释 KL 散度的负估计，以及为什么会在这种情况下发生。
参考文献：
用 python 编写的估计器
佩雷斯估计器
用 python 编码的估计器论文
一维情况的计算结果

&lt;标题&gt;

估算器
d_truth_ols
d_truth_ridge
d_ols_ridge


&lt;正文&gt;

skl_efficient
0.05405258685484415
0.08663935806497296
0.04198067991782772


scipy_estimator
0.802908876382145
0.7347464259492821
0.6900877478021367


naive_estimator
0.05405258685484412
0.08663935806497293
0.04198067991782768


skl_估计器
0.05405258685484412
0.08663935806497293
0.04198067991782768


佩雷斯
-0.06423632396883772
0.021712462670751664
0.05954526258402315



多维情况的计算结果（当我传递整个数据矩阵时）-

&lt;标题&gt;

估算者姓名
KL（y_Ridge，y_Truth）
KL（y_OLS，y_Truth）
KL（y_Ridge，y_OLS）
KL（y_OLS，y_Ridge）


&lt;正文&gt;

skl_估计器
-0.12739426
-0.22722966
-0.24495304
-0.41479071


naive_estimator
-0.12739426
-0.22722966
-0.24495304
-0.41479071


skl_efficient
-0.12739426
-0.22722966
-0.24495304
-0.41479071


scipy_estimator
7.73544109
6.74554664
7.61788232
6.55798559



最后，我只是猜测 SciPy 估计器出了问题。
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642180/negative-kl-divergence-estimates</guid>
      <pubDate>Fri, 08 Mar 2024 19:38:33 GMT</pubDate>
    </item>
    <item>
      <title>估计有限混合系数的 MMD 不是二次的？</title>
      <link>https://stats.stackexchange.com/questions/642179/mmd-to-estimate-coefficients-of-a-finite-mixture-is-not-quadratic</link>
      <description><![CDATA[我试图通过匹配 RKHS 嵌入来找到相对快速的密度估计。我对我的发现感到惊讶，并希望进行健全性检查：
我有一些观察结果 $y_1, ..., y_n \in [a, b]$ 和内核 $k$ 及其 RKHS $\mathcal H$。我的观察结果的内核嵌入可以写成 $\hat \mu = \sum_{i=1}^n \beta_i k(y_i, \cdot)$。我使用带有系数的一般符号 $\beta$ ，以便该方法可以用于“经典”模型。嵌入，还有条件嵌入。
我想快速估计手头的分布，为此我考虑了 $d$ 已知密度$p_1, ... p_d$，并且我认为 $p:= \sum_{i=1}^d w_i p_i$ 这样对于所有 $i$、$w_i \geq 0$ 和  $\sum_{i=1}^d w_i =1$ 和 $\mu_p$ 其内核嵌入。我可以找到：
$$\mathbf w^* \in \arg\min \lVert \mu_p -\hat \mu \rVert_\mathcal{H}^2 \text{ 在约束下 } w_i \geq 0 \text{ 和 } \sum_{i=1}^d w_i =1$$
事实证明，通过引入 $\mu_{p_i}:= \mathbb{E}_{U\sim p_i}[k(U, \cdot)]$ $p_i$ 的内核嵌入，并使用 $\mu_p = \sum_{i=1}^ d w_i \mu_{p_i}$ 我们有：
$$\left\Vert \mu_p -\hat \mu \right\Vert_\mathcal{H}^2 = \left\Vert \sum_{i=1}^d w_i \ mu_{p_i}\right\Vert_\mathcal{H}^2-2 \sum_{i=1}^d w_i \langle \mu_{p_i} , \hat \mu \rangle_\mathcal{H}+\lVert \帽子 \mu \rVert_\mathcal{H}^2$$
对于我的最小化问题，我可以忽略最后一项，因为它独立于 $w_i$。
要计算第二个，我只需要使用复制属性，我发现：
$$\sum_{i=1}^d w_i \langle \mu_{p_i} , \hat \mu \rangle_\mathcal{H} =\sum_{i=1}^ d w_i \left(\sum_{j=1}^n \beta_j \int k(u, y_j) p_i(u) \,du \right)$$
我可以预先计算积分，然后它在 $w_i$ 的向量中呈线性，简单！
现在我遇到的问题是第一个学期。还使用我发现的定义和复制属性：
$$\left\Vert \sum_{i=1}^d w_i \mu_{p_i}\right\Vert_\mathcal{H}^2 = \sum_{i=1} ^d \sum_{i=1}^d w_i w_j \mathbb{E}_{U\sim p_i, V\sim p_j}[k(U, V)] = \sum_{i=1}^d \sum_ {i=1}^d w_i w_j \int k(u, v) p_i(u) p_j(v) \,du \,dv$$
该项在 $w_i$ 中是二次项，但是具有条目 $\int k(u, v) p_i 的矩阵(u) p_j(v) \,du \,dv$ 是对称的，但看起来不是正定的？ （至少基于我的数值实验）。这不太好：我曾希望使用“简单”的方法来实现。 $p$ 的表达式将允许我通过二次规划来解决它，并即时获得快速/相对便宜的估计。
我发现这非常令人惊讶且违反直觉，因此我有两个问题：

我的发现是否正确，还是我的疏忽或错误？
有没有什么“直观”的东西？解释为什么带有条目 $\int k(u, v) p_i(u) p_j(v) \,du \,dv$ 的矩阵有条件为正确定不是 p.d.，为什么有限混合的 MMD 表现如此糟糕？

提前致谢，干杯！]]></description>
      <guid>https://stats.stackexchange.com/questions/642179/mmd-to-estimate-coefficients-of-a-finite-mixture-is-not-quadratic</guid>
      <pubDate>Fri, 08 Mar 2024 19:10:12 GMT</pubDate>
    </item>
    <item>
      <title>从非常高维的高斯采样</title>
      <link>https://stats.stackexchange.com/questions/642178/sampling-from-a-very-high-dimensional-gaussian</link>
      <description><![CDATA[我想要一个来自高斯 $N(0,K)$ 的样本，其中 $K$ 是一个核克矩阵，因此 $K=[K_{ij}]$ 与 $K_{ij} = k(x_i,x_j)$ 对于某些正定函数$k$。第一个问题是我有兴趣评估 $x_i,x_j$ 的二维网格非常好，因此 $K$ 非常大，我无法显式计算这个矩阵。一旦我们有了 $K$ 的表示，我们就需要进行 cholesky 分解才能进行采样。我注意到这个问题之前，但答案有点模糊，没有指出任何具体的参考资料。理想情况下，我想在 Python 中执行此操作。]]></description>
      <guid>https://stats.stackexchange.com/questions/642178/sampling-from-a-very-high-dimensional-gaussian</guid>
      <pubDate>Fri, 08 Mar 2024 18:59:24 GMT</pubDate>
    </item>
    <item>
      <title>仅训练卷积神经网络最后一层的两种不同场景</title>
      <link>https://stats.stackexchange.com/questions/642177/two-different-senarios-to-train-only-the-last-layer-of-a-convolutional-neural-ne</link>
      <description><![CDATA[我有一个已经在数据 A 上训练过的卷积神经网络。该网络由特征提取层和两个分类层组成。我从头开始仅在数据 B 上训练了最后一个分类层（没有在数据 A 上训练初始权重！）。
为此，我遵循了两种不同的场景，结果截然不同。谁能帮我找出这个巨大的差异吗？
场景 1 结果
AUC=0.53 准确度=0.50 精密度=0.58 F1-Score=0.51 灵敏度=0.50 特异性=0.44
场景 2 结果
AUC=0.66 准确度=0.63 精密度=0.70 F1-Score=0.64 灵敏度=0.63 特异性=0.56
场景 1
#创建网络：
分类网络=分类器（参数[0]，参数[1]，参数[2]，参数[3]，参数[4]）
#获取state_dict：
state_dict=classifying_network.state_dict()

#加载在数据A上训练的最佳权重，用于所有特征提取和两个分类层：
optimal_weights=torch.load(folder_with_networks+network+&#39;/optimal_weights&#39;)
#创建新的权重字典，其中包含除最后一层之外的所有层的权重，最后一层是来自状态字典的随机初始值：
optimal_weights_withfirstclassificationlayer_secondrandom=optimal_weights
optimal_weights_withfirstclassificationlayer_secondrandom[&#39;classifier.2.weight&#39;]=state_dict[&#39;classifier.2.weight&#39;]
optimal_weights_withfirstclassificationlayer_secondrandom[&#39;classifier.2.bias&#39;]=state_dict[&#39;classifier.2.bias&#39;]
#加载权重：
classification_network.load_state_dict(torch.load(folder_with_networks+network+&#39;/optimal_weights_withfirstclassificationlayer_secondrandom&#39;))
    
#在冻结特征提取层和第一个分类层之后训练最后一层
classification_network.freeze_feature_extraction_first_classification()```

场景2
#读取之前在数据A上训练的权重：
optimal_weights=torch.load(folder_with_networks+network+&#39;/optimal_weights&#39;)
#删除最后一层
optimal_weights_withfirstclassificationlayer={k:v for k,v in optimization_weights.items() if k !=&#39;classifier.2.weight&#39; and k !=&#39;classifier.2.bias&#39;}
torch.save(optimal_weights_withfirstclassificationlayer,folder_with_networks+network+&#39;/optimal_weights_withfirstclassificationlayer&#39;)

#创建一个没有最后一层的网络：
分类网络 = Classifiernolastlayer(参数[0],参数[1],参数[2],参数[3],参数[4])
#加载上面提到的权重字典
classification_network.load_state_dict(torch.load(folder_with_networks+network+&#39;/optimal_weights_withfirstclassificationlayer&#39;))
#添加一个新层
分类网络.分类器.append(nn.Linear(256,1))
#在冻结特征提取层和第一个分类层之后训练最后一层
classification_network.freeze_feature_extraction_first_classification()
]]></description>
      <guid>https://stats.stackexchange.com/questions/642177/two-different-senarios-to-train-only-the-last-layer-of-a-convolutional-neural-ne</guid>
      <pubDate>Fri, 08 Mar 2024 18:55:13 GMT</pubDate>
    </item>
    <item>
      <title>GLMM 伽马分布的效应大小</title>
      <link>https://stats.stackexchange.com/questions/642176/effect-size-with-glmm-gamma-distribution</link>
      <description><![CDATA[回应上一个问题提出的关于广义线性混合效应大小的问题由于模型具有二项式分布，因此估计效应大小并不简单。我有一个包含连续预测变量的数据集，其中每个响应变量的 family = gamma (link = “log”)。
对每个响应进行模型选择后，我确定了一个始终出现在我的最佳模型中的预测变量。是否有一种方法可以直观地表示该预测变量与每个响应变量之间关系的大小，类似于使用 sjPlot::plot_model？尽管我已经利用 ggeffects 以图形方式描述了该模型，但我正在寻求一种简单的方法来展示该预测变量与每个响应之间关系的强度。]]></description>
      <guid>https://stats.stackexchange.com/questions/642176/effect-size-with-glmm-gamma-distribution</guid>
      <pubDate>Fri, 08 Mar 2024 18:54:41 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中跨不同级别重复测量来分析二进制数据</title>
      <link>https://stats.stackexchange.com/questions/642175/analyzing-binary-data-with-repeated-measures-across-different-levels-in-r</link>
      <description><![CDATA[我有这个数据框：https://i.stack.imgur.com/EGh1z .png
它是受试者在 2 个环境条件下对 4 个不同测试的二元记录响应（重复测量）（2x4 因子设计，对两个因素进行重复测量）。
我正在寻找条件变化可能对受试者的反应产生的任何统计显着差异，并解释不同的测试和重复测量。
我尝试在 R 中进行 Cochran&#39;s Q 测试。这是我第一次尝试此测试，每个块进行多个观察并没有帮助，而且我经常遇到错误。我想到的另一个解决方案是将响应变量更改为受试者响应为“1”的次数百分比。每个测试有四次重复测量。这样，二元响应将变为数字，我可以进行重复测量方差分析吗？
我很感激您的想法！]]></description>
      <guid>https://stats.stackexchange.com/questions/642175/analyzing-binary-data-with-repeated-measures-across-different-levels-in-r</guid>
      <pubDate>Fri, 08 Mar 2024 18:53:51 GMT</pubDate>
    </item>
    <item>
      <title>是否应该使用整个数据集的迁移学习来调整单个模型？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/642173/should-transfer-learning-from-the-whole-data-set-be-used-tuning-individual-model</link>
      <description><![CDATA[我正在使用神经网络进行时间序列的异常检测。我的计划是根据历史（基线）数据训练 CNN 或 LSTM 模型，然后应用它来检测新数据流中的异常。有一个共享相同上下文的大型时间序列数据库。我看到两条路：

选项 A：在整个数据集或其代表性样本上训练模型。然后使用迁移学习来调整各个时间序列的模型。我预计不会有什么好处，例如快速调整单个记录的最终模型，所有单个时间序列模型将共享相同的上下文，并且最终调整进度可能会暗示异常值。
选项 B：只需单独处理每个时间序列，因为选项 A 太过分了。

因此这里有一个问题：选择选项A有用吗？我以前从未使用过迁移学习，希望得到实用的见解和评论。]]></description>
      <guid>https://stats.stackexchange.com/questions/642173/should-transfer-learning-from-the-whole-data-set-be-used-tuning-individual-model</guid>
      <pubDate>Fri, 08 Mar 2024 18:09:36 GMT</pubDate>
    </item>
    <item>
      <title>迁移学习期间波动的验证损失和准确性 (ResNet50) - FER+ 数据集</title>
      <link>https://stats.stackexchange.com/questions/642170/fluctuating-validation-loss-accuracy-during-transfer-learning-resnet50-fer</link>
      <description><![CDATA[我正在尝试构建一个用于图像分类的 CNN 模型，更具体地说，使用 FER+ 数据集进行情感分类，但事实证明该模型很难使用。
我尝试了多种模型变体，从“从头开始”到我当前的最佳解决方案 - 迁移学习。到目前为止，我最好的结果来自于使用 ResNet50 或 MobileNetV2 作为我的基本模型以及我自己的自定义可训练头。更具体地说，我截断了基本模型，只冻结前几个块，同时留下最接近头部的块，可训练。到目前为止，这种特征提取和微调的组合已达到 93-95% 的验证准确率（取决于 ResNet50 还是 MobileNetV2）。
虽然这听起来不错，但在训练时会出现问题，其中验证损失和验证损失会增加。尽管尝试进行正则化、向数据生成器添加更多增强功能并在微调时降低学习率，但准确性仍波动很大。下图是我使用 ResNet50 作为基础模型时的训练结果。此外，在混淆矩阵中，您还可以看到它如何从未从测试集中正确预测任何“厌恶”图像，其中包含“厌恶”类中的 20 个图像。此外，无论我使用 ResNet 还是 MobileNet 作为我的基础模型，我似乎仍然在损失和准确度上得到相同的波动。
有关我的模型和训练的一些详细信息：

基础模型：使用“imagenet”权重的 ResNet50 或 MobileNetV2
损失函数：分类交叉熵
优化器：Adam
纪元：100
学习率：0.001



就预处理而言，我重新缩放了图像，而我的最佳结果来自于仅对训练数据应用随机水平翻转。 FER+ 图像的标准灰度为 48x48，因此我将采样上采样到 224x224 并转换为 RGB。我的网络非常深，因此我想减少在小尺寸（例如 1x1、2x2...）上运行的任何卷积实例。
我还应该注意到，数据集本质上是相当不平衡的，这通常需要对类权重进行一些实现，但是，我发现当使用类权重时，我的结果会变得明显更差，验证量减少了 15%-20%准确性以及混淆矩阵的不良结果。下面是训练集的类别分布图。

如何在训练过程中稳定验证损失和准确性？]]></description>
      <guid>https://stats.stackexchange.com/questions/642170/fluctuating-validation-loss-accuracy-during-transfer-learning-resnet50-fer</guid>
      <pubDate>Fri, 08 Mar 2024 17:29:45 GMT</pubDate>
    </item>
    <item>
      <title>我想使用 5 个数据点创建波动率分数</title>
      <link>https://stats.stackexchange.com/questions/642169/i-want-to-create-a-volatility-score-using-5-data-points</link>
      <description><![CDATA[我想使用过去 5 年的活动来衡量客户群的波动性。即 5 年期间按年计算的购买总额。
我计划使用这个公式来计算方差（即找到平方偏差的平均值）。
[![方差计算][1]][1]
我想知道这是否是回答这个问题的正确计算方法 - 哪些客户每年波动性最大。我主要看到与证券/股票相关的波动性，但这是一个不同的用例。这是正确的方法还是有更好的方法？
编辑：我不确定这是正确的公式。考虑这些例子：

记录 1：2020、2020、2080、2020、2020
记录 2：4、8、26、50、13

我认为记录 1 非常一致，因此它应该具有较低的方差，但方差为 576。记录 2 具有较高的变异性，但方差低于记录 1 (277)。我们有非常大的客户和非常小的客户，我想显示出无论大小的差异。有没有办法做到这一点？
[1]: https://i.stack.imgur.com/mkRLO.png]]></description>
      <guid>https://stats.stackexchange.com/questions/642169/i-want-to-create-a-volatility-score-using-5-data-points</guid>
      <pubDate>Fri, 08 Mar 2024 17:23:44 GMT</pubDate>
    </item>
    <item>
      <title>我可以找到生成内核指数的显式特征图吗？</title>
      <link>https://stats.stackexchange.com/questions/642167/can-i-find-the-explicit-feature-map-that-generates-exponent-of-a-kernel</link>
      <description><![CDATA[假设我有一个内核 $K$，以及另一个以下形式的内核：
$$
K&#39; = e^K
$$
现在我知道如何证明 K&#39; 是一个内核，我可以使用 $e^x$ 围绕 $0$,
但假设我想找到一个生成 $K&#39;$ 的显式特征图，因为 $\phi(x) $ 生成 $K$。
我该如何做到这一点，或者甚至可能吗？我正在考虑内核多项式展开的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/642167/can-i-find-the-explicit-feature-map-that-generates-exponent-of-a-kernel</guid>
      <pubDate>Fri, 08 Mar 2024 17:22:02 GMT</pubDate>
    </item>
    </channel>
</rss>