<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 30 Aug 2024 06:23:16 GMT</lastBuildDate>
    <item>
      <title>在 MCMC 中转换变量以获得与提议相匹配的先验分布</title>
      <link>https://stats.stackexchange.com/questions/653598/transforming-variables-within-mcmc-to-get-the-prior-distribution-to-match-propos</link>
      <description><![CDATA[我正在做贝叶斯 MCMC，我建议使用一些权重，比如狄利克雷分布中的 a_1:a_5，以确保总和为 1。但是，先前的（Beta）分布是基于这些权重的一些计算，b_5:b_5。我的理解是我应该进行转换。以下是 a 和 b 之间的关系：
a_1=b_1
a_2=(1-b_1)(b_2)
a_3=(1-b_1)(1-b_2)b_3
a_4=(1-b_1)(1-b_2)(1-b_3)b_4
a_5=(1-b_1)(1-b_2)(1-b_3)(1-b_4)b_5

我发现雅可比矩阵为：(a - 1)^4*(b - 1)^3*(c - 1)^2*(d - 1)
但我不确定接下来该怎么做。在找到先验密度时，我是否要将输入乘以这个雅可比矩阵？下面是我的 R 代码，好像我忽略了先前和提议之间的不匹配。
 a&lt;-rDirichlet.acomp(1,mcmc_chain_weights[i,1:5]*(tuning_parameter))
b=rep(NA,5)
b[1]&lt;-a[1]
b[2]&lt;-a[2]/((1-b[1]))
b[3]&lt;-a[3]/((1-b[1])*(1-b[2]))
b[4]&lt;-a[4]/((1-b[1])*(1-b[2])*(1-b[3]))
b[5]&lt;-a[5]/((1-b[1])*(1-b[2])*(1-b[3])*(1-b[4]))

Hastings_ratio&lt;-L()*dbeta(b,1,tau)*dDirichlet(a_previous,alpha=a) / ...

请注意，tau 是一个常数，我将似然函数留空，因为它在这里无关紧要。如能得到任何帮助，我将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653598/transforming-variables-within-mcmc-to-get-the-prior-distribution-to-match-propos</guid>
      <pubDate>Fri, 30 Aug 2024 03:22:33 GMT</pubDate>
    </item>
    <item>
      <title>描述辛普森多样性的概率分布</title>
      <link>https://stats.stackexchange.com/questions/653592/probability-distribution-describing-simpsons-diversity</link>
      <description><![CDATA[假设群落中有 $n$ 种丰度未知的物种。每种物种的比例为 $p_i$，即 $\sum_ip_i = 1$。辛普森多样性定义为 $S = \sum_ip_i^2$，最大值为 1，最小值为 $1/n$。
如果我们从这个种群中抽取样本，我相信我们观察到的每种物种的比例将被理解为来自 $n$ 维狄利克雷分布 $D(p_1, p_2, ... p_n)$。给定这个分布，有没有办法推导出多样性指数$S$的概率分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/653592/probability-distribution-describing-simpsons-diversity</guid>
      <pubDate>Fri, 30 Aug 2024 00:58:32 GMT</pubDate>
    </item>
    <item>
      <title>混合模型模拟研究：与线性模型（功效）和无协变量模型（1 类错误）进行比较，包 lmerTest</title>
      <link>https://stats.stackexchange.com/questions/653566/mixed-model-simulation-study-comparing-to-linear-model-power-and-model-withou</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653566/mixed-model-simulation-study-comparing-to-linear-model-power-and-model-withou</guid>
      <pubDate>Thu, 29 Aug 2024 15:59:58 GMT</pubDate>
    </item>
    <item>
      <title>SPSS 中自动删除了逻辑回归的类别</title>
      <link>https://stats.stackexchange.com/questions/653494/categories-automatically-dropped-in-spss-for-my-logistic-regression</link>
      <description><![CDATA[我的逻辑回归模型有问题。我使用 SPSS 分析一些分类 IV/2 数值变量与客户流失之间的关系（著名的 IBM Telco 数据集）。我选择了相关的因变量和所有自变量，并将其中一些标记为分类（最后一个类别作为参考）。我知道没有显示参考类别，但为什么在我的情况下会这样？我不知道该怎么做，因为我需要分析效果。
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/653494/categories-automatically-dropped-in-spss-for-my-logistic-regression</guid>
      <pubDate>Wed, 28 Aug 2024 16:34:10 GMT</pubDate>
    </item>
    <item>
      <title>使用投影将策略拟合到目标分布 $\pi$</title>
      <link>https://stats.stackexchange.com/questions/649480/fitting-a-policy-to-a-target-distribution-pi-with-projections</link>
      <description><![CDATA[给定一个离散目标分布$\mathbf{\pi}\in\Delta^n$，可以通过交叉熵损失将策略$\mathbf{p}$拟合到该分布，即最小化$-\pi^\top \log \mathbf{p}$。
现在假设$n$非常大，以至于我们无法直接观察到所有的$\pi$。相反，我们希望通过一个迭代过程进行训练，其中在每个步骤$i$中，我们都可以访问$\pi$到某个低维单纯形的投影，比如$\pi_i&#39;\in\Delta^d$。我正在尝试弄清楚如何根据 $\pi_i&#39;$ 为 $\mathbf{p}$ 制定分步目标。
最简单的做法是进行类似“子交叉熵”损失的操作，即最小化 $-\pi_i&#39;^\top \log \mathbf{p}&#39;$，其中 $\mathbf{p}&#39;$ 只是 $\mathbf{p}$ 投影到与 $\pi_i&#39;$ 相同的低维单纯形上。
但是，如果可能的话，我希望目标满足一个附加条件。固定某个步骤 $i$，让 $\mathbf{q}$ 为给定 $\pi_i&#39;$ 更新 $\mathbf{p}$ 后的新策略，并让 $D\subset [n]$ 为构成第 $i$ 个投影的总共 $n$ 个单纯形的 $d$ 个顶点。我想要 $\sum_{j\in D} p_j = \sum_{j\in D} q_j$。换句话说，我想要在策略更新后，在 $D$ 中的顶点之间保留概率质量。这似乎要求有点多，所以也许另一种条件是$\sum_{j\in D} p_j \geq \sum_{j\in D} q_j$，也就是说，更新后的概率比原始概率占用的总质量更少。
天真地执行上述“子交叉熵损失”会导致相反的行为，我们得到$\sum_{j\in D} q_j \geq \sum_{j\in D} p_j$，这实际上导致策略更加偏向它以前见过的东西。
我希望我以连贯的方式提出了这个问题，我很乐意澄清任何令人困惑的地方。我也感谢任何与这个问题相关的作品的指点。提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/649480/fitting-a-policy-to-a-target-distribution-pi-with-projections</guid>
      <pubDate>Tue, 18 Jun 2024 19:14:11 GMT</pubDate>
    </item>
    <item>
      <title>如果前几个组件大于一，那么报告某些 PC 组件的零特征值可以吗？</title>
      <link>https://stats.stackexchange.com/questions/638833/is-it-okay-to-report-zero-eigen-values-for-some-pc-components-if-the-first-few-c</link>
      <description><![CDATA[我有一个数据集，收集了 3 年内的家庭反馈。由于并非所有家庭都参与了这三次调查，因此该数据集是不平衡的。我在 stata 中运行多级 PCA 来解释内部和之间的变化。为了进行比较，我还对整个数据集运行了整体 PCA，因为数据是独立的。
内部和内部 PCA 给出了 5 个和 4 个大于 1 的特征值，但是有许多特征值恰好为零。
但是，整体 PCA 有 11 个 PC 的特征值大于 1，其余的 PC 正在缓慢减少，并且有 0.14 个特征值。
可以报告这样的结果吗？我该如何解释我的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/638833/is-it-okay-to-report-zero-eigen-values-for-some-pc-components-if-the-first-few-c</guid>
      <pubDate>Thu, 08 Feb 2024 10:13:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么结构风险最小化中的估计误差较小</title>
      <link>https://stats.stackexchange.com/questions/631038/why-is-the-estimation-error-smaller-in-structural-risk-minimization</link>
      <description><![CDATA[在这本在线《理解机器学习》一书的第 87 页中，作者写道：

与前几章讨论的 ERM 范式不同，我们不再只关心经验风险 $L_S(h)$，但我们愿意将对低经验风险的一些偏见换成对 $\epsilon_{n(h)}(m, w(n(h))\cdot\epsilon)$ 较小的类别的偏见，以便获得较小的估计错误。。

SRM 的输出 $h$ 定义为：

输出：$h\in\underset{h\in\mathcal{H}}{\arg\min}\ L_S(h)+\epsilon_{n(h)}(m, w(n(h))\cdot\delta)$。
其中 $\epsilon_n(m, \delta) := \min\ \lbrace\epsilon\in (0, 1): m_\mathcal{H_n}^{UC}(\epsilon, \delta)\le m \rbrace$，$w(n)$ 是一个从 $n\in\mathbb{N}\to[0, 1]$ 开始的函数，使得 $\sum_{n=1}^{\infty}w(n)\le1$ 且 $n(h):=\min\lbrace n: h\in\mathcal{H}_n\rbrace$

这就是学习器 $h$ 将最小化 $L_S(h)+\epsilon_{n(h)}(m, w(n(h))\cdot\delta)$ 的输出。
然而，$\epsilon_n$ 的定义是使用来自假设类 $\mathcal{H}_n$ 的 $m$ 个示例样本实现的 $L_S(h)-L_\mathcal{D}(h)$ 之间差距的最低可能上限，而估计误差定义为：
$$\epsilon_{est}:=L_\mathcal{D}(h)-\underset{h\in\mathcal{H}}{\min} L_\mathcal{D}(h).$$
此外，定理 7.4。书中显示：
$$
\mathbb{P}\lbrace S\sim\mathcal{D}^m: (\forall h\in\mathcal{H}) (L_\mathcal{D}(h)\le L_S(h) + \epsilon_{n(h)}(m, w(n(h))\cdot\delta)) \rbrace \ge 1-\delta,
$$
因此最小化 $L_S(h)+\epsilon_{n(h)}(m, w(n(h))\cdot\delta)$ 将至少有 $1-\delta$ 的概率最小化 $L_\mathcal{D}(h)$ 但它与最小化 $\epsilon_{est}$ 不同？
因此我找不到最小化 $L_S(h)+\epsilon_{n(h)}(m, w(n(h))\cdot\delta)$ 与较小的估计误差之间的联系。]]></description>
      <guid>https://stats.stackexchange.com/questions/631038/why-is-the-estimation-error-smaller-in-structural-risk-minimization</guid>
      <pubDate>Sat, 11 Nov 2023 04:37:05 GMT</pubDate>
    </item>
    <item>
      <title>我的学习曲线或模型是否存在问题，因为它从完全相反的尾端开始？</title>
      <link>https://stats.stackexchange.com/questions/628446/is-there-something-wrong-with-my-learning-curve-or-my-model-because-it-starts-at</link>
      <description><![CDATA[
如果您能查看我的图表并告诉我是否有问题，那就太好了。上下文是它使用了 MLP。]]></description>
      <guid>https://stats.stackexchange.com/questions/628446/is-there-something-wrong-with-my-learning-curve-or-my-model-because-it-starts-at</guid>
      <pubDate>Wed, 11 Oct 2023 05:19:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么训练集上的性能会随着样本数量的增加而下降？</title>
      <link>https://stats.stackexchange.com/questions/618993/why-does-the-performance-on-the-training-set-go-down-as-the-number-of-samples-in</link>
      <description><![CDATA[据我所知，有两种类型的学习曲线，一种显示随着 epoch 数量的增加而性能的进展，另一种显示随着训练数据量的增加而性能的进展。我指的是第二种。这是使用 sklearn.model_selection.learning_curve 制作的图：

我观察到我的训练指标随着训练样本数量的增加而下降。我想再检查一下我的推理是否正确。我假设这种情况发生是因为当只有少量训练数据时，模型（在这种情况下是简单的神经网络）能够准确地学习大部分训练集（甚至可能过度拟合）。因此，模型具有足够的复杂性来保存描述训练数据的信息。随着我们添加更多数据，模型“记住”训练数据的任务变得越来越困难，并且需要更复杂的模型来保持相同的训练集性能。这个推理正确吗？还是有其他因素在起作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/618993/why-does-the-performance-on-the-training-set-go-down-as-the-number-of-samples-in</guid>
      <pubDate>Sat, 17 Jun 2023 09:06:18 GMT</pubDate>
    </item>
    <item>
      <title>Python 机器学习预测模型 - 根据多个其他字符串变量预测字符串变量</title>
      <link>https://stats.stackexchange.com/questions/618785/python-machine-learning-prediction-model-predict-string-variable-based-on-mult</link>
      <description><![CDATA[我对机器学习还很陌生，所以请原谅这里的简单。可能是因为我是新手，但我似乎无法在网上找到足够相关的信息来提供帮助。
我有关于笔记本电脑、手机和打印机的数据，如下所示：
制造商、型号名称、型号 ID（以及其他一些）。
例如：
戴尔、Latitude 3000、Latitude 3340
联想、ThinkPad X1、X1 Carbon
戴尔、1100、1130 Laser
每个项目都分配有一个类别，例如笔记本电脑、手机或打印机。我有数千个项目，大多数都有类别，但少数没有（我的几个类别是空白的），我希望能够根据提供的制造商、型号名称和型号 ID 尝试预测它属于哪个类别。我知道这可能不完全“适合”某个模型，但我希望这里有人可以提供帮助。我真的是个初学者，甚至不知道我可能需要什么库。提前感谢帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/618785/python-machine-learning-prediction-model-predict-string-variable-based-on-mult</guid>
      <pubDate>Wed, 14 Jun 2023 18:50:34 GMT</pubDate>
    </item>
    <item>
      <title>样本量选择是如何进行的（通常为 $20\times (p+q)$）？</title>
      <link>https://stats.stackexchange.com/questions/612144/how-does-sample-size-selection-happen-which-is-generally-used-as-20-times-pq</link>
      <description><![CDATA[有人能解释一下样本量选择是如何进行的吗？通常用$20\times (p+q)$表示吗？这里$p$是最终模型中的参数数量，$q $是可能已检查但在此过程中丢弃的参数数量。
任何可靠的参考资料都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/612144/how-does-sample-size-selection-happen-which-is-generally-used-as-20-times-pq</guid>
      <pubDate>Thu, 06 Apr 2023 15:39:54 GMT</pubDate>
    </item>
    <item>
      <title>从区间数据中学习操作概率</title>
      <link>https://stats.stackexchange.com/questions/562851/learning-operating-probabilities-from-interval-data</link>
      <description><![CDATA[假设我有一台机器。当机器处于活动状态（操作）时，它至少运行 $\mu &gt; 0$ 时间。我知道在时间间隔 $[l, h]$（$l, h \in \mathbb R_{\ge 0}, l &lt; h$）的某个时间点，机器处于活动状态，但我不知道何时或持续多长时间（除了每个操作至少花费 $\mu$ 时间）。它可能已多次处于活动状态。
我有关于（可能重叠的）子间隔 $[l_i, h_i] \subseteq [l, h]$ 的数据，其中 $i = 1,\dots,n$ 观察到机器处于活动状态。没有观察到机器在整个子间隔内处于活动状态，但已知它至少在此间隔的某个时间点处于活动状态。[例如：办公室里有一台打印机，早上看到它在打印。几个小时后，当你回想起这件事时，你可能记不清具体时间了，但你知道最早是在 9:00，最晚是在 11:00 之间。]
我感兴趣的是机器在任何时间点 $t \in [l, h]$ 处于活动状态的（近似）概率 $\Pr (t)$。我怀疑这种近似值可以从我拥有的 $n$ 个子区间中以某种方式学习到。我是否需要施加其他假设才能使问题得到明确定义？是否有文献研究过这个问题或类似的问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/562851/learning-operating-probabilities-from-interval-data</guid>
      <pubDate>Wed, 02 Feb 2022 18:28:15 GMT</pubDate>
    </item>
    <item>
      <title>关于数据增量学习中的更新过程</title>
      <link>https://stats.stackexchange.com/questions/558874/about-update-procedure-in-data-incremental-learning</link>
      <description><![CDATA[据我所知，数据增量学习的理念在于让模型始终保持最新状态。假设我们使用语音作为输入来训练用户识别模型。因此，输入是用户的语音，输出是用户的标签（用户 1、2、...）。经过一段时间（例如几年），用户的输入分布可能会发生变化，因此我们需要调整基础模型。
这个想法在我看来是随机梯度学习（在深度学习中）的理念，我们一次只使用一个数据点来更新模型参数。
但是，我的问题是，为了用新的测试数据更新模型，我们必须有测试的标签吗？在实际情况下，这怎么可能呢？
编辑 1：我想到了一个想法，也许解决方案就是这样（完全不确定）？
我想到了一个想法。假设我们有一个针对用户 1、2 和 3 训练的深度模型。然后，有一个新的输入到达。我们的模型将其预测为用户 2（概率最高，例如考虑深度网络的 softmax 结果）。因此，在损失函数中，在反向传播时，我们将预测的标签作为新数据的真实标签（实际上我们没有该标签），作为基本事实。因此，假设 softmax 输出：
0.1 表示属于用户 1 类
0.7 表示属于用户 2 类
0.2 表示属于用户 3 类

用户 2 的概率最高，我们将传入数据的真实标签视为：
0 表示用户 1 类
1 表示用户 2 类
0 表示用户 3 类

因此，交叉熵损失计算如下：
损失 = - (0*ln(0.1) + 1*ln(0.7) + 0*ln(0.2)) = -ln(0.7) = 0.357

然后我们在整个网络中反向传播这个错误。
我需要验证，这是在现实中对数据增量学习过程所做的吗生活？]]></description>
      <guid>https://stats.stackexchange.com/questions/558874/about-update-procedure-in-data-incremental-learning</guid>
      <pubDate>Fri, 31 Dec 2021 20:21:15 GMT</pubDate>
    </item>
    <item>
      <title>如何从 SVC 分类中检索特征权重和公式</title>
      <link>https://stats.stackexchange.com/questions/556084/how-to-retrieve-feature-weights-and-formula-from-svc-classification</link>
      <description><![CDATA[我对 skit-learn 还很陌生。我一直在研究 SVC 分类问题，似乎取得了不错的效果。我正在使用 40 度的 SVC 多项式分类器；请参阅附件（哎呀无法附加）。
我如何检索特征权重和通用公式]]></description>
      <guid>https://stats.stackexchange.com/questions/556084/how-to-retrieve-feature-weights-and-formula-from-svc-classification</guid>
      <pubDate>Tue, 14 Dec 2021 15:09:56 GMT</pubDate>
    </item>
    <item>
      <title>对“在线学习”和“数据或类增量学习”感到困惑？</title>
      <link>https://stats.stackexchange.com/questions/555476/confusion-about-online-learning-and-data-or-class-incremental-learning</link>
      <description><![CDATA[我看到 stackexchange 上有一些关于该主题的帖子（example1、example2 和 example3）。然而，在这篇论文中，他们使用 SGD 作为在线学习模型。他们指出

增量学习系统由深度和在线机器学习模型组成

据我所知，在在线模型中，初始模型不可用，我们使用在线学习训练一个模型作为我们的初始模型。例如使用 SGD 的深度学习模型。此外，他们还指出了两种类型的增量学习：类增量学习 (CIL) 和数据增量学习 (DIL)。
他们还指出

请注意，OL 模型是使用从 LSTM 模型生成的特征构建的，该模型的长度可以是 64、128 或 256，具体取决于 LSTM 模型中存在的隐藏单元的数量。

那么，在线学习 (OL) 模型是一个单独的模型吗？如果是，我不明白 SGD 是如何以这种方式工作的。
我或多或少地明白，类增量学习不同于在线学习，因为它有新的类，而在线学习则不是这样。但是，我不明白在线学习和数据增量学习之间的区别。也许使用不同的损失（例如加权损失）会导致不同的学习，但我不确定。有人可以从在线、课堂增量和数据增量学习的角度给我更多解释吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/555476/confusion-about-online-learning-and-data-or-class-incremental-learning</guid>
      <pubDate>Thu, 09 Dec 2021 15:29:01 GMT</pubDate>
    </item>
    </channel>
</rss>