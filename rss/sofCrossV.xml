<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 07 Jul 2024 09:16:14 GMT</lastBuildDate>
    <item>
      <title>报告 clmms 中固定效应的重要性 - 何时使用 ANODE 表？</title>
      <link>https://stats.stackexchange.com/questions/650628/reporting-significance-of-fixed-effects-in-clmms-when-to-use-anode-tables</link>
      <description><![CDATA[我正在使用 clmm 研究一些用于序数结果的混合效应模型。我已经确定了最终模型，现在想展示研究结果。阅读后，我看到 ANODE 表既用于模型比较，也用于分解模型中每个固定效应的贡献。我无法找到任何关于这是否与报告相关的指导，以及最佳实践是什么。该模型是使用 R 中的序数包估计的，ANODE 表来自 RVAideMemoire。
实际上，这与模型输出中报告的 z 检验之间的结果几乎没有差异（如下所示）。但是，我想更多地了解两组输出之间的差异。有人可以提出一些建议吗？我可以找到有关模型比较的信息，但找不到关于如何报告最终模型中固定效应的重要性的具体问题的答案。
非常感谢！
 估计误差 z Pr(&gt;|z|)

Var1 -2.966 0.482 -6.152 &lt;0.001

Var2 -2.102 0.486 -4.32 &lt;0.001

Var3 -1.593 0.476 -3.349 0.001

Var4 0.973 0.474 2.051 0.040

Var5 -0.711 0.175 -4.07 &lt;0.001

偏差分析（II 型检验）

LR Chisq Df Pr(&gt;Chisq) 

Var1 29.2981 1 &lt;0.001 ***
Var2 16.2687 1 &lt;0.001 ***
Var3 10.2870 1 0.001 **
Var4 3.9415 1 0.047 *
Var5 14.5733 1 &lt;0.001 ***
]]></description>
      <guid>https://stats.stackexchange.com/questions/650628/reporting-significance-of-fixed-effects-in-clmms-when-to-use-anode-tables</guid>
      <pubDate>Sun, 07 Jul 2024 08:26:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么考虑自相关残差几乎无助于分布滞后模型中的参数估计</title>
      <link>https://stats.stackexchange.com/questions/650626/why-does-accounting-for-autocorrelated-residuals-barely-help-parameter-estimatio</link>
      <description><![CDATA[这个问题困扰了我很长时间。基本上，我有一个分布式滞后模型$$y_t=\sum_{i=0}^{p} \beta_i x_{t-i} + u_t.$$
回归问题有点错误指定，所以我最终得到自相关错误$$u_t=\alpha u_{t-1}+\epsilon_t.$$
由于我的模型中自相关程度很高，$\beta$的估计应该非常低效，但是当我使用 GLS 校正自相关时，我的$\beta$估计没有任何改善。当我的问题略有不同，并且 $$y_t= \sum_{i=1}^p \beta_i x_t^i + u_t,$$ 时，$y$ 只是同时存在的不同 $x$ 的函数，GLS 表现惊人，而最小二乘则举步维艰。
为什么 GLS 在第一个例子中表现如此糟糕，我如何让它表现得更好（我只关心参数估计）？
我在 R 中编写了两个例子：
n_sim&lt;-15
LS_R2&lt;-rep(0,n_sim)
GLS_R2&lt;-rep(0,n_sim)
ar_noise&lt;-0.7
for(sim in 1:n_sim){
n=5000
set.seed(sim)
x_vec&lt;-arima.sim(list(order=c(1,0,0),ar=c(0.5)),n=n,sd=1)
noise&lt;-arima.sim(list(order=c(1,0,0),ar=c(ar_noise)),n=n,sd=1)
y&lt;-rep(0,n)
p&lt;-150
true_beta&lt;-seq(from=5,to=0,length.out=p)+rnorm(p,sd=0.1)
for(i in p:length(y)){
y[i]&lt;-y[i]+sum(x_vec[i:(i-p+1)]*true_beta)
}
y&lt;-y+noise*var(y)/var(noise)/50

#尝试简单最小二乘法（应该非常低效）
Xmat&lt;-matrix(0,ncol = p,nrow = n)
for(i in 1:ncol(Xmat)){
Xmat[,i]&lt;-c(rep(0,i-1),x_vec[1:(length(x_vec)-i+1)])
}

XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
LS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

#尝试广义最小二乘法（应该是最优且有效的）
get_T&lt;-function(ar,N){
i_vec&lt;-c(1:N,2:N)
j_vec&lt;-c(1:N,1:(N-1))
x_vec&lt;-c(sqrt(1-ar^2),rep(1,N-1),rep(-ar,N-1))
sparseMatrix(i = i_vec, j = j_vec, x = x_vec, dims = c(N,N))
}

T1&lt;-get_T(ar_noise,length(y))

Xmat&lt;-T1%*% Xmat
y&lt;-as.numeric(T1%*% matrix(y,ncol=1))

XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
GLS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

}
LS_R2
GLS_R2
mean(LS_R2)
mean(GLS_R2)

and
n_sim&lt;-15
LS_R2&lt;-rep(0,n_sim)
GLS_R2&lt;-rep(0,n_sim)
for(sim in 1:n_sim){
n=5000
set.seed(sim)
noise&lt;-arima.sim(list(order=c(1,0,0),ar=c(ar_noise)),n=n,sd=1)
y&lt;-rep(0,n)
p&lt;-150
Xmat&lt;-matrix(0,ncol = p,nrow = n)
for(i in 1:ncol(Xmat)){
Xmat[,i]&lt;-arima.sim(list(order=c(1,0,0),ar=c(0.5)),n=n,sd=1)
}
true_beta&lt;-seq(from=5,to=0,length.out=p)+rnorm(p,sd=0.1)
for(i in p:length(y)){
y[i]&lt;-y[i]+sum(Xmat[i,]*true_beta)
}
y&lt;-y+noise*sd(y)/sd(noise)

#尝试简单最小二乘法（应该是非常低效的）
XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
LS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

#尝试广义最小二乘法（应该是最优且有效的）
get_T&lt;-function(ar,N){
i_vec&lt;-c(1:N,2:N)
j_vec&lt;-c(1:N,1:(N-1))
x_vec&lt;-c(sqrt(1-ar^2),rep(1,N-1),rep(-ar,N-1))
sparseMatrix(i = i_vec, j = j_vec, x = x_vec, dims = c(N,N))
}

T1&lt;-get_T(ar_noise,length(y))

Xmat&lt;-T1%*% Xmat
y&lt;-as.numeric(T1%*% matrix(y,ncol=1))

XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
GLS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

}
LS_R2
GLS_R2
mean(LS_R2)
mean(GLS_R2)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/650626/why-does-accounting-for-autocorrelated-residuals-barely-help-parameter-estimatio</guid>
      <pubDate>Sun, 07 Jul 2024 07:15:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么逆倾向得分加权有效？</title>
      <link>https://stats.stackexchange.com/questions/650624/why-does-inverse-propensity-score-weighting-work</link>
      <description><![CDATA[假设某些治疗 $D = 0, 1$ 对结果 $Y = 0,1$ 的影响受到性别 $S = 0,1$ 的混淆。对 $D$ 对 $Y$ 的因果影响的无混淆估计将使我们估计层内风险，然后在计算其差异之前根据层的流行程度对这些风险进行加权。从数学上讲，我们会计算
$$ E[Y(D=d)] = \sum_s E[Y \mid D=d, S=s] P(S=s) $$
对每个 $d$ 计算差值。如果简单地写出均值估计量的简单差异，就会发现权重不正确，这是造成混杂的原因
$$ E[Y\mid D=d] = \sum_s E[Y \mid D=d, S=s] P(S=s \mid D=D) $$
请注意，通过贝叶斯规则
$$ P(S=s \mid D=D) = \dfrac{P(D=D \mid S=S) P(S=s)}{P(D=d)} $$
它是倾向得分和正确权重的函数$P(S=s)$。但是，简单地用倾向得分的倒数对 $E[Y \mid D=d]$ 的估计值进行加权，就会在 $E[Y \mid D=d]$ 的表达式中留下一个 $1/P(D=d)$ 因子。
那么，为什么 IPTW 会得出正确的因果对比估计值呢？我希望得到一个符合我在此处所写的期望加权和的答案。特别是，我希望证明 IPTW 会得出一个类似于我提出的第一个方程的表达式。]]></description>
      <guid>https://stats.stackexchange.com/questions/650624/why-does-inverse-propensity-score-weighting-work</guid>
      <pubDate>Sun, 07 Jul 2024 05:59:37 GMT</pubDate>
    </item>
    <item>
      <title>广义策略迭代（GPI）、Actor-Critic 和 Q 学习方法之间有什么关系？</title>
      <link>https://stats.stackexchange.com/questions/650622/whats-the-relation-between-generalized-policy-iteration-gpi-actor-critic-an</link>
      <description><![CDATA[在我看来，广义策略迭代 (GPI) 和 Actor-Critic 是一样的，而 Q-learning 方法则是一类独立的算法。我认为 GPI 和 Actor-Critic 都描述了策略评估 (critic) 和策略改进 (actor) 的迭代过程，而 Q-learning 只是使用贝尔曼最优方程进行引导。
详细阐述我的理解：策略评估 (critic) 是通过蒙特卡洛或时间差分方法完成的，必要时包括函数逼近，策略改进 (actor) 可以通过贪婪 (表格情况) 或使用策略梯度定理 (大状态空间) 来完成。Q-learning 不做任何这些。它只是尝试使用贝尔曼最优方程通过迭代拟合 Q 值的贝尔曼最优方程来估计 $Q^\ast$。
如果有人能确认我的理解是否正确，或者对在线 RL 算法的分类法给出更系统/精确的总结，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650622/whats-the-relation-between-generalized-policy-iteration-gpi-actor-critic-an</guid>
      <pubDate>Sun, 07 Jul 2024 05:24:58 GMT</pubDate>
    </item>
    <item>
      <title>故意发表错误统计方法的著名例子有哪些？</title>
      <link>https://stats.stackexchange.com/questions/650620/what-are-famous-examples-of-erroneous-statistical-methods-being-deliberately-pub</link>
      <description><![CDATA[是否有著名的错误统计方法发表的例子，作者从一开始就知道他们的方法是错误的，但故意隐瞒它？
例如，我想到的是人们试图测试某些期刊的同行评审过程的可靠性，或者在战争时期，出版物可能旨在鼓励敌人使用错误的方法。但我对其他可能的动机也很感兴趣。促使我提出这个问题的原因是，在社会科学中有几个这样的例子，所以我想知道它是否也发生在统计研究中。
我不认为有很多著名的例子（我从未听说过这样的案例，这就是我问这个问题的原因），因为隐藏方法不正确可能非常困难，所以我想问题的范围不是太广泛。]]></description>
      <guid>https://stats.stackexchange.com/questions/650620/what-are-famous-examples-of-erroneous-statistical-methods-being-deliberately-pub</guid>
      <pubDate>Sun, 07 Jul 2024 04:46:31 GMT</pubDate>
    </item>
    <item>
      <title>当因果关系的方向可能朝任一方向发展时，是否有一个好的统计方法来区分相对强度？</title>
      <link>https://stats.stackexchange.com/questions/650617/when-the-direction-of-causation-can-plausiblely-run-in-either-direction-is-ther</link>
      <description><![CDATA[我对这样一种情况感兴趣：意识形态影响经济结果，经济结果也影响意识形态。假设我对每个方面都有良好且相关的衡量标准，并且还假设（但有点令人怀疑）没有第三个因素可以同时解释这两个方面，那么是否有统计方法可以确定两个因果关系方向的相对重要性？
这是一个基于历史数据的准实验，因此我没有机会以适当的随机化方式重新运行事件。]]></description>
      <guid>https://stats.stackexchange.com/questions/650617/when-the-direction-of-causation-can-plausiblely-run-in-either-direction-is-ther</guid>
      <pubDate>Sun, 07 Jul 2024 03:25:25 GMT</pubDate>
    </item>
    <item>
      <title>关于多重比较的错误发现率校正问题</title>
      <link>https://stats.stackexchange.com/questions/650616/problem-regarding-false-discovery-rate-correction-for-multiple-comparison</link>
      <description><![CDATA[我正在开展研究，以寻找基因与疾病之间的关联。这是一项病例对照研究。我根据基因型将病例分为 A 组和 B 组，将对照分为 C 组和 D 组。我想使用非配对 t 检验比较 A 组和 B 组之间 20 个不同参数的平均值。我将比较 C 组和 D 组之间的相同 20 个参数。
在 FDR 校正期间，我是否必须同时对 40 个 p 值进行排序？还是我需要分别调整 A 组和 B 组之间的 20 个 p 值，然后调整 C 组和 D 组之间的 20 个 p 值？]]></description>
      <guid>https://stats.stackexchange.com/questions/650616/problem-regarding-false-discovery-rate-correction-for-multiple-comparison</guid>
      <pubDate>Sun, 07 Jul 2024 03:21:50 GMT</pubDate>
    </item>
    <item>
      <title>策略梯度方法中的目标函数是否正是期望值函数？</title>
      <link>https://stats.stackexchange.com/questions/650615/is-the-objective-function-in-policy-gradient-methods-exactly-the-expected-value</link>
      <description><![CDATA[
我正在阅读 DRL 中的 Spinning Up。我想知道策略梯度算法中的目标 $J_\theta$ 是否正是期望值函数 $E_{S_0}[V^\pi(S_0)]$。我从未见过有人将目标写为 V，但我觉得它们是一样的。有人可以证实这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650615/is-the-objective-function-in-policy-gradient-methods-exactly-the-expected-value</guid>
      <pubDate>Sun, 07 Jul 2024 02:45:34 GMT</pubDate>
    </item>
    <item>
      <title>如何估计用于训练和推理的 GPU 内存、数据要求以及大型语言模型的训练时间？</title>
      <link>https://stats.stackexchange.com/questions/650614/how-to-estimate-gpu-memory-for-training-and-inference-data-requirements-and-tr</link>
      <description><![CDATA[今天面试 ML 工程师时遇到这个问题，当时答得不是很完美，理想情况下应该怎么回答？
假设我们有 Transformer、BERT、GPT 等模型，每个模型有 x 亿个参数，参数为 FP32 精度。

GPU 内存要求：

如果使用 Adam 作为优化器，训练（考虑激活、优化器状态，​​如动量等）和推理（考虑 KV Cache 等）需要多少 GPU 内存？
请提供 x = 7B 和 x = 70B 的具体值，至少需要多少个 H100 GPU 才能满足内存需求？ （H100 80GB 内存）


数据要求：

如果您的经理为您分配此任务，您需要多少文本训练数据（TB）来确保 x 亿参数模型收敛？
请提供 x = 7B 和 x = 70B 的具体值。


训练时间：

如果您的经理希望使用上述数量的训练数据在一个月（30 天）内完成训练，您需要多少个 H100 GPU？
考虑 H100 规格（FP32 67 TFLOPS，带宽 ~ 3TB/s）和并行效率（加速）适用于多个 GPU。


]]></description>
      <guid>https://stats.stackexchange.com/questions/650614/how-to-estimate-gpu-memory-for-training-and-inference-data-requirements-and-tr</guid>
      <pubDate>Sun, 07 Jul 2024 01:51:13 GMT</pubDate>
    </item>
    <item>
      <title>拆分数据然后进行回归是否合理？</title>
      <link>https://stats.stackexchange.com/questions/650613/is-it-reasonable-to-split-the-data-and-then-perform-the-regression</link>
      <description><![CDATA[有一家商店销售圆珠笔。我已从该商店获取每笔交易的数据，包括交易 ID、颜色、每笔交易的销售数量、总价等。通过将总价除以每笔交易数量，我计算出了每笔交易中每支笔的单价。我认为每支圆珠笔的单价与其颜色和每笔交易中购买的数量有关。因此，我将使用线性回归来检验这一假设：单价 = Alpha1 x 颜色 + Alpha2 x 数量 + Beta。
原始数据图像：

问题是，我可以在执行回归之前拆分这些数据吗？例如，在原始样本数据中，第一笔交易销售了 2 支圆珠笔，因此我将把它拆分为两个条目。拆分数据如下图所示，回归方程不变：单价 = Alpha1 x 颜色 + Alpha2 x 数量 + Beta。
拆分数据图片：

我的问题是：这个操作可以吗？会有什么影响，为什么？有相关参考吗？
我觉得这个操作可能不合理，比如反而增加了蓝色笔的数据权重。但是我对统计学的理解不够，无法清晰的表达出为什么或者怎么不合理。]]></description>
      <guid>https://stats.stackexchange.com/questions/650613/is-it-reasonable-to-split-the-data-and-then-perform-the-regression</guid>
      <pubDate>Sun, 07 Jul 2024 01:30:45 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 AR(p) 模型无法拟合数据</title>
      <link>https://stats.stackexchange.com/questions/650609/arp-model-in-r-not-fitting-data</link>
      <description><![CDATA[我有一组数据，我正尝试用一个简单的 AR(p) 模型来建模。我已经对单位根平稳性进行了 Dickey Fuller 检验并拒绝了零假设。
但是，当我在 R 中运行一个简单的 ar 命令时，我似乎得到了一个只有截距的模型。我不知道这是为什么，希望有人能给出一些建议。代码如下。
数据和 R 代码如下：
data &lt;- c(-2.93, -1.86, 0.45, -1.07, 5.92, 3.90, 1.28, -0.13, 1.33, 
2.05, 17.69, -16.59, -3.84, -5.67, 4.76, -0.58, 1.06, 
-0.63, 3.21, 1.06, -4.25, -6.24, -2.33, -6.64, 
-4.56, -5.83, -1.99, 3.10, 7.82, 1.99, 4.42, -1.22, -7.52, 
4.37, -3.24, -0.37, -2.77, -0.72, 0.10, -3.78, 1.35, -1.48, 
-3.66, -1.87, -1.98, -2.39, -0.06, -0.16, 0.97, 3.79, 0.10, 
-3.94, -2.00, 14.47, 5.29, -1.59, 6.86, -2.38, -9.99, -1.29, 
-0.44, -4.45, 1.37, 6.36, 3.43, -0.60, 7.55, 5.34, -7.85, 
8.52, 5.34, -13.36, 4.64, -0.61, 2.96, 4.90, 10.89, -7.19, 
-2.16, -0.63, -6.03, -10.62, -7.78, -4.33, -3.55, -3.47, 
1.64, -1.85, -2.88, 0.78, 12.39, -5.90)

time_series_data &lt;- ts(data, start = c(2012, 5), frequency = 12)

ar_model &lt;- ar(time_series_data, order.max = 3)

summary(ar_model)

残差 &lt;- ar_model$resid

fitted_values &lt;- time_series_data -残差

打印（fitted_values）

一月 二月 三月 四月 五月 六月 七月 八月 九月 十月
2012 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2013 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2014 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
-0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2015 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2016 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2017 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2018 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
2019 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739 -0.3021739
十一月 十二月
2012 -0.3021739 -0.3021739
2013 -0.3021739 -0.3021739
2014 -0.3021739 -0.3021739
2015 -0.3021739 -0.3021739
2016 -0.3021739 -0.3021739
2017 -0.3021739 -0.3021739
2018 -0.3021739 -0.3021739
2019 -0.3021739 -0.3021739 
]]></description>
      <guid>https://stats.stackexchange.com/questions/650609/arp-model-in-r-not-fitting-data</guid>
      <pubDate>Sat, 06 Jul 2024 23:01:46 GMT</pubDate>
    </item>
    <item>
      <title>增强状态空间滤波问题中的 Hessian 表示</title>
      <link>https://stats.stackexchange.com/questions/650606/representation-of-hessian-in-augmented-state-space-filtering-problems</link>
      <description><![CDATA[问题
设 $z_t := (x_t, x_{t-1}, x_t^2, x_{t-1}x_t,x_{t-1}x_t,x_{t-1}^2)$，且
$R(x_t) := \sum_{(i,j) \in \{\{0,1,2,3,4\} \otimes \{0,1,2,3,4\} : i+j \le 4\}} w_{i,j} x_t^i x_{t-1}^j$，
因此 $R(\cdot)$ 在 $x_t, x_{t-1}$，但在 $z_t$ 中是二次函数。
在 $R(z)$ 的二阶泰勒展开式中，$R(z^*)$，
$R(z) = R(z^*) + J_R(z^*)(z - z^*) + 0.5 (z - z^*)^\prime H_R(z^*) (z - z^*) $
如何表达雅可比矩阵 $J_R$ 和 Hessian，$H_R$，$R(z_t)$，来解释$z_t$中的项是彼此的函数这一事实？
背景
我正在解决一个困难的过滤问题。
让$x_t$和$y_t$成为标量随机变量。
状态转换动力学可以用以下方式来表征：$x_t | x_{t-1} \sim \mathcal{N}(\Phi x_{t-1},Q)$。
测量方程具有以下动态，$y_t | y_{t-1}, x_t, x_{t-1} \stackrel{\text{approx}}{\sim} \mathcal{N}(A + B y_{t-1} + f(x_t,x_{t-1}), R(x_t,x_{t-1})),$ 其中 $f(\cdot)$ 在 $\tilde{x}_t := (x_t, x_{t-1})^\prime$ 中为 二次 方程，而 $R(\cdot)$ 在 $\tilde{x}_t$ 中为 四次 方程。近似值来自匹配随机积分的矩，但我们现在可以忽略它并假设它完全是高斯的。
到目前为止，我的解决方案是用状态的二阶项来扩充状态空间，$z_t := (\tilde{x}_t^\prime,vec(\tilde{x}_t^\prime \tilde{x}_t)^\prime)^\prime = (x_t, x_{t-1}, x_t^2, x_t x_{t-1},x_{t-1} x_t, x_{t-1}^2 )^\prime$。我可以跟踪 $z_t | z_{t-1}$ 恰好，则 $f(\cdot)$ 在 $z_t$ 中是仿射的，而 $R(\cdot)$ 在 $z_t$ 中是二次的。
据我所知，在我的设置中，卡尔曼滤波器在计算创新的协方差时会失效。设$f(z_t) = \alpha_f + \beta_f z_t$，且$\mathcal{Y}_{t-1} := \{y_{\tau}\}_{\tau = t_0}^{t-1}$则
$S_t = \beta_f P_{t|t-1} \beta_f^\prime + \mathbb{E}[R(z_t) | \mathcal{Y}_{t-1}]$，
其中 $S_t := \mathbb{E}[(y_t - \mathbb{E}[y_t | \mathcal{Y}_{t-1}])(y_t - \mathbb{E}[y_t | \mathcal{Y}_{t-1}])^\prime | \mathcal{Y}_{t-1}]$。
我目前的计划是取二阶泰勒展开式的期望值 $R(\hat{z}_{t|t-1})$，
$\mathbb{E}[R(z_t)|\mathcal{Y}_{t-1}] = \mathbb{E}[ R(\hat{z}_{t|t-1}) + J_R(\hat{z}_{t|t-1}) (z_t - \hat{z}_{t|t-1}) + 0.5 (z_t - \hat{z}_{t|t-1})^\prime H_R(\hat{z}_{t|t-1})(z_t - \hat{z}_{t|t-1}) |\mathcal{Y}_{t-1}] = R(\hat{z}_{t|t-1}) + 0.5 \ tr\{H_R(\hat{z}_{t|t-1}) P_{t|t-1}\}$
其中 $\hat{z}_{t|t-1} := \mathbb{E}[z_t | \mathcal{Y}_{t-1}]$，从而得到精确的创新协方差公式，
$S_t = \beta_f P_{t|t-1} \beta_f^\prime + R(\hat{z}_{t|t-1}) + 0.5 \ tr\{H_R(\hat{z}_{t|t-1}) P_{t|t-1}\}$。
最后，我的问题是，如果 $z_t$ 中的几个元素是其他元素的函数，我该如何计算 Hessian $H_R(z_t)$？特别是如果，
$R(z_t) = \sum_{(i,j) \in \{0,1,2,3,4\} \otimes \{0,1,2,3,4\}} w_{i,j} x_t^i x_{t-1}^j$，
如何表达 $R(z_t),$ $H_R(z_t)$ 的 Hessian？]]></description>
      <guid>https://stats.stackexchange.com/questions/650606/representation-of-hessian-in-augmented-state-space-filtering-problems</guid>
      <pubDate>Sat, 06 Jul 2024 21:17:18 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯线性回归中的滞后因变量</title>
      <link>https://stats.stackexchange.com/questions/650582/lagged-dependent-variable-in-bayesian-linear-regression</link>
      <description><![CDATA[我正在构建贝叶斯广义线性模型，以尝试模拟企业拥有的客户数量。本质上是市场组合模型。
我认为客户数量可以通过媒体支出和一些控制（傅立叶季节性、趋势、公共假期等）来解释。
我基本上是这样定义模型的（省略了一些细节，因为我认为它们对我想问的问题并不重要）：
$$y_t \sim N(\mu_t, \sigma)$$
$$\mu_t=\alpha+\beta f(X_t)+\gamma W_t$$
$$f(X_t) = \sum_{k=0}^m \lambda^k X_{t-k}$$
$$\beta \sim Exp(.)$$
$$\gamma \sim N(.)$$
$$\lambda \sim Beta(.)$$
$y_t$ 表示 $t$ 时刻的客户数量，$\alpha$ 为基线客户，$\beta$ 为各种媒体渠道的系数向量，$X_t$ 为我们的媒体支出数据，$\gamma$ 为各种控制变量的系数向量，$W_t$ 是控制变量数据。
$f(x)$ 是一个广告库存函数，它考虑了媒体支出在客户心中积累并在消散前停留一段时间的情况。
我特别感兴趣的是发现不同媒体类型的媒体支出的有效性，所以基本上是过去一段时间内的 $\beta X$。预测目前不是优先事项。
我认为 $t$ 时刻的客户数量应该受到 $t-1$ 时刻的客户数量的影响。事实上，当我运行上述模型并查看残差时，似乎有自相关的证据。因此，我觉得我应该将 $\mu_t$ 重新定义为
$$\mu_t = \alpha+\beta f(X_t)+\gamma W_t +\eta y_{t-1}$$
当我这样做时，显然媒体变量的解释力将被抑制，因此在我所观察的时间段内，媒体的有效性将降低。
这公平吗？今天的客户数量部分由昨天的客户数量决定，但昨天的客户本身部分由媒体决定。那么，我是否应该将 $t$ 时滞后变量的有效性归因于 $t-1$ 期间的媒体变量？或者这会是重复计算吗？
抱歉，如果这有点复杂，感谢您对此的任何意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/650582/lagged-dependent-variable-in-bayesian-linear-regression</guid>
      <pubDate>Sat, 06 Jul 2024 08:47:59 GMT</pubDate>
    </item>
    <item>
      <title>如何将贝叶斯模型拟合到 Beta、指数和一零膨胀数据的混合中？</title>
      <link>https://stats.stackexchange.com/questions/650533/how-to-fit-a-bayesian-model-to-a-mixture-of-beta-exponential-and-one-zero-infl</link>
      <description><![CDATA[我的数据非常嘈杂，我相信这是通过多个物理过程的相互作用而产生的。在映射 $Y = f(X),$ 中，$Y$ 是一个比率 $[0, 1]$ 和 $X \ge 0.$，而 $Y$ 是 $X,$ 的函数，它也可以取 $0$（更可能在较低的 $X$ 值时）或 $1$（更可能在较高的 $X$ 值时）。 $Y$ 是每个 $X$ 间隔的指数、Beta 和零一膨胀过程的混合。指数部分在 $X$ 值较低时更明显，并随着 $X$ 的增加而缓慢消失。
如何使用贝叶斯方法对此类过程进行建模？我是贝叶斯统计的新手，希望得到任何帮助。我可以拟合零一膨胀的 Beta 模型，但它无法捕捉指数类分量。
模拟真实数据的虚拟数据：
# 设置种子以实现可重复性
set.seed(123)

# 生成 x 值
x &lt;- seq(0, 20, length.out = 1000)

# 为 y 创建非线性函数
y &lt;- 0.15 + 0.005 * x^1.05 + 1 / (2.5 + 2532 * exp(-1.611 * x))

# 添加一些随机噪声
noise_factor &lt;- 0.03
# 使用 beta 噪声创建模型（此处使用正态分布创建）
noisy_y &lt;- rnorm(length(x), mean = 0, sd = noise_factor * sqrt(x))

y &lt;- y + noisy_y

# 向数据添加零个和一个噪声
noisy_indices &lt;- sample(1:length(x), round(0.2 * length(x)))
for (i in noisy_indices) {
if (runif(1) &lt; 1 / (1 + exp(x[i]))) {
y[i] &lt;- 1
} else {
y[i] &lt;- 0
}
}

# 添加指数分布
noisy_indices &lt;- sample(1:length(x), round(0.5 * length(x)))
for (i in noisy_indices) {
if (runif(1) &lt; 100 / (1 + exp(x[i]))) {
y[i] &lt;- rexp(1, rate =4)
} else {
y[i] &lt;- y[i]
}
}

# 创建数据框
data &lt;- data.frame(x = x, y = y) |&gt;
filter(y&lt;=1 &amp; y&gt;=0)

ggplot(data, 
aes(x, y)) +
geom_point() +
xlim(0, 20) + 
ylim(0, 1)

ggplot(data = data, 
aes(x=y))+
geom_histogram()

我正在尝试制定一个将 X 映射到 Y 的函数

整个数据集中 Y 的分布。在原始数据集中，从零（@Y=0）到指数部分（Y ~ 0-0.25）的过渡非常平滑。

我尝试（在原始数据上）在 brms 中使用零一膨胀 Beta 得出此后验预测：
]]></description>
      <guid>https://stats.stackexchange.com/questions/650533/how-to-fit-a-bayesian-model-to-a-mixture-of-beta-exponential-and-one-zero-infl</guid>
      <pubDate>Fri, 05 Jul 2024 14:49:43 GMT</pubDate>
    </item>
    <item>
      <title>对于给定平均值和标准差的正数据，偏度的下限是多少？</title>
      <link>https://stats.stackexchange.com/questions/650039/vintage-of-this-lower-bound-on-skewness-for-positive-data-with-given-mean-and-sd</link>
      <description><![CDATA[事实证明，对于任何具有给定平均值 μ 和标准差 σ 的严格正数据集，其偏度 $g_1$ 都有一个下限：
$$
g_1 &gt; \sigma/\mu - \mu/\sigma。
$$
虽然在最近的一些文献中，它被当作一个新的结果来讨论，但在我看来，它很可能相当古老——原因我在这篇 PubPeer 文章（其中还包含一个基本证明）中概述过。
来这里问这个问题时，我遇到了 2 个可以立即应用这个结果的问题：请参阅我的答案这里和这里。因此，这表明下限至少没有它应该的那么出名。但它可能是最近才出现的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650039/vintage-of-this-lower-bound-on-skewness-for-positive-data-with-given-mean-and-sd</guid>
      <pubDate>Thu, 27 Jun 2024 11:01:24 GMT</pubDate>
    </item>
    </channel>
</rss>