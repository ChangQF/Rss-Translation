<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 01 Aug 2024 12:29:35 GMT</lastBuildDate>
    <item>
      <title>随机森林：MSE 和 R2 较好，但交叉验证结果较差</title>
      <link>https://stats.stackexchange.com/questions/652148/random-forest-good-mse-and-r2-but-poor-cross-validation-results</link>
      <description><![CDATA[我使用标准缩放器构建、预处理和清理（na/0s、winsorise、log 等）一些特征并对其进行标准化。
如果我仅使用平均值计算基线 MSE，我会得到 8.22
简单线性回归的 MSE 为 7.15，R2 为 0.13
具有 20 个估计量的随机森林模型的 MSE 为 3.07，R2 为 0.62 - 这似乎很奇怪。
因此，我尝试使用相同的随机森林模型进行 k 倍交叉验证，并得到了一些非常糟糕的结果：
交叉验证分数：[0.02259823 -0.70599662 -0.12186488 -0.18245173 -0.33035053]
平均 CV 分数：-0.2636131047737679
CV 分数的标准差：0.24849696694857612

在此阶段我应该关注什么来排除模型故障？不确定该走哪条路。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652148/random-forest-good-mse-and-r2-but-poor-cross-validation-results</guid>
      <pubDate>Thu, 01 Aug 2024 12:24:54 GMT</pubDate>
    </item>
    <item>
      <title>对数正态分布和 Galton Watson 过程</title>
      <link>https://stats.stackexchange.com/questions/652147/lognormal-distribution-and-galton-watson-process</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652147/lognormal-distribution-and-galton-watson-process</guid>
      <pubDate>Thu, 01 Aug 2024 12:19:50 GMT</pubDate>
    </item>
    <item>
      <title>增长曲线分析建议</title>
      <link>https://stats.stackexchange.com/questions/652146/growth-curve-analysis-advice</link>
      <description><![CDATA[我对生长曲线模型还不熟悉，需要一些指导。我有大约 50,000 只羊羔的数据，每只羊羔都有出生体重，并在出生后大约 30、60、90 和 120 天进行了两次额外测量。我想应用 Logistic、Gompertz 和 von Bertalanffy 等生长曲线模型。
我有一些顾虑：
我能否同时使用天数和所有动物记录进行生长曲线分析，还是需要计算单个动物的 A 和 K 等参数？
如果需要单独计算，对每只动物进行三次测量是否足够？
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/652146/growth-curve-analysis-advice</guid>
      <pubDate>Thu, 01 Aug 2024 12:16:42 GMT</pubDate>
    </item>
    <item>
      <title>寻求最佳统计检验方法建立截止值以过滤 NGS 数据中的假阳性突变</title>
      <link>https://stats.stackexchange.com/questions/652145/seeking-the-best-statistical-test-to-establish-cutoff-for-filtering-false-positi</link>
      <description><![CDATA[我有一个程序，可以调用患者 DNA 序列中的突变。虽然该测试的灵敏度为 100%，但它会产生大量假阳性 (FP)。
我开发了一种使用两个参数识别 FP 突变的方法。为简单起见，我将解释其中一个。
在对 DNA 进行测序时，测序机会产生 DNA 读数。例如：
ATGCATGTCA 是一个包含 10 个碱基的读数。

测序机还为每个碱基提供质量分数 (Q 分数)。 Q 分数以对数形式定义，与碱基调用错误概率 (P) 相关：

Q = − 10 log10 P

例如，如果某个碱基的 Q 分数为 30 (Q30)，则这相当于 1000 次中发生 1 次错误碱基调用的概率。
当与参考基因组相比，有大量碱基支持突变时，即可识别出突变。例如，考虑 10 个读取，其中 5 个读取支持突变，5 个读取支持野生型：
ATGCACGTCA
ATGCACGTCA
ATGCACGTCA
ATGCACGTCA
ATGCACGTCA
ATGCATGTCA
ATGCATGTCA
ATGCATGTCA
ATGCATGTCA
我观察到，在真阳性 (TP) 事件中，支持突变的碱基的平均 Q 分数与支持野生型的碱基的平均 Q 分数非常相似。然而，在 FP 事件中，支持突变的碱基的平均 Q 分数明显低于（由于机器错误）支持参考的碱基的平均 Q 分数。
以下图表说明了这一观察结果：

X 轴：突变频率（支持突变和参考的读数分布）。
Y 轴：平均 Q 分数的差异（REF - ALT）。
（忽略蓝点）。
我需要一个测试来帮助我建立最佳截止值，因为这是我使用训练数据进行的分析，所以我知道哪些是 TP 和 FP，但在实分析中，我不会知道这一点。
我需要一个测试来帮助建立最佳截止值，因为这个分析是使用训练数据进行的，我知道哪些是 TP 和 FP，但在实分析中，我不会有这些信息。
我的方法必须非常保守，因为我想尽可能地减少误报。真正例 (TP) 对我们来说非常重要，我们不想应用任何删除 TP 的方法。
我找到了一个程序，它可以为这个特定的分析计算 Mann-Whitney-Wilcoxon 秩和检验。此处对此进行了解释：GATK 秩和检验。当两个平均值相似时，此 Z 分数返回 0，当支持 ALT 的读数的平均 Q 分数较低时，返回较低的值。但是，这种统计测试对我不起作用。请参阅下一个图：

一些 TP 事件的 Z 分数非常低，我不知道为什么。图中的所有事件至少有 &gt;1000 次读取，这意味着两个组的平均值至少有 500 次事件。 SD 也不能解释这个低 Z 分数。

所以我的问题是，建立截止值并过滤掉 FP 突变的最佳统计测试是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652145/seeking-the-best-statistical-test-to-establish-cutoff-for-filtering-false-positi</guid>
      <pubDate>Thu, 01 Aug 2024 11:48:04 GMT</pubDate>
    </item>
    <item>
      <title>评估已知矩阵近似的成功率</title>
      <link>https://stats.stackexchange.com/questions/652142/estimating-the-success-of-an-approximation-of-a-known-matrix</link>
      <description><![CDATA[我试图用“估计”矩阵$A&#39;$近似已知的$N\times N$矩阵$A$。问题是，如何量化此近似中的误差 - $A$和$A&#39;$之间的差异。
如果$A$和$A&#39;$是单个数字，这个问题就很简单了。但是，当数据为矩阵形式时，误差的含义变得更加模糊。
我知道 RMS 和矩阵范数，但使用它们来量化估计误差存在问题，因为它们取决于数据的动态范围 - 如果矩阵值在 $0-1000$ 范围内，则 RMS 值 $0.5$ 不会说明任何有用信息；无论 RMS 是多少，矩阵元素 $a_{ij}$ 和 $a_{ij}&#39;$ 之间可能存在显著差异。我认为矩阵范数遇到了完全相同的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/652142/estimating-the-success-of-an-approximation-of-a-known-matrix</guid>
      <pubDate>Thu, 01 Aug 2024 10:34:41 GMT</pubDate>
    </item>
    <item>
      <title>规范化（自动缩放规范化、Z 分数规范化）改变相关结果 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/652141/normalization-autoscaling-normalization-z-score-normalization-changes-correla</link>
      <description><![CDATA[我正在尝试执行 Spearman 相关性。我在标准化（自动缩放）之前和之后得到了不同的结果。我读了一些帖子，说标准化不会影响相关性结果。

library(POMA)
library(ggstatsplot)

# 这是标准化之前的示例
ggcorrmat(
data = data.frame(test_Not_Normalized),
colors = c(&quot;#B2182B&quot;, &quot;white&quot;, &quot;#4D4D4D&quot;),
title = &quot;Not Normalized&quot;,
type = &quot;spearman&quot;, # 或 &quot;robust&quot; 用于稳健相关性估计
ggtheme = ggplot2::theme_bw()
)



# 这是标准化之后的示例
normalized &lt;- test_Not_Normalized %&gt;% 
PomaNorm(method = &quot;auto_scaling&quot;)
test_Normalized &lt;- t(as.data.frame(normalized@assays@data@listData))

ggcorrmat(
data = data.frame(test_Normalized),
colors = c(&quot;#B2182B&quot;, &quot;white&quot;, &quot;#4D4D4D&quot;),
title = &quot;Normalized&quot;,
type = &quot;spearman&quot;, # 或 &quot;robust&quot; 用于稳健相关性估计
ggtheme = ggplot2::theme_bw()
)

这里是 link 以获取生成的图表。
我想知道为什么我得到不同的结果，或者哪一个最适合用于下游分析。]]></description>
      <guid>https://stats.stackexchange.com/questions/652141/normalization-autoscaling-normalization-z-score-normalization-changes-correla</guid>
      <pubDate>Thu, 01 Aug 2024 10:13:12 GMT</pubDate>
    </item>
    <item>
      <title>图像分类中的分数级融合</title>
      <link>https://stats.stackexchange.com/questions/652140/score-level-fusion-in-image-classification</link>
      <description><![CDATA[我想使用多数投票和软投票，但我找不到它们的数学方程式。你能帮帮我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652140/score-level-fusion-in-image-classification</guid>
      <pubDate>Thu, 01 Aug 2024 09:51:56 GMT</pubDate>
    </item>
    <item>
      <title>绘制/建模包含大量小值的直方图</title>
      <link>https://stats.stackexchange.com/questions/652139/plotting-modelling-a-histogram-with-large-bins-of-small-values</link>
      <description><![CDATA[我想知道一些最佳实践或方法，例如，如下图所示，低值箱最常见，但您对整个分布感兴趣。
这是原始数据的视觉效果：

当我们采用logy时，我们可以看到在更高的值中存在更多潜在的有趣行为。但现在轴使得解释更加困难。

这是一个相当广泛的问题，但是

我们如何对这样的分布进行建模？
我们可以将多个分布拟合到对数直方图中吗？

原始数据集可以在这里找到：
https://www.kaggle.com/datasets/wilomentena/uk-government-petitions
该图用于未被驳回的请愿]]></description>
      <guid>https://stats.stackexchange.com/questions/652139/plotting-modelling-a-histogram-with-large-bins-of-small-values</guid>
      <pubDate>Thu, 01 Aug 2024 09:47:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么 sem() 与 lavvan 和 lm() 中的线性回归结果不同？</title>
      <link>https://stats.stackexchange.com/questions/652138/why-different-results-for-linear-regression-in-sem-from-lavvan-and-lm</link>
      <description><![CDATA[感谢您阅读本文。
我是一名学生，正在尝试更多地了解社会科学问题的统计数据。我试图在 R 中建立 {lavvan} 中的 sem() 函数和 {stats} 中的 lm() 函数之间的等价性，以进行具有一个结果和一个预测变量的简单线性回归，这两个预测变量都不是潜在变量。但是，即使我可以为模型获得相同的参数估计值，无论我使用哪个估计器，估计的标准误差都会略有不同。下面附上一个例子：
#加载库
library(lavaan)

#创建数据框
set.seed(1231)
n &lt;- 100 #观察值数量

X &lt;- rnorm(n, mean = 50, sd = 10)
Y &lt;- rnorm(n, mean = 65, sd = 8)

df &lt;- data.frame(X, Y)

#使用 lm() 函数
lm &lt;- lm(Y ~ X, data = df)
summary(lm)

#使用 lavaan 的 sem() 函数
model_sem &lt;- &#39;Y~X&#39;
sem &lt;- sem(model_sem, estimator = &quot;ML&quot;, se = &quot;standard&quot;, data = df)
summary(sem, nd = 7)

当前示例的结果：

来自 lm() 输出

 估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 67.30819 4.37739 15.38 &lt;2e-16
X -0.04116 0.08571 -0.48 0.632 


来自 sem() 输出

回归：
估计 Std.Err z 值 P(&gt;|z|)
Y ~ 
X -0.0411622 0.0848524 -0.4851035 0.6276029

参数估计相等，但参数的 SE 和 p 值略有不同。我还使用 {stats4} 中的 vcov() 函数检查了两个模型的方差-协方差矩阵。
vcov(lm)[c(&quot;X&quot;),c(&quot;X&quot;)]
[1] 0.00734687
vcov(sem)[c(&quot;Y~X&quot;),c(&quot;Y~X&quot;)]
[1] 0.007199932

我尝试手动计算 lm() 输出中的方差-协方差矩阵并成功完成。但是，我找不到从 sem() 中提取观察到的（或预期的）信息矩阵或计算 lavaan 文档中使用的对数似然函数的函数。在这种特定情况下，是否有可能实现两者之间的等价性？为什么（我哪里做错了）或者为什么不（有什么区别，是模型估计和规范还是仅仅是因为包）？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652138/why-different-results-for-linear-regression-in-sem-from-lavvan-and-lm</guid>
      <pubDate>Thu, 01 Aug 2024 09:22:58 GMT</pubDate>
    </item>
    <item>
      <title>方差公式的澄清</title>
      <link>https://stats.stackexchange.com/questions/652136/clarification-on-variance-formula</link>
      <description><![CDATA[可以使用两个公式来计算方差。一个是除以 n，另一个是除以 n-1。因此，我的问题是
我们通过除以 (n) 和 (n-1) 得到的结果是否相同？
示​​例]]></description>
      <guid>https://stats.stackexchange.com/questions/652136/clarification-on-variance-formula</guid>
      <pubDate>Thu, 01 Aug 2024 09:02:07 GMT</pubDate>
    </item>
    <item>
      <title>在营养替代分析中，为什么只有两种摄入量，而营养摄入量却以百分比建模？</title>
      <link>https://stats.stackexchange.com/questions/652134/in-nutritional-substitution-analysis-why-is-nutrient-intake-modeled-as-a-percen</link>
      <description><![CDATA[我在下面这篇文章中看到了营养替代分析的建模方法。
营养流行病学中的替代分析：谨慎行事
简而言之，你可以做下面的建模。这里，α1表示每份A替代B的效果大小。
f(Y)~α1×A＋α2×B＋α3×(A＋B＋C)
我的问题是，如果模型中没有C，即只有两次摄入（当它们互相替代时），这种方法有效吗？
f(Y)~α1×A＋α3×(A＋B)
另一篇论文使用了百分比。它探讨了茶和咖啡的替代。
咖啡还是茶？一项关于咖啡和茶摄入量与男性和女性总体和特定原因死亡率之间关系的前瞻性队列研究
建模为f(Y)~α1×茶/(茶+咖啡)+α3×(茶+咖啡)。也就是说，α1 是茶摄入量占茶和咖啡总摄入量的百分比。
该论文声称，使用百分比而不是连续值的原因是茶和咖啡摄入量是非线性的，而不是传统的负线性相关性。

标准替代分析假设暴露变量与疾病风险/死亡率之间存在线性关系 [18]，因此可以估计等量替代（例如，用一杯咖啡代替一杯茶）的效果。由于与咖啡和茶的关联显着非线性（参见“结果”），因此这里使用的方法是计算茶占每天饮用的咖啡和茶总杯数的百分比。这个变量被分类并用于多变量分析，同时还控制了咖啡和茶的总摄入量。

这里我不太明白，如果只有两次摄入的模型也有效，那么直接建模和百分比之间有什么区别。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652134/in-nutritional-substitution-analysis-why-is-nutrient-intake-modeled-as-a-percen</guid>
      <pubDate>Thu, 01 Aug 2024 07:31:52 GMT</pubDate>
    </item>
    <item>
      <title>当预测变量出现错误时会发生什么？</title>
      <link>https://stats.stackexchange.com/questions/652131/what-happens-when-there-are-errors-in-the-predictor-variables</link>
      <description><![CDATA[我昨天问了这个问题，但现在无法登录我的账户了：在未来模型中使用响应变量作为预测变量？
在思考了这个问题（估计雇用新员工对工厂生产率的净成本效益影响）之后，我想到了一种看待这个问题的新方法（即当预测变量有错误时该怎么办？）。我认为也许可以使用工具变量？
方法 1：直接使用工具变量分析净收益

对员工和已处理订单之间的关系进行建模：
$$\hat{P}_t = \hat{\alpha} \hat{E}_t + \hat{\epsilon}_t$$
其中 $\hat{E}_t$ 是 $E_t$ 的仪表化版本。我们使用第一阶段回归：
$$E_t = \gamma_0 + \gamma_1 Z_t + \nu_t$$
$$\hat{E}_t = \hat{\gamma}_0 + \hat{\gamma}_1 Z_t$$
此处，$Z_t$ 为工具变量（例如，招聘的滞后预算分配）。

模型的其余部分保持不变，但在所有部分中使用 $\hat{E}_t$ 代替 $E_t$方程。


我认为工具变量$Z_t$（或$Z_{t-1}$）应该与员工人数相关，但不应直接与主方程中的误差项相关。这可能有助于解决潜在的内生性问题？
这就是工具变量的使用方式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652131/what-happens-when-there-are-errors-in-the-predictor-variables</guid>
      <pubDate>Thu, 01 Aug 2024 05:19:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么用平方和来计算离散度[重复]</title>
      <link>https://stats.stackexchange.com/questions/652128/why-sum-of-squares-to-calculate-dispersion</link>
      <description><![CDATA[方差给出了分布分散的概念。要计算方差，需要将每个值与平均值的差值之和以及每个差值的平方相加。对差值进行平方以避免使用负数。但是....为什么？差值的绝对值就可以完成这项工作。通过使用平方和，较大的数字在计算中被赋予不成比例的权重。例如，如果一个值与平均值之间的差值为 2，则差值的平方为 4，但如果这个差值为 3，则平方为 9，因此 1 的差值被放大为 5 的差值。为什么这样做？为什么不使用绝对值？]]></description>
      <guid>https://stats.stackexchange.com/questions/652128/why-sum-of-squares-to-calculate-dispersion</guid>
      <pubDate>Thu, 01 Aug 2024 04:14:32 GMT</pubDate>
    </item>
    <item>
      <title>ANN 输出的不确定性作为分布参数</title>
      <link>https://stats.stackexchange.com/questions/652113/uncertainty-of-ann-outputs-as-distribution-parameters</link>
      <description><![CDATA[通过负对数似然$-\mathcal{L}(x, y_{true}, \mu, \sigma)$来训练神经网络模型，以估计位置（$\mu$）和尺度（$\sigma$），这样$\mu, \sigma = f(x)$，其中$f$是优化的神经网络，$x$是一些数据，这是一种常见的做法。
在训练期间，$\mu$和$\sigma$网络输出参数化分布$p$，其负对数似然（$\mathcal{L}$）用作训练目标。直觉是，神经网络是根据预测分布如何很好地解释训练样本来训练的，因此神经网络学会预测与数据点$x$相对应的输出量的分布。
但是，由于以下原因，我无法理解这如何在推理时产生有效的不确定性估计（$\sigma$）：

由于$\mu$和$\sigma$本身就是点估计，我们不知道它们相关的不确定性。
如果我们假设在训练期间，每个数据点估计的$\sigma$产生校准的异方差残差，则不能保证这将适用于样本外数据（由于协变量偏移），假设未进行温度缩放等操作。
如果数据不是来自 $p$ 分布系列（因此 $\mathcal{L}$），预测的不确定性 $\sigma$ 可能会进一步校准错误。

因此，对于预测 $\mu$ 和 $\sigma$ 的神经网络，在什么条件下可以将尺度 $\sigma$ 视为将位置 $\mu$ 作为预测量时不确定性的有效估计？]]></description>
      <guid>https://stats.stackexchange.com/questions/652113/uncertainty-of-ann-outputs-as-distribution-parameters</guid>
      <pubDate>Wed, 31 Jul 2024 20:11:49 GMT</pubDate>
    </item>
    <item>
      <title>合并两组正态分布样本后的分布</title>
      <link>https://stats.stackexchange.com/questions/652103/distribution-after-combining-two-sets-of-normal-distribution-samples</link>
      <description><![CDATA[假设我从分布 $N(\mu_1,\sigma_1^2)$ 中抽取 $N1$ 个样本，从分布 $N(\mu_2,\sigma_2^2)$ 中抽取 $N2$ 个样本。这两个分布是独立的。
可以将$N1+N2$个观测值的组合样本视为来自单个正态分布$N(\mu,\sigma^2)$的样本吗？
其中$\mu = \frac{N1}{N1+N2}\mu_1+\frac{N2}{N1+N2}\mu_2$，$\sigma^2=(\frac{N1}{N1+N2})^2\sigma_1^2+(\frac{N2}{N1+N2})^2\sigma_2^2$。
如果是，那就太好了；如果不是，其分布情况如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/652103/distribution-after-combining-two-sets-of-normal-distribution-samples</guid>
      <pubDate>Wed, 31 Jul 2024 17:59:41 GMT</pubDate>
    </item>
    </channel>
</rss>