<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 16 May 2024 01:01:35 GMT</lastBuildDate>
    <item>
      <title>基于曲线预测连续变量</title>
      <link>https://stats.stackexchange.com/questions/647329/predicting-continuous-variable-based-on-curve</link>
      <description><![CDATA[我有一组在不同频率下测量的曲线的数据集，因此它由如下图所示的曲线组成。当然，我的数据集还有更多曲线。曲线与连续因变量（例如高度）相关联。哪种机器学习方法可以让我根据整个曲线来预测因变量的值？
我想过线性混合效应，但是有没有一种机器学习方法，例如高斯过程，有谁知道我如何做到这一点的例子？
我没有高斯过程的经验，但我想学习如何做到这一点。
谢谢，非常感谢您的帮助。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647329/predicting-continuous-variable-based-on-curve</guid>
      <pubDate>Thu, 16 May 2024 00:53:41 GMT</pubDate>
    </item>
    <item>
      <title>测试时间序列数据的平稳性</title>
      <link>https://stats.stackexchange.com/questions/647327/testing-time-series-data-stationarity</link>
      <description><![CDATA[我正在处理时间序列，想要测试不同的预测方法，但首先我需要测试我的时间序列（销售）数据是否稳定。所以我一直在学习KPSS和Dickey-fuller测试。我的数据是以百万美元为单位的货币价值
我是个新手，所以我仍在学习、阅读和观看有关如何操作的教程。我开发了一个 dickey-fuller：

无漂移：
t-stat=-1.6899
有漂移：
t-stat=9.9672
漂移+趋势：
t-stat=-9.9099
增强（2 个滞后）：
t-stat=-4.6365

我的最全面的关键价值观是：

&lt;标题&gt;

值
无趋势
趋势


&lt;正文&gt;

1%
-3.43
-3.96


5%
-2.86
-3.41



我所看到的（如果我错了，请纠正我）是，除了“无漂移”之外的所有内容都可以。 t-stat 显示我的时间序列数据是平稳的。
第一个问题：我是否可以假设因为 4 个 t 统计中有 3 个通过了平稳性测试，所以我的系列数据是平稳的？我不清楚如果无漂移 t-stat 显示不平稳，我应该得出什么结论。
第二个问题：我的累积残差没有加到零，所以这意味着我做错了什么？
因为我对Dickey-fuller感到困惑，所以我也参加了KPSS测试。以下是我的结果：

&lt;标题&gt;

值
常量
常量 + 趋势


&lt;正文&gt;

KPSS
0.02090016
0.020655886


临界值95%
0.463
0.146


临界值99%
0.739
0.216



因此，因为我的临界值高于我的 KPSS 统计数据，所以我接受零假设，并且我的数据系列是平稳的。
完成所有测试后，看起来我的数据确实是静止的，但我不确定我的残差没有加到零这一事实是否意味着我做错了什么，并且 t-stat 是否没有漂移，表明单位根的存在与我继续使用需要固定数据的预测方法相关。
如果您可以支持我，请告诉我。
提前谢谢您。
正如我之前提到的：
创建数据图表
迪基富勒测试
没有漂移，
随着漂移，
漂移+趋势，
增强（2 个滞后），以及
KPSS - 您可以看到上面的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/647327/testing-time-series-data-stationarity</guid>
      <pubDate>Thu, 16 May 2024 00:13:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用泊松和高斯族对泊松数据进行 glm 拟合几乎没有差异？</title>
      <link>https://stats.stackexchange.com/questions/647325/why-is-there-little-difference-in-glm-fit-using-poisson-and-gaussian-family-for</link>
      <description><![CDATA[我一直对模拟泊松分布数据的玩具回归问题感到困惑，并希望受过更多统计学教育的人可以帮助我对以下观察结果有一些了解。
使用的库
库(tidyverse)
图书馆（牛区）
图书馆（扫帚）
库（基于模型）
库（参数）
图书馆（ggbeeswarm）

数据生成
我使用 rpois 模拟了两种场景的计数值：

交通事故计数，其中 lambda 与交通量成线性比例。
当 lambda 按交通量指数缩放时的交通事故计数。

# 观察值
n_obs = 10

# 生成日志相关数据
流量 = log(c(1, 2, 4, 7, 10, 15))
日志数据=小标题（
  流量=流量_流量，
  lambda=exp(0.43*体积+0.2)
) %&gt;%
  逐行 %&gt;%
  mutate(accident_counts = list(rpois(n_obs, lambda = lambda))) %&gt;%
  突变（observed_avg_accidents = 平均值（accident_counts））

# 生成线性相关数据
线性数据=小标题（
  流量=流量_流量，
  拉姆达 = 0.43*体积 + 0.2
) %&gt;%
  逐行 %&gt;%
  mutate(accident_counts = list(rpois(n_obs, lambda = lambda))) %&gt;%
  突变（observed_avg_accidents = 平均值（accident_counts））

建模
我为每个数据集拟合了两个 glms。一种使用gaussian族，另一种使用poisson族。我对日志数据使用了“log”链接器，对线性数据使用了“identity”链接器。
# 适合
proc_list = 列表(
  日志=列表（数据=log_data，链接器=“日志”），
  线性=列表（数据=线性_数据，链接器=“身份”）
）
模型 = 地图（proc_list，函数（proc）{
  泊松模型 &lt;- glm(
    事故计数 ~ 数量，
    数据 = proc$data %&gt;% unnest(accident_counts),
    家庭=泊松（链接= proc $链接器），
  ）
  高斯模型 = glm(
    事故计数 ~ 数量，
    数据 = proc$data %&gt;% unnest(accident_counts),
    族=高斯(link=proc$linker),
    开始=c(1, 1)
  ）
  返回（列表（“泊松”= poisson_model，“高斯”= gaussian_model））
})

结果
&lt;代码&gt;&gt; Compare_models(unlist(模型，递归=FALSE))

参数|对数泊松 |对数高斯 |线性泊松|线性高斯
-------------------------------------------------- ----------------------------------------------------------
（拦截）| 0.01（-0.40，0.43）| -0.03 (-0.59, 0.53) | 0.39（0.06，0.73）| 0.43（-0.08，0.94）
卷 | 0.52（0.32，0.72）| 0.54（0.30，0.79）| 0.36（0.13，0.59）| 0.34（0.05、0.62）
-------------------------------------------------- ----------------------------------------------------------
观察| 60| 60| 60| 60

可视化
# 创建可视化网格并预测值
viz_grid = modelbased::visualization_matrix(tibble(volume=traffic_volume)) %&gt;% as_tibble
增强=map_df（unlist（模型，递归= FALSE），函数（.x）{
  增强（.x，newdata = viz_grid，type.predict =“响应”）
}, .id=&quot;型号&quot;)

# 单独的模型和数据标签
增强=增强%&gt;%
  split(“模型”, c(“数据”, “回归”), sep=&quot;\\.&quot;)

p = map_df(proc_list, ~.x$data, .id=&quot;数据&quot;) %&gt;%
  解除嵌套（事故计数）%&gt;%
  ggplot(aes(体积, 事故计数)) +
  # geom_violin(调整=1.5) +
  geom_quasirandom() +
  几何点（
    data=~.x %&gt;% unique(数据、体积、observed_avg_accidents),
    aes（数量，observed_avg_accidents），
    颜色＝“红色”
  ) +
  geom_line(数据=增强，aes(体积，.fitted，颜色=回归)) +
  facet_wrap(~data, labeller=label_both) +
  主题灰色(base_size=16)
p %&gt;% ggsave(file=“temp.pdf”, w=8, h=4)


问题
为什么无论家庭功能如何，拟合基本上没有差异？我故意选择了少量的观察值和相对较小的 lambda 值，希望使用高斯拟合家庭会崩溃。但这并没有发生。如果这里的数据生成过程真的是泊松分布，那么族函数的选择不会影响拟合吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647325/why-is-there-little-difference-in-glm-fit-using-poisson-and-gaussian-family-for</guid>
      <pubDate>Wed, 15 May 2024 23:10:11 GMT</pubDate>
    </item>
    <item>
      <title>PCA 因子模型 - 无关紧要的因子载荷</title>
      <link>https://stats.stackexchange.com/questions/647324/pca-factor-model-insignificant-factor-loadings</link>
      <description><![CDATA[我有一个包含 N 个资产的时间序列，我正在尝试为其估计因子模型。令 $Z_{t}$ 为这些资产在 $t$ 时的价格之一。我们可以将其写为：
$$
Z_{t} = β F_{t} + θ_{t}
$$
其中 $F_{t}$ 是一些线性因子，$\theta_{t} = \alpha + \ epsilon_{t}$，$\epsilon_{t}$ 是一些具有协方差的白噪声 $\Sigma_ {\theta}$
有了这些假设，我们可以将 $Z_{t}$ 的期望值写为：
$$
\mu_{z} = \alpha + \beta \mu_{F}
$$
协方差矩阵：
$$
\Sigma_{z} = \beta\Sigma_{\theta}\beta^{T} + \Sigma_{\theta}
$$
我们的想法是，我们显着减少了需要估计的参数数量（尤其是协方差），因此（希望）估计出噪声较小的均值和协方差。
如果有一些股票投资组合，其投资组合权重为 $\mathbb{x}$，那么我们可以将投资组合均值写为 $\mu_{p} = \mathbb{b}\mu_{F}$，其中 $\mathbb{b} = \beta^{T }\mathbb{x}$ 和投资组合协方差为 $\mathbb{b}^{T}\Sigma_{F}\mathbb{b} + \mathbb{ x}^{T}\Sigma_{\theta}\mathbb{x}$。
我选择对贬低数据矩阵进行 SVD 分析作为因子模型（可以证明这相当于对协方差进行 PCA）。这非常方便，因为协方差矩阵 $\Sigma_{F}$ 与特征值平方成对角线。一旦我获得了 PC，我的 $F_{t}$，我就会估算 $\beta$ OLS 参数（但是，我也尝试了一些其他方法，例如迭代重新加权最小二乘法）。然而，在诊断分析中我可以看到这些参数并不重要。我对此有点困惑。一方面，我将其理解为只是一种线性代数方法，即最小二乘法只是一种用于查找因子的数值方法，那么显着性应该不重要（与推理意义上的回归不同）。即便如此，如果我的参数接近于零（微不足道），那么我的因子并没有真正..正确分解..。
有人可以向我解释一下这个结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647324/pca-factor-model-insignificant-factor-loadings</guid>
      <pubDate>Wed, 15 May 2024 23:05:28 GMT</pubDate>
    </item>
    <item>
      <title>条件期望算子是否像线性代数中的投影矩阵那样具有可解释的分解？</title>
      <link>https://stats.stackexchange.com/questions/647323/does-the-conditional-expectation-operator-have-an-interpretable-decomposition-li</link>
      <description><![CDATA[我试图将有限线性空间中的投影概念与无限线性空间中的投影概念进行比较。
这是设置，首先是有限维情况，然后是无限维情况：
给定一个单射矩阵 $A: \mathbb{R}^m \rightarrow \mathbb{R}^n$，我们可以构造一个正交投影算子让$P_A = A(A^TA)^{-1}A^T$。然后我们可以用它来获取 $y \in \mathbb{R}^n$ 并将其投影到 $A$ 得到 $P_A y = x \in \text{col(A)}$。
现在假设我们有两个随机变量 $X$ 和 $Y$，其二阶矩存在。条件期望 $\mathbb{E}[X|Y]$ 为我们提供了一些新的随机变量 $h(Y) $ 即 $X$ 到 $\sigma(Y)$ 的正交投影，$Y$ 的 sigma 代数。
我的问题是，在条件期望情况下是否存在与 $A$ 类似的可解释的类比。也就是说， $\mathbb{E}[X|Y]$ 是 $P_A$ 作为 [ ???] 是 $A$。
我看到用户 ExcitedSnail 在这里&lt; /a&gt;，但问题下面的评论似乎没有解决问题，除非我只是误解了。]]></description>
      <guid>https://stats.stackexchange.com/questions/647323/does-the-conditional-expectation-operator-have-an-interpretable-decomposition-li</guid>
      <pubDate>Wed, 15 May 2024 21:59:19 GMT</pubDate>
    </item>
    <item>
      <title>在回归模型中包含不相关变量时的方差比</title>
      <link>https://stats.stackexchange.com/questions/647322/variance-ratio-when-including-irrelevant-variables-in-a-regression-model</link>
      <description><![CDATA[我有兴趣知道是否有一个通用公式来计算正确指定模型和错误指定模型中预测变量的回归系数方差之比。
具体来说，假设我们有一组与回归 X 真正相关的变量和一组与回归 Y 不相关的变量，并且我们做了两个回归。
首先，我们进行 $y = X\beta_1$ 形式的加权最小二乘回归，这是正确的，并给出了 $\hat{\beta_1}$。
然后，我们进行形式为 $y = X\beta_1 + Y\beta_2$ 的加权最小二乘回归，这是正确的，给出的系数估计为$\tilde{\beta_1}$。
我有兴趣以封闭形式描述比率 $var(\hat{\beta_1}) / var(\tilde{\beta_1})$。&lt; /p&gt;
对于普通的未加权线性回归，Fomby 表现出回归分析效率损失，原因是
不相关变量：根据预测变量 $r_i$ 之间的典型相关性，两个模型中的方差比存在一个封闭形式 $var(\hat{\beta_1}) / var(\tilde{\beta_1}) = \prod_i \frac{1}{1 - r_i^2}$。
对于加权最小二乘法的情况，是否有一个清晰的概括？]]></description>
      <guid>https://stats.stackexchange.com/questions/647322/variance-ratio-when-including-irrelevant-variables-in-a-regression-model</guid>
      <pubDate>Wed, 15 May 2024 21:57:27 GMT</pubDate>
    </item>
    <item>
      <title>包含随机效应会降低模型拟合度</title>
      <link>https://stats.stackexchange.com/questions/647320/including-random-effect-reduces-model-fit</link>
      <description><![CDATA[我正在将零膨胀负二项式 GLMM 拟合到模型计数中。除 Effort_sq 为非零值外，固定效应均为分类效应。该实验在一次旅行中进行了多次，并进行了多次旅行（&gt; 6 个级别，因此我将其作为随机效应包括在内）。
shark_zi &lt;- glmmTMB(sharks ~ Treatment+ Net_type + Effort_sq + (1|Trip_code), ziformula = ~., family=“nbinom1”, data=P1)

我使用 DHARMa 包执行诊断，它表明分位数测试很重要：
simulateResiduals（fittedModel = shark_zi，plot = T）


但是，如果我尝试使用 GLM，则测试并不重要：
shark_zi_2 &lt;- glmmTMB(sharks ~ Treatment+ Net_type + Effort_sq, ziformula = ~., family=“nbinom1”, data=P1)

模拟残差（fittedModel = shark_zi_2，图= T）


我比较了两个模型，如  Bolker GLMM 常见问题解答
anova(shark_zi, shark_zi_2)


我如何解释这些结果以及为了改善贴合度我还应该考虑什么？我没有其他变量作为随机效应包含在内，并且我已经使用“疏浚”执行了模型选择，但由此产生的简化模型也不太适合。
另外，排除随机效应会不会是伪复制？根据 Hurlbert (1984)，“考虑不测试随机效应的显着性。如果随机效应是实验设计的一部分，这个过程可以被认为是“牺牲性伪复制”
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647320/including-random-effect-reduces-model-fit</guid>
      <pubDate>Wed, 15 May 2024 21:30:03 GMT</pubDate>
    </item>
    <item>
      <title>我对嵌套交叉验证、最终模型调整的理解/方法是否正确？</title>
      <link>https://stats.stackexchange.com/questions/647319/is-my-understanding-approach-to-nested-cross-validation-final-model-tuning-corr</link>
      <description><![CDATA[我正在使用不平衡类的有限训练数据来训练 SVM。
以下是我想做的事情：
1.) 我想声明该方法对不同独立训练和测试数据集的通用性。
2.) 我想训练最终的生产模型。
对于 1.)，我的理解是我会进行嵌套交叉验证。
这是我从各种来源艰难地总结出来的方法，只是希望得到有关这里是否有严重错误的反馈：
# 我想在优化中尝试的 SVM 参数
parameters_svm = {&#39;C&#39;: [1, 10, 100, 1000], &#39;kernel&#39;: [&#39;线性&#39;], &#39;概率&#39;: [True]}



# 定义内部和外部cv
# 在这里，我为内部简历选择了“n_splits=5”，为外部简历选择了“n_splits=10”，因为 https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/
# 我决定在这里使用 StratifiedKFold 作为内部简历，因为类别不平衡
# 我决定在外部 cv 中使用带有 n_repeats=10 的 RepeatedStratifiedKFold，因为它将在合理的时间内运行，并且因为您希望获得基于多次迭代的性能数字似乎是有意义的。


inner_cv = StratifiedKFold(n_splits=5,random_state=42, shuffle=True)
external_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)




# 运行嵌套交叉验证并计算外部分数（泛化误差）
嵌套得分 = cross_val_score(clf, X=nX, y=y, cv=outer_cv, 评分=&#39;balanced_accuracy&#39;)

print(f&#39;嵌套 CV 平衡精度：{nested_scores.mean()} +/- {nested_scores.std()}&#39;)

对于 2.)，我在这里不太确定，我已经看到了一些关于利用在嵌套 CV 中最常表现最佳的超参数集的讨论，但基于此 link 我会做一个外循环的循环，例如： 
grid = GridSearchCV(估计器=SVC(), param_grid=parameters_svm, cv=outer_cv, Scoring=&#39;balanced_accuracy&#39;)
网格.fit(X, y)

# 获取最佳参数
best_params = grid.best_estimator_.get_params()

这一切有意义还是我离谱了？]]></description>
      <guid>https://stats.stackexchange.com/questions/647319/is-my-understanding-approach-to-nested-cross-validation-final-model-tuning-corr</guid>
      <pubDate>Wed, 15 May 2024 21:04:03 GMT</pubDate>
    </item>
    <item>
      <title>相关数据集中的 Fisher 精确检验</title>
      <link>https://stats.stackexchange.com/questions/647318/fisher-exact-test-in-correlated-dataset</link>
      <description><![CDATA[假设我有 n 个科目。我对它们进行了两次测量，得出了一些二元结果。现在我想测试之前测量的结果是否与后来测量的结果一致。通常，我需要通过 McNemar 检验而不是卡方检验/Fisher 精确检验来完成此操作，后者不考虑重复测量。
$Q:$ 假设给出了数据 (n&lt;50) 并且标识符被删除。人们被迫使用卡方检验或费舍尔精确检验。假设在这种情况下相关性为正。在这种情况下可以使用 Fisher 精确检验吗？请注意，Fisher 的精确检验条件基于边际，而卡方条件基于独立性假设。
$Q&#39;:$ 在这种相关性&gt;0.2 的情况下，卡方检验和 Fisher 精确检验的覆盖范围有多差？]]></description>
      <guid>https://stats.stackexchange.com/questions/647318/fisher-exact-test-in-correlated-dataset</guid>
      <pubDate>Wed, 15 May 2024 21:02:21 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试拟合一个混合效应模型，并以比例作为响应。我很困惑哪个分布适合我的模型</title>
      <link>https://stats.stackexchange.com/questions/647316/i-am-trying-to-fit-a-mixed-effects-model-with-a-proportion-as-the-response-im</link>
      <description><![CDATA[目前，这是我最适合的模型。 dHARMA 看起来不太好。响应有许多 0 和许多 1
model_pollen_species.bi &lt;- glmmTMB(proportion_sunflower ~ 物种 + (1|farm) + (1|date) + (1|Bee.ID), family = binomial(link = &quot;logit&quot;),
数据=组合花粉）
诊断（model_pollen_species.bi）
simulation.model_pollen_species.bi &lt;-simulateResiduals(fittedModel = model_pollen_species.bi)
绘图（simulation.model_pollen_species.bi）
dHARMA 残差：
!(https://imgur.com/a/8LGNeFm)]]></description>
      <guid>https://stats.stackexchange.com/questions/647316/i-am-trying-to-fit-a-mixed-effects-model-with-a-proportion-as-the-response-im</guid>
      <pubDate>Wed, 15 May 2024 20:45:12 GMT</pubDate>
    </item>
    <item>
      <title>关于比较 3 个比例的卡方检验的困惑</title>
      <link>https://stats.stackexchange.com/questions/647315/confusion-about-the-chi-squared-test-to-compare-3-proportions</link>
      <description><![CDATA[我进行了一项受试者内实验，其中每个参与者回答 3 个二元问题（A、B 和 C）。这意味着所有参与者都回答了所有问题。
我想比较每对问题之间正确答案的比例：p(A) 是否与 p(B) 有显著差异？其他两对也一样。
我的第一个想法是对每对问题进行 3 次测试，即测试 H0 的形式为“p(X) = p(Y)”，其中 X、Y = A、B 或 C。这就是我认为当只有两个问题时进行卡方检验的方式。
还有什么可以提供对整个表进行的卡方检验？
在这种情况下，最好进行哪些测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/647315/confusion-about-the-chi-squared-test-to-compare-3-proportions</guid>
      <pubDate>Wed, 15 May 2024 20:26:38 GMT</pubDate>
    </item>
    <item>
      <title>给定$X$和$Y$的边际和联合分布，如何从$X=x_0$估计$Y=y_0$？</title>
      <link>https://stats.stackexchange.com/questions/647312/given-the-marginals-and-joint-distribution-of-x-and-y-how-to-estimate-y-y</link>
      <description><![CDATA[假设我有两个随机变量 $X$ 和 $Y$ 及其边际分布（例如GEV 和 t 位置尺度），并假设它们的联合分布是 Frank copula 及其参数 ($\theta$)。我想知道，对于给定的 $X$ 值，如何估计 $Y$&lt; 的相应值/span&gt; 来自联合分布？
我已阅读这篇相关文章它的链接，但仍然无法弄清楚如何评估联合分布的条件期望。顺便说一句，正如链接文章中提到的，我还看到了 Python 中的一个 copula 包，您可以在其中插入数据，并且它会模拟具有相同依赖结构的新数据。但我不知道如何根据 $X$ 的给定值估计 $Y$将联结函数拟合到数据。
编辑：
我将用一个例子来阐明我的观点，
假设我们有 100 行数据，其中有两个随机变量 $X$ 和 $Y$。假设我已经计算了 $X$ 和 $Y$ 的边际分布及其联合分布（这是系词）。假设我的数据中的一行的值为 $X=10 $ 和 $Y= 15.4$ ，我想使用拟合的 copula 来开发一个模型，这样如果我将值 $X=10$ 赋予模型，它就会估计相应的 $Y$（假设它估计为$Y= 15.6$）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647312/given-the-marginals-and-joint-distribution-of-x-and-y-how-to-estimate-y-y</guid>
      <pubDate>Wed, 15 May 2024 20:01:16 GMT</pubDate>
    </item>
    <item>
      <title>最高密度与等尾置信区间</title>
      <link>https://stats.stackexchange.com/questions/647310/highest-density-vs-equal-tailed-confidence-interval</link>
      <description><![CDATA[当采样分布是对称的（如果必要的话，我也可以假设单峰分布），很自然地将置信区间集中在点估计周围。但对于偏态分布（例如卡方），选择端点（在我见过的每一本书中）来创建 等尾间隔（ETI） 这似乎也是一个“自然”的选择。但在这种情况下，另一个自然的选择是最高密度区间 (HDI)。 （我只在贝叶斯可信区间设置中看到过 ETI 和 HDI，但它们似乎同样适用于频率论置信区间设置。）

在现实世界中是否存在使用 HDI 置信区间（更有意义？）的场景？我更喜欢一个统计量是样本方差的示例。
为什么教科书中没有讨论 HDI 与 ETI 的置信区间？
]]></description>
      <guid>https://stats.stackexchange.com/questions/647310/highest-density-vs-equal-tailed-confidence-interval</guid>
      <pubDate>Wed, 15 May 2024 19:34:37 GMT</pubDate>
    </item>
    <item>
      <title>可微分投票损失</title>
      <link>https://stats.stackexchange.com/questions/647306/differentiable-voting-loss</link>
      <description><![CDATA[我遇到一个问题，需要我为图像表示的场景中的每个对象（例如 0 或 1）分配一个类。我将其视为分割问题（​​因为场景中有很多对象，我想立即处理整个场景）。我事先知道对象边界。
但是，这意味着学习网络会针对每个像素而不是每个对象生成分类。我使用的是 IoU 和 Dice 损失，它们是常见的分割损失，旨在精确匹配分割掩模。
然后，我可以对对象的所有像素进行投票，以在对象级别进行分类。
但是，对我来说，更重要的目标是每个对象类分配的准确性。由于我使用像素投票来确定多数类，因此这是一个不可微分的操作 - 我如何将其转变为可以通过反向传播的可微分代理？]]></description>
      <guid>https://stats.stackexchange.com/questions/647306/differentiable-voting-loss</guid>
      <pubDate>Wed, 15 May 2024 18:44:54 GMT</pubDate>
    </item>
    <item>
      <title>使用 matplotlib 展示广义数据</title>
      <link>https://stats.stackexchange.com/questions/647314/showcasing-generalized-data-with-data-using-matplotlib</link>
      <description><![CDATA[阿富汗面包平均价格
我们目前正在调查世界各地的食品价格。我们想要显示某个国家/地区价格的总体趋势（以阿富汗为例）。目前，我们的图表显示了多年来每个城市的价格变化以及每个时间段所有市场的平均价格（显示为黑线）。我们关心异常值如何影响平均值。我们是否应该使用更好的指标，例如方差、z 分数？我们希望能够将其展示在与数据点相同的图表/图片上。
阿富汗面包价格存在差异，忽略图例中的“平均”
我们尝试了方差（pandas df.var()），但它使我们的轴倾斜，因为它的比例不正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/647314/showcasing-generalized-data-with-data-using-matplotlib</guid>
      <pubDate>Wed, 15 May 2024 15:57:21 GMT</pubDate>
    </item>
    </channel>
</rss>