<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sun, 16 Mar 2025 06:22:08 GMT</lastBuildDate>
    <item>
      <title>当响应变量主观时该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/662693/what-to-do-when-the-response-variable-is-subjective</link>
      <description><![CDATA[
一群研究人员想对“友好”的方式建模答案
医生提供的医疗建议提供。有医疗清单
问题 - 要求每个人都保存答案。这
然后将答案显示给人类列表，这些清单将排名答案
就友善而言（从1到10）。年龄和
每个研究人员的经验都是已知的。

 但是，如果“友好性”，真的可以制作模型。是主观数量吗？ 
我试图阅读有关潜在回归模型和项目响应的信息，以查看在这种情况下是否可以完成某件事。我写道：
The (true) latent response for rater $i$ and answer $j$ is $Y_{ij}^*$ :
  $$ y_ {ij}^* = \ theta_j- \ beta_i + \ epsilon_ {ij} $$ 
 $$ \ beta_i = \ beta_0 + \ beta _ {\ text {age}} \ cdot \ cdot \ text {age} _i + \ beta _ {\ beta _ {\ text}
 $$ y_ {ij}^* = \ theta_j- \ beta_0  -  \ beta _ {\ text {age}} \ cdot \ cdot \ cdot \ cd {age} _i} _i} _i- \ beta _ \ beta _ { \ epsilon_ {ij} $$  
其中：

  $ \ theta_j $ 表示“ true”答案的友善 $ j $  
  $ \ beta_i $ 表示评估者的严重性/宽大处理 $ i $   
  $ \ epsilon_ {ij} $ 是随机变化
  $ \ beta_0 $ 是基线严重性参数
在
在
  $ u_i $ 是单独的随机效果

然后，观察到的等级 $ y_ {ij} $ （以：将值1，2，...，...，...，...，10）连接到潜在响应
  $$ y_ {ij} = k \ text {if} \ gamma_ {k-1}＆lt; y_ {ij}^* \ leq \ gamma_k $$  
   $ i $ 给出答案 $ j $   $ k $ 的额定值是（因为class =“数学 - 范围”&gt; $ f $ 是logistic Distribution  $ f（x）= \ frac {1} {1 + e^{ -  x}}} $ ）：）：）：）
  $$ P（y_ {ij} = k）= P（\ gamma_ {k-1}＆lt; y_ {ij}^* \ leq \ gamma_k）
  $$ P（Y_ {IJ} = K）= P（\ Gamma_ {K-1}＆lt; \ Theta_j- \ \ beta_i + \ epsilon_ {ij}
 $$ = P（\ gamma_ {k -1}  -  \ \ theta_j + \ beta_i＆lt; \ epsilon_ {ij} \ leq \ leq \ gamma_k- \ theta_j + beta_i_j + beta_i_i）
$$ P(Y_{ij} = k) = F(\gamma_k - \theta_j + \beta_i) - F(\gamma_{k-1} - \theta_j + \beta_i) $$
  $$ p（y_ {ij} = k）= \ frac {1} {1 + e^{ - （\ gamma_k- \ theta_j + \ beta_i_i）}}}}}}}}}}}}}}}  -  \ frac {1} {1} {1} {1 + e^_________________（\ k-1（\ k-^{ -  \^thth-a） \ beta_i）}} $$  
  $$ p（y_ {ij} = k）= \ frac {1} {1 + e^{ - （\ gamma_k- \ \ theta_j + \ beta_0 + \ beta_0 + \ beta + \ beta _ { \ beta _ {\ text {exp}} \ cdot \ text {经验} _i + u_i）}}}}}  -  \ frac {1} {1 + e^{ - （\ gamma_ {k -1 {k -1}  - \ text {age} _i + \ beta _ {\ text {exp}} \ cdot \ cdot \ text {axepens} _i + u_i）}}} $$   
通过大量工作，我可以定义可能性并估算参数以估计“ true”。给定答案的友好性...但是，如果真正的友善是从根本上主观的，那么这是否毫无意义（即使使用潜在模型）？像SEM这样的事情更好吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662693/what-to-do-when-the-response-variable-is-subjective</guid>
      <pubDate>Sun, 16 Mar 2025 04:56:49 GMT</pubDate>
    </item>
    <item>
      <title>两阶段采样设计的样本尺寸，第一阶段包括分层</title>
      <link>https://stats.stackexchange.com/questions/662691/sample-size-for-two-stage-sampling-design-where-the-first-stage-includes-strati</link>
      <description><![CDATA[我正在使用两阶段的采样设计，其中第一阶段包括分层。我的目标是估计人口比例 $ \ hat {p} $ 具有指定的错误和置信度级别。
具体来说，我需要确定：
 在第一阶段的样本大小（即，在每个层中选择的主要采样单元（PSU）的数量）。
在第二阶段（即，在每个PSU中选择的辅助采样单元（SSU）的数量）。
 
考虑到所需的误差和置信度范围，我应该使用哪些方法或公式来计算两个阶段的样本量？？
任何指导或对实际示例的参考都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/662691/sample-size-for-two-stage-sampling-design-where-the-first-stage-includes-strati</guid>
      <pubDate>Sun, 16 Mar 2025 00:50:57 GMT</pubDate>
    </item>
    <item>
      <title>与Newey-West SE的模型内模型具有很高的T统计数据，但并不重要</title>
      <link>https://stats.stackexchange.com/questions/662688/within-model-with-newey-west-se-has-high-t-stats-but-not-significant</link>
      <description><![CDATA[我在r中使用 feols（）在敏感性测试带有Newey-West标准误差。观察次数为5,672，单个面板ID的数量为3,843，其自由度比通常的纵向分析（2年Fe，15 fe，fe and fe and conteraction）。的相互作用）。的相互作用。
我知道这将影响推断期间T分布的形状。但是，我的T-Statats巨大为-4.673702，但p值为0.13。尽管T统计量很高，但我不太了解输出如何毫无意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/662688/within-model-with-newey-west-se-has-high-t-stats-but-not-significant</guid>
      <pubDate>Sat, 15 Mar 2025 23:09:21 GMT</pubDate>
    </item>
    <item>
      <title>采样事件以预测线性回归中的低频事件</title>
      <link>https://stats.stackexchange.com/questions/662687/sampling-events-to-predict-low-frequency-events-in-linear-regression</link>
      <description><![CDATA[我正在研究一个项目，在该项目中，我正在使用两个不同的数据源来预测一个国家人口的变化为百分比。我从这些不同更新中收到数据的频率相对固定但不同。

  事件类型A ：这些事件给我一个国家人口的快照，并且每五天生产一次数据。

  事件类型b ：这些事件为我提供了有关该国境内城市或州的各种统计数据，并且每天生成几次数据。


请注意，事件类型B 比事件类型A 更频繁地发生。我可以使用事件b 数据来预测事件a 数据。
我正在构建几个功能，以输入线性回归模型。这些功能是在所有事件类型上计算的，我计算出的某些功能是与时间相关的（例如，我可以在事件B中提供给我的某些值的移动平均值，以预测两个事件A类型之间提供的人口的变化）。由于两个不同事件的密度不同，我预测提供较低频率的事件的变化，因此我被引入以下问题：

 在对我的线性回归模型中进行采样事件以进行培训数据时，如果我只在“两个事件” a之间进行一次更新类型？如果我允许在“两个事件”之间进行几个事件进行采样。事件，然后我将绘制相当相关的特征以预测人口增长的相同变化（即，我的“变量变量或“人口增长的变化”，“对于抽样间隔的变化”将是相同的。我认为这可能是一个关注点，因为我有效地复制了我的一些观察值）。

 我是否应该只是抽样事件，在上一个和下一个事件A类型之间计算出的国家人口增长发生巨大变化？在很多情况下，人口增长的变化将接近零（即，在事件A 事件中观察到的国家人口没有变化）。我的“ y”中会有很多零条目可变偏见我的线性模型？我只关心预测的价值超过一定的阈值时，我也不在乎预测小变化（尽管我不想预测在大变化期间的小变化或在小变化期间进行大型移动）。&gt; 


谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662687/sampling-events-to-predict-low-frequency-events-in-linear-regression</guid>
      <pubDate>Sat, 15 Mar 2025 20:54:38 GMT</pubDate>
    </item>
    <item>
      <title>在我的CFA模型中该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/662686/what-to-do-in-my-cfa-model</link>
      <description><![CDATA[我有一个单构建的CFA模型，带有11个项目（关于使用Google Maps的焦虑）。该CFA的目的是验证构建体。它已经以英语存在，但随后翻译成阿拉伯语并需要重新验证（样本尺寸= 342）。
所有项目均为序数（5pt李克特量表），所有项目均显示出高度非正态性（高偏度）。为此，R-Software自动使用DWLS（这对这种情况很有益）。
CHI-Square的 p值均为0（对于用户模型和与基线模型的比较）0。这是第一个坏消息。
cli / tli bot＆gt; 90％这是个好消息。
STD和缩放数据的RMSEA分别为0.085 / 0.124。
SRMR为0.073
以下是负载，导致可接受的AVE。
  如果我删除了带有SQ-loadings＆lt;的项目。 0.5，结果提高了一点：
 1-Chi-square的p值在STD数据中变为0.140，并且缩放为0（这是模型测试用户模型）。为了与基线进行比较，两个p值为0。
 2- CLI/TLI仍然很好（＆gt; 90％）。
 3- rmsea增强到0.037（对于性病数据）和0.083（对于缩放数据）。强大的RMSEA = 0.126。
 4-SRMR为0.03 
 5- ave = 0.7。
您对我有什么建议？我想验证规模。
还有最好的报告（缩放或性病数据）。因为在某些情况下（如您所见），它们相互矛盾。
而且，对于RMSEA，我应该直接使用强大的rmes。但是，正如您所看到的，它太大了。]]></description>
      <guid>https://stats.stackexchange.com/questions/662686/what-to-do-in-my-cfa-model</guid>
      <pubDate>Sat, 15 Mar 2025 20:48:34 GMT</pubDate>
    </item>
    <item>
      <title>澄清包含排除原则中的非空交集数量</title>
      <link>https://stats.stackexchange.com/questions/662685/clarifying-number-of-non-empty-intersections-in-inclusion-exclusion-principle</link>
      <description><![CDATA[我试图更深入地了解包容性排斥原则，尤其是在不同情况下非空交集的数量。虽然我了解包容和排除的基本交替，但我想澄清的是不同级别的非空交集的结构。
似乎有两个主要情况：

 所有n组都有非空交集。 •如果所有n组的交点是非空的，则所有成对的NCHOOSE2，TRIPE NCHOOSE3和最高n的高阶交叉点也必须是非空的。自然而然的是，这是因为非空交叉路口的每个子集仍然是非空的。

 只有一些K＆lt; n交叉点是非空的。 •这种情况似乎更复杂：如果某些大小K相交但不是全部n的子集，我们如何确定较低级别的非空交集的数量？ •是否有一般条件决定每个级别上有多少个交叉点仍然是非空的？ •是否存在组合框架或现有研究，可以量化给定部分交集信息的非空交叉点的数量？


也想知道这一含义：
如果大小k的所有交叉点都是非空的，是否暗示着大小k-1，k-2等的所有交集，也必须是非空的？
例如，如果您设置了ABCD，请定义k = 3。这些是ABC ABD ACD和BCD的交集。其中包括所有可能的成对交叉点AB AC AD BC BD CD，因此，如果ABC，ABD，ACD和BCD都是非空的，那么所有成对的交集也是如此。
我正在寻找一种更严格的方法来分析这一点，而不是直觉。如果有人可以在包容性排斥中考虑这一点时指出相关的组合结果，资源或常见的陷阱，我将非常感谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/662685/clarifying-number-of-non-empty-intersections-in-inclusion-exclusion-principle</guid>
      <pubDate>Sat, 15 Mar 2025 20:37:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么尽管数据增加和高参数调整，为什么我的VIT和RESNET-18模型不超过77％的精度？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/662684/why-do-my-vit-and-resnet-18-models-not-exceed-77-accuracy-despite-data-augmenta</link>
      <description><![CDATA[我正在处理包含7,839张图像的数据集，以进行三类分类任务。我培训了VIT（Vision Transformer）和Resnet-18，但两种模型都达到了73％至77％的精度，尽管尝试了几次尝试。。
这是我已经尝试的技术：
数据增强（旋转，翻转，变焦等）
更改批处理大小
优化学习率
图像归一化
这是否意味着我的数据集太小了这些模型？还是我还可以尝试提高性能？
欢迎任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/662684/why-do-my-vit-and-resnet-18-models-not-exceed-77-accuracy-despite-data-augmenta</guid>
      <pubDate>Sat, 15 Mar 2025 20:20:21 GMT</pubDate>
    </item>
    <item>
      <title>比较两种交叉验证方法用于高参数调整</title>
      <link>https://stats.stackexchange.com/questions/662683/comparing-two-cross-validation-methods-for-hyperparameter-tuning</link>
      <description><![CDATA[对于超参数的交叉验证，我有一个问题，即在运行正规化回归（特别是弹性Net L1，L2惩罚）的背景下通常认为哪种方法更好
假设您有5倍，并且每个折叠的火车/验证拆分为80％/20％。

对于每个折叠的训练集，请选择（L1，L2）处罚的网格，然后拟合回归系数。
对于每个系数测量，验证集中的平方误差
 a vs b在下方

方法A：
对于5倍的每一个，您都会有一个单数（L1，L2）最佳罚款。平均这5个元组获得最佳最佳（L1，L2）
接近b：
对于每个（L1，L2）元组，计算在5倍上设置的平均平方验证误差。最终最佳（L1，L2）是最低的MSE 

这两个中的哪一个会更好地概括？
在我看来，A VS B是您是否信任AVG（折叠的参数）更多vs avg（折叠之间的平方错误）更多？
我可以想到一个看上去差得多的情况，即您适合超参数 $ ax^\ lambda $ 。方法A可能会给您 $ A_1X^2 $ 和 $ a_2x^4 $ 用于两个不同的折叠。 Averaging the exponent here doesn&#39;t make sense since the hyperparameter is nonlinear (ie you would end up fitting $ax^3$), but is this also true in regularized linear regression (specifically the $|\beta|$ l1 term)?
]]></description>
      <guid>https://stats.stackexchange.com/questions/662683/comparing-two-cross-validation-methods-for-hyperparameter-tuning</guid>
      <pubDate>Sat, 15 Mar 2025 20:10:17 GMT</pubDate>
    </item>
    <item>
      <title>观察值和拟合值的协方差</title>
      <link>https://stats.stackexchange.com/questions/662681/covariance-of-observed-and-fitted-values</link>
      <description><![CDATA[我对我在线性回归中响应和拟合值之间看到的几个计算感到困惑。
例如，这是得出偏见变化权衡的标准步骤，以表明
 $$
\ Mathbb {e} [（y- \ \ m athbb {e} [y]）（\ hat y  -  \ mathbb {e} [\ hat y]）| x = x_0] = 0
$$ 
参见例如在这里 href =“ https://web.archive.org/web/20140821063842/http://ttic.uchicago.edu/%7egregory/courregory/courregory/courregory/wis-ml2012/lecters/biasvardecom.pdecom.pdf” class =“ Math -Container”&gt; $ y  -  \ m athbb {e} [y] = \ epsilon $ 是错误项）。
我的理解是，该计算的关键步骤是，如果我们首先在培训数据集上条件 $ \ Mathcal t = \ {（x_1，y_1），\ dots，（x_n，y_n，y_n）\ \} $ ，然后y] $ 对于固定 $ x = x_0 $ ，因此是常数
 $$
\ begin {align} \ tag {1} \ label {eq：1}
\ Mathbb {e} [（y  -  \ \ Mathbb {e} [y]）（\ hat y  -  \ mathbb {e} \ hat [y]）| x = x_0，\ mathcal t]＆amp; =（\ hat y  -  \ mathbb {e} \ hat [y]）\ mathbb {e} [（y- \ \ m马理bb {e} [y] [y]）| X = X_0，\ Mathcal t] \\＆amp; = 0。
\ end {align}
$$  
另一方面，我已经看到了
 $$
\ operatorName {cov}（y_i，\ hat y_i）\ neq 0，
$$ 
参见例如 $ \ operatorName {cov}（y_i，\ hat y_i）= \ operatorname {cov}（y，\ hat y | x = x_i） \ Mathbb {e} [\ hat y]）| x = x_i] $ ，其中现在 $ x_i $ 不是任意的，而是训练集中的一点。
无论如何，方程\ eqref {eq：1}对于任何 $ x = x_0 $ ，特别是对于 $ x = x_i $  a训练集中的点。
如果有人可以解释这两个显然与之相矛盾的结果是兼容的，我将非常感谢。
我有一种感觉，这全都与一个人的条件有关，但是在我看来，这两种情况只有在单个输入点 $ x = x_0 $ 和两个 $ y $  y $ 和 $ \ hat y $ 取决于 $ y $ 通过 $ \ hat y = x \ hat y = x \ hat \ hat \ beta = x（x^tx）]]></description>
      <guid>https://stats.stackexchange.com/questions/662681/covariance-of-observed-and-fitted-values</guid>
      <pubDate>Sat, 15 Mar 2025 19:28:57 GMT</pubDate>
    </item>
    <item>
      <title>小样本重叠如何影响过度拟合：对系数，P值和R²的影响</title>
      <link>https://stats.stackexchange.com/questions/662680/how-small-sample-overlap-affects-overfitting-impact-on-coefficient-p-value-an</link>
      <description><![CDATA[我使用样本量为4,000的数据集训练了一个模型，并在另一个带有结果B和C的样本上测试了该模型。
 A和B之间的相关性为0.7，A和C之间的相关性为0.5。。
排除了测试集中的100个重叠样品后，该预测因子的系数，P值和增量R²大大下降了结果B。但是，对于结果C，仅影响了P值和增量R²，而该系数则受到影响，而该系数可将其置于无链接状态（请参见下表）。
过度拟合会对不同的结果有所不同的原因是什么？这应该如何从统计角度解释？
  &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stats.stackexchange.com/questions/662680/how-small-sample-overlap-affects-overfitting-impact-on-coefficient-p-value-an</guid>
      <pubDate>Sat, 15 Mar 2025 19:21:32 GMT</pubDate>
    </item>
    <item>
      <title>将文本可读性指标与主观测量相关联</title>
      <link>https://stats.stackexchange.com/questions/662642/correlating-text-readability-metrics-against-subjective-measurements</link>
      <description><![CDATA[假设我想找出文本的不同可读性指标与文本复杂性的主观测量相关。我要求18个人阅读12条短文，我衡量他们认为每个文本的量表都有5个项目的范围（因此得分为5.0表示高复杂性）。我想尝试找出哪些度量与主观复杂性最有关系。
一种幼稚的方法是从所有参与者中获取每个文本的平均主观得分，并在应用于文本时发现哪种复杂性度量与结果的相关性最强。但是，我认为这将丢失很多信息（例如，如果两个参与者将他们的某些分数换成一些文本片段，那将不会影响结果，但感觉应该是这样）。多级模型会在这里适当吗？
评论：这个问题类似于
示例：
一个指标可能将第一个文本的复杂性评为4，第二个文本为6等，而另一个指标将在其自身的尺度上对与10和12相同的文本进行评分。同时，一个参与者关于前两个文本的复杂性的主观得分分别为3和4（满分5）。来自不同量表的数字不是直接可比的。我们只想找出他们与参与者的主观分数有多相关。]]></description>
      <guid>https://stats.stackexchange.com/questions/662642/correlating-text-readability-metrics-against-subjective-measurements</guid>
      <pubDate>Fri, 14 Mar 2025 21:32:21 GMT</pubDate>
    </item>
    <item>
      <title>什么是随机变量与有限样本中的完全随机分配相关的$ k $处理</title>
      <link>https://stats.stackexchange.com/questions/662637/what-is-random-variable-associated-with-complete-random-assignment-in-a-finite-s</link>
      <description><![CDATA[我正在尝试创建一个模拟，该模拟随机将有限的样本 $ n $ 进入 $ k $ 处理，并努力地数学上没有这样的任务。我知道如何实施该程序，但是定义了我正在努力的治疗成员的随机变量。
说我们有 $ k = 3 $ 治疗组的总体样本大小为 $ n = 30 $ 。我们希望在每个组中具有平衡的样本量 $ n_k = 10 $ 。
随机变量 $ k_i \ in \ {1,2,3 \} $ 是一个分类变量，代表 $ i $  $  th person。
我们可以建模：
 $$
k_i \ sim多项式（{\ bf {p}} = 1/3，n = 1，k = 3）
$$  
但这不容易 $ n_k $ 仅在期望中常数才能等于 $ n_k $ 。
我将如何注意随机变量 $ k_i $ 给定 $ k_i $ ？]]></description>
      <guid>https://stats.stackexchange.com/questions/662637/what-is-random-variable-associated-with-complete-random-assignment-in-a-finite-s</guid>
      <pubDate>Fri, 14 Mar 2025 19:52:47 GMT</pubDate>
    </item>
    <item>
      <title>低坡/歧视问题：IRT的有用性？</title>
      <link>https://stats.stackexchange.com/questions/662618/low-slope-discrimination-questions-usefulness-in-irt</link>
      <description><![CDATA[在项目响应理论中，2-PL模型同时捕获了斜率和截距，而Rasch模型仅捕获截距，将曲线左/右移动（下面捕获）。。
   IRT的一般背景是推断问题难度和学生能力。尽管X轴范围为（-inf，inf），但可以将其转换为范围（0,1）。换句话说， $ x = 0 $ 捕获中位学生能力（或物品难度，因为它们在同一潜在空间中映射。）
通常，给定曲线的歧视力在其拐点处是最大的。关于上面的红色曲线，拐点位于 $ x = 0 $ ，这意味着，如果一个学生真正处于中间位置，则该问题将提供最大的信息，并随着给定的学生的能力增加或降低信息，从而提供了最大的信息。     。
上下文，我的问题很简单：陡峭的斜坡在实践中总是更喜欢？
假设地，如果给定的问题可以通过零差异返回学生的能力（知道学生在拐点以上或以下），则可以使用二进制搜索来找到学生在 $ o（\ log log（\ log log（n））$（\ log（n））$  $ time。
当然，这些问题不是确定性的，因此我们绝对可以确定学生没有超出他们的能力问题。但是，我认为，随着这些曲线的斜率接近无穷大（ $ \ lim：b \ to \ infty）$ 。
考虑到这一假设，较小的歧视性问题（较低的斜率）有用吗？在什么情况下？
我问了一个类似的问题在这里]]></description>
      <guid>https://stats.stackexchange.com/questions/662618/low-slope-discrimination-questions-usefulness-in-irt</guid>
      <pubDate>Fri, 14 Mar 2025 16:10:25 GMT</pubDate>
    </item>
    <item>
      <title>与自相关和部分自动相关的时间序列</title>
      <link>https://stats.stackexchange.com/questions/662587/time-series-with-autocorrelation-and-partial-autocorrelation</link>
      <description><![CDATA[我正在使用时间序列数据，其中每天由包含24×25网格的CSV文件表示，每个条目都充当像素。
我已经生成了ACF和PACF来了解我的数据的时间结构，并且整天都使用了第一个功能：
 导入statsmodels.api as s sm
导入matplotlib.pyplot作为PLT

系列= data_flatted [：，0]＃整天使用第一个功能
图，轴= plt.subplot（2，1，无花果=（10，8））
sm.graphics.tsa.plot_acf（系列，滞后= 50，ax = axes [0]）
sm.graphics.tsa.plot_pacf（系列，滞后= 50，ax = axes [1]）
plt.show（）
 
我的输出：
对于 lags = 50  
  对于 lags = 100  
  对于 lags = 150  
  对于 lags = 250  
  对于 lags = 500  
  对于 lags = 900  
  从上面的图像中，我会说短/长滞后时的强大ACF相关性表明时间依赖性很大？
或
我的意思是问我的数据集有任何重复模式或趋势？
或
所有数据点都可能遵循一些简单的确定性线性结构方程，并具有一些小的白噪声？
或我的数据集中存在强大的时间依赖性？]]></description>
      <guid>https://stats.stackexchange.com/questions/662587/time-series-with-autocorrelation-and-partial-autocorrelation</guid>
      <pubDate>Fri, 14 Mar 2025 00:47:24 GMT</pubDate>
    </item>
    <item>
      <title>在NLL中，您如何产生给定RMSE（global_minimum_params）的RMSE（true_params）的准确估计？</title>
      <link>https://stats.stackexchange.com/questions/662544/in-nlls-how-do-you-produce-accurate-estimates-of-rmsetrue-params-given-rmseg</link>
      <description><![CDATA[我有指数衰减
  $ f（t）= \ sum_n \ left（a_n e^{ -  \ frac {t} {\ tau_n}} \ right） + c + c + \ epsilon（t）
 n代表不同的指数衰减成分， $ a_n $ 代表每个衰减振幅， $ \ tau_n $ 代表每个衰减率， $ \ epsent ouss  $ c $ 是噪声内固有的偏移常数。我想根据损失创建一个排除标准，以便我可以忽略比真实参数更糟糕的最小值。
我有Levenberg – Marquardt算法的实现，我认为这很好。我已经在单个指数衰减上使用了此损失（3个参数{ $ a $ ， $ \ tau $ ， $ c $ c $  $ c $  $ c $ ）
在
在
到目前为止这还不错，并且使用我在网上找到的方程式，
  $ rmse（true \ _params）\ oft \ frac {rmse（global \ _min \ _params）} {\ sqrt {1- \ sqrt {1- \ frac {\ frac {\ nu} {\ nu}} {p}}} {p}} {
其中 $ \ nu $ 是拟合参数内的自由度，p是信号中的点数。在我的示例中，这个yeilds：
  $ \ frac {0.00990305} {\ sqrt {\ sqrt {1  -  \ frac {3} {2726}}} = 0.00990851
它非常接近实际损失。这给了我希望，在尝试双重衰减时，它很快就被剥夺了（5个params { $ a_1 $ ， $ \ tau_1 $ \ tau_1 $ ， $ a_2 $ a_2 $  $ a_2 $  class =“ Math-Container”&gt; $ \ tau_2 $ ， $ C $ }）：
  $ rmse（true \ _Params）= 0.01059385 \ neq \ frac {0.01007084} {\ sqrt {1  -  \ frac {5}
显然还有其他事情正在发生，我发现的方程式没有描述，但此时我不远。我试图研究一种感觉分析方法，以更好地估计 $ \ nu $ ，而不是使用jacobians的参数数量，但它给出了 $ \ nu = 4.999999 $ 既有趣又有趣and dunelelpful。
这是一篇寻求理论帮助的文章，但我将包括指向完整代码的链接：&lt;a href =“ https://github.com/ollie-spoon/explmopt/blob/blob/main/main/lm_test.ipynb”]]></description>
      <guid>https://stats.stackexchange.com/questions/662544/in-nlls-how-do-you-produce-accurate-estimates-of-rmsetrue-params-given-rmseg</guid>
      <pubDate>Wed, 12 Mar 2025 22:45:06 GMT</pubDate>
    </item>
    </channel>
</rss>