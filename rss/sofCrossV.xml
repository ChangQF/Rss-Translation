<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 25 Jan 2025 12:28:54 GMT</lastBuildDate>
    <item>
      <title>预先注册的假设是否需要进行多重比较校正？</title>
      <link>https://stats.stackexchange.com/questions/660522/do-pre-registered-hypotheses-need-a-correction-for-multiple-comparisons</link>
      <description><![CDATA[我最近偶然发现一个说法，研究人员只需预先注册他们将要执行的每项可能测试的假设，就可以避免使用校正进行多重比较。这是正确的吗？该声明没有引用任何参考文献，老实说，我以前没有在其他地方明确读到过这一点。如果能提供相关文献或任何形式的评论，我将不胜感激。谢谢！
编辑：错别字]]></description>
      <guid>https://stats.stackexchange.com/questions/660522/do-pre-registered-hypotheses-need-a-correction-for-multiple-comparisons</guid>
      <pubDate>Sat, 25 Jan 2025 12:14:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么“充足”的理念仍然有效</title>
      <link>https://stats.stackexchange.com/questions/660518/why-the-idea-of-sufficiency-even-work</link>
      <description><![CDATA[实验
假设有 1000 扇绿门、99 扇红门和 1 扇蓝门。选择一扇门，使得选中红门的概率为 $p$，选中蓝门的概率为 $\frac{p}{2}$，选中绿门的概率为 $1-\frac{3p}{2}$。
假设实验仅进行一次。
可以检查 $T = \mathbb{1}_{\{Red door \cup blue door\}}$ 是否为充分统计量。
但如果我们假设 $p$ 为 $\frac{1}{1000}$，则给定任何 T 值时 R、G、B 的条件概率与最初选择 R、G、B 的实际概率存在很大差异。
疑问
条件概率是否更像是实验完成后妥协的“信念测量”，而不是真实实验的模拟。因此，为什么使用这种技术来模拟数据点是有意义的。我遗漏了什么？
充分统计量的想法是不是要模拟原始实验，而是要创建一种严重偏向所选样本的场景？条件分布将使得那些更接近观察到的样本的点出现的概率更大。]]></description>
      <guid>https://stats.stackexchange.com/questions/660518/why-the-idea-of-sufficiency-even-work</guid>
      <pubDate>Sat, 25 Jan 2025 10:10:19 GMT</pubDate>
    </item>
    <item>
      <title>两种在零和一相等的数组中查找 1 的位置的算法的比较</title>
      <link>https://stats.stackexchange.com/questions/660516/comparison-of-two-algorithms-for-finding-a-position-of-1-in-an-array-with-equal</link>
      <description><![CDATA[给定一个包含一半零和一半一的数组 𝑎[1..𝑛]，我们需要在 𝑎 中找到一个包含值 1 的位置。考虑以下两种算法：
算法 1
i = 1
while a[i] != 1:
i += 1
return i

算法 2
while True:
i = random(1, n)
if a[i] == 1:
return i

函数 random(1, n) 返回 1 和 𝑛 之间的随机整数。
a) 比较这两种算法。
b) 哪种算法更好？
这是我的解决方案部分 (a)：：
算法 1（线性搜索）：
优点：

如果存在，保证找到 1。
易于实现。

缺点：

最坏情况下的时间复杂度为 O(n)，其中 n 是数组的大小。
如果数组的前半部分只包含零，则可能会很慢。

算法 2（随机搜索）：
优点：

如果早点找到 1，则可能会非常快。

缺点：

无法保证在有限的步骤中找到 1。
最坏情况在理论上是无限的。
平均时间复杂度更难分析，但通常比算法 1效率低。

这是我对部分 (b) 的解决方案：

一般而言，算法 1（线性搜索）通常被认为更好。
保证成功：它在有限的步骤内提供保证的解决方案。
可预测的性能：其最坏情况的时间复杂度是已知且有界的。
当算法 2 可能更可取（在非常特殊的情况下）：如果数组非常大，并且早期找到 1 的概率非常高（例如，如果数组几乎完全由 1 填充），算法 2 可能会更快。但是，这是一个非常特殊且不太可能的情况。

在大多数实际情况下，算法 1（线性搜索）是更可靠且通常更有效的选择。
目前，我不知道如何从理论上分析这个问题，所以我希望有人能支持我解决它。]]></description>
      <guid>https://stats.stackexchange.com/questions/660516/comparison-of-two-algorithms-for-finding-a-position-of-1-in-an-array-with-equal</guid>
      <pubDate>Sat, 25 Jan 2025 06:30:52 GMT</pubDate>
    </item>
    <item>
      <title>解释不相关但具有统计意义的 ODD 比率</title>
      <link>https://stats.stackexchange.com/questions/660515/interpreting-odds-ratios-that-are-irrelevant-yet-statistically-significant</link>
      <description><![CDATA[我有一个有点独特的数据集。
结果是一个二进制是/否变量。然而，结果非常不平衡。95% 是，5% 不是。
协变量 1：时间变量，从第 -200 天开始，到第 200 天结束，第 0 天是事件发生的那一天。-200、-199、-113、-14、0、11、25、89、135、200
协变量 2：事件，二进制变量，0（无事件）或 1（事件是）
如您所见，协变量 1（时间）和协变量 2（事件）高度相关。当时间为 -ve 时，事件为 0，当时间为 +ve 时，事件为 1。
当我拟合像这样的简单逻辑回归模型时
 glm(y ~ time + event + time*event, data= df, family=&quot;binomial&quot;)

这些是该模型的估计值
 项 优势比 S.E pvalue。
截距 0.02 0.04 0.051
时间 0.94 0.4 0.47
事件 1.01 0.3 0.9
时间*事件 1.001 0.0004 0.02

我不确定如何截取这些结果。从高层次来看，主要影响是直接的，时间的 OR 为 0.94 且不显著，事件的 OR 为 1.01 且不显著。
然而，时间和事件相互作用的 OR 是显著的，但 OR 实际上毫无意义。不确定如何理解这个总结结果。需要帮助把这些点连接起来。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660515/interpreting-odds-ratios-that-are-irrelevant-yet-statistically-significant</guid>
      <pubDate>Sat, 25 Jan 2025 05:51:09 GMT</pubDate>
    </item>
    <item>
      <title>如何从时间序列模型进行模拟？</title>
      <link>https://stats.stackexchange.com/questions/660513/how-to-simulate-from-time-series-models</link>
      <description><![CDATA[我想我知道如何模拟拟合的 ARIMA 时间序列模型的预测：
library(tidyverse)
library(forecast)
library(patchwork)

set.seed(123)

y_arima &lt;- rnorm(50, mean = 0, sd = 1)
ts_y_arima &lt;- ts(y_arima, frequency = 12)
arima_model &lt;- auto.arima(ts_y_arima)

n_ahead &lt;- 20
n_sims &lt;- 50

arima_sims &lt;- matrix(NA, nrow = n_sims, ncol = n_ahead)
for(i in 1:n_sims) {
arima_sims[i,] &lt;- mock(arima_model, nsim = n_ahead)
}

historical_data_arima &lt;- tibble(
time = 1:50,
value = y_arima,
type = &quot;Historical&quot;
)

arima_future &lt;- tibble(
time = rep(51:70, n_sims),
value = as.vector(t(arima_sims)),
simulation = rep(1:n_sims, each = n_ahead)
)

p1 &lt;- ggplot() +
geom_line(data = historical_data_arima, aes(x = time, y = value), 
color = &quot;black&quot;, size = 1) +
geom_line(data = arima_future, aes(x = time, y = value, group = simulation), 
alpha = 0.2, color = &quot;blue&quot;) +
geom_vline(xintercept = 50, linetype = &quot;dashed&quot;, color = &quot;red&quot;) +
labs(title = &quot;ARIMA Simulations&quot;,
x = &quot;Time&quot;, y = &quot;Y value&quot;) +
theme_minimal()


但我想知道，如何模拟 ARIMAX 模型的预测？我认为应该类似？例如假设我在整个预测过程中将协变量固定为一个常数值（例如 2）：
n_obs &lt;- 50
n_ahead &lt;- 20
n_sims &lt;- 50
future_x_value &lt;- 2
future_x &lt;- rep(future_x_value, n_ahead)

y &lt;- rnorm(n_obs, mean = 0, sd = 1)
x &lt;- rnorm(n_obs, mean = 1, sd = 0.5)

ts_y &lt;- ts(y, frequency = 12)
ts_x &lt;- ts(x, frequency = 12)

arimax_model &lt;- auto.arima(ts_y, xreg = ts_x)

arimax_sims &lt;- matrix(NA, nrow = n_sims, ncol = n_ahead)

for(i in 1:n_sims) {
arimax_sims[i,] &lt;- mock(arimax_model, nsim = n_ahead, xreg = future_x)
}

historical_data_arimax &lt;- tibble(
time = 1:n_obs,
value = y
)

arimax_future &lt;- tibble(
time = rep((n_obs + 1):(n_obs + n_ahead), n_sims),
value = as.vector(t(arimax_sims)),
simulation = rep(1:n_sims, each = n_ahead)
)

p2 &lt;- ggplot() +
geom_line(data = historical_data_arimax, aes(x = time, y =值), 
color = &quot;black&quot;, size = 1) +
geom_line(data = arimax_future, aes(x = 时间, y = 值, group = 模拟), 
alpha = 0.2, color = &quot;green&quot;) +
geom_vline(xintercept = n_obs, linetype = &quot;dashed&quot;, color = &quot;red&quot;) +
labs(title = &quot;ARIMAX 模拟&quot;,
subtitle = paste(&quot;所有未来 X 值设置为&quot;, future_x_value),
x = &quot;时间&quot;, y = &quot;Y 值&quot;) +
theme_minimal()


这是正确的吗？（我想知道是否有办法让彩色模拟与黑色历史数据完全对齐，即消除间隙）]]></description>
      <guid>https://stats.stackexchange.com/questions/660513/how-to-simulate-from-time-series-models</guid>
      <pubDate>Sat, 25 Jan 2025 04:31:45 GMT</pubDate>
    </item>
    <item>
      <title>较弱的“完整”统计定义</title>
      <link>https://stats.stackexchange.com/questions/660508/weaker-complete-statistic-definition</link>
      <description><![CDATA[为什么我们不定义充分统计量 $T(x)$ 的完备性，因为 $g(T(x))$ 依赖于所有函数 g 的 $\theta$？
定义
$$\mathbb{E}_\theta \left[ g(T(X)) \right] = 0 \quad \text{for all } \theta \quad \Rightarrow \quad g(T(X)) = 0 \quad \text{almost sure}$$
似乎更强。
此外，前一个定义似乎足以证明 Basu 定理，而且更直观？]]></description>
      <guid>https://stats.stackexchange.com/questions/660508/weaker-complete-statistic-definition</guid>
      <pubDate>Sat, 25 Jan 2025 00:29:55 GMT</pubDate>
    </item>
    <item>
      <title>使用皮尔逊卡方拟合优度检验来比较混合对数正态和逆伽马拟合数据</title>
      <link>https://stats.stackexchange.com/questions/660507/pearsons-chi-squared-goodness-of-fit-test-to-compare-mixed-log-normal-and-inver</link>
      <description><![CDATA[我有一些数据（非分类数据），我认为它们来自某些基础分布。数据严格为正值。从视觉上看，我认为逆伽马分布和 2 分量混合对数正态分布看起来都是数据的合理分布。我正在使用 Pearson 卡方拟合优度检验（通过 MATLAB 的 chi2gof 函数）来测试我是否应该接受或拒绝我的数据可能来自这些分布的零假设。
虽然 Pearson 卡方检验应该用于分类数据，但我读过许多在构建一些箱体后将其用于非分类数据的例子，这有点主观。关于这一点，我理解每个箱体的预期计数应该有 &gt;5 个计数才能使测试可靠，并且它们不需要均匀分布。但是，由于分箱会影响统计量的计算，我是否应该对每个分布的拟合优度检验使用相同的分箱边界，以便对它们进行最佳比较？
我还想能够说明哪种分布更适合。从视觉上看，混合对数正态分布看起来稍好一些，但我想避免过度拟合，因为有 6 个参数，而逆伽马只有两个参数。我还读到，较低的卡方统计量代表更好的分布。但是，卡方统计量不包含自由度的数量（这仅在从卡方统计量计算 p 值时使用），所以我假设这在比较具有不同数量参数的分布时不一定成立，就像我的情况一样。相反，合理的比较似乎是 p 值较高的分布可能更适合。这听起来对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660507/pearsons-chi-squared-goodness-of-fit-test-to-compare-mixed-log-normal-and-inver</guid>
      <pubDate>Sat, 25 Jan 2025 00:24:47 GMT</pubDate>
    </item>
    <item>
      <title>生存结果和连续中介的中介分析给出了较大的治疗效果估计</title>
      <link>https://stats.stackexchange.com/questions/660506/mediation-analysis-with-survival-outcome-and-continuous-mediation-giving-large-t</link>
      <description><![CDATA[在执行中介分析时，我收到了非常奇怪的输出。
具体来说，我正在使用 AFT 模型和连续变量（即身体质量指数）作为中介，对事件发生时间事件（即心肌梗死）的结果进行中介分析。
但是，在执行分析时，我收到了非常奇怪的治疗效果估计和置信区间，例如效果约为 31,100，95% CI（2,590.00；80,574.58）。
这是正常的吗？收敛过程中是否存在错误或类似情况？
我给你一个示例代码：
event=rep(c(0,1),700)
event=as.numeric(event)
time=as.numeric(c(1:1400))
predictor=as.numeric(rep(c(1,0,0,1),350))
mediator=c(1:1400)

reg=lm(mediator~predictor)

surv=survreg(Surv(event = event, time = time)~ predictor + mediator)

med=mediate(
model.y = surv, model.m = reg, treat = &quot;predictor&quot;, mediator = &quot;mediator&quot;, 
boot = FALSE, sims = 1000
)

摘要（med）
]]></description>
      <guid>https://stats.stackexchange.com/questions/660506/mediation-analysis-with-survival-outcome-and-continuous-mediation-giving-large-t</guid>
      <pubDate>Sat, 25 Jan 2025 00:19:15 GMT</pubDate>
    </item>
    <item>
      <title>如何从 Benjamini Hochberg 检验中获得总体 P 值？</title>
      <link>https://stats.stackexchange.com/questions/660505/how-to-obtain-an-overall-p-value-from-benjamini-hochberg-test</link>
      <description><![CDATA[我写信是为了询问如何将 Benjamini Hochberg 程序应用于独立样本 t 检验。我知道如何获得 SPSS 上每个参与者的校正 p 值。但是，我需要澄清的是，如何根据 Benjamini Hochberg 程序计算总体 p 值，类似于原始独立样本 t 检验提供 p 值的方式。
感谢您对这个问题的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/660505/how-to-obtain-an-overall-p-value-from-benjamini-hochberg-test</guid>
      <pubDate>Sat, 25 Jan 2025 00:02:49 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归 CS229 斯坦福</title>
      <link>https://stats.stackexchange.com/questions/660499/logistic-regression-cs229-stanford</link>
      <description><![CDATA[我正在尝试从 Andrew Ng 在 YouTube 上的课程学习基本的机器学习。我们刚刚介绍了逻辑回归，我尝试自己使用课程中的 ds1_train.csv 数据集来实现该理论，该数据集可在此处找到。
这是数据的图，以及预期的决策边界（我在 Mathematica 中使用 LogitModelFit 找到）：https://i.imgur.com/aSavXMo.png（如果有更多代表可以在此处添加图片，我将不胜感激）。
预期的分类器是 $h_\theta(x)=\sigma(\theta^T x)$，其中$\sigma(z)=1/(1+e^{-z})$是通常的 S 形函数，并且$\theta=(6.26,-2.47,0.03)$。我尝试自己使用下降法重现参数的这个值，即我们通过迭代更新初始猜测
$$
\theta_j\leftarrow \theta_j+\alpha(y^{(i)}-h_\theta(x^{(i)}))x^{(i)}_j,\qquad j=0,1,2
$$
其中 $i$ 遍历所有数据点。这在课程讲义的第 5 节中有解释，可在此处找到 。。 （此处的公式没有解释如何处理索引 $i$，但 Ng 教授解释了两种方法，要么对所有 $i$ 求和，要么对其进行迭代，他称之为“批量下降”，应该对大型数据集运行得更快）。
上面的公式似乎没有收敛，我不确定我是否误解了算法，或者在实现它时犯了错误。
这是我在 Mathematica 中的代码（如果有帮助，我可以尝试翻译成 python，但希望代码本身足够容易理解）
data = Import[&quot;ds1_train.csv&quot;] // Rest; (* import dataset *)
X = {1, #[[1]], #[[2]]} &amp; /@ data; (* 前两列是 x，我们用 1 来增加截距 *)
Y = #[[3]] &amp; /@ data; (* 第三列是 y *)
σ[z_] := 1/(1 + E^-z); (* sigmoid *)

h[θ_, x_] := σ[θ . x]; (* 逻辑模型 *)

(* 现在我们迭代 10 次，初始猜测 θ = {0, 0, 0} *)
Nest[# + .1 Sum[(Y[[i]] - h[#, X[[i]]]) X[[i]], {i, 1, Length[X]}] &amp;, {0, 0, 0}, 10] // Quiet

迭代失败。知道我做错了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660499/logistic-regression-cs229-stanford</guid>
      <pubDate>Fri, 24 Jan 2025 21:23:03 GMT</pubDate>
    </item>
    <item>
      <title>如何用贝叶斯公式更新概率来计算证据权重？</title>
      <link>https://stats.stackexchange.com/questions/660497/how-to-update-probabilities-with-bayesian-formula-to-calculate-weight-of-evidenc</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660497/how-to-update-probabilities-with-bayesian-formula-to-calculate-weight-of-evidenc</guid>
      <pubDate>Fri, 24 Jan 2025 19:37:22 GMT</pubDate>
    </item>
    <item>
      <title>如何提取和比较两个混合效应模型的预测值分布？</title>
      <link>https://stats.stackexchange.com/questions/660480/how-to-extract-and-compare-the-distribution-of-predicted-values-of-two-mixed-eff</link>
      <description><![CDATA[我有 6 天的 100 个样本（每天 100 个观测值，总共 600 个观测值）。我尝试将混合模型拟合到数据中。还有一次，我尝试将混合模型拟合到来自相同数据的两天的观测值中（例如：第 1 天和第 2 天的观测值 - 总共 200 个观测值）。我知道数据中存在人与人之间的差异会导致错误。我尝试使用混合效应模型将其消除。现在，我的问题是如何提取响应变量的分布？如何比较两个混合模型的分布？总的来说，有没有建议消除数据中人与人之间的差异？
以下代码用于 lme4 包中的 6 天数据。
library(lmer)

long_nutt1 &lt;- nutt1 %&gt;%
pivot_longer(
cols = c(BCP1, BCP2, BCP3, BCP4, BCP5, BCP6), 
names_to = &quot;Day&quot;,
values_to = &quot;BCP&quot;
)

long_nutt1 &lt;- long_nutt1 %&gt;%
mutate(ID = rep(1:(nrow(nutt1)), each = length(grep(&quot;^BCP&quot;, names(nutt1)))))

data_6days &lt;- long_nutt1

################### 6 天

model_6days &lt;- lmer(log(BCP) ~ 1 + (1 | ID), data = long_nutt1)

summary(model_6days)

REML [&#39;lmerMod&#39;] 拟合的线性混合模型

公式：log(BCP) ~ 1 + (1 | ID)

数据：long_nutt1

收敛时的 REML 标准：1494.1

缩放残差：
最小值 1Q 中位数 3Q 最大值

-3.0346 -0.5696 0.0553 0.6336 3.1517

随机效应：
组名称方差标准差
ID（截距）0.1747 0.4180 
残差 0.4940 0.7028 
观察数：600，组：ID，107

固定效应：
估计标准误差 t 值
（截距）4.29281 0.04901 87.58
]]></description>
      <guid>https://stats.stackexchange.com/questions/660480/how-to-extract-and-compare-the-distribution-of-predicted-values-of-two-mixed-eff</guid>
      <pubDate>Fri, 24 Jan 2025 14:45:03 GMT</pubDate>
    </item>
    <item>
      <title>OLS 估计量和条件方差加权</title>
      <link>https://stats.stackexchange.com/questions/641135/ols-estimator-and-conditional-variance-weighting</link>
      <description><![CDATA[我正在阅读 Morgan 和 Winship 的反事实与因果推理。在第 6 章中，他们讨论了 OLS 作为估计二元暴露$D$的平均治​​疗效果的方法（假设所有假设都得到满足）。他们描述了一种场景，其中人群可以通过变量$S = \left\{ 1, 2, 3 \right\} $完美分层，并且$S$足以阻止任何后门路径。假设执行回归分析，其中 $S$ 为虚拟编码，使用 $S=1$ 作为参考组，OLS 的估计值将等于
$$ \delta_{OLS} = \dfrac{1}{c}\sum_s \operatorname{Var}[d_i\mid s_i=s] \operatorname{Pr}[s_i=s] \left\{ E[y_i \mid d_i=1, s_i=s] - E[y_i \mid d_i=0, s_i=s] \right\} $$
其中 $c$ 是缩放常数，等于条件方差。
这对我来说相当令人惊讶。我原本以为 OLS 的系数是对 $S$ 分布的 ATE 平均值的估计值（即权重将只是 $\operatorname{Pr}[s_i=s]$），但似乎 OLS 为倾向得分更接近 0.5 的层赋予了更多权重。用作者的话来说，“[OLS] 即使在无限样本中也能产生远离真实 ATE 的估计值”。
为什么 OLS 会这样执行条件方差加权？有人能向我解释为什么这是 OLS 典型设置的结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/641135/ols-estimator-and-conditional-variance-weighting</guid>
      <pubDate>Sun, 25 Feb 2024 17:20:56 GMT</pubDate>
    </item>
    <item>
      <title>单变量的多元格兰杰检验</title>
      <link>https://stats.stackexchange.com/questions/521386/multivariate-granger-test-on-single-variables</link>
      <description><![CDATA[假设我有一些三变量模型，其中包含变量 X、Y、Z。现在我想知道 X 是否 Granger 导致 Y。
为了进行此测试，我使用了 library(vars) 中的 causality() 函数。然而，这并不能测试 X Granger 是否导致 Y，但它可以检查 X Granger 是否导致 Y 和 Z，或者 X 和 Z Granger 是否导致 Y。因此输出方法是：
Granger 因果关系 H​​0：X Z 不 Granger 导致 Y

或
Granger 因果关系 H​​0：X 不 Granger 导致 Y Z

问题可能是这种方法以这种方式计算更简单的测试统计量。现在我还检查了 library(imtest) 中的 grangertest 函数。遗憾的是，这种方法只适用于双变量或单变量模型。
你知道用什么函数来测试 X 是否导致 Y 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/521386/multivariate-granger-test-on-single-variables</guid>
      <pubDate>Sun, 25 Apr 2021 17:11:44 GMT</pubDate>
    </item>
    <item>
      <title>非独立同分布随机变量的 CLT</title>
      <link>https://stats.stackexchange.com/questions/517987/clt-for-non-iid-random-variables</link>
      <description><![CDATA[假设$U_k$是相关的标准正态随机变量。
设$R_k := a_k U_k$。我正在寻找总和 $S_p := \sum_{k=1}^{p}\frac{R_k}{\sqrt{p}}$ 的 CLT。
由于 $U_k$ 是相关的，我正在查看 弱相关变量的 CLT，但这里也假设了相同的分布，因此不确定如何处理权重 $a_k &gt;0$ ($\sum_{k=1}^{\infty}a_k &lt; \infty$)。另一方面，对于非 iid 变量，CLT 有变体，但通常假设独立性。
哪种 CLT 适用于我的情况？是否有任何已知结果可以在组合（弱）依赖性和非同一分布下起作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/517987/clt-for-non-iid-random-variables</guid>
      <pubDate>Sat, 03 Apr 2021 00:43:40 GMT</pubDate>
    </item>
    </channel>
</rss>