<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Fri, 28 Mar 2025 21:16:05 GMT</lastBuildDate>
    <item>
      <title>最小二乘的历史</title>
      <link>https://stats.stackexchange.com/questions/663255/history-of-least-squares</link>
      <description><![CDATA[我正在阅读试图将理想化曲线（如椭圆形）适合天文数据的历史。当时（1700年代至1800年代）已经存在各种方法。一个这样的例子是一种简单的平均方法，在该方法中，您将过度确定的线性系统添加成组，直到解决。还存在其他方法，例如用于最小化最大偏差的算法（以及最小化总偏差）。
 Legendre的最小二乘方法是什么使它成为最受欢迎的方法？仅仅是因为它比其他方法容易得多？更具体地说，使用最小二乘有几乎是自动的答案，而要最大程度地减少最大偏差需要一种费力的算法（当时是手工完成的）。
最小二乘作为MLE或蓝色ECT的理由。 ，所有这些都发生了。但是在早期，在1700年代至1800年代之间，与其他现有方法相比，最小二乘的拟合只是最简单的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663255/history-of-least-squares</guid>
      <pubDate>Fri, 28 Mar 2025 18:55:18 GMT</pubDate>
    </item>
    <item>
      <title>在混合模型中与与互动的混合模型中的收敛性和奇异性问题</title>
      <link>https://stats.stackexchange.com/questions/663253/issues-with-convergence-and-singularity-in-mixed-models-with-interactions</link>
      <description><![CDATA[我正在尝试使用 lme4  r 中的包装&gt; r 中的软件包适合某些三级混合模型，以与个人对经济重新分配的态度的数据，其中个人在州年内嵌套在州年内，在州内嵌套在州内（“参考美国州”）。我还获得了对他们接受调查的每个人居住状况的平均房价以及他们是否是房主的数据。一种运行良好且不会引发错误或警告的模型如下：
  lmer（y〜logrealprice_bar +房主 + logrealprice_bar：房主 +  
    logrealprice_demeaned + logrealprice_demeaned：房主 +  
    （1 | fipsStat） +（1 | fipsstatyr），data = d）
 
其中 y 是支持个人 i 更多重新分配的二进制指标；  logrealprice_bar 是1985  -  2022年期间 i 状态中的AVG（log）房价； 房主是一个虚拟，表明 i 是房主；  logrealprice_demeaned 是对 i 在这一年中 i 状态中的平均（日志）房价进行了调查。  fipsStat 是 i 的状态；  fipsStatyr 是 i 的州年。  logrealprice_demeaned 是感兴趣的主要预测指标。此系数代表“州内”平均值。在（日志）平均房价中增加1的影响在特定州年的平均值中，其州的平均值对支持非房屋的重新分布的可能性。除此之外，在州和州年水平上也有随机的拦截。
但是，如果我修改了此模型以包含logrealprice_deaned的随机斜率，该斜率可以在各州中变化，即：
  lmer（y〜logrealprice_bar +房主 + logrealprice_bar：房主 +  
    logrealprice_demeaned + logrealprice_demeaned：房主 +  
    （logrealprice_demeaned | fipsStat） +（1 | fipsstatyr），data = d）
 
我将获得以下输出（带有有关收敛的“单数”拟合的警告）：
 收敛上的reml标准：23628.2

缩放残差： 
    最小1Q中位数3Q最大 
-1.8435 -1.3328 0.5498 0.7645 1.0094 

随机效果：
 组名称差异std.dev。 corr
 fipsstatyr（截距）0.0016712 0.04088      
 fipsStat（截距）0.0003577 0.01891      
            logrealprice_demeaned 0.0005313 0.02305 1.00
 残留0.2122573 0.46071      
OBS数量：18208年，组：FipsStatyr，870； FIPSSTAT，51

固定效果：
                                  估计标准。错误t值
（截距）0.739009 0.280197 2.637
logrealprice_bar 0.001294 0.022606 0.057
HOMEWHORNER1 0.444785 0.28996 1.534
logrealprice_demeaned 0.086037 0.033588 2.562
logrealprice_bar：Homeowner1 -0.045609 0.023372 -1.951
HOMEWHORNER1：LOGREALPRICE_DEMEANED -0.022460 0.039547 -0.568

固定效果的相关性：
            （int）lgrlprc_b homeowner1 lgrlprc_d l_：hom
logrlprc_br -1.000                                      
HOMEWHORNER1 -0.644 0.642                               
lgrlprc_dmn 0.072 -0.072 -0.101                     
L_：Homeowne 0.643 -0.642 -1.000 0.102          
HOMEWHORNER1：-0.081 0.082 0.152 -0.725 -0.155
优化器（nloptwrap）收敛代码：0（确定）
边界（单数）拟合：请参阅帮助（&#39;Issingular&#39;）
 
  lme4 如果据说有单一的拟合，为什么还会给我结果？另外，如果我修改上述模型并消除涉及房主的术语，即：
  lmer（y〜logrealprice_bar + logrealPrice_demeaned +（logrealPrice_demeaned |  
    fipsStat） +（1 | fipsStatyr），data = d）
 
我不会收到有关奇异性或融合的警告。也不使用以下模型来保持房主互动但删除状态年的随机截距：
  lmer（y〜logrealprice_bar +房主 + logrealprice_bar：房主 +  
    logrealprice_demeaned + logrealprice_demeaned：房主 +  
    （logrealprice_demeaned | fipsStat），data = d）
 
这里发生了什么？不幸的是，数据受到保护，因此我无法共享它们，但是似乎我缺少一些理论问题，即引发警告的模型的可识别性。我只是不知道这是什么。而且我也不知道该怎么做的事实是，尽管存在问题，  仍然会打印出结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/663253/issues-with-convergence-and-singularity-in-mixed-models-with-interactions</guid>
      <pubDate>Fri, 28 Mar 2025 17:26:34 GMT</pubDate>
    </item>
    <item>
      <title>LGD模型的欧洲央行回测的t检验描述</title>
      <link>https://stats.stackexchange.com/questions/663252/description-of-t-test-in-ecb-backtest-of-lgd-models</link>
      <description><![CDATA[ 以下文本有关将模型与已实现值与t检验的实现值进行比较的文本发生。我是否在指出零假设的措辞（第一个亮点）是（礼貌地）高度罕见的，并且在第二个亮点中所做的那样，p值的计算会导致1的p值，如果p值是1，那么如果模型过多的实现值？  ？
    &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stats.stackexchange.com/questions/663252/description-of-t-test-in-ecb-backtest-of-lgd-models</guid>
      <pubDate>Fri, 28 Mar 2025 17:23:43 GMT</pubDate>
    </item>
    <item>
      <title>我是对高斯流程的不确定性量化吗？还是我的预测这么糟糕？ （gpytorch）</title>
      <link>https://stats.stackexchange.com/questions/663249/am-i-doing-uncertainty-quantification-for-gaussian-processes-incorrectly-or-are</link>
      <description><![CDATA[快速概述我的数据；我有将近300个样本，大约有40个功能（33个数值，7个编码为0和1，因为它们是绝对的），因此绝对是一个高维数据集。我使用大多数基本的精确高斯流程来在gpytorch中对这些数据进行建模并查看预测的值，我不相信它们都是可怕的，但是当我尝试获得错误界限时，看来置信区间绝对是巨大的。。
事实是，我以前从未做过，我完全不确定UQ如何与GP回归一起工作。我知道这个模型很可能存在认知和态度不确定性。在寻找示例的同时，许多模型似乎对训练值建立了不确定性，而其他模型则在测试集中。我个人的假设是我想检查测试集，并且为了可视化置信区间，我使用标准偏差和情节错误栏。 （当然，我无法真正做人们倾向于用于1-D回归输​​入和输出的漂亮图）。注意：我的代码在Sklearn中使用常规火车测试。
我正在添加我使用的代码段，并且会喜欢任何人都可以拥有的任何见解; 
  model.eval（）
可能性.eval（）

使用Torch.no_grad（）：
    pred_y =似然（模型（test_x））
test_y = test_y.detach（）。numpy（）
pred_mean = pred_y.mean.numpy（）
pred_std = pred_y.stddev.numpy（）

test_real = yscaler.inverse_transform_mean（test_y.reshape（-1，1））。squeeze（）
pred_mean_real = yscaler.inverse_transform_mean（pred_mean.reshape（-1，1））。squeeze（）
std_real = yscaler.inverse_transform_std（pred_std）

轴[1] .scatter（test_real，pred_mean_real，s = 8，c =&#39;b&#39;，alpha = 0.6）
轴[1] .set_xlabel（“测试值”）
轴[1] .set_ylabel（“预测”
axes [1] .plot（[test_real.min（），test_real.max（）]，[test_real.min（），test_real.max（）]，&#39;r--&#39;）
轴[1] .set_title（“预测与腐蚀率的测试值”
plt.tight_layout（）
plt.show（）

upper = 1.96 * std_real
较低= 1.96 * std_real
信任_Region = [下部，上]

plt.errorbar（test_real，pred_mean_real，yerr = upper，fmt =&#39;o&#39;，markersize = 5，color =&#39;b&#39;， 
             ecolor =&#39;灰色&#39;，alpha = 0.5，倾斜= 3）
plt.xlabel（“测试值”）
plt.ylabel（“预测”
plt.plot（[[test_real.min（），test_real.max（）]，[test_real.min（），test_real.max（）]，&#39;r--&#39;，babel =; plabel =; quote;
 
我从中得到的是：
  但显然这不是很漂亮，误差界限（标准偏差 - 使用 gpytorch文档文档，这是完全了解的。 But essentially it states, &quot;If we denote a test point (test_x) as x* with the true output being y*, then model(test_x) returns the model posterior distribution p(f* | x*, X, y), for training data X, y.该后部是我们试图建模的功能的分布，从而量化了模型不确定性。”然后文档继续并列出
  f_preds =模型（test_x）
y_preds =可能性（型号（test_x））

f_mean = f_preds.mean
f_var = f_preds.variance
f_covar = f_preds.covariance_matrix
f_samples = f_preds.sample（sample_shape = torch.size（1000，））
 
但似乎不使用这些？我有一个暗示，这里的卑鄙和差异对我想要的东西很有用，但是老实说，我至少需要一些帮助理解发生了什么，我真的很感激是否有人可以解释我担心的任何事情。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/663249/am-i-doing-uncertainty-quantification-for-gaussian-processes-incorrectly-or-are</guid>
      <pubDate>Fri, 28 Mar 2025 17:06:04 GMT</pubDate>
    </item>
    <item>
      <title>套索模型的转换配件</title>
      <link>https://stats.stackexchange.com/questions/663248/transformed-fitting-of-a-lasso-model</link>
      <description><![CDATA[考虑标准拉索回归问题：
  $$
\ hat {\ beta} = \ arg \ min _ {\ beta} \ frac {1} {2} {2} \ | y -x \ beta \ |^2 + \ lambda \ sum_ {j = 1}^{p} | \ beta_j |。
$$  
现在，假设我们使用转换的设计矩阵 $ XW $ ，其中 $ W $ 是对角度重量矩阵，其中 $ xw $ 。也就是说，我们解决：
  $$
\ hat {\ beta}^w = \ arg \ min _ {\ beta} \ frac {1} {2} {2} \ | y -xw \ beta \ |^2 + \ lambda \ sum_ {j = 1}^{p} | \ beta_j |。
$$  
  $ w $ 如何影响估计的套索系数 $ \ hat {\ beta}^w $ ？我们可以根据解决未加权问题的解决方案来重写吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663248/transformed-fitting-of-a-lasso-model</guid>
      <pubDate>Fri, 28 Mar 2025 16:51:55 GMT</pubDate>
    </item>
    <item>
      <title>终身估计是自上次次要事件以来的时间（几乎是泊松过程）</title>
      <link>https://stats.stackexchange.com/questions/663245/lifetime-estimates-conditional-on-time-since-last-secondary-event-almost-poisso</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/663245/lifetime-estimates-conditional-on-time-since-last-secondary-event-almost-poisso</guid>
      <pubDate>Fri, 28 Mar 2025 15:21:08 GMT</pubDate>
    </item>
    <item>
      <title>估计分布中K新样本总和的不确定性</title>
      <link>https://stats.stackexchange.com/questions/663244/uncertainty-in-sum-of-k-new-samples-from-an-estimated-distribution</link>
      <description><![CDATA[ i有 $ n $ 来自未知正常分布的独立样本 $ \ Mathcal {n} $ 。如果我从 $ \ Mathcal {n} $ 中绘制一个新样本，我从文献中知道，此新样本的置信区间由给出
  $ M \ pm t_ {1- \ alpha，n-1} s \ sqrt {1+ \ frac {1} {n} {n}}} $    
其中 $ m $ 和 $ s $ 是n个以前的n个以前的样本的示例平均值和标准偏差， $ t $ 为某些信心级别 $ \ alpha $ ）。
现在，我想绘制 $ k $ 来自 $ \ Mathcal {n} $ 的新样本，我有兴趣了解新样本总和的置信区间。我的第一个天真的想法是，这将是
  $ km \ pm ts \ sqrt {k（1 + \ frac {1} {n} {n}）} \ quad \ quad \ quad \ quad（1）$   
由于 $ k $ 从与 $ \ sqrt {k} $ 乘以该分布的单个值的标准偏差的相同分布量表值。
但是，在这种情况下，我认为存在错误/不确定性组件来自对 $ \ Mathcal {n} $ 并非每次绘制一个新值时都真正独立采样。因此，这使我认为总和应该是的置信区间
  $ km \ pm ts \ sqrt {k（1 + \ frac {k} {n} {n}）} \ quad \ quad \ quad \ quad（2）$   
这是正确的，还是公式会不同？
我注意到第一个假设（1）中（假定的）错误的原因是，如果您有 $ k $  $ k $ 值，从 $ \ mathcal&gt; $ \ mathcal {n} class =“ Math-Container”&gt; $ k＆gt;＆gt; n $ ，人口平均值的置信区间为
  $ M \ pm TS \ frac {1} {\ sqrt {n}} $  
因此，该人群总和的置信区间为
  $ km \ pm ts \ frac {k} {\ sqrt {n}} $  
直觉上，您已经拥有样本的人口总和的不确定性最多不应该大于相同数量的新样品的不确定性，但是与第一个天真估计（1）相比，如果 $ k $ a&gt; $ k $ 与 $ k $ class =“ Math-Container”&gt; $ K $ 。]]></description>
      <guid>https://stats.stackexchange.com/questions/663244/uncertainty-in-sum-of-k-new-samples-from-an-estimated-distribution</guid>
      <pubDate>Fri, 28 Mar 2025 14:33:09 GMT</pubDate>
    </item>
    <item>
      <title>如何确定超出协变量效果的“太大”如何影响线性回归中的因变量？</title>
      <link>https://stats.stackexchange.com/questions/663243/how-to-determine-how-much-beyond-the-effect-of-the-covariate-the-independent</link>
      <description><![CDATA[我正在做一些涉及一些协变量的简单线性回归。假设我正在查看X和Y之间的关联，该关联是针对Z进行了调整的。当我将Z添加到模型中时，X和Y之间没有显着的关系。没有z，x和y之间的关系较少。我如何量化X超过Z以外的Y影响？我会比较r^2吗？ beta？还是其他？]]></description>
      <guid>https://stats.stackexchange.com/questions/663243/how-to-determine-how-much-beyond-the-effect-of-the-covariate-the-independent</guid>
      <pubDate>Fri, 28 Mar 2025 14:00:16 GMT</pubDate>
    </item>
    <item>
      <title>香草方差分析的用法和哲学</title>
      <link>https://stats.stackexchange.com/questions/663242/usage-and-philosophy-of-vanilla-anova</link>
      <description><![CDATA[我没有统计背景，所以请耐心等待。我试图理解简单的一种方差分析布局。特别是我
有一个疑问对用F检验检验的零假设的疑问，这似乎是ANOVA   $$ H_0：\ MU_1 = \ MU_2 =…= \ MU_K $$ $  
这个假设对我来说似乎很奇怪，因为它没有说什么是最好的治疗方法。为什么不直接估计效应大小，例如直接 $ \ mu_i $ 或 $ \ mu_i- \ mu_j $ ？我给自己的答案是这个。当我们没有足够的数据将每种处理与彼此进行比较时（因为单独的每种治疗都有很少的样本，这可能会导致错误低估和误报），但是ANOVA很有用，但是我们有足够的数据回答 $ h_0 $ h_0 $ 。如果 $ h_0 $ 被拒绝，那么我们可以：

 收集更多样本以回答有关个人治疗的更多特定问题或 

 更多地相信ANOVA后完成的效应大小分析的结果（从这个意义上讲，我们构建了一个组合模型）。


从这个意义上讲，方差分析是避免误报或指导实验选择的初步测试。
这真的是ANOVA NULL假设背后的哲学吗？还是我误会了和缺少其他无用的方式或需要的其他方式？
我很抱歉，如果已经解决了这个基本问题。如果我将删除此。]]></description>
      <guid>https://stats.stackexchange.com/questions/663242/usage-and-philosophy-of-vanilla-anova</guid>
      <pubDate>Fri, 28 Mar 2025 13:52:35 GMT</pubDate>
    </item>
    <item>
      <title>最小化CRP的期望</title>
      <link>https://stats.stackexchange.com/questions/663240/minimising-expectation-of-crps</link>
      <description><![CDATA[让 $ x，y \ sim \ mathcal {n}（0,1）$ 为i.i.d随机变量并定义严格正确的评分规则：
 $$ \ text {crps}（f_y，y）= \ int _ { -  \ infty}^{\ infty}（f_y（t） -  \ Mathbb {1} _ {1} _ {t \ geq y}）
目标是找到 $ f $ ，将 $ \ mathbb {e} [\ text {crps}（f_x，f（y））$  an class =“ Math-Container”&gt; $ \ Mathbb {e} [\ text {crps}（f_x，f（y^2））] $  
对于第一种情况，我尝试了直接计算，让 $ \ phi $ 表示标准正态分布的CDF， $ \ phi $ 是其密度。
 \ begin {align}
\ mathbb { \ phi（y）dy \\
＆amp; = \ int _ { -  \ infty}^\ infty \ weft [\ int _ { -  \ infty}^{f（y）} \ phi（t）^2dt+\ int_ {f（f（y）
\ end {align} 
这似乎很难从分析中最小化。
另一方面，使用CRP是一个严格的正确评分规则，意味着“预期得分仅被真实的预测最小化。这让我认为应该在第一种情况下选择 $ f = id $ ，而 $ f = \ sqrt {\ cdot} $ 在第二种情况下。这是正确的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663240/minimising-expectation-of-crps</guid>
      <pubDate>Fri, 28 Mar 2025 13:30:10 GMT</pubDate>
    </item>
    <item>
      <title>伯努利试用的概率概率错误</title>
      <link>https://stats.stackexchange.com/questions/663236/errors-on-summed-probabilities-of-a-bernoulli-trial</link>
      <description><![CDATA[假设我们有4个结果的Bernoulli试验。
我们可以使用
 $$ p_ {i} = \ frac {n_ {i}} {n} {n} \ pm \ pm \ frac {1.96} {\ sqrt {n}}}}}}} \ sqrt {
其中1.96的因子反映了95％的置信区间。
假设我们有兴趣测量以下数量：
  $$ a = p_ {1}+p_ {2} -p_ {3} -p_ {4} $$ 
 $ a $ 如何累积？如何
我们只是使用标准错误传播来总和：〜
 $$ \ delta a = \ sqrt {（\ delta p_ {1}）^2 +（\ delta p_ {2}）
$$ 
还是方案是不同的，因为这些值固有地连接
 $$ P_ {1}+P_ {2}+P_ {3}+P_ {4} = 1 $$  ]]></description>
      <guid>https://stats.stackexchange.com/questions/663236/errors-on-summed-probabilities-of-a-bernoulli-trial</guid>
      <pubDate>Fri, 28 Mar 2025 10:58:03 GMT</pubDate>
    </item>
    <item>
      <title>训练轨迹：CNN培训中AUC和PR-AUC的不稳定行为</title>
      <link>https://stats.stackexchange.com/questions/663233/training-trajectory-erratic-behaviour-of-auc-and-pr-auc-in-cnn-training</link>
      <description><![CDATA[我已经训练了一个CNN，该CNN旨在预测患者是否死亡。该模型输入大小244x244的图像并输出二进制结果（高度不平衡7％）。我拥有的数据集很小。我总共有965张图像。其中，在火车加载器（772张图像）中使用了80％，测试装载机（193张图像）中使用了20％。我知道我可以使用数据扩展，但是在这一刻，我想保留培训数据。损失是Bceloss。
我是ML和CNN的新手，但我认为该模型正在从火车和测试损失曲线中进行适当训练。令我惊讶的是，与火车和测试损失相比，AUC和PRAUC的不稳定行为。我希望在所有情况下都更加顺畅曲线，但是我会得到上下行为（尽管总体趋势是向上的）。在这些模型中，这种行为通常吗？
此外，即使火车损失减少，从时代20开始，测试损失几乎保持恒定。但是，火车AUC和PR-AUC急剧增加，并且测试AUC仍在增加。损失的改善很小，以这种方式改善AUC是正常的吗？
谢谢
  &lt;img alt =“火车和测试损失，AUC和PR-AUC，auc and pr-auc per acoch” src =“ src”]]></description>
      <guid>https://stats.stackexchange.com/questions/663233/training-trajectory-erratic-behaviour-of-auc-and-pr-auc-in-cnn-training</guid>
      <pubDate>Fri, 28 Mar 2025 07:15:33 GMT</pubDate>
    </item>
    <item>
      <title>证明回归参数的差异与确定系数负相关</title>
      <link>https://stats.stackexchange.com/questions/663197/proof-that-variance-of-a-regression-parameter-is-negatively-related-to-the-coeff</link>
      <description><![CDATA[根据古吉拉特语（P.328，等式7.4.12），在具有常数和两个回归器的多线性回归模型中， $ \ hat \ hat \ beta_2 $ 是
 $$
\ frac {\ sigma^2} {\ sum_ix_ {2i}^2（1-r^2_ {23}）}，
$$ 
在哪里
 $$
r^2_ {23} = \ frac {（\ sum_ix_ {2i} x_ {3i}）^2} {\ sum_ix_ {2i}^2 \ sum_ix_ {3i}^2}
$$  
和下案字母表示与变量的平均值的偏差， $ x_ {ji} = x__ {ji}  -  \ bar {x_j} $ 。。
我设法计算直到
  $$ var-cov（\ hat {\ beta}）= \ sigma^{2} {2}（x^{\ prime} x）^{ -  1} = \\
\ frac {\ sigma^{2}}} {\ left | x^{\ prime} x \ right |} \ left [\ begin {array {array} {cccc} 1＆amp; r_ {12} \ sqrt {c_ {11} \ times c_ {22}}＆amp; \ dots＆amp; r1n \ sqrt {c_ {11} \ times c_ {nm}} \\
r_ {21} \ sqrt {c_ {22} \ times c_ {11}}}＆amp; 1＆amp; \ dots＆amp; r2n \ sqrt {c_ {22} \ times c_ {nm}} \\
\ vdots＆amp; \ vdots＆amp; \ ddots＆amp; \ vdots \\
r_ {k1} \ sqrt {c_ {kk} \ times c_ {11}}}＆amp; r_ {k2} \ sqrt {cc_ {kk} \ times c_ {22}}}＆amp; \ dots＆amp; 1 \ end {array} \ right] $$  
，但从那里开始很有雾。有人可以告诉我如何从2中得出1个？]]></description>
      <guid>https://stats.stackexchange.com/questions/663197/proof-that-variance-of-a-regression-parameter-is-negatively-related-to-the-coeff</guid>
      <pubDate>Thu, 27 Mar 2025 13:36:15 GMT</pubDate>
    </item>
    <item>
      <title>测试二项式分布</title>
      <link>https://stats.stackexchange.com/questions/663190/testing-for-binomial-distribution</link>
      <description><![CDATA[我有两个不同的过程，我想测试它们是否通过二项式分布进行了很好的近似。我的数据由形式的许多三元组成（n =试验数，p =成功概率，a =实际成功的数量）。我每个过程都有数十万个这样的三元组，问题是每个过程是否会创建具有给定参数的随机样本，或者是否对成功数量也有其他影响。
对于每个三重I计算：
在
在
，然后是我的关键统计信息：
  $ x =（a-e）/\ sigma = $ 实际成功与预期成功的归一化偏差
如果我的过程是正确的随机二项式分布，我希望x是高斯正态分布，平均0和方差为1。这通常可以与我的数据一起使用，其中一个过程非常接近高斯分布，而另一个过程则具有许多极端值，大约有1％的时间与0相距10个以上的标准偏差，这证实了我的可信度，以确认哪个过程是由二项式分布很好地模拟的，一个不是。 。
但是有一个问题，我的高斯解释给出了奇怪的结果。也就是说，我有几个三元组，具有诸如（ $ n = 1，p = 0.01，a = 1 $ ）之类的值。对于二项式分布，这是一个不太可能的结果，但在天文学上不是。在数十万个三元组中，其中少数几个不寻常。 However my computation gives $E=0.01$, $\sigma \approx 0.1$ and so $X \approx 10$ and a result 10 standard deviations away from the mean is astronomically unlikely.
那么，这里发生了什么，为什么我的方法给出这些奇怪的结果，什么是对此进行调整的干净方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/663190/testing-for-binomial-distribution</guid>
      <pubDate>Thu, 27 Mar 2025 11:51:37 GMT</pubDate>
    </item>
    <item>
      <title>相关比例之间差异的置信区间</title>
      <link>https://stats.stackexchange.com/questions/663184/confidence-interval-for-difference-between-dependent-proportions</link>
      <description><![CDATA[这是我需要一些帮助的情况：
一群学生参加/失败测试，​​所以JAG在这里获得百分比通过
同一位学生稍后再次参加考试（干预之后），所以我在这里有一个新的百分比
我想比较这两个百分比，以表明已经有所改善（第二次测试的百分比实际上是更高的）
我很想能够使用jasp做到这一点，如果有人知道如何，但是我也可以手工做。
最好的置信区间是最好的。但是测试也有效。
如果样本被视为独立（无论如何），我知道该怎么做。但是我不清楚在这里被认为是什么独立的，因为我看到了一个示例，我知道的方法是比较篮子/镜头的百分比/镜头，就像在两个不同的几周内做出的同一个人表明她已经改善了，这对我来说似乎是依赖的样本，而且非常相似，这是我处境的某些方法。   
任何帮助将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/663184/confidence-interval-for-difference-between-dependent-proportions</guid>
      <pubDate>Thu, 27 Mar 2025 09:48:04 GMT</pubDate>
    </item>
    </channel>
</rss>