<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 05 Aug 2024 06:23:09 GMT</lastBuildDate>
    <item>
      <title>当相关系数为正时，copula 所求的条件期望是否严格增加，反之亦然？</title>
      <link>https://stats.stackexchange.com/questions/652311/is-conditional-expectation-evaluated-by-the-copula-strictly-increasing-when-the</link>
      <description><![CDATA[我使用 copula 来评估 $\mathbb{E}[Y|X]$，从我对一些 copula 的实验中，我观察到当随机变量具有正相关系数时，$\mathbb{E}[Y|X]$ 严格增加，而当它们负相关时，$\mathbb{E}[Y|X]$ 严格减少。此外，这篇文章中的条件期望图也显示了严格的行为。我想知道这是否正确以及如何证明这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/652311/is-conditional-expectation-evaluated-by-the-copula-strictly-increasing-when-the</guid>
      <pubDate>Mon, 05 Aug 2024 06:12:13 GMT</pubDate>
    </item>
    <item>
      <title>尝试定义一个迭代函数来使用不同的 n 值重复调用 KNeighboursClassifier</title>
      <link>https://stats.stackexchange.com/questions/652310/trying-to-define-an-iterative-function-to-repertitively-call-kneighboursclassifi</link>
      <description><![CDATA[当我运行代码并使用 KNN 而不调用函数时，如果 n 的值是固定的，则不会出现任何错误，准确度得分为 1.0。但是，我想绘制具有不同 n_neighbours 值的准确度得分图。为此，我创建了一个函数，该函数每次迭代都会使用不同的 n_neighbours 值调用分类器。



请帮忙。]]></description>
      <guid>https://stats.stackexchange.com/questions/652310/trying-to-define-an-iterative-function-to-repertitively-call-kneighboursclassifi</guid>
      <pubDate>Mon, 05 Aug 2024 06:00:06 GMT</pubDate>
    </item>
    <item>
      <title>如何测试序列中的事件是否均匀（有规律）或随机分布？</title>
      <link>https://stats.stackexchange.com/questions/652309/how-can-one-test-whether-events-in-a-sequence-are-evenly-regularly-or-randomly</link>
      <description><![CDATA[假设有一个长线性分子（例如 DNA 或 RNA），其中位置具有从 1 到 n（最大长度）的增量整数值，我感兴趣的是了解哪些统计测试最适合用于确定某些事件（例如特定碱基的存在或某些其他属性/标准）是否在分子位置之间相对均匀（有规律）间隔发生，或以簇形式发生（可能在局部稍微随机地定位），或仅仅纯粹在分子上的随机间隔发生。如果是这样，那么在确定某些特定的统计分布是否能最好地解释观察到的间隔长度（观察到属性/事件的位置之间的碱基对数）时，某些测试是否比其他测试更有力（更有效）？
从一些阅读中可以看出，非参数检验（例如累积分布函数的 Kolomogorov-Smirnov 检验或 Wald-Wolfowitz 运行检验）可能适合将观察到的分布与某些预期分布进行比较，但我不太清楚是否有更合适（更强大）的参数检验来确定此类事件沿分子的分布是随机的、均匀的，还是以簇的形式分布，簇本身可能也是随机分布的。
我也不清楚，鉴于分子在功能上分为长度为 3 的密码子，其中已知第 3 个或摆动碱基可能与其他两个不同，此类测试在多大程度上可以假设事件发生在任何特定位置的概率与相邻或近相邻位置的概率无关位置，并且代码中存在冗余，因此可能需要对偏差进行一些校正（某些事件在给定位置上发生的可能性可能高于其他位置）。
对于最直接感兴趣的分子，最大长度在 500-5000 之间变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/652309/how-can-one-test-whether-events-in-a-sequence-are-evenly-regularly-or-randomly</guid>
      <pubDate>Mon, 05 Aug 2024 04:44:52 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据超过 50% 的填补理由</title>
      <link>https://stats.stackexchange.com/questions/652307/justification-for-imputation-with-over-50-missing-data</link>
      <description><![CDATA[我希望就以下情况获得一些建议/想法：假设我有一项前瞻性观察性研究，旨在评估按照护理标准使用药物 A 和药物 B 的人群在 2 年随访期间的 BMI 变化（主要结果）。重点不是比较 A 组和 B 组之间的 BMI，而是评估每个组内的 BMI 变化。
身高和体重测量应该每 6 个月进行一次（基线、6 个月、12 个月、18 个月和 24 个月），总共 24 个月。然而，由于退出率高，只有 40% 的参与者最终完成了整整 24 个月的随访，因此未达到主要结果的样本量目标。
考虑到研究的纵向性质，我正在考虑使用混合效应模型来解释参与者内的相关性，其中
固定效应针对时间（自基线以来的月份）、药物组及其相互作用。
随机效应：每个参与者的随机截距和斜率以解释个体差异。
但是，研究人员正在推动也进行缺失数据填补，但我不确定这是否可行，或者如何向监管机构证明这一点，因为我们必须填补超过 50% 的数据。
您将如何处理这种情况？这里是否需要进行插补？如果是，哪种插补方法最适合（也许是模式混合模型，因为缺失数据模式是 MNAR？）有没有什么文章可以推荐我阅读，了解其他人如何处理类似问题以及他们如何解决这个问题？
如能提供任何建议/参考，我将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652307/justification-for-imputation-with-over-50-missing-data</guid>
      <pubDate>Mon, 05 Aug 2024 02:49:05 GMT</pubDate>
    </item>
    <item>
      <title>选择轨迹模型中的组数</title>
      <link>https://stats.stackexchange.com/questions/652305/choosing-number-of-groups-in-trajectory-model</link>
      <description><![CDATA[我正在研究基于组的多轨迹模型，该模型有两个二元结果，每个结果在四个时间点进行测量。结果似乎在多大组数（四个或六个 - 五个组更差）最适合方面存在一些冲突，我不确定如何判断。
具体来说，六组解决方案具有更好的 BIC（约 100 分，因此证据确凿），并且正确分类的几率通常更高（OCC - 六组的 8.5-15 vs 四组的 5.7-12），但分配的平均后验概率 (APPA) 低于 Nagin 推荐的阈值 &gt;0.7（六组为 .54 - .81，四组为 .69-.84）。
我该如何选择/证明这个决定？]]></description>
      <guid>https://stats.stackexchange.com/questions/652305/choosing-number-of-groups-in-trajectory-model</guid>
      <pubDate>Mon, 05 Aug 2024 01:41:26 GMT</pubDate>
    </item>
    <item>
      <title>配对测量后提取重要样本</title>
      <link>https://stats.stackexchange.com/questions/652290/extraction-of-significant-samples-after-paired-measures</link>
      <description><![CDATA[我有两组时间配对值：A 和 B。我知道 B 显著高于
A（使用 Wilcoxon 检验）（我的样本量很小），但我想知道哪些样本的 B 有显著差异。
使用 B-A 的差异，我得到了时间变化的分布，并据此计算了置信区间（通过自举法）。
我不确定应该使用什么阈值来确定哪些样本在 A 和 B 之间确实有显著变化。
提前感谢 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/652290/extraction-of-significant-samples-after-paired-measures</guid>
      <pubDate>Sun, 04 Aug 2024 16:12:40 GMT</pubDate>
    </item>
    <item>
      <title>嵌套 GLM 的 F 检验</title>
      <link>https://stats.stackexchange.com/questions/652281/f-test-for-nested-glm</link>
      <description><![CDATA[假设我们有两个嵌套的 GLM 模型 $M_0 \subset M_1$，分别具有 $q$ 和 $p$ 个参数。我们还知道两个模型中的弥散参数估计为相同的值，表示为 $\widehat{\phi} \neq 1$。我的目标是测试 $p-q$ 个附加参数在更大模型中的重要性。在这种情况下，适当的检验将是 F 检验（例如，参见第 4.7.6.2 节此处），其中
$$
F = \frac{D_0-D_1}{\widehat{\phi} (p-q)},
$$
其中 $D_0, D_1$ 是 $M_0$ 和 $M_1$ 的偏差。在同一本书中，偏差定义为
$$
D = 2 \phi(L_\textrm{full} - L),
$$
其中 $L_\textrm{full}$ 和 $L$ 是完整（饱和）模型和考虑模型的对数似然。简单来说，我们可以通过用 $\widehat{\phi}$ 代替 $\phi$ 来估计偏差，因此在我们的例子中
$$
F = \frac{2 \widehat{\phi} (L_\textrm{full} - L_0) - 2 \widehat{\phi}(L_\textrm{full} - L_1)}{\widehat{\phi} (p-q)} = \frac{2(L_1-L_0)}{p-q}。
$$
另一方面，我偶然发现了一个练习，其中给出了 $L_0, L_1$ 和 $\widehat{\phi}$，并且 F 比率计算为
$$
F = \frac{2(L_1-L_0)}{\widehat{\phi}(p-q)},
$$
这让我认为这里使用了缩放偏差（$D^* = D/\phi$）而不是常规偏差。
计算此统计数据的哪种方法是正确的？
我查找了很多不同的来源（例如 此处 或 此处)，但我觉得每一篇都说得不一样，我无法调和所有版本。任何帮助我都会很感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/652281/f-test-for-nested-glm</guid>
      <pubDate>Sun, 04 Aug 2024 13:05:05 GMT</pubDate>
    </item>
    <item>
      <title>在梯度下降中目标是否应该标准化？</title>
      <link>https://stats.stackexchange.com/questions/652232/should-the-target-be-standardized-in-gradient-descent</link>
      <description><![CDATA[假设我们有一个一般的损失函数，它依赖于一些参数$w$（例如神经网络权重）：
$$L_w =\frac{1}{N} \sum_i \ell(\hat{y}_i, y_i)$$
除了特征之外，标准化目标是否有好处？
也就是说，我们是否应该更倾向于优化$L_w&#39;$：
$$L_w&#39; =\frac{1}{N} \sum_i \ell\left(\hat{y}_i, \frac{y_i-\bar{y}}{\sigma} \right)$$
over $L_w$?
相关问题
在此问题的公认答案中，指出：

对输出进行归一化不会影响$f$的形状，因此通常没有必要。

其中$\hat{y} = f_w (x)$。然而，在训练期间我们优化了损失函数，因此$f$的形状无关紧要。]]></description>
      <guid>https://stats.stackexchange.com/questions/652232/should-the-target-be-standardized-in-gradient-descent</guid>
      <pubDate>Fri, 02 Aug 2024 23:09:42 GMT</pubDate>
    </item>
    <item>
      <title>假设 $Z_i$ 是独立同分布的。$N(0, 1).$ 且令 $M_n = \max\{Z_1, \ldots, Z_n\}$，表明 $P(M_n > t) \leq n(1 - \Phi(t))$</title>
      <link>https://stats.stackexchange.com/questions/652187/suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n-sh</link>
      <description><![CDATA[证明 $P(M_n &gt; t) \leq n(1 - \Phi(t))$
我的工作：
\begin{align}
&amp; P(M_n &gt; t) \leq P\left(\bigcup_{i=1}^n (Z_i &gt; t) \right) \\ \leq {} &amp; \sum_{i=1}^n P(Z_i &gt; t)= n(1 - \Phi(t))
\end{align&gt;
以上是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/652187/suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n-sh</guid>
      <pubDate>Thu, 01 Aug 2024 22:30:21 GMT</pubDate>
    </item>
    <item>
      <title>生长曲线分析建议</title>
      <link>https://stats.stackexchange.com/questions/652146/growth-curve-analysis-advice</link>
      <description><![CDATA[我对生长曲线模型还不熟悉，需要一些指导。我有大约 50,000 只羊羔的数据，每只羊羔都有出生体重，并在出生后大约 30、60、90 和 120 天进行了两次额外测量。我想应用 Logistic、Gompertz 和 von Bertalanffy 等生长曲线模型。
我有一些顾虑：
我能否同时使用天数和所有动物记录进行生长曲线分析，还是需要为每只动物计算 A 和 K 等参数？
如果需要单独计算，每只动物进行三次测量是否足够？]]></description>
      <guid>https://stats.stackexchange.com/questions/652146/growth-curve-analysis-advice</guid>
      <pubDate>Thu, 01 Aug 2024 12:16:42 GMT</pubDate>
    </item>
    <item>
      <title>当预测变量出现错误时会发生什么？</title>
      <link>https://stats.stackexchange.com/questions/652131/what-happens-when-there-are-errors-in-the-predictor-variables</link>
      <description><![CDATA[我昨天问了这个问题，但现在无法登录我的账户了：在未来模型中使用响应变量作为预测变量？
在思考了这个问题（估计雇用新员工对工厂生产率的净成本效益影响）之后，我想到了一种看待这个问题的新方法（即当预测变量有错误时该怎么办？）。我认为也许可以使用工具变量？
方法 1：直接使用工具变量分析净收益

对员工和已处理订单之间的关系进行建模：
$$\hat{P}_t = \hat{\alpha} \hat{E}_t + \hat{\epsilon}_t$$
其中 $\hat{E}_t$ 是 $E_t$ 的仪表化版本。我们使用第一阶段回归：
$$E_t = \gamma_0 + \gamma_1 Z_t + \nu_t$$
$$\hat{E}_t = \hat{\gamma}_0 + \hat{\gamma}_1 Z_t$$
此处，$Z_t$ 为工具变量（例如，招聘的滞后预算分配）。

模型的其余部分保持不变，但在所有部分中使用 $\hat{E}_t$ 代替 $E_t$方程。


我认为工具变量$Z_t$（或$Z_{t-1}$）应该与员工人数相关，但不应直接与主方程中的误差项相关。这可能有助于解决潜在的内生性问题？
这就是工具变量的使用方式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652131/what-happens-when-there-are-errors-in-the-predictor-variables</guid>
      <pubDate>Thu, 01 Aug 2024 05:19:04 GMT</pubDate>
    </item>
    <item>
      <title>独立样本均值乘积的 UMVUE</title>
      <link>https://stats.stackexchange.com/questions/652122/umvue-for-the-product-of-means-from-independent-samples</link>
      <description><![CDATA[设 $ x_1, \ldots, x_m $ 为从分布 $P$ 中抽取的 i.i.d. 样本，$ y_1, \ldots, y_n $ 为从分布 $Q$ 中抽取的 i.i.d. 样本。假设样本 $x_i$ 和 $y_j$ 彼此独立。假设 $\bar{X}$ 是 $\mu_X = E_{X \sim P}[X]$ 的均匀最小方差无偏估计量 (UMVUE)，而 $\bar{Y}$ 是 $\mu_Y = E_{Y \sim Q}[Y]$ 的 UMVUE。
参数 $\mu_X \mu_Y$ 的 UMVUE 是多少？ $\bar{X} \bar{Y}$ 是 $\mu_X \mu_Y$ 的 UMVUE 吗，或者有更好的估计量？]]></description>
      <guid>https://stats.stackexchange.com/questions/652122/umvue-for-the-product-of-means-from-independent-samples</guid>
      <pubDate>Thu, 01 Aug 2024 00:38:34 GMT</pubDate>
    </item>
    <item>
      <title>调查（病例对照）数据的生存分析</title>
      <link>https://stats.stackexchange.com/questions/652112/survival-analysis-for-survey-case-control-data</link>
      <description><![CDATA[我有一个数据集，其中包含大约 500 名患有大约 10 种不同疾病的患者，可能具有相关结果，以及 200 名健康对照者。患者数据来自医院，而对照数据来自志愿者，并且不匹配。我们有各种生活事件的全面记录，包括患者和对照者的具体日期（例如，首次非法使用毒品的年龄）和诊断日期。但是，没有可用的抽样权重。
作为第一步，我计划将 Cox 比例风险 (PH) 模型分别应用于每种疾病，使用出生作为时间参考（时间 = 0）。事件是二元的（无论是否诊断出疾病）。数据集包括大约 10 个潜在预测因子，例如性别、种族和教育程度，一些协变量可能与时间有关（例如，婚姻史和就业情况）。
(A) 鉴于病例抽样过多，我可以根据外部来源的患病率或发病率对样本进行加权吗？ （以前做过此类研究的论文链接将非常有帮助。）
(B) 即使这项研究不符合传统定义，它是否可以被视为病例队列研究？
(C) 虽然逻辑回归通常用于病例对照研究（仅产生比值比），但在生存分析中是否有类似的方法来处理此类数据？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652112/survival-analysis-for-survey-case-control-data</guid>
      <pubDate>Wed, 31 Jul 2024 19:36:40 GMT</pubDate>
    </item>
    <item>
      <title>如何量化百分比排序数据集的重要性？</title>
      <link>https://stats.stackexchange.com/questions/652094/how-do-i-quantify-the-significance-of-a-percentage-ranked-data-set</link>
      <description><![CDATA[我正在考虑针对给定数据集的七种不同的预测模型，这些模型经过多次预测迭代，并量化每个预测模型总体上最准确的次数。
我需要某种方法来量化结果的重要性。例如，如果给定的预测模型在 7 个预测中排名第一的概率为 23%（7 个预测中平均分布为 14.2%），那么这有多重要？
我希望能够为这些结果的重要性建立某种基线。我怀疑这可能涉及某种正态分布，但我不知道如何计算。由于我总是使用百分比，并且总是考虑 7 个预测，因此一个参考表将是理想的选择 — 如果我能够指出 23% 是高度重要的，但 18% 是有点重要的或类似的情况。
就其本身而言，这些百分比缺乏足够的背景信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/652094/how-do-i-quantify-the-significance-of-a-percentage-ranked-data-set</guid>
      <pubDate>Wed, 31 Jul 2024 15:26:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么梯度消失/爆炸是不好的？</title>
      <link>https://stats.stackexchange.com/questions/593071/why-gradient-vanishing-exploding-is-bad</link>
      <description><![CDATA[我不知道为什么梯度消失/爆炸是一件坏事？
如果通过梯度下降和反向传播，参数的梯度很小，那么数学规则（链式法则）的力量就告诉梯度应该这么小才能得到优化的函数值。
因此，根据定义，无论梯度多大或多小，只要不下溢或上溢，梯度值都应该始终正确。
那么，为什么我们需要与数学斗争来改变微积分计算出的梯度？
或者链式法则中存在一些错误？]]></description>
      <guid>https://stats.stackexchange.com/questions/593071/why-gradient-vanishing-exploding-is-bad</guid>
      <pubDate>Fri, 21 Oct 2022 07:21:37 GMT</pubDate>
    </item>
    </channel>
</rss>