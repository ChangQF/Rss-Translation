<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 02 Aug 2024 12:28:53 GMT</lastBuildDate>
    <item>
      <title>计算不同统计检验的效应大小、统计功效和置信区间</title>
      <link>https://stats.stackexchange.com/questions/652209/calculation-of-effect-size-statistical-power-and-confidence-interval-for-diffe</link>
      <description><![CDATA[我对非正态分布使用以下双样本检验：

卡方检验
Kolmogorov-Smirnov 检验
Wilcoxon 秩和检验
Kruskal-Wallis 检验

它们都返回一个 p 值，即卡方检验的 p 值、Kolmogorov-Smirnov 检验的 p 值、Wilcoxon 秩和检验的 p 值和 Kruskal-Wallis 检验的 p 值。
由于 p 值不足以理解数据/分布（例如，请参阅Sullivan &amp; Feinn (2012)、Dunkler 等人 (2020)、Greenland (2016) 和 du Prel 等人 (2009)），我想计算

效果大小，
检验的统计功效，以及
置信区间（假设检验）。

但是，有些事情不清楚。
您能否告诉我，所有附加（p 值）指标，即 (i) 效果大小、(ii) 检验的统计功效和 (iii) 置信区间（假设检验），是否需要针对每项统计检验（即卡方检验、Kolmogorov-Smirnov 检验、Wilcoxon 秩和检验和 Kruskal-Wallis 检验）进行计算，或者它们不依赖于统计检验，并且只需计算一次？
此外，如果所有附加（p 值）度量，即 (i) 效应大小、(ii) 检验的统计功效和 (iii) 置信区间（假设检验），都需要针对每项统计检验进行计算，我是否应该针对每种类型的统计检验调整与效应大小、统计功效和置信区间相关的方程？]]></description>
      <guid>https://stats.stackexchange.com/questions/652209/calculation-of-effect-size-statistical-power-and-confidence-interval-for-diffe</guid>
      <pubDate>Fri, 02 Aug 2024 11:41:26 GMT</pubDate>
    </item>
    <item>
      <title>E-test 值的多重校正</title>
      <link>https://stats.stackexchange.com/questions/652208/multiple-correction-for-e-test-values</link>
      <description><![CDATA[我目前正在执行多个“E-tests”（poisson.mean），并且想知道使用 E-tests 进行多次校正的最合适方法，以及如何在 R 中进行此操作。
我正在计算 7 个不同实验组（2 个对照组，5 个感兴趣的实验组）中某个事件发生的次数（在给定的时间间隔内）。
我选择通过列出 7 个条件组和值来比较各组之间的泊松分布均值，然后以迭代方式执行泊松检验。然后从结果中获取 P 值，例如。

Cond1 &lt;- c(0,0,0,1,1,2,3,3,3) Cond2 &lt;- c(0,1,1,1,1,1,2,3,3)Cond3 &lt;- c(0,1,2,3,3,3,3,3,4)... Cond7 &lt;- c(3,3,3,3,4,4,4,5,6) result1 &lt;- poisson.test(x c(sum(Cond1), sum(Cond2)), T = c(length(Cond1), length (Cond2)), alternative = &quot;two.sided&quot;)
result2 &lt;- poisson.test(x c(sum(Cond1), sum(Cond3)), T = c(length(Cond1), length (Cond3)), alternative = &quot;two.sided&quot;) ... 
result20 &lt;- poisson.test(x c(sum(Cond6), sum(Cond7)), T = c(length(Cond6), length (Cond7)), alternative = &quot;two.sided&quot;)  P1 &lt;- result1§p.value P2 &lt;- result2§p.value ...P20&lt;- result20§p.value 

从这一点开始，我需要对多个测试进行校正，并希望使用 Benjamini-Hochberg 类型的排序 p 值显着性校正，但我想知道
A)哪种测试最适合这种分析
B) 如何在 R 中进行此操作
提前感谢您的帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/652208/multiple-correction-for-e-test-values</guid>
      <pubDate>Fri, 02 Aug 2024 11:36:56 GMT</pubDate>
    </item>
    <item>
      <title>复高斯分布和瑞利分布之间存在可互换性吗？</title>
      <link>https://stats.stackexchange.com/questions/652207/does-an-interchangeability-exist-between-complex-gaussian-distribution-and-rayle</link>
      <description><![CDATA[假设，一个复杂的高斯分布由以下公式给出：
$$N\sim\mathcal{CN}(0,1)$$
它也可以写成：
$$N=X+jY$$其中$X\sim\mathcal{N}(0,1/2)$和$Y\sim\mathcal{N}(0,1/2)$，$X$和$Y$都是正态分布的，并且彼此独立。
现在，我们知道对于独立的高斯分布随机变量$X$和$ class=&quot;math-container&quot;&gt;$Y$，$|r|=\sqrt{X^2+Y^2}$ 服从瑞利分布，而 $\theta=\tan^{-1}\frac{y}{x}$ 服从均匀分布。
问题：

复高斯和瑞利分布是否服从？均匀分布分别是同一量的笛卡尔形式和极坐标形式，即$N=X+jY=|r|\exp{(j\theta)}$?

我们能用$f_{R,\theta}(r,\theta)$的联合分布代替复杂的高斯分布吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/652207/does-an-interchangeability-exist-between-complex-gaussian-distribution-and-rayle</guid>
      <pubDate>Fri, 02 Aug 2024 11:11:32 GMT</pubDate>
    </item>
    <item>
      <title>适应数字跟踪数据的序列分析（应用程序跟踪）</title>
      <link>https://stats.stackexchange.com/questions/652206/adaptation-of-sequence-analysis-for-digital-trace-data-app-tracking</link>
      <description><![CDATA[我是一名通信科学家，对 TraMineR 和序列分析完全是新手。我有一个（相对较大）的数据集，其中包括研究参与者的应用程序使用情况。我的目标是识别连续使用的应用程序类别序列。
原始数据集如下所示：



参与者 ID
会话 ID
使用的应用程序类别
开始时间（实际上是 unix 时间）
结束时间（实际上是 unix 时间）




0001
0001_1
通信
2021-03-02 10:05:02
2021-03-02 10:05:09


0001
0001_1
社交媒体
2021-03-02 10:05:09
2021-03-02 10:07:09


0002
0002_1
游戏
2021-03-02 14:36:07
2021-03-02 14:36:07


...
...
...
...
...



因此，我有两个分析层次：(1) 一方面是参与者，另一方面是 (2) 会话。
第一步，我的目标是确定连续使用的应用程序类别序列。会话是打开和关闭智能手机屏幕之间的连贯使用序列。该数据集包含近 400 名参与者，每个参与者有大约 2000-5000 个会话（整个数据集约 140 万个会话）。
我已经首次尝试使用子样本，并遇到了两个问题：

我已将拼写格式的数据放入 seqdef 函数中。这是最佳时间格式的问题。这里有经验吗？我目前使用的是 unix-time，但我觉得单位太细了。

labels = seqstatl(sample$app_category)
states = 1:length(labels)

session_seq = seqdef(data = sample, 
var = c(&quot;session&quot;, &quot;begin&quot;, &quot;end&quot;, &quot;app_category&quot;), 
informat = &quot;SPELL&quot;,
states = states,
labels = labels,
process = FALSE)

print(session_seq[1:15, ], format = &quot;SPS&quot;)


第二个问题与所需的计算资源有关。即使是子样本，我也需要相对大量的计算能力。是否可以使计算更节省资源？是否可以选择拆分数据集，然后合并序列距离（批处理），或者这会扭曲我的结果？

我也很高兴收到有关阅读和阅读目标的更多提示。 TraMineR 用户指南已经帮了我很多忙。]]></description>
      <guid>https://stats.stackexchange.com/questions/652206/adaptation-of-sequence-analysis-for-digital-trace-data-app-tracking</guid>
      <pubDate>Fri, 02 Aug 2024 10:45:01 GMT</pubDate>
    </item>
    <item>
      <title>改变得分作为预测变量</title>
      <link>https://stats.stackexchange.com/questions/652205/change-score-as-predictor</link>
      <description><![CDATA[我想看看独立变量（T2-T1）的变化是否能预测 T2 时的另一个变量。例如，痴呆症患者在 1 年内认知障碍的增加越多，生活质量就越低。
我的问题是：我需要控制基线生活质量（因变量）吗？
我已经读到我应该控制 IV，但不确定 DV。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/652205/change-score-as-predictor</guid>
      <pubDate>Fri, 02 Aug 2024 10:42:34 GMT</pubDate>
    </item>
    <item>
      <title>RM Anova 或 2 配对 t 检验？并使用 RCI 验证个体差异</title>
      <link>https://stats.stackexchange.com/questions/652203/rm-anova-or-2-paired-t-tests-and-verifying-for-individual-differences-with-rci</link>
      <description><![CDATA[对于一个使用记录对刺激的反应时间的测试来评估麻醉后认知能力变化的研究项目，我们在麻醉后基线、1 小时和 4 小时对受试者进行了测试，总共进行了三次。该研究旨在判断麻醉后开车是否危险。
RM Anovas 或配对 t 检验是否更适合比较这 3 个时刻？另一项类似于小时的研究使用了 RM Anovas，但我担心会失去统计能力。RM Anova 的优点是它更具表现力，我可以在我的分析中添加受试者间因素（例如他们的代谢对麻醉剂的吸收）。
第二个问题，当我们处理安全问题时，报告是否有一个人受到镇静的负面影响非常重要。为此，我决定暂时采用可靠变化指数，但我不确定这是否是最好的选择，因为我手头没有重测信度。我使用了这个公式：calculate_RCI &lt;- function(M1, SD1, M2, SD2) {return((M1 - M2) / sqrt(SD1^2 + SD2^2))
是使用整个组的 SD 更好，还是使用不同时间点的个人的 SD 更好？]]></description>
      <guid>https://stats.stackexchange.com/questions/652203/rm-anova-or-2-paired-t-tests-and-verifying-for-individual-differences-with-rci</guid>
      <pubDate>Fri, 02 Aug 2024 08:59:59 GMT</pubDate>
    </item>
    <item>
      <title>对单个组的样本大小进行论证以获得所需准确度的平均值估计值</title>
      <link>https://stats.stackexchange.com/questions/652201/sample-size-justification-for-single-group-to-get-estimate-of-mean-to-desired-ac</link>
      <description><![CDATA[
我有一个计算机组件样品
这些计算机组件是分批生产的（1 批 = 1 批次），每批 200 个
组件可以单独进行电子测试
然后对该测试结果进行平均，以得出批次级值，以判断整个批次是否通过
我需要知道需要从批次中抽样多少个组件，以便对整个批次进行
准确的测试测量。
有人知道我应该如何证明这一点吗？
例如，测试 10 个组件是否能让我足够准确地估计出整个批次的平均测试结果？

我知道这里有一些未知数，比如“足够准确” - 也许是某种置信区间？
任何帮助都太棒了！
林肯]]></description>
      <guid>https://stats.stackexchange.com/questions/652201/sample-size-justification-for-single-group-to-get-estimate-of-mean-to-desired-ac</guid>
      <pubDate>Fri, 02 Aug 2024 08:15:30 GMT</pubDate>
    </item>
    <item>
      <title>如何手动计算零膨胀泊松回归的伪 R2（McFadden）</title>
      <link>https://stats.stackexchange.com/questions/652200/how-to-calculate-pseudo-r2-mcfadden-for-zero-inflated-poisson-regression-by-ha</link>
      <description><![CDATA[我正在寻找在 R 中手动计算伪 R2 McFadden 的方法。但是，当我使用下面的代码时
zeropr &lt;- zeroinfl(g ~ a + f | a + f, data = xuly240731_1000) summary(zeropr)
结果如下：
调用：
zeroinfl(formula = g ~ a + f | a + f, data = xuly240731_1000)
皮尔逊残差：
最小 1Q 中位数 3Q 最大
-2.4010 -1.0299 -0.4369 0.6539 6.2740
计算模型系数（带对数链接的泊松）：
估计标准差。误差 z 值 Pr(&gt;|z|)
（截距）0.709857 0.115392 6.152 7.67e-10 ***
a 0.038266 0.002577 14.846 &lt; 2e-16 ***
f 0.927251 0.282940 3.277 0.00105 **
零通胀模型系数（带 logit 链接的二项式）：
估计标准差。误差 z 值 Pr(&gt;|z|)
(截距) 0.22235 1.03148 0.216 0.8293
a -0.14307 0.06518 -2.195 0.0282 *
f -1.81661 2.19863 -0.826 0.4087
有效代码：0 &#39;&#39; 0.001 &#39;&#39; 0.01 &#39;&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
但是，当我尝试计算 Pseudo-R2 McFadden 时
library(performance)

library(DescTools)
PseudoR2(zeropr,c(&quot;McFadden&quot;))
结果是 &gt; PseudoR2(zeropr,c(&quot;McFadden&quot;))
[1] NA
您能告诉我如何处理这个问题并计算 Pseudo-R2 (McFadden) 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652200/how-to-calculate-pseudo-r2-mcfadden-for-zero-inflated-poisson-regression-by-ha</guid>
      <pubDate>Fri, 02 Aug 2024 07:56:36 GMT</pubDate>
    </item>
    <item>
      <title>处理表格小数据集[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652198/dealing-with-tabular-small-data-set</link>
      <description><![CDATA[我有一个表格数据集。该数据集有 18 列和 66 行。我借助 IQR 技术删除了异常值。我缩放了数据。但结果非常差。您建议我如何改进这个模型？我的问题是回归，应该借助其他 17 列来预测第 18 列。
训练和测试图
结果]]></description>
      <guid>https://stats.stackexchange.com/questions/652198/dealing-with-tabular-small-data-set</guid>
      <pubDate>Fri, 02 Aug 2024 07:30:07 GMT</pubDate>
    </item>
    <item>
      <title>频率嵌入的聚类方法</title>
      <link>https://stats.stackexchange.com/questions/652196/clustering-method-for-frequency-embeddings</link>
      <description><![CDATA[例如，我有以下要聚类的单词列表。列表的长度可能不同，词汇表为 $W = \{a,b,c\}$。将两个列表聚类到同一个簇中的标准是“它们重叠得越多，它们就越相似”。



索引
列表
嵌入




1
$[a,a,b,c]$
$[2,1,1]$


2
$[b,b,c]$
$[0,2,1]$


3
$[a,b,c,c,c]$
$[1,1,3]$


4
$[a,a,a]$
$[3,0,0]$



我发现使用欧几里得距离的经典聚类方法（例如 Kmeans）存在一些问题，即 $[a], [b],$ 和 $[c]$（具有嵌入 $[1,0,0], [0,1,0],$ 和 $[0,0,1]$）可以聚类到同一个聚类中，即使列表中存在不重叠的事件。此外，当嵌入是整数并且可能包含大量 0 时，Kmeans 不是一种好的聚类方法。
对于这个聚类问题，我应该使用哪种距离和哪种聚类方法？或者我应该在这里使用一些不同的嵌入？]]></description>
      <guid>https://stats.stackexchange.com/questions/652196/clustering-method-for-frequency-embeddings</guid>
      <pubDate>Fri, 02 Aug 2024 06:31:45 GMT</pubDate>
    </item>
    <item>
      <title>弗里德曼、皮萨尼和普维斯书中的辛普森悖论</title>
      <link>https://stats.stackexchange.com/questions/652195/simpsons-paradox-in-freedman-pisani-and-purves-book</link>
      <description><![CDATA[本书中有一个研究生录取性别歧视的例子。



专业
男性

女性






申请人数
录取率
申请人数
%录取


A
825
62
108
82


B
560
63
25
68


C
325
37
593
34


D
417
33
375
35


E
191
28
393
24


F
373
6
341
7


总计
2691
45
1835
30



总申请人数只是上述条目的总和。录取的总百分比，男性为 45%，是
62 * 825 / 2691 + ... + 6 * 373 / 2691

女性也是如此。
然后作者提出统计员会执行以下操作的论点：



专业
申请人总数




A
933 = 825 + 108


B
585


C
918


D
792


E
584


F
714 = 373 + 341


总计
4526



然后他们指出男性的加权平均录取率为：
62 * 933 / 4526 + ... + 6 * 714/4526 = 39（近似值）

对于女性来说也是如此：
82 * 933 / 4526 + ... + 7 * 714/4526 = 43（近似值）

我很难解释最后一对计算“男女加权平均录取率”。
他们说：

加权平均值控制了混杂因素——专业选择。这些平均值表明，如果有的话，录取过程对男性有偏见。

在这种情况下，39% 和 43% 的加权平均值究竟意味着什么？如何正确解释这些数字？原始百分比 45% 和 30% 似乎对我来说更容易理解和解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/652195/simpsons-paradox-in-freedman-pisani-and-purves-book</guid>
      <pubDate>Fri, 02 Aug 2024 05:33:00 GMT</pubDate>
    </item>
    <item>
      <title>对异方差和同方差感到困惑。我真的不知道这张图说明了什么</title>
      <link>https://stats.stackexchange.com/questions/652188/confused-about-heteroscedasticity-and-homoscedasticity-i-really-cant-tell-what</link>
      <description><![CDATA[因此，我正在使用大约 13 年期间某些股票的股票数据，现在我想在 stata 上检查异方差和自相关性。残差与拟合值如下所示。


该图是否暗示异方差？

如果该图不够充分，我可以使用什么测试？潜在的自相关性可能会影响 Beusch-pagan 或怀特检验的结果，以确定异方差

]]></description>
      <guid>https://stats.stackexchange.com/questions/652188/confused-about-heteroscedasticity-and-homoscedasticity-i-really-cant-tell-what</guid>
      <pubDate>Fri, 02 Aug 2024 01:11:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么 glmnet 不像 lm 那样处理丢失数据？</title>
      <link>https://stats.stackexchange.com/questions/652183/why-doesnt-glmnet-handle-missing-data-the-way-lm-does</link>
      <description><![CDATA[在 R 中进行计算时，我有一些玩具数据，并尝试使用 glmnet 来拟合弹性网络模型。我注意到，即使只有一个缺失值，算法也不会执行，建议事先估算缺失值。
# 设置可重复性的种子
set.seed(123)

# 生成一个 100x5 的随机数矩阵
data_matrix &lt;- matrix(rnorm(100*5), nrow=100, ncol=5)
data_df &lt;- as.data.frame(data_matrix)
data_df[1:1, 3] &lt;- NA # 单个缺失值
# 生成一个包含 100 个观测值的向量 Y，每个观测值为 1、2 或 3
Y &lt;- sample(1:3, 100, replace=TRUE)
glmnet::cv.glmnet(x = as.matrix(data_df),
y = as.matrix(Y),
alpha = 0.5,
family = &quot;multinomial&quot;)
glmnet(x, y, weights = weights, offset = offset, lambda = lambda, 中的错误：
x 有缺失值；考虑使用 makeX() 来估算它们

从算法上讲，当有缺失值时，是什么原因导致弹性网络不适合？相反，当使用 lm 并且有缺失值时，
ctl &lt;- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,NA)
trt &lt;- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group &lt;- gl(2, 10, 20, labels = c(&quot;Ctl&quot;,&quot;Trt&quot;))
weight &lt;- c(ctl, trt)
lm.D9 &lt;- lm(weight ~ group)

代码运行无任何错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/652183/why-doesnt-glmnet-handle-missing-data-the-way-lm-does</guid>
      <pubDate>Thu, 01 Aug 2024 21:42:45 GMT</pubDate>
    </item>
    <item>
      <title>正态分布概率密度函数与累积分布函数之比</title>
      <link>https://stats.stackexchange.com/questions/652176/ratio-of-normal-pdf-to-cdf</link>
      <description><![CDATA[我想证明
$$\Bigl\lvert \frac{\phi(a)}{\Phi(a)} - \frac{\phi(b)}{\Phi(b)} \Bigr\rvert \leq |a-b|$$
其中 $\phi$ 是标准正态 pdf，而 $\Phi$ 是标准正态 cdf。]]></description>
      <guid>https://stats.stackexchange.com/questions/652176/ratio-of-normal-pdf-to-cdf</guid>
      <pubDate>Thu, 01 Aug 2024 20:06:38 GMT</pubDate>
    </item>
    <item>
      <title>残差与拟合图显示了周期性模式。我从 300 个解释变量中选择了 5 个。我应该添加更多变量还是冒着过度拟合的风险？</title>
      <link>https://stats.stackexchange.com/questions/652174/resids-vs-fitted-plot-shows-cyclical-patterns-i-have-chosen-5-explanatory-varia</link>
      <description><![CDATA[我根据其他属的相对丰度预测 1 个属 (A) 的相对丰度。我随意选择了 5 个似乎最有可能有帮助的属（我所有重复实验中随时间推移最丰富的 5 个属），但我的社区总共有 300 多个属。我使用相同的方法预测了 2 个细菌属和 2 个真核生物属的丰度。
除了残基与拟合值之外，诊断结果看起来都很好，并且该模型在预测未来数据方面表现得出奇的好。
我正在写一篇文章，想说的是，虽然残差与拟合值显示出拟合不足的迹象，并且添加其他属很可能有助于预测，但仅包含这 5 个物种使我们能够相当准确地预测随时间的变化。
该建模不是我文章的核心，目的不是预测现实世界中发生的现象，而是一个探索性过程，只是看看是否可以预测属的相对丰度变化。这种思路在发表的文章中会成立吗？


使用包 mvgam 在 R 中建模]]></description>
      <guid>https://stats.stackexchange.com/questions/652174/resids-vs-fitted-plot-shows-cyclical-patterns-i-have-chosen-5-explanatory-varia</guid>
      <pubDate>Thu, 01 Aug 2024 19:31:37 GMT</pubDate>
    </item>
    </channel>
</rss>