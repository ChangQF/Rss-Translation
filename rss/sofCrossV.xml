<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 19 Oct 2024 12:30:42 GMT</lastBuildDate>
    <item>
      <title>针对元分析，应选择哪个估计量^REML 还是使用 Wild Bootstrap 的 CR2？</title>
      <link>https://stats.stackexchange.com/questions/656000/which-estimator-to-choose-for-meta-analysis-reml-or-cr2-with-wild-bootstrap</link>
      <description><![CDATA[我正在关注以下书籍：https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/multilevel-ma.html
我无法选择要使用哪个估计器：REML 还是带有 Wild Bootstrap 的 CR2。
或者也许同时运行它们并呈现为敏感性分析，尽管我看不到任何其他元分析这样做，所以也许这会进一步使文章的读者感到困惑。
一些细节：
我的样本量很小（两者都可以帮助）
和依赖效应大小（CR2 最适合它）
我的结果是一个连续变量（REML 似乎更适合）
如果您有类似的问题，您能否建议您做了什么？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656000/which-estimator-to-choose-for-meta-analysis-reml-or-cr2-with-wild-bootstrap</guid>
      <pubDate>Sat, 19 Oct 2024 12:01:22 GMT</pubDate>
    </item>
    <item>
      <title>是否可以将其作为时间序列数据分析？我应该使用什么模型来处理这些数据？</title>
      <link>https://stats.stackexchange.com/questions/655999/is-it-possible-to-analyse-this-as-time-series-data-what-model-should-i-use-for</link>
      <description><![CDATA[我有一个从 1 到 10 的变量，其中 1 表示“永远无法证明”，而 10 表示“始终可以证明”。答案在极端值和中间值（1、10、5、6）处密度较高。此项目还有一个“不想回答”选项。这个问题是在 5 轮研究中从不同人（但在同一个国家）收集的。
我想使用其他 5 个分类和数值变量来预测此变量的响应。问题是，我不知道是否可以使用线性回归、逻辑回归，或者我是否需要切换到机器学习模型。无论如何，如果我可以将它们作为时间数据进行陈述，那将是理想的，但我认为 5 个数据集合少于任何模型所需的数量。
所以我的问题是：

是否可以仅使用 5 个数据集合来对此数据进行陈述？
如果我的 10 分项目作为因变量，我应该使用什么模型？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655999/is-it-possible-to-analyse-this-as-time-series-data-what-model-should-i-use-for</guid>
      <pubDate>Sat, 19 Oct 2024 11:36:18 GMT</pubDate>
    </item>
    <item>
      <title>后验预测 p 值和模型复杂性</title>
      <link>https://stats.stackexchange.com/questions/655998/posterior-predtive-p-values-and-model-complexity</link>
      <description><![CDATA[我正在执行贝叶斯后验预测检验，我发现更复杂模型（所有随机效应）的后验预测 p 值比更简单模型（所有固定效应或混合效应）的后验预测 p 值更远离（且低于）0.5。这可能吗？显然，一切都是正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655998/posterior-predtive-p-values-and-model-complexity</guid>
      <pubDate>Sat, 19 Oct 2024 08:53:54 GMT</pubDate>
    </item>
    <item>
      <title>为了在拥有菲多利和桂格食品的情况下超越百事可乐，可口可乐公司应该收购哪些食品品牌和公司？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655996/to-one-up-pepsico-with-their-ownership-of-frito-lay-and-quaker-what-food-brands</link>
      <description><![CDATA[我实际上查看了百事可乐和可口可乐公司旗下各个品牌的图片，并决定提出一个值得撰写的假设情景问题，例如可口可乐收购各种食品公司，以与百事可乐对菲多利和桂格燕麦的历史所有权竞争。
我向 AI 网络搜索询问了以下两个版本的同一问题，并将链接给您答案。
1：https://poe.com/s/vkiUk4NocxZ60x9Z9qQx?utm_source=link
2：https://poe.com/s/1EIzOGBooffeNXwWclgs?utm_source=link
第一个链接谈到百事可乐收购 Siete Foods 及其类似品牌，此外还有 Bare Snacks、Health Warrior、ChickPea Snacks、Pop Corners、Kettle Brand、LesserEvil 和 RXBAR 等公司，这些都是可口可乐收购的理想对象。
第二个链接列出了 Kettle、Cape Cod Potato Chips、Popchips、RXBAR、Kind Snacks、Annie’s Homegrown、Banza、Naked Juice、Honest Tea、一个（或更多）区域性玉米片品牌，以及当地和/或手工小吃品牌，这些都是可口可乐收购的理想对象。
但是你们呢？真人的猜测呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/655996/to-one-up-pepsico-with-their-ownership-of-frito-lay-and-quaker-what-food-brands</guid>
      <pubDate>Sat, 19 Oct 2024 07:05:10 GMT</pubDate>
    </item>
    <item>
      <title>令人困惑的逻辑回归模型输出</title>
      <link>https://stats.stackexchange.com/questions/655994/confusing-logistic-regression-model-output</link>
      <description><![CDATA[我正在使用加权逻辑回归模型分析来自样本量大（&gt;88,000）的国家数据集的数据，以预测基于各种组成员身份的结果的概率。我想将每个组成员身份与不属于该组的成员进行比较，而不是与定义的参考组进行比较（例如，添加所有虚拟编码变量，而不是忽略参考变量）。对于我研究的大多数健康结果，这种方法效果很好，但其中一个结果返回的结果是，属于每个详尽且互斥的组的成员的 OR 为 &gt;1，CI 不超过零。我的解释是，与不属于该组的成员相比，每个组的几率都更高……这在逻辑上说不通。
我正在使用 SAS 9.4 surveylogistic 程序，并指定 NOMCAR 来解释缺失数据。域、权重、层、集群和模型都经过了三重准确性检查，看起来不错。所有单元格大小均大于 10。模型收敛且无错误。当我看到加权分析的结果时，所有输出看起来都很合理，并且相对接近我作为诊断的一部分运行的未加权分析的结果，尽管其中一个组在未加权分析中并不显著（未加权 OR 1.06；加权 OR 1.80，CI 1.11-2.9）
我试图确定问题是否在于在没有指定参考组的情况下进行比较（如果是这样，我预计会出现脊状误差，但没有发生）或者模型中的权重是否能够以某种方式将事物转移到这个奇怪的结果。或者相反，如果我的解释有问题，而输出没问题。任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655994/confusing-logistic-regression-model-output</guid>
      <pubDate>Sat, 19 Oct 2024 03:13:18 GMT</pubDate>
    </item>
    <item>
      <title>使用列范数限制精度矩阵的谱范数</title>
      <link>https://stats.stackexchange.com/questions/655993/bound-the-spectral-norm-of-the-precision-matrix-using-column-wise-norm</link>
      <description><![CDATA[在本文中，作者获得了关于谱范数的精度矩阵的收敛速度，（定理 1，第 7 页）
$$
\|\hat{\Omega}-\Omega\|_2 \le CM_p s_p\sqrt{\frac{\log p}{n}}
$$
其中$\|\Omega\|_{L1}=\underset{1\le j\le p}{\max}\sum_{i=1}^{p}|\omega_{ij}|\le M_p$ 和 $\underset{1\le j\le p}{\max}\sum_{i=1}^{p}1\left(\omega_{ij}\neq 0\right)\le s_p$。
他们通过控制精度矩阵的列来证明这个定理（第 37 页，不等式 (9)）：
$$
|\hat{\beta}_{S_i}-\omega_{S_i}|\le C\sqrt{\frac{\log p}{n}}
$$
其中 $\hat{\beta}_i$ 是 $\hat{\Omega}$ 的第 i 列。
我们如何使用逐列边界来控制收敛速度？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655993/bound-the-spectral-norm-of-the-precision-matrix-using-column-wise-norm</guid>
      <pubDate>Sat, 19 Oct 2024 02:44:14 GMT</pubDate>
    </item>
    <item>
      <title>二进制时间序列数据的置信带</title>
      <link>https://stats.stackexchange.com/questions/655991/confidence-bands-for-binary-time-series-data</link>
      <description><![CDATA[上下文：我有二进制数据 $x_{it}\in\{0,1\}$，其中 $i\in\{1,...,N\}$ 表示试验索引，而 $t\in\{1,...,T\}$ 表示时间索引（在试验之间独立；不在时间之间独立）。这是我运行的模拟（$N$ 次，每次 $T$ 个周期），我没有对随机过程 $\{x_{\cdot t}\}_{t=1}^T$ 的明确描述。
我的问题：我可视化了 $x_{\cdot,t}$ 在时间 $t$ 之后始终保持在 1 的频率，并绘制了每个 $t$ 的图表。我还想绘制一个“置信区间”，但我不知道如何/是否可以做到这一点。
我目前的工作：对于每个$(i,t)$，$S_{it} = \prod_{\tau=t}^{T}x_{i\tau}$ 编码事件，即对于所有$\tau\geq t$，$x_{i\tau}=1$。我在每个 $t$ 上绘制了 $\frac{1}{N}\sum_{n=1}^N 1\{S_{\cdot t}=1\}$，以可视化 $x_{\cdot t}$ 在 $t$ 时间之后保持为 1 的频率。（这正确吗？）关于可视化置信区间，我曾尝试查找有关如何对“生存曲线”进行可视化的指南（因为我所绘制的内容似乎与此相关），但我不知道它们是否适用（即使如此，我也不完全确定如何将迄今为止找到的方法转化为我的问题）。任何指导都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655991/confidence-bands-for-binary-time-series-data</guid>
      <pubDate>Fri, 18 Oct 2024 22:58:48 GMT</pubDate>
    </item>
    <item>
      <title>两个随机变量之间差异的概率区间</title>
      <link>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</link>
      <description><![CDATA[假设 X1 和 X2 是两个随机变量，其中 X1 有 95% 的概率位于区间 [L1, R1] 内，X2 有 95% 的概率位于区间 [L2, R2] 内。这是否意味着 X1 - X2 之差位于区间 [L1 - R2, R1 - L2] 内的概率将超过 95%？此外，X1 和 X2 可以是相关的，也可以是独立的。
(1) 有人可以澄清概率界限是否适用于这种情况吗？或者这个说法的反例。
(2) 如果有反例，是否有其他条件可以添加以使其成立？]]></description>
      <guid>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</guid>
      <pubDate>Fri, 18 Oct 2024 19:35:37 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 包 marginaleffects 进行编码比较和交互</title>
      <link>https://stats.stackexchange.com/questions/655981/coding-comparisons-and-interactions-with-the-r-package-marginaleffects</link>
      <description><![CDATA[我开始学习如何使用 R 包 marginaleffects，并希望得到一些特定应用方面的帮助。
为了说明，我们使用 afex 包中的数据集。变量 phase 是一个具有三个级别的因子：“fup”、“post”和“pre”。变量 age 是连续的。下面是使用 lme4 拟合的模型：
library(afex); library(lme4); library(phia)
data(obk.long, package = &quot;afex&quot;)
options(contrasts = c(&quot;contr.sum&quot;, &quot;contr.poly&quot;))
fm &lt;- lmer(value ~ phase * age + (1|id), data = obk.long)

我想使用 marginaleffects 复制以下七个比较和交互：

对比因子 phase 的前两个级别（“fup”与“post”）
在 phia 中，这是通过以下方式完成的：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), adjustment = &quot;none&quot;)


对比phase的前两个级别，其中age固定为 5.5
在phia中：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), covariates = c(age = 5.5), adjustment = &quot;none&quot;)


age的斜率（phase所有级别的平均值）
在phia中：
testInteractions(fm, pairwise = NULL, slope = &quot;age&quot;, adjustment = &quot;none&quot;)


前两个级别之间的age斜率差异 (&quot;fup&quot; vs. &quot;post&quot;) 的 phase
在 phia 中：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), slope = &quot;age&quot;, adjustment = &quot;none&quot;)


phase 的三个级别之间的综合对比（例如 &quot;fup&quot; - &quot;pre&quot; 和 &quot;post&quot; - &quot;pre&quot;）
在 phia 中：
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))))


phase 三个级别的综合斜率比较（例如，&quot;fup&quot; 与 &quot;pre&quot; 以及 &quot;post&quot; 与 &quot;pre&quot; 的斜率差异）
在 phia 中：
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))), slope = &quot;age&quot;)


固定年龄的 phase 三个级别的综合对比（例如，&quot;fup&quot; - &quot;pre&quot;和“post” - “pre” 在 age = 5.5)
在 phia:
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))), covariates = c(age = 5.5))



我的问题是：如何使用 marginaleffects 包对这七个效应进行编码？]]></description>
      <guid>https://stats.stackexchange.com/questions/655981/coding-comparisons-and-interactions-with-the-r-package-marginaleffects</guid>
      <pubDate>Fri, 18 Oct 2024 18:51:31 GMT</pubDate>
    </item>
    <item>
      <title>调整因变量的个别值</title>
      <link>https://stats.stackexchange.com/questions/655970/adjusting-individual-values-of-a-dependent-variable</link>
      <description><![CDATA[我有一个数据集，其中包含 600 个脉搏波速度读数，我需要根据每个参与者的平均动脉血压进行调整。我可以得到这样的结果：
m &lt;- lm(pulse_wave_velocity ~ mean_arterial_bp, data = df)

那么我是否可以使用模型中的残差来计算调整后的脉搏波速度，如果是，是否应该将它们添加到截距中？]]></description>
      <guid>https://stats.stackexchange.com/questions/655970/adjusting-individual-values-of-a-dependent-variable</guid>
      <pubDate>Fri, 18 Oct 2024 14:57:17 GMT</pubDate>
    </item>
    <item>
      <title>负二项回归与普通逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/655965/negative-binominal-regression-vs-ordinary-logistic-regression</link>
      <description><![CDATA[我有选举期间的社交媒体数据，其中包含数千名政治人物在社交媒体上的帖子。数据集有许多控制变量，例如日期、关注者数量、视觉效果的存在、是否是热门演员的转发等。
这项研究本质上是关于语言学的。我的目标是测试隐喻相关指标是否与高参与度（喜欢、分享、评论）相关。由于它是社交媒体数据，因此存在高度过度分散。我确认负二项回归是最佳选择。
在用喜欢计数拟合模型后，我注意到该模型在处理参与度非常高或参与度非常低的帖子时遇到了困难。它似乎也有显著的异常值。




考虑到这是高度密集时期的社交媒体数据，我对模型在某些帖子上遇到困难并不感到惊讶。大多数被低估的帖子都包括特殊/耸人听闻的视觉效果、视频或公告，这些都使它们非常高。
由于它们不是虚假数据并且是社交媒体固有的，所以我没有删除它们。主要目标不是建立一个预测参与度的模型，而是看看隐喻指标是否与参与度呈正相关。
我想知道这是否是正常的，因为数据的性质。此外，NBR 是否对我来说是正确的测试，或者我是否应该在根据百分位数将参与度数据分解为高、中、低参与度后考虑 OLR。]]></description>
      <guid>https://stats.stackexchange.com/questions/655965/negative-binominal-regression-vs-ordinary-logistic-regression</guid>
      <pubDate>Fri, 18 Oct 2024 14:02:35 GMT</pubDate>
    </item>
    <item>
      <title>疾病建模与微生物组建模：结果应该是哪一个？</title>
      <link>https://stats.stackexchange.com/questions/655941/modeling-disease-vs-microbiome-which-should-be-the-outcome</link>
      <description><![CDATA[我有一个与微生物组研究相关的问题，在这个领域，许多研究人员评估疾病组和对照组之间的分类单元丰度是否不同。我经常看到统计模型，其中分类单元作为结果变量，疾病状态作为解释变量。但是，我想知道这种模型是否更适合评估疾病是否影响微生物组，而不是相反。大多数研究人员的目标是找到微生物组影响疾病的证据。鉴于此，该模型是否不合适，使用分类单元作为解释变量，疾病状态作为结果的模型是否更合适？当使用仅包含数值变量且不涉及协变量的线性模型时，等式中的位置（无论是在左侧还是右侧）可能不太重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/655941/modeling-disease-vs-microbiome-which-should-be-the-outcome</guid>
      <pubDate>Fri, 18 Oct 2024 01:10:05 GMT</pubDate>
    </item>
    <item>
      <title>回归模型中每个变量都需要具有统计显著性吗？</title>
      <link>https://stats.stackexchange.com/questions/655938/does-every-variable-need-to-be-statistically-significant-in-a-regression-model</link>
      <description><![CDATA[我最近拟合了一个回归模型 (ARIMAX)，其中有些变量 (3) 具有统计显著性，有些则不显著 (1)。我删除了统计上不显著的变量并重新拟合模型，现在所有变量都具有统计显著性（即新模型有 3 个变量，旧模型有 4 个变量）。
但是，这个新模型（所有变量都具有统计显著性）的表现比旧模型（并非所有变量都具有统计显著性）更差。也就是说，新模型的预测误差比旧模型更严重。
这是统计学中的常见做法吗？如果所有变量都具有统计显著性，选择性能较差的模型是否更可取，还是最好选择性能较好的模型，即使并非所有变量都具有统计显著性。
我知道过度拟合和交叉验证等概念。我使用除过去 6 个月数据之外的所有可用数据训练了这两个模型。我还让这两个模型预测过去 6 个月的可用数据，并将预测值与实际值进行比较。使用旧模型（即并非所有变量都具有统计显著性的模型）我仍然获得了更好的结果。
即使并非所有变量都具有统计显著性，是否可以采用性能更好的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/655938/does-every-variable-need-to-be-statistically-significant-in-a-regression-model</guid>
      <pubDate>Fri, 18 Oct 2024 01:02:57 GMT</pubDate>
    </item>
    <item>
      <title>计数值的统计检验</title>
      <link>https://stats.stackexchange.com/questions/655928/statistical-test-for-count-values</link>
      <description><![CDATA[我有 4 个故事，每个故事都有字数和复数词的数量：



故事
单词数
复数




1
356
45


2
273
23


3
303
28


4
289
42



我想知道是否可以进行统计测试以确定这些故事在字数方面是否存在显着差异，然后再进行另一项测试以确定这些故事在复数数量方面是否存在显着差异。
测试的目的是确保这些故事在阅读难度方面没有显着差异。这是一项心理学研究，我们需要确保故事难度中没有混淆。我们正在测试其他更相关的单词特征，但这些是连续值，我们可以对其进行其他测试。
我没有人口频率可以与之比较，以便使用 Fisher 精确检验，我认为我不能使用卡方检验，因为那里的计数似乎应该是相关的，例如测试一群人是否喜欢苹果、橘子或香蕉，而一个人不能选择两个选项，我有点困惑，不知道我可以在这里使用什么测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/655928/statistical-test-for-count-values</guid>
      <pubDate>Thu, 17 Oct 2024 19:33:29 GMT</pubDate>
    </item>
    <item>
      <title>为什么$\text{rank}(L)=\dim(Z_{h})$？</title>
      <link>https://stats.stackexchange.com/questions/655853/why-textrankl-dimz-h</link>
      <description><![CDATA[高斯隐变量图模型
假设我们有高斯分布的观测变量$Z_o$和隐变量$Z_h$。与这些变量相关的联合精度矩阵$K_{(o,h)}$由以下公式给出：
$$
K_{(o,h)} = \begin{bmatrix} K_o &amp; K_{o,h} \\ K_{h,o} &amp; K_h \end{bmatrix}。
$$
根据 Schur 补函数，$Z_o$ 的边缘化精度矩阵 $\tilde{K}_o$ 可以写成：
$$
\tilde{K}_o = K_o - K_{o,h} K_h^{-1} K_{h,o} = K_o - L,
$$
其乘积矩阵 $L = K_{o,h} K_h^{-1} K_{h,o}$。这两个组件具有特定的属性：$K_o$ 是 $Z_o$ 的稀疏条件精度矩阵，以 $Z_h$ 为条件；乘积矩阵 $L$ 总结了边缘化对隐藏变量的影响。该矩阵的秩（等于隐藏变量 $Z_h$ 的数量）较低，因为隐藏变量的数量应该很少。
给定 $Z_o$ 的 i.i.d. 样本，我们的目标是估计 $K_o$ 和 $L$；我们特别感兴趣的是${\color{red}{\text{}L}}$的秩，因为${\color{red}{\text{它等于隐藏变量的数量 } Z_h}}$。这些矩阵可以通过求解凸松弛来恢复：
$$
(\hat{K}_o, \hat{L}) = \underset{K_o, L}{\text{argmin}} \, \text{trace}((K_o - L)\Sigma_o) - \log \det(K_o - L) + \lambda(\gamma \|K_o\|_1 + \text{trace}(L)),
$$
其中$\hat{K}_o$ 和 $\hat{L}$ 分别是 $K_o$ 和 $L$ 的估计值，$\Sigma_o$ 是 $Z_o$ 的经验边际协方差。

根据矩阵基本理论，$L$ 的秩应该小于或等于 $\dim(Z_h)$，即隐变量的数量。我很难理解为什么许多参考文献直接将$L$的秩与$\dim(Z_h)$等同起来。这种方法的理论依据和实际意义是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655853/why-textrankl-dimz-h</guid>
      <pubDate>Wed, 16 Oct 2024 10:55:39 GMT</pubDate>
    </item>
    </channel>
</rss>