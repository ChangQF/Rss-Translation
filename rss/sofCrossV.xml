<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 05 Feb 2025 15:18:16 GMT</lastBuildDate>
    <item>
      <title>为什么 mgcv GAM 中的 p 值有时正好为零？</title>
      <link>https://stats.stackexchange.com/questions/660994/why-p-values-are-sometimes-exactly-zero-in-mgcv-gam</link>
      <description><![CDATA[我正在使用 GAM 来模拟表型水平如何随时间变化。我们对 4 个时间点进行了表型测量。当时间有显著影响时，时间平滑项的 p 值等于 0。这是一个模拟示例：
d &lt;- data.frame(x = c(rep(1,20), rep(2,20), rep(3,20), rep(4,20)), 
+ y = c(rnorm(20, 0.5, 0.5), rnorm(20, 0.2, 0.5), rnorm(20, -0.2, 0.5), rnorm(20, -0.5, 0.5)))

m &lt;- gam(y ~ s(x, k = 4), data = d, method = &#39;REML&#39;)

数据如下所示：

因此，时间的影响确实不是一条水平线，因此是显著的。我知道 GAM p 值只是近似值，但有人能解释一下为什么在这种特殊情况下无法计算出更精确的 p 值吗？我是不是做错了什么，有没有办法得到一个不同于 0 的值？
（在这个特殊情况下，依赖关系是线性的，我可以使用线性回归，但在我的数据中，我经常有我想研究的非线性关系）。
summary(m) 的输出：
系列：高斯 
链接函数：恒等 
公式：
y ~ s(x, k = 4)
参数系数：
估计标准误差 t 值 Pr(&gt;|t|) 
（截距）0.05883020 0.03378357 1.74139 0.085559 .
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df F p 值 
s(x) 1.000016 1.000031 157.0853 &lt; 2.22e-16 ***
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) = 0.664 偏差解释 = 66.8%
-REML = 21.711 尺度估计 = 0.091306 n = 80

以及平滑项的单独摘要：
s(x) 1.000015629 1.000031257 157.0852647 0

任何帮助都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660994/why-p-values-are-sometimes-exactly-zero-in-mgcv-gam</guid>
      <pubDate>Wed, 05 Feb 2025 14:58:39 GMT</pubDate>
    </item>
    <item>
      <title>引导和选择调整</title>
      <link>https://stats.stackexchange.com/questions/660993/bootstrap-and-adjustment-for-selection</link>
      <description><![CDATA[假设我有许多估计量 $\{ \hat{\theta} \}_{i=1}^m$ 和感兴趣的参数 $\{ \theta \}_{i=1}^m$。我对最大 $\theta$ 感兴趣，我可以使用 bootstrap 构建一个考虑选择的置信区间吗？
我可以想到几种可能的策略，估计所有 $\theta$ 的最大偏差。即，在引导样本 $j$ 中获取最大偏差：
$$ B_j = \max_i (\hat{\theta}^j_i-\theta_i), $$
或来自最大估计的偏差，
$$ B_j = \max_i (\hat{\theta}^j_i- \max_k \theta_k)。 $$
第二个问题是，这是否可用于构建置信区间？任何参考资料都很好。]]></description>
      <guid>https://stats.stackexchange.com/questions/660993/bootstrap-and-adjustment-for-selection</guid>
      <pubDate>Wed, 05 Feb 2025 13:37:29 GMT</pubDate>
    </item>
    <item>
      <title>无法从 gam.check() 解释 qqplot</title>
      <link>https://stats.stackexchange.com/questions/660991/trouble-interpreting-qqplot-from-gam-check</link>
      <description><![CDATA[我无法解释从使用 family=&quot;scat&quot; 建模的游戏中获得的诊断图。
数据似乎可以很好地调整到 45 度线，但红色参考线垂直于 x 轴。这是否意味着模型的结果不可靠？
我粘贴了其余的诊断图，它们看起来不错。

我用来拟合模型的代码是
model&lt;- gam(pHT ~ s(T) + s(O2) + s(S) + s(pratio)+ s(T, by=station) + s(O2, by=station) + s(S, by=station) + s(pratio, by=station)+ month, data=datosresu14, method=&quot;REML&quot;, family=&quot;scat&quot;) 
除 station 和 month 外，所有变量都是连续的，它们是因子。
此外，k.check() 看起来好的
`&gt; k.check(m15GIg)
k&#39; edf k 指数 p 值
s(T) 9 1.000001e+00 1.0394585 0.4950
s(O2) 9 1.398550e+00 1.0388868 0.4625
s(S) 9 1.000000e+00 0.9649325 0.3500
s(pratio) 9 1.000005e+00 1.3053333 0.8975
s(T):station1 km 9 1.000000e+00 1.0394585 0.4825
s(T):station4 km 9 3.338502e-07 1.0394585 0.5075
s(O2):站1公里 9 1.000000e+00 1.0388868 0.4900
s(O2):站4公里 9 1.000003e+00 1.0388868 0.5375
s(S):站1公里 9 4.601437e+00 0.9649325 0.3400
s(S):站4公里 9 2.627084e-06 0.9649325 0.3550
s(pratio):站1公里 9 2.971070e-07 1.3053333 0.8775
s(pratio):站4公里 9 1.000001e+00 1.3053333 0.8800`

谢谢，
三月。]]></description>
      <guid>https://stats.stackexchange.com/questions/660991/trouble-interpreting-qqplot-from-gam-check</guid>
      <pubDate>Wed, 05 Feb 2025 13:18:09 GMT</pubDate>
    </item>
    <item>
      <title>当 $y$ 已从 $x$ 计算出来时进行回归</title>
      <link>https://stats.stackexchange.com/questions/660990/regression-when-y-has-been-calculated-from-x</link>
      <description><![CDATA[我正在阅读这篇论文：

Catalán, N., Marcé, R., Kothawala, D. N., &amp; Tranvik, L. J. (2016)。内陆水域水滞留时间控制有机碳分解速率。Nature Geoscience, 9, 501–504. doi:10.1038/ngeo2720。摘自https://www.nature.com/articles/ngeo2720

作者假设某些过程可以建模为
$$y_i = \exp(-a t_i ^{b+1})$$
其中 $y_i$ 和 $t_i$ 是来自不同实验的配对测量值，$a$ 和 $b$ 是经验拟合常数。为了识别 $a$ 和 $b$，他们使用对数-对数线性回归，这似乎是合理的。如果我这样做，我可能会尝试这样的事情：
$$\ln(-\ln(y_i)) = \ln(a) + (b + 1)t_i \tag 1\label 1$$
这应该是一条直线，斜率为 $(b + 1)$，截距为 $\ln(a)$。然而，在论文中，他们实际拟合的模型是：
$$\ln \left( \frac{-\ln(y_i)}{t_i} \right) = \ln(a) + b\ln(t_i) \tag 2\label 2 $$
只需简单重新排列，即可使斜率等于 $b$，而不是 $(b + 1)$，但看到他们的响应变量和解释变量中都有 $t_i$，我感到很不舒服。 这样可以吗？
我最初假设回归方程两边都有$t_i$会导致虚假相关性和显著性估计值过高 - 显然，如果方程一边有$\ln(x)$，另一边有$\ln(\text{something }/ x)$，那么无论如何，您都可能会发现显著关系。但是，我刚刚下载了他们的数据，并尝试自己拟合这两个模型，使用这两种方法，我得到的参数估计值、置信区间和显著性得分基本相同。此外，他们的方法（$\eqref 2$）的 R2 值实际上低于 $\eqref 1,$，所以我的直觉似乎至少有部分错误。
这两种方法（$\eqref 1,~\eqref 2$）是否都是识别 $a$ 和 $b$ 的有效方法？我对响应变量是预测变量的显式函数的回归保持警惕是否正确？如果是这样，在什么情况下可以这样做（在这种情况下似乎没有太大区别）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660990/regression-when-y-has-been-calculated-from-x</guid>
      <pubDate>Wed, 05 Feb 2025 12:43:17 GMT</pubDate>
    </item>
    <item>
      <title>通过一次一个/双变量双选择套索 p 值进行推断的变量选择问题</title>
      <link>https://stats.stackexchange.com/questions/660988/problems-of-variable-selection-for-inference-through-one-at-a-time-bivariate-dou</link>
      <description><![CDATA[对于这个可能难以理解的标题，我深表歉意，因为这是我在能力范围内能做到的最好的。
我从事医学研究，但我进入该领域时拥有医学学位，而不是数学/统计学背景，以及足以让我理解医学文献中大部分统计数据的生物统计学基本知识。我想请您帮助我指出在实施多元回归的变量选择特定程序以进行推断时存在的问题。
我的任务是处理一个数据集（n = 300），以找出变量列表（=10 个变量）与二元结果 Y（“1”表示死亡，“0”表示生存）之间的统计关联（如果有的话）。
我已经成功说服高级/主要研究人员不要仅根据双变量分析的结果（X1 上的 Y、X2 上的 Y、X3 上的 Y、X4 上的 Y 等，其中当 p 值达到某个阈值时，X 将被添加到多元回归模型中）来构建多元回归模型，这在医学研究中非常普遍。我更喜欢通过对主题的理解和批判性/全面的文献综述来构建推理模型，同时认识到这样做的局限性。
然而，她担心这种方法会导致某些变量中收集的数据根本无法使用，因为我们肯定无法将所有十个变量插入最终的回归模型中（考虑到我们的样本量很小）。
她想让我尝试 Stata 中提供的双选择套索技术（自 2019 年起在 Stata 版本 16 中https://blog.stata.com/2019/09/09/using-the-lasso-for-inference-in-high-Dimension-models/; 我是 R 的初学者，所以这对我来说不是一个选择此时可以使用两种方式来运行我通过主题理解/文献综述在双选择套索中构建的回归模型，其中我没有选择的变量作为双选择套索所需的控制协变量的一部分。

运行双变量分析（X1 上的 Y、X2 上的 Y，依此类推），其中其余未选择的变量将在套索中指定为控制协变量，例如，


2a. X1 上的 Y，控制（X2 到 X10）
2b. X2 上的 Y，控制（X1、X3、...、X10）
2c. X3 上的 Y，控制（X1-X2、...、X4-X10）
2d.等等
...并将达到双选择套索 p 值为 .05 的变量纳入最终回归模型。
虽然我认为方法 1 值得一试（我对套索回归应用于推理的理解不完整），但我觉得方法 2 非常成问题，可能接近数据挖掘。
我想请教您对这两种方法的评论。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660988/problems-of-variable-selection-for-inference-through-one-at-a-time-bivariate-dou</guid>
      <pubDate>Wed, 05 Feb 2025 12:14:36 GMT</pubDate>
    </item>
    <item>
      <title>如何固定高斯混合拟合的权重和均值？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660987/how-to-fixate-weights-and-means-for-gaussian-mixture-fitting</link>
      <description><![CDATA[有没有办法固定 sklearn.mixture.GaussianMixture 的 权重 和 均值？
可以设置初始值，但拟合算法会改变它。我需要精确地修复它，以适应多个样本，保持除 sigma 之外的所有内容相同。
虽然可以通过使样本对称来保持均值，但它不适用于权重。
示例：
import numpy as np
from sklearn.mixture import GaussianMixture

# 生成样本
n_samples = 10000
means = [0, 0]
variances = [1, 4]
weights = [0.7, 0.3]

sample = np.hstack([
np.random.normal(loc=means[0], scale=np.sqrt(variances[0]), size=int(n_samples * weights[0])),
np.random.normal(loc=means[1], scale=np.sqrt(variances[1]), size=int(n_samples * weights[1]))
])
np.random.shuffle(sample) # 随机混合成分

# 拟合高斯混合
sample = sample.reshape(-1, 1)
gmm = GaussianMixture(
n_components=2, tol=1e-5, max_iter=500, n_init=10,

# 如何修复？
weights_init = np.asarray([0.7, 0.3]),
means_init = np.asarray([0, 0]).reshape(-1, 1)

)
gmm.fit(sample)

# 结果
print(&quot;Fitted means: &quot;, gmm.means_.flatten())
print(&quot;Fitted variances:&quot;, gmm.covariances_.flatten())
print(&quot;拟合权重：&quot;, gmm.weights_)
]]></description>
      <guid>https://stats.stackexchange.com/questions/660987/how-to-fixate-weights-and-means-for-gaussian-mixture-fitting</guid>
      <pubDate>Wed, 05 Feb 2025 11:31:41 GMT</pubDate>
    </item>
    <item>
      <title>经历结果的人的事件发生时间中位数</title>
      <link>https://stats.stackexchange.com/questions/660986/median-time-to-event-in-those-who-experienced-the-outcome</link>
      <description><![CDATA[我正在研究研究人群中相对罕见的结果。 A 组的发病率为每年每 1000 人 26 例，B 组的发病率为每年每 1000 人 10 例。由于不到 50% 的人口经历了这种结果，因此中位生存时间未定义。
(fit &lt;- survfit(Surv(time, status) ~ x, d))
# 调用：survfit(formula = Surv(time, status) ~ x, data = d)
# 
# n 事件中位数 0.95LCL 0.95UCL
# x=A 868934 41822 NA NA NA
# x=B 249722 4886 NA NA NA

plot(
fit,
col = 2:3,
xscale = 365.25 / 12,
yscale = 100,
fun = &quot;event&quot;,
xlab = &quot;自进入队列以来的时间（月）&quot;,
ylab = &quot;累积事件概率（％）&quot;
)
legend(
&quot;topleft&quot;,
legend = levels(d$x),
col = 2:3,
lty = 1,
bty = &quot;n&quot;
)


一个重要的结果是，对于经历结果的人来说，A 组中有一半的人在随访的前 6 个月内发生了结果，B 组中有一半的人在随访的前 9 个月内发生了结果。
tapply(d[d$status == 1, &quot;time&quot;] / 365.25 * 12, d[d$status == 1, &quot;x&quot;], median)
# A B 
# 6.373717 8.788501

是否有特定术语来指代此事件发生时间？例如，经历过该结果的人的事件发生时间中位数？我在文献中找不到术语。]]></description>
      <guid>https://stats.stackexchange.com/questions/660986/median-time-to-event-in-those-who-experienced-the-outcome</guid>
      <pubDate>Wed, 05 Feb 2025 11:29:20 GMT</pubDate>
    </item>
    <item>
      <title>面板大小和固定效应</title>
      <link>https://stats.stackexchange.com/questions/660985/panel-size-and-fixed-effects</link>
      <description><![CDATA[背景
亲爱的 CV-Community，受 Shugart 等人 (2021) 的启发，我探讨了一个政党将其立法者分配到立法机构中三种不同类型的委员会。我假设政党是效用最大化的，因此根据个人特征和委员会属性系统地将立法者与委员会匹配。为简单起见，我假设立法者的性别以及她/他是来自农村还是城市地区会影响被分配到这三种委员会类型的概率。
数据
我的数据集涵盖四个立法任期（即，我有面板数据，一些立法者退出，其他立法者留在四个不同的测量点）。



任期
ID
选择
性别
城市




1
1
嗨
男性
城市


2
1
嗨
男性
城市


3
1
BA
男性
城市


4
1
DT
男性
城市


1
2
BA
女性
农村


2
2
BA
女性
农村


3
2
DT
女性
农村


4
2
DT
女性
农村



统计方法
我使用 R 中的多项逻辑回归（特别是 mlogit 包）对此进行建模。汇集的数据被转换为 dfidx，如插图所示。我估计了以下模型：
mod1 &lt;- mlogit(choice ~ 0 | urban + gender, data = mlogit.data.mod1)
随后，我根据假定的数据生成过程按立法任期对标准误差进行聚类。
mod1_cl &lt;- coeftest(mod1, vcov = vcovCL(mod1, cluster = data.mod1$term))
问题
然而，这个特定的立法机构的规模显著增加（在四个任期内几乎翻了一番）——该党的立法者人数也一直保持着类似的席位份额。因此，在我的汇总数据集中，我对后续任期有了更多的观察。我现在担心最新术语中的特质对我的整体估计产生了不成比例的影响。
问题
因此，我的问题是：我可以通过包括术语固定效应来解释面板大小的增加吗？
mod1 &lt;- mlogit(choice ~ 0 | urban + gender + factor(term), data = mlogit.data.mod1)
非常感谢任何帮助或反馈 - 提前谢谢您！

MacBookPro Apple M1 上的 R 版本 4.4.2（2024-10-31）]]></description>
      <guid>https://stats.stackexchange.com/questions/660985/panel-size-and-fixed-effects</guid>
      <pubDate>Wed, 05 Feb 2025 11:07:26 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型的证据下限</title>
      <link>https://stats.stackexchange.com/questions/660984/evidence-lower-bound-for-diffusion-models</link>
      <description><![CDATA[在这篇论文第 13 页的公式 (21) 中，它将 ELOB 重写为可计算项。从定义开始，
$$
L = \mathbb{E}_q \left[ - \log \frac{p_{\theta}(x_{0:T})}{q(x_{1:T} | x_0)} \right]，
\tag{17}
$$
它将其展开并重写为
$$
L = \mathbb{E}_q \left[ - \log \frac{p(x_T)}{q(x_T | x_0)} - \sum_{t &gt; 1} \log \frac{p_{\theta}(x_{t-1} | x_t)}{q(x_{t-1} | x_t, x_0)} - \log p_{\theta}(x_0 | x_1) \right].
\tag{21}
$$
到目前为止我都明白了。然而，最后一步是我们用 KL 散度重写 $L$，这让我感到困惑
$$
L = \mathbb{E}_q \left[ D_{KL} (q(x_T | x_0) \parallel p(x_T)) + \sum_{t &gt; 1} D_{KL} (q(x_{t-1} | x_t, x_0) \parallel p_{\theta}(x_{t-1} | x_t)) - \log p_{\theta}(x_0 | x_1) \right].
\tag{22}
$$
我不明白外部期望 $\mathbb{E}_q$ 从何而来。当我进行计算时，我只得到
$$
D_{KL} (q(x_T | x_0) \parallel p(x_T)) + \sum_{t &gt; 1} D_{KL} (q(x_{t-1} | x_t, x_0) \parallel p_{\theta}(x_{t-1} | x_t)) - \mathbb{E}_q [\log p_{\theta}(x_0 | x_1)]
$$
来自 $(21)$。如能得到任何帮助，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660984/evidence-lower-bound-for-diffusion-models</guid>
      <pubDate>Wed, 05 Feb 2025 10:56:36 GMT</pubDate>
    </item>
    <item>
      <title>Benjamini-Hochberg 校正跨子组进行多重检验：适用于所有层内还是跨所有层？</title>
      <link>https://stats.stackexchange.com/questions/660983/benjamini-hochberg-correction-for-multiple-testing-across-subgroups-apply-withi</link>
      <description><![CDATA[我正在对三个不同亚组（例如年轻人、中年人和老年人）中的约 3,000 种蛋白质（因变量）进行蛋白质组范围的研究。为了将错误发现率 (FDR) 控制在 5%，应该如何应用 Benjamini-Hochberg 程序？
是否应该在每个亚组中分别进行 FDR 校正（每组约 3,000 次假设检验）？
还是应该将其应用于所有亚组（总共约 9,000 次假设检验）？
如果能解释这些方法背后的理论考虑，以及任何相关参考资料，我将不胜感激。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660983/benjamini-hochberg-correction-for-multiple-testing-across-subgroups-apply-withi</guid>
      <pubDate>Wed, 05 Feb 2025 10:10:17 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 lavaan R 提高具有复合变量的 SEM 模型的模型拟合度？</title>
      <link>https://stats.stackexchange.com/questions/660982/how-to-improve-model-fit-of-sem-model-with-composite-variables-using-lavaan-r</link>
      <description><![CDATA[我正在尝试构建一个 SEM 来了解一系列环境变量与景观中“稳定性”之间的因果关系。稳定性是使用植被指数的趋势分析计算得出的。环境变量包括气候变量、区域的异质性、因火灾而烧毁的区域百分比、区域与最近人类土地利用的距离（人类土地利用压力的代理）以及地下水位深度。首先，我在 Powerpoint 中清楚地画出了所有的关系，见下图。

我想构建两个复合变量 - 来自两个长期季节性指标和长期年温度的背景气候条件以及来自两个干旱和热浪指标的气候脉冲压力源。我遵循了这篇文章和这篇文章中关于如何设置复合变量的建议。请注意，这两个链接是关于设置复合变量的不同博客文章/资源。
我的模型是
comp_trial1&lt;- &#39;
#Climate composite variable
backgroundclimate_composite &lt;~ 1*longterm_rainfallseasonality + mean_annual_temp
backgroundclimate_composite ~~ 0*backgroundclimate_composite
pulse_stressors &lt;~ 1*droughtindex + heatwave
pulse_stressors ~~ 0*pulse_stressors

#regression
stable_area ~ 1*backgroundclimate_composite + 1*pulse_stressors + water_depth + pixel_hetero + anthropic_dist + burnedarea
ndvi_stability ~~ 1*ndvi_stability

#remaining relationships
pulse_stressors ~ backgroundclimate_composite
biodiversity ~ pulse_stressors + backgroundclimate_composite + anthropic_dist
burnedarea ~ pulse_stressors + backgroundclimate_composite
heatwave ~~ mat #covariance related
&#39;

使用 lavaan google 群组的此帖子，在主回归公式中，我将两个气候复合变量的载荷设置为彼此相等（且等于 1）。如果我只包括两个气候复合变量而没有相等的载荷，那么 lavaan 模型就会失败。第一个问题 - 为什么模型会失败，为什么我需要使用相等的载荷？
因此，我的样本量为 3700，所有数据都是连续的和非正态的，请参见下面的变量之间的分布和相关性图。
还要注意，由于所有变量的单位不可比较，我将数据缩放到以每个变量的平均值为中心。考虑到非正态分布，我使用 Satorra Bentler 测试的引导法运行 sem 模型

 modeltrial1&lt;- sem(comp_trial1, scaled_analyses_ndvistability, se= &quot;boot&quot;, test = &quot;Satorra.Bentler&quot;, bootstrap = 1000, fixed.x= F)
summary(modeltrial1, standardize = T, fit.measures = TRUE)

模型运行，但模型拟合统计数据非常糟糕，请参见下面的结果图。 第二个问题 - 我的模型出了什么问题，以至于校正后的卡方、CFI、TLI 和 RMSEA 的检验统计量如此糟糕？我该如何提高模型适应度？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660982/how-to-improve-model-fit-of-sem-model-with-composite-variables-using-lavaan-r</guid>
      <pubDate>Wed, 05 Feb 2025 09:54:43 GMT</pubDate>
    </item>
    <item>
      <title>适合小样本量的对称高斯混合？</title>
      <link>https://stats.stackexchange.com/questions/660979/fit-symmetrical-gaussian-mixture-with-small-sample-size</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660979/fit-symmetrical-gaussian-mixture-with-small-sample-size</guid>
      <pubDate>Wed, 05 Feb 2025 07:11:11 GMT</pubDate>
    </item>
    <item>
      <title>回归可以应用于网络吗？</title>
      <link>https://stats.stackexchange.com/questions/660977/can-regression-be-applied-to-networks</link>
      <description><![CDATA[我有一个如下所示的图形网络。没有新节点可以出现，也没有现有节点可以消失。此外，不会出现新的边，也不会消失现有的边：

此网络中的每个节点都有在不同时间记录的多个测量值，例如
 node subgraph total_nodes_in_subgraph first_degree_neighbors number_of_first_neighbors time y x1
1 A 3 2,3 1 1 26.788488 -0.06136412
1 A 3 2,3 1 4 10.834021 -6.20129015
1 A 3 2,3 1 9 1.555070 5.76456306
2 A 3 1,3 1 1 4.171894 1.71324788
2 A 3 1,3 1 10 14.494354 11.93502071
3 A 3 1,2 2 1 7.002672 6.68514794

在这种情况下，是否有可能在此图网络结构上拟合随机效应回归模型？
我尝试编写模型，其中节点 $i$ 在时间 $t$ 的响应受到其一度邻居、同一子图中的邻居和其他网络的影响属性：
$$ y_{it} = \beta_0 + \beta_1x_{it} + \beta_2N_i + \beta_3S_​​i + \beta_4t + \beta_5\left(\frac{1}{N_i}\sum_{j \in \mathcal{N}i} x{jt}\right) + u_i + c_{ij} + v_g + w_t + \epsilon_{it} $$
其中：

$y_{it}$ 是节点 $i$ 在时间 $t$ 的结果

$\beta_0$ 是截距项

$x_{it}$ 表示随时间变化的预测变量，其系数为 $\beta_1$

$N_i$ 是一级邻居的数量，其系数为 $\beta_2$

$S_i$ 是子图中的总节点数，其系数为 $\beta_3$

$t$ 是时间变量，其系数为 $\beta_4$

$\mathcal{N}_i$ 表示与节点 i 相邻的节点集

$\frac{1}{N_i}\sum_{j \in \mathcal{N}i} x{jt}$ 是来自相邻节点的协变量值的平均值

$\beta_5$ 测量邻居的协变量对节点 i 响应的影响程度

$u_i$ 是节点特定的随机效应，其中 $u_i \sim N(0, \sigma^2_u)$

$c_{ij}$ 是节点 $i$ 和 $j$ 之间连接的随机效应，其中 $c_{ij} \sim N(0, \sigma^2_c)$

$v_g$ 是子图特定的随机效应，其中 $v_g \sim N(0, \sigma^2_v)$

$w_t$ 是时间特定的随机效果，其中 $w_t \sim N(0, \sigma^2_w)$

$\epsilon_{it}$ 是误差项，其中 $\epsilon_{it} \sim N(0, \sigma^2_\epsilon)$


这是将回归应用于图网络的合适方法吗？
结束语：

当取节点 $i$ 的邻居的平均协变量信息时，由于可以在不同时间测量节点，我正在考虑使用 $i$ 邻居的协变量信息，此时测量节点 $i$ 之前最近一次被测量的时间
]]></description>
      <guid>https://stats.stackexchange.com/questions/660977/can-regression-be-applied-to-networks</guid>
      <pubDate>Wed, 05 Feb 2025 03:29:59 GMT</pubDate>
    </item>
    <item>
      <title>如何匹配均值、方差和偏度</title>
      <link>https://stats.stackexchange.com/questions/660974/how-to-do-matching-on-mean-variance-and-skewness</link>
      <description><![CDATA[我正在分析一项政策对结果 y 的影响。但是，混杂因素 x 也可能影响 y，并在治疗组和对照组中显示出不同的模式。
在对 y 运行组虚拟变量回归之前，我试图执行匹配方法来平衡治疗组和对照组。
我应该如何设置匹配以在混杂因素 x 的均值、方差和偏度上创建相似的治疗组和对照组？
数据看起来像
library(ggplot2)
library(sn)
set.seed(1)
x1 &lt;- rsn(n = 1000, xi = 3, omega = 3, alpha = 5) 
x2 &lt;- rsn(n = 1000, xi = 2, omega = 2, alpha = 0) 
df &lt;- data.frame(
x = c(x1, x2),
y = rnorm(2000),
group = rep(c(&quot;treated&quot;, &quot;control&quot;), each = 1000)
)
ggplot(df, aes(x = x, fill = group)) +
geom_density(alpha = 0.5) +
theme_minimal() 


提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/660974/how-to-do-matching-on-mean-variance-and-skewness</guid>
      <pubDate>Wed, 05 Feb 2025 00:00:03 GMT</pubDate>
    </item>
    <item>
      <title>AR 流程偏差和其他问题</title>
      <link>https://stats.stackexchange.com/questions/660965/ar-process-skew-and-other-moments</link>
      <description><![CDATA[我读过这篇文章：分析 ACF 和 PACF 图，评论中指出数据有左偏，这是 AR 过程的问题。
我想知道为什么这是一个问题，以及在时间序列上执行 ACF 图并得出该时间序列具有统计意义的自回归结论的一般条件是什么。
我的猜测是，偏斜意味着您有更多机会在分布的左侧拥有数据，因此您可能会发现虚假相关性？因为数据更有可能位于分布的同一侧，而如果偏斜为 0，情况就不是这样。
所以我的猜测是我们不希望时间序列的分布有任何不对称。因此，我会直观地说，要执行 AR 分析，以便我们可以以一定的统计意义说该过程是 AR，我们需要始终：$E[X^n]$ 当 $n$ 为奇数时等于 $0$。我的直觉正确吗？如果是，有办法证明吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660965/ar-process-skew-and-other-moments</guid>
      <pubDate>Tue, 04 Feb 2025 19:37:09 GMT</pubDate>
    </item>
    </channel>
</rss>