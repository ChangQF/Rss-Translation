<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 25 Sep 2024 15:18:43 GMT</lastBuildDate>
    <item>
      <title>应该用置信区间还是 t 检验来评估统计显著性？</title>
      <link>https://stats.stackexchange.com/questions/654897/should-one-assess-statistically-significance-with-confidence-intervals-or-a-t-te</link>
      <description><![CDATA[我对评估温差的统计显著性感兴趣。
为了这个目标，我生成了历史和未来时期的平均值的引导时间序列。
然后我遵循了两种方法：
A. 计算引导差异的 95% 置信区间，并认为零不在置信区间内的区域具有统计显著性。
B. 使用历史和未来引导均值之间的配对 t 检验 (scipy.stats.ttest_rel) 来计算 p 值，并认为 p 值低于 .05 的区域具有统计显著性
以下哪个选项是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/654897/should-one-assess-statistically-significance-with-confidence-intervals-or-a-t-te</guid>
      <pubDate>Wed, 25 Sep 2024 15:15:05 GMT</pubDate>
    </item>
    <item>
      <title>球体上的采样角度：从广义协方差矩阵到浓度参数</title>
      <link>https://stats.stackexchange.com/questions/654893/sampling-angles-on-a-sphere-from-a-general-covariance-matrix-to-concentration-p</link>
      <description><![CDATA[我正在尝试使用 Python 提取球体上的点。
我必须在天空中定位事件并使用 healpy 生成地图。
在测试期间，我使用了 von Mises-Fisher，因为我假设 $\theta$ 的方差与 $\phi$ 的方差相同。一切运行良好，我能够通过使用 $\kappa=1/\sigma^2$ 获得浓度参数 $\kappa$。
我用于评估像素中概率的函数是
def Mises_Fisher(theta,phi,DS_theta,DS_phi,conc):
meanvec=hp.ang2vec(DS_theta,DS_phi)
meanvec=np.asarray(meanvec,dtype=np.float128)
norm=np.sqrt(np.dot(meanvec,meanvec))
meanvec=meanvec/norm

var=hp.ang2vec(theta,phi)
var=np.asarray(var,dtype=np.float128)
norm=np.sqrt(np.dot(var,var))
var=var/norm

factor=np.dot(conc*var,meanvec)
factor=np.float128(factor)
#归一化是徒劳的，我们将除以总和
#fullnorm=conc/(2*np.pi*(np.exp(conc)-np.exp(-conc)))
ret=np.float128(np.exp(factor))#/fullnorm
#ret=factor
return ret

然后，对于 healpy 图中的每个像素，我可以分配一个概率。
现在我有一个不再各向同性的协方差矩阵，在这种情况下，我如何在球体上生成点？我知道Kent 分布的存在，但我没有所需的数量，例如$\gamma$、$\beta$ 和 $\kappa$。我不知道是否有办法根据协方差矩阵获得这些。
为了进一步复杂化问题，矩阵是 11 维的，但我只需要投影到 (distance,$\theta$,$\phi$) 空间，然后生成地图。
现在我尝试从多元高斯中提取，但由于高斯在切平面上，对于某些方差，分布产生的角度超出了 $\theta$ 和 $\phi$ 的范围。
这是我用来提取点的代码
num_samples = 10**7
samples = np.random.multivariate_normal(perm_mean, perm_cov, num_samples)

phi = samples[:, 2]
theta = samples[:, 1]
print(np.min(theta),np.max(theta))
print(np.min(phi),np.max(phi))
print(&#39;starting mean values&#39;)
print(&#39;theta={}, phi={}&#39;.format(perm_mean[1],perm_mean[2]))

关键是，对于某些矩阵，方差使得角度可以超出范围。我无法对矩阵采取行动，这些矩阵是由其他一些代码提供给我的，应被视为固定数据。
提前感谢大家！
*编辑
在这里我澄清一下，使我的陈述更加严格。
因此，矩阵是另一段代码给我的协方差矩阵，我无法更改。我必须评估引力波 (GW) 事件的天空定位。在我的例子中，这意味着将包括天空位置在内的 11 个参数提供给程序，并且此代码会返回一个协方差矩阵。对于这个问题的范围，该程序可以被视为一个黑匣子，因为我无法修改那里的任何东西。
现在我可以从这个矩阵中采样并获得 $\theta$ 和 $\phi$，即天空位置。
让我们以单位球体为中心，表面上的每个点都由指向引力波事件天空坐标的向量标识。我们现在可以忘记其他参数。
如果事件定位良好，这意味着如果角度的变化“很小”，我们可以想象建立一个与天空相切的平面，法向量沿径向，从引力波位置开始。现在，如果我们对高斯分布进行采样，该分布的参数为 $\mu$ 和 $\Sigma$，其中 $\mu$ 为 11 个起始参数给出的均值向量，$\Sigma$ 为 cov 矩阵，我们可以获得 $\theta$ 和 $\phi$ 的样本。这种方法效果很好，但是一旦方差足够大，我们开始“感觉”我们在球体上而不是在平面上，这种方法就会失效。解决这个问题的分布是 Kent 分布。我的问题是
给定一个均值向量$\mu$和一个协方差矩阵$\Sigma$，是否可以构造肯特分布中所需的必要量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654893/sampling-angles-on-a-sphere-from-a-general-covariance-matrix-to-concentration-p</guid>
      <pubDate>Wed, 25 Sep 2024 13:00:09 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证不起作用</title>
      <link>https://stats.stackexchange.com/questions/654892/cross-validation-doesnt-work</link>
      <description><![CDATA[我目前在当地大学听一场数据科学演讲。我们是从工作单位来的，我从事 DS/ML 工作，已经 7 年了，但我的学位是计算机科学，因此我在 DS/ML 方面主要是自学的。
这个人告诉我们，DS 文章中写到的很多东西实际上都不起作用。
例如，他提到精确度、召回率和 F1 分数很少使用（相反，他更喜欢 AUC）。
但对我来说，另一个更古怪的事情是，交叉验证也不应该用于业务问题。他解释说它不起作用，因为它不代表现实生活。在现实生活中，你的目标不是预测数据分布中的随机样本，而是必须根据过去 x 年建立一个模型来预测未来 y 个月的数据。
所以他说交叉验证基本上是无用的，应该使用前向优化。
首先，它是如何工作的？它只用于验证还是也可以用于优化？怎么做？
此外，CV 真的那么没用吗？这是我读过的关于 DS 的任何文章中最被接受的验证形式。但也许这是我自学知识的不足之处。
还有什么关于很多事情的“神话”更高大上，但在现实生活中却不起作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/654892/cross-validation-doesnt-work</guid>
      <pubDate>Wed, 25 Sep 2024 12:55:02 GMT</pubDate>
    </item>
    <item>
      <title>估计低人口规模的误差幅度</title>
      <link>https://stats.stackexchange.com/questions/654891/estimating-margin-of-error-with-low-population-sizes</link>
      <description><![CDATA[我协助举办一个小型的定期活动，随后对部分贸易参与者进行调查，以评估他们的体验，并尝试改进未来活动的体验。到目前为止，响应率约为 40%，而预计响应人数不会超过 100 人，目前约为 50 人。我的一些问题的答案可能是“差”、“一般”或“好”，这些答案的比例显然可以逐一跟踪。
鉴于存在一些混杂因素，这些因素可能会使响应人群与总体人群存在重大差异，是否可以通过数字判断答案比率随时间的变化是否显著？我可以假设这些回答在一定程度上具有代表性，但使用 Z 值的标准 MoE 计算器似乎假设了无限的人口或至少比样本量大几个数量级的人口，而这里的情况并非如此。
目前我有一个加权分数，如下所示：
((A x 1)+(B x 0.5)+(C x -1))/n，其中：
A =“良好”回答
B =“平均”回答
C =“较差”回答
n = 总回答
这给了我一个介于 -1 和 1 之间的总分，可以随时间进行跟踪。有没有办法计算或估计这个分数的误差幅度？还是我只是目测？我的样本数字是否在任何情况下都使收集这些数据毫无意义？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654891/estimating-margin-of-error-with-low-population-sizes</guid>
      <pubDate>Wed, 25 Sep 2024 12:24:31 GMT</pubDate>
    </item>
    <item>
      <title>如何在单个 mids 对象中合并多重插补的并行处理结果？[已迁移]</title>
      <link>https://stats.stackexchange.com/questions/654890/how-can-i-combine-the-results-of-parallel-processing-of-multiple-imputation-in-a</link>
      <description><![CDATA[我一直在尝试使用 miceadds 进行多重插补（我使用 2l.pmm 方法，但 mice 中没有该方法）。这是并行处理的代码：
library(foreach)
library(doParallel)
library(miceadds)

# 设置并行后端
num_cores &lt;- 30
cl &lt;- makeCluster(num_cores)
registerDoParallel(cl)

# 定义插补函数
impute_function &lt;- function(data, pred_matrix, method, seed) {
set.seed(569)
mice::mice(
data,
method = &quot;2l.pmm&quot;,
predictorMatrix = pred,
maxit = 2,
seed = seed
)
}

num_imputations &lt;- 5
seeds &lt;- 1:num_imputations

# 并行运行插补
imputations &lt;- foreach(seed = seeds, .combine = &#39;c&#39;, .packages = &#39;miceadds&#39;) %dopar% {
impute_function(data, pred_matrix, method = &quot;2l.pmm&quot;, seed = seed)
}

# 停止集群
stopCluster(cl)

对象 imputations 是一个包含每次迭代的列表。
我如何将这些迭代组合成一个像函数这样的单个 mids 对象
mice(data, method=&quot;2l.pmm&quot;, predictorMatrix = pred, maxit = 2, seed = 569)

会给出什么结果？
P.S 我尝试使用函数 futuremice，但无法将其与 miceadds 中的 2l.pmm 方法一起使用。如果您知道这样做的方法，我想会更好。]]></description>
      <guid>https://stats.stackexchange.com/questions/654890/how-can-i-combine-the-results-of-parallel-processing-of-multiple-imputation-in-a</guid>
      <pubDate>Wed, 25 Sep 2024 12:20:59 GMT</pubDate>
    </item>
    <item>
      <title>一般时间序列模型估计量的渐近性质</title>
      <link>https://stats.stackexchange.com/questions/654889/asymptotic-properties-of-estimators-for-general-time-series-model</link>
      <description><![CDATA[我的问题涉及时间序列分析中估计量的渐近性质。特别是，我对时间序列（不是 ARMA 时间序列）的估计量的行为感兴趣。因此，让 $(Y_t)_{t \in I \subset \mathbb{N}}$ 成为单变量时间序列。我们可以假设时间序列遵循以下形式的更新方程：
$Y_t = g(Y_{t-1}, ..., Y_{t-p}, f(\epsilon_{t-1}, ..., \epsilon_{t-q}), \epsilon_t)$
其中 $\epsilon_t$ 是 $iid$ 创新，其中 $\epsilon_t \sim (0, \sigma^2)$。 $f(\epsilon_{t-1}, ..., \epsilon_{t-q})$ 是某种类似于移动平均的部分，用于使时间序列具有衰减的自相关性（而不是截止）。$g$ 是处理自相关的函数。请注意，对于特殊选择，其中 $g$ 和 $f$ 是线性函数，我们得到经典的 ARMA 模型。我们可以假设 $g$ 由参数 $\phi$ 参数化，而 $f$ 由参数 $\theta$ 参数化。我感兴趣的是足以满足 $\phi$ 和 $\theta$ 的 MLE 估计量的一致性和渐近正态性的条件。在几篇论文中（对函数 $g$ 和 $f$ 做出特殊选择），我遇到了平稳性和混合条件。但是，我想知道这些条件是否足以满足我在此处给出的相当通用的模型。
任何有关论文/书籍/网站等的提示都将不胜感激。当然，直接回答也很好 :D。]]></description>
      <guid>https://stats.stackexchange.com/questions/654889/asymptotic-properties-of-estimators-for-general-time-series-model</guid>
      <pubDate>Wed, 25 Sep 2024 11:55:48 GMT</pubDate>
    </item>
    <item>
      <title>当零过多时使用零膨胀 GlMM</title>
      <link>https://stats.stackexchange.com/questions/654883/using-zero-inflated-glmm-when-you-have-too-many-zeros</link>
      <description><![CDATA[我试图使用广义线性混合模型来了解几个预测因子（n=8）对物种存在与否的影响。不幸的是，我没有很好的数据。我有 13000 个点，其中 300 个为 1（存在），其余为 0（不存在）。在遇到收敛和高特征值问题后，我现在认为问题出在我的数据上，具体来说，就是 0 太多了。我想知道使用零膨胀模型是否可以解决这些问题。
发布 GlmmTMB 后，我使用 delta AIC 进行模型选择以选择最佳模型。
下面是我的代码：
SP1 &lt;- cbind(Data_scaled, 
SP1 = Data$SP1, 
Dist_ID = Data$Dist_ID) 

set.seed(123)

SP1_Final &lt;- SP1 %&gt;% dplyr::select(ProtectedAreas, TRI, 
Water, Perc_NR, Perc_TB, Settlements, Precipitation, 
HMI, SP1, Dist_ID)

SP1_ZIGLMM &lt;- glmmTMB(SP1 ~ ProtectedAreas + TDF + Water + Perc_NR +
Settlements + TRI+ Perc_TB + Precipitation + (1 | Dist_ID), 
data = SP1_Final, family = binomial, 
ziformula = ~ 1, 
na.action = na.fail,# 零膨胀模型（仅截距模型）
control = glmmTMBControl(optimizer = &quot;nlminb&quot;, # 已更改优化器
optCtrl = list(iter.max = 100000)))
summary(SP1_ZIGLMM)
SP1model_set_sample &lt;- dredge(SP1_ZIGLMM)
print(SP1model_set_sample)
]]></description>
      <guid>https://stats.stackexchange.com/questions/654883/using-zero-inflated-glmm-when-you-have-too-many-zeros</guid>
      <pubDate>Wed, 25 Sep 2024 10:16:22 GMT</pubDate>
    </item>
    <item>
      <title>如何从重复的 nestcv.glmnet() 中获取系数[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654882/how-to-get-coefficients-from-repeated-nestcv-glmnet</link>
      <description><![CDATA[我一直在使用 nestedcv 包，使用 nestcv.glmnet() 函数运行嵌套交叉验证的逻辑回归。它效果很好，使程序非常简单。为了获得更准确的预测，我使用“repeatcv(n, rep.cores = n)”术语重复该过程几次。
完成此操作后，我可以使用以下命令轻松访问每次运行中每个观察值的预测类成员资格：

model$output

但是，还想访问每次运行的独立变量的系数。对于单个模型，您只需使用：

model$final_coef

但这不是重复模型的选项。我想知道是否有办法访问它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/654882/how-to-get-coefficients-from-repeated-nestcv-glmnet</guid>
      <pubDate>Wed, 25 Sep 2024 10:13:35 GMT</pubDate>
    </item>
    <item>
      <title>二项分布中中位数和众数有什么关系</title>
      <link>https://stats.stackexchange.com/questions/654894/whats-the-relationship-of-median-and-mode-in-binomial-distribution</link>
      <description><![CDATA[假设$X\sim B(30,\frac{1}{3})$。
可以说中位数是$15$。
如果我们要找出$\Pr(X\gt15)$和$\Pr(X\lt15)$哪个值更大，众数大于中位数（右偏）是否表示$\Pr(X\gt15)$值更大，反之亦然。
这个逻辑正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654894/whats-the-relationship-of-median-and-mode-in-binomial-distribution</guid>
      <pubDate>Wed, 25 Sep 2024 10:08:04 GMT</pubDate>
    </item>
    <item>
      <title>信用风险神经网络：召回率、准确度还是精确度？[重复]</title>
      <link>https://stats.stackexchange.com/questions/654880/credit-risk-neural-networks-recall-accuracy-or-precision</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654880/credit-risk-neural-networks-recall-accuracy-or-precision</guid>
      <pubDate>Wed, 25 Sep 2024 07:34:50 GMT</pubDate>
    </item>
    <item>
      <title>使用缺失值的 Wilcoxon 符号秩检验</title>
      <link>https://stats.stackexchange.com/questions/654879/using-wilcoxon-signed-rank-test-with-a-missing-value</link>
      <description><![CDATA[我正在研究一个问题，我应该使用 Wilcoxon 符号秩检验，$9$ 个元素。第九对中的一个值缺失，我只知道它的结果为负数。我应该如何处理该值？我在网上找到了信息，“如果数据范围内有缺失值，则整个对将被排除在分析之外”，但在符号检验的情况下，我知道如果我们不知道最后一个条目但知道它的秩，我们仍然可以使用它。但在这种情况下，我们有配对结果，所以我不确定。我应该手动完成计算，而不是使用 R。
差异如下：$−7$, $−15$, $−1$, $−17$, $−10$, $−5$, $+11$, $−6$, $X_{9}&lt;0$。
我的猜测是，我可以将其省略，因为它是负数，并且与大多数 $X_{i}$ 值没有什么不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/654879/using-wilcoxon-signed-rank-test-with-a-missing-value</guid>
      <pubDate>Wed, 25 Sep 2024 07:34:40 GMT</pubDate>
    </item>
    <item>
      <title>是否可以选择置信区间的下限（或上限）作为参数而不是中心值？</title>
      <link>https://stats.stackexchange.com/questions/654878/can-the-lower-or-upper-for-that-matter-limit-of-a-confidence-interval-be-chos</link>
      <description><![CDATA[为了在一项关于政策干预措施的研究中创建一个反事实测量，以减少室外温度对晚年死亡率的影响，我想使用通过回归模型获得的置信区间的下限 - 与点估计相比，它们更能反映我感兴趣的“假设”问题。
但是，我从未遇到过这样使用置信区间的界限。理论上，置信区间内的任何参数值都具有相同的概率，我的直觉是这样做没问题，但我想知道在进一步分析中选择参数置信区间的极限之一是否存在任何统计复杂性。]]></description>
      <guid>https://stats.stackexchange.com/questions/654878/can-the-lower-or-upper-for-that-matter-limit-of-a-confidence-interval-be-chos</guid>
      <pubDate>Wed, 25 Sep 2024 06:30:01 GMT</pubDate>
    </item>
    <item>
      <title>检验统计量适中，但 F 检验的 p 值较低</title>
      <link>https://stats.stackexchange.com/questions/654854/moderate-test-statistic-but-low-p-value-in-an-f-test</link>
      <description><![CDATA[我正在 R 中对模拟数据运行多元回归。样本大小为 100。有一个相关回归量和 18 个不相关回归量。我正在使用 Newey-West 协方差矩阵测试 18 个不相关回归量的联合显著性。
谜题 1：我发现 18 个不相关回归量具有高度统计显著性。
谜题 2：我在 18 自由度下获得了 6.8814 的检验统计量，这对我来说似乎是适中的（在 F(18, 80) 分布的右尾不远），那么这怎么会产生非常低的 p 值 4.5e-10？
我能够解决谜题 1。显然，Newey-West 是问题所在。使用 vanilla 协方差矩阵，结果更加合理。但是，我仍然对谜题 2感到困惑，而这是我的问题。
library(car)
library(sandwich)

m &lt;- 20
n &lt;- 100
set.seed(9999)
x &lt;- rnorm(m * n)
X &lt;- matrix(x, ncol = m)
X[, 2] &lt;- X[, 1] + X[, 2]
# 现在，第二列是第一列 + 一些噪音，
# 而所有其他列都是纯噪音。
# 因此，如果我们尝试预测第一列，那么只有第二列应该有用。
m1 &lt;- lm(X[, 1] ~ X[, -1])
(test &lt;- linearHypothesis(
model = m1,
hypothesis.matrix = (diag(m)[-c(1:2), ]),
rhs = rep(0, m - 2),
test = &quot;F&quot;,
vcov. = NeweyWest(m1)
))

结果：
线性假设检验

假设：

模型 1：受限模型

模型 2：X[, 1] ~ X[, -1]

注意：提供系数协方差矩阵。

Res.Df Df F Pr(&gt;F) 
1 98 
2 80 18 6.8814 4.494e-10 ***

不使用 Newey-West：

(test &lt;- linearHypothesis(
model = m1,
hypothesis.matrix = (diag(m)[-c(1:2), ]),
rhs = rep(0, m - 2),
test = &quot;F&quot;
))

结果：
线性假设检验

假设：

模型 1：受限模型
模型 2：X[, 1] ~ X[, -1]

Res.Df RSS Df Sq F 之和Pr(&gt;F)
1 98 38.856 
2 80 31.982 18 6.8739 0.9552 0.5178

编辑：感谢 Lukas Lohse 的精彩评论。当非正式地评估检验统计量的大小时，我考虑的是 $\chi^2$ 对 $F$ 分布的近似，但忘记了必须将 $F$ 值乘以分子自由度（此处为 18）才能得到相应的 $\chi^2$ 统计量... 好的，因此，我们现在有了新的 谜题 3，而不是 谜题 2：为什么使用 Newey-West 的检验使用 6.8 作为 $F$ 统计量，而使用普通方差估计量的检验使用平方和。]]></description>
      <guid>https://stats.stackexchange.com/questions/654854/moderate-test-statistic-but-low-p-value-in-an-f-test</guid>
      <pubDate>Tue, 24 Sep 2024 15:26:30 GMT</pubDate>
    </item>
    <item>
      <title>不同的起点（在生存分析中）</title>
      <link>https://stats.stackexchange.com/questions/654828/different-starting-point-in-survival-analysis</link>
      <description><![CDATA[我们正在进行一项研究，定期对患者进行癌症复发检测。每四个月安排一次检查（T0、T4、T8、T12、T16、T20）。
我的问题是这些患者的入组时间不同。第一位患者从 9 月开始，另一位患者从 11 月开始。即使患者的起点不同，我们是否仍可以使用具有固定（相同）间隔的离散时间模型？我们可以说下面的数据结构正确，可以代表我们的发现吗？
ID TIME EVENT GENDER 
1 T0 0 M 
1 T4 0 M 
1 T8 0 M 
1 T12 1 M 
2 T0 0 F 
2 T4 1 F 
3 T0 0 M 
3 T4 0 M 
3 T8 1 M 
4 T0 0 F 
4 T4 1 F 
]]></description>
      <guid>https://stats.stackexchange.com/questions/654828/different-starting-point-in-survival-analysis</guid>
      <pubDate>Tue, 24 Sep 2024 08:20:10 GMT</pubDate>
    </item>
    <item>
      <title>我们如何在 R 中计算一个数据集中的一个记录与第二个数据集中的所有记录之间的 Gower 距离？</title>
      <link>https://stats.stackexchange.com/questions/654811/how-do-we-calculate-the-gower-distance-between-one-record-in-one-dataset-and-all</link>
      <description><![CDATA[我想计算数据集 1 的一条记录与数据集 2 的所有记录之间的 Gower 距离。第一种方法如下
library(gower)

data(iris)
dat1 &lt;- iris[1:10,]
dat2 &lt;- iris[11:30,]

# 第一种方法
gower::gower_dist(dat1[1,], dat2)

这给了我长度为 20 的结果。
0.09079365 0.09873016 0.16142857 0.29476190 0.20920635 0.33079365 
0.21936508 0.05000000 0.23952381 0.11507937 0.12095238 0.15079365 
0.16984127 0.24523810 0.16539683 0.12920635 0.17206349 0.03555556 
0.02761905 0.14063492

我可以将第一个值解释为 dat1[1,] 和 dat2[1,] 之间的 gower 距离，将第二个值解释为 dat1[1,] 和 dat2[2,] 之间的 gower 距离，依此类推吗？
让我感到困惑的是，如果我计算
gower::gower_dist(dat1[1,],dat2[1,])

这给了我
0.75

这与 0.09079365 不同。最终，我想计算 dat1 中每个观测值与 dat2 中每个观测值的 Gower 距离。如果我使用第二种方法，我将需要在 dat2 中的所有观测值上添加一个 for 循环，如下所示。
# 第二种方法
for(i in 1:nrow(dat2)) {
print(gower::gower_dist(dat1[1,],dat2[i,]))
}

由于这两种方法给出的结果不同，我应该使用哪一种方法来实现目的？]]></description>
      <guid>https://stats.stackexchange.com/questions/654811/how-do-we-calculate-the-gower-distance-between-one-record-in-one-dataset-and-all</guid>
      <pubDate>Mon, 23 Sep 2024 17:37:36 GMT</pubDate>
    </item>
    </channel>
</rss>