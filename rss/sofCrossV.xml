<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 27 May 2024 21:14:24 GMT</lastBuildDate>
    <item>
      <title>即时选择唯一的访客</title>
      <link>https://stats.stackexchange.com/questions/648101/choosing-a-unique-visitor-on-the-fly</link>
      <description><![CDATA[我一直认为这是“本周的奖项”问题。假设您经营一家商店，并且希望每周向随机选择购买的人发放一次奖品。您在购买时发放奖品，但希望确保每周发放一份奖品。选择是否将奖品作为给定交易的一部分授予的最佳方式是什么？
作为第一个近似值，我可以以每周平均交易数 1 的概率随机选择。一旦颁发了奖品，直到新的一周开始我才能检查，一周内不得颁发超过一个奖品。
但这并不能解决没有人被选中的可能性。看来，到本周末，获奖的可能性应该会上升。我可以查找该发行版的名称以供进一步阅读吗？
我意识到这个问题没有完美的解决方案。通常周五很忙，但偶尔也会有午饭后没人进来的情况。我还在寻找有关如何对此进行建模并根据典型行为限制未能奖励的概率的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/648101/choosing-a-unique-visitor-on-the-fly</guid>
      <pubDate>Mon, 27 May 2024 20:49:08 GMT</pubDate>
    </item>
    <item>
      <title>情节应该是什么样的？</title>
      <link>https://stats.stackexchange.com/questions/648100/what-should-the-plot-look-like</link>
      <description><![CDATA[如果我绘制以下数据，该图实际上应该是什么样子？
残留计数密度 Tau0
10.00000000000000 0.00100000000000 20.45500000000000
10.00000000000000 0.00500000000000 20.56100000000000
10.00000000000000 0.01000000000000 20.47000000000000
10.00000000000000 0.05000000000000 12.00900000000000
10.00000000000000 0.10000000000000 2.87100000000000
10.00000000000000 0.50000000000000 0.56100000000000
15.00000000000000 0.00100000000000 52.31600000000000
15.00000000000000 0.00500000000000 51.71400000000000
15.00000000000000 0.01000000000000 51.79800000000000
15.00000000000000 0.05000000000000 13.90400000000000
15.00000000000000 0.10000000000000 4.02100000000000
15.00000000000000 0.50000000000000 0.62300000000000
25.00000000000000 0.00100000000000 154.67699999999999
25.00000000000000 0.00500000000000 159.32100000000000
25.00000000000000 0.01000000000000 150.49700000000001
25.00000000000000 0.05000000000000 20.88800000000000
25.00000000000000 0.10000000000000 9.05100000000000
25.00000000000000 0.50000000000000 0.81800000000000
35.00000000000000 0.00100000000000 320.11700000000002
35.00000000000000 0.00500000000000 319.95200000000000
35.00000000000000 0.01000000000000 274.41100000000000
35.00000000000000 0.05000000000000 31.19400000000000
35.00000000000000 0.10000000000000 14.48100000000000
35.00000000000000 0.50000000000000 1.13700000000000
50.00000000000000 0.00100000000000 668.97699999999998
50.00000000000000 0.00500000000000 614.91200000000003
50.00000000000000 0.01000000000000 415.28500000000003
50.00000000000000 0.05000000000000 48.31100000000000
50.00000000000000 0.10000000000000 23.13500000000000
50.00000000000000 0.50000000000000 2.01600000000000
75.00000000000000 0.00100000000000 1,404.40100000000010
75.00000000000000 0.00500000000000 910.11300000000006
75.00000000000000 0.01000000000000 471.95499999999998
75.00000000000000 0.05000000000000 77.83700000000000
75.00000000000000 0.10000000000000 38.08300000000000
75.00000000000000 0.50000000000000 6.05100000000000
100.00000000000000 0.00100000000000 2,271.11700000000020
100.00000000000000 0.00500000000000 1,036.93200000000000
100.00000000000000 0.01000000000000 520.51999999999998
100.00000000000000 0.05000000000000 109.75100000000000
100.00000000000000 0.10000000000000 53.53800000000000
100.00000000000000 0.50000000000000 13.86700000000000
150.00000000000000 0.00100000000000 3,810.31300000000010
150.00000000000000 0.00500000000000 1,120.37100000000010
150.00000000000000 0.01000000000000 667.46600000000001
150.00000000000000 0.05000000000000 175.28999999999999
150.00000000000000 0.10000000000000 84.73900000000000
150.00000000000000 0.50000000000000 26.74000000000000
200.00000000000000 0.00100000000000 4,940.75900000000000
200.00000000000000 0.00500000000000 1,215.74100000000000
200.00000000000000 0.01000000000000 771.80600000000004
200.00000000000000 0.05000000000000 233.23800000000000
200.00000000000000 0.10000000000000 119.22100000000000
200.00000000000000 0.50000000000000 39.39300000000000

当我使用编程绘制这些数据时，它显示以下图：

当我使用 OriginPro 绘制此数据时，它显示以下图：

当我使用 SYSTAT 绘制此数据时，它显示以下图：
]]></description>
      <guid>https://stats.stackexchange.com/questions/648100/what-should-the-plot-look-like</guid>
      <pubDate>Mon, 27 May 2024 20:42:45 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯线性回归中的非信息先验</title>
      <link>https://stats.stackexchange.com/questions/648098/non-informative-prior-in-bayesian-linear-regression</link>
      <description><![CDATA[已知在方差参数$\sigma^2$先验为$\text{Inv-}\Gamma(a_0, b_0)$的贝叶斯线性回归中，经过$n$个观测值$(X, Y)$后的后验分布为$f(\beta, \sigma^2\mid X, Y)=f(\beta\mid X, Y, \sigma^2)\cdot f(\sigma^2\mid X, Y)$。第二项是$\text{Inv-}\Gamma(a_1, b_1)$分布，其$a_1=a_0+\frac n 2$。
我正试图将其与另外两个事实相协调。第一个事实是，在标准线性回归（频率学派方法）中，估计量$\hat\beta=(X^TX)^{-1}X^TY$遵循$k$维多元$t$分布，以模型参数$\beta_0$为中心，具有$n-k$个自由度：
$t(k, \beta_0, (\hat{\sigma^2})(X^TX)^{-1}, n-k)$。第二个事实是，贝叶斯线性回归的非信息先验必须具有$a_0=b_0=0$，因此$\sigma^2$ 上的不当先验是 $f(\sigma^2)\propto \frac 1 \sigma^2$。
但是，取后验 $f(\beta, \sigma^2\mid X, Y)$，其中 $a_0=b_0=0$，并积分出 $\sigma^2$ 以获得边际分布 $\beta$，则得到 $t$-分布，其中 $n$-自由度。
$$\int_{\sigma^2} \frac{1}{\left(2\pi\sigma^2\right)^{k/2}\det\Sigma}\exp\left(-\frac{1}{2\sigma^2}(\beta-\mu_1)^T\Sigma^{-1}_{1}(\beta - \mu_1)\right)\cdot \frac{b_1^{a_1}}{\Gamma(a_1)}\frac{1}{(\sigma^2)^{n/2+1}}\exp\left(-\frac {b_1}{\sigma^2}\right)d\sigma^2$$
其中，上面的$\mu_1$和$\Sigma_1$是参数对于后验$f(\beta\mid X, Y, \sigma^2)$，已知其服从高斯分布。被积函数中 sigma 的幂为 $k/2+n/2+1$，这将产生分布 $f(\beta\mid X, Y)\propto (1+\beta^T V \beta)^{-(n+k)/2}$。因此，我选择了 $n$ 个自由度，而不是 $n-k$。这里一定有什么不对劲。您能指出逻辑上的缺陷吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648098/non-informative-prior-in-bayesian-linear-regression</guid>
      <pubDate>Mon, 27 May 2024 20:35:10 GMT</pubDate>
    </item>
    <item>
      <title>广义线性混合效应模型的事后测试</title>
      <link>https://stats.stackexchange.com/questions/648095/post-hoc-tests-for-a-generalized-linear-mixed-effects-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648095/post-hoc-tests-for-a-generalized-linear-mixed-effects-model</guid>
      <pubDate>Mon, 27 May 2024 19:48:32 GMT</pubDate>
    </item>
    <item>
      <title>给定条件评级后，条件评级为 5 的概率是多少？</title>
      <link>https://stats.stackexchange.com/questions/648093/what-is-the-probability-of-condition-rating-5-following-a-given-condition-rating</link>
      <description><![CDATA[我有一个资产管理系统，其中资产的状况评级从 1（好）到 5（坏）。资产每年都会接受检查并评级；新资产的状况评级从 1 开始，随着时间的推移逐渐恶化，直到评级为 5。
我想了解具有给定评级的资产在第二年获得评级 5 的概率。我的问题是：我是否有足够的信息来估计这一点？如果没有，我需要哪些更多信息或假设才能估计这一点？
我记录了显示资产如何随时间恶化的数据（图 1）。

图 1. 图表显示了不同恶化率下状况评级如何从 1 变为 5。
如果我假设恶化率的分布，我可以估计给定年龄的资产中每种状况评级的比例（图 2）。

图 2. 资产状况等级概率随时间的变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/648093/what-is-the-probability-of-condition-rating-5-following-a-given-condition-rating</guid>
      <pubDate>Mon, 27 May 2024 19:24:57 GMT</pubDate>
    </item>
    <item>
      <title>在消除伽玛参数的估计偏差之前是否存在可能性惩罚或（不）适当的惩罚？</title>
      <link>https://stats.stackexchange.com/questions/648090/is-there-a-likelihood-penalization-or-improper-prior-to-remove-estimation-bias</link>
      <description><![CDATA[所以我了解到伽马分布参数的最大似然估计是有偏差的。据我所知，一般不能保证存在可以给出无偏估计的先验（或基本速率），但对于我的许多应用程序，我不一定需要参数的正确概率分布。
是否有专门针对伽马分布的惩罚，可以消除其参数的 MLE 偏差？
来源：

https ://math.stackexchange.com/questions/4380570/prove-that-the-mle-of-the-lambda-parameter-of-gamma-distribution-is-unbiased
https://sci-hub.se/https ://doi.org/10.1109/ITNG.2015.151
对于 Gamma 分布，使用 MLE 还是 MoM？ 
使用 Gamma 先验的方差/精度估计器偏差
偏差校正惩罚最大似然/最大后验估计
]]></description>
      <guid>https://stats.stackexchange.com/questions/648090/is-there-a-likelihood-penalization-or-improper-prior-to-remove-estimation-bias</guid>
      <pubDate>Mon, 27 May 2024 19:06:33 GMT</pubDate>
    </item>
    <item>
      <title>根据 GLICKO1 和 GLICKO2 评级计算获胜概率的公式是什么？</title>
      <link>https://stats.stackexchange.com/questions/648088/what-is-the-formula-to-calculate-win-probability-based-on-glicko1-and-glicko2-ra</link>
      <description><![CDATA[给定 GLICO1 或 GLICO2 系统的非平局游戏、评级、mu、phi 和 sigma，如何计算各方获胜概率？
我搜索了有关这些系统的信息，例如http://glicko.net/glicko/glicko.pdf 或 wiki，甚至研究了来源计算库的代码，但未能找到解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/648088/what-is-the-formula-to-calculate-win-probability-based-on-glicko1-and-glicko2-ra</guid>
      <pubDate>Mon, 27 May 2024 18:09:59 GMT</pubDate>
    </item>
    <item>
      <title>混合效应分析中的 P 值与数据不匹配</title>
      <link>https://stats.stackexchange.com/questions/648086/p-values-not-matching-data-in-mixed-effects-analysis</link>
      <description><![CDATA[我有一个数据集，其中包含 3 种不同鱼类的耗氧量 (MO2) 值。我的实验是重复测量设计，在 4 个不同温度点（15C、20C、25C 和 30C）下测量了每个物种的 14 条鱼的 MO2。我还记录了研究中使用的所有鱼的重量。我正在尝试在 R 中运行一个混合效应模型（采用重复测量设计），其中包含重量作为协变量，因为已知重量会影响耗氧量 (MO2)。
我有一个重复测量混合效应模型，正在 R 中运行，并以权重作为协变量。我使用以下代码来运行模型：
model_interaction &lt;- lmer(MO2 ~ 温度 * 物种 + 重量 + (1|Subject_ID), 数据 = MO2mixed)
然后我进行了事后测试，因为我想知道在每个给定温度下每个物种之间的 MO2 值是否存在差异。我使用了这段代码：
emm_interaction &lt;- emmeans(model_interaction, 成对 ~ 物种 | 温度)
pairwise_interaction &lt;-pairs(emm_interaction)
打印（pairwise_interaction）
但是，当我获得事后测试的结果时，p 值和显着性与我的数据图表的外观完全不一致。例如，emmeans 函数为我提供以下统计数据：
表格参见图片：
温度=30：
对比估计 SE df t.ratio p.value
FTD-JD 0.16016 0.109 123.5 1.465 0.3115
FTD-RBD 0.47990 0.109 129.1 4.413 0.0001
JD-RBD 0.31974 0.123 101.3 2.600 0.0286
自由度方法：kenward-roger
P 值调整：用于比较 3 个估计值的 tukey 方法
然而，这对我的图表没有任何意义（见附件），在 30 度时，FTD 和 JD 之间的差异看起来最大，但在统计数据中，p 值表明它根本不显着。&lt; /p&gt;
关于为什么会发生这种情况有什么想法吗？
对于我的一些数据，在较高温度下个体缺少点，因为鱼无法应对这些温度。因此，对于某些人来说，存在早期温度的数据点，但较高温度的数据点不存在。这会是一个问题吗？我认为混合效应模型能够处理空白值？
为什么我的 p 值与数据集图表中给出的关系根本不匹配，有什么建议吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/648086/p-values-not-matching-data-in-mixed-effects-analysis</guid>
      <pubDate>Mon, 27 May 2024 17:24:20 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用多个 T 检验作为 AN(C)OVA 后事后测试的替代方法吗？如果是这样，我该如何在 R 中做到这一点？</title>
      <link>https://stats.stackexchange.com/questions/648096/can-i-use-multiple-t-tests-as-an-alternative-to-post-hoc-testing-after-ancova</link>
      <description><![CDATA[我有一个数据集，在其中测量了多年和多种作物的表型。我寻找关系的第一种方法是双向方差分析，我问“在考虑了抽样结构后，多样性对表型是否有影响？”即
表型〜采样事件+品种
我真正感兴趣的问题是，是否有任何品种明显优于或差于总体平均值。
鉴于我发现表型和品种之间存在显着关系，我一直在努力寻找合适的事后测试。 TukeyHSD 对我来说不起作用，因为我对不同品种之间的比较不感兴趣，而是对平均值的比较感兴趣。
作为一种解决方法，我一直在使用 T 检验，并针对多次测试调整 p 值。然而，我不确定这是否a）有效，b）是否可以在R中以更简化的方式完成。目前我必须手动创建一个新列，其中我感兴趣的品种是“a”而其他一切都是“b”，因此 T 检验将样本“a”与样本“a”进行比较。到平均值。然而，考虑到我有 30 个不同的品种和 8 个不同的表型，这将需要很长时间手动完成！
非常欢迎任何帮助！我附上了一些示例数据。为简单起见，我只包含一种表型
品种 &lt;- c(A,A,A,A,B,B,B,B,C,C,C,C,D,D,D,D,E,E,E, E、F、F、F、F、G、G、G、G、H、H、H、H）
采样事件 &lt;- c(A1,A1,A2,A2,A1,A1,A2,A2,A1,A1,A2,A2,A1,A1,A2,A2,A1,A1,A2,A2,A1,A1, A2,A2,A1,A1,A2,A2,A1,A1,A2,A2)
表型1 &lt;- c(13.86,14.48,15.5,16.22,14.72,14.72,16.6,16.98,16.98,12.34,15.6,17.82,17.6,9.26,13.46,12.24,13.1,16.22,15.94,10 .86,12.44,10.58, 17.3,13.38,15.2,13.66,18.2,14.9,15.68,18.8,15.94,13.38)

虚拟数据 &lt;-data.frame(品种、采样事件、表型1)

我按照https://www.datanovia.com/en/blog/how-to-perform-multiple-t-test-in-r-for- Different-variables/。由此，我成功地为每个品种的所有表型生成了 T 检验，这很好，但我宁愿对每个表型的所有品种进行 T 检验。]]></description>
      <guid>https://stats.stackexchange.com/questions/648096/can-i-use-multiple-t-tests-as-an-alternative-to-post-hoc-testing-after-ancova</guid>
      <pubDate>Mon, 27 May 2024 13:25:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Lehr 方法和 Statsmodels 的样本量估计存在如此大的差异</title>
      <link>https://stats.stackexchange.com/questions/648073/why-is-there-such-is-difference-in-sample-size-estimation-between-lehrs-method</link>
      <description><![CDATA[我一直在使用Lehr规则来估计一些实验所需的样本量我得跑了。
Lehr 规则指出我们需要：
$$ n = \frac{ 2\left(z(1-\alpha) + z(1-\beta)\right)^2 \sigma^2}{ \Delta^2} $$
其中 $ z(x) $ 是显着性水平的 $z$ 分数 $x$，$\sigma^2$ 是样本方差，$\Delta^2$ 是最小可检测效果。
下面是一些计算所需样本量的代码。
将 numpy 导入为 np
将 pandas 导入为 pd
从 scipy.stats 导入 ttest_ind，规范
从 statsmodels.stats.power 导入 TTestPower

# 计算所需样本量的函数
def计算样本大小（α，β，样本方差，mde）：
    ## https://en.wikipedia.org/wiki/Power_of_a_test#Rule_of_thumb

    norm_inv_z5 =norm.ppf(1.0 - alpha/2)
    norm_inv_1_z6 =norm.ppf(1.0 - beta)
    K = 2 * (norm_inv_z5 +norm_inv_1_z6)**2
    num = K * 样本方差
    分母 = mde ** 2
    样本大小 = 数字 / 分母
    返回 int(np.ceil(sample_size))

alpha = 0.1 # t 检验的显着性水平
beta = 0.2 # 功率等级
CvR = 0.1 # 转化率
Sample_variance = CvR * (1 - CvR) # 样本方差
MDE = 0.05 # 最小可检测效果 %
n_samples =calculate_sample_size(alpha, beta,sample_variance, CvR * MDE) # 样本大小

在此示例中，我想计算网站干预的样本量。我想将转化率提高 5%。这样做可以得到大约 50,000 个样本。
使用相同的输入，我发现了以下 Statsmodels 函数来计算 t 检验的功效：
 效果大小 = (CvR * MDE) / 样本方差 
 分析 = TTestPower()
 n_samples = int(np.ceil(analysis.solve_power(effect_size, power=1.0-beta, nobs=None, alpha=alpha, Alternative=&#39;双面&#39;)))

但是，该方法仅需要约 3000 个样本。
如何解释这种差异以及原因？]]></description>
      <guid>https://stats.stackexchange.com/questions/648073/why-is-there-such-is-difference-in-sample-size-estimation-between-lehrs-method</guid>
      <pubDate>Mon, 27 May 2024 12:43:03 GMT</pubDate>
    </item>
    <item>
      <title>固定效应回归模型中模型非常不稳定，变量大多不显著</title>
      <link>https://stats.stackexchange.com/questions/648072/very-unstable-model-and-mostly-insignificant-variables-in-fixed-effects-regressi</link>
      <description><![CDATA[上周我一直在尝试为我的硕士论文创建一个回归模型，但我遇到了以下问题。目前正在寻求我能得到的任何帮助，非常感谢您提供的任何意见。 :)
我的目标是通过几个公司和宏观经济控制变量找出欧盟排放配额价格对公司自由现金流的影响。我为此使用的数据集涵盖了大约 500 家公司以及 2005 年至 2022 年的数据。
我在 R 中建立了一个单向固定效应模型（内部），并尝试用它来估计模型。它得出以下结果，这些结果还可以，但在我看来没有意义，因为我确信某些变量应该会产生重大影响，例如 GDP 增长。
我可以做/调查什么，看看我估计模型的方式是否存在错误？我是否需要以某种方式转换变量（已经尝试过一些方法，例如日志、标准化、差分）？
非常感谢您的帮助！非常感谢。
R 输出：
模型内的单向（个体）效应
致电：
plm(公式 = FCFF ~ GDP_Growth + 无形资产 + 收入 +
折旧 + TOTAL_ASSETS + 已申请专利 + 汇率_EUR.CNY +
通货膨胀+石油价格+铅现货+EU_ETS_期货+EU_ETS_现货，
数据=数据，模型=“内”）
平衡面板：n = 511，T = 18，N = 9198
残差：
分钟。    第一曲。     第三曲中位数。       最大限度。
-5609351.5 -5784.3 -676.8 3676.6 7938700.2

信号。代码：0&#39;&#39;0.001&#39;&#39;0.01&#39;&#39;0.05&#39;.&#39;0.1&#39;&#39;1
总平方和：3.5016e+14
残差平方和：2.8466e+14
R 平方：0.18705
调整。 R 平方：0.13814
F 统计量：12 和 8675 DF 上为 166.339
p 值：&lt; 2.22e-16]]></description>
      <guid>https://stats.stackexchange.com/questions/648072/very-unstable-model-and-mostly-insignificant-variables-in-fixed-effects-regressi</guid>
      <pubDate>Mon, 27 May 2024 12:34:17 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中预测斜率不断变化的增长时间序列？</title>
      <link>https://stats.stackexchange.com/questions/648054/how-to-predict-a-growing-time-series-with-changing-slopes-in-python</link>
      <description><![CDATA[我有一个单变量时间序列数据集，它表示持续增长的趋势，但斜率以不同的间隔变化。我想预测这个时间序列的未来值。
以下是一些关键细节：
该系列一直在增加。
斜率在不同点发生变化。
数据只有一个变量。
我正在寻找合适的模型或方法来准确预测未来价值。
我需要在测试集之外执行预测，这意味着使用预测来迭代地进一步预测未来。
到目前为止，我已经考虑过线性回归，但它不能很好地处理不断变化的斜率。我也研究过 ARIMA，但我不确定如何针对这种情况配置它。
任何人都可以推荐适当的 Python 模型或技术来处理这种类型的时间序列吗？示例或教程参考将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/648054/how-to-predict-a-growing-time-series-with-changing-slopes-in-python</guid>
      <pubDate>Mon, 27 May 2024 07:56:10 GMT</pubDate>
    </item>
    <item>
      <title>针对小型且不平衡的数据集进行训练-验证-测试分割？</title>
      <link>https://stats.stackexchange.com/questions/647996/train-validation-test-split-for-small-and-unbalanced-dataset</link>
      <description><![CDATA[我有一个大约 100 行的数据集，每行大约有 400 个特征。其中 93 个为 0 类，7 个为 1 类。
我希望能够将 100 个示例拆分为训练集、验证集和测试集，以便我可以优化超参数并选择一个好的模型。
但是，我的 1 类行数非常少，以至于将它们混入验证或测试集的方式会导致性能指标出现巨大波动。
分割数据集以便选择良好的超参数并报告有意义的性能指标的最佳方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647996/train-validation-test-split-for-small-and-unbalanced-dataset</guid>
      <pubDate>Sun, 26 May 2024 03:47:26 GMT</pubDate>
    </item>
    <item>
      <title>工具变量是否要求工具和处理之间独立？</title>
      <link>https://stats.stackexchange.com/questions/647993/does-an-instrumental-variable-require-independence-between-the-instrument-and-tr</link>
      <description><![CDATA[如果满足以下条件，则工具变量 Z 是 T（处理）的合法工具：

Z 对 Y 具有完全由 T 介导的因果效应（即从 Z 到 Y 没有直接影响，并且因果关系流必须至少贯穿 T）
Z 没有通往 Y 的后门路径。
单调性（仪器中的值越高，所采用的治疗值越高）
第一阶段实际上存在（Z 和 T 之间存在非零相关性）。

但是，如果我们有以下 DAG，会发生什么？

C 是治疗和仪器之间的混杂变量。 UC 是一组未观察到的混杂因素。 Z 仍然是 T 的合法工具吗？我的印象是答案是否定的，但根据 https://dagitty.net/dags.html# 
...C 和 Z 都是 T 的合法工具。我可以看到 C 是合法工具，因为所有因果路径都经过 T（直接或由 Z 介导）。然而，如果不先以 C 为条件，Z 又如何能成为 T 的工具呢？我可以通过 C 跳转到 T。大多数消息来源似乎都表明 T 和 Z 必须以 d 分隔，但只是想验证这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/647993/does-an-instrumental-variable-require-independence-between-the-instrument-and-tr</guid>
      <pubDate>Sun, 26 May 2024 00:19:40 GMT</pubDate>
    </item>
    <item>
      <title>聚类分析中的变量重要性</title>
      <link>https://stats.stackexchange.com/questions/647887/variable-importance-in-cluster-analysis</link>
      <description><![CDATA[我是聚类分析的新手，阅读了很多东西，但我无法理解如何将变量排序到聚类中。我的意思是，我发现我的数据聚集成 3 个不同的簇，但我如何理解哪些变量与评估此结果最相关？我使用R并且有很多包来执行聚类分析，但是在函数手册中我没有找到任何与变量重要性相关的内容。有人可以尝试向我解释一下吗？提前致谢
编辑：
例如，我使用 k 均值对具有 40 行（不同样本）和 30 列（特征、数值变量）的数据集进行聚类分析。我如何确定这 30 个特征中哪一个对于确定最终聚类结果最重要/最重要/最相关？我认为并非所有功能都会带来相关信息。例如在监督机器学习中，但没有关于数据结构/类的先验信息。基于聚类分析的结果建立监督模型，使用聚类作为样本所属的类并在其上构建模型，这可能是一种正确的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647887/variable-importance-in-cluster-analysis</guid>
      <pubDate>Fri, 24 May 2024 11:35:54 GMT</pubDate>
    </item>
    </channel>
</rss>