<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 05 Jan 2025 21:14:45 GMT</lastBuildDate>
    <item>
      <title>梦幻篮球：重新思考球员的价值</title>
      <link>https://stats.stackexchange.com/questions/659577/fantasy-basketball-rethinking-player-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659577/fantasy-basketball-rethinking-player-value</guid>
      <pubDate>Sun, 05 Jan 2025 20:56:33 GMT</pubDate>
    </item>
    <item>
      <title>如何实现全卷积神经网络（FCN）用于多类分类任务？</title>
      <link>https://stats.stackexchange.com/questions/659573/how-can-a-fully-convolutional-neural-network-fcn-be-implemented-for-a-multicla</link>
      <description><![CDATA[在网络上我看到的几乎所有资料中，FCN 主要用于分割等问题（例如具有各种上采样层的 U-net），所以我的问题是，考虑到它们能够处理不同分辨率的图像，如何使用这些网络进行简单的多类分类任务。
我能想到的唯一解决方案是 FCN 产生具有 c 个通道（其中 c 是类别数）的特定热图体积，然后是 GAP，然后是 softmax。还有其他完全卷积方法吗？我读到过一种称为“卷积化”的过程，它可以让你在这种情况下重用预先训练的 CNN（非完全卷积）的权重，但我真的不明白它是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/659573/how-can-a-fully-convolutional-neural-network-fcn-be-implemented-for-a-multicla</guid>
      <pubDate>Sun, 05 Jan 2025 20:08:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么交互项虚拟变量的个体显著性取决于基类/省略类，而联合显著性却不取决于基类/省略类？</title>
      <link>https://stats.stackexchange.com/questions/659572/why-is-individual-significance-of-interaction-term-dummies-dependent-on-the-base</link>
      <description><![CDATA[我不认为我可以展示数据，但在线性回归模型中，除了其他几个变量外，我还有一个连续变量年龄和分类变量健康之间的交互项。健康有 5 个类别。当我以不同的类别为基础运行模型时，每个非省略类别的个体显著性检验 p 值差异很大（例如，当“优秀”健康为基础时，年龄和“一般”健康之间的交互作用显著，达到 95%，但当“较差”健康为基础时，它并不单独显著），但联合显著性检验 p 值始终相同（显著性达到 95%）。
此外，交互项的输出系数会发生变化，但使用“margins”和“marginsplot”的图形的实际斜率不会发生变化Stata 中的命令。
因此
regressdependentvar c.age##ibx.healthother_variable1other_variable2testparm c.age#ibx.healthmargins,at(age=(16(1)80)health=(12345))atmeansmarginsplot 产生相同的联合显著性和相同的图形，但每个交互项的个体显著性 p 值和系数不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/659572/why-is-individual-significance-of-interaction-term-dummies-dependent-on-the-base</guid>
      <pubDate>Sun, 05 Jan 2025 20:03:09 GMT</pubDate>
    </item>
    <item>
      <title>SPSS中具有多个分类预测变量和一个连续预测变量的线性回归[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659570/linear-regression-with-multiple-categorical-predictor-and-one-continuous-predict</link>
      <description><![CDATA[我想在 SPSS 中执行包含 3 个分类预测因子（每个都有两个级别）、一个连续预测因子和一个标准变量的回归分析。我希望能够查看简单的效果，因此我计划使用 PROCESS。但是，对话框中只有一个 X 变量的空间。我如何才能将所有 4 个预测变量输入模型并获取所有交互项的统计数据，并获得简单斜率？]]></description>
      <guid>https://stats.stackexchange.com/questions/659570/linear-regression-with-multiple-categorical-predictor-and-one-continuous-predict</guid>
      <pubDate>Sun, 05 Jan 2025 19:13:35 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 SHAP 值</title>
      <link>https://stats.stackexchange.com/questions/659566/how-to-interpret-shap-values</link>
      <description><![CDATA[我是 AI 新手。我有一张尺寸为 (28, 28, 3) 的 MNIST 图像，心里有几个问题。如果有人能就此提出建议，那就太好了：

SHAP 如何确定值范围？例如，为什么有时是 -2 到 +2？它应该这么大吗？有时，当我使用其他格式运行它时，它会给出 -0.00005 到 0.00005 的范围。正确的有效范围是什么？

如果我的模型对此图像的置信度得分为 30，那么将 SHAP 值相加是否也会得到 30？这是否意味着总贡献得分应该与置信度得分相匹配？如果不是，为什么？


]]></description>
      <guid>https://stats.stackexchange.com/questions/659566/how-to-interpret-shap-values</guid>
      <pubDate>Sun, 05 Jan 2025 14:51:01 GMT</pubDate>
    </item>
    <item>
      <title>除了单纯形之外，狄利克雷分布还有哪些其他支持的推广形式？</title>
      <link>https://stats.stackexchange.com/questions/659565/is-there-any-generalization-of-the-dirichlet-distribution-to-supports-other-than</link>
      <description><![CDATA[让我们考虑$(\theta_{1},\theta_{2},...,\theta_{k}) \sim$ Dirichlet($a_{1},a_{2},...,a_{k})$。我想知道我们是否还有$\theta_{1} &gt; \epsilon_{1}$, $\theta_{2} &gt; \epsilon_{2}$,...,$\theta_{k} &gt; \epsilon_{k}$，其中 $\epsilon_{i} \geq 0, \forall i \in {1,,2...,k}$ 是已知常数。
是否有任何已知的分布或封闭的解析形式？
我曾尝试通过条件概率计算来发展这个想法，但这有点具有挑战性。]]></description>
      <guid>https://stats.stackexchange.com/questions/659565/is-there-any-generalization-of-the-dirichlet-distribution-to-supports-other-than</guid>
      <pubDate>Sun, 05 Jan 2025 14:41:16 GMT</pubDate>
    </item>
    <item>
      <title>比较两个模型中的分类变量</title>
      <link>https://stats.stackexchange.com/questions/659562/comparing-a-categorical-variable-accross-two-models</link>
      <description><![CDATA[我在 R 中运行两个固定效应回归：一个针对男性，一个针对女性。除了年份固定效应外，我还有一个分类变量作为我感兴趣的解释变量，年龄组作为另一个分类变量。
如果两个模型之间的分类变量系数不同，我该如何比较？
我依稀记得你估计了一个合并模型，并包括性别和分类变量之间的交互项。然后你进行 Wald 检验以检查交互项是否具有联合显著性。但是，我不确定这是否是正确的方法。
此外，我不确定我是否还应该包括性别和年龄组之间的交互项，还是只包括性别和感兴趣的分类变量之间的交互项。
但是，最好直接比较系数，而不需要估计合并模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/659562/comparing-a-categorical-variable-accross-two-models</guid>
      <pubDate>Sun, 05 Jan 2025 12:03:16 GMT</pubDate>
    </item>
    <item>
      <title>空间滞后模型对数似然计算</title>
      <link>https://stats.stackexchange.com/questions/659560/spatial-lag-model-log-likelihood-calculation</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659560/spatial-lag-model-log-likelihood-calculation</guid>
      <pubDate>Sun, 05 Jan 2025 11:31:04 GMT</pubDate>
    </item>
    <item>
      <title>股票价格变动分布的重尾现象表现在哪里？</title>
      <link>https://stats.stackexchange.com/questions/659559/wheres-heavy-tail-in-the-distribution-of-the-stock-price-changes</link>
      <description><![CDATA[有假设认为股票价格变化具有混合分布 - 头部服从正态分布，尾部服从幂律分布。
幂律$f(x) = C x^{-\alpha}$可以在对数对数图上识别为直线。
我绘制了实际股票价格变化的 CDF，但我找不到尾部 - 直线。它在哪里？ （相同数据上也有正常的 CDF 拟合，仅用于比较）。

在 CDF 图表上 - 仅显示部分 CDF - 对数对数刻度上的正向变化。此外，差异通过对数变换进行变换，并且以中位数为中心。正态 CDF 拟合中心差值，强制使用 0 作为均值。
数据 - 股票价格差值 - 计算为每天的年度变化 $d_i=p_i/p_{i-360}$，针对几十年来单一股票的每日价格。
更新：我错误地构建了对数/对数图，正如评论中明智的人士所建议的那样，该图应该“反转”为了更好地显示尾部，应使用互补 CDF，这里绘制了与互补 CDF 相同的数据。
似乎虽然正态分布低估了尾部，但尾部不是帕累托（尾部不是直线），而是更弱的东西：

数据和代码
代码
import json
将 numpy 导入为 np
从 scipy.stats 导入 norm
将 matplotlib.pyplot 导入为 plt

# 加载 &#39;diffs.json&#39;
使用 open(&#39;diffs.json&#39;, &#39;r&#39;) 作为文件：
diffs = json.load(file)

# 对数据进行对数转换
log_diffs = np.log(diffs)

# 将中心计算为中位数，它比平均值更合适
center = np.median(log_diffs)

# 将对数差异居中
log_diffs_centered = log_diffs - center

# 拟合真实 CDF 的函数
def fit_cdf_(data):
sorted_data = np.sort(data)
n = len(data)
cdf = [(x, (i + 1) / n) for i, x in enumerate(sorted_data)]
return cdf

# 拟合实数 CDF
real_cdf = fit_cdf_(log_diffs_centered)

# 拟合正态 CDF，强制均值为 0
variance = np.mean(log_diffs_centered**2) # 方差
sigma = np.sqrt(variance) # 标准差

# 提取 CDF x 值
cdf_xs = np.array([x for x, _ in real_cdf])

# 计算这些 x 值的正态 CDF
normal_cdf = [(x, norm.cdf(x, loc=0, scale=sigma)) for x in cdf_xs]

# 绘制实数 CDF 和正态 CDF
real_cdf_ys = [p for _, p in real_cdf]
normal_cdf_ys = [p for _, p in normal_cdf]

plt.figure(figsize=(8, 6))
plt.plot(cdf_xs, real_cdf_ys, label=&#39;Real CDF&#39;, linestyle=&#39;-&#39;)
plt.plot(cdf_xs, normal_cdf_ys, label=&#39;Normal CDF&#39;, linestyle=&#39;--&#39;)
plt.xscale(&#39;log&#39;) # 对数 x 轴刻度
plt.yscale(&#39;log&#39;) # 对数 x 轴刻度
plt.ylim(0.5, 1) # y 轴域
plt.xlim(0.001, 2) # x 轴域
plt.xlabel(&#39;x (对数刻度)&#39;)
plt.ylabel(&#39;累积概率&#39;)
plt.title(&#39;Real vs Normal CDF&#39;)
plt.legend()
x_ticks = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2]
plt.xticks(x_ticks, [str(label) for label in x_ticks])
y_ticks = [0.5, 0.6, 0.7, 0.8, 0.9, 1]
plt.yticks(y_ticks, [str(label) for label in y_ticks])
plt.grid(True)
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/659559/wheres-heavy-tail-in-the-distribution-of-the-stock-price-changes</guid>
      <pubDate>Sun, 05 Jan 2025 10:34:17 GMT</pubDate>
    </item>
    <item>
      <title>如何计算独立拍卖实验中销售额、退货和退货率变化的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/659552/how-to-compute-confidence-intervals-for-changes-in-sales-returns-and-return-ra</link>
      <description><![CDATA[问题
假设我正在组织一场汽车拍卖会，并进行两个独立的实验：

拍卖会 A 进行了 1000 次。
拍卖会 B 进行了 1000 次。
（例如，我更换了拍卖会 B 中的拍卖师，并想测量其效果。）

以下是观察到的结果：




拍卖会 A
拍卖会 B
符号




数量运行
1000
1000
常数 $ n_A $ 和 $ n_B $


售出数量
500
600
随机变量 $ S_A $ 和 $ S_B $


（售出和）退回数量
200
300
随机变量$ R_A $ 和 $ R_B $



根据这些数据，增量（我感兴趣的）如下：

销售数量增加了 20%：从 500 增加到 600。
退货数量增加了 50%：从 200 增加到 300。
退货率增加了 25%：从 40%（$ \frac{200}{500} $）增加到 50%（$ \frac{300}{600} $)。

问题 1：增量的置信区间
如何计算 95% 置信水平下每个增量的置信区间？例如：

销售数量增量，例如 $[+16\%, +27\%]$。
退货数量增量，例如 $[+42\%, +53\%]$。
退货率增量，例如 $[-5\%, +41\%]$。


我目前的方法（针对 #1）：
计算销售数量增量的置信区间：

我假设 $ S_A \sim \text{Binomial}(n_A, p^s_A) $ 和 $ S_B \sim \text{Binomial}(n_B, p^s_B) $，其中 $ p^s_A $ 和 $ p^s_B $ 是拍卖 A 或拍卖 B 中拍卖成交的概率 ($ p^s_A = 50\%, p^s_B = 60\% $)。
然后，我计算置信区间如下：
$$
\Delta S \pm z_{\alpha/2} \sqrt{\text{Var}(\Delta S)}
$$
其中：
$$
\text{Var}(\Delta S) = \text{Var}(S_A) + \text{Var}(S_B),
$$
并且：
$$
\text{Var}(S_A) = n_A p^s_A (1 - p^s_A), \quad \text{Var}(S_B) = n_B p^s_B (1 - p^s_B)。
$$
这种方法有意义吗？


我的挑战（针对 #2 和 #3）：
计算回报数量和回报率的增量置信区间：

我假设 $ R_A \mid S_A \sim \text{Binomial}(S_A, p^r_A) $，对于 $ R_B $ 也是如此。
我应该如何计算 $ \text{Var}(R_A) $ 和 $ \text{Var}(R_B) $？

我是否应该将观察到的销售数量（$ s_A $ 和 $ s_B $）视为常数（如第一种情况下的 $ n_A $ 和 $ n_B $）？
或者我应该将销售数量（$ S_A $ 和 $ S_B $）视为随机变量，并使用总方差定理计算 $ \text{Var}(R_A) $：
$$
\text{Var}(R_A) = \mathbb{E}[\text{Var}(R_A \mid S_A)] + \text{Var}(\mathbb{E}[R_A \mid S_A])?
$$



如能提供关于这些计算的任何指导或替代方法的建议，我们将不胜感激！

备注

我特别关心我的假设（例如，将观察值视为常数而不是随机变量）是否正确。
我希望得到任何相关统计方法或框架的指引，以便更好地处理这些类型的分析。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659552/how-to-compute-confidence-intervals-for-changes-in-sales-returns-and-return-ra</guid>
      <pubDate>Sun, 05 Jan 2025 06:07:41 GMT</pubDate>
    </item>
    <item>
      <title>检验具有交互项的对数线性模型中变量效应的显著性</title>
      <link>https://stats.stackexchange.com/questions/659543/test-significance-of-effect-of-a-variable-in-log-linear-model-with-interaction-t</link>
      <description><![CDATA[假设我们有以下模型：
$\log(\mathbb{E}(​​y|x_1, x_2))=\beta_0+\beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2$。
它可以是逻辑回归、泊松回归或负二项模型。
假设$y$为正整数，模型为负二项模型。
假设$x_1$和$x_2$为虚拟变量。
假设所有估计系数在统计上都是显著。
那么，当 $x_1=1$ 时，将 $x_2$ 从 $0$ 切换到 $1$ 会使 $\mathbb{E}(​​y|x_1, x_2)$ 乘以 $e^{\beta_2} e^{\beta_3}$。
$\beta_2$ 和 $\beta_3$ 都具有统计显著性，足以证明上述事实吗？
或者我需要测试两者对 $y$ 的影响也具有统计显著性？在这种情况下，对 $\beta_2+\beta_3&gt;0$ 进行单侧 t 检验是否足够？]]></description>
      <guid>https://stats.stackexchange.com/questions/659543/test-significance-of-effect-of-a-variable-in-log-linear-model-with-interaction-t</guid>
      <pubDate>Sat, 04 Jan 2025 22:36:32 GMT</pubDate>
    </item>
    <item>
      <title>寻找多项式似然和拉普拉斯先验的后验</title>
      <link>https://stats.stackexchange.com/questions/659538/finding-posterior-of-multinomial-likelihood-and-laplace-prior</link>
      <description><![CDATA[使用狄利克雷先验和多项似然模型，可以推导出离散事件频率估计的后验分布。可以通过计算参数的后验均值估计来应用伪计数技术。假设对于 $\mathbf{n}$ 个可能的离散结果，存在均匀先验和多项模型，我正在寻找这些结果的概率向量 $\boldsymbol{\theta}$ 的后验分布。我来这里是为了验证我的发现。
推导：
后验来自贝叶斯规则：
$P(\boldsymbol{\theta} \mid \mathbf{n}) = \frac{P(\mathbf{n} \mid \boldsymbol{\theta}) P(\boldsymbol{\theta})}{P(\mathbf{n})}$。
似然项
多项式似然为：
$P(\mathbf{n} \mid \boldsymbol{\theta}) = \frac{N!}{\prod_{i=1}^K n_i!} \prod_{i=1}^K \theta_i^{n_i},$
其中 $N = \sum_{i=1}^K n_i$ 是观测总数。
先验项
先验是狄利克雷分布：
$P(\boldsymbol{\theta}) = \frac{1}{Z(\boldsymbol{\alpha})} \prod_{i=1}^K \theta_i^{\alpha_i - 1},$
带有归一化常数：
$Z(\boldsymbol{\alpha}) = \frac{\Gamma\left(\sum_{i=1}^K \alpha_i\right)}{\prod_{i=1}^K \Gamma(\alpha_i)}$。
合并项
后验变为：
$P(\boldsymbol{\theta} \mid \mathbf{n}) = \frac{\frac{N!}{\prod_{i=1}^K n_i!} \prod_{i=1}^K \theta_i^{n_i} \cdot \frac{1}{Z(\boldsymbol{\alpha})} \prod_{i=1}^K \theta_i^{\alpha_i - 1}}{P(\mathbf{n})}$。
简化分子：
$P(\boldsymbol{\theta} \mid \mathbf{n}) = \frac{\frac{N!}{\prod_{i=1}^K n_i!} \frac{1}{Z(\boldsymbol{\alpha})} \prod_{i=1}^K \theta_i^{n_i + \alpha_i - 1}}{P(\mathbf{n})}$。
规范化
确保$P(\boldsymbol{\theta} \mid \mathbf{n})$积分为1，归一化因子$P(\mathbf{n})$必须是：
$P(\mathbf{n}) = \frac{N!}{\prod_{i=1}^K n_i!} \cdot \frac{Z(\boldsymbol{\alpha})}{Z(\mathbf{n} + \boldsymbol{\alpha})}$。
此处：
$Z(\mathbf{n} + \boldsymbol{\alpha}) = \frac{\Gamma\left(\sum_{i=1}^K (n_i + \alpha_i)\right)}{\prod_{i=1}^K \Gamma(n_i + \alpha_i)}$.
最终后验
后验分布简化为：
$P(\boldsymbol{\theta} \mid \mathbf{n}) = \frac{1}{Z(\mathbf{n} + \boldsymbol{\alpha})} \prod_{i=1}^K \theta_i^{n_i + \alpha_i - 1}$.

均匀先验
我们使用拉普拉斯先验（不要与拉普拉斯分布混淆），它对应于均匀先验（$\boldsymbol{\alpha} = \mathbf{1}$)，其中 $\mathbf{1}$ 是一个向量，其长度与 $\mathbf{n}$ 的长度相对应。
$P(\boldsymbol{\theta} \mid \mathbf{n}) = D(\mathbf{n} + \mathbf{1}; \boldsymbol{\theta}) = \frac{1}{Z(\mathbf{n} + \mathbf{1})} \prod_{i=1}^K \theta_i^{n_i}$。
请随意评论此推导。]]></description>
      <guid>https://stats.stackexchange.com/questions/659538/finding-posterior-of-multinomial-likelihood-and-laplace-prior</guid>
      <pubDate>Sat, 04 Jan 2025 20:11:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么这么多问题是线性的以及如何解决非线性问题？</title>
      <link>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</link>
      <description><![CDATA[我这学期选修了一门深度学习 Python 课，我们正在学习线性代数。
上一节课，我们从头开始“发明”了梯度下降的线性回归（之前做过最小二乘法），我们讨论了定义假设、损失函数、成本函数等。
为什么许多问题可以看作是线性的，而“只是试图找到方程 Ax = b 的解”？
可以通过最小二乘法或训练神经网络等方法来实现这一点。
在现实世界中，大多数问题都不是线性的。
由于线性代数仅适用于线性函数，那么如何解决这些问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</guid>
      <pubDate>Sat, 04 Jan 2025 19:41:00 GMT</pubDate>
    </item>
    <item>
      <title>Mann-Whitney-U 和 Mood 的独立样本中值检验是分析两个文化样本差异的正确方法吗？</title>
      <link>https://stats.stackexchange.com/questions/659534/is-a-mann-whitney-u-and-moods-median-test-for-independent-samples-the-correct-m</link>
      <description><![CDATA[第一个问题，如果太长，我深表歉意。我设计了一个双语问卷，用他们的母语对两个不同国籍的人进行调查，试图在一个通用的文化尺度上区分他们的态度水平。由于时间限制，无法进行预测试，语言 1 的 C.-α = 0,546（n = 112），语言 2 的 C.-α = 0,774（n = 74），语言 1 的总体辨别能力很差，但语言 2 的辨别能力很好。语言 1 产生了一个非参数样本，语言 2 产生了一个参数样本，通过对独立样本进行 Kolmogorov-Smirnov 检验进行测试。对改进的问卷进行了双重检查（每种语言删除了不同的项目），结果仍然相同。
我通过应用 Mann-Whitney-U 检验了均值差异的假设，通过应用情绪中位数检验检验了中位数的假设。两者都给出了被拒绝的零假设，因此结果很重要。这是使用混合参数和非参数独立样本案例进行测试的正确方法吗？
考虑到语言 1 版问卷的低 cronbach&#39;s alpha 和判别力，有没有办法计算错误发现的可能性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659534/is-a-mann-whitney-u-and-moods-median-test-for-independent-samples-the-correct-m</guid>
      <pubDate>Sat, 04 Jan 2025 17:49:50 GMT</pubDate>
    </item>
    <item>
      <title>处理一次膨胀计数数据而不是零膨胀计数数据</title>
      <link>https://stats.stackexchange.com/questions/659503/handling-one-inflated-count-data-instead-of-zero-inflated</link>
      <description><![CDATA[处理零膨胀数据时需要零膨胀模型和 Hurdle 模型，或者考虑到研究使用截断泊松或 NB 模型似乎合适。但是，如果数据中不存在 0 计数，而是存在 1 的潜在膨胀，该如何处理？这是否与零膨胀类似，还是事件未在大量观察中发生（零膨胀）的情况是进行调整的具体原因？（也就是说，在建模计数方面，没有零的数据集中的一次膨胀与零膨胀数据集有何不同？）]]></description>
      <guid>https://stats.stackexchange.com/questions/659503/handling-one-inflated-count-data-instead-of-zero-inflated</guid>
      <pubDate>Fri, 03 Jan 2025 18:39:46 GMT</pubDate>
    </item>
    </channel>
</rss>