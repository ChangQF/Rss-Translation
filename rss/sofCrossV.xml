<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Thu, 03 Apr 2025 18:24:30 GMT</lastBuildDate>
    <item>
      <title>标准化温度数据</title>
      <link>https://stats.stackexchange.com/questions/663477/normalizing-temperature-data</link>
      <description><![CDATA[归一化温度数据我在一天中的不同时间有一个关闭温度读数。 
通常，您只会使用数据记录器来执行此操作 - 但对于此项目而言，这是不可行的。
我以为我有办法将这些数据标准化以进行比较，但它不起作用。
所以这是我拥有的示例：
岩石001-23度，上午9：13，8/12/24 
岩石002-29度，1：00 pm，8/12/24 
岩石001-27度，11：45 AM，8/24/24 
岩石002-30度，10：15，AM，8/24/24 
我在每个日期和时间都有来自最近的气象站的空气温度。
实际数据是40个岩石，在不同的日期和时间上有5个观测。
我一直在寻找具有同样问题的论文，但我认为我使用的是正确的关键字。
有什么想法对这些温度进行标准化，以便我可以比较它们？
我认为任何监视季节温度的人都必须有类似的问题才能纠正]]></description>
      <guid>https://stats.stackexchange.com/questions/663477/normalizing-temperature-data</guid>
      <pubDate>Thu, 03 Apr 2025 18:00:35 GMT</pubDate>
    </item>
    <item>
      <title>三向交互回归模型有效，但更简单的版本不会收敛 - 为什么？</title>
      <link>https://stats.stackexchange.com/questions/663460/three-way-interaction-regression-model-works-but-simpler-versions-do-not-converg</link>
      <description><![CDATA[我使用具有204行数据的数据集分析了三个预测变量的效果和对响应变量的一个随机影响。请参阅下面的变量描述：

响应：发生了多长时间（0到5分钟）的措施。大多数情况下，此事件不会发生（即持续0分钟），但是当发生时，它往往会发生整个5分钟。因此，该变量的直方图在0中具有一个峰，第二个峰在5中，然后在1和4之间进行一些峰。。
预测1：具有两个级别的因素
预测2：具有两个级别的因素
预测3：具有三个级别的因素
随机效应：24级的因子

我正在运行下面详细介绍的GLMM，负二项式分布：
 响应〜预测1 *预测2 *预测3 +（1 |随机效果） 
完整的模型（具有三向相互作用）运行良好，良好的模型拟合，没有警告等，但是更简单的模型（例如，没有交互或仅具有两个或一个预测变量）不会收敛。有人知道为什么会发生这种情况吗？
谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/663460/three-way-interaction-regression-model-works-but-simpler-versions-do-not-converg</guid>
      <pubDate>Thu, 03 Apr 2025 15:15:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么这些R软件包即使具有相同的规格也会导致不同的标准错误？</title>
      <link>https://stats.stackexchange.com/questions/663459/why-do-these-r-packages-result-in-different-standard-errors-even-with-the-same</link>
      <description><![CDATA[ i使用2个不同的R软件包计算群集的标准错误。即使有相同的小样本校正，标准错误也大不相同。谁能告诉我哪种正确的方法，为什么？这是我的代码：
  #two方式固定效果回归

formula_count＆lt;  - ＆quot y〜count_stores + factor（fips） +因子（年）;

model_count＆lt;  -  lm（formula_count，data = dataset）

#Method 1

#Clustered SE

cl_vcov_mat＆lt;  -  vcovcl（model_count，cluster = 〜fips，type =＆quot; hc1＆quort;）
clus1＆lt;  -  coeftest（model_count，vcov = cl_vcov_mat）

Stargazer（clus1，omit = c（&#39;fips; quot;&#39;

#Method 2

custom_vcov＆lt;  - 功能（型号）{
    VCOVCL（型号，cluster = 〜fips，type =＆quot; hc1＆quord;） 
}

＃用群集SES创建摘要表
模型符合（
  model_count，
  vcov = custom_vcov，
  星= C（&#39;*&#39;= .1，&#39;**&#39;= .05，&#39;***&#39;= .01），
  统计=;（{std.error}）＆quot;
  COEF_OMIT =;截然
  输出=“ Markdown”
）


``
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/663459/why-do-these-r-packages-result-in-different-standard-errors-even-with-the-same</guid>
      <pubDate>Thu, 03 Apr 2025 15:03:58 GMT</pubDate>
    </item>
    <item>
      <title>威廉·布莱克斯顿（William Blackston）报价的决定门槛[封闭]</title>
      <link>https://stats.stackexchange.com/questions/663457/decision-threshold-from-william-blackstons-quote</link>
      <description><![CDATA[威廉·布莱克斯顿（William Blackston）曾经说过，比一个无辜的人逃脱了十个有罪的人
su。在“基于模型的机器学习”书中作者建议，可以将此报价转换为确定一个人的内gui或无罪的门槛。如果阈值为t，并且基于证据的罪恶感为p。如果P＆GT，该人将被定罪； t并无罪释放。 T.作者建议T = 10/11大约。 91％与报价一致。有人可以解释是否可能发生这种连接，如果是这样，它是如何建立的？]]></description>
      <guid>https://stats.stackexchange.com/questions/663457/decision-threshold-from-william-blackstons-quote</guid>
      <pubDate>Thu, 03 Apr 2025 14:26:01 GMT</pubDate>
    </item>
    <item>
      <title>使用贝叶斯分布回归</title>
      <link>https://stats.stackexchange.com/questions/663455/regression-using-bayesian-distributions</link>
      <description><![CDATA[我正在与生态网络合作，并且是贝叶斯统计的新手。我可以理解网络中无效建模的概念，并对网络指标进行回归分析（使用零模型调整后）以了解生态过程和模式。
我正在尝试了解重建网络的贝叶斯方式（ Young等，Young等，2021 ），并在poster portherties for posteries for posteries for网络上获得了网络的范围。
我试图了解景观参数如何影响生态网络。我仍然无法理解如何对从多个网络获得的不同分布进行回归分析（广义模型）。由于每个网络属性将是后验分布，是否需要另一种统计方法来回答我的问题？
（例如，我的网络属性的后验分布之一 -  nodf-看起来像这样。 src =“ https://i.sstatic.net/ojsropsa.png”/&gt; ）]]></description>
      <guid>https://stats.stackexchange.com/questions/663455/regression-using-bayesian-distributions</guid>
      <pubDate>Thu, 03 Apr 2025 13:19:54 GMT</pubDate>
    </item>
    <item>
      <title>选择要从数据集确定的百分位数，用于配电拟合</title>
      <link>https://stats.stackexchange.com/questions/663454/choosing-the-number-of-percentiles-to-be-determined-from-dataset-for-distributi</link>
      <description><![CDATA[如果我有一个 $ n $ 值的数据集，并且我想适合概率分布，我将计算数据集中的分数百分比。但是，我对应该从数据集中计算的百分位数感到困扰。假设数据集中的每个值都不同，那么它们之间的百分位增量只是 $ \ delta p = 100/n $ ，我将有一个 $ n $ 百分位数的列表。现在，我也无法计算每个单独分数的百分位数，但是例如每个五分之一，留下较大的差距，这意味着我们不知道该百分位数是如何分布在该差距中的。这样做的是产生一个稀疏的数据集以适合分布。不同之处在于，即使我们不知道这些要点是否真的应该存在，更多的数据点将在某些领域比其他区域的重量更大，并影响分配的拟合。因此，我的想法是，通过使用多个分数来计算百分位数来减少点数，也许会带来更正确的结果。不可或缺的情况也相反 - 在Python中，使用Numpy，我们可以定义任何数量的百分位数，这些百分位数大于 $ n $ ，然后插入插入以找到“缺失”分数。这里必须有效果！
我不确定我是否以可理解的方式传达我的想法，所以请告诉我您是否需要澄清。我正在努力思考我所描述的这种效果是否是一个真正的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/663454/choosing-the-number-of-percentiles-to-be-determined-from-dataset-for-distributi</guid>
      <pubDate>Thu, 03 Apr 2025 13:01:48 GMT</pubDate>
    </item>
    <item>
      <title>四向混合（WWWB）ANOVA [重复]</title>
      <link>https://stats.stackexchange.com/questions/663452/four-way-mixed-wwwb-anova</link>
      <description><![CDATA[是否可以四种方式（WWWB）混合ANOVA？如果是这样，进行方差分析后的过程是什么？我是否需要将文件拆分以查看3向交互，然后再查看两个简单的主要效果？还是看对比？]]></description>
      <guid>https://stats.stackexchange.com/questions/663452/four-way-mixed-wwwb-anova</guid>
      <pubDate>Thu, 03 Apr 2025 12:38:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么可能的精度如此之差？</title>
      <link>https://stats.stackexchange.com/questions/663451/why-likelihood-have-such-poor-precision</link>
      <description><![CDATA[ 相同的数据与两个不同的正常分布相匹配，可能性数非常相似。
数据 -  AMD股票的年收益，历史和近期波动率和无风险率作为平均值（全部在日志转换之后）。
The mean is the same for both distributions, the sigmas - numbers in hist and recent columns - are visibly different, like 0.594 and 0.844, yet, if we calculate log likelihood $E[log p(x)]$ for the these two distributions, it will be almost相同的 llh最近：-1.0211  vs  llh历史：-0.9591 。
  hist lr_actual lrf_return最近
0.594 -0.017 0.02 0.556
0.594 0.477 0.011 0.693
0.594 0.933 0.012 0.771
0.594 1.337 0.005 0.844
0.594 1.414 0.004 0.865
...
 
 为什么？这是很小的差异，如果我们考虑这两个分布 - 差异很大，一个用于股票的完整历史，而另一种则改变了，但是，可能性几乎相同？！！
甚至很奇怪，它表明，仅静态数字，全部库存历史记录 LLH历史记录：-0.9591 ，预测未来的回报比库存更高的库存近期波动率 llh最近：-1.0211 。那是不正确的：）。
此数据集来自非固定随机过程，因此，当我们计算可能性时，每个点都会更改分布。我不确定是否可以通过这种方式计算可能性？ （如果没有，可以使用什么？）。
 
和用于计算的Python代码a）日志似然和b）将其归一化为 log pseudo pseudo概率：
 导入pandas作为pd
导入numpy作为NP
从scipy.stats进口规范

def mean_log_pseudo_prob_and_loglh（df，nee_col，sigma_col，actual_col）：
  ＃原始可能性
  lh = norm.pdf（df [muthate_col]，loc = df [mean_col]，scale = df [sigma_col]）
  log_lh = np.log（LH）

  ＃标准化的伪探针
  pseudo_prob = lh / lh.sum（）
  log_pseudo_prob = np.log（pseudo_prob）

  ＃返回：平均日志伪游行和预期的日志可能性
  返回log_pseudo_prob.mean（），log_lh.mean（）

＃阅读数据
df = pd.read_csv（&#39;tmp/data.tsv&#39;，sep =&#39;\ t&#39;）

＃计算值
a_lpp，a_llh = mean_log_pseudo_prob_and_loglh（df，&#39;lrf_return&#39;，&#39;aster&#39;s&#39;，&#39;lr_actual&#39;）
b_lpp，b_llh = mean_log_pseudo_prob_and_loglh（df，&#39;lrf_return&#39;，&#39;hist&#39;，&#39;lr_actual&#39;）

打印（&#39;a：&#39;）
print（f&#39;E [log pseudo-prob]：{a_lpp：.4f}&#39;）
print（f&#39;E [log -libiles]：{a_llh：.4f}&#39;）

打印（&#39;B：&#39;）
打印（f&#39;E [log pseudo-prob]：{b_lpp：.4f}&#39;）
print（f&#39;E [log -libiles]：{b_llh：.4f}&#39;）
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/663451/why-likelihood-have-such-poor-precision</guid>
      <pubDate>Thu, 03 Apr 2025 12:05:51 GMT</pubDate>
    </item>
    <item>
      <title>样本量低后，量化不确定性</title>
      <link>https://stats.stackexchange.com/questions/663449/quantifying-uncertainty-after-friedman-test-with-low-sample-size</link>
      <description><![CDATA[我们正在测试使用两个顺序过滤器过滤湖水的水过滤机。目的是确定机器是否有效去除某些化学物质。
为了测试这一点，我们每天收集三个水样，持续六天：
未过滤的水（进入机器之前）
曾经过滤的水（第一个过滤器之后）
两次过滤的水（第二个过滤器之后）
由于湖中的化学浓度每天都有不同，因此应将在同一天收集的样品作为一组。这意味着我们有六组三个配对样品（每天一个）。
统计方法
为了确定过滤过程是否显着改变了化学浓度，我们进行了弗里德曼测试。该测试检查了在六天的未过滤，曾经过滤和两次过滤的水之间是否存在系统的差异。
结果，在校正多次测试后，我们获得了具有相应P值的化学物质列表。
关注：小样本量
由于我们只有六个配对样品（n = 6天），因此我们预计很高的风险是：
误报（I型错误）：检测不是真实的效果。
假否定性（II型错误）：无法检测到实际效果。
这使我们的结果不那么可靠，我们需要一种量化这种不确定性的方法。
如何解释样本量较小的结果？
置信区间将很有用，但是我们的数据不遵循正态分布（其中包含多个不是真实异常值的极端值）。
相反，我们正在考虑估计最小可检测差的差异 - 弗里德曼测试可以可靠地检测到80％功率在α= 0.05时可靠地检测到的最小化学浓度变化，给定n = 6。
这可能吗？如果是这样，怎么样？
考虑到我们的样本量和显着性水平，是否可以计算每种化学物质的最小检测差？如果是这样，我们该如何计算？
 r用于分析数据]]></description>
      <guid>https://stats.stackexchange.com/questions/663449/quantifying-uncertainty-after-friedman-test-with-low-sample-size</guid>
      <pubDate>Thu, 03 Apr 2025 11:47:15 GMT</pubDate>
    </item>
    <item>
      <title>间隔审查时间较弱的事件数据的时间</title>
      <link>https://stats.stackexchange.com/questions/663446/interval-censored-time-to-event-data-with-frailty-term</link>
      <description><![CDATA[我有在3年期间收集的6个月间隔，旨在估算特定事件的时间。我们假设数据是间隔审查的，这意味着已知事件的情况属于两个随访访问之间。样本中的一些参与者收集了2眼的数据，而另一些参与者只有一只眼睛的数据。我正在寻找一个统计模型，该模型可容纳两种审查结果数据的间隔性质，并使我能够占据脆弱的术语以说明患者内聚类吗？我遇到了使用IC_SP（）或IC_PAR（）函数的贝叶斯模型以及ICENREG套件，以适合半参数和参数模型，但从文档中尚不清楚IC_SP（）如何实现脆弱的术语，我担心试图在诸如脆弱的术语中不得不产生Intera dymented Intera-correlation correlation。
例如。我运行了模型：
 fit_semiparametric＆lt;  -  ic_sp（surn，start，end，type =; interval2＆quot; quast2＆quot;
此运行并产生了一些输出，但是从文档中，尚不清楚模型中是否或如何处理脆弱（患者）项。
我还使用FrailTypenal（）遇到了R中的FrailTypack软件包，但一直在努力使其运行，并且由于我们有单个集群观察，因此尚不清楚是否对建模可能是有问题的。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/663446/interval-censored-time-to-event-data-with-frailty-term</guid>
      <pubDate>Thu, 03 Apr 2025 10:21:23 GMT</pubDate>
    </item>
    <item>
      <title>LCA随访分析 - 您可以使用完整样本中的BCH权重检查参与者的生理数据子样本吗？</title>
      <link>https://stats.stackexchange.com/questions/663431/lca-follow-up-analyses-can-you-use-bch-weights-from-the-full-sample-to-examine</link>
      <description><![CDATA[我正在使用MPLU来检查潜在类别是否适应心理生理反应和症状之间的关联。在最初的分析中，我使用BCH 3步LCA方法找到了一个具有总n = 326的3级解决方案。在这326名参与者中，有196名具有可用的心理生理数据。将LCA的BCH权重与整个样品一起训练模型并在子样本上使用Physio Data的子样本来检查物理学与LCA类主持人的症状之间的关联有什么意义，或者是致命的缺陷？是否有任何潜在的解决方案来管理/适应失踪的惊吓数据，例如混合模型框架中的FIML，并且缺少数据？
预先感谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/663431/lca-follow-up-analyses-can-you-use-bch-weights-from-the-full-sample-to-examine</guid>
      <pubDate>Wed, 02 Apr 2025 17:51:22 GMT</pubDate>
    </item>
    <item>
      <title>如何在Gamlss中为Lasso执行交叉验证以找到最佳的$ \ lambda $？</title>
      <link>https://stats.stackexchange.com/questions/663430/how-to-perform-cross-validation-for-lasso-in-gamlss-to-find-optimal-lambda</link>
      <description><![CDATA[我正在使用用于位置，比例和形状（GAMLSS）的通用加法模型，并试图确定最佳的 $ \ lambda $ 使用交叉验证的套索式回归的值。但是，我正在努力了解如何在这种情况下正确设置交叉验证程序。
对于标准的广义线性模型（GLM），可以使用cv.glmnet（）进行此操作，该步骤遵循以下步骤：

数据集分为 $ k $  folds。
对于每个折叠，使用一个模型对剩余数据进行训练
100  $ \ lambda $ 值的网格。
这些 $ k $  per  $ \ lambda $ 然后在
对应 $ k $ 测试集。
  $ k $  folds均计算每个 $ \ lambda $ 。
  $ \ lambda $ 最小化平均测试错误的选择。

我无法弄清楚如何使用gamlss2软件包实现套索回归，但是我找到了gamlss.lasso，似乎有相同的目的。但是，我的主要问题不是套索实施本身，而是如何正确设置交叉验证过程以选择最佳 $ \ lambda $  。
对于GLM，我们只调整一个 $ \ lambda $ ，但是对于gamlss，我们需要调整第二个：一个：一个用于位置参数 $ \ mu $ $ $ $ $  scale/scale/disperersion parametion参数这表明我们应该使用二维网格的 $ \ lambda $ 值，这意味着，如果我们为 $ \ lambda_ \ lambda_ \ lambda_ \ mu $ 和100 class =“ Math-Container”&gt; $ 100 \ times 100 = 10,000 $ 不同的组合。给定的 $ k = 10 $ 折叠，这将导致培训100,000款模型，这似乎在计算上昂贵。
我试图在没有交叉验证的情况下实施套索，如下所示：
  set.seed（123）
N＆lt; -500
d＆lt; -50
x＆lt;  - 矩阵（rnorm（n*d），n，d）
beta＆lt;  -  cbind（&#39;mu&#39;= rbinom（d，1，.1），sigma&#39;= rbinom（d，1，.1） * .3）
ysd＆lt;  -  Exp（1 + tcrossprod（beta [，2]，x））
data＆lt;  -  cbind（y = as.numeric（rnorm（n，sd = ysd））） + 
    t（tcrossprod（beta [，1]，x）），as.data.frame（x））

＃使用GNET默认设置估算模型
mod＆lt;  -  gamlss（y〜gnet（x.vars = names = names（data）[ -  1]），
              sigma.fo = 〜gnet（x.vars = names（data）[ -  1]）， 
              数据=数据， 
              家庭=不，
              i.control = glim.control（cyc = 1，bf.cyc = 1））

mu_betas＆lt;  -  as.matrix（mu [[1]]  $ beta）
mu_lambdas＆lt;  -  mu [[1]] $  lambda

sigma_betas＆lt;  -  as.matrix（sigma [[1]]  $ beta）
sigma_lambdas＆lt;  -  sigma [[1]] $  lambda
 
从每个 $ \ lambda $ 值的估计系数中，可以评估测试数据的性能并构建交叉验证过程。但是，我尚不清楚以下几点：

由于我们在gamlss中建模两个参数，我们需要一个
 $ \ lambda $ 值的二维网格？也就是说，我们应该测试
所有 $ 100 \ times 100 $ 组合 $（\ lambda_ \ mu，\ lambda_ \ lambda_ \ theta）$ 
独立？例如，这将允许
 $ \ lambda_ \ mu $ 很大，而 $ \ lambda_ \ lambda_ \ theta $ 很小，如果
取决于许多变量，而 $ \ mu $ 取决于很少。
在上述实施中，似乎只有100个组合
经过测试，按照序列 $（\ lambda _ {\ Mu} [1]，
\ lambda _ {\ theta} [1]），...（\ lambda _ {\ mu} [100]，
\ lambda _ {\ theta} [100]）$ ，而不是评估所有可能的
来自两个独立网格的成对组合。这是
正确的方法，或者应全部 $ 10,000 $ 组合
明确？
我读到可以将套索和交叉验证结合在一起
使用gamlss2，但我找不到有关如何如何
到
这样做。如果有人知道如何使用gamlss2进行交叉验证
有了拉索，我将感谢任何指导！
]]></description>
      <guid>https://stats.stackexchange.com/questions/663430/how-to-perform-cross-validation-for-lasso-in-gamlss-to-find-optimal-lambda</guid>
      <pubDate>Wed, 02 Apr 2025 17:51:04 GMT</pubDate>
    </item>
    <item>
      <title>所需的建议：建模超过100％的测量比例数据[封闭]</title>
      <link>https://stats.stackexchange.com/questions/663362/advice-needed-modelling-measured-proportion-data-that-goes-beyond-100</link>
      <description><![CDATA[我一直被任命从海洋探险中分析使用CTD收集水概况的数据集。收集的变量之一是饱和百分比的氧饱和度。我正在寻找一种在空间域上插入数据的方法。但是，覆盖的区域因岛屿而破裂，因此，像Kriging和IDW这样的海洋学中的传统方法不起作用。 I&#39;m currently using a gam with a soap smoother in mgcv::gam to model the surface layer of the water column across the study area (the survey area is fractured by islands, therefore IDW is not适用）。
这是问题：
直觉（以及诸如Cullen Frey图）的诊断表明，应使用Beta家族对饱和值进行建模。但是，水可能过饱和，例如找到值＆gt并不少见。 100％。
      
  将数据扩展到（0,1）然后将响应缩放为“合法”吗？我可以看到这种方法很多。
您将如何解决这个问题？
如果可以替代平滑数据 /插值（包括边界），我很想听听！&lt; / p&gt;
 ps：经验分布表示双峰性。可能是这种情况。但是，我不在乎测量的潜在效果，我正在寻找整个空间域的平滑测量。通常，您将在海洋学中使用IDW。但是，在这种情况下，调查区域和地点被裂缝并被岛屿部分切断。]]></description>
      <guid>https://stats.stackexchange.com/questions/663362/advice-needed-modelling-measured-proportion-data-that-goes-beyond-100</guid>
      <pubDate>Tue, 01 Apr 2025 05:14:23 GMT</pubDate>
    </item>
    <item>
      <title>ICC值对于具有不同自变量的不同空模型相同</title>
      <link>https://stats.stackexchange.com/questions/663337/icc-values-the-same-for-different-null-models-with-different-independent-variabl</link>
      <description><![CDATA[我有25个变量。然后，我拟合25个空模型（无预测变量）。他们对因变量的响应有所不同，但是，观察次数是相同的，并由相同数量的家庭分组。这些模型的差异是相同的，因此，ICC值是相同的，我发现这很奇怪。
这是我如何适合NULL模型的方式：
 库（LME4） 
库（数据。表）
图书馆（表演）
        
    
＃加载数据集
model1mlm＆lt;  -  read.csv（“数据位置”）  

Model1mlm
        
＃确保“实践”是一个因素（二进制结果）
model1mlm  $ raction＆lt;  -  as.factor（model1mlm $ 练习）
model1mlm  $ persyid＆lt;  -  as.factor（model1mlm $  personid）
Model1mlm  $ homeper＆lt;  -  as.factor（model1mlm $ 家庭）
        
        
＃定义模型
模型＆lt;  -  glmer（
          练习〜（1 |家庭），
          data = model1mlm，family = binomial（link =＆quot; logit; quot;），nagq = 0
         ）
        
＃模型摘要
摘要（模型）
    
＃计算ICC
ICC_VALUE＆lt;  - 性能:: ICC（模型）
打印（ICC_Value）
 
我在做什么错，或者如果正确，为什么ICC值相同？
我正在共享两个数据集，以显示暂时的两个模型示例，其中响应不同，但在运行NULL模型时具有相同的变化。
  https://drive.google.com/drive/folders/1O4WBGDPRJZBGBGBEPOEUTS3OOH8OPBBS21?usp=sharing  ]]></description>
      <guid>https://stats.stackexchange.com/questions/663337/icc-values-the-same-for-different-null-models-with-different-independent-variabl</guid>
      <pubDate>Mon, 31 Mar 2025 17:39:15 GMT</pubDate>
    </item>
    <item>
      <title>从GLMMTMB中的Beta GLME模型计算类内相关性</title>
      <link>https://stats.stackexchange.com/questions/663314/calculating-intra-class-correlation-from-beta-glme-model-in-glmmtmb</link>
      <description><![CDATA[我正在尝试从beta GLME（使用GLMMTMB软件包）中找到具有*时间相互作用效果（固定）的内部相关系数，并作为随机效应。
我正在考虑使用以下方程； 
  icc＆lt;  -  rando_var /（andury_var + ristual_var）
 
其中; 
  andy_var＆lt;  -  as.numeric（varcorr（model）$ cond [[1]]）  
  ＃提取随机效应方差（在随机截距模型中）
 
我不确定如何估计此模型的残余方差。使用正确吗？
  ristual_variance＆lt;  -  seect（（mu *（1- mu）） /（1 + phi））。 ＃ANS：0.002668998
 
其中; 
  log_phi＆lt;  -  fixef（model）$ disp
phi＆lt;  -  exp（log_phi） 
Mu＆lt;  - 拟合（模型）
 
或使用：
  var（残差（型号））＃ans：0.002668998
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/663314/calculating-intra-class-correlation-from-beta-glme-model-in-glmmtmb</guid>
      <pubDate>Mon, 31 Mar 2025 02:44:06 GMT</pubDate>
    </item>
    </channel>
</rss>