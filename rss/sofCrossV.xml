<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 01 Feb 2024 03:15:34 GMT</lastBuildDate>
    <item>
      <title>R 中多条记录的生存分析</title>
      <link>https://stats.stackexchange.com/questions/638254/survival-analysis-in-r-with-multiple-records</link>
      <description><![CDATA[我正在尝试学习如何使用生存包在 R 中进行生存分析。
我有一项超过 15 年的大型调查。有 6347 名参与者，每个参与者都有一个唯一的 ID，记录的测量值最多为 15 波。此数据以长格式导入（包含 83,382 行）。
在 Stata 中，它可以识别每个唯一的 ID，并给出每个时间点有怀孕风险的人数（见下文）。
stset stime,失败(怀孕==2) id(ID)
sts列表，生存

         失败_d：怀孕== 2
   分析时间_t: stime
                 身份证号：身份证号

           求。净幸存者标准。
  总故障时间 失去功能错误 [95% Conf.国际]
-------------------------------------------------- ----------------------------
     1 6347 0 5 1.0000 。 。 。
     2 6342 369 1 0.9418 0.0029 0.9358 0.9473
     3 5972 181 2 0.9133 0.0035 0.9061 0.9199
     4 5789 129 5 0.8929 0.0039 0.8851 0.9003
     5 5655 112 6 0.8752 0.0042 0.8669 0.8831
     6 5537 88 12 0.8613 0.0043 0.8526 0.8696
     7 5437 81 8 0.8485 0.0045 0.8394 0.8571
     8 5348 79 8 0.8360 0.0047 0.8266 0.8449
     9 5261 70 9 0.8248 0.0048 0.8152 0.8340
    10 5182 57 10 0.8158 0.0049 0.8060 0.8251
    11 5115 43 33 0.8089 0.0049 0.7990 0.8184
    12 5039 48 31 0.8012 0.0050 0.7911 0.8108
    13 4960 50 57 0.7931 0.0051 0.7829 0.8029
    14 4853 24 134 0.7892 0.0051 0.7789 0.7991
    15 4695 33 4662 0.7837 0.0052 0.7733 0.7936
-------------------------------------------------- ----------------------------

但是，在 R 中，它将每一行视为一个独特的人。
surv_obj &lt;- Surv(time = hilda_event_pregnancy$stime,
             事件 = hilda_event_pregnancy$怀孕）
km_fit &lt;- survfit(surv_obj ~ 1, 数据 = hilda_event_pregnancy)
摘要(km_fit)

调用：survfit(公式 = surv_obj ~ 1, 数据 = hilda_event_pregnancy)

 时间 n.风险 n.事件 生存 标准错误 95% CI 下限 95% CI 上限
    2 83382 369 0.996 0.000230 0.995 0.996
    3 77318 332 0.991 0.000327 0.991 0.992
    4 71267 284 0.987 0.000401 0.987 0.988
    5 65221 292 0.983 0.000476 0.982 0.984
    6 59263 266 0.979 0.000545 0.977 0.980
    7 53276 242 0.974 0.000613 0.973 0.975
    8 47355 221 0.970 0.000682 0.968 0.971
    9 41524 240 0.964 0.000768 0.962 0.965
   10 35647 216 0.958 0.000860 0.956 0.960
   11 29667 183 0.952 0.000959 0.950 0.954
   12 23698 179 0.945 0.001092 0.943 0.947
   13 17743 173 0.936 0.001287 0.933 0.938
   14 11825 126 0.926 0.001550 0.923 0.929
   15 5905 117 0.907 0.002264 0.903 0.912

有人可以建议我如何调整 R 中的代码以获得与 Stata 相同的输出吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638254/survival-analysis-in-r-with-multiple-records</guid>
      <pubDate>Thu, 01 Feb 2024 02:00:24 GMT</pubDate>
    </item>
    <item>
      <title>SPSS 的 PROCESS 宏 - 输出包括超出刻度范围的 DV 值</title>
      <link>https://stats.stackexchange.com/questions/638252/process-macro-for-spss-output-includes-values-of-the-dv-which-are-outside-of-s</link>
      <description><![CDATA[我正在运行一个有调节的调节模型（SPSS 的 PROCESS 宏模型 3），以探索三向交互作用，其中包括一个自变量、一个因变量和两个调节变量。我在输出方面遇到了麻烦，因为因变量由 1-7 等级表示，但是，为可视化条件效果而生成的数据似乎在 IV 和调节器的某些级别上生成负值和大于 7 的值。 
我想知道是否有人可以解释为什么会发生这种情况，以及我是否可以采取任何措施来避免这种情况？
]]></description>
      <guid>https://stats.stackexchange.com/questions/638252/process-macro-for-spss-output-includes-values-of-the-dv-which-are-outside-of-s</guid>
      <pubDate>Thu, 01 Feb 2024 01:13:34 GMT</pubDate>
    </item>
    <item>
      <title>理解 Word2vec 架构时遇到的问题</title>
      <link>https://stats.stackexchange.com/questions/638250/problems-in-understanding-word2vec-architectures</link>
      <description><![CDATA[我可能有一个非常简单的问题，但我在网络上没有找到任何明确的资源。

首先让我们考虑 Skip-gram 模型，在该模型中，我们尝试根据目标单词预测上下文单词。在这种情况下，输入层是一个大小为 N（词汇表大小）的 one-hot-向量；输出层由 k 个不同的向量组成（其中 k 是窗口的大小）？那么对于每个单词，我们将有 3 种不同的概率出现在目标单词上下文中的 3 个不同位置？

如果我们考虑 CBOW 模型并且 k=3，在这种情况下我们将有 3 个输入单热向量。对于给定的单词 i，单词嵌入是通过对由连接神经元 i 到隐藏层所有神经元的权重组成的 3 个向量进行平均来给出的？&lt; /p&gt;

]]></description>
      <guid>https://stats.stackexchange.com/questions/638250/problems-in-understanding-word2vec-architectures</guid>
      <pubDate>Wed, 31 Jan 2024 23:41:37 GMT</pubDate>
    </item>
    <item>
      <title>当我“想”接受通常的零假设时，我该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/638249/what-do-i-do-when-i-want-to-accept-the-usual-null-hypothesis</link>
      <description><![CDATA[我有来自两个随机变量的样本，并且假设方差相等的正态分布。我想证明分布等于意味着$\mu_1$和$\mu_2$ 。
通常的双尾 t 检验用于相反的情况。也就是说，构建以下内容并希望得到一个足够小的 $p$ 来拒绝 H0。

H0：原假设 $\mu_1 = \mu_2$
H1：备择假设 $\mu_1 \neq \mu_2$

但我想拒绝 H1，并通过统计显着性证明 H0 是正确的。
我可以使用相同的双尾 t 检验并以不同的方式解释结果吗？或者我需要一个完全不同的假设检验吗？
&lt;小时/&gt;
我的第一反应是使用相同的测试，最终得到一个大的 $p$ 而不是一个小的，然后声称 H1 被自信地拒绝$1 - p$。但在弄乱了一些数据之后，我不确定这是否是正确的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/638249/what-do-i-do-when-i-want-to-accept-the-usual-null-hypothesis</guid>
      <pubDate>Wed, 31 Jan 2024 23:40:31 GMT</pubDate>
    </item>
    <item>
      <title>可逆跳跃 MCMC 和泊松过程</title>
      <link>https://stats.stackexchange.com/questions/638246/reversible-jump-mcmc-and-poisson-processes</link>
      <description><![CDATA[假设我们有一个时间间隔 $t \in [0, T]$，其中事件以具有任意时间相关速率的泊松过程发生 $\lambda(t)$。这些事件发生的时间为 $Y=(Y_1, Y_2, \dotso, Y_M)$，时间为 $M$ 事件，其中 $Y$ 和 $M$ 都是随机变量，$0 \leq Y_i \leq T$。 $T$ 已修复。
目标是使用以下方法估计事件数 $M$ 及其时间 $Y$ MCMC。
我们知道 $M$ 服从泊松分布，速率为 $g = \int\limits^T_0 \lambda (s) ds$，因此 $p(M|T) = \frac{e^{-g} g^M}{M!}$.
我认为联合概率密度是：
$$
p(Y,M|T) = p(Y|M,T) p(M|T) = \Big( \prod\limits_{i=1}^M \frac{\lambda(y_i)}{g} \Big) \Big( \frac{e^{-g} g^M}{M!} \Big) = \frac{e^{-g}}{M!} \prod\limits_{i=1} ^M \lambda(y_i)
$$
我已确认，对于 $Y$ 和 $M$&lt;，此积分总和为 1 /span&gt;.
但是，我无法使用 MCMC 从此发行版中采样。目前，我有两个 MCMC 提案，并且在链的每个步骤中以相同的概率选择这些提案。

移动事件。对 $i$ 中的索引之一进行采样Y$ 和示例 $Y_i^\prime \sim \text{U}(0,T)$。黑斯廷斯比率 $\frac{q(M,Y|M^\prime,Y^\prime)}{q(M^\prime,Y^\prime|M,Y )} = \frac{\frac{1}{MT}}{\frac{1}{MT}} = 1$。如果$M=0$提案被拒绝。

创建/销毁事件。
a.以 0.5 的概率创建一个事件。 $M^\prime \leftarrow M+1$。对索引 $i \sim \text{U}(1, \dotso, M)$ 进行采样，并将所有下游索引上移 1：$Y_{i+1}^\prime \leftarrow Y_i, Y_{i+2}^\prime \leftarrow Y_{i+1}, \dotso$。新值统一采样 $Y_i^\prime \sim \text{U}(0, T)$。
b.以 0.5 的概率摧毁一个事件。 $M^\prime \leftarrow M-1$。对索引 $i \sim \text{U}(1, \dotso , M)$ 进行采样并删除它，将所有下游索引向下移动 1：&lt; span class=&quot;math-container&quot;&gt;$Y_{i}^\prime \leftarrow Y_{i+1}, Y_{i+1}^\prime \leftarrow Y_{i+2}, \dotso$。如果$M=0$提案被拒绝。
出生事件的黑斯廷斯比率为 $\frac{q(M,Y|M^\prime,Y^\prime)}{q(M^\prime) ,Y^\prime|M,Y)}=\frac{\frac{1}{2}\frac{1}{M+1}}{\frac{1}{2}\frac{1}{T }} = \frac{T}{M+1}$，以及 $\frac{M}{T}$ 表示死亡事件。&lt; /p&gt;


但是，如上所述，该算法没有对正确的分布进行采样（即，估计的事件数量 $M$ 通常大于预期值 $g$）。我认为问题归结为第二个运算符中使用的雅可比术语，其中涉及维度的变化。因此 MCMC 期间的接受概率为：
$$
\alpha = \min\Big(1, \frac{p(Y^\prime, M^\prime|T) q(M,Y|M^\prime,Y^\prime)}{p(Y, M |T) q(M^\prime,Y^\prime|M,Y)} |J| \Big)
$$
对于一些雅可比$J$。但是 $J$ 是什么？或者问题可能出在其他地方。任何帮助表示赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/638246/reversible-jump-mcmc-and-poisson-processes</guid>
      <pubDate>Wed, 31 Jan 2024 22:09:30 GMT</pubDate>
    </item>
    <item>
      <title>帮助我理解 Z 系数</title>
      <link>https://stats.stackexchange.com/questions/638243/help-me-understand-z-coefficients</link>
      <description><![CDATA[在处理样本大小方程时，使用 Z 系数 Z$\alpha$ 和 &lt; em&gt;Z$\beta$ 这是 I 类和 II 类错误率的 Z 系数。这些系数来自标准正态分布。
如果您正在使用的数据不是正态分布，这有什么关系吗？具体来说，我正在处理 beta 分布的植被数据。我是否需要使用不同分布的系数，或者这与采样数据无关？]]></description>
      <guid>https://stats.stackexchange.com/questions/638243/help-me-understand-z-coefficients</guid>
      <pubDate>Wed, 31 Jan 2024 22:00:52 GMT</pubDate>
    </item>
    <item>
      <title>谁能帮助我找到错误并运行此 R 代码来模拟孟德尔随机化研究中的平衡多效性效应？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638242/could-anyone-help-me-to-locate-error-and-run-this-r-code-to-simulate-for-balance</link>
      <description><![CDATA[参数取值为 NA [请参考图片]。我是否错过了与信息“temp = as.integer(commandArgs(trailingOnly = TRUE))”相关的代码的任何部分
具有平衡多效性和违反 InSIDE 假设的摘要级模拟
rm(列表=ls())
库（数据.表）
图书馆（dplyr）
图书馆（大众）
库（孟德尔随机化）
库（MRMix）
图书馆（拉普斯先生）
库（MRPRESSO）
图书馆（受处罚）
来源（“MR_lasso.R”）
thetavec = c(0.2, 0, -0.2)
θUvec = c(0.3, 0.5)
Nvec = c(5e4, 8e4, 1e5, 1.5e5, 2e5, 5e5, 1e6) # 1:7
prop_invalid_vec = c(0.3, 0.5, 0.7)
temp = as.integer(commandArgs(trailingOnly = TRUE))
theta = thetavec[temp[1]] # 从 X 到 Y 的真实因果效应
thetaU = thetaUx = thetaUvec[temp[2]] # 混杂因素对 Y/X 的影响
N = Nvec[temp[3]] # 曝光 X 的样本大小
prop_invalid = prop_invalid_vec[temp[4]] # 无效 IV 的比例
pthr = 5e-8 # 工具选择的 p 值阈值
NxNy_ratio = 2 # X 和 Y 的样本大小比率
M = 2e5 # 代表基因组中常见变异的独立 SNP 总数
效应大小分布的模型参数
pi1=0.02*(1-prop_invalid); pi3=0.01
pi2=0.02prop_invalid;
sigma2x = sigma2y = 5e-5；西格玛2u = 1e-4; sigma2x_td = sigma2y_td = (5e-5)-thetaUthetaUx*sigma2u
print(paste(“N”, N, “pthr”, pthr, “pi1”, pi1, “theta”, theta, “thetaU”, thetaU, “prop_invalid”, prop_invalid, “ ;NxNy_ratio”,NxNy_ratio))
请指导我同样的事情
谢谢
西尔维娅]]></description>
      <guid>https://stats.stackexchange.com/questions/638242/could-anyone-help-me-to-locate-error-and-run-this-r-code-to-simulate-for-balance</guid>
      <pubDate>Wed, 31 Jan 2024 21:52:24 GMT</pubDate>
    </item>
    <item>
      <title>时间序列交叉验证和避免过度拟合</title>
      <link>https://stats.stackexchange.com/questions/638241/time-series-cross-validation-and-avoidance-of-overfitting</link>
      <description><![CDATA[所以。我正在使用不同类型的分类器（深度学习、基于字典、基于距离、基于间隔、基于特征、卷积）对各种数据集进行时间序列分类。据我所知，k-fold 对于时间序列来说不是一个好的选择，所以我改用了 TimeSeriesSplit。然而，当然，即使进行交叉验证，也不能保证过度拟合。 K-fold 通过洗牌解决了这个问题，但 TimSeriesSplit 没有这样做（实际上，这就是重点）。我会使用 Dropout Layers 或正则化，但这些技术仅适用于深度学习模型，我的目标基本上是比较所有这些算法的结果。在我的例子中，什么是适用于所有类型分类器的好技术？]]></description>
      <guid>https://stats.stackexchange.com/questions/638241/time-series-cross-validation-and-avoidance-of-overfitting</guid>
      <pubDate>Wed, 31 Jan 2024 21:35:56 GMT</pubDate>
    </item>
    <item>
      <title>如何评估事件在群体内的影响</title>
      <link>https://stats.stackexchange.com/questions/638240/how-to-assess-effect-of-event-within-group</link>
      <description><![CDATA[我正在尝试为我的组织对投诉处理系统的变化进行分析，看看它是否对一些人口变量（主要是性别和种族，因为有很多人口统计变量）产生了任何不利影响。其他变量的数据缺失）。
2019 年，我们从一个系统转向了另一个系统。在新系统中，进入组织的所有信息均由 2019 年之前不存在的团队处理。感兴趣的结果是投诉是否已进展到另一个团队，以及投诉是否随后进展到纪律处分（两个投诉流程的每个部分都需要单独分析）。
通过新系统，我们现在记录了更多的投诉，只有一小部分得到了进展，这意味着新系统在任何看待这一问题的模型中都不可避免地会产生相当大的影响。这使得观察干预前和干预后对于整个人群来说有点毫无意义，但在群体内可能会看到一些有趣的趋势，而这正是最令人感兴趣的。
我正在尝试找出最好采取什么方法来测试系统的变化是否对团体产生了任何不利影响。就投诉标记的信息而言，两个系统之间的数据并不完全匹配，这使得只有少数变量可以使用，从而很难控制大量潜在的差异。还有一个问题是同一个人可能会受到多次投诉（这是否会造成面板不平衡？）。
我一直在研究中断时间序列分析，但这似乎更适合在人口水平上观察事物，而不是在群体差异内。差异之差方法也是如此。

我想知道是否有一个基本的逻辑回归模型
虚拟变量与人口变量相互作用后
兴趣可能是出路？这种方法有意义吗？
我怎样才能包含尽可能多的数据，同时还可以控制
某些个体多次出现在数据集中？
是否有一种中断时间序列分析方法，可以对同一群体内的不同组进行逐步回归，然后比较不同组之间的结果？这似乎是最简单的方法，但我还没有找到任何这方面的文献，这让我认为这可能不是可行的方法。
总体上最好采取哪种方法？

我觉得我现在正在创建一个垃圾输入、垃圾输出模型，特别是考虑到缺乏可用的有用变量，并且不知道采取的最佳方法。任何帮助将非常感激。我以前没有做过这么复杂的数据的干预分析，有点力不从心。]]></description>
      <guid>https://stats.stackexchange.com/questions/638240/how-to-assess-effect-of-event-within-group</guid>
      <pubDate>Wed, 31 Jan 2024 21:12:46 GMT</pubDate>
    </item>
    <item>
      <title>比较和选择模型，构建目标函数（复杂性、参数值分布的先验知识）</title>
      <link>https://stats.stackexchange.com/questions/638235/comparing-and-selecting-models-constructing-objective-function-complexity-pri</link>
      <description><![CDATA[我们有一组模型，这些模型是使用一些拟合例程导出的，这些例程利用给定模型的 $\chi^2$ 来优化参数值。
model1 有 100 个参数，
model2有99个参数，
...
model10 有 10 个参数..
所有参数都是使用回归技术估计的，但模型结构不同（例如，从最大复杂度下降到最低复杂度）。
所有比较模型的数据始终相同。
所有估计的参数值在现实生活中都有一些已知的分布。我们有关于此分布的先验知识，例如，n.d.有一些均值和方差（对于每个参数）。
我们希望将该信息用于两个目的：

用于比较和选择最佳模型（例如，如果我们需要比较给定数据的各种模型，但我们不知道这些模型是如何得出的）。

回归 - 将信息纳入目标函数。
使用有关参数分布的先验知识来选择更可能的参数（在给定数据和参数分布的先验知识的情况下，最大化参数值的可能性）。


这里的问题是：

我们是否可以比较不同复杂度的模型，因为我们可以计算 chi2 值 - 这将是拟合优度，也可能是在给定数据的情况下具有此类参数的可能性或概率度量？或者，如果每个模型具有不同数量的参数，那么从似然/概率函数计算的角度来看，这不是一个正确的公式？

例如，AIC/BIC (c) 使用 $\chi^2$ 值并对参数 k 的数量进行惩罚。尽管如此，它并不关心参数的值（这可能非常不可能，物理约束等）。
在我们的例子中，我们有先验信息。例如，添加如下内容：
$$OF = \chi^2 + 2 * PL$$
其中 PL - 是根据一些先验知识计算得出的术语。
例如，我们可以计算给定数据的模型复杂性概率的某个值和/或具有多个参数值的概率度量...给定参数分布。
注意 - 所有参数都源自相同的数据，但我们不关心它们是如何获得的。我们只关心他们的价值观和合身质量。
因此 PL 必须使用我们关于参数分布的知识来计算。
但是计算 PL 并比较不同模型复杂性的测量值是否正确？这种方法可能存在哪些问题？看来它与贝叶斯推理密切相关..]]></description>
      <guid>https://stats.stackexchange.com/questions/638235/comparing-and-selecting-models-constructing-objective-function-complexity-pri</guid>
      <pubDate>Wed, 31 Jan 2024 20:32:00 GMT</pubDate>
    </item>
    <item>
      <title>bagging成功的说明</title>
      <link>https://stats.stackexchange.com/questions/638231/explanation-for-the-success-of-bagging</link>
      <description><![CDATA[我正在阅读机器学习 - 工程师和科学家的第一门课程。在第 168 页，他们粗略地解释了 bagging 为何有效。我对他们的解释有点困惑。
他们考虑$B$引导数据集的集合$\mathcal{T}^{(b)}$  与 $b=1,2, \ldots, B$。它们表示来自 $b$ 个引导数据集 $\mathcal{T}^{(b)}$ 的预测 （取自原始数据集 $\mathcal{T}$）并在点 $\mathbf 处进行评估{x}_\star$ 为 $\tilde{y}^{(b)}_\star \equiv y(x_\star; \mathcal{T} ^{(b)})$。他们假设这些预测的平均值是
$$ \mathbb{E}[\tilde{y}^{(b)}_\star] = \mu^2$$
方差是
$$ \mathrm{Var}[\tilde{y}^{(b)}_\star] = \sigma^2$$
预测之间的平均相关性是
$$ \text{avg cor}[\tilde{y}^{(b)}_\star] =\frac{1}{B(B-1)}\sum_ {b\ne c}\mathbb{E}[(\tilde{y}^{(b)}_\star-\mu)(\tilde{y}^{(c)}_\star-\mu) ] = \rho \sigma^2$$
他们指出
&lt;块引用&gt;
“所有基础模型及其预测均源自相同的数据 $\mathcal{T}$ （通过引导程序）和 $\tilde{y}^{(b)}_\star$ 因此分布相同但相关。”

他们的解释是这样的：袋装预测的平均值是
$$ \mathbb{E}[\frac1B \sum^B_{b=1}\tilde{y}^{(b)}_\star] = \sigma^2$ $
方差是
$$ \mathrm{Var}[\frac1B \sum^B_{b=1}\tilde{y}^{(b)}_\star] = \frac{1- \rho}{B} \sigma^2+\rho \sigma^2 $$
如果$\rho&lt;1$，则通过增加引导样本来减少方差。
我对他们如何将 $\tilde{y}^{(b)}_\star$ 视为随机变量感到有点困惑，即概率是多少我们对 $\mathbb{E}[\tilde{y}^{(b)}_\star]$ 进行平均分布吗？由于引导过程减少了预期新数据误差的偏差-方差分解中的方差，因此我假设随机性来自原始数据集 $\数学{T}$。但是我们是否假设引导样本的索引是固定的（即 ${\mathcal{T}&#39;}^{(b)}$ 始终是通过取带有索引的数据点 $i \in \lbrace i^{(b)}_1, i^{(b)}_2, \ldots, i^{(b)}_n \rbrace $ 但 ${\mathcal{T}&#39;}^{(b)}$ 是随机的），或者它们在 $\mathcal{T}$ ?
另外，谁能直观地解释一下什么样的数据和模型特征会增加$\rho$？]]></description>
      <guid>https://stats.stackexchange.com/questions/638231/explanation-for-the-success-of-bagging</guid>
      <pubDate>Wed, 31 Jan 2024 19:21:51 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法使用预定义的 GARCH 模型或从 rmgarch 包 R 的 dccspec 中另一个自定义模型过滤的标准偏差值？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638230/is-there-any-way-to-use-a-predefined-garch-model-or-filtered-standard-deviation</link>
      <description><![CDATA[dccspec(uspec = multispec(replicate(10, spec) ),
                            dcc顺序 = c(1,1),
                            分布=“mvnorm”，
                            型号 = &#39;aDCC&#39;)

在 dccspec 的参数中，我想集成定制的 GARCH 模型或至少集成该模型的标准差值，并希望 DCC 模型仅估计相关性。
运行上面的代码会出现以下错误：
h(simpleError(msg, call)) 中的错误：
  在为函数“dccspec”选择方法时评估参数“uspec”时出错：
不是单变量 GARCH 规范的有效列表。
]]></description>
      <guid>https://stats.stackexchange.com/questions/638230/is-there-any-way-to-use-a-predefined-garch-model-or-filtered-standard-deviation</guid>
      <pubDate>Wed, 31 Jan 2024 19:03:38 GMT</pubDate>
    </item>
    <item>
      <title>最小化零一损失与最小化铰链损失何时不同</title>
      <link>https://stats.stackexchange.com/questions/638227/when-is-minimizing-zero-one-loss-different-than-minimizing-hinge-loss</link>
      <description><![CDATA[假设我们使用线性预测器，我试图从概念上理解对于一组点，它如何具有相对较低的 0-1 损失但相对较高的铰链损失。例如，有人告诉我，可以选择一组点，使得所有这些线性预测变量的 0-1 损失最小（即 $p_w(x) = \langle w, x \rangle$），其中 $w$ 位于二维平面中）低于 0.1，但对于同一组点，预测器最小化铰链损失有 0-1 损失，高于某个阈值，例如 $0.5$。也就是说，寻求最小化铰链损失可能会导致同一预测器的 0-1 损失（与具有最佳 0-1 损失的预测器相比）。
针对这个问题，在我看来，学习了SVM之后，一直很难理清0-1损失和铰链损失的概念。我对铰链损失的理解是，随着错误分类的点进一步增加，它会变得更大，但对我来说，“最小化铰链损失”的预测器会带来什么并不直观。对于给定的一组点来说，它看起来像这样，而它是立即的，至少在 $\mathbb{R^2}$ 中，对我来说显然是最小化的超平面0-1 输球的样子。谁能帮助我获得一些直觉并理解这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/638227/when-is-minimizing-zero-one-loss-different-than-minimizing-hinge-loss</guid>
      <pubDate>Wed, 31 Jan 2024 18:40:41 GMT</pubDate>
    </item>
    <item>
      <title>稀疏 0,1 数据的分布选择</title>
      <link>https://stats.stackexchange.com/questions/638221/distributional-choices-for-sparse-0-1-data</link>
      <description><![CDATA[我正在使用 GAM 对二元响应变量（0 或 1）与几个连续固定和随机解释变量之间的关系进行建模。看起来二项分布是标准选择，但数据非常稀疏，有 21,000 个 0，只有大约 800 个 1。
我很好奇是否还有其他发行版可以更好地处理这些数据？我对 beta 二项式很​​感兴趣，但据我了解，它适用于 0 到 1 之间的数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/638221/distributional-choices-for-sparse-0-1-data</guid>
      <pubDate>Wed, 31 Jan 2024 17:26:24 GMT</pubDate>
    </item>
    <item>
      <title>测量不变性分析是否假设各组之间的潜在分数相等？</title>
      <link>https://stats.stackexchange.com/questions/638210/does-measurement-invariance-analysis-assume-equal-latent-scores-across-groups</link>
      <description><![CDATA[我已经完成了一项测量不变性分析，比较了高中年龄男孩和高中年龄女孩的抑郁程度。结果表明分数不是（标量）不变；女孩报告的抑郁症状往往比“实际”更严重。抑郁程度会表明。此外，结果表明，与男孩相比，女孩在每一项上报告的症状都比其实际抑郁水平所显示的更严重（即具有更高的潜在拦截）。&lt;​​/p&gt;
我正在努力理解这种方法如何区分（a）标量测量方差，即系统性地多报或少报抑郁症状的群体，以及（b）样本内抑郁症的实际差异。在估计参与者的潜在抑郁分数时，我们只有他们的反应，那么我们如何得出结论，他们在每个项目上高估或低估了他们的抑郁水平？我能想象得出这个结论的唯一方法是首先假设两组的真实潜在均值是相等的（即这个样本中的男孩和女孩同样抑郁）——这是假设的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638210/does-measurement-invariance-analysis-assume-equal-latent-scores-across-groups</guid>
      <pubDate>Wed, 31 Jan 2024 16:10:39 GMT</pubDate>
    </item>
    </channel>
</rss>