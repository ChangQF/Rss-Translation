<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 16 May 2024 06:16:48 GMT</lastBuildDate>
    <item>
      <title>随机斜率与包含分组因素和焦点预测变量之间的相互作用</title>
      <link>https://stats.stackexchange.com/questions/647336/random-slopes-vs-including-an-interaction-between-grouping-factor-and-focal-pred</link>
      <description><![CDATA[一个人运行以下随机斜率模型，其中 ses 是焦点预测变量，schcode 是分组因子（因此模型方程中未提及）
$Y_{ij} = \gamma_{00} + \gamma_{01}\text{ses_mean}_{0j} + \gamma_{02}\text{pro4yrc} _{0j} + \gamma_{03}\text{public}_{0j} + \gamma_{10}\text{ses}_{ij} + u_{0j} + u_{1j}\text{ses}_ {ij} + \epsilon_{ij}$
然后，他们考虑删除随机斜率，转而在分组因子 schcode 和焦点预测变量 ses 之间进行交互。 schcode 的随机截取仍将保留。因此，模型如下所示：
$Y_{ij} = \gamma_{00} + \gamma_{01}\text{ses_mean}_{0j} + \gamma_{02}\text{pro4yrc} _{0j} + \gamma_{03}\text{public}_{0j} + \gamma_{04}\text{schcode}_{0j} + \gamma_{10}\text{ses}_{ij} + \gamma_{14}\text{ses}_{ij} \times \text{schcode}_{0j} + u_{0j} + \epsilon_{ij}$
不知何故，第二个模型对我来说似乎很奇怪，因为 schcode 是随机结构和固定结构的一部分，但是至少有该网站上的一个回复中，一位非常权威的消息来源建议这样做是可以的（尽管在与此处考虑的情况完全不同的情况下）。
第二个模型是否明智？为什么/为什么不呢？与第一个模型相比，它的优点和缺点是什么？
我更关心这里的一般原则而不是特定的数据集，但我也对这个特定数据集的意义感兴趣。
示例代码在这里：
图书馆（避风港）
图书馆(lme4)

d &lt;- read_sav(file =“https://github.com/user1205901/codeforposting/blob/main/ch3multilevel.sav?raw=true”)

model1 &lt;- lmer(数学 ~ 1 + ses + ses_mean + pro4yrc + public + (ses||schcode), data = d)
摘要（模型1）

model2 &lt;- lmer(math ~ 1 + ses_mean + pro4yrc + public + ses + ses*schcode + (1|schcode), data = d)
摘要（模型2）
]]></description>
      <guid>https://stats.stackexchange.com/questions/647336/random-slopes-vs-including-an-interaction-between-grouping-factor-and-focal-pred</guid>
      <pubDate>Thu, 16 May 2024 06:04:07 GMT</pubDate>
    </item>
    <item>
      <title>计算具有时变协变量的数据</title>
      <link>https://stats.stackexchange.com/questions/647330/count-data-with-time-varying-covariates</link>
      <description><![CDATA[对计数数据进行建模的一种方法是简单地计算事件数量作为结果，并加上观察时间的偏移（如果观察时间因人而异）。我认为如果您有一个重要的暴露变量，您可能希望以与时间相关的方式包含该变量，那么也可以对计数数据进行建模 - 即数据然后被格式化为计数过程形式。那么在这里，您将在曝光变化时分割不同的观察时间，计算每个间隔中的事件数量，并仍然指定间隔长度作为曝光？
在这种情况下，您需要采取任何措施来调整标准误差吗？即模型是否假设行之间独立，或者是否像 Cox 模型一样，这并不重要。标准的 glm 是否有效，或者我是否需要考虑一些可以解释潜在相关性的东西，例如 gl(mixed)m？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/647330/count-data-with-time-varying-covariates</guid>
      <pubDate>Thu, 16 May 2024 03:48:44 GMT</pubDate>
    </item>
    <item>
      <title>基于曲线预测连续变量</title>
      <link>https://stats.stackexchange.com/questions/647329/predicting-continuous-variable-based-on-curve</link>
      <description><![CDATA[我有一组在不同频率下测量的曲线的数据集，因此它由如下图所示的曲线组成。当然，我的数据集还有更多曲线。曲线与连续因变量（例如高度）相关联。哪种机器学习方法可以让我根据整个曲线来预测因变量的值？
我想过线性混合效应，但是有没有一种机器学习方法，例如高斯过程，有谁知道我如何做到这一点的例子？
我没有高斯过程的经验，但我想学习如何做到这一点。
谢谢，非常感谢您的帮助。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647329/predicting-continuous-variable-based-on-curve</guid>
      <pubDate>Thu, 16 May 2024 00:53:41 GMT</pubDate>
    </item>
    <item>
      <title>测试时间序列数据的平稳性</title>
      <link>https://stats.stackexchange.com/questions/647327/testing-time-series-data-stationarity</link>
      <description><![CDATA[我正在处理时间序列，想要测试不同的预测方法，但首先我需要测试我的时间序列（销售）数据是否稳定。所以我一直在学习KPSS和Dickey-fuller测试。我的数据是以百万美元为单位的货币价值
我是个新手，所以我仍在学习、阅读和观看有关如何操作的教程。我开发了一个 dickey-fuller：

无漂移：
t-stat=-1.6899
有漂移：
t-stat=9.9672
漂移+趋势：
t-stat=-9.9099
增强（2 个滞后）：
t-stat=-4.6365

我的最全面的关键价值观是：

&lt;标题&gt;

值
无趋势
趋势


&lt;正文&gt;

1%
-3.43
-3.96


5%
-2.86
-3.41



我所看到的（如果我错了，请纠正我）是，除了“无漂移”之外的所有内容都可以。 t-stat 显示我的时间序列数据是平稳的。
第一个问题：我是否可以假设因为 4 个 t 统计中有 3 个通过了平稳性测试，所以我的系列数据是平稳的？我不清楚如果无漂移 t-stat 显示不平稳，我应该得出什么结论。
第二个问题：我的累积残差没有加到零，所以这意味着我做错了什么？
因为我对Dickey-fuller感到困惑，所以我也参加了KPSS测试。以下是我的结果：

&lt;标题&gt;

值
常量
常量 + 趋势


&lt;正文&gt;

KPSS
0.02090016
0.020655886


临界值95%
0.463
0.146


临界值99%
0.739
0.216



因此，因为我的临界值高于我的 KPSS 统计数据，所以我接受零假设，并且我的数据系列是平稳的。
完成所有测试后，看起来我的数据确实是静止的，但我不确定我的残差没有加到零这一事实是否意味着我做错了什么，并且 t-stat 是否没有漂移，表明单位根的存在与我继续使用需要固定数据的预测方法相关。
如果您可以支持我，请告诉我。
提前谢谢您。
正如我之前提到的：
创建数据图表
迪基富勒测试
没有漂移，
随着漂移，
漂移+趋势，
增强（2 个滞后），以及
KPSS - 您可以看到上面的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/647327/testing-time-series-data-stationarity</guid>
      <pubDate>Thu, 16 May 2024 00:13:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用泊松和高斯族对泊松数据进行 glm 拟合几乎没有差异？</title>
      <link>https://stats.stackexchange.com/questions/647325/why-is-there-little-difference-in-glm-fit-using-poisson-and-gaussian-family-for</link>
      <description><![CDATA[我一直对模拟泊松分布数据的玩具回归问题感到困惑，并希望受过更多统计学教育的人可以帮助我对以下观察结果有一些了解。
使用的库
库(tidyverse)
图书馆（牛区）
图书馆（扫帚）
库（基于模型）
库（参数）
图书馆（ggbeeswarm）

数据生成
我使用 rpois 模拟了两种场景的计数值：

交通事故计数，其中 lambda 与交通量成线性比例。
当 lambda 按交通量指数缩放时的交通事故计数。

# 观察值
n_obs = 10

# 生成日志相关数据
流量 = log(c(1, 2, 4, 7, 10, 15))
日志数据=小标题（
  流量=流量_流量，
  lambda=exp(0.43*体积+0.2)
) %&gt;%
  逐行 %&gt;%
  mutate(accident_counts = list(rpois(n_obs, lambda = lambda))) %&gt;%
  突变（observed_avg_accidents = 平均值（accident_counts））

# 生成线性相关数据
线性数据=小标题（
  流量=流量_流量，
  拉姆达 = 0.43*体积 + 0.2
) %&gt;%
  逐行 %&gt;%
  mutate(accident_counts = list(rpois(n_obs, lambda = lambda))) %&gt;%
  突变（observed_avg_accidents = 平均值（accident_counts））

建模
我为每个数据集拟合了两个 glms。一种使用gaussian族，另一种使用poisson族。我对日志数据使用了“log”链接器，对线性数据使用了“identity”链接器。
# 适合
proc_list = 列表(
  日志=列表（数据=log_data，链接器=“日志”），
  线性=列表（数据=线性_数据，链接器=“身份”）
）
模型 = 地图（proc_list，函数（proc）{
  泊松模型 &lt;- glm(
    事故计数 ~ 数量，
    数据 = proc$data %&gt;% unnest(accident_counts),
    家庭=泊松（链接= proc $链接器），
  ）
  高斯模型 = glm(
    事故计数 ~ 数量，
    数据 = proc$data %&gt;% unnest(accident_counts),
    族=高斯(link=proc$linker),
    开始=c(1, 1)
  ）
  返回（列表（“泊松”= poisson_model，“高斯”= gaussian_model））
})

结果
&lt;代码&gt;&gt; Compare_models(unlist(模型，递归=FALSE))

参数|对数泊松 |对数高斯 |线性泊松|线性高斯
-------------------------------------------------- ----------------------------------------------------------
（拦截）| 0.01（-0.40，0.43）| -0.03 (-0.59, 0.53) | 0.39（0.06，0.73）| 0.43（-0.08，0.94）
卷 | 0.52（0.32，0.72）| 0.54（0.30，0.79）| 0.36（0.13，0.59）| 0.34（0.05、0.62）
-------------------------------------------------- ----------------------------------------------------------
观察| 60| 60| 60| 60

可视化
# 创建可视化网格并预测值
viz_grid = modelbased::visualization_matrix(tibble(volume=traffic_volume)) %&gt;% as_tibble
增强=map_df（unlist（模型，递归= FALSE），函数（.x）{
  增强（.x，newdata = viz_grid，type.predict =“响应”）
}, .id=&quot;型号&quot;)

# 单独的模型和数据标签
增强=增强%&gt;%
  split(“模型”, c(“数据”, “回归”), sep=&quot;\\.&quot;)

p = map_df(proc_list, ~.x$data, .id=&quot;数据&quot;) %&gt;%
  解除嵌套（事故计数）%&gt;%
  ggplot(aes(体积, 事故计数)) +
  # geom_violin(调整=1.5) +
  geom_quasirandom() +
  几何点（
    data=~.x %&gt;% unique(数据、体积、observed_avg_accidents),
    aes（数量，observed_avg_accidents），
    颜色＝“红色”
  ) +
  geom_line(数据=增强，aes(体积，.fitted，颜色=回归)) +
  facet_wrap(~data, labeller=label_both) +
  主题灰色(base_size=16)
p %&gt;% ggsave(file=“temp.pdf”, w=8, h=4)


问题
为什么无论家庭功能如何，拟合基本上没有差异？我故意选择了少量的观察值和相对较小的 lambda 值，希望使用高斯拟合家庭会崩溃。但这并没有发生。如果这里的数据生成过程真的是泊松分布，那么族函数的选择不会影响拟合吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647325/why-is-there-little-difference-in-glm-fit-using-poisson-and-gaussian-family-for</guid>
      <pubDate>Wed, 15 May 2024 23:10:11 GMT</pubDate>
    </item>
    <item>
      <title>PCA 因子模型 - 无关紧要的因子载荷</title>
      <link>https://stats.stackexchange.com/questions/647324/pca-factor-model-insignificant-factor-loadings</link>
      <description><![CDATA[我有一个包含 N 个资产的时间序列，我正在尝试为其估计因子模型。令 $Z_{t}$ 为这些资产在 $t$ 时的价格之一。我们可以将其写为：
$$
Z_{t} = β F_{t} + θ_{t}
$$
其中 $F_{t}$ 是一些线性因子，$\theta_{t} = \alpha + \ epsilon_{t}$，$\epsilon_{t}$ 是一些具有协方差的白噪声 $\Sigma_ {\theta}$
有了这些假设，我们可以将 $Z_{t}$ 的期望值写为：
$$
\mu_{z} = \alpha + \beta \mu_{F}
$$
协方差矩阵：
$$
\Sigma_{z} = \beta\Sigma_{\theta}\beta^{T} + \Sigma_{\theta}
$$
我们的想法是，我们显着减少了需要估计的参数数量（尤其是协方差），因此（希望）估计出噪声较小的均值和协方差。
如果有一些股票投资组合，其投资组合权重为 $\mathbb{x}$，那么我们可以将投资组合均值写为 $\mu_{p} = \mathbb{b}\mu_{F}$，其中 $\mathbb{b} = \beta^{T }\mathbb{x}$ 和投资组合协方差为 $\mathbb{b}^{T}\Sigma_{F}\mathbb{b} + \mathbb{ x}^{T}\Sigma_{\theta}\mathbb{x}$。
我选择对贬低数据矩阵进行 SVD 分析作为因子模型（可以证明这相当于对协方差进行 PCA）。这非常方便，因为协方差矩阵 $\Sigma_{F}$ 与特征值平方成对角线。一旦我获得了 PC，我的 $F_{t}$，我就会估算 $\beta$ OLS 参数（但是，我也尝试了一些其他方法，例如迭代重新加权最小二乘法）。然而，在诊断分析中我可以看到这些参数并不重要。我对此有点困惑。一方面，我将其理解为只是一种线性代数方法，即最小二乘法只是一种用于查找因子的数值方法，那么显着性应该不重要（与推理意义上的回归不同）。即便如此，如果我的参数接近于零（微不足道），那么我的因子并没有真正..正确分解..。
有人可以向我解释一下这个结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647324/pca-factor-model-insignificant-factor-loadings</guid>
      <pubDate>Wed, 15 May 2024 23:05:28 GMT</pubDate>
    </item>
    <item>
      <title>条件期望算子是否像线性代数中的投影矩阵那样具有可解释的分解？</title>
      <link>https://stats.stackexchange.com/questions/647323/does-the-conditional-expectation-operator-have-an-interpretable-decomposition-li</link>
      <description><![CDATA[我试图将有限线性空间中的投影概念与无限线性空间中的投影概念进行比较。
这是设置，首先是有限维情况，然后是无限维情况：
给定一个单射矩阵 $A: \mathbb{R}^m \rightarrow \mathbb{R}^n$，我们可以构造一个正交投影算子让$P_A = A(A^TA)^{-1}A^T$。然后我们可以用它来获取 $y \in \mathbb{R}^n$ 并将其投影到 $A$ 得到 $P_A y = x \in \text{col(A)}$。
现在假设我们有两个随机变量 $X$ 和 $Y$，其二阶矩存在。条件期望 $\mathbb{E}[X|Y]$ 为我们提供了一些新的随机变量 $h(Y) $ 即 $X$ 到 $\sigma(Y)$ 的正交投影，$Y$ 的 sigma 代数。
我的问题是，在条件期望情况下是否存在与 $A$ 类似的可解释的类比。也就是说， $\mathbb{E}[X|Y]$ 是 $P_A$ 作为 [ ???] 是 $A$。
我看到用户 ExcitedSnail 在这里&lt; /a&gt;，但问题下面的评论似乎没有解决问题，除非我只是误解了。]]></description>
      <guid>https://stats.stackexchange.com/questions/647323/does-the-conditional-expectation-operator-have-an-interpretable-decomposition-li</guid>
      <pubDate>Wed, 15 May 2024 21:59:19 GMT</pubDate>
    </item>
    <item>
      <title>在回归模型中包含不相关变量时的方差比</title>
      <link>https://stats.stackexchange.com/questions/647322/variance-ratio-when-including-irrelevant-variables-in-a-regression-model</link>
      <description><![CDATA[我有兴趣知道是否有一个通用公式来计算正确指定模型和错误指定模型中预测变量的回归系数方差之比。
具体来说，假设我们有一组与回归 X 真正相关的变量和一组与回归 Y 不相关的变量，并且我们做了两个回归。
首先，我们进行 $y = X\beta_1$ 形式的加权最小二乘回归，这是正确的，并给出了 $\hat{\beta_1}$。
然后，我们进行形式为 $y = X\beta_1 + Y\beta_2$ 的加权最小二乘回归，这是正确的，给出的系数估计为$\tilde{\beta_1}$。
我有兴趣以封闭形式描述比率 $var(\hat{\beta_1}) / var(\tilde{\beta_1})$。&lt; /p&gt;
对于普通的未加权线性回归，Fomby 表现出回归分析效率损失，原因是
不相关变量：根据预测变量 $r_i$ 之间的典型相关性，两个模型中的方差比存在一个封闭形式 $var(\hat{\beta_1}) / var(\tilde{\beta_1}) = \prod_i \frac{1}{1 - r_i^2}$。
对于加权最小二乘法的情况，是否有一个清晰的概括？]]></description>
      <guid>https://stats.stackexchange.com/questions/647322/variance-ratio-when-including-irrelevant-variables-in-a-regression-model</guid>
      <pubDate>Wed, 15 May 2024 21:57:27 GMT</pubDate>
    </item>
    <item>
      <title>如何互相关两个大小差异很大的数据序列？</title>
      <link>https://stats.stackexchange.com/questions/647332/how-to-cross-correlate-two-data-sequences-with-considerable-differences-in-size</link>
      <description><![CDATA[我需要对表示视频信号的两个帧序列进行互相关。但是，视频以不同的方式压缩。
第一个数据 (dados) 数组有 17167 帧，第二个 (dados2) 有 90083 帧
frame_sizes = np.loadtxt(&#39;/home/demori/jnotebook/camera_estac_mpeg_low.txt&#39;)
frame_sizes2 = np.loadtxt(&#39;/home/demori/jnotebook/camera_estac_h263_16k.txt&#39;)

# 将frame_sizes转换为DataFrame
bados = pd.DataFrame(frame_sizes, columns=[&#39;FrameSize&#39;])
bados2 = pd.DataFrame(frame_sizes2, columns=[&#39;FrameSize&#39;])

我正在使用 np.correlate 进行互相关
correlation = np.correlate(dados[&#39;FrameSize&#39;], dados2[&#39;FrameSize&#39;], mode=&#39;full&#39;)

滞后 = np.arange(-len(dados[&#39;FrameSize&#39;])+1, len(dados2[&#39;FrameSize&#39;]))
相关性 /= np.max(相关性)

plt.figure(figsize=(10, 5))
plt.stem（滞后，相关性）
plt.title(&#39;Correlação Cruzada entre MPEG Low e H263 16k&#39;)
plt.xlabel(&#39;滞后&#39;)
plt.ylabel(&#39;Correlação Cruzada Normalizada&#39;)
plt.show()

这是我得到的结果（附图）。我不知道这是否是进行互相关的最佳方法
在此处输入图片说明]]></description>
      <guid>https://stats.stackexchange.com/questions/647332/how-to-cross-correlate-two-data-sequences-with-considerable-differences-in-size</guid>
      <pubDate>Wed, 15 May 2024 21:18:26 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试拟合一个混合效应模型，并以比例作为响应。我很困惑哪个分布适合我的模型</title>
      <link>https://stats.stackexchange.com/questions/647316/i-am-trying-to-fit-a-mixed-effects-model-with-a-proportion-as-the-response-im</link>
      <description><![CDATA[目前，这是我最适合的模型。 dHARMA 看起来不太好。响应有许多 0 和许多 1
model_pollen_species.bi &lt;- glmmTMB(proportion_sunflower ~ 物种 +
                    (1|农场) + (1|日期) + (1|Bee.ID),
                    家庭=二项式（链接=“logit”），
                    数据=组合花粉）
                             
诊断（model_pollen_species.bi）

模拟.model_pollen_species.bi &lt;-
     模拟残差（fittedModel = model_pollen_species.bi）

情节（模拟.model_pollen_species.bi）

dHARMA 残差：
]]></description>
      <guid>https://stats.stackexchange.com/questions/647316/i-am-trying-to-fit-a-mixed-effects-model-with-a-proportion-as-the-response-im</guid>
      <pubDate>Wed, 15 May 2024 20:45:12 GMT</pubDate>
    </item>
    <item>
      <title>如何改进双向重复测量方差分析的 R 代码以产生正确的自由度？</title>
      <link>https://stats.stackexchange.com/questions/647333/how-can-i-improve-my-r-code-for-a-two-way-repeated-measures-anova-to-produce-the</link>
      <description><![CDATA[我正在 rstudio 中运行双向重复测量方差分析，我发现分析的输出产生了一些奇怪的自由度，我担心分析结果不准确。当我认为残差应该小于 30 时，我的残差是 352，尽管有 12 个时间点，但我的“点”的 df 为 352。部分输出只是 1。
上下文：我正在尝试比较 3 个条件下 12 个时间点的中毒评分。我的数据集有 30 个主题，每个主题有 12 个条目对应 12 个时间点。我相信这个问题是由 R 将 360 行解释为单独的组引起的，并且也没有认识到“点”有 12 个级别。因素。
我的 RM 方差分析输出如下所示：
错误：在范围内
                 Df Sum Sq Mean Sq F 值 Pr(&gt;F)
点 1 15.4 15.444 14.774 0.000144 ***
条件 2 36.8 18.410 17.611 5.13e-08 ***
点：条件2 0.4 0.176 0.169 0.844842
残差 352 368.0 1.045

我的数据集的片段
ID 状况日 Intox_score 点
2341 吨 1 0 1
2341 吨 1 1 2
2341 吨 1 0 3
2341 吨 2 3 4
2341 吨 2 2 5
2341 吨 2 3 6
2341 吨 3 0 7
2341 吨 3 2 8
2341 T 3 3 9
2341 吨 4 2 10
2341 吨 4 1 11
2341 T 4 1 12

我想补充一点，我是一个非常缺乏经验的用户，并且到目前为止已经使用基础 R 完成了所有可能的分析。如果仍然可以使用基本 R 来解决问题，那就更好了。我纠正问题的时间有限，我担心学习使用另一个包并重新进行分析。我也可能误解了此处自由度的统计组成部分，但我认为无论哪种方式我都能够产生可靠的结果。
我尝试使用 aov() 函数，我相信它是 R 的基础函数，我的代码如下所示：
behint_rm_anova &lt;- aov(Intox_score ~ 点 * 条件 + 错误(ID/点), 数据 = Behavioral_intox_data_v4_for_R)

摘要（behint_rm_anova）

我预计“Point”的自由度是我的因子水平 (12) 减去 1 = 11
相反，我的输出仅显示自由度 1。
我还预计我的残差为 27（30 个受试者 - 3 组），但我的输出显示 352。
我尝试将代码中的错误术语更改为：“Error(ID/DAY)”我尝试将其全部删除，认为这可能会改变 R 解释这些事物的方式，但这并没有改变我的自由度。
非常感谢您的反馈/帮助，非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/647333/how-can-i-improve-my-r-code-for-a-two-way-repeated-measures-anova-to-produce-the</guid>
      <pubDate>Wed, 15 May 2024 20:22:52 GMT</pubDate>
    </item>
    <item>
      <title>最高密度与等尾置信区间</title>
      <link>https://stats.stackexchange.com/questions/647310/highest-density-vs-equal-tailed-confidence-interval</link>
      <description><![CDATA[当采样分布是对称的（如果必要的话，我也可以假设单峰分布），很自然地将置信区间集中在点估计周围。但对于偏态分布（例如卡方），选择端点（在我见过的每一本书中）来创建 等尾间隔（ETI） 这似乎也是一个“自然”的选择。但在这种情况下，另一个自然的选择是最高密度区间 (HDI)。 （我只在贝叶斯可信区间设置中看到过 ETI 和 HDI，但它们似乎同样适用于频率论置信区间设置。）

在现实世界中是否存在使用 HDI 置信区间（更有意义？）的场景？我更喜欢一个统计量是样本方差的示例。
为什么教科书中没有讨论 HDI 与 ETI 的置信区间？
]]></description>
      <guid>https://stats.stackexchange.com/questions/647310/highest-density-vs-equal-tailed-confidence-interval</guid>
      <pubDate>Wed, 15 May 2024 19:34:37 GMT</pubDate>
    </item>
    <item>
      <title>基于“排序均匀分布”和 beta 分布的常数近似</title>
      <link>https://stats.stackexchange.com/questions/647292/constant-approximation-based-on-sorted-uniform-distribution-and-beta-distribut</link>
      <description><![CDATA[让 $X_1, X_2 \stackrel{\text{iid}}{\sim}\mathrm{Uniform}(0,1)$ 然后排序 &lt; span class=&quot;math-container&quot;&gt;$X_1,X_2$ 得到 $X_{(1)} $X_{(1)} &lt; X_{(2)}$。
根据$X_{(i)}$的pdf，我们知道$X_{(1)} \sim \mathrm{Beta}(1,2)$ 和 $X_{(2)} \sim \mathrm{Beta}(2,1)$ span&gt;，其中 $\mathbb{E}(​​X_{(1)}) = \frac{1}{3}$ 和 $\mathbb{E}(​​X_{(2)}) = \frac{2}{3}$。
考虑函数 $f(x) = x$ 的常数近似。

在 $(0, 1)$$x_1, x_2$ &gt; 然后对它们进行排序以获得 $x_{(1)}$ 和 $x_{(2)}$ span&gt;, $x_{(1)} &lt; x_{(2)}$。将期望表示为 $\mathbb{E}_1(\|f - c\|_2^2) = \mathbb{E}_1(\displaystyle\int_{x_{(1 )}}^{x_{(2)}} (f(t)-c)^2 \; dt)$，其中 $c = \frac{1 {x_{(2)}-x_{(1)}}\displaystyle\int_{x_{(1)}}^{x_{(2)}} f(t)\; dt$ 是一个常数。

来自 $\mathrm{Beta}(1,2) 的示例 $y_{(1)}$ )$ 和 $y_{(2)}$ 来自 $\mathrm{Beta}(2,1 ）$。将期望表示为 $\mathbb{E}_2(\|f - c\|_2^2) = \mathbb{E}_2(\displaystyle\int_{y_{(1 )}}^{y_{(2)}} (f(t)-c)^2 \; dt)$，其中 $c = \frac{1 {y_{(2)}-y_{(1)}}\displaystyle\int_{y_{(1)}}^{y_{(2)}} f(t)\; dt$ 是一个常数。


（注：$\mathbb{E}_1$ 和 $\mathbb{E}_2$ 的定义 相同；唯一的区别是获取点的方法$x_{(i)}, y_{(i)}$。）
比较 $\mathbb{E}_1(\|f - c\|_2^2)$ 和 $ \mathbb{E}_2(\|f - c\|_2^2)$。通过数值实验观察到 $\mathbb{E}_1(\|f - c\|_2^2) $\mathbb{E}_1(\|f - c\|_2^2) &lt; \mathbb{E}_2(\|f - c\|_2^2)$。这个结果让我很困惑。
我希望它们相等，因为 $x_{(i)}$ 和 $y_{(i) }$ 来自与上面讨论的相同的 Beta 发行版。
这是因为$x_{(1)} \;\mathrm{and}\; x_{(2)}$ 不独立？如果是，$x_{(1)}$ 和 $x_{(2)}$ 的 pdf 或 cdf 是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647292/constant-approximation-based-on-sorted-uniform-distribution-and-beta-distribut</guid>
      <pubDate>Wed, 15 May 2024 15:11:32 GMT</pubDate>
    </item>
    <item>
      <title>干头骨与活头骨测量调整</title>
      <link>https://stats.stackexchange.com/questions/647246/dry-skull-vs-live-skull-measurement-adjustments</link>
      <description><![CDATA[我正在研究一个数据集，其中包含博物馆藏品（样本数量的两倍）或活体标本（不太常见）的干燥头骨测量值。正如您可以想象的那样，由于肌肉、皮肤和毛皮的存在，活体标本平均要大几厘米。我可以使用哪些统计方法来校正这些较大的尺寸，以更好地适应干燥的头骨测量？头骨长度将用作更大模型中的变量。
我想到了 3 种可能的方法：

将头骨类型作为随机效应，以解释这些方法之间的差异

按性别和年龄减去每种头骨类型的预测长度或平均值之间的差异，但这似乎是一种粗略的方法。

使用从线性回归模型获得的残差直接调整测量的头骨尺寸。从活体样本的测量头骨尺寸中减去残差，有效地减小它们的尺寸以适应更“平均”的头骨尺寸。尺寸。


# 线性回归：
lm1 &lt;- lm(Skull_length ~ ns(年龄, 3) + 性别 + Skull_code,
          数据=数据框）

# 从线性回归模型中获取残差
残差 &lt;- 残差(lm1)

# 创建新的数据框用于预测
new_data &lt;- Expand.grid(年龄 = 0:30,
                        性别 = c(“M”, “F”),
                        Skull_code = as.factor(1))

# 使用每个模型预测头骨长度
Predicted_skull_df2 &lt;- new_data %&gt;%
  变异（预测头骨 = 预测（lm1，新数据 = .））

# 将残差添加到 skull_code == 1 的平均头骨长度上
# （干头骨）头骨代码 == 2 （活头骨）
Growth_data &lt;- Growth_data %&gt;%
  left_join(预测_skull_df) %&gt;%
  突变（调整后的头骨2 = ifelse（头骨代码== 2，预测头骨+
                                  残差，Skull_l))

# 创建绘图以比较调整后的测量值与原始测量值
增长数据%&gt;%
  ggplot(aes(x = 年龄, y = Skull_l)) +
  geom_point(数据 = Growth_data %&gt;%
               过滤器（Skull_code == 1），aes（x = 年龄 - 0.2），
   颜色 = “黑色”，alpha = 0.5，大小 = 1) +
  geom_smooth(数据 = Growth_data %&gt;%
                过滤器（Skull_code == 1），颜色=“黑色”）+
  geom_point(数据 = Growth_data %&gt;%
               过滤器（Skull_code == 2），aes（x = 年龄 + 0.2），
   颜色 =“紫色”，alpha = 0.5，大小 = 1) +
  geom_smooth(数据 = Growth_data %&gt;%
                过滤器（Skull_code == 2），颜色=“紫色”）+
  geom_point(aes(y = adjustment_skull_l), 颜色 = “红色”,
                 阿尔法 = 0.5，大小 = 1) +
  geom_smooth(aes(y = adjustment_skull_l), color = “红色”) +
  主题(panel.background = element_rect(fill = &quot;white&quot;),
        axis.line = element_line(color = &quot;black&quot;),
        axis.text = element_text(face = &quot;bold&quot;, size = 9.5),
        axis.title = element_text(face = &quot;bold&quot;, size = 15)) +
  ylab(“头骨长度”) +
  ylim(180, 500)

]]></description>
      <guid>https://stats.stackexchange.com/questions/647246/dry-skull-vs-live-skull-measurement-adjustments</guid>
      <pubDate>Tue, 14 May 2024 22:02:21 GMT</pubDate>
    </item>
    <item>
      <title>多元概率模型在 R 中发出警告</title>
      <link>https://stats.stackexchange.com/questions/647331/multivariate-probit-model-gives-warnings-in-r</link>
      <description><![CDATA[我有一组地块的农业实践采用数据，以及与每个农民相关的人口统计数据和其他调查变量。
需要注意的一些要点 - 一些农民列出了多个地块，因此实践信息有所不同，而人口统计数据保持不变。
我正在尝试使用两种主要类型的分析。第一种是随机森林方法，我对每种农业实践进行分类 RF，并查看排列重要性以确定哪些是最重要的解释变量。我的 OOB 错误不是很大 - 36%、14% 和 21%。
第二种方法是我根据文献发现的一种方法 - Kassie et al 2009 中所见的多元概率模型：https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1477-8947.2009.01224.x （抱歉，我认为不是开放访问！）。
我删除了所有高度相关的变量，将所有分类变量变成虚拟变量，并使用 mvProbit 包来运行分析。
一个例子：
df &lt;- tibble(AgPrac = c(1,0,1,0,0,0,0,1),
             AgPrac2 = c(1,0,0,0,1,1,1,1),
             AgPrac3 = c(1,1,0,0,1,1,0,0),
             Farmer_Woman = c(0,0,0,0,1,0,0,1),
             District2 = c(0,0,0,1,1,0,0,1),
             农民年龄 = c(41, 31, 61, 39, 50, 54, 60,55),
             Farmer_educ_primary = c(0,1,1,1,0,0,0,1),
             Farmer_educ_secondary = c(1,0,0,0,0,0,0,0))

prob_mod &lt;- mvProbit(cbind(AgPrac, AgPrac2, AgPrac3) ~ Farmer_Woman + District2 + Farmer_age + Farmer_educ_primary + Farmer_educ_secondary, data = df) `

我有大约 9 个这样的常规 + 虚拟变量，并且想添加更多，并且有大约 1100 个绘图观察值。
如此帖子论坛问题所示，我收到许多（50+）警告，表明相关矩阵不是正定的。我尝试从模型中删除变量，但没有帮助。我不认为我有虚拟变量陷阱。谁能解释一下为什么我会收到此错误以及如何解决它？我应该坚持运行 3 个单变量概率模型吗？这是否与某些地块重复的农民人口统计数据有关 - 我是否应该选择采用率最高的地块并仅保留唯一的农民 ID？
我不应该分享实际数据，但可以提供任何其他信息......]]></description>
      <guid>https://stats.stackexchange.com/questions/647331/multivariate-probit-model-gives-warnings-in-r</guid>
      <pubDate>Tue, 14 May 2024 16:18:29 GMT</pubDate>
    </item>
    </channel>
</rss>