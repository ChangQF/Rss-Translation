<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 26 Dec 2023 12:24:06 GMT</lastBuildDate>
    <item>
      <title>为什么数据中的不同值会极大地影响PCA和模型的训练</title>
      <link>https://stats.stackexchange.com/questions/635653/why-different-values-in-the-data-greatly-affect-the-pca-and-the-training-of-the</link>
      <description><![CDATA[我有与目标关联的稀疏数据，这是模拟数据的代码
make_feature &lt;- function(target, null_var=0){
  v &lt;-rep(null_var, length(target))
  j &lt;- 样本（长度（目标），1）
  v[j] &lt;- 目标[j]
  v
}

库（矩阵）
库（随机森林）
设置.种子(2)

目标 &lt;- 样本(c(1,2),50,替换 = T)
数据 &lt;- sapply(1:200,\(x) make_feature(target))

稀疏数据&lt;-矩阵（数据，稀疏= TRUE）

...
&lt;前&gt;&lt;代码&gt;稀疏数据

[42，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[43，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[44，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 2. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[45，]。 。 。 。 。 。 。 1. 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[46，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[47，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 2. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[48，]。 。 。 。 。 2. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[49，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 2. 。 。 。 2. 。 。 。 ......
[50，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......

然后我进行 PCA 并训练模型
pca_sparse_data &lt;- prcomp(sparse_data)$x

时间 &lt;- 1:40
时间 &lt;- 41:50

rf &lt;- randomForest(as.factor(target[tr])~., data=pca_sparse_data[tr,], ntree=100)

模型运行良好
cbind.data.frame(orig = target[ts],
                  pred = 预测(rf, pca_sparse_data[ts,]))


   原始预测
1 1 1
2 1 1
3 1 1
4 2 2
5 1 1
6 1 1
7 2 2
8 2 2
9 2 2
10 1 1

但是当我稍微用其他值替换数据中的值时，模型就会停止工作
new_sparse_data &lt;-稀疏数据

new_sparse_data[sparse_data==1] &lt;- -1
new_sparse_data[sparse_data==2] &lt;- 1

..
&lt;前&gt;&lt;代码&gt;new_sparse_data

[42，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 -1。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[43，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[44，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[45，]。 。 。 。 。 。 。 -1。 。 。 。 。 -1。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[46，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[47，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[48，]。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[49，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 1. 。 。 。 ......
[50，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 -1。 。 。 。 。 。 。 。 -1。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......

训练新模型
new_pca_sparse_data &lt;- prcomp(new_sparse_data)$x
 new_rf &lt;- randomForest(as.factor(target[tr])~., new_pca_sparse_data[tr,], ntree=100)
 cbind.data.frame(orig = target[ts],
                  pred = 预测(new_rf, new_pca_sparse_data[ts,]))


   原始预测
1 1 1
2 1 1
3 1 2
4 2 2
5 1 1
6 1 2
7 2 2
8 2 1
9 2 2
10 1 2

为什么新模型的表现如此差？]]></description>
      <guid>https://stats.stackexchange.com/questions/635653/why-different-values-in-the-data-greatly-affect-the-pca-and-the-training-of-the</guid>
      <pubDate>Tue, 26 Dec 2023 11:45:53 GMT</pubDate>
    </item>
    <item>
      <title>OLS 估计量中受控变量的确切含义</title>
      <link>https://stats.stackexchange.com/questions/635649/exact-meaning-of-controlled-variables-in-terms-of-the-ols-estimators</link>
      <description><![CDATA[考虑一个二回归量线性回归模型：
$$Y=\beta_0+\beta_1X+\beta_2D+u$$
其中 $X$ 是连续的，$D$ 是二进制的。
在这种情况下，我们说我们已经控制了$D$。
在这里，我想知道“控制”的确切含义。
在提出我的想法之前，请考虑三个估计器。
首先，让 $\widehat{\beta}_1$ 为使用上述二回归模型的 OLS 估计器。
其次，让 $\widehat{\beta}_{11}$ 和 $\widehat{\beta} _{10}$ 是仅使用 $D=1$ 和 $D 样本的 OLS 估计器=0$，分别基于
$$Y=\alpha_0+\alpha_1X+e$$
如果 $\widehat{\beta}_1$ 是 $\widehat{\beta}_ 的加权平均值{11}$ 和 $\widehat{\beta}_{10}$，术语“受控”非常有效，因为 $\widehat{\beta}_{11}$ 和 $\widehat{\beta}_{ 10}$ 是在控制 $D$ 时估算的。
但是，我不确定这个想法是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/635649/exact-meaning-of-controlled-variables-in-terms-of-the-ols-estimators</guid>
      <pubDate>Tue, 26 Dec 2023 10:33:53 GMT</pubDate>
    </item>
    <item>
      <title>使用 t 统计量调查​​高于机会的测试性能</title>
      <link>https://stats.stackexchange.com/questions/635645/investigating-above-chance-test-performance-using-t-statistics</link>
      <description><![CDATA[我正在阅读一篇研究论文，遇到一种情况，研究人员调查参与者的测试表现是否高于偶然性。我很好奇如何以及为何进行这种类型的分析，如果有人能提供一些解释，我将不胜感激。
在这种情况下，126 名参与者被分为两组。每个小组都接受不同类型的语言训练。然后，两组完成相同的后测试，其中包括六个目标测试项目（加上一些干扰项）。对于每个目标测试项目，参与者看到两张图片，他们必须选择与测试者所说的句子相匹配的图片。测试者说出的六个句子中，三个句子包含训练中出现的动词，另外三个句子包含新动词。参与者完成此后测试两次，或分两个部分（训练课程 1 —&gt; 后测试 1 —&gt; 培训课程 2 —&gt; 后测试 2）。然后将测试分数提交给 2x2x2 方差分析，将训练条件作为主体间因素，将动词类型（训练与新颖）和块（1 与 2）作为主体变量内的变量。
在描述方差分析结果后，研究人员报告说，对于包含块一中两个条件的训练动词的句子，参与者选择的目标图片明显多于预期，t(120) = 3.7, p &lt; .001，块 2，t(120) = 8.5，p &lt; .001.此外，对于新颖的句子，这两个条件的表现均高于第二个块中的机会水平，t(120) = 4.1，p &lt; 4.1。 .001，但不在第一个块中，t(120) = 1.8，p = .07。
研究人员表示，上述几率大于 50%。
我的问题是：

如何对这样的超概率测试性能进行分析？我猜研究人员使用了 SPSS，尽管没有直接说明。我是否需要在 SPSS 中输入任何值，或者是否需要选择特定命令来对 8 个条件 (2x2x2) 中的每一个执行此类分析？

鉴于已经使用方差分析分析了感兴趣的变量（训练类型、动词类型和块）对分数的影响，调查测试表现是否高于机会的目的可能是什么像这样的研究吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/635645/investigating-above-chance-test-performance-using-t-statistics</guid>
      <pubDate>Tue, 26 Dec 2023 09:20:10 GMT</pubDate>
    </item>
    <item>
      <title>当基于树的模型通常比线性模型效果更好时，为什么我们要使用线性模型？</title>
      <link>https://stats.stackexchange.com/questions/635642/why-do-we-use-linear-models-when-tree-based-models-often-work-better-than-linear</link>
      <description><![CDATA[在监督机器学习中，特别是在 Kaggle 中，通常会发现树模型通常优于线性模型。即使在基于树的模型中，通常 XGBoost 的性能也优于 RandomForest，而 RandomForest 的性能又优于 DecisionTrees。
如果这不是真的，那么请随时纠正这个假设。
这些只是我的观察，不知何故，很多人都同意这个观点。
为什么我们应该使用线性模型，例如线性回归或逻辑回归？具体来说，什么时候它们的性能不如基于树的模型，并且比基于树的模型有更多的要求？
对于基于树的模型，可以提出关于使用 DecisionTrees 而不是 RandomForest 或 XGBoost 的类似问题。
在某些情况下应该首选线性模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635642/why-do-we-use-linear-models-when-tree-based-models-often-work-better-than-linear</guid>
      <pubDate>Tue, 26 Dec 2023 06:59:42 GMT</pubDate>
    </item>
    <item>
      <title>相关系数公式是怎么推导出来的？</title>
      <link>https://stats.stackexchange.com/questions/635637/how-was-the-correlation-coefficient-formula-derived</link>
      <description><![CDATA[免责声明：我不是数学家或统计学家，但我现在正在学习统计学，而且我只有大学代数背景。
相关系数公式如何生成 -1 到 1 之间的值，给我留下了深刻的印象，并且想知道这个方程是如何导出的。怎么有人坐下来说“我只想要 -1 到 1 之间的值”？并得出这个方程（或者什么样的数学逻辑序列可以使最终形式变得明显）。
我理解方程的每个单独组成部分，并且我有一种直觉，答案在于分子和分母项之间的运算顺序（例如，在分子求和之前发生的项相乘），但是我真是难住了。]]></description>
      <guid>https://stats.stackexchange.com/questions/635637/how-was-the-correlation-coefficient-formula-derived</guid>
      <pubDate>Tue, 26 Dec 2023 05:18:21 GMT</pubDate>
    </item>
    <item>
      <title>$\chi^2$-$(x_1-x_2+x_3+x_4)^2-(-x_1+x_2+x_3+x_4)^2$ 与 $x_i \sim N(\mu_i,\sigma_i)$ 的分布</title>
      <link>https://stats.stackexchange.com/questions/635625/chi2-distribution-of-x-1-x-2x-3x-42-x-1x-2x-3x-42-with-x-i-s</link>
      <description><![CDATA[给出 4 个独立的正态变量 $x_i \sim \mathcal{N}(\mu_i,\sigma_i)_{i=1,\ldots,4}$，用于定义随机变量
$$Z\sim (x_1 - x_2 + x_3 + x_4)^2 - (-x_1 + x_2 + x_3 + x_4)^2.\tag{1}$$
等式(1)中的每个平方项都是独立正态变量的线性组合，因此每个平方都有一个非中心$\chi^2(k,M)$ -具有 $k=1$ 自由度和非中心参数 $M$ 的分布。两个线性组合也是正交的， $\begin{pmatrix} 1 &amp; -1 &amp; 1&amp;1 \end{pmatrix} \cdot \begin{pmatrix} -1 &amp; 1 &amp; 1&amp;1 \end{pmatrix}^T =0$
，因此不相关；由于它们是不相关的联合随机变量，因此它们是独立的（请参阅此处）。 
因此等式(1)中的平方线性组合可以写成$\chi^2$-变量的差
$$Z\sim s \left( \chi^2\left(1,M_1\right)- \chi^2\left(1,M_2\right)\right)\标签{2}$$
使用非中心参数$M_1=\dfrac{1}{s}\left(\mu_1-\mu_2+\mu_3+\mu_4\right)^2, M_2=\dfrac{ 1}{s}\left(-\mu_1+\mu_2+\mu_3+\mu_4\right)^2$ 和总方差 $s=\sum_{i=1} ^4\sigma^2_i$。
但是，只有当所有 $\sigma_i$ 相同时，此方法才有效。如何通过不同$\sigma_i$$\chi^2$变量来表达eq.(1) &gt;?
PDF 图形示例
所有$\sigma_i$都是相同的。
$\sigma=(5,5,5,5), \mu=(2,-11,-1,4)$，黑色：eq (1)，红色：eq(2)（两个图几乎重叠）

所有$\sigma_i$都是不同的。
$\sigma=(5,4,3,2), \mu=(2,-11,-1,4)$，黑色：eq (1)、红色：eq(2)
]]></description>
      <guid>https://stats.stackexchange.com/questions/635625/chi2-distribution-of-x-1-x-2x-3x-42-x-1x-2x-3x-42-with-x-i-s</guid>
      <pubDate>Mon, 25 Dec 2023 19:18:05 GMT</pubDate>
    </item>
    <item>
      <title>如何用数值目标检查分类特征的线性独立性？</title>
      <link>https://stats.stackexchange.com/questions/635612/how-to-check-linear-independence-of-categorical-features-with-a-numerical-target</link>
      <description><![CDATA[假设我正在对数据集进行线性回归。我的数据集包含列 f1, f2 ,f3 ,f4 , f5 , target
。特征（自变量）是以“f”开头的列名称。我的目标变量（因变量）是“目标”。列 f1、f2、f3 是数字列（如温度、湿度等值），而 f4 和 f5 是一些分类的（月份、假期等）
我正在尝试检查这些变量之间以及目标变量之间的联系有多紧密。使用 Python，通常人们会运行 sns.heatmap(data.corr())，它会在漂亮的热图中返回各列的 Pearson 相关性。我读到这可能不是所有事情的正确方法。对于数值变量来说没问题。正确吗？
如果是，那么分类列的方法应该是什么？ （序数和名义）？特别是在我尝试将所有分类列检查到目标（这是一个数字变量）的设置中。我读到了有关使用斯皮尔曼相关性的内容。但我不确定。
如果您能告诉我一种可以在同一热图中使用的方法，我也将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/635612/how-to-check-linear-independence-of-categorical-features-with-a-numerical-target</guid>
      <pubDate>Mon, 25 Dec 2023 10:58:46 GMT</pubDate>
    </item>
    <item>
      <title>阐明称为“内核”或“贝叶斯”的各种回归方法之间的差异</title>
      <link>https://stats.stackexchange.com/questions/635574/clarifying-the-difference-between-various-regression-methods-called-kernel-or</link>
      <description><![CDATA[我想了解四种回归类型之间的成对关系：贝叶斯线性回归、高斯过程回归、核回归 (Nadaraya-Watson) 和核岭回归。我在阅读机器学习的高斯过程这本书时遇到了所有这些问题，并且想要一种清晰简洁的方法来区分它们。
这是我目前的理解，欢迎指正。贝叶斯线性回归处理 $\hat{\beta}$ 回归系数（通常设置为 OLS 最优估计器 $\hat{\beta}= (X^TX)^{-1}X^T y$) 作为随机变量，其分布是先验（我们选择的）的函数，并且数据（这鼓励它采用上面的 OLS 形式，如果这是我们的损失函数）。高斯过程回归只是贝叶斯线性回归，其中函数的先验是高斯过程（它是由均值函数和协方差函数定义的函数空间上的分布）。
然后，我对核回归的理解是，核是一个“相似度函数”。数据点之间，因此形式为 $\hat{y}(x) = \frac{\sum_i K(x, x_i)y_i}{\sum_i K(x, x_i)}$ 作为加权平均值似乎使用起来很直观。但是内核 ridge 回归给出了形式为 $K_{x, X}(K_{X,X} + \lambda I)^{- 的估计量1}y$。这似乎与带有岭罚分的传统核回归（N-W 类型）不同。此外，我看到高斯过程回归输出与其“后验平均值”相同的估计量。现在 $K$ 是协方差内核，因此 GPR（这是 BLR 的特殊情况？）相当于 KRR？
这四个简单方法之间的关系我不清楚。非常感谢一些澄清，谢谢。技术细节越多越好。]]></description>
      <guid>https://stats.stackexchange.com/questions/635574/clarifying-the-difference-between-various-regression-methods-called-kernel-or</guid>
      <pubDate>Sun, 24 Dec 2023 08:26:18 GMT</pubDate>
    </item>
    <item>
      <title>曼惠特尼检验中获得 U 的概率证明</title>
      <link>https://stats.stackexchange.com/questions/635572/proof-of-probability-of-obtaining-u-in-mann-whitney-test</link>
      <description><![CDATA[我试图了解 U 的概率公式是如何计算的 论文，第 4 节中的公式 1。

详情：
假设我们有两组 A 和 B，每组分别包含 m 和 n 个样本。 U 计算 A 中的成员领先于 B 中的成员（排名高于）的次数。 $\bar{p}_{\text{nm}}(U)$ 是其中有 m 个 A 和 n 个 B 的序列数，其中每个 A 的成员先于（排名高于）B 的成员 U 次。那么 $\bar{p}_{\text{nm}}(U)$ 的递归公式如下：

1]有人可以帮我推导出上述内容吗？
此外，在比较A和B是否表现相同的测试时，获得$\bar{p}_{\text{nm}}(U)的概率$ 在 A 和 B 表现相同的原假设下由 ${p}_{\text{nm}}(U)$ 给出，其中其递归公式如下：

2]有人可以帮我推导出上述内容吗？
谢谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/635572/proof-of-probability-of-obtaining-u-in-mann-whitney-test</guid>
      <pubDate>Sun, 24 Dec 2023 06:33:31 GMT</pubDate>
    </item>
    <item>
      <title>什么是样品近似硬度的度量？</title>
      <link>https://stats.stackexchange.com/questions/635494/what-is-a-measure-of-hardness-of-approximation-by-samples</link>
      <description><![CDATA[假设有一个很大的实数向量$\mathbf{x}$，我想估计某个聚合函数$f(\mathbf{x})$ 通过从总体中抽取一小部分样本$\mathbf{x}$。我想知道我需要多少样本才能知道 $f(\mathbf{x})$ 例如$1\%$ 准确度。样本数量可能取决于函数 $f$：较大的数字表示 $f$ 是“通过采样更难近似”。这个样本数的术语是什么？在哪里可以找到有关哪些函数 $f$ 更容易/更难近似的数据？
我想到的一个术语是样本复杂度，但从我所看到的来看，它不一样：它测量从给定的函数类别中学习函数所需的训练样本数量。就我而言，函数是固定且给定的，我想知道将函数值估计到给定精度所需的样本数。]]></description>
      <guid>https://stats.stackexchange.com/questions/635494/what-is-a-measure-of-hardness-of-approximation-by-samples</guid>
      <pubDate>Fri, 22 Dec 2023 12:09:45 GMT</pubDate>
    </item>
    <item>
      <title>$E[X|X^3-3X]=0$ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635492/exx3-3x-0</link>
      <description><![CDATA[用 $f(x) 证明 $E[X|X^3-3X]=0$ =\frac{|x^2-1|}{4}$ 是区间 $X$ 的密度函数数学容器&quot;&gt;$[-2,2]$。
我的尝试：
设 $Y=X^3-3X$ 和 $x_1, x_2, x_3$ $x^3-3x=y$ 的根。
\begin{聚集*}
P_{X\circ Y}(A\times B)=P_\Omega(X\in A\cap Y\in B)=\int_{Y\in B}I_A(x)f(x)dx=\\
=\int_B\sum_{i=1}^3I_A(x_i)f(x_i)/|3x_i^2-3|dy=\int_B\frac{\sum I_A(x_i)f(x_i)/|3x_i^2- 3|}{\sum f(x_i)/|3x_i^2-3|}dP_Y
\end{聚集*}
从哪里：
$$P_{X/Y}(y)(A)=P_\Omega[X\in A|Y=y]=\frac{1}{3}\sum I_A (x_i)$$
所以：
$$E[X|Y=y]=\frac{1}{3}\sum x_i=0$$]]></description>
      <guid>https://stats.stackexchange.com/questions/635492/exx3-3x-0</guid>
      <pubDate>Fri, 22 Dec 2023 11:30:22 GMT</pubDate>
    </item>
    <item>
      <title>支持向量机 - Hingelos</title>
      <link>https://stats.stackexchange.com/questions/635419/support-vector-machine-hingeloss</link>
      <description><![CDATA[“SVM 铰链损失”是什么意思
估计后验类别概率的众数&#39;（统计学习原理第427页）。
决策函数 f(x) 如果大于 0，则分配给正类 (+1)；如果小于 0，则分配给负类 (-1)，但这与后验类概率有何关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/635419/support-vector-machine-hingeloss</guid>
      <pubDate>Thu, 21 Dec 2023 13:13:10 GMT</pubDate>
    </item>
    <item>
      <title>如何仅使用因变量的滞后值来实施动态回归预测</title>
      <link>https://stats.stackexchange.com/questions/635236/how-to-implement-dynamic-regression-forecasting-using-only-lagged-values-of-the</link>
      <description><![CDATA[据我了解，Arima 误差回归（也称为动态回归）通常使用外生变量来实现，是否可以仅使用内生变量来实现动态回归？这将如何实施？
以下是使用外生变量（自变量）的回归方程
\begin{align}y_t = \beta_0 + \beta_1 x_{1,t} + \dots + \beta_k x_{k,t} + \varepsilon_t \hspace{1.5厘米}(1.1)\结束{对齐}
下面是动态回归方程，其中 $\eta_t$ 是 ARIMA(1,1,1) 过程。
\begin{align*}
  y_t &amp;= \beta_0 + \beta_1 x_{1,t} + \dots + \beta_k x_{k,t} + \eta_t,\hspace{1.25cm} (2.1) \\
      &amp; (1-\phi_1B)(1-B)\eta_t = (1+\theta_1B)\varepsilon_t,
\hspace{1cm} (2.2)
\end{对齐*}
$\eta_t$ 是如何计算的？因为如果我将后移符号转换为方程 2.2 中的形式，我应该得到以下结果：
\begin{align}\eta_t = \varepsilon_t + \theta_1\varepsilon_{t-1} + \eta_{t-1} + \phi_1(\eta_{t- 1} - \eta_{t-2}) \hspace{0.36cm} (2.3)\end{align}
是否可以将方程 2.1 转换为使用内生变量（因变量），如下所示：
\begin{align}y_t = \beta_0 + \beta_1 y_{t-1} + \dots + \beta_k y_{t-k} + \eta_t \hspace{1.2cm} (3.1)\end{对齐}
问题：

除了将所有外生变量替换为内生变量之外，3.1 的实施方式与 1.1 有何不同？
公式 2.3 中显示的 ARIMA(1,1,1) 多项式表示法正确吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635236/how-to-implement-dynamic-regression-forecasting-using-only-lagged-values-of-the</guid>
      <pubDate>Tue, 19 Dec 2023 08:10:46 GMT</pubDate>
    </item>
    <item>
      <title>您是否应该模拟混杂因素对其他混杂因素的影响来测试估计器？</title>
      <link>https://stats.stackexchange.com/questions/635194/should-you-simulate-the-effect-of-confounders-on-other-confounders-to-test-an-es</link>
      <description><![CDATA[想象一下，我正在尝试模拟数据生成过程，其中我对 $Y$ 做出以下假设：
$Y$ = $X$(0.15) + $Z_1$(0.23) + $Z_2$(0.08) + $Z_3$(0.19) + $Z_4$(0.05) + 错误
此外，考虑到我对几个估计器感兴趣，并且我正在尝试找出哪个估计器恢复了 0.15 的定义治疗效果最好。然而，$X$ 被几个变量混淆，所以我相应地调整它们。
我很清楚的是，对于我认为是混杂因素的变量，我需要模拟每个混杂因素对治疗和结果的影响大小。例如，如果 $Z_1$ 对 $Y$ 的影响为 0.23，我还需要在 $X$ 上模拟 0.04 的效果，否则，它不会是一个混杂因素。
然而，在更复杂的数据生成过程中，混杂因素可能会影响其他混杂因素本身的价值。也就是说，将每个混杂因素定义为与其他感兴趣的混杂因素完全外生的分布可能是不合适的。
例如，不要说 $Z_1$ 只是一个平均值为 $\mu 的正态分布变量$ 和标准差 $\sigma$，我也可以说 $Z_2$ 对 $Z_1$ 的影响为 0.33，$Z_3$ 对 $Z_3$ 的影响为 0.07 span class=&quot;math-container&quot;&gt;$Z_1$。
为了实现这个假设模拟的目标（测试不同的估计器，看看哪个估计器能最好地恢复治疗效果），是否有必要定义每个混杂因素对另一个混杂因素的影响？或者，只要我指定每个混杂因素对结果和治疗的影响，模拟分析就可以进行了吗？
一方面，我看到了全面详细说明系统中所有变量的假设数据生成过程的好处。然而，另一方面，我发现我将进一步的假设嵌入到对不感兴趣的效应大小的分析中存在问题（即我没有实际兴趣了解/思考如何 $ Z_3$ 可能会影响 $Z_1$、$Z_2$、$Z_4$ 等）。]]></description>
      <guid>https://stats.stackexchange.com/questions/635194/should-you-simulate-the-effect-of-confounders-on-other-confounders-to-test-an-es</guid>
      <pubDate>Mon, 18 Dec 2023 15:08:33 GMT</pubDate>
    </item>
    <item>
      <title>经验基函数</title>
      <link>https://stats.stackexchange.com/questions/623344/empirical-basis-functions</link>
      <description><![CDATA[初步
考虑 $n$ 个个体，每个个体都有观察到的数据$ Z_i, i = 1, \ldots, n$。对于每个单独的 $i$，纵向预测变量 $Z_i = \{Z_i(t_{i1}), \ldots, Z_i(t_{i,R_i})\}$ 是在有限数量的观测次数下测量的 $t_i = (t_{i1}, \ldots, t_{i ,R_i})$。我们可以将有限网格定义为 $\bigcup_{i=1}^{n} t_i$，覆盖样本的所有唯一观察时间，其中 $\tau = \max (\bigcup_{i=1}^{n} t_i)$。
文章说：
从任意一组平滑基函数开始 $\psi_1(t), \ldots, \psi_K(t)$ 来表征函数预测器，其中 &lt; span class=&quot;math-container&quot;&gt;$K$ 表示基函数的总数。该基函数集合可以是例如通过传统FPCA方法估计的经验基函数，但可以灵活地扩展到其他基函数。然后，函数数据可以用矩阵表示法重写为 $(Z_1(t), \ldots, Z_n(t))^T = \bf{\lambda}\bf{\psi }(t)$，其中 $\bf{\lambda} = (\lambda_1, \ldots, \lambda_n)^T$，其中 $\lambda_i = (\lambda_{i,1}, \ldots, \lambda_{i,K})^T$ 和 $\bf{\psi}(t) = (\psi_1(t), \ldots, \psi_K(t))^T$, $t \in [0，\tau]$。
$\bf{M}$ 的维度为 $K \times K$，其中$(k, k&#39;)$ 条目为 $\langle \psi_k(t), \psi_{k&#39;} ( t) \rangle$ 为 $k, k&#39; \in K$，$t \in [0 , \tau]$.
我的问题：
如您所见，$Z_{i}$ 是不规则且稀疏的。所以，如果我们用矩阵表示法来写它，那么里面就会有 NA。例如，
&lt;前&gt;&lt;代码&gt; ####
  设置.种子(123)
  # 观察数量
  n &lt;- 10
  # 底层函数
  f &lt;- 函数(t) {
    罪恶(t)
  }
  # 生成不规则且稀疏的函数数据
    Z &lt;- 矩阵(NA, nrow = n, ncol = 11)
    for (i in 1:n) {
    # 生成随机观察时间
    R &lt;- 样本（3:10，大小 = 1）
    t &lt;- 排序（样本（0:10，大小=R））
    # 在这些时间对函数进行采样
    y &lt;- f(t) + rnorm(length(t), sd = 0.1) # 添加一些噪音
    
    ＃ 返回
    Z[i, 匹配(t, c(0:10))] &lt;- y
    }
    列名(Z) &lt;- 0:10

所以，我的理解 $\bf{\lambda}$ 是一个矩阵 $n \times K$&lt; /span&gt; 和 $\bf{M}$ 是 $K \times K$。所以，传统 FPCA 方法估计的经验基函数就是特征函数，但如果是这样，我就不能有 $K$ 特征函数随后无法获得系数矩阵 $\bf{\lambda}$ （或分数）即 $n \times K $]]></description>
      <guid>https://stats.stackexchange.com/questions/623344/empirical-basis-functions</guid>
      <pubDate>Sun, 06 Aug 2023 20:56:16 GMT</pubDate>
    </item>
    </channel>
</rss>