<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 13 Aug 2024 12:30:27 GMT</lastBuildDate>
    <item>
      <title>计算百分位数的最佳 R 分位数方法</title>
      <link>https://stats.stackexchange.com/questions/652712/optimal-r-quantile-method-for-calculating-percentile</link>
      <description><![CDATA[R 中的哪种分位数估计方法适用于计算有联系的小样本中的极端百分位数（例如，第 2 个百分位数）？&quot;]]></description>
      <guid>https://stats.stackexchange.com/questions/652712/optimal-r-quantile-method-for-calculating-percentile</guid>
      <pubDate>Tue, 13 Aug 2024 12:20:22 GMT</pubDate>
    </item>
    <item>
      <title>设计一个神经网络，利用游戏状态信息预测 2D 格斗游戏中玩家的输入</title>
      <link>https://stats.stackexchange.com/questions/652711/designing-a-neural-network-to-predict-a-players-input-in-a-2d-fighting-game-usi</link>
      <description><![CDATA[我目前正在尝试设计一个神经网络，目的是广泛模仿特定 2D 格斗游戏中某些玩家的行为。
该游戏会记录每场游戏的“重播”，从而创建一个庞大的数据库。这些重播不仅包含每帧的游戏状态（例如位置值、动作状态等），还包含玩家输入的按钮。
NN 的输入数据将是游戏状态（或一系列游戏状态），并输出该游戏状态的预测输入。
我已经在 PyTorch 中为这个问题设置了一个通用 MLP，其架构如下，将其视为一个多标签问题，其中每个按钮输入都是一个要预测的标签：
class BaseModel(nn.Module):
def __init__(self, input_size, output_size):
super(BaseModel, self).__init__()
self.block_1 = nn.Sequential(
nn.Linear(input_size, 256),
nn.ReLU(),
nn.Linear(256,128),
nn.ReLU(),
)
self.dropout = nn.Dropout(p=0.3)
self.block_2 = nn.Sequential(
nn.Linear(128,64),
nn.ReLU()
)
self.bn = nn.BatchNorm1d(64)
self.block_3 = nn.Sequential(
nn.Linear(64,32),
nn.ReLU(),
nn.Linear(32,output_size)
)

def forward(self, x):
x = self.block_1(x)
x = self.dropout(x)
x = self.block_2(x)
x = self.bn(x)
x = self.block_3(x)
return x


此问题的数据来自重播。
输入数据首先被转换成人类可读的映射（例如 {&quot;HP&quot;: 10000, &quot;x&quot;:645.4273, &quot;y&quot;:0.0000, &quot;super_meter&quot;:32.6345, etc.&gt;），然后转换成一维张量形式的数值格式（例如 [10000, 645.4273, 0.0000, 32.6345, etc.]）。
同样，按钮输入首先从重放中转换为人类可读的映射（{&quot;A&quot;: 0, &quot;B&quot;: 1, &quot;up&quot;: 0, &quot;down​​&quot;:0, &quot;left&quot;:1, etc.&gt;），然后转换为一维张量，用作训练的真值标签，也仅使用映射的值。
目前，我使用的损失函数是二元交叉熵，优化器是 Adam。输出通过 S 型函数传递，如果值超过某个阈值，则按钮被解释为按下。
当前实现效果相当差。由于大多数按钮输入对于每个游戏状态都是 0，因此模型通过预测每帧每个按钮的 0 来非常快速地实现低损失。
我应该尝试哪些架构更改来提高模型的性能/处理模型很容易实现低损失的问题？
请注意，这样做的目的是模仿玩家行为，而不是“学习”如何玩游戏。如果使用重播数据训练模型的玩家什么都不做，只是一直按下一个按钮，那么模型应该反映这种行为。类似地，如果输入的玩家是职业玩家，其动作要复杂得多，则模型也应该表示这种行为。]]></description>
      <guid>https://stats.stackexchange.com/questions/652711/designing-a-neural-network-to-predict-a-players-input-in-a-2d-fighting-game-usi</guid>
      <pubDate>Tue, 13 Aug 2024 10:37:18 GMT</pubDate>
    </item>
    <item>
      <title>元分析与混合效应模型估计效应大小</title>
      <link>https://stats.stackexchange.com/questions/652710/meta-analysis-vs-mixed-effect-model-to-estimate-effect-size</link>
      <description><![CDATA[我有来自之前三个实验的数据，我想在功效分析中使用它们来计算新研究所需的样本量。一种经典的方法是进行元分析以获得标准化均值差异的估计值（在本例中），然后可以将其输入到样本量计算中。我使用 R 包 metafor 的函数 rma（执行随机效应元分析）完成了此操作。我已经对一个演示数据集（下面的代码）进行了此操作，结果我得到了治疗效果（均值差异）的估计值为 6.86，se 为 2.238。

library(lme4)
library(metafor)

# 演示数据集：
# 治疗：分类变量：0：治疗组，1：对照组
# 研究：分类变量，表示研究编号从 1 到 3
# y：模拟测量值
y &lt;- c(15.1,14.9,12.1,17.3,14.1,16.2,15.0,16.0,25.2,23.5,27.1,20.9,29.4,25.3,24.8,25.1,
8.2,11.3,10.0,10.1,9.9,12.0,8.0,10.9,18.0,17.0,19.3,22.2,16.1,17.1,17.8,17.2,
22.0,23.1,20.9,22.1,21.8,19.9,24.6,21.9,24.5,26.4,22.1,24.1,24.0,23.7,26.5,25.8)
治疗 &lt;- as.factor(rep(c(rep(0,8),rep(1,8)),3))
研究 &lt;- as.factor(c(rep(1,16),rep(2,16),rep(3,16)))

# 使用包进行随机效应元分析metaform
rma(measure=&quot;MD&quot;,
n1i=c(8,8,8),
n2i=c(8,8,8),
m1i=c(mean(y[9:16]),mean(y[25:32]),mean(y[41:48])),
m2i=c(mean(y[1:8]),mean(y[17:24]),mean(y[33:40])),
sd1i=c(sd(y[9:16]),sd(y[25:32]),sd(y[41:48])), 
sd2i=c(sd(y[1:8]),sd(y[17:24]),sd(y[33:40]))
)

但是，由于我不仅拥有三个数据的汇总数据，荟萃分析，但实际上，除了 rma，我可以使用所有原始数据，直接用混合效应回归模型估计治疗效果。
mod &lt;- lmer(y ~ treatment + (1|study) + (1|study:treatment))
summary(mod)

这样做，我得到了略有不同的治疗效果估计值 6.904 ，其标准差为 2.231。差别不大，但确实存在。我并不惊讶，我得到了略有不同的结果，因为我从不同的信息开始：​​一种情况下“仅”使用汇总统计数据（平均值、标准差），另一种情况下使用完整的原始数据。我的问题是，哪一种是估计效果大小计算效果的“更好”方法？我看到的大多数功效计算都是基于荟萃分析（因为通常原始数据不容易获得，因为数据是从文献中提取的，而作者通常只报告汇总统计数据）。但是，凭着我天真的直觉，我会认为，如果我确实有原始数据，那么将所有原始数据作为输入的混合模型应该更精确，因为它利用了更多信息。有什么理由让我不应该根据混合模型结果来估计效应量，而是像大多数人一样使用 rma？]]></description>
      <guid>https://stats.stackexchange.com/questions/652710/meta-analysis-vs-mixed-effect-model-to-estimate-effect-size</guid>
      <pubDate>Tue, 13 Aug 2024 10:19:46 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测中的神经网络：使用前一个网络作为下一个时间间隔的起点</title>
      <link>https://stats.stackexchange.com/questions/652708/neural-net-in-time-series-forecasting-the-use-of-previous-net-as-a-staring-poin</link>
      <description><![CDATA[我使用 NN 进行时间序列预测，其中序列和我使用的特征非常嘈杂。我在前 T 个输入上训练网络并获得了不错的结果：网络从随机初始化的权重开始学习得很好。然后我移动到下一个估计点，例如使用移动窗口，它将是间隔 [T+1,2T] 或扩展窗口 [1,2T]。如果我从随机初始化的权重开始，网络将再次学习。但是，由于我预计分布不会发生巨大变化，我从上一步获得的网络开始训练，但损失在学习周期内未能改善。我理解这是可能的，因为分布没有太大变化，而且几乎没有新东西需要学习。然而，我想知道这个问题是否可能是由于我学习的权重偏离目标而导致的，而它们的统计特性使它们成为一个糟糕的初始点？]]></description>
      <guid>https://stats.stackexchange.com/questions/652708/neural-net-in-time-series-forecasting-the-use-of-previous-net-as-a-staring-poin</guid>
      <pubDate>Tue, 13 Aug 2024 10:07:34 GMT</pubDate>
    </item>
    <item>
      <title>同一 GAM 模型的不同结果取决于“discrete = TRUE”</title>
      <link>https://stats.stackexchange.com/questions/652707/different-results-of-the-same-gam-model-depends-on-discrete-true</link>
      <description><![CDATA[我正在使用 bam 函数拟合 GAM。
该模型的代码是：
mod_1 &lt;- bam(n ~ s(age, by = period, k = 15) + 
s(hh_size, by = period, k = 9) +
period +
s(token, bs = &quot;re&quot;) + s(Bundesland, bs = &quot;re&quot;) + s(period, bs = &quot;re&quot;),
data = halle_data_household,
method = &quot;fREML&quot;, discrete = TRUE,
family = nb(),
nthreads = c(4,1))
mod_2 &lt;- bam(n ~ s(age, by = period, k = 15) + 
s(hh_size, by = period, k = 9) +
period +
s(token, bs = &quot;re&quot;) + s(Bundesland, bs = &quot;re&quot;) + s(period, bs = &quot;re&quot;),
data = halle_data_household,
method = &quot;fREML&quot;, 
family = nb(),
nthreads = c(4,1))

两个模型的区别在于&quot;discrete = TRUE&quot;，以加快计算时间。但我得到了两个不同的结果。
mod_1 的结果
 家庭：负二项式 (13.366) 
链接函数：log 

公式：
n ~ s(age, by = period, k = 15) + s(hh_size, by = period, k = 9) + 
period + s(token, bs = &quot;re&quot;) + s(Bundesland, bs = &quot;re&quot;) + 
s(period, bs = &quot;re&quot;)

参数系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 0.5409 0.1354 3.996 6.74e-05 ***
period2 -0.1253 0.1674 -0.749 0.454 
period3 -0.1319 0.1600 -0.825 0.410 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df F p 值 
s(age):period1 1.000e+00 1.000 0.641 0.423337 
s(age):period2 4.683e+00 5.656 3.799 0.001034 ** 
s(age):period3 4.569e+00 5.444 4.928 0.000116 ***
s(hh_size):period1 1.960e+00 2.412 1.186 0.303077
s(hh_size):period2 1.000e+00 1.000 1.798 0.180227 
s(hh_size):period3 1.000e+00 1.000 5.930 0.014997 * 
s(token) 4.406e+02 859.000 1.242 &lt; 2e-16 ***
s(Bundesland) 5.429e-05 15.000 0.000 0.801883 
s(period) 1.082e-14 3.000 0.000 0.999933 
---
Signif.代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) = 0.323 偏差解释 = 42.4%
fREML = 3657.9 尺度估计 = 1 n = 2115

mod_2 的结果
 系列：负二项式 (13.32) 
链接函数：log 

公式：
n ~ s(age, by = period, k = 15) + s(hh_size, by = period, k = 9) + 
period + s(token, bs = &quot;re&quot;) + s(Bundesland, bs = &quot;re&quot;) + 
s(period, bs = &quot;re&quot;)

参数系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.32541 0.05293 6.148 9.83e-10 ***
period2 -0.12288 0.07204 -1.706 0.08824 . 
period3 -0.20909 0.06826 -3.063 0.00222 ** 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df F p 值 
s(age):period1 1.000e+00 1.000 0.641 0.423576 
s(age):period2 4.685e+00 5.661 3.801 0.001061 ** 
s(age):period3 4.568e+00 5.442 4.963 0.000117 ***
s(hh_size):period1 1.961e+00 2.417 1.036 0.311454
s(hh_size):period2 1.000e+00 1.000 1.811 0.178523 
s(hh_size):period3 1.000e+00 1.000 5.930 0.014986 * 
s(token) 4.405e+02 857.000 1.226 &lt; 2e-16 ***
s(Bundesland) 6.066e-05 15.000 0.000 0.802106 
s(period) -9.299e-16 3.000 0.000 0.031014 * 
---
Signif.代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.（调整）= 0.322 偏差解释 = 42.4%
fREML = 3406.3 尺度估计 = 1 n = 2115
]]></description>
      <guid>https://stats.stackexchange.com/questions/652707/different-results-of-the-same-gam-model-depends-on-discrete-true</guid>
      <pubDate>Tue, 13 Aug 2024 09:47:41 GMT</pubDate>
    </item>
    <item>
      <title>“添加”多个估计的置信区间</title>
      <link>https://stats.stackexchange.com/questions/652706/adding-confidence-intervals-of-multiple-estimations</link>
      <description><![CDATA[我有救护服务每季度接诊的受伤人数估计值以及置信区间。我想添加这些估计值以检索救护车接诊的年度总受伤人数估计值。如何计算这个总数的置信区间？
每个季度，每个救护服务都会进行 N 次接诊。从 N 中抽取 +-1000 个病例样本 (n)。对于此样本中的每个病例，确定该接诊是否与受伤有关 (1) 或无关 (0；即与疾病等有关)。这意味着我可以计算样本中受伤的比例：p̂ = n1/ntotal。为了估算受伤人数（我们称该统计数据为“x”），我将 p̂ 与 N 相乘。
但是，我想考虑随机抽样引入的不确定性，因此我使用 R 中的 stats::binom.test() 函数估算 p̂ 周围的置信区间 (CI)，并将找到的下限和上限乘以 N 以检索 x 周围的 CI。
因此，现在我对每项救护服务和每个季度（x1、x2、… xn）都有 x 的估算值，我可以将其相加得到年度全国估算值。但是，我不确定如何“添加”置信区间。我非常确定取和将产生过于悲观的区间。
我找到了这篇文章，它似乎表明我可以对 CIs 半径的平方和取平方根，因为我假设一年内的救护服务和季度之间存在统计独立性。但我不确定这是否正确。我正在考虑的另一种方法是将每个服务和季度的所有数据堆积起来，并使用它来计算 p̂ 和 CIs。然而，众所周知，受伤比例在服务（和季度）之间以及总乘车次数（N）之间存在显着差异。我不确定这种方法是否也会产生悲观的 CI。
那么，我如何使用数据来计算全年估计的 CI？]]></description>
      <guid>https://stats.stackexchange.com/questions/652706/adding-confidence-intervals-of-multiple-estimations</guid>
      <pubDate>Tue, 13 Aug 2024 09:34:10 GMT</pubDate>
    </item>
    <item>
      <title>数据自适应参数的推断</title>
      <link>https://stats.stackexchange.com/questions/652705/inference-for-a-data-adaptive-parameter</link>
      <description><![CDATA[您有一个连续变量 $A$ 的数据，表示药物的剂量，以及一个连续结果 $Y$ 的数据，表示某种健康结果。
我想估计 $A$ 的“最佳”剂量，即最小化 $Y$ 的剂量。我们称之为 $A_{opt}$。
估计 $A_{opt}$ 很简单。它是最小化 $E[Y|A=a]$ 的值 $a$，可以通过线性回归估算（例如）。
然后我想估算 $A_{opt}$ 下的 $Y$ 的“值”。我可以通过传入 $A_{opt}$ 从拟合回归中获取此值。但问题是 i) 我将 $A_{opt}$ 视为已知，即使它是估计的（使方差估计无效）和 ii) 使用相同的数据来识别 $A_{opt}$ 以估计该剂量的值。
引导解决了第一个问题，但没有解决第二个问题。两倍样本分割可能有效，但似乎很浪费。K 倍 CV 将导致 $A_{opt}$ 的多个值，这会使演示变得复杂。对于这个问题，我们有什么选择？我将不胜感激任何参考资料！
简要
我如何：

估计数据自适应参数（即药物的“最佳”剂量，相对于结果）
获得该最佳剂量下结果值的有效估计值和有效不确定性
]]></description>
      <guid>https://stats.stackexchange.com/questions/652705/inference-for-a-data-adaptive-parameter</guid>
      <pubDate>Tue, 13 Aug 2024 09:26:50 GMT</pubDate>
    </item>
    <item>
      <title>纵向多组增长模型的不变性检验。是否需要对所有时间点进行组不变性检验？</title>
      <link>https://stats.stackexchange.com/questions/652704/invariance-test-for-a-longitudinal-multi-group-growth-model-is-a-group-invarian</link>
      <description><![CDATA[我有 7 波数据，用于包含来自两个不同国家样本的构造。作为增长曲线分析的初步步骤，已经进行了纵向不变性测试，并支持部分强不变性。我的问题是，是否需要对我拥有的所有时间点进行组不变性测试？我计划在我的增长曲线模型中将国家变量指定为时间不变协变量。
此外，如果有关于需要保持“未释放”多少项目才能保持不变性的文献，那将非常有帮助。
感谢大家的支持]]></description>
      <guid>https://stats.stackexchange.com/questions/652704/invariance-test-for-a-longitudinal-multi-group-growth-model-is-a-group-invarian</guid>
      <pubDate>Tue, 13 Aug 2024 09:17:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么卡方检验的 p 值和 KS 检验的 p 值之间存在很大差异？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652702/why-do-i-get-a-large-difference-between-the-p-value-of-a-chi-square-test-and-the</link>
      <description><![CDATA[简介。我有数据，表示某个地理区域中哺乳动物的数量。我在这里展示了一个数据示例（有关更多信息，请参阅下面的代码）：
&gt;&gt; r1

500、1700、0、600、400、100、200、400、9700、4300、100 等。

我想使用双样本卡方检验和 KS 检验来比较两组哺乳动物的分布。
我能够重现与我的情况类似的情况，其中卡方检验的 p 值低于显着性水平 $\alpha = 0.05$，而 KS 检验的 p 值相当高（因此，两个 p 值非常不同）：
rng(0,&#39;twister&#39;);
a = 0;
b = 100;
bw = 100;
r1 = (b-a).*round(lognrnd(1,1,1000,1)) + a;
r2 = (b-a).*round(lognrnd(0.88,1.1,1000,1)) + a;
保持
h1 = histogram(r1,&#39;BinWidth&#39;,bw);
h2 = histogram(r2,&#39;BinWidth&#39;,bw);
la​​st_bin = 20;
[~,p_CS,~] = chi2gof(1:length(h1.Values(1:last_bin)), &#39;Expected&#39;, h2.Values(1:last_bin), &#39;Frequency&#39;, h1.Values(1:last_bin), &#39;EMin&#39;, 0)
[~,p_KS,~] = kstest2(r1,r2)
xlim([0 2000])

使用这个结果图和 p 值：

p_CS =
0.00029734

p_KS =
0.71613

请注意，卡方检验的输入是分箱数据，即“h1.Values”和“h2.Values”，而 KS 检验的输入是原始数据，即“r1”和“r2”。
问题。为什么卡方检验的 p 值和 KS 检验的 p 值之间会存在很大差异？
其他评论。我理解卡方检验“测量” 落入 bin“i” 的观测值数量（第一个数据集/分布）与预计落入 bin“i” 的观测值数量（第二个数据集/分布）之间的平方差，而 Kolmogorov-Smirnov 检验“测量”两个 ECDF 之间的最大距离。
也就是说，KS 检验“往往对分布中心比尾部更敏感”，但只是我的解释，卡方检验似乎对分布的每个“部分”都很敏感，因为观测值和预期值之间的平方差是针对分布的所有箱体计算的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652702/why-do-i-get-a-large-difference-between-the-p-value-of-a-chi-square-test-and-the</guid>
      <pubDate>Tue, 13 Aug 2024 09:08:18 GMT</pubDate>
    </item>
    <item>
      <title>在 KNN_classifier 中查找给定数据点 x 的 k 个最近邻居 [已迁移]</title>
      <link>https://stats.stackexchange.com/questions/652701/find-k-nearest-neighbors-of-a-given-data-point-x-in-knn-classifier</link>
      <description><![CDATA[在 python 中，knn 算法可以应用于训练数据，代码如下：
 from sklearn.neighbors import KNeighborsClassifier

KNN_classifier = KNeighborsClassifier(n_neighbors=k)
KNN_classifier.fit(X_train, y_train)
y_pred = KNN_classifier.predict(X_test)

现在对于给定的数据点 $x$，我想准确找到 knn 算法在学习过程中使用的 $x$ 的 $k$ 个邻居。是否可以访问给定数据点 $x$ 的邻居？如果有人能帮助我解决这个问题，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/652701/find-k-nearest-neighbors-of-a-given-data-point-x-in-knn-classifier</guid>
      <pubDate>Tue, 13 Aug 2024 09:05:57 GMT</pubDate>
    </item>
    <item>
      <title>3PL IRT 方程和程序 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/652700/3pl-irt-equation-and-program</link>
      <description><![CDATA[大家好，下面是我编写的一个程序，用于根据现有参数检查新分数 -
但我注意到不同的地方对 3PL 方程式的报告不同，例如
Wickepdia 说了一件事，而我的教科书说了另一件事 - 有人可以通过来源（自定义模型）确认 3PL 的适当公式吗？非常感谢？
library(ltm)
item_params &lt;- data.frame(
discrimination = c(1.01, 1.30, 1.43, 1.36, 1.13, 1.19, 1.04, 1.08, 1.69, 1.55, 1.18, 1.37, 1.24, 1.24, 1.43, 1.50, 1.34, 2.25, 1.92, 1.72, 1.43, 1.25, 2.35、1.32、1.66、1.98、1.67、1.14、1.36、1.35、1.34、1.05、1.54、2.02、1.28、1.62、2.24、1.23、2.11、1.93、1.91、2.81、1。 38、2.35、1.29、1.98、1.17、2.88、0.72、1.44、1.89、1.38、1.47、1.60、2.94、1.52、1.95、0.88、1.23、2.98、1.68、1.28、1.71、 2.32, 1.25, 1.54, 1.34, 1.85, 0.72, 1.34, 2.98, 1.06),
难度 = c(-5.67, -3.65, -3.04, -3.55, -3.49, -3.34, -5.18, -4.24, -3.38, -3.47, -3.39, -3.39, -2.64, -3.04, -3.49, -3.44, -2.69, -2.23, -2.76, -1.01, -1.17, -0.91, 0.17, -0.86, -0.36, -1.64, -1.05, -0.40, -0.86, -1.11, -0.48、-0.35、-1.06、1.36、-0.81、0.34、-1.94、0.64、-1.13、-0.68、0.17、-0.17、-0.35、-1.39、0.59、-0.76、-0.18、-0.67、0.34、1.58、-0。 60、-0.11、-0.14、0.15、0.53、1.54、-1.25、0.66、0.05、0.63、-0.21、-0.67、0.20、-0.34、0.11、-0.29、1.25、1.19、0.63、0.21、1.14、 -1.94)，
猜测 = c(0.00, 0.00, 0.15, 0.00, 0.00, 0.19, 0.00, 0.00, 0.00, 0.00, 0.01, 0.00, 0.00, 0.00, 0.01, 0.08, 0.49, 0.12, 0.35, 0.40, 0.25, 0.28, 0.30, 0.47, 0.41, 0.36, 0.38, 0.24, 0.15, 0.14, 0.34, 0.29, 0.37, 0.47, 0.20, 0.30, 0.00, 0.23, 0.40, 0.40, 0.19, 0.26, 0.27, 0.50, 0.32, 0.31, 0.33, 0.35, 0.35, 0.27, 0.23, 0.40, 0.33, 0.30, 0.18, 0.34, 0.30, 0.24, 0.35, 0.27, 0.57, 0.38, 0.27, 0.44, 0.21, 0.50, 0.22, 0.19, 0.45, 0.25, 0.35)
)
response_data &lt;- matrix(
c(
# 第一受访者的答复
1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,0,0,0,1,0,1,0,1,1,1,0,
# 第二位受访者的答复
1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,0,1,1,1,1,1,0,0,0,0,1,0,1,1,1,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0,1,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1,
# 第三位受访者的响应
1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,1,0,1,1,0,1,1,0,1,1,0,1,1,0,1,1,0,1,0,1,1,0,1,1,0,1,1,0,1,0,1,0,0,1,1,1,1,0,1,0,0,1,0,0,1,1,1,0,0,1,0,0
), nrow = 3, byrow = TRUE
)
custom_model &lt;- function(theta, params) {
a &lt;- params$discrimination
b &lt;- params$difficulty
c &lt;- params$guessing
P &lt;- c + ((1 - c) /(1 + exp(-a * (theta - b))))
return(P)

estimate_theta &lt;- function(response, item_params) {
theta_values &lt;- seq(-4, 4, by = 0.1)
likelihoods &lt;- sapply(theta_values, function(theta) {
probs &lt;- custom_model(theta, item_params)
likelihood &lt;- prod(probs^response * (1 - probs)^(1 - response))
return(likelihood)
})
best_theta &lt;- theta_values[which.max(likelihoods)]
return(best_theta)

theta_scores &lt;- apply(response_data, 1,estimate_theta, item_params) = item_params)
打印(theta_scores)]]></description>
      <guid>https://stats.stackexchange.com/questions/652700/3pl-irt-equation-and-program</guid>
      <pubDate>Tue, 13 Aug 2024 08:56:21 GMT</pubDate>
    </item>
    <item>
      <title>损失函数收敛于零？</title>
      <link>https://stats.stackexchange.com/questions/652699/a-loss-function-converges-to-zero</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652699/a-loss-function-converges-to-zero</guid>
      <pubDate>Tue, 13 Aug 2024 08:45:17 GMT</pubDate>
    </item>
    <item>
      <title>时间序列季节性分析-评分方法</title>
      <link>https://stats.stackexchange.com/questions/652698/time-series-seasonality-analysis-scoring-method</link>
      <description><![CDATA[我正在研究时间序列中的季节性搜索，并希望使用序列中的符号来自动化该过程，而无需手动检查曲线。我建议评估季节性的三个分数是：
季节性强度：使用 Python 的 STL 分解 (LOESS) 后，我恢复了三个组成部分：趋势、季节性和残差。我测量了季节性成分相对于噪声的方差比例。我使用 STL 参数“周期”的不同值进行迭代。
季节性相似性：使用季节性成分，我比较季节性子周期以检查从一个时期到另一个时期的模式一致性。
季节性模式：分析季节性成分子周期之间模式（上升/下降）的重复性，以评估季节性的稳定性。
我将这 3 个分数与 python 的分解 STL（来自 statsmodels.tsa.seasonal 导入 STL）结合使用，并使用参数“period”定义季节性周期，然后我检索分数。
您认为这些符号与自动搜索季节性一致吗？您知道其他有效的方法吗？也许是分类方法？我希望能够从不同的数据细分（每周、每月、每季度）中了解每个细分的最强季节性周期。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/652698/time-series-seasonality-analysis-scoring-method</guid>
      <pubDate>Tue, 13 Aug 2024 08:33:48 GMT</pubDate>
    </item>
    <item>
      <title>野生引导标准误差与分析 HAC 标准误差的收敛</title>
      <link>https://stats.stackexchange.com/questions/652695/convergence-of-wild-bootstrap-standard-error-to-analytical-hac-standard-error</link>
      <description><![CDATA[我目前正在估计局部投影回归，一个众所周知的问题是需要校正自相关残差。因此，我使用 Newey-West HAC 估计量来计算标准误差。
对于同一项目的另一部分，我需要使用引导标准误差，我目前正在测试野生依赖引导Davidson 和 Monticini (2014)。
具体来说，他们的论文提出了野生标准引导技术作为 Newey-West 估计量的引导版本（就像野生引导是 Eicker-White 方法的引导等效物一样）。 我的问题是，在有限样本中，我们是否应该预期随着引导重复次数趋近于无穷大，野生引导 SE 会收敛到（或至少近似一致）Newey-West SE？假设相同的大小相当大（&gt; 500）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652695/convergence-of-wild-bootstrap-standard-error-to-analytical-hac-standard-error</guid>
      <pubDate>Tue, 13 Aug 2024 06:01:53 GMT</pubDate>
    </item>
    <item>
      <title>我需要知道此代码中的第 3 步是否正确[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652671/i-need-to-know-if-step-3-in-this-code-is-correct</link>
      <description><![CDATA[我是 R 新手，我正在尝试使用 ltm 包从 72 项集（来自这篇已发表的论文）中获取一些 IRT 参数（a、b、g）
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4461534/#:~:text=The%20CFMT%20uses%20a%20three,be%20selected%20among%20two%20distractors（见表4)
下面是我的代码……它看起来似乎在做一些合理的事，但我需要一个绝地武士来检查我是否在这里没有脱离正轨。
library(ltm)

# 步骤 1：定义先前估计的项目参数
item_params &lt;- data.frame(
discriminator = c(1.01, 1.30, 1.43, 1.36, 1.13, 1.19, 1.04, 1.08, 1.69, 1.55, 1.18, 1.37, 1.24, 1.24, 1.43, 1.50, 1.34, 2.25, 1.92, 1.72, 1.43, 1.25, 2.35, 1.32, 1.66、1.98、1.67、1.14、1.36、1.35、1.34、1.05、1.54、2.02、1.28、1.62、2.24、1.23、2.11、1.93、1.91、2.81、1.38、2.35、1。 29、1.98、1.17、2.88、0.72、1.44、1.89、1.38、1.47、1.60、2.94、1.52、1.95、0.88、1.23、2.98、1.68、1.28、1.71、2.32、 1.54, 1.34, 1.85, 0.72, 1.34, 2.98, 1.06),
难度 = c(-5.67, -3.65, -3.04, -3.55, -3.49, -3.34, -5.18, -4.24, -3.38, -3.47, -3.39, -3.39, -2.64, -3.04, -3.49, -3.44, -2.69, -2.23, -2.76, -1.01, -1.17, -0.91, 0.17, -0.86, -0.36, -1.64, -1.05, -0.40, -0.86, -1.11, -0.48, -0.35, -1.06, 1.36, -0.81, 0.34, -1.94, 0.64, -1.13, -0.68, 0.17, -0.17, -0.35, -1.39, 0.59, -0.76, -0.18, -0.67, 0.34, 1.58, -0.60, -0.11, -0.14, 0.15, 0.53, 1.54, -1.25, 0.66, 0.05, 0.63, -0.21, -0.67, 0.20, -0.34, 0.11, -0.29, 1.25, 1.19, 0.63, 0.21, 1.14, -1.94),
猜测 = c(0.00, 0.00、0.15、0.00、0.00、0.19、0.00、0.00、0.00、0.00、0.00、0.01、0.00、0.00、0.00、0.01、0.08、0.49、0.12、0.35、0.40、0。 25、0.28、0.30、0.47、0.41、0.36、0.38、0.24、0.15、0.14、0.34、0.29、0.37、0.47、0.20、0.30、0.00、0.23、0.40、0.40、0.19、 0.26, 0.27, 0.50, 0.32, 0.31, 0.33, 0.35, 0.35, 0.27, 0.23, 0.40, 0.33, 0.30, 0.18, 0.34, 0.30, 0.24, 0.35, 0.27, 0.57, 0.38, 0.27, 0.44, 0.21, 0.50, 0.22, 0.19, 0.45, 0.25, 0.35)
)

# 步骤 2：创建三个不同样本答案的矩阵（1 表示正确，0 表示不正确）
response_data &lt;- matrix(
c(
# 第一位受访者的答案
1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1,0,1,0,0,0,0,1,0,1,0,1,1,0,1,0,1,1,1,0,
# 第二位受访者的回答
1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,0,0,1,1,0,0,1,0,0,1,0,0,0,0,1,1,0,1,0,1,0,1,0,1,0,0,1,0,0,0,0,0,1,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,
# 第三位受访者的回答
1,1,1,1,0,1,1,0,0,1,1,0,0,1,1,1,1,0,1,1,1,0,1,1,0,0,1,0,0,0,0,0,0,0,1,0,0,1,1,1,1,0,0,0,0,0,0,1,0,0,1,1,1,1,0,0,0,1,1,1,0,0,0,1,0,0,0,1,1,1,1,0,1,0,0,1,0,0,1,1,1,0,1,0,0,1,0,1,1
), nrow = 3, byrow = TRUE
)

# 步骤 3：使用给定的项目参数设置 IRT 模型
custom_model &lt;- function(theta, params) {
a &lt;- params$discrimination
b &lt;- params$difficulty
c &lt;- params$guessing
P &lt;- c + (1 - c) / (1 + exp(-a * (theta - b)))
return(P)
}

# 使用 MLE（最大似然估计）估计每个受访者的 theta
estimate_theta &lt;- function(response, item_params) {
theta_values &lt;- seq(-4, 4, by = 0.1)
likelys &lt;- sapply(theta_values, function(theta) {
probs &lt;- custom_model(theta, item_params)
likely &lt;- prod(probs^response * (1 - probs)^(1 - response))
return(likelihood)
})
best_theta &lt;- theta_values[which.max(likelihoods)]
return(best_theta)
}

# 步骤 4：计算所有受访者（三名参与者）的 IRT 量表分数
theta_scores &lt;- apply(response_data, 1,estimate_theta,item_params = item_params)

# 输出估计的 theta 分数
print(theta_scores)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652671/i-need-to-know-if-step-3-in-this-code-is-correct</guid>
      <pubDate>Mon, 12 Aug 2024 17:41:34 GMT</pubDate>
    </item>
    </channel>
</rss>