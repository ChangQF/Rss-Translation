<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 14 Jun 2024 15:17:06 GMT</lastBuildDate>
    <item>
      <title>LASSO 回归中 L1 范数的维度 - 直观的解释？</title>
      <link>https://stats.stackexchange.com/questions/649253/dimension-of-the-l1-norm-in-the-lasso-regression-intuitive-explanation</link>
      <description><![CDATA[据我所知，特征数 = p 且观测数 = n 的 LASSO 回归中的 L1 范数是 n-1 维的。
我想知道为什么会这样，因为 LASSO 范数绑定了所有 p 个参数，所以直观地我会回答它是 p 维的。
对此有任何直观的解释吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649253/dimension-of-the-l1-norm-in-the-lasso-regression-intuitive-explanation</guid>
      <pubDate>Fri, 14 Jun 2024 15:10:37 GMT</pubDate>
    </item>
    <item>
      <title>模型分布与残差分布</title>
      <link>https://stats.stackexchange.com/questions/649252/distribution-of-the-model-vs-distribution-of-the-residuals</link>
      <description><![CDATA[假设我要进行一项分析，其中我的响应变量具有伽马分布。我执行指向模型中分布的分析（例如，使用 lme4 包，m1&lt;-glmer(Y~X1, family=Gamma(link=&quot;inverse&quot;), data= database）。
接下来，为了检查残差的分布，我是否应该期望它们呈正态分布并生成带有&quot;distribution=normal&quot; 的 qqplot？因为如果我已经根据响应变量的分布调整了模型，那么更多靠近模型的观察值和更少远离模型的观察值的逻辑难道不会倾向于生成残差的正态分布吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649252/distribution-of-the-model-vs-distribution-of-the-residuals</guid>
      <pubDate>Fri, 14 Jun 2024 14:25:31 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Python 中的 scipy.optimize 校正最小二乘拟合中的系统偏差，特别是当我怀疑非正态分布时？</title>
      <link>https://stats.stackexchange.com/questions/649251/how-can-i-correct-for-systematic-bias-in-a-least-squares-fit-using-scipy-optimiz</link>
      <description><![CDATA[我有一个使用 scipy 的 curve_fit 拟合的数据集。与理论预测相比，我注意到拟合参数中存在系统误差。数据集由一个系统生成，其中输入参数取决于两个速率：Alpha 和 Beta。系统在由这些速率控制的泊松过程中运行，这些速率描述了固定数量潜在边的图形的布线。Alpha 描述新边的诞生，beta 描述现有边的消亡。系统误差取决于 Alpha 与 Beta 的比率。此外，系统上下都有界限（z：边的最大数量，0：不存在边）。
如果 Alpha/Beta &gt; 1，我更接近上限，拟合参数（平衡连通性）向下显示系统误差。
如果 Alpha/Beta &lt; 1，我更接近下限，拟合参数（平衡连通性）向上显示系统误差。我怀疑出现此错误是因为底层统计过程导致数据点可能由于系统的限制而不围绕真实统计平均值呈正态分布。
数据来自泊松过程的模拟。在事件 t 的每个时间点，图形的相应连通性 z 都会写入 csv 文件。然后我要做的是运行泊松过程的多个模拟，然后将所有这些数据点放在一个数据框中。我对相应的数据点进行排序，然后从 python 中的 scipy.optimize 包执行拟合例程（最小二乘法）。参数 alpha 和 beta 应设置为任何可能的值，因为这将修改系统连通性的平衡值。
我该如何解决这个问题并尽量减少系统误差？
我还附加了一个 Q-Q 图，以及一个显示组装图的绝对连通性随时间变化的图。


差异 delta z 是预测连通性和拟合连通性之间的差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/649251/how-can-i-correct-for-systematic-bias-in-a-least-squares-fit-using-scipy-optimiz</guid>
      <pubDate>Fri, 14 Jun 2024 13:51:53 GMT</pubDate>
    </item>
    <item>
      <title>比较不同数据的回归模型的斜率</title>
      <link>https://stats.stackexchange.com/questions/649250/comparing-slopes-of-regression-models-on-different-data</link>
      <description><![CDATA[假设我们有两个因变量：$y_1$ 和 $y_2$，并且这些因变量依赖于它们自己的外生回归变量：
$$y_1 = \beta_0 + \beta_1 x_1 + \epsilon_1$$
$$y_2 = \gamma_0 + \gamma_1 x_2 + \epsilon_2$$
其中 $y_1$ 和 $y_2$ 的长度 $n_k$ 不一定是相同。假设$n_1 \neq n_2$。
在这两种情况下，我都可以估计一个回归模型并获得参数估计值。然后，如果这些参数与某个值有显著差异，我可以通过 t 检验来测试它们。因此，我可以询问一个模型，其参数值是否与第二个模型中参数的估计值相同：
$$\frac{\hat{\beta_1} - \hat{\gamma_1}}{\text{s.d.}(\hat{\beta_1})} \sim t(n_1 - 2)$$
类似地，对于$\hat{\gamma_1}$...
但是，如果这两个参数在统计上无法区分，有没有办法同时比较它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/649250/comparing-slopes-of-regression-models-on-different-data</guid>
      <pubDate>Fri, 14 Jun 2024 13:39:10 GMT</pubDate>
    </item>
    <item>
      <title>工具变量估计中的排除限制可以表示为$\mathrm{cov}(Z, Y | X) = 0$吗？</title>
      <link>https://stats.stackexchange.com/questions/649249/can-the-exclusion-restriction-in-instrumental-variable-estimation-be-expressed-a</link>
      <description><![CDATA[在回归模型$Y = \alpha + \beta X + \epsilon$的工具变量（IV）估计中，其中$Y$为结果，$X$为内生自变量，$\epsilon$为误差项，$Z$为外生工具，相关性标准可表示为$\mathrm{cov}(Z, X) \ne 0$，外生性标准可表示为$\mathrm{cov}(Z, \epsilon) = 0$。
但是，我还没有遇到过类似的排除限制表达式。据我所知，排除限制意味着工具$Z$仅通过其对$X$的影响来影响$Y$。这是否意味着，一旦控制了$X$，即$\mathrm{cov}(Z, Y | X) = 0$，$Z$和$Y$之间的协方差应该是$0$？]]></description>
      <guid>https://stats.stackexchange.com/questions/649249/can-the-exclusion-restriction-in-instrumental-variable-estimation-be-expressed-a</guid>
      <pubDate>Fri, 14 Jun 2024 13:38:05 GMT</pubDate>
    </item>
    <item>
      <title>使用 S 型函数对 Logistic 回归进行导数运算 [重复]</title>
      <link>https://stats.stackexchange.com/questions/649247/derivative-of-logistic-regression-with-sigmoid-func</link>
      <description><![CDATA[我很难弄清楚为什么我从教授那里得到了不同的答案。我们的任务是找到逻辑回归成本函数与 S 型函数的导数：
$$L(w│D)=−\frac{1}{m}∑[y_ilog(σ(w^Tx_i))+(1−y_i)log(1−σ(w^Tx_i))]$$
经过一些计算，我得到了解决方案：
$$−\frac{1}{m}∑[y_i−σ(w^Tx_i)]x_i$$
但教授的答案是
$$−\frac{1}{m}∑[σ(w^Tx_i)-y_i]x_i$$
它的翻转...
我查看了许多其他计算，其中一些最终像我的一样，一些像教授的一样。此外，chatGPT 说两种形式都可以使用“在逻辑回归的背景下，两种形式都用于不同的上下文。”
我不明白两种形式如何以类似的方式解释，因为我们的目标是最小化成本函数，每个减号都应该很重要。
我不认为我的问题出在计算上，因为我在网上看到了每种形式的答案，我的问题更具概念性，但有人要求我上传我的作品：
]]></description>
      <guid>https://stats.stackexchange.com/questions/649247/derivative-of-logistic-regression-with-sigmoid-func</guid>
      <pubDate>Fri, 14 Jun 2024 13:26:37 GMT</pubDate>
    </item>
    <item>
      <title>如何正确比较两个亚群中的单一诊断测试</title>
      <link>https://stats.stackexchange.com/questions/649243/how-to-properly-compare-a-single-diagnostic-test-in-two-subpopulations</link>
      <description><![CDATA[假设我有一个具有二元响应的诊断测试。我已经对某些人群进行了这项测试。
现在，我将这个人群分成两个子组（例如男性/女性），并想检查我的测试的某些参数（例如敏感性和特异性）是否偏向某些组，或者每个组的这些参数之间的差异是否具有统计意义。正确的方法是什么？
我感兴趣的其他场景是，如果我有两个以上的子组（例如年龄组），并且每个组的规模非常不平衡。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649243/how-to-properly-compare-a-single-diagnostic-test-in-two-subpopulations</guid>
      <pubDate>Fri, 14 Jun 2024 12:27:20 GMT</pubDate>
    </item>
    <item>
      <title>如何使三重态损失更易于分离？</title>
      <link>https://stats.stackexchange.com/questions/649242/how-to-make-triplet-loss-more-separable</link>
      <description><![CDATA[我使用三重学习和三重损失从图像中学习嵌入，以在推理时判断两张脸部图片是同一个人还是不同的人（我真正的问题不同，但无法透露，因此我使用脸部图像类比）。我得到了相当不错的结果，但有时没有单一的欧几里德距离阈值来正确分离所有示例。
当我分析三重损失公式时，我发现，只要负例距离锚点至少比正例远，损失就会变为 0。这反过来使三重损失“不关心”正例和负例在绝对距离方面距离锚点有多远，使阈值变得不必要。我相信这可能是我的情况的一个问题。让我们看一下这个准备好的两个三元组的示例：

在此示例中，如果 Y&gt;=m（边距），则损失最小化为 0 并且训练停止，尽管没有可用于区分相似情况和不相似情况的单个阈值。
这是已知问题吗？有解决方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649242/how-to-make-triplet-loss-more-separable</guid>
      <pubDate>Fri, 14 Jun 2024 12:06:17 GMT</pubDate>
    </item>
    <item>
      <title>adj R2 的结果不可接受</title>
      <link>https://stats.stackexchange.com/questions/649241/unacceptable-results-for-adj-r2</link>
      <description><![CDATA[我有一个包含 19 个特征的数据集。当我使用 Lasso 算法运行它时，测试和训练的 R2 为 0.69。但测试的调整 r2 值为 1.28（高于 1），而训练的调整 r2 值为 0.28。这个问题的原因是什么？我该如何修复？我使用了以下公式。
def adj_r2_score(y_true, y_pred, n_samples, n_features):
r2 = r2_score(y_true, y_pred)
adj_r2 = 1 - ((1 - r2) * (n_samples - 1) / (n_samples - n_features - 1))
return adj_r2

n_samples_train = len(y_train)
n_samples_test = len(y_test)
n_features = X_train.shape[1]

adj_r2_train = adj_r2_score(y_train, train_pred, n_samples_train, n_features)
adj_r2_test = adj_r2_score(y_test, test_pred, n_samples_test, n_features)

print(f&#39;adj r2 train {adj_r2_train}&#39;)
print(f&#39;adj r2 test {adj_r2_test}&#39;)

n_samples_train = 35
n_samples_test = 10
n_features = 20]]></description>
      <guid>https://stats.stackexchange.com/questions/649241/unacceptable-results-for-adj-r2</guid>
      <pubDate>Fri, 14 Jun 2024 11:54:19 GMT</pubDate>
    </item>
    <item>
      <title>注意力层可以表示为 ANN 吗？</title>
      <link>https://stats.stackexchange.com/questions/649239/can-an-attention-layer-be-represented-as-an-ann</link>
      <description><![CDATA[因此，我花了一个多小时寻找这个问题的答案，但没有成功。这可能是一个非常简单的问题，但无论如何，我都非常感激能得到答案，因为我似乎在任何地方都找不到答案。
大型语言模型通常被归类为神经网络。我已经多次看到过这种情况，但仅举一个例子，维基百科将其归类为：

LLM 是利用 2017 年发明的变压器架构的人工神经网络

我的问题，简单地说，是：如何将注意力模块建模为 ANN？
在 CNN 的情况下，我确实理解如何将卷积运算分解为矩阵乘法和激活函数。这可能是一种低效的方法（矩阵中会有很多零），但至少在标准神经网络架构中构建它是可能的：
$$
h_1 = \sigma_1 \left( W_1x + b_1 \right) \\
h_2 = \sigma_2 \left( W_2h_1 + b_2 \right) \\
\dots \\
y = \sigma_n \left( W_n h_{n-1} + b_n \right)
$$
然而，我只是不明白 Transformer 中的注意层如何也如此。我遇到问题的部分是点积/矩阵乘法部分：
$$
\text{Attention}(Q, K, V) = \text{softmax} \left( \frac{QK^T}{\sqrt{d_k}} \right) V
$$
具体来说，对于部分$QK^T$，我不明白如何使用线性变换$W_i$与非线性激活交错来实现这一点。事实上，即使有一个神经网络将两个数字相乘，例如 $y = x_1 x_2$ 似乎也是有问题的。
我的问题是，是否有可能将自注意力层中的查询和键的点积实现为神经网络？或者我只是误解了我对神经网络的定义？我确实知道使用非常非标准的激活可以对此进行建模。例如，有一个输入向量 $[x_1, x_2]$，乘积可以建模为：
$$
h_1 = \begin{pmatrix}\log{(1 \cdot x_1 + 0 \cdot x_2)} \\ \log{(0 \cdot x_1 + 1 \cdot x_2)}\end{pmatrix} = \begin{pmatrix}\log{x_1} \\ \log{x_2}\end{pmatrix}\\
y = \exp{(1 \cdot h_{11} + 1 \cdot h_{12})} = \exp{(\log{x_1 x_2})} = x_1 x_2
$$
具体来说，我的问题是：当 Transformer 被称为神经网络时，是否意味着：

它主要是一个神经网络，但不是完全的？
它可以被建模为一个神经网络，但只能使用不再像生物神经元的奇怪激活？
有某种方法可以将它们表示为 ANN？如果有，具体怎么做？
神经网络的定义比线性投影和激活更广泛？

任何帮助都值得赞赏！]]></description>
      <guid>https://stats.stackexchange.com/questions/649239/can-an-attention-layer-be-represented-as-an-ann</guid>
      <pubDate>Fri, 14 Jun 2024 11:50:02 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归的导数（S 型）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/649238/derivative-of-logistic-regression-sigmoid</link>
      <description><![CDATA[我很难弄清楚为什么我从教授那里得到了不同的答案。我们的任务是找到逻辑回归成本函数与 S 型函数的导数：
$$ L(w│D)=-\frac{1}{m} ∑_{i=1}^{m}[y_i log(σ(w^T x_i))+(1-y_i )log(1-σ(w^T x_i)) ] $$
经过一些计算，我得到了解决方案：
$$ -\frac{1}{m} ∑_{i=1}^m[y_i-σ(w^T x_i )] x_i $$
但教授的答案是
$$ -\frac{1}{m} ∑_{i=1}^m[σ(w^T x_i ) - y_i] x_i $$
它翻转了...
我查看了许多其他计算，其中一些最终像我的一样，一些像教授的一样。此外，chatGPT 说两种形式都可以使用“在逻辑回归的背景下，两种形式都在不同的环境中使用。”
 我不明白如何以类似的方式解释这两种形式，因为我们的目标是最小化成本函数，每个减号都很重要。 

我不认为我的问题在于计算，但有人要求我上传我的作品：
]]></description>
      <guid>https://stats.stackexchange.com/questions/649238/derivative-of-logistic-regression-sigmoid</guid>
      <pubDate>Fri, 14 Jun 2024 11:49:03 GMT</pubDate>
    </item>
    <item>
      <title>社区检测 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649237/community-detection</link>
      <description><![CDATA[我需要一种方法来改进适用于图基因基因相互作用的社区检测，其中有些社区包含一个基因，因此我想改进它]]></description>
      <guid>https://stats.stackexchange.com/questions/649237/community-detection</guid>
      <pubDate>Fri, 14 Jun 2024 11:46:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 mgcv gam 进行物种分布建模中的可疑诊断</title>
      <link>https://stats.stackexchange.com/questions/649236/dubious-diagnostics-in-species-distribution-modeling-with-mgcv-gam</link>
      <description><![CDATA[我正在使用 R 中的 gams 和 mgcv 进行一些海洋物种分布建模。gam.check() 和 concurvity() 的诊断似乎令人怀疑。模型的规范是否存在问题，或者对于我拥有的数据类型，诊断是否正常？
该模型在 R 中指定为：
gam_mod &lt;- gam(DI ~ 
s(LON, LAT, bs = &quot;ds&quot;, k = 100) + 
s(Year, bs = &quot;gp&quot;, k = 10) + 
s(abs(gebco), k = 10),
data = data, method = &quot;REML&quot;, family = &quot;tw&quot;)

其中 DI 是物种丰度密度（个体/平方公里），Year 是采样年份的整数（17 年但有间隙），gebco 是采样站的水深（负整数，以米为单位）。数据集中有相当多的零丰度，tw 家族通常被认为适合这种类型的数据。
带有 str() 的数据结构：
&#39;data.frame&#39;: 1061 obs. 8 个变量中的 1 个：
$ 年份：int 1998 1998 1998 1998 1998 1998 1998 1998 1998 1998 ...
$ 纬度：num 40.9 40.7 40.6 40.8 40.7 ...
$ 经度：num 24.9 25.1 25.1 25.7 25.5 ...
$ 冲浪：num 0.0433 0.0481 0.0496 0.0439 0.0366 ...
$ TotalCatchNumber：num 0 0 369 0 0 ...
$ DI：num 0 0 7435 0 0 ...
$ gebco : int -27 -76 -145 -45 -57 -80 -134 -159 -339 -565 ...
$ TotalCatchNumber_round: num 0 0 369 0 0 235 336 274 217 0 ...

数据中带有 head() 的某些记录：
Year LAT LON Surf TotalCatchNumber DI gebco TotalCatchNumber_round
1 1998 40.85423 24.87905 0.04326880 0.00 0.000 -27 0
2 1998 40.70753 25.09062 0.04807875 0.00 0.000 -76 0
3 1998 40.59798 25.09530 0.04961738 368.92 7435.298 -145 369
4 1998 40.76515 25.69150 0.04391416 0.00 0.000 -45 0
5 1998 40.73920 25.53383 0.03664438 0.00 0.000 -57 0
6 1998 40.65958 25.41842 0.04438547 234.62 5285.964 -80 235

这是使用 summary() 的模型的摘要：
系列：Tweedie(p=1.559)
链接函数：log

公式：
DI \~ s(LON, LAT, bs = &quot;ds&quot;, k = 100) + s(Year, bs = &quot;gp&quot;, k = 10) +
s(abs(gebco), k = 10)

参数系数：
估计标准误差 t 值 Pr(\&gt;|t|) 
(截距) 5.90397 0.07315 80.71 \&lt;2e-16 \*\*\*
-

显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df F p 值
s(LON,LAT) 79.171 88.567 18.536 \&lt;2e-16 \*\*\*
s(Year) 6.903 7.140 22.604 \&lt;2e-16 \*\*\*
s(abs(gebco)) 5.299 6.296 9.818 \&lt;2e-16 \*\*\*
-

显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) = 0.537 偏差解释 = 79%
\-REML = 6959.5 尺度估计 = 22.897 n = 1061

然而，在 gam.check 结果中，所有预测因子的 k 指数均低于 1，尽管我认为指定为基础维度上限的 k 值对我的数据来说是现实的：
方法：REML 优化器：外牛顿
8 次迭代后完全收敛。
梯度范围 \[-1.002252e-05,1.056478e-05\]
（得分 6959.541 和尺度 22.89726）。
Hessian 正定，特征值范围 \[1.77463,2040.031\]。
模型等级 = 118 / 118

基础维度 (k) 检查结果。低 p 值 (k 指数 \&lt;1) 可能
表示 k 太低，尤其是当 edf 接近 k&#39; 时。

k&#39; edf k 指数 p 值

s(LON,LAT) 99.0 79.2 0.86 0.015 \* 
s(Year) 9.0 6.9 0.76 \&lt;2e-16 \*\*\*
s(abs(gebco)) 9.0 5.3 0.89 0.360
-

显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差与线性预测器的图表 &amp;观察值与拟合值似乎有问题，请参见链接的图图像文件：
最后，共曲性检查表明 s(LON, LAT) 和 s(abs(gebco)) 存在共曲性问题，因为这些预测因子的第一行（最差）中的值几乎等于 1：
 para s(LON,LAT) s(Year) s(abs(gebco))

最差 1.002761e-18 0.9976474 0.22243539 0.9976475
观察值 1.002761e-18 0.2192788 0.03608689 0.9919063
估计值 1.002761e-18 0.1367153 0.20069831 0.9799472
]]></description>
      <guid>https://stats.stackexchange.com/questions/649236/dubious-diagnostics-in-species-distribution-modeling-with-mgcv-gam</guid>
      <pubDate>Fri, 14 Jun 2024 11:41:31 GMT</pubDate>
    </item>
    <item>
      <title>Cox 回归中的调节因素分析</title>
      <link>https://stats.stackexchange.com/questions/649234/moderator-analysis-in-cox-regression</link>
      <description><![CDATA[设想一个 RCT，其中有两组，具有事件发生时间终点。分析此试验的（预先指定的）策略是 Cox 回归，使用常见的协变量调整来减少结果异质性。到目前为止，一切顺利。现在我想知道我的治疗效果是否受教育水平（3 个级别）的影响。如果我使用预先指定的 cox 回归和协变量调整并整合治疗*教育相互作用，SE 会变得非常大。可能的原因是什么？我的样本量（每组 120 个）是否太少，我应该减少要调整的协变量吗？
编辑：我控制了 4 个协变量。IG 中有 76 个事件，CG 中有 91 个事件。更具体地说：
教育水平1：IG：13 CG：18。教育水平2：IG：32 CG：28。教育水平3：IG：31 CG：45]]></description>
      <guid>https://stats.stackexchange.com/questions/649234/moderator-analysis-in-cox-regression</guid>
      <pubDate>Fri, 14 Jun 2024 10:54:34 GMT</pubDate>
    </item>
    <item>
      <title>倾向得分与倾向得分匹配？</title>
      <link>https://stats.stackexchange.com/questions/649221/propensity-score-vs-propensity-score-matching</link>
      <description><![CDATA[我正在尝试自学双重稳健估计。在我看来，双重稳健估计使用倾向得分，但不使用倾向得分匹配。
以下是我对使用逻辑回归模型的二元治疗/二元结果的倾向得分匹配的理解：

步骤 1：没有倾向得分匹配的逻辑回归、可能性和平均治疗效果：
$$ P(Y=1|X=x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + ... + \beta_k x_k)}} $$
$$ L(\beta) = \prod_{i=1}^{N} P(Y_i|X_i)^{Y_i} (1 - P(Y_i|X_i))^{(1-Y_i)} $$
$$ \tau = P(Y=1|X=x, T=1) - P(Y=1|X=x, T=0) $$

步骤 2：创建一个统计模型来估计倾向得分：
$$ e(X_i) = P(T=1|X_i) = \frac{1}{1 + e^{-(\alpha_0 + \alpha_1 x_{i1} + ... + \alpha_k x_{ik})}} $$

步骤 3：使用某种匹配方法（例如贪婪，$g$）将一种治疗中的患者与另一种治疗中最接近的患者进行匹配基于协变量和估计的倾向得分：


$$ g(i) = \underset{j: T_j=0}{\mathrm{argmin}} |e(X_i) - e(X_j)| $$

步骤 4：总结匹配：
$$ w_i = \begin{cases} 
1 &amp; \text{if individual } i \text{ is matching} \\
0 &amp; \text{如果 individual } i \text{ 不匹配}
\end{cases} $$

步骤 5：重写可能性以考虑倾向得分匹配的影响（这里我们假设在原始 $N$ 名患者中只有 $M$ 名患者匹配）：


$$ L_w(\beta) = \prod_{i=1}^{M} \left( P(Y_i|X_i)^{Y_i} (1 - P(Y_i|X_i))^{(1-Y_i)} \right)^{w_i} $$

步骤 6：使用倾向得分定义平均治疗效果匹配：

$$ \tau_{ps} = \frac{1}{M} \sum_{i=1}^{M} \left( Y_i - Y_{g(i)} \right) $$

第 7 步：倾向得分匹配的数学含义 - 使用倾向得分匹配的平均治疗效果可以更接近真实的平均治疗效果（与没有倾向得分匹配的平均治疗效果相比）：

$$ E(\tau_{ps}) \approx E(\tau_{true}) &lt; E(\tau) $$
基于此，我试图了解这与双重稳健估计的关系。在我看来，双重稳健估计使用倾向得分，但不使用倾向得分匹配：

步骤 1：建立一个统计模型，估计给定协变量（即倾向得分）接受治疗的概率：

$$ P(T=1|X) = \frac{1}{1 + e^{-(\alpha + \beta X)}} $$

步骤 2：为结果变量定义一个统计模型，例如

$$ E(Y|T,X) = \gamma + \delta T + \theta X $$
这里 $\gamma$ 是截距，$\delta$ 是治疗效果，$\theta$ 是协变量的系数（这些都需要估计）。

步骤 3：根据治疗和倾向得分定义权重：

对于接受治疗的个体 $T=1$：
$$ w_1 = \frac{1}{P(T=1|X)} $$
对于对照个体 $T=0$：
$$ w_0 = \frac{1}{1 - P(T=1|X)} $$

步骤4：最后，定义双重稳健估计下的平均治疗效果：

$$ ATE = \frac{1}{N} \sum_{i=1}^{N} \left( w_1 \cdot Y_i \cdot T_i + w_0 \cdot (Y_i - \hat{Y}_i) \cdot (1 - T_i) \right) $$
$$\hat{Y}_i = E(Y_i|T_i,X_i) = \gamma + \delta T_i + \theta X_i$$
这是正确的吗？双重稳健估计使用倾向得分而不是倾向得分匹配？]]></description>
      <guid>https://stats.stackexchange.com/questions/649221/propensity-score-vs-propensity-score-matching</guid>
      <pubDate>Fri, 14 Jun 2024 05:43:33 GMT</pubDate>
    </item>
    </channel>
</rss>