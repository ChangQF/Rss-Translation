<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 03 Sep 2024 12:31:10 GMT</lastBuildDate>
    <item>
      <title>完成充分统计量练习问题背后的动机</title>
      <link>https://stats.stackexchange.com/questions/653790/motivation-behind-this-exercise-problem-on-complete-sufficient-statistic</link>
      <description><![CDATA[这来自 Hogg 和 McKean 的《数理统计学导论》第 7 章（充分性），第 7.4 节（完整性和唯一性）。
练习 7.4.10。
设 $Y_1 &lt; Y_2 &lt; \cdots &lt; Y_n$ 为大小为 $n$ 的随机样本的顺序统计量，样本来自具有 pdf $f (x; \theta) = 1/\theta,$ $0 &lt; x &lt; \theta$ 的分布，其他地方为零。通过示例 $7.4.2$，统计量 $Y_n$ 是 $\theta$ 的完全充分统计量，并且它的 pdf
$$g(y_n;\theta)= \frac{ny_n^{n-1}}{\theta^n} , 0&lt;y_n &lt;\theta,$$
其他地方为零。
(a) 找到 $Z = n(\theta − Y_n)$ 的分布函数 $H_n(z; \theta)$。
(b) 找到 $\lim_{n \to \infty} H_n(z; \theta)$，因此是 Z 的极限分布。
我的问题：
这个问题的解决方法非常简单，我并没有问如何解决这个问题。事实上，他在上一章的练习中已经给出过这个问题，而我当时已经解决了。我的问题是“这与完整性和唯一性有什么关系？”
有关我的问题的更多详细信息：
在本文的这一点上，均匀分布$U(0,\theta)$中随机样本的$n^{th}$阶统计量可用作$\theta$的估计量，这一事实已被彻底驳倒。他还提到，已经确定（在示例 $7.4.2$ 中）它是一个完全充分统计量，并且 $n/(n+1)Y_n$ 是 $\theta$ 的所谓 MVUE。他提出的问题（其部分 (a) 和 (b) 之前已经问过）似乎与完整性无关，这感觉很奇怪。
如果您能看到此练习的解决方案与完整性之间的任何联系，即如果您能看到在完整性部分提出此问题的动机，请向我说明。]]></description>
      <guid>https://stats.stackexchange.com/questions/653790/motivation-behind-this-exercise-problem-on-complete-sufficient-statistic</guid>
      <pubDate>Tue, 03 Sep 2024 11:58:23 GMT</pubDate>
    </item>
    <item>
      <title>在元回归中正确建模小剂量的连续对数剂量反应关系</title>
      <link>https://stats.stackexchange.com/questions/653788/correctly-modelling-a-continuous-log-dose-response-relationship-in-meta-regressi</link>
      <description><![CDATA[我正在研究一种计划的有效性，该计划的疗程数范围为 1 到 20。我首先进行荟萃分析 (k = 70)，结果显示该类计划的平均效果大小为 0.50 SD。在我的荟萃分析中，平均疗程数为 7。我想预测实施 1 疗程的该计划的效果。
(1) 我可以先预测为 0.50 * (1/7) = 0.07。其中 1/7 = 0.14 可作为疗程数（即剂量）的线性调整。但是，我认为凹剂量反应关系比线性关系更合理。所以也许我应该做 ln(1)/ln(7)。嗯，这行不通，因为 ln(1) = 0。所以我可以做 ln(1+1)/ln(7+1) = 0.33 吗？
但是，我还没有看到这样的先例。我认为人们不会用 ln(income+1) 来做模型——我见过的主要变量是收入，以这种方式处理——尽管这可能并不重要，因为收入是 1000 而不是 1 到 20。还不清楚除 +1 之外的常数是否合适。
(2) 与其使用一般剂量调整，也许我想用更多的证据来锚定它。我可以用元回归来预测剂量反应关系，其中我预测参加的课程次数的效果。如果我想要对数剂量反应关系，我应该使用 ln(sessions) 作为预测因子还是使用 ln(sessions+1)？这会改变截距的含义吗？其中 ln(sessions) 的截距是 session = 1 时的效果，因为 ln(1) = 0，而 ln(sessions+1) 的截距是 session = 0 时的效果，因为 ln(0+1) = 0？
(3) 如果我的模型给出的截距为 0.20 SD，每个 session 的效果为 0.65 SD，那么我能否将调整计算为 (0.20 + ln(1+1)*0.65)/(0.20 + ln(7+1)*0.65) = 0.42？
(4) 将此预测因子均值居中是否会在解释和计算调整方面发生任何变化？
感谢您的时间！]]></description>
      <guid>https://stats.stackexchange.com/questions/653788/correctly-modelling-a-continuous-log-dose-response-relationship-in-meta-regressi</guid>
      <pubDate>Tue, 03 Sep 2024 09:50:52 GMT</pubDate>
    </item>
    <item>
      <title>多级回归，模型规范</title>
      <link>https://stats.stackexchange.com/questions/653787/multilevel-regression-model-specification</link>
      <description><![CDATA[我们非常感谢您就分析我们的研究设计的最佳方式提出建议：
我们研究了教育内容的传递媒体（即增强现实与视频）对记忆（“binary_memory_score”）随时间（“时间”）的影响。我们有 20 次增强现实体验，每次体验都有三个记忆问题（每个多项选择题有四个选项）。视频是增强现实体验的屏幕录制。
我们有两种条件（增强现实与视频），我们分别随机招募（在受试者之间）。参与者被要求参与教育内容并回答记忆问题。对于这两个组，参与者被招募到五个“群组”，代表不同的教育主题（例如群组 1 = 艺术，群组 2 = 科学），这意味着群组也是一个受试者间变量。在每个队列中，所有队列参与者都经历了五种关于该队列主题的特定体验（在队列 1 中，我们有体验 1、体验 2、体验 3、体验 4、体验 5；在队列 2 中，我们有体验 6、体验 7 等）。
在完成每项体验后的初始记忆测试（time_0）之后，一些参与者在 1 个月后（gap1）或 6 个月后（gap6）再次被问到问题（time_later）。因此，我们有一个受试者内时间因素（time_0 vs time_later）和一个受试者间差距因素（gap1 vs gap6）。我们目前将记忆作为二元变量（正确答案 vs 错误答案）作为单个记忆问题（“exp_title_question”）的“分数”。以下是我们提出的使用 glmer 的分析：
binary_memory_score ~ 1 + media*time*gap + (1 | experience / experience_question) + (1 + time | id) + (1 | cohort / id), family = binomial(&quot;logit&quot;), nAGQ=0, control=glmerControl(optimizer = &quot;nloptwrap&quot;), data=combined_data_cor_screened,contrasts = list(media = contr.sum, time=contr.sum, gap=contr.sum))

非常感谢您的想法或建议。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653787/multilevel-regression-model-specification</guid>
      <pubDate>Tue, 03 Sep 2024 08:23:00 GMT</pubDate>
    </item>
    <item>
      <title>如何比较混合模型和线性模型（忽略重复测量）？</title>
      <link>https://stats.stackexchange.com/questions/653786/how-to-compare-mixed-model-vs-linear-model-ignoring-replicated-measurements</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653786/how-to-compare-mixed-model-vs-linear-model-ignoring-replicated-measurements</guid>
      <pubDate>Tue, 03 Sep 2024 08:11:52 GMT</pubDate>
    </item>
    <item>
      <title>回归方程预测值的标准差</title>
      <link>https://stats.stackexchange.com/questions/653785/standard-deviation-of-predicted-value-of-a-regression-equation</link>
      <description><![CDATA[在残差独立的典型回归设置中，响应变量的新值的标准差将是
${\sigma} \sqrt{ \left(1 + a^T { \left(X^T X \right)}^{-1} a\right)}$
其中 $\sigma$ 是回归方程中误差项的标准差，$a$ 是解释变量的新值的向量，$X$ 是用于估计回归参数的设计矩阵。
然而在我的例子中，误差不是独立的，而是遵循以下形式
${\varepsilon}_{t} = {\gamma}_{1}{\varepsilon}_{t-1} + {\gamma}_{2}{\varepsilon}_{t-2} + {\nu}_{t} $
这里${\nu}_t$服从独立正态分布。
在这种情况下，我如何才能正确得出响应变量新值的标准差？
任何指针或在线资源都会非常有帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/653785/standard-deviation-of-predicted-value-of-a-regression-equation</guid>
      <pubDate>Tue, 03 Sep 2024 07:48:05 GMT</pubDate>
    </item>
    <item>
      <title>标题：用 Python 拟合带有趋势项的准周期函数的问题</title>
      <link>https://stats.stackexchange.com/questions/653784/title-issues-with-fitting-a-quasi-periodic-function-with-a-trend-term-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653784/title-issues-with-fitting-a-quasi-periodic-function-with-a-trend-term-in-python</guid>
      <pubDate>Tue, 03 Sep 2024 07:17:48 GMT</pubDate>
    </item>
    <item>
      <title>as.POSIXct 导致我的某些数据为 NA</title>
      <link>https://stats.stackexchange.com/questions/653781/as-posixct-results-in-nas-for-some-of-my-data</link>
      <description><![CDATA[我想将我的日期列转换为
可重现的数据集：
structure(list(rownum = c(1L, 2L, 3L, 4L, 5L, 4338L, 10694L, 
24305L, 29262L, 36277L, 48599L, 57181L, 65107L, 68320L, 74071L
), date = c(&quot;2022-04-05 22:00&quot;, &quot;2022-04-05 23:00&quot;, &quot;2022-04-06 00:00&quot;, 
&quot;2022-04-06 01:00&quot;, “2022-04-06 02:00”, “2022-10-02 02:00”, “2023-10-01 02:00”, 
“2022-10-02 02:00”, “2023-10-01 02:00”, “2021-10-03 02:00”, “2021-10-03 02:00”, 
“2022-10-02 02:00”, “2021-10-03 02:00”, “2021-10-03 02:00”, &quot;2022-10-02 02:00&quot;
), 年 = c(2022L, 2022L, 2022L, 2022L, 2022L, 2022L, 2023L, 
2022L, 2023L, 2021L, 2021L, 2022L, 2021L, 2021L, 2022L), 月 = c(4L, 
4L, 4L, 4L, 4L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L), 日 = c(5L, 5L, 6L, 6L, 6L, 2L, 1L, 2L, 1L, 3L, 3L, 2L, 
3L, 3L, 2L), hour = c(22L, 23L, 0L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L)), row.names = c(1L, 2L, 3L, 4L, 5L, 4317L, 
10648L, 18112L, 23041L, 29949L, 42012L, 46606L, 53202L, 56415L, 
62166L), class = &quot;data.frame&quot;)

如果我运行这个代码：
data_samp$date &lt;- as.POSIXct(data_samp$date, format= &quot;%Y-%m-%d %H:%M&quot;, tz = &quot;Australia/Sydney&quot;)

您可以看到，第 1-5 行具有正确的日期，而其余行都是 NA – 尽管已转换为 POSIXct。
&gt; str(data_samp)
&#39;data.frame&#39;: 15 obs. 6 个变量：
$ rownum: int 1 2 3 4 5 4338 10694 24305 29262 36277 ...
$ date : POSIXct, format: &quot;2022-04-05 22:00:00&quot; &quot;2022-04-05 23:00:00&quot; &quot;2022-04-06 00:00:00&quot; &quot;2022-04-06 01:00:00&quot; ...


我有一个更大的数据集，有 66,753 行，其中只有 10 行在我尝试转换时出现 NA。我不知道为什么。麻烦的日期是：2021 年 10 月 3 日凌晨 2 点；2022 年 10 月 2 日凌晨 2 点；2023 年 10 月 1 日凌晨 2 点。除了凌晨 2 点之外，一天中的其他时间都没有问题。
编辑 - 我设法使用以下方法修复了它：
tz=&quot;ETC/GMT+10&quot;)

而不是 tz=&quot;Australia/Sydney&quot;（或没有 tz 定义）。
但我仍然不明白为什么这样可以修复它 - 我猜可能与夏令时有关？解释一下这里发生的事情会很有帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/653781/as-posixct-results-in-nas-for-some-of-my-data</guid>
      <pubDate>Tue, 03 Sep 2024 04:13:03 GMT</pubDate>
    </item>
    <item>
      <title>从偏斜分布中均匀抽取</title>
      <link>https://stats.stackexchange.com/questions/653780/drawing-uniformly-from-a-skewed-distribution</link>
      <description><![CDATA[是否有方法可以从倾斜的总体中抽取样本，使样本均匀分布？
例如，如果我想显示身高和工资之间的相关性，但总体中身材矮小的人居多，则热图将显得倾斜，不会提供任何信息。
这是一种不好的做法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653780/drawing-uniformly-from-a-skewed-distribution</guid>
      <pubDate>Tue, 03 Sep 2024 04:12:16 GMT</pubDate>
    </item>
    <item>
      <title>anova（）和summary（）之间的区别？</title>
      <link>https://stats.stackexchange.com/questions/653778/difference-between-anova-and-summary</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653778/difference-between-anova-and-summary</guid>
      <pubDate>Tue, 03 Sep 2024 01:59:06 GMT</pubDate>
    </item>
    <item>
      <title>经过超参数调整、数据集平衡和卷积分层后，模型仍然过拟合</title>
      <link>https://stats.stackexchange.com/questions/653776/model-still-overfits-after-hyperparameter-tuning-dataset-balancing-and-convolut</link>
      <description><![CDATA[我尝试将堆叠在一起的 25x25 像素图像分类为 50x25 像素图像是相同 (1) 还是不同 (0)。我使用 keras 创建 NN 层。训练集中有 1 和 0 的实例 10,000 个，而验证集中有 2000 张 1 的图像和 500 张 0 的图像。
相同 (1) 的示例数据集：

不同 (0) 的示例数据集：

Keras 顺序层如下所示：
layers.Input((2*imsize,imsize,3)), 
layers.Reshape((2,imsize,imsize,3)), 
layers.LayerNormalization(axis=[-1,-2,-3]), 
layers.Flatten(), 
layers.Dense(16,activation=&#39;relu&#39;), 
layers.Dense(2,activation=&#39;softmax&#39;) 

然后我使用 adam 优化器编译了这些层，损失和准确率如下：
ml.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), 
metrics=[&#39;accuracy&#39;])
ml_hist = ml.fit(x=training_dataset, epochs=20, validation_data = validation_dataset, shuffle=True)

之后，我使用 epoch=20 和 batch_size=100 训练模型。我根据 epoch 绘制了这些结果。
结果

尝试将验证集平衡为 500 个 1 和 500 个 0 后，结果仍然过度拟合

我甚至删除了正则化并添加了 2 个卷积和池化层有用。它只会导致较低的准确率
layers.Input((2*imsize,imsize,3)), 
layers.Reshape((2*imsize,imsize,3)), 
layers.LayerNormalization(axis=[-1,-2,-3]), 

# 新层 
layers.Conv2D(32, (3, 3),activation=&#39;relu&#39;,padding=&#39;same&#39;),
layers.MaxPooling2D(pool_size=(2, 2)),
layers.Conv2D(64, (3, 3),activation=&#39;relu&#39;,padding=&#39;same&#39;),
layers.MaxPooling2D(pool_size=(2, 2)),

layers.Flatten(), 
layers.Dropout(rate=0.7), 
layers.Dense(16,activation=&#39;relu&#39;),
layers.Dense(2,activation=&#39;softmax&#39;) 


我的问题是：如何解决这个过度拟合问题？我不知道我做错了什么，我尝试将学习率更改为 0.1、0.01 和 0.001。我还尝试在 Flatten() 之后、ReLu 之前添加 0.2、0.5 和 0.7 的 Dropout 层。]]></description>
      <guid>https://stats.stackexchange.com/questions/653776/model-still-overfits-after-hyperparameter-tuning-dataset-balancing-and-convolut</guid>
      <pubDate>Tue, 03 Sep 2024 00:30:42 GMT</pubDate>
    </item>
    <item>
      <title>如果你得了一种疾病，存活 5 年的几率为 50%，存活 10 年的几率为 30%，那么 5 年后存活 10 年的几率是多少？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653770/if-you-had-a-disease-with-a-50-chance-of-living-5-years-and-a-30-chance-of-liv</link>
      <description><![CDATA[请参阅标题以获取所需的所有信息。另请提供方法/数学。]]></description>
      <guid>https://stats.stackexchange.com/questions/653770/if-you-had-a-disease-with-a-50-chance-of-living-5-years-and-a-30-chance-of-liv</guid>
      <pubDate>Mon, 02 Sep 2024 22:15:14 GMT</pubDate>
    </item>
    <item>
      <title>当省略随机斜率时，如何使用 lmer()、anova() 和 bootstrap 评估混合模型？</title>
      <link>https://stats.stackexchange.com/questions/653749/how-to-evaluate-mixed-model-using-lmer-anova-and-bootstrap-when-omitting-ra</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653749/how-to-evaluate-mixed-model-using-lmer-anova-and-bootstrap-when-omitting-ra</guid>
      <pubDate>Mon, 02 Sep 2024 15:12:12 GMT</pubDate>
    </item>
    <item>
      <title>当从混合模型中省略固定效应时，如何解释 1 型错误？</title>
      <link>https://stats.stackexchange.com/questions/653747/how-to-interpret-type-1-error-when-omitting-fixed-effect-from-mixed-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653747/how-to-interpret-type-1-error-when-omitting-fixed-effect-from-mixed-model</guid>
      <pubDate>Mon, 02 Sep 2024 14:21:54 GMT</pubDate>
    </item>
    <item>
      <title>具有 [0,1] 中连续权重的随机块模型</title>
      <link>https://stats.stackexchange.com/questions/653746/stochastic-blockmodel-with-continuous-weights-in-0-1</link>
      <description><![CDATA[我想使用随机块模型 (SBM) 对网络中的节点进行聚类，其中边权重是 0 到 1 之间的连续数字。似乎 blockmodels 和 SBM 等 R 软件包为权重提供了伯努利、泊松和高斯分布。高斯是唯一提供的连续分布（在我查看过的软件包中），但我的权重分布为众数为 0（最小值），一些权重恰好为零（可能不是问题，因为似乎允许不存在边），而其他权重从众数为零向上严重倾斜分布。我确实明白，SBM 中的高斯模型并不一定意味着权重必须整体呈高斯分布，因为它可以是社区内和社区之间的不同高斯的混合，但似乎仍然没有办法将两个或几个高斯的混合放在一起来模拟我所拥有的权重分布。此外，我很惊讶地发现边缘权重首先是高斯分布，因为在我知道的几乎所有情况下，权重都被限制为正，而高斯分布将质量放在整个实线上（当然，它有时仍然是正数据的良好近似值）。
在这种情况下该怎么办？无论如何都要拟合高斯模型？是否有任何版本的 SBM 实现假设其他分布，例如指数或 Beta？我应该将权重转换为“近高斯”吗？如果可能的话？
更一般地说，我是否正确理解了高斯假设适用于原始权重（分别在社区之间和社区内），而不是某些潜在变量或允许强非高斯权重的东西？我发现很难找到对连续权重的 SBM 的全面解释。此外，对我来说似乎很奇怪，唯一可用于连续数据的模型似乎是一种作为标准生成负值的模型，而实际上我所看到的只是权重被限制为非负值。]]></description>
      <guid>https://stats.stackexchange.com/questions/653746/stochastic-blockmodel-with-continuous-weights-in-0-1</guid>
      <pubDate>Mon, 02 Sep 2024 14:01:31 GMT</pubDate>
    </item>
    <item>
      <title>比较排名时的百分比变化与绝对变化</title>
      <link>https://stats.stackexchange.com/questions/653739/percentage-changes-versus-absolute-changes-when-comparing-rankings</link>
      <description><![CDATA[我们正在分析基于经济指数的国家排名变化，以确定这些变化是否显著。例如，国家 A 从第 5 位上升到第 3 位，代表着 40% 的进步，而国家 B 从第 50 位上升到第 48 位，代表着仅 4% 的进步。尽管两个国家都上升了两位，但百分比变化表明国家 A 的进步比国家 B 的进步更为显著。
使用排名来比较表现在社会科学中被广泛使用，例如经济学、社会学和心理学。这是有道理的，因为它可以简化复杂的数据，并有助于进行比较分析。有时，指数的确切数字分数可能不如了解一个国家相对于其他国家的立场重要，特别是如果目标是确定领先者和落后者。经济指数通常汇总多个指标（例如，人类发展指数），使直接比较基础数据变得复杂。排名将这种复杂性提炼为一个单一的、易于理解的数字，从而有助于跨多个维度进行比较。在这种情况下，排名的非线性特性（排名之间的间隔不相等）可能证明排名百分比变化可以更好地反映不同位置之间变化的相对重要性。
这提出了一个问题：在处理排名数据时，使用百分比变化而不是绝对变化来评估排名变化是否更有意义？是否有讨论这个问题的学术参考资料，它们提供了什么结论？]]></description>
      <guid>https://stats.stackexchange.com/questions/653739/percentage-changes-versus-absolute-changes-when-comparing-rankings</guid>
      <pubDate>Mon, 02 Sep 2024 12:24:37 GMT</pubDate>
    </item>
    </channel>
</rss>