<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 28 Dec 2023 00:58:37 GMT</lastBuildDate>
    <item>
      <title>神经网络与线性回归内联执行，我该如何改进它？</title>
      <link>https://stats.stackexchange.com/questions/635741/neural-net-performs-inline-with-linear-regression-how-can-i-improve-it</link>
      <description><![CDATA[我有一个回归问题，涉及大约 100 万个样本和 400 个特征（有些特征不太有意义和/或冗余）和 1 个目标变量。我一直在努力设计一种神经网络架构，在验证数据中击败线性回归（通过正则化），但到目前为止我得到的只是与线性回归一致，并没有明显更好。
我主要关注添加了一些复杂性的前馈网络，例如：

多个密集层（对单元数量、归一化、激活、丢失等有不同的选择）
有或没有剩余连接
具有某些门控的并行网络，这些门控取决于功能子集。类似于分层线性回归。
首先训练自动编码器以降低输入维度，然后执行上述所有操作。
短暂尝试过 CNN 和其他更复杂的层，但这不是我的重点。

它们的表现与线性回归差不多，甚至更差。对我来说有点奇怪的是，为什么打败线性回归如此困难，我认为向基线线性模型添加一个小的非线性至少应该有一点帮助。
我的问题是，除了上述之外，高级 ML 从业者还会尝试什么？任何对标准方法或开箱即用的想法的指导都将受到高度赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/635741/neural-net-performs-inline-with-linear-regression-how-can-i-improve-it</guid>
      <pubDate>Wed, 27 Dec 2023 23:46:56 GMT</pubDate>
    </item>
    <item>
      <title>使用贝叶斯定理和给定的准确度统计数据</title>
      <link>https://stats.stackexchange.com/questions/635739/using-bayes-theorem-with-given-accuracy-statistics</link>
      <description><![CDATA[证明贝叶斯基本定理的一个常见示例是药物测试或疾病测试。例如，贝叶斯定理的维基百科页面有一个大麻测试的示例其中讨论了敏感性和特异性，以证明测试可以正确识别实际用户 90 % 的情况下，这并不意味着阳性结果意味着该主题有 90% 的概率是用户。我知道这里的基本内容。
这一切都有道理。但在某些情况下，我发现类似的例子，其中准确度被用作灵敏度的直接替代品。也就是说，该示例将与上面的示例同构，但使用测试的准确性而不是灵敏度。
我知道准确性是“真实阳性”和/加上“真实阴性”除以所有预测。使用准确性来替代敏感性（或特异性）似乎是一个错误。例如，如果我们谈论死亡率，假设任何活着的人明年死亡的几率约为 1%。因此，我可以创建一个“死亡预测器”，其中包含：return False，其准确度将为 99%。
我认为应用贝叶斯定理使用准确性代替敏感性或特异性是一个错误，这是否正确？以这种方式使用准确性是否假设错误在两个类之间均匀分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/635739/using-bayes-theorem-with-given-accuracy-statistics</guid>
      <pubDate>Wed, 27 Dec 2023 22:59:43 GMT</pubDate>
    </item>
    <item>
      <title>时间序列中的残差和“误差项”</title>
      <link>https://stats.stackexchange.com/questions/635738/residuals-and-error-terms-in-time-series</link>
      <description><![CDATA[我正在自学，我发现“残差”似乎是我们去掉非随机成分后剩下的东西。因此，如果我们进行加法分解：
$$ 系列 = 漂移 + 趋势\text{ }_t + 季节性\text{ }_t + RandomComponent\text{ }_t $$
$$ = \alpha + \beta t + S_t + u_t $$
残差为$u_t$。
但是现在，如果我们想在残差 $u_t$ 上拟合 ARMA，比如说 ARMA(2,2)，那么 MA(2) 就是应该是“错误术语”。所以它也可以被认为是残差（残差是观察到的错误）。也许错误的是，我从这个术语中推断出 MA 应该被理解为“残差”。 ARMA 流程：
$$ ARMA(2,2) : $$
$$u_t = X_t = \sum_{i=1}^2 {\phi_{t-i}X_{t-i}} + \sum_{i=1}^2 \theta_{t-i }\varepsilon_{t-i}$$
$$\rightarrow X_t = AR(2) + 错误\_terms$$
$$\rightarrow X_t = AR(2) + 残差 $$
在这种情况下，残差将是 $MA(2)$。
或者，如果我们拟合 ARMA(p,0) 并且没有 MA 部分，我预计残差为 $\varepsilon$ 白噪声AR 流程。
所以每当我们谈论“残差”时，例如当我们执行 Box-Jenkins 算法的测试时，我们的意思是什么？是整个 ARMA（$u_t$ 分解残差）还是我们应该放大 $u_t$&lt; 的 MA 分量/span&gt;（错误术语）？]]></description>
      <guid>https://stats.stackexchange.com/questions/635738/residuals-and-error-terms-in-time-series</guid>
      <pubDate>Wed, 27 Dec 2023 22:37:47 GMT</pubDate>
    </item>
    <item>
      <title>分类变量的假设检验</title>
      <link>https://stats.stackexchange.com/questions/635735/hypothesis-testing-of-categorical-variables</link>
      <description><![CDATA[上下文

假设我通过 Google 表单收集了一项调查的数据集，我的样本由 32 行组成，其中包含填写调查的人员的年龄/性别/专业，每个问题都有多项选择答案以及满意度示例（我的问题是 1+1=？ a) 1 , .. e) 5 每个都具有“完全不同意”的满意程度“完全同意”，我的研究对象是影响就业率的决定因素，这是我的概念模型：


问题：
3）还有人可以向我解释如何构建相关矩阵吗？或者它被称为独立性，还有关联性检验，以及如何为我的统计研究构建回归模型？

因此，调查中问题的答案被视为定性实体，因此我们应用 chi² 检验，但在我们根据所选选项的每个满意度进行编码后，这是否会使实体定量？

好吧，无论我测试正态性的变量是什么类型，测试的 p 值是否能告诉我这是否是总体上的最佳/正确选择？

]]></description>
      <guid>https://stats.stackexchange.com/questions/635735/hypothesis-testing-of-categorical-variables</guid>
      <pubDate>Wed, 27 Dec 2023 21:41:05 GMT</pubDate>
    </item>
    <item>
      <title>前/后测试[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635732/pre-post-testing</link>
      <description><![CDATA[上下文

假设我通过 Google 表单收集了一项调查的数据集，我的样本由 32 行组成，其中包含填写调查的人员的年龄/性别/专业，每个问题都有多项选择答案以及满意度示例（我的问题是 1+1=？ a) 1 , .. e) 5 每个都具有“完全不同意”的满意程度“完全同意”，我的研究对象是影响就业率的决定因素，这是我的概念模型：

问题：

完成编码阶段后（将每个问题的答案的满意度从字符串转换为数字（0-5），
我是否必须测试包含每个问题答案的满意度的表中每一列的正态性？如果是这样，我必须应用什么测试是 chisq.test 吗？分别对每一行进行正态性测试，我们能得到什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635732/pre-post-testing</guid>
      <pubDate>Wed, 27 Dec 2023 20:33:39 GMT</pubDate>
    </item>
    <item>
      <title>给定一个不同非整数值的数组，如何找到 99% 的数据在上面的值和 99% 的数据在下面的值</title>
      <link>https://stats.stackexchange.com/questions/635730/given-an-array-of-different-non-integer-values-how-do-i-find-the-value-where-99</link>
      <description><![CDATA[通过浏览列表，我可以轻松找到列表的最小值和最大值，
但我似乎不知道如何获得最小值的 99% 和最大值的 99%。
我需要这个主要是因为数据中有一些尖峰，我想在没有这些尖峰的情况下绘制它
我认为取整个分布的加权平均值，
然后除以权重*99 就会得到 1% 的位置，权重/99 就会得到 99% 的位置。这是正确的吗？
我试图在不对数组进行排序的情况下解决问题]]></description>
      <guid>https://stats.stackexchange.com/questions/635730/given-an-array-of-different-non-integer-values-how-do-i-find-the-value-where-99</guid>
      <pubDate>Wed, 27 Dec 2023 19:56:40 GMT</pubDate>
    </item>
    <item>
      <title>差异中的差异和治疗选择</title>
      <link>https://stats.stackexchange.com/questions/635729/difference-in-difference-and-selection-into-treatment</link>
      <description><![CDATA[假设我强加一些感兴趣变量的真实模型是：
$$
Y_{it} = \alpha_i + \beta_t+\tau_{it}D_{it}+\epsilon_{it}
$$
其中 $ D_{it} = 1\{E_i \geq t\} $。这是一种 DID 模型，您可以看到治疗效果存在异质性。进一步假设治疗分配不依赖于随机冲击：
$$ E[D_{it}|\epsilon_{it}, \alpha_i, \beta_t, X] = E[D_{it}| \alpha_i, \beta_t, X] $$
我相信我在这里问了一些愚蠢的问题，但是有没有办法从这个假设得出以下结论？：
$$
E[\epsilon_{it}|D_{it}, \alpha_i, \beta_t, X] = E[\epsilon_{it}| \alpha_i, \beta_t, X]
$$
后者当然是非常标准的。我问这个问题的原因是，如果治疗时间是随机的，则隐含着前一个假设，这对于 DID 来说应该足够了，但我在这里没有看到它。也许治疗分配的平均独立性不够强？]]></description>
      <guid>https://stats.stackexchange.com/questions/635729/difference-in-difference-and-selection-into-treatment</guid>
      <pubDate>Wed, 27 Dec 2023 19:27:05 GMT</pubDate>
    </item>
    <item>
      <title>OLS 不相关性假设</title>
      <link>https://stats.stackexchange.com/questions/635728/ols-assumptions-of-uncorrelatedess</link>
      <description><![CDATA[处理非时间序列数据的数据$(X,Y)$时，例如$X= \text{weight}$ 和 $Y=\text{height}$，我们可以使用 OLS 来估计系数 $Y=b_1 X+b_0 的容器&quot;&gt;$b_1$ 和 $b_0$ $ 仅当某些假设得到满足时。
假设之一是残差彼此不相关。我们如何用数字检验这个假设？我们是否简单地执行函数 $\text{res}(X)$ 和它的移动版本 $\text 之间的自相关{res}(X + \delta X)$？
另一个假设是 $X$ 值和残差 $\text{res}(X)$  不相关。我们是否只需对两两乘积 $X\cdot \text{res}(X)$ 求和，希望总和接近于零？]]></description>
      <guid>https://stats.stackexchange.com/questions/635728/ols-assumptions-of-uncorrelatedess</guid>
      <pubDate>Wed, 27 Dec 2023 19:19:50 GMT</pubDate>
    </item>
    <item>
      <title>如何通过采样计算混合分布的矩和中值？</title>
      <link>https://stats.stackexchange.com/questions/635727/how-to-calculate-the-moments-and-median-of-a-mixture-of-distributions-by-samplin</link>
      <description><![CDATA[此问题来自书籍简介广义线性模型

双峰分布是 2 个正态分布 $N(2, 1)$ 和 $N(5 , 0.5^2)$。我认为 2 个正态分布的总和也应该是正态的。
我不知道如何从该双峰分布中获取该双峰和样本的密度，并使用该样本计算该双峰分布的矩和中值：
theta &lt;- seq(-1,7,0.01)
d_theta = 0.5*dnorm(theta,平均值=2,sd=1)+0.5*dnorm(theta,平均值=5,sd=0.5)

曲线(0.5*dnorm(x,平均值=2,sd=1)+0.5*dnorm(x,平均值=5,sd=0.5), -1, 7, col=“西耶娜”,
    lwd=2,n=1001, ylab=“PDF”, xlab=“theta”) # 绘制结果

数据 = tibble(&#39;x&#39;=theta, &#39;y&#39;=d_theta)
data2 &lt;- data[样本(seq_len(nrow(data)), 500, prob=data$y),]

段(x0 = data2$x,
     y0 = 0,
     x1 = 数据2$x,
         y1 = 数据2$y,
         科尔=“黑色”，
         类型＝“1”，
         长宽比 = 0.1)


样本均值可以与真实均值匹配：
#sample 意思
加权平均值(data2$x,data2$y)
加权平均值(数据$x,data$y)

#真实的意思
c &lt;- 积分(\(x) (dnorm(x,mean=2,sd=1)+dnorm(x,mean=5,sd=0.5)), -10, 10)
密度_x &lt;- 函数(x){
  (dnorm(x,均值=2,sd=1)+dnorm(x,均值=5,sd=0.5))*x/c$值
}
积分(密度_x, -10, 10)$值

&lt;代码&gt;[1] 3.63361
[1]3.503125
[1]3.5

但是样本的中位数无法与真实中位数匹配：
#sample 中位数
分位数(data2$x, c(0.5))

#真实中位数
for (1:7 中的 i) {
  if(abs(积分(\(x) (0.5*dnorm(x,平均值=2,sd=1)+0.5*dnorm(x,平均值=5,sd=0.5)), -10, i)$值 - 0.5)&lt;0.001){
    打印（一）
  }
}

&lt;代码&gt; 50%
3.035
[1] 4
]]></description>
      <guid>https://stats.stackexchange.com/questions/635727/how-to-calculate-the-moments-and-median-of-a-mixture-of-distributions-by-samplin</guid>
      <pubDate>Wed, 27 Dec 2023 19:11:47 GMT</pubDate>
    </item>
    <item>
      <title>UMAP 表现不佳的示例</title>
      <link>https://stats.stackexchange.com/questions/635726/examples-of-umap-performing-poorly</link>
      <description><![CDATA[任何人都可以建议一些数据集或示例，这些数据集或示例对于显示 UMAP 性能不佳的情况（例如产生虚假簇或丢失簇的情况）有用吗？对于 t-SNE，这里有一些很好的例子 https://arxiv.org/pdf/2110.02573.pdf ，但是当我在它们上运行 UMAP 时，效果很好。]]></description>
      <guid>https://stats.stackexchange.com/questions/635726/examples-of-umap-performing-poorly</guid>
      <pubDate>Wed, 27 Dec 2023 19:08:13 GMT</pubDate>
    </item>
    <item>
      <title>如果 Cov(X,Y)=Var(Y)，X 和 Y 之间的依赖关系是什么？</title>
      <link>https://stats.stackexchange.com/questions/635725/if-covx-y-vary-what-is-the-dependence-between-x-and-y</link>
      <description><![CDATA[在一个问题中我发现
$$Cov(X,Y)=Var(Y),$$
其中 $X$ 和 $Y$ 是随机变量。
关于 $X$ 和 $Y$ 之间的线性相关性我可以得出什么结论？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635725/if-covx-y-vary-what-is-the-dependence-between-x-and-y</guid>
      <pubDate>Wed, 27 Dec 2023 19:05:08 GMT</pubDate>
    </item>
    <item>
      <title>非参数分布的费舍尔信息或贝叶斯不确定性</title>
      <link>https://stats.stackexchange.com/questions/635724/fisher-information-or-bayesian-uncertainty-for-non-parametric-distributions</link>
      <description><![CDATA[这个问题听起来很荒谬，让我澄清一下动机：
渔夫信息&amp;贝叶斯推理不确定性对我来说似乎非常酷，因为它们可以有效地告诉您“您的样本的代表性如何”。但他们通过分布/模型参数的不确定性来做到这一点。
我想知道是否可以对自由形式（或非参数）分布（例如 KDE 中的不确定性）做类似的事情。或者是否需要对参数统计分布做出的假设来回答“我的样本的代表性如何”的问题？
附注与这张海报不同，我并不是试图对已知的不确定性进行编码，而是试图检测不确定性在非参数分布中（例如 KDE）。]]></description>
      <guid>https://stats.stackexchange.com/questions/635724/fisher-information-or-bayesian-uncertainty-for-non-parametric-distributions</guid>
      <pubDate>Wed, 27 Dec 2023 18:58:11 GMT</pubDate>
    </item>
    <item>
      <title>LDDP 与二进制浮点表示上的信息熵？</title>
      <link>https://stats.stackexchange.com/questions/635723/lddp-vs-info-entropy-on-binary-float-representations</link>
      <description><![CDATA[我刚刚读到LDDP，我发现它近似于连续分布任意密集的离散分布。这让我想起了我们如何用二进制来近似浮点数。
然后我想到，只要我们将讨论限制在实际场景（即计算机上的数值计算），那么我们实际上可以通过简单地将（例如 32 位）浮点数转换为位字符串来计算信息熵的原始定义。 我想知道优点和缺点是什么。与使用 LDDP 相比，这样做的缺点是，LDDP 也用离散分布来近似连续分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/635723/lddp-vs-info-entropy-on-binary-float-representations</guid>
      <pubDate>Wed, 27 Dec 2023 18:49:00 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法估计或计算分布总和的预期 P99？</title>
      <link>https://stats.stackexchange.com/questions/635721/is-there-a-way-to-estimate-or-calculate-the-expected-p99-of-a-sum-of-distributio</link>
      <description><![CDATA[假设我有一个事件 X，其延迟无法直接测量，但 X 由一堆子事件 X_0、X_1、X_2、...、X_n 组成，我只能单独测量其延迟。
直观上，将每个 X_i 的 P99 延迟相加来计算 X 的 P99 似乎是不正确的，因为每个 X_i 的 P99 事件不太可能同时发生。
考虑到所有组件的测量延迟分布，是否有标准和/或数学上正确的方法来计算 X 的预期 P99 延迟？
我将尝试用一个具体的例子来澄清我的术语和问题：

令 X = 作为处理特定 API 调用的一部分在数据库查询上花费的总时间。
令 X_i = 第 i 个数据库查询所花费的总时间。

假设我可以测量针对新数据库的单个数据库查询的延迟，并且可以多次这样做。
进一步假设测量单个实验中所有查询所花费的总时间是不切实际的。
我想根据所有 X_i 估计或计算 X 的分布，然后找到该分布的第 99 个百分位数。]]></description>
      <guid>https://stats.stackexchange.com/questions/635721/is-there-a-way-to-estimate-or-calculate-the-expected-p99-of-a-sum-of-distributio</guid>
      <pubDate>Wed, 27 Dec 2023 18:38:46 GMT</pubDate>
    </item>
    <item>
      <title>如何更改 Scipy.Optimize.Minimize 配置以更好地找到约束优化的解决方案？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635720/how-do-i-change-my-scipy-optimize-minimize-configuration-to-better-find-solution</link>
      <description><![CDATA[我正在尝试使用 Scipy.Optimize.Minimize 进行约束优化，当我知道有解决方案时，我一直得不到解决方案，因为当我更改初始值时我可以找到一个解决方案对其他事物的价值观。但我不想受到初始值的束缚，因为我试图在不同的时间段内循环进行大量优化，然后查看最佳解决方案的分布。老实说，我不想对我认为的解决方案应该有太多偏见。
目前，我使用 SLSQP 作为求解器方法。我还将 maxiter 设置为 10000 我想知道是否可以调整其他设置以强制求解器运行更长时间？
数据集本身并不大，问题本身也不难。我试图解决两个变量。变量有界限（必须为正或负）和一些附加约束。它有点非线性，因为它涉及 MIN 和 MAX 函数。但由于数据集很小，而且我有时间，所以我可以等待。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635720/how-do-i-change-my-scipy-optimize-minimize-configuration-to-better-find-solution</guid>
      <pubDate>Wed, 27 Dec 2023 18:28:38 GMT</pubDate>
    </item>
    </channel>
</rss>