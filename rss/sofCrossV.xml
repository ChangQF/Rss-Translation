<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Fri, 14 Mar 2025 12:33:08 GMT</lastBuildDate>
    <item>
      <title>在密度预测中，是否有标准的清晰度度量？</title>
      <link>https://stats.stackexchange.com/questions/662602/in-density-forecasting-is-there-a-standard-measure-of-sharpness</link>
      <description><![CDATA[在密度预测的背景下， （2007）表征清晰度如下：

清晰度是指预测分布的浓度，仅是预测的特性。预测分布越集中，预测越来越尖锐，并且越来越越好，可以按照校准。

这不足以暗示一个清晰度的量度。在论文中，作者继续这样做：

为了评估清晰度，我们使用了预测间隔宽度的数值和图形摘要。例如，表4显示了我们最初的模拟研究中预测者中心50％和90％预测间隔的平均宽度。

然而，其他方法是可能的，例如预测密度的报告（摘要特征）方差，熵，四分位范围等。适当的评分规则也可以分解为几个要素，其中一个是清晰度，因此可以从那里采取措施。参见例如。至少对于某些适当的评分规则，有许多可能的分解，因此从不同分解中得出的清晰度的度量不一定是相同的。
 问题：在密度预测文献中是否有任何特殊的测量清晰度选择成为标准？没有考虑密度预测的具体用户，我正在考虑在学术文章中要报告的有关密度预测的应用。
 参考 

 Arnold，S.，Walz，E.M.，Ziegel，J。，＆amp; Gneiting，T。（2024）。 Decompositions of the mean连续排名的概率得分。 电子统计杂志，18 （2），4992-5044。
 Gneiting，T.，Balabdaoui，F。，＆amp; Raftery，A。E.（2007）。 概率的预测，校准和敏锐，校准和尖锐， 243-268。
]]></description>
      <guid>https://stats.stackexchange.com/questions/662602/in-density-forecasting-is-there-a-standard-measure-of-sharpness</guid>
      <pubDate>Fri, 14 Mar 2025 09:12:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么一些自变量有巨大的性病错误？</title>
      <link>https://stats.stackexchange.com/questions/662601/why-are-some-independent-variables-having-huge-std-errors</link>
      <description><![CDATA[我想知道我的结果是否正确。我不明白为什么四个独立变量有大的性病错误。
可以在此处访问数据：
 https://drive.google.com/file/d/1iefjzybovmbz1oqq1_rj5xqsi-o3b4d5/view?usp = sharing  
以下是GLM调用：
致电：
  glm（公式=练习〜Urban_zone + peri_urban_zone + rural_zone + 
    remote_rural_zone + num_female_age_10_30 + num_female_age_31_51 + 
    num_female_age_52_72 + num_female_age_73_90plus + num_male_age_10_30 + 
    num_male_age_31_51 + num_male_age_52_72 + num_male_age_age_73_90plus + 
    num_no_education + num_lower_primary + num_upper_primary + 
    num_junior_secondary + num_senior_secondary + num_tertiary + 
    num_employed + num_unemployed + num_pensioners + num_learners， 
    family =二项式，data = beanpurepractice）
 
和结果：
 系数：（3由于奇异性而未定义）
                           估计标准。错误z值pr（＆gt; | z |）  
（截距）2.69299 2.60852 1.032 0.3019  
Urban_Zoneyes -6.17754 2.53048 -2.441 0.0146 *
peri_urban_zoneyes 16.33651 6566.01336 0.002 0.9980  
rural_zoneyes -1.48510 2.13068 -0.697 0.4858  
远程_rural_zoneyes na na na na na na na na na na na  
num_female_age_10_30 -2.27482 2.41113 -0.943 0.3454  
num_female_age_31_51 2.31677 2.66000 0.871 0.3838  
num_female_age_52_72 2.62843 2.80616 0.937 0.3489  
num_female_age_73_90plus 28.03286 5429.89633 0.005 0.9959  
num_male_age_10_30 2.17702 2.20519 0.987 0.3235  
num_male_age_31_51 -0.04994 3.15402 -0.016 0.9874  
num_male_age_52_72 2.23831 3.76589 0.594 0.5523  
num_male_age_73_90plus 21.97843 8491.96006 0.003 0.9979  
num_no_education 0.61582 2.44018 0.252 0.8008  
num_lower_primary 16.32515 5412.19502 0.003 0.9976  
num_upper_primary -0.71340 2.14795 -0.332 0.7398  
num_junior_secondary 0.42343 1.77102 0.239 0.8110  
num_senior_secondary 1.00463 1.47758 0.680 0.4966  
num_tertiary na na na na  
num_employed 0.05111 2.88391 0.018 0.9859  
num_unemployed 0.63221 2.06144 0.307 0.7591  
num_pensioners -4.4.00465 3.29184 -1.217 0.2238  
num_learners na na na na na na na na  
---
象征。代码：0&#39;***’0.001&#39;**’0.01&#39;*’0.05&#39;。’0.1’’1

（二项式家族的分散参数为1）

    空偏差：94.242在119自由度上
剩余偏差：31.062 on 100自由度
AIC：71.062

Fisher评分迭代的数量：21
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662601/why-are-some-independent-variables-having-huge-std-errors</guid>
      <pubDate>Fri, 14 Mar 2025 08:30:56 GMT</pubDate>
    </item>
    <item>
      <title>如何计算样本量对假正率的影响？</title>
      <link>https://stats.stackexchange.com/questions/662600/how-to-calculate-effect-of-sample-size-on-false-positive-rate</link>
      <description><![CDATA[安慰剂对照研究（样本量为500）发现，新药将死亡率从10％降低到7％，而P = 0.04。
这种差异的理想样本量（保持80％的功率，α为0.05）为1353。
研究的批评者指出，较小的样本量增加了假正率，即使p值为0.04（假阳性率为4％）
这是真的吗？如果是这样，该研究如何计算确切的假阳性率？]]></description>
      <guid>https://stats.stackexchange.com/questions/662600/how-to-calculate-effect-of-sample-size-on-false-positive-rate</guid>
      <pubDate>Fri, 14 Mar 2025 08:28:31 GMT</pubDate>
    </item>
    <item>
      <title>解释过程宏中的适度</title>
      <link>https://stats.stackexchange.com/questions/662599/interpreting-moderation-in-process-macro</link>
      <description><![CDATA[我正在测试一个模型，该模型在SPSS中可用的过程宏中具有主持人变量。结果如下：
  因此，效果x*m是正的，这意味着随着m的增加，x对y的影响应增加。但是，当我绘制结果时，我会得到相反的情况：
  图像中
privsco2 = x
vuln_aff = y
DVP = M 
关于如何理解这些结果的任何想法？]]></description>
      <guid>https://stats.stackexchange.com/questions/662599/interpreting-moderation-in-process-macro</guid>
      <pubDate>Fri, 14 Mar 2025 08:06:47 GMT</pubDate>
    </item>
    <item>
      <title>r中的Invlogit（）以及我们是否需要使用截距和斜率或仅使用斜率来估计概率</title>
      <link>https://stats.stackexchange.com/questions/662598/invlogit-in-r-and-whether-we-need-to-use-the-intercept-and-the-slope-or-just-t</link>
      <description><![CDATA[我有兴趣估计二进制结果（y）作为X的函数的概率。使用r中的r中的glm（）在family =二项式中运行logistic回归，我获得了截距和斜率。我的问题：当试图估算y作为X函数的总体概率时，我可以使用ARM :: Invlogit（），但是我是否应该将截距和斜率用作 Invlogit（Intercept+Slope+Slope） 或Just  Invlogit（X slope of x）？？？？？？？？？？？？？？
是要回答以下问题：由于X？
我使用了一个数据集，该数据集预测冠状动脉疾病是年龄的函数，当应用 Invlogit（Slope）时，我能够获得比 Invlogit（Intercept+Slope+Slope）更现实的概率，与0.22％相比，概率约为50％？后者是不现实的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662598/invlogit-in-r-and-whether-we-need-to-use-the-intercept-and-the-slope-or-just-t</guid>
      <pubDate>Fri, 14 Mar 2025 06:48:54 GMT</pubDate>
    </item>
    <item>
      <title>面板数据中的第一差模型与固定效果</title>
      <link>https://stats.stackexchange.com/questions/662595/first-difference-models-vs-fixed-effects-in-panel-data</link>
      <description><![CDATA[我正在使用个人级别的小组数据，以研究政治意识形态如何随收入和其他财务变量而变化。但是，我正在努力决定使用单个固定效果或最初差异（而包括年份或地区等其他假人）。。
一个混乱的一点是，为什么有些研究人员会使用固定效果，而另一些研究人员则包括假人。如果固定效果说明了时间不变的个体特征，则使用其他假人使用第一差异的优势是什么？在什么情况下，一种方法比另一种方法更可取？
我感谢对这些方法之间权衡的任何见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/662595/first-difference-models-vs-fixed-effects-in-panel-data</guid>
      <pubDate>Fri, 14 Mar 2025 05:49:48 GMT</pubDate>
    </item>
    <item>
      <title>使用比例自变量</title>
      <link>https://stats.stackexchange.com/questions/662594/using-a-proportional-independent-variable</link>
      <description><![CDATA[我正在分析财富和收入不平等的偏差如何影响投票行为，使用定义为：的措施
 skewness = wally_gini / income_gini &lt; / p&gt;
但是，我担心如何解释重大结果。具体而言，如何确定偏度度量本身是否有意义，或者结果是否由基础Gini系数之一驱动？
例如，如果收入Gini与政治参与负相关，那么我的偏差措施（Gini Gini在分母中）可能最终仅仅由于相互关系而显示出积极的效果。这不一定表明偏度具有独立的效果，而是机械地捕获了收入基尼的倒数。
最好先将财富基尼和收入Gini分别包括在模型中，然后将该比例作为附加变量引入？还是有其他方法可以测试偏度度量是否具有独立的解释力？
任何建议都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/662594/using-a-proportional-independent-variable</guid>
      <pubDate>Fri, 14 Mar 2025 05:48:38 GMT</pubDate>
    </item>
    <item>
      <title>卡方检验的预期频率的相互信息等于零？</title>
      <link>https://stats.stackexchange.com/questions/662592/is-the-mutual-information-of-the-expected-frequencies-for-a-chi-squared-test-equ</link>
      <description><![CDATA[我正在进行一些分析，我遇到了以下观察。
进行卡方测试时，我从应急表中计算了预期的频率。  好奇心使我变得更好，因为我想知道预期频率的共同概率将是什么相互信息。  令我惊讶的是，这是零。  因此，我采用了一些进一步的方案，所有这些方案都相同的结果：相互信息对于预期频率的关节概率为零。
我试图找到讨论我的观察的参考文献，但我尚未设法找到任何。
所以我的问题是：

是一种条件，预期频率的联合概率将具有零的相互信息？
预期频率的关节概率是互信息为零的独特解决方案吗？ （即，对于与边缘密度一致的频率的任何其他布置，这将导致相互信息大于零）。

我希望我已经充分解释了我的观察/问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/662592/is-the-mutual-information-of-the-expected-frequencies-for-a-chi-squared-test-equ</guid>
      <pubDate>Fri, 14 Mar 2025 03:15:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的深厚的增强学习根本不融合？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/662591/why-does-my-deep-reinforcement-learning-not-converge-at-all</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662591/why-does-my-deep-reinforcement-learning-not-converge-at-all</guid>
      <pubDate>Fri, 14 Mar 2025 02:31:20 GMT</pubDate>
    </item>
    <item>
      <title>ACF或PACF的强烈时间依赖性</title>
      <link>https://stats.stackexchange.com/questions/662587/strong-temporal-dependency-with-acf-or-pacf</link>
      <description><![CDATA[我正在使用时间序列数据，其中每天由包含24×25网格的CSV文件表示，每个条目都充当像素。
我已经生成了ACF和PACF来了解我的数据的时间结构，并且整天都使用了第一个功能：
 导入statsmodels.api as s sm
导入matplotlib.pyplot作为PLT

系列= data_flatted [：，0]＃整天使用第一个功能
图，轴= plt.subplot（2，1，无花果=（10，8））
sm.graphics.tsa.plot_acf（系列，滞后= 30，ax = axes [0]）
sm.graphics.tsa.plot_pacf（系列，滞后= 30，ax = axes [1]）
plt.show（）
 
我的输出：
  从上图中，我会说短暂滞后的强大相关性表明时间依赖性很大吗？
或
我的意思是问我的数据集有任何重复模式或趋势？
或
所有数据点都可能遵循一些简单的确定性线性结构方程，并具有一些小的白噪声？
或我的数据集中存在强大的时间依赖性？]]></description>
      <guid>https://stats.stackexchange.com/questions/662587/strong-temporal-dependency-with-acf-or-pacf</guid>
      <pubDate>Fri, 14 Mar 2025 00:47:24 GMT</pubDate>
    </item>
    <item>
      <title>使用测试集评估小样本中的模型：Bootstrap与LOOCV</title>
      <link>https://stats.stackexchange.com/questions/662584/evaluating-a-model-in-a-small-sample-using-a-test-set-bootstrap-vs-loocv</link>
      <description><![CDATA[线程 评估具有小样本的分类器 考虑了其标题中的问题。具体而言，问题是要多次从其他数据分开测试集，而不仅仅是一次以减少样本外部性能的估计值的可变性。
戴夫的回答建议遵循弗兰克·哈雷尔（Frank Harrell）的建议。用戴夫的话来说，

他对样本外测试的建议是通过对整个数据集的替换，在该新样本上构建模型，评估整个数据集上的模型性能，并将此性能与在完整数据集中受过训练和评估的模型的性能进行比较。这是重复的数十个，数百或数千次，以获得性能差异的分布。再次，他的RMS书讨论了这一点。

在一个小样本中对我来说似乎直觉的另一种方法是（允许计算资源！）进行嵌套的剩余交叉验证（LOOCV）。也就是说，在外循环中，将单个观察结果分为测试集。然后在内部循环中do loocv选择和调整模型。厕所而不是k折应最大程度地减少样本外性能的估计偏差，这在处理小样本时可能非常重要，而且这里的情况也是如此。我想相对于k折的loo的差异可能是一个问题，也可能不是一个问题。在这里）。
 cbeleites在对第一个链接线程的评论中警告我，这可能不是一个好主意。我在这里发布此信息以弄清楚细节。因此，我的问题是，弗兰克·哈雷尔（Frank Harrell）的方法比我的方法更可取，如果是，我的方法的主要缺点是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/662584/evaluating-a-model-in-a-small-sample-using-a-test-set-bootstrap-vs-loocv</guid>
      <pubDate>Thu, 13 Mar 2025 19:29:28 GMT</pubDate>
    </item>
    <item>
      <title>为什么负概率密度是不正确的评分规则？反例？</title>
      <link>https://stats.stackexchange.com/questions/662570/why-is-negative-probability-density-an-improper-scoring-rule-a-counterexample</link>
      <description><![CDATA[Gneiting and Katzfuss (2014) discuss (among other things) proper scoring rules for evaluating density forecasts.引用论文（第133页），

 定义4：评分规则 $ s：f \ times r \ rightarrow \ bar r $ 相对于类 $ \ nathcal {f}
 $$ s（g，g）\ leq s（f，g）\ tag {1} $$ 
对于所有 $ f，g \ in \ Mathcal {f} $ 。如果方程式 $ 1 $ 仅在 $ f = g $ 。

以及

 定理3：得分规则 $ s $ 相对于类 $ \ nathcal {f} $ ，仅当预期得分函数 $ e $ e（$ e e（$ e e（f）， class =“数学container”&gt; $ s（f，\ cdot）$ 是 $ e $ 在点 $ f $  $  $ f $ 的超级gradeient

他们指出，线性得分， $ s（f，y）=  -  f（y）$ （即，在目标随机变量实现时评估的负概率密度函数）不是正确的得分规则，因为它不是超级级别。他们引用了Ovcharov（2013）。我在任何地方都找不到Ovcharov（2013）。此外，我并不是想研究涉及凸分析和超级成分的证据。这听起来很技术！
相反，我想了解 intuition 为什么线性得分不是适当的得分规则。理想情况下，我想要一个示例展示某个密度 $ f \ neq g $ 比真实密度 $ g $ 连续随机变量 参考 

 gneiting，T。，＆amp; Katzfuss，M。（2014年）。 概率的预测。 125-151。
 Ovcharov E.2013。多变量的本地适当评分规则。 Heidelberg大学应用数学研究所工作论文。
]]></description>
      <guid>https://stats.stackexchange.com/questions/662570/why-is-negative-probability-density-an-improper-scoring-rule-a-counterexample</guid>
      <pubDate>Thu, 13 Mar 2025 16:21:21 GMT</pubDate>
    </item>
    <item>
      <title>设置r最佳目标函数类似于NLME VARCONSTPROP？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/662563/set-r-optim-objective-function-similar-to-nlme-varconstprop</link>
      <description><![CDATA[我试图写下比 nlme :: gls 。更具普遍化的目标函数
这个想法是有一个任意函数j和方差函数g。
在此基本示例中，j和输出y之间有一个直接的映射，因此计算差异f（观察到 - 实际）。
两校区错误的差异是 $ g = \ sigma ^2 *观察到的 ^2 + \ sigma_1 $ ，其中每个Sigma都是平均值0. 的标准分布的标准偏差。
一个论文中的-log可能性为：
 $$ \ sum_i \ dfrac {（y_i -j（p）_i）^2} {g_i} + ln（g_i）
  nll＆lt;  -  function（params，conc，conc_std，lognorm = f）{
  sigma1＆lt;  -  params [1] 
  sigma2＆lt;  - 参数[2] 

  f＆lt;  -  conc_std

  如果（lognorm）{ 
    conc＆lt;  -  log（conc） 
    conc_std＆lt;  -  log（conc_std）
  } 
  
  g＆lt;  -  sigma2 ** 2*conc^2 + sigma1 ** 2 
  l＆lt;  -  log（g） +（f^2/g）
  sum（l）＃== -log（y | theta），没有否定
}



stdconc_dil＆lt; -1：200
res＆lt;  -  lapply（1：nrep，function（i）{
    响应＆lt;  -  stdconc_dil + rnorm（长度（stdconc_dil），0，0.06*stdconc_dil） + rnorm（长度（stdconc_dil），0，0.4）
    data.frame（stdconc = stdconc_dil，conc = revertmon）
}））

res＆lt;  -  do.call（rbind，res）
optim（c（1，1），nll，conc = res  $ con，conc_std = res $  stdconc，hessian = true，method =＆quort; l-bfgs-b＆quot

GLS（conc〜stdconc-1，data = res， 
  striges = varconstprop（form = 〜StdConc），控制=列表（Sigma = 1））

 
在此示例中，这给出了我的需求。结果非常相似，只有一个负参数发行。
但是，如果我从实现中的零转移而不是 gls（） ，则常数 $ sigma_1 $ 发​​生了重大问题。
当然，要获得接近零的积分对于估计此参数很有益，但是我希望我的实现至少有效，因为 gls（） 
这是两个示例：
  stdconc_dil＆lt;  -  100：200
＃这里的sigma_1为零，范围已从零转移
res＆lt;  -  lapply（1：nrep，function（i）{
    响应＆lt;  -  stdconc_dil + rnorm（长度（stdconc_dil），0，0.06*stdconc_dil） + rnorm（长度（stdconc_dil），0，0，0）
    data.frame（stdconc = stdconc_dil，conc = revertmon）
}））

res＆lt;  -  do.call（rbind，res）
优点（C（1，1），NLL，Conc = Res  $ cons，conc_std = res $  stdconc，hessian = true）

＃ 结果
＃Sigma 1：1.62
＃Sigma 2：-0.058
 

GLS（conc〜stdconc-1，data = res， 
  striges = varconstprop（form = 〜StdConc），控制=列表（Sigma = 1））
＃ 结果
＃Sigma 1：0.002
＃Sigma 2：-0.06

 
  stdconc_dil＆lt;  -  100：200＃这里的范围已从零转移

res＆lt;  -  lapply（1：nrep，function（i）{
    响应＆lt;  -  stdconc_dil + rnorm（长度（stdconc_dil），0，0.06*stdconc_dil） + rnorm（长度（stdconc_dil），0，0.4）
    data.frame（stdconc = stdconc_dil，conc = revertmon）
}））

res＆lt;  -  do.call（rbind，res）
优点（C（1，1），NLL，Conc = Res  $ cons，conc_std = res $  stdconc，hessian = true）
＃ 结果
＃Sigma 1：4.54
＃Sigma 2：-0.051

GLS（conc〜stdconc-1，data = res， 
  striges = varconstprop（form = 〜StdConc），控制=列表（Sigma = 1））

＃ 结果
＃Sigma 1：0.64
＃Sigma 2：-0.059

 
所以看来 nlme :: gls（）显然对我的方法更稳定和敏感。
我有几个问题。我不需要完全实现：

如何使我的实现更适合数据范围，例如 gls（）？
最好是如何将参数限制为非阴性？我试图拥有“ l-bfgs-b”以0为0，但有时会失败。
]]></description>
      <guid>https://stats.stackexchange.com/questions/662563/set-r-optim-objective-function-similar-to-nlme-varconstprop</guid>
      <pubDate>Thu, 13 Mar 2025 14:10:00 GMT</pubDate>
    </item>
    <item>
      <title>如何在MonoBit测试中确定阈值，为什么要比5％的显着性水平高1％？</title>
      <link>https://stats.stackexchange.com/questions/662552/how-is-the-threshold-determined-in-the-monobit-test-and-why-is-it-larger-for-a</link>
      <description><![CDATA[在随机性的单托测试中，通过或失败的阈值基于置信区间。我了解到1％的显着性水平（99％的置信度）导致阈值较大，而显着性水平为5％（95％的置信度）。
然而，这似乎是违反直觉的 - 由于较高的信心应该意味着与预期的50:50比率更少的偏差，为什么它允许在零数量和零之间有更大的差异？更严格的测试（较低的alpha）不需要较小的偏差吗？
有人可以澄清阈值是如何设定的，为什么会发生这种行为？
我尝试的是：我审查了单片测试公式，该公式根据对应于所选置信度的z得分设置阈值。我还研究了95％和99％置信度的临界值是从正态分布中得出的。
我期望的是：我期望较高的置信度（99％）会导致更严格的测试，这意味着允许的数量和零之间的差异较小。
实际发生的事情：相反，我发现较高的置信度（99％）允许在零和零之间差异更大，而95％则允许置信度更大。这似乎是违反直觉的，因为我认为更严格的测试应该忍受较小的偏差。我想澄清为什么这是数学上会发生的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662552/how-is-the-threshold-determined-in-the-monobit-test-and-why-is-it-larger-for-a</guid>
      <pubDate>Thu, 13 Mar 2025 05:18:08 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助将名称放在发行</title>
      <link>https://stats.stackexchange.com/questions/662551/need-help-putting-a-name-to-a-distribution</link>
      <description><![CDATA[最近，我一直在研究精算师协会在我的ASA认证之路上进行的概率考试。现在有几个问题涉及一个可以表征如下的分布：
  $$
\ begin {Aligned}
p_x（x）=（1 -r）r^x = r^x -r^{x+1}
\ end {Aligned}
$$  
如果我错了一般的公式，请纠正我，这已经晚了，我有点累。本质上，这是概率质量函数的一般形式，该概率质量函数在支持 $ r \ in（0,1）$  in Support  $ x \ in（0，\ infty）
  $$
p_x（n+1）= r*p_x（n）
$$  
即。发生事件发生的概率再次产生的概率小于先前的概率，而 $ r $ 。作为参考，可以找到引发这个问题的问题 noreflow noreferrer“&gt; noreferrer”&gt;在这里问题13和15和15。 The first question (13) only gives the sequence definition of the probability function, so to solve it you have to solve the infinite geometric series (as per $\frac{a}{1-r}$) and then solve for $a$ such that the sum of probabilities is one, as we expect.当然，这会产生 $ a = 1-r $ ，从而将其乘以我们不断减小的因子 $ r^x $ 产生PMF。对不起，漫不经心的人只是想澄清发行的来源，以便有人可以在一般公式上查看我的工作。
我认为这个几何系列发行很有趣，并且想知道是否有正式名称。如果是这样，我想对此进行更多的研究。如果没有，我认为这是一个整洁的分布，很有趣。让我知道。]]></description>
      <guid>https://stats.stackexchange.com/questions/662551/need-help-putting-a-name-to-a-distribution</guid>
      <pubDate>Thu, 13 Mar 2025 04:01:44 GMT</pubDate>
    </item>
    </channel>
</rss>