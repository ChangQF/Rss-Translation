<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 16 Jan 2024 18:17:32 GMT</lastBuildDate>
    <item>
      <title>解释具有多级和交互固定变量的 glmm (lmer) 的结果</title>
      <link>https://stats.stackexchange.com/questions/637000/interpreting-results-from-a-glmm-lmer-with-multilevel-and-interaction-fixed-va</link>
      <description><![CDATA[我正在 R 上运行 GLMM，以测试品种对喵声声学参数的影响是否取决于性别水平 (sex*breed)，并测试发射上下文的影响是否受品种水平的影响（breed*context）。性别级别为 M（雄性）和 F（雌性），上下文级别为 B（刷牙）、I（隔离）、F（食物），品种为杂种猫（EU）和缅因猫（MC）。
例如，我运行这个完整模型
full_FL &lt;- lmer（中位数_频率_log ~ 性别 + 品种 + 上下文 + 性别*品种 + 品种*上下文 + (1|Cat_ID)，数据 = 数据）。
我对交互项（例如 Sex*Breed 和 Breed*Context）对响应的影响感兴趣。
我从摘要（full_FL）中获得了以下系数，我只关心和报告交互的系数：
&lt;前&gt;&lt;代码&gt;（截距）6.325 0.133 18.346 47.445 0.000
性别M：品种MC 0.211 0.236 16.313 0.894 0.384
品种MC：上下文F 0.166 0.054 432.756 3.093 0.002
品种MC：上下文I -0.109 0.052 434.439 -2.093 0.037

我还运行 drop1 函数来获取预测变量的一般 p 值，因此 round(as.data.frame(drop1(full_FL, test=&quot;Chisq&quot;)) ,3)
并得到这个：
&lt;预&gt;&lt;代码&gt;性别：品种 0.025 0.025 1 16.313 0.799 0.384
品种：上下文 1.010 0.505 2 433.615 16.467 0.000

然后我对两种交互与 lsmeans 进行事后成对比较：
1)pairs(lsmeans(full_FL, ~ Sex * Breed), adjustment = &quot;mvt&quot;):
这里没有什么是重要的，与上面性别*品种的 p 值一致。
2)pairs(lsmeans(full_FL, ~ Breed * Context), adjustment = &quot;mvt&quot;)：这里我获得了一些显着的 p 值，即：
&lt;预&gt;&lt;代码&gt;EU B - EU I -0.2469 0.0396 432.2 -6.230 &lt;.0001
MC B - MC F -0.2059 0.0400 434.9 -5.141 &lt;.0001
MC B - MC I -0.1377 0.0340 436.9 -4.050 0.0005
EU F - EU I -0.2072 0.0300 433.9 -6.908 &lt;.0001

因此，我以书面形式报告从 drop1 获得的两次交互作用的总体 p 值（0.384，&lt; 0.001）。但随后我想发现这两个品种是否对同一环境类型内的声学参数产生了不同的影响。那么，这里我应该考虑事后获得的P值，对吗？就我而言，如果我在相同背景下寻找两个品种之间的比较（例如 MC-B 与 EU-B、MC-I 与 EU-I 等），这些 p 值都不显着，但它们仅对于不同类型的上下文才有意义。那么我应该忽略这些显着的 p 值吗？这个推理对吗？
但在写作中我是否需要报告从摘要（full_FL）中获得的p值？即 0.002，唯一显着的 p 值，并且表示缅因猫在食物环境中发出的喵叫声的 f0 明显高于混种猫发出的喵叫声（来自模型的输出：t 值 = 3.093，P 值 = 0.002）刷牙时？
对于其他一些声学参数，我获得了总体 P 值 &gt;对于两种交互，均为 0.05（使用 drop1），&gt; 0.05 也来自模型的摘要，但是当我运行事后分析时，我获得了一些重要的 p 值，例如：
&lt;前&gt;&lt;代码&gt; M EU - M MC 0.3928 0.126 15.4 3.128 0.0310

所以一般问题是，我的论文应该考虑哪些 p 值？即使一般 p 值对于交互作用并不显着，事后检验是否有可能报告显着差异？如果是这样，我应该报告什么？如果我想研究环境对参数的影响是否受到品种水平的影响，那么考虑直接从模型输出获得的 p 值是否有意义，因为它们比较不同的环境？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/637000/interpreting-results-from-a-glmm-lmer-with-multilevel-and-interaction-fixed-va</guid>
      <pubDate>Tue, 16 Jan 2024 17:33:02 GMT</pubDate>
    </item>
    <item>
      <title>重现经典辍学论文的结果[关闭]</title>
      <link>https://stats.stackexchange.com/questions/636999/reproducing-results-from-classic-dropout-paper</link>
      <description><![CDATA[在经典论文《Dropout: A Simple Way to Prevent Neural Networks
“过拟合”，有一张图比较了在 MNIST 上训练的单层自动编码器在有 dropout 和没有 dropout 的情况下学习到的特征。使用 dropout 学习到的特征似乎更有意义。有谁知道 pytorch 或 tensorflow 实现可以准确或几乎准确地重现此结果吗？
具体来说，我正在尝试重现下面的一对图像。该论文声称，这些都是通过具有 256 个 ReLU 单元的单个隐藏层的自动编码器学习的特征。我相信 此 存储库包含原始代码，但我无法获取在我的计算机上运行。
]]></description>
      <guid>https://stats.stackexchange.com/questions/636999/reproducing-results-from-classic-dropout-paper</guid>
      <pubDate>Tue, 16 Jan 2024 17:11:22 GMT</pubDate>
    </item>
    <item>
      <title>用于评估的分位数损失的真实示例</title>
      <link>https://stats.stackexchange.com/questions/636998/real-world-example-of-quantile-loss-used-for-evaluation</link>
      <description><![CDATA[我们可以使用分位数损失（又名刻度或弹球损失）来训练模型或评估预测。 （清楚地区分两者是有帮助的，例如，此处。）我对后一种情况感兴趣。预测问题的一个很好的例子（最好来自商业、经济或金融）是什么？其中过度预测的损失与预测误差呈线性关系，而不足预测的损失与预测误差也呈线性关系，但两条线具有不同的斜率？换句话说，当我们想使用分位数损失来评估预测时，现实世界的例子是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/636998/real-world-example-of-quantile-loss-used-for-evaluation</guid>
      <pubDate>Tue, 16 Jan 2024 16:57:40 GMT</pubDate>
    </item>
    <item>
      <title>评估两个数据集是否对应于给定的成对匹配</title>
      <link>https://stats.stackexchange.com/questions/636997/evaluate-two-datasets-for-corresponding-to-given-pairwise-matching</link>
      <description><![CDATA[假设我有两个匹配的 $N \times D$ 数据集 $X$ 和 $Y$。样本按匹配顺序排列（$X$ 中的第 $n$ 个样本与$Y$ 中的第 $n$ 个样本）。这些特征位于（或至少应该位于）同一“空间”中。我正在寻找一个指标来衡量实际情况的程度。
我正在计划一种将每一对视为一个集群的方法。换句话说，我会将 $X$ 和 $Y$ 连接成 $2N \times D$ 矩阵，并使用每对的 $N$ 唯一集群标签定义集群标签。然后，我可以使用接受数据和聚类标签的聚类指标，然后输出它们的“协议”，例如 Calinski-Harabasz 指数（方差比率标准）或 Silhouette 系数。
有更好的方法吗？
编辑：我正在寻找一个指标来指示 $X$ 和 $Y$ 是否包含配对样本的相同表示。一般来说，该度量应该“大”。当 $X=Y$ 时，如果使用 $X=Y=0$&lt; 轻松实现这一点，那就不好了/跨度&gt;。如果 $Y_{nd} = X_{nd} + \epsilon_{nd}, \epsilon_{nd} \sim N(0, \sigma^2)$,那么理想情况下，当 $\sigma$ 上升时，指标应该下降。如果$Y = X M$，那么理想情况下，指标应该“进一步”下降。 $M$ 来自 $I_d$，即使 $ M$ 是正交的。理想情况下，我想要一个指标 $m$ 其中 $m(X, Y) = m(2X, 2Y)$ ，但是$m(X, 2X) \ne 0$。理想情况下，该指标应该易于理解并向其他人解释，并且已经在统计中广泛使用，因此易于向其他人证明。]]></description>
      <guid>https://stats.stackexchange.com/questions/636997/evaluate-two-datasets-for-corresponding-to-given-pairwise-matching</guid>
      <pubDate>Tue, 16 Jan 2024 16:50:05 GMT</pubDate>
    </item>
    <item>
      <title>如何洗牌和应对约束？</title>
      <link>https://stats.stackexchange.com/questions/636996/how-to-shuffle-and-deal-with-constraints</link>
      <description><![CDATA[考虑到一副牌，并且知道某些玩家不能拥有零到三花色的牌，我如何洗牌并将牌发给玩家，同时保持在这些限制之内？
我可以在像平常一样发牌的情况下使用样本拒绝，并检查玩家是否有不允许的牌，然后重新洗牌和重新发牌，但我想要一种只洗牌和发牌一次的方法。 
如果一名玩家缺少花色，问题很简单：我可以从牌堆中取出这些牌，洗牌该玩家可能拥有的牌并将其发给该玩家，然后将剩余的牌发给其他玩家，但是如果有多个玩家缺少花色，当我到达最后一个玩家时，我必须发给该玩家的剩余牌可能有该玩家不允许的花色，从而强制重新洗牌。
如何洗牌并只发牌一次，保证每个玩家都有一手有效牌？]]></description>
      <guid>https://stats.stackexchange.com/questions/636996/how-to-shuffle-and-deal-with-constraints</guid>
      <pubDate>Tue, 16 Jan 2024 16:47:51 GMT</pubDate>
    </item>
    <item>
      <title>自适应模拟退火的名称，它周期性地减小步长，然后增加温度，在每次接受的移动后重置两者？</title>
      <link>https://stats.stackexchange.com/questions/636995/name-for-adaptive-simulated-annealing-that-cyclically-decreases-stepsize-then-i</link>
      <description><![CDATA[我有一个包含 1 到 99 之间许多离散参数的模型。每个步骤的新参数都是从离散均匀分布中采样的，步长围绕当前参数值变化，将结果限制在 1 到 99 之间。
本质上，我初始化温度，以便只接受沿着梯度移动的提案，并将步长设置为 99。然后，每次提案被拒绝时，从步长中减去 1。但如果提案被接受，我会将步长重置为 99。
如果连续拒绝的次数太多，且步长 = 1，则每次拒绝的温度都会升高，直到我收到已接受的提案为止。然后温度和步长重置为初始值。
这对于我的问题非常有效（比我迄今为止尝试过的任何其他方法都好），因为它可以防止陷入任何局部最优。即，该算法永远不会真正收敛，但我关心的是最佳拟合。
由于所有的拒绝（只有大约 2% 的步骤被接受），它的效率有些低，但我可以让它运行，它会无限期地探索。当然也有一些变化，例如不将步长一直重置为 99，而是在每次提案被接受时添加 10 等。
如果不清楚，我可以发布一些代码，但这是一个非常简单的概念：从大步骤开始，如果这不起作用，则采取越来越小的步骤，如果仍然找不到任何内容，则允许采取步骤沿着梯度向上进一步探索。
我想知道是否还有其他人提出了这个想法的变体。]]></description>
      <guid>https://stats.stackexchange.com/questions/636995/name-for-adaptive-simulated-annealing-that-cyclically-decreases-stepsize-then-i</guid>
      <pubDate>Tue, 16 Jan 2024 16:46:48 GMT</pubDate>
    </item>
    <item>
      <title>帮助理解“预测过程”潜在高斯过程模型</title>
      <link>https://stats.stackexchange.com/questions/636994/help-understanding-the-predictive-process-latent-gaussian-process-model</link>
      <description><![CDATA[在一篇论文中，介绍了一种通用框架，该框架结合了高斯过程 (GP) 的几种近似方法，通过对精度矩阵施加稀疏性进行操作 [1]。作者提到了一个特定的潜在过程模型，我对此有点模糊。实现这种稀疏性的方法是策略性地假设点之间的条件独立： $q_y(i)$ 是 $q_y(i)$ 的变量集&quot;&gt;$y_i$“需要”
总而言之，有一个索引集：
$S = {S_1, \ldots, S_l}$
变量 $\{ y_i = y(S_i) | i \in 1\ldots l\}$ 是分布式联合高斯分布。
作者后来指定 $\{y_i | i \in 1\ldots l\}$ 可以被视为基础高斯过程中的潜在变量，从中我们获得观测值 $\{z_j = y_j + \epsilon_j | j \in O \subseteq\ 1\ldots l\}$ 其中 $\epsilon_j$ 是高斯噪声（即噪声项 $\epsilon_i$ 和 $\epsilon_j$ 是独立的）在某些子集 $O 上$ 索引集。
我对区分 $z_i$ 和 $y_i$ 的确切目的感到困惑相同的位置。 $y_j + \epsilon_j$ 又是高斯分布，那么为什么不简单地将 $\epsilon$ 合并到 $y$ 并说我们直接从 $\{y_j | 获取观测值j \in O \subseteq\ 1\ldots l\}$？协方差函数可能需要重新定义以具有“块金”。组件，如果它还没有，但这就是我们需要删除 $z$ 并只关注  $y$？
他们在其他地方发表了以下声明：
&lt;块引用&gt;
在 $y_j$ 上进行条件化比在 $z_j$&lt; 上进行条件化可能更准确，但计算成本也更高/跨度&gt;;我们将在第 5 节中探讨这种权衡。我们始终选择 $y_i$ 作为 $z_i$，因为 $z_i$ 被定义为有条件独立于给定 $y_i$ 的所有其他向量。出于同样的原因，通过在 $y_j$ 上调节 $y_i$ 也没有任何好处$z_j$，因此我们总是采用 $q_y(i) ∩ q_z(i) = ∅$ .

这表明区别很重要，而不仅仅是符号上的方便。在观察到的 $z_i$ 后面包含一组潜在的 $y_i$ 的目的是什么？
[1] 高斯过程的 Vecchia 近似的通用框架，Katzfuss &amp;吉尼斯世界纪录]]></description>
      <guid>https://stats.stackexchange.com/questions/636994/help-understanding-the-predictive-process-latent-gaussian-process-model</guid>
      <pubDate>Tue, 16 Jan 2024 16:40:38 GMT</pubDate>
    </item>
    <item>
      <title>在棒棒糖型图表中为每个数据集绘制 3 个点 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636993/plotting-3-points-per-data-set-in-lollipop-type-chart</link>
      <description><![CDATA[我想绘制一个图表，其中每个数据类别有多个数据点。对于某些上下文，我对不同的样本进行了一些分析，现在每个样本最多有 3 3 个数据点，我想以棒棒糖图表类型的方式呈现它们（见图）。我想知道这是否可以在 Excel 中绘制，如果不能，以这种方式绘制数据的最简单方法是什么？
如果我可以为每个样本设置 2 个由 3 个数据点（例如不同颜色）组成的“线”，以呈现我从每个样本的数据中提取的不同值，也会很有帮助。
谢谢，
夏洛特
]]></description>
      <guid>https://stats.stackexchange.com/questions/636993/plotting-3-points-per-data-set-in-lollipop-type-chart</guid>
      <pubDate>Tue, 16 Jan 2024 16:24:31 GMT</pubDate>
    </item>
    <item>
      <title>离散选择实验的适当设计是什么？</title>
      <link>https://stats.stackexchange.com/questions/636991/what-is-the-appropriate-design-for-a-discrete-choice-experiment</link>
      <description><![CDATA[我需要在 R 中开发一个离散选择实验，这是一个未标记的实验。
然而，在深入研究离散选择实验背后的理论后，仍不清楚是否有推荐的设计可供采用。尽管正交设计似乎是一个合适的选择，但一旦收集数据，它就变成非正交的。这是否意味着需要过渡到高效设计？然而，有效的设计需要事先估计，而我目前缺乏这种估计。考虑到我倾向于使用 MNL，我发现自己倾向于正交设计。
我很困惑如何在两者之间做出选择。我的选择集应包含 2 个选项，每个选项具有相同的 8 个属性，具有 2 个级别（2^8 = 256 个可能的选项）。由于调查的时间限制，每个受访者只能评估一组选择。因此，需要实施阻塞。]]></description>
      <guid>https://stats.stackexchange.com/questions/636991/what-is-the-appropriate-design-for-a-discrete-choice-experiment</guid>
      <pubDate>Tue, 16 Jan 2024 15:50:26 GMT</pubDate>
    </item>
    <item>
      <title>SE 和 CI 在 RVE 元回归 (robumeta) 的 R 输出中未对齐</title>
      <link>https://stats.stackexchange.com/questions/636990/se-and-ci-not-aligning-in-r-output-from-rve-meta-regression-robumeta</link>
      <description><![CDATA[我使用 robumeta 命令在 R 中实现了随机方差估计荟萃分析。我对 R 输出在解释显着性水平方面感到困惑。我正在复制下面的输出示例。根据标准误差和 t 值，效果在 5% 的水平上应该是显着的，但是，根据 95% CI 和指定的显着性水平，效果仅在 10% 的水平上才显着。我想知道哪些信息是正确的以及为什么会出现这种差异？
]]></description>
      <guid>https://stats.stackexchange.com/questions/636990/se-and-ci-not-aligning-in-r-output-from-rve-meta-regression-robumeta</guid>
      <pubDate>Tue, 16 Jan 2024 15:39:40 GMT</pubDate>
    </item>
    <item>
      <title>当已知事件未发生的几率与发生的事件相比非常低时，执行 Fisher 检验</title>
      <link>https://stats.stackexchange.com/questions/636989/performing-a-fisher-test-when-the-odds-of-the-events-not-occurring-are-known-to</link>
      <description><![CDATA[假设我有一个像这样的列联表：
 事件存在 事件缺席

事件 B 呈现 40 56
事件 b 缺席 23 238923

对于我的具体数据，我本质上知道a和b发生的概率很低，那么事件a和b都不存在的可能性就非常大。
在我看来，这可能高估了共现的结果。我有兴趣了解 a 和 b 何时比预期更频繁地一起出现。
有什么办法可以解决这个问题吗？就像寻找 a 和 b 同时出现，但知道 a 或 b 出现的可能性很小。
最后，我有兴趣看看存在 a 和 b 与仅存在 a 或仅存在 b 之间是否存在显着差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/636989/performing-a-fisher-test-when-the-odds-of-the-events-not-occurring-are-known-to</guid>
      <pubDate>Tue, 16 Jan 2024 15:36:24 GMT</pubDate>
    </item>
    <item>
      <title>一个群体、两个变量、两个时间点：正确的统计方法？</title>
      <link>https://stats.stackexchange.com/questions/636988/one-population-two-variables-two-timepoints-the-proper-statistical-method</link>
      <description><![CDATA[我有一组受试者 (n = 29)，他们在基线和 1 年后对两个变量进行了测试。对于参数，我们假设这两个为 var_behavior 和 var_brain。假设并基于其他研究，var_behavior ~ var_brain 是倒 U 形关系。值得注意的是，我的研究对象的年龄和性别是协变量。我的问题是我可以使用什么统计方法来测试：

如果一个方面的变化与另一个方面的变化相关
如果 Q#1 = true，是否符合倒 U 模型？

我试图使用 R 中的 Lavaan 来拟合二元潜在变化评分模型，但由于受试者数量较少，这不是一个很好的拟合。我也在考虑线性混合效应模型，因此我转换为包含 subjectID、var_behavior、var_brain 和访问（基线或第一年）的长格式，为每个主题分配两行两个访问值。公式为：
var_behavior ~ var_brain + (1|visit) + (1|subjectID) + 年龄 + 性别

但我不确定这是否是最佳选择。]]></description>
      <guid>https://stats.stackexchange.com/questions/636988/one-population-two-variables-two-timepoints-the-proper-statistical-method</guid>
      <pubDate>Tue, 16 Jan 2024 15:35:37 GMT</pubDate>
    </item>
    <item>
      <title>Cox 回归和 HR 缺失数据</title>
      <link>https://stats.stackexchange.com/questions/636984/missing-data-for-cox-regression-and-hr</link>
      <description><![CDATA[我正在进行一项研究，其中患者接受了手术，其中一些患者手术成功（结果 = 1），而另一些患者则没有成功（结果 = 0）。使用 Cox 模型计算风险因素，以获得关于收集的患者不同特征的 HR（风险比）。这些特征之一是“手术原因”，这是一个具有两个值的二元特征，我们将其称为“手术原因 X”。和“原因Y”。我的挣扎是，由于“原因 Y”，数据中没有患者手术不成功（结果 = 0）。这不允许我执行 Cox 回归来说明原因 X 与原因 Y 的相对风险。还值得一提的是，样本量很小 (N=27)。
在这种情况下，我可以做什么来说明相对于原因 X 和原因 Y 的相对风险 (HR)？
提前谢谢大家:)]]></description>
      <guid>https://stats.stackexchange.com/questions/636984/missing-data-for-cox-regression-and-hr</guid>
      <pubDate>Tue, 16 Jan 2024 14:02:20 GMT</pubDate>
    </item>
    <item>
      <title>哪个因变量最受预测变量影响？</title>
      <link>https://stats.stackexchange.com/questions/636982/which-dependent-variable-is-mostly-impacted-by-predictor</link>
      <description><![CDATA[通常，人们希望确定回归模型中最重要的预测变量（x1、x2、x3...、xn）。我的问题是相反的：我有一个数据集，其中包含一个风险因素risk和随着时间t的多个结果y1, y2, y3, ..., yn 。我想找出这些结果中哪些y1, y2, y3, ..., yn随着时间的推移t受风险的影响最大，这样我就可以做出类似“承载因子风险的单位显示 y3 和 y10 随着时间的推移增长幅度最大”之类的声明。
设置多个单一模型对我来说听起来太简单了（会使用 lmer 或 glmer，具体取决于分布），但是看看y1，y2， y3, ..., yn 作为风险的联合预测因子听起来也是错误的。有人有想法吗？
编辑：
根据 @Peter Flom 的建议，我提供了一些有关我的数据的附加信息。

风险是一个二元因素。
y1,...,n_ 是离散（分数）和连续变量（标准化分数）。理论上，它们可以被 z 标准化为相同的单位（这是我所在领域的常见做法）。大多数结果都具有相同的缺失数据模式，除了 2 个变量未在所有单位中进行测量，仅从 t3 开始。

数据示例：
#省略：更多变量、更多时间点、控制变量

单位风险时间 Y1 Y2 Y3 Y4
0 0 10 0.2 1 -0.2
0 1 10 0.3 1.4 -0.5
0 2 10 0.4 1.4 -0.5
0 3 10 0.5 1 -0.4
b 1 0 10 0.8 0.9 -0.3
b 1 1 10 1.0 1.6 -0.7
b 1 2 10 1.5 2.0 -0.8
b 1 3 10 1.7 2.8 -1.2
1 0 10 0.2 1 -0.4
c 1 1 10 0.6 1 -0.4
1 2 10 0.7 3.4 -1.2
1 3 10 0.6 4.1 -1.6


编辑2：
检查单独模型中的结果会产生......
model_1 &lt;- lmer(Y1 ~ RISK*时间 + 协变量 + (1|单位)，数据 = 数据集)
model_2 &lt;- lmer(Y2 ~ RISK*时间 + 协变量 + (1|单位)，数据 = 数据集)
＃ 等等

初始方法：

从 summary(model_n) 中选择 RISK*Time 交互作用显着的 Yn，并选择 AIC 最低的模型。
或者（另外）如果如果y1, ..., yn 等比例缩放：
选择 summary(model_n) 中具有最大 Beta 值的 Yn 进行 RISK*Time 交互......
]]></description>
      <guid>https://stats.stackexchange.com/questions/636982/which-dependent-variable-is-mostly-impacted-by-predictor</guid>
      <pubDate>Tue, 16 Jan 2024 13:52:21 GMT</pubDate>
    </item>
    <item>
      <title>解释 PCA 输出</title>
      <link>https://stats.stackexchange.com/questions/636979/interpreting-pca-output</link>
      <description><![CDATA[我有 40 列（变量）；我的 PCA 输出（来自 Minitab）表明 PC1-PC14 占我的变异的 75%。如何选择/确定每个 PC 列中哪些（原始）变量最重要？我在 PC1 列中看到 5 个（原始）变量具有较高的正值。因此，这五个人是该线性组合中最有影响力的。然后我是否会查看 PC2 列（依此类推，直到 PC14）并挑选出具有最高值的（原始）变量并说它们也很重要？我试图将 40 个原始变量归结为最有影响力的子集，然后进行回归分析，然后使用该子集查看有影响力的变量对因变量的影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/636979/interpreting-pca-output</guid>
      <pubDate>Tue, 16 Jan 2024 12:06:31 GMT</pubDate>
    </item>
    </channel>
</rss>