<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 13 Jun 2024 03:17:29 GMT</lastBuildDate>
    <item>
      <title>按实际收入匹配与按意外收入类型匹配</title>
      <link>https://stats.stackexchange.com/questions/649154/matching-on-actual-earnings-versus-matching-on-the-kind-of-unexpectedness-in-ear</link>
      <description><![CDATA[为简单起见，我们假设这是一个关于线性建模的问题，尽管我实际上正在研究一些非线性模型，并且愿意考虑其他模型，如果它们更有利的话。
我有大量短期、重叠的两年面板。我想将它们粘合在一起，以便创建一个持续时间更长的合成面板，用于研究收入动态和一生或十年的收入不平等。为此，我需要将一个面板第二年的家庭或个人与下一个面板第一年的家庭或个人联系起来。在面板中，我有关于哪些家庭或个人匹配（大多数年份）的数据信息，尽管搬入或搬出该地区的人可能不会被分配匹配。我希望匹配在经济行为和结果上与匹配的经济相似。
作为初步事项，我为每个样本面板年构建了 Mincer 方程，根据教育和培训历史以及人口统计特征预测收入。然而，在其他特征上匹配的个人的收入（对数收入）存在相当大的差异。此外，我已经确定这些错误具有高度持久性。所以我想我会把预测收入与实际收入的比率扔进我的匹配算法中，让最小二乘法来解决它。
但后来我想，既然我可以在匹配中使用的相似性算法中使用实际收入，为什么要使用这个比率作为预测因子。虽然这两种方法似乎选择了相似的人作为匹配，但几乎所有匹配产生的实际配对都会发生变化。
从那时起，我就一直在兜圈子，反复改变主意。最后，我想我应该问那些真正了解这种模型的人。因此我向你们求助。
救命！]]></description>
      <guid>https://stats.stackexchange.com/questions/649154/matching-on-actual-earnings-versus-matching-on-the-kind-of-unexpectedness-in-ear</guid>
      <pubDate>Thu, 13 Jun 2024 01:53:47 GMT</pubDate>
    </item>
    <item>
      <title>我如何将家庭分配到与成对距离测量一致的社会空间坐标？</title>
      <link>https://stats.stackexchange.com/questions/649151/how-can-i-assign-households-to-coordinates-in-a-social-space-consistent-with-pai</link>
      <description><![CDATA[如何将家庭分配到与成对距离测量一致的社会空间坐标？
我有一个定义不太明确的问题，关于创建一个有趣且有用的社会距离测量。
过去已经这样做过，例如，将社会经济地位压缩为一个维度。然而，在这种情况下，虽然他们想要一个内部一致的指标，但我认为他们同样有兴趣创建一个符合他们直觉的指标，而我希望由数据引导，而不是引导数据。这是许多人面临的一种问题，我认为对问题更清晰的定义和技术解决方案是相辅相成的。
我有很多测量人物特征的向量。我还有一个基于相似性的有意义但嘈杂的成对距离测量。我可以将每个特征分配给一个维度，然后定位这些点，但对于我的目的而言，这些位置没有用。只有点之间的距离才重要。为了回答这个问题，假设距离测量有意义，或者让我担心如何构建距离。
我对大约 180 个特征进行了测量。有些是连续的，具有有意义的差异和比率。其他是分类的，这就是我犹豫是否使用 PCA 的原因。我目前倾向于使用 Jaccard 度量将分类差异转换为差异度量，从而转换为距离度量。我正在寻找一种方法来减少与距离测量一致的维度。一旦我将数据尽可能地扁平化，我就会寻找有趣的特征、关系和形状，并使用一种方法让数据说话，而无需在其上施加线性模型。例如，我想尝试几种拓扑数据分析方法，如持久同源性。
多年来，我所做的大多数统计分析都是计量经济学或计量经济学衍生的，并且几乎完全由线性回归的变体组成。过去，当我谈到非线性模型时，我通常指的是对数线性的模型，或包括二次项和交互项等。走出那个领域让人感到兴奋又有点害怕。我不会想到有实用的技术可以在数据中查找形状，而无需明确说明允许什么样的形状。
如果我可以分配与我的距离测量一致的点位置，那将非常方便。为了获得洞察力和数据可视化，我希望使用尽可能少的维度。我如何——根据什么标准——确定我需要多少个维度？
一方面，我容忍的错误越少，需要的维度就越多。当某些点与其他两个点之间的距离比其他点之间的距离更远时，将更大的距离扩展到另一个维度可以避免违反三角不等式。如果三角不等式有很多大的违反，那么空间位置可能不是社会地位或社会距离的有用类比。知道它是否是本身就很有趣。但是因为我的距离测量值很嘈杂，所以如果这意味着我可以将数据压缩为更少的维度，那么允许对距离进行一些细微的调整是有意义的。
一旦我有了多个维度，我想为每个点对找到一组与该维度数和我的距离测量值一致的坐标。我不关心点云的旋转或平移，并且乐于使用任何方便的方法。有人能建议一种可以做到这一点的技术吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649151/how-can-i-assign-households-to-coordinates-in-a-social-space-consistent-with-pai</guid>
      <pubDate>Thu, 13 Jun 2024 00:43:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么维数会影响完全条件独立 (FullCI) 检验中的显著性和效应大小？</title>
      <link>https://stats.stackexchange.com/questions/649147/why-does-dimensionality-affect-significance-and-effect-size-in-a-full-conditiona</link>
      <description><![CDATA[2018 年 Runge 等人的论文“检测大型非线性时间序列数据集中的因果关联” 描述了 PCMCI 方法。它将新的 PCMCI 方法与他们称之为完全条件独立性测试 (FullCI) 的另一种方法进行了比较。FullCI 的工作原理是测试以所有其他变量为条件的两个变量之间的独立性（如果我理解正确的话，它就像是 PC 的强力版本）。
他们通过使用 FullCI 来测试天气模式（$Nino$）和不列颠哥伦比亚省地表温度（$BCT$）之间的因果关系，强调了 PCMCI 的必要性。首先，他们使用 FullCI 测试（并正确找到）链接 $Nino \rightarrow BCT$。然后，他们添加一个变量 $Z$，该变量由 $Nino + \mu $ 驱动，存在一些滞后，其中 $\mu$ 是噪声。重要的是，$Z$ 不会影响 $BCT$。
添加 $Z$ 会导致 $Nino \rightarrow BCT$ 关系的影响和重要性降低。他们通过指出$Z$将“解释”$BCT$的部分影响来解释这种减少的部分原因，因为它将成为条件集的一部分，这对我来说很有意义。但他们也指出，重要性降低的部分原因是维数增加。
为什么/如何维数会降低这种“FullCI”方法确定的因果关系的影响大小/重要性？]]></description>
      <guid>https://stats.stackexchange.com/questions/649147/why-does-dimensionality-affect-significance-and-effect-size-in-a-full-conditiona</guid>
      <pubDate>Thu, 13 Jun 2024 00:12:15 GMT</pubDate>
    </item>
    <item>
      <title>独立高斯分布的界积</title>
      <link>https://stats.stackexchange.com/questions/649146/bound-product-of-independent-gaussians</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/649146/bound-product-of-independent-gaussians</guid>
      <pubDate>Wed, 12 Jun 2024 23:16:03 GMT</pubDate>
    </item>
    <item>
      <title>对零假设的困惑</title>
      <link>https://stats.stackexchange.com/questions/649145/confusion-regarding-the-null-hypothesis</link>
      <description><![CDATA[我最近在做统计题时看到了这个问题：

一罐 Fun Juice 应该至少装有 64 盎司果汁。

灌装机经过校准，平均每瓶应该装有 64.05 盎司果汁。一位经理想知道机器是否灌装不足。她计划随机抽取一些瓶子样本，然后进行显著性检验。
零假设和备择假设是什么？

答案指出 $H_0$ 是 $\mu=64.05$ 并且 $H_a$ 是 $\mu&lt;64.05$。但是，我得到的结果是 $H_0$ 是 $\mu=64$，而 $H_a$ 是 $\mu&lt;64%$。这里的“未充满”难道不是意味着平均值低于其应包含的量（64 盎司）而不是低于机器校准的填充量（64.05 盎司）吗？这是教科书中的错误，还是我只是遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/649145/confusion-regarding-the-null-hypothesis</guid>
      <pubDate>Wed, 12 Jun 2024 23:15:30 GMT</pubDate>
    </item>
    <item>
      <title>凸序下的期望</title>
      <link>https://stats.stackexchange.com/questions/649141/expectation-under-convex-order</link>
      <description><![CDATA[我试图理解以下陈述是否正确。让 $M,N$ 和 $X$ 为随机变量。如果以下不等式对任何凹非减函数都成立 $u$
\begin{equation}
\mathbb{E}[u(N)]\leq\mathbb{E}[u(M)]
\end{equation
则
\begin{equation}
\mathbb{E}[u(N+X)]\leq\mathbb{E}[u(M+X)]
\end{equation
请注意，$N$ 和 $M$ 之间不存在假定的关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/649141/expectation-under-convex-order</guid>
      <pubDate>Wed, 12 Jun 2024 21:54:20 GMT</pubDate>
    </item>
    <item>
      <title>手动特征提取可以被视为学习算法的一部分吗？</title>
      <link>https://stats.stackexchange.com/questions/649140/can-manual-feature-extraction-be-considered-a-part-of-a-learning-algorithm</link>
      <description><![CDATA[我们可以将学习算法视为一个元组$(\mathcal{H}, \mathcal{O}, \mathcal{L})$，其中$\mathcal{H}$、$\mathcal{O}$和$\mathcal{L}$分别是假设类、优化器和损失函数。
我们还可以将学习算法视为将我们从数据带到模型的整个管道。
假设我们有以下机器学习方法：
$$\text{输入，输出数据} \xrightarrow{\phi} \text{特征，输出数据} \to \text{训练分类器} \to \text{模型} $$
其中 $\phi$ 是固定的，即无法从数据中学习。如果我们假设输入是图像，则 SIFT 方法就是这样一个例子。在这种情况下，我们是否可以将学习算法定义为从输入、输出数据到模型的整个流程，包括特征提取步骤作为学习算法？换句话说，特征提取步骤是否被视为学习算法的一部分？
我的观点，可能是错误的
我认为是的，因为我们将 CNN 视为一种学习算法。本质区别在于，在 CNN 的情况下，$\phi$ 不再是固定的，而是可以从数据中学习的。
此外，当使用固定特征提取方法时，学习算法的假设类是什么？
如果 $z=\phi(x)$，假设类是否由函数组成：
$$f \colon Z \to Y$$
或：
$$f \colon X \to Y $$
？]]></description>
      <guid>https://stats.stackexchange.com/questions/649140/can-manual-feature-extraction-be-considered-a-part-of-a-learning-algorithm</guid>
      <pubDate>Wed, 12 Jun 2024 21:54:15 GMT</pubDate>
    </item>
    <item>
      <title>调整多元预测模型以适应季节性变化</title>
      <link>https://stats.stackexchange.com/questions/649139/adjusting-a-multivariate-predictive-model-for-drifting-seasonalities</link>
      <description><![CDATA[这个问题是最初在《量化金融》中提出的一个问题的重新发布。我被告知这是一个更适合它的地方。
我有一个每日观察的时间序列，这些序列被汇总为每月周期。月度序列表现出强烈而可靠的季节性模式，非常适合用 X-13ARIMA-SEATS 进行调整。X-13ARIMA-SEATS 可以生成预测，OOS 预测通常很好，误差分布接近对称，平均中位数和众数接近零，平均方差平稳，没有明显的序列自相关。
现在我对未来一个月有了一个很好的预测，我想预测个别日子。每日数据仅限于预先知道的工作日子集。一个月内还有其他季节性模式，我正在尝试预测这些模式。许多模式在时间上都高度可靠，一个月的季节性与同一月份在具有相同工作日模式的不同年份的季节性非常相似。
我采用的方法是使用与任何给定日期相对应的月度总数的百分比作为因变量，然后使用一系列描述季节性的二元独立变量。由于这些特征在几个月内基本一致，因此可以使用所有月份的组合来计算系数。问题是季节性会随时间而变化，尽管变化非常缓慢，这导致了两个问题：

每日预测的准确性会随着时间的推移而下降
较早的观察结果对于计算系数的用处越来越小。

一个简单的例子是：我正在停车场计算汽车数量，我的目标是预测每天将有多少辆车停放。在月份开始之前，我对将停放的汽车总数有一个预测。从之前的观察中，我知道每个工作日的利用率水平都不同，假期前几天比较安静，月底和月中比较繁忙，但其他模式也会随着时间而变化（繁忙的周三可能会逐渐变成繁忙的周二）
我正在尝试找到训练回归的“最佳点”，我发现最好的方法是将某种衰减分配给观察结果，以便它们对系数的影响随着时间的推移而下降。我一直在做的一件事是根据近期历史的较小滚动样本每月计算系数，然后以指数方式加权系数与前一个月的系数。到目前为止，它有点有效，但似乎笨拙而笨拙，并且仍然难以适应新模式。我也尝试过简单地重复使用上个月具有相同工作日模式的值，这几乎不需要做任何工作就可以得到很多正确结果，但不够准确，无法使用。
我希望得到关于如何改进此过程的建议。我尝试搜索了好几次，但似乎不知道该搜索什么才能找到有用的东西。下面是一些 R 伪代码，希望能说明一下我目前正在做的事情。我希望有一种方法可以将权重构建到模型本身中。我知道我可以根据观察结果的近期性（越近，副本越多）复制观察结果，通过填充训练数据来模拟这种情况，但这似乎非常可疑？任何建议都将不胜感激。
library(lubridate)
library(tibble)
library(dplyr)
library(tidyr)
library(purrr)

training_data &lt;- daily_data |&gt; 
filter(date &gt;= max(date) - months(24)) |&gt;
group_by(period = floor_date(date, &#39;month&#39;) |&gt;
mutate(value = value/sum(value)) |&gt; 
ungroup() |&gt; inner_join(features, by = &#39;date&#39;)

model &lt;- lm(value ~ feat1 + feat2 + feat3, data = training_data)
#实际上这是一个矩阵而不是数据框，这只是一个例子
model_coef &lt;- pivot_wider(enframe(coef(model)))
previous_coefs &lt;- union_all(
previous_coefs, 
add_column(model_coef, date = max(training_data$period))
)
ewma_lambda &lt;- 0.85
weighted_coefs &lt;- mutate(
across(
-date,
\(x) acquire(
x,
\(.x, .y)(1 - ewma_lambda) * .y + ewma_lambda * .x
)
)
)
]]></description>
      <guid>https://stats.stackexchange.com/questions/649139/adjusting-a-multivariate-predictive-model-for-drifting-seasonalities</guid>
      <pubDate>Wed, 12 Jun 2024 21:50:52 GMT</pubDate>
    </item>
    <item>
      <title>如何对泊松分布数据进行功效分析</title>
      <link>https://stats.stackexchange.com/questions/649138/how-to-perform-a-power-analysis-for-poisson-distributed-data</link>
      <description><![CDATA[我想执行简化的功效分析，以确定在对照和实验条件下应有多少细胞（样本）（假设在各种条件下 n 相等）。对于 0.05 的 alpha 水平、0.95 功效，并检测计数 10% 的变化（对照中的平均计数为 0.2，而实验中的平均计数为每样本 0.22 个计数）。对于 t 检验或正态分布，R 中的 pwr 包和确定 cohen&#39;s d 很简单，但我不确定在处理遵循泊松分布的计数数据时如何执行此操作。
如果需要 sd，请使用 0.3。]]></description>
      <guid>https://stats.stackexchange.com/questions/649138/how-to-perform-a-power-analysis-for-poisson-distributed-data</guid>
      <pubDate>Wed, 12 Jun 2024 21:48:31 GMT</pubDate>
    </item>
    <item>
      <title>多元概率估计</title>
      <link>https://stats.stackexchange.com/questions/649135/estimation-of-multivariate-probability</link>
      <description><![CDATA[假设 $(X_{1}, \dots, X_{n})$ 为多元分布，我可以从中生成样本。接下来，假设我必须计算
$$
P(X_{1}\in A_{1}, \dots, X_{n}\in A_{n}),
$$
其中 $A_{1}, \dots, A_{n}$ 是一些区间。然后，自然的做法是从样本$(x_{1}^{i}, \dots, x_{n}^{i})$中进行估计，其中$i = 1:N$
$$
\frac{\sum_{i=1}^{N}I\{ x_{1}^{i}\in A_{1}, \dots, x^{i}_{n}\in A_{n})\}}{N}。
$$
对于哪些分布，这是一种不好的方法？如果可以写出联合分布，在哪些情况下取数值积分会更好？]]></description>
      <guid>https://stats.stackexchange.com/questions/649135/estimation-of-multivariate-probability</guid>
      <pubDate>Wed, 12 Jun 2024 20:45:24 GMT</pubDate>
    </item>
    <item>
      <title>复制数据集是否是一种增强？</title>
      <link>https://stats.stackexchange.com/questions/649133/is-duplicating-dataset-an-augmentation</link>
      <description><![CDATA[对于非常小的数据集，随机森林回归模型中存在大量过拟合。我已经删除了无关数据、缩放和特征选择，但过拟合仍然存在。过采样技术极大地改善了结果，但由于它不会创建不切实际的数据，因此不允许我使用这种技术。我可以将数据集加倍（重复数据两次）并像这样改进数据集吗？或者我应该将数据集乘以一个数字并将其添加到主数据集？您认为这些方法合理有效吗？数据集是表格和数字。]]></description>
      <guid>https://stats.stackexchange.com/questions/649133/is-duplicating-dataset-an-augmentation</guid>
      <pubDate>Wed, 12 Jun 2024 20:31:16 GMT</pubDate>
    </item>
    <item>
      <title>在核回归的背景下，为什么我们将特征图定义为等于核 $\varphi(x)=k(\cdot ,x)$？</title>
      <link>https://stats.stackexchange.com/questions/649132/in-the-contex-of-kernel-regression-why-do-we-define-the-feature-map-as-equal-to</link>
      <description><![CDATA[我有一个符号上的困惑，正在努力澄清。在核回归的上下文中，核和特征图之间的关系定义如下：
考虑一个正定实值核$ k:{\mathcal {X}}\times {\mathcal {X}}\to \mathbb {R} $，它位于非空集$\mathcal {X}$上，其对应的再生核希尔伯特空间$H_{k} $。
定义映射
${\begin{aligned}\varphi \colon {\mathcal {X}}&amp;\to H_{k}\\\varphi (x)&amp;=k(\cdot ,x)\end{aligned}}$
（因此 $ \varphi (x)=k(\cdot ,x) $ 本身就是一个映射 $ \mathcal {X}\to \mathbb{R} $）。由于 $k$ 是一个再生核，因此
$ \varphi (x)(x&#39;)=k(x&#39;,x)=\langle \varphi (x&#39;),\varphi (x)\rangle ,$
其中$ \langle \cdot ,\cdot \rangle $ 是 $ H_{k}$ 的内积。
现在这一切都很好，但是当我看一个例子时，我不确定 $ \varphi (x)=k(\cdot ,x) $ 是如何的。例如取 2 次多项式核：
$$
k(x, x&#39;) = (x \cdot x&#39; + 1)^2,
$$
在这种情况下，特征图为
$$
\varphi(x) = \begin{pmatrix}
x^2 \\
\sqrt{2} \cdot x \\
1
\end{pmatrix},
$$
事实上 $\langle \varphi (x&#39;),\varphi (x)\rangle = k(x, x&#39;)$。但是 $ \varphi (x)=k(\cdot ,x) $ 又是如何呢？在这种情况下我该如何理解这个符号？]]></description>
      <guid>https://stats.stackexchange.com/questions/649132/in-the-contex-of-kernel-regression-why-do-we-define-the-feature-map-as-equal-to</guid>
      <pubDate>Wed, 12 Jun 2024 20:23:11 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 tf.image.SSIM 函数[关闭]</title>
      <link>https://stats.stackexchange.com/questions/649126/how-to-use-the-tf-image-ssim-function</link>
      <description><![CDATA[有人能帮我理解如何使用这个 SSIM 函数吗（https://www.tensorflow.org/api_docs/python/tf/image/ssim）？根据文档信息，filter_size 参数的默认值为 11，“由于过滤器大小，图像大小必须至少为 11x11”。如果我使用 8x11 大小的图像，我应该如何调整这个参数，如果适用的话，应该如何调整其他函数参数？我使用 filter_size = 8 进行了测试，它可以工作，但我不知道简单地这样做是否正确。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/649126/how-to-use-the-tf-image-ssim-function</guid>
      <pubDate>Wed, 12 Jun 2024 19:11:18 GMT</pubDate>
    </item>
    <item>
      <title>如何根据先验概率 $P(R)$ 和后验概率 $P(R/B)$ 获得似然值 ($P(B/R)$)</title>
      <link>https://stats.stackexchange.com/questions/649125/how-to-obtain-likelihood-pb-r-given-the-prior-pr-and-the-posterior-pr</link>
      <description><![CDATA[我正在研究一个与多项选择题相关的主题。我想衡量信息源（或学生的信息搜索）的效率，我相信贝叶斯统计是正确的方法；但是，由于我只知道基础知识，所以我想展示它以查看我的推理是否连贯。
给定一个多项选择题（例如，有 4 个答案），其中只有一个答案是正确的，学生可以仅根据他/她在家学习的内容来回答，为每个答案分配一个概率，例如 P(R)=(0.4, 0.3, 0.15, 0.15)。答案可能就此结束，或者学生可能会查阅书籍并更新这些概率，例如 P(R|B)=(0.4,0.6,0,0)。 P(R) 是先验概率，P(R|B) 是后验概率，(多项式) 和 P(B/R) 都是似然率，我将其理解为我先前信念 P(R) 的更新，并将其转换为 P(R|B)。
所以我想知道 P(B|R)，我也想看看我是否可以确定 P(B|R) 会使 P(R|B)=(1,0,0,0)，也就是说，确定地选择正确的答案。
我理解这是一种逆问题，不会有唯一的解决方案；但也许有一些启发式方法来近似解决方案，至少对于寻找 P(B|R) 的第一个挑战而言。
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/649125/how-to-obtain-likelihood-pb-r-given-the-prior-pr-and-the-posterior-pr</guid>
      <pubDate>Wed, 12 Jun 2024 19:08:35 GMT</pubDate>
    </item>
    <item>
      <title>与马哈拉诺比斯距离相关的术语“白化”数据的含义是什么？</title>
      <link>https://stats.stackexchange.com/questions/649111/what-is-the-meaning-of-term-whiten-data-in-relation-to-mahalanobis-distance</link>
      <description><![CDATA[我正在写论文，但在理解这篇论文时遇到了困难：https://people.bu.edu/bkulis/pubs/ftml_metric_learning.pdf
我的专业不是数学，但我能理解基础知识，所以我希望你能用基本的词汇帮助我理解
我在第 2.2.1 节马哈拉诺比斯距离。
据我所知，马哈拉诺比斯距离是在数据点“白化”后计算它们之间的欧几里得距离（据我理解，就是将数据的分布转换为高斯分布（正态分布），其均值为 0，协方差为单位矩阵。哇，但它不会丢失数据点之间的相关距离，对吧？
顺便问一下，这样做有什么直觉吗？比如数据的形状一开始可能是椭圆形并向左倾斜，变换后它会变成圆形和垂直的，对吧？它对噪音有什么作用吗？
最后抱歉，因为我不是本地人，我不明白“白化”这个词，你在这里如何表达白化的含义
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/649111/what-is-the-meaning-of-term-whiten-data-in-relation-to-mahalanobis-distance</guid>
      <pubDate>Wed, 12 Jun 2024 16:01:50 GMT</pubDate>
    </item>
    </channel>
</rss>