<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 07 Mar 2024 09:12:31 GMT</lastBuildDate>
    <item>
      <title>分析和比较非平稳时间相关信号</title>
      <link>https://stats.stackexchange.com/questions/642038/analyse-and-compare-non-stationary-time-dependent-signals</link>
      <description><![CDATA[我需要进行健全性检查。我正在处理力-时间、位移-时间和速度-时间信号的数据集。我的所有信号都是非平稳的，它们包含趋势（低频变化）和周期性（高频变化）。我感兴趣的是分析不同信号的频率内容以及比较不同信号。我已经阅读了很多可能适用于我的问题的不同技术，此时我觉得我正在阅读相互矛盾的信息。这就是我到目前为止一直在做的事情：

计算整个频谱和选定事件的功率/幅度密度频谱以研究频率内容
绘制累积功率谱密度以查看不同信号之间的频率内容如何变化
用小波图研究频率内容如何随时间变化
绘制自相关函数以查找每个信号的基频
绘制滤波信号的自相关函数以关注高频内容
（待完成）绘制不同信号之间的相关函数以进行比较，或将部分信号与整个信号进行比较（事件检测）
计算不同信号的皮尔逊相关系数，以全面了解相似性

当我的信号不稳定时，使用这些技术有意义吗？我是否必须使用差分使信号稳定？我对预测或建模不感兴趣，我真的只想定性分析我的信号。另外，还有其他我可以研究的技术吗？
谢谢你了！]]></description>
      <guid>https://stats.stackexchange.com/questions/642038/analyse-and-compare-non-stationary-time-dependent-signals</guid>
      <pubDate>Thu, 07 Mar 2024 08:08:04 GMT</pubDate>
    </item>
    <item>
      <title>获取高斯过程二元分类的认知不确定性</title>
      <link>https://stats.stackexchange.com/questions/642037/get-epistemic-uncertainty-of-gaussian-process-binary-classification</link>
      <description><![CDATA[假设 $f \colon \mathbb R \to \{-1, 1\}$ 是由 $P(f(x) = 1)=p(x)$ 对于所有 $x \in \mathbb R$，其中 $p(x)$ 是一个 sigmoid 函数（对于 $x \to -\infty$ 为零， $x \to \infty$ 为 1，它是连续且非递减的）。
我有 $(x_i, f(x_i))$ 的示例 $i = 1, \ldots, N $。我想获得函数 $p$ 的估计及其认知不确定性的估计。我的目标是有一个不确定性界限，就像 $p(x) \in [\langle p \rangle(x) - C_\alpha(x), \langle p \rangle(x ) + C_\alpha(x)]$，其中 $\langle p\rangle$ 是 $p$ 和 $C_\alpha$ 是依赖于 $x$ 的置信度区间宽度取决于置信水平 $\alpha$。
由于我事先不知道 $p(x)$ 的适当函数形状，所以我想到了高斯过程分类。借助 sklearn，我可以使用 GaussianProcessClassifier 并通过该函数获得 $p(x)$ 的估计值预测概率。此函数不允许使用关键字 return_std。有数学原因吗？
这是一个代码片段，其中使用 $p$ 生成数据，该数据是重新缩放的 arctan：
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

从 sklearn.gaussian_process 导入 GaussianProcessClassifier
从 sklearn.gaussian_process.kernels 导入 RBF、ConstantKernel

# %%
# 生成合成数据

贝塔 = 10
prob_func = lambda x: 1 / np.pi * (np.pi / 2 + np.arctan(beta * x))
rng = np.random.default_rng(2024)
N = 100

X = rng.normal(大小=N, 比例=1/np.sqrt(beta))
Y = rng.二项式(1, prob_func(X), size=N)

plt.plot(X, Y, &#39;o&#39;)
plt.plot(np.sort(X), prob_func(np.sort(X)))

# %%
# 高斯过程分类

rbf = ConstantKernel(1.0) * RBF(length_scale=1.0)

gpc = GaussianProcessClassifier(内核=rbf)

gpc.fit(np.reshape(X, (N, 1)), Y)

# %%
# 预测概率

x_test = np.reshape(np.linspace(-3, 3, 1000), (1000, 1))
prob_estimate = gpc.predict_proba(x_test)
估计 = gpc.predict(x_test)

plt.plot(x_test, prob_estimate[:, 1])
plt.plot(x_test, prob_func(x_test))
plt.plot(x_test, 估计)
plt.legend([&#39;GP 估计&#39;, &#39;真相&#39;])
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/642037/get-epistemic-uncertainty-of-gaussian-process-binary-classification</guid>
      <pubDate>Thu, 07 Mar 2024 07:59:47 GMT</pubDate>
    </item>
    <item>
      <title>圆上贪婪匹配的期望平均距离</title>
      <link>https://stats.stackexchange.com/questions/642036/expected-average-distance-in-greedy-matching-on-a-circle</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/642036/expected-average-distance-in-greedy-matching-on-a-circle</guid>
      <pubDate>Thu, 07 Mar 2024 07:44:36 GMT</pubDate>
    </item>
    <item>
      <title>根据序数因变量识别与常模不同的异常值名义组</title>
      <link>https://stats.stackexchange.com/questions/642035/identifying-an-outlier-nominal-group-different-than-the-norm-based-on-an-ordina</link>
      <description><![CDATA[作为我的研究生论文的一部分，我使用 4 点有序李克特量表（范围从 1：非常不满意到4：非常满意）。我想要看看是否有任何地区在满意度方面与所有地区的整体标准存在显着差异，而不仅仅是彼此之间的差异。我熟悉差异检验，例如我现在使用的 SPSS 程序上的 Kruskal Wallis，但这些检验通常是为成对比较而构建的，而不是真正针对 4 个以上自变量组（例如我的情况）。因此我想问是否有任何合适的方法可以用来有效地做到这一点。感谢大家并感谢您的所有见解。干杯！]]></description>
      <guid>https://stats.stackexchange.com/questions/642035/identifying-an-outlier-nominal-group-different-than-the-norm-based-on-an-ordina</guid>
      <pubDate>Thu, 07 Mar 2024 07:30:10 GMT</pubDate>
    </item>
    <item>
      <title>当 lambda <=0 时，岭回归的解决方案是否仍然可以最小化成本函数？</title>
      <link>https://stats.stackexchange.com/questions/642032/does-solution-to-ridge-regression-still-minimizes-the-cost-function-when-lambda</link>
      <description><![CDATA[这是一个家庭作业问题，要求我找到最小化成本函数的显式表达式。
我找到的解决方案是：
$\hat{\theta} = (X^TX + \lambda I)^{-1}X^Ty$
现在问题进一步询问：
如果 lambda &lt;=0 是这个解，仍然相当于最小化成本函数吗？
我不知道如何回答这个问题，我的理解是它仍然会最小化成本函数，但可能会使协变量不稳定？]]></description>
      <guid>https://stats.stackexchange.com/questions/642032/does-solution-to-ridge-regression-still-minimizes-the-cost-function-when-lambda</guid>
      <pubDate>Thu, 07 Mar 2024 06:12:46 GMT</pubDate>
    </item>
    <item>
      <title>缩放条件随机变量不会改变条件分布，为什么？</title>
      <link>https://stats.stackexchange.com/questions/642031/scaling-the-conditioned-random-variable-does-not-change-conditional-distribution</link>
      <description><![CDATA[给定两个随机变量 $X$ 和 $Y$，我凭直觉知道
$$
\mathbb{E}[X\,|\,Y]=\mathbb{E}[X\,|\,cY],
$$
其中 $c$ 是一些非随机常数。我的直觉告诉我，缩放条件随机变量不会改变我们所条件化的信息量。还有更严谨的论证吗？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/642031/scaling-the-conditioned-random-variable-does-not-change-conditional-distribution</guid>
      <pubDate>Thu, 07 Mar 2024 06:10:35 GMT</pubDate>
    </item>
    <item>
      <title>随机森林模型中特征的敏感性分析</title>
      <link>https://stats.stackexchange.com/questions/642030/sensitivity-analysis-of-features-in-a-random-forest-model</link>
      <description><![CDATA[我构建了一个大型随机森林分类器，并且能够输出特征重要性，如下所示：

我知道这种重要性是基于平均减少的杂质。但如何解释这一点 - 对于那些相对重要性较高的人来说，它与线性回归中的小 p 值大致相同吗？
此外，我想知道如何进一步检查这些功能对我的响应变量 Y 的影响 - 类似于敏感性分析。我采用套索回归并尝试找到更容易解释的系数。但我的测试集上的 R 平方很糟糕（〜-10）。例如，有没有办法表明重要性图上最重要的特征对我的 Y 变量产生积极或消极的影响？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642030/sensitivity-analysis-of-features-in-a-random-forest-model</guid>
      <pubDate>Thu, 07 Mar 2024 04:20:01 GMT</pubDate>
    </item>
    <item>
      <title>回归分析总是需要去趋势吗？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/642028/regression-analysis-always-need-detrend</link>
      <description><![CDATA[特别是，利用海温数据研究全球变暖的影响的案例，
是否需要对海温数据进行去趋势处理？
有人说我们必须消除它的趋势以防止线性关系重叠。
但我无法理解它，因为如果我们对温度数据进行去趋势（线性），我认为它没有“全球变暖”趋势。
还有相关性分析怎么样？]]></description>
      <guid>https://stats.stackexchange.com/questions/642028/regression-analysis-always-need-detrend</guid>
      <pubDate>Thu, 07 Mar 2024 03:29:17 GMT</pubDate>
    </item>
    <item>
      <title>通过结构方程建模获得简单单变量回归的 R 平方等价物</title>
      <link>https://stats.stackexchange.com/questions/642026/getting-an-equivalent-of-r-squared-for-simple-univariate-regression-done-with-st</link>
      <description><![CDATA[我需要计算一个非常简单的回归模型结果〜预测器。为了处理缺失，我必须使用 FIML 并且还需要引导。由于 R 中的 lavaan 包同时提供了这两种功能，所以我使用了它：
模型 &lt;- sem(&#39;结果 ~ 预测器&#39;, data = data, Missing = &quot;FIML&quot;, se=&quot;BOOTSTRAP&quot;, bootstrap = 2000,fixed.x = F)
摘要（模型）

不幸的是，在这种结构方程建模方法中，没有给出 R 平方和调整后的 R 平方。有人能告诉我如何获得表明效应大小的等效度量吗？
如果有比使用 lavaan 更简单的方法，为单变量回归提供 FIML、引导和效应大小输出，那就更好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/642026/getting-an-equivalent-of-r-squared-for-simple-univariate-regression-done-with-st</guid>
      <pubDate>Thu, 07 Mar 2024 02:44:45 GMT</pubDate>
    </item>
    <item>
      <title>通过归一化方法改变的主成分可以用于通过 SVD 构造原始数据形状吗</title>
      <link>https://stats.stackexchange.com/questions/642025/can-principal-components-changed-by-a-normalization-method-be-used-to-construct</link>
      <description><![CDATA[我计划使用一种名为 Harmony 的算法，该算法专为数据标准化而设计，特别是在单细胞数据分析的背景。 Harmony 的运行方式是将主成分 (PC) 作为输入并输出校正后的主成分 (PC)。
通常，Harmony 应用于排名前 k 的 PC，以纠正批次效应或其他变异源。但是，我想保留标准化后的原始数据结构。为此，我会将从我的数据集生成的所有 PC 输入到 Harmony 中。我将使用奇异值分解 (SVD) 来生成所有可能的主成分。
矩阵A的SVD可以表示为：
$$
A = 美国V^T
$$
这里，U和V是正交矩阵，而S是包含奇异值的对角矩阵。为了创建PC，我将乘以U S，而不是执行k-rank近似子集PC正如我见过的所有使用和谐的方法一样。
这些PC将输入到和声，从而产生输出PC&#39;。
$$
PC \rightarrow 和谐 \rightarrow PC&#39;
$$
经过Harmony处理后，得到归一化的PC（PC&#39;）。我的假设是标准化分量 PC&#39; 可以等效地表示为修改矩阵 U&#39; 和 S&#39; 的乘积，这意味着：
$$
PC&#39; \equiv U&#39;S&#39; \equiv (US)&#39;
$$
最终目标是以标准化形式重建原始数据集，我认为可以通过以下方式实现：
$$
(美国)&#39; V^T = A&#39;
$$
我向社区提出的问题是：

考虑到 Harmony 标准化了 PC (PC -&gt; PC&#39;)，将标准化 PC (PC&#39;) 等同于 $(US)&#39;$ 然后使用它以标准化形式重建原始数据矩阵，如 $(US)&#39; V^T = A&#39;$?
我使用所有 PC 通过 Harmony 进行标准化并随后重建数据集的方法是否存在任何概念或数学缺陷？
]]></description>
      <guid>https://stats.stackexchange.com/questions/642025/can-principal-components-changed-by-a-normalization-method-be-used-to-construct</guid>
      <pubDate>Thu, 07 Mar 2024 02:27:39 GMT</pubDate>
    </item>
    <item>
      <title>我可以从数据集中的相同属性派生出多个相似的特征吗？</title>
      <link>https://stats.stackexchange.com/questions/642024/can-i-have-multiple-similar-features-derived-from-same-properties-in-a-dataset</link>
      <description><![CDATA[假设我正在将（线性）回归模型拟合到一个一百行数据集，其数据记录了一系列我几乎无法重现或进一步进行以获得更多记录的实验，我注意到有多个列/特征&lt; em&gt;x1, ..., xn 本质上是一个名为 X 的更基本属性的派生。
现在，显然如果可能的话只记录X是很自然的，但是由于实验的限制，X是不可能直接测量的，因此我们必须寻求其他方法来测量坐标下的X。请注意，X 上的不同观测系统可能具有不同的数值。这就是让我困惑的地方，因为 X 上的不同表示似乎在统计上无关，在某种程度上，这些特征中的每一对都没有很强的相关性（coeff。&gt; 0.9），这是可以接受的吗将所有这些特征（大约 5 到 10 个）保留在我的数据集中，而不必担心“过度强调” X的重要性？
我还考虑过只保留其中一个特征，无论是任意的还是通过更严格的统计分析，然而，这会显着减少我的数据的维度，这似乎相当危险，因为我没有很多其他特征可以使用与.
对这种情况有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642024/can-i-have-multiple-similar-features-derived-from-same-properties-in-a-dataset</guid>
      <pubDate>Thu, 07 Mar 2024 01:33:03 GMT</pubDate>
    </item>
    <item>
      <title>如何将更高级别的分组纳入lmer模型中？</title>
      <link>https://stats.stackexchange.com/questions/642022/how-to-include-higher-level-grouping-into-lmer-model</link>
      <description><![CDATA[我有一个面板数据集，我的因变量是长期合同农场工人的 Logit 转换比例。我对以可变田园为代表的田园重点对农业的影响特别感兴趣。困难有两方面。首先，这个变量的影响随着时间的推移而变化。其次，该变量的数据仅在更高级别的分组（称为 RC）中可用。为了处理第一个问题，我使用混合模型：
模型 &lt;- lmer(logitshare ~ 田园 + 其他变量 + (田园 | 年),
               数据=我的数据）

我该如何处理第二个问题，即在模型中包含田园仅适用于 RC 的事实？]]></description>
      <guid>https://stats.stackexchange.com/questions/642022/how-to-include-higher-level-grouping-into-lmer-model</guid>
      <pubDate>Thu, 07 Mar 2024 00:40:56 GMT</pubDate>
    </item>
    <item>
      <title>如何将问题呈现为逻辑回归模型[关闭]</title>
      <link>https://stats.stackexchange.com/questions/642021/how-to-present-a-problem-as-a-logistic-regression-model</link>
      <description><![CDATA[我正在学习逻辑回归，并且我试图了解何时适合使用逻辑回归模型。到目前为止，我们已经讨论了当我们的响应是二元时使用逻辑回归模型，并使用 logit 作为链接函数。然而，我在实际编写如何编写特定问题的逻辑回归模型时遇到了困难。我想知道是否有关于这个主题的任何参考资料或示例？另外，有什么好书可能有助于学习广义线性模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642021/how-to-present-a-problem-as-a-logistic-regression-model</guid>
      <pubDate>Thu, 07 Mar 2024 00:33:21 GMT</pubDate>
    </item>
    <item>
      <title>依次缩小模型</title>
      <link>https://stats.stackexchange.com/questions/642004/reduce-the-model-sequentially</link>
      <description><![CDATA[我收到了一个方差分析表，并要求按顺序缩小模型。

这里，Mix 和 Plasticizer 是两个主要效果，Run 是块因子，因此是随机效果。
我搜索了在线资源，说：按顺序简化模型时，通常首先评估高阶项的重要性，然后在必要时继续评估低阶项。
本作业的解决方案是将模型按顺序缩小：Plasticizer* Mix、Plasticizer、Run*Mix
关于为什么按这个顺序有什么想法吗？如果我们从最大的 p 值交互开始，那么首先是 Run*Mix？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642004/reduce-the-model-sequentially</guid>
      <pubDate>Wed, 06 Mar 2024 20:26:49 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归；协变量相互影响预测结果</title>
      <link>https://stats.stackexchange.com/questions/642003/logistic-regression-covariates-effect-on-each-other-predicting-the-outcome</link>
      <description><![CDATA[我有一个逻辑回归模型，其中我的结果变量是一种具有“是”和“否”结果的疾病。我们知道，年龄与这种疾病高度相关。我有一种感兴趣的蛋白质的数据，想看看这种蛋白质 P 是否与该疾病有关。当我在逻辑模型（R 中）中单独使用蛋白质作为预测变量时，我得到了显着的 p 值。但当我在模型中添加年龄时，我的蛋白质不再显着。
我还研究了我的蛋白质与年龄的相关性，结果是不相关的（相关系数为 0.08）。那么从回归模型中忽略年龄是否安全？
疾病 ~ 蛋白质 # 显着（p 值：0.00003）
疾病 ~ 蛋白质 + 年龄
    # 年龄很重要，但蛋白质不再重要（p 值 = 0.2）
]]></description>
      <guid>https://stats.stackexchange.com/questions/642003/logistic-regression-covariates-effect-on-each-other-predicting-the-outcome</guid>
      <pubDate>Wed, 06 Mar 2024 20:19:36 GMT</pubDate>
    </item>
    </channel>
</rss>