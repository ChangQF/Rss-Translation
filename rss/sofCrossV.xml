<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 14 Jul 2024 15:22:29 GMT</lastBuildDate>
    <item>
      <title>寻找概率密度函数的练习</title>
      <link>https://stats.stackexchange.com/questions/651024/exercise-on-finding-propability-density-function</link>
      <description><![CDATA[设 $Y_1$ 和 $Y_2$ 独立且在区间 (0, 1) 上均匀分布。求 $U = Y_1/Y_2$ 的概率密度：
解决方案：
$F_U(u) = P(U \le u) = P(Y_1/Y_2 \le u)$。看图：

我们可以看到有两个区域：$0 \le u \le 1$ 和 $u \gt 1$。因为 $tg\alpha = \frac{1}{u} = \frac{y_2}{y_1}$ 我们看到 $u = y_1$，所以可以说 $F_U(u) = \frac{y_1 y_2}{2} = \frac{u y_2}{2}$，因为 $y_2 = 1$，然后 $F_U(u) = \frac{u}{2}$ 对于 $0 \le u \le 1$。因此，$f_U(u) = \frac{d[F_U(u)]}{du} = \frac{1}{2}$在此范围内。
接下来，我们需要找到当$u \gt 1$时的$f_U(u)$。为此，我们需要找到积分：
$$F_U(u) = \int_0^1 \int_0^{y_1/u}{\frac{1}{(\theta_2 - \theta_1)^2}dy_2 dy_1} = \frac{1}{2u}$$
因为 $\theta_2 = 1$ 且 $\theta_1 = 0$。因此，对其进行微分，得到负结果 $f_U(u) = \frac{-1}{2u^2}$。这看起来是可以解释的，因为 $\frac{1}{1u}$ 是一条双曲线，在 $u \gt 1$ 上它递减 1，所以导数是负的，但根据密度函数的定义，它显然不能为负。
对此的答案是：
$$f_U(u) = \frac{1}{2}, 0 \le u \le 1$$
并且
$$f_U(u) = \frac{1}{2u^2}, u \gt 1$$
我不明白 $f_U(u)$ 是如何变成的积极的，请帮忙。]]></description>
      <guid>https://stats.stackexchange.com/questions/651024/exercise-on-finding-propability-density-function</guid>
      <pubDate>Sun, 14 Jul 2024 14:58:38 GMT</pubDate>
    </item>
    <item>
      <title>非对称分布在均值周围两侧的 PDF 下的面积是否可以相同？</title>
      <link>https://stats.stackexchange.com/questions/651022/can-a-non-symmetrical-distribution-have-the-same-areas-under-the-pdf-in-the-two</link>
      <description><![CDATA[我正在思考对称与非对称分布，我发现自己陷入了一个我从未想过的想法。我们知道，正态分布、拉普拉斯分布等对称分布在均值附近的曲线下面积相同（在对称情况下，均值等于中位数）。
但是，如果非对称分布（例如 GEV https://w.wiki/AfKx）尾部下的面积等于主瓣面积，那么非对称分布是否也可以具有此属性？
这种分布的参数可以通过分析找到吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651022/can-a-non-symmetrical-distribution-have-the-same-areas-under-the-pdf-in-the-two</guid>
      <pubDate>Sun, 14 Jul 2024 14:25:37 GMT</pubDate>
    </item>
    <item>
      <title>选择问答法学硕士 (LLM) 的评估模型</title>
      <link>https://stats.stackexchange.com/questions/651021/choosing-an-evaluation-model-for-llm-for-question-and-answering</link>
      <description><![CDATA[我正在学习 LLM 评估的基础知识，深度学习 AI 的一门短期课程中介绍的框架是生成问答样本作为基本事实。之后，需要评估的模型返回的预测将与基本事实进行比较。
根据课程中所做的，将要评估的模型也用于生成基本事实。这是正确的做法吗？因为我们使用相同的模型来生成正确答案，这不会导致评估结果出现偏差吗？
这个评估框架有什么价值？我们是否使用一些 SOTA 模型来生成基本事实以评估其他规模较小的 LLM？]]></description>
      <guid>https://stats.stackexchange.com/questions/651021/choosing-an-evaluation-model-for-llm-for-question-and-answering</guid>
      <pubDate>Sun, 14 Jul 2024 12:47:07 GMT</pubDate>
    </item>
    <item>
      <title>在 GAM 中将具有两个水平的因子设置为随机效应可以吗？[重复]</title>
      <link>https://stats.stackexchange.com/questions/651020/is-factor-with-two-levels-set-as-random-effect-okay-in-gams</link>
      <description><![CDATA[a. 协变量是具有 2 个级别的因素/类别，例如是/否或存在/不存在，并且每年都会改变空间位置，是否可以具有“re”的平滑基础（bs=re）？是否应该将其固定而不是没有平滑基础？
b. 将平滑基础设置为“cr”有什么好处？我之所以选择这个，是因为每年都有大量数据集。我知道如果数据不是明显的周期性，那么差别就不大。我将看看设置为 cr 的协变量在设置为 tp/默认选项时是否会发生很大变化，并了解到对于跨年的大型数据集，计算效率可能会很低。
进入 gam 的数据：
• 物种计数 = 丰度，每年沿河流长度计数数据
• 协变量 1 = 连续，在河流中每年都不同
• 协变量 2 = 计数数据（0-100+，沿河流长度每年都不同
• 协变量 3 = 因子/类别，存在或不存在（1=是，0=否），沿河流长度每年都不同
• 协变量 4 = 因子/类别，沿河流长度收集的五年数据（1-5）
Gam_run &lt;- gam(Species_count~ 
s(log10(Covariate1+1), bs=&quot;cr&quot;, k=7)+
s(Covariate2, bs=&quot;cr&quot;, k=6)+
s(Covariate3, bs=&quot;re&quot;, k=6)+
s(Covariate4, bs=&quot;re&quot;,k=6)+

data=dat,
family=nb(link = &quot;log&quot;),
method=&quot;ML&quot;, optimizer=&quot;efs&quot;, select=TRUE)
]]></description>
      <guid>https://stats.stackexchange.com/questions/651020/is-factor-with-two-levels-set-as-random-effect-okay-in-gams</guid>
      <pubDate>Sun, 14 Jul 2024 12:42:48 GMT</pubDate>
    </item>
    <item>
      <title>对大小为 61,000 的数据集执行完全匹配有哪些可能的解决方案？</title>
      <link>https://stats.stackexchange.com/questions/651017/what-are-the-possible-solutions-for-performing-full-matching-on-a-dataset-with-a</link>
      <description><![CDATA[我正在处理一个包含大约 61,000 个观测值的数据集（其中 27,686 个为治疗组，32,405 个为对照组），需要使用 R 中的 MatchIt 包执行完全匹配。我遇到了性能问题和冗长的计算时间。这是我得到的错误
`matchit()` 中的错误：！（来自 optmatch）结果将超过 2^31-1 字节。运行 `rlang::last_trace()` 以查看错误发生的位置。
在如此大的数据集上使用 MatchIt 执行完全匹配的潜在解决方案或最佳实践是什么？具体来说，我正在寻找优化匹配过程的方法或可以有效处理大型数据集的替代方法。
任何有关参数调整、并行处理或其他可以提高 MatchIt 中完全匹配性能的技术的建议都将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651017/what-are-the-possible-solutions-for-performing-full-matching-on-a-dataset-with-a</guid>
      <pubDate>Sun, 14 Jul 2024 11:27:16 GMT</pubDate>
    </item>
    <item>
      <title>当我感兴趣的是交互项（泊松分布或负二项式）时，我应该选择哪种分布？</title>
      <link>https://stats.stackexchange.com/questions/651016/which-distribution-should-i-choose-when-my-interest-is-the-the-interaction-term</link>
      <description><![CDATA[这是此问题的后续问题。结果变量右偏，方差明显高于平均值（方差 = 137，平均值 = 7.66）。此外，当我比较泊松和 NB 模型的结果以及两个模型之间的残差图时，似乎 NB 模型是一个不错的选择。但根据实际观察，泊松模型的结果更接近现实，我应该选择哪种分布？
第一个图是泊松模型的残差图。
第二张图是 NB 模型的残差图。
更新：我现在明白了均值和方差是有条件的。
以下是数据集的描述：响应变量是每个参与者的联系人数量。每个参与者在封锁之前和封锁期间记录他们的联系信息。我的研究主题是比较封锁之前和封锁期间联系号码的个体内差异。感兴趣的变量包括年龄、家庭规模、性别、原籍国、教育水平、就业状况、婚姻状况、交通方式、此联系是否在周末记录、地区和省份。
6.0% 的结果变量值为零。随机效应变量包括参与者ID和省份。

]]></description>
      <guid>https://stats.stackexchange.com/questions/651016/which-distribution-should-i-choose-when-my-interest-is-the-the-interaction-term</guid>
      <pubDate>Sun, 14 Jul 2024 10:58:48 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯逻辑回归：JASP 上的默认无信息先验选择</title>
      <link>https://stats.stackexchange.com/questions/651012/bayesian-logistic-regression-default-uninformative-priors-choice-on-jasp</link>
      <description><![CDATA[我目前正在尝试使用 JASP 执行贝叶斯逻辑回归。为此，我需要选择一个先验分布。JASP 提供以下选项：AIC、BIC、EB-local、g-prior、CCH、Beta-Prime、Intrinsic、Robust。
我想要一个默认的非信息性先验。JASP 自动选择 CCH 先验（alpha = 0.5、beta = 2、s = 0）。我是否应该得出结论，这是一个合适的默认先验？与 JASP 中的其他贝叶斯分析不同，我很难找到有关此事的明确文档。因此，我很难理解和证明这一选择。
此外，如果您对 JASP 中可用的先验有任何其他建议，我将不胜感激。
在我的分析中，我正在进行分层逻辑回归。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/651012/bayesian-logistic-regression-default-uninformative-priors-choice-on-jasp</guid>
      <pubDate>Sun, 14 Jul 2024 09:25:48 GMT</pubDate>
    </item>
    <item>
      <title>比较具有不同分散参数的模型时 AIC 的有效性</title>
      <link>https://stats.stackexchange.com/questions/651008/validity-of-aic-when-comparing-models-with-varying-dispersion-parameters</link>
      <description><![CDATA[
我目前正在制作一个带有 logit 链接的二项式模型，由于我允许它计算分散参数，因此该模型被参数化为准二项式。我想知道，由于模型结构的更改（添加/删除预测变量）会改变模型，从而改变分散参数，这是否会影响 AIC 在比较它们时的有效性？例如，假设我有一个包含 5 个参数的模型，然后我添加了第 6 个参数。分散参数现在已经改变，那么我可以使用 AIC 来决定它们之间的区别吗？


我认为我使用的程序计算缩放 AIC 的方式如下：$-2*\frac{\textrm{loglikelihood}(\theta)}{\phi}+2k$


我的讲师说，只要误差结构不变，就可以使用 AIC，但我的想法是，分散参数会改变误差的方差，从而改变误差的分布。那么，我可以使用 AIC 来制定关于我的模型的决策吗？还是我必须设置一个固定的缩放参数才能进行比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/651008/validity-of-aic-when-comparing-models-with-varying-dispersion-parameters</guid>
      <pubDate>Sun, 14 Jul 2024 06:25:16 GMT</pubDate>
    </item>
    <item>
      <title>在比较倾向匹配中使用的二元协变量的平衡时，使用 SMD 还是比例的原始差异？</title>
      <link>https://stats.stackexchange.com/questions/651015/use-smd-or-raw-difference-in-proportions-when-comparing-balance-of-binary-covari</link>
      <description><![CDATA[我是医学领域的一名大三学生，我的任务是使用 R 对一些数据进行倾向匹配分析。
我正在比较我的协变量的平衡（匹配前后），查看 cobalt 包的文档时，它说连续协变量将显示 SMD，而对于二元变量，则会自动计算比例的原始差异。
我知道我可以更改我要求它计算的内容，但是我需要一些指导，知道应该使用哪个？
查看发表在一些影响力较高的医学期刊上的倾向匹配论文，以及报告如何在医学文献中报告倾向得分和匹配的论文（例如 DOI：10.1002/sim.3697；doi：10.1136/bmjopen-2020-036961； doi.org/10.1016/j.jtcvs.2007.07.021；和 doi: 10.21037/atm.2018.12.10)，它们似乎都暗示 SMD 是计算出来的，而不是原始差异（或根本没有提到二元变量）。
查看医学文献/医学统计文献中记录的内容，我无法找到任何明确的指导，说明我应该使用 SMD 还是原始差异。
因此，到目前为止，我在计算中使用了 SMD]]></description>
      <guid>https://stats.stackexchange.com/questions/651015/use-smd-or-raw-difference-in-proportions-when-comparing-balance-of-binary-covari</guid>
      <pubDate>Sun, 14 Jul 2024 05:23:36 GMT</pubDate>
    </item>
    <item>
      <title>我可以将数据增强应用于测试集吗？</title>
      <link>https://stats.stackexchange.com/questions/650992/can-i-apply-data-augmentation-to-the-test-set</link>
      <description><![CDATA[我正在处理一个包含 102 行（表格数据）的数据集，其中 91 行用于训练，11 行用于测试。我通过为训练集添加高斯噪声来使用数据增强。假设我做了所有正确的预处理（没有数据泄露），那么科学出版物将数据增强应用于我的测试集是否正确/可以接受，因此它可以大于 11 行？]]></description>
      <guid>https://stats.stackexchange.com/questions/650992/can-i-apply-data-augmentation-to-the-test-set</guid>
      <pubDate>Sat, 13 Jul 2024 21:47:42 GMT</pubDate>
    </item>
    <item>
      <title>评估贝叶斯回归模型后验的黄金标准是什么？</title>
      <link>https://stats.stackexchange.com/questions/650988/what-is-the-gold-standard-for-evaluating-the-posterior-of-a-bayesian-regression</link>
      <description><![CDATA[让我解释一下我的意思和上下文：

我的意思是评估后验的正确性（例如对于近似贝叶斯推理方法）。
我最关心的是贝叶斯深度学习，我想要一种可以扩展到非常高维度的方法&amp;参数计数。。
有许多方法可用于分类（例如 Brier 评分），但我要求一些可与回归相媲美的方法。

一个有前途的想法是后验预测检查，但老实说，鉴于大多数贝叶斯模型输出样本而不是显式 pdf，我不确定如何以实用的方式实现它……
有什么想法吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650988/what-is-the-gold-standard-for-evaluating-the-posterior-of-a-bayesian-regression</guid>
      <pubDate>Sat, 13 Jul 2024 19:51:03 GMT</pubDate>
    </item>
    <item>
      <title>将两个水平的因子设置为随机效应可以吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650981/is-factor-with-two-levels-set-as-random-effect-okay</link>
      <description><![CDATA[a. 协变量是具有 2 个级别的因素/类别，例如是/否或存在/不存在，并且每年都会改变空间位置，是否可以具有“re”的平滑基础（bs=re）？是否应该将其固定而不是没有平滑基础？
b. 将平滑基础设置为“cr”有什么好处？我之所以选择这个，是因为每年都有大量数据集。我知道如果数据不是明显的周期性，那么差别就不大。我将看看设置为 cr 的协变量在设置为 tp/默认选项时是否会发生很大变化，并了解到对于跨年的大型数据集，计算效率可能会很低。
进入游戏的数据：

物种计数 = 丰度，沿河流长度计数数据
逐年
协变量 1 = 连续，在河流中每年不同
协变量 2 = 计数数据（0-100+，沿河流长度每年不同
协变量 3 = 因子/类别，存在
或不存在（1=是，0=否），沿河流长度每年不同
协变量 4 = 因子/类别，沿长度收集的五年数据（1-5）的河流


Gam_run &lt;- gam(Species_count~ 
s(log10(Covariate1+1), bs=&quot;cr&quot;, k=7)+
s(Covariate2, bs=&quot;cr&quot;, k=6)+
s(Covariate3, bs=&quot;re&quot;, k=6)+
s(Covariate4, bs=&quot;re&quot;,k=6)+

data=dat,
family=nb(link = &quot;log&quot;),
method=&quot;ML&quot;, optimizer=&quot;efs&quot;, select=TRUE)

非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650981/is-factor-with-two-levels-set-as-random-effect-okay</guid>
      <pubDate>Sat, 13 Jul 2024 17:52:17 GMT</pubDate>
    </item>
    <item>
      <title>对于拟泊松回归来说，多少分散才算太多？</title>
      <link>https://stats.stackexchange.com/questions/650973/how-much-dispersion-is-too-much-for-quasipoisson-regression</link>
      <description><![CDATA[拟泊松回归超越了标准泊松回归，考虑了过度离散（即因变量的方差远大于其均值）。本文对此进行了解释。
但是离散程度要达到什么程度才算太大，以至于应该排除使用拟泊松回归？
在此网站上一个获得高度点赞的答案中，即使方差是均值的 206 倍，也会使用拟泊松。这是声音吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650973/how-much-dispersion-is-too-much-for-quasipoisson-regression</guid>
      <pubDate>Sat, 13 Jul 2024 13:37:26 GMT</pubDate>
    </item>
    <item>
      <title>使用 CPAT 库检测 AR(1) 模型中的负变化的问题</title>
      <link>https://stats.stackexchange.com/questions/650959/issues-with-detecting-negative-change-in-ar1-model-using-cpat-library</link>
      <description><![CDATA[我目前正在评估 CUSUM、Rényi CUSUM 和 Erdős-Darling 检验在检测 AR(1) 模型中的变化点方面的经验功效，特别关注平均值的变化。下面是我用于此分析的代码片段：
library(CPAT)

Test=function(n, nb, beta, ro, alpha, g){
#### 初始化变量和向量
p = 20
X1 = numeric(n + 2 * p)
X2 = numeric(n + 2 * p)
D1 = numeric(n)

prob2 = logical(nb)
prob3 = logical(nb)
prob4 = logical(nb)

a = 1:p

# AR(1) 模型的模拟
for(k in 1:nb){
E = rnorm(n + 2 * p)

# 在变化点之前模拟 AR(1) 模型
X1[1] = rnorm(1)
for(i in 2:(g + p)){
X1[i] = ro * X1[i - 1] + E[i]
}

# 在变化点之后模拟 AR(1) 模型
X2[1] = rnorm(1)
for(i in 2:(n - g + p)){
X2[i] = (ro + beta / sqrt(n)) * X2[i - 1] + E[(g + p + i - 1)]
}

X = c(X1[-a], X2[-a])

# 计算模型残差
D1[1] = X[1] - ro * X1[p]
for(i in 2:n){
D1[i] = X[i] - ro * X[i - 1]
}

# 应用 CPAT 检验并评估功效
prob2[k] = (CUSUM.test(D1, use_kernel_var = FALSE, stat_plot = FALSE, kernel = &quot;ba&quot;, bandwidth = &quot;and&quot;)$p.value &lt; alpha)
prob3[k] = (HR.test(D1, kn = sqrt, use_kernel_var = FALSE, stat_plot = FALSE, kernel = &quot;ba&quot;, bandwidth = &quot;and&quot;)$p.value &lt; alpha)
prob4[k] = (CPAT::stat_de(X) &gt; CPAT::qdarling_erdos(1 - alpha))
}

# 计算模拟中的平均概率
Ls = list(mean(prob2), mean(prob3), mean(prob4))
return(Ls)
}

目前，我遇到一个问题，当 beta（平均值的变化）为负时，测试的功效明显低于指定的显着性水平 alpha。这似乎违反直觉。
我的问题：
我的代码中是否存在导致此问题的错误？
如何确保正确应用 CPAT 包中的函数，以准确确定这些测试在检测 AR(1) 模型中的负面变化方面的功效？]]></description>
      <guid>https://stats.stackexchange.com/questions/650959/issues-with-detecting-negative-change-in-ar1-model-using-cpat-library</guid>
      <pubDate>Sat, 13 Jul 2024 01:56:27 GMT</pubDate>
    </item>
    <item>
      <title>交叉熵和 MLE 之间的联系</title>
      <link>https://stats.stackexchange.com/questions/650884/link-between-cross-entropy-and-mle</link>
      <description><![CDATA[有许多材料显示了MLE 和交叉熵之间的关系。
通常，这些是显示 I.I.D 数据生成过程 $D = (X,Y)$ 的关系所采取的步骤：
$$
L(D) = \prod_{i=1}^N p(x_i, y_i; \theta)
$$
将可能性除以 num。样本$N$，并在两边取$\log$，因为这两个操作都不会影响最优模型参数估计$\theta^*$
$$
\frac{1}{N} \times \log(L(D)) = \frac{1}{N} \times \sum_{i=1}^N log(p(x_i, y_i; \theta))
$$
最后，这相当于经验分布和模型分布之间的交叉熵。
$$
\frac{1}{N} \times \sum_{i=1}^N log(p(x_i, y_i; \theta)) = \mathbb{E}_{p_{data}}[log(p_{model}(x,y;\theta))]
$$
我有几个问题：

如果数据生成过程不是 I.I.D 会怎样？这种关系还成立吗？

为什么这种关系很特殊，它如何帮助参数估计？鉴于 MLE 和交叉熵都给出了完全相同的最佳模型参数 $\theta^*$。

]]></description>
      <guid>https://stats.stackexchange.com/questions/650884/link-between-cross-entropy-and-mle</guid>
      <pubDate>Thu, 11 Jul 2024 15:13:46 GMT</pubDate>
    </item>
    </channel>
</rss>