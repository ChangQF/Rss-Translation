<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 16 Nov 2024 01:18:20 GMT</lastBuildDate>
    <item>
      <title>为什么机器学习不会遭受维数灾难？</title>
      <link>https://stats.stackexchange.com/questions/657344/why-doesnt-ml-suffer-from-curse-of-dimensionality</link>
      <description><![CDATA[免责声明：我三天前在 Data Science Stack Exchange 上问过这个问题，但至今没有得到回复。也许这不是正确的网站。我希望在这里得到更多积极的参与。
这个问题困扰了我很久。我是一名训练有素的统计学家，我知道有些事情在高维度上是无法做到的（或者至少你不会得到你想要的，但你可能会得到其他东西）。
有维数灾难的概念。例如，密度估计在高维度上非常慢，因为核密度估计的收敛速度是 $𝑛^{−2/(2+𝑑)}$
。显然，当 𝑑→∞
时，这个速率基本上表现得像一个常数，因此在高维度上进行密度估计基本上是不可能的。但我们经常看到在高维度中使用扩散模型和其他方法。我在这里并不是真正谈论理论；相反，它们用于稳定扩散、Dall-E 等，效果很好！
然后是高维分类中的可分离性概念。逻辑回归通常用作许多神经网络的顶层。随着数据维数的增加，类别变得越来越分离。因此，分类在高维中几乎是微不足道的。但这也意味着逻辑 MLE 不存在，因为可以有无限多个分类器。所以，我们得到了一个分类器，但我们得到了我们想要的吗？
传统知识提供的内容与 ML 所实现的内容之间似乎存在差异。我的问题是关于这种差异的。传统理论家错过了什么？有明显的陷阱，但不知何故 ML 似乎并没有陷入其中。我们得到的是不是我们真正想要的东西，而只是因为最终产品“看起来”很好，我们认为这就是我们一直想要的？
有人知道可能的原因是什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657344/why-doesnt-ml-suffer-from-curse-of-dimensionality</guid>
      <pubDate>Sat, 16 Nov 2024 00:56:40 GMT</pubDate>
    </item>
    <item>
      <title>小样本量最佳统计方法的建议</title>
      <link>https://stats.stackexchange.com/questions/657339/advice-for-best-statistical-methods-on-small-sample-size</link>
      <description><![CDATA[我想做一项回顾性图表审查研究，研究出院后意外停药率。研究规模只有 70 人，我想比较停药率与性别、年龄、心力衰竭、糖尿病、痴呆症、制剂类型（是否为复方药片）的关系。最好的统计方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657339/advice-for-best-statistical-methods-on-small-sample-size</guid>
      <pubDate>Fri, 15 Nov 2024 23:42:24 GMT</pubDate>
    </item>
    <item>
      <title>缩小比例影像的验证</title>
      <link>https://stats.stackexchange.com/questions/657338/validation-of-downscaled-imagery</link>
      <description><![CDATA[如果该帖子不适合本网站，我提前表示歉意。如果是这样，那么请随意推荐其他相关网站，我会关闭这个问题。
想象一个传感器（我们称之为传感器 A），它可以从两个视角捕获图像，近天底（NN）和离天底（ON）。任务是缩小（DS）图像。假设，为了进行验证，有另一个传感器（传感器 B）可以捕获与传感器 A 相同波长的图像。传感器 B 的图像在时间分辨率方面并不规则，它可以从不同的视角（VA）获取特定区域的图像。在传感器 B 图像的元数据中，未提及 VA。
您将如何使用传感器 B 完成验证来自传感器 A 的 DS 图像的任务？我想说的是，“传统”验证测试（即 r 平方或 RMSE）可能不合适，因为（至少对我来说）这就像比较苹果和橘子。我的意思是，如果我要将 NN VA 的 DS 图像与传感器 B 的图像进行比较，并且后者的图像是从 NN 位置拍摄的，那么与 ON 和传感器 B 相比，r 平方会更高是有道理的。
您有什么建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/657338/validation-of-downscaled-imagery</guid>
      <pubDate>Fri, 15 Nov 2024 23:37:03 GMT</pubDate>
    </item>
    <item>
      <title>协变量平衡爱情情节和距离</title>
      <link>https://stats.stackexchange.com/questions/657337/covariate-balance-loveplot-and-distance</link>
      <description><![CDATA[love.plot 上绘制的距离参数是什么？我无法在 cobalt 包中找到任何参考或解释。任何有助于理解此值“距离”的信息都会有所帮助。谢谢。
library(MatchThem)

data(&quot;osteoarthritis&quot;)

library(mice)
imputed.datasets &lt;- mice(osteoarthritis, m = 5)

table(imputed.datasets$data$OSP)

table(imputed.datasets$data$KOA)

matched.datasets &lt;- matchthem(OSP ~ AGE + SEX + BMI + RAC + SMK,
datasets = imputed.datasets,
approach = &#39;within&#39;,
method = &#39;nearest&#39;,
caliper = 0.05,
ratio = 2)

]]></description>
      <guid>https://stats.stackexchange.com/questions/657337/covariate-balance-loveplot-and-distance</guid>
      <pubDate>Fri, 15 Nov 2024 22:06:49 GMT</pubDate>
    </item>
    <item>
      <title>根据另一个统计模型创建非同质队列？</title>
      <link>https://stats.stackexchange.com/questions/657336/creating-a-non-homogenous-queue-based-on-another-statistical-model</link>
      <description><![CDATA[我有一个问题，关于如何根据变化的参数构建/近似统计队列。
我在 R 中创建/模拟了 MMK 队列的这个近似版本：
library(tidyverse)

k &lt;- 3 # 服务器数量
lambda &lt;- 2 # 到达率
mu &lt;- 1 # 每台服务器的服务率
T &lt;- 100 # 模拟时间
n_sims &lt;- 20 # 模拟次数
dt &lt;- 0.05 # 时间步长
initial_n &lt;- 100 # 初始队列长度

simulate_mmk &lt;- function(sim_number) {
n_steps &lt;- ceiling(T/dt)
queue_length &lt;- numeric(n_steps)
queue_length[1] &lt;- initial_n

到达 &lt;- rpois(n_steps, lambda * dt)
出发 &lt;- rpois(n_steps, k * mu * dt)

for(i in 2:n_steps) {
current_n &lt;- 队列长度[i-1]
到达 &lt;- 到达[i]
出发 &lt;- min(departures[i], current_n)
队列长度[i] &lt;- current_n + 到达 - 出发
}

data.frame(
time = seq(0, T-dt, length.out=n_steps),
队列长度 = 队列长度,
模拟 = 因子(sim_number)
)
}

set.seed(123)
sim_data &lt;- bind_rows(
lapply(1:n_sims, function(i) {
set.seed(123 + i)
模拟_mmk(i)
})
)


我有兴趣调整这个队列，以允许改变到达、离开和服务器的数量。
例如，在上面的模拟中，服务器的数量保持不变，到达和离开是从具有固定参数的概率分布中随机选择的。我想制作一些可以随时间变化的分布。
例如，假设到达、离开和服务器随时间变化（例如，分段，时间值变化的概率分布）。
我是否可以预先根据这些变化的分布生成到达、离开和服务器的向量（例如，将回归模型拟合到历史到达、离开和服务器数据），然后从这些模型中模拟随机数据以创建非同质队列？
run_sims &lt;- function(n_sims = 20, T = 100, dt = 0.05, initial_n = 100) {

n​​_steps &lt;- ceiling(T/dt)

set.seed(123)
attendances &lt;- abs(rnorm(n_steps, mean = 25, sd = 2))
service_rates &lt;- abs(rnorm(n_steps, 平均值 = 15, sd = 1))
服务器 &lt;- abs(rnorm(n_steps, 平均值 = 5, sd = 0.5))

sim_data &lt;- map_dfr(1:n_sims, function(i) {
set.seed(123 + i)

队列长度 &lt;- numeric(n_steps)
队列长度[1] &lt;- initial_n

for(i in 2:n_steps) {
current_n &lt;- 队列长度[i-1]
到达 &lt;- rpois(1, 到达[i] * dt)
出发 &lt;- min(rpois(1, 服务器[i] * 服务费率[i] * dt), current_n)
队列长度[i] &lt;- current_n + 到达 - 出发
}

data.frame(
时间= seq(0, T-dt, length.out=n_steps),
queue_length =queue_length,
simulation =factor(i)
)
})
return(sim_data)
}

sim_data &lt;-run_sims(
n_sims = 20,
T = 100,
dt = 0.05,
initial_n = 100
)



澄清：

首先，我将拟合 3 个不同的模型（例如GAM/时间序列）到历史到达、离开和服务器数据
然后，我将根据这 3 个模型在一段时间内预测未来值
然后，在这个范围的每个时间点 - 我将根据以这 3 个模型产生的每个预测值为中心的概率分布（例如指数、泊松）模拟到达、离开和服务器数量
重复
]]></description>
      <guid>https://stats.stackexchange.com/questions/657336/creating-a-non-homogenous-queue-based-on-another-statistical-model</guid>
      <pubDate>Fri, 15 Nov 2024 21:32:48 GMT</pubDate>
    </item>
    <item>
      <title>R 如何使用包含 0 和 1 值的 lmer 和 glmmTMB 最好地模拟连续双峰生存数据</title>
      <link>https://stats.stackexchange.com/questions/657335/r-how-best-to-model-continuous-bimodal-survival-data-using-lmer-and-glmmtmb-that</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657335/r-how-best-to-model-continuous-bimodal-survival-data-using-lmer-and-glmmtmb-that</guid>
      <pubDate>Fri, 15 Nov 2024 21:22:44 GMT</pubDate>
    </item>
    <item>
      <title>处理不同群体规模的偏差</title>
      <link>https://stats.stackexchange.com/questions/657329/handling-bias-with-varying-group-sizes</link>
      <description><![CDATA[在我们的研究中，我们观察到仓鼠在接触熟悉或不熟悉的个体时表现出攻击性。我们担心，在治疗中，陌生个体 (2) 比熟悉个体 (1) 数量多可能会引起偏见，这可能导致对陌生个体的攻击性更强，仅仅因为陌生个体数量更多。
我们通过使用个体层面的数据（每只仓鼠对其他仓鼠的攻击次数）来解决这个问题，而不是按组汇总攻击。此外，我们在模型中将个体 ID 作为随机效应纳入，以解释仓鼠之间攻击性水平的固有差异。
我们如何确信我们的结果（攻击性主要针对陌生的仓鼠）不仅仅是陌生个体数量较多的结果，而是反映了真实的行为模式？我们的方法是否有效地减轻了实验中熟悉和不熟悉的个体数量不同所带来的偏见？
模型：
该模型的因变量是每只仓鼠在每次试验中对其他仓鼠的攻击性互动次数。我们纳入了攻击者攻击熟悉还是不熟悉的仓鼠（熟悉度）的固定因素。仓鼠 ID 和试验 ID 包括随机效应。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657329/handling-bias-with-varying-group-sizes</guid>
      <pubDate>Fri, 15 Nov 2024 19:12:57 GMT</pubDate>
    </item>
    <item>
      <title>使用矩法估计 θ，使用变换 g(θ)=ln x</title>
      <link>https://stats.stackexchange.com/questions/657326/estimator-of-%ce%b8-using-the-method-of-moments-using-transformation-g%ce%b8-ln-x</link>
      <description><![CDATA[问题：
我们有一个连续随机变量 𝑋，其概率密度函数 (pdf) 为：
$$f(x) = \begin{cases}\theta/(x^\theta)+1, &amp; x &gt; 1, \theta&gt; 0\\ 0, &amp;\textrm{otherwise}\end{cases}.$$
使用变换的矩量法找到 θ 的估计量，$g(\theta) = \ln x$。
方法：
我首先尝试使用一般程序，该程序涉及计算 X 的期望，而不考虑变换，但找不到任何解决方案。
我在这里发布这个问题，希望有人可以指导我如何解决这个问题。如果有人可以澄清使用变换是否是解决问题的关键，那将非常有帮助，如果是这样，任何关于如何使用它的见解都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657326/estimator-of-%ce%b8-using-the-method-of-moments-using-transformation-g%ce%b8-ln-x</guid>
      <pubDate>Fri, 15 Nov 2024 18:33:41 GMT</pubDate>
    </item>
    <item>
      <title>威尔科克森符号秩检验总是发现随机生成的比率不同于 1？</title>
      <link>https://stats.stackexchange.com/questions/657325/wilcoxon-signed-rank-test-always-finding-randomly-generated-ratios-to-be-differe</link>
      <description><![CDATA[我需要测试实验中的一组比率（根据成对样本的条件 1/条件 2 计算）是否与一个比率有显著差异。实验中的所有测量值都是正实数，因此我认为 1 附近的分布更符合对数正态性，因此 t 检验不合适。我的第一个想法是使用 Wilcoxon 符号秩检验（如 scipy.stats.wilcoxon 中实现的）。我想先用建模数据测试它，看看这样做是否合理，但我不明白结果。我正在使用下面的代码来测试它。
import numpy as np
from scipy.stats import wilcoxon, ttest_1samp

n_iters = int(1e4)
n_samps = int(100)
n_sig = 0
for iter in range(n_iters):
s0 = np.random.rand(n_samps)
s1 = np.random.rand(n_samps)
ratio = s0/s1
p = wilcoxon(ratio-1, alternative=&#39;greater&#39;).pvalue
# p = ttest_1samp(np.log(ratio), 0, alternative=&#39;greater&#39;).pvalue
if p &lt; 0.05：
n_sig += 1
print(n_sig/n_iters*100)

按原样运行此代码，大约一半的比率是“显著的”。随着 n_samps（每次迭代抽取的样本数量）的增加，显著的比率数量增加到 100%。考虑到我选择的 p 阈值，我预计大约 5% 的比率是显著的。如果我将 p 值计算为 p = ttest_1samp(np.log(ratio), 0, alternative=&#39;greater&#39;).pvalue（当前已注释掉），无论 n_samps 的值是多少，我总是得到 ~5% 的测试是显著的。
我误解了 Wilcoxon 检验吗？我以为它是专门用于基础分布不正常的情况。请注意，随机样本 s0 和 s1 都是使用同一函数生成的，该函数取自区间 [0, 1) 上的均匀分布，因此虽然中位数为 1，但我认为分布更符合对数正态性。]]></description>
      <guid>https://stats.stackexchange.com/questions/657325/wilcoxon-signed-rank-test-always-finding-randomly-generated-ratios-to-be-differe</guid>
      <pubDate>Fri, 15 Nov 2024 18:14:17 GMT</pubDate>
    </item>
    <item>
      <title>如果 alpha = 0.05 时 p 值为 0.0503，我们是否拒绝原假设？如果有的话，用什么方法可以验证拒绝？</title>
      <link>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</link>
      <description><![CDATA[我知道它大于 0.05，但我只是想知道，因为将其四舍五入到小数点后两位会得到 0.05。我只是想确保我没有错误地接受零假设。有没有办法说，即使这个值接近 alpha，也有足够的证据拒绝零假设？
另外，我知道我不应该这样做，但在进行事后分析后，我得到了不同治疗之间的均值结果。
感谢那些花时间回答的人！]]></description>
      <guid>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</guid>
      <pubDate>Fri, 15 Nov 2024 17:58:11 GMT</pubDate>
    </item>
    <item>
      <title>REML 与 ML 的比较</title>
      <link>https://stats.stackexchange.com/questions/657323/comparisions-between-reml-and-ml</link>
      <description><![CDATA[我有两个问题，非常感谢您的回答。
如果最大似然 (ML) 和限制最大似然 (REML) 方法在模型中具有相同的固定效应，那么这两种方法的结果是否具有可比性？
当 ML 和 REML 以相同的固定效应应用时，它们是否会产生相同的固定效应估计方差？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657323/comparisions-between-reml-and-ml</guid>
      <pubDate>Fri, 15 Nov 2024 17:44:11 GMT</pubDate>
    </item>
    <item>
      <title>就状态值函数而言的动作值函数</title>
      <link>https://stats.stackexchange.com/questions/657309/action-value-function-in-terms-of-state-value-function</link>
      <description><![CDATA[我正在读 Sutton&amp;Barto 的书。我在练习 3.13 处卡住了。问题是根据 vπ 和 p(s′,r∣s,a) 写出 qπ。我追踪了以下步骤：
$q_\pi(s,a) = \sum_g g \text{ Pr}\{G_t=g|S_t=s, A_t=a\}$
$= \sum_g g \sum_{s&#39;} \text{ Pr}\{G_t=g, S_{t+1}=s&#39;|S_t=s, A_t=a\}$
$= \sum_g g \sum_{s&#39;} \text{ Pr}\{G_t=g|S_{t+1}=s&#39;, S_t=s, A_t=a\} \text{ Pr}\{S_{t+1}=s&#39;|S_t=s, A_t=a\}$
$= \sum_{s&#39;} \text{ Pr}\{S_{t+1}=s&#39;|S_t=s, A_t=a\} \sum_g g \text{ Pr}\{G_t=g|S_{t+1}=s&#39;, S_t=s, A_t=a\}$
我该如何继续，或者我的逻辑是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/657309/action-value-function-in-terms-of-state-value-function</guid>
      <pubDate>Fri, 15 Nov 2024 11:40:51 GMT</pubDate>
    </item>
    <item>
      <title>在 Kruskal-Wallis 之后，通过使用 Wilcoxon 进一步比较各组来获取更多信息？（当无法进行双向方差分析时）</title>
      <link>https://stats.stackexchange.com/questions/657307/gaining-additional-information-after-kruskal-wallis-by-further-comparing-groups</link>
      <description><![CDATA[我有以下实验设置，数字是六组中的个体：



场景
治疗 1
治疗 2
治疗 3




A
28
27
27


B
28
28
28



已经测量过一次的是基于两种治疗方法的小鼠移动距离不同场景。所有个体都是独一无二的，在各组之间不会重复。
研究问题是三种治疗方法在移动距离上是否会有所不同。为了增加另一层，我们在两种不同的场景中对其进行了测试，以查看这是否对治疗方法有影响。
不幸的是，我们无法进行双向方差分析来测试交互作用。相反，我们针对每种情况分别进行了 Kruskal-Wallis (KW)，然后如果显著则进行 Dunn 的事后检验。

问题 1。在 A 和 B 中的治疗 1 之间进行 Wilcoxon 检验，然后在 A 和 B 中的治疗 2 之间进行另一次 Wilcoxon 检验，最后在 A 和 B 中的治疗 3 之间进行一次 Wilcoxon 检验，这在统计上合理吗？
问题 2。同样，在场景 A 和 B 之间进行 Wilcoxon 检验听起来是否合理？

我的理由是，对于 Q1，我将根据场景查看治疗之间是否存在差异。但与此同时，我知道这不是双向方差分析相互作用效应的适当替代品。如果我发现治疗 1 在 A 和 B 之间存在显著性，但其余治疗没有显著性，那么解释起来会很困难。因此，我认为 Q2 会更合理，因为它至少可以表明这两个场景作为一个整体是否有影响。
我知道 p-hacking，这是我希望避免的事情。但如果可以从实验中获得更多信息，那就太好了，这就是我希望得到答案的原因！此外，如果其中任何一个可行，我需要考虑哪些调整？]]></description>
      <guid>https://stats.stackexchange.com/questions/657307/gaining-additional-information-after-kruskal-wallis-by-further-comparing-groups</guid>
      <pubDate>Fri, 15 Nov 2024 10:51:11 GMT</pubDate>
    </item>
    <item>
      <title>当方差估计量不是样本方差时的 T 检验</title>
      <link>https://stats.stackexchange.com/questions/657305/t-test-when-variance-estimator-is-not-sample-variance</link>
      <description><![CDATA[众所周知，如果 $x \sim \mathcal{N}(0, \sigma^2)$，并且我们有一个 $n$ 个 $x$ 观测样本，则 $\frac{x}{\hat{\sigma}}$ 的分布（其中 $\hat{\sigma}$ 是样本方差）将遵循具有 $n-1$ 自由度的 Studnent-t 定律。
但是，如果 $\sigma$ 的 ML 估计量在功能上受到惩罚，即 $\sigma = f(\theta)$，而 $\sigma$ 的估计量 $\hat{\sigma}(\theta)$ 只能通过 $\theta$ 的 MLE 以数值方式获得？在这种情况下，我们能对 $\frac{x}{\hat{\sigma}(\theta)}$ 的分布说些什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657305/t-test-when-variance-estimator-is-not-sample-variance</guid>
      <pubDate>Fri, 15 Nov 2024 10:29:48 GMT</pubDate>
    </item>
    <item>
      <title>（更完整）证明 Fisher 信息是可加的</title>
      <link>https://stats.stackexchange.com/questions/657303/more-complete-proof-the-fisher-information-is-additive</link>
      <description><![CDATA[对于独立、同分布的变量，众所周知，Fisher 信息是可加的，即
\begin{align}
\mathcal{I}_n(\theta)&amp;=\left&lt;{\left({\frac{\partial}{\partial\theta}\log f(X_1, X_2, \dots, X_n)}\right)^2}\right&gt;\\
&amp;=n\left&lt;{\left({\frac{\partial}{\partial\theta}\log f(X_1)}\right)^2}\right&gt;\\
&amp;=n\mathcal{I}_1(\theta).
\end{align&gt;
这些行不是证明，而是一个陈述。当我尝试解决这个问题时，我知道我应该使用变量是独立的，但我不知道如何做。如果我针对两个变量尝试此方法，则会得到如下结果：
\begin{align}
\left&lt;\left(\frac{\partial}{\partial\theta}\log f(X_1, X_2)\right)^2\right&gt;=&amp;\left&lt;\left(\frac{\partial}{\partial\theta}\log f(X_1)f( X_2)\right)^2\right&gt;\\
=&amp;\left&lt;\left(\frac{\partial}{\partial\theta}\log f(X_1)+\log f(X_2)\right)^2\right&gt;\\
=&amp;\mathcal I_1(\theta)+\mathcal I_2(\theta)+2\left&lt;\left(\frac{\partial}{\partial\theta}\log f(X_1)\right)\left(\frac{\partial}{\partial\theta}\log f(X_2)\right)\right&gt;
\end{align
因此最后一项应为零。如果该项分解为因子，
$$\left&lt;\left(\frac{\partial}{\partial\theta}\log f(X_1)\right)\left(\frac{\partial}{\partial\theta}\log f(X_2)\right)\right&gt;\overset{?}{=}
\left&lt;\frac{\partial}{\partial\theta}\log f(X_1)\right&gt;\left&lt;\frac{\partial}{\partial\theta}\log f(X_2)\right&gt;,
$$
我们完成了，因为我们在真实参数值处进行评估，并且分数的方差为零。但是我们如何知道这是真的？因为变量是独立的，我们只知道$\left&lt;X_1X_2\right&gt;=\left&lt;X_1\right&gt;\left&lt;X_2\right&gt;$。]]></description>
      <guid>https://stats.stackexchange.com/questions/657303/more-complete-proof-the-fisher-information-is-additive</guid>
      <pubDate>Fri, 15 Nov 2024 10:04:51 GMT</pubDate>
    </item>
    </channel>
</rss>