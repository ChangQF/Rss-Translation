<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 21 Jan 2024 12:24:14 GMT</lastBuildDate>
    <item>
      <title>分类报告中f1-score下的准确度值</title>
      <link>https://stats.stackexchange.com/questions/637380/accuracy-value-under-f1-score-in-classification-report</link>
      <description><![CDATA[考虑一下
y_true = [0, 1, 2, 2, 2]
y_pred = [0, 0, 2, 2, 1]
从 sklearn.metrics 导入分类报告
打印（分类报告（y_true，y_pred））

打印内容
 精确召回率 f1-score 支持

           0 0.50 1.00 0.67 1
           1 0.00 0.00 0.00 1
           2 1.00 0.67 0.80 3

    准确度 0.60 5
   宏观平均 0.50 0.56 0.49 5
加权平均 0.70 0.60 0.61 5

据我了解，准确度值不是特定于类的指标，而是一个全局指标，在所有类中计算，因此没有自己的精度、&lt;代码&gt;调用或&lt;代码&gt;支持。是否有任何特定原因导致它显示在f1-score列下，而不是在 precision第一列下？我还尝试向 classification_report 提供 output_dict = True 参数，它也只有一个 accuracy 键值。
classification_report（y_true，y_pred，output_dict = True）

打印内容
{&#39;0&#39;: {&#39;精度&#39;: 0.5,
  “回忆”：1.0，
  &#39;f1 分数&#39;: 0.66666666666666666,
  “支持”：1.0}，
 &#39;1&#39;: {&#39;精度&#39;: 0.0, &#39;召回率&#39;: 0.0, &#39;f1-score&#39;: 0.0, &#39;支持率&#39;: 1.0},
 &#39;2&#39;: {&#39;精度&#39;: 1.0,
  “回忆”：0.66666666666666666，
  “f1 分数”：0.8，
  “支持”：3.0}，
 “准确度”：0.6，
 &#39;宏平均值&#39;：{&#39;精度&#39;：0.5，
  “回忆”：0.5555555555555555，
  &#39;f1-分数&#39;：0.48888888888888893，
  “支持”：5.0}，
 &#39;加权平均值&#39;：{&#39;精度&#39;：0.7，
  “回忆”：0.6，
  &#39;f1-分数&#39;: 0.6133333333333334,
  “支持”：5.0}}

这只会让我认为 accuracy 行中的 support 值以及 accuracy 在报告字符串格式中的位置可能是巧合。是否有我遗漏的任何关系，或者这只是报告的打印方式？]]></description>
      <guid>https://stats.stackexchange.com/questions/637380/accuracy-value-under-f1-score-in-classification-report</guid>
      <pubDate>Sun, 21 Jan 2024 12:12:45 GMT</pubDate>
    </item>
    <item>
      <title>从 AdaBoost 返回不良异常值的目的是什么？</title>
      <link>https://stats.stackexchange.com/questions/637376/whats-the-purpose-by-returning-back-the-bad-outliers-from-adaboost</link>
      <description><![CDATA[假设您有一个包含数字和二进制数据的矩阵 $X$。您将数据 $X$ 插入 AdaBoost，AdaBoost 通过仅关注无法进行正确分类的行。
所以矩阵 $X$ 最终将包含属于异常值的行，对吧？
示例：
如果我在 $X$ 中有 10 行，并且其中只有两行分类不好，因为它们是“异常值”。我的 $X$ 最终会得到很多这两行，因为 AdaBoost 会大大增加它们的权重，因为它们的分类不好。
如果它们的权重较大，则重新训练行的概率高于正确分类行的概率。]]></description>
      <guid>https://stats.stackexchange.com/questions/637376/whats-the-purpose-by-returning-back-the-bad-outliers-from-adaboost</guid>
      <pubDate>Sun, 21 Jan 2024 10:25:04 GMT</pubDate>
    </item>
    <item>
      <title>R中summary()和anova()结果的解释[重复]</title>
      <link>https://stats.stackexchange.com/questions/637375/interpretation-of-summary-and-anova-results-in-r</link>
      <description><![CDATA[我在理解 anova() 函数和summary() 函数的使用差异时遇到一些困难。对于上下文，这是我正在研究的内容：
我正在使用 GLMM：
glmm_dogs2 &lt;- lmer(Den.Weeks ~ 人类 * 捕食者 + (1|packseasid)，数据 = 狗)
glmm_dogs3 &lt;- lmer(Den.Distance ~ 人类 * 捕食者 + (1|packseasid), data = dogs)
glmm_dogs4 &lt;- lmer(Pups.lost ~ 人类 + 捕食者 + Den.Distance + (1|packseasid), data = dogs)
我自己所依据的代码继续绘制残差并测试残差的正态性，然后使用 Anova(glmm_dogs2) 和 summary( glmm_dogs2)。然后我得到以下输出：
&lt;前&gt;&lt;代码&gt;方差分析(glmm_dogs2)
偏差表分析（II 型 Wald 卡方检验）
回复：Den.Weeks
              Chisq Df Pr(&gt;Chisq)
人类 2.1423 1 0.14329
捕食者 5.5678 1 0.01829 *
人类：掠食者 5.0390 1 0.02478 *
-------------
摘要（glmm_dogs2）
REML 拟合线性混合模型。 t 检验的使用
  萨特思韦特方法 [lmerModLmerTest]
公式：
Den.Weeks ~ 人类 * 掠夺者 + (1 | packseasid)
   数据：狗

REML 收敛准则：98.4

 缩放残差：
最小 1Q 中值 3Q 最大
-1.5586 -0.4267 -0.0769 0.6049 1.6837

随机效果：
 组名称方差标准差
 packseasid（拦截）1.015 1.008
 剩余 2.012 1.419
obs 数量：28，组：packseasid、11

固定效果：
               估计标准。误差df t值Pr(&gt;|t|)
（截距）9.9312 0.4444 14.2747 22.347 1.64e-12 ***
人类1 -2.3783 0.9541 20.1319 -2.493 0.02151 *
捕食者1 -3.6509 1.1213 18.7048 -3.256 0.00422 **
人类1：掠食者1 3.9813 1.7736 21.8223 2.245 0.03526 *
---
西尼夫。代码：
0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应的相关性：
    (Intr) Humns1 Prdtr1
人类1 -0.255
捕食者1 -0.179 0.126
Hmns1:Prdt1 0.099 -0.579 -0.673

现在我有 Chisq 和 Pr(&gt;Chisq) 值，并且有 t 和 Pr(&gt;|t|) 值。根据Anova()，人类：捕食者之间的相互作用是显着的，掠夺者是显着的，而根据summary()，包括相互作用在内的所有术语都是显着的。
[旁注：我已经使用了dredge(global_glmm)函数来压缩AIC，所以我的模型已经被简化了，这个问题主要涉及我应该如何报告我的结果以及哪些变量我可以认为彼此之间有显着的相关性。]
我确实读到 Anova() 执行 II 型测试，summary() 执行 III 型测试，所以如果我理解正确，这意味着在这种情况下我应该使用 summary() 输出，因为人类：掠食者之间的重要相互作用。但是，如果summary()函数没有给我带来显着的结果，我应该使用Anova()结果吗？还是我误解了这一点？
仅供参考，下面是我构建的其他 GLMM 之一的结果，其中没有显着的交互作用；在这种情况下，我将在报告中使用 Anova() 结果，因为 summary() 没有显示任何显着的交互作用？
&lt;前&gt;&lt;代码&gt;方差分析(glmm_dogs3)
偏差表分析（II 型 Wald 卡方检验）
响应：密度距离
          Chisq Df Pr(&gt;Chisq)
人类 3.4109 1 0.06477 。
捕食者 0.0976 1 0.75467
人类：掠食者 1.3987 1 0.23694
---
西尼夫。代码：
0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

&gt;摘要（glmm_dogs3）
REML 拟合线性混合模型。 t 检验的使用
萨特思韦特方法 [lmerModLmerTest]
公式：
Den.Distance ~ 人类 * 掠食者 + (1 | packseasid)
  数据：狗

REML 收敛准则：108.9

缩放残差：
 最小 1Q 中值 3Q 最大
-1.28514 -0.50117 -0.01259 0.56893 2.10258

随机效果：
 组名称方差标准差
 packseasid（拦截）2.554 1.598
 剩余 2.652 1.628
obs 数量：28，组：packseasid、11

固定效果：
                  估计标准。误差df t值Pr(&gt;|t|)
（截距）2.1269 0.6105 11.2745 3.484 0.00494 **
人类1 0.9035 1.1232 17.1159 0.804 0.43221
捕食者1 -0.7322 1.3067 15.6333 -0.560 0.58319
人类1：掠食者1 2.4991 2.1131 18.7481 1.183 0.25172
---
西尼夫。代码：
0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应的相关性：
    (Intr) Humns1 Prdtr1
人类1 -0.211
捕食者1 -0.143 0.132
Hmns1:Prdt1 0.071 -0.586 -0.670
]]></description>
      <guid>https://stats.stackexchange.com/questions/637375/interpretation-of-summary-and-anova-results-in-r</guid>
      <pubDate>Sun, 21 Jan 2024 10:10:57 GMT</pubDate>
    </item>
    <item>
      <title>对线性回归的疑问</title>
      <link>https://stats.stackexchange.com/questions/637373/doubt-regarding-linear-regression</link>
      <description><![CDATA[我读过并被告知，如果在线性回归问题中，回归方程 Y= mX +N + E 中的误差 E 归因于 Y 是随机变量。如果 Y 不是随机变量且具有确定性，则点 (X,Y) 将位于回归线上。
我不明白的是，即使 Y 不是随机的，通过多对 (X,Y) 拟合一条直线不会导致某些点位于回归线上方或下方吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637373/doubt-regarding-linear-regression</guid>
      <pubDate>Sun, 21 Jan 2024 09:38:47 GMT</pubDate>
    </item>
    <item>
      <title>比较组时平均比例差异的统计显着性</title>
      <link>https://stats.stackexchange.com/questions/637372/statistical-significance-for-difference-in-mean-proportions-when-comparing-group</link>
      <description><![CDATA[我可能没有准确地描述我的问题，但我希望我能用下面的例子来说明它。
假设我有 $m$ 列联表：

&lt;表类=“s-表”&gt;
&lt;标题&gt;


第 1 列
第 2 列
总计


&lt;正文&gt;

第 1 行
$a_i$
$b_i$
$a_i+b_i$


第 2 行
$c_i$
$d_i$
$c_i+d_i$


总计
$a_i+c_i$
$b_i+d_i$
$N$




其中$a_i+b_i+c_i+d_i=N,i=1,2,\dots,m$。对于每个表，令 $p_{1i}=\frac{a_i+b_i}{N}, p_{2i}=\frac{a_i+c_i}{N}$，$p_{1i}-p_{2i}$ 的标准误差由下式给出
$$se(p_{1i}-p_{2i})=\frac{1}{N}\sqrt{b_i+c_i-\frac{(b_i-c_i)^2 {N}}.$$
自从
$$
Var\left({{p_{1i}}-p_{2i}}\right)={Var(p_{1i})+Var(p_{2i})}- {2Cov(p_{1i},p_{2j) })}=\frac{1}{N^2}\left(b_i+c_i-\frac{(b_i-c_i)^2}{N}\right)。
$$
然后我可以对原假设 $p_{1i}=p_{2i}$ 进行显着性检验，假设原假设为真，标准错误简化为
$$
se(p_{1i}-p_{2i})=\frac{1}{N}\sqrt{b_i+c_i},
$$
检验统计量为
$$
z=\frac{p_{1i}-p_{2i}}{se(p_{1i}-p_{2i})}=\frac{b_i-c_i}{\sqrt{b_i+c_i}}。
$$
我的问题
如何进行以下测试？
$$H_0:\frac{\sum_{i=1}^m{p_{1i}}}{m}=\frac{\sum_{i=1}^m{ p_{2i}}}{m}$$
$$H_1:\frac{\sum_{i=1}^m{p_{1i}}}{m}\not=\frac{\sum_{i=1}^ m{p_{2i}}}{m}$$
事实上，每一对 $(p_{is},p_{jt}) $ 都是相关的， $i,j \in\{1,2\}, 1\le s,t \le m$，我还可以获得每对对应的所有列联表。同样，我可以计算 $\frac{\sum_{i=1}^m{p_{1i}}-p_{2i}}{m}$ 确定它们的协方差矩阵后，
$$
Var\left({\sum_{i=1}^m{p_{1i}}-p_{2i}}\right)=\sum_{i=1}^m \left({Var(p_{1i}) +Var(p_{2i})}\right)+{2\sum_{1\le i&lt; j \le m}\left({Cov(p_{1i},p_{1j})+Cov(p_{2i},p_{2j})}\right)} - {2\sum_{1\le i \ le j \le m}{Cov(p_{1i},p_{2j})}}
$$
假设原假设为真，我如何简化它。我可以直接使用它而忽略 ${\sum_{i=1}^m{b_{i}}}={\sum_{i=1}^m{c_ 的条件吗{i}}}$。
与我的问题相关的任何其他测试方法或文章/书籍都可以。提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/637372/statistical-significance-for-difference-in-mean-proportions-when-comparing-group</guid>
      <pubDate>Sun, 21 Jan 2024 07:09:09 GMT</pubDate>
    </item>
    <item>
      <title>为（隐藏的）抛硬币问题编写最大似然方程</title>
      <link>https://stats.stackexchange.com/questions/637371/writing-maximum-likelihood-equations-for-a-hidden-coin-toss-problem</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637371/writing-maximum-likelihood-equations-for-a-hidden-coin-toss-problem</guid>
      <pubDate>Sun, 21 Jan 2024 06:22:09 GMT</pubDate>
    </item>
    <item>
      <title>如何使用STATA创建社会参与指数？</title>
      <link>https://stats.stackexchange.com/questions/637370/how-to-create-social-participation-index-using-stata</link>
      <description><![CDATA[为了构建老年人的社会参与变量（SPV），该研究采用了一套全面的问题，旨在捕捉老年人参与的各种社会活动。调查问卷涵盖社会参与的各个维度，包括外出就餐、悠闲地游览公园或海滩、室内和室外游戏、与亲友互动、观看文化表演或电影、参加宗教活动或活动、参与政治和社区活动会议以及利用技术进行电子邮件和上网等活动。受访者以细致入微的 7 点李克特量表表达了他们参与这些活动的频率，范围从每天参与到从不参与或不相关。鉴于李克特量表反应的序数性质，可以采用因子分析或主成分分析等方法来识别社会参与变量之间的潜在模式和相互关系。在这种情况下应用哪种方法最好？请问有人知道这些方法的 STATA 语法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637370/how-to-create-social-participation-index-using-stata</guid>
      <pubDate>Sun, 21 Jan 2024 06:12:44 GMT</pubDate>
    </item>
    <item>
      <title>Box-Cox变换公式</title>
      <link>https://stats.stackexchange.com/questions/637369/box-cox-transformation-formula</link>
      <description><![CDATA[我正在阅读一些有关 Box-Cox 转换的资源。我找到的几乎所有网站都给出了变换公式的公式为
$$y^{(\lambda )} =\begin{cases}\frac{y^\lambda-1}{\lambda}&amp;\lambda \neq 0 \cr \ln y&amp;\lambda =0\end{cases}.$$
但是，它们后面通常会跟一个表格，给出非常简单的转换，如 $$y^{(\lambda)}=y^{\lambda}$$
例如，$\lambda=2$表示转换后的数据为$y^2$； $\lambda=-1$ 表示转换后的数据为 $\frac{1}{y}$等。请参阅此处的链接： Box-Cox转型
我只是很困惑应该使用哪个公式进行转换。]]></description>
      <guid>https://stats.stackexchange.com/questions/637369/box-cox-transformation-formula</guid>
      <pubDate>Sun, 21 Jan 2024 05:15:26 GMT</pubDate>
    </item>
    <item>
      <title>如何计算样本量？如何影响样本量？</title>
      <link>https://stats.stackexchange.com/questions/637367/how-to-calculate-sample-size-how-to-affect-sample-size</link>
      <description><![CDATA[我们正在尝试确定我们研究的样本量。我们正在与群体进行比较。第 1 组将接受治疗，第 2 组不接受治疗。从之前的研究中我们知道，第 1 组的治疗复发率为每例 1%，第 2 组的复发率为每例 6%。
我通过比较比例对样本大小进行了测试（比例推断：比较两个独立样本，https://www.stat.ubc.ca/~rollin/stats/ssize/b2.html）。我使用了之前研究中的比例，第 1 组 0.01，第 2 组 0.06。据计算，我们每组需要 211 名患者。如果我们收集 211 名患者，将花费太多的时间和资源。
对于我们来说，每组收集大约 40-60 名患者是现实的。还有其他可能性吗？我可以使用效果大小吗？我该如何计算它？]]></description>
      <guid>https://stats.stackexchange.com/questions/637367/how-to-calculate-sample-size-how-to-affect-sample-size</guid>
      <pubDate>Sun, 21 Jan 2024 04:37:24 GMT</pubDate>
    </item>
    <item>
      <title>在分类模型的超参数调整期间是否应该使用阈值相关指标作为优化目标？</title>
      <link>https://stats.stackexchange.com/questions/637366/should-threshold-dependent-metrics-be-used-as-optimization-objectives-during-hyp</link>
      <description><![CDATA[在超参数调整期间我们应该优化哪些指标？
根据我从 Frank Harrell 的 文章 和其他相关问题（降低分类概率阈值），分类问题应该被视为概率预测问题和决策问题。建立一个能够提供良好的数据区分强度的模型是一个统计问题，而选择分配标签的阈值是一个决策问题，取决于使用该模型的决策者的要求。如果我们想要高召回率，那么阈值越低越好，而高精度则需要更高的阈值。
既然是这种情况，那么在超参数调整期间优化阈值相关指标（例如精度、召回率、准确度和 f1 分数）是否有意义？ （例如，在 Sklearn 的各种 CV 调整方法中，我们可以从多种选项中进行选择）
通过在超参数调整期间优化依赖于预测阈值的指标，这不是在模型开发阶段明确地融入了决策假设吗？
如果我们在模型开发过程中只关心模型判别强度，那么不依赖于阈值的指标（例如 AUC-ROC、AUC-PRC）应该是（唯一？）在超参数调整期间优化的合适指标。这个想法正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637366/should-threshold-dependent-metrics-be-used-as-optimization-objectives-during-hyp</guid>
      <pubDate>Sun, 21 Jan 2024 03:19:36 GMT</pubDate>
    </item>
    <item>
      <title>术语：当分类变量有多个级别时是多变量？</title>
      <link>https://stats.stackexchange.com/questions/637358/terminology-multivariable-when-multiple-levels-of-categorical-variable</link>
      <description><![CDATA[人们经常会看到人们使用单变量和多变量逻辑回归等术语，其中明确指的是预测变量的数量，而不是响应变量的数量。我知道在这种情况下使用术语“多变量”而不是“多元”可能会更好。我的问题是，当存在多个级别的分类预测变量时，在这种情况下它会被视为单变量（单变量）还是多变量（多变量）模型？混乱源于这样一种观念，即尽管有一个预测变量，但它在形式上对应于多个虚拟变量，例如，每个虚拟变量都与各自的优势比相关联。]]></description>
      <guid>https://stats.stackexchange.com/questions/637358/terminology-multivariable-when-multiple-levels-of-categorical-variable</guid>
      <pubDate>Sat, 20 Jan 2024 23:38:13 GMT</pubDate>
    </item>
    <item>
      <title>卡林-鲁宾定理：具有 MLR 属性的检验统计量与充分性检验统计量之间的关系</title>
      <link>https://stats.stackexchange.com/questions/637347/karlin-rubin-theorem-relationship-between-test-statistic-having-the-mlr-propert</link>
      <description><![CDATA[假设我们正在尝试比较单个参数 $\theta$ 的两个假设。原假设 $H_0$ 是 $\theta = \theta_0$，替代假设是 &lt; span class=&quot;math-container&quot;&gt;$\theta ≥ \theta_0$。
据我所知，卡林-鲁宾定理告诉我们，如果存在这样一个统计量 $T(X)$，它具有单调性似然比（MLR）属性，意味着函数
$$
\frac{P\left(T(X)|\theta_1\right)}{P\left(T(X)|\theta_0\right)}
$$
在$T$中是单调非递减的，我们可以通过基于$T(X)$。
问题：$T(X)$ 是 MLR 和  之间有什么关系$T(X)$ 是一个足够的统计数据吗？

卡林-鲁宾定理是否要求 $T(X)$ 也足够，或者只是 MLR？
对于成为 MLR 和充分性有什么影响吗？

我们是否有足够的 MLR $\to$ 和/或足够的 $\to$ MLR？ 


关于 MLR 和最小足够怎么样？

我们是否有足够的最低 $\to$ MLR 和/或 MLR $\to$ 最低限度够了吗？


这些事情有任何关联吗？

简而言之，我在这里看到很多帖子谈论卡林-鲁宾定理设置中的足够统计量，但当我阅读它时，MLR 属性似乎是真正重要的标准。&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/637347/karlin-rubin-theorem-relationship-between-test-statistic-having-the-mlr-propert</guid>
      <pubDate>Sat, 20 Jan 2024 19:47:12 GMT</pubDate>
    </item>
    <item>
      <title>独立分量分析 (ICA)：为什么按主成分而不是右奇异向量旋转白化数据？</title>
      <link>https://stats.stackexchange.com/questions/637334/independent-component-analysis-ica-why-rotate-whitened-data-by-principal-comp</link>
      <description><![CDATA[我有一个数据矩阵 $ X $ ，即 $n \times m$，其中 &lt; span class=&quot;math-container&quot;&gt;$n$ 是特征数量，$m$ 是样本数量，$ n &lt; m$。令 $X$ 的奇异值分解 (SVD) 为 $$ X = U \Sigma V^T $$&lt; /跨度&gt;
在独立成分分析 (ICA) 的传统预处理中，主成分分析 (PCA) 应用于由 $$ XX^T = U \Sigma V^T V 形成的协方差矩阵\Sigma^T U^T = U \Sigma^2 U^T $$ 然后由主成分和特征值形成白化矩阵 $$ W = \Sigma^ {2^{-\frac{1}{2}}}U^T $$
然后将数据投影到白化矩阵 $$ WX $$
该投影通过正交矩阵迭代旋转，直到获得独立分量，如独立分量分析教程中所述
我想知道为什么使用主成分和特征值来白化数据，而不是直接使用正确的奇异向量。我最初的想法是旋转白化数据 $ WX $ 应该相当于旋转正确的奇异向量 $ V^T $ ，因为我相信白化数据应该与正确的奇异向量相同：
$$ WX = \Sigma^{2^{-\frac{1}{2}}}U^TU \Sigma V^T = \Sigma^{-1} \Sigma V^T = V^T $$
我对为什么这不正确的猜测可能是由于协方差矩阵的估计或给定 $ n &lt;; 的情况下右奇异向量的稳定性。 m$，但我不确定。此外，我认为这可能与这篇文章有关，但并不积极SVD 和 PCA 之间的关系。如何使用SVD进行PCA？。第 5.3 节 降维元素和流形学习似乎也相关，因为它们展示了如何使用奇异值和右奇异向量的组合获得投影。]]></description>
      <guid>https://stats.stackexchange.com/questions/637334/independent-component-analysis-ica-why-rotate-whitened-data-by-principal-comp</guid>
      <pubDate>Sat, 20 Jan 2024 17:06:50 GMT</pubDate>
    </item>
    <item>
      <title>准实验因子设计 3（操纵）x 1（测量）ANCOVA 的功效分析</title>
      <link>https://stats.stackexchange.com/questions/637317/power-analysis-for-a-quasi-experimental-factorial-design-3manipulated-x-1-mea</link>
      <description><![CDATA[这里是社会心理学家。我正在努力寻找合适的分析来计算我想要实施的实验的功效，所以这是我向您提出的问题。
我想运行一个准实验设计 A（操纵：3 个水平）X B（测量：序数有 5 个水平，但被视为连续）并控制 2 个连续混杂变量。
我使用的仪器非常可靠（alpha 为 0.84、0.94、0.99）。
我的第一选择是简单地在 G*Power 上运行多元回归的功效分析，其中包含 3 个测试的预测变量（IV、IV 和交互项）和总共 5 个预测变量（IV、IV、交互项和 2 个混杂因素），其中有一个小的预测交互效果。
但我知道这里有很多问题。我认为将 IV 和序数视为连续是最糟糕的，因为其中存在问题：如果我有 5 个级别，我将需要 1829 个受试者（Acova、固定效应、主要效应和相互作用：EF f=.10，alpha = .05 ，功效 = 0.80，df = 14，组 = 15，协变量 = 2)。
然后我想到了第二种选择。关于测量 IV 的理论表明，4 及以上的答案将被视为“高”，因此我认为，我可以在此前提下拆分主题。但这样我可能会失去信息和/或权力，而且，无论如何，我都需要超过 1200 个受试者。
然后，我认为（第三种可能性），我可以将参数输入层次回归，看看我得到的样本大小，但操纵变量显然不允许我使用这种思路。
我认为，这种设计的主要问题是测量的预测器。
任何有关如何计算样本量的建议将不胜感激。
谢谢大家。
编辑：要使用InteractionPower，请遵循评论中的一些好的建议，如下一些数字：
libray(InteractionPower)
power_test = power_interaction_r2(
alpha = 0.05, # p 值
N = seq(250,300, by=50), # 样本大小
r.x1.y = .23, # x1 和 y 之间的相关性
r.x2.y = .23, # x2 和 y 之间的相关性
r.x1.x2 = .53, # x1 和 x2 之间的相关性
r.x1x2.y = seq(.1,.2,by=.001)) # x1x2 和 y 之间的相关性
功率测试
#结果=样本量=300； x1x2 和 y 之间的相关性= 0.169；功率= 0.8074179
#结果=样本量=250； x1x2 和 y 之间的相关性= 0.184；功率=0.8013529

# 当r.x1.x2 = 0时
power_test = power_interaction_r2(
alpha = 0.05, # p 值
N = seq(250,300, by=50), # 样本大小
r.x1.y = .23, # x1 和 y 之间的相关性
r.x2.y = .23, # x2 和 y 之间的相关性
r.x1.x2 = 0, # x1 和 x2 之间的相关性
r.x1x2.y = seq(.1,.2,by=.001)) # x1x2 和 y 之间的相关性
功率测试
#结果=样本量=300； x1x2 和 y= 0.155 之间的相关性；功率= 0.8039252
#结果=样本量=250； x1x2 和 y= 0.170 之间的相关性；功率=0.8035689

使用方法进行计算这里对我来说很难使用，因为实际上，我明白，我应该有手段和差异，但我没有。最后，我刚刚尝试的设置在我看来只是一个带有交互项功效分析的多元回归。我喜欢这样一个事实：在 250 个人中，我能够检测到如此小的影响，但对我来说，它似乎太大了（特别是当我看到 这个）。明天我会提出其他解决方案。
同时，欢迎任何提示]]></description>
      <guid>https://stats.stackexchange.com/questions/637317/power-analysis-for-a-quasi-experimental-factorial-design-3manipulated-x-1-mea</guid>
      <pubDate>Sat, 20 Jan 2024 11:49:50 GMT</pubDate>
    </item>
    <item>
      <title>Seaborn 箱线图的四分位数</title>
      <link>https://stats.stackexchange.com/questions/637302/seaborn-boxplots-quartiles</link>
      <description><![CDATA[我试图了解如何正确解释 seaborn 生成的 boxplot。
考虑以下代码：
导入 pandas 作为 pd
将seaborn导入为sns
df = pd.DataFrame([[1], [2], [3], [4]])
sns.boxplot(数据=df)

当我在 Google Colab 中运行此代码时，会出现以下绘图：

据我所知，框下侧的 y 值是数据的四分位数。这意味着，根据 seaborn，数据的四分位数严格大于 1.5。
这与我所了解的四分位数不一致。据我所知，四分位数是任何满足 x 的数字
&lt;前&gt;&lt;代码&gt;P(X &lt; x) &lt;= 1/4
P(X &lt;= x) &gt;= 1/4

并且，如果X是离散的，并且如果x1 &lt; x2 是属于 X 支持的两个四分位数，那么按照惯例，代表性四分位数取为 x1 和 x2 的平均值.
将此应用于上面示例的数据，这意味着四分位数应精确为 1.5，这与绘图相反，该图显示四分位数严格大于 1.5&lt; /代码&gt;.]]></description>
      <guid>https://stats.stackexchange.com/questions/637302/seaborn-boxplots-quartiles</guid>
      <pubDate>Sat, 20 Jan 2024 06:59:28 GMT</pubDate>
    </item>
    </channel>
</rss>