<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 23 Dec 2023 00:57:52 GMT</lastBuildDate>
    <item>
      <title>如何对计数数据拟合非线性混合模型？</title>
      <link>https://stats.stackexchange.com/questions/635526/how-to-fit-non-linear-mixed-model-for-count-data</link>
      <description><![CDATA[我一直在阅读这篇论文及其补充编码有关如何为与我感兴趣的建模用例非常接近的用例拟合非线性混合模型的材料：
nlme(emaintent ~ theta1 + theta2*exp(theta3*n..ij - theta4*dtime..ij), data=temp,
         固定=列表（
           theta1 ~ 1 + blsmk.never + 性别 + 少数派 + 周末,
           θ2 ~ 1 ,
           theta3 ~ 1 + blsmk.never,
           theta4 ~ 1 + blsmk.never),
         随机=列表（subid =列表（theta1〜1，theta2〜1）），
         开始=列表（固定=mcoef），
         控制=列表(maxIter=10000)

)
他们使用 R 中的 nlme 包来建模非线性模型，以处理暴露对响应变量的指数衰减效应。起初这对我来说听起来很棒，但我的数据（机密，但如果需要的话可以合成新的数据集）是计数数据，我意识到需要特殊处理，我不确定 nlme 包中是否已实现。当我使用 glmmTMB 使用广义线性混合模型进行建模时，我获得了相当好的拟合效果，没有过度离散。
如果您下载了本文底部链接的两个补充文件，则可以运行上述模型。但是，如果您绘制（或只是阅读）他们使用的响应数据的分布，很明显它不是正态分布的。事实上，它的范围是 0-10（根据定义，响应变量是 0-10 范围内的几个分数的平均值）。如果模型假设残差呈正态分布，这是否有问题？
如果响应变量是离散且泊松分布的，使用这种类似的 nlme 框架是否可以？
如果不是，我可以使用哪些库来以尽可能少的痛苦实现此模型？我拥有统计学硕士学位，但在非线性模型方面我是自学的。
感谢您的阅读]]></description>
      <guid>https://stats.stackexchange.com/questions/635526/how-to-fit-non-linear-mixed-model-for-count-data</guid>
      <pubDate>Fri, 22 Dec 2023 22:19:59 GMT</pubDate>
    </item>
    <item>
      <title>如何从 medflex 包中获取中介主效应</title>
      <link>https://stats.stackexchange.com/questions/635524/how-to-get-mediation-main-effect-from-the-medflex-package</link>
      <description><![CDATA[我从@Brennan Baker &amp; 借用了这个例子。 @Manetheran。
我正在使用分类结果和预测变量进行中介分析。我看到了直接、间接和总体影响，以及协变量的影响。如何找到中介对结果的影响？
示例：
&lt;前&gt;&lt;代码&gt;库(medflex)
图书馆（调解）
数据（成帧）

# 准备数据以具有适当的格式
expData &lt;- neImpute(cong_mesg ~ treat + emo + 年龄,
                     家庭=二项式（“logit”），数据=框架）
＃ 模型
nMod &lt;- neModel(cong_mesg ~ treat0 + treat1 + 年龄,
                family = 二项式(“logit”), expData = expData)

# 系数（包括直接和间接影响）
&gt;摘要(nMod)
自然效应模型
具有基于非参数引导的标准误差
---
暴露：治疗
调解人：情绪
---
参数估计：
             估计标准。误差z值Pr(&gt;|z|)
（截距）-1.251923 0.412290 -3.037 0.002393 **
治疗0 0.066202 0.278854 0.237 0.812340
治疗1 0.414177 0.121858 3.399 0.000677 ***
年龄 0.008794 0.008103 1.085 0.277782
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

# 直接、间接和总体影响

&gt;摘要(neEffdecomp(nMod))
线性预测器规模的效应分解
具有基于非参数引导的标准误差
---
条件：年龄
其中 x* = 0，x = 1
---
                        估计标准。误差z值Pr(&gt;|z|)
自然直接效应 0.0662 0.2788 0.237 0.812340
自然间接影响 0.4142 0.1219 3.399 0.000677 ***
总效应 0.4804 0.2998 1.603 0.109044
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
（报告单变量 p 值）
]]></description>
      <guid>https://stats.stackexchange.com/questions/635524/how-to-get-mediation-main-effect-from-the-medflex-package</guid>
      <pubDate>Fri, 22 Dec 2023 21:21:25 GMT</pubDate>
    </item>
    <item>
      <title>编写时间因变量的扩展 Cox 模型的统计模型</title>
      <link>https://stats.stackexchange.com/questions/635522/writing-the-statistical-model-for-extended-cox-model-for-time-dependent-variable</link>
      <description><![CDATA[我正在写一篇论文，其中使用扩展的 Cox 模型来处理因时间变量。我想看看两次劳动改革（自变量）是否对工作合同期限（因变量）有影响。数据库的主体不是人，而是合同本身。
由于有些合同在劳动改革之前和之后都有效（有些合同在改革通过之前就没有延长，有些则在改革通过之后开始），因此“劳动改革”被视为“劳动改革”。是一个时间因变量（因为有些合同在一段时间内“不受劳动改革影响”，然后受到第一次改革的影响，最终受到第二次改革的影响。
我还将经济危机作为时间相关协变量纳入其中，因为一些合同在 2008 年至 2014 年经济危机期间延期。然后我还纳入了其他协变量，包括签订合同的人的性别、合同类型（永久、临时）、工业部门等。
现在，我想非常清楚地解释我的方法，并希望将统计模型包含在代数符号中。我发现有些论文仅包含 Cox 比例风险模型的一般统计模型，例如： https: //imgur.com/a/u7AtY7P
但是其他一些论文则采取了不同的方式，根据我的理解，“加倍努力”，编写他们将要使用的统计模型的特定版本，例如：https://imgur.com/a/4jEJFGu
我的问题是：是否有一个名称来描述您在辣椒上使用的特定统计模型（而不是一般公式）？您在其中解释每个符号的变量含义等。
我该如何按照后一个示例编写我将要使用的时间相关变量的扩展 Cox 模型的特定版本？我是否需要编写我的扩展 Cox 模型版本和风险比方程版本？您知道有这样做的论文示例吗？ （我发布的第一个例子仅说明了 Cox 模型和风险比的一般方程，加上它涉及 Cox 比例风险模型，因此我担心如果我太密切地遵循它，我可能会搞砸，因为我&#39;我使用扩展的 Cox 模型，用于时间相关变量）。
非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/635522/writing-the-statistical-model-for-extended-cox-model-for-time-dependent-variable</guid>
      <pubDate>Fri, 22 Dec 2023 20:23:21 GMT</pubDate>
    </item>
    <item>
      <title>使用较低层级（产品）的样本来推断较高层级（公司）</title>
      <link>https://stats.stackexchange.com/questions/635519/using-sample-at-lower-hierarchical-level-products-to-draw-inferences-about-a-h</link>
      <description><![CDATA[我有一个概念性问题，我们是否可以使用随机的产品样本来推断公司。更一般地说，我认为这将扩展到对分层数据进行采样，我们希望在与抽取样本的不同级别上进行推理。
基本设置如下：有 $i=\{1, ..., M\}$ 个公司。每个公司 $i$ 销售一组产品 $X_{ij}$，其中 $j=\{1,...,N_i\}$，这样 $N_i$ 是产品总数$i^\text{th}$ 公司出售。每个产品 $X_{ij}$ 要么包含警告标签，要么不包含。使用网站，我们可以进行搜索查询并获取所有 $\sum_i N_i$ 产品的列表（即示例框架）。我们对这些产品进行随机抽样，并记录每个产品的公司以及产品是否包含警告标签。目标是使用此随机样本来估计销售至少一种带有警告标签的产品的独特公司的总数。
我们可以假设 $N_i$ 的分布是已知的。一个例子是 $N_i \sim \text{NegBin}\left(\text{size}=1, \text{prob}=\frac{1}{6}\right ) + 1$，但我希望了解如何将该解决方案应用于任何已知的发行版。 （这可能是编写分布的一种草率方式——我添加 1，以便每个公司的产品总数永远不会为 0。）
假设我们根据搜索结果发现共有 52,000 种产品。我们对 500 种产品进行了抽样，发现有 480 家独特的母公司。举个简单的例子，假设 100% 的产品都有警告标签。我知道认为有 $\frac{480}{500}\times 52,000 = 49,920$ 独特公司至少有一种产品具有警告标签，因为拥有更多产品的公司更有可能出现在样本中。
但是从产品样本估算公司总数的正确方法是什么？
我尝试创建一些模拟，但我仍然没有走得太远/还没有弄清楚如何处理模拟数据。
图书馆(tidyverse)

N_comps &lt;- 10000 # 公司数量
设置.种子(1356)
n_prod &lt;- 1+rnbinom(N_comps, size=1, prob=1/6) # 每个公司的产品总数
compID &lt;- 1:N_comps # 给每个公司一个ID
comp.df &lt;- data.frame(compID, n_prod) # 存储在数据帧中
N_prod &lt;- sum(comp.df$n_prod) # 产品总数

prodID &lt;- unlist(map(comp.df$n_prod, ~1:.x)) # 给每个产品一个 ID
compID &lt;- unlist(map2(comp.df$compID, comp.df$n_prod, ~rep(.x, .y))) # 重复公司 ID每个相关产品
prod.df &lt;- data.frame(prodID, compID)
prod.df$hasLabel &lt;-sample(c(TRUE, FALSE), N_prod, Replace=TRUE, prob=c(1.00, 0)) # 为简单起见，假设它们都有标签
sampSize &lt;- seq(100, nrow(prod.df), 400) # 逐渐增加产品样本大小
results &lt;-rep(NA, length(sampSize)) # 存储结果的向量

设置.种子(21551)
for(i in 1:length(sampSize)){
  prodSamp &lt;-sample(1:nrow(prod.df), size=sampSize[i]) # 抽取产品样本
  结果[i] &lt;- prod.df %&gt;%
                  切片(prodSamp) %&gt;%
                  过滤器(hasLabel) %&gt;%
                  不同（compID）%&gt;%
                  nrow() # 统计不同公司的数量
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/635519/using-sample-at-lower-hierarchical-level-products-to-draw-inferences-about-a-h</guid>
      <pubDate>Fri, 22 Dec 2023 18:37:15 GMT</pubDate>
    </item>
    <item>
      <title>PERT 分布的最小和最大参数的均匀最小方差无偏估计量 (UMVUE) 是多少？</title>
      <link>https://stats.stackexchange.com/questions/635518/what-is-the-uniformly-minimum-variance-unbiased-estimators-umvue-for-the-minim</link>
      <description><![CDATA[我相信这个问题的答案是样本最小值和样本最大值，但我还没有找到这方面的参考或证明。]]></description>
      <guid>https://stats.stackexchange.com/questions/635518/what-is-the-uniformly-minimum-variance-unbiased-estimators-umvue-for-the-minim</guid>
      <pubDate>Fri, 22 Dec 2023 18:15:15 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 LSTM、TFT 或其他 RNN 处理不同长度的时间序列</title>
      <link>https://stats.stackexchange.com/questions/635517/how-to-use-lstm-tft-or-other-rnn-with-time-series-of-different-lengths</link>
      <description><![CDATA[我有每天的金融交易数据集，其中包含交易量和交易价格。对于每一天，我想计算当天结束时的成交量加权平均价格。但每天的交易笔数和交易次数有所不同。
训练 LSTM、TFT 或其他神经网络来解决此问题的标准方法是什么？

填充
采样（但对于我的问题，这不起作用）

数据集如下所示：
日 |时间 |交易# |价格|音量
对于每一天，我想在当天结束之前预测交易量加权平均价格，所以我的目标是
日 |成交量加权平均价]]></description>
      <guid>https://stats.stackexchange.com/questions/635517/how-to-use-lstm-tft-or-other-rnn-with-time-series-of-different-lengths</guid>
      <pubDate>Fri, 22 Dec 2023 17:28:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么鲁汶方法是非确定性的？</title>
      <link>https://stats.stackexchange.com/questions/635507/why-is-louvain-method-non-deterministic</link>
      <description><![CDATA[我正在 R 中的 igraph 中使用 Louvain 算法的实现进行社区检测。我观察到多次运行它会产生不同的答案。然而，当我读到算法时
Louvain 方法 - 维基百科，没有任何东西具有任何明显的随机性。我的猜测是，以不同的顺序遍历这些点可能会产生不同的答案，并且 igraph 代码在处理顶点之前会随机化顶点的顺序。这就是它产生多个答案的原因 - 还是还有其他原因？]]></description>
      <guid>https://stats.stackexchange.com/questions/635507/why-is-louvain-method-non-deterministic</guid>
      <pubDate>Fri, 22 Dec 2023 14:37:42 GMT</pubDate>
    </item>
    <item>
      <title>R：MASS::glm.nb 和 glmmTMB“nbinom2”之间的参数化差异</title>
      <link>https://stats.stackexchange.com/questions/635498/r-parameterization-differences-betwen-massglm-nb-and-glmmtmb-nbinom2</link>
      <description><![CDATA[我想了解有关 RStudio 中两个不同 GLM 输出的意见。
我使用样方计算为面积偏移，对 21 个地点的计数数据（粪便颗粒）进行了建模。我首先使用 GLM 泊松回归来定义模型结构，该模型具有严重的过度分散性和严重的过度分散性。零膨胀。我转向负二项式，它解决了这两个问题，但根据使用的包（MASS：glm.nb 和 glmmTMB nbinom2），我得到了不同的结果。他们给出相同的 theta 估计、相同的 AIC，但不同的 SE 和z 值，特别是对于一个预测变量，它在一个包中显得重要，但在另一个包中则不然。这是在模型选择之前。
因此，我想知道所使用的两个包之间的参数化有什么区别？根据我的阅读，他们似乎使用相同的方差公式，都是通过最大似然估计的：

glmmTMB：方差 = µ(1 + µ/k)
MASS：方差 = μ+μ²/θ，使得 θ=1/k

我怀疑这与 MASS::glm.nb 从对数似然计算中删除常量有关，而 glmmTMB 则不然，但我无法确认。
我倾向于坚持使用 MASS，因为我在这里不使用任何 RE，但我想知道发生了什么。
代码输出：
&lt;前&gt;&lt;代码&gt;&gt; # 海量包
&gt; mod.nbmass &lt;- glm.nb(颗粒 ~ RS1+RS2+RS4+RS5+RS6+offset(log(quadrats)), link = &quot;log&quot;, data=data_site)
&gt;摘要（mod.nbmass）

称呼：
glm.nb(公式 = 颗粒 ~ RS1 + RS2 + RS4 + RS5 + RS6 + 偏移量(log(quadrats)),
    数据 = data_site，链接 =“日志”，init.theta = 0.9808088892）

残差偏差：
    最小 1Q 中值 3Q 最大
-2.6923 -0.9313 -0.1119 0.2173 1.5372

系数：
            估计标准。误差z值Pr(&gt;|z|)
（截距） 0.17109 0.22170 0.772 0.4403
RS1 -0.04392 0.34372 -0.128 0.8983
RS2 0.21905 0.31118 0.704 0.4815
RS4 -0.04524 0.31740 -0.143 0.8866
RS5 0.21135 0.34775 0.608 0.5433
RS6 -0.67892 0.33963 -1.999 0.0456 *
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（负二项式(0.9808)族的色散参数取为1）

    零偏差：20 自由度上为 29.252
残余偏差：15 个自由度上为 24.854
注册会计师：246.43

Fisher 评分迭代次数：1


              西塔：0.981
          标准。误差：0.290

 2 x 对数似然：-232.429
&gt; # glmmTMB 包
&gt; mod.nbTMB&lt;-glmmTMB(颗粒 ~ RS1+RS2+RS4+RS5+RS6+offset(log(quadrats)), family=“nbinom2”, data=data_site)
&gt;摘要(mod.nbTMB)
 家族：nbinom2（日志）
公式：颗粒 ~ RS1 + RS2 + RS4 + RS5 + RS6 + 偏移量(log(quadrats))
数据：data_site

     AIC BIC logLik 偏差 df.resid
   246.4 253.7 -116.2 232.4 14


nbinom2 系列的色散参数 ()：0.981

条件模型：
            估计标准。误差z值Pr(&gt;|z|)
（截距）0.17109 0.22163 0.772 0.440
RS1 -0.04393 0.39138 -0.112 0.911
RS2 0.21905 0.26685 0.821 0.412
RS4 -0.04525 0.30701 -0.147 0.883
RS5 0.21135 0.40676 0.520 0.603
RS6 -0.67892 0.48995 -1.386 0.166

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635498/r-parameterization-differences-betwen-massglm-nb-and-glmmtmb-nbinom2</guid>
      <pubDate>Fri, 22 Dec 2023 12:42:43 GMT</pubDate>
    </item>
    <item>
      <title>$E[X|X^3-3X]=0$ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635492/exx3-3x-0</link>
      <description><![CDATA[用 $f(x) 证明 $E[X|X^3-3X]=0$ =\frac{|x^2-1|}{4}$ 是区间 $X$ 的密度函数数学容器&quot;&gt;$[-2,2]$。]]></description>
      <guid>https://stats.stackexchange.com/questions/635492/exx3-3x-0</guid>
      <pubDate>Fri, 22 Dec 2023 11:30:22 GMT</pubDate>
    </item>
    <item>
      <title>在 GAMM 中指定 corAR1 结构</title>
      <link>https://stats.stackexchange.com/questions/635469/specifying-corar1-structure-in-gamm</link>
      <description><![CDATA[我有一个包含两个站点（A 和 B）的数据集，其中包含跨年份的多个观测值，但并非每年都在每个站点进行采样（跨年份的观测值也不是平衡的）。
例如，在站点 A，有 20 年（跨越 30 年）的数据，每年有 10-103 个观测值。
acf 和 pacf 图显示了两个站点之一的一些自相关性（如下例）。
我一直在使用 gam 来模拟时间变化：
gam(RO ~ s(YEAR) + s(YEAR, SITE, bs = &quot;sz&quot;))

但是，我想改用 gamm 并添加关联结构。理想情况下，这将嵌套在站点内，但我没有成功地运行我尝试的任何结构：
gamm(RO ~ s(YEAR) + s(YEAR, SITE, bs = &quot;sz&quot;), 相关性 = corAR1(form = ~ YEAR | SITE))
Initialize.corAR1(X[[i]], ...) 中的错误：
  协变量在“corAR1”的组内必须具有唯一的值。物体
另外：警告消息：
在 gam.side(sm, X, tol = .Machine$double.eps^0.5) 中：
  模型重复对同一变量进行一维平滑。

gamm(RO ~ s(YEAR) + s(YEAR, SITE, bs = &quot;sz&quot;), 相关性 = corAR1(form = ~ YEAR))
Initialize.corAR1(X[[i]], ...) 中的错误：
  协变量在“corAR1”的组内必须具有唯一的值。物体
另外：警告消息：
在 gam.side(sm, X, tol = .Machine$double.eps^0.5) 中：
  模型重复对同一变量进行一维平滑。

我还尝试创建一个单独的时间变量，其中年份按顺序编号。例如，如果有 1970 年、1971 年和 1973 年的数据，则编号为 1、2 和 4。
gamm(RO ~ s(YEAR) + s(YEAR, SITE, bs = &quot;sz&quot;), 相关性 = corAR1(form = ~ time))
Initialize.corAR1(X[[i]], ...) 中的错误：
  协变量在“corAR1”的组内必须具有唯一的值。物体
另外：警告消息：
在 gam.side(sm, X, tol = .Machine$double.eps^0.5) 中：
  模型重复对同一变量进行一维平滑。

最后，我创建了另一个带有编号年份的时间变量，但我忽略了编号中没有数据的年份。例如，如果有 1970 年、1971 年和 1973 年的数据（至少 1 个站点），则这些数据编号为 1、2 和 3。
gamm(RO ~ s(YEAR) + s(YEAR, SITE, bs = &quot;sz&quot;), 相关性 = corAR1(form = ~ seqtime))
Initialize.corAR1(X[[i]], ...) 中的错误：
  协变量在“corAR1”的组内必须具有唯一的值。物体
另外：警告消息：
在 gam.side(sm, X, tol = .Machine$double.eps^0.5) 中：
  模型重复对同一变量进行一维平滑。

我错过了什么？
站点 = A 的 acf 图

站点 = B 的 acf 图
]]></description>
      <guid>https://stats.stackexchange.com/questions/635469/specifying-corar1-structure-in-gamm</guid>
      <pubDate>Fri, 22 Dec 2023 01:07:04 GMT</pubDate>
    </item>
    <item>
      <title>关于数据对数转换的有趣观察</title>
      <link>https://stats.stackexchange.com/questions/635466/an-interesting-observation-regarding-the-log-transformation-of-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635466/an-interesting-observation-regarding-the-log-transformation-of-data</guid>
      <pubDate>Fri, 22 Dec 2023 00:42:00 GMT</pubDate>
    </item>
    <item>
      <title>我们可以从置信区间推导出 2 类错误概率吗？</title>
      <link>https://stats.stackexchange.com/questions/635464/can-we-derive-type-2-error-probability-from-confidence-interval</link>
      <description><![CDATA[如果我们可以计算估计值的置信区间$\hat{\theta}$，然后我们还可以计算相关假设$\theta=\theta_0$，这是特定样本出现 1 类错误的概率（即在正确的情况下拒绝假设）。
我们是否还可以使用这些置信区间来获取该假设和样本出现 2 类错误的概率（即，当假设不正确时接受该假设）？
直观上，我们似乎应该能够做到这一点，因为较窄的置信区间似乎与更强大的测试成正比，这（根据定义）是较低的 2 类错误概率。因为 2 类错误似乎类似于 {无错误} + {1 类错误} 的补集。 （但如果这些表面不正确，对此的解释也可能有帮助。）]]></description>
      <guid>https://stats.stackexchange.com/questions/635464/can-we-derive-type-2-error-probability-from-confidence-interval</guid>
      <pubDate>Fri, 22 Dec 2023 00:19:57 GMT</pubDate>
    </item>
    <item>
      <title>混合效应模型中 p 值计算的当前观点</title>
      <link>https://stats.stackexchange.com/questions/635275/current-perspectives-on-p-value-computation-in-mixed-effects-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635275/current-perspectives-on-p-value-computation-in-mixed-effects-models</guid>
      <pubDate>Tue, 19 Dec 2023 17:06:52 GMT</pubDate>
    </item>
    <item>
      <title>您是否应该模拟混杂因素对其他混杂因素的影响来测试估计器？</title>
      <link>https://stats.stackexchange.com/questions/635194/should-you-simulate-the-effect-of-confounders-on-other-confounders-to-test-an-es</link>
      <description><![CDATA[想象一下，我正在尝试模拟数据生成过程，其中我对 $Y$ 做出以下假设：
$Y$ = $X$(0.15) + $Z_1$(0.23) + $Z_2$(0.08) + $Z_3$(0.19) + $Z_4$(0.05) + 错误
此外，考虑到我对几个估计器感兴趣，并且我正在尝试找出哪个估计器恢复了 0.15 的定义治疗效果最好。然而，$X$ 被几个变量混淆，所以我相应地调整它们。
我很清楚的是，对于我认为是混杂因素的变量，我需要模拟每个混杂因素对治疗和结果的影响大小。例如，如果 $Z_1$ 对 $Y$ 的影响为 0.23，我还需要在 $X$ 上模拟 0.04 的效果，否则，它不会是一个混杂因素。
然而，在更复杂的数据生成过程中，混杂因素可能会影响其他混杂因素本身的价值。也就是说，将每个混杂因素定义为与其他感兴趣的混杂因素完全外生的分布可能是不合适的。
例如，不要说 $Z_1$ 只是一个平均值为 $\mu 的正态分布变量$ 和标准差 $\sigma$，我也可以说 $Z_2$ 对 $Z_1$ 的影响为 0.33，$Z_3$ 对 $Z_3$ 的影响为 0.07 span class=&quot;math-container&quot;&gt;$Z_1$。
为了实现这个假设模拟的目标（测试不同的估计器，看看哪个估计器能最好地恢复治疗效果），是否有必要定义每个混杂因素对另一个混杂因素的影响？或者，只要我指定每个混杂因素对结果和治疗的影响，模拟分析就可以进行了吗？
一方面，我看到了全面详细说明系统中所有变量的假设数据生成过程的好处。然而，另一方面，我发现我将进一步的假设嵌入到对不感兴趣的效应大小的分析中存在问题（即我没有实际兴趣了解/思考如何 $ Z_3$ 可能会影响 $Z_1$、$Z_2$、$Z_4$ 等）。]]></description>
      <guid>https://stats.stackexchange.com/questions/635194/should-you-simulate-the-effect-of-confounders-on-other-confounders-to-test-an-es</guid>
      <pubDate>Mon, 18 Dec 2023 15:08:33 GMT</pubDate>
    </item>
    <item>
      <title>如何激励人工智能做出危险的预测</title>
      <link>https://stats.stackexchange.com/questions/633338/how-to-incentivise-ai-to-make-risky-predictions</link>
      <description><![CDATA[我正在尝试构建一个天气预报人工智能。我有一个包含每天峰值温度的数据集。我用 MSE 作为损失函数来训练它，效果相当好。但我确实注意到，它往往更喜欢“安全”的东西。预测，即该时期平均温度附近的预测。我也对做出正确的意外预测感兴趣，因此我一直在尝试激励它做出风险更高的预测，但我没有运气。
我尝试使用指数和高阶多项式损失函数而不是平方，认为值的更快增加会奖励精确性。我尝试通过扩大平均温度附近预测的损失来惩罚安全预测。我尝试用阶跃函数包围平均温度。我不知道还能尝试什么，也不知道在线搜索答案的术语。]]></description>
      <guid>https://stats.stackexchange.com/questions/633338/how-to-incentivise-ai-to-make-risky-predictions</guid>
      <pubDate>Thu, 07 Dec 2023 18:26:00 GMT</pubDate>
    </item>
    </channel>
</rss>