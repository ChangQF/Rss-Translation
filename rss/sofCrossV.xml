<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 19 Dec 2024 18:23:01 GMT</lastBuildDate>
    <item>
      <title>非正态数据变换</title>
      <link>https://stats.stackexchange.com/questions/658975/non-normal-data-transformation</link>
      <description><![CDATA[我目前正在尝试转换我的非正态数据，以便我可以运行 glmm 模型进行一些研究。我的数据与行为有关，因此与此相关的任何数据都不是正态分布的，但我目前不知道下一步如何转换我的数据。到目前为止，我已经尝试了 sqrt 和 log10，但当我测试均匀性时，图表仍然显示它们不正常。我的数据也非常零膨胀。我对 r studio 还不熟悉，所以我知道的不多，但我能以某种方式使用负二项式族吗？
这些是我在尝试任何转换之前的图表：


关于我应该如何转换数据以便可以运行 glmm 的任何建议都很好有帮助！
我尝试了 sqrt 和 log10 转换。我相信它们部分有效，但不能解决数据的所有问题。
这是我的 log10 图表：这是在我的模型上使用 log10 转换得到的 零通胀与 log10 转换


这是我的 sqrt 图表： sqrt 转换 sqrt 零通胀


此外，这里是我用来获取这些图表和模型的代码。我研究蝾螈，所有这些数据都与它们的攻击性行为有关。
SimOutput.sallys &lt;- glmmTMB(sqrt(ATR + .1) ~ Treatment * Status + (1 | CoverObj), data = sallys)
SQRTsimulationoutput1 &lt;- mockResiduals(SimOutput.sallys, n = 1000, plot = TRUE) plot(SQRTsimulationoutput1) testUniformity(simulationOutput = SQRTsimulationoutput1) testDispersion(SQRTsimulationoutput1) testZeroInflation(SQRTsimulationoutput1)]]></description>
      <guid>https://stats.stackexchange.com/questions/658975/non-normal-data-transformation</guid>
      <pubDate>Thu, 19 Dec 2024 17:03:10 GMT</pubDate>
    </item>
    <item>
      <title>本文中的随机分位数残差</title>
      <link>https://stats.stackexchange.com/questions/658974/randomized-quantile-residuals-in-this-paper</link>
      <description><![CDATA[我正在阅读 Emrah Altun 和 Gauss M. Cordeiro 撰写的文章“单位改进的二阶林德利分布：推理和回归建模”。我想复制他们的一个结果。我正在尝试为 Beta 回归制作随机分位数残差图，但我没有得到相同的结果。他们有这个图
$\hskip2in$ 
但是我明白了

使用 qqPlot 和 residuals。并且至少从视觉上看它们并不相似，例如有一个大约为 -3 的值，但在我的例子中却不是这样。我的代码是
y = c(2.640, 0.596, 0.680, 2.190, 4.560, 2.140, 0.410, 
0.530, 0.750, 0.280, 4.390, 3.390, 5.190, 0.800, 2.160, 
2.640, 0.060, 2.549, 0.930, 0.310, 0.540, 7.750, 0.470, 
2.810, 1.760, 3.170, 1.760, 1.010, 0.990, 1.318, 0.550, 
                  0.040、1.374、2.890)
y = y/100
x = c(30.78, 57.87, 121.52, 90.17, 45.39, 11.08, 55.92, 51.54, 
                56.31、43.34、11.64、20.85、21.99、276.22、28.81、27.56、 
                30.6、21.02、5.93、7.24、380.1、15.76、305.44、8.94、 
                48.05、5.41、23.68、3.56、14.53、41.9、 71.7, 162.75, 
61.86, 40.43)
x = x/100
beta_model = betareg(y ~ x)
r_i = residuals(beta_model, type = &quot;quantile&quot;)
car::qqPlot(r_i, main = &quot;Beta&quot;, ylab = &quot;r_i&quot;)

如有任何关于此主题的帮助或参考，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658974/randomized-quantile-residuals-in-this-paper</guid>
      <pubDate>Thu, 19 Dec 2024 16:56:41 GMT</pubDate>
    </item>
    <item>
      <title>在预测方面，我可以用与简单回归相同的方式处理高斯过程回归吗？</title>
      <link>https://stats.stackexchange.com/questions/658972/can-i-treat-gaussian-process-regression-in-the-same-way-as-simple-regression-in</link>
      <description><![CDATA[我正在学习高斯过程回归。我有两个设置：
设置 1：
$$
y = a + f_{1}(x_{1}) + f_{2}(x_{2}) + e
$$
其中 $ f_{1}() , f_{2}() $是核。
设置 2：
$$
y = a + f(X) + e
$$
其中在我的例子中，$X$ 是 $N$ x 2 矩阵。
如果我想预测 $y$ 当 $x_{2}$ = 0，我该如何在两种设置中正确执行此操作？这与简单回归相同吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658972/can-i-treat-gaussian-process-regression-in-the-same-way-as-simple-regression-in</guid>
      <pubDate>Thu, 19 Dec 2024 15:42:32 GMT</pubDate>
    </item>
    <item>
      <title>有人能想到需要估计均匀分布参数的真实情况吗？</title>
      <link>https://stats.stackexchange.com/questions/658971/can-anyone-think-of-a-real-situation-in-which-the-parameters-of-a-uniform-distri</link>
      <description><![CDATA[（现在根据回复进行了编辑）
我正在研究如何基于具有未知参数的连续均匀分布的样本预测连续均匀分布的值的问题（whuber 在回复中给出了一个很好的公式）。
有一个有趣的客观贝叶斯解决方案，带有一个有趣的纸笔推导。
这是一个很好的例子，可以说明贝叶斯预测的好处。
但是有没有可以在现实世界中使用它的例子？我希望能够在我的演讲中提到一个例子，或者甚至可以研究一个真实的例子。
Ben 和 Nick 在回复中提出的“德国坦克问题”是针对离散随机变量的。我想知道是否还有连续随机变量的例子。
随机变量可能是单变量，也可能是某种多变量泛化...所以我猜在二维中它可能是一个圆形或矩形。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658971/can-anyone-think-of-a-real-situation-in-which-the-parameters-of-a-uniform-distri</guid>
      <pubDate>Thu, 19 Dec 2024 15:41:32 GMT</pubDate>
    </item>
    <item>
      <title>概率有界于确定性常数表达式</title>
      <link>https://stats.stackexchange.com/questions/658970/bounded-in-probability-with-the-deterministic-constant-expression</link>
      <description><![CDATA[我研究了下面链接中的论文：
https://projecteuclid.org/journals/bernoulli/volume-24/issue-2/Smooth-backfitting-for-additive-modeling-with-small-errors-in-variables/10.3150/16-BEJ898.full
本文中命题1（第1241页）的结果是
\begin{aligned}
\max_{1 \leq i \leq n}|\hat{\xi}^i_{jk}-{\xi}_{jk}^i|=O_p(n^{-(\beta-1)/(2\beta)}), \quad 1\leq j\leq d,1 \leq k \leq L_j, \beta \geq 2.
\end{aligned&gt;
但是，在引理 1（第 1256 页）的证明中，论文是这样陈述的：
我们可以假设 $\max_{i,j,k} |\hat{\xi}^i_{jk}-{\xi}_{jk}^i| \leq C_0 n^{−(\beta−1)/(2\beta)}$
对于某个正常数 $C_0$ ，根据命题 1。
我想知道这是怎么可能的。通常 $\max_{i,j,k} |\hat{\xi}^i_{jk}-{\xi}_{jk}^i| = O_p(n^{−(\beta−1)/(2\beta)})$ 并不意味着 $\max_{i,j,k} |\hat{\xi}^i_{jk}-{\xi}_{jk}^i| \leq C_0 n^{−(\beta−1)/(2\beta)}$。我正在考虑使用$C_0$来定义该事件，概率趋向于一，但我仍然找不到解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/658970/bounded-in-probability-with-the-deterministic-constant-expression</guid>
      <pubDate>Thu, 19 Dec 2024 14:56:38 GMT</pubDate>
    </item>
    <item>
      <title>模拟面板数据时解释间接滞后治疗效应</title>
      <link>https://stats.stackexchange.com/questions/658969/interpreting-indirect-lagged-treatment-effects-when-simulating-panel-data</link>
      <description><![CDATA[考虑以下 DAG，我感兴趣的是估计当前 (X2) 和滞后 (X1) 治疗对 Y2 的影响：

接下来，考虑 DAG 隐含的以下数据生成过程：
library(dplyr)

set.seed(12345)
n &lt;- 2000

dgp2_wide &lt;- tibble(id = 1:n) %&gt;% 
# 创建滞后和当前治疗和结果值
mutate(Z1 = rnorm(n, 0, 1),
X1 = (0.1 * Z1) + rnorm(n, 0, sqrt(0.99)),
Y1 = (0.1 * Z1) + (0.4 * X1) + rnorm(n, 0, sqrt(0.822)),
Z2 = (0.2 * Z1) + (0.4 * X1) + rnorm(n, 0, 1),
X2 = (0.1 * Z2) + (0.4 * X1) + rnorm(n, 0, sqrt(0.5196)),
# X1 对 Y2 的间接影响是什么？
Y2 = (0.2 * Z2) + (0.4 * X2) + (0.4 * Y1) + rnorm(n, 0, sqrt(0.4582)))

我如何确定 X1 的间接影响 -&gt; Y2？X1 导致 Z2 发生一些变化，进而导致 Y2 发生一些变化。我如何确定 X1 对 Y2 的影响，经过 Z2 过滤后如何？
请注意，我并不是在寻求一种估算方法（我现在正在学习边际结构模型）。我想知道如何根据我模拟的信息确定滞后间接效应是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/658969/interpreting-indirect-lagged-treatment-effects-when-simulating-panel-data</guid>
      <pubDate>Thu, 19 Dec 2024 14:40:12 GMT</pubDate>
    </item>
    <item>
      <title>曲线拟合SCILAB/MATHLAB发散解释</title>
      <link>https://stats.stackexchange.com/questions/658968/curve-fitting-scilab-mathlab-divergence-explanation</link>
      <description><![CDATA[我正在完成一个研讨会，会上我会得到一组数据。然后我必须预测数据范围之外的未来数据点。
我以图形方式解释了数据，并发现它可以用以下类型的正弦函数来近似：
f(t) = Asin(WT + k) + at + b
我编写了代码来执行以下操作：
找到函数参数的粗略初始拟合以确保更快的收敛，然后编写代码使用 L2 范数评估 f(t) 和每个数据点之间的误差幅度。之后，通过递归算法，它将创建一些噪声并评估新的噪声参数的误差，并将其与初始拟合进行比较。并确定哪个误差较小，然后继续进行新的拟合。
现在我的问题来了，根据噪音的大小和我运行算法的次数，我会得到荒谬的结果。
在当前模型中，我运行 100 次循环会得到很好的结果，但 1000 次循环的精度会低于初始拟合！此外，如果我从一条线开始，我会发散我输入的任何噪声/迭代。
有没有关于曲线拟合收敛/发散的论文可以读，因为我对这个领域非常陌生。另外，有谁知道为什么会发生这种情况吗？
我的代码已经过审查，没有任何逻辑缺陷，但我认为我缺乏曲线拟合理论……
以下是 PARA 作为初始参数的代码。
function y = MODEL(x, PARA)

y = PARA(1)*sin(A(:,1)&#39;*PARA(2))+PARA(4) + PARA(5)*A(:,1)&#39; + PARA(6)

endfunction

function err = myerror(PARA,A)
B=zeros(size(A,1))
B = PARA(1)*sin(A(:,1)&#39;*PARA(2))+PARA(4) + PARA(5)*A(:,1)&#39; + PARA(6) - A(:,1)&#39;
err = norm(B,2)

endfunction

function NPARA = fit_rand(PARA, A, 错误, N)
    M = 零(1,N+1)
    
    M(1) = myerror(PARA,A)
    噪音=0.2
    对于 i = 1:N
        我 = 兰特(1,6) - 0.5
        I = I*噪声
        NPARA = PARA + I.*PARA
        M(i+1) = myerror(NPARA,A)
        if (err(NPARA, A) &lt; err(PARA, A)-1)
            帕拉 = 尼帕拉
        结尾
    结尾
    
结束函数
]]></description>
      <guid>https://stats.stackexchange.com/questions/658968/curve-fitting-scilab-mathlab-divergence-explanation</guid>
      <pubDate>Thu, 19 Dec 2024 14:29:32 GMT</pubDate>
    </item>
    <item>
      <title>具有多个预测变量的 OLS 模型的成对检验</title>
      <link>https://stats.stackexchange.com/questions/658967/pairwise-tests-for-ols-model-with-multiple-predictors</link>
      <description><![CDATA[我想请教以下问题：
我的 LR 模型 ols(formula=&quot;Income~ Major + Experience&quot;)，其中 Major 是分类预测因子，而 Experience 是尺度预测因子。
这两个预测因子都很重要，我想知道分类预测因子在哪些层面上有所不同。
问题是，经典的 Python 事后检验不会根据其他预测因子的贡献进行固有调整，而是仅基于正在检查的预测因子。
我只找到了 statsmodels.regression.linear_model.OLSResults.t_test_pairwise，但我不确定它在存在交互的情况下如何工作。
有人能告诉我在具有多个预测因子（有和没有交互）的 OLS 模型中进行成对测试的最佳方法是什么吗？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658967/pairwise-tests-for-ols-model-with-multiple-predictors</guid>
      <pubDate>Thu, 19 Dec 2024 14:21:19 GMT</pubDate>
    </item>
    <item>
      <title>在混合模型中的部分合并过程中，聚类估计值消失或超出总体估计值</title>
      <link>https://stats.stackexchange.com/questions/658964/cluster-estimates-going-away-or-beyond-grand-estimates-during-partial-pooling-in</link>
      <description><![CDATA[我认为我对混合模型中部分池化的主要目标和特征有相当好的理解。然而，部分池化的实际执行中有一些细节与我期望从各个集群得到的行为相冲突。例如，在下面我将链接的所有三个演示中，使用了各种表达式来表明特定于集群的截距和斜率估计应该向样本中相应的总体估计移动（也允许保持静止）。但是，如果您仔细跟踪集群估计从无池化到部分池化版本的一些可视化运动，您就会看到集群估计实际上如何沿着各个轴远离总体估计。在某些情况下，集群估计值也可能超出总体估计值。
https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/
https://towardsdatascience.com/when-mixed-effects-hierarchical-models-fail-pooling-and-uncertainty-77e667823ae8
https://m-clark.github.io/posts/2019-05-14-shrinkage-in-mixed-models/
至少定义集群截距重新定位的公式（参见上面的中间链接和此视频讲座）表明，单个集群的移动范围应限制在初始无合并位置和总体估计值之间（据我所知，如有必要，请纠正我）。但是，上述相互矛盾的观察结果是否与同一模型中随机截距和斜率的存在及其相关性有关？还没有拿尺子，但我的直觉告诉我，虽然聚类估计值可以沿着单个轴发散，但也许在部分池化期间整体斜边会变小。错误：我实际上拿了尺子，通过从屏幕上测量，由于部分池化，至少有一个整体距离增加了（参见最后列出的网站、df = create_data(sd_int = .25, sd_slope = 1) 的图和右上角的一个聚类）。
如果观察到的行为不是由错误引起的，而且我没有误解什么，那么原因能否从直观的实际意义上得到解释。为什么这种行为是有益的，尽管它似乎与部分池化的主要原则不一致。为什么不让所有的聚类估计值都沿着截距和斜率轴更接近总体估计值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658964/cluster-estimates-going-away-or-beyond-grand-estimates-during-partial-pooling-in</guid>
      <pubDate>Thu, 19 Dec 2024 12:35:28 GMT</pubDate>
    </item>
    <item>
      <title>我得到的部分 McFadden 伪 R^2 为负数。这可能吗？</title>
      <link>https://stats.stackexchange.com/questions/658963/i-got-a-negative-number-for-the-partial-mcfaddens-pseudo-r2-is-this-possible</link>
      <description><![CDATA[对于 R 中的逻辑回归，我尝试分别计算一个预测变量的 McFadden 偏 R 平方。我使用了以下代码，该代码来自这个问题：如何计算 R 中仅一个变量的 McFadden r 平方？
model1 &lt;- glm(Q22_factor ~ Q24_1 + age, family = &quot;binomial&quot;, data = subset_data&quot;)
model_age &lt;- glm(Q22_factor ~ age, family = &quot;binomial&quot;, data = subset_data)

loss_full &lt;- ModelMetrics::logLoss(
actual = subset_data$Q22_factor,
predict = predict(model1, type = &quot;response&quot;)
)

loss_reduced &lt;- ModelMetrics::logLoss(
actual = subset_data$Q22_factor,
predict = predict(model_age, type = &quot;response&quot;)
)
(loss_reduced - loss_full)/(loss_reduced)

在我的数据上使用此代码，我得到了负结果 (-0.269)。有人知道这是否可能，或者我的代码是否出了什么问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/658963/i-got-a-negative-number-for-the-partial-mcfaddens-pseudo-r2-is-this-possible</guid>
      <pubDate>Thu, 19 Dec 2024 12:32:24 GMT</pubDate>
    </item>
    <item>
      <title>具有（非平方）L2惩罚的正则化属性[重复]</title>
      <link>https://stats.stackexchange.com/questions/658960/regularisation-properties-with-the-not-squared-l2-penalty</link>
      <description><![CDATA[我一直在寻找有关线性回归设置中 L2 范数惩罚的正则化属性的资料。我的意思是，例如，当使用 L2 范数而不是平方 L2 范数作为惩罚时的收缩属性（所以我不是在谈论岭回归）。我正在思考的问题如下：
$$
\min_{\beta} \frac{1}{n}\|y - X\beta\|_2^2 + \lambda\|\beta\|_2,
$$
其中 $\beta$ 是实向量，$X$ 是实矩阵，$y$ 是实向量，$\lambda$ 是正实标量。
有谁知道关于这个问题的正则化性质的讨论好的资料吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658960/regularisation-properties-with-the-not-squared-l2-penalty</guid>
      <pubDate>Thu, 19 Dec 2024 11:20:10 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归中使用 Loess 平滑变量与其他预测因子</title>
      <link>https://stats.stackexchange.com/questions/658954/using-a-loess-smoothed-variable-with-other-predictors-in-linear-regression</link>
      <description><![CDATA[我正在运行一个普通最小二乘回归分析，其中有 9 个预测变量，2 个数值变量，5 个二进制 (1/0) 变量和 2 个分类变量。我的一个预测变量 (pred3) 与响应具有明显的非线性关系，如所附散点图所示。我拟合了一个线性模型，没有转换任何预测变量，并得到了 $R^2$ 值为 0.57。我希望我的模型具有较高的 $R^2$ 值。如果可能的话，我想避免交互项。为了解释 pred 3 和响应之间的非线性关系，我遵循了 ChatGPT 的建议，其中我拟合了一个形式为 pred3 ~ response 的 loess 平滑模型，然后在 lm() 模型语句中使用了 pred3 的 loess 预测值（参见下面的代码片段）。这导致 $R^2$ 值为 0.95。但是，我并不完全确定这是否是预测我的反应的有效方法。有人同意这个想法或有什么建议吗？我尝试过使用广义加性模型和多项式模型，但它们似乎并没有改善我的模型拟合度。请让我知道！
loess_fit=loess(pred3 ~ response,data=data)
loess_pred3=predict(loess_fit)
model=lm(response ~ pred1+pred2+loess_pred3+pred4+pred5+pred6+pred7+pred8+pred9,data=data)
]]></description>
      <guid>https://stats.stackexchange.com/questions/658954/using-a-loess-smoothed-variable-with-other-predictors-in-linear-regression</guid>
      <pubDate>Thu, 19 Dec 2024 06:24:15 GMT</pubDate>
    </item>
    <item>
      <title>轻松理解混合模型中聚类变量和随机变量之间的区别</title>
      <link>https://stats.stackexchange.com/questions/658926/easy-way-to-understand-the-difference-between-a-cluster-variable-and-a-random-va</link>
      <description><![CDATA[假设我们有一个数据集，其中我们根据社会经济地位对一系列不同学校的数学成绩分数进行建模。使用 lme4 的适当模型将是：
lmer(math~ses + (ses | school), data=d)
我的学生经常混淆 ses 和 school 的位置。为了解决这个问题，我制作了一个 YouTube 视频，帮助学生识别他们的“聚类变量”。该视频为他们提供了三条规则来帮助识别他们的聚类变量：

这个变量在您的数据集中是否经常重复出现？（聚类变量将重复出现）
这个变量是否识别一个人？ （如果是，那就是您的聚类变量，跳过 #3）
此变量是否表示特定组？（如果是，那就是您的聚类变量）

对于此示例，学校将被重复（该学校的每个学生一行），它不会识别特定的人，但会识别特定的组。
我对我的解释一直不太满意，因为它留下了一些歧义。让我们修改示例以使我的规则失败。假设我们正在预测数学成绩，但这次，我们想添加种族作为预测因素。合适的模型可以是：
lmer(math~ses + ethnicity + (ses + ethnicity | school), data=d)
（假设 ses 和 ethnicity 的斜率实际上因学校而异）。
这个例子的问题是学生会感到困惑，特别是如果数据集尚未按学校排序。ethnicity 和 school 都符合标准：两者都重复，都不能识别一个人，并且都表示一个“群体”。当他们问为什么 ethnicity 不是时，我有点不知道如何解释为什么 ethnicity 不是一个群体。
关于如何使差异更具体，有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658926/easy-way-to-understand-the-difference-between-a-cluster-variable-and-a-random-va</guid>
      <pubDate>Wed, 18 Dec 2024 15:33:06 GMT</pubDate>
    </item>
    <item>
      <title>防止时间序列数据拆分中的数据泄露</title>
      <link>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</link>
      <description><![CDATA[我正在研究机械系统的故障检测问题，目标是确定故障类型。我使用的数据集对于每种类型的故障（目标标签）都有三种大小，每种故障大小都有四种不同的工作条件，如下图所示。请注意，数据集中的每个样本都是时间序列，由于样本数量太少而且太长，因此需要将每个样本分成固定长度的块。现在的问题是如何将每个块分配给训练集或测试集，以确保公平和无偏见的评估。

在之前的研究中，常见的做法是将所有块随机分成训练集和测试集。

使用这种方法，神经网络模型通常在测试集上实现近乎完美的性能。然而，这种方法似乎存在根本缺陷，因为将近似平稳的信号分成块会导致来自同一信号的块高度相似，而相似的块可能最终出现在两个集合中，从而导致严重的数据泄漏。为了说明这种数据泄漏，我将 t-SNE 算法应用于这些块。

在此图中，每种颜色对应特定的故障类型和故障大小。请注意，来自同一样本的块紧密聚集在一起。以下是放大版的图：

我认为应该根据故障大小来拆分块。例如，故障大小为 1 和 2 的样本块应包含在训练集中，而故障大小为 3 的样本块应包含在测试集中。这可确保测试集中不存在来自训练信号的任何信息。

现在我想问：

我关于数据泄露的说法正确吗？如果正确，是否有其他方法可以更严格地证明数据泄露，例如使用相似性指标或其他可视化？
您如何看待提议的拆分方法？基于故障大小的拆分是否足以防止数据泄露？如果不是，您会推荐哪些替代拆分策略来确保公平评估？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</guid>
      <pubDate>Tue, 17 Dec 2024 15:38:37 GMT</pubDate>
    </item>
    <item>
      <title>针对群体数据/种族数据的最自然机器学习模型类</title>
      <link>https://stats.stackexchange.com/questions/658871/most-natural-class-of-machine-learning-models-for-group-data-race-data</link>
      <description><![CDATA[我有一个学生考试成绩的数据集，如下所示：
班级 ID 班级大小 学生编号 智商 小时数 分数 前几名
1 3 3 101 10 98 1
1 3 4 99 19 80 0
1 3 6 130 3 95 0
2 5 4 93 5 50 0
2 5 5 103 9 88 0
2 5 8 112 12 99 0
2 5 1 200 10 100 1
2 5 2 90 19 78 0
3 2 5 100 12 84 0
3 2 7 102 13 88 1

我想建立一个机器学习模型，试图预测谁将成为前几名对于任何给定的 Class_ID，使用 IQ 和 Hours（学习小时数）作为特征，计算班级（即具有最高 Score 的学生）的得分。
换句话说，输入是班级中每个学生（例如 1 到 n）的 IQ 和 Hours，输出是概率向量 (p_1, ..., p_n)，其中每个 p_i 是学生 i 在班级中得分最高的概率。
这是我尝试过的：

最简单的方法是对 Score 使用回归，然后确定谁将在班级中取得最高分数。这种方法的问题在于，它不会产生谁最有可能在任何给定类别中获得最高分数的概率。

由于这是一个排名问题，因此自然的学习模型类别是使用 XGBoost 中的 XGBRanker 或 lightgbm 中的 LGBMRanker。不幸的是，输出是 相关性分数 列表，而不是概率列表，概率列表在概率方面没有自然解释。


解决这个问题的一个明显方法是在 xgboost 中的相关性分数上应用 softmax，但没有直接有意义的概率解释，如基于能量的模型（如 RBM 的能量函数）。事实上，我曾尝试过这样做，但概率变得非常极端（大多数概率集中在每个班级的一名学生身上，导致测试结果不佳且方差较大）

另一类学习模型是Top上的分类模型，如逻辑回归/决策树。但是，这种方法有两个主要问题。

首先，将每个学生视为训练样本不是一个好方法，因为例如，同一个班级可能有两个非常聪明（高智商）和勤奋（高小时数）的学生，如果很多班级都有很多这样的学生，那么传统的模型（如基于逻辑/树的模型）可能会难以进行训练。
为了解决上述将单个学生视为训练样本的问题，我们可以将每个班级视为一个训练样本。为此，我们“扁平化”我们的数据集并对 Top 进行多类分类：
Class_ID Class_size IQ_1 IQ_2 IQ_3 IQ_4 IQ_5 Hours_1 Hours_2 Hours_3 Hours_4 Hours_5 Score_1 Score_2 Score_3 Score_4 Score_5 Top
1 3 101 99 130 NaN NaN 10 19 3 NaN NaN 98 80 95 NaN NaN 3 
2 5 93 103 112 200 90 5 9 12 10 19 50 88 99 100 78 1
3 2 100 102 NaN NaN NaN 12 13 NaN NaN NaN 84 88 NaN NaN NaN 7

这种方法的问题在于，数字每个班级的学生人数不同，因此特征矩阵变得非常稀疏（因为不同班级的学生人数可能非常不同）
因此，逻辑模型/普通前馈神经网络/基于树的模型似乎也不适用于这类群体数据。
所以我的问题是，是否有任何自然的机器学习模型可以处理这些“群体数据”，就像我上面的数据集一样？
此外，在这个问题中，我只关心最终名列前茅的人（或者可能是前三名），所以排名并不是那么重要（例如，知道学生 4 排名第 11 位，学生 8 排名第 12 位并不重要）
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/658871/most-natural-class-of-machine-learning-models-for-group-data-race-data</guid>
      <pubDate>Tue, 17 Dec 2024 11:40:53 GMT</pubDate>
    </item>
    </channel>
</rss>