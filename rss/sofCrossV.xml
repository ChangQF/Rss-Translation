<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 03 Dec 2023 12:23:54 GMT</lastBuildDate>
    <item>
      <title>回归样条 - 公式中的“加”（加法）符号下标是什么？</title>
      <link>https://stats.stackexchange.com/questions/632936/regression-spline-what-is-the-plus-addition-symbol-subscript-in-the-formul</link>
      <description><![CDATA[我见过带有连续预测器的回归模型，其拟合为样条线，如下所示：

这个小“加法符号”是什么意思？我用红色圈出的下标？它只是一个“指针”吗？下面的下一个方程，其中给出了关于我们根据条件分配给 x 的特定值的额外信息？我不确定这是否意味着任何“添加”因为它是一个加号。它看起来不是那样，因为西格玛符号已经暗示了这一点？这对我来说似乎有点不必要，但我可能是错的。]]></description>
      <guid>https://stats.stackexchange.com/questions/632936/regression-spline-what-is-the-plus-addition-symbol-subscript-in-the-formul</guid>
      <pubDate>Sun, 03 Dec 2023 11:50:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们使用假设检验而不是仅仅让人们进行贝叶斯更新？</title>
      <link>https://stats.stackexchange.com/questions/632935/why-do-we-use-hypothesis-tests-instead-of-just-letting-people-do-bayesian-update</link>
      <description><![CDATA[如果这是一个愚蠢的问题，我很抱歉，我不太明白这一点，但我想知道为什么我们需要“离散化”我们使用假设检验进行判断。为什么我们不能在每次研究完成时，让人们报告数据、p 值和效应大小，然后报告数据如何改变他们的主观概率？
对于人们来说，拥有自己的某些陈述为真的概率，然后在研究中遇到新数据时更新该概率，似乎更有价值。
只有当数据“具有统计显着性”时才让人们这样做对我来说似乎有点武断。统计上不显着但仍然指向某个方向的数据仍然是应该更新你的信念的证据，只是不够强大，以至于你可以“合理地”相信这些数据。认为研究结论是正确的（不要期望很多时候都是错误的）。
我听到有些人说它是有害的，因为它会导致人们不发表没有统计意义的研究。
总的来说，对我来说，它在概念上似乎更清晰，每个人都有自己分配给陈述的概率，然后，当他们遇到一组新数据时，他们会更新自己的概率。然后，也许这些数据在统计上并不显着，而且更新也没有那么多，但这总比没有好。特别是如果这会导致科学界更健康的规范，所有研究都会发表。
如果这是一个非常愚蠢的问题，再次抱歉。]]></description>
      <guid>https://stats.stackexchange.com/questions/632935/why-do-we-use-hypothesis-tests-instead-of-just-letting-people-do-bayesian-update</guid>
      <pubDate>Sun, 03 Dec 2023 11:42:19 GMT</pubDate>
    </item>
    <item>
      <title>平稳分布估计迭代法中Kullback-Leibler散度单调递减的证明</title>
      <link>https://stats.stackexchange.com/questions/632933/proving-monotonic-decrease-of-kullback-leibler-divergence-in-iterative-method-fo</link>
      <description><![CDATA[简介
考虑一个具有理想属性（不可约、非周期、正循环）的良好马尔可夫链，其特征为转移矩阵 $P$ 和平稳分布 $\pi$。平稳分布满足方程：
$$
\pi = \pi P \标签 1
$$
这里，$\pi$是一个行向量，其总和等于1。
在实践中，直接求解 $(1)$ 对于小规模的 $\pi$ 是可行的维矩阵，但对于更大的矩阵，采用迭代方法。
平稳分布估计的迭代方法：
输入：转移矩阵$P$，迭代误差$\epsilon$

初始化 $\pi^{(0)}$，使元素之和为 1。
计算 $\pi^{(k)} = \pi^{(k-1)} P$。
如果 $\pi^{(k)}$ 和 $\pi^{(k- 1)}$小于$\epsilon$，停止迭代并输出$\pi^{( k)}$。否则，继续迭代。

我希望展示 Kullback-Leibler 散度 $KL(\pi^{(k)} \mid \pi)$ 在整个过程中单调递减迭代过程。
数值模拟
为了说明这种单调递减，考虑了五阶转换矩阵 $P$。
$$
P = \begin{pmatrix}
0 &amp; 0.25&amp; 0.25&amp; 0.25&amp; 0.25\\
0.2&amp; 0.2&amp; 0.2&amp; 0.2&amp; 0.2\\
0 &amp; 0.5&amp; 0 &amp; 0 &amp; 0.5\\
0 &amp; 1/3 &amp; 1/3 1/3 &amp; 1/3 0 &amp; 1/3\\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0
\end{p 矩阵}
$$
相应的平稳分布为 $\pi = [0.08759124, 0.4379562, 0.1459854, 0.10948905, 0.2189781]$
使用随机初始分布$\pi^{(0)} = [0.2, 0.2, 0.2, 0.2, 0.2]$，计算出的KL散度为如下：
$$
\开始{对齐}
KL(\pi^{(0)}\mid\pi) = 0.1736967812\\
KL(\pi^{(1)}\mid\pi) = 0.0219343265\\
KL(\pi^{(2)}\mid\pi) = 0.0022525586\\
KL(\pi^{(3)}\mid\pi) = 0.0006414772\\
KL(\pi^{(4)}\mid\pi) = 0.0000681666\\
\结束{对齐}
$$
该数值模拟支持观察到的单调递减。下一步是为这种现象提供严格的证明。
请注意，KL 散度定义为：
$$
KL(\pi^{(k)} \mid \pi) = \sum_{i=1}^n \pi^{(k)}_i \log \frac{\pi^{(k)}_i}{ \pi_i}
$$
将 numpy 导入为 np

# 转移矩阵
P = np.array([[0, 0.25, 0.25, 0.25, 0.25],
              [0.2,0.2,0.2,0.2,0.2],
              [0, 0.5, 0., 0., 0.5],
              [0, 1./3, 1./3, 0., 1./3],
              [0, 1., 0., 0., 0.]])
I = np.eye(P.shape[0])
A = I - P.T
b = np.ones_like(P[:, 0])
pi = np.linalg.solve(A, b)
pi = pi / np.sum(pi)
print(&quot;真实平稳分布 pi: &quot;, pi)

# 初始分布
pi0 = np.array([0.2, 0.2, 0.2, 0.2, 0.2])

# 计算 KL 散度
每股收益 = 1e-8
print(f&quot;KL(pi{0:&lt;2} || pi) = {np.sum(pi0 * np.log((pi0 + eps) / (pi + eps))):.10f}&quot;)
对于范围（10）内的 i：
    pi0 = pi0.点(P)
    kli = np.sum(pi0 * np.log((pi0 + eps) / (pi + eps)))
    print(f&quot;KL(pi{i+1:&lt;2} || pi) = {kli:.10f}&quot;)

谁能帮忙证明一下这个说法或者举个反例吗？实际上 K-L 散度是不必要的，我们只能使用 L2 范数，即表明 $|| \pi^{(k)} - \pi ||_2^2$ 减少到 0。
任何提示表示赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/632933/proving-monotonic-decrease-of-kullback-leibler-divergence-in-iterative-method-fo</guid>
      <pubDate>Sun, 03 Dec 2023 11:06:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 Sobol 指数的模型的非线性</title>
      <link>https://stats.stackexchange.com/questions/632931/nonlinearity-of-model-using-sobol-indices</link>
      <description><![CDATA[我正在分析一个计算要求较高的数值模型，我想证明非线性对我的问题起着一定的作用。我想使用一阶 Sobol 敏感性指数来实现这一点，方法是显示它们的总和小于 1。
但是，我有点不确定如何证明这一点，因为差异也可能来自 MC 模拟中采样的不确定性。
有人有这方面的经验吗？
我解决这个问题的第一个办法是假设检验可以作为解决方案，因为由于抽样问题，指数本身是随机的。对此有何看法？
提前谢谢您
索博尔]]></description>
      <guid>https://stats.stackexchange.com/questions/632931/nonlinearity-of-model-using-sobol-indices</guid>
      <pubDate>Sun, 03 Dec 2023 10:41:10 GMT</pubDate>
    </item>
    <item>
      <title>均值和方差</title>
      <link>https://stats.stackexchange.com/questions/632930/mean-and-variance</link>
      <description><![CDATA[令 X 为离散随机变量，使得 X = 0 的概率为 0.5，X = 1 的概率为 0.5。令 Y 为离散随机变量，当 X = 1 时，Y = 1；当 X = 0 时，Y = 0。X - 3Y 的均值和方差是多少（令 W = X – 3Y）？
计算如下
X 和 Y 平均值 0.5
X 和 Y 方差 0.25
平均X-3Y-&gt;&gt; 0.5-3*.5 = -1.5
方差 X-3Y -&gt;&gt; .25-3 * .25 = -0.5
所以答案是-1.5 ns -0.5
但给定的选项是 -1, 1
-1, 0.5
1, -1
0.5, 1
我哪里错了？]]></description>
      <guid>https://stats.stackexchange.com/questions/632930/mean-and-variance</guid>
      <pubDate>Sun, 03 Dec 2023 09:19:25 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归中的变量选择[重复]</title>
      <link>https://stats.stackexchange.com/questions/632925/variable-selection-in-logistic-regression</link>
      <description><![CDATA[所以我尝试在 R studio 中制作多元逻辑回归模型。我不知道该怎么做。对我来说似乎有意义的是根据响应单独对每个预测变量进行建模，看看是否有任何个体意义。如果单个预测变量和响应之间没有关系，为什么我要将其添加到我的模型中？
然后，我会创建一个仅包含单独显着的预测变量的模型，然后运行 ​​AIC/BIC 或 ridge/lasso 以减少或删除不显着的预测变量。我所得到的就是我的最终模型。
我只是想知道这是否是构建多元回归的明智方法，如果不是，还有什么更好的方法。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/632925/variable-selection-in-logistic-regression</guid>
      <pubDate>Sun, 03 Dec 2023 06:47:13 GMT</pubDate>
    </item>
    <item>
      <title>使用倾斜决策树理解聚类</title>
      <link>https://stats.stackexchange.com/questions/632924/understanding-clustering-using-oblique-decision-tree</link>
      <description><![CDATA[我想了解以下关于以下代码的帖子。
https://www.kaggle.com /competitions/optiver-realized-volatility-prediction/discussion/276137#1559582
首先，对维度为 [ time ids x stock ids ] 的特征数组（例如收益）进行主成分分析 (PCA)。有112只股票。输出是另一个包含 PC 的数组 c。该数组的维度为 [ 库存 ID x 主成分 ]。所有 112 个主成分均已选择。 c 是 sklearn 中 PCA 函数输出的转置。
p = otree_clusters(c, depth=3) # c 的形状为 [112 x 112]

def get_cut(X):
    y = X
    X = np.hstack((X, np.ones((X.shape[0], 1))))
    y2 = np.sum(y**2, axis=1, keepdims=True)/2
    y = np.hstack((y, y2, 0*y+1, y2 + 1))
    yX = np.matmul(y.T, X)

    minkowski = -np.ones((y.shape[1],1))
    明可夫斯基[-1,0] = +1.0
 
    A = np.matmul(yX.T, minkowski*yX)
    
    Ao = np.expand_dims(A[:-1,-1],1)
    Aoo = A[-1,-1]
    A = A[:-1,:-1] - np.matmul(Ao, Ao.T)/Aoo
    
    lam, v = sp.linalg.eigh(A, eigvals=(0,0))
    v = np.vstack((v, -np.dot(Ao[:,0],v)/Aoo))
    
    c = np.matmul(X, v) &gt; 0.0

    返回 c[:,0]


def otree_clusters(X, 最大深度):
    集合 = np.zeros((X.shape[0])).astype(int)
    对于范围内的 k（最大深度）：
        新集 = 0*集
        
        对于范围内的 kk(np.max(组)+1)：
            b = 集合==kk
            Xs = X[b, :] #x[特征 x 组件]
            c = get_cut(Xs)
            new_sets[b] = 2*sets[b] + c
        集 = 新集
        
    返回集

基本上，我想了解 otree_clusters() 函数如何计算 p。我相信 p 是股票集群的某个截止值？该函数的输入是 c。
在 get_cut(X) 函数中，用 1 和平方和等扩充矩阵 y 有何意义？
y = np.hstack((y, y2, 0*y+1, y2 + 1))
    yX = np.matmul(y.T, X)

同样，找到特征值与解决以下优化有什么关系？
我想了解这个函数内部发生了什么以及它如何链接到 $min(v, b)[ \sum_{ij} [ || y_i - y_j ||^2 * ( x_i . v + b ) * ( x_j . v + b ) ] ] $
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/632924/understanding-clustering-using-oblique-decision-tree</guid>
      <pubDate>Sun, 03 Dec 2023 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>如何从 glmmTMB 零膨胀（计数）模型中提取正确的单位减少和置信区间？</title>
      <link>https://stats.stackexchange.com/questions/632938/how-to-extract-the-correct-unit-decrease-and-confidence-intervals-from-glmmtmb-z</link>
      <description><![CDATA[我正在使用这个模型来计算羽翼鸟数量（作为计数）的单位减少量与ISA水平增加一定百分比（不透水表面积的百分比）的关系，这是我的零膨胀模型结构使用：
m1GTb_ns&lt;- glmmTMB(Fledglings~ISA+CS+LayDate+Mass_Fem+Year,data=DataGT_noNA, ziformula=~ISA+CS+LayDate+Mass_Fem+Year,family=poisson)

这里是摘要（m1GTb_ns）代码
这是我得到的汇总统计数据：
族：泊松 ( log )
公式：Fredglings ~ ISA + CS + LayDate + Mass_Fem + Year
零通货膨胀：~ISA + CS + LayDate + Mass_Fem + Year
数据：DataGT_noNA

     AIC BIC logLik 偏差 df.resid
    1120 1183 -542 1084 236


条件模型：
            估计标准。误差z值Pr(&gt;|z|)
（截距）0.67333 0.64199 1.05 0.2943
ISA -0.00368 0.00212 -1.74 0.0821 。
CS 0.10937 0.02228 4.91 0.00000092 ***
定位日期 0.01503 0.00519 2.90 0.0038 **
质量_Fem -0.00219 0.03622 -0.06 0.9518
2018年 0.02526 0.10232 0.25 0.8050
2019年 -0.13293 0.10319 -1.29 0.1977
2020年 -0.04784 0.10336 -0.46 0.6435
2021年 -0.15376 0.11429 -1.35 0.1785
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

零通胀模型：
            估计标准。误差z值Pr(&gt;|z|)
（截距）-10.8668 4.7877 -2.27 0.02322 *
ISA 0.0396 0.0116 3.42 0.00063 ***
CS -0.2493 0.1529 -1.63 0.10302
定位日期 -0.1065 0.0480 -2.22 0.02658 *
质量_Fem 0.6689 0.2601 2.57 0.01012 *
2018年 0.0398 0.8613 0.05 0.96313
2019年 0.9951 0.6572 1.51 0.12996
2020年1.2193 0.6701 1.82 0.06882 。
2021年 0.7888 0.8621 0.91 0.36021
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

现在，我们可以清楚地看到，在条件模型中，ISA 效应仅具有边际显着性。尽管如此，我还是有兴趣预测 ISA 一定增加（例如 70%）后幼鸟总数的减少。这是我使用 avg_comparisons 计算该值时得到的结果：
&lt;前&gt;&lt;代码&gt;&gt; avg_comparisons(m1GTb_ns, 变量 = 列表(ISA = 70))

术语对比度估计标准。误差 z Pr(&gt;|z|) 2.5 % 97.5 %
ISA +70 -2.73 0.786 -3.47 &lt;0.001 -4.27 -1.19
谁能向我解释一下为什么这里显示的 95% 置信区间不与零重叠？当我做出这个预测时，我很惊讶效果看起来很强大......
预先非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/632938/how-to-extract-the-correct-unit-decrease-and-confidence-intervals-from-glmmtmb-z</guid>
      <pubDate>Sun, 03 Dec 2023 01:34:15 GMT</pubDate>
    </item>
    <item>
      <title>暴露组不同随访时间的生存分析</title>
      <link>https://stats.stackexchange.com/questions/632910/survival-analysis-with-different-follow-up-times-in-exposure-groups</link>
      <description><![CDATA[我被要求帮助分析一些复发事件生存数据（使用 Anderson-Gill 模型），研究疾病的两种不同亚型（主要协变量）之间的疾病复发风险，并调整其他协变量。一切都好。
然后我被告知，亚型组在观察的时间段内存在系统性差异 - 一组的随访时间比另一组短。那么问题是，生存模型如何解释观察时间较长的群体有更大的机会发生更多事件？
我一直在尝试思考这是否违反了任何审查假设（独立的、非信息性的），但我认为没有？但我也无法清楚地回答他们的问题？有人可以帮忙吗？
（此问题相关：Cox 模型分组跟进时间不同)]]></description>
      <guid>https://stats.stackexchange.com/questions/632910/survival-analysis-with-different-follow-up-times-in-exposure-groups</guid>
      <pubDate>Sat, 02 Dec 2023 21:05:16 GMT</pubDate>
    </item>
    <item>
      <title>lme4 估计的线性混合效应模型的残差协方差结构是什么？</title>
      <link>https://stats.stackexchange.com/questions/632909/what-is-the-residual-error-covariance-structure-for-linear-mixed-effects-models</link>
      <description><![CDATA[最近我读了很多关于残差协方差结构的内容，特别是纵向模型。我发现在 lme4 中不可能指定这样的结构。所以我的问题是，它假设/估计什么样的结构？看起来就像 $I\delta$ ，其中 $I$ 是单位矩阵， $\delta$ 是（标量）残差，它被估计并显示为 summary()` 的随机效应输出的一部分，也就是说，对于仅具有随机效应术语，例如：
&lt;前&gt;&lt;代码&gt;+ (1|ID)

这是正确的吗？如果正确的话，这个结构有什么名称吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/632909/what-is-the-residual-error-covariance-structure-for-linear-mixed-effects-models</guid>
      <pubDate>Sat, 02 Dec 2023 21:01:14 GMT</pubDate>
    </item>
    <item>
      <title>指数原假设的排列检验：真的很糟糕吗？</title>
      <link>https://stats.stackexchange.com/questions/632907/permutation-test-for-exponential-null-hypothesis-really-bad</link>
      <description><![CDATA[找到了在指数分布样本下检验零假设的好公式，我想看看效果如何排列测试可以完成这项工作。假设没有错误，答案似乎是：非常糟糕！排列测试真的这么弱，还是这里出了问题？
挑战：给定指数分布变量的两个样本集 {x} 和 {y}，计算 p&lt; /em&gt;-原假设下的值 $H_0$（即，p = 如果抽取两个样本集，则观察到这些样本的概率来自相同的指数分布）。
正如上面链接的答案中所述，我们有两个很好的测试统计数据：

F 统计数据：F = &lt; span class=&quot;math-container&quot;&gt;$\frac{\bar{x}}{\bar{y}} \sim F(n_x, n_y)$
A 似然比检验统计量 L = $\frac{\mathcal{L}(H_0)}{\mathcal{L}(H_1)}$

为了测试结果，我选择查看大小为 9 的样本。我使用以下代码通过模拟在原假设下生成了 L 的抽样分布： 
将 numpy 导入为 np
从 scipy.stats 导入 permutation_test，percentileofscore

def LRTstat(x, y):
    “”“指数分布的似然比检验统计量”“”
    mx = np.mean(x)
    我的 = np.mean(y)
    m0 = np.mean(np.concatenate((x, y)))
    # 这些样本在均值相等的原假设下的可能性：
    L0 = np.prod(expon.pdf(np.concatenate((x, y)), 尺度=m0))
    # 这些样本在不同均值的备择假设下的可能性：
    L1 = np.prod(expon.pdf(x,scale=mx)) * np.prod(expon.pdf(y,scale=my))
    返回 L0 / L1

nx, ny = (9, 9)
纳西姆 = 10_000
L = np.zeros(nsim) # 似然比模拟
对于我在范围内（nsim）：
    x = np.random.exponential(size=nx)
    y = np.random.exponential(size=ny)
    L[i] = LRTstat(x, y)

现在，对于任何样本，我使用两种统计数据计算 p 值，如下所示：
# 生成随机样本
x = np.random.exponential(size=nx)
y = np.random.exponential(size=ny,scale=0.5) # 违反零假设使其变得有趣
mx = np.mean(x)
我的 = np.mean(y)
Fstat = mx/my
F_CDF = f.cdf(Fstat, nx*2, ny*2)
F_p = 2*min(F_CDF, 1-F_CDF)
LRT_p = 分数百分位数(L, LRTstat(x, y))/100
print(f&#39;样本 ({n1}) MeanX: {np.mean(x):.2f}\t({n2}) MeanY: {np.mean(y):.2f}\n&#39;
      f&#39;F 统计: {Fstat:.1f};\tCDF={F_CDF:.1%};\tp={F_p:.1%}\n&#39;
      f&#39;LRT统计：{LRTstat(x, y):.3f};\tp={LRT_p:.1%}&#39;)

因此该代码的典型结果是：
样本 (9) MeanX: 1.26 (9) MeanY: 0.36
F统计：3.5；累积分布函数=99.5%； p=1.1%
轻轨统计：0.036； p=1.3%

这两种方法的p值差异绝不会大于 1%。
现在，对于相同的样本数据，我使用 scipy 实现。我给它 10,000 次迭代，这是本例中排列空间的 20%（9+9 个样本）。这是代码：
res = permutation_test((x, y), LRTstat, vectorized=False,
                       n_resamples=10_000，替代=&#39;双面&#39;）
print(f&#39;排列 p={res.pvalue:.1%}&#39;)

在这种情况下，它显示p=15%，这比其他测试给出的 &lt;2% 高很多！我通过代码运行了一千多个测试，排列 p 值到处都是：几乎总是比 L 的其他测试大得多&gt; 值 &lt; 0.8，而且常常是荒谬的。 L = 0.14 的一种情况给出 p=96%！
此典型或预期性能是此应用程序中的排列测试吗？这是一个特别糟糕的应用程序吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/632907/permutation-test-for-exponential-null-hypothesis-really-bad</guid>
      <pubDate>Sat, 02 Dec 2023 20:51:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么简单线性回归模型中的估计系数具有分布？</title>
      <link>https://stats.stackexchange.com/questions/632895/why-do-the-estimated-coefficients-in-a-simple-linear-regression-model-have-a-dis</link>
      <description><![CDATA[当我们进行 OLS 时，据我了解，我们会进行所有导数以获得一些 $\beta_0$ 和  $\beta_1$ 最小化 SSE（观测数据和估计响应 $y_i$-hat 之间无法解释的错误）。既然我们已经优化了 SSE 并获得了 $\beta_0$ 和 $\beta_1$ 的值，那么为什么他们被视为随机变量？

它们有一个标准误差，因此有一个方差，我们还可以在这里看到一个 t 值。因此它们都有一个分布，我不明白为什么会这样。]]></description>
      <guid>https://stats.stackexchange.com/questions/632895/why-do-the-estimated-coefficients-in-a-simple-linear-regression-model-have-a-dis</guid>
      <pubDate>Sat, 02 Dec 2023 17:38:26 GMT</pubDate>
    </item>
    <item>
      <title>除了 John Uebersax 的文章之外，还有哪些关于贝叶斯无条件功效分析的好资源？</title>
      <link>https://stats.stackexchange.com/questions/632870/what-are-some-good-resources-on-bayesian-unconditional-power-analysis-besides-j</link>
      <description><![CDATA[我参考了文章“贝叶斯无条件功效分析”作者：John S. Uebersax (2007)。
我想进一步探讨这个主题。我还没有检查 Uebersax 的文章提到的参考文献，但我想知道是否还有其他关于该主题的好的参考文献或资源。
我优先（但不一定）寻找使用数值示例的资源，以检查我是否没有误解某些公式或算法。]]></description>
      <guid>https://stats.stackexchange.com/questions/632870/what-are-some-good-resources-on-bayesian-unconditional-power-analysis-besides-j</guid>
      <pubDate>Sat, 02 Dec 2023 07:41:42 GMT</pubDate>
    </item>
    <item>
      <title>用于确定两个非参数分布之间差异显着性的自适应样本大小</title>
      <link>https://stats.stackexchange.com/questions/632823/adaptive-sample-size-for-determining-the-significance-of-difference-between-two</link>
      <description><![CDATA[我有两个非参数分布 A 和 B，我想确定它们是否显着不同（例如，通过 U 检验的 p 值）。通常，我会从分布 A 中采样 $n=1000$ 来形成数据集 A，并类似地采样 $n=1000 $从分布B形成数据集B。然后，我将U检验应用于两个样本组A和B以获得结果。
我想知道是否有一种自适应方法来执行 U 测试。例如，我逐渐增加 A 和 B 的样本量，在某个时刻，对两组来说 $n=600$ ，我已经非常有信心 A和 B 有显着差异。所以我就到此为止，为剩下的 400*2 个样本节省时间。
我不确定每次增加 $n$ 时简单地执行 U 测试在科学上是否正确。有关于这个主题的论文或材料吗？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/632823/adaptive-sample-size-for-determining-the-significance-of-difference-between-two</guid>
      <pubDate>Fri, 01 Dec 2023 17:53:10 GMT</pubDate>
    </item>
    <item>
      <title>将中心极限定理应用于分段 PDF</title>
      <link>https://stats.stackexchange.com/questions/632793/applying-the-central-limit-theorem-to-a-piecewise-pdf</link>
      <description><![CDATA[对于大小为 1296 的大样本，我们正在研究由分段概率密度函数定义的独立且同分布的随机变量 $f(x) = \frac{1}{ 3} (I_{(0,1)}(x) + I_{(3,5)}(x))$
(a) 我试图找到 $ Y = |X_1 - 2| 的累积分布函数 (CDF) $。我的方法是用 Y 求出 X，代入 pdf，然后考虑绝对值，在各个区间内对 PDF 进行积分。如果有人能够审查我的方法并纠正任何可能的错误，我将不胜感激。
(b) 对于如此大的样本，我被要求使用中心极限定理来近似 $ P\left(\sum_{i=1}^{1296} X_i \leq 3600\right) $.我知道中心极限定理保证 $X$ 的总和将服从正态分布，但是我如何找到此正态分布的参数：$\mu, \sigma$?]]></description>
      <guid>https://stats.stackexchange.com/questions/632793/applying-the-central-limit-theorem-to-a-piecewise-pdf</guid>
      <pubDate>Fri, 01 Dec 2023 13:15:11 GMT</pubDate>
    </item>
    </channel>
</rss>