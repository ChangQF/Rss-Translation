<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 22 Nov 2024 15:18:52 GMT</lastBuildDate>
    <item>
      <title>我是否以正确的方式对加权分类调查数据进行统计显着性检验？</title>
      <link>https://stats.stackexchange.com/questions/657687/am-i-going-about-statistical-significance-testing-for-weighted-categorical-surve</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657687/am-i-going-about-statistical-significance-testing-for-weighted-categorical-surve</guid>
      <pubDate>Fri, 22 Nov 2024 15:12:36 GMT</pubDate>
    </item>
    <item>
      <title>关于神经网络反向传播的问题</title>
      <link>https://stats.stackexchange.com/questions/657684/questions-on-backpropagation-in-a-neural-net</link>
      <description><![CDATA[我理解如何以符号方式应用反向传播，用笔和纸计算公式。当真正将这些推导应用于数据时，我有两个问题：

假设某个梯度看起来像 $o_i \times w_{i,j}$，其中 $o_i$ 是第 $i$ 个神经元的输出，而 $w_{i,j}$ 是其权重之一。现在我有一批数据点，$o_i$ 中的每个数据点都有不同的值，那么我该如何用数字计算它？我是否只需对该批次中的所有数据点取平均值？
换句话说：假设我将误差（最后）定义为平均值，那么该平均值（期望值）是否只是与其余的反向传播一起传播，并且每当我看到输入数据的依赖性时，我只需插入平均运算符？
有人可以提供一些关于此的直觉吗？我的看法是，因为误差位于所有梯度的“分子”中，所以无论我们对它做什么，无论是平均还是求和，都可以简单地向后传播，您只需对您看到的所有项执行该运算符（例如平均）。如果您有一个常数（例如权重），它不会做任何事情，如果您有一个输出，您会对批次进行平均。这是合理的解释吗？

如果我们有一个较早的神经元 $N$，它在后面的层中作为输入出现两次，那么在进行反向传播时，我们可以在第二次遇到它时对其导数执行 $+=$，即我们可以天真地将各种梯度​​贡献相加。但是这个神经元可以以不同的方式参与后续神经元，它们可能有不同的数学表达式等。然而，我们可以天真地将其所有梯度相加，这是如何工作的？
这是一个很好的特性，但我不明白它是如何如此简单地发挥作用而没有任何问题。有人可以提供直观的解释吗？这似乎与“反向传播如何分块、分步骤地工作，因此确切的依赖关系不应该重要”有关，这是我目前的理解水平。

]]></description>
      <guid>https://stats.stackexchange.com/questions/657684/questions-on-backpropagation-in-a-neural-net</guid>
      <pubDate>Fri, 22 Nov 2024 14:20:10 GMT</pubDate>
    </item>
    <item>
      <title>Ian Goodfellow 的深度学习书中介绍 softmax 近似的原因</title>
      <link>https://stats.stackexchange.com/questions/657683/reason-for-softmax-approximation-in-ian-goodfellows-deep-learning-book</link>
      <description><![CDATA[在第 6.2.2.2 节（公式 6.31）中，他们指出：

总体而言，非正则化最大似然将驱动模型学习驱动 softmax 预测训练集中观察到的每个结果的计数分数的参数：
$$
\text{softmax}(\pmb{z}(\pmb{x},\pmb{\theta}))_i \approx \frac{\sum_{j=1}^{m}\pmb{1}_{y^{(j)}=i,\pmb{x}^{(j)}=\pmb{x}}}{\sum_{j=1}^{m}\pmb{1}_{x^{(j)}=\pmb{x}}}
$$

其中 $m$ 是训练集中的示例数量。
1. 如何得出这个近似值？
（此相关问题仅讨论了一个例子）
2.这个近似值是否等于以下内容：
$$
\begin{align}
&amp;\stackrel{?}{=}\frac{P_\text{data}(y=i,\pmb{x})}{P_\text{data}(\pmb{x})} \\
&amp;=P_\text{data}(y=i|x) \\
&amp;\approx P_\text{true}(y=i|x)
\end{align}
$$
此外，如果是，这是否就是为什么具有 softmax 的神经网络实际上学习所需的概率分布而不是 $[0,1]$ 上其他一些度量的原因？]]></description>
      <guid>https://stats.stackexchange.com/questions/657683/reason-for-softmax-approximation-in-ian-goodfellows-deep-learning-book</guid>
      <pubDate>Fri, 22 Nov 2024 14:02:49 GMT</pubDate>
    </item>
    <item>
      <title>YouTube 缩略图 A/B/C 测试中的留存模式分析</title>
      <link>https://stats.stackexchange.com/questions/657681/accounting-for-retention-patterns-in-youtube-thumbnail-a-b-c-testing</link>
      <description><![CDATA[我正在使用 YouTube 缩略图 A/B/C 测试功能，但遇到了令人难以置信的结果 - 我正在尝试找出原因。一种理论是 YouTube 在计算时没有考虑留存率，观看时间的巨大差异可能会影响计算结果。
上下文：
视频长达数小时（2-3 小时）。
大多数观众（约 50%）在第一分钟内就离开了
一小部分人观看了整个视频（7-10%）。
测试平台将展示次数（观看缩略图的人）平均分配给缩略图。
成功指标为：（缩略图变体的观看时间）/（所有变体的总观看时间）
示例场景：
如果 10 个人被分配到 2 个缩略图（每个 5 个），并且其中一个组恰好包含观看整个视频的单个观众，这可能会严重扭曲结果。我的直觉是，这种高方差需要更多样本才能获得可靠的结果。
问题：

根据观看时间百分比计算最佳缩略图时，是否需要考虑留存模式？或者这些信息是否不需要直接处理，因为它将反映在观看时间份额百分比中。

如果是这样，需要多少样本才能获得具有统计意义的结果？我需要用什么公式来计算这个？

]]></description>
      <guid>https://stats.stackexchange.com/questions/657681/accounting-for-retention-patterns-in-youtube-thumbnail-a-b-c-testing</guid>
      <pubDate>Fri, 22 Nov 2024 12:07:33 GMT</pubDate>
    </item>
    <item>
      <title>两组样本数不同但增长至相同值的相关性</title>
      <link>https://stats.stackexchange.com/questions/657680/correlation-of-two-sets-growing-to-the-same-value-but-different-number-of-sample</link>
      <description><![CDATA[如何获取两个不同长度的集合之间的相关性？我知道皮尔逊相关性不起作用。但是如果它们增长到相同的值，我可以做些什么吗？这就是我的意思。
假设我有两个集合：
[1, 2, 3, 4] 和 [1, 1, 2, 2, 1, 3]
我们可以看到它们的长度不同，但总和相同。
[1, 3, 6, 10] 和 [1, 2, 4, 6, 7, 10]
我们可以看到它们都累积到 10。
我在想，如果我将它们绘制成 x 轴上的累积和以及 y 轴上的原始点。我可以像“连接点”一样。之后，我在想也许我可以对它们进行卷积或者类似的事情，或者像它们的内积？不太确定我在说什么。
这能行得通吗？你能建议一些可以帮助解决这个问题的方法吗？
非常感谢！
编辑：
在回答这些数据代表什么的问题时，这个问题是一个信号处理问题。
系统的工作方式如下。我在一段时间内收到随机数量的尖峰。就我上面的示例而言，假设为 10 秒。
每 10 秒，我都会读取一些尖峰，但尖峰到达的时间与前一个尖峰的时间不同。这就是这个集合所代表的内容：
[1, 2, 3, 4] 和 [1, 1, 2, 2, 1, 3]
现在的问题是，这两个有多大关系？
编辑 2：
在这种情况下，“相关”是什么意思？
对于我的应用程序，“相关”的概念看起来像这样：
[5, 4, 3, 2, 1]
与...略有关系
[4, 3, 2, 1, 1, 2, 2]
如果我绘制到达时间的曲线，一个只是另一个的延迟版本。
我不知道如何称呼我试图描述的这个属性。希望这个描述有所帮助！
编辑 3：
给定：[5, 4, 3, 2, 1]
我们还可以说它与以下内容相关：
[3.9, 3.1, 2, 0.8, 1.2, 2, 2]
此外，我需要能够判断采样是晚还是早。
我们可以说
[3.9, 3.1, 1.9, 0.8, 1.2, 2, 2]
与给定值相比晚了。
并且
[2.5, 5, 4, 3, 0.5]
与给定值相比早了。
编辑4：
抱歉，这有点令人困惑。
什么是晚，什么是早？
给定 A = [5, 4, 3, 2, 1]
B = [4, 3, 2, 1, 1, 2, 2]
且 C = [1, 5, 4, 3, 2]
与 A 相比，B 晚了。
与 A 相比，C 早了。
直觉是这样的。

[5, 4, 3, 2, 1] -&gt; A：完美时机
[4, 3, 2, 1, 1, 2, 2] -&gt; B：晚时机
[1, 5, 4, 3, 2] -&gt; C：早期时机

看到 B 的某些部分与 A 相似，C 同样与 A 相似。它们有相似之处，但索引发生了偏移。
B 和 C 与 A“相关”。
此外，我们可以说
D = [3.9, 3.1, 2, 0.8, 1.2, 2, 2]
D 是 B 的一个略微不准确的版本。
在我的“相关”上下文中，D 也与 A 相关。
希望有所帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/657680/correlation-of-two-sets-growing-to-the-same-value-but-different-number-of-sample</guid>
      <pubDate>Fri, 22 Nov 2024 12:03:51 GMT</pubDate>
    </item>
    <item>
      <title>如何从 N-2 边际生成 N 维多元正态样本</title>
      <link>https://stats.stackexchange.com/questions/657678/how-to-generate-n-dimensional-multivariate-normal-sample-from-n-2-marginals</link>
      <description><![CDATA[我的“计算器”遇到了一个问题，它使用通过 N 维多元正态分布生成的样本。我在下面附上了一个代码片段来说明这个问题。
我的计算器从 sample_1 中提取：

M：对 sample_1 中的每个数字都敏感的数字
M_n：一个由 N 个数字组成的向量，每个数字都对 sample_1 中的一列且仅一列敏感

现在，我需要分析我的计算器对相关矩阵中一个特定元素的敏感度。我通过将 correlation_matrix_1 中的 (0, 1) 元素从 0.0 更改为 0.02 来实现。简而言之，问题在于 sample_2 中的第 3 列与 sample_1 中的第 3 列不同。这会导致 M_2 发生更改，这是不理想的结果。两个示例的屏幕截图都位于本消息的末尾，
现在的问题是：我如何从以下位置生成 sample_2 的第 0 列和第 1 列：

sample_1 的第 2 列 -&gt;修复 M_2
correlation_matrix_2

请注意，我必须能够对更大的矩阵执行此操作，尽管仍然需要每次更改一个矩阵元素。
import numpy as np

def main(correlation_matrix: np.ndarray, mc_seed: int = 1234,
n_trials: int = 10):
generator = np.random.default_rng(seed=mc_seed)
segment_factor_sample = generator.multivariate_normal(
mean=[0] * correlation_matrix.shape[0],
cov=correlation_matrix,
size=n_trials,
check_valid=&#39;raise&#39;)
returnsegment_factor_sample

if __name__ == &#39;__main__&#39;:
correlation_matrix_1 = np.array([[1.0, 0.0, 0.0],
[0.0, 1.0, 0.0],
[0.0, 0.0, 1.0]])
sample_1 = main(correlation_matrix_1)

correlation_matrix_2 = np.array([[1.0, 0.02, 0.0],
[0.02, 1.0, 0.0],
[0.0, 0.0, 1.0]])
sample_2 = main(correlation_matrix_2)


sample_1


sample_2]]></description>
      <guid>https://stats.stackexchange.com/questions/657678/how-to-generate-n-dimensional-multivariate-normal-sample-from-n-2-marginals</guid>
      <pubDate>Fri, 22 Nov 2024 11:33:44 GMT</pubDate>
    </item>
    <item>
      <title>GAMM 中的 AIC 值问题</title>
      <link>https://stats.stackexchange.com/questions/657675/problems-with-aic-values-in-gamms</link>
      <description><![CDATA[为了检验一个假设，我在 R 中使用广义加性混合模型，并使用 mgcv 包构建了以下模型：
 gam(Resp ~ s(Pred1, bs=&quot;cr&quot;) + s(Pred2, bs=&quot;cr&quot;) + s(Pred3, bs=&quot;cr&quot;) + s(Pred4, bs=&quot;cr&quot;) + ti(Pred3, Pred4) + s(Factor, bs=&quot;re&quot;), data=Data, family=binomial)

然后，我使用 dredge 函数（MuMIn 包）获取按 AIC 值递增排序的所有潜在模型的列表。在此列表中，前四个模型具有相同的 AIC 值，因此具有相同的 DeltaAIC 和 AIC 权重（见下图）。并且这种情况一直发生在以下模型中。
为什么会发生这种情况？这是估算 Pred1 以及 Pred3 和 Pred4 之间相互作用的问题吗？任何帮助都将不胜感激！
]]></description>
      <guid>https://stats.stackexchange.com/questions/657675/problems-with-aic-values-in-gamms</guid>
      <pubDate>Fri, 22 Nov 2024 11:07:37 GMT</pubDate>
    </item>
    <item>
      <title>使用看似不相关的回归检验两个不同回归的系数相等性</title>
      <link>https://stats.stackexchange.com/questions/657674/testing-equality-of-coefficients-from-two-different-regressions-with-seemingly-u</link>
      <description><![CDATA[我正在运行两个回归，一个嵌套在另一个中。
$$ y = \beta_1 X + \epsilon_1$$
$$ y = \beta_2 X + \beta_3 Z + \nu_2$$
我想评估两个方程式中的 X 系数是否相同 $$\hat\beta_{1} \neq \hat\beta_{2} ?$$
基本上，我想知道添加协变量 Z 是否会显著改变 y 和 X 之间的关联。
我尝试使用 R 执行此操作，如下所示：
#install.packages(&quot;systemfit&quot;)
library(systemfit)

# 指定两个方程式
eq2 &lt;- y ~ x + z
eq1 &lt;- y ~ x

# 将模型组合成一个系统
system &lt;- list(eq1 = eq1, eq2 = eq2)

# 拟合 SUR 模型
fit &lt;- systemfit(system, method = &quot;SUR&quot;, data=data_full2)

# 测试模型中 X 系数的相等性
linearHypothesis(fit, &quot;eq1_x = eq2_x&quot;)

但是，当我查看 eq2 的 fit 结果时，我发现与我分别计算每个回归时的情况非常不同。（使用 lm(y~x+z, data=data_full2)）。我理解两种情况下的结果可能会有所不同，但这是一个非常大的差异，因为在单独计算时，受限模型中的系数为 0.1，完整模型中的系数为 0.05，而在 SUR 计算中，两者均变为 0.1 左右。因此，当然，我的 linearHypothesis(fit, &quot;eq1_x = eq2_x&quot;) 命令的结果告诉我差异并不显著。
与两个独立的 lm() 相比，使用 systemfit() 命令运行系数时，系数变化如此之大，这正常吗？我是否仍应相信分析结果，即两个方程中的系数实际上并没有显著差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/657674/testing-equality-of-coefficients-from-two-different-regressions-with-seemingly-u</guid>
      <pubDate>Fri, 22 Nov 2024 10:43:59 GMT</pubDate>
    </item>
    <item>
      <title>在随机森林中绘制预测值与实际值时出现的离散垂直线</title>
      <link>https://stats.stackexchange.com/questions/657667/discrete-vertical-lines-when-plotting-predicted-values-against-actual-values-in</link>
      <description><![CDATA[我对我的数据集使用随机森林，其中我的响应是连续的，所有特征都是因子。当我绘制预测值与实际值的关系图时，该图显示离散的垂直线，如下图所示。有人知道我该如何解决这个问题吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657667/discrete-vertical-lines-when-plotting-predicted-values-against-actual-values-in</guid>
      <pubDate>Fri, 22 Nov 2024 09:37:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么 R 中的二项式家族（link="log"）的 glm 有时需要起始值？</title>
      <link>https://stats.stackexchange.com/questions/657665/why-does-glm-in-r-with-family-binomiallink-log-sometimes-require-start-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657665/why-does-glm-in-r-with-family-binomiallink-log-sometimes-require-start-value</guid>
      <pubDate>Fri, 22 Nov 2024 09:25:45 GMT</pubDate>
    </item>
    <item>
      <title>测试马尔可夫特性和模拟/验证的代码</title>
      <link>https://stats.stackexchange.com/questions/657664/code-for-testing-markov-property-simulation-validation</link>
      <description><![CDATA[我知道这个问题之前已经有人问过了（例如1、2、3），但这些答案都没有提供代码。
根据以上链接提供的信息（尤其是这篇论文），我已经实现了 R 代码来：

生成随机马尔可夫样本
运行 Pearson &amp;似然比$\chi^2$检验

代码
注意：我们不允许零概率转换；这会使测试统计数据的定义更加复杂。
library(&#39;ggplot2&#39;)
rbind.lappy = function(...){ # 便利
do.call(rbind,parallel::mclapply(...,mc.cores=7))
}
px.random = function(d=2){ # 生成随机转换矩阵
px = matrix(runif(d^2,.1,.9),d,d) # 随机数
px = sweep(px,1,rowSums(px),&#39;/&#39;) # 标准化
}
markov.limit = function(px){ # 获取极限分布
e1 = eigen(t(px))$vectors[,1]
p0 = e1 / sum(e1)
}
markov.sim = function(p0,px,nt,ni){ # 模拟样本
ns = length(p0)
state = list(sample(1:ns,ni,p=p0,rep=TRUE)) # 初始时间
for (i in 2:nt){ # 后续每个时间
state[[i]] = sapply(state[[i-1]],function(si){ sample(1:ns,1,p=px[si,]) })
}
names(state) = paste0(&#39;s&#39;,1:nt)
ms = data.frame(i=1:ni,state)
}
markov.test = function(ms){
ns = length(unique(ms[,2])) # 状态数
nt = ncol(ms)-1 # 时间点数
n_hij = array(1,c(ns,ns,ns)) # 二阶计数*
n_ij = array(1,c(ns,ns)) # 一阶计数*
# *初始化为 1 以避免除以零
for (m in seq(nt-2)){ n_hij = n_hij + 表(ms[paste0(&#39;s&#39;,m+0:2)]) }
  for (m in seq(nt-1)){ n_ij = n_ij + table(ms[paste0(&#39;s&#39;,m+0:1)]) }
  n_hi = rowSums(n_hij,dim=2)
  n_i = rowSums(n_ij, 暗淡=1)
  p_hij = 扫描(n_hij,1:2,n_hi,&#39;/&#39;)
  p_ij = 扫描(n_ij, 1, n_i, &#39;/&#39;)
  Q.p = sum(扫描(扫描(扫描(p_hij,2:3,p_ij,&#39;-&#39;)^2,2:3,p_ij,&#39;/&#39;),1:2,n_hi,&#39;*&#39;))
Q.lr = 2*sum(n_hij*log(sweep(p_hij,2:3,p_ij,&#39;/&#39;)))
Q = c(pearson=Q.p, likel.ratio=Q.lr)
p = pchisq(Q,df=ns*(ns-1)*(nt-1),lower=FALSE)
}
markov.test.pvs = function(nt,ni,ns=2,nk=100,lim=1){
pvs = rbind.lappy(1:nk,function(k){
set.seed(k)
px = px.random(ns)
if (lim){ p0 = markov.limit(px) }
else { p0 = rep(1,ns) / ns }
ms = markov.sim(p0,px,nt=nt,ni=ni)
pv = c(nt=nt,ni=ni,ns=ns,nk=nk,lim=lim,markov.test(ms))
})
}
# main
G = expand.grid( # 要扫描的参数
ni=c(30,100,300,1000), # 个体数（链）
nt=3:7, # 时间点数
ns=2, # 状态数
nk=1000, # 重复次数
lim=0:1) # 在稳定状态下初始化
pvs = rbind.lappy(split(G,1:nrow(G)),do.call,what=markov.test.pvs)
# 重塑 &amp;图
pvs.m = reshape2::melt(as.data.frame(pvs),id=colnames(pvs)[1:5])
pvs.m$init = factor(pvs.m$lim,0:1,c(&#39;uniform&#39;,&#39;limit&#39;))
pos = position_dodge(width=1)
g = ggplot(pvs.m,aes(y=value,x=&#39;&#39;,color=variable,lty=init)) +
facet_grid(&#39;ni~nt&#39;,labeller=label_both) +
geom_violin(scale=&#39;width&#39;,position=pos,fill=NA) +
geom_hline(yintercept=.05,lty=&#39;11&#39;) +
stat_summary(geom=&#39;text&#39;,position=pos,show.legend=FALSE,
fun.data=function(x){ data.frame(y=-.1,label=mean(x &lt; .05),size=2) }) +
labs(y=&#39;p value&#39;,x=&#39;&#39;,color=&#39;statistic&#39;) + ylim(-.1,1)
ggsave(&#39;Rplots.pdf&#39;,w=8,h=6)

结果

问题

我的代码是否正确模拟了马尔可夫样本？
我的代码是否正确实现了两个测试？
如果 1 &amp; 2、为什么 I 类（假阳性）错误率存在差异：


观察到的时间点数量（nt：水平面板）
观察到的链数量（ni：垂直面板）

这些趋势是预期的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657664/code-for-testing-markov-property-simulation-validation</guid>
      <pubDate>Fri, 22 Nov 2024 09:04:40 GMT</pubDate>
    </item>
    <item>
      <title>rugarch 包中条件方差的初始值是如何计算的？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657651/how-are-the-initial-value-of-conditional-variance-calculated-in-rugarch-package</link>
      <description><![CDATA[我正在尝试使用 rugarch 库验证我的零均值 GARCH(1,1) 模型的计算。起初，我认为条件方差的初始第一个值与无条件方差（python 中的 arch 包使用）的值相同，因为没有过去的回报，也没有过去的方差来计算它。
但是当我使用 garch_fit@fit$var 重新检查条件方差的第一个初始值时，它与无条件方差不同。
我尝试使用计算器手动计算无条件方差，它给出的输出与 uncvariance(garch_fit) 相同，这不是模型中条件方差的初始第一个值。那么，如果 GARCH 过程不是由无条件方差初始化的，那么第一个值是如何计算的呢？
以下是我的规范代码：
garch_spec &lt;- ugarchspec(
mean.model = list(armaOrder = c(0, 0), include.mean = FALSE), # 无 ARMA 项，零均值
variance.model = list(model = &quot;sGARCH&quot;, garchOrder = c(1, 1)), # GARCH(1, 1)
distribution.model = &quot;norm&quot; # 正态分布
)
garch_fit &lt;- ugarchfit(
spec = garch_spec,
data = data$log_return_pct,
solver = &quot;hybrid&quot;,
out.sample = 83
)

以及两者之间的区别第一个初始方差
&gt; uncvariance(garch_fit)
[1] 0.5865156
&gt; garch_fit@fit$var[1]
[1] 0.5869211
]]></description>
      <guid>https://stats.stackexchange.com/questions/657651/how-are-the-initial-value-of-conditional-variance-calculated-in-rugarch-package</guid>
      <pubDate>Fri, 22 Nov 2024 00:48:50 GMT</pubDate>
    </item>
    <item>
      <title>使用线性混合模型时，输出变量中缺失多少数据是可以接受的？</title>
      <link>https://stats.stackexchange.com/questions/657631/how-much-missing-data-in-the-output-variable-is-ok-when-using-linear-mixed-model</link>
      <description><![CDATA[我有重复测量数据，但由于缺失，我计划使用线性混合模型。我唯一的预测因子是时间，结果变量是定量测量的幸福感得分。目标是确定幸福感是否随着时间的推移而发生整体变化。
幸福感得分是通过四个时间点的季度调查收集的，参与人数如下：

时间 1：25 名参与者
时间 2：54 名参与者
时间 3：70 名参与者
时间 4：120 名参与者

由于大量缺失数据，近 80% 的答复不完整。许多参与者只参加了一次，特别是在时间 4，缺乏后续数据。为了解决这个问题，我过滤了数据集以仅包含至少参加过两个时间点的参与者。经过筛选后，参与人数如下：

时间 1：21 名参与者
时间 2：35 名参与者
时间 3：46 名参与者
时间 4：47 名参与者

此调整将缺失数据减少至约 36%。排除仅参加过一次的参与者是否合适？缺失数据多少才合适？
我非常感谢任何反馈或建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/657631/how-much-missing-data-in-the-output-variable-is-ok-when-using-linear-mixed-model</guid>
      <pubDate>Thu, 21 Nov 2024 17:24:52 GMT</pubDate>
    </item>
    <item>
      <title>glmmTMB nbinom1 计算不正确？coef</title>
      <link>https://stats.stackexchange.com/questions/657620/glmmtmb-nbinom1-computing-incorrect-coef</link>
      <description><![CDATA[我有固定效应模型（无随机效应）葡萄糖 ~ 基因型，其中基因型是具有两个水平的因子。拟泊松和负二项式 GLM 应该估计相同的系数。但是，glmmTMB(nbinom1) 不会计算与 glm(quasipoisson)、glmTMBB(nbinom2) 或 glm.nb 匹配的模型系数。由于系数不同，估计的组边际均值也不同。这些在函数之间应该相同并且等同于样本均值，对吗？发生了什么？
library(data.table)
library(MASS)
library(glmmTMB)
fd &lt;- data.table(
genotype = rep(c(&quot;WT&quot;, &quot;KO&quot;), each = 8),
tumors = rnegbin(8*2, mu = rep(c(5, 10), each = 8), theta = 1)
)
qp1 &lt;- glm(tumors ~ genotype,
family = quasipoisson(link = &quot;log&quot;),
data = fd)
qp2 &lt;- glmmTMB(tumors ~ genotype,
family = nbinom1(link = &quot;log&quot;),
data = fd)
nb1 &lt;- glm.nb(tumors ~ genotype,
data = fd)
nb2 &lt;- glmmTMB(tumors ~ genotype,
family = nbinom2(link = &quot;log&quot;),
data = fd)
coef(summary(qp1))
coef(summary(qp2))$cond
coef(summary(nb1))
coef(summary(nb2))$cond

 估计标准误差 t 值 Pr(&gt;|t|)
(截距) 2.431418 0.2891563 8.408662 7.631869e-07
genotypeWT -1.215023 0.6044945 -2.009981 6.410986e-02
估计标准误差误差 z 值 Pr(&gt;|z|)
(截距) 2.3225197 0.3044603 7.628318 2.378361e-14
genotypeWT -0.8076885 0.4786590 -1.687399 9.152671e-02
估计标准误差 z 值 Pr(&gt;|z|)
(截距) 2.431418 0.3515361 6.916553 4.627644e-12
genotypeWT -1.215023 0.5226885 -2.324564 2.009530e-02
估计标准误差 z 值 Pr(&gt;|z|)
(截距) 2.431419 0.3515362 6.916554 4.627620e-12
genotypeWT -1.215022 0.5226886 -2.324563 2.009535e-02

更新
在评论中，PBulls 表示我的期望只发生在特殊情况下，并且链接到帖子。特殊情况是预测因子是分类（因子）变量，这当然是我的情况，也是我发布这个问题的原因。该链接很有用，因为在回复中，用户 cardinal 给出了数学公式，说明如果预测因子是一个因子，那么为什么所有 GLM 的系数都会输出相同的系数（或者在其他链接中输出等效系数）。那么，为什么 glmmTMB(family = nbinom1) 不是这种情况呢？
我修改了该链接中用户 cardinal 回复的代码，以包含两个准泊松拟合。这些是无截距模型中的系数（因此这些系数应等于样本均值）。
 negbin poisson gaussian invgauss gamma qpoisson qpoissson_tmb
XX1 4.234107 4.234107 4.234107 4.234107 4.234107 4.234107 4.288181
XX2 4.790820 4.790820 4.790820 4.790820 4.790820 4.789353
XX3 4.841033 4.841033 4.841033 4.841033 4.841033 4.841033 4.811718

以下是带有截距的模型的系数。这里，X2 和 X3 的系数（我们试图估计的影响）与其他 glms 相差约 10%。
 negbin poisson gaussian invgauss gamma qpoisson qpoissson_tmb
（截距）4.234107 4.234107 4.234107 4.234107 4.234107 4.234107 4.2881807
XX2 0.556713 0.556713 0.556713 0.556713 0.556713 0.5011718
XX3 0.606926 0.606926 0.606926 0.606926 0.606926 0.606926 0.5235374
]]></description>
      <guid>https://stats.stackexchange.com/questions/657620/glmmtmb-nbinom1-computing-incorrect-coef</guid>
      <pubDate>Thu, 21 Nov 2024 15:14:54 GMT</pubDate>
    </item>
    <item>
      <title>统计检验两种测量社区组成的方法是否产生相同的分布？</title>
      <link>https://stats.stackexchange.com/questions/657572/statistical-test-for-whether-two-methods-of-measuring-community-composition-prod</link>
      <description><![CDATA[我正在测量 1 个地点的 3 个样本中捕获的 30 个分类群的群落组成（即丰度分布）。对于我的每个样本，我使用两种不同的方法测量了群落组成：DNA 宏条形码，产生约 1M 个读数的分布，以及对在地点拍摄的图像进行注释，产生约 1K 个注释点的分布。我想要一个统计测试来告诉我这两种方法是否产生了有意义的不同结果（因此我需要同时使用这两种方法才能捕获完整的多样性）或者它们是否产生了相同的结果（因此我只能使用其中一种）。
最好的测试是什么？
我考虑过的测试：

卡方拟合优度检验：我认为两种方法之间的量级差异会是一个问题。
Kolmogorov-Smirnov：需要连续分布，而我在名义类别上有一个离散分布。
PERMANOVA：似乎可以行得通，尽管重复次数太少，功效会很低。
Mantel 测试：似乎可以行得通，尽管重复次数太少，功效会很低。

还有其他想法吗？
更新：澄清实验/数据结构&gt;&gt;
我正在寻求测量固着生物的生物量。对于每个样本，我做了两件事：1) 拍摄固着生物的图像，在图像上创建分层随机点，并记录每个点下方的生物类群； 2) 刮取生物体，提取/扩增/测序其 DNA，并将分类单元分配给测序读数。
生成的数据集在 30 个分类单元中看起来像这样（虚拟数据）：
# 起始数据（图像注释点计数和读数
# metabarcoding)
df &lt;- data.frame(
Sample = c(&quot;S1&quot;, &quot;S2&quot;, &quot;S3&quot;, &quot;S1&quot;, &quot;S2&quot;, &quot;S3&quot;),
Method = c(&quot;Image&quot;, &quot;Image&quot;, &quot;Image&quot;, &quot;Metabarcoding&quot;, &quot;Metabarcoding&quot;,
&quot;Metabarcoding&quot;),
Taxa1 = c(500, 200, 1000, 100000, 200000, 150000),
Taxa2 = c(137, 70, 500, 80000, 270000, 130000),
Taxa3 = c(10, 90, 300, 500, 30, 160000)
)
样本方法 Taxa1 Taxa2 Taxa3
1 S1 图像 500 137 10
2 S2 图像 200 70 90
3 S3 图像 1000 500 300
4 S1 Metabarcoding 100000 80000 500
5 S2 Metabarcoding 200000 270000 30
6 S3 Metabarcoding 150000 130000 160000

然后我将其转换为每个样本/方法的分布：
# 每个样本的总注释点或读数
s1.tot.anns &lt;- 10000
s2.tot.anns &lt;- 10000
s3.tot.anns &lt;- 10000
s1.tot.reads &lt;- 1000000
s2.tot.reads &lt;- 1100000
s3.tot.reads &lt;- 900000

# 将 df 转换为每个样本/方法的分类群分布
df2 &lt;- df
df2[1, 3:5] &lt;- df2[1, 3:5] / s1.tot.anns
df2[2, 3:5] &lt;- df2[2, 3:5] / s2.tot.anns
df2[3, 3:5] &lt;- df2[3, 3:5] / s3.tot.anns
df2[4, 3:5] &lt;- df2[4, 3:5] / s1.tot.reads
df2[5, 3:5] &lt;- df2[5, 3:5] / s2.tot.reads
df2[6, 3:5] &lt;- df2[6, 3:5] / s3.tot.reads

样本 方法 Taxa1 Taxa2 Taxa3
1 S1 图像 0.0500000 0.0137000 0.00100000000
2 S2 图像0.0200000 0.0070000 0.00900000000
3 S3 图像 0.1000000 0.0500000 0.03000000000
4 S1 Metabarcoding 0.1000000 0.0800000 0.00050000000
5 S2 Metabarcoding 0.1818182 0.2454545 0.00002727273
6 S3 Metabarcoding 0.1666667 0.1444444 0.17777777778

无论这两种方法是否准确估计了生物量的分布，我感兴趣的是确定这两种方法是否产生了有意义的不同估计生物质。

Mike
]]></description>
      <guid>https://stats.stackexchange.com/questions/657572/statistical-test-for-whether-two-methods-of-measuring-community-composition-prod</guid>
      <pubDate>Wed, 20 Nov 2024 19:02:51 GMT</pubDate>
    </item>
    </channel>
</rss>