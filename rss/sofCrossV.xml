<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 10 Jan 2025 12:32:58 GMT</lastBuildDate>
    <item>
      <title>对于 OLS 假设，随机样本是否需要 IID</title>
      <link>https://stats.stackexchange.com/questions/659821/does-random-sample-need-to-be-iid-for-ols-assumption</link>
      <description><![CDATA[假设要为 OLS 回归 创建样本，我分 2 个阶段 在不同的总体中抽样数据。例如，在一个总体中，我有 5000 个数据点，我从该总体中选择了 1000 个数据。而在另一个总体中，有 3000 个数据点，我从该总体中选择了 500 个数据。
然后我 组合 2 个抽样数据集（因此，组合数据集有 1500 个数据点），并构建横截面 OLS 回归。
我的问题是，在这种情况下，随机样本的 OLS 假设 是否得到满足？对于随机样本，我们是否需要数据为 IID？
在另一个抽样选项中，我有相同的 2 个数据总体。但对于 1 个样本，我进行了 分层抽样，而对于另一个样本，我进行了 简单随机抽样。然后 合并 2 个抽样数据集。
在这种情况下，随机样本假设是否成立？]]></description>
      <guid>https://stats.stackexchange.com/questions/659821/does-random-sample-need-to-be-iid-for-ols-assumption</guid>
      <pubDate>Fri, 10 Jan 2025 11:50:05 GMT</pubDate>
    </item>
    <item>
      <title>二项式多层模型：如何“正确地”生成和解释响应尺度上的预测概率？</title>
      <link>https://stats.stackexchange.com/questions/659820/binomial-multi-level-model-how-to-correctly-generate-and-intepret-predicted-p</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659820/binomial-multi-level-model-how-to-correctly-generate-and-intepret-predicted-p</guid>
      <pubDate>Fri, 10 Jan 2025 11:43:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么因果参数不能提供最佳的预测性能？</title>
      <link>https://stats.stackexchange.com/questions/659818/why-causal-parameters-does-not-give-best-predictive-performance</link>
      <description><![CDATA[假设我们有一些协变量 $X$ 和目标 $Y$，它们来自线性因果模型。
我读到，估计因果参数可能会导致对测试数据的预测性能保守，而如果对测试数据的干预不是太极端，OLS 可能会提供更好的性能，因此我们通常更喜欢使用其他系数（如 OLS），这些系数与因果系数相比不那么保守。
但我不明白为什么会这样。如果我们知道因果模型（即生成数据的代理）的系数，为什么这些系数与来自“错误”模型（在某种意义上，它不是真正的底层模型）的其他一组系数相比表现不佳？我不明白这种直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/659818/why-causal-parameters-does-not-give-best-predictive-performance</guid>
      <pubDate>Fri, 10 Jan 2025 11:21:04 GMT</pubDate>
    </item>
    <item>
      <title>`contrasts<-`(`*tmp*`,value=contr.funs[1+isOF[nn]]) 中出现错误：由于数据不平衡，对比只能应用于具有 2 个或更多级别的因子？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659816/error-in-contrasts-tmp-value-contr-funs1isofnn-contrasts-can-be-a</link>
      <description><![CDATA[我在 R 中遇到以下问题，但我不知道如何解决：
我想运行线性混合模型，将反应时间建模为组和任务的函数。
尝试运行模型时
lmm.reaction.time.LT.RT.PD.CG &lt;- lmer(
reaction_time ~ group * task +
PANDA.total + FSS + education.years + 
PANDA.mood + 
(1 + group * task | subject_nr) + 
(1 + group * task | sentence),
data = df.master.correct.responses.no.rt.outliers.LT.RT.PD.CG.copy)

我收到此错误警告：
contrasts&lt;-(*tmp*, value = contr.funs[1 + isOF[nn]]) 中的错误：
对比只能应用于具有 2 个或更多级别的因子
我的所有预测因子至少有两个级别：
对比（df.master.correct.responses.no.rt.outliers.LT.RT.PD.CG.copy$group）
对比（df.master.correct.responses.no.rt.outliers.LT.RT.PD.CG.copy$task）
[,1]
CG 1
PD -1 
[,1]
LT 1
RT -1

简化随机结构不起作用，因为以下模型导致相同的错误警告：
lmm.reaction.time.LT.RT.PD.CG &lt;- lmer(
reaction_time ~ group * task +
PANDA.total + FSS + education.years + 
PANDA.mood + 
(1 | subject_nr) + 
(1 | sentence),
data = df.master.correct.responses.no.rt.outliers.LT.RT.PD.CG.copy)

`contrasts&lt;-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) 中的错误：
对比只能应用于具有 2 个或更多级别的因子

我尝试使用其他预测器而不是 task.sum 来运行模型，并且成功了，所以我认为问题来自这个变量，它有两个级别（RT：反应时间任务和 LT：语言任务）
由于 RT 的试验次数少于 LT，因此这两个级别之间存在很大的不平衡，这可能会导致此问题？
table(df.master.correct.responses.no.rt.outliers.LT.RT.PD.CG.copy$group, + 
df.master.correct.responses.no.rt.outliers.LT.RT.PD.CG.copy$task)

LT RT
CG 4341 724
PD 3955 791

我的数据框看起来像这样（我仅显示相关列和一些示例行）：
subject_nr group sentence condition reaction_time education.years PANDA.total PANDA.mood FSS.a task
CG01 CG 43lf lf 3.433987 12 25 2 23 LT
CG01 CG 43sf sf 7.078342 12 25 2 23 LT
CG01 CG 45sc sc 6.137727 12 25 2 23 LT
CG01 CG NA 左 7.198184 12 25 2 23 RT
PD12 PD 47sf sf 6.658011 11 28 3 57 LT
PD12 PD 13lc lc 5.986452 11 28 3 57 LT
PD12 PD NA 右 6.920672 11 28 3 57 RT

还有其他原因可能导致此错误吗？
也许列“句子”中的 NA 为“句子”用于随机结构？
如果由于这两个任务之间的数据点不平衡而发生错误，是否有办法以另一种方式构造我的数据框以便能够运行模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/659816/error-in-contrasts-tmp-value-contr-funs1isofnn-contrasts-can-be-a</guid>
      <pubDate>Fri, 10 Jan 2025 10:01:43 GMT</pubDate>
    </item>
    <item>
      <title>识别 PC 算法中的所有 v 结构</title>
      <link>https://stats.stackexchange.com/questions/659812/identifying-all-the-v-structures-in-the-pc-algorithm</link>
      <description><![CDATA[我对 PC 算法的最优性有一个简单的问题。
假设 PC 算法已经确定了图的骨架（即确定了所有边但没有确定它们的方向）。将此称为第 1 阶段。
据我了解，在第 1 阶段中删除边 (i,j) 的过程是选择一个条件集 C 并测试 $$X_i \perp\!\!\!\!\perp X_j | C.$$如果确认独立性，我们删除边并保存条件集 C。如果我们将 $Sep(X_i,X_j)$ 表示为满足此条件独立性的所有条件集的集合，我们可以说 $$C \in Sep(X_i,X_j)。$$ 然后我们继续处理其他边。
在第 2 阶段，我们开始通过识别 v 结构来定位边。假设 $$X-Y-Z$$ 形成一个 v 结构。如果我们保存的条件集 $C \in Sep(X,Z)$ 不包含 $Y$，则算法会识别它，因为这意味着没有依赖关系可以流经 Y。问题在于：我们只保存了我们遇到的 $Sep(X,Z)$ 中的第一个条件集，然后立即着手删除边。据我所知，这就是 PC 算法的重点：尽量减少我们必须进行的测试次数，并从小条件集开始。这是否意味着 $Sep(X,Z)$ 中还有其他我们不知道的集合？假设 $Y \in C$。难道不存在$C&#39;$，使得$Y \notin C&#39; \in Sep(X,Z)$，而这对我们来说是未知的，因此我们无法确定 v 结构的方向，尽管我们应该这样做？
如果我们实际上“缺少”v 结构，那么算法如何仍然是最优的，即恢复真实图的马尔可夫等价类？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659812/identifying-all-the-v-structures-in-the-pc-algorithm</guid>
      <pubDate>Fri, 10 Jan 2025 09:14:37 GMT</pubDate>
    </item>
    <item>
      <title>与夹层形式矩阵的 Frobenius 范数相关的不等式 [迁移]</title>
      <link>https://stats.stackexchange.com/questions/659811/inequality-related-to-the-frobenius-norm-of-sandwich-form-matrices</link>
      <description><![CDATA[我从一篇论文的证明中读到一个不等式。假设 $A, B, C, D$ 是矩阵，$\Vert \cdot \Vert$ 表示 Frobenius 范数，则 $\Vert A^{1/2}BA^{1/2} - C^{1/2}DC^{1/2} \Vert \lesssim \Vert B - D\Vert + \Vert A^{1/2} - C^{1/2}\Vert$。为什么这是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/659811/inequality-related-to-the-frobenius-norm-of-sandwich-form-matrices</guid>
      <pubDate>Fri, 10 Jan 2025 08:41:47 GMT</pubDate>
    </item>
    <item>
      <title>21 世纪第一季度机器学习理论中最重要的成果是什么？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659810/what-are-the-most-important-results-in-machine-learning-theory-in-the-first-quar</link>
      <description><![CDATA[21 世纪已经过去了四分之一。在过去的 25 年里，机器学习取得了巨大的进步。很容易找到总结过去 25 年机器学习领域最重要成果的调查。然而，这些结果大多不是理论结果。
考虑到这一点，您认为 21 世纪第一季度机器学习理论领域最重要的成果是什么？以下是我提名的一些成果：

多臂老虎机的有限时间分析。由 [Auer et al., 2002] 发起的一系列研究（[Audibert and Bubeck, 2010]、[Zimmert and Seldin, 2018]）已使人们对多臂老虎机的有限时间行为有了几乎全面的了解。

在线优化领域的建立。由 [Zinkevich, 2003] 发起的一系列研究定义了基本问题（对抗性老虎机、在线凸优化）并建立了该领域的基本技术（在线次梯度下降、OMD、FTRL、FTPL...）。

差分隐私的概念。这一概念产生了一系列新问题和研究方向。特别有趣的是差异隐私、泛化和自适应数据分析之间的联系（[Dwork 等，2015]）。


这些是我提名的 21 世纪前 1/4 学习理论中最重要的结果。您认为还有哪些重要结果？我很想听听您的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/659810/what-are-the-most-important-results-in-machine-learning-theory-in-the-first-quar</guid>
      <pubDate>Fri, 10 Jan 2025 07:07:59 GMT</pubDate>
    </item>
    <item>
      <title>理解相关二元解释变量和分类结果的模型</title>
      <link>https://stats.stackexchange.com/questions/659809/models-for-understanding-correlated-binary-explanatory-variables-and-categorical</link>
      <description><![CDATA[给定一个由相关二元变量和分类结果组成的数据集，我的目标是了解结果如何依赖于二元变量。假设样本大小为 1e5 的数量级，特征数量为 1e2--1e3 的数量级。哪些模型或方法适合这种类型的分析？现实世界中的哪些数据集符合此描述？]]></description>
      <guid>https://stats.stackexchange.com/questions/659809/models-for-understanding-correlated-binary-explanatory-variables-and-categorical</guid>
      <pubDate>Fri, 10 Jan 2025 06:27:31 GMT</pubDate>
    </item>
    <item>
      <title>重复测量混合效应模型的设置</title>
      <link>https://stats.stackexchange.com/questions/659808/setup-for-mixed-effects-model-with-repeated-measures</link>
      <description><![CDATA[我正在开展一个项目，该项目涉及从参与者那里收集一些生物特征数据。以下是基本设置：

该研究共涉及 28 名参与者。
参与者被分为两组（“积极”组和“消极”组）。
每个参与者完成几项任务。任务有两种方法（“A”和“U”），每种方法都以多个方向（“左”、“上”、“右”）完成，并在每个方法/方向上重复多次试验。

我的研究问题是响应变量与以下内容有何关系：

组主效应
方法主效应
按方法分组交互效应

我想尝试使用线性混合模型方法来解决这些问题。我计划使用 R / lme4，但我也愿意接受其他方法。这是一个与我的结构相同的示例数据框：
set.seed(6538)

example_data &lt;-
tibble(
Participant = rep(rep(paste0(&quot;Subj&quot;, 1:28), each = 15), times = 2),
Direction = rep(rep(rep(c(&quot;Left&quot;, &quot;Up&quot;, &quot;Right&quot;), each = 5), times = 28), times = 2),
Trial = rep(1:5, times = 3*28*2),
Group = rep(rep(c(&quot;Positive&quot;, &quot;Negative&quot;), each = 210), times = 2),
Method = rep(c(&quot;A&quot;, &quot;U&quot;), each = 420),
Response = runif(840, 8, 12)
)

实际数据框中唯一的区别（除了随机响应数据）是一些参与者缺少第 4 次和第 5 次试验的数据。所有患者在每个方法和方向上至少有 3 次良好的试验。
在我看来：

参与者应该贡献随机效应
组、方法和方向都应该是固定效应
模型的合理开价可能是 lmer(Response ~ Group * Method + Direction + (1|Participant/Trial), data = example_data)

我有一些问题：

这看起来像是一个合理的开始吗？
通过以这种方式构建模型，我是否会放弃任何潜在的统计能力？
我还应该问自己哪些其他类型的问题指导我以不同的方式（或不）设置模型？
]]></description>
      <guid>https://stats.stackexchange.com/questions/659808/setup-for-mixed-effects-model-with-repeated-measures</guid>
      <pubDate>Fri, 10 Jan 2025 03:41:16 GMT</pubDate>
    </item>
    <item>
      <title>使用什么样的规范化[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659807/what-kind-of-normalization-is-used</link>
      <description><![CDATA[yelp_features_1

0 1 2 3 4 ... 27 28 29 30 31
0 8 2.0000 1 0 0 ... 1.4545 1.7439 1.9363 0.000 142.0909
1 9 0.0000 0 0 0 ... 1.4545 1.7439 1.9363 0.000 142.0909
2 2 2.0000 1 0 0 ... 1.4545 1.7439 1.9363 0.000 142.0909
3 6 2.0000 1 0 0 ... 1.4545 1.7439 1.9363   0.000 142.0909
4 3 0.0000 0 0 0 ... 1.4545 1.7439 1.9363 0.000 142.0909
   .. ... .. .. .. .. ... ... ... ... ... ...
45949 3 0.3333 1 0 0 ... 0.7437 0.3631 1.8376 1.6182 170.4366
45950 1 0.6667 0 0 1 ... 0.7437 0.3631 1.8376 1.6182 170.4366
45951 3 1.0000 1 0 0 ... 0.8488 1.0167 1.7599 2.4910 133.1060
45952 2 2.0000 0 0 0 ... 0.8488 1.0167 1.7599 2.4910 133.1060
45953 1 1.0000 1 0 1 ... 0.8488 1.0167 1.7599 2.4910 133.1060

yelp_feature_2
-----------------
0 1 2 3 4 ... 27 28 29 30 31
0 0.0224 0.0705 0.4287 1.0000 1.0000 ... 0.0100 0.0149 0.5920 0.1393 0.4975
1 0.0249 1.0000 1.0000 1.0000 1.0000 ... 0.0100 0.0149 0.5920 0.1393 0.4975
2 0.0062 0.0705 0.4287 1.0000 1.0000 ... 0.0100 0.0149 0.5920 0.1393 0.4975
3 0.0174 0.0705 0.4287 1.0000 1.0000 ... 0.0100 0.0149 0.5920 0.1393 0.4975
4 0.0091 1.0000 1.0000 1.0000 1.0000 ... 0.0100 0.0149 0.5920 0.1393 0.4975
     ……………………………………
45949 0.0091 0.6951 0.4287 1.0000 1.0000 ... 0.4577 0.2687 0.3682 0.3035 0.8458
45950 0.0032 0.5739 1.0000 1.0000 0.0228 ... 0.6020 0.4030 0.4826 0.8010 0.1642
45951 0.0091 0.3500 0.4287 1.0000 1.0000 ... 0.6020 0.4030 0.4826 0.8010 0.1642
45952 0.0062 0.0705 1.0000 1.0000 1.0000 ... 0.7811 0.8557 0.4428 0.4478 0.5871
45953 0.0032 0.3500 0.4287 1.0000 0.0228 ... 0.7811 0.8557 0.4428 0.4478 0.5871

yelp_features_1 被标准化为yelp_feature_2。无法弄清楚使用了什么规范化。看起来像是对数。]]></description>
      <guid>https://stats.stackexchange.com/questions/659807/what-kind-of-normalization-is-used</guid>
      <pubDate>Fri, 10 Jan 2025 03:12:12 GMT</pubDate>
    </item>
    <item>
      <title>分析一个条件涉及内生分配而另一个条件涉及外生分配的设计是否有效？</title>
      <link>https://stats.stackexchange.com/questions/659803/is-it-valid-to-analyze-a-design-where-one-condition-involves-endogenous-and-anot</link>
      <description><![CDATA[我正在使用彩票设置进行一项实验，其中向参与者提供有关风险和奖励的信息。
设计包括两个因素：

条件：在一种条件下（自由序列），参与者可以选择信息的顺序（先有风险还是先有奖励）。在另一个（固定序列）中，它们被分配顺序（先有风险还是先有回报）。

序列顺序：人们首先看到的是风险还是回报。


这导致了 2（固定序列 vs. 自由序列）x 2（先有风险 vs. 先有回报）的设计。
因变量 (DV)：参与者对后续结果的兴趣（二进制：0/1）。
分析计划：
我们计划使用逻辑回归来预测 DV，预测因子如下：

条件（固定序列 vs. 自由序列）
序列顺序（先有风险 vs. 先有回报）
交互项（条件 × 序列顺序）

关键问题：
在“自由序列”条件下，参与者选择先查看风险还是先查看回报，从而使序列顺序具有内生性。在“固定序列”条件下，序列顺序是外生的（随机分配）。序列顺序的这种性质差异（内生与外生）是否会导致分析无效？如果是，我在测试假设时如何解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659803/is-it-valid-to-analyze-a-design-where-one-condition-involves-endogenous-and-anot</guid>
      <pubDate>Fri, 10 Jan 2025 01:35:56 GMT</pubDate>
    </item>
    <item>
      <title>相关性/巧合性测量中的统计数据[重复]</title>
      <link>https://stats.stackexchange.com/questions/659798/statistics-in-correlation-coincidence-measurement</link>
      <description><![CDATA[我从事实验物理工作，对所谓的“巧合”测量中使用的某些统计模型感到困惑。
为了说明背景，我们有可以检测单个粒子（在我的情况下是光子）存在的探测器。您可以想象一束连续的光子撞击探测器。总检测周期被分成非常小的时间段，当它检测到光子撞击传感器时，它会在任何给定的时间段输出 1，如果没有，则输出 0。在某些光源（例如激光器）中，数字统计遵循泊松分布 - 在任何时间段检测到光子的概率与所有其他时间段的概率无关。对于一个探测器，这是一个“单个”测量。当我们有两个探测器和两个光源时，“巧合”事件是每个探测器在同一时间箱中输出 1，即它们同时在各自的路径中检测到一个光子（以时间箱的分辨率为准）。
以下是问题的概述：
假设我们有两个探测器 $1$ 和 $2$。每个探测器都有一个光源输出一束光子。每个光源和每个探测器彼此独立。将每个探测器上的时间段称为$t_1,\ldots,t_N$（所有时间段的持续时间相同，即$t_1=t_2=\cdots=t_n=\Delta t$），总实验时间窗口称为$T=\sum^{N}_{i=1}t_i$。假设每个光源都遵循泊松统计，并且每个探测器实验窗口中的总计数平均值为 $R_1T$ 和 $R_2T$（$R_1$ 和 $R_2$ 是光源已知的固定发射率）。此外，假设 $R_1\Delta t\ll1$ 和 $R_2\Delta t\ll1$，因此我们几乎总是在任何时间段内得到 $0$ 或 $1$。我将在每个探测器上随机获得 $1$ 和 $0$ 的组合，如果我多次重复实验，每个探测器上的总计数将有一个大致等于平均值​​平方根的标准差。
我的问题是，巧合计数（当两个探测器在同一时间段上注册 $1$ 时为 $1$，否则为 $0$）是否也遵循泊松分布？我认为我知道如何找到实验的平均巧合计数，它应该是 $R_cT=T\Delta tR_1R_2$（$R_c$ 是巧合中的固定计数率）。在许多论文中，巧合计数被假定具有泊松统计量，这是有道理的，因为获得巧合计数的概率在不同时间应该彼此独立。但是，我也可以将巧合计数的数量表示为每个探测器上的单个计数的乘积，其中单个计数本身是泊松的 - 但两个泊松的乘积不是泊松的。如果它是泊松的，有没有严格的方法来证明它？]]></description>
      <guid>https://stats.stackexchange.com/questions/659798/statistics-in-correlation-coincidence-measurement</guid>
      <pubDate>Thu, 09 Jan 2025 21:09:36 GMT</pubDate>
    </item>
    <item>
      <title>样本均值平方和样本均值平方之间的方差差异[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659789/difference-in-variance-between-sample-mean-of-squares-and-square-of-sample-mean</link>
      <description><![CDATA[假设我们有独立同分布的随机变量 $X_1 \ldots X_N$，我们从中计算样本均值 $\overline{X}$。我对数量 $Var[\overline{X^2}]$ 和 $Var[\overline{X}^2]$ 感兴趣。前者可以用来估计或限制后者吗？
在上面，我使用 $Var$ 来表示其参数的方差，将参数视为随机变量。例如，在此符号中，平均值的经典结果是 $Var[\overline{X}] = Var[X]/N$。
我的尝试 #1：
对于第一个方差，可以用期望的形式写成
$$ Var[\overline{X^2}] = \frac{1}{N} Var[X^2] = \frac{1}{N} (E[X^4]-E[X^2]^2)$$
对于第二个，我们使用以下事实：$E(X) - \overline{X}$ 很小，因此
$$ Var[f(\overline{X})] \sim Var[f(E[X]) + f&#39;(E[X])\cdot(\overline{X}-E[X])] = f&#39;(E[X])^2 \cdot Var[\overline{X}] = \frac{f&#39;(E[X])^2}{N} \cdot Var[X] = \frac{f&#39;(E[X])^2}{N} \cdot (E[X^2]-E[X]^2)$$
得出
$$ Var[\overline{X}^2] \sim \frac{4}{N} E[X]^2 \cdot (E[X^2]-E[X]^2)$$
我得出的两个表达式不是立即可比较的，但 4 这个因子让我怀疑 $Var[\overline{X^2}] &gt; Var[\overline{X}^2]$..? 对这一说法的证明肯定能回答我的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/659789/difference-in-variance-between-sample-mean-of-squares-and-square-of-sample-mean</guid>
      <pubDate>Thu, 09 Jan 2025 17:06:04 GMT</pubDate>
    </item>
    <item>
      <title>何时使用哪种样本方差公式？</title>
      <link>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</link>
      <description><![CDATA[我知道样本方差的公式为
$$s^2 = \frac{\sum (x_i - \bar{x})^2}{n - 1}$$
我还知道样本方差的公式为“均值平方减均值平方”。
在计算给定样本的样本方差时，我使用了这两个公式，但发现它们给出了两个不同的答案，因此我想问，什么时候该使用第一个公式，什么时候该使用第二个公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</guid>
      <pubDate>Tue, 07 Jan 2025 05:32:19 GMT</pubDate>
    </item>
    <item>
      <title>在比较两个过程的输出时如何解释抽样变异性</title>
      <link>https://stats.stackexchange.com/questions/659519/how-to-account-for-sampling-variability-when-comparing-outputs-of-two-process</link>
      <description><![CDATA[我有一个粉末批次（批次 A），其粒度分布 (PSD) 已知。从这个批次中，我抽取两个单独的样本，用于工艺的两种不同方法（方法 A 和方法 B）。我想比较这两种方法的输出，看看它们是否产生粉末输出 PSD 结果。
但是，由于输入粉末批次 A 具有粒度分布（粒度范围），我采集的每个样本仅代表整体分布的一个子集，这可能会影响两种方法的输出结果。鉴于此，在比较方法 A 和 B 的输出时，我应该如何解释样本之间的粒度差异？
我是否应该通过考虑批次的整体 PSD（即粒度分布的平均值和标准差）来调整结果，并以某种方式将其计入两种方法的输出 PSD？]]></description>
      <guid>https://stats.stackexchange.com/questions/659519/how-to-account-for-sampling-variability-when-comparing-outputs-of-two-process</guid>
      <pubDate>Sat, 04 Jan 2025 05:02:37 GMT</pubDate>
    </item>
    </channel>
</rss>