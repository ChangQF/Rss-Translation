<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Thu, 27 Feb 2025 12:35:31 GMT</lastBuildDate>
    <item>
      <title>与正常错误的简单线性回归中响应的分布</title>
      <link>https://stats.stackexchange.com/questions/661917/distribution-of-response-in-simple-linear-regression-with-normal-errors</link>
      <description><![CDATA[假设我估计
 $$ y_t = \ alpha + \ beta \ times x_t + \ varepsilon_t $$ 
通过OLS，其中 $ \ VAREPSILON_T \ SIM \ MATHCAL {n}（0，\ SIGMA^2）$  $ 在观察过程中是独立的。这是一个标准结果，当 $ t_ {n-2}（\ alpha）$ 是学生的 $ t $ t $  -distribution  $ \ alpha $   - 预测响应的信心频段有条件在 $ x_0 $ 由
 \ begin {equation}
\ hat {\ alpha} + x_0 \ times \ hat {\ beta} \ pm t_ {n -2}（n -2}（\ alpha）\ times \ hat \ hat {\ sigma} \ sigma} \ times \ sqrt \ sqrt {1 + \ frac {1 + \ frac {1} {N} { \ edline {x}）^2} {\ sum（x_i- \ edimelline {x}）^2}}}，
\ end {equation} 
带有明显的符号。
 问题1：是否正确推断预测的响应 $ \ hat {y} _0 | x_0 = x_0 = x_0 $ 遵循一个位置范围（或非标准化）学生的 $ t $ t $   - class =“ Math-container”&gt; $$ lst \ left（\ hat {\ alpha} + x_0 \ times \ hat {\ beta}，var \ left（\ hat {\ alpha} + x_0 + x_0 \ times \ times \ hat n-2 \ right）？$$  
 问题2：假设 $ x_0 $ 本身是一个随机变量，具有已知分布（以及因此矩），与OLS参数估计无关。进一步假设该分布是对称的，并且在其平均值周围是单峰。在这种情况下，有没有一种方法可以挽救 $ \ alpha $ 的标准公式？例如，仅通过计算 $ var（\ hat {\ beta} \ times x_0）$ 来替换第三项，并使用]]></description>
      <guid>https://stats.stackexchange.com/questions/661917/distribution-of-response-in-simple-linear-regression-with-normal-errors</guid>
      <pubDate>Thu, 27 Feb 2025 12:11:52 GMT</pubDate>
    </item>
    <item>
      <title>不平衡的情况 - 控制样本</title>
      <link>https://stats.stackexchange.com/questions/661916/unbalanced-case-control-samples</link>
      <description><![CDATA[我正在研究由约40k个个体组成的数据库。
确定病例后，通过一定的临床诊断，我想看看病例和对照组之间的脑测量（平均灰质和白质量的平均皮质厚度）是否有所不同。
我有一个由约200个人组成的案例组，与我对照样本相匹配的人；对照样本中的多个个体与多种情况匹配。我确保仅将每个控件分配给任何情况下一次（如果有多个匹配项，则可以随机选择要匹配的情况）。
现在，我有一个匹配数字不均匀的示例。例如，情况1具有18个匹配的对照，情况2具有3个匹配的对照，案例3具有103个匹配的对照等。。
对于每个参与者，我有几个大脑测量值，我有兴趣比较病例对照之间的平均值以及半球之间的潜在差异。我该如何处理？
我进行了一些实验计算，以1：1的情况匹配病例和对照组，随机选择对照，结果在我做不同的种子时差异很大。我猜想控制样本中存在变化...我的直觉是根据与特定情况相匹配的控件数量加权控件的。]]></description>
      <guid>https://stats.stackexchange.com/questions/661916/unbalanced-case-control-samples</guid>
      <pubDate>Thu, 27 Feb 2025 11:05:08 GMT</pubDate>
    </item>
    <item>
      <title>关于$ \ vec {king}+（\ vec {warry}  -  \ vec {man}）\ oft \ vec {queen} $</title>
      <link>https://stats.stackexchange.com/questions/661915/regarding-vecking-vecwoman-vecman-approx-vecqueen</link>
      <description><![CDATA[我有一个关于嵌入式著名示例的疑问，我们可能会得到 $ \ vec {king}+（\ vec {warry}  -  \ vec {man}）\ oft vec {man}）\ oft \ vec {Queen}} $ 。我有一个论点，即为什么这不起作用，我想知道我的论点怎么了？
在简化的模型中；将有“城堡”的元素“君主”国际象棋“男人”与“城堡”相关联，“君主”国际象棋“女人”因此，以简化的方式，我假设我们有：
  $ \ vec {king} = \ alpha_1 \ cdot \ cdot \ vec {castle}+\ alpha_ 2 \ cdot \ cdot \ cdot \ cdot \ vec {monarch}+\ alpha_3 \ alpha_3 \ cdot \ cdot \ cdess \ cdess \ vec {chess}+\ cd $ \ cd plapen+cdpaspent {
在一个简化的世界中，我们可能拥有
 $ \ vec {queen} = \ alpha_1 \ cdot \ cdot \ vec {castle}+\ alpha_ 2 \ cdot \ cdot \ cdot \ vec {monarch}+\ alpha_3 \ alpha_3 \ cdot \ cdot \ cdes \ vec {wand} $ 。
现在，如果我们服用 $ \ vec {king}+（\ vec {warry}  -  \ vec {man}）$ ，我们得到 $ \ vec {Queen}+（1- \ alpha_4）\ cdot（\ vec {worme}  -  \ vec {man}）$ 。。
问题在于，在我的参数 $ \ alpha_4 $ 可能不是零，但可能是 $ 0＆lt; \ alpha_4＆alpha_4＆lt; 1 $ 。
我的论点怎么了？是否可以修改参数以表明 $ \ vec {king}+（\ vec {warry}  -  \ vec {man}）\ acter
为什么不是 $ \ vec {king}+\ beta（\ vec {woman}  -  \ \ vec {man}）\近似\ vec {queen} $ 
 更新： 
我会得到参数的工作，如果 $ \ vec {man} \近似\ vec {r}+\ vec {u} $ ，其中u是一个编码男性的矢量， $ \ vec {$ \ vec {  $ \ vec {V} $ 是编码女性的通用向量。这接近真相吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661915/regarding-vecking-vecwoman-vecman-approx-vecqueen</guid>
      <pubDate>Thu, 27 Feb 2025 10:30:19 GMT</pubDate>
    </item>
    <item>
      <title>是否有很好的参考来讨论与PCA和MCA使用调查权重的使用？</title>
      <link>https://stats.stackexchange.com/questions/661914/are-there-good-references-discussing-the-use-of-survey-weights-with-pca-and-mca</link>
      <description><![CDATA[我发现，R中的调查包允许使用带有主要组件分析的调查权重
但是，它似乎没有提供相同的对应分析或多个对应分析。另外，该软件包似乎没有提供参考，我可以在其中了解更多有关它的信息。
 有很好的参考讨论它吗？我对其背后的理论和数学细节感兴趣。
尽管我对调查权重+PCA的数学细节感兴趣，但我也有兴趣知道使用调查权重在理论上对于MCA是否也是可行的，因为我可能会尝试自己为将来的项目（用R或其他语言）（使用现有的实现），因为缺乏现有的实现。&gt; &gt; &gt; 。
我不确定目前缺乏实施的原因是任务的不可能/困难，还是其他开发人员缺乏兴趣。我认为在浪费时间做一项无法解决的任务之前，是个好主意。]]></description>
      <guid>https://stats.stackexchange.com/questions/661914/are-there-good-references-discussing-the-use-of-survey-weights-with-pca-and-mca</guid>
      <pubDate>Thu, 27 Feb 2025 10:01:58 GMT</pubDate>
    </item>
    <item>
      <title>是$ 100 \ times \ frac {x_i} {x _ {\ text {max}}} $，是一种用于缩放数据的公式吗？</title>
      <link>https://stats.stackexchange.com/questions/661912/is-100-times-fracx-ix-textmax-a-known-formula-for-scaling-data</link>
      <description><![CDATA[ i在表面以下土壤深度上有数据，并且深度值随着不规则的间距的增加而增加。请注意，第一个深度不是从 $ 0 $ 开始，而是在 $ 0.245 $  m之类的数字上，并继续 $ 45.320 $  $  $  $ 45.320 $。我想使用公式， $ 100 \ times \ dfrac {x_i} {x _ {x _ {x _ {\ text {max}}} $ span clast clast clast =“ Mather  $ x _ {\ text {max}} $ 是最大深度（ $ 45.320 $ 在这种情况下）。
我想知道这是否是已知的缩放方法，以及是否有名称。我知道可以通过 $ \ dfrac {x_i-x _ {\ text {min}}} {x _ {x _ {\ text {max}}} $  $ x _ {\ text {min}} $ 。另一个类似的方法是百分位数，它指示数据的百分比低于此特定数据点，但是我的公式是不同的，也就是说，最大数据的百分比（不是数据本身）是。
如果这不是已知的缩放方法，我将感谢您在正确参考此缩放方法方面的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/661912/is-100-times-fracx-ix-textmax-a-known-formula-for-scaling-data</guid>
      <pubDate>Thu, 27 Feb 2025 08:09:44 GMT</pubDate>
    </item>
    <item>
      <title>如何结合三个位置的Google趋势时间序列？</title>
      <link>https://stats.stackexchange.com/questions/661911/how-to-combine-google-trends-time-series-for-three-locations</link>
      <description><![CDATA[我想结合英格兰，威尔士和苏格兰的Google趋势（基本上，我希望没有北爱尔兰的英国趋势）。
将它们结合在一起的最佳方法是什么？目前，我相信我应该添加它们，然后将每个数据点与时间序列的最大复合数据点进行分配，然后将其乘以100。这是正确的方法吗？
此外，我在15天内下载数据，然后平均。我应该每天制作此复合材料，然后在15天内平均每个时间序列，然后做一个复合材料？]]></description>
      <guid>https://stats.stackexchange.com/questions/661911/how-to-combine-google-trends-time-series-for-three-locations</guid>
      <pubDate>Thu, 27 Feb 2025 07:49:47 GMT</pubDate>
    </item>
    <item>
      <title>计算平均测试统计量的差异</title>
      <link>https://stats.stackexchange.com/questions/661909/computing-the-variance-of-a-mean-test-statistic</link>
      <description><![CDATA[给定我有两个示例 $ s_x $ 和 $ s_y $ ，其中 $ s_x $ 从 $ s_y $ 是从 $ p_y $ 中绘制的。以下方式创建了两个样本之间的测试统计量：

我们将这两个样本修复到具有相同大小的 $ nk $ 。
对于每个样本，我将它们分组为 $ n $ 相等尺寸的批量 $ k $   - 我们表示 $ s_ {x_1}，\ dots，s_ {x_n} $ ，我们用 $ s_y $  as 我们以以下方式将批次配对： $（s_ {x_1}，s_ {y_1}），\ dots，（s_ {x_n}，s_ {y__n}，s_ {y_n}）
对于每对，我们计算地球移动距离（又称wasserstein-1距离），并将其表示为 $ d_1，\ dots，\ dots，d_n $ 。。
测试统计 $ \ bar {d} $ 是通过取用 $ d_1，\ dots，d_n $ 。。

 问题：修复总尺寸 $ nk $ ，我想知道 $ k $ 的大小如何变化class =“ Math-Container”&gt; $ \ bar {d} $ 。是否可以为 $ \ bar {d} $ 获得接近表单方差公式？我怀疑主要问题可能是距离度量 - 例如，如果我用估计的最大平均差异（MMD）替换距离度量，那么我将允许我获得 $ \ bar {d} $ 的方差公式？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661909/computing-the-variance-of-a-mean-test-statistic</guid>
      <pubDate>Thu, 27 Feb 2025 05:31:32 GMT</pubDate>
    </item>
    <item>
      <title>固定效应和跨越随机效应结构的模型选择</title>
      <link>https://stats.stackexchange.com/questions/661905/model-selection-for-fixed-effect-and-crossed-random-effect-structure-in-glmer</link>
      <description><![CDATA[我是（广义）线性混合效应模型的新手。任何帮助将不胜感激！
以下是我的研究设计，其中包含虚拟数据。我正在探索我在第1场比赛中操纵的参数对连续游戏2中参与者行为的影响。游戏1的刺激有所不同。
从图像中看到：

 para1和para2是一个概率的中位数和平均值
发生的刺激，在用户行为的运行时计算
第一场比赛和时间，来自Sigmoid功能。
 v1和v2是固定的，用于定义Sigmoid函数并在游戏1中编码条件。
 d1和d2是游戏1的每个块中发生的刺激数量。
第1场中的每个街区随后进行了4场比赛的4次试验，这些试验呈现给
参与者。第2场比赛中的每个试验都略有不同，以试验_id表示。因此，每4行代表第1场比赛中的一个街区和第2场比赛的四个不同试验。

   
有48名参与者（ID），每个参与者都经历了所有24个试验。因此，这是一项对重复措施的受试者内部研究。
我想适合第2游戏中的用户行为的binary_outcome的回归模型，而不是游戏1中的操作。但是，我不确定哪些因素可以最好地代表我在第1场比赛中的操纵，因为它们在用户行为和时间方面是动态计算的。 para1，para2，d1，d2高度相关（＆gt; 0.5）。
我做到了：
 ＃首先，测试不同的随机效果结构
m1＆lt;  -  glmer（binary_outcome〜1 +（1 | id），data = mydata，family = binorial）
m2＆lt;  -  glmer（binary_outcome〜1 +（1 | id） +（1 | trial_id），data = mydata，family = biinasial）

＃M2具有较低的AIC，然后添加固定效果，使用Para1（中位数），因为它显示出比平均值更广泛的分布，并给出更多的“粒度”。
complex_m1＆lt;  -  glmer（binary_outcome〜para1 +（1 | id） +（1 | trial_id），data = mydata，family = biinal = binomial）
complex_m2＆lt;  -  glmer（binary_outcome〜para1 + d1 + d1 + d2 +（1 | id） +（1 | tration_id），data = mydata，family = birneper = binorial）

＃与试验的测试互动效果，更改了优化器，因为该模型无法收敛
complex_m3＆lt;  -  glmer（binary_outcome〜（para1 + d1 + d2） *试验_num +（1 | id） +（1 | tration_id），data = mydata，family，family = binomial，
                     控制= glmercontrol（优化器=; bobyqa; quot））
complex_m4＆lt;  -  glmer（binary_outcome〜para1 + d1 + d1 + d2 + trial_num +（1 | id） +（1 | tration_id），data = mydata，family = binorial = binomial，
                     控制= glmercontrol（优化器=; bobyqa; quot））

＃将试验大致编码为难度条件，省略了试验的变化
complex_m5＆lt;  -  glmer（binary_outcome〜条件 *试验_num +（1 | id） +（1 | tration_id），data = mydata，family，family = binomial，control = glmercontrol（optimizer = optimizer =; nloptwrap; nloptwrap; quot; quot; quot;

＃测试试验的主要效果
mod_tn＆lt;  -  update（complex_m3，。〜。-trial_num）
＃para1
mod_median＆lt;  -  update（complex_m3，。〜。 -para1）
＃Para1 D1 D2的主要效果
mod_three_factors＆lt;  -  update（complex_m3，。〜。 -para1 -d1 -d2）

#Compare模型AIC
AICCTAB（complect_m1，complex_m2，complex_m3，complex_m4，complex_m5，mod_tn，mod_three_factors，mod_median，mnames = model_names = model_names，base = true，striges = true，loglik = true，loglik = true）
                  
 
我得到了结果：
  complex_m3获得最低的AIC，我可以选择此模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661905/model-selection-for-fixed-effect-and-crossed-random-effect-structure-in-glmer</guid>
      <pubDate>Thu, 27 Feb 2025 02:19:26 GMT</pubDate>
    </item>
    <item>
      <title>LAVAAN SEM模型：如何使用三级IV和R中的两级主持人建模2×3阶乘设计？</title>
      <link>https://stats.stackexchange.com/questions/661903/lavaan-sem-model-how-to-model-a-2%c3%973-factorial-design-with-a-three-level-iv-and</link>
      <description><![CDATA[我有一个2×3的阶乘设计：
•因子1（主持人）：源文本复杂性（2级：低，高）
•因子2（iv）：翻译质量（3级：坏，好，人）
我使用虚拟变量来编码三个翻译级别，但是我注意到在我的Lavaan SEM模型中，虚拟编码仅允许比较：
•人与坏
•好与坏
该模型永远不会直接比较良好与人。
  data  $ good_translation＆lt;  -  ifelse（data $  three_level_dummy_translation == 2， 
                                  1，0）
数据 $ human_translation＆lt;  -  ifelse（数据$  three&gt; three_level_dummy_translation == 3， 
                                  1，0）

＃创建与主持人“ sourceGroup”的互动术语“
数据 $ good_translation_complexity＆lt;  - 数据$  good_translation * 
                                     数据 $ sourceGroup
数据$  human_translation_complexity＆lt;  - 数据 $ human_translation * 
                                 数据$  SourceGroup

＃指定简化的SEM模型（无信任）
模型＆lt;  - &#39;
  ＃潜在变量
  智能= 〜Intelligent_1 + impelligent_2 +智能_3 + 
                    智能_5 +智能_6
  personificaiton =〜personificaiton1 + personificaiton2 + 
                      personificaiton3 + personificaiton4

  ＃直接对感知智能的影响（有节制）
  智能〜A1*good_translation + a2*human_translation +
                A3*good_translation_complexity + 
                a4*human_translation_complexity

  ＃直接影响感知的人格化（适度）
  ＃控制智力
  personificaiton〜B1*智能 +
                    a5*good_translation + a6*human_translation +
                    A7*good_translation_complexity + 
                    a8*human_translation_complexity

    ＃直接差异的定义参数：
  diff_intelligence：= a2 -a1       
    ＃对智力的影响差异（人与善）
  diff_personification：= a6 -a5       
    ＃直接影响人格化的差异（人与善良）

  ＃定义的适度参数（交互）差异：
  diff_mod_intelligence：= a4 -a3   
    ＃适度效果对智能的差异
  diff_mod_personification：= a8 -a7   
    ＃适度对人格化影响的差异

  ＃从IV到拟人化的调解（间接）效应 
  ＃ 智力：
  indirect_good：= a1 * b1＃良好的中介效果 
  ＃ 翻译
  indirect_human：= a2 * b1＃人类的调解效果 
  ＃ 翻译

  ＃针对拟人化的调解差异的定义参数：
  diff_med_personification：= indirect_human -indirect_good
&#39;
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661903/lavaan-sem-model-how-to-model-a-2%c3%973-factorial-design-with-a-three-level-iv-and</guid>
      <pubDate>Thu, 27 Feb 2025 01:24:03 GMT</pubDate>
    </item>
    <item>
      <title>Fisher信息的重新聚集[重复]</title>
      <link>https://stats.stackexchange.com/questions/661896/reparameterization-of-the-fisher-information</link>
      <description><![CDATA[  大家好，
我不明白为什么我们为什么有 $ l _ {\ phi}（\ phi）= l _ {\ theta}（h^{ -  1}（\ phi）（\ phi））$ span $不应该是或如何 $ l _ {\ theta}（h^{ -  1}（\ phi）（\ phi）= l _ {\ phi}（\ phi}（\ phi}（\ theta））也许下标使我在这里感到困惑。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661896/reparameterization-of-the-fisher-information</guid>
      <pubDate>Wed, 26 Feb 2025 22:08:26 GMT</pubDate>
    </item>
    <item>
      <title>从山脊回归中的重要特征相互矛盾的特征 - 如何解释？</title>
      <link>https://stats.stackexchange.com/questions/661893/conflicting-feature-importance-from-ridge-regression-how-to-interpret</link>
      <description><![CDATA[我正在使用多种方法来得出具有相关功能的数据集的特征重要性：
我正在为以下模型使用模型系数：
山脊，套索和弹性净回归
此外，我还将置换重要性用于随机森林模型，XGBoost模型的平均增益用于分析特征重要性。
这些方法中的大多数在最重要的特征中表现出合理的一致性，但是脊回归侧重于不同的特征。处理相关功能时，这是一种适当的方法吗？
编辑：我要解决的具体问题是预测某些（生理化学）特性，以及哪些特征对于预测它们最重要。山脊回归具有溶解度为最重要的特征（根据特征系数），其他模型却没有。]]></description>
      <guid>https://stats.stackexchange.com/questions/661893/conflicting-feature-importance-from-ridge-regression-how-to-interpret</guid>
      <pubDate>Wed, 26 Feb 2025 22:04:03 GMT</pubDate>
    </item>
    <item>
      <title>SVD的行告诉我们有关PCA的什么？</title>
      <link>https://stats.stackexchange.com/questions/661892/what-do-the-rows-of-svd-tell-us-about-pca</link>
      <description><![CDATA[If we have a matrix $X\in\mathbb{R}^{n\times p}$ with SVD $X = UDV^T$, we can say for example that the columns of $V$ are the principal directions and  $ ud $ 的列是主要组件（请参阅此答案）。）。）。）。
我们可以就PCA的这些行做出任何有趣的陈述吗？一位同事告诉我， $ v $ 的行与功能对每个主要组件的贡献相对应，但是我无法在此上找到任何证据或文献。]]></description>
      <guid>https://stats.stackexchange.com/questions/661892/what-do-the-rows-of-svd-tell-us-about-pca</guid>
      <pubDate>Wed, 26 Feb 2025 21:59:12 GMT</pubDate>
    </item>
    <item>
      <title>选择一种重复测量的统计测试方法，以确定测量值是否存在趋势</title>
      <link>https://stats.stackexchange.com/questions/661888/selecting-a-statistical-test-method-for-repeated-measurements-to-determine-if-th</link>
      <description><![CDATA[这可能是一个简单的问题，但是...
我与之合作的城市有一个固定墙，显示了装饰性面部的一些裂缝。我们无法判断这是否只是需要修复的面孔，还是墙壁实际移动（那将是不好的）。  从现场观测来看，我们看不到任何其他证据表明墙壁运动（例如墙后的土壤或墙壁倾斜的土壤 - 所以，这很好）。  我们已经使用了调查设备来测量8个不同位置的墙壁顶部（通常在发生裂缝的位置上）。  我们从8月底开始了测量结果，并每月（一周内+/-）与相同的设备和操作员进行了相同的位置。  我们对每个位置都有6个观察结果。  测量误差的设备为+/- 0.03英尺。  数据是北向和朝东的坐标对（北方的坐标就像y柱，朝东是x柱子）。  我不知道的一件事是，季节性天气是否会引起墙壁的某些自然运动，我们只衡量了大约半年 - 我们从夏天开始，现在已经低于零，地面被冻结了 - 因此，如果有一些自然运动，我不会感到惊讶。我确定我还没有足够的数据来回答这个问题。
无论如何，我想分析我必须查看的数据是否存在一个方向（墙正在移动），还是运动和观察误差或多或少是随机的，或者没有足够的数据说，我们需要继续测量。  我的直觉告诉我，这并没有显着移动，但是我希望以某种方式以某种程度的概率进行中间分析。
我首先想到按位置对数据进行线性回归分析，以查看 $ r^{2} $ 表示线性性，但是我认为如果墙壁只是来回振荡，这可能会显示出线性模式，尽管不是一个方向。  我想到了北向的T测试和t的t测试，以为如果动作是随机的，它将聚集在某个中心点周围（正常分布？也许？），但我并没有真正比较两个数据集的平均值。我正在比较随着时间的推移在同一位置进行的测量。  假设我的比较样本为零，我考虑了T测试，但这似乎也不正确。我有点狡猾，可以使用一些指导，将我指向正确的方向进行适当的测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/661888/selecting-a-statistical-test-method-for-repeated-measurements-to-determine-if-th</guid>
      <pubDate>Wed, 26 Feb 2025 21:42:01 GMT</pubDate>
    </item>
    <item>
      <title>自相关和信息丢失</title>
      <link>https://stats.stackexchange.com/questions/661879/autocorrelation-and-loss-of-information</link>
      <description><![CDATA[当我们想在样本上训练ML模型时，最好拥有I.I.D培训样本。如果样本是自相关的，我们需要更多数据才能实际训练模型。
直觉上，这很有意义，因为当示例为i.i.d时，每个新数据点都会添加“信息”。 （我们更好地理解分布 $ \ Mathbb {p} _x $ ）。当数据自动相关时，很难理解 $ \ MATHBB {p} _x $ 由于每个数据点没有添加太多信息，我们总是会看到几乎相同的数据点。
我的第一个问题是：有没有一种方法可以实际量化“信息”的概念。数学上？因此，表明当数据自动相关时，我们会丢失有关分布的信息，因此需要更多的数据点。
我的第二个问题是：要使模型了解数据是自动关节的，因此它实际上并不能代表 $ x $ 的真实分布，我们经常考虑datapoints： $ x_t-$ x_t-\ sum \ sum \ alpha_i x_i x_i x_i $ 。现在我的问题是：如果我们观察到数据的转换版本，我们仍然可以收敛到密度 $ \ Mathbb {p} _x $ ，此转换后的收敛速度有多慢？]]></description>
      <guid>https://stats.stackexchange.com/questions/661879/autocorrelation-and-loss-of-information</guid>
      <pubDate>Wed, 26 Feb 2025 16:45:58 GMT</pubDate>
    </item>
    <item>
      <title>左截断和间隔审查数据使用Turnbull提出的自洽算法</title>
      <link>https://stats.stackexchange.com/questions/661848/left-truncated-and-interval-censored-data-using-the-self-consistency-algorithm-p</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661848/left-truncated-and-interval-censored-data-using-the-self-consistency-algorithm-p</guid>
      <pubDate>Tue, 25 Feb 2025 18:29:13 GMT</pubDate>
    </item>
    </channel>
</rss>