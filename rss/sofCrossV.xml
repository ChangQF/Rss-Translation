<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 21 Jun 2024 18:20:10 GMT</lastBuildDate>
    <item>
      <title>与 t 分布相矛盾</title>
      <link>https://stats.stackexchange.com/questions/649682/contradiction-with-t-distribution</link>
      <description><![CDATA[假设我们有一个来自$N(\mu, \sigma^{2})$分布的样本$X_{1}, \dots, X_{n}$。然后，已知
$$
T = \frac{\bar{X} - \mu}{s/\sqrt{n}}
$$
其中$\bar{X}$和$s$是样本均值和样本方差，具有 t 分布，并且分布不依赖于$\mu$和$s$。
让我们按以下方式计算$T$的 cdf
$$
P(T\leq t ) = P (\bar{X} - \mu \leq t\frac{s}{\sqrt{n}}) = E[I\{\bar{X} - \mu \leq t \frac{s}{\sqrt{n}}\}] = E[E[I\{\bar{X} - \mu \leq t\frac{s}{\sqrt{n}}\}|s]] = E[P(I\{\bar{X} - \mu \leq t\frac{s}{\sqrt{n}}\}|s)]
$$
然后，由于 $\bar{X}$ 和 $s$ 是独立的，我们有
$$
E[P(I\{\bar{X} - \mu \leq t\frac{s}{\sqrt{n}}\}|s)] = E[P(I\{\bar{X} - \mu \leq t\frac{s}{\sqrt{n}}\})] = E[\Phi(\frac{s/\sqrt{n}}{\sigma})]
$$
但现在我们有了依赖于$\sigma$的cdf。
错误在哪里？]]></description>
      <guid>https://stats.stackexchange.com/questions/649682/contradiction-with-t-distribution</guid>
      <pubDate>Fri, 21 Jun 2024 17:48:23 GMT</pubDate>
    </item>
    <item>
      <title>这些是从我的代码生成的所谓的特征图吗？</title>
      <link>https://stats.stackexchange.com/questions/649680/are-these-generated-from-my-code-the-so-called-feature-maps</link>
      <description><![CDATA[我假设人们构建激活函数来检测图像中的特定部分的方式是通过执行网络并在每一层提取结果；当输出来自卷积层时，它被称为特征图（据我所知）。
我的问题是，实际上说这是一个特征图是否正确，这是每次运行网络到特定深度的结果（除了我丢弃的层）。
我生成的图像（这个问题是关于的。）在底部。
我是否正确地假设这里的layer.output是一个KerasTensor，它可以记住到那时为止的所有变换（和权重）？
所以它在这里并不是一个真正的符号张量。
如果你想运行它，基于 keras 文档的代码，在笔记本中作为示例执行此操作，代码如下：
!pip install tensorflow[and-cuda]==2.16.1 keras==3.3.3

import os
os.environ[&quot;KERAS_BACKEND&quot;] = &quot;tensorflow&quot;

导入 numpy 作为 np
导入 tensorflow 作为 tf
导入 keras
从 keras 导入 o​​ps
从 keras 导入层
导入 imageio 作为 iio
从 PIL 导入图像
导入 matplotlib.pyplot 作为 plt
# 检索 vgg19
vgg19 = keras.applications.VGG19()

# 获取张量，可能还有历史记录
features_list = [layer.output for layer in vgg19.layers]

# 我不确定 keras 如何解释列表，但似乎
# 它将包含所有操作
feat_extraction_model = keras.Model(inputs=vgg19.input, output=features_list)

# 在互联网上的图像上进行测试（a狗。)
img=iio.imread(&quot;https://images.squarespace-cdn.com/content/v1/54822a56e4b0b30bd821480c/29708160-9b39-42d0-a5ed-4f8b9c85a267/labrador+retriever+dans+pet+care.jpeg?format=1500w&quot;)
img = Image.fromarray(img).resize((224, 224))
plt.imshow(img)

# print(img.shape)
img = tf.image.convert_image_dtype(image=img, dtype=&quot;float32&quot;)
img = tf.expand_dims(img,axis=0)
img = img.numpy().astype(&quot;float32&quot;)

extracted_features = feat_extraction_model(img)

fig = plt.figure(figsize=(20, 20))
columns = 4
rows = 7

for i, v in enumerate(extracted_features):
f = tf.squeeze(extracted_features[i])
if len(f.shape) != 3:
continue
if f.shape[-1] &gt; 3：
print(f.shape)
f = f[:,:,0:3] # 使用 3 个通道以便我们可以绘图
pil_img = keras.preprocessing.image.array_to_img(f)
fig.add_subplot(rows, columns, i+1)
plt.imshow(pil_img)
# time.sleep(10)
plt.show()


我得到了这个：
]]></description>
      <guid>https://stats.stackexchange.com/questions/649680/are-these-generated-from-my-code-the-so-called-feature-maps</guid>
      <pubDate>Fri, 21 Jun 2024 17:44:37 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑回归中交换预测变量和结果变量会有什么变化</title>
      <link>https://stats.stackexchange.com/questions/649678/what-changes-in-swapping-predictor-and-outcome-variables-in-logistic-regression</link>
      <description><![CDATA[我有一个数据集，其中包含一个表示细菌分离源的变量，该变量有 2 个因子，以及多个其他二进制变量，表示该细菌是否对某些抗生素具有耐药性（是或否）。
我一直在进行逻辑回归，最初将分离源视为预测因子。
glm &lt;- glm(antibiotic1 ~ source, data = df, family = binomial()) 
但是，我正在考虑将分离源视为结果的可能性。这样，我可以使用多个抗生素耐药性变量作为预测因子，让我可以对一些抗生素进行分组并进行多元逻辑回归，看看它是否能产生更好的见解。
glm &lt;- glm(source ~ antibiotic1 + antibiotic2, data = df, family = binomial()) 
这种方法可行吗？在可解释性方面会发生什么变化？以这种方式进行是否可取？]]></description>
      <guid>https://stats.stackexchange.com/questions/649678/what-changes-in-swapping-predictor-and-outcome-variables-in-logistic-regression</guid>
      <pubDate>Fri, 21 Jun 2024 17:12:15 GMT</pubDate>
    </item>
    <item>
      <title>重复测量的二元分类模型</title>
      <link>https://stats.stackexchange.com/questions/649673/binary-classification-model-with-repeated-measures</link>
      <description><![CDATA[我有一个模型，可以预测某人是否执行特定操作（即二元结果）。他们不“转换”的情况多于没有转换的情况。数据设置为一行按 ID 和按月份，然后加上其他特征（模型中不包括 ID 和月份）。我想知道如何处理那些没有转换的人 - 是否最好对数据进行建模，以便我们按 ID 获得最后一个条目，因此单一条目（最小化数据量）或者对于像随机森林和 XG boost 这样的算法，是否有更好的方法来转换数据（即将多个条目保留为重复测量并以另一种方式处理它们）。
我对单一条目的问题是，所有转换的 ID 可能在不同时间转换，而 0 的 ID 都来自最新日期（即现在），因此如果存在季节性影响，则无法处理。
多个条目的问题是数据中有集群。]]></description>
      <guid>https://stats.stackexchange.com/questions/649673/binary-classification-model-with-repeated-measures</guid>
      <pubDate>Fri, 21 Jun 2024 16:07:06 GMT</pubDate>
    </item>
    <item>
      <title>相关伯努利变量的成功次数</title>
      <link>https://stats.stackexchange.com/questions/649672/number-of-successes-for-correlated-bernoulli-variables</link>
      <description><![CDATA[大家早上好！给定一组独立伯努利随机变量的成功次数由二项分布描述。但是，我想知道如果伯努利变量是相关的，会怎么说。例如，在不重新插入的情况下进行采样，则成功次数由超几何分布描述，但这是一种特殊情况（相当于从瓮中取出球而不重新插入它们）。您能否推荐一些文本，其中以更通用的方式解决了相关伯努利变量的总成功次数问题？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649672/number-of-successes-for-correlated-bernoulli-variables</guid>
      <pubDate>Fri, 21 Jun 2024 15:46:52 GMT</pubDate>
    </item>
    <item>
      <title>计算由 a/b 组成的比率的百分比变化的贡献</title>
      <link>https://stats.stackexchange.com/questions/649671/calculate-the-contributions-of-percentage-change-of-a-ratio-compossed-by-a-b</link>
      <description><![CDATA[我想知道如何计算对比率 a/b 的变化贡献，其中 b 等于 a 加上其他变量：b = a + c+ d + e + f
我在几个地方看到了对 GDP 增长的常见贡献，但这些方法没有捕捉到对每个组成部分份额比率的贡献变化。我的意思是，a/b 比率可能会因为 a 的变化或因为组成 b 的其他成分而发生变化。
我提到的其他来源是：
https://math.stackexchange.com/questions/33889/calculate-relative-contribution-to-percent-change
https://www.linkedin.com/pulse/calculating-contribution-percent-change-jay-sumners-mia-lssgb/]]></description>
      <guid>https://stats.stackexchange.com/questions/649671/calculate-the-contributions-of-percentage-change-of-a-ratio-compossed-by-a-b</guid>
      <pubDate>Fri, 21 Jun 2024 15:13:39 GMT</pubDate>
    </item>
    <item>
      <title>心率测量 (bpm) 的 Bland-Altman 图遵循某些“线”模式</title>
      <link>https://stats.stackexchange.com/questions/649670/bland-altman-plot-for-heart-rate-measurements-bpm-follow-certain-line-patter</link>
      <description><![CDATA[我正在比较不同设备在不同活动期间（5 分钟休息、5 分钟锻炼和 5 分钟恢复）的心率测量值。
为了分析设备之间的一致性，我想制作 Bland Altman 图（使用极坐标 H10 作为黄金标准）。
但是，在使用所有参与者的数据制作 H10 与 Vantage V3 的 Bland Altman 图时，我注意到图中有一些奇怪的线条图案，我不完全确定为什么会出现这些图案/这意味着什么？

我还为每个参与者制作了图，如下所示：

创建 Bland Altman 图时对于此参与者，出现了以下线条模式：

在某种程度上，这些线条对我来说是有意义的，因为您可以清楚地看到，当开始锻炼时，平均心率会增加，设备之间的差异也会变大。而当完成锻炼时，平均心率以及差异会再次下降。
然而，在我读过的所有论文中，我都没有看到出现如此精确的线条模式，这让我怀疑我是否在这里做错了什么？
例如，我是否需要排除某些数据点，或者首先进行一些标准化？
任何想法或帮助，都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/649670/bland-altman-plot-for-heart-rate-measurements-bpm-follow-certain-line-patter</guid>
      <pubDate>Fri, 21 Jun 2024 15:06:25 GMT</pubDate>
    </item>
    <item>
      <title>特定事件发生时间对响应的影响</title>
      <link>https://stats.stackexchange.com/questions/649668/impact-of-time-to-particular-event-on-response</link>
      <description><![CDATA[我正在尝试评估哪些变量会对结果产生影响。我的临床团队想检查特定事件发生的时间是否会影响结果。如果发生了特定事件，那么发生该事件的时间就很明显了，但如果没有发生该事件，该如何设置发生特定事件的时间。如果我将发生特定事件的时间设置为没有发生事件的患者接受治疗的最大时间，那么我会自动发现存在影响]]></description>
      <guid>https://stats.stackexchange.com/questions/649668/impact-of-time-to-particular-event-on-response</guid>
      <pubDate>Fri, 21 Jun 2024 14:42:32 GMT</pubDate>
    </item>
    <item>
      <title>（理论）树模型是否输出概率？</title>
      <link>https://stats.stackexchange.com/questions/649666/theory-do-tree-models-output-probabilities</link>
      <description><![CDATA[我有一个关于决策树分类输出的纯理论问题。我听过很多人说“树模型的输出不是概率”，研究过这些之后，我不明白他们为什么会这么说。
我说它们实际上是概率的原因如下：
1. 简单分类树：决策树中的每个叶子代表训练数据的一个子集，具有一定的类别分布。叶子中每个类别的比例可以解释为属于该类别的概率估计。例如，如果叶子包含 80 个 A 类样本和 20 个 B 类样本，则 A 类的概率估计为 80%，B 类的概率估计为 20%。
2. 集成模型（随机森林）：在随机森林中，多个决策树在数据和/或特征的不同子集上进行训练。然后汇总这些树的预测。对于分类，这通常涉及进行多数投票或平均每棵树的预测概率。通过对多棵树的预测概率进行平均，随机森林可以提供比单个决策树更可靠的概率估计。这进一步支持了基于树的模型可以输出概率的观点。
3. 增强模型（梯度增强，XGBoost）：像梯度增强或 XGBoost 这样的增强模型按顺序构建树，每棵树都会纠正前一棵树的错误。对于二元分类，最终输出通常采用对数几率的形式，然后使用逻辑函数（S 型函数）将其转换为概率。此转换明确产生概率估计。
说它们不是概率的原因是：
1.校准：众所周知，许多分类问题都涉及不平衡的数据集，为此，许多人使用 is_unbalance 或 class_weights 等参数来补偿这一点。使用这些参数会使输出校准不充分。这意味着预测的概率不一定与事件的真实可能性相对应。例如，一片叶子可能以 80% 的概率预测一个类别，但实际上，该类别的真实可能性可能不同。校准技术（例如 Platt 缩放或保序回归）通常用于改善这种情况。虽然我相信这个理由是有效的，但使用这些参数只是树模型的一个特例，所以我不会那么快地说基于树的模型不会产生概率。
2.过度拟合：我们都同意决策树很容易过度拟合（尽管我会在随机森林的情况下对此进行更多辩论），尤其是那些未经修剪的决策树，这会导致过度自信的概率估计。这种过度拟合可能导致叶子样本很少，从而使概率估计不太可靠。我有点同意这种说法，但是，这只是告诉我这是一个训练不良的模型，这并不意味着基于树的模型本质上不输出概率，这只是一个像其他模型一样训练不良的模型的情况。训练不良的神经网络甚至逻辑回归也可能会发生同样的情况。
我很想听听你对这个问题的想法和意见，并学习一些新东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/649666/theory-do-tree-models-output-probabilities</guid>
      <pubDate>Fri, 21 Jun 2024 14:37:50 GMT</pubDate>
    </item>
    <item>
      <title>关于分层分析的几个问题</title>
      <link>https://stats.stackexchange.com/questions/649661/a-few-questions-on-stratified-analysis</link>
      <description><![CDATA[
如果 IWRS 的 3 个分层因子之一有数据错误，我们是否应该用 CRF 收集的基线值替换它？这会破坏分层块的平衡吗？

对于非 ITT 人群，例如，每个方案人群中约有 15% 的患者低于 ITT，我们还能使用随机化中的因子进行分层分析吗？

如果随机化有 3 个因子；当我们使用一个因子进行亚组分析时，我们可以使用其他 2 个分层因子进行分层分析吗？


谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/649661/a-few-questions-on-stratified-analysis</guid>
      <pubDate>Fri, 21 Jun 2024 13:31:36 GMT</pubDate>
    </item>
    <item>
      <title>广义似然比检验：H0：µ<=µ0 vs. H1：µ>µ0，σ 未知 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649660/the-generalized-likelihood-ratio-test-of-h0-%c2%b5-%c2%b50-v-s-h1-%c2%b5%c2%b50-with-unknown-%cf%83</link>
      <description><![CDATA[在受限参数空间中，为什么 MLE 是 min{µ0,X̄} ？
如何在受限参数空间中获取 MLE？
请帮帮我]]></description>
      <guid>https://stats.stackexchange.com/questions/649660/the-generalized-likelihood-ratio-test-of-h0-%c2%b5-%c2%b50-v-s-h1-%c2%b5%c2%b50-with-unknown-%cf%83</guid>
      <pubDate>Fri, 21 Jun 2024 13:09:05 GMT</pubDate>
    </item>
    <item>
      <title>想要创建一个测量截止点（长度乘以宽度），当该点发生不良结果</title>
      <link>https://stats.stackexchange.com/questions/649659/wanting-to-create-a-cut-off-point-for-measurement-length-by-width-at-which-an</link>
      <description><![CDATA[我正在研究一个研究肩部撕裂尺寸及其对术后再次撕裂率影响的项目。
从文献来看，年龄和撕裂尺寸（尺寸 AP [宽度]、ML [长度]、面积 [AP x ML]）与结果相关。
我正在根据用于固定撕裂的锚点数量来研究不同的组。一般的想法是，非常小的撕裂尺寸可以使用一个锚点，而较大的撕裂尺寸可以使用多个锚点。
我的目标是找到使用单个锚点等于使用多个锚点的尺寸（AP x ML）的临界点。
我拥有的数据相当偏向多个锚点：单个锚点为 n=200，多个锚点为 n=1000。
如果我们查看中等大小的撕裂（ML&lt;=30mm），我们会得到单锚的 n=200 和多锚的 n=600。
我之前所做的是使用 SPSS 上的倾向得分匹配来匹配几个变量 - 年龄、撕裂大小 ML、AP、撕裂面积（AP x ML）和性别。我对撕裂大小进行了卡方比较，将撕裂大小分为 ML&lt;=10 和 ML11-30mm，并将每个子组分为 AP&lt;=10mm 和 AP 11-30mm。
这是基于创建这些类别的先前研究。
但是我想知道是否有办法确定截止点，就像 ROC 曲线一样。但是我正在寻找的是单锚组与多锚组可比的值。我想应该有一种方法可以通过回归来实现这一点，或者也许是我所缺少的技术。
TL;DR - 处理以确定变量的截止点，在该截止点，一组的结果与另一组的结果具有可比性。]]></description>
      <guid>https://stats.stackexchange.com/questions/649659/wanting-to-create-a-cut-off-point-for-measurement-length-by-width-at-which-an</guid>
      <pubDate>Fri, 21 Jun 2024 13:04:13 GMT</pubDate>
    </item>
    <item>
      <title>不同长度合规率（按时间段）的单因素方差分析</title>
      <link>https://stats.stackexchange.com/questions/649647/one-way-anova-on-compliance-rates-by-time-period-with-different-lengths</link>
      <description><![CDATA[我对此有点困惑，因为在我的统计课上，我们很好地打包了数据，其中包含易于理解的良好、正常数据！如果这看起来太明显，请原谅。
我的数据是几个审计期 (AP) 中几类员工的一系列合规率。我们会说他们应该执行的操作是上班时刷卡。当然，合规率是他们实际刷卡的次数/他们预期刷卡的次数。
我有三个日期组要比较，但它们的长度各不相同，因为我们试图展示 COVID 期间和之后的合规性。每四个月测量一次数据，因此一年有三个 AP，从 11 月开始：

AP 1：11 月 1 日至 3 月 31 日
AP 2：4 月 1 日至 6 月 30 日
AP 3：7 月 1 日至 10 月 31 日

我正在观察 2018 年 11 月至 2022 年 10 月的数据，拆分如下：
日期组 1（COVID 之前，基线/对照）：

AP-1，2018 年 11 月 - 2019 年 3 月 31 日
AP-2，2019 年 4 月 1 日 - 2019 年 6 月 30 日
AP-3，2019 年 7 月 1 日 - 2019 年 10 月 31 日
AP-1，11 月 1 日2019 年 - 2020 年 3 月 31 日 [12 个月，共 4 个时间段]

日期组 2 (COVID)：

AP-2，2020 年 4 月 1 日 - 2020 年 6 月 30 日
AP-3，2020 年 7 月 1 日 - 2020 年 10 月 31 日
AP-1，2020 年 11 月 1 日 - 2021 年 3 月 31 日
AP-2，2021 年 4 月 1 日 - 2021 年 6 月 30 日
AP-3，2021 年 7 月 1 日 - 2021 年 10 月 31 日 [20 个月，共 5 个时间段]

日期组 3 (后疫情时代)：

AP-1，2020 年 11 月 1 日2021 - 2022 年 3 月 31 日
AP-2，2022 年 4 月 1 日 - 2022 年 6 月 31 日
AP-3，2022 年 7 月 1 日 - 2022 年 10 月 31 日 [9 个月，共 3 个时期]

所有类别员工的数据合计如下。



组
AP 代码
刷卡
总计条目
合规性




1
2019-1
1019
1231
0.790


1
2019-2
782
878
0.788


1
2019-3
934
1132
0.793


1
2020-1
973
1151
0.821


2
2020-2
640
749
0.834


2
2020-3
901
1075
0. 810


2
2021-1
952
1122
0.816


2
2021-2
674
807
0.800


2
2021-3
841
1001
0.804


&lt; td&gt;3
2022-1
727
857
0.820


3
2022-2
733
887
0.784


3
2022-3
868
1041
0.801



我想要使用方差分析来查看日期组 1（COVID 之前）与日期组 2 和 3（COVID 和 COVID 之后）之间的合规率是否存在显著差异。使用单向方差分析是解决方案吗？询问是因为我不习惯处理费率，而是“这是花瓣的长度”。如果有帮助的话，使用 R 工作。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649647/one-way-anova-on-compliance-rates-by-time-period-with-different-lengths</guid>
      <pubDate>Fri, 21 Jun 2024 08:33:58 GMT</pubDate>
    </item>
    <item>
      <title>统计学中的经验法则含义</title>
      <link>https://stats.stackexchange.com/questions/649644/rule-of-thumb-meaning-in-statistics</link>
      <description><![CDATA[我想知道统计学中“经验法则”一词的实际含义。为什么他们选择这个名称来计算样本量？它是否像是一种基于实践而非理论的近似值？]]></description>
      <guid>https://stats.stackexchange.com/questions/649644/rule-of-thumb-meaning-in-statistics</guid>
      <pubDate>Fri, 21 Jun 2024 07:46:05 GMT</pubDate>
    </item>
    <item>
      <title>这个公式是如何推导出来的</title>
      <link>https://stats.stackexchange.com/questions/649598/how-is-this-formula-derived</link>
      <description><![CDATA[我进行了多次重复实验，我的程序返回了 EC50 及其 CI(95%) 置信区间、LogEC50 和 (LogEC50) 标准误差的值。这些对数来自 Hill 方程。在这种情况下，标准误差指的是曲线拟合，而不是 SEM。
根据 Cochrane 指南，我根据 EC50 值和 CI 计算了 SD。 https://handbook-5-1.cochrane.org/chapter_7/7_7_3_2_obtaining_standard_deviations_from_standard_errors_and.htm
我也在这里读到（https://www.ncbi.nlm.nih.gov/books/NBK91994/），可以通过将 LogEC50 的误差乘以 来计算估计值的拟合误差（百分比）将其乘以 ln(10) * 100：
%FE(EC50)= FE(Log(EC50))*​​ln(10)*100
据此我假设您可以通过将 EC50 乘以 FE(Log(EC50))*​​ln(10) 来推断绝对拟合误差。
我得到的值似乎与之前计算的 SD 非常吻合。
我不明白的是这个公式实际上做了什么
我知道 Log10(EC50) 可以重写为 ln(EC50)/ln10，所以我猜 ln(10) 会抵消，但之后呢。
我理解，由于 SE(Log(EC50)) 是从 Log(EC50) 中添加和减去的，因此我们将绝对值乘以误差值是有道理的（log(xy)=log(x)+log(y) 等等）。我似乎无法将这种直觉与公式中实际发生的事情联系起来
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/649598/how-is-this-formula-derived</guid>
      <pubDate>Thu, 20 Jun 2024 13:56:35 GMT</pubDate>
    </item>
    </channel>
</rss>