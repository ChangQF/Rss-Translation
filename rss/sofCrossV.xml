<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sun, 23 Feb 2025 12:30:19 GMT</lastBuildDate>
    <item>
      <title>在公共条件模型下，INID与IID数据的参数估计的差异？</title>
      <link>https://stats.stackexchange.com/questions/661756/differences-in-parameter-estimation-for-inid-vs-iid-data-under-a-common-conditi</link>
      <description><![CDATA[ 这篇文章表明条件独立性足以在条件模型中进行参数估计。这使我思考了数据是独立但并非相同分布（INID）与IID案例相同的细微差别 - 在这两种情况下都是一个常见的条件模型。
 具体示例：&lt; /strong&gt; 
考虑回归模型
 $$
y_i = \ beta_0 + \ beta_1 x_i + u_i，
$$ 
与假设：

  $$ e（y_i \ mid x_i）= \ beta_0 + \ beta_1 x_i，$$  
  $$ \ operatatorName {var}（y_i \ mid x_i）= \ sigma^2。 $$  

现在假设数据是从 $ n $ 不同区域收集的（每个样本都来自其他区域）。尽管条件模型 $ p（y_i \ mid x_i; \ theta）$ 对于所有观测值都是相同的，但 $ x_i $ 在地区之间有所不同（例如，由于社会经济或教育因素的不同）。因此，尽管观察结果是独立的，并且共享相同的条件结构，但它们是无穷的，而不是IID。
 我的问题：&lt; /strong&gt; 
数据的无限性吗？对IID案？例如，使用MLE或OLS等方法时，对估计器的一致性，渐近正态性或有效样本大小有影响吗？
我将感谢任何详细讨论这些问题的见解或参考。预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661756/differences-in-parameter-estimation-for-inid-vs-iid-data-under-a-common-conditi</guid>
      <pubDate>Sun, 23 Feb 2025 11:12:00 GMT</pubDate>
    </item>
    <item>
      <title>此数据显示过度表示吗？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/661755/does-this-data-display-an-over-representation</link>
      <description><![CDATA[样品A -12733人类。 369领导。
样本B -4672人类。 188领导。
所有人类都以同样的资格开始职业。]]></description>
      <guid>https://stats.stackexchange.com/questions/661755/does-this-data-display-an-over-representation</guid>
      <pubDate>Sun, 23 Feb 2025 10:31:36 GMT</pubDate>
    </item>
    <item>
      <title>计算反应时间逆高斯模型的ICC</title>
      <link>https://stats.stackexchange.com/questions/661754/calculating-icc-for-an-inverse-gaussian-model-for-response-times</link>
      <description><![CDATA[ 2 
我正在使用混合效应模型进行一项研究，以分析反应时间，并且在使用逆高斯家族对数据进行建模时，我遇到了类内相关系数（ICC）的问题。我希望您的见解更好地理解和解决这个问题。
背景
我的因变量是反应时间，它是积极偏斜的。我正在使用具有随机拦截的参与者（ID）的混合效应模型和两个预测因素的固定效果：种族和身份。我的模型是使用R中的LME4软件包构建的。这是我测试过的模型：
具有身份链接的逆高斯逆高斯：
 model1_rt_invgauss_identity＆lt;  -  glmer（反应_time〜种族 +身份 +（1 | id），
data = data_clean，
family = inverse.gaussian（link =＆quot; Identity;），
控制= glmercontrol（优化器=; bobyqa＆quort; optctrl = list（maxfun = 2e5））））））））
ICC：调整后的ICC = 1，未经调整的ICC = 0.811。
固定效果：系数很简单，对我来说很有意义（例如，表示毫秒的反应时间变化）。
随机效应：残余方差非常小（8.25E-03），而随机截距的方差更大（40.12）。
与日志链接的逆高斯：
 model1_rt_invgauss_log＆lt;  -  glmer（反应_time〜种族 +身份 +（1 | id），
data = data_clean，
family = inverse.gaussian（link =; log; quot;），
控制= glmercontrol（优化器=; bobyqa＆quort; optctrl = list（maxfun = 2e5））））））））
ICC：调整后的ICC = 0.420，未经调整的ICC = 0.384。
固定效果：系数很难解释，因为它们处于日志尺度上。在开发后，它们代表比例变化（例如百分比），但这不如身份链接直观。
随机效果：残余方差和随机截距方差都更加平衡。
与Lmer（高斯家庭）的比较：
使用LMER与原始或对数转换的反应时间一起产生ICC = 1问题，这表明该问题是特定于高斯家族的。
问题
使用逆高斯家族时，ICC会大大变化，这取决于链接函数：
具有身份链接，ICC为1，因为残差方差几乎为零。使用日志链接，ICC更合理（例如，0.42）。此外，系数的可解释性各不相同：
身份链接在原始反应时间单元中提供了直观的，添加的解释。日志链路稳定方差并避免ICC = 1，但系数变得乘法且难以直接解释。我尝试了诊断：
检查了两个模型的残差和方差成分。身份链接中的残余差异始终接近零，即ICC充气。模型比较：
使用AIC和BIC比较了模型，并且日志链路始终如一地表现更好。替代分布：
使用高斯分布（LMER）避免了ICC问题，但不能解释反应时间的偏差。我的问题为什么链接的选择在逆高斯家庭中起作用会极大地影响ICC？
这是由于逆高斯模型的方差假设所致，还是与我的特定数据结构有关（例如，参与者内部反应时间高度一致）？我应该优先考虑哪个链接功能？
身份链接可提供直观的系数，但会夸大ICC。日志链接解决了ICC问题，但使解释复杂化。我可以尝试平衡ICC和可解释性吗？是否还有其他检查或替代方法？
是否会修改随机效应结构或使用不同的优化器有助于稳定身份链接模型中的残余方差？预先感谢您的见解！
混合模型]]></description>
      <guid>https://stats.stackexchange.com/questions/661754/calculating-icc-for-an-inverse-gaussian-model-for-response-times</guid>
      <pubDate>Sun, 23 Feb 2025 09:56:28 GMT</pubDate>
    </item>
    <item>
      <title>将高维向量可视化到2D极空间</title>
      <link>https://stats.stackexchange.com/questions/661753/visualizing-high-dimensional-vectors-into-2d-polar-space</link>
      <description><![CDATA[实际上这是降低维度的问题，但是使用T-SNE或UMAP应该找到正确的参数并取决于数据集的可用性。问题是，随着时间的推移，样本的数量正在增加，因此这意味着我需要重述参数。
这是因为我正在制作一个迅速的猜测游戏，其中提示器提示生成图像，然后猜测者猜测生成的图像。两个原始提示和猜测的提示都存储在高维矢量中。因此，我不得不使用缩小维度缩减技术，这些技术取决于第一次生成的图像引起的数据可用性正在等待猜测器的可用性。

 正如我的直觉所说的那样，圆/球/球是中立形状的，这就是为什么我打算使用极地坐标。

 所以，我想创建一个带有极地坐标格式（2D空间）的仪表板，以可视化原始提示的当前相似性，而不是猜测的提示。其中中心（原点点）是原始提示的点。

 这意味着，我需要通过猜测在原始提示向量中执行向量相似性操作。

 归一化的L2标准在极坐标中解释为半径，而余弦相似性用于theta。


让 $ r_1 $ 是第一个猜测提示的半径， $ \ theta_1 $ 是第一个角度猜测提示， $ l_2 $ 是原始和猜测之间的欧几里得距离， $ \ cos（\ phi）$ 是余弦相似性， $ \ vec {o} $ 是原始提示，并且 $ \ vec {g} _1 $ 首先是猜测提示。

  $ r_1 = l_2（\ vec {o}  -  \ vec {g} _1）$  
  $ \ theta_1 = \ pi \ cos（\ phi）$    

问题是，我如何归一化半径以使范围是[0,1]？使用标准归一化或最低最大标准化，需要数据可用性依赖性。我打算使用：
 $$
r_1 = 1- \ frac {\ min（\ | \ | \ vec {o} \ |，\ | \ | \ vec {g} _1 \ |）} {\ max（\ | \ | \ | \ vec {o} {g} _1 \ |）}
$$  
这个想法是，因为半径更接近零，表明欧几里得距离更近。
   
这是仿真： https://wwwww.desmos.com/calculator/calculator/calculator/calculator/s7gjqpycficpedcpedcpedcpedcfi  ]]></description>
      <guid>https://stats.stackexchange.com/questions/661753/visualizing-high-dimensional-vectors-into-2d-polar-space</guid>
      <pubDate>Sun, 23 Feb 2025 05:23:06 GMT</pubDate>
    </item>
    <item>
      <title>是否有一个已知的理论或实际证据表明，较高的对象检测性能会导致更高的聚类准确性？</title>
      <link>https://stats.stackexchange.com/questions/661752/is-there-a-known-theoretical-or-practical-proof-that-higher-object-detection-per</link>
      <description><![CDATA[我正在处理一个基于图像的对象检测问题，我注意到相关性：对象检测性能的改进（按照标准指标（例如MAP或IOU）衡量）似乎在下游聚类任务中产生了更高的准确性。 
我想知道这种关系是在理论上还是通过文献中的经验研究正式表达或证明。是否存在已知的参考文献，论文或经过良好接受的分析，这些分析（或挑战）更好地检测指标可以直接转化为提高的聚类准确性？任何指示或见解都将不胜感激。
我在文献审查过程中，到目前为止，我还没有遇到任何类似的理论。我一直在研究Google Scholar的相关论文。
预先感谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/661752/is-there-a-known-theoretical-or-practical-proof-that-higher-object-detection-per</guid>
      <pubDate>Sun, 23 Feb 2025 04:34:20 GMT</pubDate>
    </item>
    <item>
      <title>Euler-Maruyama近似与估计参数的强烈收敛</title>
      <link>https://stats.stackexchange.com/questions/661747/strong-convergence-of-euler-maruyama-approximation-with-estimated-parameters</link>
      <description><![CDATA[ 背景。考虑一个扩散过程 $（x_t）$ 是以下随机微分方程（SDE）的解决方案：&lt; /p&gt;
  $$ DX_T = B（X_T）dt + \ sigma（x_t）dw_t $$   
其中 $ W_T $ 是标准Wiener过程。表示 $ x_t $  as  $ \ {\ bar {x} _ {k \ delta} \ } _ {k = 1}^n $ ，因此定义了连续的时间过程 $ \ bar {x} _t：= \ bar {x} _ {k \ delta} $  for  $ t \ in [k in [k in [k in] \ delta，（k+1）\ delta）$ 。众所周知，牢固的连接保持：
  $$ \ | x- \ bar {x} \ | _ {l_2（\ omega \ times [0，t]）}：= \ sqrt {\ int_0^t \ Mathrm {e} | x_t- \ bar {x} _t |^2 dt} = o（\ delta^{ -  \ frac {1} {2}}）$$ 
参见，例如，此注释。。 
 问题。假设函数 $ b $  and  $ \ sigma $ 由 $ \ theta $ 参数化。例如，最简单的线性过程：
在
 with  $ \ theta =（b，\ sigma）$ 。但是，我们不知道 $ \ theta $ 的值，因此，为了计算欧拉近似，我们首先估计 $ \ theta $  with  $ \ hat {\ theta} $ 从某些观测数据中class =“ Math-Container”&gt; $ \ hat {\ theta} $  in  $ \ {\ bar {x} _ {k \ delta} \} _ {k {k {k {k = 1}^n $ 获得 $ \ {\ hat {\ bar {x}} _ {k \ delta} \} _ {k = 1}^n $ 。
我们调用 $ \ {\ hat {\ bar {x}} _ {k \ delta} \} _ {k = 1}^n $ 作为Euler近似估计参数。 Define  $ \ hat {\ bar {x}} _ t：= \ hat {\ bar {x}} _ {k \ delta} $  for 。中
我们如何获得 $ \ | x- \ hat {\ bar {x}}} \ | _ {l_2（\ omega \ times [0，t]） } $ ，给定 $ \ delta \ to 0 $ 和 $ \ hat {\ theta} \ to \ theta $ （以任何形式）？
 注。这仅供示范。此外，我们有 $ \ hat {\ theta} $ 是从某些数据估算的，独立于 $ w_t $  （ $ \ hat {\ theta} \ perp w_t $ ）。]]></description>
      <guid>https://stats.stackexchange.com/questions/661747/strong-convergence-of-euler-maruyama-approximation-with-estimated-parameters</guid>
      <pubDate>Sun, 23 Feb 2025 02:14:46 GMT</pubDate>
    </item>
    <item>
      <title>在计算Nesterov优化梯度时，深度学习框架是否会“向前看”？</title>
      <link>https://stats.stackexchange.com/questions/661745/do-deep-learning-frameworks-look-ahead-when-calculating-gradient-in-nesterov-o</link>
      <description><![CDATA[ Nesterov优化背后的全部要点是计算当前参数值 $ \ theta_t $ ，而是在 $ \ theta_t + \ beta m $ ，其中 $ \ beta $ 是动量系数和 $ M $ 动量。更新步骤如下：
  $$
m \ get \ beta m- \ eta \ nabla l（\ theta + \ beta m）\\
\ theta \ get \ theta + m
$$  
通过查看
  velocity =动量 *速度-Learning_rate * g
w = w +动量 *速度-Learning_rate * g
 
通过查看 pytorch的文档更新步骤是：
    
如果我错了，请纠正我，但是在这两种情况下，梯度都不以“向前看”计算。参数位置（由于需要Nesterov优化）。这些实现原始方法的近似吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661745/do-deep-learning-frameworks-look-ahead-when-calculating-gradient-in-nesterov-o</guid>
      <pubDate>Sat, 22 Feb 2025 22:20:04 GMT</pubDate>
    </item>
    <item>
      <title>用于证明Q学习收敛的定理中数学术语的含义</title>
      <link>https://stats.stackexchange.com/questions/661723/meaning-of-mathematical-terms-in-a-theorem-used-to-prove-q-learning-convergence</link>
      <description><![CDATA[我试图在这里理解定理的陈述 htttps：// apps.dtic.mil/sti/tr/pdf/ada276517.pdf ，用于证明Q学习算法的收敛性（即使定理更抽象）：
    
，但是我在理解术语的含义方面有问题。您能评论以下几点：
 1-什么是 $ x $ 在这里？是在x $ 中假设 $ x \的语句，因此，每个 $ x $ ，例如在高斯流程中？并且 $ x $ 即使没有明确提及条件1的状态空间？
 2-标准 $ || \ cdot || _W $ 在哪个设置上定义了？是在上一个集合 $ x $ 上定义的规范（在这种情况下是矢量空间）？是在基本概率空间的随机变量 $ \ omega $ 上定义的规范，让我们称其为 $ v（\ omega） ）$ ？它是否在随机过程的空间中定义了标准（我猜 $ v（\ Omega \ times x）$ ）？
无论正确的解释如何，我都会发现条件3和4之间的差异令人困惑。正确的成员是相同类型的，而在左侧，我们在第一种情况下有一个额外的规范，我们在条件4中找不到这是对有效性领域的任何其他评论
感谢您帮助我澄清。该定理中似乎给予了一些设置。]]></description>
      <guid>https://stats.stackexchange.com/questions/661723/meaning-of-mathematical-terms-in-a-theorem-used-to-prove-q-learning-convergence</guid>
      <pubDate>Sat, 22 Feb 2025 11:11:23 GMT</pubDate>
    </item>
    <item>
      <title>如何在不同聚集/粒度水平下的时间序列数据的经验估计标准偏差和变异系数？</title>
      <link>https://stats.stackexchange.com/questions/661685/how-to-empirically-estimate-standard-deviation-and-coefficient-of-variation-for</link>
      <description><![CDATA[我正在与2024年9月19日至11月19日的图书馆建筑物收集的时间序列建筑物占用数据。每5分钟，使用Motion（PIR）传感器（总共450张椅子）记录每5分钟的数据。然后将数据重新采样至30分钟的间隔（2689个数据点），并在不同级别进行汇总：
椅子级别：450椅→1,210,050个数据点（450*2689）
表级：50个表→134,450数据点（50*2689）
子区域级别：6个子区域→16,134个数据点（6*2689）
区域级别：2区→5,378个数据点（2*2689）
 客观：我旨在使用两个关键指标（即标准偏差（SD）（SD）和变异系数（CV），在不同水平的粒度（椅子，桌子，子区域和区域）处量化可变性。 。
在较小的级别（例如椅子级）下，我有更多的观察结果（更高的数据点，而在更粗的水平（例如区域级别）下，样本量明显较小。
我的主要问题是
 1-当每个粒度水平的数据点总数显着差异时，我如何从经验上估计SD，CV进行公平比较？我已经计算了原始SD，而没有考虑到不平等的观察数（请参阅附件图）每小时标准偏差的箱形图表所有粒度级别” src =“ https://i.sstatic.net/vok57dth.jpg”/&gt; 。
数据集附加在此处
考虑不平等的数据点，可以用来估算SD的任何见解，参考或方法将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661685/how-to-empirically-estimate-standard-deviation-and-coefficient-of-variation-for</guid>
      <pubDate>Fri, 21 Feb 2025 13:39:12 GMT</pubDate>
    </item>
    <item>
      <title>我是否了解主教的主教？</title>
      <link>https://stats.stackexchange.com/questions/661681/have-i-understood-bishop-on-uninformative-priors</link>
      <description><![CDATA[主教将A 定义参数满足以下内容，
 $$
p（x | \ mu）= f（x- \ mu）。
$$ 
他想定义“不信息先验”对于 $ {\ MU} $ 对于贝叶斯推理。如果我没记错的话，那是他想利用以下不变性，
 $$
\ wideHat {x}：= x + c \ leadsto p（\ wideHat {x} | \ wideHat {\ mu}）= p（x | \ mu），
$$ 
我们定义了 $ {\ wideHat {\ mu} = \ mu+c} $ 。这是我想验证我理解的阶段：他本质上想定义先前的 $ {p（\ mu）} $ ，以便我们具有以下后代：
 $$
p（\ wideHat {\ mu} | \ wideHat {x} _1，...，\ wideHat {x} _n）= p（\ mu | x_1，...，...，x_n）。
$$ 
他并没有这样说，所以这就是为什么我想检查我本质上理解这个想法的原因。如果您继续这个想法，则最终会以 $ {p（\ wideHat {\ mu}）= p（\ mu）} $ ，并且由于选择了 $ {c} $ 是任意的，您最终会 $ {p（\ mu）= \ text {const。}} $  

  edit ：要澄清，我应该提到 $ {p（\ wideHat {\ mu}）= p（\ mu）} $ 最终是一个足够的（但我认为不是严格必要的条件） class =“ Math-Container”&gt; $ {p（\ wideHat {\ mu} | \ wideHat {x}）= p（\ mu | x）} $ ：
 $$
p（\ wideHat {\ mu} | \ wideHat {x}）= p（\ mu | x）\ rightarrow \ frac {p（\ wideHat {\ mu}）}} {\ int_d p（\ wideHat {x} | \ wideHat {\ mu}）p（\ wideHat {\ mu}）d \ wideHat {\ mu}} =
\ frac {p（\ mu）} {\ int_d p（x | \ mu）p（\ mu）d \ mu}。
$$ 
由于我们已经确定 $ { span class =“ nath-container”&gt; $ {p（\ wideHat {\ mu}）= p（\ mu）} $ 对于任何 $ c $ 满足了平等。]]></description>
      <guid>https://stats.stackexchange.com/questions/661681/have-i-understood-bishop-on-uninformative-priors</guid>
      <pubDate>Fri, 21 Feb 2025 12:12:55 GMT</pubDate>
    </item>
    <item>
      <title>纯粹的可预测性衡量</title>
      <link>https://stats.stackexchange.com/questions/661679/purely-theoretical-measure-of-predictability</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661679/purely-theoretical-measure-of-predictability</guid>
      <pubDate>Fri, 21 Feb 2025 11:57:38 GMT</pubDate>
    </item>
    <item>
      <title>GLMM用于计数数据，受试者的随机效果为小样本量，I型错误风险，如何推断因子效应和事后。</title>
      <link>https://stats.stackexchange.com/questions/661652/glmm-for-count-data-with-random-effect-of-subject-in-small-sample-size-with-risk</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661652/glmm-for-count-data-with-random-effect-of-subject-in-small-sample-size-with-risk</guid>
      <pubDate>Thu, 20 Feb 2025 18:03:25 GMT</pubDate>
    </item>
    <item>
      <title>了解人们为什么对自己的身高撒谎（第2部分）</title>
      <link>https://stats.stackexchange.com/questions/661343/understanding-why-people-lie-about-their-height-part-2</link>
      <description><![CDATA[我有兴趣了解不同类型的人（例如不同年龄，不同的性别，不同的身高）在他们的自我报告如何自我报告以及可能存在哪种偏见方面存在差异。
我想我站在街上进行类似的实验（ https://www.youtube 。获得一些有关它们的基本信息（例如性别，年龄）。我可以写一个非常基本的模型：
  $$ D = H_R -H_T $$ 
 $$ d = \ beta_0 + \ beta_1h_t + \ beta_2a + \ beta_3g + \ beta_3g + \ epsilon $$

  $ H_R $ ：报告高度
  $ H_T $ ：true Height 
  $ a $ ：age 
  $ g $ ：性别（ $ g = 1 $  vs vs  $ g = 0 $ ）

我想添加以下注释：

这些是我拥有的一些幼稚理论（为人们如何撒谎制定统计模型）：



在许多文化中，人们认为男人很高。因此，也许男人更有可能比他们高的自我报告高度
实际上是。
一般来说，高个子（即超出一定身高）可能会通过自我报告的高度比实际的高度来获得任何收益。
年长的人可能会更认为他们通过误会高度而获得的收益较少，因此可能是更真实的



在这种情况下，我的数据很可能包含更多类型的人群（例如，男性大学生）。

 如何考虑我的统计模型，考虑到我对高度报告的天真理论以及某些人口统计学的反映在数据中？。第一点，我会认为贝叶斯的方法可能很有用。对于第二点，我已经阅读了可能在这里可能相关的heckman选择模型的信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/661343/understanding-why-people-lie-about-their-height-part-2</guid>
      <pubDate>Thu, 13 Feb 2025 19:41:26 GMT</pubDate>
    </item>
    <item>
      <title>计算调整为患病率的PPV的置信区间或标准误差</title>
      <link>https://stats.stackexchange.com/questions/595786/calculating-the-confidence-interval-or-standard-error-of-a-ppv-adjusted-for-prev</link>
      <description><![CDATA[我正在尝试评估疾病测试在病例对照研究中的表现。在此示例中，患病率为0.5％，结果如下：




 
疾病 +
疾病 -  




 测试 + 
 40（TP）
 10（fp）


 测试 -   
 600（FN）
 5000（TN）




随着样本的疾病患者的样本，标准PPV计算 $ ppv = \ frac {tp} {tp+fp} $ 不准确。我可以使用 $ ppv = \ frac {p \ cdot sens} {p \ cdot sens +（1-p）\ cdot（1-spec）} $计算出患病率调整的PPV。 ，如此页面，此处的PPV为13.6％。
但考虑到较低的患病率，我担心假阳性数量的少量变化可能会对PPV产生很大的影响，因此我想计算此PPV的95％置信区间。
 这个问题标准错误为 $ SE = \ sqrt { \ frac {ppv（1-ppv）} {tp+fp}} $ 。
这将给出4.8％的标准错误，如果然后使用 $ ci_ {ppv} = ppv \ pm 1.96*se $ ，我得到的CI为4.1％ -23.1％。
但是：

 在调整PPV的患病率时，该方程仍然适用吗？

 我读到，由于比例的不确定性不是对称的，因此使用上述方程计算CI不是很有用（例如，在”这个问题）。


因此，在这种情况下，有更好的方法可以计算PPV的置信区间吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/595786/calculating-the-confidence-interval-or-standard-error-of-a-ppv-adjusted-for-prev</guid>
      <pubDate>Tue, 15 Nov 2022 16:51:56 GMT</pubDate>
    </item>
    <item>
      <title>IPW之后如何进行竞争风险回归？</title>
      <link>https://stats.stackexchange.com/questions/579723/how-to-do-competing-risks-regression-after-ipw</link>
      <description><![CDATA[我的数据中有4种治疗类型。为了平衡不同治疗组的协变量，我使用了 twang :: mnps 功能来执行反比概率加权并成功获得权重。 ASMDS表明，这四组之间的协变量与权重平衡。但是我找不到在IPW之后在数据中执行多变量竞争风险回归的方法。我只发现 cmprsk :: crr 函数可用于执行多变量的竞争风险回归。但是在 crr 功能中没有权重的论点。因此，如何在IPW之后执行加权多变量竞争风险回归？]]></description>
      <guid>https://stats.stackexchange.com/questions/579723/how-to-do-competing-risks-regression-after-ipw</guid>
      <pubDate>Thu, 23 Jun 2022 07:04:16 GMT</pubDate>
    </item>
    </channel>
</rss>