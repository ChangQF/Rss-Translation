<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 20 May 2024 09:18:16 GMT</lastBuildDate>
    <item>
      <title>如何证明 EIV 回归模型中斜率 MLE 的单调性？</title>
      <link>https://stats.stackexchange.com/questions/647596/how-can-i-prove-monotonicity-of-slope-mle-in-eiv-regression-model</link>
      <description><![CDATA[我正在尝试计算 Casella 和 Berger 练习 12.4(c)，该练习涉及变量误差回归模型斜率的最大似然估计量的单调性。目标是表明
$$
\开始{对齐*}
\hat{\beta}(\lambda) &amp;= \frac{-(S_{xx} - \lambda S_{yy}) + \sqrt{(S_{xx} - \lambda S_{yy})^{2 } + 4 \lambda S_{xy}^{2}}}{2 \lambda S_{xy}}
\结束{对齐*}
$$
在$\lambda$中是单调的，如果$S_{xy} &gt; 则增加。 0$ 并减少如果 $S_{xy}  0$.
导数是
$$
\开始{对齐*}
\hat{\beta}&#39;(\lambda) &amp;= \left(\frac{S_{xx}\sqrt{(S_{xx} - \lambda S_{yy})^{2} + 4\lambda S_{ xy}^{2}} + \lambda S_{xx}S_{yy} - 2\lambda S_{xy}^{2} - S_{xx}^{2}}{\sqrt{(S_{xx} - \lambda S_{yy})^{2} + 4\lambda S_{xy}^{2}}}\right) \left(\frac{1}{2\lambda^{2} S_{xy}}\正确的）
\结束{对齐*}
$$
如果我可以证明分子 ($S_{xx}\sqrt{(S_{xx} - \lambda S_{yy})^{2} + 4S_{xy左侧的 }^{2}\lambda} + \lambda S_{xx}S_{yy} - 2S_{xy}^{2}\lambda - S_{xx}^{2}$)项是正数，那么我就完成了。
我们有约束$S_{xx} &gt; 0$，$S_{yy}&gt; 0$，$S_{xy}^{2} \le S_{xx}S_{yy}$。
我为此花费的时间比我愿意承认的要长得多，而且与开始时相比，我并没有更接近目标。每次尝试使用 $S_{xy}^{2} \le S_{xx}S_{yy}$ 约束来导出有用的“初始项大于” 0”不平等走进了死胡同。
如果有任何指点，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/647596/how-can-i-prove-monotonicity-of-slope-mle-in-eiv-regression-model</guid>
      <pubDate>Mon, 20 May 2024 07:19:22 GMT</pubDate>
    </item>
    <item>
      <title>关于线性回归的基本数据清理的问题</title>
      <link>https://stats.stackexchange.com/questions/647593/questions-on-basic-data-cleansing-for-linear-regression</link>
      <description><![CDATA[我正在遵循一些关于进行线性回归的教程，并且在构建笔记本时，我正在研究异常值检测，并且在用于进行异常值检测的技术中，其中之一涉及计算标准偏差，但是对于我需要知道我的列是否属于高斯分布。我知道有不同的技术，例如：
直方图
KDE 图
Q-Q图
科洛莫戈洛夫-斯米尔诺夫检验
夏皮罗-威尔克检验
达戈斯蒂诺和皮尔逊检验
我敢打赌还有更多。那么最好使用哪一种呢？我想直方图只是提供了线索，但并没有显示真正的意图。识别数据集是否为高斯分布的标准做法是什么？例如，我绘制了波士顿数据集和 RM 列的直方图（每间住宅的平均房间数），我发现它是高斯分布：

但是当我使用 shapiro 和 kstest 时，它说 RM 不是高斯！
对于 X.columns 中的 i：
    print(f&#39;{i}: {“非高斯” if shapiro(X[i])[1]&lt;0.05 else “高斯”} {shapiro(X[i])}&#39;)
    print(f&#39;{i}: {“非高斯” if kstest(X[i].values,“范数”)[1]&lt;0.05 else “高斯”} {kstest(X[i].values) ,“标准”)}&#39;)

上面的代码打印：
RM：非高斯 ShapiroResult（统计=0.9608722575483464，pvalue=2.411976537849353e-10）
RM：非高斯 KstestResult（统计=0.9998152774582629，pvalue=0.0，statistic_location=3.561，statistic_sign=-1）

怎么会这样呢？我应该相信什么？
此外，我计算了零和 NaN 的数量，如下所示：
列 ZN：零 = 372，NaN = 0
CHAS 列：零 = 471，NaN = 0

查看这些列的含义：
ZN - 划分为 25,000 平方英尺以上地块的住宅用地比例。
CHAS - 查尔斯河虚拟变量（如果区域边界为河流，则为 1；否则为 0）

我如何决定将它们作为特征列还是忽略它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/647593/questions-on-basic-data-cleansing-for-linear-regression</guid>
      <pubDate>Mon, 20 May 2024 05:21:30 GMT</pubDate>
    </item>
    <item>
      <title>获得观察模式的统计显着差异</title>
      <link>https://stats.stackexchange.com/questions/647592/getting-statistically-significant-differences-of-observation-patterns</link>
      <description><![CDATA[首先我要说的是，如果我对统计学了解更多一点，我想我可能能够找到解决问题的方法。然而，你必须原谅我，因为我不确定如何用一般统计术语来表述它，从而产生有效的谷歌搜索。解决问题。
我有一个由位置序列定义的模式。假设我有这个模式的 2 个实例，每个实例的长度都相等 $n$ （模式的长度和位置始终相同）。将此模式称为 $X$，并且在任意位置进行观察 $i=0,1,...n$&lt; /span&gt; 为 $X_i$。
在我的模式的任何位置，我对存在 3 种类型的属性（我们称之为类型）进行了不同数量的观察 $A,B,C$&lt; /跨度&gt;。我的观察也可能产生空白（无类型），这意味着没有发现颜色。我可以用一个向量来表示，其中列是类型，值是观测值的数量： $X_i = (X_{iA}, X_{iB}, X_{iC}, X_ {iN})$。作为参考，观测总数的数量级 $\Sigma \ X_i = 10$。
我的模式 $X$ 因此是一个 $n*4$ 矩阵。我有两个 $X$ 实例，我想知道它们总体上是否不同（或者在我可以概括的子集中）。我知道 $X$ 的每个实例都是从不同的采样池中获取的（我提到这一点是为了防止模式随采样池的变化而变化）。如果重要的话，可以认为采样池是独立的。
感谢您为我指明正确方向的任何帮助。到目前为止，我的搜索已经让我在多项分布、似然比和 Z 分数上陷入了 MLE 的困境，但是我很难将我所学到的知识推广到我的特定解决方案。感谢您的时间和帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/647592/getting-statistically-significant-differences-of-observation-patterns</guid>
      <pubDate>Mon, 20 May 2024 04:26:46 GMT</pubDate>
    </item>
    <item>
      <title>如何解决这个关于汽车传感器的贝叶斯表达式问题？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647591/how-to-solve-this-bayesian-expression-question-about-car-sensor</link>
      <description><![CDATA[在每个时间步 t，传感器返回 K 辆汽车的精确位置列表，但位置列表会移动随机数量的索引（带有环绕）。例如，如果时间步 1 的真实汽车位置为 c11=(1,1),c12=(3,1),c13=(8,1),c14=(5,2)，则 e1 将为 [ (1,1),(3,1),(8,1),(5,2)], [(3,1),(8,1),(5,2),(1,1)] 、[(8,1)、(5,2)、(1,1)、(3,1)] 或 [(5,2)、(1,1)、(3,1)、(8, 1)]，每个概率为 1/4。这种转变可以从一个时间步长改变到下一时间步长。
定义辅助变量 z1,z2,…zt，可用于对 ct 和 et 之间的关系进行建模。用 e1,⋯,et 和 zt 给出 p(ct∣ct−1) 的表达式。]]></description>
      <guid>https://stats.stackexchange.com/questions/647591/how-to-solve-this-bayesian-expression-question-about-car-sensor</guid>
      <pubDate>Mon, 20 May 2024 04:04:43 GMT</pubDate>
    </item>
    <item>
      <title>在R中，当在表格（最好是gsummary）中呈现数据（RCT）时，如何包括组内和组间的显着性检验？ [图片][关闭]</title>
      <link>https://stats.stackexchange.com/questions/647590/in-r-when-presenting-data-rct-in-a-table-preferably-gtsummary-how-to-inclu</link>
      <description><![CDATA[我正在学习如何使用 R 分析数据并呈现 RCT 的结果。我尝试阅读软件包文档，并在线搜索，但未找到解决方案。我有 2 组参与者，并且想在一个表中表达两组的基线数据、每组的变化（从基线到终点）以及终点之间的差异 - 所有这些都针对每个结果。我在下面附上了一个示例表。

我模拟了一个数据框，并尝试编写代码，并将在此处讨论这些问题
ID &lt;- seq(1:50)
data &lt;- data.frame(ID)
data$drug &lt;- rbinom(n = 50, 1, prob = 0.5)
data$drug &lt;- factor(data$drug, levels = c(0, 1), 
labels = c(&quot;Drug X&quot;, &quot;Drug Y&quot;))
data$wt_0 &lt;- rnorm(n = 50, mean = 70, sd = 5)
data$wt_12 &lt;- rnorm(50, 68, 4.9)
head(data)

library(gtsummary)
library(gt)
subset(data, select = -ID) %&gt;%
tbl_summary(by = drug) %&gt;% 
add_p()


我尝试手动添加体重变化列
data_new &lt;- data
data$wt_change &lt;- data$wt_0 - data$wt_12
subset(data_new, select = -ID) %&gt;%
tbl_summary(by = drug) %&gt;% 
add_p()


我想要一个像最初显示的表格。并且，每行应该只对应一个结果。使用 gtsummary() 包或 R 中的任何其他包是否可行？如果有人能帮忙就太好了，因为这可能是一种常见的情况
注意：是的，多重性调整并没有被违反，我们将声明其他测试（主要测试除外）是探索性的，不应被解释为探索性的]]></description>
      <guid>https://stats.stackexchange.com/questions/647590/in-r-when-presenting-data-rct-in-a-table-preferably-gtsummary-how-to-inclu</guid>
      <pubDate>Mon, 20 May 2024 03:50:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么二元正态性的充分统计量并不意味着二元正态性下相关性的充分统计量？</title>
      <link>https://stats.stackexchange.com/questions/647589/why-does-the-sufficient-statistic-for-the-bivariate-normal-not-imply-a-sufficien</link>
      <description><![CDATA[此问题链接到 Jon Wellner 撰写的文档它定义了多元正态的充分统计量（第 7 页，示例 2.7）。结果来自因式分解定理，并在对帖子的回复中得到证明。
但是，这篇文章中的示例 5（第 1316、1320-1321 页）&lt; Ghosh 等人 (2010) 对辅助性和条件推理的回顾表明，二元正态性下相关性的充分统计量尚不清楚。具体来说，它表明二元正态性下的相关性存在多个非唯一的辅助补充。它从建议的辅助补充文献中给出了许多例子。而且，这意味着选择或构建最佳的辅助统计数据仍然是一个悬而未决的（或者可能无法解决的）问题。
我的困惑是，我认为二元正态分布的足够统计量意味着相关性的足够统计量，因为后者是前者的参数。难道不是这样吗？如果没有，为什么不呢？如果是这样，为什么要以辅助补充为条件呢？或者我只是误解了这些例子——比如，Wellner 给出的统计数据只是渐近充分的，还是只是理论上的？]]></description>
      <guid>https://stats.stackexchange.com/questions/647589/why-does-the-sufficient-statistic-for-the-bivariate-normal-not-imply-a-sufficien</guid>
      <pubDate>Mon, 20 May 2024 03:48:23 GMT</pubDate>
    </item>
    <item>
      <title>销售数据趋势</title>
      <link>https://stats.stackexchange.com/questions/647588/sales-data-trend</link>
      <description><![CDATA[我有历史销售数据，我想检查趋势（增加、减少或没有变化）。当我制作年度折线图时，线性方程的斜率是正的（表示增加），但是当我制作月度图表并显示线性方程时，斜率是负的（非常小，但为负）。我不确定这意味着什么，或者线性方程是否是分析我的销售数据的最佳方法。如果我不输入线性方程，就很难在我的销售数据中看到一个水平。]]></description>
      <guid>https://stats.stackexchange.com/questions/647588/sales-data-trend</guid>
      <pubDate>Mon, 20 May 2024 02:33:15 GMT</pubDate>
    </item>
    <item>
      <title>模型训练损失始终收敛于 1.35</title>
      <link>https://stats.stackexchange.com/questions/647587/model-training-loss-always-converge-to-1-35</link>
      <description><![CDATA[我正在尝试使用 RNN 创建多类分类模型。输入数据的序列长度为 90，由 5 个特征组成，归一化到 [0,1] 范围。
这是我尝试过的网络架构，它是具有减少训练损失的最小容量模型：
inputs = tf.keras.Input(shape=(sequence_length, feature_length))
x1 = tf.keras.layers.GRU(512)(输入)
x2 = tf.keras.layers.LayerNormalization()(x1)
输出 = tf.keras.layers.Dense(4, 激活 =“softmax”)(x2)
模型= tf.keras.Model（输入，输出）

我尝试过的最大模型有 3 个 GRU 层，每层有 1024 个单元。
令我困惑的是，无论模型容量如何，所有模型的训练损失都收敛到 1.35 左右。我不明白为什么这些模型无论其容量如何都会始终收敛到相似的值。
有谁知道为什么会出现此问题以及如何解决它？]]></description>
      <guid>https://stats.stackexchange.com/questions/647587/model-training-loss-always-converge-to-1-35</guid>
      <pubDate>Mon, 20 May 2024 01:46:55 GMT</pubDate>
    </item>
    <item>
      <title>两个子群体回归模型的刀切方差估计</title>
      <link>https://stats.stackexchange.com/questions/647584/jackknife-variance-estimate-for-a-regression-model-for-two-subpopulation</link>
      <description><![CDATA[考虑两个亚群的回归模型
\begin{align}
Y_i&amp;=X_i+\epsilon_i, i=1,\ldots,n/2\\
Y_i&amp;=-X_i+\epsilon_i, i=n/2+1,\ldots,n \quad(1)
\end{对齐}
其中 $\{X_i\}$ 是 i.i.d.均值为零的随机变量。
我想使用折刀估计计算样本协方差的方差，其中样本协方差由 $$\hat{cov}((X_1,. ..,X_n),(Y_1,...,Y_n))=\frac{1}{n}\sum_{i=1}^{n}X_iY_i-\frac{1}{n}\sum_{i =1}^{n}X_i\frac{1}{n}\sum_{i=1}^{n}Y_i.$$
有趣的是，我发现两种不同的视角给出了不同的样本协方差方差。我们将模型写为
$$Y_i=\beta_iX_i+\epsilon_i$$
首先，我们将 $\beta_i$ 视为常量（对于 i=1,...,n/2 等于 1，对于 i=n 等于 -1 /2+1,...,n), 那么通过计算我们有
$$var(\hat{cov}((X_1,...,X_n),(Y_1,...,Y_n)))=\frac{1}{n} \{E(X^4)+E(\epsilon^2)-(E(X^2)^2)\}+o_p(\frac{1}{n})$$
其次，我们认为 $\beta_i$ 是来自分类分布的随机变量。 $P(\beta_i)=1)=P(\beta_i)=-1)=0.5$。那么通过计算我们有
$$var(\hat{cov}((X_1,...,X_n),(Y_1,...,Y_n)))=\frac{1}{n} \{E(X^4)+E(\epsilon^2)\}+o_p(\frac{1}{n})$$
这两个推导经过仿真验证，结果是正确的。当数据生成过程恰好来自（1）时，我认为我们应该使用第一个视角来估计方差。然而，当我使用折刀估计来近似协方差的方差时，它支持第二种观点。这很令人困惑，因为我实际上并没有通过将 $\beta$ 视为随机变量来生成数据。
这个现象有什么解释吗？如果我想要从第一个角度对协方差进行方差估计，即将回归系数视为常数，我可以通过使用子采样技术来实现吗？
这是模拟代码
&lt;前&gt;&lt;代码&gt;n=1000

#第一视角的方差估计
β=c(代表(1,500),代表(-1,500))
veccov=NULL
for(i in 1:1000){
  x=rnorm(n,sd=1)
  y=x*beta+rnorm(n,sd=1)
  veccov=c(veccov,cov(x,y))
}

var(veccov)*n

#第二视角的方差估计
n=1000
veccov=NULL
for(i in 1:1000){
  β=样本(c(1,-1),n,替换=T)
  x=rnorm(n,sd=1)
  y=x*beta+rnorm(n,sd=1)
  veccov=c(veccov,cov(x,y))
}

var(veccov)*n

#100 倍折刀方差估计
#数据是从第一视角生成的
β=c(代表(1,500),代表(-1,500))
veccov=NULL
for(i in 1:100){
  x=rnorm(n,0,sd=1)
  y=x*beta+rnorm(n,sd=1)
  
  covxyfull=cov(x,y)
  covxy=NULL
  for(j in 1:n){
    covxy=c(covxy,cov(x[-j],y[-j]))
  }
  
  jcovxy=n*covxyfull-(n-1)*covxy
  veccov=c(veccov,var(jcovxy))
}
均值（维可夫）
]]></description>
      <guid>https://stats.stackexchange.com/questions/647584/jackknife-variance-estimate-for-a-regression-model-for-two-subpopulation</guid>
      <pubDate>Mon, 20 May 2024 01:24:49 GMT</pubDate>
    </item>
    <item>
      <title>具有异方差性的 R 中的分层回归</title>
      <link>https://stats.stackexchange.com/questions/647581/hierarchical-regression-in-r-with-heterocedasticity</link>
      <description><![CDATA[我使用 lm 在 R 中执行了层次回归。我使用性能包通过统计和视觉方式评估了这些假设。从视觉上看，我观察到异方差性，尽管 Breuch-Pagan 是正确的。尽管如此，我想使用健壮的包来稳健地运行层次回归分析。我用 lmrob 做到了这一点，没有出现任何问题。关于系数 $R^2$ 和调整后的 $R^2$ 的结果几乎相同在非鲁棒模型中。但当我跑步时
anova(modelr1, modelr2, model3r, modelr4) 得到
关于 $F$ 的信息，我得到了非常不同的结果。我不明白为什么。有没有人在 R 中做过具有异方差性的层次回归并且可以帮助我
模型示例
mstep1 &lt;- lm (X ~ A + B + D + E, data=数据)
mstep2 &lt;- lm (X ~ A + B + D + E + F, data=数据)
mstep1r &lt;- lmrob (X ~ A + B + D + E, data=Data)
mstep2r &lt;- lmrob (X ~ A + B + D + E + F, data=Data)

方差分析（mstep1，mstep2，mstep3，mstep4）
方差分析表
Res.Df RSS Df Sq F 之和 Pr(&gt;F)
1 909 1728.1
2 908 1622.5 1 105.547 59.3509 3.456e-14 ***
3 907 1611.5 1 11.002 6.1866 0.01305 *
4 906 1611.2 1 0.319 0.1793 0.67212

```方差分析（mstep1r，mstep2r，mstep3r，mstep4r）
鲁棒 Wald 测试台
  伪Df Test.Stat Df Pr(&gt;chisq)
1933
2 934 0.019976 1 0.8876
3 934 0.019976 1 0.8876
4 934 0.019976 1 0.8876

````&gt; test_wald(mstep1,mstep2,mstep3,mstep4)
名称 |型号| df | df_diff | df_diff | F | p
-----------------------------------------------------------
mstep1 | LM | 909 | 909 | |
mstep2 | LM | 908 | 908 1.00 | 59.35 | 59.35 &lt; .001
mstep3 | LM | 907 | 907 1.00 | 6.19 | 6.19 0.013
mstep4| LM | 906 | 906 1.00 | 0.18 | 0.18 0.672
模型被检测为嵌套的（就固定参数而言）并按顺序进行比较。
&gt; test_wald（mstep1r，mstep2r，mstep3r，mstep4r）
名称 |型号| df | df_diff | df_diff | F | p
------------------------------------------------
mstep1r|抱歉，暂无相关信息936 | 936 | |
mstep2r|抱歉，暂无相关信息935 | 935 1.00 | 65.63 | &lt; .001
mstep3r | mstep3r |抱歉，暂无相关信息934 | 934 1.00 | 10.06 | 10.06 0.002
mstep4r | mstep4r |抱歉，暂无相关信息933 | 933 1.00 | |
模型被检测为嵌套的（就固定参数而言）并按顺序进行比较。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647581/hierarchical-regression-in-r-with-heterocedasticity</guid>
      <pubDate>Mon, 20 May 2024 00:11:02 GMT</pubDate>
    </item>
    <item>
      <title>原假设是否需要是无差异的陈述？</title>
      <link>https://stats.stackexchange.com/questions/647557/does-the-null-hypothesis-need-be-a-statement-of-no-difference</link>
      <description><![CDATA[我只是想自学统计学的基础知识。而且我不完全理解原假设与备择假设。
我不明白的是：原假设可以是有方向性的陈述，还是必须始终是无差异的陈述？
例如，假设我们有组 1 和组 2：
$$H_0: \mu_1 = \mu 2$$
$$H_1: \mu_1 \neq \mu 2$$
与不同的陈述
$$H_0: \mu_1 \leq \mu 2$$
$$H_1: \mu_1 \gt \mu 2$$
这两个语句都有效，因此 $H_0$ 可以具有方向性吗？
我已经与 ChatGPT 讨论过这个问题，但它出现了明显的矛盾。]]></description>
      <guid>https://stats.stackexchange.com/questions/647557/does-the-null-hypothesis-need-be-a-statement-of-no-difference</guid>
      <pubDate>Sun, 19 May 2024 15:53:10 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归模型的单边似然比检验？</title>
      <link>https://stats.stackexchange.com/questions/647549/one-sided-likelihood-ratio-test-for-a-logistic-regression-model</link>
      <description><![CDATA[我需要对逻辑回归模型的一个参数运行单方面测试：
$H_0$：$\beta = 0$
$H_1$：$\beta \geq 0$
我想避免与 Wald 等效的方法，因为已知这些方法在逻辑回归方面存在问题。 （Piegorsch，1990）表明基于单边似然比的检验对于 glms 是可能的。有在 R 中实现过吗？
如果不是，以下是实施测试的合法方法（对于 alpha = 0.05）吗？

使用confint计算两侧90%置信区间；请注意，从 R 4.4.0 开始，它使用 MASS 中的轮廓似然方法。
将 CI 的下端替换为 -∞，以获得单边置信区间。
如果 CI 排除 0，则拒绝 H0。

Piegorsch W.W. (1990)。二分响应下广义线性模型的单边显着性检验。生物识别学，46(2), 309–316。]]></description>
      <guid>https://stats.stackexchange.com/questions/647549/one-sided-likelihood-ratio-test-for-a-logistic-regression-model</guid>
      <pubDate>Sun, 19 May 2024 12:39:11 GMT</pubDate>
    </item>
    <item>
      <title>轻松估算标准误差[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647502/estimate-standard-errors-effortlessly</link>
      <description><![CDATA[我有一个未观察到的变量 $𝑧_𝑖$，以及它的三个观察到的估计值：$𝑤_𝑖、𝑥_𝑖、𝑦_𝑖$ 。误差 $𝑤_𝑖−𝑧_𝑖,𝑥_𝑖−𝑧_𝑖,𝑦_𝑖−𝑧_𝑖$ 为零均值，彼此独立且在  之间独立$𝑖$，但 $𝑖$ 之间的分布是相同的（尽管不一定在 $𝑤$ 之间） 、$𝑥$ 和 $𝑦$）。如果我有 $𝑁$
观察值 ($𝑖=1,…,𝑁$)，如何估计 $𝑤$ 的标准误差span&gt;、$𝑥$ 和 $𝑦$？
$W$ 和 $X$ 之间的差异的方差为 $\textrm{Var}(W-X) = \textrm{se}^2_W + \textrm{se}^2_X$ 在上述设置下，当  $N\rightarrow \infty$ 其中 $\textrm{se}$ 代表标准错误。这同样适用于“$X$”和“$Y$”和“$Y$ 和 $W$”。
所以我们有
$$
\开始{对齐}
\textrm{Var}(W-X) &amp;= \textrm{se}^2_W + \textrm{se}^2_X, \\
\textrm{Var}(X-Y) &amp;= \textrm{se}^2_X + \textrm{se}^2_Y,\\
\textrm{Var}(Y-W) &amp;= \textrm{se}^2_Y + \textrm{se}^2_W。
\结束{对齐}
$$
差异的方差（左侧）可以根据观察到的数据计算出来。该方程组是否提供标准误差的解？特别是，该系统的反演提供了解析解，但这真的解决了吗？
我特别想知道，因为如果确实如此，这样的解决方案将在实际应用中产生重大影响：在这样的应用中，我们想要估计/测量一些潜在的 $Z$ （既不是固定的也不是固定的，但可以根据测量的时间/地点而变化）通过使用我们的模型/假设/设备$X$；为了验证我们的 $X$，我们准备更可靠的数据（地面事实或测试数据）作为 $Y$&lt; /span&gt; （生成配对数据集 $\{(X_i, Y_i)\}_{i=1}^N$ 其中 $N$ 表示观察索引，例如时间戳和/或位置编号等）；这里我们知道 $X-Y$ 差异的标准差给出了复合标准误差 ($\textrm{Var} (X-Y) = \textrm{se}^2_X + \textrm{se}^2_Y$) 但无法分解为每个标准错误（特别对 $\textrm{ se}_X$）。上面的三个方程组告诉我们，只有引入一个新变量 $W$，$\textrm{se}_X$  是可以估计的，更令人惊讶的是， $W$ 不需要依赖于 $Z$ （不需要测量 $Z$），但可以是不相关的随机数。]]></description>
      <guid>https://stats.stackexchange.com/questions/647502/estimate-standard-errors-effortlessly</guid>
      <pubDate>Sat, 18 May 2024 14:27:38 GMT</pubDate>
    </item>
    <item>
      <title>将百分比组与对名义问题的回答进行比较[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647463/comparing-percentage-groups-with-responses-to-nominal-question</link>
      <description><![CDATA[我可以使用什么统计测试来查看某个问题的回答对于某些人群是否具有统计显着性？]]></description>
      <guid>https://stats.stackexchange.com/questions/647463/comparing-percentage-groups-with-responses-to-nominal-question</guid>
      <pubDate>Sat, 18 May 2024 02:06:06 GMT</pubDate>
    </item>
    <item>
      <title>寻找嘈杂多边形的角点</title>
      <link>https://stats.stackexchange.com/questions/647344/finding-the-corners-of-noisy-polygons</link>
      <description><![CDATA[我有一些多边形，例如如下所示：

如果我将一侧放大得非常近，您可以看到噪音。

数据是 x 坐标列表和相应的 y 坐标列表。
我想要一种能够找到更小、更简单、噪音更少的坐标列表的算法。
我认为多边形的边是线性方程的连续列表。
我读到了Lasso并决定尝试一下。
from sklearn.linear_model import Lasso
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

xs_name = &quot;xs.txt&quot;;
ys_name = &quot;ys.txt&quot;;

xs = np.loadtxt(xs_name).reshape(-1, 1)
ys = np.loadtxt(ys_name).reshape(-1, 1)

reg = 套索(alpha=0.1)
reg.fit(xs, ys)

供参考，xs 和 ys 如下所示：
xs

ys

但是我只得到一个系数
&lt;前&gt;&lt;代码&gt;reg.coef_
输出[31]：数组（[0.82647029]）

我希望获得每条识别线的系数列表。
我觉得我在概念上错过了一些东西。我什至不确定 Lasso 是否适合这项工作。
有谁知道我如何正确使用 Lasso，或者向我指出适合这项工作的正确工具。
&lt;小时/&gt;
编辑
x 坐标
坐标
我还认为值得一提的是，调查论文中也提到了 group lasso 破裂库
&lt;小时/&gt;
编辑
为了清楚起见，放大的区域用红色圈出

编辑
我在 R 中尝试自回归模型取得了一些成功
xs &lt;- read.table(&#39;xs.txt&#39;, sep=&quot;\n&quot;)
ys &lt;- read.table(&#39;ys.txt&#39;, sep=&quot;\n&quot;)

xs &lt;- as.numeric(as.character(unlist(xs)))
ys &lt;- as.numeric(as.character(unlist(ys)))

fastcp_xs &lt;- fastcpd::fastcpd.ar(xs, 3, r.progress = FALSE)
摘要（fastcp_xs）
情节（fastcp_xs）


然而，在这种情况下，这种方法的成功似乎主要是运气，因为在更多数据上尝试此方法会发现不好的结果。
在 ys 上尝试相同的方法：
fastcp_ys &lt;- fastcpd::fastcpd.ar(ys, 3, r.progress = FALSE)
摘要（fastcp_ys）
情节（fastcp_ys）


自回归模型无法检测 ys 的边缘。
fastcpd 库中的其他例程在我的情况下似乎给出了类似的糟糕结果。
我目前认为我最好的选择是某种形式的套索算法。因为套索的概念是拟合一系列直线。
这可能会变成线性规划问题。
也许我需要求助于使用类似 pyomo 的东西？]]></description>
      <guid>https://stats.stackexchange.com/questions/647344/finding-the-corners-of-noisy-polygons</guid>
      <pubDate>Thu, 16 May 2024 07:46:23 GMT</pubDate>
    </item>
    </channel>
</rss>