<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 29 Nov 2024 12:35:02 GMT</lastBuildDate>
    <item>
      <title>原始协方差与多个 MCMC 链上均值的协方差之间的等价性</title>
      <link>https://stats.stackexchange.com/questions/658028/equivalence-between-raw-covariance-and-covariance-of-mean-over-multiple-mcmc-cha</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658028/equivalence-between-raw-covariance-and-covariance-of-mean-over-multiple-mcmc-cha</guid>
      <pubDate>Fri, 29 Nov 2024 11:56:15 GMT</pubDate>
    </item>
    <item>
      <title>RWE：使用目标试验模拟框架：为什么要模拟 RCT？</title>
      <link>https://stats.stackexchange.com/questions/658027/rwe-use-of-target-trial-emulation-framework-why-aiming-to-emulate-rct</link>
      <description><![CDATA[Hernán 和 Robins [1] 于 2016 年引入了目标试验模拟框架，以定义观察性研究中感兴趣的问题。目标试验框架要求研究人员指定 RCT 方案的关键要素，这些要素理想情况下将用于解决感兴趣的问题。但是，如果无法模拟目标 RCT，那么因果问题就无法制定。为什么他们的目标是完全模拟 RCT？是因为在 RCT 中定义因果问题所需的假设较少吗？
[1] Hernán, M. A. 和 Robins, J. M. (2016)，“当无法进行随机试验时使用大数据模拟目标试验”，美国流行病学杂志，183，758–764。]]></description>
      <guid>https://stats.stackexchange.com/questions/658027/rwe-use-of-target-trial-emulation-framework-why-aiming-to-emulate-rct</guid>
      <pubDate>Fri, 29 Nov 2024 11:51:32 GMT</pubDate>
    </item>
    <item>
      <title>如何为多元荟萃分析假设两种精神疾病之间的协方差 (rho)</title>
      <link>https://stats.stackexchange.com/questions/658022/how-can-i-assume-covariance-rho-between-two-psychiatric-disorders-for-multivar</link>
      <description><![CDATA[我想进行多变量荟萃分析，因为每个研究都有几种效应大小。例如，我想调查品行障碍 (CD) 和对立违抗性障碍 (ODD) 对物质使用障碍（包括酒精使用障碍 [AUD] 和药物使用障碍 [DUD]）的风险（比值比）。例如，
研究 A 研究了 AUD 上的 ODD 风险、DUD 上的 ODD 风险、AUD 上的 ODD 风险和 DUD 上的 CD 风险。
研究 B 研究了 AUD 上的 ODD/CD 风险和 DUD 上的 ODD/CD 风险（因此不是 ODD 和 CD 的两种不同测量方法，而是合二为一）
研究 C 研究了 AUD/DUD 上的 ODD 风险和 AUD/DUD 上的 CD 风险
通过多变量荟萃分析，我可以控制预测因子（ODD 和 CD）和结果（物质使用障碍）的相关结构，因为它考虑了嵌套结构。问题是我必须假设构造之间存在协方差，以便正确校正相关结构。个别研究没有报告这种协方差。
我如何假设足够的协方差？有关于例如 ODD 和 CD 之间遗传相关性的文献，我应该使用这种遗传相关性作为协方差吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658022/how-can-i-assume-covariance-rho-between-two-psychiatric-disorders-for-multivar</guid>
      <pubDate>Fri, 29 Nov 2024 09:44:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么卡方检验给出不直观的结果？</title>
      <link>https://stats.stackexchange.com/questions/658020/why-is-the-chi-square-test-is-giving-unintuitive-results</link>
      <description><![CDATA[我正在对不同年龄组之间的变量分布进行卡方检验。数据在 R 中如下所示：
 a &lt;- c(66,97, 48)
b &lt;- c(145,174,58)
c &lt;- c(129,128,58)

M &lt;- data.frame(cbind(a,b,c))
colnames(M) &lt;- c(&quot;18-34&quot;, &quot;35-49&quot;,&quot;50-66&quot;)
rownames(M) &lt;- c(&quot;Below avg&quot; , &quot;Average&quot;,&quot;Above avg&quot;)
view(M)

绘制时，最年轻组的数据分布与中间组相似，与最年长组不同。

如果我进行整体卡方检验，我会得到一个不显著的差异：
X-squared = 8.6905, df = 4, p-value = 0.06932

但是，如果我成对比较年龄组，我会得到最小和中间之间的显著差异，而不是最小和最年长之间的显著差异。
数据：M[, 1:2]
X-squared = 6.0153, df = 2, p-value = 0.04941

数据：M3[, c(1, 3)]
X-squared = 5.2093，df = 2，p 值 = 0.07393

我认为这与每个年龄组的参与者数量不平衡有关，尽管每个组的总体观察数量相当大。但我不确定是否以及如何解释这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/658020/why-is-the-chi-square-test-is-giving-unintuitive-results</guid>
      <pubDate>Fri, 29 Nov 2024 09:07:03 GMT</pubDate>
    </item>
    <item>
      <title>使用 $\beta$ 系数对模型中的特征进行优先级排序</title>
      <link>https://stats.stackexchange.com/questions/658019/prioritization-of-features-in-model-using-beta-coefficients</link>
      <description><![CDATA[我想知道 - 如果您有一个模型，它为您提供了每个变量的 $\beta$ 估计值，但没有 p 值，那么如何优先考虑对结果影响更大的变量？
请注意，我不希望集中和缩放所有变量，我有不同性质的数据，这些数据已进行了相应的标准化。
对于连续变量，我正在考虑考虑系数 &lt;​​span class=&quot;math-container&quot;&gt;$\tilde{\beta}=\beta_X \cdot range(X)$ 或 $\tilde{\beta}=\beta_X \cdot sd(X)$，以消除变量范围与 $\beta$ 之间的高度依赖性估计。
对于分类变量，我考虑考虑$\beta$本身，因为它们不依赖于变量的范围。
这种方法正确吗？如果正确，如何客观地比较连续变量与分类变量的影响？
谢谢！
我的想法是进行特征选择，他们根据模型中的重要性提供了所选特征的列表。]]></description>
      <guid>https://stats.stackexchange.com/questions/658019/prioritization-of-features-in-model-using-beta-coefficients</guid>
      <pubDate>Fri, 29 Nov 2024 07:59:06 GMT</pubDate>
    </item>
    <item>
      <title>基于专家建议的在线二元决策的下限</title>
      <link>https://stats.stackexchange.com/questions/658018/lower-bound-for-online-binary-decision-making-with-expert-advice</link>
      <description><![CDATA[假设我们想要根据 $k$ 位专家的建议，对 $n$ 个二元决策进行排序。我们根据从其处获得建议的最佳专家来定义遗憾。现在我想证明我们将至少享受 $\Omega(m)$ 个遗憾，其中 $m=\min \{n,\log k\}$。当 $n&gt;\log k$ 时，情况对我来说很清楚，但对于其他情况，我不知道该如何进行。]]></description>
      <guid>https://stats.stackexchange.com/questions/658018/lower-bound-for-online-binary-decision-making-with-expert-advice</guid>
      <pubDate>Fri, 29 Nov 2024 07:51:02 GMT</pubDate>
    </item>
    <item>
      <title>带有插值数据的回归模型？</title>
      <link>https://stats.stackexchange.com/questions/658017/regression-models-with-interpolated-data</link>
      <description><![CDATA[我有一个国家，里面有很多城市（层级结构：国家-省-城市）。我只有 2010 年和 2020 年每个城市的平均社会经济信息（例如就业率、中位数收入等）。
2016 年举行了选举。我知道从 2010 年到选举期间每个城市的政治倾向，以及选举后政治倾向的变化。
我想建立一个回归模型，研究社会经济条件的变化如何影响投票选择（我知道生态谬误，我只对研究总体趋势感兴趣，而不是将其推广到总体中的个人）。
如果我每年都有数据，我会尝试使用一些技术，例如差异差异或回归不连续性，以查看选举前后的情况。但是，就我而言，这不可用。
我对该怎么做有这个天真的想法。

我认为我可以创建一个基于增长率的插值回归模型。我首先假设每个社会经济变量有一个简单的纵向模型（假设它只依赖于自身而不依赖于其他因素，遵循单调/均匀变化的线性增长）：

$$ \frac{x_{i,2020} - x_{i,2010}}{x_{i,2010}} = \alpha_0 + u_{px} + v_{ix} + \epsilon_{ix} $$
其中：

$\alpha_0$ 是所有城市的平均增长率
$u_{px}$ 是各省与平均增长率的偏差
$v_{ix}$ 是城市与其所在省份增长率的偏差
$\epsilon_{ix}$ 是误差项

现在，对于 2010 年至 2020 年之间任何时间 $t$ 的插值，我们想要计算到时间 $t$ 时应该发生的总变化的百分比。公式变为：
$$ \hat{x}_{it} = x_{i,2010}\left(1 + \frac{t-2010}{10}(\alpha_0 + u_{px} + v_{ix})\right) $$
例如具体计算：
$$ \hat{x}_{i,2015} = x_{i,2010}\left(1 + \frac{2015-2010}{10}(\alpha_0 + u_{px} + v_{ix})\right) $$
$$ \hat{x}_{i,2015} = x_{i,2010}\left(1 + \frac{5}{10}(\alpha_0 + u_{px} + v_{ix})\right) $$
$$ \hat{x}_{i,2015} = x_{i,2010}(1 + 0.5(\alpha_0 + u_{px} + v_{ix})) $$

从这里我将转换概率 $\pi_{ijk}$ 定义为城市 $i$ 从 2015 年的政治归属 $j$ 转变为 2016 年的政治归属 $k$ 的概率。我想到这个转换样式模型：

$$ \log\left(\frac{\pi_{ijk}}{\pi_{ijJ}}\right) = \beta_{jk0} + \theta_{jk}&#39;\mathbf{w}_i + u_{pjk} $$
其中：

$\mathbf{w}_i$ 是一个包含社会经济预测因子的向量：
$$ \mathbf{w}_i = \begin{bmatrix} \hat{x}_{i,2016} \\ \hat{z}_{i,2016} \\ (\hat{x}_{i,2016} - \hat{x}_{i,2015}) \end{bmatrix} $$
$\theta_{jk}$ 是一个特定于过渡的系数向量
$\beta_{jk0}$ 是从状态 $j$ 到 $k$ 的基线转换概率&gt;
$J$ 表示参考类别
$u_{pjk}$ 是从 $j$ 到 $k$ 转换的省份特定随机效应。

我感觉我的建模方法完全失败了，哈哈。插值值有误差，而第二步没有考虑到这个误差。我确信这里有很多问题。有人能告诉我我到底搞砸了多少吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658017/regression-models-with-interpolated-data</guid>
      <pubDate>Fri, 29 Nov 2024 05:34:47 GMT</pubDate>
    </item>
    <item>
      <title>置信区间 - CLT，初级水平</title>
      <link>https://stats.stackexchange.com/questions/658015/confidence-interval-clt-begginer-level</link>
      <description><![CDATA[我正在参加一个关于统计学的在线课程，更准确地说是关于置信区间的课程。
下面是一个练习，他们试图根据以前收集的数据估计每个月份可以出售的鞋子数量。
如下图所示，第 7 行代表月份，B 列代表鞋子尺码。
表格表示频率分布。

1- 如果我们取鞋子尺码 6（第 8 行），他们计算出的置信区间在 [1.8-4.04] 之间。
据我所知，我知道置信区间仅在正态分布上计算。但我看不出鞋子尺码 6 的分布表如何形成正态分布？
我说得对吗？
我知道，如果样本分布不正常，我们可以使用 CLT，即具有正态分布的样本的平均值。是否可以将其应用于 6 号鞋子（第 8 行）？

2- 为什么要计算标准误差？我以为标准误差仅适用于均值样本（CLT），而第 8 行中的数据不是样本均值，而是正态分布。

此外，标准误差公式的分母代表样本均值的数量，但事实并非如此。
有人可以澄清一下歧义吗？
谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/658015/confidence-interval-clt-begginer-level</guid>
      <pubDate>Fri, 29 Nov 2024 02:32:37 GMT</pubDate>
    </item>
    <item>
      <title>时间序列-线性滤波模型</title>
      <link>https://stats.stackexchange.com/questions/658014/time-series-linear-filter-model</link>
      <description><![CDATA[我正在研究时间序列中的线性滤波模型。
“线性滤波模型。一个可观察的时间序列 𝑧𝑡，其中连续值高度相关，通常可以被视为由一系列独立的“冲击”𝑎𝑡 产生的。这些冲击是从固定分布中随机抽取的，通常假设为正态分布，均值为零，方差为 𝜎2 𝑎。这种独立随机变量序列 𝑎𝑡、𝑎𝑡-1、𝑎𝑡-2、……称为白噪声过程。白噪声过程 𝑎𝑡 应该通过所谓的线性滤波器转换为过程 𝑧𝑡。线性滤波操作只是对先前的随机冲击𝑎𝑡取加权和，因此𝑧𝑡 = 𝜇 + 𝑎𝑡 + 𝜓1𝑎𝑡−1 + 𝜓2𝑎𝑡−2 + ⋯ = 𝜇 + 𝜓(𝐵)𝑎𝑡 (1.2.1) 一般来说，𝜇 是决定过程“水平”的参数，𝜓(𝐵)=1+ 𝜓1𝐵 + 𝜓2𝐵2 + ⋯ 是将𝑎𝑡 转换为𝑧𝑡的线性算子，被称为滤波器的传递函数。模型表示可以允许过程 {𝑧𝑡} 的值之间存在一系列灵活的依赖模式，这些依赖模式以独立（不可观察）随机冲击 𝑎𝑡 的形式表示。从理论上讲，权重形成的序列 𝜓1、𝜓2、… 可以是有限的，也可以是无限的。如果这个序列是有限的，或者是无限的，并且绝对可求和，即 ∑∞ 𝑗=0 |𝜓𝑗| &lt; ∞，则称滤波器是稳定的，过程 𝑧𝑡 是平稳的。参数 𝜇 是过程变化的平均值。否则，𝑧𝑡 是非平稳的，𝜇 除了作为过程水平的参考点之外没有特定含义。&quot;
根据共享的细节，我不确定这是否与移动平均模型相同。即使是 p 阶 MA 模型也是基于白噪声系数的线性组合。
MA 模型和线性滤波器模型之间到底有什么区别？请指教。]]></description>
      <guid>https://stats.stackexchange.com/questions/658014/time-series-linear-filter-model</guid>
      <pubDate>Fri, 29 Nov 2024 02:02:48 GMT</pubDate>
    </item>
    <item>
      <title>比较完成一项工作所需的时间</title>
      <link>https://stats.stackexchange.com/questions/657981/comparing-the-time-duration-to-do-a-job</link>
      <description><![CDATA[我需要比较两个不同工人完成生产操作的时间长度。
基本上，原材料被分成两个独立的组：一组物体将由工人 A 使用旧机器加工，每次加工需要一定数量的可变分钟数，而第二组物体由工人 B 使用新机器加工，每次加工也需要一定数量的可变分钟数。
然后我将得到两组数字：第一组是使用旧机器生产物体的测量时间，第二组是使用新机器生产物体的测量时间。
我应该使用什么统计测试来检查新机器的加工时间是否显著不同，因为时间分布可能不正常？]]></description>
      <guid>https://stats.stackexchange.com/questions/657981/comparing-the-time-duration-to-do-a-job</guid>
      <pubDate>Thu, 28 Nov 2024 13:38:32 GMT</pubDate>
    </item>
    <item>
      <title>神经网络使用反向传播可以学习布尔公式吗？</title>
      <link>https://stats.stackexchange.com/questions/657961/learnability-of-boolean-formulae-by-neural-networks-using-back-propagation</link>
      <description><![CDATA[我一直在研究神经网络和布尔公式。从我的努力来看，神经网络似乎通常无法使用反向传播来学习布尔公式。这在直觉上是有道理的，因为布尔公式的输出可以根据输入值表现出巨大的变化，因此会有很多不连续性，从而导致局部最优。
另一方面，我也明白，任何布尔公式都可以用神经网络来表示，根据通用近似定理，所以神经网络没有内在原因不能表示，因此可能学习任意的布尔公式。问题似乎出在学习算法上，所有通用的机器学习算法似乎都会陷入局部最优，无论我使用梯度下降、进化算法、期望最大化等，因为它们都基于局部增量改进是通向全局最优解的途径这一前提。
话虽如此，我也知道还有其他类型的算法，如 Quine-McCluskey 和 Espresso，它们可以从真值表中得出最小布尔公式。可以使用这些算法随后生成一个神经网络，该神经网络嵌入从真值表中得出的算法的最小布尔公式。或者，更简单，只需将真值表转换为神经网络。然而，据我所知，这些都是非常具体的算法，专门针对布尔公式，在更通用的机器学习环境中没有使用。
所以，这让我想到了我的问题。是否有任何证据表明神经网络能够或不能使用反向传播和梯度下降或任何其他通用机器学习算法来学习任意布尔公式？
我检查了 Cross Validated，并在 Google 上搜索了这个问题，但未能找到任何明确的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/657961/learnability-of-boolean-formulae-by-neural-networks-using-back-propagation</guid>
      <pubDate>Thu, 28 Nov 2024 01:09:53 GMT</pubDate>
    </item>
    <item>
      <title>需要使用结束标记来使 Ngram 模型正确</title>
      <link>https://stats.stackexchange.com/questions/657932/end-tokens-are-required-to-make-ngram-models-proper</link>
      <description><![CDATA[标准二元模型（例如定义于此处）基于以下原则在语料库$V$上定义概率分布：

单词$w$的边际概率定义为其在$V$中的计数除以$V$中的单词总数（计算重复次数）：$P(w) = \text{count}(w) / |V|$
一个单词跟随另一个单词的条件概率直观地定义为二元组计数与第一个单词计数之比：$p(w_2|w_1) = \text{count}(w_1 w_2) / \text{count}(w_1)$
（马尔可夫假设）：一个句子（一个单词序列）的概率可以通过链式法则计算：$p(w_1 w_2 ... w_n) = p(w_1) p(w_2|w_1) p(w_3|w_1 w_2)... \approx p(w_1) p(w_2|w_1) p(w_3|w_2) ...$

然而，这似乎并没有定义一个适当的概率分布。例如，取一个语料库 $V = \text{&quot;foo bar baz&quot;}$。然后，取所有可能的二元组上定义的联合分布 $w_1 w_2$。根据我们的原则：
\begin{equation}
p(w_1 w_2) = p(w_1) p(w_2|w_1) = [\text{count}(w_1) / 3][\text{count}(w_1 w_2) / \text{count}(w_1)]
\end{equation&gt;
如果 $w_1 w_2$ 不在语料库中，则显然 $p(w_1 w_2) = 0$。因此，联合分布中唯一非零的条目是 $p(\text{foo bar}) = p(\text{bar baz}) = 1/3$。这些的总和是$2/3 \neq 1$，那么这种分配是否不合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/657932/end-tokens-are-required-to-make-ngram-models-proper</guid>
      <pubDate>Wed, 27 Nov 2024 13:18:18 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在处理一个重复测量数据集，需要进行降维。在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法涉及以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 之间的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除非数字变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不均等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    <item>
      <title>如何制作一个能够抵御数据不平衡变化的分类器？</title>
      <link>https://stats.stackexchange.com/questions/657898/how-do-i-make-a-classifier-thats-robust-to-variation-in-data-imbalance</link>
      <description><![CDATA[我正在为通常非常不平衡的数据编写一个二元分类器，例如大多数类别中 99% 的数据（使用梯度提升），但我希望有一个分类器至少对不平衡的严重程度具有一定的鲁棒性。一个数据集与另一个数据集之间的不平衡率差异很大。A 类分数可能 &gt;99% 或低至 75%。理想情况下，我希望在单个训练集上训练我的分类器，然后让它在类别频率差异很大的测试集上表现得相当好。有没有既定的方法可以做到这一点？或者我只需要根据预期的不平衡程度为每个新数据集重新训练模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/657898/how-do-i-make-a-classifier-thats-robust-to-variation-in-data-imbalance</guid>
      <pubDate>Tue, 26 Nov 2024 20:26:32 GMT</pubDate>
    </item>
    <item>
      <title>关于神经网络反向传播的问题</title>
      <link>https://stats.stackexchange.com/questions/657684/questions-on-backpropagation-in-a-neural-net</link>
      <description><![CDATA[我理解如何以符号方式应用反向传播，用笔和纸计算公式。当真正将这些推导应用于数据时，我有两个问题：

假设某个梯度看起来像 $o_i \times w_{i,j}$，其中 $o_i$ 是第 $i$ 个神经元的输出，而 $w_{i,j}$ 是其权重之一。现在我有一批数据点，$o_i$ 中的每个数据点都有不同的值，那么我该如何用数字计算它？我是否只需对该批次中的所有数据点取平均值？
换句话说：假设我将误差（最后）定义为平均值，那么该平均值（期望值）是否只是与其余的反向传播一起传播，并且每当我看到输入数据的依赖性时，我只需插入平均运算符？
有人可以提供一些关于此的直觉吗？我的看法是，因为误差位于所有梯度的“分子”中，所以无论我们对它做什么，无论是平均还是求和，都可以简单地向后传播，您只需对您看到的所有项执行该运算符（例如平均）。如果您有一个常数（例如权重），它不会做任何事情，如果您有一个输出，您会对批次进行平均。这是合理的解释吗？

如果我们有一个较早的神经元 $N$，它在后面的层中作为输入出现两次，在进行反向传播时，我们可以在第二次遇到它时对其导数执行 $+=$，即我们可以天真地将各种梯度​​贡献相加。但是这个神经元可以以不同的方式参与后续神经元，它们可能有不同的数学表达式等。然而，我们可以天真地将其所有梯度相加，这是如何工作的？
这是一个很好的属性，但我不明白它是如何如此简单地发挥作用而没有任何问题。有人可以提供直观的解释吗？这似乎与“反向传播如何分块、分步骤地工作，因此确切的依赖关系不应该重要”有关，这是我目前的理解水平。

]]></description>
      <guid>https://stats.stackexchange.com/questions/657684/questions-on-backpropagation-in-a-neural-net</guid>
      <pubDate>Fri, 22 Nov 2024 14:20:10 GMT</pubDate>
    </item>
    </channel>
</rss>