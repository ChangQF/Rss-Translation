<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 29 Aug 2024 03:18:11 GMT</lastBuildDate>
    <item>
      <title>MANOVA - 单变量 Wilks 的 Lambda 检验（R 解释）</title>
      <link>https://stats.stackexchange.com/questions/653530/manova-univariate-wilks-lambda-test-r-interpretation</link>
      <description><![CDATA[我正在运行一个具有 2 个因变量和 2 个连续预测变量的 MANOVA 模型。 （仅供参考 - STATA 将此称为 MANCOVA，并要求在每个预测因子前面删除“c。”以表示每个预测因子在 manova 运行期间都是连续缩放的。无论如何，R 将直接接受连续变量，因此使用 manova 命令在 R 中运行 MANCOVA 不会出现问题） - 本质上是 MVNREG。
使用 UC-Irvine ML Repository Wine 数据集，模型为：
model &lt;- lm(cbind(alcohol, hue) ~ flavanoids + ash, na.action=na.exclude, data=wine)
wine.manova=manova(model)

我试图了解使用这两种方法时 Wilks&#39; Lambda 对黄烷类化合物预测因子的 F 近似值之间的差异：
方法1
library(car)
lh.out &lt;- linearHypothesis(model, hypothesis.matrix = c(&quot;flavanoids = 0&quot;))
lh.out

结果如下：

方法 2
以及基于命令的 Wilks&#39; 值
summary(wine.manova,&#39;Wilks&#39;)

输出如下：

尽管 p 值相同，但我试图理解为什么 Wilks&#39; Lambda 的 F 值在基于所有响应变量的黄酮类化合物预测因子的两次零系数检验中有所不同。结果表明，当有更多预测因子或因变量时，这两次 Wilks&#39; Lambda 计算之间的差异更大。
仅供参考 - 当将 R 与 STATA 进行基准测试时，几乎不可能在 STATA 中获得上述方法 2 下列出的表格结果，而方法 1 的结果很容易从 STATA 中获得。]]></description>
      <guid>https://stats.stackexchange.com/questions/653530/manova-univariate-wilks-lambda-test-r-interpretation</guid>
      <pubDate>Thu, 29 Aug 2024 02:58:38 GMT</pubDate>
    </item>
    <item>
      <title>率最差于 $\frac{1}{n}$ 的最小方差估计量示例</title>
      <link>https://stats.stackexchange.com/questions/653527/example-of-minimum-variance-estimator-with-rate-worst-than-frac1n</link>
      <description><![CDATA[考虑 $n$ 个 i.i.d. 观测值，该观测值来自分布 $p(X| \theta)$。假设我们有兴趣根据此数据估算 $\theta$。
我对一个示例感兴趣，该示例将表明：

存在一个 $\theta$ 的一致估计量。用 $\hat{\theta}$ 表示它。换句话说，我希望这个问题得到明确的定义。
“最佳”（最小方差）的方差不会以通常的$\frac{1}{n}$速度收敛，而是以较慢的速度收敛。

文献中有相当多的结果表明，至少 MLE（在适当的）规律性条件下以$\frac{1}{n}$速度收敛。在我看来，如果存在这样的例子，那么对于这种设置，Fisher 信息必须为零。]]></description>
      <guid>https://stats.stackexchange.com/questions/653527/example-of-minimum-variance-estimator-with-rate-worst-than-frac1n</guid>
      <pubDate>Thu, 29 Aug 2024 01:50:17 GMT</pubDate>
    </item>
    <item>
      <title>如何比较多组计数数据（数百万或零，差异很大）？</title>
      <link>https://stats.stackexchange.com/questions/653526/how-do-i-compare-multiple-groups-of-count-data-that-are-either-millions-or-zero</link>
      <description><![CDATA[我有三个独立的组：治疗组、药物 1 和药物 2。对于每个组，我都有 CFU 中的细菌计数。我不太擅长统计，所以请耐心听我说。我知道我不能使用方差分析，因为分布不正常，有些计数相距很远，而且有相当多的零（虽然不是太多）。组内的方差也不相等，样本量也不相等。
我看过一些论文，建议使用负二项分布、泊松分布或其他一些分布。我的问题是：有没有针对这种情况的推荐方法？我如何比较不同类别的模型以确定哪个更好？我主要使用 R。有没有办法在 R 中测试多种方法并让它建议最佳（或接近最佳）模型？这种方法是否适合我的情况？或者我应该不要太担心并使用非参数检验？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653526/how-do-i-compare-multiple-groups-of-count-data-that-are-either-millions-or-zero</guid>
      <pubDate>Thu, 29 Aug 2024 01:08:06 GMT</pubDate>
    </item>
    <item>
      <title>如何使用高相关模型选择 A/B 测试样本</title>
      <link>https://stats.stackexchange.com/questions/653520/how-to-select-sample-for-a-b-testin-with-high-correlated-models</link>
      <description><![CDATA[嗨，我正在对两个机器学习模型进行 A/B 测试，这两个模型会为每个客户提供一个分数。这两个模型具有很高的相关性。我担心，如果采用模型 A，选择样本，然后选择模型 B 的样本，例如，这可能会在我的测试中产生偏差（剩余的总体将拥有低“质量”的客户，因为这两个模型具有很高的相关性）。有什么关于如何克服这个问题的想法吗？我也会很感激任何参考资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/653520/how-to-select-sample-for-a-b-testin-with-high-correlated-models</guid>
      <pubDate>Thu, 29 Aug 2024 00:16:55 GMT</pubDate>
    </item>
    <item>
      <title>在 brms 中使用求和项拟合非线性贝叶斯回归</title>
      <link>https://stats.stackexchange.com/questions/653519/fitting-nonlinear-bayesian-regression-with-a-summation-term-in-brms</link>
      <description><![CDATA[我正在尝试为多个猎物拟合 Holling II 型曲线的参数。其形式如下：
$$
\frac{dP_i}{dt} = \frac{a_iP_i}{1 +\sum_j{a_jh_jP_j}}
$$
其中 $P_i$ 是猎物种类的密度 $i$，$a_i$ 是“攻击率”，$h_i$ 是“处理时间”。我有 $\frac{dP_i}{dt}$ 和 $P_i$ 的数据，因此想对每个 $a_i$ 和 $h_i$ 的参数值进行后验分布采样。
如果物种数量相对较少，那么为每个 $P$ 设置虚拟变量并以此方式进行拟合可能很简单，但如果存在许多不同的 $P_i$，这种方法就站不住脚了。假设我们有数百种猎物，我们希望 $a_i$ 和 $h_i$ 符合随机效应。有没有办法在 r 中使用 brms 来指定这一点？
描绘如下内容：
 bf(dP ~ (a * P)/(1 + T),
a ~ (1|species),
T ~ sum(a * h * P),
h ~ (1|species),
nl = TRUE)
]]></description>
      <guid>https://stats.stackexchange.com/questions/653519/fitting-nonlinear-bayesian-regression-with-a-summation-term-in-brms</guid>
      <pubDate>Wed, 28 Aug 2024 23:47:35 GMT</pubDate>
    </item>
    <item>
      <title>三角相关？</title>
      <link>https://stats.stackexchange.com/questions/653518/triangular-correlations</link>
      <description><![CDATA[正如我在 https://stats.stackexchange.com/a/652022/11887 上的回答中所使用的，三角相关似乎是一个有用的概念/术语，可以得到更多的使用。但搜索后我发现它没什么用，下面是一些例子。也许还有其他术语在使用？一些文献中的例子：


这是学生课程成绩与（y 轴）缺课率的关系，似乎缺课率给出了成绩的近似上限。来自 Othmar W Winkler 的论三角相关。他说

尽管缺课和学期成绩之间存在明显的关系，但使用线性回归计算的相关系数为 r = -.18024。对此进行解释$R^2 = .03249$似乎表明，了解缺课百分比几乎无法解释这些课程成绩分散的 3%。

如果没有图表，这似乎非常具有误导性。该论文中的另一个例子：

他将其包括进来是为了展示来自科学而非社会科学的例子。摘自
&quot;Shake hole, A morphometric Field Project for Sixth-Form Geographers&quot; Geography, Vol. 65 pt. 3, July 1980, No. 288&quot;（我无法通过互联网搜索找到它）。其他有趣的例子可以在 Richard R. Hake 的 互动参与与传统方法：对入门物理课程力学测试数据的六千名学生调查中找到。

应该如何分析和呈现这些数据？相关系数似乎没什么用...还有其他例子吗？是否使用了其他术语？]]></description>
      <guid>https://stats.stackexchange.com/questions/653518/triangular-correlations</guid>
      <pubDate>Wed, 28 Aug 2024 23:41:28 GMT</pubDate>
    </item>
    <item>
      <title>价值迭代 GridWorld 中的终端状态与奖励的价值</title>
      <link>https://stats.stackexchange.com/questions/653516/value-of-terminal-state-vs-reward-in-value-iteration-gridworld</link>
      <description><![CDATA[我看到很多帖子说终端状态的值始终为 0，但很多价值迭代的例子将奖励（在终端）指定为值。例如，在下面的网格世界中，我们将 +1 和 -1 作为终端状态的值。

这取决于我们如何定义奖励吗？上面的例子是否是奖励仅取决于离开的状态的情况？或者它也适用于奖励取决于进入状态的情况？
我倾向于认为，如果我们将奖励定义为取决于进入状态 s&#39;，则终止状态的值不应该是其相关奖励（如上例所示）。但如果是这种情况，算法如何知道为相邻状态分配导致终止状态的操作？]]></description>
      <guid>https://stats.stackexchange.com/questions/653516/value-of-terminal-state-vs-reward-in-value-iteration-gridworld</guid>
      <pubDate>Wed, 28 Aug 2024 23:12:19 GMT</pubDate>
    </item>
    <item>
      <title>我如何对系数进行随机效应建模</title>
      <link>https://stats.stackexchange.com/questions/653509/how-can-i-model-with-random-effect-on-the-coefficient</link>
      <description><![CDATA[简单线性回归模型为：$$y= a x + b$$
然而，在实际数据中：

存在随机效应（误差或变化）；
当 $x$ 增加时，随机效应的绝对值会成比例增加。
因此它看起来像 $$y = ax + b + ex$$ 或 $$y = (a + e) x + b$$ 但 $e$ 是随机效应。
对这种建模有什么建议吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653509/how-can-i-model-with-random-effect-on-the-coefficient</guid>
      <pubDate>Wed, 28 Aug 2024 20:29:44 GMT</pubDate>
    </item>
    <item>
      <title>根据汇总统计数据计算 Welch Anova 后的 Omega 平方</title>
      <link>https://stats.stackexchange.com/questions/653508/omega-squared-after-welch-anova-from-summary-statistics</link>
      <description><![CDATA[我根据汇总统计数据进行了 Welch 方差分析，结果如下：
# Welch 方差分析（均值的单因素分析）

数据：组和分数

F 值 df1 df2 p 值

5.35 2 16.83 0.015912 *

---
Signif. 代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

汇总统计数据

组大小均值 sd
&lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
A 10 77.3 11.324016 
B 10 89.3 4.808557 
C 10 84.7 5.292552 

基础数据

df &lt;- data.frame(group = rep(c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;), each = 10),
score = c(64, 66, 68, 75, 78, 94, 98, 79, 71, 80,
91, 92, 93, 85, 87, 84, 82, 88, 95, 96,
79, 78, 88, 94, 92, 85, 83, 85, 82, 81))
#summary
组大小平均值 sd
&lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
A 10 77.3 11.324016 
B 10 89.3 4.808557 
C 10 84.7 5.292552 

我找到了一些关于如何计算欧米茄平方的参考资料：
https://peterstatistics.com/Packages/python-docs/effect_sizes/eff_size_omega_sq.html
由于我没有计算任何平方和，哪个公式适合检索欧米茄平方？参考资料指出，所有公式都给出相同的结果。但不知何故，使用 Kirk 1996 和 Caroll 和 Nordholm 1975 的公式得出的结果与 Hays 1973（以及 Albers 和 Lakens 2018）提供的公式有所不同。有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653508/omega-squared-after-welch-anova-from-summary-statistics</guid>
      <pubDate>Wed, 28 Aug 2024 20:24:41 GMT</pubDate>
    </item>
    <item>
      <title>测量两组内部距离差异的重要性</title>
      <link>https://stats.stackexchange.com/questions/653500/measure-the-significance-of-differences-in-internal-distances-in-two-groups</link>
      <description><![CDATA[我是一名语言学家，正在研究 169 名挪威女性作家和 169 名挪威男性作家的语法变异（使用树库），该变异基于八个屈折和句法属性。这八个属性是两种表达类别的备选方式之间的八个二元选择，称为“保守”和“激进”。对于给定属性，记录的是作者保守选择的百分比。因此，它将是 0 到 100 之间的值。因此，这八个属性定义了作者分布的八维空间。然后可以像往常一样计算任何两个作者之间的（欧几里得）距离，取点坐标平方差之和的平方根。两组之间的一个显着差异（在各个属性之间都稳定）是，在八维可能性空间中，男性比女性分散得更多，女性聚集得更密集，选择组合的变化较少。我计算群体密度的方式是内部距离的平均值，即取每个群体成员与群体中其他作者的平均距离的平均值。该图显示了女性和男性与同性别其他成员的平均距离。男性的平均距离为 69（标准差为 16.6），女性的平均距离为 60（标准差为 15.3）。t 检验可以极高置信度地得出显著性，但作为统计学家，我对 t 检验的适用性表示怀疑。群体成员的数值是相互依赖的，因此我们测试的是性别群体的整体属性，而不是两个群体中每个成员的可比属性。因此，我的问题是：是否存在适合此类数据的适当显着性检验 - 或者我错误地认为 t 检验不合适（这很好）？]]></description>
      <guid>https://stats.stackexchange.com/questions/653500/measure-the-significance-of-differences-in-internal-distances-in-two-groups</guid>
      <pubDate>Wed, 28 Aug 2024 18:39:51 GMT</pubDate>
    </item>
    <item>
      <title>Metropolis Hastings 连锁店价值停滞不前</title>
      <link>https://stats.stackexchange.com/questions/653492/metropolis-hastings-chain-getting-stuck-at-high-values</link>
      <description><![CDATA[我是 Metropolis-Hastings 算法的新手。我正尝试将其实现为逆伽马分布 $p(x,\alpha,\beta)=\frac{\beta^\alpha}{\Gamma(\alpha)}(\frac{1}{x})^{\alpha+1} e^{\frac{-\beta}{x}}$。我面临的问题是，有时我的链会卡在高值。我使用对数正态步骤，因为点应该始终为正。由于分布仅在 $\alpha&gt;1$ 时才具有预期值，因此我将 $x_0$ 设置为 p.d.f 的最大值。我测试了一些 $\sigma$ 的值，20 左右似乎不错，但我只测试了 $\alpha=1,\beta=1$
我该怎么做才能避免这种情况？
我的代码：
def Metropolis(n,sigma,alpha,beta):
x_0=beta/(alpha+1)
target = lambda x: 1/(x**(alpha+1))*np.exp(-beta/x)
lognormal = lambda x,y:np.exp(-(np.log(x)-y)**2/(2*sigma**2))/(sigma*x*np.sqrt(2*np.pi))
x=[x_0]
for c in range(n):
x_now=x[c]
x_star=np.random.lognormal(x_now,sigma)
alpha=np.min([1,(target(x_star)*lognormal(x_now,x_star))/(target(x_now)*lognormal(x_star,x_now))])
u=np.random.uniform()
如果 u&lt;=alpha:
x.append(x_star)
否则:
x.append(x_now)
###绘图###
x_max=np.max(x)
fig, axs = plt.subplots(1,2)
fig.set_figheight(10)
fig.set_figwidth(10)
t=np.linspace(0.01,x_max)
axs[0].plot(x,range(n+1))
line = axs[1].hist(x,range=[0,x_max],bins=100,density=True)
max_hist=np.max(line[0])
max_target=np.max(target(t))
scale=max_hist/max_target
axs[1].plot(t,scale*target(t))
axs[0].grid()
axs[1].grid()
axs[0].set_xlim(0,x_max)
Metropolis(20000,20,1,1)

此图显示了我运行代码时通常会发生的情况。您可以看到它在一段时间内停留在高值，但又恢复了。

这显示了有时会发生的一些不良模拟

正如建议的那样，以下是建议值的图。由于 $\sigma$ 很大，建议值通常超出比例。但减少$\sigma$也无济于事。
]]></description>
      <guid>https://stats.stackexchange.com/questions/653492/metropolis-hastings-chain-getting-stuck-at-high-values</guid>
      <pubDate>Wed, 28 Aug 2024 15:46:44 GMT</pubDate>
    </item>
    <item>
      <title>如何进行数据驱动的样本量选择</title>
      <link>https://stats.stackexchange.com/questions/653472/how-to-perform-data-driven-choice-of-sample-size</link>
      <description><![CDATA[假设我想比较两个回归模型的结果。一个是参考模型，另一个是新模型，我想知道新模型是否表现更好。每个模型都用皮尔逊相关性进行评估，假设数据集是依赖的，并且测试数据相同，我想得到配对差异的置信区间，看看它是否包含零。
但我事先不知道差异的方差，也不知道正确的样本量是多少，所以我想到了以下方法：
min_diff_to_detect
all_pearsons_ref = []
all_pearsons_new = []
alpha = 0.05

循环直到循环中断 -&gt;对于当前循环 n：
train_ref、train_new、test_data = get_new_data_split()

ref_model = train_ref_model(train_ref)
pearson_ref = assess( ref_model(test_data) )
all_pearsons_ref.append(pearson_ref)

new_model = train_new_model(train_new)
pearson_new = assess( new_model(test_data) )
all_pearsons_new.append(pearson_new)

Differences = all_pearsons_new - all_pearsons_ref # 成对差异
confidence_interval = compute_CI(0, np.std(differences), n, alpha)

如果 min_diff_to_detect 不在 confidence_interval 中：
如果 np.mean(differences) 不在 confidence_interval 中：
返回 are_different
返回are_not_different

train_data 是依赖的，而 test_data 对于两个模型是相同的。这个想法是使用数据来寻找最佳循环数 N。否则 N 将被猜测，并且可能太小而没有足够的统计能力，或者太大而需要太长时间进行训练。
但是，方差在早期循环中也有可能波动很大，从而导致 min_diff_to_detect 可能被错误检测。后一点可以通过在评估 if 条件之前引入最小循环数来缓解，但这感觉很武断，最终，我不知道这种方法是否有效。
我也知道 bootstrapping，但它需要大量的训练才能有效。
那么，第一个 if 条件可以改进以避免错误吗？最终，这是一种有效的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653472/how-to-perform-data-driven-choice-of-sample-size</guid>
      <pubDate>Wed, 28 Aug 2024 07:32:11 GMT</pubDate>
    </item>
    <item>
      <title>两个 AR(1) 过程之和的持久性</title>
      <link>https://stats.stackexchange.com/questions/653465/persistence-of-the-sum-of-two-ar1-processes</link>
      <description><![CDATA[考虑一个时间序列 $y_t$，它可以分解为两个组成部分的总和：
$$y_t = x_{1,t} + x_{2,t} $$
假设每个组成部分都是独立的，并遵循平稳 AR(1) 过程：
$$\begin{align*} 
x_{1,t} &amp;= \phi_1 x_{1,t-1} + \varepsilon_{1,t} \\
x_{2,t} &amp;= \phi_2 x_{2,t-1} + \varepsilon_{2,t} \\
\end{align*}$$
其中：
$$\begin{align*} 
\varepsilon_{1,t} &amp;\sim N \left (0,\sigma_1^2 \right ) \\
\varepsilon_{2,t} &amp;\sim N \left (0,\sigma_2^2 \right ) \\
\end{align*}$$
我使用模拟来生成一系列长序列 $X_1$、$X_2$ 以及它们的和 $Y$。然后，我估计 $y_t$ 的 AR(1) 模型
$$y_t = \phi_y y_{t-1} + \varepsilon_{y,t}$$
在我的模拟/估计中，我发现 $\phi_y$ 的估计值是 $\phi_1$ 和 $\phi_2$ 的加权平均值，其中每个成分的 $\phi_i$ 的权重由其无条件方差的比例决定。也就是说，我发现：
$$
\hat{\phi}_y \approx \left ( \frac{\frac{\sigma_1^2}{1-\phi_1^2}}{\frac{\sigma_1^2}{1-\phi_1^2} +\frac{\sigma_2^2}{1-\phi_2^2}} \right ) \phi_1 + \left ( \frac{\frac{\sigma_2^2}{1-\phi_2^2}}{\frac{\sigma_1^2}{1-\phi_1^2} +\frac{\sigma_2^2}{1-\phi_2^2}} \right ) \phi_2
$$
我知道Lütkepohl (1984)（虽然我还没有获得副本），据称证明了$y_t$遵循平稳 ARMA 过程。
是否有人知道以下任一证明（或能够推导出证明）：

$y_t$遵循 AR(1) 过程。
$\phi_y \equiv \left ( \frac{\frac{\sigma_1^2}{1-\phi_1^2}}{\frac{\sigma_1^2}{1-\phi_1^2} +\frac{\sigma_2^2}{1-\phi_2^2}} \right ) \phi_1 + \left ( \frac{\frac{\sigma_2^2}{1-\phi_2^2}}{\frac{\sigma_1^2}{1-\phi_1^2} +\frac{\sigma_2^2}{1-\phi_2^2}} \right ) \phi_2$

最后，有谁知道任何相关的证明涉及更一般的情况，当$\varepsilon_{1,t}$和$\varepsilon_{2,t}$ 是相关的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653465/persistence-of-the-sum-of-two-ar1-processes</guid>
      <pubDate>Wed, 28 Aug 2024 02:09:13 GMT</pubDate>
    </item>
    <item>
      <title>在 Metropolis-Hastings 算法的这种特殊情况下应该使用哪个提议函数？</title>
      <link>https://stats.stackexchange.com/questions/653457/which-proposal-function-should-be-used-in-this-particular-case-of-the-metropolis</link>
      <description><![CDATA[作为我研究的一部分，我想应用 Metropolis-Hastings 来从某些后验分布中抽样。更准确地说，数据来自存在审查制度的多元正态分布，而先验具有正态-逆威沙特分布（协方差矩阵具有逆威沙特分布，而以协方差矩阵为条件的均值具有正态分布）。Metropolis-Hastings 算法的一个可能的提议分布是使用先验分布本身，因为从中抽样很容易。然而，接受率通常很低，算法发展得相当慢。话虽如此，我想知道是否有人可以就这个问题为我提供一些指导，也就是说，我有兴趣知道先验分布的选择是否可接受，以及是否存在另一种更有效的提议分布。
任何帮助都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/653457/which-proposal-function-should-be-used-in-this-particular-case-of-the-metropolis</guid>
      <pubDate>Tue, 27 Aug 2024 23:45:06 GMT</pubDate>
    </item>
    <item>
      <title>混合效应逻辑模型产生的预测值低于 R 中观察到的预测值[重复]</title>
      <link>https://stats.stackexchange.com/questions/653427/mixed-effects-logistic-model-generating-lower-predicted-values-than-observed-in</link>
      <description><![CDATA[我有一个患者数据框，其中标记了癌症结果，还有其他变量用作协变量（其中大约有 20 个）。数据框由多个队列组成，这些队列在单个列中用数字标记以指示队列成员身份。



患者 ID
癌症
年龄
性别
吸烟状况
体重指数猫
群组




00001
0
56
1
2
1
1


00002
0
54
1
1
2
1


00003
0
70
2
1
2



等
至允许与年龄进行不同的交互，我有一个热编码的队列变量，就像在单队列模型中一样，发现有些变量与年龄有交互作用。
我的模型形式如下：
glmer(cancer ~ ns(age_idate, df=3) + 
ns(age_idate, df=3):(cohort_6,cohort_4,cohort_9) + cohort_6 + 
cohort_4 + cohort_1 + cohort_2 + sex + bmi_cat + smoke_status + 
tired...etc. + (1|patid), family=binomial, data=model_data, 
nAGQ=0, control=glmerControl(calc.derivs=FALSE)

当我使用 predict() 获取原始 model_data 中的癌症预测风险时，我根据我的个人模型和临床知识的结果实现了合理的预测。
但是，我需要针对每个队列在每个年龄（30-100）和性别（男性、女性）组合下获得预测风险，而不是在单个患者级别。
我创建了一个包含所有年龄和性别组合的数据框，然后将所有其他变量附加到它们的基值（即 2 级因子中的 0），除了我感兴趣的队列，我将其设置为 1。



年龄
性别
吸烟状况
bmi_cat
群组 1
群组 2




30
1
0
0
1
0


31
1
0
0
1
0


32
1
0
0
1
0



等等
我用来预测的代码是：
model_pred_cohort_1 &lt;- marginaleffects::predictions(
model=mixed_effects_mod, newdata=grouped_data,
re.form=NA, type=&#39;response&#39;
)

当我对这个数据框进行预测时，每个年龄段的预测风险都比预期的要低得多。我也尝试过添加具有不同随机值的 patid 变量，因为我不确定这是否必要，但似乎没有什么区别。
我的问题是：这是这种模型类型的正确用法吗？我的模型输出的风险比观察到的风险低得多，这有什么原因吗？
如果我只是查看我的 model_data，按特定群组进行过滤，并查看患有癌症的患者与未患癌症的患者的比例，它会给出比相同预测值组合更高的值，但仅限于预测每个特定年龄和性别组合时，而不是仅获取人群中每个患者的预测风险时。
如果问题不清楚或需要更多信息，请见谅。]]></description>
      <guid>https://stats.stackexchange.com/questions/653427/mixed-effects-logistic-model-generating-lower-predicted-values-than-observed-in</guid>
      <pubDate>Tue, 27 Aug 2024 13:55:57 GMT</pubDate>
    </item>
    </channel>
</rss>