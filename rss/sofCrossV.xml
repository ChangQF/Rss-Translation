<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 19 Apr 2024 12:24:30 GMT</lastBuildDate>
    <item>
      <title>破解 R 包。是否可以估计过度训练的程度？</title>
      <link>https://stats.stackexchange.com/questions/645379/phacking-r-package-is-it-possible-to-estimate-the-degree-of-overtraining</link>
      <description><![CDATA[有一个名为 phacking 的软件包，它提供了演示 p-hacking 的工具，研究人员滥用数据分析来产生有意义的 p 值的做法。它包含执行 p-hacking 并演示其效果的功能，使其成为有用的学习工具。
这是一些初始使用示例
库（破解）
?money_priming_meta
？ phacking_meta
df &lt;- Money_priming_meta
ph &lt;- phacking_meta(yi = df$yi, vi = df$vi,parallelize = F)

我离这个话题很远，所以我的问题可能很愚蠢，我提前道歉。
我使用优化算法来运行许多模型并尝试选择最好的模型。也就是说，本质上，我面临着多重测试或 p-hacking 的问题。
我的问题是：我可以使用这个 phacking_meta 算法作为选择模型的标准来避免 p-hacking。如果可以的话，那么我应该向 phacking_meta 输入提交什么内容，以了解我的模型是经过重新训练的还是 p-hacking 的结果。
例如
X &lt;- iris[样本(150),-5]
时间 &lt;- 1:100
时间 &lt;- 101:150
mod &lt;- lm(Sepal.Length~., X[tr,])

ph &lt;- phacking_meta(yi = ???, vi = ???, 并行化 = F)
]]></description>
      <guid>https://stats.stackexchange.com/questions/645379/phacking-r-package-is-it-possible-to-estimate-the-degree-of-overtraining</guid>
      <pubDate>Fri, 19 Apr 2024 12:11:42 GMT</pubDate>
    </item>
    <item>
      <title>具有相同自由度比较的无参数中介路径SEM</title>
      <link>https://stats.stackexchange.com/questions/645375/unpaarametered-mediation-paths-sem-with-same-degree-of-freedom-comparison</link>
      <description><![CDATA[我正在为我的数据建模多级中介路径。这个想法是a1，a2，b1，b2，c1，c2，d1，d2都对结果变量y有贡献，并且b级，c级和d级变量也通过影响a级变量来影响y， c 级、d 级变量也通过受影响的 b 级影响 y 来影响 a 级变量，依此类推。我在 R 中使用 lavaan，以下是我当前的代码：
model1 &lt;- &quot;
y ~ a1 + a2 + b1 + b2 + c1 + c2 + d1 + d2
”

模型2&lt;-&gt;
y ~ a1 + a2 + b1 + b2 + c1 + c2 + d1 + d2
a1 ~ b1 + b2 + c1 + c2 + d1 + d2
a2～b1+b2+c1+c2+d1+d2”

模型3&lt;-&gt;
y ~ a1 + a2 + b1 + b2 + c1 + c2 + d1 + d2
a1 ~ b1 + b2 + c1 + c2 + d1 + d2
a2 ~ b1 + b2 + c1 + c2 + d1 + d2
b1 ~ c1 + c2 + d1 + d2
b2 ~ c1 + c2 + d1 + d2
”
...
...

我有两个问题。

我的语法是否有意义，或者它们是否按照我在文本中指定的方式执行？正如我在传统中介路径模型中所看到的，人们会指定如下参数
y ~ a*x1 + b*x2 等，但这会给我的模型增加很多复杂性，我不知道如何在我的多层模型中处理它。
模型摘要确实表明我在更多层上有更多参数，但除了 basline（多元线性回归）模型之外，自由度保持不变。这是因为我有嵌套模型吗？
如果我的语法正在执行“正确的工作”，我应该如何比较模型以查看其他中介路径是否有利于模型？我尝试在每个级别与基线级别之间执行 anova()，因为由于相同的 df，我无法在中介层之间使用 anova()。

我真的很感激任何建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/645375/unpaarametered-mediation-paths-sem-with-same-degree-of-freedom-comparison</guid>
      <pubDate>Fri, 19 Apr 2024 11:08:37 GMT</pubDate>
    </item>
    <item>
      <title>IV 估计器的一致性</title>
      <link>https://stats.stackexchange.com/questions/645374/consistency-of-iv-estimator</link>
      <description><![CDATA[我有一个关于 IV 估计器一致性证明的简单问题。我遵循戴维森和麦金农（第一版）的文本，其中作为他们的假设之一，他们陈述了以下等式：
$$
\text{plim}_{n \to \infty} (n^{-1} \mathbf{Z&#39;u})=\text{lim}_{n \to \infty} (n^{-1}E (\mathbf{Z&#39;u}))=0
$$
我的问题是，我们如何证明第二项蕴含第一项？通常，我们假设该工具与误差项不相关，因此第二项所说的对我来说是有意义的。但是我们如何用它来证明 $n^{-1} \mathbf{Z&#39;u}$ 收敛到零的概率呢？
我最初的想法是必须与均值收敛有关：
$$
\lim_{n \to \infty} (n^{-1}E(\mathbf{|Z&#39;u-0|}))
$$
由于均值或均方的收敛意味着概率的收敛，所以这个论点是成立的。但在上面的等式中，没有使用绝对值，当然，$\mathbf{Z&#39;u}$ 不必为正数。
通常情况下，一个并不暗示另一个。但那么如何才能从缺乏相关性到概率收敛呢？这里我的想法是简单地使用切比雪夫不等式，但是获得 $n^{-1} \mathbf{Z&#39;u}$ 的方差并不容易（并且要到达任何地方可能需要某种平均独立性假设）。书中没有这样做，这让我觉得我错过了一些东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/645374/consistency-of-iv-estimator</guid>
      <pubDate>Fri, 19 Apr 2024 11:06:31 GMT</pubDate>
    </item>
    <item>
      <title>边列表上的回归模型</title>
      <link>https://stats.stackexchange.com/questions/645373/regression-model-on-edge-list</link>
      <description><![CDATA[我想拟合一个回归，其中我的数据是来自网络的链接（边缘），输出是每个链接的权重。
收入水平是一个节点属性，每个链接都涉及两个节点，所以我有一个像这样的边列表：

&lt;标题&gt;

node_node
链接
怀特


&lt;正文&gt;

a_b
高-高
3


a_d
高低
4


a_f
高-中
1


c_f
高-中
5


d_f
低-中
1



我对链接值和权重之间的关系感兴趣，看看哪种收入水平组合会导致权重变化。
我应该如何将链接列合并到我的回归模型中？
我应该将链接列作为虚拟变量输入到我的回归模型中，还是有更好的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/645373/regression-model-on-edge-list</guid>
      <pubDate>Fri, 19 Apr 2024 10:48:39 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 模型低估</title>
      <link>https://stats.stackexchange.com/questions/645370/arima-model-underestimates</link>
      <description><![CDATA[如果我的 ARIMAX 模型持续低估，我们应该采取什么措施？
此外，这种低估是否应该成为我分析中的一个重大问题？
编辑：
我正在进行 ARIMAX 预测，其中使用报纸中的情绪作为外生变量来预测股票走势，并将误差指标 + Diebold-Mariano 与随机游走的误差指标进行比较。
这意味着我在周末和节假日缺少值。
我的 ARIMAX 预测值低估了实际运动的值。
ARIMAX 模型通过了偏度和序列相关性，并且没有此类问题。
代码：
库（预测）

set.seed(123) # 设置种子

# 分割、训练和测试。
split_index &lt;- round(0.8 * nrow(fin_zoo2))
train_data &lt;- fin_zoo2[1:split_index, ]
test_data &lt;- fin_zoo2[(split_index + 1):nrow(fin_zoo2), ]

# 列名称
colnames(train_data)[which(colnames(train_data) == “FINsentiment2”)] &lt;- “FINsentiment2”
colnames(test_data)[which(colnames(test_data) == “FINsentiment2”)] &lt;- “FINsentiment2”

train_data_core &lt;- coredata(train_data)
test_data_core &lt;- coredata(test_data)

# 标准差
error_sd &lt;- sd(diff(train_data_core[,“OMXdaily_return2”]))

# 指标累积向量
metrics_accumulator &lt;- 列表（
  RW_MAPE = 数字（50），ARIMAX_MAPE = 数字（50），
  RW_MedAE = 数字（50），ARIMAX_MedAE = 数字（50），
  RW_sMAPE = 数字（50），ARIMAX_sMAPE = 数字（50），
  RW_RMSE = 数字(50)，ARIMAX_RMSE = 数字(50)
）

for(1:50 后试听) {
    set.seed(123 + 试用版) # 种子
    
    random_walk_forecasts &lt;- numeric(nrow(test_data_core))
    arimax_forecasts &lt;- 数字(nrow(test_data_core))
    
    for(i in 1:nrow(test_data_core)) {
        current_train_data &lt;- fin_zoo2[1:(split_index + i - 1), ]
        current_train_data_core &lt;- coredata(current_train_data)
        
        # 根据迄今为止所有可用数据更新标准差
        Updated_error_sd &lt;- sd（diff（current_train_data_core [，“OMXdaily_return2”]））
        
        error_term &lt;- rnorm(1, 均值 = 0, sd = Updated_error_sd)
        last_observation &lt;- tail(current_train_data_core[, “OMXdaily_return2”], 1)
        random_walk_forecasts[i] &lt;-last_observation
        
        如果（我&gt; 1）{
            xreg_train &lt;- as.matrix(current_train_data_core[, &quot;FINsentiment2&quot;, drop = FALSE])
            xreg_forecast &lt;- test_data_core[i - 1,“FINsentiment2”, drop = FALSE]
            arima_model_with_exog &lt;- Arima(current_train_data_core[, “OMXdaily_return2”],
                                           xreg = xreg_train,
                                           顺序 = c(2, 0, 2),
                                           包括.平均值=假）
            arimax_forecasts[i] &lt;- 预测(arima_model_with_exog, xreg = xreg_forecast, h = 1)$mean
        }
    }
    

 
 #指标计算
    
    实际值 &lt;- test_data_core[, “OMXdaily_return2”]
    metrics_accumulator$RW_MAPE[试验] &lt;- 平均值（abs（（实际值 - random_walk_forecasts）/实际值）） * 100
metrics_accumulator$ARIMAX_MAPE[试验] &lt;- 平均值(abs((actual_values - arimax_forecasts) /actual_values)) * 100
    metrics_accumulator$RW_MedAE[试验] &lt;- 中位数(abs(actual_values - random_walk_forecasts))
metrics_accumulator$ARIMAX_MedAE[试验] &lt;- 中位数(abs(actual_values - arimax_forecasts))
    metrics_accumulator$RW_sMAPE[试验] &lt;- 平均值(2 * abs(actual_values - random_walk_forecasts) / (abs(actual_values) + abs(random_walk_forecasts))) * 100
metrics_accumulator$ARIMAX_sMAPE[试验] &lt;- 平均值(2 * abs(actual_values - arimax_forecasts) / (abs(actual_values) + abs(arimax_forecasts))) * 100
    # RMSE 计算
    metrics_accumulator$RW_RMSE[试验] &lt;- sqrt(mean((actual_values - random_walk_forecasts)^2))
metrics_accumulator$ARIMAX_RMSE[试用] &lt;- sqrt(mean((actual_values - arimax_forecasts)^2))
}



# 计算平均指标
Final_metrics &lt;- sapply(metrics_accumulator, 平均值)

# 结局表
Final_metrics_table &lt;- data.frame(
  度量=c(“MAPE”、“MedAE”、“sMAPE”、“RMSE”)，
  Random_Walk=final_metrics[c(“RW_MAPE”、“RW_MedAE”、“RW_sMAPE”、“RW_RMSE”)]，
  ARIMAX = Final_metrics[c(“ARIMAX_MAPE”、“ARIMAX_MedAE”、“ARIMAX_sMAPE”、“ARIMAX_RMSE”)]
）
打印（最终指标表）
]]></description>
      <guid>https://stats.stackexchange.com/questions/645370/arima-model-underestimates</guid>
      <pubDate>Fri, 19 Apr 2024 10:24:12 GMT</pubDate>
    </item>
    <item>
      <title>具有不同因变量的多个回归</title>
      <link>https://stats.stackexchange.com/questions/645369/several-regressions-with-different-dependent-variables</link>
      <description><![CDATA[我正在开发一个项目，我想根据几个不同的指标来比较两组参与者。现在，我正在估计具有不同因变量（即我考虑的指标）和类似解释变量的单独回归，以了解它们有何不同（例如，第 1 组的虚拟变量和一些控制变量）。这种方法可以吗，还是我应该考虑其他方法？在所有回归中，我都使用固定效应和聚类标准误差。所有回归的样本大小并不相同，因为对于特定事件需要实现的某些指标。
我正在寻求有关此方法是否合适或者是否有我应该考虑的更合适方法的指导。具体来说，我很好奇如何解决两组因变量之间的潜在相关性。任何有关处理此问题的见解或建议将不胜感激。此外，研究人员根据不同指标（因变量）对群体之间的差异进行建模的任何论文都将受到高度赞赏！]]></description>
      <guid>https://stats.stackexchange.com/questions/645369/several-regressions-with-different-dependent-variables</guid>
      <pubDate>Fri, 19 Apr 2024 09:51:55 GMT</pubDate>
    </item>
    <item>
      <title>需要 R studio 帮助：逐步 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/645368/r-studio-help-needed-stepwise</link>
      <description><![CDATA[我有一个包含 2000 列（SNP 二进制值）和 500 行的数据集。
我想使用 R 来执行，逐步向前减少变量数量。
任何人都可以建议一些示例脚本或函数。
我尝试使用 stepcalc.disc 但它不起作用。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/645368/r-studio-help-needed-stepwise</guid>
      <pubDate>Fri, 19 Apr 2024 09:31:59 GMT</pubDate>
    </item>
    <item>
      <title>计算共享方差</title>
      <link>https://stats.stackexchange.com/questions/645367/computing-shared-variances</link>
      <description><![CDATA[假设我估计一个具有 3 个相关解释变量的 OLS 回归模型。然后我可以分解解释的方差，如下图所示：

来源：https://www.researchgate.net/publication/49749932_CORINE_land_cover_and_floristic_variation_in_a_Mediterranean_wetland
如何计算共享方差？我知道如何计算 A、B 和 C 作为半偏相关²。但 D、E、F 和 G 又如何呢？欢迎任何建议，特别是 Stata，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/645367/computing-shared-variances</guid>
      <pubDate>Fri, 19 Apr 2024 09:26:29 GMT</pubDate>
    </item>
    <item>
      <title>连续混合物分布</title>
      <link>https://stats.stackexchange.com/questions/645366/continuous-mixture-distribution</link>
      <description><![CDATA[我目前正在研究负二项分布的推导，该分布是泊松分布和伽马分布连续混合的结果，用于回归目的。
为了获得整个条件分布，需要整合未观察到的异质性的影响：
$$f(y_i \mid x_i) = \int_{0}^{\infty} h(y_i \mid x_i, \nu_i) \omega(\nu_i \mid x_i) \, d\nu_i
$$
这可以例如如果选择 $\omega(\nu_i \mid x_i)$ 作为 Gamma 分布，则可以完成此操作，但也有其他可能性。
我的问题是，整合 $\nu_i$ 等干扰的影响意味着什么？是否可以通过一个简单的例子来直观地了解这里发生的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/645366/continuous-mixture-distribution</guid>
      <pubDate>Fri, 19 Apr 2024 08:58:10 GMT</pubDate>
    </item>
    <item>
      <title>测试参与者的两种条件之间随着时间的推移是否存在显着差异的正确统计数据是什么？</title>
      <link>https://stats.stackexchange.com/questions/645365/what-is-the-correct-statistic-to-test-whether-there-is-a-significant-difference</link>
      <description><![CDATA[我正在进行一项研究，使用受试者内重复测量设计来检查焦虑水平随时间的变化。参与者经历两种情况：显着的积极和显着的消极。在第一个图像中，他们观看 2 个中性图像，然后观看 3 个正显着图像，然后再次观看 2 个中性图像（2 nt、3 sp、2nt）。对于他们每个人，他们需要提供从 1 到 10 的焦虑等级。在第二种情况下，他们看到 2 个中性图像，然后是 3 个显着的负面图像，然后再次看到 2 个中性图像（2 nt、3 sn、2nt） 。这一系列试验重复了 180 次。
焦虑评级数据分为 7 个时间段（对应于序列中连续试验的数量）。我想统计分析每个条件下的焦虑水平是否随时间段发生显着变化，以及每个时间段内两种条件之间的焦虑水平是否存在显着差异。我怎样才能实现这一点，测试这一点的正确统计模型是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/645365/what-is-the-correct-statistic-to-test-whether-there-is-a-significant-difference</guid>
      <pubDate>Fri, 19 Apr 2024 08:40:47 GMT</pubDate>
    </item>
    <item>
      <title>完美校准输出的布赖尔技能得分悖论？</title>
      <link>https://stats.stackexchange.com/questions/645364/paradox-of-brier-skill-score-of-perfectly-calibrated-output</link>
      <description><![CDATA[给定结果，$y \in \{0,1\}$ 并输出 $o = f(x ) \in \mathbb R, o \in [0,1]$，我对模型 $f$ 完美建模的情况感兴趣变量$Y$。
由于 $Y$ 是伯努利，这意味着
$$
P(Y=1\中X=x)=f(x)\\
P(Y=0\中X=x)=1-f(x)
$$
因此
$$
E\左[Y\中X=x\右]=f(x)
$$
和
\begin{align}
\运算符名称{Var}(Y|X=x)
&amp;=E\left[Y^2\mid X=x\right]-(E\left[Y\mid X=x\right])^2\\
&amp;=E\left[Y\mid X=x\right]-(E\left[Y\mid X=x\right])^2\\
&amp;=f(x)-f(x)^2=f(x)(1-f(x))
\end{对齐}
如果我们模拟这种情况下的数据，并计算 Brier 技能得分 (BSS)，我们会看到：
将 numpy 导入为 np
将 pandas 导入为 pd
从plotnine导入*

def BSS_simulation(n):
    f = np.random.uniform(0, 1, n)
    y = np.random.binomial(1, f)
    yhat = y.mean()
    brier_f = ((y - f)**2).mean()
    brier_yhat = ((y - yhat)**2).mean()
    bss = 1 - brier_f / brier_yhat
    返回BSS

n = 1000
n_sim = 1000
bss = [BSS_simulation(n) for _ in range(n_sim)]

df_bss = pd.DataFrame({“BSS”: bss})
(
    ggplot(df_bss, aes(x=“BSS”))
    + geom_histogram(bins=30)
    + 主题_bw()
    + 主题(figure_size=(5, 3))
    + labs(title=“Brier技能评分模拟”, x=“BSS”, subtitle=f“平均 BSS: {np.mean(bss):.2f}”)
）


对于我来说，这个结果是出乎意料的。
事实上，完美校准的预测并不能实现 $BSS=1$。
然而，证明获得 $BSS=1$ 的唯一方法是 if $f(x )=y$ 对于每个预测，即模型 $f$ 的 Brier 分数为零。
我为下面仓促做出（且缺​​乏严谨性）的推导表示歉意，但我相信我们可以证明（假设 $f$ 是统一的并且普遍存在正类是 $\bar y = 0.5$，尽管我相信给定 $f$ 可以更严格地定义它)
$$E[(y-f)^2]=\int (y-f)^2 df = \int f(1-f) df = \left。 \frac{3f^2-2f^3}{6}\right|_{f=0}^{f=1}=\frac{3-2}{6}=1/6$$ 
还有
$$E[(y-\bar y)^2]=\bar y (1 - \bar y) = 1/2 \cdot 1/2 = 1/ 4$$
然后技能分数变为
$$\text{BSS} = 1 - \frac{1/6}{1/4} = 1 - \frac23=\frac13$$&lt; /p&gt;
这是否意味着当我们完全捕获数据生成过程时，Brier 技能还远未达到 1？]]></description>
      <guid>https://stats.stackexchange.com/questions/645364/paradox-of-brier-skill-score-of-perfectly-calibrated-output</guid>
      <pubDate>Fri, 19 Apr 2024 08:24:26 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 在 QI 宏中签署了等级测试</title>
      <link>https://stats.stackexchange.com/questions/645363/wilcoxon-signed-rank-test-in-qi-macros</link>
      <description><![CDATA[我需要一些帮助来理解 wilcoxon 签名等级测试。我正在使用此测试来比较两个分析仪。我们在两台分析仪上运行相同样本的 PT（凝血酶原时间），结果是非参数的。我对 QI 宏应用程序运行了 wilcoxon 符号秩检验，计算出数据集（每个点）之间差异的列显示所有数据点上的差异为 1 或小于 1。然而，该检验仍然拒绝了两个数据集之间的数据没有不同的原假设。
与其他测试进行比较时，差异小于0.1。
在另一个数据集中（同样是非参数），即使数据集之间的差异 &gt;1，检验也能够拒绝原假设。
有人能够解释为什么会这样吗？我是否使用了错误的测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/645363/wilcoxon-signed-rank-test-in-qi-macros</guid>
      <pubDate>Fri, 19 Apr 2024 08:22:28 GMT</pubDate>
    </item>
    <item>
      <title>系统 GMM 对于任何加权矩阵都会产生相同的结果</title>
      <link>https://stats.stackexchange.com/questions/645362/system-gmm-yields-identical-results-for-any-weighting-matrix</link>
      <description><![CDATA[我正在估计 R 中看似不相关的回归 (SUR) 系统。每个方程都有一个唯一的回归量和一个公共回归量。我正在使用 gmm::sysGmm 并尝试不同的权重矩阵。无论权重矩阵如何，我都会得到相同的结果（点估计、标准误差和我能看到的任何其他结果）。我认为这是不正确的。
无论我使用哪种类型的协方差矩阵估计器，这种现象都会持续存在：MDS、CondHom 或 HAC。无论我使用无限制估计还是限制其中一个系数在方程中相等，它都仍然存在。
问题：为什么系统 GMM 通过 gmm::sysGmm 对于任何加权矩阵都会产生相同的结果？
库(gmm)
库（系统适配）

# 生成并准备数据
n &lt;- 1000 # 样本量
m＜-100#“第二部分”的长度样本的
N &lt;- 3 # 方程数
设置.种子(321); x &lt;- 矩阵(rnorm(n*N),ncol=N); colnames(x) &lt;-paste0(“x”,1:N) # 生成回归量
dummy &lt;- c(rep(0,n-m),rep(1,m))#生成一个公共回归器
x &lt;- cbind(x,dummy) # 包含公共回归器和其余回归器
设置.种子(123); y &lt;- 矩阵(rnorm(n*N),ncol=N); colnames(y) &lt;- Paste0(“y”,1:N) # 因变量的占位符
for(i in 1:N){
 y[,i] &lt;- i + sqrt(i)*x[,i] - i*虚拟 + y[,i]*15*sqrt(i)
 # y[,i] 是 x[,i] 和虚拟变量的线性函数，
 # 加上一个带有方程特定方差的误差项
}
data1 &lt;- as.data.frame(cbind(y,x)) # 创建所有数据（y 和 x）的数据框

# 创建模型方程和力矩条件
eqSystem_g = eqSystem_h &lt;- list()
for(i in 1:N){
 eqSystem_g[[i]] &lt;- as.formula(assign(paste0(&quot;eq&quot;,i), value=paste0(&quot;y&quot;,i,&quot; ~ x&quot;,i,&quot; + dummy&quot;) )) # 定义 SUR 的线性方程
 eqSystem_h[[i]] &lt;- as.formula(assign(paste0(&quot;eq&quot;,i), value=paste0( &quot;~ x&quot;,i,&quot; + dummy&quot;))) # 定义矩条件对于高斯模型
}

# 估计 WLS 类型的权重矩阵，用作 GMM 中用户指定的权重矩阵
m0 &lt;- systemfit(公式=eqSystem_g，方法=“OLS”，数据=data1)
OLSmat &lt;- diag(diag(m0$residCov)); Wmat &lt;- 求解(OLSmat)

# 选择GMM中协方差矩阵的类型
vc1＜-“MDS”
vc1＜-“CondHom”
vc1＜-“HAC”
#vc1 &lt;-“TrueFixed”

# 在限制估计和非限制估计之间进行选择
cec1=NULL # 无限制
cec1=3 # 限制虚拟变量的系数在方程中相等

# 使用不同的权重矩阵“sysGmm”估计模型：identity、“optimal”并手动指定
m1a &lt;- sysGmm(g=eqSystem_g, h=eqSystem_h, wmatrix=“ident” ,weightsMatrix=NULL, vcov=vc1, crossEquConst=cec1, data=data1);摘要(m1a)
m1b &lt;- sysGmm(g=eqSystem_g, h=eqSystem_h, wmatrix=“最佳”,weightsMatrix=NULL, vcov=vc1, crossEquConst=cec1, data=data1);摘要(m1b)
m1c &lt;- sysGmm(g=eqSystem_g, h=eqSystem_h,weightsMatrix=Wmat, vcov=vc1, crossEquConst=cec1, data=data1);摘要(m1c)

相关：
* 通过 systemfit 与 sysGmm 估计的 SUR：不同的标准误差 
* 为什么 systemfit 对于 OLS 和 WLS 会产生相同的结果？  
* 为什么在交叉方程限制下，systemfit 会产生不同的 OLS 和 WLS 结果？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/645362/system-gmm-yields-identical-results-for-any-weighting-matrix</guid>
      <pubDate>Fri, 19 Apr 2024 07:51:09 GMT</pubDate>
    </item>
    <item>
      <title>我们如何应用敏感性分析来比较两个衡量干预效果的 ARIMA 模型？</title>
      <link>https://stats.stackexchange.com/questions/645360/how-can-we-apply-sensitivity-analysis-in-comparing-two-arima-models-both-measur</link>
      <description><![CDATA[我有一个从基线（4 个月）和干预期间（4 个月）收集的 8 个月期间报告率数据集。目标是确定干预措施是否具有显着效果。我使用 ARIMA 模型来比较观测值和预测值。所有差异均不显着。然而，干预期间第三个月的比率似乎是一个严重的异常值，因此需要使用 SPSS ARIMA 建模中的敏感性分析来比较包含该比率的模型和排除该比率的另一个模型。我以前从未经历过这种情况，需要您的帮助。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/645360/how-can-we-apply-sensitivity-analysis-in-comparing-two-arima-models-both-measur</guid>
      <pubDate>Fri, 19 Apr 2024 06:13:05 GMT</pubDate>
    </item>
    <item>
      <title>确定嘈杂的医疗保险索赔数据中的政策变化</title>
      <link>https://stats.stackexchange.com/questions/645345/determine-policy-changes-in-noisy-medicare-insurance-claim-data</link>
      <description><![CDATA[我希望这是问这个问题的正确地方，我不会因为一个糟糕的问题而受到批评，但这里是。
背景：
我有一个包含五年内提交的所有医疗保险索赔（非个性化）的数据库。
该数据库由 8.68B 条记录组成。每条记录都包括提交索赔的日期、寻求的金额、索赔是否获得批准、金额以及时间。每条记录还通过适用于程序/设备的约 22,000 个代码（CPT 代码）之一对索赔进行分类。数据按这些 CPT 代码排序，并在 CPT 代码内按日期排序。
是否涵盖索赔取决于影响我无权访问的相关 CPT 代码的各种政策。此外，对于我的问题来说，重要的是，适用于 CPT 代码的政策可能会随着时间的推移而发生变化。一些没有被覆盖的东西可能会变得如此。曾经被覆盖的东西可能不再被覆盖。甚至可能会来来回回，例如，覆盖-不覆盖-覆盖。或者，该策略在数据库期间可能永远不会改变。
最后，数据是有噪音的。虽然某些内容通常会被承保，但索赔仍可能因各种原因被拒绝，例如，提交晚、未提供所需文件等。同样，某些内容通常会被拒绝，但它仍然可能被承保，例如，同情心护理。&lt; /p&gt;
问题：
有没有一种方法可以从数据本身检测这些保单变化，这样我就可以说，对于给定的 CPT 代码，一个时期内批准的索赔百分比是 X，而在不同时期是 Y等等？
另一种说法可能是：面对这些嘈杂的数据，我如何找出适当的窗口和截止百分比来计算平均批准率，以便我可以比较两个时间序列？ 
需要明确的是，我有软件背景，并准备好进行暴力破解，即，如有必要，尝试所有可能的窗口。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/645345/determine-policy-changes-in-noisy-medicare-insurance-claim-data</guid>
      <pubDate>Thu, 18 Apr 2024 22:19:23 GMT</pubDate>
    </item>
    </channel>
</rss>