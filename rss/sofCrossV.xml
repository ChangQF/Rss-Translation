<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 10 Jul 2024 03:18:20 GMT</lastBuildDate>
    <item>
      <title>在哪里可以找到 f 分布的 K-S 临界值表？</title>
      <link>https://stats.stackexchange.com/questions/650774/where-can-i-find-a-k-s-critical-value-table-for-an-f-distribution</link>
      <description><![CDATA[我开发了一个 Excel 模型，用于 f 分布的单样本 Kolmogorov-Smirnov 检验。我有 K-S 检验统计量，但没有 CV 可以与之比较。如果有人知道 K-S F 检验的临界值在线表格，我将不胜感激。我假设输入要求将是参考 f 分布的 df1 和 df2，以及检验的显著性水平。]]></description>
      <guid>https://stats.stackexchange.com/questions/650774/where-can-i-find-a-k-s-critical-value-table-for-an-f-distribution</guid>
      <pubDate>Wed, 10 Jul 2024 02:20:12 GMT</pubDate>
    </item>
    <item>
      <title>在 Cox 回归中降低受试者数量较少的分类变量的级别</title>
      <link>https://stats.stackexchange.com/questions/650769/dropping-a-level-of-a-categorical-variable-with-small-number-of-subjects-on-cox</link>
      <description><![CDATA[我试图将 Cox 回归模型拟合到我的事件发生时间数据，并有一个具有 5 个不同级别的分类变量。我将一个级别留作“参考”。我还有 2 个级别，每个级别包含少量受试者，并且我收到有关这些变量（级别）方差较低的警告，如下所示：
ConvergenceWarning：列 [&#39;xxx&#39;] 的方差非常低。这可能会损害收敛。1) 您使用的是公式吗？您是不是想在末尾添加“-1”。2) 如果收敛失败，请尝试在拟合之前删除这个冗余列。
我的模型没有收敛。我应该如何处理这种情况？
我正在使用 Python 中生命线库中的 CoxTimeVaryingFitter。]]></description>
      <guid>https://stats.stackexchange.com/questions/650769/dropping-a-level-of-a-categorical-variable-with-small-number-of-subjects-on-cox</guid>
      <pubDate>Tue, 09 Jul 2024 21:36:00 GMT</pubDate>
    </item>
    <item>
      <title>状态空间模型和卡尔曼滤波器</title>
      <link>https://stats.stackexchange.com/questions/650761/state-space-models-and-kalman-filter</link>
      <description><![CDATA[我有以下模型规范：
$y_t = \mu_t + v_t,$
$\mu_{t+1|t} = \phi \, \mu_{t|t-1} + k\, v_t $
其中 v_t= y_t - mu_{t|t-1}, v_t|F_{t-1} ~ tv(0, sigma^2)。
我被要求提供 mu_t 或 mu_{t|t-1} 的滤波估计值，并估计静态参数：phi、v、sigma^2。
我使用卡尔曼滤波器。一般状态空间表示为：y_t = Z_t* alpha_t + G_t* epsilon_t。 alpha_{t+1} = T_t* alpha_t + H_t* eta_t
在这种情况下：Z_t=1，T_t = phi，G_t= sigma_v，H_t= k*sigma_v，alpha_t= mu_t。
对于卡尔曼滤波器：v_t = y_t - Z_t* alpha_{t|t-1} # 预测误差
F_t = Z_t * P_{t|t-1} Z_t&#39; + G_t G_t&#39; # 预测误差的方差
alpha_{t|t} = alpha_{t|t-1} + P_t* Z_t&#39;* F_t^-1 *vt # E[alpha_t| F_t]
P_{t|t} = P_{t|t-1} - P{t|t-1}*Z_T&#39; * F_t^-1 Z_tP_t # V[alpha_t|F_t]
alpha_{t+1|t} = T_t* alpha_{t|t-1} + k_t *vt# 更新状态估计
P_{t+1|t} = T_t* P_{t|t-1}* T_t&#39;+ H_tQ_tH_t&#39; - K_t * F_t *K_t&#39;# 更新状态方差
卡尔曼增益 K_t= T_t* P_{t|t-1Z_t&#39; F_t^-1
为了计算估计值mu_{t|t}，我是否只需替换 alpha_{t|t} = alpha_{t|t-1} + P_t* Z_t&#39;* F_t^-1 *vt？
mu_{t|t} = mu_{t|t-1} + P_t* Z_t&#39;* F_t^-1 *vt？]]></description>
      <guid>https://stats.stackexchange.com/questions/650761/state-space-models-and-kalman-filter</guid>
      <pubDate>Tue, 09 Jul 2024 19:02:36 GMT</pubDate>
    </item>
    <item>
      <title>纵向或时间序列的 GLM - 如何使用 R 建模和解释随时间控制协变量的二元逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/650762/glm-for-longitudinal-or-time-series-how-to-model-and-interpret-a-binary-logis</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650762/glm-for-longitudinal-or-time-series-how-to-model-and-interpret-a-binary-logis</guid>
      <pubDate>Tue, 09 Jul 2024 18:26:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在 sommer R 包中正确指定嵌套？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650758/how-do-i-correctly-specify-nesting-in-the-sommer-r-package</link>
      <description><![CDATA[我习惯于 lme4，它很简单：(1|genotype/root_ID)，但我通过查看文档不清楚在 sommer 中执行此操作的适当方法。
mod1 &lt;- mmer(Y ~ 1,
random= ~vsr(genotype,Gu=a) + genotype + genotype:root_ID,
rcov= ~units, nIters=10,
data=fold, verbose = FALSE, dateWarning=FALSE)
结果看起来很逼真，但我不完全确定这是否正确，并担心我会得到虚高的 CV 准确度...]]></description>
      <guid>https://stats.stackexchange.com/questions/650758/how-do-i-correctly-specify-nesting-in-the-sommer-r-package</guid>
      <pubDate>Tue, 09 Jul 2024 18:10:33 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中进行网络元分析 - 输入二分数据</title>
      <link>https://stats.stackexchange.com/questions/650768/conducting-a-network-meta-analysis-in-r-inputting-dichotomous-data</link>
      <description><![CDATA[我希望使用 {netmeta} 在 R 中进行荟萃分析。但是，我感兴趣的结果有点复杂，希望得到有关如何最好地将其输入数据集的建议。
我正在研究牛营养补充后体外受精的卵母细胞卵裂率。大多数研究都没有在结果中说明平均值 +/- s.e.m. 或 s.d. - 它们主要将其报告为比例。
由于卵裂在技术上是一个二元结果（它已经卵裂了吗？是或否？），我打算将比例转换为风险比（这相当简单）。但是，问题之一是大多数研究不止一次从实验中的动物身上收集卵母细胞。例如，他们可能有五只动物在对照组，五只动物在实验组，它们经历三个卵母细胞收集周期。但是，大多数研究只是三次收集的结果的平均值，例如对照组三次采集五只动物，平均有 6/11 个卵母细胞分裂（54.5%），实验组有 9/15 个卵母细胞分裂（60%）。我觉得我需要考虑每项研究的样本量，但只需在下面的列中输入 6 和 11，以及 9 和 15：
没有考虑到这一点。
仅将动物数量乘以采集数量来估计总事件数和总数是否合适，或者这是否严重简化并可能引入抽样误差？]]></description>
      <guid>https://stats.stackexchange.com/questions/650768/conducting-a-network-meta-analysis-in-r-inputting-dichotomous-data</guid>
      <pubDate>Tue, 09 Jul 2024 17:57:44 GMT</pubDate>
    </item>
    <item>
      <title>在 MVGAM 中，如何模拟 1 个连续变量（丰度）、1 个离散变量（天数）和 1 个因素（真核生物属）之间的相互作用</title>
      <link>https://stats.stackexchange.com/questions/650741/in-mvgam-how-can-i-model-an-interaction-between-1-continuous-variable-abundanc</link>
      <description><![CDATA[我正在从事微生物生态学研究，并试图在微生物初级演替的情况下模拟几个属的丰富程度对单个感兴趣的属随时间的影响。我已经创建了这个模型，但我真的不确定我是否理解得正确，尤其是关于相互作用。
我发现有几个主题讨论 1 个变量和因素，但没有 1 个连续变量（丰度）、一个离散变量（时间）和因素（属）

Alkanindiges 是包含我感兴趣的属的相对丰度的列
丰度是每天所有属的相对丰度
时间是天数（1-24）
生物反应器是我的实验三重奏（其中有 3 个）

我使用 CAR(1)，因为我预计前一天我感兴趣的属的丰度会对当天的丰度产生影响，但我缺少一些数据点。
这是完整的模型，我包含了数据的摘要我正在处理。如果您想要整个文件，我很乐意通过电子邮件发送给您！
非常感谢您抽出时间。

mod_alk &lt;- mvgam( Alkanindiges ~ te(Abundance, time, by = Genus) + s(bioreactor, bs = &#39;re&#39;),

trend_model = CAR(1),

noncentred = TRUE,

data = AHAPCN_train, 

chains = 4,

adapt_delta = 0.97,

max_treedepth = 14,

parallel = TRUE,

backend = &#39;cmdstanr&#39;,

family = Gamma(link = &#39;inverse&#39;)) 

这是我的 df 的摘要。 NA 是因为我将丰度列分成了每个属的丰度的多个列。
]]></description>
      <guid>https://stats.stackexchange.com/questions/650741/in-mvgam-how-can-i-model-an-interaction-between-1-continuous-variable-abundanc</guid>
      <pubDate>Tue, 09 Jul 2024 14:16:22 GMT</pubDate>
    </item>
    <item>
      <title>如何测量二进制数据列表中分布的规律性？</title>
      <link>https://stats.stackexchange.com/questions/650739/how-do-i-measure-the-regularity-of-the-distribution-in-a-list-of-binary-data</link>
      <description><![CDATA[假设我有一个列表 list = [0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1]，它给出了某人在某一天是生病 (1) 还是没生病 (0) 的信息，由于该列表有 15 个元素，我考虑 1-15 天。现在我想确定如何“很好地”或者这些病假有规律地分布在这段时间内。
例如，规则的分布是
[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1]

不美观的分布是例如：
[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]

我考虑的是基尼系数或距离的标准差。但是我不知道如何处理第二个列表。
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]

这里，距离的标准差值为 0，但 1 的分布不太好。
还有什么其他可能性？]]></description>
      <guid>https://stats.stackexchange.com/questions/650739/how-do-i-measure-the-regularity-of-the-distribution-in-a-list-of-binary-data</guid>
      <pubDate>Tue, 09 Jul 2024 13:46:10 GMT</pubDate>
    </item>
    <item>
      <title>通过 TP、TN、FP 和 FN 值判断模型</title>
      <link>https://stats.stackexchange.com/questions/650709/judging-a-model-through-the-tp-tn-fp-and-fn-values</link>
      <description><![CDATA[我正在使用多个数据集评估一个模型，该模型可以预测某个“特征”是否存在（例如，“这幅图像中有一只狗”）。系统会针对每个数据集输出 TP、TN、FP 和 FN。
我想要一个指标来判断模型的工作效果如何，但我意识到我无法仅绘制 TP，因为例如第一个数据集有 20 个具有特征（有一只狗）的实例，而第二个数据集只有 10 个。即使模型是完美的，第二个数据集也只有 10 个 TP。
我正在考虑计算每个数据集和所有数据集的准确率、精确率和召回率。
我也对每个数据集运行了三次模型，变化很小
我也在研究精确率-召回率曲线，但似乎这些是针对不同的阈值的，显然每个数据集只有一组精确率、召回率
有什么好方法可以判断模型是否“好”？由于我的经验不足，我无法提出一个好的判断标准
起初我想绘制所有数据集的每个（TP 等）的分布
然后我想绘制一个结合所有数据集的混淆矩阵
任何建议都将不胜感激

作为一个简单的虚构示例，我想到
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confused_matrix, precision_score, recall_score, f1_score, accuracy_score

# 示例虚构数据
datasets = {
&#39;datasetA&#39;: {&#39;TP&#39;: 150, &#39;TN&#39;: 200, &#39;FP&#39;: 50, &#39;FN&#39;: 100, &#39;no_GT&#39;: 34},
&#39;数据集B&#39;：{&#39;TP&#39;：180，&#39;TN&#39;：220，&#39;FP&#39;：40，&#39;FN&#39;：81，&#39;no_GT&#39;：20}，
&#39;数据集C&#39;：{&#39;TP&#39;：160，&#39;TN&#39;：240，&#39;FP&#39;：70，&#39;FN&#39;：110，&#39;no_GT&#39;：30}，
&#39;数据集D&#39;：{&#39;TP&#39;：190，&#39;TN&#39;：250，&#39;FP&#39;：60，&#39;FN&#39;：90，&#39;no_GT&#39;：42}，
}

def calculate_metrics（TP，TN，FP，FN）：
准确度 = (TP + TN) / (TP + TN + FP + FN)
精度 = TP / (TP + FP) if (TP + FP) &gt; 0 else 0
召回率 = TP / (TP + FN) if (TP + FN) &gt; 0 else 0
f1 = 2 * (准确率 * 召回率) / (准确率 + 召回率) if (准确率 + 召回率) &gt; 0 else 0

return {
&#39;Accuracy&#39;: 准确度,
&#39;Precision&#39;: 精度,
&#39;Recall&#39;: 召回率,
&#39;F1 分数&#39;: f1
}

# 聚合计数
total_TP = sum(data[&#39;TP&#39;] for data in datasets.values())
total_TN = sum(data[&#39;TN&#39;] for data in datasets.values())
total_FP = sum(data[&#39;FP&#39;] for data in datasets.values())
total_FN = sum(data[&#39;FN&#39;] for data in datasets.values())

# 计算总体指标
overall_metrics = calculate_metrics(total_TP, total_TN, total_FP, total_FN)

# 计算每个数据集的指标
metrics_df = pd.DataFrame({dataset: calculate_metrics(data[&#39;TP&#39;], data[&#39;TN&#39;], data[&#39;FP&#39;], data[&#39;FN&#39;]) for dataset, data in datasets.items()})

# 添加总体指标
metrics_df[&#39;Overall&#39;] = Overall_metrics

print(metrics_df)

# 可视化
fig, axis = plt.subplots(2, 2, figsize=(14, 10))
axes = axis.flatten()

for i, (dataset, data) in enumerate(datasets.items()):
cm = confused_matrix([1] * data[&#39;TP&#39;] + [0] * data[&#39;TN&#39;] + [1] * data[&#39;FN&#39;] + [0] * data[&#39;FP&#39;],
[1] * (data[&#39;TP&#39;] + data[&#39;FP&#39;]) + [0] * (data[&#39;TN&#39;] + data[&#39;FN&#39;]))
sns.heatmap(cm, annot=True, fmt=&#39;d&#39;, cmap=&#39;Blues&#39;, ax=axes[i])
axes[i].set_title(f&#39;混淆矩阵 - {dataset}&#39;)
axes[i].set_xlabel(&#39;预测&#39;)
axes[i].set_ylabel(&#39;True&#39;)

plt.tight_layout()
plt.show()

我得到了
 数据集A 数据集B 数据集C 数据集D 总体
准确率 0.700000 0.767754 0.689655 0.745763 0.725696
精确率 0.750000 0.818182 0.695652 0.760000 0.755556
召回率 0.600000 0.689655 0.592593 0.678571 0.640905
F1 分数 0.666667 0.748441 0.640000 0.716981 0.693524

和
]]></description>
      <guid>https://stats.stackexchange.com/questions/650709/judging-a-model-through-the-tp-tn-fp-and-fn-values</guid>
      <pubDate>Tue, 09 Jul 2024 05:43:39 GMT</pubDate>
    </item>
    <item>
      <title>无法从 shapley 值的全局热图中识别出重要特征</title>
      <link>https://stats.stackexchange.com/questions/650699/cannot-identify-important-feature-from-global-heatmap-of-shapley-value</link>
      <description><![CDATA[在我的例子中，每个实例有 166 个特征。我以 80:20 的比例分割训练和测试数据集，并训练了一个用于二元分类的 DNN 模型。模型架构如下：

现在对于测试数据，我使用 shap 库 来识别重要特征。我计算 shap 值的代码如下：
dnn_explainer = shap.DeepExplainer(model, X_train_shap.float().to(device)) 
shap_values_test = dnn_explainer.shap_values(X_test_shap.float().to(device))

现在我试图从局部和全局热图中可视化真正样本的重要特征。对于单个真阳性实例，我得到了这个热图：

从这个热图中，我看到大多数特征都很重要，因为它们是红色的，这些特征对模型的预测没有任何影响，因为它们的 shapley 值为零。
我还使用以下代码绘制了全局热图：
import matplotlib.pyplot as plt
import seaborn as sns 

plt.figure(figsize=(10, 2)) 

sns.heatmap(shap_values_test_tp, cmap=&#39;coolwarm&#39;, cbar_kws={&#39;label&#39;: &#39;特征重要性值&#39;}) 
plt.title(&#39;TP 样本的全局分析&#39;, fontsize=10)
plt.show()

使用 SHAP 值的全局热图：
我获得了测试数据集所有真正实例的全局热图，如下所示：

从这个热图中，我也无法在全球范围内识别任何重要特征。我正在尝试找出整个模型解释过程中的错误，但我无法找到。
使用分层相关性传播值的局部和全局热图：
我已经从测试数据中为所有真正的阳性实例计算了分层相关性传播值。

对于单个实例，我有这个热图：

对于所有真正的测试数据阳性实例，我有此热图：

从这些局部和全局热图中，我无法识别重要特征。
我已阅读题为使用逐层相关性传播解释表格数据的深度学习模型的论文，并查看了其局部和全局热图如下：

从这些热图中，我们可以轻松识别局部和全局重要特征。我想在我的模型解释中实现这一点。我在解释我的模型时是否遗漏了任何步骤？任何澄清或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650699/cannot-identify-important-feature-from-global-heatmap-of-shapley-value</guid>
      <pubDate>Mon, 08 Jul 2024 23:22:18 GMT</pubDate>
    </item>
    <item>
      <title>使用皂膜平滑器进行问题拟合和绘制 GAM</title>
      <link>https://stats.stackexchange.com/questions/650673/issue-fitting-and-plotting-gam-with-soap-film-smoother</link>
      <description><![CDATA[我在使用 R 中的 mgcv 拟合游戏时遇到问题，正在寻求帮助。简而言之，我有一个数据集，其中包含在大型湖泊系统中的接收器处检测到的两组（孵化场或野生）之一的鱼的数量。这些接收器放置在特定位置，具有唯一的经度和纬度。该数据集是在 4 年内收集的。我希望对研究期间每组接收器处检测到的鱼的数量进行建模。我在 R 中使用 mgcv 完成了此操作，代码如下：
mod1 &lt;- gam(number_of_fish ~ s(x, y, by = origin, k = 40) + s(study_year, k = 3) + origin, offset = log(max_fish),
data = n_fish_spring_utm, 
family=nb(link = &#39;log&#39;),
method = &quot;REML&quot;)

这里，我使用偏移量来表示每组中可以检测到的最大鱼数的对数，因为两组的鱼数不同。我还使用了负二项分布。
这个模型似乎运行良好。
参数系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -2.83417 0.02592 -109.327 &lt; 2e-16 ***
originWild 0.31964 0.04188 7.632 2.3e-14 ***
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df Chi.sq p 值 
s(x,y):originHatchery 16.393 21.146 252.9 &lt;2e-16 ***
s(x,y):originWild 12.041 16.024 144.5 &lt;2e-16 ***
s(study_year) 1.871 1.983 274.2 &lt;2e-16 ***
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) = 0.306 偏差解释 = 50.2%
-REML = 2258.5 尺度估计 = 1 n = 1347


但是，我的湖泊系统有很多轮廓和一些大岛屿，我想使用肥皂膜平滑器来解释它们。
我使用湖泊系统的 shapefile 生成了肥皂膜表面，并使用 soapcheckr() 包检查一切是否正常（即没有结落在边界之外）。

然后我运行了以下模型，包括肥皂膜平滑器：
mod2 &lt;- gam(number_of_fish ~ s(x, y, by = origin, k = 40, bs = &quot;so&quot;, xt = list(bnd = border.aut, nmax=1500)) + s(study_year, k = 3) + origin, offset=log(max_fish),
data = n_fish_spring_utm, 
family=nb(link = &#39;log&#39;),
method = &quot;REML&quot;, 
knots = lake_knots)

模型运行良好。
参数系数：
估计标准差。误差 z 值 Pr(&gt;|z|)
(截距) -2.8287 4.4271 -0.639 0.523
originWild 0.2641 13.2274 0.020 0.984

平滑项的近似显著性：
edf Ref.df Chi.sq p 值 
s(x,y):originHatchery 42.000 42.00 216.9 &lt;2e-16 ***
s(x,y):originWild 42.000 42.00 173.2 &lt;2e-16 ***
s(study_year) 1.827 1.97 230.4 &lt;2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

排名：308/866
R-sq.(adj) = 0.307 偏差解释 = 52.7%
-REML = 1640 尺度估计 = 1 n = 1347

但是，这些图似乎不合理，表明没有检测到任何鱼。


我也无法像以前一样使用 gratia() 包从我的模型生成图表。我收到以下错误消息：
`mutate()` 中的错误：ℹ在参数中：`.loop = rep(seq_along(pts), each = pts)`。由错误引起：！`.loop` 的大小必须是 536 或 1，而不是 1446。

我已经摆弄了大约一个星期，但似乎无法解决这个问题。任何帮助，甚至是正确方向的推动都将不胜感激！
代码、数据和 shapefile 可以在这里找到。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650673/issue-fitting-and-plotting-gam-with-soap-film-smoother</guid>
      <pubDate>Mon, 08 Jul 2024 13:39:39 GMT</pubDate>
    </item>
    <item>
      <title>贝塔随机变量的乘积与和的分布</title>
      <link>https://stats.stackexchange.com/questions/650663/distribution-of-product-and-sum-of-beta-random-variables</link>
      <description><![CDATA[我有一组概率，我将其建模为（独立的）$p_{A,i} \sim Beta(\alpha_{A,i},\beta_{A,i})$ 和 $p_{B,i} \sim Beta(\alpha_{B,i},\beta_{B,i})$。我正在计算以下乘积：
$$Y = \sum_{i=1}^N p_{A,i}^{n_{A}}(1-p_{B,i})^{n_{B}} + p_{B,i}^{n_{B}}(1-p_{A,i})^{n_{A}},$$
其中 $n_{A}$ 和 $n_{B}$ 为整数。我想推断（近似）$Y$ 的累积分布。由于 $Y$ 因支持值 $\gt 1$ 而出现偏差，我考虑将 Beta-Prime（或对数正态）密度分布拟合到 $Y$。这样对吗？您能否就 $Y$ 的真实分布或更好的近似值提供一些见解？
PD。如果之前有人问过类似的问题，请见谅。]]></description>
      <guid>https://stats.stackexchange.com/questions/650663/distribution-of-product-and-sum-of-beta-random-variables</guid>
      <pubDate>Mon, 08 Jul 2024 08:59:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 R STM 包分析评论评级-样本平衡问题</title>
      <link>https://stats.stackexchange.com/questions/650661/analyzing-review-rating-using-r-stm-package-sample-balance-issue</link>
      <description><![CDATA[对于在线评论数据集，其中一项任务是研究主题比例的差异（例如，主题为正面评论与负面评论）。由于在线评论评分呈正偏的J形分布/评分分布不平衡，学者倾向于平衡样本量，即随机选择正面评分评论（即4分和5分评分），使其数量等于或接近负面评分评论（即1分和2分评分）。类似于以下论文的做法：
论文1：酒店顾客抱怨什么？使用结构化主题模型进行文本分析
论文 2：药物消费者的声音：使用结构化主题模型进行在线文本评论分析
删除一些评级评论以实现平​​衡样本的原因是（摘自论文 2）：

...当在 STM 模型中使用评论极端值作为协变量时，首先过滤正面和负面评论以平衡正面和负面评论的样本量是必不可少的，这可以帮助我们更可靠地识别负面评论中出现次数明显多于正面评论的主题。

由于从数据集中删除样本始终是一种不好的做法，我的问题是：在以下情况下，删除一些评级评论以实现平​​衡样本是否合理考察 STM 模型中主题比例的差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/650661/analyzing-review-rating-using-r-stm-package-sample-balance-issue</guid>
      <pubDate>Mon, 08 Jul 2024 08:17:13 GMT</pubDate>
    </item>
    <item>
      <title>第一/第二选择与简单概率的等价性——我不这么认为</title>
      <link>https://stats.stackexchange.com/questions/650647/equivalence-of-first-second-choice-with-naive-probability-i-dont-buy-it</link>
      <description><![CDATA[我希望更好地理解Blitzstein and Huang (2015)（第 1 章，练习 31，第 35 页）中的以下问题：

一个罐子里有 $r$ 个红球和 $g$ 个绿球，其中 $r$ 和 $g$ 是固定的正整数。从罐子中随机抽取一个球（所有可能性都相同），然后随机抽取第二个球。
(a) 直观地解释为什么第二个球是绿色的概率与第一个球是绿色的概率相同。

现在，我明白了，在进行实验之前，理论上没有证据可以作为条件，并且这两个概率是等价的。没有哪个球比其他球更容易被选中。但在实践中，我并不这么认为。
第一个球是绿色的几率是 $g/(r + g)$。抽取一个球时，严格来说只有两种可能的结果：要么是绿色，要么是红色。如果是绿色，第二个球是绿色的几率是$(g-1) / (r + g - 1)$。如果第一个球是红色的，第二个球是绿色的几率是$g/ (r + g -1)$。这两个都不等同于$g/(r + g)$。虽然这确实是关于已经发生的实验的说法，而不是尚未发生的实验的说法，但它仍然让我感觉作者的说法实际上不包含任何信息，类似于：“我们不知道如何在实验前调整几率，因为实验还没有发生。”
有人能帮我理解一下，不是我为什么错了，而是为什么作者的说法包含有用的信息？]]></description>
      <guid>https://stats.stackexchange.com/questions/650647/equivalence-of-first-second-choice-with-naive-probability-i-dont-buy-it</guid>
      <pubDate>Sun, 07 Jul 2024 23:16:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么具有随机效应的动态面板数据模型会根据 R 包（plm 与 lme4）产生不同的效果？</title>
      <link>https://stats.stackexchange.com/questions/650607/why-do-dynamic-panel-data-models-with-random-effects-yield-different-effects-dep</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/650607/why-do-dynamic-panel-data-models-with-random-effects-yield-different-effects-dep</guid>
      <pubDate>Sat, 06 Jul 2024 22:14:17 GMT</pubDate>
    </item>
    </channel>
</rss>