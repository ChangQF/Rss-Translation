<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 17 Aug 2024 06:19:53 GMT</lastBuildDate>
    <item>
      <title>如何从给出零一通胀和条件一通胀（ZOIB）的模型中计算零通胀和一通胀？</title>
      <link>https://stats.stackexchange.com/questions/652946/how-to-compute-zero-inflation-and-one-inflation-from-a-model-which-gives-you-zer</link>
      <description><![CDATA[我正在 brms 中拟合零一膨胀回归模型。此模型的 brms 版本估计 4 个参数：当 y != 0 或 1 时，beta 分布的 mu 和 phi、zoi（零一膨胀，即响应为零/一与非零/一的概率）和 coi（以 y 为 0 或 1 为条件的一膨胀）。
我想要的是“zi”和“oi”，即作为我的预测因子函数的 y = 0 的概率和作为我的预测因子函数的 y = 1 的概率。
如果我提取参数值 mu、phi、zoi 和 coi 的分布，是否有任何代数运算可以计算“zi”和“oi”？我已经研究了两天了，但似乎还是想不通。
附加问题：为什么这个模型要用 zoi 和 coi 而不是 zi 和 oi 来参数化？有什么数学上的原因吗？我无法想象出一个概念上的理由来说明为什么这样做是更好的选择。]]></description>
      <guid>https://stats.stackexchange.com/questions/652946/how-to-compute-zero-inflation-and-one-inflation-from-a-model-which-gives-you-zer</guid>
      <pubDate>Sat, 17 Aug 2024 04:59:33 GMT</pubDate>
    </item>
    <item>
      <title>邻域搜索比近似邻域搜索更好吗？</title>
      <link>https://stats.stackexchange.com/questions/652945/is-neighbour-search-better-than-approximate-neighbour-search</link>
      <description><![CDATA[如果我有以下内容：
200k 个向量
在 100 个向量中查找最近邻居
我应该只使用 NN 并在请求时计算距离，还是使用向量数据库进行 ANN？
我可以在内存中保存 200k 个向量，但我只想在请求时从选定数量（n=100）中搜索最近的向量。
尝试在线搜索此答案。查找何时对 n 值使用 ANN。]]></description>
      <guid>https://stats.stackexchange.com/questions/652945/is-neighbour-search-better-than-approximate-neighbour-search</guid>
      <pubDate>Fri, 16 Aug 2024 22:07:45 GMT</pubDate>
    </item>
    <item>
      <title>如何根据残差图判断是否应包括交互项？</title>
      <link>https://stats.stackexchange.com/questions/652944/how-to-tell-if-an-interaction-term-should-be-included-based-on-residual-plot</link>
      <description><![CDATA[应用线性回归模型说：

此外，残差
应该针对回归模型中未包括的潜在交互作用的交互项绘制，例如针对$X_1X_2$、$X_1X_3$和$X_2X_3$，以查看模型中是否需要部分或全部
这些交互项。

但是我不确定我在图中寻找什么来确定是否应该包括给定的交互项。例如，在问题 6.10 中，$e$ 与 $X_1X_2$ 的图如下所示：

我看到两组（数据包括一个二进制编码变量 $X_3$），但该图看起来类似于 $e$ 与 $X_1$：

我如何知道 $X_1X_2$ 项是否重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/652944/how-to-tell-if-an-interaction-term-should-be-included-based-on-residual-plot</guid>
      <pubDate>Fri, 16 Aug 2024 21:00:48 GMT</pubDate>
    </item>
    <item>
      <title>Python：获取两点/坐标之间的距离[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652940/python-get-distance-between-2-points-coordinates</link>
      <description><![CDATA[我想获取两点之间的行驶距离。我知道 Google Maps 有 API 并且存在其他解决方案，但如果可能的话，我想避免为此花钱。
我尝试了 openrouteservice（找不到足够的地址）和 Google Maps。
我每个月有大约 30,000 个地址，我想获取到这些地址的行驶距离和行驶时间。有人有不花钱的解决方案吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652940/python-get-distance-between-2-points-coordinates</guid>
      <pubDate>Fri, 16 Aug 2024 20:01:45 GMT</pubDate>
    </item>
    <item>
      <title>使用 CVXPY 解决逻辑回归问题</title>
      <link>https://stats.stackexchange.com/questions/652935/solving-logistic-regression-using-cvxpy</link>
      <description><![CDATA[我正在尝试使用 CVXPY 库编写逻辑回归模型。到目前为止，我编写的代码“有效”，因为它可以执行，不会产生任何错误消息并提供解决方案。但是，此解决方案与 scikit-learn 逻辑回归实现提供的解决方案不匹配。
我知道 scikit-learn 实现默认包含 L2 惩罚，在下面的代码示例中，您将看到我将其更改为 None。我还从 sklearn 模型中删除了截距。但解决方案仍然不匹配：
import cvxpy as cp
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression

X, y = make_classification(n_features=10, random_state=42)

sk = LogisticRegression(penalty=None, fit_intercept=False)
sk.fit(X, y)
print(sk.coef_)

这将产生输出：
[[-13.46939518 -7.09935934 19.41989522 -10.36990818 3.76335965
2.84616038 3.32474461 -2.84162961 3.13246888 1.08887971]]

现在，cvxpy 实现：
beta = cp.Variable(X.shape[1])
log_likelihood = cp.sum(cp.multiply(y, X @ beta) - cp.logistic(X @ beta))
problem = cp.Problem(cp.Maximize(log_likelihood/X.shape[0]))
problem.solve()
beta = beta.value
print(beta)

产生解决方案：
[-31.38130594 -10.72178524 44.07489985 -34.06127916 8.01950276
5.96941765 9.6143194 -7.88785049 12.96349703 -0.13264449]

编辑：
我的代码正在解决的对数似然公式是
$$
\ell(\beta)=\sum_{i=1}^m y_i \beta^T x_i-\log \left(1+\exp \left(\beta^T x_i\right)\right)
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/652935/solving-logistic-regression-using-cvxpy</guid>
      <pubDate>Fri, 16 Aug 2024 17:28:02 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用卡方统计量来根据 60,000 个值的经验数据集评估理论 PDF 吗？</title>
      <link>https://stats.stackexchange.com/questions/652934/can-i-use-the-chi-square-statistic-to-evaluate-theoretical-pdfs-against-an-empir</link>
      <description><![CDATA[我有一个包含 60,000 个数值的数值模拟数据集。
我正在测试 4 个理论 PDF（gamma、beta、Weibull 和对数正态）与该数据的拟合度，其中分布的参数是根据数据估算的。
我可以使用卡方统计量来比较这些分布的拟合优度吗？或者卡方统计量不适合此目的，尤其是考虑到我的数据集很大？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652934/can-i-use-the-chi-square-statistic-to-evaluate-theoretical-pdfs-against-an-empir</guid>
      <pubDate>Fri, 16 Aug 2024 17:15:30 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯 Cramer-Rao 下限计算的困惑</title>
      <link>https://stats.stackexchange.com/questions/652931/confusion-on-bayesian-cramer-rao-lower-bound-calculation</link>
      <description><![CDATA[我正在研究 Cramer-Rao 下限 (CRLB)，并利用先前的知识来了解非视距 (NLOS) 造成的额外长度。我正在阅读的文章是关于非视距环境中使用先前信息的地理定位准确性和非视距环境中无线地理定位的分析。两篇文章均来自同一作者，并讨论了类似的事情。扩展CRB算法的公式为
$$J = \frac{1}{c^2}\left( \begin{bmatrix} H_{NL}\Lambda_{NL}H_{NL}^T+H_{L}\Lambda_{L}H_{L}^T &amp; H_{NL}\Lambda_{NL} \\ \Lambda_{NL}H_{NL} &amp; \Lambda_{NL}+c^2\Omega \end{bmatrix} \right),$$
其中$H_{NL}$和$H_L$分别是NLOS和LOS基站的角度矩阵。 $\Lambda$ 代表根据接收信号计算出的对角矩阵 $\operatorname{diag}8\pi^2\beta^2\cdot R_b$。$\Omega = \operatorname{diag}(\sigma^2_l)$ 是先前已知的 NLOS 延迟协方差矩阵。第一篇文章中方程为(20)(21)，第二篇文章中方程为(50)。
由于局部化只关心$(x,y)$位置，所以只考虑上子矩阵，这意味着先验NLOS延迟$\sigma^2_l$对计算没有太大影响。论文中还提到，当先验NLOS延迟的方差很大时，即$\sigma^2_l \rightarrow +\infty$，$H_{NL}\Lambda_{NL}H_{NL}^T$会减小；如果 $\sigma^2_l \rightarrow 0$，则 NLOS 部分可视为 LOS 估计值。
让我感到困惑的是，这些论文仍然没有告诉我如何在事先了解 NLOS 延迟的情况下计算 CRB。例如，对于总共 10 个 rx 雷达，我知道其中 2 个是 LOS，其余 8 个是 NLOS。并且根据先前的知识，我知道 NLOS 延迟呈分布，即 $\sigma^2 = 0.5$。因此，定位 CRB 的计算应该是 $H_{NL}\Lambda_{NL}H_{NL}^T+H_L \Lambda_L H_L^T$（考虑 $8+2$ 个接收器）或 $H_L\Lambda_{L}H_L^T$（仅考虑 2 个 LOS）？如果方差是 1 或 2 甚至 10，情况会怎样？
对我来说，“先验知识”似乎不用于计算 CRB，但也给出了一个判断，即某些雷达信息是否不应该在计算中考虑。]]></description>
      <guid>https://stats.stackexchange.com/questions/652931/confusion-on-bayesian-cramer-rao-lower-bound-calculation</guid>
      <pubDate>Fri, 16 Aug 2024 15:26:14 GMT</pubDate>
    </item>
    <item>
      <title>用类高斯因子近似高维积分的有效方法</title>
      <link>https://stats.stackexchange.com/questions/652919/efficient-methods-for-approximating-high-dimensional-integrals-with-gaussian-lik</link>
      <description><![CDATA[我正在寻找一种计算效率高的方法来近似地评估以下形式的高维积分：
$$\int f(\textbf{x}) \prod_i g_i(x_i) \, d\textbf{x}$$
其中 $f(\mathbf{x}) = (\mathbf{x}&#39;\mathbf{A}\mathbf{x})^{-k}$，其中 $k$ 是一个大整数，而 $\mathbf{x}$ 的维度通常为 $n &gt; 5,000$。函数$g_i(x_i)$是概率密度函数，可以用高斯分布$\mathcal{N}(x_i; \mu_i, \tau_i)$来近似，因为$g_i(x_i)$的拉普拉斯近似很容易推导。一般而言，$g_i(x_i)$ 可以假设为具有简单且易处理的单变量形式，并且易于从中采样。
到目前为止我尝试过的方法：

蒙特卡洛积分：虽然从 $g_i(x_i)$ 采样很简单，但收敛速度非常慢。一般而言，基于采样的方法可能不可行，因为计算成本高。

拉普拉斯近似：这种方法不切实际，因为$\mathbf{A}$的结构、$f(\mathbf{x})$的行为（当$\mathbf{x} = 0$时会飙升至无穷大）以及高维性使得以计算成本低廉的方式找到被积函数的模式非常具有挑战性。

关注$g_i(x_i)$：当所有$\tau_i$都很小时，拉普拉斯近似在近似被积函数模式$\mathbf{\mu}$下进行近似，甚至简单地使用$\int f(\mathbf{x}) \prod_i g_i(x_i) \, d\mathbf{x} \approx (\mathbf{\mu}&#39;\mathbf{A}\mathbf{\mu})^{-k}$都非常有效。但是，假设所有 $i$ 的 $\tau_i$ 都很小并不总是可行的。

直接近似：尝试近似随机变量 $g(\mathbf{x})$ 的高斯近似值 $\mathbf{x}&#39;\mathbf{A}\mathbf{x}$ 的密度，然后估计所得分布的第 $k$ 个负矩，这有点有效，但结果并不令人满意。


我很好奇，考虑到$g_i(x_i)$ 是（近似）高斯分布且独立的。考虑到此问题的结构，还有其他近似方法可能在计算上可行吗？如能提供任何替代方向的建议或提示，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/652919/efficient-methods-for-approximating-high-dimensional-integrals-with-gaussian-lik</guid>
      <pubDate>Fri, 16 Aug 2024 09:16:27 GMT</pubDate>
    </item>
    <item>
      <title>了解何时使用负二项式 GLMM</title>
      <link>https://stats.stackexchange.com/questions/652909/understanding-when-to-use-a-negative-binomial-glmm</link>
      <description><![CDATA[我有 16 只鸟。其中有 6 只雄性和 10 只雌性。数据集名为“Gbirds_sex”，“timeInside”列显示释放地点内的停留时间。我想在 R 中进行统计分析，看看性别是否影响停留时间（timeInside）。鉴于我的样本量不相等，我不知道哪种测试效果最好，以及它的 R 代码是什么。
首先，我运行了一个 GLM：
使用高斯族将“性别”作为预测因子，为“timeInside”拟合 GLM
glm_timeInside &lt;- glm(timeInside ~ sex, data = Gbirds_sex)
summary(glm_timeInside)

其次，我检查了过度分散：
residual_deviance &lt;- deviance(glm_timeInside)
df_residual &lt;- df.residual(glm_timeInside)
计算过度分散统计量
overdispersion_statistic &lt;- residual_deviance / df_residual
print(overdispersion_statistic)

第三，由于分散度很高（7），我运行了一个 GLMM，以 timeInside 作为响应变量，以 sex 作为固定效应，以 id 作为随机效应
glmm_timeInside &lt;- lmer(timeInside ~ sex + (1|id), data = Gbirds_sex)
summary(glmm_timeInside)
这不适合 - “边界（奇异）拟合：请参阅帮助（&#39;isSingular&#39;）”。
下一步是准高斯 GLM 吗？它不提供 AIC 值（“NA”）可以吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652909/understanding-when-to-use-a-negative-binomial-glmm</guid>
      <pubDate>Fri, 16 Aug 2024 03:05:07 GMT</pubDate>
    </item>
    <item>
      <title>戴明回归和数值配方</title>
      <link>https://stats.stackexchange.com/questions/652796/deming-regression-and-numerical-recipes</link>
      <description><![CDATA[我试图对戴明回归进行分类，这意味着我想通过 x 和 y 坐标中都有“错误”的数据来拟合一个函数（一条直线）。我正在查看《数值方法》第 15.3 章，发现他们的方法的基础很神秘。
对我来说最令人费解的是他们选择最小化的优值函数：
\begin{equation}
\chi^{2} = \sum_{i=1}^{N} \frac{(y_{i} - a - b\cdot x_{i})^{2}}{\sigma_{yi}^{2} + b^{2}\cdot\sigma_{xi}^{2}}
\end{equation&gt;
这对我来说看起来不对。 $y_{i} - a - b\cdot x_{i}$ 是 y 中的残差。难道不应该有一个附加项，用于最小化线和 x 数据之间的平方距离吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652796/deming-regression-and-numerical-recipes</guid>
      <pubDate>Wed, 14 Aug 2024 15:31:13 GMT</pubDate>
    </item>
    <item>
      <title>如何计算生存模型中累积风险预测差异的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/652760/how-do-i-compute-confidence-intervals-for-the-predicted-difference-in-cumulative</link>
      <description><![CDATA[我有以下数据：
library(cobalt)
library(tidycmprsk)
library(ggsurvfit)
library(gtsummary)

set.seed(123)
lalonde &lt;- cbind(lalonde, 
event = sample(c(0, 1), size = 614, replace = TRUE, 
prob = c(0.84, 0.16)), 
time = runif(614, min = 10, max = 365))
n &lt;- ceiling(0.05 * nrow(lalonde)) 
selected_indices &lt;- sample(1:nrow(lalonde), size = n)
lalonde[selected_indices, &quot;event&quot;] &lt;- 2

lalonde$event &lt;- factor(lalonde$event, levels = c(0, 1, 2),
labels = c(&quot;Censored&quot;, &quot;Event1&quot;, &quot;Event2&quot;))

我可以从累积发生率函数中得出绝对风险：
p &lt;- cuminc(Surv(time, event) ~ treat, lalonde) %&gt;% 
tbl_cuminc(
times = c(180, 230),
label_header = &quot;**{time}-day cuminc**&quot;) 

得出：
特征 180 天cuminc 230 天 cuminc
治疗 

0 8.1% (5.6%, 11%) 14% (11%, 19%)
1 9.1% (5.3%, 14%) 13% (8.2%, 20%)

如何计算指定时间点的置信区间风险差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/652760/how-do-i-compute-confidence-intervals-for-the-predicted-difference-in-cumulative</guid>
      <pubDate>Tue, 13 Aug 2024 08:25:01 GMT</pubDate>
    </item>
    <item>
      <title>如何使用统计测试比较多个列表中各个项目的排名？</title>
      <link>https://stats.stackexchange.com/questions/652692/how-to-compare-ranks-for-individual-items-across-multiple-lists-using-statistica</link>
      <description><![CDATA[我有多个针对相同项目的排名列表，我想比较特定项目在两个列表子集中的排名并评估统计意义，我应该使用哪些统计测试？我可以简单地对排名进行 t 检验吗，尽管它们的分布不正常？
例如，在虚拟数据集 df 中：
&gt; set.seed(123)
&gt; df &lt;- data.frame(replicate(n = 6, expr = sample(1:10, 10, replace = FALSE)))
&gt; rownames(df) &lt;- paste0(&quot;Item&quot;, LETTERS[1:10])

&gt; df
X1 X2 X3 X4 X5 X6
ItemA 3 10 8 7 7 2
ItemB 10 5 7 5 5 1
ItemC 2 3 2 4 10 9
ItemD 8 8 1 10 9 3
ItemE 6 1 6 2 3 8
ItemF 9 4 3 9 1 5
ItemG 1 6 4 3 2 7
ItemH 7 9 10 1 8 6
ItemI 5 7 9 8 6 4
ItemJ 4 2 5 6 4 10

我想看看 ItemF 在两个子集（列 1、2、3 与列 4、5、6）之间的排名是否不同。我可以这样做吗：
&gt; t.test(df[&quot;ItemF&quot;, 1:3], df[&quot;ItemF&quot;, 4:6])

Welch 双样本 t 检验

数据：df[&quot;ItemF&quot;, 1:3] 和 df[&quot;ItemF&quot;, 4:6]
t = 0.11251，df = 3.823，p 值 = 0.9161
备选假设：均值的真实差异不等于 0
95% 置信区间：
-8.044952 8.711619
样本估计值：
x 的均值 y 的均值
5.333333 5.000000
]]></description>
      <guid>https://stats.stackexchange.com/questions/652692/how-to-compare-ranks-for-individual-items-across-multiple-lists-using-statistica</guid>
      <pubDate>Tue, 13 Aug 2024 03:18:05 GMT</pubDate>
    </item>
    <item>
      <title>测量嵌入空间中的相似性？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651840/measuring-similarity-in-embedding-spaces</link>
      <description><![CDATA[就上下文而言，我一直在使用特征哈希对快速文本分类器进行处理，该分类器的特征数量非常少（2000 个，故意设置得非常少）。我注意到由于碰撞，一些结果有点不稳定，我想知道是否可以选择更好的哈希（改变哈希函数和随机密钥）以获得更“自然”的结果碰撞。
为了从经验上选择一个更好的哈希，我已经确定，对于给定的数据集，测量哈希特征与神经特征的分布的相似性。具体来说，我想捕获：

邻域保存得如何？
邻域之间的距离保存得如何？

这是我到目前为止尝试过的：

Kendall 的 Tau，捕获 1。但不是 2。计算成本也相对较高（在较旧的计算机上约为 20 秒）
Gromov-Wasserstein，查看分布而不是特定单词。与 1 的时间相似
求解两者之间的线性变换（最小二乘法）。不确定如何将其转换为有意义的指标（残差、幅度？）。成本是可变的。

除了测量嵌入空间相似性的方法之外，我还愿意接受其他方法来选择更好的哈希值]]></description>
      <guid>https://stats.stackexchange.com/questions/651840/measuring-similarity-in-embedding-spaces</guid>
      <pubDate>Fri, 26 Jul 2024 22:54:11 GMT</pubDate>
    </item>
    <item>
      <title>如何使用重复测量对嵌套数据进行建模</title>
      <link>https://stats.stackexchange.com/questions/633635/how-to-model-nested-data-with-repeated-measures</link>
      <description><![CDATA[我的数据如下：我有 N 名来自不同课程的学生（变量 course_id），他们被问及家庭收入（变量 income），并且必须参加两次数学测试；一次测试被认为是“收入公平”，另一次则不是（变量 test_type）。数学测试的结果在变量 test_results 中。每个学生都参加了两次测试。学生按课程分组。学生有一个 ID 变量 student_id。
我一般的问题是收入对测试结果的影响是否因测试类型而异，即收入公平测试的影响较小。我现在面临的挑战是对此进行建模，因为学生嵌套在课程中（每门课程有多名学生；每个学生只参加一门课程），并且有重复的测量（每个学生参加两次测试：公平测试和正常测试）。我想考虑到课程的测试结果可能存在随机截距和收入斜率。怎么做？
我已经阅读并尝试了很多类似这个的东西，现在我很困惑。我在 R 中做的是这样的：
my_fit &lt;- lme4::lmer(test_results ~ income + (1|test_type) + (1|course_id) +
(income|course_id), data= anna_long)
summary(my_fit)

但我不确定这是否正确。而且收入预测器没有 p 值...我迷路了..

之前我也想考虑到每个学生也可能有随机截距和斜率，我所做的是...
my_fit &lt;- lme4::lmer(test_results~income + (1|test_type) + 
(1|course_id/student_id) + (income|course_id/student_id), 
data= anna_long)
summary(my_fit)

...但这导致了错误

观察次数 (=361) &lt;= 随机效应次数 (=362)

...因此，我丢弃了与单个学生相关的随机效应，并专注于课程的随机效应，如下所示以上。]]></description>
      <guid>https://stats.stackexchange.com/questions/633635/how-to-model-nested-data-with-repeated-measures</guid>
      <pubDate>Mon, 11 Dec 2023 15:29:48 GMT</pubDate>
    </item>
    <item>
      <title>如何选择度量学习的输出向量大小？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/622655/how-to-choose-the-output-vector-size-for-metric-learning</link>
      <description><![CDATA[在度量学习中，例如，MNIST 图像，CNN 将 28 x 28 图像投影到 $d$ 维向量中，该向量将传递给度量学习损失函数：如果这些向量来自同一个数字，则最小化它们之间的欧几里得距离或余弦距离，如果它们来自不同的数字，则最大化距离。
现在我正在做机器学习（度量学习），我面临的问题是：如何最好地选择输出向量的大小，$d$？
因为，如果我选择大尺寸：我必须有更多的学习周期才能获得足够的结果
而且我认为：如果我选择小尺寸，那么有可能无法创建最终向量以明确区分不同组中的对象。
我应该怎么做？
我怎么知道输出向量大小不够？
这样的特征（维度）只能选择，或者也许存在某种估计公式，或者至少存在取决于图像大小的参数数量的上限？]]></description>
      <guid>https://stats.stackexchange.com/questions/622655/how-to-choose-the-output-vector-size-for-metric-learning</guid>
      <pubDate>Sat, 29 Jul 2023 18:55:30 GMT</pubDate>
    </item>
    </channel>
</rss>