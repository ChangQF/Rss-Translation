<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 29 Jul 2024 18:20:08 GMT</lastBuildDate>
    <item>
      <title>简单随机抽样是对抽象概率测度空间中的概率测度的假设吗？</title>
      <link>https://stats.stackexchange.com/questions/651959/is-simple-random-sampling-an-assumption-on-the-probability-measure-in-the-abstra</link>
      <description><![CDATA[我想知道我对简单随机抽样含义的直觉是否正确。
假设我们有一个抽象概率测度空间$(\Omega, \mathcal{A}, \mathbb{P})$，
某个可测空间$(\mathbb{R}, \mathcal{B}(\mathbb{R}))$，以及一个映射$X$，它是一个有效的随机变量，写为$X : \Omega \rightarrow \mathcal{B}(\mathbb{R})$。然后，$\mathbb{P}_{X}$ 是由 $X$ 引起的 $\mathbb{P}$ 的 前推测度，它是概率测度 $\mathbb{P}_{X} : \mathcal{B}(\mathbb{R}) \rightarrow [0, 1]$。因此，$\mathbb{P}_{X}$ 是 $X$ 的 概率分布测度，而
$(\mathbb{R}, \mathcal{B}(\mathbb{R}), \mathbb{P}_{X})$ 是 具体 的概率测度空间（即，如下所示）。

这样说对吗即：

我们为 $\mathbb{P}_{X}$ 选择的函数形式是我们对总体（即样本空间 $\Omega$）中测量值 $X$ 分布的假设？

简单随机抽样机制（即均匀分布）是我们对 $\{\omega\}$ 元素（例如，人）在 $\Omega$ 中的概率的假设？换句话说，我们是否假设$\mathbb{P}$是均匀分布？


我的背景是心理学，在我的阅读中，我没有遇到任何作者描述符合我上述第二个问题的简单随机抽样——重点似乎在$\mathbb{P}_{X}$上。假设上面的第二个问题是正确的，这不就等于说

事件$\{\omega\} \in \mathcal{A}$的发生（即，无论它对一个人意味着什么...）与其被选为样本$\{\omega_{1}, \omega_{2}, \omega_{3}, ...\} \subseteq \Omega$的一部分的概率相同吗？

我希望这是有道理的，我将不胜感激任何意见和直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/651959/is-simple-random-sampling-an-assumption-on-the-probability-measure-in-the-abstra</guid>
      <pubDate>Mon, 29 Jul 2024 17:45:24 GMT</pubDate>
    </item>
    <item>
      <title>测量逻辑核函数变换后的准确率</title>
      <link>https://stats.stackexchange.com/questions/651958/measuring-the-accuracy-after-transforming-function-in-logistic-kernel</link>
      <description><![CDATA[我有一个使用高斯核和逻辑核的非参数估计器。假设使用高斯核的估计定义为 $E_G$，逻辑核定义为 $R_L$。随着样本量的增加，我发现 $E_G$ 的 MSE（均方误差）正在减小。当谈到 $E_G$ 时，我收到的输出为
&quot;**标量幂中遇到溢出
return np.exp(-z)/(1+np.exp(-z)**2)**2,RuntimeWarning: 标量除法中遇到无效值
return np.exp(-z)/(1+np.exp(-z)**2)**2,IntegrationWarning: 检测到舍入误差的发生，这会阻止
实现所请求的容差。错误可能被低估了。&quot;。
如果我们使用 sigmoid 函数，那么可以控制溢出，但它也包含错误，在这种情况下，比较 $E_G$ 和 $E_L$ 是否公平。]]></description>
      <guid>https://stats.stackexchange.com/questions/651958/measuring-the-accuracy-after-transforming-function-in-logistic-kernel</guid>
      <pubDate>Mon, 29 Jul 2024 17:38:36 GMT</pubDate>
    </item>
    <item>
      <title>中期分析如何改变非劣效性分析所需的样本量？</title>
      <link>https://stats.stackexchange.com/questions/651957/how-does-interim-analysis-change-sample-size-needed-for-non-inferiority-analyses</link>
      <description><![CDATA[我正在测量试验 1 与试验 2，并进行非劣效性分析以确保试验 1 不会明显差于试验 2。这涉及测试 4 个假设（即，4 个测量中性能差异的 95% 置信区间的上限必须小于 15%）。
团队希望进行中期分析。我建议不要这样做，因为除非我们很幸运并且具有完美的一致性，否则我们肯定无法拒绝这 4 个假设，因为否则置信区间将太宽而无法拒绝 &gt;15% 的增量。
此外，如果我们进行中期分析，我们可能会被要求增加样本量。但在这种情况下，样本量调整究竟如何计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/651957/how-does-interim-analysis-change-sample-size-needed-for-non-inferiority-analyses</guid>
      <pubDate>Mon, 29 Jul 2024 17:28:50 GMT</pubDate>
    </item>
    <item>
      <title>既然我们现在拥有无限的计算能力（相对于历史规范），我们是否需要使用统计方法而不是模拟？</title>
      <link>https://stats.stackexchange.com/questions/651956/since-we-now-have-unlimited-computation-power-relative-to-historical-norms-do</link>
      <description><![CDATA[Allen Downey 于 2016 年撰写了一篇博客文章，标题为“仍然只有一个测试”，其中讨论了运行模拟相对于传统统计测试的优势。它认为，由于计算速度现在比历史标准快了数万倍，因此统计中的传统分析方法不再有意义。例如，当 t 检验于 1908 年被发现时，它非常有用，因为所有计算都是手工完成的。但如今，iPhone 运行统计计算的速度比 1908 年人类手工计算的速度快约 10 万倍。
引用 Downey 的话：

当计算速度慢且成本高时，这些分析方法是必要的，但随着计算变得更便宜、更快，它们的吸引力就降低了，因为：

它们不灵活：如果您使用标准测试，则必须使用特定的测试统计量和零假设的特定模型。您可能不得不使用不适合您问题领域的测试统计量，只是因为它适合分析。如果您试图解决的问题不适合现成的模型，那么您就倒霉了。

它们不透明：零假设是一个模型，这意味着它是对世界的简化。对于任何现实世界场景，都存在许多基于不同假设的可能模型。在大多数标准测试中，这些假设都是隐含的，很难知道某个模型是否适合特定场景。


模拟方法最重要的优势之一是它们使模型明确化。当您创建模拟时，您不得不考虑您的建模决策，而模拟本身会记录这些决策。

他还在这篇博文中提供了此类模拟的实际示例。这让我感到疑惑：

在当今的计算能力如此强大的情况下，为什么我们仍然要运行传统的统计测试，而不是创建明确的模型并运行数百万次模拟来找出观察结果的真实 p 值？
是否还存在传统统计方法优于模拟的情况？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651956/since-we-now-have-unlimited-computation-power-relative-to-historical-norms-do</guid>
      <pubDate>Mon, 29 Jul 2024 16:59:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 eventdd 进行事件研究 - 解释</title>
      <link>https://stats.stackexchange.com/questions/651955/event-study-with-eventdd-interpretation</link>
      <description><![CDATA[我对实现这类模型还很陌生，所以这可能是一个基本问题，但我希望你能帮助我。
我试图了解复制对论文引用计数的影响。为此，我的论文导师建议我绘制一个事件研究。
我的数据是一个看起来像这样的面板：

其中，paper_id是论文，replicated是处理，lenght n_authors m_authors m_share是每篇论文的附加特征，不会随时间而变化。这个小组非常不平衡（有些论文有 20 年的引用，因为它们是很久以前发表的，有些论文有 4 年的引用，因为它们是最近发表的）。有些论文从未被复制过（因此 replicated=0）
我相信我应该实现的模型应该是这样的：

其中 years_since_rep 在事件发生前为负数，在事件发生后为正数。
我遇到了 eventdd 命令，我将其实现如下：
set more off
clear all

ssc install matsort
ssc install eventdd, replace
net install eventdd, from(&quot;https://raw.githubusercontent.com/damiancclarke/eventdd/master&quot;)替换

*导入数据集
import excel &quot;C:\Users\User\Desktop\clean_pandat.xlsx&quot;, firstrow

*声明面板数据
encode paper_id, gen(P_id) /*将 paper_id 字符串转换为数字*/

xtset P_id year

generate timeToTreat = year- rep_year
*删除一些异常值后
drop if rep_year &gt; 2021 &amp; !missing(rep_year) //57 个 obs 被删除
drop if paper_id == &quot;Pool_1972&quot; //52 个 obs 被删除
drop if paper_id == &quot;Hirschman_1967&quot; //57 个 obs 被删除

eventdd 引用重复 i.year, timevar(timeToTreat) method(,cluster(P_id)) graph_op(ytitle(&quot;Citations per Year&quot;))

我的结果如下：


我的问题是：

我以为结果表中只应出现滞后和领先，但我还得到了各年的系数。通常情况是这样吗？
我看到只有最后的领先是显著的。这是否意味着，重复对引用几乎没有影响？
鉴于这似乎很重要，但领先并不重要，那么重复的系数是否相关？
我认为此命令不允许泊松回归。但是，由于我的因变量引用是计数非负变量，因此实现包含泊松模型的模型是否更合适？

我希望我的问题清楚。感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/651955/event-study-with-eventdd-interpretation</guid>
      <pubDate>Mon, 29 Jul 2024 16:50:14 GMT</pubDate>
    </item>
    <item>
      <title>分层抽样加权平均值计算中缺失组的处理</title>
      <link>https://stats.stackexchange.com/questions/651954/handling-missing-groups-in-stratified-sampling-for-weighted-mean-calculation</link>
      <description><![CDATA[我使用分层样本进行了一项统计调查，以测量意大利学生对特定主题的知识。人口根据以下类别分层：地区（城市和农村）、性别（男性、女性和其他）、区域（北部、南部和中心）和学校类型（高中、技术和专业）。这导致 2 * 3 * 3 * 3 = 54 个组组合。
但是，有些组没有回应，这会扭曲权重估计，从而扭曲分数的加权平均值。每个单位的权重计算为组样本大小的倒数。我想知道如何处理没有回应的组以获得正确的估计值。
此外，性别中的“其他”类别仅由 8 个单位代表（约占抽样人口的 2%）。我该如何处理这种情况？
数据模拟可以帮助您（语言 R）：
 library(dplyr)
library(tidyr)

# 数据模拟
set.seed(42)
data &lt;- data.frame(
Region = sample(c(&quot;North&quot;, &quot;Center&quot;, &quot;South&quot;), 300, replace = TRUE),
Area = sample(c(&quot;Urban&quot;, &quot;Rural&quot;), 300, replace = TRUE),
Gender = sample(c(&quot;Male&quot;, &quot;Female&quot;, &quot;Other&quot;), 300, replace = TRUE, prob = c(0.49, 0.49, 0.02)),
Type = sample(c(&quot;High School&quot;, &quot;Technical&quot;, &quot;专业&quot;), 300, replace = TRUE),
Score = runif(300, 60, 100)
)

# 缺失类别
data &lt;- data %&gt;%
filter(!(Region == &quot;北部&amp; 地区 == &quot;城市&amp; 类型 == &quot;专业&quot;))

# 检查并完成缺失组
data_complete &lt;- data %&gt;%
group_by(Region, 地区, 性别, 类型) %&gt;%
summarise(
size = n(),
weight = if_else(size == 0, 0, 1 / size)
) %&gt;%
ungroup() %&gt;%
complete(Region, 地区, 性别, 类型, fill = list(size = 0, weight = 0))

# 组缺失
data_complete %&gt;%
过滤器（大小 == 0）
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/651954/handling-missing-groups-in-stratified-sampling-for-weighted-mean-calculation</guid>
      <pubDate>Mon, 29 Jul 2024 16:43:19 GMT</pubDate>
    </item>
    <item>
      <title>你能将多个滞后变量的 SHAP 值相加吗？</title>
      <link>https://stats.stackexchange.com/questions/651953/can-you-sum-the-shap-values-of-multiple-lagged-variables</link>
      <description><![CDATA[我想评估用于预测计数结果 $Y$ 的梯度提升机模型的特征重要性。数据是时间序列，我在模型中引入了预测因子的滞后形式，例如：$X$、$X_{-t1}$、$X_{-t2}$、$X_{-t3}$ 都是模型特征的一部分，其中 $X$ 是给定的预测因子，$t$ 是三个时刻的滞后时间。我的问题是，当我通过平均边际 SHapley Additive exPlanations (SHAP)（因此对每个特征取平均值）评估特征重要性时，我可以将 $X$ 和所有 $X$ 滞后特征相加为一个唯一的 SHAP 值吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651953/can-you-sum-the-shap-values-of-multiple-lagged-variables</guid>
      <pubDate>Mon, 29 Jul 2024 16:40:20 GMT</pubDate>
    </item>
    <item>
      <title>均匀分布中的无偏估计量</title>
      <link>https://stats.stackexchange.com/questions/651951/unbiased-estimators-in-uniform-distributions</link>
      <description><![CDATA[变量 x 在区间 (a-1,a+1) 内均匀分布，其中 a 的值未知。对 x 的一次观察给出了值 x1。
我如何（有证据）使用 x1 的这个值来确定 a 的无偏估计值，并确定 a 的 99% 置信限度。]]></description>
      <guid>https://stats.stackexchange.com/questions/651951/unbiased-estimators-in-uniform-distributions</guid>
      <pubDate>Mon, 29 Jul 2024 16:07:54 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 VAR 脉冲响应及其置信区间</title>
      <link>https://stats.stackexchange.com/questions/651950/how-to-var-calculate-impulse-responses-and-their-confidence-intervals</link>
      <description><![CDATA[我正在尝试弄清楚如何在实践中计算脉冲响应，因为我在互联网上找到的所有材料都给出了纯理论解释，这对我来说很难理解。我可以简单地运行 VAR(x_1 + 1, x_2, x_3) - VAR(x_1, x_2, x_3) 并准确获得脉冲响应吗？我尝试将此类脉冲响应与 statsmodels.VAR.impulse_responses 进行比较，它们似乎相等。如果是这样，那么我该如何计算它们的置信区间？我可以简单地取 (1 - B)^(-1) 并计算其标准误差吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651950/how-to-var-calculate-impulse-responses-and-their-confidence-intervals</guid>
      <pubDate>Mon, 29 Jul 2024 16:01:55 GMT</pubDate>
    </item>
    <item>
      <title>ABM 穿越时间</title>
      <link>https://stats.stackexchange.com/questions/651947/abm-crossing-times</link>
      <description><![CDATA[假设我有一个遵循算术布朗运动的过程
$dX_t = \sigma dW_t$
如何计算在某个间隔$\Delta t$内，该过程从起始时间起“离开”某个波段$\delta$的预期次数。
即，假设我有一个起点$X_0$和$t_0$。假设到$t_1, X_1 &gt; X_0 + \delta$ 或 $X_1 &lt; X_0 -\delta$。这应该将计数加一。然后我想将频带重置为 $X_1 \pm \delta$ 等。过程 $X_t$ 将在 $\Delta t$ 内离开这些频带的预期次数是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/651947/abm-crossing-times</guid>
      <pubDate>Mon, 29 Jul 2024 15:44:42 GMT</pubDate>
    </item>
    <item>
      <title>不平衡面板数据——最佳选择？</title>
      <link>https://stats.stackexchange.com/questions/651946/unbalanced-panel-data-best-options</link>
      <description><![CDATA[我有 1920-1935 年的一组购房交易。我希望研究一系列变量对这些交易规模的影响。这些交易通常涉及相同的买家，但它们在这段时间内的分布并不一致（例如，公司 A 可能在 1921 年、1927 年和 1933 年有重复交易，而公司 C 在 1922 年、1927 年、1930 年和 1935 年有重复交易）。
理想情况下，我会使用固定效应估计量来解释实体特定特征，但我认为我不能这样做，因为我没有足够的一致重复（如果我选择最佳间隔 - 在我的情况下是 1923 年、1927 年、1932 年和 1934 年 - 在这些年份我可以获得重复数据的公司数量最多为 8 家）。考虑到这个问题，我应该使用合并 OLS 回归吗？或者，我的数据是否最适合时间序列（虽然丢失实体级变化似乎很可惜）？
非常感谢您的建议，]]></description>
      <guid>https://stats.stackexchange.com/questions/651946/unbalanced-panel-data-best-options</guid>
      <pubDate>Mon, 29 Jul 2024 15:14:18 GMT</pubDate>
    </item>
    <item>
      <title>确保至少遇到 1 只动物的概率的圆的半径</title>
      <link>https://stats.stackexchange.com/questions/651945/radius-of-circle-to-ensure-certain-probability-of-encountering-at-least-1-animal</link>
      <description><![CDATA[我正在尝试计算一个圆的半径，在这个圆中，至少有一只已知密度的动物以一定的概率出现。为简单起见，我们假设动物呈连续的圆形均匀分布。
首先，我知道动物密度 (D) 是丰度 (N) 与面积 (A) 之比，
$$
D = \frac{N}{A}
$$
我知道圆面积与半径 (R) 的关系方程，
$$
D = \frac{N}{\pi R^2}
$$
重新排列为 $R$，
$$
R^2 = \frac{N}{\pi D}
$$
这就是我有点迷茫的地方。举个例子，我们假设 $D = 5$（意味着每 100 公里有 5 只动物$^2$ 或每公里有 0.05 只动物$^2$），我将概率设置为 10%。那么半径应该是，
$$
R = \sqrt{\frac{0.10}{0.05\pi}}
$$
那么半径为 ~0.80 公里的圆有 10% 的概率遇到至少 1 只动物（再次假设连续圆形均匀分布）？]]></description>
      <guid>https://stats.stackexchange.com/questions/651945/radius-of-circle-to-ensure-certain-probability-of-encountering-at-least-1-animal</guid>
      <pubDate>Mon, 29 Jul 2024 15:13:55 GMT</pubDate>
    </item>
    <item>
      <title>麦克尼马尔检验需要经过多少次试验才会得出错误结果？</title>
      <link>https://stats.stackexchange.com/questions/651944/how-many-trials-until-mcnemars-test-gives-an-incorrect-result</link>
      <description><![CDATA[（虽然这个问题的表述方式像是一道考试题，但这是我完全自己编造的一道题。）
L 先生是一名机器学习研究生，致力于构建会玩游戏的人工智能。他们通过让两个人工智能相互对战来测试它们。每场比赛都会有一个模型获胜，另一个模型失败，他们只是记录每个模型在测试过程中获胜的次数。
L 先生是一名机器学习研究生，致力于构建会玩游戏的人工智能。他们通过让两个人工智能相互对战来测试它们。每场比赛都会有一个模型获胜，另一个模型失败，他们只是记录每个模型在测试过程中获胜的次数。
 L 不太擅长统计，所以他们使用 ChatGPT 并了解 McNemar 检验来计算结果是否具有统计意义。
具体来说：
def mcnemars_test(w1, w2):
n10 = w1 # 玩家 1 获胜
n01 = w2 # 玩家 2 获胜

# 计算检验统计量（使用 Yates 连续性校正）
chi2_stat = (abs(n01 - n10) - 1)**2 / (n01 + n10)

# 从自由度为 1 的卡方分布计算 p 值
p_value = stats.chi2.sf(chi2_stat, df=1)

return chi2_stat, p_value

但是，由于 L 先生是毕业生学生担心发表，他们希望确保他们的结果具有统计意义。因此，他们决定继续让人工智能玩游戏，直到结果具有统计意义（p&lt;0.05）。
假设 L 先生失败了，两个人工智能实际上是等价的。平均而言，L 先生需要让人工智能玩多少场游戏，McNemar 的测试才会返回结果，即数据由性能相同的模型生成的概率小于 5%（p&lt;0.05）？
额外加分 #1：我们已经回答了“平均而言”L 先生需要玩多少场游戏的问题，但分布是什么样的？如果 L 先生进行了 $n$ 次试验，那么观察到显著结果的概率是多少（尽管模型相同）？
额外加分 #2：如果 L 先生真的想确保他们的结果显著，因此他们使用 p&lt;0.01 作为截止值，会怎样？那么平均需要多少场游戏？一般情况下，p
我问这个问题是因为我被告知，对于统计测试，您应该事先确定试验次数，然后使用测试，并且增加测试次数直到获得显著结果就是 p-hacking 并破坏测试。但是，我实际上还没有看到过关于这种 p 值操纵有多严重的计算，而且我不知道如何凭空计算这样的事情。
我的直觉是，额外积分 #1 (EC#1) 实际上相当容易回答，我只是没有清楚地考虑它，主要问题只是 EC#1 的预期值，所以它也可能很容易回答。但是，我真的不确定 EC#2。]]></description>
      <guid>https://stats.stackexchange.com/questions/651944/how-many-trials-until-mcnemars-test-gives-an-incorrect-result</guid>
      <pubDate>Mon, 29 Jul 2024 15:10:13 GMT</pubDate>
    </item>
    <item>
      <title>使用向量自回归 (VAR) 模型预测金融资产回报</title>
      <link>https://stats.stackexchange.com/questions/651943/predicting-financial-asset-returns-using-a-vector-autoregressive-var-model</link>
      <description><![CDATA[我有 10 种资产（假设是股票）的交易数据。数据自 2007 年以来以 5 分钟为间隔。数据行和列的示例如下所示，其中“ivv”、“iwm”和“xlf”是 10 种资产中的 3 种，而“_o”、“_h”、“_l”、“_c”和“_v”后缀指的是时间戳中每项资产的开盘价、最高价、最低价、收盘价和成交量值。整个数据集的形状为 (342200, 55)。这些值不是按百分比变化（回报）直接计算的价格。

从理论上讲，可以想象每个变量都会影响每个变量。因此，我运行了一个 VAR 模型，其中所有变量都是内生变量（并且基于 AIC 的阶数为 5）。但实际上，我最感兴趣的是预测收盘价，因为您可以更轻松地根据收盘价进行交易（但开盘价也可以，而且预测最高价和最低价仍然是非常有用的信息）。
接下来，我计算每个方程的 R 平方，即方程中实际值和拟合值之间的平方相关性。R 平方的范围从 0.3% 到 73%。所有收盘变量的 R 平方均小于 6%，而 R 平方最高的变量几乎都是开盘价。
可视化预测表现的一种方法是绘制累积实际值和拟合值。请记住，这些值是回报，因此这将是累积回报，这接近于交易系统绩效的评估方式。对于资产“ijr”收盘价（R 平方=6%），图表如下所示：

而对于资产“xlu”开盘价（R 平方=73%），图表如下所示：

因此，我有几个问题：

xlu_o 的预测看起来非常好。我是否忽略了方法论中的某些内容？
鉴于这些资产不会隔夜交易，并且今天的收盘价与明天的开盘价非常接近，那么如何解释所有收盘价预测都如此糟糕，而开盘价预测却如此好？
我将所有变量都用作内生变量而没有一个变量是外生变量的理由是否正确？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651943/predicting-financial-asset-returns-using-a-vector-autoregressive-var-model</guid>
      <pubDate>Mon, 29 Jul 2024 14:57:55 GMT</pubDate>
    </item>
    <item>
      <title>lme 成对比较中的估计解释</title>
      <link>https://stats.stackexchange.com/questions/651941/interpretation-of-estimate-in-lme-pairwise-comparison</link>
      <description><![CDATA[我正在运行此模型：mod &lt;- lme(log_weight ~ log_weight0 + Group*Day, random = ~ 1 | ID, data = mydata, na.action = na.exclude)。
Day 变量是我模型中的一个因素，因此我可以比较不同日期的多个组。对于成对比较，我使用 emmeans_results &lt;- emmeans(mod, specs = trt.vs.ctrlk ~ Group | Day) 和 pairs(emmeans_results)。
例如，Day=1 的输出如下所示：
 对比估计 SE df t.ratio p.value
Group1 - Group2 -0.026452 0.0423 202 -1.627 0.5817

我的问题是：由于我的因变量是对数变换后的权重，估计值是否等于 log(group1 的权重) - log(group2 的权重) = log(group1 的权重/group2 的权重)？据我所知，如果我将其变换回来，它将不再是权重的平均值，而是权重的几何平均值？因此，在我的示例中，估计值 -0.026 意味着 Group1 的权重几何平均值比 Group2 低 exp(-0.026) 倍？]]></description>
      <guid>https://stats.stackexchange.com/questions/651941/interpretation-of-estimate-in-lme-pairwise-comparison</guid>
      <pubDate>Mon, 29 Jul 2024 13:49:42 GMT</pubDate>
    </item>
    </channel>
</rss>