<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Tue, 11 Feb 2025 01:16:10 GMT</lastBuildDate>
    <item>
      <title>建立一个统计模型，说明人们如何对自己的身高说谎</title>
      <link>https://stats.stackexchange.com/questions/661204/making-a-statistical-model-for-how-people-lie-about-their-heights</link>
      <description><![CDATA[这些是我在北美居住时注意到的一些社会趋势：

当人们的自我调整高度时，错误可能会分为2个部分：有意识的错误（即自我报告是故意的，是故意的）和潜意识错误（即，自我报告偶然地报告了错误的高度）
在许多文化中，人们认为男人很高。因此，也许男人更有可能比实际高度高。
一般来说，高个子（即超出一定身高）可能会通过自我报告的高度比实际的高度来获得任何收益。
年长的人可能会更认为他们通过误会高度而获得的收益较少，因此可能是更真实的
我不知道女性的同等推理

假设现在我有一个数据集，其中包含年龄，性别和自我报告的身高（每人1行）。 我想制作一个统计模型，该模型试图纠正高度自我报告的偏见（使用贝叶斯技术），但我不确定如何开始。   
我试图编写基础知识：

  $ h_i^r $  =报告高度
  $ h_i^t $  = true Height（未观察到）
  $ a_i $  = age 
  $ g_i $  =性别（0 =女人，1 =男性）
  $ b_i $ 表示人的报告偏差 $ i $ 。

基本模型现在变为：
  $$ h_i^r = h_i^t + b_i $$ 
 $$ b_i = \ beta_0 + \ beta_1g_i + \ beta_2a_i + \ beta_3（h_i^t- \ \ mu_h）
但我不确定如何将我对自我报告的高度偏见的先入为主的观念转变为贝叶斯先生。此外，我不确定如何以有意义的方式定义关节先验。
有人可以告诉我如何做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661204/making-a-statistical-model-for-how-people-lie-about-their-heights</guid>
      <pubDate>Mon, 10 Feb 2025 22:51:09 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归系数的线性模型中缩放坐标（纬度和经度）</title>
      <link>https://stats.stackexchange.com/questions/661202/scaling-coordinates-latitude-and-longitude-in-a-linear-model-for-partial-regre</link>
      <description><![CDATA[我有一个数据集，我有兴趣比较部分回归系数。我在多个地方读到，预测变量应以均值为中心和缩放（按1个标准偏差）来促进这一点，尤其是如果变量在较大的尺度上。但是，我的预测因素之一恰好是经度。一般示例：
 响应变量〜中心和缩放变量1 +中心和缩放变量2 +经度 + 
中心和缩放变量1：中心和缩放变量2 + 
中心和缩放变量1：经度 + 
中心和缩放变量2：经度）
 
看来，约定是要中心/缩放所有变量，或者没有变量，但这使我想知道缩放和居中是否是必要和适合纬度和经度的。我遇到了这个Stackoverflow帖子，似乎表明答案可能是“否”因为它扭曲了坐标的含义：
在48426533/变异分区 - 使用纬度和宽容 - 解释性变量）
，但我不太了解在多个线性回归的背景下，缩放和居中是否不合适，是否主要对系数感兴趣？
感谢您对此的想法！]]></description>
      <guid>https://stats.stackexchange.com/questions/661202/scaling-coordinates-latitude-and-longitude-in-a-linear-model-for-partial-regre</guid>
      <pubDate>Mon, 10 Feb 2025 22:44:18 GMT</pubDate>
    </item>
    <item>
      <title>危险功能的直觉在生存功能的对数方面</title>
      <link>https://stats.stackexchange.com/questions/661201/intuition-for-hazard-function-in-terms-of-logarithm-of-survival-function</link>
      <description><![CDATA[  this 帖子有助于解释危险功能的直觉。在其中，危险功能被解释为
在
其中 $ f（t）$ 是pdf， $ s（t）$ 是生存功能。这导致身份
  $$ h（t）=  -  \ frac {d} {dt} {dt} \ log（s（t））。 $$  
是否有任何直觉可以从中获得？危险功能是时间t的瞬时死亡率，鉴于患者在时间t中存活。令我惊讶的是，某种程度上等于生存函数对数转换的变化速率。]]></description>
      <guid>https://stats.stackexchange.com/questions/661201/intuition-for-hazard-function-in-terms-of-logarithm-of-survival-function</guid>
      <pubDate>Mon, 10 Feb 2025 22:12:18 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯统计，100页的机器学习书籍</title>
      <link>https://stats.stackexchange.com/questions/661200/bayesian-statistics-the-100-page-machine-learning-book</link>
      <description><![CDATA[我有一个关于本书中的贝叶斯统计数据的问题，“ 100页机器学习书籍的Andriy Burkov。问题是关于贝叶斯统计的。我有一本书中的屏幕截图，其中包含相关信息。这本书可以在这里免费找到： http://themlbook.com/wiki/wiki/wiki/doku.php  
    
 关于红线： 
为什么他替换 $ p（\ theta = \ hat {\ theta}）$ 用 $ \ frac { 1} {n} p（\ theta = \ hat {\ theta} | x = x）$ ？他在这里是什么意思？我不明白的是：当您计算出 $ p（\ theta = \ hat {\ theta} | x = x_1）$ 时，您只有&lt; span class =“数学 - 容器”&gt; $ p（\ theta = \ hat {\ theta} | x = x）$  for  $ x_1 $ ，不是其他吗？因此，如何通过所有 $ x的$ 获得 $ \ frac {1} {n} p（\ theta p（\ theta） = \ hat {\ theta} | x = x）$ ？
我在另一本书中看了看，他们这样做了：计算出的 $ p（\ theta = \ hat {\ theta} | x_1）$ ，然后，他们使用此值来计算 $ p（\ theta = \ hat {\ theta} | x_1，x_1，x_2）$ ，然后他们用它来计算 $ p（\ theta = \ hat {\ theta} | x_1，x_2，x_3）$ 。这是他所做的，但在其他符号中？我不明白他的平均值？
 关于绿色框： 
表达式是否与 $ \ text {arg max} _ \ theta p（\ theta = \ hat {\ theta} | x_1，x_2，x_2，x_3，\ ldots ，x_n）$ ？如果没有，这不是更自然的表达方式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661200/bayesian-statistics-the-100-page-machine-learning-book</guid>
      <pubDate>Mon, 10 Feb 2025 22:04:55 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证和固定套件</title>
      <link>https://stats.stackexchange.com/questions/661198/the-use-of-cross-validation-and-a-hold-out-set</link>
      <description><![CDATA[我一直在考虑使用交叉验证和固定集，但我真的没有看到随机选择的保持测试集的使用。不过，我不得不说，当没有随机进行固定时，它被用来评估特殊特征，例如一个超级样本，我完全看到了它的目的。
我的意思是，当我使用交叉验证来做出建模决策时，我已经解决了过度拟合的问题，即使它可以使用所有数据，它可以引入数据集中的一些偏见，但我也将获得。通过不故意减少培训数据而进行预测能力。
尽管如此，我到处都在看到每个人都从培训数据中随机分开测试集。不要分开随机测试集并使用：是不可接受的

 EDA的整个数据集
变量选择的交叉验证
用于模型选择和超参数优化的嵌套交叉验证
重复交叉验证的最终模型的估计误差
将模型运送到使用整个数据集进行训练的生产中。
]]></description>
      <guid>https://stats.stackexchange.com/questions/661198/the-use-of-cross-validation-and-a-hold-out-set</guid>
      <pubDate>Mon, 10 Feb 2025 21:29:23 GMT</pubDate>
    </item>
    <item>
      <title>应用T-SNE时，您是否知道有此行为的数据集吗？</title>
      <link>https://stats.stackexchange.com/questions/661194/do-you-know-of-any-dataset-with-this-behavior-when-applying-t-sne</link>
      <description><![CDATA[    
嘿，伙计们！
我目前正在寻找一个数据集，该数据集在应用T-SNE时表现出此行为。 T-SNE是一种降低算法，有时可以分开最初属于同一群集的数据点。
在本文的图9中（ https://arxiv.org/abs/2009.01512 ） ，您可以完全看到这种现象。作者提出了一种拓扑维度降低算法（TOPOMAP），该算法使簇保持完整，并将其与T-SNE进行比较。很明显，T-SNE最终分开应该保留在一个群集中的点。
您曾经遇到过这种现象吗？如果是这样，您可以共享数据集及其上下文吗？我正在研究一个本科研究项目，并非常感谢任何帮助。
谢谢您的时间和关注！]]></description>
      <guid>https://stats.stackexchange.com/questions/661194/do-you-know-of-any-dataset-with-this-behavior-when-applying-t-sne</guid>
      <pubDate>Mon, 10 Feb 2025 20:33:58 GMT</pubDate>
    </item>
    <item>
      <title>在这种简单的语言建模情况下，数学概率如何出现？</title>
      <link>https://stats.stackexchange.com/questions/661193/how-does-the-log-probabilities-mathematically-appear-in-this-simple-case-of-lang</link>
      <description><![CDATA[在（又名 word2vec ），说明：
    
一个人如何得出这个公式？如果一个人遍历每个word  $ \ pm c $  words; （即使用单词和周围。）并计算与周围单词发生的单词的关节概率，可以写：
  \ begin {align}
\ prod_ {-c \ leq j \ leq c，j \ neq 0} p（w_ {i+j} | w_i）
\ end {align}  
，总而言之，我们添加了所有单词
  \ begin {align}
1 = \ sum_ {i = 0} \ prod_ {-c \ leq j \ leq c，j \ neq 0} p（w_ {i+j} | w_i）
\ end {align}  
用日志概率替换，因为 $ p（i）$ 总是大于 $ \ log p（ i）它的$ ，为负；然后我们可以说：
  \ begin {align}
0 \ geq \ sum_ {i = 0} \ sum_ {-c \ leq j \ leq c，j \ neq 0} \ log p（w_ {i+j} | w_i）
\ end {align}  
人们想最大化这一点是有道理的。但是我不确定这种推理是正确的，还是背后有不同的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/661193/how-does-the-log-probabilities-mathematically-appear-in-this-simple-case-of-lang</guid>
      <pubDate>Mon, 10 Feb 2025 20:16:48 GMT</pubDate>
    </item>
    <item>
      <title>使用HyperOPT FMIN进行LightGBM超参数调整</title>
      <link>https://stats.stackexchange.com/questions/661191/lightgbm-hyperparameter-tuning-using-hyperopt-fmin</link>
      <description><![CDATA[我正在遇到一个多分类问题。我正在尝试使用HyperOPT FMIN执行超参数调整。但是，我不知道我应该在搜索空间中使用什么合适的值，以及我应该如何解决此问题。我是否先执行随机搜索，然后在该区域进行搜索？每个搜索空间的价值应该是什么？我的数据集为6000行，我有大约200个变量（如果执行一个热编码，则为400个）。我的目标变量有4个级别
 来自sklearn.model_selection导入随机搜索
导入numpy作为NP
从HyperOPT Import Fmin，TPE，HP，status_ok，试验
导入LightGBM作为LGB
来自sklearn.model_selection导入train_test_split
来自Sklearn.metrics导入精度_score
从hyperopt.pyll.base导入范围

＃定义随机搜索的参数分布
param_dist = {
    &#39;num_leaves&#39;：范围（20，150），
    &#39;Learning_rate&#39;：np.linspace（0.01，0.3，10），
    &#39;n_estimators&#39;：范围（100，1000，100），
    &#39;min_child_weight&#39;：np.linspace（0.01，10，10），
    “子样本”：np.linspace（0.5，1.0，6），
    &#39;colsample_bytree&#39;：np.linspace（0.5，1.0，6），
    &#39;reg_alpha&#39;：np.linspace（0.0，1.0，10），
    &#39;reg_lambda&#39;：np.linspace（0.0、1.0、10）
}

＃创建LightGBM分类器
model = lgb.lgbmclassifier（objective =&#39;多类&#39;，num_class = len（set（y）））

＃执行随机搜索
Random_search = RandomizedSearchCV（
    估算器=模型，
    param_distributions = param_dist，
    n_iter = 20，＃采样的参数设置数量
    评分=&#39;准确性&#39;，
    CV = 3，＃交叉验证分裂策略
    Random_State = 42，
    n_jobs = -1＃使用所有可用内核
）

＃适合随机搜索
Random_search.fit（x_train，y_train）

＃获取最佳参数
best_params = rando_search.best_params_
打印（使用随机搜索搜索发现的最佳超参数：＆quot; best_params）

＃定义围绕最佳参数的搜索空间
search_space = {
    &#39;num_leaves&#39;：scope.int（hp.quniform（&#39;num_leaves&#39;，best_params [&#39;num_leaves&#39;]  -  10，best_params [&#39;num_leaves&#39;] + 10，1），），），），），
    &#39;Learning_rate&#39;：hp.Uniform（&#39;Learning_rate&#39;，best_params [&#39;Learning_rate&#39;] * 0.8，best_params [&#39;Learning_rate&#39;] * 1.2）， * 1.2），
    &#39;n_estimators&#39;：scope.int（hp.quuniform（&#39;n_estimators&#39;，best_params [&#39;n_estimators&#39;]  -  100，best_params [&#39;n_estimators&#39;] + 100，10），），
    &#39;min_child_weight&#39;：hp.ribour（&#39;min_child_weight&#39;，best_params [&#39;min_child_weight&#39;] * 0.8，best_params [&#39;min_child_weight&#39;] * 1.2），
    &#39;subsample&#39;：hp. rustom（&#39;subsample&#39;，max（0.5，best_params [&#39;subsampe&#39;] * 0.8），min（1.0，best_params [&#39;subsampe&#39;] * 1.2）），），），
    &#39;colsample_bytree&#39;：hp.uliform（&#39;colsample_bytree&#39;，max（0.5，best_params [&#39;colsample_bytree&#39;] * 0.8），min（1.0，best_params [&#39;colsample_bytree&#39;] * 1.2），），
    &#39;reg_alpha&#39;：hp.riborm（&#39;reg_alpha&#39;，best_params [&#39;reg_alpha&#39;] * 0.8，best_params [&#39;reg_alpha&#39;] * 1.2），
    &#39;reg_lambda&#39;：hp.Uniform（&#39;reg_lambda&#39;，best_params [&#39;reg_lambda&#39;] * 0.8，best_params [&#39;reg_lambda&#39;] * 1.2）
}

＃定义目标功能
DEF目标（参数）：
    型号= lgb.lgbmclassifier（objective =&#39;多类&#39;，num_class = len（set（y_train）），** params）
    得分= cross_val_score（型号，x_train，y_train，cv = 3，评分=&#39;cercucy&#39;）。平均（）
    返回{&#39;损失&#39;：-score，&#39;状态&#39;：status_ok}

＃运行优化
试验=试验（）
best_hyperparams = fmin（fn =客观，
                        space = search_space，
                        algo = tpe.suggest，
                        max_evals = 50，＃根据您的需求调整评估次数
                        试验=试验，
                        rstate = np.random.default_rng（42））

打印（使用Hyperopt找到的最佳超参数：＆quot; best_hyperparams）
``
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661191/lightgbm-hyperparameter-tuning-using-hyperopt-fmin</guid>
      <pubDate>Mon, 10 Feb 2025 19:47:00 GMT</pubDate>
    </item>
    <item>
      <title>分析分位数残差分析回归拟合</title>
      <link>https://stats.stackexchange.com/questions/661190/analysing-regression-fit-with-quantile-residual</link>
      <description><![CDATA[我是指基于估计的 Quantile Restuals  分析回归方程的拟合的论文。
  http://www.statsci.orgg y&gt;  
替代链接：
  nofollow noreferrer“&gt; https://www.researchgate.net/publiation/publiation __net/publiation/2647151 
在第3节中指出，
  如果正确指定了回归参数/方程，分数残差的分布会收敛到标准正态分布。   
以下是其定义的快照
    
然而，鉴于分数残差基于正常分布的逆CDF ”容器“&gt; $ f $ ，不是估计分数残差 始终 be    正态分布至关重要的如果回归方程的响应变量是连续的，无论是否正确指定了回归方程？
任何洞察力都会非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/661190/analysing-regression-fit-with-quantile-residual</guid>
      <pubDate>Mon, 10 Feb 2025 19:24:06 GMT</pubDate>
    </item>
    <item>
      <title>为不同的交互拟合单独的LMM</title>
      <link>https://stats.stackexchange.com/questions/661189/fitting-separate-lmms-for-different-interactions</link>
      <description><![CDATA[我使用线性混合模型（LMM）分析了主要临床范围（DV）的主要临床量表的纵向变化。我的完整模型包括：
  dv〜time ∗因子1 ∗因子2+协变量+（1 riD）
 
其中：
  dv =抑郁症状的临床量表，
时间=重复测量点，
因子1 =一个分类变量区分两个亚组（条件1 vs条件2），
因子2 =与临床特征相关的二元分类（Group1 vs Group2），
id =对个别参与者的随机效果。
 
三向相互作用时间：factor1：factor2 很重要。
为了更好地了解每个因素的贡献，我分别拟合三个LMM，每个LMM都对不同的相互作用进行建模：
 基线模型：
  dv〜time+协变量+（1月）
 
  factor1相互作用的模型：
  dv〜time ∗因子1+协变量+（1月ID）
 
  factor2相互作用的模型：
  dv〜time ∗因子2+协变量+（1月ID）
 
考虑到完整模型中的三向相互作用很重要，这种方法是否过于普遍？
具体来说，运行单独的模型是否会过分简化解释？
是否有更好的方法可以在保留完整的模型结构的同时分解重要的三向相互作用？
对解释LMM中三向互动的最佳实践的任何见解将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661189/fitting-separate-lmms-for-different-interactions</guid>
      <pubDate>Mon, 10 Feb 2025 19:20:04 GMT</pubDate>
    </item>
    <item>
      <title>GLMM（LME4包）中极低的R²m，无线性趋势怀疑</title>
      <link>https://stats.stackexchange.com/questions/661188/extremely-low-r%c2%b2m-in-glmm-lme4-package-with-a-non-linear-trend-suspected</link>
      <description><![CDATA[上下文和数据集：
我正在使用LME4软件包的GLMER功能的广义线性混合模型（GLMM）来建模“ Mean_cover_of_aquatic_plants”随着时间的流逝（时间=年度抽样，有37年的样本）在人造湖泊中。
响应变量是Mean_cover_of_aquatic_plant，它是一个百分比值，是通过将所有水生植物在同一湖中不同子图中的封面进行求和，然后除以子图的数量。解释性变量是年份，随机效应是katervervation_site（即不同的保护_ site之间的可变性）。
   
型号设置：
  glmer（mean_cover_of_aquatic_plants〜Time +（1 | kedervation_site），family = gaussian（link =＆quos; log＆quot; log＆quot; log＆quot; data = lake_data）
 
我正在使用高斯家族使用日志链接函数，因为我怀疑时间和均值_cover_of_aquatic_plants之间的非线性关系。
 问题： 
r²m（边际R²）值极低，结果始终低于0.001。
  print（r2_values）
             R2M R2C
[1，] 0.001076443 0.2087605
 
我怀疑低R²m表示该模型没有捕获预期趋势，即使我应用了日志变换来处理数据中可疑的非线性（ logistic ？）。或者，即使在同一年之内的变异性如此之高，以至于导致此输出？
我已经检查了模型拟合，探索了替代的随机效应结构（例如随机斜率），并确保对数链接适用于对非线性趋势进行建模。
我已经考虑了模型中的过度分散，但这似乎不是一个问题。
我已经测试了其他潜在的解释变量，但时间是我分析中感兴趣的主要因素。
    ]]></description>
      <guid>https://stats.stackexchange.com/questions/661188/extremely-low-r%c2%b2m-in-glmm-lme4-package-with-a-non-linear-trend-suspected</guid>
      <pubDate>Mon, 10 Feb 2025 19:18:13 GMT</pubDate>
    </item>
    <item>
      <title>将数据集分为培训和测试集方法</title>
      <link>https://stats.stackexchange.com/questions/661187/split-a-dataset-into-training-and-testset-method</link>
      <description><![CDATA[我创建了一个用于培训神经网络的二进制分类问题的数据集。培训数据来自与特定环境（例如2D地图环境）有关的集合。对于测试案例，我考虑了来自同一2D地图的数据点，但培训集中不存在数据点。
这将是有效的测试用例设计？
任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/661187/split-a-dataset-into-training-and-testset-method</guid>
      <pubDate>Mon, 10 Feb 2025 19:17:01 GMT</pubDate>
    </item>
    <item>
      <title>如何解释队列研究中置信区间宽度的差异和无与伦比的病例对照研究？</title>
      <link>https://stats.stackexchange.com/questions/661186/how-to-explain-the-difference-in-the-width-of-confidence-interval-in-cohort-stud</link>
      <description><![CDATA[ i有一项队列研究的数据，我称之为研究1。在这项研究中，死亡是结果，糖尿病（存在或不存在）是暴露，年龄和性别是协变量。我使用的回归公式是：
 死亡〜糖尿病 +性别 +年龄，家庭=二项式（link =; logit; quot;
接下来，我从队列研究中选择了所有病例（死亡），然后选择了相等数量的对照组，创建了我称为研究2的无与伦比的病例对照研究。对于研究2，我使用了相同的回归模型如研究1。
研究1和研究2的所有系数（糖尿病，性别和年龄）的估计非常相似，除了拦截。但是，研究2中系数的置信区间（CI）比研究1中的系数宽。如何使用数学公式来解释这种差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/661186/how-to-explain-the-difference-in-the-width-of-confidence-interval-in-cohort-stud</guid>
      <pubDate>Mon, 10 Feb 2025 19:10:11 GMT</pubDate>
    </item>
    <item>
      <title>拉普拉斯分布的后部带有拉普拉斯先验</title>
      <link>https://stats.stackexchange.com/questions/661183/posterior-of-a-laplace-distribution-with-a-laplace-prior</link>
      <description><![CDATA[我正在练习我的研究生统计课程中的一些概念，并试图得出平方损耗函数的贝叶斯规则 $ l（\ theta，a）=（\ theta-a） ^2 $ 。我有一个带有位置参数 $ \ theta $ 和单位刻度（即 $ x \ sim \ sim \ text {laplace} { （\ theta，1）$ ）和可能性 $ f（x; \ theta）= \ frac {\ exp \ \ exp \ { -  \ sum_ {i = 1}^n | x_i- \ theta | \}}} {2^n} $ 。此外，我有一个laplace先验，位于位置 $ \ eta $ 和单位刻度，即 $ \ pi_ \ theta（\ theta） = \ frac {\ exp \ { -  | \ theta- \ eta | \}}} {2} $ 。
首先，我不完全确定该计算的方法，但我从衍生后验，如下所示：
 $$ \ pi _ {\ theta | x}（\ theta | x）\ propto \ exp \ exp \ big \ big \ { -  \ sum_ {i = 1}^n | x_i--- \ \ theta | -  | \ theta- \ eta | \ big \} $$ 
但是我不知道如何简化我的表达。如果它们都是正常的分布，我知道要完成正方形，并用 $ \ theta $ 来写出我的表达。但是，在这种情况下，我对模量标志感到困惑。我以前从未使用过拉普拉斯（Laplace）发行版，因此对任何帮助都将不胜感激。谢谢！
编辑：要回答贝叶斯规则的问题，我认为我必须找到一个 $ a $ 才能最小化
 $$ \ MATHBB {e} [l（\ theta，a）| x = x] \ propto \ int \ int _ { -  \ infty}^\ infty（\ theta-a）^2 \ exp \ big \ { -  \ sum_ {i = 1}^n | x_i- \ theta |  -  | \ theta- \ eTa | \ big \} d \ theta $$  
但是，如果没有更多有关我的后部的信息，这变得很困难。]]></description>
      <guid>https://stats.stackexchange.com/questions/661183/posterior-of-a-laplace-distribution-with-a-laplace-prior</guid>
      <pubDate>Mon, 10 Feb 2025 16:30:10 GMT</pubDate>
    </item>
    <item>
      <title>分层COX模型：为什么对重采样数据的C索引比明显的C索引更好（Tidymodels和审查的R软件包）？</title>
      <link>https://stats.stackexchange.com/questions/661185/stratified-cox-model-why-is-c-index-on-resampled-data-better-than-apparent-c-in</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661185/stratified-cox-model-why-is-c-index-on-resampled-data-better-than-apparent-c-in</guid>
      <pubDate>Mon, 10 Feb 2025 07:53:22 GMT</pubDate>
    </item>
    </channel>
</rss>