<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 13 Nov 2024 03:21:54 GMT</lastBuildDate>
    <item>
      <title>在 R 中模拟 rstpm2 模型随时间变化的协变量</title>
      <link>https://stats.stackexchange.com/questions/657178/simulating-time-varying-covariates-for-a-rstpm2-model-in-r</link>
      <description><![CDATA[我正在尝试生成随时间变化的协变量来运行模拟。问题是，对于灵活的参数生存模型，估计误差非常大。我不确定为什么会发生这种情况。我的随时间变化协变量生成过程是否正确？我在这里做错了什么？
gendata &lt;- function(n){

n = n # 患者人数
lambda = 0.001 # 威布尔尺度参数（基线风险）
gamma = 1.5 # 威布尔形状参数（基线风险）
time_max = 60 # 最大随访时间
alpha = 0.1 # 真实系数
beta = 0.2 # 空间系数
sigma = 0.5 # 测量误差的标准偏差
censoring_rate = 0.25

times &lt;- numeric(n) 
event &lt;- numeric(n)
event_times &lt;- numeric(n)
covariate_trajectory &lt;- list()

beta0 &lt;- rnorm(n, 0, 1) 
beta1 &lt;- rnorm(n, 1, 0.5)
X2 = rnorm(n, 0, 1) # 随机地理标记

# 使用指数分布生成审查时间
censoring_times &lt;- -log(runif(n)) / censoring_rate

for (i in 1:n) {

# 定义随时间变化的协变量的函数 W(t) = beta0 + beta1 * t
covariate_function &lt;- function(t) {
beta0[i] + beta1[i] * t
}

# 使用威布尔基线风险的随时间变化的协变量和空间效应的风险函数
hazard_function &lt;- function(t) {
W_t &lt;- covariate_function(t)
h_t &lt;- lambda * gamma * t^(gamma - 1) * exp(alpha * W_t + beta * X2[i])
return(h_t)
}

# 累积风险函数（数值积分）
cumulative_hazard_function &lt;- function(t) {
integrate(hazard_function, lower = 0, upper = t)$value
}

u &lt;- runif(1)

# 定义寻根目标函数（求解生存时间）
target_function &lt;- function(t) {
cumulative_hazard_function(t) + log(u)
}

# 使用 uniroot 求解生存时间（寻根方法）
f_lower &lt;- target_function(0)
f_upper &lt;- target_function(time_max)

if (f_lower * f_upper &lt; 0) {
# 仅在确认相反符号时运行 uniroot
sol &lt;- uniroot(target_function, lower = 0, upper = time_max, tol = 1e-8)
times[i] &lt;- sol$root 
} else {
# 使用近似方法细化 times[i]
times[i] &lt;- max(time_max, -f_lower / (f_upper - f_lower) * time_max)
}

event_times[i] &lt;- min(times[i], censoring_times[i])

event[i] &lt;- ifelse(times[i] &lt; censoring_times[i], 1, 0)

# 生成具有测量误差的协变量测量值
measurement_times &lt;- seq(0.001, times[i], length.out = 10) 
covariate_values &lt;- covariate_function(measurement_times) + rnorm(length(measurement_times), 0, sigma)

# 存储此人的协变量测量值
covariate_trajectory[[i]] &lt;- data.frame(time = measure_times, W_t = covariate_values)

}
survdata = data.frame(id = 1:n, time = times, event = event, X2 = X2)

result = list(survival_data = survdata, covariate_trajectory = covariate_trajectory)

# 提取生存数据和协变量轨迹
survivor_data &lt;- result$survival_data
covariate_trajectory &lt;- result$covariate_trajectory

combined_data &lt;- do.call(rbind, lapply(1:n, function(i) {
# 获取个体的协变量轨迹
cov_trajectory &lt;- covariate_trajectory[[i]]

# 将生存时间和事件状态添加到协变量轨迹中
cov_trajectory$id &lt;- i # 分配受试者 ID
cov_trajectory$survival_time &lt;- survivor_data$time[i] # 添加生存时间

cov_trajectory$event &lt;- 0 # 用 0 初始化事件列
cov_trajectory$event[nrow(cov_trajectory)] &lt;- survivor_data$event[i] # 添加事件状态

return(cov_trajectory)
}))

names(combined_data) &lt;- c(&#39;survtime&#39;, &#39;X1&#39;, &#39;id&#39;, &#39;survival_time&#39;, &#39;event&#39;)

var2 = as.data.frame(X2)
var2 = cbind(1:nrow(var2), var2)
colnames(var2) &lt;- c(&#39;id&#39;, &#39;X2&#39;)

simdata = combined_data %&gt;% left_join(var2, by = &#39;id&#39;) 

return(simdata)
}

simd2 = gendata(1000)

s = stpm2(Surv(survtime, event) ~ X1+X2, tvc = list(X1 = 2), data = simd2, df = 2)


系数结果为
系数：
X1 -0.5818367
X2 0.4652501
其中 |X1 - 0.1| = 0.68
和 |X2 - 0.2| = 0.36
这些偏差应该低得多，表明数据生成过程或模型 rstpm2 本身存在问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/657178/simulating-time-varying-covariates-for-a-rstpm2-model-in-r</guid>
      <pubDate>Wed, 13 Nov 2024 03:12:44 GMT</pubDate>
    </item>
    <item>
      <title>夏皮罗-威尔克与正态分布的箱线图</title>
      <link>https://stats.stackexchange.com/questions/657176/shapiro-wilk-vs-box-plot-for-normality-distribution</link>
      <description><![CDATA[我运行了 Shapiro-Wilk 正态性检验 (n=8)，以决定是否使用参数或非参数检验进行显著性检验。结果表明我的数据呈正态分布 (p &gt;0.05)，但箱线图的目视检查并未表明呈正态分布。样本量很小，所以我想知道是否是因为这个原因，但现在我不确定是否要继续进行重复测量方差分析或 Friedman 检验。]]></description>
      <guid>https://stats.stackexchange.com/questions/657176/shapiro-wilk-vs-box-plot-for-normality-distribution</guid>
      <pubDate>Wed, 13 Nov 2024 02:08:07 GMT</pubDate>
    </item>
    <item>
      <title>模型堆叠训练测试拆分方法</title>
      <link>https://stats.stackexchange.com/questions/657175/model-stacking-train-test-split-methdods</link>
      <description><![CDATA[我试图验证我的流程，即我如何参与二元分类的模型堆叠。假设我有两个模型作为我的基础模型，模型 A 和 B 都具有不同的分类器，而模型 C 是我的元模型。
我的步骤如下。

将数据拆分为训练集和测试集
将我的测试集拆分为验证集（用于我的元模型训练）和最终测试集。
使用 CV 在训练集上训练我的基础模型 A 和 B。在我的最终测试集上返回基础模型的测试统计数据。
使用第 2 部分中在验证集上的基础模型中生成的概率训练我的元模型。在最终测试集上返回元模型的测试统计数据。
比较模型 A、B、C 的测试结果。
]]></description>
      <guid>https://stats.stackexchange.com/questions/657175/model-stacking-train-test-split-methdods</guid>
      <pubDate>Wed, 13 Nov 2024 01:58:42 GMT</pubDate>
    </item>
    <item>
      <title>当响应变量和解释变量都是自相关的时，如何指定回归模型？</title>
      <link>https://stats.stackexchange.com/questions/657174/how-do-you-specify-a-regression-model-when-both-the-response-and-explanatory-var</link>
      <description><![CDATA[我有两组数据点：

第一组中的每个数据点 (y_t) 代表未来十年月回报数据的年化回报，即，这是前瞻性数据，因此我的最后一个数据点来自 2014 年 10 月
第二组中的每个数据点 (x_t) 代表过去十年的月平均值，即，这是回顾性数据，因此我有截至 2024 年上个月的数据

第二组数据是一个经济指标，许多人用它来描述股市按历史标准是昂贵还是便宜，我想尝试用它来预测十年的年化回报。从经验上看，存在明显的线性关系，但这两个时间序列的性质让我怀疑如何正确指定我的模型。
鉴于响应变量和解释变量都依赖于如此多的相邻数据，并且基本 OLS 的残差表明存在自相关性（经验和 Durbin-Watson），我不知道下一步该怎么做。一阶差分增加了平稳性，这由显著的 Dickey-Fuller 检验统计量证明，但我不确定是否还需要为我的响应变量和解释变量添加滞后变量，以及考虑到创建数据集的前向和后向范围，这些滞后应该延伸到多远。 ACF 和 PACF 图表强烈暗示我需要多个滞后变量，我已经开始阅读如何实施 Cochrane-Orcutt 程序，但在将互联网上的学术笔记翻译并应用到适用于我的场景的 Python 代码时遇到了困难。
在偶然发现一篇有点相关的帖子（在 R 中校正简单线性回归中的自相关）后，深入探讨了误差调整与模型更改的利弊，我想知道我一直在追求的转变是否完全必要。使用异方差和自相关稳健标准误差是否能满足预测的要求，或者模型错误指定导致的无效系数是否更有可能使预测失去信心？
如果有人遇到过这个问题并且有任何我可能忽略的阅读建议或 Python 包，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657174/how-do-you-specify-a-regression-model-when-both-the-response-and-explanatory-var</guid>
      <pubDate>Wed, 13 Nov 2024 01:34:22 GMT</pubDate>
    </item>
    <item>
      <title>重复测量方差分析/线性混合效应模型和缺失数据</title>
      <link>https://stats.stackexchange.com/questions/657171/repeated-measures-anova-linear-mixed-effects-model-and-missing-data</link>
      <description><![CDATA[我正在开展一项研究，测量 4 个时间点的幸福感，旨在确定整体幸福感是否有所增加。四个时间点所需的样本量为 24，三个时间点所需的样本量为 28。但是，我需要帮助来留住参与者。以下是详细情况：
调查 1：24 名参与者
调查 2：36 名参与者（调查 1 中有 8 名参与者）
调查 3：60 名参与者（调查 2 中有 24 名参与者，调查 1 中没有参与者）
调查 4：100 名参与者（与之前的调查有部分重叠）
为了分析数据，我只考虑那些至少完成了调查 2、3 或 4 中的两项调查的人。结果有 36 名参与者，大约 20% 的数据缺失。由于缺失数据超过 50%，我已排除调查 1 的参与者。
我的问题是：
仅包括完成调查 2-4 中至少两项调查的参与者是否具有统计意义？
我应该估算缺失数据并使用重复测量方差分析吗？还是线性混合效应模型可以更好地处理缺失数据？
我的模型很简单：
幸福感得分 - 因变量，时间 - 自变量。
任何建议都将不胜感激！我感谢您提供的任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/657171/repeated-measures-anova-linear-mixed-effects-model-and-missing-data</guid>
      <pubDate>Tue, 12 Nov 2024 23:06:25 GMT</pubDate>
    </item>
    <item>
      <title>加权 RMS 差异是否有一个普遍接受的定义？</title>
      <link>https://stats.stackexchange.com/questions/657170/is-there-a-commonly-accepted-definition-for-weighted-rms-difference</link>
      <description><![CDATA[假设有两个数据集 $x$ 和 $y$，均包含 $n$ 个数据点：$\{x_1,...,x_n\}$ 和 $\{y_1,...,y_n\}$，两个数据集之间最广泛认可的差异度量之一是它们的 RMS 差异，其定义很简单：
$$\mathbf{RMSD}=\sqrt{\frac{1}{n}\sum_{i=1}^n{(x_i-y_i)^2}}$$
如果已知某些数据点对对于由于领域特定的原因，可以通过将每对与权重关联起来来表示：$\{w_1,...,w_n\}$，其中 $w_i$ 为正实数。
因此，在这种情况下，人们将使用加权 RMSD 作为差异度量。但据我所知，wRMSD 没有普遍接受的定义，有两个合理的候选者：

加权差异的 RMS：$\sqrt{\frac{1}{n}\sum_{i=1}^n{[w_i(x_i-y_i)]^2}}$
加权平方差的均根：$\sqrt{\frac{1}{n}\sum_{i=1}^n{w_i(x_i-y_i)^2}}$

我的问题是，这两个公式是否普遍被接受为“加权 RMSD”或以其他名称命名？如果不是，那么这两个公式中的哪一个更适合用作两个数据集之间的差异统计量？]]></description>
      <guid>https://stats.stackexchange.com/questions/657170/is-there-a-commonly-accepted-definition-for-weighted-rms-difference</guid>
      <pubDate>Tue, 12 Nov 2024 22:35:28 GMT</pubDate>
    </item>
    <item>
      <title>模型堆叠的复杂性</title>
      <link>https://stats.stackexchange.com/questions/657169/model-stacking-intricacies</link>
      <description><![CDATA[我尝试使用模型堆叠方法，在训练集上训练基础模型后收集基础模型的结果。
但是，我发现自己有一个问题，那就是当我在验证集上训练元模型时，是否应该在基础模型训练中包含使用的特征。
我看到的优点是元模型可以使用特征以基础模型未看到的方式“调整”基础模型的结果，但缺点是通过基本上重新引入我在基础模型训练期间所做的相同信号而引入噪音。此外，我使用简单的对数回归作为我的元模型。
最后，如果我还打算对二元分类进行建模以尽量减少负对数损失，那么使用基础模型的概率预测或纯分类预测（我的数据集属于哪个类别）是否更有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/657169/model-stacking-intricacies</guid>
      <pubDate>Tue, 12 Nov 2024 22:29:55 GMT</pubDate>
    </item>
    <item>
      <title>当比率有意义时，对治疗组与对照组进行统计比较</title>
      <link>https://stats.stackexchange.com/questions/657168/statistical-comparison-of-treatment-vs-control-when-ratio-is-meaningful</link>
      <description><![CDATA[我遇到了一个统计问题，不知道您是否愿意帮助我。我做过一个实验，测量了植物叶片中的荧光信号（来自标记蛋白），我想找出激素处理是否会使该信号与对照相比增强。我已进行了 4 次运行，每株植物有 3 个相等的叶片样本（rep），但不知何故实验条件（溶液年龄、机器、植物批次等）导致每次运行中获得的值之间存在相当大的差异。请参阅下面的一些数据；请注意，对照和处理条件实际上是不同的植物，因此数据不成对：
运行处理信号表示
1 对照 4.27 1
1 对照 3.85 2
1 对照 3.93 3
1 激素 5.14 1
1 激素 5.37 2
1 激素 4.13 3
2 对照 4.94 1
2 对照 4.43 2
2 对照 6.04 3
2 激素 9.42 1
2 激素 7.98 2
2 激素 5.95 3
3 对照 20.26 1
3 对照 19.98 2
3 对照 16.46 3
3 激素 24.06 1
3 激素 18.78 2
3 激素 17.56 3
4 对照 15.93 1
4 对照 12.99 2
4 对照12.71 3
4 激素 17.28 1
4 激素 18.39 2
4 激素 17.76 3

如您所见，实验运行 1 和 2 中的信号值与 3 和 4 有很大不同。然而，在运行中，激素治疗似乎一直在增加信号。我们从这四个实验运行的其他数据中看到了非常相似的结果。
我想对这两种治疗进行统计比较，但仅仅进行成对测试不会有太大帮助。我可以尝试控制实验运行引起的信号变化，方法是将激素值除以每次运行的对照值的平均值，以获得平均比率：
运行治疗平均值_信号
1 对照 1.00
1 激素 1.21
2 对照 1.00
2 激素 1.52
3 对照 1.00
3 激素 1.07
4 对照 1.00
4 激素 1.28

...但是，我正在将平均比率与对照进行比较...所有值都是 1.00（因此变化为零）。感觉好像我错过了什么，但我不知道是什么。任何帮助都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/657168/statistical-comparison-of-treatment-vs-control-when-ratio-is-meaningful</guid>
      <pubDate>Tue, 12 Nov 2024 22:13:15 GMT</pubDate>
    </item>
    <item>
      <title>我如何理解赌徒谬误？[重复]</title>
      <link>https://stats.stackexchange.com/questions/657166/how-can-i-understand-the-gamblers-fallacy</link>
      <description><![CDATA[假设你掷骰子 500 次。在这 500 次中你不可能永远掷出 6，不是吗？
但同时，每次掷骰子都是独立的，平均掷出 6 的概率只有 1/6。
那么... 认为第 501 次掷骰子“不太可能”不是 6 是对还是错？我只是很难解开这个谜团。]]></description>
      <guid>https://stats.stackexchange.com/questions/657166/how-can-i-understand-the-gamblers-fallacy</guid>
      <pubDate>Tue, 12 Nov 2024 20:43:54 GMT</pubDate>
    </item>
    <item>
      <title>进行“最大 p 值估计”而不是最大似然估计</title>
      <link>https://stats.stackexchange.com/questions/657156/doing-maximum-p-value-estimation-instead-of-maximum-likelihood</link>
      <description><![CDATA[每当我们进行最大似然估计时，我们都会寻找最大化数据概率密度的参数。另一方面，当我们计算 p 值时，我们会查看获得至少与数据一样极端的事物的尾部概率。这种不匹配通常会导致数据在其自己的 MLE 参数上无法通过假设检验。
是否有一种技术可以最大化 p 值而不是最大化似然？这意味着我们正在寻找使我们的样本“最典型”的参数而不是最有可能。
当然，有很多不同的方法可以做到这一点 - 不同的尾部概率、检验统计量等。但任何直接最大化从样本的某些充分统计量中得出的尾部概率（而不仅仅是最大化密度）的基本方向都会很有趣。
例如，假设我们从 $[0, \theta]$ 均匀地抽取一个 $X$，并且我们想要估计 $\theta$。MLE 只是 $\hat \theta = X$。但是，假设我们使用双侧假设检验，以 $\hat theta$ 的值作为零假设，则 $X$ 是一个极端异常值，p 值为 0。选择 $\hat \theta$ 来最大化该 p 值，则会得到 $\hat \theta = 2X$，在这种情况下也与 MVUE 一致。]]></description>
      <guid>https://stats.stackexchange.com/questions/657156/doing-maximum-p-value-estimation-instead-of-maximum-likelihood</guid>
      <pubDate>Tue, 12 Nov 2024 18:04:13 GMT</pubDate>
    </item>
    <item>
      <title>零点的中位绝对偏差</title>
      <link>https://stats.stackexchange.com/questions/657149/median-absolute-deviation-of-zero</link>
      <description><![CDATA[我使用 MAD 来衡量不同数字数据分布的分布范围，其中一些分布的 MAD 为 0。我很好奇，这怎么可能呢？如果我理解正确的话，MAD 是衡量数据集变异性的指标。我检查了一下，这些数据集的观测值并非全部相同。如果是这样的话，MAD 怎么会是零呢？
对于那些好奇的人，我在 R 中使用 mad() 函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/657149/median-absolute-deviation-of-zero</guid>
      <pubDate>Tue, 12 Nov 2024 16:39:02 GMT</pubDate>
    </item>
    <item>
      <title>连接“自由度”的两种不同含义</title>
      <link>https://stats.stackexchange.com/questions/657145/connecting-2-different-meanings-of-degree-of-freedom</link>
      <description><![CDATA[我至少听说过 2 个“自由度”的含义。

t 分布中的参数。

统计量的最终计算中可以自由变化的值的数量（例如使用 $n-1$ 来估计样本方差）。


它们之间有什么联系吗？
这个问题来自 @Glen_b 在另一个主题中的评论。他说，“当某些随机变量（例如 t 统计量）具有 t 分布时，两个 df 之间存在联系。”]]></description>
      <guid>https://stats.stackexchange.com/questions/657145/connecting-2-different-meanings-of-degree-of-freedom</guid>
      <pubDate>Tue, 12 Nov 2024 15:32:46 GMT</pubDate>
    </item>
    <item>
      <title>柯西分布数据的模型比较</title>
      <link>https://stats.stackexchange.com/questions/657142/model-comparison-on-data-with-cauchy-distribution</link>
      <description><![CDATA[我感兴趣的是确定状态位置对磁场的依赖性。状态位置是通过将缩放的柯西分布拟合到表示每个磁场值的状态的峰值来确定的。然后构建一个似然函数，该函数由各个柯西分布及其拟合中位数和伽马值组成。

其中  表示磁场函数，该函数模拟峰值位置对磁场的依赖性，并通过最大化可能性，确定  中的拟合参数。
我想测试  的三个模型。
零假设是 B 独立的：
第一个替代方案添加了一个线性项：
第二个替代方案有一个二次项而不是线性项：
我想获得零假设的 p 值，然后确定如果零假设被拒绝，哪个备选假设更适合。为此，我研究了似然比检验和威尔克斯定理，该定理将检验统计量  近似为卡方分布

但是，我不确定结果是否可信，因为我只有 46 个不同磁场值的峰值位置。
为了获得实际分布，我对由 46 对峰值位置和磁场组成的全样本进行了非参数引导替换它是在 (B, ) 处拍摄的。这导致原始数据集上的测试统计量围绕测试统计量呈近似对称分布。这是有道理的，因为我预计某些数据点的残差会比其他数据点小。
为了使引导程序工作，我认为我需要在每个磁场值下多次运行相同的测量。这样，我将获得每个磁场的峰值位置分布，可以在引导程序期间重新采样。不幸的是，我无法进行更多测量，所以我正在寻找其他选择。]]></description>
      <guid>https://stats.stackexchange.com/questions/657142/model-comparison-on-data-with-cauchy-distribution</guid>
      <pubDate>Tue, 12 Nov 2024 13:53:40 GMT</pubDate>
    </item>
    <item>
      <title>执行单样本加权 t 检验的自由度是多少</title>
      <link>https://stats.stackexchange.com/questions/657139/what-are-the-degrees-of-freedom-for-performing-a-1-sample-weighted-t-test</link>
      <description><![CDATA[我对一批生命中的死亡经历进行了 7 年的观察。我假设每年的经历与其他年份无关。对于每一年，我们都有一个预期死亡人数和一个实际死亡人数。我想对实际死亡人数与预期死亡人数的比率进行加权 t 检验，以检验 A/E 是否不等于 1。
权重表示该年经验的可信度。
我可以计算加权样本均值 x_bar，本文 (https://seismo.berkeley.edu/~kirchner/Toolkits/Toolkit_12.pdf) 解释了如何获取加权样本方差。
我还可以通过将 root(n) 替换为 root(权重平方和/权重平方和) 来计算适当的检验统计量。
我的问题与临界值和自由度有关。我不确定如何计算自由度。我的直觉是自由度应该只是 6，因为我们有 7 个独立观察值，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/657139/what-are-the-degrees-of-freedom-for-performing-a-1-sample-weighted-t-test</guid>
      <pubDate>Tue, 12 Nov 2024 12:21:52 GMT</pubDate>
    </item>
    <item>
      <title>带样条协变量的逻辑回归模型</title>
      <link>https://stats.stackexchange.com/questions/657144/logistic-regression-model-with-splines-covariates</link>
      <description><![CDATA[我正在尝试在 R 中建立一个逻辑回归模型，并使用样条函数检查某些协变量是否可能遵循非线性分布。
我使用的数据集是威斯康星州乳腺癌：
例如，我通过执行以下操作检查了 fractal_dimension_mean 列的线性
fit.splines.fractal &lt;- lrm(diagnosis ~ 
rcs(fractal_dimension_mean, 4), data=data)
print(fit.splines.fractal) # 非线性

我得到了这个：
Coef S.E. Wald Z Pr(&gt;|Z|)
截距 -2.4383 0.4609 -5.29 &lt;0.0001
fractal_dimension_mean -2.1338 0.4876 -4.38 &lt;0.0001
fractal_dimension_mean&#39; 9.3886 2.3722 3.96 &lt;0.0001 
fractal_dimension_mean&#39;&#39; -23.0268 6.2039 -3.71 0.0002

现在据我所知，这个变量的分布似乎是非线性的，因此我应该考虑将此列的复数形式添加到模型中。
所以我所做的就是创建一个函数来添加这些变量的复杂形式，并尝试对模型变量使用前向选择方法：
spline_vars &lt;- c(&quot;texture_se&quot;, &quot;fractal_dimension_mean&quot;)

# formula:
formula &lt;- as.formula(paste(
&quot;diagnosis ~&quot;, 
paste(
lapply(names(data), function(var) {
if (var %in% spline_vars) {
paste0(&quot;rcs(&quot;, var, &quot;, 4)&quot;) # rcs() for splines
} else if (var != &quot;diagnosis&quot;) {
var # 保留变量而不进行变换
}
}), 
collapse = &quot; + &quot;
)
))

model_null &lt;- glm(diagnosis ~ 1, data = data, family = binomial) # 空模型
model_full &lt;- glm(formula, data = data, family = binomial) # 完整模型

# 正向选择
model_forward &lt;- stepAIC(model_null, scope = list(lower = model_null, 
upper = model_full), direction = &quot;forward&quot;)
summary(model_forward)

现在，由于经过转换的变量的重要性，我认为模型会将它们作为协变量，但与使用不经过转换的前向选择方法相比，我获得了更大的 AIC 和对数似然。我做错了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657144/logistic-regression-model-with-splines-covariates</guid>
      <pubDate>Tue, 12 Nov 2024 12:02:15 GMT</pubDate>
    </item>
    </channel>
</rss>