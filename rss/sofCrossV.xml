<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 27 May 2024 15:16:23 GMT</lastBuildDate>
    <item>
      <title>如何从 lcmm 模型获得平均后验概率</title>
      <link>https://stats.stackexchange.com/questions/648082/how-to-obtain-the-average-posterior-probabilities-from-a-lcmm-model</link>
      <description><![CDATA[如何从 lcmm 模型对象获取平均后验概率 (APP)？我希望这个参数能够帮助我选择最合适的模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/648082/how-to-obtain-the-average-posterior-probabilities-from-a-lcmm-model</guid>
      <pubDate>Mon, 27 May 2024 15:14:10 GMT</pubDate>
    </item>
    <item>
      <title>如何比较线性回归模型与混合效应模型的性能</title>
      <link>https://stats.stackexchange.com/questions/648081/how-to-compare-the-performance-of-a-linear-regression-model-with-a-mixed-effect</link>
      <description><![CDATA[我正在分析对照小鼠和转基因 (KO) 小鼠之间的葡萄糖水平数据。我已经进行过多次这个实验（&gt; 5 个独立实验）。
为了进行分析，我执行了 3 个模型：

我只是比较各组之间的血糖水平，而不考虑体验效应 (~Group)。
在另一个例子中，我使用实验作为协变量，以考虑实验效果 (~ 实验 + 组)
最后是一个混合效应模型，其中组作为固定效应，实验作为随机效应（~Group + (1|Experiment)）。

现在，我想比较这三个模型，看看它们是否相似，并且在最好的情况下，我可以就哪个模型最好做出明智的决定。为此，我应该使用哪种指标和/或方法？我目前正在研究 AIC，但是我有点不确定该使用什么。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648081/how-to-compare-the-performance-of-a-linear-regression-model-with-a-mixed-effect</guid>
      <pubDate>Mon, 27 May 2024 15:13:04 GMT</pubDate>
    </item>
    <item>
      <title>位于不同国家/地区的设备的多元回归模型</title>
      <link>https://stats.stackexchange.com/questions/648080/multiple-regression-model-for-devices-located-in-different-countries</link>
      <description><![CDATA[如何处理回归问题，其中我有一组时间序列信号 (40) 并预测一些特征，情况是数据来自世界各地测量内部-外部温度的不同设备/电压/电流/功耗/等..
当我为每个位置设备构建模型时，我得到了很好的结果，但是当尝试将来自所有不同位置的所有数据合并到单个模型中时，性能要差得多。
鉴于测量的信号相同，为什么它给出的结果更差，我应该尝试其他方法吗？为每个设备添加某种标识符，或者我应该坚持为每个设备构建模型？
我尝试过 SGD 回归、XGboost 和 Catboost。]]></description>
      <guid>https://stats.stackexchange.com/questions/648080/multiple-regression-model-for-devices-located-in-different-countries</guid>
      <pubDate>Mon, 27 May 2024 15:07:34 GMT</pubDate>
    </item>
    <item>
      <title>修正 t 分布</title>
      <link>https://stats.stackexchange.com/questions/648078/modified-t-distribution</link>
      <description><![CDATA[假设 $X_{1}, \dots, X_{n}$ 为正态分布 $N(\mu, \sigma^{2})$ 的一个样本。接下来，
$$
t_{n} = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}}
$$
具有 $t$ 分布，自由度为 $n-1$。

$$
\frac{\bar{X}}{\sigma/\sqrt{n}} 的分布是什么？
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/648078/modified-t-distribution</guid>
      <pubDate>Mon, 27 May 2024 14:27:08 GMT</pubDate>
    </item>
    <item>
      <title>对多个校准曲线之间的灵敏度进行排序</title>
      <link>https://stats.stackexchange.com/questions/648074/rank-the-sensitivity-among-multiple-calibration-curves</link>
      <description><![CDATA[假设，通过测量设备，输出测量值I（以 mV 为单位）和分析物的浓度C之间存在线性关系。目标是测量 C。
我们有 3 种不同的设备硬件配置，它们会影响灵敏度：

配置 1：I = a_1 * C + b_1

配置 2：I = a_2 * C + b_2

配置 3：I = a_3 * C + b_3


如何使用数字指示器定义我们的配置对浓度 C 的灵敏度？
直观地说，a_i 值越高，我们的设备（输出 I）对 C 的微小变化最敏感。
但在另一方面，在这两个校准曲线之间：
I = 0.2 * C + 1000 std=100 (1)
I = 0.1 * C + 100 std=10 (2)

(2) 可能是灵敏度更高的校准，即使斜率 0.1 最低，因为
0.1/10 &gt; 0.2/1000，即噪音减少了 10 倍。
这个论点相当牵强，如何用更严格的数字指标将其形式化？
注意：在在物理检测测试的背景下，$y=a x+b$ 回归中的 $\frac{a}{b}$ 叫什么？我考虑过将 斜率/截距 作为指标，但肯定有更通用的指标。​​
指标 斜率/标准差 在化学计量学中常见吗？它有名字吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648074/rank-the-sensitivity-among-multiple-calibration-curves</guid>
      <pubDate>Mon, 27 May 2024 12:44:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Lehr 方法和 Statsmodels 的样本量估计存在如此大的差异</title>
      <link>https://stats.stackexchange.com/questions/648073/why-is-there-such-is-difference-in-sample-size-estimation-between-lehrs-method</link>
      <description><![CDATA[我一直在使用Lehr规则来估计一些实验所需的样本量我得跑了。
Lehr 规则指出我们需要：
$$ n = \frac{ 2\left(z(1-\alpha) + z(1-\beta)\right)^2 \sigma^2}{ \Delta^2} $$
其中 $ z(x) $ 是显着性水平的 $z$ 分数 $x$，$\sigma^2$ 是样本方差，$\Delta^2$ 是最小可检测效果。
下面是一些计算所需样本量的代码。
将 numpy 导入为 np
将 pandas 导入为 pd
从 scipy.stats 导入 ttest_ind，规范
从 statsmodels.stats.power 导入 TTestPower

# 计算所需样本量的函数
def计算样本大小（α，β，样本方差，mde）：
    ## https://en.wikipedia.org/wiki/Power_of_a_test#Rule_of_thumb

    norm_inv_z5 =norm.ppf(1.0 - alpha/2)
    norm_inv_1_z6 =norm.ppf(1.0 - beta)
    K = 2 * (norm_inv_z5 +norm_inv_1_z6)**2
    num = K * 样本方差
    分母 = mde ** 2
    样本大小 = 数字 / 分母
    返回 int(np.ceil(sample_size))

alpha = 0.1 # t 检验的显着性水平
beta = 0.2 # 功率等级
CvR = 0.1 # 转化率
Sample_variance = CvR * (1 - CvR) # 样本方差
MDE = 0.05 # 最小可检测效果 %
n_samples =calculate_sample_size(alpha, beta,sample_variance, CvR * MDE) # 样本大小

在此示例中，我想计算网站干预的样本量。我想将转化率提高 5%。这样做可以得到大约 50,000 个样本。
使用相同的输入，我发现了以下 Statsmodels 函数来计算 t 检验的功效：
 效果大小 = (CvR * MDE) / 样本方差 
 分析 = TTestPower()
 n_samples = int(np.ceil(analysis.solve_power(effect_size, power=1.0-beta, nobs=None, alpha=alpha, Alternative=&#39;双面&#39;)))

但是，这种方法只需要约 3000 个样本。
如何解释这种差异以及原因？]]></description>
      <guid>https://stats.stackexchange.com/questions/648073/why-is-there-such-is-difference-in-sample-size-estimation-between-lehrs-method</guid>
      <pubDate>Mon, 27 May 2024 12:43:03 GMT</pubDate>
    </item>
    <item>
      <title>模型非常不稳定，固定效应回归模型中的变量大多不显着</title>
      <link>https://stats.stackexchange.com/questions/648072/very-unstable-model-and-mostly-insignificant-variables-in-fixed-effects-regressi</link>
      <description><![CDATA[上周我一直在尝试为我的硕士论文创建一个回归模型，但我遇到了以下问题。目前正在寻求我能得到的任何帮助，非常感谢您提供的任何意见。 :)
我的目标是通过几个企业和宏观经济控制变量找出欧盟排放配额价格对企业自由现金流的影响。我为此使用的数据集涵盖了大约 500 家公司以及 2005 年至 2022 年的数据。
我在 R 中建立了一个单向固定效应模型（内部），并尝试用它来估计模型。它得出以下结果，这些结果还可以，但在我看来没有意义，因为我确信某些变量应该会产生重大影响，例如 GDP 增长。
我可以做/调查什么，看看我估计模型的方式是否存在错误？我是否需要以某种方式转换变量（已经尝试过一些方法，例如日志、标准化、差分）？
非常感谢您的帮助！非常感谢。
R 输出：
模型内的单向（个体）效应
致电：
plm(公式 = FCFF ~ GDP_Growth + 无形资产 + 收入 +
折旧 + TOTAL_ASSETS + 已申请专利 + 汇率_EUR.CNY +
通货膨胀 + 石油价格 + 铅现货 + EU_ETS_期货 + EU_ETS_现货，
数据=数据，模型=“内”）
平衡面板：n = 511，T = 18，N = 9198
残差：
分钟。    第一曲。     第三曲中位数。       最大限度。
-5609351.5 -5784.3 -676.8 3676.6 7938700.2

信号。代码：0&#39;&#39;0.001&#39;&#39;0.01&#39;&#39;0.05&#39;.&#39;0.1&#39;&#39;1
总平方和：3.5016e+14
残差平方和：2.8466e+14
R 平方：0.18705
调整。 R 平方：0.13814
F 统计量：12 和 8675 DF 上为 166.339
p 值：&lt; 2.22e-16]]></description>
      <guid>https://stats.stackexchange.com/questions/648072/very-unstable-model-and-mostly-insignificant-variables-in-fixed-effects-regressi</guid>
      <pubDate>Mon, 27 May 2024 12:34:17 GMT</pubDate>
    </item>
    <item>
      <title>当处理方法是欧盟立法时，我如何论证双向固定效应模型中的控制变量？</title>
      <link>https://stats.stackexchange.com/questions/648071/how-do-i-argue-for-control-variables-in-a-two-way-fixed-effects-model-when-the-t</link>
      <description><![CDATA[首先，我不知道这是否是发布此问题的合适位置。
我使用双向固定效应回归来分析欧盟指令对公司利润的影响是否受到国家公共资金总体使用情况的调节。
问题是，当争论模型中应包含哪些控制变量以解释对国家产生不同影响的时变变量时，我有点陷入困境。几年后，对我的一些单位（位于欧盟成员国的单位）进行处理（以强制执行指令的形式），而对其他单位则不会，因为它们没有放置在国家/地区是欧盟的一部分。接下来对我提出挑战的是要包含哪个控件。
由于该指令尚未实施，所有单位一开始都不会受到任何待遇，而谁受到待遇的决定因素是这些国家是否是欧盟的一部分。通常将其他变量纳入控制范围，例如国家 GDP（因为它们随时间变化并单独影响每个国家），但是，正常控制在这里似乎并不相关，因为实施指令时国家 GDP 不会产生影响。与此同时，仅包含一个变量作为控件似乎并不正确。
所以我希望有人可以帮助我了解哪种控件是合适的。]]></description>
      <guid>https://stats.stackexchange.com/questions/648071/how-do-i-argue-for-control-variables-in-a-two-way-fixed-effects-model-when-the-t</guid>
      <pubDate>Mon, 27 May 2024 12:21:54 GMT</pubDate>
    </item>
    <item>
      <title>什么因果推理方法适合识别网页不同组成部分对购买决策的影响？</title>
      <link>https://stats.stackexchange.com/questions/648069/what-causal-inference-method-is-suitable-to-identify-the-effect-of-different-com</link>
      <description><![CDATA[我正在开始为一个项目进行因果推断，我想评估网页不同组成部分对用户购买决定的因果影响。出于说明目的，我们假设我想对 Airbnb 房源执行此操作。
我想测量用户进入列表页面后某个功能对用户决策的影响（独立于搜索中列表的排名）。兴趣的变化可以是价格变化、添加图片、新功能（例如列表的专用工作区、免费取消的可能性等）。
因果图如下所示。
我测量了更改后一个月内的购买数量。我会在更改时获取该图表中显示的相关变量的值。
我的问题如下：
评级和评论数量等变量可能会在测量期间发生变化，从而导致循环依赖性（以橙色突出显示）。
我应该如何处理这个问题 - 如果评级和评论数量保持不变，我是否应该将测量周期更改为 1？ （因此将目标变量更改为（购买次数）/（测量时间段）？）
]]></description>
      <guid>https://stats.stackexchange.com/questions/648069/what-causal-inference-method-is-suitable-to-identify-the-effect-of-different-com</guid>
      <pubDate>Mon, 27 May 2024 11:34:21 GMT</pubDate>
    </item>
    <item>
      <title>尽可能扩大观察表以使每个观察一行：总是高效？</title>
      <link>https://stats.stackexchange.com/questions/648067/widening-the-observation-table-as-much-as-possible-to-get-one-row-per-observatio</link>
      <description><![CDATA[我有一个观察表，或者更确切地说是“分组”观察表，其中每个组代表一笔交易，每行代表一个产品。但预测是在交易层面进行的。以下是示例数据集。
示例数据集：
df = pd.DataFrame({&#39;deal&#39;: [&#39;deal1&#39;, &#39;deal1&#39;, &#39;deal2&#39;, &#39;deal2&#39;, &#39;deal3&#39;, &#39;deal3&#39;],
                   &#39;产品&#39;: [&#39;prd_1&#39;, &#39;prd_2&#39;, &#39;prd_1&#39;, &#39;prd_2&#39;, &#39;prd_1&#39;, &#39;prd_2&#39;],
                   &#39;数量&#39;: [2, 1, 5, 3, 6, 7],
                   &#39;总价&#39;: [10, 7, 25, 24, 30, 56],
                   &#39;结果&#39;: [&#39;赢&#39;, &#39;赢&#39;, &#39;输&#39;, &#39;输&#39;, &#39;赢&#39;, &#39;赢&#39;]})

我的方法：
使用pivot_table展平数据以获取每行一个观察值，以便我们为每个交易获取一行，然后继续进行分类建模。
在上面的例子中，我们有：
要旋转的 1 列（产品，具有 2 个唯一值）
2 个度量（数量和价格）作为系列/值。
结果为 4 列。
生成的展平表：

问题/想法：
在这种情况下，这总是最好的方法吗？我看到的问题（或者可能不是？）是当要旋转的列数超过 1 时，并且如果其中的唯一值组合更多，则表可能会变得非常宽。
如果有其他有效的方法，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/648067/widening-the-observation-table-as-much-as-possible-to-get-one-row-per-observatio</guid>
      <pubDate>Mon, 27 May 2024 10:39:43 GMT</pubDate>
    </item>
    <item>
      <title>这篇文章关于似然函数的解释正确吗？</title>
      <link>https://stats.stackexchange.com/questions/648066/is-this-post-correct-about-interpreting-the-likelihood-function</link>
      <description><![CDATA[我正在阅读这篇中等文章，其中使用了似然公式：
\begin{方程}
L(\theta) = \prod_t^V \prod_{-m\leq j \leq m,\, j\neq0} P(w_{t+j}|w_t;\theta)
\end{方程}

$\theta$ 是参数（此处为神经网络的权重）
$-m$ 和 $m$ 标记中心词之外的词。
$V$ 是本例中词汇表中的每个单词。 （就像一本字典。）
条件概率是单词 $t$ 伴随单词 $t+j$

这是针对word2vec的，但我的问题纯粹是关于公式的概念性问题。
我不明白为什么这是真的（来自上面的链接。）：
&lt;块引用&gt;
最终结果是一个似然得分，当模型表现良好时（预测实际的外部词应该是外部词）应该很高，而当模型表现不佳时（认为实际的外部词不应该是）则应该很低。外部词）。

由于这里我们没有计算相对于真实情况的任何误差，因此它可能很高并且完全错误。
有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648066/is-this-post-correct-about-interpreting-the-likelihood-function</guid>
      <pubDate>Mon, 27 May 2024 09:40:30 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归系数解释</title>
      <link>https://stats.stackexchange.com/questions/648065/interpretation-of-logistic-regression-coefficient</link>
      <description><![CDATA[在逻辑回归框架中，几率定义为：
$$\frac{p(X)}{1-p(X)}=e^{\beta_0+\beta_{1}X}。$$
在教科书《统计学习导论》中（Gareth James 等人，2013 年），第 132 页我读到：

相比之下，在逻辑回归模型中，将 $X$ 增加一个单位，对数概率将改变 $\beta_1 (4.4)$，或者等价地将概率乘以 $e^{\beta_1} (4.3)$。

为什么 $X$ 的一个单位变化将概率乘以 $e^{\beta_1}$？
我的理由如下：
$$\frac{\partial e^{\beta_0+\beta_{1}X}}{\partial X}= \beta_1e^{\beta_0+\beta_{1}X},$$
因此，$X$ 的单位变化应使 $\frac{p(X)}{1-p(X)}$ 发生 $\beta_1e^{\beta_0+\beta_{1}X}$ 变化。这不对吗？
编辑 在引用中，我们有 (4.3) 和 (4.4) 方程，分别给出
$$\frac{p(X)}{1-p(X)}=e^{\beta_0+\beta_{1}X}。 $$
$$log(\frac{p(X)}{1-p(X)})=\beta_0+\beta_{1}X。 $$]]></description>
      <guid>https://stats.stackexchange.com/questions/648065/interpretation-of-logistic-regression-coefficient</guid>
      <pubDate>Mon, 27 May 2024 09:13:13 GMT</pubDate>
    </item>
    <item>
      <title>心理物理学中的非正态数据：三路混合方差分析的替代方案？ （已编辑）</title>
      <link>https://stats.stackexchange.com/questions/648005/non-normal-data-in-psychophysics-alternative-to-three-way-mixed-anova-edited</link>
      <description><![CDATA[我正在进行一项关于人们检测信号的能力的实验。我计算信号检测理论测量 d prime 和 beta。我想调查信号“蓝色”是否有效比“红色”更好地被检测到。以及在实验的前半部分和后半部分中这种情况是否发生变化（两部分是看是否发生学习）。样本量为 N=18。
使用 R，我的方差分析将如下所示：
anova = aov(d&#39;~ color *section * color:section * 1|观察者)

和 

beta = aov(d&#39;~ 颜色 * 部分 * 颜色:部分 * 1|观察者)

因此，我计算了每个观察者和颜色实验部分（第一或第二）的每个组合的测量值。我使用每个实验部分的总体误报率。
事实证明，数据确实存在偏差。 d prime 是双峰分布。 d prime 的 Shapiro-Wilk 检验给出了 W = 0.92869，p 值 = 0.0003652，β 的同样结果给出了 W = 0.70378，p 值 = 4.312e-11。
在绘制 d prime 和 beta 时，d prime 似乎具有双峰分布，而 beta 严重向右倾斜。对于 Beta 值，似乎有些人在部分实验中采用了非常保守的响应偏差（Beta 值从 7 到 12）。然而，近 200 次试验并没有太大差异（因此您不会期望部分和信号之间的 beta 差异如此之大
我尝试标准化数据（平方根和对数），但没有成功。考虑到样本量较小，这种方法很难纠正它。对此有什么建议吗？我一直在寻找一种非参数替代方案，其作用与我的方差分析相同，但我找不到。如果您需要有关实验的更多详细信息，请告诉我！
]]></description>
      <guid>https://stats.stackexchange.com/questions/648005/non-normal-data-in-psychophysics-alternative-to-three-way-mixed-anova-edited</guid>
      <pubDate>Sun, 26 May 2024 09:09:22 GMT</pubDate>
    </item>
    <item>
      <title>Ali-Mikhail-Haq 和 Farlie-Gumbel-Morgenstern Copula 的条件反函数的公式是什么？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647911/what-is-the-formula-for-the-conditional-inverse-function-for-the-ali-mikhail-haq</link>
      <description><![CDATA[我正在尝试进行蒙特卡罗模拟，并希望为 Ali-Mikhail-Haq 和 Farlie-Gumbel-Morgenstern Copula 的条件反函数定义一个函数。这是我正在寻找的公式的示例 ]]></description>
      <guid>https://stats.stackexchange.com/questions/647911/what-is-the-formula-for-the-conditional-inverse-function-for-the-ali-mikhail-haq</guid>
      <pubDate>Fri, 24 May 2024 16:50:34 GMT</pubDate>
    </item>
    <item>
      <title>计算边际效应与 brms 模型的边际效应对比</title>
      <link>https://stats.stackexchange.com/questions/647910/calculating-contrasts-of-marginal-effects-with-marginaleffects-for-brms-model</link>
      <description><![CDATA[我已经使用 brms 拟合了逻辑模型，并想要计算平均边际效应 (AME)。
库(brms)

模型 &lt;- brm(公式 = 结果 ~ var1 + var2 + var3, family = Bernoulli(), data = data)

var1 是分类的，具有两个级别 (1, 0)，var3 是分类的，具有三个级别（“a”、“b”、“0”）。 c”）。 var3 是另一个变量，在计算边际效应时我不想设置/平均其值。
现在，我想计算 var2 每个级别的 var1 的 AME/斜率。 （我不想使用平均协变量 (MEM)。）
库（边际效应）

斜率 &lt;- avg_slopes(
  模型，
  变量=“var1”，
  通过=“var2”
) %&gt;%terior_draws()

这给了我：
 术语对比度 var2 估计 2.5 % 97.5 %
 var1 平均值(1) - 平均值(0) a 0.0361 -0.1098 0.1735
 var1 平均值 (1) - 平均值 (0) b 0.0618 -0.0454 0.1666
 var1 平均值(1) - 平均值(0) c -0.0788 -0.1667 0.0177

现在，我需要这些对比之间的成对对比。即，a - b、a - c 和 b - c 的估计差异。
我可以像这样手动完成：
slopes_a &lt;- 斜率 %&gt;% 过滤器(var2 == &quot;a&quot;)
lopes_b &lt;- 斜率 %&gt;% 过滤器(var2 == &quot;b&quot;)
lopes_c &lt;- 斜率 %&gt;% 过滤器(var2 == &quot;c&quot;)

df &lt;- data.frame(
  `a - b` =lopes_a$draw-slopes_b$绘制，
  `a - c` =lopes_a$draw-slopes_c$绘制，
  `b - c` =lopes_b$draw-slopes_c$绘制
）

这是一种有效的方法吗？是否有更好/更好的方法，例如直接使用 marginaleffects 包？]]></description>
      <guid>https://stats.stackexchange.com/questions/647910/calculating-contrasts-of-marginal-effects-with-marginaleffects-for-brms-model</guid>
      <pubDate>Fri, 24 May 2024 16:50:10 GMT</pubDate>
    </item>
    </channel>
</rss>