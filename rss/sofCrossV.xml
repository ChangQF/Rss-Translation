<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 04 Jun 2024 12:27:23 GMT</lastBuildDate>
    <item>
      <title>Python 拟合的 Sigmoid 极值几乎未被使用</title>
      <link>https://stats.stackexchange.com/questions/648607/python-fitted-sigmoid-extreme-values-barely-being-used</link>
      <description><![CDATA[我最初处理的是大量值对。我使用自定义启发式方法从每对值计算得分，并将该集合转换为值数组。我对其进行了排序，并将每个值分配给 x，将其标准化排名（介于 0 和 1 之间，均排除）分配给 y。
这是一个例子：

我尝试拟合 S 型函数，但我认为它被大量居中数据误导，没有考虑到极端值，而我实际上计划使用这个新函数将 0 到 1 之间的得分分配给任何新值。现在，使用该解决方案，任何超过阈值 31 的值的排名都会达到大约 0.93。
如何降低中心点的影响？我考虑过简单地删除一些，但我不知道正确的方法，甚至不知道这是否是正确的方法。
这是我的代码：
import json
import numpy as np
from scipy.optimize import curve_fit
import matplotlib.pyplot as plt

filename = &quot;scores.json&quot;

使用 open(filename, &#39;r&#39;) 作为 f:
data = json.load(f)

x_values = [point[&#39;x&#39;] for point in data]
y_values = [point[&#39;y&#39;] for point in data]

x_data = np.array(x_values)
y_data = np.array(y_values)

def sigmoid(x, L, x0, k):
return L / (1 + np.exp(-k * (x - x0)))

initial_guess = [1, np.median(x_data), 1]

params, covariance = curve_fit(sigmoid, x_data, y_data, p0=initial_guess, maxfev=10000)

L, x0, k = params

print(f&quot;优化参数：L = {L}, x0 = {x0}, k = {k}&quot;)

plt.scatter(x_data, y_data, marker=&#39;+&#39;, label=&#39;Data&#39;)

x_fit = np.linspace(min(x_data), max(x_data), 400)
y_fit = sigmoid(x_fit, *params)
plt.plot(x_fit, y_fit, label=&#39;Fitted Sigmoid&#39;, color=&#39;red&#39;)

plt.legend()
plt.show()

以下是找到的参数：
# 优化参数：L = 0.9305200252602871，x0 = 2.107303517527327，k = 0.24761667539895446
]]></description>
      <guid>https://stats.stackexchange.com/questions/648607/python-fitted-sigmoid-extreme-values-barely-being-used</guid>
      <pubDate>Tue, 04 Jun 2024 12:07:38 GMT</pubDate>
    </item>
    <item>
      <title>使用与差异估计量不随时间变化的控件</title>
      <link>https://stats.stackexchange.com/questions/648606/using-controls-that-are-time-invariant-with-the-difference-in-differences-estima</link>
      <description><![CDATA[我进行了一项实验，其中有两组参与者在第一阶段执行完全相同的任务。在第二阶段，这两组必须第二次执行相同的任务。但是，对于其中一组，我为第二部分引入了附加信息。这两组被称为社交信息条件和无社交信息条件。
最简单的模型如下：
DE=Beta0 + Beta1 X SocialInfo + Beta2 X Time +Beta3 X SocialInfo X Time + u
（抱歉没有放索引）。
DE 是因变量，即处置效应。
社交信息是一个虚拟变量，当没有社交信息（无治疗）时取 0，当有治疗社交信息时取 1。
时间是一个虚拟变量，在研究的第一部分取 0，在第二部分取 1。
从这里开始，就理解而言，一切对我来说似乎都很好，但我认为我可能犯了一个错误：
在每个组中，参与者在两个时间段内有不同的时间限制来执行任务：没有时间限制、20 秒时间限制、10 秒时间限制。因此，我建立的模型如下：
DE=Beta0 + Beta1 X SocialInfo + Beta2 X Time +Beta3 X SocialInfo X Time + Beta4 X 20TC + Beta5 X 10TC + Beta6 X 人口统计控制+ u
10TC 和 20TC 是虚拟变量，如果个人在每个时期有 10 秒或 20 秒的时间来完成任务，则取 1，如果没有时间限制，则取 0。
对我来说，这些系数代表基线差异，即没有社交信息和时间限制的人与没有社交信息但有时间限制的人之间的差异。
人口统计控制表示在执行任何任务之前测量的变量，例如风险规避、损失规避、性别、年龄等。
我认为添加这些将使我有更精确的估计。
但由于我没有材料来验证这一点，所以我我很怀疑添加这些变量是否明智。
我冒了这个险，因为添加这些变量后 DiD 估计量 (Beta3) 并没有改变。
我的问题如下：
为什么 did 估计量的系数在有或没有这些控制（不随时间变化）的情况下保持不变？
为什么在使用 DiD 估计量的回归模型中添加错误的时间不变控制？]]></description>
      <guid>https://stats.stackexchange.com/questions/648606/using-controls-that-are-time-invariant-with-the-difference-in-differences-estima</guid>
      <pubDate>Tue, 04 Jun 2024 11:23:18 GMT</pubDate>
    </item>
    <item>
      <title>就风险因素的变化而言，绝对风险降低/相对风险降低与比值比存在哪些问题</title>
      <link>https://stats.stackexchange.com/questions/648605/what-are-the-issues-with-absolute-risk-reduction-relative-risk-reduction-vs-odds</link>
      <description><![CDATA[以下引文来自此：
当结果是分类的或代表事件发生时间时，任何可能用一个常数总结所有类型患者的治疗效果的测量方法都是不可折叠的。绝对风险降低和相对风险降低等可折叠测量必须随风险因素而变化（产生数学但不与主题相关的相互作用），否则会出现超出允许范围 [0,1] 的概率。
我对此有几个问题。

前两句话似乎相互矛盾。计数数据是分类的，但可以产生可折叠的汇总统计数据？
我不明白为什么第二句话是正确的。我们不是先计算概率，然后再计算 ARR 和 RRR 吗？
鉴于它们确实会变化并导致概率超出范围 [0,1]，这对使用泊松或任何其他估计风险比率的回归有影响吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648605/what-are-the-issues-with-absolute-risk-reduction-relative-risk-reduction-vs-odds</guid>
      <pubDate>Tue, 04 Jun 2024 11:22:20 GMT</pubDate>
    </item>
    <item>
      <title>具有离散时间点和随时间变化的协变量的生存分析的样本大小（R 中的 SampleSizeDiscSurv）</title>
      <link>https://stats.stackexchange.com/questions/648604/sample-size-for-survival-analysis-with-discrete-time-points-and-time-varying-cov</link>
      <description><![CDATA[**针对我关于计算具有时间依赖性协变量和有限时间点的 cox 回归的样本量的问题，我得到的反馈是，我可以通过基于二项回归或具有互补对数对数链接的二项回归进行估计来计算样本量。
具有离散时间的生存分析 (Cox 回归) 的样本量或进行深度模拟。
我浏览了网站上关于计算具有时间变化协变量的离散生存时间 (cox) 的样本量的所有建议，但没有人建议使用 R 中的以下函数 SampleSizeDiscSurv 进行计算。
所以我想知道 R 中的这个函数是否可用于计算样本量？这个功能有任何限制-假设-局限吗？?*]]></description>
      <guid>https://stats.stackexchange.com/questions/648604/sample-size-for-survival-analysis-with-discrete-time-points-and-time-varying-cov</guid>
      <pubDate>Tue, 04 Jun 2024 11:12:27 GMT</pubDate>
    </item>
    <item>
      <title>寻找合适的方法来查找事件组</title>
      <link>https://stats.stackexchange.com/questions/648603/looking-for-a-suitable-way-to-find-groups-of-events</link>
      <description><![CDATA[我有一个 excel 文件，其中有三列。第一列是事件的名称，第二列是事件的开始时间，第三列是事件的结束时间。假设我正在处理人们登录服务器的时间。
某些行将是：
Robert 2023-11-28 13:34:43 2023-11-28 13:34:45
Alice 2023-11-28 13:35:22 2023-11-28 13:37:01
Robert 2023-11-28 13:44:43 2023-11-28 13:54:08
Anna 2023-11-28 13:45:02 2023-11-28 13:47:04
我的想法是使用 python 生成另一个文件，其列数与人员数和将许多行按秒为单位，如果该人在该秒内登录，则输入 1，否则输入 0。然后，在列上使用层次聚类、平均链接和Roger&#39;s Tanimoto距离来查看人与人之间的亲密程度，然后使用关联规则将每行视为一个篮子。我还可以计算人与人之间的相关矩阵。
我也想知道其他人对这个话题的意见。
最后，我想创建基于人们同时在线的场景，例如罗伯特和萨曼莎通常同时在线。
任何关于如何做到这一点的意见都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/648603/looking-for-a-suitable-way-to-find-groups-of-events</guid>
      <pubDate>Tue, 04 Jun 2024 11:07:08 GMT</pubDate>
    </item>
    <item>
      <title>R 中的二项分布不对称</title>
      <link>https://stats.stackexchange.com/questions/648602/binomial-distribution-in-r-is-not-symmetrical</link>
      <description><![CDATA[我期望下面的代码产生相同的输出，但事实并非如此。我的想法是基于密度函数的二项分布公式。我使用 Rstudio。
错误在哪里？
$$
P(x) = \binom{n}{x} p^xp^{n-x}
$$
r12 = pbinom(2,5,(pnorm(1.4)))
r13 = pbinom(3,5,(1-pnorm(1.4)))
]]></description>
      <guid>https://stats.stackexchange.com/questions/648602/binomial-distribution-in-r-is-not-symmetrical</guid>
      <pubDate>Tue, 04 Jun 2024 11:06:53 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Openmx 确定单变量 ADE/ACE 模型（或饱和模型）中的“起始值”？</title>
      <link>https://stats.stackexchange.com/questions/648601/how-to-determine-starting-values-in-univariate-ade-ace-model-or-saturated-mod</link>
      <description><![CDATA[有人知道如何确定起始值吗，例如在未测量的基因型数据中执行饱和模型？我使用了 https://hermine-maes.squarespace.com/#/one/ 中的代码“oneSATc.R”，但它没有很好地解释如何确定起始值，所以也许有人有这方面的经验，可以帮助我。这里我将提供我的代码片段。
 #################
## 假设测试 ##
#################

#------------#
## 准备数据 ##
#------------#

# 选择要分析的变量
vars &lt;- &#39;SBJS5T&#39; # 变量名称列表
nv &lt;- 1 # 变量数量
ntv &lt;- nv*2 # 总变量数量
selVars &lt;- paste(vars,c(rep(1,nv),rep(2,nv)),sep=&quot;&quot;) 

# 选择要分析的数据
mzData &lt;- subset(raw, ZYGO == 1, selVars) 
dzData &lt;- subset(raw, ZYGO == 2, selVars) 

# 生成描述性统计
colMeans(mzData,na.rm=TRUE)
colMeans(dzData,na.rm=TRUE)
cov(mzData,use=&quot;complete&quot;)
cov(dzData,use=&quot;complete&quot;)

# 设置起始值
# 更新设置起始值
svMe &lt;- 18.42 # 平均值的起始值，四舍五入的平均平均值
svVa &lt;- 3.45 # 方差的起始值，四舍五入的方差意味着双胞胎
lbVa &lt;- .0001 # 方差的下限


现在我仅使用 4 个“colMeans”的平均值作为“svME”，使用 8 个“cov”的平均值作为“svVa”
有人可以肯定这一点或告诉我哪种方法可以准确确定这些起始值吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648601/how-to-determine-starting-values-in-univariate-ade-ace-model-or-saturated-mod</guid>
      <pubDate>Tue, 04 Jun 2024 10:30:08 GMT</pubDate>
    </item>
    <item>
      <title>如何比较二元名义变量和离散变量？</title>
      <link>https://stats.stackexchange.com/questions/648598/how-do-i-compare-a-binary-nominal-variable-and-a-discrete-variable</link>
      <description><![CDATA[我试图比较服务是否已交付（是/否）与员工必须完成的异常任务数量（1、2、... n）。
我可以使用什么统计测试来做到这一点？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/648598/how-do-i-compare-a-binary-nominal-variable-and-a-discrete-variable</guid>
      <pubDate>Tue, 04 Jun 2024 10:03:54 GMT</pubDate>
    </item>
    <item>
      <title>逐步回归模型中 alpha-entry 和 alpha-stay 的功能？（R）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648597/functioning-of-alpha-entry-and-alpha-stay-in-stepwise-regression-model-r</link>
      <description><![CDATA[我必须执行逐步回归模型：

Alpha-entry = 0.05
Alpha-stay = 0.10

此模型用于选择基因型并构建我​​的 GPS。
此回归模型应用于 35 个 SNP，它们存储在我的数据集的第 67:101 列中。此外，我还必须添加 5 个变量（不是 SNP），即：

ds1（虚拟变量）
ds2（虚拟变量）
leeftijd（年龄）
lengte（身高）
gewicht（体重）

现在我已经编写了一些代码来实现海平面 VO2max = normoxia，在我的数据集中定义为“vo2max_nor”。然而，我不确定输出，因为看起来模型不包括所有 35 个 SNP 和 5 个附加变量，还是因为 alpa-entry 和 alpha-stay？
这里我将提供我的代码：
# 提取 SNP 的列名（第 67 至 101 列）
snp_columns &lt;- colnames(data)[67:101]
covariates &lt;- c(&quot;ds1&quot;, &quot;ds2&quot;, &quot;leeftijd&quot;, &quot;lengte&quot;, &quot;gewicht&quot;)
full_model_formula &lt;- as.formula(paste(&quot;vo2max_nor ~&quot;, paste(c(snp_columns, covariates), collapse = &quot; + &quot;)))

# 拟合初始完整模型
full_model &lt;- lm(full_model_formula, data = data)

# 执行逐步回归
stepwise_model &lt;- stepAIC(full_model, direction = &quot;both&quot;, 
trace = FALSE, 
scope = list(lower = ~1, upper = full_model_formula),
test = &quot;F&quot;, 
alpha.enter = 0.05, 
alpha.remove = 0.10)

# 逐步模型摘要
summary(stepwise_model)

这是我得到的输出：
&gt; summary(stepwise_model)

调用：
lm(formula = vo2max_nor ~ CYP11B2_1799998 + AGT_699 + VEGFA_699946 + 
ADRB2_1042713 + AGT__5051 + MTHFR__1801133 + ADRB2__1042714 + 
EPO__1617640 + VHL__1642742 + VEGFA__3025000 + PPARA__4253778 + 
EPAS1_2 + EPAS1_6 + ds1 + lengte + gewicht，数据 = 数据)

残差：
最小值 1Q 中值 3Q 最大值 
-0.96486 -0.31467 0.01245 0.34651 0.96294

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
（截距） -1.588832 1.782297 -0.891 0.375698 
CYP11B2_1799998 0.289258 0.081576 3.546 0.000698 ***
AGT_699 0.589812 0.271716 2.171 0.033300 * 
VEGFA_699946 0.238185 0.141934 1.678 0.097717 . 
ADRB2_1042713 0.156056 0.104941 1.487 0.141423 
AGT__5051 -0.650848 0.273614 -2.379 0.020066 * 
MTHFR__1801133 -0.275354 0.098954 -2.783 0.006903 ** 
ADRB2__1042714 0.252455 0.111131 2.272 0.026137 * 
EPO__1617640 -0.244739 0.082780 -2.957 0.004221 ** 
VHL__1642742 -0.176201 0.079984 -2.203 0.030845 * 
VEGFA__3025000 -0.222606 0.121931 -1.826 0.072104 .
PPARA__4253778 -0.172292 0.109876 -1.568 0.121315 
EPAS1_2 -0.154734 0.095706 -1.617 0.110363 
EPAS1_6 0.231668 0.094907 2.441 0.017142 * 
ds1 -0.487358 0.153105 -3.183 0.002163 ** 
长度 0.021990 0.011371 1.934 0.057124 . 
gewicht 0.027701 0.008697 3.185 0.002150 ** 
---
Signif. 代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：71 个自由度上的 0.4798
多重 R 平方：0.5612，调整后的 R 平方：0.4623
F 统计量：16 和 71 DF 上的 5.674，p 值：1.213e-07

有人能帮我理解这个代码/输出是否正确吗？还是我做错了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648597/functioning-of-alpha-entry-and-alpha-stay-in-stepwise-regression-model-r</guid>
      <pubDate>Tue, 04 Jun 2024 09:49:03 GMT</pubDate>
    </item>
    <item>
      <title>从独立负二项式构造狄利克雷多项式</title>
      <link>https://stats.stackexchange.com/questions/648595/construction-of-dirichlet-multinomial-from-independent-negative-binomials</link>
      <description><![CDATA[我有一个数据集，其中包含 ISO3 国家代码、年份（从 2010 年到 2019 年）、死亡原因类别（共 24 个类别）和死亡人数。各种原因的死亡人数总数是固定的。我的目标是预测 2020-2023 年期间每个国家/原因组合的预期死亡人数。
我的想法是使用 R 中的 gam 函数为每个国家/原因组合运行独立的负二项回归模型，因为我的数据明显过度分散：
for (i in unique(df$iso3)) {

for (j in unique(df$cause)) {

whichs &lt;- which(df$iso3 == i &amp; df$cause == j)

temp &lt;- df[whichs, ]

model &lt;- gam(deaths ~ s(year), data = temp, family = nb(theta = NULL, link = &quot;log&quot;))

pred &lt;- predict(model, se.fit = TRUE, type = &quot;response&quot;, newdata = data.frame(year = c(2020,2021,2022,2023)))

}

}


为了确保各种原因的死亡人数总和等于已知且固定的总数，我似乎需要从这些独立的负二项式中构建一个狄利克雷多项式。请参阅此参考资料：https://arxiv.org/pdf/2001.04343 &quot;狄利克雷多项分布相当于一组独立的负二项分布，具有相同的尺度参数，以它们的总和为条件&quot;。这是正确的做法吗？
如果是这样，我不确定我需要在 R 中做什么来应用它。我尝试了以下代码中的不同 theta 值，但各种原因的死亡人数总和并未达到固定总数 + 设置定义的 theta 值会影响模型拟合。
model &lt;- gam(deaths ~ s(year), data = temp, family = nb(theta = **NULL**, link = &quot;log&quot;))

我该怎么办？一种简单的方法是重新调整预期的死亡人数，使各种原因的总和与固定总数相匹配，但我希望正确地做事。]]></description>
      <guid>https://stats.stackexchange.com/questions/648595/construction-of-dirichlet-multinomial-from-independent-negative-binomials</guid>
      <pubDate>Tue, 04 Jun 2024 08:47:19 GMT</pubDate>
    </item>
    <item>
      <title>双变量 von Mises 分布的 CF（特征函数）有封闭形式吗？</title>
      <link>https://stats.stackexchange.com/questions/648592/is-there-a-closed-form-of-the-cf-characteristic-function-of-a-bivariate-von-mi</link>
      <description><![CDATA[双变量冯·米塞斯分布的 CF（特征函数）是否有封闭形式？
如果我有两个参数遵循冯·米塞斯分布，但我的两个参数会混合在一起，那么我应该转到双变量冯·米塞斯分布，还是可以只使用冯·米塞斯分布进行计算？
附言：如果不清楚，请见谅，这是我第一次使用它！]]></description>
      <guid>https://stats.stackexchange.com/questions/648592/is-there-a-closed-form-of-the-cf-characteristic-function-of-a-bivariate-von-mi</guid>
      <pubDate>Tue, 04 Jun 2024 08:14:32 GMT</pubDate>
    </item>
    <item>
      <title>纵向和事件发生时间数据的联合模型与具有时间依赖性协变量的生存分析</title>
      <link>https://stats.stackexchange.com/questions/648590/joint-models-for-longitudinal-and-time-to-event-data-vs-survival-analysis-with-a</link>
      <description><![CDATA[我需要一些帮助来理解具有时间依赖性协变量的生存分析（cox 回归）与纵向和事件发生时间数据联合模型（R 中的 JM 包）之间的区别。您能否通过一个实际示例解释这两种方法之间的区别。]]></description>
      <guid>https://stats.stackexchange.com/questions/648590/joint-models-for-longitudinal-and-time-to-event-data-vs-survival-analysis-with-a</guid>
      <pubDate>Tue, 04 Jun 2024 06:41:09 GMT</pubDate>
    </item>
    <item>
      <title>R(k+1，n+1)<R(k，n)？</title>
      <link>https://stats.stackexchange.com/questions/648586/rk1-n1-rk-n</link>
      <description><![CDATA[“在 n+1 次试验中至少有 k+1 次成功的概率小于在 n 次试验中至少有 k 次成功的概率”是否正确？是否不正确？无法评估？
$
R(k,n)=\sum_{i=k}^n\binom ni p^iq^{n-i}
$]]></description>
      <guid>https://stats.stackexchange.com/questions/648586/rk1-n1-rk-n</guid>
      <pubDate>Tue, 04 Jun 2024 03:35:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么要正式检验工具变量的相关性假设？</title>
      <link>https://stats.stackexchange.com/questions/648577/why-can-we-formally-test-the-relevance-assumption-of-instrument-variable</link>
      <description><![CDATA[我在我以前的关于 IV 的幻灯片中看到，教授说我们无法测试 IV 的排除假设，但我们可以测试 IV 的相关性假设。他关于无法测试排除的论据是：

$y=\beta_1 x_1 +\beta_2 x_2+\gamma z + u$如果 z 不独立于 u，那么您无法通过执行此回归来测试排除要求，并与 $\gamma=0$ 争论，因为 $cov(z,u)\ne 0$ 会使 $\gamma$ 的估计产生偏差&gt;

同时，他说您可以通过以下方式测试相关性假设：

$x_1=\beta_2 x_2+\gamma z+v$，如果 $\gamma$ 与 0 显著不同，我们满足了相关性要求

但是，第二个不是也存在内生性问题吗？所以如果 z 不独立于 v，而是与 x_2 相关，那么 $\gamma$ 就会有偏差。如果我们观察到非零 gamma，则可能存在向上偏差，如果没有偏差，z 本身与 x 没有任何关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/648577/why-can-we-formally-test-the-relevance-assumption-of-instrument-variable</guid>
      <pubDate>Mon, 03 Jun 2024 21:57:36 GMT</pubDate>
    </item>
    <item>
      <title>重复测量方差分析问题</title>
      <link>https://stats.stackexchange.com/questions/648560/repeated-measures-analysis-of-variance-question</link>
      <description><![CDATA[我有以下数据集。
My_Data &lt;- data.frame(Sampling_Date = rep(1:4, each = 12), Block = rep(1:3, length.out = 48), Treatment = rep(LETTERS[1:4], each = 3, length.out = 48), Response = abs(rnorm(48, 10, 1)))

我正在做重复测量方差分析。每个区块包含四个图，其中区块中的每个图都接受不同的处理。这些图在一年内被重复采样。我想知道在 R 中对这些数据进行建模的最合适方法是什么。这是我根据所读内容得出的结论。
Model &lt;- aov(Response ~ (Treatment * as.factor(Sampling_Date)) + Error(as.factor(Block) / (Treatment * as.factor(Sampling_Date))), data = My_Data)
summary(Model)

在此模型输出中，每个主效应和交互项都有自己的误差项，这本质上是主效应或感兴趣的交互与阻塞（复制）变量的相互作用。
我有几个问题。
首先，此模型的工作方式是否合适？换句话说，这些误差项是否适用于每个不同的主效应和交互？如果是，那么为什么？
其次，我是否需要考虑混合效应模型，以便可以将块视为随机变量？由于区块本质上只是我们的复制变量，我认为它不应该包含在模型中。
第三，何时以及为什么要考虑球形度？这取决于我们将采样日期视为数字变量还是分类变量吗？
第四，如果我将采样日期视为数字变量，模型将如何变化？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648560/repeated-measures-analysis-of-variance-question</guid>
      <pubDate>Mon, 03 Jun 2024 17:20:53 GMT</pubDate>
    </item>
    </channel>
</rss>