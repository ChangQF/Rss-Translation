<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 24 Dec 2023 09:13:56 GMT</lastBuildDate>
    <item>
      <title>阐明称为“内核”或“贝叶斯”的各种回归方法之间的差异</title>
      <link>https://stats.stackexchange.com/questions/635574/clarifying-the-difference-between-various-regression-methods-called-kernel-or</link>
      <description><![CDATA[我想了解四种回归类型之间的成对关系：贝叶斯线性回归、高斯过程回归、核回归 (Nadaraya-Watson) 和核岭回归。我在阅读机器学习的高斯过程这本书时遇到了所有这些问题，并且想要一种清晰简洁的方法来区分它们。
这是我目前的理解，欢迎指正。贝叶斯线性回归处理 $\hat{\beta}$ 回归系数（通常设置为 OLS 最优估计器 $\hat{\beta}= (X^TX)^{-1}X^T y$) 作为随机变量，其分布是先验（我们选择的）的函数，并且数据（这鼓励它采用上面的 OLS 形式，如果这是我们的损失函数）。高斯过程回归只是贝叶斯线性回归，其中函数的先验是高斯过程（它是由均值函数和协方差函数定义的函数空间上的分布）。
然后，我对核回归的理解是，核是一个“相似度函数”。数据点之间，因此形式为 $\hat{y}(x) = \frac{\sum_i K(x, x_i)y_i}{\sum_i K(x, x_i)}$ 作为加权平均值似乎使用起来很直观。但是内核 ridge 回归给出了形式为 $K_{x, X}(K_{X,X} + \lambda I)^{- 的估计量1}y$。这似乎与带有岭罚分的传统核回归（N-W 类型）不同。此外，我看到高斯过程回归输出与其“后验平均值”相同的估计量。现在 $K$ 是协方差内核，因此 GPR（这是 BLR 的特殊情况？）相当于 KRR？
这四个简单方法之间的关系我不清楚。非常感谢一些澄清，谢谢。技术细节越多越好。]]></description>
      <guid>https://stats.stackexchange.com/questions/635574/clarifying-the-difference-between-various-regression-methods-called-kernel-or</guid>
      <pubDate>Sun, 24 Dec 2023 08:26:18 GMT</pubDate>
    </item>
    <item>
      <title>曼惠特尼测试中获得 U 的概率证明</title>
      <link>https://stats.stackexchange.com/questions/635572/proof-of-probability-of-obtaining-u-in-mann-whitney-test</link>
      <description><![CDATA[我试图了解 U 的概率公式是如何计算的 论文，第 4 节中的公式 1。

详情：
假设我们有两组 A 和 B，每组分别包含 m 和 n 个样本。 U 计算 A 中的成员领先于 B 中的成员（排名高于）的次数。 $\bar{p}_{\text{nm}}(U)$ 是其中有 m 个 A 和 n 个 B 的序列数，其中每个 A 的成员先于（排名高于）B 的成员 U 次。那么 $\bar{p}_{\text{nm}}(U)$ 的递归公式如下：

1]有人可以帮我推导出上述内容吗？
此外，在比较A和B是否表现相同的测试时，获得$\bar{p}_{\text{nm}}(U)的概率$ 在 A 和 B 表现相同的原假设下由 ${p}_{\text{nm}}(U)$ 给出，其中其递归公式如下：

2]有人可以帮我推导出上述内容吗？
谢谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/635572/proof-of-probability-of-obtaining-u-in-mann-whitney-test</guid>
      <pubDate>Sun, 24 Dec 2023 06:33:31 GMT</pubDate>
    </item>
    <item>
      <title>图像融合背景下有关 MI 和 NMI 的查询</title>
      <link>https://stats.stackexchange.com/questions/635570/query-regarding-mi-and-nmi-in-the-context-of-image-fusion</link>
      <description><![CDATA[我正在图像融合的背景下探索互信息（MI）和归一化互信息（NMI）。在回顾各种来源时，经常提到互信息的值表示融合的质量，值越高表示融合越好。不过，我很好奇什么才是高价值。
图像融合中互信息值的范围是多少？大多数消息来源表明值越高越好，但是什么范围被认为非常高或表明融合质量良好？
此外，关于归一化互信息（NMI），我理解理想情况下它应该在0-1范围内，表示注册的质量。然而，在学术论文中，报告的值通常徘徊在 0.x 或 1.x 左右。对于有效配准的融合图像的值范围到底应该预期什么？
就像查看其中一篇论文中的 NMI 值 NMI- 0.8316, 0.8352, 1.1684, 0.5978, 0.9891, 1.0071, 1.2135, 1.1879, 1.1198, 0.9010, 0.9585, 1.1968, 1.1082, 1.0031、1.2485
我正在寻求有关互信息和归一化互信息值的预期范围或阈值的澄清，以更好地解释图像融合的质量。任何见解或参考综合解释将不胜感激。
您可以检查“metricMI.m”在指标工具箱 - https://github.com/zhengliu6699/imageFusionMetrics]]></description>
      <guid>https://stats.stackexchange.com/questions/635570/query-regarding-mi-and-nmi-in-the-context-of-image-fusion</guid>
      <pubDate>Sun, 24 Dec 2023 06:01:10 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何处理具有大量互斥虚拟变量的有序 logit 模型？</title>
      <link>https://stats.stackexchange.com/questions/635568/how-should-i-deal-with-an-ordered-logit-model-with-numerous-mutually-exclusive</link>
      <description><![CDATA[我试图估计一个有序 Logit 模型，其中 DV 是一个 Likert 量表响应 (1-5)，并且我有 6 个独立的虚拟变量，代表一个观察值是否属于六个互斥聚类之一。例如，如果虚拟 c1 属于簇 1，则它 = 1，否则为 0，对于所有其他簇也是如此。我希望有一个额外的虚拟对象 (h) 与每个簇的效果进行交互，因此模型如下：
ologit y = beta0 + beta1c1 + beta2c1h + beta3c2 + beta5c2h + ... + betac6 + betac6*h
由于该模型的目标是评估属于每个集群的效果，因此出现的问题是必须丢弃一个虚拟对象。我正在考虑克服这个问题的方法，尽管我有点卡住了。虽然我可以为每个集群建立单独的模型，但由于与每个集群相关的分类不平衡，这将导致零膨胀。此外，像看似无关的回归这样的方法似乎不可行，因为这种方法特定于线性（而不是 ologit）模型。
关于如何解决这个问题有什么建议吗？非常感谢提前]]></description>
      <guid>https://stats.stackexchange.com/questions/635568/how-should-i-deal-with-an-ordered-logit-model-with-numerous-mutually-exclusive</guid>
      <pubDate>Sat, 23 Dec 2023 21:52:19 GMT</pubDate>
    </item>
    <item>
      <title>使用元回归输出估计新预测的平均值和预测区间</title>
      <link>https://stats.stackexchange.com/questions/635565/estimating-mean-and-prediction-intervals-for-new-predictions-using-meta-regressi</link>
      <description><![CDATA[让我们从线性回归开始。您开发一个简单的线性回归方程$y = ax + b$。您可以预测 $x_h$ 的 $\hat{y}_h$ 并使用&lt; /p&gt;
$$\hat{y}_h \pm t_{\frac{\alpha}{2}} \times s \times \sqrt{1 + \frac{1} {n} + \frac{(x_h - \bar{x})^2}{\sum_{i=1}^{n}(x_i - \bar{x})^2}}$$ 
让我们继续元回归。假设我们使用元回归来建立方程 $y = a(m - x) + b$。当 $x = x_h$ 时，我们如何估计 $\hat{y}_h$ 的预测区间？
到目前为止，我已经从 Spinelli 和 Pandis (2019) 中找到了这个方程
$M \pm t_{\frac{\alpha}{2},k-2} \times \sqrt{T^2 + V_M}$&lt; /p&gt;
其中 $M$ 是平均效应大小，$T^2$ 是异质性， $V_M$ 是平均效应的方差。
对我来说，这是研究开发的方程的预测区间方程，而不是您在进行预测时应该使用的方程，主要是因为我看不到  在哪里这个方程实际上使用了$x_h$。然而，带有方程的出版物包含这些变量，这让我觉得我遗漏了一些东西。
如果这个方程不正确，有人可以给我提供正确的方程吗？如果像线性回归一样，简单回归和多元线性回归之间存在差异，请提供多元线性回归的方程？
谢谢
另外，对于 LaTex 来说还是个新手，所以如果有人可以帮助解决这个方程，那就太好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/635565/estimating-mean-and-prediction-intervals-for-new-predictions-using-meta-regressi</guid>
      <pubDate>Sat, 23 Dec 2023 20:52:58 GMT</pubDate>
    </item>
    <item>
      <title>PERT 分布族的统计量足够吗？</title>
      <link>https://stats.stackexchange.com/questions/635564/sufficient-statistic-for-the-family-of-pert-distributions</link>
      <description><![CDATA[beta 分布 是以下形式之一
$$
\text{常数}\times x^{\alpha-1} (1-x)^{\beta-1} \, dx \quad \text{ 对于 } 0
根据这篇维基百科文章，“PERT 发行版”家族是重新调整和重新定位 beta分布的分布，其中$$\alpha+\beta=6,$$按常规参数化由支持区间的端点 $a&lt;c$ 和众数 $b.$&lt; /p&gt;
因此分布是
$$
\text{常数} \times (x-a)^{\alpha-1} (c-x)^{\beta-1} \quad \text{for } a
在哪里
\begin{align}
\alpha &amp; = 1 + 4\cdot\frac{b-a}{c-a}, \\[8pt]
\beta &amp; = 1 + 4\cdot\frac{c-b}{c-a}。
\end{对齐}
该分布系列的最小足够统计量是多少？ （这不取决于使用哪种参数化。）]]></description>
      <guid>https://stats.stackexchange.com/questions/635564/sufficient-statistic-for-the-family-of-pert-distributions</guid>
      <pubDate>Sat, 23 Dec 2023 20:24:26 GMT</pubDate>
    </item>
    <item>
      <title>当我应用数据生成器时，RAM 内存不足，GPU RAM 内存不足[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635562/insufficient-ram-memory-insufficient-gpu-ram-memory-when-i-apply-a-data-generat</link>
      <description><![CDATA[我正在训练用于图像分割的 3D Unet 模型，图像采用 nifti 格式，因此它们非常大。
当我尝试加载整个数据集时，我用完了 RAM 内存，因为它太大了，所以我做了一个数据生成器，但现在 GPU RAM 内存耗尽了内存，你们还有其他方法吗？做？我正在考虑云解决方案或者可能使用 apache Spark，但我认为它不适用于计算机视觉]]></description>
      <guid>https://stats.stackexchange.com/questions/635562/insufficient-ram-memory-insufficient-gpu-ram-memory-when-i-apply-a-data-generat</guid>
      <pubDate>Sat, 23 Dec 2023 19:57:49 GMT</pubDate>
    </item>
    <item>
      <title>随机二次方程解的矩和 PDF</title>
      <link>https://stats.stackexchange.com/questions/635560/moments-and-pdf-of-solution-to-random-quadratic-equation</link>
      <description><![CDATA[考虑以下随机二次方程，
$$
x^2 + Z x + Y = 0，
$$
在哪里，
$$
\开始{聚集}
Z \sim \mathcal{N}(\mu_Z,\sigma_Z),
\qquad
Y \sim \mathcal{N}(\mu_Y,\sigma_Y)。
\end{聚集}
$$
解决方案 $x$ 的分布 (PDF) 是什么，时刻是什么？
我对任何可解决的情况或解决方案的近似感兴趣；仅近似前两个时刻就足够了。假设 $Z$ 和 $Y$ 不相关；然而，相关案例的解决方案将会很有趣。]]></description>
      <guid>https://stats.stackexchange.com/questions/635560/moments-and-pdf-of-solution-to-random-quadratic-equation</guid>
      <pubDate>Sat, 23 Dec 2023 19:36:35 GMT</pubDate>
    </item>
    <item>
      <title>社会科学数据中添加高斯噪声</title>
      <link>https://stats.stackexchange.com/questions/635554/gaussian-noise-added-in-social-sciences-data</link>
      <description><![CDATA[在模拟研究中（模拟次数$n=200$），有一个添加高斯噪声模拟的二次/抛物线函数：
y= 4 * (x - 0.5)^2 + rnorm(200, 0, 0.05)

将 $x$ 作为变量，遵循从 $0$ 到  的均匀分布类=“数学容器”&gt;$1$。我的问题涉及添加的高斯噪声 rnorm(200,0,0.05) 以及以下输入：

$n=200$
$\text{mean}=0$
$\text{SD} = 0.05$

提醒一下，标准正态分布（通常称为钟形曲线）的平均值 = $0$ 和标准差 = $1$。
这种类型的高斯噪声是平均值 = $0$ 和标准差 = $0.05$ （很多低于 $1$）可能出现在社会科学数据中？或者我们是否需要 rnorm(200,2,3) 类型的不同高斯噪声，平均值为 $2$，标准差为 &lt; span class=&quot;math-container&quot;&gt;$3$？或高斯噪声的任何其他平均值和任何其他标准差（例如 $5$ 或 $8$ 的平均值）或 $12$，...标准差为 $3, 5, 7,$...) ？
或者说均值和标准差的值在社会科学数据模拟中使用的高斯噪声中没有多大重要性？]]></description>
      <guid>https://stats.stackexchange.com/questions/635554/gaussian-noise-added-in-social-sciences-data</guid>
      <pubDate>Sat, 23 Dec 2023 17:07:47 GMT</pubDate>
    </item>
    <item>
      <title>在制定一组最佳预测变量之前如何减少连续变量的数量（针对女性的握力）</title>
      <link>https://stats.stackexchange.com/questions/635499/how-to-reduce-number-of-continuous-variables-before-i-make-a-set-of-best-predict</link>
      <description><![CDATA[我的作业问题被引用：
”2.哪组变量最能预测女性的握力？
A。在进行分析之前减少连续变量的数量。”
我真的不知道如何减少连续变量的数量。我拥有的变量是：
• Vnr = 受试者编号
• 性别 = 性别（0= 女性，1= 男性）
• Lft = 年龄（岁）
• 狮子座 = 腰围（厘米）
• Sbd1 = 收缩压（毫米汞柱）
• Dbd1 = 舒张压（毫米汞柱）
• Gluc = 葡萄糖（毫克/分升）
• Trig = 甘油三酯（mg/dl）
• Hdl = 高密度脂蛋白胆固醇 (mg/dl)
• Eberoepcal = 期间的能量消耗
职业（卡路里/周）
• Esportcal = 期间的能量消耗
端口（卡路里/周）
• Eavtcal = 期间的能量消耗
休闲时间（卡路里/周）
• PAL = 身体活动水平
• Tkijk = 电视时间（小时/周）。
• BIAP = 通过生物电气的兽医百分比
阻抗 (%)
• RUSTP = rust 中的 hartslag pols (bpm)
• VO2A = 最大耗氧量 -
绝对（升/分钟）
• HGR= 握力（公斤）
因此，首先我可能需要减少那些与“握力”预测/相关性不够的变量，以便在减少连续变量后进行必须要做的分析。
其次，哪种分析最能获得“最佳预测变量集”？
我将通过以下方式解决这个问题；

降维：对连续变量应用降维技术以减少其数量。 -&gt;主成分分析 (PCA)。
预测建模：使用预测建模技术来确定精简后的变量集中哪些变量最能预测握力 (HGR)。 -&gt;多元线性回归。
模型评估：使用适当的指标（例如回归任务的均方误差）和交叉验证技术来评估模型，以确保其预测性能。

任何人都可以确认这一点，或者如果我错了可以优化它吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635499/how-to-reduce-number-of-continuous-variables-before-i-make-a-set-of-best-predict</guid>
      <pubDate>Fri, 22 Dec 2023 13:07:48 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中，如何使用调查数据运行 Spearman 排名相关？</title>
      <link>https://stats.stackexchange.com/questions/620135/in-r-how-can-i-run-a-spearman-rank-correlation-using-survey-data</link>
      <description><![CDATA[我知道，使用调查包来解释复杂的调查数据，我可以使用 jtools 库中的 svycor() 函数来运行 Pearson 相关性。
但是如何对调查设计中的数据进行排名相关性呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/620135/in-r-how-can-i-run-a-spearman-rank-correlation-using-survey-data</guid>
      <pubDate>Fri, 30 Jun 2023 08:45:11 GMT</pubDate>
    </item>
    <item>
      <title>假设有一种算法可以在 D 维空间中的 $D-1$ 球体上绘制点，是否可以在 $D-2$ 球体上均匀地绘制点？</title>
      <link>https://stats.stackexchange.com/questions/618418/is-it-possible-to-uniformly-draw-points-over-a-d-2-sphere-given-that-one-has</link>
      <description><![CDATA[假设我有以下场景：

我知道有一种算法可以从（在本例中）2-球体中均匀地绘制。这个相同的算法是否容易扩展到我随机采取“切割/切片”的情况？ （如上图红色所示）什么点均匀地分布在这个圆上？
此外，假设现在我在任意黎曼流形上有一个均匀随机采样算法。同样的原则是否一定适用？]]></description>
      <guid>https://stats.stackexchange.com/questions/618418/is-it-possible-to-uniformly-draw-points-over-a-d-2-sphere-given-that-one-has</guid>
      <pubDate>Sat, 10 Jun 2023 16:50:32 GMT</pubDate>
    </item>
    <item>
      <title>纠正交互中的多重比较</title>
      <link>https://stats.stackexchange.com/questions/573128/correcting-for-multiple-comparisons-in-interaction</link>
      <description><![CDATA[我有 13 个独立的分层线性回归模型 - 所有模型都有一个作为最后一步输入的交互项（按感兴趣的变量分组）。由于我有 3 个虚拟编码组，因此对于 13 个组中的每一个组，我都有 2 个 p 值（即 A 组（参考组）与 B 组的 p 值，以及 A 组（参考组）与 C 组的 p 值）楷模。我想纠正多重比较，但无法确定需要纠正哪些 p 值。例如，我认为 0.05 / 26 不正确，因为我没有进行 26 次比较（交互步骤一步完成）。除了 bonferroni 修正之外的任何想法/建议将不胜感激。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/573128/correcting-for-multiple-comparisons-in-interaction</guid>
      <pubDate>Tue, 26 Apr 2022 20:48:55 GMT</pubDate>
    </item>
    <item>
      <title>剩余/跳过连接的最大池化与平均池化</title>
      <link>https://stats.stackexchange.com/questions/530044/max-pooling-vs-average-pooling-for-residual-skip-connections</link>
      <description><![CDATA[我已经实现了一个带有跳过连接的 CNN；一些连接跳过没有空间下采样的残差块，但一些连接跳过具有步幅为 2 的卷积的块，因此张量的宽度和高度减半。
目前，我正在使用平均池进行空间下采样，但我想知道使用最大池来传播最高强度特征是否有优势。
我查看了原始的 ResNet 论文，它似乎只详细介绍了连接的特征计数维度变化，而不是空间维度变化，所以我想知道该领域是否有任何新的工作比较这两种池化技术资源网。]]></description>
      <guid>https://stats.stackexchange.com/questions/530044/max-pooling-vs-average-pooling-for-residual-skip-connections</guid>
      <pubDate>Wed, 09 Jun 2021 17:48:24 GMT</pubDate>
    </item>
    <item>
      <title>可能性如何衡量拟合的优度？</title>
      <link>https://stats.stackexchange.com/questions/506714/how-does-the-likelihood-measures-the-goodness-of-a-fit</link>
      <description><![CDATA[可能性：
&lt;块引用&gt;
在统计学中，似然函数（通常简称为似然）衡量统计模型与给定未知参数值的数据样本的拟合优度。

我不明白这个似然函数：
$$LH = \prod q_i^{Np_i} \hspace{1em} (1)$$
$q_i$ 是使用某种模型估计的概率，$p_i$ 是经验概率（来自训练集）。 $N$ 令人困惑，但这只是我们要求 $i$ 的次数。
现在，这到底应该如何使用？假设我们使用某个函数得到 $q_i$，假设猫的 $0.88$，$0.12$ 对于非猫，
$$LH = 0.88^{p_{cat}}\hspace{1em}(2)$$
如果还要求 2 只猫和 1 只非猫：
$$LH(cat,nocat) = 0.88^{2*p_{cat}}*0.12^{1*p_{nocat}} \hspace{1em}$$ 
但是其余部分到底是如何计算的，更重要的是，如何解释的？]]></description>
      <guid>https://stats.stackexchange.com/questions/506714/how-does-the-likelihood-measures-the-goodness-of-a-fit</guid>
      <pubDate>Wed, 27 Jan 2021 04:13:33 GMT</pubDate>
    </item>
    </channel>
</rss>