<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 02 May 2024 12:26:23 GMT</lastBuildDate>
    <item>
      <title>基于多个变量创建具有相似值的两个组</title>
      <link>https://stats.stackexchange.com/questions/646352/create-two-groups-with-similar-values-based-on-multiple-variables</link>
      <description><![CDATA[我想创建两个大小相等的组。我想根据利润、销售额和收入的类似值对我的 ID 进行分组。
我的数据看起来像这样：
ID周利润销售收入
1 1 50 10 30
1 2 59 15 34
......
2 1 5 1 3
....

如果我想绘制我的两个组（例如绘制收入），则绘图应尽可能相似，可能会重叠。我有 1200 个数据点，数据显示为周 (1-54)。请注意，我不想要只有两个相同规模的组，但就像我所说的在利润、收入和销售额方面类似。我用的是rstudio。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646352/create-two-groups-with-similar-values-based-on-multiple-variables</guid>
      <pubDate>Thu, 02 May 2024 12:18:58 GMT</pubDate>
    </item>
    <item>
      <title>使用相关系数对数据进行采样[关闭]</title>
      <link>https://stats.stackexchange.com/questions/646345/using-correlation-coefficient-to-sample-data</link>
      <description><![CDATA[假设我有两个变量 A 和 B，它们都有不同的分布。
我知道这两个变量存在一定程度的相关性（-1 到 1 之间的任何值）。
我随机采样了变量 A（例如给出第 70 个百分位数）。我现在想知道在给定 A 样本和相关性的情况下从哪里对变量 B 进行采样 - 是否有执行此操作的公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/646345/using-correlation-coefficient-to-sample-data</guid>
      <pubDate>Thu, 02 May 2024 10:59:05 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tweedie 分布进行方差分解 – 需要反向变换吗？</title>
      <link>https://stats.stackexchange.com/questions/646344/variance-decomposition-with-tweedie-distribution-back-transform-necessary</link>
      <description><![CDATA[我们正在运行一个分层随机截距模型，其中包含 Tweedie 分布因变量（见下文）和三个层次结构。我们的目标是估计层次结构的每个级别解释了多少总方差（以百分比为单位）。我们通过估计层次结构每个级别的随机截距的方差，然后将其除以总方差来实现此目的。
因变量服从 Tweedie 分布（连续、零膨胀、右偏）。随机截距的先验是正态分布，我们估计其方差。鉴于我们对 DV 使用 Tweedie 分布，我们是否需要对各个随机效应的方差估计进行反向变换或逆变换，以正确估计解释的方差份额，或者不需要反向变换？
请注意，我们没有像 Tweedie 分布中经常使用的那样在模型中使用日志链接函数。 Tweedie 分布的平均值只需添加几个变量即可确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/646344/variance-decomposition-with-tweedie-distribution-back-transform-necessary</guid>
      <pubDate>Thu, 02 May 2024 10:39:20 GMT</pubDate>
    </item>
    <item>
      <title>在多级 cfa 中，因子得分解释的方差小于项目均值</title>
      <link>https://stats.stackexchange.com/questions/646343/factor-scores-explain-less-variance-than-item-means-in-a-multilevel-cfa</link>
      <description><![CDATA[我在拉万针对重复测量问卷数据（对旅行量表的满意度）进行了多级 CFA。 42 名参与者在自然多式联运旅行后平均进行了约 9 次测量（不平衡）。
该调查问卷希望将旅行满意度作为一个包含三个子因素的分层模型来衡量：积极停用（高价低唤醒）、积极激活（高价、高唤醒和认知评估）。每个因素在 1 到 3 个项目上进行测量7.
整体模型拟合度不错，所有局部拟合统计数据均显着且令人满意
对于内部模型，潜在变量的层次结构提供了最少的不良拟合
对于中间模型，与 2 或 3 个因素相比，1 个因素结构提供的不良拟合最少，但层次结构没有正确收敛。
我将内部潜在变量解释为对特定旅行的满意度（正如预期的那样，因为因子结构提供了适当的拟合）。
但由于模型之间是一个单因子结构，并且协方差矩阵内部和之间的汇集是独立构建的，因此我会将模型之间的潜在变量解释为总体评分倾向，而不是对旅行的平均/稳定满意度。
我使用 lavpredict() 计算了因子得分之内和之间
支持我的解释，神经质（用 2 个项目测量，bfi10）解释了潜在变量因子得分之间 20% 的方差。
在所有旅行中，旅行持续时间和旅行满意度之间没有显着关系。无论是我们的内部潜在变量分数还是平均项目分数 (n=400)
当我们只考虑路线大致相同的行程时（n=132），这种关系就变得很重要（但非常小）。
但有趣的是，行程持续时间解释了平均项目得分 (R2=.076) 的方差比内部潜在变量得分 (R2=.028) 的方差更大。
我认为随着内部满意度变量的潜在变量得分，这种关系会变得更强。如果我创建一个新变量，在分数之间添加分数，则 R2 变为 0.076，作为平均项目分数。
您如何解释这里发生的事情？我知道这种关系非常小，但是一般评级倾向会增加这种关系是否有意义？旅行持续时间不能解释内部因子得分比项目得分平均值更大的方差，这是一个坏兆头吗？这个话题非常抽象，所以我很想知道对此的不同看法。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646343/factor-scores-explain-less-variance-than-item-means-in-a-multilevel-cfa</guid>
      <pubDate>Thu, 02 May 2024 10:26:18 GMT</pubDate>
    </item>
    <item>
      <title>仅依靠高度不平衡测试集的混淆矩阵来评估模型性能是一个坏主意吗？</title>
      <link>https://stats.stackexchange.com/questions/646341/is-relying-on-just-the-confusion-matrix-for-highly-imbalanced-test-sets-to-evalu</link>
      <description><![CDATA[我有一个二元分类模型，其测试集高度倾斜，多数类 0 比少数类 1 大 22 倍。
这导致我的 Precision 较低，Recall 较高，但总体 F1 得分较差。只用混淆矩阵来评估模型的性能可以吗？
根据我的观察，混淆矩阵上的性能看起来并不差。我使用 BalancedRandomForestClassifier 为我的测试集取得了这些结果：
0 级： 8941 / 11061 预测正确
第 1 类： 476 / 522 预测正确
如果我提高概率阈值，我可以降低 FP 率，但代价是 FN 略有增加。 我想知道在这种情况下，是否可以依赖混淆矩阵。]]></description>
      <guid>https://stats.stackexchange.com/questions/646341/is-relying-on-just-the-confusion-matrix-for-highly-imbalanced-test-sets-to-evalu</guid>
      <pubDate>Thu, 02 May 2024 09:39:00 GMT</pubDate>
    </item>
    <item>
      <title>VCA（Day、Lot、Operatore）嵌套的正确方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/646340/whats-the-correct-way-to-nest-for-vca-day-lot-operatore</link>
      <description><![CDATA[我有一个正在研究的数据集，我通常很擅长统计数据，但我越看这个，我就越质疑自己。
因此，我对由两名不同操作员使用两批试剂在 4 天内测量的分析物进行了测量，一式三份。
我使用 VCA 是因为我需要遵守 CLSI 指南，而且我还看过其他示例。
我的问题是最合适的嵌套是什么。
当我这样做时：
anovaVCA（分析物〜（批次+操作员）/天，df）

从嵌套的角度来看，这在我看来是有道理的，但它产生的结果我很难解释。
&lt;前&gt;&lt;代码&gt; 名称 DF SS MS VC % 总 SD CV[%]
1 总计 31.2048 0.7332 100 0.8563 17.3991
2 批次 1 0.8217 0.8217 0* 0* 0* 0*
3 操作员 1 1.7927 1.7927 0.028 3.8234 0.1674 3.4021
4 批次：操作员：第 13 天 14.5582 1.1199 0.2073 28.2789 0.4554 9.2525
5 错误 32 15.9306 0.4978 0.4978 67.8977 0.7056 14.3369

平均值：4.9214（N = 48）


从数据中可以明显看出，当天是变化的最大来源，但这是否是显示这一点的最佳方式？]]></description>
      <guid>https://stats.stackexchange.com/questions/646340/whats-the-correct-way-to-nest-for-vca-day-lot-operatore</guid>
      <pubDate>Thu, 02 May 2024 09:34:40 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用 FEGLM 固定效应概率</title>
      <link>https://stats.stackexchange.com/questions/646337/fixed-effects-probit-using-feglm-in-r</link>
      <description><![CDATA[我使用 R 中的 feglm 包并包含单独的固定效应。
代码：feglm(y ~ x|z, family = binomial(link=&quot;probit&quot;)
这可行吗？我在文献中找不到固定效应概率的任何理由？
祝好，
Marco]]></description>
      <guid>https://stats.stackexchange.com/questions/646337/fixed-effects-probit-using-feglm-in-r</guid>
      <pubDate>Thu, 02 May 2024 09:17:08 GMT</pubDate>
    </item>
    <item>
      <title>回归的选择</title>
      <link>https://stats.stackexchange.com/questions/646347/choice-of-regression</link>
      <description><![CDATA[我正在做一个项目，我正在尝试找出要使用哪种类型的回归。我有一个数据集，其中包含大约 10000 个观察值和 7 个变量。它是客户支付发票时的数据，因此每个观察结果都是一张发票。我有以下变量：
客户姓名
货币
状态
关闭
行业
发票金额
付款条件
除 InvoiceAmount 和 ClosingDate 之外的所有变量都是因子变量。例如，NameOfCustomer可以是“Apple”，货币“Dollar”，州可以是“Alaska”，“Industry”等等。可以是技术，付款期限可以是 15、30 或 60 天。如果发票已在到期日支付，则“已关闭” = 0。如果发票迟付 2 天，则“关闭” = -2 并且如果提前 2 天付款，则“关闭” = 2.我想生成一个模型，其中“Closed”是响应变量，其他是回归变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/646347/choice-of-regression</guid>
      <pubDate>Thu, 02 May 2024 09:02:41 GMT</pubDate>
    </item>
    <item>
      <title>纵向设计中的加权程序</title>
      <link>https://stats.stackexchange.com/questions/646336/weighting-procedure-in-longitudinal-design</link>
      <description><![CDATA[我目前正在尝试弄清楚该怎么做，但似乎找不到合适的解决方案。我的问题如下：我有纵向设计。对于每一天，我都有一个变量说明事件是否发生（1）或未发生（0），以及一个以 5 点李克特量表回答的变量。该评估主要通过电话完成（生态瞬时评估）。不幸的是，有时手机坏了，参与者用纸笔表格填写不同的变量。这意味着现在我只对少数参与者进行了几天的评估，没有电话，只有纸质评估。我想看看是否可以将这些评估方法合并到 1 个数据集中。这意味着：根据评估方法，问题的答案是否有所不同？但我有几个困难：首先，我的纸质评估屈指可数。其次，我有 4 个组，它们的评估期长度不同（有些有 16 天，有些有 24 天）。第三，我为参与者安排了不同的缺席天数。有的电话评估只缺失一两天，有的甚至更长。当手机丢失时，只有少数人有纸质表格，因此该时期的纸质表格也不完整。
我想看看逆概率加权是否可行。我知道，在对合并样本进行加权后，我可以使用一般线性模型（当我计算所有天的概率或平均值时）或广义估计方程（当每天都有单个条目时）。
我想知道这是否正确，以及在使用加权程序时是否有其他可能性来比较评估方法。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646336/weighting-procedure-in-longitudinal-design</guid>
      <pubDate>Thu, 02 May 2024 09:00:25 GMT</pubDate>
    </item>
    <item>
      <title>模拟随机过程以检查平稳性</title>
      <link>https://stats.stackexchange.com/questions/646335/simulation-of-random-processes-to-check-stationarity</link>
      <description><![CDATA[我想知道这是否是一种有效的方法：
我想通过模拟验证某些随机过程不是弱平稳的（均值恒定，协方差取决于滞后，有限方差）；不一定需要极其严格的程序，但至少需要建立直觉。
我知道使用像 ADF 这样的单位根测试，我不确定它是否一定是平稳性的综合测试。
Python 中的 Statsmodel 具有允许您为 arma 模型提供参数并生成时间序列的函数。对于每个过程，我想生成 10,000 个长度为 1000 的时间序列，具有较短的季节性，例如每 5 个点。
（这是否是查看随机过程属性、从生成器生成集合并查看其属性的有效起点？）
我正在尝试的一些流程包括

纯季节性 ARMA（无单位根）
混合季节性 ARMA（无单位根）
生成确定性正弦波和 ARMA 序列，并将它们相加。
生成确定性正弦波和 ARMA 序列，并将它们相乘。

然后我可以做一个整体均值来看看均值是否恒定；如果它不是恒定的，那么它可能不是弱平稳的。
如果平均值看起来恒定，那么我会查看自协方差；但我不确定这是如何工作的。计算序列自协方差的公式似乎取决于该序列弱平稳的假设，但这就是我想要证明的。
&lt;小时/&gt;
同样回到平均值，我确实看了一些例子：
对于确定性正弦波 + 平稳 AR(1) 的情况，整体平均值往往如下所示，这显然不是整个时间的恒定平均值。


但是对于没有单位根的纯季节性 ARMA；
如果我有
$x_{t}=0.7x_{t-5}+w_{t}, \sigma=1$
或者
$x_{t}=0.7x_{t-7}+w_{t}, \sigma=1$
集成均值如下图所示，看起来有所不同，但值非常小；有没有办法判断这个？

]]></description>
      <guid>https://stats.stackexchange.com/questions/646335/simulation-of-random-processes-to-check-stationarity</guid>
      <pubDate>Thu, 02 May 2024 08:22:33 GMT</pubDate>
    </item>
    <item>
      <title>如何在统计检验中进行 p 调整？</title>
      <link>https://stats.stackexchange.com/questions/646333/how-do-i-do-the-p-adjustement-in-statistical-tests</link>
      <description><![CDATA[背景：一项关于哪种类型的面包和/或馅料最吸引蚂蚁的研究
我有一个包含 3 列的表格：吸引的蚂蚁数量、面包类型、馅料类型。问题是：做测试看看蚂蚁的数量是否存在差异。
所以首先我做了一些预测试来检查正态性，然后检查方差相等性。然后用单向方差分析来检查一般差异，填充组有显着差异，为了看看精确度，我做了成对 t 检验。
所以问题是：这就足够了吗？如果是，我该如何进行 p 调整？
额外问题：测试应该针对自变量，对吗？因为在一个步骤中，我只是比较面包类型，然后只是比较馅料类型。]]></description>
      <guid>https://stats.stackexchange.com/questions/646333/how-do-i-do-the-p-adjustement-in-statistical-tests</guid>
      <pubDate>Thu, 02 May 2024 07:28:16 GMT</pubDate>
    </item>
    <item>
      <title>比较离散数据的均值</title>
      <link>https://stats.stackexchange.com/questions/646304/compare-means-for-discrete-data</link>
      <description><![CDATA[我有两组观察结果，分别对应于两位不同希腊作者的短指六音步单词数。直方图具有漂亮的钟形形状，但数据不正常：一首诗中只能有离散数量的单词。它也不是泊松分布：方差小于均值（根据经验，一节经文不少于 4 个单词且不超过 12 个单词）。

有哪些方法可以比较两种均值以确定它们是否显着不同？
我正在考虑使用卡方来比较 2 个分布，但是这样，我们似乎将 5 字行和 6 字行视为分类数据（这并非完全没有意义，但很尴尬）。
另一种选择是计算每 n 行（例如 5 行）的均值，然后应用 z 检验或 t 检验（通过中心极限定理）。
然而，这两种解决方案似乎都有些牵强。有更优雅的解决方案吗？
更新。根据下面评论的建议，我添加了 Shapiro 测试的结果和 qq-plot。
a) Agronautica 样本返回的 Shapiro-Wilk 正态性检验
W = 0.94682，p 值 = 2.056e-12；对于《伊利亚特》样本 -- W = 0.95116，p 值 = 8.582e-12
b) 两个样本的 QQ 图看起来相似：

upd2：添加每个样本的计数表（第一行是一首诗中的单词数）
iliad_sample
4 5 6 7 8 9 10 11 12
13 33 115 128 124 69 13 3 2
argo_样本
4 5 6 7 8 9 10 11
22 67 136 149 85 32 7 2]]></description>
      <guid>https://stats.stackexchange.com/questions/646304/compare-means-for-discrete-data</guid>
      <pubDate>Wed, 01 May 2024 19:07:14 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该将数据解释为噪音</title>
      <link>https://stats.stackexchange.com/questions/646300/should-i-interprete-data-as-noise-or-not</link>
      <description><![CDATA[我正在解决 3 个类别的分类问题。以下是这些类在前两个主轴上的样子。

我对 SVM 模型进行了微调，可实现的最佳性能为 50%。通过始终预测 3 个类别中的一个，我达到了 43%。我的问题是：

因为我（用眼睛）清楚地看到数据是线性可分离的 - 即使有噪音并且 SVM 的性能不再增加，任何其他方法（如 NN 或 Tree）是否可以取得更好的分数？或者即使它们也不会优于 SVM。
如果没有，您认为有没有办法在不修改数据统计属性的情况下减少数据中的噪音？

编辑：在 whuber 回复后，我根据前两个主轴绘制了密度。我注意到这些类在输入空间维度上并不是那么可分离。
]]></description>
      <guid>https://stats.stackexchange.com/questions/646300/should-i-interprete-data-as-noise-or-not</guid>
      <pubDate>Wed, 01 May 2024 18:28:36 GMT</pubDate>
    </item>
    <item>
      <title>渐近无偏+渐近零方差=一致性？</title>
      <link>https://stats.stackexchange.com/questions/646259/asymptotic-unbiasedness-asymptotic-zero-variance-consistency</link>
      <description><![CDATA[此处，Ben 表明无偏估计量 $\hat渐近方差为零的参数 $\theta$ 的 \theta$ 收敛于 $ 的概率\theta$。也就是说，$\hat\theta$ 是 $\theta$ 的一致估计量。
我们应该能够将条件放宽到渐近无偏性，这是有道理的：$\underset{n\rightarrow\infty}{\lim} \mathbb E\left[\hat\theta_n - \theta\right] = 0$。这似乎符合估计器接近真实参数值的精神......
...但是数学以前就让我感到惊讶。
我们可以将条件放宽到渐近无偏吗？证据是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/646259/asymptotic-unbiasedness-asymptotic-zero-variance-consistency</guid>
      <pubDate>Wed, 01 May 2024 00:32:23 GMT</pubDate>
    </item>
    <item>
      <title>是否有可能根据现实世界的观测数据来评估因果算法？</title>
      <link>https://stats.stackexchange.com/questions/646243/is-it-possible-to-evaluate-causal-algorithms-on-real-world-observational-data</link>
      <description><![CDATA[很多时候，我被要求使用因果算法（例如估计干预结果的算法，或一般的因果推理算法），并将它们与现实世界观测数据的非因果预测算法进行比较，而无需任何额外的知识。是否可以对真实数据进行定量评估（例如评估拟合的 $R^2$）因果算法？比较因果算法与非因果算法有意义吗？您能否提供或指出一个示例（也可以是合成的，可能包含连续数据）来支持您的答案？
&lt;小时/&gt;
剧透：这里按照我的想法作为正确答案，但我仍然希望得到确认或证明我错了。
我对此的想法如下：我认为这是不可能的，因为我们要么需要因果 DAG 的知识，要么我们需要干预数据，而不是观察数据。因此，我认为评估因果算法与非因果算法的唯一方法是基于合成数据，并且一旦合成示例被证明可以在因果模型中工作，而不是在非因果模型中工作。然后，唯一要做的就是为手头的任务使用正确的算法：“假设”的因果算法或干预场景，非因果场景用于简单预测场景。我还认为，如果根据非因果度量进行评估，例如 $R^2$ 评估，非因果模型在大多数情况下会过度执行因果模型一些预测的拟合度，因为它们是专门为此设计和优化的。]]></description>
      <guid>https://stats.stackexchange.com/questions/646243/is-it-possible-to-evaluate-causal-algorithms-on-real-world-observational-data</guid>
      <pubDate>Tue, 30 Apr 2024 20:42:22 GMT</pubDate>
    </item>
    </channel>
</rss>