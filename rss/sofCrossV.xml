<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 19 May 2024 03:17:07 GMT</lastBuildDate>
    <item>
      <title>了解 ARMA 模型拟合</title>
      <link>https://stats.stackexchange.com/questions/647536/understanding-arma-model-fit</link>
      <description><![CDATA[我使用 python 中的 statsmodels 将 ARMA(1,1) 模型拟合到单变量数据系列，并且得到了看似非常显着的拟合。
&lt;块引用&gt;
对数似然：200,000

&lt;块引用&gt;
AIC/BIC/HQIC：-400,000

&lt;块引用&gt;
AR.L1：0.1（z 45）

&lt;块引用&gt;
MA.L1：-0.09 (z -45)

&lt;块引用&gt;
sigma2：z：200

但我收到一条警告，指出 cov 矩阵接近奇异，条件号为 2e16

几乎相等且相反的 AR 和 MA 系数是否表明存在问题？
它指的是哪个协方差矩阵？
我如何整体解读这些结果 - 尤其是超高 AIC/BIC 等。
sigma2 的高 z 分数 - 是否只是说明残差明显不正常。 AIC 高有关系吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/647536/understanding-arma-model-fit</guid>
      <pubDate>Sun, 19 May 2024 01:32:24 GMT</pubDate>
    </item>
    <item>
      <title>如何使用多元线性回归来预测有意义的值</title>
      <link>https://stats.stackexchange.com/questions/647535/how-to-use-a-multi-linear-regression-to-forecast-meaningful-values</link>
      <description><![CDATA[我构建了一个基于两个预测变量 $P_1$ 和 $P_2$ 的多线性回归模型预测$Q$：
$$
q = A + Bx_1 + Cx_2 + Dx_1^2 + Ex_2^2 + Fx_1*x_2
$$
其中 $x_1$ 和 $x_2$ 是原始预测变量的标准化和去趋势版本 &lt; span class=&quot;math-container&quot;&gt;$P_1$ 和 $P_2$ ($P_1$ span&gt; 和 $P_2$ 有趋势）。我假设 $q$ 是 $Q$ 的预测标准化/去趋势值。回归模型对于我的需要具有统计显着性。
问题：如何使用上面的 MLR 来估计 $Q$ 的值？换句话说，如何从 $q$ 返回到 $Q$ ？如果是这样，我是否需要对我的预测变量进行标准化和去趋势化？]]></description>
      <guid>https://stats.stackexchange.com/questions/647535/how-to-use-a-multi-linear-regression-to-forecast-meaningful-values</guid>
      <pubDate>Sun, 19 May 2024 00:48:55 GMT</pubDate>
    </item>
    <item>
      <title>拉斯穆森方程 5.9</title>
      <link>https://stats.stackexchange.com/questions/647532/rasmussen-equation-5-9</link>
      <description><![CDATA[任何人都可以添加显示 Rasmussen 如何从方程 5.9 的第 1 行到第 2 行的步骤。 （第 114 页）？它正在计算对数似然的梯度。
\begin{方程}
\开始{对齐}
\frac{d}{d\theta_j} \log p(y|X, \theta) &amp;= \frac{1}{2}y^TK^{-1}\frac{dK}{d\theta_j} K^{-1}y - \frac{1}{2}\text{tr}(K^{-1}\frac{dK}{d\theta_j})\\
&amp;= \frac{1}{2}\text{tr}\Bigl((\alpha\alpha^T-K^{-1})\frac{dK}{d\theta_j}\Bigl)
\结束{对齐}
\end{方程}
其中：$\alpha=K^{-1}y$ 和 $K$ 是PSD]]></description>
      <guid>https://stats.stackexchange.com/questions/647532/rasmussen-equation-5-9</guid>
      <pubDate>Sun, 19 May 2024 00:20:57 GMT</pubDate>
    </item>
    <item>
      <title>如何估计可行的广义变量误差模型（结合戴明回归/TLS 和 f-广义最小二乘法）</title>
      <link>https://stats.stackexchange.com/questions/647531/how-to-estimate-a-feasible-generalized-error-in-variable-model-combine-deming-r</link>
      <description><![CDATA[我有具有空间结构的观测数据。假设的数据集可能是 100 种鸟类的脑质量和同一物种的体重。这些数据具有空间结构，因为它们沿着进化树的路径随时间共同进化，使得相关物种的错误更加相似。通常还存在与空间结构无关的显着白噪声。
因为这是观察数据，所以我想解释这两个特征中的错误，并允许这两个错误具有不同空间结构的可能性。即使底层空间结构相同，一个特征的误差可能主要来自白噪声，而另一个特征的误差则几乎没有白噪声。
但是，我在开发变量错误戴明式回归时遇到了麻烦。我的问题是这样的。我已经知道我必须指定两个误差的显式方差或至少它们的比率，但是我还需要指定白噪声的相对量吗？如果我的空间结构由 $\Sigma$ 描述，而我的白噪声由 $I_{n}$ 描述（其中 I 是 n x n 单位矩阵），因此特征一的总误差方差为 $\sigma_{1a}^{2}\Sigma+\sigma_{1b}^{2}I $ 并且对于特征 2 来说是 $\sigma_{2a}^{2}\Sigma+\sigma_{2b}^{2}I$，我可以吗只需指定比率 $(\sigma_{1a}^{2}+\sigma_{1b}^{2})/(\sigma_{2a}^{2} +\sigma_{2b}^{2})$ 然后拟合 $\sigma_{1a}^{2}$, $\sigma_{1b}^{2}$, $\sigma_{2a}^{2}$, $\sigma_{2b}^{2}$ 使用可行的广义最小二乘法（或其他技术）之类的技术？或者是否还需要指定这些方差修改器，以便成功地将变量误差回归模型拟合到具有可能不同的误差空间结构的观测数据？
如果有帮助，我非常乐意首先对数据进行日志转换（因为这样做有很大的生物学动机，而且我知道 log(error) 可能比未转换的错误表现得更好。]]></description>
      <guid>https://stats.stackexchange.com/questions/647531/how-to-estimate-a-feasible-generalized-error-in-variable-model-combine-deming-r</guid>
      <pubDate>Sun, 19 May 2024 00:19:03 GMT</pubDate>
    </item>
    <item>
      <title>SVM 内核将直方图作为输入向量进行比较</title>
      <link>https://stats.stackexchange.com/questions/647529/svm-kernel-to-compare-histograms-as-input-vectors</link>
      <description><![CDATA[在 Andrew Ng 的 CS229 第 7 讲中，他在最后提到了一个特定的内核，该内核允许 SVM 对数据进行“分类”。两个直方图的相似程度，例如两个国家的人口统计数据。他描述说“内核取两个直方图的最小值并将它们相加”。
以下是他提到这一点的时间戳的讲座视频：youtube 链接
有人知道他指的是哪个内核或者有关于这个主题的任何资源吗？预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647529/svm-kernel-to-compare-histograms-as-input-vectors</guid>
      <pubDate>Sat, 18 May 2024 23:32:08 GMT</pubDate>
    </item>
    <item>
      <title>时间序列平方预测评估</title>
      <link>https://stats.stackexchange.com/questions/647523/time-series-squared-forecast-evaluation</link>
      <description><![CDATA[我有一个自相关性非常弱的时间序列 - 大部分是不可预测的。然而，其平方值具有更强的自相关性。像这样的事情：
idx = pd.date_range(&#39;2020-01-01&#39;, &#39;2023-12-31&#39;)
y = pd.DataFrame(索引= idx, 数据=[0]*len(idx))
对于 t，i 枚举（idx）：
    如果 t&gt;1：
        y.loc[i] = np.sign(np.random.random_integers(-500000,500000))*(0.01*y.loc[idx[t-1]]+0.005*y.loc[idx[t-2] ]]) + np.random.randn()

考虑到平方值的可预测性，我使用简单的 EWMA 来预测它们。
我通过测量我的预测平方移动与在完整样本平均值和滚动基础上实现的距离有多远来评估预测的质量。此外，我还在研究异常值有多大。
在评估 EWMA 样本的不同回溯窗口的预测后，我观察到一些对我来说不太直观的行为：
&lt;前&gt;&lt;代码&gt;roll_window = 60
评估 = {}
对于范围 (1,100) 内的 com：
    sq_fcst = (y ** 2).ewm(com).mean().shift(1)
    x = ((y**2) / sq_fcst).replace(-np.inf, np.nan).replace(np.inf, np.nan)
    roll_x = np.sqrt((x).rolling(roll_window).mean())
    full_dev = np.sqrt((x).mean())[0]-1
    roll_dev = np.sqrt(((roll_x - 1)**2).mean()[0])
    异常值 = np.percentile(x.abs().dropna().values, 99)

    eval[com] = {&#39;full_dev&#39;：full_dev，&#39;rolling_dev&#39;：rolling_dev，&#39;离群值&#39;：离群值}

pd.DataFrame(eval).T.plot(secondary_y = &#39;异常值&#39;)


在这里您可以看到滚动偏差在 com=10 附近有最小值，但随后开始增加。
然而，full_dev 和异常值确实在持续减少。
我认为，正如我的预测，通过接近全样本平方平均值，预计全样本偏差将继续减少，因为平均值使平方偏差最小化。但是，我不确定为什么滚动版本会更早出现最小值，以及为什么异常值会继续减少。]]></description>
      <guid>https://stats.stackexchange.com/questions/647523/time-series-squared-forecast-evaluation</guid>
      <pubDate>Sat, 18 May 2024 19:16:47 GMT</pubDate>
    </item>
    <item>
      <title>通过与经验规则相关的不断演变的时间序列数据集中每个新价格值的概率来确定相对稀有性的最佳方法</title>
      <link>https://stats.stackexchange.com/questions/647522/best-way-to-determine-relative-rarity-through-probability-of-each-new-price-valu</link>
      <description><![CDATA[我正在处理股票市场时间序列数据，我会在不同的时间跨度（通常是 2-8 天的长度）内以 30 分钟为间隔查看数据片段。我用起点和终点标记了不同的历史片段（在特定股票内），以作为模型数据集或数据集的形式。许多这些细分创建的分布具有厚尾并且往往是非正态的。我想尝试确定当当前股价每天都在变化时，每个新数据值的相对罕见程度。当我分析当前不断变化的股票价格时间序列时，我会确定一个片段的起始地点/时间段，并最终确定未来日期（通常是 2-8 天后）的结束地点。就经验规则之类的东西而言，在我确定了一个片段的起始地点/时间段之后，当然不会有完整的分布，直到将来，当我的片段结束的标准得到满足并从而实现时，通常是2-8天后。每个新的价格周期到来（一项创新）并以更高的样本量更新细分市场。在这个不断发展的分布/开发过程中，是否有一种实用或有用的方法来确定每个创新/新值在标准差或其他概率方法方面的相对罕见程度？我知道 68/95/99.7% 经验规则适用于正态分布，并且当您有完整的数据集/分布向后看时使用。不过，一开始我会保持前瞻性。如果我通过创建 z 分数（使用标准差和平均值）来标准化每个新的价格创新，则该 z 分数必须计算为某个固定窗口大小的向后移动窗口标准差，该窗口使用过去的数据，直到如果窗口向前移动足以到达我开始该片段的位置。为了尝试确定稀有性，我通常会查看价格周期之间相对于（差异价格）移动窗口标准差的百分比差异，以尝试确定每个周期的标准差有多少。这是我有两个问题。对于这个稀有度测试，我应该使用 z 分数（值平均值）/标准差吗？或者简单地创建一个通过除以值/标准差来计算的单位方差标准化而不用担心（值均值）是否可行？我的第二个问题是，是否有更好的方法来确定每项新创新的相对罕见程度，因为在未来某个日期之前都没有完整的分发？]]></description>
      <guid>https://stats.stackexchange.com/questions/647522/best-way-to-determine-relative-rarity-through-probability-of-each-new-price-valu</guid>
      <pubDate>Sat, 18 May 2024 19:16:17 GMT</pubDate>
    </item>
    <item>
      <title>如何让 ORB、SSIM、VGG16 等方法根据图的区域检查相似率？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647507/how-can-i-have-methods-such-as-orb-ssim-vgg16-check-the-similarity-rate-accord</link>
      <description><![CDATA[我有一个空图，只有轴，如图所示：
空图表
从数学上讲，该图由 4 部分组成（四部分）。尽管绘制的图在角度、大小等方面相同，但它们具有不同的数学值。举个例子，我有 4 张不同的图像。我在图表的 4 个不同区域中绘制了相同的角度和相同的尺寸（四个不同的图片同一帧）并将第一个区域绘制的图形与其他三个区域进行比较，假设答案。通常情况下，老师在评分时会给其他3张打低分，但这里的ORB SSIM和VGG16方法会看图纸整体上是否相同大小和相同角度，并给出较高的相似率。另外，我希望它注意他绘制的区域，因为在不同区域绘制的图表的结果将是错误的，因此该人将获得较低的分数。如何让 ORB、SSIM、VGG16 等方法根据图的区域检查相似率？]]></description>
      <guid>https://stats.stackexchange.com/questions/647507/how-can-i-have-methods-such-as-orb-ssim-vgg16-check-the-similarity-rate-accord</guid>
      <pubDate>Sat, 18 May 2024 15:05:47 GMT</pubDate>
    </item>
    <item>
      <title>轻松估计标准误差[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647502/estimate-standard-errors-effortlessly</link>
      <description><![CDATA[我有一个未观察到的变量 $𝑧_𝑖$，以及它的三个观察到的估计值：$𝑤_𝑖、𝑥_𝑖、𝑦_𝑖$ 。误差 $𝑤_𝑖−𝑧_𝑖,𝑥_𝑖−𝑧_𝑖,𝑦_𝑖−𝑧_𝑖$ 为零均值，彼此独立且在  之间独立$𝑖$，但 $𝑖$ 之间的分布是相同的（尽管不一定在 $𝑤$ 之间） 、$𝑥$ 和 $𝑦$）。如果我有 $𝑁$
观察值 ($𝑖=1,…,𝑁$)，如何估计 $𝑤$ 的标准误差span&gt;、$𝑥$ 和 $𝑦$？
$W$ 和 $X$ 之间的差异的方差为 $\textrm{Var}(W-X) = \textrm{se}^2_W + \textrm{se}^2_X$ 在上述设置下，当  $N\rightarrow \infty$ 其中 $\textrm{se}$ 代表标准错误。这同样适用于“$X$”和“$Y$”和“$Y$ 和 $W$”。
所以我们有
$$
\开始{对齐}
\textrm{Var}(W-X) &amp;= \textrm{se}^2_W + \textrm{se}^2_X, \\
\textrm{Var}(X-Y) &amp;= \textrm{se}^2_X + \textrm{se}^2_Y,\\
\textrm{Var}(Y-W) &amp;= \textrm{se}^2_Y + \textrm{se}^2_W。
\结束{对齐}
$$
差异的方差（左侧）可以根据观察到的数据计算出来。该方程组是否提供标准误差的解？]]></description>
      <guid>https://stats.stackexchange.com/questions/647502/estimate-standard-errors-effortlessly</guid>
      <pubDate>Sat, 18 May 2024 14:27:38 GMT</pubDate>
    </item>
    <item>
      <title>无意识统计学家的条件期望定律和条件分布的前推测度</title>
      <link>https://stats.stackexchange.com/questions/647498/law-of-the-unconscious-statistician-for-conditional-expectation-and-pushforward</link>
      <description><![CDATA[设 $(\Omega, \mathcal{A}, \mathbb{P})$ 为概率空间，$X:\Omega\rightarrow\mathcal{X}$ 和 $Z:\Omega\rightarrow\mathcal{Z}$ 两个随机变量。无意识统计学家定律的无条件版本是
$$\mathbb{E}[g(X)]=\int_{\Omega}g(X)(\omega)\mathbb{P}(d\omega)=\ int_{\mathcal{X}}g(x)\mathbb{P}_X(dx)$$
1.) 条件情况看起来如何：
$$\mathbb{E}[g(X)|Z]=\int_{\mathcal{X}}g(x)\mathbb{P}_{X|Z} (dx)$$
2.) 当我们修复一个事件 $z$ 时，情况看起来如何：
$$\mathbb{E}[g(X)|Z=z]=\int_{\mathcal{X}}g(x)\mathbb{P}_{X| Z=z}(dx)$$
也就是说，我想要找到的是这些条件期望与域 $\Omega$ 上的集成的表达式。
这里的根本问题是：什么是条件分布 $\mathbb{P}_{X|Z}$ （以及 $\mathbb{P}_{X|Z=z}$) 的前推度量？]]></description>
      <guid>https://stats.stackexchange.com/questions/647498/law-of-the-unconscious-statistician-for-conditional-expectation-and-pushforward</guid>
      <pubDate>Sat, 18 May 2024 13:04:36 GMT</pubDate>
    </item>
    <item>
      <title>标签被已知噪声模型损坏的逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/647469/logistic-regression-with-labels-corrupted-by-known-noise-model</link>
      <description><![CDATA[我有兴趣了解“正确的方法”以拟合二元逻辑回归，其中标签已翻转，具有已知的特定于实例的噪声概率。
对于我想到的场景，我们给出一个三元组数据集，
$$ D = \{ (x_i, y_i, q_i) \}_{i=1}^n$$
其中 $x_i \in \mathbb{R}^d$ 是特征向量，$y_i \in \{0,1\}$ 是噪声损坏标签，$q_i \in [0, 1]$ 是特定于每个实例的已知损坏概率。
给定 $x_i$ 和 $q_i$，损坏的标签 $y_i$ 由以下模型生成：

设 $p_i = \sigma(x_i^\top w + b)$，其中 $\sigma(\cdot)$ 为 S 型函数，$w$ 和 $b$ 为真实但未知的逻辑回归参数。
设 $z_i \in \{0,1\}$ 为 $x_i$ 的未损坏标签，其中 $z_i \sim \text{Bernoulli}(p_i)$。
最后，损坏的标签 $y_i$ 生成为$$
y_i = \begin{cases}
z_i \text{ 概率 } q_i \\
1 - z_i \text{ 概率 } 1 - q_i \\
\end{cases}
$$

鉴于上述情况，似乎拟合逻辑回归的正确方法是使用 $q_i$ 从 $y_i$ 创建软标签，并将 KL 散度最小化到这些软标签标签。
但是，我也可以想象在拟合模型时使用$q_i$来加权每个实例$(x_i, y_i)$，这样在腐败概率较低的实例上，损失的权重更高。
非常欢迎任何关于在这种情况下拟合逻辑回归模型的建议、见解或参考。]]></description>
      <guid>https://stats.stackexchange.com/questions/647469/logistic-regression-with-labels-corrupted-by-known-noise-model</guid>
      <pubDate>Sat, 18 May 2024 05:04:31 GMT</pubDate>
    </item>
    <item>
      <title>如何阅读正态分布和期望符号[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647458/how-to-read-normal-distribution-and-expectation-notations</link>
      <description><![CDATA[我正在阅读有关扩散模型的论文(Eq. 4)  并发现了这个等式：
$$q(x_t|x_0) = N(x_t; \sqrt{\bar{\alpha_t}}x_0, (1-\bar{\alpha_t})I) $$
现在，我不知道如何读取正态分布。该方程是否意味着我们正在采样 $x_t$ 给出旁边提到的均值和方差。分号（;）是什么意思？
此外，我总是很难阅读期望符号。例如，期望表示为
$E_{X \sim P(X)} [X].$
我如何以计算方式读取这样的符号，以便我可以将其编写为程序。类似于我们如何将随机变量 $X$$\sum_i x_i P(x_i)$ &gt; 这样的范围 $R_X = \{x_1, x_2, x_3, ...\}$ 参考。]]></description>
      <guid>https://stats.stackexchange.com/questions/647458/how-to-read-normal-distribution-and-expectation-notations</guid>
      <pubDate>Fri, 17 May 2024 23:34:28 GMT</pubDate>
    </item>
    <item>
      <title>匹配后：如何解释 r 包 cobalt bal.tab 的平衡度量表中“距离”类型的值（=倾向得分）？</title>
      <link>https://stats.stackexchange.com/questions/647348/after-matching-how-do-i-interpret-the-value-of-the-type-distance-propensity</link>
      <description><![CDATA[我使用了R 包“MatchIt” 来执行 (1) 基于弗雷明汉心脏研究的最近邻倾向得分匹配 (NNM) 和 (2) 进行比较，最佳 PS相同 PS 模型的匹配（OM）。
PS 模型：BPMeds ~ 年龄 + 男性 + 教育程度 + BMI + 糖尿病 + prevalentHyp
对于天平诊断，我使用了R-Package ‘Cobalt’的bal.tab功能，并得到了以下结果：
&lt;前&gt;&lt;代码&gt;
平衡措施
                 类型 M.0.Un M.1.Un Diff.Un M.0.Adj M.1.Adj Diff.Adj M.Threshold
距离 距离 0.0276 0.1188 1.7333 0.1172 0.1172 -0.0003 平衡，&lt;0.1
年龄 继续。 49.3479 56.0721 0.8821 56.0000 56.0182 0.0024 平衡，&lt;0.1
男性 二元 0.4483 0.2973 -0.1510 0.3091 0.3000 -0.0091 平衡，&lt;0.1
教育 继续1.9828 1.9009 -0.0812 1.9000 1.8909 -0.0090 平衡，&lt;0.1
BMI 继续。 25.7068 28.2104 0.4770 28.2804 28.1248 -0.0296 平衡，&lt;0.1
糖尿病 二元 0.0257 0.0721 0.0464 0.0636 0.0636 0.0000 平衡，&lt;0.1
prevalentHyp 二元 0.2901 1.0000 0.7099 1.0000 1.0000 0.0000 平衡，&lt;0.1

平均差的平衡计数
                   数数
平衡，&lt;0.1 7
不平衡，&gt;0.1 0

具有最大平均差的变量
 可变 Diff.Adj M.Threshold
      BMI -0.0296 平衡，&lt;0.1

样本量
          对照处理
全部 3547 111
已匹配 110 110
无与伦比 3437 1

bal.tab(m.framingham_**OM**, Continuous = &quot;std&quot;, binary = &quot;raw&quot;, disp = c(&quot;means&quot;), un = TRUE, stats = c(&quot;m&quot;) ,+ 阈值 = c(m = .10))
平衡措施
                 类型 M.0.Un M.1.Un Diff.Un M.0.Adj M.1.Adj Diff.Adj M.Threshold
距离 距离 0.0276 0.1188 1.7333 0.1184 0.1188 0.0085 平衡，&lt;0.1
年龄 继续。 49.3479 56.0721 0.8821 56.5135 56.0721 -0.0579 平衡，&lt;0.1
男性 二元 0.4483 0.2973 -0.1510 0.3423 0.2973 -0.0450 平衡，&lt;0.1
教育 继续1.9828 1.9009 -0.0812 1.9820 1.9009 -0.0804 平衡，&lt;0.1
BMI 继续。 25.7068 28.2104 0.4770 27.8785 28.2104 0.0632 平衡，&lt;0.1
糖尿病 二元 0.0257 0.0721 0.0464 0.0721 0.0721 0.0000 平衡，&lt;0.1
prevalentHyp 二元 0.2901 1.0000 0.7099 1.0000 1.0000 0.0000 平衡，&lt;0.1

平均差的平衡计数
                   数数
平衡，&lt;0.1 7
不平衡，&gt;0.1 0

具有最大平均差的变量
  可变 Diff.Adj M.Threshold
 教育程度 -0.0804 平衡，&lt;0.1

样本量
          对照处理
全部 3547 111
已匹配 111 111
无与伦比 3436 0


如何解释 r 包 cobalt bal.tab 平衡度量表第一行中“距离”类型的值（=倾向得分）？
我可以使用距离来说明哪种匹配方法更适合（比较 NNM 与 OM 的两种模型/匹配方法）吗？

我刚刚找到以下关于距离的描述，但没有解释（ https://ngreifer.github.io/cobalt/reference/bal.tab.matchit.html）：
距离包含距离值距离（例如倾向得分）的可选公式或数据框或包含其名称的字符向量。如果指定了公式或变量名称，bal.tab() 将在 data 的参数中查找（如果指定）。由 matchit() 生成的距离测量（例如倾向得分）会自动包含在内并命名为“距离”。]]></description>
      <guid>https://stats.stackexchange.com/questions/647348/after-matching-how-do-i-interpret-the-value-of-the-type-distance-propensity</guid>
      <pubDate>Thu, 16 May 2024 09:41:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 emtrends 为不同组提供相同的 SE 值</title>
      <link>https://stats.stackexchange.com/questions/647164/identical-se-values-for-different-groups-using-emtrends</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647164/identical-se-values-for-different-groups-using-emtrends</guid>
      <pubDate>Mon, 13 May 2024 14:24:53 GMT</pubDate>
    </item>
    <item>
      <title>从有限的采样数据估计平滑密度场</title>
      <link>https://stats.stackexchange.com/questions/647128/estimating-smooth-density-field-from-limited-sampled-data</link>
      <description><![CDATA[我想估计一个“密度场”，特别是$P(y|x, m)$，用于二进制标签$y$ 与以空间坐标 $m$ 和其他时空特征  为特征的 2D 点相关联$x$。该模型应该旨在预测每个特定点（“逐点概率场”）的概率，而不是整个空间的概率。换句话说，这些点的估计概率不需要在 2D 空间上总和为 1；事实上，它们的总和可能会明显大于 1，除非输入 𝑥 存在一些不利的设置。我认为这个问题也可以看作是估计 3D 表面，其中 x 和 y 跨越 2D 空间，z 介于 0 和 1 之间。
虽然我的数据集由数十万个数据点组成，但这对于估计整个表面来说可能仍然有限。此外，我还面临着确保模型输出平滑的挑战。我想知道什么是好的问题设置、神经网络架构和损失函数来促进输出的平滑度。
问题：

什么类型的损失函数和神经网络架构适合对概率场进行建模，以确保相邻点和相似特征集之间的概率值平滑过渡，特别是当只有有限的点集可用时？
我正在寻找能够解决类似建模挑战的正确术语和文献领域。虽然对分布估计有大量研究（例如，使用高斯混合模型），但它与我估计密度场的需要并不相符。事实上，我什至不确定“密度场”或“逐点概率场”是否是我正在寻找的正确术语。我应该在处理类似问题的文献中搜索哪些术语和问题规范？

我感谢任何可以帮助有效地构建和解决我的问题的类似工作的指导或参考。]]></description>
      <guid>https://stats.stackexchange.com/questions/647128/estimating-smooth-density-field-from-limited-sampled-data</guid>
      <pubDate>Mon, 13 May 2024 08:47:45 GMT</pubDate>
    </item>
    </channel>
</rss>