<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 12 Mar 2024 12:23:52 GMT</lastBuildDate>
    <item>
      <title>sklearn.linear_model.LogisticRegressionCV 中 L2 正则化的显式形式</title>
      <link>https://stats.stackexchange.com/questions/642406/explicit-form-of-l2-regularization-in-sklearn-linear-model-logisticregressioncv</link>
      <description><![CDATA[我正在使用sklearn的LogisticRegressionCV，我想知道Logistic回归中L2正则化的显式形式。
在LogisticRegressionCV的官方页面中写道$Cs$ 是“正则化强度的倒数”，但尚不清楚正则化项的显式形式是什么。
在岭回归讲义中，5.3中的第一个方程，写为岭回归的正则化项是 $-\frac{1}{2}\lambda \bf{\beta}^T \bf{\beta}$，但是我不确定这个 $\lambda$ 与上面的 $Cs$ 有何关系。谁能帮我解答这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642406/explicit-form-of-l2-regularization-in-sklearn-linear-model-logisticregressioncv</guid>
      <pubDate>Tue, 12 Mar 2024 12:22:07 GMT</pubDate>
    </item>
    <item>
      <title>联合纵向模型和生存模型是否有 R2？</title>
      <link>https://stats.stackexchange.com/questions/642404/is-there-an-r2-for-joint-longitudinal-and-survival-models</link>
      <description><![CDATA[就像上面说的那样：联合纵向和生存模型是否有 R2（或伪）？]]></description>
      <guid>https://stats.stackexchange.com/questions/642404/is-there-an-r2-for-joint-longitudinal-and-survival-models</guid>
      <pubDate>Tue, 12 Mar 2024 11:51:55 GMT</pubDate>
    </item>
    <item>
      <title>联合模型的成对趋势比较</title>
      <link>https://stats.stackexchange.com/questions/642402/pairwise-trend-comparisons-for-a-joint-model</link>
      <description><![CDATA[我使用 JM 中的 jointModel 函数构建了纵向和生存数据的联合模型。我想对联合模型纵向结果的三个趋势进行成对比较。有没有办法做到这一点？我是否必须创建单独的模型并进行多重比较调整？]]></description>
      <guid>https://stats.stackexchange.com/questions/642402/pairwise-trend-comparisons-for-a-joint-model</guid>
      <pubDate>Tue, 12 Mar 2024 11:33:11 GMT</pubDate>
    </item>
    <item>
      <title>消极乐观导致更好的调整模型性能</title>
      <link>https://stats.stackexchange.com/questions/642400/negative-optimism-resulting-in-better-adjusted-model-performance</link>
      <description><![CDATA[在执行 200 次引导程序来估计使用逐步 BIC 逻辑回归开发的模型的净收益的乐观程度后，我得到了一个负值，这意味着当从表观净收益中减去时，我最终得到了改进。以前有其他人遇到过这个吗？我并不是在寻找有关变量选择方法的建议，我意识到还有更稳健的逐步替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/642400/negative-optimism-resulting-in-better-adjusted-model-performance</guid>
      <pubDate>Tue, 12 Mar 2024 11:23:43 GMT</pubDate>
    </item>
    <item>
      <title>R 脚本中使用 trident 分数进行蛋白质保守分析</title>
      <link>https://stats.stackexchange.com/questions/642399/protein-conservation-analysis-with-trident-scores-in-r-script</link>
      <description><![CDATA[我目前正在使用 MstatX 工具的输出 Trident 分数来分析跨氨基酸位置的蛋白质保守性。我有 40,000 个 Trident 评分文件，每个文件都包含氨基酸位置及其各自的评分。
为了简化我的分析，我最初编写了一个 bash 脚本来循环遍历每个文件，然后实现了一个 R 脚本来进行计算。 R脚本计算不同跨度的移动平均值以识别局部蛋白质保守性具有高偏差的区域，称为“热点”。然后分析这些热点以确定最强的偏差、其位置和相关指标。
这是我的 R 脚本的片段：
# 将输入文件分配给向量
args = commandArgs(trailingOnly = T)

# 将样本名称放入变量中
样本&lt;-sprintf(“%s”, args[1])

# 加载样本并制作数据框
raw.entropy&lt;-read.table(sprintf(“%s”, args[1]))
col.names&lt;-c(“AA.pos”,“Entropy.Score”)
colnames(raw.entropy)&lt;-col.names
AA.pos&lt;-raw.entropy$AA.pos
熵.Score&lt;-raw.entropy$熵.Score

# 让样本名称更好听
sub(“_entropyscores”, “”, 样本)-&gt;样本

# 加载ggplot
库（ggplot2）

# 计算短期和长期移动平均线
mydata&lt;-ggplot(data=raw.entropy, aes(x=AA.pos)) +
  geom_point(aes(y=Entropy.Score), size=2, color=“black”) +
  geom_smooth(mapping=aes(y=Entropy.Score), method = “黄土”, color = “red”, span = 0.1) +
  geom_smooth(mapping=aes(y=Entropy.Score), method = “黄土”, color = “blue”, span = 0.4) +
  主题_经典() +
  主题（plot.title = element_text（hjust = 0.5，face =“粗体”））+
  labs(title = sprintf(“%s”, args[1]), x = “氨基酸位置”, y = “三叉戟得分”)

# 推断短期和长期移动平均线之间的比率
# 比率代表遵守当地保护的程度
# 比率在 1 左右表示完美守恒，比率在 0 左右表示守恒较差
rolling_mean_10&lt;-layer_data(mydata, 2)$y
rolling_mean_50&lt;-layer_data(mydata, 3)$y
比率&lt;-rolling_mean_10/rolling_mean_50

# 查找第 10 个百分位的索引值
下限&lt;-NULL
for (i in (0.1*length(rolling_mean_10)):length(rolling_mean_10)){
if (rolling_mean_10[i] &gt;= 0.9*median(raw.entropy$Entropy.Score)){
下界&lt;-i
休息
}
}

# 查找第 90 个百分位的索引值
上限&lt;-NULL
for (i in (0.9*length(rolling_mean_10)):1){
if (rolling_mean_10[i] &gt;= 0.9*median(raw.entropy$Entropy.Score)){
上限&lt;-i
休息
}
}

# 找到序列中局部蛋白质保守偏差最大的位置
其中(ratios==min(ratios[下限:上限]))-&gt;热点
比率[热点]-&gt;截止
layer_data(mydata, 3)$x[热点]-&gt;x
百分位数&lt;-x/长度(raw.entropy$AA.pos)*100

# 将相关项写入标准输出
# 顺序是簇名称、最强偏差、四舍五入的氨基酸位置、发生偏差的百分位
cat(sprintf(“%s %s %s %s %s\n”，样本，截止，round(x)，round(百分位数，2))，file=“./output_deviation.txt”，append=真的）

编写输出文件后，我的目标是创建一个密度图，其中 x 轴代表每个输入文件的最强偏差。然而，当前的方法没有捕获预期的双峰分布。我正在寻求有关除使用简单移动平均线之外的其他方法来计算小但强偏差的建议。
我探索过的一些选项包括 EMA、z 分数、步数检测和异常检测。我将非常感谢任何见解或建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/642399/protein-conservation-analysis-with-trident-scores-in-r-script</guid>
      <pubDate>Tue, 12 Mar 2024 11:08:51 GMT</pubDate>
    </item>
    <item>
      <title>事件研究：测试功效取决于窗口长度吗？</title>
      <link>https://stats.stackexchange.com/questions/642398/event-studies-does-test-power-depend-on-the-window-lenght</link>
      <description><![CDATA[我正在读《Cambell, Lo &amp;》。 MacKinlay “金融市场计量经济学”（1996）。
第 4 章介绍事件研究。 4.6 节提供了 4.4 节中讨论的测试的功效分析。这些测试用于确定股票回报率的预期值 $\mathbb{E}(​​R_{i,t})$ 是否为 $R_{i,t}$，由于股票分割等事件而发生变化。 （$i$ 索引公司，$t$ 索引相对于事件的时间。）
在介绍功率分析设置时。 p。 168-169，作者似乎没有提到尺寸 $L_1$ 和 $L_2$分别是估计窗口和事件窗口。估计窗口是估计未来收益预期值的参考期。预期值称为正常回报并进行标记。事件窗口是预期回报值可能因事件而发生变化的时期。实际回报值减去预期值称为异常回报，并表示为$\epsilon_{i,t}^*$。检验的零假设是异常收益的预期值为零，$\mathbb{E}(​​\epsilon_{i,t}^*)=0$。两个窗口不重叠。
缺乏对估计和/或事件窗口长度的参考，$L_1$ 和 $L_2$&lt; /span&gt;，功率分析让我感到惊讶。测试的力量是否不依赖于它们中的任何一个？毕竟，通过无限大的估计窗口（$L_1\rightarrow\infty$），我们对异常收益的估计将非常精确：$\hat\epsilon_{i,t}^*=\epsilon_{i,t}^*$。并且通过无限大的事件窗口（$L_2\rightarrow\infty$），我们将能够以完美的精度估计它们的期望值。因此，预期值等于 0 的合理测试的功效为 1。
我错过了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/642398/event-studies-does-test-power-depend-on-the-window-lenght</guid>
      <pubDate>Tue, 12 Mar 2024 10:52:27 GMT</pubDate>
    </item>
    <item>
      <title>P值等于1？</title>
      <link>https://stats.stackexchange.com/questions/642396/p-value-equal-to-1</link>
      <description><![CDATA[我在 lme4 中运行以下逻辑混合模型：
CAPS_PDI_Cond25_CV&lt;- glmer(响应 ~ caps_AvSev.ct + pdi_AvSev.ct + Av_dBSNR.ct + num_train.ct + (1|Pt_ID), family= 二项式, data = lme.df_25,control=glmerControl(optimizer) =“bobyqa”））

我得到以下模型结果：
修复效果：
                估计标准。误差z值Pr(&gt;|z|)
(截距)-1.046e+00 1.050e-01 -9.960＜ 2e-16 ***
caps_AvSev.ct 4.805e-02 3.384e-02 1.420 0.156
pdi_AvSev.ct 8.753e-06 3.217e-02 0.000 1.000
Av_dBSNR.ct 1.835e-01 3.909e-02 4.695 2.66e-06 ***
num_train.ct -3.883e-03 5.005e-03 -0.776 0.438
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

为什么 pdi_AvSev.ct 的p值为 1？]]></description>
      <guid>https://stats.stackexchange.com/questions/642396/p-value-equal-to-1</guid>
      <pubDate>Tue, 12 Mar 2024 10:33:55 GMT</pubDate>
    </item>
    <item>
      <title>用于单个多元线性回归模型的 anova_lm 函数</title>
      <link>https://stats.stackexchange.com/questions/642395/anova-lm-function-for-a-single-multiple-linear-regression-model</link>
      <description><![CDATA[当使用 statsmodels 中的 anova_lm 和单个多元线性回归模型时，如何计算每个预测变量的统计数据？
例如
model = sm.formula.ols(mpg ~ 气缸数 + 排量 + 马力 + 重量 + 加速度 + 年份 + 原点, data = auto)

anova_lm（模型）


如何计算每个独立预测变量的 sum_sq、mean_sq 和 F 值（例如马力）？&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/642395/anova-lm-function-for-a-single-multiple-linear-regression-model</guid>
      <pubDate>Tue, 12 Mar 2024 10:30:53 GMT</pubDate>
    </item>
    <item>
      <title>基于预测值与实际数据一致性的潜力评估</title>
      <link>https://stats.stackexchange.com/questions/642394/potential-evaluation-based-on-the-coherence-of-predicted-value-with-actual-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/642394/potential-evaluation-based-on-the-coherence-of-predicted-value-with-actual-data</guid>
      <pubDate>Tue, 12 Mar 2024 10:25:26 GMT</pubDate>
    </item>
    <item>
      <title>试验随机价格变动</title>
      <link>https://stats.stackexchange.com/questions/642393/experimenting-random-price-movement</link>
      <description><![CDATA[随机价格变动
考虑以下因素：
一个苹果的价格从 1 美元起。
每天，价格都会以相同的概率变化 -10% 或 +10%。
您在第 1 天购买这个苹果，并在第 N 天出售。
最后你赔钱的概率是多少？
假设 N = 2，那么我们有 4 种相同概率的可能结果：

0.9 * 0.9 = 0.81
0.9 * 1.1 = 0.99
1.1 * 0.9 = 0.99
1.1 * 1.1 = 1.21

因此赔钱的概率是 3/4。
让我们用不同的增量值（例如 10%）和步长（天）运行一个实验。
&lt;小时/&gt;
导入 matplotlib.pyplot 作为 plt


def main():
    对于 [0.01, 0.1, 0.2, 0.4, 0.5, 0.8] 中的 delta：
        步骤 = 列表(范围(1, 20))
        p_lose = [find_p_lose(n, delta) for n in Steps]
        plt.figure(figsize=(5, 3))
        plt.title(f&quot;delta = {delta}&quot;)
        plt.xlabel(“步数（天）”)
        plt.ylabel(“失败概率”)
        plt.xticks(步骤)
        plt.tight_layout()
        plt.plot(步数, p_lose)
        plt.show()


def find_p_lose(步数, 增量)​​:
    结果 = find_outcomes(步骤, 增量)
    p_lose = len([x 表示结果中的 x，如果 x &lt; 1]) / len(结果)
    返回 p_lose


def find_outcomes(步骤, 增量)​​:
    如果步骤 == 1：
        返回 [1 - 增量，1 + 增量]
    结果 = []
    对于 [1 - delta, 1 + delta] 中的 a：
        对于 find_outcomes 中的 b（步骤 - 1，增量）：
            结果.append(a * b)
    返回结果


print(“首先让我们验证一开始的内容（2步，delta = 0.1）”)
print(“结果”, find_outcomes(2, 0.1))
print(&quot;p(lose)&quot;, find_p_lose(2, 0.1))

主要的（）

&lt;小时/&gt;



&lt;小时/&gt;
观察结果
情况 1：[0.01, 0.1] 中的增量
p（损失）振荡

奇数步数始终为 0.5。
偶数步数总是更有可能赔钱，
概率随着步数的增加而减少，并且遵循一条很好的曲线。

情况 2：[0.2, 0.4, 0.5, 0.8] 中的增量
p(lose) 振荡时增加
问题

我们可以看到似乎出现了分叉，那么 delta 的值是多少？
出现分叉吗？
两种情况下趋势所遵循的曲线的解析表达式是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/642393/experimenting-random-price-movement</guid>
      <pubDate>Tue, 12 Mar 2024 10:19:17 GMT</pubDate>
    </item>
    <item>
      <title>如果我在不先运行方差分析的情况下运行 Tukey，会发生什么情况？</title>
      <link>https://stats.stackexchange.com/questions/642390/what-really-happens-if-i-run-tukey-without-running-anova-first</link>
      <description><![CDATA[我发现理论说，如果我想测试 3 个以上组之间的均值差异，我应该首先使用方差分析，如果方差分析拒绝零假设，那么我可能想将 Tukey 作为事后检验找出哪些组的平均值确实不同。
我的问题是：为什么不直接运行 Tukey？如果我在不先运行方差分析的情况下运行 Tukey，会发生什么情况？这有哪些风险/影响？
直觉告诉我，如果 Tukey 发现了一些显着差异，那么方差分析也应该发现了它。什么时候不是这样？]]></description>
      <guid>https://stats.stackexchange.com/questions/642390/what-really-happens-if-i-run-tukey-without-running-anova-first</guid>
      <pubDate>Tue, 12 Mar 2024 09:38:44 GMT</pubDate>
    </item>
    <item>
      <title>作为时间序列的可视化数据标签，有什么好的 python 模块/库可以替代“Visplore”？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/642389/what-would-be-a-good-python-module-lybrary-as-an-alternative-to-visplore-as-vi</link>
      <description><![CDATA[我一直在寻找一个好的时间序列标签解决方案，并找到了 Visplore 的这段视频
https://www.youtube.com/watch?v=2bgfn6PH3E0 
我正在使用类似的模式并使用大量代码进行标记（用于峰值检测的 scipy.signal、numpy、pandas 等），但每次我感兴趣的信号发生变化时，我都需要花费大量时间重写我针对这种不同模式的脚本。
也许有人会知道一些 python 模块，它们可以帮助我更有效地标记时间序列，而无需太多的重新编码工作 --&gt;像 Visplore 这样的 GUI。]]></description>
      <guid>https://stats.stackexchange.com/questions/642389/what-would-be-a-good-python-module-lybrary-as-an-alternative-to-visplore-as-vi</guid>
      <pubDate>Tue, 12 Mar 2024 09:21:18 GMT</pubDate>
    </item>
    <item>
      <title>计算 R 中的置信区间</title>
      <link>https://stats.stackexchange.com/questions/642386/calculating-confidence-intervals-in-r</link>
      <description><![CDATA[我很好奇为什么我在 R 中得到两个不同的 95% 置信区间，平均值为 $0.008$，SD 为 $0.1035697$ 和 $n = 39$（正态分布）。当我使用代码时：
a &lt;- 平均值(m)

n &lt;- 39

s &lt;-sd(m)

误差 &lt;- s/sqrt(n)

一个+错误

一个 - 错误

使用此方法我得到 95% 的置信区间 $(-0.02450488, 0.04050488)$，但是当我只使用 t.test(m) 时，我得到 &lt; span class=&quot;math-container&quot;&gt;$(-0.02557342,0.04157342)$。这是为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/642386/calculating-confidence-intervals-in-r</guid>
      <pubDate>Tue, 12 Mar 2024 09:06:34 GMT</pubDate>
    </item>
    <item>
      <title>压缩高维数据中的过度拟合和改进泛化的解决方案</title>
      <link>https://stats.stackexchange.com/questions/642384/overfitting-in-compressed-high-dimensional-data-and-solutions-for-improved-gener</link>
      <description><![CDATA[我正在处理一个相当大的数据集：1141 个样本充满了 2715 个特征（在 get_feature_importance 之后可能有 63 个特征，当然还有过度拟合），每个样本都位于区间 (0, 1)。此外，目标列标榜用于分类任务的单热编码标签。
我采用了三种卷积技术：循环卷积，通过将行样本的信息（减少一半的特征）与归一化数据合并来压缩特征计数；线性卷积，由于圆形卷积的影响而对齐形状进行训练；和自卷积，以衡量测试的必要性。
训练结果看起来好得令人难以置信，尤其是在面对测试集时（比训练结果好一点）。我将这些技术与多种模型（逻辑回归、SVM、决策树、kNN、XGBoost）结合起来，但没有成功。
我非常感谢您的帮助，也许可以找到对我来说具有特殊意义的来源。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642384/overfitting-in-compressed-high-dimensional-data-and-solutions-for-improved-gener</guid>
      <pubDate>Tue, 12 Mar 2024 08:11:55 GMT</pubDate>
    </item>
    <item>
      <title>使用工具变量时，是否需要在回归模型中包含混杂变量？</title>
      <link>https://stats.stackexchange.com/questions/642383/do-i-need-to-include-confounding-variables-in-my-regression-model-when-i-use-ins</link>
      <description><![CDATA[假设我相信“年龄”、“性别”、“能力”和“动机”是影响因变量和内生变量的混杂变量。我使用“教育水平”作为处理变量，“收入”作为因变量。在浏览了有关该主题的许多公开示例后，大多数示例仅使用工具变量“距离”。所以我开始想知道是否可以使用工具变量“距离”来解决内生性问题，而不考虑混杂变量作为协变量。
我是否需要或应该在回归模型中包含混杂变量作为协变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/642383/do-i-need-to-include-confounding-variables-in-my-regression-model-when-i-use-ins</guid>
      <pubDate>Tue, 12 Mar 2024 07:24:44 GMT</pubDate>
    </item>
    </channel>
</rss>