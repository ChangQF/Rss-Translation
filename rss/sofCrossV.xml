<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Sep 2024 21:15:18 GMT</lastBuildDate>
    <item>
      <title>适合我的实验的统计方法</title>
      <link>https://stats.stackexchange.com/questions/653871/appropriate-statistical-approach-for-my-experiment</link>
      <description><![CDATA[我需要一些关于我想运行哪种统计分析的建议。
我进行了一项实验，开始时有 20 种细菌菌株，数量相等。该实验有 4 种感兴趣的处理方法，每种处理方法重复 15 个种群。该实验进行了数月，种群数量增长相当大。最后，我从每个种群中分离出 3 个单独的细菌，并确定它们属于 20 种原始细菌菌株中的哪一种。每个处理方法有 15 个重复种群，因此每个处理方法识别出 45 种菌株，总共识别出 180 种菌株。
我想弄清楚的是如何确定这 4 种不同的处理方法最终是否在 20 种起始菌株中选择了不同的菌株。从定性上看，我可以看到存在差异；有些处理方法比其他处理方法多得多。但从统计学上看，我很难确定应该使用哪种方法。我觉得我应该使用某种二项式或卡方方法，因为它们实际上代表了从人群中随机抽取的结果。但由于有多种可能的菌株可供选择，我不知道该怎么做。]]></description>
      <guid>https://stats.stackexchange.com/questions/653871/appropriate-statistical-approach-for-my-experiment</guid>
      <pubDate>Wed, 04 Sep 2024 19:59:03 GMT</pubDate>
    </item>
    <item>
      <title>检查某个事件是否导致了语料库中某些单词的出现发生变化</title>
      <link>https://stats.stackexchange.com/questions/653869/check-whether-an-event-made-a-change-in-the-appearance-of-certain-words-in-a-cor</link>
      <description><![CDATA[场景
我正在研究 1980 年至 2000 年期间学生撰写的 100,000 篇学术论文。我认为 1999 年底的某个特定事件可能增加了某些特定主题术语的使用。我有一个包含 1000 个单词的列表 $A$，我认为它的使用量可能会增加；还有一个包含 1000 个单词的列表 $b_1, b_2, ..., b_{1000}$，是我从论文中随机抽取的。我确保所有 2000 个单词每年至少在一篇论文中出现一次，并且它们都是不同的，因此列表内没有重叠，列表之间也没有重叠。
理想情况下，我想检查 A 中的单词在 2000 年是否“比正常情况”增加。与 B 进行比较可以帮助我检查这种增加是否不是每个单词都如此，与 1999 年之前的年份进行比较可以让我检查这种波动是否不常见。但是，我受到所拥有的数据类型的限制。这种情况是相当人为的，所以请耐心等待。
现在，我无法直接访问这些论文，但我可以使用搜索引擎来扫描给定年份的论文中出现了多少个单词。每年的论文数量不同；我知道每年的数量。
示例
1980 年有 4567 篇论文。对于 $A$ 和 $B$ 中的每个单词，我都可以提取包含该单词的论文数量。将其除以 4567，我可以轻松计算出该单词出现的论文比例。因此，例如，我可以告诉您 $a_1$ 出现在 1980 年的 3456 篇论文中，比例为 3456/4567。比较$a_1$在一年中出现的论文数量意义不大，因为论文数量每年都在变化，但我可以计算出$a_1$在论文中的比例每年的绝对和相对增加/减少。
问题
现在，我可以对我拥有的$A$中单词的数据运行什么样的测试来检查我看到的这个统计数据的增长是否显著？我的怀疑，以及我想要测试的是，从 1999 年到 2000 年，A 中的单词的相对比例发生了变化，而我在 B 中或之前几年（即从 1998 年到 1999 年、从 1997 年到 1998 年等）没有看到这些单词。回顾一下，比例是论文中至少出现一次该单词的比例，这里的相对意味着我认为从 2% 到 4% 的增长比从 50% 到 55% 的增长要高得多。
附加信息：

年复一年，包含单词 $w$ 的论文百分比，无论 $w$ 是在 $A$ 中还是 $B$，增加。因此，任何类似列联表的东西实际上都不起作用：我从来不指望比例是稳定的。我或许可以使用 $B$ 中的数据来估计每年的随机增长是多少——单词比例的相对增长似乎是——但我知道如何正确地做到这一点。
我无法绘制任何其他数据。具体来说，我们无法获得单词的实际频率（单词出现的次数/文本的长度）。我知道这极大地限制了结果。
我完全可以接受逐年进行比较；我不想进行多年的比较。

我的想法
这是我能想到的最好的办法：我可以计算 1999-2000 年 2000 个单词中每个单词 $w$ 的论文比例的相对变化（例如，一个单词从 2% 变为 4%，则得分为 200% 的变化）。然后，我使用 Kolmogorov–Smirnov 检验比较 $A$ 中的单词和 $B$ 中的单词的结果：如果 1999 年的大事件有影响，我应该检测到两个不同的分布。相反，对 1999 年之前的每一年进行同样的操作应该会得到相反的结果（或者至少 p 值要低得多）。
这种方法合理吗？您有更好的解决方案吗？有没有办法运行不涉及 $B$ 的测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/653869/check-whether-an-event-made-a-change-in-the-appearance-of-certain-words-in-a-cor</guid>
      <pubDate>Wed, 04 Sep 2024 18:51:48 GMT</pubDate>
    </item>
    <item>
      <title>绘制狄利克雷回归中的效应</title>
      <link>https://stats.stackexchange.com/questions/653868/plotting-effects-in-dirichlet-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653868/plotting-effects-in-dirichlet-regression</guid>
      <pubDate>Wed, 04 Sep 2024 18:28:03 GMT</pubDate>
    </item>
    <item>
      <title>假设检验。基于受限信息的决策 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/653866/hypothesis-testing-decision-based-on-restricted-information</link>
      <description><![CDATA[基于关于假设检验的操纵软件输出（来自 R），我想了解如何回答以下问题：
(a) 这是什么类型的测试？假设是什么？
(b) 重要性水平是多少？测试决策是什么？
(c) alpha 位于哪个“区域”？
问题的作者（在原始问题中）用“？”替换了测试名称、p 值、假设和替代方案等重要信息。所以我复制了这样一个问题。
在下面，您可以找到包含所有信息的输出。当我创建这个模拟问题时，我们知道了整个过程。

?

数据：x
X 平方 = 93.177，df = 29，p 值 = ?
备选假设：真实方差为 ? 2.5
95% 置信区间：
5.09473 14.51621
样本估计值：
x 的方差 
8.032507 

我在回答 (a)-(c) 时所做的努力是：
(a&#39;) 根据“X 平方”、“方差”和“x”，我认为：一个样本方差卡方检验。除了将样本方差与总体方差进行比较之外，不可能进一步指定假设。$H_{0}$ 包括“等号”就像假设检验理论中总是做的那样。我无法说测试是单侧还是双侧。
(b&#39;)“95% 置信区间”表示 $\alpha = 0.05$。我无法争论测试决定。在我看来，我在这里缺少统计假设检验理论的一个基本部分。
(c&#39;) 参见 (b&#39;)。
任何关于如何进行的提示都非常感谢。

注意
(1) R 代码产生输出。
x = rnorm(30, mean = 1, sd = 3)
library(DescTools)
VarTest(x, sigma.squared = 2.5)

也就是说，$x$ 的生成来自 $X\sim\mathcal{N}(1,3)$，其中 $n=30$。
(2) 完整输出，其中 操纵 输出源于此。

方差单样本卡方检验

数据：x
X 平方 = 93.177，df = 29，p 值 = 1.28e-08
备选假设：真实方差不等于 2.5
95% 置信区间：
5.09473 14.51621
样本估计值：
x 方差
8.032507

(3) 软件说明。
DescTools::VarTest() 的默认值为双侧。 p 值明显低于 5%（默认值）。即检验拒绝了原假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/653866/hypothesis-testing-decision-based-on-restricted-information</guid>
      <pubDate>Wed, 04 Sep 2024 18:14:05 GMT</pubDate>
    </item>
    <item>
      <title>无法绘制具有分层变量的 ggsurvplot 曲线[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653865/unable-to-plot-ggsurvplot-curves-with-stratified-variables</link>
      <description><![CDATA[我试图创建一个分层了不同类型变量的 ggsurvplot 曲线，但一直出现错误。
这是代码：
# 定义用于 OS 分析的 Surv 对象
surv_object_os &lt;- Surv(time = target_time_series_os$tstart, time2 = target_time_series_os$tend, event = target_time_series_os$death_status)

# 步骤 4：拟合 Cox 比例风险模型
# 以治疗组为主要协变量并根据需要拟合其他协变量，拟合 Cox 模型
cox_model_os &lt;- coxph(surv_object_os ~ age_at_sample + strata(sex) + rt_dosage + chemo_dosage + stad_bin + ps_bin + rt_arm + library_prep_plate, 
data = target_time_series_os)

# 步骤 5：Cox 模型摘要
# 显示 Cox 模型摘要，包括系数、p 值等。
summary(cox_model_os)

# 根据 Cox 模型生成生存曲线
surv_fit_os &lt;- survminer::surv_fit(cox_model_os, data = target_time_series_os)

all: survfit(formula = cox_model_os, data = target_time_series_os)
records n.max n.start events median 0.95LCL 0.95UCL
0 127 31 27 35 1168 674 NA
1 164 38 33 40 1236 730 NA

survminer::ggsurvplot(fit=surv_fit_os, data = target_time_series_os,
pval = TRUE, conf.int = TRUE,
legend.title = &quot;生存曲线&quot;,
risk.table = TRUE,
xlab = &quot;时间（天）&quot;,
ylab = &quot;生存概率&quot;)

我不断收到：

在新窗口中显示
调用：
coxph(formula = surv_object_os ~ age_at_sample + strata(sex) + 
rt_dosage + chemo_dosage + stad_bin + ps_bin + rt_arm + library_prep_plate, 
data = target_time_series_os)

n= 291，数量事件= 75 

coef exp(coef) se(coef) z Pr(&gt;|z|)
age_at_sample 0.007480 1.007508 0.018403 0.406 0.684
rt_dosage -0.006263 0.993756 0.032314 -0.194 0.846
chemo_dosage -0.087179 0.916513 0.464639 -0.188 0.851
stad_bin 0.323840 1.382427 0.379841 0.853 0.394
ps_bin 0.352640 1.422819 0.373342 0.945 0.345
rt_arm60 Gy 0.020243 1.020449 0.483095 0.042 0.967
library_prep_plate 0.085032 1.088752 0.109380 0.777 0.437

exp(coef) exp(-coef) 下限 .95 上限 .95
age_at_sample 1.0075 0.9925 0.9718 1.045
rt_dosage 0.9938 1.0063 0.9328 1.059
chemo_dosage 0.9165 1.0911 0.3687 2.278
stad_bin 1.3824 0.7234 0.6566 2.910
ps_bin 1.4228 0.7028 0.6845 2.958
rt_arm60 Gy 1.0204 0.9800 0.3959 2.630
library_prep_plate 1.0888 0.9185 0.8787 1.349

一致性= 0.591 (se = 0.041 )
似然比检验= 7 df 上 4.42，p=0.7
Wald 检验 = 7 df 上 4.87，p=0.7
得分 (对数秩) 检验 = 7 df 上 5，p=0.7

在新窗口中显示
生存中的错误::survdiff(eval(fit$call$formula), data = data) : 
“formula”参数不是公式


并且
eval(predvars, data, env) 中的错误：未找到对象“sex”

如果我这样做：
ggsurvplot(surv_fit_os, data = target_time_series_os,
strata = &quot;sex&quot;, # 替换 &quot;other_variable&quot;替换为要使用的变量的实际名称
pval = TRUE, conf.int = TRUE,
legend.title = &quot;生存曲线&quot;,
risk.table = TRUE,
xlab = &quot;时间（天）&quot;,
ylab = &quot;生存概率&quot;,
facet.by = &quot;性别&quot;)


有人知道如何解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653865/unable-to-plot-ggsurvplot-curves-with-stratified-variables</guid>
      <pubDate>Wed, 04 Sep 2024 16:44:43 GMT</pubDate>
    </item>
    <item>
      <title>蠕虫图 - GAM 的应用</title>
      <link>https://stats.stackexchange.com/questions/653864/worm-plots-application-for-gam</link>
      <description><![CDATA[最近，我偶然发现了“蠕虫图”在模型诊断中的应用。对我来说，这是一种观察模型残差的新方法。对于那些不熟悉蠕虫图的人来说，这是一种去趋势的 QQ 图。我最初是在 gamlss R 包 (wp(...)) 中偶然发现它的，后来在 gratia R 包 (worm_plot(...)) 中找到了它的一个版本。
这是来自 gamlss::wp(model) 的示例图。

在运行该函数并在文献中了解了更多关于该图的信息后，出于好奇心的驱使（请参阅 von Buuren and Fredriks (2001)) 我开始深入研究 gamlss::wp(...) 代码（就像猪追逐松露一样）以了解更多信息。&quot;u&quot;形虚线本质上是正态分布的置信区间（如果我错了，请纠正我）
代码看起来像这样...
level &lt;- 0.95
z &lt;- seq(-4,4,0.25)
p &lt;- pnorm(z)
se &lt;- (1/dnorm(z))*(sqrt(p*(1-p)/length(qq$y)))
low &lt;- qnorm((1-level)/2)*se
high &lt;- -low

plot(...)
lines(z, low, lty=2)
lines(z, high, lty=2)

gratia 包为我们提供了几个不同的选项，包括“正常”和“模拟”方法来生成 QQ 统计数据和参考带。以下是使用 Tweedie 分布的模型的“模拟”方法的示例。代码非常简单 gratia::worm_plot(model,method = &quot;simulate&quot;)。

所以我想我的问题是，具体到这个例子，从模型中指定的特定分布生成 QQ 理论与残差会更好吗？在这种情况下，它将是来自 Tweedie 分布的 QQ。类似地，对于参考带，基于 Tweedie 分布的置信区间会更好吗（即第一个图中的虚线“u”形线）？
我已经开始探索这一点，但不确定

是否合适或值得深入研究？

“模拟”是否给定数据和模型，参考带是否足够好？


如何正确估计 Tweedie 分布的理论分位数

我已经接近了，但一直纠结于如何最好地估计 qtweedie 分布（下面的示例）。


（还没有做到这一点，但刚刚开始考虑）与估计 Tweedie 分布的置信区间相关的数学。

开始一个示例以制作特定于 tweedie 的 QQplot
library(mgcv)
library(tweedie)
library(statmod)

# 示例数据
set.seed(123)
n &lt;- 100
x &lt;- runif(n)
y &lt;- rtweedie(n, mu = 5 + 2 * x, phi = 1，功率 = 1.5)

# 使用 Tweedie 分布拟合 GAM
gam_fit &lt;- gam(y ~ s(x), family = tw())

# 计算残差
residuals &lt;- residuals(gam_fit, type = &quot;response&quot;)

# 生成理论分位数
predicted_values &lt;- predict(gam_fit, type = &quot;response&quot;)

theoretical_quantiles &lt;- qtweedie(ppoints(n), 
mu = predict_values, 
phi = ???,
power = ???)

]]></description>
      <guid>https://stats.stackexchange.com/questions/653864/worm-plots-application-for-gam</guid>
      <pubDate>Wed, 04 Sep 2024 16:17:22 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的负面特征归因是什么意思？</title>
      <link>https://stats.stackexchange.com/questions/653863/what-do-negative-feature-attributions-in-machine-learning-mean</link>
      <description><![CDATA[也许这不是一个特别聪明的问题，但我无法理解可解释机器学习中 IntegratedGradients 等算法的负面特征归因（重要性分数）。特征归因 0 表示该特征对预测不重要，正分表示该特征对预测很重要，但负分是什么意思？
我读过不同的东西。有一次我读到正分表示该特征对二元分类中的第 1 类很重要，负分表示该特征对第 0 类很重要。它们是这样的吗？然而，在另一篇网络文章（https://medium.com/geekculture/feature-attribution-in-explainable-ai-626f0a1d95e2）中，它是这样说的：分数的范围可以从正值（表示该特征对模型预测的贡献）、零值（表示该特征没有贡献）到负值（表示删除该特征会增加预测类别的概率）。例如，图像背景已在某些对象识别任务中用作特征。如果归因算法为手势识别模型分配了负分，则意味着删除背景像素将改善手势类别的识别。
如果你能帮助我，那就太好了！
非常感谢，
托马斯]]></description>
      <guid>https://stats.stackexchange.com/questions/653863/what-do-negative-feature-attributions-in-machine-learning-mean</guid>
      <pubDate>Wed, 04 Sep 2024 15:56:12 GMT</pubDate>
    </item>
    <item>
      <title>当数据为观察数据时，如何解释不确定性</title>
      <link>https://stats.stackexchange.com/questions/653862/how-to-interpret-uncertainty-when-data-is-observational</link>
      <description><![CDATA[当数据是观察数据时，例如在行政环境中，我们如何解释频率统计不确定性度量，例如置信区间？
例如，在 2023 年一所拥有 500 名学生的学校中，我们测量所有 500 名学生的 GPA。平均 GPA 是这组特定学生的固定数量。
为了概念化频率不确定性，我们是否建议这 500 名学生是一个人口的成员？
例如，我们可能会说学生可能代表社区中更广泛的学生，或者每年都有新生，一年是所有可能学生年份的样本。另一个概念是，如果我们时光倒流，学生重温那一年，他们的学校经历会有所不同，GPA 也会有所不同。
我正试图理解人口定义的这种模糊性。]]></description>
      <guid>https://stats.stackexchange.com/questions/653862/how-to-interpret-uncertainty-when-data-is-observational</guid>
      <pubDate>Wed, 04 Sep 2024 15:37:18 GMT</pubDate>
    </item>
    <item>
      <title>双样本 Kolmogorov-Smirnov、双样本 Anderson-Darling 和（双样本）Wilcoxon 秩和检验的零假设</title>
      <link>https://stats.stackexchange.com/questions/653837/null-hypotheses-of-two-sample-kolmogorov-smirnov-two-sample-anderson-darling-a</link>
      <description><![CDATA[据我所知，双样本 Kolmogorov-Smirnov (KS) 检验和双样本 Anderson-Darling (AD) 检验的零假设 $H_0$ 是相同的，即两个样本来自同一分布/总体。
我们可以说（双样本）Wilcoxon 秩和 (WRS) 检验的零假设 $H_0$ 与 KS 和 AD 检验的零假设相同，只是“附加条件”是两个样本的中位数应该相同吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653837/null-hypotheses-of-two-sample-kolmogorov-smirnov-two-sample-anderson-darling-a</guid>
      <pubDate>Wed, 04 Sep 2024 09:23:39 GMT</pubDate>
    </item>
    <item>
      <title>在轮盘赌中，出现长红色序列的频率是否低于出现短红色序列的频率？</title>
      <link>https://stats.stackexchange.com/questions/653816/in-roulette-is-the-frequency-of-getting-long-sequences-of-reds-lower-than-that</link>
      <description><![CDATA[在一场无限期的轮盘游戏中，与连续 10 次出现红色相比，连续 100 次出现红色的概率（可能每百万次旋转才出现一次）要小得多，这样说对吗？
如果出现一长串红色的概率会随着序列变长而降低，那么为什么认为在一长串红色之后出现黑色的可能性更大会被视为赌徒谬误？如果 101 次出现红色的序列比 100 次出现红色的序列出现的可能性更小，那么为什么认为当前序列更有可能是 100 次出现红色并因此下一轮旋转将是黑色是错误的？
编辑：
我知道这些都是独立事件，概率没有记忆，因此必须保持不变。我在问，这一事实如何与较长序列出现频率较低的说法相一致。
此外，我并不是说根据大数定律，它应该平衡，因此下一次旋转更有可能是黑色。我是说，我们更有可能处于 100 个红色的序列而不是 101 个红色的序列，因为它发生的频率更高，并且如果更有可能假设现在是较短的序列而不是较长的序列，那么从逻辑上讲，下一次旋转更有可能是黑色不是吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653816/in-roulette-is-the-frequency-of-getting-long-sequences-of-reds-lower-than-that</guid>
      <pubDate>Tue, 03 Sep 2024 23:44:05 GMT</pubDate>
    </item>
    <item>
      <title>为多元分布生成准随机数</title>
      <link>https://stats.stackexchange.com/questions/653814/generate-quasi-random-numbers-for-a-multivariate-distribution</link>
      <description><![CDATA[Sobol 或 Holton 等算法在超立方体 $[0,1]^d$ 中提供准随机数（即，这些数字在均匀分布的意义上“看起来”是随机的，但它们是确定性的）。让 $$x_1, x_2, ..., x_n$$ 成为此类伪随机数的序列。对于特定分布（例如正态分布）的任何分布函数 $F$，$$F^{-1}(x_1), F^{-1}(x_2), ..., F^{-1}(x_n)$$ 都是按照 $F$ 分布的准随机数。
如果 $F$ 是正态分布的分布函数，其均值为 $\mu$，方差-协方差矩阵为 $\Sigma$，则 $$F^{-1}(x_i) = C\Phi^{-1}(x_i) + \mu,$$，其中 $F$ class=&quot;math-container&quot;&gt;$\Phi^{-1}$ 是标准正态函数的分位数函数，该函数逐个分量应用于向量 $x_i$，而 $C$ 是 $\Sigma$ 的 Cholesky 分解。也就是说，我可以轻松生成具有多元正态分布的准随机向量。
现在我想生成具有多元 t 分布的准随机向量。可以通过 $$\sqrt{\frac{k}{\chi}}C\Phi^{-1}(x_i) + \mu,$$ 生成具有多元 t 分布且自由度为 $k$ 的随机向量，其中 $\chi$ 是具有 $k$ 自由度的卡方分布随机变量。通过设置 $\chi = \mathcal X^{-1}_k(y)$，其中 $\mathcal X^{-1}_k$ 表示具有 $k$ 自由度的卡方分布的分位数函数。 $y$ 是什么？嗯，这正是我的问题。问题是，如果我选择 $x_i$ 的第一个元素作为 $y$，那么 $y$ 和 $x_i$ 显然不再独立，这与生成具有多元 t 分布的随机数的算法相矛盾。当然，我可以随机选择一个 $i$ 和一个 $j$（组件），但这样我就可以首先生成随机数，而这并不是我想要的（这个问题是重要性抽样集成问题的一部分）。一个显而易见的解决方案是直接计算$F^{-1}(x_i)$。但是，$F^{-1}$没有封闭形式，因此很难近似。
还有其他解决方案可以帮助我实现我想要的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653814/generate-quasi-random-numbers-for-a-multivariate-distribution</guid>
      <pubDate>Tue, 03 Sep 2024 22:36:46 GMT</pubDate>
    </item>
    <item>
      <title>季节性差分后 ADF/KPSS 检验的适用性</title>
      <link>https://stats.stackexchange.com/questions/653797/appropriateness-of-adf-kpss-tests-after-seasonal-differencing</link>
      <description><![CDATA[给定一个具有已知季节性的序列，我尝试在执行季节性差分后使用 ADF 和 KPSS 测试来验证平稳性。我正在使用这些测试的 statsmodels 实现。
import pandas as pd
from statsmodels.tsa.stattools import adfuller, kpss

def adf_test(timeseries, return=&#39;c&#39;):
test = adfuller(timeseries, return=regression, autolag=&#39;AIC&#39;)
output = pd.Series(
test[0:4],
index=[
&#39;测试统计量&#39;,
&#39;p 值&#39;,
&#39;使用的滞后数&#39;,
&#39;使用的观测值数量&#39;
]
)
for key, value in test[4].items():
output[f&#39;临界值 ({key})&#39;] = value
return output

def kpss_test(timeseries):
test = kpss(timeseries, return=&#39;c&#39;, nlags=&#39;auto&#39;)
output = pd.Series(
test[0:3], index=[&#39;测试统计量&#39;, &#39;p-value&#39;, &#39;# Lags Used&#39;]
)
for key, value in test[3].items():
output[f&#39;临界值 ({key})&#39;] = value
return output

可以使用以下方法重现原始数据：
data = {&#39;Value&#39;: {
&#39;2018-01-31&#39;: 104242, &#39;2018-02-28&#39;: 98662, &#39;2018-03-31&#39;: 105616, 
&#39;2018-04-30&#39;: 101179, &#39;2018-05-31&#39;: 98739, &#39;2018-06-30&#39;: 100133, &#39;2018-07-31&#39;: 107332, &#39;2018-08-31&#39;: 103455, &#39;2018-09-30&#39;: 81907, &#39;2018-10-31&#39;: 92845, &#39;2018-11-30&#39;: 83670, &#39;2018-1 2-31&#39;：84512，&#39;2019-01-31&#39;：108605，&#39;2019-02-28&#39;：97747，&#39;2019-03-31&#39;：101699，&#39;2019-04-30&#39;：103547，&#39;2019-05-31&#39;： 100278, &#39;2019-06-30&#39;: 98013, &#39;2019-07-31&#39;: 115181, &#39;2019-08-31&#39;: 110444, &#39;2019-09-30&#39;: 99455, &#39;2019-10-31&#39;: 100262, &#39;2019- 11-30&#39;: 88399, &#39;2019-12-31&#39;: 94493, &#39;2020-01-31&#39;: 109185, &#39;2020-02-29&#39;: 99482, &#39;2020-03-31&#39;: 108055, &#39;2020-04-30&#39;: 102379, &#39;2020-05-31&#39;: 115724, &#39;2020-06-30&#39;: 137875, &#39;2020-07-31&#39;: 136895, &#39;2020-08-31&#39;: 134005, &#39;2020-09-30&#39;: 123025, 0-10-31&#39;：155176，&#39;2020-11-30&#39;：116240，&#39;2020-12-31&#39;：117168，&#39;2021-01-31&#39;：136058，&#39;2021-02-28&#39;：122891，&#39;2021-03-31&#39;： 166424, &#39;2021-04-30&#39;: 152417, &#39;2021-05-31&#39;: 126856, &#39;2021-06-30&#39;: 173682, &#39;2021-07-31&#39;: 166529, &#39;2021-08-31&#39;: 147111, &#39;202 1-09-30&#39;：137624，&#39;2021-10-31&#39;：133565，&#39;2021-11-30&#39;：132117，&#39;2021-12-31&#39;：124160，&#39;2022-01-31&#39;：135815，&#39;2022-02-28&#39;： 127005, &#39;2022-03-31&#39;: 145378,
&#39;2022-04-30&#39;: 138972, &#39;2022-05-31&#39;: 140055, &#39;2022-06-30&#39;: 164881,
&#39;2022-07-31&#39;: 164568, &#39;2022-08-31&#39;: 178675, &#39;2022-09-30&#39;: 149753,
&#39;2022-10-31&#39;: 127887, &#39;2022-11-30&#39;: 114095, &#39;2022-12-31&#39;: 115408}}
df = pd.DataFrame(data)

其图表为：

我的测试为：
adf_test(df.diff(12).dropna())
kpss_test(df.diff(12).dropna())

ADF 测试返回临界值 -3.61 和 p 值 0.005。
KPSS 测试返回临界值 0.25 和 p 值 0.1，插值警告实际 p 值大于返回的 p 值。
这些表明季节性差分后不存在单位根和（水平）平稳性。但是，我收到反馈：

ADF 测试的 regression 参数应为 &#39;n&#39;。
KPSS 测试不合适，因为其回归参数只能是 &#39;c&#39; 或 &#39;ct&#39;，而不能是 &#39;n&#39;。
可视化的 12 个月差分序列似乎不是平稳的。

这些说法合适吗？尤其是，我从来没有听说过 KPSS 测试以这种方式不合适。]]></description>
      <guid>https://stats.stackexchange.com/questions/653797/appropriateness-of-adf-kpss-tests-after-seasonal-differencing</guid>
      <pubDate>Tue, 03 Sep 2024 16:01:06 GMT</pubDate>
    </item>
    <item>
      <title>具有幂律分布的自激马尔可夫过程的文献</title>
      <link>https://stats.stackexchange.com/questions/653740/literature-for-self-excited-markovian-processes-with-power-law-distributions</link>
      <description><![CDATA[我正在研究一个事件时间序列模型，该模型具有事件间隔的幂律分布。我选择了一个由随机微分方程控制的点过程
$$
d\lambda = -a \lambda^2 dt + b\eta,
$$
其中 $\lambda$ 是泊松过程的强度，$a$ 和 $b$ 是常数，$\eta \sim \text{Ber}(\lambda dt)$ 是事件变量，如果事件发生则等于 1，否则等于 0。这个方程式看起来很简单，一定有人研究过它或类似的方程式，但似乎找不到它。有什么建议应该在哪里寻找吗？
PS。我熟悉霍克斯过程、非线性霍克斯过程和二次霍克斯过程，但它们都是非时间局部的。此外，霍克斯过程根本不为事件间隔提供幂律分布，而其他模型似乎要复杂得多]]></description>
      <guid>https://stats.stackexchange.com/questions/653740/literature-for-self-excited-markovian-processes-with-power-law-distributions</guid>
      <pubDate>Mon, 02 Sep 2024 12:39:40 GMT</pubDate>
    </item>
    <item>
      <title>了解 XGboost 早期轮次的预测</title>
      <link>https://stats.stackexchange.com/questions/653649/understanding-predictions-from-early-rounds-of-xgboost</link>
      <description><![CDATA[我有一个数据集，我正在通过 xgboost 使用伽马回归进行建模。目标变量的平均值约为 13,000。如果我以 nrounds = 20 运行 xgb.train，我的拟合指标会得到如下改进：
[1] eval-gamma-nloglik:19068.589753 train-gamma-nloglik:19214.349747 
[2] eval-gamma-nloglik:14126.776741 train-gamma-nloglik:14234.760451 
[3] eval-gamma-nloglik:10465.869439 train-gamma-nloglik:10545.868618 
[4] eval-gamma-nloglik:7753.880010 train-gamma-nloglik:7813.146760 
[5] eval-gamma-nloglik:5744.865650 train-gamma-nloglik:5788.775051 [6] eval-gamma-nloglik:4256.630570 train-gamma-nloglik:4289.161127 [7] eval-gamma-nloglik:3154.190101 train-gamma-nloglik ：3178.297719 [8] eval-gamma-nloglik：2337.566473 train-gamma-nloglik：2355.427432 [9] eval-gamma-nloglik：1732.674952 train-gamma-nloglik：1745.907601 [10]    eval-gamma-nloglik：1284.639146 train-gamma-nloglik：1294.441921 [11] eval-gamma-nloglik：952.802399 train-gamma-nloglik：960.065419 [12] eval-gamma-nloglik：707.048396 train-gamma-nloglik： 712.430466 [13] eval-gamma-nloglik:525.066581 train-gamma-nloglik:529.055224 [14] eval-gamma-nloglik:390.324413 train-gamma-nloglik:393.284621 [15]    eval-gamma-nloglik:290.585986 train-gamma-nloglik:292.780028 [16] eval-gamma-nloglik:216.774041 train-gamma-nloglik:218.400892 [17] eval-gamma-nloglik:162.168768 train-gamma-nloglik:16 3.375479 [18] eval-gamma-nloglik:121.791626 train-gamma-nloglik:122.687146 [19] eval-gamma-nloglik:91.956086 train-gamma-nloglik:92.619277 [20] eval-gamma-nloglik:69.927169 train-gamma-nloglik:70.418368 

如果我对验证集进行预测，20 轮后该模型的平均预测为 194 - 相对于目标变量的大小（平均值为 13,000），这似乎很荒谬。直到大约 50 轮后，我才得到相对于目标变量大小的合理结果。我对算法的理解是，Tree 0 至少应该产生一个合理的模型，即使它基本上只是一个没有实际分割的截距，因为选择了一个坏变量作为它的覆盖。
我是否遗漏了关于提升树如何工作的某些内容，或者这只是一个教训，即如果 nrounds 太低，该模型基本上毫无意义，比仅截距模型更糟糕？]]></description>
      <guid>https://stats.stackexchange.com/questions/653649/understanding-predictions-from-early-rounds-of-xgboost</guid>
      <pubDate>Fri, 30 Aug 2024 21:01:01 GMT</pubDate>
    </item>
    <item>
      <title>三角相关？</title>
      <link>https://stats.stackexchange.com/questions/653518/triangular-correlations</link>
      <description><![CDATA[正如我在 https://stats.stackexchange.com/a/652022/11887 上的回答中所使用的，三角相关似乎是一个有用的概念/术语，可以得到更多的使用。但搜索后我发现它没什么用，下面是一些例子。也许还有其他术语在使用？一些文献中的例子：


这是学生课程成绩与（y 轴）缺课率的关系，似乎缺课率给出了成绩的近似上限。来自 Othmar W Winkler 的论三角相关。他说

尽管缺课和学期成绩之间存在明显的关系，但使用线性回归计算的相关系数为 r = -.18024。对此进行解释$R^2 = .03249$似乎表明，了解缺课百分比几乎无法解释这些课程成绩分散的 3%。

如果没有图表，这似乎非常具有误导性。该论文中的另一个例子：

他将其包括进来是为了展示来自科学而非社会科学的例子。摘自
&quot;Shake hole, A morphometric Field Project for Sixth-Form Geographers&quot; Geography, Vol. 65 pt. 3, July 1980, No. 288&quot;（我无法通过互联网搜索找到它）。其他有趣的例子可以在 Richard R. Hake 的 互动参与与传统方法：对入门物理课程力学测试数据的六千名学生调查中找到。
同一作者的另一篇论文（较短），包含相同的图（没有围起来），是 一种简单的图形方法来评估相关性。
应如何分析和呈现此类数据？相关系数似乎没什么用...还有其他例子吗？是否使用了其他术语？]]></description>
      <guid>https://stats.stackexchange.com/questions/653518/triangular-correlations</guid>
      <pubDate>Wed, 28 Aug 2024 23:41:28 GMT</pubDate>
    </item>
    </channel>
</rss>