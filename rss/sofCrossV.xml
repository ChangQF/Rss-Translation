<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 16 May 2024 15:14:49 GMT</lastBuildDate>
    <item>
      <title>您可以使用 ANCOVA 评估适度吗？</title>
      <link>https://stats.stackexchange.com/questions/647365/can-you-assess-moderation-with-ancova</link>
      <description><![CDATA[我正在使用 SPSS 进行 1 组 IV（4 个水平）的分析，每组中的每个参与者在时间 1 和时间 2 测量一个 DV，并在时间 2 测量一次协变量。每组接受不同类型的在时间 1 和 2 之间进行干预。
我计划使用组内变量作为时间进行 2 x 4 混合 ANCOVA。我可以使用相同的模型来评估 CV 的调节效果吗？我想根据 CV 水平了解哪组/（干预类型）的 DV 增加幅度更大。
我正在考虑进行后续审核；但是，我不确定是否可以通过将 git 作为受试者内因素来计算模型中的时间 1 DV 分数。
我想看看当我调整 CV 时，IV 对 DV 的影响是否显着。我还想看看 IV 和 IV 之间的关系在不同的 CV 点是否会发生变化。我不确定这两项调查是否从根本上相互对立（即，由于违反了彼此的模型假设，两者不能同时发挥重要作用）。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647365/can-you-assess-moderation-with-ancova</guid>
      <pubDate>Thu, 16 May 2024 15:13:02 GMT</pubDate>
    </item>
    <item>
      <title>在这种情况下，FCI（快速因果推理）算法是否自相矛盾？有向边可见吗？</title>
      <link>https://stats.stackexchange.com/questions/647364/does-the-fci-fast-causal-inference-algorithm-contradict-itself-in-this-case-i</link>
      <description><![CDATA[
以上两个 PAG 都是在相同条件下使用 FCI 算法生成的，唯一的区别是右边的 PAG 是在从数据集中排除变量 5 后生成的。鉴于左侧 PAG 中的变量 5 是 9 和 11 的常见原因（混杂因素），我预计从数据集中删除变量 5 后，右侧 PAG 中将在 9 和 11 之间出现一个双头箭头，表示变量 9 和 11 混淆或缺少共同原因。因此，FCI 算法似乎是自相矛盾的。
有人向我指出我的上述推理是错误的。特别是，从 9 到 11 的有向边与 9 和 11 的未测量混杂因素（即 5）并不矛盾。我应该将从 9 到 11 的有向箭头解释为 9 只是 11 的祖先（不是父级？），并且这个有向箭头本身并不能肯定 9 和 11 之间不存在混杂因素。更深入地研究这一点需要我们将有向边分类为可见或&lt; em&gt;不可见。只有当我们能够确定 9 和 11 之间的有向边可见时，我提出的 2 个 PAG 彼此不兼容的主张才成立，因为可见的有向边与未测量的混杂因素不兼容端点的，而不可见的有向边缘与端点的未测量的混杂因素兼容。
有人可以确定 9 和 11 之间的有向边是否可见并解释一下此分析中涉及的步骤吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647364/does-the-fci-fast-causal-inference-algorithm-contradict-itself-in-this-case-i</guid>
      <pubDate>Thu, 16 May 2024 15:07:50 GMT</pubDate>
    </item>
    <item>
      <title>比较具有不同变量数量的两组之间的回归斜率</title>
      <link>https://stats.stackexchange.com/questions/647363/comparing-regression-slopes-between-two-groups-that-have-differing-number-of-var</link>
      <description><![CDATA[我被要求比较 R 中两个多元线性回归之间的斜率（例如，找到斜率之间的 p 值），并将年龄作为模型中的协变量。这是通常做的事情吗？你能帮我在 R 中完成这个任务吗？
基因 &lt;- c(9508,6064,7148,6505,9855,7868,7806,7189,6200,8336)
测试 &lt;- c(47,57,42,45,67,34,30,38,38,40)
年龄 &lt;- c(9.333,12,10.916,4.583,5.583,12.583,14.583,12.167,12.916,12.667)
Group &lt;- c(1, 1, 1, 1, 2, 2, 2, 2, 2, 2) # 假设 1 为实验组，2 为对照组
数据 &lt;- data.frame(基因 = 基因,
                   测试=测试，
                   年龄=年龄，
                   组=组）
]]></description>
      <guid>https://stats.stackexchange.com/questions/647363/comparing-regression-slopes-between-two-groups-that-have-differing-number-of-var</guid>
      <pubDate>Thu, 16 May 2024 14:48:00 GMT</pubDate>
    </item>
    <item>
      <title>随时间变化的对数秩检验？</title>
      <link>https://stats.stackexchange.com/questions/647357/log-rank-test-for-a-time-dependent-variable</link>
      <description><![CDATA[我正在研究时间依赖性治疗变量与死亡之间的关联。治疗具有时间依赖性，因为患者可以在随访期间更换组。我关注了[本文]（https://www.tandfonline.com/doi/abs /10.1198/000313005X70371），使用计数过程数据创建扩展的 Kaplan Meier 曲线。然后尝试使用对数秩检验来比较曲线。我的问题是对数秩检验是否可以用于随时间变化的变量。我搜索过，但没有找到关于这个话题的太多讨论。感谢您的任何意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/647357/log-rank-test-for-a-time-dependent-variable</guid>
      <pubDate>Thu, 16 May 2024 13:47:32 GMT</pubDate>
    </item>
    <item>
      <title>倾向评分匹配后的亚组分析</title>
      <link>https://stats.stackexchange.com/questions/647356/subgroup-analyses-after-propensity-score-matching</link>
      <description><![CDATA[假设倾向得分已经匹配群组。
倾向评分模型中包含的变量之一是性别。
主要cox模型研究两种药物缓解癌症的比较效果。
coxph(Surv(时间，状态) ~ 药物，数据 = 数据)

现在我想研究一种可能的调节（按性别）。
根据 Green &amp; Stuart (2014)，估计单独的倾向评分模型可以显示出最佳的平衡。
因此，我创建了两个数据集（男性和女性）并计算了匹配的倾向得分。
对于每个数据集，我对 cox 模型使用了与主效应相同的公式。
这与原始数据集中（包括男性和女性）的 cox 模型的计算有何不同？：
coxph(Surv(时间，状态) ~ 药物：性别，数据 = 数据)
]]></description>
      <guid>https://stats.stackexchange.com/questions/647356/subgroup-analyses-after-propensity-score-matching</guid>
      <pubDate>Thu, 16 May 2024 13:46:38 GMT</pubDate>
    </item>
    <item>
      <title>当使用人类身高的正态近似值时，两个身高未知但大致相等的人都很高的概率是多少？</title>
      <link>https://stats.stackexchange.com/questions/647354/when-using-normal-approximations-of-human-height-whats-the-probability-two-peo</link>
      <description><![CDATA[基本上，我看到了一张两个身高大致相等的人的照片，并突然想到“他们都很高的可能性有多大？”。这就是我想回答的问题。
我承认我的想法可能犯了错误，但我认为这只是我不知道如何进行最后一步。
我在数学上思考这个问题的方式是，我们可以假设高度的法线，即 $X \sim N(\mu_X,\sigma^2_X), Y \sim N (\mu_Y,\sigma^2_Y)$，因此我的问题是：
$$\mathbb{P}(X = x_1 = Y = y_1 \pm \frac{\epsilon}{2} \space \cap \space x_1 &gt; \mu_X \space \cap \space y_1 &gt; \mu_Y)$$
其中 $\epsilon$ 是一些小的正常数，代表视觉等效的限制，例如如果约翰身高 181 厘米，亨利身高 182 厘米，当你站在一起时，你真的能看出他们的身高不同吗？我认为不是，因此 $\epsilon$。
现在，虽然我怀疑一起拍照的两个人实际上并没有独立的高度，但我可以假设他们是独立的，因此：
$$\mathbb{P}(X = x_1 = Y = y_1 \pm \frac{\epsilon}{2}) \cdot\mathbb{P}(x_1 &gt; ; \mu_X)\cdot \mathbb{P}(y_1 &gt; \mu_Y)$$
我相信最后两个可以简单地计算为 $\mathbb{P}(x_1 &gt; \mu_X) = \mathbb{P}(X &gt; \mu_X)$  = 1 - rnorm(mu, mu, sigma) （使用 R）但我不知道如何做第一个，特别是在 $X = 的情况下Y$，这是如果两个人都是男性或都是女性时我会做出的假设。特别是，起点似乎是这样的：
$$\mathbb{P}(X &gt; Y) =&gt; X - Y \sim N(\mu_X - \mu_Y, \sigma_X^2 - \sigma_Y^2) $$
但当 $X = Y 时，显然会是 $X - Y \sim N(0, 0)$ $，我不知道如何使用。我更不知道如何合并我的 $\epsilon$ 广泛的视觉等效区间。]]></description>
      <guid>https://stats.stackexchange.com/questions/647354/when-using-normal-approximations-of-human-height-whats-the-probability-two-peo</guid>
      <pubDate>Thu, 16 May 2024 13:02:16 GMT</pubDate>
    </item>
    <item>
      <title>Clopper-Pearson CI 用于 Python 中的发病率</title>
      <link>https://stats.stackexchange.com/questions/647353/clopper-pearson-ci-for-an-incidence-rate-in-python</link>
      <description><![CDATA[我确实有自己的 Python 代码来计算发病率的 Clopper-Pearson 置信区间。除了审查这段代码之外，我更希望有一个标准的包函数。但例如在 scipy 中我找不到一个。这可能取决于我使用的错误搜索词？
这是代码：
from scipy.stats import beta

# 格格贝内·沃特
x = 113235 # 观察值
n = 737237 # 参考人群
fx = 1000 # 相乘因子
alpha = 0.05 # 置信度 niveau

＃ 发病率
ir = x / n * fx

# 克洛珀-皮尔逊-CI
CI_lower = beta.ppf((1 - 95 / 100) / 2, x, n - x + 1) * fx
CI_upper = beta.ppf((1 + 95 / 100) / 2, x + 1, n - x) * fx

print(f&#39;IR: {round(ir, 2)}&#39;)
print(f&#39;Clopper-Pearson-95% CI: ({round(CI_lower, 2)}, {round(CI_upper, 2)})&#39;)

这个输出：
&lt;前&gt;&lt;代码&gt;IR：153.59
Clopper-Pearson-95% CI：（152.77，154.42）
]]></description>
      <guid>https://stats.stackexchange.com/questions/647353/clopper-pearson-ci-for-an-incidence-rate-in-python</guid>
      <pubDate>Thu, 16 May 2024 12:38:52 GMT</pubDate>
    </item>
    <item>
      <title>2 个独立的数值数据集。 A 是法律类别的优先级（1 到 10）。 B - 对同一事物优先级的看法。使用什么统计测试？</title>
      <link>https://stats.stackexchange.com/questions/647352/2-independent-numerical-datasets-a-is-prioritisation-1-to-10-of-legal-categor</link>
      <description><![CDATA[我有 2 个数据集。其中一个（A 组）是立法中的类别排名。另一组数据（B）是社区成员对相同类别的排名。我想对此进行统计分析，以确定是否存在一致性 - 即法律和社区是否相似。]]></description>
      <guid>https://stats.stackexchange.com/questions/647352/2-independent-numerical-datasets-a-is-prioritisation-1-to-10-of-legal-categor</guid>
      <pubDate>Thu, 16 May 2024 12:21:59 GMT</pubDate>
    </item>
    <item>
      <title>如何制作一个简单的聊天机器人 - 当你深入/充分了解 Python 基础知识和 JavaScript 时 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647350/how-to-make-a-simple-chat-bot-when-you-know-python-basics-and-javascript-in-de</link>
      <description><![CDATA[我想参加今年 6 月 4 日举行的当地人工智能竞赛。 （还有两周半的时间。）我有一个好主意想提交。
我需要关于使用什么路线图来学习人工智能的建议。这是我迄今为止所掌握的知识。
JavaScript：

我拥有 Udemy 颁发的全栈 Web 开发证书。
这意味着我可以使用 html、css 和 JavaScript 制作一个网站。
而且我也熟悉 Node JS、Express Mongo DB 等。
我对前端开发比后端开发更满意
时刻。

Python：

我在学校上过一个学期的 Python 课程，我真的很高兴
了解。
作为初学者，我可以轻松地使用 Python 进行编程。
但是我从未使用 Python 制作过任何网站。
我不知道如何在网站上显示Python代码
但我听说学习时推荐Python
人工智能。
出于某种原因，我觉得使用 Python 编程比使用 Python 编程更舒服
使用 JavaScript。

从这里学习人工智能最有效的途径是什么。既是为了比赛，也只是为了学习人工智能。
编辑
大家好，感谢您迄今为止的回复。我正在编辑问题，尝试使其更加具体和切题：
如何利用如上所述的基础知识/知识开始制作一个简单的聊天机器人？聊天机器人应该能够向用户提供有关国家财政/收入状况等数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/647350/how-to-make-a-simple-chat-bot-when-you-know-python-basics-and-javascript-in-de</guid>
      <pubDate>Thu, 16 May 2024 10:04:22 GMT</pubDate>
    </item>
    <item>
      <title>将质量体积解释为无监督异常检测的评估标准</title>
      <link>https://stats.stackexchange.com/questions/647349/interpreting-mass-volume-as-an-evaluation-criterion-for-unsupervised-anomaly-det</link>
      <description><![CDATA[我发现这篇论文讨论了通过使用什么来评估无监督异常评分函数作者称之为质量体积和过剩质量。我还从这里的论文中找到了代码，这相当不错便利。我专注于 M-V，并试图解释其含义以及为什么它有意义。
质量-体积描述如下：
$$
MV_{s}(\alpha) = \inf_{u \geq 0} Leb(s(\mathbf{U}) \geq u) ~~~ s.t. ~~~ \mathbb{P}(s((\mathbf{X})) \geq u) \geq \alpha
$$
哪里
$\alpha$ 是累积质量
$s$ 是一些异常评分函数
$\mathbf{X}$ 是我们的特征集，维度为 (N,M)
$\mathbf{U}$ 是一个随机生成的多元均匀变量，以下边界 $\inf(\mathbf{ X})$ 和上限 $\sup(\mathbf{X})$。这本质上创建了一个从最小特征值到最大特征值的矩形。
$u$ 是我们评估勒贝格度量的分位数，表示为 $Leb$。
在 Python 中的实现中，如下所示：
clf = SomeAnomalyScoringModel()


阿尔法最小值 = 0.9
阿尔法最大值 = 0.999
axis_alpha = np.arange(alpha_min, alpha_max, 0.0001)


lim_inf = X.min(轴=0)
lim_sup = X.max(轴=0)
n_生成 = 100000
unif = np.random.uniform(lim_inf, lim_sup,
                            大小=（n_生成，n_特征））
Volume_support = (lim_sup - lim_inf).prod()


s_unif = clf.decision_function(unif)
s_x = clf.decision_function(X)


def 质量体积（axis_alpha、volume_support、s_unif、s_X、n_generate）：
    n_samples = s_X.shape[0]
    s_X_argsort = s_X.argsort()
    质量 = 0
    点 = 0
    u = s_X[s_X_argsort[-1]]
    mv = np.zeros(axis_alpha.shape[0])
    对于范围内的 i(axis_alpha.shape[0])：
        而质量&lt; axis_alpha[i]：
            #在这里找你
            cpt += 1
            u = s_X[s_X_argsort[-cpt]]
            质量 = 1./ n​​_samples * cpt # sum(s_X &gt; u)
        mv[i] = float((s_unif &gt;= u).sum()) / n_ generated * volume_support
    返回 auc(axis_alpha, mv), mv

我对这里发生的事情有一个大概的了解。通过对 $s(x)$ 进行排序，我们正在寻找给定 $u$ =&quot;math-container&quot;&gt;$\alpha$ 通过添加 $mass$ 直到达到所需的  $\alpha$-质量。完成后，我们停止，因为我们已经达到约束 $\mathbf{P}(s(\mathbb{X})\geq q) \geq \alpha$&lt; /跨度&gt;。此时，我们计算 $Leb(s(\mathbf{U})\geq u)$。我们对所有所需的 $\alpha$ 级别重复此操作。
这里有两个问题：
我们如何解释这一点？我最好的解释是，我们将评分函数 $s$ 视为均匀分布（由设计没有离群值），并在到达真实得分分布的尾部后测量其累积密度，以勒贝格测量为代表（因此，在本例中只是面积）。但这如何表明 $s$ 是一个好模型呢？
为什么 Lebesgue 定义为 float((s_unif &gt;= u).sum()) / n_generate *volume_support？
当统一变量大于$u$时，这相当于矩形盒子的体积，那么它是二元累积密度吗？这是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647349/interpreting-mass-volume-as-an-evaluation-criterion-for-unsupervised-anomaly-det</guid>
      <pubDate>Thu, 16 May 2024 09:45:24 GMT</pubDate>
    </item>
    <item>
      <title>匹配后：如何解释 r 包 cobalt bal.tab 的平衡度量表中“距离”类型的值（=倾向得分）？</title>
      <link>https://stats.stackexchange.com/questions/647348/after-matching-how-do-i-interpret-the-value-of-the-type-distance-propensity</link>
      <description><![CDATA[我使用了R 包“MatchIt” 来执行 (1) 基于弗雷明汉心脏研究的最近邻倾向得分匹配 (NNM) 和 (2) 进行比较，最佳 PS相同 PS 模型的匹配（OM）。
PS 模型：BPMeds ~ 年龄 + 男性 + 教育程度 + BMI + 糖尿病 + prevalentHyp
对于天平诊断，我使用了R-Package ‘Cobalt’的bal.tab功能，并得到了以下结果：
&lt;前&gt;&lt;代码&gt;
平衡措施
                 类型 M.0.Un M.1.Un Diff.Un M.0.Adj M.1.Adj Diff.Adj M.Threshold
距离 距离 0.0276 0.1188 1.7333 0.1172 0.1172 -0.0003 平衡，&lt;0.1
年龄 继续。 49.3479 56.0721 0.8821 56.0000 56.0182 0.0024 平衡，&lt;0.1
男性 二元 0.4483 0.2973 -0.1510 0.3091 0.3000 -0.0091 平衡，&lt;0.1
教育 继续1.9828 1.9009 -0.0812 1.9000 1.8909 -0.0090 平衡，&lt;0.1
BMI 继续。 25.7068 28.2104 0.4770 28.2804 28.1248 -0.0296 平衡，&lt;0.1
糖尿病 二元 0.0257 0.0721 0.0464 0.0636 0.0636 0.0000 平衡，&lt;0.1
prevalentHyp 二元 0.2901 1.0000 0.7099 1.0000 1.0000 0.0000 平衡，&lt;0.1

平均差的平衡计数
                   数数
平衡，&lt;0.1 7
不平衡，&gt;0.1 0

具有最大平均差的变量
 可变 Diff.Adj M.Threshold
      BMI -0.0296 平衡，&lt;0.1

样本量
          对照处理
全部 3547 111
已匹配 110 110
无与伦比 3437 1

bal.tab(m.framingham_**OM**, Continuous = &quot;std&quot;, binary = &quot;raw&quot;, disp = c(&quot;means&quot;), un = TRUE, stats = c(&quot;m&quot;) ,+ 阈值 = c(m = .10))
平衡措施
                 类型 M.0.Un M.1.Un Diff.Un M.0.Adj M.1.Adj Diff.Adj M.Threshold
距离 距离 0.0276 0.1188 1.7333 0.1184 0.1188 0.0085 平衡，&lt;0.1
年龄 继续。 49.3479 56.0721 0.8821 56.5135 56.0721 -0.0579 平衡，&lt;0.1
男性 二元 0.4483 0.2973 -0.1510 0.3423 0.2973 -0.0450 平衡，&lt;0.1
教育 继续1.9828 1.9009 -0.0812 1.9820 1.9009 -0.0804 平衡，&lt;0.1
BMI 继续。 25.7068 28.2104 0.4770 27.8785 28.2104 0.0632 平衡，&lt;0.1
糖尿病 二元 0.0257 0.0721 0.0464 0.0721 0.0721 0.0000 平衡，&lt;0.1
prevalentHyp 二元 0.2901 1.0000 0.7099 1.0000 1.0000 0.0000 平衡，&lt;0.1

平均差的平衡计数
                   数数
平衡，&lt;0.1 7
不平衡，&gt;0.1 0

具有最大平均差的变量
  可变 Diff.Adj M.Threshold
 教育程度 -0.0804 平衡，&lt;0.1

样本量
          对照处理
全部 3547 111
已匹配 111 111
无与伦比 3436 0


如何解释 r 包 cobalt bal.tab 平衡度量表第一行中“距离”类型的值（=倾向得分）？
我可以使用距离来说明哪种匹配方法更适合（比较 NNM 与 OM 的两种模型/匹配方法）吗？

我刚刚找到以下关于距离的描述，但没有解释（ https://ngreifer.github.io/cobalt/reference/bal.tab.matchit.html）：
距离包含距离值距离（例如倾向得分）的可选公式或数据框或包含其名称的字符向量。如果指定了公式或变量名称，bal.tab() 将在 data 的参数中查找（如果指定）。由 matchit() 生成的距离测量（例如倾向得分）会自动包含在内并命名为“距离”。]]></description>
      <guid>https://stats.stackexchange.com/questions/647348/after-matching-how-do-i-interpret-the-value-of-the-type-distance-propensity</guid>
      <pubDate>Thu, 16 May 2024 09:41:28 GMT</pubDate>
    </item>
    <item>
      <title>如果样本数据遗漏了某些内容，我可以使用它吗？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647339/can-i-use-a-sample-data-if-it-misses-sth-out</link>
      <description><![CDATA[我正在研究学校、电子设备使用模式和睡眠质量之间的关系。最初我们计划对3所学校的2个系进行抽样，只询问了他们的系。不属于以上6个部门的参与者将被标记为“其他部门”。
但是，有些院系没有足够的学生，后来我们被告知可以为每所学校抽取两个以上的院系。
首先，标签为“其他部门”的样品如何处理？
大多数研究都删除了它们，但我可以在检验与学校无关的假设时使用它们吗？
第二，如果我发现学校与睡眠质量或 ED 使用模式相关，我可以使用后面的两个 v. 来预测学校吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647339/can-i-use-a-sample-data-if-it-misses-sth-out</guid>
      <pubDate>Thu, 16 May 2024 06:53:14 GMT</pubDate>
    </item>
    <item>
      <title>FPP教材中简单指数平滑（状态空间形式）的误差和残差</title>
      <link>https://stats.stackexchange.com/questions/647280/errors-and-residuals-in-simple-exponential-smoothing-state-space-form-in-fpp-t</link>
      <description><![CDATA[我正在阅读 Hyndman &amp; Athanasopoulos《预测：原理与实践》第二版（FPP2）。 （我知道存在第三版。）在关于指数平滑的章节中，第 7.5 节讨论了具有附加误差的简单指数平滑，ETS(A,N,N)。它引入了残差 $e_t:=y_t-\ell_{t-1}$ 其中 $\ell_{t-1 }$ 是平滑方程的滞后水平。然后就在下面几行，有下面一段话：
&lt;块引用&gt;
对于具有加性误差的模型，我们假设残差（一步训练误差）$e_t$ 是正态分布的白噪声，平均值为 $0$ 和方差 $\sigma^2$。其简写形式为 $e_t = \varepsilon_t \sim NID(0,\sigma^2)$; NID 代表“正态独立分布”。

然后使用 $e_t$ 的一些方程用 $\varepsilon_t$ 重写。我对引用段落中 $e_t = \varepsilon_t$ 的含义有点困惑。它只是为 $e_t$ 引入了一个新符号吗？如果是这样，为什么不从一开始就使用 $\varepsilon_t$ 呢？或者 $e_t = \varepsilon_t$ 是否具有其自身的某种含义，告诉我们一个对象等于另一个对象？如果是这样，会有什么影响？简而言之，编写 $e_t = \varepsilon_t$ 的意义是什么？
（本书的某些部分似乎对模型误差（随机变量）、拟合误差/残差（其拟合值）和输入与输出之间的区别不太仔细，这并没有帮助。样本预测误差（随机变量或其实现）。）]]></description>
      <guid>https://stats.stackexchange.com/questions/647280/errors-and-residuals-in-simple-exponential-smoothing-state-space-form-in-fpp-t</guid>
      <pubDate>Wed, 15 May 2024 11:39:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么机器学习模型要学习概率分布以及为什么它很重要？</title>
      <link>https://stats.stackexchange.com/questions/647266/why-do-ml-models-learn-probability-distributions-and-why-does-it-matter</link>
      <description><![CDATA[我知道这个问题很愚蠢，但我已经阅读和编码了神经网络很长一段时间，研究了反向传播等等。
但是，我认为我从未理解过神经网络建模的概率分布是什么？
我确实知道它们是频率与特征图，但我为什么了解数据集中 L 形边界的数量会有帮助呢？
当然，我也没有看到线性回归学习任何这些（我寻找一个非常简单的案例来分析。）
如果可能的话，您的概念解释是什么？您能给我推荐一些针对这方面的初学者的文章吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647266/why-do-ml-models-learn-probability-distributions-and-why-does-it-matter</guid>
      <pubDate>Wed, 15 May 2024 08:46:40 GMT</pubDate>
    </item>
    <item>
      <title>使用 mgcv 的 GAM 中的随机效应与使用 lme4 的 LMM 中的随机效应</title>
      <link>https://stats.stackexchange.com/questions/647242/random-effects-in-gams-with-mgcv-vs-random-effects-in-lmms-with-lme4</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647242/random-effects-in-gams-with-mgcv-vs-random-effects-in-lmms-with-lme4</guid>
      <pubDate>Tue, 14 May 2024 21:41:43 GMT</pubDate>
    </item>
    </channel>
</rss>