<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 11 Oct 2024 15:17:24 GMT</lastBuildDate>
    <item>
      <title>基于梯度法的攻击对于神经网络来说似乎没有意义，因为训练误差是非凸的</title>
      <link>https://stats.stackexchange.com/questions/655655/the-gradient-method-based-attack-does-not-seem-make-sense-for-neural-networks-be</link>
      <description><![CDATA[有几种基于梯度的攻击方法。设$J$为训练误差，则例如投影梯度攻击为，
$$
\widetilde{x} = \Pi( x + \epsilon \nabla_x J(\theta, x, y) )
$$
快速有符号梯度法为
$$
\widetilde{x} = x + \epsilon \text{sign}( \nabla_x J(\theta, x, y) )
$$
这些方法都假设我们正在添加$\nabla_x J(\theta, x, y)$。这是在假设$\nabla_x J(\theta, x, y)$指向$J$相对于$x$的最大无穷增量方向的情况下实现的。
但这个假设是错误的，因为$J$是$x$的非凸函数。因此，添加 $\nabla_x J(\theta, x, y)$ 不一定会产生 $\widetilde x$，从而产生更大的 $J$ 值。
由于大多数这些方法都是单步的，因此不能保证 $\widetilde x$ 会增加 $J$ 的值，它甚至可能会降低 $J$ 的值。
我的推理有缺陷吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655655/the-gradient-method-based-attack-does-not-seem-make-sense-for-neural-networks-be</guid>
      <pubDate>Fri, 11 Oct 2024 14:53:11 GMT</pubDate>
    </item>
    <item>
      <title>我如何对多个分布进行排序或分类，然后总结这个有序列表的“分位数”？</title>
      <link>https://stats.stackexchange.com/questions/655654/how-can-i-order-or-sort-many-distributions-then-summarize-the-quantiles-of-th</link>
      <description><![CDATA[对大量分布进行排序的最佳做法是什么？执行此操作的不同方法有哪些优缺点？
假设我正在处理对调查问题的李克特评分，评分范围为 1 到 5。（例如：非常不同意；不同意；中立；同意；非常同意。或者另一个例子：差；一般；好；非常好；优秀。）但我想将它们作为批次的响应进行比较，而不是在单个响应的级别进行比较。
例如，想象一下产品的在线评级，从 1 到 5 星：我如何对一长串产品进行排序，每个产品都有自己的分布评级？
我知道没有单一的最佳方法来定义这种排序顺序，对于哪种排序最适合该任务，这是一个判断问题。例如，如果一个产品获得 10 个 1 星评级和 10 个 5 星评级，而另一个产品获得 20 个 3 星评级，那么两者之间没有明显的区别。但如果我必须对这些（以及 100 个其他产品评级分布）进行排序，我有什么选择？
我可以按均值排序：用 1 到 5 的数字表示 5 个李克特量表值，对每个批次取平均值，然后按平均值排序。但这忽略了一个事实，即 1 和 2 之间的差异可能与 4 和 5 之间的差异非常不同，等等。
我还可以按加权均值排序，即为某些值分配比其他值更大的权重（例如，5 的权重高于 4 等）。对于我的应用程序，我宁愿避免使用任何需要我们选择此类权重的方法；这需要利益相关者的认同和共识，而这很难实现。
或者我可以按高于/低于某个阈值的比例排序：例如，计算每个批次中评级为 4 或更高的比例，然后按这些比例排序。这似乎更好，但仍然取决于我选择的阈值。
我也听说过词典优势：首先按 5 的比例进行部分排序。然后，如果某些 5 的比例相等，则按其 4 的比例对该子组进行排序。依此类推。这似乎更好，但我可能忽略了这种方法的一些明显缺点。
还有哪些其他方法可以定义此类分布的全序？它们的优点和缺点是什么？

（PS——我在这个网站上找到的最接近的问题是这里。但它专注于一种特定的方法，而且大家似乎一致认为这不是一个很好的方法。我很好奇还有哪些其他替代方案。）
（PPS——如果我错过了与此相关的其他问题/答案，请见谅；我找不到正确的关键字来搜索。我曾尝试搜索有关“随机顺序”或“随机优势”的最佳实践，但我发现的大多数搜索结果都是关于部分顺序的。对于我的应用程序，我需要选择一个全顺序。）
（PPPS——上面列出的排序可能会受到小样本量的强烈影响。对于这个问题，假设所有批次的样本量都相同，因此重点只是排序/排序。我知道还有其他工具，如贝叶斯评级，可以帮助更公平地比较小批次和大批次；但这不是我在这里问的。）

如果有帮助，我最终想要做的是为这些分布选择某种“分位数”。例如：产品评级分数的“中位数”分布是什么？第 10 和第 90 个“百分位数”是多少？这样我们就能大致了解“看到这么糟糕/这么好的分数分布并不罕见”？
一种方法是先对分布进行全排序，然后使用排名列表中 10%、50% 和 90% 的分布作为示例/典范。
但也许还有其他方法可以选择或总结“低但不是最低”和“典型”以及“高但不是最高”的分布，而无需先对所有分布进行实际排序。我实际上可以显示每个百分位数的几个典范，因此如果“平局”组不是太大，则平局排序是可以的。我很想听听其他想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/655654/how-can-i-order-or-sort-many-distributions-then-summarize-the-quantiles-of-th</guid>
      <pubDate>Fri, 11 Oct 2024 14:41:45 GMT</pubDate>
    </item>
    <item>
      <title>规范化并模拟报告数据和调查回复之间的关系</title>
      <link>https://stats.stackexchange.com/questions/655650/normalize-and-model-relationships-between-report-data-and-survey-responses</link>
      <description><![CDATA[背景：
我有两个数据集的场景；

包含从报告系统收集的公司数据，我们称之为$ReportingData$，具有数字特征，例如hours_worked、meeting_hours、collaboration_hours、company_role、seniority，...等等。

同样的个人，在一项调查中，通过 0-5 之间的评分回答了诸如wellbeing、workplace_experience，...等问题。我们将其称为 $SurveyData$。


我想要做的事情：
我希望检查 $ReportingData$ 中的不同功能如何/是否能够提供有关人们如何响应 $SurveyData$ 的见解。也就是说，不同的功能如何有助于幸福感。我希望这能够为工作场所的改进提供指导，例如，“我们可以看到影响幸福感的最重要因素是hours_worked，占整体幸福感的 20%，因此，如果我们想改善幸福感，就应该专注于减少工作时间”。
问题：

由于我的数据包含来自所有不同角色和资历的分组数据，我认为重要的是要考虑到整个公司的期望和角色看起来非常不同。如果在部门$x$工作的人每周工作 60 小时，那么他们可能工作“很多”，而如果在部门$y$工作的人每周工作 44 小时，那么他们可能工作很多。我考虑过的一种方法是使用 Z 分数来根据不同的资历和角色对我的数据进行规范化。您对此有什么反馈意见，或者我是否应该尝试不同的方法？

您是否有任何建模建议，或者是否有适合我想要生成的输出的模型系列？我尝试过回归模型和百分比相对重要性作为评估指标。


谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655650/normalize-and-model-relationships-between-report-data-and-survey-responses</guid>
      <pubDate>Fri, 11 Oct 2024 13:56:03 GMT</pubDate>
    </item>
    <item>
      <title>解释如何在引入 pdf 后获得点概率的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/655649/what-is-the-best-approach-to-explaining-how-to-obtain-point-probabilities-after</link>
      <description><![CDATA[在解释概率密度函数 (pdf) 在假设检验中的用途后，有人问我它们在获得点概率（随机变量假设特定值的概率）中的用途。在我看来，最好的办法是找到变量假设值的范围非常接近该值的概率，但永远不是该值本身，并且当考虑将积分（表示曲线下的面积）相减时，情况仍然如此（或者更清楚地如此）。既然如此，我欢迎大家提出建议，在讨论点概率时，应该如何从 pdf 模型迁移到合适的替代模型，假设在与 pdf 上的先前学习建立有用的联系时，谈论相对频率（分子除以分母）不是一种非常自然的过渡。]]></description>
      <guid>https://stats.stackexchange.com/questions/655649/what-is-the-best-approach-to-explaining-how-to-obtain-point-probabilities-after</guid>
      <pubDate>Fri, 11 Oct 2024 13:24:49 GMT</pubDate>
    </item>
    <item>
      <title>在使用 ARMA 过程拟合 GAMM 时如何优化资源使用？</title>
      <link>https://stats.stackexchange.com/questions/655648/how-to-optimise-ressource-use-when-fitting-a-gamm-with-arma-process</link>
      <description><![CDATA[我正在根据一系列时间预测因素（例如一年中的时间、昼夜循环、潮汐……类似于此帖子）对每小时物种的出现情况（存在/不存在）进行建模。我使用收集自约 100 个人的数据，有 266,000 个数据点。我目前正在尝试按照以下结构拟合 GAMM 模型*：
ResGAM8 = gamm(data = Datanal, HL ~ s(Day) + s(Temperature) + s(ref, bs = &quot;re&quot;) + ti(Day, Temperature, SI), family = binomial, method = &quot;fREML&quot;, correlation = corARMA(form = ~1 | ref,p=1))

在之前的版本中，我使用 bam( ... rho = ) 来解释时间自相关，但是，ACF 和 pACF 仍然表明残差中存在一些自相关。因此，我决定在每个个体中嵌套一个 ARMA，以更好地解释时间自相关以及解释变量之间的相关性。 
我尝试在免费版 google colab 上运行此模型几次（大约 1 分钟后总是出现错误，表明会话已崩溃，因为它已达到分配的 RAM 限制）并在我自己的计算机上（没有 colab 快）运行了大约 2 个小时，没有任何显著的结果。

我的问题很简单（表述）：我如何优化这个过程以减少资源消耗（并避免上述问题）？

减少观察和/或个体的数量是可能的，但实际上是作为最后的手段，因为包括的动物数量是这项工作的原因之一。

*为了清楚起见，我删除了简单平滑中包含的一些解释变量]]></description>
      <guid>https://stats.stackexchange.com/questions/655648/how-to-optimise-ressource-use-when-fitting-a-gamm-with-arma-process</guid>
      <pubDate>Fri, 11 Oct 2024 12:48:58 GMT</pubDate>
    </item>
    <item>
      <title>有效影响功能的干预措施取决于暴露的自然价值</title>
      <link>https://stats.stackexchange.com/questions/655646/efficient-influence-function-with-interventions-that-depend-on-the-natural-value</link>
      <description><![CDATA[图 A1 显示了 SWIG，其中 L 是暴露 X 和结果 Y 之间关联的混杂因素。

我正在处理对 X 的干预，该干预根据其自然值对其进行修改（例如，不是每个人都设置为 1 的确定性静态方案）。例如，如果 X 的自然值为 2，则将其降低为 1，否则保持原样。感兴趣的因果效应（g 公式）定义如下（为了便于表示，我将干预节点表示为 $\tilde{x}$，而不是用红色标记）：
\begin{equation}
\Psi = \sum_{l, x, \tilde{x}} E \left[ Y | X = \tilde{x}, L=l \right] p \left( X = \tilde{x} | X=x, L=l \right) p \left( X=x | L=l \right) p(l)。
\label{eq:swig_1e1t_n}
\end{equation&gt;
我想构建一个双重稳健估计量，特别是增强逆概率加权 (AIPW) 估计量。因此，我想写下我的因果参数的有效影响函数 (EIF)。我遵循 Kennedy 2023 中的提示（此处）。为了便于表示，我将定义 $\mu(x,l) = E \left[ Y | X=x, L=l \right]$ 和 $\pi(x|l) = p \left( X=x | L=l \right)$。 EIF ($\mathbb{IF}$) 可以写成如下形式：
\begin{align}
\mathbb{IF}{(\Psi)} &amp;= \sum_{l, x, \tilde{x}} \mathbb{IF}{\left\{ \mu(\tilde{x},l) \right\}} p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) p(l) + \mu(\tilde{x},l) p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) \mathbb{IF}{\left\{ p(l) \right\}}.
\label{eq:swig_1e1t_n_eif}
\end{align&gt;
对于 EIF 求和中的第一个项，我们有：
\begin{align}
\mathbb{IF}{(\Psi)}_1 &amp;= \sum_{l, x, \tilde{x}} \frac{\mathbb{1}(X=\tilde{x}, L=l)}{p(X=\tilde{x}, L=l)} \left\{ Y^{\tilde{x}} - \mu(\tilde{x},l) \right\} p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) p(l) \nonumber \\
&amp;= \sum_{x} \frac{p \left( \tilde{X} | X=x, L \right) \pi(x|L)}{\pi(\tilde{X} | L)} \left\{ Y^{\tilde{x}} - \mu(\tilde{X},L) \right\}。
\end{align&gt;
对于 EIF 求和中的第二项，我们有：
\begin{align}
\mathbb{IF}{(\Psi)}_2 &amp;= \sum_{l, x, \tilde{x}} \mu(\tilde{x},l) p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) \left\{ \mathbb{1}(L=l) - p(l) \right\} \nonumber \\
&amp;= \sum_{x, \tilde{x}} \mu(\tilde{x},L) p \left( X = \tilde{x} | X=x, L \right) \pi(x|L) - \sum_{l, x, \tilde{x}} \mu(\tilde{x},L=l) p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) p(L=l) \nonumber \\
&amp;= \sum_{x, \tilde{x}} \mu(\tilde{x},L) p \left( X = \tilde{x} | X=x, L \right) \pi(x|L) - \Psi.
\end{align&gt;
将它们放在一起，我们得到：
\begin{equation}
\mathbb{IF}{(\Psi)} + \Psi = \sum_{x} \frac{p \left( \tilde{X} | X=x, L \right) \pi(x|L)}{\pi(\tilde{X} | L)} \left\{ Y^{\tilde{x}} - \mu(\tilde{X},L) \right\} + \sum_{x, \tilde{x}} \mu(\tilde{x},L) p \left( X = \tilde{x} | X=x, L \right) \pi(x|L)。
\label{eq:swig_1e1t_n_eif_derived}
\end{equation&gt;
Kennedy 2023 的评论中没有类似的例子，最接近的是随机干预。我正在将获得的 EIF 与此处找到的 EIF 进行比较，特别是第 15 页最后一段中写的 EIF：
\begin{equation}
r(A,L) (Y - m(A,L)) + m(\mathbb{d}(A,L), L) - \theta,
\end{equation&gt;
其中 $\theta$ 是感兴趣的参数，$r$ 是第 15 页顶部定义的密度比，$m$ 是给定暴露和混杂因素的预期结果。作者使用函数 $\mathbb{d}$ 来定义暴露干预。很明显，我的 EIF 和他们的并不相同，尽管相似。一个关键的区别是，在我的密度比（EIF 总和中的第一个项）中，$\tilde{X}$ 同时存在于分子和分母中。对于 $Y^{\tilde{x}}$ 和 $\mu(\tilde{X}, L)$ 也是如此。我不确定 EIF 的推导或 g 公式本身是否存在错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/655646/efficient-influence-function-with-interventions-that-depend-on-the-natural-value</guid>
      <pubDate>Fri, 11 Oct 2024 11:34:19 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中拟合一个分布，平均值是一些变量的线性组合</title>
      <link>https://stats.stackexchange.com/questions/655644/fit-a-distribution-in-r-with-the-mean-as-a-linear-combination-of-some-variable</link>
      <description><![CDATA[我想将 PDF 拟合到我的数据（最好是 Gamma），但我想使形状 $k$（或比例 $\theta$）线性依赖于某个外部变量 $t$：$k=a+bt$，其中 $a, b$ 系数待定。
奇怪的是，我知道如何使用 extRemes 对极值分布执行此操作，但我不知道如何在更一般的环境中执行此操作。也许这很简单，我不知道，我对 R 还比较陌生。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655644/fit-a-distribution-in-r-with-the-mean-as-a-linear-combination-of-some-variable</guid>
      <pubDate>Fri, 11 Oct 2024 11:17:10 GMT</pubDate>
    </item>
    <item>
      <title>从未知分布估计概率值大于 x</title>
      <link>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknow-distribution</link>
      <description><![CDATA[假设我们有 N 个项目的总体，其值从 0 到 6000。
假设总体的平均值是 $\mu$。
我们不知道项目的分布。
我们从这个总体中提取一个项目，我们如何估计 $P(x\geq 2500)$？
同样的问题，假设分布是均匀的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknow-distribution</guid>
      <pubDate>Fri, 11 Oct 2024 08:52:55 GMT</pubDate>
    </item>
    <item>
      <title>推导单位 n 球面上均匀分布矢量/点的 k 个坐标平方和的概率密度</title>
      <link>https://stats.stackexchange.com/questions/655611/derivation-for-the-probability-density-of-the-squared-sum-of-k-coordinates-of-a</link>
      <description><![CDATA[
n 球面上均匀分布的向量/点的单个坐标的分布是 beta 分布，如下所述：随机单位向量坐标的平均绝对值？

n 球面上均匀分布的向量/点的多个坐标的平方和的分布也是 beta 分布。


我想尝试以与第一点证明相同的方式推导出第二点。
这种证明将提供一种几何方法来推导 F 分布，该 F 分布可以与 n 球面上均匀点的 k 个坐标的平方和相关联（证明 F 统计量遵循 F 分布)。]]></description>
      <guid>https://stats.stackexchange.com/questions/655611/derivation-for-the-probability-density-of-the-squared-sum-of-k-coordinates-of-a</guid>
      <pubDate>Thu, 10 Oct 2024 16:04:19 GMT</pubDate>
    </item>
    <item>
      <title>选择零值计数数据进行组间显著性差异的统计检验</title>
      <link>https://stats.stackexchange.com/questions/655609/selecting-statistical-test-for-significant-difference-between-groups-from-count</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655609/selecting-statistical-test-for-significant-difference-between-groups-from-count</guid>
      <pubDate>Thu, 10 Oct 2024 15:41:21 GMT</pubDate>
    </item>
    <item>
      <title>标准化 beta 强度有一般解释吗？</title>
      <link>https://stats.stackexchange.com/questions/655605/is-there-a-general-interpretation-for-standardized-beta-strentgh</link>
      <description><![CDATA[运行线性回归模型后，我得到了 beta 作为效果大小。此线性回归模型在 r 中使用 geeglm 函数运行，指定 family= &quot;gaussian&quot;。该模型包括组状态（3 个级别）作为预测因子、结果和可交换相关结构，以解释数据集中的熟悉度（兄弟姐妹）。
例如：geeglm(educational_level ~ group_status, family = &quot;gaussian&quot;, id = ID, data = data, corstr = &quot;exchangeable&quot;)
通过标准化我的结果变量并运行相同的分析，我假设得到标准化 beta 而不是 beta 作为输出。
有了标准化 beta，我想评论一下我的关联的强度。我明白标准化 beta 值越高，关联越强。但是，是否有标准/通用的方法来解释标准化 beta 强度？就像解释 r 系数（皮尔逊相关系数）或 Cohen&#39;s D 的经验法则一样。]]></description>
      <guid>https://stats.stackexchange.com/questions/655605/is-there-a-general-interpretation-for-standardized-beta-strentgh</guid>
      <pubDate>Thu, 10 Oct 2024 14:08:20 GMT</pubDate>
    </item>
    <item>
      <title>方差总是等于二阶导数的倒数吗？</title>
      <link>https://stats.stackexchange.com/questions/655583/is-variance-always-equal-to-the-inverse-of-the-second-derivative</link>
      <description><![CDATA[这是基于 Fisher 评分法（本质上是 Newton-Raphson 优化算法的统计版本）估计模型参数的著名公式：
$$\theta^{(k+1)} = \theta^{(k)} + [I(\theta^{(k)})]^{-1}U(\theta^{(k)})$$
其中：

$\theta^{(k)}$ 是迭代时的估计值 $k$
$U(\theta)$ 是得分函数（对数似然的一阶导数）
$I(\theta)$ 是 Fisher 信息矩阵（基于 Hessian，即二阶导数）

我认为 Fisher 评分的真正酷之处在于它同时估计参数的方差：
$$E[-\nabla^2 \log L(\theta)] = I(\theta)$$
$$\text{Var}(\hat{\theta}) \approx I^{-1}(\hat{\theta})$$
在之前的问题中（例如如何防止似然优化中的负方差估计？），我了解到许多软件实现实际上并没有使用这种精确的 Fisher 评分方法，因为执行使用 Fisher 评分方法所需的矩阵微积分可能非常复杂。而是使用拟牛顿方法，例如 BFGS 算法。
BFGS 算法（具有与 Fisher 评分非常相似的结构）按如下方式更新 $\theta$ 的估计值：
$$\theta^{(k+1)} = \theta^{(k)} - \alpha^{(k)} H^{(k)} \nabla L(\theta^{(k)})$$
其中：

$\alpha^{(k)}$ 是由线搜索确定的步长
$H^{(k)}$ 是逆 Hessian 的近似值矩阵
$\nabla L(\theta^{(k)})$ 是对数似然的梯度
梯度$\nabla L(\theta)$与 Fisher 评分中的得分函数$U(\theta)$相同。

所有这些都让我感到疑惑。假设 BFGS 中产生的最终 Hessian（即收敛时）表示为 $H_{final}$。
这样说公平吗？
$$H_{final} \xrightarrow{p} [-\nabla^2 \log L(\theta)]^{-1}$$
$$\text{Var}(\hat{\theta}) \approx H_{final}$$
最终呢？
$$\text{Var}(\hat{\theta}) \approx \begin{cases}
I^{-1}(\hat{\theta}) &amp; \text{for Fisher Scoring} \\
H_{final} &amp; \text{for BFGS}
\end{cases}$$
因此，BFGS 算法似乎也估计了参数估计的方差（就像 Fisher Scoring 一样）。
如果这是真的（即 BFGS 通过避免 Fisher Scoring 所需的矩阵微积分节省了时间，并且 BFGS 仍然提供方差估计），那么为什么 Fisher Scoring 在应用中会使用呢？在我看来，Fisher Scoring 只有在一些非常具体的建模情况下才会真正具有优势（例如指数族、GLM），在这些情况下，我们已经事先知道填充得分函数和预期的 hessian 所需的精确矩阵微积分？或者也许从优化的角度来看，Fisher Scoring 更稳定，与 BFGS 相比，它不太可能陷入困境？]]></description>
      <guid>https://stats.stackexchange.com/questions/655583/is-variance-always-equal-to-the-inverse-of-the-second-derivative</guid>
      <pubDate>Thu, 10 Oct 2024 04:26:36 GMT</pubDate>
    </item>
    <item>
      <title>概率/标准正态分布作业帮助</title>
      <link>https://stats.stackexchange.com/questions/655578/probability-standard-normal-distribution-homework-help</link>
      <description><![CDATA[我在家庭作业中被这个问题难住了，想知道是否有人可以提供一些关于如何解决这个问题的建议？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655578/probability-standard-normal-distribution-homework-help</guid>
      <pubDate>Thu, 10 Oct 2024 01:56:25 GMT</pubDate>
    </item>
    <item>
      <title>证明 $\mathbb{E} (|X-Y|) = 0 \implies X^2 = Y^2$</title>
      <link>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</link>
      <description><![CDATA[$\boxed{\text{设 } X,Y \text{ 为任意随机变量。证明如果 } \mathbb{E}(​​|X-Y|) = 0，\text{则 } X^2 = Y^2。}$
我们有 $\mathbb{E}(​​|X-Y|) = 0$，我认为如果我能以某种方式证明 $X=Y$，那么它直接意味着 $X^2 = Y^2$，但我不知道如何实现。
附言：这不是任何形式的家庭作业，我只是在大学概率课程的往期考试中看到了这个问题，想尝试一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</guid>
      <pubDate>Wed, 09 Oct 2024 19:54:07 GMT</pubDate>
    </item>
    <item>
      <title>所有相关性荟萃分析</title>
      <link>https://stats.stackexchange.com/questions/655563/all-correlations-meta-analysis</link>
      <description><![CDATA[我是 MetaSEM 的新手。我正在尝试进行一个简单的元分析（我只想分析 2 个相关性；见图）。
在这里您可以找到我使用的一些模拟数据的代码，但如果没有回归，我就无法让它工作（除非我添加回归系数，否则它会永远工作下去）。这应该是一个简单的模型，但我被卡住了。我只想要两个协方差，我已经将所有方差固定为一个。换句话说，我只想对 S-D 和 I-D 之间的相关性进行元分析。
S 和 D、S 和 I 以及 D 和 I 之间的相关性存储在此处：
rSD &lt;- c(0.85, 0.8, 0.90, 0.78, 0.70,NA,NA,NA,NA,NA)
rSI &lt;- c(NA,NA,NA,NA,NA,0.85,NA,NA,NA,NA)
rDI &lt;- c(NA,NA,NA,NA,NA,0.60, 0.50, 0.55, 0.60, 0.55)

rSI 可能是 al NA，因为我对这种相关性不感兴趣。
我读过关于 SEM 和 RAM 模型的文章，我认为这个模型是可以识别的，应该很容易拟合。任何帮助和指导都将不胜感激。
library(metaSEM)
source(&quot;http://www.suzannejak.nl/MASEM_functions.R&quot;)

rSD &lt;- c(0.85, 0.8, 0.90, 0.78, 0.70,NA,NA,NA,NA,NA)
rSI &lt;- c(NA,NA,NA,NA,NA,0.85,NA,NA,NA,NA)
rDI &lt;- c(NA,NA,NA,NA,NA,0.60, 0.50, 0.55, 0.60, 0.55)

N &lt;- c(10000,40000, 30000, 10000, 10000,20000,10000, 50000, 10000, 10000 )

数据 &lt;- as.data.frame(cbind(rSD,rSI,rDI, N))

nvar &lt;- 3
varnames &lt;- c(&quot;S&quot;,&quot;D&quot;, &quot;I&quot;)
labels &lt;- list(varnames,varnames)

cormatrices &lt;- readstack(data[,c(1,2,3)], no.var = nvar, var.names = varnames, diag = FALSE)

n &lt;- data$N

pattern.na(cormatrices, show.na=F)
pattern.n(cormatrices, n=n)

my.df &lt;- Cor2DataFrame(cormatrices, n, acov = &quot;weighted&quot;)

## 使用指定模型lavaan 语法
模型 &lt;-
&#39;

# 协方差
D ~~ I
D ~~ S
# 方差

D ~~ 1*D
S ~~ 1*S
I ~~ 1*I
&#39;

RAM1 &lt;- lavaan2RAM(model, obs.variables=varnames)
RAM1

## 创建具有隐式对角线约束的模型隐含相关结构
M0 &lt;- create.vechsR(A0=RAM1$A, S0=RAM1$S)

## 创建异质性方差-协方差矩阵
T0 &lt;- create.Tau2(RAM=RAM1, RE.type=&quot;Diag&quot;, Transform=&quot;expLog&quot;, RE.startvalues=0.05)

## 拟合模型
mx.fit0 &lt;- osmasem(model.name=&quot;No moderator&quot;, Mmatrix=M0, Tmatrix=T0, data=my.df)

## 查看结果
summary(mx.fit0, fitIndices = TRUE)
VarCorr(mx.fit0)

]]></description>
      <guid>https://stats.stackexchange.com/questions/655563/all-correlations-meta-analysis</guid>
      <pubDate>Wed, 09 Oct 2024 19:33:34 GMT</pubDate>
    </item>
    </channel>
</rss>