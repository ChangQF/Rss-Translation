<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 29 Dec 2024 15:14:54 GMT</lastBuildDate>
    <item>
      <title>阐明拓扑数据分析在检测股价暴跌中的应用[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659329/clarification-for-the-application-of-topological-data-analysis-to-detect-stock-p</link>
      <description><![CDATA[我想使用拓扑数据分析检测股价暴跌。例如，我获取了一个名为 tesla 的 excel 文件，其中包含日期、开盘价、最高价、最低价、收盘价和成交量等列。我想要收盘价列的时间序列。现在我首先应用 Takens 嵌入定理，然后应用 slinging 窗口。然后使用 rips 复合体检测漏洞。
我使用了一些关于 tda 的研究论文来获取此信息，但无法理解为什么要实施这些内容。
有人能解释一下发生了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659329/clarification-for-the-application-of-topological-data-analysis-to-detect-stock-p</guid>
      <pubDate>Sun, 29 Dec 2024 08:51:03 GMT</pubDate>
    </item>
    <item>
      <title>平方和与叉积 (SSCP) 矩阵的逆</title>
      <link>https://stats.stackexchange.com/questions/659323/inverse-of-sums-of-squares-and-cross-products-sscp-matrix</link>
      <description><![CDATA[在《应用线性回归》一书的第 3 章中，Weisberg 提出，已校正 SSCP 矩阵的逆$(\chi^T\chi)^{-1}$是未校正 SSCP 矩阵的逆$(X^TX)^{-1}$的第一行和第一列以外的所有元素。这是为什么呢？
$\chi$ 就是 $X$，但没有截距，并且从每列中减去了相应的平均值，仅供参考。]]></description>
      <guid>https://stats.stackexchange.com/questions/659323/inverse-of-sums-of-squares-and-cross-products-sscp-matrix</guid>
      <pubDate>Sun, 29 Dec 2024 02:08:49 GMT</pubDate>
    </item>
    <item>
      <title>OLS 怎么会有遗漏变量偏差？OLS 不是应该总是消除内生性吗？</title>
      <link>https://stats.stackexchange.com/questions/659320/how-can-there-be-omitted-variable-bias-in-ols-shouldnt-ols-always-eliminate-en</link>
      <description><![CDATA[OLS 中怎么会存在遗漏变量偏差（OVB）？难道所有回归都不能在没有内生性的情况下计算吗？
作为介绍，这是 Greene（计量经济学分析，第 8 版）关于 OVB 的条目：

重新表述问题：为什么 $b$ 不捕获调用 $X$ 对 $y$ 的影响并使误差项不相关？
例如 - 假设正确指定的模型（$R^2 = 1$) 和 $x_1$:
$ y = \beta.x_1 + \gamma.x_2$
$x_2= \delta.x_1 + w$
因此，我们看到 $x_1$ 和 $x_2$ 是相关的。
现在让我们使用 OLS 对 $y$ 进行回归：
$E[y\,|x_1] = a + b.x_1+ \epsilon$
由于 $x_2$ 应该位于 $\epsilon$ 上，$b$ 应该具有 OVB，对吗？这里有一个反对意见。
让我们重新表述 $y$ 的方程式：
$y = (\beta +\gamma.\delta).x_1 + \delta.w$
因此，回归量可以重新表述为 $x_1$ 和不相关的 $w$。如果是这样，为什么回归会有 OVB？]]></description>
      <guid>https://stats.stackexchange.com/questions/659320/how-can-there-be-omitted-variable-bias-in-ols-shouldnt-ols-always-eliminate-en</guid>
      <pubDate>Sun, 29 Dec 2024 00:55:52 GMT</pubDate>
    </item>
    <item>
      <title>区间变量与名义变量之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/659311/correlation-between-interval-and-nominal-variables</link>
      <description><![CDATA[我有一个表示村庄大小（以公顷为单位）的数值变量和一个表示四种土壤类型的分类变量。我想使用 R 研究土壤类型是否与村庄大小有关。我绘制了箱线图，但现在我想得到一些关联度量。我读过这里的一些答案，建议使用 ANOVA 的 Eta（相关比）。我的规模数据不是正态分布的，所以我怀疑我是否可以使用它。在包 rstatix 中，函数 kruskal_effsize 也给出了 eta-squared 的值，但基于 H。根据 rstatix 文档“...eta-squared...表示由独立变量解释的因变量方差的百分比。”使用这个测量方法来得出关于两个变量之间关系的结论是否正确？
如果有人能对此有所启发，我将不胜感激。
我得到了所有的 Eta 值，但我需要知道我是否可以使用它们。]]></description>
      <guid>https://stats.stackexchange.com/questions/659311/correlation-between-interval-and-nominal-variables</guid>
      <pubDate>Sat, 28 Dec 2024 21:32:21 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA(12,0,0) - 缺少第 14 个参数？拟合值 <> 已计算</title>
      <link>https://stats.stackexchange.com/questions/659310/arima12-0-0-missing-14th-param-fitted-values-calculated</link>
      <description><![CDATA[我在 R 中创建了一个 ARIMA(12, 0, 0) 模型。我计算出的拟合值为
$$\hat{y}(t) = \phi_1 y(t-1) + \phi_2 y(t-2) + \ldots + \phi_{12} y(t-12) + \text{intercept}$$
将我的计算结果与模型的最后 10 个拟合值进行比较，结果存在恒定的差异（这 10 个差异是相同的）。为什么会有差异？为了弄清楚这一点，我遇到了这个等式
$$ \text{AIC} = 2k - 2\ln(L) $$
其中 k 是参数的数量，L 是最大似然。当我求解 k 时，我得到的结果是 14，而预期结果是 13（12 个滞后和一个截距）。第 14 个参数是什么？我在 R 中哪里可以找到它？它能解释错误吗？重现该问题的代码如下：
library(readxl)
library(curl)
library(dplyr)
url &lt;- &quot;https://img1.wsimg.com/blobby/go/e5e77e0b-59d1-44d9-ab25-4763ac982e53/downloads/e1fcc664-eaa1-48ed-b682-88e0c33db496/ie_data.xls?ver=1733242673788&quot;
temp_file &lt;- tempfile(fileext = &quot;.zip&quot;)
curl_download(url, temp_file)
shiller_data &lt;- suppressWarnings(suppressMessages({
read_excel(
temp_file,
sheet = &quot;Data&quot;,
range = &quot;A8:V1856&quot;,
col_types = c(
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;skip&quot;,
&quot;numeric&quot;,
&quot;skip&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;
)
)
}))
colnames(shiller_data) &lt;- c(
&quot;Date&quot;,
&quot;SPCompP&quot;,
&quot;D&quot;,
&quot;E&quot;,
&quot;CPI&quot;,
&quot;DateFraction&quot;,
&quot;LongRateGS10&quot;,
&quot;RealP&quot;,
&quot;RealD&quot;,
&quot;RealTRP&quot;,
&quot;RealE&quot;,
&quot;RealTRScaledE&quot;,
&quot;CAPE&quot;,
&quot;TRCAPE&quot;,
&quot;ExcessCAPEYld&quot;,
&quot;BondReturns&quot;,
&quot;RealBondReturns&quot;,
&quot;StockRealRet10Y&quot;,
&quot;BondRealRet10Y&quot;,
&quot;ExcessRealRet10Y&quot;
)

DateFraction2Date &lt;- function(dateFraction) {
y = floor(dateFraction)
m = ceiling((dateFraction - y)*12) + 1
idx &lt;- m &gt; 12
y[idx] &lt;- y[idx] + 1
m[idx] &lt;- 1
out &lt;- as.Date(paste0(y, &quot;-&quot;,m,&quot;-1&quot;), format = &quot;%Y-%m-%d&quot;) - 1
return(out) 
}

shiller_data &lt;- shiller_data %&gt;% mutate(Date1 = DateFraction2Date(DateFraction))
通货膨胀 &lt;- shiller_data$CPI[2:nrow(shiller_data)]/shiller_data$CPI[1:(nrow(shiller_data) -1)] - 1 
inflation_ts &lt;- ts(inflation, start = c(lubridate::year(shiller_data$Date1[2]), lubridate::month(shiller_data$Date1[2])), 频率 = 12)

window_data &lt;- indication_ts[1:360]
ar_model &lt;- Arima(window_data, order = c(12, 0, 0))
fitted10 &lt;- ar_model$fitted[351:360]
calcFitted10 &lt;- numeric(10)
for (i in 351:360) {
calcFitted10[i-350] &lt;- sum(window_data[(i-12):(i-1)] * ar_model$coef[12:1]) + ar_model$coef[13]
}
fitted10 - calcFitted10
implied_pa​​rams &lt;- (ar_model$aic - ar_model$loglik*-2)/2

本例中的数据来自 Shiller 的 CAPE 数据。
摘要：为什么不是

fitted10 - calcFitted10

全为零？是因为

implied_pa​​rams

等于 14，而我只使用了 13 个系数？
我读过类似问题和这个问题，但还没搞清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/659310/arima12-0-0-missing-14th-param-fitted-values-calculated</guid>
      <pubDate>Sat, 28 Dec 2024 20:40:40 GMT</pubDate>
    </item>
    <item>
      <title>如果我们知道总体分布不正常，那么创建参考 Z 分布的置信区间是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/659299/does-it-make-sense-to-create-a-confidence-interval-referencing-the-z-distributio</link>
      <description><![CDATA[我正在学习生物学学位的入门统计学课程，在学习生成总体均值的置信区间时，我开始怀疑，如果我们知道原始总体不服从正态分布，这样做是否有意义。据我所知，CLT 在这种情况下没有任何效用，因为我们关心的是创建一个置信区间，其假定机会与原始概率分布（即总体的概率分布）一致。
我遗漏了什么吗？如果没有，评估引用此类理论分布来构建置信区间的正确性的程序是什么？
澄清编辑：
我不是在问 CLT 对抽样分布及其估计量的影响，而是在我们知道总体根本不服从正态分布的情况下，使用渐近正态抽样分布对总体参数进行推断的效用。因此，我的问题是：当抽样分布具有如此不同的分布概率，以至于两个分布看起来完全不同时，我们如何使用正态抽样分布来尝试估计非正态总体的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/659299/does-it-make-sense-to-create-a-confidence-interval-referencing-the-z-distributio</guid>
      <pubDate>Sat, 28 Dec 2024 15:19:07 GMT</pubDate>
    </item>
    <item>
      <title>用逻辑回归对病例对照样本进行建模的参数估计</title>
      <link>https://stats.stackexchange.com/questions/659328/estimation-of-parameters-for-modelling-case-control-samples-with-logistic-regres</link>
      <description><![CDATA[
这个问题的灵感来自于“使用 Python 进行统计学习” （斯坦福）课程由 Edx 提供。

考虑两个结果（0 和 1）被建模为 $$\Pr(Y=1\mid X)=\frac{e^{\beta_0+\beta_1X_1+...+\beta_pX_p}}{1+e^{\beta_0+\beta_1X_1+...+\beta_pX_p}}$$
对于给定的案例样本（Y=1）和控制（Y=0），用于模拟现实世界中接收 $Y=1$ 的概率，为什么有人说回归参数 $\beta_j$ 可以准确估计，而通过病例对照样本估计的常数项$\beta_0$是不正确的，而$\beta_0$的正确估计为：$$\hat{\beta_0^*}=\hat{\beta_0}+\log(\frac{\pi}{1-\pi})-\log(\frac{\tilde{\pi}}{1-\tilde{\pi}})$$
其中$\pi$表示在现实世界中获得$Y=1$的概率，$\tilde{\pi}$表示获得病例对照样本中的$Y=1$。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659328/estimation-of-parameters-for-modelling-case-control-samples-with-logistic-regres</guid>
      <pubDate>Sat, 28 Dec 2024 03:35:06 GMT</pubDate>
    </item>
    <item>
      <title>$\text{U}(0, \theta)$ 中 ${θ}/{2}$ 的置信区间</title>
      <link>https://stats.stackexchange.com/questions/659276/confidence-interval-for-%ce%b8-2-in-textu0-theta</link>
      <description><![CDATA[我试图找到 ${\theta}/{ 2}$ 的置信区间，置信度为 $1-\alpha$（使用 $p_1 = \alpha$ 和 $p_2 = 1$ 处的分位数）。因此，我采用 ${\hat{\theta}}/{2} = {X_{(n)}}/{2}$ 的无偏估计量。然后从我们在课堂上学到的知识：
$$\mathbb{P} \bigg( \dfrac{cX_{(n)}}{2\theta} \leqslant q_{p_1} \bigg)
= \mathbb{P} \bigg( \dfrac{X_{(n)}}{\theta} \leqslant \dfrac{2q_{p_1}}{c} \bigg)
= \alpha
= \bigg( \dfrac{2q_{p_1}}{c} \bigg)^n,$$
这意味着 $q_{p_1}=\tfrac{c}{2}\alpha^{{1}/{n}}$ 并且对于 $q_{p_2}$ 将给我们 $q_{p_2} = {c}/{2}$。由此得出：
$$\mathbb{P} \bigg( \dfrac{c}{2}\alpha^{{1}/{n}} \leqslant \dfrac{cX_{(n)}}{\theta} \leqslant \dfrac{c}{2} \bigg)
= \mathbb{P} \bigg( X_{(n)} \leqslant \dfrac{\theta}{2} \leqslant \dfrac{X_{(n)}}{\alpha^{{1}/{n}}} \bigg)
= 1-\alpha,$$
因此得出的 CI 为：
$$\dfrac{\theta}{2} \in \bigg[ X_{(n)}, \dfrac{X_{(n)}}{\alpha^{{1}/{n}}} \bigg].$$
这看起来正确吗？还是我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659276/confidence-interval-for-%ce%b8-2-in-textu0-theta</guid>
      <pubDate>Fri, 27 Dec 2024 21:45:01 GMT</pubDate>
    </item>
    <item>
      <title>多元方差分析，其中一些因变量是序数，一些是区间数</title>
      <link>https://stats.stackexchange.com/questions/659269/manova-with-some-dependent-variables-being-ordinal-and-some-being-interval</link>
      <description><![CDATA[MANOVA 测试似乎非常适合以下研究，只是因变量不是所需的间隔，我想研究传统和非传统学习者在两种写作类型上的差异，反映在 1) 总体印象、2) 内容、3) 组织、4) 词汇准确性和 5) 语法准确性上。学习者（传统和非传统）和类型（叙述和论证）是两个独立变量。总体而言，内容和组织按 1 到 5 的等级进行评分，因此这三个因变量是序数，而词汇和语法按百分比计算，因此这两个因变量是间隔。
我的问题是 1) 我还可以使用 MANOVA 吗？2) 如果不能，我可以使用什么其他测试？3) 如果可以，我可以使用哪些修改来使 MANOVA 发挥作用？
我对统计学的了解有限，大多数时候使用 SPSS，但如果其他软件可以更有效地处理这个问题，我愿意尝试它们。非常感谢！！

抱歉造成混淆。我刚刚修改了标题。其实我是想问，如果一些因变量是序数的，而一些是区间的，我是否可以使用 MANOVA。研究设计的细节已经解释清楚了。
谢谢你的回复。希望你的笔记本电脑能尽快恢复正常！]]></description>
      <guid>https://stats.stackexchange.com/questions/659269/manova-with-some-dependent-variables-being-ordinal-and-some-being-interval</guid>
      <pubDate>Fri, 27 Dec 2024 13:37:14 GMT</pubDate>
    </item>
    <item>
      <title>从指数函数分布获得幂律的必要充分条件？</title>
      <link>https://stats.stackexchange.com/questions/659182/necessary-and-sufficient-conditions-to-obtain-power-law-from-distribution-over-e</link>
      <description><![CDATA[分布 $p(x)$ 的哪些属性 (1) 是充分的且 (2) 是必要的，以使
$$-\log \Bigg(1 - \int_{x=0}^{x=1} p(x) \, (1-x)^k \, dx \Bigg)$$
导致幂律
$$\propto k^{-b}$$
对于某个常数 $b &gt; 0$？
我有一个隐含的假设，即分布 $p(x)$ &quot; n&quot;在某种意义上，但我不确定这个假设到底是什么。也许是平滑的、连续的，还是类似的东西？
我已经得出 Beta 分布和 Kumaraswamy 分布就足够了。从数值上讲，连续伯努利分布也同样有效。我正在寻找这些分布背后的一般“结构”。]]></description>
      <guid>https://stats.stackexchange.com/questions/659182/necessary-and-sufficient-conditions-to-obtain-power-law-from-distribution-over-e</guid>
      <pubDate>Tue, 24 Dec 2024 23:53:30 GMT</pubDate>
    </item>
    <item>
      <title>X-meta 学习器和 CATE 估计器</title>
      <link>https://stats.stackexchange.com/questions/658957/x-meta-learner-and-the-cate-estimator</link>
      <description><![CDATA[在 X-learner 中，使用适当的模型估算治疗样本和对照样本（使用对照样本估算治疗样本响应，反之亦然）。
然后使用两个模型来估计 CATE，每组估算值一个模型（通常使用倾向得分组合）。我添加了从 Kunzel 等人 2019 年获得的 X-learner 伪代码。

为什么我们使用单独的 CATE 模型？为什么不将所有估算结果组合起来并拟合单个模型（例如，使用逆倾向对观察结果进行加权）。有没有探讨这个想法的作品？]]></description>
      <guid>https://stats.stackexchange.com/questions/658957/x-meta-learner-and-the-cate-estimator</guid>
      <pubDate>Thu, 19 Dec 2024 08:55:03 GMT</pubDate>
    </item>
    <item>
      <title>我是否正确推导出加权最小二乘的迭代更新？</title>
      <link>https://stats.stackexchange.com/questions/658722/have-i-correctly-derived-the-iterative-updates-for-weighted-least-squares</link>
      <description><![CDATA[我有一项练习，需要从迭代加权最小二乘更新方程 $b^{(m)} = \left( X^\top W^{(m-1)} X \right)^{-1} X^\top W^{(m-1)} z^{(m-1)}$ 中推导出 $w_i^{(m-1)}$ 和 $z_i^{(m-1)}$，其中 BeetleMortality 数据具有概率单位链接 $\phi$。然后我必须在 R 中实现它。据我所知，$w_i^{(m-1)}=\frac{1}{\text{Var}(Y)} (\frac{\partial \mu_i}{\partial \eta_i}) ^2 = \frac{\phi&#39;(\eta_i)^{(m-1)}}{n\mu_i^{(m-1)}(1 - \mu_i^{(m-1)})}$ 和 $z_i^{(m-1)} = \eta_i^{(m-1)} (y_i -\mu_i) \frac{\partial \eta_i}{\partial \mu_i}= \eta_i^{(m-1)} + \frac{y_i + \mu_i^{(m-1)}}{\phi&#39;(\eta_i)^{(m-1)}}$ 其中 $\phi&#39;$ 是正态分布 PDF。我已经在 R 中实现了这一点，我非常确定实现中的所有内容都是正确的。因此，我相信问题在于我如何得出这些值。我犯了什么错误吗？我对这一切还比较陌生，所以很可能是我犯了一些我无法发现的明显错误。任何反馈都值得赞赏！]]></description>
      <guid>https://stats.stackexchange.com/questions/658722/have-i-correctly-derived-the-iterative-updates-for-weighted-least-squares</guid>
      <pubDate>Sat, 14 Dec 2024 16:41:27 GMT</pubDate>
    </item>
    <item>
      <title>当每个站点具有单一预测值时，在混合效应模型中将研究站点视为随机效应的适当性</title>
      <link>https://stats.stackexchange.com/questions/658528/appropriateness-of-treating-study-site-as-a-random-effect-in-mixed-effects-model</link>
      <description><![CDATA[我有来自 12 个研究地点的数据，每个地点都有相应的建筑面积值。在每个地点，我测量了海龟的体型，并有兴趣研究体型如何随着建筑面积的梯度而变化。由于同一地点内的海龟不是独立的，我正在考虑使用混合效应模型来解释这种相关性。但是，由于每个地点只有一个建筑面积值，我不确定在这种情况下将研究地点视为随机效应是否合适。
这是一个示例图，显示了体重和不透水表面覆盖率（％）之间的关系。由于每个站点的不透水表面覆盖率都有一个值，我认为不适合包含随机效应，因为它无法估计站点的随机效应，因为没有站点内的变化可以建模。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658528/appropriateness-of-treating-study-site-as-a-random-effect-in-mixed-effects-model</guid>
      <pubDate>Tue, 10 Dec 2024 15:35:48 GMT</pubDate>
    </item>
    <item>
      <title>确定具有大量数据的两个分类列之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/601799/determine-correlation-between-two-categorical-columns-with-lots-of-data</link>
      <description><![CDATA[我有一个包含国家名称和音乐家姓名的大型数据集，如下所示，有超过 50,000 行：




国家
音乐家




澳大利亚
Jimmy Barnes


澳大利亚
Grinspoon


英格兰
Giles


美利坚合众国
鲍勃·迪伦


美利坚合众国
哈姆雷特


美利坚合众国
里克·艾斯利


瑞典
朱迪思


美国美国
披头士乐队


牙买加
JPM


德国
Ruslana


俄罗斯
Ruslana


乌克兰
Ruslana


美国美国
着魔


法国
乔治·布拉森


希腊
雅克·布雷尔


法国
狄俄尼西斯·萨沃普洛斯


希腊
狄俄尼西斯·萨沃普洛斯


法国
Léo Ferré


希腊
Léo Ferré


美利坚合众国
Ulali


美利坚合众国
Zozobra


哥伦比亚
Aterciopelados


哥伦比亚
Carlos Vives


哥伦比亚
Shakira


英国
The Smiths


英国
Morrissey




我想使用 pandas（因为这些数据位于数据框）来确定两列之间是否存在相关性，即国家/地区是否表明了哪位音乐家的名字。这有可能吗，还是我完全错了？如果相关的话，列联表是 11949 行 × 190 列。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/601799/determine-correlation-between-two-categorical-columns-with-lots-of-data</guid>
      <pubDate>Thu, 12 Jan 2023 20:45:13 GMT</pubDate>
    </item>
    <item>
      <title>处理 gam/bam 中的大量随机效应</title>
      <link>https://stats.stackexchange.com/questions/582310/dealing-with-a-large-number-of-random-effects-in-gam-bam</link>
      <description><![CDATA[我有大量数据集，想使用 gam 或 bam 建模二项式结果，但由于我的数据集中有大量随机效应，r 出现内存错误。我正在寻找有关如何使用更少内存运行模型的建议。
示例：数据集包含 n = 60451 个观测值；varOUTCOME 是二项式的，var1 和 var2 是分类的，var3 是线性数字，var4RE 是随机效应的整数变量。在这个集合中，n = 51660 名参与者，表明大约 10k 个观测值来自重复参与者（参与者在数据中出现 1 到 8 次）。我们知道 ICC 足够高，我们需要考虑这种重复。
我们已尝试使用 gam 和 bam，varOUTCOME ~ var1 + var2 + s(var3, by var1) + s(var4RE, bs=&#39;re&#39;)。
我们现在正在尝试这个，但它也需要几个小时才能运行：
gamm4(varOUTCOME ~ var1 + var2 + s(var3, by var1) + s(var4RE, bs=&#39;re&#39;) + random = ~(1|var4RE),
data = thedata, verbose = TRUE, family = binomial(link=&#39;logit&#39;))
作为补充说明，使用不太理想的 s(var3) 代替与 var1 的交互没有帮助。
我已经搜索/阅读了关于“bam、gam 和随机效应”的帖子，但没有找到解决方案。如果我遗漏了什么，请见谅。
提前感谢您对如何处理大量随机效应的任何建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/582310/dealing-with-a-large-number-of-random-effects-in-gam-bam</guid>
      <pubDate>Mon, 18 Jul 2022 02:17:53 GMT</pubDate>
    </item>
    </channel>
</rss>