<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 13 Aug 2024 01:09:15 GMT</lastBuildDate>
    <item>
      <title>多项变量的趋势检验</title>
      <link>https://stats.stackexchange.com/questions/652687/trend-test-for-multinomial-variables</link>
      <description><![CDATA[当结果（因变量）是多项式（具有多个无序类别，如种族）且独立变量是有序分类变量（例如 BMI 具有 3 个类别（例如 &lt;30 kg/m2、30-40、&gt;=40）时，应使用哪种检验来估计趋势的 p 值。以及如何在 SAS 和/或 R 中实现它。任何示例代码/参考都会有所帮助。
我相信我们可以对连续变量使用 Jonckheere–Terpstra 趋势检验，对二元变量使用 Cochran–Armitage 趋势检验。但是，我不确定当涉及多项变量时，哪种检验是合适的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652687/trend-test-for-multinomial-variables</guid>
      <pubDate>Tue, 13 Aug 2024 00:35:05 GMT</pubDate>
    </item>
    <item>
      <title>对 SQL 查询文本进行回归。良好的 ML 模型架构</title>
      <link>https://stats.stackexchange.com/questions/652686/regression-on-sql-query-texts-good-ml-model-architecture</link>
      <description><![CDATA[对 SQL 查询进行快速回归。良好的 ML 模型架构。
我们的目标是预测哪个 SQL 引擎（目前有 2 个）将更快地执行给定的查询。
输入是查询文本，将来我们可能会获得有关表大小的一些信息。
模型需要快速运行（毫秒）。
什么是这项任务的最佳模型架构？
一些想法和子问题：
输入查询不是很长，但长度可变。固定输入模型可能不起作用。
模型输出是几个数字（每个引擎一个），而不是一个序列。
Transformers 与 RNN（甚至可能是 CNN）。考虑到输入相对较小，哪种架构最适合？
最好从头开始训练模型。大多数现有的 LLM 对于这种专门的任务来说太大太慢了。SQL 语言是一种特殊的小词汇表。
最好为每个子查询运行一个模型，计算“思维向量”，然后在处理父查询时插入该思维向量吗？或者模型文本处理架构是否足够智能，不会从这种手动特征制作中受益？
将数值数据（例如表格大小）与查询文本一起提供给模型的最佳方法是什么？基于标记的解析在数字方面并不擅长，因此这可能需要一种侧通道（例如嵌入侧的额外数字）。Transformer 可以处理数值数据吗？在我看来，考虑到交叉注意机制，数值数据在此过程中会非常混乱。
调整查询（例如将“SELECT”子句移动到查询的末尾）是否有助于模型更好地理解查询？]]></description>
      <guid>https://stats.stackexchange.com/questions/652686/regression-on-sql-query-texts-good-ml-model-architecture</guid>
      <pubDate>Tue, 13 Aug 2024 00:15:44 GMT</pubDate>
    </item>
    <item>
      <title>预测两个（或更多）选项的相对速度的最佳损失函数</title>
      <link>https://stats.stackexchange.com/questions/652684/best-loss-function-for-predicting-relative-speed-of-two-or-more-options</link>
      <description><![CDATA[我想创建一个模型，尝试预测对于给定的用户查询，哪个执行引擎会更快。该模型没有足够的信息来预测实际运行时间，但我们希望预测相对执行速度。
我认为这意味着模型应该为每个引擎类输出一个不受约束的正数。
训练标签是使用不同引擎时查询的实际执行时间。
我需要一个损失函数，它采用模型输出（2 个数字）和实际时间（2 个数字）并计算损失。
您认为这里最合适的损失函数是什么？
一些想法：
对于二元类标签目标，常见的损失函数是 CrossEntropy。但在我们的例子中，目标不是二元的。
我们可以规范化模型输出和目标，然后使用 CrossEntropy。
我们可以将模型输出转换为二元响应。正确答案/顺序的损失为 0，而错误答案的损失为运行时间差。
对于 2 类情况，我们可以将输出和目标转换为比率并计算平方误差。
我们可以将输出和目标视为向量并计算这些向量之间的角度。
我喜欢 BetaBinomial 分布的概念（基于一些先前结果的未来二项式结果的概率）。我们可以将模型输出视为先验并计算目标结果的概率。但 BetaBinomial 分布在技术上适用于整数，而我们的目标是实数。使用该公式仍然正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652684/best-loss-function-for-predicting-relative-speed-of-two-or-more-options</guid>
      <pubDate>Mon, 12 Aug 2024 23:55:55 GMT</pubDate>
    </item>
    <item>
      <title>粒度和聚合数据的功率分析</title>
      <link>https://stats.stackexchange.com/questions/652683/power-analysis-for-granular-and-aggregated-data</link>
      <description><![CDATA[我需要创建一个 A/B 测试，以了解移除某种包装是否会减少物品损坏。我有一份大约 2000 件目前采用特定包装的物品的清单，以及过去六个月的月度损坏率（损坏单位与现有单位的比例）。
由于我们不确定实验在技术上是否可行（这将是一个零散的实验，我们无法在太多物品和单位上进行测试），我们希望大致估计一下需要多少物品及其单位才能取得显著成果。
为此，我将重点关注网络中数量足够多的物品，以便快速进行实验。我会找出损坏率较高的物品，然后确定适当的物品数量及其样本量。
我设计这个的方法是首先通过分析历史数据来估计这些顶级物品的损坏率差异，从而计算物品的样本量。这将帮助我们了解不同物品之间的损坏率差异有多大。然后，我将进行功效分析以确定每组所需的物品数量。
为了计算每件物品的样本量，我将估计单个物品内损坏率的差异。我将根据单位级别的损坏率差异来定义效应大小。这可能与物品级别的相同或更细粒度，具体取决于物品内损坏率的一致性。然后，我将进行功效分析以计算每件物品所需的单位数以检测指定的效果。
这是进行此分析的正确方法吗？我需要考虑哪些限制和注意事项？在这种情况下，我应该对 t 检验还是比例检验进行功效分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/652683/power-analysis-for-granular-and-aggregated-data</guid>
      <pubDate>Mon, 12 Aug 2024 21:56:11 GMT</pubDate>
    </item>
    <item>
      <title>哪种拟合优度检验适合检验大小为一的样本？</title>
      <link>https://stats.stackexchange.com/questions/652682/which-goodness-of-fit-test-to-test-a-sample-of-size-one</link>
      <description><![CDATA[我有一个 1 到 16 范围内的整数样本。它们是从某个未指定的分布中独立同分布抽取的。如果我再得到一个从可能不同的分布中独立抽取的整数，那么什么样的拟合优度检验可以拒绝原假设，即它与第一组整数来自相同的分布？
我考虑过使用卡方检验，但我不知道当第二个样本大小为 1 时这是否合适。]]></description>
      <guid>https://stats.stackexchange.com/questions/652682/which-goodness-of-fit-test-to-test-a-sample-of-size-one</guid>
      <pubDate>Mon, 12 Aug 2024 21:22:04 GMT</pubDate>
    </item>
    <item>
      <title>内点法能保证收敛到凸目标函数的全局最优值吗？</title>
      <link>https://stats.stackexchange.com/questions/652681/are-interior-point-methods-guranteed-to-converge-to-the-global-optimum-of-a-conv</link>
      <description><![CDATA[我正在研究凸优化。但是，我不确定是否存在内点法，在给定严格凸或凸优化目标的情况下，保证收敛到全局最优解。这两种情况都相关。
我读过关于基于梯度的凸优化方法的文章，例如顺序二次规划，根据它们的初始化（和迭代次数），它们可能不一定会收敛到严格凸或凸优化目标的全局最优解。由于这种方法与牛顿法密切相关，牛顿法在收敛方面有同样的缺点。
因此我的问题是：内点法是否保证收敛到凸目标函数的全局最优值？
有人可以回答我的问题吗，或者可以给我指出出版物，甚至是出版物中回答我问题的声明？]]></description>
      <guid>https://stats.stackexchange.com/questions/652681/are-interior-point-methods-guranteed-to-converge-to-the-global-optimum-of-a-conv</guid>
      <pubDate>Mon, 12 Aug 2024 21:21:00 GMT</pubDate>
    </item>
    <item>
      <title>如何计算偶数的 Q1 和 Q3？[重复]</title>
      <link>https://stats.stackexchange.com/questions/652674/how-can-you-calculate-q1-and-q3-for-even-numbers</link>
      <description><![CDATA[我到处搜索过这个问题，但我发现答案各不相同，而且没有一个答案与 Numpy 给出的答案相同。
我有以下数据：[0, 1, 2, 3, 4, 4, 5, 5, 6, 8]
当对 25（Q1）和 75（Q3）使用 numpy.percentile 时，我得到以下答案：2.25 和 5.0。
但是，我无法复制此公式。例如，当查看这篇文章时，答案应该是每一半数据的中心，这将导致 Q1 = 2 和 Q3 = 5。
如果按照另一篇文章，答案将是 Q1 = 2.75 和 Q3 = 5.25。
我不知道哪个答案是正确的，也不知道 numpy 使用的是哪个公式。]]></description>
      <guid>https://stats.stackexchange.com/questions/652674/how-can-you-calculate-q1-and-q3-for-even-numbers</guid>
      <pubDate>Mon, 12 Aug 2024 18:27:00 GMT</pubDate>
    </item>
    <item>
      <title>R 代码用于根据先前发布的 IRT 工作中提供的参数估算三个人的分数 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/652671/r-code-for-estimating-three-individuals-scores-from-parameters-provided-in-previ</link>
      <description><![CDATA[我是 R 新手，我正在尝试使用 ltm 包从 72 项集（来自这篇已发表的论文）中获取一些 IRT 参数（a、b、g）
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4461534/#:~:text=The%20CFMT%20uses%20a%20three,be%20selected%20among%20two%20distractors（见表4)
下面是我的代码……它看起来似乎在做一些合理的事，但我需要一个绝地武士来检查我是否在这里没有脱离正轨。
library(ltm)
步骤 1：定义先前估计的项目参数
item_params &lt;- data.frame(
discrimination = c(1.01, 1.30, 1.43, 1.36, 1.13, 1.19, 1.04, 1.08, 1.69, 1.55, 1.18, 1.37, 1.24, 1.24, 1.43, 1.50, 1.34, 2.25, 1.92, 1.72, 1.43, 1.25, 2.35, 1.32, 1.66、1.98、1.67、1.14、1.36、1.35、1.34、1.05、1.54、2.02、1.28、1.62、2.24、1.23、2.11、1.93、1.91、2.81、1.38、2.35、1。 29、1.98、1.17、2.88、0.72、1.44、1.89、1.38、1.47、1.60、2.94、1.52、1.95、0.88、1.23、2.98、1.68、1.28、1.71、2.32、 1.54, 1.34, 1.85, 0.72, 1.34, 2.98, 1.06)，
难度 = c(-5.67, -3.65, -3.04, -3.55, -3.49, -3.34, -5.18, -4.24, -3.38, -3.47, -3.39, -3.39, -2.64, -3.04, -3.49, -3.44, -2.69, -2.23, -2.76, -1.01, -1.17, -0.91, 0.17, -0.86, -0.36, -1.64, -1.05, -0.40, -0.86, -1.11, -0.48, -0.35, -1.06, 1.36, -0.81, 0.34, -1.94, 0.64, -1.13, -0.68, 0.17, -0.17, -0.35, -1.39, 0.59, -0.76, -0.18, -0.67, 0.34, 1.58, -0.60, -0.11, -0.14, 0.15, 0.53, 1.54, -1.25, 0.66, 0.05, 0.63, -0.21, -0.67, 0.20, -0.34, 0.11, -0.29, 1.25, 1.19, 0.63, 0.21, 1.14, -1.94),
猜测 = c(0.00, 0.00, 0.15, 0.00, 0.00, 0.19, 0.00, 0.00, 0.00, 0.00, 0.01, 0.00, 0.00, 0.00, 0.01, 0.08, 0.49, 0.12, 0.35, 0.40, 0.25, 0.28, 0.30, 0.47, 0.41, 0.36, 0.38, 0.24, 0.15, 0.14, 0.34, 0.29, 0.37, 0.47, 0.20, 0.30, 0.00, 0.23, 0.40, 0.40, 0.19, 0.26, 0.27, 0.50, 0.32, 0.31, 0.33, 0.35, 0.35, 0.27, 0.23, 0.40, 0.33, 0.30, 0.18, 0.34, 0.30, 0.24, 0.35, 0.27, 0.57, 0.38, 0.27, 0.44, 0.21, 0.50, 0.22, 0.19, 0.45, 0.25, 0.35)
)
步骤 2：创建三个不同样本答案的矩阵（1 表示正确，0 表示不正确）
response_data &lt;- matrix(
c(
# 第一位受访者的回答
1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1,0,1,0,1,0,0,0,1,0,1,1,0,1,0,1,0,1,1,1,0,
# 第二位受访者的回答答复
1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,0,0,1,1,0,0,1,0,0,0,0,1,1,0,1,0,1,0,0,0,0,1,1,0,1,0,1,0,0,1,0,0,0,0,0,1,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,
# 第三位受访者的响应
1,1,1,1,0,1,1,0,0,1,1,0,0,1,1,1,1,0,1,1,1,0,1,1,0,0,1,0,0,0,0,0,0,0,1,0,0,1,0,1,1,1,1,0,0,0,0,0,0,1,0,0,1,1,1,1,0,0,0,1,1,1,0,0,0,1,0,0,0,1,1,1,1,0,1,0,0,1,0,0,1,1,1,0,1,0,0,1,0,1,1
), nrow = 3, byrow = TRUE
)
步骤 3：使用给定的项目参数设置 IRT 模型
custom_model &lt;- function(theta, params) {
a &lt;- params$discrimination
b &lt;- params$difficulty
c &lt;- params$guessing
P &lt;- c + (1 - c) / (1 + exp(-a * (theta - b)))
return(P)

使用 MLE（最大似然估计）估计每个受访者的 theta
estimate_theta &lt;- function(response, item_params) {
theta_values &lt;- seq(-4, 4, by = 0.1)
likelihoods &lt;- sapply(theta_values, function(theta) {
probs &lt;- custom_model(theta, item_params)
likelihood &lt;- prod(probs^response * (1 - probs)^(1 - response))
return(likelihood)
})
best_theta &lt;- theta_values[which.max(likelihoods)]
return(best_theta)

步骤 4：计算所有受访者（三名参与者）的 IRT 量表分数
theta_scores &lt;- apply(response_data, 1,estimate_theta,item_params = item_params)
输出估计的 theta 分数
print(theta_scores)]]></description>
      <guid>https://stats.stackexchange.com/questions/652671/r-code-for-estimating-three-individuals-scores-from-parameters-provided-in-previ</guid>
      <pubDate>Mon, 12 Aug 2024 17:41:34 GMT</pubDate>
    </item>
    <item>
      <title>两种荟萃分析方法：哪一种更可取？</title>
      <link>https://stats.stackexchange.com/questions/652670/two-ways-of-meta-analysis-which-one-is-preferred</link>
      <description><![CDATA[假设我有 $k=1, 2, 3...K$ 项研究，其中连续自变量 $Y$ 和因变量 $X$ 为同一组。研究之间的效果可能不同，我想进行荟萃分析。
我知道的一种方法是进行回归分析。我可以创建一个 $(K-1)$ 维虚拟变量 $Z$，并运行具有随机效果的线性回归。如果 $j$ 是研究指标，$i$ 是样本指标：
$$Y_{ij}=\beta X_{ij}+\gamma_j Z_{ij}+\epsilon$$
$$\gamma_j\sim N(0,\tau^2)$$
$$\epsilon\sim N(0,\sigma^2)$$
或者如果研究不多，我可以做一个固定效应模型：
$$Y_{ij}=\beta X_{ij}+\beta_j Z_{ij}+\epsilon$$
$$\epsilon\sim N(0,\sigma^2)$$
但是，我也看到了对每项研究单独进行分析并计算对数 p 值的加权平均值（可能按样本量或样本量的平方根加权）的做法，如以下线程所示：
组合 p 值时，为什么不直接取平均值？
我是元分析的新手。有人可以给我简单介绍一下哪种方法更可取吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652670/two-ways-of-meta-analysis-which-one-is-preferred</guid>
      <pubDate>Mon, 12 Aug 2024 17:26:34 GMT</pubDate>
    </item>
    <item>
      <title>成分分布的概率[重复]</title>
      <link>https://stats.stackexchange.com/questions/652668/probability-of-constituent-distributions</link>
      <description><![CDATA[我有一组 N 个正态分布，代表一个人在比赛中可以获得的分数。每个分布的平均值和标准差都是已知的，为了简单起见，我们假设它们没有偏差。我们还假设这些分布是独立的。
在这样的系统中，得分最高的人将赢得比赛。
根据正态分布的加性，我们知道将这些组成正态分布相加会产生另一个正态分布。
我的问题是：有没有办法提取一个人赢得比赛的概率？
我曾尝试假设一个人赢得比赛的概率等于该人与所有其他人之间的所有差异概率（即差异正态分布在 0 处的 CDF）的乘积。对于表现最好的人，我似乎取得了不错的成绩，但其他人的成绩太低了。
谢谢！
PS：已经进行了蒙特卡洛测试，以验证有关独立性、总体正态分布和尝试表现的声明。]]></description>
      <guid>https://stats.stackexchange.com/questions/652668/probability-of-constituent-distributions</guid>
      <pubDate>Mon, 12 Aug 2024 16:31:10 GMT</pubDate>
    </item>
    <item>
      <title>关于置信区间公式的一个问题</title>
      <link>https://stats.stackexchange.com/questions/652664/a-question-about-formula-of-confidence-interval</link>
      <description><![CDATA[
我不明白这句话“同样，区间...包含 μ 的概率为 95%”。有人能给我解释一下其中的逻辑吗？它怎么会突然跳到包含 μ 的结论？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652664/a-question-about-formula-of-confidence-interval</guid>
      <pubDate>Mon, 12 Aug 2024 15:47:05 GMT</pubDate>
    </item>
    <item>
      <title>当推导 ELBO 来解决变分推理问题时，为什么我们知道 p(z) 和 p(x,z)，但不知道 p(x) 和 p(z|x)？</title>
      <link>https://stats.stackexchange.com/questions/652660/when-deriving-elbo-to-solve-variational-inference-problems-why-do-we-know-pz-a</link>
      <description><![CDATA[我对 ELBO 的推导有点困惑，因为我不明白为什么有些分布是已知的，而有些分布是未知的。
我猜我们知道 p(z)（先验），因为它是考虑前一个证据后 q(z) 的最后一个值？
我猜我们不能使用 p(z|x) = p(x,z) / p(x)，因为我们不知道 p(x)？
我不知道我们怎么知道 p(x,z) 却不知道 p(x)。p(x) 中的信息肯定包含在 p(x,z) 中？所以如果你知道 p(x,z)，那么你应该能够找到 p(x)？
任何帮助都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652660/when-deriving-elbo-to-solve-variational-inference-problems-why-do-we-know-pz-a</guid>
      <pubDate>Mon, 12 Aug 2024 15:11:54 GMT</pubDate>
    </item>
    <item>
      <title>卡方检验如何能拒绝原假设，而 KS 检验却不能？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652657/how-can-the-chi-square-reject-the-null-hypothesis-while-the-ks-test-does-not</link>
      <description><![CDATA[与F 检验如何拒绝零假设而 KS 检验却不能？类似，我想知道，卡方检验如何拒绝零假设而 KS 检验却不能？
例如，我可以得到卡方检验的 p 值为 $0.001$，KS 检验的 p 值为 $0.45$。
我指定我指的是双样本检验，其中使用卡方检验和Kolmogorov-Smirnov 检验，零假设是两个数据样本来自同一分布/两个样本相同。
关于数据，它们代表了过去 100 年中在某些地区观察到的三组哺乳动物的数量，我们可以称之为 M1、M2 和 M3。例如，1920 年观察到 10 只哺乳动物 M1，1921 年观察到 13 只哺乳动物 M1，1922 年观察到 45 只哺乳动物 M1，依此类推。M2 和 M3 组的哺乳动物也是如此。
此外，我理解卡方检验“测量” 落入 bin“i” 的观测值数量（第一个数据集/分布）与预计落入 bin“i” 的观测值数量（第二个数据集/分布）之间的平方差，而 Kolmogorov-Smirnov 检验“测量”两个 ECDF 之间的最大距离。
也就是说，KS 测试“往往对分布中心附近比尾部更敏感”，但只是我的解释，卡方检验似乎对分布的每个“部分”都很敏感，因为观测值和预期值之间的平方差是针对分布的所有箱体计算的。
但是，我无法“看到”为什么卡方检验会拒绝零假设，即两个数据集/分布不同，而 KS 检验不会被拒绝（即我们无法拒绝），即我们没有足够的统计证据证明两个数据集/分布不同。
这两种“情况”，即 (i) 卡方检验拒绝零假设和 (ii) KS 检验无法拒绝零假设，可以共存吗？
（附加问题：在科学论文中报告这些相反的结果，即 (i) 和 (ii)，是否正确？）]]></description>
      <guid>https://stats.stackexchange.com/questions/652657/how-can-the-chi-square-reject-the-null-hypothesis-while-the-ks-test-does-not</guid>
      <pubDate>Mon, 12 Aug 2024 14:18:18 GMT</pubDate>
    </item>
    <item>
      <title>指数和数值稳定对数概率</title>
      <link>https://stats.stackexchange.com/questions/652651/sums-of-exponentials-numerically-stable-log-probability</link>
      <description><![CDATA[在这个问题中，我问：
如果我们有：$\tau_i \overset{\text{independent}}{\sim}
\exp(\lambda_i)$，对于$i=1,2,3,...,n$，其中$\lambda_i\neq \lambda_j, \forall i\neq j$，那么我想找到概率的一般形式：
$$
\text{Pr}(\sum_{i=1}^{n-1} \tau_i \leq t, \sum_{i=1}^{n} \tau_i &gt; t)
$$
我收到了 Ben 的回答：
$$
\sum_{i=1}^{n-1} m_{n,i} \cdot [ \exp (- \lambda_i t) - \exp (- \lambda_n t) ],
$$
其中术语 $m_{n,j}$ 定义为如：
$$
m_{n,i} = \frac{\lambda_i}{\lambda_n} \prod_{j=1 \\ j \neq i}^{n} \frac{\lambda_j}{\lambda_j-\lambda_i}。
$$
我发现，当 $n$ 相当大（甚至高于 10）时，上述规则计算出的概率在计算上可能会变为负数。即由于 $m_{n,i}$ 既可以为正数也可以为负数，因此计算的精度对于确保概率为正数非常重要。
我想知道是否有一种计算稳定的方法来计算 对数概率？
注意：我意识到 $m_{n,i}$ 的一部分就是所谓的 拉格朗日多项式：
$$
l_j(0) := \prod_{j=1 \\ j \neq i}^{n} \frac{\lambda_j}{\lambda_j-\lambda_i},
$$
其确实有一个稳定的形式定义在这里。不过，我试过了，对于中等大小的 n，我仍然会得到负概率。这也是我希望找到对数概率更稳定表达式的部分原因；使用对数概率也更方便，因为我正在做使用这个的 MCMC。
注意：使用这里设计的一些用于稳定和对数的巧妙解决方案并不简单，因为$m_{n,i}$ 可能是负数。]]></description>
      <guid>https://stats.stackexchange.com/questions/652651/sums-of-exponentials-numerically-stable-log-probability</guid>
      <pubDate>Mon, 12 Aug 2024 13:33:50 GMT</pubDate>
    </item>
    <item>
      <title>竞争风险 - 加权人群中的累积发生率</title>
      <link>https://stats.stackexchange.com/questions/652642/competing-risk-cumulative-incidence-in-a-weighted-population</link>
      <description><![CDATA[我有以下基于倾向得分加权的数据。

模型中唯一感兴趣的独立变量是 treat，因为协变量已使用权重进行平衡。
感兴趣的事件是疾病。

竞争风险是死亡。

因此，event == 0（审查），event == 1（疾病），event == 2（死亡）。
library(cobalt)
library(cmprsk)

set.seed(123)
lalonde &lt;- cbind(lalonde,
event = sample(c(0, 1), size = 614, replace = TRUE, prob = c(0.84, 0.16)),
time = runif(614, min = 10，最大值 = 365))
n &lt;- ceiling(0.05 * nrow(lalonde)) 
selected_indices &lt;- sample(1:nrow(lalonde), size = n)
lalonde[selected_indices, &quot;event&quot;] &lt;- 2

formula &lt;- treat ~ age + educ + race + marriage + nodegree + re74 + re75 + re78

# PS
lalonde$pscore &lt;- glm(formula, data = lalonde,
family = binomial(link = &quot;logit&quot;))$fitted.values

# Weights
lalonde$weight &lt;- ifelse(lalonde$treat == 1,
pmin(lalonde$pscore, 1 - lalonde$pscore) / lalonde$pscore,
pmin(lalonde$pscore, 1 - lalonde$pscore) / (1 - lalonde$pscore))


如果没有权重，我会计算并绘制如下：
cr &lt;- cuminc(ftime = lalonde$time,
fstatus = lalonde$event, 
cencode = 0,
group = lalonde$treat)

p &lt;- ggcompetingrisks(fit = cr, 
multiple_panels = F, 
xlab = &quot;Days&quot;, 
ylab = &quot;Cumulative事件发生率&lt;,
title = &quot;竞争风险分析&quot;) 

p$mapping &lt;- aes(x = time, y = est, colour = group)

由于我对调整竞争风险后的事件感兴趣，因此我排除了竞争风险的曲线：
p$data &lt;- p$data[p$data$event == 1, ]

p + labs(colour = &quot;Group&quot;) 

结果为：

问题：

如何解释权重？
或者它是否迫使某人使用匹配而不是权重，因为没有参数来实现权重？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652642/competing-risk-cumulative-incidence-in-a-weighted-population</guid>
      <pubDate>Mon, 12 Aug 2024 09:07:17 GMT</pubDate>
    </item>
    </channel>
</rss>