<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 17 Jan 2025 09:16:34 GMT</lastBuildDate>
    <item>
      <title>确认蒙特卡洛简历</title>
      <link>https://stats.stackexchange.com/questions/660151/confirmation-on-montecarlo-cv</link>
      <description><![CDATA[我想估算一个测量值。假设我们采用经验估计来估计累积分布函数 (CDF) $F(x,y)$。我想将交叉验证与蒙特卡洛相结合。
我的想法：
方法说明
目标是结合使用经验估计与蒙特卡洛模拟和k 倍交叉验证来估计基于累积分布函数 (CDF) (F(x, y)) 的测量值。

数据生成：
每次蒙特卡洛迭代都会从均匀分布生成数据。例如，两个变量 (X) 和 (Y) 由独立均匀随机变量产生，样本量为 (n = 300)。

为了进行比较，假设测量值有一个固定的真实值（例如 (0.23)）。


蒙特卡罗模拟：为了提供统计稳健性，模拟通过 5,000 次迭代完成。

根据获得的数据，使用平滑的经验 CDF 计算每次迭代中的估计量。


通过 k 倍验证：
每次迭代将数据集分为 (k = 5) 倍。

对训练集（数据）上的每个折叠计算估计量估计量与真实值之间的平均平方差称为“偏差”。估计量与真实值在所有迭代过程中的平均平方差称为均方误差 (MSE)。

实施和输出：- 模拟在 5,000 次迭代中生成测量估计值，以及偏差和 MSE。这些测量值显示出 MSE 随着样本量增加而降低的模式，用于评估估计量的准确性和可靠性。

我们可以这样做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660151/confirmation-on-montecarlo-cv</guid>
      <pubDate>Fri, 17 Jan 2025 07:54:49 GMT</pubDate>
    </item>
    <item>
      <title>r 匹配倾向得分和最近邻</title>
      <link>https://stats.stackexchange.com/questions/660146/r-matching-propensity-scores-and-nearest-neighborhood</link>
      <description><![CDATA[我对匹配过程有理论上的理解，但我不明白 MatchThem 库中是如何实现的。
我像这样指定模型
 matchthem( treatment ~ x1 + x2, x3, 
data = df,
method = &quot;nearest&quot;,
distance = &quot;glm&quot;,
link = &quot;logit&quot;
)

当使用 bal.tab 函数检查余额时，我看到
 Mean.Diff.Unmatch Mean.Diff.Adj
distance 1.087 0.715


我的问题是，Mean.Diff.Unmatched (distance) 1.087 是多少？由于 matchtem 函数估计倾向得分，距离不应该小于 1 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660146/r-matching-propensity-scores-and-nearest-neighborhood</guid>
      <pubDate>Fri, 17 Jan 2025 05:40:43 GMT</pubDate>
    </item>
    <item>
      <title>日食是否减少了新冠肺炎死亡人数？</title>
      <link>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</link>
      <description><![CDATA[我在 R 中模拟了一些现实数据，这些数据显示了 Covid-19 死亡人数随时间的变化情况，以及日食（2024 年 4 月 8 日）发生前的天数：

如果有人不太了解，仅从数据来看，可能会认为日食是降低 Covid 死亡人数的原因。此外，有人可以拟合回归模型，该模型甚至可能很好地拟合数据。
我读到过，我们在统计学中拥有所有这些复杂的技术，例如差异-差异、回归不连续性、合成控制、工具变量、倾向得分匹配等 - 所有这些方法旨在在某种程度上找出我们是否能够真正得出结论，即统计模型的结果忠实地代表了自然。
但在某种程度上，我们在决定将哪些变量纳入统计模型时是否只是使用常识？]]></description>
      <guid>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</guid>
      <pubDate>Fri, 17 Jan 2025 05:13:01 GMT</pubDate>
    </item>
    <item>
      <title>CNN 模型在经过几个周期后仍无法学习</title>
      <link>https://stats.stackexchange.com/questions/660143/cnn-model-is-not-learning-after-some-epochs</link>
      <description><![CDATA[我根据一篇研究论文实现了一个对象检测模型（代码包含在 github 中），并对其进行了一些更改，以便为我的硕士论文创建一个新的更好的模型。为了比较它们，我在相同的环境中使用具有相同参数和其他内容的整个测试数据集。我的模型运行良好，它给了我 90% 的准确率，而原始模型只给了我 63%，因为我只使用部分数据来训练这两个模型，我认为这一定是原始模型的准确率低于研究论文中记录的分数（%86）的原因。这是我的模型的训练损失，它有 5 个损失，并且它们似乎在几个时期后一直在改善，基于高结果和测试集上的准确预测（我已经检查过预测 BBoxes 与 GTs 非常接近），我的模型可能已经达到了一个很好的局部最小值，或者它正在努力达到最佳的全局最小值，因为有 5 个损失，它们的结果似乎在这一点上收敛并且没有得到很好的改善（学习步骤太低）。我检查了各种优化器和学习率调度器，发现它们都以相同的方式运行，但 AdamW 和 Cosing LR Scheduler 是所有调度器中最好的，因为它们的损失最低。

如您所见，没有过度拟合，损失不断减少，模型非常大，我给了模型 1500 张图像（每张 500 张），并将结果翻倍到 3000 张（每张 1000 张），损失略有降低，但模式相同，并且在相同数量的 epoch 之后保持不变。所以我有一些问题：我的模型是否达到了可能的最佳分数？它不能学到更多吗？如何让它学到更多？
我期望模型能学到更多，但它并没有进步。]]></description>
      <guid>https://stats.stackexchange.com/questions/660143/cnn-model-is-not-learning-after-some-epochs</guid>
      <pubDate>Fri, 17 Jan 2025 05:06:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有事实依据的情况下评估重要性抽样的质量</title>
      <link>https://stats.stackexchange.com/questions/660142/how-to-evaluate-the-quality-of-importance-sampling-without-groundtruth</link>
      <description><![CDATA[我对通过重要性抽样估计$\mathbb E_{p(x)}[f(x)]$感兴趣。用$q(x)$表示提议分布。我已推导出一些提议分布$q_j(x)$，我想知道在相同数量的蒙特卡洛样本下，哪个能产生最精确的估计。问题是我不知道真实期望值，而且可能永远无法获得，因为 $x$ 的维度相对较高（~20）。
我能想到的提案分布 $q$ 成为“好”分布的一个必要条件是 $\frac{p(x)f(x)}{q(x)}$ 相对于 $x \sim q(x)$ 的方差应该很小。这是因为当$q(x) \propto p(x) f(x)$时，重要性抽样估计量的方差变为零，而蒙特卡洛平均值给出精确的积分$\int p(x) f(x)\,\mathrm dx$。但这是一个充分条件吗？我应该通过蒙特卡洛方差来评估提案分布的质量吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660142/how-to-evaluate-the-quality-of-importance-sampling-without-groundtruth</guid>
      <pubDate>Fri, 17 Jan 2025 03:42:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 和 R 中提取负二项式参数 $r$ 和 $\pi$？</title>
      <link>https://stats.stackexchange.com/questions/660141/how-to-extract-negative-binomial-parameters-r-and-pi-in-python-and-r</link>
      <description><![CDATA[我尝试使用 Python 和 R 提取移位负二项分布的参数 $r$ 和 $\pi$。但是，我很难在两种语言之间获得一致的结果。
假设我的示例数据是：1,2,3,4,5,6,7,8,9,9,8,7,6,5,4,3,2,1
我对负二项 PMF 使用以下参数化：
$$
p(k) = \binom{k - 2 + r}{k - 1} \cdot \pi^r \cdot (1 - \pi)^{k-1}
$$
这是我的 Python 代码（使用statsmodels):
X = np.ones_like(s)
s = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 8, 7, 6, 5, 4, 3, 2, 1])
res = sm.NegativeBinomial(s, X).fit(start_params=[1, 1], disp=False)
mu = np.exp(res.params[0]) # 平均值 (mu)
p = 1 / (1 + np.exp(res.params[0]) * res.params[1]) # 成功概率

这是我的 R 代码（使用 fitdistr）：
data = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 8, 7, 6, 5, 4, 3, 2, 1)
fit &lt;- fitdistr(data, &quot;Negative Binomial&quot;)
size &lt;- fit$estimate[&quot;size&quot;] # r：size 参数
mu &lt;- fit$estimate[&quot;mu&quot;] # 平均值，用于计算 p
r = size
pi = r / (r + mu)

我不确定我将 Python 中的拟合参数转换为 $r$ 和 $\pi$ 是否正确，我也不清楚这两种方法是否使用相同的参数化。
有人能帮忙澄清一下吗：

我对 $r$ 和 $\pi$ 的转换在 Python 和 R 中是否正确？
Python 和 R 对负二项分布的拟合是否存在差异，或者我应该注意哪些参数化差异？

提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/660141/how-to-extract-negative-binomial-parameters-r-and-pi-in-python-and-r</guid>
      <pubDate>Fri, 17 Jan 2025 03:38:59 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归中的虚拟变量与虚拟变量交互作用</title>
      <link>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</link>
      <description><![CDATA[我正在 R 中进行泊松回归，以估计按年龄组和病毒分类的死亡人数，其中相互作用的项是因子：
model &lt;- glm(death_count ~ strain * cohort + age + year,
family = poisson(link = &quot;log&quot;),
offset = log(exposure),
data = df)

我的 df 是面板数据，其中包含每年特定年龄的死亡人数。每年都以特定病毒为特征，每个年龄分配一个群体。我试图找出以病毒 C 为特征的年份中死亡人数减少的统计意义。以下是简化的回归输出：
 估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -15.39575 0.07621 -202.012 &lt; 2e-16 ***
病毒A -1.29389 0.08358 -3.516 0.000437 ***
病毒B 2.80059 0.06230 12.851 &lt; 2e-16 ***
病毒C 4.22142 0.05298 60.800 &lt; 2e-16 ***
群组X -2.99472 0.02494 -39.890 &lt; 2e-16 ***
群组Y -1.76074 0.02747 -27.691 &lt; 2e-16 ***
群组Z -1.31331 0.03499 -8.953 &lt; 2e-16 ***
病毒A：群组X 1.39666 0.07366 5.385 7.24e-08 ***
病毒B：群组X 1.21714 0.05685 3.820 0.000134 ***
病毒C：群组X -3.97906 0.03390 -28.883 &lt; 2e-16 ***
病毒A：队列Y 1.24520 0.10246 2.393 0.016701 * 
病毒B：队列Y 1.05056 0.07980 0.634 0.526360 
病毒C：队列Y -1.43923 0.03422 -12.836 &lt; 2e-16 ***
virusA:cohortZ 0.12472 0.13408 0.930 0.352274 
virusB:cohortZ -0.33748 0.11851 -2.848 0.004404 ** 
virusC:cohortZ -1.13441 0.04187 -3.210 0.001327 ** 

我知道没有交互项的系数是与参考组相比的，但我听说在泊松回归中，交互项并不那么简单。
我有兴趣解释为什么与队列 Y 和 Z 相比，队列 X 感染病毒 C 的死亡率减少幅度最大。我不太明白如何理解交互系数，我也不明白为什么截距为负。如果没有偏移量，截距 = 0.18252，我无法理解这一点，因为我认为添加偏移量会将 DV 变成速率。]]></description>
      <guid>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</guid>
      <pubDate>Fri, 17 Jan 2025 00:16:33 GMT</pubDate>
    </item>
    <item>
      <title>在 Anderson-Gill 模型中，tstart 和 tstop 可以相同吗？</title>
      <link>https://stats.stackexchange.com/questions/660134/can-tstart-and-tstop-be-the-same-in-an-anderson-gill-model</link>
      <description><![CDATA[我正在处理事件发生时间数据，并使用 R 中生存包的 coxph() 函数中实现的 Anderson-Gill 模型。在此模型中，时间间隔由 tstart（开始时间）和 tstop（停止时间）定义，我需要了解如何处理 tstart == tstop 的间隔。
具体来说，我想知道：
在 Anderson-Gill 模型中，tstart 和 tstop 相同是否有效？
如果不是，零长度间隔的含义是什么，应该如何处理？
例如，考虑以下数据集：



id
tstart
tstop
event




1
0
10
0


1
10
10
1


2
5
5
1



当我尝试使用 coxph(Surv(tstart, tstop, event) ~ 1, data = my_data)，我收到有关 tstart == tstop 的警告。我理解零长度间隔并不代表有意义的风险时间，但我想确认解决这种情况的最佳方法。
我应该如何处理这些情况？我应该：排除 tstart == tstop 的行？为 tstop 添加一个小值（例如，tstop = tstart + 1e-5）？还有其他推荐的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660134/can-tstart-and-tstop-be-the-same-in-an-anderson-gill-model</guid>
      <pubDate>Thu, 16 Jan 2025 23:19:41 GMT</pubDate>
    </item>
    <item>
      <title>包含两个样本之间差异值的数据集是否会违反独立性假设？</title>
      <link>https://stats.stackexchange.com/questions/660131/would-a-dataset-that-included-a-value-that-is-the-difference-between-two-samples</link>
      <description><![CDATA[例如，我的数据是这样的：
df &lt;- data.frame(
patch1 = c(&quot;Sample1-1&quot;, &quot;Sample1-1&quot;, &quot;Sample2-1&quot;,&quot;Sample1-2&quot;, &quot;Sample1-2&quot;,&quot;Sample2-2&quot;),
patch2 = c(&quot;Sample2-1&quot;, &quot;Sample3-1&quot;, &quot;Sample3-1&quot;, &quot;Sample2-2&quot;, &quot;Sample3-2&quot;,&quot;Sample3-2&quot;),
Contrast= c(1, 2, 3, 4,5,6),
Species = c(&quot;Species1&quot;, &quot;物种1&quot;、&quot;物种1&quot;、&quot;物种2&quot;、&quot;物种2&quot;、&quot;物种2&quot;))

从个体中抽取样本并相互测量，以得出给定个体样本之间的差异（我在“对比”中看到的）。
我想要做的是使用一个简单的高斯线性模型来查看不同物种之间的对比变量是否存在显着差异。
我想知道这是否会违反独立性假设，如果是，我该如何解决这个问题，我想使用一个随机效应模型，其中 patch1 和 patch2 都是随机效应，这样可行吗？或者我对随机效应如何应用的理解是错误的。
为了进一步说明，我真正想做的是估计在动物体内发现的塑料碎片（我的样本）之间的 dS（色度对比度）是否存在显着差异，以及这种模式在物种层面上是否存在差异。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660131/would-a-dataset-that-included-a-value-that-is-the-difference-between-two-samples</guid>
      <pubDate>Thu, 16 Jan 2025 22:08:55 GMT</pubDate>
    </item>
    <item>
      <title>进行缺失数据插补是否会导致观测值之间的依赖性？</title>
      <link>https://stats.stackexchange.com/questions/660127/does-doing-missing-data-imputation-lead-to-dependency-between-observations</link>
      <description><![CDATA[当对数据集的所有观测值进行插补时，这是否会导致观测值之间的依赖性？那么假设观测值独立的统计模型是否不够充分？
例如，K 最近邻观测值的插补缺失值是其他观测值观测值的函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/660127/does-doing-missing-data-imputation-lead-to-dependency-between-observations</guid>
      <pubDate>Thu, 16 Jan 2025 20:41:13 GMT</pubDate>
    </item>
    <item>
      <title>推断回归拟合中存在异方差</title>
      <link>https://stats.stackexchange.com/questions/660123/inference-on-the-presence-of-heteroscedasticity-in-regression-fit</link>
      <description><![CDATA[我已经拟合了一个简单的线性回归，如下所示
dat = structure(list(A = c(-3.673, -4.914, -4.556, -4.732, -3.36, -3.731, 
-5.069, -5.263, -5.054, -3.711, -4.159, -3.191, -5.035, -5.205, 
-4.809, -5.485, -3.621, -4.551, -3.989, -3.963, -5.092, -4.508, 
-6.163, -4.923, -4.022, -3.098), B = c(0.01, 0.016, 0.011, 0.023, 
-0.014, 0.036, 0.083, 0.082, 0.03, 0.005, 0.025, 0.012, 0.027, 
0.056, 0.023, 0.103, 0.009, 0.02, 0.033, 0.051, 0.076, 0.004, 
0.049, 0.052, 0.033, -0.032), C = c(-0.205, -0.15, -0.378, -0.751, 
0.304, -0.314, 0.587, 0.258, 0.147, -0.379, -0.271, -0.527, -0.076, 
-0.149, -0.001, 0.412, 0.021, -0.182, -0.363, -0.447, 0.335, 
0.108, 1.209, 0.035, -0.116, -0.319)), row.names = c(NA, -26L
), class = &quot;data.frame&quot;)

MyModel = lm(A ~ B + C, data = dat)

&gt; print(summary(MyModel))

调用：
lm(formula = A ~ B + C, data = dat)

残差：
最小值 1Q 中位数 3Q 最大值 
-0.8979 -0.4668 0.1139 0.3984 0.7566 

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) -4.0786 0.1619 -25.198 &lt; 2e-16 ***
B -13.0134 3.7676 -3.454 0.00216 ** 
C -0.7241 0.2879 -2.515 0.01935 * 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：23 个自由度上的 0.5183

多重 R 平方：0.5904，调整后的 R 平方：0.5547

F 统计量：2 和 23 DF 上的 16.57，p 值：3.488e-05

但是，如果我想获得异方差稳健估计，我会得到
library(sandwich)
&gt; print(coeftest(MyModel, vcov = vcovHC(MyModel, type = &quot;HC0&quot;)))

系数的 t 检验：

估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) -4.07864 0.16581 -24.5980 &lt; 2.2e-16 ***
B -13.01339 3.40801 -3.8185 0.000882 ***
C -0.72411 0.34479 -2.1001 0.046885 * 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

正如您所看到的，对变量 C 重要性的推断会根据异方差稳健估计而改变，该变量似乎略微不重要。
基于上述情况，我应该采用异方差稳健估计还是普通估计？
但是，如果我使用 Berush-pegan 检验来测试残差中是否存在异方差，我会发现似乎没有异方差
&gt; bptest(MyModel)

学生化 Breusch-Pagan 检验

数据：MyModel
BP = 2.3604，df = 2，p 值 = 0.3072

我该如何解释这种相互矛盾的结果？样本量相对较小是真正的问题吗？即使在这种情况下，我应该采用哪个估计值？]]></description>
      <guid>https://stats.stackexchange.com/questions/660123/inference-on-the-presence-of-heteroscedasticity-in-regression-fit</guid>
      <pubDate>Thu, 16 Jan 2025 18:47:17 GMT</pubDate>
    </item>
    <item>
      <title>如果需要真实参数的值来确定统计数据是否无偏，那么无偏估计量的意义何在？</title>
      <link>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</link>
      <description><![CDATA[我对无偏估计量的定义是：“如果用于估计参数的统计数据的抽样分布的平均值等于被估计参数的值，则该统计数据是无偏估计量。”
我知道如何确定统计数据是否是无偏估计量，因为我能够基于此解决应用题，但我不明白我们为什么要使用无偏估计量。我的笔记说，您需要使用无偏估计量，以便您的估计更准确。这对我来说很有意义，但为了确定统计数据是否是无偏估计量，您需要知道参数的值，以便将其与抽样分布的平均值进行比较，看看它们是否相等。如果使用无偏估计量来估计参数的值，如果我们已经知道参数的值，使用它有什么意义呢？
我一直在为此绞尽脑汁，但无济于事，如能得到任何帮助我将不胜感激，谢谢。
（我不擅长措辞，如果我听起来很重复或没有意义，请原谅）]]></description>
      <guid>https://stats.stackexchange.com/questions/660108/what-is-the-point-of-unbiased-estimators-if-the-value-of-true-parameter-is-neede</guid>
      <pubDate>Thu, 16 Jan 2025 15:06:38 GMT</pubDate>
    </item>
    <item>
      <title>回归分析中总体模型和样本模型的形式区别？</title>
      <link>https://stats.stackexchange.com/questions/660132/formal-difference-between-population-and-sample-model-in-regression-analysis</link>
      <description><![CDATA[术语“样本回归模型”在回归分析中究竟指什么？假设我们有一个数据集$\{(\mathbf{x}_i,\mathbf{y}_i)\}$，我们假设一个底层回归模型形式为
$$
\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon},
$$
其中$\boldsymbol{\theta}$是真实总体参数（频率学派观点）和$\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\Sigma)$。我们所说的样本回归模型到底是什么意思？
以下是我正在探索的一些可能性：

拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}})$，从某种意义上说，我们已经选择了一个估计值$\hat{\boldsymbol{\theta}}$;
拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}}) + \hat{\boldsymbol{\epsilon}}$，其中我们有一个估计值$\hat{\boldsymbol{\theta}}$ 而且 $\hat{\boldsymbol{\epsilon}} \sim \mathcal{N}(\mathbf{0},\hat{\Sigma})$;
从字面上理解，人口模型 $\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon}$，但现在以样本指数的形式写出：$\mathbf{y}_i = f(\mathbf{x}_i;\boldsymbol{\theta}) + \boldsymbol{\epsilon}_i$;
关系$\mathbf{y}_i = f(\mathbf{x}_i;\hat{\boldsymbol{\theta}}) + \mathbf{e}_i$，其中$\mathbf{e}_i = \mathbf{y}_i - \hat{\mathbf{y}}_i$为残差。

如能提供严格说明，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660132/formal-difference-between-population-and-sample-model-in-regression-analysis</guid>
      <pubDate>Wed, 15 Jan 2025 20:28:19 GMT</pubDate>
    </item>
    <item>
      <title>核学习中 RKHS 与特征空间的关系</title>
      <link>https://stats.stackexchange.com/questions/660057/relation-of-rkhs-to-feature-space-in-kernel-learning</link>
      <description><![CDATA[在标准 SVM 公式中，我们通常会寻找一个向量 $w \in \mathbb{R}^D$，该向量定义 $\mathbb{R}^D$ 中的超平面。决策函数的形式如下：
$$
f(x) = \operatorname{sign}(\langle w, x \rangle + b),
$$
其中 $\langle \cdot, \cdot \rangle$ 是 $\mathbb{R}^D$ 中的标准内积，而 $b \in \mathbb{R}$ 是偏差项。
现在，假设我们有一个 p.d 内核 $k$，我们知道有一个唯一的 RKHS $H_k$，因此我们可以寻找 $f \in H_k$ 在 $H_k$ 中定义一个超平面。相应的决策函数变为：
$$
f(x) = \operatorname{sign}(\langle f, \phi_1(x) \rangle_{H_k} + b),
$$
其中 $\phi_1(x) = k(\cdot, x) \in H_k$ 是进入 RKHS 的规范特征图。现在，例如通过铰链损失公式的软边距 svm，我们可以使用表示定理来论证 $f^*$ 位于由我们的训练模式引起的规范特征图的跨度内。
问题
现在，我的问题如下。在这个公式中，我们“看”对于 RKHS 中的超平面，但在大多数标准介绍中，人们认为我们在（可能无限的）特征空间中寻找超平面。
我知道 $k$ 会诱导另一个特征图（实际上，我认为有无数个，因为内积对正交变换不变？）$\phi_2: X \to F$ 进入某个希尔伯特空间 $F$，满足：
$$
\langle \phi(x)_2, \phi(y)_2 \rangle_{F} = k(x, y)。
$$
因此，我们有两个特征图：
$$
\phi_{1}: x \mapsto k(\cdot, x) \in H_k \quad \text{(进入 RKHS 的规范映射),}
$$
$$
\phi_{2}: x \mapsto \phi_2(x) \in F \quad \text{(进入某个希尔伯特空间 $F$ 的映射)}。
$$
我们现在是否可以争辩说，找到某个 $f^* \in H_k$ 将自动导致 $g^* \in F$，如下所示：
$$
\langle \phi(x)_2, \phi(y)_2 \rangle_{F} = \langle \phi(x)_1, \phi(y)_1 \rangle_{H_k} = k(x, y) $$
因此
$$ \langle f^*, \phi_1(y) \rangle_{H_k} = \sum_{i=1}^n \alpha_i \langle \phi_1(x_i), \phi_1(y) \rangle_{H_k} = \sum_{i=1}^n \alpha_i \langle \phi_2(x_i), \phi_2(y) \rangle_{F} = \langle g^*, \phi_2(y) \rangle_{F}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660057/relation-of-rkhs-to-feature-space-in-kernel-learning</guid>
      <pubDate>Wed, 15 Jan 2025 12:18:36 GMT</pubDate>
    </item>
    <item>
      <title>L2 惩罚 cox 比例风险回归的统计推断</title>
      <link>https://stats.stackexchange.com/questions/660048/statistical-inference-for-l2-penalized-cox-proportional-hazard-regression</link>
      <description><![CDATA[首先，感谢您阅读我的问题。这是我第一次在这个平台上提问，所以如果某些要求没有得到满足，我深表歉意。
我试图使用 cox 比例风险生存分析来估计多个预测因子（HR 及其 95% CI 和 p 值）对直肠癌复发概率的影响。
由于我的数据集规模小（140 个观测值）且事件计数低（7 个事件），我决定使用 glmnet 包中的岭回归。Lasso 并不可取，因为我想保留所有预测因子，因为我有证据表明它们对复发的重要性。
我搜索了文献并了解到，虽然惩罚模型的统计推断以前由于惩罚引入的偏差而并不可取，但现在已被诸如“hdi”和“selectiveInference”之类的包克服，用于 Lasso 型回归，“lmridge”用于 L2 惩罚线性回归。
我的问题如下：

有没有什么方法可以对 Cox 比例模型上的岭回归进行统计推断。到目前为止，我还没有找到任何具有此功能的文章或 R 包
如果岭回归的统计推断仍然不可接受，我该如何解释 glmnet() 提供的 HR

这是我用于拟合模型的代码：
set.seed(10)
y &lt;- with(df_cox, Surv(df_cox$recurrencetime, df_cox$recurrence)) # 响应变量
x &lt;- model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1] # 预测器
df_cox = model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1] # 预测器
df_cox = model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1]
cv_model &lt;- cv.glmnet(
x, y,
family = &quot;cox&quot;,
alpha = 0, # 弹性网络 (alpha = 0.5 是套索和脊线的混合)
nfolds = 10 # 10 倍交叉验证
)
best_lambda &lt;- cv_model$lambda.min

# 使用最佳 lambda 拟合最终模型
final_model &lt;- glmnet(x, y, family = &quot;cox&quot;, alpha = 0, lambda = best_lambda)
]]></description>
      <guid>https://stats.stackexchange.com/questions/660048/statistical-inference-for-l2-penalized-cox-proportional-hazard-regression</guid>
      <pubDate>Wed, 15 Jan 2025 07:30:52 GMT</pubDate>
    </item>
    </channel>
</rss>