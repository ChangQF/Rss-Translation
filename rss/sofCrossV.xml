<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 29 Nov 2024 21:16:02 GMT</lastBuildDate>
    <item>
      <title>为什么我的方差参数不会在 Metropolis-Hastings 采样器中收敛？</title>
      <link>https://stats.stackexchange.com/questions/658046/why-wont-my-variance-parameter-converge-in-my-metropolis-hastings-sampler</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658046/why-wont-my-variance-parameter-converge-in-my-metropolis-hastings-sampler</guid>
      <pubDate>Fri, 29 Nov 2024 20:22:02 GMT</pubDate>
    </item>
    <item>
      <title>似然比检验与 Wald 检验多重共线性</title>
      <link>https://stats.stackexchange.com/questions/658039/likehood-ratio-test-vs-wald-test-multicolinearity</link>
      <description><![CDATA[我想做一个项目，展示似然比检验的稳健性。我的想法是，在一个预测因子显示多重共线性的逻辑回归中，Wald 检验在 LRT 中的 p 值结果不太可靠，因为 LRT 关注的是整个模型而不是单个系数。我只是不知道如何正确证明这一点，以及这个想法有多有效。有人可以提供一些指导吗？
例如，我的场景是一个有五个预测因子的逻辑回归，其中两个显示高相关性。我运行模型并运行 Wald 检验以检查模型中的所有系数是否显著。然而，由于相关性，结果可能会受到影响。我的想法是，然后使用完整模型和另一个没有受到影响的变量的模型运行 LRT，并测试 LRT 是否告诉我完整模型更好。这个想法是表明 LRT 比 Wald 检验更稳健，因为 LRT 查看整个模型而不是单个系数。]]></description>
      <guid>https://stats.stackexchange.com/questions/658039/likehood-ratio-test-vs-wald-test-multicolinearity</guid>
      <pubDate>Fri, 29 Nov 2024 18:22:21 GMT</pubDate>
    </item>
    <item>
      <title>推导指数族中的尺度参数</title>
      <link>https://stats.stackexchange.com/questions/658038/deriving-scale-parameter-in-exponential-family</link>
      <description><![CDATA[以下内容摘自 Casella &amp; Berger 的《统计推断》（2024 年版）第 98 页：

第 3.3 节中介绍的几个家族要么是尺度家族，要么有尺度家族
作为子家族。如果 α 是固定值且 β 是尺度参数，则这些家族为伽马家族，如果 µ = 0 且 σ 是尺度参数，则这些家族为正态家族，指数家族，如果 µ = 0 且 σ 是尺度参数，则这些家族为双指数家族。在每种情况下，标准 pdf 都是通过将尺度参数设置为 1 获得的 pdf。然后，该家族的所有其他成员都可以证明为定义 3.5.4 中的形式。

这是第 3.5.4 页上出现的定义 3.5.4。 97:

定义 3.5.4 设 $f(x)$ 为任意 pdf。则对于任意 $\sigma &gt; 0$，pdf 家族 $(1/\sigma)f(x/\sigma)$，由参数 $\sigma$ 索引，被称为具有标准 pdf $f(x)$ 的尺度家族，而 $\sigma$ 被称为该家族的尺度
参数。

因此，我一直在试图证明 $\mathbf{\theta}$ 是尺度指数家族的尺度参数，其 pdf 给出为 $f(x|\mathbf{\theta})=h(x)c(\mathbf{\theta})\exp{\sum_{i=1}^{k}w_{i}(\mathbf{\theta})t_{i}(x)}$ 在第 90 页。另请参阅第 90 页。 92,

这里 $h(x) \geq 0$ 和 $t_{1}(x), \cdots ,t_{k}(x)$ 是观测 $x$ 的实值函数（它们不能依赖于 $\mathbf{θ}$ ），而 $c(\mathbf{θ}) \geq 0$ 和 $w_{1}(\mathbf{θ}), \cdots , w_{k}(\mathbf{θ})$ 是可能的向量值
参数$\mathbf{θ}$（它们不能依赖于$x$）。上一节中介绍的许多常见家族
都是指数家族。这些包括连续家族——正态、伽马和贝塔；和离散族——二项式、泊松和负二项式。

我很难证明这一点，因为关于$h(x)$和$t_{i}(x)$的信息并不多，我是否可以将指数族 pdf 写为$(1/\sigma)f(x/\sigma)$。
所以我的问题是$\theta$是否真的是指数族的比例参数，如果是，如何根据定义证明它？]]></description>
      <guid>https://stats.stackexchange.com/questions/658038/deriving-scale-parameter-in-exponential-family</guid>
      <pubDate>Fri, 29 Nov 2024 18:11:15 GMT</pubDate>
    </item>
    <item>
      <title>.jmp 中的一阶模型与二阶模型</title>
      <link>https://stats.stackexchange.com/questions/658037/1st-order-model-vs-2nd-order-model-in-jmp</link>
      <description><![CDATA[我如何解释我的二阶模型显示预测因子和响应之间存在显著关系，因为我没有拟合度不足，而对于一阶模型中的相同数据，我存在显著的拟合度不足。我如何解释二阶模型提供了更好的数据近似值？我只是试图理解它，因为我目前对它只有基本的了解。提前谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658037/1st-order-model-vs-2nd-order-model-in-jmp</guid>
      <pubDate>Fri, 29 Nov 2024 17:58:44 GMT</pubDate>
    </item>
    <item>
      <title>如何过滤手动记录的数据中的异常值？</title>
      <link>https://stats.stackexchange.com/questions/658035/how-can-i-filter-outliers-in-data-that-is-manually-recorded</link>
      <description><![CDATA[为了填写表格，不同的人必须写下某种参数的值，而人们显然容易写错。有时，错误率高达 1000。这会产生大量与数据本身无关的异常值，而是人为错误造成的。
有没有适当的方法来处理这些异常值？很难区分“真实”异常值和人为错误造成的异常值。
所讨论的数据：

所讨论的参数是“剂量面积乘积”(DAP)，是在某个程序中对患者进行 X 射线后填写的。
数据偏向较低的值，但并不完全呈现“完全正常”分布（虽然看起来有点像）。
数据不能为零。
所有数据都是由不同的人输入的，这会导致很大的不确定性。

过滤异常值并将其从数据中排除的理想方法是什么？
我曾尝试：

手动删除异常值：我停止这样做，因为这是一种主观的过滤形式，我认为本质上是“非法的”。也很难区分“真实”的异常值和人为造成的异常值。
箱线图：我曾尝试计算 Q1、Q3、IQR、下限（LL = Q1 - 1,5*IQR）和上限（UL = Q3 + 1,5*IQR）。然后，我过滤掉碰巧超出晶须和箱线的数据。我认为“问题”在于数据是非负的。上限附近的异常值会被移除，但下限附近的异常值不会被移除，因为 LL 总是为负，而我没有负数据。

只使用箱线图就“足够好”了吗？或者是否有实际的统计方法可用于客观地“移除”异常值？]]></description>
      <guid>https://stats.stackexchange.com/questions/658035/how-can-i-filter-outliers-in-data-that-is-manually-recorded</guid>
      <pubDate>Fri, 29 Nov 2024 16:40:32 GMT</pubDate>
    </item>
    <item>
      <title>短期随机赌博机的下界</title>
      <link>https://stats.stackexchange.com/questions/658033/lower-bound-for-stochastic-bandits-with-short-horizons</link>
      <description><![CDATA[我想表明，如果地平线 $n$ 严格小于臂的数量 $k$，则每个算法都会至少享有
$$
\frac{n(2k-n-1)}{2k}
$$ 的遗憾。现在，Lattimore 和 Szepesvári 从一个具有高斯臂的强盗机开始，其平均值为 $\mu=(\Delta,0,\cdots,0)$，并构建一个具有相同平均值的臂，但算法在面对 $\mu$ 时探索最少的点除外，其平均值为 $2\Delta$。将第二个向量称为 $\mu&#39;$，并使用信息论的思想，他们表明
$$
R_n(\pi,\nu_\mu)+R_n(\pi,\nu_{\mu&#39;})\geq\frac{n\Delta}{4}\exp(-\frac{2n\Delta^2}{k-1})
$$
他们选择的 $\Delta$ 必须介于零和 $1/2$ 之间，所以我不能用那个来解决我的问题。但就我的情况而言，也许还有另一个 $\Delta\in[0,1/2]$ 可以利用。但我不知道如何找到这样的$\Delta$。（也许我应该走一条完全不同的路，但我也不知道该怎么做。）]]></description>
      <guid>https://stats.stackexchange.com/questions/658033/lower-bound-for-stochastic-bandits-with-short-horizons</guid>
      <pubDate>Fri, 29 Nov 2024 16:27:11 GMT</pubDate>
    </item>
    <item>
      <title>Youtube 垃圾邮件分类器 - 不同方法产生相同的准确率（94％）</title>
      <link>https://stats.stackexchange.com/questions/658032/youtube-spam-classifier-different-methods-yielding-the-same-accuracy-94</link>
      <description><![CDATA[(上下文)
我目前正在大学里做一个报告项目，使用此数据集构建一个分类器模型，将评论分类为垃圾邮件或正常（非垃圾邮件），然后将预测 csv 提交到 Kaggle。数据分为约 68% 用于训练，其余 32% 用于测试。请注意，作为学生，我们获得了训练的标签，但无法访问测试数据集的标签。关于预处理，我只执行了词干提取。
我的报告重点比较不同的字符 n-gram、基于频率的文本嵌入和模型组合。具体来说，我们将模型与以下模型进行比较：

字符 n-gram 从 1 到 6
文本嵌入：TF-IDF 与词袋 (BoW)
模型：朴素贝叶斯、随机森林、支持向量机 (SVM)

问题
我的困惑来自两件事：

首先，虽然我的模型在分层 10 倍交叉验证中始终表现超过 95%，但在测试数据集中的准确度评估时，准确度下降到只有大约 93-94%。这在我的所有模型中都是一致的，因为 CV 的准确度始终高于测试准确度；可能是什么问题？似乎我的数据目前过度拟合了。我该如何解决这个问题？
另一个值得关注的问题是，出于某种奇怪的原因，我的许多“最佳”模型的测试准确率都相同。这里的“最佳”是指最高的 CV 准确率。具体来说，我发现使用 BoW 进行 3 和 4 的 n-gram 的随机森林和 SVM 模型都获得了相同的测试准确率，尽管 CV 准确率不同。这可能是什么原因造成的？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658032/youtube-spam-classifier-different-methods-yielding-the-same-accuracy-94</guid>
      <pubDate>Fri, 29 Nov 2024 15:16:51 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法按子组进行预测，而不用分别预测每个子组？</title>
      <link>https://stats.stackexchange.com/questions/658030/is-there-a-way-to-forecast-by-subgroup-without-forecasting-each-subgroup-separat</link>
      <description><![CDATA[我正在尝试找到一个合适的模型，根据之前的招聘周期和本周期迄今为止收到的申请数量来预测招聘周期结束时收到的申请数量 - 如果能够将最终预测细分为不同的子组（例如，我们预计有 1,000 份申请，其中 200 份申请该职位，其中 50 份来自该地区，其中 1 份拥有博士学位），这将非常有帮助。
我们当前数据中的子组数据非常好，但有些子组非常小（许多子组的申请人数少于 10 人），所以我不确定单独预测它们是否可靠（我相信大多数自回归模型都需要这样做）。
有没有一种方法可以做到这一点，既可靠又能产生准确的预测？]]></description>
      <guid>https://stats.stackexchange.com/questions/658030/is-there-a-way-to-forecast-by-subgroup-without-forecasting-each-subgroup-separat</guid>
      <pubDate>Fri, 29 Nov 2024 13:01:38 GMT</pubDate>
    </item>
    <item>
      <title>原始协方差与多个 MCMC 链上均值的协方差之间的等价性</title>
      <link>https://stats.stackexchange.com/questions/658028/equivalence-between-raw-covariance-and-covariance-of-mean-over-multiple-mcmc-cha</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658028/equivalence-between-raw-covariance-and-covariance-of-mean-over-multiple-mcmc-cha</guid>
      <pubDate>Fri, 29 Nov 2024 11:56:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么卡方检验会给出不直观的结果？</title>
      <link>https://stats.stackexchange.com/questions/658020/why-is-the-chi-square-test-giving-unintuitive-results</link>
      <description><![CDATA[我正在对不同年龄组之间的变量分布进行卡方检验。数据在 R 中如下所示：
 a &lt;- c(66,97, 48)
b &lt;- c(145,174,58)
c &lt;- c(129,128,58)

M &lt;- data.frame(cbind(a,b,c))
colnames(M) &lt;- c(&quot;18-34&quot;, &quot;35-49&quot;,&quot;50-66&quot;)
rownames(M) &lt;- c(&quot;Below avg&quot; , &quot;Average&quot;,&quot;Above avg&quot;)
view(M)

绘制时，最年轻组的数据分布与中间组相似，与最年长组不同。

如果我进行整体卡方检验，我会得到一个不显著的差异：
X-squared = 8.6905, df = 4, p-value = 0.06932

但是，如果我成对比较年龄组，我会得到最小和中间之间的显著差异，而不是最小和最年长之间的显著差异。
数据：M[, 1:2]
X-squared = 6.0153, df = 2, p-value = 0.04941

数据：M3[, c(1, 3)]
X-squared = 5.2093，df = 2，p 值 = 0.07393

我认为这与每个年龄组的参与者数量不平衡有关，尽管每个组的总体观察数量相当大。但我不确定是否以及如何解释这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/658020/why-is-the-chi-square-test-giving-unintuitive-results</guid>
      <pubDate>Fri, 29 Nov 2024 09:07:03 GMT</pubDate>
    </item>
    <item>
      <title>带有插值数据的回归模型？</title>
      <link>https://stats.stackexchange.com/questions/658017/regression-models-with-interpolated-data</link>
      <description><![CDATA[我有一个国家，里面有很多城市（层级结构：国家-省-城市）。我只有 2010 年和 2020 年每个城市的平均社会经济信息（例如就业率、中位数收入等）。
2016 年举行了选举。我知道从 2010 年到选举期间每个城市的政治倾向，以及选举后政治倾向的变化。
我想建立一个回归模型，研究社会经济条件的变化如何影响投票选择（我知道生态谬误，我只对研究总体趋势感兴趣，而不是将其推广到总体中的个人）。
如果我每年都有数据，我会尝试使用一些技术，例如差异差异或回归不连续性，以查看选举前后的情况。但是，就我而言，这不可用。
我对该怎么做有这个天真的想法。

我认为我可以创建一个基于增长率的插值回归模型。我首先假设每个社会经济变量有一个简单的纵向模型（假设它只依赖于自身而不依赖于其他因素，遵循单调/均匀变化的线性增长）：

$$ \frac{x_{i,2020} - x_{i,2010}}{x_{i,2010}} = \alpha_0 + u_{px} + v_{ix} + \epsilon_{ix} $$
其中：

$\alpha_0$ 是所有城市的平均增长率
$u_{px}$ 是各省与平均增长率的偏差
$v_{ix}$ 是城市与其所在省份增长率的偏差
$\epsilon_{ix}$ 是误差项

现在，对于 2010 年至 2020 年之间任何时间 $t$ 的插值，我们想要计算到时间 $t$ 时应该发生的总变化的百分比。公式变为：
$$ \hat{x}_{it} = x_{i,2010}\left(1 + \frac{t-2010}{10}(\alpha_0 + u_{px} + v_{ix})\right) $$
例如具体计算：
$$ \hat{x}_{i,2015} = x_{i,2010}\left(1 + \frac{2015-2010}{10}(\alpha_0 + u_{px} + v_{ix})\right) $$
$$ \hat{x}_{i,2015} = x_{i,2010}\left(1 + \frac{5}{10}(\alpha_0 + u_{px} + v_{ix})\right) $$
$$ \hat{x}_{i,2015} = x_{i,2010}(1 + 0.5(\alpha_0 + u_{px} + v_{ix})) $$

从这里开始，我使用第 1 部分中的插值来创建一个模型，该模型研究城市在选举前/后如何改变其政治倾向（基于其选举前的倾向和第 1 部分中插值的社会经济预测因素）。我想用多项逻辑回归模型来做这件事：

$$ \log\left(\frac{P(Y_i = k)}{P(Y_i = K)}\right) = \beta_{0k} + \beta_{1k}j_i + \beta_{2k}\hat{x}_{i,2016} + \beta_{3k}(\hat{x}_{i,2016} - \hat{x}_{i,2015}) + u_{pk} $$
其中：

$Y_i$ 是城市 $i$
$k$ 代表各政党类别（参考类别 $K$ 除外）
$j_i$ 为城市 $i$ 的选举前政党归属
$\hat{x}_{i,2016}$ 和 $\hat{x}_{i,2016} - \hat{x}_{i,2015}$ 来自模型 1
$u_{pk}$ 为政党的省级随机效应 $u_{pk}$ class=&quot;math-container&quot;&gt;$k$

选举后，一个城市加入$k$政党的概率为：
$$ P(Y_i = k) = \frac{\exp(\beta_{0k} + \beta_{1k}j_i + \beta_{2k}\hat{x}_{i,2016} + \beta_{3k}(\hat{x}_{i,2016} - \hat{x}_{i,2015}) + u_{pk})}{\sum_{m=1}^K \exp(\beta_{0m} + \beta_{1m}j_i + \beta_{2m}\hat{x}_{i,2016} + \beta_{3m}(\hat{x}_{i,2016} - \hat{x}_{i,2015}) + u_{pm})} $$
我感觉我的建模方法简直是一场灾难，哈哈。插值值有误差，而第二步没有考虑到这一点。我确信这里存在很多问题。有人能告诉我我到底搞砸了多少吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658017/regression-models-with-interpolated-data</guid>
      <pubDate>Fri, 29 Nov 2024 05:34:47 GMT</pubDate>
    </item>
    <item>
      <title>置信区间 - CLT，初级水平</title>
      <link>https://stats.stackexchange.com/questions/658015/confidence-interval-clt-begginer-level</link>
      <description><![CDATA[我正在参加一个关于统计学的在线课程，更准确地说是关于置信区间的课程。
下面是一个练习，他们试图根据以前收集的数据估计每个月份可以出售的鞋子数量。
如下图所示，第 7 行代表月份，B 列代表鞋子尺码。
表格表示频率分布。

1- 如果我们取鞋子尺码 6（第 8 行），他们计算出的置信区间在 [1.8-4.04] 之间。
据我所知，我知道置信区间仅在正态分布上计算。但我看不出鞋子尺码 6 的分布表如何形成正态分布？
我说得对吗？
我知道，如果样本分布不正常，我们可以使用 CLT，即具有正态分布的样本的平均值。是否可以将其应用于 6 号鞋子（第 8 行）？

2- 为什么要计算标准误差？我以为标准误差仅适用于均值样本（CLT），而第 8 行中的数据不是样本均值，而是正态分布。

此外，标准误差公式的分母代表样本均值的数量，但事实并非如此。
有人可以澄清一下歧义吗？
谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/658015/confidence-interval-clt-begginer-level</guid>
      <pubDate>Fri, 29 Nov 2024 02:32:37 GMT</pubDate>
    </item>
    <item>
      <title>一阶矩有限性的充分条件[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658007/sufficient-conditions-for-finiteness-of-first-moment</link>
      <description><![CDATA[考虑一个具有完全支持的随机变量 $X$，使得
$$
(1)\quad E(\exp(\beta X))&lt;\infty
$$
对于某个 $\beta&gt;0$。您能帮我证明这意味着
$$
(2)\quad E(|X|)&lt;\infty
$$
我不确定从哪里开始，而且我缺乏关于为什么这是正确的任何基本直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/658007/sufficient-conditions-for-finiteness-of-first-moment</guid>
      <pubDate>Thu, 28 Nov 2024 23:15:13 GMT</pubDate>
    </item>
    <item>
      <title>具有无限上限的置信区间</title>
      <link>https://stats.stackexchange.com/questions/657947/confidence-interval-with-an-infinity-upper-limit</link>
      <description><![CDATA[因此，我想尝试找到一个具有已知均值的未知分布的方差置信区间（n 非常大）。因此，我首先使用中心极限定理，使得均值为 $\mu$ 且方差为 $\sigma^2$ 的分布 X 具有
$\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}} \xrightarrow{D} N(0,1)$
现在，我们可以找到 1-$\alpha$ 置信区间，其中随机区间为：
$ \begin{align*}
Pr\left(-z_{\frac{\alpha}{2}}&lt;\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}}&lt;z_{\frac{\alpha}{2}}\right) &amp;= 1-\alpha \\
Pr\left(0&lt;\left|\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}}\right|&lt;z_{\frac{\alpha}{2}}\right) &amp;= 1-\alpha \\
Pr\left(0&lt;\left(\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}}\right)^2&lt;z_{\frac{\alpha}{2}}^2\right) &amp;= 1-\alpha \\
Pr\left(0&lt;\frac{(\bar{X}-\mu)^2}{\frac{\sigma^2}{n}}&lt;z_{\frac{\alpha}{2}}^2\right) &amp;= 1-\alpha \\
Pr\left(\frac{1}{z_{\frac{\alpha}{2}}^2}&lt;\frac{\frac{\sigma^2}{n}}{(\bar{X}-\mu)^2}&lt;\infty\right) &amp;= 1-\alpha \\
Pr\left(\frac{n(\bar{X}-\mu)^2}{z_{\frac{\alpha}{2}}^2}&lt;\sigma^2&lt;\infty\right) &amp;= 1-\alpha
\end{align*}$
因此，$\bar{x} = \frac{\sum_{i=1}^n x_i}{n}$，我们有一个 (1-$\alpha$) 置信区间，即 $\left(\frac{n(\bar{x}-\mu)^2}{z_{\frac{\alpha}{2}}^2}, \infty\right)$
这有什么问题吗？如果没有，我们可以为置信区间设置无限上限吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657947/confidence-interval-with-an-infinity-upper-limit</guid>
      <pubDate>Wed, 27 Nov 2024 17:13:58 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中拟合已知和未知非线性形状的模型</title>
      <link>https://stats.stackexchange.com/questions/657902/fitting-models-with-known-and-unknown-nonlinear-shapes-in-r</link>
      <description><![CDATA[我正尝试使用 mgcv 在 R 中拟合一个假设检验模型。
响应 Y 被假设为 x1 和 x2 的线性函数。这是一个空间数据集，其某些结构我先验不知道，因此我另外添加了一个纬度和经度的平滑项。
到目前为止，我们有这个模型，以 R / mgcv 语法表示：
Y ~ x1 + x2 + s(Latitude, Longitude, k = someK, bs = &quot;tp&quot;)

我必须向这个模型添加另外 2 个项。第一个是饱和曲线，具有 2 个参数，形式如下：
beta1 * ( (x3 ^ beta2) - 1) / beta2)

其中 beta1 和 beta2 是要估计的参数，x3 是数据向量。下一个是过度分散参数/观察级随机效应，用于吸收残差方差。再次以 mgcv 术语表示：
s(obs, bs=&quot;re&quot;)

首先，我使用 nimble 编写了一个模型，其中代表了所有这些组件。我提到这一点只是为了解释这不是未来的选择。该模型没有收敛（或者收敛速度极慢），我认为采样器在决定将方差归因于何处（空间平滑或过度分散参数）时会遇到一些困难，即使有信息丰富的先验。好吧，那只是一厢情愿。
接下来，我尝试用非线性曲线拟合模型，没有空间平滑，并且 brms 中有过度分散项；但是，该模型应该以某种方式考虑空间结构。我似乎无法使用 brms 在非线性模型中写入平滑项。以下是通过 bf 得到的非线性 brms 公式的结构：
bf(Y ~ b0 + b1*x1 + b2*x2 + b3*( (x3 ^ b4) - 1) / b4), 
b0 ~ (1|overdisp), b1 + b2 + b3 ~ 1, nl = TRUE)

其中 b0 是全局截距，其中针对此平均值周围的每个观测值估计了一个额外的过度分散参数。但同样，我现在缺少未知形式和复杂性的空间结构。我尝试使用 mgcv 进行 GAM：
bam(Y ~ x1 + x2 + x3 + s(Latitude, Longitude, k = someK, bs = &quot;tp&quot;) + 
s(overdisp, bs=&quot;re&quot;), data = dat, ...)

此模型运行，产生合理的输出，并解释 99% 的偏差。一切都很好——只是我似乎无法为 x3 包含具有 2 个参数的非线性项。是否有某种方法可以做到这一点，而我在 mgcv 的文档中遗漏了？或者也许有一种方法可以在非线性 brms 模型中表达 GAM 项？或者是否存在一些理论/统计原因，说明我不应该像以前那样进行建模？]]></description>
      <guid>https://stats.stackexchange.com/questions/657902/fitting-models-with-known-and-unknown-nonlinear-shapes-in-r</guid>
      <pubDate>Tue, 26 Nov 2024 06:01:50 GMT</pubDate>
    </item>
    </channel>
</rss>