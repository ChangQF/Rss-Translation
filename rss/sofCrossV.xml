<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 19 Sep 2024 21:15:23 GMT</lastBuildDate>
    <item>
      <title>分层回归模型的预测区间</title>
      <link>https://stats.stackexchange.com/questions/654619/prediction-intervals-with-hierarchical-regression-model</link>
      <description><![CDATA[我正在阅读Gelman 和 Hill 撰写的这本数据分析书，并试图理解使用分层模型的预测。在第 273 页，他们演示了如何对已经观察到的组和状态做出新的预测

更一般地说，我们可以在估计的参数 α、β 和 σ 中添加推理不确定性。

我试图理解如何做到这一点。举个例子：
我有一个这样的分层回归模型：
\begin{aligned} &amp; Y = b_{0_j} + b_1 x + \epsilon \\
&amp; b_0 = U + \eta_j \\
\end{aligned&gt;
我将模型拟合到 5 个不同的组 j1、j2、j3、j4 和 j5
我收到的结果参数是

U = 5
$\eta_j = [1, 2, -1, 4, -3]$
b_1 = 3
epsilon 呈正态分布，方差为 2.25
组间方差为 2.25

我想使用此模型对新观察进行预测。新的观察结果在第 5 组中，x 值为 4。我相信我会通过将值代入上述公式来计算点预测，即
\begin{aligned} &amp; b_{0_5} = 5 + (-3) = 2 \\
&amp; Y = 2 + 3(4) = 14 \\
\end{aligned&gt;
我的主要问题是，如何围绕这个估计值构建 95% 的置信区间？我想我可能会加/减 1.96 * std(e)，但这不能解释组间差异。另一方面，我认为完全添加组间变异似乎是错误的，因为组 j5 ($U + \eta_5$) 的截距已经远离平均截距 U。
此外，如果模型具有不同的截距和斜率，构建区间的方法是否相同？]]></description>
      <guid>https://stats.stackexchange.com/questions/654619/prediction-intervals-with-hierarchical-regression-model</guid>
      <pubDate>Thu, 19 Sep 2024 21:01:08 GMT</pubDate>
    </item>
    <item>
      <title>使用不相关特征进行 OLS 高估</title>
      <link>https://stats.stackexchange.com/questions/654617/overestimation-in-ols-using-uncorrelated-features</link>
      <description><![CDATA[我正在使用 OLS 构建最佳线性模型来解释（预测）$Y$的方差，使用两个特征 $X_1$ 和 $X_2$，并考虑以下两个因素：

$X_1$ 和 $X_2$ 不表现出多重共线性，即 $\rho(X_1, X_2) \approx 0 $
$X_1$ 和 $X_2$ 均解释方差的重叠部分在$Y$中，即
$\beta_1 X_1 + \beta_2 X_2$高估了$Y$ 
其中，$\beta_1$和$\beta_2$是两个独立线性回归的结果：$Y = \beta_1 X_1 + \epsilon$和$Y = \beta_2 X_2 + \epsilon$

最好的技术是什么用什么术语来解释#2 中的上述场景？以下是否是解决这种情况的最佳方法：
步骤 1：使用 OLS 估算 $\beta_1$ $Y = \beta_1 X_1 + \epsilon$ 
步骤 2：将误差估算为 $\hat{Y_1} = Y - \beta_1 X_1$ 
步骤 3：使用 OLS 估算 $\hat{Y_1} = \beta_2 X_2 + \epsilon$ 
考虑将其推广到 $n$ 特征 $X_1, X_2, ..., X_n$]]></description>
      <guid>https://stats.stackexchange.com/questions/654617/overestimation-in-ols-using-uncorrelated-features</guid>
      <pubDate>Thu, 19 Sep 2024 20:57:32 GMT</pubDate>
    </item>
    <item>
      <title>根据多个独立标准进行调节是否会增加共同因素的预期值？</title>
      <link>https://stats.stackexchange.com/questions/654614/does-conditioning-on-multiple-independent-criteria-increases-the-expected-value</link>
      <description><![CDATA[我正在努力解决经济学论文中的一些问题。
我有一个模型，其中 A∼N(0,1) 是工人的永久能力。ε1,ε2 ~ N(0,1) 是工人能力的“噪音”。A、ε1、ε2 是独立的。
在每个时期 (t)，如果 Ât = A+εt &gt; A*，工人就会从容易的工作晋升到困难的工作（只有两个工作）。在 t=1 时，所有工人都从事轻松的工作，这意味着：在 t=2 时，从事艰苦工作的工人是那些对他们来说：A+ε1 &gt; A*。这里出现了转折，公司可以将工人从艰苦的工作降级到轻松的工作：在 t=3 时，从事艰苦工作的工人只是那些对他们来说 (A+ε1&gt;A*)^(A+ε2&gt;A*) 的工人。看看同一批工人，我试图证明在 t=3 从事艰苦工作的工人的预期值大于在 t=3 从事艰苦工作的工人的预期值，因此：E[A|(A+ε1&gt;A*)^(A+ε2&gt;A*)] &gt; E[A|(A+ε1&gt;A*)]
这是真的吗？我遗漏了什么吗？尝试了很多次使用风险率来证明这一点，但结果却不是这样。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654614/does-conditioning-on-multiple-independent-criteria-increases-the-expected-value</guid>
      <pubDate>Thu, 19 Sep 2024 17:52:50 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中测试时间序列的平稳性（而不是单位根）</title>
      <link>https://stats.stackexchange.com/questions/654613/test-in-r-for-stationarity-not-for-unit-root-of-a-time-series</link>
      <description><![CDATA[我正在教授时间序列分析课程。我们讨论平稳性这一概念，然后我们的教科书解释了增强迪基富勒检验，该检验在 R 中由命令 adf.test() 执行。不幸的是，许多非平稳时间序列没有单位根，因此 ADF 检验将正确得出“无单位根”的结论，并让学生相信时间序列是平稳的。
上次我教授这门课程时，我使用了 kpss.test 作为替代方案，鼓励学生运行这两个测试，以检查给定时间序列可能不平稳的两种不同方式（以及绘制图表、查看可变性等）。不幸的是，许多非平稳时间序列都可以通过这两种测试，例如 AR(1) 过程 $x_t = - x_{t-1} + w_t$，其中 $w_t$ 是白噪声，或 AR(2) 过程 $x_t = -x_{t-2} + w_t$。
在网上搜索后，我了解到 Priestley-Subba Rao (PSR) 测试，该测试以前在 R 库 fractal 中可用，但现在已被弃用。
还有其他平稳性测试可以与我的学生分享，这些测试在 R 包中很容易获得吗？我不需要 Phillips–Perron pp.test，因为那只是另一个单位根测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/654613/test-in-r-for-stationarity-not-for-unit-root-of-a-time-series</guid>
      <pubDate>Thu, 19 Sep 2024 17:34:05 GMT</pubDate>
    </item>
    <item>
      <title>在原型分析和 PCA 的背景下，最小化误差与最大化方差之间的等价性</title>
      <link>https://stats.stackexchange.com/questions/654612/equivalence-between-minimizing-error-vs-maximizing-variance-in-the-context-of-a</link>
      <description><![CDATA[我试图填补 Cutler 和 Breiman 的论文原型分析中的推理空白。
本文的目的是识别数据矩阵$X$中的模式或原型$Z$，这些模式或原型最能描述底层数据。数据中的每个点$X_i$都近似为这些原型的组合。原型是通过最小化重建误差来找到的。
具体来说，我想证明最小化以下误差函数：
$$
E(\alpha, Z) = \sum_{i=1}^n \left\| x_i - Z \alpha_i \right\|^2
$$
其中：

$ X \in \mathbb{R}^{m \times n} $ 是数据矩阵
$ Z \in \mathbb{R}^{m \times p} $ 具有正交列 $ Z^\top Z = I_p$
$ \alpha \in \mathbb{R}^{n \times p}$ 是系数矩阵 $\alpha_i$ 是第 $i$ 行$\alpha $

相当于最大化：
$$
\sum \limits z_k^\top S z_k = \operatorname{tr}(Z^\top S Z)
$$
其中 $S = X^\top X$。
我目前的方法：
将 $Z$ 视为给定并从 Frobenius 范数开始，我们可以将误差函数 $ E(\alpha) $ 重写为：
$$
E(\alpha) = \left\| X - Z \alpha^\top \right\|_F^2 = \operatorname{tr} \left( (X - Z \alpha^\top)^\top (X - Z \alpha^\top) \right).
$$
扩展轨迹：
$$
E(\alpha) = \operatorname{tr}(X^\top X - X^\top Z \alpha^\top - \alpha Z^\top X + \alpha Z^\top Z \alpha^\top).
$$
由于 $ Z^\top Z = I_p $，因此简化为：
$$
E(\alpha) = \operatorname{tr}(X^\top X - 2 X^\top Z \alpha^\top + \alpha \alpha^\top)。
$$
接下来，我们对 $E(\alpha)$ 求导，相对于 $\alpha$：
$$
\frac{\partial E}{\partial \alpha} = -2 X^\top Z + 2 \alpha。
$$
将其设置为零：
$$
-2 X^\top Z + 2 \alpha = 0 \quad \Rightarrow \quad \alpha = X^\top Z。
$$
将 $\alpha = X^\top Z $ 代回 $ E(\alpha) $：
现在，将 $\alpha = X^\top Z $ 代入 $ E(\alpha) $ 的表达式中，我们得到：
$$
E(\alpha) = \operatorname{tr}(X^\top X - 2 X^\top Z (X^\top Z)^\top + (X^\top Z)(X^\top Z)^\top)。
$$
进一步简化：
$$
E(\alpha) = \operatorname{tr}(X^\top X - 2 X^\top Z Z^\top X + X^\top Z Z^\top X)。
$$
这简化为：
$$
E(\alpha) = \operatorname{tr}(X^\top X - X^\top Z Z^\top X) = \operatorname{tr}(X^\top X) - \operatorname{tr}( X^\top Z Z^\top X) = \operatorname{tr}(X^\top X) - \operatorname{tr}( Z^\top XX^\top Z),
$$
因为 $\operatorname{tr}(AB) = \operatorname{tr}(BA)$。
我的问题：
因为 $X X^\top \neq X^\top X$，所以我不确定如何从这里继续完成证明并显示最大化 $ \operatorname{tr}(Z^\top S Z) $ 的等价性，其中 $ S = X^\top X $。
有人可以指导我完成接下来的步骤吗？我如何关联这两个表达式并完成这个证明？]]></description>
      <guid>https://stats.stackexchange.com/questions/654612/equivalence-between-minimizing-error-vs-maximizing-variance-in-the-context-of-a</guid>
      <pubDate>Thu, 19 Sep 2024 17:07:22 GMT</pubDate>
    </item>
    <item>
      <title>Beta 帽条件方差 - Hansen 计量经济学</title>
      <link>https://stats.stackexchange.com/questions/654608/beta-hat-conditional-variance-hansen-econometrics</link>
      <description><![CDATA[我正在研究 Bruce Hansen 的计量经济学，我不知道如何找到第 90 页的条件方差证明。
Hansen 说：
对于任何 $n \times r$ 矩阵 $\mathbf{A} = \mathbf{A}(\mathbf{X})$：
$\text{var}(\mathbf{A}^T\mathbf{y}|\mathbf{X}) = \text{var}(\mathbf{A}^T\mathbf{e}|\mathbf{X}) = \mathbf{A}^T\mathbf{D}\mathbf{A}$，其中 $D=\text{diag}(\sigma_1^2, ..., \sigma^2_n)$。
为什么会这样？我可以看到这个步骤，但我不确定如何从完整定义中证明它：$\text{var}(\mathbf{A}^T\mathbf{e}|\mathbf{X}) = \mathbf{A}^T\text{var}(\mathbf{e}|\mathbf{X})\mathbf{A} = \mathbf{A}^T\mathbf{D}\mathbf{A}$.
即我该如何实现这个：$\text{var}(\mathbf{Z}|\mathbf{X}) = \mathbb{E}[(\mathbf{Z} - \mathbb{E}[\mathbf{Z}|\mathbf{X}])(\mathbf{Z} - \mathbb{E}[\mathbf{Z}|\mathbf{X}])^T|\mathbf{X}], \mathbf{\hat\beta} = \mathbf{A}^T\mathbf{y}, \mathbf{A} = \mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}$
我试过了，但得到的矩阵维度一直不匹配向上。]]></description>
      <guid>https://stats.stackexchange.com/questions/654608/beta-hat-conditional-variance-hansen-econometrics</guid>
      <pubDate>Thu, 19 Sep 2024 16:46:25 GMT</pubDate>
    </item>
    <item>
      <title>当每个数据点都带来一个置信区间时，如何在两个或多个组之间进行检验？</title>
      <link>https://stats.stackexchange.com/questions/654615/how-to-run-a-test-between-two-or-more-groups-when-each-data-point-brings-a-confi</link>
      <description><![CDATA[早上好，
我最近开始研究一个数据集，但作为一名应届毕业生，我的经验有限，这阻碍了我取得进展。在执行了项目所需的稀疏化之后，我现在有一个包含 24 个指标的数据框，每个指标都伴随着由随机稀疏化过程生成的置信区间。这 24 个指标属于 2 个不同的非独立组，我需要进行比较。如果没有置信区间，我只能使用均值，我会使用配对 t 检验。
为了解释通过稀疏化获得的置信区间，我尝试使用从区间得出的方差执行加权 t 检验。但是，我对我的方法没有信心，也找不到任何支持这种方法的在线文章。谢谢您的帮助。
这是我的数据框：
size1 &lt;- c(32.67256,30.59280,33.56214,30.15552,29.02073,24.92427,34.79967,34.26559,29.33457,25.75716,27.91638,33.87884)
size2 &lt;-c(34.18847,30.94369,37.38462,22.96785,27.98805,31.39834,30.26401,33.59788,36.19856,31.19667,21.27245,28.87137)
尺寸 &lt;-c(尺寸1,尺寸2)
尺寸1CI05 &lt;-c(29.50177,26.23491,29.60487,25.94388,24.48941,21.78924,29.24082,28.09738,25.20056,21.21051,24.40705,30.08490)
size2CI05 &lt;-c(29.51654,23.75201,31.29203,17.60071,21.92296,26.38236,23.69115,26.15880,26.44932,26.72620,17.48761,23.76434)
sizeCI05 &lt;-c(size1CI05,size2CI05)
size1CI95 &lt;-c(35.84336,34.95070,37.51941,34.36716,33.55205,28.05929,40.35851,40.43380,33.46857,30.30381,31.42571,37.67278) 
size2CI95 &lt;-c(38.86039,38.13538,43.47722,28.33500,34.05315,36.41432,36.83687,41.03696,45.94780,35.66713,25.05730,33.97840)
sizeCI95 &lt;-c(size1CI95,size2CI95)
group &lt;- c(c(rep(&quot;1&quot;,12),rep(&quot;2&quot;,12))
df &lt;-data.frame(size,sizeCI05,sizeCI95,group)

我还按要求添加了 dput 输出：
df &lt;-structure(list(size = c(32.67256, 30.5928, 33.56214, 30.15552, 
29.02073, 24.92427, 34.79967, 34.26559, 29.33457, 25.75716, 27.91638, 
33.87884, 34.18847, 30.94369, 37.38462, 22.96785, 27.98805, 31.39834, 
30.26401, 33.59788, 36.19856, 31.19667, 21.27245, 28.87137), 
size05CI = c(29.5017662019491, 26.2349058385758, 29.6048735822698, 
25.9438818737996, 24.4894140422372, 21.7892435074709, 29.2408246478003, 
28.097376313181, 25.2005633026381, 21.2105115402011, 24.4070457401779, 
30.0849045894848, 29.5165407340379, 23.7520071901393, 31.2920265619889, 
17.6007091843407, 21.9229562124319, 26.3823600157115, 23.6911524798744, 
26.158796800294, 26.4493176960902, 26.7262037524753, 17.4876088906701, 
23.7643440166671), size95CI = c(35.8433590913617, 34.9506991382152, 
    37.5194133001315、34.3671592174968、33.5520534941053、28.0592932279925、40.3585126169722、40.4338032764411、33.46857135214 04、30.303809204322、31.4257104335821、37.6727751129716、38.8603902871733、38.1353758799793、43.4772171945701、 28.3349990423006, 34.0531465846994, 36.4143170389483, 
36.8368654619253, 41.0369594182707, 45.9478039221974, 35.6671344715295, 
25.0572999101401, 33.9783955274194), group = c(&quot;1&quot;, &quot;1&quot;, 
&quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;2&quot;, &quot;2&quot;, 
&quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;)), class = &quot;data.frame&quot;, row.names = c(NA, 
-24L))

这是我尝试做的：
install.packages(&quot;weights&quot;,dependencies=T)
library(weights)
SE1 &lt;-(size1CI95-size1CI05)/3.919928
SE2 &lt;-(size2CI95-size2CI05)/3.919928
sizepaired &lt;-size1-size2
combSE &lt;-sqrt(SE1^2+SE2^2)
weights &lt;-1/combSE^2
wtd.t.test(x=sizepaired,y=0,weight=weights)

我的方法是使用加权检验来考虑由于检验中的稀疏性而产生的置信区间（即标准偏差），其中权重来自标准偏差。但是，我不确定这是否是一种有效的方法，而且我还没有找到任何涉及这种方法的科学文章。我的同事有些怀疑，不愿意使用“实验性”方法。
此外，我目前正在使用参数检验，但在我的数据中（我没有在这里包括），有些数据不遵循正态分布。因此，我应该考虑如何进行加权配对非参数检验]]></description>
      <guid>https://stats.stackexchange.com/questions/654615/how-to-run-a-test-between-two-or-more-groups-when-each-data-point-brings-a-confi</guid>
      <pubDate>Thu, 19 Sep 2024 16:36:06 GMT</pubDate>
    </item>
    <item>
      <title>CATE 预测是否需要介于 -1 和 1 之间？</title>
      <link>https://stats.stackexchange.com/questions/654606/do-cate-predictions-need-to-be-between-1-and-1</link>
      <description><![CDATA[我尝试对此进行一些研究，但尚未找到明确的答案。从高层次来看，CATE/ITE 预测将是接受治疗与未接受治疗之间的概率差异。直观地说，如果是这样的话，我认为我的预测需要在 -1 和 1 之间。
但是，我看到很多预测超出了这个范围。这是有道理的，因为其中很多来自回归，但这些是否需要以某种方式限制在 -1 和 1 之间。换句话说，如果我的预测值为 50，我是否只需要将其强制回到 1？值 &lt; -1 或 &gt; +1 是否有特殊解释？]]></description>
      <guid>https://stats.stackexchange.com/questions/654606/do-cate-predictions-need-to-be-between-1-and-1</guid>
      <pubDate>Thu, 19 Sep 2024 15:54:47 GMT</pubDate>
    </item>
    <item>
      <title>平方矩阵表达式中转置的顺序</title>
      <link>https://stats.stackexchange.com/questions/654605/order-of-the-transpose-in-squaring-matrix-expression</link>
      <description><![CDATA[我正在研究一些计量经济学，我只是好奇如何确定矩阵表达式平方的转置顺序。
例如，在求解 OLS 时，我们有 $\hat\beta = \underset{b}{\arg\min} \; \mathbb{E}[(y - \mathbf{x}^T\mathbf{\beta})^2]$，并且我们首先进行转置，即$(y - \mathbf{x}^T\mathbf{\beta})^2 = (y - \mathbf{x}^T\mathbf{\beta})^T(y - \mathbf{x}^T\mathbf{\beta}) \rightarrow y^2 - 2\beta\mathbf{x}y + \beta^T\mathbf{x}\mathbf{x}^T\beta$.
但后来，有了方差 $\hat\beta$，我们有：
$Var(\hat\beta|\mathbf{X}) = \mathbb{E}[(\hat\beta - \mathbb{E}[\hat\beta|\mathbf{X}])^2|\mathbf{X}] = \mathbb{E}[(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T \mathbf{e}\mathbf{e}^T\mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}|\mathbf{X}]$ (含 $\hat\beta - \mathbb{E}[\hat\beta|\mathbf{X}] = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{e}$)。
为什么在这种情况下我们使用$((\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{e})((\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{e})^T$，而不是先转置？
我知道先转置会给我们留下一个标量，而这给了我们一个矩阵，但这是一个不能令人满意的解释。选择一种能给出我们想要的维度的顺序似乎有些武断，而不是采用一种“正确”的程序来对它进行排序。我是不是忽略了矩阵的一个基本属性？]]></description>
      <guid>https://stats.stackexchange.com/questions/654605/order-of-the-transpose-in-squaring-matrix-expression</guid>
      <pubDate>Thu, 19 Sep 2024 15:50:17 GMT</pubDate>
    </item>
    <item>
      <title>转换变量时的测量尺度逻辑（名义、序数等）</title>
      <link>https://stats.stackexchange.com/questions/654604/logic-of-scales-of-measurement-nominal-ordinal-etc-when-transforming-variab</link>
      <description><![CDATA[经常讨论的测量尺度如下：

名义：无序的定性类别
序数：有序但值之间没有有意义的距离
间隔：值之间的有序和有意义的距离
比率：有序、有意义的距离和真正的零

当对原始变量进行转换时，我对测量尺度的逻辑感到好奇。
例如

收入（比率） -&gt; 自然对数 -&gt; 对数（收入）比率？没有真正的零，距离的值会发生变化
身高（比率） -&gt; 标准化为平均值为零且标准差为 1 -&gt; Z 分数高度（间隔？）零代表平均值。

我们是否将测量尺度的逻辑应用于转换后的变量，并在相关时重新分类？]]></description>
      <guid>https://stats.stackexchange.com/questions/654604/logic-of-scales-of-measurement-nominal-ordinal-etc-when-transforming-variab</guid>
      <pubDate>Thu, 19 Sep 2024 15:33:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么如果我将样本分为尾部和主体，子样本相关性会发生变化，即使整个样本分布是双变量高斯分布？</title>
      <link>https://stats.stackexchange.com/questions/654589/why-subsample-correlations-change-if-i-partition-the-sample-in-tails-and-body-ev</link>
      <description><![CDATA[我通过蒙特卡罗模拟生成了一个数据样本，其中底层分布是“双变量正态”，相关系数为 0.5，两个系列的平均值均为 0%，两个系列的标准差均为 20%。
随后，我根据第一个变量的值将数据集划分为三个子样本：左尾（第一四分位数）、右尾（第四四分位数）和分布主体（第二和第三四分位数）。
为什么这两个系列之间的相关系数在这三个子样本中会发生变化，为什么它与 0.5（数据从中划分出来的原始分布的值）不同？我想从数学和直观的角度来理解它。]]></description>
      <guid>https://stats.stackexchange.com/questions/654589/why-subsample-correlations-change-if-i-partition-the-sample-in-tails-and-body-ev</guid>
      <pubDate>Thu, 19 Sep 2024 08:44:29 GMT</pubDate>
    </item>
    <item>
      <title>关于离散时间生存分析的修改问题（固定间隔，固定效应时间）</title>
      <link>https://stats.stackexchange.com/questions/654562/a-modified-question-about-discrete-time-survival-analysis-with-fixed-intervals</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654562/a-modified-question-about-discrete-time-survival-analysis-with-fixed-intervals</guid>
      <pubDate>Wed, 18 Sep 2024 18:54:52 GMT</pubDate>
    </item>
    <item>
      <title>关于双变量分布的估计</title>
      <link>https://stats.stackexchange.com/questions/654493/on-estimation-of-bivariate-distribution</link>
      <description><![CDATA[我正在处理一个具有累积分布函数$F(x, y)$的非负、绝对连续的双变量随机向量，并且我正在尝试使用 Epanechnikov 核来估计$$\int_0^{t_1}F^2(x_1,t_2)dx_1$$。对此的估计定义为
$$\widehat{I}=\frac{1}{n^2h_1^2h_2^2}\int_0^{t_1}\left(\sum_{i=1}^n K\left(\frac{x_1-X_{1i}}{h_1}\right)K\left(\frac{t_2-X_{2i}}{h_2}\right)\right)^2dx_1$$
我在模拟中使用双变量Gumbel分布。下面是我的代码，但我很难为双变量数据选择合适的带宽，而且我得到的估计值与真实值有显著差异。
library(stats)
library(ks)
n &lt;- 40
lambda1 = 2
lambda2 = 0.5
theta = 0.5

for (i in 1:100) {
X1 &lt;- rexp(n, lambda1)
X2 = rgamma(n, (runif(n) &gt; 1 - theta/(1 + lambda1 * theta)) + 1, lambda2 * (1 + lambda1 * theta * X1))
sigma1 &lt;- sd(X1)
sigma2 &lt;- sd(X2)
h1 &lt;- 0.5
h2 &lt;- 0.55
t1 &lt;- 0.2
t2 &lt;- 0.3

epan_kernel_cdf &lt;- function(u) {
0.25 * (3 * u - u^3)
}

积分1 &lt;- sapply(X1, function(Xi) h1 * epan_kernel_cdf((t1 - Xi) / h1))
积分2 &lt;- sapply(X2, function(Yi) h2 * epan_kernel_cdf((t2 - Yi) / h2))

被积函数 &lt;- function(x1) {
kernel_cdf_values &lt;- sapply(X1, function(X1) epan_kernel_cdf((x1 - X1) / h1))
prod_kernel &lt;- kernel_cdf_values * 积分 2
sum_kernel &lt;- sum(prod_kernel)
(sum_kernel)^2
}

x_vals &lt;-seq(0,t1,length.out = 10000)
dx &lt;-x_vals[2]-x_vals[1]
sum_approx &lt;-sum(sapply(x_vals,integrand))*dx
estimated_value &lt;-(1/(n^2*h1^2*h2^2))*sum_approx
true_value &lt;-0.98

bias[i] &lt;-estimated_value[1]-true_value
MSE[i] &lt;-mean((estimated_value[1]-true_value[1])^2)
}

bias
MSE
bias1 &lt;-mean(bias)
bias1
MSE1 &lt;- 平均值 (MSE)
MSE1

我面临的一些具体问题：

为我的双变量数据选择合适的带宽。
我的估计值与真实值 (0.98) 相差甚远。

如果您能提供任何关于如何改进带宽选择或我应该在代码中进行的其他调整的见解或建议，我将不胜感激。提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654493/on-estimation-of-bivariate-distribution</guid>
      <pubDate>Tue, 17 Sep 2024 16:55:15 GMT</pubDate>
    </item>
    <item>
      <title>R 中混合效应模型 (lme) 的 III 型方差分析对比</title>
      <link>https://stats.stackexchange.com/questions/654447/contrasts-for-type-iii-anova-on-mixed-effects-model-lme-in-r</link>
      <description><![CDATA[我正在使用 R 中的 nlme 运行一系列混合效应模型。这是我的最终模型的示例：
M1.Final &lt;- lme(Response ~Treatment * Species, random = ~1|ID, 
data = data, method=&quot;REML&quot;)

我运行了初始 II 型方差分析来解释不平衡设计（每个处理的范围为 9-25 个样本），并得到了以下结果：
Anova(M1.Final, type = 2)

Chisq Df Pr(&gt;Chisq) 
Treatment 152.1071 4 &lt; 2.2e-16 ***
物种 1.9636 1 0.161130 
治疗：物种 15.2138 4 0.004278 ** 

由于治疗：物种相互作用显著，我认为 III 型方差分析比 II 型方差分析更合理。我知道要运行 III 型方差分析，您必须更改模型的对比度。我想检查并确保我做得正确。只在 ANOVA 命令中更改对比度可以吗，还是我需要在 lme 命令中更改它？即这是否正确：
type3 &lt;- list(Treatment = contr.sum, Species = contr.sum)

Final_Anova &lt;- Anova(M1.Final,contras = type3,type=3)
print(Final_Anova)

Chisq Df Pr(&gt;Chisq) 
(截距) 106.6099 1 &lt; 2.2e-16 ***
Treatment 151.0898 4 &lt; 2.2e-16 ***
物种 0.0406 1 0.840396 
治疗：物种 15.2138 4 0.004278 ** 


这是交互图：

更新：听起来你应该在 lme 中指定对比。我试过了，但得到了一个奇怪的输出，所以我不确定我做错了什么：
test &lt;- lme(Response ~Treatment * Species, random = ~1|ID, 
data = data, method=&quot;REML&quot;,contras = type3)
Anova(test, type = 3)

(Intercept) 1575.8 1 &lt; 2.2e-16 ***
Treatment 0 
Species 0 
Treatment:Species 0 


编辑：听起来，如果存在显著的相互作用，则 III 型不一定是必要的。如果能对如何在这种情况下选择 ANOVA 类型提供任何见解，我们将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654447/contrasts-for-type-iii-anova-on-mixed-effects-model-lme-in-r</guid>
      <pubDate>Mon, 16 Sep 2024 17:45:12 GMT</pubDate>
    </item>
    <item>
      <title>纵向数据和多层次建模的模型规范</title>
      <link>https://stats.stackexchange.com/questions/653787/model-specification-for-longitudinal-data-and-multilevel-modeling</link>
      <description><![CDATA[我们研究了教育内容的传递媒介（即增强现实与视频）对记忆（“binary_memory_score”）随时间（“时间”）的影响。我们有 20 次增强现实体验，每次体验指定三个记忆问题（每个多项选择题有四个无序分类选项；这里有一个示例问题/答案——“你看的戏剧表演中角色的妆容是什么颜色”/“红色”、“绿色”、“蓝色”、“黄色”）。视频是增强现实体验的屏幕录制。
我们有两种条件（增强现实与视频），我们分别随机招募（在受试者之间）。请注意，视频是增强现实体验的实际视频录制（1：1 关系）。参与者被要求参与教育内容并回答记忆问题。对于这两个组，参与者被招募到四个“群组”，代表不同的教育主题（例如群组 1 = 艺术，群组 2 = 科学），这意味着群组也是一个受试者间变量（尽管我们没有理由测试群组是否不同，因为它们仅与特定主题松散相关）。在每个群组中，所有群组参与者都经历了关于群组主题的五种特定体验（在群组 1 中，我们有体验 1、体验 2、体验 3、体验 4、体验 5；在群组 2 中，我们有体验 6、体验 7 等）。
我们认为 experience_question 应该嵌套在 experience 中，因为每个体验都有 3 个仅适用于它的单独问题 - 因此体验 A 有问题 1、2、3，体验 B 有问题 4、5、6。我们认为（参与者）id 应该嵌套在群组中，因为每个群组都有唯一的参与者。因此，群组 A 有参与者 1、2、3，群组 B 有参与者 4、5、6。
在完成每次体验后的初始记忆测试 (time_0) 之后，大约 25% 的参与者在 1 个月后 (gap1) 再次被问到问题 (time_later)；另外 25% 的参与者在 6 个月后 (gap6) 再次被问到问题。举个例子来说明这一点：如果我们在时间零点为给定群组 + 媒体招募了 1000 人，那么在 t1 时，我们会再次邀请随机选择的 500 人回答问题，但在约 250 人时停止招募。在 t2 时，我们邀请剩余的 500 人（之前未邀请）回答问题，并在 250 人时再次停止招募。因此，我们的保留率为 50%，因为在 1000 名初始招募者中，只有 500 人加入了后续研究。
因此，我们有一个受试者内的时间因素（time_0 vs time_later）和一个受试者间的差距因素（gap1 vs gap6）。我们目前将记忆作为二元变量（正确答案 vs 错误答案），作为各个记忆问题（“exp_question”）的“分数”。以下是我们提出的使用 glmer 的分析：
binary_memory_score ~ 1 + media*time*gap + (1 | experience / experience_question) + (1 + time | id) + (1 | cohort / id), family = binomial(&quot;logit&quot;), nAGQ=0, control=glmerControl(optimizer = &quot;nloptwrap&quot;), data=combined_data_cor_screened,contrasts = list(media = contr.sum, time=contr.sum, gap=contr.sum))

我们假设，与体验增强现实的人相比，观看视频（媒体）的人在记忆任务（binary_memory_score）中的表现会更差。我们还假设，与体验增强现实的人相比，观看视频的人的记忆分数会随着时间的推移而更快地延迟。我们计划通过 emmeans 包探索媒体 * 时间 * 间隙相互作用来检验这些假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/653787/model-specification-for-longitudinal-data-and-multilevel-modeling</guid>
      <pubDate>Tue, 03 Sep 2024 08:23:00 GMT</pubDate>
    </item>
    </channel>
</rss>