<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 07 Apr 2024 21:13:06 GMT</lastBuildDate>
    <item>
      <title>因果中介分析，治疗在结果阶段平滑，在中介阶段线性</title>
      <link>https://stats.stackexchange.com/questions/644523/causal-mediation-analysis-with-treatment-smoothed-in-the-outcome-stage-and-linea</link>
      <description><![CDATA[我正在考虑在 r 中进行如下所示的中介分析：
m_1 &lt;- gam(mediator1 ~age_cat + s(treat, k = 50, bs = &quot;cr&quot;) +
            cov1 + cov2 + cov3 + cov4 + 年份，数据 = mediation_df，
            方法=“REML”）

y_1 &lt;- gam(dem_important ~age_cat + mediator1 +
            s（治疗，k = 50，bs =“cr”）+ cov1 + cov2 + cov3 + cov4 +
            年，数据 = mediation_df，方法 =“REML”）

结果1 &lt;- 中介(m_1, y_1, sims = 1000, boot = TRUE,
            治疗=“治疗”，调解员=“调解员1”）



其中，m_1 是中介模型，y_1 是结果模型，mediator1 是连续变量，age_cat 是一个分类变量，treat 是一个用平滑建模的因子变量，cov1、cov2、cov3 、cov4 都是虚拟变量，year 是因子变量。
我现在正在考虑中介模型不同的模型规范：
m_2 &lt;- lm(mediator1 ~age_cat + treat +
            cov1 + cov2 + cov3 + cov4 + 年份，数据 = mediation_df，
            方法=“REML”）

y_2 &lt;- gam(dem_important ~age_cat + mediator1 +
            s（治疗，k = 50，bs =“cr”）+ cov1 + cov2 + cov3 + cov4 +
            年，数据 = mediation_df，方法 =“REML”）

结果2 &lt;- 中介(m_2, y_2, sims = 1000, boot = TRUE,
            治疗=“治疗”，调解员=“调解员1”）


在此模型设置中，出于中介目的，我没有对治疗变量进行平滑处理，因为我不假设因子变量 treat 对中介变量具有平滑效果。
我想知道这个模型规范是否有意义。我见过一些调解案例，其中调解模型是线性的，结果模型是 GAM (今井等人）。然而，我还没有看到治疗变量本身是两个模型设置之间采用不同形式的变量的设置。
是否有研究做到了这一点？这种方法到底合法吗？必须做出什么样的假设才能建立这样的因果中介分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/644523/causal-mediation-analysis-with-treatment-smoothed-in-the-outcome-stage-and-linea</guid>
      <pubDate>Sun, 07 Apr 2024 20:09:23 GMT</pubDate>
    </item>
    <item>
      <title>校正自相关后，回归量在统计上变得微不足道</title>
      <link>https://stats.stackexchange.com/questions/644521/regressors-became-statistically-insignificant-upon-correcting-for-autocorrelatio</link>
      <description><![CDATA[我正在使用 Stata 并使用回归命令并收到指示回归量具有统计显着性的 p 值。
但是，在绘制残差后，我注意到存在明显的自相关（这已通过 Breusch-Godfrey 测试证实），然后我使用 prais ..., corc 命令来纠正它，但得到的结果是现在我的回归量是统计的微不足道。
这是什么意思？我的回归没用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644521/regressors-became-statistically-insignificant-upon-correcting-for-autocorrelatio</guid>
      <pubDate>Sun, 07 Apr 2024 19:02:04 GMT</pubDate>
    </item>
    <item>
      <title>附加到原始样本的子样本的样本平均值</title>
      <link>https://stats.stackexchange.com/questions/644517/sample-mean-of-subsample-appended-to-original-sample</link>
      <description><![CDATA[从 $SRSWOR(n)$ 中提取 $N$ 个单位，一个 $SRSWOR(n_1)$ 子样本已抽取
并添加到原始样本中。显示基于 $(n + n_1)$ 单位的样本平均值
是总体均值的无偏估计量。获取估计量的方差。
将此与基于开始时绘制的 $n$ 单位的估计器进行比较。
任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/644517/sample-mean-of-subsample-appended-to-original-sample</guid>
      <pubDate>Sun, 07 Apr 2024 17:57:16 GMT</pubDate>
    </item>
    <item>
      <title>2x2 研究意味着有 4 个组还是 2 个组？</title>
      <link>https://stats.stackexchange.com/questions/644516/does-a-2x2-study-mean-there-are-4-groups-or-2</link>
      <description><![CDATA[我的书房是 2x2 设计。
有 2 个 IV：
IV1 = 性别（男/女）；
IV2 = 对照组/实验组。
这是否意味着我有 2 个组，因此将使用独立的 T 检验，或者我有 4 个组，因此将使用单向独立方差分析？或者，因为有多个 IV，这是否会导致阶乘独立测量方差分析？
非常感谢任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/644516/does-a-2x2-study-mean-there-are-4-groups-or-2</guid>
      <pubDate>Sun, 07 Apr 2024 17:44:48 GMT</pubDate>
    </item>
    <item>
      <title>相关后验的 MCMC</title>
      <link>https://stats.stackexchange.com/questions/644515/mcmc-for-correlated-posterior</link>
      <description><![CDATA[我正在使用 MCMC（DREAM 算法）模拟（看起来）高度相关的后验分布的后验。
我的设置是有 7 个参数，其中 x1/x3 和 x2/x4 高度相关，这是物理逻辑的。
但是，在运行过程中，x3 或 x4 会向下边界推动，即向零推动。但是，我不能允许负值，因为这在物理上是不可能的，并且评估会失败。所以，我认为问题是算法性质的。
附上参数散点图。在这里，x4 总是推到不切实际的低值。
谁能给我一个提示，如何防止 MCMC 算法的这种行为？
重新参数化是一种选择吗？如何做到这一点？
非常感谢！

]]></description>
      <guid>https://stats.stackexchange.com/questions/644515/mcmc-for-correlated-posterior</guid>
      <pubDate>Sun, 07 Apr 2024 17:42:45 GMT</pubDate>
    </item>
    <item>
      <title>Casella 和 Berger 中估计量的方差</title>
      <link>https://stats.stackexchange.com/questions/644513/variance-of-estimator-in-casella-and-berger</link>
      <description><![CDATA[嗨，我正在尝试阅读卡塞拉和伯杰的作品。
在第 345 页的示例 7.3.21 中，他们考虑分布族 Uniform($\theta$, $\ theta +1$）并提出基于单个观察的 theta 估计量。他们声称很容易看出估计器 $X - \frac12 + \sin(2\pi X) / (2\pi)$ 的方差为 0.71 (重点是，这小于明显估计量的方差 $X- \frac12$)。
但是，当我进行计算时，我似乎无法得到这一点。
\begin{align}
Var_\theta(X - \frac12 + \sin(2\pi X) / (2\pi))
&amp;= \int_\theta^{\theta+1} (x - \frac12 + \sin(2\pi x) / (2\pi) -\theta)^2 dx \\
&amp;= (3 + 2 π^2 - 12 \cos(2 π \theta))/(24 π^2) \\
&amp;\大约 0.0959985 - 0.0506606 \cos(2\pi \theta)
\end{对齐}
我错过了一些非常简单的事情吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644513/variance-of-estimator-in-casella-and-berger</guid>
      <pubDate>Sun, 07 Apr 2024 17:25:01 GMT</pubDate>
    </item>
    <item>
      <title>因变量应接受多小的变异系数？它如何影响线性回归？</title>
      <link>https://stats.stackexchange.com/questions/644510/how-small-coefficient-of-variation-should-be-accepted-for-dependent-variable-and</link>
      <description><![CDATA[我想知道如果 $Y$ 变量的变异系数很小，线性回归模型会发生什么。另外，什么被认为是“简历太小”？最低接受阈值是多少？
更具体的上下文：我正在尝试对时间序列数据建立线性回归以用于学习目的。与天气相关的 10 个数值变量有 499 个测量值 (来源）。下面附有图表和数字摘要。
数字汇总表

所用时间序列图
标准化，即$\frac{X-mean(X)}{sd(X)}$
]]></description>
      <guid>https://stats.stackexchange.com/questions/644510/how-small-coefficient-of-variation-should-be-accepted-for-dependent-variable-and</guid>
      <pubDate>Sun, 07 Apr 2024 16:39:39 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯观点中的“数据是固定的”和频率论观点中的“数据是随机的”在数学上谈论的是同一件事吗？</title>
      <link>https://stats.stackexchange.com/questions/644489/are-data-are-fixed-in-bayesian-viewpoint-and-data-are-random-in-frequentist</link>
      <description><![CDATA[在我看来，在贝叶斯推理和频率推理中，观测数据$x$被建模为随机变量的观测值$X$ 遵循一定的概率分布。因此，当我遇到这两个语句时 - “数据已固定”从贝叶斯观点来看，“数据是随机的”。从频率论的角度来看，我发现它们很难理解，因为它似乎表明对数据概念的解释存在差异。
读了一些资料后，似乎“数据是固定的”是指观察到的数据$x$是固定的，“数据是随机的”是指随机变量&lt; span class=&quot;math-container&quot;&gt;$X$ 是随机的。这两个陈述中的“数据”所指的并不是同一件事。不确定我的解释是否正确。欢迎您的建议。如果我的解释是正确的，那么这两个陈述是否多余/令人困惑？]]></description>
      <guid>https://stats.stackexchange.com/questions/644489/are-data-are-fixed-in-bayesian-viewpoint-and-data-are-random-in-frequentist</guid>
      <pubDate>Sun, 07 Apr 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>降维和预先计算的距离矩阵</title>
      <link>https://stats.stackexchange.com/questions/644469/dimensionality-reduction-and-precomputed-distance-matrix</link>
      <description><![CDATA[我有一个关于降维的问题。我想了解 MDS 和 t-SNE 等方法是如何工作的。特别是，我想了解预先计算距离矩阵与不预先计算距离矩阵时的差异。
为了尝试理解它，我从 MNIST 数据集中获取了 10 张图像，并为每张图像创建了 10 个副本，并将它们全部放在一个文件夹中（总共 100 张图像）。然后我使用所有这些图像之间的修改豪斯多夫距离创建了一个距离矩阵。最后，我使用 sklearn.manifold 中提供的 TSNE 和 MDS 函数将它们投影到 2D 空间中。我运行了这两个函数两次，一次使用指定的预先计算的距离矩阵 (metric=&#39;precompulated&#39;)，一次使用默认值。
所以，我有 10 张图像，每张图像重复 10 次。我期望在 t-SNE 和 MDS 空间中看到由 10 个点（每个图像重复 10 次）组成的 10 个点（每个不同的 MNIST 图像一个）彼此重叠，因为距离是重复的。只有当我没有将指标指定为“预先计算”时，我才会看到这一点，而在我看到分散的其他情况下，我不会看到这一点。
为什么会发生这种情况？不知道有没有文章讲这个。如果您能帮助我解决这个问题，我将非常感激。
编辑：
抱歉缺少信息，我对此类帖子很菜鸟：C
这是 100 张图像之间的距离矩阵的热图：

正如您所看到的，由于图像的重复，它的尺寸为 100x100，并且具有 10 个完全相同值的清晰块。
我使用名为 distance_matrix 的矩阵来计算 t-SNE 和 MDS 的降维。以下是 t-SNE 案例的代码，适用于预计算指标和默认指标：
# t-SNE 参数
随机状态 = 10
n_iter = 50000
困惑度 = 4
早期夸张 = 1

# 对数据应用 t-SNE 进行降维

# tsne = TSNE(n_components=2, random_state=random_state, n_iter = n_iter, perplexity = perplexity, Early_exaggeration=early_exaggeration)

tsne = TSNE(n_components=2, random_state=random_state, n_iter = n_iter, perplexity = perplexity, Early_exaggeration=early_exaggeration, metric=&#39;预计算&#39;, init=&#39;随机&#39;)


X_tsne = tsne.fit_transform(distance_matrix)

图, ax1 = plt.subplots(1, 1, Figsize=(13,5))
cmap = plt.get_cmap(&#39;tab10&#39;)

# 散点图，颜色代表时间进展

sc = ax1.scatter(X_tsne[:,0]，X_tsne[:,1]，marker=&#39;.&#39;，s=50，c=np.arange(len(X_tsne))，edgecolors=&#39;黑色&#39;，线宽= 0.2, cmap=&#39;彩虹&#39;)

ax1.set_xlabel(&#39;t-SNE 暗淡 1&#39;)
ax1.set_ylabel(&#39;t-SNE 暗淡 2&#39;)
Fig.colorbar(sc, label=&#39;时间进程&#39;)

# 显示图
plt.tight_layout()
plt.show()

这给出了以下输出：

对于预先计算：

默认情况下：


如您所见，两个结果相似但不相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/644469/dimensionality-reduction-and-precomputed-distance-matrix</guid>
      <pubDate>Sat, 06 Apr 2024 20:30:17 GMT</pubDate>
    </item>
    <item>
      <title>三个连续变量 + 2 个因素与五个连续变量来控制混杂因素？</title>
      <link>https://stats.stackexchange.com/questions/644438/three-continous-variables-2-factors-vs-five-continous-variables-to-control-fo</link>
      <description><![CDATA[我正在尝试理解我的硕士论文的设计。
我正在研究三种不同类型的游戏与儿童焦虑的关系。因此，我有三个连续的自变量，以每种类型花费的时间来衡量，而且我还有两个可能对焦虑产生影响的潜在混杂因素，我想解释它们也是连续的（量表上的分数）。
什么是最好的设计来解释我感兴趣的三个自变量的个体影响，同时平衡两个混杂因素的影响？运行多元回归来显示五个自变量中每一个的单独贡献是否会有帮助？或者，我也许可以对两个混杂变量进行分层，并将所有参与者分配到两个因素的不同级别，这样我的设计将有两个因素和三个连续变量可供查看，这似乎过于复杂。请在这里就可能的方法提出建议。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644438/three-continous-variables-2-factors-vs-five-continous-variables-to-control-fo</guid>
      <pubDate>Sat, 06 Apr 2024 11:24:21 GMT</pubDate>
    </item>
    <item>
      <title>Wishart 过程的限制分布</title>
      <link>https://stats.stackexchange.com/questions/644404/limiting-distribution-of-the-wishart-process</link>
      <description><![CDATA[考虑 Wishart 流程：
$$
dS_t = \sqrt{S_t} \, dB_t Q + Q^\top \, dB^\top_t \sqrt{S_t} + (S_t K + K^\top S_t + \Omega \Omega^\top) \, dt
$$
或者受限版本，其中 $\Omega = \sqrt{\alpha} Q^\top$
根据https://arxiv.org/pdf/1201.3256.pdf，其中使用受限版本，如果 $\alpha \ge p+1$ 其中 $p$ 是维度的 $S_t$，则该过程有唯一的解决方案，并且 $S_t$ 是所有 $t$。它还声称极限分布是非中心 Wishart 分布。
https://link.springer.com/article/10.1007 /s10287-021-00388-7 给我们极限分布的平均值，$S_{\infty}$ 满足西尔维斯特方程：
$$-\Omega \Omega^\top = K^\top S_{\infty} + S_{\infty} K$$
（它使漂移项为 0，因此这似乎是合理的）。
是否有类似简单的方法将该限制分布的参数与过程的参数联系起来？]]></description>
      <guid>https://stats.stackexchange.com/questions/644404/limiting-distribution-of-the-wishart-process</guid>
      <pubDate>Fri, 05 Apr 2024 16:00:09 GMT</pubDate>
    </item>
    <item>
      <title>将相关系数与同一对象的两次重复相关测量之间的平均绝对差异联系起来？</title>
      <link>https://stats.stackexchange.com/questions/643905/relating-the-correlation-coefficient-to-average-absolute-differences-between-two</link>
      <description><![CDATA[我有时必须在研究计划期间进行样本量计算。对于其中一些计算，需要相关系数作为输入。根据我的经验，相关专家发现将他们的经验转化为相关性的现实值非常棘手。这就是为什么我对其他方法感兴趣，通过将其重新表达为平均绝对差来得出相关性。
具体来说，假设使用同一仪器对 $n$ 个受试者进行了两次测量。据推测，同一对象的两个测量值是相关的，例如相关系数 $\rho$。有关两个时间点的均值和方差的信息均可用。
举个例子：假设在某些干预之前和之后测量收缩压。干预前均值和方差分别为 $130$ mmHg 和 $169$ mmHg$^2$。干预后均值和方差分别为 $118$ mmHg 和 $169$ mmHg$^2$。我们假设测量前和测量后之间的相关性为 $0.65$。
问题：如何（如果有的话）将相关系数表示为同一受试者的两次测量值之间的平均绝对差？
这有点类似于基尼平均差，它是两次测量之间的平均距离两个随机抽取的观察值。]]></description>
      <guid>https://stats.stackexchange.com/questions/643905/relating-the-correlation-coefficient-to-average-absolute-differences-between-two</guid>
      <pubDate>Sat, 30 Mar 2024 14:13:53 GMT</pubDate>
    </item>
    <item>
      <title>硬币翻转游戏：HH 与 HT 的一系列翻转</title>
      <link>https://stats.stackexchange.com/questions/643092/coin-flip-game-hh-vs-ht-in-a-sequence-of-flips</link>
      <description><![CDATA[一个涉及翻转公平的有趣思想实验正在X/Twitter：
&lt;块引用&gt;
抛一枚均匀的硬币 100 次——得到一系列正面 (H) 和反面的序列
（T）。对于翻转序列中的每个 HH，Alice 都会得到一分；为了
每个 HT，Bob 都会这样做，所以例如对于序列 THHHT Alice 得到 2 分
鲍勃得 1 分。谁最有可能获胜？

答案是鲍勃更有可能获胜，这似乎违反直觉。我当然可以暴力破解这个问题来证明“鲍勃”是正确的答案——它似乎确实与鲍勃的方差比爱丽丝更低有关。但我很难理解为什么差异会有所不同。
库(dplyr)

sim.flip = 函数(X){
s2 = 样本(x = c(0,1),大小 = X,替换 = T) %&gt;% as.character() %&gt;% as.matrix()

s3 = s2 %&gt;% 矩阵(ncol = 2,byrow = T)
s4 = s2[-c(1,X)] %&gt;% 矩阵(ncol = 2,byrow = T)

s5=应用(s3,1,函数(X){粘贴(X,崩溃=“”,sep=“”)})
s6=应用(s4,1,函数(X){粘贴(X,崩溃=“”,sep=“”)})

A = 长度(grep(x = s5,模式 = “00”) )+
长度（grep（x = s6，模式=“00”））

B = 长度(grep(x = s5,模式 = “01”))+
长度（grep（x = s6，模式=“01”））

返回(数据.frame(A=A,B=B))
}

设置.种子(12345)
sims = sapply(c(1:10000),function(X){sim.flip(X=100)}) %&gt;% unlist() %&gt;% 矩阵(ncol = 2,byrow = T) %&gt;; % as.data.frame()
colnames(sims) = c(“爱丽丝”,“鲍勃”)

sims$winner = ifelse(sims$Alice &gt; sims$Bob,yes = &quot;Alice&quot;,&quot;Bob&quot;)
sims$获胜者[sims$Alice == sims$Bob] = “平局”

表（模拟$获胜者）

爱丽丝·鲍勃·蒂
 4626 4791 583

# 期望值相同
平均值（sims$Alice）
[1]24.7837
意思是（sims$鲍勃）
[1]24.7572

# 方差不同
var(sims$Alice)
[1] 30.36575
var(sims$鲍勃)
[1]6.229471
]]></description>
      <guid>https://stats.stackexchange.com/questions/643092/coin-flip-game-hh-vs-ht-in-a-sequence-of-flips</guid>
      <pubDate>Wed, 20 Mar 2024 17:15:24 GMT</pubDate>
    </item>
    <item>
      <title>不同的Joinpoint/Segmented回归结果和Durbin-Watson测试</title>
      <link>https://stats.stackexchange.com/questions/635138/different-joinpoint-segmented-regression-results-and-durbin-watson-test</link>
      <description><![CDATA[我使用了Joinpoint趋势软件（https://surveillance.cancer.gov/joinpoint/) 并发现了我的数据中有趣的结果，这确实引起了我的兴趣。
我从 2001 年到 2021 年的死亡率如下：

&lt;标题&gt;

年
人口
死亡
Crude_Death_Rate_100k


&lt;正文&gt;

2001
172402407
86228
50.02


2002
174652142
87190
49.92


2003
176890584
88838
50.22


2004
181586609
90758
49.98


2005
184948540
89878
48.60


2006
187018382
96471
51.58


2007
188994445
96705
51.17


2008
190965853
98871
51.77


2009
192935881
99139
51.38


2010
194845069
99647
51.14


2011
196557572
100648
51.21


2012
198268222
100103
50.49


2013
199956927
99954
49.99


2014
201669726
99190
49.18


2015
203427301
100436
49.37


2016
205107655
102886
50.16


2017
206755270
101132
48.91


2018
208444882
99835
47.90


2019
210096571
101000
48.07


2020
211704612
98749
46.64


2021
213266044
102980
48.29



通过连接点回归软件，我得到了根据数据估计的标准误差，因此：
测试 1）使用不相关错误选项应用它，我得到 1 个连接点作为最佳模型（具有 1 个显着趋势）。
测试 2) 此后，我使用从数据估计的一阶自相关进行测试，得到负自相关参数和 1 个连接点作为最佳模型（有 2 个显着趋势）。
测试 3) 最后，我使用 car::durbinWatsonTest() 函数通过 Durbin-Watson 测试测试了上述系列，结果是：

&lt;标题&gt;

滞后
自相关
D-W 统计
p 值


&lt;正文&gt;

1
0.5390758
0.8688534
0.002



换句话说，正自相关约为 0.54。应用到Joinpoint软件后，我得到了0个连接点的最佳模型，根本没有任何意义（请参阅上传的图像以更好地理解）。 
我的疑问是这个时间序列应该使用哪个模型？这些方法中哪一种是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/635138/different-joinpoint-segmented-regression-results-and-durbin-watson-test</guid>
      <pubDate>Sun, 17 Dec 2023 20:35:27 GMT</pubDate>
    </item>
    <item>
      <title>两种实验条件的合理设计和不完全封闭</title>
      <link>https://stats.stackexchange.com/questions/634879/appropriate-design-for-two-experimental-conditions-and-incomplete-blocking</link>
      <description><![CDATA[我计划进行一项实验，其中我将评估两个实验变量（A：6 个水平，B：4 个水平）对既定结果的作用，但是，该结果可能会受到我所考虑的外部因素的影响。将能够在定义的块中进行控制。
考虑到一些实验限制，我将无法评估块内的所有 A x B 组合，而必须采用仅具有大约 4-6 个组合的不完整块设计。
查看一些在线指南（例如，https： //people.math.ethz.ch/~meier/teaching/anova/incomplete-block-designs.html）我发现他们主要处理单个实验变量，但事实并非如此（即使我考虑一下我将有 28 个级别的组合），所以我不知道处理这个问题的最佳方法是什么（既涉及规划又涉及数据分析）。
面对这个问题更合理的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/634879/appropriate-design-for-two-experimental-conditions-and-incomplete-blocking</guid>
      <pubDate>Thu, 14 Dec 2023 09:04:15 GMT</pubDate>
    </item>
    </channel>
</rss>