<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 04 Apr 2024 03:17:06 GMT</lastBuildDate>
    <item>
      <title>例如，$E(\epsilon|z,\eta)=E(\epsilon|\eta)$ 和 $E(\epsilon)=0$ 并不意味着 $E(\epsilon|z)=0$。= 0 美元？</title>
      <link>https://stats.stackexchange.com/questions/644265/how-to-come-up-with-an-example-that-e-epsilonz-eta-e-epsilon-eta-and-e</link>
      <description><![CDATA[我试图举一个例子来显示 $E(\epsilon|z,\eta)=E(\epsilon|\eta)$和 $E(\epsilon)=0$ 并不意味着 $E(\epsilon|z)=0$跨度&gt;。该模型是非参数 IV 模型，具有结构方程 $y=m(x,z_1)+\epsilon$ 和简化形式 $x=\pi(z)+\eta$，假设 $E(\epsilon|z)=0$。
请注意，要使 $E(\epsilon|z,\eta)=E(\epsilon|\eta)$ 成立，充分条件是 &lt; span class=&quot;math-container&quot;&gt;$(\epsilon,\eta)$ 和 $z$ 是独立的。
如何构建示例？]]></description>
      <guid>https://stats.stackexchange.com/questions/644265/how-to-come-up-with-an-example-that-e-epsilonz-eta-e-epsilon-eta-and-e</guid>
      <pubDate>Thu, 04 Apr 2024 02:08:08 GMT</pubDate>
    </item>
    <item>
      <title>GAMLSS模型中估计标准差的表达</title>
      <link>https://stats.stackexchange.com/questions/644257/expression-of-estimated-standart-deviation-in-gamlss-model</link>
      <description><![CDATA[我正在尝试复制 Giamperro Marra 和 Rosalba Radice 所著的论文《A Bivariate Copula Additive Model for Location, Scale and Shape》中北卡罗来纳州出生数据分析的结果 (https://arxiv.org/abs/1605.07521)。他们在论文的补充材料中提供了代码，但我不知道这个标准差的表达来自哪里
polys.map(NC.polys, sqrt(pi^2*sigma21/3), rev.col = FALSE,
main = 表达式(paste(hat(sigma),“bwgram”)),
方案 =“拓扑”，cex.main = 1.7)

$$\hat{\sigma} = \sqrt{\pi^2 \sigma^2_1/3}$$
那个 sigma hat 是根据 GAMLSS 估计的参数。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/644257/expression-of-estimated-standart-deviation-in-gamlss-model</guid>
      <pubDate>Thu, 04 Apr 2024 00:27:24 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证背景下排列特征的重要性</title>
      <link>https://stats.stackexchange.com/questions/644256/permutation-feature-importance-in-the-context-of-cross-validation</link>
      <description><![CDATA[我正在考虑两种方法来计算 交叉验证分割期间排列特征重要性。
方法 1：计算所有 CV 分割和洗牌的所有分数的平均值、标准差 (std) 和标准误差 (se)：
给定：

$X_{i,j,k}$ = 特征 $i$ 的重要性得分随机播放 CV 拆分 $k$ 的 $j$。
$N$ = CV 分割数
$M$ = 每次拆分的随机播放次数 $\forall$ $i, k$

首先，使用来自每次洗牌和每个 CV 分割的所有分数计算每个特征的重要性分数：
$Mean_i = (\sum_{k=1}^{N} {\sum_{j=1}^{M} {X_{i,j,k}} }) / (M*N)$
然后计算标准差(std)和标准误差(se)：
$Std_i = \sqrt{\sum_{k=1}^{N} {\sum_{j=1}^{M} ({{X_{i,j ,k}} - Mean_i)^2}} / (M*N) - 1)}$
$Se_i = Std_i / \sqrt{(M*N)}$
方法 2：计算每个 CV 分割和随机播放的总分的平均值、标准差和 se：
首先，计算每个 CV 分割中每个特征的总重要性得分（或平均重要性得分）：
$Y_{i,k} = \sum_{j=1}^{M} X_{i,j,k}$
$Mean_{i} = (\sum_{k=1}^{N} Y_{i,k}) / N$
然后计算标准差和标准误差：
$Std_i = \sqrt{\sum_{k=1}^{N} {(Y_{i, k} - Mean_i)^2} / (N - 1) }$
$Se_i = Std_i / \sqrt{N}$
此 $Std_i$ 和 $Se_i$ 捕获不同 CV 分割之间特征重要性的变化但没有完全捕获每个 CV split 中各个洗牌之间的变异性。
这两种方法对特征重要性 mean、std 和 se 的解释有何不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/644256/permutation-feature-importance-in-the-context-of-cross-validation</guid>
      <pubDate>Thu, 04 Apr 2024 00:25:34 GMT</pubDate>
    </item>
    <item>
      <title>对时间序列上的模型预测误差进行插值</title>
      <link>https://stats.stackexchange.com/questions/644251/interpolation-of-errors-from-model-predictions-over-time-series</link>
      <description><![CDATA[我有一个回归模型：
# 创建数据集####
# 模拟指数关系
设置.种子(123)
# 生成 0 到 60 之间的随机 x 值
x &lt;- runif(400, 0, 60)
y &lt;- 1 - exp(-0.1 * x) * rnorm(400, 0.7, 0.1)

数据 = data.frame(sr= x, fipar = y)

# 拟合 GLM 模型 #
glm_mod &lt;- glm(fipar ~ log(sr), data = data, family = 二项式)

假设我想根据一段时间内收集的新数据来预测该模型：
&lt;前&gt;&lt;代码&gt;
newdat &lt;- data.frame(sample = c(rep(&#39;A&#39;,3),rep(&#39;B&#39;,3),rep(&#39;C&#39;,3)),
                     sr = c(1,20,55,4,11,12,2,45,20),
                     时间点 = c(1,2,3,1,2,3,1,2,3))

newpreds &lt;- 预测(glm_mod,
                    新数据=新数据，
                    类型=“响应”，se.fit=T）

newdat$predicted_fipar &lt;- newpreds$适合
newdat$predicted_fipar_se &lt;- newpreds$se.fit


从这个模型中，我得到标准误差，并可以在做出预测的时间点绘制误差条，即
newdat %&gt;%
  ggplot(aes(x=时间点,y=predicted_fipar,group=样本)) +
  geom_point(aes(颜色=样本)) +
  几何线（）+
  geom_errorbar(aes(ymin=predicted_fipar-predicted_fipar_se,
                    ymax=预测的fipar+预测的fipar_se，
                    颜色=样本），
                宽度=0.1）


但是假设我想知道时间点 1.5 的错误。如果点之间的插值是线性的，我认为也可以线性地插值误差（不确定这是否忽略了任何统计规则），即：
newdat %&gt;%
  ggplot(aes(x=时间点,y=predicted_fipar,group=样本)) +
  geom_point(aes(颜色=样本)) +
  几何线（）+
  geom_ribbon(aes(ymin=predicted_fipar-predicted_fipar_se,
                    ymax=预测的fipar+预测的fipar_se，
                    填充=样本），
                阿尔法 = 0.4) +
  主题（图例.position = &#39;无&#39;）


但是如果预测点之间的插值是非线性的怎么办？还有其他方法允许这样做吗？我想我应该首先随着时间的推移对自变量进行插值（在本例中为 sr），然后使用插值从模型中进行预测。这样我就可以计算中间点的误差，即：
# 对每个样本随时间插值 SR #
interpolated_sr &lt;-
  plyr::rbind.fill(
  lapply（唯一（newdat $样本），函数（samp）{
    采样数据 &lt;- 新数据 %&gt;%
      过滤器（样本==样本）
    
    sr_loess &lt;- loess(sr ~ 时间点，数据 = Sampledat)
    
    topred &lt;- data.frame(样本 = samp,
                         时间点 = seq(1,3,0.1))
    topred$sr &lt;- 预测(sr_loess, topred)
  
    返回（topred）
    
  }））


interpolated_preds &lt;-
  预测（glm_mod，
        新数据 = interpolated_sr,
        类型=“响应”，se.fit=T）

interpolated_sr$predicted_fipar &lt;- interpolated_preds$拟合
interpolated_sr$predicted_fipar_se &lt;- interpolated_preds$se.fit

interpolated_sr %&gt;%
  ggplot(aes(x=时间点,y=predicted_fipar,group=样本)) +
  geom_point(aes(颜色=样本)) +
  几何线（）+
  geom_ribbon(aes(ymin=predicted_fipar-predicted_fipar_se,
                  ymax=预测的fipar+预测的fipar_se，
                  填充=样本），
              阿尔法 = 0.4) +
  主题（图例.position = &#39;无&#39;）

&lt;img alt=&quot;自变量随时间的插值以估计误差的非线性动态“src =“https://i.stack.imgur.com/jeCYK.png”/&gt;
这种方法有效吗？据我所知，通过随着时间的推移对自变量进行插值，我从黄土模型中引入了一些额外的误差（在这种情况下，误差会非常小，但根据拟合情况可能会很大）。这是错误传播发挥作用的地方吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644251/interpolation-of-errors-from-model-predictions-over-time-series</guid>
      <pubDate>Wed, 03 Apr 2024 22:45:54 GMT</pubDate>
    </item>
    <item>
      <title>Wald 检验如何遵循卡方分布？ （我们是否忽视了独立性）</title>
      <link>https://stats.stackexchange.com/questions/644250/how-does-the-wald-test-follow-a-chi-square-distribution-do-we-ignore-independe</link>
      <description><![CDATA[那么，根据定义，如果我们平方并添加独立变量和标准正态变量，统计量就会遵循卡方分布，对吧？因此，对于 Wald 检验（卡方版本），我们将平方系数相加并对它们进行标准化，但它们不能是独立的，对吗？那么为什么仍然可以安全地假设它们遵循卡方分布呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/644250/how-does-the-wald-test-follow-a-chi-square-distribution-do-we-ignore-independe</guid>
      <pubDate>Wed, 03 Apr 2024 22:24:30 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯网络：如何创建一个新图来表示边缘化单个变量的结果</title>
      <link>https://stats.stackexchange.com/questions/644249/bayesian-networks-how-to-create-a-new-graph-that-represents-the-result-of-margi</link>
      <description><![CDATA[假设我有一些贝叶斯网络 $G$ ，它表示某些变量集之间的关系 $x_1, \ldots, x_n$。假设我想边缘化 $x_i$，我应该如何创建新图表 $G^*$ span&gt;，来自 $G$，它代表这个边际分布？这里的关键是，原始网络中保留的所有条件独立性仍然必须保留，但这仅适用于不涉及 $x_i$ 的独立性吗？特别是对这一部分的澄清将不胜感激。
对我来说，一般的直觉似乎是，一旦我们删除 $x_i$ 以及与其连接的所有边，我们需要做的就是保留这些关系$G$，我们需要将 $x_i$ 的每个父级连接到 $x_i$，结果将是我们新的“边际”值图表$G^*$。我在网上看到的一个消息来源指出，边缘化“使边缘化的邻居变得依赖于变量”。这是否意味着我们还需要在 $x_i$ 的每对父母和 $x_i 的每对孩子之间绘制边$，或者这被认为是多余的，因为我们已经将他们的每个父母都连接到了他们的每个孩子？我的目标是为边缘分布创建一个最小的 I-map，因此防止不必要的边缘很重要，但我不确定哪些边缘在这里是明确必要的。如果有人可以帮助我理解这一点，也许可以介入并分享创建新图的通用算法，我将不胜感激]]></description>
      <guid>https://stats.stackexchange.com/questions/644249/bayesian-networks-how-to-create-a-new-graph-that-represents-the-result-of-margi</guid>
      <pubDate>Wed, 03 Apr 2024 21:50:07 GMT</pubDate>
    </item>
    <item>
      <title>Fisher 信息矩阵的重新参数化如何改变充分统计量的方差表达式？</title>
      <link>https://stats.stackexchange.com/questions/644246/how-does-reparametrization-of-the-fisher-information-matrix-change-the-variance</link>
      <description><![CDATA[如果我有一个形式为 $$p_{\theta}(x) = e^{\theta^T\cdot t(x) - \psi 的指数族分布(\theta)},$$ 其中 $\theta$ 是参数向量，$t( x)$ 是一个足够统计量的向量，并且 $\psi(\theta)$ 进行归一化，使得 pdf 积分为 1，则为 Fisher 信息是那些充分统计量的方差。即 $$\mathbf{I}_{\theta} = \text{Var}(T(X)).$$
如果我对行为良好的函数 $\tau(\theta)$ 的 Fisher 信息感到好奇，我可以通过让 $\mathbf{J}_{ik} = \frac{d\theta_i}{d\tau(
\theta)_k}$ 并将我的新 Fisher 信息矩阵形成为 $$\mathbf{I}_{\tau(\theta)} = \mathbf{J} ^T\mathbf{I}_{\theta}\mathbf{J}.$$
我的问题是：这个新的 Fisher 信息矩阵是否也给出了 $X$ 某些函数的方差表达式？我可以写 $$\mathbf{I}_{\tau(\theta)} = \text{Var}(U(T(X))) 吗？$$ 如果是这样，我如何从我的函数 $\tau(\theta)$&lt; 中找到这个函数 $U$ /跨度&gt;？]]></description>
      <guid>https://stats.stackexchange.com/questions/644246/how-does-reparametrization-of-the-fisher-information-matrix-change-the-variance</guid>
      <pubDate>Wed, 03 Apr 2024 21:33:22 GMT</pubDate>
    </item>
    <item>
      <title>生成假设的最标准方法，自动选择最佳假设，然后手动策划最佳假设</title>
      <link>https://stats.stackexchange.com/questions/644245/most-standard-method-to-generate-hypotheses-auto-select-the-best-then-manually</link>
      <description><![CDATA[我一直在尝试做这样的事情。我真的很感激有人指导我了解这方面的标准数学（在我尝试在编程中实现它之前）。
假设您有两个文本集合。他们被选为代表两种不同的“话语”。目标是找到它们共享“形式”或“结构”的哪些方面（调查“它们具有相似形式”的假设）。
我认为我感兴趣的技术是“符号回归”，尽管我从来不知道为什么这么叫。我的描述方式是，你列举一系列“假设”。必须根据假设对数据的解释程度来对其进行评分。例如，考虑假设“字符‘t’后跟字符‘.’”，您可能会发现该假设在数据中得到证实的概率为 20%。
您枚举所有可能的零阶假设并分配它们的准确性分数。接下来，您生成一阶假设。例如，想象一下假设“句号后面跟着一个空格”是第一轮中得分最高的假设。想象一下有一个不同的假设，“包含字符‘i’和‘I’的集合（形成某种单位 - 将它们视为可互换的）”。通过高阶假设，最终，算法发现所有大写字母的集合是一个在假设中得分极高的集合，“句点和空格后面跟着（大写字母的集合）的元素” ”。
这个过程仍在继续。它构建了更高阶的类别 - 最终是单词，然后是名词，然后是名词的语法规则。
它通过按分数对当前假设进行排序来实现此目的，因此它首先检查更好的假设。然后，它根据先前的假设形成新的高阶假设。
这些假设应该是人类可读的。这样，人类就可以干预并选择拒绝哪些假设，因为他们不希望算法专注于那些特征。他们可以选择模型发现的特征作为数据的一种分析功能。
我只需要一个非常标准的数学演示，这样我就可以第一次掌握这样的统计学习技术。有人能制定这种技术的标准数学吗？非常感谢。
&lt;小时/&gt;
我向 Claude 3 Opus 寻求帮助。以下是我认为相关的一些内容：
&lt;块引用&gt;
这是该假设的更正式的数学表示
生成和选择过程：
令 X 为有限字母表上所有可能文本字符串的集合
Σ。设D1和D2为X的两个子集，代表两个集合
正在分析的文本。
定义一个假设空间H，其中每个假设h ∈ H是一个函数
h: X → {0, 1}，表示映射文本字符串的模式或规则
到二进制标签（如果字符串满足模式则为 1，否则为 0）。
定义一个评分函数 s: H → ℝ 将每个假设映射到
实值分数，表明它与 D1 中观察到的数据的拟合程度
和D2。例如，一个简单的评分函数可以是准确度
假设：
s(h) = (Σx∈D1 h(x) + Σx∈D2 h(x)) / (|D1| + |D2|)
假设生成和选择过程可以定义为
如下：
将 H0 初始化为一组基本假设（例如，简单字符或
单词模式）。
对于 t = 1, 2, ..., T：

通过组合或修改 Ht-1 中的假设，生成一组新的假设 Ht。
计算每个 h ∈ Ht 的分数 s(h)。
根据分数选择假设的子集 Ht* ⊆ Ht，例如，对于某个阈值 τ，Ht* = {h ∈ Ht: s(h) ≥ τ}。
（可选）手动整理 Ht* 以获得一组最终假设 Ht&#39;。

假设空间H和步骤1中的生成过程可以表示为
使用形式语言理论和语法中的概念进行形式化
就职。例如，H 可以定义为所有正则的集合
Σ 上的表达式，生成过程可能涉及应用
正则表达式运算符（连接、交替、Kleene 星号、
等）到Ht-1的元素。
或者，H 可以使用上下文无关语法 G 来定义，并且
生成过程可能涉及应用 G 的生产规则
到 Ht-1 的元素。
第3步中的选择过程可以看作是特征的一种形式
选择或模型选择，目标是识别子集
根据某些观点最好地解释观察到的数据的假设
标准（例如准确性、信息增益、最小描述
长度）。

&lt;小时/&gt;
另一个似乎相关的概念是FOIL，但FOIL是第一个-命令。我们可以更高，达到 n 阶吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644245/most-standard-method-to-generate-hypotheses-auto-select-the-best-then-manually</guid>
      <pubDate>Wed, 03 Apr 2024 21:27:27 GMT</pubDate>
    </item>
    <item>
      <title>回归斜率的 Cohen's d 或 Cohen's d-like 效应大小估计？</title>
      <link>https://stats.stackexchange.com/questions/644233/cohens-d-or-cohens-d-like-effect-size-estimate-for-regression-slope</link>
      <description><![CDATA[可以计算与连续预测变量相关的线性回归系数的 Cohen&#39;s d 吗？如果可以的话，公式是什么？
我发现一个问题 已经问过这个问题，答案表明计算斜率的科恩 d 是不明智的。
如果不是，那么具有类似属性（例如无界）的适当效应大小度量是什么？我正在寻找一些不测量解释的方差量的东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/644233/cohens-d-or-cohens-d-like-effect-size-estimate-for-regression-slope</guid>
      <pubDate>Wed, 03 Apr 2024 20:33:09 GMT</pubDate>
    </item>
    <item>
      <title>非重叠 1-sigma 置信区间的统计显着性</title>
      <link>https://stats.stackexchange.com/questions/644228/statistical-significance-of-non-overlapping-1-sigma-confidence-intervals</link>
      <description><![CDATA[这个逻辑正确吗？

给定两个随机变量，每个变量都有自己的均值估计值和 1-sigma (z=1, 68%) 置信区间，且彼此不重叠：
真实值高于其置信区间的概率为
$0.32/2=0.16$
真实值低于其置信区间的概率也是$0.16$
因此，具有较低估计值的变量的真实平均值高于其 CI 且具有较高估计值的变量的真实平均值低于其 CI 的概率为 $0.16*0.16 =0.026$
因此，估计值较高的变量的真实平均值实际上高于估计值较低的变量的真实平均值的概率至少 $(1 - 0.026)$ ~ 97%
]]></description>
      <guid>https://stats.stackexchange.com/questions/644228/statistical-significance-of-non-overlapping-1-sigma-confidence-intervals</guid>
      <pubDate>Wed, 03 Apr 2024 19:36:14 GMT</pubDate>
    </item>
    <item>
      <title>给定系数 + 相关性计算 $t$-统计量</title>
      <link>https://stats.stackexchange.com/questions/644212/calculate-t-statistics-given-coefficients-correlations</link>
      <description><![CDATA[我们有一个简单的多元回归方程
$$
y=a+bx_1+cx_2+\varepsilon,
$$
其中 $a,b,c$ 是通过 OLS 估算的——我们知道这些值。就像我之前的问题一样（计算给定的 $R^2$估计系数和仅$N$）我试图弄清楚，是否有足够的信息来计算$t$统计信息math-container&quot;&gt;$x_1,x_2$ 并根据样本相关性$r_{x_1,x_2}, r_{x_1,y}, r_{ 确定因子显着性仅 x_2,y}$。
由于我们缺少$\sigma_{x_i}$，因此所提供的信息不足以得出因子重要性的结论，这是真的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644212/calculate-t-statistics-given-coefficients-correlations</guid>
      <pubDate>Wed, 03 Apr 2024 16:30:12 GMT</pubDate>
    </item>
    <item>
      <title>AIC 模型选择保持变量 p = 0.47</title>
      <link>https://stats.stackexchange.com/questions/644211/aic-model-selection-is-keeping-a-variable-with-p-0-47</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644211/aic-model-selection-is-keeping-a-variable-with-p-0-47</guid>
      <pubDate>Wed, 03 Apr 2024 16:21:45 GMT</pubDate>
    </item>
    <item>
      <title>仅在给定估计系数和$N$的情况下计算$R^2$</title>
      <link>https://stats.stackexchange.com/questions/644206/calculate-r2-given-estimated-coefficients-and-n-only</link>
      <description><![CDATA[我们有一个简单的回归方程$y=a+bx$，其中$a,b$ &gt; 通过 OLS 估算——我们知道这些值。假设给出了观测值 $N=25$ 的数量。我们确实无法计算 $R^2$ （或 $F$ - 统计量，等价）？同样，标准误差 $\sigma_b$ 真的无法计算吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644206/calculate-r2-given-estimated-coefficients-and-n-only</guid>
      <pubDate>Wed, 03 Apr 2024 15:20:24 GMT</pubDate>
    </item>
    <item>
      <title>混合效应澄清 - 生态学</title>
      <link>https://stats.stackexchange.com/questions/644182/mixed-effects-clarification-ecology</link>
      <description><![CDATA[我有一项实验的数据，该实验测量了多个地点的各种响应变量（例如土壤碳），每个地点都采用了 4 种不同处理方法中的一种。这些地点都分组在相似的景观中，但每个处理也分组在一起，即处理 A 的所有地点都在同一区域，处理 B 的所有地点都在同一区域，但该区域与处理 A 不同，等等。 p&gt;
简而言之，它是治疗 - 部位 - 测量的标准嵌套设计（每个部位多个）
在这种情况下，将站点 ID 添加为随机效应是否有意义，或者变量的固定效应（例如地面植被多样性）是否会更合适地解释这些站点的相似性/变化？
从数学角度来说，问题是：
y ~ x + b1 + b2 + ……
或者
y ~ x + (1|plot_id)]]></description>
      <guid>https://stats.stackexchange.com/questions/644182/mixed-effects-clarification-ecology</guid>
      <pubDate>Wed, 03 Apr 2024 11:39:50 GMT</pubDate>
    </item>
    <item>
      <title>当使用欧几里德距离作为衡量文本相似性的指标时，最准确的标准阈值是多少？</title>
      <link>https://stats.stackexchange.com/questions/644008/what-is-the-standard-threshold-value-that-is-best-for-accuracy-when-employing-eu</link>
      <description><![CDATA[我使用欧几里得距离作为度量来比较两个句子的相似性，同时使用我的自定义增量 KMeans 算法对它们进行聚类。我当前使用的阈值是 0.7，这在我拥有的数据中似乎效果很好。我只是想知道是否存在一个在所有情况下都能发挥最佳作用的标准阈值？]]></description>
      <guid>https://stats.stackexchange.com/questions/644008/what-is-the-standard-threshold-value-that-is-best-for-accuracy-when-employing-eu</guid>
      <pubDate>Mon, 01 Apr 2024 07:32:25 GMT</pubDate>
    </item>
    </channel>
</rss>