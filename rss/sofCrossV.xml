<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sun, 23 Feb 2025 03:23:46 GMT</lastBuildDate>
    <item>
      <title>Euler-Maruyama近似与估计参数的强烈收敛</title>
      <link>https://stats.stackexchange.com/questions/661747/strong-convergence-of-euler-maruyama-approximation-with-estimated-parameters</link>
      <description><![CDATA[ 背景。考虑一个扩散过程 $（x_t）$ 是以下随机微分方程（SDE）的解决方案：&lt; /p&gt;
  $$ DX_T = B（X_T）dt + \ sigma（x_t）dw_t $$   
其中 $ W_T $ 是标准Wiener过程。表示 $ x_t $  as  $ \ {\ bar {x} _ {k \ delta} \ } _ {k = 1}^n $ ，因此定义了连续的时间过程 $ \ bar {x} _t：= \ bar {x} _ {k \ delta} $  for  $ t \ in [k in [k in [k in] \ delta，（k+1）\ delta）$ 。众所周知，牢固的连接保持：
  $$ \ | x- \ bar {x} \ | _ {l_2（\ omega \ times [0，t]）}：= \ sqrt {\ int_0^t \ Mathrm {e} | x_t- \ bar {x} _t |^2 dt} = o（\ delta^{ -  \ frac {1} {2}}）$$ 
参见，例如，此注释。。 
 问题。假设函数 $ b $  and  $ \ sigma $ 由 $ \ theta $ 参数化。例如，最简单的线性过程：
在
 with  $ \ theta =（b，\ sigma）$ 。但是，我们不知道 $ \ theta $ 的值，因此，为了计算欧拉近似，我们首先估计 $ \ theta $  with  $ \ hat {\ theta} $ 从某些观测数据中class =“ Math-Container”&gt; $ \ hat {\ theta} $  in  $ \ {\ bar {x} _ {k \ delta} \} _ {k {k {k {k = 1}^n $ 获得 $ \ {\ hat {\ bar {x}} _ {k \ delta} \} _ {k = 1}^n $ 。
我们调用 $ \ {\ hat {\ bar {x}} _ {k \ delta} \} _ {k = 1}^n $ 作为Euler近似估计参数。 Define  $ \ hat {\ bar {x}} _ t：= \ hat {\ bar {x}} _ {k \ delta} $  for 。中
我们如何获得 $ \ | x- \ hat {\ bar {x}}} \ | _ {l_2（\ omega \ times [0，t]） } $ ，给定 $ \ delta \ to 0 $ 和 $ \ hat {\ theta} \ to \ theta $ （以任何形式）？
 注。这仅供示范。此外，我们有 $ \ hat {\ theta} $ 是从某些数据估算的，独立于 $ w_t $  （ $ \ hat {\ theta} \ perp w_t $ ）。]]></description>
      <guid>https://stats.stackexchange.com/questions/661747/strong-convergence-of-euler-maruyama-approximation-with-estimated-parameters</guid>
      <pubDate>Sun, 23 Feb 2025 02:14:46 GMT</pubDate>
    </item>
    <item>
      <title>在计算Nesterov优化梯度时，深度学习框架是否会“向前看”？</title>
      <link>https://stats.stackexchange.com/questions/661745/do-deep-learning-frameworks-look-ahead-when-calculating-gradient-in-nesterov-o</link>
      <description><![CDATA[ Nesterov优化背后的全部要点是计算当前参数值 $ \ theta_t $ ，而是在 $ \ theta_t + \ beta m $ ，其中 $ \ beta $ 是动量系数和 $ M $ 动量。更新步骤如下：
  $$
m \ get \ beta m- \ eta \ nabla l（\ theta + \ beta m）\\
\ theta \ get \ theta + m
$$  
通过查看
  velocity =动量 *速度-Learning_rate * g
w = w +动量 *速度-Learning_rate * g
 
通过查看 pytorch的文档更新步骤是：
    
如果我错了，请纠正我，但是在这两种情况下，梯度都不以“向前看”计算。参数位置（由于需要Nesterov优化）。这些实现原始方法的近似吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661745/do-deep-learning-frameworks-look-ahead-when-calculating-gradient-in-nesterov-o</guid>
      <pubDate>Sat, 22 Feb 2025 22:20:04 GMT</pubDate>
    </item>
    <item>
      <title>线性混合效应模型中的非结构化协方差矩阵：用于随机效应或残留误差</title>
      <link>https://stats.stackexchange.com/questions/661743/unstructured-covariance-matrix-in-linear-mixed-effects-model-for-random-effects</link>
      <description><![CDATA[我一直在研究一些纵向研究，包括临床试验，在那里他们使用线性混合效应模型进行纵向数据。可以在此开放式文章中找到一个示例：。在方法部分中，作者提到：“我们使用了 非结构化协方差矩阵的线性混合效应模型来估计平均变化率……
在Stata 中混合 命令，有两个您可以在其中指定方差 - 交互矩阵的参数：协方差（vartype） 方差 - 稳定效应的结构或残差（RSPEC），用于残留误差的结构。
我想知道在这样的文章中，作者通常意味着他们使用非结构化方差 - 协方差矩阵来进行随机效果和残差错误，还是其中一个？
如果任何人在研究中都采用了线性混合效应模型，请随时分享您的实践。]]></description>
      <guid>https://stats.stackexchange.com/questions/661743/unstructured-covariance-matrix-in-linear-mixed-effects-model-for-random-effects</guid>
      <pubDate>Sat, 22 Feb 2025 21:05:18 GMT</pubDate>
    </item>
    <item>
      <title>如果差异取决于分散体，我该如何用GLM进行M估计器？</title>
      <link>https://stats.stackexchange.com/questions/661740/how-do-i-make-an-m-estimator-out-of-a-glm-if-the-variance-depends-on-a-dispersio</link>
      <description><![CDATA[这个问题也发布在数学堆栈交换 https://math.stackexchange.com/questions/5038432/how-do-i-i-make-an-m-simator-of-a-glm-if-th-the-varianciance-in-a-a-a-dispersio &lt; /a&gt;。
具有响应的广义线性模型 $ y_1 \ in \ mathbb {r}，\ ldots，y_n \ in \ mathbb {r} $ 和（固定）解释性变量 $ x_1 \ in \ Mathbb {r}^p，\ ldots， x_n \ in \ mathbb {r}^p $ 是一个参数模型，带有未知参数 $ \ beta \ in \ mathbb {r}^p $ 它看到 $ y_i $ 作为 $ y_i $ 在某个指数族中， $ y_1，\ ldots，y_n $ 被认为是独立的。一个通常估计 $ \ beta $ 在可能的方法中，得出一般估计方程：
  \ begin {equation*}
\ sum_ {i = 1}^n \ frac {y_i- \ mu_i} {
\ end {方程*}  
我在文学中看到了几次，人们将其视为M估计剂的解决方案。也就是说，考虑一个函数 $ \ mu（x_i，\ beta）= \ mu_i（\ beta）$  and put：
  \ begin {equation*}
\ psi（y_i，\ mu（x_i，\ beta））= \ frac {y_i- \ mu_i} {v（\ mu_i）} \ frac {\ partial}
\ end {方程*}  
因此，上述重写为：
  \ begin {equation*}
\ sum_ {i = 1}^n \ psi（y_i，\ mu（x_i，\ beta））= 0
\ end {方程*}  
然后，一个人继续找到一个估计器 $ t_n（（（x_1，y_1），\ ldots，（x_n，y_n））$ 统计函数 $ t（f_n）$ ，其中 $ f_n $ 是经验分布。这通常是通过考虑 $ t $ 来完成的，该&gt;适用于所有分布 $ f（x，x，y）$ 这样：
  \ begin {equation*}
\ int \ psi（y，\ mu（x，t（f）））df（x，y）= 0
\ end {方程*}  
有关 $ t $ 的更多详细信息不是本文的主题。

问题：如果 $ v（\ mu_i）$ 实际上也取决于分散参数，我们如何将其视为M估计器？上面的积分不再有意义，因为 $ \ psi（y，\ mu（x，\ beta））$ 对于 $ x $ 和 $ y $ 在当前数据集之外。

举例来说，考虑二项式GLM。在这种情况下，我们假设 $ y_1，\ ldots，y_n $ 使得 $ z_i = m_iy_i $ 遵循分布 $ \ text {binomial}（m_i，p_i）$ 。  $ y_i $ 的结果概率密度函数，在 $ \ {0，\ frac {1} {m_i}上支持，\ ldots，\ frac {m_i-1} {m_i}，1 \} $  
  \ begin {equation*}
\ binom {m_i} {m_iy_i} \ exp \ left \ {m_i [y_i \ eta_i- \ kappa（\ eta_i）] \ right \}
\ end {方程*}  
 there  $ \ eta_i = x_i^t \ beta $  and  $ \ kappa（\ eta）= \ ln（ 1+e^{\ eta}）$ 。然后 $ \ mu_i = p_i = \ kappa&#39;（\ eta_i）= \ frac {1} {1 + e^{ -  \ eTa_i}} $ 。继续计算，我们得到：
  \ begin {equation*}
\ frac {\ partial} {\ partial \ beta} \ mu_i = \ mu_i（1- \ mu_i）x_i
\ end {方程*}  
  \ begin {equation*}
\ text {var}（y_i）= v（\ mu_i）= \ frac {1} {m_i} \ mu_i（1- \ mu_i）
\ end {方程*}  
最后，无论是通过上述公式还是直接写出日志的可能性，我们得到：
  \ begin {equation*}
\ sum_ {i = 1}^n（y__i- \ mu_i）m_ix_i = 0
\ end {方程*}  
使函数 $ v（\ mu_i）$ 取决于分散参数 $ \ frac {1} {1} { m_i} $ 。]]></description>
      <guid>https://stats.stackexchange.com/questions/661740/how-do-i-make-an-m-estimator-out-of-a-glm-if-the-variance-depends-on-a-dispersio</guid>
      <pubDate>Sat, 22 Feb 2025 18:45:34 GMT</pubDate>
    </item>
    <item>
      <title>我们需要估算稳定重量的分子吗？</title>
      <link>https://stats.stackexchange.com/questions/661737/do-we-need-to-estimate-the-numerator-of-the-stablized-weights</link>
      <description><![CDATA[如果在Herman和Robins第12.3章中，他们引入了稳定的IP权重 $$ \ frac {p（a）}} {p（a \ mid l）} $$ &lt; /span&gt;用于二进制处理，其中 $ l $ 是covaraite。实际上，他们提到的任何IP权重 $$ \ frac {p} {f（a \ mid l} $$ 带有 $ 0＆lt; p \ le 1 $ 用于连续处理。 class =“数学 - 范围”&gt; $$ \ frac {f（a）} {f（a \ mid l）} $$ 用于连续处理。
但是，在同一章的后面某个地方，他们实际上确实进行了估计 $ p（a）$ 或 $ f（ a）$ 。我的问题是，为什么我们不能仅估计 $ f（a \ id l）$ 并施加密度函数，以平均0.5方差1表示正常，以获取值对于 $ f（a）$ ？]]></description>
      <guid>https://stats.stackexchange.com/questions/661737/do-we-need-to-estimate-the-numerator-of-the-stablized-weights</guid>
      <pubDate>Sat, 22 Feb 2025 17:18:22 GMT</pubDate>
    </item>
    <item>
      <title>横截面回归中的误差协方差矩阵（Cochrane 2005）</title>
      <link>https://stats.stackexchange.com/questions/661727/error-covariance-matrix-in-cross-sectional-regression-cochrane-2005</link>
      <description><![CDATA[我正在阅读Cochrane 2005和顶部P 237的资产定价，他解释了错误协方差 $ cov（\ alpha，\ alpha，\ alpha&#39;）$ 在横截面回归中。只是，我没有得到他的结果。
 背景 
从横截面回归的步骤1开始
  $$
r_t^i = f_ {t，1} \ beta_1^i + \ dots + f_ {t，k} \ beta_k^i + + \ varepsilon_t
$$  
以矩阵形式
  $$
\下划线{r} _i = \下划线{f} \下划线{\ beta} _i + \ usepline {\ varepsilon} _i _i
$$ 
其中的大小 $ r_i $  is  $（t \ times 1）$ 和 $ \下划线f $ 是 $（t \ times k）$ 。。
对于 $ i = 1，\ dots n $ 生产 $ n $  vector  $ \ usewandline \ beta_i $  size  $（K \ times 1）$ 。收集这些 $ \ upsine \ beta_i $   $ n $ 资产 $ \下划线B $  size  $（n \ times k）$ 并执行以下内容回归。
  $$
\ bar {r} _i = \下划线{\ beta} _i&#39;\ lissine {\ lambda} + \ alpha_i
$$  
其中 $ \ bar {r} _i = \ frac {1} {t} {t} \ sum_ {i = 1} class =“数学 - 范围”&gt; $ \ usepline {\ lambda} $  size size  $（k \ times 1）$ 。这可以使用矩阵 $ \ upes b $  as 以矩阵 来编写。
  $$
\下划线{\ bar {r}} = \下划线{b} \ lissine {\ lambda} + \ usepline {\ alpha}
$$  
 我的问题 
所以现在我想计算 $ cov（\ undesline {\ alpha}，\ suespline {\ alpha}&#39;）$ 。我会停止从现在开始强调向量和矩阵，因为一切都是向量或矩阵。
首先，这本书在第237页上说 $ cov（\ alpha，\ alpha&#39;）= \ frac {1} {t} {t}（b \ sigma_f b&#39; + \ sigma）$ 。我的派生（如下所示）产生不同的结果。
使用回归中的残差为零（即 $ e [\ alpha] = 0 $ ）：
  $$
\ begin {Aligned}
cov（\ alpha，\ alpha&#39;）＆amp; = e [\ alpha \ alpha&#39;] \\
＆amp; = e [（\ bar {r} -b \ lambda）（\ bar {r} -b \ lambda）&#39;] \\
＆amp; = e [\ bar {r} \ bar {r}&#39; -  \ bar {r} \ lambda&#39;b&#39; -  b \ lambda \ bar \ bar {r}&#39; + b \ lambda \ lambda \ lambda \ lambda&#39;b&#39;b&#39;b&#39;]
＆amp; = e [\ bar {r} \ bar {r}&#39;] + e [b \ lambda \ lambda&#39;b&#39;]  -  2e [\ bar {r} \ lambda&#39;b&#39;] \\
＆amp; = \ frac {1} {t} \ sigma + \ frac {1} {t} b \ sigma_f b -2e [\ bar {r} \ lambda&#39;b&#39;]
＆amp; = \ frac {1} {t}（b \ sigma_f b&#39; + \ sigma）-2e [\ bar {r} \ lambda&#39;b&#39;]
\ end {Aligned}
$$  
我不知道为什么作者没有得到额外的 $  -  2e [\ bar {r} \ lambda&#39;b&#39;] $ 。我一定犯了一个错误 - 我是否错过了一个协方差术语]]></description>
      <guid>https://stats.stackexchange.com/questions/661727/error-covariance-matrix-in-cross-sectional-regression-cochrane-2005</guid>
      <pubDate>Sat, 22 Feb 2025 15:17:32 GMT</pubDate>
    </item>
    <item>
      <title>用于证明Q学习收敛的定理中数学术语的含义</title>
      <link>https://stats.stackexchange.com/questions/661723/meaning-of-mathematical-terms-in-a-theorem-used-to-prove-q-learning-convergence</link>
      <description><![CDATA[我试图在这里理解定理的陈述 htttps：// apps.dtic.mil/sti/tr/pdf/ada276517.pdf ，用于证明Q学习算法的收敛性（即使定理更抽象）：
    
，但是我在理解术语的含义方面有问题。您能评论以下几点：
 1-什么是 $ x $ 在这里？是在x $ 中假设 $ x \的语句，因此，每个 $ x $ ，例如在高斯流程中？并且 $ x $ 即使没有明确提及条件1的状态空间？
 2-标准 $ || \ cdot || _W $ 在哪个设置上定义了？是在上一个集合 $ x $ 上定义的规范（在这种情况下是矢量空间）？是在基本概率空间的随机变量 $ \ omega $ 上定义的规范，让我们称其为 $ v（\ omega） ）$ ？它是否在随机过程的空间中定义了标准（我猜 $ v（\ Omega \ times x）$ ）？
无论正确的解释如何，我都会发现条件3和4之间的差异令人困惑。正确的成员是相同类型的，而在左侧，我们在第一种情况下有一个额外的规范，我们在条件4中找不到这是对有效性领域的任何其他评论
感谢您帮助我澄清。该定理中似乎给予了一些设置。]]></description>
      <guid>https://stats.stackexchange.com/questions/661723/meaning-of-mathematical-terms-in-a-theorem-used-to-prove-q-learning-convergence</guid>
      <pubDate>Sat, 22 Feb 2025 11:11:23 GMT</pubDate>
    </item>
    <item>
      <title>自我注意力的输出</title>
      <link>https://stats.stackexchange.com/questions/661710/output-of-self-attention</link>
      <description><![CDATA[  $ \ newCommand {\ softmax} {\ propatatorName {softmax}} $ 我的问题是关于注意的问题，如果我们从
  $ \ delta $   - 以15:32的方式看到。
 第二个解释： 
在我看来，在我看来，输出是 $ v_k $ 的线性组合，那就是新嵌入者本身 $ \ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v $ 。因此， $ \ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v $ 不仅仅是我们添加到oridingal嵌入中的东西，它是新的嵌入。
 我的问题： 
 is  $ \ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）嵌入以获取新的嵌入？我误解了什么吗？似乎我会说两个不同的消息。
陈述了另一种方式：如果我们有一个嵌入 $ \ textbf {x} _i $ 是新的嵌入式 $（ \ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v）_i $ 或 $ \ textbf {x} _i+（\ softmax \ left（qk^t/\ sqrt {d_k}+m \ right）v）v）_i $ ？]]></description>
      <guid>https://stats.stackexchange.com/questions/661710/output-of-self-attention</guid>
      <pubDate>Sat, 22 Feb 2025 00:27:14 GMT</pubDate>
    </item>
    <item>
      <title>关于比较三个不同小组评分的问题</title>
      <link>https://stats.stackexchange.com/questions/661696/questions-on-comparing-three-different-groups-ratings</link>
      <description><![CDATA[我目前正在比较三个群体之间的职业障碍：学生，教职员工和行业专业人员。尽管我使用李克特量表的同一调查问卷（例如，“在决定职业时工作满意度很重要”），但我注意到与其他两个组相比，行业参与者通常反应更负面。例如，学生的平均评分为6.2/7，教职员工的平均评分为6.1/7，在所有调查项目中的行业专业人员的平均评分为4.89/7。。
鉴于这些基线差异，我担心简单的均值比较可能不会产生有意义的见解。取而代之的是，我正在考虑专注于排名（例如，确定哪些障碍对学生与行业专业人员最重要）。在这种情况下，使用最合适的分析方法是什么？
我记得看到一篇有类似方法的论文，但是尽管进行了数小时的搜索，但我还是找不到它。任何人都知道有类似方法的好论文吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661696/questions-on-comparing-three-different-groups-ratings</guid>
      <pubDate>Fri, 21 Feb 2025 16:30:57 GMT</pubDate>
    </item>
    <item>
      <title>如何在不同聚集/粒度水平下的时间序列数据的经验估计标准偏差和变异系数？</title>
      <link>https://stats.stackexchange.com/questions/661685/how-to-empirically-estimate-standard-deviation-and-coefficient-of-variation-for</link>
      <description><![CDATA[我正在与2024年9月19日至11月19日的图书馆建筑物收集的时间序列建筑物占用数据。每5分钟，使用Motion（PIR）传感器（总共450张椅子）记录每5分钟的数据。然后将数据重新采样至30分钟的间隔（2689个数据点），并在不同级别进行汇总：
椅子级别：450椅→1,210,050个数据点（450*2689）
表级：50个表→134,450数据点（50*2689）
子区域级别：6个子区域→16,134个数据点（6*2689）
区域级别：2区→5,378个数据点（2*2689）
 客观：我旨在使用两个关键指标（即标准偏差（SD）（SD）和变异系数（CV），在不同水平的粒度（椅子，桌子，子区域和区域）处量化可变性。 。
在较小的级别（例如椅子级）下，我有更多的观察结果（更高的数据点，而在更粗的水平（例如区域级别）下，样本量明显较小。
我的主要问题是
 1-当每个粒度水平的数据点总数显着差异时，我如何从经验上估计SD，CV进行公平比较？我已经计算了原始SD，而没有考虑到不平等的观察数（请参阅附件图）每小时标准偏差的箱形图表所有粒度级别” src =“ https://i.sstatic.net/vok57dth.jpg”/&gt; 。
数据集附加在此处
考虑不平等的数据点，可以用来估算SD的任何见解，参考或方法将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661685/how-to-empirically-estimate-standard-deviation-and-coefficient-of-variation-for</guid>
      <pubDate>Fri, 21 Feb 2025 13:39:12 GMT</pubDate>
    </item>
    <item>
      <title>我是否了解主教的主教？</title>
      <link>https://stats.stackexchange.com/questions/661681/have-i-understood-bishop-on-uninformative-priors</link>
      <description><![CDATA[主教将A 定义参数满足以下内容，
 $$
p（x | \ mu）= f（x- \ mu）。
$$ 
他想定义“不信息先验”对于 $ {\ MU} $ 对于贝叶斯推理。如果我没记错的话，那是他想利用以下不变性，
 $$
\ wideHat {x}：= x + c \ leadsto p（\ wideHat {x} | \ wideHat {\ mu}）= p（x | \ mu），
$$ 
我们定义了 $ {\ wideHat {\ mu} = \ mu+c} $ 。这是我想验证我理解的阶段：他本质上想定义先前的 $ {p（\ mu）} $ ，以便我们具有以下后代：
 $$
p（\ wideHat {\ mu} | \ wideHat {x} _1，...，\ wideHat {x} _n）= p（\ mu | x_1，...，...，x_n）。
$$ 
他并没有这样说，所以这就是为什么我想检查我本质上理解这个想法的原因。如果您继续这个想法，则最终会以 $ {p（\ wideHat {\ mu}）= p（\ mu）} $ ，并且由于选择了 $ {c} $ 是任意的，您最终会 $ {p（\ mu）= \ text {const。}} $  

  edit ：要澄清，我应该提到 $ {p（\ wideHat {\ mu}）= p（\ mu）} $ 最终是一个足够的（但我认为不是严格必要的条件） class =“ Math-Container”&gt; $ {p（\ wideHat {\ mu} | \ wideHat {x}）= p（\ mu | x）} $ ：
 $$
p（\ wideHat {\ mu} | \ wideHat {x}）= p（\ mu | x）\ rightarrow \ frac {p（\ wideHat {\ mu}）}} {\ int_d p（\ wideHat {x} | \ wideHat {\ mu}）p（\ wideHat {\ mu}）d \ wideHat {\ mu}} =
\ frac {p（\ mu）} {\ int_d p（x | \ mu）p（\ mu）d \ mu}。
$$ 
由于我们已经确定 $ { span class =“ nath-container”&gt; $ {p（\ wideHat {\ mu}）= p（\ mu）} $ 对于任何 $ C $ 满足了平等。嗯，也许我们可以说更多：
 $$
\ rightarrow \ int_d f（x- \ mu）p（
$$  ]]></description>
      <guid>https://stats.stackexchange.com/questions/661681/have-i-understood-bishop-on-uninformative-priors</guid>
      <pubDate>Fri, 21 Feb 2025 12:12:55 GMT</pubDate>
    </item>
    <item>
      <title>纯粹的可预测性衡量</title>
      <link>https://stats.stackexchange.com/questions/661679/purely-theoretical-measure-of-predictability</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661679/purely-theoretical-measure-of-predictability</guid>
      <pubDate>Fri, 21 Feb 2025 11:57:38 GMT</pubDate>
    </item>
    <item>
      <title>GLMM用于计数数据，受试者的随机效果为小样本量，I型错误风险，如何推断因子效应和事后。</title>
      <link>https://stats.stackexchange.com/questions/661652/glmm-for-count-data-with-random-effect-of-subject-in-small-sample-size-with-risk</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661652/glmm-for-count-data-with-random-effect-of-subject-in-small-sample-size-with-risk</guid>
      <pubDate>Thu, 20 Feb 2025 18:03:25 GMT</pubDate>
    </item>
    <item>
      <title>哪种概率定律被用于得出分配运动定律</title>
      <link>https://stats.stackexchange.com/questions/661152/what-law-of-probability-is-being-used-for-deriving-law-of-motion-of-distribution</link>
      <description><![CDATA[我正在研究
基本上，我们有以下元素：状态空间 $ a \ times s = \ {\ bar {a} _1，\ dots，\ bar {a} _n \} \ times \ {\ bar {s} _1，\ dots，\ bar {s} _n \}，$ 和那里存在决策规则 $ g：a \ times s \ to $ ，该$ 映射每个状态 $（a，s）$  to element  $ a&#39;= g（a，s）$  in  $ a，$ a，$ 那是被解释为&#39;当今天的状态为 $（a，s）$ 明天的决定是 $ a&#39;$&#39;$ &#39;。此外，还有一个随机变量 $（s_t）_ {t = 0}^\ int space  $ s $ 具有带有条件过渡概率的马尔可夫属性 $ p（s_ {t+1} = s&#39;| s_t = s）$ 给定，其中 $ s&#39;，s \ in s $ ，这些概率在过渡矩阵 $ p $ 文本中提到的。
然后，动力学如下：我们从初始状态 $（a_ {0}，s_ {0}）\ in a \ times s $  in ，然后随机变量的一系列实现 $（s_t）_ {t = 1}^\ infty $ 诱导路径对于我们的系统 $（a_t，s_t）_ {t = 0}^\ infty $ 。
话虽如此，我们对联合无条件分布的演变感兴趣/span&gt;状态 $（a，s）$ 在任何时候 时间。因此，我们得到了描述  $$ p（a_ {t+1} = a&#39;，s_ {t+1} = s&#39;）= \ sum_ {a_t {a_t \ in} \ sum_ {s_t \在s} p（a_ {t+1} = a&#39;| a_t = a，s_t = s）p（s_ {t+1} = s&#39;| s_t = s） ）。$$  
我有能力“直观地”理解这个方程式，但是我无法使用概率定律正式得出它。特别是，我尝试了允许我们以条件和边缘概率（即 $ p（x = x，y = y）= p（x = x = x）来编写联合概率的法律。 | y = y）p（y = y）= p（x = x | y = y）\ sum_xp（y = y | x = x）p（x = x）$ ，但我不看看我如何改变这个进入上面的表达式。
如果您能给我一些有关如何得出这个方程式的见解，我将非常感谢。
    ]]></description>
      <guid>https://stats.stackexchange.com/questions/661152/what-law-of-probability-is-being-used-for-deriving-law-of-motion-of-distribution</guid>
      <pubDate>Sun, 09 Feb 2025 07:08:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么发现因素很重要时，比较字母没有差异？</title>
      <link>https://stats.stackexchange.com/questions/660735/why-comparison-letters-do-not-differ-when-factor-was-found-significant</link>
      <description><![CDATA[我在R中运行了一系列模型，其中涉及“ Lmer”的两个因素。功能，还测试因子相互作用。
例如：
 模型＆lt;  -  lmer（参数〜因子1*factor2 +（1 | id_repeated），data = db）
摘要（模型）
toct_tests（型号）
AIC（模型）
shapiro.test（残基（模型））
 
然后，我对重要因素进行了成对的比较测试（或在显着时相互作用）以查看该因素的哪些情况有所不同。
  mcp＆lt; -emmeans（型号，〜因子，方法=“ tukey”，调整=“ bonferroni”）
cld（mcp，letters =＆quot; abcde; cretversed = true，sort = false）
 
在两种情况下，即使这些因素是根据模型结果显着的，MCP＆lt; emmeans也没有显示不同的字母。
例如，在下种情况下，互动很重要，但这并没有从我进行比较的字母中出现。
 
型号DF1 DF2 F.Ratio P.Value
 因子1 1 18 0.574 0.4584
 因子2 4 72 57.563＆lt; .0001
 因子1：因子2 4 72 2.825 0.0309

 因子1因子2 emmean se df power.cl upper.cl .group。
 A 2000 0.582 0.154 72.7 0.275 0.890 B   
 B 2000 0.670 0.154 72.7 0.362 0.977 b   
 A 2005 0.622 0.154 72.7 0.314 0.929 b   
 B 2005 0.437 0.154 72.7 0.129 0.744 b   
 A 2010 0.616 0.154 72.7 0.309 0.924 b   
 B 2010 0.534 0.154 72.7 0.227 0.842 b   
 A 2015 0.966 0.154 72.7 0.659 1.273 b   
 B 2015 1.026 0.154 72.7 0.719 1.334 b   
 A 2020 1.917 0.154 72.7 1.610 2.224 a    
 B 2020 2.556 0.154 72.7 2.249 2.863 a  
 
您能帮我理解为什么会发生这种情况以及我做错了什么？
预先感谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/660735/why-comparison-letters-do-not-differ-when-factor-was-found-significant</guid>
      <pubDate>Wed, 29 Jan 2025 18:16:14 GMT</pubDate>
    </item>
    </channel>
</rss>