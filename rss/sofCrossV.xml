<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 12 Sep 2024 01:11:42 GMT</lastBuildDate>
    <item>
      <title>在不平衡数据上进行 R 中的训练和预测函数</title>
      <link>https://stats.stackexchange.com/questions/654235/train-and-predict-function-in-r-on-imbalanced-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654235/train-and-predict-function-in-r-on-imbalanced-data</guid>
      <pubDate>Wed, 11 Sep 2024 21:35:09 GMT</pubDate>
    </item>
    <item>
      <title>有限的期望会导致有限的熵，这是真的吗？</title>
      <link>https://stats.stackexchange.com/questions/654234/is-it-true-that-finite-expectation-leads-to-finite-entropy</link>
      <description><![CDATA[让 $X$ 成为自然数支持的随机变量，具有有限期望。证明 $H(x)&lt;\infty$。另外，给出一个自然数支持的随机变量的示例，该变量具有 $H(x)=\infty$
有什么想法可以实现吗？我尝试使用定义和收敛测试，但我不确定它是否足够正式。]]></description>
      <guid>https://stats.stackexchange.com/questions/654234/is-it-true-that-finite-expectation-leads-to-finite-entropy</guid>
      <pubDate>Wed, 11 Sep 2024 21:20:33 GMT</pubDate>
    </item>
    <item>
      <title>我应该何时应用 Benjamini-Hochberg 与 Benjamini-Yekutieli FDR 校正？</title>
      <link>https://stats.stackexchange.com/questions/654233/when-should-i-apply-benjamini-hochberg-vs-benjamini-yekutieli-fdr-correction</link>
      <description><![CDATA[我几乎没听说过有人使用 BY 程序进行 FDR 校正，BH 更为常见。但是，据我所知，BY 程序对各种依赖结构更稳健，而 BH 假设独立测试。
在大量应用中，相互依赖性是一个非常合理的假设，但作者使用 BH 进行 FDR 校正。有趣的是，BY 似乎比 BH 更严格（产生更高的调整后的 Padj 值）。
对于哪些类型的依赖结构，BH 测试仍然有效？
希望为生物科学家（即非统计学家）提供建议阅读的指针。]]></description>
      <guid>https://stats.stackexchange.com/questions/654233/when-should-i-apply-benjamini-hochberg-vs-benjamini-yekutieli-fdr-correction</guid>
      <pubDate>Wed, 11 Sep 2024 21:13:56 GMT</pubDate>
    </item>
    <item>
      <title>“我们能相信我们计算出的功效值吗？”或者“当零假设为假时，I 类错误是否会立即消失”？</title>
      <link>https://stats.stackexchange.com/questions/654232/can-we-believe-the-power-values-we-compute-or-do-type-i-errors-disappear-as</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654232/can-we-believe-the-power-values-we-compute-or-do-type-i-errors-disappear-as</guid>
      <pubDate>Wed, 11 Sep 2024 21:05:35 GMT</pubDate>
    </item>
    <item>
      <title>比较回顾性队列和前瞻性队列</title>
      <link>https://stats.stackexchange.com/questions/654231/comparing-retrospective-and-prospective-cohorts</link>
      <description><![CDATA[我对比较回顾性队列和前瞻性队列有点困惑……
假设我有两个队列，一个是回顾性队列（用作对照），另一个是前瞻性队列（应用了程序/干预）。我可以使用常规统计检验（如卡方、CMH 等）来比较两个队列之间的各种特征（例如死亡人数）吗？不太确定我是否需要“特殊”测试……
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654231/comparing-retrospective-and-prospective-cohorts</guid>
      <pubDate>Wed, 11 Sep 2024 21:02:50 GMT</pubDate>
    </item>
    <item>
      <title>具有多个独立变量和因变量的 Kruskal</title>
      <link>https://stats.stackexchange.com/questions/654226/kruskal-with-multiple-independent-and-dependent-variables</link>
      <description><![CDATA[我有三个独立变量：

延迟 - 4 级序数
难度 - 2 级序数
专业度 - 2 级序数

还有三个因变量：

时间 - 度量
准确度 - 度量
挫败感 - 5 级序数

我考虑根据独立变量将其分为 16 组，然后使用 Kruskal 检验和事后 Dunn 检验对所有组进行比较。我计划以这种方式测试每个因变量。但是，此链接和 CV 上的其他问题表明此过程不准确。
我使用 Kruskal 检验，因为我的数据违反了 ANOVA 模型假设。具体来说，没有给出正态性，并且存在显着的自相关拉格朗日乘数自相关检验（时间和准确度的 p &lt; 10^40）。


我没有检查 DV 挫折的假设，因为结果对我来说看起来太差了。
请告诉我我是否做了一个大数学禁忌，因为我对此并不是 100% 肯定。
我也不确定这里是否需要多变量方法。此帖子中的评论表明，对每个 IV 进行单独的 Kurskal 测试可能是一种更好的方法。但是，我怀疑 IV 之间存在相互作用，我想找到这些相互作用。
我很高兴能得到任何有关适合这种情况的分析技术的提示。
编辑以指定我想要的内容：我不确定所描述的分析是否适合我面临的情况。我查看了多个书籍章节和博客文章，但我无法推广到这种情况。
第二次编辑：方差分析假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/654226/kruskal-with-multiple-independent-and-dependent-variables</guid>
      <pubDate>Wed, 11 Sep 2024 19:31:24 GMT</pubDate>
    </item>
    <item>
      <title>我需要帮助理解贝叶斯线性回归的重要性</title>
      <link>https://stats.stackexchange.com/questions/654224/i-need-help-understanding-importance-of-bayesian-linear-regression</link>
      <description><![CDATA[因此，我正在尝试贝叶斯线性回归。作为新手，我尝试了以下方法：
生成数据的方程式：

$$Y = \phi(X) \cdot W + \epsilon $$其中 $$W \sim \mathcal{N} ( \overline{w} ,\Sigma_w)$$
$$\epsilon \sim \mathcal{N}(\overline{\epsilon}, \Sigma_\epsilon )$$

P(Y,W) 的联合概率：

$$\begin{pmatrix}W \\ Y\end{pmatrix} \sim\mathcal{N}\left(\begin{pmatrix}\overline{w} \\\phi\overline{w} \end{pmatrix}, \begin{pmatrix} \Sigma_W &amp; \Sigma_W\phi^T \\ \phi\Sigma_W &amp; \phi\Sigma_W\phi^T + \Sigma_\epsilon\end{pmatrix}\right)$$

$\mu_{\text{post}}$ 和 $\Sigma_{\text{post}}$，P(W|Y) 的参数由以下公式给出：

$$\mu_{\text{post}} = \overline{w}+ \Sigma_{\text{W}} \phi^T (\phi \Sigma_{\text{W}} \phi^T + \Sigma_\epsilon)^{-1} (Y - \phi \overline{w})$$
$$\Sigma_{\text{post}} = \Sigma_{\text{W}} - \Sigma_{\text{W}} \phi^T (\phi \Sigma_{\text{W}} \phi^T + \Sigma_\epsilon)^{-1} \phi \Sigma_{\text{W}}$$

我观察到，使用此公式生成的 W（P(W|Y) 的平均值）类似于通过设置正则化参数 $\lambda= precision_{\text{prior}}/ 通过 MAP 获得的正则化闭式解precision_{\text{noise}}$。
这很有道理，但我不禁要问，为什么对于更简单的情况，我们需要贝叶斯线性回归。]]></description>
      <guid>https://stats.stackexchange.com/questions/654224/i-need-help-understanding-importance-of-bayesian-linear-regression</guid>
      <pubDate>Wed, 11 Sep 2024 18:53:32 GMT</pubDate>
    </item>
    <item>
      <title>理解互信息作为关系的衡量标准：为什么完全相关的确定性函数的互信息不同？</title>
      <link>https://stats.stackexchange.com/questions/654223/understanding-mutual-information-as-a-measure-of-relationship-why-is-mutual-inf</link>
      <description><![CDATA[有人能解释一下为什么 a1 和 a2 之间的互信息 (MI) 小于 b1 和 b2 之间的 MI 吗？
import numpy as np
from sklearn.metrics import mutual_info_score

a1 = np.array([10, 10, 10, 10, 8, 6, 5, 9, 8, 7])
a2 = np.array([10, 10, 10, 10, 8, 6, 5, 9, 8, 7])

b1 = np.array([0.09780311, 0.02335877, 0.10676231, 0.01144303, 0.03910861, 0.06950386, 0.06038933, 0.12563807, 0.01360671, 0.01319363])
b2 = np.log(b1)

# 计算 a1 和 a2 之间的 MI

mi_a = mutual_info_score(a1, a2)
print(mi_a) # 打印 1.609

# 计算 b1 和 b2 之间的 MI

mi_b = mutual_info_score(b1, b2)
print(mi_b) # 打印 2.303

在这两种情况下，第二个向量（a2 和 b2）都是第一个向量（a1 和 b1）的确定性函数。但是，即使 a1 和 a2 完全相关，mi_a 也小于 mi_b。由于 a2 和 b2 在给定 a1 和 b1 的情况下都是确定性的，因此我预计互信息值至少相同。为什么会出现这种差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/654223/understanding-mutual-information-as-a-measure-of-relationship-why-is-mutual-inf</guid>
      <pubDate>Wed, 11 Sep 2024 18:47:46 GMT</pubDate>
    </item>
    <item>
      <title>冷卡归因能解决类别不平衡问题吗？</title>
      <link>https://stats.stackexchange.com/questions/654220/can-cold-deck-imputation-used-to-address-class-imbalance</link>
      <description><![CDATA[如果您有使用冷牌插补解决数据集中的类别不平衡问题的经验，能否分享更多细节或参考文献？
编辑添加：
建模方法是具有一个隐藏层的神经网络。数据不平衡，带有正标签的人口不到 1%。
为了便于理解，下面是 wiki 上对冷牌插补的描述。
热牌
一种曾经常见的插补方法是热牌插补，其中从随机选择的类似记录中插补缺失值。术语“热牌”可以追溯到穿孔卡片上的数据储存，表示信息捐赠者与接收者来自同一数据集。这叠卡片是“热的”，因为它目前正在被处理。
一种热牌插补形式称为“上次观察结转” （或简称为 LOCF），它涉及根据多个变量对数据集进行排序，从而创建有序数据集。然后，该技术找到第一个缺失值，并使用缺失数据之前的单元格值来估算缺失值。对下一个具有缺失值的单元格重复该过程，直到所有缺失值都已估算完毕。在常见情况下，案例是对个人或其他实体的变量进行重复测量，这代表了这样一种信念：如果缺少测量，最好的猜测是它与上次测量时没有变化。众所周知，这种方法会增加增加偏见和可能得出错误结论的风险。因此，不建议使用 LOCF。
冷牌
相比之下，冷牌插补是从另一个数据集中选择捐赠者。由于计算机能力的进步，更复杂的插补方法通常取代了原始的随机和排序的热牌插补技术。这是一种用过去调查中类似项目的响应值进行替换的方法。它适用于测量时间间隔的调查。]]></description>
      <guid>https://stats.stackexchange.com/questions/654220/can-cold-deck-imputation-used-to-address-class-imbalance</guid>
      <pubDate>Wed, 11 Sep 2024 16:59:33 GMT</pubDate>
    </item>
    <item>
      <title>离散时间生存模型（输出）</title>
      <link>https://stats.stackexchange.com/questions/654204/discrete-time-survival-model-output</link>
      <description><![CDATA[这两个函数中哪一个更适合离散时间生存分析？假设数据集中有 8 个时间点。输出需要包含时间的单个估计值和每个时间级别的单独估计值？简而言之：我需要将时间或因素（时间）纳入分析吗？
Gompertz_Model_Baseline &lt;- glm(formula = event ~ Time,
family = binomial(link = &quot;cloglog&quot;),
data = Scania_PersonPeriod_Train)

summary(Gompertz_Model_Baseline)

系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -4.168556 0.072451 -57.54 &lt;2e-16 ***
时间 0.072376 0.004185 17.30 &lt;2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

第二个模型：
Gompertz_Model_Baseline &lt;- glm(formula = event ~ factor(Time),
family = binomial(link = &quot;cloglog&quot;),
data = Scania_PersonPeriod_Train)

summary(Gompertz_Model_Baseline)

系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -4.0762 0.1961 -20.784 &lt; 2e-16 ***
因子（时间）2 0.2717 0.2640 1.029 0.303511 
因子（时间）3 -0.1942 0.3018 -0.643 0.519926 
因子（时间）4 0.1789 0.2774 0.645 0.518810 
因子（时间）5 0.3349 0.2701 1.240 0.214988 
因子（时间）6 0.3844 0.2701 1.423 0.154699 
因子（时间）7 0.3722 0.2748 1.355 0.175537 

]]></description>
      <guid>https://stats.stackexchange.com/questions/654204/discrete-time-survival-model-output</guid>
      <pubDate>Wed, 11 Sep 2024 12:00:28 GMT</pubDate>
    </item>
    <item>
      <title>寻找分布的平均值，给出指定区间内特定百分比的结果</title>
      <link>https://stats.stackexchange.com/questions/654143/finding-mean-of-distribution-which-gives-specific-percentage-of-results-in-speci</link>
      <description><![CDATA[假设有一个已知区间 [a, b] 和一个已知标准差的正态分布。如何找到区间 [a, b] 包含定义的结果百分比 P 的分布的平均值 xbar？因此，唯一的变量是分布的平均值。我可以用数值方法找到它的近似值，但寻找解析解（通用公式）。
假设当分布在区间[a, b]中居中时，存在大于或等于定义百分比P的百分比。
将有两个解，与值a和b的距离相同。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654143/finding-mean-of-distribution-which-gives-specific-percentage-of-results-in-speci</guid>
      <pubDate>Tue, 10 Sep 2024 09:32:25 GMT</pubDate>
    </item>
    <item>
      <title>双打匹克球评分更新算法</title>
      <link>https://stats.stackexchange.com/questions/654127/rating-update-algorithm-for-doubles-pickleball</link>
      <description><![CDATA[我希望使用电子表格来跟踪匹克球联盟中每位球员的评分。像 ELO 这样的概念似乎是正确的方法，但我想跟踪每位球员的平均值（评分）和 sigma（信心），然后根据每场比赛的结果对其进行更新。由于它是在电子表格中，我希望这个计算是直接的，假设每场比赛都是赢/输（没有平局），并在更新中使用每支球队的得分。
我理解使用贝叶斯来实现这一点的概念，但我对细节不够熟悉，无法说明在现有评分和比赛得分的情况下更新平均值/sigma 的更新内容。这会是什么样子？]]></description>
      <guid>https://stats.stackexchange.com/questions/654127/rating-update-algorithm-for-doubles-pickleball</guid>
      <pubDate>Mon, 09 Sep 2024 20:56:15 GMT</pubDate>
    </item>
    <item>
      <title>比较两个散点图矩阵之间的线性斜率</title>
      <link>https://stats.stackexchange.com/questions/654110/comparing-linear-slopes-between-two-scatterplot-matrices</link>
      <description><![CDATA[下面是可重现的代码示例，它生成的数据集和图表与我正在处理的大致相似。数据集由多列基因转录本丰度值和一列二元处理变量组成。
library(GGally)
library(ggplot2)
set.seed(123)
n &lt;- 30 

treatment &lt;- factor(rep(c(&quot;Group1&quot;, &quot;Group2&quot;), each = n)) #二元分组变量 

col1_group1 &lt;- rnorm(n, mean = 50, sd = 15) 
col1_group2 &lt;- rnorm(n, mean = 50, sd = 8)

col2_group1 &lt;- 0.6 * col1_group1 + rnorm(n, sd = 7)
col2_group2 &lt;- 0.4 * col1_group2 + rnorm(n, sd = 4)
col3_group1 &lt;- 0.5 * col1_group1 + rnorm(n, sd = 7)
col3_group2 &lt;- 0.3 * col1_group2 + rnorm(n, sd = 4)
col4_group1 &lt;- 0.7 * col2_group1 + rnorm(n, sd = 7)
col4_group2 &lt;- 0.5 * col2_group2 + rnorm(n, sd = 4)
col5_group1 &lt;- 0.8 * col3_group1 + rnorm(n, sd = 7)
col5_group2 &lt;- 0.6 * col3_group2 + rnorm(n, sd = 4)
col6_group1 &lt;- 0.6 * col4_group1 + rnorm(n, sd = 7)
col6_group2 &lt;- 0.4 * col4_group2 + rnorm(n, sd = 4)

dat &lt;- data.frame(
treatment = treatment,
col1 = c(col1_group1, col1_group2),
col2 = c(col2_group1, col2_group2),
col3 = c(col3_group1, col3_group2),
col4 = c(col4_group1, col4_group2),
col5 = c(col5_group1, col5_group2),
col6 = c(col6_group1, col6_group2))

ggpairs(dat, columns = 2:7, 
lower = list(continuous = wrap(&quot;smooth&quot;, method = &quot;lm&quot;, se=FALSE)),
diag = NULL, switch = &quot;both&quot;, ggplot2::aes(colour = treatment))


在我进一步详细描述我想要实现的目标之前，先介绍一下数据的几个关键特征：

这些基因都在某种程度上相互关联，因此并不相互独立（即具有多个基因预测因子的模型存在显著的多重共线性问题）
在可视化按治疗分组的基因之间的双变量关系时，很明显 A 组和 B 组具有相等的相关性和不相等的协方差（我在我的真实数据集中也有统计证据，通过 cortest.mat() 对来自心理学包和 Box 的 M 检验的非配对样本进行分析）。不平等的协方差给许多模型方法带来了另一个问题。
所有基因都是正态分布的

现在，我感兴趣的是测试第 1 组的斜率矩阵是否等于第 2 组的斜率矩阵。好吧，更具体地说，在我的真实数据集中，我实际上想测试第 1 组中某个基因相对于其余基因的斜率向量 (?) 是否等于第 2 组的斜率向量，因为当我可视化真实数据时，这种趋势对我来说非常明显，并且这种趋势可能具有生物学相关性。但我认为我对这个更具体问题的解决方案可能来自比较矩阵的方法。
其他一些想法：

我了解交互项和对比的工作原理。我对为每个基因运行单独的 lm(col_2~col_1*treatment, data=dat) 不感兴趣。无论如何，这可能会造成共线性问题，因为治疗会影响所有基因。由于我的样本量很小，所以我也希望最大化统计能力，这就是为什么我希望测试尽可能多地使用数据。
虽然多元多元回归方法确实在一次测试中使用了所有数据，乍一看似乎很有希望（即 lm(c(col_2,col_3,col_4,col_5)~col_1*treatment, data=dat)），但不平等的协方差在这里是一个重大问题。共线性仍然是一个潜在的问题。
这并不是最好的逻辑（原谅我，我是生物学家，不是统计学家），但如果可以比较两个矩阵的协方差，那么考虑到斜率与协方差直接相关，比较斜率难道不应该是这个的简单扩展吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/654110/comparing-linear-slopes-between-two-scatterplot-matrices</guid>
      <pubDate>Mon, 09 Sep 2024 15:57:03 GMT</pubDate>
    </item>
    <item>
      <title>如何确定因素和相互作用内的显著差异？</title>
      <link>https://stats.stackexchange.com/questions/654100/how-can-i-determine-significant-differences-within-factors-and-interaction-effec</link>
      <description><![CDATA[我的研究结构如下（虚假信息，相同想法）：
因素 A：3 个水平（3 种细菌菌株）
因素 B：3 个水平（3 种抗菌剂）
因素 C：2 个水平（细菌生长阶段：早期、老年）
因素 D：6 个水平（抗菌剂剂量：5、10、15、20、25、30 毫克）
感兴趣的测量：存活人口，$X$
我想知道：

当考虑因素 A 或因素 B 时，因素 C 是否会显著影响存活人口的测量，$X$？
当比较因素的 3 个水平时A（或因子 B），存活的种群中是否存在显著差异，$X$？

我的直觉是将数据分成子集并进行多次方差分析，以比较因子 A 和因子 B 在每个剂量（因子 D）下的效果。并通过进行多次 t 检验来比较两种治疗水平。但我觉得这是错的。我从来没有使用过“复杂”（对我来说）的模型，感觉很迷茫。
编辑：所以这是一个剂量反应实验，我想我说得太模糊了。我们正在测量对数减少计数（CFU/ml），两个生长阶段（因子 C）是 18 小时指数和 48 小时平稳，因此每个菌株从相同的初始肉汤培养物同时传代培养到两个生长组 18 小时和 48 小时。然后在暴露时，将每种培养物分装到 7 个（对照和 6 个剂量水平）单独的培养皿中，暴露于抗菌剂，然后测量菌落形成单位 (cfu) 计数。我们正在比较对照的对数减少值]]></description>
      <guid>https://stats.stackexchange.com/questions/654100/how-can-i-determine-significant-differences-within-factors-and-interaction-effec</guid>
      <pubDate>Mon, 09 Sep 2024 13:37:14 GMT</pubDate>
    </item>
    <item>
      <title>广义特征值、矩阵距离、信息几何的解释</title>
      <link>https://stats.stackexchange.com/questions/651758/interpretation-of-generalized-eigenvalues-matrix-distance-information-geometry</link>
      <description><![CDATA[这个问题是关于两个协方差矩阵的广义特征值与它们相关的高斯分布的可辨别性之间的关系。
两个对称矩阵$(\pmb{A}, \pmb{B})$的广义特征值问题是$\pmb{A}\pmb{\Phi} = \pmb{B}\pmb{\Phi}\pmb{\Lambda}$，其中$\pmb{A}$和$\pmb{B}$是对称的$n \times n$ 个矩阵，$\pmb{\Phi} = [\Phi_1, ..., \Phi_n]$ 是一个 $n \times n$ 矩阵，其列是广义特征向量 $\Phi_i$，而 $\pmb{\Lambda}= \mathrm{diag}(\lambda_1, ..., \lambda_n)$ 是一个具有广义特征值的对角矩阵（其中 $\lambda_i \geq \lambda_{i+1}$）。结果与矩阵 $\pmb{B}^{-1}\pmb{A}$ 的常规特征值和特征向量相同。由于 $\pmb{B}^{-1}\pmb{A}$ 通常不对称（尽管它仍然是正定的），因此特征向量 $\Phi_i$ 不一定是正交的。
广义特征值问题与分布之间的可辨别性有关。假设向量 $\pmb{x}$ 是两个分布的混合，由变量 $y \in \{1, 2\}$ 索引。我们如何才能确定两个分布中的哪一个生成了 $\pmb{x}$ 的实例？我们可以使用由 $(\pmb{v}^T\pmb{x})^2$ 提供的二次特征，其中 $||\pmb{v}||=1$。 $\pmb{v}$ 区分两个分布的能力由预期值的比率来衡量
$$R(\pmb{v}) = \frac{\mathbb{E}\left[ (\pmb{v}^T \pmb{x})^2 | y=1\right]}{\mathbb{E}\left[ (\pmb{v}^T \pmb{x})^2 | y=2\right]} = \frac{\pmb{v}^T\pmb{\Sigma_1}\pmb{v}}{\pmb{v}^T\pmb{\Sigma_2}\pmb{v}}$$
事实证明，最大化$R$的$\pmb{v}$由$(\pmb{\Sigma_1},\pmb{\Sigma_2})$的第一个广义特征向量给出，而$R$的值由其相关的特征值给出（查看上面的参考资料）。因此，广义特征值说明了二次判别器如何判别两个分布。
有趣的是，对于 0 中心高斯分布，分布之间的 Fisher-Rao 距离（其度量衡量分布的局部变化的可判别性）由 $\sum_{i=1}^{i=n} (\log \lambda_i)^2$ 给出，其中 $\lambda_i$ 是广义特征值。这也是对称正定 (SPD) 矩阵流形中的仿射不变距离。
因此，考虑到以上所有情况，我的问题如下。很明显，一对协方差矩阵的各个 $\lambda_i$ 如何反映它们的 0 均值高斯沿相应 $\Phi_i$ 的可辨别性。但是，我不太清楚所有特征值加在一起代表什么。数量 $\sum_{i=1}^{i=n} (\log \lambda_i)^2$ 清楚地概括了一些东西，并且直观地看出它如何将 $\lambda_i$ 与 1 相加。但我还想知道不同的 $\Phi_i$ 不正交是如何解释的。关于一对协方差的广义特征值的完整集合与其可辨别性之间的关系，是否可以说得更严格一些？]]></description>
      <guid>https://stats.stackexchange.com/questions/651758/interpretation-of-generalized-eigenvalues-matrix-distance-information-geometry</guid>
      <pubDate>Thu, 25 Jul 2024 15:35:22 GMT</pubDate>
    </item>
    </channel>
</rss>