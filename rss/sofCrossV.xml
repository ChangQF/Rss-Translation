<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 31 Jul 2024 00:55:55 GMT</lastBuildDate>
    <item>
      <title>如何正确计算百分比的平均数？</title>
      <link>https://stats.stackexchange.com/questions/652044/how-to-correctly-average-percentages</link>
      <description><![CDATA[我正在处理基因组数据；百分比拼接 (psi) 值可以通过包含计数与排除计数的比例找到。为了获得样本的平均 psi 值，我只是计算百分比的平均值，现在我意识到这是错误的，因为它们不是来自相等的权重。
我是一个纯粹的“计算人”，不太擅长统计，所以我只是把东西扔进去，看看结果。分数 2（z 标准化 psi 的平均值）和分数 4（psi 的几何平均值）在实际数据中效果最好；我通过将另一个测量值与分数关联起来来实现这一点。我希望并感谢你们指导我正确的方法，也许解释为什么它是正确的。也欢迎提出更复杂的方法（也许是 Cohen D？）。非常感谢。实际数据非常嘈杂且庞大，下面是我在 R 中尝试的一个例子：
inc &lt;- data.frame(sampleA = c(1755,175 ,11 ,35),
sampleB = c(1500,199,15,20),
sampleC = c(1768,900,122,60),
sampleD = c(1808,881,123,65))

exc &lt;- data.frame(sampleA = c(11311,706 ,257 ,8900),
sampleB = c(12000,706,257,8780),
sampleC = c(2958,354,257,7000),
sampleD = c(2800,354,257,7990))
psi &lt;- inc / (inc + exc)

得分1 &lt;- colMeans(psi)
得分2 &lt;- colMeans(t(scale(t(psi))))
得分3 &lt;- colSums(inc)/(colSums(inc)+colSums(exc))
geometric.mean &lt;- function(x,na.rm=TRUE){exp(mean(log(x),na.rm=na.rm))} 
得分4 &lt;- apply(psi, 2, geometry.mean)

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/652044/how-to-correctly-average-percentages</guid>
      <pubDate>Wed, 31 Jul 2024 00:41:01 GMT</pubDate>
    </item>
    <item>
      <title>关于具有负二项分布的多元广义回归混合模型</title>
      <link>https://stats.stackexchange.com/questions/652041/about-multivariate-generalized-regression-mixed-models-with-negative-binomial-di</link>
      <description><![CDATA[我有一个关于封锁前和封锁期间接触模式的个体内变化的研究问题。我将解释接触模式的定义以及我用测试数据构建的模型。我的问题是，我不确定我构建的模型是否可以回答研究问题。
接触模式是指特定年龄、位置分层的接触率。这里有一个图表可能会给你一些提示。
。
我将接触次数和位置作为结果，因为这是计数数据，其分布是右偏的。所以我的选择有三个：1）具有泊松分布的多元广义线性混合模型，2）具有负二项分布的多元广义回归混合模型，3）具有负二项分布的多元广义回归混合模型。经过对比AIC，我选择的模型是第二个。
下面是测试数据和我使用R建立的模型。
data &lt;- data.frame(
contacts_education = rpois(100, lambda = 5),
contacts_work = rpois(100, lambda = 10),
contacts_household = rpois(100, lambda = 8),
contacts_others = rpois(100, lambda = 3),
token = rep(as.character(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;)), each = 20), 
age = rep(c(56, 77, 15, 32, 27), each = 20),
sex =因子（样本（c（&quot;男性&quot;, &quot;女性&quot;），100，替换 = TRUE）），
hh_size = rnorm（100，平均值 = 3，标准差 = 1），
city = 因子（样本（c（&quot;城市A&quot;, &quot;城市B&quot;, &quot;城市C&quot;），100，替换 = TRUE）），
period = 因子（样本（c（&quot;1&quot;, &quot;2&quot;, &quot;3&quot;），100，替换 = TRUE））
)

data_long &lt;- data %&gt;%
pivot_longer（cols = starts_with（&quot;联系人&quot;），
names_to = &quot;位置&quot;，
values_to = &quot;num_contacts&quot;）

nb_model &lt;- glmmTMB(num_contacts ~ period * location * (I(age/100) + sex + I(hh_size) + city) + (1 | location) + (1|token ) + (1|city), 
family = nbinom2, 
data = data_long)

这里，token 是参与者 id，age 是参与者年龄，sex 是参与者性别，hh_size 是家庭规模。因为研究问题是关于个体内变异，所以我只包括至少在两个时间点报告联系信息的参与者，即使他们处于同一时期。period 指的是封锁前、封锁期间（受季节影响）和封锁期间。]]></description>
      <guid>https://stats.stackexchange.com/questions/652041/about-multivariate-generalized-regression-mixed-models-with-negative-binomial-di</guid>
      <pubDate>Tue, 30 Jul 2024 23:57:09 GMT</pubDate>
    </item>
    <item>
      <title>包含所有观测因素的状态空间模型</title>
      <link>https://stats.stackexchange.com/questions/652040/state-space-model-with-all-observed-factors</link>
      <description><![CDATA[我见过当我们想要揭示潜在/未观察到的因素时实施的状态空间模型，这些因素共同解释了因变量时间序列的动态。我也见过混合了可观察和未观察因素的状态空间模型。拟合一个所有因素都可观察的状态空间模型是否有意义？这意味着我有一个因子 f_t 的数据矩阵 X，我想拟合一个状态空间模型，其中的因子遵循 AR(1) 过程，然后从给定 f_t 的 f_t+1 分布中抽样。]]></description>
      <guid>https://stats.stackexchange.com/questions/652040/state-space-model-with-all-observed-factors</guid>
      <pubDate>Tue, 30 Jul 2024 23:35:03 GMT</pubDate>
    </item>
    <item>
      <title>高斯数据无监督聚类的损失函数</title>
      <link>https://stats.stackexchange.com/questions/652039/loss-functions-for-unsupervised-clustering-of-gaussian-data</link>
      <description><![CDATA[我得到了由 $n$ 个具有不同均值和协方差的多元高斯分布生成的数据，这意味着它们是可分离的，我的任务是使用神经网络以无监督的方式对它们进行分类，也就是说不使用真实标签。
我想创建一个简单的 DNN 并定义一个损失函数，该函数根据诸如簇之间的距离、簇协方差等指标对当前批次的模型预测进行评分。
这里我遗漏了什么典型损失函数吗？我在文献中找不到任何东西。此外，如果我知道数据是从不同的分布（不是高斯分布）生成的，它将如何影响损失函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/652039/loss-functions-for-unsupervised-clustering-of-gaussian-data</guid>
      <pubDate>Tue, 30 Jul 2024 22:58:02 GMT</pubDate>
    </item>
    <item>
      <title>给定一个预测变量 $x$，在什么情况下，你会得到较高的 $R^2$ 但较低的 $\beta$</title>
      <link>https://stats.stackexchange.com/questions/652036/given-a-predictor-x-under-what-circumstance-would-you-have-high-r2-but-low</link>
      <description><![CDATA[假设我有一个时间序列 $y$ 和一个预测变量 $x$。假设它们都以零为中心。
$$R^2 = 1 - \frac{ \sum (y_i - x_i)^2 }{\sum y_i^2}$$
现在我运行一个新的回归 $y \sim \beta x$，试图“重新调整”我的预测变量。
$\beta = \frac{\operatorname{cov}(x,y)}{\operatorname{var}(x)} = \frac{\sum x_i y_i}{\sum x_i^2}$
我想找到 $\beta$ 和 $R^2$ 之间的关系 （请注意，此 $R^2$ 是我在上面计算的 $R^2 = 1 - \frac{ \sum (y_i - x_i)^2 }{\sum y_i^2}$，而不是我的新回归的 $R^2$，它产生了 $\beta$，$x$ 已经是一个预测因子 )
我的假设是 $\beta = 1$ 时 $R^2$ 最大化。因为这意味着我的预测因子 $x$ 是“尺度良好的”。但我很难证明这一点……如果这不是真的，为什么当我的预测变量是“最佳缩放”时，$R^2$ 不会最大化？
$$\sum x_i y_i = \beta \sum x_i^2,$$
插入
\begin{align}
R^2 &amp; = 1 - \frac{ \sum (y_i - x_i)^2 }{\sum y_i^2} \\[6pt] &amp; = 1 - \frac{ \sum x_i^2 - 2\sum x_i y_i + \sum y_i^2 }{\sum y_i^2} \\[6pt] &amp; = 2 \sum x_i y_i - \sum x_i^2 = (2\beta-1) \sum x_i^2。
\end{align&gt;
没有任何迹象表明 $\beta = 1$ 时 $R^2$ 最大化，但正如我所提到的，不确定为什么当我的预测器“最佳缩放”时 $R^2$ 没有最大化？]]></description>
      <guid>https://stats.stackexchange.com/questions/652036/given-a-predictor-x-under-what-circumstance-would-you-have-high-r2-but-low</guid>
      <pubDate>Tue, 30 Jul 2024 22:09:04 GMT</pubDate>
    </item>
    <item>
      <title>规范化实时数据</title>
      <link>https://stats.stackexchange.com/questions/652034/normalizing-live-data</link>
      <description><![CDATA[我正在研究一个使用孤立森林检测实时数据异常的模型，但我不确定应该使用哪种方法来实时规范化它。我正在研究使用窗口的 MinMax 缩放，但这似乎不是最佳选择，可能会出现问题。我有超过 700 个数据集，它们的最大值从不到 10 到大约 115 不等。对于孤立森林模型来说，规范化这些数据的最佳方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652034/normalizing-live-data</guid>
      <pubDate>Tue, 30 Jul 2024 21:41:53 GMT</pubDate>
    </item>
    <item>
      <title>方程线性混合模型 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/652031/equation-linear-mixed-models</link>
      <description><![CDATA[如何在 R 中估算此方程？https://www.sciencedirect.com/science/article/pii/S1751731119001848?via%3Dihub
$$
Y_{ij} = \beta_1 \cdot \text{year}_{ij} + \beta_2 \cdot \text{herd}_{ij} + \beta_3 \cdot \text{system}_{ij} + \beta_4 \cdot \text{HS}_{ij} + (\text{system} \times \text{herd})_{ij} + \epsilon_{ij}
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/652031/equation-linear-mixed-models</guid>
      <pubDate>Tue, 30 Jul 2024 19:29:47 GMT</pubDate>
    </item>
    <item>
      <title>比较治疗/事件前后动态组中的平均值</title>
      <link>https://stats.stackexchange.com/questions/652030/compare-the-means-in-a-dynamic-group-before-and-after-a-treatment-event</link>
      <description><![CDATA[我想看看在疫情爆发期间取消预防措施是否会导致更多病例或延长疫情爆发时间。
我有 6 个中心（随着居民随时间变化，中心会动态变化），每个中心都发生过 4 到 10 次疫情。
对于每个中心，我都有过去 2 年中每次疫情的病例数和每次疫情的持续时间（天）。现在，我们将取消预防措施，并在取消预防措施后最多 6 个月收集相同的数据。我打算计算 3 个指标：疫情的平均持续时间、每次疫情受影响的平均居民人数和每天的平均病例数。我想测试每个中心在事件发生前后（取消措施）的这些指标是否相同。我想知道我应该使用哪种类型的测试。
我已经检查了测量值抑制前的数据的正态性（直方图、qqplot 和 Shapiro-Wilk 正态性检验），对于大多数中心，指标的分布都是正态的。
我可以计算两组的方差（测量值抑制前后）。
我认为这两组不是独立的，因为我比较的是相同的中心。我可以计算第一组的方差（测量值抑制前），所以我可以对正态分布的数据使用 Z 检验吗？或者在这种情况下，单样本 T 检验更合适吗？对于非正态分布的数据，我可以使用什么（我读过 Mann-Whitney 检验或 Wilcoxon 检验）？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/652030/compare-the-means-in-a-dynamic-group-before-and-after-a-treatment-event</guid>
      <pubDate>Tue, 30 Jul 2024 19:25:48 GMT</pubDate>
    </item>
    <item>
      <title>混合模型的经验法则</title>
      <link>https://stats.stackexchange.com/questions/652027/rule-of-thumb-for-mixed-model</link>
      <description><![CDATA[假设我们有 $n$ 个 $(X,Y)$ 对的观测值，其中 $X$ 是实数（可能是向量），而 $Y$ 是实数。我们想要一个线性模型。一个经验法则是，除截距外，可学习参数的数量不应超过 $\frac{n}{10}$。并不是说如果每个可学习参数只有 $9$ 个观测值，我们就不会这样做，但这是一种防止过度拟合的方法。
混合模型是否有类似的经验法则？举一个简单的例子，假设 $X \in \mathbb{R}^n$ 和 $Y \in \mathbb{R}^n$ 是数据，我们得到一个名为 patient 的类，它是一个 factor，级别为 $k$。我们希望进行随机截距：
lmer(Y ~ X + 1 |patient)

是否有类似的经验法则可以防止关于可学习参数数量、$n$、$k$ 和每个患者的观察次数的过度拟合？]]></description>
      <guid>https://stats.stackexchange.com/questions/652027/rule-of-thumb-for-mixed-model</guid>
      <pubDate>Tue, 30 Jul 2024 18:51:22 GMT</pubDate>
    </item>
    <item>
      <title>关于面板数据分析包的建议：plm、ivreg 还是 fixest？</title>
      <link>https://stats.stackexchange.com/questions/652025/advice-on-panel-data-analysis-packages-plm-ivreg-or-fixest</link>
      <description><![CDATA[我目前正在从事一个涉及不平衡面板数据的项目，我预计需要使用工具变量 (IV) 和/或广义矩法 (GMM)。为此，我一直在探索各种 R 包，包括 plm（及其 pgmm 扩展）、ivreg（用于面板数据），我也听说 fixest 很好用。
鉴于我需要使用 Within 和 First Difference 估计量并仔细检查模型的第一阶段，我正在寻找有关使用哪个包的建议。
您建议使用哪个包，为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652025/advice-on-panel-data-analysis-packages-plm-ivreg-or-fixest</guid>
      <pubDate>Tue, 30 Jul 2024 17:41:21 GMT</pubDate>
    </item>
    <item>
      <title>确定两组线（预矢量）的方向是否不同</title>
      <link>https://stats.stackexchange.com/questions/652021/determine-if-two-sets-of-lines-pre-vectors-are-different-in-their-orientation</link>
      <description><![CDATA[给出两组与方向相对应的矢量。这些矢量来自材料各向异性张量的特征值，并给出某些材料的主方向。
这些矢量具有两个重要属性：1) 它们始终是单位矢量，即 $|v|=1$ 和 2) 矢量的符号未定义，即 $v = -v$。对于后一个属性，Benger &amp; Hege 也称这些向量为 pre-vectors1。
现在我想知道这两个组在统计上是否有差异，也就是说，粗略地说，我想知道这两个组之间的方向是否不同。
在 Barak et al.2 的论文中，他们使用了这样的方向，并对两个组的单位球面上的质心距离进行了置换测试以确定差异。然而，这种方法只有在所有方向向量本身都“对齐”的情况下才有效。否则，计算出的质心是不正确的。
下面是一些 Python 代码，用于生成一组这样的向量来说明问题：
import numpy as np
import matplotlib.pyplot as plt

n = 10
def generate_random_vectors(theta, phi, n):
# 对选定角度进行正常扰动
pertub_t, pertub_p = np.random.normal(0, 0.15, (2, n))
# 随机翻转符号
flip = np.random.choice([-1, 1], (n, ))
t = theta + pertub_t
p = phi + pertub_p
return flip * np.array([
np.sin(t) * np.sin(p),
np.sin(t) * np.cos(p),
np.cos(t),
])

# 实际点
a_t, a_p = np.deg2rad(60), np.deg2rad(30)
b_t, b_p = np.deg2rad(20), np.deg2rad(10)

## --&gt;这些是预向量/方向
a = generate_random_vectors(a_t, a_p, n)
b = generate_random_vectors(b_t, b_p, n)

# 绘图...
fig = plt.figure(figsize=(5, 5))
ax = fig.add_subplot(111,projection=&#39;3d&#39;)
X, Y, Z = np.zeros((3, n))
# 绘制向量
ax.quiver(X, Y, Z, *a, color=&#39;blue&#39;)
ax.quiver(X, Y, Z, *b, color=&#39;red&#39;)

# 绘制实际点
x, y, z = np.sin(a_t) * np.sin(a_p), np.sin(a_t) * np.cos(a_p), np.cos(a_t)
ax.scatter([x], [y], [z], color=&#39;blue&#39;, s=80)
x, y, z = np.sin(b_t) * np.sin(b_p), np.sin(b_t) * np.cos(b_p), np.cos(b_t)
ax.scatter([x], [y], [z], color=&#39;red&#39;, s=80)

ax.set_xlim([-1, 1])
ax.set_ylim([-1, 1])
ax.set_zlim([-1, 1])
plt.tight_layout()
plt.show()

例如，此结果如下图所示：

如您所见，向量捆绑在一起，但有些向量指向“错误”的方向。在此示例中，两个捆绑明显分开。
我尝试对齐各个向量，例如通过将点积与其中一个轴向量进行比较（例如 $(0,0,1)$），但这总是为某些特殊情况留下空间。
因此，我的问题一般是：统计上比较此类预向量的正确方法是什么？
假设 Barak et al. 使用的方法效果很好，目标是能够正确计算此类预向量的质心。因此，另一种答案也可以是回答这个问题：有什么方法可以在两个组的单位球面上构建质心，而不会产生由向量符号引起的问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/652021/determine-if-two-sets-of-lines-pre-vectors-are-different-in-their-orientation</guid>
      <pubDate>Tue, 30 Jul 2024 16:24:44 GMT</pubDate>
    </item>
    <item>
      <title>将单独评估的总分数结合起来以评估干预收益是否合理？</title>
      <link>https://stats.stackexchange.com/questions/652020/is-it-defensible-to-combine-total-scores-from-separate-assessments-to-assess-int</link>
      <description><![CDATA[我进行了两次评估，每次评估有 28 个多项选择题，样本量总计约 180 名学生。两次评估均在干预前和干预后对学生进行。两次评估均相同，但有些题目经过了调整以尽量减少记忆效应。在我们的干预研究中，学生被随机分配到对照组和实验组。
在分别评估每次评估的干预收益后，我想计算两次评估的平均分数，并以此方式检查收益，因为我认为平均分数更可靠，因为其中包含了更多数据。此外，从理论上讲，我认为评估会利用相关的知识结构。但是，我想通过以下方式证明合并的决定是合理的，并且我很想听听你们的意见，看看我的做法是否合理，以及在使用平均分数检查学生从干预中获得的收益之前，我是否还应该考虑其他事情。

我在两个评估期间检查了两次评估总分之间的皮尔逊相关性。评估前为 0.61，评估后为 0.62。
我计算了一个四分法相关矩阵（之所以是四分法，是因为项目被评为正确/不正确），并且没有明显的模式表明一次评估中的项目比评估之间的项目具有更高的相关性。说实话，由于项目太多，长时间盯着这个相关矩阵也很难。于是我转向下一步，即 CFA。
我进行了两次 CFA：模型 1：我将所有 56 个项目放入单因素模型中。顺便说一句，我在 lavaan 中使用了 DWLS 估计器，因为项目是二进制的。模型 2，其中 28 个项目进入评估 A 的一个因素，其余进入评估 B 的第二个因素。然后我使用 lavTestLRT 函数比较了两者之间的模型拟合度，发现单模型因子在两个时间点的拟合度都明显优于双因素模型。

我有两个问题：(1) 您认为上述分析和结果是否提供了使用平均分数的充分理由，并允许我以这种方式检查干预收益？如果答案是否定的，我还应该考虑和做什么？(2) 如果可能，您能否确认 lavTestLRT 函数可用于具有二进制数据的模型的模型比较？我不明白为什么不行，但我想确认一下，因为这是我第一次处理二进制数据。
非常感谢您的阅读以及您提供的任何意见！]]></description>
      <guid>https://stats.stackexchange.com/questions/652020/is-it-defensible-to-combine-total-scores-from-separate-assessments-to-assess-int</guid>
      <pubDate>Tue, 30 Jul 2024 15:52:06 GMT</pubDate>
    </item>
    <item>
      <title>对 p 值和 Cohen's d 感到困惑</title>
      <link>https://stats.stackexchange.com/questions/652003/confused-about-the-p-value-and-cohens-d</link>
      <description><![CDATA[我有以下代码，用于计算 p 值和 cohen 距离。
import numpy as np
from scipy.stats import ttest_ind

# 计算 Cohen 的 d
def calculate_cohens_d(group1, group2):
mean_group1 = np.mean(group1)
mean_group2 = np.mean(group2)
std_group1 = np.std(group1, ddof=1)
std_group2 = np.std(group2, ddof=1)
n_group1 = len(group1)
n_group2 = len(group2)
pooled_std = np.sqrt(((n_group1 - 1) * (std_group1 ** 2) + (n_group2 - 1) * (std_group2 ** 2)) / (n_group1 + n_group2 - 2))
cohen_d = (mean_group1 - mean_group2) / pooled_std
return cohen_d

# 模拟数据并执行 t 检验和 Cohen&#39;s d 计算的函数
def perform_experiment():
# 模拟数据
group1_EXP = np.random.normal(80, 10, 10)
group2_EXP = np.random.normal(81, 10, 10)

# 执行多重 t 检验
_, p_value_EXP = ttest_ind(group1_EXP, group2_EXP)
cohen_d_EXP = calculate_cohens_d(group1_EXP, group2_EXP)

return p_value_EXP, cohen_d_EXP


如果我使用给定的种子运行代码两次：
# 可重复性的种子
np.random.seed(42)

# 执行 2 次实验
p_value_EXP, cohen_d_EXP = perform_experiment()
print(f&#39;p-value: {p_value_EXP:.4f}, Cohen\&#39;s d: {cohen_d_EXP:.4f}&#39;)

p_value_EXP, cohen_d_EXP = perform_experiment()
print(f&#39;p-value: {p_value_EXP:.4f}, Cohen\&#39;s d: {cohen_d_EXP:.4f}&#39;)

我得到：
p-value: 0.0029， Cohen 的 d：1.5402
p 值：0.9792，Cohen 的 d：-0.0118

因此可以说，第一个实验的 p 值为 0.0029，Cohen 距离“较大”，是显著的。
相比之下，我会说第二个实验并不那么重要。
现在，如果我运行 1,000 次模拟
# 执行 1000 次实验

n_simulations = 1000

p_values_EXP = np.zeros(n_simulations)

cohen_ds_EXP = np.zeros(n_simulations)

for i in range(n_simulations):
p_values_EXP[i], cohen_ds_EXP[i] = perform_experiment()

# 计算 p 值 &gt; 的比例0.05
prop_p_value_EXP_greater_0_05 = np.mean(p_values_EXP &gt; 0.05)

print(&quot;Proportion of p-values &gt; 0.05:&quot;, prop_p_value_EXP_greater_0_05)

我得到
Proportion of p-values &gt; 0.05: 0.951

这意味着更有可能观察到不显著的结果。但前 2 个实验显示相反的结果。
因此，我不确定在这种情况下 Cohen 距离的用处。]]></description>
      <guid>https://stats.stackexchange.com/questions/652003/confused-about-the-p-value-and-cohens-d</guid>
      <pubDate>Tue, 30 Jul 2024 12:20:20 GMT</pubDate>
    </item>
    <item>
      <title>对数尺度图中的相对误差线与绝对误差线</title>
      <link>https://stats.stackexchange.com/questions/651983/relative-vs-absolute-error-bars-in-log-scaled-plots</link>
      <description><![CDATA[关于在对数刻度图上显示误差线的正确方法，看似知识渊博的来源提供了相互矛盾的信息。

$log_{10}(x \pm \Delta x)$ 显示绝对误差。一方面，它很容易解释：如果我们以某种概率知道 $x$ 在 $\vert x - \Delta x, x + \Delta x \vert$ 内，那么对数转换后该概率不会改变。我们可以读取刻度标记并轻松了解间隔。另一方面，当 $\Delta x$ 接近 $x$ 时，误差线看起来不对称，各种来源都认为这是不好的（有时没有解释，有时因为它在视觉上暗示该值低于平均值的概率大于高于平均值的概率）。对于 $\Delta x \ge x$，下部误差线部分将延伸出图外。

$x \pm \frac{\Delta x}{x \ln 10}$ 使用不确定性传播显示相对误差。误差线在视觉上是对称的。但我不明白当根据刻度线读取时，您应该如何解释长度。


例如：

这里，第一个点（蓝色）的 $x = 8000$ 和 $\Delta x = 7000$，第二个点的 $x = 5000$ 和 $\Delta x = 500$第二（黄色）。当 $\Delta x \ll x$（黄色）时，两种方法基本无法区分。当 $\Delta x \approx x$（蓝色）时，条形图显示范围从 3,335 到 19,190。 您应该如何解释这些数字？
显示误差线的正确方法是什么？为什么？

各种来源：

Eric Stuve 的讲座
https://physics.stackexchange.com/q/95254/31907（请注意，我对我的评论中的第二个答案也感到困惑）
对数-对数图上的相对误差
]]></description>
      <guid>https://stats.stackexchange.com/questions/651983/relative-vs-absolute-error-bars-in-log-scaled-plots</guid>
      <pubDate>Tue, 30 Jul 2024 03:30:15 GMT</pubDate>
    </item>
    <item>
      <title>均匀分布中的无偏估计量</title>
      <link>https://stats.stackexchange.com/questions/651951/unbiased-estimators-in-uniform-distributions</link>
      <description><![CDATA[变量 $x$ 在区间 $(a-1,a+1)$ 内均匀分布，其中 $a$ 的值未知。对 $x$ 的一次观察给出了值 $x_1$。
如何（有证据）使用 $x_1$ 的这个值来确定 $a$ 的无偏估计，并确定 $a$ 的 $99\%$ 置信限度？
我知道
$$E(x)=\frac{\int_{a-1}^{a+1} xf(x) \;\mathrm{d}x}{\int_{a-1}^{a+1} f(x) \;\mathrm{d}x}=a$$但接下来该怎么做呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/651951/unbiased-estimators-in-uniform-distributions</guid>
      <pubDate>Mon, 29 Jul 2024 16:07:54 GMT</pubDate>
    </item>
    </channel>
</rss>