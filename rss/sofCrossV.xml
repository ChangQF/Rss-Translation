<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 10 Sep 2024 15:17:03 GMT</lastBuildDate>
    <item>
      <title>PCA 是否可以最大化数据点之间的成对距离？</title>
      <link>https://stats.stackexchange.com/questions/654159/does-pca-maximize-pairwise-distance-between-data-points</link>
      <description><![CDATA[我们有一个点数据集 $x_i$，其中 $x_i \in \mathbb{R}^n$。如果我们对保留 $k$ 个分量的数据集进行 PCA，则投影到 $k$ 个分量上的结果点 $y_i$ 将最大化向量与均值的平方距离（即 PCA 最大化保留的方差）。如果平均值$\bar{x}=0$，则 PCA 最大化范数平方和$\sum_i \|y_i \|^2$。
直观地讲，最大化点到平均值的总平方距离$\sum_i \|y_i - \bar{y} \|^2$似乎与最大化点之间的成对平方距离$\sum_i \sum_j \|y_i - y_j \|^2$有关。我尝试通过代入 $\bar{y} = \frac{1}{n}\sum_j y_j$ 来查看这两个“目标”是否等价，但得到的公式并不相同，因此目标并不等价。因此，PCA 似乎并没有最大化点之间的成对平方距离。
首先，我想知道在什么条件下最大化 $\sum_i \|y_i - \bar{y} \|^2$ 和 $\sum_i \sum_j \|y_i - y_j \|^2$ 这两个目标可能会重合（即导致相同的解决方案）。其次，我想知道是否存在一些已知的降维方法来最大化成对平方距离而不是方差。
编辑：尝试证明$\sum_i \|y_i - \bar{y} \|^2$和$\sum_i \sum_j \|y_i - y_j \|^2$并不相同：
$$\sum_i \|y_i - \bar{y} \|^2 =
\sum_i \|y_i - \frac{1}{n}\sum_j y_j\|^2 = \frac{1}{n^2}\sum_i \|\sum_j \left( y_i - y_j \right)\|^2 
$$
如果我们可以将$\sum_j$置于平方范数之外，则方差公式将成比例。但似乎我们不能：
$$\|\sum_j \left( y_i - y_j \right)\|^2 =
\langle \sum_j \left( y_i - y_j \right), \sum_k \left( y_i - y_k \right) \rangle = \\
\sum_j \|y_i - y_j \|^2 + \sum_{j \neq k} \langle \left( y_i - y_j \right), \left( y_i - y_k \right) \rangle
$$
我可能遗漏了一些东西，但我不明白为什么术语$\sum_{j \neq k} \langle \left( y_i - y_j \right)、\left( y_i - y_k \right) \rangle$ 应为 0，因为方差和成对平方距离必须相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/654159/does-pca-maximize-pairwise-distance-between-data-points</guid>
      <pubDate>Tue, 10 Sep 2024 14:23:27 GMT</pubDate>
    </item>
    <item>
      <title>完全多重共线性下无限解的原因[重复]</title>
      <link>https://stats.stackexchange.com/questions/654158/reason-for-infinite-solutions-under-perfect-multicollinearity</link>
      <description><![CDATA[我想知道为什么当变量多于观测值（$p&gt;n$）时，在最小二乘估计中，正则方程$X’X\beta = X’y$会有无数个解（而不是没有解）。
我试图从向量空间和伴随算子的角度来回答这个问题，但我不知道如何进行。
如能提供提示或直接答案，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/654158/reason-for-infinite-solutions-under-perfect-multicollinearity</guid>
      <pubDate>Tue, 10 Sep 2024 14:13:01 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 和 lavaan 的混合效应 CFA</title>
      <link>https://stats.stackexchange.com/questions/654157/mixed-effects-cfa-using-r-and-lavaan</link>
      <description><![CDATA[我想进行一个包含 3 个因子和 9 个项目的 CFA。数据包含大小变化很大的聚类。（1 &lt; n &lt; 40，总共 90 个聚类，而 40 个聚类只有一个观测值）。我想以某种方式考虑聚类结构。由于聚类中的观测值数量较少，诸如稳健标准误差估计之类的常用方法可能不起作用。我正在考虑指定混合效应模型。到目前为止，我还没有找到在 R 中实现它的方法。关于如何实现这一点，有什么提示或想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654157/mixed-effects-cfa-using-r-and-lavaan</guid>
      <pubDate>Tue, 10 Sep 2024 13:58:39 GMT</pubDate>
    </item>
    <item>
      <title>通过python进行线性混合效应模型分析</title>
      <link>https://stats.stackexchange.com/questions/654156/linear-mixed-effect-model-analysis-via-python</link>
      <description><![CDATA[我想对我的研究进行线性混合效应分析。我试图了解和比较 3 种不同的干预模式对结果的影响。我对结果有 2 个衡量指标，即事前分析和事后分析。
我使用 Python 代码，但当我将其与 SPSS 结果进行比较时，结果大不相同。我想知道我是否使用了正确的代码。
这是我的变量
DV：ACC
IV：组（3），时间（2）
协变量：性别，年龄，受教育年限。
性别，组和时间是分类变量。
我使用了下面的代码
model = smf.mixedlm(
&quot;ACC ~ C(Time) * C(Group) + Age + C(Sex) + Education years&quot;,
data,
groups=data[&quot;ID&quot;]
)
result = model.fit()
您觉得如何？我应该更改某些内容吗？
提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/654156/linear-mixed-effect-model-analysis-via-python</guid>
      <pubDate>Tue, 10 Sep 2024 13:34:28 GMT</pubDate>
    </item>
    <item>
      <title>可能性平坦化</title>
      <link>https://stats.stackexchange.com/questions/654153/flattening-a-likelihood</link>
      <description><![CDATA[背景
设 $y_1,y_2,\dots,y_K$ 为测量序列。
我已经从均匀先验$p_0(i)\triangleq1/n$开始，得出了通过贝叶斯分类器解决分类问题的可能性\begin{equation}
p_k(i)=\frac{\mathcal{L}(y_k|i)\,p_{k-1}(i)}{\sum_{\nu=1}^n \mathcal{L}(y_k|\nu)\,p_{k-1}(\nu)} \qquad i=1,\dots,n
\end{equation&gt;
。 $\mathcal{L}(y_k|i)$ 的主要问题是它倾向于“过度自信”，即几乎所有类别的值都微不足道，除了一两个类别。由于这一事实，$p_k(i)$ 使用少量测量（例如两个）收敛到狄拉克分布，但无法保证渐近分布以正确的类别为中心。
简而言之，我的分类器“草率”，其最终答案往往是错误的。
解决方案
为了解决这个问题，我对可能性进行了“扁平化”变换，这往往会使 $\mathcal{L}(y|i)$ 的类别值相等。受到 softmax 分类器的启发，我考虑的转换是
\begin{equation}
\tilde{\mathcal{L}}(y|i)\triangleq \exp\left(\frac{\mathcal{L}(y|i)}{\tau}\right)
\qquad i=1,\dots,n
\end{equation&gt;
其中 $\tau&gt;0$ 是控制平坦化动作激进程度的参数。由此产生的分类器
\begin{equation}
p_k(i)=\frac{\tilde{\mathcal{L}}(y_k|i)\,p_{k-1}(i)}{\sum_{\nu=1}^n \tilde{\mathcal{L}}(y_k|\nu)\,p_{k-1}(\nu)} \qquad i=1,\dots,n
\end{equation&gt;
允许任意减慢（通过$\tau$）后验的收敛速度，这样
就可以在达到最终的狄拉克分布之前强制可视化所有测量值。通过这样做，分类器的最终答案正确的几率会增加，并且通过减慢收敛速度，分类器通常会猜出正确的类别。
问题
似然模型$\mathcal{L}(y|i)$是从用于生成测量序列的测量模型中无近似值推导出来的。从这个事实来看，我认为最好的做法（从数学和实践的角度来看）是只考虑“原始”似然$\mathcal{L}(y|i)$。
然而，“扁平化”似然$\tilde{\mathcal{L}}(y|i)$不遵循测量背后的真实测量模型，但会带来更好的性能。
我的问题如下。

是否有可能对启发式可能性$\tilde{\mathcal{L}}(y|i)$背后的测量模型进行“逆向工程”？
是否有一种严格的方法来解决我的“草率”分类器的问题？
可能性的指数通常意味着什么？

如有必要，我可以提供有关我的分类问题的更多详细信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/654153/flattening-a-likelihood</guid>
      <pubDate>Tue, 10 Sep 2024 13:15:43 GMT</pubDate>
    </item>
    <item>
      <title>训练多个二元模型而不是一个多模态模型</title>
      <link>https://stats.stackexchange.com/questions/654152/training-multiple-binary-models-instead-of-one-multimodal-model</link>
      <description><![CDATA[我正在努力预测各种 Spark 配置与基线配置相比的性能改进。我的目标是将这些预测用作优化算法（例如，贝叶斯优化或递归随机搜索）中的成本函数，以找到最佳配置。
目前，我已经训练了一个将数据分为三个百分位数的模型：

0 到 33 百分位数（第一类）。
33 到 66 百分位数（第二类）
66 百分位数以上（第三类）。

但是，我实现的最佳模型的准确率只有 62% 左右。
为了提高性能，我正在考虑一种不同的方法：
首先，使用 50 百分位数作为分割，在所有数据上训练一个通用模型。
然后，训练两个单独的模型：
模型 1：针对 0 到 25 百分位数和 25 到 50 百分位数的数据。
模型 2：针对 50 到 75 百分位数和 75 到 100 百分位数的数据。
这种针对不同百分位数范围使用单独模型的方法是否是一种可行且合乎逻辑的提高准确率的方法？还是会产生与当前多类模型类似的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/654152/training-multiple-binary-models-instead-of-one-multimodal-model</guid>
      <pubDate>Tue, 10 Sep 2024 13:11:41 GMT</pubDate>
    </item>
    <item>
      <title>我不确定在科学论文中“polytomous”在这种情况下的用法。有人能帮我找到适合这种情况的词吗？</title>
      <link>https://stats.stackexchange.com/questions/654149/i-am-not-sure-about-the-use-of-polytomous-in-this-context-in-a-scientific-pape</link>
      <description><![CDATA[这是正文：

如表 2 和图 3 所示，我们对研究中点的亚组分析在统计学上并不显著 (p=0.92)。这一发现得到了单变量和多变量随机效应元回归（表 3）的进一步支持，表明 ICP 发病率不存在线性或多分型（截止值：2005 年和 2015 年）时间模式（分别为 p=0.15 和 p=0.78）。

背景：我通过将受试者分为三类进行分析：&lt;2005、2005-2014 和 2015-2023，每组受试者之间没有差异，表明基于这种分类没有时间趋势。
我不确定这里使用的正确词是否是多分型。我尝试使用 ChatGPT 来获得更多选项，但效果不佳。我也在英语 StackExchange 上问过这个问题，但是还没有得到答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/654149/i-am-not-sure-about-the-use-of-polytomous-in-this-context-in-a-scientific-pape</guid>
      <pubDate>Tue, 10 Sep 2024 10:47:54 GMT</pubDate>
    </item>
    <item>
      <title>估计 OLS 回归中的相关特征</title>
      <link>https://stats.stackexchange.com/questions/654147/estimating-correlated-features-in-ols-regression</link>
      <description><![CDATA[我获得了相当多的样本集 $y_{i,t}$ 和 ${\beta}_{i,j,t}$，这些样本集来自其他人拟合的滚动（时间 $t$）OLS 回归，我想估计时间序列 $x_{j,t}$ :
$y_{i,t}$ = $\sum_{j=1}^{m}({\beta}_{i,j,t} x_{j,t})$ + $\alpha_{i,t}$ + $\epsilon_{t}$
$i$ 和 $j$ 分别从 $1$ 到 $n$ 和 $1$ 到 $m$ 变化，其中 $n&gt;&gt;m$
$t$ 是时间索引
$y_{i,t}$ 和 $x_{j,t}$ 可以可视化为时间序列分别为 $n$ 股票收益和 $m$ 因子收益。
$\beta_{i,j,t}$ 可以可视化为 $n$ 时间序列的 $m$ 因子暴露。这里，$\beta_{i=I,j=J,t=T}$ 可能与 $\beta_{i=I,j=J,t=T+1}$ 不同，因为它是使用上面的滚动时间序列回归方程估算的。
给定 $y_{i,t}$ 和 $\beta_{i,j,t}$ 的样本，我想估算 $m$ 个因子收益的时间序列，即 $x_{j,t}$（例如 $\hat{x}_{j,t}$）。假设原始模型的作者在拟合上述模型方面做得不错，我是否可以正确地估计$\hat{x}_{j=J,t=T}$，即因子回报$x_J$在任何给定时间$T$如下：
$\hat{x}_{j=J,t=T}$ = $\frac{Cov({\beta}_{i,j=J,t=T}, y_{i,t=T})}{Var({\beta}_{i,j=J,t=T})}$
会$\hat{x}_{j}$ 是有偏的，如果我被告知 $Corr(x_{p},x_{q}) \neq 0$ 对于所有 p, q，即 $x_j$ 存在多重共线性。如果这是有偏的，那么获得 $\hat{x}_{j, t}$ 的最佳方法是什么？
可以安全地假设不存在缩放问题，即 $x$ 和 $y$ 在同一尺度上。然而，它们是肥尾的。]]></description>
      <guid>https://stats.stackexchange.com/questions/654147/estimating-correlated-features-in-ols-regression</guid>
      <pubDate>Tue, 10 Sep 2024 10:19:24 GMT</pubDate>
    </item>
    <item>
      <title>适合月度数据的去趋势和异常方法吗？</title>
      <link>https://stats.stackexchange.com/questions/654145/proper-detrend-and-anomaly-method-for-monthly-data</link>
      <description><![CDATA[我正在尝试计算 SST（海面温度）数据的 JJA 异常。
在计算异常之前，我尝试对数据进行去趋势处理。
但是，我很困惑是否应该分别对 6 月、7 月和 8 月进行去趋势处理以获得 JJA 异常，还是根据 JJA 平均值进行去趋势处理。
我知道当我得到 JJA 异常时，我会得到每个月的异常并取平均值，但我想知道这是否也适用于去趋势。]]></description>
      <guid>https://stats.stackexchange.com/questions/654145/proper-detrend-and-anomaly-method-for-monthly-data</guid>
      <pubDate>Tue, 10 Sep 2024 10:00:49 GMT</pubDate>
    </item>
    <item>
      <title>比较两个散点图矩阵之间的线性斜率</title>
      <link>https://stats.stackexchange.com/questions/654110/comparing-linear-slopes-between-two-scatterplot-matrices</link>
      <description><![CDATA[下面是可重现的代码示例，它生成的数据集和图表与我正在处理的大致相似。数据集由多列基因转录本丰度值和一列二元处理变量组成。
library(GGally)
library(ggplot2)
set.seed(123)
n &lt;- 30 

treatment &lt;- factor(rep(c(&quot;Group1&quot;, &quot;Group2&quot;), each = n)) #二元分组变量 

col1_group1 &lt;- rnorm(n, mean = 50, sd = 15) 
col1_group2 &lt;- rnorm(n, mean = 50, sd = 8)

col2_group1 &lt;- 0.6 * col1_group1 + rnorm(n, sd = 7)
col2_group2 &lt;- 0.4 * col1_group2 + rnorm(n, sd = 4)
col3_group1 &lt;- 0.5 * col1_group1 + rnorm(n, sd = 7)
col3_group2 &lt;- 0.3 * col1_group2 + rnorm(n, sd = 4)
col4_group1 &lt;- 0.7 * col2_group1 + rnorm(n, sd = 7)
col4_group2 &lt;- 0.5 * col2_group2 + rnorm(n, sd = 4)
col5_group1 &lt;- 0.8 * col3_group1 + rnorm(n, sd = 7)
col5_group2 &lt;- 0.6 * col3_group2 + rnorm(n, sd = 4)
col6_group1 &lt;- 0.6 * col4_group1 + rnorm(n, sd = 7)
col6_group2 &lt;- 0.4 * col4_group2 + rnorm(n, sd = 4)

dat &lt;- data.frame(
treatment = treatment,
col1 = c(col1_group1, col1_group2),
col2 = c(col2_group1, col2_group2),
col3 = c(col3_group1, col3_group2),
col4 = c(col4_group1, col4_group2),
col5 = c(col5_group1, col5_group2),
col6 = c(col6_group1, col6_group2))

ggpairs(dat, columns = 2:7, 
lower = list(continuous = wrap(&quot;smooth&quot;, method = &quot;lm&quot;, se=FALSE)),
diag = NULL, switch = &quot;both&quot;, ggplot2::aes(colour = treatment))


在我进一步详细描述我想要实现的目标之前，先介绍一下数据的几个关键特征：

这些基因都在某种程度上相互关联，因此并不相互独立（即具有多个基因预测因子的模型存在显著的多重共线性问题）
在可视化按治疗分组的基因之间的双变量关系时，很明显 A 组和 B 组具有相等的相关性和不相等的协方差（我在我的真实数据集中也有统计证据，通过 cortest.mat() 对来自心理学包和 Box 的 M 检验的非配对样本进行分析）。不平等的协方差给许多模型方法带来了另一个问题。
所有基因都是正态分布的

现在，我感兴趣的是测试第 1 组的斜率矩阵是否等于第 2 组的斜率矩阵。好吧，更具体地说，在我的真实数据集中，我实际上想测试第 1 组中某个基因相对于其余基因的斜率向量 (?) 是否等于第 2 组的斜率向量，因为当我可视化真实数据时，这种趋势对我来说非常明显，并且这种趋势可能具有生物学相关性。但我认为我对这个更具体问题的解决方案可能来自比较矩阵的方法。
其他一些想法：

我了解交互项和对比的工作原理。我对为每个基因运行单独的 lm(col_2~col_1*treatment, data=dat) 不感兴趣。无论如何，这可能会造成共线性问题，因为治疗会影响所有基因。由于我的样本量很小，所以我也希望最大化统计能力，这就是为什么我希望测试尽可能多地使用数据。
虽然多元多元回归方法确实在一次测试中使用了所有数据，乍一看似乎很有希望（即 lm(c(col_2,col_3,col_4,col_5)~col_1*treatment, data=dat)），但不平等的协方差在这里是一个重大问题。共线性仍然是一个潜在的问题。
这并不是最好的逻辑（原谅我，我是生物学家，不是统计学家），但如果可以比较两个矩阵的协方差，那么考虑到斜率与协方差直接相关，比较斜率难道不应该是这个的简单扩展吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/654110/comparing-linear-slopes-between-two-scatterplot-matrices</guid>
      <pubDate>Mon, 09 Sep 2024 15:57:03 GMT</pubDate>
    </item>
    <item>
      <title>在调节分析中调节变量和因变量之间是否需要直接关系？</title>
      <link>https://stats.stackexchange.com/questions/654093/is-a-direct-relationship-between-the-moderator-and-dependent-variable-necessary</link>
      <description><![CDATA[我目前正在与一位朋友讨论回归分析中的调节效应，我想对此进行一些澄清。假设我们有兴趣通过实证检验 X 和 Y 之间是否存在关系，并且我们假设这种影响可能取决于第三个变量 M（调节变量）。我的问题是：在制定我们的假设以说明 X 对 Y 的影响为何取决于 M 时，是否还需要论证 M 和 Y 之间存在直接关系？我的理解是，调节关注的是 M 如何改变 X-Y 关系，而不一定要求 M 对 Y 产生直接影响。但是，我的朋友坚持认为，为了引入调节变量，M 和 Y 之间必须始终存在直接关系。要求这种直接的 M-Y 关系是标准做法吗？还是说，即使没有这样的要求，假设调节效应也足够了？]]></description>
      <guid>https://stats.stackexchange.com/questions/654093/is-a-direct-relationship-between-the-moderator-and-dependent-variable-necessary</guid>
      <pubDate>Mon, 09 Sep 2024 12:52:32 GMT</pubDate>
    </item>
    <item>
      <title>样本量计算的假设检验与置信区间</title>
      <link>https://stats.stackexchange.com/questions/654055/hypothesis-testing-vs-confidence-intervals-for-sample-size-calculation</link>
      <description><![CDATA[假设我们正在审计一个低风险集团，该集团的历史平均逃税额为 \$7,883，审计时的标准差为 \$27,274。我的目标是确定平均逃税额是否接近于零。使用 t 检验，假设平均逃税额为零（双侧，$\alpha = 0.05$，功效 = 0.8），双侧检验所需的样本量为 96，单侧检验所需的样本量为 76。我假设备择假设下的平均值和标准差就是历史数据所显示的。
但是，如果我使用置信区间 $\bar{x} \pm 1.96 * \frac{\sigma}{\sqrt{n}}$ 进行计算并将下限设置为接近零，则求解 $n$ 得到的样本量为 46。
使用样本量 46 来确定零是否在置信区间内有效，从而否定了假设检验所建议的更大样本量的需要吗？如果不是，为什么这种方法是错误的？]]></description>
      <guid>https://stats.stackexchange.com/questions/654055/hypothesis-testing-vs-confidence-intervals-for-sample-size-calculation</guid>
      <pubDate>Sun, 08 Sep 2024 20:43:37 GMT</pubDate>
    </item>
    <item>
      <title>可以对多项研究的标准差取平均值以用于样本量计算吗？</title>
      <link>https://stats.stackexchange.com/questions/654048/can-standard-deviations-from-multiple-studies-be-averaged-to-use-for-a-sample-si</link>
      <description><![CDATA[想象一下，您正在计划一项临床试验，以评估一种新疗法对改善慢性中风患者 VO2peak 的有效性。根据 Jin 等人的初步研究，您使用 Jin 等人报告的 VO2peak 方差估计试验所需的样本量。
来自 Jin 等人的数据：

VO2peak 的标准差 (SD)：2.5 ml/kg/min
估计样本量：每组 40 名参与者

但是，您后来发现，您的试点研究中的 SD 远高于 Jin 等人的估计值。
来自其他研究的数据：

DaCun：SD = 10 ml/kg/min
Mac：SD = 15 ml/kg/min
Len：SD = 20 ml/kg/min
Ive：SD = 18 ml/kg/min
Glob：SD = 25 ml/kg/min

修订方法：
现在，您不再仅仅依赖 Jin 等人的 SD 估计值，而是包括来自这些其他研究的数据：

来自其他研究的平均 SD：(10 + 15 + 20 + 18 + 25) / 5 = 17.6 ml/kg/min

修订样本量计算：使用这个更高的平均 SD，您可以计算出一个新的样本量估计值。


结果：

新的样本量估计值：每组 80 名参与者（基于更高的平均 SD）

这是计算样本的可接受方法吗尺寸？]]></description>
      <guid>https://stats.stackexchange.com/questions/654048/can-standard-deviations-from-multiple-studies-be-averaged-to-use-for-a-sample-si</guid>
      <pubDate>Sun, 08 Sep 2024 17:52:41 GMT</pubDate>
    </item>
    <item>
      <title>比较嵌套模型时，anova.mitml.results 给出高 df2</title>
      <link>https://stats.stackexchange.com/questions/654044/anova-mitml-results-giving-high-df2-when-comparing-nested-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654044/anova-mitml-results-giving-high-df2-when-comparing-nested-models</guid>
      <pubDate>Sat, 07 Sep 2024 04:11:33 GMT</pubDate>
    </item>
    <item>
      <title>如何加快以下 ELBO 评估？</title>
      <link>https://stats.stackexchange.com/questions/653855/how-to-speed-up-the-following-elbo-evaluation</link>
      <description><![CDATA[我有一个估计问题，需要最大化证据下限：
$$ \mathrm{ELBO} = -\frac{1}{2} \Bigg( \mathbb{E}_{q(\theta)} \left[ \mathrm{vec}(\mathbf{Z})^{\mathrm{H}} \mathbf{C}^{-1} \mathrm{vec}(\mathbf{Z})+ \log \left| \mathbf{C} \right| \right] + N_T \times L \log \left(2\pi\right) \\ \nonumber +\mathrm{tr}\left( \mathbf{C}_{\xi}^{-1} \mathbf{\Sigma} \right) + (\mathbf{m})^\top \mathbf{C}_{\xi}^{-1} (\mathbf{m}) - \log \frac{|\mathbf{C}_{\xi}|}{|\mathbf{\Sigma}|} - K \Bigg) $$
任务：
$$ [\hat{\mathbf{m}}, \hat{\mathbf{\Sigma}}, \hat{\xi}] = \arg\max_{[{\mathbf{m}}, {\mathbf{\Sigma}}, \xi]} \mathrm{ELBO}({\mathbf{m}}, {\mathbf{\Sigma}}, \xi) $$
括号中的第一个项ELBO 是近似分布 $q(\theta)$ 的预期值。现在，我正在使用蒙特卡罗模拟来评估它，这非常耗时。这里，$\mathrm{vec}$ 是 $\mathbf{Z}$ 的矢量化形式，它最初是二维的。协方差 $\mathbf{C}$ 是一个块对角矩阵，它是 $\theta$ 的函数。$q(\theta) = \mathcal{N}(\mathbf{m}, \mathbf{\Sigma})$。有六个参数控制$\mathbf{C}_{\xi}$。参数$\theta$的大小与$\mathbf{m}$相同，即$3 \times K$。对于$\mathbf{\Sigma}$，我使用对角矩阵，其中$\mathrm{diag}[\mathbf{\Sigma}] = \mathbf{m}/N$，其中$N$是需要估计的常数。如果 $K = 64$，则要估计的参数数量为 $6 + 192 + 1 = 199$。要估计这么多参数，我无法花费太多计算时间来评估一次目标函数（因为它涉及蒙特卡罗期望步骤）。有没有办法加快这个过程？
我正在使用 MATLAB。我使用 MATLAB 中的简单函数进行所有评估。即使我使用有效的函数，例如 $A\setminus B$ 而不是 $A*inv(B)$，它仍然需要大量时间，因为它必须执行蒙特卡罗。在每个蒙特卡罗步骤中，我需要对 $\theta$ 进行采样，如下所示：$\theta \sim q(\theta)$。任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653855/how-to-speed-up-the-following-elbo-evaluation</guid>
      <pubDate>Wed, 04 Sep 2024 14:05:16 GMT</pubDate>
    </item>
    </channel>
</rss>