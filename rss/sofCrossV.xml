<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 07 May 2024 12:25:22 GMT</lastBuildDate>
    <item>
      <title>使用合成 AA 测试（蒙特卡罗）在同一样本上获得的 p 值是否是独立值？</title>
      <link>https://stats.stackexchange.com/questions/646720/are-the-p-values-obtained-on-the-same-sample-using-synthetic-aa-tests-monte-car</link>
      <description><![CDATA[假设我们有以下过程。
我们采用大小为 n 的固定样本并执行该过程 1000 次：

我们将其平均分为 2 组；
我们使用F函数计算p值（例如，t检验，但我对一般情况感兴趣）；
我们得到了 1000 个 p 值（或 1000 个 p 值 &lt; alpha 的值）

考虑到我们都处理了相同的固定样本和相同的函数 F 1000 次，这 1000 个值是相关的还是独立的？]]></description>
      <guid>https://stats.stackexchange.com/questions/646720/are-the-p-values-obtained-on-the-same-sample-using-synthetic-aa-tests-monte-car</guid>
      <pubDate>Tue, 07 May 2024 12:03:24 GMT</pubDate>
    </item>
    <item>
      <title>无随机效应的简单线性混合模型的近似功效分析</title>
      <link>https://stats.stackexchange.com/questions/646718/approximate-power-analysis-for-simple-linear-mixed-model-without-random-effects</link>
      <description><![CDATA[出于教育目的，对两种条件下所有参与者的重复测量被建模为线性混合模型。我们对控制混杂因素 c1 和 c2 时结果的差异感兴趣；只有固定效应才有意义，随机效应完全可以忽略不计（事实上为零）：
模型 &lt;- &#39;结果 ~ 条件 + c1 + c2 + (1 | id)&#39;

通过模拟进行复杂的功率分析（如 LMM 的建议）在我们的环境中是不可行的。
那么，我怎样才能完成一个非常粗略（也许保守）的功效估计，只需要一些参数（例如 G*Power 中通常使用的参数），例如效应大小 f2、误差和 1-β 概率，而不是过多的其他参数参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/646718/approximate-power-analysis-for-simple-linear-mixed-model-without-random-effects</guid>
      <pubDate>Tue, 07 May 2024 11:56:26 GMT</pubDate>
    </item>
    <item>
      <title>RCT 中的辍学率</title>
      <link>https://stats.stackexchange.com/questions/646717/drop-outs-in-rct</link>
      <description><![CDATA[我进行了一项随机对照试验，共有 34 名参与者，包括实验组和对照组。我们在随机化之前在基线 (T0) 获取测量数据，然后每 4 个月进行一次后续测量（因此 T1 和 4 个月，T2 在 8 个月，最后一次在 12 个月时为 T3）。干预是在一家公司的工作时间进行的。
我有 4 名参与者在 T0 后立即退出（因此根本没有后续数据），原因很随机：换工作 (n=2)、退休 (n=1)、受伤在运动期间休过长期病假（n=1）。
我认为，由于退出原因与我们的研究完全无关，也与结果无关，所以最好的想法是排除这 4 名参与者。
这样合理吗？我应该做点别的事情吗？
提前非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646717/drop-outs-in-rct</guid>
      <pubDate>Tue, 07 May 2024 11:51:10 GMT</pubDate>
    </item>
    <item>
      <title>提取的平均方差和因子加载截止值未对齐</title>
      <link>https://stats.stackexchange.com/questions/646716/average-variance-extracted-and-factor-loading-cutoff-not-aligning</link>
      <description><![CDATA[因子载荷的截止值通常约为 0.4（Stevens 1992）、Fidell（2007）、0.32（差）、0.45（一般）、0.55（好），遵循 Comrey 和 Lee（1992）。但对于收敛有效性，您需要提取的平均方差为 0.5 或以上，这意味着您的平均因子载荷应为 0.7 或以上。
那么它们之间的差异是巨大的，为什么呢？
此外，几乎所有研究都使用PCA作为因子提取方法，但事实上并非如此。通过使用 PCA，您可以获得很好的加载值，这是我得到的，但使用 PAF 却得不到。仍然困惑该采用哪种方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/646716/average-variance-extracted-and-factor-loading-cutoff-not-aligning</guid>
      <pubDate>Tue, 07 May 2024 11:33:00 GMT</pubDate>
    </item>
    <item>
      <title>改造的 Ornstein Uhlenbeck 工艺</title>
      <link>https://stats.stackexchange.com/questions/646715/transformed-ornstein-uhlenbeck-process</link>
      <description><![CDATA[假设我有 𝑋 遵循 Ornstein-Uhlenbeck 过程：
&lt;块引用&gt;
$𝑑𝑋_𝑡=𝜙X_t𝑑𝑡+𝜎𝑑𝑊_𝑡$

让 $𝑌_𝑡=exp(𝑋_𝑡)$。
如何计算$Y_t$的自相关函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/646715/transformed-ornstein-uhlenbeck-process</guid>
      <pubDate>Tue, 07 May 2024 11:30:27 GMT</pubDate>
    </item>
    <item>
      <title>当所有测量值都有噪声时，线性最小二乘法是否存在偏差？</title>
      <link>https://stats.stackexchange.com/questions/646713/is-there-a-bias-in-linear-least-squares-when-all-measurements-have-noise</link>
      <description><![CDATA[假设我们有一个线性相关性 $y = kx$。然而我们的测量值 $(\hat x_i, \hat y_i)$ 在 $x$ 和 $y$ 中都有噪声
$\hat x_i = x_i +\nu_i \ , \qquad \hat y_i = y_i +\varepsilon_i \ , \qquad i=\{1,..., n\}$
据我所知，在线性最小二乘法 (LLS) 中，假设只有 $y$ 测量值有噪声，对吗？然后，如果我尝试将 LLS 公式应用于噪声数据，我会得到切线
$k = \frac{\langle \hat x \hat y\rangle}{\langle \hat x^2\rangle} =
\frac{\langle (x +\nu)(y +\varepsilon)\rangle}{\langle (x +\nu)^2\rangle} =
\frac{\langle (xy +\nu y+ x\varepsilon +\nu\varepsilon)\rangle}{\langle x^2 +2x\nu+\nu^2\rangle}
=\frac{\langle x y\rangle}{\langle x^2\rangle + \langle \nu^2 \rangle}$
其中我假设噪声项彼此之间以及与实际测量值之间不相关。因此，如果我们在 $x$ 的测量中存在噪声，则 $k$ 的这个估计值似乎是错误的。这是对的吗，还是我在推理中犯了错误？有没有办法推导出无偏正切的公式？（指出一本可用的教科书也可以）。]]></description>
      <guid>https://stats.stackexchange.com/questions/646713/is-there-a-bias-in-linear-least-squares-when-all-measurements-have-noise</guid>
      <pubDate>Tue, 07 May 2024 10:17:27 GMT</pubDate>
    </item>
    <item>
      <title>如何将 PLSR 模型的载荷应用于数据点？</title>
      <link>https://stats.stackexchange.com/questions/646710/how-does-one-apply-loadings-of-a-plsr-model-to-a-data-point</link>
      <description><![CDATA[问题：
我很难理解如何将潜在变量的负载应用于数据集中的每个单独观察。
目前的理解：
我有一个模型，它使用 SIMPLS 算法并最大化每个潜在变量的预测变量的协方差。这个潜在变量有一个系数，但它也有其定义内每个自变量的载荷。
我想将我的所有观察结果重新投影到 PLSR 模型中使用的基础空间。我相信这意味着每个单独的数据点将沿着重新定义的空间中的“新”轴重新投影。为此，我不确定是否使用 x 或 y 载荷，因为我在 Python 中工作。
x_loadings 是每个潜在变量内的载荷，而 y_loadings 是每个潜在变量的系数，这是否正确？
示例
血压~体重+胆固醇：
bp = 血压
重量=重量
Chl = 胆固醇
b = 截距
wl_&#39;x&#39; = 权重潜在变量
LV_1 = 0.5重量 + 0.8chl
LV_2 = -0.5wt + 0.9chl
bp = b + w_1LV1 + w_2Lv2
在此示例中，x_loadings 将是 LV_&#39;x&#39; 函数中各项的系数，y_loadings 将是 bp 函数中各项的系数。
这是正确的理解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646710/how-does-one-apply-loadings-of-a-plsr-model-to-a-data-point</guid>
      <pubDate>Tue, 07 May 2024 09:11:48 GMT</pubDate>
    </item>
    <item>
      <title>谁能解释一下 ACF 和 PCF 从这个图中看出了什么？</title>
      <link>https://stats.stackexchange.com/questions/646709/can-anyone-explain-me-what-does-acf-and-pcf-tells-from-this-figure</link>
      <description><![CDATA[
我想知道这是什么意思？我的数据是否平稳，因为 p 值表明它是平稳的，ARIMA 模型 (p,1,q) 的阶数应该是 (p,d,0) 还是 (0,d,q)]]></description>
      <guid>https://stats.stackexchange.com/questions/646709/can-anyone-explain-me-what-does-acf-and-pcf-tells-from-this-figure</guid>
      <pubDate>Tue, 07 May 2024 09:09:47 GMT</pubDate>
    </item>
    <item>
      <title>Catboost 不经意的树可以在同一特征上多次分裂吗</title>
      <link>https://stats.stackexchange.com/questions/646704/can-a-catboost-oblivious-tree-split-on-the-same-feature-more-than-once</link>
      <description><![CDATA[在 Catboost 中训练无意识决策树时，是否可以多次使用同一特征进行拆分？假设有一个特征 age。
如果第一次拆分发生在 age&gt;30，则数据将被分为两个不重叠的部分。对该特征的任何进一步拆分（例如 age&gt;50）在第一次拆分 age&lt;30 时都不会包含任何样本。
鉴于 Catboost 使用决策表，其中的一些条目将不会被填充，并且算法无法预测这些区域的任何内容。
另一方面，如果一个特征只能使用一次，这会自动将深度限制为特征的数量。
这种理解是否正确，Catboost 使用哪种选项？]]></description>
      <guid>https://stats.stackexchange.com/questions/646704/can-a-catboost-oblivious-tree-split-on-the-same-feature-more-than-once</guid>
      <pubDate>Tue, 07 May 2024 07:42:49 GMT</pubDate>
    </item>
    <item>
      <title>在 blmer 中，sigma 是变量随机效应协方差，为什么 cov(r,c)var(r) = var(c) ？</title>
      <link>https://stats.stackexchange.com/questions/646703/in-blmer-is-sigma-variable-random-effect-covariance-and-why-would-covr-cvar</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/646703/in-blmer-is-sigma-variable-random-effect-covariance-and-why-would-covr-cvar</guid>
      <pubDate>Tue, 07 May 2024 07:37:26 GMT</pubDate>
    </item>
    <item>
      <title>计算高于阈值 0.5 的概率的 AP（或 AUPRC）的正确方法</title>
      <link>https://stats.stackexchange.com/questions/646697/correct-way-to-calculate-ap-or-auprc-for-probabilities-above-a-threshold-of-0</link>
      <description><![CDATA[与这篇文章相关，我想计算平均精度（AP）或精度召回下的面积所有高于阈值 0.5 的概率的曲线 (AUPRC)。
这是正确的方法吗：
从 sklearn.metrics 导入average_ precision_score, auc

y_prob_50 = [x，如果 x &gt; 0.50，否则 y_prob 中的 x 为 0]
precision_50、recall_50、thresholds_50 = precision_recall_curve(y_true、y_prob_50)
平均精度分数（y_true，y_prob_50）
auc(recall_50, precision_50)

其中 y_prob 由范围为 [0, 1] 的预测概率组成。
我不需要在整个可能阈值范围（从 0 到 1）上优化精确召回曲线 (AUPRC) 下的面积，而只需优化 0.5 到 1.0 之间的阈值。任何建议将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/646697/correct-way-to-calculate-ap-or-auprc-for-probabilities-above-a-threshold-of-0</guid>
      <pubDate>Tue, 07 May 2024 05:34:32 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归中，误差方差估计量的渐近分布是什么？</title>
      <link>https://stats.stackexchange.com/questions/646690/in-linear-regression-whats-the-asymptotic-distribution-of-the-error-variance-e</link>
      <description><![CDATA[假设 $Y_i=X_i&#39;\beta+\epsilon_i$ 与 $E(\epsilon_i|X_i)=0$  和 $E\epsilon^2_i=\sigma^2$ ，我估计 $\sigma^2$  使用 $s^2=\frac{1}{n}\sum_{i=1}^n (Y_i-X_i&#39;\widehat{\beta})^ 2$，其中 $\widehat{\beta}$ 是 $\beta$&lt; 的 OLS 估计量/跨度&gt;。我想知道 $s^2$ （适当缩放和标准化版本）的渐近分布是什么？如果能提供详细的推导步骤就太好了。预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/646690/in-linear-regression-whats-the-asymptotic-distribution-of-the-error-variance-e</guid>
      <pubDate>Tue, 07 May 2024 04:18:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么引导间隔往往太短的根本“问题”是什么？</title>
      <link>https://stats.stackexchange.com/questions/646671/what-is-the-fundamental-problem-why-bootstrap-intervals-tend-to-be-too-short</link>
      <description><![CDATA[我发现了几篇进行模拟并证明引导间隔往往太短的帖子（即使考虑了正确的依赖/分组结构）。答案中反复询问和描述了这一点，这表明引导程序仅渐近有效。
例如这篇文章和讨论链接了很多问题
引导程序在小样本中是否存在问题？
我没有找到关于原因的讨论。
根本原因如下：通过将无限总体中的采样与有限总体中的采样进行交换，我们可以实现

在重新采样（替换抽取）之间引入了以前不存在的人工相关性（因为样本最初是随机抽取的）
我们用有限总体交换了无限总体，这样我们就可以得到与有限总体类似的效果 $\operatorname{Var}\left( \frac1n \sum_i X_i \右） =\frac{1}{n}(1-\frac{n}{N}) \sigma^2$ 对于 n=N 为零。因此，有限总体（我们从中抽取重采样的样本）的行为与真正的无限总体不同。但我无法完全理解这一点。也许有人看到了我上面引用的改变的有限人口统计数据的联系......
...

还是 1) 和 2) 的混合？
也许讨论这个为什么问题与最小/最大统计数据会有所帮助？ （我知道常见的解决方法，例如 n out of m bootstrap，我并不是在寻找对 vanilla bootstrap 的改编，而是寻找为什么 vanilla bootstrap 在某些情况下会失败的答案）。]]></description>
      <guid>https://stats.stackexchange.com/questions/646671/what-is-the-fundamental-problem-why-bootstrap-intervals-tend-to-be-too-short</guid>
      <pubDate>Mon, 06 May 2024 22:46:02 GMT</pubDate>
    </item>
    <item>
      <title>我的训练/验证数据准确率达到 99-100%，但在全新数据上表现不佳</title>
      <link>https://stats.stackexchange.com/questions/646611/getting-99-100-accuracy-on-my-training-validation-data-but-performs-bad-on-comp</link>
      <description><![CDATA[我有一个 ASL（美国手语）的大型数据集。我将这些数据分成 70:15:15 进行训练、验证、测试。
然后我在其上训练了一个 CNN 模型，其中我使用 70% 的验证集进行训练，并在 15% 的验证集上进行评估。经过一些时期后，我能够在训练/验证数据上实现 100% 的准确性。然后，我在剩余的“看不见的”测试数据上运行这个经过训练的模型，它也达到了 99% 的准确率，我认为这很好。
但是，我随后从第三方来源获得了更多 ASL 数据，这些数据更多是“看不见的数据”，但我只达到了 40% 左右的准确度。看起来我的模型在这个原始数据源上严重过度拟合（数据集大约有 87000 张图像），而且我很确定我也没有将测试集泄漏到模型的训练中。
首先，对此还有其他解释吗？其次，有什么方法可以改进我当前的模型吗？我最初的想法是将这些第三方数据与我的原始数据混合在一起，但是数据集仍然不平衡吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646611/getting-99-100-accuracy-on-my-training-validation-data-but-performs-bad-on-comp</guid>
      <pubDate>Mon, 06 May 2024 10:59:38 GMT</pubDate>
    </item>
    <item>
      <title>伯努利试验的样本平均值在平方损失下是可接受的</title>
      <link>https://stats.stackexchange.com/questions/646565/sample-mean-of-bernoulli-trials-is-admissible-under-squared-loss</link>
      <description><![CDATA[令 $X_1,\ldots,X_n$ 为独立同分布伯努利试验，概率为 $\theta\in(0,1)$，令 $L:(0,1)\times[0,1]\to\mathbb{R}$ 为平方损失函数，即 $L(\theta,a)=(\theta-a)^2$。我试图证明样本均值 $d(\mathbf{X})=\overline{X}$ 是一个可接受的决策规则，也就是说，不存在一条决策规则 $d&#39;:\{0,1\}^n\to\mathbb{R}$ 使得对于所有 $\theta$ 都有 $R(\theta,d&#39;)\leq R(\theta,d)$，并且对于某些 $\theta$ 都有 $R(\theta,d&#39;)&lt;R(\theta,d)$。这里，$R(\theta,d)$ 表示风险，定义为
$$R(\theta,d)=E(L(\theta,d(\mathbf{X})))=E(\theta-d(\mathbf{X}))^2.$$
我觉得应该有一种直接的方式来展示这一点，但我没有看到。我已经证明，给定 $\text{Beta}(\alpha,\beta)$ 上的先验分布，我证明了贝叶斯估计量是 $d_{\alpha,\beta}(\mathbf{X})=\frac{\alpha+\sum_{i=1}^n X_i}{\alpha+\beta+n}$。我相信在这种情况下成为贝叶斯估计量意味着 $d_{\alpha,\beta}$ 是可接受的决策规则。然后，取极限$\alpha,\beta\to 0$，我们得到$d_{\alpha,\beta}(\mathbf{X})\to\overline{X}$，所以如果我可以声称可接受的决策规则的极限是可接受的，那我就完成了。但我不认为这一般是正确的。有什么想法吗？
从 MSE 交叉发布
编辑：这里有一个类似的问题，但是，答案似乎使用了“不当先验”分布在$(0,1)$上。老实说，我对不恰当的先验分布不是很熟悉，而且我并不完全相信它们的有效性。如果有不依赖于不恰当先验的解决方案，我会非常感兴趣。]]></description>
      <guid>https://stats.stackexchange.com/questions/646565/sample-mean-of-bernoulli-trials-is-admissible-under-squared-loss</guid>
      <pubDate>Sun, 05 May 2024 18:38:59 GMT</pubDate>
    </item>
    </channel>
</rss>