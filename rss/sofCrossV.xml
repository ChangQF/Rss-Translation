<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 02 Jun 2024 15:13:54 GMT</lastBuildDate>
    <item>
      <title>我被分配使用 metropolis 算法来数值求解积分。我编写了一个 Python 代码，我做错了什么？</title>
      <link>https://stats.stackexchange.com/questions/648478/i-have-been-assigned-to-use-the-metropolis-algorithm-in-order-to-solve-numerical</link>
      <description><![CDATA[几天来，我一直在尝试使用 metropolis 算法解决以下问题：
$A = \frac{\int_0^1...\int_0^1\prod_{l=1}^N d^3r_l\frac{1}{|\vec{r_1}-\vec{r_2}|_\alpha}*e^{\eta u(\vec{r_1},...,\vec{r_N})}}{\int_0^1...\int_0^1\prod_{l=1}^N d^3r_le^{\eta u(\vec{r_1},...,\vec{r_N})}}$
其中 $u(.)=\frac{1}{N}\sum_{1\le l &lt; j\le N}\frac{1}{|\vec{r_l}-\vec{r_j}|_\alpha}$。
对于$|\vec{r_l}-\vec{r_j}|\ge \alpha$，则$\frac{1}{|\vec{r_l}-\vec{r_j}|_\alpha}=\frac{1}{|\vec{r_l}-\vec{r_j}|}$，而对于$|\vec{r_l}-\vec{r_j}|\le \alpha$，则$\frac{1}{|\vec{r_l}-\vec{r_j}|_\alpha}=-\frac{1}{\alpha}$.
这取自：https://arxiv.org/pdf/astro-ph/0505561.
我基本上用大都市来近似 A，如下所示（m 是蒙特卡洛的迭代次数）：
$&lt;A&gt; = \frac{1}{m}\sum_1^m \frac{1}{|\vec{r_1}-\vec{r_2}|_\alpha}$
（还有一个常数$\frac{N(N-1)}{2}$，但我暂时忽略它，因为我将 A 代入另一个方程中，它们会相互抵消）
现在，我编写了以下 Python 代码，以便使用 metropolis 算法解决 A，如上面的 Arxiv（第 3 节）中所述。但是，我似乎没有得到与论文相同的结果。
@jit(nopython=True)
def potential(coord_array, A, N):
energy_sum = 0
for l in range(N-1):
for j in range(l+1, N):
dif = np.sqrt((coord_array[l, 0] - coord_array[j, 0])**2 +
(coord_array[l, 1] - coord_array[j, 1])**2 +
(coord_array[l, 2] - coord_array[j, 2])**2)
if dif &gt;= A:
energy = -1/dif
else:
energy = 1/A
​​energy_sum += energy
return energy_sum / N

@jit(nopython=True)
def potential_move(coord_array, random_particle, A, N):
energy_sum = 0
for l in range(N):
if l == random_particle:
continue
dif = np.sqrt((coord_array[l, 0] - coord_array[random_particle, 0])**2 +
(coord_array[l, 1] - coord_array[random_particle, 1])**2 +
(coord_array[l, 2] - coord_array[random_particle, 2])**2)
if dif &gt;= A:
energy = -1 / dif
else:
energy = 1 / A
energy_sum += energy
return energy_sum / N

@jit(nopython=True)
def canonical_ensemble(coord_array, eta, A, iterations, N, delta):
final_coords = np.zeros((N, 3, 迭代))
acc = np.zeros((迭代))
for i in range(迭代):
random_particle = random.randint(0, N-1)
if i == 0:
coordinates = np.copy(coord_array)
else:
coordinates = np.copy(final_coords[:, :, i-1])

for j in range(3):
coordinates[random_particle, j] += delta * (2 * np.random.rand() - 1)

if i == 0:
energy_dif = (potential_move(coordinates, random_particle, A, N) - potential_move(coord_array, random_particle, A, N))
#energy_dif = (potential(coordinates, A, N) - potential(coord_array, A, N))
else:
energy_dif = (potential_move(坐标，random_particle，A，N) - potential_move(final_coords[:, :, i-1]，random_particle，A，N))
#energy_dif = (potential(坐标，A，N) - potential(final_coords[:, :, i-1]，A，N))

如果 energy_dif &lt;= 0:
final_coords[:, :, i] = 坐标
acc[i] = 1
否则：
ratio = np.exp(-eta * energy_dif)
Omega = np.random.random()
如果 min(1, ratio) &gt;= Omega:
final_coords[:, :, i] = 坐标
acc[i] = 1
否则：
final_coords[:, :, i] = final_coords[:, :, i-1]
acc[i] = 0
integration_sum = 0
for i in range(iterations):
distance = np.sqrt((final_coords[0,0,i] - final_coords[1,0,i])**2 +
(final_coords[0,1,i] - final_coords[1,1,i])**2 +
(final_coords[0,2,i] - final_coords[1,2,i])**2)
if distance &gt;= A:
integration_sum += (1 / distance)
else:
integration_sum += -(1/A)
Phi = (N-1) * integration_sum / (2 * iterations)
#print(final_coords&gt;=1)
print(np.sum(acc)*100/iterations)
return Phi 

有任何帮助吗将不胜感激，因为我已经困在这个问题上好几天了:)]]></description>
      <guid>https://stats.stackexchange.com/questions/648478/i-have-been-assigned-to-use-the-metropolis-algorithm-in-order-to-solve-numerical</guid>
      <pubDate>Sun, 02 Jun 2024 14:38:00 GMT</pubDate>
    </item>
    <item>
      <title>对于左截断计数数据，哪个对数似然要最大化？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648477/which-log-likelihood-is-to-be-maximized-for-left-truncated-count-data</link>
      <description><![CDATA[如果计数数据缺少零点上的计数（即左截断数据），该怎么办？假​​设有人想估计泊松回归，目标是推导出最大化的对数似然。
我的方法：
$$
f(y_i \mid y_i &gt; 0, x_i) = \frac{f(y_i \mid x_i)}{1 - f(y_i = 0 \mid x_i)}
$$
$$
f(y_i \mid y_i &gt; 0, x_i) = \frac{e^{-\lambda} \lambda^{x_i}}{x_i! \left(1 - e^{-\lambda}\right)}
$$
要最大化的似然函数是：
$$
L(\lambda) = \prod_{i=1}^{n} \frac{e^{-\lambda} \lambda^{x_i}}{x_i! \left(1 - e^{-\lambda}\right)}
$$
对数似然函数为：
$$
\log L(\lambda) = \sum_{i=1}^{n} \left(-\lambda + x_i \log(\lambda) - \log(x_i!) - \log\left(1 - e^{-\lambda}\right)\right)
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/648477/which-log-likelihood-is-to-be-maximized-for-left-truncated-count-data</guid>
      <pubDate>Sun, 02 Jun 2024 14:23:04 GMT</pubDate>
    </item>
    <item>
      <title>拒绝怀疑不属于目标人群的样本[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648475/rejection-of-samples-suspected-of-not-coming-of-the-target-population</link>
      <description><![CDATA[假设有一个平稳过程，它应该类似于具有“已知”均值和方差的高斯分布。从中取出三次（或 n 次）Iid 样本。众所周知，一些样本可能会受到污染，即包括来自其他分布（具有不同的形状、均值和/或方差）的观测值。
假设这种污染可以通过产生具有不可思议的高范围的样本来表现出来。血压测量可以作为一个例子。在这种情况下，偶尔会出现不代表被测变量的“奇怪”测量值，虽然它们的起源尚有争议，但它们很容易是测量过程中血压本身偶尔出现的时间波动以及仪器和方法的怪癖的结果。这被视为污染，因为此类异常值是由测量技术机械引入的，与临床无关。
因此，评估每个 n 重样本的范围，并将其与基于假定的“干净”高斯母分布选择的截止值进行比较。如果超出该值，则拒绝该样本，并且不将其纳入分析。
我的问题是（以三次重复为例，假设该程序是可接受的）：以下哪种方法更合适？

如果前两个单独的观察值超出允许的最大范围，则拒绝它们并从下一个观察值开始下一个三次重复样本。

无论如何都要取第三个样本以完成三次采样程序，然后拒绝它。


第一个选项保证（给定上述程序）无论尚未进行的第三次观察如何，样本都将被拒绝，但拒绝标准是基于三次重复的范围，而不是两个相邻测量之间的差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/648475/rejection-of-samples-suspected-of-not-coming-of-the-target-population</guid>
      <pubDate>Sun, 02 Jun 2024 13:41:51 GMT</pubDate>
    </item>
    <item>
      <title>基因变异的事件时间分析：是否要根据年龄进行调整？</title>
      <link>https://stats.stackexchange.com/questions/648473/time-to-event-analysis-for-genetic-variants-whether-or-not-to-adjust-for-age</link>
      <description><![CDATA[据我理解，当人们有兴趣研究暴露与事件发生时间结果之间的关联（在 Cox PH 回归的背景下）时，暴露的性质决定了如何制定结果。举个例子，假设我有一群来自普通人群的个体，他们在某个时间跨度（这里指 2000 年至 2004 年之间）参加了一项研究，并对他们进行了跟踪调查，直到 2020 年。5 名假设参与者的整体研究如下所示：

我有两个问题，如果有人能纠正我，我将不胜感激：

如果我有兴趣研究遗传变异与特定结果的事件发生时间之间的关联，我会在我的模型中考虑发病年龄和出生日期之间的差异，因为在这种情况下感兴趣的暴露（遗传变异）在出生时就存在，并且不会随时间而变化。但是，如果感兴趣的暴露是生物标志物（例如 ALT 水平），那么事件发生时间将是发病年龄和入组日期之间的差异，因为每个受试者的暴露都是在他们参加研究时测量的。我的理解正确吗？

在上述两种情况下，如何将年龄视为协变量？例如，在暴露是遗传变异的情况下，最近的可扩展方法（例如此处）未根据年龄进行调整：



对于所有疾病，我们使用前四个主成分 (PC) 和性别作为协变量。

或者来自本文：

我们没有包括任何年龄或出生年份的协变量，因为这些与我们的表型直接相关。

但是关于感兴趣的暴露何时与时间相关（例如 ALT）。此外，如果人们有兴趣解释其他时间依赖性协变量（例如仅在入组时基线测量的 BMI）的影响，而感兴趣的暴露是遗传变异，那么最合适的方法是什么？
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648473/time-to-event-analysis-for-genetic-variants-whether-or-not-to-adjust-for-age</guid>
      <pubDate>Sun, 02 Jun 2024 12:36:11 GMT</pubDate>
    </item>
    <item>
      <title>布伦特原油价格季节性调整</title>
      <link>https://stats.stackexchange.com/questions/648472/seasonal-adjustment-of-brent-crude-oil-price</link>
      <description><![CDATA[我需要使用布伦特原油的全球价格（月度数据；1990 年 1 月，2024 年 4 月）
数据集未经季节性调整。我分解了趋势和季节性，如下图所示。
我需要做季节性调整吗？如果是，我该如何在 R 中处理这种季节性调整？
谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648472/seasonal-adjustment-of-brent-crude-oil-price</guid>
      <pubDate>Sun, 02 Jun 2024 12:06:40 GMT</pubDate>
    </item>
    <item>
      <title>将离散生存时间转换为连续生存时间</title>
      <link>https://stats.stackexchange.com/questions/648471/converting-discreate-survival-time-to-continuous-one</link>
      <description><![CDATA[我记得几年前有位科学家告诉我，我们可以根据以下示例方法将流行病学中的离散生存时间转换为连续生存时间。如果您能告诉我我们是否可以确认此方法（如果可以，请告诉我该技术的名称），我将不胜感激。
假设，我有一项研究，患者每三个月来医院检查一次。T0（手术前一周）、T1（手术后三个月）、T2（手术后 6 个月）直至 T8（手术后 21 个月）。如果患者 1 在 3 到 6 个月（T2）的间隔内发生事件，那么我们可以将生存时间转换为 3+1.5=4.5。如果患者 2 在 6 到 9 个月（T2）的间隔内发生事件，那么我们可以将生存时间转换为 6+1.5=7.5]]></description>
      <guid>https://stats.stackexchange.com/questions/648471/converting-discreate-survival-time-to-continuous-one</guid>
      <pubDate>Sun, 02 Jun 2024 11:42:26 GMT</pubDate>
    </item>
    <item>
      <title>在没有外生价格变化的情况下估计需求函数</title>
      <link>https://stats.stackexchange.com/questions/648470/estimating-demand-function-without-exogenous-variation-in-prices</link>
      <description><![CDATA[假设我拥有关于保险产品需求和价格的个人层面信息。如果消费者 i 购买了保险产品，则需求 D_i 为虚拟变量，等于 1，否则为 0。这是一次性决定，因此我没有面板数据（不过，我观察了不同的群体）。现在假设 i 的定价规则如下：
p_i=b+f(risk_i)，
其中 b 是某个在个体之间相等的基准价格，而 f(risk_i) 是影响风险的可观察个体特征的函数，并且假定计量经济学家知道该函数。
目标是估算标准需求曲线：
D_i=a+β*p_i+ε_i&lt;​​/code&gt;。
我面临的问题是 p_i 的变化不是外生于个体需求特征的（即，可观察风险特征中的支付意愿可能会增加），但如果我估算 D_i=a+β_1*b+β_2*f(risk_i)+ε_i&lt;​​/code&gt;，我缺乏价格。
不幸的是，我无法想出解决这个问题的方法。IV 方法是不可行的，因为定价没有随机成分（例如，取决于保险员工等）。我想，即使假设 f() 是非线性的，估计 D_i=a+β 1*p_i+β_2*risk+ε_i&lt;​​/code&gt; 也会不一致。
另一方面，定价规则是在 t 年引入的，没有可靠的个人预期。在此之前，每个 i 都面临着一个对所有个人都相同的通用时不变价格。但是，鉴于购买保险产品是一次性决定，我每年都会观察不同的人。
很高兴收到有关如何在这种情况下估计需求曲线的任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/648470/estimating-demand-function-without-exogenous-variation-in-prices</guid>
      <pubDate>Sun, 02 Jun 2024 11:00:21 GMT</pubDate>
    </item>
    <item>
      <title>对顺序数据的依赖性是什么？</title>
      <link>https://stats.stackexchange.com/questions/648464/what-is-dependency-on-sequential-data</link>
      <description><![CDATA[我们知道，只要数据集中的点依赖于数据集中的其他点，数据就被称为顺序数据。
一个常见的例子是时间序列，例如天气数据。

我的问题是“依赖”一词是什么意思？在上面的例子中，数据点如何相互依赖？]]></description>
      <guid>https://stats.stackexchange.com/questions/648464/what-is-dependency-on-sequential-data</guid>
      <pubDate>Sun, 02 Jun 2024 05:33:05 GMT</pubDate>
    </item>
    <item>
      <title>使用预测值置信区间来“预测”结果</title>
      <link>https://stats.stackexchange.com/questions/648463/using-predictive-value-confidence-intervals-to-predict-outcomes</link>
      <description><![CDATA[以下是简要版本：
假设我有一个混淆矩阵，其中包含以下数据，这些数据基于预测试的熟练程度分数线和课程结果（通过/不通过）。
TP：550 FP：200
FN：280 TN：825
以下是一些统计数据：
敏感度：66.27%
1 - 特异性：19.51%
准确度：74.12%
阳性预测值 (PPV；贝叶斯理论)：73.33% 95% 可信区间 (70.64%，75.86%)
1 - 阴性预测值 (1 - NPV)：25.34% 95% 可信区间 (23.49%， 27.28%)
是否可以将 PPV 置信区间中的最小值和最大值与 1 - NPV 置信区间中的最小值和最大值结合使用，根据预测试的结果“预测”某个班级中一组学生通过考试的概率范围？目标是了解预测试结果对学生在课堂上的成功有多“预测”。
例如，根据我们的熟练程度分数线，开学第一天 75% 的学生在预测试中获得了“熟练”的成绩。如果过去的数据（如混淆矩阵所示）表明，如果学生在预测试中表现良好，则通过该课程的概率 (PPV) 为 73.33%，95% CI（70.64%，75.86%），如果学生在预测试中表现不佳，则通过该课程的概率 (1 - NPV) 为 25.34%，95% CI（23.49%，27.28%），我们能否使用两个置信区间的最小值和最大值来表示：
0.7064 * 75 + 0.2349 * 25 [两个置信区间的最小值] = 58.9%
0.7586 * 75 + 0.2728 * 25 [两个置信区间的最大值] = 63.7%
我们预计当前学生群体中会有 58.9% 到 63.7%通过这门课程？
这实际上是使用贝叶斯定理/条件概率，使用过去收集的预测试和课程通过率数据来回答我们的问题。使用置信区间而不是实际条件概率 73.33% 和 25.34% 来做到这一点有问题吗？当然，这里的“预测”是笼统的。我们知道现实世界总是有一些有趣的事情在等着我们。 （旁注：我们将来会添加一门必修课程，希望能随着时间的推移提高通过率。）一旦有数据可供在学习本课程之前修读必修课程的学生使用，比较必修课程与无必修课程组的数据、两组在预考中的分数以及课程的通过/不通过率等，看看课程结果实际上如何随时间变化将会很有趣，但就目前而言……
根据过去的数据，根据该课程在预考中的表现，我们是否可以进行上述计算并说，根据该课程在预考中的表现，我们预计当前这组学生中 58.9% 至 63.7% 的学生会通过该课程？]]></description>
      <guid>https://stats.stackexchange.com/questions/648463/using-predictive-value-confidence-intervals-to-predict-outcomes</guid>
      <pubDate>Sun, 02 Jun 2024 04:55:58 GMT</pubDate>
    </item>
    <item>
      <title>中位数的平均值始终不同于中位数</title>
      <link>https://stats.stackexchange.com/questions/648458/mean-of-medians-consistently-differs-from-median</link>
      <description><![CDATA[免责声明：这是我的第一个问题。
问题背景：
我想比较两个分布（n1 ~ 500 和 n2 ~ 700），它们不是正态分布，方差也不同，但大致是单峰分布。我决定使用中位数进行比较统计。
使用（scipy 的）置换检验，我得到了两个中位数观察到的差异的 p 值。使用同样生成的零假设分布，我也能够得到实验的最小可检测效果。
我想估计观察到的差异（中位数）的误差（-&gt; 用于绘图的误差线）。所以我使用 np.random.choice 绘制两个具有相同大小的新分布并重复/替换；但不混合组（即假设效果/观察到的差异是真实的）。我计算了两个新分布的中位数差，并重复了 100000 次。
问题
在所有这些实现中，我计算了平均值和标准差，发现平均值（中位数差）与原始数据中位数差相比始终相差约 13%。
这是错误、测试设计错误还是实际可能的结果？如果是最后一个，为什么？这意味着什么？
代码
# 原始实验数据：A、B
# 绘制新的分布 a、b，不进行混合
a = np.random.choice(A, (100000, len(A), True) 
b = np.random.choice(B, (100000, len(B), True)
med_m = np.mean(np.median(a, axis = 1) - np.median(b, axis = 1))
med_s = np.std(np.median(a, axis = 1) - np.median(b, axis = 1))
med = np.median(A) - np.median(B)

med_m / med
&gt;&gt;&gt; 1.13...
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/648458/mean-of-medians-consistently-differs-from-median</guid>
      <pubDate>Sun, 02 Jun 2024 00:57:18 GMT</pubDate>
    </item>
    <item>
      <title>按离散的、不相关的属性进行聚类？</title>
      <link>https://stats.stackexchange.com/questions/648455/clustering-by-discrete-unrelated-properties</link>
      <description><![CDATA[我有大量具有不相关属性的对象，例如

color=yellow
material=stone
is_important=true
等等。

这些属性基本上是随机的，只要用户认为有就好。没有实际的方法可以将这些属性强制转换为具有欧几里得距离的类似物。
我认为，如果不存在某种距离度量，那么从概念上讲，考虑通过这些属性对对象进行聚类是没有意义的（这是正确的吗？），但我希望存在可以产生类似输出的东西
“90% 的 color=yellow 对象也有 material=plastic 和 is_important=false”
除了强制通过数据集之外，还有其他东西可以进行此类分析吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648455/clustering-by-discrete-unrelated-properties</guid>
      <pubDate>Sun, 02 Jun 2024 00:19:01 GMT</pubDate>
    </item>
    <item>
      <title>我们可以使用 CDF 而不是 PDF 来表达无意识统计学家的定律吗？[重复]</title>
      <link>https://stats.stackexchange.com/questions/648452/can-we-express-the-law-of-the-unconscious-statistician-using-the-cdf-instead-of</link>
      <description><![CDATA[我只见过LOTUS以密度形式给出
$$\mathbb{E}[g(X)] = \int g(x) f(x) dx$$
或以勒贝格-斯蒂尔杰斯积分形式给出
$$\mathbb{E}[g(X)] = \int g(x) dF_X(x).$$
我还见过这篇文章，其中展示了如何使用 CDF 而不是PDF：

与计算这些矩类似，有没有办法使用 CDF 而不是 PDF 来编写 LOTUS？]]></description>
      <guid>https://stats.stackexchange.com/questions/648452/can-we-express-the-law-of-the-unconscious-statistician-using-the-cdf-instead-of</guid>
      <pubDate>Sat, 01 Jun 2024 22:37:36 GMT</pubDate>
    </item>
    <item>
      <title>什么是协同过滤？</title>
      <link>https://stats.stackexchange.com/questions/648424/what-defines-collaborative-filtering</link>
      <description><![CDATA[协同过滤的定义特征是什么？
如果您采用两个嵌入向量（一个用于用户，一个用于项目），您可以进行点积并将结果传递给 S 型函数来预测 CTR。这是协同过滤吗？
或者，您可以在每个嵌入上放置多个 FC 层，然后进行点积。这是协同过滤吗？
您还可以将多个离散和连续特征连接到每个嵌入，然后将它们传递给 FC 层并进行 S 型函数。这是协同过滤吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648424/what-defines-collaborative-filtering</guid>
      <pubDate>Sat, 01 Jun 2024 09:23:06 GMT</pubDate>
    </item>
    <item>
      <title>条件 Logit 模型 - 效用结构估计 - 元分析</title>
      <link>https://stats.stackexchange.com/questions/648401/conditional-logit-model-utility-structural-estimation-meta-analysis</link>
      <description><![CDATA[我正在使用 McFadden (2001) 框架（参见参考资料）对多个数据库（来自不同的文章）中的效用函数进行结构估计。
每篇文章的数据库包含 N 个主题、J 个选项，从而给出 J x N 行。每个主题都选择了 J 个选项中的一个。数据还包括一些特定于选择的特征。
使用此数据结构，我通过条件逻辑模型 (CLM) 以两种方式估计效用参数：
一般估计：我对整个数据集运行了一个唯一的 CLM。请注意，J 可以在不同文章中变化
逐篇文章估计：我对每篇文章运行一个 CLM，并对结果估计进行平均
但是，这两种方法给出的结果截然不同。
有谁知道哪种程序（如果有的话）最适合提供这些参数的元估计？
谢谢！
参考文献：McFadden，D.（2001）。经济选择。美国经济评论，91(3)，351-378。]]></description>
      <guid>https://stats.stackexchange.com/questions/648401/conditional-logit-model-utility-structural-estimation-meta-analysis</guid>
      <pubDate>Fri, 31 May 2024 16:58:04 GMT</pubDate>
    </item>
    <item>
      <title>随机效应模型：理解与、之间和上下文效应</title>
      <link>https://stats.stackexchange.com/questions/648373/random-effect-models-understanding-with-between-and-contextual-effect</link>
      <description><![CDATA[为了更好地理解和更有效地应用随机/固定效应和聚类标准误差，我一直在努力理解“内部”、“之间”和“上下文”效应这些术语。

据我所知，我们只能在没有上下文效应的情况下应用随机效应模型 - 否则随机效应假设不成立。对吗？这是否也意味着在这种情况下，组内和组间效应是相同的？

请看以下示例：



数据：汇总的横断面调查数据，其中各个受访者嵌套在各个国家/地区，并且多年来在每个国家/地区进行多次调查
研究问题旨在找出国家级变量（例如 GDP）是否影响受访者回答有关生活满意度的问题的方式
感兴趣的影响：GDP 对生活满意度的总体影响

我感兴趣的是哪种影响：组内、组间还是上下文？这样的研究是否需要随机效应模型？或者聚类标准误差就足够了？]]></description>
      <guid>https://stats.stackexchange.com/questions/648373/random-effect-models-understanding-with-between-and-contextual-effect</guid>
      <pubDate>Fri, 31 May 2024 12:58:22 GMT</pubDate>
    </item>
    </channel>
</rss>