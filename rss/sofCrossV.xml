<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 18 Jan 2025 03:17:03 GMT</lastBuildDate>
    <item>
      <title>如何根据诊断图改进线性模型</title>
      <link>https://stats.stackexchange.com/questions/660185/how-to-improve-linear-model-based-on-diagnostic-plots</link>
      <description><![CDATA[我一直在处理包含五个变量和一个响应的数据集，如下所示：
.CSV 文件
使用 Python，我从以下代码开始：
import statsmodels.api as sm
import numpy as np
X = subset[[&#39;X1&#39;, &#39;X2&#39;, &#39;X3&#39;, &#39;X4&#39;]]
y = subset[&#39;Y&#39;]
X = sm.add_constant(X)
model = sm.OLS(y, X)
result = model.fit()
plt.figure(figsize=(8, 6))
plt.scatter(fitted_values, residuals, color=&#39;blue&#39;, edgecolors=&#39;k&#39;, alpha=0.7)
plt.axhline(y=0, color=&#39;red&#39;, linestyle=&#39;--&#39;)
plt.title(&#39;残差 x 预测值&#39;)
plt.xlabel(&#39;预测值&#39;)
plt.ylabel(&#39;残差&#39;)
plt.show()

给出模型摘要：

我不知道如何处理“残差 x 预测图”的结果。在探索性分析过程中，我发现这些变量与 Y 有中等相关性，因此我选择它们来构建初始模型。从该图中，我们可以说方差不是恒定的吗？此外，从这种模式中，我们可以获得有关如何改进模型的任何见解吗？

我尝试对 X 变量应用对数或 box-cox 变换，但它并没有改变变量散点图的可视化。我考虑过应用加权最小二乘法，例如，对 Y 大于 100 的位置赋予较低的权重，但图并没有改善，模式几乎相同。或者如果它真的是一个非线性问题，我想如果一些机器学习方法在这里可以更好地发挥作用，但我首先想尝试基本方法。
如果有人能提供一些想法/代码来处理这种情况，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660185/how-to-improve-linear-model-based-on-diagnostic-plots</guid>
      <pubDate>Fri, 17 Jan 2025 20:39:09 GMT</pubDate>
    </item>
    <item>
      <title>评估混合模型聚类和分类的准确性</title>
      <link>https://stats.stackexchange.com/questions/660184/evaluating-accuracy-of-mixture-model-clustering-and-categorisation</link>
      <description><![CDATA[我正在运行混合模型，我没有自由参数，我只是让它评估给定数据点属于一个集群的可能性。另外，我有一个关于这些值的基本事实，但模型从未见过。我想测试模型是否成功预测了数据点集群的可能性。您建议哪些指标最适合此目的？
交叉熵 RMSE MAE 和其他指标是好的指标吗？
（我知道经典模型比较 - 例如，BIC、AIC、WAIC CV_LOO 等等，但我不是在测试我的模型是否是最佳模型，而是在测试它是否能够预测聚类）]]></description>
      <guid>https://stats.stackexchange.com/questions/660184/evaluating-accuracy-of-mixture-model-clustering-and-categorisation</guid>
      <pubDate>Fri, 17 Jan 2025 19:23:57 GMT</pubDate>
    </item>
    <item>
      <title>帮助理解吉布斯采样问题？</title>
      <link>https://stats.stackexchange.com/questions/660183/help-understanding-gibbs-sampling-problem</link>
      <description><![CDATA[我正在努力理解一个特定的问题，并设计了一个类似的场景
如果我要分析三组就读寄宿学校的学生，每组学生分别在两个教室中的一个，并住在三个宿舍中的一个，那么这些数据可以可视化为如下所示的有向无环图。
如果一名教职员工试图找出每个组、房间和宿舍对特定学生结果的影响，他们将如何做，以及可以以何种确定性收集这些信息？
假设成绩遵循某种偏态分布$P(\Theta_G = \theta_G, \Theta_R = \theta_R, \Theta_D = \theta_D)$其中$\theta_G\in\{1,2,3\}$
这个过程中边际是如何计算的，是否必须使用吉布斯抽样，还是可以通过代数过程，这是如何完成的？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660183/help-understanding-gibbs-sampling-problem</guid>
      <pubDate>Fri, 17 Jan 2025 18:53:38 GMT</pubDate>
    </item>
    <item>
      <title>季节性虚拟变量回归。为什么我们要在这个回归中使用时间趋势？或者说，在什么情况下我们应该使用时间趋势？</title>
      <link>https://stats.stackexchange.com/questions/660180/regression-with-seasonal-dummies-why-do-we-use-time-trend-in-this-regression-o</link>
      <description><![CDATA[我的导师希望我用季节性虚拟变量进行回归分析。
我有 DPPI 指数（土耳其国内生产者价格指数），这是月度数据。
首先，我需要用截距项和 11 个虚拟变量进行回归分析。
其次，我需要用 12 个虚拟变量进行不带截距项的回归分析。
在这两种情况下，我都应该包括时间趋势项吗？在哪种情况下，或者为什么包括时间趋势项？
或者，我应该同时使用和不使用时间趋势项进行这两个回归分析吗？
我的最后一个问题是我需要分析残差。为此，我应该对残差应用哪些测试或图？
请与我分享您的想法。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660180/regression-with-seasonal-dummies-why-do-we-use-time-trend-in-this-regression-o</guid>
      <pubDate>Fri, 17 Jan 2025 18:42:39 GMT</pubDate>
    </item>
    <item>
      <title>在高斯 - 马尔可夫假设中，给定预测变量的误差条件期望等于协方差[重复]</title>
      <link>https://stats.stackexchange.com/questions/660178/conditional-expectation-of-errors-given-predictors-equals-covariance-in-gauss-ma</link>
      <description><![CDATA[在此视频的 2:08 处，谈到 OLS 中的高斯-马尔可夫假设，Ben Lambert 说$\mathbb{E}(​​u_i|x_i)=0$ 等同于 $Cov(u_i, x_i)=0$，用数学符号表示为$\mathbb{E}(​​u_i|x_i)=0 \Leftrightarrow Cov(u_i, x_i)=0$。
这是为什么？
你如何证明这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/660178/conditional-expectation-of-errors-given-predictors-equals-covariance-in-gauss-ma</guid>
      <pubDate>Fri, 17 Jan 2025 18:35:59 GMT</pubDate>
    </item>
    <item>
      <title>使用对数链接解释 GLM 模型中的系数</title>
      <link>https://stats.stackexchange.com/questions/660177/interpretation-of-the-coefficients-in-a-glm-model-using-the-log-link</link>
      <description><![CDATA[当在 GLM 设置中使用对数链接时，目标均值和线性预测器通过以下方式关联：
$$
\mu = e^{\beta_0}\prod_{i=1}^p e^{\beta_i X_i}
$$
我的学习手册说，当 $X_j$ 是具有系数 $\beta_j$ 的数字预测器时，我们可以用以下方式描述 $X_j$ 和 $\mu$ 之间的关联

当所有其他变量保持不变时，$X_j$ 的单位增加与乘法增加相关目标均值增加 $e^{\beta_j}$ 倍，即
$$
\text{new} \ \mu = e^{\beta_j} \times \ \text{old} \ \mu \tag{1}
$$

我不确定作者是如何得出这个解释的。我认为这个过程看起来像是这样的
$$
\frac{\partial \mu}{\partial X_j} = \beta_j \times e^{\beta_0}\prod_{i=1}^p e^{\beta_i X_i} = \beta_j \times \text{old} \ \mu \tag{2}
$$
所以
$$
\text{new} \ \mu = \text{old} \ \mu + \frac{\partial \mu}{\partial X_j} = \text{old} \ \mu + \beta_j \times \text{old} \ \mu = (\text{old} \ \mu )(1 + \beta_j) \tag{3}
$$
显然，$(1)$ 和 $(3)$ 完全不同，所以我不确定我的错误是什么。我在 $(2)$ 或 $(3)$ 中的工作是否不正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/660177/interpretation-of-the-coefficients-in-a-glm-model-using-the-log-link</guid>
      <pubDate>Fri, 17 Jan 2025 18:31:37 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SE 和 P 值计算每 100,000 个比率之间的差异</title>
      <link>https://stats.stackexchange.com/questions/660173/how-to-calculate-the-difference-between-2-rates-per-100-000-with-se-and-p-value</link>
      <description><![CDATA[我有一个数据集，其中包含每年记录的每 100,000 人口年龄调整死亡率及其针对特定疾病的标准误差 (SE)。数据来自 CDC Wonder 数据库。
我旨在通过计算差异、构建置信区间 (CI) 和确定此差异的 p 值来比较两个特定年份之间的死亡率。
此外，我旨在通过以下方式计算相对比率变化：
$$
\text{相对变化} = \frac{(\text{第 2 年比率} - \text{第 1 年比率})}{\text{第 2 年比率}}
$$
这在统计上合适吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660173/how-to-calculate-the-difference-between-2-rates-per-100-000-with-se-and-p-value</guid>
      <pubDate>Fri, 17 Jan 2025 16:46:06 GMT</pubDate>
    </item>
    <item>
      <title>伪似然与似然的比较</title>
      <link>https://stats.stackexchange.com/questions/660172/pseudolikelihood-compared-to-likelihood</link>
      <description><![CDATA[假设我们有一个离散多元概率分布，其密度$f_{\theta}(X=(x_1,\ldots,x_n))=\frac{g_{\theta}(X=(x_1,\ldots,x_n))}{Z}$取决于某个参数$\theta$。我特意以这种形式将其写出，以表示 Z 是难以计算的归一化常数（它也可能依赖于$\theta$）。这种分布的伪似然函数（为简单起见，针对单个数据点）是否定义为：
$$
PL_{\theta}(X=(x_1,\ldots,x_n)) = \prod_{i}f_{\theta}(X_i=x_i | X_j=x_j, i \neq j)
$$
如果是这样，则由此得出的公式在我看来有点奇怪，因为：
$$
= \prod_{i}\frac{g_{\theta}(X)}{\sum_{X_i=a}g_{\theta}(X_1=x_1,\ldots,X_i=a,\ldots)}
$$
调用分母 $Z_i(X)$ 可得到：
$$
\log(PL_{\theta}(X=(x_1,\ldots,x_n))) = n \log(g_{\theta}(X)) - \sum_i \log( Z_i(a))
$$
而真实可能性为
$$
\log(L_{\theta}(X=(x_1,\ldots,x_n))) = \log(g_{\theta}(X)) - \log(Z)
$$
我不知道为什么伪对数可能性可以替代对数可能性。我确实知道计算起来比可能性容易得多，但我无法理解为什么这是一个可接受的估计值。原始文章（格点数据的统计分析）在这方面没有太大帮助，维基百科上的文章也很简短。我知道现在人们可能更喜欢蒙特卡洛方法，但我仍然想了解一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/660172/pseudolikelihood-compared-to-likelihood</guid>
      <pubDate>Fri, 17 Jan 2025 16:25:55 GMT</pubDate>
    </item>
    <item>
      <title>加权交叉熵的理论依据</title>
      <link>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</link>
      <description><![CDATA[假设我们正在构建一个二元分类模型，可以将其视为学习函数
$$ p : X \mapsto [0, 1] $$
其中$p(X) := \mathbb{P}(Y=1|X)$，而$\hat{p}$是某种机器学习模型（例如神经网络）。
常用的损失函数是最小化$p$和$\hat{p}$之间的负交叉熵：
$$ l(p, \hat{p}) = -y\log \hat{p}(x) - (1-y)\log(1-\hat{p}(x))$$
这当然相当于模型$Y|X \sim Bernoulli(p(X))$的最大似然估计。
在某些情况下，结果高度不平衡，这使得训练在实践中变得困难。例如，如果数据是垃圾邮件分类，其中只有 1% 的结果是垃圾邮件，那么很容易收敛到一个简单的解决方案/局部最优，它只为每个观察设置$p(X) \approx 0$。理论上，在大样本量和全局最优的情况下，这不是问题 - 但在实践中，这可能是一个大问题。
解决这个问题的一种常见方法是使用“加权交叉熵”损失，其中权重与观察到的频率成比例。例如，
$$w_0 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=0\}}, w_1 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=1\}} $$
损失为
$$ l^{weighted}(p, \hat{p}) = -w_1y\log\hat{p}(x) - w_0(1-y)\log(1-\hat{p}(x)) $$
其中直觉是稀有类别的权重更高，因此模型“更加关注”对这些观察结果。

通过最小化这个加权损失函数找到的最优函数 $\hat{p}^{weighted}$ 是否有任何已知的理论性质，或者它是否纯粹是启发式的？在全局最优值中，最优 $\hat{p}$ 和 $\hat{p}^{weighted}$ 相比如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</guid>
      <pubDate>Fri, 17 Jan 2025 09:25:45 GMT</pubDate>
    </item>
    <item>
      <title>日食是否减少了新冠肺炎死亡人数？</title>
      <link>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</link>
      <description><![CDATA[我在 R 中模拟了一些现实数据，这些数据显示了 Covid-19 死亡人数随时间的变化情况，以及日食（2024 年 4 月 8 日）发生前的天数：

如果有人不太了解，仅从数据来看，可能会认为日食是降低 Covid 死亡人数的原因。此外，有人可以拟合回归模型，该模型甚至可能很好地拟合数据。
我读到过，我们在统计学中拥有所有这些复杂的技术，例如差异-差异、回归不连续性、合成控制、工具变量、倾向得分匹配等 - 所有这些方法旨在在某种程度上找出我们是否能够真正得出结论，统计模型的结果忠实地代表了自然（例如因果关系与联想关系）。
但在某种程度上，我们在决定将哪些变量纳入统计模型时是否只是使用常识？]]></description>
      <guid>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</guid>
      <pubDate>Fri, 17 Jan 2025 05:13:01 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归中的虚拟变量与虚拟变量交互作用</title>
      <link>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</link>
      <description><![CDATA[我正在 R 中进行泊松回归，以估计按年龄组和病毒分类的死亡人数，其中相互作用的项是因子：
model &lt;- glm(death_count ~ strain * cohort + age + year,
family = poisson(link = &quot;log&quot;),
offset = log(exposure),
data = df)

我的 df 是面板数据，其中包含每年特定年龄的死亡人数。每年都以特定病毒为特征，每个年龄分配一个群体。我试图找出以病毒 C 为特征的年份中死亡人数减少的统计意义。以下是简化的回归输出：
 估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -15.39575 0.07621 -202.012 &lt; 2e-16 ***
病毒A -1.29389 0.08358 -3.516 0.000437 ***
病毒B 2.80059 0.06230 12.851 &lt; 2e-16 ***
病毒C 4.22142 0.05298 60.800 &lt; 2e-16 ***
群组X -2.99472 0.02494 -39.890 &lt; 2e-16 ***
群组Y -1.76074 0.02747 -27.691 &lt; 2e-16 ***
群组Z -1.31331 0.03499 -8.953 &lt; 2e-16 ***
病毒A：群组X 1.39666 0.07366 5.385 7.24e-08 ***
病毒B：群组X 1.21714 0.05685 3.820 0.000134 ***
病毒C：群组X -3.97906 0.03390 -28.883 &lt; 2e-16 ***
病毒A：队列Y 1.24520 0.10246 2.393 0.016701 * 
病毒B：队列Y 1.05056 0.07980 0.634 0.526360 
病毒C：队列Y -1.43923 0.03422 -12.836 &lt; 2e-16 ***
virusA:cohortZ 0.12472 0.13408 0.930 0.352274 
virusB:cohortZ -0.33748 0.11851 -2.848 0.004404 ** 
virusC:cohortZ -1.13441 0.04187 -3.210 0.001327 ** 

我知道没有交互项的系数是与参考组相比的，但我听说在泊松回归中，交互项并不那么简单。
我有兴趣解释为什么与队列 Y 和 Z 相比，队列 X 感染病毒 C 的死亡率减少幅度最大。我不太明白如何理解交互系数，我也不明白为什么截距为负。如果没有偏移量，截距 = 0.18252，我无法理解这一点，因为我认为添加偏移量会将 DV 变成速率。]]></description>
      <guid>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</guid>
      <pubDate>Fri, 17 Jan 2025 00:16:33 GMT</pubDate>
    </item>
    <item>
      <title>在 Anderson-Gill 模型中，tstart 和 tstop 可以相同吗？</title>
      <link>https://stats.stackexchange.com/questions/660134/can-tstart-and-tstop-be-the-same-in-an-anderson-gill-model</link>
      <description><![CDATA[我正在处理事件发生时间数据，并使用 R 中生存包的 coxph() 函数中实现的 Anderson-Gill 模型。在此模型中，时间间隔由 tstart（开始时间）和 tstop（停止时间）定义，我需要了解如何处理 tstart == tstop 的间隔。
具体来说，我想知道：
在 Anderson-Gill 模型中，tstart 和 tstop 相同是否有效？
如果不是，零长度间隔的含义是什么，应该如何处理？
例如，考虑以下数据集：



id
tstart
tstop
event




1
0
10
1


1
10
10
1


2
5
5
1



当我尝试使用 coxph(Surv(tstart, tstop, event) ~ 1, data = my_data)，我收到有关 tstart == tstop 的警告。我理解零长度间隔并不代表有意义的风险时间，但我想确认解决这种情况的最佳方法。
我应该如何处理这些情况？我应该：排除 tstart == tstop 的行？为 tstop 添加一个小值（例如，tstop = tstart + 1e-5）？还有其他推荐的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660134/can-tstart-and-tstop-be-the-same-in-an-anderson-gill-model</guid>
      <pubDate>Thu, 16 Jan 2025 23:19:41 GMT</pubDate>
    </item>
    <item>
      <title>进行缺失数据插补是否会导致观测值之间的依赖性？</title>
      <link>https://stats.stackexchange.com/questions/660127/does-doing-missing-data-imputation-lead-to-dependency-between-observations</link>
      <description><![CDATA[当对数据集的所有观测值进行插补时，这是否会导致观测值之间的依赖性？那么假设观测值是独立的统计模型是否不够充分？
我理解，在观测值中的变量之间当然存在关系/依赖性。我对观测值之间的依赖性很好奇。
两个观测值$y_i$和$y_j$，它们是独立随机抽样的，因此$y_i \perp\!\!\perp y_j$。 $y_i$ 缺失，并且使用 $y_j$ 或更多观测值的函数来输入 $y_i$
例如，$K$ 个最近邻域。根据不缺失的 $X$ 找到 $K$ 个最近的观测值，然后将其归结为 $y_i = 1/K\sum_j^K y_j$。
$y_i$ 是 $K$ 个观测值 $y$ 变量的函数，这是否意味着 $y_i$ 和 $K$ 个观测值 $y$ 是相关的？]]></description>
      <guid>https://stats.stackexchange.com/questions/660127/does-doing-missing-data-imputation-lead-to-dependency-between-observations</guid>
      <pubDate>Thu, 16 Jan 2025 20:41:13 GMT</pubDate>
    </item>
    <item>
      <title>连续随机变量的充分统计因式分解定理</title>
      <link>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics-in-case-of-continuous-random-var</link>
      <description><![CDATA[根据因式分解定理 (Fisher-Neyman)，我们得到一个统计量 $ T(X) $ 充分当且仅当存在因式分解：$ f(x\mid \theta) = g(T(x)\mid \theta)h(x) $。符号遵循 Casella/Berger 第页。 276.
Casella/Berger 在离散情况下给出了证明，指出具体分解的形式如下：$$ P(X=x \mid {\theta}) = P(T(X) = T(x) \mid {\theta})P(X=x \mid T(X) = T(x)) $$
我的问题是：我们能否将这种解释应用于连续情况，并且它总是成立吗？因此：$ f(x\mid \theta) = f(T(x)\mid \theta)f(x\mid T(x)) $ 其中 $f$ 表示相应的 pdf？]]></description>
      <guid>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics-in-case-of-continuous-random-var</guid>
      <pubDate>Mon, 13 Jan 2025 22:52:25 GMT</pubDate>
    </item>
    <item>
      <title>对称单峰分布系列，其中峰度与峰值成反比？</title>
      <link>https://stats.stackexchange.com/questions/659400/family-of-symmetric-unimodal-distributions-where-kurtosis-is-inversely-related</link>
      <description><![CDATA[DeCarlo 于 1997 年在著名期刊《心理学方法》上发表了论文《论峰度的意义和用途》。该论文被广泛引用（引用次数超过 1500 次，其中 129 次“极具影响力”），人们仍然在文献和网络内容中频繁引用该论文。然而，摘要的第一句话指出：

对于对称单峰分布，正 [过量] 峰度表示
相对于正态分布，尾部较重且呈尖峰状，而负 [过量] 峰度表示尾部较轻且呈平坦状。

这种说法在尖峰状和平坦状方面是不正确的，并且无疑导致了“尖峰状/平坦状”现象的持续存在尽管最近的研究彻底推翻了峰度可以衡量分布的峰值或平坦度（无论是对称分布还是单峰分布）的观点，但这种误解仍然难以消除。
如果给出一组对称单峰分布，其中峰度降低时分布变得更加尖锐，峰度增加时分布变得更加平顶，这将有助于消除这种误解。
（编辑：由于“峰值”定义不明确，因此出于本练习的目的，可以将其操作为标准化变量分布的高度。）
这种对称单峰族的一个简单示例是$\{F_1, F_2\}$，其中$F_1$ 和 $F_2$ 在 维基百科页面 中给出：$F_1$ 是参数为 $0.5$ 和 $1$ 的 beta 分布与其关于 $0.0$ 的反射的均等混合，而 $F_2$ 是 $−1$ 和 $1$ 具有 $T(4.0000001)$ 学生 t 分布，混合概率为 $0.999$ 和 $0.001$。这些分布对应的标准化变量的密度函数如下所示：


在这个家族中，较低峰度（和“platykurtic”）分布是“无限峰值”，而较高峰度分布较低，且呈现完美的平顶。
然而，描述一个更传统的无限族$F_{\theta}$将会很有趣，其中$\theta$连续变化，峰度范围从&quot;platykurtic&quot; ($&lt;3$) 到无穷大，并且分布（所有对称和单峰）范围从无限峰值到几乎平顶，因为峰度范围从最小值到无穷大。
有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659400/family-of-symmetric-unimodal-distributions-where-kurtosis-is-inversely-related</guid>
      <pubDate>Tue, 31 Dec 2024 17:07:42 GMT</pubDate>
    </item>
    </channel>
</rss>