<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 24 Jan 2024 03:15:46 GMT</lastBuildDate>
    <item>
      <title>使用加权估计方程（WEE）估计缺失数据的线性回归模型时，如果缺失概率为 1，该怎么办</title>
      <link>https://stats.stackexchange.com/questions/637619/when-using-weighted-estimating-equations-wee-to-estimate-a-linear-regression-m</link>
      <description><![CDATA[使用加权估计方程 (WEE) 估计缺失数据的线性回归模型时。一种方法是随机假设缺失，然后使用一些回归模型（例如逻辑回归）计算缺失概率。
但是，考虑这种情况：我们有独立样本 $(Y_i,X_i),i=1,\ldots,n$，并且还有另一个二元协变量$Z_i$ 取 $\{0,1\}$ 上的值。当 $Z_i=0$ 时，第 $i$ 个观测值丢失。这种情况意味着缺失概率为 0 或 1。因此 WEE 中的权重是不可计算的。这种情况我们能做什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/637619/when-using-weighted-estimating-equations-wee-to-estimate-a-linear-regression-m</guid>
      <pubDate>Wed, 24 Jan 2024 02:43:54 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证和集成</title>
      <link>https://stats.stackexchange.com/questions/637618/cross-validation-and-ensemble</link>
      <description><![CDATA[我对五个预训练模型进行了 5 倍交叉验证。平均准确度最佳，我发现 VGG16 和 InceptionV3 在分类图像方面具有最佳的平均准确度。我想合并 InceptionV3 和 VGG16。我怎样才能从这里继续前进？我还为每次折叠保存了最佳模型 (.h5)。
我的计划是为 VGG16 和 InceptionV3 选择最佳的折叠，并通过堆叠将其集成。这是正确的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637618/cross-validation-and-ensemble</guid>
      <pubDate>Wed, 24 Jan 2024 02:19:37 GMT</pubDate>
    </item>
    <item>
      <title>如何查询嵌入以进行语义搜索？</title>
      <link>https://stats.stackexchange.com/questions/637617/how-to-query-embeddings-for-semantic-search</link>
      <description><![CDATA[我对某些 SKU 商品有 1000 个描述，我想生成逆嵌入映射来进行语义搜索
例如，这就是我所拥有的
项目描述
项目1 [单词1，单词2，单词3，单词4......]
项目2 [字1、字2_2、字3_3、字4_4......]

如您所见，item1 和 item2 共享 word1，但 item1 和 item2 有两个不同的上下文，通过生成嵌入，我们应该能够捕获每个单词的上下文
这是我生成嵌入的方法
my_description = []
以 open(&#39;/content/gdrive/My Drive/my.csv&#39;, &#39;r&#39;) 作为数据：
    df = pd.read_csv(数据, 编码 = (&#39;utf-8&#39;),nrows=100)
    对于索引，df.iterrows() 中的行：
        my_str = 行[&#39;描述&#39;]
        my_description.append(my_str)



进口火炬
从 Transformer 导入 BertTokenizer、BertModel
%matplotlib 内联
tokenizer = BertTokenizer.from_pretrained(&#39;bert-base-uncased&#39;)
模型 = BertModel.from_pretrained(&#39;bert-base-uncased&#39;,
output_hidden_​​states = True, # 模型是否返回所有隐藏状态。
）
模型.eval()


文本2 = 公司描述[0]

# 添加特殊标记。
标记文本2 =“[CLS]” + 文本2 + &quot; [九月]”

# 将句子分割成标记。
tokenized_text2 = tokenizer.tokenize(marked_text2)

# 将标记字符串映射到它们的词汇索引。
indexed_tokens2 = tokenizer.convert_tokens_to_ids(tokenized_text2)

snippets_ids2 = [1] * len(tokenized_text2)
tokens_tensor2 = torch.tensor([indexed_tokens2])
snippets_tensors2 = torch.tensor([segments_ids2])

使用 torch.no_grad()：
    输出2 =模型（tokens_tensor2，segments_tensors2）
    隐藏状态2 = 输出2[2]

token_embeddings2 = torch.stack(hidden_​​states2, 暗淡=0)
token_embeddings2.size()
token_embeddings2 = torch.squeeze(token_embeddings2, 暗淡=1)
token_embeddings2.size()
token_embeddings2 = token_embeddings2.permute(1,0,2)
token_embeddings2.size()

token_vecs_cat2 = []

对于 token_embeddings2 中的令牌：
     cat_vec = torch.cat((令牌[-1], 令牌[-2], 令牌[-3], 令牌[-4]), 暗淡= 0)
     token_vecs_cat2.append(cat_vec)
token_vecs_sum2 = []
将 numpy 导入为 np
x_token = np.empty((0, 768))

对于 token_embeddings2 中的令牌：
    sum_vec = torch.sum(token[-4:], dim=0)
    token_vecs_sum2.append(sum_vec)
    x_token = np.concatenate((x_token, sum_vec.numpy().reshape((1,-1))), axis=0)

x_token 将是我所有单词/令牌在一个描述中的嵌入
例如，item1 有 500 个 token，嵌入数为 700
x_token 的形状为 (500 x 700)
所以对于每个项目我都会有这样的东西
项目标记嵌入
项目 1 标记 1 [x1,x2,x3,.....]
项目 1 标记 2 [x1,x2,x3,.....]
....
项目 2 令牌 1_2 [x1,x2,x3,.....]
项目 2 标记 2_2 [x1,x2,x3,.....]
....
项目 n 标记 1_n [x1,x2,x3,.....]
项目 n 标记 2_n [x1,x2,x3,.....]

现在我的问题是如何执行搜索
如果我的搜索查询是一个句子
“word1 word2 word3.....wordn”
如果我为句子中的每个单词生成嵌入，并对每个标记的前 10 个最近邻执行 ANN
如果我的查询有 10 个令牌，我将得到 100 个项目描述（每个令牌 10 个）
在这种情况下，我如何入围前 10 名项目描述？我应该使用哪个令牌？
查询 = [token1, token2.......tokenN]

                   前10名的nearest_neighbor的物品，
query_token1 -&gt;; [项目x1_1、项目x1_2、项目x1_10]
query_token2 -&gt;; [itemx2_1、itemx2_2、itemx2_10]

我做语义搜索错了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637617/how-to-query-embeddings-for-semantic-search</guid>
      <pubDate>Wed, 24 Jan 2024 02:17:56 GMT</pubDate>
    </item>
    <item>
      <title>在持仓与时间图表上绘制误差线，其中 st。开发人员。用于向量而不是总位置</title>
      <link>https://stats.stackexchange.com/questions/637612/drawing-error-bars-on-a-position-vs-time-chart-where-st-dev-is-for-vectors-and</link>
      <description><![CDATA[我有以下数据用于位置与时间分析。

请注意，总距离只是平均向量距离的总和。我想在总距离与时间的图表上显示误差线。问题是，圣。开发人员。表中显示的是每个向量段的距离，而不是总距离。例如，在时间 0.000125，图表上的位置在总距离列下显示为 0.000407。但圣。开发人员。误差是针对从时间 0.000083 到 0.000125 的矢量测量，而不是从 0 到 0.000125 的矢量测量。我不知道这是否有什么不同。我只是展示圣。开发人员。为该点处的向量（在本例中 st.dev. 等于 0.000018）。我心中没有解决的问题是先前向量的错误怎么办？前一个向量的误差为 0.000024。然后之前的向量就有错误。我不需要以某种方式解释这些先前的错误吗？他们会被添加吗？我想我要说的是，如果第一段的误差为 11%，第二段的误差为 24%，那么在从 0 到第二段末尾的总距离上，这两个段的误差是多少段（或第三段、第四段等）？第一段的 11% 误差是否会增加第二段结束时总位置或距离的额外不确定性？]]></description>
      <guid>https://stats.stackexchange.com/questions/637612/drawing-error-bars-on-a-position-vs-time-chart-where-st-dev-is-for-vectors-and</guid>
      <pubDate>Wed, 24 Jan 2024 00:53:25 GMT</pubDate>
    </item>
    <item>
      <title>排队论中的随机任务处理时间</title>
      <link>https://stats.stackexchange.com/questions/637607/stochastic-task-processing-times-in-queueing-theory</link>
      <description><![CDATA[我正在努力解决一个运筹学问题，该问题有 3 个站点，包含 3 个不同的任务处理时间和不同的变异系数（例如，站点 1 有 3 个任务，变异系数分别为 1,0.5 和 0.75）。我被要求计算流线和各个车站的平均等待时间。假设周期时间是恒定的，并且流程遵循具有恒定 WIP 的同步推送策略。我该如何处理这个问题？我还应该说明对到达间隔时间的假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/637607/stochastic-task-processing-times-in-queueing-theory</guid>
      <pubDate>Tue, 23 Jan 2024 23:46:02 GMT</pubDate>
    </item>
    <item>
      <title>Matlab 中的 AdaBoost - 使用 Fisher 的 Iris 数据集仅获得 88% 的准确率，而在一层神经网络中则获得 100% 的准确率</title>
      <link>https://stats.stackexchange.com/questions/637600/adaboost-in-matlab-only-get-88-accuracy-with-fishers-iris-data-set-while-100</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637600/adaboost-in-matlab-only-get-88-accuracy-with-fishers-iris-data-set-while-100</guid>
      <pubDate>Tue, 23 Jan 2024 22:56:07 GMT</pubDate>
    </item>
    <item>
      <title>估计时间序列缺失观察的可能性</title>
      <link>https://stats.stackexchange.com/questions/637595/estimating-a-time-series-likelihood-of-a-missing-observation</link>
      <description><![CDATA[我有季节性月度数据的时间序列，其中有时缺少观察结果。
观测值缺失的可能性主要取决于月份，但也取决于观测值没有缺失的情况。我对下一次观察中该系列的价值进行了估计。我想估计它是否真的会从系列中丢失（即未观察到）。
显然，我也知道那是几月。
我可以对过去缺失的（未观察到的）数据（SARIMA 和/或外部指标）进行估计。
解决这个问题的最佳方法是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/637595/estimating-a-time-series-likelihood-of-a-missing-observation</guid>
      <pubDate>Tue, 23 Jan 2024 22:02:58 GMT</pubDate>
    </item>
    <item>
      <title>根据评估者间的一致性估计敏感性和特异性？</title>
      <link>https://stats.stackexchange.com/questions/637593/estimate-sensitivity-and-specificity-from-inter-rater-agreement</link>
      <description><![CDATA[假设有两个二进制（{0, 1} 中的 Y）注释器或分类器（A 和 B），即：

条件独立，即 P(A=0, B=0|Y=1) = P(A=0|Y=1)*P(B=0|Y=1)，对于 Y=0 也是如此.
优于随机，即 ROC-AUC&gt;0.5

高 Cohen kappa 是否意味着高灵敏度和特异性？
是否可以根据 Cohen Kappa 估计（或至少设置下限）每个分类器（或其整体）的敏感性和特异性？
我的直觉是，如果两个假设都成立，那么要同意这些模型必须都符合基本事实。
我找不到任何关于根据协议指标直接估计准确性指标的文献。]]></description>
      <guid>https://stats.stackexchange.com/questions/637593/estimate-sensitivity-and-specificity-from-inter-rater-agreement</guid>
      <pubDate>Tue, 23 Jan 2024 21:55:54 GMT</pubDate>
    </item>
    <item>
      <title>嵌套时间序列的混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/637591/mixed-effects-model-of-nested-time-series</link>
      <description><![CDATA[我有来自不同气候模型的变量的时间序列数据，每个模型都使用不同的初始条件（集合成员）进行多次运行。一小部分数据，以了解其布局（竞争数据集包括 36 年和 19 个模型，每个模型有 5 到 49 个成员）。
&lt;前&gt;&lt;代码&gt;#&gt;会员模特时间 hgt
#&gt;  &lt;字符&gt;  &lt;num&gt;
#&gt; 1: 1.1.1.1 访问-CM2 1979 -0.045225795
#&gt; 2: 1.1.1.1 访问-CM2 1980 -0.009871858
#&gt; 3: 1.1.1.1 访问-CM2 1981 -0.062349852
#&gt; 4：2.1.1.1 访问-CM2 1979 -0.051631382
#&gt; 5：2.1.1.1 访问-CM2 1980 -0.043643211
#&gt; 6：2.1.1.1 访问-CM2 1981 -0.029604119
#&gt; 7：1.1.1.1 访问-ESM1-5 1979 -0.009869267
#&gt; 8：1.1.1.1 访问-ESM1-5 1980 -0.014024862
#&gt; 9: 1.1.1.1 访问-ESM1-5 1981 -0.016568455
#&gt; 10：2.1.1.1 访问-ESM1-5 1979 -0.008007551
#&gt; 11：2.1.1.1 访问-ESM1-5 1980 -0.009915181
#&gt; 12：2.1.1.1 访问-ESM1-5 1981 -0.015526597
#&gt; 13：1.1.1.1 AWI-CM-1-1-MR 1979 -0.030887150
#&gt; 14：1.1.1.1 AWI-CM-1-1-MR 1980 -0.036778999
#&gt; 15：1.1.1.1 AWI-CM-1-1-MR 1981 -0.028872595
#&gt; 16：2.1.1.1 AWI-CM-1-1-MR 1979 -0.046219117
#&gt; 17：2.1.1.1 AWI-CM-1-1-MR 1980 -0.024323372
#&gt; 18：2.1.1.1 AWI-CM-1-1-MR 1981 -0.024374409

我想对线性趋势进行建模，同时考虑到集合成员和模型的不确定性。为此，我计划使用混合效应建模，将集合成员视为随机效应（因为它们是可能模型运行总体的随机样本），将模型视为固定效应（模型不是随机的，也不是从更大的样本中采样的）人口）。
第一个问题：我的推理合理吗？我错过了什么吗？
所以，现在在 R 中进行编码。我使用的是 lme4，如果我正确理解了文档，我想我需要使用这样的公式：
库(lme4)
模型 &lt;- lmer(hgt ~ 时间*模型 + (时间 | 模型/成员), 数据 = 数据)
#&gt;边界（单数）拟合：参见 help(&#39;isSingular&#39;)

因此，时间与模型相互作用的固定效应，因此斜率（和截距）可以在模型之间变化，再加上嵌套在 modelmember 的随机效应code&gt; 这样每个成员也可以有一个随机斜率（和截距）。
第二个问题：这个公式正确吗？
这种方法存在的两个问题是，我没有获得平均时间效果，而是为每个模型获得了一个斜率。
第三个问题：如何获得平均斜率及其不确定性？我是否需要将模型效应视为随机，因为我在某种程度上假设存在控制模型效应分布的“平均斜率”？
第二个问题是我收到一条警告，指出拟合是单一的。我测试了共线性，并在模型中发现了一些重复的成员，但我在该数据中删除了它，所以这不是问题。
# 所有时间序列之间最高的四个相关性
数据%&gt;%
  data.table::copy() %&gt;%
  .[, 成员 := 交互(模型, 成员)] %&gt;%
  widyr::pairwise_cor(成员, 时间, hgt, 排序 = TRUE, upper = FALSE) %&gt;%
  data.table::as.data.table() %&gt;%
  头(4)
#&gt;项目1 项目2 相关性
#&gt;   &lt;num&gt;
#&gt; 1：访问-ESM1-5.14.1.1.1 CanESM5.11.1.1.1 0.6410348
#&gt; 2：访问-ESM1-5.40.1.1.1 MIROC6.5.1.1.1 0.6364663
#&gt; 3：CNRM-CM6-1.10.1.1.2 MPI-ESM1-2-HR.5.1.1.1 0.6300627
#&gt; 4：CESM2.10.1.1.1 NESM3.2.1.1.1 0.6281228

第四个问题：这严重吗？是什么原因导致了这个问题？
创建于 2024 年 1 月 23 日，使用 reprex v2.0.2]]></description>
      <guid>https://stats.stackexchange.com/questions/637591/mixed-effects-model-of-nested-time-series</guid>
      <pubDate>Tue, 23 Jan 2024 21:43:35 GMT</pubDate>
    </item>
    <item>
      <title>R 中“by = 因子”的 GAM 图</title>
      <link>https://stats.stackexchange.com/questions/637590/gam-plot-in-r-for-by-factor</link>
      <description><![CDATA[我有一个与海豚相遇的数据集（计数数据），这些数据按“类型”分开事件检测（声音、视觉、混合）。我运行了 GAMM 来测试环境变量对遭遇次数的影响。我有以下代码：
s1 &lt;- gam(遇到 ~ s(dist, k= 5, by = type) +
          s(深度, k= 5, by = 类型) +
          s(timeenc, k= 5, by = type) + s(船, k= 5, by = type) +
          te(swell, bft, k= 3, by = 类型) + 类型 +
          s(line, bs= &quot;re&quot;) + offset(log(lineseg)), family = tw(),
          方法=“REML”，数据=sousa_full）

当我绘制模型时，我自然会为每个变量绘制三个图，显示它们对检测类型类别内遇到次数的影响。

有没有办法为每个变量绘制一个图来代表所有三个图？我正在使用 mgcViz 进行绘图，并且对整个事情非常陌生！]]></description>
      <guid>https://stats.stackexchange.com/questions/637590/gam-plot-in-r-for-by-factor</guid>
      <pubDate>Tue, 23 Jan 2024 21:36:02 GMT</pubDate>
    </item>
    <item>
      <title>每个用户具有多行的回归模型来预测死亡</title>
      <link>https://stats.stackexchange.com/questions/637580/regression-model-with-multiple-rows-per-user-to-predict-death</link>
      <description><![CDATA[我正在尝试建立一个回归模型，用于根据用户的实验室报告预测死亡率，问题是在我的数据集中，即使对于同一用户，每一行也是不同的实验室，例如：
值开始类别单位类型显示record.death种子report_Frequency
 3 25.83 1291715668918 生命体征 kg/m2 39156-5 体重指数 (BMI) [比率] 1561456468918 -4803776664509238228 4
25 26.47 1318326868918 生命体征 kg/m2 39156-5 体重指数 (BMI) [比率] 1561456468918 -4803776664509238228 4
37 27.42 1386669268918 生命体征 kg/m2 39156-5 体重指数 (BMI) [比率] 1561456468918 -4803776664509238228 4
49 29.19 1481622868918 生命体征 kg/m2 39156-5 体重指数 (BMI) [比率] 1561456468918 -4803776664509238228 4
74 19.35 1196939625807 生命体征 kg/m2 39156-5 体重指数 (BMI) [比率] 1490267625807 401572787436335446 10

我不太确定使用什么作为我的特征，我使用值、开始（这是时间戳中的实验室日期）和类型（这是指标类型的代码），目标变量是record.death，事情正如您在表中看到的那样，根据每个用户访问实验室的次数，我可以有多个行，我使用线性回归，但我的均方误差太高，可能出了什么问题？也许我需要为这种情况使用另一个模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/637580/regression-model-with-multiple-rows-per-user-to-predict-death</guid>
      <pubDate>Tue, 23 Jan 2024 19:19:52 GMT</pubDate>
    </item>
    <item>
      <title>R 中具有广泛范围和大量低频数据的计数数据的最佳绘图</title>
      <link>https://stats.stackexchange.com/questions/637567/best-plot-in-r-for-count-data-with-a-broad-range-and-lots-of-low-frequency-data</link>
      <description><![CDATA[我有一个看起来像这样的数据集，实际上大约有 20 个类别，数量为 1：
事情很重要
汽车500
卡车 250
吉普车 17
飞机 2
脚 1
橙子 1
膏药 1
葡萄 1
药片 1
枕头1

我尝试过绘制：

饼图（太多低频条目 - 第二次放大低计数中的一个，这看起来很愚蠢，因为它们的计数都是一）。

条形图：尾部有很多 1 计数，不太美观。

树状图（使用 treemapify） - 低频图块太多，很多人都没有自己的名字。


我想知道人们如何以可呈现的方式可视化这些数据。在线搜索不会产生很多有用的答案。也许我会坚持使用一张桌子？
这是一个玩具示例，实际上，我试图将已接受某种疾病基因诊断的患者形象化为“事物”。是基因，然后是它们的计数。许多人都有一种罕见基因，因此计数较低，但少数基因在诊断中所占比例较大。我想以最具视觉吸引力的方式讲述这个故事。我去过 R Gallery，但似乎没有一个图真正处理范围如此广泛的计数数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/637567/best-plot-in-r-for-count-data-with-a-broad-range-and-lots-of-low-frequency-data</guid>
      <pubDate>Tue, 23 Jan 2024 16:27:56 GMT</pubDate>
    </item>
    <item>
      <title>如何将多个二元（二项式）变量相互关联？</title>
      <link>https://stats.stackexchange.com/questions/637561/how-to-correlate-several-binary-binominal-variables-with-each-other</link>
      <description><![CDATA[我有一个数据集，描述了学生对 7 个问题（正确/错误）的回答。所以：

&lt;表类=“s-表”&gt;
&lt;标题&gt;


问题1
问题2
...
问题7


&lt;正文&gt;

学生#1
正确
正确

错误


学生#2
错误
正确

正确


学生#3
正确
正确

正确


...
...
...

...




我想将每个问题相互关联以查看模式，例如，当 Q1 回答正确时，Q7 也往往会回答正确。
我可以使用什么方法？四面相关性？点双列相关性？皮尔逊？
我不确定哪种方法最适合比较多个二元（二项式）变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/637561/how-to-correlate-several-binary-binominal-variables-with-each-other</guid>
      <pubDate>Tue, 23 Jan 2024 14:49:09 GMT</pubDate>
    </item>
    <item>
      <title>如何标准化线性混合效应模型的连续变量？</title>
      <link>https://stats.stackexchange.com/questions/637511/how-to-standardize-continuous-variable-for-linear-mixed-effect-model</link>
      <description><![CDATA[我正在将线性混合效应模型拟合到反应时间等行为数据。我有一个连续预测因素，那就是置信度。现在我想标准化预测器。我应该标准化所有参与者的置信度还是单独标准化每个参与者的置信度？]]></description>
      <guid>https://stats.stackexchange.com/questions/637511/how-to-standardize-continuous-variable-for-linear-mixed-effect-model</guid>
      <pubDate>Tue, 23 Jan 2024 02:28:30 GMT</pubDate>
    </item>
    <item>
      <title>Bing 藏文错误表情符号问题</title>
      <link>https://stats.stackexchange.com/questions/637505/the-bing-tibetan-glitch-emoji-problem</link>
      <description><![CDATA[这是一个非常有趣的数理统计难题，是我在使用 Bing 时偶然发现的。事实证明这个问题太深了，我花了相当长的时间思考如何解决它！尽管背景故事相对有趣，但看起来这可能是一个非常普遍（众所周知？）的统计问题。
请原谅我的篇幅，但我认为背景故事很有趣，值得分享:)
谜题：Bing 的新 AI 语言模型有一个非常奇特的错误。如果您向它发送一个来自未知“故障表情符号”列表中的单个表情符号，它会随机用藏语回复。例如，这是它对 🥲 的响应：

目标是描述引起此响应的所有表情符号的特征。由于表情符号有 3782 个，因此每个表情符号发送一条消息需要几个小时。
但有趣的是。如果您向 Bing 发送的消息仅包含有此“故障”的表情符号，财产，它会用西藏的废话来回应。但是，即使您发送一个没有表情符号的表情符号，它也会正常响应。这是两者的示例，其中 🥲🫥🤥🤫🤠 是故障表情符号，而 😊 不是：

因此，可以“批量测试”表情符号，并可能减少表征该集合所需的消息数量。大批量的风险更大，因为如果你足够幸运，选择了所有故障表情符号，你会立即获得大量信息，但如果没有，你除了至少有一个表情符号不是故障表情符号之外，一无所知。 
问题：用最少的消息来描述整套故障表情符号的最佳策略是什么？
为了简单起见，以下是我们可以做出的数学假设：

所有表情符号都同样可能是故障表情符号。
对于哪些表情符号是故障标记、哪些不是故障标记，没有特定的模式。
各种表情符号的故障/非故障状态在条件上都是相互独立的。
特别是，如果我们知道某些表情符号是或不是故障表情符号，我们假设这与概率无关，例如相邻的故障表情符号或任何其他表情符号。
我们可以访问一个黑盒函数，该函数将表情符号的一些子集作为输入，并且当且仅当每个表情符号都是故障表情符号时才返回 TRUE。

那么问题实际上是：如果你作为一个坚定的常客/贝叶斯/无论如何，被要求解决这个问题，并在尽可能少的查询中，在一些可证明最优的问题（相对到您认为“最佳”的任何内容）您会如何处理？
在我看来，“最佳”可能有多种概念。贝叶斯主义者和频率主义者对此可能有不同的看法。一个人可以尝试查看发送的消息数量的预期值；另一个可能会查看似然函数等。所以，我将其保留。我将在下面发布我的部分解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/637505/the-bing-tibetan-glitch-emoji-problem</guid>
      <pubDate>Tue, 23 Jan 2024 01:23:09 GMT</pubDate>
    </item>
    </channel>
</rss>