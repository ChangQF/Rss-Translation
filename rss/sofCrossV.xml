<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 02 Feb 2025 21:14:16 GMT</lastBuildDate>
    <item>
      <title>数据聚合方面的困惑</title>
      <link>https://stats.stackexchange.com/questions/660884/confusion-on-aggregation-of-data</link>
      <description><![CDATA[我有一组约 7500 场比赛结果的数据集。每场比赛只有两名参赛者，我正在查看两个起跑站之间的获胜率差异，并尝试按不同组别（男性比赛与女性比赛、经验水平、生理因素等）进行划分。
我使用二项分布累积概率函数来表明，如果两个站的获胜率是 50:50，则总体获胜率差异的可能性很小，但除此之外，我感到很困惑。与我在网上找到的示例不同，计算获胜率差异需要进行一些汇总（而不是人口身高或在网站上花费的时间）。
我希望能够说，在获胜率方面，性别/经验水平/体重存在/不存在统计差异。为此，我认为我需要使用 t 检验/方差分析。但要计算获胜率的差异，我需要以某种方式进行汇总。到目前为止，我都是按年份进行操作的，所以我计算每年的胜率差异，然后将其用于我的测试。但我想知道这是否会隐藏一些信息。但如果我想计算总体（所有年份）的胜率差异，我只剩下一个数字，我认为这意味着方差分析不起作用？令人困惑的是，使用按年份计算的胜率差异时的 p 值为 0.0016，按日期聚合时为 3.2。所以改变聚合级别肯定是有作用的！
我可以把最细的粒度级别降低到日级别，这样我就可以得到每天的胜率差异。我应该这么做吗？
或者我完全走错了路，应该使用不同的测试]]></description>
      <guid>https://stats.stackexchange.com/questions/660884/confusion-on-aggregation-of-data</guid>
      <pubDate>Sun, 02 Feb 2025 19:51:25 GMT</pubDate>
    </item>
    <item>
      <title>约翰森测试条件</title>
      <link>https://stats.stackexchange.com/questions/660882/johansen-test-conditions</link>
      <description><![CDATA[我正在经历这个（链接) 文章。
作者提到，对于具有 k 个不同序列的 VAR 过程，我们不能有 k 个有效的协整关系。我的思路是，对于 k=2：两个有效的协整关系意味着存在 $\beta_1$ 和 $\beta_2$，使得 $y_t-\beta_1x_t$ 和 $x_t-\beta_2y_t$ 都是 $I(0)$。所以，这似乎有点多余。
只是想澄清我的推理是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/660882/johansen-test-conditions</guid>
      <pubDate>Sun, 02 Feb 2025 19:17:46 GMT</pubDate>
    </item>
    <item>
      <title>有序回归（分类预测变量）的样本大小计算</title>
      <link>https://stats.stackexchange.com/questions/660878/sample-size-calculation-for-ordinal-regression-categorical-predictor</link>
      <description><![CDATA[如果您能为我提供一些公式/代码来计算 R 中有序回归的样本量，我将不胜感激。
我有一个 3 级有序结果变量（轻度、中度、重度）和一个分类预测变量（不利、有利）。
目标是找到一个具有 80% 功效和 0.25 F^2 效应大小的样本量。我更愿意通过模拟来计算样本量。
我了解 R 的基础知识，但我不是专业人士，所以我在搜索网站和完全理解代码方面遇到了麻烦。
提前感谢您的建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/660878/sample-size-calculation-for-ordinal-regression-categorical-predictor</guid>
      <pubDate>Sun, 02 Feb 2025 18:23:05 GMT</pubDate>
    </item>
    <item>
      <title>样本量选择策略。序数尺度。远离正态分布</title>
      <link>https://stats.stackexchange.com/questions/660873/sample-size-selection-strategy-ordinal-scale-distribution-far-from-normal</link>
      <description><![CDATA[我之前在Bootstrap 用于样本量估计。序数尺度。远离正态分布上问过类似的问题
有人正确地指出，所提出的策略可能会导致 p-hacking。所以问题是哪种策略更好。
我们经常在约 50 到 100 个句子（这是我们的样本量）的测试翻译上比较人工翻译或机器翻译系统（每次实验中为 2 到 4 个）。
每个句子的每个翻译都由一名称职的翻译人员进行评分，通常为 5 分制，有时为 10 分制（分数通常为整数，但可以包括中点，例如 3.5），这很昂贵。
量表由口头描述定义（“小幅编辑”、“严重改变含义”等），因此它们本质上是序数。分数分布通常是倾斜的，有时是双峰的。
如果有两个翻译，则使用 Wilcoxon 检验来评估结果；如果有两个以上的翻译，则使用 Friedman 检验来评估结果。
第一个想法是，如果我们不能拒绝零假设，就尝试更大的样本。但这是一种 p-hacking，除非我们一开始就决定要抽取两个样本，并相应地降低第一个样本的 alpha。然后我们可以提前终止。
一种正确的方法是估计给定效应大小和 II 类错误概率的样本量。但我们事先不知道方差和分布形状。
零假设的更新。
TLDR 它是两个分布（有时超过两个）之间差异的配对检验。通常双侧也可以是单侧。
我们使用盲测，因此评分员不知道谁是人，谁是机器。他们获得原始语言中每个句子的两个或更多个翻译，并应该在给定的范围内对每个翻译的质量进行评分。
通常，我们希望比较两个机器翻译系统，看看哪一个更适合特定的领域和语言对。或者我们有一个由（另一个）人工翻译编辑的机器（或人工）翻译，并想看看编辑器是否真的让它变得更好。
因此，零通常是“质量没有差异”或“新的翻译/MT 系统并不比现有的更好”。]]></description>
      <guid>https://stats.stackexchange.com/questions/660873/sample-size-selection-strategy-ordinal-scale-distribution-far-from-normal</guid>
      <pubDate>Sun, 02 Feb 2025 13:00:29 GMT</pubDate>
    </item>
    <item>
      <title>caret 包中的 varImp 不适用于 bagEarth [关闭]</title>
      <link>https://stats.stackexchange.com/questions/660870/varimp-from-caret-package-not-working-for-bagearth</link>
      <description><![CDATA[我有一个函数，用于训练许多不同的模型。在函数中，我使用 caret 中的训练：
mod = caret::train(x=X, y=train$Y, trControl=control, preProcess=&quot;zv&quot;, 
tuneLength=4, method=model) 

我想跟踪 x 中的每个变量对拟合模型的重要性。环顾四周，varImp() 似乎是最佳选择。对于我尝试过的大多数模型，它都按预期工作 (varImp(mod) )。但是，当我使用 varImp 和 method = &quot;bagEarth&quot; 时，我收到以下错误：
Error in .(var) : could not find function &quot;.&quot;

查看 caret 文档，似乎表明 varImp 函数适用于 bagEarth。我尝试查找是否有其他人遇到过此问题，但没有找到任何问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/660870/varimp-from-caret-package-not-working-for-bagearth</guid>
      <pubDate>Sun, 02 Feb 2025 11:46:48 GMT</pubDate>
    </item>
    <item>
      <title>限制高斯 S 型函数期望的近似误差</title>
      <link>https://stats.stackexchange.com/questions/660861/bounding-the-approximation-error-of-the-expectation-of-the-sigmoid-of-a-gaussian</link>
      <description><![CDATA[我想限制$\mathbb{E}_x[\sigma(x)],$的近似误差 $\sigma(x):=1/(1+\exp(-x)),$ $x\sim\mathcal{N}(\mu,v)$:
$$\mathbb{E}_x[\sigma(x)]=\sigma(\mu)+\sum_{k=1}^\infty \frac{\sigma^{(k)}(\mu)}{k!}\mathbb{E}[(x-\mu)^k].$$
由于$\mathbb{E}[(x-\mu)^k]=v^k(k-1)!!,$ 这简化为 $$\mathbb{E}_x[\sigma(x)]=\sigma(\mu)+\sum_{k=1}^\infty \frac{v^k\sigma^{(k)}(\mu)}{k!!}.$$
事实上，看起来 $\frac{\sigma^{(k)}(\mu)}{k!!}$ 发散，但这意味着期望发散，而我真的不这么认为。我哪里做错了？
编辑：看来方差在这里至关重要，对于 .05 左右及以下的值，项（至少最多 140 个项，这是我可以计算而不会溢出的极限）不会爆炸。这种期望确实只存在于某些方差中吗？对我来说似乎违反直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/660861/bounding-the-approximation-error-of-the-expectation-of-the-sigmoid-of-a-gaussian</guid>
      <pubDate>Sat, 01 Feb 2025 23:55:33 GMT</pubDate>
    </item>
    <item>
      <title>卡方检验是参数检验还是非参数检验？</title>
      <link>https://stats.stackexchange.com/questions/660848/is-a-chi-squared-test-a-parametric-or-non-parametric-test</link>
      <description><![CDATA[也许这是一个微不足道的问题，但我一直收到一些相互矛盾的信息，这让我有些困惑。
首先，关于参数检验和非参数检验之间的区别似乎存在一些相互矛盾的信息。即，

一些来源表明参数检验对样本所来自的总体分布的参数做出假设
其他来源表明参数检验仅适用于正态分布的数据

我个人认为第一个说法是正确的，而不是后者，但我希望对此有清晰的认识。
如果第一点是正确的，这就引出了我的第二个问题。我看到多个来源都这么说：

卡方检验是一种非参数检验（a、b、c）

但是我想知道为什么卡方检验是非参数的，如果像 Z 检验、t 检验、ANOVA 等参数检验一样，它假设总体分布遵循特定分布，不是吗？我认为卡方检验假设检验统计量来自卡方分布，因此由于它做出了分布假设，所以它是参数化的。但我肯定是误解了什么。有人能帮忙澄清一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660848/is-a-chi-squared-test-a-parametric-or-non-parametric-test</guid>
      <pubDate>Sat, 01 Feb 2025 16:00:09 GMT</pubDate>
    </item>
    <item>
      <title>样本均值与自举均值相同，但 T 检验拒绝原假设</title>
      <link>https://stats.stackexchange.com/questions/660844/sample-mean-is-same-as-bootstrapped-mean-but-t-test-rejects-null-hypothesis</link>
      <description><![CDATA[我有 2 个样本（每个样本有大约 8500 个数据点）。我进行了引导（有替换）并绘制了平均差异的分布：

然后，我计算了 2 个样本的实际平均差异，结果是-5.53
我的理解表明，这意味着我的样本之间没有显着差异。但是，当我进行 T 检验时，我得到p_value=0.048
有人可以解释这是怎么可能的吗？据我理解，这本质上就是 T 检验所做的工作 - 创建均值差异分布并检查样本之间的实际均值差异在该分布范围内的可能性。
每个样本的原始分布都非常右偏，但我认为 8500 的样本量可以弥补这一点。此外，我进行了 Levene 检验，发现两个样本之间的方差没有差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/660844/sample-mean-is-same-as-bootstrapped-mean-but-t-test-rejects-null-hypothesis</guid>
      <pubDate>Sat, 01 Feb 2025 11:34:50 GMT</pubDate>
    </item>
    <item>
      <title>当比例风险假设不成立时，如何用重复测量来模拟事件发生时间</title>
      <link>https://stats.stackexchange.com/questions/660801/how-to-model-time-to-event-with-repeated-measures-when-proportional-hazards-assu</link>
      <description><![CDATA[我的数据：
我每天对两个连续变量进行测量，直到他们移民或死亡。
我的目标：
我想使用我的两个每日指标来预测移民时间。
我的模型：
我已经对预测因子进行了 Box Cox 转换和缩放。我已对状态 = 1 的死亡个体和状态 = 2 的移民个体进行了编码。days 是从研究开始到死亡或移民之间的天数。
例如：



ID
metric1
metric2
days
status




A
0.428
-1.42
267
2


A
0.204
-1.97
267
2


A
0.168
-2.65
267
2



我已经开始使用简单的 CoxPH 模型：
coxph(Surv(days, status) ~ metric1 = metric2, data=df)

测试比例风险假设会返回一个显著的全局 p 值。我只能假设这与我的度量随着时间的推移逐渐增加到渐近线有关，而随着年龄的增长，移民的可能性会更大，但死亡的可能性会更小。
我的下一步努力：
我发现了许多处理随时间变化数据的建议方法。这些包括使用tt()拟合时间变换，在coxme中添加随机效应，将预测因子与时间相互作用，使用联合建模，以及添加层或集群。
我的问题：
因为似乎有有如此多的选择被平等地提倡，我正在寻求建议，看是否存在“最佳”选择，如果有的话，对我来说哪个是最佳选择。]]></description>
      <guid>https://stats.stackexchange.com/questions/660801/how-to-model-time-to-event-with-repeated-measures-when-proportional-hazards-assu</guid>
      <pubDate>Fri, 31 Jan 2025 11:37:17 GMT</pubDate>
    </item>
    <item>
      <title>决定是否在模型中包含约束</title>
      <link>https://stats.stackexchange.com/questions/660786/deciding-whether-or-not-to-include-constraints-into-a-model</link>
      <description><![CDATA[我有一个离散随机过程，我认为当前状态$ X_n $取决于三个最近的状态$ X_{n-1}, X_{n-2}, X_{n-3} $，但具有加权结构，使得较新的状态比较旧的状态对结果的影响更大（即$w_1 &gt; w_2 &gt; w_3$）。
使用逻辑回归对此进行建模是有意义的：
$$
P(X_n = 1 \mid X_{n-1}, X_{n-2}, X_{n-3}) = \sigma\left( b_0 + w_1 X_{n-1} + w_2 X_{n-2} + w_3 X_{n-3} \right),
$$
其中：

$ \sigma(z) = \frac{1}{1 + e^{-z}} $ 是逻辑 (S 形) 函数，
$ b_0 $ 是截距，
$ w_1, w_2, w_3 $ 是权重分配给过去的状态，这决定了它们对$ X_n $的影响，


方法 1：无约束
如果不考虑约束，可以使用 MLE。给定一个包含 $ N $ 个观测值的数据集，似然函数和解为：
$$
L(b_0, w_1, w_2, w_3) = \prod_{n=1}^{N} P(X_n \mid X_{n-1}, X_{n-2}, X_{n-3})^{X_n} (1 - P(X_n \mid X_{n-1}, X_{n-2}, X_{n-3}))^{1 - X_n}。
$$
$$
\ell(b_0, w_1, w_2, w_3) = \sum_{n=1}^{N} \left[ X_n \log \sigma(z_n) + (1 - X_n) \log (1 - \sigma(z_n)) \right],
$$
$$
z_n = b_0 + w_1 X_{n-1} + w_2 X_{n-2} + w_3 X_{n-3}。
$$
$$
(b_0^, w_1^, w_2^, w_3^) = \arg\max_{b_0, w_1, w_2, w_3} \ell(b_0, w_1, w_2, w_3)。
$$

方法 2：带约束
考虑以下约束：$w_1 &gt; w_2 &gt; w_3$
现在，我们不再直接估计 $ w_1, w_2, w_3 $，而是引入新参数 $ \beta_1, \beta_2, \beta_3 $，使得：
$$
\beta_1 &gt; \beta_2 &gt; \beta_3.
$$
$$
\beta_1 = \alpha_1, \quad \beta_2 = \alpha_1 - e^{\alpha_2}, \quad \beta_3 = \alpha_1 - e^{\alpha_2} - e^{\alpha_3}.
$$
这保证：
$$
\beta_1 &gt; \beta_2 &gt; \beta_3。
$$
$$
w_i = e^{\beta_i}, \quad i=1,2,3。
$$
从这里开始，定义一个类似的似然函数：
$$
\ell(b_0, \alpha_1, \alpha_2, \alpha_3) = \sum_{n=1}^{N} \left[ X_n \log \sigma(z_n) + (1 - X_n) \log (1 - \sigma(z_n)) \right],
$$
$$
z_n = b_0 + w_1 X_{n-1} + w_2 X_{n-2} + w_3 X_{n-3}。
$$
$$
(b_0^, \alpha_1^, \alpha_2^, \alpha_3^) = \arg\max_{b_0, \alpha_1, \alpha_2, \alpha_3} \ell(b_0, \alpha_1, \alpha_2, \alpha_3)。
$$

我的问题与以下内容有关：假设我首先对数据使用方法 1（无约束），并发现 $ w1 \ngtr w2 \ngtr w3 $。这是否意味着（不幸的是）数据不支持我关于 $w_1 &gt; w_2 &gt; w_3$ 的假设，我应该停止研究这个模型？或者我应该使用方法 2（带约束）并强制假设 $w_1 &gt; w_2 &gt; w_3$？
这个问题的统计建模标准做法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660786/deciding-whether-or-not-to-include-constraints-into-a-model</guid>
      <pubDate>Fri, 31 Jan 2025 01:30:00 GMT</pubDate>
    </item>
    <item>
      <title>比较覆盖概率和间隔长度：BCa 与百分位数引导方法</title>
      <link>https://stats.stackexchange.com/questions/660390/comparing-coverage-probabilities-and-interval-lengths-bca-vs-percentile-bootst</link>
      <description><![CDATA[我进行了参数引导研究，以评估四个参数的覆盖概率，样本量分别为 35、50 和 100。3 个参数来自具有指数分布的混合模型，并通过 EM 算法进行估计：$\theta_{j}^{(k+1)} =\frac{\sum_{i=1}^{n} h_{ij}^{(k)}t_{i:n}}{\sum_{i=1}^{n} h_{ij}^{(k)}}$，其中 $h_{ij}^{(k)}$ 是后验概率。因此，无法确定估计的偏差。
在研究中，首先，我使用真实参数模拟 B 时间原始样本。对于每个样本，我估计参数以获得 MLE。基于MLE和每个样本，我做了参数引导，即我使用MLE作为“真实”参数，根据我的模型（部分混合模型）生成B时间引导样本，并且对于每个引导样本，我再次计算引导MLE。因此，我可以得到B时间百分位数CI和BCa CI（BCa使用B时间原始样本，加速参数就是经典的刀切估计量，见下面的评论）。覆盖概率是通过确定B时间CI是否包含真实参数来计算的。
该问题涉及混合模型中的两个指数尺度参数。结果表明，百分位数方法的覆盖概率趋于更保守，而BCa方法通常可以实现更接近名义水平的覆盖概率（$1-\alpha$）。但是，百分位数法的平均间隔长度通常较短。例如，对于 90% CI，百分位数法的 $\theta_{2}$ 覆盖概率为 95.2%，而 BCa 法的覆盖概率为 88.3%。但是，百分位数的平均间隔长度为 9.09，而 BCa 的平均间隔长度为 10.52。
我怀疑这种差异是由于研究中使用的样本量较小造成的。我查阅的一篇参考文献提到，BCa CI 会根据偏差和偏斜度进行调整，除了小样本外，通常是准确的。我也知道最短的 CI 并不总是最好的。从覆盖概率的角度来看，在这种情况下，BCa 似乎优于百分位数法。但与直觉相反，较短的 CI 也提供了更高的覆盖概率。我该如何证明我认为 BCa 更好？
我查阅了经典书籍，例如 Efron, B., &amp; Tibshirani, R. J. (1994) An Introduction to the Bootstrap、Davison, A. C., &amp; Hinkley, D. V. (1997) Bootstrap Methods and Their Application，并搜索了一些论文以找到类似的现象或讨论。但是，我还没有找到解决这一特定观察的明确理由，尤其是较短的 CI 提供更高的覆盖概率。
是否有人有见解或参考资料可以提供对这种行为的更深入了解？在此先感谢您的想法和指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/660390/comparing-coverage-probabilities-and-interval-lengths-bca-vs-percentile-bootst</guid>
      <pubDate>Wed, 22 Jan 2025 18:45:21 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯分布学习任务失败</title>
      <link>https://stats.stackexchange.com/questions/660238/bayesian-distribution-learning-task-failing</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660238/bayesian-distribution-learning-task-failing</guid>
      <pubDate>Sun, 19 Jan 2025 16:47:19 GMT</pubDate>
    </item>
    <item>
      <title>如何使用引导程序处理大规模文本匹配和不确定性？</title>
      <link>https://stats.stackexchange.com/questions/659912/how-to-handle-large-scale-text-matching-and-uncertainty-with-bootstrap</link>
      <description><![CDATA[我有一个大型数据库，其中有一个字符列，其中包含数百万个产品描述。我有一个参考表，其中有一个字符列，其中包含我试图匹配的描述。我将使用 EXACT 匹配、IN 匹配和最终的 Levenshtein 距离进行匹配。然后我想计算匹配次数。有时会出现错误匹配，例如参考词包含在一个不匹配的大词中，这更像是参考数据的异常。所以我还想在组合中添加不确定性。我不会在完成后检查所有匹配，因为匹配实在太多了。
我对此有两个疑问：

我知道如何进行匹配。这不是问题。我想计算匹配次数，并说我们怀疑 3 月份有 200 次匹配。我们不知道误报率，但它很小（我们怀疑）。参考列表由另一个部门保存。假阳性可能由包含单词的产品引起，例如 shoe 可能包含在 Shoehorn 中。引导捆绑是一种我可以使用的方法吗？逐月从数据库中提取数据，然后应用匹配。这将为我提供该月的总匹配数，然后从每月样本中进行引导（10k 个案例 5000 次，并将这些案例相加并计算置信区间。

假设 A 是正确的。在理想情况下，我会这样做，其中一行包含一个产品实例。但是数据库很大。是否可以先在数据库中聚合 Shoehorn - 100 个匹配项。然后进行引导。这不会给我一个完全不同的答案吗，因为抽样不再在 100 个匹配项中随机抽样，它会将 Shoehorn - 100 个匹配项作为单个记录进行抽样。


所以我的问题是第一点是否是解决这个问题的有用方法，第二点是关于如何聚合数据对置信区间的有效性的影响。
下面是一些 R 代码，它生成数据的两种方法出现
# 加载必要的库
library(dplyr)

# 生成逐行数据 ----------------------------------------------------------
# 生成具有随机卷的虚假产品描述数据
set.seed(123)
descriptions &lt;- c(
&#39;红色鞋子&#39;, &#39;蓝色衬衫&#39;, &#39;绿色鞋带&#39;, &#39;黄色鞋拔&#39;, 
&#39;黑色帽子&#39;, &#39;白色鞋子&#39;, &#39;粉色衬衫&#39;, &#39;灰色帽子&#39;, 
&#39;紫色鞋拔&#39;, &#39;橙色鞋带&#39;
)
volumes &lt;- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)

product_descriptions &lt;- data.frame(
ProductID = unlist(lapply(1:10, function(i) rep(i, volumes[i]))),
Description = unlist(lapply(1:10, function(i) rep(descriptions[i], 
volumes[i]))),
Volume = unlist(lapply(1:10, function(i) rep(volumes[i], 
volumes[i])))
)

# 随机抽取 5000 行并替换以生成 
# 逐行乘积
set.seed(456) # 设置种子以实现可重复性
line_by_line_df &lt;- product_descriptions %&gt;%
sample_n(5000, replace = TRUE) |&gt; 
mutate(ProductID = row_number()) %&gt;% 
mutate(match = sample(0:1, n(), replace = TRUE))

# 生成聚合数据 -------------------------------------------------
# 在这里我们从“数据库”中提取数据并聚合计数 
# 在数据库中
aggregated_df &lt;- line_by_line_df |&gt; 
group_by(Description) |&gt; 
summarise(total_products = sum(Volume),
matches = sum(match))

]]></description>
      <guid>https://stats.stackexchange.com/questions/659912/how-to-handle-large-scale-text-matching-and-uncertainty-with-bootstrap</guid>
      <pubDate>Sun, 12 Jan 2025 12:03:38 GMT</pubDate>
    </item>
    <item>
      <title>BIBD 块内分析问题</title>
      <link>https://stats.stackexchange.com/questions/659837/bibd-intrablock-analysis-issue</link>
      <description><![CDATA[我很难理解 Peter W. M. John 所著《实验的统计设计和分析》中平衡不完全块设计部分提出的这个问题。问题如附图所示。
示例问题第 1 部分：

示例问题第 2 部分：

为了便于复制我的问题，下面是值表，其中每行是一个块，每 4 行连续组成一个组：



处理
值
处理
值




A
38
B
29


C
49
D
&lt; td&gt;28


E
32
F
29


G
64
H
32


A
37
C
27


B
37
H
50


D
90
E
89


F
28
G
71


A
15
D
23


B
 47
G
64


C
35
F
39


E
22
H
18


A
3
E
13


B&lt; /td&gt;
45
C
36


D
11
G
24


F
39
H
37


A
23
F
39

&lt; tr&gt;
B
21
D
14


C
18
H
10


E
23
G
53


A
66
G
68


B
23
F
46


C
22
E
28


D
23
H
39


A
28
H
30


B
10
E
40


C
32
G
33


D
18
F
23



我在计算块的 SS（块内）时遇到了特别困难。根据前面的块内分析部分，方程应该是：
$$
\begin{equation}
k^{-1}\sum_{j}B_j^2-G^2/N
\end{equation}
$$
其中 k 是块的图，B 是每个块的治疗观察值的总和，G 是治疗观察值的全局总和，N 是观察值总数。我只能得到 ~15,405。
我很难看出我哪里做错了。治疗 SS 的块内方程运行良好，块间分析中调整后的块 SS 也运行良好。我还通过计算值获得了正确的块内错误！我感觉好像漏掉了某个公式，但仔细阅读了整章后，还是不知道在哪里。任何帮助我都感激不尽。]]></description>
      <guid>https://stats.stackexchange.com/questions/659837/bibd-intrablock-analysis-issue</guid>
      <pubDate>Fri, 10 Jan 2025 18:28:21 GMT</pubDate>
    </item>
    <item>
      <title>异方差和序列相关性检验</title>
      <link>https://stats.stackexchange.com/questions/633578/heteroscedasticity-and-serial-correlation-test</link>
      <description><![CDATA[让我们考虑使用 OLS 估计的线性回归模型。
根据 Hayashi（计量经济学，第 2 章）的信息

必须在误差不存在序列相关性的情况下才能执行 White 条件异方差检验；
必须在存在条件同方差的情况下才能执行 Ljung-Box Q 检验和 Breusch-Godfrey 检验以确定不存在序列相关性。

合理的问题是：如果一个检验中的 H0 是另一个检验中的假设，那么应该如何执行此类检验？
也许存在其他一些检验，例如，用于测试不依赖于条件同方差假设的序列相关性，或用于测试不依赖于无序列相关性假设的条件异方差？]]></description>
      <guid>https://stats.stackexchange.com/questions/633578/heteroscedasticity-and-serial-correlation-test</guid>
      <pubDate>Mon, 11 Dec 2023 06:06:30 GMT</pubDate>
    </item>
    </channel>
</rss>