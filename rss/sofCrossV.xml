<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 02 Aug 2024 15:16:49 GMT</lastBuildDate>
    <item>
      <title>核均值嵌入的收敛</title>
      <link>https://stats.stackexchange.com/questions/652212/convergence-of-kernel-mean-embeddings</link>
      <description><![CDATA[设 $k(\cdot,\cdot)$ 为丰富核，$\mathcal{H}$ 为其相关 RKHS。定义核均值嵌入 $\mu=\int k(\cdot,x)dP_X(x)$，设 $\frac{1}{n}\sum k(x_i,\cdot)$ 为其样本模拟。两者之间的误差 $||\mu-\hat{\mu}||_{\mathcal{H}}=O(\frac{1}{\sqrt{n}})$。各种结果通过使用希尔伯特空间的伯恩斯坦型不等式来证明这一点。
对我来说，从中心极限定理的角度来看，这感觉很直观。有希尔伯特空间 CLT 吗？是否有可能从 CLT 的应用中显示这种速率？]]></description>
      <guid>https://stats.stackexchange.com/questions/652212/convergence-of-kernel-mean-embeddings</guid>
      <pubDate>Fri, 02 Aug 2024 14:32:18 GMT</pubDate>
    </item>
    <item>
      <title>软问题：统计学硕士（计算统计学专业）与计算机科学硕士（数据科学专业）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652211/soft-question-ms-in-statistics-computational-statistics-specialisation-vs-ms</link>
      <description><![CDATA[问题：我打算在美国/欧洲的一所顶尖大学攻读机器学习/深度学习博士学位。我应该选择印度统计研究所的统计硕士还是计算机科学硕士来加强我的博士申请和研究基础？
背景：我拥有纯数学学士-硕士学位，希望在申请博士学位之前打下坚实的基础。我对计算统计和数据科学同样感兴趣。印度统计研究所的统计课程备受推崇，但计算机科学课程则不那么受推崇。我寻求建议，看看哪个硕士学位对博士委员会更有吸引力，并能更好地为机器学习/深度学习方面的有影响力的研究做好准备。
感谢您的见解。
PS：如果这个问题不适合在这里提出，请告诉我合适的平台，我会在那里发布它。感谢您的耐心。对造成的麻烦深表歉意。]]></description>
      <guid>https://stats.stackexchange.com/questions/652211/soft-question-ms-in-statistics-computational-statistics-specialisation-vs-ms</guid>
      <pubDate>Fri, 02 Aug 2024 12:38:05 GMT</pubDate>
    </item>
    <item>
      <title>计算不同统计检验的效应大小、统计功效和置信区间[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652209/calculation-of-effect-size-statistical-power-and-confidence-interval-for-diffe</link>
      <description><![CDATA[我对非正态分布使用以下双样本检验：

卡方检验
Kolmogorov-Smirnov 检验
Wilcoxon 秩和检验
Kruskal-Wallis 检验

它们都返回一个 p 值，即卡方检验的 p 值、Kolmogorov-Smirnov 检验的 p 值、Wilcoxon 秩和检验的 p 值和 Kruskal-Wallis 检验的 p 值。
由于 p 值不足以理解数据/分布（例如，请参阅Sullivan &amp; Feinn (2012)、Dunkler 等人 (2020)、Greenland (2016) 和 du Prel 等人 (2009)），我想计算

效果大小，
检验的统计功效，以及
置信区间（假设检验）。

但是，有些事情不清楚。
您能否告诉我，所有附加（p 值）指标，即 (i) 效果大小、(ii) 检验的统计功效和 (iii) 置信区间（假设检验），是否需要针对每项统计检验（即卡方检验、Kolmogorov-Smirnov 检验、Wilcoxon 秩和检验和 Kruskal-Wallis 检验）进行计算，或者它们不依赖于统计检验，并且只需计算一次？
此外，如果所有附加（p 值）度量，即 (i) 效应大小、(ii) 检验的统计功效和 (iii) 置信区间（假设检验），都需要针对每项统计检验进行计算，我是否应该针对每种类型的统计检验调整与效应大小、统计功效和置信区间相关的方程？]]></description>
      <guid>https://stats.stackexchange.com/questions/652209/calculation-of-effect-size-statistical-power-and-confidence-interval-for-diffe</guid>
      <pubDate>Fri, 02 Aug 2024 11:41:26 GMT</pubDate>
    </item>
    <item>
      <title>E-test 值的多重校正</title>
      <link>https://stats.stackexchange.com/questions/652208/multiple-correction-for-e-test-values</link>
      <description><![CDATA[我目前正在执行多个“E-tests”（poisson.mean），并且想知道使用 E-tests 进行多次校正的最合适方法，以及如何在 R 中进行此操作。
我正在计算 7 个不同实验组（2 个对照组，5 个感兴趣的实验组）中某个事件发生的次数（在给定的时间间隔内）。
我选择通过列出 7 个条件组和值来比较各组之间的泊松分布均值，然后以迭代方式执行泊松检验。然后从结果中获取 P 值，例如。

Cond1 &lt;- c(0,0,0,1,1,2,3,3,3) Cond2 &lt;- c(0,1,1,1,1,1,2,3,3)Cond3 &lt;- c(0,1,2,3,3,3,3,3,4)... Cond7 &lt;- c(3,3,3,3,4,4,4,5,6) result1 &lt;- poisson.test(x c(sum(Cond1), sum(Cond2)), T = c(length(Cond1), length (Cond2)), alternative = &quot;two.sided&quot;)
result2 &lt;- poisson.test(x c(sum(Cond1), sum(Cond3)), T = c(length(Cond1), length (Cond3)), alternative = &quot;two.sided&quot;) ... 
result20 &lt;- poisson.test(x c(sum(Cond6), sum(Cond7)), T = c(length(Cond6), length (Cond7)), alternative = &quot;two.sided&quot;)  P1 &lt;- result1§p.value P2 &lt;- result2§p.value ...P20&lt;- result20§p.value 

从这一点开始，我需要对多个测试进行校正，并希望使用 Benjamini-Hochberg 类型的排序 p 值显着性校正，但我想知道
A)哪种测试最适合这种分析
B) 如何在 R 中进行此操作
提前感谢您的帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/652208/multiple-correction-for-e-test-values</guid>
      <pubDate>Fri, 02 Aug 2024 11:36:56 GMT</pubDate>
    </item>
    <item>
      <title>复高斯分布和瑞利分布之间存在可互换性吗？</title>
      <link>https://stats.stackexchange.com/questions/652207/does-an-interchangeability-exist-between-complex-gaussian-distribution-and-rayle</link>
      <description><![CDATA[假设，一个复杂的高斯分布由以下公式给出：
$$N\sim\mathcal{CN}(0,1)$$
它也可以写成：
$$N=X+jY$$其中$X\sim\mathcal{N}(0,1/2)$和$Y\sim\mathcal{N}(0,1/2)$，$X$和$Y$都是正态分布的，并且彼此独立。
现在，我们知道对于独立的高斯分布随机变量$X$和$ class=&quot;math-container&quot;&gt;$Y$，$|r|=\sqrt{X^2+Y^2}$ 服从瑞利分布，而 $\theta=\tan^{-1}\frac{y}{x}$ 服从均匀分布。
问题：

复高斯和瑞利分布是否服从？均匀分布分别是同一量的笛卡尔形式和极坐标形式，即$N=X+jY=|r|\exp{(j\theta)}$?

我们能用$f_{R,\theta}(r,\theta)$的联合分布代替复杂的高斯分布吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/652207/does-an-interchangeability-exist-between-complex-gaussian-distribution-and-rayle</guid>
      <pubDate>Fri, 02 Aug 2024 11:11:32 GMT</pubDate>
    </item>
    <item>
      <title>适应数字跟踪数据的序列分析（应用程序跟踪）</title>
      <link>https://stats.stackexchange.com/questions/652206/adaptation-of-sequence-analysis-for-digital-trace-data-app-tracking</link>
      <description><![CDATA[我是一名通信科学家，对 TraMineR 和序列分析完全是新手。我有一个（相对较大）的数据集，其中包括研究参与者的应用程序使用情况。我的目标是识别连续使用的应用程序类别序列。
原始数据集如下所示：



参与者 ID
会话 ID
使用的应用程序类别
开始时间（实际上是 unix 时间）
结束时间（实际上是 unix 时间）




0001
0001_1
通信
2021-03-02 10:05:02
2021-03-02 10:05:09


0001
0001_1
社交媒体
2021-03-02 10:05:09
2021-03-02 10:07:09


0002
0002_1
游戏
2021-03-02 14:36:07
2021-03-02 14:36:07


...
...
...
...
...



因此，我有两个分析层次：(1) 一方面是参与者，另一方面是 (2) 会话。
第一步，我的目标是确定连续使用的应用程序类别序列。会话是打开和关闭智能手机屏幕之间的连贯使用序列。该数据集包含近 400 名参与者，每个参与者有大约 2000-5000 个会话（整个数据集约 140 万个会话）。
我已经首次尝试使用子样本，并遇到了两个问题：

我已将拼写格式的数据放入 seqdef 函数中。这是最佳时间格式的问题。这里有经验吗？我目前使用的是 unix-time，但我觉得单位太细了。

labels = seqstatl(sample$app_category)
states = 1:length(labels)

session_seq = seqdef(data = sample, 
var = c(&quot;session&quot;, &quot;begin&quot;, &quot;end&quot;, &quot;app_category&quot;), 
informat = &quot;SPELL&quot;,
states = states,
labels = labels,
process = FALSE)

print(session_seq[1:15, ], format = &quot;SPS&quot;)


第二个问题与所需的计算资源有关。即使是子样本，我也需要相对大量的计算能力。是否可以使计算更节省资源？是否可以选择拆分数据集，然后合并序列距离（批处理），或者这会扭曲我的结果？

我也很高兴收到有关阅读和阅读目标的更多提示。 TraMineR 用户指南已经帮了我很多忙。]]></description>
      <guid>https://stats.stackexchange.com/questions/652206/adaptation-of-sequence-analysis-for-digital-trace-data-app-tracking</guid>
      <pubDate>Fri, 02 Aug 2024 10:45:01 GMT</pubDate>
    </item>
    <item>
      <title>将分数改变为预测变量</title>
      <link>https://stats.stackexchange.com/questions/652205/change-score-as-predictor</link>
      <description><![CDATA[我想看看独立变量（T2-T1）的变化是否能预测 T2 时的另一个变量。例如，痴呆症患者在 1 年内认知障碍的增加越多，生活质量就越低。
我的问题是：我需要控制基线生活质量（因变量）吗？
我已经读到我应该控制 IV，但不确定 DV。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/652205/change-score-as-predictor</guid>
      <pubDate>Fri, 02 Aug 2024 10:42:34 GMT</pubDate>
    </item>
    <item>
      <title>RM Anova 或 2 配对 t 检验？并使用 RCI 验证个体差异</title>
      <link>https://stats.stackexchange.com/questions/652203/rm-anova-or-2-paired-t-tests-and-verifying-for-individual-differences-with-rci</link>
      <description><![CDATA[对于一个使用记录对刺激的反应时间的测试来评估麻醉后认知能力变化的研究项目，我们在麻醉后基线、1 小时和 4 小时对受试者进行了测试，总共进行了三次。该研究旨在判断麻醉后开车是否危险。
RM Anovas 或配对 t 检验是否更适合比较这 3 个时刻？另一项类似于小时的研究使用了 RM Anovas，但我担心会失去统计能力。RM Anova 的优点是它更具表现力，我可以在我的分析中添加受试者间因素（例如他们的代谢对麻醉剂的吸收）。
第二个问题，当我们处理安全问题时，报告是否有一个人受到镇静的负面影响非常重要。为此，我决定暂时采用可靠变化指数，但我不确定这是否是最好的选择，因为我手头没有重测信度。我使用了这个公式：calculate_RCI &lt;- function(M1, SD1, M2, SD2) {return((M1 - M2) / sqrt(SD1^2 + SD2^2))
是使用整个组的 SD 更好，还是使用不同时间点的个人的 SD 更好？]]></description>
      <guid>https://stats.stackexchange.com/questions/652203/rm-anova-or-2-paired-t-tests-and-verifying-for-individual-differences-with-rci</guid>
      <pubDate>Fri, 02 Aug 2024 08:59:59 GMT</pubDate>
    </item>
    <item>
      <title>对单个组的样本大小进行论证以获得所需准确度的平均值估计值</title>
      <link>https://stats.stackexchange.com/questions/652201/sample-size-justification-for-single-group-to-get-estimate-of-mean-to-desired-ac</link>
      <description><![CDATA[
我有一个计算机组件样品
这些计算机组件是分批生产的（1 批 = 1 批次），每批 200 个
组件可以单独进行电子测试
然后对该测试结果进行平均，以得出批次级值，以判断整个批次是否通过
我需要知道需要从一批中抽样多少个组件，以便对整个批次进行
准确的测试测量。
有人知道我应该如何证明这一点吗？
例如，测试 10 个组件是否能让我足够准确地估计出整个批次的平均测试结果？

我知道这里有一些未知数，比如“足够准确” - 也许是某种置信区间？
任何帮助都太棒了！
林肯]]></description>
      <guid>https://stats.stackexchange.com/questions/652201/sample-size-justification-for-single-group-to-get-estimate-of-mean-to-desired-ac</guid>
      <pubDate>Fri, 02 Aug 2024 08:15:30 GMT</pubDate>
    </item>
    <item>
      <title>如何手动计算零膨胀泊松回归的伪 R2（McFadden）</title>
      <link>https://stats.stackexchange.com/questions/652200/how-to-calculate-pseudo-r2-mcfadden-for-zero-inflated-poisson-regression-by-ha</link>
      <description><![CDATA[我正在寻找在 R 中手动计算伪 R2 McFadden 的方法。但是，当我使用下面的代码时
zeropr &lt;- zeroinfl(g ~ a + f | a + f, data = xuly240731_1000) summary(zeropr)
结果如下：
调用：
zeroinfl(formula = g ~ a + f | a + f, data = xuly240731_1000)
皮尔逊残差：
最小 1Q 中位数 3Q 最大
-2.4010 -1.0299 -0.4369 0.6539 6.2740
计算模型系数（带对数链接的泊松）：
估计标准差。误差 z 值 Pr(&gt;|z|)
（截距）0.709857 0.115392 6.152 7.67e-10 ***
a 0.038266 0.002577 14.846 &lt; 2e-16 ***
f 0.927251 0.282940 3.277 0.00105 **
零通胀模型系数（带 logit 链接的二项式）：
估计标准差。误差 z 值 Pr(&gt;|z|)
(截距) 0.22235 1.03148 0.216 0.8293
a -0.14307 0.06518 -2.195 0.0282 *
f -1.81661 2.19863 -0.826 0.4087
有效代码：0 &#39;&#39; 0.001 &#39;&#39; 0.01 &#39;&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
但是，当我尝试计算 Pseudo-R2 McFadden 时
library(performance)

library(DescTools)
PseudoR2(zeropr,c(&quot;McFadden&quot;))
结果是 &gt; PseudoR2(zeropr,c(&quot;McFadden&quot;))
[1] NA
您能告诉我如何处理这个问题并计算 Pseudo-R2 (McFadden) 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652200/how-to-calculate-pseudo-r2-mcfadden-for-zero-inflated-poisson-regression-by-ha</guid>
      <pubDate>Fri, 02 Aug 2024 07:56:36 GMT</pubDate>
    </item>
    <item>
      <title>频率嵌入的聚类方法</title>
      <link>https://stats.stackexchange.com/questions/652196/clustering-method-for-frequency-embeddings</link>
      <description><![CDATA[例如，我有以下要聚类的单词列表。列表的长度可能不同，词汇表为 $W = \{a,b,c\}$。将两个列表聚类到同一个簇中的标准是“它们重叠得越多，它们就越相似”。



索引
列表
嵌入




1
$[a,a,b,c]$
$[2,1,1]$


2
$[b,b,c]$
$[0,2,1]$


3
$[a,b,c,c,c]$
$[1,1,3]$


4
$[a,a,a]$
$[3,0,0]$



我发现使用欧几里得距离的经典聚类方法（例如 Kmeans）存在一些问题，即 $[a], [b],$ 和 $[c]$（具有嵌入 $[1,0,0], [0,1,0],$ 和 $[0,0,1]$）可以聚类到同一个聚类中，即使列表中存在不重叠的事件。此外，当嵌入是整数并且可能包含大量 0 时，Kmeans 不是一种好的聚类方法。
对于这个聚类问题，我应该使用哪种距离和哪种聚类方法？或者我应该在这里使用一些不同的嵌入？]]></description>
      <guid>https://stats.stackexchange.com/questions/652196/clustering-method-for-frequency-embeddings</guid>
      <pubDate>Fri, 02 Aug 2024 06:31:45 GMT</pubDate>
    </item>
    <item>
      <title>弗里德曼、皮萨尼和普维斯书中的辛普森悖论</title>
      <link>https://stats.stackexchange.com/questions/652195/simpsons-paradox-in-freedman-pisani-and-purves-book</link>
      <description><![CDATA[本书中有一个研究生录取性别歧视的例子。



专业
男性

女性






申请人数
录取率
申请人数
%录取


A
825
62
108
82


B
560
63
25
68


C
325
37
593
34


D
417
33
375
35


E
191
28
393
24


F
373
6
341
7


总计
2691
45
1835
30



总申请人数只是上述条目的总和。录取的总百分比，男性为 45%，是
62 * 825 / 2691 + ... + 6 * 373 / 2691

女性也是如此。
然后作者提出统计员会执行以下操作的论点：



专业
申请人总数




A
933 = 825 + 108


B
585


C
918


D
792


E
584


F
714 = 373 + 341


总计
4526



然后他们指出男性的加权平均录取率为：
62 * 933 / 4526 + ... + 6 * 714/4526 = 39（近似值）

对于女性来说也是如此：
82 * 933 / 4526 + ... + 7 * 714/4526 = 43（近似值）

我很难解释最后一对计算“男女加权平均录取率”。
他们说：

加权平均值控制了混杂因素——专业选择。这些平均值表明，如果有的话，录取过程对男性有偏见。

在这种情况下，39% 和 43% 的加权平均值究竟意味着什么？如何正确解释这些数字？原始百分比 45% 和 30% 似乎对我来说更容易理解和解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/652195/simpsons-paradox-in-freedman-pisani-and-purves-book</guid>
      <pubDate>Fri, 02 Aug 2024 05:33:00 GMT</pubDate>
    </item>
    <item>
      <title>该图显示的是异方差性还是同方差性？</title>
      <link>https://stats.stackexchange.com/questions/652188/does-this-graph-show-heteroscedasticity-or-homoscedasticity</link>
      <description><![CDATA[因此，我正在使用大约 13 年期间某些股票的股票数据，现在我想在 stata 上检查异方差和自相关性。残差与拟合值如下所示。


该图是否暗示异方差？

如果该图不够充分，我可以使用什么测试？潜在的自相关性可能会影响 Beusch-pagan 或怀特检验的结果，以确定异方差

]]></description>
      <guid>https://stats.stackexchange.com/questions/652188/does-this-graph-show-heteroscedasticity-or-homoscedasticity</guid>
      <pubDate>Fri, 02 Aug 2024 01:11:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么 glmnet 不像 lm 那样处理丢失数据？</title>
      <link>https://stats.stackexchange.com/questions/652183/why-doesnt-glmnet-handle-missing-data-the-way-lm-does</link>
      <description><![CDATA[在 R 中进行计算时，我有一些玩具数据，并尝试使用 glmnet 来拟合弹性网络模型。我注意到，即使只有一个缺失值，算法也不会执行，建议事先估算缺失值。
# 设置可重复性的种子
set.seed(123)

# 生成一个 100x5 的随机数矩阵
data_matrix &lt;- matrix(rnorm(100*5), nrow=100, ncol=5)
data_df &lt;- as.data.frame(data_matrix)
data_df[1:1, 3] &lt;- NA # 单个缺失值
# 生成一个包含 100 个观测值的向量 Y，每个观测值为 1、2 或 3
Y &lt;- sample(1:3, 100, replace=TRUE)
glmnet::cv.glmnet(x = as.matrix(data_df),
y = as.matrix(Y),
alpha = 0.5,
family = &quot;multinomial&quot;)
glmnet(x, y, weights = weights, offset = offset, lambda = lambda, 中的错误：
x 有缺失值；考虑使用 makeX() 来估算它们

从算法上讲，当有缺失值时，是什么原因导致弹性网络不适合？相反，当使用 lm 并且有缺失值时，
ctl &lt;- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,NA)
trt &lt;- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group &lt;- gl(2, 10, 20, labels = c(&quot;Ctl&quot;,&quot;Trt&quot;))
weight &lt;- c(ctl, trt)
lm.D9 &lt;- lm(weight ~ group)

代码运行无任何错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/652183/why-doesnt-glmnet-handle-missing-data-the-way-lm-does</guid>
      <pubDate>Thu, 01 Aug 2024 21:42:45 GMT</pubDate>
    </item>
    <item>
      <title>如何在 GLM 中推导出指数分布的典型链接函数</title>
      <link>https://stats.stackexchange.com/questions/652165/how-to-derive-canonical-link-function-of-exponential-distribution-in-glm</link>
      <description><![CDATA[我想知道推导过程，以及基本如何计算它]]></description>
      <guid>https://stats.stackexchange.com/questions/652165/how-to-derive-canonical-link-function-of-exponential-distribution-in-glm</guid>
      <pubDate>Thu, 01 Aug 2024 17:22:22 GMT</pubDate>
    </item>
    </channel>
</rss>