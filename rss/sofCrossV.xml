<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 26 Nov 2024 12:35:06 GMT</lastBuildDate>
    <item>
      <title>理解 Jensen-Shannon 散度</title>
      <link>https://stats.stackexchange.com/questions/657869/understanding-of-the-jensen-shannon-divergence</link>
      <description><![CDATA[考虑两个分布$p$和$q$（绝对连续性没有提及），Jensen-Shannon散度定义为：
$$
JSD(p||q) = \frac{1}{2}\left[D(p||m) + D(q||m)\right],
$$
其中$m = (p + q) / 2$。维基百科上有一个不等式：$JSD(p||q) \le \frac{1}{2}V(p, q) = \frac{1}{2} \sum_i |p_i - q_i|$。
据我所知，后者适用于任何具有相同支持的 $p$ 和 $q$，但在实践中这似乎是错误的。我有相同形状的数组，请参见图像。
有什么问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/657869/understanding-of-the-jensen-shannon-divergence</guid>
      <pubDate>Tue, 26 Nov 2024 12:32:10 GMT</pubDate>
    </item>
    <item>
      <title>含义：各层级系数的同质性？</title>
      <link>https://stats.stackexchange.com/questions/657868/meaning-of-homogeneity-of-the-coefficient-for-all-levels</link>
      <description><![CDATA[“粗体”部分是什么意思？
“此外，堆肥期（分别为 7 周和 10 周）与添加剂之间的相互作用具有统计显著性（P 值 &lt;0.01），这意味着可以假设协变量的系数在因子的各个水平上是同质的。”
我认为因子是 7 周或 10 周。协变量（添加剂）被赋予一个系数 - 我明白这句话的表面含义。但我不明白为什么统计显著性意味着系数在所有水平上都是同质的。我的知识中缺少了一些东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/657868/meaning-of-homogeneity-of-the-coefficient-for-all-levels</guid>
      <pubDate>Tue, 26 Nov 2024 12:04:43 GMT</pubDate>
    </item>
    <item>
      <title>均值抽样分布近似于学生 t 分布的证据是什么？</title>
      <link>https://stats.stackexchange.com/questions/657867/what-is-the-proof-of-the-mean-sampling-distribution-being-approximated-by-studen</link>
      <description><![CDATA[在方差未知的非正态分布的情况下，平均值的抽样分布（大样本）近似于学生 t 分布的理由是什么？
==============================
我知道

在方差未知的正态分布的情况下，平均值的抽样分布恰好是学生 t 分布。
大样本中平均值的抽样分布在大样本中近似于正态（通过 CLT）

但是，证明方差未知的近似正态分布近似于学生 t 分布在我看来需要额外的步骤。]]></description>
      <guid>https://stats.stackexchange.com/questions/657867/what-is-the-proof-of-the-mean-sampling-distribution-being-approximated-by-studen</guid>
      <pubDate>Tue, 26 Nov 2024 11:55:09 GMT</pubDate>
    </item>
    <item>
      <title>LMM：当天的效果可能因受试者而异——固定效果还是随机效果？</title>
      <link>https://stats.stackexchange.com/questions/657861/lmm-effect-of-day-may-differ-between-subjects-fixed-or-random-effect</link>
      <description><![CDATA[我们在九天内对 12 只动物进行了一项测试，测试分为三个阶段（a/b/c），三种条件（C1/C2/C3），即每只动物经历每种条件三次。每天，在三种条件下测试四只动物。这是一个简化的示例表，其中有三只动物，为期两天：

我计划使用广义线性混合模型分析在各个阶段收集的计数数据（每个阶段一个数据点）。感兴趣的效果是条件 * 阶段相互作用 - 我们期望在第一阶段（习惯化，无论条件如何，治疗都相同）的值相似，但在其他阶段根据条件的不同值不同。该模型需要对每只动物进行随机截距，并且由于动物对不同条件和阶段的反应在个体之间会有所不同，我们还需要对它们进行随机斜率。
使用条件和阶段虚拟编码，基本模型将是
changes ~ phase * cond + 
(1 + cond.code.2 + cond.code.3 + phase.code.2 + phase.code.3 | animal)

需要将日期作为随机效应输入，因为我们可以在不同的日子进行采样。这应该以个体为基础（“动物日”），因为动物对每一天的具体情况的反应（例如，不同昆虫压力引起的烦躁）预计在个体之间会有所不同：
changes ~ phase * cond + 
(1 + cond.code.2 + cond.code.3 + phase.code.2 + phase.code.3 | animal) + 
(1 | day.in.animal)

问题是：我是否也需要将一天作为固定效应输入？也许是为了一天的一般效应，与“动物日”形成对比？如果是这样，它需要与阶段和条件进行三向交互，并且还需要有一个随机斜率，因为条件对阶段影响的影响可能在不同的日期之间有所不同，并且它们之间的差异对于每个人来说都是不同的。我对当天的效果本身不感兴趣，但如果它影响我感兴趣的效果，那么上述模型中的随机效应是否足够？]]></description>
      <guid>https://stats.stackexchange.com/questions/657861/lmm-effect-of-day-may-differ-between-subjects-fixed-or-random-effect</guid>
      <pubDate>Tue, 26 Nov 2024 10:49:04 GMT</pubDate>
    </item>
    <item>
      <title>比率标度是一种什么样的代数结构？</title>
      <link>https://stats.stackexchange.com/questions/657860/what-kind-of-algebraic-structure-is-a-ratio-scale</link>
      <description><![CDATA[在一篇开创性的论文中，Stevens (1946) 引入了四重尺度分类：名义尺度、序尺度、区间尺度和比率尺度。他根据尺度在变换下保留的比较类型（即：相等、顺序、差异和比率）对尺度进行分类。
在原始论文中，Stevens 将这些与代数群（分别为置换、等渗、线性和相似性）联系起来。但是，我认为另一种（也许更直观的）描述尺度的方法可能是使用一些众所周知的结构：

名义：等价关系
序数：全序
区间：Lebesque 测度（维度 1）/ Lawvere 度量空间
比率：？

有人知道可以很好地描述比率尺度的结构吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657860/what-kind-of-algebraic-structure-is-a-ratio-scale</guid>
      <pubDate>Tue, 26 Nov 2024 10:48:59 GMT</pubDate>
    </item>
    <item>
      <title>正态性假设 - qqplot 解释</title>
      <link>https://stats.stackexchange.com/questions/657859/normality-assumption-qqplot-interpretation</link>
      <description><![CDATA[我目前正在从事一个涉及评估多个变量分布的项目，并且我正在使用 Q-Q 图作为分析的一部分。虽然我已经为这些变量生成了 Q-Q 图。确实，我已经研究这些很长时间了，但我仍然想在这里听取意见。这些变量的样本量接近 70，目的是在纵向分析的几个变量之间进行独立 t 检验。我可以提出，shapiro 和 ks-test 拒绝正态性假设。
如果您能指导我准确解释它们以评估正态性并识别任何偏离高斯分布的情况，我将不胜感激。这些生物标志物通常在尾部变得更重，但我不会进行转化。欢迎任何评论！


]]></description>
      <guid>https://stats.stackexchange.com/questions/657859/normality-assumption-qqplot-interpretation</guid>
      <pubDate>Tue, 26 Nov 2024 10:45:29 GMT</pubDate>
    </item>
    <item>
      <title>从两个直方图中按相对权重进行重要性抽样</title>
      <link>https://stats.stackexchange.com/questions/657858/importance-sampling-with-relative-weight-from-two-histograms</link>
      <description><![CDATA[我有两个实数值数据集，$X = (x_1, \dots, x_N)$ 和 $Y = (y_1, \dots, y_M)$。这里 $Y$ 是 $X$ 的子集。这些数据点可以被视为来自某些未知密度的样本，分别为$x\sim p(\cdot)$和$y \sim p(\cdot|A)$，其中$A$是一些限制条件。
具体而言，我们可以假设$p(x|A)$非零意味着$p(x)$也非零。事实上，考虑到$A$为真或为假的两种可能性，我们有$p(x) = p(A)p(x|A) + (1-p(A))p(x|\text{not } A)$，其中$p(A)$是$A$为真的概率。
我有兴趣估计以下形式的积分：
$$I = \int \frac{p(x|A)}{p(x)} f(x) \mathrm{d}x$$
但是，我不知道密度的形式$p(x)$ 或 $p(x|A)$。我可能也不知道 $p(A)$ 的值，尽管我可能可以轻松估算它。直觉上，我认为我需要 $p(A)$ 来估算 $I$。除此之外，假设我唯一可以访问的是样本 $X = (x_1, \dots, x_N)$ 和 $Y = (y_1, \dots, y_M)$。
我们可以使用样本 $X = (x_1, \dots, x_N)$ 和 $Y = (y_1, \dots, y_M)$ 来构建 $I$ 的估计值吗？如果需要，假设我们还知道 $p(A)$。
请随意编辑这个问题的标题，我不确定如何称呼它。]]></description>
      <guid>https://stats.stackexchange.com/questions/657858/importance-sampling-with-relative-weight-from-two-histograms</guid>
      <pubDate>Tue, 26 Nov 2024 09:52:28 GMT</pubDate>
    </item>
    <item>
      <title>四分位数变异系数：Q1+Q3 与中位数</title>
      <link>https://stats.stackexchange.com/questions/657856/quartile-coefficient-of-variation-q1q3-versus-median</link>
      <description><![CDATA[概率分布离散度的常用度量是变异系数 ($CV$)，计算方法为 $$CV = \frac{\sigma}{\mu}$$。
但是，对于某些类型的分布，它可能并不合适，在文献中，我可以找到基于分布四分位数的其他度量。但是，有两种方法可以计算“基于四分位数的变异系数”/“四分位数离散度系数”/“四分位数变异系数”/“四分位数变异系数” （这些没有一致的命名）：
$$CV_Q = \frac{Q_3 - Q_1}{Q_3 + Q_1}$$
或
$$CV_Q = \frac{Q_3 - Q_1}{Q_2}$$
后一种变体似乎主要用于弹性成像，例如通过超声测量肝脏硬度(1)，而前一种变体似乎在大部分文献中更常见，并且显然在这本书中介绍过（但这可能不是主要来源......可能比 1999 年更早）：CRC 标准概率和统计表和Formulae (1999)，作者 Zwillinger 和 Kokoska，第 17 页。
到目前为止，我找不到任何描述，说明两种变体的含义相似或不同，以及为什么应该优先选择其中一种。对于后一种变体，另一个问题中有一条评论：具有总体中位数的变异系数

这是一个不同的度量。一般来说，它不是 SD/均值的良好估计量。对于偏斜数据，中位数通常不是均值的良好估计量，并且 IQR 预计不会等于 SD。

因此，在处理偏斜分布时，总是应该优先选择前一种变体？]]></description>
      <guid>https://stats.stackexchange.com/questions/657856/quartile-coefficient-of-variation-q1q3-versus-median</guid>
      <pubDate>Tue, 26 Nov 2024 09:39:40 GMT</pubDate>
    </item>
    <item>
      <title>R 中针对大型纵向数据集的有效插补方法</title>
      <link>https://stats.stackexchange.com/questions/657855/efficient-imputation-method-for-big-longitudinal-dataset-in-r</link>
      <description><![CDATA[我有一个非常大的数据集，大约有 300 万行和 50 个不同类型的变量。该数据集是长格式的纵向数据集（大约有 350,000 个唯一个体）。我想在考虑嵌套在个体中的数据的纵向性质的同时填补缺失数据。我最初的想法是在 2 个级别上使用预测均值匹配进行多重填补。（mice 包与辅助包 miceadds 和 2l.pmm），然而，不仅填补需要几天时间才能完成，而且即使对于高端台式机（64GB DDR5，i9），使用来自多个数据集的池化结果进行填补后分析也几乎是不可能的。我还尝试了带有 missForests 的随机森林（ID 用作预测因子，我认为它并没有真正考虑嵌套数据），以及 doParallel，但即使对于 10,000 行的小子集，使用 20 个核心并行也需要很长时间才能完成。
我可以选择哪些方式来最好地通过一次归纳来归纳该数据集，尽可能高效，同时还能考虑到数据集的纵向格式？]]></description>
      <guid>https://stats.stackexchange.com/questions/657855/efficient-imputation-method-for-big-longitudinal-dataset-in-r</guid>
      <pubDate>Tue, 26 Nov 2024 09:22:14 GMT</pubDate>
    </item>
    <item>
      <title>用百分比来描述少于100人的样本是否有问题？</title>
      <link>https://stats.stackexchange.com/questions/657851/is-it-problematic-to-use-percentages-to-describe-a-sample-with-less-than-100-peo</link>
      <description><![CDATA[这是一个非常基础、愚蠢的问题，但我找不到答案，而且最重要的是，我通常对常识/直觉持怀疑态度。
当整个样本中不到 100 人时，如果说“样本中 80% 的人喜欢香蕉口味”，我觉得这是“作弊”。但也许我错了，所以我才问这个问题。我发现至少有两个问题：

如果我忽略了样本量，可能会造成误导

有些百分比是不可能达到的，例如，如果样本中只有 10 个人，就不可能有 0 到 10% 之间的任何百分比


我在这里是否过于谨慎，使用这样的百分比真的可以吗？或者这真的是个问题？是否还有其他我没发现的问题？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657851/is-it-problematic-to-use-percentages-to-describe-a-sample-with-less-than-100-peo</guid>
      <pubDate>Tue, 26 Nov 2024 07:51:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么在分类中不使用软标签是可以的？</title>
      <link>https://stats.stackexchange.com/questions/657850/why-is-it-ok-not-to-use-soft-labels-in-classification</link>
      <description><![CDATA[从某种意义上说，我有一个与使用交叉熵损失函数与软标签可以吗？相反的问题，也就是为什么不可以在分类中使用软标签？
假设您有一个要解决的二元分类任务。以下是您通常的处理方式。您从一些未知的概率分布u(y=1|x)开始。您通过从中抽样来近似u(y=1|x)以生成数据集（概率分布p(y=1|x)）。然后创建一个模型q(y=1|x)。然后，通过最小化 q(y=1|x) 和 p(y=1|x) 之间的交叉熵损失，将模型拟合到概率分布 p(y=1|x)。
为了计算交叉熵，通常假设 p(y=1|x) 始终为 1 或 0，尽管这不一定正确 - 例如，假设我们的数据集中有两个体重、身高等相同的患者，但一个生病，另一个没有生病 - 如果是这样，则 p(y=1|x) = 1/2。相反，您通常会将第一个样本 p(y=1|x) 设置为 0，将第二个样本设置为 1。为什么做出这种假设如此普遍？这是一个安全的假设吗？如果是，为什么？换句话说，为什么软标签不总是用于分类任务？]]></description>
      <guid>https://stats.stackexchange.com/questions/657850/why-is-it-ok-not-to-use-soft-labels-in-classification</guid>
      <pubDate>Tue, 26 Nov 2024 07:50:10 GMT</pubDate>
    </item>
    <item>
      <title>预测确定性数据集的概率分布</title>
      <link>https://stats.stackexchange.com/questions/657848/predicting-the-probability-distribution-of-a-deterministic-dataset</link>
      <description><![CDATA[在经典机器学习回归中，我们通常假设目标变量$y$，给定输入$x$，遵循概率分布，这使我们能够建模和预测不仅$y$的预期值，而且还可以建模和预测其方差。
但是，考虑这样一种情况，其中输入$x$和目标变量$y$之间的关系是确定性的。也就是说，对于任何给定的输入$x$，都存在一个唯一且理论上可知的地面真相$y$。我们训练一个回归模型来预测给定$x$的$y$，生成一个预测$\hat{y}$。在预测$y$的值之后，我们还想预测预测本身的&quot;不确定性&quot;，或者在某种意义上&quot;方差&quot;。我们通过预测给定输入 $x$ 的值 $\sigma$（预测值为 $\hat{y}$，真实值为 $y$）来实现此目的，使得似然值 $f(y | \hat{y}, \sigma)$ 达到最大化，其中 $f$ 是以 $\hat{y}$ 为中心，方差为 $\sigma^2$ 的正态分布的概率密度函数。直观地看，我们针对给定 $x$ 预测的 $\sigma$ 在某种意义上告诉我们预测的不确定性。
由于数据生成过程中没有固有的随机性，并且数据集是确定性的，因此方差的传统概率解释并不直接适用。因此，核心问题是：
我们能否在这种确定性设置中为预测值 $\sigma$ 提供概率或正式解释？如果不是条件概率分布 $p(y|x)$ 的标准差，那么 $\sigma$ 代表什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657848/predicting-the-probability-distribution-of-a-deterministic-dataset</guid>
      <pubDate>Tue, 26 Nov 2024 06:04:39 GMT</pubDate>
    </item>
    <item>
      <title>如何拆分小型数据集以进行生存分析：训练/验证还是包含测试集？</title>
      <link>https://stats.stackexchange.com/questions/657847/how-to-split-a-small-dataset-for-survival-analysis-train-validation-or-include</link>
      <description><![CDATA[我正在使用一个包含 140 个样本的小型数据集对胰腺癌进行生存分析。该数据集包括 WSI 和掩码数据以及生存信息。
1. 当前方法
我在训练/验证拆分中使用 5 倍交叉验证，结果每倍有 112 个样本用于训练，28 个样本用于验证。
2. 合作者的建议
将数据集分成三部分 - 98 个用于训练，28 个用于验证，14 个用于测试集。
鉴于数据集较小且无法使用外部数据集（由于需要掩码和生存信息），我不确定从同一数据集中留出测试集是否合理。

仅依靠训练/验证结果会更好吗？
进一步拆分成测试集是否会冒着未充分利用本来就很小的数据集的风险？

任何关于小样本生存分析最佳实践的见解都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657847/how-to-split-a-small-dataset-for-survival-analysis-train-validation-or-include</guid>
      <pubDate>Tue, 26 Nov 2024 05:06:12 GMT</pubDate>
    </item>
    <item>
      <title>理解重复实验中置信区间的解释</title>
      <link>https://stats.stackexchange.com/questions/657838/understanding-the-interpretation-of-confidence-intervals-in-repeated-experiments</link>
      <description><![CDATA[我理解 95% 置信区间 (CI) 的解释是，从长远来看，从重复实验计算出的 95% 的区间将包含真实参数。我还知道 CI 不是关于参数本身的概率陈述 - 我们不能说特定观察到的 CI 有 95% 的概率包含真实值。
但是，我试图理解以下场景：
假设我们运行 100 次实验，每次都计算感兴趣参数的 95% 置信区间。如果我随机选择其中一个 CI，那么说所选区间有 95% 的概率包含真实参数是否正确？
关键区别在于我们不能说相同的固定 CI 在重复实验中将保持 95% 的概率，而是每次新的重复都有新的 CI 值，并且每个新值都有 95% 的概率包含或不包含？]]></description>
      <guid>https://stats.stackexchange.com/questions/657838/understanding-the-interpretation-of-confidence-intervals-in-repeated-experiments</guid>
      <pubDate>Tue, 26 Nov 2024 00:12:44 GMT</pubDate>
    </item>
    <item>
      <title>概率收敛速度</title>
      <link>https://stats.stackexchange.com/questions/657829/rate-of-convergence-in-probability</link>
      <description><![CDATA[我正在阅读这篇论文
在这篇论文中，他们证明了定理 7，其表述如下

定理 7：让 $p, q, X, Y$ 按照问题 1 中的方式定义，并假设 $0 \leq k(x, y) \leq K$。然后：
$$
\Pr_{X, Y} \left\{ 
\big| \text{MMD}_b[\mathcal{F}, X, Y] - \text{MMD}[\mathcal{F}, p, q] \big| &gt; 2 \left( \left( \frac{K}{m} \right)^{\frac{1}{2}} + \left( \frac{K}{n} \right)^{\frac{1}{2}} \right) + \varepsilon
\right\}
\leq 
2 \exp\left(-\frac{\varepsilon^2 mn}{2K(m+n)}\right),
$$
其中 $Pr_{X, Y}$ 表示 $m$ 个样本 $X$ 和 $n$ 个样本 $Y$ 的概率。

在此之前定理中，作者指出经验 MMD 以 $O((m+n)^{-\frac{1}{2}})$ 的概率收敛到其总体值。我不明白他们是如何得出这个收敛速度的。您能否提醒我一下以速率收敛的概率定义，并解释它与定理 7 有何关联？]]></description>
      <guid>https://stats.stackexchange.com/questions/657829/rate-of-convergence-in-probability</guid>
      <pubDate>Mon, 25 Nov 2024 21:18:24 GMT</pubDate>
    </item>
    </channel>
</rss>