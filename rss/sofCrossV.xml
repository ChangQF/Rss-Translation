<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 02 Jan 2025 21:15:24 GMT</lastBuildDate>
    <item>
      <title>关于 Montiel Olea 和 Pflueger 弱 IV 检验中有效自由度计算的问题</title>
      <link>https://stats.stackexchange.com/questions/659467/questions-on-the-calculation-of-effective-degrees-of-freedom-in-montiel-olea-and</link>
      <description><![CDATA[我正在使用 stata 运行回归分析，并使用 Montiel Olea 和 Pflueger (2013) 提出的著名异方差稳健检验来测试我的 IV 的弱点。我注意到 stata 给出的临界值始终保持不变，这似乎很奇怪，因为我已经多次更改了样本量。此外，临界值似乎不依赖于我选择将常数部分排除。
我的回归是一个简单的 IV-LS，只有一个因变量、一个自变量和一个工具。stata 代码如下所示：
ivreg2 y (x = z)，first noconst robust
weakivtest

这种现象对我来说似乎很奇怪，因为在普通的 F 检验中，临界值取决于自由度，而自由度又取决于样本量和截距的包含。我对计量经济学了解甚少，因此很难快速浏览 Montiel Olea 等人的文章。 （2013），尤其是他们使用一种我看不懂的复杂算法来计算有效自由度的部分。我想知道当我改变样本量或排除截距时，临界值（和有效自由度）保持不变是否正常？或者 weakivtest 使用的默认自由度是 $1$？有人能尽可能清楚地向我解释一下吗？提前谢谢！
我也尝试使用 RStudio 运行相同的测试，也出现了相同的现象。我的代码如下所示：
library(ivDiag)
library(momentfit)
mod = momentModel(y ~ 0 + x, ~ 0 + z, data = dat, vcov=&quot;MDS&quot;)
MOPtest(mod, tau = 0.10)
]]></description>
      <guid>https://stats.stackexchange.com/questions/659467/questions-on-the-calculation-of-effective-degrees-of-freedom-in-montiel-olea-and</guid>
      <pubDate>Thu, 02 Jan 2025 19:42:09 GMT</pubDate>
    </item>
    <item>
      <title>如何从逻辑回归的引导程序中获取 p 值？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659465/how-to-obtain-p-values-from-a-bootstrap-of-a-logistic-regression</link>
      <description><![CDATA[我有一个二元响应变量y和一组协变量(x_1, x_2, ..., x_n)。在执行多元逻辑回归时（在我的例子中使用 R 和 glm 函数：glm(y ~ x1 + x2 + x3 + ... + xn, family = binomial)），我可以获得 $p$ 值来检验协变量的系数是否显著，即 $H_0:\beta_j = 0$。
由于我的数据的维度（超过 100000 行和 5000 列），我无法执行多元逻辑回归来获取 $p$ 值（我的数据已经过过滤，即我无法执行变量选择）。我有如此庞大的数据集，以至于我必须对数据进行子采样才能容纳在我的计算机内存中。因此，我选择执行引导程序（b=引导样本数）以获得多元逻辑回归的系数，如下所示：

我使用替换执行行选择，保持采样的二进制响应变量中 0/1 值的分布。
我将 glm 函数拟合到简化的数据集并获得系数和 p 值。
我重复此过程 b 次，获得系数和 p 值的向量。

每个变量（在原始数据集中）的最终系数是每个引导样本中获得的系数之间的平均值。
我的问题是：每个样本中获得的 p 值向量的平均值是最终的 p 值吗？
恐怕不是，但在这种情况下，我如何获得引导程序的 p 值逻辑回归？
你肯定会建议我使用惩罚逻辑回归（套索）。我已经尝试过了，计算速度非常快。但是，使用后者，我仍然无法获得这些系数显著性的 p 值。如果你有关于如何获得最后这些值的参考，这对我也很有用。]]></description>
      <guid>https://stats.stackexchange.com/questions/659465/how-to-obtain-p-values-from-a-bootstrap-of-a-logistic-regression</guid>
      <pubDate>Thu, 02 Jan 2025 19:07:17 GMT</pubDate>
    </item>
    <item>
      <title>在 lme 中，混合中断时间序列模型中是否应仅排除干预之前/之后的观察结果？</title>
      <link>https://stats.stackexchange.com/questions/659464/in-lme-should-the-observations-only-before-after-an-intervention-be-excluded-in</link>
      <description><![CDATA[我们正在使用中断时间序列 (ITS) 模型检查 y 是否在 事件 之后在水平和/或斜率上发生变化。鉴于每个用户在 时间 上都有多个观察结果，我们使用以下混合模型：
m = 
lme(y ~ x + time + event + time:event, 
random = ~time|user_id, 
correlation = corAR1(form = ~1|user_id), 
weights = varExp(form = ~time), 
data = df)

有些用户的 y 值仅在事件发生前，有些用户的 y 值仅在事件发生后。
在拟合上述模型之前，是否应该排除这些用户（大约占总数的 1/3）？]]></description>
      <guid>https://stats.stackexchange.com/questions/659464/in-lme-should-the-observations-only-before-after-an-intervention-be-excluded-in</guid>
      <pubDate>Thu, 02 Jan 2025 18:24:37 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯参数估计的假设检验和 p 值</title>
      <link>https://stats.stackexchange.com/questions/659463/hypothesis-tests-and-p-values-of-bayesian-parameter-estimates</link>
      <description><![CDATA[在频率统计中，通常对（广义）线性模型的估计参数进行假设检验，例如检验其中一个系数是否与 0 有显著差异或比其他系数有更大的影响。这样，您还可以检索给定系数的 p 值，这允许您例如根据某些标准对它们进行排名。
我的问题是，当您没有模型参数的 MLE 固定估计值，而只有贝叶斯方法的均值（和方差）估计值时，是否可以应用相同的假设检验（Wald 检验、F 检验、T 检验等）？
我知道这在技术上是可行的，因为您可以将均值视为固定值并像以前一样运行测试，但我想知道这是否严重违反了测试有效性所必需的某些假设。
此外，如果可以这样做，在解释结果 p 值之前有什么特别需要注意的吗？
注意：我知道当使用贝叶斯方法时，人们可以只查看后验概率来回答在频率论环境中使用假设检验回答的类似问题（正如本 问题），但有时仍然需要 p 值。]]></description>
      <guid>https://stats.stackexchange.com/questions/659463/hypothesis-tests-and-p-values-of-bayesian-parameter-estimates</guid>
      <pubDate>Thu, 02 Jan 2025 18:19:19 GMT</pubDate>
    </item>
    <item>
      <title>这个设置是否正确，可以比较 3 个数据集中的值，其中一些是正态分布的，一些不是？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659461/is-this-set-up-correctly-to-compare-values-across-3-data-sets-some-of-which-are</link>
      <description><![CDATA[下面是我目前正在进行的数据分析的摘录，用于比较数据的平均值。有三个实验（c、s 和 m），每个实验有 2 种处理方法（处理 b 和 p）。每个实验大约包含 45 个观察值。如果有人能快速浏览一下并告诉我我是否设置正确，我将不胜感激。
使用 Lillie 检验检查正态性，p 值截止值为 0.05。然后使用 Wilcoxon 秩和检验（matlab 函数 rankedsum）比较非正态分布，并使用双尾 t 检验（matlab 函数 ttest2）比较正态分布值。数据也被转换为自然对数值并再次进行比较。
提前感谢您的帮助。
|| || ||C|S|M| |B|.1379|.001|.001| |P|.0789|.0055|.001|
Lillie 正态性检验的结果，在 B 部分中，只有 C 数据的值呈正态分布，就像在 p 版本中一样。
对数变换数据
|| || ||C|S|M| |B|.0276|.0052|.0022| |P|.2816|.0018|.001|
对数变换后，对于 C P 部分之外呈正态分布的数据，任何处理后的数据均不呈正态分布。
仅 Wilcoxon 秩和 P 与 B
|| || ||C|S|M| |非变换|.2816|.0018|.001| |对数变换|.6755|.0582|.6042|
使用 Wilcoxon 秩和比较每种治疗的 P 组和 B 组。S 组和 M 组之间没有显著差异，但 C 组确实显示出随时间推移的剩余数据的显著差异。当对数据进行对数变换时，所有三种治疗在组间均未显示出显著差异。
非配对双尾 T 检验仅 P 与 B
|| || ||C|S|M| |非变换|.4819|.0407|.9336| |对数变换|.3765|.0177|.7556|
使用非配对双尾 t 检验比较每种治疗的 P 组和 B 组。唯一显著的差异出现在 S 中，对于非转换和对数转换的数据值，S 都存在显著差异，而 C 和 M 没有显著差异。
使用 Matlab 中的 Lilliefors 检验以 5% 的显著性水平检查数据的正态性。对于正态分布的数据，使用非配对 t 检验（Matlab 函数 ttest2），而对于非正态分布的数据，使用 Wilcoxon 秩和检验（Matlab 函数 Ranksum - 功能等同于 Mann-Whitney U 检验）。]]></description>
      <guid>https://stats.stackexchange.com/questions/659461/is-this-set-up-correctly-to-compare-values-across-3-data-sets-some-of-which-are</guid>
      <pubDate>Thu, 02 Jan 2025 17:52:08 GMT</pubDate>
    </item>
    <item>
      <title>在回归中指定仅与部分人群相关的交互项</title>
      <link>https://stats.stackexchange.com/questions/659460/specifying-interaction-terms-in-a-regression-that-are-only-relevant-to-some-part</link>
      <description><![CDATA[这是我教科书上的一道题。

瑞士的一位社会科学家正在研究移民对收入的影响。她有 1000 个人的数据（每个人一个数据点），包括他们当前的年龄、当前收入、是否出生在瑞士以及他们移民到瑞士时的年龄（如果适用）。她如何建立回归模型来研究在瑞士生活相同百分比的生活对收入的影响，与年轻时移民的人相比，与年老时移民的人相比，两者有何不同？


我是这样处理这个问题的
（我想我们假设一个出生在瑞士的人永远不会离开，一旦一个人移民到瑞士，他就永远不会离开——或者在外面度过的时间可以忽略不计，这个问题就可以成立）
：

$y$ 是因变量：收入（我可能会使用对数收入来防止负面预测）
$x_1$ 表示当前年龄（针对所有人）
$x_2$ 表示某人是否是移民：$x_2 = 0$ 为本土出生者，$x_2 = 1$ 为移民
$x_3$ 代表移民时的年龄：对于移民：他们抵达时的年龄，对于本土出生者：等于 0
$x_4$ 代表在该国度过的生命比例：对于本土出生者：$x_4 = 1$ 始终如此，对于移民：

$x_4 = \frac{\text{当前年龄} - \text{移民时的年龄}}{\text{当前年龄}} = \frac{x_1 - x_3}{x_1}$
我为本土出生者建立了一个模型（$x_2 = 0$):
$$ y = \beta_0 + \beta_1x_1 + \epsilon $$
然后我为移民建立了一个模型（$x_2 = 1$）：
$$ y = (\beta_0 + \beta_2) + \beta_3x_4 + \beta_4x_3 + \beta_5x_1 + \epsilon $$
然后我结合了两个模型：
$$ y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3(x_4 \cdot x_2) + \beta_4(x_3 \cdot x_2) + \beta_5(x_1 \cdot x_2) + \epsilon $$
从这里我们可以看到：

$\beta_0$：当所有变量都为零时（即出生在本国的人在 0 岁时的生活比例如何影响其收入（假设年龄和移民年龄保持不变）
$\beta_1$：年龄对收入的基本影响适用于所有人，无论移民身份如何
$\beta_2$：当所有其他变量为零时，移民与出生在本国的人相比的额外基线收入差异
$\beta_3$：在年龄和移民年龄保持不变的情况下，在本国度过的生活比例如何影响移民收入
$\beta_4$：在当前年龄和生活比例保持不变的情况下，移民的年龄如何影响其收入
$\beta_5$：与基线相比，移民的年龄影响有多大差异年龄效应

从这里开始，我认为该模型可用于以下解释：

$\beta_3$告诉我们，在该国度过更大人生比例的移民是否有更高的收入，即使在控制了他们目前的年龄和抵达时的年龄之后也是如此。

$\beta_4$揭示了抵达时年龄较大与较小是否会影响收入，即使在考虑了某人在该国居住的时间长短和他们目前的年龄之后也是如此。

在任何给定年龄$x_1$，移民和本土出生者之间的总收入差异为$\beta_2 + \beta_3x_4 + \beta_4x_3 + \beta_5x_1$。这表明移民与本地人的差距如何随着年龄、在该国居住的时间以及抵达时的年龄而变化。



当回归模型中的交互项仅适用于部分人口时，这是正确指定和解释交互项的方式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659460/specifying-interaction-terms-in-a-regression-that-are-only-relevant-to-some-part</guid>
      <pubDate>Thu, 02 Jan 2025 17:49:11 GMT</pubDate>
    </item>
    <item>
      <title>使用 ARIMA/SARIMA 对重叠周期数据进行预测</title>
      <link>https://stats.stackexchange.com/questions/659459/forecasting-using-arima-sarima-for-overlapping-cycle-data</link>
      <description><![CDATA[我正在处理历史招聘周期的申请数据，并尝试使用 SARIMA 预测当前招聘周期结束时的申请数量。但是，招聘周期重叠 - 例如，2023/24 年的申请将在 2024/25 年的申请开始的同时提交。重要的是，模型对这两个周期的处理方式不同（即使它们同时发生），因为周期开始时的申请最多，而周期结束时的申请最少。另外，我不想预测 X 时间的申请数量，我想预测 Y 招聘周期 X 时间的申请数量。
每个招聘周期的数据都遵循非常相似的时间路径，因此原则上它应该非常适合 SARIMA。但是，我不熟悉历史数据不连续时的预测，所以我不确定是否存在关于最佳处理方式的细微差别。任何建议都会非常有帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/659459/forecasting-using-arima-sarima-for-overlapping-cycle-data</guid>
      <pubDate>Thu, 02 Jan 2025 17:46:58 GMT</pubDate>
    </item>
    <item>
      <title>随着 p 增加的几何分布的期望和方差</title>
      <link>https://stats.stackexchange.com/questions/659457/expectation-and-variance-of-geometric-distribution-with-increasing-p</link>
      <description><![CDATA[考虑这样一种情况，我们从伯努利分布中得出成功概率为$p $（为简单起见，假设$p &lt; \frac{2}{3}$）。每次失败都会使成功概率增加$0.1p$，最大成功概率上限为$1.5p$。实现一次成功所需的试验期望值和方差是多少？
对于恒定的成功概率，这简化为几何分布，其成功率为$p$，预期值$ \mu = \frac{1}{p} $，方差为$ \sigma^2 = \frac{1-p}{p^2} $。因此，解决方案似乎受限于 $ \mu = [\frac{1}{1.5p}, \frac{1}{p}]$ 和 $ \sigma^2 = [\frac{1-1.5p}{(1.5p)^2}, \frac{1-p}{p^2}]$。

更新：
这是我得到平均值的方法：
让 $P(X=n)$ 成为第 n 次试验后成功的 pmf，然后
$P(X=1)= p$ 
$P(X=2)=(1-P(X=1))1.1p$
$P(X=3)=(1-P(X=1)-P(X=2))1.2p$
$P(X=4)=(1-P(X=1)-P(X=2)-P(X=3))1.3p$
$P(X=5)=(1-P(X=1)-P(X=2)-P(X=3)-P(X=4))1.4p$
$P(X=6)=(1-P(X=1)-P(X=2)-P(X=3)-P(X=4)-P(X=5))1.5p$
$P(X=7)=(1-P(X=1)-P(X=2)-P(X=3)-P(X=4)-P(X=5)-P(X=6))1.5p$
请注意，从第 6 次试验开始，分布遵循几何分布，$p^\prime=1.5p$。
则平均值为：
$\mu=XP(X)=P(X=1)+2P(X=2)+3P(X=3)+4P(X=4)+5P(X=5)+6P(X=6)+...$
$=p+2(1-P(X=1))1.1p+3(1-P(X=1)-P(X=2))1.2p+4(1-P(X=1)-P(X=2)-P(X=3))1.3p+5(1-P(X=1)-P(X=2)-P(X=3)-P(X=4))1.4p+(1-P(X=1)-P(X=2)-P(X=3)-P(X=4)-P(X=5))*(5+1/1.5p)$
对于 p=0.1，平均值为 7.535067。]]></description>
      <guid>https://stats.stackexchange.com/questions/659457/expectation-and-variance-of-geometric-distribution-with-increasing-p</guid>
      <pubDate>Thu, 02 Jan 2025 16:59:23 GMT</pubDate>
    </item>
    <item>
      <title>结合多个调查设计对象的年份，何时适当使用交互项</title>
      <link>https://stats.stackexchange.com/questions/659458/combining-years-for-multiple-survey-design-object-when-to-appropriately-use-inte</link>
      <description><![CDATA[我正在使用 KID（儿童住院数据库）并使用 R 中的调查包。我有两个问题

何时使用 Strata 和 PSU 的交互项：
KID 数据库包含每年重新采样的 PSU（医院），而 Strata 包括 10% 的健康新生儿出院和 80% 的其他出院。
我不确定何时在定义 svydesign() 的 id 和 strata 参数时使用交互项。

id 参数应该使用 ~PSU 还是 ~interaction(PSU, YEAR) 来解释医院的年度重新采样？
strata 参数应该使用 ~strata 还是 ~interaction(strata, YEAR)？
我想确保设计反映了调查结构。

在子集化之后是否可以合并 survey.design 对象？或者是否需要先合并原始数据框，创建一个调查设计对象，然后再进行子集化？

例如，如果我按每年的人口统计组对 survey.design 对象进行子集化，是否可以合并生成的对象？]]></description>
      <guid>https://stats.stackexchange.com/questions/659458/combining-years-for-multiple-survey-design-object-when-to-appropriately-use-inte</guid>
      <pubDate>Thu, 02 Jan 2025 16:44:23 GMT</pubDate>
    </item>
    <item>
      <title>比较两个时间段内 beta 系数的相对重要性</title>
      <link>https://stats.stackexchange.com/questions/659455/comparing-the-relative-importance-of-beta-coefficients-across-two-time-periods</link>
      <description><![CDATA[我正在做一个项目，使用歌曲级数据集分析 1960-2000 年的 Billboard 100 数据。这涉及检查与每首歌曲相关的 6 个左右的音乐特征（价数、响度等），所有特征的刻度都在 0 到 1 之间，并确定它们是否与歌曲流行度有关（在数据集中从 1 到 100 测量）。
我可以使用简单的多元回归来做到这一点，其中流行度 = b1（特征 1）+ b2（特征 2）等 - 一切都很好。我还想做的是看看在哪些特征最能预测两个时间段之间的流行度方面是否存在“时代”差异。换句话说，我想分别比较每个时间段的 beta 系数的相对重要性。
我想要这样做的方式是对相同的 6 个特征运行两个单独的回归 - 一个针对时间段 A，一个针对时间段 B。我想要得出的结论可能是“对于 60 年代发行的歌曲，价位是流行度的最强预测因素，但对于 80 年代发行的歌曲，舞蹈性是最强的预测因素”。
这是一种有效的方法吗？需要说明的是，我并不是想比较两个回归之间的系数 - 只是比较它们内部的系数。]]></description>
      <guid>https://stats.stackexchange.com/questions/659455/comparing-the-relative-importance-of-beta-coefficients-across-two-time-periods</guid>
      <pubDate>Thu, 02 Jan 2025 16:16:15 GMT</pubDate>
    </item>
    <item>
      <title>如何计算由相关二项分布得出的综合得分的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/659454/how-to-calculate-confidence-intervals-for-a-composite-score-derived-from-depende</link>
      <description><![CDATA[假设我有一个名为 F 的模型，我计划问它 X 个不同的问题。由于 F 可能会由于某些随机因素而出错，因此我会将每个问题问 Y 次。如果它正确回答了某个问题，我们将得分定为 1；否则，我们将得分定为 0（二元结果）。
此外，如果在 Y 次重复同一个问题中，它至少正确回答了一次，我们将为该组 Y 个查询分配 1 分；否则，我们将分配 0 分。
这会产生一个由 0 和 1 组成的 X \times Y 矩阵，其中每一行对应于问同一个问题 Y 次。要评估模型在回答问题方面的表现，有两点很重要：

在 Y 次试验中至少有一次正确回答了多少个问题？
在 $X \times Y$ 中回答了多少个问题？

我正在寻找一个包含 (1) 和 (2) 的公式。一个可以区分以下三种情况下模型性能差异的公式（仅作为示例）：
$$
\text{Case 1} =
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
\end{bmatrix}
$$
$$
\text{Case 2} =
\begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
\end{bmatrix}
$$
$$
\text{Case 3} =
\begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 1 \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
\end{bmatrix}
$$
每种情况下的每个矩阵都是 $45 \times 4$，为了节省每个矩阵中的空间，使用点代替 0。
我正在考虑使用以下公式：
$$
\text{分数} = (0.5 \times \frac{\text{矩阵中所有条目的总和}}{X \times Y}) + (0.5 \times \frac{\text{至少回答正确的问题数}}{X})
$$
0.5 系数为公式的每个部分赋予相同的权重，并确保最终分数在 [0, 1] 范围内。如果 X = 45 且 Y = 4，我应该如何计算这个综合得分的置信区间？
我主要担心的是所涉及的两个分布是相互依赖的：(1) 矩阵中所有 0 和 1 的分布（总大小为 X \times Y），以及 (2) 每个问题在 Y 次试验中是否至少给出一个正确答案的分布（大小为 X）。
如果我想使用诸如 Clopper-Pearson 区间（适合二项分布并避免退化区间）之类的置信区间，考虑到这两个分布是相互依赖的，这是否合适？如果不是，哪种方法更适合构建这个综合得分的置信区间？
或者建议一个替代公式来衡量模型在给定 (1) 和 (2) 中的点时的性能。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659454/how-to-calculate-confidence-intervals-for-a-composite-score-derived-from-depende</guid>
      <pubDate>Thu, 02 Jan 2025 15:46:03 GMT</pubDate>
    </item>
    <item>
      <title>相当于 99％ 置信度的“三分法则”吗？[重复]</title>
      <link>https://stats.stackexchange.com/questions/659452/equivalent-of-rule-of-three-for-99-confidence</link>
      <description><![CDATA[除了 99% 的置信区间，“三法则” 的类似物是什么？
即，在查看包含 n 个未发生给定事件的受试者的样本后，如何以 99% 的置信度估计人群中发生率？]]></description>
      <guid>https://stats.stackexchange.com/questions/659452/equivalent-of-rule-of-three-for-99-confidence</guid>
      <pubDate>Thu, 02 Jan 2025 15:38:44 GMT</pubDate>
    </item>
    <item>
      <title>在 rugarch 包中为 arfima 模型建立不同的 DS 平稳性模型</title>
      <link>https://stats.stackexchange.com/questions/659453/modelling-different-ds-stationarity-for-arfima-models-in-rugarch-package</link>
      <description><![CDATA[众所周知，时间序列有两种主要的平稳类型：趋势平稳（TS 序列），如 x_{t} = f(t) + e_{t，其中 e_{t 是平稳过程；差分平稳（DS 序列），如 (1 - L)^d x_{t} = mu + e_{t，其中 e_{t 是平稳过程。
因此，arfimaspec 方法仅包含 include.mean 和 d 作为规范中的差分阶数。但据我所知，没有办法在 DS 序列中添加 mu，其中 d &gt; 0。而且也没有办法添加混合型平稳性，例如 (1 - L)^d x_{t} = f(t) + e_{t？
我错了吗？也许可以通过 arfimaspec 中的外部回归器添加它？
还有一个简短而无关紧要的问题：arfimaforecast/ugarchforecast 是否能为滞后值 &gt; 1 生成正确的均值预测？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659453/modelling-different-ds-stationarity-for-arfima-models-in-rugarch-package</guid>
      <pubDate>Thu, 02 Jan 2025 15:29:10 GMT</pubDate>
    </item>
    <item>
      <title>如果我对 MAE 损失求平方然后取其平方根，这会对模型训练有什么影响？</title>
      <link>https://stats.stackexchange.com/questions/659451/what-difference-would-it-make-to-model-training-if-i-squared-the-mae-loss-and-th</link>
      <description><![CDATA[我正在尝试使用汉明距离优化模型以对属于同一类的向量进行聚类。由于我无法直接使用汉明距离，因此我使用 MAE 损失，当 x_i != y_i 时，将 x_i 和 y_i 之间的差值限制在 0 和 1 之间。然而，在训练期间，使用 MAE 并不奏效（就模型收敛而言），但对 MAE 求平方并取其平方根似乎有效。有人知道原因吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659451/what-difference-would-it-make-to-model-training-if-i-squared-the-mae-loss-and-th</guid>
      <pubDate>Thu, 02 Jan 2025 15:14:56 GMT</pubDate>
    </item>
    <item>
      <title>如何估计两个坐标系之间的旋转？</title>
      <link>https://stats.stackexchange.com/questions/659430/how-can-i-estimate-the-rotation-between-two-cooordinate-frames</link>
      <description><![CDATA[我在两个坐标系（xyz 和 XYZ）中测量了 N 个点 p 的三维尺寸：
$$
p_i: \vec{x_i}, \vec{X_i} 
$$
坐标系相互旋转：
$$
\vec{X_i} = R\vec{x_i} 
$$
其中
$$
\vec{X_i} = 
\begin{bmatrix}X_i\\Y_i\\Z_i\end{bmatrix}
$$
$$
\vec{x_i} =
\begin{bmatrix}x_i\\y_i\\z_i\end{bmatrix}
$$
并且 $R(\alpha,\beta,\gamma)$ 是 3x3 旋转矩阵：

假设所有坐标都呈正态分布，方差相同：
$$
x_1 \sim \mathcal{N}(\mu_{x_1},\sigma),...,z_n \sim \mathcal{N}(\mu_{z_n},\sigma) 
$$
$$
X_1 \sim \mathcal{N}(\mu_{X_1},\sigma), ...,Z_n \sim \mathcal{N}(\mu_{Z_n},\sigma)
$$
对于 $\alpha$、$\beta$ 和 $\gamma$，一个好的估计量是什么？为什么？
到目前为止，我所做的是最小化：
$$
\underset{\alpha,\beta,\gamma}{\mathrm{argmin}} 
\{SE(\alpha,\beta,\gamma) = \Sigma_i |R\vec{x_i} - \vec{X_i}|^2\} 
$$
使用 Levenberg-Marquardt 算法 (scipy.optimize.least_squares)。
但是，我使用这种方法时仅考虑了 $\vec{X_i}$ 中的错误。我想同时考虑 $\vec{x_i}$ 和 $\vec{X_i}$ (总体最小二乘法) 中的误差。
解决这个问题是否像最小化一样简单：
$$
\underset{\alpha,\beta,\gamma}{\mathrm{argmin}} 
\{TSE(\alpha,\beta,\gamma) = \Sigma_i [|R\vec{x_i} - \vec{X_i}|^2 + |R^{-1}\vec{X_i} - \vec{x_i}|^2]\} 
$$
相反？
此外，我使用 $L_2$ 范数（最小二乘法），因为这似乎是标准做法。但为什么它比其他估计器更好？为什么不改用 $L_1$ 或 $L_{\infty}$？
我创建了一个 pandas 测试数据集。
这里我使用了$\alpha = 1°$、$\beta = 2°$和$\gamma = 3°$，并在$\vec{x}$和$\vec{X}$中添加了$\sigma = 0.01$的噪声。
这里是用 Python 实现的线性求解器。
它产生了以下输出：
实际旋转矩阵：
[[ 0.9980212 -0.05171974 0.03575975]
[ 0.05230407 0.99850932 -0.01560227]
[-0.0348995 0.01744177 0.99923861]]
估计旋转矩阵：
[[ 1.00228603 -0.06671378 0.0452653 ]
[ 0.04621024 0.97714644 -0.01505205​​]
[-0.02123221 0.01683688 1.00103115]]
alpha: 0.971802, beta: 1.886494, gamma: 3.266041

这里我取了 100 个解决方案的平均值（因为估计值是随机变量）。
结果相当不错，但有一个缺陷：
估计的旋转矩阵不正交。
每行的范数应该是 1，但第一行和最后一行都有元素 &gt; 1。
这是一个用 Python 实现的非线性求解器。
它产生了以下输出：
不对称：alpha：1.382373，beta：1.677021，gamma：3.002319
对称：alpha：1.382373，beta：1.677019，gamma：3.002318

总体最小二乘结果（对称）几乎与最小二乘结果（不对称）完全相同。此外，我在这里取了 100 个解决方案的平均值（因为估计值是随机变量）。]]></description>
      <guid>https://stats.stackexchange.com/questions/659430/how-can-i-estimate-the-rotation-between-two-cooordinate-frames</guid>
      <pubDate>Wed, 01 Jan 2025 22:27:53 GMT</pubDate>
    </item>
    </channel>
</rss>