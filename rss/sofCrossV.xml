<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 15 Jun 2024 15:15:28 GMT</lastBuildDate>
    <item>
      <title>最小化 $KL(q_\theta|p)$ 而不是 $KL(p|q_\theta)$ 的理论依据是什么？</title>
      <link>https://stats.stackexchange.com/questions/649292/theoretical-justification-for-minimizing-klq-thetap-rather-than-klpq-t</link>
      <description><![CDATA[假设我们有一个真实但未知的分布$p$，分布在某个离散集上（即假设没有结构或领域知识），以及一个参数化的分布族$q_\theta$。
总的来说，我认为最小化$KL(p|q)$是有意义的。这表示当我们弄清楚真实分布是 $p$ 而不是 $q$ 时，我们获得的惊讶或信息量。
如果我们最小化 $KL(q|p)$，那么我们通常会做出过度自信的估计：我们原则上可以为根据 $p$ 很可能发生的事件分配零概率。
然而，在各种实际应用中（例如变分贝叶斯），我们最小化 $KL(q|p)$，我通常看到的理由是这更容易计算。
但是，是否有更原则的理论理由来最小化 $KL(q|p)$？ class=&quot;math-container&quot;&gt;$KL(q|p)$ 而不是 $KL(p|q)$? 如果我们真的对 $\text{argmin} KL(p|q)$ 感兴趣，那么即使假设它实际上不可计算，为什么我们要特别选择 $\text{argmin} KL(q|p)$？例如，如果后者只是一个估计量，那么是否有一些更好的估计量不具有 $\text{argmin} KL(q|p)$ 的过度自信属性？]]></description>
      <guid>https://stats.stackexchange.com/questions/649292/theoretical-justification-for-minimizing-klq-thetap-rather-than-klpq-t</guid>
      <pubDate>Sat, 15 Jun 2024 14:35:35 GMT</pubDate>
    </item>
    <item>
      <title>我是否使用了正确的方法来建模零膨胀数据？</title>
      <link>https://stats.stackexchange.com/questions/649291/am-i-using-the-right-method-to-model-my-zero-inflated-data</link>
      <description><![CDATA[我有一个工作场所许可证数据集，样本量 n=3000。数据是在 2012-2020 年之间收集的，因此如果许可证在 2012-2020 年之间的某个时间有效，我会将其纳入我的分析中。我感兴趣的是行业（例如营利性、公共、学术），我的结果是工作场所事件。我想测试行业和工作场所事件之间是否存在关联。我将工作场所事件视为计数，因此每个许可证的结果都是其有效期内的事件数量。由于我的数据中观察到的变量有限，我只能包含一些协变量，例如许可证有效的时间跨度、许可证的风险级别。
我担心以下几点：

零过多（大多数许可证没有工作场所
事件）
工作场所不独立（因为一个机构可以持有
多个许可证，对应多个工作场所）
我想通过汇总年份按时间段分层（例如，第 1 期：2012-2014 年，第 2 期：2015-2017 年等）
我有异常值（例如，我的结果范围是 0 到 30），我认为这些异常值可能会影响我的模型，但我犹豫是否要删除它们。

为了解决零过多的问题，我比较了零膨胀泊松和零膨胀负二项回归（基于 AIC 和 BIC）来选择最佳拟合模型。但在模型比较期间没有进行分层。我在选择最佳模型后对数据进行了分层。
我不知道如何处理非独立性。我不想按机构聚类或将其视为随机效应，因为我的兴趣暴露是基于机构定义的，因此同一机构内许可证之间的部门没有差异。我正在考虑使用聚类标准错误来处理这个问题。
我不知道到目前为止我所做的是否正确。我的方法是正确的还是完全不适合我的数据？如果有更好的方法来处理这个问题，请告诉我，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649291/am-i-using-the-right-method-to-model-my-zero-inflated-data</guid>
      <pubDate>Sat, 15 Jun 2024 13:48:31 GMT</pubDate>
    </item>
    <item>
      <title>多状态生存分析由不同事件触发的状态之间的转换</title>
      <link>https://stats.stackexchange.com/questions/649289/multi-state-survival-analysis-transition-between-states-triggered-by-different-e</link>
      <description><![CDATA[我有一个用于多状态生存分析的状态图，在 2 个特定状态之间，我有两种类型的转换，它们由不同类型的事件触发，即从状态 1 到状态 2，转换可以由 2 个不同的事件触发。如何在多状态生存分析中解释这些转换？我应该将事件类型添加为 Cox 回归的协变量吗？还是我应该为由不同事件触发的 2 个转换拟合一个单独的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/649289/multi-state-survival-analysis-transition-between-states-triggered-by-different-e</guid>
      <pubDate>Sat, 15 Jun 2024 13:32:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 lme4 的 bootMer 并行化不起作用？</title>
      <link>https://stats.stackexchange.com/questions/649288/parallelization-with-bootmer-from-lme4-not-working</link>
      <description><![CDATA[下面是我使用 lme4 包中的 bootMer 执行引导的 R 代码：
library(lme4); library(snow)
d &lt;- read.table(...)
m &lt;- lmer(..., d)
extract_stuff &lt;- function(model) {...}
nc &lt;- 12
cl &lt;- makeCluster(nc, type = &quot;SOCK&quot;)
clusterEvalQ(cl,library(&quot;lme4&quot;))
clusterExport(cl, list = c(&quot;d&quot;))
boot_results &lt;- bootMer(m, FUN = extract_stuff, use.u=T, nsim = 1000,
type = &quot;parametric&quot;, parallel=&quot;snow&quot;, ncpus=nc, cl=cl)
stopCluster(cl)

奇怪的是，无论我指定多少个 CPU，甚至我根本没有指定，运行时间都保持不变。我可能遗漏了什么？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649288/parallelization-with-bootmer-from-lme4-not-working</guid>
      <pubDate>Sat, 15 Jun 2024 12:37:46 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么分布来预测三种可能的结果</title>
      <link>https://stats.stackexchange.com/questions/649282/what-distribution-should-i-use-to-predict-three-possible-outcomes</link>
      <description><![CDATA[我今年 70 岁，14 岁辍学，但几年前开始学习数学以预防痴呆症，所以请原谅我的问题很幼稚。
我一直在使用泊松分布来解决我的问题，但我认为它不太合适。
三种结果，比如抛硬币。可以正面/反面/侧面落地。但事件是不平衡的，比如说边缘有一部分是平的，或者正面稍重。这些不平衡的属性永远不会改变，而且它们是已知的。所以，如果我抛硬币 100 次，这个事件正面/反面/侧面的概率是多少。那么你会推荐我使用什么模型。感谢您阅读并花时间。问候 Simon]]></description>
      <guid>https://stats.stackexchange.com/questions/649282/what-distribution-should-i-use-to-predict-three-possible-outcomes</guid>
      <pubDate>Sat, 15 Jun 2024 09:13:03 GMT</pubDate>
    </item>
    <item>
      <title>标准化为 t 分布之前的样本均值分布名称 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649281/name-for-distribution-of-sample-mean-before-standardization-to-t-distribution</link>
      <description><![CDATA[我正在重新学习一个非常基本的统计学知识，即均值的标准误差。根据中心极限定理，当总体方差已知时，样本均值的分布为正态分布。另一方面，当总体方差未知时，我们可以根据无偏方差估计样本均值的分布。无偏方差的平方根称为（无偏）标准误差。基于无偏方差的样本均值的分布标准化后，分布为 t 分布。
我们可以在各种教科书中找到这种解释。但是，在标准化为 t 分布之前，基于无偏方差的样本均值的分布有什么名字吗？我找到了一个术语“位置尺度系列”，但我不确定这是否是合适的术语。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/649281/name-for-distribution-of-sample-mean-before-standardization-to-t-distribution</guid>
      <pubDate>Sat, 15 Jun 2024 06:22:05 GMT</pubDate>
    </item>
    <item>
      <title>双因素试验的多重比较及解释</title>
      <link>https://stats.stackexchange.com/questions/649280/multiple-comparisons-and-explanation-of-two-factor-experiment</link>
      <description><![CDATA[我正在研究温度和种质对 R 植物性状的影响。
温度：25/20、30/25、35/30
种质：V9、BTx623、2-16-6、1-10-4、2-16-6、19-22-12
相互作用和温度与种质均显著。
这是我的代码和输出：
lm.hd = lm(HD~Temperature+Accession+Accession*Temperature, data = df1)
summary(lm.hd, digits = 2)

系数：
Temperature30/25:Accession19-22-12 -14.4667 5.1797 -2.793 0.00710 ** 
Temperature35/30:Accession19-22-12 -26.1500 5.7496 -4.548 2.88e-05 ***
Temperature30/25:Accession2-16-6 -0.5167 4.8452 -0.107 0.91545 
Temperature35/30:Accession2-16-6 -4.9500 5.7496 -0.861 0.39288 
Temperature30/25:Accession6-13-19 -4.5167 5.3167 -0.850 0.39914 

25/20:1-10-4,30/25:1-10-4,35/30:1-10-4,1-10-4,25/20...这些是没有效果的，因为它的效果是效果参考点，所以它们都是0。但是当我想做多重比较的时候我发现这些参考点是比较的：
model&lt;-aov(HD~Temperature+Accession+Accession*Temperature, data = df1)
hsd = TukeyHSD(model, conf.level=.95)
$`Temperature:Accession`
diff lwr upr p adj
30/25:1-10-4-25/20:1-10-4 -5.4000000 -17.78670947 6.9867095 0.9771241
35/30:1-10-4-25/20:1-10-4 3.2000000 -13.18607642 19.5860764 0.9999992
25/20：19-22-12-25/20：1-10-4 5.4000000 -6.98670947 17.7867095 0.9771241
30/25：19-22-12-25/20：1-10-4 -14.4666667 -28.76960677 -0.1637266 0.0446504
35/30：19-22-12-25/20：1-10-4 -17.5500000 -30.68808940 -4.4119106 0.0011157
25/20：2-16-6-25/20：1-10-4 10.9500000 -2.18808940 24.0880894 0.2144087
30/25:2-16-6-25/20:1-10-4 5.0333333 -6.82603809 16.8927048 0.9822835
35/30:2-16-6-25/20:1-10-4 9.2000000 -3.18670947 21.5867095 0.3952535
**25/20:6-13-19-25/20:1-10-4 18.8666667 4.56372657 33.1696068 0.0013738**
30/25：6-13-19-25/20：1-10-4 8.9500000 -4.18808940 22.0880894 0.5481008
35/30：6-13-19-25/20：1-10-4 8.2000000 -4.18670947 20.5867095 0.5976845
25/20：BTx623-25/20：1-10-4 27.4000000 15.01329053 39.7867095 0.0000000
30/25：BTx623-25/20：1-10-4 15.8666667 1.56372657 30.1696068 0.0160463
35/30:BTx623-25/20:1-10-4 21.7000000 5.31392358 38.0860764 0.0012876
25/20:V9-25/20:1-10-4 -1.9666667 -13.82603809 9.8927048 0.9999999

** 是我真正困惑的地方。还有，有没有合适的方法来展示这些效果和比较结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/649280/multiple-comparisons-and-explanation-of-two-factor-experiment</guid>
      <pubDate>Sat, 15 Jun 2024 06:19:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Kaiming/He 权重初始化不寻求前向和后向传递的 50/50 折衷？</title>
      <link>https://stats.stackexchange.com/questions/649279/why-doesnt-kaiming-he-weight-initialization-seek-a-50-50-compromise-for-forward</link>
      <description><![CDATA[抱歉，如果我错了请告诉我，但似乎 He 初始化旨在通过前向传递或后向传递保持恒定方差。
似乎这个想法是，对于具有权重 $W$（平均值为 0）的特定神经元，对于仅经过 Relu（如果是前向传递）或仅被 Relu 导数点缀（如果是后向传递）的传入值 $Y$，我们应用权重 $W$ 来获得 $Y&#39;=W \cdot Y$。这可以被视为 #$W$ 随机变量 $w_iy_i$，因此由于 $W \cdot Y$ 的均值为 0，并且使用 relu 的方差属性， $Var(Y&#39;)=Var(W\cdot Y)=$ #$W 
\cdot Var(W) \cdot \mathbb{E}[Y^2]=$ #$W \cdot Var(W) \cdot \frac{1}{2} Var[Y_{previous}]$，因此我们通过选择来维持 $Var(Y&#39;)=1$ $Var(W)=\frac{2}{\#W}$（并假设 $Var(Y_{previous})=1$）。在这里，我将 #$W$ 视为结构化事物的大小，该事物与值相对应并产生单个标量，例如 MLP 中前向/后向传递的输入/输出大小以及 CNN 中前向/后向的整个张量输入大小/输出大小。
我可能错了，但似乎使用 fan_in 不会为后向传递保持恒定的方差。例如，在使用 fan_in 的 MLP 中，（我认为）前向方差保持为常数。如果我们将连续输入标记为 $Y_{1}\dots Y_{n}$，将最终输出标记为 $O$，并使用误差函数（如 MSE），则第一层梯度为 $\frac{2(O_{i}-C_{i})}{\#O}$，其中 $C$ 是正确的输出，如果将它们视为具有与之前相同的方差（因为减法保留了方差）但经过缩放的独立随机变量，那么我们似乎可以用同样的想法倒退。
但直到第 $k$ 层，初始方差现在似乎积累了因子 $\frac{\#O}{\#Y_n}\cdot\frac{\#Y_{n}}{\#Y_{n-1}}\cdots\frac{\#Y_{k+1}}{\#Y_{k}}=\frac{\#O}{\#Y_k}$。由于初始化似乎通常使用 fan_in，是否希望或有意让 $k$ 层上的梯度方差在更新期间与 $\frac{1}{\#Y_k}$ 成比例？如果这是正确的，我们难道不希望方差为 1 或常数吗？看起来前向和后向传递之间的折衷可能会导致与 Xavier 相同的方差初始化，（我相信）$\frac{2}{\text{fan_in}+\text{fan_out}}$？我可能犯了多个错误或遗漏了一些东西。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/649279/why-doesnt-kaiming-he-weight-initialization-seek-a-50-50-compromise-for-forward</guid>
      <pubDate>Sat, 15 Jun 2024 05:53:05 GMT</pubDate>
    </item>
    <item>
      <title>当两个暴露变量的模型相同时，如何解释估计值？</title>
      <link>https://stats.stackexchange.com/questions/649255/how-do-you-interpret-estimates-when-the-model-is-the-same-for-two-exposure-varia</link>
      <description><![CDATA[我想研究两个环境变量$X_1$和$X_2$对数量$Y$的直接影响。$X_1$和$X_2$相互关联，并且与另外两个环境变量$X_3$和$X_4$（也已测量）相互关联。我构建了一个 DAG，其中包括我能想到的 $X_i$ 之间所有相关且合理的因果关系，以选择估计 $X_1$ 和 $X_2$ 的影响所需的调整集（见下图）。

我的问题是，ggdag 建议的用于估计 X1 和 X2 的直接影响的调整集会产生相同的模型。对于 X1，我需要调整 {X2、X3 和 X4}，对于 X2，我需要调整 {X1、X3 和 X4}。在这两种情况下，我的模型如下所示：$ Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_4$。对于 $\beta_1$ 和 $\beta_2$ 的可解释性，这是什么意思？]]></description>
      <guid>https://stats.stackexchange.com/questions/649255/how-do-you-interpret-estimates-when-the-model-is-the-same-for-two-exposure-varia</guid>
      <pubDate>Fri, 14 Jun 2024 16:09:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 mgcv gam 进行物种分布建模中的可疑诊断</title>
      <link>https://stats.stackexchange.com/questions/649236/dubious-diagnostics-in-species-distribution-modeling-with-mgcv-gam</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/649236/dubious-diagnostics-in-species-distribution-modeling-with-mgcv-gam</guid>
      <pubDate>Fri, 14 Jun 2024 11:41:31 GMT</pubDate>
    </item>
    <item>
      <title>拟合旋转 S 形曲线的良好起始模型是什么？</title>
      <link>https://stats.stackexchange.com/questions/649261/what-is-a-good-starting-model-for-fitting-a-rotated-sigmoidal-curve</link>
      <description><![CDATA[我试图在 R 中建立一个模型来拟合旋转的 S 形曲线，但在寻找适合该模型的方程时不知道从哪里开始。
下面显示了一些示例数据和我目前得到的拟合类型：
library(tidyverse)
#示例数据
df &lt;- data.frame(x = c(50,54,56,55,58,64,91,148,345,722,1641,4320,4931,5224), y = c(1,2,4,8,16,32,64,128,256,512,1024,2048,4096,8192))

# 4 阶多项式拟合
model1 &lt;- lm(y ~ poly(x,4, raw = TRUE), data = df)
# 逆对数非线性模型？
model2 &lt;- nls(y ~ I(1 / x * a) + b * x, data = df, start = list(a = 1, b = 1))

# 为 x 制作一些均匀分布的点并拟合模型
model_df &lt;- data.frame(logx = seq(1.7, 3.7, by=0.01)) %&gt;% mutate(x = 10^logx)
model_df$fit1 &lt;- predict(model1, model_df) 
model_df$fit2 &lt;- predict(model2, model_df) 

# 在对数轴上绘图
ggplot(df) +
aes(x = x, y = y) +
geom_point(size = 4) +
geom_point(data = model_df, aes(x = x, y = fit1), colour = &quot;red&quot;, size = 1) +
geom_point(data = model_df, aes(x = x, y = fit2), colour = &quot;blue&quot;, size = 1) +
scale_x_log10() +
scale_y_log10() 



有人知道任何合适的方法来拟合这样的曲线吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649261/what-is-a-good-starting-model-for-fitting-a-rotated-sigmoidal-curve</guid>
      <pubDate>Fri, 14 Jun 2024 09:12:29 GMT</pubDate>
    </item>
    <item>
      <title>在不了解被标记人员的情况下重新捕获标记</title>
      <link>https://stats.stackexchange.com/questions/649219/mark-recapture-with-no-knowledge-of-marked-individuals</link>
      <description><![CDATA[我是一名数学系学生，与一群野外生物学家一起工作。在对同一群体进行标记-重新捕获的多次实验中，他们声称，如果观察次数（重新捕获次数）足够大，则可以仅基于样本推断出群体大小（$N$）和比例（$p=K/N$），而无需事先了解最初标记的个体数量（$K$）。
考虑到从群体中抽取一个大小为 $n$ 的样本，其中有 $k$ 个标记个体，使用刀切法子样本创建观察到的比例直方图。然后使用最小平方将超几何分布拟合到直方图。这导致了一对估计参数$\hat{p}$和$\hat{N}$。
我确信，在$K$未知的假设下，该估计量收敛到样本大小（$n$），即$\hat{N} \rightarrow n$（或至少收敛到不同于$N$的值）。但是，我还没有证明这一点。
他们用模拟数据测试了这个估计量。我的结论是，在模拟中，$\hat{N}$ 的标准偏差足够大，因此 $N$ 和 $\hat{N}$ 的值有时会重合。
我提出这个问题是为了验证我是否正确。另外，我不太擅长解释自己，需要提出一个论点来说服非专业人士 $\hat{N} \rightarrow n$。感谢大家的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/649219/mark-recapture-with-no-knowledge-of-marked-individuals</guid>
      <pubDate>Fri, 14 Jun 2024 05:04:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的 lme4 进行回归建模</title>
      <link>https://stats.stackexchange.com/questions/649182/regression-modelling-using-lme4-in-r</link>
      <description><![CDATA[我拥有一种沙漠瞪羚在不同季节的 GPS 项圈数据，并希望使用 R 中的 lme4 包模拟天气模式的季节性变化对其运动模式（例如每日移动距离）的影响。
由于有些个体早逝，因此每个个体的数据量都不同。例如，一个个体可能有 90 天的数据，而另一个个体有 450 天的数据。范围是 11 到 459 天。项圈每小时进行一次 GPS 定位，因此每天最多有 24 个位置，但有时项圈可能会发生故障，可能会丢失一些位置。我还有来自每个 GPS 位置和每个时间的项圈温度数据。
我计算了每个个体每天的最高、最低和平均温度以及每天移动的平均距离。我想使用 lme4 中的回归模型模拟温度对动物日常运动模式的影响
#我的数据结构如下所示：
str(data)
# tibble [16,641 × 8] (S3: tbl_df/tbl/data.frame)
# $ COLLARID : chr [1:16641] &quot;IRI2016-4471&quot; &quot;IRI2016-4471&quot; ...
# $ SEX : chr [1:16641] &quot;Male&quot; &quot;Male&quot; &quot;Male&quot; &quot;Male&quot; ...
# $ ZONE : chr [1:16641] &quot;H&quot; &quot;H&quot; &quot;H&quot; &quot;H&quot; ...
# $ DATE : Date[1:16641]，格式：“2023-03-11” ...
# $ TEMP.MAX : 数字 [1:16641] 29.7 25.2 26.9 29.4 25.4 32.2 26.1 18.8 ...
# $ TEMP.MIN : 数字 [1:16641] 10 13 16.4 13 16.5 12.9 15.3 11.2 15.7 ...
# $ TEMP.MEAN : 数字 [1:16641] 22.7 19.5 21.6 24.3 20.7 ...
# $ TOTAL_DIST: 数字 [1:16641] 6408 10999 11604 10785 11781 ...

# 我使用以下代码对数据运行混合效应模型，其中最高温度作为固定效应，项圈 ID（即单个动物）作为随机效应：

model1 &lt;- lmer(TOTAL_DIST ~ TEMP.MAX + (1 | COLLARID), data = dat.sg)

# 模型摘要：

summary(model1)

# REML [&#39;lmerMod&#39;] 拟合的线性混合模型
# 公式：TOTAL_DIST ~ TEMP.MAX + (1 | COLLARID)
# 数据：dat.sg
#
# 收敛时的 REML 标准：338556
#
# 缩放残差：
# 最小 1Q 中位数 3Q 最大值
#-2.3846 -0.6187 -0.1946 0.3689 17.0222
#
# 随机效果：
# 组名称 方差 标准差
# COLLARID（截距） 6471327 2544
# 残差 39528228 6287
# 观察数：16641，组：COLLARID，86
#
# 固定效果：
# 估计标准误差 t 值
#（截距） 9268.979 367.720 25.207
# TEMP.MAX 25.951 6.788 3.823
#
# 固定效果相关性：
#（截距）
# TEMP.MAX -0.625

残差看起来真的很大。。以上是否是模拟季节间温度变化对瞪羚运动模式的影响的正确方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/649182/regression-modelling-using-lme4-in-r</guid>
      <pubDate>Thu, 13 Jun 2024 06:42:08 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归给出了重复 ID 变量上的多个预测变量</title>
      <link>https://stats.stackexchange.com/questions/649124/poisson-regression-given-multiple-predictors-on-a-repeating-id-variable</link>
      <description><![CDATA[我想知道，对于我的数据集，泊松回归将如何工作，该数据集描述了一系列按年龄组、性别和死亡人数分层的邮政编码。
回归将使用死亡人数作为因变量，邮政编码、年龄组和性别作为预测因子。
问题是每个相同的邮政编码有多行，我不确定如何在泊松回归模型中解释这一点。我必须重新排列数据集吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/649124/poisson-regression-given-multiple-predictors-on-a-repeating-id-variable</guid>
      <pubDate>Wed, 12 Jun 2024 18:57:48 GMT</pubDate>
    </item>
    <item>
      <title>找到 $\theta$ 的二维充分统计量</title>
      <link>https://stats.stackexchange.com/questions/643275/find-a-two-dimensional-sufficient-statistic-for-theta</link>
      <description><![CDATA[假设$\theta$服从分布，则令$\{X_i\}_{i=1}^n$为条件独立
$$p_{X_i | \theta} (x |\theta) = \frac{1}{2i\theta}, \ -i\theta&lt;x&lt;i\theta.$$
为$\theta.$找到一个二维充分统计量
尝试使用因式分解定理求解：
$$p_{X | \theta} = \prod_{i=1}^{n}\frac{1}{2i\theta}1_{x_i &gt; -i\theta} 1_{x_i &lt; i\theta} = \frac{1}{(2i\theta)^n} 1_{\min(x_i) &gt; -i\theta} 1_{\max(x_i) &lt; i\theta}$$
因此我们可以选择 $T(x) = \big(T_1(x), T_2(x)\big) = \big(\min(x_i), \max(x_i)\big) $ 和 $g\big(\theta, T_1(x), T_2(x)\big) = \frac{1}{(2i\theta)^n} 1_{T_1 &gt; -i\theta} 1_{T_2 &lt; i\theta}$。
根据因式分解定理，$T(x)$ 应该是一个充分的二维统计量，对吗？
关于充分统计量的维度，我们总是可以稍微增加维度，例如说 $T_n(x) = 1$ 并乘以它？另一方面，我们不能将维度降低到某个点吗？在这个例子中，二维统计量是我们能达到的最低值吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/643275/find-a-two-dimensional-sufficient-statistic-for-theta</guid>
      <pubDate>Fri, 22 Mar 2024 16:56:42 GMT</pubDate>
    </item>
    </channel>
</rss>