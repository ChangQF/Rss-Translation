<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 11 Feb 2025 09:23:30 GMT</lastBuildDate>
    <item>
      <title>具有不确定性的泊松过程的中值预期上限</title>
      <link>https://stats.stackexchange.com/questions/661210/median-expected-upper-limit-for-a-poisson-process-with-uncertainties</link>
      <description><![CDATA[考虑在存在不确定的背景速率$b$的情况下确定过程信号速率$s$的上限的问题。背景速率受到另一个测量的限制，其中观察到$b_{obs}$个事件。然后，观察到$n_{obs}$个事件的总可能性由以下公式给出：
$$
L(s,b| n_{obs}, b_{obs}) = Pois(n_{obs}| s+b) \times Pois(b_{obs} | b)
$$
这里感兴趣的参数是$s$。我知道如何建立置信区间，或者对于这个问题更重要的是，使用各种频率学派技术和玩具蒙特卡罗实验来提取上限。现在我所苦苦挣扎的是如何计算“预期”中位数上限。几篇文章（我稍后会添加参考资料）只是说，应该在背景假设中执行“玩具 MC 实验”，将它们视为数据，然后从那里构建上限的分布。如何生成玩具？具体来说，$b$ 使用什么值？
任何帮助都将非常有帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/661210/median-expected-upper-limit-for-a-poisson-process-with-uncertainties</guid>
      <pubDate>Tue, 11 Feb 2025 05:56:06 GMT</pubDate>
    </item>
    <item>
      <title>通过模拟进行对数秩检验的功效</title>
      <link>https://stats.stackexchange.com/questions/661209/power-of-logrank-test-through-simulation</link>
      <description><![CDATA[对数秩检验样本量公式由 Lachin 和 Foulkes (1986) 制定，题为“评估样本量和生存分析的功效，同时考虑患者入组不均匀、失访、不依从和分层”。我正在运行一个玩具模拟来查看公式的准确性。按照论文的符号，患者在 R 年的累积期内被招募，并被跟踪到研究结束 T 年。假设 R = 3、T =5、指数生存、均匀累积，并且在研究结束前没有其他审查，geDesign 包中的 nSurvival 函数使用 Lachin 和 Foulkes (1986) 方法，并给出样本量 = 368 以达到 90% 的功效：
# 事件发生时间样本量计算 (Lachin-Foulkes)
library(gsDesign)

ss &lt;- nSurvival(
lambda1 = .3, lambda2 = .2, eta = 0, Ts = 5, Tr =3,
sided = 1, alpha = .05
)
ss

以下是我用来验证此方法的模拟代码：
n &lt;- 368
followup &lt;- 2
eff &lt;- 0
Nsim &lt;- 20000
level &lt;- 0.05
lamda1 &lt;- .2
lamda0 &lt;- .3
p &lt;- 1/2
R &lt;- 3

for (i in 1:Nsim){
trt &lt;- rbinom(n,1,p)

cumentrytime &lt;- runif(n,0,R) #统一累积
censorT &lt;- R + followup #研究结束 T =5

T1 &lt;- rexp(n,lamda1) #指数生存
T0 &lt;- rexp(n,lamda0)
T &lt;- T1
T[trt==0] &lt;- T0[trt==0]

statustrue &lt;- (T+cumentrytime &lt; censorT) #如果事件时间在结束之前，则 status = 1研究
T[statustrue==0] &lt;- censorT-cumentrytime[statustrue==0] # 审查对象的曝光时间

logrank_testfinal &lt;- survdiff(Surv(T, statustrue) ~ trt)
pvaluefinal &lt;- pchisq(logrank_testfinal$chisq, length(logrank_testfinal$n)-1, lower.tail = 
FALSE)
if (pvaluefinal &lt; level ) eff &lt;- eff+1 
}

eff/Nsim

结果功效约为 83%。模拟和公式之间 7% 的功效差异是否在预期范围内（假设我的模拟进行了公平比较）？如果不是，是否有其他样本量计算公式可以给出与模拟更一致的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/661209/power-of-logrank-test-through-simulation</guid>
      <pubDate>Tue, 11 Feb 2025 03:26:49 GMT</pubDate>
    </item>
    <item>
      <title>建立人们如何谎报身高的统计模型</title>
      <link>https://stats.stackexchange.com/questions/661204/making-a-statistical-model-for-how-people-lie-about-their-heights</link>
      <description><![CDATA[这是我在北美生活时注意到的关于身高的一些社会趋势：

当人们自我声明身高时，错误可以分为两部分：有意识的错误（即故意报告错误的身高）和无意识的错误（即不小心报告错误的身高）
在许多文化中，人们认为男性身高较高是更好的选择。因此，男性可能更有可能自报比实际身高更高的身高。
一般来说，身高较高的男性（即超过一定身高）可能通过自报比实际身高更高的身高而一无所获。
老年人可能更认为虚报身高对他们的益处较小，因此可能更诚实
我不知道女性是否有类似的理由

假设现在我有一个数据集，其中包含个人的年龄、性别和自报身高（每人 1 行）。 我想建立一个统计模型，尝试纠正自我报告的身高偏差（使用贝叶斯技术），但我不知道如何开始。
我尝试编写基础知识：

$h_i^r$ = 报告身高
$h_i^t$ = 真实身高（未观察到）
$a_i$ = 年龄
$g_i$ = 性别（0 = 女性，1 = 男性）
$b_i$ 表示人员的报告偏差$i$。

基本模型现在变成：
$$h_i^r = h_i^t + b_i$$
$$b_i = \beta_0 + \beta_1g_i + \beta_2a_i + \beta_3(h_i^t - \mu_h)g_i + \epsilon_i$$
但我不确定如何将我对自我报告身高偏见的先入为主的观念转化为贝叶斯先验。此外，我不确定如何以有意义的方式定义联合先验。
有人可以告诉我怎么做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661204/making-a-statistical-model-for-how-people-lie-about-their-heights</guid>
      <pubDate>Mon, 10 Feb 2025 22:51:09 GMT</pubDate>
    </item>
    <item>
      <title>偏回归系数线性模型中的缩放坐标（纬度和经度）</title>
      <link>https://stats.stackexchange.com/questions/661202/scaling-coordinates-latitude-and-longitude-in-a-linear-model-for-partial-regre</link>
      <description><![CDATA[我有一个数据集，我想比较一下偏回归系数。我在多个地方都读到，预测变量应该是均值中心化的，并按 1 个标准差缩放，以便于实现这一点，特别是当变量的尺度相差很大时。但是，我的一个预测变量恰好是经度。一般示例：
响应变量 ~ 中心化和缩放变量 1 + 中心化和缩放变量 2 + 经度 + 
中心化和缩放变量 1：中心化和缩放变量 2 + 
中心化和缩放变量 1：经度 + 
中心化和缩放变量 2：经度)

似乎惯例是将所有变量中心化/缩放或不缩放，但这让我想知道缩放和中心化对于纬度和经度是否必要且合适。我偶然发现了这篇 StackOverflow 帖子，似乎暗示答案可能是“否”因为它扭曲了坐标的含义：
（https://stackoverflow.com/questions/48426533/variation-partitioning-using-latitude-and-longitude-as-explanatory-variables）
但是，如果我主要对系数感兴趣，我不太明白在多元线性回归的背景下，缩放和居中纬度/经度是否不合适？
感谢您对此的任何想法！]]></description>
      <guid>https://stats.stackexchange.com/questions/661202/scaling-coordinates-latitude-and-longitude-in-a-linear-model-for-partial-regre</guid>
      <pubDate>Mon, 10 Feb 2025 22:44:18 GMT</pubDate>
    </item>
    <item>
      <title>根据生存函数的对数直观地了解风险函数</title>
      <link>https://stats.stackexchange.com/questions/661201/intuition-for-hazard-function-in-terms-of-logarithm-of-survival-function</link>
      <description><![CDATA[此帖子有助于解释风险函数的直觉。其中，风险函数被解释为
$$h(t) = - \frac{f(t)}{S(t)},$$
其中 $f(t)$ 是 PDF，$S(t)$ 是生存函数。这导致了身份
$$h(t) = -\frac{d}{dt} \log (S(t)). $$
从中获得任何直觉吗？风险函数是假设患者存活到时间 t，则在时间 t 时的瞬时死亡率。令我惊讶的是，它不知何故等于生存函数对数变换的变化率。]]></description>
      <guid>https://stats.stackexchange.com/questions/661201/intuition-for-hazard-function-in-terms-of-logarithm-of-survival-function</guid>
      <pubDate>Mon, 10 Feb 2025 22:12:18 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯统计，100 页的机器学习书籍</title>
      <link>https://stats.stackexchange.com/questions/661200/bayesian-statistics-the-100-page-machine-learning-book</link>
      <description><![CDATA[我对“Andriy Burkov 所著的 100 页机器学习书籍”一书中的贝叶斯统计有疑问。该问题与贝叶斯统计有关。我有一张书中的截图，其中包含相关信息。这本书可以在这里免费找到：http://themlbook.com/wiki/doku.php

关于红线：
为什么他要用$\frac{1}{N}P(\theta=\hat{\theta}|X=x)$来代替$P(\theta=\hat{\theta})$？他在这里的意思是什么？我不明白的是：当您计算出$P(\theta=\hat{\theta}|X=x_1)$时，对于$x_1$，您只有$P(\theta=\hat{\theta}|X=x)$，而没有其他的？那么，如何将所有 $x&#39;s$ 相加，得到 $\frac{1}{N}P(\theta=\hat{\theta}|X=x)$？
我看了另一本书，他们是这样做的：计算 $P(\theta=\hat{\theta}|x_1)$，然后他们用这个值计算 $P(\theta=\hat{\theta}|x_1, x_2)$，然后他们用这个值计算 $P(\theta=\hat{\theta}|x_1,x_2,x_3)$。这是他做的，但是用其他符号表示吗？我不明白他平均了什么？
关于绿色框：
表达式会与 $\text{arg max}_\theta P(\theta=\hat{\theta}|x_1,x_2,x_3,\ldots,x_N)$ 相同吗？如果不是，这不是更自然的表达式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661200/bayesian-statistics-the-100-page-machine-learning-book</guid>
      <pubDate>Mon, 10 Feb 2025 22:04:55 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证和保留集</title>
      <link>https://stats.stackexchange.com/questions/661198/the-use-of-cross-validation-and-a-hold-out-set</link>
      <description><![CDATA[我一直在考虑交叉验证和保留集的使用，但我真的不明白随机选择的保留测试集有什么用处。不过，我不得不说，当保留集不是随机进行的，而是用于评估特殊特征（如过时的样本）时，我完全明白它的目的。
我的观点是，当我使用交叉验证进行建模决策时，我已经解决了过度拟合问题，尽管由于使用所有数据，它可能会对数据集产生一些偏差，但我将通过不刻意减少训练数据来获得预测能力。
尽管如此，我到处都看到每个人都随机将测试集与训练数据分开。不分离随机测试集并使用：是否不可接受：

用于 EDA 的整个数据集
用于变量选择的交叉验证
用于模型选择和超参数优化的嵌套交叉验证
通过重复交叉验证估计最终模型的误差
使用整个数据集对模型进行训练，将其投入生产。
]]></description>
      <guid>https://stats.stackexchange.com/questions/661198/the-use-of-cross-validation-and-a-hold-out-set</guid>
      <pubDate>Mon, 10 Feb 2025 21:29:23 GMT</pubDate>
    </item>
    <item>
      <title>您是否知道应用 t-SNE 时具有这种行为的任何数据集？</title>
      <link>https://stats.stackexchange.com/questions/661194/do-you-know-of-any-dataset-with-this-behavior-when-applying-t-sne</link>
      <description><![CDATA[
我正在寻找一个在应用 t-SNE 时表现出这种行为的数据集。t-SNE 是一种降维算法，有时可以分离原本属于同一簇的数据点。
在本文的图 9（https://arxiv.org/abs/2009.01512）中，您可以清楚地看到这种现象。作者提出了一种保持簇完整的拓扑降维算法（TopoMap），并将其与 t-SNE 进行了比较。很明显，t-SNE 最终会将本应保留在单个群集中的点分开。
您遇到过这种现象吗？如果遇到过，您能分享数据集及其上下文吗？我正在做一个本科研究项目，非常感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/661194/do-you-know-of-any-dataset-with-this-behavior-when-applying-t-sne</guid>
      <pubDate>Mon, 10 Feb 2025 20:33:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 Hyperopt Fmin 进行 LightGBM 超参数调整</title>
      <link>https://stats.stackexchange.com/questions/661191/lightgbm-hyperparameter-tuning-using-hyperopt-fmin</link>
      <description><![CDATA[我遇到了一个多分类问题。我尝试使用 Hyperopt Fmin 来执行超参数调整。但是，我不知道应该为搜索空间使用什么合适的值，以及我应该如何解决这个问题。我是否先执行随机搜索，然后在该区域周围搜索？每个搜索空间的值应该设置为多少？我的数据集有 6000 行，我有大约 200 个变量（如果执行独热编码则为 400 个）。我的目标变量有 4 个级别
from sklearn.model_selection import RandomizedSearchCV
import numpy as np
from hyperopt import fmin, tpe, hp, STATUS_OK, Trials
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from hyperopt.pyll.base import scope

# 定义 RandomizedSearch 的参数分布
param_dist = {
&#39;num_leaves&#39;: range(20, 150),
&#39;learning_rate&#39;: np.linspace(0.01, 0.3, 10),
&#39;n_estimators&#39;: range(100, 1000, 100),
&#39;min_child_weight&#39;: np.linspace(0.01, 10, 10),
&#39;subsample&#39;: np.linspace(0.5, 1.0, 6),
&#39;colsample_bytree&#39;: np.linspace(0.5, 1.0, 6),
&#39;reg_alpha&#39;: np.linspace(0.0, 1.0, 10),
&#39;reg_lambda&#39;: np.linspace(0.0, 1.0, 10)
}

# 创建 LightGBM 分类器
model = lgb.LGBMClassifier(objective=&#39;multiclass&#39;, num_class=len(set(y)))

# 执行 RandomizedSearchCV
random_search = RandomizedSearchCV(
estimator=model,
param_distributions=param_dist,
n_iter=20, # 采样的参数设置数量
scoring=&#39;accuracy&#39;,
cv=3, # 交叉验证拆分策略
random_state=42,
n_jobs=-1 # 使用所有可用核心
)

# 拟合 RandomizedSearchCV
random_search.fit(X_train, y_train)

# 获取最佳参数
best_params = random_search.best_params_
print(&quot;使用 RandomizedSearchCV 找到的最佳超参数：&quot;, best_params)

# 定义最佳参数周围的搜索空间
search_space = {
&#39;num_leaves&#39;: scope.int(hp.quniform(&#39;num_leaves&#39;, best_params[&#39;num_leaves&#39;] - 10, best_params[&#39;num_leaves&#39;] + 10, 1)),
&#39;learning_rate&#39;: hp.uniform(&#39;learning_rate&#39;, best_params[&#39;learning_rate&#39;] * 0.8, best_params[&#39;learning_rate&#39;] * 1.2),
&#39;n_estimators&#39;：scope.int(hp.quniform(&#39;n_estimators&#39;，best_params[&#39;n_estimators&#39;] - 100，best_params[&#39;n_estimators&#39;] + 100，10))，
&#39;min_child_weight&#39;：hp.uniform(&#39;min_child_weight&#39;，best_params[&#39;min_child_weight&#39;] * 0.8，best_params[&#39;min_child_weight&#39;] * 1.2)，
&#39;subsample&#39;：hp.uniform(&#39;subsample&#39;，max(0.5，best_params[&#39;subsample&#39;] * 0.8)，min(1.0，best_params[&#39;subsample&#39;] * 1.2))，
&#39;colsample_bytree&#39;：hp.uniform(&#39;colsample_bytree&#39;，max(0.5，best_params[&#39;colsample_bytree&#39;] * 0.8)， min(1.0, best_params[&#39;colsample_bytree&#39;] * 1.2)),
&#39;reg_alpha&#39;: hp.uniform(&#39;reg_alpha&#39;, best_params[&#39;reg_alpha&#39;] * 0.8, best_params[&#39;reg_alpha&#39;] * 1.2),
&#39;reg_lambda&#39;: hp.uniform(&#39;reg_lambda&#39;, best_params[&#39;reg_lambda&#39;] * 0.8, best_params[&#39;reg_lambda&#39;] * 1.2)
}

# 定义目标函数
def objective(params):
model = lgb.LGBMClassifier(objective=&#39;multiclass&#39;, num_class=len(set(y_train)), **params)
score = cross_val_score(model, X_train, y_train, cv=3,scoring=&#39;accuracy&#39;).mean()
return {&#39;loss&#39;: -score, &#39;status&#39;: STATUS_OK}

# 运行优化
trials = Trials()
best_hyperparams = fmin(fn=objective,
space=search_space,
algo=tpe.suggest,
max_evals=50, # 根据您的需要调整评估次数
trials=trials,
rstate=np.random.default_rng(42))

print(&quot;使用 Hyperopt 找到的最佳超参数：&quot;, best_hyperparams)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/661191/lightgbm-hyperparameter-tuning-using-hyperopt-fmin</guid>
      <pubDate>Mon, 10 Feb 2025 19:47:00 GMT</pubDate>
    </item>
    <item>
      <title>这是最大似然估计的可能替代方法吗？</title>
      <link>https://stats.stackexchange.com/questions/661174/is-this-a-possible-alternative-to-maximum-likelihood-estimation</link>
      <description><![CDATA[如果问题很简单，请原谅我，因为我来自纯数学背景。直观地说，最大似然估计量是从样本计算出的统计数据，以便最大化观察到的数据的概率。在我看来，以下未知参数的估计量更自然（根据 Glivenko-Cantelli 定理）：
假设我们的模型遵循分布 $F_{\theta_0}$，它是分布系列 $\{F_{\theta}\}_{\theta\in I}$ 的成员。假设 $X_1,X_2,X_3,...$ 为 iid 分布，且服从分布 $F_{\theta_0}$ （因此 $\theta_0$ 是真实参数）。可以寻找估计量 $\hat{\theta}_n(X_1,X_2,...,X_n)$，该估计量定义为 $\theta$ 的值，使得分布 $F_{\theta}$ 最接近（即在 $L^2$ 意义上）$X_1,X_2,..,X_n$ 的经验分布。文献中是否探讨过此估计量？它是否具有合理的属性？为什么 MLE 估计量比我描述的估计量更有利？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/661174/is-this-a-possible-alternative-to-maximum-likelihood-estimation</guid>
      <pubDate>Mon, 10 Feb 2025 09:32:52 GMT</pubDate>
    </item>
    <item>
      <title>分层 Cox 模型：为什么重采样数据的 C 指数比明显的 C 指数（tidymodels 和审查的 R 包）更好？</title>
      <link>https://stats.stackexchange.com/questions/661185/stratified-cox-model-why-is-c-index-on-resampled-data-better-than-apparent-c-in</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661185/stratified-cox-model-why-is-c-index-on-resampled-data-better-than-apparent-c-in</guid>
      <pubDate>Mon, 10 Feb 2025 07:53:22 GMT</pubDate>
    </item>
    <item>
      <title>如果一个人（非）故意忽略了所有可用数据的 10％，那么最高的准确度是多少？</title>
      <link>https://stats.stackexchange.com/questions/661168/if-one-unintentionally-ignores-10-of-all-available-data-what-is-the-highest</link>
      <description><![CDATA[我不记得当时的场合了，但我相信是一位语言学家提出，如果忽略 10% 或 15% 的数据，那么从人们所关注的 85% 的数据中就永远无法得出任何有意义的结论。
从统计学的角度来看，这种情况会发生吗？还是取决于人群遵循哪种分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/661168/if-one-unintentionally-ignores-10-of-all-available-data-what-is-the-highest</guid>
      <pubDate>Mon, 10 Feb 2025 05:55:22 GMT</pubDate>
    </item>
    <item>
      <title>如何确定偏斜自举分布的平均值和 95% 置信区间</title>
      <link>https://stats.stackexchange.com/questions/661165/how-to-determine-the-mean-and-95-confidence-interval-of-a-skewed-bootstrapped-d</link>
      <description><![CDATA[我已经对我的数据进行了 1000 次（甚至 10,000 次）引导，但这种引导分布是有偏差的，因此真正的组平均值与分布的模式更一致，而不是平均值。
我如何在保持真实组平均值的同时报告平均值和 CI？我可以报告模式吗？
以下编辑以通过一个具体示例阐明我的确切方法：
我使用线性 SVM 在两个变量之间进行解码（来自 EEG 数据）。从 20 个受试者中，我获得了每个条件的解码准确度轨迹。在这里，解码准确度轨迹是每个时间点（例如，从 0 到 1000 毫秒）的准确度百分比。我的目标是测试哪种情况（A 或 B）可以更早地解码。
统计测试 1：首先，为了测试解码准确度在组级别是否高于偶然性（分别针对条件 A 和 B），我执行基于排列的簇大小推断。简而言之，我通过将每个样本解码准确度输出随机乘以 +1 或 -1 来排列样本标签，以生成零分布（设置为 50% 的概率水平）。然后，确定最早的重要时间点（即开始时间）。
统计测试 2：然后，为了测试哪种情况（A 或 B）具有更早的开始时间，我通过随机抽样替换对数据集进行了 1000 次引导。这种方法背后的原理是在两个开始时间之间进行强有力的统计比较。我不能直接使用开始时间来对两种情况之间的差异做出强有力的断言，因为它们是奇异值并且不反映底层分布。请参阅 Sassenhagen 和 Draschko，心理生理学。2019；56：e13335。
因此，我随机抽样 20 次，进行替换，执行上述定义的统计测试，并保存第一个重要时间点。重复此过程 1000 次后，我得到了一个发病时间分布（我计划从中得出平均引导发病时间和置信区间）。
但是，第二次测试中的发病时间分布不是正态分布，因此引导发病时间的平均值与基于聚类的置换测试的发病时间不匹配。我是否应该在更干净的数据中期待正态分布？如果结果是真实的，我可以报告模式 +/- CI，而不是平均值 +/- CI，以解释数据的偏斜吗？
我希望这有意义。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661165/how-to-determine-the-mean-and-95-confidence-interval-of-a-skewed-bootstrapped-d</guid>
      <pubDate>Sun, 09 Feb 2025 21:35:46 GMT</pubDate>
    </item>
    <item>
      <title>估计具有外生状态的状态空间模型</title>
      <link>https://stats.stackexchange.com/questions/661071/estimating-state-space-model-with-exogenous-states</link>
      <description><![CDATA[我正在尝试使用 R 中的 DLM 包来估计状态空间模型，其中观测和状态方程如下：
$y_t=\beta_1a_t + B_t\beta_2(\frac{u_t-v_t}{u_t}) + C_t\beta_3(\frac{u_t-v_t}{u_t}) + \epsilon_t$
$v_t = v_{t-1}+ \zeta_t$
其中 $\epsilon_t\sim N(0,\sigma_\epsilon^2)$ 和 $\zeta_t\sim N(0,\sigma_\zeta^2)$
我有$y_t, a_t, B_t, C_t, u_t$的数据（时间序列）
我想估计 beta 并找到时间序列$v_t$。
我完全不确定如何估计这个模型，我只有一个状态方程，但我不确定我的状态在这里是什么。由于必须同时估计参数$\beta$和序列$v_t$，我无法将此模型与我读过的模型联系起来。
如果在这方面有任何帮助，我将不胜感激。
我认为我需要将其表示为状态空间模型，然后应用带有卡尔曼滤波的 EM 算法来估计参数和状态变量。例如，以下代码估计 $\beta$、$\sigma_\epsilon^2$ 和 $\sigma_\zeta^2$ 以及状态 $v_t$:
library(dlm)

# 观测方程
observation_equation &lt;- function(beta, a_t, B_t, C_t, u_t, v_t) {
beta[1] * a_t + B_t * beta[2] * ((u_t - v_t) / u_t) + C_t * beta[3] * ((u_t - v_t) / u_t)
}

# 定义状态空间模型
build_dlm &lt;- function(Q, R) {
# 我认为这个 dlmModPoly 将充当 v_t = v_{t-1} + \zeta_t
dlmModPoly(order = 1, dV = R, dW = Q)
}

# def 平方误差和
objective_function &lt;- function(params, y_t, a_t, B_t, C_t, u_t, v_t) {
beta &lt;- params[1:3]
y_pred &lt;- sapply(1:length(y_t), function(t) observer_equation(beta, a_t[t], B_t[t], C_t[t], u_t[t], v_t[t]))
error &lt;- y_t - y_pred

sum(error^2)
}

# beta、Q 和的初始猜测R
beta_init &lt;- c(0.5, 0.5, 0.5)
Q_init &lt;- 0.1
R_init &lt;- 0.1
params_init &lt;- c(beta_init, Q_init, R_init)
#初始化变量
Q_estimated = Q_init
R_estimated = R_init

# EM 算法
for (iteration in 1:10) {
# E-Step：使用当前 beta、Q 和 R 估计 v_t
model &lt;- build_dlm(Q_estimated, R_estimated)
fit &lt;- dlmFilter(y_t, model) # 卡尔曼滤波器应用
v_estimated &lt;- dropFirst(fit$m) # 估计状态 v_t

# M-Step：使用估计的参数更新模型
result &lt;- optim(params_init, objective_function, y_t = y_t, a_t = a_t, B_t = B_t, C_t = C_t, u_t = u_t, v_t = v_estimated)
params_estimated &lt;- result$par
beta_estimated &lt;- params_estimated[1:3]
Q_estimated &lt;- params_estimated[4]
R_estimated &lt;- params_estimated[5]

# 更新下一次迭代的初始参数
params_init &lt;- c(beta_estimated, Q_estimated, R_estimated)
}

其中 a_t、B_t、C_t、u_t 是已知且长度相同的时间序列。
这准确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661071/estimating-state-space-model-with-exogenous-states</guid>
      <pubDate>Fri, 07 Feb 2025 01:47:16 GMT</pubDate>
    </item>
    <item>
      <title>条件与边际：概率、可能性和模型</title>
      <link>https://stats.stackexchange.com/questions/660175/conditional-vs-marginal-probability-likelihood-and-models</link>
      <description><![CDATA[我很难理清这些想法。
1) 条件概率与边际概率：这是我最了解的一个，它依赖于概率的基本定律。
如果我们有两个连续随机变量 $X$ 和 $Y$。
$X$ 的边际概率密度函数，表示为 $f_X(x)$，是通过对 $Y$ 所有可能值的联合 PDF 进行积分获得的：
$$f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) dy$$
给定 $Y=y$，$X$ 的条件概率密度函数：
$$f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}$$
$$f_{X|Y}(x|y) = \frac{f_{Y|X}(y|x)f_X(x)}{f_Y(y)}$$
到目前为止一切正常。
2) 条件似然与边际似然：这个我也理解，因为它是一个第一部分的扩展。
我可以定义一个联合似然函数$L(\theta, \phi|X)$为：
$$L(\theta, \phi|X) \propto f_X(X|\theta, \phi)$$
从这里，边际似然和条件似然可以写成：
$$L_M(\theta|X) = \int_{-\infty}^{\infty} L(\theta, \phi|X) d\phi$$
$$L_C(\theta|X,\phi) = L(\theta, \phi|X)$$
3) 条件模型与边际模型（第 1 部分） 事情开始让我感到困惑。我以前听说过“条件和边际”这两个术语用于混合效应回归模型。例如，在纵向/聚类模型的背景下，我听说过以下内容：

像 GEE（一般估计方程）这样的回归框架被称为边际模型，因为它们估计整个总体的边际平均值。虽然 GEE 能够在估计阶段使用数据中存在的聚类级相关性，但最终模型无法在聚类级别提供任何统计推断。 GEE 只能描述整个人口层面上正在发生的事情。

$$ \text{logit}(P(Y_{ij} = 1|X_{ij})) = X_{ij}\beta^* $$

另一方面，混合/随机效应等回归框架被称为条件模型，因为它们可以通过其随机效应结构在集群级别提供统计推断。举例来说，聚类级别均值可以看作是条件均值（即以聚类为条件）。

$$ \text{logit}(P(Y_{ij} = 1|X_{ij}, b_i)) = X_{ij}\beta + b_i $$
我认为在我看来这一切都是合理的。
4) 条件模型与边际模型（第 2 部分）：我感到困惑的根源来自这里：https://en.wikipedia.org/wiki/Conditional_logistic_regression。虽然我并没有完全理解这一点，但这似乎是一种固定效应回归，我们不再对估计集群级别效应感兴趣。相反，我们似乎根据某些集群级别信息集来匹配人员，以避免变量混淆。这是维基百科上关于条件逻辑回归的一个示例 - 这次我们不是估计聚类级别的影响（就像在随机影响中所做的那样），而是对它们进行匹配以控制它们的影响：
$$P(Y_{i1}=1, Y_{i2}=0|X_{i1},X_{i2}, Y_{i1}+Y_{i2}=1) = \frac{\exp(\beta^TX_{i1})}{\exp(\beta^TX_{i1}) + \exp(\beta^TX_{i2})}$$
因此，似乎在所有这些情况下，被条件化的术语及其条件化方式都会发生变化。
我说得对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660175/conditional-vs-marginal-probability-likelihood-and-models</guid>
      <pubDate>Fri, 17 Jan 2025 17:36:04 GMT</pubDate>
    </item>
    </channel>
</rss>