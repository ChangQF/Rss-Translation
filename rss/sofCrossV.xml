<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 14 Jan 2024 06:18:02 GMT</lastBuildDate>
    <item>
      <title>为什么指数族的似然函数是凸的？</title>
      <link>https://stats.stackexchange.com/questions/636815/why-are-likelihood-functions-from-exponential-family-convex</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636815/why-are-likelihood-functions-from-exponential-family-convex</guid>
      <pubDate>Sun, 14 Jan 2024 05:10:40 GMT</pubDate>
    </item>
    <item>
      <title>对均值未知的两个分布进行 A/B 测试</title>
      <link>https://stats.stackexchange.com/questions/636814/a-b-test-from-two-distributions-with-unknown-means</link>
      <description><![CDATA[我将运行一个实验来检查给定的更改是否在用户交互中具有一定的意义。我有两组，从两组中采样，一组称为 control，用于计算对照组中 30 个采样用户的交互次数，而我有 treatment，用于计算对照组中 30 个采样用户的交互次数。 30 个样本用户与测试功能的交互。它们在下面的 Python 代码中给出
将 numpy 导入为 np

控制 = np.array([1, 0, 1, 3, 2, 1, 0, 1, 3, 2, 1, 0, 1, 3, 2, 1, 0, 1, 3, 2, 1, 0 , 1, 3, 2, 1, 0, 1, 3, 2])
治疗 = np.array([0, 1, 3, 2, 1, 2, 1, 3, 2, 1, 0, 2, 3, 2, 1, 0, 2, 3, 2, 1, 0, 2 , 3, 2, 1, 0, 2, 3, 2, 4])

对于此测试，我将使用以下参数
实际重要边界：$d_{min} = 0.05$
显着性水平$\alpha = 0.05$
d_min = 0.05
阿尔法 = 0.05

我想检查平均两组之间的使用情况是否存在差异。然后我将原假设陈述为
$H_0: \mu_t == \mu_c \implies d = 0$
其中 $\mu$ 是对照组 (c) 或治疗组 (t) 和 $d 的平均值$ 差异 $d = \mu_t - \mu_c$。
mu_c = control.mean()
mu_t = 治疗.mean()
d = mu_t - mu_c

根据数据的特点，我将使用t检验进行评估。我假设两组之间的方差相同，这将为我提供以下计算来测试统计数据。
n_c = len(control) # 控制中的样本数
n_t = len(treatment) # 处理中的样本数

df = n_c - 1 + n_t - 1 # 自由度

# 对照组误差的平方和
SS_c = np.sum((控制 - mu_c)**2)

# 治疗组的误差平方和
SS_t = np.sum((治疗 - mu_t)**2)

# 合并标准误
S_pool = np.sqrt((SS_c + SS_t)/df)

# 测试 t 分布的统计量
TS = d / (S_pool * np.sqrt(1/n_c + 1/n_t))

现在我将验证测试是否证实或拒绝原假设。为此，我计算了具有 58 个自由度的 t_alpha，
导入 scipy.stats 作为统计数据

t_alpha = stats.t.ppf(1-alpha/2, df)

TS&gt; t_alpha或TS＜ -t_alpha
# 返回真

由于 TS 超出了 t_alpha 的边界，我们可以拒绝原假设。
现在我将验证结果是否实际上显着，即包括标准误差的置信区间是否与显着性区域相交。为此，我需要估计保证金误差 ($m$)，然后根据&lt;计算置信区间 span class=&quot;math-container&quot;&gt;$d \pm m$
m = t_alpha * S_pool
ci = np.array([d - m, d + m])

提醒一下，d 是两组（对照组和治疗组）平均值之间的差异。
为了可视化，我们可以构建给定的绘图。
导入 matplotlib.pyplot 作为 plt
图 = plt.figure(figsize=(10, 3))
斧头 = 图.add_subplot(111)
ax.vlines(0, -1, 1)
ax.vlines([-d_min, d_min], -1, 1, linestyles=&#39;虚线&#39;, label=“重要边界”);
ax.plot(d, 0,&#39;b.&#39;, label=“中心置信区间”);
ax.hlines(0, *ci, &#39;b&#39;, label=&quot;置信区间&quot;);
ax.set_title(“意义”);
plt.图例();


由于置信区间与显着边界（完全）重叠，甚至跨越$0$，我不能假设这个测试具有实际意义，因此我会&lt;强&gt;拒绝它。
问题是：我没想到间隔这么大。也许我只是使用了错误的边距误差公式，但它似乎是正确的。欢迎任何有助于推进此事的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/636814/a-b-test-from-two-distributions-with-unknown-means</guid>
      <pubDate>Sun, 14 Jan 2024 04:32:55 GMT</pubDate>
    </item>
    <item>
      <title>“似然性”是否适用于“非似然解”？</title>
      <link>https://stats.stackexchange.com/questions/636811/do-likelihood-properties-apply-to-non-likelihood-solutions</link>
      <description><![CDATA[如果$X$是PDF中的随机变量$f(x;\Theta)$ ，那么我们将似然函数定义为：
$$L(\Theta; x) = f(x;\Theta)$$
据我了解，我们说 $\Theta^*$ 是真正的 MLE 估计器，如果 $\Theta^ *$满足以下条件
$$\Theta^* = \arg\max_{\Theta} L(\Theta; x)$$
因此，MLE 估计器具有以下所需属性：

渐近正态性（对于创建置信区间很有用）
最小方差（Cramer-Rao 界，即 ML 估计器在任何类似估计器中具有尽可能低的方差）
一致性（样本量较大的 ML 估计器更接近真实值的概率更高）
变换下的不变性

从实际角度来看，我们尝试通过数值确定$\Theta^*$。尽管在许多流行的情况下，确定 $\Theta^*$ 的问题是凸优化问题（即我听说概率分布中的所有似然函数都属于指数家庭是凸的），我确信还有其他此类问题，但问题不一定是凸的（我猜测是在层次回归模型或混合模型中）。
我的意思是，有时近似数值解 $\Theta^{**}$ 不可避免地不等于真正的机器学习解$\Theta^*$。在这种情况下，我有兴趣知道：

期望 $\Theta^{**}$ 渐近正态、最小方差、一致且不变是否仍然合理？
假设两个不同的人尝试以两种不同的方式优化似然函数（例如两种不同的数值算法、两种不同的似然函数参数化等）并得出估计值 $\Theta^{***}$ 和 $\Theta^{****}$，而真正的机器学习解决方案是 $\Theta^*$。可以说 $|\Theta^{***} - \Theta^*| &lt; |\Theta^{****} - \Theta^*|$。换句话说，与 $\Theta 相比，$\Theta^{***}$ 更接近真正的机器学习解决方案^{***}$。如果 $\frac{\Theta^{***}}{\Theta^{****}} = a$，我们可以说 $\Theta^{***}$ 更渐近正态（即需要更小的 $n$ 才正常） ，比 $\Theta^ 更一致（即需要更小的 $n$ 来更接近真实值）和更小的方差{****}$ 乘以 $a$？
]]></description>
      <guid>https://stats.stackexchange.com/questions/636811/do-likelihood-properties-apply-to-non-likelihood-solutions</guid>
      <pubDate>Sun, 14 Jan 2024 02:48:35 GMT</pubDate>
    </item>
    <item>
      <title>如何定义不可数样本空间的概率函数的定义域和余域？</title>
      <link>https://stats.stackexchange.com/questions/636809/how-to-define-the-domain-and-codomain-for-the-probability-function-of-an-uncount</link>
      <description><![CDATA[离散样本空间的概率函数的域和余域可以定义为...
定义域：样本空间的幂集
共域：$y \in [0, 1]$
如何为不可数样本空间定义域和辅域？我应该在哪里寻找更多信息？]]></description>
      <guid>https://stats.stackexchange.com/questions/636809/how-to-define-the-domain-and-codomain-for-the-probability-function-of-an-uncount</guid>
      <pubDate>Sun, 14 Jan 2024 02:17:33 GMT</pubDate>
    </item>
    <item>
      <title>线性回归中残差的期望</title>
      <link>https://stats.stackexchange.com/questions/636807/expectation-of-residuals-in-linear-regression</link>
      <description><![CDATA[考虑线性回归模型
$$ Y=X\beta + \epsilon, $$
其中 $Y\in R^n$，$X = (x_1,...,x_n)^T\in R^{n\times p}$ 是 i.i.d. $p$ 维观测值、$\beta\in R^p$ 和 $\epsilon = (\epsilon_1,...,\epsilon_n)\in R^n$ 是独立同分布的。令 $\hat\beta$ 为 $\beta$ 的估计量。那么残差为 $\hat\epsilon = (\hat\epsilon_1,...,\hat\epsilon_n)= Y - X\hat\beta = X(\beta-\ hat\beta) + \epsilon$。我们认为 $X$ 和 $\epsilon$ 都是随机的。这是正确的吗
$$ E(\hat\epsilon_1) = \cdots = E(\hat\epsilon_n) = E\left(\frac{1}{n}\sum_{i=1} ^n \hat\epsilon_i \right)? $$]]></description>
      <guid>https://stats.stackexchange.com/questions/636807/expectation-of-residuals-in-linear-regression</guid>
      <pubDate>Sun, 14 Jan 2024 01:47:44 GMT</pubDate>
    </item>
    <item>
      <title>spss中李克特量表的检验</title>
      <link>https://stats.stackexchange.com/questions/636806/tests-for-likert-scale-in-spss</link>
      <description><![CDATA[这是我第一次使用李克特量表，我需要帮助在 SPSS 中选择合适的测试。
我有一个李克特陈述，想看看是否存在基于年龄（18-25）和25-30）和性别（女性、男性、其他，而不是说）的差异（如果有，它们之间有什么差异）。对此最好的测试是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/636806/tests-for-likert-scale-in-spss</guid>
      <pubDate>Sun, 14 Jan 2024 01:42:55 GMT</pubDate>
    </item>
    <item>
      <title>测试确实检查复杂变量的循环性</title>
      <link>https://stats.stackexchange.com/questions/636805/a-test-do-check-the-circularity-of-a-complex-variable</link>
      <description><![CDATA[我需要一种方法来测量复杂随机变量的循环性。当复数随机变量的 PDF 仅取决于其大小而不取决于其角度时，该变量是圆形的。
例如，$z$是一个复杂的随机变量$z=x+iy$，其中$i=\sqrt{-1}$ 和 $x$ 和 $y$ 是真正的随机变量 $z$ 的 PDF ($f(z) $) 只能写在 $|z|$ 的函数中，如果 $z$是圆形的。
一些论文使用由变量的方差（$\phi_z$）归一化的伪方差来判断变量是否是循环的：
$$\phi_z=\frac{E[z^2]}{E[zz^*]}$$
因为 $\phi_z=0$ 如果 $z$ 是循环的，但是复数变量可以具有 $\phi_z=0$ 并且如果其实部和虚部正交，则不是循环。如下非循环变量样本实部和虚部散点图所示，其中 $\phi_z=0$：

很明显，概率密度不仅仅随着样本大小的变化而变化。
由于 PDF 不依赖于角度，因此在圆形变量中，样本必须均匀分布在所有角度间隔上（即 $-\pi$到 $\pi$）。下图显示了圆形随机变量的示例以及使用直方图估计的样本角度的 PDF：


因此，我想到了执行假设检验来检查变量的循环性的想法，其中：
$H_0$：可变角度的PDF是统一的
$H_1$：可变角度的PDF不均匀
因此$H_0$对应于循环的变量
这个测试有效吗？有论文提出该测试吗？有没有更好的方法来检查复杂随机变量的循环性？]]></description>
      <guid>https://stats.stackexchange.com/questions/636805/a-test-do-check-the-circularity-of-a-complex-variable</guid>
      <pubDate>Sun, 14 Jan 2024 01:38:01 GMT</pubDate>
    </item>
    <item>
      <title>证明后验不依赖于数据分解</title>
      <link>https://stats.stackexchange.com/questions/636802/proof-that-posterior-does-not-depend-on-data-breakdown</link>
      <description><![CDATA[假设根据先验计算某个参数 $P(\theta\mid x)$ 的后验分布。现在假设我们将该数据分为两部分，例如 $x = x_1 \cup x_2$。直观地说，在给定相同先验的情况下，分解数据必然会导致相同的后验，即 $$P(\theta\mid x) = P(\theta\mid x_1, x_2)$ $
但是，从贝叶斯定律来看，这并不明显是正确的。
有哪些方法可以正式证明这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/636802/proof-that-posterior-does-not-depend-on-data-breakdown</guid>
      <pubDate>Sun, 14 Jan 2024 00:02:05 GMT</pubDate>
    </item>
    <item>
      <title>为什么将 ECM 重写为这种格式？</title>
      <link>https://stats.stackexchange.com/questions/636801/why-rewrite-the-ecm-to-this-format</link>
      <description><![CDATA[

本文作者写了一个典型的ECM公式，即第一个方程。然后他们说“我们可以将方程重写为第二个方程并通过 OLS 对其进行估计”谁能解释一下他们是如何能够以这种方式转换的？如果我展开括号，我仍然得不到第二个方程]]></description>
      <guid>https://stats.stackexchange.com/questions/636801/why-rewrite-the-ecm-to-this-format</guid>
      <pubDate>Sat, 13 Jan 2024 23:46:34 GMT</pubDate>
    </item>
    <item>
      <title>使用线性回归测试二元结果 - R^2 误报？</title>
      <link>https://stats.stackexchange.com/questions/636799/testing-binary-outcomes-with-linear-regression-r2-false-positives</link>
      <description><![CDATA[有很多理由不使用线性回归（而不是逻辑回归）来测试二元结果。如果这样做，是否存在确定系数的 F 检验 ($R^2$) 会产生假阳性的情况？也就是说，如果使用逻辑回归测试模型，实际上模型中的所有变量都不显着，那么 F 检验是否显着？
例如，如果运行第一个模型而不是第二个模型：
图书馆（棕榈企鹅）
数据（包=&#39;棕榈企鹅&#39;）
dat = 企鹅

model_线性 = lm(as.numeric(sex) ~ ., data = dat)
model_log = glm(sex ~ ., data = dat,family = “二项式”)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/636799/testing-binary-outcomes-with-linear-regression-r2-false-positives</guid>
      <pubDate>Sat, 13 Jan 2024 22:46:42 GMT</pubDate>
    </item>
    <item>
      <title>数据自然对数的平均值和标准差</title>
      <link>https://stats.stackexchange.com/questions/636797/mean-and-standard-deviation-of-natural-log-of-data</link>
      <description><![CDATA[Y = 自然对数数据 = -6.9077、-6.2146、-8.1117、-5.1159、-7.2644
平均值 (Y) = -6.7229
(Y) 的标准 = 1.128801537
我想绘制平均值的误差图，并使用标准差作为对数刻度上的误差线：
我通过指数变换平均值：
exp（(Y) 的平均值）
但我不知道如何处理 std，因为取它的指数是不对的。]]></description>
      <guid>https://stats.stackexchange.com/questions/636797/mean-and-standard-deviation-of-natural-log-of-data</guid>
      <pubDate>Sat, 13 Jan 2024 21:55:57 GMT</pubDate>
    </item>
    <item>
      <title>Welch t 检验是否应该使用无偏标准差估计来计算自由度？</title>
      <link>https://stats.stackexchange.com/questions/636793/should-welch-t-test-use-unbiased-standard-deviation-estimates-to-compute-degrees</link>
      <description><![CDATA[此答案建议我们应该（如果可能）更正 Satterthwaite 方程 计算自由度 $\nu$ t 检验。 评论不同意。 p&gt;
当然，只有当我们使用非常小的样本量时，这才有意义，并且只有当我们能够找到标准偏差估计的修正项时才实用。
如果我们假设随机变量呈正态分布，那么我们可以通过应用 修正系数 $c_G(n) = \sqrt{\frac{N-1}{2}}\,\,\frac{\Gamma\left (\frac{N-1}{2}\right)}{\Gamma\left(\frac{N}{2}\right)}$。
如果变量是正态的，那么合并该校正因子是否会改善我们的计算？
&lt;小时/&gt;
我试图通过对独立正态变量 X、Y 的均值差异进行一系列模拟实验来回答这个问题；使用 $\nu$ 计算有或没有校正因子的差异的置信区间 (CI)；并计算 CI 内真实差异的频率。 （Python 代码如下。）但是，即使使用小至 4 的样本大小 n 进行 100,000 次迭代，我也找不到任何导致 CI​​ 覆盖率超出所需置信度 1% 的模拟参数，两个公式的 CI 覆盖率差异绝不会超过 0.3%。因此，如果存在差异，我还没有通过这种方法成功找到它。
# 模拟检查估计平均值差异的置信区间
导入数学
将 numpy 导入为 np
从 scipy.stats 导入 t
nsim = 100_000 # 要运行的模拟次数
# 用于模拟的随机变量参数：
nX, nY = (8, 4)
X 平均值、Y 平均值 = (1, 2)
sigmaX, sigmaY = (1, .3)

gamma = 0.9 # 置信区间覆盖范围

定义 cG(n):
    返回 math.exp(math.lgamma((n-1)/2) - math.lgamma(n/2) - math.log(math.sqrt(2/(n-1))))
cGx = cG(nX)
cGy = cG(nY)

count_contains_true = 0 # 基础 CI 包含真实差异 (meanX-meanY) 的模拟次数
count_ Corrected_contains_true = 0 # 相同，但使用无偏标准差计算 CI
对于我在范围内（nsim）：
    x = np.random.normal(大小=nX, loc=meanX, 尺度=sigmaX)
    y = np.random.normal(大小=nY, loc=meanY, 尺度=sigmaY)
    muX = np.mean(x)
    muY = np.mean(y)
    varX = np.var(x, ddof=1)
    varY = np.var(y, ddof=1)
    eX = varX / nX
    eY = varY / nY
    nu = (eX + eY)**2 / (eX**2 / (nX-1) + eY**2 / (nY-1))
    CI = t.interval(gamma, df=nu, loc=(muX - muY), scale=np.sqrt(eX+eY))
    如果 CI[0] &lt;平均X-平均Y＜ CI[1]:
        count_contains_true += 1

    # 使用校正因子计算 nu
    eXc = cGx**2 * eX
    eYc = cGy**2 * eY
    nu = (eXc + eYc)**2 / (eXc**2 / (nX-1) + eYc**2 / (nY-1))
    CI = t.interval(gamma, df=nu, loc=(muX - muY), scale=np.sqrt(eX+eY))
    如果 CI[0] &lt;平均X-平均Y＜ CI[1]:
        count_ Corrected_contains_true += 1

print(f&#39;在 {nsim:,} 模拟 {gamma:.0%} 置信区间包含真实参数:\n&#39;
      基础 CI 的 f&#39;\t\t{count_contains_true / nsim:.1%}\n&#39;
      f&#39;\t\t{count_ Corrected_contains_true / nsim:.1%} 的无偏 CI 时间&#39;
）
]]></description>
      <guid>https://stats.stackexchange.com/questions/636793/should-welch-t-test-use-unbiased-standard-deviation-estimates-to-compute-degrees</guid>
      <pubDate>Sat, 13 Jan 2024 21:21:09 GMT</pubDate>
    </item>
    <item>
      <title>LOOCV：要报告哪些性能指标聚合？</title>
      <link>https://stats.stackexchange.com/questions/636784/loocv-which-aggregation-of-the-performance-metric-to-report</link>
      <description><![CDATA[目标变量是收入，有 81 个观测值和 10 个特征。
目标分布是这样的：标准对数变换不会产生近似正态分布，但收入**(1/4) 会产生近似正态分布。预期模型根据转换后的目标进行训练，但根据反向转换的预测值进行评估。
我选择 RMSLE 作为我的性能指标，因为它是一种相对度量，对低估的惩罚高于对高估的惩罚。
LOOCV 用于超参数调整、模型选择和最终模型验证。
但是要开始做出决策，我需要选择一种聚合方法。下面显示的是 RMSLE 分数分布的示例：

我的理解是，平均值通常是针对 LOOCV 报告的。但是，考虑到这种分布，使用/报告中位数或几何平均值更合适吗？
编辑：
一位评论者指出，嵌套简历在这里更合适。我相信我正在这样做（很抱歉没有更具描述性），但我可能是错的：
从 sklearn.linear_model 导入 Ridge

alpha_range = np.logspace(-2,2,20,base=10,endpoint=True)
rmsle_df_ridge = pd.DataFrame(columns=list(map(str, alpha_range)))

对于 i，枚举（kf.split（X））中的（train_index，test_index）：
    X_train = X.iloc[train_index]
    X_test = X.iloc[test_index]
    y_train = y.iloc[train_index]
    y_test = y.iloc[test_index]
    对于 alpha_range 中的 alpha：
        山脊 = 山脊(alpha=alpha)
        col_tf = make_column_transformer((StandardScaler()，scaler_cols)，余数=&#39;passthrough&#39;)
        pip_dt = make_pipeline(col_tf, ridge)
        pip_dt.fit(X_train, y_train)
        y_pred = pip_dt.predict(X_test)
        均方根误差=mean_squared_log_error(y_test**4, y_pred**4)**0.5
        rmsle_df_ridge.loc[i, str(alpha)] = rmsle

然后绘图是通过以下方式生成的：
sns.lineplot(x=np.log10(alpha_range),y=rmsle_df_ridge.mean(axis=0))
plt.title(&#39;LOOCV Ridge&#39;)
plt.ylabel(&#39;RMSLE_mean&#39;)
plt.show()
plt.clf()
print(&#39;RMSLE_mean: &#39;,np.min(rmsle_df_ridge.mean(axis=0)))


因此 RMSLE 值存储在 n x m 矩阵中，其中 n = # rev_obs = 81 且 m = len(alpha_range)，其中 RMSLE (i,j) 表示通过排除第 i 个观察值进行训练然后对 i 进行测试而获得的 RMSLE，同时使用 j 作为岭回归的超参数 alpha。然后，我使用每列的算术平均值进行聚合，以获得 mx2 矩阵 RMSLE_agg，其行对应于 (alpha, RMSLE_mean_LOOCV)。
如有不正确之处，请指教。
无论如何，鉴于 RMSLE 分数的分布如上所示，我仍然不知道用算术平均值（而不是中位数或几何平均值）进行聚合是否最合适。]]></description>
      <guid>https://stats.stackexchange.com/questions/636784/loocv-which-aggregation-of-the-performance-metric-to-report</guid>
      <pubDate>Sat, 13 Jan 2024 18:14:26 GMT</pubDate>
    </item>
    <item>
      <title>显着的曼·惠特尼 (Mann Whitney) 和显着的 t 检验，但方向相反</title>
      <link>https://stats.stackexchange.com/questions/636755/significant-mann-whitney-and-significant-t-test-but-in-the-other-direction</link>
      <description><![CDATA[我想知道是否有可能有 2 个样本（A 和 B），其中 A 随机支配 B（通过 Mann Withney 或 Kruskal Wallis），但相反，B 的均值显着高于 A（通过2 样本韦尔奇检验）。
A 和 B 不可能是对称的，而且可能也不具有相同的形状。 A 和 B 也不会是正态的，但 t 检验根据 CLT 有效（例如样本量为 30 或 40）。对于单面测试来说，这种情况可能比双面测试更有可能发生。我尝试了各种方法，但到目前为止还没有成功......
这样的反例是否存在，或者如果A对B占主导地位，那么A的均值在统计上永远不会劣于B的均值（可能不会在统计上显着优于B，但不能劣于）。
也就是说，MW 和韦尔奇都很重要，但方向相反。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/636755/significant-mann-whitney-and-significant-t-test-but-in-the-other-direction</guid>
      <pubDate>Sat, 13 Jan 2024 02:19:46 GMT</pubDate>
    </item>
    <item>
      <title>月级固定效应模型</title>
      <link>https://stats.stackexchange.com/questions/636685/month-level-fixed-effects-model</link>
      <description><![CDATA[我试图了解男性成员的流动对留守妇女就业结果的影响。我每月进行观察，已有 5 年了。我正在使用具有月级和年级固定效应的固定效应模型。就业结果是妇女在家庭农场度过的时间。我之所以使用月度固定效应，是因为我认为农业部门可能会出现季节性冲击。这些季节性冲击可能会影响我的因变量和解释变量。
因此，我想控制月份级别的影响。我使用月份级别固定效应的逻辑正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636685/month-level-fixed-effects-model</guid>
      <pubDate>Fri, 12 Jan 2024 06:43:06 GMT</pubDate>
    </item>
    </channel>
</rss>