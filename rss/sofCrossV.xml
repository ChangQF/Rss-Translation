<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Thu, 20 Feb 2025 18:22:51 GMT</lastBuildDate>
    <item>
      <title>区分二项式分布的归一化项以获取方差</title>
      <link>https://stats.stackexchange.com/questions/661641/differentiating-the-normalization-term-of-a-binomial-distribution-to-get-the-var</link>
      <description><![CDATA[我正在Bishop的模式识别和机器学习中进行练习2.4。该问题要求与U相对于U区分归一化条件，以获得n均值的表达式，并在方差上相对于U区分两次。在这篇文章的帮助下（为什么区分二项式分布的标准化项会产生预期值吗？）我能够得到均值，但我陷入了差异。到目前为止，我有
  $$ \ sum_ {m = 0}^n \ binom {n} {m} {m} u^m（1-u）^{（n-m）} = 1 $$  
拿第一个衍生物我得到：
  $$ \ sum_ {m = 0}^n \ binom {n} {m} {m} [mu^{m-1}（1-U）（1-u）^{n-m}  - u^m（n-m）（1-u）^{n-m-1}] = 0 $$  
我能够从这里得到平均值，但是当我走上差异时，我会卡住。乘坐第二个导数：
  $$ \ sum_ {m = 0}^n \ binom {n} {m} {M} {（M-1）[（M）U^{M-2}（1 -u）^{n-m} -Mu^{M-1}（N-M）（1-U）^{N-M-1}  - mu^{m-1}（n-m）（1-u）^{n-m-1} + u^m（n-m）（n-m-1）（n-m-1）（1-u）^{n-m-2} = 0 $$跨度&gt; 
结合我得到的术语：
  $$ \ sum_ {m = 0}^n \ binom {n} {m} {M} {（M-1）[（M）U^{M-2}（1 -u）^{n-m} -2MU^{M-1}（N-M）（1-U）^{N-M-1} + U^M（N-M）（N-M-1）（1-U）^{N-M-2} = 0 $$  
现在，我在跨越方程式上分配总和和二项式系数
  $$ \ sum_ {m = 0}^n \ binom {n} {m} {M} {（M-1）[（M）U^{M-2}（1 -u）^{n-m}] [1] $$  
  $$ \ sum_ {m = 0}^n \ binom {n} {m} {M} [2Mu^{M-1}（M-1}（N-M）（N-M）（1-U）^{{ N-M-1}] [2] $$  
  $$ \ sum_ {m = 0}^n \ binom {n} {m} {m} [u^m（n-m）（n-m）（n-m-1）（n-m-1）（1-u）^^ {N-M-2}] [3] $$  
对于[1]，我将 $ u^-2 $ 从 $ u^m $ ，给出
  $$ u^{ -  2} \ sum_ {m = 2}^{n-2} {n-2} \ binom {n} {m} {m} [（m-1） ）u^{m}（1-u）^{n-m}] $$  
然后我从二项式系数取消M（M-1）
  $$ u^{ -  2} \ sum_ {m = 2}^{n-2} \ binom {n} {n} {m-2} （1-u）^{n-m}] $$  
然后我从二项式系数中拔出n（n-1），给出
  $$ u^{ -  2}（n）（n）（n-1）\ sum_ {m = 2}^{n-2} \ binom {n-2} { m-2} [u^{m}（1-u）^{n-m}] $$  
，然后意识到我有归一化，这将减少为：
  $$ u^{ -  2}（n）（n-1）[1] $$
对于[2]，
  $$ \ sum_ {m = 0}^n \ binom {n} {m} {M} [2Mu^{M-1}（M-1}（N-M）（N-M）（1-U）^{{ N-M-1}] $$  
 i首先分开 $ u^{ -  1} $ 从 $ u^{m-1 {m-1} $ &lt; /span&gt;以及2，给出
  $$ 2U^{ -  1} \ sum_ {m = 0}^n \ binom {n} {m} {m} [mu^{m}（n-m）（1-- u）^{n-m-1}] $$  
 i然后取消 $ n-m $ 从二项式中取出，然后我撤出n以将转换保持为 $ $ N-1 $  
  $$ 2U^{ -  1} n \ sum_ {m = 1}^{n-1} \ binom {n-1} {n-1} {m} [mu^{m }（1-u）^{n-m-1}] $$  
看到我在总结中有期望
  $$ 2U^{ -  1} N \ MATHBB {E} [M] $$
最后，对于[3] 
  $$ \ sum_ {m = 0}^n \ binom {n} {m} {m} [u^m（n-m）（n-m）（n-m-1）（n-m-1）（1-u）^^ {N-M-2}] [3] $$  
 i取消 $（n-m）（n-m-1）$ 并拔出n（n-1），给出
  $$（n）（n）\ sum_ {m = 2}^{n-2} \ binom {n} {n} {m} {m} [u^m（n-m） ）^{n-m-2}] $$  
再次意识到我有归一化，这将减少到
  $$（n）（n-1）$$
所以将它们结合在一起，我有
在n-1）= 0 $$  
，但随后我被困在这一点上，我无法从这里获得差异的方程式。我假设我的问题可能与重新索引我目前没有有关，但我不确定。任何帮助将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/661641/differentiating-the-normalization-term-of-a-binomial-distribution-to-get-the-var</guid>
      <pubDate>Thu, 20 Feb 2025 17:20:11 GMT</pubDate>
    </item>
    <item>
      <title>如何调整回归模型的选择偏差？</title>
      <link>https://stats.stackexchange.com/questions/661637/how-to-adjust-regression-models-for-selection-bias</link>
      <description><![CDATA[我试图更好地了解如何制作回归模型以纠正数据中的不同偏差。例如，考虑以下情况：

我收集有关人们年龄，性别以及他们是否有一定的数据的数据
疾病与否。我想制作一个统计模型
在不同年龄组中这种疾病的患病率。但是，我知道
某些年龄组更有可能接受该疾病的测试
某些年龄段更有可能向
民意调查。我如何将这些偏见分为模型？


阅读有关这些主题的信息，这是一种对我来说有意义的方法，涉及测试和调查参与偏见。我定义了：

  $ d $  =患病（1如果是，0，如果否）
  $ a $  = age 
  $ t $  =进行测试（1如果测试，0，如果不是，则））
  $ s $  =调查参与（1如果参与，如果没有，则为0）

我们要估计疾病在年龄 $ a $ a $   $ p时，我们要估计疾病的真实流行似乎是合乎逻辑的（d | a）$ 。
但我只观察到年龄 $ a $ 经过测试并参加调查 $ p的患病率（d | a，t = 1，s = 1）$ 。
使用贝叶斯定理：
  $$ p（d | a，t = 1，s = 1）= \ frac {p（t = 1，s = 1 | d，a）p（d | a）} {p（t = 1，s = 1 | a）} $$ 
 $$ p（d | a）= \ frac {p（d | a，t = 1，s = 1）p（t = 1，s = 1）} {p（ t = 1，s = 1 | d，a）} $$  
我需要估计：

  $ p（t = 1 | a）$  =在年龄上测试的概率 $ a $ a $  
  $ p（s = 1 | a）$  =年龄参加调查的概率 $ a $ a $  

我选择了基本的逻辑回归来建模以下：
  $$ \ log \ left（\ frac {p（t = 1 | a）} {1-p（t = 1 | a）} \ right）= \ beta_0 + \ \ beta_1a + \ beta_2a^2 $$  
  $$ \ log \ left（\ frac {p（s = 1 | a）} {1-p（s = 1 | a）} \ right）= \ gamma_0 + \ \ gamma_1a + \ gamma_2a^2 $$  
假设在给定年龄和疾病状态的测试和调查参与之间具有独立性：
  $$ p（t = 1，s = 1 | d，a）= p（t = 1 | d，a）p（s = 1 | d，a） $$  
最终疾病患病率模型使用：
  $$ \ log \ left（\ frac {p（d | a）} {1-p（d | a）} \ right）= \ alpha_0 + \ alpha_1a + alpha_1a + \ alpha_2a^2 $$  
 这是我感到困惑的地方。正确说明不同的偏见，估计最终模型的参数需要前两个模型的估计。但是，我不确定如何正确参与其中。我试图这样做:: 
  $$ l（\ alpha_0，\ alpha_1，\ alpha_2）= \ prod_ {i = 1}^n [p（d_i | a_i）]^{d_i} [1 -p（d_i | a_i）]^{1-d_i} \ times w_i $$  
  $$ W_I = \ frac {1} {p（t = 1 | a_i）p（s = 1 | a_i）} $$   
  $$ w_i =（1 + e^{ - （\ beta_0 + \ beta_1a_i + \ beta_2a_i^2）}） gamma_1a_i + \ gamma_2a_i^2）}）$$  

我的分析正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661637/how-to-adjust-regression-models-for-selection-bias</guid>
      <pubDate>Thu, 20 Feb 2025 16:50:08 GMT</pubDate>
    </item>
    <item>
      <title>折刀CI的随机森林取决于树木的数量？</title>
      <link>https://stats.stackexchange.com/questions/661636/jackknife-ci-for-random-forests-dependent-on-number-of-trees</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661636/jackknife-ci-for-random-forests-dependent-on-number-of-trees</guid>
      <pubDate>Thu, 20 Feb 2025 16:14:59 GMT</pubDate>
    </item>
    <item>
      <title>IPW用于审查：比标准化更强大？ （示例表格，如果？）</title>
      <link>https://stats.stackexchange.com/questions/661635/ipw-for-censoring-more-powerful-than-standardization-example-form-what-if</link>
      <description><![CDATA[我在埃尔南（Hernán）的书中遇到了一句话。我感到非常困惑。
具体来说，在图8.4的情况下，他正在谈论审查。以下是相关图的屏幕截图。治疗是 $ a $ 结果是 $ y $ ，审查 $ c $ ， $ u $ 未衡量。
    
这是相关引号：

&#39;最后，人们可以说，在图8.3中所述的类似的设置中，不需要IP加权来调整选择偏差。相反，人们可能会尝试通过分层（即，通过估计效果测量在L变量上的效果度量）而不是通过IP加权来消除选择偏差。
分层可以在L水平内产生无偏的条件效应措施，因为在L上的条件足以阻止从C到Y [...]分层的后门路径，但是在图8.4和8.6中所示的结构下不起作用。 

我同意为什么的解释。本质上，我们对 $ y^{a，c = 0} $ ，我们找不到阻止 $ a $ 和 $ c $ 同时。
他继续：

相反，IP加权适当调整以下选择偏差
图8.3-8.6，因为这种方法不是基于估计效果指标的
在协变量l的条件下，而不是估计无条件效应
根据个人的待遇重新加权后，采取措施
他们的L。

我不明白为什么IPW加权不会遇到相同的问题：缺乏适当的调整集。 理论上可以证明为什么IPW有效，而标准化却没有？ 
此外，本书的后面部分中有一些相当神秘的评论：

; ip wa，c调整两个混淆
以及在交换性的可识别性条件下的选择偏差
联合处理（A，C）在L上有条件 - 即Y
a，c =0⊥⊥（a，c）| l  - ，关节
（a = a，c = 0）和一致性的阳性。如果L中的某些变量
如图8.4所示，受到治疗A的影响，有条件的独立性 $ y^{a，c = 0} \ perp \！\！\！\！\！\！\ perp（a，c）\ mid l $ 通常不会容纳。在第三部分中，我们表明有一些替代的交换性条件可以许可我们使用IP加权
估计当L的某些成分受到影响时A和C的关节效应。

这听起来很奇怪，就像承认IPW是无效的，但存在某种替代的理由。]]></description>
      <guid>https://stats.stackexchange.com/questions/661635/ipw-for-censoring-more-powerful-than-standardization-example-form-what-if</guid>
      <pubDate>Thu, 20 Feb 2025 16:08:23 GMT</pubDate>
    </item>
    <item>
      <title>医院评估的纵向分析：如何正确分析这些数据？</title>
      <link>https://stats.stackexchange.com/questions/661634/longitudinal-analysis-of-hospital-evaluations-how-to-correctly-analyze-this-dat</link>
      <description><![CDATA[我目前正在分析医院绩效数据大约 5至8年，医院：

根据其保险规模捐款。
每年在八个绩效标准上进行评估：结果是每年0至8的分数。
如果符合所有标准（即，如果有8/8），则获得一部分合并资金，否则就没有钱。

我们的目标是模型这些性能如何随着时间的流逝而发展并调查是否：

 最初表现良好的医院继续获得更多资金，进一步改善。
 最初表现不佳的医院收到的钱更少，随着时间的流逝而恶化。

我们计划使用混合模型来解释：

 固定效果：代表分数随时间的演变。
 随机拦截：捕获特定医院的基线表现水平。
 随机斜率：随着时间的推移表示医院特定的趋势。

并评估随机斜率与随机截距之间的相关性，以查看较低的截距（即医院最初做得不好）是否导致高负面随机斜率（即医院随着时间的流逝而变得更糟） 。一个问题是，医院以最高分数开始可能会随着时间的流逝而没有变化，从而导致随机斜率接近零&gt;。这可能会影响医院之间斜率可变性的解释。
我很想听听您对这种方法的想法：

您在混合模型中是否遇到了性能高原的类似问题？
关于建模最初分数的医院的任何建议？
关于这种模型的任何文献？
]]></description>
      <guid>https://stats.stackexchange.com/questions/661634/longitudinal-analysis-of-hospital-evaluations-how-to-correctly-analyze-this-dat</guid>
      <pubDate>Thu, 20 Feb 2025 16:03:08 GMT</pubDate>
    </item>
    <item>
      <title>预测时变连续变量的危险比</title>
      <link>https://stats.stackexchange.com/questions/661632/predicting-hazard-ratio-for-time-varying-continuous-variable</link>
      <description><![CDATA[ i具有cox pH模型（拟合了R生存包），其时间变化持续变量（tt（）变换，天然立方样条，与分类预测指标的相互作用），我想知道我如何绘制与ci的危险预测连续变量范围的比率，其他变量保持固定。一直在尝试使用se.fit = true的新数据进行预测（），但这似乎失败了。]]></description>
      <guid>https://stats.stackexchange.com/questions/661632/predicting-hazard-ratio-for-time-varying-continuous-variable</guid>
      <pubDate>Thu, 20 Feb 2025 14:31:10 GMT</pubDate>
    </item>
    <item>
      <title>根据分类变量检测“ true”无效得分的“ false”无效分数</title>
      <link>https://stats.stackexchange.com/questions/661631/detecting-false-null-scores-from-true-null-scores-based-on-categorical-varia</link>
      <description><![CDATA[我从事教育统计数据，并且在各种测试中都有一个学生分数的数据集。在此数据集中，我有一个 fulence评分（这是一分钟内读取的单词数）和 profile 基于七种模态的阅读理解得分（进行）从1开始，学生面临严重的困难，使日常生活沟通，倾听和写入困难到7，这报告了阅读理解的水平）。这些测试是详尽的，每个学生都参加了测试（即使流动的参与评分较低）。。
 Fluence测试旨在检测日常沟通和阅读中的巨大困难，文本很容易阅读。一个可以在一分钟内读取少于120个单词的学生被认为是困难的。
 问题是，数据集中有错误的无效分数（应该是NAS的零），因为某些学校不让他们的班级的每个学生参加Fluence测试（是否因为老师认为学生的服用是不可能的参加测试之前的所有分数都达到0）。
我想使用阅读理解资料和其他辅助变量（例如学校身份证明），以检测和删除这些“ false”零得分在频率中。但是我不知道该怎么做。
我试图做出一些现实的假设：

理论上不应有剖面7的学生的剖面分数（实际上，此概况的学生的1％以上的学生得分为无效）
在我的数据中，概况1的无效分数的学生的实际比例应接近相同配置文件的零分数的比例。

由此，随着概况性能的提高，我应该降低零分数的比例。但是，我找不到这样做的模型，因为配置文件是一个分类变量（而且我只假设在7种模式中的2个中假设假设），而且因为我没有虚拟变量，该变量可告知null得分是否为A＆quit a＆quot ;真实的零评分或a false; quot零评分。
 i首先尝试通过在虚拟变量“ profile” profile&#39;profile == 7之前设置正常的分数概率的逻辑回归为零。平均值-20和标准偏差1，它降低了配置文件7的零分数的比例，但我真的不明白它如何按照我想要的方式影响其他配置文件（这是说，概况越糟，越多实际的无效分数比例可能接近数据中的零评分比例）。
事先感谢您提供的任何建议：）
 Steve ]]></description>
      <guid>https://stats.stackexchange.com/questions/661631/detecting-false-null-scores-from-true-null-scores-based-on-categorical-varia</guid>
      <pubDate>Thu, 20 Feb 2025 14:25:53 GMT</pubDate>
    </item>
    <item>
      <title>尖峰和slab中正常分布的混合物之间的联系</title>
      <link>https://stats.stackexchange.com/questions/661630/link-between-mixture-of-normals-and-laplace-distribution-in-spike-and-slab</link>
      <description><![CDATA[我正在阅读Spike-and-slab模型（主要是通过本文）。回顾一下，一般连续的尖峰和slab先验由 $ \ beta $ ，给出
  $$ P（\ beta \ Mid \ gamma，\ sigma^2）= \ prod_ {j = 1}^{p} 
\ left [（1- \ gamma_j）\ Mathcal {n}（0，\ sigma^2 \ tau_0^2） + \ gamma_j \ gamma_j \ mathcal {n}（0，\ sigma^2 \ sigma^2 \ tau_1^2） $$ 
 $$
p（\ gamma \ mid \ theta）= \ prod_ {j = 1}^{p} \ theta^{\ gamma_j}（\ gamma_j}（1  -  \ theta）^{1  -  \ gamma_j} \ theta），\ Quad $$ 
 $$ \ sigma^2 \ sim p（\ sigma^2）。$$ 
其中 $ 0＆lt; \ tau_0^2＆lt;＆lt; \ tau_1^2 $ 。现在，在论文中指出这是正常的混合物。我们还认为套索等于以下拉普拉斯先验
  $$
p（\ beta \ mid \ lambda）= \ prod_ {j = 1}^{p} \ frac {\ lambda} {2} {2} e^{ -  \ lambda | \ beta_jj |}，
$$ 
这导致以下尖峰和斜纹套件先验
  $$
p（\ beta \ mid \ gamma）= \ prod_ {j = 1}^{p} \ left [（1  -  \ gamma_j）\ psi（\ beta_j \ beta_j \ beta_j \ mid \ lambda_0） \ lambda_1）\ right]，
$$ 
 $$
p（\ gamma \ mid \ theta）= \ prod_ {j = 1}^{p} \ theta^{\ gamma_j}（1- \ theta）^{1  -  \ \ gamma_j}，
\ Quad 
$$ 
 $$
\ theta \ sim \ text {beta}（a，b）。
$$  
我还读过拉普拉斯分布是正常的混合物。我正在尝试将这些概念联系起来，但我正在努力。 那里有直接链接吗？我们可以将连续的尖峰和单杆重写为拉普拉斯分布或尖峰和slab套索作为正常的混合物？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/661630/link-between-mixture-of-normals-and-laplace-distribution-in-spike-and-slab</guid>
      <pubDate>Thu, 20 Feb 2025 14:12:34 GMT</pubDate>
    </item>
    <item>
      <title>参数方法绕过计算关节分布？</title>
      <link>https://stats.stackexchange.com/questions/661629/parametric-methods-bypass-calculating-the-joint-distribution</link>
      <description><![CDATA[如果我想使用平方损耗函数解决ML问题，那么最佳预测因子是 $ \ Mathbb {e} [y \ mid x] $  &lt;&lt;&lt;。 /p&gt;
有两种计算方法 $ \ Mathbb {e} [y \ mid x] $ 。我们要么平镇 $ \ Mathbb {p} _ {x，y} $ 是关节分布，要么假设 Mathbb {e} [y \ mid x] $ 是一个函数 $ f $   $ n $ 参数： $ p_i $ 。
如果我没记错的话，第一个解决方案是局部平均方法尝试在ML中使用的方法，例如K-NN，树。在第二种情况下，这是线性回归和神经网络尝试做的。
因此，参数方法不使用联合分布来计算 $ \ mathbb {e} [y \ mid x] $ ，假设贝叶斯预测器具有一个他们解决的某些机构形式。
但这意味着这些模型无法计算 $ \ text {var}（y \ id x）$ ，因为我们只是训练该模型以解决&lt;&lt; SPAN class =“ Math-Container”&gt; $ \ Mathbb {e} [y \ mid x] $ 。
我的理解正确吗？因此，我们可以得出结论，如果样本的数量很高，则本地平均方法是优越的，因为它们为我们提供了有关该问题的更多信息（有关 $ \ Mathbb {p} _ { x，y} $ 可以帮助我们计算更多的指标，而不是 $ \ Mathbb {e} [y \ mid x] $ ）。]]></description>
      <guid>https://stats.stackexchange.com/questions/661629/parametric-methods-bypass-calculating-the-joint-distribution</guid>
      <pubDate>Thu, 20 Feb 2025 14:07:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么在指数族中的足够统计量与随机样本的分布相同？</title>
      <link>https://stats.stackexchange.com/questions/661626/why-is-the-distribution-of-sufficient-statistic-same-as-the-random-sample-in-exp</link>
      <description><![CDATA[指数分布家族的定义为以下在弗格森的数学统计数据中：决策理论方法书：
   
一个足够的统计量， $ \ Mathbf {t} $ ，如下：
   
然后，在引理1中， $ \ Mathbf {t} $ 的分布被证明是定义1中的形式。但是如何证明这一点？我们知道随机样本是从指数级的家庭分布中得出的，但是为什么足够的统计数据的分布相同？
   ]]></description>
      <guid>https://stats.stackexchange.com/questions/661626/why-is-the-distribution-of-sufficient-statistic-same-as-the-random-sample-in-exp</guid>
      <pubDate>Thu, 20 Feb 2025 13:29:13 GMT</pubDate>
    </item>
    <item>
      <title>编码高比例的缺失值以使连续变量导致相互信息高于二进制变量的熵</title>
      <link>https://stats.stackexchange.com/questions/661624/encoding-high-proportion-of-missing-values-for-continuous-variable-results-in-mu</link>
      <description><![CDATA[这与 a&gt;但在这种情况下删除丢失值不是一个选项。
我尝试使用 sklearn.feature_selection.mutual_info_classif 来计算共同信息。这些不是我可以扔掉的观察结果，因为这些是“有意义的nulls”。 - 他们的失踪性龋齿信息。由于 mutual_info_classif 不接受缺失值，因此我将它们编码为非错失部分的外部值（例如-999）。最重要的是，只有0.15％的人口是二元目标的正类别。结果，我得到的共同信息高于目标的熵，这是不可能的：因为：
 $$
i（x; y）\ leq \ min（h（x），h（y））
$$ 
这是玩具示例：
 导入numpy作为np
来自sklearn.feature_selection import mutual_info_classif
来自Scipy.pexial Import Xlogy

rng = np.random.default_rng（seed = 42）
x = rng.pendential（1，10_000）
＃仿真编码nulls
x = np.append（x，-999 * np.ones（80_000））

＃完全独立的目标
y = np.zeros_like（x）
y_1 = rng.integers（0，len（x），150）
y [y_1] = 1

print（y y y y Mutual_info_classif的熵：h（y）= {mutual_info_classif（y [：，none]，y，y，y，iNCETE_FEATURES = true）[0]};）
打印（y的熵计算：h（y）= {xlogy（y.mean（），1/y.mean（））+xlogy（1-y.mean（），1/（1/（1-y.mean） （）））}＆quot;）
print（f＆quot X和y的互相信息来自mutual_info_classif：i（x，y）= {mutual_info_classif（x [：x [：，none]，y），y）[0]};）
 
结果：
 
显然是错误的，因为 x 和 y 是独立的，并且相互信息高于 y 的熵。]]></description>
      <guid>https://stats.stackexchange.com/questions/661624/encoding-high-proportion-of-missing-values-for-continuous-variable-results-in-mu</guid>
      <pubDate>Thu, 20 Feb 2025 13:14:05 GMT</pubDate>
    </item>
    <item>
      <title>优势比不变性：在逻辑回归中调整时如何？</title>
      <link>https://stats.stackexchange.com/questions/661623/odds-ratio-invariance-how-about-when-adjusted-in-logistic-regression</link>
      <description><![CDATA[我理解几率是不变的，这意味着您将获得OR（暴露与未暴露）的相同点估计值，即使您将暴露视为结果：
 


 
事件
没有事件




暴露
 a 
 b 


未暴露
 c 
 d 


 
 or =（ad）/（bc）
现在，我想知道该属性即使在逻辑回归中也是如此，同时调整了协变量。例如，假设我符合对年龄调整的暴露结果关系的逻辑回归：
 logit（pr（结果|曝光，年龄））=拦截 + beta1 *暴露 + beta2 * age 
，相应的（调整后的）优势比为：exp（beta1）
如果我通过曝光来翻转结果怎么样？是否有任何数学原因认为我会得到类似的赔率估计值？例如：
 logit（pr（暴露|结果，年龄））=拦截 + beta1 *结果 + beta2 * age 
我已经使用了一些实验数据尝试了此操作，而对于我指定了结果暴露关系的方向，似乎对Beta1获得的估计值非常相似。但是我无法弄清楚这是偶然的，还是它是“优势比”的“属性不变性”的属性的扩展。]]></description>
      <guid>https://stats.stackexchange.com/questions/661623/odds-ratio-invariance-how-about-when-adjusted-in-logistic-regression</guid>
      <pubDate>Thu, 20 Feb 2025 12:45:20 GMT</pubDate>
    </item>
    <item>
      <title>样本量计算在事故分析中以危险比为非效率终点</title>
      <link>https://stats.stackexchange.com/questions/661608/sample-size-calculation-in-time-to-event-analysis-with-hazard-ratio-as-non-infer</link>
      <description><![CDATA[我正在对200名患者的数据集进行回顾性分析，这些患者接受了A或B治疗，然后在复发和死亡方面进行了研究。我已经进行了竞争风险（复发和非释放死亡率（NRM））以及使用COX pH模型的总体生存分析进行的生存分析。现在，我试图找出样本量是否足够大以确认非效率（Ni），Ni-Margin为HR 1.5，功率为0.9和0.05。 （或者，Ni-Margin不是危险比，而是中位生存时间或在24个月时失去无事件生存状态的累积发生率。不知道我的治疗组的标准偏差 /标准误差 /危险率 /生存率（治疗B）。我根本找不到有关如何根据一组的生存分析和定义的劣等缘的生存分析来计算样本量的建议。
我尝试的一种相当绝望的方法是使用建议的方程式在功率= 0.9和alpha = 0.05的条件下估算样本量。 （21 *（SD（对照）/ni-Margin）^2）在给定的MWE中，我将其应用于样本量以确认非效率，如果治疗组累积的发生率是2年失去无事件生存状态的。在对照组的95％CI下限累积发生率的95％高于2年时失去无事件生存状态的累积发病率。绝对看起来不正确，也不是我想使用的措施。
任何帮助将不胜感激！
 库（生存）
图书馆（dplyr）
图书馆（ggfortify）

患者＆lt;  -  c（seq（1,100））
状态＆lt;  -  rbinom（n = 100，size = 1，prob = 0.6）
ftime＆lt;  - 示例（尺寸= 100，x = 1:60，替换= true）
复发＆lt;  -  rbinom（n = 100，尺寸= 1，prob = 0.3）
df＆lt;  -  cbind（患者，状态，FTIME，复发）
as.data.frame（df） - ＆gt; DF

for（i in 1：nrow（df））{
  df  $ time_relapse [i]＆lt;  -  ifelse（df [i，“复发”] == 1，示例（size = 1，x = df $  ftime [i ] -1），NA）
}

df  $ nrm＆lt;  -  ifelse（df $  status == 1＆amp; df $ repapse == 0，1，0）

df  $ time_efs＆lt;  -  pmin（df $  ftime，df $ time_relapse，na.rm = true）

df％＆gt;％
  突变（cistat = case_when（复发== 1〜1，
                            nrm == 1〜2，
                            复发== 0＆amp; nrm == 0〜0）） - ＆gt; DF

df  $ cistat＆lt;  - 因子（df $  cistat，latver = c（0,1,2），labels = c（＆quort&#39;censored; ，“ NRM”）

fit＆lt;  -  survIt（surv（time_efs，cistat）〜1，data = df）

＃功率的样本量计算= 0.9，alpha = 0.05，参考2年无事件生存 
强化（fit）％＆gt;％
  过滤器（event ==;（s0）＆quot;） - ＆gt; fit_s0

fit_s0 [whe.min（abs（fit_s0 $ time -time -24）），]  - ＆gt; power_data_2y＃连续24个月的时间

21 * 
  （（（power_data_2y  $ std.err * sqrt（max（fit_s0 [，“ n.risk”）））） /＃将std.err转换为SD
 （power_data_2y $  pstate -power_data_2y $ low）
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661608/sample-size-calculation-in-time-to-event-analysis-with-hazard-ratio-as-non-infer</guid>
      <pubDate>Wed, 19 Feb 2025 22:09:21 GMT</pubDate>
    </item>
    <item>
      <title>AR [I] mA [x]模型比标准回归有什么好处</title>
      <link>https://stats.stackexchange.com/questions/661601/what-is-the-benefit-of-arimax-models-over-standard-regression-with-lagged-pr</link>
      <description><![CDATA[我试图更深入地了解时间序列模型，我一直回到这种根本的困惑。如果我们成功地通过包括结果的滞后版本和其他滞后预测变量来显式地模型   ，我们为什么需要ARMAS？当我们错误地忽略必要的自相关预测变量并且在错误中存在残留的自相关时，ARMA是否只是涵盖了案例（即，如果我们有正确的滞后或变量，那么简单的回归在理论上就足够了，但从来没有实践）？）？
使用滞后的预测变量（称为Cochran-Orcutt估计？）似乎令人信服，但据说您也失去了效率。省略的可变自相关和效率丧失是在简单回归中使用ARMA模型的基本原因，还是我缺少某些内容？]]></description>
      <guid>https://stats.stackexchange.com/questions/661601/what-is-the-benefit-of-arimax-models-over-standard-regression-with-lagged-pr</guid>
      <pubDate>Wed, 19 Feb 2025 18:56:13 GMT</pubDate>
    </item>
    <item>
      <title>了解一个样本比例的功率公式：受限与无约束的方法</title>
      <link>https://stats.stackexchange.com/questions/661597/understanding-power-formulas-for-one-sample-proportion-constrained-vs-unconstr</link>
      <description><![CDATA[我遇到了以下公式，以估计进行平等的一个样本比例测试（对于大样本）：
  $$
1- \ beta = \ phi \ left（\ frac {\ sqrt {n} | \ delta | -z _ {\ alpha/2} \ sqrt {\ pi_0（1- \ pi_0）}} 1- \ pi_1）}} \ right）
$$  
其中 $ \ pi_0 $ 和 $ \ pi_1 $ 分别是NULL和NULL和替代假设， $ \ delta = \ pi_0- \ pi_1 $ ， $ z _ {\ alpha/2} $ 是标准常规变量 $ z $  at  $ \ alpha/2 $ ， $ \ beta $ 是II型错误率下的II类错误率替代假设， $ \ phi $   $ z $ 。。
在这个公式中让我感到困惑的是术语 $ \ pi_0（1- \ pi_0）$ ，这表明，在替代假设下，测试统计量的差异 $ z $ 在某种程度上受零假设下比例方差的影响。
看似更明智的我认为公式将是：
  $$
1- \ beta = \ phi \ left（\ frac {\ sqrt {n} | \ delta |} {\ sqrt {\ sqrt {\ pi_1（1- \ pi_1）}}} -z _ {
$$  
这意味着在替代假设下，测试统计量的方差 $ z $ 仅受的影响$ \ pi_1（1- \ pi_1）$   - 而不是 $ \ pi_0（1- \ pi_0）$ ，这对我来说更有意义，因为功率是 $ z $ 仅在替代假设下进行统计。
我一直在寻找一种解释，发现两个公式都出现在临床研究中的样本量计算中（第二版，2008年）      by Chow，Shao和Wang。在  的大型样本测试（第84-88页）中，作者将第一个公式称为约束公式，第二个公式为无约束的公式。虽然在 4.1.5备注 中，他们讨论了他们的不同假设并在权力方面进行比较，但他们没有明确解决其相对固有有效性。
这导致了我的问题：为什么在这种情况下，有限的公式（第一个）在不受约束的公式上被认为是正确的？ 
任何见解或解释都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661597/understanding-power-formulas-for-one-sample-proportion-constrained-vs-unconstr</guid>
      <pubDate>Wed, 19 Feb 2025 17:30:11 GMT</pubDate>
    </item>
    </channel>
</rss>