<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 20 Dec 2024 15:17:13 GMT</lastBuildDate>
    <item>
      <title>GAM 留一交叉验证 (LOOCV)，适用于较大的模型</title>
      <link>https://stats.stackexchange.com/questions/659016/gam-leave-one-out-cross-validation-loocv-for-biggish-models</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659016/gam-leave-one-out-cross-validation-loocv-for-biggish-models</guid>
      <pubDate>Fri, 20 Dec 2024 14:44:07 GMT</pubDate>
    </item>
    <item>
      <title>损失函数在低值时对错误进行更多的惩罚</title>
      <link>https://stats.stackexchange.com/questions/659013/loss-function-that-penalizes-errors-more-at-low-values</link>
      <description><![CDATA[我正在训练深度学习模型来预测某些设备的剩余使用寿命 (RUL)。RUL 是设备预计发生故障前剩余时间的估计值。当 RUL 较低时，准确的预测尤其重要，因为您几乎没有时间做出反应来计划维护或减轻潜在损害。
传统损失函数的一个限制是，它们会统一惩罚预测误差的幅度，而不管实际 RUL 值是多少。例如，$(y,\hat y) = (90, 100)$ 和 $(y,\hat y) = (0, 10)$ 两种情况都会导致相同的平均绝对误差 (MAE) 10。但是，后一种情况更为严重，应受到更严厉的惩罚。
为了解决这个问题，我尝试使用相对误差作为损失函数：
$$L=\frac{\mathrm{abs}(y-\hat{y})}{y+\epsilon},$$
其中 $\epsilon &gt; 0$ 是一个较小的值，以避免被零除。尽管进行了这样的修改，结果还是不令人满意，模型的表现不如预期。
因此，有没有更有效的方法来设计一个在低 RUL 值时强调错误的损失函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/659013/loss-function-that-penalizes-errors-more-at-low-values</guid>
      <pubDate>Fri, 20 Dec 2024 14:05:05 GMT</pubDate>
    </item>
    <item>
      <title>在回归中独立性是否意味着条件独立性？</title>
      <link>https://stats.stackexchange.com/questions/659012/does-independence-imply-conditional-independence-in-regression</link>
      <description><![CDATA[我正在阅读统计学习的要素，并看到了这句话：

&quot;从统计学的角度来看，如果训练观测值$(x_i, y_i)$代表从其总体中独立随机抽取的样本，则该标准是合理的。即使 $x_i$ 不是随机抽取的，如果 $y_i$ 在给定输入 $x_i$ 的情况下是条件独立的，则该标准仍然有效。&quot;

为了探索这一点，我考虑了两种情况下的联合似然：

情况 1：$(x_i, y_i)$ 完全独立
如果 $(x_i, y_i)$ 对完全独立，则联合似然为：
$$
P(x_1, y_1, \dots, x_n, y_n \mid \theta) = \prod_{i=1}^n P(y_i \mid x_i, \theta) P(x_i)
$$

案例 2：给定 $x_i$，$y_i$ 的条件独立性&gt;
如果给定 $x_i$，$y_i$ 是条件独立的，则联合似然为：
$$
P(x_1, y_1, \dots, x_n, y_n \mid \theta) = \left( \prod_{i=1}^n P(y_i \mid x_i, \theta) \right) P(x_1, x_2, \dots, x_n)。
$$


在这两种情况下，与最大化 $\theta$ 相关的可能性简化为：
$$
L(\theta) = \prod_{i=1}^n P(y_i \mid x_i, \theta),
$$
表明条件分解是相同的。这让我很疑惑：
问题：
假设$(x_i, y_i)$完全独立（案例 1）是否意味着在给定$x_i$的情况下，$y_i$具有条件独立性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659012/does-independence-imply-conditional-independence-in-regression</guid>
      <pubDate>Fri, 20 Dec 2024 13:04:15 GMT</pubDate>
    </item>
    <item>
      <title>使用麦当劳 Omega 作为非加权总和评分的可靠性度量是合理的</title>
      <link>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</link>
      <description><![CDATA[在最近的文献中，报告麦当劳欧米茄作为可靠性估计值显然比报告系数 alpha 更受青睐（例如 McNeish，2017）。一个经常给出的论点是，系数 alpha（或 Cronbach&#39;s alpha）假设（本质上）tau-euqivalent 测量模型，即因子载荷必须相等，而麦当劳欧米茄允许不同的载荷。由于对 omega 有多种看法，为了简单起见，我们只关注单维尺度上的总 omega，如 McNeish (2017) 所指定的那样：

（其中 $\lambda_i$ 是因子载荷，$\theta_{ii}$ 是第 i 项的误差/残差方差）
在文章中，McNeish 写道：

Omega (McDonald, 1970, 1999）是常用的复合信度测量方法，可用于多种软件程序。Omega 专为同类量表而设计，其中项目与被测构造的相关程度各不相同（即，在因子分析设置中，不会假设负载相等）。换句话说，不假设 tau 等价。当量表中的项目按单位加权以形成总量表分数但量表本身为同类时，复合信度是合适的（Bentler，2007；Geldhof 等人，2014）。单位加权量表意味着量表的总分是通过将各个项目的原始分数（或反向编码的原始分数，如果适用）相加来计算的：每个项目的权重相等。

我觉得这违反直觉：例如，假设 CFA 表明同类模型（自由载荷）比更严格的 tau 等效模型更适合样本数据，因此我们决定使用 omega 而不是系数 alpha。然而，后续分析将使用基于同等权重项目计算得出的总和/平均分数，尽管我们刚刚在 CFA 中表明这种类型的测量模型无法很好地拟合我们的数据。
我的问题：
有人能否提供一些合理的解释，为什么对于由同等权重项目组成的分数，报告麦当劳的 omega 是有意义的？

来源：
McNeish，D. (2017)。感谢系数 alpha，我们将从这里开始。心理方法，23(3)，412–433。https://doi.org/10.1037/met0000144]]></description>
      <guid>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</guid>
      <pubDate>Fri, 20 Dec 2024 12:24:36 GMT</pubDate>
    </item>
    <item>
      <title>rm-ANOVA 中的事后 Bonferroni 校正：常规调整多少次</title>
      <link>https://stats.stackexchange.com/questions/659007/post-hoc-bonferroni-correction-in-rm-anova-how-many-times-to-adjust-for-convent</link>
      <description><![CDATA[我以为，方差分析后的后验 Bonferroni 校正将需要调整研究中进行的所有统计比较（例如，2 个成对比较 * 10 个变量 = 20）。
然而，我越来越多地注意到，后验 Bonferroni 校正仅适用于对单个变量进行的测试次数的论文。
本文的表 2 就是一个例子。根据脚注，尽管测试了如此多的变量，但调整后的 p 值截止值为 0.0125。
如果有人可以对此进行一些说明，我将不胜感激，非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659007/post-hoc-bonferroni-correction-in-rm-anova-how-many-times-to-adjust-for-convent</guid>
      <pubDate>Fri, 20 Dec 2024 09:58:38 GMT</pubDate>
    </item>
    <item>
      <title>策略改进定理的使用问题[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659005/policy-improvement-theorem-usage-issues</link>
      <description><![CDATA[在 Sutton 和 Barto 的《强化学习》一书（2018 年版）第 99-100 页中，需要证明 $\epsilon$-greedy 是对 $\epsilon$-soft 策略的改进，他们是如何使用策略改进定理的，因为之前讨论的定理适用于确定性策略，而这里并非如此。]]></description>
      <guid>https://stats.stackexchange.com/questions/659005/policy-improvement-theorem-usage-issues</guid>
      <pubDate>Fri, 20 Dec 2024 08:44:36 GMT</pubDate>
    </item>
    <item>
      <title>使用重复横断面调查数据进行回归分析[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659004/regression-analysis-using-repeated-cross-sectional-survey-data</link>
      <description><![CDATA[我有一个使用相同调查工具连续 5 年收集的数据集。每年的受访者各不相同，但调查问题保持不变。
我有兴趣研究几个独立变量与分类结果变量 (Y) 之间的关系。

为这五年中的每一年运行单独的逻辑回归模型是否合适？

是否有必要验证受访者的资料在五年内是否一致？

]]></description>
      <guid>https://stats.stackexchange.com/questions/659004/regression-analysis-using-repeated-cross-sectional-survey-data</guid>
      <pubDate>Fri, 20 Dec 2024 08:32:25 GMT</pubDate>
    </item>
    <item>
      <title>$E[X|XY]$ 其中 $(X,Y)$ 是从单位正方形 $[0,1]^2$ 均匀选取的任意坐标</title>
      <link>https://stats.stackexchange.com/questions/659003/exxy-where-x-y-is-any-coordinate-uniformly-selected-from-the-unit-squar</link>
      <description><![CDATA[我正在尝试解决这个问题，但不确定我是否正确。
问题：查找 $E[X|XY]$，其中 $(X,Y)$ 是从单位正方形 $[0,1]^2$ 中均匀选择的任何坐标
我尝试过的方法：让 $Z=XY$ 然后 $P(X \leq x | Z=z) = 1 - \int^{1}_{z} \int^{1}_{z/x} dy dx = 1-z+z\ln(z)$，$ 0&lt;z&lt;1$。
我卡在这里，因为我不知道如何获取 $X|Z=z$ 的 PDF，以便我可以继续计算 $E[X|Z=z]$。我做错了什么？还有其他正确的方法吗？（也许我应该使用双重期望定理？）]]></description>
      <guid>https://stats.stackexchange.com/questions/659003/exxy-where-x-y-is-any-coordinate-uniformly-selected-from-the-unit-squar</guid>
      <pubDate>Fri, 20 Dec 2024 08:00:07 GMT</pubDate>
    </item>
    <item>
      <title>lmer 中嵌套随机效应的排序</title>
      <link>https://stats.stackexchange.com/questions/659002/ordering-of-nested-random-effects-in-lmer</link>
      <description><![CDATA[我在许多不同的来源中读到，在 lmer() 中指定嵌套随机效应可以通过“(1|A) + (1|A:B)”或“(1|A/B)”来完成，其中 B 嵌套在 A 中。然而令人困惑的是，当我使用任一语法运行模型时，随机效应是相同的，但嵌套的顺序在输出中以及在使用 ranef() 函数提取随机效应时会发生变化。任何帮助都将不胜感激，我在下面提供了一个示例输出。]]></description>
      <guid>https://stats.stackexchange.com/questions/659002/ordering-of-nested-random-effects-in-lmer</guid>
      <pubDate>Fri, 20 Dec 2024 07:55:40 GMT</pubDate>
    </item>
    <item>
      <title>多元 PDF 变量变化证明</title>
      <link>https://stats.stackexchange.com/questions/658990/proof-change-of-variables-for-multivariate-pdf</link>
      <description><![CDATA[在阅读规范化流时，我熟悉了一维分布的变量变化。如果 $Z$ 是随机变量，并且 $X=f(Z)$ 是单调的，逆为 $Z = h(X) = f^{-1}(X)$，则我们有：
$$
p_X(x) = \frac{\partial P(X \le x)}{\partial x} = \frac{\partial P(Z \le z)}{\partial z}\big|\frac{\partial z}{\partial x}\big| = p_Z\big(h(x)\big)\big|h&#39;(x)\big|
$$
对于随机向量 $Z$ 和 $X=\mathbf{f}(Z)$，有一个非常相似的公式。
$$
p_X(\mathbf{x}) = p_Z\big(\mathbf{f}^{-1}(\mathbf{x})\big)\Big| \det\big( \frac{\partial\mathbf{f}^{-1}(\mathbf{x})}{\partial \mathbf{x}} \big) \Big|
$$
但我无法正式证明这一点。有什么建议吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658990/proof-change-of-variables-for-multivariate-pdf</guid>
      <pubDate>Fri, 20 Dec 2024 01:46:59 GMT</pubDate>
    </item>
    <item>
      <title>分位数的贝叶斯区间估计</title>
      <link>https://stats.stackexchange.com/questions/658982/bayesian-interval-estimate-for-a-quantile</link>
      <description><![CDATA[这个问题是为了澄清后验分布和后验预测分布是否可用于创建分位数的区间估计。考虑以下设置：
假设我有 $X_i\stackrel{iid}{\sim} N(\mu, \sigma^2)$，其中 $i=1,...,n$。为了论证的目的，我并不关心先验的形式是什么，但让我们假设我在 $\mu$ 和 $\sigma^2$ 上都放置了先验。现在，我可以运行我的 MCMC 采样器并获取 $\mu$ 和 $\sigma^2$ 的后验样本（我们将它们称为 $\mu_{*b}$ 和 $\sigma^2_{*b}$，其中我有 $b=1,...,B$ 个）。现在，给定 $X_i$ 的分布，我可以通过以下方式获得后验样本，例如第 95 分位数：
$$q_b= \mu_{*b} + z_{0.95}\sigma_{*b}$$
其中 $z_{0.95}$ 是标准正态分布的第 95 分位数。此外，由于这是基于样本的，我有一个后验分位数的分布，并且可以取这些后验分位数样本的分位数来获得不确定性区间估计。到目前为止一切顺利。
现在，我很好奇是否有办法使用后验预测分布来做到这一点？例如，在相同的设置下，后验预测分布可能是 $y_{\text{new}}\sim N(\mu_{\text{new}}, \sigma^2_{\text{new}})$，因此我可以模拟该分布的 $y_{\text{new}}$ 值并取第 95 分位数来估计它。但是，这个估计没有像后验分布那样的不确定性量化。我想总结一下我的问题，

基于后验分布和后验预测分布的结果是否应该匹配，并且
后验预测分布是否应该为第 95 分位数产生不确定性估计（以区间的形式）？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658982/bayesian-interval-estimate-for-a-quantile</guid>
      <pubDate>Thu, 19 Dec 2024 19:37:12 GMT</pubDate>
    </item>
    <item>
      <title>如何针对伽马分布改进 DKW 不等式？</title>
      <link>https://stats.stackexchange.com/questions/658981/how-can-the-dkw-inequality-be-refined-for-the-gamma-distribution</link>
      <description><![CDATA[Dvoretzky-Kiefer-Wolfowitz (DKW) 不等式为经验 CDF $\hat F_n(x)$ 和分布支持面上任意位置的总体 CDF $F_n(x)$ 之间的绝对误差提供了一个统一的、不受分布影响的界限。但是，DKW 界限对于特定分布通常比较宽松。从一般意义上讲，它对于收敛速度最慢的情况也必须成立，但我预计这些界限对于常用分布（如伽马分布）来说过于悲观。
伽马分布对我来说是一个值得入手的起点，因为它与事件发生时间分布相关。我研究了各种离散事件模拟，随着时间的推移，我注意到事件发生时间分布通常与 Gamma 分布（或指数分布等特殊情况）非常吻合。最糟糕的情况是，我看到了似乎是 Gamma 的混合，但这比我想在这篇文章中介绍的内容更为宏大。
对于 Gamma 分布 $\operatorname{Gamma}(\alpha,\beta)$，是否有更严格的误差容差可以利用 Gamma CDF 的属性？例如：

我们能否利用伽马 CDF 的平滑度或尾部行为来推导出更严格的界限？
作为 DKW 不等式的特殊情况，伽马分布是否有具体结果？


我通常通过模拟来处理这类事情。我选择一组总体参数、一系列样本大小和一些重复（例如，根据判断，在 $[10^4, 10^6]$ 中），然后估计所述绝对误差和概率。这些模拟研究并不难设置，但最好只选择一个样本大小，并至少知道我保证的结果正确性的界限。另一件事是，这些模拟研究在样本大小和公差方面也存在估计（抽样）误差，这就引发了一个元问题：我的模拟研究需要多大才能估计样本量？🤭]]></description>
      <guid>https://stats.stackexchange.com/questions/658981/how-can-the-dkw-inequality-be-refined-for-the-gamma-distribution</guid>
      <pubDate>Thu, 19 Dec 2024 18:45:43 GMT</pubDate>
    </item>
    <item>
      <title>本文中的随机分位数残差</title>
      <link>https://stats.stackexchange.com/questions/658974/randomized-quantile-residuals-in-this-paper</link>
      <description><![CDATA[我正在阅读 Emrah Altun 和 Gauss M. Cordeiro 撰写的文章“单位改进的二阶林德利分布：推理和回归建模”。我想复制他们的一个结果。我正在尝试为 Beta 回归制作随机分位数残差图，但我没有得到相同的结果。他们有这个图
$\hskip2in$ 
但是我明白了

使用 qqPlot 和 residuals。并且至少从视觉上看它们并不相似，例如有一个大约为 -3 的值，但在我的例子中却不是这样。我的代码是
y = c(2.640, 0.596, 0.680, 2.190, 4.560, 2.140, 0.410, 
0.530, 0.750, 0.280, 4.390, 3.390, 5.190, 0.800, 2.160, 
2.640, 0.060, 2.549, 0.930, 0.310, 0.540, 7.750, 0.470, 
2.810, 1.760, 3.170, 1.760, 1.010, 0.990, 1.318, 0.550, 
                  0.040、1.374、2.890)
y = y/100
x = c(30.78, 57.87, 121.52, 90.17, 45.39, 11.08, 55.92, 51.54, 
                56.31、43.34、11.64、20.85、21.99、276.22、28.81、27.56、 
                30.6、21.02、5.93、7.24、380.1、15.76、305.44、8.94、 
                48.05、5.41、23.68、3.56、14.53、41.9、 71.7, 162.75, 
61.86, 40.43)
x = x/100
beta_model = betareg(y ~ x)
r_i = residuals(beta_model, type = &quot;quantile&quot;)
car::qqPlot(r_i, main = &quot;Beta&quot;, ylab = &quot;r_i&quot;)

如有任何关于此主题的帮助或参考，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658974/randomized-quantile-residuals-in-this-paper</guid>
      <pubDate>Thu, 19 Dec 2024 16:56:41 GMT</pubDate>
    </item>
    <item>
      <title>混合模型中部分合并聚类估计消失或超出总体估计</title>
      <link>https://stats.stackexchange.com/questions/658964/partial-pooled-cluster-estimates-going-away-or-beyond-grand-estimates-in-mixed-m</link>
      <description><![CDATA[我认为我对混合模型中部分池化的主要目标和特征有相当好的理解。然而，部分池化的实际执行中有一些细节与我期望从各个集群得到的行为相冲突。例如，在下面我将链接的所有三个演示中，使用了各种表达式来表明特定于集群的截距和斜率估计应该向样本中相应的总体估计移动（也允许保持静止）。但是，如果您仔细跟踪集群估计从无池化到部分池化版本的一些可视化运动，您就会看到集群估计实际上如何沿着各个轴远离总体估计。在某些情况下，集群估计值也可能超出总体估计值。
https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/
https://towardsdatascience.com/when-mixed-effects-hierarchical-models-fail-pooling-and-uncertainty-77e667823ae8
https://m-clark.github.io/posts/2019-05-14-shrinkage-in-mixed-models/
至少定义集群截距重新定位的公式（参见上面的中间链接和此视频讲座）表明，单个集群的移动范围应限制在初始无合并位置和总体估计值之间（据我所知，如有必要，请纠正我）。但是，上述相互矛盾的观察结果是否与同一模型中随机截距和斜率的存在及其相关性有关？还没有拿尺子，但我的直觉告诉我，虽然聚类估计值可以沿着单个轴发散，但也许在部分池化期间，整体斜边会变小。错误：我实际上拿了尺子，通过从屏幕上测量，由于部分池化，至少有一个整体距离增加了（参见最后列出的网站、df = create_data(sd_int = .25, sd_slope = 1) 的图和右上角的一个聚类）。
如果观察到的行为不是由错误引起的，而且我没有误解什么，那么原因能否从直观的实际意义上得到解释。为什么这种行为是有益的，尽管它似乎与部分池化的主要原则不一致。为什么不让所有的聚类估计值都沿着截距和斜率轴更接近总体估计值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658964/partial-pooled-cluster-estimates-going-away-or-beyond-grand-estimates-in-mixed-m</guid>
      <pubDate>Thu, 19 Dec 2024 12:35:28 GMT</pubDate>
    </item>
    <item>
      <title>针对群体数据的最自然机器学习模型类</title>
      <link>https://stats.stackexchange.com/questions/658871/most-natural-class-of-machine-learning-models-for-group-data</link>
      <description><![CDATA[我有一个学生考试成绩的数据集，如下所示：
班级 ID 班级大小 学生编号 智商 小时数 分数 前几名
1 3 3 101 10 98 1
1 3 4 99 19 80 0
1 3 6 130 3 95 0
2 5 4 93 5 50 0
2 5 5 103 9 88 0
2 5 8 112 12 99 0
2 5 1 200 10 100 1
2 5 2 90 19 78 0
3 2 5 100 12 84 0
3 2 7 102 13 88 1

我想建立一个机器学习模型，试图预测谁将成为前几名对于任何给定的 Class_ID，使用 IQ 和 Hours（学习小时数）作为特征，计算班级（即具有最高 Score 的学生）的得分。
换句话说，输入是班级中每个学生（例如 1 到 n）的 IQ 和 Hours，输出是概率向量 (p_1, ..., p_n)，其中每个 p_i 是学生 i 在班级中得分最高的概率。
这是我尝试过的：

最简单的方法是对 Score 使用回归，然后确定谁将在班级中取得最高分数。这种方法的问题在于，它不会产生谁最有可能在任何给定类别中获得最高分数的概率。

由于这是一个排名问题，因此自然的学习模型类别是使用 XGBoost 中的 XGBRanker 或 lightgbm 中的 LGBMRanker。不幸的是，输出是 相关性分数 列表，而不是概率列表，概率列表在概率方面没有自然解释。


解决这个问题的一个明显方法是在 xgboost 中的相关性分数上应用 softmax，但没有直接有意义的概率解释，如基于能量的模型（如 RBM 的能量函数）。事实上，我曾尝试过这样做，但概率变得非常极端（大多数概率集中在每个班级的一名学生身上，导致测试结果不佳且方差较大）

另一类学习模型是Top上的分类模型，如逻辑回归/决策树。但是，这种方法有两个主要问题。

首先，将每个学生视为训练样本不是一个好方法，因为例如，同一个班级可能有两个非常聪明（高智商）和勤奋（高小时数）的学生，如果很多班级都有很多这样的学生，那么传统的模型（如基于逻辑/树的模型）可能会难以进行训练。
为了解决上述将单个学生视为训练样本的问题，我们可以将每个班级视为一个训练样本。为此，我们“扁平化”我们的数据集并对 Top 进行多类分类：
Class_ID Class_size IQ_1 IQ_2 IQ_3 IQ_4 IQ_5 Hours_1 Hours_2 Hours_3 Hours_4 Hours_5 Score_1 Score_2 Score_3 Score_4 Score_5 Top
1 3 101 99 130 NaN NaN 10 19 3 NaN NaN 98 80 95 NaN NaN 3 
2 5 93 103 112 200 90 5 9 12 10 19 50 88 99 100 78 1
3 2 100 102 NaN NaN NaN 12 13 NaN NaN NaN 84 88 NaN NaN NaN 7

这种方法的问题在于，数字每个班级的学生人数不同，因此特征矩阵变得非常稀疏（因为不同班级的学生人数可能非常不同）
因此，逻辑模型/普通前馈神经网络/基于树的模型似乎也不适用于这类群体数据。
所以我的问题是，是否有任何自然的机器学习模型可以处理这些“群体数据”，就像我上面的数据集一样？
此外，在这个问题中，我只关心最终名列前茅的人（或者可能是前三名），所以排名并不是那么重要（例如，知道学生 4 排名第 11 位，学生 8 排名第 12 位并不重要）
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/658871/most-natural-class-of-machine-learning-models-for-group-data</guid>
      <pubDate>Tue, 17 Dec 2024 11:40:53 GMT</pubDate>
    </item>
    </channel>
</rss>