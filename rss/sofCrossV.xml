<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 26 Jun 2024 06:22:01 GMT</lastBuildDate>
    <item>
      <title>在 LCA 中选择类别数</title>
      <link>https://stats.stackexchange.com/questions/649921/choosing-number-of-classes-in-lca</link>
      <description><![CDATA[我是一名本科生，对拟合优度检验有点困惑。我正在尝试使用 R 中的 poLCA 包为潜在类别分析选择适当的类别数。我的数据有 89 个观察到的二元变量，我正在比较拟合优度统计数据以确定正确的类别数。
AIC 和 BIC 值随着类别数的增加而下降，但它们在第 4 个类别之后趋于稳定，对数似然值在第 4 个类别之后也趋于稳定。话虽如此，BIC 和 AIC 值即使在 10 个类别之后也会继续下降，尽管幅度很小。
我认为 4 个类别合适是错误的吗？还是我应该做完全不同的事情？
我也喜欢任何阅读材料，总是希望学习。谢谢。
&gt; aic_值
[1] 509311.8 456245.0 436084.9 426650.1 422403.6 417608.8 413242.8 411011.4 408163.3 406278.5 404276.3
&gt; bic_值
[1] 510443.8 457946.6 438356.2 429491.0 425814.1 421588.9 417792.5 416130.7 413852.2 412537.0 411104.5
&gt; log_lik
[1] -254498.9 -227886.5 -217727.5 -212931.0 -210728.8 -208252.4 -205990.4 -204795.7 -203292.6 -202271.2 -201191.2



]]></description>
      <guid>https://stats.stackexchange.com/questions/649921/choosing-number-of-classes-in-lca</guid>
      <pubDate>Wed, 26 Jun 2024 05:21:32 GMT</pubDate>
    </item>
    <item>
      <title>使用 JAGS 对分数 Caputo 模型进行参数估计〜Jags 模型中的错误 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649919/using-jags-for-parameter-estimation-for-a-fractional-caputo-model-error-in-jag</link>
      <description><![CDATA[我正在研究贝叶斯估计，目的是使用 Caputo 导数找到分数模型的后验分布。
但是，当我编译拟合模型时，我收到以下错误，并且我无法识别它。
&gt; fit.caputo&lt;-jags(data=caputo.data, inits = caputo.inits1, parameters.to.save= caputo.params,
+ n.chains =2, n.iter = 10000, n.burnin=1000,model.file=&quot;caputo.jags&quot;)
module glm 已加载
编译模型图
解析未声明的变量
删除模型

jags.model(model.file, data = data, inits = init.values, n.chains = n.chains, 中出现错误： 
运行时错误：
第 10 行编译错误。
数组 W 的维度不一致

代码如下：
cat(&quot;
model{
# unlikely
for(t in 1:N1)
{
y1[t] ~ dnorm(V[t], tau)
y2[t] ~ dnorm(W[t], tau)
for(k in 1:t){
V[t+1, k]= V[1]+ ((h^q)/(exp(loggam(q+1)))) * sum ( ((t-k+1)^(q)-(t-k)^(q))* (r1*V[k]*(1-V[k]/k1) -a*V[k]*W[k]) )
W[t+1, k]= W[1]+ ((h^q)/(exp(loggam(q+1)))) * sum ( ((t-k+1)^(q)-(t-k)^(q))* (a*V[k]*W[k]-r2*W[k]) )
}
}
V[1]&lt;-v0
W[1]&lt;-w0
#tamaño de paso
h=0.01
#distribucuiones iniciales
a ~ dnorm(0.06,10000)T(0,1)
k1 ~ dnorm(50,1)
r1 ~ dnorm(1.8,1000)T(0,) 
r2 ~ dnorm(0.24,1000)T(0,)
q ~ dunif(0.9,1)
sigma2 &lt;- 1/tau
tau ~ dgamma(1,1) # media =1 y var=10
}&quot;, file=&quot;caputo.jags&quot;, fill=T)

之前，我从系统的数值解生成了一个合成数据集（对于为此目的使用分数前向欧拉方法）。
我考虑在 JAGS 中添加一个数值向量来存储 s1, s2, s3 的信息。
但是，我认为您不能将此函数 s1&lt;-s2&lt;-matrix(0,N1,N1) 嵌入 JAGS 模型中，因为 JAGS 有自己的 BUGS 语言解释器，它完全独立于 R 解释器。
提前感谢您的建议]]></description>
      <guid>https://stats.stackexchange.com/questions/649919/using-jags-for-parameter-estimation-for-a-fractional-caputo-model-error-in-jag</guid>
      <pubDate>Wed, 26 Jun 2024 04:02:58 GMT</pubDate>
    </item>
    <item>
      <title>寻找 ANCOVA 类型 glmm 中变量重要性的修改</title>
      <link>https://stats.stackexchange.com/questions/649917/looking-for-a-modification-of-variable-importance-in-ancova-type-glmm</link>
      <description><![CDATA[这个问题是关于一个我认为应该存在的统计概念。我想知道它是否有名字，并希望有一个可以实现它的 R 包。它与变量重要性/主导性有关，但我感兴趣的不是考虑包含变量的模型的整体改进，而是它如何影响模型中关键固定因素的估计（精度和偏差）。我可以用一个例子更好地解释。
我感兴趣的是估计昆虫数量随时间的变化。数据是光诱捕器中个体的数量，光诱捕器每周运行一次，持续两年，然后在 30 年后重复运行。以一个物种为例，使用仅包含主效应“时间”的模型，我发现没有显着差异。时间效应的估计值为 0.035（考虑到对数链接，这是 3.6% 的增长），但估计值的标准差是这个的 10 倍。
捕获量的大部分变化是由于该物种的季节性和每周采样。在模型中添加二次方周分量可以得到更好的模型，ΔAIC 为 -159，时间估计值现在为 0.25（增加了 28%），但标准误（0.26）与估计值大致相等，因此仍然不足以声称该物种数量有所增加。
另一个改进模型的变量是气温（影响昆虫飞行活动），其 ΔAIC 为 -18。但现在，随时间变化的估计值为 -0.76（减少 50%），标准误为 0.25。这种巨大变化的原因是过去 30 年来平均气温上升——昆虫活动的增加掩盖了数量减少。如果包括温度而不是季节性，则 ΔAIC 为 -125，因此按分步程序，季节性比温度更受青睐，但温度对时间效应的估计影响最大。如果这是一个设计好的实验（并且空气温度在时间上保持平衡），则不会出现此特定案例的某些方面，但这是一个现实世界的问题，我无法控制气候。
另一个复杂因素是残差中存在时间自相关性，因此使用 glmmTMB，我为自相关性引入了一个随机效应（Ornstein-Uhlenbeck，因为有一些缺失的星期，并且自相关性为正）。该模型将如下所示：
model&lt;-glmmTMB (spX ~ Time + week + I(week^2) + airT+ou(seq + 0 | group), data=datx, family=nbinom2)

估计的自相关性为 0.61，ΔAIC 为 -18。时间效应现在为 -0.96（减少了 62%），但 s.e。已增加到 0.46，因此效果较大但“不太显著”。显然，模型的这三个组成部分（季节性、温度和自相关）都很重要（原因略有不同），但还有其他潜在的协变量（例如月亮、云、风、雨）会影响光诱捕器捕获的昆虫，其中一些会随着时间而平衡（例如气压），但有些可能表现得更像空气温度，排除它们会在估计中留下偏差。
是否有一个框架可以评估所有这些变量在获得时间效应的精确和无偏估计方面的相对效用？我如何证明和量化我对其他昆虫学家的建议：“你真的应该测量这个协变量”。]]></description>
      <guid>https://stats.stackexchange.com/questions/649917/looking-for-a-modification-of-variable-importance-in-ancova-type-glmm</guid>
      <pubDate>Wed, 26 Jun 2024 02:56:04 GMT</pubDate>
    </item>
    <item>
      <title>似然比检验对于有限样本是否“最佳”？</title>
      <link>https://stats.stackexchange.com/questions/649916/is-the-likelihood-ratio-test-best-for-finite-samples</link>
      <description><![CDATA[维基百科说

Neyman-Pearson 引理指出，对于这种情况，这种似然比 (lr) 检验是所有 α 级 alpha 检验中最强大的。

这只适用于无限样本量吗？在某些情况下，对于有限样本，是否有可能存在对给定 alpha 级更强大的测试？如果是这样，哪种检验会比似然比检验更好，在什么情况下更好？
我知道对于有限样本问题，似然比统计量的分布在很大程度上是未知的，但如果它很重要，为了回答这个问题，我愿意假设我们总是知道给定问题的 lr 统计量的真实分布。
我的问题的另一部分是，什么是非 lr 检验？感觉一切实际上都是 lr 检验（例如 t 检验、f 统计量、参数引导等）。我想在某些情况下，最小二乘法（和矩量法）一定不等同于 lr，因此对于有限样本，是否存在最小二乘法实际上可以胜过 lr 的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/649916/is-the-likelihood-ratio-test-best-for-finite-samples</guid>
      <pubDate>Wed, 26 Jun 2024 02:36:57 GMT</pubDate>
    </item>
    <item>
      <title>在不同的数据集上同时优化两个函数</title>
      <link>https://stats.stackexchange.com/questions/649913/simultaneously-optimizing-two-functions-on-different-datasets</link>
      <description><![CDATA[我有两个共享参数的函数，每个函数都需要针对不同的数据进行优化。我的问题是：我是否可以简单地将两个函数的残差平方和 (RSS) 添加到我的目标函数中并运行优化？
例如，rss1 是将函数 f1 的结果与数据 d1 进行比较时的值，rss2 是将 f2 与数据 d2 进行比较时的值。我如何在 R 的 optim 函数中使用这两个 rss？这是简单的求和，还是另有隐情？
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/649913/simultaneously-optimizing-two-functions-on-different-datasets</guid>
      <pubDate>Wed, 26 Jun 2024 00:12:19 GMT</pubDate>
    </item>
    <item>
      <title>使用共享参数在两个数据集上优化两个函数</title>
      <link>https://stats.stackexchange.com/questions/649912/optimize-two-functions-on-two-datasets-with-shared-parameters</link>
      <description><![CDATA[我有两个共享参数的函数，每个函数都需要根据单独的数据进行优化。我的问题是：我可以在目标函数中简单地添加两个函数的残差平方和吗？
我将给出一个玩具 R 代码作为示例。
eq_1_optim = function(ka,kel,t){return(0.004*(exp(-kel*t)-exp(-ka*t)))
eq_2_optim = function(kel,t){return(0.004*(exp(-kel*t)))
数据集 1：t1=c(0,0.3,0.7,1,1.5,4,6)，p1=c(0,2.5,4,4.4,3.8,2,0.9)
数据集 2：t2=c(0.01,0.1,0.5,1,8)， p2=c(0.5,0.4,0.01,0.01,0.004)
t=list(t1,t2)
observ = list(p1,p2)
obj_fun = function(par,t,observed){
t1=t[[1]]
t2=t[[2]]
observed_1 = perceived[[1]]
observed_2 = perceived[[2]]
predicted_model_1 = eq_1_optim(par[1],par[2],t1)
predicted_model_2 = eq_2_optim(par[2],t2)
rss1 = sum((observed_1-predicted_model_1)^2)
rss2 = sum((observed_2-predicted_model_2)^2)
return(rss1+rss2)
fit = optim(par=c(5,0.3),fn = obj_fun,t=t,observed=observ,method = &quot;L-BFGS-B&quot;,lower=c(0.5,0.01),upper=c(10,10))
如能得到任何帮助，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/649912/optimize-two-functions-on-two-datasets-with-shared-parameters</guid>
      <pubDate>Tue, 25 Jun 2024 23:54:23 GMT</pubDate>
    </item>
    <item>
      <title>个人卫生用品调查的多元分析</title>
      <link>https://stats.stackexchange.com/questions/649911/multivariate-analysis-for-personal-hygiene-product-survey</link>
      <description><![CDATA[我进行了一项调查，调查涉及 5 种不同的个人卫生产品。每种产品有 6 个不同的品牌，参与者被要求为每种产品选择一个或多个他们喜欢的品牌。除了品牌偏好之外，我还收集了参与者的社会人口统计数据，例如年龄、收入和其他相关特征。
调查详情：

产品：5 种不同的个人卫生产品
品牌：每种产品有 6 个品牌
选择：参与者可以为每种产品选择多个品牌（多选题）
其他数据：社会人口特征（年龄、收入等）。我计划在我的分析中包含这些社会人口变量，以便更好地了解关系和模式。

我的问题：

多变量分析：鉴于我的数据的性质，多变量分析是否合适？如果是，您会推荐哪种特定类型？

资源：您能否推荐一些书籍、研究或文章来解释如何有效地进行这种分析，尤其是针对多项选择题的分析？

]]></description>
      <guid>https://stats.stackexchange.com/questions/649911/multivariate-analysis-for-personal-hygiene-product-survey</guid>
      <pubDate>Tue, 25 Jun 2024 23:01:44 GMT</pubDate>
    </item>
    <item>
      <title>Fisher 信息中的评分函数的导数</title>
      <link>https://stats.stackexchange.com/questions/649907/derivative-of-the-score-function-in-fisher-information</link>
      <description><![CDATA[我正在研究 Fisher 信息，并试图形成一种直观的理解。请记住，我只有本科数学背景，所以我希望得到一个更直观的解释而不是数学推导的答案。
我理解我们使用 Fisher 信息来让我们对 MLE 有某种“信心”。但是，我在数学上感到困惑，我们如何才能在 MLE 处获得除零之外的任何 Fisher 信息。由于 FI 等于得分函数一阶导数平方的期望值（wrt X），因此在等于 MLE 的 theta 处的导数就是 0。而 0 的平方等于 0。那么，如何才能让 FI 在 MLE 处有意义呢？这是否与我们对随机变量 X 的所有值求导数的平均值有关，因此在某些情况下斜率可能不为零？
任何见解都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/649907/derivative-of-the-score-function-in-fisher-information</guid>
      <pubDate>Tue, 25 Jun 2024 22:15:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么单尾研究的标准 alpha 值为 0.025？</title>
      <link>https://stats.stackexchange.com/questions/649904/why-is-the-standard-alpha-for-one-tailed-studies-0-025</link>
      <description><![CDATA[似乎文献中的标准是仅当 p &lt;= 0.025 时才认为单尾研究“显著”。这是为什么呢，特别是如果研究从一开始就计划采用单尾研究的话。]]></description>
      <guid>https://stats.stackexchange.com/questions/649904/why-is-the-standard-alpha-for-one-tailed-studies-0-025</guid>
      <pubDate>Tue, 25 Jun 2024 21:29:59 GMT</pubDate>
    </item>
    <item>
      <title>神经网络如何区分输出 0 的神经元和丢失的神经元？</title>
      <link>https://stats.stackexchange.com/questions/649899/how-does-a-neural-network-differentiate-between-a-neuron-that-outputs-0-and-a-dr</link>
      <description><![CDATA[网络如何区分输出为 0 的神经元和丢失的神经元（该神经元可能输出非零值，但由于丢失而输出 0）？]]></description>
      <guid>https://stats.stackexchange.com/questions/649899/how-does-a-neural-network-differentiate-between-a-neuron-that-outputs-0-and-a-dr</guid>
      <pubDate>Tue, 25 Jun 2024 19:59:58 GMT</pubDate>
    </item>
    <item>
      <title>少数聚类的标准误差聚类</title>
      <link>https://stats.stackexchange.com/questions/649871/standard-error-clustering-with-few-clusters</link>
      <description><![CDATA[我试图使用来自三个州 166 个县的县级犯罪数据来估计警察在场对犯罪率的因果影响。处理是在州一级分配的。对于我的基本估计（TWFE 包括县、年份、月份和星期几），我将标准误差聚类在县级。但是，我知道常见的方法是在处理级别进行聚类。由于这在只有三个集群的情况下是不可能的，因此另一种方法是使用野生集群引导标准误差（Cameron 等人，2008 年）。我不确定 WCB 方法是否在只有三个集群的情况下可行。
有人遇到过类似的问题或可以提供一些建议吗？
亲切的问候]]></description>
      <guid>https://stats.stackexchange.com/questions/649871/standard-error-clustering-with-few-clusters</guid>
      <pubDate>Tue, 25 Jun 2024 11:32:59 GMT</pubDate>
    </item>
    <item>
      <title>与三元变量进行 3 次比较</title>
      <link>https://stats.stackexchange.com/questions/649689/making-3-comparisons-with-a-ternary-variable</link>
      <description><![CDATA[我有一项研究，其中我想研究三元变量 $x$ 与二元变量 $y$ 交互的影响。三元变量是分类变量，出于某些原因，我想在 $3$ 组之间进行 $3$ 比较。
我明白要进行一次比较，我必须进行两次对比。例如，如果我对 group1 与 group3 感兴趣，我定义 $C_1= (-1,0,1)$ 和 $C_2=(-1,2,-1)$。如果我想测试所有的比较，那么我应该做$6$个对比吗？在这种情况下，回归量不会共线吗？有没有更简单的方法可以做到这一点？
谢谢你的帮助！

谢谢你的回答！你的代码运行得很好，但我不确定如何得到我需要的答案。事实上，当我使用我的三元变量的引用（1作为引用，2和3作为另外2个值）并运行一个简单的glm模型时，我得到了这样的输出：
## y 9.782e-03 1.418e-04 69.008 &lt; 2e-16 *** 
## x2 8.677e-05 9.265e-04 0.094 0.92539 
## x3 -3.617e-03 9.229e-04 -3.919 8.96e-05 ***
## y:x2 -5.481e-04 2.935e-04 -1.868 0.06184 . 
## y:x3 9.430e-04 2.941e-04 3.206 0.00135 **

在这里，您可以看到，对于前两个比较，您可以访问关于 x 与变量 y 交互作用的 p 值。我想得到第三个交互项。
当我使用 emmeans 进行多重比较时，我得到了类似这样的结果（它包含的行数比这个还多）：
## (y0 x1) - y1 x2 -0.060 0.0189 159## -3.183 0.0186
## (y0 x1) - (y0 x2) -0.006 0.0277 159## -0.216 0.9999
## (y0 x1) - y1 x2 -0.046 0.0277 159## -1.658 0.5601
## (y0 x1) - (y0 x3) 0.207 0.0277 159## 7.472 &lt;.0001

由于我可以访问所有比较，因此我无法简单地分析变量 x 和 y 之间的相互作用。我希望获得与第一个块相同的输出，但是通过三个比较，有没有办法获得它？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649689/making-3-comparisons-with-a-ternary-variable</guid>
      <pubDate>Fri, 21 Jun 2024 20:51:47 GMT</pubDate>
    </item>
    <item>
      <title>最佳解决方案未重复 - metaMDS 没有可靠的结果？</title>
      <link>https://stats.stackexchange.com/questions/649643/best-solution-was-not-repeated-no-reliable-result-for-metamds</link>
      <description><![CDATA[我拥有丰富的蜘蛛数据，这些数据是我在不同林地中捕获的，我想执行 NMDS。它通常有效，尽管压力值相对较高。但是，我收到消息说最佳解决方案无法重复。

```Spiders_NMDS &lt;- metaMDS(nmds_data[,7:54], k = 2, distance = &quot;horn&quot;, trymax= 100, maxit=1000 )

以下是输出的最后几行：
Run 100 stress 0.2085273
... Procrustes: rmse 0.008630914 max resid 0.05303693
*** 最佳解决方案未重复 -- monoMDS 停止标准：
100：压力比 &gt; sratmax

以及 print(Spiders_NMDS) 的输出
metaMDS(comm = nmds_data[, 7:54], distance = &quot;horn&quot;, k = 2, trymax = 100, maxit = 1000)

使用 monoMDS 进行全局多维缩放

数据：wisconsin(nmds_data[, 7:54])
距离：horn

维度：2
压力：0.208454
压力类型 1，弱关系
最佳解决方案在 100 次尝试后未重复
最佳解决方案来自第 75 次尝试（随机开始）
缩放：居中、PC 旋转、半变化缩放
物种：基于‘wisconsin(nmds_data[, 7:54])


我在另一个论坛上看到，依赖这些数据并将其用于进一步分析在统计上并不有效。是这样吗？毕竟，官方 R 网站表示您仍然可以使用这些数据，但上述论坛的担忧肯定不是毫无根据的……请参阅：https://stackoverflow.com/questions/741 ... -nmds-in-r
不幸的是，R 针对这个问题给出的建议对我没有帮助。参见：https://rdrr.io/cran/vegan/man/metaMDS.html（“结果无法重复”部分）
例如，我已经增加了 maxit 和 trymax，但仍然输出该消息。我还用 previous.best 运行了另一次迭代
metaMDS(nmds_data[,7:54], k = 2, distance = &quot;horn&quot;,trymax= 100, maxit= 100, previous.best = Spiders_NMDS)
但是，这也不会改变输出。
增加维度也不会带来任何变化，例如，在可视化方面没有用，对吗？
有人有这个问题的经验吗？有没有办法获得更可靠的结果？
我想继续使用 envfit 函数....
我的数据集通常包含许多零，并且可能有许多陷阱彼此之间的距离非常大（不共享任何物种）...也许这很重要？
感谢您的反馈 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/649643/best-solution-was-not-repeated-no-reliable-result-for-metamds</guid>
      <pubDate>Fri, 21 Jun 2024 07:44:57 GMT</pubDate>
    </item>
    <item>
      <title>对 $k$ 个最近邻中的维度（特征）进行加权（重新缩放）</title>
      <link>https://stats.stackexchange.com/questions/649038/weighting-rescaling-the-dimensions-features-in-k-nearest-neighbors</link>
      <description><![CDATA[当使用 $k$ 个最近邻时，必须对数据集进行归一化（如果 X 是数据矩阵，其中每行代表一个特征或维度，每列代表一个样本点，那么从每个 $X_{ij}$ 中减去每行 $i$ 的平均值，然后将每个 $X_{ij}$ 除以行 $i$ 的标准差是一个不错的选择）
在以下问题中：
https://datascience.stackexchange.com/questions/6786/weighted-k-nearest-neighbor-search
以下内容第二个答案中提到：
如果你想要将一个维度的权重高于其他维度，那么我建议你对所有数据进行标准化，使平均值为零，标准差为一。然后，你可以将不太重要的维度乘以一个因子（2-10），这样它们看起来离 KNN 距离度量更远，而最重要的维度则不缩放
我的问题是关于这部分：
然后，你可以将不太重要的维度乘以一个因子（2-10），这样它们看起来离 KNN 距离度量更远，而最重要的维度则不缩放
事实不是相反吗？
将一个维度乘以 (2-10) 中的一个因子，难道不会使其比其他维度更重要吗？
例如，如果我们考虑以下简单情况：当输入属于 $\mathbb{R}^2$ 时，函数 $F(x,y)$。让我们制作两个点 A 和 B，其坐标如下
A(1,0)
B(0,1)
让我们通过第一个最近邻预测坐标为 (0,0) 的点 C 的值。
最初，点 A 和 B 与 C 的距离相同
点 A(1,0) 和 C(0,0) 具有相同的 y 值 0
点 B(0,1) 和 C(0,0) 具有相同的 x 值 0
现在将维度 x 乘以 2 将得到以下点
A(2,0)
B(0,1)
C(0,0)
并且将使点 B 比 A 更靠近 C，因此 C 的值将被选择为 B 的值。请注意，B 和 C 具有相同的 x 值，而 A 和 C 具有相同的 y 值，并且 C 的选择值将是共享相同 x 值的 B 的值，因此将维度 x 乘以 2 使得 x 值在确定最近邻居时比 y 值更重要，因此它使该维度更重要。
而如果我们将 y 维度乘以 2，点 A 的值（与 C 共享更接近的 y 值）将被选择为 C 的值。
换句话说，标准化后将维度 x 乘以一个大于 1 的数字将使具有更接近此维度 x 值的点对于 k 个最近邻居来说彼此更接近，这将使该维度更重要。例如：
A(4,1)
B(1,5)
C(2,2)
dist(A,C)=√5
dist(C,B)=√10
A更接近C，A的y值也更接近C，而不是B接近C
现在将x维度乘以3
我们得到
A(12,1)
B(3,5)
C(6,2)
dist(A,C)=6.082
dist(C,B)=4.242
B现在变得更接近C，在相乘之前，B的x值最初也更接近C
这是是真的吗？或者我没有得到任何东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/649038/weighting-rescaling-the-dimensions-features-in-k-nearest-neighbors</guid>
      <pubDate>Tue, 11 Jun 2024 13:52:29 GMT</pubDate>
    </item>
    <item>
      <title>线性模型中均值-方差依赖性的教学示例</title>
      <link>https://stats.stackexchange.com/questions/646657/didactic-example-of-mean-variance-dependency-in-linear-models</link>
      <description><![CDATA[我想说明在线性模型推断中考虑均值和方差之间的依赖关系的重要性。下面我的例子好吗？你同意我的评论吗？

在这里，我模拟了 4 个具有不同均值和相同分散参数的组的负二项分布计数数据。我使用普通线性回归 (lm) 和具有负二项误差分布 (glm) 的广义线性模型拟合了相同的模型。可以看到：

普通线性模型对四个组中的每一个都返回相同的误差估计（因此置信区间宽度相同，CI）。这是因为 lm 假设方差恒定。而 glm 则将误差调整为均值。 （请注意，误差估计还取决于组大小，这里所有组的组大小都相同）。

因此，lm 低估 均值较大的组（即 A）中的误差，而 高估 均值较小的组（C 和 D）中的误差。事实上，A 组的 95% CI 刚好偏离真实值 50，而 C 和 D 的 CI 在视觉上感觉不对。

lm 的 CI 包含负值，这对于计数数据来说是不合常理的。



那么，glm 如何将方差（以及误差估计和 CI）调整到均值？这是在选择误差分布时。对于计数数据，我们可以选择方差等于均值的泊松分布。泊松分布经常低估方差，因为您会假设不同的观察结果在各方面都是相同的，而唯一的变异来源是随机抽样（瓮模型）。如果您计算来自不同动物的寄生虫卵，则泊松分布不太可能很好地拟合，因为动物在很多方面都会有所不同，例如接触感染和对感染的反应。
负二项式通过分散参数允许额外的变异。与平均值一样，离散度也是通过数据估计的，即对于给定的平均值和离散度，数据的似然性最大化（实际上，所有 glms 都是通过最大似然拟合的）。

要重现的 R 代码
library(data.table)
library(ggplot2)
library(ggbeeswarm)
library(emmeans)
library(MASS)
library(RColorBrewer)

set.seed(12345)

a &lt;- 4
b &lt;- 4
c &lt;- 4
d &lt;- 4
count &lt;- list(
A=rnbinom(n=a, mu=50, size=10),
B=rnbinom(n=b, mu=30, size=10),
C=rnbinom(n=c, mu=5, size=10),
D=rnbinom(n=d, mu=0.5, size=10)
)
dat &lt;- data.table(
count=unlist(count),
cnd=rep(names(count), c(a, b, c, d))
)

norm &lt;- lm(count ~ cnd, data=dat)
emm &lt;- as.data.table(emmeans(norm, &#39;cnd&#39;))

negbin &lt;- glm.nb(count ~ cnd, data=dat)
emm2 &lt;- as.data.table(emmeans(negbin, &#39;cnd&#39;, type=&#39;response&#39;))

cc &lt;- brewer.pal(3, &#39;Dark2&#39;)
cols &lt;- c(&#39;lm&#39;=cc[1], &#39;glm&#39;=cc[2])
gg &lt;- ggplot(数据=dat，aes(x=cnd，y=count)) +
geom_quasirandom(颜色=&#39;grey20&#39;，宽度=0.1) +
geom_hline(yintercept=0，颜色=&#39;grey60&#39;，线型=&#39;dashed&#39;) +
geom_segment(数据=emm2，aes(x=as.numeric(cnd) - 0.1，y=asymp.LCL，
yend=asymp.UCL，颜色=&#39;glm&#39;)，线宽=0.5) +
geom_point(数据=emm2，aes(x=as.numeric(cnd) - 0.1，y=response，
colour=&#39;glm&#39;)，pch=4，size=2) +
geom_segment(数据=emm，aes(x=as.numeric(cnd) + 0.1，y=lower.CL，
yend=upper.CL, colour=&#39;lm&#39;), linewidth=0.5) +
geom_point(data=emm, aes(x=as.numeric(cnd) + 0.1, y=emmean, 
colour=&#39;lm&#39;), pch=4, size=2) +
scale_colour_manual(name=&quot;95% CI from:&quot;, values=cols) +
ggtitle(&#39;从负二项分布模拟的数据&#39;) + 
theme_light() +
theme(axis.title.x=element_blank())
ggsave(&#39;error.pdf&#39;, width=12, height=10, unit=&#39;cm&#39;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/646657/didactic-example-of-mean-variance-dependency-in-linear-models</guid>
      <pubDate>Mon, 06 May 2024 20:33:20 GMT</pubDate>
    </item>
    </channel>
</rss>