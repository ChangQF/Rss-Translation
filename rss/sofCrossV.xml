<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 13 Apr 2024 12:19:39 GMT</lastBuildDate>
    <item>
      <title>计算 R 中威布尔分布的 CDF</title>
      <link>https://stats.stackexchange.com/questions/644932/calculate-cdf-of-weibull-distribution-in-r</link>
      <description><![CDATA[我想计算 Weibull 随机变量 X 大于 1000 的概率，其中 X ~ Weibull(lambda, g)。
使用 CDF，我将其计算为：
&lt;前&gt;&lt;代码&gt;g = log(log(.7)/log(.5))/log(40/81)
拉姆达 = -log(.7)/400^g

&gt; exp(-lambda*1000^g)
[1] 0.4294352

但使用如下R包，结果不同
&lt;前&gt;&lt;代码&gt;&gt; pweibull(1000，形状= g，尺度= lambda，lower.tail = FALSE)
[1] 0

为什么结果是错误的？我是否错误地使用了 R 包？]]></description>
      <guid>https://stats.stackexchange.com/questions/644932/calculate-cdf-of-weibull-distribution-in-r</guid>
      <pubDate>Sat, 13 Apr 2024 12:12:59 GMT</pubDate>
    </item>
    <item>
      <title>比较分析随时间变化的轨迹的方法</title>
      <link>https://stats.stackexchange.com/questions/644930/comparing-methodologies-for-analysing-trajectories-over-time</link>
      <description><![CDATA[我有一个纵向数据集，其中测量了 20 周以上运动员和非运动员每周使用镇痛药的情况。我将镇痛剂使用的流行率和频率作为我在两组中进行比较的单独结果。我有兴趣寻找随时间推移使用镇痛药的不同亚组。所以，我找到了这三个模型：1）基于组的轨迹建模（GBTM）2）潜在增长混合建模（LGML）3）纵向潜在类建模（LLCM）。我对统计软件、stata 和 R 都是新手。我的问题是：

对于我的情况，以下哪种方法更适合使用？为什么？各自的优缺点是什么？
您推荐哪些软件或软件包？
感谢您的指导。
]]></description>
      <guid>https://stats.stackexchange.com/questions/644930/comparing-methodologies-for-analysing-trajectories-over-time</guid>
      <pubDate>Sat, 13 Apr 2024 11:56:58 GMT</pubDate>
    </item>
    <item>
      <title>气候极端事件重现期（极值分析）+解释</title>
      <link>https://stats.stackexchange.com/questions/644929/return-period-of-climate-extreme-events-extreme-value-analysis-interpretatio</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644929/return-period-of-climate-extreme-events-extreme-value-analysis-interpretatio</guid>
      <pubDate>Sat, 13 Apr 2024 10:29:43 GMT</pubDate>
    </item>
    <item>
      <title>在诊断测试准确性上下文中将数据从宽格式转换为长格式</title>
      <link>https://stats.stackexchange.com/questions/644928/converting-data-from-wide-to-long-format-in-the-diagnostic-test-accuracy-context</link>
      <description><![CDATA[我有大约 100 项研究，每项研究都包含一行，其中报告了每项一项或多项测试的诊断测试准确性指数（图 1）。它们采用宽幅格式。

为了进行分析，我需要将它们转换为长格式。与图2完全相同：

现在我可以手动执行此操作，但这会带来很大的不准确风险。我对 R、Python 和 Excel 有一定的了解。任何有关如何解决此问题的帮助将不胜感激。
附注这是我创建的数据的文件：file.io 链接]]></description>
      <guid>https://stats.stackexchange.com/questions/644928/converting-data-from-wide-to-long-format-in-the-diagnostic-test-accuracy-context</guid>
      <pubDate>Sat, 13 Apr 2024 10:18:07 GMT</pubDate>
    </item>
    <item>
      <title>具有省略变量的非参数回归</title>
      <link>https://stats.stackexchange.com/questions/644924/non-parametric-regression-with-an-omitted-variable</link>
      <description><![CDATA[假设我们使用核回归估计器$$\hat{m}(c)=\frac{\sum_{i=1}^n K\left(\frac{ x_i-c}{h}\right)y_i}{\sum_{i=1}^n K\left(\frac{x_i-c}{h}\right)}$$
其中 $h\to 0$ 和 $nh\to \infty$ 为 $n\to \infty$。
真正的 DGP 的形式为 $$y_i=\alpha +\beta x_i +\gamma z_i+\varepsilon_i$$
我假设 $\{(y_i,x_i,z_i)\}$ 是独立同分布的。并且所有变量都是绝对连续的，具有有限的二阶矩，并且在整个实线上具有正密度。我假设两个变量都具有严格的外生性，即 $\mathbb{E}[\varepsilon_i|x_i;z_i]=0$，并且 $x_i$ 和 $z_i$ 彼此独立。
我想知道 $\hat{m}(c)$ 收敛到什么对象。
为此，定义 $\hat{g}(c)=\frac{1}{nh}\sum_{i=1}^n K\left(\ frac{x_i-c}{h}\right)y_i$ 和 $\hat{f}(c)=\frac{1}{nh}\sum_{ i=1}^n K\left(\frac{x_i-c}{h}\right)$ 使得 $\hat{m}(c)= \hat{g}(c)/\hat{f}(c)$。很容易显示 $\hat{f}(c)\xrightarrow{p} f(c)$ 其中  $f(c)$ 是 $x$ 的 pdf。现在，让 $p(z)$ 为 $z$ 的 pdf，\begin{align*}
\mathbb{E}[\hat{g}(c)]
&amp;= \mathbb{E}\left[\frac{1}{nh}\sum_{i=1}^nK\left(\frac{x_i-c}{h}\right)y_i\right] \\
&amp;= \frac{1}{h}\mathbb{E}\left[K\left(\frac{x_i-c}{h}\right)y_i\right] \\
&amp;=\frac{1}{h}\mathbb{E}\left[K\left(\frac{x_i-c}{h}\right)(\alpha +\beta x_i +\gamma z_i+\varepsilon_i) \正确的] \\
&amp;=\frac{1}{h}\mathbb{E}\left[K\left(\frac{x_i-c}{h}\right)(\alpha +\beta x_i +\gamma z_i)\right ] \\
&amp;= \frac{1}{h}\int_{\Omega}K\left(\frac{x-c}{h}\right)(\alpha +\beta x +\gamma z)d\mathbb{P} \\
&amp;=\frac{1}{h}\iint K\left(\frac{x-c}{h}\right)(\alpha +\beta x +\gamma z)f(x)p(z)dxdz \ \
&amp;=\iint K(u)(\alpha +\beta (uh+c) +\gamma z)f(uh+c)p(z)dudz \\
&amp;= (\alpha + \beta c+\gamma \mathbb{E}[z])f(c) +o(1) \\
&amp;\xrightarrow{n\to \infty} (\alpha + \beta c+\gamma \mathbb{E}[z])f(c)
\end{对齐*}
我还可以显示 $\mathbb{V}[\hat{g}(c)]\to 0$ 显示 $\hat{g}(c)\xrightarrow{p} (\alpha + \beta c+\gamma \mathbb{E}[z])f(c)$.因此，我认为 $$\hat{m}(c)\xrightarrow{p}\alpha + \beta c+\gamma \mathbb{E}[z]$$
但是，我正在学习的课程的助教提到 $\hat{m}(c)$ 应该收敛到 $c$ 我显然没有得到。我认为原因可能是我假设 $x_i$ 和 $z_i$ 是独立的。但是，如果没有这个假设，我不确定如何找到 $\hat{m}(c)$ 的概率极限。
有人可以指出我工作中出错的地方，或者解释如何在不假设独立的情况下找到限制吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644924/non-parametric-regression-with-an-omitted-variable</guid>
      <pubDate>Sat, 13 Apr 2024 08:13:14 GMT</pubDate>
    </item>
    <item>
      <title>使用 blme 避免 R 中混合模型中的奇异拟合 - 检查外行人的先验</title>
      <link>https://stats.stackexchange.com/questions/644923/avoid-singular-fits-in-mixed-models-in-r-with-blme-checking-laymans-priors</link>
      <description><![CDATA[在拟合线性混合模型时，我想避免零随机效应 (ranef(model)) 和集群级 SD 估计 (as.data.frame(VarCorr(model) ))[1,5])。这些可以在某些两级场景中由 lme4 R 包生成，即使模拟的采样总体是集群且异构的。零输出的典型符号是奇异拟合。 lme4 模型的另一个令人沮丧的特征是，在某些情况下，奇异拟合率似乎随着聚类数量的增加而增加。与直觉相反的是，随着输入的信息增多，模型会放弃并且不估计任何聚类级别的变化，即使模拟的抽样群体是异质的（如 ICC 0.05）。作为特定的背景细节，我希望至少有很小的 ranef(model) 和 as.data.frame(VarCorr(model))[1,5] 甚至如果群体确实是同质的（ICC 0.00），则在模型拟合后启用引导程序。我的目标模型是dependent ~ dicthomous_predictor + (1|cluster)。
作为 lme4 文档中建议的替代方案来管理这些问题，可以使用被称为“部分贝叶斯方法”的 blme R 包。经过测试，我可以验证，在默认先验优于随机效应/建模系数的协方差（cov.prior = Wishart 参数）的情况下，模型拟合的总体成功率随着 &lt;代码&gt;blme包。我所说的成功是指非零ranef(model)。然而，簇级 SD 估计值会超出图表，因为簇数量很少，例如两个，两者都具有 cov.prior = Wishart 和 cov.prior = gamma（让我们此时排除基本建议“获取更多测量/聚类”）。另一方面，当我模拟异质群体（例如国际商会 0.10-0.98）。另一方面，在没有奇异拟合的情况下，在不同数量的簇、簇大小和 ICC 中幸存下来的 lme4 模型的簇级 SD 估计更加平衡，与真实的簇级匹配更好我模拟的总体标准差。
因此，如果非奇异 lme4 模型的非零簇级估计值更高，我会很高兴。这就是为什么我想为 blme 模型找到一个合适的 cov.prior ，从而实现与非奇异  类似的非零簇级估计&gt;lme4 模型的成功率有所提高。
以下是 blme 文档中如何定义自定义先验的示例：
# 自定义优先级
惩罚Fn &lt;-函数(西格玛)
dcauchy(西格玛, 0, 10, log = TRUE)
(fm5 &lt;- blmer(反应 ~ 天数 + (0 + 天数|主题), sleepstudy,
cov.prior = 自定义（penaltyFn，chol = TRUE，scale =“log”）））

如有错误，请指正。我刚刚熟悉这个概念，还没有找到好的介绍材料。这是否是一种合理的方法，并且可以使用此 penaltyFn 来定义找到与总均值相关的聚类均值（更低或更高）的概率，类似于抛硬币吗？因此，如果我们假设总体呈正态分布，我们是否可以将 dcauchy() 替换为 dbinom()，如下所示：
penaltyFn &lt;- 函数(sigma) {
dbinom(sigma, 簇数, 0.5)
}
模型 &lt;- blmer（依赖 ~ dicthomous_predictor + (1|cluster)，数据，
cov.prior = 自定义(penaltyFn)))

这个原则是否有意义，实施情况如何？或者有人可以建议一种更好的方法来拟合dependent ~ dicthomous_predictor + (1|cluster)模型和其他提供的上下文？当前的结果并不完美，但根据测试 dbinom() 之前提高了获得非零 ranef(model) 的成功率，并在整个模拟中实现了更平衡的集群级 SD 估计。一个缺点是，如果模拟的抽样群体确实是同质的（ICC 和簇级 SD 均为零），即使有 30 个簇且簇大小为 30，簇级 SD blme 估计值也稳定在 0.75 左右，而 lme4 估计值更接近真实的零。通过对最小变化簇进行如此多的测量，我想知道为什么 dbinom() 先验会导致估计更高的簇级别 SD？我的逻辑和/或实现也可能没有意义。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644923/avoid-singular-fits-in-mixed-models-in-r-with-blme-checking-laymans-priors</guid>
      <pubDate>Sat, 13 Apr 2024 07:39:10 GMT</pubDate>
    </item>
    <item>
      <title>当 Metropolis-Hastings 算法仅使用比例分布时，它如何从目标分布中进行采样？</title>
      <link>https://stats.stackexchange.com/questions/644921/how-does-the-metropolis-hastings-algorithm-sample-from-the-target-distribution-w</link>
      <description><![CDATA[我最近开始研究 M-H 算法，据我了解，它用于通过使用比例分布 f(x) 从复杂目标分布 P(x) 生成样本。这个想法是样本使用基于 P(x_new)/P(x_old) 的接受概率，这相当于 f(x_new)/f(x_old)。我的问题是样本如何直接收敛到 P(x)，而不是收敛到与 P(x) 成比例的其他分布。例如，如果目标分布是 P(x)/2，那么 M-H 算法的行为不是完全相同吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644921/how-does-the-metropolis-hastings-algorithm-sample-from-the-target-distribution-w</guid>
      <pubDate>Sat, 13 Apr 2024 07:07:16 GMT</pubDate>
    </item>
    <item>
      <title>确定结果变量的显着特征的最佳方法是什么</title>
      <link>https://stats.stackexchange.com/questions/644920/what-is-the-best-method-to-determine-the-significant-features-for-an-outcome-var</link>
      <description><![CDATA[我正在使用的数据集位于https://archive。 ics.uci.edu/dataset/45/heart+disease。
有 14 个属性，数据集包含数值变量和分类变量。有一个二分结果变量。
最好的方法是什么？我正在为一些分类变量制定假设，并运行费舍尔精确和卡方以确定统计显着性。对于数值变量，我正在考虑逻辑回归模型（类别不平衡）并根据变量的 p 值进行过滤。
有人可以证明这些方法是正确的吗？另一种选择是因素分析。然而，数据集是数字变量和分类变量的组合。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644920/what-is-the-best-method-to-determine-the-significant-features-for-an-outcome-var</guid>
      <pubDate>Sat, 13 Apr 2024 06:15:50 GMT</pubDate>
    </item>
    <item>
      <title>倾向调整的最坏情况</title>
      <link>https://stats.stackexchange.com/questions/644918/worst-case-for-propensity-adjustment</link>
      <description><![CDATA[我正在研究因果 ML 下的各种 CATE 估计方法（x/t/s/r 学习器和因果森林）。我想知道是否存在已知的倾向调整困难的场景？ （即 CATE 估计偏差最大的设置），具有标准假设（倾向重叠、SUTVA 等）
是否有任何研究对此进行探索？比较不同倾向设置下的不同算法？]]></description>
      <guid>https://stats.stackexchange.com/questions/644918/worst-case-for-propensity-adjustment</guid>
      <pubDate>Sat, 13 Apr 2024 05:23:16 GMT</pubDate>
    </item>
    <item>
      <title>风险价值/尾部风险价值</title>
      <link>https://stats.stackexchange.com/questions/644911/value-at-risk-tail-value-at-risk</link>
      <description><![CDATA[问题：设 X 为具有以下损失分布的随机变量
&lt;前&gt;&lt;代码&gt; k Pk
    0 0.50
 1000 0.30
 2000年0.10
 5000 0.06
10000 0.04

 – 计算 95% 的风险价值。
– 计算 95% 尾部风险价值。
大家好，以上是我需要帮助的问题。我尝试了公式
风险值 (%) = [预期回报 – (投资组合的标准偏差 x 置信区间的 Z 分数)]。然而，答案是否定的，这看起来并不正确。任何帮助，将不胜感激。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644911/value-at-risk-tail-value-at-risk</guid>
      <pubDate>Sat, 13 Apr 2024 00:01:35 GMT</pubDate>
    </item>
    <item>
      <title>如何建立轮廓似然模型进行估计？</title>
      <link>https://stats.stackexchange.com/questions/644906/how-to-make-the-profile-likelihood-model-for-estimation</link>
      <description><![CDATA[我尝试使用土壤中的化合物结果来制作年龄估计模型。最初，我使用多变量回归模型。然而，由于过度拟合问题，审稿人强烈建议使用轮廓似然而不是回归模型。我学习了轮廓似然法。我想仅使用轮廓可能性来制作估计模型。然而，我发现仅仅使用轮廓似然来建立估计模型是不可能的。它需要创建基本函数（如线性模型），然后应用似然度。
但我也听说没有人将似然法应用到线性回归模型中，因为结果是相同的，而且更复杂。我确信我的方式是错误的。但我不明白如何使用轮廓似然方法来开发估计模型。
你能帮我借一下你的大脑吗？如果您有任何建议，请告诉我。
这是我用来制作估计模型的原始代码。
Com1&lt;- c(-0.91475561, -1.39706018, -3.88102766, -2.15068888, 3.36007488, 8.09092947, 5.10511848, 4.98272449)
Com2＜-c(-0.642793922、-0.481519952、0.545645985、-0.151149253、-0.812447751、-0.363022089、4.288690815、0.523588945)
年龄 &lt;-c(20, 21, 22, 23, 93, 94, 95, 96)
ChemicalResult&lt;-data.frame(年龄、Com1、Com2)
RegModel &lt;-lm(Age~., data = ChemicalResult)
ExC1＜-c(0.00169)
ExC2＜-c(0.94)
Chem&lt;-data.frame（ExC1、ExC2）
名称(Chem)&lt;-c(“Com1”，“Com2”)
Expred&lt;-预测（PCR、化学）
]]></description>
      <guid>https://stats.stackexchange.com/questions/644906/how-to-make-the-profile-likelihood-model-for-estimation</guid>
      <pubDate>Fri, 12 Apr 2024 23:05:15 GMT</pubDate>
    </item>
    <item>
      <title>额外的协变量可降低混合模型（LMM、GLMM、GAM）中的 AIC</title>
      <link>https://stats.stackexchange.com/questions/644863/additional-covariate-reduces-aic-in-mixed-models-lmm-glmm-gam</link>
      <description><![CDATA[在不同Group中对时间点进行重复测量时，Age和Gender充当模型中的协变量，Age code&gt; 在每个时间点计算，但 Gender 是每个受试者的静态变量。
m1 &lt;- lmer(分数 ~ 组 + 时间点 + (1 | 主题))
m2 &lt;- lmer(分数 ~ 组 + 时间点 + 年龄 + (1 | 主题))
m3 &lt;- lmer(分数 ~ 组 + 时间点 + 性别 + (1 | 主题))
m4 &lt;- lmer(分数 ~ 组 + 时间点 + 年龄 + 性别 + (1 | 主题))

AIC 用于评估模型拟合
&lt;前&gt;&lt;代码&gt;&gt; AIC(m1, m2, m3, m4)
   df AIC
m1 5 752.6940
平方米 6 758.4476
米3 6 753.5923
m4 7 759.0831

如果 AIC 没有改善，这些协变量是否应该被排除在模型中？]]></description>
      <guid>https://stats.stackexchange.com/questions/644863/additional-covariate-reduces-aic-in-mixed-models-lmm-glmm-gam</guid>
      <pubDate>Fri, 12 Apr 2024 09:46:54 GMT</pubDate>
    </item>
    <item>
      <title>光谱测试值遵循什么分布（如果有）？</title>
      <link>https://stats.stackexchange.com/questions/644859/what-distribution-if-any-are-the-spectral-test-values-following</link>
      <description><![CDATA[我不确定这是否是问这个问题的正确地方，但这似乎是最相关的，因为我的问题是关于随机分布的。请告诉我是否应该将其移至其他社区。
我一直在研究 LCG/MCG 伪随机发生器的频谱测试值。在本文和我自己对更大的二次幂模数运行一些测试之间（在特别是 2^64 和 2^128），看起来在 24 维以内的光谱测试有一致的趋势，看起来与链接论文中提供的相似。使用 scipy.stats，我确定随着维度变高，分布越来越接近拟合 beta 分布，但对于 2 维和 3 维谱来说，它显然非常糟糕至少测试结果。此外，贝塔分布似乎低估了“高度”。即使在相对较高的尺寸下也能达到峰值。 1 减去光谱测试值的伽马分布也相当适合，但它往往会高估。
这是否更适合某些现有的连续分布，还是 beta 或 gamma 分布是我能做到的最好的？
作为参考，下面列出了我使用模数 2^128 进行测试得到的直方图和最佳拟合分布。不幸的是，由于我的声誉不超过 10 个，因此我的链接仅限于 8 个（即最多 8 维）。






]]></description>
      <guid>https://stats.stackexchange.com/questions/644859/what-distribution-if-any-are-the-spectral-test-values-following</guid>
      <pubDate>Fri, 12 Apr 2024 08:50:12 GMT</pubDate>
    </item>
    <item>
      <title>生成每个 ID 具有多个记录的合成数据</title>
      <link>https://stats.stackexchange.com/questions/644667/generating-synthetic-data-with-multiple-records-per-id</link>
      <description><![CDATA[我想生成一个合成数据集，其中每个 ID 有多个记录，并且每个 ID 的记录之间保持自我一致性。
例如，想象一个数据集，其中 ID 是一家杂货店，每条记录是该商店在给定日期内各种商品的销售额。换句话说，多个时间序列。您可以想象，虽然所有商店都有全球趋势，但也有商店级别的趋势，而现实的数据集不仅必须保留全球趋势，还必须保留商店级别的趋势。也许 A 店在周末出售的薯条较多，而 B 店周末出售的薯条较少，但饼干较多。
对虚假记录 IID 进行采样的合成数据模型只能保留全球销售趋势（“周五薯片的销量通常比饼干多”）。复杂性又提高了一步的模型，例如 LSTM，可以保留在所有商店中表达的时间趋势（“如果饼干在时间 t-1 的销量少于薯片，那么它们在时间 t 的销量通常会更高”）。但是，我如何制作一个模型，让这些趋势在每个商店都有所不同（“在某些商店，薯片在周六的销量通常超过饼干，但在其他商店却恰恰相反”）？
我的一个想法是使用领域知识/集群将商店分配给 N 个“配置文件”之一，然后使用该配置文件作为功能。该模型自然能够捕获依赖性。也就是说，这种方法需要手动定义 N 并创建一组有限的配置文件。我正在寻找限制较少的东西，并且可以检测到比我手动检测到的更微妙的配置文件（如果存在）。
希望我已经很好地解释了我的问题 - 请随时要求澄清。相关论文的链接将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644667/generating-synthetic-data-with-multiple-records-per-id</guid>
      <pubDate>Tue, 09 Apr 2024 19:47:01 GMT</pubDate>
    </item>
    <item>
      <title>分段指数分布的样本</title>
      <link>https://stats.stackexchange.com/questions/644922/sample-from-a-piecewise-exponential-distribution</link>
      <description><![CDATA[给定一个分布 $p(x)\propto \exp(\min_{i=1}^N [a_i^Tx + b_i])$，其中$x$ 和 $a_i$ 都是 D 维向量，$b_i$ 是标量，并且 $(a_i,b_i)$ 是已知的。我如何从中取样？这种形式基本上是分段指数分布。可以进行分析取样吗？我不确定“分析”是否是此处使用的正确词，但基本上我的意思是它可以像高斯分布或均匀分布一样进行采样，而不是使用 MCMC。
假设 $(a_i,b_i)$ 值保证有效分布，即 $p(x)$&lt; /span&gt; 可以标准化为 1。]]></description>
      <guid>https://stats.stackexchange.com/questions/644922/sample-from-a-piecewise-exponential-distribution</guid>
      <pubDate>Tue, 09 Apr 2024 15:37:22 GMT</pubDate>
    </item>
    </channel>
</rss>