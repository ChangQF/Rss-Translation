<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 06 Nov 2024 18:22:21 GMT</lastBuildDate>
    <item>
      <title>对俄罗斯的制裁可以在计量经济分析中作为虚拟变量来建模吗？</title>
      <link>https://stats.stackexchange.com/questions/656850/can-sanctions-against-russia-be-modeled-as-a-dummy-variable-in-econometric-analy</link>
      <description><![CDATA[我目前正在进行计量经济学分析，旨在评估对俄罗斯的制裁对 28 个欧盟国家可再生能源份额（占总能源的百分比）的影响。
我正在考虑将制裁建模为虚拟变量，其中：
0 表示未对俄罗斯实施制裁的时期（2014 年之前）。
1 表示实施制裁的时期（2014 年以后）。
我的因变量是这些国家在特定时间段内可再生能源的份额。
我有一个控制变量向量（GDP、能源价格和政策激励）。
我的问题是：
在这种情况下，使用虚拟变量来表示制裁是否合适？
是否有任何特定的计量经济学模型或技术可以推荐用于分析这种二元处理变量对可再生能源份额等连续结果变量的影响？
我很感激任何关于此类分析最佳实践的见解或建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/656850/can-sanctions-against-russia-be-modeled-as-a-dummy-variable-in-econometric-analy</guid>
      <pubDate>Wed, 06 Nov 2024 17:36:01 GMT</pubDate>
    </item>
    <item>
      <title>如何将 2 个方差与观察到的方差分开？</title>
      <link>https://stats.stackexchange.com/questions/656846/how-to-separate-2-variances-from-observed-variance</link>
      <description><![CDATA[我将其分解为以下内容：
var(predicted_conc) = actual_conc*var1 + var2
请注意，随机变量生成器是独立的，因此添加的是方差而不是标准差。
我首先运行模拟来重新生成该信息。
actual_conc &lt;- c(0,3, 5, 10, 20, 30,50,80,90, 100, 150, 180)

predicted_conc &lt;- c()
for(i in actual_conc){
predicted_conc &lt;- c(predicted_conc, i + rnorm(1000, mean =0, sd = (0.05*i)) + rnorm(1000, mean = 0, sd = 0.1))
}

如您所见，我必须将随机变量生成与按浓度缩放或只是常数分开。
但是，这种关系不是线性的。然后我计算方差，非线性关系变得非常明显，如果我拟合线性或二次回归，我会得到负截距，其中实际常数方差为 0.01。
尽管我在这个模拟中接近真实值，如果我使用 sd 而不是 var，并且将 sd~conc 建模为常数方差很小，但我认为这应该是更正确的建模方法。
欢迎提出想法。
谢谢！
编辑
我猜这与方差有关，因为零会导致零结果！我当然有坚定的假设，即浓度在任何时候都不会为负。]]></description>
      <guid>https://stats.stackexchange.com/questions/656846/how-to-separate-2-variances-from-observed-variance</guid>
      <pubDate>Wed, 06 Nov 2024 16:42:32 GMT</pubDate>
    </item>
    <item>
      <title>针对回归问题的贝叶斯分歧主动学习（BALD）</title>
      <link>https://stats.stackexchange.com/questions/656845/bayesian-active-learning-by-disagreement-bald-for-regression-problems</link>
      <description><![CDATA[我一直在研究 BALD 方法，我理解它在分类问题中的应用，但我不确定如何在回归问题中实现它。
在分类情况下，BALD 最大化了互信息，其定义如下
$$
\mathcal{H}[y | x, D] - \mathbb{E}_{\theta \sim p(\theta | D)}[\mathcal{H}[y | x, \theta]]
$$
其中 $x$ 是输入，$y$ 是可能的标签，$D$ 是训练数据，$\theta$ 是可能的参数。在回归案例中，我们可以使用贝叶斯推理将第一项改为输出的方差。但是，第二项旨在减去随机不确定性。我可以看到在回归场景中，通过使用每个 $(x,y)$ 组合重新训练神经网络以获得可能的输出 y 并再次执行贝叶斯推理来实现这一点。但是，如果您想从 2000 个未标记数据点池中最大化相互信息，这似乎效率低得可笑。我想知道是否存在更直接的方法来计算这种随机不确定性。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/656845/bayesian-active-learning-by-disagreement-bald-for-regression-problems</guid>
      <pubDate>Wed, 06 Nov 2024 16:36:42 GMT</pubDate>
    </item>
    <item>
      <title>难道预期 Sarsa 是离策略的，而 SARSA 只是预期 SARSA 的 MC 估计，为什么它是在线策略的？</title>
      <link>https://stats.stackexchange.com/questions/656843/is-expected-sarsa-is-off-policy-and-sarsa-is-just-an-mc-estimate-of-expected-sa</link>
      <description><![CDATA[因此，预期 SARSA 将更新定义为：
$$
Q(s,a) = Q(s,a) +\alpha (R+ \mathbb{E}_{a\sim\pi(s&#39;)}[Q(s&#39;, a)] - Q(s,a))
$$
其中 SARSA 将更新定义为 $a&#39;\sim\pi(s&#39;)$：
$$
Q(s,a) = Q(s,a) +\alpha (R+ Q(s&#39;, a&#39;) - Q(s,a))
$$
那么 SARSA 怎么会不仅仅是 ExpSARSA 的 MC 估计呢？既然 MC 是无偏的，那么为什么 SARSA 不应该是一种离策略算法呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/656843/is-expected-sarsa-is-off-policy-and-sarsa-is-just-an-mc-estimate-of-expected-sa</guid>
      <pubDate>Wed, 06 Nov 2024 15:53:03 GMT</pubDate>
    </item>
    <item>
      <title>如何根据障碍伽马模型计算后验分布？</title>
      <link>https://stats.stackexchange.com/questions/656841/how-to-compute-posterior-distribution-from-a-hurdle-gamma-model</link>
      <description><![CDATA[我正在对孢子陷阱中的数据进行建模。响应是 DNA 数量，因此 &gt;0。有很多 0（3/4 的数据）。零主要来自潜在孢子源的缺失，而数量取决于孢子源的强度/接近度。
Hurdle-gamma 模型似乎适合此数据。我确实找到了如何在 JAGS 中拟合 hurdle-gamma 模型，并且它收敛得很好。但是，我正在努力计算响应数据 Y 的后验分布。
• 如何计算 Y 的后验？我想到：
 S1[i]~ dbern(P[i]) 
S2[i]~ dgamme(shape[i], rate[i]) 
Ysim​​[i]&lt;- S1[i]*S2[i]

对吗？
• 我仍然需要弄清楚如何从使用的参数化中检索伽马的形状和速率。
我的模型是：
 cat(&quot;model{ # beta / gamma 成分的先验、尺度参数 r 和随机因子方差
for (i in 1:ng) {gamma[i]~ dnorm(0, 0.0001)}
for (i in 1:nb) {binom[i]~ dnorm(0, 0.0001)} 
r~ dgamma(1e-2, 1e-2)
sigma.a ~ dunif(0.001, 50); tau.a= 1 / sigma.a^2
# 使用零技巧的可能性
C &lt;- 10000
for (i in 1:N) { Zeros[i] ~ dpois(-loglik[i] + C)
# 创建一个虚拟的存在/不存在变量，如果 y 小于 0，则为 0如果 y &gt; 0.0001，则为 0.0001 和 1
z[i] &lt;- step(Y[i] - 0.0001)
# gamma 对数似然
# 如果 y&lt;0.0001（即 z=0），则似然为 log(1 - P) 或
# 如果 y&gt;=0.0001（z=1），则为 P * gammalik
logGamma[i] &lt;- (r - 1) * log(Y[i]) - (Y[i] * r) / mu[i] - loggam(r) + r * log(r / mu[i])
loglik[i] &lt;- (1 - z[i]) * log(1 - P[i]) + z[i] * ( log(P[i]) + logGamma[i] )
# 伽马均值和伯努利概率的线性预测器
log(mu[i]) &lt;- inprod(gamma[], Xg[i,]) + alea[comb[i]]
logit(P[i]) &lt;- inprod(binom[], Xb[i,]) }
for (k in 1:ncomb) { alea[k] ~ dnorm(0, tau.a) }
} #close model&quot;, fill=TRUE, file= &#39;traces.R&#39;)

DATA= list(Y= ANA$conc.spore, # 响应
Xg= model.matrix(~1+PI1, ANA), # 来自 gamma 成分的协变量
Xb= model.matrix(~1+(expose&gt;0.5), ANA), # 来自二元成分的协变量 
comb= ANA$COMB, # 随机因子
ncomb= max(ANA$COMB), # Nb 个随机因子组
N= nrow(ANA), # 样本大小
Zeros= rep(0, nrow(ANA)))
DATA$ng= ncol(DATA$Xg); DATA$nb= ncol(DATA$Xb)
]]></description>
      <guid>https://stats.stackexchange.com/questions/656841/how-to-compute-posterior-distribution-from-a-hurdle-gamma-model</guid>
      <pubDate>Wed, 06 Nov 2024 15:22:31 GMT</pubDate>
    </item>
    <item>
      <title>如何测试事件频率（梯度）是否随时间变化？</title>
      <link>https://stats.stackexchange.com/questions/656839/how-to-test-if-the-frequency-of-events-gradient-changes-over-time</link>
      <description><![CDATA[我有 Python 中的时间序列数据，用于跟踪特定操作随时间的变化。我已经量化了这些操作，并想测试这些事件在单位时间内的频率（基本上是梯度）是否随着时间的推移而发生统计变化。基本上，我假设梯度会随着时间的推移而减小，但我想测试这在统计上是否正确。
基本上，我假设梯度会随着时间的推移而减小，但我想测试这在统计上是否正确。
数据由时间戳和一列组成，该列指示操作是否在该时间戳发生。一些时间戳有重复发生的事件（用相同的 ID 分组），而其他时间戳为空或包含单个事件。哪些统计方法（以及 Python 中的库）最适合进行此分析？
data = {
&#39;timestamp&#39;: [
&#39;00:01&#39;, &#39;00:02&#39;, &#39;00:03&#39;, &#39;00:04&#39;, &#39;00:05&#39;, 
&#39;00:06&#39;, &#39;00:07&#39;, &#39;00:08&#39;, &#39;00:09&#39;, &#39;00:10&#39;, 
&#39;00:11&#39;, &#39;00:12&#39;, &#39;00:13&#39;, &#39;00:14&#39;, &#39;00:15&#39;
],
&#39;event_group&#39;: [
1, 1, &#39;&#39;, &#39;&#39;, 2, 
2, 2, &#39;&#39;, &#39;&#39;, 
&#39;&#39;, 3, &#39;&#39;, &#39;&#39;, 4, 4
]
}

df = pd.DataFrame(data)
]]></description>
      <guid>https://stats.stackexchange.com/questions/656839/how-to-test-if-the-frequency-of-events-gradient-changes-over-time</guid>
      <pubDate>Wed, 06 Nov 2024 15:13:25 GMT</pubDate>
    </item>
    <item>
      <title>R 中多个组之间的计数/比例的统计比较？</title>
      <link>https://stats.stackexchange.com/questions/656837/statistical-comparison-of-counts-proportions-between-multiple-groups-in-r</link>
      <description><![CDATA[我正在努力为一个数据集选择适当的统计分析，该数据集中有多个组（groupA-groupE），每个组在两个类别（健康或患病）中都有一定数量的计数，也可以表示为比例（患病/[患病+健康]）：
df &lt;- data.frame(group = c(&quot;groupA&quot;,&quot;groupB&quot;,&quot;groupC&quot;,&quot;groupD&quot;,&quot;groupE&quot;),
n_sick = c(12, 32, 99, 37, 48),
n_healthy = c(36, 250, 120, 68, 93))
df %&lt;&gt;% mutate(tot = n_sick + n_healthy, prop = n_sick / tot)

我想找出哪些组在统计上彼此具有不同的比率，类似于我在 ANOVA/Kruskal-Wallis+事后检验中所做的操作（当存在重复时）。但是，这显然在这里不起作用，因为数据是端点，因此不包含变化。我发现 stats 包包含一个名为 pairwise_prop_test 的函数，它看起来就像是我想要它做的事情：
t &lt;- as.table(rbind(
c(12, 32, 99, 37, 48),
c(36, 250, 120, 68, 93)))
dimnames(t) &lt;- list(
condition = c(&quot;n_sick&quot;, &quot;n_healthy&quot;),
group = c(&quot;groupA&quot;,&quot;groupB&quot;,&quot;groupC&quot;,&quot;groupD&quot;,&quot;groupE&quot;))

pairwise_prop_test(t, p.adjust.method = &quot;bonferroni&quot;)

... 它会针对组间每次比较得出一个 p.adj 值（例如，组 B 与组 C 不同）。这是正确的方法吗，还是我忽略了什么？感谢您抽出时间来提供帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/656837/statistical-comparison-of-counts-proportions-between-multiple-groups-in-r</guid>
      <pubDate>Wed, 06 Nov 2024 14:33:01 GMT</pubDate>
    </item>
    <item>
      <title>相关性质的乘积</title>
      <link>https://stats.stackexchange.com/questions/656836/product-of-correlations-properties</link>
      <description><![CDATA[corr(A,B)*corr(B,C) 是否与 corr(A,C) 有一定关联，还是完全独立？
此乘积 (corr(A,B)*corr(B,C)) 有任何属性吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656836/product-of-correlations-properties</guid>
      <pubDate>Wed, 06 Nov 2024 14:31:48 GMT</pubDate>
    </item>
    <item>
      <title>Pymc-BART 索引错误</title>
      <link>https://stats.stackexchange.com/questions/656835/pymc-bart-index-error</link>
      <description><![CDATA[我尝试按照此处的示例笔记本进行操作，但在执行代码时遇到了一些 IndexError。
这是一个最小的工作示例：
import numpy as np
import pandas as pd
import pymc as pm
import pymc_bart as pmb
import pytensor.tensor as pt
from scipy.special import logit

# 读取样本数据
data_df = pd.read_csv(
&quot;https://raw.githubusercontent.com/juanitorduz/website_projects/master/data/retention_data.csv&quot;,
parse_dates=[&quot;cohort&quot;, &quot;period&quot;],
)

# 处理数据
eps = np.finfo(float).eps
train_data_red_df = data_df.query(&quot;cohort_age &gt; 0&quot;).reset_index(drop=True)
train_obs_idx = train_data_red_df.index.to_numpy()
train_n_users = train_data_red_df[&quot;n_users&quot;].to_numpy()
train_n_active_users = train_data_red_df[&quot;n_active_users&quot;].to_numpy()
train_retention = train_data_red_df[&quot;retention&quot;].to_numpy()
train_retention_logit = logit(train_retention + eps)
train_data_red_df[&quot;month&quot;] = train_data_red_df[&quot;period&quot;].dt.strftime(&quot;%m&quot;).astype(int)
features: list[str] = [&quot;age&quot;, &quot;cohort_age&quot;, &quot;month&quot;]
x_train = train_data_red_df[features]

# 模型
with pm.Model(coords={&quot;feature&quot;: features}) as model:
# --- 数据 ---
model.add_coord(name=&quot;obs&quot;, values=train_obs_idx, mutable=True)
x = pm.MutableData(name=&quot;x&quot;, value=x_train, dims=(&quot;obs&quot;, &quot;feature&quot;))
n_users = pm.MutableData(name=&quot;n_users&quot;, value=train_n_users, dims=&quot;obs&quot;)
n_active_users = pm.MutableData(name=&quot;n_active_users&quot;, value=train_n_active_users, dims=&quot;obs&quot;)

# --- 参数化 ---
# BART 组件在
# logit 变换下对保留率的图像进行建模，因此范围不限制在 [0, 1]。
mu = pmb.BART(
name=&quot;mu&quot;,
X=x,
Y=train_retention_logit,
dims=&quot;obs&quot;,
)
# 我们使用逆 logit 变换将保留率恢复到 [0, 1]。
p = pm.Deterministic(name=&quot;p&quot;, var=pm.math.invlogit(mu), dims=&quot;obs&quot;)
# 我们添加一个小的 epsilon 以避免数值问题。
p = pt.switch(pt.eq(p, 0), eps, p)
p = pt.switch(pt.eq(p, 1), 1 - eps, p)

# --- 可能性 ---
n_active_users_estimated = pm.Binomial(
name=&quot;n_active_users_estimated&quot;,
n=n_users,
p=p,
perceived=n_active_users,
dims=&quot;obs&quot;,
)

pm.model_to_graphviz(model=model)

# 拟合模型
使用模型：
idata = pm.sample(draws=100, chains=1)
posterior_predictive = pm.sample_posterior_predictive(trace=idata)

我已检查 x_train 和 train_retention_logit 的形状传递给 BART 方法，它们似乎具有正确的形状，分别为 (1128,3) 和 (1128,)。
然而，后验采样返回了一个我无法追溯到其来源的错误：
IndexError：元组索引超出范围
导致错误的应用节点：BART_rv{&quot;(i00,i01),(i10),(),(),(),(i50)-&gt;(o00)&quot;}(RNG(&lt;Generator(PCG64) at 0x1721017E0&gt;), [], x, [-1.609437 ... .51268651], 100, 0.95, 2.0, [])
Toposort 索引：0
输入类型：[RandomGeneratorType, TensorType(int64, shape=(0,)), TensorType(float64, shape=(None, None)), TensorType(float64, shape=(1128,)), TensorType(int8, shape=()), TensorType(float64, shape=()), TensorType(float32, shape=()), TensorType(float64, shape=(0,))]
输入形状：[&#39;无形状&#39;, (0,), (1128, 3), (1128,), (), (), (), (0,)]
输入步幅：[&#39;无步幅&#39;, (0,), (8, 9024), (8,), (), (), (), (0,)]
输入值：[Generator(PCG64) at 0x1721017E0, array([], dtype=int64), &#39;未显示&#39;, &#39;未显示&#39;, array(100, dtype=int8), array(0.95), array(2., dtype=float32), array([], dtype=float64)]
输出客户端：[[output[1](BART_rv{&quot;(i00,i01),(i10),(),(),(),(i50)-&gt;(o00)&quot;}.0)], [Second(mu, [-3.09309984])]]

相关库的版本为：
python 3.10.15
pymc 5.16.2
pymc-bart 0.7.0

以防它与软件包版本之间的行为差​​异有关。]]></description>
      <guid>https://stats.stackexchange.com/questions/656835/pymc-bart-index-error</guid>
      <pubDate>Wed, 06 Nov 2024 14:10:28 GMT</pubDate>
    </item>
    <item>
      <title>“最好的测试是无偏见的”这一说法的证明</title>
      <link>https://stats.stackexchange.com/questions/656832/proof-of-the-statement-the-best-test-is-unbiased</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656832/proof-of-the-statement-the-best-test-is-unbiased</guid>
      <pubDate>Wed, 06 Nov 2024 12:41:53 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归后需要进行后续分析吗？</title>
      <link>https://stats.stackexchange.com/questions/656829/need-for-post-analysis-after-logistic-regression</link>
      <description><![CDATA[我正在研究一组 3200 名患者，他们存在许多术后并发症风险因素。我在 R 中进行了逻辑回归，并使用 step() 函数改进了回归。因此，我确定了几个非常重要的风险因素。其中之一就是液体平衡。众所周知，液体过多和过少都可能促进并发症，但我从 R 中得到的是，每增加 100 毫升液体，并发症的可能性就会增加 0.03（估计值）。P=0.001。
我需要对此进行某种事后分析吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656829/need-for-post-analysis-after-logistic-regression</guid>
      <pubDate>Wed, 06 Nov 2024 12:00:05 GMT</pubDate>
    </item>
    <item>
      <title>样本量越大，错误拒绝 0 假设的风险是否会越大？</title>
      <link>https://stats.stackexchange.com/questions/656828/does-the-risk-of-incorrectly-rejecting-the-0-hypothesis-increase-with-a-large-sa</link>
      <description><![CDATA[我经常看到类似这样的话：“如果样本量足够大，较小的效应量可以产生显著的结果”。我不太明白这一点。
对我来说，这听起来是这样的：增加样本量，你最终肯定会拒绝 0 假设（也就是说，如果你将样本量增加到一定大小，你 100% 肯定会拒绝 0 假设）。
重新阅读此主题。据我所知，鉴于我在统计学方面的经验，0 假设被正确拒绝。
决定在 ttest_1samp 测试的代码中检查这一点，使 popmean=15.03 与样本 (mean=15) 的差异非常小。滑块选择 N - 样本，分布实时重新绘制，垂直条是上限值（蓝色）和 p_value（橙色）。
在大约 N - 4000 之后，在大多数情况下，零假设被拒绝。更不清楚的是，在 popmean=15 时，零假设有时也会被拒绝（即均值相等）。
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import t, norm, ttest_1samp
from matplotlib.widgets import Slider

fig, ax = plt.subplots()
fig.subplots_adjust(bottom=0.25)

ax_n = fig.add_axes([0.25, 0.15, 0.65, 0.03])
s_n = Slider(ax_n, &quot;N&quot;, valmin=15, valmax=16000,valinit=30, valstep=1)
mu_0 = 15.03

rng = np.random.default_rng(1)

def update(val):
N = s_n.val
rvs = np.sort(norm.rvs(loc=15, scale=1, size=N, random_state=rng))
mu, std = np.mean(rvs), np.std(rvs)
z_values = (rvs - mu) / std
df = N - 1
pdf = t.pdf(rvs, loc=mu, scale=std, df=df)
tst = ttest_1samp(rvs, popmean=mu_0)
l, r = t.ppf(1 - 0.975, df=df), t.ppf(0.975, df=df)
ci = tst.confidence_interval(confidence_level=0.95)
ci = (ci - mu) / std
ax.clear()
ax.plot(z_values, pdf, lw=2, color=&quot;red&quot;)
ax.axvline(x=(mu_0 - mu) / std, color=&quot;green&quot;, label=&quot;mean 0&quot;)# 0 假设的平均值
ax.axvline(x=ci[0], linestyle=&quot;--&quot;, color=&quot;magenta&quot;, label=&quot;CI&quot;)
ax.axvline(x=ci[1], linestyle=&quot;--&quot;, color=&quot;magenta&quot;)
ax.axvline(x=l, linestyle=&quot;--&quot;, color=&quot;blue&quot;, label=&quot;alfa&quot;)# alfa
ax.axvline(x=r, linestyle=&quot;--&quot;, color=&quot;blue&quot;)# alfa
ax.axvline(x=t.ppf(tst[1]/2, df=df), linestyle=&quot;--&quot;, color=&quot;orange&quot;, label=&quot;p-value&quot;)#p-value
ax.axvline(x=-t.ppf(tst[1]/2, df=df), linestyle=&quot;--&quot;, color=&quot;orange&quot;)#p-value
ax.text(0, (np.max(pdf) + np.min(pdf))/2, &quot;p_value =&quot; + str(round(tst[1], 4)), fontsize=12)
ax.legend()

s_n.on_changed(update)
update(0)

plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/656828/does-the-risk-of-incorrectly-rejecting-the-0-hypothesis-increase-with-a-large-sa</guid>
      <pubDate>Wed, 06 Nov 2024 11:43:12 GMT</pubDate>
    </item>
    <item>
      <title>“分类数据”是“名义数据”的同义词吗？</title>
      <link>https://stats.stackexchange.com/questions/656778/is-categorical-data-a-synonym-of-nominal-data</link>
      <description><![CDATA[到目前为止，我一直认为名义数据是一种分类数据，而不是它的同义词。对我来说，分类数据包括序数数据，而不仅仅是名义数据。
截至 2024 年 11 月，维基百科说（粗体是我的）：

序数数据是一种分类统计数据类型，其中变量具有自然、有序的类别，并且类别之间的距离未知。

这似乎与 Alan Agresti 的分类数据分析简介（第二版，2007 年）一致。第 2 页：

分类变量有两种主要的测量尺度。 [...]
具有有序尺度的分类变量称为序数
变量。
具有无序尺度的分类变量称为
名义变量。

另一方面，CrossValidated 上的categorical-data 标签 表示（粗体是我的）：

分类（也称为名义）数据可以采用有限数量的
可能值，称为类别。分类值“标记”，它们不“测量”。 [...]
对于分析，分类值被视为抽象实体
没有任何数学结构，例如顺序或拓扑，
无论它们如何编码和存储。

加州大学洛杉矶分校统计方法和数据分析网站似乎同意 CrossValidated 的定义（粗体是我的）：

分类变量（有时称为名义变量）是具有两个或多个类别的变量，但类别没有内在顺序。 [...] 纯名义变量仅允许您分配类别，但您无法明确排序类别。

因此，这里似乎存在一些差异。虽然我一般对维基百科有点警惕，但我没有理由怀疑我提到的其他资源，特别是当它们的定义似乎不模棱两可时。
这是否反映了对“分类”定义缺乏共识？换句话说，“分类”是一个允许灵活使用的术语吗？还是我误解了某些内容或遗漏了一些可以调和这些不同参考资料的重要信息？
如果有的话，我还对（最好是学术性的）参考资料感兴趣，讨论“分类”的定义以及可能存在不同定义的问题。
我问这个问题的原因当然不是为了吹毛求疵，而是为了避免在阅读或与其他人讨论这个主题时可能出现的误解。]]></description>
      <guid>https://stats.stackexchange.com/questions/656778/is-categorical-data-a-synonym-of-nominal-data</guid>
      <pubDate>Tue, 05 Nov 2024 10:31:33 GMT</pubDate>
    </item>
    <item>
      <title>结合加权均匀分布和正态分布变量的复杂概率分布建模</title>
      <link>https://stats.stackexchange.com/questions/656659/modelling-of-a-complex-probability-distribution-combining-weighted-uniform-and-n</link>
      <description><![CDATA[最近，我一直在尝试为视频游戏中的随机分布提出一个准确的概率模型。我试图建模的过程如下：

从加权战利品表中随机选择三个物品（有替换）
每个物品都被分配一个正态分布的大小
然后比较这三个物品的大小，并将其中最大的一个交给玩家

在这个过程中，我已经知道从战利品表中选中每个物品的概率，以及每个物品大小分布的平均值和标准差。我如何将这个基本概率与大小分布结合起来，找出考虑到大小分布后选中某个物品的真实概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/656659/modelling-of-a-complex-probability-distribution-combining-weighted-uniform-and-n</guid>
      <pubDate>Sat, 02 Nov 2024 14:33:55 GMT</pubDate>
    </item>
    <item>
      <title>不同大小样本的统计检验[关闭]</title>
      <link>https://stats.stackexchange.com/questions/619762/statistic-test-for-samples-with-different-sizes</link>
      <description><![CDATA[我应该使用什么统计测试来比较不同大小的样本？
我正在使用 DataSUS 的公共数据集，我想看看不同医院同一类型手术的平均值/中位数之间是否存在差异。
手术数量按年份分布：
对于手术类型 1，医院 x 从 2011 年到 2021 年的样本量为 653，医院 y 在同一时期的样本量为 4502（我也有每年的数字）
那么考虑到我想测试同一时期和医院的其他 4 种类型的手术，我应该使用什么测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/619762/statistic-test-for-samples-with-different-sizes</guid>
      <pubDate>Mon, 26 Jun 2023 11:12:41 GMT</pubDate>
    </item>
    </channel>
</rss>