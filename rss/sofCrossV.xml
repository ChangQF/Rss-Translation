<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 16 Nov 2024 09:16:22 GMT</lastBuildDate>
    <item>
      <title>`sklearn.datasets.make_regression` 中 `n_informative` 参数的具体含义是什么？</title>
      <link>https://stats.stackexchange.com/questions/657350/what-is-the-exact-meaning-of-n-informative-parameter-in-sklearn-datasets-make</link>
      <description><![CDATA[sklearn 的官方文档指出

[sklearn.datasets.make_regression] 的输出是通过将具有 n_informative 非零回归量的（可能有偏差的）随机线性回归模型应用于先前生成的输入和一些具有可调比例的高斯中心噪声而生成的。

我很难理解这些词的确切含义。“n_informative 非零回归量”的数学模型是什么？这是否意味着我们生成 n_informative 系数 $w_{k}$，形式为 $w_{0}+\sum_{k=1}^{\text{n_informative}-1}w_{k}x_{k}$，并将其与一些随机噪声一起应用于 n_features 随机字符串以生成初始数据？我们是否生成随机 n_informative$\times$n_features 矩阵？我们如何生成 y 列？]]></description>
      <guid>https://stats.stackexchange.com/questions/657350/what-is-the-exact-meaning-of-n-informative-parameter-in-sklearn-datasets-make</guid>
      <pubDate>Sat, 16 Nov 2024 05:29:38 GMT</pubDate>
    </item>
    <item>
      <title>是否应将规范化应用于交互特征</title>
      <link>https://stats.stackexchange.com/questions/657349/should-normalization-be-applied-on-interaction-feature</link>
      <description><![CDATA[我正在机器学习模型中使用交互特征，通过将数值变量与编码分类特征相乘来创建新特征。我的问题是：
是否应该对这些交互项应用规范化？
如果是，那么规范化不会改变交互项的含义吗？具体来说，当我先对数值特征进行归一化，然后创建交互项时，交互项是否仍表示其最初要捕获的关系？
如果在创建交互项之前对数值变量进行归一化，交互项是否会失去其真实比例或含义？
例如，如果我将归一化数值特征与分类变量（可以是独热编码）相乘，我是否会扭曲数值特征与类别之间的原始关系？
我希望澄清交互项是否应进行归一化或保持原样，尤其是在交互项在捕获特定关系中起关键作用的情况下。
谢谢！
我尝试了什么：
我尝试在创建交互项之前对数值特征进行归一化。具体来说，我先对数值变量进行归一化，然后将其与编码的分类特征相乘。我还尝试在不先对数值变量进行归一化的情况下创建交互特征，以比较这两种方法。
我期望什么？
我希望了解在创建交互项之前对数值特征进行归一化是否会影响模型捕捉数值和分类特征之间预期关系的能力。我还很好奇，由于数值特征的归一化，交互项的含义是否会保留或扭曲。我希望了解归一化是否会导致交互项失去其原始规模和重要性，或者它是否有利于模型收敛和性能。]]></description>
      <guid>https://stats.stackexchange.com/questions/657349/should-normalization-be-applied-on-interaction-feature</guid>
      <pubDate>Sat, 16 Nov 2024 04:02:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么机器学习不会遭受维数灾难？</title>
      <link>https://stats.stackexchange.com/questions/657344/why-doesnt-ml-suffer-from-curse-of-dimensionality</link>
      <description><![CDATA[免责声明：我三天前在 Data Science Stack Exchange 上问过这个问题，但至今没有得到回复。也许这不是正确的网站。我希望在这里得到更多积极的参与。
这个问题困扰了我很久。我是一名训练有素的统计学家，我知道有些事情在高维度上是无法做到的（或者至少你不会得到你想要的，但你可能会得到其他东西）。
有维数灾难的概念。例如，密度估计在高维度上非常慢，因为核密度估计的收敛速度是 $𝑛^{−2/(2+𝑑)}$
。显然，当 𝑑→∞
时，这个速率基本上表现得像一个常数，因此在高维度上进行密度估计基本上是不可能的。但我们经常看到在高维度中使用扩散模型和其他方法。我在这里并不是真正谈论理论；相反，它们用于稳定扩散、Dall-E 等，效果很好！
然后是高维分类中的可分离性概念。逻辑回归通常用作许多神经网络的顶层。随着数据维数的增加，类别变得越来越分离。因此，分类在高维中几乎是微不足道的。但这也意味着逻辑 MLE 不存在，因为可以有无限多个分类器。所以，我们得到了一个分类器，但我们得到了我们想要的吗？
传统知识提供的内容与 ML 所实现的内容之间似乎存在差异。我的问题是关于这种差异的。传统理论家错过了什么？有明显的陷阱，但不知何故 ML 似乎并没有陷入其中。我们得到的是不是我们真正想要的东西，而只是因为最终产品“看起来”很好，我们认为这就是我们一直想要的？
有人知道可能的原因是什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657344/why-doesnt-ml-suffer-from-curse-of-dimensionality</guid>
      <pubDate>Sat, 16 Nov 2024 00:56:40 GMT</pubDate>
    </item>
    <item>
      <title>R 如何使用包含 0 和 1 值的 lmer 和 glmmTMB 最好地模拟连续双峰生存数据</title>
      <link>https://stats.stackexchange.com/questions/657335/r-how-best-to-model-continuous-bimodal-survival-data-using-lmer-and-glmmtmb-that</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657335/r-how-best-to-model-continuous-bimodal-survival-data-using-lmer-and-glmmtmb-that</guid>
      <pubDate>Fri, 15 Nov 2024 21:22:44 GMT</pubDate>
    </item>
    <item>
      <title>使用矩法估计 θ，使用变换 g(θ)=ln x</title>
      <link>https://stats.stackexchange.com/questions/657326/estimator-of-%ce%b8-using-the-method-of-moments-using-transformation-g%ce%b8-ln-x</link>
      <description><![CDATA[问题：
我们有一个连续随机变量 𝑋，其概率密度函数 (pdf) 为：
$$f(x) = \begin{cases}\theta/(x^\theta)+1, &amp; x &gt; 1, \theta&gt; 0\\ 0, &amp;\textrm{otherwise}\end{cases}.$$
使用变换的矩量法找到 θ 的估计量，$g(\theta) = \ln x$。
方法：
我首先尝试使用一般程序，该程序涉及计算 X 的期望，而不考虑变换，但找不到任何解决方案。
我在这里发布这个问题，希望有人可以指导我如何解决这个问题。如果有人可以澄清使用变换是否是解决问题的关键，那将非常有帮助，如果是这样，任何关于如何使用它的见解都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657326/estimator-of-%ce%b8-using-the-method-of-moments-using-transformation-g%ce%b8-ln-x</guid>
      <pubDate>Fri, 15 Nov 2024 18:33:41 GMT</pubDate>
    </item>
    <item>
      <title>如果 alpha = 0.05 时 p 值为 0.0503，我们是否拒绝原假设？如果有的话，用什么方法可以验证拒绝？</title>
      <link>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</link>
      <description><![CDATA[我知道它大于 0.05，但我只是想知道，因为将其四舍五入到小数点后两位会得到 0.05。我只是想确保我没有错误地接受零假设。有没有办法说，即使这个值接近 alpha，也有足够的证据拒绝零假设？
另外，我知道我不应该这样做，但在进行事后分析后，我得到了不同治疗之间的均值结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</guid>
      <pubDate>Fri, 15 Nov 2024 17:58:11 GMT</pubDate>
    </item>
    <item>
      <title>泛化误差与模型复杂度呈 U 形曲线（偏差方差权衡）</title>
      <link>https://stats.stackexchange.com/questions/657317/generalization-error-as-u-shape-curve-with-respect-to-model-complexity-bias-var</link>
      <description><![CDATA[是否有任何数学著作严格证明某些学习问题的泛化误差随模型复杂度（偏差方差权衡）呈现 U 形曲线？有任何参考资料吗]]></description>
      <guid>https://stats.stackexchange.com/questions/657317/generalization-error-as-u-shape-curve-with-respect-to-model-complexity-bias-var</guid>
      <pubDate>Fri, 15 Nov 2024 15:41:58 GMT</pubDate>
    </item>
    <item>
      <title>就状态值函数而言的动作值函数</title>
      <link>https://stats.stackexchange.com/questions/657309/action-value-function-in-terms-of-state-value-function</link>
      <description><![CDATA[我正在读 Sutton&amp;Barto 的书。我在练习 3.13 处卡住了。问题是根据 vπ 和 p(s′,r∣s,a) 写出 qπ。我追踪了以下步骤：
$q_\pi(s,a) = \sum_g g \text{ Pr}\{G_t=g|S_t=s, A_t=a\}$
$= \sum_g g \sum_{s&#39;} \text{ Pr}\{G_t=g, S_{t+1}=s&#39;|S_t=s, A_t=a\}$
$= \sum_g g \sum_{s&#39;} \text{ Pr}\{G_t=g|S_{t+1}=s&#39;, S_t=s, A_t=a\} \text{ Pr}\{S_{t+1}=s&#39;|S_t=s, A_t=a\}$
$= \sum_{s&#39;} \text{ Pr}\{S_{t+1}=s&#39;|S_t=s, A_t=a\} \sum_g g \text{ Pr}\{G_t=g|S_{t+1}=s&#39;, S_t=s, A_t=a\}$
我该如何继续，或者我的逻辑是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/657309/action-value-function-in-terms-of-state-value-function</guid>
      <pubDate>Fri, 15 Nov 2024 11:40:51 GMT</pubDate>
    </item>
    <item>
      <title>在 Kruskal-Wallis 之后，通过使用 Wilcoxon 进一步比较各组来获取更多信息？（当无法进行双向方差分析时）</title>
      <link>https://stats.stackexchange.com/questions/657307/gaining-additional-information-after-kruskal-wallis-by-further-comparing-groups</link>
      <description><![CDATA[我有以下实验设置，数字是六组中的个体：



场景
治疗 1
治疗 2
治疗 3




A
28
27
27


B
28
28
28



已经测量过一次的是基于两种治疗方法的小鼠移动距离不同场景。所有个体都是独一无二的，在各组之间不会重复。
研究问题是三种治疗方法在移动距离上是否会有所不同。为了增加另一层，我们在两种不同的场景中对其进行了测试，以查看这是否对治疗方法有影响。
不幸的是，我们无法进行双向方差分析来测试交互作用。相反，我们针对每种情况分别进行了 Kruskal-Wallis (KW)，然后如果显著则进行 Dunn 的事后检验。

问题 1。在 A 和 B 中的治疗 1 之间进行 Wilcoxon 检验，然后在 A 和 B 中的治疗 2 之间进行另一次 Wilcoxon 检验，最后在 A 和 B 中的治疗 3 之间进行一次 Wilcoxon 检验，这在统计上合理吗？
问题 2。同样，在场景 A 和 B 之间进行 Wilcoxon 检验听起来是否合理？

我的理由是，对于 Q1，我将根据场景查看治疗之间是否存在差异。但与此同时，我知道这不是双向方差分析相互作用效应的适当替代品。如果我发现治疗 1 在 A 和 B 之间存在显著性，但其余治疗没有显著性，那么解释起来会很困难。因此，我认为 Q2 会更合理，因为它至少可以表明这两个场景作为一个整体是否有影响。
我知道 p-hacking，这是我希望避免的事情。但如果可以从实验中获得更多信息，那就太好了，这就是我希望得到答案的原因！此外，如果其中任何一个可行，我需要考虑哪些调整？]]></description>
      <guid>https://stats.stackexchange.com/questions/657307/gaining-additional-information-after-kruskal-wallis-by-further-comparing-groups</guid>
      <pubDate>Fri, 15 Nov 2024 10:51:11 GMT</pubDate>
    </item>
    <item>
      <title>证明 $(X, Y, Z)$ 相互独立意味着给定 $Z$，$X$ 和 $Y$ 也独立</title>
      <link>https://stats.stackexchange.com/questions/657266/proving-mutual-independence-of-x-y-z-implies-independence-of-x-and-y-g</link>
      <description><![CDATA[我想证明或反驳以下结果：
设$(\Omega, \mathcal F, \mathbb P)$为概率空间，且$X, Y, Z : \Omega \to \mathbb R$为相互独立的、$(\mathcal F, \mathcal B(\mathbb R))$-可测随机变量；那么 $X$ 和 $Y$ 在给定 $Z$ 的情况下是独立的。
我读到了以下问题的答案：在给定 Z 的情况下，X、Y、Z 的相互独立性是否意味着 X 和 Y 的条件独立性，然而在我看来，它假设 $X$、$Y$ 和 $Z$ 具有密度（相对于同一测量）。这不是我希望做出的假设。
我想使用的条件独立性、概率和独立性的特征如下（如果它们不正确，请告知）：

$X$ 和 $Y$ 是独立的，给定 $Z$，如果 $\mathbb P((X, Y) \in A \times B | Z) = \mathbb P(X \in A | Z) \mathbb P(Y \in B | Z)$ 对每对 borelian 集 $(A, B)$ 成立；
$\mathbb P(Y \in A | Z) = \mathbb E[\boldsymbol 1_{A} \circ Y | Z]$ 对于每个 borelian 集 $A$;
$\mathbb E[U | Z]$ 对于一个$(\mathcal F, \mathcal B(\mathbb R))$-可测变量，定义为唯一（几乎处处相等）$(\sigma(Z), \mathcal B(\mathbb R))$-可测随机变量，满足$\int_\Omega \boldsymbol (1_A \circ U)\ U \text d\mathbb P = \int_\Omega \mathbb E[U | Z] \boldsymbol 1_A \circ U \text d \mathbb P$ 对于每个 borelian 集 $A \subseteq \mathbb R$。

我仍然对所有这些符号感到困惑，并希望正式推导结果，尽可能合理地使用测度理论符号而不是概率符号。
我的问题是：

结果在一般情况下仍然正确吗？
我给出的预期期望定义是否正确（它应该是将我的教科书中给出的定义翻译成测度理论语言，但我可能遗漏了一些东西）？
这种表征是证明结果的合理起点吗？
我应该如何开始？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657266/proving-mutual-independence-of-x-y-z-implies-independence-of-x-and-y-g</guid>
      <pubDate>Thu, 14 Nov 2024 18:11:34 GMT</pubDate>
    </item>
    <item>
      <title>将 Hessian 矩阵居中并进行 QR 变换后恢复为原始参数 X</title>
      <link>https://stats.stackexchange.com/questions/657210/transforming-hessian-to-original-parameters-after-centering-and-qr-transforming</link>
      <description><![CDATA[在进行最大似然估计 (MLE) 或贝叶斯后验抽样时，我开始更常规地对设计矩阵 $X$ 进行均值中心化和 QR 旋转。这有助于收敛，并在存在共线性时加快后验抽样。在对 $X$ 的列进行均值中心化之后，R qr 函数会转换（正交归一化）$X$，并提供一个矩阵 Rinv（我将其缩写为 $R$），该矩阵可与参数向量相乘以获得原始尺度上的参数。然后，将均值中心化反转以调整截距。我正在使用比例优势半参数模型来计算因变量 $k+1$ 个不同值 $Y$，因此有 $k$ 个截距 $\alpha_{1}, \ldots, \alpha_{k}$。在原始尺度上，当 $p$ 个 $X$ 列时，有 $p$ 个回归系数 $\beta_{1}, \ldots, \beta_{p}$。假设变换后的 $X$ 上的 MLE 为 $\delta$ 和 $\gamma$，分别对应于原始 $X$ 上的 $\alpha, \beta$。
给定矩阵 $R$ 和均值向量，很容易从 $\delta, \gamma$ 计算出 $\alpha, \beta$。令 $M$ 为 $k$ 行行重复矩阵，其中 $p$ 列包含 $X$ 的 $p$ 个原始列均值，即 $M = 1_{k\times 1} \times \bar{X}$，其中 $\bar{X}$ 是 $1\times p$ 均值向量。然后
$\beta = R \gamma$
$\alpha = \delta - M R \gamma$
让 $H$ 表示 $\delta, \gamma$ 的对数似然函数的二阶偏导数的 $(k+p)\times (k+p)$ 矩阵。将 $H$ 划分为
$$
\begin{bmatrix}
A_{k\times k} &amp; B_{k \times p} \newline
B&#39; &amp; D_{p\times p}
\end{bmatrix}
$$
我的理解是，变换参数尺度上的 $H$ 由以下公式计算得出
$J&#39;HJ$
其中雅可比矩阵 $J$ 由以下公式给出
$$
\begin{bmatrix}
\frac{\partial\alpha}{\partial\delta} &amp; \frac{\partial\alpha}{\partial\gamma} \newline
\frac{\partial\beta}{\partial\delta} &amp; \frac{\partial\beta}{\partial\gamma}
\end{bmatrix}
$$
等于
$$
\begin{bmatrix}
I_{k\times k} &amp; -M_{k\times p}R_{p\times p} \newline
0_{p\times k} &amp; R_{p\times p}
\end{bmatrix}
$$
其中 $I$ 是单位矩阵，而 $0$ 是零矩阵。
我用于计算转换后的 $H$ 的 R 代码是
M &lt;- matrix(1, nrow=k, ncol=1) %*% matrix(xbar, nrow=1)
J &lt;- rbind(cbind(diag(k), -M %*% R),
cbind(matrix(0, nrow=p, ncol=k), R ) )
H2 &lt;- t(J) %*% H %*% J

但在我的例子中，我得到的 H2 值，尤其是 $\beta$ 的右下子矩阵，偏差很大。有人能发现我哪里出错了吗？在贝叶斯设置中，一切都很简单，因为您只需为每个后验抽样计算 $\alpha$ 和 $\beta$，即可获得原始参数的正确后验分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/657210/transforming-hessian-to-original-parameters-after-centering-and-qr-transforming</guid>
      <pubDate>Wed, 13 Nov 2024 15:34:57 GMT</pubDate>
    </item>
    <item>
      <title>以不同时间频率收集变量的纵向回归模型？</title>
      <link>https://stats.stackexchange.com/questions/655840/longitudinal-regression-models-with-variables-collected-at-different-time-freque</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655840/longitudinal-regression-models-with-variables-collected-at-different-time-freque</guid>
      <pubDate>Wed, 16 Oct 2024 05:18:50 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型是否有类似间隔重复学习的东西？</title>
      <link>https://stats.stackexchange.com/questions/624601/is-there-anything-like-spaced-repetition-learning-for-machine-learning-models</link>
      <description><![CDATA[我想知道是否存在类似间隔重复的方法，但这种方法可以帮助机器学习模型学习。
间隔重复是一种人类学习抽认卡的方法，算法会尝试在学习者可能忘记之前展示抽认卡。
例如，如果抽认卡正确，你会在一天内再次看到它。如果再次正确，你会在两天后看到它，然后是四天，依此类推。如果你做错了，你的记忆时间就会降到零天，你必须重新做一遍。它基于赫尔曼·艾宾浩斯对遗忘曲线的发现。从 1880 年到 1885 年，他通过记忆一种假语言的单词对自己进行了实验（因为没有其他人愿意这样做）。这使他无法将已知单词与他试图记忆的单词联系起来，因此他可以获得更好的原始记忆数据。如今，确定等待时间的算法稍微复杂一些，但基本思想仍然适用。（如果您有兴趣尝试，请谷歌搜索“anki”）

将这个想法应用于机器学习会产生任何好处吗？或者已经存在类似的东西吗？基本上是相同的想法，但使用时期而不是天来管理何时应该进行审查。我知道灾难性遗忘是一种现象，但如果以类似于间隔重复的方式进行训练，也许有一些架构会保留在记忆中。这个想法让我想到了批处理，有时如果你不同时关注所有示例的梯度，你就可以摆脱局部最小值。
还有一些细节：你如何判断模型是否“正确”？例如，假设你正在训练一个分类模型，当它对正确类别有 90% 的确定性时，它是否正确？也许你可以随着每张卡片的训练而将正确所需的百分比降低到更高的水平，以将其引入 99.99% 的领域？也许有一种更好的通用方法可以根据该卡片的确定性历史来确定何时进行审查？使用这种方法是否存在偏见的危险？ （即：它会对有困难的练习进行更艰苦的训练，因此它会变得更好，但在它认为容易的练习上却变得更糟，并且来回反复？）在开启间隔重复之前，你是否必须进行一段时间的定期训练才能使其发挥作用？
谢谢阅读。]]></description>
      <guid>https://stats.stackexchange.com/questions/624601/is-there-anything-like-spaced-repetition-learning-for-machine-learning-models</guid>
      <pubDate>Tue, 22 Aug 2023 13:24:04 GMT</pubDate>
    </item>
    <item>
      <title>如何测试离散特征中的系统发育信号（即寄生虫数量）</title>
      <link>https://stats.stackexchange.com/questions/604797/how-can-i-test-for-phylogenetic-signal-in-a-discrete-trait-i-e-counts-of-para</link>
      <description><![CDATA[我正在 R 中运行具有泊松误差分布的 PGLMM，以评估社会性（二项式）对寄生虫负荷的影响。我想测试离散数据中的系统发育信号（例如鸟类寄生虫数量）。但是，我发现了几种在连续数据（phytools::phylosig ..pagel&#39;s, K, ）和分类数据（data ape::delta）中测试系统发育信号的方法，但在离散数据（计数数据）中测试系统发育信号的方法并不多。任何想法都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/604797/how-can-i-test-for-phylogenetic-signal-in-a-discrete-trait-i-e-counts-of-para</guid>
      <pubDate>Thu, 09 Feb 2023 01:51:14 GMT</pubDate>
    </item>
    <item>
      <title>如果我只能计算 $g(X)$ 的平均值，那么 LOTUS 的意义何在？</title>
      <link>https://stats.stackexchange.com/questions/602510/what-is-the-point-of-lotus-if-i-can-just-compute-the-average-of-gx</link>
      <description><![CDATA[无意识统计学家定律 (LOTUS) 是一条定理，用于计算随机变量 $X$ 的函数 $g(X)=Y$ 的期望值，当人们知道 $X$ 的概率分布，但不知道 $g(X)$ 的分布时。
如果 LOTUS 的目的是找到期望值 $E[g(X)]$，那么该定理建议使用 $X$ 的概率密度和 $g(X)$ 的值：
$$E[g(X)]=\sum_x\,g(x)f_X(x),\;\text{(discrete)}$$
或
$$E[g(X)]=\int_{-\infty}^{\infty}\,g(x)f_X(x)\,dx,\;\text{(continuous).}$$
但是，这是我的问题：如果我们知道并且可以访问所有实现$y=g(x)$，那么为什么我们不计算$g$的平均值呢？为什么我要涉及$X$的 PDF/PMF？]]></description>
      <guid>https://stats.stackexchange.com/questions/602510/what-is-the-point-of-lotus-if-i-can-just-compute-the-average-of-gx</guid>
      <pubDate>Thu, 19 Jan 2023 13:00:49 GMT</pubDate>
    </item>
    </channel>
</rss>