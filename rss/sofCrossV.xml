<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 12 Oct 2024 09:17:29 GMT</lastBuildDate>
    <item>
      <title>关于因子分析的一些困惑</title>
      <link>https://stats.stackexchange.com/questions/655678/some-confusion-on-factor-analysis</link>
      <description><![CDATA[我是一名数学专业的学生，​​最近在自学因子分析。
虽然我对基础统计学有一些了解，但我觉得很难转换成统计学的思维方式。
以下是我对因子分析的一些困惑。
我读的书和维基百科都是这样定义因子分析的：

在因子分析中，让$\mathbf{x}=(x_1,\cdots,x_p)$成为一个显性变量。
我们想要找到一个矩阵 $L$，
$k$ 个随机变量 $f_1,\cdots,f_k$ 和 $p$ 个随机变量 $\epsilon_1,\cdots,\epsilon_p$，
且它们相互独立，$E(f_i)=0$，$\text{var}(x_i)=1$ 和 $E(\epsilon_i)=0$，并且
\begin{equation*}
\begin{pmatrix}x_1\\ \cdots\\x_p\end{pmatrix}=L\begin{pmatrix}f_1\\ \cdots\\f_k\end{pmatrix}+\begin{pmatrix}\epsilon_1\\ \cdots\\ \epsilon_p\end{pmatrix}.
\end{equation*&gt;

我有几个问题。
(1) 在上面的等式中，我们是否将$x_i$视为随机变量？
例如，我们通常对样本值进行标准化。
如果我们事先知道每个$x_i$都服从正态分布，并对其进行了标准化，那么在上面显示的方程中，我们是否将$x_i$视为随机变量，并且$x_i\sim N(0,1)$？
(2) 假设 (1) 成立。那么显示的方程就是一个随机变量方程。
但是没有像概率论那样的概率空间。
那么我们如何解释显示的方程，它是随机变量之间的等式？
一开始我认为这应该意味着它的似然性，或者，$p(\text{方程成立}| L)$应该接近于$1$。
但后来我觉得可能不是这样，因为我们不知道$\epsilon_i$和$f_i$的分布。
但是，如果我们不要求上述等式以一定的似然性成立，
那么似乎几乎任何随机变量都可以成为一个因子，条件很简单？
(3) 我问过一位教授，如果我们已经确定了$L$，那么我们如何回过头来为我们收集的每个样本数据求解$(f_i)_{1\le i\le k}$，$(\epsilon_i)_{1\le i\le k}$？
教授回答说我们不需要这样做，因为$f_i,\epsilon_i$是随机的。
对吗？如何进一步解释这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/655678/some-confusion-on-factor-analysis</guid>
      <pubDate>Sat, 12 Oct 2024 05:32:18 GMT</pubDate>
    </item>
    <item>
      <title>如果倾向评分匹配 (PSM) 中治疗组大于对照组，应该怎么办 - DiD 方法</title>
      <link>https://stats.stackexchange.com/questions/655677/what-should-it-be-if-the-treatment-group-is-larger-than-the-control-group-in-pro</link>
      <description><![CDATA[为了进行差异分析（DiD），以模拟随机对照试验，我们通常使用倾向得分匹配（PSM）来消除事件日期之前治疗组和对照组之间的差异。
通常，我们会有一个小的治疗组和一个大的对照组，我们只需遵循原来的步骤即可。
但今天我面临的是不同的事情：
当我尝试检查法律 A 对澳大利亚所有上市公司的影响时，我应该将法律 A 对澳大利亚公司的影响与匹配后的新治疗组和对照组中的公司进行比较。只有 1:1 匹配效果很好。
在使用 1:1 匹配运行回归分析后，我仍然发现法律 A 对澳大利亚公司的影响比新西兰公司更大（通过使用 DiD）。
我想知道我的 1:1 匹配设置是否可以接受，因为这意味着由于最后一家新西兰公司，并非所有澳大利亚公司都会在匹配样本中匹配。]]></description>
      <guid>https://stats.stackexchange.com/questions/655677/what-should-it-be-if-the-treatment-group-is-larger-than-the-control-group-in-pro</guid>
      <pubDate>Sat, 12 Oct 2024 04:51:39 GMT</pubDate>
    </item>
    <item>
      <title>我们何时在 glm 中使用非规范链接函数？</title>
      <link>https://stats.stackexchange.com/questions/655676/when-do-we-use-non-canonical-link-functions-in-glm</link>
      <description><![CDATA[例如，如果响应变量服从二项分布，则典型链接函数为 logit 链接。但是，其他链接函数也可用，例如 probit 链接和对数对数链接（但这些不是典型链接函数）。典型链接函数使统计推断的某些方面变得容易得多。但是，有时典型链接函数不太适合数据，我们不得不使用非典型链接函数来建立更好的回归模型。
我想知道在统计建模中是否存在一些经典情况，我们可以立即知道典型链接函数不适合？
我尝试进行一些研究，并认为混合模型或 gamma-hurdel 模型等一些模型可能由于其独特的设置而涉及非典型链接函数。但是是否存在一些众所周知的情况（例如双峰响应，响应中有许多零），我们可以立即知道具有典型链接的 GLM 不是一个好主意？]]></description>
      <guid>https://stats.stackexchange.com/questions/655676/when-do-we-use-non-canonical-link-functions-in-glm</guid>
      <pubDate>Sat, 12 Oct 2024 04:38:33 GMT</pubDate>
    </item>
    <item>
      <title>威尔克斯定理，投影子空间上的置信区域？</title>
      <link>https://stats.stackexchange.com/questions/655675/wilks-theorem-confidence-regions-on-a-projected-subspace</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655675/wilks-theorem-confidence-regions-on-a-projected-subspace</guid>
      <pubDate>Sat, 12 Oct 2024 04:03:54 GMT</pubDate>
    </item>
    <item>
      <title>报告缺失数据的分类器准确率</title>
      <link>https://stats.stackexchange.com/questions/655674/report-classifier-accuracy-with-missing-data</link>
      <description><![CDATA[假设我们正在读取血压。有些读数已损坏且无法使用。然后我们训练二元分类器来检测高血压。当我们的模型无法使用某些数据时，实验设计理论对报告分类器准确性有何看法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655674/report-classifier-accuracy-with-missing-data</guid>
      <pubDate>Sat, 12 Oct 2024 00:40:54 GMT</pubDate>
    </item>
    <item>
      <title>从系统中删除无关值以确定概率</title>
      <link>https://stats.stackexchange.com/questions/655673/removing-extraneous-values-from-system-to-determine-probability</link>
      <description><![CDATA[我试图确定以下系统实例的发生概率，该系统有利于总和 &gt;= 106.6 和 =&lt; 117：
106.6 =&lt; 4.1x + 4.7y + 5.6z + 6.6t =&lt; 117 &amp;&amp; x + y + z + t == 26, {x,y,z,t} ∈ ℕ
但是，产生的组合数大大超过有利于确定概率的实际计数。例如，任何组合中 6.6 从初始位置连续出现 18 次，系统都不可能产生结果 =&lt; 117。然而，仍有 4^8 个子代组合。我可以通过什么方式确定系统内所有此类子代组合的数量？我怎样才能将这些后代从不利组合池中移除？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655673/removing-extraneous-values-from-system-to-determine-probability</guid>
      <pubDate>Fri, 11 Oct 2024 23:45:24 GMT</pubDate>
    </item>
    <item>
      <title>需要进行多少次测试（以及必须通过多少次）才能保证我的软件在 90% 的时间内以 95% 的置信度正常运行？</title>
      <link>https://stats.stackexchange.com/questions/655671/how-many-test-executions-are-required-and-how-many-must-pass-to-say-my-softwar</link>
      <description><![CDATA[我有一些软件，其运行方式不确定。根据未知的外部因素，对代码运行测试可能会导致测试通过或失败。假设由于这些因素，测试通过或失败的几率相等，我必须运行测试多少次，软件必须通过测试多少次，这样我才能有 95% 的信心说软件在 90% 的时间内按预期运行？
编辑：假设外部因素导致测试失败的几率未知，而不是测试通过/失败相等。]]></description>
      <guid>https://stats.stackexchange.com/questions/655671/how-many-test-executions-are-required-and-how-many-must-pass-to-say-my-softwar</guid>
      <pubDate>Fri, 11 Oct 2024 22:37:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 GLM 或 GLMM 来衡量多样性指标</title>
      <link>https://stats.stackexchange.com/questions/655665/using-glms-or-glmms-for-diversity-metrics</link>
      <description><![CDATA[我希望有人能帮我解答一个有关统计分析的问题。我正在查看物种计数数据，其中在重复地点进行了多年的采样。例如，每年在六个不同的地点进行采样。这些年份被分为一个温度组，有两个因素：温暖或寒冷。我只对探索不同温度组和不同年份之间的社区差异感兴趣。我使用 vegan 包来计算多样性指标（丰度、丰富度、多样性指数），并希望统计检查指标之间的差异。
我一直在使用带有负二项分布的 mvabund 包，但我想知道现在是否应该将重复的站点添加为随机效应，它实际上是一个混合模型。在这种情况下，glmmTMB 或 lme4 是否更合适？我不太熟悉在 R 中使用混合模型，因此非常感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655665/using-glms-or-glmms-for-diversity-metrics</guid>
      <pubDate>Fri, 11 Oct 2024 19:40:20 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 到 pytorch 权重转移[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655658/tensorflow-to-pytorch-weights-transfer</link>
      <description><![CDATA[我正尝试在 pytorch 中模拟一个经过修改的 efficientnet TF 模型。我在 pytorch 中对模型进行了架构更改，转储了 TF 模型权重，然后将其重新加载到新的 pytorch 模型中。使用以下代码在 TF 中转储权重：
model = tf.saved_model.load(model_path)
ws = []
for i in range(len(model.variables)):
ws.append((i, model.variables[i].name, model.variables[i].numpy()))

with open(&quot;manually_dumped_contentnet_weights.pkl&quot;, &quot;wb&quot;) as ofile:
pickle.dump(ws, ofile)

pytorch 中的权重形状似乎与架构和导入的权重相匹配（在 conv2d 和深度 conv2d 之间进行转换之后）。我可以毫无错误地运行模型。但输出结果与 TF 模型的输出结果大不相同。
我注意到在 TF 代码中，模型不是直接加载的，而是在 tf Session 中加载的：
with Session(graph=Graph(), config=ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
saved_model.loader.load(sess, [saved_model.tag_constants.SERVING], model_path)
patch_feature, patch_label = sess.run(output_nodes,feed_dict={input_node: patch})

现在我想知道我最初转储模型权重的尝试是否做得不正确。或者如果我遗漏了其他内容。
我在加载数据时进行的转置是 conv2d 的 (3,2,0,1) 和深度 conv2d 的 (2,3,0,1)：
def reload_conv2d(layer, weights):
### weights 是一个元组，其中每个元素都由一个三元组组成：(1) 索引号，(2) TF 中权重转储的层的名称，以及 (3) 权重
count = 0
if (
&quot;/conv2d/kernel&quot; not in weights[0][1]
and &quot;/conv2d_1/kernel&quot; not in weights[0][1]
and &quot;depthwise_conv2d/depthwise_kernel&quot; not in weights[0][1]
and &quot;final_conv2d/final_conv2d&quot; 不在 weights[0][1] 中 :
raise ValueError(
f&quot;需要在第一个索引上有 conv2d/kernel，但得到了 {weights[0][1]}&quot;
)
transpose_shape = (2,3,0,1) if &quot;depthwise&quot;在 weights[0][1] 中否则（3、2、0、1）
transposed_weights = torch.from_numpy（weights[0][2].transpose（transpose_shape[0]、transpose_shape[1]、transpose_shape[2]、transpose_shape[3]））
layer.weight.data = transposed_weights
count += 1
如果 layer.bias 不是 None 或 layer.bias:
如果（
&quot;/conv2d/bias&quot; 不在 weights[1][1] 中
并且 &quot;/conv2d_1/bias&quot; 不在 weights[1][1] 中
）：
引发 ValueError（
f&quot;需要在第二个索引上有 conv2d/bias 但得到了 {weights[1][1]}&quot;
)
layer.bias.data = (
torch.from_numpy(weights[1][2])
如果type(weights[1][2]) == np.ndarray
else torch.from_numpy(weights[1][2])
)
count += 1
return layer, count

为什么 pytorch 和 TF 模型对相同输入给出完全不同的结果？是因为权重倾倒，还是权重加载……或者是模型架构变化？输入 TF 权重（在模型更改和转置之后）加载正常，我可以毫无问题地运行模型，但这对于调试它没有任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655658/tensorflow-to-pytorch-weights-transfer</guid>
      <pubDate>Fri, 11 Oct 2024 16:26:04 GMT</pubDate>
    </item>
    <item>
      <title>估计概率值大于来自未知分布的 x</title>
      <link>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</link>
      <description><![CDATA[假设我们有 N 个项目的总体，其值从 0 到 6000。
假设总体的平均值是 $\mu$。
我们不知道项目的分布。
我们从这个总体中提取一个项目，我们如何估计 $P(x\geq 2500)$？
同样的问题，假设分布是均匀的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</guid>
      <pubDate>Fri, 11 Oct 2024 08:52:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么 $H(Y|X) \le H(Y)$</title>
      <link>https://stats.stackexchange.com/questions/655621/why-hyx-le-hy</link>
      <description><![CDATA[假设我们有 100 张牌，其中 98 张两面都是白色，一张两面都是黑色，最后一张一面是白色，另一面是黑色。
如果我问“我看到的是哪一面”，我们有 $p(F) \sim Be(0.985)$，因为我们有 3 张黑面和 197 张白面。因此，$H(F) \approx 0.0808$
现在，假设我知道另一面是黑色。然后 $p(F|F&#39;=black) \sim Be(0.5)$, $H(F|F&#39;=black) = 1$
因此，在我看来，额外的信息似乎增加了熵，但信息论明确指出 $H(Y|X) \le H(Y)$，因此知道另一面的颜色不应该让我更加不确定
因此，我的结论是，我严重误解/遗漏了一些东西，有什么想法吗？我应该考虑平均条件熵而不是特定情况吗？...]]></description>
      <guid>https://stats.stackexchange.com/questions/655621/why-hyx-le-hy</guid>
      <pubDate>Thu, 10 Oct 2024 21:04:25 GMT</pubDate>
    </item>
    <item>
      <title>事件发生后定义治疗的差异-差异法</title>
      <link>https://stats.stackexchange.com/questions/655620/difference-in-difference-with-treatment-defined-after-event</link>
      <description><![CDATA[我正在写一篇使用差异-差异设计方法的科学论文，但这不是标准的 DID 设置。
考虑一下我们在多个时间段收集多个公司观察结果的情况。在 $t=0$ 时发生一个事件。到目前为止，一切都很基本。现在偏离标准设置：不知道哪些公司属于治疗组和对照组，治疗组被定义为那些可观察特征 $x$ 从事件前到事件后从 $0$ 变为 $1$ 的公司。控制公司是那些特征 $x$ 保持在 $0$ 的公司。
这是 DID 设计的常见/已知版本吗？如果是，如果您能给我提供一些文献，我会很高兴，因为我还没有找到任何接近这个的文献。]]></description>
      <guid>https://stats.stackexchange.com/questions/655620/difference-in-difference-with-treatment-defined-after-event</guid>
      <pubDate>Thu, 10 Oct 2024 20:42:08 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归：共线性或接近共线性的参数的部分效应解释</title>
      <link>https://stats.stackexchange.com/questions/655518/multiple-linear-regression-partial-effects-interpretation-of-parameters-at-near</link>
      <description><![CDATA[我正在看一个最简单的多元线性回归模型示例：
\begin{equation}\label{linreg}
Y = \beta_1 X_1 + \beta_2 X_2 + \varepsilon,
\end{equation&gt;
我对当 $X_1=X_2$（共线性）或 $\text{cor}(X_1, X_2)$ 非常高（可能是 $\text{cor}(X_1, X_2)&gt;0.999$）时获得的参数估计值（同时估计）感兴趣。
回归系数的标准解释是偏效应：$\beta_1$ 是 $X_1$ 增加一个单位时 $Y$ 的变化，同时控制所有其他变量（此处仅 $X_2$）。但是，如果 $X_1=X_2$，则一旦我们控制了 $X_2$，$X_1$ 显然无法再解释 $Y$ 中的任何变化。基于此推理，我期望得到估计值$\hat\beta_1=0$，并且基于相同推理，我期望得到$\hat\beta_2=0$。
但是，如果我估计回归模型（在完全共线情况下使用贝叶斯模型，或在近共线情况下使用贝叶斯/频率论），我会得到 beta 系数，其总和等于真实参数的总和$\beta_1+\beta_2$。从优化的角度来看，这也是有道理的，因为如果 $X_1=X_2$，则上述模型的 RHS 可以重写为 $(\beta_1+\beta_2)X_1 + \varepsilon$，这也说明了为什么模型无法识别。
基于上述内容，似乎 $\beta_1, \beta_2$ 的部分效应解释与我在（近）共线情况下得到的结果不一致。显然，我犯了一个推理错误，我希望有人能指出这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/655518/multiple-linear-regression-partial-effects-interpretation-of-parameters-at-near</guid>
      <pubDate>Wed, 09 Oct 2024 08:49:59 GMT</pubDate>
    </item>
    <item>
      <title>R 中许多类别测试的插入符号和 pROC 结果之间的敏感性和特异性差异</title>
      <link>https://stats.stackexchange.com/questions/655442/difference-in-sensitivity-and-specificity-between-caret-and-proc-results-for-man</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655442/difference-in-sensitivity-and-specificity-between-caret-and-proc-results-for-man</guid>
      <pubDate>Mon, 07 Oct 2024 15:06:39 GMT</pubDate>
    </item>
    <item>
      <title>具有协变量以及人间和人内中介的中介模型</title>
      <link>https://stats.stackexchange.com/questions/617060/mediation-model-with-covariates-and-between-and-within-person-mediators</link>
      <description><![CDATA[我对多级模型中的中介作用还很陌生。
我想在 R 中运行 2-1-1（也许是 2-2-1）中介模型。
数据集由 110 名参与者组成，每天进行三次评估。
协变量 = 性别；年龄；财务状况和哔哔声。性别；年龄；财务状况均为 2 级），哔哔声为 1 级。
中介 = 压力水平（在每次评估时测量），即解开 cstress（人内压力水平）；bstress（人际压力水平）。
预测因子 = 抑郁症状（在基线测量 = 2 级）
结果 = 倦怠（在每次评估时测量 = 1 级）
根据我的理解，使用 lavaan 包似乎是最合适的方法。
但是，我不确定如何将协变量纳入中介模型。此外，我想知道如何将人际压力（2 级 - 2-2-1 中介）和人际压力（1 级 - 2-1-1 中介）都纳入中介。如果不建议这样做，我希望将压力水平（压力）作为中介（2-1-1 中介），而无需解开。

如能提供任何有关 R 代码的帮助，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/617060/mediation-model-with-covariates-and-between-and-within-person-mediators</guid>
      <pubDate>Sat, 27 May 2023 12:21:13 GMT</pubDate>
    </item>
    </channel>
</rss>