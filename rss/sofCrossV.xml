<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 19 Oct 2024 09:16:14 GMT</lastBuildDate>
    <item>
      <title>后验预测 p 值和模型复杂性</title>
      <link>https://stats.stackexchange.com/questions/655998/posterior-predtive-p-values-and-model-complexity</link>
      <description><![CDATA[我正在执行贝叶斯后验预测检验，我发现更复杂模型（所有随机效应）的后验预测 p 值比更简单模型（所有固定效应或混合效应）的后验预测 p 值更远离（且低于）0.5。这可能吗？显然，一切都是正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655998/posterior-predtive-p-values-and-model-complexity</guid>
      <pubDate>Sat, 19 Oct 2024 08:53:54 GMT</pubDate>
    </item>
    <item>
      <title>为了在拥有菲多利和桂格食品的情况下超越百事可乐，可口可乐公司应该收购哪些食品品牌和公司？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655996/to-one-up-pepsico-with-their-ownership-of-frito-lay-and-quaker-what-food-brands</link>
      <description><![CDATA[我实际上查看了百事可乐和可口可乐公司旗下各个品牌的图片，并决定提出一个值得撰写的假设情景问题，例如可口可乐收购各种食品公司，以与百事可乐对菲多利和桂格燕麦的历史所有权竞争。
我向 AI 网络搜索询问了以下两个版本的同一问题，并将链接给您答案。
1：https://poe.com/s/vkiUk4NocxZ60x9Z9qQx?utm_source=link
2：https://poe.com/s/1EIzOGBooffeNXwWclgs?utm_source=link
第一个链接谈到百事可乐收购 Siete Foods 及其类似品牌，此外还有 Bare Snacks、Health Warrior、ChickPea Snacks、Pop Corners、Kettle Brand、LesserEvil 和 RXBAR 等公司，这些都是可口可乐收购的理想对象。
第二个链接列出了 Kettle、Cape Cod Potato Chips、Popchips、RXBAR、Kind Snacks、Annie’s Homegrown、Banza、Naked Juice、Honest Tea、一个（或更多）区域性玉米片品牌，以及当地和/或手工小吃品牌，这些都是可口可乐收购的理想对象。
但是你们呢？真人的猜测呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/655996/to-one-up-pepsico-with-their-ownership-of-frito-lay-and-quaker-what-food-brands</guid>
      <pubDate>Sat, 19 Oct 2024 07:05:10 GMT</pubDate>
    </item>
    <item>
      <title>令人困惑的逻辑回归模型输出</title>
      <link>https://stats.stackexchange.com/questions/655994/confusing-logistic-regression-model-output</link>
      <description><![CDATA[我正在使用加权逻辑回归模型分析来自样本量大（&gt;88,000）的国家数据集的数据，以预测基于各种组成员身份的结果的概率。我想将每个组成员身份与不属于该组的成员进行比较，而不是与定义的参考组进行比较（例如，添加所有虚拟编码变量，而不是忽略参考变量）。对于我研究的大多数健康结果，这种方法效果很好，但其中一个结果返回的结果是，属于每个详尽且互斥的组的成员的 OR 为 &gt;1，CI 不超过零。我的解释是，与不属于该组的成员相比，每个组的几率都更高……这在逻辑上说不通。
我正在使用 SAS 9.4 surveylogistic 程序，并指定 NOMCAR 来解释缺失数据。域、权重、层、集群和模型都经过了三重准确性检查，看起来不错。所有单元格大小均大于 10。模型收敛且无错误。当我看到加权分析的结果时，所有输出看起来都很合理，并且相对接近我作为诊断的一部分运行的未加权分析的结果，尽管其中一个组在未加权分析中并不显著（未加权 OR 1.06；加权 OR 1.80，CI 1.11-2.9）
我试图确定问题是否在于在没有指定参考组的情况下进行比较（如果是这样，我预计会出现脊状误差，但没有发生）或者模型中的权重是否能够以某种方式将事物转移到这个奇怪的结果。或者相反，如果我的解释有问题，而输出没问题。任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655994/confusing-logistic-regression-model-output</guid>
      <pubDate>Sat, 19 Oct 2024 03:13:18 GMT</pubDate>
    </item>
    <item>
      <title>使用列范数限制精度矩阵的谱范数</title>
      <link>https://stats.stackexchange.com/questions/655993/bound-the-spectral-norm-of-the-precision-matrix-using-column-wise-norm</link>
      <description><![CDATA[在本文中，作者获得了关于谱范数的精度矩阵的收敛速度，（定理 1，第 7 页）
$$
\|\hat{\Omega}-\Omega\|_2 \le CM_p s_p\sqrt{\frac{\log p}{n}}
$$
其中$\|\Omega\|_{L1}=\underset{1\le j\le p}{\max}\sum_{i=1}^{p}|\omega_{ij}|\le M_p$ 和 $\underset{1\le j\le p}{\max}\sum_{i=1}^{p}1\left(\omega_{ij}\neq 0\right)\le s_p$。
他们通过控制精度矩阵的列来证明这个定理（第 37 页，不等式 (9)）：
$$
|\hat{\beta}_{S_i}-\omega_{S_i}|\le C\sqrt{\frac{\log p}{n}}
$$
其中 $\hat{\beta}_i$ 是 $\hat{\Omega}$ 的第 i 列。
我们如何使用逐列边界来控制收敛速度？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655993/bound-the-spectral-norm-of-the-precision-matrix-using-column-wise-norm</guid>
      <pubDate>Sat, 19 Oct 2024 02:44:14 GMT</pubDate>
    </item>
    <item>
      <title>二进制时间序列数据的置信带</title>
      <link>https://stats.stackexchange.com/questions/655991/confidence-bands-for-binary-time-series-data</link>
      <description><![CDATA[上下文：我有二进制数据 $x_{it}\in\{0,1\}$，其中 $i\in\{1,...,N\}$ 表示试验索引，而 $t\in\{1,...,T\}$ 表示时间索引（在试验之间独立；不在时间之间独立）。这是我运行的模拟（$N$ 次，每次 $T$ 个周期），我没有对随机过程 $\{x_{\cdot t}\}_{t=1}^T$ 的明确描述。
我的问题：我可视化了 $x_{\cdot,t}$ 在时间 $t$ 之后始终保持在 1 的频率，并绘制了每个 $t$ 的图表。我还想绘制一个“置信区间”，但我不知道如何/是否可以做到这一点。
我目前的工作：对于每个$(i,t)$，$S_{it} = \prod_{\tau=t}^{T}x_{i\tau}$ 编码事件，即对于所有$\tau\geq t$，$x_{i\tau}=1$。我在每个 $t$ 上绘制了 $\frac{1}{N}\sum_{n=1}^N 1\{S_{\cdot t}=1\}$，以可视化 $x_{\cdot t}$ 在 $t$ 时间之后保持为 1 的频率。（这正确吗？）关于可视化置信区间，我曾尝试查找有关如何对“生存曲线”进行可视化的指南（因为我所绘制的内容似乎与此相关），但我不知道它们是否适用（即使如此，我也不完全确定如何将迄今为止找到的方法转化为我的问题）。任何指导都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655991/confidence-bands-for-binary-time-series-data</guid>
      <pubDate>Fri, 18 Oct 2024 22:58:48 GMT</pubDate>
    </item>
    <item>
      <title>高效 Net V2 M ONNX 模型在小输入上的推理速度明显较慢</title>
      <link>https://stats.stackexchange.com/questions/655990/efficient-net-v2-m-onnx-model-infers-significantly-slower-on-small-input</link>
      <description><![CDATA[当我将 Efficient net v2 m 模型从 Pytorch 转换为 Onnx 以适应不同大小的输入时，我注意到一种奇怪且无法解释的行为。我希望从这个社区找到对我的观察的解释。
在我的 RTX 4090 上，1280X1280 大小图像上的 ONNX 模型在 35 毫秒内推断出批处理大小为 1。当我将图像大小缩小到大约 192X192（批处理大小相同为 1）时，运行时间几乎保持不变。这是可以理解的，因为固定开销占主导地位，例如初始化时间、线程池预热、与 GPU 之间的低效数据传输，最重要的是，计算库针对 GPU 上的矢量化和 SIMD 指令进行了优化。
然而，令人困惑的是，一旦我开始将输入图像大小减小到 192X192 以下，运行时间就会急剧增加。对于 64X64 图像，批处理大小为 1 时运行时间为 &gt;100ms。我完全理解为什么在较小的图像上推理不应该更快，但我不明白为什么它会更慢（而且慢得多）。
当我增加较小图像的批处理大小时，每批的运行时间会大幅改善（不仅仅是每幅图像的运行时间）。对于批处理大小为 16 的图像，推理 192X192 图像每批需要 25 毫秒（每幅图像不到 2 毫秒），而批处理大小为 1 时则需要 &gt;100ms。同样，我对此没有任何解释。固定开销和优化的 SIMD 矢量化将决定每幅图像的摊销运行时间应该随着批处理大小的增加而改善。但是，我观察到整个批次的运行时间也得到了改善。
对于较大的图像（例如 1280X1280），增加批次大小会增加每个批次的运行时间（尽管是亚线性的，这是完全可以预料的 - 随着批次大小的增加，每个图像的运行时间仍然会缩短到一定限度，之后，对于几乎无法放入 GPU 内存的更高批次大小，每个图像的运行时间也会增加约 10%）。
但是在 CPU 上运行时，处理时间会随着输入大小的增加而单调增加，正如预期的那样。
当我要求它对所有输入进行处理时，我已经验证了 ONNX 模型在 GPU 上成功运行。事实上，对于小输入，CPU 推理时间比 GPU 更快（这是可以理解的，因为有固定的 I/O 和其他开销）
注意：由于我在整个实验过程中将动态轴设置为 None，因此我为具有不同输入大小的同一 torch 模型保存了多个版本的 ONNX 模型。使用或不使用 onnx-sim 几乎不会对运行时间产生影响（处理速度差异小于 10-15%）。我在 C++ 中以 OrtCUDAProviderOptions 作为执行提供程序运行 onnx 模型，使用或不使用 GraphOptimizationLevel 几乎没有区别。
神经网络的输出对于所有输入都符合预期，因此我不希望我的代码中出现任何错误。
TL;DR我的 ONNX 模型对于中等大小图像的运行速度比 GPU 上的小图像更快。对于较小的图像，增加批次大小会大幅减少每批次的处理时间（而不仅仅是 SIMD 并行化所预期的每张图像的摊销时间）。]]></description>
      <guid>https://stats.stackexchange.com/questions/655990/efficient-net-v2-m-onnx-model-infers-significantly-slower-on-small-input</guid>
      <pubDate>Fri, 18 Oct 2024 21:24:44 GMT</pubDate>
    </item>
    <item>
      <title>从探索性数据分析中得出的特征是否会导致 K 折交叉验证不准确？</title>
      <link>https://stats.stackexchange.com/questions/655988/do-features-derived-from-an-exploratory-data-analysis-lead-to-inaccurate-k-fold</link>
      <description><![CDATA[我对探索性数据分析、特征工程和使用 k 倍交叉验证的特征选择之间的相互作用有些困惑。如果有人能给我一些解释，我将不胜感激。
更具体地说，我想知道我尝试使用探索性数据分析找到合适的线性回归模型的情况。
假设我有一个大小为 n 的样本，每个观察值由 k 个变量组成。作为第一步，我将留出一个测试集进行最终模型评估。然后，为了了解我的反应与其他记录变量之间的关系，我会例如查看相关性，绘制数据以查看是否可能存在任何非线性关系。我还会考虑可能的相互作用。然后，我将根据我之前的观察结果创建不同的特征（多项式、平方根、交互等）。为了查看这些添加的特征是否真的改善了与基线相比的模型，我想对用于探索性数据分析的相同数据（即除先前为最终模型评估预留的观测值之外的所有观测值）执行 k 倍交叉验证。但是，我想知道这种方法是否有缺陷，因为我根据我的观察进行了特征工程，其中已经包括用于 k 倍交叉验证的完整数据，即每个步骤中遗漏的折叠。这不会导致数据泄露吗？因为我犯了一个类似的错误，就像我在对整个数据集执行特征工程时一样，即这通常会导致模型产生良好的 k 倍交叉验证结果，但在测试数据上结果不佳吗？如果是这样，检查我设计的特征是否确实相关的正确方法是什么？留出额外的验证集？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655988/do-features-derived-from-an-exploratory-data-analysis-lead-to-inaccurate-k-fold</guid>
      <pubDate>Fri, 18 Oct 2024 20:54:09 GMT</pubDate>
    </item>
    <item>
      <title>两个随机变量之间差异的概率区间</title>
      <link>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</link>
      <description><![CDATA[假设 X1 和 X2 是两个随机变量，其中 X1 有 95% 的概率位于区间 [L1, R1] 内，X2 有 95% 的概率位于区间 [L2, R2] 内。这是否意味着差值 X1 - X2 有超过 95% 的概率位于区间 [L1 - R2, R1 - L2] 内？此外，X1 和 X2 可以是相关的，也可以是独立的。
(1) 有人可以澄清概率界限是否适用于这种情况吗？或者这个说法的反例。
(2) 如果有反例，是否有其他条件可以添加以使其成立？]]></description>
      <guid>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</guid>
      <pubDate>Fri, 18 Oct 2024 19:35:37 GMT</pubDate>
    </item>
    <item>
      <title>具有反射的离散布朗运动的表达式</title>
      <link>https://stats.stackexchange.com/questions/655982/expression-for-discrete-brownian-motion-with-reflection</link>
      <description><![CDATA[对于具有吸收状态的离散布朗运动，我们可以将位置分布表示为两个二项分布的线性和，如此处所述，其中 +1 和 -1 步的几率为 1:1，此处所述，用于更一般的几率不相等的情况。
具有反射墙的离散布朗运动的情况如何？
假设我们将时间 $t$ 的位置描述为 $X(t)$，起始位置为 $X(0) = 1$。有概率 $p$ 我们向前迈一步 $X(t+1) = X(t) + 1$ ，有概率 $1-p$ 我们向后迈一步 $X(t+1) = X(t) - 1$ ，除非 $X(t) = 0$ ，在这种情况下我们总是向前迈一步。]]></description>
      <guid>https://stats.stackexchange.com/questions/655982/expression-for-discrete-brownian-motion-with-reflection</guid>
      <pubDate>Fri, 18 Oct 2024 19:26:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 包 marginaleffects 进行编码比较和交互</title>
      <link>https://stats.stackexchange.com/questions/655981/coding-comparisons-and-interactions-with-the-r-package-marginaleffects</link>
      <description><![CDATA[我开始学习如何使用 R 包 marginaleffects，并希望得到一些特定应用方面的帮助。
为了说明，我们使用 afex 包中的数据集。变量 phase 是一个具有三个级别的因子：“fup”、“post”和“pre”。变量 age 是连续的。下面是使用 lme4 拟合的模型：
library(afex); library(lme4); library(phia)
data(obk.long, package = &quot;afex&quot;)
options(contrasts = c(&quot;contr.sum&quot;, &quot;contr.poly&quot;))
fm &lt;- lmer(value ~ phase * age + (1|id), data = obk.long)

我想使用 marginaleffects 复制以下七个比较和交互：

对比因子 phase 的前两个级别（“fup”与“post”）
在 phia 中，这是通过以下方式完成的：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), adjustment = &quot;none&quot;)


对比phase的前两个级别，其中age固定在 5.5
在phia中：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), covariates = c(age = 5.5), adjustment = &quot;none&quot;)


age的斜率（在phase的所有级别上取平均值）
在phia中：
testInteractions(fm, pairwise = NULL, slope = &quot;age&quot;, adjustment = &quot;none&quot;)


前两个级别之间的age斜率差异 (&quot;fup&quot; vs. &quot;post&quot;) 的 phase
在 phia 中：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), slope = &quot;age&quot;, adjustment = &quot;none&quot;)


phase 的三个级别之间的综合对比（例如 &quot;fup&quot; - &quot;pre&quot; 和 &quot;post&quot; - &quot;pre&quot;）
在 phia 中：
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))))


phase 三个级别的综合斜率比较（例如，&quot;fup&quot; 与 &quot;pre&quot; 以及 &quot;post&quot; 与 &quot;pre&quot; 的斜率差异）
在 phia 中：
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))), slope = &quot;age&quot;)


固定年龄的 phase 三个级别的综合对比（例如，&quot;fup&quot; - &quot;pre&quot;和“post” - “pre” 在 age = 5.5)
在 phia:
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))), covariates = c(age = 5.5))



我的问题是：如何使用 marginaleffects 包对这七个效应进行编码？]]></description>
      <guid>https://stats.stackexchange.com/questions/655981/coding-comparisons-and-interactions-with-the-r-package-marginaleffects</guid>
      <pubDate>Fri, 18 Oct 2024 18:51:31 GMT</pubDate>
    </item>
    <item>
      <title>调整因变量的个别值</title>
      <link>https://stats.stackexchange.com/questions/655970/adjusting-individual-values-of-a-dependent-variable</link>
      <description><![CDATA[我有一个数据集，其中包含 600 个脉搏波速度读数，我需要根据每个参与者的平均动脉血压进行调整。我可以得到这样的结果：
m &lt;- lm(pulse_wave_velocity ~ mean_arterial_bp, data = df)

那么我是否可以使用模型中的残差来计算调整后的脉搏波速度，如果是，是否应该将它们添加到截距中？]]></description>
      <guid>https://stats.stackexchange.com/questions/655970/adjusting-individual-values-of-a-dependent-variable</guid>
      <pubDate>Fri, 18 Oct 2024 14:57:17 GMT</pubDate>
    </item>
    <item>
      <title>负二项回归与普通逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/655965/negative-binominal-regression-vs-ordinary-logistic-regression</link>
      <description><![CDATA[我有选举期间的社交媒体数据，其中包含数千名政治人物在社交媒体上的帖子。数据集有许多控制变量，例如日期、关注者数量、视觉效果的存在、是否是热门演员的转发等。
这项研究本质上是关于语言学的。我的目标是测试隐喻相关指标是否与高参与度（喜欢、分享、评论）相关。由于它是社交媒体数据，因此存在高度过度分散。我确认负二项回归是最佳选择。
在用喜欢计数拟合模型后，我注意到该模型在处理参与度非常高或参与度非常低的帖子时遇到了困难。它似乎也有显著的异常值。




考虑到这是高度密集时期的社交媒体数据，我对模型在某些帖子上遇到困难并不感到惊讶。大多数被低估的帖子都包括特殊/耸人听闻的视觉效果、视频或公告，这些都使它们非常高。
由于它们不是虚假数据并且是社交媒体固有的，所以我没有删除它们。主要目标不是建立一个预测参与度的模型，而是看看隐喻指标是否与参与度呈正相关。
我想知道这是否是正常的，因为数据的性质。此外，NBR 是否对我来说是正确的测试，或者我是否应该在将基于百分位数的参与度数据分解为高、中、低参与度后考虑 OLR。]]></description>
      <guid>https://stats.stackexchange.com/questions/655965/negative-binominal-regression-vs-ordinary-logistic-regression</guid>
      <pubDate>Fri, 18 Oct 2024 14:02:35 GMT</pubDate>
    </item>
    <item>
      <title>疾病建模与微生物组建模：结果应该是哪一个？</title>
      <link>https://stats.stackexchange.com/questions/655941/modeling-disease-vs-microbiome-which-should-be-the-outcome</link>
      <description><![CDATA[我有一个与微生物组研究相关的问题，在这个领域，许多研究人员评估疾病组和对照组之间的分类单元丰度是否不同。我经常看到统计模型，其中分类单元作为结果变量，疾病状态作为解释变量。但是，我想知道这种模型是否更适合评估疾病是否影响微生物组，而不是相反。大多数研究人员的目标是找到微生物组影响疾病的证据。鉴于此，该模型是否不合适，使用分类单元作为解释变量，疾病状态作为结果的模型是否更合适？当使用仅包含数值变量且不涉及协变量的线性模型时，等式中的位置（无论是在左侧还是右侧）可能不太重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/655941/modeling-disease-vs-microbiome-which-should-be-the-outcome</guid>
      <pubDate>Fri, 18 Oct 2024 01:10:05 GMT</pubDate>
    </item>
    <item>
      <title>回归模型中每个变量都需要具有统计显著性吗？</title>
      <link>https://stats.stackexchange.com/questions/655938/does-every-variable-need-to-be-statistically-significant-in-a-regression-model</link>
      <description><![CDATA[我最近拟合了一个回归模型 (ARIMAX)，其中有些变量 (3) 具有统计显著性，有些则不显著 (1)。我删除了统计上不显著的变量并重新拟合模型，现在所有变量都具有统计显著性（即新模型有 3 个变量，旧模型有 4 个变量）。
但是，这个新模型（所有变量都具有统计显著性）的表现比旧模型（并非所有变量都具有统计显著性）更差。也就是说，新模型的预测误差比旧模型更严重。
这是统计学中的常见做法吗？如果所有变量都具有统计显著性，选择性能较差的模型是否更可取，还是最好选择性能较好的模型，即使并非所有变量都具有统计显著性。
我知道过度拟合和交叉验证等概念。我使用除过去 6 个月数据之外的所有可用数据训练了这两个模型。我还让这两个模型预测过去 6 个月的可用数据，并将预测值与实际值进行比较。使用旧模型（即并非所有变量都具有统计显著性的模型）我仍然获得了更好的结果。
即使并非所有变量都具有统计显著性，是否可以采用性能更好的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/655938/does-every-variable-need-to-be-statistically-significant-in-a-regression-model</guid>
      <pubDate>Fri, 18 Oct 2024 01:02:57 GMT</pubDate>
    </item>
    <item>
      <title>计数值的统计检验</title>
      <link>https://stats.stackexchange.com/questions/655928/statistical-test-for-count-values</link>
      <description><![CDATA[我有 4 个故事，每个故事都有字数和复数词的数量：



故事
单词数
复数




1
356
45


2
273
23


3
303
28


4
289
42



我想知道是否可以进行统计测试以确定这些故事在字数方面是否存在显着差异，然后再进行另一项测试以确定这些故事在复数数量方面是否存在显着差异。
测试的目的是确保这些故事在阅读难度方面没有显着差异。这是一项心理学研究，我们需要确保故事难度中没有混淆。我们正在测试其他更相关的单词特征，但这些是连续值，我们可以对其进行其他测试。
我没有人口频率可以与之比较，以便使用 Fisher 精确检验，我认为我不能使用卡方检验，因为那里的计数似乎应该是相关的，例如测试一群人是否喜欢苹果、橘子或香蕉，而一个人不能选择两个选项，我有点困惑，不知道我可以在这里使用什么测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/655928/statistical-test-for-count-values</guid>
      <pubDate>Thu, 17 Oct 2024 19:33:29 GMT</pubDate>
    </item>
    </channel>
</rss>