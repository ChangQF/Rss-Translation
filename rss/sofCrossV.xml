<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 11 Oct 2024 21:18:39 GMT</lastBuildDate>
    <item>
      <title>为什么当使用 IV 独立变量并且包括区域固定效应时，系数会失去显著性？</title>
      <link>https://stats.stackexchange.com/questions/655667/why-does-the-coefficient-lose-significance-when-using-iv-independent-variable-an</link>
      <description><![CDATA[我正在尝试研究 2018 年洪水冲击对男性和女性劳动力参与的影响。然而，洪水不仅可以归因于强降雨，还可以归因于其他因素，例如水库的蓄水能力差、水坝闸门打开。所以，洪水并非完全是外生的。因此，我首先使用地区固定效应和年份固定效应对 99 百分位季风降雨量（针对 1989-2018 年的每个季风月份计算）对洪水损害评分进行回归（使用 PCA 为每个地区构建损害指数，使用地区损害信息，例如受影响的农作物面积、受影响的养鱼场、人员伤亡等）。接下来，我使用此回归的预测值作为洪水冲击对劳动力参与回归的主要自变量。但是，当我采用地区固定效应时，系数在统计上变得不显著。在没有地区固定效应的情况下，它仍然具有统计显著性。有人能告诉我为什么会这样吗？我该如何解决这个问题？
注意：第一次回归基于 1989-2018 年期间每个地区的每日降雨量数据，这是一种面板数据，但在第二次回归中，个人和家庭层面的数据是重复的横截面，在 2017-2019 年期间每年四个季度都有。]]></description>
      <guid>https://stats.stackexchange.com/questions/655667/why-does-the-coefficient-lose-significance-when-using-iv-independent-variable-an</guid>
      <pubDate>Fri, 11 Oct 2024 19:52:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 GLM 或 GLMM 进行重复</title>
      <link>https://stats.stackexchange.com/questions/655665/using-glms-or-glmms-for-replicates</link>
      <description><![CDATA[我希望有人能帮我解答一个有关统计分析的问题。我正在查看物种计数数据，其中在重复地点进行了多年的采样。例如，每年在六个不同的地点进行采样。这些年份被分为一个温度组，有两个因素：温暖或寒冷。我只对探索不同温度组和不同年份之间的社区差异感兴趣。我使用 vegan 包来计算多样性指标（丰度、丰富度、多样性指数），并希望统计检查指标之间的差异。
我一直在使用带有负二项分布的 mvabund 包，但我想知道现在是否应该将重复的站点添加为随机效应，它实际上是一个混合模型。在这种情况下，glmmTMB 或 lme4 是否更合适？我不太熟悉在 R 中使用混合模型，因此非常感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655665/using-glms-or-glmms-for-replicates</guid>
      <pubDate>Fri, 11 Oct 2024 19:40:20 GMT</pubDate>
    </item>
    <item>
      <title>我不确定我是否完全理解了维基百科中关于基因测试结果贝叶斯分析的例子</title>
      <link>https://stats.stackexchange.com/questions/655664/im-not-sure-i-fully-understand-wikipedias-example-of-bayesian-analysis-of-gene</link>
      <description><![CDATA[因此，我目前正在阅读有关贝叶斯定理1的维基百科文章，并对“遗传学中的应用：使用基因测试结果”部分中的陈述感到困惑。

以下是该部分的概述：

本节使用贝叶斯分析作为示例，分析了一名有囊性纤维化 (CF，一种罕见的常染色体隐性遗传病) 家族史但检测结果为阴性的女性患者，以说明如何使用此方法确定患者生育患有 CF 的孩子的风险。
由于我们在这种情况下知道患者未受到影响，这意味着她要么不携带 CF（对 W 等位基因是杂合的），要么至少携带它（有一个M等位基因）。由于父母双方可能都是 CF 携带者，我们可以将 Punnett 方格画为$$\begin{array}{c|c|c}&amp;W&amp;M\\\hline W&amp;WW&amp;WM\\\hline M&amp;WM&amp;MM\end{array}$$，因此，我们有 3 种情况患者不会受到 CF 的影响，其中 2 种情况患者携带突变等位基因，因此给出的先验概率分别为 2/3 和 1/3。
然后，假设 CF 测试的检测率为 90%，我们得到阴性测试的条件概率为 0.1 和 1。因此，我们可以计算 H1：患者携带 CF 和 H2：的后验概率患者不携带 CF 的概率分别为 1/6 和 5/6。
虽然所有这些对我来说都很有道理，但我对最后一段中的内容感到困惑：

在对患者的男性伴侣（检测结果为阴性）进行相同分析后，他们的孩子受到影响的几率等于父母各自作为携带者的后验概率乘以两个携带者产生受影响后代的几率（¼）。

我的问题是：

这是否意味着男性伴侣可能是 CF 携带者（但不受其影响），因此生下患有 CF 的孩子的几率是 1/144？鉴于该测试的检测率为 90%，我们是否也应该考虑男性伴侣实际上受 CF 影响的可能性（假设测试结果为阴性）？（因此，孩子受 CF 影响的实际几率为 1/144+1/24=7/144≈4.86%）
]]></description>
      <guid>https://stats.stackexchange.com/questions/655664/im-not-sure-i-fully-understand-wikipedias-example-of-bayesian-analysis-of-gene</guid>
      <pubDate>Fri, 11 Oct 2024 19:02:20 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 到 pytorch 权重转移[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655658/tensorflow-to-pytorch-weights-transfer</link>
      <description><![CDATA[我正尝试在 pytorch 中模拟一个经过修改的 efficientnet TF 模型。我在 pytorch 中对模型进行了架构更改，转储了 TF 模型权重，然后将其重新加载到新的 pytorch 模型中。使用以下代码在 TF 中转储权重：
model = tf.saved_model.load(model_path)
ws = []
for i in range(len(model.variables)):
ws.append((i, model.variables[i].name, model.variables[i].numpy()))

with open(&quot;manually_dumped_contentnet_weights.pkl&quot;, &quot;wb&quot;) as ofile:
pickle.dump(ws, ofile)

pytorch 中的权重形状似乎与架构和导入的权重相匹配（在 conv2d 和深度 conv2d 之间进行转换之后）。我可以毫无错误地运行模型。但输出结果与 TF 模型的输出结果大不相同。
我注意到在 TF 代码中，模型不是直接加载的，而是在 tf Session 中加载的：
with Session(graph=Graph(), config=ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
saved_model.loader.load(sess, [saved_model.tag_constants.SERVING], model_path)
patch_feature, patch_label = sess.run(output_nodes,feed_dict={input_node: patch})

现在我想知道我最初转储模型权重的尝试是否做得不正确。或者如果我遗漏了其他内容。
我在加载数据时进行的转置是 conv2d 的 (3,2,0,1) 和深度 conv2d 的 (2,3,0,1)：
def reload_conv2d(layer, weights):
### weights 是一个元组，其中每个元素都由一个三元组组成：(1) 索引号，(2) TF 中权重转储的层的名称，以及 (3) 权重
count = 0
if (
&quot;/conv2d/kernel&quot; not in weights[0][1]
and &quot;/conv2d_1/kernel&quot; not in weights[0][1]
and &quot;depthwise_conv2d/depthwise_kernel&quot; not in weights[0][1]
and &quot;final_conv2d/final_conv2d&quot; 不在 weights[0][1] 中 :
raise ValueError(
f&quot;需要在第一个索引上有 conv2d/kernel，但得到了 {weights[0][1]}&quot;
)
transpose_shape = (2,3,0,1) if &quot;depthwise&quot;在 weights[0][1] 中否则（3、2、0、1）
transposed_weights = torch.from_numpy（weights[0][2].transpose（transpose_shape[0]、transpose_shape[1]、transpose_shape[2]、transpose_shape[3]））
layer.weight.data = transposed_weights
count += 1
如果 layer.bias 不是 None 或 layer.bias:
如果（
&quot;/conv2d/bias&quot; 不在 weights[1][1] 中
并且 &quot;/conv2d_1/bias&quot; 不在 weights[1][1] 中
）：
引发 ValueError（
f&quot;需要在第二个索引上有 conv2d/bias 但得到了 {weights[1][1]}&quot;
)
layer.bias.data = (
torch.from_numpy(weights[1][2])
如果type(weights[1][2]) == np.ndarray
else torch.from_numpy(weights[1][2])
)
count += 1
return layer, count

为什么 pytorch 和 TF 模型对相同输入给出完全不同的结果？是因为权重倾倒，还是权重加载……或者是模型架构变化？输入 TF 权重（在模型更改和转置之后）加载正常，我可以毫无问题地运行模型，但这对于调试它没有任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655658/tensorflow-to-pytorch-weights-transfer</guid>
      <pubDate>Fri, 11 Oct 2024 16:26:04 GMT</pubDate>
    </item>
    <item>
      <title>关系数据的趋势分析[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655657/trend-analysis-on-relational-data</link>
      <description><![CDATA[我是数据分析新手，不确定应该使用什么工具和/或编程语言来解决以下问题。
我在 SQL Server DB 中有一个表，其中包含大量企业的每日财务指标（收入、支出、付款等）。此表中的每一行如下所示：

企业 ID日期当天收入当天支出当天付款等等

每天都会有数千行这样的行，每行对应特定企业的财务指标。该表包含了几年的此类数据。
我想找到六个月内每日收入呈上升趋势的所有企业。这是我需要执行的一次性离线分析，以生成报告。计算和内存成本不是我需要优化的东西——用最少的努力获得结果更重要。有什么想法可以让我进行这样的分析吗？
在最坏的情况下，我可以用 Java / C# 编写代码来进行这种分析，但我觉得这不是最有效的解决方案。任何提示/指示都将不胜感激。新手在此先行致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655657/trend-analysis-on-relational-data</guid>
      <pubDate>Fri, 11 Oct 2024 16:22:37 GMT</pubDate>
    </item>
    <item>
      <title>时间依赖性协变量和结果乐观性</title>
      <link>https://stats.stackexchange.com/questions/655656/time-dependent-covariates-and-optimism-of-results</link>
      <description><![CDATA[我有一个涵盖 2019-2023 年的数据集，以及一组按年份和邮政编码连接的分类协变量。为了进行验证，2023 年被排除在外，该年的协变量是前几年的平均值。基于随机分割的交叉验证期间的模型显示出极大的乐观性。当对测试数据进行评估时，甚至没有接近。我建议对用于训练模型的协变量使用估计值，而不是原始值。
有人可以告诉我关于这个主题的文献吗？它是时空的，但涉及对新时间段的估计。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/655656/time-dependent-covariates-and-optimism-of-results</guid>
      <pubDate>Fri, 11 Oct 2024 15:58:48 GMT</pubDate>
    </item>
    <item>
      <title>基于梯度法的攻击对于神经网络来说似乎没有意义，因为训练误差是非凸的</title>
      <link>https://stats.stackexchange.com/questions/655655/the-gradient-method-based-attack-does-not-seem-make-sense-for-neural-networks-be</link>
      <description><![CDATA[有几种基于梯度的攻击方法。设$J$为训练误差，则例如投影梯度攻击为，
$$
\widetilde{x} = \Pi( x + \epsilon \nabla_x J(\theta, x, y) )
$$
快速有符号梯度法为
$$
\widetilde{x} = x + \epsilon \text{sign}( \nabla_x J(\theta, x, y) )
$$
这些方法都假设我们正在添加$\nabla_x J(\theta, x, y)$。这是在假设$\nabla_x J(\theta, x, y)$指向$J$相对于$x$的最大无穷增量方向的情况下实现的。
但这个假设是错误的，因为$J$是$x$的非凸函数。因此，添加 $\nabla_x J(\theta, x, y)$ 不一定会产生 $\widetilde x$，从而产生更大的 $J$ 值。
由于大多数这些方法都是单步的，因此不能保证 $\widetilde x$ 会增加 $J$ 的值，它甚至可能会降低 $J$ 的值。
我的推理有缺陷吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655655/the-gradient-method-based-attack-does-not-seem-make-sense-for-neural-networks-be</guid>
      <pubDate>Fri, 11 Oct 2024 14:53:11 GMT</pubDate>
    </item>
    <item>
      <title>我如何对多个分布进行排序或分类，然后总结这个有序列表的“分位数”？</title>
      <link>https://stats.stackexchange.com/questions/655654/how-can-i-order-or-sort-many-distributions-then-summarize-the-quantiles-of-th</link>
      <description><![CDATA[对大量分布进行排序的最佳实践是什么？执行此操作的不同方法有哪些优缺点？
假设我正在处理对调查问题的李克特答案，其评分范围为 1 到 5。（例如：非常不同意；不同意；中立；同意；非常同意。或者另一个例子：差；一般；好；非常好；优秀。）但我想将它们作为批次的答案进行比较，而不是在单个答案的级别进行比较。
例如，想象一下产品的在线评级，从 1 到 5 星：我如何对一长串产品进行排序，每个产品都有自己的分布评级？
我知道没有单一的最佳方法来定义这种排序顺序，对于哪种排序最适合该任务，这是一个判断问题。例如，如果一个产品获得 10 个 1 星评级和 10 个 5 星评级，而另一个产品获得 20 个 3 星评级，那么两者之间没有明显的区别。但如果我必须对这些（以及 100 个其他产品评级分布）进行排序，我有什么选择？
我可以按均值排序：用 1 到 5 的数字表示 5 个李克特量表值，对每个批次取平均值，然后按平均值排序。但这忽略了一个事实，即 1 和 2 之间的差异可能与 4 和 5 之间的差异非常不同，等等。
我还可以按加权均值排序，即为某些值分配比其他值更大的权重（例如，5 的权重高于 4 等）。对于我的应用程序，我宁愿避免使用任何需要我们选择此类权重的方法；这需要利益相关者的认同和共识，而这很难实现。
或者我可以按高于/低于某个阈值的比例排序：例如，计算每个批次中评级为 4 或更高的比例，然后按这些比例排序。这似乎更好，但它仍然取决于我选择的阈值。
我也听说过词典优势：首先按 5 的比例进行部分排序。然后，如果有些 5 的比例相等，则按 4 的比例对该子组进行排序。依此类推。这似乎更好，但我可能忽略了这种方法的一些明显缺点。
还有哪些其他方法可以定义此类分布的全序？它们的优点和缺点是什么？

（PS——我在这个网站上找到的最接近的问题是这里。但它专注于一种特定的方法，而且大家似乎一致认为这不是一个很好的方法。我很好奇还有哪些其他替代方案。）
（PPS——如果我错过了与此相关的其他问题/答案，请见谅；我找不到正确的关键字来搜索。我曾尝试搜索有关“随机顺序”或“随机优势”的最佳实践，但我发现的大多数搜索结果都是关于部分顺序的。对于我的应用程序，我需要选择一个全序。）
（PPPS——上面列出的排序可能会受到小样本量的强烈影响。对于这个问题，假设所有批次的样本量都相同，因此重点只是排序/排序。我知道还有其他工具，如贝叶斯评级，可以帮助更公平地比较小批次和大批次；但这不是我在这里问的。）

如果有帮助，我最终想要做的是为这些分布选择某种“分位数”。例如：产品评级分数的“中位数”分布是什么？第 10 和第 90 个“百分位数”是多少？这样我们就能大致了解“看到这么糟糕/这么好的分数分布并不罕见”？
一种方法是先对分布进行全排序，然后使用排名列表中 10%、50% 和 90% 的分布作为示例/典范。
但也许还有其他方法可以选择或总结“低但不是最低”和“典型”以及“高但不是最高”的分布，而无需先对所有分布进行实际排序。我实际上可以在每个百分位数显示几个典范，因此如果“平局”组不是太大，则平局排序也可以。我很想听听其他想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/655654/how-can-i-order-or-sort-many-distributions-then-summarize-the-quantiles-of-th</guid>
      <pubDate>Fri, 11 Oct 2024 14:41:45 GMT</pubDate>
    </item>
    <item>
      <title>在使用 ARMA 过程拟合 GAMM 时如何优化资源使用？</title>
      <link>https://stats.stackexchange.com/questions/655648/how-to-optimise-resource-use-when-fitting-a-gamm-with-arma-process</link>
      <description><![CDATA[我正在根据一系列时间预测因素（例如一年中的时间、昼夜循环、潮汐……类似于这篇文章）对每小时物种的出现情况（存在/不存在）进行建模。我使用收集自约 100 个人的数据，有 266,000 个数据点。我目前正在尝试按照以下结构拟合 GAMM 模型*：
ResGAM8 = gamm(data = Datanal, HL ~ s(Day) + s(Temperature) + s(ref, bs = &quot;re&quot;) + ti(Day, Temperature, SI), family = binomial, method = &quot;fREML&quot;, correlation = corARMA(form = ~1 | ref,p=1))

在之前的版本中，我使用 bam( ... rho = ) 来解释时间自相关，但是，ACF 和 pACF 仍然表明残差中存在一些自相关。因此，我决定在每个个体中嵌套一个 ARMA，以更好地解释时间自相关以及解释变量之间的相关性。 
我尝试在免费版 google colab 上运行此模型几次（大约 1 分钟后总是出现错误，表明会话已崩溃，因为它已达到分配的 RAM 限制）并在我自己的计算机上（没有 colab 快）运行了大约 2 个小时，没有任何显著的结果。

我的问题很简单（表述）：我如何优化这个过程以减少资源消耗（并避免上述问题）？

减少观察和/或个体的数量是可能的，但实际上是作为最后的手段，因为包括的动物数量是这项工作的原因之一。

*为了清楚起见，我删除了简单平滑中包含的一些解释变量]]></description>
      <guid>https://stats.stackexchange.com/questions/655648/how-to-optimise-resource-use-when-fitting-a-gamm-with-arma-process</guid>
      <pubDate>Fri, 11 Oct 2024 12:48:58 GMT</pubDate>
    </item>
    <item>
      <title>有效影响功能的干预措施取决于暴露的自然价值</title>
      <link>https://stats.stackexchange.com/questions/655646/efficient-influence-function-with-interventions-that-depend-on-the-natural-value</link>
      <description><![CDATA[图 A1 显示了 SWIG，其中 L 是暴露 X 和结果 Y 之间关联的混杂因素。

我正在处理对 X 的干预，该干预根据其自然值对其进行修改（例如，不是每个人都设置为 1 的确定性静态方案）。例如，如果 X 的自然值为 2，则将其降低到 1，否则保持原样。感兴趣的因果效应（g 公式）定义如下（为了便于表示，我将干预节点表示为 $\tilde{x}$，而不是用红色标记）：
\begin{equation}
\Psi = \sum_{l, x, \tilde{x}} E \left[ Y | X = \tilde{x}, L=l \right] p \left( X = \tilde{x} | X=x, L=l \right) p \left( X=x | L=l \right) p(l)。
\label{eq:swig_1e1t_n}
\end{equation&gt;
我想构建一个双重稳健估计量，特别是增强逆概率加权 (AIPW) 估计量。因此，我想写下我的因果参数的有效影响函数 (EIF)。我遵循 Kennedy 2023 中的提示（此处）。为了便于表示，我将定义 $\mu(x,l) = E \left[ Y | X=x, L=l \right]$ 和 $\pi(x|l) = p \left( X=x | L=l \right)$。 EIF ($\mathbb{IF}$) 可以写成如下形式：
\begin{align}
\mathbb{IF}{(\Psi)} &amp;= \sum_{l, x, \tilde{x}} \mathbb{IF}{\left\{ \mu(\tilde{x},l) \right\}} p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) p(l) + \mu(\tilde{x},l) p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) \mathbb{IF}{\left\{ p(l) \right\}}.
\label{eq:swig_1e1t_n_eif}
\end{align&gt;
对于 EIF 求和中的第一个项，我们有：
\begin{align}
\mathbb{IF}{(\Psi)}_1 &amp;= \sum_{l, x, \tilde{x}} \frac{\mathbb{1}(X=\tilde{x}, L=l)}{p(X=\tilde{x}, L=l)} \left\{ Y^{\tilde{x}} - \mu(\tilde{x},l) \right\} p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) p(l) \nonumber \\
&amp;= \sum_{x} \frac{p \left( \tilde{X} | X=x, L \right) \pi(x|L)}{\pi(\tilde{X} | L)} \left\{ Y^{\tilde{x}} - \mu(\tilde{X},L) \right\}。
\end{align&gt;
对于 EIF 求和中的第二项，我们有：
\begin{align}
\mathbb{IF}{(\Psi)}_2 &amp;= \sum_{l, x, \tilde{x}} \mu(\tilde{x},l) p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) \left\{ \mathbb{1}(L=l) - p(l) \right\} \nonumber \\
&amp;= \sum_{x, \tilde{x}} \mu(\tilde{x},L) p \left( X = \tilde{x} | X=x, L \right) \pi(x|L) - \sum_{l, x, \tilde{x}} \mu(\tilde{x},L=l) p \left( X = \tilde{x} | X=x, L=l \right) \pi(x|l) p(L=l) \nonumber \\
&amp;= \sum_{x, \tilde{x}} \mu(\tilde{x},L) p \left( X = \tilde{x} | X=x, L \right) \pi(x|L) - \Psi.
\end{align&gt;
将它们放在一起，我们得到：
\begin{equation}
\mathbb{IF}{(\Psi)} + \Psi = \sum_{x} \frac{p \left( \tilde{X} | X=x, L \right) \pi(x|L)}{\pi(\tilde{X} | L)} \left\{ Y^{\tilde{x}} - \mu(\tilde{X},L) \right\} + \sum_{x, \tilde{x}} \mu(\tilde{x},L) p \left( X = \tilde{x} | X=x, L \right) \pi(x|L)。
\label{eq:swig_1e1t_n_eif_derived}
\end{equation&gt;
Kennedy 2023 的评论中没有类似的例子，最接近的是随机干预。我正在将获得的 EIF 与此处找到的 EIF 进行比较，特别是第 15 页最后一段中写的 EIF：
\begin{equation}
r(A,L) (Y - m(A,L)) + m(\mathbb{d}(A,L), L) - \theta,
\end{equation&gt;
其中 $\theta$ 是感兴趣的参数，$r$ 是第 15 页顶部定义的密度比，$m$ 是给定暴露和混杂因素的预期结果。作者使用函数 $\mathbb{d}$ 来定义暴露干预。很明显，我的 EIF 和他们的并不相同，尽管相似。一个关键的区别是，在我的密度比（EIF 总和中的第一个项）中，$\tilde{X}$ 同时存在于分子和分母中。对于 $Y^{\tilde{x}}$ 和 $\mu(\tilde{X}, L)$ 也是如此。我不确定 EIF 的推导或 g 公式本身是否存在错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/655646/efficient-influence-function-with-interventions-that-depend-on-the-natural-value</guid>
      <pubDate>Fri, 11 Oct 2024 11:34:19 GMT</pubDate>
    </item>
    <item>
      <title>从未知分布估计概率值大于 x</title>
      <link>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknow-distribution</link>
      <description><![CDATA[假设我们有 N 个项目的总体，其值从 0 到 6000。
假设总体的平均值是 $\mu$。
我们不知道项目的分布。
我们从这个总体中提取一个项目，我们如何估计 $P(x\geq 2500)$？
同样的问题，假设分布是均匀的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknow-distribution</guid>
      <pubDate>Fri, 11 Oct 2024 08:52:55 GMT</pubDate>
    </item>
    <item>
      <title>事件发生后定义治疗的差异-差异法</title>
      <link>https://stats.stackexchange.com/questions/655620/difference-in-difference-with-treatment-defined-after-event</link>
      <description><![CDATA[我正在写一篇使用差异-差异设计方法的科学论文，但这不是标准的 DID 设置。
考虑一下我们在多个时间段收集多个公司观察结果的情况。在 $t=0$ 时发生一个事件。到目前为止，一切都很基本。现在偏离标准设置：不知道哪些公司属于治疗组和对照组，治疗组被定义为那些可观察特征 $x$ 从事件前到事件后从 $0$ 变为 $1$ 的公司。控制公司是那些特征 $x$ 保持在 $0$ 的公司。
这是 DID 设计的常见/已知版本吗？如果是，如果您能给我提供一些文献，我会很高兴，因为我还没有找到任何接近这个的文献。]]></description>
      <guid>https://stats.stackexchange.com/questions/655620/difference-in-difference-with-treatment-defined-after-event</guid>
      <pubDate>Thu, 10 Oct 2024 20:42:08 GMT</pubDate>
    </item>
    <item>
      <title>方差总是等于二阶导数的倒数吗？</title>
      <link>https://stats.stackexchange.com/questions/655583/is-variance-always-equal-to-the-inverse-of-the-second-derivative</link>
      <description><![CDATA[这是基于 Fisher 评分法（本质上是 Newton-Raphson 优化算法的统计版本）估计模型参数的著名公式：
$$\theta^{(k+1)} = \theta^{(k)} + [I(\theta^{(k)})]^{-1}U(\theta^{(k)})$$
其中：

$\theta^{(k)}$ 是迭代时的估计值 $k$
$U(\theta)$ 是得分函数（对数似然的一阶导数）
$I(\theta)$ 是 Fisher 信息矩阵（基于 Hessian，即二阶导数）

我认为 Fisher 评分的真正酷之处在于它同时估计参数的方差：
$$E[-\nabla^2 \log L(\theta)] = I(\theta)$$
$$\text{Var}(\hat{\theta}) \approx I^{-1}(\hat{\theta})$$
在之前的问题中（例如如何防止似然优化中的负方差估计？），我了解到许多软件实现实际上并没有使用这种精确的 Fisher 评分方法，因为执行使用 Fisher 评分方法所需的矩阵微积分可能非常复杂。而是使用拟牛顿方法，例如 BFGS 算法。
BFGS 算法（具有与 Fisher 评分非常相似的结构）按如下方式更新 $\theta$ 的估计值：
$$\theta^{(k+1)} = \theta^{(k)} - \alpha^{(k)} H^{(k)} \nabla L(\theta^{(k)})$$
其中：

$\alpha^{(k)}$ 是由线搜索确定的步长
$H^{(k)}$ 是逆 Hessian 的近似值矩阵
$\nabla L(\theta^{(k)})$ 是对数似然的梯度
梯度$\nabla L(\theta)$与 Fisher 评分中的得分函数$U(\theta)$相同。

所有这些都让我感到疑惑。假设 BFGS 中产生的最终 Hessian（即收敛时）表示为 $H_{final}$。
这样说公平吗？
$$H_{final} \xrightarrow{p} [-\nabla^2 \log L(\theta)]^{-1}$$
$$\text{Var}(\hat{\theta}) \approx H_{final}$$
最终呢？
$$\text{Var}(\hat{\theta}) \approx \begin{cases}
I^{-1}(\hat{\theta}) &amp; \text{for Fisher Scoring} \\
H_{final} &amp; \text{for BFGS}
\end{cases}$$
因此，BFGS 算法似乎也估计了参数估计的方差（就像 Fisher Scoring 一样）。
如果这是真的（即 BFGS 通过避免 Fisher Scoring 所需的矩阵微积分节省了时间，并且 BFGS 仍然提供方差估计），那么为什么 Fisher Scoring 在应用中会使用呢？在我看来，Fisher Scoring 只有在一些非常具体的建模情况下才会真正具有优势（例如指数族、GLM），在这些情况下，我们已经事先知道填充得分函数和预期的 hessian 所需的精确矩阵微积分？或者也许从优化的角度来看，Fisher Scoring 更稳定，与 BFGS 相比，它不太可能陷入困境？]]></description>
      <guid>https://stats.stackexchange.com/questions/655583/is-variance-always-equal-to-the-inverse-of-the-second-derivative</guid>
      <pubDate>Thu, 10 Oct 2024 04:26:36 GMT</pubDate>
    </item>
    <item>
      <title>概率/标准正态分布作业帮助</title>
      <link>https://stats.stackexchange.com/questions/655578/probability-standard-normal-distribution-homework-help</link>
      <description><![CDATA[我在家庭作业中被这个问题难住了，想知道是否有人可以提供一些关于如何解决这个问题的建议？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655578/probability-standard-normal-distribution-homework-help</guid>
      <pubDate>Thu, 10 Oct 2024 01:56:25 GMT</pubDate>
    </item>
    <item>
      <title>所有相关性荟萃分析</title>
      <link>https://stats.stackexchange.com/questions/655563/all-correlations-meta-analysis</link>
      <description><![CDATA[我是 MetaSEM 的新手。我正在尝试进行一个简单的元分析（我只想分析 2 个相关性；见图）。
在这里您可以找到我使用的一些模拟数据的代码，但如果没有回归，我就无法让它工作（除非我添加回归系数，否则它会永远工作下去）。这应该是一个简单的模型，但我被卡住了。我只想要两个协方差，我已经将所有方差固定为一个。换句话说，我只想对 S-D 和 I-D 之间的相关性进行元分析。
S 和 D、S 和 I 以及 D 和 I 之间的相关性存储在此处：
rSD &lt;- c(0.85, 0.8, 0.90, 0.78, 0.70,NA,NA,NA,NA,NA)
rSI &lt;- c(NA,NA,NA,NA,NA,0.85,NA,NA,NA,NA)
rDI &lt;- c(NA,NA,NA,NA,NA,0.60, 0.50, 0.55, 0.60, 0.55)

rSI 可能是 al NA，因为我对这种相关性不感兴趣。
我读过关于 SEM 和 RAM 模型的文章，我认为这个模型是可以识别的，应该很容易拟合。任何帮助和指导都将不胜感激。
library(metaSEM)
source(&quot;http://www.suzannejak.nl/MASEM_functions.R&quot;)

rSD &lt;- c(0.85, 0.8, 0.90, 0.78, 0.70,NA,NA,NA,NA,NA)
rSI &lt;- c(NA,NA,NA,NA,NA,0.85,NA,NA,NA,NA)
rDI &lt;- c(NA,NA,NA,NA,NA,0.60, 0.50, 0.55, 0.60, 0.55)

N &lt;- c(10000,40000, 30000, 10000, 10000,20000,10000, 50000, 10000, 10000 )

数据 &lt;- as.data.frame(cbind(rSD,rSI,rDI, N))

nvar &lt;- 3
varnames &lt;- c(&quot;S&quot;,&quot;D&quot;, &quot;I&quot;)
labels &lt;- list(varnames,varnames)

cormatrices &lt;- readstack(data[,c(1,2,3)], no.var = nvar, var.names = varnames, diag = FALSE)

n &lt;- data$N

pattern.na(cormatrices, show.na=F)
pattern.n(cormatrices, n=n)

my.df &lt;- Cor2DataFrame(cormatrices, n, acov = &quot;weighted&quot;)

## 使用指定模型lavaan 语法
模型 &lt;-
&#39;

# 协方差
D ~~ I
D ~~ S
# 方差

D ~~ 1*D
S ~~ 1*S
I ~~ 1*I
&#39;

RAM1 &lt;- lavaan2RAM(model, obs.variables=varnames)
RAM1

## 创建具有隐式对角线约束的模型隐含相关结构
M0 &lt;- create.vechsR(A0=RAM1$A, S0=RAM1$S)

## 创建异质性方差-协方差矩阵
T0 &lt;- create.Tau2(RAM=RAM1, RE.type=&quot;Diag&quot;, Transform=&quot;expLog&quot;, RE.startvalues=0.05)

## 拟合模型
mx.fit0 &lt;- osmasem(model.name=&quot;No moderator&quot;, Mmatrix=M0, Tmatrix=T0, data=my.df)

## 查看结果
summary(mx.fit0, fitIndices = TRUE)
VarCorr(mx.fit0)

]]></description>
      <guid>https://stats.stackexchange.com/questions/655563/all-correlations-meta-analysis</guid>
      <pubDate>Wed, 09 Oct 2024 19:33:34 GMT</pubDate>
    </item>
    </channel>
</rss>