<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 28 Jan 2025 15:17:28 GMT</lastBuildDate>
    <item>
      <title>风险降低情况下的试验样本量估计</title>
      <link>https://stats.stackexchange.com/questions/660669/trial-sample-size-estimation-in-case-of-decreasing-risk</link>
      <description><![CDATA[当您设计一项试验时，您的干预（或治疗）预计会比对照组产生更好的效果，治疗效果预计为“d=u1-u0”，其中 u1 是治疗组的平均效果，u0 是对照组的平均效果。然后：

对于优效性试验，样本量是“d”的函数，d 为正，最终是临床边际“delta”，delta 也为正。每组的样本量公式如下（如果我们预期每组的样本量相等，则 r=1）



对于非劣效性试验，样本量是“d”的函数，d 为正，最终是临床边际“delta”，delta 也为正。每组的样本量公式如下
（如果我们预期每组的样本量相等，则 r=1）


当 d&gt;0 时，这些公式显而易见，但当我们预期治疗会降低风险时（则 d&lt;0，因为 u1&lt;u0），我们如何调整它们？我很难应用这些公式，尤其是在非劣效性设计的情况下（d&lt;0，我们预期治疗不会增加风险，直到一定量的“delta”，即显着性边际）。]]></description>
      <guid>https://stats.stackexchange.com/questions/660669/trial-sample-size-estimation-in-case-of-decreasing-risk</guid>
      <pubDate>Tue, 28 Jan 2025 14:47:50 GMT</pubDate>
    </item>
    <item>
      <title>竞争风险 Cox 模型的 PH 假设</title>
      <link>https://stats.stackexchange.com/questions/660668/ph-assumption-for-competing-risks-cox-models</link>
      <description><![CDATA[我一直在研究汽车租赁“生存”的 Cox 模型。租赁有约定的结束时间，但通常会提前或晚于预期付款。车辆租赁也可能由于多次未付款而被收回而提前结束。因此，我们关注两种结果，我们称之为已付款和其他结果。
该模型的协变量自然会随着时间的推移而变化。客户需要保持良好的财务状况才能获得租赁。但随着情况的变化，生存概率也会发生变化。一个很好的例子就是信用评分。他们在开始租赁时必须拥有可接受的信用评分。但随着时间的推移，个人和环境因素（主要与经济有关）会发生变化，这些变化可以预测租赁提前结束。
我使用 R 生存包构建了一个具有时间相关协变量的竞争风险模型（针对已付款和其他结果）。在对使用时间相关协变量时 PH 假设是否仍然相关产生了很多困惑之后，我相信这是一个需要解决的问题。
大多数情况下，在正式租约结束时都会自然终止。这是发生最大转变的时间范围。有多个变量违反了 PH 假设。一个例子是信用评分。我怀疑租约持续的时间越长，信用评分就越好（对于 PAID）。然而，当信用评分下降时，租约结束时的 OTHER 会增加。
以下是使用“身份”变换对 cox.zph 输出的 PAID 和 OTHER 信用评分的图。 （我添加了一条绿线来显示该变量的估计系数）


我的问题是，在租约结束时我应该如何处理这些影响？由于我使用的是竞争风险模型，因此我只能使用“生存”包中的某些工具。人们经常使用“tt”函数进行连续时间变换。 “survival” 包中的多状态模型不支持此功能。使用“survSplit”的离散时间分割也不受支持。psplines 函数似乎也很流行，用于处理违反 PH 假设的变量转换。生存包中的竞争风险模型也不支持此功能。
最终竞争风险模型中的“状态”概率对我们来说非常有用，但似乎我必须违反 PH 假设才能获得它们。]]></description>
      <guid>https://stats.stackexchange.com/questions/660668/ph-assumption-for-competing-risks-cox-models</guid>
      <pubDate>Tue, 28 Jan 2025 14:28:50 GMT</pubDate>
    </item>
    <item>
      <title>您能“虚拟”出独立变量上的异常值吗？</title>
      <link>https://stats.stackexchange.com/questions/660667/can-you-dummy-out-an-outlier-on-the-independent-variable</link>
      <description><![CDATA[我想运行一个回归分析，其中一个回归量有一个异常值。我想知道我是否可以包含一个虚拟变量来排除这个异常值，而不会丢失来自其他回归量的信息，因为另一种选择是删除整个观察值。请考虑以下示例：
y = [1,2,1,3,1,5,4,4,4,3]
x1 = [0.1,0.9,0.1,0.7,0.5,0.5,0.3,0.2,0.4,0.3]
x2 = [10,-105,13,​​15,15,16,13,13,16,13]
x2 中的第二个观测值显然是一个异常值（由通货膨胀衡量方式的制度变化引起 - 导致数据急剧变化）。估算以下回归是否可以让我避免这个异常值对我感兴趣的系数产生的影响？
$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \gamma\times \text{ dummy}\times x_2$
其中
如果 x_2 = -105，则 dummy = 1；否则 dummy = 0]]></description>
      <guid>https://stats.stackexchange.com/questions/660667/can-you-dummy-out-an-outlier-on-the-independent-variable</guid>
      <pubDate>Tue, 28 Jan 2025 14:10:49 GMT</pubDate>
    </item>
    <item>
      <title>如何针对小数据集选择合适的统计推断方法？</title>
      <link>https://stats.stackexchange.com/questions/660664/how-to-choose-appropriate-statistical-inference-methods-for-small-datasets</link>
      <description><![CDATA[我希望提高对选择正确的统计推断方法的理解。我的经验主要是机器学习的数据驱动方法，但我想更好地了解其他统计方法以及选择正确方法时的关键考虑因素。我经常处理小型生物医学数据集。在这些情况下，哪些因素应该指导统计推断方法的选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/660664/how-to-choose-appropriate-statistical-inference-methods-for-small-datasets</guid>
      <pubDate>Tue, 28 Jan 2025 13:22:00 GMT</pubDate>
    </item>
    <item>
      <title>这个在线 A/B 测试计算器在做什么？感觉不太准确</title>
      <link>https://stats.stackexchange.com/questions/660660/what-is-this-online-a-b-testing-calculator-doing-it-doesnt-feel-accurate</link>
      <description><![CDATA[我遇到过这种情况：
https://neilpatel.com/ab-testing-calculator/
它输出的结果在我看来并不严格，我对测试的内容很感兴趣（Fisher 精确检验、学生 t 检验等）。
我不是统计学家或数据科学家，所以我很想听听统计学家或数据科学家的看法。一旦我有了方向，我可以通过计算来验证。]]></description>
      <guid>https://stats.stackexchange.com/questions/660660/what-is-this-online-a-b-testing-calculator-doing-it-doesnt-feel-accurate</guid>
      <pubDate>Tue, 28 Jan 2025 10:09:13 GMT</pubDate>
    </item>
    <item>
      <title>尽管 PCA 对多类数据的分离效果较差，但分类准确率仍然很高</title>
      <link>https://stats.stackexchange.com/questions/660658/high-classification-accuracy-despite-poor-separation-in-pca-for-multi-class-data</link>
      <description><![CDATA[我最近对一个具有四类目标变量的数据集进行了主成分分析 (PCA)。虽然 PCA 得分图显示一个组的分离效果很好，但其余三个类别的区分度较差。
对于分类，我使用主成分作为支持向量机 (SVM) 和线性判别分析 (LDA) 中的特征，并且两个模型都实现了非常好的准确性。我希望从社区获得有关这一观察的一些见解。有人可以解释这个明显的矛盾吗？为什么 PCA 图没有显示三个类别之间的明显分离，但使用主成分作为特征时分类算法表现良好？
感谢您的时间和考虑。]]></description>
      <guid>https://stats.stackexchange.com/questions/660658/high-classification-accuracy-despite-poor-separation-in-pca-for-multi-class-data</guid>
      <pubDate>Tue, 28 Jan 2025 09:43:50 GMT</pubDate>
    </item>
    <item>
      <title>使用高斯过程填补缺失的时间序列数据</title>
      <link>https://stats.stackexchange.com/questions/660657/using-gaussian-process-to-impute-missing-time-series-data</link>
      <description><![CDATA[使用 R，我模拟了一些月度时间序列数据并随机删除了一些数据点：
library(ggplot2)
library(tidyverse)
library(MASS)
library(gridExtra)

set.seed(123)

dates &lt;- seq(as.Date(&quot;2014-01-01&quot;), as.Date(&quot;2023-12-31&quot;), by = &quot;month&quot;)
n &lt;- length(dates)

trend &lt;- seq(10, 30, length.out = n)
seasonal &lt;- 5 * sin(2 * pi * (1:n) / 12)
noise &lt;- rnorm(n, 0, 0.5)
values &lt;- trend + seasonal + noise

df &lt;- data.frame(date = dates, value = values)
n_remove &lt;- floor(0.3 * (n-2))
interior_indices &lt;- 2:(n-1)
remove_indices &lt;- sample(interior_indices, n_remove)

df$type &lt;- &quot;original&quot;
df$type[remove_indices] &lt;- &quot;removed&quot;


我的目标是填补时间序列中缺失的数据点。我有以下想法 - 可以使用高斯过程（通过 RBF 核）来实现吗？
我希望以这样的方式实现，即当非缺失点之间的空间增加时，插值/估算的不确定性会变得更大。我还想在插值/估算中添加一个概率元素，这以后可能会有用。我在下面写了基本的高斯过程公式：

$$ \begin{bmatrix} y_{observed} \\ y_{interpolated} \end{bmatrix} \sim \mathcal{N}\left(\begin{bmatrix} \mu_{observed} \\ \mu_{interpolated}
\end{bmatrix}, \begin{bmatrix} K_{11} &amp; K_{12} \\ K_{21} &amp; K_{22}
\end{bmatrix}\right) $$
$$ k(x_1, x_2) = \sigma^2 \exp\left(-\frac{(x_1 - x_2)^2}{2l^2}\right)$$
$$ p(y_{interpolated}|y_{observed}) = \mathcal{N}(\mu_{post}, \Sigma_{post}) $$
$$ \mu_{post} = K_{12}K_{11}^{-1}y_{observed} $$
$$\Sigma_{post} = K_{22} - K_{12}K_{11}^{-1}K_{21} $$ $$ y_{sample} \sim
\mathcal{N}(\mu_{post}, \Sigma_{post}) $$

我首先设置了执行此操作所需的不同函数：
 kernel &lt;- function(x1, x2, l = 30, sigma = 2) {
sqdist &lt;- outer(x1, x2, function(x, y) (as.numeric(x - y))^2)
sigma^2 * exp(-0.5 * sqdist / l^2)
}

x_obs &lt;- as.numeric(df$date[df$type == &quot;original&quot;])
y_obs &lt;- df$value[df$type == &quot;original&quot;]
x_pred &lt;- as.numeric(df$date)

K &lt;- kernel(x_obs, x_obs)
K_star &lt;- kernel(x_pred, x_obs)
K_star_star &lt;- kernel(x_pred, x_pred)

K &lt;- K + diag(1e-6, length(x_obs))

K_inv &lt;- solved(K)
mu_post &lt;- as.vector(K_star %*% K_inv %*% y_obs)
Sigma_post &lt;- K_star_star - K_star %*% K_inv %*% t(K_star)

然后，我写了采样程序：
n_samples &lt;- 50
samples &lt;- t(mvrnorm(n_samples, mu_post, Sigma_post))

ci_data &lt;- data.frame(
date = df$date,
mean = mu_post,
lower = apply(samples, 1, quantile, probs = 0.025),
upper = apply(samples, 1, quantile, probs = 0.975)
)

samples_df &lt;- as.data.frame(samples)
colnames(samples_df) &lt;- paste0(&quot;sample_&quot;, 1:n_samples)
samples_df$date &lt;- df$date
samples_long &lt;- tidyr::pivot_longer(samples_df, 
-date,
names_to = &quot;sample&quot;, 
values_to = &quot;value&quot;)

最后我尝试将其可视化：

Cross Validated 的人员：您之前尝试过/听说过有人尝试这样做吗？

注意：如果有人感兴趣，我可以分享 ggplot 可视化 R 代码
]]></description>
      <guid>https://stats.stackexchange.com/questions/660657/using-gaussian-process-to-impute-missing-time-series-data</guid>
      <pubDate>Tue, 28 Jan 2025 08:48:22 GMT</pubDate>
    </item>
    <item>
      <title>绘制箱线图时应该使用模型训练精度还是测试精度？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660656/for-plotting-box-plot-should-one-use-model-training-accuracy-or-test-accuracy</link>
      <description><![CDATA[我正在处理一个包含 500 个样本的数据集。我将数据集按 80、20 的比例分成训练和测试。使用训练集，我使用网格搜索方法对 SVM、KNN 和决策树分类器进行了超参数调整，并为每个分类器获得了最佳超参数。然后再次使用获得的超参数拟合训练数据集，并通过交叉验证评估分类器的训练准确率。最后使用测试数据集计算模型准确率，并将测试准确率报告为模型准确率。
现在我想绘制箱线图来表示模型准确率，那么我应该使用训练准确率还是测试数据（交叉验证）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660656/for-plotting-box-plot-should-one-use-model-training-accuracy-or-test-accuracy</guid>
      <pubDate>Tue, 28 Jan 2025 08:16:40 GMT</pubDate>
    </item>
    <item>
      <title>SAS 和 Python 之间的 Somers D 对二进制结果不匹配吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660655/mismatch-of-somers-d-between-sas-and-python-for-binary-outcomes</link>
      <description><![CDATA[执行摘要：

scipy.stats.somersd(x,y) 将 y 视为独立变量。
与 SAS 的 PROC LOGISTIC 相比，对于二元变量，如果我切换变量，我只能让它与 Python 匹配。
在查看二元目标时，是否有令人信服的理由来切换变量，或者我在使用中遗漏了什么？

背景：
因此，我尝试将 Somers 的 D 用于观察值 x 和 y，y 是 因变量。换句话说：我想知道 x 对 y 的排名如何。我希望我的用法对于两个变量都分组的情况和 y 是二进制变量的基数是一致的。但是，SAS 和 Python 之间的惯例似乎不同。为此，我为自己生成了一些数据。x 和 y 是连续的。还有分组列和二进制目标（由 y 中的非常粗略的分箱制成）
scipy.stats.somersd 文档指出 somersd(x,y) 将 x 视为独立变量，将 y 视为独立变量。按照该标准计算 Somers 的 D（对于分组变量），我得到的值为 0.36057，我可以通过手动计算进行交叉检查。代码位于此处。
改为计算二进制情况，我得到 0.23609。如果我切换变量的顺序，我得到 0.51680。
转到 SAS（并导入相同的数据集），我尝试从 PROC LOGISTIC 获取 Somers 的 D：
ods output Association=assoc;
proc logistic data=somersd;
model y_binarized(event=&#39;1&#39;) = x_group;
run;

如果我切换因变量和自变量，则会产生与 scipy.stats.somersd 匹配的 0.51680 值。
实际问题：
我试图弄清楚特定变量 x 对二元结果 y 的预测效果如何。在我看来，这意味着 y 是 因变量，我应该计算 scipy.stats.somersd(x,y)。但是，SAS 计算与 scipy.stats.somersd(y,x) 匹配。
在计算二元结果时，是否有令人信服的理由来改变变量的顺序，或者我是否滥用了 SAS 或 Python？
备份信息：
我喜欢用代码交流。我的想法（代码）可以在这个 Github 存储库中找到。Readme.md 文件是丹麦语（合作者是丹麦人），但代码是用英语注释的。为一致性而欢呼。
Python 代码调用 scipy.stats.somersd 并通过手动计算进行交叉检查。
SAS 代码 从 Github 读取 csv 文件（您可能需要调整代理设置）并运行 PROC LOGISTIC 以获取 Somers 的 D。还有一些 PROC FREQ 的东西我还没有想完。]]></description>
      <guid>https://stats.stackexchange.com/questions/660655/mismatch-of-somers-d-between-sas-and-python-for-binary-outcomes</guid>
      <pubDate>Tue, 28 Jan 2025 08:01:37 GMT</pubDate>
    </item>
    <item>
      <title>异常值检测，取 Z 分数的平均值是否合适？</title>
      <link>https://stats.stackexchange.com/questions/660654/outlier-detection-is-it-appropriate-to-take-the-mean-of-z-scores</link>
      <description><![CDATA[简单的背景故事，我有几个加密代币想要查看。我想做一些异常检测，并寻找哪些代币可能容易受到欺诈或骗局的影响。
假设我们有 10 个代币。我将它们放在一个数据框中，每个代币都有股票代码以及价格、流动性和交易量等数字属性。
假设我计算了每个代币的价格、流动性和交易量的 $Z$ 分数。如果我想评估哪个代币可能是骗局，那么取所有 $Z$ 分数列的平均值在统计上是否合适？（即 $\frac{Z_{price}+Z_{liquidity}+Z_{volume}}{3}$）]]></description>
      <guid>https://stats.stackexchange.com/questions/660654/outlier-detection-is-it-appropriate-to-take-the-mean-of-z-scores</guid>
      <pubDate>Tue, 28 Jan 2025 06:38:38 GMT</pubDate>
    </item>
    <item>
      <title>在 GLMM 中，什么样的随机效应方差才算是“接近零”？</title>
      <link>https://stats.stackexchange.com/questions/660635/what-qualifies-as-near-zero-random-effect-variance-in-glmm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660635/what-qualifies-as-near-zero-random-effect-variance-in-glmm</guid>
      <pubDate>Mon, 27 Jan 2025 19:51:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么高度相关的特征会导致相应系数很大且符号相反？</title>
      <link>https://stats.stackexchange.com/questions/660628/why-do-highly-correlated-features-cause-the-corresponding-coefficients-to-be-lar</link>
      <description><![CDATA[我进行了以下实验。假设我们要构建一个具有 3 个特征的线性回归：$$y = w_1 * x_1 + w_2 * x_2 + w_3 * x_3$$，并且我们有一个包含一定数量样本的数据集。该数据集是一个均匀随机设计矩阵 $X$，除了特征 $x_3$，它是 $x_2$ 加上一些随机噪声，以使 $x_2$ 和 $x_3$ 高度相关。此外，真实权重向量 $w_{true}$ 也是随机生成的，导致目标计算为：$$y 
= Xw_{true} + \epsilon$$，其中 $\epsilon$ 是随机生成的噪声。给定 $X$ 和 $y$，我想要找到 $w^*$，如下所示：$$w^* = (X^T X)^{-1}X^T Y$$
这是最小化 MSE 损失函数的解析解。因此，估计系数 $w_2^*$ 和 $w_3^*$ 的绝对值较大，但符号相反。如果我将目标噪声 $\epsilon$ 调大，系数的绝对值会变大，但当我将特征 $x_2$ 和 $x_3$ 之间的噪声调小时，系数也会增大。一种可能的解释是，由于 $x_2$ 和 $x_3$ 高度相关，因此在选择相应的回归系数时具有很大的灵活性，并且我们的解决方案尝试学习目标噪声 $\epsilon$，但由于相关特征之间的差异与目标噪声相比很小，因此我们需要较大的系数来解释特征值的细微变化。但是，我并不完全了解其背后的机制，以及为什么添加相关特征会使我的模型过度拟合]]></description>
      <guid>https://stats.stackexchange.com/questions/660628/why-do-highly-correlated-features-cause-the-corresponding-coefficients-to-be-lar</guid>
      <pubDate>Mon, 27 Jan 2025 18:59:16 GMT</pubDate>
    </item>
    <item>
      <title>卡方蒙特卡罗模拟反馈和替代方案</title>
      <link>https://stats.stackexchange.com/questions/660599/chi-square-monte-carlo-simulation-feedback-and-alternatives</link>
      <description><![CDATA[我有一个列联表，我想在其上应用卡方检验，但某些单元格不大于 5，这意味着我无法使用该检验。我读到过蒙特卡罗模拟是可行的，但我不知道在这种情况下它是否合适，或者是否有替代测试。
这是我的数据：
data &lt;- matrix(c(326, 32, 22, 2, 96, 115, 271, 4, 132, 29), 
nrow = 5, byrow = TRUE,
dimnames = list(c(&quot;GR1&quot;, &quot;GR2&quot;, &quot;GR3&quot;, &quot;GR4&quot;, &quot;GR5&quot;),
c(&quot;No&quot;, &quot;Yes&quot;)))

这是 R 中的结果：
chisq.test(data, mock.p.value = TRUE, B = 10000)

带模拟 p 值的 Pearson 卡方检验（基于 10000 次重复）

数据：数据
X 平方 = 266.48，df = NA，p 值 = 9.999e-05

我的方法好吗，或者是否有更可靠或更有趣的替代方法？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660599/chi-square-monte-carlo-simulation-feedback-and-alternatives</guid>
      <pubDate>Mon, 27 Jan 2025 12:20:54 GMT</pubDate>
    </item>
    <item>
      <title>完全循环神经网络Hopfield网络和Elman网络有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/660560/what-are-the-differences-between-fully-recurrent-neural-networks-hopfield-networ</link>
      <description><![CDATA[我很难理解这两者的区别。据我所知，FCRN 中的每个隐藏神经元都会影响所有其他神经元和自身，而在 Hopfield 中，它会影响其他神经元但不会影响自身。我无法理解在相同情况下这会带来什么不同，以及不与他人连接如何意味着关联？]]></description>
      <guid>https://stats.stackexchange.com/questions/660560/what-are-the-differences-between-fully-recurrent-neural-networks-hopfield-networ</guid>
      <pubDate>Sun, 26 Jan 2025 13:33:42 GMT</pubDate>
    </item>
    <item>
      <title>解释逻辑回归中的大系数</title>
      <link>https://stats.stackexchange.com/questions/660554/interpreting-large-coefficients-in-logistic-regression</link>
      <description><![CDATA[我正在处理一个棒球数据集，该数据集包含 30,000 行，每行对应一个投球。因变量是 UMP_MISTAKE（二进制），值为零表示裁判做出了正确的判罚，值为一表示判罚不正确。大约 11% 的 UMP_MISTAKE 值为 1。有 30 个独立变量，包括三向交互：WORLD_SERIESxBAT_WINxBAT_AVG。WORLD_SERIES 是二进制的，表示比赛是否属于世界大赛。BAT_WIN 是二进制的，表示如果击球手的球队赢得当前比赛，他们是否会赢得大赛。BAT_AVG 是击球手平均值，连续的，大多数值在 0.25 到 0.30 之间。一些逻辑回归模型输出如下：



变量
估计
p 值




WORLD_SERIES
0.88
0.11


BAT_WIN
 0.38
0.44


BAT_AVG
1.17
0.12


WORLD_SERIESxBAT_WINxBAT_AVG
10.4
0.06



交互变量的系数很大。转换为比值比时，它超过 34,000，给出的概率实际上为 1。是什么原因造成的？我只能猜测，对于这个交互变量，绝大多数值（97%）将为零。30,000 行中只有大约 1000 行具有非零值。我该如何理解这一点？我能做些什么来解决这个问题并将交互变量保留在模型中吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660554/interpreting-large-coefficients-in-logistic-regression</guid>
      <pubDate>Sun, 26 Jan 2025 12:13:13 GMT</pubDate>
    </item>
    </channel>
</rss>