<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 12 Apr 2024 12:24:27 GMT</lastBuildDate>
    <item>
      <title>受限三次样条与对数相对风险 = 0 的交点</title>
      <link>https://stats.stackexchange.com/questions/644874/intersection-of-restricted-cubic-spline-with-log-relative-hazard-0</link>
      <description><![CDATA[我想确定受限三次样条与对数相对危险 = 0 的交集（即从较低危险到较高危险的变化）。谢谢！
fit &lt;- cph(Surv(时间, 状态) ~ rcs(年龄, 4), data = df, x = TRUE, y = TRUE, surv = TRUE)
ggplot（预测（拟合））
]]></description>
      <guid>https://stats.stackexchange.com/questions/644874/intersection-of-restricted-cubic-spline-with-log-relative-hazard-0</guid>
      <pubDate>Fri, 12 Apr 2024 12:17:29 GMT</pubDate>
    </item>
    <item>
      <title>$X_nY_n=\mathcal{o}_{p}(\beta_n)$ 成立吗？</title>
      <link>https://stats.stackexchange.com/questions/644873/does-x-ny-n-mathcalo-p-beta-n-hold</link>
      <description><![CDATA[&lt;块引用&gt;
设 $X_n$ 和 $Y_n$ 均为非负随机变量序列。定义 $A_n:=\left\{\omega:X_{n}(\omega)&gt;0\right\}.$ 假设 $\lim_{n\rightarrow\infty}\mathbf{P}(A_n)=0,Y_n=\mathcal{O}_{p}(\beta_n),$ 其中 $\left\{\beta_n\right\}_{n\in\mathbf{N}}$ 是严格正实数的序列。
我们能否得出结论：$X_nY_n=\mathcal{o}_{p}(\beta_n)$？

来自$\mathcal{O}_{p}$ 和 $\mathcal{ 的定义o}_{p}$，我尝试证明对于每个 $\epsilon&gt;0,\mathbf{P}\left(\frac{ X_n Y_n}{\beta_n}&gt;\epsilon\right)\rightarrow 0,$ as $n\rightarrow\infty.$
由于 $\left\{\omega:\frac{X_n Y_n}{\beta_n}&gt;\epsilon\right\}=\left\{\omega:\frac {X_n Y_n}{\beta_n}\cdot\mathbb{I}_{\{X_n&gt;0\}}&gt;\epsilon\right\}\biguplus\left\{\omega:\frac{X_n Y_n}{\ beta_n}\cdot\mathbb{I}_{\{X_n=0\}}&gt;\epsilon\right\}(\biguplus \text{表示不相交并}),$ $$\mathbf{P}\left\{\omega:\frac{X_n Y_n}{\beta_n}&gt;\epsilon\right\}=\mathbf{P}\left\{\omega:\ frac{X_n Y_n}{\beta_n}\cdot\mathbb{I}_{\{X_n&gt;0\}}&gt;\epsilon\right\}.$$
不管怎样，$$\left\{\omega:\frac{X_n Y_n}{\beta_n}\cdot\mathbb{I}_{\{X_n&gt;0\}}&gt; \epsilon\right\}\subseteq A_n,$$ 然后 $$\lim_{n\rightarrow\infty}\mathbf{P}\left(\frac{X_n Y_n}{\beta_n}&gt;\epsilon\right)=0.$$
我不确定我的证明似乎没有使用 $Y_n=\mathcal{O}_{p}(\beta_n).$ 如果需要，请纠正我.]]></description>
      <guid>https://stats.stackexchange.com/questions/644873/does-x-ny-n-mathcalo-p-beta-n-hold</guid>
      <pubDate>Fri, 12 Apr 2024 11:51:48 GMT</pubDate>
    </item>
    <item>
      <title>后验近似遵循优化方法</title>
      <link>https://stats.stackexchange.com/questions/644869/posterior-approximation-following-optimization-methods</link>
      <description><![CDATA[我正在尝试量化高维、多模态后验空间中的不确定性。我们没有正演模型的分析解，并且正演模型的运行成本可能很高。因为无梯度 MCMC 收敛时间太长并且无法并行化，所以我试图避免 MCMC。我们能做的是在多线程中运行无梯度优化。所以我想知道是否有一种方法可以在优化步骤中使用样本/步骤的集合来重建或近似后验。
这里我用一个 2D 案例来演示这个问题。背景颜色代表我们感兴趣的真实后验，黄色点是样本。我在这里使用梯度下降进行了简单的优化，仅用于演示目的。

显然直接使用直方图会导致一些过于密集的区域，这并不代表后验。蓝色阴影显示来自真实后验的样本。

如果我们使用所有优化步骤，当然也会存在相同的不平衡密度。但是有没有办法利用我们现在拥有的信息来以某种方式估计后验呢？任何想法都会受到赞赏。
]]></description>
      <guid>https://stats.stackexchange.com/questions/644869/posterior-approximation-following-optimization-methods</guid>
      <pubDate>Fri, 12 Apr 2024 11:04:21 GMT</pubDate>
    </item>
    <item>
      <title>帮助解释 ACF 和 PACF 图</title>
      <link>https://stats.stackexchange.com/questions/644868/help-interpreting-acf-and-pacf-plots</link>
      <description><![CDATA[我是时间序列分析的新手，一直在尝试了解如何正确识别 ACF 和 PACF 图。我已经运行了 gam，现在正在查看残差，然后运行 ​​GAMM。我有以下两组数据的图表，并且正在努力正确识别它们。我是否正确地认为plot1只是噪音，这不需要考虑任何自相关：

然后对于图 2，我认为它会是 MA(2)，并且在 R 中编码为关联=corARMA(p=2)。这是正确的还是我完全错误？这是否可以被视为噪音以及峰值几乎超过 95% 的区间？

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644868/help-interpreting-acf-and-pacf-plots</guid>
      <pubDate>Fri, 12 Apr 2024 10:34:11 GMT</pubDate>
    </item>
    <item>
      <title>计算不同结果变量的包含贝叶斯因子</title>
      <link>https://stats.stackexchange.com/questions/644867/calculating-inclusion-bayes-factors-across-different-outcome-variables</link>
      <description><![CDATA[我正在进行统计分析，以确定在各种模型下观察到的数据的概率，特别是根据多个标准检查包含特定效应的模型是否比不包含特定效应的模型更有可能。
在我的研究中，我正在处理四个不同的结果变量（代表不同的人格特征：Y1、Y2、Y3 和 Y4）。对于每个结果，我使用以下模型运行了三个贝叶斯线性回归：

仅包含预测变量 X1 的模型
具有预测变量 X1 和 X2 的模型
包含预测变量 X1、X2 及其交互作用的模型

对于每个结果，我都使用单独的贝叶斯因子比较了模型。现在，我正在探索是否可以计算一个汇总贝叶斯因子来汇总所有结果的这些比较。
是否有一种方法或方法来计算涵盖不同结果变量的聚合或包含贝叶斯因子？我的目标是确定，与不包含效应 X 的模型相比，包含效应 X 的模型产生观测数据的可能性平均有多大。]]></description>
      <guid>https://stats.stackexchange.com/questions/644867/calculating-inclusion-bayes-factors-across-different-outcome-variables</guid>
      <pubDate>Fri, 12 Apr 2024 10:23:18 GMT</pubDate>
    </item>
    <item>
      <title>额外的协变量使混合模型恶化（LMM、GLMM、GAM）</title>
      <link>https://stats.stackexchange.com/questions/644863/additional-covariate-worsen-the-mixed-models-lmm-glmm-gam</link>
      <description><![CDATA[在不同Group中对时间点进行重复测量时，Age和Gender充当模型中的协变量，Age code&gt; 在每个时间点计算，但 Gender 是每个受试者的静态变量。
m1 &lt;- lmer(分数 ~ 组 + 时间点 + (1 | 主题))
m2 &lt;- lmer(分数 ~ 组 + 时间点 + 年龄 + (1 | 主题))
m3 &lt;- lmer(分数 ~ 组 + 时间点 + 性别 + (1 | 主题))
m4 &lt;- lmer(分数 ~ 组 + 时间点 + 年龄 + 性别 + (1 | 主题))

AIC 用于评估模型拟合
&lt;前&gt;&lt;代码&gt;&gt; AIC(m1, m2, m3, m4)
   df AIC
m1 5 752.6940
平方米 6 758.4476
米3 6 753.5923
m4 7 759.0831

如果 AIC 没有改善，这些协变量是否应该被排除在模型中？]]></description>
      <guid>https://stats.stackexchange.com/questions/644863/additional-covariate-worsen-the-mixed-models-lmm-glmm-gam</guid>
      <pubDate>Fri, 12 Apr 2024 09:46:54 GMT</pubDate>
    </item>
    <item>
      <title>多项式逻辑回归（使用 softmax 归一化）中的指数系数可以解释为优势比吗？</title>
      <link>https://stats.stackexchange.com/questions/644862/can-exponentiated-coefficients-in-multinominal-logistic-regression-with-softmax</link>
      <description><![CDATA[指数逻辑回归系数被解释为优势比。这在多项式逻辑回归中是否仍然成立，其中 softmax 通常用于标准化概率以确保它们的总和为 1？
例如，这是由 scikit-learn 多项（多类）问题执行的。在那里，要获得与 scikit-learn (predict_proba) 相同的概率估计，必须这样做
将 numpy 导入为 np
logits = np.dot(test, coef_.T) +拦截_
exp_logits = np.exp(logits)
概率 = exp_logits / np.sum(exp_logits) # (!!) softmax
打印（概率）

由于 logits 在用于计算概率之前受到 softmax 的影响，我想知道仅对系数求幂 (np.exp(model.coef_)) 是否可以直接解释为优势比，假设此步骤中未考虑 softmax 变换。然而，当考虑所有变量时，softmax 对结果概率可能有很大影响。
不应用 softmax 的结果概率有很大不同：
probability_no_softmax = 1 / (1 + np.exp(-logits))

即使标准化为 1 后：
probability_no_softmax/np.sum(probability_no_softmax)

如果多项式模型的逻辑回归系数不能直接解释为优势比，如何将softmax纳入系数的解释中？
完整可重现示例的数据：
将 numpy 导入为 np
测试 = np.array([[50,10000,1000]])
coef_= np.array([[-1.02166294e-02,-2.32232541e-05,1.13787899e-03],[5.04602305e-03,-2.29265186e-04,7.62774637e-04],[8.26318650e-03 , 1.94503396e-04,-7.18393130e-04],[-3.09258020e-03,5.79850435e-05,-1.18226050e-03]])
Intercept_= np.array([-0.0006201,-0.0002349,0.0007245,0.0001305])

#scikit学习predict_proba
从 sklearn.linear_model 导入 LogisticRegression
模型1 = 逻辑回归()
model1.classes_=np.array([0,1,2,3,4])
model1.coef_= coef_
model1.intercept_=拦截_
Predict_proba=model1.predict_proba(测试)
打印（预测概率）

#手动计算需要softmax来获得相同的概率估计
logits = np.dot(test, coef_.T) +拦截_
exp_logits = np.exp(logits)
手动概率 = exp_logits / np.sum(exp_logits) # (!!) softmax
print(manual_probabilities) #结果与 model1.predict_proba 匹配

#没有softmax
probability_no_softmax = 1 / (1 + np.exp(-logits))
打印（probability_no_softmax）

#没有进行softmax归一化
probability_no_softmax_norm=probability_no_softmax/np.sum(probability_no_softmax)
打印（probability_no_softmax_norm）

退货
[[0.20073414 0.03771189 0.69806425 0.06348971]] #softmax手册

[[0.20073414 0.03771189 0.69806425 0.06348971]]#predict_proba

[[0.59729212 0.21792308 0.83760631 0.31931782]] #没有softmax非标准化

[[0.30286507 0.11050085 0.42471964 0.16191443]] #没有softmax归一化

]]></description>
      <guid>https://stats.stackexchange.com/questions/644862/can-exponentiated-coefficients-in-multinominal-logistic-regression-with-softmax</guid>
      <pubDate>Fri, 12 Apr 2024 09:27:37 GMT</pubDate>
    </item>
    <item>
      <title>rpart包如何在“缺失”的情况下得到“改善”？</title>
      <link>https://stats.stackexchange.com/questions/644860/how-does-the-rpart-package-get-the-improve-when-there-is-missing</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;库(mlbench)
库（r部分）

数据（声纳）

声纳[1，“V11”] &lt;- NA
ct1 &lt;- rpart(Class ~ .,data = 声纳, method = “class”, cp = 0)
摘要(ct1)


rpart包如何获得“improve=27.13488”什么时候有“1 缺失”？]]></description>
      <guid>https://stats.stackexchange.com/questions/644860/how-does-the-rpart-package-get-the-improve-when-there-is-missing</guid>
      <pubDate>Fri, 12 Apr 2024 08:55:30 GMT</pubDate>
    </item>
    <item>
      <title>这些值遵循什么分布（如果有）？</title>
      <link>https://stats.stackexchange.com/questions/644859/what-distribution-if-any-are-these-values-following</link>
      <description><![CDATA[我不确定这是否是问这个问题的正确地方，但这似乎是最相关的，因为我的问题是关于随机分布的。请告诉我是否应该将其移至其他社区。
我一直在研究 LCG/MCG 伪随机发生器的频谱测试值。在本文和我自己对更大的二次幂模数运行一些测试之间（在特别是 2^64 和 2^128），看起来在 24 维以内的光谱测试有一致的趋势，看起来与链接论文中提供的相似。使用 scipy.stats，我确定随着维度变高，分布越来越接近拟合 beta 分布，但对于 2 维和 3 维谱来说，它显然非常糟糕至少测试结果。此外，贝塔分布似乎低估了“高度”。即使在相对较高的尺寸下也能达到峰值。
这是否更适合某些现有的连续分布，还是 Beta 分布是我能做的最好的？]]></description>
      <guid>https://stats.stackexchange.com/questions/644859/what-distribution-if-any-are-these-values-following</guid>
      <pubDate>Fri, 12 Apr 2024 08:50:12 GMT</pubDate>
    </item>
    <item>
      <title>具有 Tweedie 分布的 GAM 可以用于二元响应吗？</title>
      <link>https://stats.stackexchange.com/questions/644858/can-gam-with-tweedie-distribution-be-used-for-a-binary-response</link>
      <description><![CDATA[我正在尝试使用 GAM 进行物种分布模型。数据集是每个网格中是否存在物种和环境变量。在 Virgili 等人的论文中。 (2018)，作者建议，“使用具有 Tweedie 分布和存在-不存在数据的 GAM，为罕见物种生成可靠的栖息地建模预测”。我尝试了以下代码：
模型 &lt;- gam(Occurrence ~ s(Depth) + s(Temperature), data=dt, family=tw(link=log), method=“REML”)
与二项分布模型相比，该模型具有较低的 AIC 和较高的解释偏差。 predict(Model, dt0, type=&quot;response&quot;)  的映射看起来很好。
但是，由于在 Tweedie 系列中不能选择 logit 链接函数，我可以将此预测输出称为“发生概率”吗？就像逻辑回归一样？]]></description>
      <guid>https://stats.stackexchange.com/questions/644858/can-gam-with-tweedie-distribution-be-used-for-a-binary-response</guid>
      <pubDate>Fri, 12 Apr 2024 08:49:49 GMT</pubDate>
    </item>
    <item>
      <title>数据缩减方法</title>
      <link>https://stats.stackexchange.com/questions/644857/methods-for-data-reduction</link>
      <description><![CDATA[主题：排放率计算中的数据缩减方法
亲爱的社区，
我在谷仓里进行了多次测量，以计算年排放率（例如氨、甲烷等）。这些测量是全年进行的。我正在寻找统计和数学上合理的方法来确定哪些天足以提供年排放率的代表性评估。
我已将具有固定和随机效应的混合线性模型应用于我的谷仓测量数据。然而，由于模型结果中存在科学上荒谬的相关性，我随后从数据集中计算了各个谷仓的温度加权平均值。将当前气温与该地点的长期每小时平均气温相比的相对频率作为权重因子。
猪舍的氨排放率取决于多种因素，包括温度、氮排泄量、氮排泄量中总氨氮 (TAN) 的比例、土壤污染程度、储存温度、空气流速、粪便中的 TAN 含量、粪便中的空气流速。畜舍和储藏室、脲酶活性、粪便pH值、占地面积、饲喂情况等均进行了测量。
哪些方法对于减少获取年排放平均值所需的测量天数或小时数是明智的？能否使用主成分分析（PCA）和聚类分析方法来选择或减少数据？在我的环境中应用这些方法时是否需要考虑具体步骤或注意事项？
对于有关此主题的任何建议或建议，我将非常感激。
提前谢谢您！
最好的问候]]></description>
      <guid>https://stats.stackexchange.com/questions/644857/methods-for-data-reduction</guid>
      <pubDate>Fri, 12 Apr 2024 08:37:56 GMT</pubDate>
    </item>
    <item>
      <title>我对字典学习的理解或者代码是错误的吗？</title>
      <link>https://stats.stackexchange.com/questions/644852/is-my-understanding-or-my-code-for-dictionary-learning-wrong</link>
      <description><![CDATA[所以我正在做一些休闲字典学习，我不确定我是否有正确的理解或者我的代码是否是错误的。目前，我采用 MNIST 数据集 $Y$，图像大小为 $28\times 28$ ，并尝试查找字典 $D$ 和稀疏代码 $X$，s.t. $Y \大约 DX$。在我的实验中，我采用 $Y\in \mathbb{R}^{28^2 \times 3}$，其中每一列都是手写的样本数字“5” （所以我不会将图像转换成补丁）。我初始化一个随机字典 $D\in\mathbb{R}^{28^2 \times 3}$，也就是说我总共有三个原子，即每个样品一个。对于我的稀疏代码 $X\in\mathbb{R}^{3\times 3}$，我将稀疏级别设置为 1，s.t。我在每一列中仅获得一个非零值。
现在，我希望字典算法能够“学习”只需将 $Y$ 的列放入 $D$ 中，并使稀疏代码接近到看起来像的东西
\begin{align}
X \approx \begin{pmatrix}
0 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{pmatrix},
\end{对齐}
或行的任何其他排列。这样， $D$ 中的一个原子只需乘以身份，我就可以恢复我的 $Y$&lt; 列/span&gt; 完全正确。但是，我获得的代码的输出
\begin{align}
X = \begin{pmatrix}
0 &amp; 5.58615414&amp; 6.33388578\\
0 &amp; 0 &amp; 0 \\
9.55769633&amp; 0 &amp; 1
\end{pmatrix}。
\end{对齐}
现在，由于第一行中有两个非零值，这意味着我可以几乎完全恢复 $y_1$ ，但不能恢复 $y_2, y_3$ 因为它们都混合了。
我的直觉错了吗？当我只取两个样本时，它按预期工作，即 $Y\in\mathbb{R}^{28^2 \times 2}$。
提前致谢！
我的代码：
导入 mnist
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
从 sklearn. Linear_model 导入 o​​rthogonal_mp

def approx_ksvd_dictionary_update(D: np.ndarray, X: np.ndarray, Y: np.ndarray) -&gt; np.ndarray：
    # 取自 https://github.com/fubel/sparselandtools/tree/master/sparselandtools
    n, K = D.形状
    对于范围 (K) 内的 k：
        wk = np.nonzero(X[k, :])[0]
        如果 len(wk) == 0:
            继续
        D[:, k] = 0
        g = np.transpose(X)[wk, k]
        d = np.matmul(Y[:, wk], g) - np.matmul(D, X[:, wk]).dot(g)
        d = d / np.linalg.norm(d)
        g = np.matmul(Y[:, wk].T, d) - np.transpose(np.matmul(D, X[:, wk])).dot(d)
        D[:, k] = d
        X[k, wk] = g.T
    返回D

# 选择仅代表数字5的MNIST数据
数据 = mnist.mnist()
图像 = 数据[0][数据[1] == 5]

np.随机.种子(1)

# 选择三张样本图片，放入Y的列中
N = 3
图片 = []
对于范围 (N) 内的 j：
    imgs.append(images[j].reshape(28*28, 1))
Y = np.concatenate(imgs, 轴=1)
Y /= np.max(Y)

# 用 K=N 个原子初始化随机字典
K=N
n = Y.形状[0]
D = np.zeros([n, K])
对于范围 (K) 内的 j：
    D[:, j] = np.random.randn(n)
    D[:, j] *= 1 / np.linalg.norm(D[:, j])

# 进行字典学习
n_nonzeros_coefs=1
对于范围（10）内的 _：
    X = orthogonal_mp(D, Y, n_nonzero_coefs=n_nonzeros_coefs)
    D = approx_ksvd_dictionary_update(D, X, Y)

打印（X）
]]></description>
      <guid>https://stats.stackexchange.com/questions/644852/is-my-understanding-or-my-code-for-dictionary-learning-wrong</guid>
      <pubDate>Fri, 12 Apr 2024 05:26:21 GMT</pubDate>
    </item>
    <item>
      <title>扩展隐马尔可夫模型 (HMM) 参数估计</title>
      <link>https://stats.stackexchange.com/questions/644843/extended-hidden-markov-models-hmm-parameter-estimation</link>
      <description><![CDATA[对于更简单的 HMM，我们可以使用 Viterbi 训练（而不是解码）或 Baum Welch 等算法来估计最能描述观察到的数据的参数。
当使用更复杂的多元 HMM 或二阶 HMM 时，我们如何做同样的事情？是否有资源可以用来查看在这些情况下如何调整算法和设置？如果有它们的伪代码而不是描述，那就更好了，尽管我知道早期的算法（例如向前和向后）也会改变。
编辑：
对于关闭这个问题的人来说，这不是你所说的编程/代码调试，而是关于统计和算法。]]></description>
      <guid>https://stats.stackexchange.com/questions/644843/extended-hidden-markov-models-hmm-parameter-estimation</guid>
      <pubDate>Fri, 12 Apr 2024 00:37:56 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中通过复制运行回归</title>
      <link>https://stats.stackexchange.com/questions/644854/how-to-run-regression-with-replication-in-r</link>
      <description><![CDATA[看看是否有人知道如何在 R 中运行带有复制的回归分析。我有一个数据集，每个 X 值都有多个 Y 值。我可以取 Y 值的平均值，但这会丢弃信息和统计分析将失去力量。我有一段参考文本描述了数学，当然我可以尝试手工完成，但是其中的乐趣在哪里？
我尝试寻找将这一点考虑在内的代码示例，但尚未提出任何建议。我想象它就在那里，但出于某种原因我找不到它。我确实知道我不是在寻找多元回归或具有多个回归量的回归。
示例数据：

&lt;标题&gt;

x
y


&lt;正文&gt;

15
5,2,5,6,1,3


30
2,4,7,1,4


40
1,6,8


45
5、4、9、10、2、9



对于我的应用程序，我有 45 个不同的 x 变量和 3 个关联的 y 数据点。我相信带有复制的回归应该是可能的，如果需要手动计算而不是在 R 中计算，那么这只是一个沉重的负担。
感谢您的宝贵时间。]]></description>
      <guid>https://stats.stackexchange.com/questions/644854/how-to-run-regression-with-replication-in-r</guid>
      <pubDate>Fri, 12 Apr 2024 00:01:55 GMT</pubDate>
    </item>
    <item>
      <title>我们如何摆脱 MLE 中的 $p(x|\theta)$</title>
      <link>https://stats.stackexchange.com/questions/644841/how-do-we-get-rid-of-px-theta-in-mle</link>
      <description><![CDATA[简单的问题...通常机器学习的介绍会告诉您以下内容：

您想要最大化$p(\theta|D)$
应用贝叶斯定理$p(\theta|D) \propto p(D|\theta)p(\theta)$
如果你考虑 $p(\theta)$ 常数，你会得到 MLE，如果你考虑它高斯，你会得到 L2 正则化等等

但是，我想更详细一点，这是我的问题：
$$
p(\theta|D) \propto p(D|\theta)p(\theta) = p(x,y|\theta)p(\theta) = p(y|x, \theta)p(x| θ)p(θ)
$$
现在，通常我们优化的实际上是 $p(y|x,\theta)p(\theta)$，所以我的问题是...下我们要删除哪个假设 $p(x|\theta)$？
我们是否认为 $x$ 独立于 $\theta$ 并且保持不变？.. .]]></description>
      <guid>https://stats.stackexchange.com/questions/644841/how-do-we-get-rid-of-px-theta-in-mle</guid>
      <pubDate>Thu, 11 Apr 2024 22:11:00 GMT</pubDate>
    </item>
    </channel>
</rss>