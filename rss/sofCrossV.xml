<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 17 Dec 2024 15:19:22 GMT</lastBuildDate>
    <item>
      <title>逆指数分布的双变量数据生成</title>
      <link>https://stats.stackexchange.com/questions/658879/bivariate-data-generation-of-inverse-exponential-distribution</link>
      <description><![CDATA[对于以下双变量逆指数分布，我必须从随机向量创建数据：$$ F_{X,Y}(x,y) =\exp({-x^{-1}-y^{-1}-\theta {(xy)}^{-1}}),0\leq\theta\leq 1, x,y&gt;0,$$。我知道如何使用均匀随机变量（我使用的是 $\texttt{R}$）从单变量创建和转换数据，但我不知道如何对随机向量执行相同操作。您有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658879/bivariate-data-generation-of-inverse-exponential-distribution</guid>
      <pubDate>Tue, 17 Dec 2024 14:10:42 GMT</pubDate>
    </item>
    <item>
      <title>将整数矩阵的行和分布得接近泊松分布，并对列总数和非零计数进行约束</title>
      <link>https://stats.stackexchange.com/questions/658878/distributing-row-sums-of-an-integer-matrix-to-be-close-to-poisson-with-constrain</link>
      <description><![CDATA[我遇到一种情况，我需要构建一个 $M$ x $N$ 矩阵，称为 $H$，表示 $M$ 个对象，这些对象可能具有 $N$ 个不同的修饰符，所有这些修饰符都可以应用于正整数数量。我知道每个修饰符都有一个指定的列总数，即 $\sum^{i\in 1:M} H_{i,j} = T_j, j\in 1:N$。还有一个二进制矩阵 $D_{i,j} \in \{1,0\}$ 表示受 $j$ 第个修饰符影响的对象，即我们知道 $H$ 中 $S_j$ 个条目的数量将非零。必然地，我们建立$S_j \leq T_j \forall j\in 1:N$，因为每个对象必须至少有一个修饰量，由$D$表示，并且该列的其余值必须为零。
我希望这个矩阵的行和大致服从泊松分布，但由于这些限制，我觉得不可能保证这是可以实现的。因此，或者，我希望有一种有效的算法能够尽可能接近地分配修饰符，使得​​从行总和的角度来看，应用的总修饰符数量大致呈指数衰减。
我相信，如果没有 $D$ 矩阵部分来限制每个修饰符的具体对象数量，那么使用每列上的多项分布（使用可选的狄利克雷先验来集中/使分布均匀）应该很容易实现这一点。有人有什么想法可以轻松实现这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658878/distributing-row-sums-of-an-integer-matrix-to-be-close-to-poisson-with-constrain</guid>
      <pubDate>Tue, 17 Dec 2024 14:09:41 GMT</pubDate>
    </item>
    <item>
      <title>计算 k 模式的 SSB（簇间平方和）</title>
      <link>https://stats.stackexchange.com/questions/658877/computing-calculating-ssb-sum-of-squares-between-clusters-for-k-modes</link>
      <description><![CDATA[我正在尝试计算用于验证/计算 K 模式性能的指标。我正在做论文，需要根据二元变量（疾病）对患者进行分组，我最近读到 SSW 和 SSB 指标可能合适（https://math.stackexchange.com/questions/1009297/variances-for-k-means-clustering）
我只知道如何从 kmodes 函数中提取 SSW（此处回复了 K-Modes Cluster Validation），但我不知道如何计算 SSB（簇之间）...您能给出一个如何计算它的例子吗？
有人在这里回复了，但对于 K-Means：SSB - Sum of簇之间的平方
我可以使用 Calinski–Harabasz 指数，如果无法为 K 模式计算它的话]]></description>
      <guid>https://stats.stackexchange.com/questions/658877/computing-calculating-ssb-sum-of-squares-between-clusters-for-k-modes</guid>
      <pubDate>Tue, 17 Dec 2024 13:41:53 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 R 中一个变量的 mc fadden's rsquared？</title>
      <link>https://stats.stackexchange.com/questions/658874/how-to-calculate-mc-faddens-rsquared-for-just-one-variable-in-r</link>
      <description><![CDATA[对于我的逻辑回归，我使用 Mc Fadden 的 R 平方（类似于 R 平方，但用于逻辑模型）。但是，Mc Faddens R 平方计算的是整体模型的效果，而我想知道模型中单个变量的效果。我已经设法计算了线性回归模型中单个变量的偏 R 平方（使用包：sensemakr），但我不知道如何使用 Mc Faddens R 平方进行逻辑回归。有人有什么想法吗？（我在 Rstudio 工作）]]></description>
      <guid>https://stats.stackexchange.com/questions/658874/how-to-calculate-mc-faddens-rsquared-for-just-one-variable-in-r</guid>
      <pubDate>Tue, 17 Dec 2024 12:40:35 GMT</pubDate>
    </item>
    <item>
      <title>针对群体数据/种族数据的最自然机器学习模型类</title>
      <link>https://stats.stackexchange.com/questions/658871/most-natural-class-of-machine-learning-models-for-group-data-race-data</link>
      <description><![CDATA[我有一个学生考试成绩的数据集，如下所示：
班级 ID 班级大小 学生编号 智商 小时数 分数 前几名
1 3 3 101 10 98 1
1 3 4 99 19 80 0
1 3 6 130 3 95 0
2 5 4 93 5 50 0
2 5 5 103 9 88 0
2 5 8 112 12 99 0
2 5 1 200 10 100 1
2 5 2 90 19 78 0
3 2 5 100 12 84 0
3 2 7 102 13 88 1

我想建立一个机器学习模型，试图预测谁将成为前几名对于任何给定的 Class_ID，使用 IQ 和 Hours（学习小时数）作为特征，计算班级（即具有最高 Score 的学生）的得分。
换句话说，输入是班级中每个学生（例如 1 到 n）的 IQ 和 Hours，输出是概率向量 (p_1, ..., p_n)，其中每个 p_i 是学生 i 在班级中得分最高的概率。
这是我尝试过的：

最简单的方法是对 Score 使用回归，然后确定谁将在班级中取得最高分数。这种方法的问题在于，它不会产生谁最有可能在任何给定类别中获得最高分数的概率。

由于这是一个排名问题，因此自然的学习模型类别是使用 XGBoost 中的 XGBRanker 或 lightgbm 中的 LGBMRanker。不幸的是，输出是 相关性分数 列表，而不是概率列表，概率列表在概率方面没有自然解释。


解决这个问题的一个明显方法是在 xgboost 中的相关性分数上应用 softmax，但没有直接有意义的概率解释，如基于能量的模型（如 RBM 的能量函数）。事实上，我曾尝试过这样做，但概率变得非常极端（大多数概率集中在每个班级的一名学生身上，导致测试结果不佳且方差较大）

另一类学习模型是Top上的分类模型，如逻辑回归/决策树。但是，这种方法有两个主要问题。

首先，将每个学生视为训练样本不是一个好方法，因为例如，同一个班级可能有两个非常聪明（高智商）和勤奋（高小时数）的学生，如果很多班级都有很多这样的学生，那么传统的模型（如基于逻辑/树的模型）可能会难以进行训练。
为了解决上述将单个学生视为训练样本的问题，我们可以将每个班级视为一个训练样本。为此，我们“扁平化”我们的数据集并对 Top 进行多类分类：
Class_ID Class_size IQ_1 IQ_2 IQ_3 IQ_4 IQ_5 Hours_1 Hours_2 Hours_3 Hours_4 Hours_5 Score_1 Score_2 Score_3 Score_4 Score_5 Top
1 3 101 99 130 NaN NaN 10 19 3 NaN NaN 98 80 95 NaN NaN 3 
2 5 93 103 112 200 90 5 9 12 10 19 50 88 99 100 78 1
3 2 100 102 NaN NaN NaN 12 13 NaN NaN NaN 84 88 NaN NaN NaN 7

这种方法的问题在于，数字每个班级的学生人数不同，因此特征矩阵变得非常稀疏（因为不同班级的学生人数可能非常不同）
因此，逻辑模型/普通前馈神经网络/基于树的模型似乎也不适用于这类群体数据。
所以我的问题是，是否有任何自然的机器学习模型可以处理这些“群体数据”，就像我上面的数据集一样？
此外，在这个问题中，我只关心最终名列前茅的人（或者可能是前三名），所以排名并不是那么重要（例如，知道学生 4 排名第 11 位，学生 8 排名第 12 位并不重要）
提前非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658871/most-natural-class-of-machine-learning-models-for-group-data-race-data</guid>
      <pubDate>Tue, 17 Dec 2024 11:40:53 GMT</pubDate>
    </item>
    <item>
      <title>参数复发事件分析中的马丁格尔和偏差残差？</title>
      <link>https://stats.stackexchange.com/questions/658870/martingale-and-deviance-residuals-in-parametric-recurrent-event-analysis</link>
      <description><![CDATA[我正在开发一个描述重复事件过程的参数化事件发生时间模型。我不确定我对如何计算这种情况下 Martingale 和 Deviance 残差的理解是否正确，并希望有人能就此事提供指导。来自 Therneau 等人。 (1990)，在我的例子中，马丁格尔残差如下：
$$
\hat{M}_i(t) = N_i(t) - \int_{0}^{t} Y_i(s)d\hat{\Lambda_i}(s),
$$
由于对于每个时间 t，$E[\hat{M}_i(t)] = E[\hat{M}_i(t-1)] = 0$，计算每个事件/审查时间的 $\hat{M}_i(t)$ 是否合适，以便可以根据所有记录的事件时间来评估模型准确性？如果是，那么“最佳”方法是什么？计算 $\hat{M}_i(t)$ 的方法如下：

基于从 $[t-1, t]$ 开始的区间？
或者基于从 $[0,t]$ 开始的区间？

其中 t-1 和 t 分别是上一个事件时间以及当前事件时间。或者这取决于我们试图用模型回答的问题（即，如果准确预测事件 n-1 和 n 之间的时间很重要，则选择 $[t-1,t]$）？
那么对于偏差残差，Therneau 等人（1990） 将这些结果呈现为 Cox 模型，如下所示：
$$
d_i = \operatorname{sgn}(\hat{M}_i) \left[ -2\{ \hat{M}_i + \delta_i \log (\delta_i - \hat{M}_i)\} \right]^{\​​frac{1}{2}}
$$
有没有办法将这些结果转换为“纵向”设置（即针对每个记录时间，而不是基于 $\hat{M}_i$，后者是针对每个个体 i 在整个随访期间计算得出的）？并且，与此相关的是，在重复事件的情况下，计算$d_i$以及$\hat{M}_i$能带来很多好处吗？鉴于$d_i$是为了实现更正态的残差分布而开发的，这对于重复事件来说似乎不是什么大问题，因为$\hat{M}_i$可能取值的范围（在我的案例中理论上为$[-\infty,\infty]$）。
为我的问题提供一些背景信息：本文介绍了我研究领域的偏差残差，建议使用$\hat{M}_i(t)$基于从$[t-1, t]$，并且仅适用于观察到的事件时间。我不确定这是否合适，因为我们使用这种方法丢弃了数据的审查部分。这也是我能找到的唯一一个在每个个体中多次得出$\hat{M}_i$的例子，因为其他研究，如这个和这个，只基于$[0, t_{max}]$区间计算$\hat{M}_i$和$d_i$。]]></description>
      <guid>https://stats.stackexchange.com/questions/658870/martingale-and-deviance-residuals-in-parametric-recurrent-event-analysis</guid>
      <pubDate>Tue, 17 Dec 2024 11:24:19 GMT</pubDate>
    </item>
    <item>
      <title>双变量经验估计</title>
      <link>https://stats.stackexchange.com/questions/658868/bivariate-empirical-estimation</link>
      <description><![CDATA[我想使用经验估计来估计 $\int_0^{sup A}\int_0^{\sup B} F^2(x,y)dydx,$，其中 $F$ 是 CDF，$A$ 是随机变量 $X$ 的支持集，$B$ 是随机变量 $Y$ 的支持集。对于 i.i.d，$F(x,y)$ 的经验估计。随机样本 $\{X_i,Y_i\},i=1,2,...,n$ 由 $\frac{1}{n}\sum_{I=1}^n I(X_i\leq x,Y_i\leq y)$ 给出，其中 $I$ 是指示函数。如何使用 R 编程或 Python 估计此函数。如果代码无法提供，请简要说明方法。提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658868/bivariate-empirical-estimation</guid>
      <pubDate>Tue, 17 Dec 2024 11:10:11 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost - 具有 `colsamle_bytree` <1 的树所见列的顺序</title>
      <link>https://stats.stackexchange.com/questions/658867/xgboost-order-of-columns-seen-by-a-tree-with-colsamle-bytree1</link>
      <description><![CDATA[我的理解是，如果两个或更多列在拆分时提供相同的增益，XGBoost 会选择第一列。
为了确保 XGBoost 有机会查看并包含所有相关列，我认为我可以简单地传递 colsample_bytree=0.99。但是，为了使其工作，采样返回的列必须按随机顺序排列。这种方法是否正确，还是我应该在某种交叉验证方案中对列进行打乱？]]></description>
      <guid>https://stats.stackexchange.com/questions/658867/xgboost-order-of-columns-seen-by-a-tree-with-colsamle-bytree1</guid>
      <pubDate>Tue, 17 Dec 2024 11:02:34 GMT</pubDate>
    </item>
    <item>
      <title>（在线）多重测试，预期 H1 比例非常低（发现很少）</title>
      <link>https://stats.stackexchange.com/questions/658866/online-multiple-testing-with-very-low-expected-h1-proportion-very-few-discove</link>
      <description><![CDATA[似乎大多数（在线）FDR 测试几乎完全丧失了其效力，因为非零假设比例趋于 0。在这些情况下，控制 FDR 是否有意义？有什么解决办法吗？我熟悉权重衰减，但在某种程度上，它只是一种变通方法，允许该方法为了获得更高的统计效力而提高 FDR。]]></description>
      <guid>https://stats.stackexchange.com/questions/658866/online-multiple-testing-with-very-low-expected-h1-proportion-very-few-discove</guid>
      <pubDate>Tue, 17 Dec 2024 11:02:16 GMT</pubDate>
    </item>
    <item>
      <title>具有交互作用的泊松回归的边际效应</title>
      <link>https://stats.stackexchange.com/questions/658861/marginal-effect-of-poisson-regression-with-interaction</link>
      <description><![CDATA[我很难理解 R 中带有泊松回归的 {marginaleffects} 包的结果。
如果我这样做：
library(marginaleffects)
mod &lt;- lm(mpg ~ hp * as.factor(gear), data = mtcars)
summary(mod)

我得到：
系数：估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 25.307903 2.650811 9.547 5.51e-10 ***
hp -0.052240 0.014560 -3.588 0.001356 ** 
as.factor(gear)4 15.262616 3.862728 3.951 0.000531 ***
as.factor(gear)5 7.469550 3.805534 1.963 0.060451 . 
hp:as.factor(gear)4 -0.126946 0.033574 -3.781 0.000825 ***
hp:as.factor(gear)5 -0.006029 0.019276 -0.313 0.756952 

and avg_comparisons(mod, variable = &quot;hp&quot;, by = c(&quot;gear&quot;)) 返回
 术语 gear 估计 Std.误差 z Pr(&gt;|z|) S 2.5 % 97.5 %
hp 3 -0.0522 0.0146 -3.59 &lt;0.001 11.6 -0.0808 -0.0237
hp 4 -0.1792 0.0303 -5.92 &lt;0.001 28.2 -0.2385 -0.1199
hp 5 -0.0583 0.0126 -4.61 &lt;0.001 17.9 -0.0830 -0.0335

其中第一行返回在模型摘要中找到的估计值 -0.0522，因为我有相同的参考。这对我来说很有意义。
我不明白的是泊松分布会发生什么：
mod &lt;- glm(cyl ~ hp * as.factor(gear), data = tmp, family =toxic())
summary(mod)

系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 1.5599308 0.3891456 4.009 6.11e-05 ***
hp 0.0025199 0.0020809 1.211 0.226 
as.factor(gear)4 -0.6005544 0.6561946 -0.915 0.360 
as.factor(gear)5 -0.4006457 0.6104003 -0.656 0.512 
hp:as.factor(gear)4 0.0038348 0.0058576 0.655 0.513 
hp:as.factor(gear)5 0.0005107 0.0028537 0.179 0.858 

我原本希望 avg_comparisons 返回 0.0025199，然后计算不同齿轮值的不同值，但是：
avg_comparisons(mod, variable = &quot;hp&quot;, by = c(&quot;gear&quot;))

术语 gear 估计 Std.误差 z Pr(&gt;|z|) S 2.5 % 97.5 %
hp 3 0.0188 0.0157 1.20 0.230 2.1 -0.01189 0.0496
hp 4 0.0297 0.0260 1.14 0.253 2.0 -0.02125 0.0807
hp 5 0.0182 0.0122 1.49 0.136 2.9 -0.00573 0.0421

这里，第一行估计是 0.0188，而不是 0.0025199，我不明白为什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/658861/marginal-effect-of-poisson-regression-with-interaction</guid>
      <pubDate>Tue, 17 Dec 2024 09:37:39 GMT</pubDate>
    </item>
    <item>
      <title>控制多重比较</title>
      <link>https://stats.stackexchange.com/questions/658859/control-for-multiple-comparisons</link>
      <description><![CDATA[我想选择一组特定于学生和性别的单词。因此，我让参与者根据学生喜欢程度和女性喜欢程度对单词进行评分。每个单词都是成对的（一个特定单词和一个控制单词；例如，女性和编织）。对于每个单词，我都有 2 个评分（学生喜欢和性别喜欢），每对有 4 个评分。我总共有 100 对，其中一半有特定性别的单词，一半​​有特定的学生单词。
我知道想要测试特定单词是否特定于其自己的类别，而不是其他类别（例如，比较所有对的评分）。我已经运行了 LME 和 Anova，并得到了预期的效果，即学生单词在学生属性上被评为更高。但是，我想选择评分最高的 30 个特定单词及其配对词，但要确保它们只针对自己的类别（女性应该针对性别类别，但在学生气和女性气方面评分明显低于编织词。此外，编织词和女性应该同样像学生，因为它们应该在不感兴趣的类别中作为对照）。我显然可以运行多个配对 t 检验。你会怎么做？
最好！]]></description>
      <guid>https://stats.stackexchange.com/questions/658859/control-for-multiple-comparisons</guid>
      <pubDate>Tue, 17 Dec 2024 08:39:11 GMT</pubDate>
    </item>
    <item>
      <title>使用 Shiny 在 R 中实现不准确的 KNN</title>
      <link>https://stats.stackexchange.com/questions/658862/innacurate-knn-implementation-in-r-using-shiny</link>
      <description><![CDATA[这个简单而又炫酷的应用程序让您上传一张图片，然后通过 knn 算法（使用 mnist 数据集训练）进行分析并评估图片包含的数字。假设您上传的图片为 .jpg 格式且尺寸为 28x28，则该网站可以正常运行。没有出现任何错误。
if(!require(class)) {
install.packages(&quot;class&quot;)
}
if(!require(dslabs)) {
install.packages(&quot;dslabs&quot;)
}
if(!require(shiny)) {
install.packages(&quot;shiny&quot;)
}

library(class)
library(dslabs)
library(shiny)

m &lt;- read_mnist()

ui &lt;- fluidPage(
titlePanel(
&quot;第一个 AI 实现：猜测图像上的数字&quot;
),
sidebarLayout(
sidebarPanel = sidebarPanel(
wellPanel(
fileInput(
inputId = &quot;file&quot;,
label = &quot;选择一个类似数字的图像：&quot;,
accept = c(&quot;image/jpg&quot;, &quot;image/jpeg&quot;)
),
actionButton(
inputId = &quot;预测&quot;,
label = &quot;猜猜看！&quot;
)
)
),
mainPanel = mainPanel(
tags$h3(&quot;已加载图像：&quot;),
uiOutput(&quot;image_ui&quot;),
tags$h3(&quot;预测：&quot;),
textOutput(
outputId = &quot;预测&quot;
)
)
)
)

服务器 &lt;- 函数（输入、输出、会话）{
观察事件（输入$预测，{
图像数据 &lt;- 反应式（{
请求（输入$文件）
图片 &lt;- jpeg::readJPEG（输入$文件$数据路径）
图片 &lt;- as.vector（t（trunc（img[, , 1] * 255)))
打印（m$train$images[1, ])
打印（img）
返回（img）
})

预测 &lt;- 事件反应式（输入$预测，{
请求（图像数据（）
用户图像 &lt;- 图像数据（）
预处理 &lt;- knn（训练 = m$train$images, 用户图像, m$train$labels, k = 3)
返回（as.numeric（pred））
})

输出$image_ui &lt;- renderUI({
req(input$file)
tags$img(
src = base64enc::dataURI(
file = input$file$datapath, 
mime = input$file$type
),
width = &quot;280px&quot;,
height = &quot;280px&quot;
)
})

output$prediction &lt;- renderText({
req(prediction())
paste(&quot;图像代表以下数字：&quot;, prediction())
})
})
}

shinyApp(ui, server)


但是输出一点都不准确。我应该改变k的值吗？图像格式化数据的处理是否正确？knn​​算法是否不适合这项任务？还有其他可能存在冲突的问题吗？
我尝试上传一些使用 Paint 生成的 28x28 的黑色背景和白色前景图像。预测几乎混淆了每个数字。以下是执行示例（图片在应用程序中调整大小，原始大小正确）：

这是我尝试过的一些图片。
第 1 个：

第 6 个：

第 7 条：
]]></description>
      <guid>https://stats.stackexchange.com/questions/658862/innacurate-knn-implementation-in-r-using-shiny</guid>
      <pubDate>Tue, 17 Dec 2024 08:02:28 GMT</pubDate>
    </item>
    <item>
      <title>如何从混合模型中获取总体方差？</title>
      <link>https://stats.stackexchange.com/questions/658855/how-can-i-get-the-population-variance-from-a-mixed-model</link>
      <description><![CDATA[我以为这是一个基本问题，但我被它难住了，找不到解决方案。
我有一个数据库，其中包含不同养猪生产阶段（类别）的粪浆干物质含量，并且由不同的操作员（OP）在不同时刻（季节）采集样本。我只是对估计每个类别的平均值和方差总体感兴趣。
为了解决这个问题，我建立了一个线性混合模型，其中对因变量进行了平方变换。在测试了它们的重要性（AIC、BIC）后，我将 OP 纳入随机效应，将 CATEGORY 和 SEASON 纳入固定效应。
fit &lt;- nlme::lme(sqrt(MS) ~ CATEGORY + SEASON, 
random= ~ 1|OP, data=dat)

据我了解，每个 CATEGORY 中的估计平均值是每个固定效应值对应的 LSM。但是我不太清楚如何估计每个类别的方差。简化一下，我读到过，在一般线性回归中，模型的均方误差用于估计总体的方差，但在混合模型中，对于一些分组变量，我找不到任何关于如何计算它的解释。
每个固定效应的标准误差是否等同于 MSE？
summary(fit)

固定效应：sqrt(MS) ~ CATEGORY + SEASON 
值 标准误差 DF t 值 p 值
（截距） 2.0142552 0.1127073 197 17.871557 0.0000
CATEGORYpiglets -0.2367893 0.1400533 197 -1.690708 0.0925
CATEGORYsows -0.8191891 0.1195440 197 -6.852615 0.0000
SEASONspring -0.0280369 0.02811633 194 -0.997177 0.3199
SEASONsummer -0.0126275 0.03969934 194 -0.318078 0.7508
SEASONoutom -0.0884407 0.02879816 194 -3.071054 0.0024

我的最终目标是估算覆盖 75% 人口的干物质含量值。您能帮我解决这个疑问吗？如果它有用，我正在使用 R 中的 nlme 包。]]></description>
      <guid>https://stats.stackexchange.com/questions/658855/how-can-i-get-the-population-variance-from-a-mixed-model</guid>
      <pubDate>Tue, 17 Dec 2024 06:54:51 GMT</pubDate>
    </item>
    <item>
      <title>如何找到跨多天的时间序列中变量之间的相关性？</title>
      <link>https://stats.stackexchange.com/questions/658852/how-do-i-find-correlation-between-variables-in-a-time-series-across-multiple-day</link>
      <description><![CDATA[我有每天的数据，包括日期/时间、事件以及触发次要事件的时间。
日期 | 时间 | 事件 | 触发次要事件
2019 年 9 月 9 日 | 上午 12:00 | A | 否
2019 年 9 月 9 日 | 上午 12:30 | A | 否
2019 年 9 月 9 日 | 上午 01:00 | | 否
2019 年 9 月 9 日 | 上午 01:30 | B | 否
...
2019 年 9 月 9 日 | 下午 03:00 | E | 否
2019 年 9 月 9 日 | 下午 03:30 | | 否
2019 年 9 月 9 日 | 下午 04:00 | | 是
2019 年 9 月 9 日 | 晚上 11:30 | C |是
2019 年 9 月 10 日 | 上午 12:00 | D | 否
2019 年 9 月 10 日 | 上午 12:30 | D | 否
...

每一天都是完全相互隔离的，我确信一天内没有任何事情会导致另一天触发次要事件 - 因此我们可以假设存在的任何相关性都是在一天内隔离的。
鉴于这些数据有多个“块”，每个月的每一天一个，持续数月 - 可以进行哪种分析才能更好地了解哪些事件更可能与触发次要事件有关？
我首先查看了时间序列的互相关，使用正常相关性，但将最后一列的数据移动 X 时间量，以查看哪个时间滞后量可以获得最佳相关性。
但让我困惑的是我发布这篇文章的原因是因为我的时间序列并不完全连续。它们是离散的时间序列数据块。所以在这种情况下我不确定该怎么做。]]></description>
      <guid>https://stats.stackexchange.com/questions/658852/how-do-i-find-correlation-between-variables-in-a-time-series-across-multiple-day</guid>
      <pubDate>Tue, 17 Dec 2024 03:23:25 GMT</pubDate>
    </item>
    <item>
      <title>适合还是不适合：在模型与平均值之间进行选择</title>
      <link>https://stats.stackexchange.com/questions/658851/to-fit-or-not-to-fit-choosing-between-a-model-vs-the-average</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658851/to-fit-or-not-to-fit-choosing-between-a-model-vs-the-average</guid>
      <pubDate>Tue, 17 Dec 2024 02:43:46 GMT</pubDate>
    </item>
    </channel>
</rss>