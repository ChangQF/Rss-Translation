<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 07 Jan 2025 12:33:30 GMT</lastBuildDate>
    <item>
      <title>非对称独立变量的排序</title>
      <link>https://stats.stackexchange.com/questions/659660/ranks-for-an-asymmetric-independent-variable</link>
      <description><![CDATA[我正在使用回归模型分析数据，其中感兴趣的变量是一种治疗方法，我想估计其效果。我打算调整一组协变量的估计值，包括两个生物标志物。这些生物标志物的分布高度偏斜（大多数个体的值介于 0 和 1 之间，少数个体的值超过 10,000）。最初，我考虑将生物标志物值分为 4 组，这是一种常见的方法。后来，我考虑使用等级，因为与分类相比，这可能会减少丢失的信息量。虽然这会降低参数的可解释性（使用类别更清晰，但使用等级则不那么清晰），但我的主要目标是进行调整，以便更好地估计感兴趣的变量的效果。
您觉得如何？这种方法能带来优势吗？您知道任何描述这种方法的资源吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659660/ranks-for-an-asymmetric-independent-variable</guid>
      <pubDate>Tue, 07 Jan 2025 11:54:44 GMT</pubDate>
    </item>
    <item>
      <title>回归反应的统计比较</title>
      <link>https://stats.stackexchange.com/questions/659658/statistical-comparison-of-regressed-responses</link>
      <description><![CDATA[我记录了 5000 个事件。每个事件属于 50 个细胞 (C) 中的一个，并且相对于其基线幅度 (X) 具有相应的响应幅度 (Y)。每个细胞还属于 3 个组 (T) 中的一个。我想测试在考虑基线后，每个组的响应幅度是否显著不同。我该怎么做？我原本想从 Y ~ 1 + X + (1|C) 中收集每组细胞的随机效应估计值，但这似乎是一种非正统方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/659658/statistical-comparison-of-regressed-responses</guid>
      <pubDate>Tue, 07 Jan 2025 10:51:35 GMT</pubDate>
    </item>
    <item>
      <title>对 DiD 设计中均值中位数估计量的洞察</title>
      <link>https://stats.stackexchange.com/questions/659655/insights-into-median-of-means-estimators-in-did-designs</link>
      <description><![CDATA[我目前正在开展一个研究项目，重点研究双差分 (DiD) 设计中的稳健估计量，特别是在经典的两期两组设置中。我的主要兴趣是对 y 方向异常值的稳健性（我污染了误差项），并且我一直在探索均值中位数 (MoM) 估计量作为标准 DiD 治疗效果估计量（基于均值）的潜在替代方案。
但是，我遇到了几个问题：

缺乏文献：我找不到任何先前的研究或 DiD 环境中均值中位数估计量的应用。有人知道是否存在这样的研​​究或我可以在哪里找到吗？
意外结果：当我模拟和实施 MoM 估计量时，我得到的结果与标准 DiD 估计量相同 - 即使包含受污染的数据点也是如此。这让我开始质疑为什么 MoM 估计量在这种设置下不是更稳健。

有人能解释为什么中位数估计量在这种情况下可能无法按预期执行吗？或者 DiD 框架中是否存在一些基本因素，使得 MoM 方法不太合适？
我非常感谢任何想法、文献建议，甚至直观的解释！
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/659655/insights-into-median-of-means-estimators-in-did-designs</guid>
      <pubDate>Tue, 07 Jan 2025 10:05:08 GMT</pubDate>
    </item>
    <item>
      <title>如何理解概率中的句子结构</title>
      <link>https://stats.stackexchange.com/questions/659651/how-to-understand-structure-of-sentences-in-probability</link>
      <description><![CDATA[在我的教科书中，它说
（I）随机选择的高中生吃早餐
（II）随机选择的青少年是吃早餐的高中生
（III）随机选择的吃早餐的青少年是高中生
我应该为上述概率选择正确的大小顺序。
书中说（I）的概率是$P(I)=P(早餐 | 高级)$
（II）是$P(II)=P(breakfast \cap 高级)$
（III）是$P(III)=P(高级 | 早餐)$
那么我的问题是，例如在（II）中，为什么不是$P(II)=P(早餐 |高级）$？
因为我觉得如果你把（III）写成条件概率，你也应该把（II）写成条件概率。
我这里漏掉了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659651/how-to-understand-structure-of-sentences-in-probability</guid>
      <pubDate>Tue, 07 Jan 2025 08:58:39 GMT</pubDate>
    </item>
    <item>
      <title>这里的 95% 置信区间是多少？我的答案正确吗？</title>
      <link>https://stats.stackexchange.com/questions/659650/what-is-the-95-confidence-interval-here-is-my-answer-correct</link>
      <description><![CDATA[我正在处理这个问题：

这个问题要求找出两个城市超速罚单金额差异的 95% 置信区间；换句话说，mu(Orange) - mu(DeLand)。我得到的区间在 31.2103907 和 39.5396093 之间。这是正确的吗？如果不是，正确答案是什么？
我使用了以下公式：
]]></description>
      <guid>https://stats.stackexchange.com/questions/659650/what-is-the-95-confidence-interval-here-is-my-answer-correct</guid>
      <pubDate>Tue, 07 Jan 2025 08:38:28 GMT</pubDate>
    </item>
    <item>
      <title>关于具有单位根的 AR(1) 过程的方差</title>
      <link>https://stats.stackexchange.com/questions/659648/about-the-variance-of-ar1-processes-with-unit-root</link>
      <description><![CDATA[我目前正在研究 ARIMA 过程，AR 过程在其中起着重要作用。让我们考虑以下形式的 AR(1) 过程：
$$X_t = X_{t-1} + Z_t$$
这也称为随机游走。这里 $t$ 的索引集是 $\mathbb{Z}$，而 $Z_t$ 是一个白噪声过程。
我想证明，这个过程的方差确实依赖于 $t$，因此它不是弱平稳的。
我发现了很多关于这个主题的问题，通常的“证明”是这样写的：
$$X_t = X_0 + \sum_{i=1}^t Z_i$$
现在论证：
$$Var[X_t] = Var[X_0] + \sum_{i=1}^t Var[Z_i]$$
显然取决于 $t$。
但是，我认为这个证明并不正确，或者至少总体上不正确，因为上面的陈述假设 $X_0$ 和总和不相关，这一点根本不明显。
有谁知道在不假设 $X_0$ 和 $\sum_{i=1}^t Z_i$ 不相关的情况下证明这个陈述的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659648/about-the-variance-of-ar1-processes-with-unit-root</guid>
      <pubDate>Tue, 07 Jan 2025 07:06:53 GMT</pubDate>
    </item>
    <item>
      <title>在 GLMM 中使用 k 均值空间聚类作为随机效应是否正确？</title>
      <link>https://stats.stackexchange.com/questions/659646/is-it-correct-to-use-spatial-clusters-by-k-means-as-random-effect-in-glmm</link>
      <description><![CDATA[我是统计学新手，我会尽力解释我的问题。
我正在攻读学位，研究大象袭击的驱动因素。对于响应变量，我有袭击的位置（坐标），并尝试使用一组独立变量进行预测。我使用 R 中“lme4”包中实现的逻辑回归模型，将系列设置为二项式。
我想解释任何方差以及与袭击地理位置相关的可能自相关。我正在考虑使用 k-最近邻生成坐标聚类，并将这些聚类作为随机效应拟合到我的模型中以解释这些。模型结果表明，这种方法确实解释了一些方差并增加了模型的 R2。
我没有找到使用相同方法的研究，我想知道这种方法在统计上是否正确。我只是担心随机变量的力量会被固定效应“窃取”。
根据我与教授的讨论，出于一个非常具体的原因，我不打算使用“glmmTMB”或“mgcv”等空间模型。
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659646/is-it-correct-to-use-spatial-clusters-by-k-means-as-random-effect-in-glmm</guid>
      <pubDate>Tue, 07 Jan 2025 06:02:00 GMT</pubDate>
    </item>
    <item>
      <title>何时使用哪种样本方差公式？</title>
      <link>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</link>
      <description><![CDATA[我知道样本方差的公式为
$$s^2 = \frac{\sum (x_i - \bar{x})^2}{n - 1}$$
我还知道样本方差的公式为“均值平方减均值平方”。
在计算给定样本的样本方差时，我使用了这两个公式，但发现它们给出了两个不同的答案，因此我想问，什么时候该使用第一个公式，什么时候该使用第二个公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</guid>
      <pubDate>Tue, 07 Jan 2025 05:32:19 GMT</pubDate>
    </item>
    <item>
      <title>如何根据前几年的数据最好地预测非线性时间序列末尾的值</title>
      <link>https://stats.stackexchange.com/questions/659635/how-best-to-forecast-the-value-at-the-end-of-a-non-linear-time-series-based-on-p</link>
      <description><![CDATA[我有前几个财年的每周支出数据，我想用它（以及本财年迄今为止的支出数据）预测本财年末的总支出。我并不关心在最后一周之前预测每周支出，但它可能对质量保证有用。
每个周期的支出都遵循大致相似的模式，在周期开始时更多，在结束时更少（类似于 y = x^0.5），因此使用过去几年应该有助于了解本年度剩余时间的支出进展情况。此外，我想预测不同预算的支出以及总体支出。
我一直在做一些研究，这似乎表明非线性混合效应模型将是最好的方法，使用不同的财年作为重复测量。但是，我对此不是很熟悉，并且想在开始之前检查这是否是一种好的方法（特别是因为我想在拟合模型时优先考虑最终支出，但我不确定这是否会这样做） - 此外，如果有任何关于如何最好地进行的指南（特别是如何使用 R 拟合模型），它将非常有用。]]></description>
      <guid>https://stats.stackexchange.com/questions/659635/how-best-to-forecast-the-value-at-the-end-of-a-non-linear-time-series-based-on-p</guid>
      <pubDate>Tue, 07 Jan 2025 01:55:43 GMT</pubDate>
    </item>
    <item>
      <title>条件变量的影响是否独立？</title>
      <link>https://stats.stackexchange.com/questions/659629/independence-of-conditioning-variables-effects</link>
      <description><![CDATA[通常，我们将独立性称为$f(A,B) = f(A)f(B)$，或将条件独立性称为$f(A,B|X) = f(A|X)f(B|X)$。
但是，我想知道您会如何称呼这样的事物：
$$
f(Y|A,B) = f(Y|A)f(Y|B)
$$
也就是说，给定 A 和 B，Y 发生的概率与您分别给定 A 和 B 计算 Y 发生的概率相同。换​​句话说，A 和 B 不是关于 Y 的联合信息，而是提供“唯一”的信息有关 Y 的信息。
例如，在预测的背景下，上述方程将表明 A 和 B 提供对 Y 的独立预测。[当然，如果它不成立，那么 $f(Y|A,B) \neq f(Y|A)f(Y|B)$。]
这个概念有通用术语吗？如果有，它在什么情况下使用/应用？]]></description>
      <guid>https://stats.stackexchange.com/questions/659629/independence-of-conditioning-variables-effects</guid>
      <pubDate>Mon, 06 Jan 2025 21:46:29 GMT</pubDate>
    </item>
    <item>
      <title>探索性因子分析，非正态数据</title>
      <link>https://stats.stackexchange.com/questions/659613/exploratory-factor-analysis-non-normal-data</link>
      <description><![CDATA[我正在分析的数据对于几乎每个观察到的变量都是非正态的。我想在 R 中进行探索性因子分析 (EFA)。KMO 检验和 Bartlett 检验表明数据符合 EFA 条件。在 psych 包的文档中，我没有找到应如何处理非正态分布的数据 (https://personality-project.org/r/psych/HowTo/factor.pdf)。我的样本相对较小 (N=60)。
在进行验证性因子分析时，我可以使用 lavaan 包中的 Satorra-Bentler 校正来处理非正态数据，cfa() 函数，例如cfa(model = spec, data = df_data, std.lv=TRUE, estimator = &quot;MLM&quot;) ，这种使用稳健标准误差的校正是一种可接受的方法。 estimator=&quot;MLM&quot; 代表 Satorra-Bentler 校正。我可以用 psych 包 以某种方式做到这一点吗？
psych 包执行 EFA，fa() 函数，例如fa(data, nfactors = 4, rotate = &quot;oblimin&quot;) 并提供可行的因子，但如果我没有弄错的话，它被设计用于正态分布的数据。
如果我尝试使用 lavaan 包 中的 efa() 和 Satorra-Bentler 校正，它会发出 警告，表示协方差矩阵包含较小的负值，这可能表明模型未被识别：
efa(data = df_data, nfactors=4, rotation=&quot;oblimin&quot;, std.lv=TRUE, estimator = &quot;MLM&quot;)

警告消息：
1：lavaan-&gt;lav_model_vcov()： 
估计参数 (vcov) 的方差-协方差矩阵似乎不是
正定！最小特征值 (= -5.425180e-15) 小于零。这可能是模型无法识别的症状。
2：lavaan-&gt;lav_model_vcov()：
估计参数 (vcov) 的方差-协方差矩阵似乎不是正定的！最小特征值 (= -2.190854e-32) 小于零。这可能是模型无法识别的症状。


那么问题是：如何使用心理学包计算非正态数据的 EFA？
更新：
数据分布：我有 9 个变量，每个变量都有比例尺度，因此理论上它们可以从零到无穷大。在实践中，它们计算活动，因此它们包含每个研究对象的整数值。其中一些只有 2、3 个不同的值，这给出了与理论正态分布不同的分布。我添加了一个关于一个变量的 QQ 图，如下图所示。

我使用 psych 包进行了 EFA，以发现数据可能具有从 1 个因子到 9 个因子的内容，以便我可以看到每种情况的拟合优度指标。 这产生了具有 4 个潜在变量的最佳指标。这就是我从 4 开始的原因。尽管如此，我并没有更改默认的因子提取，也没有提供相关矩阵。
我如何为 fa() 函数提供 Spearman 相关矩阵？如果我提供这个矩阵，我是否应该从 minres 更改因子提取方法？哪种因子提取方法对非正态性不太敏感？非正态性对 TLI、CFI、RMSEA 和 Chi2 指标的计算没有影响吗？
我很感激每一位回复，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659613/exploratory-factor-analysis-non-normal-data</guid>
      <pubDate>Mon, 06 Jan 2025 12:41:19 GMT</pubDate>
    </item>
    <item>
      <title>R 中 Frank's Copula 负二项式模型中 Theta 参数发散问题</title>
      <link>https://stats.stackexchange.com/questions/659647/issue-with-diverging-theta-parameter-in-negative-binomial-models-with-franks-co</link>
      <description><![CDATA[我尝试使用负二项分布结合 Frank 的 copula 来对足球比赛结果进行建模，以建立依赖结构。每支球队都被分配了单独的进攻和防守参数，并且有主场和客场进球的离散参数，以及 Frank 的 copula 的 theta 参数。
我的方法受到 McHale、Ian 和 Phil Scarf 的论文“国际足球比赛中对方球队进球依赖关系建模”中描述的方法的启发（统计建模，11.3（2011）：219-236）。但是，我没有使用基于 FIFA 世界排名位置差异的参数来对进球依赖关系进行建模（如原始研究），而是对其进行了修改，使用单独的球队参数进行进攻和防守。
不幸的是，在优化过程中，theta 参数在几次迭代后开始发散，我不知道如何解决这个问题。我怀疑 Frank 的 copula 的 theta 参数可能需要限制在特定范围内以确保数值稳定性。但是，我使用的优化函数 (nlm) 不直接支持参数约束，这使得这很难实现。
我的方法：

示例数据：

 set.seed(123)

data_model &lt;- data.frame(
Heim = sample(c(&quot;Team A&quot;, &quot;Team B&quot;, &quot;Team C&quot;, &quot;Team D&quot;), 100, replace = TRUE),
Gast = sample(c(&quot;Team A&quot;, &quot;Team B&quot;, &quot;Team C&quot;, &quot;Team D&quot;), 100, replace = TRUE),
ToreHeim = rpois(100, lambda = 1.5), # 主队进球
ToreGast = rpois(100, lambda = 1.2) # 客队进球
)

# 删除主队等于客队的比赛
data_model &lt;- data_model[data_model$Heim != data_model$Gast, ]


模型函数：

negloglik_double_nb_copula &lt;- function(params, goals_home, goals_visitor,
team_home, team_visitor, param_skeleton) {
plist &lt;- relist(params, param_skeleton)
plist$defense &lt;- c(sum(plist$defense)*-1, plist$defense)
names(plist$defense)[1] &lt;- names(plist$attack[1])

lambda_home &lt;- exp(plist$attack[team_home] + plist$defense[team_visitor] + plist$home)
lambda_visitor &lt;- exp(plist$attack[team_visitor] + plist$defense[team_home])

m1 &lt;- exp(plist$m1)
m2 &lt;- exp(plist$m2)
theta &lt;- exp(plist$theta)

log_lik_home &lt;- dnbinom(goals_home, mu = lambda_home, size = m1^(-1), log = F)
log_lik_visitor &lt;- dnbinom(goals_visitor, mu = lambda_visitor, size = m2^(-1), log = F)
log_lik_copula &lt;- log(frank_copula_density(log_lik_home, log_lik_visitor, theta))

log_lik &lt;- sum(log_lik_copula)
return(log_lik * -1)
}

frank_copula_density &lt;- function(p_home, p_visitor, theta) {
num &lt;- theta * exp(-theta * (p_home + p_visitor)) * (1 - exp(-theta))
denom &lt;- ((1 - exp(-theta * p_home)) * (1 - exp(-theta * p_visitor)) + exp(-theta) - 1)^2
return(num / denom)
}



初始参数：

parameter_list_copula &lt;- list(
attack = rep(0.2, n_teams),
defense = rep(-0.01, n_teams-1),
home = 0.1,
m1 = 0.1,
m2 = 0.15,
theta = 0.5
)

names(parameter_list_copula$attack) &lt;- all_teams
names(parameter_list_copula$defense) &lt;- all_teams[-1]



优化：

nlm_nb_copula &lt;- nlm(negloglik_double_nb_copula, unlist(parameter_list_copula), 
goals_home = data_model$ToreHeim,
goals_visitor = data_model$ToreGast,
team_home = data_model$Heim, team_visitor = data_model$Gast,
param_skeleton = parameter_list_copula, print.level = 2, 
iterlim = 10000, hessian = F)

尽管设置了合理的起始值，但经过几次迭代后，优化结果在 theta 参数上出现了分歧。
切换到支持参数约束的优化方法是否有意义（例如，使用带框约束的优化）？或者是否有其他推荐的策略来解决这个问题？
任何稳定优化的建议或改进此模型的见解都将不胜感激。
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/659647/issue-with-diverging-theta-parameter-in-negative-binomial-models-with-franks-co</guid>
      <pubDate>Sun, 05 Jan 2025 22:58:36 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们将标准误差定义为忽略偏差（与包含偏差的 MSE 不同）？</title>
      <link>https://stats.stackexchange.com/questions/659583/why-do-we-define-the-standard-error-to-ignore-bias-unlike-mse-which-includes-bi</link>
      <description><![CDATA[为什么估计量$\hat \theta$的标准误差定义为$$se = \sqrt{Var(\hat \theta)}$$，而不是$$se = \sqrt {MSE(\hat \theta)} = \sqrt{Bias^2(\hat \theta) + Var(\hat \theta)}.$$
也就是说，标准误差应该是均方误差的平方根。当然，如果估计量是无偏的，那就没有区别了。但无论如何，我能想到，如果估计量有偏差，那么我们使用标准误差的地方，偏差需要成为误差的一部分。
例如，考虑执行 Wald 检验。如果我们愿意增加偏差，我们总是可以得出任意低方差的 $\sigma^2$ 估计量。例如，给定 $\hat \sigma^2$，定义 $$\hat \sigma_1^2 = (1-t)\hat \sigma^2 + tk$$，对于任意常数 $t,k$ 将给出这样的估计量。如果我们使用它来执行 Wald 检验，我们可以通过降低 se 来获得我们想要的任何 $\alpha$，而无需真正改进测试。
如果 se 的定义包括偏差，这个问题就会得到解决 - 这会与 标准 错误 一词更加一致。我们为什么不这样做呢？

更新 - 与假设检验的相关性
除了术语之外，这里有一个有影响力的问题：在我们的估计量确实有偏差的情况下，我们应该在假设检验中使用 标准错误 还是上述定义？有些情况下，这会对测试结果产生影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/659583/why-do-we-define-the-standard-error-to-ignore-bias-unlike-mse-which-includes-bi</guid>
      <pubDate>Sun, 05 Jan 2025 21:17:49 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 SHAP 值</title>
      <link>https://stats.stackexchange.com/questions/659566/how-to-interpret-shap-values</link>
      <description><![CDATA[我是 AI 新手。我有一张尺寸为 (28, 28, 3) 的 MNIST 图像，心里有几个问题。如果有人能就此提出建议，那就太好了：

SHAP 如何确定值范围？例如，为什么有时是 -2 到 +2？它应该这么大吗？有时，当我使用其他格式运行它时，它会给出 -0.00005 到 0.00005 的范围。正确的有效范围是什么？

如果我的模型对此图像的置信度得分为 30，那么将 SHAP 值相加是否也会得到 30？这是否意味着总贡献得分应该与置信度得分相匹配？如果不是，为什么？


]]></description>
      <guid>https://stats.stackexchange.com/questions/659566/how-to-interpret-shap-values</guid>
      <pubDate>Sun, 05 Jan 2025 14:51:01 GMT</pubDate>
    </item>
    <item>
      <title>除了单纯形之外，狄利克雷分布还有哪些其他支持的推广形式？</title>
      <link>https://stats.stackexchange.com/questions/659565/is-there-any-generalization-of-the-dirichlet-distribution-to-supports-other-than</link>
      <description><![CDATA[让我们考虑$(\theta_1,\theta_2,\ldots,\theta_k) \sim \operatorname{Dirichlet}(a_1,a_2,\ldots,a_k)$。我想知道我们是否还有$\theta_1 &gt; \varepsilon_1, \theta_2 &gt; \varepsilon_2,\ldots,\theta_k &gt; \varepsilon_k,$ 其中 $\varepsilon_i \geq 0, \forall i \in \{1,2,\ldots,k\}$ 是已知常数。
是否有任何已知的分布或封闭的解析形式？
我曾尝试通过条件概率计算来发展这个想法，但这有点具有挑战性。]]></description>
      <guid>https://stats.stackexchange.com/questions/659565/is-there-any-generalization-of-the-dirichlet-distribution-to-supports-other-than</guid>
      <pubDate>Sun, 05 Jan 2025 14:41:16 GMT</pubDate>
    </item>
    </channel>
</rss>