<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 31 Dec 2023 03:14:45 GMT</lastBuildDate>
    <item>
      <title>平稳性矛盾检验</title>
      <link>https://stats.stackexchange.com/questions/635898/testing-for-stationarity-contradictions</link>
      <description><![CDATA[作为参考，我正在使用 STATA。我的数据包含从 1963 年第一季度到 2017 年第四季度的 PCE 指数。我的目标是制定一种使用 PCE 解释通货膨胀的策略，然后预测 2018 年第一季度。以下是我的问题：

首先，我记录了 PCE 指数以获得 Ln_PCE，尽管 Dicky-Fuller 测试和 Phillips-Perron 单元测试表明数据并不平稳。
其次，我首先求出每年的通货膨胀率：
400*(LnPCE[_n]-LnPCE[_n-1])。
第三，我使用以下方法测试了平稳性
增强的 Dicky-Fuller 检验和 Phillips-Perron 检验。两者都是
$0.0000$ 和 $0.0002$，说明我的数据是固定的。此外，测试统计量小于 $1$、$5$ 和 10 美元。
第四，我
使用 ACF 和 PACF 图来进一步检查平稳性，以便我可以使用
ARIMA 模型。

但是，ACF 看起来不稳定，并且与 ADF 和 Phillips-Perron 检验相矛盾。我不知道该怎么办。我是否第二次出现差异，或者我的数据通过 ADF 和 Phillips-Perron 单位根测试已经稳定了。我的感觉是我必须对通货膨胀率进行二阶差分。
另外，如果我不需要再次进行差分，并且我所做的很好，那么使用 (1,1,7) 的 ARIMA 模型可以吗？我已经从 (1,1,1) 一直测试到 (3,1,12)。
]]></description>
      <guid>https://stats.stackexchange.com/questions/635898/testing-for-stationarity-contradictions</guid>
      <pubDate>Sun, 31 Dec 2023 02:44:08 GMT</pubDate>
    </item>
    <item>
      <title>是否有均值和方差的模型？</title>
      <link>https://stats.stackexchange.com/questions/635896/is-there-a-model-for-both-mean-and-variance</link>
      <description><![CDATA[目前我们的模型为 $y^{pred}_{i} \sim N(\beta_1 x_i + \beta_0, \sigma^2)$。 
是否可以创建一个具有非常数方差的模型 $y^{pred}_{i} \sim N(\beta_1 x_i + \beta_0, e^{\ beta_3 x_i + \beta_2})$?]]></description>
      <guid>https://stats.stackexchange.com/questions/635896/is-there-a-model-for-both-mean-and-variance</guid>
      <pubDate>Sun, 31 Dec 2023 01:45:29 GMT</pubDate>
    </item>
    <item>
      <title>$K$ 阶段适应性试验的 $K-1$ 阶段的条件功效</title>
      <link>https://stats.stackexchange.com/questions/635895/conditional-power-at-stage-k-1-of-k-stage-adaptive-trial</link>
      <description><![CDATA[我发现了一个相当好的基于概率的方程，用于计算 $K$ 阶段 $k$ 的条件功效阶段适应性分组序贯试验。但是，我认为前几个 $(k-1)$ 阶段的测试统计数据总和存在错误。
假设进行单方面测试和 5 阶段自适应组序贯试验，并假设在阶段 $k=4$ 进行中期分析后需要条件功效。另外，假设阶段 $k$ 的检验统计量等于
$Z_k = \sum _{i=1}^k Z_i \sqrt{I}$，
其中 $I=n_i/N_i$ 和 $n_i$ 是一次样本大小$i$ 阶段的手臂和 $N_i$ 是阶段  的一支手臂的累积样本量类=“数学容器”&gt;$i$。
我认为错误的方程式是：
$cP_k = \sum_{j=k+1}^K P \left( \bigcap_{i=k+1}^{j-1} (Z_{\beta_i }&lt; Z_i  Z_{\alpha_j} \right)$
我认为应该是
$cP_k = \sum_{j=k+1}^K P \left( \bigcap_{i=1}^{j-1} (Z_{\beta_i}&lt; ; Z_i  Z_{\alpha_j} \right)$
替换后，第 4 阶段的条件功效将为（对于错误方程）：
$cP_4 = \sum_{j=5}^5 P \left( \bigcap_{i=5}^{4} (Z_{\beta_i}&lt; Z_i &lt; ;Z_{\alpha_i}) \bigcap Z_5 &gt; Z_{\alpha_5} \right)$
我认为应该是
$cP_4 = \sum_{j=5}^5 P \left( \bigcap_{i=1}^{4} (Z_{\beta_i}&lt; Z_i &lt; ;Z_{\alpha_i}) \bigcap Z_5 &gt; Z_{\alpha_5} \right)$
正确的（我相信）后一个方程对检验统计量既不被拒绝的次数进行求和，$Z_i &gt;Z_{\alpha_i}$ 也不低于徒劳无功，$Z_i。毕竟，除非您只考虑 $Z_{\beta_i}&lt; 的实现，否则您无法进入第五阶段。 Z_i 。]]></description>
      <guid>https://stats.stackexchange.com/questions/635895/conditional-power-at-stage-k-1-of-k-stage-adaptive-trial</guid>
      <pubDate>Sun, 31 Dec 2023 01:42:41 GMT</pubDate>
    </item>
    <item>
      <title>CLT、欧几里德距离和均值</title>
      <link>https://stats.stackexchange.com/questions/635893/clt-euclidean-distances-and-means</link>
      <description><![CDATA[这可能听起来像是一个相当奇怪的问题，但我偶然发现了一种类似于正态分布的均值分布，但我不确定是否可以证明它确实是一个。这是设置。
假设我抽取了 $n$ 个独立且同分布的随机向量/变量 $ x_1, x_2, 的样本。 ..,x_n$ （我确实使用了特定的发行版，但我认为这并不重要）。现在，我们找到每个随机变量/向量与所有其他变量的欧几里德距离并找到平均值。因此，对于示例中的每个变量 $j = 1,...,n$，我们有：
$$
Y_j = \frac{1}{n-1} \sum_{i \neq j} |x_j - x_i|
$$
现在，如果我增加 $n$ 并重复绘制这些变量的分布，我会得到越来越像正态分布的东西。这是侥幸还是有更深层次的东西我不明白？毕竟，$Y_j$ 变量并不是彼此独立的，欧几里德距离也不是。]]></description>
      <guid>https://stats.stackexchange.com/questions/635893/clt-euclidean-distances-and-means</guid>
      <pubDate>Sat, 30 Dec 2023 23:20:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Cox-PH 不能处理左或区间删失？</title>
      <link>https://stats.stackexchange.com/questions/635888/why-cant-cox-ph-handle-left-or-interval-censoring</link>
      <description><![CDATA[我一直试图为此找到数学解释。请注意，我说的是“经典” Cox-PH，不是后面给出的用于合并间隔/左审查的扩展。
在本文中据称：
&lt;块引用&gt;
“将区间审查纳入比例风险
模型无法取消基线危险函数”。

谁能证明这个？这是否正确？
根据 cox 给出的部分可能性的定义 - 似乎已被审查数据将被简单地忽略，并且间隔将被视为仅对间隔的左侧部分进行右删失。因此，Cox 似乎仍然可以工作，但可能不会很准确，因为它会忽略一些数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/635888/why-cant-cox-ph-handle-left-or-interval-censoring</guid>
      <pubDate>Sat, 30 Dec 2023 20:11:07 GMT</pubDate>
    </item>
    <item>
      <title>从范围内随机抽取——均匀分布可能吗？</title>
      <link>https://stats.stackexchange.com/questions/635887/drawing-randomly-from-range-is-a-uniform-distribution-possible</link>
      <description><![CDATA[具体任务是在0到90的范围内随机抽取5个样本，每个样本之间的最小距离为7。
我针对这些条件进行了 100 万次运行。第一张图显示了每个值的绘制频率。我的目标是均匀分布，但事实显然并非如此。
我尝试了几种技术，改善了分布。然而，范围前端和末端的峰值并没有消失。 （至少在执行 1 mio 运行时。在仅运行 10k 次的实验中，范围边缘没有可见峰值）
现在我的问题是：
给定固定范围和样本之间最小距离的条件：是否有可能抽出的数字均匀分布？
第一次尝试：在原始条件下运行 100 万次：

一百万次运行：新技术的最佳结果：
]]></description>
      <guid>https://stats.stackexchange.com/questions/635887/drawing-randomly-from-range-is-a-uniform-distribution-possible</guid>
      <pubDate>Sat, 30 Dec 2023 20:02:22 GMT</pubDate>
    </item>
    <item>
      <title>多维、稀疏、连续特征的回归模型</title>
      <link>https://stats.stackexchange.com/questions/635884/regression-model-with-multi-dimensional-sparse-and-continuous-features</link>
      <description><![CDATA[我有一个包含不到 10000 个示例的交互结果数据集。为了简单起见，假设每个示例都是对主机和客户端之间交互产生的某种类型的可观察结果的度量。
Host 和 Client 都有很多（大约 300 个）连续的特征，只有 Host 也有很少的离散特征。
我仅观察到所有可能的主机-客户端对的子集的数据。
我的目标是预测“观察矩阵”中缺失单元格的值。
作为示例，请查看 3 个主机（A、B、C）和 3 个客户端（X、Y、Z）的观察值。

我阅读了有关因子分解机、场感知 FM 和其他专门用于填充观测矩阵中缺失值的 ML 方法的论文。
问题是他们假设这些特征是分类的，但就我而言，情况并非如此。
这是我的数据集的一个虚拟示例。

请注意，即使此结构可能建议使用线性模型，我们也不能假设效果是相加的。实际上，重点是试图测量特征之间的交互，因此排除线性方法（除非明确创建新特征作为特征的产物）。
我想知道是否有一种方法专门针对此类问题，但可以很好地处理连续变量，并且同时（如分解机）考虑主机和客户端之间可能的交互。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/635884/regression-model-with-multi-dimensional-sparse-and-continuous-features</guid>
      <pubDate>Sat, 30 Dec 2023 19:18:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 Metafor 的推理测试中的差异</title>
      <link>https://stats.stackexchange.com/questions/635883/discrepancy-in-inferential-tests-using-metafor</link>
      <description><![CDATA[我正在使用 Metafor 进行分析，查看两组之间的不同分数。所有这些都使用原始均值差（因此 rma(yi = MEAN_DIFFERENCES, sei = STANDARD_ERRORS)。合著者建议我们还提供标准化均值差，因此我计算了均值、SD 和组 N对于每个分析并传递它们（所以 rma(m1i=MEANS_EXPERIMENTAL, m2i=MEANS_CONTROL, sd1i=SDS_EXPERIMENTAL, sd2i=SDS_CONTROL, n1i=NS_EXPERIMENTAL, n2i=NS_CONTROL,measure=“SMD”)） .
结果通过了初步健全性检查，但我注意到推断统计数据（zval 和 pval）与我使用平均差异获得的结果不一致（在一个实例中）这导致使用 SMD 分析时 p 值高于 alpha，但使用 MD 分析时低于 alpha）。
这是否表明存在一些潜在问题，或者我是否误解了 rma.uni 如何计算模型结果？是否有更优雅的方法来执行此操作（例如，从使用 MD 的模型计算 SMD 和置信区间）？
编辑：MD 分析之一的示例输出...
随机效应模型（k = 23；tau^2 估计器：REML）

tau^2（总异质性的估计量）：0.0604（SE = 0.0248）
tau（tau^2 估计值的平方根）：0.2457
I^2（总异质性/总变异性）：81.86%
H^2（总变异性/采样变异性）：5.51

异质性测试：
Q(df = 22) = 80.6150，p-val &lt; .0001

模型结果：

估计 se zval pval ci.lb ci.ub
 -0.2249 0.0606 -3.7096 0.0002 -0.3437 -0.1061 ***

---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

和原来的变量一样，但是SMD...
随机效应模型（k = 23；tau^2 估计器：REML）

tau^2（总异质性的估计量）：0.0498（SE = 0.0220）
tau（tau^2 估计值的平方根）：0.2232
I^2（总异质性/总变异性）：72.89%
H^2（总变异性/采样变异性）：3.69

异质性测试：
Q(df = 22) = 65.6464，p-val &lt; .0001

模型结果：

估计 se zval pval ci.lb ci.ub
 -0.2194 0.0568 -3.8612 0.0001 -0.3308 -0.1081 ***

---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
]]></description>
      <guid>https://stats.stackexchange.com/questions/635883/discrepancy-in-inferential-tests-using-metafor</guid>
      <pubDate>Sat, 30 Dec 2023 18:43:04 GMT</pubDate>
    </item>
    <item>
      <title>混合效应模型调整 p 值的事后检验</title>
      <link>https://stats.stackexchange.com/questions/635848/post-hoc-test-for-mixed-effect-model-adjusting-p-values</link>
      <description><![CDATA[我们正在对混合效应模型进行事后测试，以在 R（nmle 和 emmeans 包）中进行重复测量。对于子组分析，我们包括交互time_point * group，即
model = lme(val ~ time_point * group,
            随机 = ~1 | ID，
            相关性 = corCompSymm(),
            数据=数据）

当我们随着时间的推移观察不同群体的边际平均值时，我们会看到（至少在视觉上）一些效果。

我们希望评估各组之间在每个时间点的反应是否存在显着差异。通过查看所有组合是否有意义
pairs(emmeans(模型, ~ 组 * time_point))

并报告调整后的 p 值 (Tukey)？这会进行过多的比较并可能夸大 p 值。或者减少与例如的比较是否更有意义
pairs(emmeans(model, ~ group | time_point), adjustment = &quot;none&quot;)


然后用例如：修正所有 12 个（4 个时间点和 3 个组）p 值邦费罗尼方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/635848/post-hoc-test-for-mixed-effect-model-adjusting-p-values</guid>
      <pubDate>Fri, 29 Dec 2023 23:24:20 GMT</pubDate>
    </item>
    <item>
      <title>统计遗传学 - 如何解释数据和分析</title>
      <link>https://stats.stackexchange.com/questions/635840/statistical-genetics-how-to-interpret-data-analysis</link>
      <description><![CDATA[我的问题是如何解释以下统计遗传模型中的 $G_{ij}$ $$h(\ mu_i) = \alpha_0 + \alpha&#39;X_i + \beta&#39;G_i,$$
其中 $G_i = (G_{i1},\dots ,G_{im})$ 是等位基因计数（零个、一个或两个变异等位基因） $m$ 个感兴趣的变体（来自本文第 10 页：链接)。
具体来说，我想知道

如果读取的是 DNA 序列（如果这是错误的，请纠正我），那么如何从序列中确定等位基因类型和计数？
每个 $m$ 变体是否对应于基因组中独立且不相交的区域？
既然基因由 DNA 组成，并且可能的 DNA 序列有非常多，为什么只有 0、1 或 2 个等位基因？

请随意回答您能够或愿意的尽可能多的问题。另外，我知道这些问题可能反映了我对上下文的误解，因此很难回答。
如果有任何意见，我将不胜感激 - 谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635840/statistical-genetics-how-to-interpret-data-analysis</guid>
      <pubDate>Fri, 29 Dec 2023 19:32:26 GMT</pubDate>
    </item>
    <item>
      <title>杠杆和残差之间的相互依赖性</title>
      <link>https://stats.stackexchange.com/questions/635811/interdependence-between-leverages-and-residuals</link>
      <description><![CDATA[根据我在网上读到的以下在线引用：
&lt;块引用&gt;
值得注意的是，观察值可以具有很高的绝对值
对于标准化残差，但杠杆值较低。

我的想法如下：杠杆对模型的拟合值有直接影响。也就是说，当我们的观测值远离拟合模型时，需要高杠杆。也就是说，残差很大。那么怎么会出现杠杆率低且残差大的情况呢？我在这里缺少什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/635811/interdependence-between-leverages-and-residuals</guid>
      <pubDate>Fri, 29 Dec 2023 11:52:13 GMT</pubDate>
    </item>
    <item>
      <title>关于 LMM 的问题</title>
      <link>https://stats.stackexchange.com/questions/635717/questions-on-lmm</link>
      <description><![CDATA[我想询问线性混合模型及其在我的数据集中的应用。该数据集包括表示为“V”的因变量，除了三个相关的人口统计变量（例如，年龄和性别标记为 d1-d3）之外，单个受试者内变量标识为 wi，单个受试者间变量标识为 bw。变量“id”是变量“id”。代表数据集中唯一的主题标识符。
现在，我将初始完整模型设置为：
V ~ d1 * d2 * d3 * wi * bw + (1 + wi | id)
然后我使用 step() 来识别最能解释“V”变化的模型，从而找到一个复杂的模型，例如：
V ~ d1 + d2 + d3 + wi + bw + (1 + wi | id) + d1:d2 + d1:d3 + ... + 每个变量有 13 种组合。
然后我评估模型与这个复杂模型的拟合程度。它有很多固定效应，但只有一些显示出统计显着性（例如 d1、d1:wi 和 d2:wi:bw）。
我可以相信这个模型并得出结论：显着的固定效应（d1、d1:wi 和 d2:wi:bw）是 V 的重要因素吗？
是否有更好的方法来查找哪些变量或其相互作用对 V 很重要？
请注意，数据集有 65 个主题，所以我想知道 step() 找到的模型有太多解释变量。
欢迎大家提出宝贵意见，谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/635717/questions-on-lmm</guid>
      <pubDate>Wed, 27 Dec 2023 17:01:04 GMT</pubDate>
    </item>
    <item>
      <title>在自然实验中具有重复增益分数的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/635687/linear-mixed-models-with-repeated-gain-scores-in-a-natural-experiment</link>
      <description><![CDATA[背景：我正在处理一个数据集，其中包含来自涉及自然实验的调查问卷的观察数据。人们每周都会被问及是否收到了意外消息 (X)、他们睡了多少觉 (Z) 以及他们的健康状况 (Y)。 Y 和 Z 是在另一次子调查中测量的，因此对于 X 的每个观测值，我将 X 之前和之后最接近的 Y 和 Z 观测值合并起来，以获得前/后测量值。现在，每一行都包含用户 ID、x、z 的值以及相应的 Y 前值和后值。作为用前值调整后值以控制预测值的中心假设不满足（组有在基线时没有被随机化），我选择使用增益/变化/差异分数（https://homes.ori.org/keiths/Tips/Stats_GainScores.html）作为我的回归 Ydiff ~ X*Z 的结果，其中 Ydiff = Post - Pre。
问题：观察的数量因人而异：有些人确实比其他人参与更多，导致每个人的分数发生多个变化；其他人只有一个可用的更改分数。使用随机截距为每个用户建模潜在的嵌套结构是否有意义？多个变化分数的出现是否可以称为嵌套？我现在真的不知道如何继续这里。谢谢大家！
数据如下：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

ID
x
z
预
帖子
ydiff


&lt;正文&gt;

356
未收到
4.2590
2
2
0


356
已收到
5.6615
1
5
4


1088
已收到
8.8172
5
5
0


1089
未收到
5.0027
1
3
2


1089
没有检查
5.3050
2
5
3




在 R 中重现的代码：
&lt;前&gt;&lt;代码&gt;n &lt;- 4000
data_frame &lt;- 变换（
  数据.帧(
    ID = 样本(rep(样本(1:2000, 500, 替换 = FALSE), 每个 = 4), n, 替换 = TRUE),
    x = 样本(c(“已收到”,“未收到”,“未检查”), n, 替换 = TRUE),
    z = runif(n, 4, 10),
    前 = 样本(1:5, n, 替换 = TRUE),
    帖子=样本（1：5，n，替换= TRUE）
  ),
  ydiff = 后 - 前
）
]]></description>
      <guid>https://stats.stackexchange.com/questions/635687/linear-mixed-models-with-repeated-gain-scores-in-a-natural-experiment</guid>
      <pubDate>Wed, 27 Dec 2023 08:17:59 GMT</pubDate>
    </item>
    <item>
      <title>随机对照试验需要因果图吗？</title>
      <link>https://stats.stackexchange.com/questions/635460/causal-diagrams-necessary-in-randomized-controlled-trials</link>
      <description><![CDATA[我理解正确管理的随机对照试验如何排除混杂因素，因为除了随机化（意味着从结果到治疗变量没有后门路径）之外，没有任何变量影响治疗/对照组分配。
这是否意味着在进行 RCT 时，无需像观察性因果推理研究那样绘制因果图 (DAG) 来识别混杂因素、碰撞因素、中介因素等？
在特殊情况下您会想要花时间构建 DAG 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635460/causal-diagrams-necessary-in-randomized-controlled-trials</guid>
      <pubDate>Thu, 21 Dec 2023 22:03:22 GMT</pubDate>
    </item>
    <item>
      <title>VQ-VAE 均匀先于潜在变量</title>
      <link>https://stats.stackexchange.com/questions/591769/vq-vae-uniform-prior-over-the-latent-variables</link>
      <description><![CDATA[VQ-VAE提议

使后验分类分布 $q(z|x)$ one-hot = 定义为 $1$ 用于将码本中的 $e$ 最接近编码器的输出 $z_e(x)$跨度&gt;;
定义一个简单的先于 $z$（潜在变量）的统一先验。

作者声称，这获得了一个离散的 KL 散度，等于 $\log K$，其中 $ K$ 是离散潜在嵌入的数量。
如果我理解正确，这意味着 $z$ 上的统一先验的范围应该是这样，以便每个嵌入的概率等于 $1/K$ 最接近编码器输出。
我说得对吗？
如果是这样，我们应该如何初始化嵌入向量？它们的权重是否应该初始化为统一概率 - $U[\min(z_e(x)), \max(z_e(x))] ； x\in X$?]]></description>
      <guid>https://stats.stackexchange.com/questions/591769/vq-vae-uniform-prior-over-the-latent-variables</guid>
      <pubDate>Mon, 10 Oct 2022 10:24:20 GMT</pubDate>
    </item>
    </channel>
</rss>