<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 05 Jan 2024 15:14:17 GMT</lastBuildDate>
    <item>
      <title>从具有平滑项的 gamm 模型获取并操作预测方程</title>
      <link>https://stats.stackexchange.com/questions/636242/obtaining-and-manipulating-the-prediction-equation-from-a-gamm-model-with-smoo</link>
      <description><![CDATA[我已经阅读了此处提交的类似问题，并查看了 Wood 2017 年的书（广义可加模型：R 简介，第二版），但找不到我的问题的答案。为了提出这个问题，首先考虑一个简单的线性模型：fit&lt;-lm(Y~X+Z)。一旦我从这个简单模型中获得系数（例如，Y_hat=2.1+0.9X+3.2Z），那么如果我将 Z 的系数设置为零，我就会得到 Y 的预测值（ Y_hat*=2.1+0.6X) 以及 Y 围绕这个新方程的残差。
现在，假设我做了一个广义加性模型（例如，使用 mgcv 包的 gamm 函数）：fit&lt;-gamm(Y~s(X)+s(Z))。我怎样才能得到这个 GAM 的系数，以便我可以像使用简单的线性方程一样做同样的事情；即，如果我将与 Z 的平滑函数相关的系数设置为零，然后获得该新方程的残差，则获得 Y   的预测值？
如果我提取 GAM 的系数（例如 coef(fit$lme)），那么我可以看到与截距和每个基函数相关的系数，但我不知道之后如何继续。
感谢您的任何建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/636242/obtaining-and-manipulating-the-prediction-equation-from-a-gamm-model-with-smoo</guid>
      <pubDate>Fri, 05 Jan 2024 15:03:51 GMT</pubDate>
    </item>
    <item>
      <title>估计指数衰减基数</title>
      <link>https://stats.stackexchange.com/questions/636241/estimating-exponential-decay-base</link>
      <description><![CDATA[假设我有噪声观察的时间序列$\hat{Y_t}$，具有真实的基础但不可观察 $Y_t$ ~ $N(\hat{Y_t},\sigma)$。
我想用基本模型估算$Y_t$
$Y = 平均值(\hat{Y}_{0}...\hat{Y}_{t-1})$。
到目前为止一切顺利，现在我想补充一个事实，即底层 $Y$ 随着时间的推移逐渐变化，这意味着 $Y_t$ 与 $Y_{t-1}$ 略有不同。因此，最近的观察结果应该在均值估计中得到更大的权重。我的新模型是
$Y = wmean(w_0\hat{Y}_{0}...w_{t-1}\hat{Y}_{t-1})$  $\quad$ 与 $w_{t_0}= x^{distance(t,t_0)}$  $\quad$ ,$x\in(0,1)$。 p&gt;
因此，当 $x$ 接近 $1$ 时，衰减会变慢。您知道如何估算$x$吗？是通过参数调整（更好的词来尝试）来做到这一点的唯一方法，还是有办法通过某种模型来最佳地适应它？]]></description>
      <guid>https://stats.stackexchange.com/questions/636241/estimating-exponential-decay-base</guid>
      <pubDate>Fri, 05 Jan 2024 14:57:32 GMT</pubDate>
    </item>
    <item>
      <title>经过多重插补（R中的MICE包）后，我仍然发现一些变量仍然存在缺失值。怎么处理呢？</title>
      <link>https://stats.stackexchange.com/questions/636240/after-the-mutiple-imputation-mice-package-in-r-i-still-found-that-some-variab</link>
      <description><![CDATA[我有一个相对较大的数据集，包含大约 12000 个样本和 550 个变量。最初，我有大约 800 个变量，我使用了一个规则，如果每个变量的缺失率大于 80%，我就会放弃它，这就是为什么最后我剩下 550 个变量。我的变量有两种类型：分类变量和连续变量。
我尝试了两种类型的代码来进行多重插补。

估算&lt;-小鼠(df,pred=quickpred(df, mincor = .3),m=5,seed=10)

估算&lt;-mice(df, m=5, method=&#39;cart&#39;, Seed=10)


但是，这两个代码给了我相同的结果，即仍然有一些变量仍然具有缺失值，尽管大多数缺失值的变量都被估算了。
遇到这种情况我该怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/636240/after-the-mutiple-imputation-mice-package-in-r-i-still-found-that-some-variab</guid>
      <pubDate>Fri, 05 Jan 2024 14:36:52 GMT</pubDate>
    </item>
    <item>
      <title>处理响应变量偏向整数的回归</title>
      <link>https://stats.stackexchange.com/questions/636238/handling-a-regression-in-which-the-response-variable-is-biased-to-whole-numbers</link>
      <description><![CDATA[我正在尝试对一个人完成某项任务所记录的时间进行建模。时间以十分之一小时为单位记录，因此为 0.1、0.4、1.5 等。
这个“记录时间”似乎近似呈指数分布。但我注意到似乎存在对整数次的偏见。一个人更有可能记录一轮“2小时”是有道理的。对于任务而不是“1.9”或“2.1”。
我尝试过的回归具有较低的 R 平方和非正态残差。当然，我的模型中可能缺少变量，并且数据中可能存在大量不可约的变异性。
但我也担心这种整数偏差可能会导致问题。当人类记录数据时，这似乎也可能是一个常见问题，所以我认为这个社区可能有一些想法。
所以

这会让回归变得更糟吗？
有办法解决这个问题吗？我是否应该将这个“记录的时间”视为“记录时间”？例如，作为分类变量而不是连续变量？ （但是会有很多非常密切相关的类别，例如“0.2”和“0.3”
]]></description>
      <guid>https://stats.stackexchange.com/questions/636238/handling-a-regression-in-which-the-response-variable-is-biased-to-whole-numbers</guid>
      <pubDate>Fri, 05 Jan 2024 14:31:00 GMT</pubDate>
    </item>
    <item>
      <title>如何使用边际结构模型估计可解释的治疗效果？</title>
      <link>https://stats.stackexchange.com/questions/636237/how-to-estimate-interpretable-treatment-effects-using-a-marginal-structural-mode</link>
      <description><![CDATA[假设我使用通过逆概率加权获得的权重来估计边际结构模型。想象一下，我的模型看起来类似于： $Y_t = X_t + X_{t-1}$ ，观察值按接受治疗的逆概率加权，并使用 $Y$ 代表离散结果。
根据这个模型的估计，我想对 ATE 进行有意义的解释。在 MSM 中，报告的系数是否代表 ATE？或者，具有离散结果的 MSM 是否受到与其他离散结果回归模型相同的关注 (心情 2009，Daniel 等人。2020，诺顿等人。2019，长和 Mustillo 2018）？如果是这样，使用 g 计算使用边际结构模型来估计 ATE 是否有意义？我对此不确定。
在 {marginaleffects} 用户指南中，有一个关于 {marginaleffects} 的部分IPW 在使用 avg_comparisons 时，但我想知道这是否仍然在边际结构模型的上下文中起作用。]]></description>
      <guid>https://stats.stackexchange.com/questions/636237/how-to-estimate-interpretable-treatment-effects-using-a-marginal-structural-mode</guid>
      <pubDate>Fri, 05 Jan 2024 14:19:38 GMT</pubDate>
    </item>
    <item>
      <title>寻求应用新方法进行多元数据分析最终项目的建议[关闭]</title>
      <link>https://stats.stackexchange.com/questions/636233/seeking-advice-for-applying-new-methods-for-multivariate-data-analysis-final-pro</link>
      <description><![CDATA[我目前正在研究多元数据分析课程的期末项目，并且正在寻求有关应用过去 20 年论文中介绍的新方法的建议。我介绍了传统技术，例如正态性检验、均值推断、多元方差分析、多响应回归、主成分分析、因子分析、分类和聚类。然而，我正在努力寻找适合我的项目的最新方法。
我的数据集由足球（英式足球）的 Sofascore 数据组成，涵盖过去 5 年英超联赛中的每支球队和球员。这些数据包括各种指标，例如球队名称、球衣号码、进球数、助攻数和防守统计数据。
如果有任何关于符合我的项目要求的特定论文或方法的指导或建议，我将不胜感激。此外，任何有关识别相关多元数据分析方法的有效搜索策略的提示都将非常有帮助。只需搜索“多元数据分析方法”即可产生了太多无关的结果。
预先感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/636233/seeking-advice-for-applying-new-methods-for-multivariate-data-analysis-final-pro</guid>
      <pubDate>Fri, 05 Jan 2024 12:54:20 GMT</pubDate>
    </item>
    <item>
      <title>强制 NN 在状态空间区域中具有固定或恒等输出</title>
      <link>https://stats.stackexchange.com/questions/636230/forcing-nn-to-have-fixed-or-identity-output-in-a-region-of-state-space</link>
      <description><![CDATA[我在状态空间上定义了一个转换系统$X$，
使用转换函数 $f: X \to X$。
让我们假设我的任务是学习一个函数 $G: X\to \mathbb{R}$ 使得 $G $ 正在减少，即 $G(x) &gt; G(f(x))$，在 $X$ 中的转换子集上。我的损失函数具有以下形式：
$$ L(x) = \text{ReLU}\big(G(x) - G(f(x)) + \epsilon\big) $$
对于一些手动定义的 $\epsilon$。
我们还可以使用 sigmoid 而不是 ReLU 来定义 $L$。
我在实验过程中看到的一个案例是
如果我也希望 $G$ 保留 0
在某些转变的两个端点上，
我最终得到的模型总是预测 0。
另外一个案例是
我希望 $f$ 在转换 $x_1 \to x_2$ 时严格减少，
且仅简单递减，即$G(x) \geq G(f(x))$，
在 $x_2 \to x_1$ 上。
使用类似于我上面描述的损失函数
（使用 $\epsilon = 0$ 来编码简单递减），我观察到
我只能包含其中之一
我的训练数据中的 $x_1 \to x_2$ 和 $x_2 \to x_1$ ；
否则，$G$ 无法正确学习
至少在其中一个转换上。
这背后有理论上的机器学习解释吗？
我可以通过使用不同的损失函数来解决这个问题吗？
例如，不是采用 $\text{ReLU}(\dots$) 的形式？
我目前的黑客是
仅包含 $x_1 \to x_2$ 和 $x_2 \to x_1$ 之一
在我的训练数据中；
但这种方法限制了我们
一套相当简单的转换系统。
这个问题来自一个研究项目；
这就是为什么它缺乏上下文并且在某些方面过于简单化。]]></description>
      <guid>https://stats.stackexchange.com/questions/636230/forcing-nn-to-have-fixed-or-identity-output-in-a-region-of-state-space</guid>
      <pubDate>Fri, 05 Jan 2024 11:59:29 GMT</pubDate>
    </item>
    <item>
      <title>仅对出现次数进行算法 AB 测试的统计</title>
      <link>https://stats.stackexchange.com/questions/636228/statistics-of-algorithm-ab-testing-on-occurrences-only</link>
      <description><![CDATA[我进行了 AB 测试，我必须比较数据，但我不知道该使用哪种统计测试。
我会尝试用约会应用程序术语来表达，因为我认为这样更容易理解。
我有一个基于社区的约会应用程序。每个社区都有自己的用户，这些用户只能与该社区的用户进行交互，并根据该社区数据集中的交互创建推荐器。
对于每个社区，在 AB 测试中，用户均等地分为几组（一个用户始终位于一组），并且每个组都有自己的推荐算法。
在约会应用程序术语中，我拥有的信息是两个用户之间的个人资料访问、消息和日期。因此仅跟踪发生的情况。
最终目标：
我想知道是否有一个测试可以仅根据交互发生情况来显示在大多数社区中一种算法是否会比另一种算法产生更多的交互。
尝试过：
我想过使用卡方，但我没有关于缺乏发生的信息，并且我不确定如何将不同的社区纳入其中。]]></description>
      <guid>https://stats.stackexchange.com/questions/636228/statistics-of-algorithm-ab-testing-on-occurrences-only</guid>
      <pubDate>Fri, 05 Jan 2024 10:58:12 GMT</pubDate>
    </item>
    <item>
      <title>多级数据的子样本</title>
      <link>https://stats.stackexchange.com/questions/636227/subsamples-of-multilevel-data</link>
      <description><![CDATA[我们拥有多级结构（学生 - 学校 - 级别）的 PI​​SA 数据。这些学校是随机选择的。在这种情况下，众所周知使用多级方法。考虑到子样本，我们可以对 2 级子样本（例如，来自给定地区的学校）使用多级模型。如果我们想研究 1 级变量（例如性别）的影响，通常的方法是考虑以性别为因素的模型。
我们可以通过使用来自 1 级子样本的多级模型来采取不同的方法吗？例如，仅考虑女学生和男学生，每个子样本一个多级别。
这是方法论错误吗？
谢谢，
大卫]]></description>
      <guid>https://stats.stackexchange.com/questions/636227/subsamples-of-multilevel-data</guid>
      <pubDate>Fri, 05 Jan 2024 10:49:06 GMT</pubDate>
    </item>
    <item>
      <title>配对t检验后我们可以进一步分析组吗？</title>
      <link>https://stats.stackexchange.com/questions/636226/can-we-further-analyse-groups-after-paired-t-test</link>
      <description><![CDATA[我正在进行一组测试前测试后研究。如果我想进一步分析这些群体（男性/女性、城市/农村、年龄类别），我应该进行独立 T 检验分析还是有其他方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/636226/can-we-further-analyse-groups-after-paired-t-test</guid>
      <pubDate>Fri, 05 Jan 2024 10:43:13 GMT</pubDate>
    </item>
    <item>
      <title>提取的方差大于 1（CCA 和冗余分析）</title>
      <link>https://stats.stackexchange.com/questions/636225/extracted-variance-is-above-1-cca-and-redundancy-analysis</link>
      <description><![CDATA[我尝试重复 Stewart 和 Love 1968 的分析，以计算 CCA 的方差提取和冗余指数。根据他们的论文（如果我正确地遵循它），每个规范相关性提取的方差 $R_c$ 是 $\sum_{i =0}^{L}(p_i^2)/L \times R_c ^2$，其中 $p_i$ 是加载组件，L 是装载的长度。对于较小的数据集，提取的方差应为 1（或 100%），因为维数不会改变。然而，我遇到了一个问题，因为第一个组件的负载比 1（例如 3000）大得多，因此，解释的方差远高于 1。
我使用形状为 (7000, 128) 的 X 和形状为 (7000, 32) 的 Y，并投影到 32 维。
这是我使用过的代码
导入 dumpy 作为 np
从 sklearn.cross_decomposition 导入 CCA

暗淡 = 32
cca = CCA(n_components=dim)
cca.fit(X, Y)
X_train_r, Y_train_r = cca.transform(X, Y)
corr = np.corrcoef(X_train_r.T, Y_train_r.T)

规范相关性 = []
cc_squared_lambda = []
对于我在范围内（暗淡）：
    canonical_correlations.append(corr[dim + i][i] )
    cc_squared_lambda.append(
        (corr[dim + i][i] ) * (corr[dim + i][i] )
    ）
    
ve_x = [sum(cca.x_loadings_.T[i] ** 2) / len(cca.x_loadings_.T[i]) for i in range(dim)]
ve_y = [sum(cca.y_loadings_.T[i] ** 2) / len(cca.y_loadings_.T[i]) for i in range(dim)]

标准化
from scipy.stats import zscore
X = zscore(X,ddof=1)

没有改变任何东西
加载示例在这里：
&lt;前&gt;&lt;代码&gt;cca.y_loadings_.T[0]
数组([ 6631.90255789, -20089.44073646, 24966.82137428, -17472.53659417,
       -18221.01590917、-10419.99286959、-18827.78182335、-920.64755629、
         6350.3504796、19091.6876097、20601.59701128、-23153.96945065、
         7172.76198198、6727.43734442、-8236.01820536、19203.38971974、
         5139.47048927、-16393.65319585、-2521.8647585、-25269.42170858、
       -21303.08870837、-17103.39536595、-16719.21073426、6063.37755252、
       -25200.72626919、-10409.71743587、24201.955096、-32194.07699544、
       -12877.95758811、12650.16532332、26514.62449084、-13123.78644931])

在我发现冗余分析的所有示例中，载荷分量大小均小于 1，但是，我不明白为什么应将其限制于此。]]></description>
      <guid>https://stats.stackexchange.com/questions/636225/extracted-variance-is-above-1-cca-and-redundancy-analysis</guid>
      <pubDate>Fri, 05 Jan 2024 10:39:02 GMT</pubDate>
    </item>
    <item>
      <title>与决策树相比，为什么我的神经网络认为不同的特征很重要？</title>
      <link>https://stats.stackexchange.com/questions/636224/why-does-my-neural-network-consider-different-features-important-compared-to-my</link>
      <description><![CDATA[我使用非常相似的数据集构建了一个神经网络和一个决策树（唯一的区别是选择训练集和测试集的随机性）。我的神经网络中具有最高 shapley 值的变量与我的决策树中的顶部节点变量完全不同。这怎么可能？为什么这两个不同的模型会认为不同的变量集很重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/636224/why-does-my-neural-network-consider-different-features-important-compared-to-my</guid>
      <pubDate>Fri, 05 Jan 2024 10:39:00 GMT</pubDate>
    </item>
    <item>
      <title>使用伯努利计算预期进球 (xG)</title>
      <link>https://stats.stackexchange.com/questions/636223/calculate-expected-goals-xg-using-bernoulli</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636223/calculate-expected-goals-xg-using-bernoulli</guid>
      <pubDate>Fri, 05 Jan 2024 10:29:52 GMT</pubDate>
    </item>
    <item>
      <title>观察到的最小可检测效应与初始 MDE 估计之间的差异对解释有何影响</title>
      <link>https://stats.stackexchange.com/questions/636222/what-implications-does-the-discrepancy-between-the-observed-minimum-detectable-e</link>
      <description><![CDATA[假设应用程序的点击率为 5%。新版本可能会改善这一点。假设使用频率论方法。为了估计样本大小，新版本的点击率估计为 6%。因此，这意味着相对 MDE（最小可检测效果）为 20%（5% -&gt; 6%）。使用 https://www.evanmiller.org/ab-testing/sample-size .html 我了解到 A/B 测试每个变体需要 7,663 个样本。
我进行了测试，结果是

&lt;表类=“s-表”&gt;
&lt;标题&gt;

变化
点击次数
非点击
点击率


&lt;正文&gt;

A（对照）
402
7512
5.07%


B（挑战者）
466
7412
5.91%




我将数字输入到 https://www.evanmiller.org/ ab-testing/chi-squared.html 并得出 B 更好，p = 0.0146。
但 MDE 仅 16.5%，因此低于 20% 的初始估计。这对整个 A/B 测试意味着什么？为什么？
我想到的选项：

结果意义重大，应使用新版本，因为 MDE 仅用于初始估计。
结果并不显着，不应使用新版本。

整个测试需要使用较低的 MDE 重新运行（这意味着更大的样本量）。
现有数据可以重复使用和扩展，以扩展到更大的样本量（因为 MDE 较低）。
???


???
]]></description>
      <guid>https://stats.stackexchange.com/questions/636222/what-implications-does-the-discrepancy-between-the-observed-minimum-detectable-e</guid>
      <pubDate>Fri, 05 Jan 2024 10:28:54 GMT</pubDate>
    </item>
    <item>
      <title>绘制几个概率分布[已迁移]</title>
      <link>https://stats.stackexchange.com/questions/636220/plotting-several-probability-distributions</link>
      <description><![CDATA[我想可视化具有不同参数的对数正态概率分布。
我有以下data.frame参数：
 结构(列表(国家/地区 = c(“v1”, “v2”, “v3”, “v4”, “v5”, “v6”,
“v7”、“v8”、“v9”)，平均值＝c(47.57，44.91，47.15，44.44，42.67，
37.84, 37.91, 44.35, 54.76), SD = c(34.97, 34.4, 34.27, 33.92,
34.82, 28.19, 30.18, 33.68, 40.48)), row.names = c(NA, -9L), class = &quot;data.frame&quot;)

此外，使用以下代码，我生成以下图：
# 模拟对数正态分布的数据
设置.种子(123)
num_samples &lt;- 10000 # 选择所需的样本数量
模拟数据 &lt;- lapply(1:9,FUN=function(x)data.frame(kost=rlnorm(num_samples,meanlog =
参数$meanlog_val[x], sdlog = 参数$sdlog_val[x]),country=country[x]))
table_plot&lt;-bind_rows(模拟数据)

ggplot(table_plot,aes(x=kost,fill=国家))+geom_密度(alpha=0.3)+
  主题_经典()


但是，区分不同的形状并不那么容易。也许您知道如何更好地可视化这种差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/636220/plotting-several-probability-distributions</guid>
      <pubDate>Fri, 05 Jan 2024 09:39:33 GMT</pubDate>
    </item>
    </channel>
</rss>