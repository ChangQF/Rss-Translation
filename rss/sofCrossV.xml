<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 29 Nov 2024 09:19:10 GMT</lastBuildDate>
    <item>
      <title>帮我理解为什么卡方检验给出不直观的结果</title>
      <link>https://stats.stackexchange.com/questions/658020/help-me-understand-why-the-chi-square-test-is-giving-unintuitive-results</link>
      <description><![CDATA[我正在对不同年龄组之间的变量分布进行卡方检验。数据如下所示
 a&lt;- c(66,97, 48)
b&lt;- c(145,174,58)
c&lt;- c(129,128,58)

M &lt;- data.frame(cbind(a,b,c))
colnames(M) &lt;- c(&quot;18-34&quot;, &quot;35-49&quot;,&quot;50-66&quot;)
rownames(M) &lt;- c(&quot;Below avg&quot; , &quot;Average&quot;,&quot;Above avg&quot;)
view(M)

绘制时，最年轻组的数据分布与中间组相似，与最年长组不同。

如果我进行整体卡方检验，我会得到一个不显著的差异
X-squared = 8.6905，df = 4，p-value = 0.06932
但是，如果我成对比较年龄组，我会得到最小和中间之间的显著差异，而不是最小和最年长之间的显著差异。
数据：M[，1:2]
X-squared = 6.0153，df = 2，p-value = 0.04941
数据：M3[，c(1, 3)]
X-squared = 5.2093， df = 2，p 值 = 0.07393
我认为这与每个年龄组的参与者数量不平衡有关，尽管每个组的总体观察数量相当大，但我不确定是否以及如何解释它。]]></description>
      <guid>https://stats.stackexchange.com/questions/658020/help-me-understand-why-the-chi-square-test-is-giving-unintuitive-results</guid>
      <pubDate>Fri, 29 Nov 2024 09:07:03 GMT</pubDate>
    </item>
    <item>
      <title>使用 $\beta$ 系数对模型中的特征进行优先级排序</title>
      <link>https://stats.stackexchange.com/questions/658019/prioritization-of-features-in-model-using-beta-coefficients</link>
      <description><![CDATA[我想知道 - 如果您有一个模型，它为您提供了每个变量的 $\beta$ 估计值，但没有 p 值，那么如何优先考虑对结果影响更大的变量？
对于连续变量，我正在考虑考虑系数 &lt;​​span class=&quot;math-container&quot;&gt;$\tilde{\beta}=\beta_X \cdot range(X)$ 或 $\tilde{\beta}=\beta_X \cdot sd(X)$，以消除变量范围与 $\beta$ 估计值之间的高度依赖性。
对于分类变量，我考虑考虑 $\beta$ 本身，因为它们不依赖于变量的范围。
这种方法正确吗？如果正确，如何客观地比较连续变量与分类变量的影响？
谢谢！
我的想法是执行特征选择，他们根据模型中的重要性提供了所选特征的列表。]]></description>
      <guid>https://stats.stackexchange.com/questions/658019/prioritization-of-features-in-model-using-beta-coefficients</guid>
      <pubDate>Fri, 29 Nov 2024 07:59:06 GMT</pubDate>
    </item>
    <item>
      <title>基于专家建议的在线二元决策的下限</title>
      <link>https://stats.stackexchange.com/questions/658018/lower-bound-for-online-binary-decision-making-with-expert-advice</link>
      <description><![CDATA[假设我们想要根据 $k$ 位专家的建议，对 $n$ 个二元决策进行排序。我们根据从其处获得建议的最佳专家来定义遗憾。现在我想证明我们将至少享受 $\Omega(m)$ 个遗憾，其中 $m=\min \{n,\log k\}$。当 $n&gt;\log k$ 时，情况对我来说很清楚，但对于其他情况，我不知道该如何进行。]]></description>
      <guid>https://stats.stackexchange.com/questions/658018/lower-bound-for-online-binary-decision-making-with-expert-advice</guid>
      <pubDate>Fri, 29 Nov 2024 07:51:02 GMT</pubDate>
    </item>
    <item>
      <title>带有插值数据的回归模型？</title>
      <link>https://stats.stackexchange.com/questions/658017/regression-models-with-interpolated-data</link>
      <description><![CDATA[我有一个国家，里面有很多城市（层级结构：国家-省-城市）。我只有 2010 年和 2020 年每个城市的平均社会经济信息（例如就业率、中位数收入等）。
2016 年举行了选举。我知道从 2010 年到选举期间每个城市的政治倾向，以及选举后政治倾向的变化。
我想建立一个回归模型，研究社会经济条件的变化如何影响投票选择（我知道生态谬误，我只对研究总体趋势感兴趣，而不是将其推广到总体中的个人）。
如果我每年都有数据，我会尝试使用一些技术，例如差异差异或回归不连续性，以查看选举前后的情况。但是，就我而言，这不可用。
我对该怎么做有这个天真的想法。

我认为我可以创建一个基于增长率的插值回归模型。我首先假设每个社会经济变量有一个简单的纵向模型（假设它只依赖于自身而不依赖于其他因素，遵循单调/均匀变化的线性增长）：

$$ \frac{x_{i,2020} - x_{i,2010}}{x_{i,2010}} = \alpha_0 + u_{px} + v_{ix} + \epsilon_{ix} $$
其中：

$\alpha_0$ 是所有城市的平均增长率
$u_{px}$ 是各省与平均增长率的偏差
$v_{ix}$ 是城市与其所在省份增长率的偏差
$\epsilon_{ix}$ 是误差项

现在，对于 2010 年至 2020 年之间任何时间 $t$ 的插值，我们想要计算到时间 $t$ 时应该发生的总变化的百分比。公式变为：
$$ \hat{x}_{it} = x_{i,2010}\left(1 + \frac{t-2010}{10}(\alpha_0 + u_{px} + v_{ix})\right) $$
例如具体计算：
$$ \hat{x}_{i,2015} = x_{i,2010}\left(1 + \frac{2015-2010}{10}(\alpha_0 + u_{px} + v_{ix})\right) $$
$$ \hat{x}_{i,2015} = x_{i,2010}\left(1 + \frac{5}{10}(\alpha_0 + u_{px} + v_{ix})\right) $$
$$ \hat{x}_{i,2015} = x_{i,2010}(1 + 0.5(\alpha_0 + u_{px} + v_{ix})) $$

从这里我将转换概率 $\pi_{ijk}$ 定义为城市 $i$ 从 2015 年的政治归属 $j$ 转变为 2016 年的政治归属 $k$ 的概率。我想到这个转换样式模型：

$$ \log\left(\frac{\pi_{ijk}}{\pi_{ijJ}}\right) = \beta_{jk0} + \theta_{jk}&#39;\mathbf{w}_i + u_{pjk} $$
其中：

$\mathbf{w}_i$ 是一个包含社会经济预测因子的向量：
$$ \mathbf{w}_i = \begin{bmatrix} \hat{x}_{i,2016} \\ \hat{z}_{i,2016} \\ (\hat{x}_{i,2016} - \hat{x}_{i,2015}) \end{bmatrix} $$
$\theta_{jk}$ 是一个特定于过渡的系数向量
$\beta_{jk0}$ 是从状态 $j$ 到 $k$ 的基线转换概率&gt;
$J$ 表示参考类别
$u_{pjk}$ 是从 $j$ 到 $k$ 转换的省份特定随机效应。

我感觉我的建模方法完全失败了，哈哈。插值值有误差，而第二步没有考虑到这个误差。我确信这里有很多问题。有人能告诉我我到底搞砸了多少吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658017/regression-models-with-interpolated-data</guid>
      <pubDate>Fri, 29 Nov 2024 05:34:47 GMT</pubDate>
    </item>
    <item>
      <title>置信区间 - CLT，初级水平</title>
      <link>https://stats.stackexchange.com/questions/658015/confidence-interval-clt-begginer-level</link>
      <description><![CDATA[我正在参加一个关于统计学的在线课程，更准确地说是关于置信区间的课程。
下面是一个练习，他们试图根据以前收集的数据估计每个月份可以出售的鞋子数量。
如下图所示，第 7 行代表月份，B 列代表鞋子尺码。
表格表示频率分布。

1- 如果我们取鞋子尺码 6（第 8 行），他们计算出的置信区间在 [1.8-4.04] 之间。
据我所知，我知道置信区间仅在正态分布上计算。但我看不出鞋子尺码 6 的分布表如何形成正态分布？
我说得对吗？
我知道，如果样本分布不正常，我们可以使用 CLT，即具有正态分布的样本的平均值。是否可以将其应用于 6 号鞋子（第 8 行）？

2- 为什么要计算标准误差？我以为标准误差仅适用于均值样本（CLT），而第 8 行中的数据不是样本均值，而是正态分布。

此外，标准误差公式的分母代表样本均值的数量，但事实并非如此。
有人可以澄清一下歧义吗？
谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/658015/confidence-interval-clt-begginer-level</guid>
      <pubDate>Fri, 29 Nov 2024 02:32:37 GMT</pubDate>
    </item>
    <item>
      <title>时间序列-线性滤波模型</title>
      <link>https://stats.stackexchange.com/questions/658014/time-series-linear-filter-model</link>
      <description><![CDATA[我正在研究时间序列中的线性滤波模型。
“线性滤波模型。一个可观察的时间序列 𝑧𝑡，其中连续值高度相关，通常可以被视为由一系列独立的“冲击”𝑎𝑡 产生的。这些冲击是从固定分布中随机抽取的，通常假设为正态分布，均值为零，方差为 𝜎2 𝑎。这种独立随机变量序列 𝑎𝑡、𝑎𝑡-1、𝑎𝑡-2、……称为白噪声过程。白噪声过程 𝑎𝑡 应该通过所谓的线性滤波器转换为过程 𝑧𝑡。线性滤波操作只是对先前的随机冲击𝑎𝑡取加权和，因此𝑧𝑡 = 𝜇 + 𝑎𝑡 + 𝜓1𝑎𝑡−1 + 𝜓2𝑎𝑡−2 + ⋯ = 𝜇 + 𝜓(𝐵)𝑎𝑡 (1.2.1) 一般来说，𝜇 是决定过程“水平”的参数，𝜓(𝐵)=1+ 𝜓1𝐵 + 𝜓2𝐵2 + ⋯ 是将𝑎𝑡 转换为𝑧𝑡的线性算子，被称为滤波器的传递函数。模型表示可以允许过程 {𝑧𝑡} 的值之间存在一系列灵活的依赖模式，这些依赖模式以独立（不可观察）随机冲击 𝑎𝑡 的形式表示。从理论上讲，权重形成的序列 𝜓1、𝜓2、… 可以是有限的，也可以是无限的。如果这个序列是有限的，或者是无限的，并且绝对可求和，即 ∑∞ 𝑗=0 |𝜓𝑗| &lt; ∞，则称滤波器是稳定的，过程 𝑧𝑡 是平稳的。参数 𝜇 是过程变化的平均值。否则，𝑧𝑡 是非平稳的，𝜇 除了作为过程水平的参考点之外没有特定含义。&quot;
根据共享的细节，我不确定这是否与移动平均模型相同。即使是 p 阶 MA 模型也是基于白噪声系数的线性组合。
MA 模型和线性滤波器模型之间到底有什么区别？请指教。]]></description>
      <guid>https://stats.stackexchange.com/questions/658014/time-series-linear-filter-model</guid>
      <pubDate>Fri, 29 Nov 2024 02:02:48 GMT</pubDate>
    </item>
    <item>
      <title>应使用哪种显著性检验来检验均值差异？如何确定？</title>
      <link>https://stats.stackexchange.com/questions/658011/which-significance-test-to-use-for-a-difference-of-means-how-to-be-sure</link>
      <description><![CDATA[我对统计学和 R 语言还很陌生，这个问题出现在我的学习中（自学）。我下面的想法正确吗？我的学习感觉很杂乱，也许我需要一些指导。许多在线视频并没有介绍使用任何重要性检验需要满足的假设，也没有介绍当假设不满足时该怎么做。
我有两个数据集，其中包含这项运动在美国进行的所有官方记录比赛。一个数据集是女子队的，另一个是男子队的。我想测试男子队是否平均得分更高，我相信他们得分更高。
从数据集中，我将比赛限制为过去二十年的比赛，并且仅限于锦标赛比赛。这给出了大约 200 场比赛的女子样本和大约 300 场比赛的男子样本。我假设比赛在性别内是相互独立的，而不是在性别之间配对的。
然后我合并数据集并添加性别列。因此，这个新数据集有大约 500 行，其中有一列表示比赛/行是男子比赛还是女子比赛。
重要性水平：5%
零假设：均值之间没有差异。
备选假设：男性平均得分高于女性平均得分。
我现在在 R 中复制/模拟（？）这个数据集 5000 次，每次计算女性和男性的平均得分，然后取差值。我认为这个差值就是我所谓的检验统计量，我认为所有这 5000 个都可以用来可视化零分布。
在 R 中绘制所有这些差异会显示一个钟形直方图。我相信这是零分布的图，因此假设差异为 0。
因此：观测值是独立的，每组 200 和 300 个样本的数据集足够大，并且检验统计量遵循正态分布。因此，我可以使用非参数方差分析检验来获取 p 值。此检验不要求零分布为正态。但我认为我也可以使用双样本 t 检验，因为事实上，我的底层/零分布是正态的、独立的和大的。
此外，每次我计算 p 值时，它都是不同的，因为每个 p 值都基于一组新的 5000 次模拟。我发现这很可疑，因为看起来有时我会拒绝零假设，有时不会。]]></description>
      <guid>https://stats.stackexchange.com/questions/658011/which-significance-test-to-use-for-a-difference-of-means-how-to-be-sure</guid>
      <pubDate>Fri, 29 Nov 2024 00:11:48 GMT</pubDate>
    </item>
    <item>
      <title>基于秩的非参数极值假设检验</title>
      <link>https://stats.stackexchange.com/questions/658008/nonparametric-extrema-hypothesis-test-based-on-ranks</link>
      <description><![CDATA[是否存在一个非参数检验来检验以下假设：
给定 $\mathbb{R}^m$ 中的 $N$ 个点，以及它们在 $\mathbb{N}$ 中的排名 $Y$，答案：
$H_0：$ 点集中没有最小值或最大值（极值）
$H_a：$ 点集中存在最小值或最大值（极值）
即是否存在能够区分这两张图片的测试：
在这张图片上有一个明确的最小值，并且邻近点（低排名聚集在附近）支持这一事实

在这张图片上没有最小值，这些点只是随机的（低排名的点没有聚集在附近并且分散）

理想情况下，测试应该在 1-D 以上范围内进行，是非参数的并且仅基于排序。不对基础数据的形状做任何假设]]></description>
      <guid>https://stats.stackexchange.com/questions/658008/nonparametric-extrema-hypothesis-test-based-on-ranks</guid>
      <pubDate>Thu, 28 Nov 2024 23:25:10 GMT</pubDate>
    </item>
    <item>
      <title>一阶矩有限性的充分条件</title>
      <link>https://stats.stackexchange.com/questions/658007/sufficient-conditions-for-finiteness-of-first-moment</link>
      <description><![CDATA[考虑一个随机变量 $X$，使得
$$
(1)\quad E(\exp(\beta X))&lt;\infty
$$
其中 $\beta&gt;0$。你能帮我证明这意味着
$$
(2)\quad E(|X|)&lt;\infty
$$
我不确定从哪里开始，而且我缺乏关于为什么这是正确的基本直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/658007/sufficient-conditions-for-finiteness-of-first-moment</guid>
      <pubDate>Thu, 28 Nov 2024 23:15:13 GMT</pubDate>
    </item>
    <item>
      <title>对于满足 LLN 和 CLT 的非 IID 数据，EDF 是否收敛？</title>
      <link>https://stats.stackexchange.com/questions/657989/does-the-edf-converge-for-non-iid-data-that-satisfy-lln-and-clt</link>
      <description><![CDATA[对于 IID 数据，经验分布函数 (EDF) 已知会收敛，这是由于 Glivenko-Cantelli 定理，该定理保证 EDF 均匀收敛到真实累积分布函数 (CDF)。
如果数据是非 IID 的但仍满足大数定律 (LLN) 和中心极限定理 (CLT)：

EDF 还会收敛吗？
如果会，在什么类型的收敛下（例如，在概率上，弱收敛）？

寻找将 EDF 收敛推广到满足 LLN 和 CLT 的非 IID 数据的见解或参考。]]></description>
      <guid>https://stats.stackexchange.com/questions/657989/does-the-edf-converge-for-non-iid-data-that-satisfy-lln-and-clt</guid>
      <pubDate>Thu, 28 Nov 2024 16:28:34 GMT</pubDate>
    </item>
    <item>
      <title>使用多个解释变量和响应变量进行元分析效应大小计算</title>
      <link>https://stats.stackexchange.com/questions/657988/meta-analysis-effects-size-calculation-with-multiple-explanatory-and-response-va</link>
      <description><![CDATA[在 R 中工作。
我有一个包含 60 多个研究和 200 多个站点的数据集。
我想计算每个解释变量对我的每个响应变量的影响大小 (Hedges G&#39;)。
数据摘录自同行评审文献。
解释变量是数字 (Ph、温度、降水量、容重、C:N 比、土壤碳含量、地下水位) 和分类 (排水状况、土地覆盖、以前的土地覆盖、植被类型) 的混合，响应变量是 N2O、CH4 和 CO2 排放量。没有一项研究包含所有变量的数据，这些单元格中填充了真正的 NA。
我可以从一个表中完成所有这些操作，还是需要为 x 和 y 的每个组合创建一个表？
即。我是否需要一个单独的表格来计算 Ph 对 N2O 排放的影响大小，然后计算 C% 对 N2O 等的影响大小，并重复计算我的其他两个响应变量？
此外，我的一些研究只有一个条目（例如进行测量的一个站点），这些适合纳入吗？
干杯]]></description>
      <guid>https://stats.stackexchange.com/questions/657988/meta-analysis-effects-size-calculation-with-multiple-explanatory-and-response-va</guid>
      <pubDate>Thu, 28 Nov 2024 16:08:45 GMT</pubDate>
    </item>
    <item>
      <title>比较完成一项工作所需的时间</title>
      <link>https://stats.stackexchange.com/questions/657981/comparing-the-time-duration-to-do-a-job</link>
      <description><![CDATA[我需要比较两个不同工人完成生产操作的时间长度。
基本上，原材料被分成两个独立的组：一组物体将由工人 A 使用旧机器加工，每次加工需要一定数量的可变分钟数，而第二组物体由工人 B 使用新机器加工，每次加工也需要一定数量的可变分钟数。
然后我将得到两组数字：第一组是使用旧机器生产物体的测量时间，第二组是使用新机器生产物体的测量时间。
我应该使用什么统计测试来检查新机器的加工时间是否显著不同，因为时间分布可能不正常？]]></description>
      <guid>https://stats.stackexchange.com/questions/657981/comparing-the-time-duration-to-do-a-job</guid>
      <pubDate>Thu, 28 Nov 2024 13:38:32 GMT</pubDate>
    </item>
    <item>
      <title>神经网络使用反向传播可以学习布尔公式吗？</title>
      <link>https://stats.stackexchange.com/questions/657961/learnability-of-boolean-formulae-by-neural-networks-using-back-propagation</link>
      <description><![CDATA[我一直在研究神经网络和布尔公式。从我的努力来看，神经网络似乎通常无法使用反向传播来学习布尔公式。这在直觉上是有道理的，因为布尔公式的输出可以根据输入值表现出巨大的变化，因此会有很多不连续性，从而导致局部最优。
另一方面，我也明白，任何布尔公式都可以用神经网络来表示，根据通用近似定理，所以神经网络没有内在原因不能表示，因此可能学习任意的布尔公式。问题似乎出在学习算法上，所有通用的机器学习算法似乎都会陷入局部最优，无论我使用梯度下降、进化算法、期望最大化等，因为它们都基于局部增量改进是通向全局最优解的途径这一前提。
话虽如此，我也知道还有其他类型的算法，如 Quine-McCluskey 和 Espresso，它们可以从真值表中得出最小布尔公式。可以使用这些算法随后生成一个神经网络，该神经网络嵌入从真值表中得出的算法的最小布尔公式。或者，更简单，只需将真值表转换为神经网络。然而，据我所知，这些都是非常具体的算法，专门针对布尔公式，在更通用的机器学习环境中没有使用。
所以，这让我想到了我的问题。是否有任何证据表明神经网络能够或不能使用反向传播和梯度下降或任何其他通用机器学习算法来学习任意布尔公式？
我检查了 Cross Validated，并在 Google 上搜索了这个问题，但未能找到任何明确的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/657961/learnability-of-boolean-formulae-by-neural-networks-using-back-propagation</guid>
      <pubDate>Thu, 28 Nov 2024 01:09:53 GMT</pubDate>
    </item>
    <item>
      <title>需要使用结束标记来使 Ngram 模型正确</title>
      <link>https://stats.stackexchange.com/questions/657932/end-tokens-are-required-to-make-ngram-models-proper</link>
      <description><![CDATA[标准二元模型（例如定义于此处）基于以下原则在语料库$V$上定义概率分布：

单词$w$的边际概率定义为其在$V$中的计数除以$V$中的单词总数（计算重复次数）：$P(w) = \text{count}(w) / |V|$
一个单词跟随另一个单词的条件概率直观地定义为二元组计数与第一个单词计数之比：$p(w_2|w_1) = \text{count}(w_1 w_2) / \text{count}(w_1)$
（马尔可夫假设）：一个句子（一个单词序列）的概率可以通过链式法则计算：$p(w_1 w_2 ... w_n) = p(w_1) p(w_2|w_1) p(w_3|w_1 w_2)... \approx p(w_1) p(w_2|w_1) p(w_3|w_2) ...$

然而，这似乎并没有定义一个适当的概率分布。例如，取一个语料库 $V = \text{&quot;foo bar baz&quot;}$。然后，取所有可能的二元组上定义的联合分布 $w_1 w_2$。根据我们的原则：
\begin{equation}
p(w_1 w_2) = p(w_1) p(w_2|w_1) = [\text{count}(w_1) / 3][\text{count}(w_1 w_2) / \text{count}(w_1)]
\end{equation&gt;
如果 $w_1 w_2$ 不在语料库中，则显然 $p(w_1 w_2) = 0$。因此，联合分布中唯一非零的条目是 $p(\text{foo bar}) = p(\text{bar baz}) = 1/3$。这些的总和是$2/3 \neq 1$，那么这种分配是否不合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/657932/end-tokens-are-required-to-make-ngram-models-proper</guid>
      <pubDate>Wed, 27 Nov 2024 13:18:18 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在处理一个重复测量数据集，需要进行降维。在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法涉及以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 之间的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除非数字变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不均等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    </channel>
</rss>