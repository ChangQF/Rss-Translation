<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 02 Jan 2024 00:59:14 GMT</lastBuildDate>
    <item>
      <title>为什么attention中卷积层的最大路径长度$O(n/k)$就足够了？</title>
      <link>https://stats.stackexchange.com/questions/635979/why-is-the-maximum-path-length-for-convolutional-layer-on-k-in-attention-is</link>
      <description><![CDATA[在表 1 第三行中提到了这一点。为什么是$O(n/k)$？以 9 个标记中的 2 个标记的 1d 卷积为例，步长 $1$。它不会是 $n/k$ 或 $9/2=4.5$ 而是大约$n-1$ 或 $8$。
这篇论文没有提到跨步，所以我认为它适用于任何跨步。
来自论文：
内核宽度 k &lt; 的单个卷积层n 不连接所有输入输出对
职位。 在连续内核的情况下，这样做需要一堆 O(n/k) 卷积层，
或 O(logk(n)) 在扩张卷积的情况下 [18]，]]></description>
      <guid>https://stats.stackexchange.com/questions/635979/why-is-the-maximum-path-length-for-convolutional-layer-on-k-in-attention-is</guid>
      <pubDate>Mon, 01 Jan 2024 23:33:15 GMT</pubDate>
    </item>
    <item>
      <title>如何对收入四分位数进行回归？</title>
      <link>https://stats.stackexchange.com/questions/635977/how-do-i-regress-income-quartiles-against-each-other</link>
      <description><![CDATA[我想了解不同收入四分位数的态度是否有所不同。我的主管提到了虚拟编码和四分位数相互回归，但是，我有点不知道如何做到这一点。
我是否只需将每个受访者编码为四分位数的变量作为多元回归中的预测变量（与其他人口统计控制一起？）或者我是否必须运行单独的回归，将每个虚拟编码四分位数与最低参考四分位数进行比较。&lt; /p&gt;
但是，如果这是错误的方法，我愿意接受建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/635977/how-do-i-regress-income-quartiles-against-each-other</guid>
      <pubDate>Mon, 01 Jan 2024 21:16:23 GMT</pubDate>
    </item>
    <item>
      <title>我如何知道我的数据是否更适合幂曲线或对数曲线？</title>
      <link>https://stats.stackexchange.com/questions/635975/how-can-i-know-if-my-data-better-fits-a-power-or-a-log-curve</link>
      <description><![CDATA[我有两个数组，分别代表某个实验（1000 个样本）中的自变量和因变量。我想知道它们之间的函数关系。具体来说，我想在这两个选项之间做出决定：

对数关系：$y = a * log^b(x) + c$。
幂关系：$y = a * x^b + c$。

我使用 scipy.curve_fit 函数如下。对于对数关系：
fit_func = lambda x,a,b,c: a * (np.log(x))**b + c
popt, pcov = curve_fit(fit_func, x, y)
plt.plot(x, fit_func(x, *popt))

对于幂关系：
fit_func = lambda x,a,b,c: a * x**b + c
popt, pcov = curve_fit(fit_func, x, y)
plt.plot(x, fit_func(x, *popt))

在这两种情况下，绘图与原始数据（y 与 x）的绘图都很好地重叠。这些是我得到的值：

对于对数曲线：[a,b,c] = [0.02520347 3.43184802 1.88396929]
对于功效曲线：[a,b,c] = [ 0.70305951 0.49492494 -0.09505299]

根据这些图，我无法决定哪个模型能更好地描述数据。
有没有更好的方法来判断对数模型和幂模型哪个更好？]]></description>
      <guid>https://stats.stackexchange.com/questions/635975/how-can-i-know-if-my-data-better-fits-a-power-or-a-log-curve</guid>
      <pubDate>Mon, 01 Jan 2024 20:37:33 GMT</pubDate>
    </item>
    <item>
      <title>通过残差平方回归估计方差</title>
      <link>https://stats.stackexchange.com/questions/635974/estimating-variance-by-regressing-squared-residuals</link>
      <description><![CDATA[对于线性回归，估计新观测值的预测范围的一种方法是计算新观测值的预测区间。
如果将残差平方与初始预测变量进行回归会怎样？这是估计新观察方差的另一种方法吗？如果不是，那么该回归实际预测的是什么？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635974/estimating-variance-by-regressing-squared-residuals</guid>
      <pubDate>Mon, 01 Jan 2024 19:44:39 GMT</pubDate>
    </item>
    <item>
      <title>什么研究的统计模型（如果有）适合此应用？</title>
      <link>https://stats.stackexchange.com/questions/635973/what-studied-statistical-model-if-any-fits-this-application</link>
      <description><![CDATA[我无法确定哪种统计模型或方法适合我的应用程序。
我的情况如下：
我想创建一个股票交易代理，根据一段时间内收到的报价数据来交易单个股票-现金对。
为了简单起见：

如果代理人只持有现金，他们可以采取的行动是购买 1 单位股票或什么也不做。
如果代理商持有现金和股票或仅持有股票，他们可以采取的行动是不采取任何行动或出售该单位股票。
如果代理商没有持有现金和股票，则代理商唯一可以采取的行动就是不采取任何行动。

我将使用的符号是这样的：

$t_0, t_1 \in \mathbb{R}_{\geq 0}$：分别是第一和第二订单簿更新的时间。 

$\mathbb{B}_0, \mathbb{B}_1 \in ({\mathbb{R}_{\geq 0}})^4$ ：分别在 $t_0$ 和 $t_1$ 接收的报价数据。

$v_0, v_1 \in \mathbb{R}_{\geq 0}$：$t_0$ 和 $t_1$ 分别。

$w_0, w_1 \in \mathbb{R}_{\geq 0}$：$t_0$ 和 $t_1$ 分别。

$L(.,.,.)$表示根据当前报价数据、当前持有现金和当前持有的资产的清算价值库存


单周期设置如下：

代理观察 $o_0 = (t_0,\mathbb{B}_0, v_0, w_0)$
智能体选择一个动作$a_0^* \in \mathcal{A}_0$（这个决定可能是通过对时间的预测来通知的）下一个报价，$\hat{t_0}$，下一个报价的预测，$\hat{\mathbb{B }_{1}}$，以及对 $t_1$ 中因任何 $a_0 \in \mathcal{A}_0$、$\hat{v_1}_{|a_0}$ 和 $\hat{w_1}_{|a_0}$，对于所有 $a_0 \in \mathcal{A}_0$ .
代理观察 $o_1 = (t_1,\mathbb{B}_1, v_1, w_1)$
代理接收 $l_0 = L(\mathbb{B}_1, v_1, w_1) - L(\mathbb{B}_0, v_0, w_0)$ （观察到 $o_0$ 时获取 $a_0$ 所得的利润，然后 $o_1$ 正在被观察）。

我的直觉表明某种马尔可夫决策过程适合于此，但我不确定，因为即使有很大程度上简化的假设（对于小订单来说可能大多如此）$a_0$ 不会影响 $\mathbb{B}_1$，我们仍然需要考虑 $a_0$ 将影响 $v_1$ 和 $w_1$ （例如，如果我们决定以 $t_0$ 购买一单位股票，这很可能会影响 $v_1$ 和 $w_1$) 即使我们做一些简单的事情，例如假设它仅确定性地基于当前报价， $\mathbb{B} _0$ （$t_0$ 和 $t_1$ 之间“没有发生任何事情”尊重报价数据），我们仍然需要为每个潜在的操作进行建模。
整个过程的目标是找到 $o_1$ 的函数，该函数在 $\mathcal 中输出操作{A}_0$ 最小化 $l_0$。
是否有一个我可以研究的此类问题的通用版本的名称，或者是否有一种简化其部分内容的方法，以便我可以将其放入更深入研究的框架中？]]></description>
      <guid>https://stats.stackexchange.com/questions/635973/what-studied-statistical-model-if-any-fits-this-application</guid>
      <pubDate>Mon, 01 Jan 2024 19:27:19 GMT</pubDate>
    </item>
    <item>
      <title>评分数据和 IRT 模型</title>
      <link>https://stats.stackexchange.com/questions/635972/score-data-and-irt-models</link>
      <description><![CDATA[我计划使用 IRT 模型（二进制数据）对我的考试数据进行建模。考试包含有四个可选答案（一个正确）的问题，但考试系统仅提供二进制数据（正确/错误，IT 部门不会/无法向我提供原始数据）。因此，猜测正确答案的概率不是 0.5，而是 0.25。当最初有四种替代方案时，我如何/必须使用二进制 IRT 模型更改我的模型？我正在使用 R 包“ltm”。
珍妮]]></description>
      <guid>https://stats.stackexchange.com/questions/635972/score-data-and-irt-models</guid>
      <pubDate>Mon, 01 Jan 2024 18:19:44 GMT</pubDate>
    </item>
    <item>
      <title>将常数乘以特征对回归系数的影响[重复]</title>
      <link>https://stats.stackexchange.com/questions/635968/effect-on-regression-coefficients-by-multiplying-a-constant-to-a-feature</link>
      <description><![CDATA[我在 Coursera 上解决一个测验问题，发现了一个有趣的问题。
&lt;块引用&gt;
如果将给定特征的值加倍（即特定列）
特征矩阵），最小二乘估计会发生什么
其他每个特征的系数？ （假设你没有其他
依赖于加倍特征的特征，即没有交互
条款）。

我的问题是：

我认为，其他系数将保持不变。如果是这样，有人可以告诉我其背后的逻辑解释吗？
缩放后的特征的系数怎么样？假设我们将功能加倍且现有权重为 $m$，它是否等于 $m/2$ ？
如果还包含交互术语怎么办？那里会发生什么？

因此，总的来说，我可以说回归系数与原点的变化无关，但与规模无关。这是正确的吗？如果我们移动，系数保持不变。然而，当我们缩放系数时，系数会改变吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635968/effect-on-regression-coefficients-by-multiplying-a-constant-to-a-feature</guid>
      <pubDate>Mon, 01 Jan 2024 16:43:10 GMT</pubDate>
    </item>
    <item>
      <title>如何处理缺失的纵向结果和纵向协变量？</title>
      <link>https://stats.stackexchange.com/questions/635967/how-to-deal-with-missing-longitudinal-outcome-and-longitudinal-covariate</link>
      <description><![CDATA[我有具有连续纵向结果的数据，其中一个协变量是分类纵向变量。两者皆有失踪，同时被收集。因此，这意味着如果结果缺失，协变量也会缺失。
我的问题如下：

如果协变量存在缺失，直接似然是否仍然无偏？
如果我使用链式方程（SAS 中的 fcs 或 R 中的 mouse）进行多重插补，我是否应该在纵向结果之前首先插补缺失的纵向协变量？这样做可以吗？还是一次性将它们归结到一起更好？
]]></description>
      <guid>https://stats.stackexchange.com/questions/635967/how-to-deal-with-missing-longitudinal-outcome-and-longitudinal-covariate</guid>
      <pubDate>Mon, 01 Jan 2024 16:31:36 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的梯度下降（反向传播）实际上是如何工作的？</title>
      <link>https://stats.stackexchange.com/questions/635966/how-does-gradient-descentback-propagation-in-neural-networking-actually-work</link>
      <description><![CDATA[我绝对是这个领域的初学者。目前正在Andrew Ng的指导下学习Course时代的监督机器学习。我已经进入该续集第二门课程的第二周了。
我实际上对反向传播感到困惑。我了解反向传播的理论知识，它基本上是微分的链式法则，并存储中间导数以查找先验导数，与传统过程相比，这节省了很多迭代和时间。但我无法完全理解反向传播如何集成到梯度下降中。
让我详细阐述一下我的困惑，然后我希望你能明白我所陷入的困境。
假设网络中有 1 个隐藏层。所以总共有 3 层：初始层、隐藏层和最终层。我知道这里我们分配随机权重和偏差。但是我们如何评估梯度下降呢？我的意思是，在线性回归的情况下，我们已经看到权重和偏差随着学习率和成本函数导数相对于权重/偏差的关联而变化。$$w_1 = w_1- \alpha*\frac{d}{dw_1}J$$ 其中 J 是成本函数。神经网络也会发生同样的事情吗？
我的意思是 $$w^3 = w^3 - \alpha*\frac{d}{dw^3}J$$$$w^2_n = w^2_ n - \alpha*\frac{d}{dw^2_n}J$$ 其中 $w^ 3=&gt;$第三层的权重和$w^2_n=&gt;$第二层第n个单元的权重]]></description>
      <guid>https://stats.stackexchange.com/questions/635966/how-does-gradient-descentback-propagation-in-neural-networking-actually-work</guid>
      <pubDate>Mon, 01 Jan 2024 15:58:27 GMT</pubDate>
    </item>
    <item>
      <title>使用对数正态分布拟合数据（最大似然估计）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635963/fitting-the-data-using-lognormal-distribution-maximum-likelihood-estimation</link>
      <description><![CDATA[我正在尝试编写一个代码，使用最大似然估计对数正态分布的参数（平均值，标准差）。
我的目标是给定xdata，对数正态分布应该具有给定数组ydata的概率。
我相信我在定义似然函数时犯了一些错误。
这是我现在使用的代码：
ydata = np.array([0.03, 0.832])
xdata = np.array([0.5, 0.7])
im_log = np.log(xdata)

# 打印结果的格式
FORMAT_STRING = “{:&lt;20}{:&lt;20}{:&lt;20}”
打印（FORMAT_STRING.format（“sigma”，“beta”，“log_likelihood_sum”））

def neg_log_likelihood_sum(params, im_l):
    西格玛, 贝塔 = 参数

    # 计算正态分布的累积分布函数（CDF）
    fragility_curve = stats.norm(np.log(sigma), beta).cdf(im_l)

    # 计算可能性
    可能性 = ydata-fragility_curve

    # 计算对数似然
    log_likelihood = np.log(可能性)

    # 计算负对数似然
    neg_log_likelihood = np.sum(log_likelihood)

    print(f&quot;sigma: {sigma}, beta: {beta}, neg_log_likelihood_sum: {neg_log_likelihood}&quot;)
    返回-neg_log_likelihood

# 使用partial修复im_l参数
neg_log_likelihood_sum_partial = 部分(neg_log_likelihood_sum, im_l=im_log)

# 显式使用优化模块
res = optimize.minimize(neg_log_likelihood_sum_partial, x0=(1.3, 0.4), method=“Nelder-Mead”)

打印（解析）
x = np.linspace(0, 10, 100)
y = stats.norm(np.log(res[&quot;x&quot;][0]), res[&quot;x&quot;][1]).cdf(np.log(x))
# 绘制数据、拟合曲线和分布
plt.plot(xdata, ydata, &#39;go&#39;, label=&#39;数据&#39;)
plt.plot(x, y, label=&#39;脆弱性曲线（估计参数）&#39;)
plt.图例()
plt.xlabel(&#39;输入变量&#39;)
plt.ylabel(&#39;输出变量&#39;)
plt.title(&#39;拟合曲线和脆性曲线&#39;)
plt.show()
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/635963/fitting-the-data-using-lognormal-distribution-maximum-likelihood-estimation</guid>
      <pubDate>Mon, 01 Jan 2024 14:15:27 GMT</pubDate>
    </item>
    <item>
      <title>pinouin 库中两个样本 t 检验允许的最大样本量是多少？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/635959/what-is-the-maximum-allowed-sample-size-for-two-sample-t-test-in-pingouin-librar</link>
      <description><![CDATA[我目前正在运行测试来比较新旧机器的性能时间。处理大量数据集（超过 50,000 条记录），这使得新机器速度更快。此前，我进行过类似的测试，但在某些技术方面缺乏清晰度。因此，我选择了曼惠特尼 U 检验，为假设得出二元结果。
我投入了专门的时间来学习和更好地理解基础知识，因此我正在使用不同时期的相同数据集重新进行测试。这次我的目标是通过考虑新机器相对于旧机器的百分比改进，并考虑数据的规模和特征来执行更稳健的分析。我正在考虑使用 Pingouin 库中的双样本 t 检验，该库以其输出中提供置信区间而闻名，并且适合中心极限定理下的大样本量。
我发现的信息表明，虽然 t 检验适合较小的样本量（例如 30 个或更少），但 z 检验更适合较大的样本（例如 30 个或更多）。但是，我不确定这是否适用于 Pingouin 中如此大的样本的 ttest 函数，因为该库没有 ztest 函数。如何知道我是否可以自信地利用 Pinouin 的 ttest 来处理如此大的样本量？任何意见、建议、推荐都会非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/635959/what-is-the-maximum-allowed-sample-size-for-two-sample-t-test-in-pingouin-librar</guid>
      <pubDate>Mon, 01 Jan 2024 13:26:30 GMT</pubDate>
    </item>
    <item>
      <title>我试图理解一篇研究论文，但我无法理解 https://ieeexplore.ieee.org/document/9527655 中方程的工作原理 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635947/im-trying-to-understand-a-research-paper-but-i-couldnt-understand-the-working</link>
      <description><![CDATA[在本文中，他们使用模型方程在未标记的目标数据集中学习，如图所示，方程的工作原理对我来说并不清楚，而且第一次馈送是如何进行的对源数据进行 resnet，然后分别定位数据，帮助模型提高其性能。当他们尝试拉出训练图像中的每个图像时，他们会将所有图像彼此分开，然后使相似的图像更接近。我已经理解他们想要做什么，但无法理解图像中显示的数学公式。我会建议那些给出答案的人请浏览一次研究论文。我无法理解用于在类上进行分配的函数的工作原理。]]></description>
      <guid>https://stats.stackexchange.com/questions/635947/im-trying-to-understand-a-research-paper-but-i-couldnt-understand-the-working</guid>
      <pubDate>Mon, 01 Jan 2024 09:06:37 GMT</pubDate>
    </item>
    <item>
      <title>了解蒙特卡罗积分中的重要性采样</title>
      <link>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</guid>
      <pubDate>Mon, 01 Jan 2024 05:16:12 GMT</pubDate>
    </item>
    <item>
      <title>帮助理解 Cohen's D 在 lme 中进行成对比较</title>
      <link>https://stats.stackexchange.com/questions/635928/help-understanding-cohens-d-for-pairwise-comparisons-in-lme</link>
      <description><![CDATA[审稿人要求我提供成对、计划比较的效果大小。在实验设计中，我有一个固定因素和三个条件（一致性）。通道&amp;主题是随机效应。我想报告 Cohen 的 D 三个计划比较（一致性 1 - 一致性 2；一致性 1 - 一致性 3；一致性 2 - 一致性 3）。然而，当我计算 Cohen&#39;s D 时，我得到两个效应大小，一个标记为一致性 2 (d = .732)，另一个标记为一致性 3 (d = .296)。首先，我不确定这些效果大小指的是哪些比较，并且输出仅提供两种效果大小。其次，我怎样才能得到第三次比较的科恩 D 值？
这是我的代码：
PdatFIN$RT_target &lt;- as.numeric(PdatFIN$RT_target)
PdatFIN$一致性 &lt;- as.factor(PdatFIN$一致性)
str(PdatFIN)
m &lt;- lmer(RT_target ~ 一致性 + (1 | 主题) + (1 | 段落), PdatFIN);摘要(m)；方差分析(米)
lme.dscore(m,数据=PdatFIN,类型=“lme4”)
m.contrasts &lt;- emmeans(m,“一致性”)
对(m.contrasts)

这是我的输出：
&lt;前&gt;&lt;代码&gt;组：1
             vars n 均值 SD 中值 修剪疯狂最小值 最大范围 偏斜峰度 se
RT_目标 1 148 1709.04 527.09 1631 1697.14 650.12 846 2974 2128 0.22 -1.06 43.33
组别：2人
             vars n 均值 SD 中值 修剪疯狂最小值 最大范围 偏斜峰度 se
RT_目标 1 162 2137.73 741.01 2056.5 2081.52 717.58 897 4414 3517 0.70 0.34 58.22
组别：3人
             vars n 均值 SD 中值 修剪疯狂最小值 最大范围 偏斜峰度 se
RT_目标 1 166 1888.73 736.85 1740 1811.35 708.68 750 4318 3568 1.01 0.83 57.19

REML [&#39;lmerMod&#39;] 拟合线性混合模型
公式：RT_target ~ 一致性 + (1 | 主题) + (1 | 段落)
   数据：PdatFIN

REML 收敛准则：7314.2

缩放残差：
    最小 1Q 中值 3Q 最大
-2.0682 -0.6320 -0.1771 0.5346 4.1376

随机效果：
 组名称方差标准差
 主题（拦截）203923 451.6
 通过（拦截）23091 152.0
 剩余 239054 488.9
obs 数量：476，组：受试者，30；通道，18

固定效果：
             估计标准。误差t值
（拦截）1711.58 98.75 17.333
一致性2 427.71 56.19 7.612
一致性3 173.18 55.99 3.093

固定效应的相关性：
            (Intr) Cnsst2
一致性2 -0.301
稠度3 -0.303 0.532
偏差表分析（II 型 Wald 卡方检验）

响应：RT_target
             Chisq Df Pr(&gt;Chisq)
稠度 59.216 2 1.385e-13 ***
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
&gt; #科恩斯d
&gt; lme.dscore(m,数据=PdatFIN,类型=“lme4”)
                    t df d
一致性2 7.612028 432.5373 0.7320127
一致性3 3.092820 434.6247 0.2967068
&gt; m.contrasts &lt;- emmeans(m,“一致性”)
&gt;对(m.contrasts)
 对比估计 SE df t.ratio p.value
 一致性 1 - 一致性 2 -428 56.2 432 -7.607 &lt;.0001
 一致性 1 - 一致性 3 -173 56.1 434 -3.090 0.0060
 一致性2 - 一致性3 255 54.3 429 4.688 &lt;.0001

自由度方法：kenward-roger
P 值调整：用于比较 3 个估计值的 tukey 方法

我非常感谢您的帮助和指导。我是 LME 的新手，试图解释我的输出是一个挑战。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/635928/help-understanding-cohens-d-for-pairwise-comparisons-in-lme</guid>
      <pubDate>Sun, 31 Dec 2023 17:49:27 GMT</pubDate>
    </item>
    <item>
      <title>经验分布（直方图箱）的比率是否显示出它们的差异？</title>
      <link>https://stats.stackexchange.com/questions/635918/does-taking-the-ratio-of-empirical-distributions-histogram-bins-show-their-dif</link>
      <description><![CDATA[背景
我有两个经验分布，均来自社交媒体数据。
第一个代表约 480 万个帖子的广泛样本以及每个帖子作者拥有的关注者数量。分布如下：

第二个是专门向我推荐的 1020 个帖子的较小样本。分布如下：

从目视检查中可以明显看出，如果忽略尺度并对分布进行归一化，它们将彼此非常不同。
我已经对这些分布进行了标准化，并采用了推荐分布与广泛分布的比率。我所说的比率是指将推荐故事的 bin 值除以广泛故事的 bin 值。我将结果绘制为散点图：
$$ R_i = \frac{r_i}{b_i}$$
其中 $R_i$ 是为 bin 位置 $i$ 计算的比率，$r_i$ 是推荐故事分布的 bin 位置 $i$ 中故事的标准化数量，并且 $b_i$ 是广泛故事分布的 bin 位置 $i$ 中故事的标准化数量。
它显示了一个有趣的模式。该比率随着追随者数量的增加而增加。由此，我推断，当您获得更多关注者时，您被推荐的机会就会增加。我预料到了我找到的结果，但我不知道它是否有意义。
问题
如果您有经验分布（定义为具有相同组箱的直方图），那么采用它们的箱的比率是否可以让您了解它们之间的差异？特别是关于管理每个创建的可能行为？]]></description>
      <guid>https://stats.stackexchange.com/questions/635918/does-taking-the-ratio-of-empirical-distributions-histogram-bins-show-their-dif</guid>
      <pubDate>Sun, 31 Dec 2023 14:13:58 GMT</pubDate>
    </item>
    </channel>
</rss>