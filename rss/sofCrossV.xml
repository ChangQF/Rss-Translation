<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 08 Feb 2024 06:18:33 GMT</lastBuildDate>
    <item>
      <title>自回归过程的自协方差函数，推广到任意阶</title>
      <link>https://stats.stackexchange.com/questions/638815/autocovariance-function-of-autoregressive-process-generalized-to-any-order</link>
      <description><![CDATA[我已经计算了 AR(1) 情况下的自协方差函数，这非常简单，但我需要高阶 AR(p) 的自协方差函数，假设它仍然是静止的。我一直在网上搜索，但我很难找到任何直接的功能。函数是否以封闭形式存在？我可以在哪里阅读有关此内容的更多信息？具体来说，我需要以下内容：
$$ \gamma(a)=\text{Cov}(y_i, y_{i-a}),\: \text{其中 }y_i = \phi_1 y_{i-1}+ \phi_2y_{i-2}+\dots+\phi_py_{i-p}+\varepsilon_i$$]]></description>
      <guid>https://stats.stackexchange.com/questions/638815/autocovariance-function-of-autoregressive-process-generalized-to-any-order</guid>
      <pubDate>Thu, 08 Feb 2024 03:34:18 GMT</pubDate>
    </item>
    <item>
      <title>大规模回归：确保大量预测质量的最佳实践</title>
      <link>https://stats.stackexchange.com/questions/638814/regression-at-scale-best-practices-around-ensuring-quality-of-a-large-numbers-o</link>
      <description><![CDATA[背景
我通常会预测项目中的一到几十个变量，但我即将进行的项目将涉及预测数千个变量。我有一些自己的想法，但一如既往，当您尝试新事物时尝试获得一些指导是明智的。
问题
我想要一些有关如何对大量变量进行预测的参考资料。我主要关心的是确保预测的质量。
到目前为止的一些想法

某些变量在层次结构中相互关联，因此请考虑通过对这些变量集建立层次模型来利用部分池化，这样可以提高统计精度。
该问题是一个传统的统计预测问题。没有提及进行干预。
许多步骤（例如训练/测试分割、训练、评估、预测等）将与我小规模执行时相同，并且非常可自动化。
我看到的主要挑战是我通常手动完成的事情，例如可视化 EDA 和诊断图或摘要。从那一刻起，可以获得很多价值，“嗯，这看起来很奇怪”。
也许一些数据挖掘或集群会派上用场。例如。对时间序列进行聚类，然后专注于查看聚类中的样本，同时注意那些不太适合聚类的时间序列，这可能会帮助我分类将时间/注意力/精力放在哪里。
]]></description>
      <guid>https://stats.stackexchange.com/questions/638814/regression-at-scale-best-practices-around-ensuring-quality-of-a-large-numbers-o</guid>
      <pubDate>Thu, 08 Feb 2024 02:35:22 GMT</pubDate>
    </item>
    <item>
      <title>泊松过程的概率[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638813/probability-of-poisson-process</link>
      <description><![CDATA[考虑泊松过程 (N(t))$_{t \geq 0}$ 和 $\lambda = 1.5$ 计算以下内容
a) $P(N(2) = 2; N(2.5) = 3; N(3) = 6)$
b) $P(N(2.5)*N(3)=3)$
c) $P(N(2) + N(2.5) = 0)$
d) $P(N(2) + N(2.5) = 1)$
e) $P(N(2) + N(2.5) = 2)$
我所有这些都是错误的，我希望有人能引导我走向正确的方向
对于a）我做到了
$P(N(2) = 2; N(2.5) = 3; N(3) = 6) \\=P(N(2) = 2)*P(N (2.5)-N(2) = 3 - 2)*P(N(3)-N(2.5)=6-3)\\
=P(N(2)=2)*P(N(0.5)=1)*P(N(0.5)=3)\\=\frac{3^2e^{-2}}{2!}* \frac{0.75^1e^{-0.75}}{1!}*\frac{0.75^3e^{-0.75}}{3!}$
b）我得到了
$P(N(2.5)*N(3)=3)=P(N(16.875)=3)=\frac{16.875^3e^{-16.875} {3!}$
c)
$P(N(2)+N(2.5)=0)=\frac{6.75^0e^{-6.75}}{0!}$ 
d)
$P(N(2)+N(2.5)=1)=\frac{6.75^1e^{-6.75}}{1!}$ 
e)
$P(N(2)+N(2.5)=2)=\frac{6.75^2e^{-6.75}}{2!}$ ]]></description>
      <guid>https://stats.stackexchange.com/questions/638813/probability-of-poisson-process</guid>
      <pubDate>Thu, 08 Feb 2024 02:25:52 GMT</pubDate>
    </item>
    <item>
      <title>Mann-Whitney U 检验与二项式检验相比</title>
      <link>https://stats.stackexchange.com/questions/638812/mann-whitney-u-test-compared-to-binomial-test</link>
      <description><![CDATA[我正在对 Mann-Whitney U 测试进行一些模拟。我收集了一些 U 统计数据（U 是 2 个样本之间的所有配对竞赛中获胜的最小数量：将样本 A 的所有值与样本 B 的所有值进行比较 -nAnB 总比较 - 将 UA 添加 1，如果A样本最大，否则UB加1，然后取UA或UB中最小的一个。其实UA或UB取其一即可，但是……）
然后我考虑对这个 U 值做一个简单的二项式测试，类似于基本的 SIgn 测试：在空（无随机优势）下，期望是 UA=UB=nAnB/2。
因此，我计算了在零值下观察到 U（或更极端）的概率，就像符号检验一样。
但是当我在模拟中这样做时，比较来自相同正态分布的 2 个样本，I 类错误率非常大（远高于曼惠特尼测试，后者似乎得到了很好的控制，至少在这些条件下） 。
我很难理解为什么二项式测试失败得如此严重：在我看来，它与符号测试的逻辑相同。
我查看 2 个样本之间的所有成对比较，计算样本 A “获胜”的次数，然后通过二项式检验查看其是否与空值 (UA~= 50%) 兼容。然而，在 NULL 为 true 的简单情况下，该方法经常拒绝 null 方式。
谁能解释一下这种方法/推理的缺陷在哪里？]]></description>
      <guid>https://stats.stackexchange.com/questions/638812/mann-whitney-u-test-compared-to-binomial-test</guid>
      <pubDate>Thu, 08 Feb 2024 02:02:08 GMT</pubDate>
    </item>
    <item>
      <title>向非技术受众解释因果推理的短片</title>
      <link>https://stats.stackexchange.com/questions/638811/a-short-video-to-explain-causal-inference-to-non-technical-audiences</link>
      <description><![CDATA[我认为这个问题可能太像购物问题了，所以我最初在十折中问，但建议我在这里提问。这是我原来的问题：
&lt;块引用&gt;
有人对我可以发送给客户解释因果推理的短视频有建议吗？这似乎是一个很难简化为几句话的主题。

我不能假设我的客户像我一样花很多时间来理解因果推理，我也不能假设他们对大学水平的数学（例如数理统计或图论）有任何理解。但我的客户有时对此感兴趣。我只需要把这个主题提炼成一个简短的介绍。我喜欢 McElreath 的统计之前的科学：因果推理，但它太长且技术性太强.
我需要的是一个大约 5 分钟（最多 10 分钟）的视频，我可以将其发送给客户进行消化。此类视频的目标是传达：

什么是因果推理？
为什么因果推理可以帮助我们在不确定的情况下做出决策？
他们需要如何参与帮助形成建模的因果假设。

为非技术受众提供准确、简洁和清晰的解释将为我的沟通提供切实的价值。]]></description>
      <guid>https://stats.stackexchange.com/questions/638811/a-short-video-to-explain-causal-inference-to-non-technical-audiences</guid>
      <pubDate>Thu, 08 Feb 2024 01:44:28 GMT</pubDate>
    </item>
    <item>
      <title>凯利网络的肯德尔符号？</title>
      <link>https://stats.stackexchange.com/questions/638810/kendalls-notation-for-kelly-networks</link>
      <description><![CDATA[背景
Kendall 符号（另请参阅Ciw docs&#39;) 在您经常使用队列时非常方便。它不仅提供缩写，而且其广泛使用有助于使文献检索更加具体。
AFAIK Kendall 的符号用于描述单个队列，但如果我有一个由不同队列组成的网络，这些队列的行为取决于客户，该怎么办？
问题
如何表示凯利网络，其中节点的排队描述可能不同？
尝试回答
一旦进入网络，事情就会变得太复杂。对于整个网络来说，拥有一些专门的符号比拥有良好的图表通常不会给人类可读性带来额外的好处。对于机器，您可以自动将复杂模型存储在数据结构中或根据需要将其序列化。因此，为您的人类同胞（和您自己）画出好画。
&lt;小时/&gt;
示例：
以 Ciw 文档中的示例为例：&lt; /p&gt;
导入 ciw

N = ciw.create_network(
    到达分布={
        &#39;宝贝&#39;: [ciw.dists.Exponential(rate=1.0),
                 没有任何，
                 没有任何]，
        &#39;孩子&#39;: [ciw.dists.Exponential(rate=2.0),
                  没有任何，
                  没有任何]
    },
    服务分布={
        &#39;宝贝&#39;: [ciw.dists.Exponential(rate=4.0),
                 ciw.dists.Exponential(rate=1.0),
                 ciw.dists.Deterministic(value=0.0)],
        &#39;孩子&#39;: [ciw.dists.Exponential(rate=6.0),
                  ciw.dists.Deterministic(值=0.0),
                  ciw.dists.Exponential(rate=1.0)]
    },
    路由={&#39;宝贝&#39;: [[0.0, 1.0, 0.0],
                      [0.0, 0.0, 0.0],
                      [0.0, 0.0, 0.0]],
             &#39;孩子&#39;: [[0.0, 0.0, 1.0],
                       [0.0, 0.0, 0.0],
                       [0.0, 0.0, 0.0]]
    },
    服务器数量=[1,2,3],
）

文档更详细地解释了上面的示例。如果你愿意的话，我还写了Ciw概述除了文档之外，有关 Ciw 的更多信息。
只有三个节点，但根据客户是婴儿还是儿童，它们的到达分布、服务分布和路由有不同的规则。但基本上，该系统是一个 Kelly 网络，因为有不止一类客户。我喜欢这个例子，因为它代表了我如何发现肯德尔的符号不完整（至少在我的理解中）。]]></description>
      <guid>https://stats.stackexchange.com/questions/638810/kendalls-notation-for-kelly-networks</guid>
      <pubDate>Thu, 08 Feb 2024 01:14:59 GMT</pubDate>
    </item>
    <item>
      <title>为了确定这两个变量的关系，我可以使用的最佳相关性是什么？</title>
      <link>https://stats.stackexchange.com/questions/638809/what-is-the-best-correlation-that-i-can-use-in-order-to-determine-the-relationsh</link>
      <description><![CDATA[如何关联 2 个二分变量？
变量1：
通过：1
失败：19
变量2：
通过：3
失败：13
我尝试了$\phi$系数
$X$：
变量1
变量2
$Y$：
通过
失败
一切都很顺利，但我意识到我正在分别关联每个 var1 和 var2 的失败和通过。
哪种统计工具最适合关联这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/638809/what-is-the-best-correlation-that-i-can-use-in-order-to-determine-the-relationsh</guid>
      <pubDate>Thu, 08 Feb 2024 00:57:29 GMT</pubDate>
    </item>
    <item>
      <title>将判别式表示为高斯混合的线性分类器</title>
      <link>https://stats.stackexchange.com/questions/638808/expressing-discriminant-as-linear-classifier-for-a-gaussian-mixture</link>
      <description><![CDATA[假设我有一个高斯混合，由具有不同对角协方差矩阵的两个类组成，$\Sigma_-$ 和 $ \Sigma_+$。同样，它们具有不同的平均值，并且 $p_+$ 给出与正类相关的概率。下面的推导给出了判别式 $r(x)$ 的扩展。
我的问题是关于我们如何将这种情况下的判别式 $r(x)$ 表达为某些权重向量和某些特征映射之间的内积。在假设两个类的协方差相等的情况下，这种表示对我来说很直观，因为如果我们在这种情况下遵循与上面相同的推导，那么很明显我们可以只使用 $\phi(x) = [1, x]$ 并让我们的权重 $w$ 为 $\Sigma^{-1}(\mu_+ - \mu_-)$，偏差项是表达式的剩余部分。然而，在协方差不同的情况下，事情似乎不会很好地取消，因此表示 $\frac{1}{2}x^T 要困难得多(\Sigma_{-}^{-1} - \Sigma_{+}^{-1})x + x^T(\Sigma_{+}^{-1}\mu_{+} - \Sigma_{-}由于二次性，^{-1}\mu_{-})$ 作为一个干净的点积，对我来说它看起来不太直观。假设我们定义特征映射 $\phi(x) =$ 所有 $\leq$ 二阶单项式。那么我们如何确定权重向量 $w$ 使得 $\langle \phi(x), w \rangle = r(x)$？是否像以前一样简单，由特征映射处理二次性？
我们能否简化映射，因为协方差矩阵是对角的，即消除交叉项？或者也许这个功能映射不起作用，在这种情况下怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/638808/expressing-discriminant-as-linear-classifier-for-a-gaussian-mixture</guid>
      <pubDate>Thu, 08 Feb 2024 00:52:50 GMT</pubDate>
    </item>
    <item>
      <title>时间序列回归中的自相关和异方差</title>
      <link>https://stats.stackexchange.com/questions/638807/autocorrelation-and-heteroskedasticity-in-time-series-regression</link>
      <description><![CDATA[我正在使用一个小数据集（大约 50 个观测值和 &lt; 10 个变量）运行时间序列回归，并想知道如何在同一回归模型中校正自相关和异方差。我发现过去的文献建议最好先校正自相关，然后校正异方差：因此，在回归中（Durbin-Watson 统计量为 0.79，最热值显着，chi2=6.34），我尝试使用以下方法校正自相关： &lt;赞扬x1 x2 x3，corc&gt;然后运行 ​​纠正异方差。我想知道这是否正确？感谢您提供的任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/638807/autocorrelation-and-heteroskedasticity-in-time-series-regression</guid>
      <pubDate>Thu, 08 Feb 2024 00:01:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPytorch 求高斯过程的导数 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638803/derivative-of-gaussian-process-using-gpytorch</link>
      <description><![CDATA[我已经在 https://docs.gpytorch.ai/en 上查找过这个/stable/index.html 但我找不到有关如何直接从 GPytorch 获取 GP 导数的信息。有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638803/derivative-of-gaussian-process-using-gpytorch</guid>
      <pubDate>Wed, 07 Feb 2024 22:42:05 GMT</pubDate>
    </item>
    <item>
      <title>美国使用什么未引用的方法来测试含铅水管？</title>
      <link>https://stats.stackexchange.com/questions/638799/what-uncited-method-is-being-used-to-test-for-lead-water-pipes-in-the-us</link>
      <description><![CDATA[美国的几个州正在使用相同的统计程序来验证供水管道不含铅，但我无法弄清楚它的依据是什么，因为没有引用任何参考文献。
给定一个住宅区，此过程（来自科罗拉多州的示例）规定需要挖掘多少供水管道（从供水管到房屋的连接）并进行物理验证不含铅。
&lt;块引用&gt;
为了以 5% 的误差幅度获得 95% 的置信度，表明供水系统中不存在铅供水管线，必须进行物理验证的随机抽样，样本大小由 [下表] 确定。例如，经过记录审查，没有发现线索，5000条服务线材料仍然未知，必须随机抽取5000条服务线中的357条进行检查；如果所有 357 条服务线路都是非主导服务线路，则公用事业公司可以 95% 确信其配电系统中没有主导服务线路。

您认为他们会使用威尔逊得分区间或三法则计算领先服务线比例的 95% 置信区间，但对于上面的示例，两种方法都给出了 0.01 的置信上限，而不是引用的 MOE 0.05。我也不明白如果目标是限制潜在客户服务线的比例，而不是潜在客户服务线的总数，为什么样本量会增加。

行示例
1500 306
1600 310
1700 314
1800 317
1900 320
2000 322
2200 327
2400 331
2600 335
2800 338
3000 341
3500 346
4000 351
4500 354
5000 357
6000361
7000 364
8000 367
9000 368
10000 370
15000 375
20000 377
30000 379
40000 381
60000 382
90000 383
]]></description>
      <guid>https://stats.stackexchange.com/questions/638799/what-uncited-method-is-being-used-to-test-for-lead-water-pipes-in-the-us</guid>
      <pubDate>Wed, 07 Feb 2024 21:31:52 GMT</pubDate>
    </item>
    <item>
      <title>机器学习训练后如何整合先验知识？</title>
      <link>https://stats.stackexchange.com/questions/638788/how-to-incorporate-prior-knowledge-after-ml-training</link>
      <description><![CDATA[假设我已经在包含 5 个类别的平衡数据集上训练了我的 ML 分类器。该模型在训练和测试数据上表现良好。模型的预测置信度与概率很好地吻合，因此预测可以立即用作 $p(\mathcal C_k|\mathbf x_i)$，即概率给定输入 $\mathbf x_i$ 的类 $\mathcal C_k$。
我在生产中使用这个模型。现在我得到了一堆新数据，我当然知道它只包含类 1、2 和 3，而且我知道它们的大致比例。然而，我的模型有时会将这些错误标记为 4-5 类。更新预测的最佳方法是什么？一些想法：

将 4-5 类的预测概率设置为 $0$。然而，这不会考虑新数据是否包含明显较少的 1 类数据，因此可能性较小。
将预测概率与类别分布相乘。这会将类别 4-5 的概率设置为 $0$，但是如果类别 1 的样本很少，则可能会导致类别 1 根本无法预测存在。
在原始训练数据上重新训练模型，但仅限类别 1-3。对于具有许多类的大型模型来说是有问题的。
]]></description>
      <guid>https://stats.stackexchange.com/questions/638788/how-to-incorporate-prior-knowledge-after-ml-training</guid>
      <pubDate>Wed, 07 Feb 2024 18:58:24 GMT</pubDate>
    </item>
    <item>
      <title>是否可以对个人层面的任何汇总统计数据进行方差分析或学生检验？</title>
      <link>https://stats.stackexchange.com/questions/638784/can-anovas-or-student-tests-be-conducted-on-any-summary-statistic-at-the-individ</link>
      <description><![CDATA[我想知道是否可以对个人级别的任何表现汇总统计数据进行方差分析或学生测试，而不会对 1 类和 2 类错误产生任何影响。
例如，考虑一个带有分类自变量和连续因变量的简单实验设计。例如，人类参与者要么喝酒精饮料，要么喝非酒精饮料，然后执行 100 次检测任务试验。感兴趣的变量是每次试验中的响应时间 (RT)。研究人员通常计算每个受试者的平均 RT，并对这些单独的平均值进行方差分析或学生测试。是否可以计算每个受试者的 RT 中位数，并对这些单独的中位数运行方差分析或学生测试？我认为只要满足测试假设，这种替代方法就是有效的，但也许我遗漏了一些东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/638784/can-anovas-or-student-tests-be-conducted-on-any-summary-statistic-at-the-individ</guid>
      <pubDate>Wed, 07 Feb 2024 18:37:48 GMT</pubDate>
    </item>
    <item>
      <title>在这个问题上达成一致的一个好的衡量标准是什么？</title>
      <link>https://stats.stackexchange.com/questions/638806/what-is-a-good-metric-for-agreement-in-this-problem</link>
      <description><![CDATA[假设我有一个需要注释的数据集。
我有大约 $5000$ 总共 $x$ 值，并且需要人工注释来创建 $y$ 值。
$y$ 采用 $\{0, 1\}$ 中的值。
多人独立注释所有数据集。我需要衡量他们同意的程度。
最简单的指标是这样的：$$ 分数 = 1 - \dfrac{ \# \text{ 分歧 }}{\text{total}} $$ 
但问题是，与总数相比，1 的数量非常少，比如说
100. 如果我有 3 个注释者，即使所有人都不同意，分数也将是 $300/5000=94%$，尽管存在大量分歧，但这是一个非常高的分数。
OTOH，如果我删除只有 $0$ 的所有内容，我也会放弃所有协议。
这里什么是好的指标？]]></description>
      <guid>https://stats.stackexchange.com/questions/638806/what-is-a-good-metric-for-agreement-in-this-problem</guid>
      <pubDate>Wed, 07 Feb 2024 16:34:50 GMT</pubDate>
    </item>
    <item>
      <title>如何获取“原始”数据的（加权或未加权）L1 不平衡度量</title>
      <link>https://stats.stackexchange.com/questions/638728/how-to-obtain-the-weighted-or-unweighted-l1-imbalance-measure-for-raw-data</link>
      <description><![CDATA[我对 Iacus 等人的 JASA 论文《单调不平衡边界的多元匹配方法》有两个问题。 (2011)，作者制作了图 2（左图），其中他们比较了倾向得分、mahalanobis 和 cem 匹配方法的 L1 测量值，并与“原始”测试的 L1 测量值进行了基准测试。数据。在他们的补充材料中，他们声明“file acompleteone.R：产生图2和图3以及表3”。但他们的目录中不存在这样的文件。仔细阅读了论文和图 2 之前的前面段落后，我仍然不明白他们如何计算“原始”数据的 L1(H)。数据。
我相信，对于 250 次迭代中的每一次，他们随机选择每个变量的粗化范围的上限和下限，然后随机选择 H，而不是他们的经验法则中值方法，但看起来这就是仅适用于原始方法、倾向评分和马哈拉诺比斯方法，对于 CEM，他们指出，“我们使用具有固定粗化的 CEM（每个连续变量有 10 个间隔，并且对分类变量没有粗化）”。
此外，我并不清楚他们是否计算加权或未加权的 L1 不平衡度量，尽管 这里似乎是加权的，但实际论文中没有提及这一点。如果论文的图 2 结果使用权重，您知道为什么 L1 多元不平衡度量的公式中没有明确权重吗？ （式（6））]]></description>
      <guid>https://stats.stackexchange.com/questions/638728/how-to-obtain-the-weighted-or-unweighted-l1-imbalance-measure-for-raw-data</guid>
      <pubDate>Wed, 07 Feb 2024 01:45:27 GMT</pubDate>
    </item>
    </channel>
</rss>