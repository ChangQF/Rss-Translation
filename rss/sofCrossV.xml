<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 02 Aug 2024 01:06:43 GMT</lastBuildDate>
    <item>
      <title>假设 $Z_i$ 是独立同分布的。$N(0, 1).$ 且令 $M_n = max\{Z_1, \ldots, Z_n\}$，表明 $P(M_n > t) \leq n(1 - \Phi(t))$</title>
      <link>https://stats.stackexchange.com/questions/652187/suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n-sho</link>
      <description><![CDATA[证明 $P(M_n &gt; t) \leq n(1 - \Phi(t))$
我的工作：
\begin{align}
P(M_n &gt; t) &amp;\leq P(\cup_{i=1}^n (Z_i &gt; t))\leq \sum_{i=1}^n P(Z_i &gt; t)= n(1 - \Phi(t))
\end{align&gt;
以上是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/652187/suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n-sho</guid>
      <pubDate>Thu, 01 Aug 2024 22:30:21 GMT</pubDate>
    </item>
    <item>
      <title>比较半结构化嵌套文本数据中主题流行度检测的无监督方法</title>
      <link>https://stats.stackexchange.com/questions/652184/comparing-unsupervised-approaches-to-topic-prevalence-detection-in-semi-structur</link>
      <description><![CDATA[我试图理解（理想情况下，概率上）检测半结构化嵌套文本数据中潜在主题的普遍性的方法。具体来说，似乎至少有两种方法（如下所述）使用无监督学习/主题模型来完成这项任务，我想知道这两种方法的缺点/优点。
“半结构化嵌套文本数据”示例
假设数据是一组关于 N 个不同公司的 N 份报告（父文档）。每份报告包含一组要点（子文档），每份要点由 1-3 个句子组成 - 即推文长度。如果需要，我们可以假设每个要点映射到 1 个潜在主题（例如，公司的成本），但该主题可以在报告内和报告之间出现多次（使用不同的词语）。最后，要点的数量和主题因报告而异。因此，不同的报告经常讨论类似的主题，但有些报告可能会讨论更多或独特的主题。
这是一个带有括号中潜在主题的玩具数据示例：

还有一个快速图表，显示主题和项目符号的数量在不同的报告中可能有所不同：

识别和检测的方法主题
方法 1：将数据展平到每份报告的一列，然后使用报告作为文档与多成员主题模型
数据示例：


连接报告中的所有要点，以便每份报告都包含一个大段文字。
使用流行度参数拟合多标签概率模型（例如结构主题模型（BERTopic）来识别主题和流行度。
使用主题流行度参数将报告分配给（一个或多个）主题。

问题：主题流行度是一个概率单纯形，因此例如，一份显然包含 3 个主题的文档将为每个主题分配 0.33 的概率，为其他主题分配 0 的概率。因此，流行度仅告诉我们哪些主题最有可能相对于其他主题，但并未告诉我们绝对概率。
方法 2：将数据加长，然后使用项目符号作为文档，公司名称作为多成员主题模型中主题流行度的预测因子
数据示例：


汇集所有报告中的所有项目符号，以便项目符号被视为文档。
使用与报告关联的公司，将主题模型（例如 STM）与文档相匹配（元数据）作为主题流行度协变量。
使用公司与主题之间关联的系数作为主题相对流行度的衡量标准。

问题：所有系数均相对于平均流行度，因此您只能知道某些公司与主题流行度的相关性更强……您不知道某个主题是否在所有报告中均有提及。]]></description>
      <guid>https://stats.stackexchange.com/questions/652184/comparing-unsupervised-approaches-to-topic-prevalence-detection-in-semi-structur</guid>
      <pubDate>Thu, 01 Aug 2024 21:50:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么弹性网络不能像 lm 那样处理缺失数据？</title>
      <link>https://stats.stackexchange.com/questions/652183/why-doesnt-elastic-net-handle-missing-data-the-way-lm-does</link>
      <description><![CDATA[在 R 中进行计算时，我有一些玩具数据，并尝试使用 glmnet 来拟合弹性网络模型。我注意到，即使只有一个缺失值，算法也不会执行，建议事先估算缺失值。
# 设置可重复性的种子
set.seed(123)

# 生成一个 100x5 的随机数矩阵
data_matrix &lt;- matrix(rnorm(100*5), nrow=100, ncol=5)
data_df &lt;- as.data.frame(data_matrix)
data_df[1:1, 3] &lt;- NA # 单个缺失值
# 生成一个包含 100 个观测值的向量 Y，每个观测值为 1、2 或 3
Y &lt;- sample(1:3, 100, replace=TRUE)
glmnet::cv.glmnet(x = as.matrix(data_df),
y = as.matrix(Y),
alpha = 0.5,
family = &quot;multinomial&quot;)
glmnet(x, y, weights = weights, offset = offset, lambda = lambda, 中的错误：
x 有缺失值；考虑使用 makeX() 来估算它们

从算法上讲，当有缺失值时，是什么原因导致弹性网络不适合？相反，当使用 lm 并且有缺失值时，
ctl &lt;- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,NA)
trt &lt;- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group &lt;- gl(2, 10, 20, labels = c(&quot;Ctl&quot;,&quot;Trt&quot;))
weight &lt;- c(ctl, trt)
lm.D9 &lt;- lm(weight ~ group)

代码运行无任何错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/652183/why-doesnt-elastic-net-handle-missing-data-the-way-lm-does</guid>
      <pubDate>Thu, 01 Aug 2024 21:42:45 GMT</pubDate>
    </item>
    <item>
      <title>正态分布概率密度函数与累积分布函数之比</title>
      <link>https://stats.stackexchange.com/questions/652176/ratio-of-normal-pdf-to-cdf</link>
      <description><![CDATA[我想证明
$$\Bigl\lvert \frac{\phi(a)}{\Phi(a)} - \frac{\phi(b)}{\Phi(b)} \Bigr\rvert \leq |a-b|$$
其中 $\phi$ 是标准正态 pdf，而 $\Phi$ 是标准正态 cdf。]]></description>
      <guid>https://stats.stackexchange.com/questions/652176/ratio-of-normal-pdf-to-cdf</guid>
      <pubDate>Thu, 01 Aug 2024 20:06:38 GMT</pubDate>
    </item>
    <item>
      <title>残差与拟合图显示周期性模式。我从 300 个解释变量中选择了 5 个。我应该添加更多变量还是冒着过度拟合的风险？</title>
      <link>https://stats.stackexchange.com/questions/652174/resids-vs-fitted-plot-shows-cyclical-patterns-i-have-chosen-5-explanatory-varia</link>
      <description><![CDATA[我根据其他属的相对丰度预测 1 个属 (A) 的相对丰度。我随意选择了 5 个似乎最有可能有帮助的属（我所有重复实验中随时间推移最丰富的 5 个属），但我的社区总共有 300 多个属。我使用相同的方法预测了 2 个细菌属和 2 个真核生物属的丰度。
除了残基与拟合值之外，诊断结果看起来都很好，并且该模型在预测未来数据方面表现得出奇的好。
我正在写一篇文章，想说的是，虽然残差与拟合值显示出拟合不足的迹象，并且添加其他属很可能有助于预测，但仅包含这 5 个物种使我们能够相当准确地预测随时间的变化。
该建模不是我文章的核心，目的不是预测现实世界中发生的现象，而是一个探索性过程，只是看看是否可以预测属的相对丰度变化。这种思路在发表的文章中会成立吗？


使用包 mvgam 在 R 中建模]]></description>
      <guid>https://stats.stackexchange.com/questions/652174/resids-vs-fitted-plot-shows-cyclical-patterns-i-have-chosen-5-explanatory-varia</guid>
      <pubDate>Thu, 01 Aug 2024 19:31:37 GMT</pubDate>
    </item>
    <item>
      <title>降维以实现高维流的可视化</title>
      <link>https://stats.stackexchange.com/questions/652173/dimensionality-reduction-for-visualization-of-high-dimensional-flows</link>
      <description><![CDATA[我的问题是如何最好地可视化高维空间中的动态流。以下是所有详细信息：

我已经训练了一个 RNN (GRU) $f(x, u)$，其中包含 50 个单元来执行连续控制任务。我认为这与我的问题不太相关，但具体任务是在二维空间中对牛顿点质量施加力，使其从初始位置的静止移动到目标位置的静止。
就这个问题而言，没有系统噪音。
任务的每个情节持续 100 个时间步（RNN 单元的迭代），并产生 50 维的网络状态轨迹（即形状为 (100, 50) 的数组）。
网络的输入 $u$ 是 1）点质量的目标位置和速度，它们在一个情节期间保持不变，以及 2）关于环境状态的反馈（即点质量的当前位置和速度），它会随时间变化。
我一直在使用 FixedPointFinder 来查找 RNN 的固定点 (FP)。该方法通过使用 RNN 演化一组候选状态 $x_{\mathrm{c},i}$ 直到成本函数 $(f_u(x_{\mathrm{c},i})-x_{\mathrm{c},i})^2$ 低于某个容差，然后排除任何重复项等。请注意，$u$ 对于此操作是固定的 - RNN 的每个输入向量都定义了一个不同的动态系统，可能具有不同的 FP。
对于此任务，对于给定的网络输入向量通常只有一个 FP，我假设这个问题就是这种情况。
我一直在通过将隐藏的轨迹和 FP 投影到前 2 个主要成分上来可视化它们。我将主向量拟合到整个隐藏轨迹批次，然后重新使用这些向量来转换其他所有内容（例如 FP）。
几乎所有的方差都被前 4-5 个 PC 捕获。

我想可视化 RNN 对固定输入 $u$ 的动态流。我目前的方法是这样的：

在 PC 空间（2D）中生成一个规则的点网格 $x_{\mathrm{g},i}$，并将其投影到状态空间（50D）中。
计算 $f_u(x_{\mathrm{g},i})-x_{\mathrm{g},i}$；这些是状态演化向量。
将向量投影回 PC 空间并使用 quiver 进行绘制。

对于轨迹的每个时间步，我存储 RNN 实际收到的输入向量。因此，我在情节的每个时间步找到一个 FP 和一个向量场——即 100 个 FP 和 100 个向量场的轨迹。
但是：

在 PC 空间中，结果向量场的 2 范数的最小值（即最短的 2 向量）与 FP 并不完全一致，也投影到 PC 空间中。我认为这是有道理的，因为投影到前 2 个 PC 不会保留来自状态空间的 50 个向量的长度。
状态空间中向量场的 2 范数的最小值（最短的 50 个向量）随后投影到 PC 空间，确实与 FP 对齐，但仅在试验的开始和结束时对齐。我发现这更令人困惑，因为我不认为这是由于 PCA 造成的，我无法想象为什么向量场$f(x)-x$ 范数的最小值不会与最小化 $(f(x)-x)^2$ 的状态对齐。我曾经认为，这种差异是由于网格投影到状态空间后变得稀疏造成的，但这很难用我目前的方法进行测试，因为当我试图将常规网格扩大到正确覆盖 50D 空间时，内存会耗尽。

这两种效果在以下 PC 空间单集动画中都可见：

有没有更好的方法可以在 2D 或 3D 中可视化高维空间中的流空间？
我怀疑有一件事会起作用，那就是在 50D 空间中生成流线，这些流线是点而不是矢量，应该至少像 FP 一样投射到 PC 空间中。
我也很高兴了解我的方法的其他局限性。
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652173/dimensionality-reduction-for-visualization-of-high-dimensional-flows</guid>
      <pubDate>Thu, 01 Aug 2024 18:59:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么在零假设中包含最小实际效应大小不是标准？</title>
      <link>https://stats.stackexchange.com/questions/652168/why-is-it-not-standard-to-include-minimum-practical-effect-size-in-null-hypothes</link>
      <description><![CDATA[我是统计学新手。在假设检验中，通常使用 $\theta = \theta_0$ 形式的零假设，这让我感到困惑。在我看来，在许多情况下，我们感兴趣的不是确切的相等性，而是 $|\theta - \theta_0|&lt; \delta$，其中 $\delta$ 的某个阈值使 $\theta$ 和 $\theta_0$ 之间的差异具有实际意义。
有没有研究人员以这种方式制定零假设的例子？为什么这种情况并不常见？]]></description>
      <guid>https://stats.stackexchange.com/questions/652168/why-is-it-not-standard-to-include-minimum-practical-effect-size-in-null-hypothes</guid>
      <pubDate>Thu, 01 Aug 2024 18:00:07 GMT</pubDate>
    </item>
    <item>
      <title>根据非分层变量进行细分</title>
      <link>https://stats.stackexchange.com/questions/652166/breakdown-with-respect-to-a-non-stratification-variable</link>
      <description><![CDATA[假设我有一个关于某国企业投资的研究。假设企业按员工人数分层：三个层级 $s_1$，从 $1$ 到 $9$ 名员工，$s_2$，从 $10$ 到 $49$ 名员工，以及 $S_3$，从 $\ge 50$ 名员工。我们采取分层简单随机抽样。总投资的公式为 $$ I= N_1\overline i_1+N_2\overline i_2+ N_3\overline i_3$$
其中 $N_j$ 是 $s_j$ 层中的企业总数，$\overline i_j$ 是从 $s_j$ 层中抽取的 $n_j$ 个企业的平均投资。
现在为简单起见，假设总体中的企业只有两种工业活动，$A_1$ 和 $A_2$。我想按活动部门细分上述总投资，这意味着 $I=I_1+I_2$，其中 $I_1$ 是活动的总投资 $A_1$，$I_2$ 也是类似情况。既然我从一开始就没有将活动部门作为分层变量，那么如何做到这一点？在选择样本之前，是否强制性将细分变量 $x$ 作为分层变量来细分任何与任何变量相关的总投资？]]></description>
      <guid>https://stats.stackexchange.com/questions/652166/breakdown-with-respect-to-a-non-stratification-variable</guid>
      <pubDate>Thu, 01 Aug 2024 17:28:55 GMT</pubDate>
    </item>
    <item>
      <title>如何在 GLM 中推导出指数分布的典型链接函数</title>
      <link>https://stats.stackexchange.com/questions/652165/how-to-derive-canonical-link-function-of-exponential-distribution-in-glm</link>
      <description><![CDATA[我想知道推导过程，以及基本如何计算它]]></description>
      <guid>https://stats.stackexchange.com/questions/652165/how-to-derive-canonical-link-function-of-exponential-distribution-in-glm</guid>
      <pubDate>Thu, 01 Aug 2024 17:22:22 GMT</pubDate>
    </item>
    <item>
      <title>什么是最好的统计分析方法来分析不同代谢物随时间（时间 0、24 和 48 小时）的显著差异</title>
      <link>https://stats.stackexchange.com/questions/652164/what-is-the-best-statistical-analysis-to-analyse-significant-differences-in-diff</link>
      <description><![CDATA[我有 40 种不同的代谢物，我测量了它们在 0、24 和 48 小时时的浓度。我想知道每种代谢物是否随着时间的推移存在显著差异。我对代谢物之间是否存在差异并不感兴趣。我考虑对每种代谢物进行单向 Anova 重复测量 + Tukey 检验。所以最后我会得到 40 种不同的分析（Anova + Tukey）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652164/what-is-the-best-statistical-analysis-to-analyse-significant-differences-in-diff</guid>
      <pubDate>Thu, 01 Aug 2024 17:05:23 GMT</pubDate>
    </item>
    <item>
      <title>因式分解定理是否证明 PDF 的最简单因式分解是最具信息量的？</title>
      <link>https://stats.stackexchange.com/questions/652163/does-the-factorization-theorem-prove-that-the-simplest-factorization-of-the-pdf</link>
      <description><![CDATA[让我将因式分解定理表述为：存在 PDF 因式分解，其中 $X$ 仅通过 $T(X)$ 依赖于参数，证明 $T(X)$ 是充分的，定义为从 $X$ 传达最大可能的参数信息。其证明（或我找到的所有版本）显示了如何将 PDF 分解为两个组件的简单乘积，一个组件独立于参数，另一个组件仅通过 $T(X)$ 依赖于参数。
这只是代数，仅证明了以下陈述：“某些 PDF 可以以这种方式进行因式分解。”然后，证明从定义上强加了 $T(X)$ 是充分的。它似乎依赖于一个直观上吸引人但在数学上没有道理的假设：PDF 的各个因子的信息不能超过它们的集体信息。这个假设没有考虑到，更不用说排除了另一种可能性：可能存在将最简单的因式分解划分为许多因子的情况，其中一些或所有因子单独有条件地增加了 $T(X)$ 的信息，但集体抵消了。让我来举例说明。
Basu (1964) 表明，对于具有总体相关性 $\rho$ 的双变量正态样本 $(X, Y)$，$X$ 和 $Y$ 分别具有辅助性，但联合起来是充分的（尽管显然不是最小充分的）。在这个特殊情况下，条件推理是不可能的，即 $r|X$ 和 $r|Y$ 都不比充分统计 Pearson 的 $r$ 更具信息量。但我们能证明不存在这样的例子吗？难道我们不应该证明 FT 成立吗？
结果是，从多项式中提取因子是基本的代数，否则会抵消$-$，例如，因子与其倒数的乘积，或相反符号的相等加数。FT 不应该驳斥这种可能性吗？如果不是，那它不就是一个公理吗？还是我的逻辑有缺陷？请记住我的例子仅供说明：证明反例的负担不在我身上，而是在 FT 身上，以证明不存在反例。]]></description>
      <guid>https://stats.stackexchange.com/questions/652163/does-the-factorization-theorem-prove-that-the-simplest-factorization-of-the-pdf</guid>
      <pubDate>Thu, 01 Aug 2024 17:04:04 GMT</pubDate>
    </item>
    <item>
      <title>我构建 SIRD 模型并将其拟合到真实 COVID 数据的代码存在什么问题？</title>
      <link>https://stats.stackexchange.com/questions/652178/what-is-the-problem-with-my-code-for-building-and-fitting-an-sird-model-to-real</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652178/what-is-the-problem-with-my-code-for-building-and-fitting-an-sird-model-to-real</guid>
      <pubDate>Thu, 01 Aug 2024 12:30:20 GMT</pubDate>
    </item>
    <item>
      <title>评估已知矩阵近似的成功率</title>
      <link>https://stats.stackexchange.com/questions/652142/estimating-the-success-of-an-approximation-of-a-known-matrix</link>
      <description><![CDATA[我试图用“估计”矩阵$A&#39;$近似已知的$N\times N$矩阵$A$。问题是，如何量化此近似中的误差 - $A$和$A&#39;$之间的差异。
如果$A$和$A&#39;$是单个数字，这个问题就很简单了。但是，当数据为矩阵形式时，误差的含义变得更加模糊。
我知道 RMS 和矩阵范数，但使用它们来量化估计误差存在问题，因为它们取决于数据的动态范围 - 如果矩阵值在 $0-1000$ 范围内，则 RMS 值 $0.5$ 不会说明任何有用信息；无论 RMS 是多少，矩阵元素 $a_{ij}$ 和 $a_{ij}&#39;$ 之间可能存在显著差异。我认为矩阵范数遇到了完全相同的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/652142/estimating-the-success-of-an-approximation-of-a-known-matrix</guid>
      <pubDate>Thu, 01 Aug 2024 10:34:41 GMT</pubDate>
    </item>
    <item>
      <title>对于李克特量表的两个分类变量应该使用什么假设检验？</title>
      <link>https://stats.stackexchange.com/questions/652073/what-hypothesis-test-should-be-used-for-two-categorical-variables-in-likert-scal</link>
      <description><![CDATA[我来举个例子。
假设我在一家医院进行了一项健康调查。我问了两个问题。第一个问题是：“我吃药来改善睡眠”，第二个问题是：“我早上感觉不舒服”。我对这两个问题都获得了大约 100 个答复。
这两个问题的答案范围从 1 到 5：(1) 从不，(2) 很少，(3) 有时，(4) 经常，(5) 总是。（李克特量表）
也就是说，我有 100 行答案，范围从 1 到 5。一个有序分类变量。
在这种情况下，我想测试吃药来改善睡眠和早上感觉不舒服之间是否存在关系。我正在考虑使用卡方检验。
我的零假设是 H0：变量“我服药以睡好觉”和“我早上感觉不舒服”是独立的。换句话说，睡得好和感觉不舒服之间没有关联。
我的备选假设 H1：变量“我服药以睡好觉”和“我早上感觉不舒服”不是独立的。换句话说，服药和早上感觉不舒服之间存在显著关联。
如果我再进行一次关于心理健康的调查，问题 1：“我没有什么可期望的”，问题 2：“我作为一个人没有任何价值”，回答量表相同……测试结果还会一样吗？卡方检验？]]></description>
      <guid>https://stats.stackexchange.com/questions/652073/what-hypothesis-test-should-be-used-for-two-categorical-variables-in-likert-scal</guid>
      <pubDate>Wed, 31 Jul 2024 10:37:54 GMT</pubDate>
    </item>
    <item>
      <title>统计技术推荐</title>
      <link>https://stats.stackexchange.com/questions/651984/statistical-technique-recommendation</link>
      <description><![CDATA[研究背景：
当您在网上购物时，您可能最初购买一种产品，但最终购买另一种产品。
研究问题：
我的目标是了解最终购买的产品相对于原始产品有哪些优势，使消费者最终购买它们而不是原始产品。我对分析结果的形式很灵活，但如果能够用商业人士理解的术语来解释这一点就更好了，例如：

&quot;在电器产品类别中，随着最终购买产品的保修期增加 1 年，消费者购买该产品的可能性比原产品高 5%&quot;
&quot;在手机类别中，最终购买的产品每增加一百万像素，消费者购买该产品的可能性就会增加 12%，如果没有原产品的颜色多样性，这一比例就会降低到 4%。&quot;
&quot;由于“锚定效应”，如果原产品的价格比最终购买的产品高出至少 10%，消费者更有可能购买后者，即使其平均客户评分低 1点。”

数据：
我的数据显示了消费者在查看了 10000 多种原产产品后最终购买的前 10 种产品。数据样本如下所示。行是原产产品的 SKU，列是最终购买的 SKU。例如，当消费者查看 SKU 1001（第一行）时，他们最终购买的 SKU 通常是 [6039, 6134,4762 4754,4793,3144,4456,8146,8237,2754]

对于每个 SKU，我都有几十种产品特征的数据，例如价格、平均客户评分、发布年份、付款计划、颜色种类等。
我的问题：通过比较查看的产品与最终购买的产品的特征，我应该研究哪些统计技术和方法来回答这个研究问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/651984/statistical-technique-recommendation</guid>
      <pubDate>Tue, 30 Jul 2024 04:05:15 GMT</pubDate>
    </item>
    </channel>
</rss>