<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Thu, 20 Feb 2025 15:19:16 GMT</lastBuildDate>
    <item>
      <title>预测时变连续变量的危险比</title>
      <link>https://stats.stackexchange.com/questions/661632/predicting-hazard-ratio-for-time-varying-continuous-variable</link>
      <description><![CDATA[ i具有cox pH模型（拟合了R生存包），其时间变化持续变量（tt（）变换，天然立方样条，与分类预测指标的相互作用），我想知道我如何绘制与ci的危险预测连续变量范围的比率，其他变量保持固定。一直在尝试使用se.fit = true的新数据进行预测（），但这似乎失败了。]]></description>
      <guid>https://stats.stackexchange.com/questions/661632/predicting-hazard-ratio-for-time-varying-continuous-variable</guid>
      <pubDate>Thu, 20 Feb 2025 14:31:10 GMT</pubDate>
    </item>
    <item>
      <title>根据分类变量检测“ true”无效得分的“ false”无效分数</title>
      <link>https://stats.stackexchange.com/questions/661631/detecting-false-null-scores-from-true-null-scores-based-on-categorical-varia</link>
      <description><![CDATA[我从事教育统计数据，并且在各种测试中都有一个学生分数的数据集。在此数据集中，我有一个 fulence评分（这是一分钟内读取的单词数）和 profile 基于七种模态的阅读理解得分（进行）从1开始，学生面临严重的困难，使日常生活沟通，倾听和写入困难到7，这报告了阅读理解的水平）。这些测试是详尽的，每个学生都参加了测试（即使流动的参与评分较低）。。
 Fluence测试旨在检测日常沟通和阅读中的巨大困难，文本很容易阅读。一个可以在一分钟内读取少于120个单词的学生被认为是困难的。
 问题是，数据集中有错误的无效分数（应该是NAS的零），因为某些学校不让他们的班级的每个学生参加Fluence测试（是否因为老师认为学生的服用是不可能的参加测试之前的所有分数都达到0）。
我想使用阅读理解资料和其他辅助变量（例如学校身份证明），以检测和删除这些“ false”零得分在频率中。但是我不知道该怎么做。
我试图做出一些现实的假设：

理论上不应有剖面7的学生的剖面分数（实际上，此概况的学生的1％以上的学生得分为无效）
  fluence无效分数的学生比例应接近我数据中同一配置文件的零分数的比例。

由此，随着概况性能的提高，我应该降低零分数的比例。但是，我找不到这样做的模型，因为配置文件是一个分类变量（而且我只假设在7种模式中的2个中假设假设），而且因为我没有虚拟变量，该变量可告知null得分是否为A＆quit a＆quot ;真实的零评分或a false; quot零评分。
 i首先尝试通过在虚拟变量“ profile” profile&#39;profile == 7之前设置正常的分数概率的逻辑回归为零。平均值-20和标准偏差1，它降低了配置文件7的零分数的比例，但我真的不明白它如何按照我想要的方式影响其他配置文件（这是说，概况越糟，越多实际的无效分数比例可能接近数据中的零评分比例）。
事先感谢您提供的任何建议：）
 Steve ]]></description>
      <guid>https://stats.stackexchange.com/questions/661631/detecting-false-null-scores-from-true-null-scores-based-on-categorical-varia</guid>
      <pubDate>Thu, 20 Feb 2025 14:25:53 GMT</pubDate>
    </item>
    <item>
      <title>尖峰和slab中正常分布的混合物之间的联系</title>
      <link>https://stats.stackexchange.com/questions/661630/link-between-mixture-of-normals-and-laplace-distribution-in-spike-and-slab</link>
      <description><![CDATA[我正在阅读Spike-and-slab模型（主要是通过本文）。回顾一下，一般连续的尖峰和slab先验由 $ \ beta $ ，给出
  $$ P（\ beta \ Mid \ gamma，\ sigma^2）= \ prod_ {j = 1}^{p} 
\ left [（1- \ gamma_j）\ Mathcal {n}（0，\ sigma^2 \ tau_0^2） + \ gamma_j \ gamma_j \ mathcal {n}（0，\ sigma^2 \ sigma^2 \ tau_1^2） $$ 
 $$
p（\ gamma \ mid \ theta）= \ prod_ {j = 1}^{p} \ theta^{\ gamma_j}（\ gamma_j}（1  -  \ theta）^{1  -  \ gamma_j} \ theta），\ Quad $$ 
 $$ \ sigma^2 \ sim p（\ sigma^2）。$$ 
其中 $ 0＆lt; \ tau_0^2＆lt;＆lt; \ tau_1^2 $ 。现在，在论文中指出这是正常的混合物。我们还认为套索等于以下拉普拉斯先验
  $$
p（\ beta \ mid \ lambda）= \ prod_ {j = 1}^{p} \ frac {\ lambda} {2} {2} e^{ -  \ lambda | \ beta_jj |}，
$$ 
这导致以下尖峰和斜纹套件先验
  $$
p（\ beta \ mid \ gamma）= \ prod_ {j = 1}^{p} \ left [（1  -  \ gamma_j）\ psi（\ beta_j \ beta_j \ beta_j \ mid \ lambda_0） \ lambda_1）\ right]，
$$ 
 $$
p（\ gamma \ mid \ theta）= \ prod_ {j = 1}^{p} \ theta^{\ gamma_j}（1- \ theta）^{1  -  \ \ gamma_j}，
\ Quad 
$$ 
 $$
\ theta \ sim \ text {beta}（a，b）。
$$  
我还读过拉普拉斯分布是正常的混合物。我正在尝试将这些概念联系起来，但我正在努力。 那里有直接链接吗？我们可以将连续的尖峰和单杆重写为拉普拉斯分布或尖峰和slab套索作为正常的混合物？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/661630/link-between-mixture-of-normals-and-laplace-distribution-in-spike-and-slab</guid>
      <pubDate>Thu, 20 Feb 2025 14:12:34 GMT</pubDate>
    </item>
    <item>
      <title>参数方法绕过计算关节分布？</title>
      <link>https://stats.stackexchange.com/questions/661629/parametric-methods-bypass-calculating-the-joint-distribution</link>
      <description><![CDATA[如果我想使用平方损耗函数解决ML问题，那么最佳预测因子是 $ \ Mathbb {e} [y \ mid x] $  &lt;&lt;&lt;。 /p&gt;
有两种计算方法 $ \ Mathbb {e} [y \ mid x] $ 。我们要么平镇 $ \ Mathbb {p} _ {x，y} $ 是关节分布，要么假设 Mathbb {e} [y \ mid x] $ 是一个函数 $ f $   $ n $ 参数： $ p_i $ 。
如果我没记错的话，第一个解决方案是局部平均方法尝试在ML中使用的方法，例如K-NN，树。在第二种情况下，这是线性回归和神经网络尝试做的。
因此，参数方法不使用联合分布来计算 $ \ mathbb {e} [y \ mid x] $ ，假设贝叶斯预测器具有一个他们解决的某些机构形式。
但这意味着这些模型无法计算 $ \ text {var}（y \ id x）$ ，因为我们只是训练该模型以解决&lt;&lt; SPAN class =“ Math-Container”&gt; $ \ Mathbb {e} [y \ mid x] $ 。
我的理解正确吗？因此，我们可以得出结论，如果样本的数量很高，则本地平均方法是优越的，因为它们为我们提供了有关该问题的更多信息（有关 $ \ Mathbb {p} _ { x，y} $ 可以帮助我们计算更多的指标，而不是 $ \ Mathbb {e} [y \ mid x] $ ）。]]></description>
      <guid>https://stats.stackexchange.com/questions/661629/parametric-methods-bypass-calculating-the-joint-distribution</guid>
      <pubDate>Thu, 20 Feb 2025 14:07:44 GMT</pubDate>
    </item>
    <item>
      <title>在比例逻辑回归中解决“完美预测”</title>
      <link>https://stats.stackexchange.com/questions/661628/addressing-perfect-predictions-in-proportional-odds-logistic-regression</link>
      <description><![CDATA[我的结果是一个有序因素，其离散值在0到14之间（来自与神经发育相关的问卷的李克特量表）。值为0表示特定主题已回答“否” （可能的答案是“不可以”，“有时“有时”“经常”，“通常”）对一系列问题。 1的值是意味着对问题之一的答案有时是“有时”。等等。虽然在文献中，这种结果通常会用SQAURE词根转换以适合线性模型，但我正在尝试对其原始值进行建模。因此，我试图使用 polr 函数从 mass  r软件包使用 polr 函数。拟合了这些模型后，目的是在介入感兴趣的暴露时估计边际对比。虽然结果是有序的，但我计划提供平均对比度（例如，在没有干预和干预下，结果的平均差异）。
我在这里包括一个玩具示例，因为我无法共享我的数据：
 库（质量）
图书馆（表演）
图书馆（Tibble）
图书馆（dplyr）
图书馆（ggplot2）
图书馆（拼布）

df＆lt;  -  mtcars |＆gt;
  as_tibble（）|＆gt;
  突变（Carb =因子（Carb，ordered = true））

模型＆lt;  -  MASS :: POLR（
  公式= carb〜DISP + CYL + MPG，
  数据= DF，
  hess = t，
  方法=“逻辑”
）
model.simple＆lt;  -  mass :: polr（
  配方=碳水化合物〜1，
  数据= DF，
  hess = t，
  方法=“逻辑”
）

p1＆lt;  - 绘图（check_predictions（型号，迭代= 100，type =＆quort; iNCETE_BOTH＆quot; quot;））
p2＆lt;  - 绘图（check_predictions（model.simple，迭代= 100）
P1 + P2
 
这两个模型的结果，每种模型之一仅包括截距项，如下（就后验预测检查而言）：
    
您可以看到，这两个模型的预测非常相似。我通过自己的数据获得了类似的结果。我不明白这是怎么可能的，尤其是我的真正结果。我很想相信问题与 polr 有关，因为通过将gam（ mgcv ）与 ocat  mgcv ） &gt;作为家庭，我获得了截然不同的结果（较低级别的过度预测，尤其是0  [2] ）。这种行为是预期的吗？
  [2] ：我的数据集包含很大比例的零：
 ＆gt;表（dat $ promcome_variable）
  0 1 2 3 4 5 6 7 8 9 10 11 13 14 
155 74 77 48 43 26 17 14 14 8 3 2 3 1
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661628/addressing-perfect-predictions-in-proportional-odds-logistic-regression</guid>
      <pubDate>Thu, 20 Feb 2025 13:39:36 GMT</pubDate>
    </item>
    <item>
      <title>为什么在指数族中的足够统计量与随机样本的分布相同？</title>
      <link>https://stats.stackexchange.com/questions/661626/why-is-the-distribution-of-sufficient-statistic-same-as-the-random-sample-in-exp</link>
      <description><![CDATA[指数分布家族的定义为以下在弗格森的数学统计数据中：决策理论方法书：
   
一个足够的统计量， $ \ Mathbf {t} $ ，如下：
   
然后，在引理1中， $ \ Mathbf {t} $ 的分布被证明是定义1中的形式。但是如何证明这一点？我们知道随机样本是从指数级的家庭分布中得出的，但是为什么足够的统计数据的分布相同？
   ]]></description>
      <guid>https://stats.stackexchange.com/questions/661626/why-is-the-distribution-of-sufficient-statistic-same-as-the-random-sample-in-exp</guid>
      <pubDate>Thu, 20 Feb 2025 13:29:13 GMT</pubDate>
    </item>
    <item>
      <title>编码高比例的缺失值以使连续变量导致相互信息高于二进制变量的熵</title>
      <link>https://stats.stackexchange.com/questions/661624/encoding-high-proportion-of-missing-values-for-continuous-variable-results-in-mu</link>
      <description><![CDATA[这与 a&gt;但在这种情况下删除丢失值不是一个选项。
我尝试使用 sklearn.feature_selection.mutual_info_classif 来计算共同信息。这些不是我可以扔掉的观察结果，因为这些是“有意义的nulls”。 - 他们的失踪性龋齿信息。由于 mutual_info_classif 不接受缺失值，因此我将它们编码为非错失部分的外部值（例如-999）。最重要的是，只有0.15％的人口是二元目标的正类别。结果，我得到的共同信息高于目标的熵，这是不可能的：因为：
 $$
i（x; y）\ leq \ min（h（x），h（y））
$$ 
这是玩具示例：
 导入numpy作为np
来自sklearn.feature_selection import mutual_info_classif
来自Scipy.pexial Import Xlogy

rng = np.random.default_rng（seed = 42）
x = rng.pendential（1，10_000）
＃仿真编码nulls
x = np.append（x，-999 * np.ones（80_000））

＃完全独立的目标
y = np.zeros_like（x）
y_1 = rng.integers（0，len（x），150）
y [y_1] = 1

print（y y y y Mutual_info_classif的熵：h（y）= {mutual_info_classif（y [：，none]，y，y，y，iNCETE_FEATURES = true）[0]};）
打印（y的熵计算：h（y）= {xlogy（y.mean（），1/y.mean（））+xlogy（1-y.mean（），1/（1/（1-y.mean） （）））}＆quot;）
print（f＆quot X和y的互相信息来自mutual_info_classif：i（x，y）= {mutual_info_classif（x [：x [：，none]，y），y）[0]};）
 
结果：
 
显然是错误的，因为 x 和 y 是独立的，并且相互信息高于 y 的熵。]]></description>
      <guid>https://stats.stackexchange.com/questions/661624/encoding-high-proportion-of-missing-values-for-continuous-variable-results-in-mu</guid>
      <pubDate>Thu, 20 Feb 2025 13:14:05 GMT</pubDate>
    </item>
    <item>
      <title>优势比不变性：在逻辑回归中调整时如何？</title>
      <link>https://stats.stackexchange.com/questions/661623/odds-ratio-invariance-how-about-when-adjusted-in-logistic-regression</link>
      <description><![CDATA[我理解几率是不变的，这意味着您将获得OR（暴露与未暴露）的相同点估计值，即使您将暴露视为结果：
 


 
事件
没有事件




暴露
 a 
 b 


未暴露
 c 
 d 


 
 or =（ad）/（bc）
现在，我想知道该属性即使在逻辑回归中也是如此，同时调整了协变量。例如，假设我符合对年龄调整的暴露结果关系的逻辑回归：
 logit（pr（结果|曝光，年龄））=拦截 + beta1 *暴露 + beta2 * age 
，相应的（调整后的）优势比为：exp（beta1）
如果我通过曝光来翻转结果怎么样？是否有任何数学原因认为我会得到类似的赔率估计值？例如：
 logit（pr（暴露|结果，年龄））=拦截 + beta1 *结果 + beta2 * age 
我已经使用了一些实验数据尝试了此操作，而对于我指定了结果暴露关系的方向，似乎对Beta1获得的估计值非常相似。但是我无法弄清楚这是偶然的，还是它是“优势比”的“属性不变性”的属性的扩展。]]></description>
      <guid>https://stats.stackexchange.com/questions/661623/odds-ratio-invariance-how-about-when-adjusted-in-logistic-regression</guid>
      <pubDate>Thu, 20 Feb 2025 12:45:20 GMT</pubDate>
    </item>
    <item>
      <title>高斯差异隐私中的权衡功能的单调性W.R.T差异</title>
      <link>https://stats.stackexchange.com/questions/661621/monotonicity-of-the-tradeoff-function-in-gaussian-differential-privacy-w-r-t-var</link>
      <description><![CDATA[我正在研究权衡函数在 Gaussian差异隐私（GDP）的背景下，这衡量了在假设检验中区分两个正常分布的困难。
标准GDP框架认为均等方差的两个高斯分布但不同的方式：
  $$
n（\ mu_p，\ sigma^2）\ quad \ text {vs。} \ quad n（\ mu_q，\ sigma^2）。
$$  
在这种情况下，权衡功能定义明确，有助于量化隐私保证。
但是，在我的问题上，我最初考虑两个具有不同方差的高斯人：
  $$
n（\ mu_p，\ sigma_p^2）\ quad \ text {vs。} \ quad n（\ mu_q，\ sigma_q^2）。
$$  
为了简化分析，i 较低的两个方差带有一个共同方差 $ \ sigma_s^2 $ ，以：
  $$
\ sigma_s^2 \ leq \ min（\ sigma_p^2，\ sigma_q^2）。
$$  
我的理由是，由于原始分布具有较高的噪声水平，因此它们的区分性应比缩水噪声案例  。也就是说，如果：
  $$
t（n（\ mu_p，\ sigma_s^2），n（\ mu_q，\ sigma_s^2））
$$  
是缩水案例的权衡函数，然后应作为下限：
  $$
t（n（\ mu_p，\ sigma_p^2），n（\ mu_q，\ sigma_q^2））。
$$  
这是从增加的差异使两个分布难以区分的想法。
我的问题：

  GDP中的权衡函数是否已知在差异中是单调的？
 是否有建立此属性的正式证明或参考？我正在寻找严格表明折衷函数在差异中是非侵犯的文学作品。
 是否将这两个方差与常见的下限差异界定会在GDP设置中引入任何意外问题？ 

对相关定理，论文或参考的任何指示都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661621/monotonicity-of-the-tradeoff-function-in-gaussian-differential-privacy-w-r-t-var</guid>
      <pubDate>Thu, 20 Feb 2025 11:44:20 GMT</pubDate>
    </item>
    <item>
      <title>生存模型中的多项式对比</title>
      <link>https://stats.stackexchange.com/questions/661619/polynomial-contrasts-in-survival-models</link>
      <description><![CDATA[我一直在尝试使用此资源/示例来理解更好的多项式对比度： https://library.virginia.edu/data/articles/understanding-ordered-forderd-factors-in-a-a-linear-model 
我知道这是针对线性模型的，但是我试图使用COX回归遵循相同的步骤/逻辑，以实现事件的时间结果。我从上面网页上的示例中的理解（如果我错了，请纠正我）是，对于线性模型，使用有序因子等于使用类别的多项式-1 ，并且尽管使用不同的系数/SE，但两种方法都导致完全相同的p值（我认为使用poly（）vs ordered（））。
我一直在试图将其应用于Cox回归的示例，在这种情况下，这两种方法似乎并不相等。这是一个可再现的示例：
 库（生存）
数据（肺）
肺＆lt;  - 肺[Complete.cases（肺），]，]

肺 $ surv_obj＆lt;  -  with（肺，surv（time，status == 2））
肺$  ph.ecog_o＆lt;  - 订购（肺$ ph.ecog）

cox1＆lt;  -  coxph（surv_obj〜ph.ecog_o，data =肺）
cox2＆lt;  -  coxph（surv_obj〜poly（unclass（ph.ecog_o），2），数据=肺）
 
我无法插入图像，但结果是针对Cox1：
 致电：
coxph（公式= surv_obj〜ph.ecog_o，data =肺）

  n = 167，事件数= 120 

               COEF EXP（COEF）SE（COEF）Z PR（＆GT; | z |）  
PH.ECOG_O.L 1.57386 4.82525 0.69609 2.261 0.0238 *
PH.ECOG_O.Q 0.48669 1.62692 0.52681 0.924 0.3556  
PH.ECOG_O.C 0.08127 1.08467 0.27246 0.298 0.7655  
---
象征。代码：0&#39;***’0.001&#39;**’0.01&#39;*’0.05&#39;。’0.1’’1

            EXP（COEF）EXP（-COEF）下部.95上.95
ph.ecog_o.l 4.825 0.2072 1.2331 18.881
PH.ECOG_O.Q 1.627 0.6147 0.5794 4.569
ph.ecog_o.c 1.085 0.9219 0.6359 1.850

一致性= 0.615（SE = 0.028）
可能性比测试= 3 df，p = 0.003的13.65
WALD测试= 3 df，p = 0.001的15.48
得分（洛格兰克）测试= 3 df，p = 7E-04的16.99
 
对于Cox2：
 致电：
coxph（公式= surv_obj〜poly（unclass（ph.ecog_o），3），data =肺）

  n = 167，事件数= 120 

                                COEF EXP（COEF）SE（COEF）Z PR（＆GT; | z |）    
poly（unclass（ph.ecog_o），3）1 4.2891 72.9001 1.2037 3.563 0.000366 ***
poly（unclass（ph.ecog_o），3）2 1.2843 3.6122 1.1649 1.103 0.270224    
poly（unclass（ph.ecog_o），3）3 0.3106 1.3643 1.0413 0.298 0.765477    
---
象征。代码：0&#39;***’0.001&#39;**’0.01&#39;*’0.05&#39;。’0.1’’1

                             EXP（COEF）EXP（-COEF）下部.95上.95
poly（unclass（ph.ecog_o），3）1 72.900 0.01372 6.8886 771.48
poly（unclass（ph.ecog_o），3）2 3.612 0.27684 0.3683 35.42
poly（unclass（ph.ecog_o），3）3 1.364 0.73299 0.1772 10.50

一致性= 0.619（SE = 0.028）
可能性比测试= 3 df，p = 0.003的13.65
WALD测试= 3 df，p = 0.001的15.48
得分（洛格兰克）测试= 3 df，p = 7E-04的16.99
 
是什么导致在LM中并非如此的情况下，在这种情况下，p值的不一致是什么？假设一个人希望在我们没有数值原始数据的有序分类变量中测试线性或二次趋势，这两个模型中的哪个更准确？为什么？
预先感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/661619/polynomial-contrasts-in-survival-models</guid>
      <pubDate>Thu, 20 Feb 2025 11:32:06 GMT</pubDate>
    </item>
    <item>
      <title>meta-sem和相关矩阵</title>
      <link>https://stats.stackexchange.com/questions/661617/meta-sem-and-correlation-matrix</link>
      <description><![CDATA[我想进行一个元SEM来测试变量的预测因子和结果。
我的问题是：我没有每个独立变量（IV）与其他IV之间的相关性，也没有每个因变量（DV）和其他DV之间的相关性，因为我从不同的研究中提取了它们。鉴于此，如何构建相关矩阵？我可以将IVS或DVS之间的相关性设置为零吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661617/meta-sem-and-correlation-matrix</guid>
      <pubDate>Thu, 20 Feb 2025 09:06:48 GMT</pubDate>
    </item>
    <item>
      <title>预期的Fisher信息等于预期的得分函数平方？</title>
      <link>https://stats.stackexchange.com/questions/661613/expected-fisher-information-equal-to-expected-score-function-squared</link>
      <description><![CDATA[我理解图片中显示的证据，但最后一步对我来说尚不清楚。
    
最后一步不应该简单地为： $ = S（\ theta）^2 $ 。或那是因为 $ j（\ theta）= e [ -  \ frac {d s（\ theta）} {d \ theta}] $ ，因此 $ e [j（\ theta）] = j（\ theta）$ ，因为期望值的预期值是值本身？
也许太晚了，我在这里看不到一些细节。]]></description>
      <guid>https://stats.stackexchange.com/questions/661613/expected-fisher-information-equal-to-expected-score-function-squared</guid>
      <pubDate>Thu, 20 Feb 2025 00:00:12 GMT</pubDate>
    </item>
    <item>
      <title>样本量计算在事故分析中以危险比为非效率终点</title>
      <link>https://stats.stackexchange.com/questions/661608/sample-size-calculation-in-time-to-event-analysis-with-hazard-ratio-as-non-infer</link>
      <description><![CDATA[我正在对200名患者的数据集进行回顾性分析，这些患者接受了A或B治疗，然后在复发和死亡方面进行了研究。我已经进行了竞争风险（复发和非释放死亡率（NRM））以及使用COX pH模型的总体生存分析进行的生存分析。现在，我试图找出样本量是否足够大以确认非效率（Ni），Ni-Margin为HR 1.5，功率为0.9和0.05。 （或者，Ni-Margin不是危险比，而是中位生存时间或在24个月时失去无事件生存状态的累积发生率。不知道我的治疗组的标准偏差 /标准误差 /危险率 /生存率（治疗B）。我根本找不到有关如何根据一组的生存分析和定义的劣等缘的生存分析来计算样本量的建议。
我尝试的一种相当绝望的方法是使用建议的方程式在功率= 0.9和alpha = 0.05的条件下估算样本量。 （21 *（SD（对照）/ni-Margin）^2）在给定的MWE中，我将其应用于样本量以确认非效率，如果治疗组累积的发生率是2年失去无事件生存状态的。在对照组的95％CI下限累积发生率的95％高于2年时失去无事件生存状态的累积发病率。绝对看起来不正确，也不是我想使用的措施。
任何帮助将不胜感激！
 库（生存）
图书馆（dplyr）
图书馆（ggfortify）

患者＆lt;  -  c（seq（1,100））
状态＆lt;  -  rbinom（n = 100，size = 1，prob = 0.6）
ftime＆lt;  - 示例（尺寸= 100，x = 1:60，替换= true）
复发＆lt;  -  rbinom（n = 100，尺寸= 1，prob = 0.3）
df＆lt;  -  cbind（患者，状态，FTIME，复发）
as.data.frame（df） - ＆gt; DF

for（i in 1：nrow（df））{
  df  $ time_relapse [i]＆lt;  -  ifelse（df [i，“复发”] == 1，示例（size = 1，x = df $  ftime [i ] -1），NA）
}

df  $ nrm＆lt;  -  ifelse（df $  status == 1＆amp; df $ repapse == 0，1，0）

df  $ time_efs＆lt;  -  pmin（df $  ftime，df $ time_relapse，na.rm = true）

df％＆gt;％
  突变（cistat = case_when（复发== 1〜1，
                            nrm == 1〜2，
                            复发== 0＆amp; nrm == 0〜0）） - ＆gt; DF

df  $ cistat＆lt;  - 因子（df $  cistat，latver = c（0,1,2），labels = c（＆quort&#39;censored; ，“ NRM”）

fit＆lt;  -  survIt（surv（time_efs，cistat）〜1，data = df）

＃功率的样本量计算= 0.9，alpha = 0.05，参考2年无事件生存 
强化（fit）％＆gt;％
  过滤器（event ==;（s0）＆quot;） - ＆gt; fit_s0

fit_s0 [whe.min（abs（fit_s0 $ time -time -24）），]  - ＆gt; power_data_2y＃连续24个月的时间

21 * 
  （（（power_data_2y  $ std.err * sqrt（max（fit_s0 [，“ n.risk”）））） /＃将std.err转换为SD
 （power_data_2y $  pstate -power_data_2y $ low）
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661608/sample-size-calculation-in-time-to-event-analysis-with-hazard-ratio-as-non-infer</guid>
      <pubDate>Wed, 19 Feb 2025 22:09:21 GMT</pubDate>
    </item>
    <item>
      <title>AR [I] mA [x]模型比标准回归有什么好处</title>
      <link>https://stats.stackexchange.com/questions/661601/what-is-the-benefit-of-arimax-models-over-standard-regression-with-lagged-pr</link>
      <description><![CDATA[我试图更深入地了解时间序列模型，我一直回到这种根本的困惑。如果我们成功地通过包括结果的滞后版本和其他滞后预测变量来显式地模型   ，我们为什么需要ARMAS？当我们错误地忽略必要的自相关预测变量并且在错误中存在残留的自相关时，ARMA是否只是涵盖了案例（即，如果我们有正确的滞后或变量，那么简单的回归在理论上就足够了，但从来没有实践）？）？
使用滞后的预测变量（称为Cochran-Orcutt估计？）似乎令人信服，但据说您也失去了效率。省略的可变自相关和效率丧失是在简单回归中使用ARMA模型的基本原因，还是我缺少某些内容？]]></description>
      <guid>https://stats.stackexchange.com/questions/661601/what-is-the-benefit-of-arimax-models-over-standard-regression-with-lagged-pr</guid>
      <pubDate>Wed, 19 Feb 2025 18:56:13 GMT</pubDate>
    </item>
    <item>
      <title>了解一个样本比例的功率公式：受限与无约束的方法</title>
      <link>https://stats.stackexchange.com/questions/661597/understanding-power-formulas-for-one-sample-proportion-constrained-vs-unconstr</link>
      <description><![CDATA[我遇到了以下公式，以估计进行平等的一个样本比例测试（对于大样本）：
  $$
1- \ beta = \ phi \ left（\ frac {\ sqrt {n} | \ delta | -z _ {\ alpha/2} \ sqrt {\ pi_0（1- \ pi_0）}} 1- \ pi_1）}} \ right）
$$  
其中 $ \ pi_0 $ 和 $ \ pi_1 $ 分别是NULL和NULL和替代假设， $ \ delta = \ pi_0- \ pi_1 $ ， $ z _ {\ alpha/2} $ 是标准常规变量 $ z $  at  $ \ alpha/2 $ ， $ \ beta $ 是II型错误率下的II类错误率替代假设， $ \ phi $   $ z $ 。。
在这个公式中让我感到困惑的是术语 $ \ pi_0（1- \ pi_0）$ ，这表明，在替代假设下，测试统计量的差异 $ z $ 在某种程度上受零假设下比例方差的影响。
看似更明智的我认为公式将是：
  $$
1- \ beta = \ phi \ left（\ frac {\ sqrt {n} | \ delta |} {\ sqrt {\ sqrt {\ pi_1（1- \ pi_1）}}} -z _ {
$$  
这意味着在替代假设下，测试统计量的方差 $ z $ 仅受的影响$ \ pi_1（1- \ pi_1）$   - 而不是 $ \ pi_0（1- \ pi_0）$ ，这对我来说更有意义，因为功率是 $ z $ 仅在替代假设下进行统计。
我一直在寻找一种解释，发现两个公式都出现在临床研究中的样本量计算中（第二版，2008年）      by Chow，Shao和Wang。在  的大型样本测试（第84-88页）中，作者将第一个公式称为约束公式，第二个公式为无约束的公式。虽然在 4.1.5备注 中，他们讨论了他们的不同假设并在权力方面进行比较，但他们没有明确解决其相对固有有效性。
这导致了我的问题：为什么在这种情况下，有限的公式（第一个）在不受约束的公式上被认为是正确的？ 
任何见解或解释都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661597/understanding-power-formulas-for-one-sample-proportion-constrained-vs-unconstr</guid>
      <pubDate>Wed, 19 Feb 2025 17:30:11 GMT</pubDate>
    </item>
    </channel>
</rss>