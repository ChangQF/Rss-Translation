<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 22 Apr 2024 01:01:23 GMT</lastBuildDate>
    <item>
      <title>为什么是随机变量而不是随机数+预测？</title>
      <link>https://stats.stackexchange.com/questions/645512/why-random-variables-and-not-random-numbers-projections</link>
      <description><![CDATA[我正在阅读 Wasserman 的所有统计数据，并且正在寻找现实检验。
我想我已经对形式定义或随机变量有了基本的了解。随机变量是从样本空间到实数的函数。实数很有用，因此我们经常发现自己想要将非结构化样本空间的概率分布投影到实数中。我们使用这个投影，这样我们就可以做算术、代数和微积分等等。
但是花了一点时间研究这个定义，感觉就像随机变量将两个不同的概念打包到一个包中。两个概念对我来说更容易分开思考。这两个概念是

实数的概率分布。为了简洁起见，我将这些随机数称为随机数。

从任意分布到实数分布的投影。为了简洁起见，我将这些称为数字投影。


许多对随机变量的研究似乎都是对随机数的变相研究。例如密度函数和累积分布函数只需要随机数的概念就有意义。对于标准随机变量也是如此 - 正态分布、泊松分布、均匀分布等。这些本质上与数值投影无关，我们可以在不考虑投影的情况下研究它们。
然后还有数值投影的属性。某些随机数可能更容易根据投影来定义。我们希望通过使用数字投影来测量其他分布。掌握了随机数后，我们就可以研究数值投影的性质。
所以现实检查：这是一种非常错误的思考随机变量的方式吗？将它们视为随机数和数字投影似乎对我有帮助，但我想询问一些专家的意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/645512/why-random-variables-and-not-random-numbers-projections</guid>
      <pubDate>Mon, 22 Apr 2024 00:50:10 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯时变系数</title>
      <link>https://stats.stackexchange.com/questions/645509/bayesian-time-varying-coefficient</link>
      <description><![CDATA[当我使用贝叶斯时变回归撰写一篇关于某些国家财政政策的周期性如何随时间演变的论文时，我想问一些问题。

我知道贝叶斯回归需要先验分布（由模型制作者选择），但我不知道先验分布应该是什么。我应该使用非信息先验吗？
贝叶斯时变回归实际上是如何工作的？它是否类似于正常回归中的滚动窗口方法，或者是否有另一种方法可以在贝叶斯回归中进行时变系数模型？
]]></description>
      <guid>https://stats.stackexchange.com/questions/645509/bayesian-time-varying-coefficient</guid>
      <pubDate>Sun, 21 Apr 2024 21:04:06 GMT</pubDate>
    </item>
    <item>
      <title>多级分段回归</title>
      <link>https://stats.stackexchange.com/questions/645507/multilevel-segmented-regression</link>
      <description><![CDATA[我有一些关于几家医疗机构每年接种 X 疾病疫苗的医护人员比例的数据。我想评估两次大规模干预措施对感兴趣结果（接种疫苗的医护人员的比例）的影响，其范围在 0 和 1 之间。
我计划运行分段回归模型。鉴于我有重复的测量，我正在考虑使用多级二项式模型。
我的想法是使用机构的 ID 作为随机截距（不同机构的基线比例可能有所不同），使用时间作为随机斜率：
binom_model &lt;- glmer(vax_proportion ~ 时间 + 干预1 + time_since1 + 干预2 + time_since2 + (1 + 时间|机构_id), 权重 = 分母, 家庭 = “二项式”)
哪里
vax_proportion = 接种疫苗的个体比例，
时间 = 1-12 之间的整数（我有超过 12 年的数据），
intervention1 = 0/1（在intervention1之前编码为0，之后编码为1），
time_since1 = 从1开始计数...当干预1开始时，之前为0，
intervention2 = 0/1（在intervention2之前编码为0，之后编码为1），
time_since2 = 从1开始计数...当干预2开始时，之前为0，
分母 = 用于计算比例的分母
您认为上述模型足以解释由于重复测量而导致的自相关吗？
虽然模型中的随机效应具有随机斜率的时间，但当我尝试添加更多随机效应（例如 (1 + time_since1|id) + (1 + time_since2|id) 时，模型会崩溃。
我的理解是，虽然我的模型考虑了干预前自由变化的时间效应1，但它对于干预 1 或 2 之间以及干预 2 之后的时间段并没有起到同样的作用。]]></description>
      <guid>https://stats.stackexchange.com/questions/645507/multilevel-segmented-regression</guid>
      <pubDate>Sun, 21 Apr 2024 18:23:55 GMT</pubDate>
    </item>
    <item>
      <title>对数转换数据的 MAD（中值绝对偏差）的指数是否测量与未转换数据中值的相对距离？</title>
      <link>https://stats.stackexchange.com/questions/645506/is-the-exponent-of-the-mad-median-absolute-deviation-of-log-transformed-data-m</link>
      <description><![CDATA[我想确认采用对数转换数据的 MAD 指数是否可以衡量与原始未转换数据中位数的相对距离。
假设我的对数转换数据的 MAD 为 0.2，通过取其指数得到的值为 1.22。这个 1.22 是否意味着原始数据在中位数附近变化了 22%？
谢谢
Anon9001]]></description>
      <guid>https://stats.stackexchange.com/questions/645506/is-the-exponent-of-the-mad-median-absolute-deviation-of-log-transformed-data-m</guid>
      <pubDate>Sun, 21 Apr 2024 18:20:34 GMT</pubDate>
    </item>
    <item>
      <title>结构矩阵的导数</title>
      <link>https://stats.stackexchange.com/questions/645505/derivative-of-structure-matrices</link>
      <description><![CDATA[我正在尝试遵循“高级多元矩阵统计”，第 1.4 章。我知道这本书已经很老了，但是我的时间相当有限，而且我正在阅读的论文引用了这本书。此外，我在数学领域问了一个相关但不同的问题，但我想因为这是一本统计书我会在这里得到更多答案。自从问了另一个问题以来，我有了一些进一步的了解，但仍然无法回答一些问题。
在这本书中，我们将矩阵的导数定义为 $$\frac{dY}{dX} = \frac{d\text{vec}^T(Y)} {d\text{vec}(X)}.$$ 然后我们定义了一个结构化（toep/symm/etc）矩阵$X$，图案化矩阵 $X(K)$，其中的想法是图案化矩阵 $X(K)$ span&gt;是“子集” $X$。例如，如果 $X$ 是对称的，则 $X(K)$ 可以是上三角形部分。经过第 1.3 章中的大量理论构建后，自然产生了模式矩阵相互微分的定义，$$\frac{dY(K_2)}{dX(K_1)} = T(K_1)\frac{dY}{dX}T^T(K_2),$$ 其中 $T(K)$ 是这样的$T(K)\text{vec}(X) = \text{vec}(X(K))$。
现在这是我的问题。至少，据我了解，上述定义中存在的导数 $\frac{dY}{dX}$ 仍然是“结构化矩阵与结构化矩阵的导数” &#39;。例如，如果 $Y=X \in \mathbb{R}^{p\times p}$ 对称，则  $\frac{dY}{dX} \neq I$ 而是 $\frac{dY}{dX} = I_{p^2} + K_{p, p} - \text{diag}\left(K_{p, p}\right) $，其中 $K_{d,d}$ 是交换矩阵和 $\text{diag}$ 表示仅取对角线元素。我知道已经提出了一个框架来取（结构化矩阵的特定部分）wrt（结构化矩阵的特定部分）的导数，但我仍然不知道如何取（结构化矩阵）wrt的导数（结构化矩阵）。
例如，给定对称 $\Psi$，$\frac{d\Psi^{-1 }}{d\Psi}$？]]></description>
      <guid>https://stats.stackexchange.com/questions/645505/derivative-of-structure-matrices</guid>
      <pubDate>Sun, 21 Apr 2024 17:18:39 GMT</pubDate>
    </item>
    <item>
      <title>SuperLearner 中的元模型采用哪种算法？</title>
      <link>https://stats.stackexchange.com/questions/645504/which-algorithm-for-meta-model-in-superlearner</link>
      <description><![CDATA[您使用哪种算法作为 SuperLearner 的元模型？我总是经常看到回归，但我没有得到很好的预测。我在 SuperLearner 中尝试了所有其他算法，并获得了越来越好的预测性能，直到我运行随机森林，这使我的 ROC AUC = 1。最有可能的是，这是过度拟合。我如何知道其他算法是否可能过度拟合？如果 RF 过度拟合，我如何证明它们的使用合理？]]></description>
      <guid>https://stats.stackexchange.com/questions/645504/which-algorithm-for-meta-model-in-superlearner</guid>
      <pubDate>Sun, 21 Apr 2024 17:12:59 GMT</pubDate>
    </item>
    <item>
      <title>如何将模型系数的对比集转换为两个嵌套模型的定义以进行似然比测试？</title>
      <link>https://stats.stackexchange.com/questions/645502/how-to-translate-the-set-of-contrasts-over-model-coefficients-into-definitions-o</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/645502/how-to-translate-the-set-of-contrasts-over-model-coefficients-into-definitions-o</guid>
      <pubDate>Sun, 21 Apr 2024 16:31:45 GMT</pubDate>
    </item>
    <item>
      <title>如何确定从图像中提取的特征向量是否代表特定任务？</title>
      <link>https://stats.stackexchange.com/questions/645501/how-can-you-determine-whether-a-feature-vector-extracted-from-an-image-is-repres</link>
      <description><![CDATA[在视频摘要项目中根据视频帧的特征对其进行评分的任务中，
如果使用预训练的 CNN（例如 GoogleNet、VGG 和 ResNet）提取帧特征，如何确定哪个网络最适合摘要任务？
我知道仅靠特征无法确定帧的重要性，因此我将视频分成多个片段，并在摘要中考虑得分较高的片段。
我的问题是，有一种方法可以根据这些模型的重要性得分来评估帧的特征表示质量，还是我应该对每个模型进行试验并根据最佳性能进行选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/645501/how-can-you-determine-whether-a-feature-vector-extracted-from-an-image-is-repres</guid>
      <pubDate>Sun, 21 Apr 2024 16:18:00 GMT</pubDate>
    </item>
    <item>
      <title>Cox 或 Fine-Gray 模型可以包含观察期间发生的曝光吗？</title>
      <link>https://stats.stackexchange.com/questions/645500/can-cox-or-fine-gray-model-include-exposure-that-occurs-during-observation</link>
      <description><![CDATA[我正在制作一个关于怀孕的Fine-Gray模型，但我注意到一些妊娠并发症可能会在观察过程中而不是在开始时出现，因为这些并发症通常是在观察过程中通过检查发现的，而且很难发现找到确切的发生时间，此外，在达到诊断标准之前，它们往往已经产生了一些潜在的影响。我做过ph测试，都没有什么意义，我是不是觉得这些并发症虽然在观察过程中可能会出现，但是有“预诊断影响”呢？和 ph 测试显示它们的效果不会随时间变化，因此可以将其视为观察开始时发生的暴露并包含在 Fine-Gray 模型中吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645500/can-cox-or-fine-gray-model-include-exposure-that-occurs-during-observation</guid>
      <pubDate>Sun, 21 Apr 2024 15:48:47 GMT</pubDate>
    </item>
    <item>
      <title>我的列联表标准化残差图不是标准正态分布，为什么？</title>
      <link>https://stats.stackexchange.com/questions/645498/my-plot-of-standardised-residuals-of-contingency-table-are-not-standard-normally</link>
      <description><![CDATA[我正在学习列联表中的标准化残差。
在“分类数据分析简介”中作者：Alan Agresti (2007) 我发现了以下内容：

我想验证上述说法，即在零假设下，较大列联表的标准化残差分布为标准正态分布。
作为验证我的代码的教科书示例参考，我使用 Eric Naioti 和 Erika Mudrak 使用调整后的标准化残差解释列联表：

这里还显示标准化残差的数字：

我可以用自己的代码重现：
数组([[ 6.13651969, -4.25381552, -0.57502606, -2.28789602],
       [ 2.16428238, -3.39788279, 2.05021621, -0.50826301],
       [-0.10082422、-2.31105226、0.9895118、2.5765686]、
       [-8.32824833、9.96755012、-2.73797698、0.73202319]])

现在我知道该部分没有错误，我生成了一个相当大的列联表，有 4000 行和 3000 列。我画出了“观察到的”单元格条目均匀分布在 10 到 100 之间，我认为这应该会产生独立的单元格内容。
然后我应用了与上面相同的代码，完全期望单元格标准化残差的直方图显示标准正态分布。
但是，我得到了这个：

问题：为什么我的直方图不是标准正态分布或者我遗漏了什么？
我用来生成绘图的代码是这样的：
将 numpy 导入为 np
从 scipy 导入统计数据
导入 matplotlib
从 matplotlib 导入 pyplot 作为 plt

matplotlib.use(&#39;TkAgg&#39;)


plt.ion()


N_ROWS = 4000
N_COLS = 3000

# 生成独立的 (??) 观察结果
rng = np.random.default_rng(1)
df_obs = rng.integers(低=10，高=100，大小=(N_ROWS，N_COLS))

# 获取期望值，观察低 p 值 (??)
chi2, pvalue, dof, df_exp = stats.chi2_contingency(df_obs, Correction=False)

# 获取边际值，用于计算标准化残差（如下）
margin_col = df_obs.sum(轴=1)
margin_row = df_obs.sum(轴=0)
sum_tot = margin_col.sum()

# 循环每个单元格，记录其残差和标准化残差
resids_lst = 列表()
resids_std_lst = 列表()
对于范围内的 irow(N_ROWS)：
    对于范围内的 icol(N_COLS)：

        obs = df_obs[irow, icol]
        exp = df_exp[irow, icol]

        marg_col = margin_col[irow]
        marg_row = margin_row[icol]
        std_fac = exp * (1. - marg_col/sum_tot) * (1. - marg_row/sum_tot)

        残差 = obs - exp
        resid_std = resid / np.sqrt(std_fac)

        resids_std_lst.append(resid_std)

# 绘制记录的残差
plt.figure()
plt.suptitle(&#39;期望标准化残差的标准正态分布？&#39;)
plt.hist(resids_std_lst, alpha=0.5, label=&#39;标准化残差&#39;)
plt.图例()
]]></description>
      <guid>https://stats.stackexchange.com/questions/645498/my-plot-of-standardised-residuals-of-contingency-table-are-not-standard-normally</guid>
      <pubDate>Sun, 21 Apr 2024 15:36:52 GMT</pubDate>
    </item>
    <item>
      <title>理解“求 100 次抛硬币的 95% 置信区间”的问题</title>
      <link>https://stats.stackexchange.com/questions/645497/understanding-the-question-of-find-the-95-confidence-interval-of-100-coin-flip</link>
      <description><![CDATA[我一直看到这个问题...
&lt;块引用&gt;
求 100 次抛硬币的 95% 置信区间

这是一个经典的数据科学或统计面试问题。所以，我相信你应该使用方法来找到答案，并使用 CLT。
但是...我该如何解释这个问题？我是否认为这是询问抛硬币次数或 $\hat{p}$ 的置信区间？
对于伯努利，标准误差与平均值相同......对于公平的硬币：
$$SE = \frac{\sigma}{\sqrt{n}} = \sqrt{\frac{p(1-p)}{n}} = \sqrt{\压裂{.5(1-.5)}{100}} = 0.05$$
$$CI = \hat{x} \pm 1.96 SE \implies .5 \pm 1.96 \cdot 0.05 \implies (0.402, 0.598)$$
假设我们想要翻转次数的置信区间...如果有足够的翻转次数，我们是否可以仅使用 z 分数来表示成功次数（好吧，写出来似乎并不是 z 分数）？
$$ \mu = n \cdot p \quad \sigma = \sqrt{n\cdot p \cdot (1-p)} \意味着 z = \frac{n \cdot p }{\sqrt{n\cdot p \cdot (1-p)}} = 10$$
$$CI = (30.4, 69.6)$$
当我模拟这个时，我找到了与我在网上看到的相匹配的答案......我得到：
$$CI = (40, 60)$$
该值非常接近 $p$ 的置信区间，但乘以 $100$。我可以将 $p$ 的 CI 乘以 $100$ 吗？
将 numpy 导入为 np
将 pandas 导入为 pd

def Bernoulli_ci(n, p =.5, ci=1.96):
  se = (p*(1-p)/n)**.5
  我=ci*se
  返回（p - 我，p + 我）

def binom_ci(n, p =.5, ci=1.96):
    zscore = (n*p)/(n*p*(1-p))**.5
    我 = ci*zscore
    返回（n*p - 我，n*p + 我）


S = 100000
N = 100
df = pd.DataFrame(np.random.random(size=(S, N)))
df = (df &gt; .5).sum(axis=1) # 头数
print(&quot;伯努利 CI&quot;, bernoulli_ci(N))
print(&quot;binom CI&quot;, binom_ci(N))

阿尔法 = .05
df = df.sort_values()
print(&quot;emerical ci&quot;, (df.quantile(alpha/2), df.quantile(1-alpha/2)))
]]></description>
      <guid>https://stats.stackexchange.com/questions/645497/understanding-the-question-of-find-the-95-confidence-interval-of-100-coin-flip</guid>
      <pubDate>Sun, 21 Apr 2024 15:21:46 GMT</pubDate>
    </item>
    <item>
      <title>检测大型逻辑回归模型中的交互</title>
      <link>https://stats.stackexchange.com/questions/645493/detecting-interactions-in-large-logistic-regression-models</link>
      <description><![CDATA[我有一个包含数百万个二元响应观察值的数据集，“成功”概率平均为 1% 到 2%。该数据集包含多个分类变量（约 20 个类别，其中有多达 50 个类别）和数值变量（约 10 个）。我安装了主效应逻辑广义线性模型（GLM）作为基线和梯度提升树（GBT）。根据测试集上的对数损失来衡量，GBT 明显优于 GLM。然而，当仅比较它们的边际效应（通过观察合适的图来测量）时，这两个模型似乎非常相似。因此，GBT 优于 GLM 的一个潜在原因可能是包含了交互作用。我想验证这一点，并最好找到（其中一些）这些交互。
我的问题

有哪些可能的方法可以在 GBT 模型中找到交互作用？
更一般性的信息：我在哪里可以找到关于寻找交互的最新技术以及当前可行和不可行的信息？

我的目标非常务实：

我不需要找到所有交互，只需找到一些“重要”的交互即可。那些将是一个很好的开始。
我不需要对研究结果进行假设检验。
但是方法需要在给定“标准”的情况下是可实现的。计算资源。

到目前为止我的尝试

考虑到数据集的大小和输入的数量，任何详尽的搜索方法（例如逐步回归）似乎都是徒劳的。
与 Lasso 等正则化选择存在同样的问题。特别是，由于数字输入，稀疏设计矩阵是不可能的。
我知道弗里德曼的 H 统计量，但尚未尝试过。我看到的问题是它基于方差分解而不是对数损失。这也是一种详尽的搜索，并且（最多？）仅适用于成对交互。此外，其估计基于排列，并且某些输入表现出很强的依赖性。
数据集很复杂，并且没有先验的理由说明交互应限制为对。我“猜测”的成功在于基于我的一般领域知识的交互以及通过包含在 GLM 中进行验证的交互受到限制。
]]></description>
      <guid>https://stats.stackexchange.com/questions/645493/detecting-interactions-in-large-logistic-regression-models</guid>
      <pubDate>Sun, 21 Apr 2024 11:22:16 GMT</pubDate>
    </item>
    <item>
      <title>力矩比和 L 力矩比：</title>
      <link>https://stats.stackexchange.com/questions/645492/moment-ratios-and-l-moment-ratios</link>
      <description><![CDATA[我想知道力矩比图和L力矩比图之间的区别。
据我了解，矩比图的目的是检测概率密度函数的类型，查看偏度和峰度系数的值。
L 力矩比与力矩比相比有何优势？
为什么要考虑订单统计。
我发现 L 矩的语法很难理解
力矩比图和L力矩图是如何生成的。]]></description>
      <guid>https://stats.stackexchange.com/questions/645492/moment-ratios-and-l-moment-ratios</guid>
      <pubDate>Sun, 21 Apr 2024 11:04:05 GMT</pubDate>
    </item>
    <item>
      <title>树状图的名称，显示变量聚类如何影响解释的方差</title>
      <link>https://stats.stackexchange.com/questions/645486/name-for-a-dendrogram-showing-how-variable-clustering-affects-variance-explained</link>
      <description><![CDATA[这是来自 Harrell 的 RMS：

我确信我见过类似的树状图，用于说明变量聚类对 $R$ /  的影响$R^2$。它的 x、y 轴与刚刚显示的图表相反，但在其他方面看起来非常相似。它的轴上不是 $\rho^2$ ，而是 $R$ 或 $R^2$，以便您可以看到组合变量如何减少$R^2$。
我已经尝试了我能想到的所有搜索词，但找不到此类树状图的具体名称或可能生成它的包。有谁知道吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645486/name-for-a-dendrogram-showing-how-variable-clustering-affects-variance-explained</guid>
      <pubDate>Sun, 21 Apr 2024 08:30:44 GMT</pubDate>
    </item>
    <item>
      <title>使用背景减法来识别连续帧图像中的某些对象以开始标记对象进行 YOLO 训练是否合理？</title>
      <link>https://stats.stackexchange.com/questions/645474/is-it-reasonable-to-use-background-subtraction-to-identify-some-objects-in-seque</link>
      <description><![CDATA[我知道背景减除并不是对象检测的完整解决方案，但我已经尝试过用它来识别固定背景相机场景中出现的潜在新对象（需要解析数百万张图像以进行手动标记）。这个想法是使用背景减法来在原始数据中找到至少一个更明显对象的初始样本，以开始为训练集进行标记（一种样本启发式），并开始迭代训练 YOLO 模型，以便稍后它可以经过微调后概括并识别更微妙的对象。尽管最初存在局限性，这种方法有什么问题吗？与使用模拟数据开始相比如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/645474/is-it-reasonable-to-use-background-subtraction-to-identify-some-objects-in-seque</guid>
      <pubDate>Sat, 20 Apr 2024 22:22:01 GMT</pubDate>
    </item>
    </channel>
</rss>