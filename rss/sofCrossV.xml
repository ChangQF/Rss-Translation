<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 15 Sep 2024 09:15:50 GMT</lastBuildDate>
    <item>
      <title>双变量数据生成</title>
      <link>https://stats.stackexchange.com/questions/654392/bivariate-data-generate</link>
      <description><![CDATA[考虑具有累积分布函数的均匀分布函数$$F(t_1,t_2)=t_1^{1+\theta\log(t_2)}t_2,0&lt;t_1,t_2&lt;1; \theta\leq 0$$。
我想从这个分布生成数据（使用 R 编程）。我知道如何从单变量生成数据，但我不知道双变量。请帮助我。提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654392/bivariate-data-generate</guid>
      <pubDate>Sun, 15 Sep 2024 09:02:57 GMT</pubDate>
    </item>
    <item>
      <title>“手动”加权回归</title>
      <link>https://stats.stackexchange.com/questions/654391/manually-weighted-regression</link>
      <description><![CDATA[我有一个包含加权观测值的数据集。我正在尝试找到一种无需指定权重即可执行加权回归的方法。也就是说，我想要找到变量 $X$ 和 $Y$ 的变换（表示为 $\tilde{X}$ 和 $\ddot{Y}$），这样当对 $\tilde{X}$ 执行 $\ddot{Y}$ 的 OLS 估计时，我实际上使用权重 $W$ 对 $X$ 执行 $Y$ 的加权回归。
如果 $W$ 是对角线矩阵，则 OLS 系数可按如下方式获得：
$$
\hat{\beta}_{wols} = (X&#39;WX)^{-1} X&#39;WY。
$$
这意味着我可以用 $W$ 的平方根来变换 $X$ 和 $Y$：
$$
\ddot{Y} = \sqrt{W}Y\\
\tilde{X} = \sqrt{W}X。
$$
请注意，这是一个无截距的回归，其中 $\ddot{Y}$ 是平方根加权变量 $X$，以及这些平方根权重的向量。
我的问题是模型统计数据（特别是 R 平方）与常规加权回归不同。
有没有人知道另一种变换，当我在变换后的变量上计算未加权 OLS 估计量 $\hat{\beta}_{ols}$ 时，我会得到 $\hat{\beta}_{wols}$ 和相应的模型统计数据？
我的用例是我想“破解”不支持权重来执行加权回归的估算程序。]]></description>
      <guid>https://stats.stackexchange.com/questions/654391/manually-weighted-regression</guid>
      <pubDate>Sun, 15 Sep 2024 07:58:18 GMT</pubDate>
    </item>
    <item>
      <title>如果误差是同质的但非正态的，那么线性估计量可以是蓝色吗？</title>
      <link>https://stats.stackexchange.com/questions/654388/if-the-errors-are-homogenous-but-non-normal-can-the-linear-estimator-be-blue</link>
      <description><![CDATA[在高斯-马尔可夫假设下，OLS 为 BLUE 的要求是：

线性：估计量必须是数据的线性函数
无偏性：估计量的预期值应等于总体参数
同方差性：误差方差为常数
无完美多重共线性：解释变量不应完全共线。
外生性：误差应为零均值，且与解释变量不相关。

这是否意味着只要满足这些假设，无论误差分布如何，OLS 估计量都是 BLUE？
我有时读到误差必须呈正态分布才能为 BLUE。我有时读到如果不是，也没关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/654388/if-the-errors-are-homogenous-but-non-normal-can-the-linear-estimator-be-blue</guid>
      <pubDate>Sun, 15 Sep 2024 06:12:25 GMT</pubDate>
    </item>
    <item>
      <title>理解简单线性回归误差方差与 Y 的比较符号</title>
      <link>https://stats.stackexchange.com/questions/654387/understanding-notation-of-simple-linear-regression-error-variance-compared-with</link>
      <description><![CDATA[在简单线性回归中，不假设条件形式，我们说$Var(\epsilon) = \sigma^2$，因为误差方差是同质的。
但我不明白为什么会这样。
$Var(\epsilon) = E[Y - \beta x] = E[Y - \hat{Y}]$
但这似乎不等于 Y 的方差。
这只是符号上的差异吗？误差方差是 Y 中无法解释的方差。Y 的方差是无法解释和解释的方差的总和。
那么我们是不是只想说误差项与 $Y$ 中的方差成比例，因为这个方差是导致误差围绕 $\beta x$ 的因素？]]></description>
      <guid>https://stats.stackexchange.com/questions/654387/understanding-notation-of-simple-linear-regression-error-variance-compared-with</guid>
      <pubDate>Sun, 15 Sep 2024 04:32:29 GMT</pubDate>
    </item>
    <item>
      <title>什么是移动平均模型（真的！）</title>
      <link>https://stats.stackexchange.com/questions/654385/what-is-a-moving-average-model-really</link>
      <description><![CDATA[一段时间以来，我一直在尝试理解时间序列环境中的移动平均模型是什么。
我知道它本质上是基于过去预测误差的回归，形式如下：https://otexts.com/fpp3/MA.html（请参阅本文第 3 行）。
我很难理解的是 - 这些过去的预测误差到底是什么？或者更具体地说，这些过去预测误差中的预测元素的性质是什么？例如，它只是目标时间序列到给定点的移动平均值吗？还是别的什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654385/what-is-a-moving-average-model-really</guid>
      <pubDate>Sun, 15 Sep 2024 02:51:16 GMT</pubDate>
    </item>
    <item>
      <title>当似然函数本身是一个猜测时</title>
      <link>https://stats.stackexchange.com/questions/654383/when-the-likeihood-function-is-itself-a-guess</link>
      <description><![CDATA[当存在观测值 x 和相关未知数 $T$，但没有明显的 $f(x \mid T)$ 模型时，贝叶斯会做什么？我举的例子是在商业领域，专家报告了新商业理念未来现金流的当前估值。在硬科学中是否有类似的例子，历史数据允许我们估计不同 $x$ 和 $T$ 的经验似然分布 $f(x \mid T)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/654383/when-the-likeihood-function-is-itself-a-guess</guid>
      <pubDate>Sat, 14 Sep 2024 23:35:47 GMT</pubDate>
    </item>
    <item>
      <title>回归线是否经过>1 维的质心？</title>
      <link>https://stats.stackexchange.com/questions/654378/does-the-regression-line-go-through-the-center-of-mass-in-1-dimension</link>
      <description><![CDATA[众所周知，我也找到了证据（比如这里 https://math.stackexchange.com/questions/635670/show-that-the-least-squares-line-must-pass-through-the-center-of-mass），在简单线性回归中，回归线总是经过质心。但我没有找到任何证据将其推广到我们具有一般数量的协变量 $p$ 的情况。
它成立吗？如果成立，有证据吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654378/does-the-regression-line-go-through-the-center-of-mass-in-1-dimension</guid>
      <pubDate>Sat, 14 Sep 2024 18:33:35 GMT</pubDate>
    </item>
    <item>
      <title>处理训练数据中没有缺失值的特征在测试数据中的缺失值</title>
      <link>https://stats.stackexchange.com/questions/654374/handling-missing-values-of-a-feature-in-test-data-that-had-no-missing-values-in</link>
      <description><![CDATA[Kaggle 上的泰坦尼克号 - 灾难机器学习竞赛数据集中有一个名为“票价”的数字特征。
训练数据中的“票价”没有缺失值，但测试数据中有缺失值。我知道如何处理测试数据中缺失值的特征，这些特征在训练数据中也有缺失值，但这对我来说是第一次，我找不到如何解决的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/654374/handling-missing-values-of-a-feature-in-test-data-that-had-no-missing-values-in</guid>
      <pubDate>Sat, 14 Sep 2024 17:55:31 GMT</pubDate>
    </item>
    <item>
      <title>使用经典拟合优度检验检查逻辑回归假设</title>
      <link>https://stats.stackexchange.com/questions/654373/checking-the-logistic-regression-assumptions-with-classic-goodness-of-fit-tests</link>
      <description><![CDATA[在寻找在估计系数后检查模型充分性的方法时，我发现我需要 i) 检查逻辑回归假设和 ii) 检查拟合优度。
当我说拟合优度时，我并不是指测试预测能力（我用 McFadden Pseudo R^2 来测试）。我想检查估计值如何很好地表示观察到的数据。
由此得出我的疑问：当 gof 测试告诉你是否可以通过使模型更复杂来做得更好时，实际上是在测试是否存在你遗漏的非线性或相互作用，这是否与测试所有假设相同？简而言之：是否有必要通过使用例如来单独测试假设？低平滑（平滑 y）还是 HL 检验的替代方法测试相同？
因此：对于我的模型，它由一个连续解释变量（和一个二元结果）组成，样本量为 10，哪种检验最合适？由于我的样本量小，标准化 Pearson 不合适。另一个衡量标准可能是 Stukel 检验。很想听听你对此的看法！]]></description>
      <guid>https://stats.stackexchange.com/questions/654373/checking-the-logistic-regression-assumptions-with-classic-goodness-of-fit-tests</guid>
      <pubDate>Sat, 14 Sep 2024 16:35:11 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助理解两个分布的卷积</title>
      <link>https://stats.stackexchange.com/questions/654372/help-needed-in-understanding-the-convolution-of-two-distributions</link>
      <description><![CDATA[我正在阅读 Sheldon Ross 所著的《概率模型导论》第 12 版。第 57 页写道：

当 $X$ 和 $Y$ 独立时，能够根据 $X$ 和 $Y$ 的分布计算出 $X + Y$ 的分布通常很重要。首先假设$X$和$Y$是连续的，$X$的概率密度为$f$，而$Y$的概率密度为$g$。然后，让 $F_{X+Y}(a)$ 成为 $X + Y$ 的累积分布函数，我们有
$$ F_{X+Y}(a) = P(X + Y \leq a) $$
$$ = \int_{x+y \leq a} f(x) g(y) \, dx \, dy $$
$$ = \int_{-\infty}^{\infty} f(x) \left( \int_{-\infty}^{a - x} g(y) \, dy \right) dx $$
$$ = \int_{-\infty}^{\infty} F_Y(a - x) f(x) \, dx $$
累积分布函数 $F_{X+Y}$ 被称为分布 $F_X$ 和 $F_Y$ 的卷积（分别为 $X$ 和 $Y$ 的累积分布函数）。


但是，我们必须注意，$X+Y$ 是一个随机变量。我认为$X+Y$不一定是连续的。它也可能是离散的。设$Z=X+Y.$
如果$Z$是连续的，那么我们假设$f_{Z}$是概率密度函数。在此假设下，我们必须有，$P\{Z\leq a\}=P\{X+Y\leq a\}=\int_{-\infty}^af_Z(z)dz.$
如果$Z$是离散的，那么我们假设$F_Z$和$p_z$分别是$Z$的累积分布函数和概率质量函数。在这个假设下，我们有，$P\{Z\leq a\}=F_Z(a)=\sum_{x\leq a:p(x)&gt;0}p(x).$
但我不明白他们怎么写这个等式，

$$ F_{X+Y}(a) = P(X + Y \leq a) $$
$$ = \int_{x+y \leq a} f(x) g(y) \, dx \, dy $$
$$ = \int_{-\infty}^{\infty} f(x) \left( \int_{-\infty}^{a - x} g(y) \, dy \right) dx $$
$$ = \int_{-\infty}^{\infty} F_Y(a - x) f(x) \, dx $$

你能帮我理解一下，他们是怎么写出上面的等式的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654372/help-needed-in-understanding-the-convolution-of-two-distributions</guid>
      <pubDate>Sat, 14 Sep 2024 16:34:57 GMT</pubDate>
    </item>
    <item>
      <title>关于双重稳健估计的假设</title>
      <link>https://stats.stackexchange.com/questions/654344/assumption-about-doubly-robust-estimator</link>
      <description><![CDATA[设 $X, Y$ 为两个独立的非负连续随机变量。设 $R :=I(X &lt; Y)$。设 $Z$ 为任意随机变量。假设 $X\perp Y \mid Z$。
可以将 $R$ 视为缺失变量指标。如果 $R=1$，即 $I(X &lt; Y) = 1$，我们观察到 $X$，否则我们不会观察到 $X$。
设 $\pi^*(Z) = P(R=1\mid Z)$，且 $h^*(Z) = E(X\mid R=1, Z)$。设 $\pi(Z),h(Z)$ 为 $Z$ 的任意函数。考虑以下数量
$$
E\left(\left\{\frac{R - \pi(Z)}{\pi(Z)}\right\} [X - h(Z)]\right),
$$
众所周知，在条件$X\perp R\mid Z$下，当$\pi(Z) = \pi^*(Z)$或$h(Z) = h^*(Z)$时，该数量等于$0$。
但是，如果我们只有$X\perp Y \mid Z$呢？我们仍然具有相同的属性吗？有一件事我很确定，那就是 $X\perp Y \mid Z$ 并不意味着 $X\perp R\mid Z$。]]></description>
      <guid>https://stats.stackexchange.com/questions/654344/assumption-about-doubly-robust-estimator</guid>
      <pubDate>Fri, 13 Sep 2024 22:28:02 GMT</pubDate>
    </item>
    <item>
      <title>我该如何从“杠杆效应”的角度解释下面的 GJR-GARCH 模型？</title>
      <link>https://stats.stackexchange.com/questions/612999/how-can-i-interpret-the-below-gjr-garch-model-in-terms-of-leverage-effects</link>
      <description><![CDATA[我是这里的新手，很难解释该模型。请用通俗易懂的语言帮助我。
 AR - GJR-GARCH 模型结果 
==================================================================================================
Dep. 变量：GD R 平方：-0.003
均值模型：AR Adj。 R 平方：-0.004
Vol 模型：GJR-GARCH 对数似然：-3572.12
分布：标准化学生 t AIC：7168.24
方法：最大似然 BIC：7236.93
观测数：2261
日期：2023 年 4 月 15 日星期六 Df 残差：2257
时间：07:18:04 Df 模型：4
均值模型
========================================================================================
coef std err t P&gt;|t| 95.0% Conf.整数
-----------------------------------------------------------------------------------------
常数 0.0688 2.281e-02 3.017 2.555e-03 [2.411e-02, 0.114]
GD[1] -0.0134 2.114e-02 -0.635 0.526 [-5.485e-02,2.801e-02]
GD[2] -0.0327 2.011e-02 -1.626 0.104 [-7.210e-02,6.716e-03]
GD[3] 6.0716e-03 1.971e-02 0.308 0.758 [-3.255e-02,4.470e-02]
波动率模型
=====================================================================================
coef std err t P&gt;|t| 95.0% Conf. Int.
-----------------------------------------------------------------------------------------
omega 0.1078 4.361e-02 2.473 1.341e-02 [2.236e-02, 0.193]
alpha[1] 0.0322 1.903e-02 1.691 9.074e-02 [-5.108e-03,6.947e-02]
alpha[2] 4.1672e-14 1.602e-02 2.602e-12 1.000 [-3.139e-02,3.139e-02]
gamma[1] 0.0394 2.891e-02 1.364 0.172 [-1.722e-02,9.611e-02]
gamma[2] 0.1528 3.636e-02 4.202 2.651e-05 [8.151e-02, 0.224]
beta[1] 9.4508e-03 4.481e-02 0.211 0.833 [-7.837e-02,9.727e-02]
beta[2] 0.7992 5.555e-02 14.386 6.313e-47 [ 0.690, 0.908]
分布
===============================================================================
coef std err t P&gt;|t| 95.0% Conf. Int.
------------------------------------------------------------------------------------
nu 5.2877 0.574 9.215 3.121e-20 [ 4.163, 6.412]
===============================================================================

我在网上读了很多文章或论文，得出以下结论。但不确定我是否正确。
这里，gamma[1] 的 p 值为 0.172（大于 0.05），因此 gamma[1] 在统计上不显著，我们无法得出存在显著杠杆效应的结论。
但是，gamma[2] 的 p 值小于 0.05，表明 gamma[2] 具有统计显著性。
因此，我们可以得出结论，该模型已经捕获了显著的杠杆效应。
此外，我想编写一个通用代码，其中包含所有场景，例如，

如果 gamma[1] 为 +ve 而 gamma[2] 为 -ve，该怎么办？
如果模型中有 n 个 Gamma，那么我可以采用相同的方法吗？
如果我们有 n 个 Gamma，并且它们是 +ve 和 -ve 的组合，那么我们如何得出结论？
]]></description>
      <guid>https://stats.stackexchange.com/questions/612999/how-can-i-interpret-the-below-gjr-garch-model-in-terms-of-leverage-effects</guid>
      <pubDate>Sat, 15 Apr 2023 07:48:42 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何测试可以检查时间序列中的方差平稳性？</title>
      <link>https://stats.stackexchange.com/questions/585189/is-there-any-test-to-check-variance-stationarity-in-time-series</link>
      <description><![CDATA[问题很简单：是否有任何测试可以检查时间序列中的方差平稳性（同方差性）？
如果存在，那么在 R 或 Python 中有哪些实现？]]></description>
      <guid>https://stats.stackexchange.com/questions/585189/is-there-any-test-to-check-variance-stationarity-in-time-series</guid>
      <pubDate>Thu, 11 Aug 2022 14:44:59 GMT</pubDate>
    </item>
    <item>
      <title>自动微分中的向量雅可比积</title>
      <link>https://stats.stackexchange.com/questions/505742/vector-jacobian-product-in-automatic-differentiation</link>
      <description><![CDATA[我的问题与此帖子有关神经网络反向传播中的高阶矢量化 @shimao
我不太明白以下说法（我知道链式法则的工作原理以及反向模式自微分的本质是什么）：&quot;实际上，执行反向传播不需要计算雅可比矩阵。所需要的只是&quot;向量雅可比积&quot;，即 VJP。&quot;
据我所知，您需要在每一步计算雅可比矩阵才能执行梯度累积。例如，假设我们正在计算以下运算的导数（在神经网络中非常典型）：
$$
t = Wz, \,\,\, z\in \mathbb{R}^{m\times 1}, t \in \mathbb{R}^{n \times 1}, W\in\mathbb{R}^{n \times m}
$$
那么我们现在知道向量导数（雅可比矩阵）由以下公式给出：
$$
\frac{\partial t}{\partial z} = W
$$
然后将其插入链式法则（假设$\frac{\partial y}{\partial o}$是已经计算出来的梯度），计算链式法则给出的最终导数：
$$
\frac{\partial y}{\partial o} \frac{\partial t}{\partial z}
$$
因此，我不太理解那句话，因为那句话说我们不需要计算雅可比矩阵来执行反向传播，因为我们只需要雅可比矩阵向量积；但显然对于这一步，我们确实需要获得$t$和$z$之间变换的雅可比矩阵。有人可以提供一点直觉来说明到底指的是什么吗？总的来说，我已经看到反向模式自动微分可以通过向量雅可比矩阵积有效地实现（并且不需要计算雅可比矩阵），但是当我考虑它时，我意识到我们确实需要在每一步计算雅可比矩阵]]></description>
      <guid>https://stats.stackexchange.com/questions/505742/vector-jacobian-product-in-automatic-differentiation</guid>
      <pubDate>Wed, 20 Jan 2021 15:44:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么方差分析中的对比有一个自由度？</title>
      <link>https://stats.stackexchange.com/questions/504046/why-contrast-in-anova-has-one-degree-of-freedom</link>
      <description><![CDATA[在阅读维基百科解释后，我以为我理解了自由度，但却看到了对比的平方和$\{c_i\}$ $$SS_C = \frac{(\sum_i {c_i \bar{y_i}})^2}{\sum_i c_i^2 /n_i}$$
教科书上说它有一个自由度。为什么会这样？我不认为维基百科的解释在这里起作用，但我不知道为什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/504046/why-contrast-in-anova-has-one-degree-of-freedom</guid>
      <pubDate>Fri, 08 Jan 2021 10:55:04 GMT</pubDate>
    </item>
    </channel>
</rss>