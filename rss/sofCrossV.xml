<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Wed, 26 Feb 2025 12:33:57 GMT</lastBuildDate>
    <item>
      <title>MiRNA数据中过多的零对PCA和LDA的影响</title>
      <link>https://stats.stackexchange.com/questions/661865/impact-of-excessive-zeros-in-mirna-data-on-pca-and-lda</link>
      <description><![CDATA[我正在研究评估miRNA标记物的病例 - 霍特（〜病例对照，但将所有病例都放在子体内）研究。感兴趣的变量是miRNA表达的连续定量度量，但许多标记在很大一部分样品中表现为零。
 i计划应用主成分分析（PCA）和线性判别分析（LDA）来探索数据结构和分类潜力。但是，我担心零比例很高对这些技术的影响。
我的具体问题：
PCA：由于PCA依赖于差异，因此大量的零（可能表明缺席或检测限制问题）如何影响主要成分？它会导致文物或误导性“聚类”？
LDA：由于LDA对基于方差交联结构的类别敏感，因此过多的零会扭曲判别函数吗？零膨胀的建模是更好的选择吗？
一般建议：这些技术是否能够处理这种数量的零，实际上可能有生物学贡献？
是否有建议的预处理步骤最大程度地减少PCA和LDA中过量零引入的偏差？
在这种情况下，关于处理零连续数据的任何见解或参考都将不胜感激！
    ]]></description>
      <guid>https://stats.stackexchange.com/questions/661865/impact-of-excessive-zeros-in-mirna-data-on-pca-and-lda</guid>
      <pubDate>Wed, 26 Feb 2025 10:23:55 GMT</pubDate>
    </item>
    <item>
      <title>多级模型的固定或随机效应模型</title>
      <link>https://stats.stackexchange.com/questions/661864/fixed-or-random-effects-model-for-multilevel-model</link>
      <description><![CDATA[我有5年在美国3个州的10家商店中观察到的300种产品的每日价格（纵向）数据。 2个州有3个商店，一个州有4个商店。预测变量是一个虚拟变量在一周中，否则为0）。
我想研究该政策的影响，尤其是在我期望产品价格需求较高的事件中（因此，两个假人之间的互动将是我关注的主要变量）。我认为在商店变化之间考虑产品变化范围内是一个好主意。我读到，对于具有多层次的数据，随机效果模型更好。我还想考虑州未观察到的异质性，但我认为商店效应已经解释了这一点。我应该使用固定效果或随机效果模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661864/fixed-or-random-effects-model-for-multilevel-model</guid>
      <pubDate>Wed, 26 Feb 2025 10:10:26 GMT</pubDate>
    </item>
    <item>
      <title>分类模型的竞争风险</title>
      <link>https://stats.stackexchange.com/questions/661863/competing-risks-in-classification-model</link>
      <description><![CDATA[我有一个医学研究的数据集，该数据集关于骨折，例如入口时年龄，体重，身高，骨密度等，以及几天内骨骼骨折的进入。我目前正在将其作为分类问题进行建模，以预测10年内骨折的事件。 
但是，数据集中的一些患者在事件发生之前已经去世，这导致数据受到审查。我相信，经过审查的数据正在引入竞争风险并引起大量噪音，这阻碍了该模型预测事件发生的能力，就像我删除审查数据时一样，模型得分显着上升（约为0.78至0.88）。 
我应该如何处理审查的数据？我应该在审查的数据中增加权重还是与死亡相关的功能？还是我应该偏离分类模型，并更多地关注生存分析模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/661863/competing-risks-in-classification-model</guid>
      <pubDate>Wed, 26 Feb 2025 06:56:44 GMT</pubDate>
    </item>
    <item>
      <title>约束最小二乘</title>
      <link>https://stats.stackexchange.com/questions/661862/bound-constrained-least-squares</link>
      <description><![CDATA[让 $ ax = b $ 其中 $ b $ 是一个测量向量， $ a $ 是设计矩阵，我们希望最大程度地减少L2 Norm受到以下约束的约束： $ | x_j | ＆lt; C | x_i | $ 对于某些常数 $ C $ 。例如，如果某个系数的值为120，则我需要另一个系数的幅度小于120的5％，即6。。
标准约束最小二乘似乎不包括这种情况。
是否建议针对此类问题采用优化方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/661862/bound-constrained-least-squares</guid>
      <pubDate>Wed, 26 Feb 2025 05:27:11 GMT</pubDate>
    </item>
    <item>
      <title>基因型 - 环境关联的变量选择在部分冗余分析（RDA）中</title>
      <link>https://stats.stackexchange.com/questions/661861/variable-selection-for-genotype-environment-association-in-partial-redundancy-an</link>
      <description><![CDATA[我正在使用部分冗余分析（RDA）进行基因型 - 环境协会研究。我的数据集由大约250个个体组成，每个个体都针对5000个SNP（响应变量，编码为0/1/2）。此外，我有57个气候变量（解释变量），其中许多是高度相关的。我也有一个人口Q值（祖先系数）的矩阵，我用来部分谱系在RDA中的影响。
 问题：挑战在于在执行RDA之前选择气候变量。解释变量解释的方差比例非常低（在这类研究中与往常一样），这似乎可以防止有效利用套索回归用于可变选择。对于大多数SNP，未通过方法选择气候变量。
 问题： 

任何人都可以建议在这种情况下可以改善可变选择的套索方法调整参数吗？
是否有替代性形式变量选择方法可以更有效？

 替代方法：我正在考虑一种涉及气候变量层次聚类的替代方法，然后使用PCA为每个群集创建复合变量。步骤如下：

 在所有气候变量上执行分层聚类。

 对于每个集群，执行PCA并提取第一个主组件（PC1）的加载。

 计算原始气候变量的点产物和权重向量（PC1的PCA载荷）为每个集群创建一个复合变量。


此方法适合我的分析，还是我应该使用正式的变量选择方法？
非常感谢您的见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/661861/variable-selection-for-genotype-environment-association-in-partial-redundancy-an</guid>
      <pubDate>Wed, 26 Feb 2025 02:04:15 GMT</pubDate>
    </item>
    <item>
      <title>解决SVM微调的最佳方法</title>
      <link>https://stats.stackexchange.com/questions/661858/best-way-to-tackling-svm-fine-tuning</link>
      <description><![CDATA[我正在遇到一个多类分类问题，我正在尝试使用SVM预测4个类别。我正在尝试使用贝叶斯优化来微调其超参数，以加快持续时间。但是，这需要很长的时间才能融合。 （我说的是日子）。我可以问我是否错误地编码它，还是我应该采用其他方法？我只有大约6000个观测值和大约30个变量。
 来自bayes_opt进口
来自Sklearn.svm导入SVC
来自sklearn.model_selection导入cross_val_score

＃定义优化功能
def svm_evaluate（c，gamma_value，学位，收缩，kernel_index，class_weight_index）：
    ＃定义分类参数的选择
    kernel_choices = [&#39;linear&#39;，&#39;poly&#39;，&#39;rbf&#39;，&#39;sigmoid&#39;]
    class_weight_choices = [none，&#39;Balanced&#39;]
    
    ＃将索引转换为分类值
    kernel = kernel_choices [int（kernel_index）]
    class_weight = class_weight_choices [int（class_weight_index）]
    gamma =&#39;scale&#39;如果[&#39;linear&#39;] else gamma_value中的内核
    
    ＃使用给定参数创建SVM模型
    svm = svc（
        C = C，
        内核=内核，
        伽玛=伽玛，
        度= int（dem），
        class_weight = class_weight，
        收缩=收缩＆gt; 0.5＃转换回布尔值
    ）
    
    ＃使用交叉验证评估模型
    得分= cross_val_score（svm，x_train_short，y_train，cv = 5，评分=&#39;准确性&#39;）。eyan（）
    
    返回分数

＃定义参数范围
pbounds = {
    &#39;c&#39;：（1E-3，1E3），
    &#39;gamma_value&#39;：（1E-6，1E1），
    &#39;学位&#39;：（2，5），
    “收缩”：（0，1），＃使用0和1模拟布尔值
    &#39;kernel_index&#39;：（ 0，3），＃内核选择索引
    &#39;class_weight_index&#39;：（ 0，1）＃类重量选择索引
}

＃运行贝叶斯优化
优化器= Bayesianoptimization（
    f = svm_evaluate，
    pbounds = pbounds，
    Random_State = 42
）

优化器。maximize（init_points = 10，n_iter = 30）

＃打印最佳参数
BEST_PARAMS = Optimizer.max [&#39;params&#39;]
best_params [&#39;kernel&#39;] = [&#39;linear&#39;，&#39;poly&#39;，&#39;rbf&#39;，&#39;sigmoid&#39;] [int（best_params [&#39;kernel_index&#39;]]]]]
best_params [&#39;class_weight&#39;] = [none，&#39;balanced&#39;] [int（best_params [&#39;class_weight_index&#39;]）]]]
best_params [&#39;缩小&#39;] = best_params [&#39;shinking&#39;]＆gt; 0.5＃转换回布尔值
BEST_PARAMS [&#39;grem&#39;] = int（best_params [&#39;deg&#39;]）

打印（best_params）
``
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661858/best-way-to-tackling-svm-fine-tuning</guid>
      <pubDate>Wed, 26 Feb 2025 00:59:16 GMT</pubDate>
    </item>
    <item>
      <title>$ \ chi^2 $测试后的不确定性正常</title>
      <link>https://stats.stackexchange.com/questions/661855/normalizing-uncertainties-after-chi2-test</link>
      <description><![CDATA[我的一位教授在某个时候告诉我，我可以“重新归一化”  $ \ chi^2 $ 测试之后的不确定性如果我降低了 $ \ chi^2 $ 与 $ 1 $ 有很大不同。想象一个简单的线性模型，这个想法是我可以以以下方式重新归一化错误
  $$ \ SIGMA&#39;= \ SQRT {\ CHI^2 _ {\ MATHRM {RED}}}}} \SIGMA。$$  
如果 $ \ chi^2 _ {\ mathrm {red}} $ 很小，因为我高估了错误，这会纠正它；如果 $ \ chi^2 _ {\ mathrm {red}} $ 很大，则反之亦然，因为错误被低估了。
我的问题是，这实际上是一个著名的“技巧”，这是所做的事情？如果是这样，有人知道这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661855/normalizing-uncertainties-after-chi2-test</guid>
      <pubDate>Tue, 25 Feb 2025 23:28:10 GMT</pubDate>
    </item>
    <item>
      <title>Mann-Kendall测试和Phillips-Perron测试在R中给出不同的结果</title>
      <link>https://stats.stackexchange.com/questions/661853/mann-kendall-test-and-phillips-perron-test-giving-different-results-in-r</link>
      <description><![CDATA[考虑这个时间序列。我想检查一般趋势是什么以及它是否重要。
tss = c(255911, 305257, 314258, 294006, 380817, 412120, 419021, 336756, 242161, 232846, 295826, 398630, 372016, 374842, 417062, 379535, 321790、359170、380963、468196、492634、455149、431348、440693、274894、200003）  
使用Mann-Kendall测试进行固定时间序列，我发现没有明显的趋势，因此时间序列是固定的。

 Mann-Kendall趋势测试
数据：TSS
z = 1.8956，n = 26，p值= 0.02901
替代假设：True S大于0
样本估算：
S vars tau
87.0000000 2058.333333 0.2676923 

但是使用PP测试，我发现该系列不是固定的（p＆gt; 0.01）

菲利普斯 - 佩隆单元根测试
数据：TSS
dickey-fuller z（alpha）= -9.7259，截断滞后参数= 2，p-value = 0.4936
替代假设：固定

我期望这两个测试都会给出类似的结果（固定或不固定）]]></description>
      <guid>https://stats.stackexchange.com/questions/661853/mann-kendall-test-and-phillips-perron-test-giving-different-results-in-r</guid>
      <pubDate>Tue, 25 Feb 2025 21:39:53 GMT</pubDate>
    </item>
    <item>
      <title>线性回归中参数的差异</title>
      <link>https://stats.stackexchange.com/questions/661850/variance-of-parameter-in-linear-regression</link>
      <description><![CDATA[我的目标是尝试调和两个关于 $ \ hat {\ beta_1} $ 的显而易见的结果。我在两本计量经济学书中找到了这些。
接下来是在两个来源中众所周知和共享的：
   
不幸的是，在大多数书籍中都没有完全共享，因此我在两种情况下都显示了这些。我怀疑不同的结论来自不同的假设，但我的意思对我来说并不清楚。
现在，我显示了有关 $ v [\ hat {\ beta_1}] $ 在库存和沃森中给出的假设和结论：
   
在这里，我显示了有关 $ v [\ hat {\ beta_1}] $ 在Greene中给出的假设和结论：
    
我认为差异的理由来自这些来源：

无条件差异与条件（ $ x $ ）方差。在绿色方差肯定是有条件的，而库存和沃森对我来说还不清楚。
精确与渐近结果。渐近股票和沃森，而不是格林

关于Greene中的渐近结果，我可以补充：
   
但是，我找不到解决两个结果的方法。有人可以帮我吗？如果需要，我可以添加详细信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/661850/variance-of-parameter-in-linear-regression</guid>
      <pubDate>Tue, 25 Feb 2025 20:45:27 GMT</pubDate>
    </item>
    <item>
      <title>COX回归中连续变量的线性检查</title>
      <link>https://stats.stackexchange.com/questions/661849/linearity-check-of-continuous-variables-in-cox-regression</link>
      <description><![CDATA[嗨，我试图理解我在模型危险中看到的有关变量的线性的看似差异。
代码遵循的是，查看是否满足连续变量的线性假设：
 ＆gt;摘要（FM_2）
称呼：
coxph（formula = surch（onset_edss_conworse_m，status_onset_edss_conworse）〜 
    Geno + Pspline（YOB） + PSPLINE（AAO） + EDSS_1 + PC1 + 
        PC2 + PC3 + PC4 + PC5 + PC6 + PC7，数据=结果_2）

  n = 6656，事件数= 3611 

                     COEF SE（COEF）SE2 CHISQ DF P P       
Geno -0.05069 0.026141 0.026133 3.76 1.00 5.3E -02
PSPLINE（YOB），线性0.09715 0.002711 0.002711 1284.12 1.00 3.2E-281
PSPLINE（YOB），NONLIN 3.70 3.05 3.0E-01
PSPLINE（AAO），线性0.10701 0.002943 0.002942 1321.83 1.00 2.0E 2.0E-289
PSPLINE（AAO），NONLIN 12.08 3.01 7.2E-03
EDSS_1 -0.02626 0.010005 0.009999 6.89 1.00 8.7E -03
PC1 -2.20275 2.750456 2.749590 0.64 1.00 4.2E -01
PC2 3.09137 2.147148 2.146728 2.07 1.00 1.5E-01
PC3 8.82073 2.132244 2.129735 17.11 1.00 3.5E-05
PC4 3.03276 1.725568 1.724969 3.09 1.00 7.9E-02
PC5 -4.85096 2.122560 2.121993 5.22 1.00 2.2E -02
PC6 -5.38660 1.825511 1.825053 8.71 1.00 3.2E -03
PC7 5.12791 2.048041 2.047844 6.27 1.00 1.2E-02

             EXP（COEF）EXP（-COEF）下部.95上.95
Geno 9.506E-01 1.052E+00 9.031E-01 1.001E+00
PS（YOB）3 2.070E+00 4.831E-01 1.403E+00 3.053E+00
PS（YOB）4 4.301E+00 2.325E-01 2.265E+00 8.167E+00
PS（YOB）5 9.097E+00 1.099E-01 4.245E+00 1.950E+01
PS（YOB）6 1.887E+01 5.299E-02 8.569E+00 4.156E+01
PS（YOB）7 3.779E+01 2.646E-02 1.721E+01 8.298E+01
PS（YOB）8 8.021E+01 1.247E-02 3.643E+01 1.766E​​+02
PS（YOB）9 1.794E+02 5.574E-03 8.071E+01 3.988E+02
PS（YOB）10 3.756E+02 2.662E-03 1.672E+02 8.440E+02
PS（YOB）11 7.375E+02 1.356E-03 3.242E+02 1.678E+03
PS（YOB）12 1.427E+03 7.009E-04 6.111E+02 3.331E+03
PS（YOB）13 2.656E+03 3.765E-04 1.048E+03 6.735E+03
PS（YOB）14 4.941E+03 2.024E-04 1.620E+03 1.507E+04
PS（AAO）3 2.170E+00 4.609E-01 1.249E+00 3.769E+00
PS（AAO）4 4.707E+00 2.125E-01 1.849E+00 1.198E+01
PS（AAO）5 1.011E+01 9.889E-02 3.246E+00 3.150E+01
PS（AAO）6 1.964E+01 5.091E-02 6.066E+00 6.360E+01
PS（AAO）7 3.786E+01 2.641E-02 1.181E+01 1.214E+02
PS（AAO）8 8.190E+01 1.221E-02 2.546E+01 2.634E+02
PS（AAO）9 1.781E+02 5.613E-03 5.500E+01 5.770E+02
PS（AAO）10 4.289E+02 2.332E-03 1.313E+02 1.401E+03
PS（AAO）11 1.018E+03 9.819E-04 3.068E+02 3.381E+03
PS（AAO）12 2.438E+03 4.102E-04 6.955E+02 8.547E+03
PS（AAO）13 5.752E+03 1.738E-04 1.412E+03 2.344E+04
PS（AAO）14 1.350E+04 7.409E-05 2.482E+03 7.340E+04
EDSS_1 9.741E-01 1.027E+00 9.552E-01 9.934E-01
PC1 1.105E-01 9.050E+00 5.037E-04 2.424E+01
PC2 2.201E+01 4.544E-02 3.273E-01 1.480E+03
PC3 6.773E+03 1.476E-04 1.037E+02 4.423E+05
PC4 2.075E+01 4.818E-02 7.052E-01 6.108E+02
PC5 7.821E-03 1.279E+02 1.220E-04 5.012E-01
PC6 4.578E-03 2.185E+02 1.279E-04 1.639E-01
PC7 1.687E+02 5.929E-03 3.046E+00 9.339E+03

迭代：8外，20个牛顿 - 拉夫森
     theta = 0.983754 
     theta = 0.9706721 
条款的自由度= 1 4 4 1 1 1 1 1 1 1 1 1 
一致性= 0.737（SE = 0.004）
17.05 df，p =＆lt; 2e-16的似然比测试= 2270
 
我检查了YOB和AAO的TEMPLOT，以查看变量是否是线性的。
但是它们看起来都是线性的，而AAO的非线性效应很重要。谁能帮助理解这一点？
   ]]></description>
      <guid>https://stats.stackexchange.com/questions/661849/linearity-check-of-continuous-variables-in-cox-regression</guid>
      <pubDate>Tue, 25 Feb 2025 19:45:43 GMT</pubDate>
    </item>
    <item>
      <title>左截断和间隔审查的数据使用特恩布尔提出的自符敏感算法</title>
      <link>https://stats.stackexchange.com/questions/661848/left-truncated-and-interval-censored-data-using-the-self-consistency-algorithm-p</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661848/left-truncated-and-interval-censored-data-using-the-self-consistency-algorithm-p</guid>
      <pubDate>Tue, 25 Feb 2025 18:29:13 GMT</pubDate>
    </item>
    <item>
      <title>如何正确模拟对数正态分布中的可变性？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/661846/how-to-properly-simulate-the-variability-in-a-log-normal-distribution</link>
      <description><![CDATA[我试图通过通过先前生成的高斯白噪声的指示，差异等于2， $ y $  =“ Math-Container”&gt; $ x $ ，
  $$
y = \ exp（x），\\
x \ sim n（0，2）。
$$  
但是，所得的对数正态样品的样本方差广泛低估了理论方差，根据维基百科为
  $$
\ exp（2）（\ exp（2）-1）= 47.21
$$  
我犯了任何错误吗？有没有办法在样本中重现适量的可变性？
以下是一些可再现的python代码。
 导入numpy作为NP

n_samp = int（1E8）

＃白噪声
vwn = np.random.normal（size = n_samp，scale = np.sqrt（2））

emp_mean = np.mean（vwn）
theo_mean = 0
emp_var = np.var（vwn）
theo_var = 2

图，axs = plt.subplot（2，1，无花果=（10，8））
axs [0] .scatter（x = 0，y = emp_mean，color =; blue; quot; label =; emp; quot;）  
axs [0] .scatter（x = 0，y = theo_mean，color =; red＆quot; label =; quot; theo; quot;）
axs [0] .set_title（“平均”）
axs [0] .legend（）
axs [1] .scatter（x = 0，y = emp_var，color =; blue＆quot; label =; emp; quot;）
axs [1] .scatter（x = 0，y = theo_var，color =; red＆quot; label =; theo; quot;）
axs [1] .set_ylim（[1，3]）
axs [1] .set_title（; var; var;）
axs [1] .legend（）  
plt.show（）

＃log-normal
vksi = np.exp（vwn）
emp_mean = np.mean（vksi）
theo_mean = np.exp（1）
emp_var = np.mean（vksi）
theo_var = np.exp（2） *（np.exp（2）-1）

图，axs = plt.subplot（2，1，无花果=（10，8））
axs [0] .scatter（x = 0，y = emp_mean，color =; blue; quot; label =; emp; quot;）  
axs [0] .scatter（x = 0，y = theo_mean，color =; red＆quot; label =; quot; theo; quot;）
axs [0] .set_title（“平均”）
axs [0] .legend（）
axs [1] .scatter（x = 0，y = emp_var，color =; blue＆quot; label =; emp; quot;）
axs [1] .scatter（x = 0，y = theo_var，color =; red＆quot; label =; theo; quot;）
axs [1] .set_ylim（[[0，100]）
axs [1] .set_title（; var; var;）
axs [1] .legend（）  
plt.show（）
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/661846/how-to-properly-simulate-the-variability-in-a-log-normal-distribution</guid>
      <pubDate>Tue, 25 Feb 2025 17:43:19 GMT</pubDate>
    </item>
    <item>
      <title>COX模型预测中置信区间的差异</title>
      <link>https://stats.stackexchange.com/questions/661843/differences-in-confidence-intervals-in-cox-model-predictions</link>
      <description><![CDATA[我正在尝试通过性爱复制年龄的相对危害的情节，从此 vignette 来自生存包装。但是，我注意到相对危害估计的置信区间（CI）有所不同，具体取决于我的计算方式。
特别是，我在使用时获得不同的顺式：

  type =＆quot; lp;  in  predict&gt; predict（），然后从标准错误（SE）中计算95％CI并指出结果（如在小插图）。
  type =;风险;  in  predict&gt; predict（），然后直接从se。直接计算95％CI

在第二种情况下，置信区间更窄。
根据的帮助文件preditd.coxph ，“风险&#39;是 exp（lp）两种产生相同结果的方法。
有人知道为什么他们有所不同吗？
事先感谢您的见解！
 
 库（生存）
图书馆（dplyr）
图书馆（TinyPlot）

fit＆lt;  -  coxph（surv（未来，死亡）〜性 * splines :: ns（年龄，df = 3），data = flchain）
pdata＆lt;  -  Expand.Grid（年龄= 50:99，性= C（“ m＆quot”; f＆quot;））

lp_pred＆lt;  -  broom :: augment（fit，newdata = pdata，type.predict =＆quot; lp; lp; se = true）|＆gt; 
  突变（
    type =; lp＆quort
    conf.low = .fitting -1.96 * .se.fit，
    conf.high = .Fittit + 1.96 * .se.fit，
    跨越（c（.fited，conf.low，conf.high），exp）
  ）

firk_pred＆lt;  -  broom :: augment（
  fit，newdata = pdata，type.predict =“风险”，se = true
  ）|＆gt; 
  突变（
    类型=“风险”，
    conf.low = .fitting -1.96 * .se.fit，
    conf.high = .Fitted + 1.96 * .se.fit
  ）

pred＆lt;  -  rbind（lp_pred，firk_pred）

和（
  pread，
  TinyPlot（
    x =年龄，y =.。 
    facet = type，type =＆quord; ribbon＆quord＆quot log =&#39;y y＆quot;
  ）
）

 
    ]]></description>
      <guid>https://stats.stackexchange.com/questions/661843/differences-in-confidence-intervals-in-cox-model-predictions</guid>
      <pubDate>Tue, 25 Feb 2025 14:35:47 GMT</pubDate>
    </item>
    <item>
      <title>最大可能性估计量何时有偏见？</title>
      <link>https://stats.stackexchange.com/questions/661838/when-is-a-maximum-likelihood-estimator-biased</link>
      <description><![CDATA[众所周知，最大似然估计器（MLE）可能会偏差。我们可以预测给定的分布和感兴趣的参数是否会产生偏见的MLE？它取决于什么属性？偏斜？
例如，正态分布和平均值 $ \ mu $ 将给出公正的mle，而 $ \ theta $  in  $ \ text {stormiforn}（0，\ theta）$ 将是偏见的（根据chatgpt）]]></description>
      <guid>https://stats.stackexchange.com/questions/661838/when-is-a-maximum-likelihood-estimator-biased</guid>
      <pubDate>Tue, 25 Feb 2025 11:40:56 GMT</pubDate>
    </item>
    <item>
      <title>“最小化”高斯NLL的含义是什么？</title>
      <link>https://stats.stackexchange.com/questions/661834/what-does-minimising-the-gaussian-nll-mean</link>
      <description><![CDATA[我试图充分理解在模型训练期间的最小化高斯负模样（NLL）的最小值。使用MSE，它是直观的：接近0意味着更好的预测。但是高斯nll似乎不那么简单，尤其是因为它可能是负面和无限的。
在我的情况下，我的模型预测平均值 $ \ mu $  and  $ \ log（\ sigma^2） $ ，我指出要获得差异。我使用以下高斯NLL损失：
 $$ nll = \ frac {1} {2} {2} \ big [\ log（\ sigma^2）+\ frac {（y- \ mu）^2} {\ sigma^ 2}+\ log（2 \ pi）\ big]。$$  
我的主要问题是：最小化高斯NLL的含义是什么，我们如何跟踪改进？ 

仅查看上述方程式，我们可能会认为较低的损失总是更好的：对于完美的预测，NLL中的第二个任期将为零。在这种情况下，损失主要取决于 $ \ log（\ sigma^2）$ 。预测方差越小，负 $ \ log（\ sigma^2）$ 变成了，这似乎是一件好事，表明该模型有信心。遵循该逻辑，我们可以认为“最小化”。 NLL意味着我们只是希望它尽可能负面：-5的验证损失比-4之一好。但是，实际上，更负值的值也可能只是表明该模型过于自信并低估了不确定性，因此较低的值不一定更好，这将我带到了下一个点：
如果我正确理解，优化高斯NLL确实意味着使残留物的分布（预测错误）类似于： $ \ mu = 0 $ ，则表示预测平均是准确的， $ \ sigma^2 $ 匹配模型的预测不确定性。如果是这样，我们应该在培训期间如何解释或跟踪改进？如果较低的验证损失不一定更好，并且我们的目标不是尽可能接近零，那么哪些指标或方法可以帮助跟踪真正的改进？我们如何判断残差在培训时是否会融合到预测的高斯分布？
这是如何与早期停止和超参数调整相结合的，在哪里“更好”假定验证损失仅意味着较低的值？

我真的很感谢您对如何在培训期间解释高斯NLL的任何见解，尤其是如何平衡预测与不确定性估计以及如何在标准培训工作流程中起作用，例如早期停止和超参数调整。。]]></description>
      <guid>https://stats.stackexchange.com/questions/661834/what-does-minimising-the-gaussian-nll-mean</guid>
      <pubDate>Tue, 25 Feb 2025 10:42:25 GMT</pubDate>
    </item>
    </channel>
</rss>