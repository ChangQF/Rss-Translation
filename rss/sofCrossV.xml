<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 31 Jan 2024 12:23:20 GMT</lastBuildDate>
    <item>
      <title>条件密度估计的参考数据集</title>
      <link>https://stats.stackexchange.com/questions/638188/reference-datasets-for-conditional-density-estimation</link>
      <description><![CDATA[[如果您因为我要一个数据集而想要结束这个问题 - 我正在寻找 这个关于在 CVMeta 上请求数据集的问题。]
我正在寻找参考数据集来展示条件密度估计。
许多统计库（statsmodels、sklearn, ...) 包含一组数据集，在讨论特定方法时通常用作参考数据集。虽然我在许多实例中看到它们用于分类和回归，但我几乎没有看到它们用于条件密度估计。
有用于分类的鸢尾花数据集，加州住房数据集 用于回归 - 是否有类似的数据集（或者甚至可能是其中的列表）条件密度估计问题？如果有一个数据集可能不是一个非常常见的参考，但它同样适合该任务，那也会很有帮助。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/638188/reference-datasets-for-conditional-density-estimation</guid>
      <pubDate>Wed, 31 Jan 2024 12:21:51 GMT</pubDate>
    </item>
    <item>
      <title>时间序列数据中一个变量的自相关</title>
      <link>https://stats.stackexchange.com/questions/638186/autocorrelation-of-one-variable-in-time-series-data</link>
      <description><![CDATA[我想检查变量多年来的自相关性（时间序列数据）。在检查自相关性（Durbin-Watson）之前我们是否需要运行 Arima 模型？
在运行 AC 和 PAC 表时，我们还没有看到该变量的自相关吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638186/autocorrelation-of-one-variable-in-time-series-data</guid>
      <pubDate>Wed, 31 Jan 2024 12:10:38 GMT</pubDate>
    </item>
    <item>
      <title>coxme 和 coxph 之间使用简单随机效应有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/638184/what-is-the-difference-using-simple-random-effects-between-coxme-and-coxph</link>
      <description><![CDATA[我找不到明确说明 R 中使用 coxme 和 coxph 函数之间区别的地方。我的兴趣主要在于简单随机效应的情况。&lt; /p&gt;
我没有真正的数据可供处理，但让我们想象一个非常简单的情况：我有一个数据集，其中包含来自过去特定时期招募的队列的数据。参与者在国家的不同地区注册，每个地区对应一个招聘中心（centre）。我对治疗 (treatment) 和事件发生时间结果 (time 作为事件发生时间和 status 之间的关联感兴趣作为事件发生的指示器）。还涉及其他可能充当混杂因素的变量（协变量），因此我决定将它们也包含在模型中。
如果我必须运行 Cox 比例风险模型，语法将是这样的：

coxme(Surv(时间、状态) ~ 治疗 + 协变量 + (1|中心))
coxph(Surv(时间、状态) ~ 治疗 + 协变量 + frailty(中心))

根据我在网上阅读的内容，主要区别是一切都保留为默认值，即在 coxme 中随机效应具有分布 $N(0,1) $，而在 coxph 中，脆弱项作为 $Gamma(\alpha,\beta)$ 分布，但我不知道其值$\alpha$ 和 $\beta$。这是唯一的区别吗？
我在这个旧上找到了一些信息2007 年的帖子，但考虑到软件包可能已经更新，我想知道是否有人对此有更清晰、更明确的见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/638184/what-is-the-difference-using-simple-random-effects-between-coxme-and-coxph</guid>
      <pubDate>Wed, 31 Jan 2024 11:02:35 GMT</pubDate>
    </item>
    <item>
      <title>解释 AIC 相对可能性 ( qpcR::akaike.weights() )</title>
      <link>https://stats.stackexchange.com/questions/638181/interpreting-aic-relative-likelihoods-qpcrakaike-weights</link>
      <description><![CDATA[我想确保我正确解释 AIC 相对似然 (RL) 分数，特别是 qpcR::akaike.weights$rel.LL 返回的分数。例如，我比较两个模型，得到：
&lt;前&gt;&lt;代码&gt;$rel.LL
[1] 0.0442598 1.0000000

总和为 1.044。但是，如果我向 qpcR::akaike.weights() 提供相同的 AIC 两次，我会得到：
&lt;前&gt;&lt;代码&gt;$rel.LL
[1] 1 1

总和为 2。我注意到 AIC 权重总和为 1，但 RL 却不然。最合理（最低 AIC）模型的 RL 是否始终为“1”，而其他似然分数则与最合理模型相关？即，是否可以在第一个示例中推断出列表中的第二个模型成为“最佳”模型的可能性高出 22.59 倍。模型比劣质模型（RL 为 0.0442598）高，计算公式为 1/0.0442598 = 22.59？ qpcR::akaike.weights() 的文档给出了公式，但我在数学上不够敏锐，无法从公式中准确推断出我所看到的内容。如果我不确定，也许其他人也不确定。任何建议将不胜感激。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/638181/interpreting-aic-relative-likelihoods-qpcrakaike-weights</guid>
      <pubDate>Wed, 31 Jan 2024 10:29:06 GMT</pubDate>
    </item>
    <item>
      <title>集群分类</title>
      <link>https://stats.stackexchange.com/questions/638180/%d0%a1lassifying-clusters</link>
      <description><![CDATA[假设我们有一个类似分类问题的问题。我们有一个训练数据集，其中每条记录都有其类别标签。有多个班级，并且班级不重叠。模型应该进行预测的数据将被分为多个簇，并且我们知道每个簇对应于训练集中的单个类标签（一个簇中的所有点都来自同一类，但我们不知道哪个类）一）。
此类问题是否有一个特定的名称，我们实际上不必预测每个记录的类标签，而是预测整个集群的类标签？如果不是，什么方法最适合这项任务？
当然，我们可以将其视为常见的分类问题，只需预测集群中每个记录的类标签，然后选择最流行的预测作为集群的预测。但我觉得这种方法没有考虑每个集群中特征的一般分布，因此它没有使用可用于预测的所有信息]]></description>
      <guid>https://stats.stackexchange.com/questions/638180/%d0%a1lassifying-clusters</guid>
      <pubDate>Wed, 31 Jan 2024 09:52:08 GMT</pubDate>
    </item>
    <item>
      <title>从理论版本导出 Anderson Darling 检验统计量的样本版本</title>
      <link>https://stats.stackexchange.com/questions/638179/deriving-sample-version-of-anderson-darling-test-statistic-from-the-theoretical</link>
      <description><![CDATA[在文献中，我见过两种类型的 Anderson-Darling 检验统计量。其一表示为
$A_T^2 = n\int_{-\infty}^{\infty}\frac{(F_n(x)-F(x))^2}{F (x)(1-F(x))}dF(x)$ 另一个由 $A_s^2 = -n-\sum_{i= 给出1}^{n}\frac{2i-1}{n}[\ln F(Y_i)+\ln(1-F(Y_{n+1-i}))]$，其中 &lt; span class=&quot;math-container&quot;&gt;$Y_1, Y_2,\cdots, Y_n$ 是有序样本。
我的问题是，我们如何从 $A_T^2$ 获取 $A^2_s$ ？我的猜测是我们必须求解 Riemann-Stieltjes 积分，但我不知道如何继续。]]></description>
      <guid>https://stats.stackexchange.com/questions/638179/deriving-sample-version-of-anderson-darling-test-statistic-from-the-theoretical</guid>
      <pubDate>Wed, 31 Jan 2024 09:10:35 GMT</pubDate>
    </item>
    <item>
      <title>2xN 卡方检验后的事后分析</title>
      <link>https://stats.stackexchange.com/questions/638178/post-hoc-after-a-2xn-chi-squared-test</link>
      <description><![CDATA[我有两组人，我想确定他们的语言是否存在显着差异。我的数据由词频组成（一个人在给定时间范围内说出给定单词的次数），因此他们的列联表如下所示：

我使用卡方检验来比较词频的总和（向量 $x$ 和 $y$ ），并发现两组之间存在显着差异（非常低的 $p$ 值）。现在，我正在考虑仅对两组进行事后分析是否有意义。在这种情况下如何进行事后分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/638178/post-hoc-after-a-2xn-chi-squared-test</guid>
      <pubDate>Wed, 31 Jan 2024 08:58:16 GMT</pubDate>
    </item>
    <item>
      <title>伯努利试验的成功具有不同的概率，但概率只有在成功后才会改变</title>
      <link>https://stats.stackexchange.com/questions/638175/success-of-bernoulli-trials-with-different-probabilities-but-a-probability-is-o</link>
      <description><![CDATA[我想计算不同概率的伯努利试验，但概率只有在成功后才会改变。
比如这里，下图中每个状态下所有p都不同，s: (0, 1, ..., m)。

审判将从状态 (0) 开始。
然后，p_0将作为概率用于试验。成功的秘诀。
如果我们成功，那么 p_1 将用于下一次试验。
一般情况如何推导Pr[X=i]？更简单的方法？
我指的是泊松二项分布，但似乎有点不同。
i 是 k 次试验的成功结果。
目前，我得出如下。
$Pr[X=0] = p_0^0 \times (1-p_1)^(k-0)$。
$Pr[X=1] = p_0^1 \times (\text{所有失败组合的总和，$1-p_0$, $1-p_1$ k-1 次试验}) $。
...]]></description>
      <guid>https://stats.stackexchange.com/questions/638175/success-of-bernoulli-trials-with-different-probabilities-but-a-probability-is-o</guid>
      <pubDate>Wed, 31 Jan 2024 08:52:15 GMT</pubDate>
    </item>
    <item>
      <title>伯努利试验的成功具有不同的概率，但概率只有在成功后才会改变</title>
      <link>https://stats.stackexchange.com/questions/638174/success-of-bernoulli-trials-with-different-probabilities-but-a-probability-is-o</link>
      <description><![CDATA[我想计算不同概率的伯努利试验，但概率只有在成功后才会改变。
比如这里，下图中每个状态下所有p都不同，s: (0, 1, ..., m)。

审判将从状态 (0) 开始。
然后，p_0将作为概率用于试验。成功的秘诀。
如果我们成功，那么 p_1 将用于下一次试验。
一般情况如何推导Pr[X=i]？更简单的方法？
我指的是泊松二项分布，但似乎有点不同。
i 是 k 次试验的成功结果。
目前，我得出如下。
$Pr[X=0] = p_0^0 \times (1-p_1)^(k-0)$。
$Pr[X=1] = p_0^1 \times (\text{所有失败组合的总和，$1-p_0$, $1-p_1$ k-1 次试验}) $。
...]]></description>
      <guid>https://stats.stackexchange.com/questions/638174/success-of-bernoulli-trials-with-different-probabilities-but-a-probability-is-o</guid>
      <pubDate>Wed, 31 Jan 2024 08:52:15 GMT</pubDate>
    </item>
    <item>
      <title>了解 0-1 和铰链损耗之间的关系</title>
      <link>https://stats.stackexchange.com/questions/638171/understanding-relation-between-0-1-and-hinge-losses</link>
      <description><![CDATA[假设我们使用线性预测器，我试图从概念上理解对于一组点，它如何具有相对较低的 0-1 损失但相对较高的铰链损失。例如，有人告诉我，可以选择一组点，使得所有这些线性预测变量的 0-1 损失最小（即 $p_w(x) = \langle w, x \rangle$），其中 $w$ 位于二维平面中）低于 0.1，但对于同一组点，预测器最小化铰链损失高于某个阈值，例如 $0.5$。
针对这个问题，在我看来，学习了SVM之后，一直很难理清0-1损失和铰链损失的概念。我对铰链损失的理解是，随着错误分类的点进一步增加，它会变得更大，但对我来说，“最小化铰链损失”的预测器会带来什么并不直观。对于给定的一组点来说，它看起来像是立即的，至少在 $\mathbb{R^2}$ 中，对我来说很明显最小化超平面是什么0-1 输球的样子。谁能帮助我获得一些直觉并理解这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/638171/understanding-relation-between-0-1-and-hinge-losses</guid>
      <pubDate>Wed, 31 Jan 2024 07:44:50 GMT</pubDate>
    </item>
    <item>
      <title>先验和证据之间实际上有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/638170/what-is-actually-the-difference-between-prior-and-evidence</link>
      <description><![CDATA[当看到贝叶斯定理先验和证据时，它与联合概率(A n B)有相似之处。那么它们之间真的有明显的区别吗？？？]]></description>
      <guid>https://stats.stackexchange.com/questions/638170/what-is-actually-the-difference-between-prior-and-evidence</guid>
      <pubDate>Wed, 31 Jan 2024 06:37:03 GMT</pubDate>
    </item>
    <item>
      <title>Skellam 分布的分位数函数是什么？</title>
      <link>https://stats.stackexchange.com/questions/638165/what-is-the-quantile-function-of-a-skellam-distribution</link>
      <description><![CDATA[阅读 是否有 Skellam 分布或两个泊松 r.v. 差异的 95% 置信区间的公式？，我意识到 我宁愿使用分位数函数。不幸的是 Wiki 表明第一类修正贝塞尔函数位于概率质量函数中，这意味着我不知道如何直接求解 $k$。
能够计算 Skellam 分布式回归模型的预测区间在商业、医疗保健和物理（以及我确信的其他领域）中可能会很方便。]]></description>
      <guid>https://stats.stackexchange.com/questions/638165/what-is-the-quantile-function-of-a-skellam-distribution</guid>
      <pubDate>Wed, 31 Jan 2024 05:11:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么 OpenAI 的缩放定律论文低估了数据在模型缩放中的重要性？</title>
      <link>https://stats.stackexchange.com/questions/638150/why-did-the-openais-scaling-law-paper-underestimate-the-importance-of-data-in-m</link>
      <description><![CDATA[Chinchilla 论文 (https://arxiv.org/abs/2203.15556) 著名地发现在缩放模型时，您应该大致同等地增加参数数量和数据量，而不是早期的 OpenAI 缩放法则论文，该论文说您应该增加参数数量，其数量要远远多于数据量。
在第 3 页，Chinchilla 论文对 OpenAI 论文为何犯此错误给出了以下解释：
&lt;块引用&gt;
首先，作者对所有模型使用固定数量的训练标记和学习率计划；这
阻止他们对这些超参数对损失的影响进行建模。相比之下，我们发现
将学习率计划设置为大致匹配训练令牌结果的数量
无论模型大小如何，都能获得最佳的最终损失——见图 A1。对于固定学习率余弦时间表
对于 130B 代币，中间损失估计（对于 𝐷&#39; &lt;&lt; 130B）因此高估了
丢失使用与 𝐷&#39; 匹配的时间表长度进行训练的模型。使用这些中间损失会导致
低估了在少于 130B 代币的数据上训练模型的有效性，最终
得出这样的结论：随着计算的进行，模型大小应该比训练数据大小增加得更快
预算增加。

但是为什么会这样呢？如果您的学习率计划导致高估了少量训练数据的损失，那么这是否会导致您高估数据对损失的影响，从而建议比参数计数更快地增加数据大小，而不是相反？]]></description>
      <guid>https://stats.stackexchange.com/questions/638150/why-did-the-openais-scaling-law-paper-underestimate-the-importance-of-data-in-m</guid>
      <pubDate>Tue, 30 Jan 2024 23:19:09 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 R 中“REML 拟合的线性混合模型”的输出？</title>
      <link>https://stats.stackexchange.com/questions/638141/how-to-interpret-the-output-of-linear-mixed-model-fit-by-reml-in-r</link>
      <description><![CDATA[我制作了一个混合模型来研究两种干预措施（力量或耐力）对身体活动的影响。以下是我的变量的描述：

PA = 身体活动（以每周 PA 分钟数衡量）
progr = 干预计划（1 = 耐力，2 = 力量）
时间 = 测量时间点（基线、6 周后和 12 周后）
vnr = 受试者的 ID 号

我使用此代码来构建模型：
mix.intslo_PA_2 &lt;- lmer(PA ~ progr + time + progr * time + (time|vnr), data_l)

摘要（mix.intslo_PA_2）

现在，当我得到输出时，我不知道如何解释它，因为我在任何地方都找不到关于如何执行此操作的明确解释。解释什么是重要的？随机效应或固定效应是什么意思？以及如何解释它们？
这是输出：
&lt;前&gt;&lt;代码&gt;&gt;摘要（mix.intslo_PA_2）
REML 拟合线性混合模型。 t 检验使用 Satterthwaite 方法 [&#39;lmerModLmerTest&#39;]
公式：PA ~ progr + time + progr * time + (time | vnr)
   数据：data_l

REML 收敛准则：8772.7

缩放残差：
     最小 1Q 中值 3Q 最大
-1.99644 -0.77989 -0.01227 0.84138 1.88024

随机效果：
 组名称方差标准差科尔
 vnr（拦截）28188.4 167.89
          时 192.5 13.87 -0.54
 剩余 137102.2 370.27
obs 数量：594，组：vnr，198

固定效果：
            估计标准。误差df t值Pr(&gt;|t|)
(截距) 773.982 38.722 196.001 19.988 &lt;2e-16 ***
程序2 -54.241 53.687 196.001 -1.010 0.314
时间 -2.205 4.698 196.002 -0.469 0.639
程序2：时间 2.025 6.514 196.002 0.311 0.756
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应的相关性：
            (Intr) progr2 时间
程序2 -0.721
时间 -0.733 0.529
程序2：时间0.529 -0.733 -0.721
]]></description>
      <guid>https://stats.stackexchange.com/questions/638141/how-to-interpret-the-output-of-linear-mixed-model-fit-by-reml-in-r</guid>
      <pubDate>Tue, 30 Jan 2024 21:43:13 GMT</pubDate>
    </item>
    <item>
      <title>给定 N 个观察值 - 已知均值的正态分布的未知方差的贝叶斯后验？</title>
      <link>https://stats.stackexchange.com/questions/638137/given-n-observations-bayesian-posterior-for-unknown-variance-of-a-normal-distr</link>
      <description><![CDATA[因此，除了使用 $\mu = 0$ 的高斯试验进行 N 次试验之外，没有任何信息，我想知道未知数的最佳贝叶斯后验方差，$\sigma^2$。
到目前为止，我的方法是假设 $\tau = \frac{1}{\sigma}$ 有一个统一的先验，即标准高斯。除了更直观（对我来说）之外，这也是必要的，因为尝试对 $\sigma$ 或使用统一先验$\sigma^2$ 将导致发散积分。
然后对于 N 个观测值，这会导致后验分布：
$Pr(\tau|x_1,x_2,...,x_n) = \frac{S^{n+1}\tau^n}{\Gamma(\ frac{n+1}{2})2^{\frac{n-1}{2}}}exp(-\frac{\tau^2}{2}S^2)$
其中$S^2 = x_1^2+x_2^2+\cdots+x_n^2$，即观测值的平方和。
如果我们将变量转换为方差，那么我们有：
$Pr(\sigma^2|x_1,x_2,...,x_n) = \frac{(\frac{S^2}{2})^{\ frac{n+1}{2}}}{\Gamma(\frac{n+1}{2})(\sigma^2)^{\frac{n+3}{2}}}exp(-\ frac{S^2}{2}\frac{1}{\sigma^2}) = InvGamma({\sigma^2;\alpha = \frac{n + 1}{2},\beta = \frac{ S^2}{2})}$。
幸运的是，这正是带有参数的逆伽玛分布 $\alpha = \frac{n + 1}{2}, \beta = \frac{S^2 {2}$，与此维基百科页面相当神秘的声明相符=&quot;nofollow noreferrer&quot;&gt;https://en.wikipedia.org/wiki/Inverse-gamma_distribution：
&lt;块引用&gt;
“也许逆伽玛分布的主要用途是
贝叶斯统计，其中分布作为边际出现
正态分布的未知方差的后验分布
分布，如果使用无信息先验的话”

所以我的问题：嗯，这一切都很好，但我还没有在网上其他地方找到类似的分析，这令人担忧。而且，我推导出的后验分布的均值是 $\frac{S^2}{n-1}$，众数是 $\frac{S^2}{n+3}$。我有点怀疑其中至少有一个是 $\frac{S^2}{n}$ 因为我们知道平均值，因此我们在估计方差时不会失去一定的自由度......
帮我指出正确的方向吗？我很困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/638137/given-n-observations-bayesian-posterior-for-unknown-variance-of-a-normal-distr</guid>
      <pubDate>Tue, 30 Jan 2024 19:59:25 GMT</pubDate>
    </item>
    </channel>
</rss>