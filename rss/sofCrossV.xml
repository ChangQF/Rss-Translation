<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 17 Jul 2024 12:29:17 GMT</lastBuildDate>
    <item>
      <title>概率密度函数推断的名称</title>
      <link>https://stats.stackexchange.com/questions/651237/name-of-inference-on-probability-density-function</link>
      <description><![CDATA[数据$\{(x_i,y_i)\}_{i=1}^n \subset \mathbb{R}^2$满足$x_1 &lt; \cdots &lt; x_n$。我们假设客户相信两件事：

当给定 $x_i$ 时，$y_i$ 仍然是一个取决于 $x_i$ 的随机量（因此这不是机器学习任务）。
$y$ 相对于 $x$ 的曲线是概率密度函数。

要求统计员建立一个统计模型（即一组可能的概率密度函数），然后对概率密度函数的某些方面进行推断。例如，函数的峰值是多少。
数据的简单变换将产生从经验分布函数获取累积分布函数的问题。
例如，客户可以要求预测。
完成这项工作的一种方法：根据客户信念找到一组概率密度函数，比如正态分布，然后用最小二乘法拟合密度并进行相应的预测。
问题：这种推理的名称是什么？有关于这种推理程序技术的来源吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651237/name-of-inference-on-probability-density-function</guid>
      <pubDate>Wed, 17 Jul 2024 12:23:13 GMT</pubDate>
    </item>
    <item>
      <title>Shapley、合作博弈和线性</title>
      <link>https://stats.stackexchange.com/questions/651235/shapley-cooperative-games-and-linearity</link>
      <description><![CDATA[我正在研究合作博弈论，对理解加性不成立的情况很感兴趣。具体来说，我正在寻找一个由特征函数 $v$ 和 $g$ 定义的两个合作博弈的实际例子，其中对于联盟 $Q$，以下不等式成立：
$$(v + g)(Q) \neq v(Q) + g(Q)$$
您能否提供此类合作博弈的具体例子？我希望您能详细描述特征函数 $v$ 和 $g$，以及如何计算联盟的值以表明不存在可加性。
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/651235/shapley-cooperative-games-and-linearity</guid>
      <pubDate>Wed, 17 Jul 2024 11:47:40 GMT</pubDate>
    </item>
    <item>
      <title>如何证明许多函数（一百、一千）在区间内具有相同的形状和值分布？</title>
      <link>https://stats.stackexchange.com/questions/651231/how-to-show-that-many-functions-a-hundred-a-thousand-have-the-same-shape-an-d</link>
      <description><![CDATA[我有一些函数，它们在迭代间隔 [0,1] 上看起来都像这样：

即它们在 0.4 附近有一个零，从零到 0.4 的导数为正，在 1 附近有一个零或略微为负的导数。
我打算证明它们在这个间隔上实际上都非常相似。我需要对至少数百个这样的分布进行这样的证明。我认为这可以通过对相同参数的函数值进行采样（例如 500 个均匀分布的 x）然后在概率图上绘制其中一个函数作为参考，并在其上添加数百个其他函数 - 应该或多或少是一条直线来直观地完成。
下面是两个此类样本的 qq 图：

有没有更好或更正式的方法来做到这一点 - 你有什么建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/651231/how-to-show-that-many-functions-a-hundred-a-thousand-have-the-same-shape-an-d</guid>
      <pubDate>Wed, 17 Jul 2024 10:34:04 GMT</pubDate>
    </item>
    <item>
      <title>回归中的非独立解释变量[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651228/non-independent-explanatory-variable-in-regression</link>
      <description><![CDATA[我一直在网上学习回归的进修课程，没有老师，基本上除了广义线性混合模型之外的所有情况下，都假设解释变量是独立的（除非我弄错了）。
所以我的问题是......如果你有非独立的解释变量会发生什么？
我看到一些人谈论多元回归，但查找时似乎它或多或少与仍然假设独立的多元回归相同。
由于多元回归假设不存在多重共线性，我想知道非独立解释变量是否与多重共线性有关？
希望我的问题清楚，因为我自己也有点困惑
提前谢谢大家]]></description>
      <guid>https://stats.stackexchange.com/questions/651228/non-independent-explanatory-variable-in-regression</guid>
      <pubDate>Wed, 17 Jul 2024 09:48:15 GMT</pubDate>
    </item>
    <item>
      <title>倾向得分匹配，数据量极小。有没有其他方法可以处理小数据？</title>
      <link>https://stats.stackexchange.com/questions/651225/propensity-score-matching-with-extremly-small-data-size-is-there-any-alternativ</link>
      <description><![CDATA[我有两组 A 和 B，它们代表了两种不同的成像方法，用于检测一种罕见疾病。这不是典型的治疗对照设置；相反，它涉及比较这两种成像方法的功效。A 组由 37 名受试者组成，而 B 组仅由 9 名受试者组成。方法 A 的灵敏度为 19%（37 名中有 7 名真阳性），而方法 B 的灵敏度为 55%（9 名中有 5 名真阳性），阈值为 0.3（见结果概率图）
尽管成像专家的意见表明方法 B 在疾病检测方面质量更优，但进行定量分析以显示两种方法不同的可行方案是什么？具体来说，我们能否使用倾向得分匹配 (PSM) 来证明观察到的检测率差异归因于成像方法而不是与疾病相关的协变量？我是倾向得分匹配的新手，收到的建议是进行 1:2 匹配以匹配与疾病相关的协变量。考虑到队列规模较小，PSM 是否是一种可行的方法？还有哪些其他选项可以显示这两种成像方法观察到的疾病检测率差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/651225/propensity-score-matching-with-extremly-small-data-size-is-there-any-alternativ</guid>
      <pubDate>Wed, 17 Jul 2024 09:03:27 GMT</pubDate>
    </item>
    <item>
      <title>重新调整元分析的关联测量（例如，对数转换的独立变量）</title>
      <link>https://stats.stackexchange.com/questions/651223/rescale-measures-of-association-for-meta-analysis-e-g-log-transformed-indepen</link>
      <description><![CDATA[我正在对评估特定环境污染物血液水平与健康结果之间关系的研究进行荟萃分析（二元）。
一些研究报告了具有不同单位的连续独立变量的 OR/RR/HR（例如，增加 1 个单位，增加 10 个单位），而其他研究报告了对数或对数 (2) 转换的独立变量的 OR/RR/HR。
虽然我知道如何将未进行对数转换的独立变量的 OR/RR/HR 转换为不同单位（例如，从增加 1 个单位到增加 10 个单位），但我对使用对数转换的研究感到困惑。
关于如何在同一尺度上获得所有这些结果（无论是否进行对数转换）有什么想法吗？我需要这个来获得点估计和置信区间（或标准误差）。由于这是荟萃分析，我无法访问所包含研究中的原始个体级数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/651223/rescale-measures-of-association-for-meta-analysis-e-g-log-transformed-indepen</guid>
      <pubDate>Wed, 17 Jul 2024 08:38:44 GMT</pubDate>
    </item>
    <item>
      <title>了解渔业模型产出标记和释放</title>
      <link>https://stats.stackexchange.com/questions/651222/understanding-fisheries-model-output-tag-and-release</link>
      <description><![CDATA[我正在（为自己）审查一份出版物，该出版物分析了一项实验的数据，以了解水下地震对龙虾可捕获性的影响。de Lestang 等人（2024 年）渔业研究第 277 卷：107072
我正在寻找有关如何最好地解释结果的指导，因为我不相信结论像讨论的那样明确。
以下是论文中描述的模型细节；
总共有 190 只龙虾被放归大海，其中 96 只来自治疗组，94 只来自对照组。
根据修改后的 Baranov 捕捞方程 (Quinn and Deriso, 1999) 模拟了每组 (治疗组或对照组) 龙虾的回归情况；
$R_{i,g} = (N_{i,g}^ {}-F_{i-1,g})q_{i}e^{(-l_{i}(C+M)+T)}$
其中，第 i 次观测中重新捕获和报告的龙虾数量 (R) 因以下因素而异：该组 (g，治疗组或对照组) 放归的龙虾数量 (N)、龙虾的累计收获量 (渔民保留的龙虾数量；F)、放归后的时间 (l 天)、该观测的可捕捞性 (q)，预先确定的每日自然死亡率 + 标签丢失率 (M) 和两个仅对治疗组龙虾起作用的因素：瞬时初始释放死亡率 (T) 和瞬时慢性死亡率 (C)。根据之前对该物种的标签重新捕获研究 (de Lestang et al., 2022)，将自然死亡率和慢性标签丢失率合并为一个值，用于模型中作为每日瞬时率 (6.643e⁻⁴/天)。两组龙虾的可捕获性被认为是相同的，但可能会在采样场合 (i) 之间发生变化，这取决于该地区设置的捕捞笼数量以及水温和海浪等日常环境条件 (de Lestang et al., 2009; Srisurichan et al., 2005)。可捕获性是模型中的一个比例因子，计算结果为采样场合的估计重新捕获量总和与同一场合的观察到的重新捕获量总和相匹配。初始释放死亡率仅应用于治疗龙虾一次，代表气枪声波对龙虾生存的“中期影响”。重新捕获并重新释放的龙虾不会重新应用初始释放死亡率。慢性死亡率被用作持续的每月影响，继续减少释放治疗龙虾的重新捕获（长期影响）。瞬时地震死亡率（例如 T 和 C）的模型估计值通过以下公式从瞬时死亡率反向转换：
$\alpha = 1-e^{-\alpha }$ 其中 α 代表 T 或 C。
使用 AER 包（Kleiber and Zeileis，2008）中的“dis-persiontest”函数对观测数据进行过度分散测试，确定假设泊松分布的对数似然（R 中的 dpois 函数）是合适的。使用 R studio 中的“nlminb”程序将此对数似然的负值最小化，以调整初始释放和慢性死亡率的估计模型参数（表 2）。使用基于模型协变量和协方差矩阵估计的蒙特卡洛方法构建了模型估计的置信限度（使用 R 中 mvtnorm 包中的“rmvnorm”函数），该方法为 10000 个多元正态分布随机抽取。
估计的瞬时死亡率为
中位数 = 0.221，95%CI 下限 = .056，95%CI 上限 = 0.686
问题：鉴于 CI 的范围非常大，该估计是否应被视为不稳定？
这是我试图理解的图表。
问题：为什么对照组（紫色）和治疗组（黄色）的误差线在相反方向上不对称 - 图 a
问题：残差的正确解释 - 图 b - 在初始重新捕获期间观察到的数据和建模数据之间的兼容性要差得多，但随着时间的推移情况会变得更好，但这是随着时间的推移，重新捕获的次数非常少，这是可以预料的。
]]></description>
      <guid>https://stats.stackexchange.com/questions/651222/understanding-fisheries-model-output-tag-and-release</guid>
      <pubDate>Wed, 17 Jul 2024 07:42:31 GMT</pubDate>
    </item>
    <item>
      <title>RI CLPM 中的负协方差矩阵（lavaan）</title>
      <link>https://stats.stackexchange.com/questions/651221/negative-covariance-matrix-in-ri-clpm-lavaan</link>
      <description><![CDATA[我目前正在努力解决有关潜在变量的负协方差问题，这些变量与我的 RI CLPM 模型中的随机截距有关，我通过 lavaan 计算。
这是我的模型代码
RICLPM &lt;- &#39;
# 在组件之间创建（随机截距）
RI_x =~ 1*x_1 + 1*x_2 + 1*x_3
RI_y =~ 1*y_1 + 1*y_2 + 1*y_3

# 创建以人为中心的变量
w_x_1 =~ 1*x_1
w_x_2 =~ 1*x_2
w_x_3 =~ 1*x_3
w_y_1 =~ 1*y_1
w_y_2 =~ 1*y_2
w_y_3 =~ 1*y_3

# 估计之间的滞后效应以人为中心变量
w_x_2 ~ w_x_1
w_x_3 ~ w_x_2
w_y_2 ~ w_y_1
w_y_3 ~ w_y_2

# 估计以人为中心变量之间的交叉滞后效应
w_y_2 ~ w_x_1
w_y_3 ~ w_x_2
w_x_2 ~ w_y_1
w_x_3 ~ w_y_2

# 将观察到的变量回归到 z（常数）上
x_1 + x_2 + x_3 ~ z
y_1 + y_2 + y_3 ~ z

# 估计随机截距的方差和协方差
RI_x ~~ RI_x
RI_y ~~ RI_y
RI_x ~~ RI_y

# 估计以人为中心变量的（残差）方差
w_x_1 ~~ w_x_1
w_y_1 ~~ w_y_1
w_x_2 ~~ w_x_2
w_y_2 ~~ w_y_2
w_x_3 ~~ w_x_3
w_y_3 ~~ w_y_3

# 估计同一时间点以人为中心变量之间的残差协方差
w_x_1 ~~ w_y_1
w_x_2 ~~ w_y_2
w_x_3 ~~ w_y_3

# 估计以人为中心变量的残差方差
w_x_2 ~ u2*1
w_y_2 ~ v2*1
w_x_3 ~ u3*1
w_y_3 ~ v3*1
&#39;

fit &lt;- lavaan::sem(RICLPM, data = final_data, missing = &#39;ML&#39;, meanstructure = TRUE, int.ov.free = TRUE)

我收到以下警告：

&gt; fit &lt;- lavaan::sem(RICLPM, data = data, missing = &#39;ML&#39;, meanstructure = TRUE, int.ov.free = TRUE)
警告消息：
1：在 lav_data_full(data = data, group = group, cluster = cluster, :
lavaan 警告：由于外生变量中缺少值，删除了 259 个案例，而 fixed.x = TRUE。
2：在 lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats, :
lavaan 警告：
无法计算标准误差！信息矩阵无法反转。这可能是模型未被识别的症状。
3：在 lav_object_post_check(object) 中：
lavaan 警告：潜在变量的协方差矩阵不是正定的；
使用 lavInspect(fit, &quot;cov.lv&quot;) 进行调查。

这是我的协方差矩阵：
&gt; lavInspect(fit, &quot;cov.lv&quot;)
RI_x RI_y w___1 w___2 w___3 w____1 w____2 w____3
RI_x 0.306 
RI_y 0.168 0.269 
w_x_1 -0.056 -0.002 0.347 
w_x_2 -0.023 -0.006 0.137 0.185 
w_x_3 -0.002 -0.001 0.012 0.039 0.079 
w_y_1 -0.030 -0.029 0.153 0.085 0.011 0.210 
w_y_2 -0.011 -0.008 0.061 0.272 0.029 0.068 0.158 
w_y_3 -0.001 0.000 0.006 0.016 0.139 0.005 0.013 0.115

有人知道如何解决这个问题吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651221/negative-covariance-matrix-in-ri-clpm-lavaan</guid>
      <pubDate>Wed, 17 Jul 2024 07:33:23 GMT</pubDate>
    </item>
    <item>
      <title>检测病原体的样本量计算</title>
      <link>https://stats.stackexchange.com/questions/651220/sample-size-calculation-for-detection-of-a-pathogen</link>
      <description><![CDATA[我有一袋原料（干豆），重 25 公斤。可能存在病原体，也可能不存在。我需要从袋子中取样，以便我们能够 99% 地断言存在病原体（肉毒杆菌孢子）或不存在病原体。问题是：我需要取多少个样本（假设取 50 克样本）才能断言存在，应以何种方式进行取样（随机、系统、使用自动取样器...）？应该注意的是，病原体并不是随机分布的，如果存在，很可能是聚集的，因此病原体分布不均匀。一般来说，假设肉毒杆菌孢子的浓度较低（不超过 10%）。附加问题：有没有办法断言病原体确实分布在袋子内，而不是随机捕获的（例如，样本对病原体呈阳性，但病原体是由于手触摸而出现在袋子中的（因此这可能需要与样本中存在的病原体孢子总量/质量相关联）。]]></description>
      <guid>https://stats.stackexchange.com/questions/651220/sample-size-calculation-for-detection-of-a-pathogen</guid>
      <pubDate>Wed, 17 Jul 2024 07:27:17 GMT</pubDate>
    </item>
    <item>
      <title>具有预测器多重共线性的 GLMM 模型平均</title>
      <link>https://stats.stackexchange.com/questions/651217/glmm-model-averaging-with-predictor-multicollinearity</link>
      <description><![CDATA[我正在运行 GLMM 模型来确定环境因素如何影响鸟类碰撞。我获得了 delta AIC 小于 2 的候选模型列表，我想执行模型平均。
我理解使用基于 AIC 的平均值是一种常见方法。但是，我的预测因子在不同的候选模型中高度相关。例如，模型 1 包括“ntl500”（500m 缓冲区内的平均夜间灯光值），而模型 2 包括“ntl1000”（1000m 缓冲区内的平均夜间灯光值），它们高度相关。
在 BS Cade（2015 年）的论文模型平均和混乱的多模型推理中，他提到由于多重共线性，基于 AIC 的参数系数模型平均不可靠。对于 GLM 模型，他建议在拟合模型之前通过部分标准差对预测因子进行标准化。但是，计算偏标准差需要方差膨胀因子（VIF），而方差膨胀因子是通过运行模型获得的。这是否意味着我需要先用非标准化预测变量运行模型，然后用偏标准差对其进行标准化，然后再次运行模型？
或者请告诉我在平均模型时是否有其他方法可以处理候选模型中高度相关的变量。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/651217/glmm-model-averaging-with-predictor-multicollinearity</guid>
      <pubDate>Wed, 17 Jul 2024 06:27:44 GMT</pubDate>
    </item>
    <item>
      <title>如何对基于样本的丰度数据进行稀疏分析？</title>
      <link>https://stats.stackexchange.com/questions/651216/how-to-do-rarefaction-analysis-for-sample-based-abundance-data</link>
      <description><![CDATA[我想通过稀疏法比较不同林分的植物丰富度。数据以基于样地的方式收集。我在每个林分中设置了 4 个大小相同的样地，在每个样地的 5 个子样地中计数所有植物个体，并按样地汇总数据。因此，我的数据属于 Colwell 等人 (2012) 提出的“基于样本的丰度数据”，我的意思是，与基于个体的丰度数据相比，基本采样单位是一个样地，而不是一个个体，但丰度是在每个样本单位中测量的，而基于样本的发生率数据只记录存在/不存在。我正在使用 R 包 iNEXT 来分析数据，但无法确定我应该使用哪种稀疏法。
iNEXT 包支持基于个体的丰度数据和基于样本单位的存在/不存在发生率数据，但似乎没有处理基于样本的丰度数据的说明。我认为我应该将丰度数据转换为存在/不存在并将其作为发生率数据进行分析，而不是将其视为基于个体的丰度数据，以保留空间信息（Colwell 等，2012）。但我想知道样本单位数量少（每个林分 4 个地块）是否会成为问题？例如影响自举置信区间的准确性。此外，由于稀疏化的目标是标准化不同样本量的数据以供比较，我的数据在样本单位的情况下具有相同的样本量，但采样个体数量不同。按样本单位标准化是否合适？
此外，iNEXT 提供了按样本覆盖率标准化数据的选项。在我的情况下，将数据视为基于个体会产生更高的估计覆盖率。例如：当作为基于个体的丰度数据处理时，两个林分的估计覆盖率达到 96% 和 98%，但转换为存在-不存在数据时下降到 77% 和 91%。附件是使用不同类型数据的覆盖率的稀疏化结果示例。我希望能得到一些关于处理我的数据的最佳方法的建议。提前谢谢您。


参考文献：
Colwell, R.K., Chao, A., Gotelli, N.J., Lin, S.-Y., Mao, C.X., Chazdon, R.L.、Longino、J.T.，2012 年。基于个体和基于样本的稀疏化、外推和群落比较的模型和估计量。《植物生态学杂志》5，3-21。https://doi.org/10.1093/jpe/rtr044
Chao、A.、Gotelli、N.J.、Hsieh、T.C.、Sander、E.L.、Ma、K.H.、Colwell、R.K.、Ellison、A.M.，2014 年。使用希尔数的稀疏化和外推：物种多样性研究中的抽样和估计框架。《生态专著》84，45-67。 https://doi.org/10.1890/13-0133.1]]></description>
      <guid>https://stats.stackexchange.com/questions/651216/how-to-do-rarefaction-analysis-for-sample-based-abundance-data</guid>
      <pubDate>Wed, 17 Jul 2024 06:15:15 GMT</pubDate>
    </item>
    <item>
      <title>可以针对两点进行假设检验吗？</title>
      <link>https://stats.stackexchange.com/questions/651179/can-hypothesis-testing-be-done-on-two-points</link>
      <description><![CDATA[我为一些岛屿设置了以下内容（每个岛民的数据均可用，整个人口的数据也可用）：

2000 年：

成年人口总数：260,000；
健康成年人数量：250,000
患病成年人数量：10,000
健康率：250,000/260,000 = 0.961


2001 年：

成年人口总数：265,000；
健康成年人数量：261,000
患病成年人数量： 4,000
健康率：261,000/265,000 = 0.984



我想看看 2000 年岛上的健康率与 2001 年岛上的健康率在统计上是否有差异。
我的问题是只有两个比率可供比较，因此样本量为 2（即使每个比率本身都是根据大量人口计算的）。
即使只有两个点可供比较，这里还能进行假设检验吗？

附言：如果只有 2 个点而没有单独的数据 - 假设检验将不起作用？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651179/can-hypothesis-testing-be-done-on-two-points</guid>
      <pubDate>Tue, 16 Jul 2024 18:35:54 GMT</pubDate>
    </item>
    <item>
      <title>稳定逆概率加权 (IPW) 的夹心方差估计量或基于引导的方差</title>
      <link>https://stats.stackexchange.com/questions/651142/sandwich-variance-estimator-or-bootstrap-based-variance-for-stabilized-inverse-p</link>
      <description><![CDATA[多篇已发表的论文将 IPW 描述为类似于拥有多个相同个体副本的种群。因此，在提供权重的后续分析中，应使用夹心方差估计量或基于 bootstrap 的方差来计算和校正相关性。老实说，我不相信这一点，因为它是一个伪种群，而不是实际种群。
对于稳定的二元暴露 IPTW 权重，总样本量与预加权相同（即没有人为地增加样本量）。这是否意味着不需要使用夹心方差估计量或基于 bootstrap 的方差？如果是，二元结果是否需要它？]]></description>
      <guid>https://stats.stackexchange.com/questions/651142/sandwich-variance-estimator-or-bootstrap-based-variance-for-stabilized-inverse-p</guid>
      <pubDate>Tue, 16 Jul 2024 10:39:54 GMT</pubDate>
    </item>
    <item>
      <title>rms::val.surv 函数对所有情况估计了相同的生存概率</title>
      <link>https://stats.stackexchange.com/questions/651141/rmsval-surv-function-estimated-the-same-survival-probability-for-all-cases</link>
      <description><![CDATA[我已经拟合了一个 cox 回归模型，并使用 val.surv 函数绘制校准图，以比较观察到的生存概率与预测的生存概率。
model &lt;- cph(Surv(Time, status) ~ variable, data = data, surv = T, x = T, y = T, time.inc = 5)
obs_test &lt;- Surv(test_data$Time, test_data$status)
pred_test &lt;- survest(model, newdata = test_data, times = 5)$surv

val_ests &lt;- val.surv(est.surv = pred_test, S = obs_test, u = 5, fun = function(p)log(-log(p)), pred = sort(runif(100,0,1)))

然而，从val_ests，我看到 val_ests$actual 对所有样本的概率都相同。因此校准图显示一条直线。
请问这是否主要是由于样本量小？因此，当根据时间和状态估计生存概率时，不足以区分不同的生存概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/651141/rmsval-surv-function-estimated-the-same-survival-probability-for-all-cases</guid>
      <pubDate>Tue, 16 Jul 2024 10:21:10 GMT</pubDate>
    </item>
    <item>
      <title>使用已知 copula 参数进行预测的步骤</title>
      <link>https://stats.stackexchange.com/questions/651095/steps-for-forecasting-with-known-copulas-parameters</link>
      <description><![CDATA[我想计算我的 copula 模型的平均绝对百分比误差 (MAPE)。我卡在了预测步骤。我在这里没有为不同的数据对指定 copula。

我有两个时间序列 X 和 Y。我找到了最佳的 GARCH 参数 $\alpha$ 和 $\beta$，假设均值为 0。
两个变量之间的 Kendals tau 为 $\tau$
然后我找到了最佳 copula，其参数为 $\kappa$ 和 $\omega$。
现在为了进行预测，我需要使用在步骤 3 中找到的 copula 参数生成残差。

如果我想手动输入 copula 参数而不使用某些 param=fit 类型的代码，该如何操作R。
我既能用 R 也能用 Excel。如果有人能帮我完成第 4 点的具体步骤，请告诉我。
问题附件 - ]]></description>
      <guid>https://stats.stackexchange.com/questions/651095/steps-for-forecasting-with-known-copulas-parameters</guid>
      <pubDate>Mon, 15 Jul 2024 19:10:53 GMT</pubDate>
    </item>
    </channel>
</rss>