<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 16 Dec 2024 21:16:44 GMT</lastBuildDate>
    <item>
      <title>在此次治疗师依从性测试中，作者是否适当地应用了重复测量单因素方差分析和 ROC 分析？</title>
      <link>https://stats.stackexchange.com/questions/658834/have-the-authors-appropriately-applied-repeated-measures-one-way-anova-and-roc-a</link>
      <description><![CDATA[我正在阅读一篇关于我所从事的心理治疗类型的研究。我的直觉是，这篇论文对统计数据的使用是有缺陷的，但我在意识形态上想要找出这篇特定研究的缺陷，而且我对统计数据的了解相当基础。出于这些原因，我不会链接到这篇论文。
这篇论文的所有作者都是接受过同一种治疗培训的心理治疗师。他们创建了一份问卷，供接受过该治疗培训的观察员使用，以评估治疗师在特定疗程中对该治疗的治疗程度。（即，这是一项依从性测试。）作者将这份问卷分发给了大约 200 名参与者（均接受过相关治疗培训），并附上了 4 个治疗疗程的视频；其中 2 个由接受过相关治疗培训的治疗师制作，另外 2 个由接受过其他治疗培训的治疗师制作。参与者对前两个视频的评分（每个约平均值 = 16.5，标准差 = 0.2）高于对后两个视频的评分（每个约平均值 = 4.5，标准差 = 0.25），这表明使用问卷可以清楚地区分受过相关疗法培训的人提供的疗法和受过其他疗法培训的人提供的疗法。
作者将上述平均值和标准差值作为“单向重复测量方差分析”的一部分呈现测试，他们说这显示出了统计学意义。
然后，他们进行了 ROC 分析，以确定将感兴趣的疗法与其他类型的疗法区分开来的阈值分数，并获得了 11 的值。
我有两个顾虑：
1：Statology 说，“重复测量单向方差分析用于确定三个或更多组的平均值之间是否存在统计学上的显着差异，其中每个组中都出现了相同的受试者。”我可以看到这里有 4 个组（4 个视频中的每个视频都有 1 组分数），但是，按照 Statology 的字面意思理解，这意味着观察者评分者是受试者，而不是他们正在评分的视频会话。如果研究的目的是找到一种方法来区分感兴趣的疗法和其他类型的疗法，那么我们实际上肯定有两组（2 个感兴趣的疗法样本和 2 个来自另一种疗法的样本）。如果我们只有 4 个样本，那么我认为统计显着性检验尚不合适。我愿意被告知我对此的想法是错误的，并欢迎任何评论。
2：维基百科说 ROC 分析是为了确定什么强度的信号应该被视为值得在雷达上显示的物体而开发的。我认为该任务必然是二进制的，以限制雷达操作员必须解析的信息量。我认为阈值不适用于确定某人是否遵守特定类型的治疗（特别是如果我们只有 4 个样本并且我们只评估了 2 种类型的治疗）。再次，我欢迎任何评论，包括对我的观点的任何更正。
我不知道是否已经发布了足够的有关该研究的信息。如果我应该提供更多详细信息，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/658834/have-the-authors-appropriately-applied-repeated-measures-one-way-anova-and-roc-a</guid>
      <pubDate>Mon, 16 Dec 2024 20:53:10 GMT</pubDate>
    </item>
    <item>
      <title>建模重叠时间段</title>
      <link>https://stats.stackexchange.com/questions/658825/modelling-overlapping-time-periods</link>
      <description><![CDATA[我在很长一段时间内一直在跟踪我的体重和卡路里摄入量。假设我有连续 100 天的完整卡路里观测数据。
我可以通过回归体重和卡路里来估算诸如每日总能量消耗 (TDEE) 之类的数据。普遍接受的数字是 3,500 千卡的缺口导致体重减轻 1 磅（或 1,600 千卡的缺口导致体重减轻 1 公斤）。
现在，我可以对整个 100 天的时间段进行建模，但我也有兴趣研究其中较短的时间跨度。最简单的做法是将 100 天分成 7 个两周的时间段。但是，你可以将 100 天分成更多重叠的两周时间段，每个时间段的值分别为（总卡路里）和（总损失）。
当然，这些新时间段不会是独立的，但增加时间段的数量会给我带来更多的力量，但我不清楚如何解决这个问题，我找不到任何东西，因为我不知道该怎么称呼它。]]></description>
      <guid>https://stats.stackexchange.com/questions/658825/modelling-overlapping-time-periods</guid>
      <pubDate>Mon, 16 Dec 2024 18:37:22 GMT</pubDate>
    </item>
    <item>
      <title>是否可以对使用非概率抽样收集的加权数据进行统计显著性检验方法？</title>
      <link>https://stats.stackexchange.com/questions/658822/can-statistical-significance-testing-methods-be-carried-out-on-weighted-data-tha</link>
      <description><![CDATA[我正在分析使用非概率抽样方法收集的调查数据集。此数据集还包括一个权重字段，允许将调查结果推断到更广泛的人群。
鉴于此权重数据的存在，我是否能够使用传统的统计显着性检验方法，如卡方检验和 t 检验？（我将使用 R 的 survey 和 srvyr 包或 Python 的 samplics 包将权重值合并到我的代码中。或者这些测试是否仍然无效，因为原始数据不是从随机样本中收集的？（如果是这样，我们将非常感激与非概率抽样方法兼容的替代测试的建议。）]]></description>
      <guid>https://stats.stackexchange.com/questions/658822/can-statistical-significance-testing-methods-be-carried-out-on-weighted-data-tha</guid>
      <pubDate>Mon, 16 Dec 2024 17:39:03 GMT</pubDate>
    </item>
    <item>
      <title>在机器/深度学习中，什么才算是“低级”或“高级”特征？</title>
      <link>https://stats.stackexchange.com/questions/658819/what-qualifies-as-low-level-or-high-level-feature-in-machine-deep-learning</link>
      <description><![CDATA[在讨论 CNN 时，通常会出现术语“低级”和“高级”特征。例如：（摘自R 中的统计学习应用简介）

网络首先识别输入图像中的低级特征，
例如小边缘、色块等。然后，将这些低级
特征组合起来形成更高级的特征，例如
耳朵、眼睛等的部分。最终，这些更高级特征的存在或不存在会影响任何给定输出类的概率。

为什么“眼睛”与边缘相比，哪些特征被视为“高级”特征（即更“抽象”的特征）？
在深度学习或机器学习中，对于什么是“低级”特征和“高级”特征，是否存在共识？]]></description>
      <guid>https://stats.stackexchange.com/questions/658819/what-qualifies-as-low-level-or-high-level-feature-in-machine-deep-learning</guid>
      <pubDate>Mon, 16 Dec 2024 17:07:32 GMT</pubDate>
    </item>
    <item>
      <title>多元分布函数示例[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658818/multivariate-distribution-function-examples</link>
      <description><![CDATA[我正在寻找多元分布的累积分布函数 (CDF) 的示例。我在网上搜索过但没有找到。有人能给我提供一些示例吗？我正在寻找一些 $k$ 维 CDF。]]></description>
      <guid>https://stats.stackexchange.com/questions/658818/multivariate-distribution-function-examples</guid>
      <pubDate>Mon, 16 Dec 2024 16:59:45 GMT</pubDate>
    </item>
    <item>
      <title>统计调查。过度分散问题或大量 0</title>
      <link>https://stats.stackexchange.com/questions/658816/statistical-inquiry-overdispersion-issue-or-abundance-of-0s</link>
      <description><![CDATA[尝试查看一些数据，其中一半存在缺失，而另一半是计数数据。我最近一直在研究的模型是 lmer 和 glmer.nb 的混合，因为这似乎是计数数据的方法。下面是我正在研究的 SEM 的摘要，但它都是 lmer，但我希望其中与 F 相对应的部分是 glmer.nm，或者我应该使用 glmmTMB？整个东西必须是 glmer.nb 或 glmmTMB 吗？我想将另外两个变量添加到模型中，它们是计数数据，但如果我这样做，我会因为过度分散而收到很多警告或错误。 。有一个关于缩放预测变量的警告，但如果我缩放它，它会产生一些负值，我无法使用，这可能是数据集中 0 的结果。看起来卡方和 fishers 的优度对当前这个来说很好，但我想尝试在其中添加另外 2 个东西（我知道 F 是计数数据，可能应该以不同的方式出现在模型中）。这有点太多了吗？有什么建议吗？
df &lt;- psem(
lmer(B ~ N + A + F + (1 | site), data = d8),
#lmer(A ~ F + (1 | site), data = d8),
lmer(A ~ F +(1 | site), data = d8),
lmer(T ~ F + A + (1|site), data = d8),
lmer(S ~ B + F + (1|site), data = d8),
lmer(D ~ A + T + (1|site),data = d8),
lmer(A ~ N + (1|site), data = d8),
lmer(C ~ F + T + S + (1|site), data = d8)
)
df 的结构方程模型
调用：
B ~ N + A + F
A ~ F
T ~ F + A
S ~ B + A
D ~ F + T
F ~ N
C ~ A + T + S
AIC

1852.841

定向分离测试：
 独立声明 测试类型 DF 临界值 P 值 
T ~ N + ... 系数 42.0055 0.1793 0.6741 
S ~ N + ... 系数 37.8295 1.5885 0.2153 
D ~ N + ... 系数 55.9602 1.1410 0.2900 
C ~ N + ... 系数 31.7632 1.5056 0.2288 
A ~ N + ... 系数 46.8297 2.6263 0.1118 
T ~ B + ... 系数 28.2731 0.5232 0.4754 
D ~ B + ... 系数 35.3531 0.0203 0.8875 

C ~ B + ... 系数 29.7178 0.9221 0.3447
S ~ T + ... 系数 46.8141 1.5520 0.2190
D ~ S + ... 系数 54.9386 0.3143 0.5773
A ~ S + ... 系数 55.9466 5.2821 0.0253 *
C ~ D + ... 系数 33.4871 0.0050 0.9442
A ~ D + ... 系数48.2623 0.3947 0.5328
A ~ C + ... 系数 52.9124 0.0062 0.9375
--
整体拟合优度：
卡方 = 11.829，P 值 = 0.893，自由度为 19
Fisher C = 30.515，P 值 = 0.339，自由度为 28

系数：
 响应 预测 估计 标准误差 DF 临界值 P 值 标准估计 
B N 9.7176 1.0037 46.0216 91.5297 0.0000 0.9343 ***
B A -0.1836 0.0421 43.7463 18.7062 0.0001 -0.3859 ***
B F 0.0020 0.0005 41.9443 16.0755 0.0002 0.3260 ***
A F 0.0060 0.0013 53.6423 21.5820 0.0000 0.4709 ***
T F -0.0018 0.0006 56.5517 8.6751 0.0047 -0.4254 **
T A 0.1209 0.0506 48.7150 5.2512 0.0263 0.3557 *
S B 0.1892 0.0449 55.4474 16.8407 0.0001 0.4623 ***
S F -0.0009 0.0002 50.4275 14.3701 0.0004 -0.3607 ***
D F 0.0007 0.0003 50.4177 6.9658 0.0110 0.2295 *
D T 0.2084 0.0660 51.4101 9.5847 0.0032 0.2801 **
F N -701.2503 250.3729 49.6386 7.1996 0.0099 -0.4094 **
C A 0.0007 0.0006 48.6534 1.2172 0.2753 0.1311 
C T 0.6899 0.1468 50.4268 20.1428 0.0000 0.5521 ***
C S -0.5645 0.2596 40.3871 4.3953 0.0423 -0.2589 *

显著性。代码：0 &#39;&#39; 0.001 &#39;&#39; 0.01 &#39;&#39; 0.05

个人 R 平方：
 响应方法 边际 条件
B 无 0.30 0.95
B 无 0.22 0.66
T 无 0.15 0.40
S 无 0.24 0.77
D 无 0.13 0.76
A 无 0.14 0.51
C 无 0.32 0.49
]]></description>
      <guid>https://stats.stackexchange.com/questions/658816/statistical-inquiry-overdispersion-issue-or-abundance-of-0s</guid>
      <pubDate>Mon, 16 Dec 2024 16:36:48 GMT</pubDate>
    </item>
    <item>
      <title>条件多元正态分布的 Cholesky 因式分解</title>
      <link>https://stats.stackexchange.com/questions/658815/cholesky-factorization-of-a-conditional-multivariate-normal-distribution</link>
      <description><![CDATA[令 $X$ 为具有多元正态分布的随机向量：$X\sim \mathcal{N}(\mu,\Sigma)$。
让 $L$ 成为 $\Sigma$ 的 Cholesky 因式分解：$\Sigma = LL&#39;$，这样我们就可以写出
$$X=L X_0 +\mu,$$
其中 $X_0\sim \mathcal{N}(0,I)$。
如果我们将 $X$ 拆分为两个向量 $X=(X_1,X_2)$，我们知道
$$X_1|X_2\sim\mathcal{N}(\mu_{1|2},\Sigma_{1|2}),$$
其中 $\mu_{1|2}=\mu_1 + \Sigma_{12}\Sigma_{22}^{-1}(X_2-\mu_2)$ 和 $\Sigma_{1|2}=\Sigma_{11}-\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}$，
其中 $\mu=(\mu_1,\mu_2)$ 和 $\Sigma_{1/2,1/2}$ 对应于 $\Sigma$。
是否有一个公式可以直接从 $L$ 或 $L$ 的一些子矩阵获得 $\Sigma_{1|2}$ 的 Cholesky 因式分解？
我问这个问题是因为我想从 $L$ 模拟条件分布 $X_1|X_2$，同时避免计算矩阵的某些逆，例如 $\Sigma_{22}^{-1}$。]]></description>
      <guid>https://stats.stackexchange.com/questions/658815/cholesky-factorization-of-a-conditional-multivariate-normal-distribution</guid>
      <pubDate>Mon, 16 Dec 2024 16:14:12 GMT</pubDate>
    </item>
    <item>
      <title>在深度学习图像分割中：为 N 个类别训练 N 个模型是否比为 N 个类别训练一个模型更好</title>
      <link>https://stats.stackexchange.com/questions/658814/in-deep-learning-image-segmentation-is-it-better-to-train-n-models-for-n-class</link>
      <description><![CDATA[我想知道您是否有任何最近的出版物参考资料或有关“为 N 个类别训练 N 个模型还是为 N 个类别训练一个模型更好”问题的经验？
我知道这取决于主干、数据类型等......但我找不到有关这个问题的任何最新、可靠和稳健（论文类型）的内容。
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658814/in-deep-learning-image-segmentation-is-it-better-to-train-n-models-for-n-class</guid>
      <pubDate>Mon, 16 Dec 2024 15:42:59 GMT</pubDate>
    </item>
    <item>
      <title>Cox 回归假设</title>
      <link>https://stats.stackexchange.com/questions/658802/cox-regression-assumptions</link>
      <description><![CDATA[我正在分析血浆生物标志物与疾病发病率之间的关联，这些关联是通过年度问卷自我报告的。总样本量为 824，其中 65 人报告了至少一个事件（我不考虑多个事件）。除了事件发生之外，所有其他变量都是在基线测量的。我会使用 Cox 比例风险回归模型，但我不熟悉这个模型，并且对我获得的假设图感到很困惑。
我的完全调整模型如下所示：
assumpt.cox &lt;- coxph(Surv(time, event) ~ contvar1 + 
contvar2 + catvar1 + catvar2 + 
catvar3 + contvar3 + catvar4 + contvar4 + contvar5, data = data_assumpt.cox)

其中 contvar 是连续变量，catvar 是分类变量。我主要关注的是 contvar1。
我检查了 PH 假设，它没有表明违反（所有变量和全局变量的 p&gt;0.05）。
对于有影响的点，我检查了偏差并注意到所有报告事件的参与者都聚集在图表的顶部，而没有报告事件的参与者则聚集在底部。此外，平均偏差不为 0。但我不清楚我应该怎么做。
ggcoxdiagnostics(assumpt.cox, type = &quot;deviance&quot;,
linear.predictions = FALSE, ggtheme = theme_bw()) 


对于线性，我发现了两种主要方法来检查这个假设。

使用空模型：

 ggcox functional(Surv(time, event) ~ contvar1 + I(contvar1)^2 + log(contvar1) + 
sqrt(contvar1), data = data_assumpt.cox)



使用完全调整的模型：

data_assumpt.cox %&gt;% 
ggplot(aes(x=contvar1, y=residuals(assumpt.cox, type=&quot;martingale&quot;))) + 
geom_point() + 
geom_hline(yintercept = 0, color=&quot;blue&quot;) +
geom_smooth(color=&quot;red&quot;) +
theme_bw()



我明白，在第一组图中，我应该看到数据点和残差线之间有很好的相关性，而在第二组图中，红线应该（大部分）在 0 处笔直。但总的来说，它们应该告诉我同样的事情。这是正确的吗，还是应该优先考虑其中一个？
从这些图中，我得出结论，线性假设被违反了。
但如果是这样，我该怎么办，因为转换似乎没有帮助？我也试图排除 contvar1 中的两个极端值（一个有事件，一个没有事件），但效果只略有改善。
抱歉发了这么长的帖子，我希望至少能说清楚。
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658802/cox-regression-assumptions</guid>
      <pubDate>Mon, 16 Dec 2024 09:44:18 GMT</pubDate>
    </item>
    <item>
      <title>多个非独立同分布 beta 素数变量之和</title>
      <link>https://stats.stackexchange.com/questions/658799/the-sum-of-multiple-non-i-i-d-beta-prime-variables</link>
      <description><![CDATA[假设 $X_1$,$X_2$,$X_3$ 是独立同分布的。伽马随机变量，则$\frac{X_1}{X_2}$、$\frac{X_2}{X_3}$、$\frac{X_3}{X_1}$服从 beta 素数分布且相互关联。
那么，$\frac{X_1}{X_2}+\frac{X_2}{X_3}+\frac{X_3}{X_1}$的分布是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658799/the-sum-of-multiple-non-i-i-d-beta-prime-variables</guid>
      <pubDate>Mon, 16 Dec 2024 08:29:57 GMT</pubDate>
    </item>
    <item>
      <title>在回归模型中意外地两次包含同一个变量？</title>
      <link>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</link>
      <description><![CDATA[我在 R (mgcv) 中有这种混合效应 GAM 回归：
library(mgcv)
gam_beta &lt;- gam( 
y ~ te(time, x1) + te(time, x2) + s(time, by = city) + s(city, bs = &quot;re&quot;), 
data = my_data,
method = &quot;REML&quot;, 
family = betar(link = &quot;logit&quot;)
)

我尝试为该模型编写方程（基于我对 mgcv 中张量积函数 te 的理解 https://www.rdocumentation.org/packages/mgcv/versions/1.9-1/topics/te):
$$ y_{ij} \sim \text{Beta}(\mu_{ij}\phi, (1-\mu_{ij})\phi) $$
$$\mu_{ij} = \frac{1}{1+e^{-\eta_{ij}}}$$
$$ \text{logit}(\mu_{ij}) = \eta_{ij}= \beta_0 + f_{12}(time_{ij}, x1_{ij}) + f_{34}(time_{ij}, x2_{ij}) + h_i(time_{ij}) + b_i $$
我尝试将其进一步扩展：
$$ \eta_{ij} = \underbrace{\sum_{k=1}^{K_1} \hat{\gamma}_{1k}f_{1k}(time_{ij}) + \sum_{l=1}^{L_1} \hat{\gamma}_{2l}g_{1l}(x1_{ij}) + \sum_{k=1}^{K_1}\sum_{l=1}^{L_1} \hat{\gamma}_{3kl}f_{1k}(time_{ij})g_{1l}(x1_{ij})}_{\text{first te(): time and x1 term}} + $$
$$ \underbrace{\sum_{m=1}^{M_1} \hat{\gamma}_{4m}f_{2m}(time_{ij}) + \sum_{n=1}^{N_1} \hat{\gamma}_{5n}g_{2n}(x2_{ij}) + \sum_{m=1}^{M_2}\sum_{n=1}^{N_2} \hat{\gamma}_{6mn}f_{2m}(time_{ij})g_{2n}(x2_{ij})}_{\text{second te(): time and x2 term}} + $$
$$ \underbrace{\sum_{p=1}^P \hat{\alpha}_{ip}h_p(time_{ij})}_{\text{city-specific smooth}} + \underbrace{\hat{b}_i}_{\text{random effect}} $$
我的问题如下：我知道 mgcv 中的 te 函数包含主效应和交互效应 (GAM 回归：交互与主效应？)。但这是否意味着某个术语存在被重复计算并在 GAM 方程中出现两次的风险？
例如，我有 te(time,x1) 和 te(time,x2)。这是因为我想在我的模型中包含与协变量 x1 和 x2 的时间交互。但这是否会导致时间的主效应被包含两次？或者 mgcv 会识别这一点并且只包含一次？]]></description>
      <guid>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</guid>
      <pubDate>Mon, 16 Dec 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>数据分类</title>
      <link>https://stats.stackexchange.com/questions/658795/data-categorization</link>
      <description><![CDATA[我已将我的教育数据集分类以供以下分析。但是，我遇到过一位受访者就读于一所传教学校，我不知道其水平，也不确定将他们放在何处。我应该将他们排除在外吗？我的决定基于什么依据？
教育 是 否 总计
高等教育 22 13 35
中学 144 47 191
小学 103 52 155
未受过教育 23 13 36
]]></description>
      <guid>https://stats.stackexchange.com/questions/658795/data-categorization</guid>
      <pubDate>Mon, 16 Dec 2024 06:47:39 GMT</pubDate>
    </item>
    <item>
      <title>计算不同大小的文本语料库的卡方</title>
      <link>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</link>
      <description><![CDATA[我偶然发现了一篇论文，它批评了某文本分析软件中用于比较六个大小明显不同的文本语料库中的词频的卡方统计量的计算。该软件采用标准公式：
$$
\chi^2 = \sum_{i=1}^{n} \frac{(O_{i} - E_{i})^2}{E_{i}}
$$
这里，$O_{i}$表示在语料库$i$中观察到的频率，$E_{i}$的计算方法是将一个词在所有六个语料库中的总频率除以所有语料库中的单词总数，然后乘以语料库$i$中的单词数。
本文作者批评了这种方法，陈述：

&quot;运行交叉制表也不能产生有效可靠的评估。 [...] 事实证明，该软件使用非标准化的绝对频率，只有当要比较的文本语料库长度相等时才不会引起问题。&quot;

在这种情况下，作者将$O_{i}$解释为绝对频率，并提出了一种替代的&quot;标准化&quot;过程来计算$O_{i}$和$E_{i}$。这涉及：

选择最小的语料库作为参考。
通过将观察到的所有其他语料库的频率除以各自语料库中的单词总数，然后乘以参考语料库中的单词数，对观察到的所有其他语料库的频率进行归一化。
将预期频率计算为所有语料库（包括参考语料库）的归一化频率之和，除以六（语料库数量）。

问题 1：作者声称该软件使用的公式（如上所述）没有考虑到语料库的各种大小，他是否正确。
问题 2：在这种情况下，这种归一化方法是否适用于卡方计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</guid>
      <pubDate>Sun, 15 Dec 2024 13:37:05 GMT</pubDate>
    </item>
    <item>
      <title>纳入因变量的下限是否可以改善估计？</title>
      <link>https://stats.stackexchange.com/questions/658703/does-incorporating-lower-bound-on-dependent-variable-improve-estimation</link>
      <description><![CDATA[假设我们抛硬币 $K$ 次，其中 如果正面，则为 $Z_k = 1$，否则为 0，并且 $Y = \sum_{k=1}^{K} Z_k$ 是正面的总数。假设这些是 i.i.d. 公平硬币，并且 $P(Z_k=1) = 0.5$。
然后我们重复此游戏 $n$ 次，每次抛 $K$ 枚硬币并观察实现 $Y_i$。目标是预测每场游戏中正面朝上的次数$\{Y_i : i=1,\dots, n\}$。

由于我们知道分布$Y \sim Binom(K, 0.5)$，标准/“朴素”方法就是简单的均值估计量：
$$ \hat{Y}_i = \mathbb{E}[Y] = 0.5K$$
这为$n$场游戏中的每一场提供恒定的预测。
现在问题如下。假设我们处于$i$场游戏。在 $K$ 次抛硬币之前，我们可以随时暂停游戏，优化模型，然后继续进行其余的抛硬币。我们能改进朴素估计器吗？
Oracle 估计器会设置 $\hat{Y}_i = Y_i$ 和 $MSE(Y_i, \hat{Y}_i) = 0$，但这在实践中显然是不可能的，因为我们实际上并不知道结果是什么。然而，每次抛硬币，我们都会收集更多关于 $Y_i$ 下限的信息。更准确地说，如果我们暂停翻转并观察到有$c_i$次正面，那么我们就知道
$$ Y_i \geq c_i $$
这就会激发&quot;增强&quot;估计量：
$$ \hat{Y}_i^{aug}(c_i) = \mathbb{E}[Y|Y\geq c_i] = \frac{ \int_{c_i}^{K} y \ dP_Y}{\int_{c_i}^{K} dP_Y} = \frac{\sum_{y=c_i}^{K} y P(Y=y)}{P(Y \geq c_i)}$$
其中，朴素估计量是$c_i = 0$的一个特例。将条件$\sigma$-代数的解释作为信息，我们获得了关于每个$Y_i$的一些额外信息，这应该可以让我们获得更好的预测。例如，假设$K=10$，我们在$c=6$次翻转后暂停游戏。朴素估计器将预测$\hat{Y}_i = 5$。但是我们已经知道 $Y_i \geq 6$，因此任何高于 6 的预测都会比朴素估计更接近真实的 $Y_i$。
有没有办法正式证明增强估计在某种意义上比朴素估计“更好”？

我用 $K=10$ 进行了数值模拟，得到了一些有趣的结果。这里的 x 轴是让 $c = pY$ 和 $p \in [0,1]$。随着 $c$ 的增加，我们获得更多的“部分知识”关于$Y$。直观上讲，我们拥有的信息越多，MSE 就越低，我们的预测就越好，但 U 形现象很有趣。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658703/does-incorporating-lower-bound-on-dependent-variable-improve-estimation</guid>
      <pubDate>Sat, 14 Dec 2024 05:37:35 GMT</pubDate>
    </item>
    <item>
      <title>多参数最大似然估计的渐近正态性证明</title>
      <link>https://stats.stackexchange.com/questions/658664/proof-for-asymptotic-normality-for-mle-with-multiple-parameters</link>
      <description><![CDATA[我有一个问题，关于如何证明多个 MLE 估计量的渐近性质。您在网上找到的大多数资源都提供了仅估计一个参数的情况的证明（例如此处：https://gregorygundersen.com/blog/2019/11/28/asymptotic-normality-mle/）。在这个证明中，将参数方面的均值定理应用于似然的一阶导数，得到类似$(\hat{\theta} - \theta_0) = - \frac{L_n&#39;(\theta_0)}{L_n&#39;&#39;(\tilde{\theta})}$的表达式，然后将渐近结果应用于似然。我将这种证明扩展到多参数情况的问题是均值定理仅适用于标量函数。对于矢量值函数，只有不等式成立，参见例如。 https://en.wikipedia.org/wiki/Mean_value_theorem#Mean_value_theorem_for_vector-valued_functions。
有人能告诉我如何证明多个参数的渐近正态性吗？当然，如果能提供参考，我也非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658664/proof-for-asymptotic-normality-for-mle-with-multiple-parameters</guid>
      <pubDate>Fri, 13 Dec 2024 10:29:14 GMT</pubDate>
    </item>
    </channel>
</rss>