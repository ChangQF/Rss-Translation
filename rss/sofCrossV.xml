<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 22 Dec 2024 18:20:44 GMT</lastBuildDate>
    <item>
      <title>在 R 中对分数数据进行建模</title>
      <link>https://stats.stackexchange.com/questions/659095/modelling-fractional-data-in-r</link>
      <description><![CDATA[我有以下一组数据，其中响应变量是比例数据
dat = structure(list(Y = c(0.0104, 0.01044, 0.00809, 0.00413, 0.00634, 
0.0021, 0.00729, 0.02386, 0.00722, 0.0109, 0.00873, 0.00647, 
0.00611, 0.02342, 0.01818, 0.0176, 0.01865, 0.00546, 0.00515, 
0.02477, 0.00625, 0.01538), X = c(0.01077, 0.01956, 0.02298, 
0.10304, 0.02963, 0.04887, 0.01589, 0.00519, 0.05161, 0.00357, 
0.02279, 0.02733, 0.07581, 0.03643, 0.03257, 0.03324, 0.0509, 
0.05552, 0.08214, 0.01031, 0.08347, 0.02489)), row.names = c(NA, 
-22L), class = &quot;data.frame&quot;)

在我的例子中，Y 是比例数据。因此我想在此数据上拟合 分数逻辑模型，如下所示
&gt; summary(glm(&quot;Y ~ X&quot;, dat = dat, family = binomial()))

调用：
glm(formula = &quot;Y ~ X&quot;, family = binomial(), data = dat)

系数：
估计标准差。误差 z 值 Pr(&gt;|z|)
(截距) -4.043 3.381 -1.196 0.232
X -12.650 88.094 -0.144 0.886

(二项式系列的分散参数取为 1)

零偏差：21 个自由度上的 0.086252
残差偏差：20 个自由度上的 0.063149
AIC：4.4969

Fisher 评分迭代次数：8

这表明变量 X 非常不显著
这是违反直觉的，因为 Y 和 X 之间存在显著相关性
现在，我拟合一个 简单线性回归，然后我得到显著X 变量
&gt; library(dplyr)
&gt; summary(glm(&quot;Z ~ X&quot;, dat = dat %&gt;% mutate(Z = log(Y / (1-Y)))))

调用：
glm(formula = &quot;Z ~ X&quot;, data = dat %&gt;% mutate(Z = log(Y/(1 - Y))))

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) -4.1740 0.2074 -20.129 9.55e-15 ***
X -12.7358 4.4171 -2.883 0.00919 ** 
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（高斯族的分散参数取为 0.3104897）

零偏差：21 个自由度上的 8.7910
残差偏差：20 个自由度上的 6.2098
AIC：40.605

Fisher 评分迭代次数：2

您能帮我理解为什么我的第一个使用 glm() 的模型无法显示显著的 X 变量吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659095/modelling-fractional-data-in-r</guid>
      <pubDate>Sun, 22 Dec 2024 14:22:40 GMT</pubDate>
    </item>
    <item>
      <title>引导平均导数估计量</title>
      <link>https://stats.stackexchange.com/questions/659094/bootstrapping-the-average-derivative-estimator</link>
      <description><![CDATA[设 $f(x)=\mathbb E[Y\mathop | X=x]$ 为回归函数，$\hat {f}(x)$ 为其估计值（例如，使用核回归）。平均导数估计量（Härdle 和 Stoker，1989；Rilstone，1991；Rodríguez 和 Shelton，2013）定义为
$$
\hat\mu_X=\frac1n\sum_{i=1}^n{\hat {f^{\prime}}}(X_i)
$$
请注意，$\hat \mu_X$ 是 $\mathbb E[f&#39;(X)]$ 的一致估计量。类似地，我们可以定义高阶导数的估计量$\mathbb E[f^{(n)}(X)]$:
$$
\hat\mu_X^{(m)}=\frac 1n\sum_{i=1}^n\hat f^{(n)}(X_i)
$$
现在我想对平均导数进行假设检验。具体来说，我想测试
$$
H_0:\mathbb E[f&#39;(X)]=0
$$
和
$$
H_0&#39;:\mathbb E[f&#39;&#39;(X)]=0。
$$
我使用引导程序如下：将引导样本表示为$x_1,\cdots,x_B$，每个样本都是一个具有一定大小的向量（例如$k$），在引导数据上重新拟合模型，计算导数的 t 统计量（通过减去$\hat\mu_X$来降低平均值），然后$p$值由引导$t$统计量中大于从整个样本计算出的$t$统计量的比例给出。它类似于随机变量均值的引导检验。 （这里有一些幻灯片，供参考）

现在我想知道，这个测试是否有效（我已经在 R 中实现了它）？我是否应该为每个引导样本重新拟合模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/659094/bootstrapping-the-average-derivative-estimator</guid>
      <pubDate>Sun, 22 Dec 2024 13:18:27 GMT</pubDate>
    </item>
    <item>
      <title>最大似然估计 (MLE) 的矩收敛</title>
      <link>https://stats.stackexchange.com/questions/659091/convergence-of-moments-for-maximum-liklihood-estimators-mle</link>
      <description><![CDATA[设 $\hat{\theta}$ 为参数 $\theta$ 的 MLE 估计量，它来自紧凑空间 $\Theta$。我们知道
$$\hat{\theta}\to_P \theta$$
并且
$$\sqrt{n} (\hat{\theta}-\theta)\to_D N(0,\sigma^2)$$
其中 $\sigma^2$ 是逆 Fisher 信息。
我的问题是：我们在均方结果中是否有以下收敛？
$$E|\sqrt{n} (\hat{\theta}-\theta)|^2 \to \sigma^2$$
我有已完成：

我知道分布收敛加上均匀可积性意味着矩收敛，但是，这里，RV 序列：$\{\sqrt{n} (\hat{\theta}-\theta)\}_n$ 显然不是均匀可积的。

我在 iid 随机变量的中心极限定理 (Thm. 6.3 of 统计和概率的渐近理论):



假设 $X_1,...,X_n$ 是 iid 的，均值为 $\mu$，方差为有限 $\sigma^2$，并且假设对于某个特定的 $k$，$E|X_1|^k&lt;\infty$。假设$Z~N(0,1)$，则
$$E\left[\frac{\sqrt{n}(\bar{X}_n-\mu)}{\sigma}\right]^r = E(Z)^r + O(\frac{1}{\sqrt{n}})$$

这显然意味着
$$E\left[\frac{\sqrt{n}(\bar{X}_n-\mu)}{\sigma}\right]^r \to E(Z)^r$$
从这个结果来看，我猜我的问题应该是文献中研究得很好的问题。但是，我找不到任何参考资料或书籍。]]></description>
      <guid>https://stats.stackexchange.com/questions/659091/convergence-of-moments-for-maximum-liklihood-estimators-mle</guid>
      <pubDate>Sun, 22 Dec 2024 10:52:19 GMT</pubDate>
    </item>
    <item>
      <title>Weightthem后的中介分析</title>
      <link>https://stats.stackexchange.com/questions/659090/mediator-analysis-after-weightthem</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659090/mediator-analysis-after-weightthem</guid>
      <pubDate>Sun, 22 Dec 2024 10:08:42 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯定理助力赢得第二次世界大战</title>
      <link>https://stats.stackexchange.com/questions/659076/bayes-theorem-helps-win-world-war-ii</link>
      <description><![CDATA[有没有人读过这篇文章 (https://towardsdatascience.com/how-bayes-theorem-helped-win-the-second-world-war-7f3be5f4676c)，或者非常熟悉贝叶斯定理如何帮助二战。这是我能找到的“最好的”文章，在某种程度上说明了它是如何使用的，但他们让读者“填空”，读过这篇文章大约十几遍后，我希望得到一些帮助。这是我真正挣扎的文章部分。

盟军已经了解了日本密码本的一部分，许多密码组都是已知的。这些被称为“好组”，并与其（非携带）差异（V）一起制成表格。如果已知 50 个组，则必须计算并记录 1225 个差异。
密码分析师会比较从截获的消息和好组中计算出的差异。如果找到匹配项（在我们的例子中为 22571，以红色显示），则计算假设的加法（以绿色显示）。
最后也是最重要的任务是测试这个假设的加法的有效性。作为第一步，从每条消息中相应的编码字中减去加法（VI）。如果生成的代码（以蓝色显示）违反了“可被 3 整除”规则，则可以快速丢弃加法，从而为盟军节省大量时间。通常，多种潜在添加剂都会通过此测试，因此使用统计分析来确定它们的相对强度。

有人可以对这部分进行详细解释吗？我发现它很有趣，但计算结果极其罕见，甚至不可能找到。我将永远感激不尽谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659076/bayes-theorem-helps-win-world-war-ii</guid>
      <pubDate>Sun, 22 Dec 2024 01:30:25 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据插补生成方法背后的直觉</title>
      <link>https://stats.stackexchange.com/questions/659075/intuition-behind-generative-methods-for-imputing-missing-data</link>
      <description><![CDATA[我正在学习不同的方法来估算混合连续和分类变量的表格数据集，并且假设数据完全随机缺失。我使用频率编码器转换了分类数据，因此所有内容都是数字或 NaN。
我认为平均值、中位数等估算过于简单且容易产生偏差。我正在考虑更复杂的方法，例如确定性和生成性。
对于确定性，我尝试了 LightGBM，它非常直观。我喜欢它。基本上，对于每个具有缺失数据的特征，其非缺失数据作为对其他特征的回归，然后预测/估算缺失数据。很棒。
现在我尝试使用深度学习方法，例如 AE 或 GAN。通过查阅文献，这似乎非常可行且非常有效。但黑匣子很难理解。例如，对于 VAE，我们是否只是简单地基于整个表格数据构建一个 VAE 模型，然后“以某种方式”预测/生成/估算缺失数据？
我仍在研究这个问题以获得更清晰的解释，但我希望也尝试过估算表格数据的人可以分享一些经验。]]></description>
      <guid>https://stats.stackexchange.com/questions/659075/intuition-behind-generative-methods-for-imputing-missing-data</guid>
      <pubDate>Sun, 22 Dec 2024 01:27:59 GMT</pubDate>
    </item>
    <item>
      <title>生成模型 - 有效分布要求</title>
      <link>https://stats.stackexchange.com/questions/659069/generative-models-valid-distribution-requirement</link>
      <description><![CDATA[在 Bishop 的“深度学习”中，对生成模型的要求在我看来是错误的

（公式 14.49，第 452 页，在线网址为 https://www.bishopbook.com/ ）
我认为它应该只要求 p(x|w) 对 1/x 进行积分。书中是否有错误，或者我遗漏了什么？
我怀疑该方程的理由是：如果您考虑 [0, 2] 上的均匀分布 p(x)，即使 p(x|w) 与 p(x) 匹配，该方程也不成立。
（我已经在 Data Science StackExchange 上提问，其中一条评论建议尝试统计相关的社区）]]></description>
      <guid>https://stats.stackexchange.com/questions/659069/generative-models-valid-distribution-requirement</guid>
      <pubDate>Sat, 21 Dec 2024 23:14:38 GMT</pubDate>
    </item>
    <item>
      <title>利用 MSE 进行快速搜索</title>
      <link>https://stats.stackexchange.com/questions/659043/exploiting-mse-for-fast-search</link>
      <description><![CDATA[我有一个巨大的二进制向量数据库。给定一个传入向量，我想在数据库中找到 MSE 最接近的向量并返回 MSE 分数。到目前为止，我一直在手动进行此搜索，但花费的时间太长了。
我可以利用 MSE 与二进制向量一起使用时的特性来加快搜索速度吗？
更多详细信息：我正在寻找。我可以利用的 MSE 或二进制向量或数据稀疏性的属性来显着加快搜索速度！我的数据集有大约 400 万个高维（~4000）二进制向量，其中大部分是稀疏的（包含大量零）。我有一个循环，逐个遍历 400 万个向量并返回 MSE 分数最低的向量。我不能使用任何其他指标，并且在考虑是否可以利用 MSE 的任何属性来加快搜索速度。即使可以使用使用 MSE 的 ML 模型，它也会很完美]]></description>
      <guid>https://stats.stackexchange.com/questions/659043/exploiting-mse-for-fast-search</guid>
      <pubDate>Sat, 21 Dec 2024 01:58:16 GMT</pubDate>
    </item>
    <item>
      <title>分位数的贝叶斯区间估计</title>
      <link>https://stats.stackexchange.com/questions/658982/bayesian-interval-estimate-for-a-quantile</link>
      <description><![CDATA[这个问题是为了澄清后验分布和后验预测分布是否可用于创建分位数的区间估计。考虑以下设置：
假设我有 $X_i\stackrel{iid}{\sim} N(\mu, \sigma^2)$，其中 $i=1,...,n$。为了论证的目的，我并不关心先验的形式是什么，但让我们假设我在 $\mu$ 和 $\sigma^2$ 上都放置了先验。现在，我可以运行我的 MCMC 采样器并获取 $\mu$ 和 $\sigma^2$ 的后验样本（我们将它们称为 $\mu_{*b}$ 和 $\sigma^2_{*b}$，其中我有 $b=1,...,B$ 个）。现在，给定 $X_i$ 的分布，我可以通过以下方式获得后验样本，例如第 95 分位数：
$$q_b= \mu_{*b} + z_{0.95}\sigma_{*b}$$
其中 $z_{0.95}$ 是标准正态分布的第 95 分位数。此外，由于这是基于样本的，我有一个后验分位数的分布，并且可以取这些后验分位数样本的分位数来获得不确定性区间估计。到目前为止一切顺利。
现在，我很好奇是否有办法使用后验预测分布来做到这一点？例如，在相同的设置下，后验预测分布可能是 $y_{\text{new}}\sim N(\mu_{\text{new}}, \sigma^2_{\text{new}})$，因此我可以模拟该分布的 $y_{\text{new}}$ 值并取第 95 分位数来估计它。但是，这个估计没有像后验分布那样的不确定性量化。我想总结一下我的问题，

基于后验分布和后验预测分布的结果是否应该匹配，并且
后验预测分布是否应该为第 95 分位数产生不确定性估计（以区间的形式）？


编辑以澄清：
似乎人们没有理解我的问题的要点，但也许是我自己的错，可能不够清楚。让我用 R 代码来说明我的观点：
&gt; ### 用于生成第 95 分位数估计的代码 
&gt; ### 并附带 90% 可信区间
&gt; 
&gt; ### 为了举例说明，假设我已经完成了后验 
&gt; ### 计算，并且我有： 
&gt; 
&gt; ### p(sigma^2 | X) ~ Gamma(3, 2)
&gt; ### p(mu | sigma, X) ~ N(200, sigma)
&gt; 
&gt; 
&gt; # 后验样本数
&gt; B &lt;- 10000
&gt; 
&gt; # sigma^2* 和 mu^* 的后验样本
&gt; sigma2.star &lt;- rgamma(B, 3, 2)
&gt; mu.star &lt;- rnorm(B, 200, sqrt(sigma2.star))
&gt; 
&gt; # 第 95 分位数和 90% 可信区间的后验估计
&gt; q &lt;- mu.star + qnorm(0.95) * sigma2.star
&gt;平均值（q）
[1] 202.465
&gt; 
&gt; 分位数（q，probs = c（0.05, 0.95））
5% 95% 
200.0369 206.0277 
&gt; 
&gt; 
&gt; ### 使用后验预测分布
&gt; ynew &lt;- rnorm（B，mu.star，sqrt（sigma2.star））
&gt; 
&gt; q &lt;- 分位数（ynew，prob = 0.95）
&gt; q
95% 
202.7814 

但如您所见，使用后验预测，我仅得到 $q$ 的值的一个估计值，但没有可信区间，因为只有一个值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658982/bayesian-interval-estimate-for-a-quantile</guid>
      <pubDate>Thu, 19 Dec 2024 19:37:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 simr 了解功率曲线和非单调功率随样本量增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658923/understanding-power-curves-and-non-monotonic-power-increase-with-sample-size-usi</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658923/understanding-power-curves-and-non-monotonic-power-increase-with-sample-size-usi</guid>
      <pubDate>Wed, 18 Dec 2024 13:31:01 GMT</pubDate>
    </item>
    <item>
      <title>在此次治疗师依从性的测试中，作者是否适当地应用了重复测量单因素方差分析和 ROC 分析？</title>
      <link>https://stats.stackexchange.com/questions/658834/have-the-authors-appropriately-applied-repeated-measures-one-way-anova-and-roc-a</link>
      <description><![CDATA[我正在阅读一篇关于我所从事的心理治疗类型的研究。我的直觉是，这篇论文对统计数据的使用是有缺陷的，但我在意识形态上想要找出这篇特定研究的缺陷，而且我对统计数据的了解相当基础。出于这些原因，我不会链接到这篇论文。
这篇论文的所有作者都是接受过同一种治疗培训的心理治疗师。他们创建了一份问卷，供接受过该治疗培训的观察员使用，以评估治疗师在特定疗程中对该治疗的治疗程度。（即，这是一项依从性测试。）作者将这份问卷分发给了大约 200 名参与者（均接受过相关治疗培训），并附上了 4 个治疗疗程的视频；其中 2 个由接受过相关治疗培训的治疗师制作，另外 2 个由接受过其他治疗培训的治疗师制作。参与者对前两个视频的评分（每个约平均值 = 16.5，标准差 = 0.2）高于对后两个视频的评分（每个约平均值 = 4.5，标准差 = 0.25），这表明使用问卷可以清楚地区分受过相关疗法培训的人提供的疗法和受过其他疗法培训的人提供的疗法。
作者将上述平均值和标准差值作为“单向重复测量方差分析”的一部分呈现测试，他们说这显示出了统计学意义。
然后，他们进行了 ROC 分析，以确定将感兴趣的疗法与其他类型的疗法区分开来的阈值分数，并获得了 11 的值。
我有两个顾虑：
1：Statology 说，“重复测量单向方差分析用于确定三个或更多组的平均值之间是否存在统计学上的显着差异，其中每个组中都出现了相同的受试者。”我可以看到这里有 4 个组（4 个视频中的每个视频都有 1 组分数），但是，按照 Statology 的字面意思理解，这意味着观察者评分者是受试者，而不是他们正在评分的视频会话。如果研究的目的是找到一种方法来区分感兴趣的疗法和其他类型的疗法，那么我们实际上肯定有两组（2 个感兴趣的疗法样本和 2 个来自另一种疗法的样本）。如果我们只有 4 个样本，那么我认为统计显着性检验尚不合适。我愿意被告知我对此的想法是错误的，并欢迎任何评论。
2：维基百科说 ROC 分析是为了确定什么强度的信号应该被视为值得在雷达上显示的物体而开发的。我认为该任务必然是二进制的，以限制雷达操作员必须解析的信息量。我认为阈值不适用于确定某人是否遵守特定类型的治疗（特别是如果我们只有 4 个样本并且我们只评估了 2 种类型的治疗）。再次，我欢迎任何评论，包括对我的观点的任何更正。
我不知道是否已经发布了足够的有关该研究的信息。如果我应该提供更多详细信息，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/658834/have-the-authors-appropriately-applied-repeated-measures-one-way-anova-and-roc-a</guid>
      <pubDate>Mon, 16 Dec 2024 20:53:10 GMT</pubDate>
    </item>
    <item>
      <title>凸性和唯一或区间最优投资组合的存在性</title>
      <link>https://stats.stackexchange.com/questions/658099/convexity-and-existence-of-an-unique-or-interval-optimal-portfolio</link>
      <description><![CDATA[考虑一个包含两种资产的基本静态投资组合选择问题。投资者选择一个投资组合，即将其固定财富的正部分分配到两种金融资产中。金融资产是取值在 (a,b) 范围内的随机变量。
现在假设我将凸性定义如下：如果投资者偏好资产 1 而非资产 2，那么投资者偏好资产 1 和资产 2（这会产生另一项资产，我们将其命名为资产 3）的投资组合而非资产 2。由于资产 3 优于资产 2，因此资产 3 和资产 2 的投资组合也优于资产 2...
我的问题是，这种凸性假设是否意味着存在唯一或区间最优的投资组合。最优投资组合只是意味着存在一个优于任何其他投资组合的投资组合。我的直觉告诉我是这样，但我找不到任何参考资料。如果有人能详细解释这一点并提供一些参考资料，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658099/convexity-and-existence-of-an-unique-or-interval-optimal-portfolio</guid>
      <pubDate>Sun, 01 Dec 2024 20:18:21 GMT</pubDate>
    </item>
    <item>
      <title>在频率论的背景下，我们如何能够确定零假设为真/假？</title>
      <link>https://stats.stackexchange.com/questions/657840/in-a-frequentist-setting-how-are-we-able-to-condition-on-the-null-hypothesis-be</link>
      <description><![CDATA[引用 Casella 和 Berger (2002) 的话：假设检验由零假设 $H_0: \theta \in \Theta_0 $ 和备择假设 $H_1: \theta \in \Theta_0^c = \bar{H_0}$ 定义，其中 $\Theta$ 是总体参数 $\theta$ 的一组可能值，并且 $\Theta_0^c = \Theta - \Theta_0 $。
在频率论的设定中，$\theta$ 是一个未知但固定的量（也就是说，它是非随机的）。因此，对于给定集合$\Theta_0$，零假设$H_0$严格为真或假（但我们不知道是哪个）。备择假设，即否定，相应地为假或真。
让我们的检验统计量为$\hat{\theta} = f(X_1, ..., X_n)$。我们将拒绝域$RR \subset Range(\hat{\theta})$定义为我们选择拒绝$H_0$的检验统计量$\hat{\theta}$的值集。由于我们的样本 $X_1, ..., X_n$ 是随机的，$\hat{\theta}$ 是一个随机变量，因此数量 $p(\hat{\theta} \in RR)$ 是一个有效概率，类似于更简单的概率，如 $p(X \le 5)$
到目前为止一切顺利。然而，当我们开始定义 I 类错误时，我开始感到困惑。I 类错误是当我们拒绝 $H_0$ 即使它是 True 时。这在数学上定义为：
$$
\alpha = p(\hat{\theta} \in RR | H_0 \text{ is True}) = p(\hat{\theta} \in RR | \theta \in \Theta_0)
$$
这个概率对我来说毫无意义。$\theta$ 不是随机变量，因此 $\theta \in \Theta_0$ 不是概率事件，而是 True 或 False 值。概率框架（据我所知）不允许我们有意义地对实值或布尔值进行条件限制，而只能对事件进行条件限制。
这是怎么回事？我能做出的唯一有意义的解释是$\theta$是否是一个随机变量，这违反了频率统计的核心思想。]]></description>
      <guid>https://stats.stackexchange.com/questions/657840/in-a-frequentist-setting-how-are-we-able-to-condition-on-the-null-hypothesis-be</guid>
      <pubDate>Tue, 26 Nov 2024 01:27:13 GMT</pubDate>
    </item>
    <item>
      <title>使用看似不相关的回归检验两个不同回归的系数相等性</title>
      <link>https://stats.stackexchange.com/questions/657674/testing-equality-of-coefficients-from-two-different-regressions-with-seemingly-u</link>
      <description><![CDATA[我正在运行两个回归，一个嵌套在另一个中。
$$ y = \beta_1 X + \epsilon_1$$
$$ y = \beta_2 X + \beta_3 Z + \nu_2$$
我想评估两个方程式中 X 的系数是否相同 $$\hat\beta_{1} \neq \hat\beta_{2} ?$$
基本上，我想知道添加协变量 Z 是否会显著改变 y 和 X 之间的关联。
我尝试使用 R 执行此操作，如下所示：
# install.packages(&quot;systemfit&quot;)
library(systemfit)

# 指定两个方程式
eq2 &lt;- y ~ x + z
eq1 &lt;- y ~ x

# 将模型组合成一个系统
system &lt;- list(eq1 = eq1, eq2 = eq2)

# 拟合 SUR 模型
fit &lt;- systemfit(system, method = &quot;SUR&quot;, data=data_full2)

# 测试模型间 X 系数的相等性
linearHypothesis(fit, &quot;eq1_x = eq2_x&quot;)

但是，当我查看 eq2 的 fit 结果时，我发现与单独计算每个回归时的情况非常不同。（使用 lm(y ~ x + z, data=data_full2)）。我知道两种情况下的结果可能会有所不同，但差异非常大，因为在单独计算时，受限模型中的系数为 0.1，完整模型中的系数为 0.05，而在 SUR 计算中，两者均变为 0.1 左右。因此，当然，我的 linearHypothesis(fit, &quot;eq1_x = eq2_x&quot;) 命令的结果告诉我差异并不显著。
与两个独立的 lm() 相比，使用 systemfit() 命令运行系数时，系数变化如此之大，这正常吗？我是否仍应相信分析结果，即两个方程中的系数实际上并没有显著差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/657674/testing-equality-of-coefficients-from-two-different-regressions-with-seemingly-u</guid>
      <pubDate>Fri, 22 Nov 2024 10:43:59 GMT</pubDate>
    </item>
    <item>
      <title>对训练数据进行打乱是否会导致具有图像序列的时间序列模型中的信息泄露？</title>
      <link>https://stats.stackexchange.com/questions/657190/does-shuffling-the-training-data-cause-information-leakage-in-a-time-series-mode</link>
      <description><![CDATA[我正在研究一种基于以 10 分钟为间隔捕获的图像序列的太阳能发电预测模型。我的模型作为输入接收的单个示例由一系列图像组成。我的架构结合了 CNN 和 LSTM，CNN 处理图像序列以提取特征，然后将其传递给 LSTM 以利用图像序列中的时间信息。
我使用 10 分钟的预测间隔，图像分辨率为 10 分钟。因此，每幅图像（除了前几幅和最后几幅）将出现在多个序列中。输入批次的示例：

我想知道在训练期间打乱训练数据（即打乱图像序列的整体顺序，而不是序列内的图像）是否会导致信息泄露。我担心的是，在训练期间，模型可能在预测“当前”目标的同时已经看到了“未来”图像，这可能会破坏数据的时间结构。我没有在输入中提供任何明确的时间戳或先前的目标值，只是提供图像序列。
通过改组，我希望获得更好的梯度更新和更好的批量标准化。
编辑：
下面的图显示了训练（MSE）损失。上图表示没有改组的结果，而下图包括改组。每个图包括四次独立运行，以解释由于初始化而导致的变化。

根据验证损失应用了耐心为 2 个时期的早期停止，导致运行长度不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/657190/does-shuffling-the-training-data-cause-information-leakage-in-a-time-series-mode</guid>
      <pubDate>Wed, 13 Nov 2024 09:43:07 GMT</pubDate>
    </item>
    </channel>
</rss>