<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 17 Oct 2024 12:32:46 GMT</lastBuildDate>
    <item>
      <title>使用时间序列数据预测复杂客户群的销售量</title>
      <link>https://stats.stackexchange.com/questions/655898/predicting-sales-volume-for-complex-customer-base-with-time-series-data</link>
      <description><![CDATA[我正在研究一个时间序列问题，希望得到社区的建议。我的目标是预测未来 2-4-6 周内每个客户、每个产品系列的订购销售量。数据按客户、产品组和一年中的周进行汇总。
这是我目前采取的方法：

我扩展了数据，根据每个客户的首次和最后一次购买日期为他们创建了一个完整的时间序列。这导致许多周的销售额为 0，我认为这是有用的，因为在这种情况下，没有订单是有价值的信息。
我正在与一个由 2500 多名客户组成的复杂客户群合作。有些客户经常订购（例如每天），有些客户每隔几天订购一次，还有一些季节性客户一年只购买几周。
当我汇总所有客户的数据时，时间序列看起来是平稳的（基于 ACF 和 PACF 图）。但是，当我分析单个客户时，会发现存在稳定和非稳定模式的混合。
我实施了 XGBoost 模型，并获得了 0.9 的 R² 分数，但我怀疑这些数字被夸大了，因为在销售额为 0 的几周内有很多小预测。我现在正在试验一个两步模型：首先对是否会发生销售进行分类，然后预测这些积极实例的销售量。

考虑到客户群的多变性和复杂性，我不确定最佳的建模方法。考虑到客户数量庞大，为每个客户训练单独的模型是不可行的。
我的问题：

我应该如何最好地处理稳定和非稳定客户的混合模式？有没有办法在单个模型中平衡这一点？
有没有最佳实践来处理时间序列预测中的 0 销售周，而不会像 R² 那样夸大性能指标？
2 步分类回归模型听起来像是解决这个问题的好方法吗？或者另一种方法是否更适合如此多样化的客户群？

任何建议或意见都将不胜感激！提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/655898/predicting-sales-volume-for-complex-customer-base-with-time-series-data</guid>
      <pubDate>Thu, 17 Oct 2024 11:58:10 GMT</pubDate>
    </item>
    <item>
      <title>汇总每个展示信号的点击次数</title>
      <link>https://stats.stackexchange.com/questions/655897/aggregating-clicks-per-impression-signal</link>
      <description><![CDATA[我正在训练一个模型，根据跨会话计算的用户点击和展示信号，预测网站事件发生的概率。
当用户与网站互动时，他们的会话会聚合到训练数据行中。例​​如，如果用户 Foo 在 3 个会话中访问网站，我们将获得：

第 1 个会话的 1 行训练数据
第 1 个和第 2 个会话的 1 行训练数据
第 1 个和第 2 个会话的 1 行训练数据3

对于点击次数/展示次数（其中展示次数以秒为单位），分子和分母在会话之间相加，但分母较小会使我的信号非常嘈杂。
例如，如果在 1 个会话中，展示次数仅为 10 秒，则 1 次点击将转换为 6 的比率，这个比率非常高。
我尝试过的一些改进包括：

删除只有 1 个会话的训练行：这种方法很有效，因为大多数嘈杂信号来自 1 个会话的行；但是，许多用户只有 1 个会话，因此这会丢弃很大一部分训练集。

对分母取整：例如分子/最大值（分母，5）；这
使得比率信号在较低水平上的信息量较少；例如，比率信号 0.2 现在可能意味着 1/1、1/2、1/3、1/4 或 1/5。

直接剪切比率：例如 min(2.0, 分子/分母)；
这使得一些真正具有信息量的比率信号信息量较少；例如，min(2.0, 20/10) = 2.0 是一个具有信息量的信号，但这相当于 min(2.0, 4/1) = 2.0，一个不具有信息量的信号。


请注意，没有足够的数据来为问题提供更多特征。例如，我不能只是将所有分子和分母放入模型中，并希望它自己找出相互作用。我想知道是否有更好或更具创新性的方法来处理这个问题。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655897/aggregating-clicks-per-impression-signal</guid>
      <pubDate>Thu, 17 Oct 2024 11:47:59 GMT</pubDate>
    </item>
    <item>
      <title>处理 CFA 中的两项因素</title>
      <link>https://stats.stackexchange.com/questions/655896/dealing-with-two-item-factors-in-cfa</link>
      <description><![CDATA[我正在为 lavaan (R) 中的 CFA 设置一个潜在变量模型，计划在后续的 SEM 分析中使用测量模型。该模型包括五个相关因子，每个因子有 3-4 个指标项。
只有三个指标的因子中的一个项不会对潜在因子产生显著的负载，而且由于理论上没有理由将其加载到另一个因子上，所以我删除了它。结果，一个因子现在只有两个项，导致 R 中的识别问题。一个可能的解决方案是将两个项的因子载荷限制为相等。
我的问题是：a) 设置相等的因子载荷对解释 CFA 有何影响？b) 我可以在 SEM 分析中谨慎使用此模型吗，还是应该考虑完全放弃该因子？
我很感激任何建议！
此致，
Pilea]]></description>
      <guid>https://stats.stackexchange.com/questions/655896/dealing-with-two-item-factors-in-cfa</guid>
      <pubDate>Thu, 17 Oct 2024 10:50:48 GMT</pubDate>
    </item>
    <item>
      <title>混合模型的结果 - 较低水平还是较高水平？</title>
      <link>https://stats.stackexchange.com/questions/655894/outcome-in-mixed-models-lower-level-or-upper-level</link>
      <description><![CDATA[我正在学习混合模型，我对可以考虑的结果有一个疑问。如果我有分层数据，我可以考虑的结果是否需要属于较低级别？我想知道在考虑上层结果时是否需要汇总数据。
如果我有来自不同城市的几个人的测量值，结果是否需要与患者相关？例如预期寿命。
如果我有关于不同患者不同细胞的某些测量数据，我可以应用混合模型来评估测量值与患者结果之间的关系吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655894/outcome-in-mixed-models-lower-level-or-upper-level</guid>
      <pubDate>Thu, 17 Oct 2024 10:33:11 GMT</pubDate>
    </item>
    <item>
      <title>专家值，E [ln（X）] [关闭]</title>
      <link>https://stats.stackexchange.com/questions/655893/experted-value-elnx</link>
      <description><![CDATA[我想求参数为λ的泊松分布的E[Ln(X)]。是E[ln∣Z∣]=−γ−lnλ吗？为什么？或者给我一个参考文献（文章或书籍）来解决一个众所周知的短语。
（我到处搜索，但没有找到任何相关信息。）
γ是欧伊拉常数0.577]]></description>
      <guid>https://stats.stackexchange.com/questions/655893/experted-value-elnx</guid>
      <pubDate>Thu, 17 Oct 2024 10:14:02 GMT</pubDate>
    </item>
    <item>
      <title>库克在物流方面的距离</title>
      <link>https://stats.stackexchange.com/questions/655892/cooks-distance-in-logistic</link>
      <description><![CDATA[我对哪个 Cook 距离公式是正确的感到困惑，特别是在逻辑回归的背景下，因为我发现了两个不同的表达式。
第一个公式是：$$CD_i=\frac{rp_i^2 h_{ii}}{(k+1)(1-h_{ii})^2},$$其中 $k$ 是参数数量，$rp_i$ 是 Pearson 残差，$h_{ii}$ 是第 $i$ 个观测值的杠杆率。
第二个公式是：$$D_i = \frac{rp_i^2}{k \cdot \text{MSE}} \cdot \frac{h_{ii}}{(1 - h_{ii})^2}$$
这两个公式之间有什么关系？它们等价吗？在逻辑回归的背景下，我应该如何解释它们之间的差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/655892/cooks-distance-in-logistic</guid>
      <pubDate>Thu, 17 Oct 2024 10:04:22 GMT</pubDate>
    </item>
    <item>
      <title>Hmisc::describe 的信息度量</title>
      <link>https://stats.stackexchange.com/questions/655891/the-info-measure-of-hmiscdescribe</link>
      <description><![CDATA[Hmisc::describe 文档（PDF 的第 77 页）中写道：

对于数值变量，describe 添加了一个名为 Info 的项目，这是一个相对信息度量，使用比例几率/Wilcoxon 检验对变量的相对效率，相对于对没有关系的变量的相同检验。Info 与变量的连续性有关，不相干的值越多，关系的危害就越小。Info 的公式是 1 减去相对频率立方和，再除以 1 减去样本大小倒数的平方。最低信息来自只有一个不同值的变量，后面跟着一个高度倾斜的二进制变量。信息报告精确到小数点后两位。

我的问题是：

对于具有无限值的连续变量，这些“相对频率”是如何定义的？
为什么以这种方式而不是其他方式定义？采用此定义有什么好处？
我在哪里可以找到此变量的书目参考？
能否举一个信息量低的变量和信息量高的变量的例子？
我如何“实际”地解释这个措施？为什么我需要它？

我想我没有完全理解这个措施，我需要一种更“实用的方法”使用它。
相关问题：
帮助解释 R 中 Hmisc 包的 describe 函数的输出
R 中 hmisc 的 describe 函数]]></description>
      <guid>https://stats.stackexchange.com/questions/655891/the-info-measure-of-hmiscdescribe</guid>
      <pubDate>Thu, 17 Oct 2024 09:36:47 GMT</pubDate>
    </item>
    <item>
      <title>证明任何多元正态变量都是通过对相同维度的标准正态变量应用线性映射而获得的</title>
      <link>https://stats.stackexchange.com/questions/655890/show-that-any-multivariate-normal-variable-is-obtained-by-applying-a-linear-mapp</link>
      <description><![CDATA[我知道定理的证明：将线性（可逆）函数应用于正态变量的效果仍然是正态的。但是，我不知道如何证明我们可以从标准正态分布的线性映射中得出任何正态分布。你能告诉我以什么形式证明这一点吗？我决定找到一个矩阵 A 和向量 b
用于在标准正态分布上创建线性变换，然后尝试展示如何选择 A 和 b 来创建具有任何均值和方差矩阵的任何正态分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/655890/show-that-any-multivariate-normal-variable-is-obtained-by-applying-a-linear-mapp</guid>
      <pubDate>Thu, 17 Oct 2024 09:35:27 GMT</pubDate>
    </item>
    <item>
      <title>评分者间信度/一致性（100 位评分者，1 项）</title>
      <link>https://stats.stackexchange.com/questions/655888/inter-rater-reliability-agreement-100-raters-1-item</link>
      <description><![CDATA[我对可靠性/一致性有疑问。
100 名评估员（教师）根据 5 项标准（介绍、眼神接触等）评估 1 名学生的演讲。每位评估员对每项标准进行评分。每项标准均按 5 分制评分。
我现在想分别计算每项标准的评估员间可靠性。换句话说，例如，教师对眼神接触标准的评估在多大程度上达成一致。
由于我只想分析 1 项的可靠性，我认为许多常见的可靠性方法并不适用（Krippendorf 的 alpha、ICC）。
所以我的问题是如何计算这种一致性/可靠性？非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655888/inter-rater-reliability-agreement-100-raters-1-item</guid>
      <pubDate>Thu, 17 Oct 2024 09:10:43 GMT</pubDate>
    </item>
    <item>
      <title>如果单个数据集可作为零假设，为什么不能使用 t 检验？[重复]</title>
      <link>https://stats.stackexchange.com/questions/655887/why-can-a-t-test-not-be-used-if-a-single-data-set-is-available-as-a-null-hypothe</link>
      <description><![CDATA[我有一个数据集，我想比较其中是否有变化。但是，我的零假设仅基于一个数据点。但为什么我不能将这个数据点识别为平均值，以便我可以使用它来确定 t 检验？]]></description>
      <guid>https://stats.stackexchange.com/questions/655887/why-can-a-t-test-not-be-used-if-a-single-data-set-is-available-as-a-null-hypothe</guid>
      <pubDate>Thu, 17 Oct 2024 09:05:35 GMT</pubDate>
    </item>
    <item>
      <title>查找具有十进制自由度的 p 值</title>
      <link>https://stats.stackexchange.com/questions/655884/finding-p-value-with-decimal-degree-of-freedom</link>
      <description><![CDATA[我正在学习 Welch 的 t 检验，我成功地发现，在双样本检验中，$t=2.968$，自由度为 $5.1$。然后我使用在线 p 值计算器计算 0.05 显著性水平下的 p 值。结果如下。

问题是我不明白数字 $0.030478$ 是如何生成的。我尝试查看双尾 t 分布表，但我不知道如何从表中插入 p 值。

有人能解释一下为什么 $0.030478$ 是这里的 p 值吗？是否只使用 t 分布表和计算器就可以得到这个数字？我想学习如何在没有在线计算器帮助的情况下得到这个数字。提前谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655884/finding-p-value-with-decimal-degree-of-freedom</guid>
      <pubDate>Thu, 17 Oct 2024 06:24:44 GMT</pubDate>
    </item>
    <item>
      <title>如何用语言表达 t 检验结果</title>
      <link>https://stats.stackexchange.com/questions/655858/how-to-verbalise-t-test-results</link>
      <description><![CDATA[我正在阅读统计数据，昨天我问了问题为什么两个不同的 t 检验会得出不同的结果。
statmerkur 给出了以下答案

没有矛盾。双侧 $t$ 检验的拒绝域由以下公式给出：
$$
\left(-\infty, t_{0.05 /2}(1.6778)\right] \cup \left[-t_{0.05 /2}(1.6778), \infty\right) \approx \left(-\infty, -5.2\right] \cup \left[5.2, \infty\right),
$$
其中 $t_{0.05 /2}(1.6778)$ 是学生 $0.05 / 2 = 0.025$ 分位数class=&quot;math-container&quot;&gt;$t$ 分布，自由度为 $1.6778$。

但我不懂数学背景。我想利用这些（“解码”）知识将其转移到其他 t 检验，从而解释其他数据（我在问题中没有提出）。]]></description>
      <guid>https://stats.stackexchange.com/questions/655858/how-to-verbalise-t-test-results</guid>
      <pubDate>Wed, 16 Oct 2024 13:20:37 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归的 Frisch-Waugh-Lovell 定理</title>
      <link>https://stats.stackexchange.com/questions/655855/frisch-waugh-lovell-theorem-for-poisson-regression</link>
      <description><![CDATA[我有一个泊松模型，具有以下真实关系：
$$E(y \mid x, z)=exp(bx+cz)$$
是否可以在这里应用 Frisch-Waugh-Lovell 定理的某些非线性版本？
（请注意，之前的帖子试图提出同样的问题，但问题的文本包含错误 - 例如 1) 没有正确指定条件平均值和 2) 可能过于具体地说明了 FWL 的非线性版本是什么样子 - 并且没有收到任何相关回复。）]]></description>
      <guid>https://stats.stackexchange.com/questions/655855/frisch-waugh-lovell-theorem-for-poisson-regression</guid>
      <pubDate>Wed, 16 Oct 2024 11:07:49 GMT</pubDate>
    </item>
    <item>
      <title>ODE 系统场景的问题[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655848/problem-with-ode-system-scenario</link>
      <description><![CDATA[我有一个用于传播 HIV 病毒的 ODE 系统：
$$dx1dt = a1 * x1 * (p1 - x1) + a2 * x2 * (p1 - x1) + e * (p1 - x1) - r1 * x1
$$
$$dx2dt = a3 * x1 * (p2 - x2) + a4 * x2 * (p2 - x2) + a5 * y * (p2 - x2) + e * (p2 - x2) - r2 * x2$$
$$
dydt = c1 * x2 * (q - y) + c2 * z * (q - y) + e * (q - y) - r3 * y
$$
$$ dzdt = d1 * y * (r - z) + e * (r - z) - r4 * z$$
对于所有大于 1 的项，但 $p=0.1$ 且 $p1=10,p2=10$ 且 $q=r=50$

我们同时对双性恋女性和男性（p1 和 p2）以及异性恋男性和女性（q 和 r）进行操作。
首先，我们有一个没有移除/死亡减法（每个方程中没有负项）的模型。
因此，随着时间的推移，我们必须得出接受检查的人数都将是 HIV 阳性。
但是在还加入了移除/死亡减法之后，我的模型看起来仍然与之前的图相同，并且图表在任何时候都没有减少。
我同时使用了 $\tt Python$ 中的 odeint 包 和 数值方法 ( Euler )，并得到了相同的图（我尝试将设置从 https://github.com/vastevenson/vs-coupled-differential-eqns-python/blob/main/app.py 重写到这里 ode 系统）。
但是，由于在减去移除/死亡时，图上没有出现减少，这可能是什么问题呢？$\left(-kx_{1},-kx_{2}\right) ?$.
]]></description>
      <guid>https://stats.stackexchange.com/questions/655848/problem-with-ode-system-scenario</guid>
      <pubDate>Wed, 16 Oct 2024 08:53:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么经验贝叶斯估计量没有像预期的那样占据主导地位？</title>
      <link>https://stats.stackexchange.com/questions/655839/why-is-the-empirical-bayes-estimator-not-dominating-like-its-supposed-to</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655839/why-is-the-empirical-bayes-estimator-not-dominating-like-its-supposed-to</guid>
      <pubDate>Wed, 16 Oct 2024 03:58:04 GMT</pubDate>
    </item>
    </channel>
</rss>