<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 26 Jun 2024 09:17:41 GMT</lastBuildDate>
    <item>
      <title>估计噪声样本的总体相对标准偏差</title>
      <link>https://stats.stackexchange.com/questions/649929/estimate-population-relative-standard-deviation-from-noisy-sample</link>
      <description><![CDATA[我们想通过测量一个小样本来估计在总体上定义的随机变量$X$的相对标准差（标准差除以平均值）。
问题是测量方法相当嘈杂。通常，测量误差似乎可以建模为$\Delta x = kx + b + \varepsilon$，其中$x$是真实值，$\Delta x$是测量值减去真实值，$\varepsilon$是近似正态分布的随机数。
平均而言，$\Delta x$似乎接近于零，但由于系数$k$略为负值，仅取测量样本的相对标准偏差通常会导致对总体相对标准偏差的轻微低估，即使存在噪声项$\varepsilon$。
问题：是否有一种方法可以无偏地估计总体相对标准偏差；也就是说，有一种方法可以补偿 $k$、$b$ 和 $\varepsilon$，这些可以通过校准测量方法获得。此外，获得估计值的置信区间（或分布）之类的东西也很有趣。该方法可以是数值方法，也可以基于某种引导程序。
在应用中，总体相对标准偏差通常在 10%-50% 范围内，$\varepsilon$ 的标准偏差通常是 $x$ 平均值的 10%。]]></description>
      <guid>https://stats.stackexchange.com/questions/649929/estimate-population-relative-standard-deviation-from-noisy-sample</guid>
      <pubDate>Wed, 26 Jun 2024 08:57:17 GMT</pubDate>
    </item>
    <item>
      <title>两个随机变量乘积的 Hoeffding 不等式</title>
      <link>https://stats.stackexchange.com/questions/649927/hoeffding-inequality-for-a-product-of-two-random-variables</link>
      <description><![CDATA[设 $X_1,X_2, \dots, X_{m_1}$，$Y_1,Y_2, \dots, Y_{m_2}$ 为来自概率空间 $\mathcal{X}$ 的 $m_1 + m_2$ 个独立随机变量，设 $h: \mathcal{X} \to \{-1,1\}$
我对点估计感兴趣：$\mu = \underset{x,y \sim \mathcal{D}}{\mathbb{E}}[h(x)h(y)]$。
估计的形式为 $\hat{\mu} = \frac{1}{m_1m_2} \sum_{i=1}^{m_1} \sum_{j=1}^{m_2} h(X_i) h(Y_j)$
是否存在广义的 Hoeffding 不等式来测量此（双样本 U 统计量）设置的集中度？]]></description>
      <guid>https://stats.stackexchange.com/questions/649927/hoeffding-inequality-for-a-product-of-two-random-variables</guid>
      <pubDate>Wed, 26 Jun 2024 08:37:32 GMT</pubDate>
    </item>
    <item>
      <title>倾向得分匹配后的回归</title>
      <link>https://stats.stackexchange.com/questions/649925/regression-after-propensity-score-matching</link>
      <description><![CDATA[
在我的分析中，我试图通过匹配在治疗组和对照组中实现平衡后，观察治疗Z如何影响结果Y。
我有以下框架和问题，以及我对这些主题的理解。
有人能帮我验证我的设置和代码是否正确吗？
非常感谢任何建议或论文推荐！

在匹配样本的结果模型➁中添加psscore是否更好？

如果匹配后未达到平衡，或者为了双重稳健性。 (逻辑回归模型中的倾向得分)


我应该在结果模型➁中添加X还是仅包含Z？

如果匹配后达到平衡，则不需要X。


在进行结果模型➁时我应该添加权重吗？

如果匹配是通过替换或使用比率或完全匹配完成的。 （Bai, H.，&amp; Clark, M. (2019). 倾向评分方法和应用。SAGE Publications, Inc.，https://doi.org/10.4135/9781071814253）



在 R 中，我使用以下代码执行匹配和回归。
match1 &lt;- ma​​tchit(Z ~ 家庭特征 + 建筑信息 + …, method=&quot;nearest&quot;, ratio=4, distance=&quot;logit&quot;, caliper=0.1, data=currentDataset)
matched_data1 &lt;- match.data(match1)
公式 &lt;- c(&quot;Y1 ~ Z&quot;, &quot;Y2 ~ Z&quot;, &quot;Y3 ~ Z&quot;, &quot;Y4 ~ Z&quot;)
模型类型 &lt;- c(&quot;glm&quot;, &quot;glm&quot;, &quot;lm&quot;, &quot;lm&quot;)
for (i in 1:length(formulas)) {
公式 &lt;- formulas[I]
模型类型 &lt;- model_types[i]
if (model_type == &quot;glm&quot;) {
模型 &lt;- glm(as.formula(formula), data = matches_data1, family = binomial)}
else {
模型 &lt;- lm(as.formula(formula), data =匹配的数据1)
]]></description>
      <guid>https://stats.stackexchange.com/questions/649925/regression-after-propensity-score-matching</guid>
      <pubDate>Wed, 26 Jun 2024 08:20:29 GMT</pubDate>
    </item>
    <item>
      <title>因果变量和噪声变量的因果独立性</title>
      <link>https://stats.stackexchange.com/questions/649924/causal-variables-and-causal-independence-of-the-noise-variables</link>
      <description><![CDATA[在因果关系中，我的理解是，如果我们有因果变量$S_i$，我们必须假设与每个$S_i$相关的（外生？）噪声变量在因果上是独立的。我的理解是，这类似于统计推断的误差独立性假设。但是，在某些物理实验之外——尤其是如果我们处理的是任何类型的系统，而这几乎总是如此（再次强调，在前面提到的物理实验之外）——噪声变量之间难道不会一直存在某种/程度的因果纠缠吗？那么我们如何才能切实地进行因果推断呢？再说一次，同样的推理不也适用于统计推断中误差之间的相关性吗？然而，我们通常在进行统计推断时没有什么问题（即使排除实验者没有正确考虑误差独立性的不良（滥用）统计数据案例）？我只是想在这里澄清我的理解/想法。这是否只是一个例子，“是的，实际上，在几乎所有现实世界的实验中（除了上述物理实验），误差/噪声变量都是相关的/因果纠缠的，但这是一个程度问题，因此，我们越多地考虑/最小化这种相关性/因果纠缠，我们的统计/因果推断就越准确，因此这只是统计/因果关系哲学的一个自然组成部分，即无法证伪某事，而不是“证明它是真的”。&quot;？
另外：如果我们不确定某些变量是否具有因果独立的噪声变量，是否有某种方法可以测试/检查这一点？毕竟，我们有统计推断的方法来测试/检查误差项之间的相关性，对吧？]]></description>
      <guid>https://stats.stackexchange.com/questions/649924/causal-variables-and-causal-independence-of-the-noise-variables</guid>
      <pubDate>Wed, 26 Jun 2024 07:58:38 GMT</pubDate>
    </item>
    <item>
      <title>比例风险假设检验中的垂直线</title>
      <link>https://stats.stackexchange.com/questions/649923/vertical-lines-in-proportional-hazard-assumption-test</link>
      <description><![CDATA[我进行了 Anderson-Gill 生存分析。在检查比例风险假设是否满足时，我得到了以下图表：

我研究结束时的 Beta 肯定是错误的。我做错了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/649923/vertical-lines-in-proportional-hazard-assumption-test</guid>
      <pubDate>Wed, 26 Jun 2024 07:04:07 GMT</pubDate>
    </item>
    <item>
      <title>在 LCA 中选择类别数</title>
      <link>https://stats.stackexchange.com/questions/649921/choosing-number-of-classes-in-lca</link>
      <description><![CDATA[我是一名本科生，对拟合优度检验有点困惑。我正在尝试使用 R 中的 poLCA 包为潜在类别分析选择适当的类别数。我的数据有 89 个观察到的二元变量，我正在比较拟合优度统计数据以确定正确的类别数。
AIC 和 BIC 值随着类别数的增加而下降，但它们在第 4 个类别之后趋于稳定，对数似然值在第 4 个类别之后也趋于稳定。话虽如此，BIC 和 AIC 值即使在 10 个类别之后也会继续下降，尽管幅度很小。
我认为 4 个类别合适是错误的吗？还是我应该做完全不同的事情？
我也喜欢任何阅读材料，总是希望学习。谢谢。
&gt; aic_值
[1] 509311.8 456245.0 436084.9 426650.1 422403.6 417608.8 413242.8 411011.4 408163.3 406278.5 404276.3
&gt; bic_值
[1] 510443.8 457946.6 438356.2 429491.0 425814.1 421588.9 417792.5 416130.7 413852.2 412537.0 411104.5
&gt; log_lik
[1] -254498.9 -227886.5 -217727.5 -212931.0 -210728.8 -208252.4 -205990.4 -204795.7 -203292.6 -202271.2 -201191.2



]]></description>
      <guid>https://stats.stackexchange.com/questions/649921/choosing-number-of-classes-in-lca</guid>
      <pubDate>Wed, 26 Jun 2024 05:21:32 GMT</pubDate>
    </item>
    <item>
      <title>使用 JAGS 对分数 Caputo 模型进行参数估计〜Jags 模型中的错误 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649919/using-jags-for-parameter-estimation-for-a-fractional-caputo-model-error-in-jag</link>
      <description><![CDATA[我正在研究贝叶斯估计，目的是使用 Caputo 导数找到分数模型的后验分布。
但是，当我编译拟合模型时，我收到以下错误，并且我无法识别它。
&gt; fit.caputo&lt;-jags(data=caputo.data, inits = caputo.inits1, parameters.to.save= caputo.params,
+ n.chains =2, n.iter = 10000, n.burnin=1000,model.file=&quot;caputo.jags&quot;)
module glm 已加载
编译模型图
解析未声明的变量
删除模型

jags.model(model.file, data = data, inits = init.values, n.chains = n.chains, 中出现错误： 
运行时错误：
第 10 行编译错误。
数组 W 的维度不一致

代码如下：
cat(&quot;
model{
# unlikely
for(t in 1:N1)
{
y1[t] ~ dnorm(V[t], tau)
y2[t] ~ dnorm(W[t], tau)
for(k in 1:t){
V[t+1, k]= V[1]+ ((h^q)/(exp(loggam(q+1)))) * sum ( ((t-k+1)^(q)-(t-k)^(q))* (r1*V[k]*(1-V[k]/k1) -a*V[k]*W[k]) )
W[t+1, k]= W[1]+ ((h^q)/(exp(loggam(q+1)))) * sum ( ((t-k+1)^(q)-(t-k)^(q))* (a*V[k]*W[k]-r2*W[k]) )
}
}
V[1]&lt;-v0
W[1]&lt;-w0
#tamaño de paso
h=0.01
#distribucuiones iniciales
a ~ dnorm(0.06,10000)T(0,1)
k1 ~ dnorm(50,1)
r1 ~ dnorm(1.8,1000)T(0,) 
r2 ~ dnorm(0.24,1000)T(0,)
q ~ dunif(0.9,1)
sigma2 &lt;- 1/tau
tau ~ dgamma(1,1) # media =1 y var=10
}&quot;, file=&quot;caputo.jags&quot;, fill=T)

之前，我从系统的数值解生成了一个合成数据集（对于为此目的使用分数前向欧拉方法）。
我考虑在 JAGS 中添加一个数值向量来存储 s1, s2, s3 的信息。
但是，我认为您不能将此函数 s1&lt;-s2&lt;-matrix(0,N1,N1) 嵌入 JAGS 模型中，因为 JAGS 有自己的 BUGS 语言解释器，它完全独立于 R 解释器。
提前感谢您的建议]]></description>
      <guid>https://stats.stackexchange.com/questions/649919/using-jags-for-parameter-estimation-for-a-fractional-caputo-model-error-in-jag</guid>
      <pubDate>Wed, 26 Jun 2024 04:02:58 GMT</pubDate>
    </item>
    <item>
      <title>寻找 ANCOVA 类型 glmm 中变量重要性的修改</title>
      <link>https://stats.stackexchange.com/questions/649917/looking-for-a-modification-of-variable-importance-in-ancova-type-glmm</link>
      <description><![CDATA[这个问题是关于一个我认为应该存在的统计概念。我想知道它是否有名字，并希望有一个可以实现它的 R 包。它与变量重要性/主导性有关，但我感兴趣的不是考虑包含变量的模型的整体改进，而是它如何影响模型中关键固定因素的估计（精度和偏差）。我可以用一个例子更好地解释。
我感兴趣的是估计昆虫数量随时间的变化。数据是光诱捕器中个体的数量，光诱捕器每周运行一次，持续两年，然后在 30 年后重复运行。以一个物种为例，使用仅包含主效应“时间”的模型，我发现没有显着差异。时间效应的估计值为 0.035（考虑到对数链接，这是 3.6% 的增长），但估计值的标准差是这个的 10 倍。
捕获量的大部分变化是由于该物种的季节性和每周采样。在模型中添加二次方周分量可以得到更好的模型，ΔAIC 为 -159，时间估计值现在为 0.25（增加了 28%），但标准误（0.26）与估计值大致相等，因此仍然不足以声称该物种数量有所增加。
另一个改进模型的变量是气温（影响昆虫飞行活动），其 ΔAIC 为 -18。但现在，随时间变化的估计值为 -0.76（减少 50%），标准误为 0.25。这种巨大变化的原因是过去 30 年来平均气温上升——昆虫活动的增加掩盖了数量减少。如果包括温度而不是季节性，则 ΔAIC 为 -125，因此按分步程序，季节性比温度更受青睐，但温度对时间效应的估计影响最大。如果这是一个设计好的实验（并且空气温度在时间上保持平衡），则不会出现此特定案例的某些方面，但这是一个现实世界的问题，我无法控制气候。
另一个复杂因素是残差中存在时间自相关性，因此使用 glmmTMB，我为自相关性引入了一个随机效应（Ornstein-Uhlenbeck，因为有一些缺失的星期，并且自相关性为正）。该模型将如下所示：
model&lt;-glmmTMB (spX ~ Time + week + I(week^2) + airT+ou(seq + 0 | group), data=datx, family=nbinom2)

估计的自相关性为 0.61，ΔAIC 为 -18。时间效应现在为 -0.96（减少了 62%），但 s.e。已增加到 0.46，因此效果较大但“不太显著”。显然，模型的这三个组成部分（季节性、温度和自相关）都很重要（原因略有不同），但还有其他潜在的协变量（例如月亮、云、风、雨）会影响光诱捕器捕获的昆虫，其中一些会随着时间而平衡（例如气压），但有些可能表现得更像空气温度，排除它们会在估计中留下偏差。
是否有一个框架可以评估所有这些变量在获得时间效应的精确和无偏估计方面的相对效用？我如何证明和量化我对其他昆虫学家的建议：“你真的应该测量这个协变量”。]]></description>
      <guid>https://stats.stackexchange.com/questions/649917/looking-for-a-modification-of-variable-importance-in-ancova-type-glmm</guid>
      <pubDate>Wed, 26 Jun 2024 02:56:04 GMT</pubDate>
    </item>
    <item>
      <title>似然比检验对于有限样本是否“最佳”？</title>
      <link>https://stats.stackexchange.com/questions/649916/is-the-likelihood-ratio-test-best-for-finite-samples</link>
      <description><![CDATA[维基百科说

Neyman–Pearson 引理指出，对于这种情况，这种似然比 (lr) 检验是所有 α 级 alpha 检验中最强大的。

这只适用于无限样本量吗？在某些情况下，对于有限样本，是否有可能存在对给定 alpha 级更强大的测试？如果是这样，哪种检验会比似然比检验更好，在什么情况下更好？
我知道对于有限样本问题，似然比统计量的分布在很大程度上是未知的，但如果它很重要，为了回答这个问题，我愿意假设我们总是知道给定问题的 lr 统计量的真实分布。
我的问题的另一部分是，什么是非 lr 检验？感觉一切实际上都是 lr 检验（例如 t 检验、f 统计量、参数引导等）。我想在某些情况下，最小二乘法（和矩量法）一定不等同于 lr，因此对于有限样本，是否存在最小二乘法实际上可以胜过 lr 的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/649916/is-the-likelihood-ratio-test-best-for-finite-samples</guid>
      <pubDate>Wed, 26 Jun 2024 02:36:57 GMT</pubDate>
    </item>
    <item>
      <title>在不同的数据集上同时优化两个函数</title>
      <link>https://stats.stackexchange.com/questions/649913/simultaneously-optimizing-two-functions-on-different-datasets</link>
      <description><![CDATA[我有两个共享参数的函数，每个函数都需要针对不同的数据进行优化。我的问题是：我是否可以简单地将两个函数的残差平方和 (RSS) 添加到我的目标函数中并运行优化？
例如，rss1 是将函数 f1 的结果与数据 d1 进行比较时的值，rss2 是将 f2 与数据 d2 进行比较时的值。我如何在 R 的 optim 函数中使用这两个 rss？这是简单的求和，还是另有隐情？
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/649913/simultaneously-optimizing-two-functions-on-different-datasets</guid>
      <pubDate>Wed, 26 Jun 2024 00:12:19 GMT</pubDate>
    </item>
    <item>
      <title>Fisher 信息中的评分函数的导数</title>
      <link>https://stats.stackexchange.com/questions/649907/derivative-of-the-score-function-in-fisher-information</link>
      <description><![CDATA[我正在研究 Fisher 信息，并试图形成一种直观的理解。请记住，我只有学士学位数学背景，所以我希望得到一个更直观的解释而不是数学推导的答案。
我理解我们使用 Fisher 信息来让我们对 MLE 有某种“信心”。但是，我在数学上感到困惑，我们如何才能在 MLE 处获得除零之外的任何 Fisher 信息。由于 FI 等于得分函数一阶导数平方的期望值（wrt X），因此在等于 MLE 的 theta 处的导数就是 0。而 0 的平方等于 0。那么，如何才能让 FI 在 MLE 处有意义呢？这是否与我们对随机变量 X 的所有值求导数的平均值有关，因此在某些情况下斜率可能不为零？
任何见解都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/649907/derivative-of-the-score-function-in-fisher-information</guid>
      <pubDate>Tue, 25 Jun 2024 22:15:55 GMT</pubDate>
    </item>
    <item>
      <title>根据数据来决定使用参数检验还是非参数检验不是很有问题吗？</title>
      <link>https://stats.stackexchange.com/questions/649886/isnt-it-problematic-to-look-at-the-data-to-decide-to-use-a-parametric-vs-non-p</link>
      <description><![CDATA[我见过一些人提到，使用参数方法还是非参数方法可以通过查看数据来决定。例如这个问题：非参数与参数
这难道不是分叉路径问题的一个例子吗？
具体来说，查看数据来决定测试是否会影响类型 1 和类型 2 错误？那么S 型和 M 型错误呢？
如果这是一个问题，有什么理由可以证明这样查看数据是合理的，因为这似乎是一种常见的做法？除了不查看数据来决定测试之外，还有其他方法可以解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649886/isnt-it-problematic-to-look-at-the-data-to-decide-to-use-a-parametric-vs-non-p</guid>
      <pubDate>Tue, 25 Jun 2024 15:55:18 GMT</pubDate>
    </item>
    <item>
      <title>与三元变量进行 3 次比较</title>
      <link>https://stats.stackexchange.com/questions/649689/making-3-comparisons-with-a-ternary-variable</link>
      <description><![CDATA[我有一项研究，其中我想研究三元变量 $x$ 与二元变量 $y$ 交互的影响。三元变量是分类变量，出于某些原因，我想在 $3$ 组之间进行 $3$ 比较。
我明白要进行一次比较，我必须进行两次对比。例如，如果我对 group1 与 group3 感兴趣，我定义 $C_1= (-1,0,1)$ 和 $C_2=(-1,2,-1)$。如果我想测试所有的比较，那么我应该做$6$个对比吗？在这种情况下，回归量不会共线吗？有没有更简单的方法可以做到这一点？
谢谢你的帮助！

谢谢你的回答！你的代码运行得很好，但我不确定如何得到我需要的答案。事实上，当我使用我的三元变量的引用（1作为引用，2和3作为另外2个值）并运行一个简单的glm模型时，我得到了这样的输出：
## y 9.782e-03 1.418e-04 69.008 &lt; 2e-16 *** 
## x2 8.677e-05 9.265e-04 0.094 0.92539 
## x3 -3.617e-03 9.229e-04 -3.919 8.96e-05 ***
## y:x2 -5.481e-04 2.935e-04 -1.868 0.06184 . 
## y:x3 9.430e-04 2.941e-04 3.206 0.00135 **

在这里，您可以看到，对于前两个比较，您可以访问关于 x 与变量 y 交互作用的 p 值。我想得到第三个交互项。
当我使用 emmeans 进行多重比较时，我得到了类似这样的结果（它包含的行数比这个还多）：
## (y0 x1) - y1 x2 -0.060 0.0189 159## -3.183 0.0186
## (y0 x1) - (y0 x2) -0.006 0.0277 159## -0.216 0.9999
## (y0 x1) - y1 x2 -0.046 0.0277 159## -1.658 0.5601
## (y0 x1) - (y0 x3) 0.207 0.0277 159## 7.472 &lt;.0001

由于我可以访问所有比较，因此我无法简单地分析变量 x 和 y 之间的相互作用。我希望获得与第一个块相同的输出，但是通过三个比较，有没有办法获得它？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649689/making-3-comparisons-with-a-ternary-variable</guid>
      <pubDate>Fri, 21 Jun 2024 20:51:47 GMT</pubDate>
    </item>
    <item>
      <title>最佳解决方案未重复 - metaMDS 没有可靠的结果？</title>
      <link>https://stats.stackexchange.com/questions/649643/best-solution-was-not-repeated-no-reliable-result-for-metamds</link>
      <description><![CDATA[我拥有丰富的蜘蛛数据，这些数据是我在不同林地中捕获的，我想执行 NMDS。它通常有效，尽管压力值相对较高。但是，我收到消息说最佳解决方案无法重复。

```Spiders_NMDS &lt;- metaMDS(nmds_data[,7:54], k = 2, distance = &quot;horn&quot;, trymax= 100, maxit=1000 )

以下是输出的最后几行：
Run 100 stress 0.2085273
... Procrustes: rmse 0.008630914 max resid 0.05303693
*** 最佳解决方案未重复 -- monoMDS 停止标准：
100：压力比 &gt; sratmax

以及 print(Spiders_NMDS) 的输出
metaMDS(comm = nmds_data[, 7:54], distance = &quot;horn&quot;, k = 2, trymax = 100, maxit = 1000)

使用 monoMDS 进行全局多维缩放

数据：wisconsin(nmds_data[, 7:54])
距离：horn

维度：2
压力：0.208454
压力类型 1，弱关系
最佳解决方案在 100 次尝试后未重复
最佳解决方案来自第 75 次尝试（随机开始）
缩放：居中、PC 旋转、半变化缩放
物种：基于‘wisconsin(nmds_data[, 7:54])


我在另一个论坛上看到，依赖这些数据并将其用于进一步分析在统计上并不有效。是这样吗？毕竟，官方 R 网站表示您仍然可以使用这些数据，但上述论坛的担忧肯定不是毫无根据的……请参阅：https://stackoverflow.com/questions/741 ... -nmds-in-r
不幸的是，R 针对这个问题给出的建议对我没有帮助。参见：https://rdrr.io/cran/vegan/man/metaMDS.html（“结果无法重复”部分）
例如，我已经增加了 maxit 和 trymax，但仍然输出该消息。我还用 previous.best 运行了另一次迭代
metaMDS(nmds_data[,7:54], k = 2, distance = &quot;horn&quot;,trymax= 100, maxit= 100, previous.best = Spiders_NMDS)
但是，这也不会改变输出。
增加维度也不会带来任何变化，例如，在可视化方面没有用，对吗？
有人有这个问题的经验吗？有没有办法获得更可靠的结果？
我想继续使用 envfit 函数....
我的数据集通常包含许多零，并且可能有许多陷阱彼此之间的距离非常大（不共享任何物种）...也许这很重要？
感谢您的反馈 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/649643/best-solution-was-not-repeated-no-reliable-result-for-metamds</guid>
      <pubDate>Fri, 21 Jun 2024 07:44:57 GMT</pubDate>
    </item>
    <item>
      <title>对 $k$ 个最近邻中的维度（特征）进行加权（重新缩放）</title>
      <link>https://stats.stackexchange.com/questions/649038/weighting-rescaling-the-dimensions-features-in-k-nearest-neighbors</link>
      <description><![CDATA[当使用 $k$ 个最近邻时，必须对数据集进行归一化（如果 X 是数据矩阵，其中每行代表一个特征或维度，每列代表一个样本点，那么从每个 $X_{ij}$ 中减去每行 $i$ 的平均值，然后将每个 $X_{ij}$ 除以行 $i$ 的标准差是一个不错的选择）
在以下问题中：
https://datascience.stackexchange.com/questions/6786/weighted-k-nearest-neighbor-search
以下内容第二个答案中提到：
如果你想要将一个维度的权重高于其他维度，那么我建议你对所有数据进行标准化，使平均值为零，标准差为一。然后，你可以将不太重要的维度乘以一个因子（2-10），这样它们看起来离 KNN 距离度量更远，而最重要的维度则不缩放
我的问题是关于这部分：
然后，你可以将不太重要的维度乘以一个因子（2-10），这样它们看起来离 KNN 距离度量更远，而最重要的维度则不缩放
事实不是相反吗？
将一个维度乘以 (2-10) 中的一个因子，难道不会使其比其他维度更重要吗？
例如，如果我们考虑以下简单情况：当输入属于 $\mathbb{R}^2$ 时，函数 $F(x,y)$。让我们制作两个点 A 和 B，其坐标如下
A(1,0)
B(0,1)
让我们通过第一个最近邻预测坐标为 (0,0) 的点 C 的值。
最初，点 A 和 B 与 C 的距离相同
点 A(1,0) 和 C(0,0) 具有相同的 y 值 0
点 B(0,1) 和 C(0,0) 具有相同的 x 值 0
现在将维度 x 乘以 2 将得到以下点
A(2,0)
B(0,1)
C(0,0)
并且将使点 B 比 A 更靠近 C，因此 C 的值将被选择为 B 的值。请注意，B 和 C 具有相同的 x 值，而 A 和 C 具有相同的 y 值，并且 C 的选择值将是共享相同 x 值的 B 的值，因此将维度 x 乘以 2 使得 x 值在确定最近邻居时比 y 值更重要，因此它使该维度更重要。
而如果我们将 y 维度乘以 2，点 A 的值（与 C 共享更接近的 y 值）将被选择为 C 的值。
换句话说，标准化后将维度 x 乘以一个大于 1 的数字将使具有更接近此维度 x 值的点对于 k 个最近邻居来说彼此更接近，这将使该维度更重要。例如：
A(4,1)
B(1,5)
C(2,2)
dist(A,C)=√5
dist(C,B)=√10
A更接近C，A的y值也更接近C，而不是B接近C
现在将x维度乘以3
我们得到
A(12,1)
B(3,5)
C(6,2)
dist(A,C)=6.082
dist(C,B)=4.242
B现在变得更接近C，在相乘之前，B的x值最初也更接近C
这是是真的吗？或者我没有得到任何东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/649038/weighting-rescaling-the-dimensions-features-in-k-nearest-neighbors</guid>
      <pubDate>Tue, 11 Jun 2024 13:52:29 GMT</pubDate>
    </item>
    </channel>
</rss>