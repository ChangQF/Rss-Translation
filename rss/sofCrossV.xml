<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 16 Jul 2024 06:22:10 GMT</lastBuildDate>
    <item>
      <title>REML 可能性问题——logdet 项取消</title>
      <link>https://stats.stackexchange.com/questions/651125/issue-with-reml-likelihood-logdet-terms-cancel</link>
      <description><![CDATA[我正在尝试使用 REML 编写线性混合效应模型的实现。
我正在使用一个简单的模型：
$$ y_{ij} = X_{ij}\beta + Z_{ij}b_i + \epsilon_{ij} $$
在我的例子中，协变量 $X$ 是一个标量，所有组的大小相同，并且 $X=Z$。因此，我们可以假设 $X_{ij} = X_j = Z_{ij}$。假设$\epsilon_{ij}\stackrel{iid}{\sim}N(0,\sigma^2)$，其中$\sigma^2$已知，且$b_i\sim N(0,\gamma)$。因此，这给了我们负对数似然（最多为常数）
\begin{equation}
L(\gamma,\beta)=\sum_{i=1}^m\log\det(\sigma^2 I+\gamma XX^T) + \sum_{i=1}^m\log\det\left(X^T(\sigma^2 I+\gamma XX^T)^{-1}X)\right) + \\
+\sum_{i=1}^m (y_i - X\beta)^T(\sigma^2 I+\gamma XX^T)^{-1}(y_i - X\beta)
\end{equation&gt;
但是，前两个项取消后剩下一个常数，因此唯一剩下的非常量项成为第三个，它在 $\gamma = \infty$.这可以在以下计算中看到：
\begin{equation}
\det\left(I+\gamma XX^{T}\right)=1+\gamma\|X\|^{2} \\
\det\left(X^{T}\left(I+\gamma XX^{T}\right)^{-1}X\right) \\
=\det\left(X^{T}\left(\frac{X}{1+\gamma\|X\|^{2}}\right)\right)
\end{equation&gt;
对于第二项，应用 Sherman Morrison，
\begin{equation}
\left(I+\alpha XX^{T}\right)^{-1}=I-\frac{\alpha XX^{T}}{1+\alpha\|X\|^{2}} \\
\end{equation&gt;
将 $X^T$ 与 $X$ 相乘，并得出
\begin{equation}
X^{T}\left(I+\gamma XX^{T}\right)^{-1}X=\|X\|^{2}-\frac{\gamma\|X\|^{4}}{1+\gamma\|X\|^{2}}=\|X\|^{2}\left(1-\frac{\gamma\|X\|^{2}}{1+\gamma\|X\|^{2}}\right) \\
\end{equation&gt;
\begin{equation}
=\|X\|^{2}\left(\frac{1+\gamma\|X\|^{2}-\gamma\|X\|^{2}}{1+\gamma\|X\|^{2}}\right)=\|X\|^{2}\left(\frac{1}{1+\gamma\|X\|^{2}}\right)
\end{equation&gt;
取对数后，发现 $\gamma$ 中的非常量项相互抵消。
我不知道如何在我的代码中解决这个问题——我最初遇到这个问题是因为我对 $\gamma$ 的估计趋于无穷大。但是，当我在 python statsmodels 混合效果中运行精确模型时，我得到了非常合理的结果，所以似乎我遗漏了有关 REML 目标的某些内容。]]></description>
      <guid>https://stats.stackexchange.com/questions/651125/issue-with-reml-likelihood-logdet-terms-cancel</guid>
      <pubDate>Tue, 16 Jul 2024 06:00:36 GMT</pubDate>
    </item>
    <item>
      <title>多个样本的最小值或最大值的中值是多少？</title>
      <link>https://stats.stackexchange.com/questions/651122/what-is-the-median-of-the-minimum-or-maximum-of-multiple-samples</link>
      <description><![CDATA[假设我有一个已知分布的变量，假设我对该变量进行 k 次采样并记录最小值。如果我重复多次，最小值的中位数是否会收敛到一个可预测的值？如果会，这个值是多少？
我的直觉告诉我，中位数将收敛到累积概率为 1/(k+1) 的值，但我无法证实这一点。
请注意，我找到了一个关于正态分布样本的最大值预期值的讨论：正态分布样本的最大值预期值。但是，该讨论没有提到中位数，我认为中位数应该更简单。]]></description>
      <guid>https://stats.stackexchange.com/questions/651122/what-is-the-median-of-the-minimum-or-maximum-of-multiple-samples</guid>
      <pubDate>Tue, 16 Jul 2024 01:41:39 GMT</pubDate>
    </item>
    <item>
      <title>AUC 还可以，但对数损失很糟糕 [重复]</title>
      <link>https://stats.stackexchange.com/questions/651120/getting-ok-auc-but-awful-logloss</link>
      <description><![CDATA[我有一个二元分类问题，目前正尝试使用 xgboost 解决。这是一个处理时间序列的低信噪比情况。我的样本外 AUC 为 0.65，这还算可以（比随机猜测的结果好，后者会给出 0.5）。但是，我的对数损失非常高，大约为 0.68。看看这个答案二元分类器的“愚蠢”对数损失，考虑到我有 20% 的正样本，我预计对数损失会低于
0.2*log(0.2) + 0.8*np.log(0.8) = 0.5

但是，我的对数损失看起来相当糟糕，但同时，AUC 看起来还可以。 F1 也还好，大约为 0.35（以 20% 的概率猜测 1 的随机分类器将实现 F1=0.2）。
我主要困惑于我如何得到如此高的对数损失，是我做错了什么，还是我误解了什么？
注意：我上面使用和报告的 AUC 来自 sklearn.metrics.roc_auc_score，其他所有指标也一样。]]></description>
      <guid>https://stats.stackexchange.com/questions/651120/getting-ok-auc-but-awful-logloss</guid>
      <pubDate>Tue, 16 Jul 2024 00:54:34 GMT</pubDate>
    </item>
    <item>
      <title>如何将两个变量与滞后关联起来</title>
      <link>https://stats.stackexchange.com/questions/651118/how-to-correlate-two-variables-together-with-lag</link>
      <description><![CDATA[我很想知道事件频率与连续变量之间的相关性度量（我知道这个问题类似于这个）。
在这种情况下，我绘制了某一天的体重（以公斤为单位，实值）与吃某种食物的频率的关系图，并按日汇总。在这两种情况下，图中都使用了移动平均值，k=15（即 15 天窗口）并使用复制填充。复制 是指重复两端的边缘值来处理输入的边缘，而不是零填充或有效填充。右下角的图是各种食物类型的汇总。
尽管这种方法存在问题（复制填充的偏差、平滑将未来的数据泄漏到当前值中），但我很想知道如何将体重与不同的变量关联起来，看看哪些因素会产生更大的影响，哪些因素不会。我并不坚持这种方法，我只是认为它会很好地绘制出来。
我尝试使用 Pearson 相关系数来回答这个问题，但不明白为什么有些图的 p 值为 0。这对我来说似乎很奇怪。我也不知道如何解释滞后问题。
任何关于此的建议或资源/概念都非常感激 - 并且很乐意根据需要披露任何数据或代码！
]]></description>
      <guid>https://stats.stackexchange.com/questions/651118/how-to-correlate-two-variables-together-with-lag</guid>
      <pubDate>Mon, 15 Jul 2024 23:49:35 GMT</pubDate>
    </item>
    <item>
      <title>方差分析发现主效应可防止 I 类错误率膨胀</title>
      <link>https://stats.stackexchange.com/questions/651116/anova-finding-a-main-effect-prevents-inflation-of-type-i-error-rate</link>
      <description><![CDATA[在（免费）书籍理解统计学和实验设计第 6.3 节中，他们说

&#39;...ANOVA 提供了第二个技巧。如果我们拒绝了零假设，则适合将均值对与所谓的“事后检验”进行比较，这大致相当于计算成对比较。与第 1 章讨论的
多重测试情况相反。 5，这些多重比较不会夸大 I 型错误率，因为它们仅在方差分析发现主效应时进行。&#39;

为什么方差分析发现主效应可以防止 I 型错误率膨胀？
至少另一本书似乎暗示，在进行事后检验时，确实需要纠正 I 型错误率的膨胀。下面的 JASP 截图似乎也表明需要进行修正。
]]></description>
      <guid>https://stats.stackexchange.com/questions/651116/anova-finding-a-main-effect-prevents-inflation-of-type-i-error-rate</guid>
      <pubDate>Mon, 15 Jul 2024 22:50:53 GMT</pubDate>
    </item>
    <item>
      <title>生成高度非独立的随机样本</title>
      <link>https://stats.stackexchange.com/questions/651114/generating-highly-non-independent-random-samples</link>
      <description><![CDATA[我正在测试非独立数据下的统计测试性能，我想生成随机数据，其中我知道底层的统计分布。
最简单的方法是生成相关数据，例如像这样：
a &lt;- rnorm(10000)
b &lt;- -a + rnorm(10000, 0, 0.00001)

在此示例中，a 和 b 具有非常强的负相关性，但使用配对 t 检验进行测试时，它仍将显示零假设成立（执行多个测试时，p 值的分布是均匀的）。
问题是，当我使用常规 t 检验对独立样本测试此类相关数据时，在 alpha=0.05 时，我得到的假阳性率仅为 16.6%。
有没有办法生成更多非独立数据，使得配对 t 检验（或非参数检验，如符号检验或 Wilcoxon 符号秩检验）不会显示过多的假阳性率，但非配对 t 检验会显示假阳性率非常高？
理想情况下，我希望能够生成数据，对于几千个测量值的样本，非配对 t 检验或 Kolmogorov-Smirnov 检验通常会提供小于 1e-6 的 p 值，但使用成对检验进行测试时，p 值仍然分布均匀。]]></description>
      <guid>https://stats.stackexchange.com/questions/651114/generating-highly-non-independent-random-samples</guid>
      <pubDate>Mon, 15 Jul 2024 22:27:20 GMT</pubDate>
    </item>
    <item>
      <title>根据分类数据对编码器语言模型的嵌入空间进行归一化</title>
      <link>https://stats.stackexchange.com/questions/651113/normalizing-the-embedding-space-of-an-encoder-language-model-with-respect-to-cat</link>
      <description><![CDATA[假设我们有一个类别树/层次结构（例如电子商务网站中的产品类别），每个节点都被分配一个标题。假设每个节点的标题在语义上都是准确的，这意味着它与它所代表的类别（子节点的标题）一致。现在，采用编码器语言模型（如 BERT 或 Word2Vec）并为每个节点/类别生成嵌入。我的目标是确保这些嵌入代表分类层次结构。我想知道：

嵌入（大部分）是否应该与分类层次结构一致，即使分类层次结构非常小众和/或不均匀（意味着分类粒度不一定均匀分布，如果这有意义的话）？一致的意思是，一个父节点下的兄弟节点的嵌入应该比其他父节点的子节点更接近彼此，并且比其他父节点的嵌入更接近其父节点的嵌入。有没有一个很好的指标来衡量/验证这一点？
如果没有，有什么好的方法可以重新映射潜在空间，使其相对于分类层次结构“更漂亮”？我在想 1) 我们直接转换潜在空间或 2) 微调语言编码器模型（即 BERT）。例如：1) 假设类别/父类的子类别/子类形成的形状是一个细椭圆形，是否有可能并且有意义地将空间映射为使这个细椭圆形变成圆形？同样，对于 2)，在正确的父嵌入下对叶嵌入进行分类的任务中，对 BERT 进行微调会做同样的事情吗？

我认为这要求类别不要太小众，并且要与常规语言用法有一定的对应关系（在提供上下文之后甚至更多），这就是我的情况。
这只是我的直觉，所以请让我知道你的想法。我有兴趣探索从最简单的启发式方法到可能与这个问题相关的 SOTA NLP 技术的任何内容。]]></description>
      <guid>https://stats.stackexchange.com/questions/651113/normalizing-the-embedding-space-of-an-encoder-language-model-with-respect-to-cat</guid>
      <pubDate>Mon, 15 Jul 2024 22:21:09 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯估计量何时可以作为充分统计数据的函数注入？</title>
      <link>https://stats.stackexchange.com/questions/651112/when-are-bayes-estimators-injective-as-a-function-of-sufficient-statistics</link>
      <description><![CDATA[我知道贝叶斯估计量只能写成充分统计数据的函数。这些函数什么时候是可注入的？也就是说，什么时候我可以说，给定一个贝叶斯估计量$\delta (\cdot)$和两个充分统计数据$t \neq t&#39;$，我们将得到$\delta(t) \neq \delta(t&#39;)$？
使用二次损失（贝叶斯估计量只是后验分布的平均值）和共轭先验，我发现情况似乎确实如此。具体来说，贝叶斯估计量似乎始终是充分统计数据的仿射函数（请参阅此 Wikipedia 文章中的示例）。这是一个更通用的模式/定理吗？它成立的条件是什么？有没有不成立的反例？]]></description>
      <guid>https://stats.stackexchange.com/questions/651112/when-are-bayes-estimators-injective-as-a-function-of-sufficient-statistics</guid>
      <pubDate>Mon, 15 Jul 2024 22:11:48 GMT</pubDate>
    </item>
    <item>
      <title>残差平方和倒数的期望</title>
      <link>https://stats.stackexchange.com/questions/651110/expectation-of-reciprocal-residual-sum-of-squares</link>
      <description><![CDATA[考虑一个 IID 数据集 $X_1 , \cdots, X_n \in \mathbb{R}^d$，那么我们可以对残差倒数的期望说些什么呢？也就是说我们可以计算
$$
E \Big [ \frac{1}{||r_i||^2} \Big ] = E \Big [ \frac{1}{X_i^T (I - P_i^\perp) X_i} \Big ] .
$$
这是通过考虑精度矩阵的对角线分量得出的。我怀疑期望是无限的，但我无法证明这一点。我还假设 $X_i^TX_i = 1$ 以使问题更简单。
一个可能更简单的问题是考虑
$$
E \Big [ \sum_{j \not = i} \frac{r_i \cdot r_j}{||r_i||^2 ||r_j||^2} \Big ] = E \Big [\sum_{j \not = i} \frac{(X_i - P_iX_i)(X_j - P_jX_j)}{||X_i - P_iX_i||^2||X_j - P_jX_j||^2} \Big ] 
$$
因为我怀疑非对角线项要多得多表现更好，总体平均值为 0。
我尝试应用塔属性，因为 $P_i^\perp$ 取决于 $X_i^c:= \{ X_1, \cdots, X_n \} \backslash \{X_i\}$
$$E[ \frac{1}{1 - X_i^TP_iX_i}] = E[ E[ \frac{1}{1 - X_i^TP_iX_i}|X_i^c]] = E[ E[ \frac{1}{1 - tr (P_iX_iX_i^T)}|X_i^c]],
$$
但感兴趣的项在分母中继续阻碍任何计算期望的标准方法。我认为我可能把事情复杂化了，所以任何关于这个计算的想法都会非常感谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/651110/expectation-of-reciprocal-residual-sum-of-squares</guid>
      <pubDate>Mon, 15 Jul 2024 21:37:32 GMT</pubDate>
    </item>
    <item>
      <title>lmer-如何报告结果和群体差异？</title>
      <link>https://stats.stackexchange.com/questions/651105/lmer-how-to-report-results-and-group-differences</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651105/lmer-how-to-report-results-and-group-differences</guid>
      <pubDate>Mon, 15 Jul 2024 21:25:16 GMT</pubDate>
    </item>
    <item>
      <title>差异对数水平回归的弹性</title>
      <link>https://stats.stackexchange.com/questions/651090/elasticity-from-differenced-log-level-regression</link>
      <description><![CDATA[我有回归
$ \Delta \ln Y_i = \alpha + \beta \Delta X_i + \varepsilon_i $
其中 $\Delta \ln Y_i = \ln Y_{t,i} - \ln Y_{t-1,i}$ 和 $\Delta X_i = ((X_{t,i} - X_{t-1,i}) / T_{t-1,i} ) \cdot 100$。T 是总人口，X 是子集，i 是地区。
假设 $\beta$ 为 -0.073。我对半弹性的解释是，X 相对于基线 T 增加 1 个百分点会导致 Y 减少 7.3%。（这是正确的吗？）
问题：我如何才能消除弹性？也许可以将 $\beta$ 除以 $\Delta X_i$ 的平均值？]]></description>
      <guid>https://stats.stackexchange.com/questions/651090/elasticity-from-differenced-log-level-regression</guid>
      <pubDate>Mon, 15 Jul 2024 17:54:26 GMT</pubDate>
    </item>
    <item>
      <title>非对称分布在均值周围两侧的 PDF 下的面积是否可以相同？</title>
      <link>https://stats.stackexchange.com/questions/651022/can-a-non-symmetrical-distribution-have-the-same-areas-under-the-pdf-in-the-two</link>
      <description><![CDATA[我正在思考对称与非对称分布，我发现自己陷入了一个我从未想过的想法。我们知道，正态分布、拉普拉斯分布等对称分布在均值附近的曲线下面积相同（在对称情况下，均值等于中位数）。
但是，如果非对称分布（例如 GEV https://w.wiki/AfKx）尾部下的面积等于主瓣面积，那么非对称分布是否也可以具有此属性？
这种分布的参数可以通过分析找到吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651022/can-a-non-symmetrical-distribution-have-the-same-areas-under-the-pdf-in-the-two</guid>
      <pubDate>Sun, 14 Jul 2024 14:25:37 GMT</pubDate>
    </item>
    <item>
      <title>评估贝叶斯回归模型后验的黄金标准是什么？</title>
      <link>https://stats.stackexchange.com/questions/650988/what-is-the-gold-standard-for-evaluating-the-posterior-of-a-bayesian-regression</link>
      <description><![CDATA[让我解释一下我的意思和背景：

我的意思是评估后验的正确性（例如对于近似贝叶斯推理方法）。
我最关心的是贝叶斯深度学习，我想要一种可以扩展到非常高维度的方法&amp;参数计数。。
有许多方法可用于分类（例如 Brier 评分），但我要求一些可与回归相媲美的方法。

一个有前途的想法是后验预测检查，但老实说，鉴于大多数贝叶斯模型输出样本而不是显式 pdf，我不确定如何以实用的方式实现它……
有什么想法吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650988/what-is-the-gold-standard-for-evaluating-the-posterior-of-a-bayesian-regression</guid>
      <pubDate>Sat, 13 Jul 2024 19:51:03 GMT</pubDate>
    </item>
    <item>
      <title>如何根据 ML 模型的预测生成 95% 的预测区间？</title>
      <link>https://stats.stackexchange.com/questions/650980/how-to-generate-95-prediction-interval-around-predictions-from-ml-model</link>
      <description><![CDATA[我有来自 ML 模型的预测，并且想要围绕模型生成的每个预测生成 95% 的预测区间，这样我就可以声称这些是每个观察值可能期望的合理值范围。
我看到一些资源表明它应该是：
Yhat +- 1.96 * std(residuals)
我看到另一个资源表明它应该是 yhat，而不是范围的残差：
Yhat +- 1.96 * std(yhat)
我还看到另一个资源表明它应该是标准误差而不是标准偏差
Yhat +- 1.96 * se(Yhat)
我还看到其他资源表明您需要使用设置为 .05 的分位数参数来拟合 Sklearn 模型以生成上限和下限，这表明我需要训练再次检查模型，这是您在训练期间要做的事情。
总的来说，我现在有点困惑，不确定在预测周围生成预测区间的最佳或最合适方法，以反映每个预测周围的合理值范围。有人有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650980/how-to-generate-95-prediction-interval-around-predictions-from-ml-model</guid>
      <pubDate>Sat, 13 Jul 2024 17:34:31 GMT</pubDate>
    </item>
    <item>
      <title>多类分类的假阴性与假阳性</title>
      <link>https://stats.stackexchange.com/questions/650978/false-negative-vs-false-positive-for-multiclass-classification</link>
      <description><![CDATA[假设我有三个类别 1、2、3。
并且有如下评估，其中第二个元素是错误预测，其中模型预测类别 3，而基本事实是 2。
y_true = [1,2,3]
y_pred = [1,3,3]

我正在制作可视化工具，其中

如果模型预测为类别 1 而基本事实不是类别 1，则为红色
如果模型预测为类别 2 而基本事实不是类别 2，则为绿色
如果模型预测为类别 3 而基本事实不是类别 3，则为蓝色
真实预测无颜色

第二个元素的错误类型是什么？假阳性还是假阴性？
从我上面的案例来看，第二个元素将是蓝色。]]></description>
      <guid>https://stats.stackexchange.com/questions/650978/false-negative-vs-false-positive-for-multiclass-classification</guid>
      <pubDate>Sat, 13 Jul 2024 16:44:51 GMT</pubDate>
    </item>
    </channel>
</rss>