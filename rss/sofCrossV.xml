<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 16 Dec 2024 12:36:40 GMT</lastBuildDate>
    <item>
      <title>套索和交叉验证：模型选择</title>
      <link>https://stats.stackexchange.com/questions/658807/lasso-and-cross-validation-model-selection</link>
      <description><![CDATA[对交叉发布表示歉意
我开始使用 Lasso 和交叉验证进行模型选择，以使用线性模型解释因变量，但我不明白为什么所选模型中的所有 p 值系数都不低于 0.05：
我使用以下步骤将此示例发布在：
https://www.stata.com/features/overv...on-prediction/
代码：

sysuse auto, clear
splitsample, generate(sample) nsplit(2) rseed(1234)

lasso linear mpg i.foreign i.rep78 headroom weight turn gear_ratio price trunk length Displacement if sample == 1, Selection(bic)
estimates store bic

lasso linear mpg i.foreign i.rep78 净空重量转动齿轮比价格后备箱长度位移如果样本 == 1
估计存储 cv

lasso linear mpg i.foreign i.rep78 净空重量转动齿轮比价格后备箱长度位移如果样本 == 1，选择（自适应）
估计存储自适应

lassocoef cv bic 自适应，排序（系数，标准化）

-------------------------------------------------------------
| cv bic 自适应
-------------+--------------------------------
重量 | x x 
5.rep78 | x x x 
长度 | x x x 
齿轮比 | x x 
价格 | x x 
_cons | x x x 
----------------------------------------------
图例：
b - 基准水平
e - 空单元格
o - 省略
x - 估计

lassogof cv bic 自适应，过（样本）后选择

后选择系数
-------------------------------------------------------------------------
名称样本 | MSE R 平方 Obs
------------------------+------------------------------------
cv |
1 | 10.92984 0.7046 35
2 | 10.77016 0.6496 34
------------------------+------------------------------------
bic |
1 | 11.82234 0.6805 35
2 | 11.0608 0.6401 34
------------------------+------------------------------------
自适应 |
1 | 10.98369 0.7032 35
2 | 10.56047 0.6564 34
--------------------------------------------------------------

*adaptive 在样本 2 中具有较低的 MSE 和较高的 R^2

*我选择 Adaptive 作为最佳模型：

. reg mpg length 5.rep78 gear_ratio price

来源 | SS df MS 观测数 = 69
-------------+---------------------------------- F(4, 64) = 38.57
模型 | 1654.03213 4 413.508033 Prob &gt; F = 0.0000
残差 | 686.170766 64 10.7214182 R 平方 = 0.7068
-------------+----------------------------------- Adj R 平方 = 0.6885
总计 | 2340.2029 68 34.4147485 根 MSE = 3.2744

--------------------------------------------------------------------------------------------
mpg | 系数标准误差 t P&gt;|t| [95% 置信区间]
-------------+----------------------------------------------------------------
长度 | -.1484211 .0270004 -5.50 0.000 -.2023607 -.0944816
5.rep78 | 3.380391 1.163954 2.90 0.005 1.055125 5.705657
gear_ratio | 1.558014 1.251733 1.24 0.218 -.9426098 4.058637
价格 | -.0002964 .0001545 -1.92 0.060 -.0006049 .0000122
_缺点 | 45.84562 7.960131 5.76 0.000 29.94343 61.74781
--------------------------------------------------------------------------------------------

这里选择了 gear_ratio，但其 p 值为 0.218，太高了，无法解释 mpg？
在使用 Lasso 和交叉验证进行模型选择时，我错过了一些步骤或概念？
我现在知道 Lasso 不使用 p 值来选择模型，但我应该在最终模型中删除 gear_ratio？
任何评论我都会感激不尽
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658807/lasso-and-cross-validation-model-selection</guid>
      <pubDate>Mon, 16 Dec 2024 11:55:26 GMT</pubDate>
    </item>
    <item>
      <title>针对种族数据/群体数据的最自然的机器学习模型类</title>
      <link>https://stats.stackexchange.com/questions/658803/most-natural-class-of-machine-learning-models-for-race-data-group-data</link>
      <description><![CDATA[我有一个学生考试成绩的数据集，如下所示：
班级 ID 班级规模 学生编号 智商 小时数 分数
1 3 3 101 10 98
1 3 4 99 19 80
1 3 6 130 3 95
2 5 4 93 5 50
2 5 5 103 9 88
2 5 8 112 12 99
2 5 1 200 10 100
2 5 2 90 19 78
3 2 5 100 12 84
3 2 7 102 13 88

我想建立一个机器学习模型，尝试预测谁将成为班级第一名（即最高分数）给定 Class_ID，使用 IQ 和 Hours（学习小时数）作为特征。
换句话说，输入是班级中每个学生（例如 1 到 n）的 IQ 和 Hours，输出是概率向量 (p_1, ..., p_n)，其中每个 p_i 是学生 i 在班级中获得最高分数的概率。
这是我尝试过的：

由于这是一个排名问题，因此自然的一类学习模型是使用 XGBoost 中的 XGBRanker 或 lightgbm 中的 LGBMRanker。不幸的是，输出是 相关性得分 列表，而不是概率列表，概率列表在概率方面没有自然解释。

解决这个问题的一种方法是在 xgboost 中对相关性得分应用 softmax，但没有直接有意义的概率解释，如基于能量的模型，如 RBM 的能量函数。事实上，我试过这样做，概率变得非常极端（大多数概率质量集中在每个班级的一名学生身上，导致测试结果不佳且方差较大）

另一类学习模型是分类模型，如逻辑回归/决策树。然而，我遇到的问题是每个班级的学生人数不同，因此要训练这样的模型，我们必须首先“扁平化”特征矩阵：

Class_ID Class_size IQ_1 IQ_2 IQ_3 IQ_4 IQ_5 小时_1 小时_2 小时_3 小时_4 小时_5 Score_1 Score_2 Score_3 Score_4 Score_5
1 1 101 99 130 南 南 10 19 3 南 南 98 80 95 南 南
2 5 93 103 112 200 90 5 9 12 10 19 50 88 99 100 78
3 2 100 102 南 南 南 12 13 南 南 南 84 88 南 南 南

使得 1 行代表 1 个训练示例。但是这样一来，特征矩阵就会变得非常稀疏（因为不同班级的学生人数可能有很大差异）
因此，逻辑模型/普通前馈神经网络/基于树的模型似乎也不适用于这类群体数据。
所以我的问题是，是否有任何自然的机器学习模型可以处理这些“群体数据”，就像我上面的数据集一样？
此外，在这个问题中，我只关心最终名列前茅的人（或者可能是前三名），所以排名并不是那么重要（例如，知道学生 4 排名第 11 位，学生 8 排名第 12 位并不重要）
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/658803/most-natural-class-of-machine-learning-models-for-race-data-group-data</guid>
      <pubDate>Mon, 16 Dec 2024 09:50:29 GMT</pubDate>
    </item>
    <item>
      <title>Cox 回归假设</title>
      <link>https://stats.stackexchange.com/questions/658802/cox-regression-assumptions</link>
      <description><![CDATA[我正在分析血浆生物标志物与疾病发病率之间的关联，这些关联是通过年度问卷自我报告的。总样本量为 824，其中 65 人报告了至少一个事件（我不考虑多个事件）。除了事件发生之外，所有其他变量都是在基线测量的。我会使用 Cox 比例风险回归模型，但我不熟悉这个模型，并且对我获得的假设图感到很困惑。
我的完全调整模型如下所示：
assumpt.cox &lt;- coxph(Surv(time, event) ~ contvar1 + 
contvar2 + catvar1 + catvar2 + 
catvar3 + contvar3 + catvar4 + contvar4 + contvar5, data = data_assumpt.cox)

其中 contvar 是连续变量，catvar 是分类变量。我主要关注的是 contvar1。
我检查了 PH 假设，它没有表明违反（所有变量和全局变量的 p&gt;0.05）。
对于有影响的点，我检查了偏差并注意到所有报告事件的参与者都聚集在图表的顶部，而没有报告事件的参与者则聚集在底部。此外，平均偏差不为 0。但我不清楚我应该怎么做。
ggcoxdiagnostics(assumpt.cox, type = &quot;deviance&quot;,
linear.predictions = FALSE, ggtheme = theme_bw()) 


对于线性，我发现了两种主要方法来检查这个假设。

使用空模型：

 ggcox functional(Surv(time, event) ~ contvar1 + I(contvar1)^2 + log(contvar1) + 
sqrt(contvar1), data = data_assumpt.cox)



使用完全调整的模型：

data_assumpt.cox %&gt;% 
ggplot(aes(x=contvar1, y=residuals(assumpt.cox, type=&quot;martingale&quot;))) + 
geom_point() + 
geom_hline(yintercept = 0, color=&quot;blue&quot;) +
geom_smooth(color=&quot;red&quot;) +
theme_bw()



我明白，在第一组图中，我应该看到数据点和残差线之间有很好的相关性，而在第二组图中，红线应该（大部分）在 0 处笔直。但总的来说，它们应该告诉我同样的事情。这是正确的吗，还是应该优先考虑其中一个？
从这些图中，我得出结论，线性假设被违反了。
但如果是这样，我该怎么办，因为转换似乎没有帮助？我也试图排除 contvar1 中的两个极端值（一个有事件，一个没有事件），但效果只略有改善。
抱歉发了这么长的帖子，我希望至少能说清楚。
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658802/cox-regression-assumptions</guid>
      <pubDate>Mon, 16 Dec 2024 09:44:18 GMT</pubDate>
    </item>
    <item>
      <title>多个非独立同分布 beta 素数变量之和</title>
      <link>https://stats.stackexchange.com/questions/658799/the-sum-of-multiple-non-i-i-d-beta-prime-variables</link>
      <description><![CDATA[假设 $X_1$,$X_2$,$X_3$ 是独立同分布的。伽马随机变量，则$\frac{X_1}{X_2}$、$\frac{X_2}{X_3}$、$\frac{X_3}{X_1}$服从 beta 素数分布且相互关联。
那么，$\frac{X_1}{X_2}+\frac{X_2}{X_3}+\frac{X_3}{X_1}$的分布是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658799/the-sum-of-multiple-non-i-i-d-beta-prime-variables</guid>
      <pubDate>Mon, 16 Dec 2024 08:29:57 GMT</pubDate>
    </item>
    <item>
      <title>在回归模型中意外地两次包含同一个变量？</title>
      <link>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</link>
      <description><![CDATA[我在 R (mgcv) 中有这种混合效应 GAM 回归：
library(mgcv)
gam_beta &lt;- gam( 
y ~ te(time, x1) + te(time, x2) + s(time, by = city) + s(city, bs = &quot;re&quot;), 
data = my_data,
method = &quot;REML&quot;, 
family = betar(link = &quot;logit&quot;)
)

我尝试为该模型编写方程（基于我对 mgcv 中张量积函数 te 的理解 https://www.rdocumentation.org/packages/mgcv/versions/1.9-1/topics/te):
$$ y_{ij} \sim \text{Beta}(\mu_{ij}\phi, (1-\mu_{ij})\phi) $$
$$\mu_{ij} = \frac{1}{1+e^{-\eta_{ij}}}$$
$$ \text{logit}(\mu_{ij}) = \eta_{ij}= \beta_0 + f_{12}(time_{ij}, x1_{ij}) + f_{34}(time_{ij}, x2_{ij}) + h_i(time_{ij}) + b_i $$
我尝试将其进一步扩展：
$$ \eta_{ij} = \underbrace{\sum_{k=1}^{K_1} \hat{\gamma}_{1k}f_{1k}(time_{ij}) + \sum_{l=1}^{L_1} \hat{\gamma}_{2l}g_{1l}(x1_{ij}) + \sum_{k=1}^{K_1}\sum_{l=1}^{L_1} \hat{\gamma}_{3kl}f_{1k}(time_{ij})g_{1l}(x1_{ij})}_{\text{first te(): time and x1 term}} + $$
$$ \underbrace{\sum_{m=1}^{M_1} \hat{\gamma}_{4m}f_{2m}(time_{ij}) + \sum_{n=1}^{N_1} \hat{\gamma}_{5n}g_{2n}(x2_{ij}) + \sum_{m=1}^{M_2}\sum_{n=1}^{N_2} \hat{\gamma}_{6mn}f_{2m}(time_{ij})g_{2n}(x2_{ij})}_{\text{second te(): time and x2 term}} + $$
$$ \underbrace{\sum_{p=1}^P \hat{\alpha}_{ip}h_p(time_{ij})}_{\text{city-specific smooth}} + \underbrace{\hat{b}_i}_{\text{random effect}} $$
我的问题如下：我知道 mgcv 中的 te 函数包含主效应和交互效应 (GAM 回归：交互与主效应？)。但这是否意味着某个术语存在被重复计算并在 GAM 方程中出现两次的风险？
例如，我有 te(time,x1) 和 te(time,x2)。这是因为我想在我的模型中包含与协变量 x1 和 x2 的时间交互。但这是否会导致时间的主效应被包含两次？或者 mgcv 会识别这一点并且只包含一次？]]></description>
      <guid>https://stats.stackexchange.com/questions/658798/accidentally-including-the-same-variable-twice-in-a-regression-model</guid>
      <pubDate>Mon, 16 Dec 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>数据分类</title>
      <link>https://stats.stackexchange.com/questions/658795/data-categorization</link>
      <description><![CDATA[我已将我的教育数据集分类以供以下分析。但是，我遇到过一位受访者就读于一所传教学校，我不知道其水平，也不确定将他们放在何处。我应该将他们排除在外吗？我的决定基于什么依据？
教育 是 否 总计
高等教育 22 13 35
中学 144 47 191
小学 103 52 155
未受过教育 23 13 36
]]></description>
      <guid>https://stats.stackexchange.com/questions/658795/data-categorization</guid>
      <pubDate>Mon, 16 Dec 2024 06:47:39 GMT</pubDate>
    </item>
    <item>
      <title>需要有共同原因的因果调整公式</title>
      <link>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</link>
      <description><![CDATA[
在上述因果模型中，计算$P(X=x \mid \text{do}(Y=y))$时，是否需要使用因果调整公式$\sum_c P(X=x \mid Y=y, C=c) P(C=c)$？一旦我们$\text{do}(Y=y)$，$Y$的生成过程是否就独立于$X$的生成过程，因此$P(X=x \mid \text{do}(Y=y)) = P(X=x)$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658794/need-for-causal-adjustment-formula-with-shared-cause</guid>
      <pubDate>Mon, 16 Dec 2024 06:30:13 GMT</pubDate>
    </item>
    <item>
      <title>无线通信中的超几何函数：寻求性能分析的指导</title>
      <link>https://stats.stackexchange.com/questions/658788/hypergeometric-functions-in-wireless-communication-seeking-guidance-for-perform</link>
      <description><![CDATA[我正在从纯数学转向无线通信，对分析 Nakagami-m 衰落信道的数学挑战特别感兴趣。这些信道广泛用于模拟无线环境，中断概率和遍历容量等性能指标通常涉及超几何函数、Meijer G 函数和渐近分析等高级工具。
我一直在阅读有关如何应用这些工具的文章，但仍在努力确定它们背后更深层次的数学结构。
我的核心问题是：
在分析 Nakagami-m 衰落信道的性能指标（例如中断概率、容量）时，尤其是在 RIS 辅助或多天线系统中，关键的数学方法或未解决的问题是什么？
虽然我知道一些标准结果，但我渴望了解该领域是否存在任何未探索的挑战或创新的数学方法。
我需要你的帮助。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658788/hypergeometric-functions-in-wireless-communication-seeking-guidance-for-perform</guid>
      <pubDate>Mon, 16 Dec 2024 01:16:25 GMT</pubDate>
    </item>
    <item>
      <title>我该如何解释成对 Wilcoxon 检验的结果来识别“更好”的组？</title>
      <link>https://stats.stackexchange.com/questions/658785/how-do-i-interpret-pairwise-wilcoxon-test-results-to-identify-the-better-group</link>
      <description><![CDATA[在 Kruskal-Wallis 检验中发现显著结果后，我进行了成对 Wilcoxon 秩和检验。如果存在显著差异，我该如何根据检验结果确定哪组表现更好？我应该依靠中位数还是其他指标来得出结论？]]></description>
      <guid>https://stats.stackexchange.com/questions/658785/how-do-i-interpret-pairwise-wilcoxon-test-results-to-identify-the-better-group</guid>
      <pubDate>Mon, 16 Dec 2024 00:17:21 GMT</pubDate>
    </item>
    <item>
      <title>向量的期望 $L^2$ 范数是否大于向量元素期望的 $L^2$ 范数？</title>
      <link>https://stats.stackexchange.com/questions/658756/is-the-expected-l2-norm-of-a-vector-larger-than-the-l2-norm-of-the-vector</link>
      <description><![CDATA[假设随机变量 $X_1, X_2$ 是独立的。以下不等式是否成立？
$$
\mathbb{E}(​​\sqrt{X_1^2+X_2^2}) \ge \sqrt{\mathbb{E}^2(X_1)+\mathbb{E}^2(X_2)}
$$
如果成立，有简单的证明吗？

请注意，这不是 Jensen 不等式！
（$\sqrt{\mathbb{E}(​​X_1^2+X_2^2)} \ge \mathbb{E}(​​\sqrt{X_1^2+X_2^2})$）]]></description>
      <guid>https://stats.stackexchange.com/questions/658756/is-the-expected-l2-norm-of-a-vector-larger-than-the-l2-norm-of-the-vector</guid>
      <pubDate>Sun, 15 Dec 2024 15:14:16 GMT</pubDate>
    </item>
    <item>
      <title>计算不同大小的文本语料库的卡方</title>
      <link>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</link>
      <description><![CDATA[我偶然发现了一篇论文，它批评了某文本分析软件中用于比较六个大小明显不同的文本语料库中的词频的卡方统计量的计算。该软件采用标准公式：
$$
\chi^2 = \sum_{i=1}^{n} \frac{(O_{i} - E_{i})^2}{E_{i}}
$$
这里，$O_{i}$表示在语料库$i$中观察到的频率，$E_{i}$的计算方法是将一个词在所有六个语料库中的总频率除以所有语料库中的单词总数，然后乘以语料库$i$中的单词数。
本文作者批评了这种方法，陈述：

&quot;运行交叉制表也不能产生有效可靠的评估。 [...] 事实证明，该软件使用非标准化的绝对频率，只有当要比较的文本语料库长度相等时才不会引起问题。&quot;

在这种情况下，作者将$O_{i}$解释为绝对频率，并提出了一种替代的&quot;标准化&quot;过程来计算$O_{i}$和$E_{i}$。这涉及：

选择最小的语料库作为参考。
通过将观察到的所有其他语料库的频率除以各自语料库中的单词总数，然后乘以参考语料库中的单词数，对观察到的所有其他语料库的频率进行归一化。
将预期频率计算为所有语料库（包括参考语料库）的归一化频率之和，除以六（语料库数量）。

问题 1：作者声称该软件使用的公式（如上所述）没有考虑到语料库的各种大小，他是否正确。
问题 2：在这种情况下，这种归一化方法是否适用于卡方计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/658753/computing-chi-square-on-text-corpora-of-different-sizes</guid>
      <pubDate>Sun, 15 Dec 2024 13:37:05 GMT</pubDate>
    </item>
    <item>
      <title>箱线图是否假设区间数据？</title>
      <link>https://stats.stackexchange.com/questions/658750/does-a-boxplot-assume-interval-data</link>
      <description><![CDATA[箱线图是否假设区间数据？如果不是，那么使用箱线图来表示李克特量表（序数）数据可以吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658750/does-a-boxplot-assume-interval-data</guid>
      <pubDate>Sun, 15 Dec 2024 11:48:10 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn QuantileRegressor 中 L1 正则化的 alpha 参数是什么</title>
      <link>https://stats.stackexchange.com/questions/658748/what-is-the-alpha-parameter-for-l1-normalization-in-scikit-learn-quantileregress</link>
      <description><![CDATA[scikit-learn Quantile Regression 文档中的 示例 展示了一个将参数 alpha 设置为零的示例。默认值为 1。
文档 QuantileRegressor 显示默认值设置为 1.0。它指出这是一个乘以 L1 惩罚项的正则化常数。
我对 Lasso 是什么或 L1 回归的确切含义没有直观的理解。
参数 alpha 与这些事物的关系是否有直观的解释？
有一篇与分位数回归相关的 维基百科文章，非常详细。浏览此文，在正则化参数的选择部分中，alpha 似乎就是 lambda。它在其他地方也可能被称为t。
我的直觉可能是错的。
到目前为止，我的结论是 alpha 可能只在多维（&gt; 1）回归问题中起作用，它可能用于选择维度的子集，即具有最强统计预测能力的最重要维度？]]></description>
      <guid>https://stats.stackexchange.com/questions/658748/what-is-the-alpha-parameter-for-l1-normalization-in-scikit-learn-quantileregress</guid>
      <pubDate>Sun, 15 Dec 2024 08:40:50 GMT</pubDate>
    </item>
    <item>
      <title>涉及比率的估计量的期望</title>
      <link>https://stats.stackexchange.com/questions/658727/expectations-of-estimators-involving-ratios</link>
      <description><![CDATA[我正在研究一些面板数据计量经济学主题，我遇到了以下渐近性质：$N \to \infty$:
\begin{equation}
\theta^{\ast} \to \frac{\mathbb{E}(​​\beta_i)}{1 - \mathbb{E}(​​\gamma_i)} 
\quad \text{and} \quad 
\bar{\theta} \to \mathbb{E}\left(\frac{\beta_i}{1 - \gamma_i}\right) = \mathbb{E}(​​\theta_i),
\end{equation&gt;
幻灯片指出，除非$\beta_i$ 和 $\gamma_i$ 是独立分布的。为什么会这样？具体来说，为什么比率的期望值不等于期望值的比率？随机参数分布的独立性在这种差异中起什么作用？原因很简单，因为如果 $\beta_i$ 和 $\gamma_i$ 是独立的随机系数，则联合期望为：$\mathbb{E} (\beta_i) \times \mathbb{E}\left(\frac{1}{1-\gamma_i}\right)$?]]></description>
      <guid>https://stats.stackexchange.com/questions/658727/expectations-of-estimators-involving-ratios</guid>
      <pubDate>Sat, 14 Dec 2024 22:35:57 GMT</pubDate>
    </item>
    <item>
      <title>纳入因变量的下限是否可以改善估计？</title>
      <link>https://stats.stackexchange.com/questions/658703/does-incorporating-lower-bound-on-dependent-variable-improve-estimation</link>
      <description><![CDATA[假设我们抛硬币 $n$ 次，其中 如果正面，则 $Z_k = 1$，否则为 0，$Y = \sum_{k=1}^{n} Z_k$ 是正面的总数。硬币有两种类型：银币和金币，我们可以观察到用 $X$ 表示。此外，给定硬币的类型，我们知道正面的概率：
$$ P(Z_k|X) =: p(X) = \begin{cases} 0.8 &amp; X = 金币 \\ 0.5 &amp; X = 银币 \end{cases} $$
目标是根据硬币类型预测正面的硬币数量。

由于我们知道 $Y|X$ 的分布，第一种方法是条件均值估计量：
$$ \hat{\theta}(X) = \mathbb{E}[Y|X] $$
这是 $L^2$ 意义上的最佳估计量。在这种情况下，因为我们知道$Y|X \sim Binom(n, p(X))$，所以我们有一个闭式解
$$ \hat{\theta}(X) = np(X) = \begin{cases} 0.8n &amp; X = Gold \\ 0.5n &amp; X = Silver \end{cases} $$

现在问题如下。假设在$n$次翻转之前的任何时间点，我们都可以暂停游戏，优化我们的模型，并恢复其余的翻转。我们能改进之前的估计器吗？
请注意，对于给定的实现 $X_i$，目标是预测 $Y_i$。Oracle 估计器会设置 $\hat{Y}_i = Y_i$ 和 $MSE(Y_i, \hat{Y}_i) = 0$，但这显然是不可能的，因为我们实际上并不知道结果是什么。然而，随着每次抛硬币，我们都会收集更多关于 $Y_i$ 下限的信息。更准确地说，如果我们暂停翻转并观察到有 $c$ 次正面，那么我们就知道
$$ Y_i \geq c $$
这就会激发“增强”估计量：
$$ \hat{\theta}^{aug}(X; c) = \mathbb{E}[Y|X, Y\geq c] = \frac{ \int_{c}^{n} y \ dP_{Y|X}}{\int_{c}^{n} dP_{Y|X}}$$
其中条件均值估计量是 $c = 0$ 的一个特例。有没有办法正式证明增强估计量在某种意义上“更好”？
可能，一种方法是将条件设置为过滤序列，我们观察到越来越多有关由$Y$生成的$\sigma$-代数的信息。或者，也许我们可以将其视为
$$ Y = \mathbb{E}[Y|X] + \epsilon $$
随着翻转次数的增加，我们观察到一些关于$\sigma(\epsilon)$的部分知识。

我使用$n=10$进行了数值模拟，并得到了一些有趣的结果。这里的 x 轴是让 $c = pY$ 满足 $p \in [0,1]$。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658703/does-incorporating-lower-bound-on-dependent-variable-improve-estimation</guid>
      <pubDate>Sat, 14 Dec 2024 05:37:35 GMT</pubDate>
    </item>
    </channel>
</rss>