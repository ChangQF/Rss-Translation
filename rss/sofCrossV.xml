<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 04 Oct 2024 03:22:12 GMT</lastBuildDate>
    <item>
      <title>在 2010 年代后期小程序流行之前，统计学家用什么来快速找到 p 值？</title>
      <link>https://stats.stackexchange.com/questions/655303/what-did-statisticians-use-to-quickly-find-p-values-before-applets-were-populari</link>
      <description><![CDATA[我是统计学专业的新生，今天我从教授那里得知，实际上，模拟样本重复的小程序直到 2010 年代末才出现，这让我非常惊讶，因为它们看起来很简单 - 就像已经存在一段时间的东西一样。在这些出现之前，用什么来快速找到 p 值？]]></description>
      <guid>https://stats.stackexchange.com/questions/655303/what-did-statisticians-use-to-quickly-find-p-values-before-applets-were-populari</guid>
      <pubDate>Fri, 04 Oct 2024 03:01:10 GMT</pubDate>
    </item>
    <item>
      <title>glmer 估计值为负，但应为正</title>
      <link>https://stats.stackexchange.com/questions/655300/glmer-estimate-is-negative-but-should-be-positive</link>
      <description><![CDATA[我正在为我的硕士论文研究寻找一个 glmer（论文完成之前我不能分享数据，所以我会尽量在描述中非常明确）。
但总结一下，我的因变量是一个二进制（exhaustbinary），其中 1 表示参与者做了这件事，0 表示参与者没有做这件事。
我的独立因素是年龄组（儿童或成人）和试验类型（对照或关键），其中有两个随机截距，分别是单个参与者（SubjectID）和单个试验（Item）。
查看代码：
agebytrialopt &lt;- glmer (ExhaustBinary ~ Agegroup * TrialType +(1|SubjectID)+(1|Item), data=df, family=&quot;binomial&quot;, control=glmerControl(optimizer=&quot;bobyqa&quot;, optCtrl=list(maxfun=100000)))

这一切都运行良好。
然而，在摘要和输出中，我得到了一些违反直觉的东西。
固定效应：
估计标准差。错误 z 值 Pr(&gt;|z|) 
(截距) 8.701 1.380 6.306 2.86e-10 ***
AgegroupChild -3.805 1.213 -3.137 0.0017 ** 
TrialTypeCritical -7.049 1.148 -6.140 8.23e-10 ***
AgegroupChild:TrialTypeCritical 6.493 1.201 5.409 6.35e-08 ***

基本上，当我们从儿童级别切换到成人级别时，与成人相比，儿童在排气二进制中更有可能获得 1 值。但是，根据 glmer 选择的名称，这应该意味着儿童与成人相比具有较低的“分数”。这与数据不符，他们的得分高于成年人。
与 TrialTypeCritical 相比，与对照组相比，关键试验在排气二进制中具有更多 0 值。因此，根据名称，关键试验应该比对照组具有较低的“分数”。这在直观上是真实/准确的，并且这里的负估计是有意义的。
我确实检查了因素中对比的虚拟代码，基本因素如下所示。
&gt; 对比（df$Agegroup）
儿童
成人 0
儿童 1

&gt;对比（df$TrialType）
严重
控制 0
严重 1

公平地说，我在过去 5 个小时里一直在研究这个问题，在开始手动设置对比之前，我想确保我正确地解释了这些估计值。
此外，由于我们确实有显著的相互作用，我已经进行了分解，并查看了 emmeans 等等，那里的一切都有意义，可以解释，我对那里的任何负/正翻转都没有问题。
任何关于我哪里出错的见解（无论是我对因素/水平和对数估计的理解，还是对比的工作原理，或者只是一般情况）都会有所帮助。
不过，为了清楚起见，glmer 是我们拥有的数据的最佳选择，我已经做了使用这种方法的所有理论论证，所以我不想回答关于为什么我选择使用glmer 或类似的东西。我只是需要帮助来了解 AgegroupChild 上的极性发生了什么。
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655300/glmer-estimate-is-negative-but-should-be-positive</guid>
      <pubDate>Thu, 03 Oct 2024 22:55:02 GMT</pubDate>
    </item>
    <item>
      <title>纽伊标准误差</title>
      <link>https://stats.stackexchange.com/questions/655298/newey-standard-errors</link>
      <description><![CDATA[我目前正在 Stata 上估计时间序列回归，但遇到了瓶颈。在调查自相关的残差时，我发现滞后 19 的残差之间存在显著的自相关性。检查偏自相关性时，我发现在滞后 19、32 和 34 处存在显著的滞后。由于我计划使用新标准误差来处理这个问题，因此我不确定在使用这些新误差估计回归时应该指定什么滞后。应该是 34 吗，因为这是存在任何类型的自相关和偏自相关的最远滞后？我不擅长这些东西，所以任何答案都将不胜感激！谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655298/newey-standard-errors</guid>
      <pubDate>Thu, 03 Oct 2024 22:20:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么“无偏估计量”比最小误差估计量更重要？</title>
      <link>https://stats.stackexchange.com/questions/655296/why-is-unbiased-estimator-more-important-than-min-error-estimator</link>
      <description><![CDATA[根据 Edwin Jaynes（其著作《概率论：科学的逻辑》第 17 章）的说法，估计量的均方误差由偏差项和方差项组成，即：
$$L =E[(\beta - \alpha)^2]=E[(E[\beta] - \alpha)^2]+(E[\beta^2] - E[\beta]^2)$$
其中 $\beta$ 是数量 $\alpha$ 的估计量。
对于“无偏”估计量，我们的目标是最小化第一项$E[(E[\beta] - \alpha)^2]$，然而，这通常不会导致总误差$L$最小化。Jaynes 建议最好使用估计量$\beta$来最小化$L$，这样我们就可以充分利用有限的可用数据。
鉴于这种推理，我有点困惑，为什么我们首先想要得到“无偏估计量”而不是最小误差估计量，有人可以分享你的意见吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655296/why-is-unbiased-estimator-more-important-than-min-error-estimator</guid>
      <pubDate>Thu, 03 Oct 2024 22:14:49 GMT</pubDate>
    </item>
    <item>
      <title>非重叠、非堆叠面积图或非分支、非恒定数量流程图</title>
      <link>https://stats.stackexchange.com/questions/655295/non-overlapping-non-stacked-area-plots-or-non-branching-non-constant-quantity</link>
      <description><![CDATA[考虑对少量时间点和大量系列的数据进行可视化，在这种情况下：
day | a | b | c | d | e | f
0 | 2 | 4 | 2 | 0 | 1 | 3
90 | 4 | 2 | 3 | 1 | 0 | 1
180 | 4 | 2 | 2 | 4 | 2 | 2

由于集合的大小，条形图和折线图效果不佳，按时间点分组不能轻松地跨系列进行比较，反之亦然。堆积面积图和堆积柱形图是自然契合的，可以比较两者，但是在 X 轴点数较少（在本例中为 3）并且数据点接近零时，两者都会失真：

可以计算“填充”数据以水平对齐系列：
 日 | | a | | b | | c | | d | | e | | f
中点 | | 2 | | 7 | | 11.5 | | 16 | | 20 | | 23.5
0 | 1 | 2 | 2 | 4 | 1.5 | 2 | 3.5 | 3.5  0 | 3.5 | 3.5  1 | 1.5 | 1.5  3 90 |  0 |  4 |  2 |  2 | 2 |  3 | 2.5 | 2.5  1 | 3.5 | 3.5  0 | 3 |  1 180 |  0 |  4 |  2 |  2 | 2.5 | 2.5  2 | 1.5 | 1.5  4 | 1 |  2 | 1.5 | 1.5  2

这提高了清晰度：

并且可以通过添加沿 X 轴的间距坐标来进一步改进面积图：
 day | | a | | b | | c | | d | | e | | f
中点 | | 2 | | 7 | | 11.5 | | 16 | | 20 | | 23.5
0 | 1 | 2 | 2 | 4 | 1.5 | 2 | 3.5 | 0 | 3.5 | 1 | 1.5 | 3
10 | 1 | 2 |  2 |  4 | 1.5 | 1.5  2 | 3.5 | 3.5  0 | 3.5 | 3.5  1 | 1.5 | 1.5  3 80 |  0 |  4 |  2 |  2 | 2 |  3 | 2.5 | 2.5  1 | 3.5 | 3.5  0 | 3 |  1 100 | 1 100  0 |  4 |  2 |  2 | 2 |  3 | 2.5 | 2.5  1 | 3.5 | 3.5  0 | 3 |  1 170 |  0 |  4 |  2 |  2 | 2.5 | 2.5  2 | 1.5 | 1.5  4 | 1 |  2 | 1.5 | 1.5  2 180 |  0 |  4 |  2 |  2 | 2.5 | 2.5  2 | 1.5 | 1.5  4 | 1 |  2 | 1.5 | 1.5  2


最后一个开始类似于流程图，例如桑基图或平行集图，尽管它没有输入和输出流，只是幅度变化。它也类似于小提琴图，尽管数据与 x 轴时间点相关，宽度不是概率分布。它只是一个平行面积图 - 不堆叠，不重叠，也不受 100% 约束。
这个平行面积图有名字吗？
除了手动计算填充数据然后将其隐藏在视图之外，R 或 Python（ggplot2 或其他）中是否有此平行面积图的可视化方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655295/non-overlapping-non-stacked-area-plots-or-non-branching-non-constant-quantity</guid>
      <pubDate>Thu, 03 Oct 2024 21:59:23 GMT</pubDate>
    </item>
    <item>
      <title>统一采用政策，不错开[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655294/uniform-policy-adoption-and-not-staggered</link>
      <description><![CDATA[我有两个问题。

在政策变化是即时的而不是交错的的情况下，用什么术语来描述政策变化的情况？

分析此类数据时，哪些统计方法合适？常用的统计方法来分析此类数据。


谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655294/uniform-policy-adoption-and-not-staggered</guid>
      <pubDate>Thu, 03 Oct 2024 21:54:57 GMT</pubDate>
    </item>
    <item>
      <title>当两个多因素变量中的一些因素呈负相关时，如何评估它们之间相关性的绝对强度</title>
      <link>https://stats.stackexchange.com/questions/655291/how-to-assess-the-absolute-strength-of-a-correlation-between-two-multifactorial</link>
      <description><![CDATA[我有两个多因子构造，其中一个由 5 个子因子组成，另一个由 4 个子因子组成。我希望评估这两个构造之间的关联的“绝对”强度。
问题是，当以标准方式（CFA）构建模型时，子因子之间的正向和负向相互关系似乎将构造在全局层面上的关系平均为零。但是，在因子层面上存在显着的关系！
construct1 =~ subfactor1a + subfactor1b + subfactor1c + subfactor1d + subfactor1e
construct2 =~ subfactor2a + subfactor2b + subfactor2c + subfactor2d
construct1 ~~ constrain2




CorrTable
1a
1b
1c
1d
2a
2b
2c
2d
2e




1a
1










1b
.50
1
&lt; /td&gt;








1c
.45
.50
1




&lt; /td&gt;



1d
.60
.50
.45
1








1e
.55
.45
.45
.55
1






2a
-.10
-.20
-.15
-.09
-.11
1





2b
-.20
-.05
-.10
-.10
-.01
.57
1&lt; /td&gt;




2c
-.05
-.02
-.09
-.01
-.05
.65
.55
1



2d
.05
.01
.05
.05
.03
.55
.55
.55
1



评估两个变量之间关系的“绝对”强度的最佳方法是什么，同时避免将效果整体平均为零？
我曾尝试对第二个构造的前三个子因素进行反向评分，但这并没有改变两个构造之间的关联强度。
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/655291/how-to-assess-the-absolute-strength-of-a-correlation-between-two-multifactorial</guid>
      <pubDate>Thu, 03 Oct 2024 20:38:01 GMT</pubDate>
    </item>
    <item>
      <title>我有一份医疗保健优先事项的排序列表，该列表是我通过对两个不同国家的医生进行的调查来评估的</title>
      <link>https://stats.stackexchange.com/questions/655290/i-have-a-rank-order-list-of-healthcare-priorities-which-i-assessed-using-a-surve</link>
      <description><![CDATA[我使用调查来评估两个不同国家/地区的医疗保健提供者之间某些医疗保健优先事项的排名顺序。我使用标准独立样本 t 检验测试了归因于每个优先事项的排名值，但我试图查看优先事项的顺序是否不同。
只是显示顺序（从 1 到 6）足够不同，还是我可以使用测试来显示顺序不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/655290/i-have-a-rank-order-list-of-healthcare-priorities-which-i-assessed-using-a-surve</guid>
      <pubDate>Thu, 03 Oct 2024 20:15:42 GMT</pubDate>
    </item>
    <item>
      <title>对图表进行聚类（*不是*在图表内进行聚类）的最合理方法是什么？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655289/whats-the-most-reasonable-way-to-cluster-graphs-not-cluster-within-graphs</link>
      <description><![CDATA[假设我有一种数据，其中每个数据点都是一个图，并且我对聚类数据感兴趣。请注意，我不是在图中寻找聚类（这是研究“图聚类”时必然会出现的问题）。相反，每个数据点都是一个具有自己的邻接矩阵的图。我如何确定哪些图在模式相似性方面组合在一起？我也对以监督方式执行此操作感兴趣，因此，如果每个图都有标签 A 或 B，我将使用哪种分类器将邻接矩阵作为输入？
我知道我可以用 GNN 做到这一点，但我很好奇是否有任何不那么“黑箱”的方法来基于图的特征进行聚类或分类，但这些方法考虑的特征比邻接矩阵上的汇总统计数据更复杂。]]></description>
      <guid>https://stats.stackexchange.com/questions/655289/whats-the-most-reasonable-way-to-cluster-graphs-not-cluster-within-graphs</guid>
      <pubDate>Thu, 03 Oct 2024 19:54:33 GMT</pubDate>
    </item>
    <item>
      <title>确定分类时间序列中不规则间隔的名义观测值的序列依赖性</title>
      <link>https://stats.stackexchange.com/questions/655286/determining-serial-dependence-in-irregularly-spaced-nominal-observations-in-a-ca</link>
      <description><![CDATA[我有关于河流上游和下游鱼类活动的数据。鱼类被贴上超声波发射器的标签，以便识别个体。记录水听器被放置在河流的不同位置，用于识别和记录被标记的鱼经过的日期和时间。结果数据是鱼类（名义）上游或下游运动模式的不规则间隔时间序列。我想测试鱼类运动序列的独立性，例如，鱼的下游运动是否更有可能或不太可能随后进行下游运动？每个鱼类数据系列都不是很长（&lt;20 个数据点）我研究过分类时间序列，但找不到处理不规则间隔名义观测值的方法。任何建议都将不胜感激。提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/655286/determining-serial-dependence-in-irregularly-spaced-nominal-observations-in-a-ca</guid>
      <pubDate>Thu, 03 Oct 2024 18:49:24 GMT</pubDate>
    </item>
    <item>
      <title>信号自相关的不确定性</title>
      <link>https://stats.stackexchange.com/questions/655283/uncertainty-about-the-auto-correlation-of-a-signal</link>
      <description><![CDATA[我有以下信号，表示电动机的供电电压：

我计算该信号的自相关如下：
 Rxy[:] = signal.correlate(
(X[:] - np.mean(X[:])) / np.std(X[:]),
(X[:] - np.mean(X[:])) / np.std(x[:]),
) / len(X)

其中 signal.correlate 取自Python 的 scipy 包。
如果我绘制该信号的自相关图，我会得到一个几乎恒定在 1 附近的图，见图：

对我来说，这非常奇怪，因为通过观察信号相对于时间的变化，它似乎没有那么多的自相关。有人能解释一下发生了什么吗？
编辑：我尝试删除平均值并消除趋势，得到以下结果：

但情况只是略有好转：
]]></description>
      <guid>https://stats.stackexchange.com/questions/655283/uncertainty-about-the-auto-correlation-of-a-signal</guid>
      <pubDate>Thu, 03 Oct 2024 18:27:33 GMT</pubDate>
    </item>
    <item>
      <title>两个大型二进制数组之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/655279/correlation-between-two-large-binary-arrays</link>
      <description><![CDATA[假设我有 0 和 1 的数组，精确定位：
$$
X=\text{错误率高的位置}\\
Y=\text{数据较差的位置}
$$
用于检查 $X$ 和 $Y$ 是否相关的最佳统计测试是什么？卡方或 phi 系数是否合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/655279/correlation-between-two-large-binary-arrays</guid>
      <pubDate>Thu, 03 Oct 2024 17:15:55 GMT</pubDate>
    </item>
    <item>
      <title>纵向分析结果中与基线的对数转换比率</title>
      <link>https://stats.stackexchange.com/questions/655273/log-transformed-ratio-to-baseline-as-an-outcome-in-longitudinal-analyses</link>
      <description><![CDATA[我必须分析变量 Y 的纵向数据（8 次访问），在文献中，大多数类似研究都对 Y&#39;=log(Y/Ybl) 进行建模，其中 Ybl 是 Y 的基线值，以获得不同组中不同时间的基线百分比变化估计值。
基线的 Y&#39; 始终等于 0，因此我从分析中排除了基线数据。但是，在这种情况下，截距和随机截距涉及第 2 周的访问，这是基线后的第一次访问。在我看来，这没有意义。
将对数转换后的比率建模为基线是一个好主意吗？
在这种情况下，我该怎么做才能有效且一致地编写模型？
（我正在使用 R）
以下是一些附加信息（感谢您的评论）：
模型是 Y&#39; = log(Ybl) + Treatment + Visit + Visit * Treatment

对个人的随机影响（相关出版物中不再有精度）

使用此配置，模型无法收敛到我的数据。如前所述，根据定义，对于所有患者，log(Ybl) = 0。]]></description>
      <guid>https://stats.stackexchange.com/questions/655273/log-transformed-ratio-to-baseline-as-an-outcome-in-longitudinal-analyses</guid>
      <pubDate>Thu, 03 Oct 2024 10:29:11 GMT</pubDate>
    </item>
    <item>
      <title>混合效应模型 lme4 的数据格式</title>
      <link>https://stats.stackexchange.com/questions/655239/data-format-for-mixed-effects-model-lme4</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655239/data-format-for-mixed-effects-model-lme4</guid>
      <pubDate>Wed, 02 Oct 2024 22:17:46 GMT</pubDate>
    </item>
    <item>
      <title>零膨胀泊松/负二项分布的功率分析</title>
      <link>https://stats.stackexchange.com/questions/655177/power-analysis-for-zero-inflated-poisson-negative-binomial</link>
      <description><![CDATA[我想进行一些功效分析来帮助规划实验。
具体来说，实验旨在测试一种处理方法是否能减少植物病原体的数量。实验设置是不同的地点，每个地点都包含“处理”和“控制”象限。
从以前的实验中，我知道我的响应变量（病原体数量）可以使用负二项式和/或零膨胀泊松分布进行建模。
我有两个问题，一个是实际问题，一个是理论问题：

我找到了一些关于零膨胀泊松分布功效分析的学术论文，但我找不到可以实现这些的 R 包。任何指针都值得赞赏！
在我的实验中，病原体可以不存在，因此是 ZIP 分布。但是，由于实地工作在资源（金钱/时间）上成本高昂，我希望能够判断一个地点是否值得采样。显然，如果没有病原体，该网站就不具有信息量。我的理解是，低病原体压力（病原体数量）比高病原体压力“信息量更少”。是否可以定义病原体压力的阈值，或者这肯定会违反统计上合理的采样方案？如果没有，这与功效分析有何关系？

提前感谢您的任何指示！]]></description>
      <guid>https://stats.stackexchange.com/questions/655177/power-analysis-for-zero-inflated-poisson-negative-binomial</guid>
      <pubDate>Tue, 01 Oct 2024 15:48:46 GMT</pubDate>
    </item>
    </channel>
</rss>