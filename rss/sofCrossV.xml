<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 20 Jan 2025 21:14:33 GMT</lastBuildDate>
    <item>
      <title>如何训练具有较小ECE（预期校准误差）的模型？</title>
      <link>https://stats.stackexchange.com/questions/660282/how-to-train-a-model-with-a-small-eceexpected-calibration-error</link>
      <description><![CDATA[如果我们训练一个具有交叉熵损失的深度学习模型，我们期望该模型具有较低的交叉熵损失。有没有办法训练模型，使模型获得较小的预期校准误差，同时保持负对数似然较小？或者有没有好的后处理方法来降低 ECE，同时保持交叉熵损失较小？]]></description>
      <guid>https://stats.stackexchange.com/questions/660282/how-to-train-a-model-with-a-small-eceexpected-calibration-error</guid>
      <pubDate>Mon, 20 Jan 2025 19:19:42 GMT</pubDate>
    </item>
    <item>
      <title>Fisher 判别分析 (FDA) 是否会使类内协方差变白？其背后的直觉是什么？</title>
      <link>https://stats.stackexchange.com/questions/660281/does-fishers-discriminant-analysis-fda-whiten-the-within-classes-covariance</link>
      <description><![CDATA[作为一种降维技术，Fisher 判别分析或线性判别分析的目标是找到一组特征$W$，以最大化类间方差与类内方差之间的比率。表示该比率的一种方式（称为 Fisher 标准）是
$$J(W) = \frac{\det (W^T S_B W)}{\det (W^TS_W W)}$$
其中 $S_B$ 是类别均值之间的散点，$S_W$ 是类别内的方差。
现在，我已经在不同的地方看到了（例如 这里）该问题的解由对 $(S_{B}, S_W)$ 的广义特征向量给出，或者等效地，由 $S_W^{-1}S_B$ 的特征向量给出。
此外，我已经看到（例如 此处）对 $(S_B, S_W)$ 的广义特征值问题可以看作以下优化问题：
$$\max_{W} \quad \mathrm{Tr}(W^T{S_B}W) \\ \mathrm{s.t.} \quad W^T S_W W = \mathbf{I}$$
这两点知识让我想到，投射到特征集 $W$ 上的数据的类内方差应该被白化（即单位矩阵协方差），或者至少是不相关的，这取决于 $W$ 列的比例。但是，我没有在任何地方看到明确提到这一点，我也不明白为什么最大化上述目标会导致这种结果。
因此，鉴于上述情况，FDA/LDA 特征是否会使类内方差变白？这背后有什么直觉吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660281/does-fishers-discriminant-analysis-fda-whiten-the-within-classes-covariance</guid>
      <pubDate>Mon, 20 Jan 2025 19:14:41 GMT</pubDate>
    </item>
    <item>
      <title>根据百分点差异调整年龄组回答之间的百分比</title>
      <link>https://stats.stackexchange.com/questions/660280/adjusting-percentages-between-age-group-responses-based-on-a-percentage-point-di</link>
      <description><![CDATA[我正在对另一个组织的报告中的社会调查数据进行分析。
数据仅以百分比形式报告，我无法访问基础数据。
报告中指出，40 岁以下和 40 岁以上的人群在宗教信仰方面的自我认同存在 19 个百分点的差异。我想根据百分点差异正确调整百分比。我的“直觉”反应是将百分点差异添加到较年轻的组（差异表示为正数）并从较年长的组中扣除。但这似乎不会产生准确的结果，因为实际差异应该介于两者之间。
有人会数学吗？有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660280/adjusting-percentages-between-age-group-responses-based-on-a-percentage-point-di</guid>
      <pubDate>Mon, 20 Jan 2025 18:52:22 GMT</pubDate>
    </item>
    <item>
      <title>当使用短于一年的区块长度时，如何从 GEV 获得 1/100 的回报期？</title>
      <link>https://stats.stackexchange.com/questions/660277/how-to-get-1-in-100-return-period-from-gev-when-using-a-block-length-shorter-tha</link>
      <description><![CDATA[我正在计算一个数据集的广义极值分布，该数据集包含每 5 秒采样一次的约 15 年数据。我想从 GEV 估算 1/50 或 1/100 年的回报水平。我最初使用一年的块长度来计算 GEV（例如，取每个 1 年间隔的最大值并将其用作 GEV 拟合的输入）。这使我能够轻松计算超出回报的概率：
$$P_{exceed} = 1-1/T_{return}$$
其中 $T_{return}$ 为 50（或 100）年。然后我可以找到具有超出概率的 GEV 水平，$P_{exceed}$。
但是，数据集在给定年份通常具有多个独立的&quot;极端值&quot;，并且在给定年份可能有多达 10 个，因此采用年度区块最大值将低估极端事件的数量和回报水平。
我如何修改它以获得 50 年内 1 次的回报水平，同时使用例如GEV 中的 10 天区块长度？
我认为我可以使用 10 天区块计算 GEV，然后将 $T_{return}$ 乘以 36.5 以获得年度 $P_{exceed}$，而不是 10 天 $P_{exceed}$。这似乎有效，但我不确定它是否具有统计有效性。
这里有几个额外的注意事项：
首先，我的数据有一些差距。如果我执行年度区块最大值，那么就没有问题，因为每个区块仍然有一些数据来计算最大值，但如果我执行 10 天区块长度，那么有些区块根本没有数据，因此区块最大值为 NaN。是不是最好假装不存在间隙，时间序列更短但连续？（这就是我目前正在做的。）或者最好假设间隙具有非常小的最大值，然后只给它们一些默认的小值？
其次，极端事件很少见（呃）。如果我做一个年度区块最大值，我基本上可以保证在每个区块中都会得到一个“极端”事件。但如果我做一个 10 天的区块长度，那么很多区块的最大值都非常小。GEV 可以很好地拟合那些最小的区块最大值，但最远的极端值拟合得最差（见下图）。
任何澄清都值得赞赏！
谢谢
示例 1：年度区块最大值。 CI 确实很大，但最佳拟合 GEV 至少能很好地通过极值

示例 #2：10 天区块最大值。CI 要小得多，但最佳拟合 GEV 在约 1 年的重现间隔后甚至无法通过极值。为什么拟合度这么差？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660277/how-to-get-1-in-100-return-period-from-gev-when-using-a-block-length-shorter-tha</guid>
      <pubDate>Mon, 20 Jan 2025 17:50:29 GMT</pubDate>
    </item>
    <item>
      <title>在 lme 中，我们应该使用 ML 还是 REML 方法进行假设检验？</title>
      <link>https://stats.stackexchange.com/questions/660274/in-lme-should-we-use-ml-or-reml-method-for-hypothesis-tesing</link>
      <description><![CDATA[我们有以下模型：
m &lt;- lme(y ~ x + time + event + time:event, data = df, 
random = ~ time | user_id, 
correlation = corAR1(form = ~ 1 | user_id), 
weights = varExp(form = ~ time))

我们对系数 time:event 的重要性感兴趣。我们使用 clubSandwich 包的函数进行估计：
robust_m &lt;- coef_test(m, vcov = &quot;CR2&quot;, cluster = df$user_id)
robust_se_ &lt;- robust_m$SE
robust_p &lt;- robust_m$p_Satt # Satterthwaite 调整后的 p 值

当我们使用 ML 方法时，交互系数在 p &lt; .01 处显著，但使用 REML 时，它不显著。
请注意，我们有大约 490,000 个观察值嵌套在 900 个用户下。
不确定应该使用哪种方法进行此类假设检验。]]></description>
      <guid>https://stats.stackexchange.com/questions/660274/in-lme-should-we-use-ml-or-reml-method-for-hypothesis-tesing</guid>
      <pubDate>Mon, 20 Jan 2025 15:57:24 GMT</pubDate>
    </item>
    <item>
      <title>样品去除的独立性</title>
      <link>https://stats.stackexchange.com/questions/660271/independency-in-samples-removal</link>
      <description><![CDATA[我正在研究以下子问题。我得到了一个完全加权图，$G = (V,E)$。$1 \leq u &lt; v \leq n$ 的边集 $E = \{X_{uv}\}$ 是一组随机变量，其中每个 $X_{uv} \sim U(0,1)$。
让 $i \in [1,n]$ 成为该图的一个顶点。如果存在另外两个顶点 $j \neq k$，s.t。 $j,k \in [1,n]$ 且 $j,k \neq i$ 使得
$X_{ij} = \min\{ X_{uv} \text{ s.t. } u=j \text{ 或 }v=j \}$ 且 $X_{ik} = \max\{ X_{uv} \text{ s.t. } u=k \text{ 或 }v=k \}$
即，$i$ 与 $j$ 之间的边是 $j$ 的边中的最小值，而 $i$ 与 $k$ 之间的边是 $i$ 与 $k$ 的边中的最大值（或反之亦然），则我将表示 $R = \{ X_{uv} \text{ s.t. } u=i \text{ 或 } v=i \}$。
因此，我将通过获取 $G&#39;= (V&#39;, E&#39;)$ 来缩小我的图，其中 $V&#39; = V \setminus \{i\}$ 和 $E&#39;= E \setminus R$。
现在，我能够计算出找到具有这种属性的顶点 $i$ 的概率，因为我的所有边都是 r.v。$U(0,1)$。 $P[i \in V \text{ has property above}] = 1-e^{-1}$。但是，由于我需要递归执行此过程，并且由于集合 $R$ 的特定选择，我会说 $E&#39;$ 取决于选择 $i$，并且 $E&#39;$ 的值不再是 i.i.d。因此我很想说
$P[i&#39; \in V&#39; \text{ has property above}] \neq 1-e^{-1}$ 因为 $R$ 中的边的移除可能会增加/减少连续顶点 $i&#39; \in V&#39;$ 上的属性。
您认为有办法打破这种依赖关系吗？我可以假设（并以某种方式证明）$E&#39;$ 再次由所有 i.i.d. 随机变量组成，这样我就可以再次应用我在开始时找到的概率（$1-e^{-1}$）吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660271/independency-in-samples-removal</guid>
      <pubDate>Mon, 20 Jan 2025 13:36:19 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法将标准化逻辑回归系数转换为相关性？</title>
      <link>https://stats.stackexchange.com/questions/660270/is-there-a-way-to-convert-a-standardized-logistic-regression-coefficient-into-a</link>
      <description><![CDATA[我正在对皮尔逊相关性 (Rs) 进行荟萃分析。我正在将其他相关性度量转换为 Rs（如果两个度量都是分类的，则可能在计算它们之后进行转换），并使用有关均值和标准差的信息来估计科恩的 d，然后将其转换为 R。
然而，有两篇论文，其中一个度量是连续的，另一个是二元的，并且只有比值比及其置信区间可用。我可以计算标准化（对数）比值比，因为我有连续预测变量的标准差，但是，有没有办法将其转换为相关性？当预测变量也是二元时，我已经找到了很多关于这种转换的资料，但没有关于预测变量是连续的情况的资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/660270/is-there-a-way-to-convert-a-standardized-logistic-regression-coefficient-into-a</guid>
      <pubDate>Mon, 20 Jan 2025 13:02:46 GMT</pubDate>
    </item>
    <item>
      <title>测试一系列点偏离给定线/水平的概率/重要性</title>
      <link>https://stats.stackexchange.com/questions/660269/test-the-probability-significance-that-a-sequence-of-points-will-deviate-from-a</link>
      <description><![CDATA[我想评估后续$n$ 个点（总共 $N$ 个）偏离（即其误差线不涵盖）某个任意水平/线/模型/等的概率（或者，更好的是，如果发生这种情况，其重要性）。在下面的草图中，用红色圈出的三个连续点偏离了蓝色水平/线。在这里，连续性至关重要，我对其他两个偏离点（紫色框中）不感兴趣。
我可能会天真地根据二项分布得出某些东西，但我想知道

是否有一些（或多或少复杂的）机制、统计工具、实现或类似的东西可以解决这个问题，并且
考虑这种序列作为偏差的重要性是否可能/有意义？

请注意，我不想对黑点进行任何拟合 - 我只想判断一些离散点集与预定义的任意线（无论这条线是什么）偏离的概率/重要性。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660269/test-the-probability-significance-that-a-sequence-of-points-will-deviate-from-a</guid>
      <pubDate>Mon, 20 Jan 2025 12:51:52 GMT</pubDate>
    </item>
    <item>
      <title>包含许多零的计数数据的 GLM 类型</title>
      <link>https://stats.stackexchange.com/questions/660267/type-of-glm-for-count-data-with-many-zeros</link>
      <description><![CDATA[我有一个非常大的数据集，其中统计了因某些原因（某种疾病）而入院的人数，并且该数据集的观测值是 5 年内每天的数据。除了变量入院之外，我还有 120 个其他变量，用于研究它们与因该原因入院的关系。
我的变量入院具有以下分布：60% 的天数为零人次入院，30% 的天数为一人次入院，其余 10% 的天数为2 至 4人次，范围类似（只有 5 天为4人次入院）。
我也有来自不同医院的数据，其中一些医院的零比例甚至更大。
至于我的响应变量，我控制的是季节性和长期趋势以及星期几。其余变量是连续的气象变量，其中大多数变量重复一定次数并有滞后，因为这些变量对独立变量的影响可能会随时间滞后。例如，heat 变量重复 5 次：heat1、heat2、heat3、heat4 和 heat5，每个变量都比前一个变量滞后 1 天。
admissions 的均值和方差几乎相同（~0.02（0.515, 0.535）的差异），因此我倾向于使用泊松回归而不是负二项回归进行建模。使用此方法建模后，我使用逐步向后消元法得到最终模型，因此我最终得到一个包含 27 个响应变量的模型。
R 中使用的代码如下：
modelP &lt;- glm(admissions ~ ., data = hospital, family = poisson(link = &quot;log&quot;))
我尝试使用拟泊松回归建模来比较方法，但此方法未定义 AIC，因此我无法执行向后消元法并比较两者。
modelQP &lt;- glm(admissions ~ ., data = hospital, family = quasipoisson(link = &quot;log&quot;))
使用此类数据执行泊松回归是否正确？大量变量会造成任何麻烦吗？我是否应该寻找其他类型的模型，例如 NB 或零膨胀模型？
我还想最终计算出起作用的重要变量的归因风险。]]></description>
      <guid>https://stats.stackexchange.com/questions/660267/type-of-glm-for-count-data-with-many-zeros</guid>
      <pubDate>Mon, 20 Jan 2025 11:37:12 GMT</pubDate>
    </item>
    <item>
      <title>《危险边缘》玩家的贝叶斯分析</title>
      <link>https://stats.stackexchange.com/questions/660260/bayesian-analysis-of-jeopardy-players</link>
      <description><![CDATA[这是我的一个想法。
有一个著名的电视智力竞赛节目叫做Jeopardy。玩家回答琐事问题并相互竞争。这个游戏有一个速度元素——虽然多个玩家可能知道同一个问题的答案，但更快响铃的玩家将优先回答问题。
我很好奇，想估计一下节目中玩家的“真实知识”。我天真地以为玩家可以大致分为 4 类：

第 1 组：回答很多问题且经常正确的玩家
第 2 组：回答很多问题且经常错误的玩家
第 3 组：回答不多但经常正确的玩家
第 4 组：回答不多且经常错误的玩家

我在 R 中模拟了一些数据，以直观地展示其可能的样子：

当我们拥有关于玩家的更多数据（即第 1 组和第 2 组）时，这样做是有道理的玩家知道多少的歧义应该更少。但是，对于数据较少的玩家（即第 3 组和第 4 组），这些玩家可能实际上知道的比数据显示的要多（例如，如果他们参加有相同问题的笔试，他们的表现会与他们在智力竞赛节目中的表现不同）。这似乎应该受到他们在智力竞赛节目中回答的问题数量的影响。
贝叶斯方法（例如标准贝叶斯、经验贝叶斯）可用于尝试估计“修正”这些玩家的得分比例是多少？
这是我的想法。

标准贝叶斯：对于每个玩家$i$：


$\theta_i$是他们正确回答问题的真实概率
$n_i$是他们尝试的问题数量
$y_i$是正确答案的数量

每个玩家的似然函数遵循二项分布：
$$y_i|\theta_i \sim \text{Binomial}(n_i, \theta_i)$$
$$\theta_i \sim \text{Beta}(\alpha, \beta)$$
$$\theta_i|y_i \sim \text{Beta}(\alpha + y_i, \beta + n_i - y_i)$$
$$E[\theta_i|y_i] = \frac{\alpha + y_i}{\alpha + \beta + n_i}$$
我不确定经验贝叶斯在这里会如何使用。这些方法对这个问题有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660260/bayesian-analysis-of-jeopardy-players</guid>
      <pubDate>Mon, 20 Jan 2025 04:23:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们不屏蔽 Transformer 中除了多头注意力之外的其他层？</title>
      <link>https://stats.stackexchange.com/questions/660247/why-we-dont-mask-other-layers-besides-the-multihead-attention-in-transformers</link>
      <description><![CDATA[通常在训练 NLP 任务时，我们需要将序列填充到 max_len，以便可以以批处理方式高效处理它们。但是，这些填充的标记不应影响训练（模型参数的更新），因为它们是“虚构的”。
每个人都在谈论掩盖注意力操作的必要性。这是有道理的，因为有效标记不应该关注虚拟标记。但是，我们仍然需要考虑到所有其他层（例如 FF 中的线性层、规范化层等）不受填充的影响。
为简单起见，考虑单个 Transformer-Encoder 层：

从图中可以清楚地看出，FF 和最后的规范化层将填充的标记作为其他每个标记进行处理（即相同且独立）。为了正确屏蔽所有层，我们应该屏蔽损失吗？
例如，假设我们想使用 Transformer 编码器对序列进行分类。我们传递一个形状为 (B, N, E) 的输入 x，其中 B 是批量大小，N 是最大序列长度，E 是嵌入维度。输出具有相同的形状，我们将使用它进行分类。我们可以通过为每个序列提取一个“全局”向量来实现，然后将其传递给特定于任务的头部，如下所示：
x =coder_layer(x)
x = x.mask_fill(mask, -torch.inf) # 在最大操作期间屏蔽填充。
x = torch.max(x, dim=1)[0] # 忽略索引，简化为形状 (B, E)。
loss = loss_fn(cls_head(x), y)

由于 max 操作对任何未选定元素返回 0 梯度，因此所有参数都不会受到填充的影响。我的理解正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660247/why-we-dont-mask-other-layers-besides-the-multihead-attention-in-transformers</guid>
      <pubDate>Sun, 19 Jan 2025 18:58:05 GMT</pubDate>
    </item>
    <item>
      <title>用于样本量估计的 Bootstrap。序数尺度。分布远离正态</title>
      <link>https://stats.stackexchange.com/questions/660200/bootstrap-for-sample-size-estimation-ordinal-scale-distribution-far-from-norma</link>
      <description><![CDATA[我们经常在约 100 个句子的测试翻译上比较人工翻译或机器翻译系统（每次实验中为 2 到 4 个）。
每个句子的翻译都由一名称职的翻译人员进行评分，通常为 5 分制，有时为 10 分制（分数通常为整数，但可以包括中点，例如 3.5），费用昂贵。这是我们的黄金标准，尽管不同评分者之间的结果并非 100% 一致。这意味着我正在寻找经验法则，而不是最严格的方法。
量表由口头描述定义（“小幅编辑”、“严重改变含义”等）。因此它们本质上是有序的，通常是倾斜的，有时是双峰的。
如果有两种翻译，则使用 Wilcoxon 检验来评估结果，如果有两种以上的翻译，则使用 Friedman 检验来评估结果。
如果我们无法拒绝原假设，我们可能想看看更大的样本是否有帮助。下面是我想要使用的算法。

从原始样本中生成引导样本。使用 Wilcoxon/Friedman 检验评估每个样本，并计算我们可以拒绝原假设的样本比例。这是我们估计的功效。

通过从原始样本中重复抽样来生成更大的样本，但这次取的项目要多于原始样本量。按照与上述第 (1) 点相同的方式估计检验功效。

不断增加生成的样本量，直到达到所需功效或样本量变得过大。


从实际角度来看，这有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660200/bootstrap-for-sample-size-estimation-ordinal-scale-distribution-far-from-norma</guid>
      <pubDate>Sat, 18 Jan 2025 12:37:22 GMT</pubDate>
    </item>
    <item>
      <title>如何根据诊断图改进线性模型</title>
      <link>https://stats.stackexchange.com/questions/660185/how-to-improve-linear-model-based-on-diagnostic-plots</link>
      <description><![CDATA[我一直在处理包含五个变量和一个响应的数据集，如下所示：
.CSV 文件
使用 Python，我从以下代码开始：
import statsmodels.api as sm
import numpy as np
X = subset[[&#39;X1&#39;, &#39;X2&#39;, &#39;X3&#39;, &#39;X4&#39;]]
y = subset[&#39;Y&#39;]
X = sm.add_constant(X)
model = sm.OLS(y, X)
result = model.fit()
plt.figure(figsize=(8, 6))
plt.scatter(fitted_values, residuals, color=&#39;blue&#39;, edgecolors=&#39;k&#39;, alpha=0.7)
plt.axhline(y=0, color=&#39;red&#39;, linestyle=&#39;--&#39;)
plt.title(&#39;残差 x 预测值&#39;)
plt.xlabel(&#39;预测值&#39;)
plt.ylabel(&#39;残差&#39;)
plt.show()

给出模型摘要：

我不知道如何处理“残差 x 预测图”的结果。在探索性分析过程中，我发现这些变量与 Y 有中等相关性，因此我选择它们来构建初始模型。从该图中，我们可以说方差不是恒定的吗？此外，从这种模式中，我们可以获得有关如何改进模型的任何见解吗？

我尝试对 X 变量应用对数或 box-cox 变换，但它并没有改变变量散点图的可视化。我考虑过应用加权最小二乘法，例如，对 Y 大于 100 的位置赋予较低的权重，但图并没有改善，模式几乎相同。或者如果它真的是一个非线性问题，我想如果一些机器学习方法在这里可以更好地发挥作用，但我首先想尝试基本方法。
如果有人能提供一些想法/代码来处理这种情况，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660185/how-to-improve-linear-model-based-on-diagnostic-plots</guid>
      <pubDate>Fri, 17 Jan 2025 20:39:09 GMT</pubDate>
    </item>
    <item>
      <title>连续随机变量的充分统计量的因式分解定理</title>
      <link>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics-in-case-of-continuous-random-var</link>
      <description><![CDATA[根据因式分解定理 (Fisher-Neyman)，我们得到一个统计量 $ T(X) $ 充分当且仅当存在因式分解：$ f(x\mid \theta) = g(T(x)\mid \theta)h(x) $。符号遵循 Casella/Berger 第页。 276.
Casella/Berger 在离散情况下给出了证明，指出具体分解的形式如下：$$ P(X=x \mid {\theta}) = P(T(X) = T(x) \mid {\theta})P(X=x \mid T(X) = T(x)) $$
我的问题是：我们能否将这种解释应用于连续情况，并且它总是成立吗？因此：$ f(x\mid \theta) = f(T(x)\mid \theta)f(x\mid T(x)) $ 其中 $f$ 表示相应的 pdf？]]></description>
      <guid>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics-in-case-of-continuous-random-var</guid>
      <pubDate>Mon, 13 Jan 2025 22:52:25 GMT</pubDate>
    </item>
    <item>
      <title>我应该在层次聚类中翻转（否定）反相关变量吗？</title>
      <link>https://stats.stackexchange.com/questions/657447/should-i-flip-negate-anticorrelated-variables-in-hierarchical-clustering</link>
      <description><![CDATA[在层次聚类中，我有一个变量似乎与其他变量编码方向相反。它与大多数其他变量呈负相关。（例如下面的变量 3）

我想找出哪些变量彼此之间最相关。方向是任意的，与科学问题无关。两个问题：

我是否需要翻转（即否定）一个明显被否定的变量，以防止它成为一个单独的集群？
如果我们不知道变量是否被翻转，是否有规则来决定何时翻转它们？例如，“如果 $r_{i,j}&lt;0$ 与其他变量的相关性超过 50%，则翻转变量 i”？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657447/should-i-flip-negate-anticorrelated-variables-in-hierarchical-clustering</guid>
      <pubDate>Mon, 18 Nov 2024 15:42:09 GMT</pubDate>
    </item>
    </channel>
</rss>