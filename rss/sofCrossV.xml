<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 09 Jun 2024 01:09:04 GMT</lastBuildDate>
    <item>
      <title>DeepWalk 和 node2vec 如何处理具有孤立节点的图？</title>
      <link>https://stats.stackexchange.com/questions/648885/how-do-deepwalk-and-node2vec-work-with-graphs-with-isolated-nodes</link>
      <description><![CDATA[我想知道诸如 DeepWalk 和 node2vec 之类的方法如何能够为具有孤立节点的图生成节点嵌入。这些方法从每个节点开始执行随机游走，作为生成嵌入过程的一部分。
但是，如果有一个节点 $v$ 没有传出边，我们如何从 $v$ 开始执行随机游走？这些算法能找到这种节点的嵌入吗？我在各自的论文中没有找到任何关于这方面的提及。]]></description>
      <guid>https://stats.stackexchange.com/questions/648885/how-do-deepwalk-and-node2vec-work-with-graphs-with-isolated-nodes</guid>
      <pubDate>Sun, 09 Jun 2024 00:17:26 GMT</pubDate>
    </item>
    <item>
      <title>我想使用 FB Prophet 插入缺失的时间序列数据，但它忽略了缺失间隔附近的数据</title>
      <link>https://stats.stackexchange.com/questions/648884/i-want-to-use-fb-prophet-to-interpolate-missing-time-series-data-but-it-is-igno</link>
      <description><![CDATA[我有一些有间隙的温度数据，需要将其插入到统一的时间序列中（并进行一些外推）。我正在尝试使用 FB Prophet，它看起来几乎完美。然而......
如果您查看图表，您会发现，如果缺失数据远离每日极值，那么 Prophet 就没问题。但是当缺失数据接近每日最大值/最小值时，它会忽略测量数据。
我确实看到 changepoint_prior_scale 是一个需要调整的参数，但它似乎没有多大作用。
还有其他参数我应该尝试吗？
df_p = df[[&quot;Time&quot;,&quot;Temperature&quot;]].copy()
df_p = df_p.rename(columns={&quot;Time&quot;:&quot;ds&quot;, &quot;Temperature&quot;: &quot;y&quot;})

model = Prophet(changepoint_prior_scale=0.1)
model.fit(df_p.dropna())
end = end=df_p[&#39;ds&#39;].iloc[-1] + pd.Timedelta(1,&quot;d&quot;)
uniform_dates = pd.date_range(start=df_p[&#39;ds&#39;].iloc[0], end=end, freq=&#39;15T&#39;)
uniform_df = pd.DataFrame({&#39;ds&#39;: uniform_dates})

#
# 填写值
#
forecast = model.predict(uniform_df)

plt.plot(df_p[&quot;ds&quot;],df_p[&quot;y&quot;],&#39;o&#39;,markersize=1)
plt.plot(forecast[&quot;ds&quot;],预测[&quot;yhat&quot;])
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/648884/i-want-to-use-fb-prophet-to-interpolate-missing-time-series-data-but-it-is-igno</guid>
      <pubDate>Sun, 09 Jun 2024 00:17:04 GMT</pubDate>
    </item>
    <item>
      <title>协变量模式和饱和模型</title>
      <link>https://stats.stackexchange.com/questions/648883/covariate-patterns-and-saturated-model</link>
      <description><![CDATA[一个逻辑回归模型已拟合到包含 n = 27 个不同协变量模式的样本，
其中 ni = 10 个单位。
相应饱和模型中的参数数量是 27 还是 26（不包括截距）？]]></description>
      <guid>https://stats.stackexchange.com/questions/648883/covariate-patterns-and-saturated-model</guid>
      <pubDate>Sat, 08 Jun 2024 21:41:29 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯状态空间建模</title>
      <link>https://stats.stackexchange.com/questions/648882/bayesian-state-space-modelling</link>
      <description><![CDATA[频率派和贝叶斯派状态空间建模方法的主要区别是什么？它们都假设初始状态参数遵循随机游走吗？
此外，根据我的理解，贝叶斯状态空间建模使用 MCMC 方法来更新初始状态参数。如果这是真的，频率派方法是否假设时变系数模型的分布是固定的？]]></description>
      <guid>https://stats.stackexchange.com/questions/648882/bayesian-state-space-modelling</guid>
      <pubDate>Sat, 08 Jun 2024 21:03:16 GMT</pubDate>
    </item>
    <item>
      <title>三次拟合的误差与 y 数据的数量级有关，而不是与拟合质量有关</title>
      <link>https://stats.stackexchange.com/questions/648881/errors-on-cubic-fits-are-relative-to-the-order-of-magnitude-of-the-y-data-not-f</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648881/errors-on-cubic-fits-are-relative-to-the-order-of-magnitude-of-the-y-data-not-f</guid>
      <pubDate>Sat, 08 Jun 2024 21:00:05 GMT</pubDate>
    </item>
    <item>
      <title>如何处理固定效应和随机效应之间的方差竞争？</title>
      <link>https://stats.stackexchange.com/questions/648880/how-to-deal-with-competition-for-variance-between-a-fixed-and-random-effect</link>
      <description><![CDATA[我正在对数据进行分析，其中 X（预测变量）和 Y（响应）在广泛范围内存在假设关系，但由于预测变量的局部混合，在观察组中是随机的（无关系）。一个有趣的类比可能是餐厅里的杂烩碗，每个碗里都有不同数量的扇贝，从 10 到 100 个不等（大碗）。一碗杂烩包含未知数量的扇贝（非常大的碗）。这是一种浓稠的杂烩，因此您只能用大勺“品尝”，大勺平均能舀出与碗中扇贝总数成比例的扇贝。您还可以用勺子品尝杂烩 - 扇贝密度越高，味道越浓。此外，整个碗的味道混合均匀。我们想要确定勺子上的扇贝数量和勺子上杂烩汤的味道之间的关系（我们假设味道是由碗决定的，而不是勺子上的扇贝）。我们从每个碗中取出几把勺子（忽略消耗 - 大碗）。我们想应用一个混合模型，以味道强度作为预测因子（OK 风味浓度），勺子上的扇贝数量作为响应，碗作为随机效应的分组变量。理想情况下，我们希望定义整个餐厅的味道和数量之间的关系。我们可以轻松地汇总每个碗中的味道和计数并获得整体关系 - 但这并不能解释碗内计数的变化。当应用混合模型时，随机效应似乎解释了所有的计数变化，而预测因子（味道）并不显着。有没有比“汇总”更好的方法？在混合模型框架内如何理解这种关系？
之前有人问过类似的问题（当固定和随机效应重叠时会发生什么？），但没有得到回答。我在本文末尾添加了一个简单的模拟来说明这个问题（遗憾的是我没有添加任何杂烩）。感谢您的考虑。
干杯，Darren
#
# 固定和随机效应方差竞争
#
library(mgcv)
# 模拟一些包含 8 个组的数据
slope = 1
sY = 1 # 组内变异性
sYbar = 0.2 # 组关系变异性

# 潜在关系
grpX &lt;- c(1,1,2,2,4,4,6,6) # 每组平均 X
grpYbar &lt;- slope*grpX + rnorm(length(grpX))*sYbar
plot(grpX,grpYbar)
cor(grpX,grpYbar)^2

# 执行 500 次模拟
#
# 每组模拟 5 个响应
grp &lt;- c(1,2,3,4,5,6,7,8)
replicate &lt;- c(1,2,3,4,5)
# 要保存在向量中的值
Xp &lt;- as.numeric(NULL)
Sp &lt;- as.numeric(NULL)
Bx &lt;- as.numeric(NULL)
#
for (dups in 1:500) {
#
simData &lt;- as.data.frame(list(grp=as.numeric(NULL),
replicate=as.numeric(NULL),
X=as.numeric(NULL),
Y=as.numeric(NULL)))
for (i in grp) {
for (j in replicate) {
g &lt;- grp[i]
r &lt;- replicate[j]
X &lt;- grpX[i] + rnorm(1)
Y &lt;- grpYbar[i] + rnorm(1)*sY
simData &lt;- rbind(simData,list(grp=g,
replicate=r,
X=X,
Y=Y))
}
}
#
s1 &lt;- gam(Y ~ X + s(grp, bs = &#39;re&#39;),
data=simData,method=&quot;REML&quot;)
#
Xp &lt;- c(Xp,summary(s1)$p.table[2,4])
Sp &lt;- c(Sp,summary(s1)$s.table[1,4])
Bx &lt;- c(Bx,summary(s1)$p.table[2,1])
#
}

# 绘制重要性
par(mfrow=c(2,2))
hist(Xp,main = &quot;斜率 p 值&quot;)
abline(v=0.05,lty=2,col=&quot;red&quot;)
hist(Sp,main = &quot;随机效应 p 值&quot;)
abline(v=0.05,lty=2,col=&quot;red&quot;)
plot(Xp,Sp)
hist(Bx)

# 显著斜率
sum(Xp&lt;0.05)
# 显著 RE
sum(Sp&lt;0.05)
# 显著斜率(行) 按 RE(col)
Xsig &lt;- Xp&lt;0.05
Ssig &lt;- Sp&lt;0.05
sigTableData &lt;- as.data.frame(list(Xsig=Xsig,
Ssig=Ssig))
table(sigTableData)
]]></description>
      <guid>https://stats.stackexchange.com/questions/648880/how-to-deal-with-competition-for-variance-between-a-fixed-and-random-effect</guid>
      <pubDate>Sat, 08 Jun 2024 20:13:46 GMT</pubDate>
    </item>
    <item>
      <title>高度相关的 IV 之间不存在多重共线性</title>
      <link>https://stats.stackexchange.com/questions/648878/no-multicollinearity-between-highly-correlated-ivs</link>
      <description><![CDATA[假设我正在构建一个多元回归模型，其中 y 为因变量，X1、X2、...、Xn 为自变量。我遇到过 2 个自变量之间存在高度相关性的情况，例如 X1 和 X2 相关性为 0.81，但这两个驱动因素的 VIF 均小于 2。
有人可以解释为什么这是可能的吗？普遍的理解是高相关性导致多重共线性，正如这篇文章所解释的那样。]]></description>
      <guid>https://stats.stackexchange.com/questions/648878/no-multicollinearity-between-highly-correlated-ivs</guid>
      <pubDate>Sat, 08 Jun 2024 19:16:59 GMT</pubDate>
    </item>
    <item>
      <title>我的新个体内变异统计数据有意义吗？</title>
      <link>https://stats.stackexchange.com/questions/648877/are-my-new-intraindividual-variability-statistics-sensical</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648877/are-my-new-intraindividual-variability-statistics-sensical</guid>
      <pubDate>Sat, 08 Jun 2024 18:05:17 GMT</pubDate>
    </item>
    <item>
      <title>两个国家死亡率的最佳测试</title>
      <link>https://stats.stackexchange.com/questions/648876/best-test-for-mortality-rate-in-two-countries</link>
      <description><![CDATA[我们试图比较两个不同国家 20 年内的死亡率。Mann Whitney u 检验法是否最适合使用？我们不清楚数据是否被假定为正态分布，因为这些数字只是每年的死亡人数。]]></description>
      <guid>https://stats.stackexchange.com/questions/648876/best-test-for-mortality-rate-in-two-countries</guid>
      <pubDate>Sat, 08 Jun 2024 17:21:58 GMT</pubDate>
    </item>
    <item>
      <title>构建变量选择的子组比较</title>
      <link>https://stats.stackexchange.com/questions/648874/constructing-subgroup-comparisons-for-variable-selection</link>
      <description><![CDATA[我正尝试根据以下描述构建一个协变量：

在构建协变量以测量子组效应时，我们生成协变量来捕获给定子组中给定变量的因果效应。协变量的构建方式是，在每个子组中，治疗组和对照组形成对比；在子组之外，协变量设置为零。
此协变量的构建方式是，回归此协变量的结果的系数给出该子组中均值的差异。它通过将子组的观察值归零来实现这一点，但在该子组中创建治疗组和对照组之间的对比。请注意，可以构建此协变量来将治疗条件 k 中的那些与其他条件进行对比。该协变量将除 k 之外的所有治疗水平视为

基线，因此该协变量的系数应解释为

给定治疗与该变量的所有其他治疗水平的平均值之间的平均差异。

Ratkovic, M. (2021)。子组分析：陷阱、承诺和诚实。在 J. N. Druckman &amp; D. P. Green (Eds.) 中，实验政治科学进展 (第 271-288 页)。剑桥大学出版社。
我不确定如何构建这些子组协变量。这些协变量的目的是将它们中的许多变量包含在套索模型中以选择最重要的变量。由于我们有兴趣发现治疗效果的异质性，因此协变量应该代表子组内治疗和对照之间的均值差异（或如最后一句所述，总和对比差异）。如果协变量或相互作用意味着其他东西，那么您将调整错误的效应。
这些协变量应该如何编码？我在想也许可以将子组内控制编码为 -0.5，将子组内治疗编码为 0.5，将子组外的所有其他内容编码为 0。但您仍然必须在套索模型中排除一个类别，对吗？
我说得对，简单的治疗 x 子组方法不行吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648874/constructing-subgroup-comparisons-for-variable-selection</guid>
      <pubDate>Sat, 08 Jun 2024 16:43:55 GMT</pubDate>
    </item>
    <item>
      <title>假设残差在模型构建时与预测变量不相关，何时违反 E[Xi*ui]=0？</title>
      <link>https://stats.stackexchange.com/questions/648873/when-is-exiui-0-violated-given-that-the-residuals-are-by-construction-of-the</link>
      <description><![CDATA[首先：我知道“误差项”和“残差”是两个不同的概念。但是，我很难理解它们对（多元）线性回归和线性投影模型的影响。
在我的课堂上，我们为任何 PRF（不一定是线性）引入了一个线性投影模型，其中一个关键概念是正交性：
E[Xi*ui)=0（其中 0 是 (k+1)*1 向量）。
如果模型中有一个常数，则 Xi 和 ui 不相关。假设这里的 ui 是误差项，我不明白如果误差项和预测因子有任何关联，那么该属性（无关联）如何成立。

我不明白如何识别 E[Xi * ui]。如果 Xi 和 ui 相关，那么 Xi 和残差在构造上仍然不相关，我假设我们将使用残差来识别 E[Xi * ui]，因为我们无法观察到 ui。

如果 Xi 和 ui 相关，这是否意味着 E[Xi *ui) 不等于零？

何时违反 E[Xi * ui]= 0？我们如何识别任何违规行为？


我希望我的问题有意义，提前谢谢您 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/648873/when-is-exiui-0-violated-given-that-the-residuals-are-by-construction-of-the</guid>
      <pubDate>Sat, 08 Jun 2024 16:34:09 GMT</pubDate>
    </item>
    <item>
      <title>Cholesky 分解和 OLS 比较方法 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648872/cholesky-decomposition-and-comparing-methods-for-ols</link>
      <description><![CDATA[我一直在比较各种方法的速度和准确性，以找到最小二乘解。

$\beta = (X^TX)^{-1}X^Ty$
$R\beta = Q^Ty$ 和使用正向/反向替换进行 QR 因式分解求解
$\beta = V\Sigma^{-1}U^Ty$ 使用 SVD
$\beta = R^{-1}Q^Ty$
$L = Chol(X^TX)$，正向求解 $Z$：$LZ = X^Ty$，反向求解 $\beta$：$L^T\beta = Z$
$LU = X^TX$，正向求解 $Z$：$LZ = X^Ty$，反向求解 $\beta$：$U\beta = Z$

但是，$LU$ 和 Cholesky 得出的 MSE 比其他方法高得多。我的数据的条件数并不高，为 1.14，并且分解没有明显的精度损失。
L = np.linalg.cholesky(df.T.dot(df))
np.power(df.T.dot(df) - pd.DataFrame(L@L.T), 2).sum().sum() 
7.722374477305186e-22

结果：
QR w Triang Solve；平均时间=0.505；标准时间=0.307；MSE = 25.075
Numpy Inverse；平均时间=0.108；标准时间=0.035；MSE = 25.075
SVD Inverse；平均时间=0.353；标准时间=0.128；MSE = 25.075
R 的 QR 逆变换；平均时间=0.32；标准时间=0.115；MSE = 25.075
Cholesky；平均时间=0.064；标准时间=0.007；MSE = 46.143
LU；平均时间=0.109；标准时间=0.018； MSE = 46.143
问题：

我是否正确地执行了 Cholesky 和 ​​LU？
如果我做得正确，为什么 MSE 相对于其他方法如此之高？
为什么 numpy inverse 比其他方法（如 QR）快得多？我认为逆运算应该是昂贵的。

import time
import scipy
import numpy as np
import pandas as pd
from numba import jit

def print_info(method, times, mse):
print(f&quot;{method}; mean time={round(np.mean(times), 3)}; std time = {round(np.std(times), 3)}; MSE = {round(mse, 3)}&quot;)

np.random.seed(17)
ITERS = 10
SAMPLES = 20000
FEATURES = 100
df = pd.DataFrame(np.random.normal(size=(SAMPLES, FEATURES)))
df[&quot;intercept&quot;] = 1
BETA = np.random.normal(3, 10, size=FEATURES+1)
y = df.dot(BETA) + np.random.normal(0, 5, size=SAMPLES)

times = []
for i in range(ITERS):
start = time.time()
Q, R = np.linalg.qr(df)
beta = scipy.linalg.solve_triangular(R, Q.T.dot(y), check_finite=False)
times.append(time.time()-start)
print_info(&quot;QR w Triang Solve&quot;, times, np.mean((y-df.dot(beta))**2))

times = []
for i in range(ITERS):
start = time.time()
beta = np.linalg.inv(df.T.dot(df)).dot(df.T).dot(y)
times.append(time.time()-start)
print_info(&quot;Numpy Inverse&quot;, times, np.mean((y-df.dot(beta))**2))

times = []
for i in range(ITERS):
start = time.time()
U, s, Vh = np.linalg.svd(df, full_matrices=False)
beta = ((y.T@U)@np.diag(1/s))@Vh
times.append(time.time()-start)
print_info(&quot;SVD Inverse&quot;, times, np.mean((y-df.dot(beta))**2))

times = []
for i in range(ITERS):
start = time.time()
Q, R = np.linalg.qr(df)
beta = np.linalg.inv(R).dot(Q.T).dot(y)
times.append(time.time()-start)
print_info(&quot;QR Inv of R&quot;, times, np.mean((y-df.dot(beta))**2))

times = []
for i in range(ITERS):
start = time.time()
L = np.linalg.cholesky(df.T.dot(df))
Z = scipy.linalg.solve_triangular(L, df.T.dot(y), check_finite=False)
beta = scipy.linalg.solve_triangular(L.T, Z, check_finite=False)
times.append(time.time()-start)
print_info(&quot;Cholesky&quot;, times, np.mean((y-df.dot(beta))**2))

times = []
for i in range(ITERS):
start = time.time()
L, P, U = scipy.linalg.lu(df.T.dot(df), permute_l=False)
Z = scipy.linalg.solve_triangular(L, df.T.dot(y), check_finite=False)
beta = scipy.linalg.solve_triangular(U, Z, check_finite=False)
times.append(time.time()-start)
print_info(&quot;LU&quot;, times, np.mean((y-df.dot(beta))**2))

]]></description>
      <guid>https://stats.stackexchange.com/questions/648872/cholesky-decomposition-and-comparing-methods-for-ols</guid>
      <pubDate>Sat, 08 Jun 2024 16:19:45 GMT</pubDate>
    </item>
    <item>
      <title>在什么条件下，省略变量的回归的其余系数会相对于完整回归中的系数进行“缩放”？</title>
      <link>https://stats.stackexchange.com/questions/648871/under-what-conditions-are-the-remaining-coefficients-of-a-regression-with-a-vari</link>
      <description><![CDATA[我正在阅读这篇文章讨论了从回归方程中省略变量的影响，并分析了它将产生的影响。
这是他们使用的一些符号：给定一个数据矩阵$X$，响应变量$y$，我们有回归系数的正态方程：
$$\widehat{\beta} = (X&#39;X)^{-1}X&#39;y$$
现在假设我们省略了一些变量 z。如果我们重新运行包含该变量的回归，我们将得到新的回归系数$\beta, \gamma$，这样
$$y \sim X\beta + z\gamma$$
然后，他们给出了带有省略变量的回归系数的方程，该方程是完整回归系数的方程：
$$\widehat{\beta} = (X&#39;X)^{-1}X&#39;y=(X&#39;X)^{-1}X&#39;(X\beta + z\gamma + \epsilon)$$
$$=(X&#39;X)^{-1}X&#39;X\beta +(X&#39;X)^{-1}X&#39;z\gamma + (X&#39;X)^{-1}X&#39;\epsilon $$
在我的特定情况下，X 中的每个回归变量都是随机（不相关）伯努利变量，取值范围为 $\{0,1\}$，因此它们都具有相同的均值和方差，没有协方差。
我试图使用上述分析来理解以下条件成立的条件：当我们省略一个变量时，其余系数都会按比例缩放，因此当所有系数都设置为 1 时，预测值与之前保持不变。
换句话说，假设当完整回归中的所有回归变量都设置为 1（即所有回归变量的总和）：
$$C=\widehat{\beta}\mathbf{1}+\gamma$$
在什么条件下$$\widehat{\beta} = \frac{\beta}{C-\gamma}成立？$$
我的直觉是，在我的特殊情况下应该是这种情况，我正在尝试证明它是否正确。我认为它应该是真的的原因是，当你省略变量时，所有回归变量设置为 1 时的预测会太低，需要扩大。由于所有变量都具有相同的方差且没有相关性，我认为它们都应该按相同的比例增加。
有人能帮我证明这个说法吗？或者根据我的特殊情况的限制，证明另一个同样简单但实际上正确的说法？
不幸的是，从上面的数学运算来看，由于$X$和$z$中的每个回归量都是不相关的，$X&#39;z=0$，因此不完全回归中的回归系数不应出现预期的“膨胀”。但这似乎不正确……
谢谢，
保罗]]></description>
      <guid>https://stats.stackexchange.com/questions/648871/under-what-conditions-are-the-remaining-coefficients-of-a-regression-with-a-vari</guid>
      <pubDate>Sat, 08 Jun 2024 16:05:55 GMT</pubDate>
    </item>
    <item>
      <title>Mplus中的两级多组模型[关闭]</title>
      <link>https://stats.stackexchange.com/questions/648864/twolevel-multgroup-model-in-mplus</link>
      <description><![CDATA[我想使用 Mplus 运行具有两个组的两级多组模型（例如用户指南中的示例 9.11）。
我的问题：我有一个独立变量 X，该变量在 A 组中仅在 2 级单位之间变化，即 X 是 A 组中的仅间变量。
因此，我将 X 指定为“between=”变量。然而，在 B 组中，相同的独立变量 X 在组间和组内都变化。是否有可能估计这样的模型 - 如果可以，如何估计？]]></description>
      <guid>https://stats.stackexchange.com/questions/648864/twolevel-multgroup-model-in-mplus</guid>
      <pubDate>Sat, 08 Jun 2024 10:22:41 GMT</pubDate>
    </item>
    <item>
      <title>估计样本的概率密度</title>
      <link>https://stats.stackexchange.com/questions/648819/estimating-probability-density-for-sample</link>
      <description><![CDATA[我有一个包含 20,000 多个样本的数据集。这里的目标是为样本定义一个分布，以便我可以绘制所有可能的结果。但是，我无法找到可用于估计概率密度的适当分布。我尝试使用正态分布、柯西分布、拉普拉斯分布、学生 T 分布和威布尔分布来测试样本。在所有情况下，Kolmogorov-Smirnov 检验都拒绝了我的样本遵循上述任何分布的可能性。我也尝试使用 KDE 进行估计，但结果并不理想。我尝试使用 KS 检验来检查 KDE 和我的样本之间的相似性，但即使在这里相似性也被拒绝了。我不知道下一步该怎么做才能估算出概率密度。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648819/estimating-probability-density-for-sample</guid>
      <pubDate>Fri, 07 Jun 2024 13:27:34 GMT</pubDate>
    </item>
    </channel>
</rss>