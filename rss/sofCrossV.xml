<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 22 Dec 2024 21:14:27 GMT</lastBuildDate>
    <item>
      <title>元分析中嵌套数据的模型简化</title>
      <link>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</link>
      <description><![CDATA[我正在对子组中不同程度的异质性进行荟萃分析。由于数据结构是嵌套的（效应大小嵌套在研究中），我通过添加研究的随机效应和研究内的效应大小来考虑这一点。轮廓似然图在其估计值处达到峰值。
比较具有不同程度异质性的模型和具有共同异质性估计值的模型的似然比检验是显著的。然而，在获得 $ \tau^2_\text{between} $ 和 $ \tau^2_\text{within} $ 的置信区间 (CI) 后，除了一个之外，$ \tau^2_\text{within} $ 的所有 CI 的下限均为零。一个显著的估计值仍然是适中的。
在这种情况下，将模型简化为标准（两级）随机效应模型，仅考虑研究之间的差异是否合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</guid>
      <pubDate>Sun, 22 Dec 2024 20:41:46 GMT</pubDate>
    </item>
    <item>
      <title>R 边际效应包：估计中断时间序列中预测的减去反事实的绝对/相对变化的 95% 可信区间</title>
      <link>https://stats.stackexchange.com/questions/659105/r-marginaleffects-package-estimate-95-ci-for-predicted-minus-counterfactual-ab</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659105/r-marginaleffects-package-estimate-95-ci-for-predicted-minus-counterfactual-ab</guid>
      <pubDate>Sun, 22 Dec 2024 20:40:03 GMT</pubDate>
    </item>
    <item>
      <title>输入目的二分变量和序数变量之间的差异</title>
      <link>https://stats.stackexchange.com/questions/659103/difference-between-dichotomous-and-ordinal-variable-for-inputation-purposes</link>
      <description><![CDATA[我正在阅读 Amelia R 包的文档。
在文档的序数部分中，写到序数变量包括二分变量，其中一个例子是性别，它应该被视为序数变量，如果 0 表示男性，1 表示女性，则输入值 0.79 是完全可以接受的。
但是在名义部分中，它说另一个名为 signed 的变量，如果一个国家在当年签署了 IMF 协议，则该变量为 1如果没有，则为 0，应将其视为名义变量，并且只接受 0 和 1 值。浮点变量不可接受。
为什么性别可以被视为序数，而有符号则不能？
输入的签名值为 0.79 有什么问题，这意味着该国签署协议的概率为 79%？
相关：我们可以将性别视为序数变量吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659103/difference-between-dichotomous-and-ordinal-variable-for-inputation-purposes</guid>
      <pubDate>Sun, 22 Dec 2024 20:10:12 GMT</pubDate>
    </item>
    <item>
      <title>去趋势波动分析</title>
      <link>https://stats.stackexchange.com/questions/659102/detrended-fluctuation-analysis</link>
      <description><![CDATA[在 R 中，我尝试实现中描述的 DFA 时间序列分析算法
https://en.wikipedia.org/wiki/Detrend_fluctuation_analysis
和
https://www.kubios.com/blog/hrv-analysis-方法/
对于运动/训练教练朋友。有运动生理学研究建议使用 RR 间隔心跳时间序列（约 200 次心跳窗口）作为 DFA 低 n 系列 alpha 系数的输入，作为个人维持最佳心脏努力量的指导，而不是分配每个人在锻炼的某些部分都有相同的功率或心率目标（大致如下：&gt;~1.2 锻炼不够努力 &lt;~0.5 锻炼太努力。
为了测试我的 R 实现，我构建了白噪声使用 R 的 rnorm 函数对序列进行分析。但是，为了获得白噪声的 ~0.5 alpha 和随机游走的 ~1.5 alpha，我必须将每个的累积和输入到算法中。
此外，对于实际锻炼数据，我还需要输入 RR 锻炼系列的累计总和，以获得与 Garmin 应用程序针对相同锻炼的 alpha 输出相匹配的结果。
目前，我让我的朋友使用并相信我的 R 例程输出，输入 RR 系列和额外的累积和。但我担心我遗漏了一些基本的东西。我认为我遗漏的概念与我的白噪声系列有关，从任意开始（不一定是相等/离散时间）采样...在某种程度上，类似于心跳 RR 系列采样创建的时间尺度，由运动员的神经系统告诉身体下一次跳动的时间控制...但是我找不到任何关于 DFA 的在线讨论或参考文献中关于这个细微差别的讨论。我读到的所有内容似乎都表明你应该输入采样的白噪声流或原始 RR 流，而不是它们的累积和（因为第一步算法是另一个减去平均值的累积和，看起来累积和开始加起来了。）
有什么见解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659102/detrended-fluctuation-analysis</guid>
      <pubDate>Sun, 22 Dec 2024 19:53:36 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中对分数数据进行建模</title>
      <link>https://stats.stackexchange.com/questions/659095/modelling-fractional-data-in-r</link>
      <description><![CDATA[我有以下一组数据，其中响应变量是比例数据
dat = structure(list(Y = c(0.0104, 0.01044, 0.00809, 0.00413, 0.00634, 
0.0021, 0.00729, 0.02386, 0.00722, 0.0109, 0.00873, 0.00647, 
0.00611, 0.02342, 0.01818, 0.0176, 0.01865, 0.00546, 0.00515, 
0.02477, 0.00625, 0.01538), X = c(0.01077, 0.01956, 0.02298, 
0.10304, 0.02963, 0.04887, 0.01589, 0.00519, 0.05161, 0.00357, 
0.02279, 0.02733, 0.07581, 0.03643, 0.03257, 0.03324, 0.0509, 
0.05552, 0.08214, 0.01031, 0.08347, 0.02489)), row.names = c(NA, 
-22L), class = &quot;data.frame&quot;)

在我的例子中，Y 是比例数据。因此我想用 分数逻辑模型 拟合这些数据，如下所示
&gt; summary(glm(&quot;Y ~ X&quot;, dat = dat, family = binomial()))

调用：
glm(formula = &quot;Y ~ X&quot;, family = binomial(), data = dat)

系数：
估计标准差。误差 z 值 Pr(&gt;|z|)
(截距) -4.043 3.381 -1.196 0.232
X -12.650 88.094 -0.144 0.886

(二项式系列的分散参数取为 1)

零偏差：21 个自由度上的 0.086252
残差偏差：20 个自由度上的 0.063149
AIC：4.4969

Fisher 评分迭代次数：8

这表明变量 X 非常不显著
这是违反直觉的，因为 Y 和 X 之间存在显著相关性
现在，我拟合一个 简单线性回归，然后我得到显著X 变量
&gt; library(dplyr)
&gt; summary(glm(&quot;Z ~ X&quot;, dat = dat %&gt;% mutate(Z = log(Y / (1-Y)))))

调用：
glm(formula = &quot;Z ~ X&quot;, data = dat %&gt;% mutate(Z = log(Y/(1 - Y))))

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) -4.1740 0.2074 -20.129 9.55e-15 ***
X -12.7358 4.4171 -2.883 0.00919 ** 
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（高斯族的分散参数取为 0.3104897）

零偏差：21 个自由度上的 8.7910
残差偏差：20 个自由度上的 6.2098
AIC：40.605

Fisher 评分迭代次数：2

您能帮我理解为什么我的第一个使用 glm() 的模型无法显示显著的 X 变量吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659095/modelling-fractional-data-in-r</guid>
      <pubDate>Sun, 22 Dec 2024 14:22:40 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯定理助力赢得第二次世界大战</title>
      <link>https://stats.stackexchange.com/questions/659076/bayes-theorem-helps-win-world-war-ii</link>
      <description><![CDATA[有没有人读过这篇文章 (https://towardsdatascience.com/how-bayes-theorem-helped-win-the-second-world-war-7f3be5f4676c)，或者非常熟悉贝叶斯定理如何帮助二战。这是我能找到的“最好的”文章，在某种程度上说明了它是如何使用的，但他们让读者“填空”，读过这篇文章大约十几遍后，我希望得到一些帮助。这是我真正挣扎的文章部分。

盟军已经了解了日本密码本的一部分，许多密码组都是已知的。这些被称为“好组”，并与其（非携带）差异（V）一起制成表格。如果已知 50 个组，则必须计算并记录 1225 个差异。
密码分析师会比较从截获的消息和好组中计算出的差异。如果找到匹配项（在我们的例子中为 22571，以红色显示），则计算假设的加法（以绿色显示）。
最后也是最重要的任务是测试这个假设的加法的有效性。作为第一步，从每条消息中相应的编码字中减去加法（VI）。如果生成的代码（以蓝色显示）违反了“可被 3 整除”规则，则可以快速丢弃加法，从而为盟军节省大量时间。通常，多种潜在添加剂都会通过此测试，因此使用统计分析来确定它们的相对强度。

有人可以对这部分进行详细解释吗？我发现它很有趣，但计算结果极其罕见，甚至不可能找到。我将永远感激不尽谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659076/bayes-theorem-helps-win-world-war-ii</guid>
      <pubDate>Sun, 22 Dec 2024 01:30:25 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据插补生成方法背后的直觉</title>
      <link>https://stats.stackexchange.com/questions/659075/intuition-behind-generative-methods-for-imputing-missing-data</link>
      <description><![CDATA[我正在学习不同的方法来估算混合连续和分类变量的表格数据集，并且假设数据完全随机缺失。我使用频率编码器转换了分类数据，因此所有内容都是数字或 NaN。
我认为平均值、中位数等估算过于简单且容易产生偏差。我正在考虑更复杂的方法，例如确定性和生成性。
对于确定性，我尝试了 LightGBM，它非常直观。我喜欢它。基本上，对于每个具有缺失数据的特征，其非缺失数据作为对其他特征的回归，然后预测/估算缺失数据。很棒。
现在我尝试使用深度学习方法，例如 AE 或 GAN。通过查阅文献，这似乎非常可行且非常有效。但黑匣子很难理解。例如，对于 VAE，我们是否只是简单地基于整个表格数据构建一个 VAE 模型，然后“以某种方式”预测/生成/估算缺失数据？
我仍在研究这个问题以获得更清晰的解释，但我希望也尝试过估算表格数据的人可以分享一些经验。]]></description>
      <guid>https://stats.stackexchange.com/questions/659075/intuition-behind-generative-methods-for-imputing-missing-data</guid>
      <pubDate>Sun, 22 Dec 2024 01:27:59 GMT</pubDate>
    </item>
    <item>
      <title>在评估 GLM 模型时，AIC 值或预测显著性的 p 值更重要吗？</title>
      <link>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</guid>
      <pubDate>Sat, 21 Dec 2024 15:14:21 GMT</pubDate>
    </item>
    <item>
      <title>利用 MSE 进行快速搜索</title>
      <link>https://stats.stackexchange.com/questions/659043/exploiting-mse-for-fast-search</link>
      <description><![CDATA[我有一个巨大的二进制向量数据库。给定一个传入向量，我想在数据库中找到 MSE 最接近的向量并返回 MSE 分数。到目前为止，我一直在手动进行此搜索，但花费的时间太长了。
我可以利用 MSE 与二进制向量一起使用时的特性来加快搜索速度吗？
更多详细信息：我正在寻找。我可以利用的 MSE 或二进制向量或数据稀疏性的属性来显着加快搜索速度！我的数据集有大约 400 万个高维（~4000）二进制向量，其中大部分是稀疏的（包含大量零）。我有一个循环，逐个遍历 400 万个向量并返回 MSE 分数最低的向量。我不能使用任何其他指标，并且在考虑是否可以利用 MSE 的任何属性来加快搜索速度。即使可以使用使用 MSE 的 ML 模型，它也会很完美]]></description>
      <guid>https://stats.stackexchange.com/questions/659043/exploiting-mse-for-fast-search</guid>
      <pubDate>Sat, 21 Dec 2024 01:58:16 GMT</pubDate>
    </item>
    <item>
      <title>使用麦当劳 Omega 作为非加权总和评分的可靠性度量是合理的</title>
      <link>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</link>
      <description><![CDATA[在最近的文献中，报告麦当劳欧米茄作为可靠性估计值显然比报告系数 alpha 更受欢迎（例如 McNeish，2017）。一个经常给出的论点是，系数 alpha（或 Cronbach&#39;s alpha）假设（本质上）tau-euqivalent 测量模型，即因子载荷必须相等，而麦当劳欧米茄允许不同的载荷。由于对 omega 有多种看法，为了简单起见，我们只关注单维尺度上的总 omega，如 McNeish (2017) 所指定的那样：

（其中 $\lambda_i$ 是因子载荷，$\theta_{ii}$ 是第 i 项的误差/残差方差）
在文章中，McNeish 写道：

Omega (McDonald, 1970, 1999）是常用的复合信度测量方法，可用于多种软件程序。Omega 专为同类量表而设计，其中项目与被测构造的相关程度各不相同（即，在因子分析设置中，不会假设负载相等）。换句话说，不假设 tau 等价。当量表中的项目按单位加权以形成总量表分数但量表本身为同类时，复合信度是合适的（Bentler，2007；Geldhof 等人，2014）。单位加权量表意味着量表的总分是通过将各个项目的原始分数（或反向编码的原始分数，如果适用）相加来计算的：每个项目的权重相等。

我觉得这违反直觉：例如，假设 CFA 表明同类模型（自由载荷）比更严格的 tau 等效模型更适合样本数据，因此我们决定使用 omega 而不是系数 alpha。然而，后续分析将使用基于同等权重项目计算得出的总和/平均分数，尽管我们刚刚在 CFA 中表明这种类型的测量模型无法很好地拟合我们的数据。
我的问题：
有人能否提供一些合理的解释，为什么对于由同等权重项目组成的分数，报告麦当劳的 omega 是有意义的？

来源：
McNeish，D. (2017)。感谢系数 alpha，我们将从这里开始。心理方法，23(3)，412–433。https://doi.org/10.1037/met0000144]]></description>
      <guid>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</guid>
      <pubDate>Fri, 20 Dec 2024 12:24:36 GMT</pubDate>
    </item>
    <item>
      <title>分位数的贝叶斯区间估计</title>
      <link>https://stats.stackexchange.com/questions/658982/bayesian-interval-estimate-for-a-quantile</link>
      <description><![CDATA[这个问题是为了澄清后验分布和后验预测分布是否可用于创建分位数的区间估计。考虑以下设置：
假设我有 $X_i\stackrel{iid}{\sim} N(\mu, \sigma^2)$，其中 $i=1,...,n$。为了论证的目的，我并不关心先验的形式是什么，但让我们假设我在 $\mu$ 和 $\sigma^2$ 上都放置了先验。现在，我可以运行我的 MCMC 采样器并获取 $\mu$ 和 $\sigma^2$ 的后验样本（我们将它们称为 $\mu_{*b}$ 和 $\sigma^2_{*b}$，其中我有 $b=1,...,B$ 个）。现在，给定 $X_i$ 的分布，我可以通过以下方式获得后验样本，例如第 95 分位数：
$$q_b= \mu_{*b} + z_{0.95}\sigma_{*b}$$
其中 $z_{0.95}$ 是标准正态分布的第 95 分位数。此外，由于这是基于样本的，我有一个后验分位数的分布，并且可以取这些后验分位数样本的分位数来获得不确定性区间估计。到目前为止一切顺利。
现在，我很好奇是否有办法使用后验预测分布来做到这一点？例如，在相同的设置下，后验预测分布可能是 $y_{\text{new}}\sim N(\mu_{\text{new}}, \sigma^2_{\text{new}})$，因此我可以模拟该分布的 $y_{\text{new}}$ 值并取第 95 分位数来估计它。但是，这个估计没有像后验分布那样的不确定性量化。我想总结一下我的问题，

基于后验分布和后验预测分布的结果是否应该匹配，并且
后验预测分布是否应该为第 95 分位数产生不确定性估计（以区间的形式）？


编辑以澄清：
似乎人们没有理解我的问题的要点，但也许是我自己的错，可能不够清楚。让我用 R 代码来说明我的观点：
&gt; ### 用于生成第 95 分位数估计的代码 
&gt; ### 并附带 90% 可信区间
&gt; 
&gt; ### 为了举例说明，假设我已经完成了后验 
&gt; ### 计算，并且我有： 
&gt; 
&gt; ### p(sigma^2 | X) ~ Gamma(3, 2)
&gt; ### p(mu | sigma, X) ~ N(200, sigma)
&gt; 
&gt; 
&gt; # 后验样本数
&gt; B &lt;- 10000
&gt; 
&gt; # sigma^2* 和 mu^* 的后验样本
&gt; sigma2.star &lt;- rgamma(B, 3, 2)
&gt; mu.star &lt;- rnorm(B, 200, sqrt(sigma2.star))
&gt; 
&gt; # 第 95 分位数和 90% 可信区间的后验估计
&gt; q &lt;- mu.star + qnorm(0.95) * sigma2.star
&gt;平均值（q）
[1] 202.465
&gt; 
&gt; 分位数（q，probs = c（0.05, 0.95））
5% 95% 
200.0369 206.0277 
&gt; 
&gt; 
&gt; ### 使用后验预测分布
&gt; ynew &lt;- rnorm（B，mu.star，sqrt（sigma2.star））
&gt; 
&gt; q &lt;- 分位数（ynew，prob = 0.95）
&gt; q
95% 
202.7814 

但如您所见，使用后验预测，我仅得到 $q$ 的值的一个估计值，但没有可信区间，因为只有一个值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658982/bayesian-interval-estimate-for-a-quantile</guid>
      <pubDate>Thu, 19 Dec 2024 19:37:12 GMT</pubDate>
    </item>
    <item>
      <title>使用看似不相关的回归检验两个不同回归的系数相等性</title>
      <link>https://stats.stackexchange.com/questions/657674/testing-equality-of-coefficients-from-two-different-regressions-with-seemingly-u</link>
      <description><![CDATA[我正在运行两个回归，一个嵌套在另一个中。
$$ y = \beta_1 X + \epsilon_1$$
$$ y = \beta_2 X + \beta_3 Z + \nu_2$$
我想评估两个方程式中 X 的系数是否相同 $$\hat\beta_{1} \neq \hat\beta_{2} ?$$
基本上，我想知道添加协变量 Z 是否会显著改变 y 和 X 之间的关联。
我尝试使用 R 执行此操作，如下所示：
# install.packages(&quot;systemfit&quot;)
library(systemfit)

# 指定两个方程式
eq2 &lt;- y ~ x + z
eq1 &lt;- y ~ x

# 将模型组合成一个系统
system &lt;- list(eq1 = eq1, eq2 = eq2)

# 拟合 SUR 模型
fit &lt;- systemfit(system, method = &quot;SUR&quot;, data=data_full2)

# 测试模型间 X 系数的相等性
linearHypothesis(fit, &quot;eq1_x = eq2_x&quot;)

但是，当我查看 eq2 的 fit 结果时，我发现与单独计算每个回归时的情况非常不同。（使用 lm(y ~ x + z, data=data_full2)）。我知道两种情况下的结果可能会有所不同，但差异非常大，因为在单独计算时，受限模型中的系数为 0.1，完整模型中的系数为 0.05，而在 SUR 计算中，两者均变为 0.1 左右。因此，当然，我的 linearHypothesis(fit, &quot;eq1_x = eq2_x&quot;) 命令的结果告诉我差异并不显著。
与两个独立的 lm() 相比，使用 systemfit() 命令运行系数时，系数变化如此之大，这正常吗？我是否仍应相信分析结果，即两个方程中的系数实际上并没有显著差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/657674/testing-equality-of-coefficients-from-two-different-regressions-with-seemingly-u</guid>
      <pubDate>Fri, 22 Nov 2024 10:43:59 GMT</pubDate>
    </item>
    <item>
      <title>对训练数据进行打乱是否会导致具有图像序列的时间序列模型中的信息泄露？</title>
      <link>https://stats.stackexchange.com/questions/657190/does-shuffling-the-training-data-cause-information-leakage-in-a-time-series-mode</link>
      <description><![CDATA[我正在研究一种基于以 10 分钟为间隔捕获的图像序列的太阳能发电预测模型。我的模型作为输入接收的单个示例由一系列图像组成。我的架构结合了 CNN 和 LSTM，CNN 处理图像序列以提取特征，然后将其传递给 LSTM 以利用图像序列中的时间信息。
我使用 10 分钟的预测间隔，图像分辨率为 10 分钟。因此，每幅图像（除了前几幅和最后几幅）将出现在多个序列中。输入批次的示例：

我想知道在训练期间打乱训练数据（即打乱图像序列的整体顺序，而不是序列内的图像）是否会导致信息泄露。我担心的是，在训练期间，模型可能在预测“当前”目标的同时已经看到了“未来”图像，这可能会破坏数据的时间结构。我没有在输入中提供任何明确的时间戳或先前的目标值，只是提供图像序列。
通过改组，我希望获得更好的梯度更新和更好的批量标准化。
编辑：
下面的图显示了训练（MSE）损失。上图表示没有改组的结果，而下图包括改组。每个图包括四次独立运行，以解释由于初始化而导致的变化。

根据验证损失应用了耐心为 2 个时期的早期停止，导致运行长度不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/657190/does-shuffling-the-training-data-cause-information-leakage-in-a-time-series-mode</guid>
      <pubDate>Wed, 13 Nov 2024 09:43:07 GMT</pubDate>
    </item>
    <item>
      <title>双变量 von Mises 分布的 CF（特征函数）是否有封闭形式？</title>
      <link>https://stats.stackexchange.com/questions/648592/is-there-a-closed-form-of-the-cf-characteristic-function-of-a-bivariate-von-mi</link>
      <description><![CDATA[双变量冯·米塞斯分布的 CF（特征函数）是否有封闭形式？
如果我有两个参数遵循冯·米塞斯分布，但我的两个参数会混合在一起，那么我应该转到双变量冯·米塞斯分布，还是可以只使用冯·米塞斯分布进行计算？
附言：如果不清楚，请见谅，这是我第一次使用它！]]></description>
      <guid>https://stats.stackexchange.com/questions/648592/is-there-a-closed-form-of-the-cf-characteristic-function-of-a-bivariate-von-mi</guid>
      <pubDate>Tue, 04 Jun 2024 08:14:32 GMT</pubDate>
    </item>
    <item>
      <title>使用测量前后平均值的总和是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/587064/does-it-ever-make-sense-to-use-the-sum-of-the-pre-and-post-measure-means</link>
      <description><![CDATA[假设我定量测量了一组中每个学生的特定特征，这样每个学生都会得到一个分数。该组的平均分数为$X_0$。经过治疗后，我测量了增益，治疗后该组的平均分数为$X_1$。
在大多数情况下，有趣的是$X_0$和$X_1$之间的差异（分析治疗的有效性），但将$X_0$和$X_1$的总和用于任何非平凡目的是否有意义？如果是，那么 $X_0 + X_1$ 的含义是什么？
此外，任何有关此主题的参考资料都将不胜感激！！]]></description>
      <guid>https://stats.stackexchange.com/questions/587064/does-it-ever-make-sense-to-use-the-sum-of-the-pre-and-post-measure-means</guid>
      <pubDate>Mon, 29 Aug 2022 05:58:15 GMT</pubDate>
    </item>
    </channel>
</rss>