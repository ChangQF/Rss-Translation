<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 18 Dec 2024 18:24:57 GMT</lastBuildDate>
    <item>
      <title>如何将 Kenward-Roger 自由度应用于具有零通胀项和每个系数的离散估计的 GLMM？</title>
      <link>https://stats.stackexchange.com/questions/658932/how-to-apply-kenward-roger-degrees-of-freedom-to-a-glmm-with-a-zero-inflation-te</link>
      <description><![CDATA[假设我有一个 glmmTMB 模型（这个问题并不局限于 glmmTMB，它只是一个例子）：
glmmTMB(y~Treatment + (1|Site/Patient), dispformula = ~Site, family=gaussian(link=&quot;identity&quot;), REML=T)
如果我假设模型有一组方差，我可以计算 Kenward-Roger 自由度，或者如果 dispformula = ~Treatment，那么我可以使用单个治疗沿对角线的方差和两个治疗的平均值（最好使用加权平均值？）调整协方差矩阵，以进行非对角线校正。
在这种情况下，如果将 dispformula 应用于被视为随机效应的水平，会怎么样？这样做有意义吗？如果确实有意义，我会取给定治疗中存在的站点的平均方差吗？
问题的下一部分是针对零膨胀模型。
假设我有以下模型：
glmmTMB(y~Treatment + (1|Site/Patient), ziformula = ~Treatment, family=gaussian(link=&quot;identity&quot;), REML=T)
我是否应该将治疗固定效应的协方差和模型的零膨胀部分结合起来？由于它们处于不同的尺度（身份和逻辑），它们可以直接合并吗？还是需要以某种方式进行转换？]]></description>
      <guid>https://stats.stackexchange.com/questions/658932/how-to-apply-kenward-roger-degrees-of-freedom-to-a-glmm-with-a-zero-inflation-te</guid>
      <pubDate>Wed, 18 Dec 2024 16:38:10 GMT</pubDate>
    </item>
    <item>
      <title>基尼不纯度与误分类误差的关系</title>
      <link>https://stats.stackexchange.com/questions/658931/relationship-between-gini-impurity-and-misclassification-error</link>
      <description><![CDATA[我理解基尼不纯度和误分类误差之间的区别，但我很好奇以下处理两者关系的结果是否正确：
假设我们有两组概率$p_i$和$q_i$，其中$0 \leq p_i \leq 1$，$\forall i=1, 2, \ldots, m$和$0 \leq q_i \leq 1$，$\forall i=1, 2, \ldots, n$。此外，假设我们有两组权重$w_i$和$v_i$，它们的总和为 1，即$w_1+w_2+\cdots+w_m=1$和$v_1+v_2+\cdots+v_n=1$。如果
$\sum_{i=1}^m w_i 2p_i(1-p_i) \leq \sum_{i=1}^n v_i 2q_i(1-q_i)$，
这是否意味着
$\sum_{i=1}^m w_i (1-\max(p_i, 1-p_i)) \leq \sum_{i=1}^n v_i (1-\max(q_i, 1-q_i))$？
换句话说，与另一个分割相比，加权基尼不纯度较低的分割是否也具有较低的加权误分类误差？由于基尼不纯度和误分类误差曲线的形状，情况似乎确实如此，但我无法严格证明（或反驳）这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/658931/relationship-between-gini-impurity-and-misclassification-error</guid>
      <pubDate>Wed, 18 Dec 2024 16:23:38 GMT</pubDate>
    </item>
    <item>
      <title>关于使用监督机器学习处理时间序列数据中的结构突变以进行预测的查询</title>
      <link>https://stats.stackexchange.com/questions/658930/query-on-handling-structural-breaks-in-time-series-data-for-prediction-using-sup</link>
      <description><![CDATA[商品价格（原始数据）的结构性突变是否会影响机器学习模型的预测准确性？
如果答案是肯定的，我将非常感激您对以下方面的指导：
识别：我们如何确定时间序列数据是否包含结构性突变？
缓解/消除：在继续预测之前，我们可以采取哪些步骤来解决结构性突变？
您对此事的见解对我的研究非常有价值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658930/query-on-handling-structural-breaks-in-time-series-data-for-prediction-using-sup</guid>
      <pubDate>Wed, 18 Dec 2024 16:19:47 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑混合模型中，估计值会发生变化，但对于高斯模型则不会</title>
      <link>https://stats.stackexchange.com/questions/658929/in-logistic-mixed-model-the-estimate-changes-but-it-does-not-for-a-gaussian</link>
      <description><![CDATA[比较 2 个逻辑模型：
result~1 

和
result~1|randomeffect

两个模型之间的估计值（即比例的对数（几率））会发生变化 &amp;我正在努力解释这一点。
当我用模拟数据对高斯模型进行实验时，使平均值偏移的唯一方法是使随机效应的各组中的观测值数量不相等（我理解为什么会发生这种情况）。
但是，在逻辑/二进制中工作时，即使随机效应中每个组的观测值数量相等，我也会得到估计值的变化（对于比例的对数几率）。
我希望能够向外行观众解释这一点，否则会破坏从基础模型转移到混合模型的可信度。
有人可以提出建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658929/in-logistic-mixed-model-the-estimate-changes-but-it-does-not-for-a-gaussian</guid>
      <pubDate>Wed, 18 Dec 2024 16:11:36 GMT</pubDate>
    </item>
    <item>
      <title>如果以 $f(Y)$ 为条件的 $X$ 是正态的，那么以 $Y$ 为条件的 $X$ 也是正态的？</title>
      <link>https://stats.stackexchange.com/questions/658927/if-x-conditional-on-fy-is-normal-then-x-conditional-on-y-is-normal</link>
      <description><![CDATA[考虑两个实值随机变量 $X$ 和 $Y$，并得到完全支持。设 $f:\mathbb{R}\rightarrow \mathbb{R}$。假设
$$
X\mid f(Y) \sim N(\mu_{f(Y)}, \sigma_{f(Y)})
$$
即：$X$ 条件为 $f(Y)$ 具有正态分布，其均值和方差取决于 $f(Y)$。
问题：这个假设是否意味着给定 $Y$ 的 $X$ 也具有正态分布？如果是，那么该正态分布的参数与$\mu_{f(Y)}$和$\sigma_{f(Y)}$有何关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/658927/if-x-conditional-on-fy-is-normal-then-x-conditional-on-y-is-normal</guid>
      <pubDate>Wed, 18 Dec 2024 15:35:14 GMT</pubDate>
    </item>
    <item>
      <title>轻松理解混合模型中聚类变量和随机变量之间的区别</title>
      <link>https://stats.stackexchange.com/questions/658926/easy-way-to-understand-the-difference-between-a-cluster-variable-and-a-random-va</link>
      <description><![CDATA[假设我们有一个数据集，其中我们根据社会经济地位对一系列不同学校的数学成绩分数进行建模。使用 lme4 的适当模型将是：
lmer(math~ses + (ses | school), data=d)
我的学生经常混淆 ses 和 school 的位置。为了解决这个问题，我制作了一个 YouTube 视频，帮助学生识别他们的“聚类变量”。该视频为他们提供了三条规则来帮助识别他们的聚类变量：

这个变量在您的数据集中是否经常重复出现？（聚类变量将重复）
这个变量是否识别一个人？ （如果是，那就是您的聚类变量，跳过 #3）
此变量是否表示特定组？（如果是，那就是您的聚类变量）

对于此示例，学校将被重复（该学校的每个学生一行），它不会识别特定的人，但会识别特定的组。
我对我的解释一直不太满意，因为它留下了一些歧义。让我们修改示例以使我的规则失败。假设我们正在预测数学成绩，但这次，我们想添加种族作为预测因素。合适的模型可以是：
lmer(math~ses + ethnicity + (ses + ethnicity | school), data=d)
（假设 ses 和 ethnicity 的斜率实际上因学校而异）。
这个例子的问题是学生会感到困惑，特别是如果数据集尚未按学校排序。ethnicity 和 school 都符合标准：两者都重复，都不能识别一个人，并且都表示一个“群体”。当他们问为什么 ethnicity 不是时，我有点不知道如何解释为什么 ethnicity 不是一个群体。
关于如何使差异更具体，有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658926/easy-way-to-understand-the-difference-between-a-cluster-variable-and-a-random-va</guid>
      <pubDate>Wed, 18 Dec 2024 15:33:06 GMT</pubDate>
    </item>
    <item>
      <title>Copula 实证估计 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658925/copula-empirical-estimation</link>
      <description><![CDATA[我正在研究这篇论文。
考虑以下数据：
$X : 0.29, 0.36, 0.39, 0.41, 0.50, 0.53, 0.54, 0.55, 0.56, 0.56, 0.56, 0.58, 0.60, 0.60, 0.62, 0.64, 0.64, 0.67, 0.80, 0.87
$
$Y : 0.17, 0.24, 0.26, 0.26, 0.27, 0.29, 0.30, 0.32, 0.33, 0.34, 0.38, 0.47, 0.47, 0.50, 0.56, 0.58, 0.59, 0.62, 0.63
$
分析的第一步是估算${I}_{\overline{C}}$。我们考虑随机样本 $(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)$ 的经验生存 copula，该样本来自连续双变量分布：
$$
\overline{C}\left(\frac{i}{n}, \frac{j}{n}\right) = \frac{\text{(样本中 x &gt; x_{(i)}, y \geq y_{(j)} 的对数)}{n},
$$
其中 $ x_{(i)} ( y_{(j)}) $ 是第 $i$ 个 ($j$ ) 顺序统计量，用于对 $X$ 和 $Y$ 进行观测。使用$\overline{C} \left( \frac{i}{n}, \frac{j}{n} \right) $作为$\overline{C}(u, v) $的估计量，$I_{\overline{C}}$的再代入估计量为：
$$
\widehat{I}_{\overline{C}} = \frac{2}{n^2} \sum_{i=1}^n \sum_{j=1}^n \overline{C} \left( \frac{i}{n}, \frac{j}{n} \right) \log \overline{C} \left( \frac{i}{n}, \frac{j}{n} \right),
$$
在那些点上，$ \frac{i}{n} + \frac{j}{n} - 1 &gt; 0 $。给定样本的估计值为 $\widehat{I}_{\overline{C}} = 0.3049$。
有人可以纠正我试过的这段代码吗：
X &lt;- c(0.29, 0.36, 0.39, 0.41, 0.50, 0.53, 0.54, 0.55, 0.56, 0.56, 
0.56, 0.58, 0.60, 0.60, 0.62, 0.64, 0.64, 0.67, 0.80, 0.87)
Y &lt;- c(0.17, 0.24, 0.26, 0.26, 0.27, 0.29, 0.30, 0.32, 0.33,0.33, 0.34, 
0.38, 0.47, 0.47, 0.50, 0.56, 0.58, 0.59, 0.62, 0.63)
n &lt;- length(X)
X_sorted &lt;- sort(X)
Y_sorted &lt;- sort(Y)
C_bar &lt;- function(i, j, X_sorted, Y_sorted) {
count &lt;- sum((X_sorted &gt; X_sorted[i]) &amp; (Y_sorted &gt; Y_sorted[j]))
return(count / n)
}
I_C_hat &lt;- 0
for (i in 1:n) {
for (j in 1:n) {
u &lt;- i / n
v &lt;- j / n
C_val &lt;- C_bar(i, j, X_sorted, Y_sorted)
if (!is.na(C_val) &amp;&amp; C_val &gt; 0 &amp;&amp; (u + v - 1) &gt; 0) {
I_C_hat &lt;- I_C_hat + C_val * log(C_val)
}
}
}

I_C_hat &lt;- 2 / (n^2) * I_C_hat
cat(&quot;I_C_hat 的估计值：&quot;, I_C_hat, &quot;\n&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/658925/copula-empirical-estimation</guid>
      <pubDate>Wed, 18 Dec 2024 15:12:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 simr 了解功率曲线和非单调功率随样本量增加的情况</title>
      <link>https://stats.stackexchange.com/questions/658923/understanding-power-curves-and-non-monotonic-power-increase-with-sample-size-usi</link>
      <description><![CDATA[我正在研究一个混合效应模型来分析
反应时间 ~ 种族 * 身份 + (1 | id)

使用 R。种族 和 身份 是效应编码分类变量 (+1/-1)，因变量遵循逆高斯分布。
我做了什么：

模拟数据：将数据集扩展到 250 名参与者。添加随机截距以模拟随机效应中的实际变化。
功效分析：使用 simr 模拟几种效应大小（例如 -0.1、-0.5、-1、-1.67）的功效。值得注意的是，原始模型中的交互项并不显著。
问题：在功效曲线中，功效不会随着样本量的增加而持续增加。例如，随着样本量的增大，功效有时会稳定下来，甚至会略有下降。

set.seed(111)
n_participants &lt;- 150 

extended_data &lt;- data_clean %&gt;%
slice(rep(1:n(), length.out = n() * n_participants / 
length(unique(data_clean$id)))) %&gt;%
mutate(id = rep(1:n_participants, length.out = n()))

set.seed(111) 
extended_data &lt;- extended_data %&gt;%
group_by(id) %&gt;%
mutate(
random_intercept = rnorm(1,mean = 0,sd = sqrt(16.5^2)), 
# 根据需要调整方差
反应时间 = 反应时间 + 随机截距
) %&gt;%
ungroup()

model_updated &lt;- glmer(
反应时间 ~ 种族 * 身份 + (1 | id),
data = extended_data,
family = inverse.gaussian(link = &quot;identity&quot;),
control = glmerControl(optimizer = &quot;bobyqa&quot;, 
optCtrl = list(maxfun = 1e5))
) 

生成负面效应大小的功效曲线：-0.5 
计算沿 id 的 6 个样本大小的功效
预测因子“种族 1：身份 1”的功效，(95% 置信区间)，=========================================|
按 id 的最大值排序：
100：82.00% (73.05, 88.97) - 2814 行
110：84.00% (75.32, 90.57) - 3094 行
120：91.00% (83.60, 95.80) - 3374 行
130：80.00% (70.82, 87.33) - 3654 行
140：78.00% (68.61, 85.67) - 3934 行
150：82.00% (73.05, 88.97) - 4214 行

已用时间：0 小时 8 分 47 秒

负面效应大小的生成功率曲线： -1.67 
计算沿 id 的 6 个样本大小的功效
预测因子“种族 1：身份 1”的功效，
(95% 置信区间)，
=======================================|
按 id 的最大值排序：
100：85.00% (76.47, 91.35) - 2814 行
110：85.00% (76.47, 91.35) - 3094 行
120：83.00% (74.18, 89.77) - 3374 行
130：79.00% (69.71, 86.51) - 3654 行
140：84.00% (75.32, 90.57) - 3934 行
150：78.00% (68.61, 85.67) - 4214 行

已用时间：0 小时 10 分 12 秒
]]></description>
      <guid>https://stats.stackexchange.com/questions/658923/understanding-power-curves-and-non-monotonic-power-increase-with-sample-size-usi</guid>
      <pubDate>Wed, 18 Dec 2024 13:31:01 GMT</pubDate>
    </item>
    <item>
      <title>如何计算每种混合物成分的 BIC</title>
      <link>https://stats.stackexchange.com/questions/658922/how-to-calculate-the-bic-for-each-mixture-component</link>
      <description><![CDATA[我想将高斯混合拟合到模拟数据。然后，我需要计算每个混合成分的贝叶斯信息标准。我的观点是，在模型收敛后，我根据给定的估计值计算每个混合成分的可能性。这在理论上正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658922/how-to-calculate-the-bic-for-each-mixture-component</guid>
      <pubDate>Wed, 18 Dec 2024 13:02:48 GMT</pubDate>
    </item>
    <item>
      <title>我有两个实验针对两个不同的用户群进行。我的目标是了解实验是否效果更好。如何进行？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658921/i-have-two-experiments-going-on-two-different-user-bases-my-aim-is-to-access-wh</link>
      <description><![CDATA[我有两个实验，针对两个不同的用户群。我的目标是了解哪个实验效果更好。我每天跟踪两个指标。一个是关于留存率 - 基本上是今天使用我们应用的 100 名用户中，第二天有多少人使用。另一个是用户在两个实验中执行的活动数量。我希望活动数量更高。这里要注意的一点是，两个实验的组大小可能不同。考虑到我每天测量这些指标，并且这些测量可能不独立于时间，应该使用哪种统计测试。为了进行比较，我们跟踪了上述两个指标，即两个实验的用户在我们的应用上执行的留存率（越高越好）和活动事件数量（越高越好）。如果某个特定实验（假设为 A）的留存率和活动数量在几天内持续较高，那么 A 更好。一个实验基本上是一种旨在调整用户行为的策略。我们想弄清楚哪种策略效果更好，我应该进行哪种统计测试来确定结果是否具有统计意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/658921/i-have-two-experiments-going-on-two-different-user-bases-my-aim-is-to-access-wh</guid>
      <pubDate>Wed, 18 Dec 2024 12:40:44 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程中未知点协方差矩阵导数的近似值</title>
      <link>https://stats.stackexchange.com/questions/658911/approximation-for-the-derivative-of-the-covariance-matrix-for-unknown-points-in</link>
      <description><![CDATA[我希望标题足够具有描述性，我现在感觉有点愚蠢。在我进行有关导数的推导时，出现了以下术语
$$
K_{x*,x}K^{-1}_{xx} \frac{\partial K_{xx}}{\partial q} K^{-1}_{xx} K_{x,x*}
$$
其中 $x$ 为训练点，$x*$ 为未知点，$q$ 为该点所依赖的坐标。$K$ 为协方差矩阵。我的直觉告诉我，这个表达式至少在最小二乘拟合意义上近似于
$$
\frac{\partial K_{x*x*}}{\partial q}
$$
但目前我无法证明这一点。也许我只是希望它是真的，因为它会简化我推导中的最终表达式。
欢迎提出任何想法。也许我走错了路。]]></description>
      <guid>https://stats.stackexchange.com/questions/658911/approximation-for-the-derivative-of-the-covariance-matrix-for-unknown-points-in</guid>
      <pubDate>Wed, 18 Dec 2024 10:30:09 GMT</pubDate>
    </item>
    <item>
      <title>调整超参数以尽量减少过度拟合时的目标应该是什么？</title>
      <link>https://stats.stackexchange.com/questions/658909/what-should-the-objective-be-when-tuning-hyperparameters-to-minimize-overfitting</link>
      <description><![CDATA[我正在研究一个包含约 90k 行数据和 12 个特征的分类问题。我正在尝试调整 XGBoost 模型的超参数以尽量减少过度拟合。我使用 ROC_AUC 作为评估模型性能的指标。使用默认的 XGBoost 参数，5 倍 CV 结果分别显示训练 auc 为 0.782 和测试 auc 为 0.739。这表明过度拟合，因为训练集的表现优于测试集。
我开始调整超参数，因为 a) 应该调整，b) 已知超参数可用于减少过度拟合。但是，像许多其他人一样，我将验证 auc 设置为目标，并在目标函数中实现交叉验证。使用的库是 Optuna 和 Hyperopt。有趣的是，对于这两种情况，我发现当算法试图将验证 auc 推向 0.745 时，训练测试 auc 差距（过度拟合指标）会扩大。如果我按验证 auc 降序绘制训练和验证 auc，验证 auc 会从 0.745 降至 0.729，而训练 auc 会从 0.868 降至 0.742。
我对结果感到很困惑。我将验证 auc 设置为 Optuna 优化的目标是否正确？我是否应该选择（训练 auc - 验证 auc），但我在网上没有找到类似的例子。而且我是否应该查看结果并选择最低的验证 auc 和相关的超参数值作为“最佳参数”，因为训练验证指标差距最小？
请在这里分享您的想法，因为在我输入时，我不确定我对过度拟合的理解是否正确。
我的代码：
X, y = df[features], df[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,
random_state = 42, stratify = y)
dtrain = xgb.DMatrix(X_train, label = y_train, enable_categorical = True)
dtest = xgb.DMatrix(X_test, label = y_test, enable_categorical = True)

def objective(trial):

params = {&#39;max_depth&#39;: trial.suggest_int(&#39;max_depth&#39;, 3, 10),
&#39;min_child_weight&#39;: trial.suggest_int(&#39;min_child_weight&#39;, 1, 100),
&#39;gamma&#39;: trial.suggest_float(&#39;gamma&#39;, 0, 2),
&#39;subsample&#39;: trial.suggest_float(&#39;subsample&#39;, 0.5, 1),
&#39;colsample_bytree&#39;: trial.suggest_float(&#39;colsample_bytree&#39;, 0.5, 1),
&#39;reg_alpha&#39;: trial.suggest_float(&#39;reg_alpha&#39;, 1e-8, 10, log = True),
&#39;reg_lambda&#39;: trial.suggest_float(&#39;reg_lambda&#39;, 1e-8, 10, log = True),
&#39;learning_rate&#39;: trial.suggest_float(&#39;learning_rate&#39;, 0.001, 0.3),
&#39;objective&#39;: &#39;binary:logistic&#39;}

cv_results = xgb.cv(
params, dtrain, num_boost_round = 10000, early_stopping_rounds = 50, 
metrics = &#39;auc&#39;, nfold = 5, stratified = True, shuffle = False
)

trial.set_user_attr(&#39;n_estimators&#39;, len(cv_results))
trial.set_user_attr(&#39;train-auc&#39;, cv_results[&#39;train-auc-mean&#39;].iloc[-1])

return cv_results[&#39;test-auc-mean&#39;].iloc[-1]

study = optuna.create_study(
direction =&#39;maximize&#39;, sampler = optuna.samplers.TPESampler(seed = 42))

study.optimize(objective, n_trials = 500, n_jobs = -1)

]]></description>
      <guid>https://stats.stackexchange.com/questions/658909/what-should-the-objective-be-when-tuning-hyperparameters-to-minimize-overfitting</guid>
      <pubDate>Wed, 18 Dec 2024 09:28:26 GMT</pubDate>
    </item>
    <item>
      <title>如何计算最小化平均绝对误差的最佳拟合线的斜率？</title>
      <link>https://stats.stackexchange.com/questions/658887/how-to-calculate-the-slope-of-a-line-of-best-fit-that-minimizes-mean-absolute-er</link>
      <description><![CDATA[我有 25 个数据点，形式为 $(x,y)$，其中 $x$ 为 $1,2,3,...,25$，$y$ 为因变量。
我需要确定 $y$ 值是增加、减少还是保持不变。
最常用的方法是将这些点拟合成一条线。如果斜率为正，则 $y$ 增加，如果斜率为负，则 $y$ 减少，等等。
我一直在使用普通最小二乘回归来绘制线，但在某些情况下，异常值会导致问题。我不想忽略异常值，因为它们相关且重要；我只是不希望它们产生如此巨大的影响。我不想使用 Theil-Sen 回归，因为这实际上忽略了异常值。
似乎我想要的是一种最小化平均绝对误差或 L1 误差（而不是平方误差）的回归。这种回归似乎要困难得多。我读过几个资料，但一般分位数回归的微积分让我很费解。
我的问题是：如何计算使 L1 误差最小化的最佳拟合线的斜率？
我正在寻找的答案有一些限制：

我正在寻找一个输出直线斜率的过程（可能包括伪代码或实际代码）。
我只需要直线的斜率。
我只有 25 个点，而且它们是二维的，因此，只要它们可以处理这种小情况，效率低下且无法扩展的解决方案也可以。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658887/how-to-calculate-the-slope-of-a-line-of-best-fit-that-minimizes-mean-absolute-er</guid>
      <pubDate>Tue, 17 Dec 2024 16:12:39 GMT</pubDate>
    </item>
    <item>
      <title>有目的地将纵向数据建模为 iid？</title>
      <link>https://stats.stackexchange.com/questions/658882/purposefully-modelling-longitudinal-data-as-iid</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658882/purposefully-modelling-longitudinal-data-as-iid</guid>
      <pubDate>Tue, 17 Dec 2024 15:38:22 GMT</pubDate>
    </item>
    <item>
      <title>参数复发事件分析中的马丁格尔和偏差残差？</title>
      <link>https://stats.stackexchange.com/questions/658870/martingale-and-deviance-residuals-in-parametric-recurrent-event-analysis</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658870/martingale-and-deviance-residuals-in-parametric-recurrent-event-analysis</guid>
      <pubDate>Tue, 17 Dec 2024 11:24:19 GMT</pubDate>
    </item>
    </channel>
</rss>