<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Thu, 13 Mar 2025 03:30:14 GMT</lastBuildDate>
    <item>
      <title>减轻多个残差连接的效果</title>
      <link>https://stats.stackexchange.com/questions/662550/mitigate-the-effect-of-multiple-residual-connections</link>
      <description><![CDATA[我最近遇到了一个问题，我无法根据我的先前知识回答（注意：不是作业，我已经毕业了）：
假设，我们在具有前层归一化的变压器中使用多个残差连接（即在层开始时层标准），我们假设每个残差都独立地分布在某种程度上，那么其总和的方差就会增长到添加的数量。例如，如果我们有2个残差，那么方差就可以达到极端水平，例如3-4个数量级。因此，在培训期间，我们将遇到具有精度和二元效应的问题（层变为-1或1），并且梯度将变得很小（接近0）。
我们该怎么做才能避免这些问题？
我认为，为避免这些问题，我们必须弄清楚如何在这些残差连接之间进行检查。我的第一个思想是围绕在这些残差连接之间应用层归一化的，以使方差恢复到正常水平。但是，由于我们已经具有层归一化，因此这种想法显然是错误的。另外，这显然也会导致梯度爆炸。
您还可以提供与此问题相关的一些理论（或参考文献）吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662550/mitigate-the-effect-of-multiple-residual-connections</guid>
      <pubDate>Thu, 13 Mar 2025 02:25:05 GMT</pubDate>
    </item>
    <item>
      <title>从双变量高斯得出条件预测间隔</title>
      <link>https://stats.stackexchange.com/questions/662548/deriving-a-conditional-prediction-interval-from-a-bivariate-gaussian</link>
      <description><![CDATA[令  $ y =（y_1，y_2）^t \ in \ mathbb {r}^2 $ 是一个随机向量， $ x \ in \ in \ in \ in \ in \ in \ intcal {x}}}}}}} \ subset \ subset \ mathbb {cov $ cov a cover cov {R/ /&gt;
假设：
 $$
y | x \ sim \ mathcal {n}（\ mu（x），\ sigma（x））
$$ 
其中 $ \ mu =（\ mu_1，\ mu_2）^t $ &lt; /span&gt;和
 $$
\ sigma =  
\ begin {bmatrix}  
\ sigma_1^2＆amp; \ rho \ sigma_1 \ sigma_2 \\  
\ rho \ sigma_1 \ sigma_2＆amp; \ sigma_2^2  
\ end {bmatrix}
$$  
由于某些限制，我无法直接利用该模型隐含的椭圆形不确定性区域。相反，我必须考虑 $ y_1 |的一维预测间隔x $ 或 $ y_2 | x $ 。此外，使用 $ y_i |的边际分布计算这些间隔x $ 可能导致间隔过多。
为了减轻这种情况，我建议对 $ y_2 $ 和计算预测间隔 $ y_1 | x，y_2 $ 。具体来说，对于给定的 $ x = x $ ，我在 $ y_2 = \ mu_2 = \ mu_2（x）$ 中评估条件分布，导致：
 $$
y_1 | x = x，y_2 = \ mu_2（x）\ sim \ mathcal {n} \ left（\ mu_1（x），[1- \ rho^2（x）] \ sigma_1^2（x）\ right）
$$  
实践中，对于所有 $ x \ in \ Mathcal {x} $ ，我们 $ | \ rho（x）| ＆lt; 1 $ ，导致预测间隔较窄。但是，由于 $ \ mu $ 和 $ \ sigma $ 
您是否预见到这些条件预测间隔可能无法提供可靠的不确定性量化的任何情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/662548/deriving-a-conditional-prediction-interval-from-a-bivariate-gaussian</guid>
      <pubDate>Thu, 13 Mar 2025 00:54:27 GMT</pubDate>
    </item>
    <item>
      <title>如果我们有规模地位图，为什么要使用残差与拟合图？</title>
      <link>https://stats.stackexchange.com/questions/662547/why-use-the-residuals-vs-fitted-plot-if-we-have-the-scale-location-plot</link>
      <description><![CDATA[There is a previous question on this site asking for details on what is gained by looking at the scale-location plot after already having looked at the plot of residuals vs fitted values as a part of the regression diagnostics.
在上一个问题的答案中，建议在某些情况下，规模地点图优于残差和拟合值的图。
因此，我的问题只是从上面提到的问题中相反：如果我们有规模地点图，我们是否有任何理由我们对残留物与拟合值的绘图完全感兴趣？？]]></description>
      <guid>https://stats.stackexchange.com/questions/662547/why-use-the-residuals-vs-fitted-plot-if-we-have-the-scale-location-plot</guid>
      <pubDate>Thu, 13 Mar 2025 00:07:12 GMT</pubDate>
    </item>
    <item>
      <title>r估计的盘价弹性估计</title>
      <link>https://stats.stackexchange.com/questions/662545/cross-price-elasticity-estimation-in-r</link>
      <description><![CDATA[我在10个商店中有相同300种产品的零售价和销售数据在每周观察到的5年的三个州中传播的10个商店。我如何估计交叉价格弹性？从到目前为止阅读的内容来看，我应该使用日志记录回归，并且还要纠正内生性。我读到商店中产品的价格可以在另一家商店中以同一产品的价格进行仪器。除此之外，我可以添加控件和FES。我是否计算所有商店中所有产品的跨价格弹性？还是最好在类别级别汇总数据 - 食物，爱好，家庭，然后计算所有商店和类别的交叉弹性？在线所有示例均适用于2-3种产品。我不明白我应该如何构建数据]]></description>
      <guid>https://stats.stackexchange.com/questions/662545/cross-price-elasticity-estimation-in-r</guid>
      <pubDate>Wed, 12 Mar 2025 22:47:52 GMT</pubDate>
    </item>
    <item>
      <title>在NLL中，您如何产生给定RMSE（global_minimum_params）的RMSE（true_params）的准确估计？</title>
      <link>https://stats.stackexchange.com/questions/662544/in-nlls-how-do-you-produce-accurate-estimates-of-rmsetrue-params-given-rmseg</link>
      <description><![CDATA[我有指数衰减
  $ f（t）= \ sum_n \ left（a_n e^{ -  \ frac {t} {\ tau_n}} \ right） + c + c + \ epsilon（t）
 n代表不同的指数衰减成分， $ a_n $ 代表每个衰减振幅， $ \ tau_n $ 代表每个衰减率， $ \ epsent ouss  $ c $ 是噪声内固有的偏移常数。我想根据损失创建一个排除标准，以便我可以忽略比真实参数更糟糕的最小值。
我有Levenberg – Marquardt算法的实现，我认为这很好。我已经在单个指数衰减上使用了此损失（3个参数{ $ a $ ， $ \ tau $ ， $ c $ c $  $ c $  $ c $ ）
在
在
到目前为止这还不错，并且使用我在网上找到的方程式，
  $ rmse（true \ _params）\ oft \ frac {rmse（global \ _min \ _params）} {\ sqrt {1- \ sqrt {1- \ frac {\ frac {\ nu} {\ nu}} {p}}} {p}} {
其中 $ \ nu $ 是拟合参数内的自由度，p是信号中的点数。在我的示例中，这个yeilds：
  $ \ frac {0.00990305} {\ sqrt {\ sqrt {1  -  \ frac {3} {2726}}} = 0.00990851
它非常接近实际损失。这给了我希望，在尝试双重衰减时，它很快就被剥夺了（5个params { $ a_1 $ ， $ \ tau_1 $ \ tau_1 $ ， $ a_2 $ a_2 $  $ a_2 $  class =“ Math-Container”&gt; $ \ tau_2 $ ， $ C $ }）：
  $ rmse（true \ _Params）= 0.01059385 \ neq \ frac {0.01007084} {\ sqrt {1  -  \ frac {5}
显然还有其他事情正在发生，我发现的方程式没有描述，但此时我不远。我试图研究一种感觉分析方法，以更好地估计 $ \ nu $ ，而不是使用jacobians的参数数量，但它给出了 $ \ nu = 4.999999 $ 既有趣又有趣and dunelelpful。
这是一篇寻求理论帮助的文章，但我将包括指向完整代码的链接：&lt;a href =“ https://github.com/ollie-spoon/explmopt/blob/blob/main/main/lm_test.ipynb”]]></description>
      <guid>https://stats.stackexchange.com/questions/662544/in-nlls-how-do-you-produce-accurate-estimates-of-rmsetrue-params-given-rmseg</guid>
      <pubDate>Wed, 12 Mar 2025 22:45:06 GMT</pubDate>
    </item>
    <item>
      <title>自然有序数据在高维协方差矩阵估计问题中</title>
      <link>https://stats.stackexchange.com/questions/662542/natural-ordered-data-in-high-dimensional-covariance-matrix-estimation-problem</link>
      <description><![CDATA[我正在阅读一些有关高维情况下的估计协方差矩阵的文章，作者经常提到自然变量顺序。这意味着在排序中距离较远的变量较小。它们提供了诸如时间序列，纵向数据和光谱数据之类的示例。例如，在地理数据的情况下，我可以想象这些行代表年（观察），气象站位于列中（可以根据距离进行订购的变量），因此我们可以在两个站点之间的平均温度之间测量平均温度之间的协方差。但是，在时间序列的情况下，我很难理解这种顺序，因为我遇到了连续时间点以行表示的数据。对于任何有序，连续的时间点必须是列（这是有序变量），并且每个观察结果都是对过程的实现。所研究的协方差本质上是自动增强性。但是，此类数据结构是否常用？]]></description>
      <guid>https://stats.stackexchange.com/questions/662542/natural-ordered-data-in-high-dimensional-covariance-matrix-estimation-problem</guid>
      <pubDate>Wed, 12 Mar 2025 21:37:09 GMT</pubDate>
    </item>
    <item>
      <title>Kruskal-Wallis测试可以用于不同大小的组吗？需要引用</title>
      <link>https://stats.stackexchange.com/questions/662541/can-kruskal-wallis-test-be-used-in-groups-of-different-size-citations-needed</link>
      <description><![CDATA[我有4个样本，并使用Kruskal-Wallis比较差异。我从以前的帖子中知道，Kruskal -Wallis测试可用于不同大小的组，但我很难找到可靠的来源（书籍章节或期刊文章），向期刊文章审稿人解释了这一点，以证明可以在我们的研究中拥有不同规模的样本是合理的。谢谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/662541/can-kruskal-wallis-test-be-used-in-groups-of-different-size-citations-needed</guid>
      <pubDate>Wed, 12 Mar 2025 21:10:47 GMT</pubDate>
    </item>
    <item>
      <title>用时间系数变化的监管提交系数来解释和重新组合生存曲线</title>
      <link>https://stats.stackexchange.com/questions/662540/interpreting-and-recombining-a-survival-curve-with-time-varying-coefficient-for</link>
      <description><![CDATA[我一直在为一个分析数据集而苦苦挣扎，其中分类预测指标具有时间依赖性。它固定在观察期。为了在上面放一个创可贴，我使用了步骤功能方法。有了3个切点，我可以解决时间依赖问题，但现在我陷入困境。我现在有四个单独的曲线，我一直在尝试将它们拼凑回一个可以促进与广泛受众的沟通的情节。
根据我对互联网的搜索，这是一个开放的问题……任何人都有任何简单的示例绘制这些内容。小插图示例，不适用于我的特定情况，因为它是二进制的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662540/interpreting-and-recombining-a-survival-curve-with-time-varying-coefficient-for</guid>
      <pubDate>Wed, 12 Mar 2025 21:08:10 GMT</pubDate>
    </item>
    <item>
      <title>得出最低规范的公式[重复]</title>
      <link>https://stats.stackexchange.com/questions/662539/deriving-a-formula-for-the-minimum-norm</link>
      <description><![CDATA[ 我已经在此数学答案最小二乘的一般解决方案是（从链接的答案中提取）：
  $$ \ lvert
 X_ {LS}
\ rvert_ {2}^{2} 
=
\ lvert
 \ color {blue} {\ mathbf {a}^{\ Dagger} b} + 
 \ color {red} {\ left（\ mathbf {i} _ {n}  -  \ mathbf {a}^{\ dagger} \ dagger} \ mathbf {a} \ right）y} y}
\ rvert_ {2}^{2} 
=
\ lvert
\ color {blue} {\ mathbf {a}^{\ Dagger} b}
\ rvert_ {2}^{2} 
+
\ UnderBrace {\ lvert
 \ color {red} {\ left（\ mathbf {i} _ {n}  -  \ mathbf {a}^{\ dagger} \ dagger} \ mathbf {a} \ right）y} y}
\ rvert_ {2}^{2}} _ {y = \ Mathbf {0}} $$  
和最小规范是右手术语，即使用 $ y = 0 $ 。
但从向量之和的平方
一个人如何从单个规范到这里的规范之和？

 请注意， 扩展正方形并没有得出结论： $ y = 0 $ 弥补了最低的规范，因为 $ y $ y $ $ 可能是正或负面的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662539/deriving-a-formula-for-the-minimum-norm</guid>
      <pubDate>Wed, 12 Mar 2025 20:40:08 GMT</pubDate>
    </item>
    <item>
      <title>如何学习始终经过治疗的单位？</title>
      <link>https://stats.stackexchange.com/questions/662537/how-can-i-study-always-treated-units</link>
      <description><![CDATA[我有一个面板数据集，该数据集具有多个单位，这些单位总是经过处理。我知道，差异，综合控制和其他方法将无法始终与经过处理的单位一起使用，并且通常会从分析中删除。
但是，如果我想研究治疗对这些治疗单位的影响怎么办？有办法做到吗？也许某种类型的匹配通常经常治疗，并且从未处理过许多协变量的单位？？
我在R中工作，因此，随附的R软件包的任何方法都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/662537/how-can-i-study-always-treated-units</guid>
      <pubDate>Wed, 12 Mar 2025 20:31:34 GMT</pubDate>
    </item>
    <item>
      <title>面板与横截面 - 时间不变的自变量，随时间变化的变量</title>
      <link>https://stats.stackexchange.com/questions/662536/panel-vs-cross-section-time-invariant-independent-variable-time-varying-dep</link>
      <description><![CDATA[我正在研究政党成立。我假设，与以其他方式成立的当事方相比，从现有政党分裂而成的政党在通过立法方面将更有效。
我有在1990  -  2020年之间在整个欧洲建立的200个政党的面板数据，其中有一些关键变量：

  form_split  =如果通过从现有政党分裂而形成的当事
  bills_passed  =一项年度措施，计算一方参与通过的账单数量
  country_id  =派对处于活动的国家的唯一ID 
 年 =观察年份

我想估计 form_split 对 bills_passed 的效果。我的自变量是时间不变的（因为这是在派对形成时确定的特征），而我的因变量会随着时间而变化。
 选项1 ：我使用面板数据来运行与国家和年份固定效果的回归。政党在1990  -  2020年之间的不同年份形成。因此，有些当事方在样本中有30个观察结果（如果在1990年形成），但是大多数当事方后来形成（1990年之后），观察结果较少。完整数据集为3,749个观测值。
 选项2 ：我可以运行横截面回归。我可以创建一些 Bills_passed 的政党级别度量（例如，将它们全部添加，按年平均值），然后运行200个观察值的横截面回归。
 我的问题是：在面板和横截面方法之间，一个比另一个更好吗？
我的直觉是，我将通过将我的 Bills_passed 的度量置于横截面回归中的派对级别变量中来丢失很多信息。但是，如果我使用面板方法，那么1990年成立的当事方将比以后形成的当事方更多。我不想在面板回归中包括 age 变量来对此进行调整，因为它是处理后的。我也不能包括政党固定效果，因为主要治疗不会随着时间的流逝而改变。
任何想法都会非常有帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/662536/panel-vs-cross-section-time-invariant-independent-variable-time-varying-dep</guid>
      <pubDate>Wed, 12 Mar 2025 19:22:31 GMT</pubDate>
    </item>
    <item>
      <title>使用Poisson模型比较具有相同行百分比的表</title>
      <link>https://stats.stackexchange.com/questions/662531/comparing-tables-with-the-same-row-percentages-using-the-poisson-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662531/comparing-tables-with-the-same-row-percentages-using-the-poisson-model</guid>
      <pubDate>Wed, 12 Mar 2025 17:06:33 GMT</pubDate>
    </item>
    <item>
      <title>β二项式分布条件是实现的伽马值</title>
      <link>https://stats.stackexchange.com/questions/662498/beta-binomial-distribution-conditional-on-realized-gamma-value</link>
      <description><![CDATA[我希望得出beta二比随机变量w条件概率分布的公式，条件是驱动β的伽马随机变量的值。无条件密度是：
 $$
p（w = k | n，a，b）= \ int_0^1 {p（w = k | p，n）p（p | a，b）dp}
= \ int_0^1 {{n \ select k} p^k（1-p）^{n-k} \ frac {p^{a-1}（1-p）^{b-1}}}} {b（a，b）} dp} dp}
 = {n \选择k} \ frac {b（k+a，n-k+b）} {b（a，b）}
$$  
 Say  $ z $ 〜 $ beta（a，b）$ 。  $ z $ 可以通过使用 $ z = \ frac {x} {x+y} $ 其中x＆amp; Y是两个独立的伽玛随机变量，带有X〜  $ gamma（a，1）$ 和y〜  $ gamma（b，1）$ 。要查找条件密度 $ z | y = y $ ，我认为答案相当简单： $ p（z＆lt; z | y = y）= p（\ frac {\ frac {x}} {x+y} {x+y} {x+y}＆lt; z） $  
我正在寻找的是 $ p（w = k | y = y，n，a，a，b）$ 。我尝试过的事情包括变量a l la  $ z $ 从 $ x $ ＆amp;  $ y $ （使用 $ u = x + y $ 和 $ v = $ v = \ frac {x} {x + y}我还尝试使用 $ x $ 以及 $ y，n，a，a，b $ 以及这陷入伽玛函数无法处理大型A。   
任何帮助或指导将不胜感激，谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/662498/beta-binomial-distribution-conditional-on-realized-gamma-value</guid>
      <pubDate>Tue, 11 Mar 2025 23:20:09 GMT</pubDate>
    </item>
    <item>
      <title>我对蒙特卡洛模拟的理解是正确的吗？ （外行术语）</title>
      <link>https://stats.stackexchange.com/questions/662476/is-my-understanding-correct-about-monte-carlo-simulation-layman-terms</link>
      <description><![CDATA[我有时会在心理学期刊上遇到蒙特卡洛模拟一词。我不是一个统计书呆子，更像是统计用户，因此，即使阅读了相当数量的材料，我仍然对它的运作方式有些困惑。
假设我收集了400名研究参与者，并将他们的数据输入到统计软件中。统计软件将尝试推断这400名参与者的数据，并想象我设法收集了1000或5000名参与者的数据。我对蒙特卡洛模拟的理解是否正确？
另外，统计软件如何进行仿真过程？我收集了来自400名研究参与者的5个变量的数据。统计软件是否试图检测模式？从这种模式来看，如果我设法收集1000或5000名参与者，它将尝试推断人们如何填写问卷？如果我收集5或6个变量，结果会有所不同吗？
如果我的理解是正确的，是否需要这种统计分析？还是夸张的统计复杂形式？我仍然不确定我们是否需要模拟从10.000参与者那里收集数据的感觉。
对不起，如果这个问题非常业余。我试图理解其背后的逻辑。]]></description>
      <guid>https://stats.stackexchange.com/questions/662476/is-my-understanding-correct-about-monte-carlo-simulation-layman-terms</guid>
      <pubDate>Tue, 11 Mar 2025 13:39:24 GMT</pubDate>
    </item>
    <item>
      <title>计算检查功能是否为凸</title>
      <link>https://stats.stackexchange.com/questions/662445/computationally-checking-if-a-function-is-convex</link>
      <description><![CDATA[考虑一个实值函数 $ f：\ Mathbb {r} \ to \ Mathbb {r} $ 。给定任何 $ x \ in \ mathbb {r} $ ，我们可以计算 $ f（x）$ 。我们不知道 $ f $ 的分析形式，应将其视为黑匣子。但是，我们确实知道 $ f $ 是一阶可区分，并且可以（数值）计算其派生 $ f&#39;$ 。
 问题：是否有一种有效的方法来检查 $ f $ 是使用计算方法凸的？
我理想情况下会使用二级测试之类的东西，但是不能保证 $ f $ 是二阶可区分的，并且此方法需要推广到任意 $ c^1 $ c^1 $ 函数。

一个“蛮力”想法是从字面上应用凸的定义，
 $$ f（\ lambda x_1 +（1- \ lambda）x_2）\ leq \ lambda f（x_1） +（1- \ lambda）f（x_2）
对于所有 $ \ lambda \ in [0，1]，x_1，x_2 \ in \ mathbb {r} $ 。但是，这可能有些不切实际，因为它可能需要在 $ \ mathbb {r} $ 上测试许多不同的点，并且可能有一些本地区域违反了凸度，但此测试不会进行。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662445/computationally-checking-if-a-function-is-convex</guid>
      <pubDate>Tue, 11 Mar 2025 01:02:39 GMT</pubDate>
    </item>
    </channel>
</rss>