<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 02 Feb 2025 18:21:51 GMT</lastBuildDate>
    <item>
      <title>样本量选择策略。序数尺度。远离正态分布</title>
      <link>https://stats.stackexchange.com/questions/660873/sample-size-selection-strategy-ordinal-scale-distribution-far-from-normal</link>
      <description><![CDATA[我之前在Bootstrap 用于样本量估计。序数尺度。远离正态分布上问过类似的问题
有人正确地指出，所提出的策略可能会导致 p-hacking。所以问题是哪种策略更好。
我们经常在约 50 到 100 个句子（这是我们的样本量）的测试翻译上比较人工翻译或机器翻译系统（每次实验中为 2 到 4 个）。
每个句子的每个翻译都由一名称职的翻译人员进行评分，通常为 5 分制，有时为 10 分制（分数通常为整数，但可以包括中点，例如 3.5），这很昂贵。
量表由口头描述定义（“小幅编辑”、“严重改变含义”等），因此它们本质上是序数。分数分布通常是倾斜的，有时是双峰的。
如果有两个翻译，则使用 Wilcoxon 检验来评估结果；如果有两个以上的翻译，则使用 Friedman 检验来评估结果。
第一个想法是，如果我们不能拒绝零假设，就尝试更大的样本。但这是一种 p-hacking，除非我们一开始就决定要抽取两个样本，并相应地降低第一个样本的 alpha。然后我们可以提前终止。
一种正确的方法是估计给定效应大小和 II 类错误概率的样本量。但我们事先不知道方差和分布形状。
零假设的更新。
TLDR 它是两个分布（有时超过两个）之间差异的配对检验。通常双侧也可以是单侧。
我们使用盲测，因此评分员不知道谁是人，谁是机器。他们获得原始语言中每个句子的两个或更多个翻译，并应该在给定的范围内对每个翻译的质量进行评分。
通常，我们希望比较两个机器翻译系统，看看哪一个更适合特定的领域和语言对。或者我们有一个由（另一个）人工翻译编辑的机器（或人工）翻译，并想看看编辑器是否真的让它变得更好。
因此，零通常是“质量没有差异”或“新的翻译/MT 系统并不比现有的更好”。]]></description>
      <guid>https://stats.stackexchange.com/questions/660873/sample-size-selection-strategy-ordinal-scale-distribution-far-from-normal</guid>
      <pubDate>Sun, 02 Feb 2025 13:00:29 GMT</pubDate>
    </item>
    <item>
      <title>VAR模型、对数变换和格兰杰因果关系检验</title>
      <link>https://stats.stackexchange.com/questions/660871/var-model-logarithmic-transformation-and-granger-causality-test</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660871/var-model-logarithmic-transformation-and-granger-causality-test</guid>
      <pubDate>Sun, 02 Feb 2025 11:46:59 GMT</pubDate>
    </item>
    <item>
      <title>caret 包中的 varImp 不适用于 bagEarth</title>
      <link>https://stats.stackexchange.com/questions/660870/varimp-from-caret-package-not-working-for-bagearth</link>
      <description><![CDATA[我有一个函数，用于训练许多不同的模型。在函数中，我使用 caret 中的训练：
mod = caret::train(x=X, y=train$Y, trControl=control, preProcess=&quot;zv&quot;, 
tuneLength=4, method=model) 

我想跟踪 x 中的每个变量对拟合模型的重要性。环顾四周，varImp() 似乎是最佳选择。对于我尝试过的大多数模型，它都按预期工作 (varImp(mod) )。但是，当我使用 varImp 和 method = &quot;bagEarth&quot; 时，我收到以下错误：
Error in .(var) : could not find function &quot;.&quot;

查看 caret 文档，似乎表明 varImp 函数适用于 bagEarth。我尝试查找是否有其他人遇到过此问题，但没有找到任何问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/660870/varimp-from-caret-package-not-working-for-bagearth</guid>
      <pubDate>Sun, 02 Feb 2025 11:46:48 GMT</pubDate>
    </item>
    <item>
      <title>ECDF 的两个定义 - 为什么使用 1/(n+1) 而不是 1/n，尤其是对于 QQ 图？</title>
      <link>https://stats.stackexchange.com/questions/660866/two-definitions-of-the-ecdf-why-use-1-n1-instead-of-1-n-especially-for-qq</link>
      <description><![CDATA[在 QQ 图的上下文中，我遇到了 ECDF 的两种不同定义：第一个定义是$$F(x)=\frac{1}{n}\sum_{i=1}^n1_{[X_i,\infty[}(x)$$
第二个定义是
$$F(x)=\frac{1}{n+1}\sum_{i=1}^n1_{[X_i,\infty[}(x).$$
这两个定义都在维基百科文章中提到，虽然第一个定义对我来说似乎更自然，但第二个定义在我的 R 类中用于 QQ 图。$^1$ 此答案似乎也承认这两个定义都在实际中使用。
这两个定义分别有什么优点？

$^1$ 为了将样本 $x$ 的 ECDF 与 $n=\operatorname{length}(x)$ 与某个 CDF $F$ 进行比较，我们设置 $x&#39;=\operatorname{sort}(x)$ 和 $p=(1:n)/(n+1)$ 然后我们绘制 $(x&#39;,F^{-1}(p))$.]]></description>
      <guid>https://stats.stackexchange.com/questions/660866/two-definitions-of-the-ecdf-why-use-1-n1-instead-of-1-n-especially-for-qq</guid>
      <pubDate>Sun, 02 Feb 2025 10:30:22 GMT</pubDate>
    </item>
    <item>
      <title>什么决定了伯努利变量概率分布的平均值，其中概率是动态的和后载的？</title>
      <link>https://stats.stackexchange.com/questions/660865/what-determines-the-mean-of-a-probability-distribution-of-bernoulli-variables-wh</link>
      <description><![CDATA[抱歉，标题太笨拙了，我觉得我缺乏统计学背景知识，无法更好地描述我的问题。
这个问题涉及 gacha 游戏。对于那些不熟悉的人来说，它基本上就是赌博。由于出版商所在国家/地区的法规，他们必须提供有关赔率和机制的确切详细信息。
在我正在研究的特定系统中，第 1-58 次试验的成功概率为 0.6%。从第 59 次试验到第 80 次试验，成功概率不断增加，直到第 80 次试验，成功概率为 100%。它所运行的确切函数尚未说明，但我认为它是线性增加的。所述的“总体”包括此概率回溯在内的成功概率为 1.89%。
将本系统中的赌博视为概率为 1.89% 的几何分布，可得出 1 次成功需要 53 次试验的平均值，这是社区中用于获得 1 个所需单位所需的平均掷骰次数的公认值。
这怎么理解呢？如果平均而言，人们需要赌博 53 次才能获得成功，那么平均而言，人们在任何一次掷骰子的成功概率仅为 0.6% 时获胜。在这种概率下，53 次投掷中至少有 1 次成功的概率只有 27% 左右。
这不符合我的直觉，所以我用 Python 做了一个快速而粗略的模拟，假设从 58-80 次试验中概率呈线性增加，但没错，平均值大约是 53。
当概率迅速接近 100% 时，为什么平均值不在 58-80 范围内？
为什么可以使用“总体”概率将这种后载分布建模为简单的几何分布？
任何帮助我理解这一点的人都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660865/what-determines-the-mean-of-a-probability-distribution-of-bernoulli-variables-wh</guid>
      <pubDate>Sun, 02 Feb 2025 09:38:42 GMT</pubDate>
    </item>
    <item>
      <title>样本均值与自举均值相同，但 T 检验拒绝原假设</title>
      <link>https://stats.stackexchange.com/questions/660844/sample-mean-is-same-as-bootstrapped-mean-but-t-test-rejects-null-hypothesis</link>
      <description><![CDATA[我有 2 个样本（每个样本有大约 8500 个数据点）。我进行了引导（有替换）并绘制了平均差异的分布：

然后，我计算了 2 个样本的实际平均差异，结果是-5.53
我的理解表明，这意味着我的样本之间没有显着差异。但是，当我进行 T 检验时，我得到p_value=0.048
有人可以解释这是怎么可能的吗？据我理解，这本质上就是 T 检验所做的工作 - 创建均值差异分布并检查样本之间的实际均值差异在该分布范围内的可能性。
每个样本的原始分布都非常右偏，但我认为 8500 的样本量可以弥补这一点。此外，我进行了 Levene 检验，发现两个样本之间的方差没有差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/660844/sample-mean-is-same-as-bootstrapped-mean-but-t-test-rejects-null-hypothesis</guid>
      <pubDate>Sat, 01 Feb 2025 11:34:50 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用 Beta 回归还是 Box Cox 变换线性回归？</title>
      <link>https://stats.stackexchange.com/questions/660815/should-i-use-beta-regression-or-box-cox-transformed-linear-regression</link>
      <description><![CDATA[我的响应变量是态度分数，它是比例分数（总分/最高分），因此是连续的，范围从 0 到 1。最初，我认为 Beta 回归是一个不错的选择，因此我对分数进行了调整，以便没有真正的 0 或 1。
attitude_self$prop_score &lt;- pmin(pmax(attitude_self$prop_score, 0.001), 0.999)

我的模型如下，AIC 值为 -607：
beta_model &lt;- betareg(prop_score ~ age + group + gender + PerceivedKnowledge, 
data =itude_self, link = &quot;logit&quot;)

然而，经过进一步检查，它似乎 prop_score 不遵循真正的 beta 分布。我检查了分布/密度、偏度和峰度，并进行了 fitdist() 和 Kolmogorov-Smirnov (KS) 检验以测试拟合度。

skewness(prop_score)
[1] -2.792165
峰度(prop_score)
[1] 15.89607

fitdist(prop_score, &quot;beta&quot;)
通过最大似然法拟合分布 &#39; beta &#39; 
参数：
估计标准差。错误
shape1 2.6511869 0.17474578
shape2 0.7264323 0.03847695

&gt; ks.test(prop_score, &quot;pbeta&quot;, shape1 = 2.65, shape2 = 0.73)

渐近单样本 Kolmogorov-Smirnov 检验

数据：prop_score
D = 0.19366，p 值 &lt; 2.2e-16
备选假设：双侧

然后我使用 Box-Cox 变换对响应变量进行变换，并使用线性回归。
得到的 AIC 较低，为 -900，残差如下：

我转向变换后的线性回归而不是 beta 回归是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/660815/should-i-use-beta-regression-or-box-cox-transformed-linear-regression</guid>
      <pubDate>Fri, 31 Jan 2025 16:53:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么一个预测区间比另一个大？</title>
      <link>https://stats.stackexchange.com/questions/660694/why-is-one-prediction-interval-bigger-than-the-other</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660694/why-is-one-prediction-interval-bigger-than-the-other</guid>
      <pubDate>Wed, 29 Jan 2025 03:12:53 GMT</pubDate>
    </item>
    <item>
      <title>比较覆盖概率和间隔长度：BCa 与百分位数引导方法</title>
      <link>https://stats.stackexchange.com/questions/660390/comparing-coverage-probabilities-and-interval-lengths-bca-vs-percentile-bootst</link>
      <description><![CDATA[我进行了参数引导研究，以评估四个参数的覆盖概率，样本量分别为 35、50 和 100。3 个参数来自具有指数分布的混合模型，并通过 EM 算法进行估计：$\theta_{j}^{(k+1)} =\frac{\sum_{i=1}^{n} h_{ij}^{(k)}t_{i:n}}{\sum_{i=1}^{n} h_{ij}^{(k)}}$，其中 $h_{ij}^{(k)}$ 是后验概率。因此，无法确定估计的偏差。
在研究中，首先，我使用真实参数模拟 B 时间原始样本。对于每个样本，我估计参数以获得 MLE。基于MLE和每个样本，我做了参数引导，即我使用MLE作为“真实”参数，根据我的模型（部分混合模型）生成B时间引导样本，并且对于每个引导样本，我再次计算引导MLE。因此，我可以得到B时间百分位数CI和BCa CI（BCa使用B时间原始样本，加速参数就是经典的刀切估计量，见下面的评论）。覆盖概率是通过确定B时间CI是否包含真实参数来计算的。
该问题涉及混合模型中的两个指数尺度参数。结果表明，百分位数方法的覆盖概率趋于更保守，而BCa方法通常可以实现更接近名义水平的覆盖概率（$1-\alpha$）。但是，百分位数法的平均间隔长度通常较短。例如，对于 90% CI，百分位数法的 $\theta_{2}$ 覆盖概率为 95.2%，而 BCa 法的覆盖概率为 88.3%。但是，百分位数的平均间隔长度为 9.09，而 BCa 的平均间隔长度为 10.52。
我怀疑这种差异是由于研究中使用的样本量较小造成的。我查阅的一篇参考文献提到，BCa CI 会根据偏差和偏斜度进行调整，除了小样本外，通常是准确的。我也知道最短的 CI 并不总是最好的。从覆盖概率的角度来看，在这种情况下，BCa 似乎优于百分位数法。但与直觉相反，较短的 CI 也提供了更高的覆盖概率。我该如何证明我认为 BCa 更好？
我查阅了经典书籍，例如 Efron, B., &amp; Tibshirani, R. J. (1994) An Introduction to the Bootstrap、Davison, A. C., &amp; Hinkley, D. V. (1997) Bootstrap Methods and Their Application，并搜索了一些论文以找到类似的现象或讨论。但是，我还没有找到解决这一特定观察的明确理由，尤其是较短的 CI 提供更高的覆盖概率。
是否有人有见解或参考资料可以提供对这种行为的更深入了解？在此先感谢您的想法和指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/660390/comparing-coverage-probabilities-and-interval-lengths-bca-vs-percentile-bootst</guid>
      <pubDate>Wed, 22 Jan 2025 18:45:21 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯分布学习任务失败</title>
      <link>https://stats.stackexchange.com/questions/660238/bayesian-distribution-learning-task-failing</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660238/bayesian-distribution-learning-task-failing</guid>
      <pubDate>Sun, 19 Jan 2025 16:47:19 GMT</pubDate>
    </item>
    <item>
      <title>BIBD 块内分析问题</title>
      <link>https://stats.stackexchange.com/questions/659837/bibd-intrablock-analysis-issue</link>
      <description><![CDATA[我很难理解 Peter W. M. John 所著《实验的统计设计和分析》中平衡不完全块设计部分提出的这个问题。问题如附图所示。
示例问题第 1 部分：

示例问题第 2 部分：

为了便于复制我的问题，下面是值表，其中每行是一个块，每 4 行连续组成一个组：



处理
值
处理
值




A
38
B
29


C
49
D
&lt; td&gt;28


E
32
F
29


G
64
H
32


A
37
C
27


B
37
H
50


D
90
E
89


F
28
G
71


A
15
D
23


B
 47
G
64


C
35
F
39


E
22
H
18


A
3
E
13


B&lt; /td&gt;
45
C
36


D
11
G
24


F
39
H
37


A
23
F
39

&lt; tr&gt;
B
21
D
14


C
18
H
10


E
23
G
53


A
66
G
68


B
23
F
46


C
22
E
28


D
23
H
39


A
28
H
30


B
10
E
40


C
32
G
33


D
18
F
23



我在计算块的 SS（块内）时遇到了特别困难。根据前面的块内分析部分，方程应该是：
$$
\begin{equation}
k^{-1}\sum_{j}B_j^2-G^2/N
\end{equation}
$$
其中 k 是块的图，B 是每个块的治疗观察值的总和，G 是治疗观察值的全局总和，N 是观察值总数。我只能得到 ~15,405。
我很难看出我哪里做错了。治疗 SS 的块内方程运行良好，块间分析中调整后的块 SS 也运行良好。我还通过计算值获得了正确的块内错误！我感觉好像漏掉了某个公式，但仔细阅读了整章后，还是不知道在哪里。任何帮助我都感激不尽。]]></description>
      <guid>https://stats.stackexchange.com/questions/659837/bibd-intrablock-analysis-issue</guid>
      <pubDate>Fri, 10 Jan 2025 18:28:21 GMT</pubDate>
    </item>
    <item>
      <title>异方差和序列相关性检验</title>
      <link>https://stats.stackexchange.com/questions/633578/heteroscedasticity-and-serial-correlation-test</link>
      <description><![CDATA[让我们考虑使用 OLS 估计的线性回归模型。
根据 Hayashi（计量经济学，第 2 章）的信息

必须在误差不存在序列相关性的情况下才能执行 White 条件异方差检验；
必须在存在条件同方差的情况下才能执行 Ljung-Box Q 检验和 Breusch-Godfrey 检验以确定不存在序列相关性。

合理的问题是：如果一个检验中的 H0 是另一个检验中的假设，那么应该如何执行此类检验？
也许存在其他一些检验，例如，用于测试不依赖于条件同方差假设的序列相关性，或用于测试不依赖于无序列相关性假设的条件异方差？]]></description>
      <guid>https://stats.stackexchange.com/questions/633578/heteroscedasticity-and-serial-correlation-test</guid>
      <pubDate>Mon, 11 Dec 2023 06:06:30 GMT</pubDate>
    </item>
    <item>
      <title>AR(1) 模型中 $K$ 步后变化的方差</title>
      <link>https://stats.stackexchange.com/questions/616214/variance-of-change-after-k-steps-in-ar1-model</link>
      <description><![CDATA[我正在从标准 AR(1) 过程生成。假设衰减时间滞后 $\tau=100$ 和单位时间步长 $\Delta t=1$，因此 $\phi=\exp(-1 / (\tau/\Delta t))=0.99$。预测的自方差为 $\sigma^2 = \frac{1}{1 - \phi^2}$。
然后 AR 定义为 $y_{i+1} = \phi \times y_i + \epsilon$，其中 $\epsilon \sim \mathrm{Normal}(0,1)$。
现在我想调查 K 步之后的变化：$$y_{i+K}-y_i$$
我根据经验发现分布为正态分布且有方差：
$$\sigma(K)^2 = (\tau/2 + 1) \times (1 - \exp(K/\tau)^2)$$
这可以通过分析得出吗？
我怀疑 K 步会产生 $\tau$ 个方差标准差 $\sigma^2$，但为什么是一半，为什么会有偏移？
对于高斯过程更一般地来说：如何从功率谱密度积分中得出这个方差？
这个问题不同于自相关/自协方差，后者着眼于 $y_{i+K} \times y_i$。

这是我的 python 代码：
import numpy as np
def generate_AR(N = 1000, sigma = 1.0, c=0, dt=1., tau=100):
W = np.random.normal(0, sigma, size=N)

# 相关性：设置为 &lt; 1，否则不平稳！
phi = np.exp(-1. / (tau / dt))

y = np.empty(N)
y[0] = W[0]
for i in range(1, N):
y[i] = c + phi * y[i-1] + W[i]
return y

tau = 100
for i, dN in enumerate([2, 4, 10, 40, 100]):
dy = np.empty(10000)
for i in range(10000):
y = generate_AR(N=dN, tau=tau, dt=1)
dy[i] = y[-1] - y[0]
print(&#39;tau:&#39;, tau, &#39;steps:&#39;, (dN-1), &#39;variance:&#39;, np.var(dy))
]]></description>
      <guid>https://stats.stackexchange.com/questions/616214/variance-of-change-after-k-steps-in-ar1-model</guid>
      <pubDate>Thu, 18 May 2023 10:58:31 GMT</pubDate>
    </item>
    <item>
      <title>运行统计测试时使用后分层权重的适当方法 SPSS</title>
      <link>https://stats.stackexchange.com/questions/615957/appropriate-way-to-use-post-stratification-weights-when-running-statistical-test</link>
      <description><![CDATA[在处理使用非随机抽样设计收集的调查数据时，我使用了 SPSS 中的复杂样本（以及 SAS 中的 SUDAAN、R 中的调查）。例如，当数据收集中包含过度抽样时。复杂样本将样本设计纳入统计测试，提供更准确的估计值和标准误差。
我现在正在处理从调查小组收集的数据，其中包括后分层权重，以平衡样本与性别、年龄、种族/民族、地区和教育水平的人口。权重不用于缩放估计值以反映人口的实际规模。
由于这不是设计权重，我想知道在运行统计测试时如何应用权重。简单地“加权案例”就足够了吗？并执行标准统计测试，还是我应该像在设计中过度采样一样对待分层权重？
非常感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/615957/appropriate-way-to-use-post-stratification-weights-when-running-statistical-test</guid>
      <pubDate>Mon, 15 May 2023 19:45:27 GMT</pubDate>
    </item>
    <item>
      <title>是否应根据变量的偏度值删除它们？</title>
      <link>https://stats.stackexchange.com/questions/595880/should-variables-be-dropped-according-to-its-skewness-values</link>
      <description><![CDATA[我正在创建一个分类模型，根据许多因素预测一个人的信用评分。我从 kaggle 获得了数据集。当我开始做 EDA 部分时，我注意到数值变量的偏度值太高，例如 11、20 等。那么，我是否应该删除这些变量，或者是否有其他选择可以减少偏度并使其成为正态分布。
我尝试检查这些数值变量的异常值，发现每个变量都包含异常值。数据包含 100000 个样本，其中有 28 个变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/595880/should-variables-be-dropped-according-to-its-skewness-values</guid>
      <pubDate>Wed, 16 Nov 2022 14:05:41 GMT</pubDate>
    </item>
    </channel>
</rss>