<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 Jan 2025 12:32:10 GMT</lastBuildDate>
    <item>
      <title>这个散点图显示的是同方差性还是异方差性？</title>
      <link>https://stats.stackexchange.com/questions/660710/does-this-scatter-plot-show-homoscedasticity-or-heteroscedasticity</link>
      <description><![CDATA[回归模型的残差和预测值的散点图]]></description>
      <guid>https://stats.stackexchange.com/questions/660710/does-this-scatter-plot-show-homoscedasticity-or-heteroscedasticity</guid>
      <pubDate>Wed, 29 Jan 2025 12:26:18 GMT</pubDate>
    </item>
    <item>
      <title>如何用 IPW（WeightIt/weightthem）正确调整混杂因素，并用 adaptedCurves 绘制调整后的生存曲线？</title>
      <link>https://stats.stackexchange.com/questions/660709/how-to-properly-adjust-for-confounders-with-ipw-weightit-weightthem-and-plot-a</link>
      <description><![CDATA[我正在估计两组之间的总体生存率 (OS) 差异，同时调整混杂因素。我的工作流程包括：

缺失数据的多重插补。
使用 weightthem 包进行逆概率加权 (IPW)，方法为 &quot;cbps&quot; （estimand = &quot;ATE&quot;）。
使用 bal.tab() 和 love.plot()（来自 cobalt 包）检查平衡。
对加权数据进行 Cox 回归（在每个插补数据集中使用 coxph_weightit()）。
绘制调整后的生存曲线（使用 adjustedCurves 包，方法为 &quot;iptw_cox&quot;）。

以下是我的代码：
# 1. 生成 IPW 权重
w.out_model1 &lt;- weightthem(
formula_OS, 
data = df, 
method = &quot;cbps&quot;, # 例如 &quot;ebal&quot;、&quot;cbps&quot;、&quot;glm&quot; 等。
estimand = &quot;ATE&quot;,
criterion = &quot;smd.mean&quot;,
link = &quot;logit&quot;
)

# 2. 检查 IPW 前后的平衡
bal.tab(
w.out_model1, 
data = df, 
s.d.denom = &quot;pooled&quot;, 
m.threshold = 0.1, 
v.threshold = 2, 
imp.fun = &quot;max&quot;, 
un = TRUE, 
abs = TRUE,
binary = &quot;std&quot;
)

love.plot(
w.out_model1, 
stats = c(&quot;mean.diffs&quot;), 
Thresholds = c(m = 0.1), 
abs = TRUE, 
var.order = &quot;alphabetical&quot;,
grid = TRUE,
drop.distance = TRUE,
wrap = 20,
binary = &quot;std&quot;
)

# 3. 通过 coxph_weightit 在每个估算数据集上拟合 Cox 模型
fit.imp.cox &lt;- with(
df,
WeightIt::coxph_weightit(
Surv(OS_from_target_local_treatment, death) ~
age_binary + sex + bmi_binary + ASA_binary + 
comorbidities_Major + extrahep_metastases_at_diagnosis_CRLM +
RAS + BRAF + MMR + Systemic_treatment_prior_local_treatment +
Metastasis_diameter + Segments_treated_per_session_binned +
min_distance_gallblad_mm_binned + Margin_size_binary + stage_binary +
syn_meta_label_binary + Treatment_type_tumor_near_gallbladder
)
)

# 4. 来自 Cox 的汇总结果模型
summary(mice::pool(fit.imp.cox), conf.int = TRUE, exponentiate = TRUE)

# 5. 使用 adaptedCurves 绘制调整后的生存曲线
adj &lt;- adaptedsurv(
data = df,
variable = &quot;Treatment_type_tumor_near_gallbladder&quot;,
ev_time = &quot;OS_from_target_local_treatment&quot;,
event = &quot;death&quot;,
method = &quot;iptw_cox&quot;,
times = c(12, 36, 60, 96, 120),
bootstrap = TRUE,
n_boot = 500,
n_cores = 10,
treatment_model = Treatment_type_tumor_near_gallbladder ~
age_binary + sex + bmi_binary + ASA_binary + 
comorbidities_Major + extrahep_metastases_at_diagnosis_CRLM +
RAS + BRAF + MMR + Systemic_treatment_prior_local_treatment +
Metastasis_diameter + Segments_treated_per_session_binned +
min_distance_gallblad_mm_binned + Margin_size_binary + stage_binary +
syn_meta_label_binary,
weight_method = &quot;cbps&quot;
)

plot(adj, use_boot = TRUE, risk_table = TRUE, risk_table_stratify = TRUE, 
censoring_ind = &#39;lines&#39;)

经过此分析，我发现两组之间的 OS 没有统计学上的显著差异。但是，我想确认我的步骤是正确的，并且是 IPW + Cox 建模的最佳实践。此外，我想在调整后的生存曲线上绘制置信区间，但无法让它们出现在 adaptedCurves 生成的图中。

我的整体工作流程（多重插补中的 IPW + 通过 coxph_weightit 的 Cox 模型 + 通过 adaptedCurves 绘图）是否适合估计两组之间的调整生存曲线？

在使用 adaptedCurves 和 IPW 时，如何包含置信区间？我看到 use_boot =TRUE 选项，但置信区间仍未显示在最终图中。是否有不同的参数或已知的解决方法？


任何有关最佳实践、替代方法或调试技巧的指导都将不胜感激。提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/660709/how-to-properly-adjust-for-confounders-with-ipw-weightit-weightthem-and-plot-a</guid>
      <pubDate>Wed, 29 Jan 2025 12:02:36 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中 ELBO 推导的澄清</title>
      <link>https://stats.stackexchange.com/questions/660708/clarification-on-the-elbo-derivation-in-diffusion-models</link>
      <description><![CDATA[我正在阅读一篇关于去噪扩散模型的论文，第 10 页有以下 ELBO 推导。
$$
\begin{aligned}
\log p(\mathbf{x}_0) &amp;= \log \int p(\mathbf{x}_{0:T}) \, d\mathbf{x}_{1:T} \\
&amp;= \log \int \frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} q(\mathbf{x}_{1:T} | \mathbf{x}_0) \, d\mathbf{x}_{1:T} \\
&amp;= \log \mathbb{E}_{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \left[ \frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \right] \\
&amp;\geq \mathbb{E}_{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \right] \\
&amp;= \mathbb{E}_{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) \prod_{t=1}^{T} p_\theta (\mathbf{x}_{t-1} | \mathbf{x}_t)}{\prod_{t=1}^{T} q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right]
\end{aligned}
$$
我只是想澄清一下几件事。$x_0$ 是随机变量 $X_0$ 的实现吗？如果是，$q(x_{0:T})$ 是否意味着 $x_0$ 是实现，而其余的 $x_{1:T}$ 是随机变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/660708/clarification-on-the-elbo-derivation-in-diffusion-models</guid>
      <pubDate>Wed, 29 Jan 2025 11:54:19 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 预测区间的宽度随时间保持不变的原因是什么？</title>
      <link>https://stats.stackexchange.com/questions/660707/what-can-be-a-reason-of-width-of-arima-prediction-interval-being-constant-over-t</link>
      <description><![CDATA[我使用 forecast 包中的 forecast.Arima 来计算我的 SARIMA 模型的预测区间。我无法分享确切的数据，但我可以说它不是完全平稳的，并且模型是 SARIMA(3,0,0)(0,0,1)[12]。
forecast::forecast(model, h = 12, level = c(0.95), bootstrap = TRUE, npaths = 10^5)

我还看到了其他人的预测结果，据说他们使用相同的模型和数据，但用其他编程语言实现 - 它们是不同的。在我的例子中，预测区间随时间变宽，而在他们的例子中，预测区间的宽度大致固定。
造成这种差异的潜在原因是什么（除了代码中的拼写错误）？

我尝试设置 bootstrap = FALSE - 结果预测区间非常宽。我知道 bootstrap = TRUE 使用蒙特卡洛模拟来计算区间，我猜 TRUE 使用的是理论区间，但目前我不知道如何得出它们以及它们为什么这么宽（也许这与数据不是静止的事实以及 $\sigma$ 的估计有关？）
]]></description>
      <guid>https://stats.stackexchange.com/questions/660707/what-can-be-a-reason-of-width-of-arima-prediction-interval-being-constant-over-t</guid>
      <pubDate>Wed, 29 Jan 2025 11:22:56 GMT</pubDate>
    </item>
    <item>
      <title>非参数方法检查观测值是否与平均值不同</title>
      <link>https://stats.stackexchange.com/questions/660705/non-parametric-method-to-check-if-observations-are-different-than-mean</link>
      <description><![CDATA[我有一个随机变量的独立观测列表，我想检查这个变量的平均值是否与某个固定数字不同。我该怎么做？
分布不一定是正态的，甚至不是对称的。
有人建议我使用置换检验，但阅读更多内容后，我明白它是用来比较两个分布，而不是一个分布和一个固定数字。虽然我可以说另一个分布是固定的，但这不会有问题吗，因为方差当然是不同的？我的意思是，我想知道这个测试是否可以发现方差而不是平均值的差异，这不是我想要的。]]></description>
      <guid>https://stats.stackexchange.com/questions/660705/non-parametric-method-to-check-if-observations-are-different-than-mean</guid>
      <pubDate>Wed, 29 Jan 2025 10:39:34 GMT</pubDate>
    </item>
    <item>
      <title>从复杂的协方差矩阵生成数据是预期结果的转置</title>
      <link>https://stats.stackexchange.com/questions/660702/generating-data-from-complex-covariance-matrix-is-transpose-of-expected-result</link>
      <description><![CDATA[这是我的 Matlab 代码：
M = 2;
N = 100000;
R = [1, 0.5+0.1i; 0.5-0.1i, 1]
x = randn(M, N);
L = chol(R, &#39;lower&#39;);
x = L*x;
R_est = cov(x.&#39;)

我期望当 N 趋向于无穷大时，R_est 应该趋向于 R。相反，R_est 趋向于转置 (R)。我的理由如下：
一般来说，如果 $x=N(\mu, \Sigma)$，则 $Lx=N(L\mu, L\Sigma L^H)$。如果 $z=N(0, I)$（多元标准正态分布）且 $LL^H=\Sigma$，则 $Lz=N(0, \Sigma)$。因此，我的代码根据标准正态分布生成数据集 $x$，并采用 $Lx$ 来获取我想要的协方差矩阵。我已在我的代码中确认，$LL^H=\Sigma$。]]></description>
      <guid>https://stats.stackexchange.com/questions/660702/generating-data-from-complex-covariance-matrix-is-transpose-of-expected-result</guid>
      <pubDate>Wed, 29 Jan 2025 09:25:26 GMT</pubDate>
    </item>
    <item>
      <title>维数灾难是否适用于狄利克雷分布？</title>
      <link>https://stats.stackexchange.com/questions/660700/does-the-curse-of-dimensionality-apply-to-the-dirichlet-distribution</link>
      <description><![CDATA[我正在分析狄利克雷分布的解空间如何随着参数数量的增加而演变。我最初试图测量狄利克雷分布所覆盖的“体积”，期望它会随着参数数量的增加而增长。然而，我发现体积实际上随着参数数量的增加而缩小。
狄利克雷分布定义在$(K-1)$维单纯形上：
$$ S_{K-1} = \left\{ (x_1, x_2, \dots, x_K) \ \Big| \ x_i \geq 0, \sum_{i=1}^{K} x_i = 1 \right\}。 $$
这个单纯形的体积与 成正比
$$ \frac{1}{(K-1)!}。$$
由于阶乘增长迅速，因此随着 $K$ 的增加，这个体积会缩小。这表明，狄利克雷分布并没有扩展到广阔的空间（正如人们从维数灾难中预期的那样），而是越来越受到限制。
我的问题：

维数灾难是否适用于狄利克雷分布？我的直觉是，它并不像通常意义上的那样，因为空间在缩小而不是增长，从而防止了高维空间中常见的稀疏性问题。
狄利克雷分布是否仍然表现出高维效应（例如集中现象）？

如果能提供任何见解或参考资料来澄清这一点，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660700/does-the-curse-of-dimensionality-apply-to-the-dirichlet-distribution</guid>
      <pubDate>Wed, 29 Jan 2025 08:53:32 GMT</pubDate>
    </item>
    <item>
      <title>Somers 的二元结果 D，Python 与 SAS</title>
      <link>https://stats.stackexchange.com/questions/660697/somers-d-for-binary-outcome-python-vs-sas</link>
      <description><![CDATA[我正在尝试在编程语言之间迁移。 SAS 和 Python 似乎对 Somers&#39; D 的定义并不一致。在此示例中，x 被视为独立变量，而 y 是二元结果（因变量）。
以下是使用 scipy.stats.somersd 计算 Somers&#39; D 的 Python 代码片段，并与精心手动计算的 Somers&#39; D 进行交叉检查，结果为
$$\frac{C-D}{C+D+T},$$
其中 $C$、$D$ 和 $T$ 分别是一致、不一致和并列对的数量：
import scipy

def manual_somers_d(x, y):
# 初始化计数
C = 0
D = 0
T_Y = 0

# 计算 X 和 Y 中的一致、不一致对和关系
for i in range(len(x)):
for j in range(i + 1, len(x)):
if x[i] &lt; x[j] and y[i] &lt; y[j]: # 一致
C += 1
elif x[i] &gt; x[j] and y[i] &gt; y[j]: # 一致
C += 1
elif x[i] &lt; x[j] and y[i] &gt; y[j]: # 不一致
D += 1
elif x[i] &gt; x[j] and y[i] &lt; y[j]: # 不一致
D += 1
elif y[i] == y[j] and x[i] != x[j]: # Y 中一致（但 X 中不一致）
T_Y += 1

# 计算 Somers 的 D
return (C - D) / (C + D + T_Y)

x = [1,2,3,4,5]
y = [0,1,0,1,1]

print(manual_somers_d(x, y))
print(scipy.stats.somersd(x, y).statistic)

两种计算均得出相同结果 (0.4)。
但是，当针对同一数据集移至 SAS 时，计算结果将返回 Somers 的 D 值 2/3：
数据示例;
输入 x y;
数据线;
1 0
2 1
3 0
4 1
5 1
;
运行;

proc logistic data=example;
model y = x;
ods output Association=assoc;
运行;

proc print data=assoc;
运行;

顺便说一句，这与上面代码中计算 scipy.stats.somersd(y,x) 相同（切换变量）
一些观察：

文档 scipy.stats.somersd 指出 (x,y) 是 y 依赖于 x 的正确顺序。
模型语句文档 (SAS) 指出 model y = x 表达了相同的意思。

我在文档中遇到了错误吗？为什么值不匹配？]]></description>
      <guid>https://stats.stackexchange.com/questions/660697/somers-d-for-binary-outcome-python-vs-sas</guid>
      <pubDate>Wed, 29 Jan 2025 07:58:34 GMT</pubDate>
    </item>
    <item>
      <title>计算聚类数据中的敏感度和特异性的 SE（每个人多个测量值）</title>
      <link>https://stats.stackexchange.com/questions/660695/calculate-se-of-sensitivity-and-specificity-in-clustered-data-multiple-measures</link>
      <description><![CDATA[我正在评估诊断测试的敏感性和特异性。
我们有一个黄金标准测量方法（O2 饱和度）。每个人的评估分为 5 个级别。其中一些会低于临界值，一些会高于临界值。在每个级别，对于每个人，我们将尝试收集 5 个测量值，这些测量值要么是正数，要么是负数。



ID
级别
黄金标准
诊断




1
75
阴性
阴性


1
75
负
负


1
75
负
负


1
75
负
正


1
85
位置
位置


1
85
位置
位置


1
85
位置
负


2
75
负
负


2
..
...
...


...
..
...
...


30
95
Neg
Neg



不同的患者会有不同的测量次数，因为并不总是能够获得诊断，并且数据不会完全随机缺失（患者特征，例如年龄和体重将预测我们是否成功获得诊断，但获得诊断的概率在水平上是随机的。）
我的第一个想法是使用 GEE，但我被告知将仔细审查这些结果的机构不喜欢 GEE，我们应该使用引导来解释聚类。我从未见过如何做到这一点的例子。
我正在寻找关于在哪里学习这一点（或如何做到这一点）的建议或意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/660695/calculate-se-of-sensitivity-and-specificity-in-clustered-data-multiple-measures</guid>
      <pubDate>Wed, 29 Jan 2025 03:31:45 GMT</pubDate>
    </item>
    <item>
      <title>使用引导程序计算时间序列的预测区间</title>
      <link>https://stats.stackexchange.com/questions/660694/using-bootstrap-to-calculate-prediction-intervals-of-time-series</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660694/using-bootstrap-to-calculate-prediction-intervals-of-time-series</guid>
      <pubDate>Wed, 29 Jan 2025 03:12:53 GMT</pubDate>
    </item>
    <item>
      <title>等效结构方程模型中结构系数的解释</title>
      <link>https://stats.stackexchange.com/questions/660684/interpretation-of-structure-coefficients-in-equivalent-structural-equation-model</link>
      <description><![CDATA[本文描述了统计等效结构方程模型的问题，其中变量之间的关联（即因果关系的方向）各不相同，但拟合指标相同。作为示例，他们展示了以下两个模型的结构系数：

在模型 2 和模型 3 之间，SE、感知认可和兴趣变量之间的一些箭头被翻转（作者选择通过重新排列变量来绘制）。得到的拟合指数是相同的。
然而，这种翻转导致性别和三个中介变量的结构系数不同。例如，模型 2 预测性别对 SE 的影响为 0.27，但在模型 3 中为 0.08。
我应该怎么做？这些模型之一是“正确的”吗？ （即有充分的理论依据，并可能有实验可以找出因果关系）并且其结构系数是否正确？我是否应该不关注这些“中间”系数，而只考虑总体效应？]]></description>
      <guid>https://stats.stackexchange.com/questions/660684/interpretation-of-structure-coefficients-in-equivalent-structural-equation-model</guid>
      <pubDate>Tue, 28 Jan 2025 21:58:29 GMT</pubDate>
    </item>
    <item>
      <title>具有 beta geom 分布分位数函数的 CDF</title>
      <link>https://stats.stackexchange.com/questions/660681/cdf-with-beta-geom-distribution-quantile-function</link>
      <description><![CDATA[我有一个带 CDF 的 beta 几何 (BG) 分布：
$$F(x) = \Bigg( 1 - \frac{\text{B}(a,b+x)}{\text{B}(a,b)} \Bigg)
\quad \quad \quad 
\text{for } x \geqslant 0,$$
其中 $\text{B}$ 是 beta 函数。有没有办法在不借助数值方法和求根算法的情况下找到上述分布的分位数。我知道 beta 分布与 F 分布相关，我正在尝试看看我们是否可以找到与 BG 分布的类似关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/660681/cdf-with-beta-geom-distribution-quantile-function</guid>
      <pubDate>Tue, 28 Jan 2025 20:03:16 GMT</pubDate>
    </item>
    <item>
      <title>双向方差分析 - 参数估计解释</title>
      <link>https://stats.stackexchange.com/questions/660677/two-way-anova-parameter-estimates-interpretation</link>
      <description><![CDATA[双向方差分析中生成的参数估计表：

当我解释参数估计表时，我被引导相信截距是数据的整体总平均值？这是正确的吗？
但是，我很困惑它与参考类别有什么关系？它们的参数估计值为 0？这是否意味着设计 C 和尺寸小（参考类别）嵌入在截距内？
我的问题是设计 C 和尺寸小对因变量和整体总平均值的影响怎么会相同？]]></description>
      <guid>https://stats.stackexchange.com/questions/660677/two-way-anova-parameter-estimates-interpretation</guid>
      <pubDate>Tue, 28 Jan 2025 19:17:58 GMT</pubDate>
    </item>
    <item>
      <title>$\ell_1$ 惩罚分位数回归的收敛速度为 $\sqrt{\frac{s\log (p \vee n)}{n}}$</title>
      <link>https://stats.stackexchange.com/questions/660611/rate-of-convergence-of-ell-1-penalized-quantile-regression-is-sqrt-fracs</link>
      <description><![CDATA[在标准 LASSO 文献中，您经常会遇到 LASSO 估计量以 $\sqrt{\frac{s\log p}{n}}$ 的速率收敛（例如，参见此帖子）。
一种相关方法是 $\ell_1$ 惩罚分位数回归，这意味着您将 $\ell_1$ 惩罚（如在 Lasso 中）添加到分位数回归损失。这样，你就可以估算给定$X$的$Y$的条件分位数，同时将一些系数缩小为零以用于变量选择或正则化目的。设置如下：
$$
\hat{\beta} = \arg \min_{\beta} \sum_{i=1}^n \rho_\tau (y_i - x_i^\top \beta) + \lambda \|\beta\|_1,
$$
其中

$\rho_\tau(u) = u(\tau - \mathbb{I}\{u &lt; 0\})$ 是分位数损失，调整残差的权重，
$\lambda$ 控制惩罚强度，
$\|\beta\|_1 = \sum_{j=1}^p |\beta_j|$ 是鼓励稀疏性的 $\ell_1$-惩罚。

此方法理论的主要参考文献是 Belloni 和 Chernozhukov (2011) 在《统计年鉴》中。
在他们的论文中（例如，请参阅摘要、第 2.6 节或定理 2 了解完整结果），他们提到估计量以 $\sqrt{\frac{s\log (p \vee n)}{n}}$ 的速率收敛，其中 $\vee$ 用于表示 $p$ 和 $n$ 中的最大值。它们甚至可以在一组紧凑的分位数指标上均匀地实现这一结果。
因此，与标准 LASSO 速率相比，我们现在可以看到对数中有 $p \vee n$。对于许多有趣的制度，即 $p &gt; n$，这将给出与标准 LASSO 相同的速率。
有人知道为什么现在 $p$ 和 $n$ 存在最大值吗？任何见解都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660611/rate-of-convergence-of-ell-1-penalized-quantile-regression-is-sqrt-fracs</guid>
      <pubDate>Mon, 27 Jan 2025 14:01:25 GMT</pubDate>
    </item>
    <item>
      <title>预测变量中的随机趋势 (OLS)</title>
      <link>https://stats.stackexchange.com/questions/660588/stochastic-trend-in-predictors-ols</link>
      <description><![CDATA[我正在构建一个 OLS 模型。
据我所知，预测变量中的随机趋势会导致非平稳残差。
为了解决这个问题（我们希望残差是平稳的），有两种方法可以解决：

引入协整变量
差分

首选数字 1，因为差分会从序列中删除对长期预测至关重要的信息。（如果我错了，请纠正我）
假设我们选择数字 1，并引入另一个与具有随机趋势的预测变量协整的预测变量。
现在，将考虑随机趋势，残差应该再次平稳。
现在我的问题/方法：
我以这两个协整预测器作为输入运行 ECM。
此 ECM 的输出将在原始系统中再次引入。
现在：我是否需要删除两个预测因子，只留下 ECM 的输出？
或者我需要将这三个都包含在系统中，并将其作为 OLS 的输入？
所以基本上：
Y = b+ B1*predictor1_stoch_trend + B2*predictor2_cointegrated_w_predictor1 + B3*error_output_ecm + B4*predictor4_linear_trend

或
Y = b + B3*error_output_ecm + B4*predictor4_linear_trend

（对于 predictor4，我会从序列中减去线性趋势以使其平稳）]]></description>
      <guid>https://stats.stackexchange.com/questions/660588/stochastic-trend-in-predictors-ols</guid>
      <pubDate>Mon, 27 Jan 2025 10:12:42 GMT</pubDate>
    </item>
    </channel>
</rss>