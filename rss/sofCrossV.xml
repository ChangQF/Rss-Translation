<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 23 Apr 2024 18:16:41 GMT</lastBuildDate>
    <item>
      <title>如何使用 INLA 拟合具有随机截距和斜率的模型？</title>
      <link>https://stats.stackexchange.com/questions/645661/how-can-i-fit-a-model-with-a-random-intercept-and-slope-using-inla</link>
      <description><![CDATA[我正在尝试使用 INLA::inla() 复制我过去通过 glmmTMB::glmmTMB() 运行的负二项式 GLMM 的形式。在前者中，很容易指定每个受试者的随机截距和给定协变量的随机斜率。
set.seed(312)
my_df &lt;- data.frame(ID = rep(c(&quot;S1&quot;, &quot;S2&quot;),each = 50)) %&gt;%
         突变（X = runif（100））％&gt;％
         行式() %&gt;%
         变异（Y = if_else（ID ==“S1”，
                            rnbinom(1, mu = 5 * X, 大小 = 3),
                            rnbinom(1, mu = 2 * X, 大小 = 2))) %&gt;%
         取消分组()
mod_glmmtmb &lt;- glmmTMB::glmmTMB(Y ~ 1 + X + (1 + X | ID),
                                数据= my_df，
                                家族 = glmmTMB::nbinom2())

在 INLA 我认为这应该是正确的公式：
mod_inla &lt;- INLA::inla(Y ~ 1 + f(ID, X, model = &quot;iid&quot;),
                       家庭=“n二项式”，
                       数据 = my_df)

但是，当我检查估计的随机效应时，我只看到随机截距的值：
mod_inla$summary.random$ID

尽管事实上，当我检查拟合曲线时，每个受试者的斜率明显不同，如下所示：

我对检索每个主题的随机斜率特别感兴趣，因此我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/645661/how-can-i-fit-a-model-with-a-random-intercept-and-slope-using-inla</guid>
      <pubDate>Tue, 23 Apr 2024 17:33:44 GMT</pubDate>
    </item>
    <item>
      <title>因果推理：元学习器的使用</title>
      <link>https://stats.stackexchange.com/questions/645660/causal-inference-meta-learners-usage</link>
      <description><![CDATA[我一直在使用 Econ ML 包对我的数据运行因果推理。我有一个数据集，其中包含分为治疗和控制以及许多其他功能的客户。我对这些进行匹配并获得了包含匹配的治疗和控制的匹配数据集。如果我计算 2 个匹配组之间平均结果 Y 的差异，我得到的 ATE 为 3。
现在我的问题是我是否训练元学习者，例如。 X 学习者在匹配之前对数据进行学习，然后使用它来估计我所拥有的匹配数据集上的 ATE，我应该得到非常接近 3 的 ATE 吗？或不？如果不是，原因是什么？这是我不太清楚的部分。]]></description>
      <guid>https://stats.stackexchange.com/questions/645660/causal-inference-meta-learners-usage</guid>
      <pubDate>Tue, 23 Apr 2024 16:52:24 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用 games-howell post hoc 进行特定的成对比较吗？</title>
      <link>https://stats.stackexchange.com/questions/645658/can-i-use-games-howell-post-hoc-for-specific-pairwise-comparisons</link>
      <description><![CDATA[我将提供更多背景信息：
我最初的意图是进行单向方差分析，然后进行计划的比较（对比）。遗憾的是，方差同质性假设被违反，并且由于我的项目中的样本量差异巨大，我决定进行韦尔奇的方差分析测试。
据我了解，按照计划的对比也假设方差同质性，我不能再这样做进行分析 - 所以我考虑使用 games-howell。
问题是我不需要所有的成对比较，而且我不知道仅针对特定比较进行测试是否是正确的方法（我也没有找到 R 中支持它的函数）。&lt; /p&gt;
我想到的一个选择是多次运行游戏，每次使用不同的 2 个组，并通过 bonferonni 校正自行校正膨胀的 alpha。这种方法可以接受吗？有更好的办法吗？
我将非常感谢任何有关此事的帮助。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/645658/can-i-use-games-howell-post-hoc-for-specific-pairwise-comparisons</guid>
      <pubDate>Tue, 23 Apr 2024 16:50:20 GMT</pubDate>
    </item>
    <item>
      <title>回归分析中的系数</title>
      <link>https://stats.stackexchange.com/questions/645657/coefficient-in-regression-analysis</link>
      <description><![CDATA[我正在对两个变量（独立变量和因变量）进行回归。
如果结果显示 p 值 &gt; 0.05，无统计学意义。这是否意味着我们也拒绝该系数？如果系数为负，我们至少可以说这种关系是负的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645657/coefficient-in-regression-analysis</guid>
      <pubDate>Tue, 23 Apr 2024 16:50:19 GMT</pubDate>
    </item>
    <item>
      <title>矛盾间隔时间分布的直观解释</title>
      <link>https://stats.stackexchange.com/questions/645656/intuitive-explanation-of-paradoxical-interval-times-distribution</link>
      <description><![CDATA[当我在区间 [0,1] 上模拟泊松过程时，则

连续点之间的间隔时间服从指数分布。
例如在下面的代码中，当我选择 x[2]-x[1] 时，它是指数分布的。


但是，

连续点之间的间隔时间（以包含特定点的间隔为条件）$x$ 遵循 Erlang 分布。
例如在下面的代码中，当我选择 x[k]-x[k-1] 时，其中选择“k”使得 x[k] 是高于 0.5 的最小值，那么它是 Erlang 分布式


我可以说它应该是指数分布变量的总和，因此 Erlang 分布：例如，当特定值为 0.5 时，它之前和之后的值之间的距离是指数分布的。
但是，任何区间的分布都是指数分布，而穿过某个特定点的特定区间的分布是不同分布的，这感觉很矛盾。
如何更直观地解释这一点？
&lt;小时/&gt;
下面的代码可能会解释更多：

set.seed(1)

t = 复制(10^4, expr = {
  n = rpois(1,40)
  x = runif(n)
  x = x[阶数(x)]
  k = min(其中(x&gt;0.5))
  x[k]-x[k-1]
  #x[2]-x[1]
})

hist(t, Breaks = seq(0,1,0.005),freq = 0, xlim = c(0,0.3), main = “跨越 0.5 的区间直方图”)

t = 复制(10^4, expr = {
  n = rpois(1,40)
  x = runif(n)
  x = x[阶数(x)]
  k = min(其中(x&gt;0.5))
  #x[k]-x[k-1]
  x[2]-x[1]
})

hist(t, Breaks = seq(0,1,0.005),freq = 0, xlim = c(0,0.3), main = “第一个区间的直方图”)
]]></description>
      <guid>https://stats.stackexchange.com/questions/645656/intuitive-explanation-of-paradoxical-interval-times-distribution</guid>
      <pubDate>Tue, 23 Apr 2024 16:31:43 GMT</pubDate>
    </item>
    <item>
      <title>伯努利加权和的浓度界限</title>
      <link>https://stats.stackexchange.com/questions/645654/concentration-bound-for-weighted-sum-of-bernoullis</link>
      <description><![CDATA[$\{X_i\}_{i=1,\ldots,n}$ 是独立同分布的。带有参数 $p$ 的伯努利随机变量。定义
$$Y = \sum_{i=1}^n a_iX_i$$
其中 $a_i&gt;0$ 是已知（非随机）常量。我想要以下概率的上限
$$\mathbb{P}(|Y-\mathbb{E}Y| &gt; \varepsilon).$$
备注：

我正在寻找 $k\exp(\cdot)$ 形式的边界来表示某些常量 $k&gt; ;0$.
利用 McDiarmid 不等式，我可以得到这样的界限，但该界限不依赖于 $p$。对于我的用例， $p$ 非常小，有趣的是如何通过使其依赖于 $p$。
我怀疑边界将涉及 $\|a\|_{\infty}$ 或 $\| a\|_2$ 或两者。无论如何，我以后处理 $\|a\|_2$ 会更容易。但是，即使涉及 $\|a\|_\infty$ 或任何其他规范，也请发布您的答案。

任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/645654/concentration-bound-for-weighted-sum-of-bernoullis</guid>
      <pubDate>Tue, 23 Apr 2024 16:19:06 GMT</pubDate>
    </item>
    <item>
      <title>循环自动编码器网络的特征缩放</title>
      <link>https://stats.stackexchange.com/questions/645653/feature-scaling-for-recurrent-auto-encoder-network</link>
      <description><![CDATA[我的模型有 5 维输入。所讨论的模型是循环自动编码器，人们正在谈论无监督学习。
这些特征是物理变量，就我的目的而言，计算这些特征的导数来帮助建模似乎是可行的。然而，我对如何扩展这些衍生品有疑问。在某些情况下，某些尺寸几乎是恒定的，唯一的变化是测量产生的噪声。如果我将所有导数缩放至 &lt;0,1&gt;，那么我就人为地将噪声夸大为潜在的重要变化。最初，我将原始变量缩放为 &lt;0,1&gt;，因为我知道它们的最大范围，然后计算导数。然而，在某些情况下导数大于 1，我面临着潜在的梯度爆炸问题。
什么是合理的导数缩放方法，以便保留数据的原始性质。]]></description>
      <guid>https://stats.stackexchange.com/questions/645653/feature-scaling-for-recurrent-auto-encoder-network</guid>
      <pubDate>Tue, 23 Apr 2024 16:16:28 GMT</pubDate>
    </item>
    <item>
      <title>在梯度提升回归中，如何使输出值接近0</title>
      <link>https://stats.stackexchange.com/questions/645652/in-a-gradient-boost-regression-how-to-bring-the-output-values-nearer-to-0</link>
      <description><![CDATA[我已经建立了 GBM 回归模型。在进行交叉验证时，我注意到所有值都需要接近 0（无论是正值还是负值）。
我尝试更改一些参数，例如更改学习率、损失函数、估计器数量以及添加提前停止函数。这些改变对我来说都不起作用。
有没有办法让模型预测的数字更接近0？某种方法或函数？
我正在使用 Python 来构建模型。
如果需要，我可以提供有关模型交叉验证和我尝试的方法的更多信息。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/645652/in-a-gradient-boost-regression-how-to-bring-the-output-values-nearer-to-0</guid>
      <pubDate>Tue, 23 Apr 2024 16:06:45 GMT</pubDate>
    </item>
    <item>
      <title>平均剥夺指数得分</title>
      <link>https://stats.stackexchange.com/questions/645649/mean-index-of-deprivation-score</link>
      <description><![CDATA[我创建了一个 python 函数，它可以返回 2019 年多重剥夺指数分数的子集，表示特定纬度和经度的定义半径内的 LSOA 区域。
这是一个例子：

我想报告 IncDec 的中位数。听起来可能很明显，但这只是这些 LSOA 十分位数指标的中位数，对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645649/mean-index-of-deprivation-score</guid>
      <pubDate>Tue, 23 Apr 2024 15:51:40 GMT</pubDate>
    </item>
    <item>
      <title>学习率查找图的解释</title>
      <link>https://stats.stackexchange.com/questions/645648/interpretation-of-this-learning-rate-finder-plot</link>
      <description><![CDATA[我有以下与学习率查找器结果相关的图（遵循 Smith (2015) 的原则），根据这个代码示例制作并找到了损失降幅非常窄，这意味着什么？找到的最佳学习率为 1.5655376e-05，执行代码的批量大小为 512。

现在我使用 Plotly 制作了相同的图，以便更好地看到它，如下所示，我放大了感兴趣的部分，并且我验证了最佳学习率甚至不在突然下降的部分中，它位于更早（试图理解为什么选择的最佳学习率远没有突然下降）。
]]></description>
      <guid>https://stats.stackexchange.com/questions/645648/interpretation-of-this-learning-rate-finder-plot</guid>
      <pubDate>Tue, 23 Apr 2024 15:38:27 GMT</pubDate>
    </item>
    <item>
      <title>在另一个线性方程中使用 PLSR 分量是否可取？</title>
      <link>https://stats.stackexchange.com/questions/645645/is-it-advisable-to-use-plsr-components-in-another-linear-equation</link>
      <description><![CDATA[我目前拥有两组（健康组与疾病组）的蛋白质浓度形式的生物数据，我有兴趣确定组内这些蛋白质浓度与年龄（时间点）之间的关系。重申一下，我的协变量是我的蛋白质浓度（[n x m] 维度），我的响应变量是年龄（[n x 1] 维度），其中健康组和疾病组都有 n 个受试者。我在组内进行了 PLSR（仅限疾病或仅限健康），以确定蛋白质浓度（标准化后）能够在多大程度上预测衰老。
我还拥有另一个数据集，其中包含相同两组的功能磁共振成像数据和衰老数据。我有兴趣确定这些蛋白质特征如何解释相关的功能磁共振成像结果。我很好奇是否可以为每个组运行线性模型。该公式将遵循以下结构： $fMRI_{healthy} = PLSR_{{component1}_{scores}} + PLSR_{{component2}_{scores}} + \epsilon_{healthy }$
我想使用这些分数的原因是因为它允许我询问每个受试者的蛋白质特征，以确定它可以在多大程度上解释同一受试者的功能磁共振成像数据。但我担心的是 PLSR 模型是一种预测模型，可以最大化协变量和响应之间的协变。该响应也存在于 fMRI 数据中，因为 fMRI 数据也是在每个相应时间点收集的。所以我不确定上述内容的有效性，我想知道是否有人可以帮助澄清这是否是一个有效的分析程序。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/645645/is-it-advisable-to-use-plsr-components-in-another-linear-equation</guid>
      <pubDate>Tue, 23 Apr 2024 15:24:35 GMT</pubDate>
    </item>
    <item>
      <title>PSPP多变量线性回归分析</title>
      <link>https://stats.stackexchange.com/questions/645644/pspp-multiple-variable-linear-regression-analysis</link>
      <description><![CDATA[我刚刚开始使用线性回归，但我很难理解它。这对我来说似乎没有任何意义。是的，这是学校作业，但我需要指导，而不是寻求直接答案。我需要了解线性回归，因为稍后我将需要它来进行机器学习。至少我是这么认为的。
因变量是体重，自变量是身高、年龄、黑面包消耗量和白面包消耗量。如果我可以将所有这些变量包含在回归模型中，如何在 PSPP 中进行检查？或者我应该删除其中一些。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/645644/pspp-multiple-variable-linear-regression-analysis</guid>
      <pubDate>Tue, 23 Apr 2024 15:23:24 GMT</pubDate>
    </item>
    <item>
      <title>这就是 1,96 x √2 的原因 [已关闭]</title>
      <link>https://stats.stackexchange.com/questions/645642/which-is-the-reason-for-1-96-x-%e2%88%9a2</link>
      <description><![CDATA[使用 1,96 x √2 的原因是什么？
重复性系数在其公式中使用1,96 √2，并且最小可检测变化也使用它。
两者都是估计区间的置信度，但为什么是 1,96 x √2？]]></description>
      <guid>https://stats.stackexchange.com/questions/645642/which-is-the-reason-for-1-96-x-%e2%88%9a2</guid>
      <pubDate>Tue, 23 Apr 2024 15:19:05 GMT</pubDate>
    </item>
    <item>
      <title>低于阈值的概率总和</title>
      <link>https://stats.stackexchange.com/questions/645641/sum-of-probabilities-below-threshold</link>
      <description><![CDATA[我有一个离散概率分布 $\mathcal{D}$，支持 $\{1, \ldots , n\}$ 和 PMF $p(i), i=1,\ldots,n$。
是否有一些与 $$\sum_{i : p(i) &lt; 相关的众所周知的量（如偏度、峰度、香农熵和其他特征） ; \epsilon} p(i)?$$
我可以通过与分布的香农熵相关的东西来限制这个总和，前提是$\epsilon &lt; 1/2$：
$$ \sum_{i : p(i) &lt; \epsilon} p(i) \leq (\log \epsilon^{-1})^{-1} \sum_{i : p(i) &lt; \epsilon} p(i) \log(1/p(i)) \leq (\log \epsilon^{-1})^{-1} H(\mathcal{D})$$&lt; /p&gt;
但是，这似乎很牵强。]]></description>
      <guid>https://stats.stackexchange.com/questions/645641/sum-of-probabilities-below-threshold</guid>
      <pubDate>Tue, 23 Apr 2024 15:07:50 GMT</pubDate>
    </item>
    <item>
      <title>准蒙特卡罗 vs 蒙特卡罗 KL 散度</title>
      <link>https://stats.stackexchange.com/questions/645638/quasi-monte-carlo-vs-monte-carlo-kl-divergence</link>
      <description><![CDATA[我使用 Sobol 序列模拟了 N(0,1) 的 x 个样本与 N(0,1) 伪随机数的 100x 个样本。
我将模拟切碎为 100 个伪随机数样本。我发现 Sobol 序列的 KL 散度大约 50 倍会产生较低的 KL 散度。我预计由于索博尔序列的差异较小，该值会较低，但事实并非如此。为什么会这样？
defgenerate_random_normal(num_sims, num_fact, num_steps, use_sobol, use_antithetic):
    如果使用_sobol：
        # 初始化 2 维 Sobol 序列生成器
        sobol_gen = qmc.Sobol(d=num_fact * num_steps)
        random_numbers = sobol_gen.random_base2(m=int(np.log2(num_sims)))
        random_numbers = np.atleast_3d(np.reshape(random_numbers, (num_sims, num_steps, num_fact)))
        返回norm.ppf(随机数)
    别的：
        如果使用对立：
            norm_orig = np.random.normal(0, 1, (int(num_sims / 2), num_steps, num_fact))
            返回 np.vstack((norm_orig, -norm_orig))
        别的：
            返回 np.random.normal(0, 1, (num_sims, num_steps, num_fact))


def test_generate_random_normal(自身):

    num_sim = 2 ** 10
    时间点 = 1
    系数 = 1
    平均值 = np.zeros(时间点 * 因子)
    cov = np.identity(时间点 * 因子)
    sobol_sample = MultiFactorMarketDynamic.generate_random_normal(num_sim, time_points, 因子, True, False)

    sobol_kl_divergence = 总和(
        [np.log(multivariate_normal.pdf(sobol_sample[i, :, :].reshape(time_points * 因子), 平均值=平均值, cov=cov))
         对于范围内的 i(sobol_sample.shape[0])]) / num_sim
    一个=[]
    b = []
    对于范围（100）内的 i：
        antithetic_random_sample = MultiFactorMarketDynamic.generate_random_normal(num_sim, time_points, 因子,
                                                                                   错误的，
                                                                                   真的）
        antithetic_kl_divergence = 总和(
            [np.log(
                multivariate_normal.pdf(antithetic_random_sample[i, :, :].reshape(time_points * 因子), 均值=均值,
                                        cov=cov)) 对于范围内的 i(sobol_sample.shape[0])]) / num_sim
        a.append(antithetic_kl_divergence)

        random_sample = MultiFactorMarketDynamic.generate_random_normal(num_sim, time_points, 因子, False, False)
        norm_kl_divergence = 总和(
            [np.log(
                multivariate_normal.pdf(random_sample[i, :, :].reshape(time_points * 因子), 均值=均值, cov=cov))
             对于范围内的 i(sobol_sample.shape[0])]) / num_sim
        b.append(norm_kl_divergence)
]]></description>
      <guid>https://stats.stackexchange.com/questions/645638/quasi-monte-carlo-vs-monte-carlo-kl-divergence</guid>
      <pubDate>Tue, 23 Apr 2024 14:38:35 GMT</pubDate>
    </item>
    </channel>
</rss>