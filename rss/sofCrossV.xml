<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 24 Dec 2024 21:14:53 GMT</lastBuildDate>
    <item>
      <title>随机过程的均值、方差和收敛</title>
      <link>https://stats.stackexchange.com/questions/659176/mean-variance-and-convergence-of-stochastic-processes</link>
      <description><![CDATA[假设我有一些随机过程，我初始化两个空数组 A:[]，B:[]。接下来，从 $N(0,1)$ 中采样的元素被分配给 $A$ 或 $B$，每次采样一个元素，都会将其与均值 $\mu_A, \mu_B$ 进行比较。无论哪个均值距离采样值较远，相应的数组都会接收分配的值。
通过模拟，我观察到当采样单元以相等/均匀的分配概率随机分配给$A,B$时，均值之间的差异收敛于零，方差小于比较值。
这种随机过程有名称吗？除了纯粹通过模拟之外，是否有可用的长期行为解析解？]]></description>
      <guid>https://stats.stackexchange.com/questions/659176/mean-variance-and-convergence-of-stochastic-processes</guid>
      <pubDate>Tue, 24 Dec 2024 20:52:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们使用梯度*输入来生成 CNN 的显著图？</title>
      <link>https://stats.stackexchange.com/questions/659175/why-we-use-gradientinput-for-producing-the-saliency-map-of-a-cnn</link>
      <description><![CDATA[为 CNN 生成显著性图的最简单方法是计算特定输入的 梯度，如此处所述。
还有另一种方法，其中显著性图等于 梯度*输入。我读到它使显著性图更清晰，但我想解释一下为什么会这样，或者只是与输入相乘背后的动机。]]></description>
      <guid>https://stats.stackexchange.com/questions/659175/why-we-use-gradientinput-for-producing-the-saliency-map-of-a-cnn</guid>
      <pubDate>Tue, 24 Dec 2024 20:29:14 GMT</pubDate>
    </item>
    <item>
      <title>当我有一个具有两个以上级别的分类预测器时，GLMER 是什么？</title>
      <link>https://stats.stackexchange.com/questions/659174/glmer-when-i-have-a-categorical-predictor-with-more-than-two-levels</link>
      <description><![CDATA[如果我有一个具有两个可能输出（0/1）的因变量，以及作为预测因子的分类独立变量，同时需要在模型中包含随机截距，如果我的一个预测因子有三个不同的级别，我该怎么办？我希望能够直接在模型中检测三个级别之间的差异（a
我不想使用贝叶斯模型。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659174/glmer-when-i-have-a-categorical-predictor-with-more-than-two-levels</guid>
      <pubDate>Tue, 24 Dec 2024 20:18:24 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用哪种统计检验</title>
      <link>https://stats.stackexchange.com/questions/659173/which-statistical-test-should-i-use</link>
      <description><![CDATA[我的数据不遵循正态分布，不是线性的，并且有重复测量的变量（温度、湿度、物候）和仅测量一次的变量（DBH、年龄、总高度等）。现在，我想知道这些变量中哪一个对我的因变量影响最大，但我陷入了困境。你能给我一些建议吗？我还是个初学者。]]></description>
      <guid>https://stats.stackexchange.com/questions/659173/which-statistical-test-should-i-use</guid>
      <pubDate>Tue, 24 Dec 2024 19:57:28 GMT</pubDate>
    </item>
    <item>
      <title>预测变量在回归中可以相互关联吗？</title>
      <link>https://stats.stackexchange.com/questions/659169/can-predictors-be-correlated-with-each-other-in-regression</link>
      <description><![CDATA[这是我的设置（纵向混合效应）：

时间段：$t = 1,...,T$
集群：$j = 1,...,J$
变量：$z_{jt}$、$x_{jt}$、$y_{jt}$

最初，我想制作以下模型（Z 的当前值取决于 X 和 Y 的先前值）：
$$z_{jt} = \beta_1x_{j,t-1} + \beta_2y_{j,t-1} + \epsilon_{jt}$$
然而，就我而言，存在以下问题：

X 可能影响 Y（例如，X 的过去值和当前值可能影响 Y 的未来值）
Y 可能影响 X（例如，Y 的过去值和当前值可能影响 X 的未来值）
Z 可能同时影响 X 和 Y（例如，Z 的过去值和当前值可能影响 X 和 Y 的未来值）

因此，似乎我的数据中既有内生性问题，也有同时性问题。
在这种情况下，我可以使用哪种混合效应/纵向建模策略？这是可以使用 SEM（结构方程模型）的地方吗？还是 VAR 模型更好？工具变量方法？2 阶段回归？联立方程？我不知道从哪里开始。]]></description>
      <guid>https://stats.stackexchange.com/questions/659169/can-predictors-be-correlated-with-each-other-in-regression</guid>
      <pubDate>Tue, 24 Dec 2024 18:04:00 GMT</pubDate>
    </item>
    <item>
      <title>有争议的观点是，PDF 的卷积可能不是 PDF</title>
      <link>https://stats.stackexchange.com/questions/659168/controversial-view-that-convolutions-of-a-pdf-might-not-be-a-pdf</link>
      <description><![CDATA[有一条帖子说，卷积公式对 f(x) * f(s-x).dx 进行积分，再次返回 PDF。我有点同意这一点。但后来，我偶然发现了这个 YouTube 视频。我在下面提供了它们的链接。
在视频的 00:15:30，如果右侧的单条曲线（三角形）是 PDF，那么当他说“这个数字 s 是该（卷积）函数的输入，相应的输出是左下方图形的面积”时，他的意思是什么。
我理解，s 取精确值的概率理想情况下应该是 0。那么他怎么能说“相应的输出是左下方图形的面积”呢？由于概率，因此面积应限制为 0。
链接：
证明 PDF 的卷积可得到 PDF
https://youtu.be/IaSGqQa5O-M?si=smyv_63FsMNkH9ly&amp;t=930]]></description>
      <guid>https://stats.stackexchange.com/questions/659168/controversial-view-that-convolutions-of-a-pdf-might-not-be-a-pdf</guid>
      <pubDate>Tue, 24 Dec 2024 17:25:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 拟合带有工具变量的负二项混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/659167/fit-negative-binomial-mixed-effects-model-with-instrumental-variables-with-r</link>
      <description><![CDATA[如何使用 R 拟合带有工具变量的固定效应负二项式模型？
我尝试过 fixest 包，但它仅支持 OLS 的工具变量，而不支持负二项式：
id &lt;- rep(seq(1,10), each=5)
year &lt;- rep(seq(2021, 2025), times=10)
df &lt;- data.frame(id=id, year=year)
df[[&quot;weight&quot;]] &lt;- rnorm(nrow(df), 100, 10)
df[[&quot;height&quot;]] &lt;- 2*df$weight+rnorm(nrow(df), 0, 5)
df[[&quot;count&quot;]] &lt;- rpois(nrow(df), df$height+rnorm(nrow(df), 0, 5))
mod &lt;- fixest::fenegbin(count ~ 1 | id | height~weight, df)

fixest::fenegbin(count ~ 1 | id | height ~ weight, df) 中的错误： 
参数“fml”不能包含由竖线（“|”）分隔的两个以上部分。IV 仅适用于“feols”。
语法为：DEP VAR ~ EXPL VARS | FIXED EFFECTS。 （不允许 IV。）

相关：https://stackoverflow.com/questions/73982152/iv-regression-in-fixed-effect-models-with-diagnostics/75144897#75144897]]></description>
      <guid>https://stats.stackexchange.com/questions/659167/fit-negative-binomial-mixed-effects-model-with-instrumental-variables-with-r</guid>
      <pubDate>Tue, 24 Dec 2024 16:55:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么在半监督 VAE 模型中将目标 𝑦 y 用作编码器的输入？</title>
      <link>https://stats.stackexchange.com/questions/659156/why-is-the-target-y-used-as-an-input-to-the-encoder-in-a-semi-supervised-vae</link>
      <description><![CDATA[正如标题所述，我理解 Kingma 的原始论文中方程 (6-7) 的数学推导。但是，由于 𝑦 已在模型中用作分类器的目标，那么将 𝑦 用作编码器的输入的目的是什么？这会不会是多余的？似乎从编码器的输入中删除 𝑦 在实践中也是可行的。]]></description>
      <guid>https://stats.stackexchange.com/questions/659156/why-is-the-target-y-used-as-an-input-to-the-encoder-in-a-semi-supervised-vae</guid>
      <pubDate>Tue, 24 Dec 2024 13:53:10 GMT</pubDate>
    </item>
    <item>
      <title>如何为由另外两个类组成的类设计网络和损失函数？</title>
      <link>https://stats.stackexchange.com/questions/659148/how-to-design-a-network-and-loss-function-for-classes-composed-of-two-other-cla</link>
      <description><![CDATA[给定一个包含三个类别的图像数据集，A、B 和 C，其中 C 是 A 和 B 的组合，我们希望训练一个分类器来预测：

如果只有 A，则为 A
如果只有 B，则为 B
如果 A 和 B 都存在，则为 C。

我们如何设计最终的分类层以及损失函数？
我考虑过对 C 类进行阈值处理，即使使用可学习的阈值，但这会受到数据集中类别分布的严重影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/659148/how-to-design-a-network-and-loss-function-for-classes-composed-of-two-other-cla</guid>
      <pubDate>Tue, 24 Dec 2024 11:28:42 GMT</pubDate>
    </item>
    <item>
      <title>如何用 Python 开始使用项目反应理论</title>
      <link>https://stats.stackexchange.com/questions/659132/how-to-get-started-with-item-response-theory-in-python</link>
      <description><![CDATA[我有一个大型 CSV 文件，其中包含（String studentId、String questionId、bool isCorrect）。问题都是小学的基本数学知识，questionIds 指的是一组类似的问题。例如，我们有这样的 questionId

OPlusO（包含 2+3、5+4 等练习）
OPlusT（包含 2+10、20+4、30+7 等练习）
OPlusOWithCarry（7+8、5+9 等）
Times2（3x2、7x2 等）

一个学生可以对一个 questionId 有多个答案，我们假设所有学生练习都是在一周内完成的。 （我们有一年多的数据）
在第一阶段，我想确定问题 ID 的难度并评估学生的能力。
我认为 IRT 模型在这里很有用，所以我想开始使用它来获得一些实践经验。
但我不确定从哪里/如何开始。最好使用 Python，因为我习惯了，但其他（命令行）工具也可以。我在 Linux 上。
ChatGPT 和 Claude 都让我误以为几行代码就足够了，但都没有给出一个可行的示例。
提前谢谢，
Marc]]></description>
      <guid>https://stats.stackexchange.com/questions/659132/how-to-get-started-with-item-response-theory-in-python</guid>
      <pubDate>Mon, 23 Dec 2024 17:27:05 GMT</pubDate>
    </item>
    <item>
      <title>元分析中嵌套数据的模型简化</title>
      <link>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</link>
      <description><![CDATA[我正在对子组中不同程度的异质性进行荟萃分析。由于数据结构是嵌套的（效应大小嵌套在研究中），我通过添加研究的随机效应和研究内的效应大小来考虑这一点。轮廓似然图在其估计值处达到峰值。
比较具有不同程度异质性的模型和具有共同异质性估计值的模型的似然比检验是显著的。然而，在获得 $ \tau^2_\text{between} $ 和 $ \tau^2_\text{within} $ 的置信区间 (CI) 后，除了一个之外，$ \tau^2_\text{within} $ 的所有 CI 的下限均为零。一个显著的估计值仍然是适中的。
在这种情况下，将模型简化为仅在研究层面具有随机效应的两级模型是否合适，从而仅考虑研究之间的异质性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</guid>
      <pubDate>Sun, 22 Dec 2024 20:41:46 GMT</pubDate>
    </item>
    <item>
      <title>在评估 GLM 模型时，AIC 值或预测显著性的 p 值更重要吗？</title>
      <link>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</guid>
      <pubDate>Sat, 21 Dec 2024 15:14:21 GMT</pubDate>
    </item>
    <item>
      <title>使用麦当劳 Omega 作为非加权总和评分的可靠性度量是合理的</title>
      <link>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</link>
      <description><![CDATA[在最近的文献中，报告麦当劳欧米茄作为可靠性估计值显然比报告系数 alpha 更受青睐（例如 McNeish，2017）。一个经常给出的论点是，系数 alpha（或 Cronbach&#39;s alpha）假设（本质上）tau-euqivalent 测量模型，即因子载荷必须相等，而麦当劳欧米茄允许不同的载荷。由于对 omega 有多种看法，为了简单起见，我们只关注单维尺度上的总 omega，如 McNeish (2017) 所指定的那样：

（其中 $\lambda_i$ 是因子载荷，$\theta_{ii}$ 是第 i 项的误差/残差方差）
在文章中，McNeish 写道：

Omega (McDonald, 1970, 1999）是常用的复合信度测量方法，可用于多种软件程序。Omega 专为同类量表而设计，其中项目与被测构造的相关程度各不相同（即，在因子分析设置中，不会假设负载相等）。换句话说，不假设 tau 等价。当量表中的项目按单位加权以形成总量表分数但量表本身为同类时，复合信度是合适的（Bentler，2007；Geldhof 等人，2014）。单位加权量表意味着量表的总分是通过将各个项目的原始分数（或反向编码的原始分数，如果适用）相加来计算的：每个项目的权重相等。

我觉得这违反直觉：例如，假设 CFA 表明同类模型（自由载荷）比更严格的 tau 等效模型更适合样本数据，因此我们决定使用 omega 而不是系数 alpha。然而，后续分析将使用基于同等权重项目计算得出的总和/平均分数，即使我们刚刚在 CFA 中表明这种类型的测量模型不能很好地拟合我们的数据。
我的问题：
有人可以提供一些合理的解释，为什么对于由同等权重项目组成的分数报告麦当劳的 omega 是有意义的？

来源：
McNeish，D.（2017 年）。感谢系数 alpha，我们将从这里开始。心理方法，23(3)，412–433。https://doi.org/10.1037/met0000144]]></description>
      <guid>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</guid>
      <pubDate>Fri, 20 Dec 2024 12:24:36 GMT</pubDate>
    </item>
    <item>
      <title>防止时间序列数据拆分中的数据泄露</title>
      <link>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</link>
      <description><![CDATA[我正在研究机械系统的故障检测问题，目标是确定故障类型。我使用的数据集对于每种类型的故障（目标标签）都有三种大小，每种故障大小都有四种不同的工作条件，如下图所示。请注意，数据集中的每个样本都是时间序列，由于样本数量太少而且太长，因此需要将每个样本分成固定长度的块。现在的问题是如何将每个块分配给训练集或测试集，以确保公平和无偏见的评估。

在之前的研究中，常见的做法是将所有块随机分成训练集和测试集。

使用这种方法，神经网络模型通常在测试集上实现近乎完美的性能。然而，这种方法似乎存在根本缺陷，因为将近似平稳的信号分成块会导致来自同一信号的块高度相似，而相似的块可能最终出现在两个集合中，从而导致严重的数据泄漏。为了说明这种数据泄漏，我将 t-SNE 算法应用于这些块。

在此图中，每种颜色对应特定的故障类型和故障大小。请注意，来自同一样本的块紧密聚集在一起。以下是放大版的图：

我认为应该根据故障大小来拆分块。例如，故障大小为 1 和 2 的样本块应包含在训练集中，而故障大小为 3 的样本块应包含在测试集中。这可确保测试集中不存在来自训练信号的任何信息。

现在我想问：

我关于数据泄露的说法正确吗？如果正确，是否有其他方法可以更严格地证明数据泄露，例如使用相似性指标或其他可视化？
您如何看待提议的拆分方法？基于故障大小的拆分是否足以防止数据泄露？如果不是，您会推荐哪些替代拆分策略来确保公平评估？

编辑：针对评论，我将尝试澄清一些观点。在我的应用中，不同设置中的故障大小可能有很大差异，因此重要的是模型可以在不暴露于与不同故障大小相关的信号的情况下检测故障。理想情况下，我们会在训练集中包含不同故障大小的信号，但这是不切实际的。另一方面，预计在两种故障大小上训练的模型将难以在第三种未见过的故障大小上表现良好。这就引出了一个问题：“训练测试拆分之间的相似度有多大是可以接受的？”如果答案是这取决于应用程序，那么在我的情况下，与某些故障大小相关的信号在测试期间应该保持未知，因为这反映了生产中的条件。
正如@Ggjj11 已经提到的，在我提出的方法中，重复拆分，并报告平均准确度。具体来说，在第一次迭代中，与小故障和中等故障相关的信号包含在训练集中，而与大故障相关的信号包含在测试集中。在第二次迭代中，与小故障和大故障相关的信号包含在训练集中，而中等故障大小包含在测试集中。第三次迭代遵循类似的模式。经过一番研究，我发现这种方法被称为GroupKFold 交叉验证。]]></description>
      <guid>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</guid>
      <pubDate>Tue, 17 Dec 2024 15:38:37 GMT</pubDate>
    </item>
    <item>
      <title>估计负质谱强度测量的误差</title>
      <link>https://stats.stackexchange.com/questions/658460/estimating-errors-on-negative-mass-spec-intensity-measurements</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658460/estimating-errors-on-negative-mass-spec-intensity-measurements</guid>
      <pubDate>Sun, 08 Dec 2024 18:43:36 GMT</pubDate>
    </item>
    </channel>
</rss>