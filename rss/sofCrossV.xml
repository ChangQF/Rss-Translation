<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 29 Sep 2024 12:30:53 GMT</lastBuildDate>
    <item>
      <title>有/无交互作用的 GEE 模型 - 解释</title>
      <link>https://stats.stackexchange.com/questions/655071/gee-model-with-without-interaction-interpretation</link>
      <description><![CDATA[我在治疗期间（在几个时间点）测量了一种新的生物标志物。所有患者的临床数据都在基线时存在。现在，我正在使用 GEE 模型和探索性方法来识别在治疗期间对生物标志物有影响的临床变量。
我在单独的 GEE 模型中测试了每个临床变量，生物标志物是因变量，并在模型中采用因子时间和临床变量。
我还以相同的方式测试了每个临床变量，但还包括时间和临床变量之间的相互作用。现在我不明白为什么有些临床变量具有主效应，但包括相互作用时间/临床变量后，其他具有主效应的临床变量也出现了。
哪种方法最适合识别对生物标志物有影响的临床变量 - 使用仅包含因子时间和临床变量的模型，还是我始终必须包括相互作用？
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/655071/gee-model-with-without-interaction-interpretation</guid>
      <pubDate>Sun, 29 Sep 2024 10:23:51 GMT</pubDate>
    </item>
    <item>
      <title>Maxout 激活函数与 ReLU（权重数量）</title>
      <link>https://stats.stackexchange.com/questions/655067/maxout-activation-function-vs-relu-number-of-weights</link>
      <description><![CDATA[据我了解，Maxout 函数的工作原理与 ReLU 完全不同。
ReLU 函数是 max(0, x)，因此输入 x 是 (W_T x + b)
Maxout 函数有许多 W，它是 max(W1_T x + b1, W2_T x + b2, ...)
我理解 ReLU 函数在函数中没有感知器的权重，但 Maxout 函数在函数中有权重。 （并且有更多参数）
我理解得对吗？
许多激活函数，例如 ReLU、Sigmoid、tanh、Leaky ReLU 都使用标量值，这是一个已经计算出的值 (W_T x + b)
Maxout 函数与此不同，对吗？
Softmax 函数层没有权重吗？
那么从激活函数的变化来看，权重的数量可以改变吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655067/maxout-activation-function-vs-relu-number-of-weights</guid>
      <pubDate>Sun, 29 Sep 2024 04:23:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有样本偏差的情况下进行超参数调整？</title>
      <link>https://stats.stackexchange.com/questions/655064/how-to-hyperparameter-tune-without-sample-bias</link>
      <description><![CDATA[在寻找微调模型超参数 (HP) 的方法时，我发现了多个关于交叉验证技术 (K-folds、LPO、OOB.632+) 和选择最佳超参数组合的方法 (网格搜索、随机搜索等) 的参考资料。许多人说要使用嵌套交叉验证技术来估计模型的一些质量指标，但没有人解释如何选择最终模型将使用的超参数。
我能找到的最好的文章是有关嵌套交叉验证 (nCV) 或甚至是用于特征选择的 nCV 变体的文章，这将带来相同的模型选择问题。但是这种方法不提供一组唯一的超参数，而是为 CV 技术创建的每个折叠提供多个超参数。
我试图思考的是使用每个折叠的训练集的最佳超参数组合，并在某种类型的投票系统中考虑它们的平均质量指标和它们的“最佳组合出现”率，以确定哪种组合是最佳的，然后使用所有测试集估计所选超参数的质量指标，但我不确定这是否会导致无偏的 HP 选择和质量估计。
你有什么文章或解释可能有用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655064/how-to-hyperparameter-tune-without-sample-bias</guid>
      <pubDate>Sat, 28 Sep 2024 23:14:32 GMT</pubDate>
    </item>
    <item>
      <title>arima 模型和绘图之间存在差异</title>
      <link>https://stats.stackexchange.com/questions/655057/a-discrepancy-between-the-arima-model-and-plot</link>
      <description><![CDATA[我运行了 arima 模型并估算了拟合值。我在 arima 模型中的常数值为 153。由于时间变量 (t_centered) 以零为中心，因此常数表示零处的预测值。但是，时间中零处的红线徘徊在 185 左右。我只是想知道为什么 arima 模型的常数和时间中 0 处的绘制值之间存在差距。两者应该相似或相同。我的理解正确吗？
注意：当我运行 ols 模型时，我没有遇到上述问题。
# 拟合 ARIMA 模型
arima(x = data[, &quot;dv&quot;], order = c(4, 0, 0), xreg = data[, c(&quot;t_centered &quot;, &quot; t_centered2&quot;, &quot;x1&quot;, &quot;t_centered_x1&quot;, &quot;t_centered2_x1&quot;, &quot;x2&quot;, &quot;x3&quot;, &quot;x4&quot;, &quot;x5&quot;)], include.mean = T)

# 估计拟合值
data$fitted_m_all = fitted(m_all)

# 绘制观察值和拟合值：
gall &lt;- ggplot(data, aes(x = t_centered, y = dv, color = x1) ) +
geom_point(color=“grey”,size=2.5) +
geom_smooth(method=“lm”, linewidth = 1.2, se=F, 
mapping=aes(y=fitted_m_all), formula=y~poly(x,2)) +
geom_vline(xintercept = 0, alpha = 1, 
linewidth = .5, linetype =“solid”, color=“black”) +
coord_cartesian(xlim = c(-30, 30), ylim = c(50, 250))+
theme_bw() + 
theme(legend.position=“none”)+
scale_colour_brewer(palette=“Set1”)+
实验室（x =“时间”，y =“数字”）
胆汁

]]></description>
      <guid>https://stats.stackexchange.com/questions/655057/a-discrepancy-between-the-arima-model-and-plot</guid>
      <pubDate>Sat, 28 Sep 2024 20:06:26 GMT</pubDate>
    </item>
    <item>
      <title>brms 中的 Priors 并未按我预期发挥作用</title>
      <link>https://stats.stackexchange.com/questions/655043/priors-in-brms-are-not-working-as-i-expect</link>
      <description><![CDATA[我是贝叶斯统计的新手，我正在尝试使用 brms 拟合一个简单的线性回归并手动设置每个参数的先验，但它并没有像我预期的那样工作
这是我的代码
data_2 &lt;- structure(list(YearsExperience = c(1.1, 1.3, 1.5, 2, 2.2, 2.9, 3, 3.2, 3.2, 3.7, 3.9, 4, 4, 4.1, 4.5, 4.9, 5.1, 5.3, 5.9, 6, 
6.8, 7.1, 7.9, 8.2, 8.7, 9, 9.5, 9.6, 10.3, 10.5), Salary = c(39343L, 
46205L, 37731L, 43525L, 39891L, 56642L, 60150L, 54445L, 64445L, 
57189L, 63218L, 55794L, 56957L, 57081L, 61111L, 67938L, 66029L, 
83088L, 81363L, 93940L, 91738L, 98273L, 101302L, 113812L, 109431L, 
105582L, 116969L, 112635L, 122391L, 121872L)), class = &quot;data.frame&quot;, row.names = c(NA, 
-30L))

priors &lt;- c(
set_prior(&quot;normal(28700, 2000)&quot;, class = &quot;Intercept&quot;),
set_prior(&quot;normal(9006, 1000)&quot;, class = &quot;b&quot;, 
coef = &quot;YearsExperience&quot;),
set_prior(&quot;normal(0, 2000)&quot;, class = &quot;sigma&quot;, lb = 0) 
)

fit_brms &lt;- brm(Salary ~ YearsExperience, data = data_2, Prior=priors)

但是，当我绘制链时，例如，当先验分布远离负值时进行截距。而且我设置的先验并非完全不准确。

如果我使用默认先验进行拟合，效果很好。]]></description>
      <guid>https://stats.stackexchange.com/questions/655043/priors-in-brms-are-not-working-as-i-expect</guid>
      <pubDate>Fri, 27 Sep 2024 21:16:13 GMT</pubDate>
    </item>
    <item>
      <title>具有斜率函数的用户指定值的边际效应</title>
      <link>https://stats.stackexchange.com/questions/655041/marginal-effects-at-user-specified-values-with-slopes-function</link>
      <description><![CDATA[我在使用 marginaleffects 包的 slope 函数估计用户指定值的边际效应时遇到了麻烦
假设我想用帕尔默企鹅数据集预测 body_mass_g
library(marginaleffects)

dat &lt;- read.csv(
&quot;https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv&quot;)


这是我的函数。我想将 flipper_length 设置为 180，将 bill_length_mm  设置为 39 或 40。
mod.lm &lt;- lm(body_mass_g ~ bill_length_mm + flipper_length_mm + 
species, data = dat)

slopes(
mod.lm,
newdata = datagrid(
flipper_length_mm = 180,
bill_length_mm = c(39,40)))



我知道一些事情是错误的，因为所有预测因子的估计值都相同，无论 bill_length_mm 的值设置为 39 还是 40。
我尝试使用 glm 二元结果变量运行类似的模型，它按预期工作。
dat$large_penguin &lt;- ifelse(dat$body_mass_g &gt; 
median(dat$body_mass_g, na.rm = TRUE), 1, 0)

mod &lt;- glm(large_penguin ~ bill_length_mm + flipper_length_mm + 
species, data = dat, family = binomial)

slopes(
mod,
newdata = datagrid(
flipper_length_mm = 180,
bill_length_mm = c(39,40)))


为什么 lm 模型没有按预期执行，而 glm 模型却可以？]]></description>
      <guid>https://stats.stackexchange.com/questions/655041/marginal-effects-at-user-specified-values-with-slopes-function</guid>
      <pubDate>Fri, 27 Sep 2024 21:04:18 GMT</pubDate>
    </item>
    <item>
      <title>当某一组没有进步空间时测量二元预测因子的横截面和纵向效应</title>
      <link>https://stats.stackexchange.com/questions/655065/measuring-the-cross-sectional-and-longitudinal-effect-of-a-binary-predictor-when</link>
      <description><![CDATA[我负责分析老年人的特定疾病，并跟踪该疾病在横向和纵向上对某些结果的影响。我们通过收集结果的重复测量值并运行包含时间和疾病状态之间交互项的混合模型来实现这一点。我们通常假设患有该疾病将与横向上更差的结果分数和纵向上以更快的速度恶化的结果分数相关。在实践中，我们经常看到我们的横向假设得到证实，但纵向假设却相反。也就是说，对照组的分数比疾病组恶化得更快。我相信原因在于，在基线时，患有该疾病对横向分数的影响如此之大，以至于他们的分数几乎没有空间随着时间的推移而进一步恶化。下面是一个可以说明我的观点的例子：
data &lt;- data.frame(&quot;Group&quot; = c(rep(&quot;Disease&quot;,10), rep(&quot;Control&quot;, 10)), 
&quot;Time&quot; = c(1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2), 
&quot;Outcome&quot; = c(8,9, 7, 8, 6, 7, 5, 6, 9, 9, 8, 9, 4, 7, 4, 8, 3, 7, 5, 9))

ggplot(data, aes(x = Time, y = Outcome, color = Group)) +
geom_point() +
geom_smooth(method = &quot;lm&quot;)


因此，在这种情况下，假设结果是某人每天在家中走动时出现并发症的次数，我们在基线（时间点 1）和五年后（时间点 2）测量这个数字。由于我们研究的是老年人群，我们相信随着研究参与者年龄的增长，结果会随着时间的推移而恶化（增加）。显然，疾病组在基线（时间点 1）时有更多并发症。但是，对照组的并发症随着时间的推移而更加严重地增加。这几乎就像基线时患病的横断面效应非常强烈，以至于随着时间的推移，病情没有太大的恶化空间，而对照组则有足够的恶化空间。在这个例子中，一个人可能出现的最高并发症数量是每天 8-10 次，而疾病组在基线时已经接近这个极限。
所以我的问题是：有没有办法从统计上调整这种影响，或者这只是结果固有的一个无法克服的问题？如果我们相信这种现象对于特定结果是真实的，我们是否不应该探索疾病对所述结果的纵向影响？有人知道任何教科书和/或期刊文章解决或提到类似的现象，可以为我提供更多见解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655065/measuring-the-cross-sectional-and-longitudinal-effect-of-a-binary-predictor-when</guid>
      <pubDate>Fri, 27 Sep 2024 17:51:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 simr 计算线性混合模型中计划对比的功率和样本大小？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654818/calculate-power-and-sample-size-for-planned-contrasts-in-linear-mixed-models-usi</link>
      <description><![CDATA[我使用 lmerTest 包在 R 中建立了一个线性混合模型，其中有三个分类因子（A 有 3 个级别，B 有 8 个级别，C 有 2 个级别）和一个针对主题的随机效应。我有兴趣使用 simr 对 B 的两个特定计划水平对比进行功效分析。这可能吗？
例如，我们分别用 B1、B2、B3 和 B4 表示因子 B 的水平 1、2、3、4，用 A1 表示因子 A 的水平 1。我们需要以下对比的功效。

比较 B1 和 B2，比较 B3 和 B4，控制所有其他变量（如果模型不包含交互项）
比较 B1 和 B2，并在特定 A 水平 A2 比较 B3 和 B4（如果考虑 A 和 B 之间的交互）

我理解 simr 可以模拟模型中所有固定效应的功效和样本大小，因此我们可以通过将 B 的参考水平设置为 B1 来将 B1 与 B 的所有其他水平进行比较。但我不确定如何设置它来计算上述特定对比的功效。我也知道 emmeans 可以设置和计算事后对比，但有没有办法将它与 simr 集成以进行功效分析和大小调整？如果没有，那么适当的方法是什么？
有人可以分享使用 simr 模拟这些计划对比的功效和样本大小的经验吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654818/calculate-power-and-sample-size-for-planned-contrasts-in-linear-mixed-models-usi</guid>
      <pubDate>Tue, 24 Sep 2024 03:16:21 GMT</pubDate>
    </item>
    <item>
      <title>回归问题的预期误差减少</title>
      <link>https://stats.stackexchange.com/questions/654594/expected-error-reduction-for-regression-problems</link>
      <description><![CDATA[我想在 Python 中实现一种基于预期误差减少 (EER) 的主动学习方法：
https://axon.cs.byu.edu/Dan/778/papers/Active%20Learning/roy.pdf
https://arxiv.org/abs/2211.09283
对于回归问题，其中机器学习模型是基于树的模型（我计划使用 XGBoost、随机森林回归器或 VotingRegressor，它们只是平均输出我不需要使用贝叶斯推理框架，但如果有必要，我会使用它。目前，我有两个问题：

上述论文中的方程式非常复杂，没有伪代码。我不明白如何为 EER 编写损失函数，以及整体框架是什么。我的粗略理解是，为了计算这个损失，对于每个未标记的输入样本，我需要运行我的 ML 模型，计算每个可能标签在我的 ML 模型下的概率，然后用它来计算损失……但我错过了细节。
这些方程式是针对分类任务给出的。我实际上有一个回归任务。我如何使 EER 适应回归？我想我应该用积分代替对所有可能标签值求和...因为我可以为输出变量给出上限和下限，高斯-勒让德数值积分可能是计算效率更高的方法。

如何实现基于 EER 的回归主动学习？包含 Python 代码/伪代码的答案是最好的，但即使只是对算法和要使用的方程式的详细解释也足够了（然后我可以尝试自己用 Python 实现它，如果遇到困难，请在 StackOverflow 上提问）。]]></description>
      <guid>https://stats.stackexchange.com/questions/654594/expected-error-reduction-for-regression-problems</guid>
      <pubDate>Thu, 19 Sep 2024 09:39:01 GMT</pubDate>
    </item>
    <item>
      <title>我如何确定我的生态 GLMM 是否构建准确？</title>
      <link>https://stats.stackexchange.com/questions/654219/how-do-i-determine-if-my-ecological-glmm-is-accurately-constructed</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654219/how-do-i-determine-if-my-ecological-glmm-is-accurately-constructed</guid>
      <pubDate>Wed, 11 Sep 2024 16:42:13 GMT</pubDate>
    </item>
    <item>
      <title>证明对数 Exp 的方差大于对数 Exp 的方差</title>
      <link>https://stats.stackexchange.com/questions/648034/prove-that-variance-of-log-exp-is-greater-than-variance-of-exp-log</link>
      <description><![CDATA[在变分推断的背景下，我们从估计梯度：
$\log E_{q \sim Q(z|x)} [ \frac{p(z,x)}{q(z|x)} ]$
到：
$E_{q \sim Q(z|x)} [ \log \frac{p(z,x)}{q(z|x)} ]$，即 ELBO。
我想明确比较蒙特卡洛估计量对这两个量梯度的方差，但我在代数方面遇到了困难。
通过蒙特卡洛估计量，我的意思是我们用每个期望中的随机变量的样本均值替换每个表达式中的期望。
你能帮忙？
参考文献：https://arxiv.org/pdf/2208.11970，第 3 页，方程 7-8
基本上我不明白为什么我们不最大化上述参考文献中的方程 7 而是方程 8。也许是因为方差较低，但如何严格地证明这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/648034/prove-that-variance-of-log-exp-is-greater-than-variance-of-exp-log</guid>
      <pubDate>Sun, 26 May 2024 22:05:18 GMT</pubDate>
    </item>
    <item>
      <title>如果我使用 R 中的 wilcox.test 来处理配对数据，它到底返回什么？我想根据这个结果计算效应大小</title>
      <link>https://stats.stackexchange.com/questions/542165/if-i-use-the-wilcox-test-from-r-for-paired-data-what-exactly-it-returns-i-want</link>
      <description><![CDATA[我想计算成对 Wilcoxon（有符号秩）的效应大小。
有两个选项：Z/sqrt(N_pairs)
或秩-双列相关性。
wilcox.test(... paired=TRUE) 返回“V”。
文献中有很多字母：对于 Mann-Whitney（非成对），它要么是“U”，要么是“W” （取决于方法，即 Wilcoxon 方法），对于成对的 Wilcoxon，它是 Z 或 V。
在我的情况下，V = 0。
数据：
d &lt;- structure(list(PatientId = structure(c(1L, 1L, 2L, 2L, 3L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L), .Label = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, 
&quot;8&quot;, &quot;9&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;), class = &quot;factor&quot;), 时间点 = 结构 (c(1L, 
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
2L, 1L, 2L, 1L, 2L, 1L, 2L), .标签 = c(&quot;基线&quot;, &quot;第 3 个月&quot;
), class = &quot;factor&quot;), 结果 = c(0, 9, 6, 8, 0, 0, 0, 0, 0, 0, 
0, 0, 1, 2, 3, 3, 1, 2, 1, 1, 3, 3, 7, 7)), row.names = c(NA, 
-24L), class = &quot;data.frame&quot;)

&gt; wilcox.test(结果 ~ 时间点，配对 = TRUE，数据 = d)

带连续性校正的 Wilcoxon 符号秩检验

数据：按时间点的结果
V = 0，p 值 = 0.1
备选假设：真实位置偏移不等于 0

警告消息：
1：在 wilcox.test.default(x = c(0, 6, 0, 0, 0, 0, 1, 3, 1, 1, 3, 7) 中，:
无法计算具有关系的精确 p 值
2：在 wilcox.test.default(x = c(0, 6, 0, 0, 0, 0, 1, 3, 1, 1, 3, 7) 中，:
无法计算具有零的精确 p 值

rank_biserial 不起作用：
&gt; rank_biserial(结果 ~ 时间点，配对 = TRUE，数据 = d)
r (等级 biserial) | 95% CI
----------------------------------
-1.00 | [-1.00, -1.00]
警告消息：
在 ranktransform.numeric((x - y) - mu, sign = TRUE, verbose = verbose) 中：
检测到零。这些不能进行符号等级转换。

但 rstatix 包实现返回了其他内容（匹配 wilcox.test 而没有连续性校正）：
coin::wilcoxsign_test(结果 ~ 时间点 | PatientId，数据=d，zero.method = &quot;Wilcoxon&quot;)

渐近 Wilcoxon 符号秩检验

数据：y x (pos, neg) 
按区块分层
Z = -2，p 值 = 0.07
备选假设：真 mu 不等于 0

&gt; wilcox.test(结果 ~ 时间点，配对 = TRUE，数据 = d，正确 = FALSE)

Wilcoxon 符号秩检验

数据：按时间点的结果
V = 0，p 值 = 0.07
备选假设：真实位置偏移不等于 0

警告消息：
1：在 wilcox.test.default(x = c(0, 6, 0, 0, 0, 0, 1, 3, 1, 1, 3, 7) 中，:
无法计算具有关系的精确 p 值
2：在 wilcox.test.default(x = c(0, 6, 0, 0, 0, 0, 1, 3, 1, 1, 3, 7) 中，:
无法计算具有零的精确 p 值

因此，“V”与“Z”？
在这种情况下，我可以使用 Z/sqrt(12) = 0.577 来计算效果大小，该值是中等到大（根据 Cohen）。
那么，是否有机会直接从 R 库 wilcox.test 获取 Z（并计算效果大小）？我想坚持使用基础库。]]></description>
      <guid>https://stats.stackexchange.com/questions/542165/if-i-use-the-wilcox-test-from-r-for-paired-data-what-exactly-it-returns-i-want</guid>
      <pubDate>Wed, 01 Sep 2021 11:05:27 GMT</pubDate>
    </item>
    <item>
      <title>多次抽取的贝叶斯定理</title>
      <link>https://stats.stackexchange.com/questions/534710/bayes-theorem-with-multiple-draws</link>
      <description><![CDATA[设置
我对 Allen Downey 的 Think Bayes 2e 中的&quot;Cookie Problem Revisited&quot; 练习有疑问。贝叶斯定理定义为：
$$ P(H | E) = \frac{P(H) \ P(E | H)}{P(E)} $$
其中 E 是证据，H 是假设。
让我们考虑以下示例：两个碗里有不同的饼干。

碗 1 包含 30 块香草饼干和 10 块巧克力饼干。
碗 2 包含 20 块香草饼干和 20 块巧克力饼干。

我们随机选择一个碗并抽取一块香草饼干。它来自碗 1 的概率是多少？
$P(H=\text{Bowl1}) = 0.5$（我们随机选择碗）
$P(E=\text{vanilla} \ | \ H=\text{Bowl1}) = 30/(30+10) = 3/4 $
$P(E=\text{vanilla}) = (30 + 20)/(30 + 20 + 10 + 20) = 5/8$（香草饼干数量除以总饼干数量）
然后，后验 $P(H=\text{Bowl1} \ | \ E=\text{vanilla}) = 0.6 $。
问题
现在我们将香草饼干放回碗中并抽取第二块饼干。我们再次得到香草。我们可以使用刚刚计算的后验作为新的先验。后验现在是：$P(E=\text{vanilla} \ | \ H=\text{Bowl1}) * P(H=\text{previous posterior})$，如之前计算的。但是，证据的概率必须与我们之前计算的（香草饼干除以总饼干）不同，因为否则碗 1 和碗 2 的后验总和不会等于 1（为了简单起见，我没有在本文中表达碗 2 的后验）。
为什么当我们多次抽取时，证据的概率不等于香草饼干与总饼干的比例？在这种情况下我们如何计算它？
编辑：为清晰起见，提供附加信息]]></description>
      <guid>https://stats.stackexchange.com/questions/534710/bayes-theorem-with-multiple-draws</guid>
      <pubDate>Thu, 15 Jul 2021 14:47:49 GMT</pubDate>
    </item>
    <item>
      <title>中心极限定理和偏斜分布</title>
      <link>https://stats.stackexchange.com/questions/499403/central-limit-theorem-and-skewed-distribution</link>
      <description><![CDATA[我正在寻找一个与中心极限定理和高斯分布及偏斜分布相关的问题的简单答案（如果存在的话）。我使用二项式函数计算了 10 次抛掷不公平硬币（p=0.3，q=0.7）可能结果的概率，并获得了偏斜分布。我一直认为这是一种比例抽样分布。如果硬币被抛掷 10 万亿次，其中有 3 万亿次正面和 7 万亿次反面，并且将 10 个抛掷样本绘制到抽样分布中，就会得到我的偏斜曲线。
现在我还“了解到”中心极限定理说任何分布的抽样分布都是高斯曲线，但我承认我对此的研究相对肤浅。偏斜曲线是否仍被视为高斯曲线？关于中心极限定理，还有其他我不清楚的重要方面吗？我不一定需要全面的解释，只是需要一些关于我可能存在的误解的指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/499403/central-limit-theorem-and-skewed-distribution</guid>
      <pubDate>Fri, 04 Dec 2020 21:12:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中的固定效应模型中测试多重共线性？</title>
      <link>https://stats.stackexchange.com/questions/494225/how-to-test-multicollinearity-in-fixed-effects-model-in-r</link>
      <description><![CDATA[我在 R 中使用 plm 包并运行一些 pooling 和 fixed effects 模型。对于 pooling 模型，我能够使用 vif() 来获取方差膨胀因子，但是当我为 fixed effect 模型运行它时，它显示了以下错误：
&gt; &gt; vif(modelFE.1.i) 
&gt; &gt; R[subs, subs] 中的错误：下标超出范围
&gt; 此外：警告消息：在 vif.default(modelFE.1.i) 中：无截距：
&gt; vifs 可能不合理。

所以，我想知道在 固定效应 设置下是否有某种方法可以找到多重共线性？
错误说没有截距就无法计算 VIF，我明白这一点。但是，我还可以做哪些其他测试来测试多重共线性？]]></description>
      <guid>https://stats.stackexchange.com/questions/494225/how-to-test-multicollinearity-in-fixed-effects-model-in-r</guid>
      <pubDate>Wed, 28 Oct 2020 18:41:49 GMT</pubDate>
    </item>
    </channel>
</rss>