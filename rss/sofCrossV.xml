<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 06 Nov 2024 09:19:19 GMT</lastBuildDate>
    <item>
      <title>电子商务中的 AB 测试设计 - 按用户分组并按商品统计汇总</title>
      <link>https://stats.stackexchange.com/questions/656820/ab-test-design-in-ecommerce-group-split-per-user-and-statistic-aggregation-per</link>
      <description><![CDATA[运行 A/B 测试（其中 A/B 组按用户划分，然后按项目汇总统计数据）在统计上是否正确/可行？
让我们将问题缩小到一个具体示例：

设置：一家在线商店，多家公司发布用户可以购买的商品。公司可以购买可提升网站上商品排名的插件。
目标：增加达到特定插件点击目标的商品比例（例如 5%）
测试：我们正在处理二项分布，因此选择了 Fisher 精确检验。尤其是没有那么多项目，因此测试不应该在计算上耗费精力

示例数据：
插件点击率目标：5%




计数达到目标的项目
计数未达到目标的项目




组 A
5216
1295


组 B
5558
953



Fisher 精确p 值小于 0.0001 -&gt; 结果在 alpha=0.05 时具有统计学意义。
我担心的是，这种方法（按用户分组，按项目聚合）违反了 AB 测试设计和理论的一些假设。我们运行了 500 次 AA Fisher 精确测试，alpha=0.05，在这 500 次模拟中，只有 0.012 次具有统计学意义。
我尝试在线查找采用这种方法的文章，但由于“AB 测试教程”泛滥，我无法找到相关来源（也许我的搜索技巧很差）。我问过 GenAI，模型似乎对这种方法没有问题，但是……它是 GenAI。
有人可以详细说明一下吗？有任何相关来源或链接吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656820/ab-test-design-in-ecommerce-group-split-per-user-and-statistic-aggregation-per</guid>
      <pubDate>Wed, 06 Nov 2024 08:32:55 GMT</pubDate>
    </item>
    <item>
      <title>关于自动编码器的泛化我们了解多少？</title>
      <link>https://stats.stackexchange.com/questions/656817/what-is-known-about-the-generalization-of-autoencoders</link>
      <description><![CDATA[泛化被定义为“模型正确适应新的、以前未见过的数据的能力，这些数据来自与用于创建模型的分布相同的分布。”该模型从用于训练机器学习算法的历史数据中学习模式。
关于自动编码器或其变体的泛化的现有结果是什么？我对了解原理上的泛化很感兴趣。是否有任何定理或引理可以说明自动编码器的泛化？]]></description>
      <guid>https://stats.stackexchange.com/questions/656817/what-is-known-about-the-generalization-of-autoencoders</guid>
      <pubDate>Wed, 06 Nov 2024 06:20:30 GMT</pubDate>
    </item>
    <item>
      <title>在回归分析中将累积响应作为预测因子？是否违反？</title>
      <link>https://stats.stackexchange.com/questions/656816/including-a-cumulative-response-as-a-predictor-in-a-regression-violation-or-no</link>
      <description><![CDATA[我想制作一个纵向回归模型，它看起来类似这样：

主题 i @ 时间 t：y 的变化百分比 (t,t-1) ~ f[ x 的变化百分比 (t,t-1)]

我有这样的想法，也许我可以包含所有响应的累积总和，例如

主题 i @ 时间 t：y 的变化百分比 (t,t-1) ~ f[ x 的变化百分比 (t,t-1)，来自 (t0,t-1) 的所有 y 的总和]

我认为这样做将作为参考，表明 y 的变化百分比取决于 y 已经发生的程度。例如，如果我们知道一年中通常降雨量为 100 毫米，而现在已经下了 90 毫米的雨——这取决于一年中的什么时间，未来降雨的可能性可能会更大或更小，这取决于已经下了多少雨。或者，接种新冠疫苗的人口比例增加对群体免疫的影响可能会更大或更小，这取决于已经接种疫苗的人口数量。
在回归模型中，可以将累积反应作为预测因子纳入吗？还是这违反了假设？我这样说是因为我知道将滞后反应作为预测因子绝对违反了统计假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/656816/including-a-cumulative-response-as-a-predictor-in-a-regression-violation-or-no</guid>
      <pubDate>Wed, 06 Nov 2024 05:56:33 GMT</pubDate>
    </item>
    <item>
      <title>我如何才能正确地进行前后分析来确定投票率的相关性？</title>
      <link>https://stats.stackexchange.com/questions/656815/how-can-i-properly-set-up-a-before-and-after-analysis-to-determine-a-correlation</link>
      <description><![CDATA[就我个人而言，我感兴趣的是分析在不同的城镇，某个特定行业的游说活动增加或减少是否会导致某个政党的投票率增加或减少。
为了正确分析这一点，我需要编制哪些统计数据，此外，我需要遵循哪些程序来确定相关性或对推论有 95% 的信心？这可能看起来很模糊，但我正在寻求指导，关于我如何进行这项工作，因为这些信息可能来自数百个城市。]]></description>
      <guid>https://stats.stackexchange.com/questions/656815/how-can-i-properly-set-up-a-before-and-after-analysis-to-determine-a-correlation</guid>
      <pubDate>Wed, 06 Nov 2024 04:45:58 GMT</pubDate>
    </item>
    <item>
      <title>是否可以将具有截距的指数关系的数据转换为线性关系？</title>
      <link>https://stats.stackexchange.com/questions/656813/is-it-possible-to-transform-data-following-an-exponential-relationship-with-an-i</link>
      <description><![CDATA[在估计非线性关系的参数时，我经常发现以可以使用 OLS 线性回归的方式转换数据很有用。例如，将指数关系 $y=ax^b$ 转换为 $\ln{y}=\ln{a}+b\ln{x}$ 或将 II 型功能响应 $y=\frac{ax}{1+ahx}$ 转换为 $y^{-1}=h+a^{-1}x^{-1}$。
我有一些数据，我预计它们会遵循指数关系。我尝试使用这种方法，但预期关系有一个截距：
$$y=\frac{a}{b}(e^{-bx}-1)$$
我似乎无法弄清楚如何将其转换为线性。
我知道我可以使用 GLM，但是否可以通过将数据转换为线性来估计参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/656813/is-it-possible-to-transform-data-following-an-exponential-relationship-with-an-i</guid>
      <pubDate>Wed, 06 Nov 2024 03:06:16 GMT</pubDate>
    </item>
    <item>
      <title>估计一个向量 $\beta=\underbrace{\beta_1}_{\text{sparse}}+\underbrace{\beta_2}_{\text{dense}}$</title>
      <link>https://stats.stackexchange.com/questions/656812/estimate-a-vector-beta-underbrace-beta-1-textsparse-underbrace-beta</link>
      <description><![CDATA[在高维设置中，我们使用依赖于稀疏性假设的套索方法解​​决线性回归，
$$
\hat{\beta}=\underset{\beta\in \mathbb{R}^{p}}{\arg \min}\|Y-X\beta\|_2^2+\lambda\|\beta\|_1 。
$$
现在我对一个新模型感兴趣，其中$\beta$分解为一个稀疏向量和一个密集向量
$$
\beta=\underbrace{\beta_1}_{\text{sparse}}+\underbrace{\beta_2}_{\text{dense}},\\
Y=X\beta_1+X\beta_2+\epsilon,
$$
并获得估计量
$$
\left(\hat{\beta}_1,\hat{\beta}_2\right)=\underset{\beta_1,\beta_2}{\arg \min}\|Y-X\left(\beta_1+\beta_2\right)\|_2^2+\lambda_1\|\beta_1\|_a+\lambda_2\|\beta_2\|_b
$$
其中$\|\cdot\|_a$和$\|\cdot\|_b$鼓励估计量稀疏和密集。
我猜这个模型已经得到很好的研究了。现在这个模型的最佳结果是什么？你能给我提供一些相关的论文吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656812/estimate-a-vector-beta-underbrace-beta-1-textsparse-underbrace-beta</guid>
      <pubDate>Wed, 06 Nov 2024 02:42:52 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 二元分类模型的 AUC 值低</title>
      <link>https://stats.stackexchange.com/questions/656810/low-auc-value-for-xgboost-binary-classification-model</link>
      <description><![CDATA[我正在使用 XGBoost 构建二元分类模型，以根据体重、每日平均步数、年龄等因素识别具有诊断的个人。我的模型非常小（只有 200 个案例），并且不平衡（负数与正数之比为 4:1）。我构建了一个 XGBoost 模型，但我注意到通过调整，我只实现了小于 .5 的测试 AUC 结果，有些模型提供的测试 AUC 值为 .2-.3。训练 AUC 值从 .3-.6 不等。我曾尝试使用 SMOTE，但它并没有大大提高分类准确性。标签没有被切换，也没有编码错误。我正在使用 gamma、lambda 和正权重缩放参数来降低过度拟合的可能性。但是，似乎没有任何东西能够将模型的 AUC 提高到 .5 以上。
从概念上讲，我不太确定我是否理解二元分类模型如何能够实现完全错误的猜测，但不能实现完全正确的猜测。如果模型在判别方面几乎完全不准确（AUC &lt; .2），那么它是否也能获得良好的结果（AUC &gt; .8）？]]></description>
      <guid>https://stats.stackexchange.com/questions/656810/low-auc-value-for-xgboost-binary-classification-model</guid>
      <pubDate>Wed, 06 Nov 2024 00:06:50 GMT</pubDate>
    </item>
    <item>
      <title>具有随机变化的生物时间序列数据：回归是否合适以及中心变量是否能消除年份效应</title>
      <link>https://stats.stackexchange.com/questions/656809/biological-time-series-data-with-random-variation-is-regression-suitable-and-ce</link>
      <description><![CDATA[我有多年树木作物的数据：产量、树冠体积等。还有 2 个因素（品种、管理）。
我试图找出我的一些变量之间是否存在相关性，例如树冠和产量。我接触过一位非常严格和严谨的统计学家。他提出了一些主张，我想知道这些主张是否完全正确，是否必须像他建议的那样严格遵守。现在，另一方面，我的老板正在挑战统计学家希望我这样做的方式，并希望我能说服他。统计学家的说法是：

我必须将数据居中（从每个数据点中减去年平均值并添加总体平均值）以消除年份效应。我的老板对此不满意，因为这意味着散点图中的值不再是真实值，并且具有误导性。此外，它还缩小了数据的范围。树冠体积和产量从早年的接近零上升到树木成熟时的很高数字。统计学家说，如果我不将数据集中，就会产生误导，因为产量的增加是由于年龄（即年份）而不是树冠。从生物学的角度来看，我认为这有点愚蠢，但我确实理解这个概念。

我无法拟合回归模型。原因显然是我的实验没有设计成解释变量被复制，因此没有错误。我的解释变量（树冠）是一个观察值，而不是设计值。他让我参考了一篇论文（Powers 2021，《应用生物学年鉴》编辑部），但在同一篇论文中写道：“在其他研究中，将研究由成对的观察值组成的收集数据，以考虑它们之间的关系，而不一定在每个级别都进行复制[就像我的实验中的情况一样]……重要的是评估所提出的关系的统计质量。首先，实际上，应该问是否真的需要拟合关系。&#39;这意味着拟合模型是一种选择，尽管并非总是最佳选择。而统计学家说这是错误的，就是这样。他引用了一本书（Draper 和 Smith 的《应用回归分析》）：“回归分析的一个假设是预测变量不受随机变化的影响”[在我看来它们是]。我的统计学书（Crawley 的《统计学。使用 R 的介绍》）说：“也许知道何时回归是合适的分析的最简单方法是看散点图是否是合适的图形。&#39;[在我看来，它绝对是]另一个重要的事实是，我所在领域的大量其他论文都在做同样的事情：将回归线拟合到像我这样的数据中。这就是我老板使用的论点：人们期望看到直线和 r2，而你需要有一个很好的理由来以不同的方式去做。统计学家建议我使用带有皮尔逊相关系数的散点图，但没有线。


我感觉自己陷入了进退维谷的境地（两个非常强大和自信的个性），我需要更多的解释/意见，才能感觉自己可以更好地辩论。]]></description>
      <guid>https://stats.stackexchange.com/questions/656809/biological-time-series-data-with-random-variation-is-regression-suitable-and-ce</guid>
      <pubDate>Tue, 05 Nov 2024 23:17:29 GMT</pubDate>
    </item>
    <item>
      <title>变换后的 $y$（S 型 $y$）的线性回归是否应与响应的变换（S 型）相同</title>
      <link>https://stats.stackexchange.com/questions/656807/should-the-linear-regression-of-a-transformed-y-sigmoid-y-be-identical-to</link>
      <description><![CDATA[线性模型的预测变量 $\hat y$ 的 S 形函数 $(1/(1+e^{-y}))$ 是否应与 S 形函数 $y$ 的线性回归相同。下面的 Python 示例演示了二进制数据的 S 形函数的线性回归和响应 $\hat y$ 的 S 形变换。它们很接近但不完全相同（参见绿线和红线/曲线）。然而，一般来说，响应的转换$\operatorname{sigmoid}(\hat y)$是否应该与 S 形的回归（$\operatorname{sigmoid} (y) = a\cdot x + \varepsilon)$相同。请记住，我没有使用线性广义模型。
谢谢

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from scipy.special import expit

# 绘制逆对数函数。
#plt.figure();plt.plot(expit(np.arange(100)))

x = np.arange(10).reshape(-1, 1)
y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])

################
# 线性回归的逆 logit (Sigmoid) 
linearReg = LinearRegression().fit(x,y)
y_hat_linear = x * linearReg.coef_ + linearReg.intercept_
# 逆 logit (Sigmoid) # 1/(1+exp(-y))
inverselogit_linear = expit(y_hat_linear) 
print(linearReg.coef_)
print(linearReg.intercept_)

#############
# 逆 logit (Sigmoid) 的线性回归
linearlogReg = LinearRegression().fit(x,expit(y))
y_hat_linearlog = x * linearlogReg.coef_ + linearlogReg.intercept_
print(linearlogReg.coef_)
print(linearlogReg.intercept_)
###################
plt.figure()
plt.scatter(x,y)
plt.plot(x,y_hat_linear,label=&#39;线性回归&#39;)
plt.plot(x,inverselogit_linear,label=&#39;响应的 S 形 (OLS)&#39;)
plt.plot(x,y_hat_linearlog,label=&#39;响应的 S 形 (OLS)&#39;)
plt.legend()
]]></description>
      <guid>https://stats.stackexchange.com/questions/656807/should-the-linear-regression-of-a-transformed-y-sigmoid-y-be-identical-to</guid>
      <pubDate>Tue, 05 Nov 2024 22:08:34 GMT</pubDate>
    </item>
    <item>
      <title>变分自动编码器 - 手工制作的示例</title>
      <link>https://stats.stackexchange.com/questions/656806/variational-autoencoders-handcrafted-example</link>
      <description><![CDATA[在学习变分自动编码器 (VAE) 时，我想提出一个手工制作的小例子来帮助彻底理解它们。为此，假设我知道我的样本来自五维高斯$\mathbf{X}=(X_1,\dots,X_5)$，其中$X_2\sim\mathcal{N}(1,1)$和$X_5\sim\mathcal{N}(-1,4)$是独立的，并且$X_1=X_2$，$X_3=X_5$和$X_4=X_2+X_5$。进一步假设我们即将学习的 VAE 具有两个潜在维度。在这种情况下（如果我错了请纠正我），我预计潜在空间$\mathbf{Z}$实际上只是二维高斯$(X_2,X_5)$，因为观测数据中的所有其他随机变量完全依赖于这两个变量，并且它们是独立的。
$\textbf{Question(s) (1):}$我是否正确地认为，给定一些样本$\mathbf{x}=(x_2,x_5)$，我们理想情况下会得到$\mathbf{Z}|\mathbf{x}$只是$(x_2,x_5)$本身？例如，一个学习良好的编码器是否会产生一些结果，当从非常接近$(x_2,x_5)$的样本中进行采样时？
我不确定，因为我认为$\mathbf{Z}|\mathbf{x}$应该是一个分布，并且为了“保证”输出$(x_2,x_5)$，我们可能需要类似$p(\mathbf{Z}|\mathbf{x})=\delta(z_1-x_2)\delta(z_2-x_5)$的东西，其中$\delta$是狄拉克函数。我对这里的严格细节有点困惑，所以非常感谢您的帮助。
$\textbf{问题 (2):}$ 在实践中，我理解 $\mathbf{Z}|\mathbf{x}$ 由某个正态分布近似，其参数由某个神经网络（编码器）输出。我想在这种情况下，一个“好的”编码器输出一个正态分布的参数是有意义的，该正态分布的均值以 $(x_2,x_5)$ 为中心，协方差矩阵是对角线，对角线元素相对较小（例如 $0.01$ 左右）。这种直觉是否正确，是否符合学习编码器在实践中的表现？
$\textbf{Note:}$ 在我的屏幕上，正态分布的“\mathcal{N}”显示为方框。如果读者您也遇到同样的情况，请知道每个方框实际上都是与正态分布有关的通常“N”符号。]]></description>
      <guid>https://stats.stackexchange.com/questions/656806/variational-autoencoders-handcrafted-example</guid>
      <pubDate>Tue, 05 Nov 2024 21:59:13 GMT</pubDate>
    </item>
    <item>
      <title>分层 2x2 全因子试验的样本量计算</title>
      <link>https://stats.stackexchange.com/questions/656805/sample-size-calculation-for-a-hierarchical-2x2-full-factorial-trial</link>
      <description><![CDATA[我需要计算分层 2x2 全因子试验所需的样本量（簇数和每个簇的平均观察数）。试验中心将随机分配到四种条件（基数、基数 + A、基数 + B、基数 + A + B）。在每个中心，将针对多个个体测量主要结果（指标，可能有偏差）。A 和 B 对结果的影响以及它们的相互作用将引起人们的兴趣。
如果残差分布允许，我打算使用混合线性效应模型（我希望不必求助于广义模型或其他替代方案，但我想还是有可能的）。我将对 ICC（预计相当低，介于 0.02 和 0.04 之间）和簇大小变化做出假设。 Alpha=0.05，power=0.8。
我熟悉具有分层数据结构的集群随机试验的功效计算，这些试验通过混合线性效应模型进行分析，其中单一治疗效果是感兴趣的，但不熟悉因子试验。我也在一定程度上熟悉 2x2 全因子试验的功效计算，但不熟悉分层数据结构。
我使用 Stata 和 R。
非常感谢您的帮助！如果您可以为该方法添加可引用的参考文献，那就更好了。
Marco]]></description>
      <guid>https://stats.stackexchange.com/questions/656805/sample-size-calculation-for-a-hierarchical-2x2-full-factorial-trial</guid>
      <pubDate>Tue, 05 Nov 2024 21:40:50 GMT</pubDate>
    </item>
    <item>
      <title>在干预之前重复测量能在多大程度上提高我的统计能力？</title>
      <link>https://stats.stackexchange.com/questions/656804/how-much-will-repeating-a-measure-before-an-intervention-improve-my-statistical</link>
      <description><![CDATA[我正在一项有数千名参与者的干预研究中测量 PHQ-9 抑郁量表的基线和四周随访。
我正在考虑在基线前几天再测量一次，以提高研究的统计能力。但是，我不确定这会对统计能力产生多大的影响。PHQ-9 的重测信度据说非常好，如果在几天内重新测试，则约为 r=0.85。是否值得再测量一次？
根据 Goulet &amp; Cousineau (2019)，我猜测相关性太高，以至于不会产生太大影响，但样本量大让我重新考虑了一下。

Goulet, M. A., &amp; Cousineau, D. (2019). 重复测量的效力可提高统计能力。心理科学方法与实践进展，2(3)，199-213。

谢谢，
Benji]]></description>
      <guid>https://stats.stackexchange.com/questions/656804/how-much-will-repeating-a-measure-before-an-intervention-improve-my-statistical</guid>
      <pubDate>Tue, 05 Nov 2024 21:29:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么加权最小二乘（WLS）回归中的逆方差权重会给出“最佳”估计量？</title>
      <link>https://stats.stackexchange.com/questions/656795/why-does-inverse-variance-weights-in-weighted-least-squares-wls-regression-giv</link>
      <description><![CDATA[这是我目前对 WLS 的理解。
在 OLS 中，我们给每个数据点相同的权重。这在某些假设下给出了最佳的线性无偏估计量——其中之一是误差项的方差为常数（同方差性）
但是当残差具有异方差性时，我们确定回归系数的 OLS 估计量不再是“最佳”的估计量。这意味着它具有更多的方差。因此，然后使用 WLS 找到这个最佳估计量（考虑到误差仍然不相关）。
我读到，当权重是误差项的逆方差时，WLS 会给出回归系数的最佳估计量。这意味着我们给 OLS 模型预测高误差方差（由残差方差估计）的数据点赋予较少的权重。误差方差较小的点会获得更大的权重。
我明白这在理论上是可行的。我想更直观地理解它：为什么给予方差较小的点更大的权重会改善估计量？
为什么在执行 WLS 回归时，方差较小的点被认为更“可靠”？
谢谢 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/656795/why-does-inverse-variance-weights-in-weighted-least-squares-wls-regression-giv</guid>
      <pubDate>Tue, 05 Nov 2024 16:42:54 GMT</pubDate>
    </item>
    <item>
      <title>在反向传播中对权重矩阵进行区分时避免使用张量</title>
      <link>https://stats.stackexchange.com/questions/656649/avoiding-tensors-when-differentiating-with-respect-to-weight-matrices-in-backpro</link>
      <description><![CDATA[考虑一个仅由单个仿射变换组成且没有非线性的神经网络。使用以下符号：

$\textbf{输入}：x \in \mathbb{R}^n$
$\textbf{权重}：W \in \mathbb{R}^{h \times n}$
$\textbf{偏差}：b \in \mathbb{R}^h$
$\textbf{输出}：z = W x + b \in \mathbb{R}^h$
$\textbf{损失函数}：\ell(z) \in \mathbb{R}$

我们试图计算损失相对于权重的梯度$\frac{\partial \ell}{\partial W}$。在进行反向传播时，我们将此梯度分解为两个因子：
$$
\frac{\partial \ell}{\partial W} = \frac{\partial \ell}{\partial z} \cdot \frac{\partial z}{\partial W}
$$
但是，$\frac{\partial z}{\partial W}$是向量相对于矩阵的导数，而将产生三维张量。我们如何才能在保持事物处于二维状态的同时继续计算$\frac{\partial \ell}{\partial W}$？]]></description>
      <guid>https://stats.stackexchange.com/questions/656649/avoiding-tensors-when-differentiating-with-respect-to-weight-matrices-in-backpro</guid>
      <pubDate>Sat, 02 Nov 2024 18:53:31 GMT</pubDate>
    </item>
    <item>
      <title>在 10 个样本中，从 21 个列表中选择少于 4 个唯一数字的概率（有放回）</title>
      <link>https://stats.stackexchange.com/questions/655485/probability-of-selecting-less-than-4-unique-numbers-from-a-list-of-21-in-10-samp</link>
      <description><![CDATA[我有 21 个数字的列表，编号为 0 到 20（或 1 到 21，无所谓）。我随机挑选 10 次，每次都使该选择可用于下一次选择。这 10 次选择中唯一数字少于 4 个的概率是多少？
我用一个我认为正确的公式来解决组合问题，但是当我在电子表格上模拟该过程时，我得到了一个非常不同的结果：请问​​正确的公式是什么？以下是我对如何获得公式和模拟结果的解释。
选择少于 4 个唯一数字的概率是始终选择相同数字的概率 + 选择 2 个不同数字的概率 + 选择 3 个不同数字的概率。
$$P(&lt;4) = P(1) + P(2) +P(3)$$
我第一次从 10 个数字中挑选出 1 个唯一数字。第二次挑选时，我可以选择相同的数字，概率为 $\frac1{21}$，也可以选择不同的数字，概率为 $\frac{20}{21}$。在第一次选择之后的 9 次选择中始终选择相同数字的概率为
$$P(1) = \left(\frac1{21}\right)^9$$
在第二次选择之后，我选择了一个与第一次不同的数字，然后我还有第三次选择，我可以选择前 2 个数字中的一个，概率为 $\frac2{21}$，或者选择第三个不同的数字，概率为 $\frac{19}{21}$。在前 2 个数字之后，我在剩余的 8 次选择中继续选择相同的 2 个数字的概率为
$(\frac{2}{21})^8$，因此
$$P(2) = \frac{20}{21}\left(\frac{2}{21}\right)^8$$
继续同样的思路，在第 4 次选择时，我可以选择之前选择的 3 个数字之一，概率为 $\frac3{21}$，或者选择第 4 个不同的数字，概率为 $\frac{18}{21}$。在前 3 个数字之后，我在剩余的 7 次选择中继续选择相同的 3 个数字的概率为
$(\frac{3}{21})^7$，因此
$$P(3) = \frac{20}{21}\frac{19}{21}\left(\frac3{21}\right)^7$$
将三项相加
$$P(&lt;4) = \left(\frac1{21}\right)^9 + \frac{20}{21}\left[\left(\frac{2}{21}\right)^8 + \frac{19}{21}\left(\frac3{21}\right)^7\right] = $$
这给了我大约 $P(&lt;4) = 0.00011\%$
当我尝试通过在 Google 表格中模拟该过程来验证结果时，我无法模拟足够的试验进行计算；上面的概率意味着大约 909,000 次试验的平均值是 1，但我发现 Google 表格允许我模拟大约 47,500 次试验。因此，我将问题从 10 次选择缩减为 8 次选择，通过归纳法获得
$$P(&lt;4) = \left(\frac1{21}\right)^7 + \frac{20}{21}\left[\left(\frac{2}{21}\right)^6 + \frac{19}{21}\left(\frac3{21}\right)^5\right] = 0.0052\%$$
但是当我模拟它时，我得到 $P(&lt;4) = 0.016\%$
我用来模拟上述结果的 Google Sheets 公式是
=countif( byrow( map(RANDarray(55000, 8), lambda(x, int(x*21))), lambda(trial,COUNTUNIQUE(trial)) ), &quot;&lt;4&quot;) / 55000
]]></description>
      <guid>https://stats.stackexchange.com/questions/655485/probability-of-selecting-less-than-4-unique-numbers-from-a-list-of-21-in-10-samp</guid>
      <pubDate>Tue, 08 Oct 2024 18:49:31 GMT</pubDate>
    </item>
    </channel>
</rss>