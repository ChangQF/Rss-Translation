<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 08 Jan 2025 09:18:11 GMT</lastBuildDate>
    <item>
      <title>如何找到解释最高范围数据的一个线性回归？</title>
      <link>https://stats.stackexchange.com/questions/659705/how-to-find-a-linear-regression-that-explains-highest-range-of-data</link>
      <description><![CDATA[
颜色是虚构的。你不知道前方的颜色。我用颜色来表示它们是从不同的潜在空间中采样的。
LR 是一组线性回归，其中每个线性回归 i 都由以下函数拟合：
$X=1,2,...,i$
$Y=y_1,y_2,...,y_i$。
如何为集合 $LR$ 找到一个最优线性回归，使其适合大多数蓝点，但适合最少的橙色点。
例如，适合 x = 1,2, ...,11, y = y1, y2, ...,y11 的模型将满足我的需求。是否有任何指标表明该模型比其他模型更大？]]></description>
      <guid>https://stats.stackexchange.com/questions/659705/how-to-find-a-linear-regression-that-explains-highest-range-of-data</guid>
      <pubDate>Wed, 08 Jan 2025 07:06:00 GMT</pubDate>
    </item>
    <item>
      <title>不带 MAR 假设计算临床试验的敏感性和特异性</title>
      <link>https://stats.stackexchange.com/questions/659704/computing-sensitivity-and-specificity-of-a-clinical-test-without-mar-assumption</link>
      <description><![CDATA[如周氏《诊断医学中的统计方法》第 337-338 页所述，假设 $D$ 是一个随机变量，如果受试者患有疾病，则假设其值为 $1$。假设 $T$ 是一个随机变量，如果疾病检测结果为阳性，则假设其值为 $1$。假设 $V$ 是一个随机变量，如果受试者已对该疾病进行了进一步验证，则假设其值为 $1$。给定以下参数的值$\lambda_{11} = P(V=1|T=1,D=1)$, $\lambda_{01} = P(V=1|T=1,D=0)$, $\lambda_{10} = P(V=1|T=0,D=1)$, $\lambda_{00} = P(V=1|T=0,D=0)$, $\phi_1 = P(T=1)$, $\phi_{20} = P(D=1|T=0)$, $\phi_{21} = P(D=1|T=1)$，根据这些参数计算敏感度和特异性的正确方法是什么？例如，我知道敏感度是 $P(T=1|D=1)$，不考虑 $V$，它应该计算为 $P(T=1|D=1)P(D=1)/P(T=1)$，但如果必须考虑随机变量 $V$，公式会如何变化？]]></description>
      <guid>https://stats.stackexchange.com/questions/659704/computing-sensitivity-and-specificity-of-a-clinical-test-without-mar-assumption</guid>
      <pubDate>Wed, 08 Jan 2025 06:29:17 GMT</pubDate>
    </item>
    <item>
      <title>如何在线性混合效应模型中使用重复测量数据描述 RCS？</title>
      <link>https://stats.stackexchange.com/questions/659700/how-to-depict-rcs-using-repeated-measured-data-in-linear-mixed-effect-model</link>
      <description><![CDATA[我正在使用“lmer”包来拟合线性混合效应模型，以访问 Y 和 X 的关联。我的数据的响应变量是连续且重复测量的，这需要随机效应和混合效应。但是“rms”包中的“ols”函数仅适用于拟合线性回归模型，无法捕捉时间的随机效应，从而导致模型拟合不准确。 R 代码如下：
fit3 &lt;- lmer(HDS_Z_score ~ VBGP +age + sex + basecog + diftime + (1 | ID), data = main)
fit_rcs &lt;- ols(HDS_Z_score ~ rcs(VB12,5)+ age + sex+ basecog + diftime, data=main) # knots set as 5
我对使用此代码有一些疑问：

“ols”函数是否适用于拟合重复测量数据？
还有什么可以描述线性混合效应模型中重复测量数据的 RCS，无论是 R 包还是 SAS 宏？
]]></description>
      <guid>https://stats.stackexchange.com/questions/659700/how-to-depict-rcs-using-repeated-measured-data-in-linear-mixed-effect-model</guid>
      <pubDate>Wed, 08 Jan 2025 02:19:43 GMT</pubDate>
    </item>
    <item>
      <title>在汇总疾病分类的优势比时，测量工具是否需要同质性？</title>
      <link>https://stats.stackexchange.com/questions/659696/is-homogeneity-of-measurement-tools-necessary-when-pooling-odds-ratios-for-disea</link>
      <description><![CDATA[在荟萃分析中汇总估计值时，众所周知，保持研究之间的同质性至关重要，尤其是在处理连续数据时。在这种情况下，使用一致报告的工具和测量值进行有效汇总非常重要。但是，当使用不同的工具对疾病进行分类，但最终将其归类为疾病的存在或不存在，并且结果以比值比的形式进行统计呈现时，是否仍有必要保持所用工具的同质性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659696/is-homogeneity-of-measurement-tools-necessary-when-pooling-odds-ratios-for-disea</guid>
      <pubDate>Wed, 08 Jan 2025 01:12:47 GMT</pubDate>
    </item>
    <item>
      <title>逆倾向评分和几种结果</title>
      <link>https://stats.stackexchange.com/questions/659691/inverse-propensity-scores-and-several-outcomes</link>
      <description><![CDATA[假设我使用面板数据来估计某些干预措施对两种不同结果的平均治疗效果。由于存在明确定义的治疗组和对照组，因此使用 DID 方法是有意义的，但我希望施加条件平行趋势假设。为此，我使用一组时间不变的治疗前协变量来重新加权对照组，使其看起来更像治疗组。正式地，我估计双向固定效应回归（治疗不交错），概率权重（治疗组的权重为 1，而对照组使用估计的倾向得分）。
我的问题是：我正在处理两个不同的结果变量。我用于条件平行趋势假设的协变量在两者之间是否应该相同？一方面，结果变量的趋势可能仅在不同的组内相同。但另一方面，我只有一种干预措施，即使结果发生变化，使用不同的变量来模拟对同一治疗的选择似乎很奇怪。
有什么要点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659691/inverse-propensity-scores-and-several-outcomes</guid>
      <pubDate>Tue, 07 Jan 2025 22:46:24 GMT</pubDate>
    </item>
    <item>
      <title>与将 $n$ 个物品分配到 $m$ 个容器相关的概率</title>
      <link>https://stats.stackexchange.com/questions/659690/probabilities-related-to-distributing-n-items-into-m-containers</link>
      <description><![CDATA[一辆冰淇淋车停在公园里，随机地将 10 个冰淇淋分发给 20 个孩子。随机选择的孩子没有收到冰淇淋的概率是多少？只收到一个冰淇淋？还是收到两个或更多个冰淇淋？
我目前的方法是使用 20 个孩子找到 10 个冰淇淋的所有整数组合，其中（显然）允许使用零。因此，例如，其中一个整数组合可能是：
1+1+1+1+2+4+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0=20

在上述整数组合中，20 个孩子中有 14 个没有收到冰淇淋，20 个孩子中有 4 个收到了一个冰淇淋，20 个孩子中有 2 个收到了 2 个或更多个冰淇淋。我可以使用许多随机整数组合执行蒙特卡罗模拟来获得概率。
p(x=0) = 0.66
p(x=1) = 0.24
p(x=2) = 0.08
p(x=3) = 0.01
p(x=4) 至 p(x=10) = 小于 0.01
---
p(x&gt;=0 &amp; x &lt;= 10) = 1

这种模式似乎是一种离散概率分布。有人能指出分布的名称吗？出于某种原因，我很难看出一种常见分布（泊松分布、二项分布等）如何适合这个问题！]]></description>
      <guid>https://stats.stackexchange.com/questions/659690/probabilities-related-to-distributing-n-items-into-m-containers</guid>
      <pubDate>Tue, 07 Jan 2025 21:57:43 GMT</pubDate>
    </item>
    <item>
      <title>线性回归 - 响应变量为百分比改善或 m/s？</title>
      <link>https://stats.stackexchange.com/questions/659686/linear-regression-response-variabel-as-percent-improvement-or-m-s</link>
      <description><![CDATA[我正在尝试对包含 8 种不同跑步距离的数据集进行统计，这些距离在遵循训练方案之前和之后都有时间，并且基于距离对改进进行线性回归（所有完成时间都有所下降）。我不确定是否要转换为百分比改进或使用 m/s 之类的变量，然后减去跑步时间 1 和跑步时间 2，以便能够比较不同的距离组。显然，绝对时间差异并不大，因为更长的距离自然会有更大的改进。但我读到过，不建议将百分比改进转换为线性回归中的响应变量。我该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/659686/linear-regression-response-variabel-as-percent-improvement-or-m-s</guid>
      <pubDate>Tue, 07 Jan 2025 21:03:50 GMT</pubDate>
    </item>
    <item>
      <title>在 statsmodels 中 GLM 上使用哪些参数</title>
      <link>https://stats.stackexchange.com/questions/659683/what-params-to-use-on-glm-from-statsmodels</link>
      <description><![CDATA[我正在模拟试剂转化率对试剂 L 和 M 之间比率的依赖性。比率越高，试剂转化率越高，在 1.5 左右有一个明显的拐点。下面是我拥有的完整数据集

df = pd.DataFrame({&#39;L_M&#39;:[4.75, 3.8, 3.32, 2.85, 2.37, 1.9, 1.42, 0.95, 0.71, 0.47, 0.24, 0.09],
&#39;Conversion&#39;:[0.992, 0.987, 0.993, 1, 0.9, 0.7, 0.31, 0.1, 0.07, 0.06, 0.07, 0.065]})

为此，我使用二项式家族的 GLM 模型，以 Logit 作为链接函数（又称 Logistic 回归）。这似乎很合适，因为我正在对二项式过程中的成功率进行建模（试剂要么发生反应，要么不发生反应）。我尝试使用 statmodels.GLM 失败了，下面的代码产生了非常差的拟合效果：
# 定义因变量和自变量 
Xtrain = df[&#39;L_M&#39;] 
ytrain = df[&#39;Conversion&#39;]

# 构建模型并拟合数据 
log_reg = sm.GLM(ytrain, Xtrain, family=sm.families.Binomial()).fit()

# 推理 
df[&#39;Predicted&#39;] = log_reg.predict(Xtrain)


然而，我使用了一种 hack 的方法，为每个变量创建了 100 个原始数据实验点，每个原始 y 变量为 0 或 1，概率等于此实验点的转换，然后使用 sklearn 将 logreg 拟合到这个（膨胀很多的）数据集，效果很好，产生更好的拟合效果：
from sklearn.linear_model import LogisticRegression

# 实例化模型（使用默认参数）
logreg = LogisticRegression(random_state=16)

# 用数据拟合模型
logreg.fit(X_train, y_train)
new_X = pd.DataFrame(df[&#39;L_M&#39;])
new_X.columns = [&#39;ratio&#39;]
df[&#39;Predicted&#39;]= logreg.predict_proba(new_X)[::,1]



我在 statsmodels.GLM 中遗漏了哪些参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/659683/what-params-to-use-on-glm-from-statsmodels</guid>
      <pubDate>Tue, 07 Jan 2025 20:27:59 GMT</pubDate>
    </item>
    <item>
      <title>mgcv::gam 不能正确地从平滑中分解线性分量[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659680/mgcvgam-does-not-correctly-decompose-the-linear-component-from-the-smooth</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659680/mgcvgam-does-not-correctly-decompose-the-linear-component-from-the-smooth</guid>
      <pubDate>Tue, 07 Jan 2025 18:52:03 GMT</pubDate>
    </item>
    <item>
      <title>我应该将点大小（面积）比例缩放为 1/标准误差还是 1/SE^2？</title>
      <link>https://stats.stackexchange.com/questions/659678/should-i-scale-point-size-area-proportion-to-1-standard-error-or-1-se2</link>
      <description><![CDATA[我有一堆估计值，我想将它们绘制在 y 轴上，而 x 轴上则绘制其他值。我想传达每个点的不确定性（x 轴值已知，y 轴值是估计值）。误差线会使图变得非常混乱，所以我想使用点的大小来传达我们对每个点的确定程度。据我所知，建议人们将面积（而不是直径）视为信息量（例如，参见本文或此链接 - 不确定这些是否是标准参考文献）。
但是，有没有研究信息度量应该是 1/SE（标准误差的倒数）还是 1/SE^2（抽样方差的倒数）。鉴于对于误差线，我们将使用 +-SE 或置信区间（95% 的置信区间大约为 +- 1.96*SE），我猜是 1/SE？不知何故，我找不到是否有人尝试过实证测试这是否有效（例如，当人们被问到问题时，他们会根据所选的可视化做出适当的回答，即当给出基于 1/SE 或 1/SE^2 或其他东西的点大小时，他们是否表现得更好）。
更新：一位同事指出，对于元回归，我们通常根据信息缩放点。信息（或研究权重）与 1/方差成正比，因此可以说按 1/方差缩放面积是有意义的。虽然，查看流行的 metafor R 包，似乎我们默认获得了按元回归权重（即 1/方差）缩放的半径（与直径成比例）（我还仔细检查了源代码，并支持按 1/方差和 1/se 缩放直径）。奇怪的是，按 1/方差缩放半径意味着按 1/方差缩放面积（与半径^2 成比例）。这似乎夸大了点所获得的权重。相比之下，为了根据信息缩放面积，将半径或直径缩放 1/SE 似乎更有意义（或者如果您想要与 SE 成比例的面积，则可以将半径缩放 $1/\sqrt(SE)$）。]]></description>
      <guid>https://stats.stackexchange.com/questions/659678/should-i-scale-point-size-area-proportion-to-1-standard-error-or-1-se2</guid>
      <pubDate>Tue, 07 Jan 2025 17:47:22 GMT</pubDate>
    </item>
    <item>
      <title>对 DiD 设计中均值中位数估计量的洞察</title>
      <link>https://stats.stackexchange.com/questions/659655/insights-into-median-of-means-estimators-in-did-designs</link>
      <description><![CDATA[我目前正在开展一个研究项目，重点研究双差分 (DiD) 设计中的稳健估计量，特别是在经典的两期两组设置中。我的主要兴趣是对 y 方向异常值的稳健性（我污染了误差项），并且我一直在探索均值中位数 (MoM) 估计量作为标准 DiD 治疗效果估计量（基于均值）的潜在替代方案。
但是，我遇到了几个问题：

缺乏文献：我找不到任何先前的研究或 DiD 环境中均值中位数估计量的应用。有人知道是否存在这样的研​​究或我可以在哪里找到吗？
意外结果：当我模拟和实施 MoM 估计量时，我得到的结果与标准 DiD 估计量相同 - 即使包含受污染的数据点也是如此。这让我开始质疑为什么 MoM 估计量在这种设置下不是更稳健。

有人能解释为什么中位数估计量在这种情况下可能无法按预期执行吗？或者 DiD 框架中是否存在一些基本问题，导致 MoM 方法不太合适？
如果您有任何想法、文献建议，甚至直观的解释，我将不胜感激！
在此先感谢您的帮助！

这是我的模拟设置：

数据生成：我模拟了 N=500 和 T=2 个时间段（治疗前和治疗后）的面板数据。一半的单位在第二期进行治疗。结果方程为 $Y = 0.1 + 0.2⋅time − 0.1⋅group + β_{true}⋅D + ϵ $。这里，$β_{true} = 0.4 $，ϵ 是带有污染的随机噪声。
污染：随机噪声 𝜖 以混合形式生成：
$ ϵ = \begin{cases} N(0, \sigma^2) &amp; \text{with probability } (1 - p), \\
U(-c, c) &amp; \text{with probability } p \end{cases}$ 
我尝试过参数 $\sigma$、$p$ 和 $c$（也尝试过非对称污染），但这似乎没有什么区别。在下图中，$\sigma = 0.1$，$p = 0.1$ 和 $c = 50$。
估计量构造如下：
$ \text{DiD 估计} =
\left(
\overline{Y}_{\text{Treated, Post}} - \overline{Y}_{\text{Treated, Pre}}
\right)
-
\left(
\overline{Y}_{\text{Control, Post}} - \overline{Y}_{\text{Control, Pre}}
\right)
$
$
\text{中位数（MoM）：}
$

将数据拆分为 $ K = \sqrt(N) $ 个块
计算特定于块的 DiD 估计值：$
\text{Block DiD Estimate} = \text{DiD(Block_i})$
最终 MoM 估计值是块估计值的中位数：$
\text{MoM Estimate} = \text{Median(Block DiD Estimates)}$




块在单元级别定义。因此，每个单元被随机分配到 K 个块中的一个：
block_assignment &lt;- sample(1:K, length(unique(Y_df$unit)), replace = TRUE)

同一单元（在两个时间段内）的所有观察结果都分配给同一个块：
block_map &lt;- data.frame(unit = unique_units, block = block_assignment)Y_df &lt;- Y_df %&gt;% left_join(block_map, by = &quot;unit&quot;)



时间 (T) 取值 {1,2} = {治疗前、治疗后

组 (P) 取值 {0,1} = {对照、治疗
 P &lt;- rbinom(N, 1, 0.5)


治疗虚拟变量 (D) 取值 {0,1}
 D[P == 1, 2] &lt;- 1 # 治疗开始于第 2 阶段，适用于接受治疗的单位





 ]]></description>
      <guid>https://stats.stackexchange.com/questions/659655/insights-into-median-of-means-estimators-in-did-designs</guid>
      <pubDate>Tue, 07 Jan 2025 10:05:08 GMT</pubDate>
    </item>
    <item>
      <title>如何理解概率中的句子结构</title>
      <link>https://stats.stackexchange.com/questions/659651/how-to-understand-structure-of-sentences-in-probability</link>
      <description><![CDATA[我的教科书上是这么写的

(I) 随机选择的一名高中生吃早餐
(II) 随机选择的一名青少年是吃早餐的高中生
(III) 随机选择的一名吃早餐的青少年是高中生

我应该为上述概率选择正确的大小顺序。
书上说概率是

(I): $P(\mathrm I)=\Pr(\text{Breakfast }\mid\text{ Senior})$
(II): $P(\mathrm{II})=\Pr(\text{Breakfast} \cap \text{Senior})$
(III): $P(\mathrm{III})=\Pr(\textrm{Senior} \mid \textrm{Breakfast})$

那么我的问题是，例如在 (II) 中，为什么不是 $P(\mathrm{II})=\Pr(\text{Breakfast} \mid\text{ Senior})$？
因为我觉得如果你把 (III) 写成条件概率，你也应该把 (II) 写成条件概率。
我这里漏掉了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659651/how-to-understand-structure-of-sentences-in-probability</guid>
      <pubDate>Tue, 07 Jan 2025 08:58:39 GMT</pubDate>
    </item>
    <item>
      <title>何时使用哪种样本方差公式？</title>
      <link>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</link>
      <description><![CDATA[我知道样本方差的公式为
$$s^2 = \frac{\sum (x_i - \bar{x})^2}{n - 1}$$
我还知道样本方差的公式为“均值平方减均值平方”。
在计算给定样本的样本方差时，我使用了这两个公式，但发现它们给出了两个不同的答案，因此我想问，什么时候应该使用第一个公式，什么时候应该使用第二个公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/659644/when-to-use-which-formula-for-sample-variance</guid>
      <pubDate>Tue, 07 Jan 2025 05:32:19 GMT</pubDate>
    </item>
    <item>
      <title>以 Y 的指标为条件，对 X 对 Y 的影响进行条件化</title>
      <link>https://stats.stackexchange.com/questions/659633/condition-the-effect-of-x-on-y-on-the-indicator-of-y</link>
      <description><![CDATA[正如标题所示，我正在做一个研究项目，研究X（因变量）和Y（自变量）之间的关系。它们都是连续变量，Y在0附近对称分布。朴素的OLS回归模型是：
Y ~ X + e 

但我们有强有力的理论论据，即X对Y的影响应该取决于Y是正还是负：
Y ~ X + Z + X*Z + e
Z = I(Y&gt;0)

显然，Z是内生的。我有两个问题：
1，我可以使用交互模型吗？如果可以，需要什么条件？
2，还有其他方法可以实现我正在做的事情吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659633/condition-the-effect-of-x-on-y-on-the-indicator-of-y</guid>
      <pubDate>Tue, 07 Jan 2025 01:07:53 GMT</pubDate>
    </item>
    <item>
      <title>探索性因子分析，非正态数据</title>
      <link>https://stats.stackexchange.com/questions/659613/exploratory-factor-analysis-non-normal-data</link>
      <description><![CDATA[我正在分析的数据对于几乎每个观察到的变量都是非正态的。我想在 R 中进行探索性因子分析 (EFA)。KMO 检验和 Bartlett 检验表明数据符合 EFA 条件。在 psych 包的文档中，我没有找到应如何处理非正态分布的数据 (https://personality-project.org/r/psych/HowTo/factor.pdf)。我的样本相对较小 (N=60)。
在进行验证性因子分析时，我可以使用 lavaan 包中的 Satorra-Bentler 校正来处理非正态数据，cfa() 函数，例如cfa(model = spec, data = df_data, std.lv=TRUE, estimator = &quot;MLM&quot;) ，这种使用稳健标准误差的校正是一种可接受的方法。 estimator=&quot;MLM&quot; 代表 Satorra-Bentler 校正。我可以用 psych 包 以某种方式做到这一点吗？
psych 包执行 EFA，fa() 函数，例如fa(data, nfactors = 4, rotate = &quot;oblimin&quot;) 并提供可行的因子，但如果我没有弄错的话，它被设计用于正态分布的数据。
如果我尝试使用 lavaan 包 中的 efa() 和 Satorra-Bentler 校正，它会发出 警告，表示协方差矩阵包含较小的负值，这可能表明模型未被识别：
efa(data = df_data, nfactors=4, rotation=&quot;oblimin&quot;, std.lv=TRUE, estimator = &quot;MLM&quot;)

警告消息：
1：lavaan-&gt;lav_model_vcov()： 
估计参数 (vcov) 的方差-协方差矩阵似乎不是
正定！最小特征值 (= -5.425180e-15) 小于零。这可能是模型无法识别的症状。
2：lavaan-&gt;lav_model_vcov()：
估计参数 (vcov) 的方差-协方差矩阵似乎不是 
正定的！最小特征值 (= -2.190854e-32) 小于零。这可能是模型无法识别的症状。


所以问题是： 如何使用非正态数据计算 EFA，可能使用 psych 包？
从响应来看，我似乎可以为 fa() 函数提供一个相关矩阵，例如 Spearman 相关，并从最大似然 (ML) 中选择不同的因子提取方法。
关于响应的更新问题：
(1) 我如何为 fa() 函数提供 Spearman 相关矩阵？我会选择“wls”作为因子提取方法。在这种情况下可以接受吗？(2) Muthen 的方法是否在任何 R 包中可用？
更新，有关数据的响应的更多信息：
数据的分布：我有 9 个变量，每个变量都有比例尺度，因此理论上它们可以从零到无穷大。在实践中，它们计算活动，因此它们包含每个研究对象的整数值。其中一些只有 2、3 个不同的值，这给出了与理论正态分布不同的分布。我添加了一个关于一个变量的 QQ 图，如下图所示。

我使用心理学包进行了 EFA，以发现数据可能具有从 1 个因子到 9 个因子的内容，以便我可以看到每种情况的拟合优度指标。 这产生了具有 4 个潜在变量的最佳指标。这就是我从 4 开始的原因。尽管如此，我并没有更改默认的因子提取，也没有提供相关矩阵。
我很感激每一个回复，谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659613/exploratory-factor-analysis-non-normal-data</guid>
      <pubDate>Mon, 06 Jan 2025 12:41:19 GMT</pubDate>
    </item>
    </channel>
</rss>