<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 13 Dec 2024 21:16:09 GMT</lastBuildDate>
    <item>
      <title>解释负二项残差图</title>
      <link>https://stats.stackexchange.com/questions/658692/interpreting-negative-binomial-residual-plot</link>
      <description><![CDATA[我对圣巴巴拉 125 个街区组的自行车事故数据进行了负二项回归。方程式如下：
事故 ~ 自行车网络连接 + 偏移量（log（自行车出行次数））
我得到了一个带有曲线的残差图，如下图所示。这是否意味着这种关系是非线性的？我不知道该如何处理：我应该添加非线性项还是应该尝试其他模型，还是其他？如果有人能对此有所启发，那就太好了。谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658692/interpreting-negative-binomial-residual-plot</guid>
      <pubDate>Fri, 13 Dec 2024 20:44:28 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost/XGBRanker 用于乘积概率而不是排名分数</title>
      <link>https://stats.stackexchange.com/questions/658687/xgboost-xgbranker-to-product-probabilities-instead-of-ranking-scores</link>
      <description><![CDATA[我有一个学生考试成绩的数据集，如下所示：
班级 ID 班级规模 学生编号 智商 学习时间 分数
1 3 3 101 10 98
1 3 4 99 19 80
1 3 6 130 3 95
2 4 4 93 5 50
2 4 5 103 9 88
2 4 8 112 12 99
2 4 1 200 10 100 

我想建立一个机器学习模型，尝试使用 IQ 和 Hours_Studied 预测谁将成为班级第一名（即最高 Score），对于任何给定的 Class_ID特征。
由于这是一个排名问题，因此自然的一类学习模型是使用 XGBoost 中的 XGBRanker 或 lightgbm 中的 LGBMRanker。
这是我使用 xgboost 的代码：
from sklearn.model_selection import GroupShuffleSplit
import xgboost as xgb

gss = GroupShuffleSplit(test_size=.40, n_splits=1, random_state = 7).split(df, groups=df[&#39;Class_ID&#39;])

X_train_inds, X_test_inds = next(gss)

train_data = df.iloc[X_train_inds]
X_train = train_data.loc[:, ~train_data.columns.isin([&#39;Class_ID&#39;,&#39;Student_Number&#39;,&#39;Score&#39;])]
y_train = train_data.loc[:, train_data.columns.isin([&#39;Score&#39;])]

groups = train_data.groupby(&#39;Class_ID&#39;).size().to_frame(&#39;Class_size&#39;)[&#39;Class_size&#39;].to_numpy()

test_data = df.iloc[X_test_inds]

X_test = test_data.loc[:, ~test_data.columns.isin([&#39;Student_Number&#39;,&#39;Score&#39;])]
y_test = test_data.loc[:, test_data.columns.isin([&#39;Score&#39;])]

model = xgb.XGBRanker( 
tree_method=&#39;hist&#39;,
device=&#39;cuda&#39;,
booster=&#39;gbtree&#39;,
objective=&#39;rank:pairwise&#39;,
enable_categorical=True,
random_state=42, 
learning_rate=0.1,
colsample_bytree=0.9, 
eta=0.05, 
max_depth=6, 
n_estimators=175, 
subsample=0.75 
)

model.fit(X_train, y_train, group=groups, verbose=True)

def predict(model, df):
return model.predict(df.loc[:, ~df.columns.isin([&#39;Class_ID&#39;,&#39;Student_Number&#39;])])

predictions = (X_test.groupby(&#39;Class_ID&#39;)
.apply(lambda x: predict(model, x)))

代码运行良好，具有合理的预测能力。但是，输出是“相关性得分”列表，而不是概率列表。但似乎 XGBRanker 和 LGBMRanker 都没有属性 predict_proba，该属性返回获得班级最高分的概率。
所以我的问题是，有没有办法将 相关性得分 转换为概率，或者是否有其他自然类别的排名模型可以处理此类问题？
编辑在这个问题中，我只关心最终名列前茅的人（或者可能是前三名），所以排名并不是那么重要（例如，知道学生 4 排名第 11 位，学生 8 排名第 12 位并不那么重要），所以我想一种方法是在 xgboost 中使用分类而不是排名。但我想知道还有其他方法吗。]]></description>
      <guid>https://stats.stackexchange.com/questions/658687/xgboost-xgbranker-to-product-probabilities-instead-of-ranking-scores</guid>
      <pubDate>Fri, 13 Dec 2024 19:11:11 GMT</pubDate>
    </item>
    <item>
      <title>对偏斜响应变量进行建模</title>
      <link>https://stats.stackexchange.com/questions/658686/modelling-a-skewed-response-variable</link>
      <description><![CDATA[我有一个生物标志物比率（淀粉样蛋白 42/40），我在建模方面遇到了问题。我将其用作暴露和结果，但显然，当我将变量视为结果时，变量的这种分布更成问题。如果您能就您对此类数据使用了哪些建模方法提出建议，我将不胜感激
]]></description>
      <guid>https://stats.stackexchange.com/questions/658686/modelling-a-skewed-response-variable</guid>
      <pubDate>Fri, 13 Dec 2024 19:02:18 GMT</pubDate>
    </item>
    <item>
      <title>对点对之间的变化与纵向回归进行建模？</title>
      <link>https://stats.stackexchange.com/questions/658685/modelling-the-change-between-pairs-of-points-vs-longitudinal-regression</link>
      <description><![CDATA[
这是基本的纵向模型（混合效应），用于解释个体群体中重复测量之间的相关性：

$$ y_{it} = X_{it}\beta + Z_{it}b_i + \epsilon_{it} $$
其中：

$y_{it}$ 是受试者 $i$ 在时间 $t$ 的结果
$X_{it}$ 表示具有相应参数 $\beta$ 的固定效应设计矩阵
$Z_{it}$ 是具有特定于主题的随机效应的随机效应设计矩阵 $b_i$
$\epsilon_{it}$ 表示误差项
$ b_i \sim N(0, \Sigma_b) $
$ \epsilon_{it} \sim N(0, \sigma^2) $


一阶差分回归对两个观测值之间的差异进行建模，从而可以最大限度地减少时间不变遗漏变量偏差的影响：

$$ \Delta y_{it} = \Delta X_{it}\beta + \Delta \epsilon_{it} $$
其中：

$\Delta y_{it} = y_{it} - y_{i,t-1}$ 表示结果的变化
$\Delta X_{it} = X_{it} - X_{i,t-1}$ 表示预测变量的变化
$\Delta \epsilon_{it} = \epsilon_{it} - \epsilon_{i,t-1}$ 是差分误差项

我只是想知道是否可以将这两个模型结合起来以创建一个混合模型效果一阶差分回归模型？例如：
$$ \Delta y_{it} = \Delta X_{it}\beta + Z_{it}b_i + \Delta \epsilon_{it} $$
$$ b_i \sim N(0, \Sigma_b) $$
$$ \Delta \epsilon_{it} \sim N(0, 2\sigma^2) $$
在统计学中可以这样做吗？结合两全其美 - 允许一般相关结构，同时控制某些类型的遗漏变量偏差？]]></description>
      <guid>https://stats.stackexchange.com/questions/658685/modelling-the-change-between-pairs-of-points-vs-longitudinal-regression</guid>
      <pubDate>Fri, 13 Dec 2024 18:47:14 GMT</pubDate>
    </item>
    <item>
      <title>非参数回归：开创性论文</title>
      <link>https://stats.stackexchange.com/questions/658688/non-parametric-regression-seminal-papers</link>
      <description><![CDATA[这个问题主要是参考文献的问题，无法客观回答，因为文献推荐本质上取决于个人偏好。我希望它仍然可以。
我想问一下，您认为非参数回归中的开创性/重要论文是什么？这个问题的背景是，我正在对非参数回归的某个特定方面进行研究，但对它总体上不太了解。在深入研究某个特定方向之前，我想提出一些建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/658688/non-parametric-regression-seminal-papers</guid>
      <pubDate>Fri, 13 Dec 2024 16:58:01 GMT</pubDate>
    </item>
    <item>
      <title>如何处理间歇性的 NUTS Sampler 卡在简单的逆问题中？</title>
      <link>https://stats.stackexchange.com/questions/658681/how-to-deal-with-intermittent-nuts-sampler-stuck-in-simple-inverse-problem</link>
      <description><![CDATA[给定一个模型，我尝试使用 blackjax python 包中的 NUTS 推断参数并量化估计的不确定性。我有多个输入数据集并尝试估计后验。对于使用 blackjax 提供的自动调整的一些人来说，这很有效。然而对于其他人，即使使用手动调整，NUTS 采样器也会遇到非最大似然的点，采样器会卡住。后验和迹线如下所示


问题似乎是先验的下限 &gt;=0，因为压力先验应该是正的。
不，NUTS 采样器似乎卡住了，导致边缘伪影。问题点代表了底层 ODE 的模型简化。除了模型中的硬先验和潜在附加条件（if 语句确定简化）之外，是否有自然的方法来挽救这些后验？我可以从数学上合理地排除事后条件，同时仍然获得有效的不确定性量化吗？
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/658681/how-to-deal-with-intermittent-nuts-sampler-stuck-in-simple-inverse-problem</guid>
      <pubDate>Fri, 13 Dec 2024 16:40:42 GMT</pubDate>
    </item>
    <item>
      <title>截断正态分布方差的选择修正方法</title>
      <link>https://stats.stackexchange.com/questions/658680/selection-correction-method-with-the-variance-of-the-truncated-normal-distributi</link>
      <description><![CDATA[考虑以下数据生成过程：
$$Y=\beta_0+\beta_1X_1+\beta_2X_2+\beta_3u+\varepsilon,$$
$$D=1\left[\gamma_0+\gamma_1Z+\gamma_2X_1+\gamma_3X_2+u&gt;0\right],$$
其中，如果单位被观察到，则$D=1$，否则$0$，并且$u$呈正态分布，均值为零。
众所周知，$Y$对$X_1$ 和 $X_2$ 仅使用观察到的单位（即 $D=1$）会导致有偏差的估计，而经典的解决方案是包括额外的回归量 $$\lambda(\widehat{\gamma})=\frac{\phi\left(-\left(\widehat{\gamma_0}+\widehat{\gamma_1}Z+\widehat{\gamma_2}X_1+\widehat{\gamma_3}X_2\right)\right)}{1-\Phi\left(-\left(\widehat{\gamma_0}+\widehat{\gamma_1}Z+\widehat{\gamma_2}X_1+\widehat{\gamma_3}X_2\right)\right)},$$
其中 $\widehat{\gamma}=\left[\widehat{\gamma_0},\widehat{\gamma_1},\widehat{\gamma_2},\widehat{\gamma_3}\right]&#39;$ 来自 $D$ 在 $Z$、$X_1$ 和 $X_2$ 上的概率单位。
附加回归量解决问题的原因是 $\sigma_u\mathbb{E}\left[u/\sigma_u\middle|D=1\right]=\sigma_u\lambda(\widehat{\gamma})$，可以使用截断正态分布的矩轻松得出。
因此，我认为，如果结果 $Y$ 生成如下（注意 $u$ 的平方），
$$Y=\beta_0+\beta_1X_1+\beta_2X_2+\beta_3u+\beta_4u^2+\varepsilon,$$
额外的回归量 $\lambda(\widehat{\gamma})$ 和 $\lambda_2(\widehat{\gamma})=1-\lambda(\widehat{\gamma})^2-W&#39;\widehat{\gamma}\cdot\lambda(\widehat{\gamma})$，其中 $W=[1, Z, X_1, X_2]&#39;$，可以产生无偏估计结果，这是由于截断正态分布的方差公式为：
$$\sigma_u^2\mathbb{E}\left((u/\sigma_u)^2\middle|D=1\right)=\sigma_u^2\lambda_2(\widehat{\gamma})$$
因此，我检查了这是否属实：
#################################
### 数据生成过程 1 ###
#################################
set.seed(1)
N &lt;- 100000
x1 &lt;- rnorm(N)
x2 &lt;- rnorm(N)
z &lt;- rnorm(N)
u &lt;- rnorm(N)
e &lt;- rnorm(N)

y &lt;- 1 + 2 * x1 + 2 * x2 + 2 * u + e # 结果方程
d &lt;- (1 + 2 * z + x1 + 2 * x2 + u &gt; 0) # 选择方程

# 使用观察单位的回归
lm(y ~ x1 + x2, subset = (d == 1))
# 真值 = 1, 2, 2, 估计值 = 1.536, 1.844, 1.681

# Heckman 的两步估计
prb &lt;- glm(d ~ z + x1 + x2, family = binomial(link = &quot;probit&quot;)) # probit
zgam &lt;- cbind(1, z, x1, x2) %*% c(1, 2, 1, 2)
phi &lt;- dnorm(-zgam)
PHI &lt;- pnorm(-zgam)
lam &lt;- phi / (1 - PHI) # 逆米尔斯比率
lm(y ~ x1 + x2 + lam, subset = (d == 1))
# 真值 = 1, 2, 2，2 估计值 = 1.003，2.001，1.994，1.986

#################################
### 数据生成过程 2 ###
#################################
y &lt;- 1 + 2 * x1 + 2 * x2 + 2 * u + 2 * u^2 + e # 结果方程
d &lt;- (1 + 2 * z + x1 + 2 * x2 + u &gt; 0) # 选择方程

# 使用观察单位的回归
lm(y ~ x1 + x2, subset = (d == 1))
# 真实值 = 1, 2, 2, 估计值 = 3.537, 1.805, 1.582

# 截断正态方差
lam2 &lt;- 1 - lam^2 - zgam * lam
lm(y ~ x1 + x2 + lam + lam2，子集 = (d == 1))
# 真实值 = 1, 2, 2, 2, 2 估计值 = -3.393, 1.974, 1.927, 7.331, 6.565

但是，正如您所见（尤其是最后一行），只有 $\beta_1$ 和 $\beta_2$ 的结果看起来合理。
我是否遗漏了什么要点？]]></description>
      <guid>https://stats.stackexchange.com/questions/658680/selection-correction-method-with-the-variance-of-the-truncated-normal-distributi</guid>
      <pubDate>Fri, 13 Dec 2024 16:23:55 GMT</pubDate>
    </item>
    <item>
      <title>Jeffreys 离散参数空间的先验</title>
      <link>https://stats.stackexchange.com/questions/658678/jeffreys-prior-for-a-discrete-parameter-space</link>
      <description><![CDATA[以下问题涉及二项分布，其概率已知$p$，但试验次数未知$n$。
试验次数的二项置信区间
尝试思考如何为这种情况构建贝叶斯区间，我首先进入了思考 Jeffreys 先验的阶段。但是，对于离散参数空间，这没有定义，因为导数不存在。
是否有根据相同想法找到先验的方法？当然，坐标变换下分布的不变性已经过时，因为概率质量函数不会像概率密度函数那样变换。这是 Jeffreys 先验的唯一属性/动机吗，或者还有其他属性可以应用于概率质量函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/658678/jeffreys-prior-for-a-discrete-parameter-space</guid>
      <pubDate>Fri, 13 Dec 2024 16:07:13 GMT</pubDate>
    </item>
    <item>
      <title>在 Heckman 模型中，我可以使用选择方程中的因变量作为选择方程中的自变量吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658677/in-heckman-model-can-i-use-dependent-variable-in-selection-equation-as-independe</link>
      <description><![CDATA[我已经将上述变量作为选择中的从属变量和结果方程中的独立变量。但在结果中，所选的和最重要的变量被省略了。由于共线性，它显示省略了。如何解决这个问题。请有人给我建议。我的研究是关于 FPOs 的，我想知道 fpos 对 FPO 农民收入的影响。样本量是来自一个地区的 60 名 FPO 农民和 60 名非 fpo 农民，我已经从 3 个不同的地区和作物收集了数据。所以我想知道是什么因素促使农民加入 fpo，加入 fpo 后他们的收入是否增加了。为此，我想要 Heckman 两步模型。

提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/658677/in-heckman-model-can-i-use-dependent-variable-in-selection-equation-as-independe</guid>
      <pubDate>Fri, 13 Dec 2024 15:47:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么机器学习课程中的回归分析大多侧重于梯度下降，尽管我们有闭式估计量$(X'X)^{-1}X'Y$？[重复]</title>
      <link>https://stats.stackexchange.com/questions/658672/why-do-machine-learning-courses-on-regression-mostly-focus-on-gradient-descient</link>
      <description><![CDATA[在许多在线机器学习课程和视频（例如 Andrew Ng 的 Coursera 课程）中，当谈到回归（例如对特征 $X$ 进行 $Y$ 回归）时，虽然我们有回归系数 $\widehat{\beta}=(X&#39;X)^{-1}X&#39;Y$ 的闭式估计量，并且基于此我们可以得出 $X_i=x$ 的预测为 $x&#39;\widehat{\beta}$。这很简单，不需要数值优化。我的问题是：

鉴于闭式回归估计器（和预测器）的简单性，为什么机器学习课程通常会忽略它，而只关注梯度下降？

以这种方式教授回归有什么优点？

此外，梯度下降在实际性能方面的相对优点是什么？

]]></description>
      <guid>https://stats.stackexchange.com/questions/658672/why-do-machine-learning-courses-on-regression-mostly-focus-on-gradient-descient</guid>
      <pubDate>Fri, 13 Dec 2024 14:08:57 GMT</pubDate>
    </item>
    <item>
      <title>当 $X\sim \operatorname{Beta}(\alpha,\beta)$ 时，$Y=-\log(X)$ 的分布</title>
      <link>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</guid>
      <pubDate>Fri, 13 Dec 2024 11:02:03 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用函数 HSD.test 作为 R 中双向方差分析的事后检验吗？</title>
      <link>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</link>
      <description><![CDATA[我已经进行了双向方差分析与交互作用（编辑），现在我想进行事后检验。我有 2 个因素，并且都只有 2 个类别。我找到了 agricolae 包中的 HSD.test 函数，我非常喜欢它为您提供了组和有关组间差异的字母。但我不确定这个函数是否可以用于两个因素，或者它是否仅在您有单向方差分析时才有效。有人知道吗？
编辑：我进行了方差分析来检验一个假设，即这两个因素都不会对连续因变量产生影响。我拒绝了这个假设，现在我想知道这 4 个组之间的差异。我应该如何测试它？]]></description>
      <guid>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</guid>
      <pubDate>Thu, 12 Dec 2024 23:05:32 GMT</pubDate>
    </item>
    <item>
      <title>高斯对数似然值究竟如何计算？</title>
      <link>https://stats.stackexchange.com/questions/658636/how-is-gaussian-log-likelihood-value-calculated-exactly</link>
      <description><![CDATA[我检查了这些 R 函数 glm.fit() gaussian()$aic stats:::logLik.glm() 和 stats:::logLik.lm()，发现 stats:::logLik.glm() 报告的对数似然值是根据 gaussian()$aic 计算的，其定义为
function (y, n, mu, wt, dev) 
{
nobs &lt;- length(y)
nobs * (log(dev/nobs * 2 * pi) + 1) + 2 - sum(log(wt))
}

stats:::logLik.lm() 报告的对数似然值使用以下公式计算。
0.5 * (sum(log(w)) - N * (log(2 * pi) + 1 - log(N) + 
log(sum(w * res^2))))

这两个公式在高斯家族中得出相同的 logLik 和 AIC。我理解 $AIC = -2 \ln{L} + 2df$ 并且可以重现与基本函数 logLik() 相同的结果，但我不知道为什么要以上述方式计算它们。使用基于经典公式的对数密度值总和，如“正态分布 - 最大似然估计”中所示https://www.statlect.com/fundamentals-of-statistics/normal-distribution-maximum-likelihood，我得到了不同的对数似然值，无法识别我的计算和默认输出之间的关系。请参阅以下最小示例。
Data &lt;- data.frame(
y = c(0.2, 0.2, 0.3), 
n = c(10, 20, 30)
)

# GLS 模型
with(Data, sum(y * n)/sum(n)) # 0.25
summary(Model &lt;- glm(y ~ 1, weights = n, data = Data))
&quot;估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.25000 0.03536 7.071 0.0194 *
(高斯族的分散参数取为 0.075)
零偏差：2 个自由度上的 0.15
残差偏差：2 个自由度上的 0.15
AIC：-5.1731&quot;
with(Model, Prior.weights)
&quot; 1 2 3 
10 20 30 &quot;
with(Model, weights)
&quot; 1 2 3 
10 20 30 相同，无迭代重新加权&quot;

# 默认函数
logLik(Model)
&quot;4.58654 (df=2)&quot;
AIC(模型)
&quot;-5.17308 因为 -2 * 4.58654 + 2 * 2 == -5.17308&quot;
with( # 基于 gaussian()$aic 和 glm.fit()
模型，nobs(模型) * (log(deviance/nobs(模型) * 2 * pi) + 1) + 
2 - sum(log(weights)))
&quot;-7.17308
-7.17308 + 2*1 == -5.17308 是报告的 AIC
logLik 源自 AIC 测量&quot;

# OLS 模型
summary(模型 &lt;- lm(y ~ 1, weights = n, data = Data))
logLik(模型)
&quot;4.58654 (df=2) 与上文相同&quot;
AIC(Model)
&quot;-5.17308 与上文相同&quot;
with(Model, 0.5 * (
sum(log(weights)) - nobs(Model) * (
log(2 * pi) + 1 - log(nobs(Model)) + log(sum(weights * residuals^2)))))
&quot;4.58654 为报告的 logLik&quot;

# 手动计算
with(Model, sum(prior.weights * log(
dnorm(y, mean = coef(Model), sd = sigma(Model)))))
&quot;21.5717&quot;
with(Model, sum(weights) * (-1/2 * log(2 * pi)))
&quot;-55.13631&quot;
带有（模型，总和（权重）*（-1/2 * log（sigma（模型）^2）））
“77.70801”
带有（模型，（-1/（2 * sigma（模型）^2））* 总和（权重*（y - coef（模型））^2））
“-1
-55.13631 + 77.70801 - 1 == 21.5717”
with(Model, sum(weights * (y - coef(Model))^2))

答案和更新
常规高斯密度函数是
$f_a = \frac{1}{\sqrt{2\pi\sigma^2}}\exp{-\frac{(y_i − \hat{y}^2_i)}{2\sigma^2}}$
但当有权重时，它就变成
$f_b = \frac{1}{\sqrt{2\pi\sigma^2/w_i}}\exp{-\frac{(y_i − \hat{y}^2_i)}{2\sigma^2/w_i}}$
这表明底层正态分布的方差为 $\sigma^2/w_i$。直观地看，它类似于计算为$SD/\sqrt{n}$的平均标准误差，这表明组大小（即权重）越大，误差方差$s^2/n$越小。
基于gaussian()$aic的stats:::logLik.lm()和stats:::logLik.glm()都使用$N\sigma^2 = \sum{w_i(y_i - \hat{y}^2_i)}$来取消上面的$\sigma$项。但是，我不明白为什么默认不使用$(N-p)\sigma^2 = \sum{w_i(y_i - \hat{y}^2_i)}$。这就是$\sigma$在lm()和glm()中的导出方式，它对应于残差方差的无偏估计，而不是低估残差方差的最大似然估计量。]]></description>
      <guid>https://stats.stackexchange.com/questions/658636/how-is-gaussian-log-likelihood-value-calculated-exactly</guid>
      <pubDate>Thu, 12 Dec 2024 17:03:36 GMT</pubDate>
    </item>
    <item>
      <title>如何在我的受污染数据问题中找到具有 ML 组件的去偏估计量？</title>
      <link>https://stats.stackexchange.com/questions/658578/how-to-find-a-de-biased-estimator-with-a-ml-component-in-my-contaminated-data-pr</link>
      <description><![CDATA[我试图使用机器学习模型的输出来估计（使用最大似然法）分布中的参数。我得到的估计量的偏差比参数值大得多。我想使用 Neyman 正交性/双机器学习方法（Chernozhukov et al., 2018）、影响函数或任何相关（或不相关）方法找到一个去偏估计量。但我不清楚如何在我的情况下构建去偏估计量。
我的估计问题
我已经“污染”了数据：大多数数据来自概率分布$P_0(x)$，但部分数据来自不同的分布$P_1(x)$（“污染”）。因此，我假设我的数据点是从分布$$P(x) = (1-\theta) P_0(x) + \theta P_1(x).$$中独立同分布抽取的。我的目标是找出受污染数据的比例$\theta$。 $\theta$ 的最大似然估计量是 $$0 = \frac{1}{n}\sum_i\frac{r(x_i)-1}{1+\hat{\theta}\bigl(r(x_i)-1\bigr)},$$ 的解，其中 $x_1,\ldots,x_n$ 是数据点，$r(x) = \frac{P_1(x)}{P_0(x)}$。
我不知道概率分布 $P_0(x)、P_1(x)$ 或它们的比率 $r(x)$直接，但我确实有另一个标记为数据集 $(\tilde{x}_i, y_i)$ 的数据点，其生成分布是已知的：对于从 $P_0$ 中抽取的点，$y_i=0$ ；对于从 $P_1$ 中抽取的点，$y_i=1$ ：$$Prob(\tilde{x}_i | y_i) = P_{y_i} (\tilde{x}_i)$$ （为简单起见，假设我有相同数量的 $\tilde{x}_i$，其中 $\tilde{x}_i$ class=&quot;math-container&quot;&gt;$y=0$ 和 $y=1$)。因此，我尝试通过两个步骤估计 $\theta$：

在标记数据集上训练 ML 分类器 $f(x)$ 以估计 $Prob(y=1|x)$，从而获得概率比的估计值为：$\hat{r}(x) = \frac{f(x)}{1-f(x)}$。

将此 $\hat{r}$ 代入 MLE 方程，得出 $$0 = \frac{1}{n}\sum_i\frac{\hat{r}(x_i)-1}{1+\hat{\theta}\bigl(\hat{r}(x_i)-1\bigr)},$$ 并求解 $\hat{\theta}$。


请注意，用于 MLE 估计（步骤 2）的数据集与用于训练 ML 模型（步骤 1）的数据不同且独立。
我的问题
$\hat{r}$ 是一个有偏估计量，例如在双重机器学习文献中讨论过（参见上面的链接）。因此，我得到了 $\theta$ 的有偏估计量。在我的案例中，我感兴趣的是 $\theta$ 的值远小于此偏差。因此，我想找到 $\theta$ 的去偏估计量。但我对如何将双重机器学习方法或影响函数应用于我的案例感到困惑。
在我的案例中，Neyman 正交 MLE 方程是什么？我如何使用我拥有的信息来找到污染分数 $\theta$ 的去偏估计量？]]></description>
      <guid>https://stats.stackexchange.com/questions/658578/how-to-find-a-de-biased-estimator-with-a-ml-component-in-my-contaminated-data-pr</guid>
      <pubDate>Wed, 11 Dec 2024 15:48:04 GMT</pubDate>
    </item>
    <item>
      <title>当预测变量在抽样单位内不变时，对其估计效应的解释</title>
      <link>https://stats.stackexchange.com/questions/658505/interpretation-of-estimated-effect-of-a-predictor-variable-when-it-does-not-vary</link>
      <description><![CDATA[让我们考虑以下场景。John 很快就要对他的学生进行测验，他想知道测验格式的字体类型是否与学生在测验中的表现有关。John 假设在前两次测验中得分较高的学生在即将到来的测验中也会获得高分。John 计算了前两次测验的平均分数并将其命名为 last_score。即将到来的测验在各个方面与前两次测验相似：每个即将到来的测验也将有 10 个问题，每个正确答案都会为测验总分贡献 1 分。John 使用有序变量 new_score 来记录每个即将到来的测验的总分。John 在测验中将使用的两种字体类型是 Arial 和 Times New Roman； John 使用因子变量 type 对它们进行编码。
他设置了两个随机截距模型，以将 new_score 的条件多项分布建模为具有比例几率结构的 last_score 和 type 的函数：
formula.mod1 &lt;- new_score ~ last_score + type + (1 | student)

formula.mod2 &lt;- new_score ~ last_score*type + (1 | student)

在格式化 John 将要进行的六个测验之一以测试字体类型对测验表现的影响时，John 问自己，“我应该如何解释具有公式 formula.mod1 的随机截距模型的 last_score 系数”？ John 认为测验的难度差异不大。他使用两个序列“ATATAT”和“TATATA”，其中 T 代表字体“Times New Roman”，A 代表“Arial”，以确保每个学生都能解决这两种类型的测验，使用 last_score 对学生进行排名，并将每个序列交替分配给排名的学生列表。
假设 last_score 在对学生进行的六次测验中没有变化，那么使用随机截距模型对 new_score 进行建模是否可行，其中随机截距遵循 MVN 分布（例如装有 ordinal::clmm 的模型）？如果可以，如何解释 last_score 对给定参与者的 new_score 的估计影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/658505/interpretation-of-estimated-effect-of-a-predictor-variable-when-it-does-not-vary</guid>
      <pubDate>Mon, 09 Dec 2024 21:51:33 GMT</pubDate>
    </item>
    </channel>
</rss>