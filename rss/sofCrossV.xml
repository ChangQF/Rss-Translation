<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 15 Mar 2025 15:15:46 GMT</lastBuildDate>
    <item>
      <title>多项式或顺序比例的同时或二项式置信区间？</title>
      <link>https://stats.stackexchange.com/questions/662667/simultaneous-or-binomial-confidence-intervals-for-multinomial-or-ordinal-proport</link>
      <description><![CDATA[我们正在使用随机抽样进行审核过程，我们将其概念化为Bernoulli，并将采样项目评分为通过或失败。为了对审计人的公平性，我们使用精确的（确保标称覆盖）二项式置信区间的下限作为故障比例的估计。我们需要将此审核方法概括为多项式或有序案例。
以4个级别的分类分数为例：通过，次要缺陷，主要缺陷，不可恢复的缺陷。三个有问题的水平中的每一个导致与审核员的惩罚不同。这创造了对下限的3个估计值的需求。我们不需要对通过类别的估算值。
我的理解是（满足模型假设）边缘分布应该是二项式的。我们没有比较它们之间的3个比例或寻找（显着）差异，而只是在寻找每个比例的差异。 
在这种情况下，计算3个单独的二项式间隔是公平的，或者它们的个人覆盖范围会受到比例的相互依存关系的影响吗？我一直以为这是例如选举民意调查。
我发现了许多有关在这种情况下构建同时置信区间的方法的文献，但是我与之相关的软件实施相对较少，至关重要：在解释或理由方面，我们是否真的需要它们是否真的需要它们以使在这种情况下对审计保持公平。。。
事先感谢您对此的任何输入，特别是如果您可以提供任何来源。]]></description>
      <guid>https://stats.stackexchange.com/questions/662667/simultaneous-or-binomial-confidence-intervals-for-multinomial-or-ordinal-proport</guid>
      <pubDate>Sat, 15 Mar 2025 14:34:10 GMT</pubDate>
    </item>
    <item>
      <title>可以用GPU加速Kalman Filter矩阵乘法吗？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/662666/can-kalman-filter-matrix-multiplication-be-sped-up-with-a-gpu</link>
      <description><![CDATA[卡尔曼过滤器需要计算巨大的矩阵。在GPU上编码解决方案会使其大大更快吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662666/can-kalman-filter-matrix-multiplication-be-sped-up-with-a-gpu</guid>
      <pubDate>Sat, 15 Mar 2025 14:19:31 GMT</pubDate>
    </item>
    <item>
      <title>推导Elbo扩散模型（MHVAE）</title>
      <link>https://stats.stackexchange.com/questions/662663/derive-elbo-for-diffusion-models-mhvae</link>
      <description><![CDATA[我正在尝试得出用于训练扩散模型的基于ELBO（证据下限）的损耗功能。

以下等式来自 arxiv：2208.11970   

等式。 43写如下：
  $$
\ Mathbb {
$$  
然后在等式中。 44，写下以下简化：

 联合概率密度函数 $ q（\ MathBf {x} _ {1：t} | \ Mathbf {x} _ {0}）$ 在 $ \ Mathbf {$ \ spers In  $ Q（\ Mathbf {X} _ {1} | \ MathBf {X} _ {0}）$  

  $$
\ Mathbb {
$$  
  q ：如何得出上述边缘化？

 我的尝试：
 $$
\ begin {align}
\ Mathbb { 
＆amp; = \ int _ {\ forall \ mathbf {x} _ {1：t}}} \ log p _ {\ theta}（\ Mathbf {x} _ {0} | \ Mathbf {x} _ {1}）\，q（\ Mathbf {x} _ {1：t} | \ mathbf {x} _ {0}）\，\ Mathbf {\ Mathrm {d} x} _ {1：t} \\
＆amp; = \ int _ {\ forall \ mathbf {x} _ {1：t}}} \ log p _ {\ theta}（\ mathbf {x} _ {0} | \ mathbf {x} _ {1}）\，q（\ mathbf {x} _ {2} _ {2：t} | \ m athbf {x} _ {1}，\ mathbf {x} _ {0}）\，q（\ mathbf {x} _ {1} | \ Mathbf {x} _ {0} _ {0}）\， \ Mathbf {\ Mathrm {D} X} _ {1} \，\ MathBf {\ Mathrm {d} X} _ {2：T} \\ \\
＆amp; = \ int _ {\ forall \ mathbf {x} _ {1}}} \ left（\ int _ {\ forall） \ MathBf {X} _ {2：T}} Q（\ MathBf {X} _ {2：T} | \ MathBf {X} _ {1}，\ MathBf {x} _ {0} _ {0} _ {0}） p _ {\ theta}（\ Mathbf {x} _ {0} | \ Mathbf {x} _ {1}）\，q（\ Mathbf {x} _ {1} _ {1} | \ Mathbf {\ Mathrm {D} X} _ {1} \\
\ end {align}
$$  
在上面的最后一个方程中，内部整合必须是 $ \ mathbf {x} _ {0} $ 和 $ \ mathbf {x} {x} _ {1} _ {1} $  $ G（\ MathBf {X} _ {0}，\ MathBf {X} _ {1}）$ 。为什么？

（我的推理） $ \ Mathbf {X} _ {i} $ 代表Markov链的状态（变分扩散模型是Markovian Hierchical shierharch hierharchical hierhartical autiational Auto-cododers的特殊情况）。从Markov-Property  $ \ MathBf {X} _ {2} $ 取决于 $ \ mathbf {x} _ {1} _ {1} $} $ ;因此，在上面的内部综合中，至少是整数W.R.T.  $ \ Mathbf {X} _ {2} $ 必须具有 $ \ Mathbf {x} _ {1} _ {1} $  $ 。

然后我们得到以下等式
  $$
\ begin {align}
＆amp; = \ int _ {\ forall \ mathbf {x} _ {1}} g（\ mathbf {x} _ {0}，\ \ mathbf {x} _ {1} _ {1}）\ log \ log p _ {\ theta}（\ Mathbf {x} _ {0} | \ Mathbf {x} _ {1}）\，q（\ Mathbf {x} _ {1} _ {1} | \ Mathbf {\ Mathrm {D} X} _ {1} \\
\ end {align}
$$  
现在，我们如何减少等式44中期望的不可或缺的组成部分！！

 参考：

派生这里似乎假设整数W.R.T.的限制 $ \ MathBf {X} _ {*} $ 独立于 $ \ Mathbf {x} _ {0} _ {0} $ ， $ \ Mathbf {X} _ {t-1} $ ，它似乎违反了Markovian-Property，即扩散模型的状态转换基于！
]]></description>
      <guid>https://stats.stackexchange.com/questions/662663/derive-elbo-for-diffusion-models-mhvae</guid>
      <pubDate>Sat, 15 Mar 2025 13:25:58 GMT</pubDate>
    </item>
    <item>
      <title>如何比较两个不同样本之间的相同调解模型？</title>
      <link>https://stats.stackexchange.com/questions/662660/how-to-compare-the-same-mediation-model-between-two-different-samples</link>
      <description><![CDATA[我想比较两个中介模型之间仅与所使用的样本不同的拟合。
这是一个简单的模型，其中x-＆gt; m  - ＆gt;是的，没有协变量。
有没有办法这样做？
预先感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/662660/how-to-compare-the-same-mediation-model-between-two-different-samples</guid>
      <pubDate>Sat, 15 Mar 2025 12:06:15 GMT</pubDate>
    </item>
    <item>
      <title>在预测范围内施加Diebold-Mariano测试</title>
      <link>https://stats.stackexchange.com/questions/662658/applying-the-diebold-mariano-test-with-a-decreasing-forecast-horizon</link>
      <description><![CDATA[我正在使用Diebold-Mariano测试来比较两个预测的预测精度，但是我的数据集具有独特的特征：预测范围随着时间的推移而下降。随着事件日期的临近，预测和实现之间的时间缩小，这意味着我的预测是用不同的交货时间进行的，而不是固定的 h  step结构。
 DM测试的大多数应用都采用常数预测范围，通常比较一步或多步预测的预测，其中 h 是固定的。但是，就我而言， h 随着 t 的进展而动态变化，这引起了人们对标准DM测试假设是否存在的担忧。
从我的分析中：

损失差异序列是自相关的，但是DM测试使用其长期差异估计器来解释这一点。
损失差异系列中没有漂移或确定性的时间趋势。
没有足够的异性症证据，因此标准差异假设可能存在。

我的问题：

在此设置中，DM测试仍然有效，其中 h 未修复？
是否有人遇到过文献，其中DM测试（或类似的预测精度测试）已在缩小的预测范围内应用？
如果标准DM测试无效，当预测范围随着时间的推移降低时，是否有其他方法可以比较预测准确性？

预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662658/applying-the-diebold-mariano-test-with-a-decreasing-forecast-horizon</guid>
      <pubDate>Sat, 15 Mar 2025 10:57:12 GMT</pubDate>
    </item>
    <item>
      <title>在实现中，推断出Ornstein-Uhlenbeck过程的参数无法直接观察到</title>
      <link>https://stats.stackexchange.com/questions/662657/inferring-the-parameters-of-a-ornstein-uhlenbeck-process-given-realisations-of-i</link>
      <description><![CDATA[我有一个（嘈杂）测试结果的数据集。您可以认为这是准确性的，国际象棋球员在各种比赛或篮球比赛中得分的得分数量。 
我认为一个很好的模型是，游戏中的分数 $ s_t $ 是从：中绘制的
在
其中 $ \ mu_t $ 是一种均值（ornstein – uhlenbeck）随机过程，在离散时间内可以表示为：
  $ \ mu_t =（1-a）\ mu_ {t-1} + ab + \ epsilon $   
其中 $ \ epsilon $ 是用方差 $ \ delta $ 。
我基本上想使用我的测试结果（实现的顺序 $ [s_t] _ {t = 0}^t $ ）能够得出最终能力参数的后验分布和 $ b $ 。 是否有一种稳定，有效的，计算上有效的方法？ 
我最好的想法就像是期望的最大化：假设 $ a，b，\ sigma，\ delta $ 的值。然后找到序列 $ [\ MU_T] _ {t = 0}^t $ 的最大似然估计。然后，使用该估计值查找 $ a，b，\ sigma，\ delta $ 的最大似然估计。然后继续重复，直到我希望收敛到固定点。但是，这可能是相当大的计算密集型，这将使​​我的应用程序不可行（我将为每个播放器运行它）。
我希望有一种更简单的方法可以做到这一点。或者，如果没有更简单的方法可以做到这一点，那么也许有一个模型简化可以简化它的求解而无需放弃潜在的能力（ $ \ MU_T $ 随时间变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/662657/inferring-the-parameters-of-a-ornstein-uhlenbeck-process-given-realisations-of-i</guid>
      <pubDate>Sat, 15 Mar 2025 10:05:32 GMT</pubDate>
    </item>
    <item>
      <title>人口规模的置信区间</title>
      <link>https://stats.stackexchange.com/questions/662655/confidence-interval-for-the-size-of-a-population</link>
      <description><![CDATA[说我想估计数字 $ n $ 在urn中的球中的球 $ n $ 球（无替换）。球从 $ 1 $  to  $ n $ 和让 $ z $ 表示样品的最大值。
一个人可以证明 $ z $  is  $ e（z）= \ frac {n} {n+1}（n+1}（n+1）$  $ \ hat { z（1+ \ frac {1} {n}） -  1 $ 是 $ n $ 的无偏估计器。  $ \ hat {n} $  is  $ v（\ hat {n}）= \ frac {（n-n+1）}
我想使用Chebyshev的不平等来计算 $ n $ 以95％的置信度为95％的置信区间，前提
我将如何执行此操作而不近似差异 $ v（\ hat {n}）$ （例如，用 $ n $   $ z $ z $ 最好只使用马尔可夫的不等式 $ p（| \ hat {n} -n |＆gt; a）＆lt; \ frac {]]></description>
      <guid>https://stats.stackexchange.com/questions/662655/confidence-interval-for-the-size-of-a-population</guid>
      <pubDate>Sat, 15 Mar 2025 08:36:51 GMT</pubDate>
    </item>
    <item>
      <title>平均统计值还是平均其相应的p值？</title>
      <link>https://stats.stackexchange.com/questions/662654/average-the-statistic-values-or-average-their-corresponding-p-values</link>
      <description><![CDATA[说我正在计算 hopkins统计范围聚类趋势的。统计量将数据云与在同一空间区域中随机和均匀模拟的点云进行比较。在零假设中，数据是统一的随机，统计量已知遵循β分布。因此，我可以计算统计量的P值。如果p值不显着，我们得出结论数据的群集不超过随机均匀点。。
由于可以多次模拟随机点的云，因此可以多次计算统计值及其相应的p值。然后，一个人希望对多个测试的总和结果产生总体印象。什么是：的利弊

 平均p值的多个实例; 

 平均统计量的多个实例，然后计算一个
该平均统计量的P值。

]]></description>
      <guid>https://stats.stackexchange.com/questions/662654/average-the-statistic-values-or-average-their-corresponding-p-values</guid>
      <pubDate>Sat, 15 Mar 2025 08:27:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的Copula模型关闭了？</title>
      <link>https://stats.stackexchange.com/questions/662652/why-is-my-copula-model-off</link>
      <description><![CDATA[我是第一次是自学的，主要是使用由索斯滕·施密特（Thorsten Schmidt）作者。我主要学习这件事是为了模拟基于Copula的发行版的数据，我需要该项目，该项目正在从事工作。在将学习应用于任何真实数据之前，我想确保我了解自己在做什么，所以我决定查看玩具模型。
 i生成 $ x $  as  $ \ Mathcal {n}（0，1）$ ，并让 $ y = x+y = x+x+epsilon $ sim 是高斯噪声。
 导入matplotlib.pyplot as plt
导入numpy作为NP

n = 10000
噪声= 1

x = np.random.normal（0，1，n）
y = x + np.random.normal（0，噪声，n）
 
  $ x $ 根据定义是正常的， $ y $ 应该基于两个高斯随机变量添加的方式。双变量正态分布似乎只是3个因素的产物：两个高斯和相关因素，我希望这是我的模拟数据的结果分布，所以我认为尝试一个高斯copula是有意义的。&gt; 
我对如何从这种副本中采样的理解是：首先，用x和y之间的协方差矩阵从标准的双变量正态分布中生成样品，作为参数：
 导入scipy.stats作为统计
导入数学

samples = stats.multivariate_normal.rvs（平均= [0，0]，
                                        cov = np.cov（x，y），
                                        尺寸= n）
 
以生成点的CDF使其均匀：
  uniform_samples = stats.norm.cdf（示例）
 
最后，通过应用逆CDF（python中的PPF）将统一样品转换回原始空间：
  ointer_samples = np.empty_like（uniform_samples）
onigral_samples [：，0] = stats.norm.ppf（uniform_samples [：，0]，
                                        比例= 1）
onigral_samples [：，1] = stats.norm.ppf（uniform_samples [：，1]，
                                        比例= Math.sqrt（2））
 
请注意，X值的PPF来自 $ \ Mathcal {n}（0,1）$ ，如果来自 $ \ mathcal {n} n}（0,2）$  $ x $ 和 $ Y $ 已定义。但是，当我这样做时，来自copula仿真的数据和直接模拟的数据似乎并不排队
  direct_fit_slope，direct_fit_intercept = np.polyfit（x，x，y，1）
x_fit = np.linspace（-5，5，10000）
direct_fit = direct_fit_slope*x_fit + direct_fit_intercept
copula_fit_slope，copula_fit_intercept = np.polyfit（oilter_samples [：，0]，
                                                    onigral_samples [：，1]，
                                                    1）
copula_fit = copula_fit_slope*x_fit + copula_fit_intercept

图，ax = plt.subplots（）
AX.Scatter（X，Y，Alpha = 0.03）
ax.Scatter（Original_samples [：，0]，Original_samples [：，1]，alpha = 0.03）
ax.Scatter（[]，[]，C =;＃1f77b4＆quot; label =;直接模拟＆quot; alpha = 0.3）
ax.scatter（[]，[]，c =;＃ff7f0e; label =; copula Simulation＆quot; alpha = 0.3）
ax.plot（x_fit，direct_fit，c =“＃1f77b4
ax.plot（x_fit，copula_fit，c =“＃ff7f0e”
ax.set_xlim（-5，5）
ax.set_ylim（-10，10）
ax.legend（）
 
    [246]：direct_fit_slope
OUT [246]：NP.Float64（0.9881371016103613）

在[247]中：copula_fit_slope
OUT [247]：NP.Float64（1.390232088699879）
 
我必须缺少一些东西。有人可以帮我了解发生了什么事吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/662652/why-is-my-copula-model-off</guid>
      <pubDate>Sat, 15 Mar 2025 06:04:40 GMT</pubDate>
    </item>
    <item>
      <title>将文本可读性指标与主观测量相关联</title>
      <link>https://stats.stackexchange.com/questions/662642/correlating-text-readability-metrics-against-subjective-measurements</link>
      <description><![CDATA[假设我想找出文本的不同可读性指标与文本复杂性的主观测量相关。我要求18个人阅读12条短文，我衡量他们认为每个文本的量表都有5个项目的范围（因此得分为5.0表示高复杂性）。我想尝试找出哪些度量与主观复杂性最有关系。
一种幼稚的方法是从所有参与者中获取每个文本的平均主观得分，并在应用于文本时发现哪种复杂性度量与结果的相关性最强。但是，我认为这将丢失很多信息。多级模型在这里是否合适？
评论：这个问题类似于
示例：
提供一些示例，一个指标可能将第一个文本的复杂性评为4，第二个文本为6等，而另一个指标将其自身尺度上的文本与10和12的相同文本进行评分。同时，一个参与者关于前两个文本的复杂性的主观得分分别为3和4（满分5）。来自不同量表的数字不是直接可比的。我们只想找出他们与参与者的主观分数有多相关。]]></description>
      <guid>https://stats.stackexchange.com/questions/662642/correlating-text-readability-metrics-against-subjective-measurements</guid>
      <pubDate>Fri, 14 Mar 2025 21:32:21 GMT</pubDate>
    </item>
    <item>
      <title>低坡/歧视问题：IRT的有用性？</title>
      <link>https://stats.stackexchange.com/questions/662618/low-slope-discrimination-questions-usefulness-in-irt</link>
      <description><![CDATA[在项目响应理论中，2-PL模型同时捕获了斜率和截距，而Rasch模型仅捕获截距，将曲线左/右移动（下面捕获）。。
   IRT的一般背景是推断问题难度和学生能力。尽管X轴范围为（-inf，inf），但可以将其转换为范围（0,1）。换句话说， $ x = 0 $ 捕获中位学生能力（或物品难度，因为它们在同一潜在空间中映射。）
通常，给定曲线的歧视力在其拐点处是最大的。关于上面的红色曲线，拐点位于 $ x = 0 $ ，这意味着，如果一个学生真正处于中间位置，则该问题将提供最大的信息，并随着给定的学生的能力增加或降低信息，从而提供了最大的信息。     。
上下文，我的问题很简单：陡峭的斜坡在实践中总是更喜欢？
假设地，如果给定的问题可以通过零差异返回学生的能力（知道学生在拐点以上或以下），则可以使用二进制搜索来找到学生在 $ o（\ log log（\ log log（n））$（\ log（n））$  $ time。
当然，这些问题不是确定性的，因此我们绝对可以确定学生没有超出他们的能力问题。但是，我认为，随着这些曲线的斜率接近无穷大（ $ \ lim：b \ to \ infty）$ 。
考虑到这一假设，较小的歧视性问题（较低的斜率）有用吗？在什么情况下？
我问了一个类似的问题在这里]]></description>
      <guid>https://stats.stackexchange.com/questions/662618/low-slope-discrimination-questions-usefulness-in-irt</guid>
      <pubDate>Fri, 14 Mar 2025 16:10:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么一些自变量有巨大的性病错误？</title>
      <link>https://stats.stackexchange.com/questions/662601/why-are-some-independent-variables-having-huge-std-errors</link>
      <description><![CDATA[我想知道我的结果是否正确。我不明白为什么四个独立变量有大的性病错误。
以下是GLM调用：
致电：
  glm（公式=练习〜ranban_zone + peri_urban_zone + rural_zone + 
        remote_rural_zone + num_female_age_10_30 + num_female_age_31_51 + 
        num_female_age_52_72 + num_female_age_73_90plus + num_male_age_10_30 + 
        num_male_age_31_51 + num_male_age_52_72 + num_male_age_age_73_90plus + 
        num_no_education + num_lower_primary + num_upper_primary + 
        num_junior_secondary + num_senior_secondary + num_tertiary + 
        num_employed + num_unemployed + num_pensioners + num_learners， 
        family =二项式，data = beanpurepractice）
 
和结果：
 系数：（3由于奇异性而未定义）
                               估计标准。错误z值pr（＆gt; | z |）  
    （截距）2.69299 2.60852 1.032 0.3019  
    Urban_Zoneyes -6.17754 2.53048 -2.441 0.0146 *
    peri_urban_zoneyes 16.33651 6566.01336 0.002 0.9980  
    rural_zoneyes -1.48510 2.13068 -0.697 0.4858  
    远程_rural_zoneyes na na na na na na na na na na na  
    num_female_age_10_30 -2.27482 2.41113 -0.943 0.3454  
    num_female_age_31_51 2.31677 2.66000 0.871 0.3838  
    num_female_age_52_72 2.62843 2.80616 0.937 0.3489  
    num_female_age_73_90plus 28.03286 5429.89633 0.005 0.9959  
    num_male_age_10_30 2.17702 2.20519 0.987 0.3235  
    num_male_age_31_51 -0.04994 3.15402 -0.016 0.9874  
    num_male_age_52_72 2.23831 3.76589 0.594 0.5523  
    num_male_age_73_90plus 21.97843 8491.96006 0.003 0.9979  
    num_no_education 0.61582 2.44018 0.252 0.8008  
    num_lower_primary 16.32515 5412.19502 0.003 0.9976  
    num_upper_primary -0.71340 2.14795 -0.332 0.7398  
    num_junior_secondary 0.42343 1.77102 0.239 0.8110  
    num_senior_secondary 1.00463 1.47758 0.680 0.4966  
    num_tertiary na na na na  
    num_employed 0.05111 2.88391 0.018 0.9859  
    num_unemployed 0.63221 2.06144 0.307 0.7591  
    num_pensioners -4.4.00465 3.29184 -1.217 0.2238  
    num_learners na na na na na na na na  
    ---
    象征。代码：0&#39;***’0.001&#39;**’0.01&#39;*’0.05&#39;。’0.1’’1
    
    （二项式家族的分散参数为1）
    
        空偏差：94.242在119自由度上
    剩余偏差：31.062 on 100自由度
    AIC：71.062
    
    Fisher评分迭代的数量：21
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662601/why-are-some-independent-variables-having-huge-std-errors</guid>
      <pubDate>Fri, 14 Mar 2025 08:30:56 GMT</pubDate>
    </item>
    <item>
      <title>如何计算样本量对假正率的影响？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/662600/how-to-calculate-effect-of-sample-size-on-false-positive-rate</link>
      <description><![CDATA[安慰剂对照研究（样本量为500）发现，新药将死亡率从10％降低到7％，而P = 0.04。
这种差异的理想样本量（保持80％的功率，α为0.05）为1353。
研究的批评者指出，较小的样本量增加了假正率，即使p值为0.04（假阳性率为4％）
这是真的吗？如果是这样，该研究如何计算确切的假阳性率？
编辑：这个问题与其他类似问题不同，因为我不仅询问是否存在关系，而且还要求可能的公式来定量估计效果。此外，这个问题不仅有一个投票，而且已经有了高质量的答案。因此，应该打开这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/662600/how-to-calculate-effect-of-sample-size-on-false-positive-rate</guid>
      <pubDate>Fri, 14 Mar 2025 08:28:31 GMT</pubDate>
    </item>
    <item>
      <title>回归的AIC低于具有中介模型的模型</title>
      <link>https://stats.stackexchange.com/questions/662516/aic-of-regression-is-lower-than-for-model-with-mediation</link>
      <description><![CDATA[  tl; dr ：我试图了解AIC在调解分析中的作用是什么，以及如何在不同模型之间进行选择 - 简单回归和包括中介的路径分析。这应该基于AIC吗？如果调解效果显着，但是中介模型的AIC比简单回归呢？ 
 详细信息：
 r代码和CSV文件可以找到在这里。。
我有以下回归：
  fit = lm（y〜x1 + x2 + x3 + x_ex，data = df）
摘要（fit）
 
所有预测变量都非常重要，但是总体 $ r^2 $ 相对较低（〜0.18）。
研究人员有兴趣知道 $ x_2 $ 和 $ x_3 $ 对 $ x_1 $ x_1 $  $    Mediate（）功能从中介 library 来检查这一点。
  med_model = mediate（fit_mediator，fit_direct，treat =; x1＆quot; x1＆quort&#39;sediator =; x2＆quort; x2＆quot; boot = true，sims = 5000）
摘要（Med_model）
 
表明，确实 $ x_2 $ 具有稍微调解效果（ACME：0.017，ADE：0.107，Prop 〜13.8％）。直接和间接效应都非常重要。对于 $ x_3 $ 数字或多或少相同，但间接效果是边界/不再重要的。
事实证明， $ x_2 $ 也对 $ x_3 $ 和 $ y $ y $ y $ y $  acme = -0.04，adde = -04，adde = -00。; P.Values）。
我决定还使用 SEM 从 lavaan 。尝试更复杂的结构。
  fit = sem（mediation_model，data = df）＃mediation_model是指定路径分析的字符串
摘要（fit，fit.measures = true，标准化= true）
 
为了理智检查，我在这里还重新运行调解分析，并得到相同的结果。
此外，我尝试了一些模型，其中包括两个型号 $ x_2，x_3 $ 作为 $ x_1 $ 和和 $ y $ y $ y $ y $   $ y $   和另一个结合了上述结论的模型（模型5）：
  但是，在比较不同模型的AIC或log样本时，我知道最好的模型是一个简单的回归。
这是AIC的摘要（全部取自 sem 输出）：
 


模型
 aic 




回归
 143 


 x2作为中介
 727 


 x3作为中介
 288 


 x2和x3作为介体
 842 


模型5 
 696 


 
我发现这有点令人困惑。如果我选择基于AIC的模型，我将进行常规回归。这是否意味着没有调解？此外，具有 $ x_3 $ 的模型具有比 $ x_2 $ 的模型更好的AIC，这与我之前进行的调解分析相矛盾。最后，根据中介效应（模型5）对我来说似乎最合乎逻辑的模型具有很高的AIC。这是否意味着这个模型不错的问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/662516/aic-of-regression-is-lower-than-for-model-with-mediation</guid>
      <pubDate>Wed, 12 Mar 2025 13:33:29 GMT</pubDate>
    </item>
    <item>
      <title>文献：效果大小的预测间隔</title>
      <link>https://stats.stackexchange.com/questions/662406/literature-prediction-intervals-for-effect-size</link>
      <description><![CDATA[ 简短版本：我有兴趣形成从给定尺寸的未来样本中得出的汇总数量的频繁预测间隔，主要集中于广义线性模型中各种效应大小的度量（例如，两组观察到的平均值之间的差异/比率/比率））。除线性模型外，文献是否有正常噪声的结果？
 详细信息＆amp;结果到目前为止： 
我在这个主题上发现的文献几乎是心理方法论文。这让我觉得我可能缺少一些描述统计文献中相同数量的关键字。
这是我到目前为止发现的： spence＆amp＆amp; Stanley 2024-回火期望：在复制的背景下计算和解释预测间隔的教程汇总方法以计算平均值，平均值和相关性的预测间隔，这在正常线性模型中均在正常线性模型中。从那里的参考链跟踪回到 Cumming，G。，G。，＆amp; Maillardet，R。（2006） - 置信区间和复制：下一个平均值将在哪里跌落？和“ noreferrer”&gt; estes（1997）。关于通过标准错误和置信区间的显示信息的通信。 都讨论了未来分布的未来样本平均值的预测间隔。
特别是在引文网络中的所有论文中，间隔均来自第一原理，并且没有与更广泛的理论的联系。
与此引用网络分开，统计间隔 bek by Meeker＆amp;在这种情况下，倾向于经常推荐Hahn，但它仅讨论未来样本的平均值的预测间隔，而仅讨论一些分布。我在引用文献中没有发现大量扩展（经过一点攻击性过滤）。
我是否缺少一些关键字，还是此时尚未真正开发有关此类型的预测间隔的文献？或在Meeker＆amp;中进行讨论的方法哈恩如此琐碎地扩展到更复杂的案例，以至于没有人打扰它们分别描述它们？
请注意，我需要合理的有限样本保证，因此在广义模型中使用正常线性模型的方法不起作用（例如，我已经看到在小样本负二项式模型中从正常近似值下降到85％的95％间隔的覆盖率）。）。）。）。）。
 编辑：我确实需要体面的频繁保证，因此，除非有证据表明他们在类似情况下提供此类保证，否则贝叶斯的方法将无法执行。频繁的行为不一定是确切的，但必须是好的（最差的1个百分点底部底漆可能还可以）。
本网站上的相关问题包括：

 预测间隔
 预测间隔？  
 ＆quort“&gt;＆quot”对于适合新数据的模型的斜率（我自己）
]]></description>
      <guid>https://stats.stackexchange.com/questions/662406/literature-prediction-intervals-for-effect-size</guid>
      <pubDate>Mon, 10 Mar 2025 11:45:29 GMT</pubDate>
    </item>
    </channel>
</rss>