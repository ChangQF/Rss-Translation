<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 24 May 2024 09:15:56 GMT</lastBuildDate>
    <item>
      <title>REML 解决方案与 BLUP 解决方案</title>
      <link>https://stats.stackexchange.com/questions/647874/reml-solutions-vs-blup-solutions</link>
      <description><![CDATA[当对随机效应的解决方案感兴趣时，常见的过程是使用 REML 来估计方差分量，然后使用 BLUP 来预测 RE。然而，REML 是一种迭代方法（例如期望最大化算法），这意味着随机 RE 的解是作为副产品获得的，它们也称为 BLUP。那么，为什么不使用 REML 最后一次迭代（收敛之前）的解决方案呢？如果输入（方差）来自 REML，为什么它们会与从 BLUP 程序获得的解不同？这是用于反转 MME 左侧的不同算法的问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647874/reml-solutions-vs-blup-solutions</guid>
      <pubDate>Fri, 24 May 2024 09:12:18 GMT</pubDate>
    </item>
    <item>
      <title>固定效应模型“内部”“个人”添加时间虚拟人</title>
      <link>https://stats.stackexchange.com/questions/647873/fixed-effects-model-within-individual-adding-time-dummies</link>
      <description><![CDATA[目前我正在撰写有关自然资源依赖对儿童健康影响的论文。
我有一个包含 2002 年至 2020 年 117 个国家/地区的不平衡面板数据集。我使用所提供问题下的代码。
当我进行双向固定效应模型时，控制时间和国家/地区固定效应，我的 R2 变得非常低 (0.115)。然而，在这个例子中，我感兴趣的自变量 (NRR3) 处于预测方向并且显着。然而，我的一些控制变量并未达到预期的方向。在这种情况下，我的稳健性检查之一（对于回答我的研究问题很重要）是完美的。
当我进行个人固定效应和国家固定效应时，每个变量都处于预期方向，但我的自变量不再显着。我的 R2 是 0.550。
我预计这些年来将会发生重大变化（因为例如可持续发展目标的首要任务是降低死亡率）。我在我的国家固定效应模型中包含了时间虚拟变量，我的 r2 现在为 0.8，但它给出了与双向模型完全相同的系数和标准误差。我试图理解这一点，并试图找到实证文献来证实这种思维方式，但不幸的是我暂时找不到。
与双向固定效应模型相比，在国家固定效应模型中包含时间虚拟变量有何作用？这是可以通过实证文献证实的吗？
还有一个小问题：在进行固定效应模型后，我发现我的数据中仍然存在异方差和自相关，我现在正在做 HAC 标准错误，这是一件好事吗？我还需要对我的标准错误进行聚类吗？下面提供了代码。
包括两个滞后
###固定效应模型：主要分析
FEMA2 &lt;- plm(公式 = MU52 ~ NRR3_lag2 + MVAA3 + REER2 + CEPI3 + GE2 + COC2 + EYS + PM2.52 + TE2 + CHE2, 数据 = MD2, 索引 = c(“州”, “年份”) ，模型=“内部”，效果=“个体”）
观星者（FEMA2，类型=“文本”）
#HAC 标准错误 (FE)
vcov_hac_FEMA2 &lt;- vcovSCC(FEMA2, type = &quot;HC1&quot;, maxlag =7)
stargazer(FEMA2, type = “text”, se = list(sqrt(diag(vcov_hac_FEMA2))), title = “带有 HAC 标准误差的主要分析 (FE)（2 滞后）”,align = TRUE)]]></description>
      <guid>https://stats.stackexchange.com/questions/647873/fixed-effects-model-within-individual-adding-time-dummies</guid>
      <pubDate>Fri, 24 May 2024 07:53:43 GMT</pubDate>
    </item>
    <item>
      <title>线性判别分析降维中类内协方差的含义</title>
      <link>https://stats.stackexchange.com/questions/647871/meaning-of-within-class-covariance-in-linear-discriminant-analysis-dimensionalit</link>
      <description><![CDATA[在 Hastie、Tibshirani 和 Friedman 的统计学习的要素的第 4.3.3 节中，作者列出了减少输入矩阵维度的过程  $\mathbf{X}$，首先使用线性判别分析，然后使用主成分分析：

计算类质心的 $K\times p$ 矩阵 $\mathbf{M}$和公共协方差矩阵 $\mathbf{W}$ （类内协方差）；
使用谱分解计算 $\mathbf{M}^* = \mathbf{MW}^{-\frac{1}{2}}$ $\mathbf{W}$;
计算 $\mathbf{B}^*$，即 $\mathbf{M}^* 的协方差矩阵$ 及其谱分解 $\mathbf{B}^* = \mathbf{V}^*\mathbf{D}_B{\mathbf{V}^*} ^T$。

这给出了第 l 个判别变量 $Z_l = v_l^TX$ 以及相应的判别方向 $v_l=\mathbf{W}^{-\frac{1}{2}}v_l^*$。
我对该过程的理解是 $\mathbf{X}$ 首先投影到质心创建的子空间上（这不会影响 LDA 结果），对子空间进行主成分分析，进一步缩小其维度。我对我的理解如何与上面的矩阵运算保持一致感到困惑，特别是 $\mathbf{W}$ 的效果。]]></description>
      <guid>https://stats.stackexchange.com/questions/647871/meaning-of-within-class-covariance-in-linear-discriminant-analysis-dimensionalit</guid>
      <pubDate>Fri, 24 May 2024 06:58:28 GMT</pubDate>
    </item>
    <item>
      <title>通过除以AB测试结果来解释</title>
      <link>https://stats.stackexchange.com/questions/647869/interpreting-by-dividing-up-results-of-ab-test</link>
      <description><![CDATA[在我的公司，我们正在对我们的游戏功能（移动应用、超休闲游戏、全球规模）进行 AB 测试（置信度为 95%）。
测试完成后，我们的做法是将全球指标划分为国家/地区指标，以查看其是否具有统计显着性。如果重要，我们就会为这些国家/地区推出该功能，如果不重要，我们就不推出。
我不禁觉得这违反了某些统计规则。似乎我们正在挑选任何看起来不错的结果来认为它们是好的。
你们觉得怎么样，这是一个很好的测试实践吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647869/interpreting-by-dividing-up-results-of-ab-test</guid>
      <pubDate>Fri, 24 May 2024 05:24:49 GMT</pubDate>
    </item>
    <item>
      <title>对 $X\sim N(\mu, 2)$ 进行假设检验，如果我们知道 $X>2$ 会怎样？这会如何改变事情？</title>
      <link>https://stats.stackexchange.com/questions/647868/hypothesis-test-on-x-sim-n-mu-2-what-if-we-had-knowledge-that-x2-how-w</link>
      <description><![CDATA[我对 $X\sim N(\mu, 2)$ 的假设检验感兴趣，其中 $ H_0：\mu=1$。那么 p 值将如下所示：
$$
\text{p 值 = }2\cdot P(X&gt;|x|)
$$
现在，如果我们知道 $X&gt;2$ 会怎样？这会改变什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647868/hypothesis-test-on-x-sim-n-mu-2-what-if-we-had-knowledge-that-x2-how-w</guid>
      <pubDate>Fri, 24 May 2024 05:10:11 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 III 型方差分析输出中的 F 值格式不同？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647866/why-is-the-format-of-the-f-values-in-my-type-iii-anova-output-different</link>
      <description><![CDATA[我正在使用以下代码使用 III 型方差分析来研究因素 A、B 和 C 如何相互作用来影响连续变量 X 的持续时间：
type3.X &lt;- list(A = contr.sum, B = contr.sum, C = contr.sum)
modelA&lt;-lm(X~A*B*C, 数据 = X.data, 对比 = type3.X)
摘要（模型A）
图书馆（车）
方差分析（模型 A，类型 = 3）

称呼：
lm(公式 = X ~ A * B * C, 数据 = X.data, 
    对比 = type3.X)

残差：
     最小 1Q 中值 3Q 最大 
-0.47811 -0.06984 0.00492 0.06959 0.77616 

系数：
                            估计标准。误差t值Pr(&gt;|t|)    
(截距)2.410488 0.006446 373.959＜ 2e-16 ***
A1 0.121081 0.013185 9.183＜ 2e-16 ***
A2 0.106227 0.012806 8.295 1.80e-15 ***
A3 -0.006331 0.011020 -0.575 0.5660    
A4 -0.079784 0.010525 -7.580 2.55e-13 ***
B1 -0.370909 0.006446 -57.542＜ 2e-16 ***
C1 0.026642 0.006446 4.133 4.38e-05 ***
A1:B1 0.032538 0.013185 2.468 0.0140 *  
A2:B1 -0.027068 0.012806 -2.114 0.0352 *  
A3:B1 -0.003961 0.011020 -0.359 0.7194    
A4:B1 0.006678 0.010525 0.634 0.5262    
A1:C1 -0.026770 0.013185 -2.030 0.0430 *  
A2:C1 0.014719 0.012806 1.149 0.2511    
A3:C1 0.010877 0.011020 0.987 0.3242    
A4:C1 -0.005515 0.010525 -0.524 0.6006    
B1:C1 0.002496 0.006446 0.387 0.6988    
A1:B1:C1 -0.007837 0.013185 -0.594 0.5526    
A2:B1:C1 0.017249 0.012806 1.347 0.1788    
A3:B1:C1 -0.009595 0.011020 -0.871 0.3844    
A4:B1:C1 -0.011190 0.010525 -1.063 0.2883    
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

剩余标准误差：389 自由度上为 0.1123
多重 R 平方：0.9154，调整 R 平方：0.9112 
F 统计量：19 和 389 DF 上为 221.4，p 值：＜0 2.2e-16

方差分析的输出如下。
Anova 表（III 类测试）

回应：X
                         Sum Sq Df F 值 Pr(&gt;F)    
(截距) 1762.22 1 1.3985e+05 &lt; 2.2e-16***
A 2.92 4 5.7918e+01＜ 2.2e-16***
B 41.72 1 3.3111e+03＜ 2.2e-16***
C 0.22 1 1.7083e+01 4.385e-05 ***
A:B 0.11 4 2.2662e+00 0.06151 。  
答：C 0.07 4 1.3965e+00 0.23445    
B：C 0.00 1 1.4990e-01 0.69882    
A：B：C 0.05 4 8.9700e-01 0.46571    
残差 4.90 389                         
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

我想知道是否有人能告诉我为什么 R 会将 F 值采用 1.3985xe+05 格式而不是仅使用完整数字，以及是否有任何方法可以将它们转换为完整数字，以便我可以精确到小数点后两位。]]></description>
      <guid>https://stats.stackexchange.com/questions/647866/why-is-the-format-of-the-f-values-in-my-type-iii-anova-output-different</guid>
      <pubDate>Fri, 24 May 2024 04:16:32 GMT</pubDate>
    </item>
    <item>
      <title>残差的图形分析</title>
      <link>https://stats.stackexchange.com/questions/647864/graphical-analysis-of-residuals</link>
      <description><![CDATA[在一次电实验中，我收集了电容器充电和放电的数据。使用数据和 scipy.curve_fit，我已经拟合了理论模型。现在，我需要验证回归。使用残差图形，我有以下图形。我的问题是，这个残差图形应该是这样的吗？而且，我还可以使用什么其他方法来验证回归？ $R^2 $ 系数应该有效吗？
[
这是理论模型
$V = V_0(1-e^{-t/RC)} \\
V = V_0e^{-t/RC}$]]></description>
      <guid>https://stats.stackexchange.com/questions/647864/graphical-analysis-of-residuals</guid>
      <pubDate>Fri, 24 May 2024 03:47:33 GMT</pubDate>
    </item>
    <item>
      <title>具有数百万个协变量/特征的高维回归</title>
      <link>https://stats.stackexchange.com/questions/647862/high-dimensional-regression-with-millions-of-covariates-features</link>
      <description><![CDATA[首先，我是一名机器学习研究员。我很感兴趣这个社区是否可以向我介绍一些研究和工作，以显示协变量数量大于 100 万的情况下执行回归的设置？
我熟悉 LASSO、Ridge，甚至高维回归中的其他求解器。但是，我还没有看到/遇到任何论文证明求解器在数百万个特征级别上的有效性。
更具体地说，我的意思是：$$Y = X\theta$$，其中$ X \in \mathbb{R}^{n\times p}$ 是一个包含 $n$ 个样本和 $p$ 功能。我正在询问 $p\ge 1,000,000$ 案例的求解器。另外，假设 $p\ge n$，因此这是未确定的情况。
如果您有这方面的经验，请随时分享适用的论文和代码的参考。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/647862/high-dimensional-regression-with-millions-of-covariates-features</guid>
      <pubDate>Fri, 24 May 2024 03:28:21 GMT</pubDate>
    </item>
    <item>
      <title>（需要建议）通过多级模型预测美国龙卷风数量</title>
      <link>https://stats.stackexchange.com/questions/647861/advice-desired-predicting-us-tornado-counts-via-multi-level-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647861/advice-desired-predicting-us-tornado-counts-via-multi-level-model</guid>
      <pubDate>Fri, 24 May 2024 03:07:14 GMT</pubDate>
    </item>
    <item>
      <title>不同版本的添加剂切尔诺夫</title>
      <link>https://stats.stackexchange.com/questions/647860/different-versions-of-additive-chernoff</link>
      <description><![CDATA[加法切尔诺夫界限表示 $X_i \in \{0,1\}$ 满足 $\mathbb {E}[X_i] = p,$
$$
\mathbb P\left(\sum\limits_{i}^nX_i \geq np+n\epsilon \right) \leq \exp\left(-\frac{(n\epsilon)^2}{2(np+\frac) {n\epsilon}{3})}\right) .$$
这个不平等是我的老师给出的。
我不明白切尔诺夫是什么样的添加剂？我在维基百科上没有看到任何地方。
我只知道这个，
附加版本说
$$
\mathbb P\left(\sum\limits_{i}^nX_i \geq np+n\epsilon \right) \leq e^{-2n\epsilon^2} 。
$$
任何人都可以帮助我如何获取我的顾问 chernoff 版本。]]></description>
      <guid>https://stats.stackexchange.com/questions/647860/different-versions-of-additive-chernoff</guid>
      <pubDate>Fri, 24 May 2024 02:43:58 GMT</pubDate>
    </item>
    <item>
      <title>方差分析替代方案</title>
      <link>https://stats.stackexchange.com/questions/647838/anova-alternatives</link>
      <description><![CDATA[想象一下以下研究：

目标：测试治疗是否可以增强认知功能。
分组：干预组 29 名受试者，对照组 20 名受试者。
测试：在 3 分钟内回答尽可能多的问题，在治疗前和治疗后进行测试。
指标：正确回答问题的比例。

假设：

每个问题的难度相同（无论这意味着什么）。
每个主题都会回答不同的问题。
受试者在预习和预习中可能会回答不同的问题总数
测试后。
每个主题大量已回答的问题。
正确答案的比例范围为 0.7 到 1.0。
比例和残差的分布不正常（大部分向右倾斜，请参见下面的 QQ 图和直方图）。

我的担忧：
由于残差的非正态分布，传统的方差分析并不适用。
对我来说，每个主题回答的问题总数的变化也增加了复杂性。
问题：
我应该使用什么统计程序来确定干预措施是否显着提高了正确回答问题的平均比例？
任何想法或指示将不胜感激！
编辑：
以下是显示非正态性的残差 QQ 图：

正确回答问题的比例分布：
]]></description>
      <guid>https://stats.stackexchange.com/questions/647838/anova-alternatives</guid>
      <pubDate>Thu, 23 May 2024 16:18:26 GMT</pubDate>
    </item>
    <item>
      <title>用于对两个同心圆对应的数据点进行分类的非线性内核[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647830/non-linear-kernel-for-classifying-data-points-corresponding-to-two-concentric-ci</link>
      <description><![CDATA[在自学时看过关于非线性可分离问题的文章，这里&lt; /a&gt;.给出的图像位于此处和此处。 sstatic.net/f5tu2tO6.jpg&quot; rel=&quot;nofollow noreferrer&quot;&gt;此处。
它解决了一个常见的教科书问题，其中数据点位于两个不相交的同心圆组中。
给出的方法是将核函数设置为：$φ(x) = φ((x_1, x_2)) = (x_1^2, √2 x_1x_2, x_2^ 2).$
但是，如果举个例子，内圆的 radius 直径为 $2$ 单位，而外圆的  radius $4$ 单位的直径；然后让我们在内圆上有两个点： $(2,2), (2,4)$;分别用 $x_{i1}$ 和 $x_{i2}$ 表示。
同样，让外圆上有两个数据点： $x_{o1}= (2,1),$ 和 $x_{o2}=(2,5).$
核函数的应用，似乎并没有用线性SVC将两个同心圆上的点分开，如新坐标所示，以及Norms，如下所示：

$φ(x_{o1})=(2,1) = (4, 2\sqrt{2}, 1),$ 范数 $||φ(x_{o1})||=16+1+8 = 25,$
$φ(x_{i1})=(2,2) = (4, 4\sqrt{2}, 4),$ 范数 $||φ(x_{i1})||=64,$
$φ(x_{i2})=(2,4) = (4, 8\sqrt{2}, 16),$ 范数 $||φ(x_{i2})||=16+256+128 = 400,$
$φ(x_{o2})=(2,5) = (4, 10\sqrt{2}, 25),$ 范数 $||φ(x_{o2})||=481.$

目前尚不清楚给定的核函数如何将这些点转换/映射为两个线性可分离的类。]]></description>
      <guid>https://stats.stackexchange.com/questions/647830/non-linear-kernel-for-classifying-data-points-corresponding-to-two-concentric-ci</guid>
      <pubDate>Thu, 23 May 2024 14:50:12 GMT</pubDate>
    </item>
    <item>
      <title>残差与 AIC 和“最佳”拟合的正态性</title>
      <link>https://stats.stackexchange.com/questions/647805/normality-of-residuals-versus-aic-and-best-fit</link>
      <description><![CDATA[希望深入了解残差的正态性与“最佳”残差的正态性。模型的拟合度。
运行简单的线性回归并检查残差的正态性后，我记录了结果变量，这显着提高了残差的正态性。见下文：

使用geom_smooth()绘图后，我注意到也许这种关系不是线性的，而是二阶多项式的。

我将模型与 AIC 进行了比较，认为 poly^2 更适合。
&lt;前&gt;&lt;代码&gt; df AIC
PT~3岁496.7536
PT~聚(年龄,2) 4 490.3009

我的问题出现在检查二阶多项式模型的残差时。我可以看到，与简单的线性回归相比，它们不是正态分布的。

我的问题是，这里什么更重要？我应该使用简单线性回归还是二阶多项式（视觉上看起来更适合我的数据）？我还应该补充一点，在生理层面上，这对于从 50 左右开始的拐点确实有意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/647805/normality-of-residuals-versus-aic-and-best-fit</guid>
      <pubDate>Thu, 23 May 2024 03:28:01 GMT</pubDate>
    </item>
    <item>
      <title>在生存分析中我应该取时间对数吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647802/shall-i-take-the-logarithm-of-time-in-survival-analysis</link>
      <description><![CDATA[我有生存数据。作为响应变量的时间是整数，以从成年（18岁）到第一次结婚的年数来衡量，例如1,2,3,....当使用生存分析时，例如随机生存森林，我应该取对数吗时间？]]></description>
      <guid>https://stats.stackexchange.com/questions/647802/shall-i-take-the-logarithm-of-time-in-survival-analysis</guid>
      <pubDate>Thu, 23 May 2024 02:08:44 GMT</pubDate>
    </item>
    <item>
      <title>Cox 模型 - 不确定分析的时间单位</title>
      <link>https://stats.stackexchange.com/questions/647753/cox-model-unsure-of-time-unit-of-analysis</link>
      <description><![CDATA[我正在对癌症患者的事件发生时间进行生存分析（Cox 模型）。随访的开始时间是治疗的结束时间。从癌症诊断开始，每 6 个月进行一次事件（复发）测试，每个患者都知道这些测试的确切日期（日、月、年）。我不确定 Cox 模型所需的分析单位和计算事件发生时间变量。因为我们知道随访的开始日期和测试日期，所以我们可以以天为单位计算事件发生时间变量。但是，我认为这不是正确的方法，因为这肯定意味着在随访期间每天都进行测试，而不是像我们一样每 6 个月进行一次。如果在测试日期检测到事件，我们所知道的只是该事件发生在前一个（无事件）和当前（检测到事件）测试日期之间的某个时间。考虑到这一点，在这种情况下，先以天为单位计算事件发生时间变量，然后将其分成每个长度为 6 个月的间隔是否有意义？分析单位将是半年，因此对危险的解释将是例如每半年每个处于危险中的人发生 X 次事件？]]></description>
      <guid>https://stats.stackexchange.com/questions/647753/cox-model-unsure-of-time-unit-of-analysis</guid>
      <pubDate>Wed, 22 May 2024 12:28:53 GMT</pubDate>
    </item>
    </channel>
</rss>