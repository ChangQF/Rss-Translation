<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 12 Oct 2024 03:19:47 GMT</lastBuildDate>
    <item>
      <title>报告缺失数据的分类器准确率</title>
      <link>https://stats.stackexchange.com/questions/655674/report-classifier-accuracy-with-missing-data</link>
      <description><![CDATA[假设我们正在读取血压。有些读数已损坏且无法使用。然后我们训练二元分类器来检测高血压。当我们的模型无法使用某些数据时，实验设计理论对报告分类器准确性有何看法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655674/report-classifier-accuracy-with-missing-data</guid>
      <pubDate>Sat, 12 Oct 2024 00:40:54 GMT</pubDate>
    </item>
    <item>
      <title>从系统中删除无关值以确定概率</title>
      <link>https://stats.stackexchange.com/questions/655673/removing-extraneous-values-from-system-to-determine-probability</link>
      <description><![CDATA[我试图确定以下系统实例的发生概率，该系统有利于总和 &gt;= 106.6 和 =&lt; 117：
106.6 =&lt; 4.1x + 4.7y + 5.6z + 6.6t =&lt; 117 &amp;&amp; x + y + z + t == 26, {x,y,z,t} ∈ ℕ
但是，产生的组合数大大超过有助于确定概率的实际计数。例如，任何组合中 6.6 从初始位置连续出现 18 次，系统都不可能产生结果 =&lt; 117。然而，仍有 4^8 个子代组合。我可以通过什么方式确定系统内所有此类子代组合的数量？我怎样才能将这些后代从不利组合池中移除？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655673/removing-extraneous-values-from-system-to-determine-probability</guid>
      <pubDate>Fri, 11 Oct 2024 23:45:24 GMT</pubDate>
    </item>
    <item>
      <title>需要进行多少次测试（以及必须通过多少次）才能保证我的软件在 90% 的时间内以 95% 的置信度正常运行？</title>
      <link>https://stats.stackexchange.com/questions/655671/how-many-test-executions-are-required-and-how-many-must-pass-to-say-my-softwar</link>
      <description><![CDATA[我有一些软件，其运行方式不确定。根据未知的外部因素，对代码运行测试可能会导致测试通过或失败。假设由于这些因素，测试通过或失败的几率相等，我必须运行测试多少次，软件必须通过测试多少次，这样我才能有 95% 的信心说软件在 90% 的时间内按预期运行？
编辑：假设外部因素导致测试失败的几率未知，而不是测试通过/失败相等。]]></description>
      <guid>https://stats.stackexchange.com/questions/655671/how-many-test-executions-are-required-and-how-many-must-pass-to-say-my-softwar</guid>
      <pubDate>Fri, 11 Oct 2024 22:37:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么当使用 IV 独立变量并且包括区域固定效应时，系数会失去显著性？</title>
      <link>https://stats.stackexchange.com/questions/655667/why-does-the-coefficient-lose-significance-when-using-iv-independent-variable-an</link>
      <description><![CDATA[我正在尝试研究 2018 年洪水冲击对男性和女性劳动力参与的影响。然而，洪水不仅可以归因于强降雨，还可以归因于其他因素，例如水库的蓄水能力差、水坝闸门打开。所以，洪水并非完全是外生的。因此，我首先使用地区固定效应和年份固定效应对 99 百分位季风降雨量（针对 1989-2018 年的每个季风月份计算）对洪水损害评分进行回归（使用 PCA 为每个地区构建损害指数，使用地区损害信息，例如受影响的农作物面积、受影响的养鱼场、人员伤亡等）。接下来，我使用此回归的预测值作为洪水冲击对劳动力参与回归的主要自变量。但是，当我采用地区固定效应时，系数在统计上变得不显著。在没有地区固定效应的情况下，它仍然具有统计显著性。有人能告诉我为什么会这样吗？我该如何解决这个问题？
注意：第一次回归基于 1989-2018 年期间每个地区的每日降雨量数据，这是一种面板数据，但在第二次回归中，个人和家庭层面的数据是重复的横截面，在 2017-2019 年期间每年四个季度都有。]]></description>
      <guid>https://stats.stackexchange.com/questions/655667/why-does-the-coefficient-lose-significance-when-using-iv-independent-variable-an</guid>
      <pubDate>Fri, 11 Oct 2024 19:52:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 GLM 或 GLMM 来衡量多样性指标</title>
      <link>https://stats.stackexchange.com/questions/655665/using-glms-or-glmms-for-diversity-metrics</link>
      <description><![CDATA[我希望有人能帮我解答一个有关统计分析的问题。我正在查看物种计数数据，其中在重复地点进行了多年的采样。例如，每年在六个不同的地点进行采样。这些年份被分为一个温度组，有两个因素：温暖或寒冷。我只对探索不同温度组和不同年份之间的社区差异感兴趣。我使用 vegan 包来计算多样性指标（丰度、丰富度、多样性指数），并希望统计检查指标之间的差异。
我一直在使用带有负二项分布的 mvabund 包，但我想知道现在是否应该将重复的站点添加为随机效应，它实际上是一个混合模型。在这种情况下，glmmTMB 或 lme4 是否更合适？我不太熟悉在 R 中使用混合模型，因此非常感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655665/using-glms-or-glmms-for-diversity-metrics</guid>
      <pubDate>Fri, 11 Oct 2024 19:40:20 GMT</pubDate>
    </item>
    <item>
      <title>我不确定我是否完全理解了维基百科中关于基因测试结果贝叶斯分析的例子</title>
      <link>https://stats.stackexchange.com/questions/655664/im-not-sure-i-fully-understand-wikipedias-example-of-bayesian-analysis-of-gene</link>
      <description><![CDATA[因此，我目前正在阅读有关贝叶斯定理1的维基百科文章，并对“遗传学中的应用：使用基因测试结果”部分中的陈述感到困惑。

以下是该部分的概述：

本节使用贝叶斯分析作为示例，分析了一名有囊性纤维化 (CF，一种罕见的常染色体隐性遗传病) 家族史但检测结果为阴性的女性患者，以说明如何使用此方法确定患者生育患有 CF 的孩子的风险。
由于我们在这种情况下知道患者未受到影响，这意味着她要么不携带 CF（对 W 等位基因是杂合的），要么至少携带它（有一个M等位基因）。由于父母双方可能都是 CF 携带者，我们可以将 Punnett 方格画为$$\begin{array}{c|c|c}&amp;W&amp;M\\\hline W&amp;WW&amp;WM\\\hline M&amp;WM&amp;MM\end{array}$$，因此，我们有 3 种情况患者不会受到 CF 的影响，其中 2 种情况患者携带突变等位基因，因此给出的先验概率分别为 2/3 和 1/3。
然后，假设 CF 测试的检测率为 90%，我们得到阴性测试的条件概率为 0.1 和 1。因此，我们可以计算 H1：患者携带 CF 和 H2：的后验概率患者不携带 CF 的概率分别为 1/6 和 5/6。
虽然所有这些对我来说都很有道理，但我对最后一段中的内容感到困惑：

在对患者的男性伴侣（检测结果为阴性）进行相同分析后，他们的孩子受到影响的几率等于父母各自作为携带者的后验概率乘以两个携带者产生受影响后代的几率（¼）。

我的问题是：

这是否意味着男性伴侣可能是 CF 携带者（但不受其影响），因此生下患有 CF 的孩子的几率是 1/144？鉴于该测试的检测率为 90%，我们是否也应该考虑男性伴侣实际上受 CF 影响的可能性（假设测试结果为阴性）？（因此，孩子受 CF 影响的实际几率为 1/144+1/24=7/144≈4.86%）
]]></description>
      <guid>https://stats.stackexchange.com/questions/655664/im-not-sure-i-fully-understand-wikipedias-example-of-bayesian-analysis-of-gene</guid>
      <pubDate>Fri, 11 Oct 2024 19:02:20 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 到 pytorch 权重转移[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655658/tensorflow-to-pytorch-weights-transfer</link>
      <description><![CDATA[我正尝试在 pytorch 中模拟一个经过修改的 efficientnet TF 模型。我在 pytorch 中对模型进行了架构更改，转储了 TF 模型权重，然后将其重新加载到新的 pytorch 模型中。使用以下代码在 TF 中转储权重：
model = tf.saved_model.load(model_path)
ws = []
for i in range(len(model.variables)):
ws.append((i, model.variables[i].name, model.variables[i].numpy()))

with open(&quot;manually_dumped_contentnet_weights.pkl&quot;, &quot;wb&quot;) as ofile:
pickle.dump(ws, ofile)

pytorch 中的权重形状似乎与架构和导入的权重相匹配（在 conv2d 和深度 conv2d 之间进行转换之后）。我可以毫无错误地运行模型。但输出结果与 TF 模型的输出结果大不相同。
我注意到在 TF 代码中，模型不是直接加载的，而是在 tf Session 中加载的：
with Session(graph=Graph(), config=ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:
saved_model.loader.load(sess, [saved_model.tag_constants.SERVING], model_path)
patch_feature, patch_label = sess.run(output_nodes,feed_dict={input_node: patch})

现在我想知道我最初转储模型权重的尝试是否不正确。或者如果我遗漏了其他内容。
我在加载数据时进行的转置是 conv2d 的 (3,2,0,1) 和深度 conv2d 的 (2,3,0,1)：
def reload_conv2d(layer, weights):
### weights 是一个元组，其中每个元素都由一个三元组组成：(1) 索引号，(2) TF 中权重转储的层的名称，以及 (3) 权重
count = 0
if (
&quot;/conv2d/kernel&quot; not in weights[0][1]
and &quot;/conv2d_1/kernel&quot; not in weights[0][1]
and &quot;depthwise_conv2d/depthwise_kernel&quot; not in weights[0][1]
and &quot;final_conv2d/final_conv2d&quot; 不在 weights[0][1] 中 :
raise ValueError(
f&quot;需要在第一个索引上有 conv2d/kernel，但得到了 {weights[0][1]}&quot;
)
transpose_shape = (2,3,0,1) if &quot;depthwise&quot;在 weights[0][1] 中否则（3、2、0、1）
transposed_weights = torch.from_numpy（weights[0][2].transpose（transpose_shape[0]、transpose_shape[1]、transpose_shape[2]、transpose_shape[3]））
layer.weight.data = transposed_weights
count += 1
如果 layer.bias 不是 None 或 layer.bias:
如果（
&quot;/conv2d/bias&quot; 不在 weights[1][1] 中
并且 &quot;/conv2d_1/bias&quot; 不在 weights[1][1] 中
）：
引发 ValueError（
f&quot;需要在第二个索引上有 conv2d/bias 但得到了 {weights[1][1]}&quot;
)
layer.bias.data = (
torch.from_numpy(weights[1][2])
如果type(weights[1][2]) == np.ndarray
else torch.from_numpy(weights[1][2])
)
count += 1
return layer, count

为什么 pytorch 和 TF 模型对相同输入给出完全不同的结果？是因为权重倾倒，还是权重加载……或者是模型架构变化？输入 TF 权重（在模型更改和转置之后）加载正常，我可以毫无问题地运行模型，但这对于调试它没有任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655658/tensorflow-to-pytorch-weights-transfer</guid>
      <pubDate>Fri, 11 Oct 2024 16:26:04 GMT</pubDate>
    </item>
    <item>
      <title>时间依赖性协变量和结果乐观性</title>
      <link>https://stats.stackexchange.com/questions/655656/time-dependent-covariates-and-optimism-of-results</link>
      <description><![CDATA[我有一个涵盖 2019-2023 年的数据集，以及一组按年份和邮政编码连接的分类协变量。为了进行验证，2023 年被排除在外，该年的协变量是前几年的平均值。基于随机分割的交叉验证期间的模型显示出极大的乐观性。当对测试数据进行评估时，甚至没有接近。我建议对用于训练模型的协变量使用估计值，而不是原始值。
有人可以指出我关于这个主题的文献吗？它是时空的，但涉及对新时间段的估计。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/655656/time-dependent-covariates-and-optimism-of-results</guid>
      <pubDate>Fri, 11 Oct 2024 15:58:48 GMT</pubDate>
    </item>
    <item>
      <title>在使用 ARMA 过程拟合 GAMM 时如何优化资源使用？</title>
      <link>https://stats.stackexchange.com/questions/655648/how-to-optimise-resource-use-when-fitting-a-gamm-with-arma-process</link>
      <description><![CDATA[我正在根据一系列时间预测因素（例如一年中的时间、昼夜循环、潮汐……类似于这篇文章）对每小时物种的出现情况（存在/不存在）进行建模。我使用收集自约 100 个人的数据，有 266,000 个数据点。我目前正在尝试按照以下结构拟合 GAMM 模型*：
ResGAM8 = gamm(data = Datanal, HL ~ s(Day) + s(Temperature) + s(ref, bs = &quot;re&quot;) + ti(Day, Temperature, SI), family = binomial, method = &quot;fREML&quot;, correlation = corARMA(form = ~1 | ref,p=1))

在之前的版本中，我使用 bam( ... rho = ) 来解释时间自相关，但是，ACF 和 pACF 仍然表明残差中存在一些自相关。因此，我决定在每个个体中嵌套一个 ARMA，以更好地解释时间自相关以及解释变量之间的相关性。 
我尝试在免费版 google colab 上运行此模型几次（大约 1 分钟后总是出现错误，表明会话已崩溃，因为它已达到分配的 RAM 限制）并在我自己的计算机上（没有 colab 快）运行了大约 2 个小时，没有任何显著的结果。

我的问题很简单（表述）：我如何优化这个过程以减少资源消耗（并避免上述问题）？

减少观察和/或个体的数量是可能的，但实际上是作为最后的手段，因为包括的动物数量是这项工作的原因之一。

*为了清楚起见，我删除了简单平滑中包含的一些解释变量]]></description>
      <guid>https://stats.stackexchange.com/questions/655648/how-to-optimise-resource-use-when-fitting-a-gamm-with-arma-process</guid>
      <pubDate>Fri, 11 Oct 2024 12:48:58 GMT</pubDate>
    </item>
    <item>
      <title>估计概率值大于来自未知分布的 x</title>
      <link>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</link>
      <description><![CDATA[假设我们有 N 个项目的总体，其值从 0 到 6000。
假设总体的平均值是 $\mu$。
我们不知道项目的分布。
我们从这个总体中提取一个项目，我们如何估计 $P(x\geq 2500)$？
同样的问题，假设分布是均匀的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655642/estimate-probability-value-is-greater-than-x-from-an-unknown-distribution</guid>
      <pubDate>Fri, 11 Oct 2024 08:52:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么 $H(Y|X) \le H(Y)$</title>
      <link>https://stats.stackexchange.com/questions/655621/why-hyx-le-hy</link>
      <description><![CDATA[假设我们有 100 张牌，其中 98 张两面都是白色，一张两面都是黑色，最后一张一面是白色，另一面是黑色。
如果我问“我看到的是哪一面”，我们有 $p(F) \sim Be(0.985)$，因为我们有 3 张黑面和 197 张白面。因此，$H(F) \approx 0.0808$
现在，假设我知道另一面是黑色。然后 $p(F|F&#39;=black) \sim Be(0.5)$, $H(F|F&#39;=black) = 1$
因此，在我看来，额外的信息似乎增加了熵，但信息论明确指出 $H(Y|X) \le H(Y)$，因此知道另一面的颜色不应该让我更加不确定
因此，我的结论是，我严重误解/遗漏了一些东西，有什么想法吗？我应该考虑平均条件熵而不是特定情况吗？...]]></description>
      <guid>https://stats.stackexchange.com/questions/655621/why-hyx-le-hy</guid>
      <pubDate>Thu, 10 Oct 2024 21:04:25 GMT</pubDate>
    </item>
    <item>
      <title>事件发生后定义治疗的差异-差异法</title>
      <link>https://stats.stackexchange.com/questions/655620/difference-in-difference-with-treatment-defined-after-event</link>
      <description><![CDATA[我正在写一篇使用差异-差异设计方法的科学论文，但这不是标准的 DID 设置。
考虑一下我们在多个时间段收集多个公司观察结果的情况。在 $t=0$ 时发生一个事件。到目前为止，一切都很基本。现在偏离标准设置：不知道哪些公司属于治疗组和对照组，治疗组被定义为那些可观察特征 $x$ 从事件前到事件后从 $0$ 变为 $1$ 的公司。控制公司是那些特征 $x$ 保持在 $0$ 的公司。
这是 DID 设计的常见/已知版本吗？如果是，如果您能给我提供一些文献，我会很高兴，因为我还没有找到任何接近这个的文献。]]></description>
      <guid>https://stats.stackexchange.com/questions/655620/difference-in-difference-with-treatment-defined-after-event</guid>
      <pubDate>Thu, 10 Oct 2024 20:42:08 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归：共线性或接近共线性的参数的部分效应解释</title>
      <link>https://stats.stackexchange.com/questions/655518/multiple-linear-regression-partial-effects-interpretation-of-parameters-at-near</link>
      <description><![CDATA[我正在看一个最简单的多元线性回归模型示例：
\begin{equation}\label{linreg}
Y = \beta_1 X_1 + \beta_2 X_2 + \varepsilon,
\end{equation&gt;
我对当 $X_1=X_2$（共线性）或 $\text{cor}(X_1, X_2)$ 非常高（可能是 $\text{cor}(X_1, X_2)&gt;0.999$）时获得的参数估计值（同时估计）感兴趣。
回归系数的标准解释是偏效应：$\beta_1$ 是 $X_1$ 增加一个单位时 $Y$ 的变化，同时控制所有其他变量（此处仅 $X_2$）。但是，如果 $X_1=X_2$，则一旦我们控制了 $X_2$，$X_1$ 显然无法再解释 $Y$ 中的任何变化。基于此推理，我期望得到估计值$\hat\beta_1=0$，并且基于相同推理，我期望得到$\hat\beta_2=0$。
但是，如果我估计回归模型（在完全共线情况下使用贝叶斯模型，或在近共线情况下使用贝叶斯/频率论），我会得到 beta 系数，其总和等于真实参数的总和$\beta_1+\beta_2$。从优化的角度来看，这也是有道理的，因为如果 $X_1=X_2$，则上述模型的 RHS 可以重写为 $(\beta_1+\beta_2)X_1 + \varepsilon$，这也说明了为什么模型无法识别。
基于上述内容，似乎 $\beta_1, \beta_2$ 的部分效应解释与我在（近）共线情况下得到的结果不一致。显然，我犯了一个推理错误，我希望有人能指出这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/655518/multiple-linear-regression-partial-effects-interpretation-of-parameters-at-near</guid>
      <pubDate>Wed, 09 Oct 2024 08:49:59 GMT</pubDate>
    </item>
    <item>
      <title>R 中许多类别测试的插入符号和 pROC 结果之间的敏感性和特异性差异</title>
      <link>https://stats.stackexchange.com/questions/655442/difference-in-sensitivity-and-specificity-between-caret-and-proc-results-for-man</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655442/difference-in-sensitivity-and-specificity-between-caret-and-proc-results-for-man</guid>
      <pubDate>Mon, 07 Oct 2024 15:06:39 GMT</pubDate>
    </item>
    <item>
      <title>在多级模式下设置 3 级预测变量</title>
      <link>https://stats.stackexchange.com/questions/653456/setting-predictor-variables-with-3-levels-in-multilevel-mode</link>
      <description><![CDATA[我正在使用随机截距多级建模。
我想根据调查数据预测总体健康状况。调查使用三个级别的嵌套数据集：个人、县和州。
我正在使用所有三个级别的预测变量。我想确保让模型知道每个变量的级别
age 和 diet 是个人级别
altitude 是县级
pol.party 和 minimum.wage 是州级
这是我的基线模型：
model1 &lt;- lmer(health.outcome ~ 1 + age + diet + elevation + pol.party + minimum.wage +
(altitude|state:county) +
(altitude + pol.party + minimum.wage|state),
REML=FALSE,
data = df)
]]></description>
      <guid>https://stats.stackexchange.com/questions/653456/setting-predictor-variables-with-3-levels-in-multilevel-mode</guid>
      <pubDate>Tue, 27 Aug 2024 23:37:45 GMT</pubDate>
    </item>
    </channel>
</rss>