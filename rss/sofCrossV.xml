<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 30 Sep 2024 06:25:28 GMT</lastBuildDate>
    <item>
      <title>样本均值和贝塔回归系数之间有协方差吗？</title>
      <link>https://stats.stackexchange.com/questions/655101/is-there-covariance-between-the-sample-mean-and-beta-regression-coefficients</link>
      <description><![CDATA[在线性回归中，样本均值和 beta 回归估计值之间是否存在协方差？
例如模型如下：
$$ y_i = \beta_0 + \beta_1 x_i + \epsilon_i $$
在此设置中，$\bar{y}$ 是因变量的样本均值，$\bar{x}$ 是自变量的样本均值。
我想要找出答案：
$$ Cov(\bar{y}, \hat{\beta_1})$$
我首先写了 OLS 估计：
$$ \hat{\beta_1} = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} $$
然后我以 $y_i$ 的形式写下 $\bar{y}$：
$$ \bar{y} = \frac{1}{n} \sum_{i=1}^n y_i $$
把所有东西放在一起：
$$ Cov(\bar{y}, \hat{\beta_1}) = E[(\bar{y} - E[\bar{y}])(\hat{\beta_1} - E[\hat{\beta_1}])] $$
然后代入公式：
$$ Cov(\bar{y}, \hat{\beta_1}) = E\left[\left(\frac{1}{n} \sum_{i=1}^n y_i - E[\bar{y}]\right)\left(\frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} - E[\hat{\beta_1}]\right)\right] $$
但我不确定如何从这里继续。
我认为协方差确实存在（即非零），因为$\bar{y}$ 具有来自样本的不确定性，并且$\hat{\beta_1}$ 具有来自样本的不确定性……但我不确定回归理论是否表示它们之间的协方差从根本上来说为 0，或者在大样本下的期望值约为 0，或者实际上为非零。
我应该如何进行？]]></description>
      <guid>https://stats.stackexchange.com/questions/655101/is-there-covariance-between-the-sample-mean-and-beta-regression-coefficients</guid>
      <pubDate>Mon, 30 Sep 2024 05:36:49 GMT</pubDate>
    </item>
    <item>
      <title>引导程序如何保持时间依赖性？</title>
      <link>https://stats.stackexchange.com/questions/655095/how-does-bootstrapping-preserve-time-dependence</link>
      <description><![CDATA[这是一个经典的纵向模型，其中 100 人进行了 20 次测量：
$$ y_{ij} = \beta_0 + \beta_1 x_{ij} + \beta_2 t_{ij} + u_i + \epsilon_{ij} $$
其中：

$ i = 1, 2, ..., 100 \text{ (患者指数)} $

$ j = 1, 2, ..., 20 \text{ (测量指数)} $

$y_{ij}$ 结果在测量值 $j$ 时，患者 $i$ 的变量

$\beta_0$ 是截距

$\beta_1$ 是时间不变协变量 $x_{ij}$ 的系数

$\beta_2$ 是时间变量 $t_{ij}$ 的系数

$u_i$ 是患者 $i$,$ u_i \sim N(0, \sigma_u^2) $

$\epsilon_{ij}$ 是误差项 $ \epsilon_{ij} \sim N(0, \sigma_{\epsilon}^2) $


我感兴趣的是测量 $\beta_1$ 还是 $\beta_2$ 对 $Y$ 的影响更大。我认为有两种方法可以做到这一点：

标准化系数：比较回归模型中不同预测因子的相对重要性

$$ \beta_{1,std} = \beta_1 \frac{SD(x)}{SD(y)} $$
$$ \beta_{2,std} = \beta_2 \frac{SD(t)}{SD(y)} $$
$SD()$ 表示标准差。

弹性：衡量独立变量发生 1% 变化时因变量的百分比变化。

$$ E_x = \frac{\partial y}{\partial x} \cdot \frac{x}{y} $$
$$ E_x = \beta_1 \cdot \frac{\bar{x}}{\bar{y}} $$
$$ E_t = \beta_2 \cdot \frac{\bar{t}}{\bar{y}} $$
其中 $\bar{x}$、$\bar{t}$ 和 $\bar{y}$ 是 $x$ 的均值，$t$ 和 $y$。
我可以在 R 中拟合原始模型，但我不知道如何计算这些估计值的标准误差。如果这是一个标准回归模型（非纵向），我只需进行标准引导：对原始数据进行替换采样，拟合模型，计算估计值，重复并制作估计值的直方图。但在这种情况下，我不确定如何设置引导以保留数据中可能的时间依赖性。例如，$Y$ 可能是随着时间的推移而恶化的肾功能，引导可能导致随机样本显示肾功能改善和恶化，而实际上肾功能在统计上随着时间的推移而下降。
我想也许我可以进行引导并将采样单位作为整个人。例如。

引导样本 1：（患者 1 的所有测量值、患者 87 的所有测量值、患者 91 的所有测量值、患者 55 的所有测量值、患者 87 的所有测量值等）
引导样本 2：（患者 9 的所有测量值、患者 71 的所有测量值、患者 91 的所有测量值、患者 55 的所有测量值、患者 87 的所有测量值等）
等等。

但我不确定这是否是个好主意。
是否可以修改引导程序以在这种情况下工作？
PS：我知道在时间序列中有一种用于交叉验证的滚动窗口方法，但我不确定它是否可以在这里应用。]]></description>
      <guid>https://stats.stackexchange.com/questions/655095/how-does-bootstrapping-preserve-time-dependence</guid>
      <pubDate>Mon, 30 Sep 2024 02:19:42 GMT</pubDate>
    </item>
    <item>
      <title>方差未知的正态分布数据上两个精确假设的贝叶斯因子</title>
      <link>https://stats.stackexchange.com/questions/655089/bayes-factor-for-two-exact-hypotheses-on-normally-distributed-data-with-unknown</link>
      <description><![CDATA[假设观测值$x_i$服从正态分布
$$
x_i \sim N(\mu, \sigma^2)
$$
并且方差$\sigma^2$未知。贝叶斯因子用于比较平均值上的两个点假设
$$
H_0: \mu=\mu_0, \sigma^2 \text{unknown}\\\\
H_1: \mu=\mu_1, \sigma^2 \text{unknown}
$$
是
$$
B_{01} = \frac{M(H_0 | \textbf{x})}{M(H_1 | \textbf{x})} 
= \frac{\int L(\mu_0, \sigma | \textbf{x}) p(\sigma) d\sigma}
{\int L(\mu_1, \sigma | \textbf{x}) p(\sigma) d\sigma}
$$
其中 $M(H_i | \textbf{x})$ 为边际似然，$L(\mu_i, \sigma | \textbf{x})$ 为联合似然，$p(\sigma)$ 为未知参数 $\sigma$ 的先验分布。
联合似然函数对应于给定均值 $\mu$ 和方差 $\sigma^2$ 时正态分布数据的概率
$$
L(\mu, \sigma | \textbf{x}) = p(\textbf{x} | \mu, \sigma) = \prod_{i=1}^n f(x_i | \mu, \sigma)
$$
其中 $f(x_i | \mu, \sigma)=\frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(x_i-\mu)^2}{2 \sigma^2}}$ 是正态分布的概率密度函数
$N(\mu, \sigma^2)$。
众所周知，先验对边际似然和贝叶斯因子的影响大于对后验分布的影响（例如 Rouder 等人，2009 年；
Lambert，2018 年）。
问题：

是否存在先验$p(\sigma)$，可以得出边际似然和/或贝叶斯因子的简单表达式？
使用不恰当的先验，例如$p(\sigma) = 1/\sigma$是否有意义?
使用先验，使其预期值对应于数据$E_p[\sigma] = s^2$的方差，这样不是更好吗？
如果没有边际似然或贝叶斯因子的解析表达式，那么使用哪种算法（或 R 函数）来计算边际似然和贝叶斯因子？

附注：我使用缩放$\chi^2$分布 $\text{scaled-}\chi^2(k,\theta)$作为$\sigma$，这证实了参数 $k$ 和 $\theta$ 的选择会对贝叶斯因子产生很大影响。我可以发布这些结果来为这个问题提供进一步的动机并说明潜在的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/655089/bayes-factor-for-two-exact-hypotheses-on-normally-distributed-data-with-unknown</guid>
      <pubDate>Sun, 29 Sep 2024 22:00:09 GMT</pubDate>
    </item>
    <item>
      <title>协整秩的后验概率</title>
      <link>https://stats.stackexchange.com/questions/655088/posterior-probability-of-cointegration-rank</link>
      <description><![CDATA[我一直在尝试学习 VECM 的贝叶斯估计。现在，我无法弄清楚如何估计协整秩值的后验概率。
我查看了 R 中的 bvartools 库，以找到现成的实现（因为它们通常还包括文档中的引用）。
文档条目 draw_posterior.bvecmodel 和 post_coint_kls 都引用了 Koop 等人的论文 。 在论文中，作者详细介绍了模型的先前引出和推理
$$\Delta y_t=\alpha\beta^Tx_t+\varepsilon_t$$
并声称以某种方式可以计算协整秩的后验概率。但是，文章中没有算法，bvartools 中似乎也没有实现。
有没有关于这个主题的其他文献，最好有关于协整秩概率推断的详细信息？也许，有一种直接的方法来计算概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/655088/posterior-probability-of-cointegration-rank</guid>
      <pubDate>Sun, 29 Sep 2024 21:29:03 GMT</pubDate>
    </item>
    <item>
      <title>如何有效地从 xgboost 森林中移除树木？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655087/how-to-efficiently-remove-trees-from-xgboost-forest</link>
      <description><![CDATA[我想手动从 xgboost 学习到的森林中删除一棵特定的树。
一种解决方案是将 xgb 模型序列化为 json，手动删除一棵树，然后将其再次转换回 xgboost：https://stackoverflow.com/questions/76318396/can-i-remove-one-booster-from-xgboost-model
但是这会非常低效。
有没有更快的方法来实现这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/655087/how-to-efficiently-remove-trees-from-xgboost-forest</guid>
      <pubDate>Sun, 29 Sep 2024 21:01:01 GMT</pubDate>
    </item>
    <item>
      <title>时间序列的 AIC 和差分</title>
      <link>https://stats.stackexchange.com/questions/655080/aic-and-differencing-for-time-series</link>
      <description><![CDATA[我正在教授一门应用时间序列课程，并想到了一个我不知道如何回答的问题。假设我们有一个非平稳时间序列，我们尝试使用常规差分、季节性差分或两者的模型。这三种转换都会导致数据看起来是平稳的。像这样的例子出现在《Stat 2》一书的第 12 章中，涉及和平桥上的车辆交通。您可以使用以下 R 块获取数据。
require(Stat2Data)
data(PeaceBridge2003)
plot(PeaceBridge2003$Traffic)

我考虑了几个模型，发现其中三个模型的残差没有自相关性，即

模型 1：SARIMA(1,1,0)x(1,0,0)[12]，这是我“手工”得到的模型来自 ACF 和 PACF
模型 2：SARIMA(0,0,0)x(0,1,1)[12]，auto.arima() 选择的模型
模型 3：SARIMA(0,1,1)x(1,1,0)[12]，来自 Stat 2 一书的模型

我希望这个符号没问题。第一个表示进行一阶正则差分，然后使用 AR(1) 项和季节性 AR(1) 项 $x_{t-12}$。第二个说进行一阶季节性差分，然后包含季节性 MA(1) 项 $w_{t-12}$。
要在这些模型之间进行选择，我的直觉是选择最简单的一个（对我来说，就是模型 1），因为差分是一种破坏性的转换。
但是，我确信我的学生会建议使用 AIC 来比较这三个模型，当你这样做时，它会选择模型 3。我担心的是这三个模型代表了三种不同的转换。响应变量可以是 $\Delta x_t$ 或 $\Delta_{12} x_t = x_t - x_{t-12}$ 或 $\Delta_{12} (\Delta x_t)$。
众所周知，您不应使用 AIC 来比较对响应变量进行不同变换的模型。例如，对响应变量进行对数或平方根变换将产生截然不同的 AIC，正如之前所介绍的那样。
令我惊讶的是，当我模拟数据并使用 stats 包中的函数 AIC() 时，我不会像上例中那样为不同类型的差分获得截然不同的值。而且 AIC 通常会在模拟中选择正确的模型。我开始怀疑它在 R 中的实现方式，是否可以用它来比较上述三个模型，也许是因为，归根结底，这三个模型中的响应变量仍然是 $x_t$（例如，R 内置了反向转换）。这样对吗？或者，我们不应该使用 stats 包中的 AIC() 函数来比较具有不同类型差分的上述模型？
最后，我很清楚，关于使用什么顺序差分的真正决策者是“这种差分后数据是否平稳？”的问题；并且，考虑到生成机制，理论上，三种差分类型中只有一种应该导致平稳性。而且，通常，季节性差异是没有必要的。但问题是，我们没有足够的数据来肯定地说，两个选择会留下非平稳数据，而第三个选择会成功（这里$n = 156$；这是 13 年的月度数据）。据我们所知，这三个选择都是有效的。因此，了解 AIC 是否可用于帮助在这种情况下做出决定将会很有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655080/aic-and-differencing-for-time-series</guid>
      <pubDate>Sun, 29 Sep 2024 17:07:25 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法根据变量的同比变化百分比（YoY）来计算指数值（以 100 为基数）？</title>
      <link>https://stats.stackexchange.com/questions/655076/is-there-away-to-compute-index-values-base-100-from-year-over-year-change-y</link>
      <description><![CDATA[假设我有这样的时间序列：



时间段
同比变化（%）




2024 年 _ Q1
7.00


2024 年 _ Q2
4.85


2024 年 _第三季度
5.77


2024 年 _ 第四季度
5.66


2025 年 _ 第一季度
6.54


2025 年 _ 第二季度
6.48


2025 年 _ 第三季度
6.36


2025 年第四季度
6.25



有没有办法将“同比变化百分比”系列转换为“指数值”系列（以给定日期为基数 100）？
目标系列将类似于：



时间段
指数（以 100 为基数，位于 Y2023_Q1）




Y2023 _ Q1
100


Y2023 _ Q2
103


2023 年 _ 第 3 季度
104


2023 年 _ 第 4 季度
106


2024 年 _ 第 1 季度
107


2024 年 _ 第 2 季度
108


2024 年 _ 第 3 季度
110


2024 年 _ 第 4 季度
112


2025 年 _ 第 1 季度
114


2025 年 _ 第 2 季度
115


2025 年 _ 第三季度
117


2025 年 _ 第四季度
119



或者可能无法重建 2023 年第一季度的数据，所以也许我应该着眼于构建类似的东西，并在 2024 年第一季度修复基准参考（索引 = 100）：



时间段
索引（基数 100 = Y2024_Q1)




Y2024 _ Q1
100


Y2024 _ Q2
1XX


Y2024 _ Q3
1XX


Y2024 _ Q4
等。



如果我们有四分位数据，我知道我们可以使用以下公式计算指数的同比变化百分比：
$$\frac{\mathbf{Index}_{Year\_Y, Quarter\_Q}-\mathbf{Index}_{Year\_(Y-1), Quarter\_Q}}{ \mathbf{Index}_{Year \_(Y-1), Quarter\_Q}}$$
但我只有 YoY 数据，我想将其反转回指数值。有没有实际的方法可以做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/655076/is-there-away-to-compute-index-values-base-100-from-year-over-year-change-y</guid>
      <pubDate>Sun, 29 Sep 2024 15:45:06 GMT</pubDate>
    </item>
    <item>
      <title>组成数据中的零值和使用狄利克雷分布的问题到底是什么？</title>
      <link>https://stats.stackexchange.com/questions/655075/what-exactly-is-the-issue-with-zero-values-in-compositional-data-and-using-the-d</link>
      <description><![CDATA[因此，Aitchison 描述了零值的问题，即无法对这些数字取对数。但他也解释说，如果只有少量的零，我们可以简单地用一个小数字替换它们。他警告说，选择如此小的值可能会影响结果。我有两个问题：

为什么我们不能只取最小的可用数字（R 中的机器 epsilon）？
为什么无论有多少个零都不能使用这种方法？

这篇论文已经过时了，但最近仍然被引用来描述使用狄利克雷建模时与零值相关的问题。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655075/what-exactly-is-the-issue-with-zero-values-in-compositional-data-and-using-the-d</guid>
      <pubDate>Sun, 29 Sep 2024 14:56:09 GMT</pubDate>
    </item>
    <item>
      <title>理解为什么 beta 分布适合我的数据</title>
      <link>https://stats.stackexchange.com/questions/655050/understanding-why-a-beta-distribution-fits-to-my-data</link>
      <description><![CDATA[显然，我的统计知识遇到了一些我无法理解的问题。
我有一组数据，基本上应该将图像分类为二元分类（假设年轻和年老，为了进一步讨论，我将它们标记为 0 和 1）。
不幸的是，我应该处理的这个数据集是一个直方图，x 轴是两个二元结果的（几乎）连续分数。例如，有数据点在 bin 0.65 中。我会将其解释为更多人在调查中表示该图像属于分类 1。
有趣的是，我是 beta 分布的新手，我拥有的数据与参数为 5.94 和 2.42 的 beta 分布非常吻合。
在过去几周里，我阅读了很多关于统计学、beta 分布和二项式联系的文章，但这完全令人费解。我真的很想知道为什么我得到的这个数据集显然遵循 beta 分布。
到目前为止，我的想法是，我有 n 张图像，对于每张图像，假设有 k 个人问他们这个问题：“这张图片属于 0 类还是 1 类”。由于现在我对每张图片都有 k 个答案，我可以理解为什么结果会有分数（介于 0 和 1 之间，而不仅仅是 0 和 1）。我也能理解这个问题可能遵循二项分布 - 但为什么结果遵循 beta 分布而不是二项分布？
我知道对于有经验的人来说这可能是一个简单的问题，但我到目前为止还没有接触过这些问题，并且想学习。
非常感谢您的见解
编辑：添加更多信息以澄清问题
所以这是我的数据集（黑点），符合 beta 分布（我将直方图标准化为 1，因此您看不到箱中的计数，而是我理解的密度）

减小的 chi^2 约为 1.35，这就是我认为这个拟合度非常好的原因。评论“惊人”更多的是因为显然我对 beta 分布的理解不够充分。
从我今天读到的内容来看，如果二项式实验中 p 未知，则可以使用 beta 分布。这似乎很有道理，因为在实验之前 p 是未知的（或未知的）。
关于排序的陈述不清楚。排序不是我做的，当然也不是数据集做的。数据集是二元标签排序的结果。
但是，排序是通过向一群人询问每张图片并让他们将图片放入两个标签中来完成的。之后，对于每张图片，得分被评估为答案 1 占答案总数的百分比。因此，我的前任创建了该直方图。
我猜想，我对直方图的拟合可能意味着它是每张图片被放入标签 1 的概率分布。将 beta 的参数解释为成功和失败的次数对我来说有些道理，但我不确定如何解释这一点。
我希望有人可以澄清这一点，首先我必须为这个不清楚的问题道歉]]></description>
      <guid>https://stats.stackexchange.com/questions/655050/understanding-why-a-beta-distribution-fits-to-my-data</guid>
      <pubDate>Sat, 28 Sep 2024 15:56:07 GMT</pubDate>
    </item>
    <item>
      <title>回归问题的预期误差减少</title>
      <link>https://stats.stackexchange.com/questions/654594/expected-error-reduction-for-regression-problems</link>
      <description><![CDATA[我想在 Python 中实现一种基于预期误差减少 (EER) 的主动学习方法：
https://axon.cs.byu.edu/Dan/778/papers/Active%20Learning/roy.pdf
https://arxiv.org/abs/2211.09283
对于回归问题，其中机器学习模型是基于树的模型（我计划使用 XGBoost、随机森林回归器或 VotingRegressor，它们只是平均输出我不需要使用贝叶斯推理框架，但如果有必要，我会使用它。目前，我有两个问题：

上述论文中的方程式非常复杂，没有伪代码。我不明白如何为 EER 编写损失函数，以及整体框架是什么。我的粗略理解是，为了计算这个损失，对于每个未标记的输入样本，我需要运行我的 ML 模型，计算每个可能标签在我的 ML 模型下的概率，然后用它来计算损失……但我错过了细节。
这些方程式是针对分类任务给出的。我实际上有一个回归任务。我如何使 EER 适应回归？我想我应该用积分代替对所有可能的标签值求和...因为我可以为输出变量给出上限和下限，高斯-勒让德数值积分可能是计算效率更高的方法。

如何实现基于 EER 的回归主动学习？包含 Python 代码/伪代码的答案是最好的，但即使只是对算法和要使用的方程式的详细解释也足够了（然后我可以尝试自己用 Python 实现它，如果遇到困难，请在 StackOverflow 上提问）。]]></description>
      <guid>https://stats.stackexchange.com/questions/654594/expected-error-reduction-for-regression-problems</guid>
      <pubDate>Thu, 19 Sep 2024 09:39:01 GMT</pubDate>
    </item>
    <item>
      <title>可以从梯度提升模型 CatBoost 和 XGBoost 中获得概率预测吗？</title>
      <link>https://stats.stackexchange.com/questions/653569/can-probabilistic-predictions-be-obtained-from-gradient-boosting-models-catboost</link>
      <description><![CDATA[我正在寻找使用 CatBoost 或 XGBoost 对连续目标变量（位于 [0, 1] 中，即比例）进行概率预测（$\Pr(Y\mid X=x)$）。我可以使用官方库来生成概率预测，而不是 $E[Y\mid X=x]$ 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653569/can-probabilistic-predictions-be-obtained-from-gradient-boosting-models-catboost</guid>
      <pubDate>Thu, 29 Aug 2024 17:18:07 GMT</pubDate>
    </item>
    <item>
      <title>AR(1) 的手动 MLE 产生了一个奇怪的初始值 $y_0$</title>
      <link>https://stats.stackexchange.com/questions/648189/manual-mle-of-ar1-yields-a-weird-initial-value-y-0</link>
      <description><![CDATA[我正在尝试手动实现 AR(1) 模型中参数的最大似然估计 (MLE)
$$
y_t = c + \varphi_1 y_{t-1} + \varepsilon_t
$$
其中 $\text{Var}(\varepsilon_t)=\sigma^2$。我将我的结果与 forecast 包中的 Arima 获得的结果进行比较（基于 stats 包中的 arima）。

我的可能性略高于 Arima。
除了初始值 $y_0$ 之外，估计值并不相同，但相当接近。我的估算器给出的值似乎太高（高于 $y$ 的范围），并且远离 Arima 的更合理值。

我尝试了几个不同的手动 MLE 起始值，但每次都得到相同的结果。
我做错了什么？
library(fpp2) # 示例数据集所需

# AR(1) 的对数似然
loglik &lt;- function(pars){
c &lt;- pars[&quot;c&quot; ] # 常数
phi1 &lt;- pars[&quot;phi1&quot; ] # 斜率
sigma2 &lt;- pars[&quot;sigma2&quot;] # 误差方差
y0 &lt;- pars[&quot;y0&quot; ] # 时间序列的初始值
T &lt;- length(y)
e &lt;- rep(NA,T)
e[1] &lt;- y[1] - ( c + phi1*y0 )
for(t in 2:T){
e[t] &lt;- y[t] - ( c + phi1*y[t-1] )
}
Li &lt;- dnorm(e, mean=0, sd=sqrt(sigma2))
loglik &lt;- sum(log(Li))
return(loglik)
}

y &lt;- diff(log(oil)) # 1966-2013 年沙特阿拉伯石油产量年度变化百分比

# 优化 loglik 函数
opars &lt;- c(c=0, phi1=0, sigma2=var(y), y0=mean(y)) # 参数的初始值
#opt &lt;- optim(par=opars, fn=loglik, method=&quot;BFGS&quot;, control=list(fnscale=-1)) # 无界优化
opt &lt;- optim(par=opars, fn=loglik, method=&quot;L-BFGS-B&quot;, control=list(fnscale=-1), 
lower=c(-Inf,-0.99,1e-10,-Inf), 
upper=c( Inf, 0.99,Inf , Inf)) # 有界优化，-0.99&lt;=phi1&lt;=0.99 且 0&lt;sigma2
opt$convergence # 值为 0 表示优化算法正确收敛
optres &lt;- c(opt$par, logL=opt$value) # 主要结果为单个向量

# 与以下内容进行比较`forecast::Arima` 对相同数据产生的结果
m1 &lt;- Arima(y, order=c(1,0,0), method=&quot;CSS-ML&quot;)
m1 &lt;- Arima(y, order=c(1,0,0), method=&quot;ML&quot; )
chat &lt;- unname(m1$coef[2]*(1 - m1$coef[1])) # 用 mu 的估计值表示的 c 估计值
phi1hat &lt;- unname(m1$coef[1])
y0hat &lt;- (y[1] - chat - m1$residuals[1]) / phi1hat # y0 的估计值
m1par &lt;- c(c=chat, phi1=phi1hat, sigma2=m1$sigma2, y0=y0hat) 
m1res &lt;- c(m1par, logL=m1$loglik) # 单个向量中的主要结果

# 打印并将手动 ML 估计值与 `Arima` 中的估计值进行比较
估计值&lt;- rbind(optres,m1res)
rownames(估计值) &lt;- c(&quot;Manual&quot;,&quot;Arima&quot;) 
print(round(估计值, 数字=6))
]]></description>
      <guid>https://stats.stackexchange.com/questions/648189/manual-mle-of-ar1-yields-a-weird-initial-value-y-0</guid>
      <pubDate>Wed, 29 May 2024 08:09:04 GMT</pubDate>
    </item>
    <item>
      <title>ACME 在中介分析中显著，但在比例中介和拟合终止时不显著，并出现步骤失败警告</title>
      <link>https://stats.stackexchange.com/questions/643485/acme-significant-in-mediation-analysis-but-not-proportion-mediated-and-fitting</link>
      <description><![CDATA[我正在使用中介包和以下代码在 R 中运行一系列中介分析：
m_1 &lt;- gam(mediator1 ~ age_cat + s(treat, k = 50, bs = &quot;cr&quot;) + 
cov1 + cov2 + cov3 + cov4 + year, data = mediation_df, 
method = &quot;REML&quot;)

y_1 &lt;- gam(dem_important ~ age_cat + mediator1 + 
s(treat,k = 50, bs = &quot;cr&quot;) + cov1 + cov2 + cov3 + cov4 + 
year, data = mediation_df, method = &quot;REML&quot;)

results1 &lt;- mediate(m_1, y_1, sims = 1000，boot = TRUE，

treat = &quot;treat&quot;，mediator = &quot;mediator1&quot;)

m_2 &lt;- gam(mediator2 ~ age_cat + s(treat，k = 50，bs = &quot;cr&quot;) + 
cov1 + cov2 + cov3 + cov4 + year，数据 = mediation_df，

method = &quot;REML&quot;)

y_2 &lt;- gam(dem_important ~ age_cat + mediator2 + 
s(treat，k = 50，bs = &quot;cr&quot;) + cov1 + cov2 + cov3 + 
cov4 + year，数据 = mediation_df，method = &quot;REML&quot;)

results1 &lt;- mediate(m_2，y_2，sims = 1000，boot = TRUE， 
treat = &quot;treat&quot;，mediator = &quot;mediator1&quot;)

m_3 &lt;- gam(mediator3 ~ age_cat + s(treat，k = 50，bs = &quot;cr&quot;) + 
cov1 + cov2 + cov3 + cov4 + year，数据 = mediation_df， 
method = &quot;REML&quot;)

y_3 &lt;- gam(dem_important ~ age_cat + mediator3 + 
s(treat，k = 50，bs = &quot;cr&quot;) + cov1 + cov2 + 
cov3 + cov4 + year，数据 = mediation_df，方法 = &quot;REML&quot;)

results3 &lt;- mediate(m_3，y_3，sims = 1000，boot = TRUE， 
treat = &quot;treat&quot;，mediator = &quot;mediator3&quot;)


我收到以下结果：
summary(results1)
summary(results2)
summary(results3)

因果中介分析

使用百分位数法的非参数 Bootstrap 置信区间

估计 95% CI 下限 95% CI 上限 p 值

ACME -0.000691 -0.001773 0.00 0.038 *
ADE -0.002030 -0.003628 0.00 0.232
总效应 -0.002721 -0.004609 0.00 0.176
Prop. 中介 0.253953 -0.939163 1.21 0.182 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

使用的样本量：3230

模拟：1000

因果中介分析

使用百分位数法的非参数引导置信区间

估计 95% CI 下限 95% CI 上限 p 值
ACME -0.000253 -0.000612 0.00 0.18
ADE -0.002058 -0.003715 0.00 0.13
总效应 -0.002311 -0.003951 0.00 0.12
Prop. 中介 0.109508 -0.331097 0.52 0.28

样本量：3230

模拟：1000

因果中介分析

使用百分位数法的非参数引导置信区间

估计 95% CI 下限 95% CI 上限 p 值
ACME -0.000334 -0.003641 0.00 0.37
ADE -0.002725 -0.004098 0.01 0.36
总效应 -0.003059 -0.006020 0.01 0.28
Prop. 中介 0.109084 -1.115058 1.36 0.53

样本量：3230

模拟：1000


我希望比较这些不同的模型，并比较每个中介的中介效应。在回归一中，我得到了 ACME 的显著效应，并且 25% 的中介效应比其他两个中介的要大得多。但是，该比例的中介效应并不显著，其他模型的 ACME 也不显著。我知道其他帖子已经解释了间接效应如何显著而直接效应不显著，但我没有看到这种情况。
为什么可以找到显著的 ACME，但中介比例却不显著？我的结果可以完全信任吗？还是不能得出结论？此外，我可以对不同的中介进行合理的比较吗？我是否可以说模型 1 中的中介比其他模型具有更强的中介效应，因为中介比例更高。
这一切都是由权力问题引起的吗？这和 MCMC 中的迭代次数有关吗？
此外：
对于最终模型，我还收到以下警告：
运行非参数引导程序

警告：拟合因步骤失败而终止 - 仔细检查结果 

我从这个警告中推断出什么？我的结果可信吗，或者我该如何检查？]]></description>
      <guid>https://stats.stackexchange.com/questions/643485/acme-significant-in-mediation-analysis-but-not-proportion-mediated-and-fitting</guid>
      <pubDate>Mon, 25 Mar 2024 14:12:03 GMT</pubDate>
    </item>
    <item>
      <title>如果双向方差分析的假设不满足，我应该使用哪种统计检验？</title>
      <link>https://stats.stackexchange.com/questions/596606/which-statistical-test-should-i-use-if-the-assumptions-of-a-2-way-anova-are-not</link>
      <description><![CDATA[我的研究设计包含两个因素（一个有 2 个级别，另一个有 6 个级别）和一个连续响应变量。为了分析这两个因素对解释变量的影响，我构建了一个线性模型，格式如下：
modela&lt;-lm(response~factor1*factor2, data=dataset)
我打算运行双向方差分析来检验每个解释变量的重要性，但是，在评估此检验的假设后，我发现残差正态性假设被违反（通过 Shapiro-Wilk 检验的显著 p 值显示）。所有其他假设（独立观测、无显著异常值、方差齐性）均得到满足。
考虑到这个假设违反，是否有更适合分析我的数据的非参数替代检验。我也读到过转换数据可能会有帮助，但我不确定 a) 这是否合适，以及 b) 我应该使用哪些转换。
任何人提供的帮助都将不胜感激。
编辑 1 - 这是我的模型的 Q-Q 图：

编辑 2：
这是我为对齐等级转换 ANOVA 获得的输出。
调用：
art(formula = Duration.egg ~ 温度 + 物种 + 温度：物种，
data = egg.na.1)

对齐响应的列总和（应全部为 ~0）：
温度 物种 温度：物种
0 0 0 

对不感兴趣的对齐响应的方差分析的 F 值（应全部为 ~0）：
最小值 第 1 组 中位数 平均值 第 3 组 最大值。
0.0000 0.0000 0.0000 0.4130 0.1609 2.2636 
警告消息：
在 summary.art(x) 中：
对不感兴趣的对齐响应的方差分析的 F 值并非全部为 ~0。ART 可能不合适。
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/596606/which-statistical-test-should-i-use-if-the-assumptions-of-a-2-way-anova-are-not</guid>
      <pubDate>Tue, 22 Nov 2022 17:19:47 GMT</pubDate>
    </item>
    <item>
      <title>蒙特卡洛随机失分的不确定性得分</title>
      <link>https://stats.stackexchange.com/questions/594819/uncertainty-score-from-monte-carlo-dropout</link>
      <description><![CDATA[当使用神经网络进行多类分类时，有些情况下估计网络预测类别的不确定性很有用。估计不确定性的一种主要方法是蒙特卡洛 dropout，由 Gal 等人 提出。
让 $f(y|x)$ 表示神经网络对输入 $x$ 的 softmax 输出，类别为 $y$。他们的方法是使用 dropout 来训练 $f$，在测试时保持 dropout 启用，并通过从 $f(y|x)$ 中抽取一些样本来估计 $\mathbb{E}[f(y|x)]$ 和 $\textrm{Var}[f(y|x)]$，即通过在输入 $x$ 上运行神经网络几次并计算输出的平均值和标准差。到目前为止，这一切都说得通，但我不清楚如何从中获得不确定性分数。
如果我想要一个分数来衡量网络对 $x$ 类别的预测的不确定性，那么从这些信息中获得不确定性分数的标准方法是什么？本文似乎没有提出任何特定方法。本文描述了如何估计后验预测分布，但没有描述如何从中获得不确定性分数。
我可以想象到多种可能性，即如何从通过蒙特卡洛 dropout 获得的后验预测分布中构建不确定性分数：

我们可以使用后验预测分布中预测类别的概率作为我们的不确定性分数，即 $\max_y \mathbb{E}[f(y|x)]$。

我们可以使用后验预测分布的熵作为我们的不确定性分数，即
$$H(\mathbb{E}[f(\cdot|x)]) = - \sum_y \mathbb{E}[f(y|x)] \log \mathbb{E}[f(y|x)].$$

我们可以使用正态近似来估计未来对神经网络的评估将输出与预测类别相同的类别的概率。具体来说，我们可以将$p(y|x)$近似为高斯$\mathcal{N}(\mu_y,\sigma_y^2)$，其平均值$\mu_y = \mathbb{E}[f(y|x)]$，方差$\sigma_y^2 = \textrm{Var}[f(y|x)]$。对于二分类器，让 $y$ 为测试时预测的类（即 $y=\arg\max_{y&#39;} \mathbb{E}[f(y&#39;|x)]$），$\neg y$ 为另一个类。那么，分类器的未来评估也将输出 $y$ 的概率为 $u=\Pr[X\ge 0]$，其中 $X \sim \mathcal{N}(\mu_y-\mu_{\neg y},\sigma^2_y+\sigma^2_{\neg y})$。我们可以通过误差函数估计 $u$，然后使用 $u$ 作为我们的不确定性分数。（对于多类分类器，我们可以通过对 $y$ 以外的类的所有 logit 求和并将其视为单个其他类 $\neg y$ 的 logit，使用二类 softmax，并估计这些 softmax 输出的正态分布，从而简化为二类分类器。）


在我看来，所有这些都是合理的选择。什么是公认的做法？使用 Monte Carlo dropout 获得不确定性分数的标准方法是什么？如果没有标准，哪种方法最有效？]]></description>
      <guid>https://stats.stackexchange.com/questions/594819/uncertainty-score-from-monte-carlo-dropout</guid>
      <pubDate>Sun, 06 Nov 2022 05:02:16 GMT</pubDate>
    </item>
    </channel>
</rss>