<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 12 Nov 2024 21:15:20 GMT</lastBuildDate>
    <item>
      <title>如何理解赌徒谬误？</title>
      <link>https://stats.stackexchange.com/questions/657166/how-can-i-understand-the-gamblers-fallacy</link>
      <description><![CDATA[假设你掷骰子 500 次。在这 500 次中你不可能永远掷出 6，不是吗？
但同时，每次掷骰子都是独立的，平均掷出 6 的概率只有 1/6。
那么... 认为第 501 次掷骰子“不太可能”不是 6 是对还是错？我只是很难解开这个谜团。]]></description>
      <guid>https://stats.stackexchange.com/questions/657166/how-can-i-understand-the-gamblers-fallacy</guid>
      <pubDate>Tue, 12 Nov 2024 20:43:54 GMT</pubDate>
    </item>
    <item>
      <title>排序样本的含义</title>
      <link>https://stats.stackexchange.com/questions/657161/meaning-of-sorted-samples</link>
      <description><![CDATA[假设您有一组来自某个分布的有限样本。
您取出这些样本，按值从小到大排序，然后制作图表。像这样：

横轴是排序位置（任意），纵轴是样本值。
我的问题是：这个形状说明了样本来自的分布是什么？我很想说它是累积分布函数的逆函数，但我无法证明这一点。
我知道它能说明很多关于分布的信息，因为我已经非常习惯阅读这些图表（因为在 Excel 2007 中制作直方图很麻烦）。例如，对于上图，我可以看到底层分布是一条钟形曲线，右尾较短，左尾较长。]]></description>
      <guid>https://stats.stackexchange.com/questions/657161/meaning-of-sorted-samples</guid>
      <pubDate>Tue, 12 Nov 2024 19:55:05 GMT</pubDate>
    </item>
    <item>
      <title>从专家判断中选择最佳类别样本的适当统计分析是什么？</title>
      <link>https://stats.stackexchange.com/questions/657160/whats-the-appropriate-statistical-analysis-for-selecting-best-category-exemplar</link>
      <description><![CDATA[我正在寻求有关适当统计分析的建议，以便根据我正在进行的虚假新闻实验中的专家判断选择最佳类别样本。
我的研究背景：

我构建了 39 个虚假新闻刺激。
11 位专家评委将每个刺激归类为 7 个可能的类别之一（名义数据）。类别 A、B、C、D、E、F 和“以上都不是”。结果是一个 39×11 矩阵（429 个单元格），其中每个单元格包含 7 个可能的类别之一。
我的目标是从六个类别中每个类别中选择总共 24 个最佳/最具代表性的样本。如果某些类别最终变得不平衡，或者最终出现一个没有任何刺激的类别，这都没关系。

当前分析：

我计算了 Fleiss&#39; Kappa 与 39 个刺激的总体一致性。
然后对于刺激选择，我开发了一个“一致性指数”，该指数减去第一个投票最多的类别的百分比减去第二个投票最多的类别（目的是“惩罚”刺激的模糊性）。


例如，如果 70% 的人投票给 A 类，15% 的人投票给 B 类，其余的人分布在其他类别中，则刺激获得 55 个百分点。
如果类别之间有平局，则刺激获得 0 分。


再次计算“最佳”24 个刺激子集的 Fleiss&#39; Kappa。

问题：

我没有关于我最终使用的“一致性指数”的参考资料，也找不到任何使用类似方法或存在类似问题的手册或论文，即必须找到类别的最佳代表。
Fleiss&#39; Kappa 用于估计多个评估者之间的一致性，但使用完整的数据集（具有 429 个值的矩阵）。据我了解，我需要为每个刺激单独估计一个指数。
当我在 RStudio 中修改 Fleiss&#39; Kappa 包以计算每个刺激的 kappa 时，我最终没有得到一个显著的 p 值（可能是因为每个刺激只有 11 个值，并且 Fleiss&#39; Kappa 不打算以这种方式使用）。
大多数系数都关注评估者之间的一致性，但我需要关注的是，其中哪一个刺激被大多数人认为是其类别的最佳典范。

问题：

选择最佳类别典范的适当统计分析是什么？
什么是分析这种类型数据的最合适的系数？ （我的意思是第二步）
是否有既定的方法，可根据多位评委的分类选择最佳类别范例？
Fleiss&#39; Kappa 是否以这些方式正确使用并考虑到这些目标？

我是认真的，感谢您提供的任何指导或相关参考资料，我将不胜感激。另外，真的希望我在这里提出的研究问题能够说清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/657160/whats-the-appropriate-statistical-analysis-for-selecting-best-category-exemplar</guid>
      <pubDate>Tue, 12 Nov 2024 19:38:12 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA：对于通货膨胀数据，对数差分比二阶差分更好吗？</title>
      <link>https://stats.stackexchange.com/questions/657158/arima-log-differencing-is-better-tnan-two-order-differencing-on-inflation-data</link>
      <description><![CDATA[我正在尝试对通货膨胀数据执行 ARIMA
我可以看到：

我需要两个顺序差分才能获得平稳性数据
并且只需要一个对数差分即可获得平稳性。
在对数差分中，我有两个数据下降，然后在 2020 年出现大幅飙升
在两次差分中，我首先出现大幅飙升，然后在 2020 年出现低点
两者在 ADF 测试中的 p 值几乎相同（约为 .01）。

在这种情况下，最好的差分方法是什么，以获得更好的 ARIMA？（我在 Rstudio 中工作）谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/657158/arima-log-differencing-is-better-tnan-two-order-differencing-on-inflation-data</guid>
      <pubDate>Tue, 12 Nov 2024 19:08:03 GMT</pubDate>
    </item>
    <item>
      <title>进行“最大 p 值估计”而不是最大似然估计</title>
      <link>https://stats.stackexchange.com/questions/657156/doing-maximum-p-value-estimation-instead-of-maximum-likelihood</link>
      <description><![CDATA[每当我们进行最大似然估计时，我们都会寻找最大化数据概率密度的参数。另一方面，当我们计算 p 值时，我们会查看获得至少与数据一样极端的尾部概率。这种不匹配通常会导致数据在其自己的 MLE 参数上无法通过假设检验。
是否有一种技术可以最大化 p 值而不是最大化似然？这意味着我们正在寻找使我们的样本“最典型”的参数而不是最有可能。
当然，有很多不同的方法可以做到这一点 - 不同的尾部概率、检验统计量等。但任何直接最大化从样本的某些充分统计量中得出的尾部概率（而不仅仅是最大化密度）的基本方向都会很有趣。
例如，假设我们从 $[0, \theta]$ 均匀地抽取一个 $X$，并且我们想要估计 $\theta$。MLE 只是 $\hat \theta = X$。但是，假设我们使用双侧假设检验，以 $\hat theta$ 的值作为零假设，则 $X$ 是一个极端异常值，p 值为 0。选择 $\hat \theta$ 来最大化该 p 值，则会得到 $\hat \theta = 2X$，在这种情况下也与 MVUE 一致。]]></description>
      <guid>https://stats.stackexchange.com/questions/657156/doing-maximum-p-value-estimation-instead-of-maximum-likelihood</guid>
      <pubDate>Tue, 12 Nov 2024 18:04:13 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 R 中的 MARS 模型的输出？</title>
      <link>https://stats.stackexchange.com/questions/657154/how-to-interpret-output-from-a-mars-model-in-r</link>
      <description><![CDATA[我正在使用包 earth 在 R 中拟合多元自适应回归样条 (MARS) 模型。我正在拟合一个非常像这样的模型：
model &lt;- earth(y ~ x, data = df)

这将产生如下所示的输出：
系数
(截距) 15.4
h(x- -10) -1.2
h(20 -x) 0.92
h(x -20) 1.01

我的问题是如何解释系数。
最后，我希望能够解释每个间隔内发生的事情（在这种情况下，间隔将在 -10 之前、-10 和 20 之间以及 20 之后）。
任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657154/how-to-interpret-output-from-a-mars-model-in-r</guid>
      <pubDate>Tue, 12 Nov 2024 16:47:59 GMT</pubDate>
    </item>
    <item>
      <title>对数-对数变换数据的多元回归的预测区间</title>
      <link>https://stats.stackexchange.com/questions/657151/prediction-intervals-for-multiple-regression-on-log-log-transformed-data</link>
      <description><![CDATA[我正在使用对数对数变换数据进行普通最小二乘线性多元回归来建立树木生物量估计模型。最后，我希望得到一个生物量预测，其预测区间在原始范围内。我读过几篇关于这个主题的帖子（这里和其他地方），但没有变得更聪明。我是统计学新手，希望能得到一些实际的建议。以下是我所知道的：
我希望我的独立变量（$x_i$）和独立变量（$y$）之间的关系是幂函数。回归是在对数对数变换数据上执行的，如下所示：
$$ln(y)=\alpha+\beta_1ln(x_1)+\dots+\beta_n ln(x_n)$$
我意识到我需要一个校正因子来获得无偏估计，并检查残差的恒定方差和正态分布，因此估计值应如下所示：
$$\hat y=e^{a+b_1 ln(x_1)+\dots +b_n ln(x_n)+\hat\sigma^2/2}$$
其中 $a$ 和 $b_i$ 是回归系数，$\hat\sigma$ 是残差的标准误差。
到目前为止一切顺利（我希望！）。我想要的是我的 $\hat y$ 的 PI（即一个方程，指定 95% 的未来观测值将落在一个范围内，以 kg 为单位）。我怀疑转换和误差与 $y$ 不独立这一事实可能会导致一些复杂情况。阅读​​这个主题只会让我感到困惑。我有两个猜测：

从回归中计算${ln(y)}$的PI，添加${\hat\sigma^2/2}$并对其进行反向转换。
从$s=\sqrt{{1\over{N-p}}\sum{(\hat y-y_{obs})^2}}$计算新的误差估计并使用它来计算PI，但我猜异方差会是一个问题。

当然，我很感激能提供能提高我理解的评论和参考资料，但我真正需要的是一种能给我一个统计上有效的结果的清晰方法。在这种情况下，GLM 对我来说不是一个选择。
干杯！]]></description>
      <guid>https://stats.stackexchange.com/questions/657151/prediction-intervals-for-multiple-regression-on-log-log-transformed-data</guid>
      <pubDate>Tue, 12 Nov 2024 16:42:45 GMT</pubDate>
    </item>
    <item>
      <title>在观察来自同一 CDF 的实际绘制后更新连续 CDF</title>
      <link>https://stats.stackexchange.com/questions/657150/updating-a-continuous-cdf-after-observing-realised-draw-from-same-cdf</link>
      <description><![CDATA[我正在尝试求解一些更新的分布，但在概念化我正在做的事情时遇到了一些麻烦。
具体来说，假设我有两个 CDF，即 $U[0,0.8]$ 和 $U[0.2,1]$；分别称它们为 $CDF_1$ 和 $CDF_2$。我从两个 CDF 中的一个中提取一些 $x$，但我不知道 $x$ 是从哪一个中提取的。假设$\mathbb{P}(CDF_1) = 0.4$和$\mathbb{P}(CDF_2) = 0.6$。我相信这会产生 $E[x] = \mathbb{P}(CDF_1)\frac{0.8}{2} + \mathbb{P}(CDF_2)\frac{1.2}{2} = 0.52$。
关键问题：一旦我观察到已实现的 $x$，我想知道下次抽奖的最新期望。
示例：

$x$ 从 $U[0,0.8]$ 抽取，概率为 $0.4$，并且从 $U[0.2,1]$ 抽取概率为 $0.6$。

我观察到一些已实现的 $x_1$，比如 $x_1 = 0.4$。

根据这一观察，下一次抽取 $x$ 的预期值是多少？即：$E[x_2 | x_1 = 0.4]$

相关问题：在观察到 $x_1$ 后，$x$ 的分布是什么？


标准贝叶斯方程不起作用，因为自然 $\mathbb{P}(x_1 = 0.4) = 0$ 因为我们有一个连续分布。据我所知，连续贝叶斯方程对于 $x_1$ 的范围有更好的定义。
上述设置让我想到的是假设检验，它也会问“给定一些实际结果，真实参数遵循给定分布的可能性有多大”，但我不太确定我们是否可以在这里直接转化这种思维方式（例如，我们能否查看尾部概率来得到解决方案？）。
如能得到任何帮助，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/657150/updating-a-continuous-cdf-after-observing-realised-draw-from-same-cdf</guid>
      <pubDate>Tue, 12 Nov 2024 16:39:20 GMT</pubDate>
    </item>
    <item>
      <title>零点的中位绝对偏差</title>
      <link>https://stats.stackexchange.com/questions/657149/median-absolute-deviation-of-zero</link>
      <description><![CDATA[我使用 MAD 来衡量不同数字数据分布的分布范围，其中一些分布的 MAD 为 0。我很好奇，这怎么可能呢？如果我理解正确的话，MAD 是衡量数据集变异性的指标。我检查了一下，这些数据集的观测值并非全部相同。如果是这样的话，MAD 怎么会是零呢？
对于那些好奇的人来说，我在 R 中使用了 mad() 函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/657149/median-absolute-deviation-of-zero</guid>
      <pubDate>Tue, 12 Nov 2024 16:39:02 GMT</pubDate>
    </item>
    <item>
      <title>柯西分布数据的模型比较</title>
      <link>https://stats.stackexchange.com/questions/657142/model-comparison-on-data-with-cauchy-distribution</link>
      <description><![CDATA[我感兴趣的是确定状态位置对磁场的依赖性。状态位置是通过将缩放的柯西分布拟合到表示每个磁场值的状态的峰值来确定的。然后构建一个似然函数，该函数由各个柯西分布及其拟合中位数和伽马值组成。

其中  表示磁场函数，该函数模拟峰值位置对磁场的依赖性，并通过最大化可能性，确定  中的拟合参数。
我想测试  的三个模型。
零假设是 B 独立的：
第一个替代方案添加了一个线性项：
第二个替代方案有一个二次项而不是线性项：
我想获得零假设的 p 值，然后确定如果零假设被拒绝，哪个备选假设更适合。为此，我研究了似然比检验和威尔克斯定理，该定理将检验统计量  近似为卡方分布

但是，我不确定结果是否可信，因为我只有 46 个不同磁场值的峰值位置。
为了获得实际分布，我对由 46 对峰值位置和磁场组成的全样本进行了非参数引导替换它是在 (B, ) 处拍摄的。这导致原始数据集上的测试统计量围绕测试统计量呈近似对称分布。这是有道理的，因为我预计某些数据点的残差会比其他数据点小。
为了使引导程序工作，我认为我需要在每个磁场值下多次运行相同的测量。这样，我将获得每个磁场的峰值位置分布，可以在引导程序期间重新采样。不幸的是，我无法进行更多测量，所以我正在寻找其他选择。]]></description>
      <guid>https://stats.stackexchange.com/questions/657142/model-comparison-on-data-with-cauchy-distribution</guid>
      <pubDate>Tue, 12 Nov 2024 13:53:40 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中应用 scale() 后数据分布的变化</title>
      <link>https://stats.stackexchange.com/questions/657141/change-in-data-distribution-after-applying-scale-in-r</link>
      <description><![CDATA[我对在 R 中应用 scale() 后分布的变化有疑问。如果我的整个过程是错误的，我将非常乐意接受建议、更正和建议。
当我尝试使用 lmer() 构建 LMM 时，由于数据处于不同的尺度，我遇到了收敛问题。我正在预测特定时间思维方向的比例 (0 - 1.00)，以及醒来后的小时数（视为连续变量；醒来后 0-17 小时）、注意力需求 (0-6) 和特定问卷的分数 (累计分数 16-86)。
根据我的（有限的）知识，缩放数据不应显著改变数据的分布。因此，缩放变量“注意力需求”和“问卷分数”后，原始数据的分布保持不变。然而，在醒来后的几个小时内，分布发生了（轻微的）变化。
原始分布：

缩放后的分布：

为什么我会观察到分布中的这些变化？我很乐意阅读本论坛或一些文献中现有的任何答案，因为我无法在我熟悉的资源中找到答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/657141/change-in-data-distribution-after-applying-scale-in-r</guid>
      <pubDate>Tue, 12 Nov 2024 13:51:36 GMT</pubDate>
    </item>
    <item>
      <title>广义加性模型中的平滑因子相互作用</title>
      <link>https://stats.stackexchange.com/questions/657140/smooth-factor-interactions-in-generalized-additive-models</link>
      <description><![CDATA[我目前正在尝试理解 GAM 模型中的平滑因子相互作用，但我很难理解主效应和交互效应之间的分离。考虑以下简单函数：
$$
f(x) = \sin(x) + A + A\times \cos(x), 
$$
其中 $A$ 是取值为 0 或 1 的因子变量。
对我来说，将不同的术语视为：
$\sin(x)$：协变量 x 的主要影响
$A$：因子变量的主要影响
$A\times\cos(x)$：A 和 x 之间的相互作用。
我现在构建一个合成数据集，如下所示如下：
data &lt;- expand.grid(x = seq(0,10), A = c(0,1))
data$y &lt;- sin(data$x) + data$A + data$A*cos(data$x)
data$A &lt;- as.factor(data$A)

我使用一个简单的交互模型来拟合这些：
model &lt;- mgcv::gam(y ~ s(x) + A + ti(x, by = A),
data = data,
family = gaussian(),
method = &quot;REML&quot;)

我天真的期望是这个模型能够准确恢复上面的主要和交互效应。但这不是我从模型摘要或结果平滑中看到的。我的模型规范是否错误，或者我误解了平滑因子相互作用？
系列：高斯

链接函数：身份

公式：
y ~ s(x) + A + ti(x, by = A)

参数系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.12829 0.07626 1.682 0.126 
A1 0.96205 0.10785 8.920 7.28e-06 ***
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df F p 值 
s(x) 6.675 7.738 12.784 0.000457 ***
ti(x):A0 2.666 2.827 5.253 0.028219 * 
ti(x):A1 1.342 1.474 0.892 0.406407 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

排名：18/19
R-sq.(adj) = 0.937 偏差解释 = 97.2%
-REML = 19.568 尺度估计 = 0.063974 n = 22

s(x):

ti(x,A=0):

ti(x,A=1)
]]></description>
      <guid>https://stats.stackexchange.com/questions/657140/smooth-factor-interactions-in-generalized-additive-models</guid>
      <pubDate>Tue, 12 Nov 2024 12:23:29 GMT</pubDate>
    </item>
    <item>
      <title>执行单样本加权 t 检验的自由度是多少</title>
      <link>https://stats.stackexchange.com/questions/657139/what-are-the-degrees-of-freedom-for-performing-a-1-sample-weighted-t-test</link>
      <description><![CDATA[我对一批生命中的死亡经历进行了 7 年的观察。我假设每年的经历与其他年份无关。对于每一年，我们都有一个预期死亡人数和一个实际死亡人数。我想对实际死亡人数与预期死亡人数的比率进行加权 t 检验，以检验 A/E 是否不等于 1。
权重表示该年经验的可信度。
我可以计算加权样本均值 x_bar，本文 (https://seismo.berkeley.edu/~kirchner/Toolkits/Toolkit_12.pdf) 解释了如何获取加权样本方差。
我还可以通过将 root(n) 替换为 root(权重平方和/权重平方和) 来计算适当的检验统计量。
我的问题与临界值和自由度有关。我不确定如何计算自由度。我的直觉是自由度应该只是 6，因为我们有 7 个独立观察值，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/657139/what-are-the-degrees-of-freedom-for-performing-a-1-sample-weighted-t-test</guid>
      <pubDate>Tue, 12 Nov 2024 12:21:52 GMT</pubDate>
    </item>
    <item>
      <title>带样条协变量的逻辑回归模型</title>
      <link>https://stats.stackexchange.com/questions/657144/logistic-regression-model-with-splines-covariates</link>
      <description><![CDATA[我正在尝试在 R 中构建一个逻辑回归模型，并且正在使用样条函数检查某些协变量是否可能遵循非线性分布。
我使用的数据集是威斯康星州乳腺癌：
例如，我通过执行以下命令检查了 fractal_dimension_mean 列的线性
fit.splines.fractal &lt;- lrm(diagnosis ~ rcs(fractal_dimension_mean, 4), data=data)
print(fit.splines.fractal) # non linear

我得到了这个：
Coef S.E. Wald Z Pr(&gt;|Z|)
截距 -2.4383 0.4609 -5.29 &lt;0.0001
fractal_dimension_mean -2.1338 0.4876 -4.38 &lt;0.0001
fractal_dimension_mean&#39; 9.3886 2.3722 3.96 &lt;0.0001 
fractal_dimension_mean&#39;&#39; -23.0268 6.2039 -3.71 0.0002

现在据我所知，这个变量的分布似乎是非线性的，因此我应该考虑将此列的复数形式添加到模型中。
所以我所做的就是创建一个函数来添加这些变量的复杂形式，并尝试对模型变量使用前向选择方法：
spline_vars &lt;- c(&quot;texture_se&quot;, &quot;fractal_dimension_mean&quot;)

# formula:
formula &lt;- as.formula(paste(
&quot;diagnosis ~&quot;, 
paste(
lapply(names(data), function(var) {
if (var %in% spline_vars) {
paste0(&quot;rcs(&quot;, var, &quot;, 4)&quot;) # rcs() for splines
} else if (var != &quot;diagnosis&quot;) {
var # 保留变量而不进行变换
}
}), 
collapse = &quot; + &quot;
)
))

model_null &lt;- glm(diagnosis ~ 1, data = data, family = binomial) # 空模型
model_full &lt;- glm(formula, data = data, family = binomial) # 完整模型

# 正向选择
model_forward &lt;- stepAIC(model_null, scope = list(lower = model_null, upper = model_full), direction = &quot;forward&quot;)
summary(model_forward)

现在，由于经过转换的变量的重要性，我认为模型会将这些变量作为协变量，但与使用不带转换的前向选择方法相比，我获得了更大的 AIC 和对数似然。我做错了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657144/logistic-regression-model-with-splines-covariates</guid>
      <pubDate>Tue, 12 Nov 2024 12:02:15 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助 F 统计要求</title>
      <link>https://stats.stackexchange.com/questions/657134/need-help-f-statistics-requirment</link>
      <description><![CDATA[我做论文的时候卡在F检验，之前用0.05或者5%的概率值，但是检验结果不够或者超出条件，现在想试试用0.1或者10%的概率值来满足条件。
我的问题是，10%的概率值有没有依据或者参考，这个概率值一定要是5%吗？有参考资料的请帮忙，谢谢
我现在在eviews 10上使用面板模型]]></description>
      <guid>https://stats.stackexchange.com/questions/657134/need-help-f-statistics-requirment</guid>
      <pubDate>Tue, 12 Nov 2024 10:18:11 GMT</pubDate>
    </item>
    </channel>
</rss>