<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 21 Aug 2024 12:28:51 GMT</lastBuildDate>
    <item>
      <title>仅具有一个 Dense 层的神经网络</title>
      <link>https://stats.stackexchange.com/questions/653113/neural-network-with-just-one-dense-layer</link>
      <description><![CDATA[我有一个模型，仅使用一个 Dense 层即可很好地运行。我的模型有一个输入层、一个 Dense 层，然后是一个 Reshape 层，它将输出重塑为所需的形式。通常，神经网络模型由一个或多个隐藏层和一个输出层组成。如果我添加另一个 Dense 层，我的模型的性能肯定会提高，然后我可以说我的模型有一个隐藏层和一个输出层。
但是在只有一个 Dense 层的情况下，该层应该被视为隐藏层还是输出层？]]></description>
      <guid>https://stats.stackexchange.com/questions/653113/neural-network-with-just-one-dense-layer</guid>
      <pubDate>Wed, 21 Aug 2024 12:17:34 GMT</pubDate>
    </item>
    <item>
      <title>如何比较两个非线性模型拟合</title>
      <link>https://stats.stackexchange.com/questions/653110/how-to-compare-two-non-linear-model-fits</link>
      <description><![CDATA[我正在处理两个包含叶片参数（气体交换、温度和湿度）的数据集。每个数据集都来自一个采样点。我使用 NLS 模型来拟合使用温度和湿度的气体交换。现在我想知道两个站点在叶片气体交换方面是否不同，一开始我认为对所有三个参数进行简单的 t 检验就可以了，但后来我认为最好测试一下模型本身是否不同，但我不确定最好的方法是什么。
如果这是一个线性模型，我会比较斜率，但有一个指数分量。我应该采用嵌套方法来测试似然比吗？或者有没有更好更简单的方法来测试它们是否不同？
任何帮助或评论都值得赞赏]]></description>
      <guid>https://stats.stackexchange.com/questions/653110/how-to-compare-two-non-linear-model-fits</guid>
      <pubDate>Wed, 21 Aug 2024 10:36:36 GMT</pubDate>
    </item>
    <item>
      <title>观察数据效应大小的荟萃分析——如何处理一项研究的多个结果</title>
      <link>https://stats.stackexchange.com/questions/653108/meta-analyses-with-effect-sizes-from-observational-data-how-to-handle-mutiple</link>
      <description><![CDATA[我希望使用调整后的优势比和置信区间（使用 Stata）进行我的第一个荟萃分析。
我特别关注的是具有两个子类的一类群体。
我从一项队列研究中获得了以下结果：

子类 I 与未暴露：aOR 1.71（0.78 – 3.78）
子类 II 与未暴露：aOR 2.17（1.20 -3.91）
子类 II 与子类 I：aOR 1.27（0.57 - 2.82）

理想情况下，我希望得到整体类别与未暴露的优势比，即子类 I/子类 II 与未暴露（假设子类相互独家）。
如果可以做到上述情况，或者我是否应该同时包括上述1）和2）的结果（尽管我认为这可能会过分强调这项单独的研究），我非常希望得到建议。
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653108/meta-analyses-with-effect-sizes-from-observational-data-how-to-handle-mutiple</guid>
      <pubDate>Wed, 21 Aug 2024 09:31:41 GMT</pubDate>
    </item>
    <item>
      <title>通过大量观察来检验 2 个以上变量的独立性</title>
      <link>https://stats.stackexchange.com/questions/653107/testing-more-than-2-variables-for-independence-with-many-observations</link>
      <description><![CDATA[给定一个包含 165 个变量的数据表，每个变量大约有 8000 个观测值（例如，每个邮政编码的犯罪率、每个邮政编码的居民人数，...）
我想挑选出其中几个变量并测试它们的独立性，因为我想将这些变量用于随机森林。
不幸的是，我无法找到适合我的问题的测试。另一个问题是观测的数量。
有谁知道在有这么多观测值的情况下测试预选变量（可能在 80 到 100 个左右）的独立性的合适方法吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653107/testing-more-than-2-variables-for-independence-with-many-observations</guid>
      <pubDate>Wed, 21 Aug 2024 09:09:51 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯模型在数据截止处缺失异常值</title>
      <link>https://stats.stackexchange.com/questions/653099/bayesian-model-missing-outliers-at-cutoff-in-data</link>
      <description><![CDATA[我无法让模型拟合。在加热实验中，我得到了珊瑚中叶绿素的 ED50 值。我有 4 个珊瑚礁遗址和 4 种珊瑚，每个遗址物种组约有 14 种珊瑚。数据向右倾斜，因为几个异常值的值为 45 的临界点，因为它们的叶绿素水平没有下降太多。以下是数据的箱线图

这是我通常使用的模型公式
 NDVIsandbox.form &lt;- bf(ED50 | trunc(lb = 0, ub = 60) ~ Site*Species,
sigma = ~ Site*Species,
family = student(link = &quot;identity&quot;))

我也尝试过使用 skew_normal 家庭分布，但看起来不太合适
以下是我用作弱先验的先验。我已经修改了其中的许多内容，试图让它更好地适应，但这并没有真正起到帮助作用
priors &lt;-prior(normal(38.5, 3), class = &#39;Intercept&#39;) +
prior(student_t(3, 0, 0.5), class = &#39;Intercept&#39;, dpar = &#39;sigma&#39;) +
prior(normal(0.2, 2), class = &#39;b&#39;) +
prior(gamma(4, 1), class = &#39;nu&#39;) +
prior(normal(0, 0.5), class = &#39;b&#39;, dpar = &#39;sigma&#39;)

然后我运行模型
NDVIsandbox.brm1 &lt;-brm(NDVIsandbox.form,
data = Geno_ED50s %&gt;%filter(Type == &quot;NDVI&quot;) %&gt;% droplevels(),
prior = priority,
sample_prior = &#39;yes&#39;,
iter = 5000,
warmup = 1000,
chains = 3,
cores = 3,
thin = 5,
backend = &#39;cmdstanr&#39;,
control=list(adapt_delta=0.99),
refresh = 100)

我进行了常规跟踪图检查和其他指标，它们看起来都很好，但是当我使用 dens_overlays 进行 pp_check 时，它不太合适，并且它错过了 45 处的大部分值，这是 ED50 值的截止值，如下图所示
 NDVIsandbox.brm1 |&gt; pp_check(type = &#39;dens_overlay&#39;, ndraws = 100)


我还运行了一个函数，该函数为我提供了 brm 模型上的 Dharma 图，它显示它高估了较小和较大的值，您也可以在上面的 dens_overlay 图上看到

我想知道我是否可以做些什么来让它识别 45 处增加的点数，这是因为它是 ED50 模型的截止点。没有可以运行的膨胀型模型，例如 0 和 1 之间的模型分布。我让模型在 glmm 上运行（见下文），但我想尝试让贝叶斯模型工作，因为我在论文中还有其他贝叶斯模型
modNDVI &lt;- glmmTMB(ED50 ~ Site * Species,
data = Geno_ED50s %&gt;% filter(Type ==&quot;NDVI&quot;) %&gt;% 
droplevels(),
dispformula = ~ Site * Species, 
family = t_family(link = &quot;identity&quot;),
REML=TRUE)
]]></description>
      <guid>https://stats.stackexchange.com/questions/653099/bayesian-model-missing-outliers-at-cutoff-in-data</guid>
      <pubDate>Wed, 21 Aug 2024 05:51:00 GMT</pubDate>
    </item>
    <item>
      <title>当风险差异如此容易解释时，为什么 Cohen's h 对于比较比例有用？</title>
      <link>https://stats.stackexchange.com/questions/653098/why-is-cohens-h-useful-to-compare-proportions-when-risk-difference-is-so-interp</link>
      <description><![CDATA[当风险差异如此易于解释时，为什么 Cohen&#39;s h 可用于比较比例？
我认为这与标准化不同比例量级的比较有关（例如，当 $p_{1}$ 和 $p_{2}$ 分别接近 0、接近 0.5 和接近 1 时，$p_{1}-p_{2}$）。
但我很难在脑海中将其形式化。]]></description>
      <guid>https://stats.stackexchange.com/questions/653098/why-is-cohens-h-useful-to-compare-proportions-when-risk-difference-is-so-interp</guid>
      <pubDate>Wed, 21 Aug 2024 05:46:44 GMT</pubDate>
    </item>
    <item>
      <title>使用（错误的）正态分布获取 95％CI 图 - R 或 Minitab</title>
      <link>https://stats.stackexchange.com/questions/653095/getting-95-ci-graph-using-wrong-normal-distribution-either-r-or-minitab</link>
      <description><![CDATA[我试图在课堂上演示以下内容。
我有 N=50 个总体数据点，其数字如下：5.1、3.2、...、2.8。真实总体平均值为 $\mu=3.3$，这在现实中是未知的。
我通过 SRSWOR（无放回）对 n=5 进行抽样，以获得样本估计值 $\bar{x}=\frac{x_1+...+x_5}{5} = 2.1$。假设样本标准差为：
$$ \sqrt\frac{1}{4}\times\sqrt{(x_1 - 2.1)^2 + ...+(x_5 - 2.1)^2} \approx 1.3$$
现在，我从样本中获取样本均值的标准误差的估计值，如下所示：
$$\widehat{SE}(\bar{X})=\sqrt\frac{45}{49}\times\sqrt\frac{1}{5}\times1.3\approx 0.56$$
现在，我想演示一下取 $2.1 \pm 1.96 \times 的过程0.56 美元（当然，对于不同的样本）不会是 95% CI，因为 1.96 是正态分布的值，而不是自由度为 4 的 t 分布，其值在 2.7764 时更高。
我当然可以通过 Excel 模拟来做到这一点，但它很麻烦。是否有可能在 R 或 Minitab 中执行此“错误”计算，在其中我可以获得一个漂亮的图表，该图表模拟 100 个这样的间隔，并表明如果我使用 1.96 而不是 2.7764，大约少于 95 个这样的 CI 将包含 3.3 的真实总体值？]]></description>
      <guid>https://stats.stackexchange.com/questions/653095/getting-95-ci-graph-using-wrong-normal-distribution-either-r-or-minitab</guid>
      <pubDate>Wed, 21 Aug 2024 04:41:51 GMT</pubDate>
    </item>
    <item>
      <title>预测变量与响应变量的观测值不匹配</title>
      <link>https://stats.stackexchange.com/questions/653101/mismatch-in-observations-for-predictor-vs-response-variables</link>
      <description><![CDATA[我有一个数据集，其中只有几个预测变量（2-3 个），但有数百万个观测值。这些数据代表了幼鱼在进入渔场之前几年穿越海洋的日常身体状况。响应变量是招募，大约是每年加入成年鱼群的个体数量的 30 个值。所以，我遇到的问题是，我有一个很棒的数据集，其中包含大约 2-3 个预测变量和大量观测值（数百万），我需要使用它们来建模一个只有很少观测值（约 30 个）的响应变量。
我已经按年份进行了总结，并使用混合模型和 GAM 对招募进行了建模，但这样做会丢失很多信息。从数百万个数据点减少到 30 个...我知道我必须先以某种方式总结数据，因为它太大了，但仍然感觉不好。
有没有办法，我可以使用预测变量的大量观测值来模拟响应变量的少量观测值？时间序列分析，或者引导法？]]></description>
      <guid>https://stats.stackexchange.com/questions/653101/mismatch-in-observations-for-predictor-vs-response-variables</guid>
      <pubDate>Wed, 21 Aug 2024 01:59:20 GMT</pubDate>
    </item>
    <item>
      <title>优化正定矩阵的简单问题</title>
      <link>https://stats.stackexchange.com/questions/653090/simple-problem-of-optimizing-a-positive-definite-matrix</link>
      <description><![CDATA[我正在编写一个关于约束优化的简单教程。我计划使用两个示例：约束一个向量具有单位范数，约束一个矩阵为对称正定矩阵。我想用合成数据来提供一些此类优化的非常简单的示例。
例如，对于单位范数约束，我生成单位圆上分布的随机样本，然后优化一个向量 $\theta$，以最小化到样本的平均平方距离。当不约束 $\theta$ 时，结果不在单位圆内，而添加约束后，我们得到一个在单位圆内的 $\theta$。
我试图想出一个同样简单直观的问题，涉及优化某个应该是正定的矩阵 $\Sigma$。但是，我想不出任何简单明了的东西。例如，如果我们想按照上述方法操作并找到最小化与一组正定矩阵的距离的矩阵，则不受约束的结果将是正定的。我曾考虑过使用一个损失函数将 $\Sigma$ 推向非 SPD 矩阵，但后来我猜想优化过程不会收敛。
因此，我的问题是，矩阵 $\Sigma$ 上的一些简单的、表现良好的优化问题是什么，直观地了解我们为什么要让它是正定的，以及如果我们在优化中不包含约束，它在哪里不会是正定的？我希望能够在我的教程中用不太多的代码为我的问题合成数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/653090/simple-problem-of-optimizing-a-positive-definite-matrix</guid>
      <pubDate>Tue, 20 Aug 2024 22:33:09 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中对两个样本进行加权中值检验？</title>
      <link>https://stats.stackexchange.com/questions/653096/how-to-do-a-weighted-median-test-for-two-samples-in-r</link>
      <description><![CDATA[我有两个样本（第 1 组和第 2 组），每个样本包含 1) 一个收入变量和 2) 一个权重变量，表示每个观察值的权重。
我只是想测试两个样本（第 1 组和第 2 组）的收入中位数在统计上是否有差异。
我知道如果不考虑权重，我可以使用 Mood 的中位数检验，但是有没有办法在考虑每个观察值的权重的同时进行中位数检验？
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/653096/how-to-do-a-weighted-median-test-for-two-samples-in-r</guid>
      <pubDate>Tue, 20 Aug 2024 20:50:53 GMT</pubDate>
    </item>
    <item>
      <title>BCa bootstrap CI 调整 A-B 组中位数差异的偏差，但不调整相反方向的偏差</title>
      <link>https://stats.stackexchange.com/questions/653083/bca-bootstrap-ci-adjusts-for-bias-in-median-difference-of-groups-a-b-but-not-th</link>
      <description><![CDATA[我正在使用 R 中的 boot-package 来计算两组 A 和 B 之间等待时间中位数差异的 BCa bootstrap 间隔，四舍五入到天数。按照 boot 中的符号，让原始样本的中位数差异为 $t0$，中位数的 bootstrap 复制为 $t$。
每组的等待时间都是长尾的，但大部分质量集中在一小组离散值上。总体而言，bootstrap 分布将 20% 的质量放在 $t0$ 的左侧，40% 的质量放在 $t0$ 处，40% 放在 $t0$ 的右侧。每组的总样本量约为 100。
令我惊讶的是，我注意到 BCa 置信区间存在很大差异，这取决于我估计的是“A 组中位数 - B 组中位数”还是“B 组中位数 - A 组中位数”。百分位数 CI 的情况并非如此，因为方向的改变只会翻转 y 轴周围的引导分布，t 一个方向的 2.5 百分位数对应于翻转引导分布的 97.5 百分位数。
但是，由于 $t0$ 周围的 20/40/40 分布，BCa 中的偏差校正参数 $z_0$ 有效地重新排列了 $\alpha=0.05$ 在 B-A 方向上的程度远高于 A-B 方向。
$$ z_0 = \Phi^{-1}(\Sigma(t&lt;t0)/B)$$
对于我的数据，在 A-B 中，使用 BCa 时 bootstrap 分布的百分位数变为 0.0001 和 0.6，而在 B-A 方向，则为 0.01 和 0.92。 boot 包正确地发出了关于“BCa 区间使用极端分位数，某些 BCa 区间可能不稳定”的警告。
[]
如果我相信偏差校正正在做一些明智的事情（但我不确定，见下文），它告诉我，由于对 40% 侧存在强烈偏差，偏差调整后的中位数差异应该强烈推向 20% 侧，在 20% 侧尾部，我们实际上不能相信引导分布在极端尾部是可靠的。
但我想知道这是否与大量质量集中在 $t0$ 有关，我不会认为这是偏差。获得对称边界的可能解决方案是均匀分布在 $t0$ 的质量，例如通过平滑引导程序（例如，在每个原始等待时间中添加 Uniform[-0.5, 0.5]），或者更少地涉及，将 $t0$ 处的质量减半并将其归因于每个尾部，即
$$ z_0 = \Phi^{-1}((\Sigma(t&lt;t0) + 1/2 \Sigma(t = t0))/B)$$
使用此定义可获得对称结果，即 A-B 的下限和 B-A 的上限的结果相同。
如果有人可以从 BCa 中的某些假设中激发这种分裂，或者如果您发现该提案等存在任何潜在问题，将非常乐意听到任何关于此的评论。
编辑以回应whuber：使用不同的种子，结果是一致的，使用 5000 次重复，在不同批次中得到一致的结果。还添加了一张图片来突出显示该问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/653083/bca-bootstrap-ci-adjusts-for-bias-in-median-difference-of-groups-a-b-but-not-th</guid>
      <pubDate>Tue, 20 Aug 2024 20:46:33 GMT</pubDate>
    </item>
    <item>
      <title>准确计算截断二项式期望</title>
      <link>https://stats.stackexchange.com/questions/653081/compute-a-truncated-binomial-expectation-accurately</link>
      <description><![CDATA[我需要计算二项式随机变量的以下期望值
$$E_{S \sim \rm{Binom}(\frac{k}{M}; N)} \left[\left(\frac{k-1}{k}\right)^S 1_{\{S \leq k\}}\right] = \sum_{s=0}^k \binom{N}{s} \left(\frac{k}{M}\right)^s \left(1 - \frac{k}{M}\right)^{N-s} \left(\frac{k-1}{k}\right)^s.$$
变量的典型范围是 $0 &lt; k \leq 256$，$M = N = 10^9$。如果 $k = N$，则可以使用二项式 RV 的独立伯努利分解来很好地评估。如果不存在 $\left(\frac{k-1}{k}\right)^s$ 项，则这是二项式的累积分布函数，等于不完全 Beta 积分，并且在数值上相当稳定。但是，如何以数值稳定的方式处理上述混合公式？我不需要它很快，只需要给我合理的数字而不是 nan 或类似的数字 $&gt; 1$.
更新：为了完整性，总和可以用超几何函数重写
$$\sum_{s=0}^k \binom{N}{s} p^s q^{N-s} = q^N\left((1 + p/q)^N - (p/q)^{k+1} \binom{N}{k+1} {}_2F_1(1, k-N + 1; k + 2; -p/q)\right),$$
其中
\begin{align*}
{}_2F_1(a, b; c; z) := \sum_{n=0}^\infty \frac{(a)_n(b)_n}{(c)_n} \frac{z^n}{n!}.
\end{align*}
但是对于非常大的 $N$，这会导致数字溢出。总和在 $n &gt; N - k + 1$ 之后终止，但不值得用 $k+1$ 项的总和与具有更多项的总和进行权衡。]]></description>
      <guid>https://stats.stackexchange.com/questions/653081/compute-a-truncated-binomial-expectation-accurately</guid>
      <pubDate>Tue, 20 Aug 2024 20:03:48 GMT</pubDate>
    </item>
    <item>
      <title>MNAR 问题的巨大潜力——我们还可以在 R 中使用 MI，即 mice() 吗？</title>
      <link>https://stats.stackexchange.com/questions/653078/strong-potential-of-mnar-issue-can-we-still-use-mi-i-e-mice-in-r</link>
      <description><![CDATA[研究目标：估计在最多 5 年的随访期内经历结果 Y（1=是，0=否）的患者比例。
缺失数据问题：大部分人的结果 Y 缺失（96% 缺失）。对于我们观察到的结果 Y 数据，大多数都有结果（78% 的结果 Y=1），因为我们只验证了我们怀疑经历过结果的人的结果数据。这样做是出于效率原因 - 为了验证那些有真实 Y 的人，我们必须仔细检查医疗记录，这非常耗时。我们预计，研究人群中缺失结果 Y 的其余部分不会有相同的结果 Y 患病率。事实上，我们认为患病率要低得多 - 可能为 5-10%。
问题：鉴于我们确实存在缺失而非随机 (MNAR) 问题（即数据缺失的原因与值本身有关），我们能否使用我们拥有的数据将结果 Y 归因于研究人群的其余部分？我们的归因模型中确实有很多结果 Y 的强预测因子，并且归因模型中也有可疑 Y 的标记，因此至少可以解释部分缺失数据机制。但考虑到未观察样本（5-10%）与观察样本（78%）中结果 Y 的预期百分比有多么不同，我对使用 MI 持谨慎态度……]]></description>
      <guid>https://stats.stackexchange.com/questions/653078/strong-potential-of-mnar-issue-can-we-still-use-mi-i-e-mice-in-r</guid>
      <pubDate>Tue, 20 Aug 2024 19:23:48 GMT</pubDate>
    </item>
    <item>
      <title>向 2x2 方差分析添加控制组</title>
      <link>https://stats.stackexchange.com/questions/653050/adding-a-control-group-to-a-2x2-anova</link>
      <description><![CDATA[我正在开展一项包含 2 个因素的实验，其中将向参与者提供有关任务的反馈。因素 1 是效价（正面或负面），因素 2 是反馈细节（低与高）。因此每个因素都有 2 个级别。
此外，我想添加一个完全不会被操纵的对照组（无反馈）。
目的是测试此反馈对任务持久性的影响。
然后我想比较反馈与无反馈、正面与负面反馈以及高细节与低细节，以及这两个因素之间是否存在相互作用。
所以我很困惑 - 这个对照组应该被视为一个因素吗？如果是，它将代表哪个因素？还是它将代表两个因素？然后如何将其分析为 3x3 方差分析而不是 2x2？
此外，我假设如何分析数据的决定也会影响对照组的大小？]]></description>
      <guid>https://stats.stackexchange.com/questions/653050/adding-a-control-group-to-a-2x2-anova</guid>
      <pubDate>Tue, 20 Aug 2024 13:35:58 GMT</pubDate>
    </item>
    <item>
      <title>寻找统计函数来表示数据</title>
      <link>https://stats.stackexchange.com/questions/653041/looking-for-statistical-function-to-represent-data</link>
      <description><![CDATA[假设我有一个包含 9 个原子的分子。对于每个原子，我使用某种方法计算了 prop_1、prop_2...prop_5 的属性。为了检查该方法是否稳定，我对每个属性进行了 10 次相同的计算。每次运行，我都有 MAE、maxAE 和 RMSE 值。例如，对于 prop_1，每个原子有 10 个 MAE、10 个 RMSE 和 10 个 maxAE 值。
我试图弄清楚两件事，

现在，假设对于 prop_1，我想报告 prop_1 上所有运行的数字（例如平均值 +- SD）。除了平均值+-SD之外，还有其他统计函数可以使用吗？

合并所有属性并检查方法的稳定性是否合理？


我是化学专业的，请原谅我的无知。]]></description>
      <guid>https://stats.stackexchange.com/questions/653041/looking-for-statistical-function-to-represent-data</guid>
      <pubDate>Tue, 20 Aug 2024 09:25:29 GMT</pubDate>
    </item>
    </channel>
</rss>