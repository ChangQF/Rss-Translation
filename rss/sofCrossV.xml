<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 11 Jan 2025 12:30:24 GMT</lastBuildDate>
    <item>
      <title>M 估计量的一致性条件</title>
      <link>https://stats.stackexchange.com/questions/659869/conditions-of-m-estimator-to-be-consistent</link>
      <description><![CDATA[我从渐近统计学（Van der Vaart，1998）定理 5.7 中读到，要让 M 估计量 $\hat{\theta}_n$ 有概率收敛到 $\theta_0$，需要满足两个条件，其中一个条件是对于每个 $\epsilon&gt;0$，
$$\sup_{\theta:d(\theta,\theta_0)\geq\epsilon}M(\theta)&lt;M(\theta_0).$$
这个不等式看起来很复杂，涉及到度量 $d$，这让我很困惑。为什么我们不能删除度量，将其表示为
$$\forall\theta\neq\theta_0,M(\theta)&lt;M(\theta_0)$$
这两者不是等价的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659869/conditions-of-m-estimator-to-be-consistent</guid>
      <pubDate>Sat, 11 Jan 2025 10:00:26 GMT</pubDate>
    </item>
    <item>
      <title>证明具有非常量转移概率的马尔可夫链的终止性质</title>
      <link>https://stats.stackexchange.com/questions/659866/proving-termination-properties-of-a-markov-chain-with-non-constant-transition-pr</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659866/proving-termination-properties-of-a-markov-chain-with-non-constant-transition-pr</guid>
      <pubDate>Sat, 11 Jan 2025 09:20:35 GMT</pubDate>
    </item>
    <item>
      <title>无法拟合高斯混合模型，估计错误参数</title>
      <link>https://stats.stackexchange.com/questions/659851/cant-fit-gaussian-mixture-model-estimates-wrong-parameters</link>
      <description><![CDATA[下面的测试从高斯混合模型生成样本，然后对其进行拟合。
拟合模型与原始模型完全不同。为什么？这怎么可能呢，结果不只是稍微不同——错误是巨大的。

原文：weights=[0.5, 0.5], means=[0, 0], sigmas=[1, 2]
拟合：weights=[0.525, 0.475], means=[-0.617, 0.716], sigmas=[1.434, 1.443]
代码（带图的完整代码)
import numpy as np
from sklearn.mixture import GaussianMixture

def fit_normal_mixture(*, n_components, values, random_state, n_init):
values = np.array(values).reshape(-1, 1) # 转换为 2D 数组
nmm = GaussianMixture(n_components, covariance_type=&#39;diag&#39;, random_state=random_state, n_init=n_init)
nmm.fit(values)
means = nmm.means_.flatten().tolist()
sigmas = np.sqrt(nmm.covariances_.flatten()).tolist()
weights = nmm.weights_.flatten().tolist()
return weights, means, sigmas

def sample_normal_mixture(*, weights, means, sigmas, n):
if not np.isclose(sum(weights), 1):
raise ValueError(&quot;Weights must sum to 1&quot;)
components = np.random.choice(len(weights), size=n, p=weights)
return np.random.normal(loc=np.array(means)[components], scale=np.array(sigmas)[components])

# 测试
if __name__ == &#39;__main__&#39;:
# 从正态混合模型生成样本
nmm_sample = sample_normal_mixture(weights=[0.5, 0.5], means=[0, 0], sigmas=[1, 2], n=10000)

# 将样本拟合到正态混合模型
print(fit_normal_mixture(n_components=2, values=nmm_sample, random_state=0, n_init = 10))

附言：是否可以告诉拟合算法使用 0 作为平均值？]]></description>
      <guid>https://stats.stackexchange.com/questions/659851/cant-fit-gaussian-mixture-model-estimates-wrong-parameters</guid>
      <pubDate>Sat, 11 Jan 2025 06:59:18 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯后验预测均值比确定性预测更嘈杂吗？</title>
      <link>https://stats.stackexchange.com/questions/659848/bayesian-posterior-predictive-mean-is-noisier-than-deterministic-predictions</link>
      <description><![CDATA[由于复杂性，我使用后验预测均值进行预测，而不是完整的后验预测分布。具体来说，我计算：
$\mathbb{E}[y_* \mid x_*, \mathcal{D}] = \int f(x_*, \theta) p(\theta \mid \mathcal{D}) \, d\theta$，
其中 $f(x_∗ ,θ)$ 是给定参数 $θ$ 的模型输出，而 $p(\theta∣\mathcal{D})$ 是给定数据 $\mathcal{D}$ 的 $θ$ 的后验。
然而，我观察到后验预测均值比完全确定性模型的预测噪声更大。
具体来说：

0% 贝叶斯，（左图）：确定性模型（使用 MSE 训练的 $f(x_*,θ)$）可产生平滑且准确的点预测。
50% 贝叶斯：使用具有固定方差的均值场 VI（即，在 ELBO 中将 MSE 视为“NLL”）会在均值预测中引入一些噪声。
100% 贝叶斯，（右图）：允许模型预测均值和方差 σ(x)（即，在 ELBO 中使用适当的 NLL）会进一步增加噪声。

确定性与贝叶斯（均值）预测的比较


这种平均预测的退化是贝叶斯建模中已知的问题吗？如果是，这种行为的根本原因是什么，如何解决？]]></description>
      <guid>https://stats.stackexchange.com/questions/659848/bayesian-posterior-predictive-mean-is-noisier-than-deterministic-predictions</guid>
      <pubDate>Sat, 11 Jan 2025 00:21:13 GMT</pubDate>
    </item>
    <item>
      <title>使用图查看标量样本和矢量样本是否具有线性关系</title>
      <link>https://stats.stackexchange.com/questions/659847/using-plot-to-see-if-a-scalar-sample-and-a-vector-sample-has-a-linear-relationsh</link>
      <description><![CDATA[假设我们有 $N$ 个样本，每个样本都是一个具有 $p+1$ 个分量的向量：
\begin{equation*}
(y_i, x_{i,1}, \cdots, x_{i, p}) = (y, \mathbf x_i) \quad (1\le i\le N)。
\end{equation*&gt;
通过减去平均值，我们可以假设 $y$ 和 $\mathbf x$ 的平均值 $0$ 和 $\mathbf 0$。
我们进一步假设 $y$ 和 $\mathbf x$ 服从正态分布。
假设我想测试 $y$ 和 $\mathbf x$ 是否具有线性关系。
如果 $\mathbf x$ 是标量，我们可以绘制 $(x_i, y_i)$ ($1\le i\le N$) 的散点图。
但现在 $\mathbf x$ 是一个向量。如果我使用最小二乘法找到了一个向量 $\mathbf a$
，该向量最小化 $$ \sum_{i=1}^{N} (y_i - \langle \mathbf a, \mathbf x_i \rangle ) ^2, $$
，并且我发现 $ (\langle \mathbf a, \mathbf x_i \rangle, y_i) $ 的图并不集中在直线 $y=x$ 附近，
那么我是否可以拒绝承认 $y$ 和 $\mathbf x$ 之间存在线性关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/659847/using-plot-to-see-if-a-scalar-sample-and-a-vector-sample-has-a-linear-relationsh</guid>
      <pubDate>Fri, 10 Jan 2025 23:57:28 GMT</pubDate>
    </item>
    <item>
      <title>Yahoo! Webscope ydata-frontpage-todaymodule-clicks-v1_0 数据集中出现意外功能 ID [关闭]</title>
      <link>https://stats.stackexchange.com/questions/659846/unexpected-feature-id-in-yahoo-webscope-ydata-frontpage-todaymodule-clicks-v1-0</link>
      <description><![CDATA[我正在使用 Yahoo! Webscope 数据集 ydata-frontpage-todaymodule-clicks-v1_0（具体来说，是 2009 年 5 月前十天的点击日志）。数据集描述指出，每个用户和文章都有 6 个特征，编号为 1 到 6。特征 #1 是一个常数（始终为 1），特征 #2-6 是通过联合分析构建的。格式为 feature_id:feature_value 对。
但是，我发现有些文章的特征值为 feature_id = 7。下面是出现这种情况的示例行：

1241196300 109522 0 |user 2:0.008078 3:0.005109 4:0.000172 5:0.007422 6:0.979220 1:1.000000 |109523 2:0.316894 3:0.000023 4:0.210890 5:0.198013 6:0.274180 1:1.000000 |109498 2:0.306008 3:0.000450 4:0.077048 5:0.230439 6:0.386055 1:1.000000 |109509 2:0.306008 3:0.000450 4:0.077048 5:0.230439 6:0.386055 1:1.000000 |109508 2:0.264355 3:0.000012 4:0.037393 5:0.420649 6:0.277591 1:1.000000 |109473 2:0.295442 3:0.000014 4:0.135191 5:0.292304 6:0.277050 1:1.000000 |109524 2:0.274868 3:0.000032 4:0.046639 5:0.362209 6:0.316252 1:1.000000 |109527 2:0.375829 3:0.000025 4:0.033041 5:0.349637 6:0.241468 1:1.000000 |109520 2:0.016328 3:0.953419 4:0.000538 5:0.008263 6:0.021452 1:1.000000 |109503 2:0.306008 3:0.000450 4:0.077048 5:0.230439 6:0.386055 1:1.000000 |109510 2:0.287909 3:0.000025 4:0.008983 5:0.511333 6:0.191751 1:1.000000 |109526 2:0.432433 3:0.000002 4:0.069055 5:0.351774 6:0.146736 1:1.000000 |109495 2:0.313277 3:0.000125 4:0.018413 5:0.410555 6:0.257630 1:1.000000 |109506 2:0.264355 3:0.000012 4:0.037393 5:0.420649 6:0.277591 1:1.000000 |109512 2:0.297322 3:0.000025 4:0.034951 5:0.413566 6:0.254137 1:1.000000 |109511 2:0.381149 3:0.000129 4:0.060038 5:0.269129 6:0.289554 1:1.000000 |109514 2:0.297750 3:0.000013 4:0.011603 5:0.512182 6:0.178452 1:1.000000 |109528 7:1.000000 |109522 2:0.214605 3:0.000037 4:0.410493 5:0.097704 6:0.277162 1:1.000000 |109515 2:0.281649 3:0.000173 4:0.195994 5:0.151003 6:0.371182 1:1.000000 |109525 2:0.306008 3:0.000450 4:0.077048 5:0.230439 6:0.386055 1:1.000000 |109513 2:0.211406 3:0.000036 4:0.002773 5:0.569886 6:0.215900 1:1.000000

具体来说，article_id=109528的文章有特征7:1.000000，这是意料之外的。有没有其他人遇到过此数据集的问题？对于为什么会出现这种差异以及在解析数据时如何处理这种差异，您有什么见解吗？这是否表明数据集中可能存在更广泛的问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659846/unexpected-feature-id-in-yahoo-webscope-ydata-frontpage-todaymodule-clicks-v1-0</guid>
      <pubDate>Fri, 10 Jan 2025 23:56:52 GMT</pubDate>
    </item>
    <item>
      <title>理解相互矛盾的 Cox 回归结果</title>
      <link>https://stats.stackexchange.com/questions/659845/understanding-conflicting-cox-regression-results</link>
      <description><![CDATA[我有一个数据集，其中我使用 Cox 模型检查生存时间与血清胆固醇水平之间的关联，同时调整 BMI 和性别。我以两种不同的方式进行了分析，但难以协调两种不同方法之间的结果：
方法 1：对整个数据集进行 Cox 回归，以生存为结果，以胆固醇、BMI 和性别为预测变量。
coxph(Surv(time = survivor_time, event = censor_status) ~ cholesterol + BMI + sex, data = df)
这导致输出结果为胆固醇与生存时间相关 (P &lt; 0.05)。 BMI 和性别的风险比并不显著，这表明胆固醇与生存时间相关，与本分析中的性别和 BMI 无关（解释正确吗？）

方法 2：Cox 回归，同时将数据集分层为男性和女性队列，而不使用性别作为预测变量：
#女性患者
coxph(Surv(time = survivor_time, event = censor_status) ~ cholesterol + BMI, data = filter(df, sex == &quot;F&quot;))

#男性患者
coxph(Surv(time = survivor_time, event = censor_status) ~ cholesterol + BMI, data = filter(df, sex == &quot;M&quot;))

这导致输出结果为女性患者的胆固醇与生存时间之间没有关联队列，但在男性队列中胆固醇与生存率之间确实存在关联。这难道不表明性别确实是决定胆固醇是否与生存时间相关的一个因素吗？为什么方法 1（其中性别被作为整个数据集中的预测变量）表明胆固醇与生存率相关，而与性别无关？]]></description>
      <guid>https://stats.stackexchange.com/questions/659845/understanding-conflicting-cox-regression-results</guid>
      <pubDate>Fri, 10 Jan 2025 23:37:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么因果参数不能提供最佳的预测性能？</title>
      <link>https://stats.stackexchange.com/questions/659818/why-causal-parameters-does-not-give-best-predictive-performance</link>
      <description><![CDATA[假设我们有一些协变量 $X$ 和目标 $Y$，它们来自线性因果模型。
我读到，估计因果参数可能会导致对测试数据的预测性能保守，而如果对测试数据的干预不是太极端，OLS 可能会提供更好的性能，因此我们通常更喜欢使用其他系数（如 OLS），这些系数与因果系数相比不那么保守。
但我不明白为什么会这样。如果我们知道因果模型（即生成数据的代理）的系数，为什么这些系数与来自“错误”模型（在某种意义上，它不是真正的底层模型）的其他一组系数相比表现不佳？我不明白这种直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/659818/why-causal-parameters-does-not-give-best-predictive-performance</guid>
      <pubDate>Fri, 10 Jan 2025 11:21:04 GMT</pubDate>
    </item>
    <item>
      <title>（Fisher z）相关性的平均值与平均值的相关性</title>
      <link>https://stats.stackexchange.com/questions/659787/mean-of-fisher-z-correlations-vs-correlation-of-means</link>
      <description><![CDATA[这可能是一个基本问题，但我花了很长时间试图找到答案，但通常都失败了。
我进行了一项实验，尝试使用新方法多次复制固定变量 X0=[1,2,3,4,5,6,7,8,9,10]，这会产生新变量 X1、X2、...Xi。
评估复制率的一种方法是计算 X0 与 X1...Xi 的分段平均值之间的相关性，从而得到十个均值。我们称之为 r_means。
另一种方法是首先计算 X0 与每个复制 X1...Xi 之间的相关性，然后对这些相关性求平均值（使用或不使用 Fisher z 变换并返回）。那将是 Mean_r
我不断得到非常不同的值 r_means 和 Mean_r，但我无法找出导致差异的原因。我意识到 X1、...Xi 的方差以某种方式参与其中，但无法找到具体原因。
是否有人知道 r_means 和 Mean_r 之间（潜在）差异所涉及的因素？
更新。根据要求，我提供了更多详细信息。我正在开展蒙特卡罗模拟研究，X0 是真实参数的向量。我使用这些参数来模拟数据，然后使用旨在恢复 X0 的新模型对其进行分析。这些方法通过 i 次模拟估计 X1...Xi。
我已经检查了覆盖范围，但我真正感兴趣的是参数的排序，因此我查看了 X0 与每个（或平均）X1...Xi 之间的相关性。Mean_r 和 r_means 是否显示差异？了解发生这种情况的原因可能会对评估模型的问题提供见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/659787/mean-of-fisher-z-correlations-vs-correlation-of-means</guid>
      <pubDate>Thu, 09 Jan 2025 17:00:20 GMT</pubDate>
    </item>
    <item>
      <title>估计量与合并 OLS/随机效应之间</title>
      <link>https://stats.stackexchange.com/questions/659235/between-estimator-versus-pooled-ols-random-effects</link>
      <description><![CDATA[例如，我熟悉 Hausman 检验可以帮助我选择固定效应模型和随机效应模型中哪个更好。但是，是否有一个检验可以帮助我在估计模型（例如，在 R 中使用 plm(y~x, model=&quot;between&quot;) 实现）与池化 OLS（plm(y~x, model=&quot;pooling&quot;)）和随机效应模型（plm(y~x, model=&quot;random&quot;)）之间进行选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/659235/between-estimator-versus-pooled-ols-random-effects</guid>
      <pubDate>Thu, 26 Dec 2024 16:59:24 GMT</pubDate>
    </item>
    <item>
      <title>在 3 之前出现差值 2 的概率是多少？</title>
      <link>https://stats.stackexchange.com/questions/630801/what-is-the-probability-a-difference-of-two-appears-before-3</link>
      <description><![CDATA[给定一个试验序列，其中每次试验都会掷两个骰子，每次试验的结果都是骰子上的值的绝对差。结果 2 先于结果 3 出现的概率是多少？
我的解决方案：
有 8 种组合，差值为 2 {(1,3), (2,4), (3,5), (4,6), (3,1), (4,2), (5,3), (6,4)}，那么概率是不是就是 8/36？]]></description>
      <guid>https://stats.stackexchange.com/questions/630801/what-is-the-probability-a-difference-of-two-appears-before-3</guid>
      <pubDate>Wed, 08 Nov 2023 23:06:34 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的 Johansen 协整检验（统计模型）</title>
      <link>https://stats.stackexchange.com/questions/600918/johansen-cointegration-test-in-python-statsmodels</link>
      <description><![CDATA[我有三个时间序列 df[&#39;a&#39;]、df[&#39;b&#39;] 和 df[&#39;c&#39;]，我想使用 statsmodels.tsa.vector_ar.vecm.coint_johansen 函数测试它们的协整性（并获得协整向量）。
我首先使用 ADF 测试确保所有三个时间序列均为 I(1)。
ADF 测试级别：
statsmodels.tsa.stattools.adfuller(df[&#39;a&#39;]) 给出较大的 p 值，因此我们得出结论，时间序列是非平稳的。测试根据 AIC 给出最佳滞后长度 2。 df[&#39;b&#39;] 和 df[&#39;c&#39;] 上的 ADF 检验同样给出了较大的 p 值，最佳滞后长度分别为 4 和 7。
一阶差分中的 ADF 检验：
statsmodels.tsa.stattools.adfuller(df[&#39;a&#39;].diff().dropna()) 给出的 p 值 &lt; 0.05，因此我们得出结论，时间序列在一阶差分中是平稳的，因此是 I(1)。类似地，我们得出结论，df[&#39;b&#39;] 和 df[&#39;c&#39;] 是 I(1)。
我现在准备使用 Johansen 检验来测试协整...
result = statsmodels.tsa.vector_ar.vecm.coint_johansen(df[[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]], det_order=0, k_ar_diff=???)
...但我不确定要使用什么作为滞后长度。它应该是 2，应该是 4，应该是 7，还是应该用其他方式确定？
此外，我对 Johansen 检验的结果有几个问题：


我们是否从上述结果得出结论，协整秩为 3，意味着有 3 个独立的协整向量？
如果是这样，我们如何选择使用哪个协整向量来形成平稳时间序列？只使用第一个 coint_vec = result.evec[:,0] 是否合适？
最后，我的分析中是否缺少任何步骤？我读到了一些关于检查 VAR 模型残差是否不自相关的内容 - 我们是否可以使用 Johansen 检验的 result.r0t 或 result.rkt 输出之一来执行此操作？
]]></description>
      <guid>https://stats.stackexchange.com/questions/600918/johansen-cointegration-test-in-python-statsmodels</guid>
      <pubDate>Wed, 04 Jan 2023 20:56:09 GMT</pubDate>
    </item>
    <item>
      <title>正态分布与异常分布之间的 Kullback–Leibler 散度</title>
      <link>https://stats.stackexchange.com/questions/589585/kullback-leibler-divergence-between-normal-distribution-and-improper-distributio</link>
      <description><![CDATA[假设我有一个高斯分布$p(x;\mu,\sigma^{2})=N(x;\mu,\sigma^{2})$和一个不正确的分布$p(x)\propto 1, x\in \mathbb{R}.$
我想计算这两个分布之间的概率距离，为此我使用 Kullback–Leibler 散度。
$$KL(p(x;\mu,\sigma^{2}),p(x)) = \int p(x;\mu,\sigma^{2})\frac{p(x;\mu,\sigma^{2})}{p(x)}$$
由于$p(x)$赋予所有实线正密度，因此我们有$p(x;\mu,\sigma^{2})$与$p(x)$绝对连续。因此，我们可以继续计算$KL$。
然后是$KL(p(x;\mu,\sigma^{2}),p(x))= log(\frac{1}{2\pi \sigma^{2}})+\sqrt{2\pi}|\sigma|^{3}$
这个计算正确吗？？我浏览了链接高斯分布与均匀分布之间的 KL 散度，这让我怀疑我的计算是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/589585/kullback-leibler-divergence-between-normal-distribution-and-improper-distributio</guid>
      <pubDate>Wed, 21 Sep 2022 16:15:00 GMT</pubDate>
    </item>
    <item>
      <title>一个人从窗外看到一棵树的概率是多少？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/571798/what-is-the-probability-a-person-sees-a-tree-by-looking-out-of-the-window</link>
      <description><![CDATA[我熟悉基本概率规则，问题的形式如下：

抛硬币掷出正面的概率是多少？0.5
如果从集合 {1, 2, 3, 4} 中均匀随机地选择一个数字，掷出 3 的概率是多少？0.25

更复杂的问题形式如何计算？例如：假设从窗户可以看到两棵树，那么一个人从窗户向外看时看到一棵树的概率是多少？
有很多事情需要考虑：

人的眼睛视力。
一天中的时间（如果是日落之后，周围有多少个灯泡）
他看的方向。
树有多高？
这个人在特定时刻能通过药物测试吗？
他有妄想史吗？

还有无数种可能导致看到/看不到树的可能性。鉴于我们没有从同一扇窗户看到树的人的频率，如何以任何精度计算概率？假设我们 100% 确信从 {1, 2, 3, 4} 中得到 3 的概率是 0.25，我们有多大把握？如果我们什么都没有给出，在这种情况下问题与标题相同，该怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/571798/what-is-the-probability-a-person-sees-a-tree-by-looking-out-of-the-window</guid>
      <pubDate>Sat, 16 Apr 2022 04:51:38 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用方差分析比较两个模型？</title>
      <link>https://stats.stackexchange.com/questions/515373/comparing-2-models-with-anova-in-r</link>
      <description><![CDATA[我很难解释这个结果。
我有 2 个模型
Model_1 &lt;- lm(formula = gamble ~ income * gender)
Model_2 &lt;- lm(formula = gamble ~ income + gender)

现在，我很难理解它们是否嵌套，如果是，哪一个是满的，哪一个是减少的。
然后，如果我尝试使用 anova(Model_1, Model_2) 选择一个更好的，我会得到这个输出：
** 模型 1：gamble ~ income * gender
模型 2：gamble ~ income + factor(gender)
Res.Df RSS Df Sum of Sq F Pr(&gt;F) 
1 43 18930 
2 44 22781 -1 -3851.4 8.7486 0.005018 **

看起来 $p$ 值对其中一个模型有显著影响。会是哪一个？]]></description>
      <guid>https://stats.stackexchange.com/questions/515373/comparing-2-models-with-anova-in-r</guid>
      <pubDate>Tue, 23 Mar 2021 22:30:32 GMT</pubDate>
    </item>
    </channel>
</rss>