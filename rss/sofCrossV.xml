<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 23 Sep 2024 03:21:45 GMT</lastBuildDate>
    <item>
      <title>影响 1/2 结果的多个相关变量的统计分析方法</title>
      <link>https://stats.stackexchange.com/questions/654749/statistical-method-for-analysis-of-multiple-related-variables-affecting-1-2-outc</link>
      <description><![CDATA[我将抽象化这个问题以隐藏我实际的研究内容，但我绝对是统计分析方面的菜鸟，我想向这个网站的大神们学习更多。
我目前正在研究睡眠时间、是否生病以及白天的工作时间，以及这些因素在一年的时间内如何导致抑郁症的发展。另一个结果是他们因抑郁而产生暴力倾向。
我想调查的是这些因素对每个结果的独立影响，以解释潜在的混杂因素（因为抑郁是众所周知的暴力倾向的诱因，但我想看看这些因素是否会导致即使没有抑郁也会产生暴力倾向）。
我最初在 MANCOVA 和多元线性回归之间争论，但我不确定我应该如何处理这个问题。对所用方法还有其他建议吗？在此先向那些愿意帮助我的人表示感谢。这对我来说意义重大，是一次学习经历。]]></description>
      <guid>https://stats.stackexchange.com/questions/654749/statistical-method-for-analysis-of-multiple-related-variables-affecting-1-2-outc</guid>
      <pubDate>Mon, 23 Sep 2024 02:39:35 GMT</pubDate>
    </item>
    <item>
      <title>如何判断分类变量或变量之间的相互作用是否影响连续结果变量</title>
      <link>https://stats.stackexchange.com/questions/654748/how-to-see-if-a-categorical-variable-or-interactions-between-variables-affects-a</link>
      <description><![CDATA[(1) 通常，如果我有一个非序数的、具有许多唯一值的分类变量 (X)，以及一个连续、高度偏斜（根本不是正态分布）的结果变量，那么应该使用哪种测试或技术来查看是否存在任何关系？
(2) 我正在尝试进行推断研究，目前处于测试每个独立变量对结果连续变量的影响的阶段（然后我将尝试一些方法来测试某些变量之间的相互作用）。我的下一个问题是，我们如何将一个分类变量（例如，已经编码的）和一个连续变量（非正态分布）结合起来，并使用这种相互作用或新创建的特征来查看它如何影响结果变量？
对于第一种情况，我遇到了 Kruskal-Wallis 检验，但仍在努力仔细理解。但是您处理此类案件的经验是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654748/how-to-see-if-a-categorical-variable-or-interactions-between-variables-affects-a</guid>
      <pubDate>Mon, 23 Sep 2024 02:20:55 GMT</pubDate>
    </item>
    <item>
      <title>R 包 aTSA 中的 ARCH-LM 检验统计量</title>
      <link>https://stats.stackexchange.com/questions/654745/arch-lm-test-statistic-in-r-package-atsa</link>
      <description><![CDATA[我想执行 ARCH-LM 测试。首先，我自己计算了 LM 统计量，方法是将平方残差回归为常数和 p 滞后值。根据 Engle (1982)，LM 统计量是 TR^2，其中 T 个观测值和 R^2 作为辅助回归的判定系数。
然后，我尝试了 aTSA 中的 arch.test() 函数，它返回了完全不同的值，行为完全相反。顺序越大，统计量越小。此外，考虑到顺序=自由度、统计量和 p 值的组合，统计量似乎不是卡方分布。以下是我的步骤：
#访问数据

library(yfR)
CVX_data=yf_get(
tickers = &quot;CVX&quot;,
first_date = &quot;2020-01-02&quot;,
last_date = &quot;2021-12-31&quot;)

#计算数据

attach(CVX_data)
close_ln=c(log(price_adjusted))
close_ln_d=c(NA, diff(log(price_adjusted)*100))

#新格式

new_df=data.frame(ref_date, price_adjusted, close_ln, close_ln_d)
new_df_2=new_df[-c(1),]
comp_data=new_df_2[,4]

#ARCH 测试

ARM=arima(comp_data, order=c(2,0,0))
library(aTSA)
arch.test(ARM)

有人能解释一下这个差异吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654745/arch-lm-test-statistic-in-r-package-atsa</guid>
      <pubDate>Mon, 23 Sep 2024 00:30:45 GMT</pubDate>
    </item>
    <item>
      <title>如何简化径向图网络同时保留关键信息？</title>
      <link>https://stats.stackexchange.com/questions/654742/how-can-i-simplify-a-radial-graph-network-while-preserving-key-information</link>
      <description><![CDATA[我创建了一个径向图网络来可视化大脑区域之间的连接。每个区域都用一个圆圈表示，每个区域使用独特的颜色。圆圈边框表示组/子网络成员身份，大小反映网络度量（中介中心性）。然而，使用多种颜色似乎会增加读者的认知负荷。您能否建议一些简化可视化的方法，同时保留以下三个关键方面：
1. 确定哪个节点代表哪个大脑区域及其连接
2. 指示子网络成员身份
3. 显示节点的大小以表示网络度量尺度

]]></description>
      <guid>https://stats.stackexchange.com/questions/654742/how-can-i-simplify-a-radial-graph-network-while-preserving-key-information</guid>
      <pubDate>Sun, 22 Sep 2024 22:54:05 GMT</pubDate>
    </item>
    <item>
      <title>如何使用生存分析对不同期限的分期付款进行建模？</title>
      <link>https://stats.stackexchange.com/questions/654738/how-to-model-installment-payments-with-different-durations-using-survival-analys</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654738/how-to-model-installment-payments-with-different-durations-using-survival-analys</guid>
      <pubDate>Sun, 22 Sep 2024 19:55:11 GMT</pubDate>
    </item>
    <item>
      <title>均值较小的逆高斯分布具有不可靠的样本均值</title>
      <link>https://stats.stackexchange.com/questions/654737/inverse-gaussian-with-small-mean-has-unreliable-sample-mean</link>
      <description><![CDATA[考虑一个平均值为$\mu$（如$0.001$）的逆高斯分布，我们将其方差固定为一个较大的值$\sigma^2$，比如说$0.5$。然后，如果我从该分布中抽取 $N$ 次样本，我预计样本平均值约为 $\mu$，但除非 $N$ 的值非常大，否则这种情况不会发生。
import scipy as sp

N = 1_000 # 我们至少需要使用 10_000_000，否则它会非常小，比如 1e-6 
mean = 0.001
var = 0.5
lmbda = mean**3 / var

print(f&quot;样本平均值：{sp.stats.invgauss.rvs(mu=(mean/lmbda), loc=0, scale=lmbda, size=N).mean()}&quot;)

如果您运行此脚本N 等于 1000、10_000、1_000_000，您将得到大约 1e-6，其数量级与均值的平方相同。

为什么会出现这种情况，我该如何避免？即，我可以从均值较小、方差相对较大的逆高斯中采样，而不会产生数值问题吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/654737/inverse-gaussian-with-small-mean-has-unreliable-sample-mean</guid>
      <pubDate>Sun, 22 Sep 2024 19:23:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么 VAE 损失中的期望项在实际中没有实现？</title>
      <link>https://stats.stackexchange.com/questions/654736/why-expectation-term-in-vae-loss-not-implemented-in-practical</link>
      <description><![CDATA[根据 VAE 论文：https://arxiv.org/pdf/1906.02691（等式 2.10，第 21 页）
VAE 损失包含期望项。如果我理解正确的话，我们需要从输入 x 中抽取超过 1 个结果并平均其损失以满足期望项。但我发现许多实现只抽取一个结果，但为什么呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/654736/why-expectation-term-in-vae-loss-not-implemented-in-practical</guid>
      <pubDate>Sun, 22 Sep 2024 18:52:47 GMT</pubDate>
    </item>
    <item>
      <title>损失函数——在一个数据点还是所有数据点上计算？</title>
      <link>https://stats.stackexchange.com/questions/654735/loss-function-computed-on-one-data-point-or-on-all-data-points</link>
      <description><![CDATA[我正在尝试阅读 Jerome H. Friedman 关于梯度提升决策树的讲座。不幸的是，我对统计学和数学的理解非常肤浅，我感到很困惑，所以我希望这里有人能帮忙。
Friedman 谈到了似乎在单个数据点上评估的损失函数。在他的符号中，训练样本是集合 $\{ (\vec{x_1},y_1),(\vec{x_2},y_2),...,(\vec{x_N},y_N)\}$。每个 $\vec{x_i}$ 都是一组输入值，每个 $y_i$ 都是一个标量，即相应的输出值（他实际上将该集合缩写为 $\{y_i,\vec{x_i}\}_1^N$）。
然后他将损失函数定义为 $L(y,F(\vec{x}))$。具体来说，$y$ 未标记为向量，因此我认为他谈论的是单个标量值。 $F(\vec{x})$ 也可以解释为标量，因为 $F(\vec{x})$ 表示模型 $F$ 的输出，我们用它来近似数据集的真实样本。我们将单个数据点输入到这个模型中，得到标量输出。
因此，根据 Friedman 的说法，损失函数似乎是在每个数据点上单独计算的。
但在大多数地方，损失函数被定义为所有输入和输出的函数。例如，均方误差 (MSE) 定义为：
MSE = $\frac{1}{n}\sum_{i=1}^n (Y_i-\hat{Y}_i)^2$ 这里 $\hat{Y_i}$ 对应于弗里德曼的 $F(\vec{x_i})$。
因此，很明显，MSE 是针对所有输入和所有输出定义的。
Friedman 继续声明，拟合模型是通过操纵 F 来计算 $E_{y,\vec{x}}(L(y,F(\vec{x}))$ 的最小值的过程。这是对所有可能的输入和输出的损失函数的期望。
具体来说：$F^{*}=argmin_{F} E_{y,\vec{x}}(L(y,F(\vec{x}))$
但实际上，我们优化的是最小 MSE。
这是对同一事物的离散/连续解释吗？还是我读错了？]]></description>
      <guid>https://stats.stackexchange.com/questions/654735/loss-function-computed-on-one-data-point-or-on-all-data-points</guid>
      <pubDate>Sun, 22 Sep 2024 18:30:02 GMT</pubDate>
    </item>
    <item>
      <title>用于近似离散随机变量分布的 KL 散度误差的量化</title>
      <link>https://stats.stackexchange.com/questions/654734/quantification-of-kl-divergence-error-for-approximating-a-distribution-over-disc</link>
      <description><![CDATA[我想知道以下已在某些文献中提及但从未明确证明的内容
考虑一个由长度为 n 的随机变量的二进制向量组成的设置，例如 $\vec{v}=(v_0,v_1,v_2....v_n)$，其中每个 $v_i \in \{1,-1\}$。让我们定义一个任意分布，该分布定义在 $2^n$ 个随机 $\vec{v}$ 向量的支持上，即 $P(\vec{v}): \{-1,1\}^n \mapsto [0,1]$。声明是，总是可以将 $P(\vec{v})$ 近似地表示为 k 次多线性多项式的指数，如下所示
\begin{equation}
P(\vec{v}) \approx e^{A(\vec{v})}
\end{equation
其中
\begin{equation}
A(\vec{v}) = a_0 + \sum_i c_i v_i + \sum_{i,j, i\ne j} K_{ij} v_i v_j + \sum_{i,j,p, i\ne j\ne p} H_{ijp} v_i v_jv_p + .....\sum_{i,j,p,q.... i\ne j\ne p\ne q ....} G_{ijpq....k} v_i v_jv_pv_q....v_k
\end{equation
并且 $a_0$、$\vec{c}$、$\vec{K}$、$\vec{H}$、...$\vec{G}$ 都是在实数域上定义的。这个说法总是正确的吗？如何证明它？如何量化第一个方程的 RHS 和 LHS 之间的 KL 散度误差？任何正式的证明、参考文献、证明草图都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654734/quantification-of-kl-divergence-error-for-approximating-a-distribution-over-disc</guid>
      <pubDate>Sun, 22 Sep 2024 18:24:33 GMT</pubDate>
    </item>
    <item>
      <title>哪种条件交叉制表解释是合适的？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654729/which-conditional-cross-tabulation-interpretation-is-appropriate</link>
      <description><![CDATA[假设是老年人不太可能说外语。
交叉表结果如下：

我的问题是：在下面的解释中，哪一个是正确的，为什么另一个是错误的？
解释 1：接受假设是因为在回答“是”的人中，37.3% 的人年龄在 30 岁以下，18.7% 的人年龄在 30-39 岁之间，17.5% 的人年龄在 40-49 岁之间，11.6% 的人年龄在 50-59 岁之间，只有 15% 的人年龄在 30 岁以上60.
解释 2：接受假设，因为在回答“是”的人中，70.8% 的人年龄在 30 岁以下，39.6% 的人年龄在 30-39 岁之间，42.1% 的人年龄在 40-49 岁之间，27.5% 的人年龄在 50-59 岁之间，19.3% 的人年龄在 60 岁以上。]]></description>
      <guid>https://stats.stackexchange.com/questions/654729/which-conditional-cross-tabulation-interpretation-is-appropriate</guid>
      <pubDate>Sun, 22 Sep 2024 14:13:19 GMT</pubDate>
    </item>
    <item>
      <title>如何解释具有多个变量和单个变量的 GAM？</title>
      <link>https://stats.stackexchange.com/questions/654727/how-to-interpret-gams-with-multiple-vs-single-variables</link>
      <description><![CDATA[因此，我一直在尝试使用 GAM 来观察总体经济损失（由于某个事件）与各种因素之间的关系，包括事件总数、受影响的总人数、基础设施发展水平等。
以下是我迄今为止尝试过的方法：
library(mgcv)

model1 &lt;-gam(total_damages ~ s(total_events) + s(total_affected) + 
s(coastlines) + s(total_gdp, k=1) + s(urban_landarea) + 
s(infrastructure_index), tw(link=&quot;log&quot;))

我使用了 tw(link=&quot;log&quot;)，因为 total_damages 不是正态分布的。我绘制了一个直方图来检查。我还注意到这个变量的方差比它的平均值大得多。但是，如果在这里使用 tweedie 是错误的，请告诉我。
此外，我不太确定是否应该对所有独立变量使用平滑函数。我注意到 total_gdp 与 total_damages 具有线性关系，因此我设置了 k=1。但是，我不太确定对这么多变量使用平滑函数是否会产生任何影响。
我想向您展示我从这个模型中获得的结果。
summary(model1)


我认为 p 值在这种情况下用处不大。我想知道调整后的 $R^2$ 和“偏差解释”值在这里是否有价值。如果它们在 GAM 中具有重要意义，请告诉我。
我想在此处显示其中一个图表：
plot(model1)


该图显示了独立变量 (infrastructure_index) 和平滑 s(infrastructure_index) 之间的图。该线看起来有点直，但查看系数 (coef(model1)) 告诉我它们经常在负值和正值之间波动。我认为这意味着 infrastructure_index 和 total_damages 之间存在不规则关系？
我尝试对另一个 GAM 进行建模，但这次，我只专注于使用 1 个独立变量“infrastructure_index”。
model2 &lt;- gam(total_damages ~ s(infrastructure_index))

以下是模型摘要：

调整后的 $R^2$ 和偏差解释值下降了。但情节变得更加清晰，我觉得我对基础设施指数和总损害之间的关系有了更清晰的理解：


具有多个变量的 GAM 模型是否是理解独立变量与总损害之间关系的更好工具？

具有单个变量的 GAM 是否不太有用？为什么这两个图表差别这么大？

我什么时候应该使用具有多个变量而不是单个变量的 GAM？

]]></description>
      <guid>https://stats.stackexchange.com/questions/654727/how-to-interpret-gams-with-multiple-vs-single-variables</guid>
      <pubDate>Sun, 22 Sep 2024 10:23:32 GMT</pubDate>
    </item>
    <item>
      <title>离散随机变量的 CDF 分段常数？</title>
      <link>https://stats.stackexchange.com/questions/654695/cdf-of-a-discrete-random-variable-piecewise-constant</link>
      <description><![CDATA[在我的脚本中，它说：

给定$X$是一个离散随机变量，$\Bbb P(X\in D)=1,D=\{a_1,a_2,\ldots\},p_i:=\Bbb P_X(\{a_i\})&gt;0,\forall i\ge1,$我们有$F_X(x)=\sum\limits_{a_i\le x}p_i,$这意味着离散随机变量的CDF是分段常数。

我的想法
假设$X:\Omega\to\Bbb R$是一个离散随机变量，其中$\Bbb P_X(\{q_i\})=\frac1{2^i}&gt;0,$，其中$\{q_i\}_{i\in\Bbb N}$是$\Bbb Q.$的枚举，因为$\Bbb Q$是稠密的，所以对于每两个$x_1,x_2\in\Bbb R,x_1&lt;x_2,$，存在某个$q_j\in(x_1,x_2)$，意味着$q_j\in(x_1,x_2)$ class=&quot;math-container&quot;&gt;$F_X(x_1)&lt;F(x_2).$ 因此，这似乎与 $F_X$ 是分段常数的说法相矛盾，这让我怀疑如果该说法成立，我的随机变量 $X$ 是否存在。
问题：任何离散随机变量的 CDF 确实是分段常数吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654695/cdf-of-a-discrete-random-variable-piecewise-constant</guid>
      <pubDate>Sat, 21 Sep 2024 13:03:38 GMT</pubDate>
    </item>
    <item>
      <title>基于汇总数据的平均差异</title>
      <link>https://stats.stackexchange.com/questions/654693/mean-difference-based-on-summary-data</link>
      <description><![CDATA[我遇到了以下问题：我想评估 5 个平衡组的平均差异，但我只有可用的汇总数据（平均值、标准差和样本大小），以及汇总数据基于正态分布数据的信息。
我愿意听取有关如何进行的建议。
这是一些示例数据（编辑：更新的数据）
data &lt;- data.frame(
group = c(&quot;probe_a&quot;, &quot;probe_b&quot;, &quot;probe_c&quot;, &quot;probe_d&quot;, &quot;control&quot;),
n = c(10, 10, 10, 10, 10), # 每组样本大小
means = c(57.6, 95.9, 102.9, 69.6, 73.8), # 组平均值
sd = c(4.2, 4.0, 2.7, 7.6, 3.6) # 每组标准差
)

我的方法包括使用 Welch 方差分析 来解释方差不等的情况（如果 Hartley 的 Fmax 表明存在这种情况），然后进行事后 Games-Howell 检验（我需要对几个数据框进行此检验，其中一些数据框的方差不等，但我不想在传统方差分析和 Welch 方差分析之间切换，因此我坚持使用更为稳健的方法）。由于我无法直接检查残差，因此我根据汇总数据和正态性假设对残差进行了模拟，并使用引导来评估是否满足正态分布残差和同方差性的假设，使用Shapiro-Wilk 和 Levene 检验。在 5% 的置信水平下，蒙特卡洛 p 值未超过此阈值，这意味着我拒绝了正态性和同方差性的零假设。这表明残差违反了 Welch 方差分析的假设。由于我的猜测不支持这些假设，我得出结论，Welch 方差分析的 p 值具有探索性，而事后结果是精确的。
编辑：澄清了步骤

检验各组间方差不等：

fmax &lt;- max(sd^2)/min(sd^2)
df &lt;- 5
k &lt;- 9

Hartley 的 Fmax 为 7.9，小于表中的临界 Fmax 值（p &lt; 0.05），表明各组间的方差不同

Welch 的方差分析

准确（Welch）方差分析结果的假设是残差呈正态分布且方差同。但是，由于无法访问基础数据，我无法直接评估残差，因此我模拟了基础数据。

使用蒙特卡罗模拟测试残差

我模拟了 5 个与我的数据汇总统计数据相匹配的正态分布组。使用这些模拟数据，我计算了残差并使用 Shapiro-Wilk 和 Levene 检验对其进行了评估。蒙特卡洛 p 值被确定为这些检验中 p 值不超过我选择的显著性水平的比例
# 相关代码片段
set.seed(578)
for (i in 1:n_sim) {
# 使用 rnorm() 为每个组生成模拟数据
simulated_data_list &lt;- lapply(1:length(means), function(j) {
stats::rnorm(n = n[j], mean = means[j], sd = sd[j])
})

# 通过减去组均值来计算残差
means_of_groups &lt;- sapply(simulated_data_list, mean)
residuals_list &lt;- mapply(function(data, mean) data - mean,
simulated_data_list, means_of_groups,
SIMPLIFY = FALSE)

# 执行正态性和同方差检验
sw_pval[i] &lt;- shapiro_wilk_test(residuals_list)
l_pval[i] &lt;- 同方差检验(residuals_list)
}
normality_prop &lt;- mean(sw_pval &lt; 0.05)
homoscedasticity_prop &lt;- mean(l_pval &lt; 0.05)

Shapiro-Wilk 检验 p 值 &lt; 0.05（表明残差非正态分布）的模拟比例：
0.29（n_sim = 5000）
Leven-Test p 值 &lt; 的模拟比例0.05（表明非同方差残差）：
0.49（n_sim = 5000）
我的问题：

这是一种有效的方法吗？
是否有更稳健的方法来获得精确的 p 值，因为蒙特卡罗模拟表明（Welch）方差分析假设被违反（例如通过模拟基础数据进行置换检验）
]]></description>
      <guid>https://stats.stackexchange.com/questions/654693/mean-difference-based-on-summary-data</guid>
      <pubDate>Sat, 21 Sep 2024 11:32:47 GMT</pubDate>
    </item>
    <item>
      <title>逻辑函数的自然动机？[重复]</title>
      <link>https://stats.stackexchange.com/questions/654739/natural-motivation-for-logistic-function</link>
      <description><![CDATA[我一直在学习机器学习，最近学到的方法之一是用于分类问题的逻辑回归。为了简单起见，我们假设每个数据点只有一个特征$x_i$，其响应为$y_i \in \{0, 1\}$，因此我们的预测函数将是
$$p_c(x)=\frac{1}{1+e^{-c_0-c_1x}}.$$
我理解逻辑回归的要点及其作用。我不明白的是它从何而来。我发现逻辑函数具有许多优良特性。是否有可能将逻辑函数视为（也许）唯一具有一系列优良特性的函数？如果是这样，那么这些属性是什么？我如何证明任何这样的函数都会导致逻辑回归？如果不是，从第一原理推导出这种函数的最自然方法是什么？
附注：我确实注意到这里有其他类似的问题，但没有一个能完全回答我的问题。我查看了几乎所有与逻辑回归/函数相关的 stack exchange 问题，包括你发送的那些。我也在《统计学习要素》上读过相关内容，但在那里他们从对概率比取对数开始，而我也很难理解他们的动机。]]></description>
      <guid>https://stats.stackexchange.com/questions/654739/natural-motivation-for-logistic-function</guid>
      <pubDate>Wed, 18 Sep 2024 15:04:30 GMT</pubDate>
    </item>
    <item>
      <title>二项式检验和 Jeffreys 检验之间有什么联系？</title>
      <link>https://stats.stackexchange.com/questions/619765/what-is-the-connection-between-binomial-and-jeffreys-test</link>
      <description><![CDATA[通常，我会使用二项式检验来测试违约概率模型的校准。欧洲央行建议使用 Jeffreys 检验。
它们之间有关联吗？ Jeffreys 检验是否在任何方面优于简单的二项式检验？
目标是将预测成功率（默认值）与实际成功率进行比较。

请参阅https://www.bankingsupervision.europa.eu/banking/tasks/internal_models/shared/pdf/instructions_validation_reporting_credit_risk.en.pdf]]></description>
      <guid>https://stats.stackexchange.com/questions/619765/what-is-the-connection-between-binomial-and-jeffreys-test</guid>
      <pubDate>Mon, 26 Jun 2023 11:43:34 GMT</pubDate>
    </item>
    </channel>
</rss>