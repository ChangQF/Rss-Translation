<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 16 Mar 2024 03:14:36 GMT</lastBuildDate>
    <item>
      <title>在双稳健框架中估计结果回归时，是否应该以治疗变量为条件？</title>
      <link>https://stats.stackexchange.com/questions/642731/should-you-condition-on-the-treatment-variable-when-estimating-the-outcome-regre</link>
      <description><![CDATA[寻找一些正式的论点/证据，说明为什么或为什么不以双稳健估计的处理变量为条件，就像 Susan Athey 在因果随机森林方面的工作一样。]]></description>
      <guid>https://stats.stackexchange.com/questions/642731/should-you-condition-on-the-treatment-variable-when-estimating-the-outcome-regre</guid>
      <pubDate>Sat, 16 Mar 2024 00:34:17 GMT</pubDate>
    </item>
    <item>
      <title>垂直与水平尺度感知差异的实验证据</title>
      <link>https://stats.stackexchange.com/questions/642730/experimental-evidence-for-differences-in-perception-on-vertical-vs-horizontal-s</link>
      <description><![CDATA[我正在寻找克利夫兰或其他任何人进行的实验研究，这些研究根据数据是否以水平布局和垂直布局呈现来测试定量判断（或视觉感知的相关方面）的准确性差异。

我一般都知道 Cleveland 的工作（例如 Cleveland 和 McGill 1984、1987）以及其他人随后进行的许多类似实验（例如 Heer 和 Bostock 2010、Kennedy 2016），但是我不知道有任何明确考虑水平方向和垂直方向的。 此答案下面的评论表明，第 1 章中有一些材料。克利夫兰 Elements of Graphing Data 的 1985 年版 4；我在互联网档案馆上查看了修订版（1994），但没有看到任何内容； 我必须等待通过馆际互借获得第一版的副本我在网上发现了 1985 年版的盗版 PDF，在第 1 章中没有看到任何相关内容。 4 那里要么（只有我已经知道的“克利夫兰等级制度”的东西）...

我知道有关 水平布局与垂直布局的相对优点，但据我所知，这些都归结为（1）易用性的标准标签定位/阅读 (2) 特定领域的文化习俗 (3) 视觉隐喻 (4) 整体呈现布局/可用空间（例如，参见 这里，没有任何关于感知的内容。（我也认为我已经看到了关于感知是否会有所不同的猜测习惯于横向[主要是从左到右]阅读的西方文化和习惯于垂直阅读的东方文化之间......）


如果实验还没有完成，也许有人应该尝试一下......
&lt;小时/&gt;
克利夫兰，威廉·S.和罗伯特·麦吉尔。 1984。“图形感知：图形方法开发的理论、实验和应用。”美国统计协会杂志 79 (387): 531–54。 https://doi.org/10.2307/2288400。
——。 1987.“图形感知：数据图形显示上定量信息的视觉解码。”皇家统计学会杂志。 A 系列（综述）150 (3)：192–229。 https://doi.org/10.2307/2981473。
埃利奥特，肯尼迪。 2016 年。“30 分钟内关于人类感知的 39 项研究。”肯尼迪·埃利奥特（博客）。 2016 年 5 月 2 日。 https:// medium.com/@kennelliott/39-studies-about- human-perception-in-30-mines-4728f9e31a73。
希尔、杰弗里和迈克尔·博斯托克。 2010.“众包图形感知：使用 Mechanical Turk 评估可视化设计。”载于 SIGCHI 计算系统人为因素会议记录，203-12。 ACM。]]></description>
      <guid>https://stats.stackexchange.com/questions/642730/experimental-evidence-for-differences-in-perception-on-vertical-vs-horizontal-s</guid>
      <pubDate>Fri, 15 Mar 2024 23:51:34 GMT</pubDate>
    </item>
    <item>
      <title>关于AR(3)模型</title>
      <link>https://stats.stackexchange.com/questions/642729/about-ar3-model</link>
      <description><![CDATA[问题给出一个 AR(3) 过程，即 $$(CB^3 - CB^2 + B + 1)X_t = W_t$$，如果过程是非平稳的，求出$$C$$的所有值？
我知道当它是平稳的时，那么 AR 多项式的所有根 $$CB^3 - CB^2 + B + 1 = 0$$ 应该位于在单位圆之外。但我怎样才能解这个多项式来求根呢？我真的不知道如何开始。]]></description>
      <guid>https://stats.stackexchange.com/questions/642729/about-ar3-model</guid>
      <pubDate>Fri, 15 Mar 2024 23:32:35 GMT</pubDate>
    </item>
    <item>
      <title>使用不正确的先验时如何生成数据</title>
      <link>https://stats.stackexchange.com/questions/642727/how-is-data-generated-when-using-an-improper-prior</link>
      <description><![CDATA[设 $X$ 为 $\mathcal{X}$ 值随机变量。我们正在做贝叶斯统计。假设 $\theta$ 是一个具有已知先验分布的 $\Theta$ 值随机变量 $\Pi$ 并且常规条件概率 $P_{X \mid \theta}$ 已知。如果 $\Pi$ 正确（即 $\Pi(\Theta)=1$），则我们将 $X$ 视为一个随机变量，对于任何可测量的 $P_X$ 为=&quot;math-container&quot;&gt;$A \subseteq \mathcal{X}$：
\begin{方程}
P_X(A) = \int_{\Theta} P_{X \mid \theta = u}(A) d \Pi(u)
\end{方程}
也就是说，这不是最常见的方法，即 $P_X$ 基于一个真实的 $\theta$，这里我们将 $P_X$ 建模为 $\theta$ 的所有可能值的积分到之前选择的。再说一遍，如果样本量为 $n$，那么我们将考虑样本 $X_1$ span&gt;、$\ldots$、$X_n$ 根据 $P_X$ 在上面的等式 (1) 中定义。
所以，问题是，如果我们使用不正确的先验，$X$ 是如何生成的？鉴于上面的讨论，它感觉不像是一个自然的概括，因为 $P_X$ 不会是概率分布。我们是否只是将 $X$ 视为通用的可测量函数？我知道，出于实际目的，我们需要考虑不正确的先验，例如非信息先验。但是不正确的先验有任何理论动机吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642727/how-is-data-generated-when-using-an-improper-prior</guid>
      <pubDate>Fri, 15 Mar 2024 21:05:10 GMT</pubDate>
    </item>
    <item>
      <title>Logistic 回归潜在混合模型 -0 为中心的预测变量，具有正值和负值</title>
      <link>https://stats.stackexchange.com/questions/642726/logistic-regression-latent-mixture-models-0-centred-predictor-with-positive-and</link>
      <description><![CDATA[我们将潜在生长混合模型拟合到 150 个轨迹并确定了 2 个类别。按照惯例，我们随后使用逻辑回归来测试分配给所述类别之一的概率与预测变量之间的关联。
这种方法适用于大多数预测变量[其中大部分是连续的[在一个示例中为 0 到 78]。
但是，我们还想针对变化预测变量进行测试。在本例中，数据以 0 为中心，但可以具有负值或正值 [范围从 -56.7 到 43.6]。我们确实只想测试与负值的关联。
我们已更改数据以反映排名，但您会失去差异范围。我们还使用了二元变量[如果在负值最高的四分位数中则为 1，否则为 0]，但不确定这种方法的有效性。
想知道是否有人有任何想法/可以指出相关论文的方向，以帮助找到处理这些数据的最佳方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/642726/logistic-regression-latent-mixture-models-0-centred-predictor-with-positive-and</guid>
      <pubDate>Fri, 15 Mar 2024 20:55:55 GMT</pubDate>
    </item>
    <item>
      <title>EM 算法的推广[关闭]</title>
      <link>https://stats.stackexchange.com/questions/642725/em-algorithm-generalized</link>
      <description><![CDATA[我正在研究EM算法，我发现空间交替广义期望最大化（SAGE）是EM的广义版本。我只是想检查一下我是否理解正确。假设我们有两个隐藏变量，SAGE 将首先在第一个隐藏变量上计算 EM，而不确认第二个变量，然后使用第一个隐藏变量的结果计算第二个隐藏变量；是这样的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642725/em-algorithm-generalized</guid>
      <pubDate>Fri, 15 Mar 2024 20:55:18 GMT</pubDate>
    </item>
    <item>
      <title>揭示高价值客户：识别和定位高 CLV 客户的机器学习方法 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/642724/unveiling-high-value-customers-a-machine-learning-approach-to-identify-and-targ</link>
      <description><![CDATA[对于零售商，我拥有客户数据，其中包含性别、年龄、距最近零售商的距离、销售人员等以及个人 CLV（客户生命周期价值）
我想了解构成我的最高 CLV 客户的固有特征。目标是寻找并获取具有相似特征的其他客户。
我应该使用什么机器学习算法？
一方面，我在想，“高 CLV 的预测因子是什么”听起来像是一个监督模型。
另一方面，这听起来也像是一个分割问题。关于“Meta (Facebook/instagram) 上最适合定位的细分市场”
在营销方面具有数据分析经验的人可以参与进来并提供一些指导吗？
（顺便说一句，我正在使用 R 工作）]]></description>
      <guid>https://stats.stackexchange.com/questions/642724/unveiling-high-value-customers-a-machine-learning-approach-to-identify-and-targ</guid>
      <pubDate>Fri, 15 Mar 2024 20:52:00 GMT</pubDate>
    </item>
    <item>
      <title>训练 GAN（改进？）</title>
      <link>https://stats.stackexchange.com/questions/642723/training-gans-improvements</link>
      <description><![CDATA[我目前正在训练 GAN 和条件 GAN，并正在考虑一些提高性能的选项。到目前为止，我认为在我的条件 GAN 环境中使用标签平滑有所帮助（不完全确定），并且在训练时更新鉴别器以比生成器进行更多迭代也有帮助，从而带来了一些性能提升。
但是，当我下一步时，我想知道是否有帮助：

为鉴别器使用更深/更宽的神经网络，为生成器使用更小的神经网络。
使用较小/较浅的神经网络作为鉴别器，同时使用较大的神经网络作为生成器。
]]></description>
      <guid>https://stats.stackexchange.com/questions/642723/training-gans-improvements</guid>
      <pubDate>Fri, 15 Mar 2024 20:43:18 GMT</pubDate>
    </item>
    <item>
      <title>R 中的正交和为零对比？</title>
      <link>https://stats.stackexchange.com/questions/642721/orthogonal-sum-to-zero-contrasts-in-r</link>
      <description><![CDATA[我正在运行一个混合效应逻辑回归模型，其中有两个具有四个级别的预测变量和三个具有两个级别的预测变量。我对预测变量水平之间的特定对比感兴趣，因此我正在考虑继续分配正交和为零对比，以便在模型的输出中进行所需的比较。但我想知道是否有必要用正交和为零对比来编码那些只有两个的变量级别，或者我可以保留默认的 R 编码（即，R 将第二个级别与按字母顺序给定的第一个级别进行比较的处理） ）？
此外，我的第二个问题是：如果我按照以下方式分配对比

contrasts&lt;-list() 与指定值的对比列表
contrasts.tmp &lt;- rbind( ,tmp = 1) 括号内为对比名称
对比 &lt;-solve(contrasts.tmp)
对比&lt;-对比[,-1]
对比（数据$VARIABLE）&lt;-对比
6) 属性(data$变量)

正确吗？
还是使用 R 中的特定包和函数更好？
我也知道这个函数：options(contrasts = c(“contr.sum”,“contr.poly”))，但我不确定它是否相同。
我对这个世界很陌生，但我正在努力理解这些事情。]]></description>
      <guid>https://stats.stackexchange.com/questions/642721/orthogonal-sum-to-zero-contrasts-in-r</guid>
      <pubDate>Fri, 15 Mar 2024 20:34:43 GMT</pubDate>
    </item>
    <item>
      <title>无法估计组内方差时的混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/642720/mixed-effects-model-when-within-group-variance-cannot-be-estimated</link>
      <description><![CDATA[当无法估计组内方差时，什么是混合效应模型。
例如，我的结果一开始就非常罕见。不到 5% 的儿童会出现这种结果。然后，我在全国各地有不同的小组，他们为这种情况提供了数据，包括协变量。
二进制结果。 （良好发展、不良或低于发展）

x1：烟草母体（是/否）

x2：母亲教育（高中毕业、高中未毕业）

组：州（加利福尼亚州、佐治亚州、纽约州、马里兰州、威斯康星州）

这是每个 x 和组内结果的分布
 1=良好发展，0=不良或低于发展
  加州 是 高中 10 6
      没有高中 67 3
  加州 是 高中 105 16
      没有高中 121 4
  加利福尼亚州 是 高中 22 4
      没有高中 126 4
  加州 是 高中 18 5
      没有高中 26 4
  加州 是 高中 150 9
      没有高中 66 3



                1=良好发展，0=不良或低于发展
  CA 是 烟草 74 7
      无烟 3 2
  GA 是 烟草 209 17
      无烟 17 3
  纽约 是 烟草 140 8
      无烟 8 0
  MD 是 烟草 42 2
      无烟 9 0
  WI 是 烟草 208 8
      无烟 12 0

混合效应模型无法收敛。我怀疑这是因为 Y+x+(1|Group) 的某些组合的某些单元格中的值稀疏。我想知道只做固定效应而不是随机效应是否会更好。我没有看到拟合混合效应模型有任何优势。请原谅我的无知。看到你的建议。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/642720/mixed-effects-model-when-within-group-variance-cannot-be-estimated</guid>
      <pubDate>Fri, 15 Mar 2024 19:36:01 GMT</pubDate>
    </item>
    <item>
      <title>确定两个变量之间影响的大小</title>
      <link>https://stats.stackexchange.com/questions/642709/determining-the-magnitude-of-influence-between-two-variables</link>
      <description><![CDATA[我试图找出一个变量对另一个变量的影响大小，以及如果我们也以相反的方向分析它会发生多大的变化。本质上，我试图弄清楚变量 A 是否对变量 B 的影响更大，或者相反。我运行了两个简单的线性回归模型并得到了以下结果，尽管我对统计有点陌生，所以我不太确定如何解释它们，或者这种分析方法是否是解决问题的正确方法。任何帮助将不胜感激。谢谢！
]]></description>
      <guid>https://stats.stackexchange.com/questions/642709/determining-the-magnitude-of-influence-between-two-variables</guid>
      <pubDate>Fri, 15 Mar 2024 16:38:02 GMT</pubDate>
    </item>
    <item>
      <title>通过高斯分类器与逻辑回归进行分类。什么时候选择更间接的回归方法？</title>
      <link>https://stats.stackexchange.com/questions/642702/performing-classification-by-gaussian-classifier-versus-logistic-regression-whe</link>
      <description><![CDATA[假设我们测量一个依赖于二分类的变量 $X|_\text{class}$，其中分布以该类为条件
$$X|_\text{class =1} \sim N(\mu_1,\sigma^2)$$
$$X|_\text{class =2} \sim N(\mu_2,\sigma^2)$$
在这种情况下，我们可以应用逻辑模型，如下所述：

对于二元分类示例，如何证明 LDA 具有与 Logistic 回归类似的形式？
推导出逻辑回归公式

这里的问题是哪种方法可以为分类边界创建最低的均方误差

我们可以根据两个总体拟合正态分布，并用它来计算分类边界。
我们可以执行逻辑回归并用它来计算分类边界。

这些方法不会给出与下面代码所示相同的结果（与拟合逻辑回归模型相比，拟合正态分布更好，与理想边界的偏差更低）。
问题：显然，逻辑回归并不总是表现最好的。是否有系统/方法来决定使用逻辑回归而不是直接拟合正态分布？
set.seed(1)


样本=函数（）{
  n = 30
  x = rnorm(n,0)
  y = rnorm(n,1)
  xy = c(x,y)
  z = 代表(c(0,1), 每个 = n)
  
  mod = glm(z ~xy, 族 = 二项式())
  
  ### 边界基于组均值之间的平均值
  边界1 = 均值(c(x,y))
  ### 逻辑模型的边界
  border2 = -mod$系数[1]/mod$系数[2]
  
  返回（c（边界1，边界2））
}


b = 复制(10^3, 样本())

绘图（b[1，]，b[2，]）
mean((b[1,]-0.5)^2) ### 直接分类的错误 = 0.0166966
Mean((b[2,]-0.5)^2) ### 逻辑回归误差 = 0.01713042
]]></description>
      <guid>https://stats.stackexchange.com/questions/642702/performing-classification-by-gaussian-classifier-versus-logistic-regression-whe</guid>
      <pubDate>Fri, 15 Mar 2024 14:46:44 GMT</pubDate>
    </item>
    <item>
      <title>一般决定系数的抽样分布</title>
      <link>https://stats.stackexchange.com/questions/642605/sampling-distribution-of-coefficient-of-determination-in-general</link>
      <description><![CDATA[我正在研究多元线性回归的属性，并偶然发现了经常用于测试的 F 统计量。我们正在测试回归系数（假设除了截距项之外还有 $p$ 变量）：
$$H_0:\beta_1=\dots =\beta_p=0$$
与其补语相对应。
我们都知道，在原假设下，$R^2/(1-R^2)$ 假设服从（缩放的）F 分布。但当我在替代方案下搜索发行版时，可用的资源很少。我发现提到对于 $p=1$ 情况，它是一个缩放的非中心 F 变量，但一般情况不存在。
有人可以指点一下如何证明一般 $p$ 的类似结果，或者提供一些来源吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642605/sampling-distribution-of-coefficient-of-determination-in-general</guid>
      <pubDate>Thu, 14 Mar 2024 15:08:45 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.linear_model.LogisticRegressionCV 中 L2 正则化的显式形式 [重复]</title>
      <link>https://stats.stackexchange.com/questions/642551/explicit-form-of-l2-regularization-in-sklearn-linear-model-logisticregressioncv</link>
      <description><![CDATA[我正在使用sklearn的LogisticRegressionCV，我想知道Logistic回归中L2正则化的显式形式。
在LogisticRegressionCV的官方页面中写道$Cs$ 是“正则化强度的倒数”，但尚不清楚正则化项的显式形式是什么。
在岭回归讲义中，5.3中的第一个方程，写为岭回归的正则化项是 $-\frac{1}{2}\lambda \bf{\beta}^T \bf{\beta}$，但是我不确定这个 $\lambda$ 与上面的 $Cs$ 有何关系。有人能帮我解决这个问题吗？
（我还在Stack Overflow)
额外说明：我注意到这个问题类似于这个 ，但我不确定 $Cs$ 和 $\lambda$ 之间的显式关系是什么。是 $Cs=\frac{1}{\lambda}$、$Cs=\frac{1}{\frac {1}{2}\lambda}$，否则？
注意：我问了ChatGPT，参数之间的关系似乎是$Cs$（让我们将其中一个参数称为 LogisticRegressionCV 中的 $C$) 和 $\lambda$ 是 $\lambda = 1/(C*N )$，其中 $N$ 是样本数。我假设岭的修正项为 $\log P -\frac{1}{2}\lambda |\beta|^2$，其中 $P$ 是可能性。]]></description>
      <guid>https://stats.stackexchange.com/questions/642551/explicit-form-of-l2-regularization-in-sklearn-linear-model-logisticregressioncv</guid>
      <pubDate>Wed, 13 Mar 2024 23:26:28 GMT</pubDate>
    </item>
    <item>
      <title>OLS 回归完美拟合的含义</title>
      <link>https://stats.stackexchange.com/questions/642547/implication-for-a-perfect-fit-in-ols-regression</link>
      <description><![CDATA[如果 $ \hat{\beta} = (X&#39;X)^{-1}X&#39;y $ 与 $ X $ 是一个 $ n \times k $ 矩阵，那么据我了解，只要 $ k \leq n $，$ X&#39;X $ 是可逆的（只要满足所有其他 OLS 假设），因此有$ \hat{\beta} $ 的独特解决方案。但如果与 $ k = n $ 完美契合，那么 $ \hat{\sigma} 是真的吗？ (u) = 0 $ 为 $ \hat{\sigma}(u) = \hat{s}^2 = \frac{1}{n-k+ 1} \epsilon&#39;^\top \epsilon = 0 $
因此 $ \text{Var}(\hat{\beta}) = \hat{\sigma}(u) (X&#39;X)^{-1} $ 也是 $ 0 $？]]></description>
      <guid>https://stats.stackexchange.com/questions/642547/implication-for-a-perfect-fit-in-ols-regression</guid>
      <pubDate>Wed, 13 Mar 2024 22:49:34 GMT</pubDate>
    </item>
    </channel>
</rss>