<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 09 Oct 2024 21:15:28 GMT</lastBuildDate>
    <item>
      <title>Neal 算法 1 是如何推导出来的？</title>
      <link>https://stats.stackexchange.com/questions/655568/how-is-neals-algorithm-1-derived</link>
      <description><![CDATA[我正在阅读 Neal 的狄利克雷过程混合模型的马尔可夫链抽样方法。我无法理解方程 3.2、3.3 和 3.4 是如何推导出来的。它们直观上是有意义的，但我很难想出一个正式的推导，特别是方程 3.4。
摘自论文：

这是我所得到的（不正确？）
$$\begin{align*}
p(\theta_i|\theta_{-i}, y_i)&amp;\propto p(\theta_i, \theta_{-i}, y_i)\\
&amp;=p(y_i|\theta_i, \theta_{-i})p(\theta_i|\theta_{-i})p(\theta_{-i})\\
&amp;=p(y_i|\theta_i)p(\theta_i|\theta_{-i})p(\theta_{-i}) \quad\text{since}\;{y_i\perp \theta_{-i}|\theta_i}\\
&amp;\propto p(y_i|\theta_i)p(\theta_i|\theta_{-i})
\end{align*}$$
我不确定积分从何而来。]]></description>
      <guid>https://stats.stackexchange.com/questions/655568/how-is-neals-algorithm-1-derived</guid>
      <pubDate>Wed, 09 Oct 2024 20:43:54 GMT</pubDate>
    </item>
    <item>
      <title>证明 $\mathbb{E} (|X-Y|) = 0 \implies X^2 = Y^2$</title>
      <link>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</link>
      <description><![CDATA[$\boxed{\text{设 } X,Y \text{ 为任意随机变量。证明如果 } \mathbb{E}(​​|X-Y|) = 0，\text{则 } X^2 = Y^2。}$
我们有 $\mathbb{E}(​​|X-Y|) = 0$，我认为如果我能以某种方式证明 $X=Y$，那么它直接意味着 $X^2 = Y^2$，但我不知道如何实现。
附言：这不是任何形式的家庭作业，我只是在大学概率课程的往期考试中看到了这个问题，想尝试一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</guid>
      <pubDate>Wed, 09 Oct 2024 19:54:07 GMT</pubDate>
    </item>
    <item>
      <title>所有相关性荟萃分析</title>
      <link>https://stats.stackexchange.com/questions/655563/all-correlations-meta-analysis</link>
      <description><![CDATA[我是 MetaSEM 的新手。我正在尝试进行一个简单的元分析（我只想分析 2 个相关性；见图）。
在这里您可以找到我使用的一些模拟数据的代码，但如果没有回归，我就无法让它工作（除非我添加回归系数，否则它会永远工作下去）。这应该是一个简单的模型，但我被卡住了。我只想要两个协方差，我已经将所有方差固定为一个。换句话说，我只想对 S-D 和 I-D 之间的相关性进行元分析。
S 和 D、S 和 I 以及 D 和 I 之间的相关性存储在此处：
rSD &lt;- c(0.85, 0.8, 0.90, 0.78, 0.70,NA,NA,NA,NA,NA)
rSI &lt;- c(NA,NA,NA,NA,NA,0.85,NA,NA,NA,NA)
rDI &lt;- c(NA,NA,NA,NA,NA,0.60, 0.50, 0.55, 0.60, 0.55)

rSI 可能是 al NA，因为我对这种相关性不感兴趣。
我读过关于 SEM 和 RAM 模型的文章，我认为这个模型是可以识别的，应该很容易拟合。任何帮助和指导都将不胜感激。
library(metaSEM)
source(&quot;http://www.suzannejak.nl/MASEM_functions.R&quot;)

rSD &lt;- c(0.85, 0.8, 0.90, 0.78, 0.70,NA,NA,NA,NA,NA)
rSI &lt;- c(NA,NA,NA,NA,NA,0.85,NA,NA,NA,NA)
rDI &lt;- c(NA,NA,NA,NA,NA,0.60, 0.50, 0.55, 0.60, 0.55)

N &lt;- c(10000,40000, 30000, 10000, 10000,20000,10000, 50000, 10000, 10000 )

数据 &lt;- as.data.frame(cbind(rSD,rSI,rDI, N))

nvar &lt;- 3
varnames &lt;- c(&quot;S&quot;,&quot;D&quot;, &quot;I&quot;)
labels &lt;- list(varnames,varnames)

cormatrices &lt;- readstack(data[,c(2,1,3)], no.var = nvar, var.names = varnames, diag = FALSE)

n &lt;- data$N

pattern.na(cormatrices, show.na=F)
pattern.n(cormatrices, n=n)

my.df &lt;- Cor2DataFrame(cormatrices, n, acov = &quot;weighted&quot;)

## 使用指定模型lavaan 语法
模型 &lt;-
&#39;

# 协方差
D ~~ I
D ~~ S
# 方差

D ~~ 1*D
S ~~ 1*S
I ~~ 1*I
&#39;

RAM1 &lt;- lavaan2RAM(model, obs.variables=varnames)
RAM1

## 创建具有隐式对角线约束的模型隐含相关结构
M0 &lt;- create.vechsR(A0=RAM1$A, S0=RAM1$S)

## 创建异质性方差-协方差矩阵
T0 &lt;- create.Tau2(RAM=RAM1, RE.type=&quot;Diag&quot;, Transform=&quot;expLog&quot;, RE.startvalues=0.05)

## 拟合模型
mx.fit0 &lt;- osmasem(model.name=&quot;No moderator&quot;, Mmatrix=M0, Tmatrix=T0, data=my.df)

## 查看结果
summary(mx.fit0, fitIndices = TRUE)
VarCorr(mx.fit0)

]]></description>
      <guid>https://stats.stackexchange.com/questions/655563/all-correlations-meta-analysis</guid>
      <pubDate>Wed, 09 Oct 2024 19:33:34 GMT</pubDate>
    </item>
    <item>
      <title>在风险函数的定义中，$\leq$ 应该放在哪里？</title>
      <link>https://stats.stackexchange.com/questions/655562/where-should-the-leq-go-in-the-definition-of-the-hazard-function</link>
      <description><![CDATA[我在几本教科书和在线资源中都看到过两种风险函数定义。
定义 1。这里例如。
$$h(t) = \lim_{\epsilon \to 0+}\dfrac{P(t &lt; T \leq t + \epsilon \mid T &gt; t)}{\epsilon},$$
定义 2。这里例如。
$$h(t) = \lim_{\epsilon \to 0+}\dfrac{P(t \leq T &lt; t + \epsilon \mid T \geq t)}{\epsilon}.$$
我推测如果 $T$ 是绝对连续的，那么它们是等价的。但是，是否存在它们不同的情况？如果有，哪一个是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/655562/where-should-the-leq-go-in-the-definition-of-the-hazard-function</guid>
      <pubDate>Wed, 09 Oct 2024 18:40:31 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助理解具有多个随机变量的条件概率分布</title>
      <link>https://stats.stackexchange.com/questions/655561/need-help-with-understanding-conditional-probability-distributions-with-multiple</link>
      <description><![CDATA[我试图理解我正在阅读的一些机器学习讲义中介绍的以下步骤。在这种情况下，我们想要用参数化函数类 $\mathcal{F}(\Theta)$ 中的函数来近似函数 $f^*: \mathcal{X} \to \mathcal{Y}$，其中该类中的每个函数都依赖于一些参数 $\theta \in \Theta$。我们给出了输入 $x_{1:n}$ 和标签 $y_{1:n}$，其中我们使用符号 $x_{1:n} = (x_1, \ldots, x_n)^T$。我们假设标签是独立同分布的，并且 $y_i \sim p( \cdot | x_i, \theta)$ 成立。此外，我们假设参数 $\theta$ 具有先验分布 $p(\theta)$。我们现在希望通过对 $\theta$ 进行条件设定，预测新输入 $x^*$ 时的输出 $y^*$：
$$p(y^* | x^*, x_{1:n}, y_{1:n}) = \int_{\Theta}p(y^*, \theta | x^*, x_{1:n}, y_{1:n}) d\theta = \int_{\Theta}p(y^* | x^*, \theta) \cdot p(\theta | x_{1:n}, y_{1:n})d\theta,$$
根据讲义，第一个等式如下根据求和规则，其表述为
$$p(x_{1:i - 1}, x_{i + 1:n}) = \int_{X_i(\Omega)}p(x_{1:i-1},x_i, x_{i + 1: n}) dx_i,$$
第二个等式根据 $y^* \perp x_{1:n}, y_{1:n} | \theta$ 和乘积规则，其表述为
$$p(x_{1:n}) = p(x_1) \prod_{i = 2}^np(x_i | x_{1: i-1}).$$
我认为我理解第一个等式，因为根据条件概率分布的定义，我们有
$$p(x_{1:i-1}, x_{i+1:n} | y_{1:n}) = \frac{p(x_{1:i-1}, x_{i+1:n}, y_{1:n})}{p(y_{1:n})} = \frac{\int_{X_i(\Omega)}p(x_{1:i-1},x_i, x_{i + 1: n}, y_{1:n}) dx_i}{p(y_{1:n})} = $$
$$ = \frac{\int_{X_i(\Omega)} p(y_{1:n})p(x_{1:i-1},x_i, x_{i + 1: n} | y_{1:n}) dx_i}{p(y_{1:n})} = \int_{X_i(\Omega)}p(x_{1:i-1},x_i, x_{i + 1: n} | y_{1:n}) dx_i.$$
但是，我不明白第二个等式如何从 $y^* \perp 得出x_{1:n}, y_{1:n} | \theta$ 和所述乘积规则。
如能得到任何帮助，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/655561/need-help-with-understanding-conditional-probability-distributions-with-multiple</guid>
      <pubDate>Wed, 09 Oct 2024 18:33:29 GMT</pubDate>
    </item>
    <item>
      <title>寻找使用“求解方程”带宽进行核密度估计的可靠教程</title>
      <link>https://stats.stackexchange.com/questions/655559/looking-for-robust-tutorial-using-solve-the-equation-bandwidth-for-kernel-dens</link>
      <description><![CDATA[我目前正在从事的工作是让我为通过任意有界函数 $z=p(\vec{x})$ 诱导的分布生成 CDF 函数，其中 $p:\mathcal{D} \subset \mathbb{R}^m \to \mathcal{R} \subset \mathbb{R}$，并且 $\mathcal{D}:=\times_{i=1}^m [a_i,b_i]$ 和 $-\infty &lt; a_i &lt; b_i &lt; \infty$。更具体地说，我取随机变量$ \vec{X} \sim \mathcal{U}(\mathcal{D})$，并诱导随机变量$Z = p(\vec{X})$，并使用$n$个样本构建近似值$F_n(z)$，以获得“真实的”（可能/通常不可知的）累积分布函数$F(z)$。我正在使用高斯核的核密度估计构建这个近似值，$K(t) = (2\pi)^{-1/2}\exp(-t^2/2)$，并应用 Silverman 的经验法则来计算带宽的值，$h$。此规则为
$$
h = 0.9 \min\left\{\widehat{\sigma}, \frac{IQR}{1.34} \right\}
$$
（顺序问题，我发现很多不同的规则被称为 Silverman 经验法则，因此这 可能 实际上不是 Silverman 经验法则。请在评论中纠正我，但这最终与我的询问无关）。
我还想使用 Solve-the-Equation（糟糕的品牌名称）带宽计算来估算这一点，但我找不到任何关于如何进行此操作的易于理解的演示文稿/来源/参考资料。如果有人可以指出有关如何为 KDE 进行 Solve-the-Equation 带宽的详尽解释/来源，我将不胜感激。尤其是不会掩盖太多细节的。这种数学不是我的强项。或者，如果网上找不到这样的教程，可以在这里介绍一个强大的教程。此外，请纠正我的术语中的任何错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/655559/looking-for-robust-tutorial-using-solve-the-equation-bandwidth-for-kernel-dens</guid>
      <pubDate>Wed, 09 Oct 2024 18:04:25 GMT</pubDate>
    </item>
    <item>
      <title>线性变换后计算 RBF 核矩阵的有效方法</title>
      <link>https://stats.stackexchange.com/questions/655558/efficient-way-to-compute-rbf-kernel-matrix-after-linear-transformation</link>
      <description><![CDATA[我有一个点数据集$\{\mathbf{x}_i | \mathbf{x}_i \in \mathbb{R}^n\}$ 和一个线性变换矩阵 $\mathbf{F} \in \mathbb{R}^{n \times m}$，使得 $\mathbf{y}_i = \mathbf{F}^T \mathbf{x}_i$，其中 $\mathbf{y}_i \in \mathbb{R}^m$ $m&lt;n$。
矩阵 $\mathbf{F}$ 是可学习的，可能带有约束，例如每列具有单位范数，和/或列是正交的。我想计算点 $\mathbf{y}_i$ 上的径向基函数核矩阵，也就是说，对于每个 $i,j$，计算 $\exp\left(\|\mathbf{y}_i - \mathbf{y}_j\|^2\right/2\sigma^2)$。
由于 $\mathbf{F}$ 会更新，我想知道是否有某种有效的方法可以在每次 $\|\mathbf{y}_i - \mathbf{y}_j\|^2$ 之后重新计算或近似距离 $\|\mathbf{y}_i - \mathbf{y}_j\|^2$ class=&quot;math-container&quot;&gt;$\mathbf{F}$ 更新。]]></description>
      <guid>https://stats.stackexchange.com/questions/655558/efficient-way-to-compute-rbf-kernel-matrix-after-linear-transformation</guid>
      <pubDate>Wed, 09 Oct 2024 18:04:09 GMT</pubDate>
    </item>
    <item>
      <title>向线性回归模型添加更多回归量与模型的 F 统计量之间的关系</title>
      <link>https://stats.stackexchange.com/questions/655557/relationship-between-adding-more-regressors-to-a-linear-regression-model-and-the</link>
      <description><![CDATA[我在思考当我们添加更多回归量时对线性回归模型中不同参数的影响，但我不太确定 F 统计量会发生什么。
我知道对于 $Y=\beta_0+\beta_1 x_1 +...+\beta_p x_p$，我们有 $({\rm Explained}\ SS/p)/({\rm Residual}\ SS/n-p-1) \sim F_{p,n-p-1}$，并且当我们在模型中添加更多回归量时，${\rm Residual}\ SS$ 将减少，而 ${\rm Explained}\ SS$ 将增加。对我来说，这应该意味着 $F$ 统计量应该增加，但在运行一些方差分析测试后，情况似乎不一定如此。
我的想法是否正确，即 $F$ 统计量应该增加？或者我的初步测试是否正确，并且 $F$ 统计量的值将无法确定？]]></description>
      <guid>https://stats.stackexchange.com/questions/655557/relationship-between-adding-more-regressors-to-a-linear-regression-model-and-the</guid>
      <pubDate>Wed, 09 Oct 2024 17:46:42 GMT</pubDate>
    </item>
    <item>
      <title>创建针对一个主题和每个项目的评分者间信度</title>
      <link>https://stats.stackexchange.com/questions/655556/create-inter-rater-reliability-on-one-subject-and-per-item</link>
      <description><![CDATA[我公司接到一项任务，因为我不太懂统计学，也没有找到解决我的问题的具体方法，所以我想问问你们。
那么我的任务是什么呢？
我们必须每年培训员工。培训如下：
员工们正在观看一个主题的视频，然后他们必须对视频的不同部分进行 1-5 的评分，如果无法评估，则为 0。
目标是评估不同的评分者是否对特定部分给出了相同的评分。例如，可以使用 Landis Koch 基准来评估可靠性。
如果特定部分高于某个阈值，则公司感到满意。如果没有，则必须对员工进行该特定部分的培训。
这意味着我必须为每个部分创建一个可靠性分数，以查看是否需要培训。此外，公式还必须考虑评级是否接近。
这就是为什么例如简单的百分比可靠性不起作用的原因（我认为）
此外，像 Fleiss Kappa 这样的公式也不起作用，因为它无法确定一个主题的单个部件（或项目）的 kappa。
例如，我们有 50 位评分者，并且特定部件的评级为 5 次“0”，5 次“1”，10 次“2”，30 次“3”，其他部件没有投票。还有一个权重也应该计算在内。评级为“1”表示未通过，而“0”表示该部件无法评级。数字上很接近，但对主题来说却是灾难性的。然后，一个评分员给他打了不及格分，另一个评分员给他打了不及格分。
有没有办法计算一个项目的分数、Kappa 值或其他东西，并以某种方式对其进行加权？
正如我所说，我不太喜欢统计，但当我知道要寻找什么时，我认为这会有所帮助。
编辑：我可能必须澄清一下。
整个设置都是法律规定的。因此，员工，即教员，观看视频。他们必须根据不同的能力对视频中的受训者进行评分。他的知识如何，他的领导能力如何等。他们必须用上述等级对每项能力进行评分。目标是确保每个教员的评分几乎相同。因为如果不是这样，受训者在现实生活中将高度依赖他得到的教员。这就是我们需要这个培训计划的原因。我们必须评估我们必须与教员合作的能力。为此，我们需要一个量表。我们收到了一家公司的报价，他们使用 Landis Koch 量表并借助 kappa 进行评估。但他们当然没有告诉我们具体是哪种。我们想重建它，自己在公司内部制造。但我们知道这在某种程度上是可行的。这就是为什么我们需要为每项能力设置一个分数或其他东西。遗憾的是，设置无法更改。]]></description>
      <guid>https://stats.stackexchange.com/questions/655556/create-inter-rater-reliability-on-one-subject-and-per-item</guid>
      <pubDate>Wed, 09 Oct 2024 17:39:48 GMT</pubDate>
    </item>
    <item>
      <title>线性回归中的标准差方差</title>
      <link>https://stats.stackexchange.com/questions/655554/variance-of-standard-deviation-in-linear-regression</link>
      <description><![CDATA[考虑线性回归设置$$y=X\beta+\epsilon$$，其中$\epsilon\sim N(0,\sigma)$，因此$y|X\sim N(X,\sigma I)$。让 $X$ 为 $n\times p$，并且 $Y$ 为 $n\times 1$。
我理解 $\sigma$ 的无偏估计量是 $\hat{\sigma}=\frac{1}{n-p}||y-X\hat{\beta}||_2^2$，并且我知道一些方法可以证明这一点，例如 这里。
问题：我不确定下面概述的方法出了什么问题，该方法表明$\hat{\sigma} = 1/n ||y-X\hat{\beta}||_2^2$是一个无偏估计量。希望有人指出我的错误：
$$\mathbb{E}(​​||y-X\hat{\beta}||_2^2)=\mathbb{E}(​​\sum_{n} (y_i-\sum_p x_{ij} \beta_j)^2)$$
然后从上面的$y|X$分布，我们得到$y_i|X\sim N(\sum_p x_{ij} \beta_j,\sigma)$，因此这通过线性减少到
$$\sum_n \mathbb{V}(y_i|X) = n\sigma$$
因此可以看出 $\hat{\sigma}=1/n ||y-X\hat{\beta}||_2^2$ 是一个无偏估计量。$X$ 的排名 $p$ 在哪里发挥作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/655554/variance-of-standard-deviation-in-linear-regression</guid>
      <pubDate>Wed, 09 Oct 2024 16:53:58 GMT</pubDate>
    </item>
    <item>
      <title>Diaconis 关于一副牌洗 3 次的论点</title>
      <link>https://stats.stackexchange.com/questions/655549/diaconis-argument-for-3-shuffles-in-a-deck</link>
      <description><![CDATA[我记得听过伟大的概率论者 Persi Diaconis 说过，三次洗牌就足以得到一副充分洗过的牌。我想知道这一说法是否有原始参考，或者是否有令人信服的标准或假设来证明这一说法。]]></description>
      <guid>https://stats.stackexchange.com/questions/655549/diaconis-argument-for-3-shuffles-in-a-deck</guid>
      <pubDate>Wed, 09 Oct 2024 16:04:36 GMT</pubDate>
    </item>
    <item>
      <title>当将一个向量中的某些值切换为零时的相关行为</title>
      <link>https://stats.stackexchange.com/questions/655548/correlation-behaviour-when-switching-some-values-in-one-vector-to-zero</link>
      <description><![CDATA[如果我们将第二个变量中的某些值切换为零，那么两个变量之间的相关性是否存在系统性行为？
这里有一个例子：
# 样本数量
n &lt;- 1000

# 生成相关的连续变量
Sigma &lt;- matrix(c(1, 0.2, 0.2, 1), 2, 2)
continuous_vars &lt;- MASS::mvrnorm(n, mu = c(0, 0), Sigma = Sigma)

# 对连续变量进行二值化
x &lt;- as.numeric(continuous_vars[, 1] &gt; quantile(continuous_vars[, 1], probs = 0.8))
y &lt;- as.numeric(continuous_vars[, 2] &gt; quantile(continuous_vars[, 2], probs = 0.8))
z &lt;- x*y # &lt;- 这会将许多 1 变成零

paste0(&quot;sum(x) = &quot;, sum(x) )
paste0(&quot;sum(y) = &quot;, sum(y) )
paste0(&quot;sum(z) = &quot;, sum(z) )

[1] &quot;sum(x) = 200&quot;
[1] &quot;sum(y) = 200&quot;
[1] &quot;sum(z) = 54&quot;
paste0(&quot;cor(x,y) = &quot;, round(cor(x, y), digits = 2))
paste0(&quot;cor(x,z) = &quot;, round(cor(x, z), digits = 2))

[1] &quot;cor(x,y) = 0.09&quot;
[1] &quot;cor(x,z) = 0.48&quot;
在此示例中，一旦我们将第二个变量中的某些 1 切换为 0，相关性就会增加。
是否存在特定设置，在将某些 y 值切换为 0 时，我们期望相关性始终更高？]]></description>
      <guid>https://stats.stackexchange.com/questions/655548/correlation-behaviour-when-switching-some-values-in-one-vector-to-zero</guid>
      <pubDate>Wed, 09 Oct 2024 15:37:03 GMT</pubDate>
    </item>
    <item>
      <title>交互绘图</title>
      <link>https://stats.stackexchange.com/questions/655547/interaction-plotting</link>
      <description><![CDATA[如何绘制研究文章中的交互图。我试图绘制连续响应变量上的连续预测变量和二元交互变量的交互图。例如，$Y=β+β1X1+β2X2+β3X1*X2$，其中$X1$是连续的，$X2$是二元的，$Y$是连续的。经过回归分析，我发现响应变量存在正交互作用。我想用图形支持这些发现。我看到很多研究论文都这样做。但在 x 轴的图形中，我看到方程的连续预测变量分为低和高。当变量是连续变量时，如何进行这种分类？
所以我找到了如何使用 interaction.plot() 函数在 R 中绘图的方法。但我的图表看起来像这样。有人能解释一下为什么吗？

我使用的代码：
interaction.plot(x.factor = Data_cleaningsave$IExM,
trace.factor = Data_cleaningsave$Stlog, 
response = Data_cleaningsave$logres1,fun = median,xlab=&quot;IM&quot;, 
ylab=&quot;RM&quot;, trace.label=&quot;ST&quot;)



@Shawn 收到您的评论后，我修改了代码。图表与上图类似]]></description>
      <guid>https://stats.stackexchange.com/questions/655547/interaction-plotting</guid>
      <pubDate>Wed, 09 Oct 2024 15:33:25 GMT</pubDate>
    </item>
    <item>
      <title>什么原因导致测试损失始终优于评估损失？</title>
      <link>https://stats.stackexchange.com/questions/655546/what-could-be-causing-test-loss-to-consistently-outperform-eval-loss</link>
      <description><![CDATA[我正在训练许多不同的模型，它们都是 XGBoost/LightGBM 类型的模型，因此它们需要一个评估集来进行提前停止。
尽管如此，除非我在进行训练-评估-测试拆分时做了一些粗心的事情，否则我预计停止时的评估损失将非常接近测试损失。一般的想法是，我会选择在停止时对其评估集表现最好的模型并将其放入生产中，如果我需要报告我期望模型在生产中的表现如何，则检查其测试损失。
虽然我们不希望测试和评估损失有很大差异，假设我在 MaxDepth 值的网格上对 xgboost 进行了网格搜索，并选择了以最佳评估损失退出的那个，在某种程度上，我选择了“走运”的组合对于此训练-评估组合，我们可能预计测试损失会略差。
但是，我发现我的测试损失明显好于获胜模型的评估损失（交叉熵的第二位小数点改进）。因此，我回过头来查看了我的所有模型（在 maxDepth 上对 XGB 模型进行网格搜索，在 NumLeaves 上对 lightgbm 模型进行网格搜索），在每种情况下，模型的测试损失都明显好于评估损失。
除了“你搞砸了你的训练-评估-测试分割”或“这是一个统计伪影，如果你重新采样，你会得到不同的结果”之外，有人能想到为什么会发生这种情况吗？
分割细节
我的数据集包含具有 ParticipantId 的“参与者”，可以将其视为 customerId。每个参与者可能有许多与之相关的行。虽然我们不会将参与者 ID 作为特征，但有足够多的连续特征，某些特征组合完全有可能让我们唯一地识别参与者，从而促进过度拟合。因此，我对参与者 ID 进行了哈希修改，然后分层，以便与参与者相关的所有行最终进入训练、评估或测试。
数据非常大（评估集是最小的，其约 1500 万行），因此我可以轻松证明这些差异不是由于抽样误差造成的。有可能（测试成本高），此过程中的方差比标准误差所暗示的要大得多（如果我进行了完全随机的训练-评估-测试分割，则可能归因于简单的抽样误差）。如果某些参与者有很多属于他们的行，并且他们的行为不同（目标基准率非常不同），那么我想他们最终进入哪个集合可能很重要。这是我现在最好的假设，但检查这一点会非常耗时且成本高昂，所以在我用 5 种不同的哈希函数运行整个过程 5 次之前，我想看看是否有人有其他想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/655546/what-could-be-causing-test-loss-to-consistently-outperform-eval-loss</guid>
      <pubDate>Wed, 09 Oct 2024 15:28:01 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归的最大似然估计方法中存在普遍的不一致性</title>
      <link>https://stats.stackexchange.com/questions/655545/widespread-inconsistency-in-maximum-likelihood-estimation-approach-to-logistic-r</link>
      <description><![CDATA[我发现，通过最大似然估计方法得出逻辑回归的损失函数的方式存在一些普遍的不一致之处。
在逻辑回归模型中，我们假设$\Pr[Y = +1| X = x] = \sigma(w^T x)$，其中$\sigma$是逻辑函数，$\sigma(w^T x) = \dfrac{\exp(w^T x)}{1 + \exp(w^T x)}$。类似地，$\Pr[Y = -1| X = x] = 1 - \sigma(w^T x).$
$X, Y$ 具有示例和标签的通常含义。
请注意，$w$ 是一个恒定权重参数（没有假设分布），我们希望对其进行调整。 查找 $w$ 的最常见方法是通过最大条件似然估计。
这就是文献中出现不一致的地方：一些作者假设 $w$ 是我们以此为条件的随机变量，其他作者假设 $w$ 是一个常数参数。
假设 $w$ 为常数的参考文献参数：
https://www.cs.cornell.edu/courses/cs4780/2015fa/web/lecturenotes/lecturenote06.html
请注意，作者使用冒号符号来分隔随机变量和常数参数，即 $p(y|x; w)$
https://web.stanford.edu/class/archive/cs/cs109/cs109.1178/lectureHandouts/220-logistic-regression.pdf
https://cseweb.ucsd.edu/~elkan/250B/logreg.pdf
https://web.engr.oregonstate.edu/~xfern/classes/cs534-18/Logistic-Regression-3-updated.pdf
假设 $w$ 为随机变量的参考文献：
https://www.cs.cmu.edu/~awm/15781/slides/LogRegress-9-29-05.pdf
请注意作者对 $w$ 的条件，即 $p(y|x, w)$
https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf
https://zstevenwu.com/courses/s20/csci5525/resources/slides/lecture05.pdf
https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote06.html
https://svivek.com/teaching/lectures/slides/logistic-regression/logistic-regression.pdf（作者使用两种符号可以互换使用）
本书：https://mml-book.github.io/
我的问题是：

哪种推导是正确的？$w$ 应该被视为常数参数还是随机变量？

只是为了消除一些困惑：

在最大似然估计中，我们总是最大化常数的似然，还是最大化随机变量的似然？

也许 2 的后续问题是，在最大后验估计中，我们总是最大化常数的似然，还是最大化随机变量的似然？]]></description>
      <guid>https://stats.stackexchange.com/questions/655545/widespread-inconsistency-in-maximum-likelihood-estimation-approach-to-logistic-r</guid>
      <pubDate>Wed, 09 Oct 2024 15:14:21 GMT</pubDate>
    </item>
    </channel>
</rss>