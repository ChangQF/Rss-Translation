<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 13 Sep 2024 21:15:23 GMT</lastBuildDate>
    <item>
      <title>统计作业问题：手术室安排概率</title>
      <link>https://stats.stackexchange.com/questions/654343/statistics-homework-problem-operating-room-schedule-probability</link>
      <description><![CDATA[假设一个手术室需要安排三例膝关节手术、四例髋关节手术和五例肩关节手术。假设所有安排的概率相同。确定以下哪项的概率：a. 所有髋关节手术都在另一类手术之前完成。b. 安排从髋关节手术开始。c. 第一个和最后一个手术都是髋关节手术。d. 前两个手术都是髋关节手术。]]></description>
      <guid>https://stats.stackexchange.com/questions/654343/statistics-homework-problem-operating-room-schedule-probability</guid>
      <pubDate>Fri, 13 Sep 2024 21:12:57 GMT</pubDate>
    </item>
    <item>
      <title>我应该进行多重卡方检验还是进行多元逻辑回归？</title>
      <link>https://stats.stackexchange.com/questions/654342/should-i-conduct-multiple-chi-square-tests-or-make-multiple-logistic-regression</link>
      <description><![CDATA[因此，我有一个细菌数据集，并且有 1 个独立变量（隔离源）和 3 个可能的位置。我的其他变量是对许多抗菌药物的耐药性（它们都是二进制的，要么是 0，要么是 1）。我想知道隔离源是否在耐药性中发挥作用。我应该做很多逻辑回归模型吗？（我这样做是因为我可以使用优势比）。
但我也看到人们使用大量卡方检验来测试耐药性和隔离源是否相关。
这些方法有什么区别？有没有更好的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/654342/should-i-conduct-multiple-chi-square-tests-or-make-multiple-logistic-regression</guid>
      <pubDate>Fri, 13 Sep 2024 20:37:06 GMT</pubDate>
    </item>
    <item>
      <title>作为一名想要深入研究机器学习的中级 R 程序员，我应该选择 Python 还是坚持使用 R？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654341/as-an-intermediate-r-programmer-looking-to-dive-into-machine-learning-should-i</link>
      <description><![CDATA[我是一名中级 R 程序员，在机器学习概念和 R 中的简单建模方面有一些经验。我有机会与一个专业的机器学习团队合作，他们同意我使用 R，但我相信我最终需要切换到 Python。
我有两个任务：

学习 Python（如果我继续使用 R，可以推迟学习，但我知道我最终需要切换）。
掌握一种机器学习工具（Tidymodels、mlr3 或 scikit-learn），以便在面试期间给团队留下深刻印象。

正如我所说，任务 1 可以稍后完成。但是，任务 2 应该在几周内完成。因此，如果您认为我应该选择 Python，请考虑到我近期要参加面试，因此我必须同时掌握 Python 和 ML。
我知道 Python 内存效率更高，GPU 访问能力更强，但我也听说过 R 的 ML 包（如 Tidymodels 和 mlr3）的好评。
鉴于 R 在 ML 领域前景光明，但 Python 目前使用更为广泛，我该怎么办？路线图是什么？如果我应该坚持使用 R，我应该使用哪些包，应该学习哪些资源？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654341/as-an-intermediate-r-programmer-looking-to-dive-into-machine-learning-should-i</guid>
      <pubDate>Fri, 13 Sep 2024 20:15:23 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归模型中是否应包括不显著的预测因子？</title>
      <link>https://stats.stackexchange.com/questions/654339/should-a-non-significant-predictor-be-included-in-a-multiple-linear-regression-m</link>
      <description><![CDATA[给定多元线性回归模型：$$Weight = \beta_0 + \beta_1\cdot Height+\beta_2\cdot Age$$
如果我们得到$Height$是显著的（p&lt;0.05），但$Age$不是（p&gt;0.05），我们是否应该在预测特定$height$和$age$的$weight$值时将$Age$纳入模型？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/654339/should-a-non-significant-predictor-be-included-in-a-multiple-linear-regression-m</guid>
      <pubDate>Fri, 13 Sep 2024 19:29:43 GMT</pubDate>
    </item>
    <item>
      <title>注意力图逐渐消失——这是正常的吗？</title>
      <link>https://stats.stackexchange.com/questions/654338/the-attention-map-fades-is-this-normal</link>
      <description><![CDATA[我目前正在构建 Vision Transformer (ViT)，到目前为止，一切似乎进展顺利 - 低损失值、高准确度。然而，当我可视化注意力图时，我注意到它们随着时间的推移逐渐消失并变得统一。我预期的情况恰恰相反 - 随着模型的学习，注意力图将被 Transformer 用于识别哪些补丁对决策的影响更大，哪些补丁的影响较小。最初，情况确实如此，但随着模型的不断学习，注意力图变得越来越统一。
似乎我的模型出了问题，或者 Transformer 在决策过程中停止关注补丁之间的关系。我很好奇是否有其他人遇到过这种行为并可以帮助我解释发生了什么。
至于模型本身，它表现良好并显示出有希望的结果，所以我倾向于认为它没有问题。然而，很难明确地说什么是“正确”或“错误”在这种情况下。
简而言之，我很感激任何有助于解释这些结果的帮助——我不明白为什么注意力图变得如此统一，而且它们的值可以忽略不计，这表明转换器可能没有考虑其决策过程中补丁之间的关系。
我使用了超过 10k 个样本。在第 5 个时期我得到了这些值
时期 5/20
1179/1179 [===============================] - 1197s 1s/step - 损失：0.1253 - sparse_categorical_accuracy：0.9950 - val_loss：0.0607 - val_sparse_categorical_accuracy：1.0000
感谢您的帮助。




]]></description>
      <guid>https://stats.stackexchange.com/questions/654338/the-attention-map-fades-is-this-normal</guid>
      <pubDate>Fri, 13 Sep 2024 18:56:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么两个正态分布相加会产生新的正态分布？</title>
      <link>https://stats.stackexchange.com/questions/654337/why-adding-two-normal-distributions-gives-rise-to-new-normal-distributions</link>
      <description><![CDATA[所以我的推理是，由于每个正态分布都是对称分布。对于每个 P(X_1=x_1)，当添加到另一个正态分布 P(X_2=x_2) 时会产生一个新的分布，如 x_1+x_2 = x_3，其中 x_3 属于新分布。
我只是需要一个直观的解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/654337/why-adding-two-normal-distributions-gives-rise-to-new-normal-distributions</guid>
      <pubDate>Fri, 13 Sep 2024 18:09:40 GMT</pubDate>
    </item>
    <item>
      <title>这是混杂偏差还是选择偏差，或者两者兼而有之？</title>
      <link>https://stats.stackexchange.com/questions/654336/is-this-confounding-bias-or-selection-bias-or-both</link>
      <description><![CDATA[混杂和选择偏差（有偏抽样）能等同吗？
在流行病学中，选择偏差和混杂通常被视为两种不同的偏差。我想知道在某些情况下它们是否可以等同。这是一个简单的思想实验：
让$Y_0$、$Y_1$表示研究对象的潜在结果。我将通过将他们的$Y_0$值与随机变量$X$的值进行比较来确定每个人的治疗状态。例如，如果 $Y_0$ 大于 $X$，受试者将接受治疗（$T=1$），如果 $Y_0$ 小于 $X$，受试者将不会接受治疗（$T=0$）。
我尝试根据以下结构模型在此绘制因果图
\begin{align*}
T=f_T(Y_0,X) \because T=I(Y_0 &gt;X) 
\end{align*&gt;
\begin{align*}
Y=f_y(Y_0, Y_1, T)=Y_0(1-T)+Y_1T
\end{align*&gt;

所以我们可以看到 $T \leftarrow Y_0 \rightarrow Y$ 是一条混杂路径。 $T \leftarrow X \cdot \cdot\cdot\cdot\cdot Y_0 \rightarrow Y$ 是一条混杂和选择偏差路径？ $T=1$ 和 $T=0$ 之间观察到的 $Y$ 差异是否同时归因于混杂和偏差采样？]]></description>
      <guid>https://stats.stackexchange.com/questions/654336/is-this-confounding-bias-or-selection-bias-or-both</guid>
      <pubDate>Fri, 13 Sep 2024 18:05:08 GMT</pubDate>
    </item>
    <item>
      <title>多重比较校正，在对具有相关因变量的 4 个模型进行成对比较后，何时进行？</title>
      <link>https://stats.stackexchange.com/questions/654335/correction-for-multiple-comparison-after-pairwise-comparison-on-4-models-with-r</link>
      <description><![CDATA[我正在使用线性混合效应模型对我的实验进行统计评估。实验由在受试者内以随机顺序进行的几种不同的干预方案组成。每次干预期间都有 3 个不同的时间段。我希望评估每个时间段内干预方案的效果以及每个干预方案内时间段之间的差异。
具体来说，我的模型如下：
fit_simple &lt;- lmer(log(target_variable) ~ Protocol * period + sex + (1 | contestant), data = input_data, REML = TRUE)

数据是对数转换的，因此它符合假设，而且数据分布的性质在文献中几乎总是对数转换的。我的最终模型中的随机结构有点复杂，但这与此无关。
这就是棘手的地方。我对略有不同的数据（不同的 HRV 参数，均根据 ECG 数据计算得出）运行了此模型 4 次，数据高度相关。
对于 4 个模型中的每一个，我希望评估时间段内干预方案之间的差异以及干预方案内时间段之间的差异。我采用成对比较，并使用估计边际均值（R 中的包 emmeans）。默认情况下，emmeans 包已经包含了针对每个成对比较的多重比较校正（默认情况下为 Tukey HMD），但可以关闭此功能。
emm &lt;- emmeans(fit_simple, ~ Protocol * period)

# 每个 Protocol 内各个周期级别之间的成对比较

pairwise_comparisons_Protocol &lt;-contrast(emm, method = &quot;pairwise&quot;, by = &quot;Protocol&quot;)

# 每个周期内各个 Protocol 级别之间的成对比较

pairwise_comparisons_period &lt;-contrast(emm, method = &quot;pairwise&quot;, by = &quot;period&quot;)

#Summpary

summary_Protocol &lt;-summary(pairwise_comparisons_Protocol)

summary_period &lt;- summary(pairwise_comparisons_period)

因此，对于每个模型，我都运行两次成对比较。成对比较可以通过我能想到的三种方式进行：

每个成对比较都可以通过多重比较进行校正（默认情况下是这样）。
可以对每个模型的两次成对比较的所有 p 值同时进行多重比较校正。
可以一次对所有模型的成对比较的所有 p 值进行多重比较校正。

最后一种方法是一次对所有 4 个模型的所有 p 值进行校正，这似乎是正确的做法，但我不确定。测试多重比较的正确方法是什么？
另一个问题是，我应该使用哪种多重比较校正方法？如果可能的话，我希望避开 Bonferroni。
感谢您的帮助，非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654335/correction-for-multiple-comparison-after-pairwise-comparison-on-4-models-with-r</guid>
      <pubDate>Fri, 13 Sep 2024 17:15:54 GMT</pubDate>
    </item>
    <item>
      <title>1 类错误是否与线性模型的模型精度相关</title>
      <link>https://stats.stackexchange.com/questions/654329/are-type-1-errors-associated-with-model-accuracy-for-linear-models</link>
      <description><![CDATA[在讨论预测因子的统计显著性时，至少很少会提到模型准确性。但是，我的直觉是，我更愿意相信更准确的模型（可能存在训练误差，但理想情况下是保留集上的一些误差）中各个预测因子的重要性，而不是不太准确的模型。
首先，高误差可能表明某些线性模型的函​​数形式不正确，或者我们缺少重要的预测因子。
在检查系数显著性时，是否有任何文献或先前讨论过将第 1 类误差与模型准确性联系起来？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654329/are-type-1-errors-associated-with-model-accuracy-for-linear-models</guid>
      <pubDate>Fri, 13 Sep 2024 14:36:28 GMT</pubDate>
    </item>
    <item>
      <title>卷积问题[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654328/convolution-problem</link>
      <description><![CDATA[如果滤波器 h 的系数之和为零，则在与图像 f(m,n) 进行卷积后，对于什么填充，所得卷积图像的元素之和也为零？]]></description>
      <guid>https://stats.stackexchange.com/questions/654328/convolution-problem</guid>
      <pubDate>Fri, 13 Sep 2024 13:50:34 GMT</pubDate>
    </item>
    <item>
      <title>具有相关和层次效应的元回归中异常大的系数</title>
      <link>https://stats.stackexchange.com/questions/654327/oddly-large-coefficients-in-meta-regression-with-correlated-and-hierarchical-eff</link>
      <description><![CDATA[我正在执行元回归，以调查参与者特征和研究特征对发病率比 (IRR) 估计的影响。我有 10 项研究的数据，每项研究都为不同的年龄组、性别和风险窗口长度贡献了多个效应估计。我的数据描述可以在此处找到。
我使用了具有稳健方差估计 (RVE) 和小样本校正的随机效应元回归（包 metafor 和 clubSandwich）。我选择相关和分层效应作为 RVE 的工作模型。结果变量是 IRR 的对数。
由于解释变量在研究内部和研究之间都存在差异，我使用这些变量的研究平均值和以研究平均值为中心的值来估计研究间和研究内效应，正如 Yaremych (2023) 所建议的那样
变量“男性比例”(prop_male_guess) 有 5 个级别：0%、&lt;45%、45%-55%、&gt;55%、100%。下表显示了我的数据中每个级别的分布情况，对角线单元格是具有该级别的研究数量（效果大小）：

由于级别“&lt;45%&gt;”仅出现在 1 项研究中，因此我将其与级别“45-55&gt;”合并 -&gt; 新级别“大致相等”。
当我用“男性比例”拟合模型时作为预测因子，截距和系数变得异常大：
#加载数据并拟合模型
urlfile=&quot;https://raw.githubusercontent.com/trangtph/Meta_Regression/main/example_data.csv&quot;
mydata&lt;-read_csv(url(urlfile))

# 恒定采样相关工作模型
rho_const &lt;- 0.7
V &lt;- vcalc(var, cluster = study_id, obs = effect_id, data = mydata, rho = rho_const)

# 具有组均值中心的模型
model_sex &lt;- 
rma.mv(log_effect ~ 1 + prop_male_merge_roughly.equal.c + prop_male_merge_.55.c + prop_male_merge_100.c +
prop_male_merge_roughly.equal_m + prop_male_merge_.55_m + prop_male_merge_100_m, 
V = V, 
random = ~ 1 | study_id / effect_id,
data = mydata, sparse = TRUE)

model_sex_robust &lt;- robust(model_sex, cluster=study_id, clubSandwich=TRUE)

这是模型输出：
多变量荟萃分析模型 (k = 122; 方法：REML)

方差成分：

estim sqrt nlvls 固定因子 
sigma^2.1 0.1044 0.3231 10 无 study_id 
sigma^2.2 0.3511 0.5925 122 无 study_id/effect_id 

调节器检验 (系数 2:7)：¹
F(df1 = 6, df2 = 0) = 0.0000, p-val = NA


研究内效应（协变量以“.c”结尾）很好，但截距和研究间效应（协变量以“_m”结尾）异常大（截距 13.4 将转化为不可能的 IRR 660003）。
我的问题是：我该如何解释我的模型的奇怪行为？。我的一个猜测是水平之间的相关性：“&lt;45&quot;、&quot;45-55&quot; &quot;&gt;55&quot; 从未在研究中同时出现。但我不确定。
附带问题：我的模型的自由度相当低。正如 Tipton (2015) 中所述，DF &lt;4 的 p 值不应被信任。那么，有没有办法在 RVE 中生成可靠的标准误差和 p 值？
欢迎提出任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/654327/oddly-large-coefficients-in-meta-regression-with-correlated-and-hierarchical-eff</guid>
      <pubDate>Fri, 13 Sep 2024 13:46:27 GMT</pubDate>
    </item>
    <item>
      <title>如何计算给定数据估计值的最小均方误差 (MMSE)？</title>
      <link>https://stats.stackexchange.com/questions/654326/how-to-calculate-minimum-mean-square-error-mmse-of-an-estimated-value-from-the</link>
      <description><![CDATA[我觉得这个问题真的很基础，但我对方法论感到困惑。
我必须根据观测值$k(g)$估计一个参数$g$，我有 PDF $f(g|k)$。
已知最小均方误差 (MMSE) 估计量可由以下公式得出：
$$\hat{g}(k)=\int_{_-\infty}^{\infty} g~f(g|k)~\partial{d}g$$
这是我使用数值积分得出的，现在我有几个 $\hat{g}$ 值，它们分别对应于 $g$ 的各种值。
均方误差 (MSE) 由 $$\mathbb{E}_{G|K}[(g-\hat{g}(k))^2].$$ 给出
现在我的问题是：
要用数字方式计算 MSE 的平均值，我是否可以简单地将获得的数值平均为 $$\frac{1}{N}\Sigma(g-\hat{g}(h))^2$$，其中 $N$ 是可用的 $g$ 估计值的总数（总迭代次数）。但是，如果我的意思确实是这样的，那么平均值是如何给出的：
（连续）$$\int xf(x)\text{d}x$$ 和（离散）$$\Sigma_i x_i P(x=x_i),$$ 其中 PDF/PMF 也在计算平均值时被考虑。
我是否需要进行数值积分，因为$$\int_{-\infty}^{\infty}(g-\hat{g}(h))^2f(g|y)\partial g?$$ 但是，我不认为这会给出正确的值，因为对于给定的估计数值$\hat{g}(k)$，我将在整个范围内进行积分为给定值 $$ 的 $g$]]></description>
      <guid>https://stats.stackexchange.com/questions/654326/how-to-calculate-minimum-mean-square-error-mmse-of-an-estimated-value-from-the</guid>
      <pubDate>Fri, 13 Sep 2024 13:39:59 GMT</pubDate>
    </item>
    <item>
      <title>参数属性的假设检验</title>
      <link>https://stats.stackexchange.com/questions/654323/hypothesis-testing-a-property-of-parameters</link>
      <description><![CDATA[假设我有 $n$ 个 i.i.d 观测值 $X = (X_1,X_2,\cdots,X_n)$，它们由某个分布 $p(x;\theta)$ 生成，其中 $\theta \in \mathbb{R}^m$ 是我想从观测值中推断出的未知参数。
我已经执行了最大似然估计，使用似然函数 $L(X;\theta)$ 获得了 MLE 估计值 $\hat{\theta_{\text{MLE}}} \quad$。
我想检验一个假设，即真实参数 $\hat{\theta_{\text{MLE}}} \quad$。 class=&quot;math-container&quot;&gt;$\theta$ 满足某些属性，即 $\theta \in \Omega$。我只能通过计算来测试这一点，即它不是某些分析属性。对于任何 $\theta$，我都必须模拟一些复杂的系统来检查该属性是否成立。
如何在频率论框架中计算检验 $\theta \in \Omega$ 的假设 $H_1$？
我的第一次直观尝试是这样的：我们知道在某些条件下，MLE 估计是渐近正态分布的 $\hat{\theta_{\text{MLE}}} \sim N(\theta,I_n(\theta)^{-1})$，其中 $I_n$ 是费希尔信息矩阵。我可以通过评估 $\hat{\theta_{\text{MLE}}}$ 处的似然函数的 Hessian 并取其逆来估计这个协方差矩阵 - 将此数量表示为 $H(\hat{\theta_{\text{MLE}}})$。
现在是棘手的部分：然后我抽样说 $k$ 估计 $\theta^{&#39;}_k \sim N(\hat{\theta_{\text{MLE}}},H(\hat{\theta_{\text{MLE}}}))$，并使用我的复杂程序评估 $ \theta^{&#39;}_k \in \Omega$ 是否成立。然后我计算成功的次数，这就是我接受假设的信心，即$\alpha = \sum_{k} \mathbb{1}( \theta^{&#39;}_k \in \Omega) / k$。
是否有任何程序可以将我正在做的事情形式化？有没有更好的方法来解决这个问题？我应该说我无法再收集任何数据了。
干杯]]></description>
      <guid>https://stats.stackexchange.com/questions/654323/hypothesis-testing-a-property-of-parameters</guid>
      <pubDate>Fri, 13 Sep 2024 12:46:13 GMT</pubDate>
    </item>
    <item>
      <title>关于生存建模中区间删失的澄清</title>
      <link>https://stats.stackexchange.com/questions/654313/a-clarification-on-interval-censoring-in-modeling-survival</link>
      <description><![CDATA[直到阅读 Vinh Nguyen 的 第 11 讲：区间删失和离散时间数据 (2012)，我才认为离散时间生存模型才是适合我们研究的统计方法。我的理解是离散时间生存分析 (Cox) 包括区间删失。然而，区间删失似乎是一种独立的技术（如果我错了，请纠正我）。现在，我有点困惑，区间审查方法或离散时间生存是否适合我的研究。
在我们的研究中，受试者每三个月（最多 18 个月）访问一次中心，在以下时间检查他们的疾病状态：T0、T3、T6、T9、T12、T15 和 T18。主要协变量 测试状态 是二元的且与时间相关（1 vs. 0）。事件是二元结果（1：健康状况下降，0：健康状况稳定）。这项研究是单一事件。数据可能看起来像这样：
ID TIME AGE EVENT TEST STATUS
1 0 45 0 0
1 3 45 1 1
2 0 46 0 0
2 3 46 0 1
2 6 46 0 0
2 9 46 1 1
3 0 34 0 0
3 3 34 0 0
3 6 34 0 1
3 9 34 0 1
3 12 34 0 0
3 15 34 0 1
3 18 34 1 0
]]></description>
      <guid>https://stats.stackexchange.com/questions/654313/a-clarification-on-interval-censoring-in-modeling-survival</guid>
      <pubDate>Fri, 13 Sep 2024 09:17:13 GMT</pubDate>
    </item>
    <item>
      <title>mmrm R 包：没有优化器导致模型拟合成功</title>
      <link>https://stats.stackexchange.com/questions/654310/mmrm-r-package-no-optimizer-led-to-a-successful-model-fit</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654310/mmrm-r-package-no-optimizer-led-to-a-successful-model-fit</guid>
      <pubDate>Fri, 13 Sep 2024 07:52:54 GMT</pubDate>
    </item>
    </channel>
</rss>