<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 06 Jan 2025 15:17:37 GMT</lastBuildDate>
    <item>
      <title>解释优化 MSE 的模型中的模块权重和激活函数</title>
      <link>https://stats.stackexchange.com/questions/659615/interpreting-module-weights-and-activation-functions-in-a-model-optimizing-mse</link>
      <description><![CDATA[正文：我正在使用一个由三个模块组成的模型：{A、B、C}。每个模块在预测股票价格方面都发挥着作用，模型的学习目标是最小化均方误差 (MSE)。
这些模块具有以下特点：
模块 A：具有较大的正权重。模块 B：具有较小的负权重。模块 C：具有接近于零的权重（例如，绝对值在 0.01 左右）。
权重是从检查点文件分析的，该文件是根据在验证集上评估的最佳性能参数保存的。
我试图了解这些权重如何影响模型以及某些设计决策背后的原理。以下是我的具体问题：
了解 A 和 B 的互补作用：
在训练期间，模块 A 的权重会以幅度（正向）增加，这会降低 MSE。另一方面，模块 B 的权重变得更负，也会降低 MSE。我发现很难解释为什么一个模块用较大的正权重学习，而另一个模块用较小的负权重学习。我如何理解它们的互补作用，特别是在股票价格预测这样的任务中？
ReLU 的历史用途：
虽然 ReLU 现在不那么常用，但它在过去被广泛使用。采用 ReLU 是否是为了故意忽略负面贡献，例如来自模块 B 的贡献？如果是这样，这是否意味着在某些任务或情况下负权重被认为意义较小？或者，主要动机是为了避免梯度消失或简化计算？
转向 GELU：
像 GELU 这样的现代激活函数允许使用负权重。这是否意味着负面贡献现在被认为更有意义，而 GELU 有助于在模型中保留它们的影响力？
删除权重接近于零的模块：
如果模块 C 的权重非常小（例如 0.01 或 -0.01），这是否应该是将其从模型中删除的信号？这是否表明模块 C 对模型没有做出有意义的贡献，特别是如果消融研究表明删除后没有性能差异？
我特别有兴趣在有效集优化检查点分析的背景下理解上述观点。
摘要：
我使用在验证集上优化的已保存检查点分析了模型权重。我希望了解为什么模块 A 以较大的正权重学习，而模块 B 以较小的负权重学习，两者都降低了 MSE。我还希望确定权重接近于零的模块 C 是否做出了有意义的贡献并应该保留。然而，我很难解释 A 和 B 的互补作用以及模块 C 接近零的权重与模型性能的相关性。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659615/interpreting-module-weights-and-activation-functions-in-a-model-optimizing-mse</guid>
      <pubDate>Mon, 06 Jan 2025 13:50:46 GMT</pubDate>
    </item>
    <item>
      <title>探索性因子分析，非正态数据</title>
      <link>https://stats.stackexchange.com/questions/659613/exploratory-factor-analysis-non-normal-data</link>
      <description><![CDATA[我正在分析的数据对于几乎每个观察到的变量都是非正态的。我想在 R 中进行探索性因子分析 (EFA)。KMO 检验和 Bartlett 检验表明数据符合 EFA 条件。在 psych 包的文档中，我没有找到应如何处理非正态分布的数据 (https://personality-project.org/r/psych/HowTo/factor.pdf)。我的样本相对较小 (N=60)。
在进行验证性因子分析时，我可以使用 lavaan 包中的 Satorra-Bentler 校正来处理非正态数据，cfa() 函数，例如cfa(model = spec, data = df_data, std.lv=TRUE, estimator = &quot;MLM&quot;) ，这种使用稳健标准误差的校正是一种可接受的方法。 estimator=&quot;MLM&quot; 代表 Satorra-Bentler 校正。我可以用 psych 包 以某种方式做到这一点吗？
psych 包执行 EFA，fa() 函数，例如fa(data, nfactors = 4, rotate = &quot;oblimin&quot;) 并提供可行的因子，但如果我没有弄错的话，它被设计用于正态分布的数据。
如果我尝试使用 lavaan 包 中的 efa() 和 Satorra-Bentler 校正，它会发出 警告，表示协方差矩阵包含较小的负值，这可能表明模型未被识别：
efa(data = df_data, nfactors=4, rotation=&quot;oblimin&quot;, std.lv=TRUE, estimator = &quot;MLM&quot;)

警告消息：
1：lavaan-&gt;lav_model_vcov()： 
估计参数 (vcov) 的方差-协方差矩阵似乎不是
正定！最小特征值 (= -5.425180e-15) 小于零。这可能是模型无法识别的症状。
2：lavaan-&gt;lav_model_vcov()：
估计参数 (vcov) 的方差-协方差矩阵似乎不是 
正定的！最小特征值 (= -2.190854e-32) 小于零。这可能是模型无法识别的症状。


所以问题是：如何使用非正态数据计算 EFA，可能使用 psych 包？]]></description>
      <guid>https://stats.stackexchange.com/questions/659613/exploratory-factor-analysis-non-normal-data</guid>
      <pubDate>Mon, 06 Jan 2025 12:41:19 GMT</pubDate>
    </item>
    <item>
      <title>auto_arima() 可以在行为不良的时间序列中使用吗？</title>
      <link>https://stats.stackexchange.com/questions/659612/can-auto-arima-be-used-in-badly-behaved-time-series</link>
      <description><![CDATA[也许我无法正确配置它，但是当将 Python 模块 pmdarima 的 auto_arima() 函数应用于表现不佳的时间序列（例如来自加密货币的 OHLC 数据的时间序列）时，我遇到了非常糟糕的体验。
您能否为我提供使用它的指南？由于 pmd_arima 大量借鉴了 Hyndman 在 R 中的 forecast 代码，我阅读了它的 vignette，似乎整个算法最适合 (p, d, q) 分量的低值。]]></description>
      <guid>https://stats.stackexchange.com/questions/659612/can-auto-arima-be-used-in-badly-behaved-time-series</guid>
      <pubDate>Mon, 06 Jan 2025 12:11:24 GMT</pubDate>
    </item>
    <item>
      <title>解释 R 中零膨胀模型的均值预测：为什么零膨胀均值与原始均值不同？</title>
      <link>https://stats.stackexchange.com/questions/659607/interpreting-mean-predictions-from-zero-inflated-models-in-r-why-do-zi-adjusted</link>
      <description><![CDATA[我使用以下代码在 R 中拟合零膨胀模型：glmmTMB(score ~ year - 1 + (1 | farm), ziformula = ~ year - 1, data = data, family = &quot;nbinom2&quot;)
为了提取我的分数的平均预测值，我使用以下方法：

对于&quot;true&quot;零：exp(fe_mod4$cond)
包括零膨胀公式：exp(fe_mod4$cond) * (1 - plogis(fe_mod4$zi))
直接从样本计算的原始均值，没有任何模型。

结果均值如下：
年份 原始均值 均值（不含 ZI） 均值（含 ZI）
1 0.5 1.1 0.4
2 0.9 1.6 0.6
3 0.6 1.4 0.4
4 0.4 1.2 0.4
5 0.5 1.5 0.4

问题：

为什么用零膨胀 (ZI) 公式计算的均值与原始均值非常相似样本均值？
为什么使用 ZI 公式和不使用 ZI 公式计算出的均值之间存在很大差异？这是否表明背景效应导致模型（不使用 ZI）没有考虑到过多的零值？
为什么我们对没有零膨胀 (ZI) 部分的结果感兴趣？
如果 ZI 调整后的预测与原始数据均值非常相似，那么我们为什么需要这个模型，使用 ZI 公式进行预测的目的是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/659607/interpreting-mean-predictions-from-zero-inflated-models-in-r-why-do-zi-adjusted</guid>
      <pubDate>Mon, 06 Jan 2025 09:09:38 GMT</pubDate>
    </item>
    <item>
      <title>估计量的偏差是否取决于观测值的数量？预期值的实际解释</title>
      <link>https://stats.stackexchange.com/questions/659603/can-the-bias-of-an-estimator-depend-on-the-number-of-observations-practical-int</link>
      <description><![CDATA[这里表示
$\hat{\theta}=\frac{1}{n} \sum x_i + \frac{1}{n}$
是样本均值的有偏估计量。
我们来看看：
\begin{align}
\mathbb{E}(​​\hat{\theta}) &amp;= \frac{1}{n} \sum \mathbb{E}(​​x_i) + \frac{1}{n} \\
&amp;= \frac{1}{n} \sum \mu + \frac{1}{n} \\
&amp;= \frac{n \cdot \mu}{n} + \frac{1}{n} \\
&amp;= \mu + \frac{1}{n} \\
\end{align&gt;
因此偏差是观察次数的函数。
我觉得这很奇怪。
以下是我对如何计算$\mathbb{E}(​​\hat{\theta})$的直觉。
我们从总体中抽取一个大小为$n_1$的样本。称之为$x^{(1)} \in \mathbb{R}^{n_1}$。
我们应用函数来计算平均值$\hat{\theta}^{(1)}$的估计值。
在这种情况下$\hat{\theta}^{(1)}=\frac{1}{n} \sum x^{(1)}_i + \frac{1}{n}$。
我们从总体中抽取另一个样本，大小为$n_2$。称之为$x^{(2)} \in \mathbb{R}^{n_2}$。
我们应用我们的函数来计算平均值$\hat{\theta}^{(2)}$的估计值。
我们从总体中抽取另一个样本，大小为$n_3$。称之为$x^{(3)} \in \mathbb{R}^{n_3}$。
我们应用我们的函数来计算平均值$\hat{\theta}^{(3)}$的估计值。
我们以此方式进行无数次。
然后我们取所有这些估计值的平均值（期望值）。
$\mathbb{E}(​​\hat{\theta}) = (\hat{\theta}^{(1)}+\hat{\theta}^{(2)}+\hat{\theta}^{(3)}+\cdots+\hat{\theta}^{(N)})/N$
根据这种解释，期望值取决于观察次数似乎很奇怪。
观察次数是多少？我是否必须有同样大小的样本？
编辑：我发现，由于我的估计量本身是观察次数的函数，因此其预期值是观察次数的函数也就不足为奇了。然后我必须固定 $n$，因此样本大小相同（也就是说，更改 $n$ 会改变估计量）。
不过，由于我进行了无限次采样，因此预期值取决于样本大小感觉很奇怪。]]></description>
      <guid>https://stats.stackexchange.com/questions/659603/can-the-bias-of-an-estimator-depend-on-the-number-of-observations-practical-int</guid>
      <pubDate>Mon, 06 Jan 2025 07:53:24 GMT</pubDate>
    </item>
    <item>
      <title>$|μ| \gg σ$ 的 Delta 方法近似条件</title>
      <link>https://stats.stackexchange.com/questions/659598/condition-for-delta-method-approximation-for-%ce%bc-gg-%cf%83</link>
      <description><![CDATA[我试图理解当 $|μ|$ 远大于 $σ.$ 时 Delta 方法近似的数学依据。具体来说，我正在寻找以下公式的证明：
$$ E[g(X)] \approx g(\mu) + \frac{1}{2}g&#39;&#39;(\mu)\sigma^2 $$
$$ \operatorname{Var}[g(X)] \approx (g&#39;(\mu))^2\sigma^2 $$
其中 $X$ 是均值为 $μ$ 的随机变量和标准偏差 $σ,$ 和 $g$ 是一种变换。
我不确定获取这些简化形式所涉及的具体步骤和假设。
我有一些问题：
条件 $|μ| \gg σ$ 是如何正式定义或量化的？我的讲义中提到了这个条件。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659598/condition-for-delta-method-approximation-for-%ce%bc-gg-%cf%83</guid>
      <pubDate>Mon, 06 Jan 2025 03:46:26 GMT</pubDate>
    </item>
    <item>
      <title>除了单纯形之外，狄利克雷分布还有哪些其他支持的推广形式？</title>
      <link>https://stats.stackexchange.com/questions/659565/is-there-any-generalization-of-the-dirichlet-distribution-to-supports-other-than</link>
      <description><![CDATA[让我们考虑$(\theta_1,\theta_2,\ldots,\theta_k) \sim \operatorname{Dirichlet}(a_1,a_2,\ldots,a_k)$。我想知道我们是否还有$\theta_1 &gt; \varepsilon_1, \theta_2 &gt; \varepsilon_2,\ldots,\theta_k &gt; \varepsilon_k,$ 其中 $\varepsilon_i \geq 0, \forall i \in \{1,2,\ldots,k\}$ 是已知常数。
是否有任何已知的分布或封闭的解析形式？
我曾尝试通过条件概率计算来发展这个想法，但这有点具有挑战性。]]></description>
      <guid>https://stats.stackexchange.com/questions/659565/is-there-any-generalization-of-the-dirichlet-distribution-to-supports-other-than</guid>
      <pubDate>Sun, 05 Jan 2025 14:41:16 GMT</pubDate>
    </item>
    <item>
      <title>识别与平方根过程相关的随机过程的分布</title>
      <link>https://stats.stackexchange.com/questions/659526/identifying-the-distribution-of-a-random-process-associated-to-the-square-root-p</link>
      <description><![CDATA[让 $x(t)$ 成为遵循以下的随机平方根过程
$$dx(t) = (a + bx(t)) \, dt + c\sqrt{x(t)} \, dW(t)$$
其中 $W(t)$ 是某些过滤的标准布朗运动。
它有很多名字，但出于本文的目的，我不会提及它们。如果我们定义
$$ \varphi(u;t,h) = \mathbb E\left( e^{u x(t+h)} \mid x(t) \right); \quad u\in \mathbb C$$
那么我可以证明对于 $\Re(u) \leqslant 0$，我们有
$$
\mathbb E(e^{u x(t+h)} \mid x(t) = x ) = 
\frac{1}{\left(1- 2z(h)u
\right)^{\frac k2}}\exp\left(
\dfrac{\lambda(t)x\cdot z(h)u }{1- 2z(h)u}
\right) $$
其中 $z(h) = q(h)e^{bh}\frac{c^2}{4}$，$q(h) = \dfrac{1-e^{-bh}}{b}$，$\lambda(h) = \frac{4q(h)^{-1}}{c^2}$ 和 $k = \frac{4a}{c^2}$。因此，在 $x(t)$ 条件下，我们有
$$
z(h)^{-1} x(t+h) \sim \chi_k^2(\lambda(h)^{-1}x(t))
$$
其中右边是非中心卡方分布，具有 $k$ 自由度和非中心参数 $\lambda = \lambda(h)^{-1}x(t)$。具体来说，我们可以让 $c=2$ 和 $b\to 0$ 恢复平方贝塞尔过程满足
$$
h^{-1} x(t+h) \sim \chi_k^2(h^{-1}x(t))
$$
这是众所周知的。

现在考虑联合过程$y(t) = \left( \int_0^t x(s) \, ds, x(t) \right)$。然后，我可以证明联合条件特征函数
$$\varphi(u;t,h) = 
\mathbb E\left( e^{u\cdot y(t+h)}\mid y(t) \right); \quad u\in \mathbb C^2 
$$
对于 $y(t) = (y_1, y_2)$ 等于
$$ \varphi(u;t,h) = \frac1 {\left(1- 2z \right)^{\frac k2}}
\exp\left(\dfrac{ \lambda z}
{1- 2 z}y_2 + v y_2\right)\exp(u_1 y_1 + ah v(u_1))
$$
其中 $v(u_1)$ 是 $\frac 12 c^2 v^2 + bv = u_1$ 的解，并且
\begin{align*}
z(h,u) &amp;= (u_2 - v(u_1))e^{(b + v(u_1) c^2)h} \lambda^{-1}(h,u) \\
\lambda(h,u) &amp;= \frac{4}{c^2}q_0(h,u)^{-1} \\
q_0(h, u) &amp;= \dfrac{1-e^{-(b + v(u_1)c^2)h}}{b + v(u_1)c^2} 
\end{align*&gt;
一个明显的检查是，如果 $u_1=0$ 那么我们可以连续选取 $v(u_1)=0$ 并且那么特征函数就是 $x(t)$，正如它应该的那样。
但是，我无法识别这个联合分布。我最天真的猜测是，它可能是广义卡方分布，如这里，但我没有取得太大进展。
有人知道该怎么做吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659526/identifying-the-distribution-of-a-random-process-associated-to-the-square-root-p</guid>
      <pubDate>Sat, 04 Jan 2025 12:28:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 GEE 和 GLMM 分析离散数据中的相关性</title>
      <link>https://stats.stackexchange.com/questions/659520/analyzing-correlation-in-discrete-data-with-gee-and-glmm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659520/analyzing-correlation-in-discrete-data-with-gee-and-glmm</guid>
      <pubDate>Sat, 04 Jan 2025 06:01:42 GMT</pubDate>
    </item>
    <item>
      <title>为每个受试者建模累积率</title>
      <link>https://stats.stackexchange.com/questions/659518/modelling-cumulative-rates-per-subject</link>
      <description><![CDATA[有多个受试者，每个受试者都有多个观察结果（每次测量时都会观察到连续的预测因子，并观察到 ​​0/1 的响应）。纵向回归可用于对每个受试者的（演变）累积率进行建模吗？

例如：对于每个受试者 $i$ 和时间点 $t$，观察一个二元结果 $Y_{it}$（0 或 1）和一个预测因子向量 $X_{it}$。累积率 $R_{it}$ 是截至时间 $t$，对于主题 $i$，积极响应的比例：
$$R_{it} = \frac{\sum_{s=1}^t Y_{is}}{t}$$
基本逻辑回归：
$$\text{logit}(E[R_{it}|X_{it}, b_i]) = X_{it}^\top \beta + \gamma t + b_i$$
其中：

$\beta$是固定效应系数
$b_i$ 是主题 $i$ 的随机效应，例如 $b_i \sim N(0, \sigma_b^2)$
主题级别的相关性：$\text{Corr}(R_{it}, R_{is}) = \rho^{|t-s|}$

我想也许可以使用 Beta 分布回归，但它有点超出我的理解范围，我想保持简单。但我认为由于 Beta 分布模拟比例响应，它也可能合适。
有什么想法？]]></description>
      <guid>https://stats.stackexchange.com/questions/659518/modelling-cumulative-rates-per-subject</guid>
      <pubDate>Sat, 04 Jan 2025 03:52:05 GMT</pubDate>
    </item>
    <item>
      <title>BAM mgcv 算法的可重复性</title>
      <link>https://stats.stackexchange.com/questions/659490/reproducibility-of-bam-mgcv-algorithm</link>
      <description><![CDATA[我经常处理大型空间数据集，其中 mgcv 中实现的 bam() 算法非常适合。对于我的分析来说，点估计的可重复性是一个关键问题，不幸的是，我经常看到 BAM 预测的结果取决于所用数据集中数据点的顺序。
最小可重复示例
以下内容基于由协变量 x、y 和目标变量 z 组成的 15.000 个数据点的数据集，可在此处下载：https://drive.google.com/file/d/16dZ66KmT4CrQHkVQtw7vRP065SoztUNg/view?usp=drive_link
另请注意，在执行每个代码示例之前下面，数据集已重新加载并使用相同的随机种子进行了混洗。
首先考虑使用 bam() 拟合的结果：
set.seed(1)

model1 &lt;- mgcv::bam(z ~ s(x, y, k = 100),
data = dataset,
family = Gamma(link = log),
method = &quot;REML&quot;)

dataset &lt;- dataset[sample(nrow(dataset)),]

model2 &lt;- mgcv::bam(z ~ s(x, y, k = 100),
data = dataset,
family = Gamma(link = log),
method = &quot;REML&quot;)

#calculate response on scale of linear predictor
dataset$pred_model1 &lt;- as.vector(predict.gam(model1, dataset))
dataset$pred_model2 &lt;- as.vector(predict.gam(model2, dataset))
plot(dataset$pred_model1, dataset$pred_model2)

这将生成以下图表：

现在考虑 gam() 的结果：
model1 &lt;- mgcv::gam(z ~ s(x, y, k = 100),
data = dataset,
family = Gamma(link = log),
method = &quot;REML&quot;)

数据集 &lt;- 数据集[sample(nrow(数据集)),]

模型2 &lt;- mgcv::gam(z ~ s(x, y, k = 100),
数据 = 数据集,
family = Gamma(link = log),
method = &quot;REML&quot;)

#计算线性预测器尺度上的响应
数据集$pred_model1 &lt;- as.vector(predict.gam(model1, dataset))
数据集$pred_model2 &lt;- as.vector(predict.gam(model2, dataset))

plot(数据集$pred_model1, dataset$pred_model2)


这将生成以下图表：

所以我的问题是：这种行为是预料之中的，还是我这边的一个错误？如果这只是使用 bam() 时必须忍受的事情，那么除了始终确保数据点的顺序相同之外，还能做些什么来确保可重复性？
我已经通过尝试 k=1000 个基函数来测试它是否与有限的空间分辨率有关。在这里我发现了同样的问题。然而，我确实看到将数据集大小减少到只有 1000 个数据点可以大大减少问题。然而，这不是理想的解决方案，因为我想使用所有数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/659490/reproducibility-of-bam-mgcv-algorithm</guid>
      <pubDate>Fri, 03 Jan 2025 13:43:22 GMT</pubDate>
    </item>
    <item>
      <title>“AUROC 曲线”这个术语实际上是否正确且有意义？</title>
      <link>https://stats.stackexchange.com/questions/659370/is-the-term-auroc-curve-actually-correct-or-meaningful</link>
      <description><![CDATA[15 年前，当我进入机器学习领域时，我了解到 AUC 代表“曲线下面积”，即“ROC 曲线下面积”，而 ROC 是“接收者操作特性”。
现在我自己在指导学生，（当然）他们有时会根据他们首先阅读的文献和资料使用不同的术语。我听说过 AUROC，根据这里的一些观点，它比 AUC 更好，因为后者没有指定指的是哪条曲线，而且除了 ROC 之外还有其他可能。
但后来我读到 AUROC 曲线，它在很多层面上听起来都是错误的。 （我不是以英语为母语的人。）
您指的是曲线下的面积，即 AUC 或 AUROC，或曲线本身，即ROC 曲线，因此 AUROC 曲线对我来说真的没有意义。但是，通过 CV 搜索我发现它被使用了几次，但从未被更正或解决，例如

为什么 ROC 曲线和 AUC 值并不总是相关的？
如何解释抵押贷款拒绝/批准的 AUROC 曲线？
如何解释 AUROC分数？

所以，我的问题是：我在这里是对的还是过于迂腐？还是忽略了一些显而易见的东西？
澄清：
似乎我的问题含糊不清，我应该澄清：
我的问题是使用术语“AUROC 曲线”来表示曲线，而不是值，例如

对于随机分类器，AUROC 曲线将是一条从 [0,0] 到 [1,1] 的对角线
]]></description>
      <guid>https://stats.stackexchange.com/questions/659370/is-the-term-auroc-curve-actually-correct-or-meaningful</guid>
      <pubDate>Mon, 30 Dec 2024 15:26:49 GMT</pubDate>
    </item>
    <item>
      <title>可视化多种样品类型和杂质水平的 PCA 结果</title>
      <link>https://stats.stackexchange.com/questions/659145/visualizing-pca-results-with-multiple-sample-types-and-impurity-levels</link>
      <description><![CDATA[我正在对一个数据集执行主成分分析 (PCA)，该数据集包含四种材料 (a、b、c、d) 的样本，这些样本的杂质水平各不相同 (10%、20%、30% 和 40%)。此外，还有一个纯样本 (p)。
我打算使用 R 创建一个分数图，以根据这些样本的主要成分直观地显示这些样本的分离情况。我希望在图中有效地表示样本类型 (a、b、c、d、p) 和杂质水平 (10%、20%、30%、40%)。
我正在寻找有关如何在分数图中以最佳方式直观地编码此双重信息 (样本类型和杂质水平) 的建议。是否有既定的最佳实践或建议用于在 PCA 得分图中表示多个分类变量？
其他详细信息
• 数据有 17 列（a、b、c、d 及其级别以及纯样本）和 949 行。
任何见解或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659145/visualizing-pca-results-with-multiple-sample-types-and-impurity-levels</guid>
      <pubDate>Tue, 24 Dec 2024 09:54:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 G*Power 进行样本量估计</title>
      <link>https://stats.stackexchange.com/questions/654196/sample-size-estimation-using-gpower</link>
      <description><![CDATA[我正在尝试使用 G*Power 为一个我打算做的项目计算先验样本量。我将在两个时间点（T1、T2）收集两组参与者的反应时间数据。实验将是一个简单的非语言 Stroop 任务，包含三个实验条件（带有情绪面孔 - 快乐、愤怒、中性）和一个控制条件（无情绪面孔）。将在 T1 和 T2 时比较各组，并在两个时间点进行组内比较。将在 T1 和 T2 时比较各组，并在两个时间点进行组内比较。
我如何估计每个组的样本量？在这种情况下，组数和测量次数是多少？
G*Power 能够进行这种估计吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654196/sample-size-estimation-using-gpower</guid>
      <pubDate>Wed, 11 Sep 2024 08:48:36 GMT</pubDate>
    </item>
    <item>
      <title>“不可预测”的定义</title>
      <link>https://stats.stackexchange.com/questions/620271/definition-of-unpredictable</link>
      <description><![CDATA[在点和密度预测的情况下，我们如何严格定义术语“不可预测”？
术语“不可预测”用于各种上下文，例如

“抛一枚公平硬币的结果是不可预测的”，
“随机游走的增量是不可预测的”或
“在信息有效的市场中，价格变化是不可预测的”。

这些陈述并非完全正确，因为人们总是可以提供预测，无论预测多么不准确。我可以做出点数预测（硬币将出现正面；增量为 0.18879；价格变化为 0.12 英镑）或密度预测（$P(\text{heads})=0.51$，增量为 N(0,0.4)，价格变化为 ...）。
直观地说，“不可预测”意味着“无法比一些简单/朴素/自然的基准更准确地预测”，例如“抛硬币的最佳密度预测是 $P(\text{heads})=0.5$”。但随后我们需要定义“最佳”的含义在评估密度预测时。
那么，我们如何严格定义“不可预测”一词？
关键词：不可预测、不可预测、可预测性、可预测性。]]></description>
      <guid>https://stats.stackexchange.com/questions/620271/definition-of-unpredictable</guid>
      <pubDate>Sat, 01 Jul 2023 18:56:43 GMT</pubDate>
    </item>
    </channel>
</rss>