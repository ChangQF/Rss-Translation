<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 07 Apr 2024 12:22:10 GMT</lastBuildDate>
    <item>
      <title>动量 SGD：特征值</title>
      <link>https://stats.stackexchange.com/questions/644491/sgd-with-momentum-eigenvalues</link>
      <description><![CDATA[我正在阅读《动量如何真正发挥作用》一文（https://distill.pub/2017/momentum/），我特别困惑两点：

可用步长的范围为 $0&lt;αλ_i&lt;2+2β$，对于 $0 ≤β&lt;1$。这里的推理是：这可以通过以上述收敛率的显式形式减少所有 4 + 1 情况的不等式来导出。但老实说我不明白那部分。
我正在尝试从以下方程推导出动量的收敛速度：

&lt;块引用&gt;
$\min_{\alpha, \beta}\max\lbrace \parallel \begin{pmatrix}
\beta &amp; \lambda_1 \\
-\alpha\beta &amp; 1-\alpha\lambda_1
\end{pmatrix} \parallel, ..., \parallel \begin{pmatrix}
\beta &amp; \lambda_n \\
-\alpha\beta &amp; 1-\alpha\lambda_n
\end{pmatrix} \并行\rbrace$

$\parallel\parallel$ 这里表示最大特征值的大小，当对极值对应的矩阵重复特征多项式的根时出现特征值。所以我们知道 R 的特征值：
$\sigma_i =\frac{1}{2}(1-\alpha\lambda+\beta\pm\sqrt{(-\alpha\lambda+\beta+1) ^2-4\测试版})$
但不知何故，我不知道如何在这里进行代数。有人可以帮忙吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644491/sgd-with-momentum-eigenvalues</guid>
      <pubDate>Sun, 07 Apr 2024 10:08:17 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯观点中的“数据是固定的”和频率论观点中的“数据是随机的”在数学上谈论的是同一件事吗？</title>
      <link>https://stats.stackexchange.com/questions/644489/are-data-are-fixed-in-bayesian-viewpoint-and-data-are-random-in-frequentist</link>
      <description><![CDATA[在我看来，在贝叶斯推理和频率推理中，观测数据$x$被建模为随机变量的观测值$X$ 遵循一定的概率分布。因此，当我遇到这两个语句时 - “数据已固定”从贝叶斯观点来看，“数据是随机的”。从频率论的角度来看，我发现它们很难理解，因为它似乎表明对数据概念的解释存在差异。
读了一些资料后，似乎“数据是固定的”是指观察到的数据$x$是固定的，“数据是随机的”是指随机变量&lt; span class=&quot;math-container&quot;&gt;$X$ 是随机的。这两个陈述中的“数据”所指的并不是同一件事。不确定我的解释是否正确。欢迎您的建议。如果我的解释是正确的，那么这两个陈述是否多余/令人困惑？]]></description>
      <guid>https://stats.stackexchange.com/questions/644489/are-data-are-fixed-in-bayesian-viewpoint-and-data-are-random-in-frequentist</guid>
      <pubDate>Sun, 07 Apr 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 mlexperiments 和 mllrnrs 对多变量 lightgbm 机器学习模型进行交叉验证</title>
      <link>https://stats.stackexchange.com/questions/644487/how-to-do-cross-validation-for-multi-variate-lightgbm-machine-learning-model-usi</link>
      <description><![CDATA[我尝试使用轻型 GBM 模型来拟合多元时间序列。为了构建模型，我使用 mlexperiments 和 mllrnrs。

使用 timetk 和 Sample 分割时间序列

 分割 &lt;- 生产 %&gt;%time_series_split(date_var = newdate,assess=&quot;4 个月&quot;,cumulative = TRUE)
训练 &lt;- rsample::training(splits)%&gt;% select(-newdate)
测试 &lt;- rsample::testing(splits)%&gt;% select(-newdate)


创建时间序列折叠

fold_list&lt;- splitTools::create_timefolds(y = unlist(train_y),k = 5L, use_names = T, type =c (“扩展”))


设置参数和参数网格

#必需的学习者参数，未优化
learner_args &lt;- 列表(
  最大深度=-1L，
  详细 = -1L，
  目标=“回归”，
  公制＝“l2”
）

为mlexperiments::MLCrossValidation 和mlexperiments::MLNestedCV 所需的预测函数和性能指标设置参数
predict_args &lt;- NULL
Performance_metric &lt;- metric(“rmse”)
Performance_metric_args &lt;- NULL
return_models &lt;- TRUE

网格搜索所需
parameter_grid &lt;- Expand.grid(
  bagging_fraction = seq(0.6, 0.8, .2),
  特征分数 = seq(0.6, 0.8, .2),
  min_data_in_leaf = seq(20, 40, 4),
  学习率 = seq(0.1, 0.2, 0.1),
  num_leaves = seq(2, 20, 4))

optim_args &lt;- 列表（
  iters.n = ncores,
  卡帕 = 3.5，
  acq=“ucb”；
）


调整模型

 调谐器 &lt;- mlexperiments::MLTuneParameters$new(
  学习者 = mllrnrs::LearnerLightgbm$new(
        metric_optimization_higher_better = FALSE)，策略 = “网格”，ncores = ncores，seed = 种子)

    调谐器$parameter_grid &lt;-parameter_grid
调谐器$learner_args &lt;- learner_args
调谐器$set_data(x = train_x,y = train_y)
tuner_results_grid &lt;-tuner$执行(k = 3)

在此之前我可以完美地运行代码。
但是当我开始进行交叉验证时
验证器 &lt;- mlexperiments::MLNestedCV$new(
+ 学习者 = mllrnrs::LearnerLightgbm$new(
+ metric_optimization_higher_better = FALSE
+ ),
+策略=“网格”，
+ 折叠列表 = 折叠列表,
+ k_tuning = 3L,
+ ncores = ncores,
+ 种子 = 种子
+)
&gt;验证器 &lt;- mlexperiments::MLNestedCV$new(
+ 学习者 = mllrnrs::LearnerLightgbm$new(
+ metric_optimization_higher_better = FALSE
+ ),
+策略=“网格”，
+ 折叠列表 = 折叠列表,
+ k_tuning = 3L,
+ ncores = ncores,
+ 种子 = 种子
+)
&gt;验证器$parameter_grid &lt;-parameter_grid
&gt;验证器$learner_args &lt;- learner_args
&gt; validator$split_type &lt;- &quot;分层&quot;
&gt;验证器$predict_args &lt;-predict_args
&gt;验证器$performance_metric &lt;- Performance_metric
&gt;验证器$performance_metric_args &lt;- Performance_metric_args
&gt;验证器$return_models &lt;- return_models
&gt;验证器$set_data(
+ x = 火车_x,
+ y = 火车_y
+)
&gt; validator_results &lt;- validator$execute()

我收到一个错误
&lt;块引用&gt;
CV 折叠：kdry::mlh_subset(private$x, train_index) 中的 Fold1 错误：
ids 必须是整数

当我检查验证器环境时，我发现......
我的代码中的以下行
fold_list = Fold_list

不工作。 mlexperiment 和 mllrns 尚未准备好接受时间序列分割输出，每次折叠都有样本内和样本外。
如何解决这个问题。为什么 mlexperiment 和 mllrns 不支持时间序列分割？]]></description>
      <guid>https://stats.stackexchange.com/questions/644487/how-to-do-cross-validation-for-multi-variate-lightgbm-machine-learning-model-usi</guid>
      <pubDate>Sun, 07 Apr 2024 06:57:48 GMT</pubDate>
    </item>
    <item>
      <title>估计 2 个随机变量的商</title>
      <link>https://stats.stackexchange.com/questions/644486/estimation-of-a-quotient-of-2-random-variables</link>
      <description><![CDATA[我是一名数学家，统计学知识为零。那么问题来了
假设我有 3 个随机变量，$X$（噪声图像的像素矩阵），$Y$ （去噪未知图像的像素矩阵），$Z$（高斯噪声的像素矩阵），通过$$X=Y.Z$$
实际上，$X$ 数据是已知的，由特定审查员收集。审查器具有未知的噪声特征，由 $Z$ 表示。 $Z$ 的均值和方差已知，我们可以做出合理的假设 $Z$ 独立于 $X$ 和 $Y$。
估计 $Y$ 的最佳方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644486/estimation-of-a-quotient-of-2-random-variables</guid>
      <pubDate>Sun, 07 Apr 2024 06:48:46 GMT</pubDate>
    </item>
    <item>
      <title>每个分类因素还是所有分类因素的对比？</title>
      <link>https://stats.stackexchange.com/questions/644485/contrasts-by-each-categorical-factor-or-by-all</link>
      <description><![CDATA[我有以下模型：
Cmic_mg_cm2 ~ 组*样本日期 +mean_ph +mean_shan_veg +mean_tree_shandiv + (1|图)
group 和sample_date 都是分类因子变量
我用它来检查以下问题：
对于给定的样本日期，各组之间是否存在差异？
给定组的样本日期之间是否存在差异？
协变量是否有影响？
该模型纯粹用于推断，而不是用于预测 - 包含随机效应来处理采样的伪复制。
当检查与 R emmeans 包的对比时，可以选择检查所有配对，仅检查“组”。对并且仅“sample_date”对。我的问题是，哪个更有效，因为当然将所有对组合起来会导致更多的多次测试，因此在对此进行调整时会受到更高的惩罚。]]></description>
      <guid>https://stats.stackexchange.com/questions/644485/contrasts-by-each-categorical-factor-or-by-all</guid>
      <pubDate>Sun, 07 Apr 2024 05:34:52 GMT</pubDate>
    </item>
    <item>
      <title>使用回归似然从回归中复制 t 或 F 检验</title>
      <link>https://stats.stackexchange.com/questions/644482/replicate-t-or-f-test-from-regression-using-regression-likelihoods</link>
      <description><![CDATA[我听说我们用来获取回归结果显着性的 t 检验和 F 检验是从似然比检验得出的，但我在复制 t/F 的 p 值时遇到了麻烦对回归似然进行似然比检验的检验
使用底部的数据集，
在 R 中运行这三个回归：
withCov&lt;-lm(Y~X)
logLik(withCov) # &#39;log Lik。&#39; -61.98043（df=3）
与Int&lt;-lm(Y~1)
logLik(withInt) # &#39;log Lik.&#39; -63.18456（df=2）
有无&lt;-lm(Y~0)
logLik(withNone) # &#39;log Lik.&#39; -65.32909（df=1）

例如，当我对 beta_1 的显着性进行似然比检验时，我得到
1-pchisq(2*(logLik(withCov)-logLik(withInt)),df = 1)
# 0.1206958
＃ 相比于
摘要（withCov）
称呼：
lm(公式 = Y ~ X)

残差：
     最小 1Q 中值 3Q 最大
-1.98508 -0.44415 -0.02294 0.59907 1.66593

系数：
            估计标准。误差t值Pr(&gt;|t|)
（截距）-0.2568 0.1206 -2.129 0.0384 *
X -0.2045 0.1329 -1.53​​9 0.1304
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残余标准误差：48 自由度上为 0.8531
多重 R 平方：0.04702，调整 R 平方：0.02717
F 统计量：1 和 48 DF 上为 2.369，p 值：0.1304

虽然值很接近，但 0.1304 显然与 0.1206958 不同。
对于似然比检验的所有 6 种组合，我无法从 lm 恢复任何 p 值。
我做错了什么？谢谢！
下面的 R 代码设置 X 和 Y 变量：
&lt;预&gt;&lt;代码&gt;X&lt;-c(0.147462983739098,-0.552822250273655,0.0791413008277721,1.64705442993914,0.68248797132517,-0.315633973636888,1. 40047872456033,0.776033233883272,-0.343689753439294,-0.526351059575156,0.275611183793461,1.7751174954305,-0.932913434395753,0 .163895795533468,-1.00807323166609,-0.434797856886559, 0.112072003876197,-0.319445372479459,1.6989373340732,0.639738727242407,0.02980494131095,0.564230726111237,1.61191604859755, -0.474733281647485,-1.46213462226689,-1.33823497263023,0.0771907623203949,-0.698998017227839,-0.775816444324552,1.46468840793 603,-0.0940659257837727,-1.85718512842644,0.109762500597346,0.293088069440979,-1.33774986808507,0.804321505460817,1.246387803 51287 ,-1.66909878637454,-0.107871283787089,-0.286526054190293,-1.30268476505327,0.241186917275982,0.0941940655245403,0.426156461 908492,-0.951908401332523,-0.782389908678191,0.436387212517629,0.491981905432585,0.863964246361868,-0.715853080383197)
Y＜-c(0.123592053622774，-0.156626343170975，-1.00704515111936，-0.333485064105835，0.539121555715671，0.0827543989201612，-1.381 38102448818,-0.510996824863877,1.40679987755037,-0.289587787513398,-1.00983646108717,0.20397559183913,-1.53​​795623798144,-0.37 4138120013244,0.753381985793875,-0.195106670583694,-0.395410227522805, 0.314058948313302,-0.567075906102368,-0.823999734395967,0.334195737940288,-0.382748868492066,-1.1924589353617,-2.1447830778 6596,0.198528331051895,0.616636192164357,-1.66623239116232,0.906880778089087,0.663909698659448,-0.96026161021686,-0.028951352 9973109,0.103477089026045,-0.517840007699842,-1.42770065687853,-1.18735568345121,0.441872906307648,- 0.814014579874374,-0.96658546843308,0.474244931448731,-0.975319336891573,-0.0672523439350411,-0.743286641930158,0.788159757 412595,1.23723123779866,-0.508581741865352,0.220065470600985,0.822051420773978,-0.383737198032438,-2.04890944754108,1.5555393 999865)
]]></description>
      <guid>https://stats.stackexchange.com/questions/644482/replicate-t-or-f-test-from-regression-using-regression-likelihoods</guid>
      <pubDate>Sun, 07 Apr 2024 01:59:46 GMT</pubDate>
    </item>
    <item>
      <title>哪种统计方法最适合 A/B 测试中的不同转化率？</title>
      <link>https://stats.stackexchange.com/questions/644483/which-statistical-approach-is-best-for-diverse-conversion-rates-in-an-a-b-test</link>
      <description><![CDATA[我们的软件初创公司为电子商务网站构建聊天机器人。聊天机器人与打开聊天机器人的顾客进行对话，目标是完成商店主要产品的销售。我们有大约 100 家活跃的电子商务商店使用我们的聊天机器人。聊天机器人对话要么会促成销售，要么不会，因此我们正在优化的指标是每个商店的转化率。
我们希望对所有商店的聊天机器人运行 A/B 测试，以衡量转化率的改进情况。我们的目标是进行变革，以最大限度地提高所有类型商店（大/小，无论什么产品类别）的整体转化率。
以下是使我们的场景变得棘手的主要考虑因素：

每家商店都有不同的内在转化率，因为我们的商店属于所有类型的类别并且具有不同的客户人口统计数据

我们只有 100 家活跃商店，样本量相当小。然而，在所有 100 家商店中，我们每周约有 30 万个唯一用户对话，其中约 1 万个对话发生了转化

商店的每周对话量和转化率差异很大。有些商店每周有 5 万次对话，而其他商店可能每周只有 1 万次。每家商店的平均每周对话次数和中位数分别为 2000 次和 230 次。

我们希望对聊天机器人进行更改，从而对所有商店产生积极影响


最好的方法是什么？分层建模？贝叶斯？常客？或者有什么特别的？]]></description>
      <guid>https://stats.stackexchange.com/questions/644483/which-statistical-approach-is-best-for-diverse-conversion-rates-in-an-a-b-test</guid>
      <pubDate>Sun, 07 Apr 2024 00:43:14 GMT</pubDate>
    </item>
    <item>
      <title>标准化基于树的模型或逻辑回归的特征</title>
      <link>https://stats.stackexchange.com/questions/644477/standardise-features-for-a-tree-based-model-or-logistic-regression</link>
      <description><![CDATA[我试图了解是否应该标准化所有模型的功能以及何时这样做有意义。
下面的说法正确吗？如果是的话，请您稍微解释一下。
逻辑回归和基于树的算法（例如决策树、随机森林和梯度提升）对变量的大小不敏感。因此在拟合此类模型之前不需要标准化。
在上面的此链接中找到。&lt; /p&gt;
这是否意味着异常值不会影响基于树的算法？]]></description>
      <guid>https://stats.stackexchange.com/questions/644477/standardise-features-for-a-tree-based-model-or-logistic-regression</guid>
      <pubDate>Sun, 07 Apr 2024 00:13:52 GMT</pubDate>
    </item>
    <item>
      <title>解释流行病学模型的泊松 GAM</title>
      <link>https://stats.stackexchange.com/questions/644475/interpreting-poisson-gam-for-epidemiological-model</link>
      <description><![CDATA[我正在开展一个项目，调查 PM2.5（一种污染形式）与缺血性中风住院治疗（即每天收集的住院总人数）之间的关系。我的模型如下所示，结果图也是如此：
&lt;前&gt;&lt;代码&gt;库(mgcv)
gam_model &lt;- gam(行程 ~ s(PM2.5) +
        因素（地区）+
        ns(日期, df= 7) +
        偏移量（日志（人口）），
                 数据=区域数据，
                 家庭=泊松（链接=“日志”））

绘图（gam_model，trans = exp，xlab =“PM2.5”，ylab =“相对风险”，rug = TRUE）


因为我想根据相对风险（相对于零基线 PM2.5 水平）来解释模型，所以我设置了 trans = exp。然而，我不明白如何解释结果，该结果表明，PM2.5 时，因缺血性中风住院的相对风险较低 $\approx 20$ 比 0 低。我犯错了吗？
如果这是一个愚蠢的问题，我很抱歉，我对这一切都很陌生。]]></description>
      <guid>https://stats.stackexchange.com/questions/644475/interpreting-poisson-gam-for-epidemiological-model</guid>
      <pubDate>Sat, 06 Apr 2024 22:31:38 GMT</pubDate>
    </item>
    <item>
      <title>用配对数据比较两组</title>
      <link>https://stats.stackexchange.com/questions/644471/compairing-two-groups-with-paired-data</link>
      <description><![CDATA[我有两组样本：健康组和患病组。每个人都接受了 X 治疗。所以，我有一个健康的基线和健康的 X 治疗。对于疾病组也是如此。分析它们的最佳方法是什么？如果我使用单向方差分析，它只会测量平均值。但它没有考虑到它们是成对测量。健康组确实有变化，但均值较低；因此，它不被认为是重要的。如果我进行配对 T 检验，我可以了解每组对治疗的反应，但无法比较健康与疾病。希望你能帮助我。]]></description>
      <guid>https://stats.stackexchange.com/questions/644471/compairing-two-groups-with-paired-data</guid>
      <pubDate>Sat, 06 Apr 2024 20:51:29 GMT</pubDate>
    </item>
    <item>
      <title>中心极限定理是关于多个样本还是只关于一个样本？</title>
      <link>https://stats.stackexchange.com/questions/644441/is-central-limit-theorem-about-multiple-samples-or-just-one</link>
      <description><![CDATA[我研究过 CLT，我的理解是多个样本将生成以总体平均值为中心的正态分布。然而，今天，Linkedin 上的一篇帖子称“CLT 表示足够大的样本具有与总体相同的特征”。准确吗？看来不是。帖子的作者是否犯了任何错误或者我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644441/is-central-limit-theorem-about-multiple-samples-or-just-one</guid>
      <pubDate>Sat, 06 Apr 2024 11:45:33 GMT</pubDate>
    </item>
    <item>
      <title>SEM 有 50% 缺失数据（由于项目在各种调查选票/浪潮中的分布）</title>
      <link>https://stats.stackexchange.com/questions/644413/sem-with-50-missing-data-due-to-distribution-of-items-over-various-survey-ball</link>
      <description><![CDATA[我想使用一般社会调查中调查的主要分类变量来测试多级中介（特别是测试关于社会阶级对右翼威权主义影响的可能中介因素的一些假设），为此，我将喜欢使用结构方程模型。但是，由于缺少数据，我对其可行性表示怀疑。
事实上，没有一个参与者拥有我想要包含的所有变量的数据，因为每个项目都是在不同的浪潮或选票中提出的。例如，我有一个项目仅在选票 A 和 B 中询问，第二个项目仅在选票 B 和 C 中出现，第三个项目在选票 A 和 C 中出现。因为我正在处理分类数据，所以我正在考虑Mplus 中的 WLSMV，使用成对删除。理论上，我可以绘制一个协方差矩阵，因为每个变量都与一次或另一次选票中的所有其他变量同时出现。对于每对变量（因此对于我需要的每个协方差），我至少有 900 名参与者（尽管总共有超过 10,000 名参与者）。因此，直观上，使用成对删除对我来说似乎不是很有问题，因为大多数缺失应该是 MCAR（它们是由某些选票/模块管理中的随机化造成的）——也许除了一些没有被询问的变量之外特别是年份/波浪。然而，当我读到这篇文章时，通常建议当缺失超过 10% 时（我远远超过了这里的阈值），成对删除是不合理的。
是否有一种处理缺失的方法可以让我估计这个模型，即使每个受访者都有大约 50% 的变量随机缺失数据？或者在我的情况下使用 SEM 不可行/不建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/644413/sem-with-50-missing-data-due-to-distribution-of-items-over-various-survey-ball</guid>
      <pubDate>Fri, 05 Apr 2024 19:08:50 GMT</pubDate>
    </item>
    <item>
      <title>不同样本量的 2 比例测试中的连续性校正</title>
      <link>https://stats.stackexchange.com/questions/644347/continuity-correction-in-a-2-proportion-test-with-different-sample-sizes</link>
      <description><![CDATA[在 2 个比例的检验中（二项式 -&gt; 正态），当样本大小不同时，连续性校正是什么样的？
通常，在 1 个样本测试中，我们将除以 $n$（样本大小）$\frac {1}{2}$ 术语。但是，对于不同的样本量，我们该怎么办？
为了了解更多背景信息，我们假设我们有一个来自离散分布 $F_{X}$ 的样本，其中 $ E(X)=\mu$ 和 $Var(X) = \sigma^2$，我们将通过 $\frac{\bar X - \mu}{\frac{\sigma}{\sqrt{n}}}\sim^a N(0,1)$。
我正在读的一本书指出，在这种情况下，我们应该使用以下连续性校正：
$P(\sum X_i \leq c) = P(\sum X_i \leq c+1/2) = P\left(\frac{\bar X - \mu}{ \frac{\sigma}{\sqrt{n}}} \leq \frac{(c+1/2)/n - \mu}{\frac{\sigma}{\sqrt{n}}}\right) $
最后一个表达式可以近似为 $\Phi\left(\frac{(c+1/2)/n - \mu}{\frac{\sigma}{\sqrt{ n}}}\右）$
无论$X$遵循泊松分布还是伯努利分布，都可以应用此方法...
我的问题涉及这种技术如何推广到 2 个离散总体的情况，$X_1 \sim F_1, X_2\sim F_2$ （目前都是伯努利） ...我将搜索看看它对于其他类型的分布（例如泊松分布）是否有意义）
$\frac{\bar X_1 - \bar X_2 - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma_1^2 }{n_1}+ \ frac{\sigma_2^2}{n_2}}}\sim^a N(0,1)$
与$n_1\neq n_2$。]]></description>
      <guid>https://stats.stackexchange.com/questions/644347/continuity-correction-in-a-2-proportion-test-with-different-sample-sizes</guid>
      <pubDate>Thu, 04 Apr 2024 21:11:25 GMT</pubDate>
    </item>
    <item>
      <title>将相关系数与同一对象的两次重复相关测量之间的平均绝对差异联系起来？</title>
      <link>https://stats.stackexchange.com/questions/643905/relating-the-correlation-coefficient-to-average-absolute-differences-between-two</link>
      <description><![CDATA[我有时必须在研究计划期间进行样本量计算。对于其中一些计算，需要相关系数作为输入。根据我的经验，相关专家发现将他们的经验转化为相关性的现实值非常棘手。这就是为什么我对其他方法感兴趣，通过将其重新表达为平均绝对差来得出相关性。
具体来说，假设使用同一仪器对 $n$ 个受试者进行了两次测量。据推测，同一对象的两个测量值是相关的，例如相关系数 $\rho$。有关两个时间点的均值和方差的信息均可用。
举个例子：假设在某些干预之前和之后测量收缩压。干预前均值和方差分别为 $130$ mmHg 和 $169$ mmHg$^2$。干预后均值和方差分别为 $118$ mmHg 和 $169$ mmHg$^2$。我们假设测量前和测量后之间的相关性为 $0.65$。
问题：如何（如果有的话）将相关系数表示为同一受试者的两次测量值之间的平均绝对差？
这有点类似于基尼平均差，它是两次测量之间的平均距离两个随机抽取的观察值。
编辑：答案在 Vila 等人的论文中给出。 （2024）第 4.1 节。表达式（论文中的方程 14）很复杂，但结果与我的任意均值、标准差和相关性的模拟相匹配。
参考文献
Vila, R.、Balakrishnan, N. 和索洛，H.（2024）。基于相关随机变量的基尼平均差的上限和特征。统计与概率快报，207, 110032。（链接到 arXiv 版本）。]]></description>
      <guid>https://stats.stackexchange.com/questions/643905/relating-the-correlation-coefficient-to-average-absolute-differences-between-two</guid>
      <pubDate>Sat, 30 Mar 2024 14:13:53 GMT</pubDate>
    </item>
    <item>
      <title>在生存分析中是否可以将批次效应“调整”为随机？</title>
      <link>https://stats.stackexchange.com/questions/643763/is-it-possible-to-adjust-batch-effect-as-random-in-survival-analysis</link>
      <description><![CDATA[我的尝试是根据病例队列研究定义生存分析模型，其中最初随机选择一个子队列。随后，整个队列中的所有病例都被非随机添加到子队列中。就我而言，目标是估计血液中测量的分子是否可以作为心血管疾病的生物标志物。我正在使用 R 中的生存包，特别是使用 cch 函数。我在此处观察到经典 Cox 回归模型中的随机效应，此处
问题源于实验分析，树状图显示某一特定批次存在异常，需要进一步调整。到目前为止，我主要使用纵向模型，这使我能够确定和指定随机效应。
我很好奇是否可以将随机效应纳入 Cox 回归，特别是使用 cch 函数。在探索有关交叉验证的信息时，我发现讨论 cch 的线程有限。但我还没有发现函数中包含的参数允许包含随机效应
从概念上讲，如果我人为或自愿地将病例添加到子队列中，确定随机效应是否合适？据我了解，这不是随机发生的，而是有待确定的具体效果。
如果不可能将其包含为随机效应，您认为将其包含为协变量是否合理，仅考虑 240 的子队列大小以及经过验证的大约 10 个样本的批次效应
我尝试执行的模型：
# 没有batch或者box效果的模型
# tocoro：事件或审查的时间
# iam：事件（急性梗塞）
# edat：年龄
# 性别：性别
# hsamir985p：感兴趣的协变量

Surv(tocoro, iam) ~ edat + sexe + hsamir985p

# 包括盒子
Surv(tocoro, iam) ~ edat + sexe + hsamir985p + 盒子


编辑1：
通过分层分析以确定批次或盒子是否存在不同的簇，结果显示一个盒子或批次的 DNA 质量较低，并且被分开聚类。我在其他生物标志物中提到了 hsamir985p，但是，是的，这是受影响的变量。我试图平滑这个批次或盒子效果。不确定您指的是什么使它们具有可比性？建立像回归，然后包括问题框的结果？
关于病例和对照，我有 194 个对照和 52 个病例 = iam，急性心肌梗死]]></description>
      <guid>https://stats.stackexchange.com/questions/643763/is-it-possible-to-adjust-batch-effect-as-random-in-survival-analysis</guid>
      <pubDate>Thu, 28 Mar 2024 13:39:39 GMT</pubDate>
    </item>
    </channel>
</rss>