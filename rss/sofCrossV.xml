<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 26 Nov 2024 15:19:40 GMT</lastBuildDate>
    <item>
      <title>聚类方法之前先进行 SVD（无降维）</title>
      <link>https://stats.stackexchange.com/questions/657878/svd-before-clustering-method-no-dimensionality-reduction</link>
      <description><![CDATA[在应用聚类方法之前将 SVD 应用于数据集是否在性能方面有意义？我的意思是：这样做是否有统计上的原因？它是否取决于方法，取决于维数？或者也许没有办法概括这一点？
我指的是仅应用 SVD，而不是完整的 PCA（即：没有降维）]]></description>
      <guid>https://stats.stackexchange.com/questions/657878/svd-before-clustering-method-no-dimensionality-reduction</guid>
      <pubDate>Tue, 26 Nov 2024 15:18:27 GMT</pubDate>
    </item>
    <item>
      <title>计算贝叶斯后验与重复对比的最佳实践</title>
      <link>https://stats.stackexchange.com/questions/657877/best-practice-to-compute-contrasts-from-bayesian-posterior-with-repeats</link>
      <description><![CDATA[我有来自参数 ($\theta$) 后验分布的样本 ($i$)，针对两个不同条件 $a$ 和 $b$。
两个条件 $\theta_{\delta i}$ 之间的后验差异的样本只需从条件 a 中减去条件 b 的后验：($\theta_{\delta i} = \theta_{bi} - \theta_{ai}$)。
但是，我有来自每个条件 $r$ 次重复的后验样本，即$\theta_{ai}^1, \theta_{ai}^2, ... \theta_{ai}^r$，以及 $\theta_{bi}^1, \theta_{bi}^2, ... \theta_{bi}^r$。
我知道，理想情况下，要计算 $\theta_{\delta}$，我应该有一个分层公式，其中每个条件重复的效果共享一些超先验，然后我只需使用 $\theta_a$ 和 $\theta_b$ 的超先验样本来计算对比度。
但是，如果我要处理的只是来自重复（例如 $\theta_{ai}^1, \theta_{ai}^2, ... \theta_{ai}^r$），计算 $\theta_{\delta}$ 样本的最佳方法是什么？
我考虑过的选项：

配对重复。即计算$\theta_{\delta i}^1 = \theta_{bi}^1 - \theta_{ai}^1$, $\theta_{\delta i}^2 = \theta_{bi}^2 - \theta_{ai}^2$等...然后将所有$\theta_{\delta i}^1, \theta_{\delta i}^2$, ...堆叠在一起以创建$\theta_{\delta i}$。这很好，但如果每个条件的重复次数不同，则不会使用所有重复。
与 1 类似，但不是对每个条件制作 $\theta_i$ 的重复对，而是计算所有成对的重复组合。这样，所有条件的所有重复都会被使用，并且所有重复都会相互比较。但重复次数较少的条件的后验样本被更多地使用，这感觉不对。

还有其他方法可以做到这一点吗？什么是最好的？（或者最不坏的？）
感谢您的任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/657877/best-practice-to-compute-contrasts-from-bayesian-posterior-with-repeats</guid>
      <pubDate>Tue, 26 Nov 2024 14:36:27 GMT</pubDate>
    </item>
    <item>
      <title>如何验证和报告具有 family = quasibinomal 的 glm 的结果？</title>
      <link>https://stats.stackexchange.com/questions/657876/how-to-verify-and-report-results-from-a-glm-with-family-quasibinominal</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657876/how-to-verify-and-report-results-from-a-glm-with-family-quasibinominal</guid>
      <pubDate>Tue, 26 Nov 2024 14:29:47 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中执行比例分层抽样的正确方法？</title>
      <link>https://stats.stackexchange.com/questions/657875/correct-way-to-perform-proportional-stratified-sampling-in-r</link>
      <description><![CDATA[我有一个大型纵向数据集，由于内存问题，我必须从中抽取 10% 的样本。因此，我决定首先使用 R 对人群中的个体进行按比例分层随机抽样。我尝试了两种方法：一种使用 data.table，另一种使用 dplyr。使用的层次是性别、出生年份 (dob) 和地区 (rgn)。
后来，当我执行分析时（如果需要上下文：收入动态 - 收入过程的分解），我得到了完全不同的结果（即不同的趋势）。这两个样本之间的唯一区别是下面的编码方式。所以我想知道，在两种获取样本的方法之间，到底是什么区别导致了不同的结果？获取样本的“正确”方法是什么？这两种方法有什么问题吗？或者我应该先对所有列进行排序？或者层次规模可能太小，我应该将出生年份分组到更广泛的出生队列中吗？
这是我的代码片段（在函数中编写 - 因此可以决定要采样的百分比和种子值等）。在相关部分，我首先读入数据（reg_data），确保标识符变量是字符类型，然后在执行采样之前过滤掉我用于分层的三个变量中的缺失值。随后使用从输出样本中提取的 ID 列表，我将其与另一个包含收入和其他变量数据的数据集进行连接。
reg_data 包含四列：id（标识符）、性别（性别）、出生年份（dob）和地区（rgn）。
所需库：
library(data.table)
library(dplyr)

由于保密原因，我无法共享数据，但这里有一些可以复制数据的内容：
set.seed(123) # 设置种子以实现可重复性

# 观察次数
n &lt;- 10000

# 生成数据集
reg_data &lt;- data.frame(
id = replicate(n, paste0(sample(c(LETTERS, 0:9), 6, replace = TRUE), collapse = &quot;&quot;)), # 6 个字母/数字的随机字符串
gender = sample(c(1, 2), n, replace = TRUE), # 随机分配性别（1 或 2）
dob = sample(1930:2000, n, replace = TRUE), # 随机分配 1930 至 2000 之间的出生年份
rgn = sample(c(&quot;0200&quot;, &quot;0300&quot;, &quot;0400&quot;), n, replace = TRUE) # 随机分配区域
)

head(reg_data)

id gender dob rgn
1 BDOD6B 1 1985 0300
2 TL4FMM 2 1967 0400
3 IAPDVC 2 1973 0400
4 LQ6DF2 1 1951 0400
5 A6UJ41 2 1995 0400
6 8EFYXU 1 1978 0400

id 最初是字符串。其他三列是数字。
 # 读入寄存器数据
reg_data &lt;- read_parquet(reg_file) 
setDT(reg_data)
reg_data[, id := as.character(id)]
reg_data &lt;- reg_data |&gt; 
filter(!is.na(gender) &amp; !is.na(dob) &amp; !is.na(rgn)) 

# 设置种子
set.seed(seed_value)

使用 data.table 的方法：
 sampled_ids_df &lt;- reg_data[, .SD[sample(.N, ceiling(percent_value * .N))], by = .(gender, dob, rgn)] |&gt;
unique()

使用 dplyr 的方法：
 sampled_ids_df &lt;- reg_data |&gt;
group_by(gender, dob, rgn) |&gt;
split_sample(prop = percent_value) |&gt;
ungroup() |&gt;
distinct()

乍一看，比较两个样本中每个层的比例，它们大致相等。例如，在总体中，假设有 60% 的女性和 40% 的男性，那么两个样本中每个性别的比例基本相同。这也适用于其他层。在绝对数字中，子组内存在差异，但主要是由于四舍五入（因此在某些子组中，即层的组合中，差异为 1）。我还检查了感兴趣的变量（收入），平均值基本相同（差异非常接近 0），方差有差异（但 &lt; 1）。
我最初在 stack overflow 上发布了这个，但有人说我应该在这里发布。]]></description>
      <guid>https://stats.stackexchange.com/questions/657875/correct-way-to-perform-proportional-stratified-sampling-in-r</guid>
      <pubDate>Tue, 26 Nov 2024 14:20:30 GMT</pubDate>
    </item>
    <item>
      <title>我如何改进我的扩散模型？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657873/how-can-i-improve-my-diffusion-model</link>
      <description><![CDATA[我一直在研究一个受 2020 年 DDPM 论文启发的扩散模型。它运行良好，但我不明白为什么它没有表现得更好。
情况如下：

在 MNIST 上，该模型的 FID 达到 15 左右，您可以识别这些数字。
在 CIFAR-10 上，大多数时候很难分辨出生成了什么。
在 CelebA 上，有些脸还可以，但大多数最终看起来像扭曲的怪物。

我尝试调整学习率、批量大小和其他超参数，但没有产生显着的变化。我从头开始构建了 UNet 架构和 loss+sample 函数，因此我怀疑那里可能存在问题，但经过几个小时的调试，我仍然找不到任何明显的东西。
我的模型应该表现得比这更好吗？我应该专注于进一步调整或调试哪些特定领域？有人可以看看我的代码并提供反馈或建议吗？
这是 github 上项目的链接：https://github.com/juliuseg/Diffusion_plz_help]]></description>
      <guid>https://stats.stackexchange.com/questions/657873/how-can-i-improve-my-diffusion-model</guid>
      <pubDate>Tue, 26 Nov 2024 13:39:01 GMT</pubDate>
    </item>
    <item>
      <title>PLS 是否适合通过 NIR 光谱预测化学浓度？</title>
      <link>https://stats.stackexchange.com/questions/657872/is-pls-appropriate-for-predicting-chemical-concentrations-from-nir-spectroscopy</link>
      <description><![CDATA[我有一组各种饮料样品的 NIR 光谱数据，每个样品都有相应的化学成分浓度（例如咖啡因）。我想训练一个 PLS 模型来根据光谱预测不同化学成分的浓度。但是，大多数浓度值集中在一个狭窄的范围内（例如，咖啡因水平大多在 0.3 左右，只有少数数据点的浓度为 0.2 或 0.4）。鉴于浓度值的这种分布，PLS 是否是适合此任务的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/657872/is-pls-appropriate-for-predicting-chemical-concentrations-from-nir-spectroscopy</guid>
      <pubDate>Tue, 26 Nov 2024 13:19:04 GMT</pubDate>
    </item>
    <item>
      <title>UMP 无偏测试的定义到底是什么？</title>
      <link>https://stats.stackexchange.com/questions/657870/what-exactly-is-the-definition-of-a-ump-unbiased-test</link>
      <description><![CDATA[我正在解答 Hogg 和 McKean 的《数理统计学导论》第 8.3 节的练习。&amp;我无法继续，因为作者没有正式定义 UMPU 测试，即使他们给出了 UMP 测试的定义。
上下文：在练习 $8.3.8,$ 中，作者要求我们证明用于测试 $H_0:\theta = \theta_0$ 对 $H_1:\theta \neq \theta_0$ 的 LRT 原理导致不等式 $\lvert \overline{x}-\theta_0\rvert \geq c,$ 其中 $\overline{x}$ 是来自 $N(\theta,1),$ 的随机样本的实际平均值，其中 $\overline{x}$ class=&quot;math-container&quot;&gt;$\theta_0$ 已指定。然后他们问

(a) 这是 $H_0$ 对 $H_1$ 的一致最强检验吗？
(b) 这是 $H_0$ 对 $H_1$ 的一致最强无偏检验吗？

事实上，在文中，作者已经表明，对于这种双面假设，没有 UMP 检验。也有 SE 帖子（如 这个）显示了这一点。对我来说，问题是部分 (b)。
UMP 无偏 测试的定义到底是什么？我在这里卡住了，因为文本中没有对此的正式定义。只有一行说

那里表明，对于这种情况不存在 UMP 测试。如果我们将注意力限制在无偏测试类别上（定义 $8.1.2$），那么就可以构建最佳测试理论；参见 Lehmann ($1986$)。

定义 $8.1.2$ 是在 我之前的一篇文章中给出的，其中基本上说，如果 $\theta \in \omega_1$，即备选参数集，则 $P_\theta(X \in C) \geq \alpha,$ 其中 $C$ 临界区域，级别为 $\alpha$。如果 UMP 测试是大小为 $\alpha$ 的 最佳临界区域，用于针对 $H_1$ 中的每个简单假设测试 $H_0$，则 UMP 测试是由此临界区域定义的测试。
我的问题：UMPU 测试的精确数学定义到底是什么？我们究竟应该为这道练习题的 (b) 部分展示什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657870/what-exactly-is-the-definition-of-a-ump-unbiased-test</guid>
      <pubDate>Tue, 26 Nov 2024 12:44:23 GMT</pubDate>
    </item>
    <item>
      <title>含义：各层级系数的同质性？</title>
      <link>https://stats.stackexchange.com/questions/657868/meaning-of-homogeneity-of-the-coefficient-for-all-levels</link>
      <description><![CDATA[“粗体”部分是什么意思？
“此外，堆肥期（分别为 7 周和 10 周）与添加剂之间的相互作用具有统计显著性（P 值 &lt;0.01），这意味着可以假设协变量的系数在因子的各个水平上是同质的。”
我认为因子是 7 周或 10 周。协变量（添加剂）被赋予一个系数 - 我明白这句话的表面含义。但我不明白为什么统计显著性意味着系数在所有水平上都是同质的。我的知识中缺少了一些东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/657868/meaning-of-homogeneity-of-the-coefficient-for-all-levels</guid>
      <pubDate>Tue, 26 Nov 2024 12:04:43 GMT</pubDate>
    </item>
    <item>
      <title>均值抽样分布近似于学生 t 分布的证明是什么？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657867/what-is-the-proof-of-the-mean-sampling-distribution-being-approximated-by-studen</link>
      <description><![CDATA[在方差未知的非正态分布的情况下，平均值的抽样分布（大样本）近似于学生 t 分布的理由是什么？
==============================
我知道

在方差未知的正态分布的情况下，平均值的抽样分布恰好是学生 t 分布。
大样本中平均值的抽样分布在大样本中近似于正态（通过 CLT）

但是，证明方差未知的近似正态分布近似于学生 t 分布在我看来需要额外的步骤。]]></description>
      <guid>https://stats.stackexchange.com/questions/657867/what-is-the-proof-of-the-mean-sampling-distribution-being-approximated-by-studen</guid>
      <pubDate>Tue, 26 Nov 2024 11:55:09 GMT</pubDate>
    </item>
    <item>
      <title>正态性假设 - qqplot 解释</title>
      <link>https://stats.stackexchange.com/questions/657859/normality-assumption-qqplot-interpretation</link>
      <description><![CDATA[我目前正在从事一个涉及评估多个变量分布的项目，并且我正在使用 Q-Q 图作为分析的一部分。虽然我已经为这些变量生成了 Q-Q 图。确实，我已经研究这些很长时间了，但我仍然想在这里听取意见。这些变量的样本量接近 70，目的是在纵向分析的几个变量之间进行独立 t 检验。我可以提出，shapiro 和 ks-test 拒绝正态性假设。
如果您能指导我准确解释它们以评估正态性并识别任何偏离高斯分布的情况，我将不胜感激。这些生物标志物通常在尾部变得更重，但我不会进行转化。欢迎任何评论！


]]></description>
      <guid>https://stats.stackexchange.com/questions/657859/normality-assumption-qqplot-interpretation</guid>
      <pubDate>Tue, 26 Nov 2024 10:45:29 GMT</pubDate>
    </item>
    <item>
      <title>用百分比来描述少于100人的样本是否有问题？</title>
      <link>https://stats.stackexchange.com/questions/657851/is-it-problematic-to-use-percentages-to-describe-a-sample-with-less-than-100-peo</link>
      <description><![CDATA[这是一个非常基础、愚蠢的问题，但我找不到答案，而且最重要的是，我通常对常识/直觉持怀疑态度。
当整个样本中不到 100 人时，如果说“样本中 80% 的人喜欢香蕉口味”，我觉得这是“作弊”。但也许我错了，所以我才问这个问题。我发现至少有两个问题：

如果我忽略了样本量，可能会造成误导

有些百分比是不可能达到的，例如，如果样本中只有 10 个人，就不可能有 0 到 10% 之间的任何百分比


我在这里是否过于谨慎，使用这样的百分比真的可以吗？或者这真的是个问题？是否存在我没​​有发现的其他问题？
我不确定为什么这个问题被关闭了（顶部的消息说这不是关于统计学的问题，这是一个错误吗？如果我正确理解了帮助页面，我应该把它发布到数学 stackexchange 上吗？）。答案中有人说这取决于上下文，但我没有具体的例子，所以我的问题是“这取决于什么？”。什么时候可以报告样本量小于 100 的百分比，什么时候不可以？
TL;DR：如果我正确理解了当前的答案，只要我也报告样本量，报告百分比总是可以的。不随百分比一起报告样本量总是有问题的。这个说法正确吗，还是还有其他需要考虑的事情？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657851/is-it-problematic-to-use-percentages-to-describe-a-sample-with-less-than-100-peo</guid>
      <pubDate>Tue, 26 Nov 2024 07:51:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么分类时不能使用软标签？[重复]</title>
      <link>https://stats.stackexchange.com/questions/657850/why-is-it-ok-not-to-use-soft-labels-in-classification</link>
      <description><![CDATA[从某种意义上说，我有一个与使用交叉熵损失函数与软标签可以吗？相反的问题，即为什么不可以在分类中使用软标签？
假设您有一个要解决的二元分类任务。以下是您通常的处理方式。您从一些未知的概率分布$u(y=1|x)$开始。您通过从中抽样来近似$u(y=1|x)$以生成数据集（概率分布$p(y=1|x)$）。然后创建一个模型 $q(y=1|x)$。然后，通过最小化 $q(y=1|x)$ 和 $p(y=1|x)$ 之间的交叉熵损失，将模型拟合到概率分布 $p(y=1|x)$。
为了计算交叉熵，通常假设 $p(y=1|x)$ 始终为 1 或 0，尽管这不一定正确 - 例如，假设我们的数据集中有两个体重、身高等相同的患者，但一个生病，另一个没有生病 - 如果是这样 $p(y=1|x) = 1/2$。相比之下，您通常会将第一个样本 $p(y=1|x)$ 设置为 0，将第二个样本设置为 1。为什么做出这种假设如此普遍？这是一个安全的假设吗？如果是，为什么？换句话说，为什么不始终使用软标签进行分类任务？
编辑：进一步说明。如果我有一个有限的数据集，则 $p(y=1|x)$ 是一个有限概率分布。我可以使用交叉熵公式来测量$q(y=1|x)$估计误差，如下所示
$$
CE(p, q) = \sum_{x \in X} p(y=1|x) log(q(y=1|x))
$$
假设我的数据集由两个特征结果向量$(f_1, ... f_p, 0)$和$(f_1, ..., f_p, 1)$组成。然后我像这样计算交叉熵（我将$p(y=1|x)$缩写为$p(x)$）。
$$
X = \{x_0\} = \{(f_1, ..., f_p)\} \\
p(x_0) = 0.5 \\
CE(p, q) = \sum_{x \in X} p(x)log(q(x)) = p(x_0)log(q(x_0)) = 0.5log(q(x_0))
$$
另一方面，以下是人们经常谈论的实现交叉熵的方式（示例）
$$
X = \{x_0, x_1\}; \; x_0 = x_1 \\
p(x_0) = 0; \; p(x_1) = 1 \\
x_0 = x_1 \implies q(x_0) = q(x_1) \\
CE(p, q) = \frac{1}{|X|}\sum_{x \in X}p(x)log(q(x)) = \frac{1}{2}(0 \cdot log(q(x_0)) + 1 \cdot log(q(x_1))) = 0.5log(q(x_0))
$$
我对此有三个问题：

从数学上来说，说 $p(x_0) = 0$ 和 $p(x_1) = 1$ 是不合理的，因为 $x_0 = x_1 \implies p(x_0) = p(x_1)$
在这种情况下，我得到了相同的数字，但我不知道是否总是如此。
我不知道如何将一个定义与另一个定义联系起来（这与这个未解答的问题非常相似
]]></description>
      <guid>https://stats.stackexchange.com/questions/657850/why-is-it-ok-not-to-use-soft-labels-in-classification</guid>
      <pubDate>Tue, 26 Nov 2024 07:50:10 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证在 Python 中拟合零膨胀负二项式时出错</title>
      <link>https://stats.stackexchange.com/questions/657805/error-in-fitting-zero-inflated-negative-binomial-in-python-using-cross-validatio</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657805/error-in-fitting-zero-inflated-negative-binomial-in-python-using-cross-validatio</guid>
      <pubDate>Mon, 25 Nov 2024 13:56:01 GMT</pubDate>
    </item>
    <item>
      <title>单一结果，随时间重复的协变量：线性混合模型？</title>
      <link>https://stats.stackexchange.com/questions/657802/single-outcome-repeated-covariates-in-time-linear-mixed-models</link>
      <description><![CDATA[我有一个数据集，我想预测一个结果（最后一次随访的 EDSS，以 0 到 10 的数字尺度测量，仅包括 0.5 个小数）。对于每个患者，我有每个患者的 2 个生物标志物测量值。我想创建一个使用生物标志物预测最后一次随访的 EDSS 的预测模型。
我尝试了线性混合模型，但由于未实现收敛，因此会引发错误。这是我使用的公式
EDSS_lastfollow ~ nfl + (1|ID)
我尝试过使用高斯链接函数，也尝试过将结果用作序数变量，但无法达到收敛。我怀疑这是因为我实际上没有重复的结果，而是重复的协变量。我想考虑协变量的 ID 变异性来对其进行建模。你知道我该如何继续建模吗？只要拍一部简单的电影就更好了？]]></description>
      <guid>https://stats.stackexchange.com/questions/657802/single-outcome-repeated-covariates-in-time-linear-mixed-models</guid>
      <pubDate>Mon, 25 Nov 2024 12:04:23 GMT</pubDate>
    </item>
    <item>
      <title>使用贝叶斯 (STAN) 与多层模型 (nlme) 得到相反的结果。这怎么可能呢？</title>
      <link>https://stats.stackexchange.com/questions/657798/opposite-results-using-bayesian-stan-vs-multilevel-model-nlme-how-is-this-p</link>
      <description><![CDATA[我的数据集包含 20 年期间 4000 个县的平均工资和累计风力发电装机容量。工资在此期间趋于上涨，而各县之间的发电容量差异很大。作为第一步，我想分析广泛的影响，然后按州和其他类别对各县进行分组。
我在 R 中使用贝叶斯马尔可夫链蒙特卡罗 (MCMC) 模拟和 STAN 进行了基础分析，并得到了小的正相关性，其他研究也支持这一结论。代码一定是正确的，因为它是另一项研究的近 100% 复制品。
现在我尝试使用 nlme 的分层线性模型复制相同的结果，但得到了完全相反的结果。
nmle：
 model &lt;- lme(median_wage ~ cum_installed_wind + period,
random = ~ period | county_id,
correlation = corAR1(form = ~ period | county_id),
data = obs_level,
method = &quot;ML&quot;)

Stan：
data {
int&lt;lower = 0&gt; N; // 观察值数量
int&lt;lower = 0&gt; C; // 县数
int&lt;lower = 1, upper=C&gt; county[N]; // 县 ID
vector[N] median_wage; // 平均年薪
vector[N] period; // 时间段
vector[N] capacity; // 累计风力发电能力
}

转换后的数据 {
vector[N] st_median_wage;
vector[N] st_capacity;
vector[N] st_period;

// 标准化输入
st_median_wage = (median_wage - mean(median_wage)) / sd(median_wage);
st_capacity = (capacity - mean(capacity)) / sd(capacity);
st_period = (period - mean(period)) / sd(period);
}

参数 {
real&lt;lower=0&gt; sigma_alphaW; // 随机截距标准差
real&lt;lower=0&gt; sigma_beta0W; // 随机斜率标准差
real&lt;lower=0&gt; sigma_y; // 残差标准差

real mu_alphaW; // 截距平均值
real mu_beta0W; // 周期斜率平均值
real beta1W; // 风力容量的固定效应

vector[C] alphaW_raw; // 原始随机截距
vector[C] beta0W_raw; // 周期原始随机斜率
}

转换参数 {
vector[C] alphaW;
vector[C] beta0W;
vector[N] y_hat;

// 计算随机效应
alphaW = mu_alphaW + sigma_alphaW * alphaW_raw;
beta0W = mu_beta0W + sigma_beta0W * beta0W_raw;

// 定义模型预测
for (i in 1:N) {
y_hat[i] = alphaW[county[i]] + beta0W[county[i]] * st_period[i] + beta1W * st_capacity[i];
}
}

model {
// 先验
mu_alphaW ~ normal(0, 5);
mu_beta0W ~ normal(0, 5);
beta1W ~ normal(0, 5);
sigma_alphaW ~ cauchy(0, 5);
sigma_beta0W ~ cauchy(0, 5);
sigma_y ~ cauchy(0, 5);

alphaW_raw ~ normal(0, 1);
beta0W_raw ~ normal(0, 1);

// 可能性
median_wage ~ normal(y_hat, sigma_y);
}



这段代码对我的分析来说正确吗？
这些相反的结果怎么可能呢？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657798/opposite-results-using-bayesian-stan-vs-multilevel-model-nlme-how-is-this-p</guid>
      <pubDate>Mon, 25 Nov 2024 10:43:45 GMT</pubDate>
    </item>
    </channel>
</rss>