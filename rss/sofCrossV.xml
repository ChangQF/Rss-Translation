<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Wed, 02 Apr 2025 03:35:16 GMT</lastBuildDate>
    <item>
      <title>将方向纳入Fisher的方法[关闭]</title>
      <link>https://stats.stackexchange.com/questions/663399/incorporating-direction-in-fishers-method</link>
      <description><![CDATA[我正在使用Fisher的方法结合了来自多个独立研究的P值。这些p值是双面的，因此它们不会直接指示效果的方向。
然而，除了p值外，我还从每项研究中还有另一个指标来捕获效果的方向。
我想知道是否可以修改或扩展Fisher的方法以结合方向性。我的一个想法是分别运行Fisher的方法以实现正方向和负面方向，然后以某种方式比较或结合结果以推断总体方向。
这是一种有效的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663399/incorporating-direction-in-fishers-method</guid>
      <pubDate>Wed, 02 Apr 2025 00:51:50 GMT</pubDate>
    </item>
    <item>
      <title>有什么方法可以比较这些化学浓度？</title>
      <link>https://stats.stackexchange.com/questions/663396/is-there-any-way-to-compare-these-chemical-concentrations</link>
      <description><![CDATA[我不确定这甚至是要问的论坛，但也许您可以提供帮助。
我有关于在给定6公顷的地点喷涂的农药的信息。提供这样的信息：
 所以，我知道3273.81毫升的农药luna宁静，其具有吡imi虫的活性成分（占配方的33.8％）和氟林兰（fluopyram（占配方的11.3％））总计6公顷6公顷。我知道单位说“ g或ml/l＆＆quot”意味着如果它是ML/L，我可以将其更改为PPM，但这并不意味着它仅仅是ML或G或L中应用的总卷，那就是收集数据的人出于某种原因将其写入的方式。 
我还拥有从该位置收集的蜜蜂蜡中的吡imi虫和荧光嘧啶量的数据。例如，我知道在这个位置发现蜜蜂的蜡具有0.085ppm的荧光嘧啶。
我想进行一项chisquare分析，在其中计算本应在蜜蜂蜡中本来应该是这些化学物质的预期ppm，而我在蜜蜂蜡中发现的这些化学物质的实际PPM。有25个蜂巢/公顷，因此，对于此数据线，计算预期的荧光素我正在认为每个蜜蜂都可以计算预期值，为818.45/25 = 32.73ml luna tranquility = 32.73*.113*.113 = 3.69ml furopyram。但是我不知道如何或是否可以将3.69毫升与0.0885ppm进行比较？？
我不知道我是否可以比较给定单位的这些值？ 有没有办法将剂量/HA信息转换为PPM？
如果没有，我是否可以将这些数据转换为比例或百分比或某种方法使两种类型的数据可比的方法？
我希望这足以解释我的问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/663396/is-there-any-way-to-compare-these-chemical-concentrations</guid>
      <pubDate>Tue, 01 Apr 2025 23:34:36 GMT</pubDate>
    </item>
    <item>
      <title>仅具有交互作用的模型缺点？</title>
      <link>https://stats.stackexchange.com/questions/663394/drawbacks-of-model-with-only-interaction-effects</link>
      <description><![CDATA[This a question I came across on regression models that only contain interactions (without the main effects) : Including the interaction but not the main effects in a model .虽然这个问题包含在可能允许的特殊情况下的答案，但我试图理解为什么总的来说，不建议具有没有主要影响的回归模型。 
我定义了两个模型：

互动模型： $ y = b_0 + b_1（x_1x_2）$   
完成模型： $ y = B_0 + B_1X_1 + B_2X_2 + B_3（X_1X_2）$  

现在，我试图考虑仅使用互动术语的模型的一些问题。


边际效应分析

在完整的模型中与仅相互作用模型， $ x_1 $  on  $ y $ ：
 $$ \ frac {\ partial y} {\ partial x_1} = b_1 + b_3x_2 $$
当 $ x_2 = 0 $ 时，我们数学强制 $ \ frac {\ frac {\ partial y} {\ partial x_1} = 0 $ 。这意味着模型假设 $ x_1 $ 在 $ y $ 时绝对没有影响

估计中的问题

这是一个微妙的问题。当我们估计仅相互作用模型时，我们会（通过OLS）：
  $$ \ hat {b} _1 = \ frac {\ text {cov}（y，x_1x_2）} {\ text {var} {var}（x_1x_2）
假设这是我们的真实数据生成过程包括主要影响：
  $$ y = \ beta_0 + \ beta_1x_1 + \ beta_2x_2 + \ beta_3（x_1x_2） + \ epsilon $$
替换和操纵（通过协方差的线性）：
在x_1x_2）} {\ text {var}（x_1x_2）} $$  
  $$ \ hat {b} _1 = \ frac {\ beta_1 \ text {cov}（x_1，x_1，x_1x_2） + \ beta_2 \ beta_2 \ text {cov} x_1x_2）} {\ text {var}（x_1x_2）} $$  
以来 $ \ text {cov}（x_1x_2，x_1x_2）= \ text {var}（x_1x_2）$ ：：&gt;
  $$ \ hat {b} _1 = \ beta_1 \ frac {\ text {cov}（x_1，x_1，x_1x_2）} {\ text {v text {var} x_1x_2）} {\ text {var}（x_1x_2）} + \ beta_3 $$  
  $$ \ HAT {B} _1 = \ beta_3 + \ text {bias} $$   
因此，这将导致有偏见的估计值。

我是否正确地确定了仅相互作用模型的一些问题？还有其他众所周知的数学问题仅导致相互作用回归模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663394/drawbacks-of-model-with-only-interaction-effects</guid>
      <pubDate>Tue, 01 Apr 2025 22:58:52 GMT</pubDate>
    </item>
    <item>
      <title>计算平均值，而不是差异会降低自由度？</title>
      <link>https://stats.stackexchange.com/questions/663391/calculating-the-mean-not-variance-reduces-the-degrees-of-freedom</link>
      <description><![CDATA[我知道，当您有一个尺寸n的样本并且需要计算模型的平均值时，其余的自由度就会减少1。我可以将其概念化为对第10个观察构成限制，以满足所知道的前9个观察后计算的平均值。。。。
但是，我不完全理解的是，样本方差的计算不会降低自由度。在此处适用的平均值不是相同的理由吗？第9和第10个观察结果将已经有一定的价值来满足计算的差异，并且在知道前8个观测之后，是emane of吧？ 
一个简单的单样本t检验具有N-1的自由度，而不是N-2，而平均值和标准偏差则用于确定T统计量。
如何确定哪些计算参数降低了模型的自由度？]]></description>
      <guid>https://stats.stackexchange.com/questions/663391/calculating-the-mean-not-variance-reduces-the-degrees-of-freedom</guid>
      <pubDate>Tue, 01 Apr 2025 21:47:34 GMT</pubDate>
    </item>
    <item>
      <title>欧几里得距离与平方距离损失功能，弹跳损失</title>
      <link>https://stats.stackexchange.com/questions/663390/euclidean-distance-vs-squared-distance-for-loss-function-bouncing-loss</link>
      <description><![CDATA[我正在使用具有参数矢量 $ \ theta $ 的复杂分布。我有功能可以近似分布的矩，表示 $ \ sigma（\ theta）$  for the COADARIANCE和 $ \ mu（\ theta）$（\ theta）
我想使用这些公式来找到参数 $ \ theta $ ，最好与随机变量的观察到的矩， $ \ sigma $  $ $ \ $ \ $ $ 我的问题是要使用哪种损失函数进行优化。两个看似合理的选择是平方距离：
 $$ \ | \ mu（\ theta） -  \ mu \ |^2 + \ | \ sigma（\ theta） -  \ sigma \ |^2 = \ sum_i \ left（\ mu（\ theta）_i- \ mu_i \ right）^2 + \ sum_ {i，j} \ less j} $$ 
和平原距离
 $$ \ | \ mu（\ theta） -  \ mu_ {obs} \ | + \ | \ sigma（\ theta） -  \ sigma_ {obs} \ | = \ sqrt {\ sum_i \ left（\ mu（\ theta）_i- \ mu_i \ right）^2} + \ sqrt {\ sum_ {\ sum_ {i，j} \ sigma_ {i，j} \ right）^2} $$  
我偏爱平方距离的一个原因是，我记得知道平方根使优化变得困难，因为随着您接近0（虽然现在找不到参考），梯度尺度会迅速到无限。但是，我一直发现距离损失会带来更好的结果。
但有趣的是，我使用NADAM优化器，每一个 $ k $ 迭代的学习率降低，并且我发现损失主要围绕中间点弹跳，直到学习率下降。闻起来就像平方根对优化所做的那种事情。在训练期间损失的放大下方
  随着平方距离损失，我看到损失的平稳变化，但是结果拟合较差。使用平方距离放大损失的放大：

我的问题是：
为什么距离损失的性能要比平方距离损失更好？
是否有清晰的方法可以改善距离损失的优化？我尝试了LBFGS算法，但这也会导致更糟的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/663390/euclidean-distance-vs-squared-distance-for-loss-function-bouncing-loss</guid>
      <pubDate>Tue, 01 Apr 2025 21:38:26 GMT</pubDate>
    </item>
    <item>
      <title>如何计算准波森回归的功率</title>
      <link>https://stats.stackexchange.com/questions/663388/how-to-calculate-power-for-a-quasi-poisson-regression</link>
      <description><![CDATA[我运行了准散烟回归（由于过度分散），现在我想知道如何计算测试的功能。我尝试了G-Power，但似乎只能计算泊松的功率，但不能计算Quasi-Poisson。我尝试使用R，但我还没有找到支持准假回归的软件包。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/663388/how-to-calculate-power-for-a-quasi-poisson-regression</guid>
      <pubDate>Tue, 01 Apr 2025 20:00:04 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么统计测试来比较每单位工作的两组计数？</title>
      <link>https://stats.stackexchange.com/questions/663387/what-statistical-test-should-i-use-to-compare-two-groups-of-counts-per-unit-effo</link>
      <description><![CDATA[我想比较每人小时两组是否相同。假设我将500人送去果园A挑选苹果每个三个小时，而果园B则是同样的。然后，我计算每个人摘下的苹果数量除以他们花在搜索的时间。每个人都花了大约三个小时的搜索时间，但是我跟踪几秒钟，所以有很小的变化。
果园A和果园B的每个人小时数据集被证明是正态分布的。但是，数据中有一些重复，因为例如，很多人在3小时内找到了3个苹果，因此他们有1个苹果小时的小时，然后下一个选择是找到2个苹果，以便这些人有0.66个苹果小时。另外，一个数据集包含的差异比另一个数据集更大。
这种情况是假设的，但这是我的数据中的QQ图，显示由于离散的苹果计数是离散的，并且人小时大约相等。。
  我的无效假设是每个果园的苹果小时是相同的。
我正在辩论一个韦尔奇的两个样本t检验，两个样本kolmogorov – smirnov测试或拟合测试的卡方好处。
 韦尔奇的两个样本t检验
我可以比较均值，但是具有一堆几乎相似的值的数据是否会使其非参数？数据在技术上是连续的，但它来自离散数据。请注意，在我的真实数据上运行Welch的t检验表明，这两种均值显着不同。
  kolmogorov – smirnov检验
我也可以比较分布和位置，但是重复或几乎重复数据点意味着我无法准确计算此测试的P值？请注意，估计的p值表明这两个分布有显着差异，但是使用r中的 ks.test 函数，我在重复值中得到了警告。
 卡方的拟合测试优点
从理论上讲，我知道我可以对计数使用此测试，但是我对如何比较两组计数有些丢失……而且我的数据在技术上不再是计数了。
我也开放考虑其他统计测试。让我知道我是否可以提供更多信息。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/663387/what-statistical-test-should-i-use-to-compare-two-groups-of-counts-per-unit-effo</guid>
      <pubDate>Tue, 01 Apr 2025 19:56:00 GMT</pubDate>
    </item>
    <item>
      <title>从非IID过程中采样多个独立的样本路径如何实现有意义的估计以及哪些模型是合适的？</title>
      <link>https://stats.stackexchange.com/questions/663385/how-does-sampling-multiple-independent-sample-paths-from-a-non-iid-process-enabl</link>
      <description><![CDATA[我想跟进以下提出的有趣点（例如，讨论）。提出的核心点是，即使数据生成过程（DGP）是非IID的，如果我们可以从同一DGP中采样许多独立的样本路径（或横截面块），那么我们可以通过平均这些独立的轨迹在这些独立的轨迹上进行平均。
要澄清，这个想法是，每个独立的样本路径（即使在本身内部依次非IID）都是从相同的基础非IID过程中绘制的（例如，MDP或类似图像的集合）。因此，将每条路径视为经验分布，可以通过将每个样本路径的NLL缩放到独立路径的数量来恢复信息等效的信息。
基于此，我有以下问题：

  此类数据的示例：&lt; /strong&gt; 
什么是数据的具体示例，我们可以从非IID DGP获得多个独立的样本路径？例如，是否有时间序列，加固学习或其他领域的典型示例？

   llms的文本数据：&lt; /strong&gt; 
用于培训语言模型（LLM）的大型语料库是否属于这一类别？换句话说，鉴于文本数据本质上是顺序且非IID，我们可以将每个文档（或其他分割）视为独立的示例路径吗？

  估计中的收敛：&lt; /strong&gt; 
由于每个样本路径均独立于相同的非IID DGP绘制，因此该框架是否保证了估计的跨熵（或MLE）的收敛性，并且给定适当的模型和足够的数据？

  此类数据的模型：&lt; /strong&gt; 
哪些模型或学习框架适合于此类数据培训？是否有特定的模型类（例如，用于MDP的加固学习或专门序列模型的类别），可以更适合处理非IID轨迹的独立采样？


我感谢任何可以帮助澄清这些观点的见解或参考，尤其是在示例或理论支持的情况下。预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/663385/how-does-sampling-multiple-independent-sample-paths-from-a-non-iid-process-enabl</guid>
      <pubDate>Tue, 01 Apr 2025 19:16:46 GMT</pubDate>
    </item>
    <item>
      <title>k折交叉验证申请</title>
      <link>https://stats.stackexchange.com/questions/663380/k-folds-cross-validation-application</link>
      <description><![CDATA[我们有一个n = 130的小数据集。当前的步骤正在探索数据，以寻找任何有趣的东西。我们的主要目的是比较使用其他变量是否有助于改善模型预期。使用的变量分别为28和28+57。结果是二进制预测。
在开始进行编码之前，这是我的工作流程：n = 130分为10倍（k折交叉验证）。十倍被视为火车组的九个折中的九个，一个被视为测试集。这将是经过训练和测试的10种型号（也许还可以通过k折验证执行脊和拉索选择λ）。在同一图中绘制的10个AUC/PRC，F1分数，以评估模型性能。同样最大的F1得分，定量评估的准确性平均值。
但是，作为ML/回归的新来者，我对此不确定。批准中有缺陷吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663380/k-folds-cross-validation-application</guid>
      <pubDate>Tue, 01 Apr 2025 12:41:47 GMT</pubDate>
    </item>
    <item>
      <title>使用预处理评估作为预测治疗后评估的主持人</title>
      <link>https://stats.stackexchange.com/questions/663378/using-pre-treatment-assessment-as-a-moderator-in-predicting-post-treatment-asses</link>
      <description><![CDATA[使用预处理X作为Z预测治疗后X效果的主持人的主要问题是什么，同时控制预处理X作为COV的主要效果？与使用预处理K（COV），预处理X，Y和预处理x*y预测治疗后K的模型相比？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/663378/using-pre-treatment-assessment-as-a-moderator-in-predicting-post-treatment-asses</guid>
      <pubDate>Tue, 01 Apr 2025 12:26:37 GMT</pubDate>
    </item>
    <item>
      <title>过高的精确度是否有问题？</title>
      <link>https://stats.stackexchange.com/questions/663351/is-there-any-problem-with-too-high-of-precision</link>
      <description><![CDATA[例如，我经常与成人和婴儿一起工作。对于成年人，0.001年不到一天。我们很少需要知道成年人的年龄到一个小时。但是，通常将数据库存储到许多小数位。
这看起来很愚蠢，但是在年龄在五个小数位时回归时是否有任何可测量的危害，而实际上最多只有两个是遥不可及的？]]></description>
      <guid>https://stats.stackexchange.com/questions/663351/is-there-any-problem-with-too-high-of-precision</guid>
      <pubDate>Mon, 31 Mar 2025 22:50:12 GMT</pubDate>
    </item>
    <item>
      <title>ICC值对于具有不同自变量的不同空模型相同</title>
      <link>https://stats.stackexchange.com/questions/663337/icc-values-the-same-for-different-null-models-with-different-independent-variabl</link>
      <description><![CDATA[我有25个变量。然后，我拟合25个空模型（无预测变量）。他们对因变量的响应有所不同，但是，观察次数是相同的，并由相同数量的家庭分组。这些模型的差异是相同的，因此，ICC值是相同的，我发现这很奇怪。
这是我如何适合NULL模型的方式：
 模型＆lt;  -  glmer（
  练习〜（1 |家庭），
  data = bean_pureemlm，family = binomial（link =＆quot; logit; quot;），nagq = 0
 
我在做什么错，或者如果正确，为什么ICC值相同？
我共享两个数据集，以显示两个模型示例，其中响应不同，但在运行NULL模型时具有相同的变化。
 https://drive.google.com/drive/folders/1O4WBGDPRJZBGBGBEPOEUTS3OOH8OPBBS21?usp=sharing  ]]></description>
      <guid>https://stats.stackexchange.com/questions/663337/icc-values-the-same-for-different-null-models-with-different-independent-variabl</guid>
      <pubDate>Mon, 31 Mar 2025 17:39:15 GMT</pubDate>
    </item>
    <item>
      <title>如何计算平均比例之间比率的置信区间</title>
      <link>https://stats.stackexchange.com/questions/663333/how-to-calculate-the-confidence-interval-for-the-ratio-between-mean-proportions</link>
      <description><![CDATA[一个数据由两组观测值组成，每个观察结果是一个比例，一个人如何计算一组平均比例与另一组平均比例之间的置信区间？
编辑：这不是关于计数变量的问题；如前所述，这是一个关于连续变量在0到1之间的问题，并表示比例（或同样的概率）。鉴于“基础”计数是可以恢复的（或首先存在的）。我接受的答案（即@pbulls的答案）是迄今为止唯一回答问题的答案。如果您读到了这篇文章，您将理解为什么我的问题是合理的，并且按书面响应，而没有有关基本计数变量等的更多信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/663333/how-to-calculate-the-confidence-interval-for-the-ratio-between-mean-proportions</guid>
      <pubDate>Mon, 31 Mar 2025 16:04:49 GMT</pubDate>
    </item>
    <item>
      <title>需要建议：非正常数据的统计分析，样本量不等</title>
      <link>https://stats.stackexchange.com/questions/663327/advice-needed-statistical-analysis-for-non-normal-data-with-unequal-sample-size</link>
      <description><![CDATA[我正在使用Python在数据集上进行研究，在那里我正在分析吸烟状况，年龄和性别对响应时间（也是身高和体重）的影响。如所附小提琴图所示（  ）。此外，跨组的样本量非常不平衡（例如，一个组只有16个观察结果，而另一组的观测值超过4,900）。以下是有关数据的一些关键细节：

响应时间：连续变量以秒为单位。
组：年龄类别（18-27，28-37等），吸烟状态（是/否）和性别（男性/女性）。
根据可视化和统计措施，数据显然是非正常的

到目前为止，我使用非参数自举来计算不同组的中位数。问题是CI的下限或上限与中位数相同（对于某些组）。
我应用了Kruskal-Wallis测试来检查差异。显示结果＆lt; 0.5。为了进一步评估数据，我在事后测试中应用了Dunns，Bonferroni校正没有明显的差异。
 问题： 

 您建议使用哪些统计测试比较这些组的响应时间，并且具有正确的措施？？

 是否还有其他建议评估报告的数据？

]]></description>
      <guid>https://stats.stackexchange.com/questions/663327/advice-needed-statistical-analysis-for-non-normal-data-with-unequal-sample-size</guid>
      <pubDate>Mon, 31 Mar 2025 14:18:52 GMT</pubDate>
    </item>
    <item>
      <title>价值实现 - 方法</title>
      <link>https://stats.stackexchange.com/questions/663227/value-realization-approaches</link>
      <description><![CDATA[我试图以一种容易理解的方式提出我的观点。如果我仍然是统计的学生，请原谅是否有任何不准确或缺少的东西。
我有一系列与代理服务客户所花费的时间有关的数据点（每天约2k至4K互动）。我有两个簇，一个对照组和一个测试组。对照组有一堆使用普通系统运行的代理。测试组有一组代理，可以使用新系统进行操作。因此，我们为每个小组都有一系列的数据点跟踪他们的“服务时间”（“服务时间”  - 服务代理所花费的时间为呼叫服务）。我需要提供一种具有统计技术的框架或方法，该技术有助于分析一段时间内收集的数据（例如2周）并建模价值实现的设置。
我已经报告了针对对照组的指标和该指标的改进，并分享了它们的性能。但是我不确定价值实现方法。此外，业务并不渴望以货币方式找到任何东西（以$为$），而是主要是在节省的持续时间或时间上。
如果有解决此案的标准方法，请分享指针，我将尝试开发解决案件的解决方案。
主要是，要问设置VR（值实现）框架，并进行机械化该方法的步骤。 （从技术上讲）]]></description>
      <guid>https://stats.stackexchange.com/questions/663227/value-realization-approaches</guid>
      <pubDate>Fri, 28 Mar 2025 02:29:13 GMT</pubDate>
    </item>
    </channel>
</rss>