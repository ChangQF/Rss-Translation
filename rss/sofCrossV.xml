<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 06 Mar 2024 15:15:32 GMT</lastBuildDate>
    <item>
      <title>如果 E(XY)=E(XZ)，我们什么时候可以说 Y=Z</title>
      <link>https://stats.stackexchange.com/questions/641969/when-can-we-say-that-y-z-if-exy-exz</link>
      <description><![CDATA[标题已经概括了一切。假设我们有：
$$
E\左(XY\右)=E\左(XZ\右)
$$
什么时候可以说 $Y=Z?$]]></description>
      <guid>https://stats.stackexchange.com/questions/641969/when-can-we-say-that-y-z-if-exy-exz</guid>
      <pubDate>Wed, 06 Mar 2024 15:03:46 GMT</pubDate>
    </item>
    <item>
      <title>如何使用生物标志物或生物变量创建分数？</title>
      <link>https://stats.stackexchange.com/questions/641968/how-to-create-an-score-using-biomarkers-or-biological-variables</link>
      <description><![CDATA[我目前正在开展一个项目，该项目涉及根据特定生物标志物的值对一组患者进行分层。主要目标是开发一个评分系统，将患者分为低、中、高炎症特征。
我正在寻找以下方面的见解：

构建分数：标准化（z 值）？还有比这更好的方法吗？考虑到变量是定量连续的（作为浓度）。将变量视为高斯分布
将生物标记物纳入量表或进行转换后，如何在分数中指定分类的截止点？

3组低、中、高炎症特征的想法是随机的，可能是4个，为了直观的想法我宁愿是3个，但欢迎任何见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/641968/how-to-create-an-score-using-biomarkers-or-biological-variables</guid>
      <pubDate>Wed, 06 Mar 2024 15:00:00 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch Transformer 编码器层返回填充序列的“nan”值</title>
      <link>https://stats.stackexchange.com/questions/641964/pytorch-transformer-encoder-layer-returns-nan-values-for-padding-sequences</link>
      <description><![CDATA[我正在使用变压器的编码器层。该模型接收来自不同序列长度的输入。
处理数据时，我向所有样本添加填充并生成形状 [seq_len, 1] 掩码，我将其传递到 src_key_padding_mask 参数中的编码器层。转换器的输入张量的形状为[1, seq_len, features]，batch_size=1。
问题是在编码器输出中生成“nan”有填充位置的值。例如，形状张量[1,150,100]（其中seq_len的前130个值不是填充的但最后20个是填充的）生成具有“nan”的最后20个值。在最后一个维度。
这是我的代码：
 mask = mask.reshape(batch_size, num_frames, num_features)
        掩码 = ~mask.any(轴=2)
        mask = mask.bool().transpose(0,1)
        
        positional_encodings = get_positional_encoding(video_frames.size(1), self.embedding_dim).to(video_frames.device)
        视频帧 = 视频帧 + 位置编码
        
        Transformer_output = self.transformer_encoder( # 期望 [batch, seq_len, emb_dim]
            视频帧，
            src_key_padding_mask=mask # 需要 [batch, seq_len]
        ）
]]></description>
      <guid>https://stats.stackexchange.com/questions/641964/pytorch-transformer-encoder-layer-returns-nan-values-for-padding-sequences</guid>
      <pubDate>Wed, 06 Mar 2024 14:39:42 GMT</pubDate>
    </item>
    <item>
      <title>R中适合倾斜连续百分比丰度数据的GLM函数</title>
      <link>https://stats.stackexchange.com/questions/641962/suitable-glm-function-in-r-for-skewed-continuous-percentage-abundance-data</link>
      <description><![CDATA[我有一个小数据集，我通过计算两个成分的丰度百分比来检查它们的丰度。当我检查连续变量的分布时，它们大多偏向零和一百。我想问哪个 glm 适合此类数据。
历史记录（组件1）

fitdistrplus::descdist(component1, boot=1000)

您能指导我如何进行分析吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/641962/suitable-glm-function-in-r-for-skewed-continuous-percentage-abundance-data</guid>
      <pubDate>Wed, 06 Mar 2024 14:07:17 GMT</pubDate>
    </item>
    <item>
      <title>适当的测试来证明给定样本的假设</title>
      <link>https://stats.stackexchange.com/questions/641959/appropriate-test-to-prove-hypothesis-for-given-sample</link>
      <description><![CDATA[本质上，我正在写一篇研究论文，我将这些受试者按照从 I 到 IV 的癌症分期（顺序量表）以及他们是否对特定标记物呈阳性（名义量表）进行分组。我正在尝试确定标记物呈阳性的患者是否更有可能患有较高阶段的癌症。我已经做了卡方检验和 Mann Whitney U，两者都给了我一个统计上显着的 p&lt;0.05 值。我只是不确定这两者中哪一个证明了我的假设（如果有的话）。如果两者都不能回答我的问题，如果有人能给我提出不同测试的建议，我将不胜感激。
]]></description>
      <guid>https://stats.stackexchange.com/questions/641959/appropriate-test-to-prove-hypothesis-for-given-sample</guid>
      <pubDate>Wed, 06 Mar 2024 13:51:07 GMT</pubDate>
    </item>
    <item>
      <title>右删失和右截断如何相互作用？</title>
      <link>https://stats.stackexchange.com/questions/641956/how-do-right-censoring-and-right-truncation-interact</link>
      <description><![CDATA[我正在处理与某些实体产品的事件时间相关的数据。数据是当前状态数据，有时也称为间隔审查类型 II 数据，这意味着我只对每个数据点进行一次检查，我知道事件是否发生。这意味着我的所有数据点要么在检查时进行左审查（事件已发生），要么在检查时进行右审查（事件尚未发生）。因此，如果事件发生时间为 $T_i$ 并且与检查相对应的审查时间为 $C_i$，则观察到的数据是一系列间隔，可以是 $T_i \in [0,C_i]$ 或 $T_i \in [ C_i,\infty)$ 取决于事件是否发生。
为了使数据点具有可比性是合理的，因为随着时间的推移，材料的质量可能会有所不同，我只考虑在某个固定时间之前创建的数据点$A $。这意味着我的数据也被截断，因为不可能观察到大于 $A$ 的事件时间，所以我的所有数据点都来自正确的截断分布，可以说 $T_i \sim F(\, \cdot \,|\, T_i \leq A)$。到目前为止，我还没有考虑过这种截断，但我想确保它不会产生太大的差异。
问题是如何让审查和截断相互作用。对我来说，直觉似乎是审查间隔必须包含在截断间隔中，这意味着我要么限制正确的审查 $T_i \in [C_i,A] \subset [0,A ]$，或者我忽略正确截断的右截断观察 $T_i|T_i&gt; C_i \sim F$ 和 $ T_i|T_i\leq C_i \sim F(\, \cdot \,|\, T_i \leq A)$ 。当然第三种可能是我的直觉是错误的，我只是保留右删失和右截断，然后删失区间不包含在截断区间中。]]></description>
      <guid>https://stats.stackexchange.com/questions/641956/how-do-right-censoring-and-right-truncation-interact</guid>
      <pubDate>Wed, 06 Mar 2024 12:49:51 GMT</pubDate>
    </item>
    <item>
      <title>边际效应包中的平均比较是什么？</title>
      <link>https://stats.stackexchange.com/questions/641953/what-are-average-comparisons-in-the-marginal-effects-package</link>
      <description><![CDATA[我对 marginal_effects 包中的 avg_comparison 函数的作用感到困惑。
库(lme4)
图书馆（边际效应）


我定义一个模型
模型 &lt;- glmer(y ~
                 + t
                 + 一个
                 + 一个：t
                 + e:t
                 + e:类型名称:a
                 + (1|participant_id) + (1|image_id),
                 数据 = 数据，族 = 二项式，控制 = glmerControl(optimizer=“bobyqa”))


并且我对有关该模型的各种问题感兴趣。变量t有4个组，1个参考组和3个效应组（这是我的实验条件）。现在我想将每个治疗组与参考组进行比较，同时所有其他变量均为平均值。
contrasts_h1 &lt;- avg_comparisons(model, var=list(t = &quot;reference&quot;))
对比_h1
## 术语对比度估计标准。误差 z Pr(&gt;|z|) S 2.5 %
## type_nametreatment_1 - 基线 0.0716 0.0200 3.57 &lt; 0.001 11.5 0.03235
## type_nametreatment_2 - 基线 0.0614 0.0196 3.13 0.00177 9.1 0.02289
## type_nametreatment_3 - 基线 0.0365 0.0196 1.86 0.06232 4.0 -0.00188

为了了解这实际上是什么，我遵循了边际效应动物园教程。我运行这个是为了更好地理解结果：
grid_emperical_t1 &lt;- 数据 |&gt;;变换（治疗_1=1，治疗_2=0，治疗_3=0，基线=0）
grid_emperical_bl &lt;- 数据 |&gt;变换（治疗_1 = 0，治疗_2 = 0，治疗_3 = 0，基线 = 1）
yhat_emperical_t1 &lt;- 预测（模型，newdata = grid_emperical_t1，类型 =“响应”）
yhat_emperical_bl &lt;- 预测（模型，newdata = grid_emperical_bl，类型 =“响应”）
对比m &lt; - 平均值（yhat_emperical_t1，na.rm = TRUE） - 平均值（yhat_emperical_bl，na.rm = TRUE）
对比度_m
## [1] 0.06137143

观察底部的0.06137143与对比表中的0.0614吻合良好。然而，我在第二块中所做的是：我覆盖所有数据的处理条件并将它们相互比较。我不会比较现有条件组内的预测平均值。我觉得这很奇怪，因为还有其他相关的协变量。例如，e 取决于治疗组。因此，计算所有数据的avg_comparison似乎很奇怪。我们强迫数据属于该组的非典型组。我发现将 predict(data[t == &quot;treatment_1&quot;]) 与 predict(data[t == &quot;treatment_0&quot;]) 进行比较更自然，即对数据进行子集化。
最后，我的问题：

我在概念上正确理解这里发生了什么吗？
如果是，为什么要以这种方式计算平均比较？
]]></description>
      <guid>https://stats.stackexchange.com/questions/641953/what-are-average-comparisons-in-the-marginal-effects-package</guid>
      <pubDate>Wed, 06 Mar 2024 12:29:14 GMT</pubDate>
    </item>
    <item>
      <title>pyimagesearch.com - 反向传播算法。与最后两层到底有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/641950/pyimagesearch-com-backpropagation-algorithm-what-is-exactly-the-difference-wi</link>
      <description><![CDATA[在本教程的一部分中，您可以找到以下几行：
np.arange(len(A) - 2, 0, -1) 中的层：

在这里，我们开始向后循环各层，以构建导数链。他针对不考虑最后两层的情况发表了以下声明：
# 最后两层是一种特殊情况，其中输入
# 连接需要偏置项，但输出不需要

这是什么意思？事实上，当我们处于最后（输出）层时，因为它不是隐藏层，而是前一个隐藏层，所以我们仍然需要以与具有 a 的前一层兼容的方式指定矩阵的维度偏置权重但当前没有？]]></description>
      <guid>https://stats.stackexchange.com/questions/641950/pyimagesearch-com-backpropagation-algorithm-what-is-exactly-the-difference-wi</guid>
      <pubDate>Wed, 06 Mar 2024 11:14:10 GMT</pubDate>
    </item>
    <item>
      <title>多级建模与多级路径分析</title>
      <link>https://stats.stackexchange.com/questions/641949/multilevel-modelling-vs-multilevel-path-analysis</link>
      <description><![CDATA[有人可以用非常适合初学者的术语解释一下这两种类型的分析有何不同吗？有哪些相似之处？两者互补是否有意义？还是多余的？这些分析中的一种是否比另一种“更好”？我非常感谢您的指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/641949/multilevel-modelling-vs-multilevel-path-analysis</guid>
      <pubDate>Wed, 06 Mar 2024 11:12:56 GMT</pubDate>
    </item>
    <item>
      <title>此类矩阵数据的全局函数[关闭]</title>
      <link>https://stats.stackexchange.com/questions/641948/global-function-for-this-kind-of-matrix-data</link>
      <description><![CDATA[假设我有一个 $m\times 2875$ 训练数据矩阵和一个 $n\times 2875$&lt; /span&gt; 测试数据矩阵，每个条目的值均以单位间隔 $\left [ 0, 1 \right )$ 表示。
预测的目标是基于$m$个样本的每个$n$个样本的one-hot值.
我不知道开始编写类似 $m$-修改随机矩阵函数，然后用它来求解$n\times 2875$（针对预测，例如，$f\left ( [\ddots] \right )$)。我需要你的帮助。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/641948/global-function-for-this-kind-of-matrix-data</guid>
      <pubDate>Wed, 06 Mar 2024 10:34:02 GMT</pubDate>
    </item>
    <item>
      <title>超参数调整后模型性能更差</title>
      <link>https://stats.stackexchange.com/questions/641947/worse-model-performance-after-hyperparameter-tuning</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/641947/worse-model-performance-after-hyperparameter-tuning</guid>
      <pubDate>Wed, 06 Mar 2024 10:13:53 GMT</pubDate>
    </item>
    <item>
      <title>使用确定性处理重新计算 IPW</title>
      <link>https://stats.stackexchange.com/questions/641945/ipw-recalculating-with-deterministic-treatment</link>
      <description><![CDATA[假设我想计算某种确定性治疗的 ATE，例如手术（即，接受或未接受手术），并且我对按方案分析感兴趣。
请注意，那些接受过手术的人将始终被视为“已接受治疗”，但那些没有接受过手术的人可能会因接受手术而违反其协议。
这意味着治疗组中的人没有任何随时间变化的混杂因素（没有什么可以影响他们的暴露 - 他们现在并且永远都会暴露），但对于对照组来说，他们接受手术的可能性可能会改变随时间变化的混杂因素。
为了调整组之间的差异，我想在基线时使用 IPW，但随后我还想使用重复的 IPW 来调整随时间变化的混杂因素。我的理解是，我应该只对对照组应用重复的 IPW，而不是对治疗组应用重复的 IPW。那是对的吗？如果是这样，是否有人有一些参考资料来证明这种方法的合理性（方法论或研究示例）？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/641945/ipw-recalculating-with-deterministic-treatment</guid>
      <pubDate>Wed, 06 Mar 2024 10:03:26 GMT</pubDate>
    </item>
    <item>
      <title>用于比较两个样本分布的 Kullback-Leibler 散度</title>
      <link>https://stats.stackexchange.com/questions/641944/kullback-leibler-divergence-to-compare-two-sample-distributions</link>
      <description><![CDATA[我有一个算法，我向其提供特定的输入。该算法是确定性的，并且始终会产生相同的结果。
我还有一个随机算法，它使用随机选择来加速执行。对于相同的输入，它可能会计算出不同的结果，但通常不会。如果它计算出不同的结果，它与确定性结果没有太大不同。
我对这些算法有 200 个独特的输入，我想谈谈结果的分布。我声称结果的分布是相同的，确定性算法充当基本事实。
下面是确定性算法的结果图：

这是我使用例如随机算法时的结果图。 5核

分布似乎呈偏态正态分布。我可以在视觉上说服自己，他们应该从相同的分布中得出结果（最多有一些小的方差），但我想测试一下。 我在网上读到了 Kullback-Leibler Divergence，并发现它计算了一种分布与另一种分布差异程度的数值度量。当我将数据推入该算法时，我得到的数字非常低。但是，可以像这样使用我的真实数据作为基线分布吗？我没有实际的分布，我只有我知道从中提取的数据。哪个数字足够低，我可以说该算法从相同的分布中得出结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/641944/kullback-leibler-divergence-to-compare-two-sample-distributions</guid>
      <pubDate>Wed, 06 Mar 2024 10:00:54 GMT</pubDate>
    </item>
    <item>
      <title>具有交互作用的稳健线性回归</title>
      <link>https://stats.stackexchange.com/questions/641936/robust-linear-regression-with-interaction</link>
      <description><![CDATA[我正在使用稳健的线性回归来研究表观遗传年龄与四个不同道路缓冲区（1000m、2000m、3000m 和 4000m）中有毒元素暴露的关系。我可以在没有交互项的情况下运行稳健的线性回归，但是您能否帮助我如何在交互项（Hg*缓冲区）的情况下运行稳健的线性回归。我在下面尝试使用交互项运行稳健回归，但我没有得到 1000m 缓冲区与 Hg 的交互，而且我也没有得到 Pvalue。我想使用年龄、性别和吸烟状况作为协变量。
&lt;前&gt;&lt;代码&gt;&gt;摘要（rr.huber &lt;- rlm（PCGrimAge_IEAA ~ Hg*buffer.zone + 性别 + 年龄 + Smoking_Status，数据 = ph））

调用：rlm(公式 = PCGrimAge_IEAA ~ Hg * buffer.zone +
            性别 + 年龄 + 吸烟状态，数据 = ph)
残差：
  最小 1Q 中值 3Q 最大
-7.68190 -1.59376 -0.01048 1.58263 16.07211

系数：
  价值标准。误差t值
（截距）-0.4037 0.5335 -0.7567
           汞 -0.2404 0.3345 -0.7187
缓冲区2000米 0.4443 0.6275 0.7081
缓冲区3000米 -0.3850 0.3601 -1.0692
缓冲区4000米 -0.6141 0.5109 -1.2020
性别 -1.9878 0.1239 -16.0398
年龄 0.0011 0.0066 0.1720
吸烟状态 2.7252 0.0922 29.5725
汞：缓冲区2000米 -0.6463 0.8488 -0.7614
汞：缓冲区3000米 0.2163 0.3691 0.5860
汞：缓冲区4000米 0.5614 0.5351 1.0491

剩余标准误差：1801 个自由度上的 2.352
（1 个观察因缺失而被删除）

&gt;图书馆（emmeans）
&gt; EMM &lt;- emmeans(rr.huber, ~ Hg * buffer.zone)
&gt; EMM
Hg 缓冲区 emmean SE df asymp.LCL asymp.UCL
0.876 1000m 0.0311 0.1602 不适用 -0.283 0.3452
0.876 2000m -0.0911 0.2949 数值范围 -0.669 0.4868
0.876 3000m -0.1644 0.0774 不适用 -0.316 -0.0127
0.876 4000m -0.0909 0.1572 不适用 -0.399 0.2173

结果按以下级别进行平均： 性别
使用的置信水平：0.95
]]></description>
      <guid>https://stats.stackexchange.com/questions/641936/robust-linear-regression-with-interaction</guid>
      <pubDate>Wed, 06 Mar 2024 07:04:45 GMT</pubDate>
    </item>
    <item>
      <title>如何为逻辑回归编码多个布尔目标</title>
      <link>https://stats.stackexchange.com/questions/641927/how-to-encode-multiple-boolean-targets-for-logistic-regression</link>
      <description><![CDATA[我正在研究SAMHSA 心理健康客户级数据集。我正在尝试训练分类器来预测给定其余列的混乱情况。根据诊断，有 13 个二元疾病栏（躁郁症、精神分裂症、多动症等）。
代码：https://github.com/jacksonwalters/ml -examples/tree/main/mental_health_client-level_data
我已经训练了 RandomForestClassifier 和多类 LogisticRegression。它们的准确率是 36%，精确率是 30%，召回率是 36%。我对疾病进行了分类 [0 种疾病，1 种疾病，&gt; 1 种疾病。 1 障碍]。我还尝试对 2^13=8192 种疾病组合进行二进制编码，其准确度相似，但精确度为 17%。前一种情况的随机猜测应该是 ~7%。
如果我预测 k 均值标签，我会获得约 92% 的准确度、精确度和召回率。
对于无序标记，我应该使用 LogisticRegression 并删除所有其他列，并对剩余列执行分类吗？我会对所有 13 列执行此操作，然后除以总和即可获得 13d 向量概率输出。
输出/标签实际上是布尔向量。如果一个人被两个不同的医生诊断为 ADHD，他们就没有 2*ADHD，他们只是 ADHD，所以 ADHD + ADHD = ADHD，即幂等。
]]></description>
      <guid>https://stats.stackexchange.com/questions/641927/how-to-encode-multiple-boolean-targets-for-logistic-regression</guid>
      <pubDate>Wed, 06 Mar 2024 00:01:34 GMT</pubDate>
    </item>
    </channel>
</rss>