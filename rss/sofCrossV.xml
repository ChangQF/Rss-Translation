<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 22 Dec 2023 18:16:52 GMT</lastBuildDate>
    <item>
      <title>PERT 分布的最小和最大参数的均匀最小方差无偏估计量 (UMVUE) 是多少？</title>
      <link>https://stats.stackexchange.com/questions/635518/what-is-the-uniformly-minimum-variance-unbiased-estimators-umvue-for-the-minim</link>
      <description><![CDATA[我相信这个问题的答案是样本最小值和样本最大值，但我无法找到这方面的参考或证明。]]></description>
      <guid>https://stats.stackexchange.com/questions/635518/what-is-the-uniformly-minimum-variance-unbiased-estimators-umvue-for-the-minim</guid>
      <pubDate>Fri, 22 Dec 2023 18:15:15 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 LSTM、TFT 或其他 RNN 处理不同长度的时间序列</title>
      <link>https://stats.stackexchange.com/questions/635517/how-to-use-lstm-tft-or-other-rnn-with-time-series-of-different-lengths</link>
      <description><![CDATA[我有每天的金融交易数据集，其中包含交易量和交易价格。对于每一天，我想计算当天结束时的成交量加权平均价格。但每天的交易笔数和交易次数有所不同。
训练 LSTM、TFT 或其他神经网络来解决此问题的标准方法是什么？

填充
采样（但对于我的问题，这不起作用）

数据集如下所示：
日 |时间 |交易# |价格|音量
对于每一天，我想在当天结束之前预测交易量加权平均价格，所以我的目标是
日 |成交量加权平均价]]></description>
      <guid>https://stats.stackexchange.com/questions/635517/how-to-use-lstm-tft-or-other-rnn-with-time-series-of-different-lengths</guid>
      <pubDate>Fri, 22 Dec 2023 17:28:43 GMT</pubDate>
    </item>
    <item>
      <title>我可以应用二项分布来模拟公司股票价格的上涨和下跌吗？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635513/can-i-apply-binomial-distribution-to-model-the-increasing-and-decreasing-of-a-co</link>
      <description><![CDATA[导入 yfinance 作为 yf
将 pandas 导入为 pd
将seaborn导入为sns
将 matplotlib.pyplot 导入为 plt
从 scipy.stats 导入 binom

# 下载历史数据
aapl_data = yf.download(“AAPL”, period=“max”)

# 重置索引以便于操作
aapl_data.reset_index(inplace=True)

# 按日期降序对数据进行排序
aapl_data.sort_values(by=“日期”, 升序=False, inplace=True)

# 检查空值
打印（aapl_data.isnull（）。sum（））

# 检查数据类型一致性
aapl_data.info()

# 计算每日收益
aapl_data[&#39;每日收益&#39;] = aapl_data[&#39;调整收盘&#39;].pct_change() * 100

# 天数和成功概率
试验= len(aapl_data)
success_prob = aapl_data[&#39;每日收益&#39;].gt(0).sum() / len(aapl_data)
打印（试验，成功概率）

# 使用二项式分布对数据建模
n = 试验 # 试验次数
p = success_prob # 成功概率（每日正回报）
x = range(1, n + 1) # 可能的成功次数

# 创建二项式分布
binomial_dist = binom.pmf(x, n, p)

# 绘制二项式分布
plt.figure(figsize=(10, 6))
plt.xlim(4700, 5400)
plt.bar(x, binomial_dist, label=f&#39;二项分布 (n={n}, p={p:.2f})&#39;, alpha=0.7)
plt.title(&#39;正日收益的二项分布&#39;)
plt.xlabel(&#39;每日正收益数&#39;)
plt.ylabel(&#39;概率&#39;)
plt.图例()
plt.show()

此代码使用二项式分布对每天代表 0 和 1 的股票价格的下跌和上涨进行建模。我想知道得到的 PMF 是否正确，如果正确，这意味着什么？
这是对股票价格进行建模的更好方法还是有其他合适的分布？
我怎样才能让这段代码变得更专业？]]></description>
      <guid>https://stats.stackexchange.com/questions/635513/can-i-apply-binomial-distribution-to-model-the-increasing-and-decreasing-of-a-co</guid>
      <pubDate>Fri, 22 Dec 2023 15:45:36 GMT</pubDate>
    </item>
    <item>
      <title>由此产生的单变量边际分布不是 $t$ 分布 - 为什么？ （S木芯统计）</title>
      <link>https://stats.stackexchange.com/questions/635511/resulting-univariate-marginal-distributions-are-not-t-distributed-why-s-wo</link>
      <description><![CDATA[西蒙·伍德 (Simon Wood) 的核心统计数据显示：
&quot;如果我们用随机变量 $ 替换随机变量 $Z_i\sim_{i.i.d} N(0,1)$ T_i \sim_{i.i.d}t_k$ 在多元正态的定义中，我们得到一个具有多元$t_k(\mu, \Sigma)$ 分布。 ...请注意，生成的单变量边际分布不是 $t$ 分布的。
您能解释一下为什么不吗？
看起来像这个问题多元 t 分布的边际是单变量学生 t 分布吗？ 给出了不同的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/635511/resulting-univariate-marginal-distributions-are-not-t-distributed-why-s-wo</guid>
      <pubDate>Fri, 22 Dec 2023 15:16:35 GMT</pubDate>
    </item>
    <item>
      <title>MDS 和 Isomap 应用于相同的预计算距离</title>
      <link>https://stats.stackexchange.com/questions/635510/mds-and-isomap-applied-to-the-same-precomputed-distances</link>
      <description><![CDATA[我对 Isomap 的理解是，它是一个两步过程：首先计算样本之间的成对（测地线）距离，然后通过 MDS 来表示较低维空间中的距离矩阵。
下面，我提供sklearn MDS 和 Isomap 与相同的预先计算的距离矩阵，我恢复了 2D 表示：

结果表明，当 MDS 和 Isomap 提供相同的预计算距离矩阵时，尽管距离排名大致相同，但确切的结果可能有质的不同。例如，BD 使用 MDS 时距离较远，但使用 Isomap 时距离较近，并且 Isomap 也比 MDS 具有更强的聚类性。差异不仅仅是轮换的。
在相同的预先计算距离上出现不同行为的原因是什么？
图中的测试数据和代码：
将 numpy 导入为 np
将 pandas 导入为 pd
将 matplotlib.pyplot 导入为 plt
从 sklearn.manifold 导入 MDS、Isomap

#测试数据-5个特征之间的Spearman r矩阵
特征名称 = [&#39;A&#39;、&#39;B&#39;、&#39;C&#39;、&#39;D&#39;、&#39;E&#39;、&#39;F&#39;]
Spearman_r = np.random.uniform(size=[len(feature_names)] * 2)

#将相关性转换为距离
距离 = 1 - 绝对值(spearman_r)

#确保距离矩阵对称
距离 = (距离 + 距离.T) / 2
np.fill_diagonal（距离，0）

#Fit MDS 和 Isomap
np.随机.种子(0)
mds_坐标 = MDS(n_components=2,
                      相异性=&#39;预先计算&#39;,
                      random_state=0).fit_transform(距离)
np.随机.种子(0)
isomap_coordinates = Isomap(n_components=2, metric=&#39;预先计算&#39;).fit_transform(距离)

#绘制结果
f, axs = plt.subplots(1, 2, Figsize=(6, 3), sharey=True, sharex=True, 布局=&#39;紧&#39;)
对于轴中的轴：
    标题, 坐标 = (&#39;MDS&#39;, mds_坐标) if ax == axs[0] else (&#39;Isomap&#39;, isomap_坐标)
    坐标 = np.array(坐标) #output_type 可以是 df
    ax.scatter(坐标[:, 0], 坐标[:, 1], 标记=&#39;s&#39;, s=30,
               c=范围(len(feature_names)), cmap=&#39;Set1&#39;)
    ax.set_title(标题)
    [ax.annotate(名称, xy, fontsize=10, fontweight=&#39;bold&#39;)
     对于名称，zip 中的 xy（要素名称，坐标）
     ]
f.suptitle(&#39;MDS 和 Isomap 应用于预先计算的距离矩阵&#39;)

]]></description>
      <guid>https://stats.stackexchange.com/questions/635510/mds-and-isomap-applied-to-the-same-precomputed-distances</guid>
      <pubDate>Fri, 22 Dec 2023 15:11:31 GMT</pubDate>
    </item>
    <item>
      <title>A/B 测试设置中 Diff-in-Diff 的推断</title>
      <link>https://stats.stackexchange.com/questions/635509/inference-of-a-diff-in-diff-in-an-a-b-test-setting</link>
      <description><![CDATA[我有一个将运行很长时间的实验，其中用户有平等的机会被分配到治疗组或对照组，并且新用户一直加入实验，但我想计算一个无偏的指标实验开始前选择的用户群体。然后，我将使用该队列计算比率指标的差异。
使用这个预定义队列的原因是，这样的指标比简单地比较治疗组和对照组要敏感得多。该指标的定义如下：
$ \text{比率指标 (RM) } = \space \frac{\text{实验期间的计数指标 } - \text{ 实验前的计数指标}}{\ text{群组中的用户数量}} $
$ \text{对 RM 的影响} = RM_{治疗} - RM_{控制}$
如何计算该效应的置信区间和 p 值？如何运行功耗分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/635509/inference-of-a-diff-in-diff-in-an-a-b-test-setting</guid>
      <pubDate>Fri, 22 Dec 2023 15:06:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么鲁汶方法是非确定性的？</title>
      <link>https://stats.stackexchange.com/questions/635507/why-is-louvain-method-non-deterministic</link>
      <description><![CDATA[我正在 R 中的 igraph 中使用 Louvain 算法的实现进行社区检测。我观察到多次运行它会产生不同的答案。然而，当我读到算法时
Louvain 方法 - 维基百科，没有任何东西具有任何明显的随机性。我的猜测是，以不同的顺序遍历这些点可能会产生不同的答案，并且 igraph 代码在处理顶点之前会随机化顶点的顺序。这就是它产生多个答案的原因 - 还是还有其他原因？]]></description>
      <guid>https://stats.stackexchange.com/questions/635507/why-is-louvain-method-non-deterministic</guid>
      <pubDate>Fri, 22 Dec 2023 14:37:42 GMT</pubDate>
    </item>
    <item>
      <title>蒙特卡罗假设检验：选择合适的统计量[关闭]</title>
      <link>https://stats.stackexchange.com/questions/635506/montel-carlo-hypothesis-test-choosing-a-suitable-statistic</link>
      <description><![CDATA[我试图理解“蒙特卡洛假设检验”是如何进行的。有效，我正在尝试解决以下问题：
$Z_{i,1},...,Z_{i,5}$ 是 iid $N (\mu , \sigma^2)$，其中 $\mu$ 和 $\sigma^ 2$ 未知。
$X_i=max\{Z_{i,1},...,Z_{i,5}\}-min\{Z_{i,1},. ..,Z_{i,5}\}$
给定观察样本$X_{1,obs},...,X_{10,obs}$，目标是执行蒙特卡罗假设检验： $H_0: \sigma = 1$ vs $H_1: \sigma  1$.
&lt;小时/&gt;
最初我认为为了解决这个问题我可以考虑以下 3 个步骤：

#1 计算观察到的$T$-观测值$X_{1,obs},...的统计量,X_{10,obs}$，例如：$T_{obs}=\sum_{i=1}^{10} |X_{i,obs}| $

然后，对 $j=1,...,99$ 执行步骤#2：

#2 模拟来自 $N(\mu , 1) 的一组五个 $Z$ 值$ 对于一些 $\mu$ （它看起来像 $\mu$ 的值对此没有影响）。然后计算$X_{1,j}$的值。同样，再模拟九组五个 $Z$ 值，最终计算出 $X_{2,j} 的值， ...,X_{10,j}$。接下来，计算模拟 $X$ 的 $T$ 统计量，例如：$T_j=\sum_{i=1}^{10} |X_{i,j}|$ 。

#3 按升序排列：$T_{obs}$ 和 $T_1,.. .,T_{99}$.那么对于 $\alpha=5\%$ 我们可以拒绝原假设，如果 $T_{obs}$ 排在五个最小值之列；否则我们没有证据来拒绝原假设。


&lt;小时/&gt;
因此，我选择 $X$ 的绝对值之和作为统计量 ($T $）在这里，因为我认为这将是一个好主意，因为在替代假设下这将给出一个小值
我的问题是：我是否选择了合适的统计数据来解决这个问题，还是应该选择不同的统计数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/635506/montel-carlo-hypothesis-test-choosing-a-suitable-statistic</guid>
      <pubDate>Fri, 22 Dec 2023 14:32:02 GMT</pubDate>
    </item>
    <item>
      <title>期望最大化中的特征重要性</title>
      <link>https://stats.stackexchange.com/questions/635505/feature-importance-in-expectation-maximization</link>
      <description><![CDATA[上下文使用 EM 算法进行混合模型 - 更准确地说是狄利克雷多项式混合，如 狄利克雷多项式混合物：微生物宏基因组学的生成模型。这里通常处理数百个样本和可能数十到数百个特征，尽管这些特征中只有少数被认为是重要的（在引用的论文的上下文中，它是几个微生物属，它们在某些混合物中最显着地表达）组件。）
是否有系统的方法根据特征的重要性对特征进行排名（使用 EM 时）？或者选择功能的基本组合？
例如，我找到了这篇论文：高斯混合模型功能选择：一种嵌入式方法，但我无法访问它，并且我不确定它是否提供了一种主流/足够可靠的方法来花时间。]]></description>
      <guid>https://stats.stackexchange.com/questions/635505/feature-importance-in-expectation-maximization</guid>
      <pubDate>Fri, 22 Dec 2023 14:22:28 GMT</pubDate>
    </item>
    <item>
      <title>SEM：正态理论最大似然拟合函数</title>
      <link>https://stats.stackexchange.com/questions/635502/sem-normal-theory-maximum-likelihood-fitting-function</link>
      <description><![CDATA[我参加了一些课程，其中讨论了结构方程建模中通过最大似然进行的模型估计。我在经典文献中也发现了正态理论 ML 拟合函数的一个定义（例如 博伦，1989）：
$ \hat{F}_{ML} = \ln|\boldsymbol{\Sigma}(\boldsymbol{\theta})| + tr[\mathbf{S} \boldsymbol{\Sigma}(\boldsymbol{\theta})^{-1}] - \ln|\mathbf{S}|- p $
其中 $\boldsymbol{\Sigma}(\boldsymbol{\theta})$ 是模型隐含的协方差矩阵，$\mathbf{S}$ 是观察到的样本协方差矩阵，$p$ 是明显变量的数量。
Bollen (1989) 证明，当 $\hat{\boldsymbol{\Sigma}} = \mathbf{S}$ （且 $\boldsymbol{\Sigma}(\boldsymbol{\theta})$ 替换为 $\hat{\boldsymbol{\Sigma}}$ )，$\hat{F}_{ML}$ 为零，因此代表完美拟合。
但是，在课程中我看到了这样的规范：
$ \hat{F}_{ML} = \ln|\boldsymbol{\Sigma}(\boldsymbol{\theta})| + tr[\mathbf{S} \boldsymbol{\Sigma}(\boldsymbol{\theta})^{-1}] - \ln|\mathbf{S}|- p + [\mathbf{m}-\boldsymbol {\mu}(\boldsymbol{\theta})]&#39;\boldsymbol{\Sigma}^{-1}[\mathbf{m}-\boldsymbol{\mu}(\boldsymbol{\theta})] $
看起来平均结构也被添加到拟合函数中，其中 $\mathbf{m}$ 是观察到的平均向量，$\boldsymbol{\mu}(\boldsymbol{\theta})$ 是模型隐含的均值向量。
我的假设是，为什么有这两种不同的定义，因为在经典的 CFA（以及许多其他类型的更一般的 SEM）中，均值结构是饱和的，并且模型失配不可能来自均值结构。这意味着 $[\mathbf{m}-\boldsymbol{\mu}(\boldsymbol{\theta})]$ 为零，因为 $\mathbf{m}=\boldsymbol{\mu}(\boldsymbol{\theta})$ 并且附加项将消失。然而，我找不到任何文献证实这一点，所以如果有人知道第二个（更一般的）规范来自哪里或者可以更详细地解释它，我将非常感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/635502/sem-normal-theory-maximum-likelihood-fitting-function</guid>
      <pubDate>Fri, 22 Dec 2023 13:33:48 GMT</pubDate>
    </item>
    <item>
      <title>删除多个组和多个特征中的异常值</title>
      <link>https://stats.stackexchange.com/questions/635501/removing-outliers-in-several-groups-and-for-several-features</link>
      <description><![CDATA[我不确定如何删除或缩小异常值。假设我有两组，治疗组和对照组。我测量了两者的特征 1 和特征 2。
我应该如何处理异常值？分别针对每个组和每个功能？
含义：特征1组1、特征1组2、特征2组1和特征2组2
还是作为一个整体？]]></description>
      <guid>https://stats.stackexchange.com/questions/635501/removing-outliers-in-several-groups-and-for-several-features</guid>
      <pubDate>Fri, 22 Dec 2023 13:32:21 GMT</pubDate>
    </item>
    <item>
      <title>在进行PCA之前如何减少连续变量的数量？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635499/how-to-reduce-number-of-continuous-variables-before-doing-pca</link>
      <description><![CDATA[哪组变量最能预测女性的握力？
-&gt;我有 18 个变量，现在想要进行 PCA，但首先我必须：“在进行分析之前减少连续变量的数量。”
我的作业问题被引用：
”2.哪一组变量最能预测女性的握力？
A。在进行分析之前减少连续变量的数量。”
我想我必须进行 PCA，但他们说“在进行分析之前减少连续变量的数量（= 这可能是 PCA）。”现在我不知道如何减少变量？也许可以向前/向后选择？谁能证实这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/635499/how-to-reduce-number-of-continuous-variables-before-doing-pca</guid>
      <pubDate>Fri, 22 Dec 2023 13:07:48 GMT</pubDate>
    </item>
    <item>
      <title>R：MASS::glm.nb 和 glmmTMB“nbinom2”之间的参数化差异</title>
      <link>https://stats.stackexchange.com/questions/635498/r-parameterization-differences-betwen-massglm-nb-and-glmmtmb-nbinom2</link>
      <description><![CDATA[我想了解有关 RStudio 中两个不同 GLM 输出的意见。
我使用样方计算为面积偏移，对 21 个地点的计数数据（粪便颗粒）进行了建模。我首先使用 GLM 泊松回归来定义模型结构，该模型具有严重的过度分散性和严重的过度分散性。零膨胀。我转向负二项式，它解决了这两个问题，但根据使用的包（MASS：glm.nb 和 glmmTMB nbinom2），我得到了不同的结果。他们给出相同的 theta 估计、相同的 AIC，但不同的 SE 和z 值，特别是对于一个预测变量，它在一个包中显得重要，但在另一个包中则不然。这是在模型选择之前。
因此，我想知道所使用的两个包之间的参数化有什么区别？根据我的阅读，他们似乎使用相同的方差公式，都是通过最大似然估计的：

glmmTMB：方差 = µ(1 + µ/k)
MASS：方差 = μ+μ²/θ，使得 θ=1/k

我怀疑这与 MASS::glm.nb 从对数似然计算中删除常量有关，而 glmmTMB 则不然，但我无法确认。
我倾向于坚持使用 MASS，因为我在这里不使用任何 RE，但我想知道发生了什么。
代码输出：
&lt;前&gt;&lt;代码&gt;&gt; # 海量包
&gt; mod.nbmass &lt;- glm.nb(颗粒 ~ RS1+RS2+RS4+RS5+RS6+offset(log(quadrats)), link = &quot;log&quot;, data=data_site)
&gt;摘要（mod.nbmass）

称呼：
glm.nb(公式 = 颗粒 ~ RS1 + RS2 + RS4 + RS5 + RS6 + 偏移量(log(quadrats)),
    数据 = data_site，链接 =“日志”，init.theta = 0.9808088892）

残差偏差：
    最小 1Q 中值 3Q 最大
-2.6923 -0.9313 -0.1119 0.2173 1.5372

系数：
            估计标准。误差z值Pr(&gt;|z|)
（截距） 0.17109 0.22170 0.772 0.4403
RS1 -0.04392 0.34372 -0.128 0.8983
RS2 0.21905 0.31118 0.704 0.4815
RS4 -0.04524 0.31740 -0.143 0.8866
RS5 0.21135 0.34775 0.608 0.5433
RS6 -0.67892 0.33963 -1.999 0.0456 *
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（负二项式(0.9808)族的色散参数取为1）

    零偏差：20 自由度上为 29.252
残余偏差：15 个自由度上为 24.854
注册会计师：246.43

Fisher 评分迭代次数：1


              西塔：0.981
          标准。误差：0.290

 2 x 对数似然：-232.429
&gt; # glmmTMB 包
&gt; mod.nbTMB&lt;-glmmTMB(颗粒 ~ RS1+RS2+RS4+RS5+RS6+offset(log(quadrats)), family=“nbinom2”, data=data_site)
&gt;摘要(mod.nbTMB)
 家族：nbinom2（日志）
公式：颗粒 ~ RS1 + RS2 + RS4 + RS5 + RS6 + 偏移量(log(quadrats))
数据：data_site

     AIC BIC logLik 偏差 df.resid
   246.4 253.7 -116.2 232.4 14


nbinom2 系列的色散参数 ()：0.981

条件模型：
            估计标准。误差z值Pr(&gt;|z|)
（截距）0.17109 0.22163 0.772 0.440
RS1 -0.04393 0.39138 -0.112 0.911
RS2 0.21905 0.26685 0.821 0.412
RS4 -0.04525 0.30701 -0.147 0.883
RS5 0.21135 0.40676 0.520 0.603
RS6 -0.67892 0.48995 -1.386 0.166

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/635498/r-parameterization-differences-betwen-massglm-nb-and-glmmtmb-nbinom2</guid>
      <pubDate>Fri, 22 Dec 2023 12:42:43 GMT</pubDate>
    </item>
    <item>
      <title>确定泊松过程速率是否变化</title>
      <link>https://stats.stackexchange.com/questions/635477/determine-if-poisson-process-rate-changes</link>
      <description><![CDATA[想象一下，一个人 P 每小时多次呼叫呼叫中心。有 50% 的概率，P 会一直以较低的速率进行呼叫（例如平均每小时约 3 个呼叫）。有 50% 的概率，P 将以更高的速率开始每小时呼叫（例如每小时约 30 个呼叫）；然而，在一小时内的任何时间，P 都有可能停止如此频繁的呼叫，并进入较慢的速率（每小时约 3 个呼叫）。
如果我们查看一小时内收到多少个呼叫的概率分布，它将接近泊松分布之和，看起来像双峰分布：
值得注意的是，存在“桥梁”的可能性很低。在两个峰值之间（在 10 到 20 次呼叫之间最明显），这是 P 在一个小时内的某个时刻停止大量呼叫的情况。具体来说，一小时的通话可能如下所示：

我们看到在前半小时 P 的呼叫频率很高，但随后大约半小时后转为低频率。需要非常清楚的是，实际上我们能够访问的唯一数据是蓝色曲线（累计数量）的调用），而不是橙色曲线（这本质上是我们试图推断的，但我将其包含在这里只是为了说明目的）。
问题是，考虑到一小时内接到电话的时间线（如上所示），我们是否可以以非常高的概率做出决定：

P 开始以更高的费率打电话吗？
如果 (1) 为真，P 是否在某个时刻开始以较低的费率呼叫？

本质上，我们的目标是推断橙色的“True or False”。上图中蓝色曲线“累计呼叫数与时间”的关系曲线。我并不关心从 True 到 False 的变化何时发生，只确定它是否确实发生。
对于（1），我们可以在呼叫总数中设置一些阈值，例如，如果收到超过 10 个呼叫，那么 P 在开始时一定以很高的速率呼入。&lt; /p&gt;
对于（2）来说有点棘手。一种想法是，通话记录可能会在一小时的前几分钟显示比一小时后几分钟更多的呼叫。例如，我曾想过查看呼叫之间的延迟分布，而不是呼叫总数，但在这种情况下还没有找到一种非常有效的方法来制定决策。尽管如此，我觉得我们拥有完整的通话记录这一事实应该比仅仅设置通话总数的阈值更能回答这个问题。
任何关于如何思考这个问题的帮助或指示将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/635477/determine-if-poisson-process-rate-changes</guid>
      <pubDate>Fri, 22 Dec 2023 05:50:38 GMT</pubDate>
    </item>
    <item>
      <title>关于数据对数转换的有趣观察</title>
      <link>https://stats.stackexchange.com/questions/635466/an-interesting-observation-regarding-the-log-transformation-of-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635466/an-interesting-observation-regarding-the-log-transformation-of-data</guid>
      <pubDate>Fri, 22 Dec 2023 00:42:00 GMT</pubDate>
    </item>
    </channel>
</rss>