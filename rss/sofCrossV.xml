<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 14 Dec 2023 18:17:21 GMT</lastBuildDate>
    <item>
      <title>研究数据集几何结构的学术领域名称</title>
      <link>https://stats.stackexchange.com/questions/634930/name-of-academic-field-studying-geometric-structure-of-data-sets</link>
      <description><![CDATA[我对数据集的几何结构有疑问，尤其是。因为它涉及预测变量之间的关系。该字段有名称吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/634930/name-of-academic-field-studying-geometric-structure-of-data-sets</guid>
      <pubDate>Thu, 14 Dec 2023 17:44:51 GMT</pubDate>
    </item>
    <item>
      <title>如何用 sin 和 cos 函数之和来近似时间序列？</title>
      <link>https://stats.stackexchange.com/questions/634929/how-do-i-approximate-a-timeseries-with-a-sum-of-sin-and-cos-functions</link>
      <description><![CDATA[我有一个时间序列，我试图使用以下类型的方程来近似它：
y = A + B*sin(2*pi*x/n) + C*cos(2*pi*x/m) + D*sin(2*pi*x/q) + . ..
问题是如何找到参数A、B、C、D、n、m、q等...手动查找这些值显然是一个非常繁琐的过程。我认为这对于 FFT 来说是一个相对简单的问题，但我一无所获（以前从未做过！）。
我的代码（R）是这样的：
value.ft &lt;- fft(out.df$VALUE)
value.terms &lt;- 4

fft.value &lt;-rep(0, length(value.ft))
fft.value[1:value.terms] &lt;- value.ft[1:value.terms]

value.approx &lt;- Re(fft(fft.value, inverse=TRUE)) / length(out.df$VALUE)

使用以下 data.frame (out.df) 作为输入：
结构(列表(out.df.SEC = c(0, 300, 600, 900, 3000, 3300, 3600,
3900、4200、4500、6600、6900、7200、7500、7800、8100、10200、
10500、10800、11100、11400、13500、13800、14100、14400、14700、
15000、17100、17400、17700、18000、18300、18600、20700、21000、
21300、21600、21900、22200、24000、24300、24600、24900、25200、
25500、27600、27900、28200、28500、28800、29100、31200、31500、
31800、32100、32400、32700、34500、34800、35100、35400、35700、
36000、38100、38400、38700、39000、39300、39600、41700、42000、
42300、42600、42900、43200、45300、45600、45900、46200、46500、
48600、48900、49200、49500、49800、50100、52200、52500、52800、
53100、53400、53700、55800、56100、56400、56700、57000、59100、
59400、59700、60000、60300、60600、62700、63000、63300、63600、
63900、64200、66300、66600、66900、67200、67500、69600、69900、
70200、70500、70800、71100、73200、73500、73800、74100、74400、
74700、76800、77100、77400、77700、78000、78300、80100、80400、
80700, 81000, 81300, 81600), out.df.VALUE = c(4.858, 4.938, 4.724,
4.45、3.70666666666667、3.9、3.83、3.784、3.704、3.6775、3.4375、
3.368、3.394、3.552、3.728、3.65、3.46、3.444、3.392、3.378、
3.444、3.34、3.328、3.246、3.192、3.212、3.23、3.6475、3.484、
3.418、3.556、3.778、3.80666666666667、4.278、4.428、4.62、4.886、
4.872、4.99、6.7、6.132、5.318、4.722、4.556、4.32、4.4125、4.442、
4.376、4.43、4.55、4.58、4.114、4.026、4.11、3.994、3.97、4.13、
3.98、4.006、3.918、3.75、3.734、3.652、3.81、3.814、3.816、3.674、
3.592、3.78、3.608、3.446、3.474、3.564、3.252、3.17、3.1、3.044、
2.818、2.868、2.564、2.65、2.732、2.76、2.646、2.608、2.6075、
3.0975、2.794、2.962、2.848、2.276、2.15、2.326、2.19、2.396、
2.072、2.758、2.73666666666667、2.66、2.726、2.556、2.61、2.964、
3.125、3.014、2.966、2.794、2.95、2.91666666666667、3.054、3.148、
3.068、2.97、3.08、2.9、2.88、2.904、2.976、3.148、3.078、3、
2.888、2.914、2.774、2.708、2.59666666666667、3.008、2.976、3.152、
3.102, 2.954, 2.96, 2.895, 2.854, 2.832, 2.908, 2.886, 3.026)), 类 = &quot;data.frame&quot;, row.names = c(NA, -138L))

结果看起来像这样，我认为它并没有达到预期的那么好：

更改变量value.terms不会改善结果，并且往往会导致过度拟合。 FFT 是正确的方法吗？还是我把事情变得过于复杂了？]]></description>
      <guid>https://stats.stackexchange.com/questions/634929/how-do-i-approximate-a-timeseries-with-a-sum-of-sin-and-cos-functions</guid>
      <pubDate>Thu, 14 Dec 2023 17:34:01 GMT</pubDate>
    </item>
    <item>
      <title>基于混淆矩阵绘制树状图</title>
      <link>https://stats.stackexchange.com/questions/634927/drawing-a-dendrogram-based-on-a-confusion-matrix</link>
      <description><![CDATA[我有一个简单的二维混淆矩阵，我对每个真实类别进行了标准化。现在，将其可视化为树状图的最佳方法是什么？
我已经看到了基于混淆矩阵本身的分层凝聚聚类，这就是我目前正在做的事情。然而，这感觉有点违反直觉，因为这样的聚类方法通常应用于原始数据，而不是由处理该原始数据的另一种方法产生的混淆矩阵。有没有更好的办法？例如，通过直接将混淆分数转换为可以绘制树状图的距离矩阵？]]></description>
      <guid>https://stats.stackexchange.com/questions/634927/drawing-a-dendrogram-based-on-a-confusion-matrix</guid>
      <pubDate>Thu, 14 Dec 2023 17:15:18 GMT</pubDate>
    </item>
    <item>
      <title>从 R 中的模拟数据推断混合逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/634925/inference-of-a-mixture-of-logistic-regression-from-simutation-data-in-r</link>
      <description><![CDATA[这里是允许模拟逻辑回归 15 个分量的混合的设置和代码；这里每个组件都有 5 个与其他组件共享的公共变量（尽管 Beta 值不同）和 5 个特定变量。我们有 2500 x 15 个观测值，每个观测值可以观测到所有 80 个变量。系数和变量均来自 i.i.d.标准高斯。
&#39;&#39;&#39; # 模拟的一些参数
设置.种子(42)
n &lt;- 2500 # 按组件观察的数量
k &lt;- 15 # 组件数量

n_var_com=5
n_var_spec=5

# 常见的解释变量
x_common&lt;-NULL
# 具体的解释变量
x_spec&lt;-NULL
beta_0&lt;- NULL
beta_common&lt;-矩阵（数据 = NA，nrow = k，ncol = 5）
beta_specific&lt;-矩阵（数据 = NA，nrow = k，ncol = 5）

for(j in 1:n_var_com){
  x_common &lt;- cbind(x_common,rnorm(n*k))
}
设置.种子(42)
# 解释性变量特定
for(j in 1:(n_var_spec * k)){
  x_specific &lt;- cbind(x_specific,rnorm(n*k))
}
for(i in 1:k){
  # 各分量逻辑回归公共变量参数
  beta_0[i]&lt;- runif(1, -3, 3)
  for(j in 1:n_var_com){
    beta_common[i,j] &lt;- runif(1, -3, 3)
  }
  # 该组件神逻辑回归特定变量的参数
  for(j in 1:n_var_spec) {
    beta_specific[i,j] &lt;-runif(1, -3, 3)
  }
}

x&lt;-cbind(x_common,x_special)
# 将空数据框初始化为股票数据
数据 &lt;- data.frame()

# 循环每个组件生成数据

for (i in 1:k) {
  # 每个观察值的逻辑概率
  索引_var_comm = 1:5
  index_var_spec = (1+i*n_var_spec):((i+1)*n_var_spec)
  logit_prob &lt;- beta_0[i] + rowSums(beta_common[i,] * x[(1+(i-1)*n):(i*n), index_var_comm]) +
    rowSums(beta_specific[i,] * x[(1+(i-1)*n):(i*n), index_var_spec])
    
  # 生成目标变量
  y &lt;- rbinom(n, 1, plogis(logit_prob))
    
  # 将该组件的数据与之前的模拟相结合
  data_comp &lt;- data.frame(
    x = x[(1+(i-1)*n):(i*n), 1:80],
    y = y，
    plogis(logit_prob),
    矩阵（1：5，nrow = n，ncol = 5，byrow = TRUE），
    矩阵（（1 + i * n_var_spec）：（（i + 1）* n_var_spec），nrow = n，ncol = 5，byrow = TRUE），
    component = rep(i, n) # 注入标识符 le composant d&#39;origine
  ）
  数据&lt;-bind_rows（数据，data_comp）
}

# 检查第一行
头（数据）
#现在正在整理数据

行 &lt;- 样本（nrow（数据））
data_shuffle&lt;- 数据[行, ]
&#39;&#39;&#39;

现在问题如下：
从“data_shuffle”推断原始模型，但限制是我们不知道每个观察属于哪个组件（信息保存在 data_shuffle 中仅用于后验性能评估目的）也不知道组件的数量。
这意味着我们需要估计组件的数量，每个组件的每个逻辑回归系数（这很棘手，因为需要组件的逻辑回归中的变量选择方法（80 多个中只有 10 个有贡献！） !))，最后是每个观测值的某种成分分类方法（一个概率向量，其中每个坐标代表观测值属于该成分的概率）。
附注：到目前为止我已经尝试过flymix但没有取得太大成功]]></description>
      <guid>https://stats.stackexchange.com/questions/634925/inference-of-a-mixture-of-logistic-regression-from-simutation-data-in-r</guid>
      <pubDate>Thu, 14 Dec 2023 16:57:37 GMT</pubDate>
    </item>
    <item>
      <title>爆炸边际似然的数值优化</title>
      <link>https://stats.stackexchange.com/questions/634924/numerical-optimization-of-marginal-likelihood-that-explodes</link>
      <description><![CDATA[我有一个具有以下形式的边际可能性的模型：
$$\mathcal{L}(\theta_1, \theta_2, \theta_3|\{x_{i,j}\}_{i=1, j=1} ^{N, M_i})=\prod_{i=1}^{N}\int_{0}^{1} f(p_i;\theta_1) \prod_{j=1}^{M_i}\big(p_i g(x_{i,j};\theta_2)+(1-p_i) h(x_{i,j};\theta_3)\big)dp_i$$
我希望通过数值求解 $(\theta_1, \theta_2, \theta_3)$ 来最大化上述可能性。问题是分布 $G$ 和 $H$ 相当尖峰，因此， $M_i$ 上的乘积往往会很快爆炸到无穷大。通常，在 MLE 中，记录可能性可以解决这个问题，但我显然不能将日志放入积分中。是否有任何数值解决方法或不同的优化方法可以处理这种类型的边缘化可能性？]]></description>
      <guid>https://stats.stackexchange.com/questions/634924/numerical-optimization-of-marginal-likelihood-that-explodes</guid>
      <pubDate>Thu, 14 Dec 2023 16:41:31 GMT</pubDate>
    </item>
    <item>
      <title>倾向评分匹配会降低 OVB 吗？</title>
      <link>https://stats.stackexchange.com/questions/634923/does-propensity-score-matching-reduce-ovb</link>
      <description><![CDATA[假设您有大量人口的数据，其中一小部分得到了治疗。假设有足够的已处理数据点，您不需要倾向得分来减少数据。然后可以选择

包含所有协变量的正态逻辑回归，包括作为二元协变量的“isTreated”。
倾向得分匹配以创建对照组和对照组随后对两组进行比较。

第二个选项是否减少了遗漏变量偏差，因为：

在可测量变量方面相似的个体在未测量变量方面也可能相似
它将获取逻辑回归中未包含的交互项的影响

我本以为会这样做，但是弗兰克·哈雷尔写入：
&lt;块引用&gt;
我看到许多研究人员在直接协变量调整要优越得多时使用 PS，例如，当有 100,000 个观察值和 100 个协变量时。

&lt;小时/&gt;
我找到了一篇讨论这个问题的论文，但它相当不确定。
Shah、B. R.、A. Laupacis、J. E. Hux 和 P. C. Austin。 2005年。
“倾向评分方法
在观察研究中给出了与传统回归模型类似的结果：系统回顾。”临床流行病学杂志 58（6）：550–9。]]></description>
      <guid>https://stats.stackexchange.com/questions/634923/does-propensity-score-matching-reduce-ovb</guid>
      <pubDate>Thu, 14 Dec 2023 16:13:32 GMT</pubDate>
    </item>
    <item>
      <title>在没有自然分组的情况下使用双重差异</title>
      <link>https://stats.stackexchange.com/questions/634921/using-difference-in-differences-with-no-natural-groupings</link>
      <description><![CDATA[我在我的组织中进行了许多分析，其中人们在没有自然分组的情况下对个人级别的数据进行双重差异。例如，研究人员研究了某种特定药物对健康结果的影响。许多人在一年中的不同时间点开始服用药物，分析对这些人进行分析，并根据同一时间段的一组协变量为每个人匹配一个对照个体，然后将治疗个体及其对照进行堆叠以便治疗期的开始时间重叠（即一个治疗期可能在一月开始，另一个可能在六月开始，但为了分析，这两个治疗期都被视为治疗期的开始）。然后他们运行标准 2x2 DiD。
假设匹配足以处理选择问题和平行趋势，这是一个合适的方法吗？我的直觉告诉我，这会遇到一些文献中提到的交错采用的问题，但由于它们及时地重新集中了每个人，我对此并不清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/634921/using-difference-in-differences-with-no-natural-groupings</guid>
      <pubDate>Thu, 14 Dec 2023 15:53:02 GMT</pubDate>
    </item>
    <item>
      <title>如何量化错误指定的回归模型残差的随机性？</title>
      <link>https://stats.stackexchange.com/questions/634920/how-can-i-quantify-the-randomness-in-the-residuals-for-a-mis-specified-regressio</link>
      <description><![CDATA[假设我有一个错误指定的模型，导致我无法观察到一些重要的变量。我认为这个错误指定的模型中的残差包括来自那些重要的不可观察量的变化以及一些随机性。我想量化这种随机性。让我们假设明确的模型如下：
$$Y = a+ bX_1+bX_2+e$$
但是，我们无法看到或测量$X_2$。因此，我们可以估计以下回归：
$$Y = a+ bX_1+v$$
其中 $v$ 包括 $bX_2+e$。我可以观察 $v$，但我正在寻找的是量化 $bX_2$ 的大小。由于我无法直接测量 $bX_2$，我正在考虑使用模拟或引导方法来估计 $e$&lt; /span&gt; 然后将 $e$ 的分布与 $v$ 的分布进行比较，得到关于 $bX_2$ 的更好主意。我想知道是否有人可以就我的问题给我任何建议。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/634920/how-can-i-quantify-the-randomness-in-the-residuals-for-a-mis-specified-regressio</guid>
      <pubDate>Thu, 14 Dec 2023 15:43:27 GMT</pubDate>
    </item>
    <item>
      <title>两个随机函数图中同时游走发生碰撞之前的预期步骤</title>
      <link>https://stats.stackexchange.com/questions/634918/expected-steps-until-collision-of-a-simultaneous-walk-in-two-random-functional-g</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/634918/expected-steps-until-collision-of-a-simultaneous-walk-in-two-random-functional-g</guid>
      <pubDate>Thu, 14 Dec 2023 15:13:42 GMT</pubDate>
    </item>
    <item>
      <title>rpact包中的临界值是如何计算的？</title>
      <link>https://stats.stackexchange.com/questions/634914/how-is-the-critical-value-calculated-in-rpact-package</link>
      <description><![CDATA[R 代码输出的临界值（治疗效果量表）为 0.127：
&lt;前&gt;&lt;代码&gt;要求(ract)
getPowerRates(组=1，双面=1，alpha=0.025，thetaH0=0.075，pi1=0.2，maxNumberOfSubjects=100)

临界值是如何计算的？]]></description>
      <guid>https://stats.stackexchange.com/questions/634914/how-is-the-critical-value-calculated-in-rpact-package</guid>
      <pubDate>Thu, 14 Dec 2023 14:39:30 GMT</pubDate>
    </item>
    <item>
      <title>单独或一大多元回归</title>
      <link>https://stats.stackexchange.com/questions/634912/separate-or-one-large-multiple-regressions</link>
      <description><![CDATA[我正在调查 3 份问卷（SPQ、CAPS、PDI）的分数与实验“条件”对表现的影响（正确/不正确）之间的关系。我在 lme4 中运行了以下逻辑混合效应模型（为了便于阅读，此处删除了随机效应）：

正确 ~ PE_Condition*spq

正确 ~ PE_Condition*(spq+caps+pdi)

正确 ~ PE_Condition*(spq+caps+pdi)


然后我运行了带有额外协变量的模型 3，但这并没有收敛。有一些证据表明预测变量之间存在多重共线性，这已通过将所有预测变量居中来解决。
目前，SPQ 变量是调查问卷的汇总分数。然而，该调查问卷可以有不同的解释，以生成 3 个单独的子量表分数。我想研究这 3 个分量表。
问题：我不确定哪种方法最适合执行此操作：

单独运行
a)正确 ~ PE_Condition*(spq1+caps+pdi)
b)正确~PE_Condition*(spq2+caps+pdi)
c)正确~PE_Condition*(spq3+caps+pdi)

正确 ~ PE_Condition*(spq1+spq2+spq3+caps+pdi)

]]></description>
      <guid>https://stats.stackexchange.com/questions/634912/separate-or-one-large-multiple-regressions</guid>
      <pubDate>Thu, 14 Dec 2023 14:36:00 GMT</pubDate>
    </item>
    <item>
      <title>取得成功的迭代次数分布</title>
      <link>https://stats.stackexchange.com/questions/634911/distribution-of-the-number-of-iterations-to-achieve-success</link>
      <description><![CDATA[设 $Z=X+jY$ （$j$ 是虚数单位），其中$X\sim\mathcal{N}(\mu,1)$ 和 $Y\sim\mathcal{N} (0,1)$.
我正在运行一个算法，在每次迭代时 $k$ 对复数进行采样 $z_k$ 紧随 $Z$ 并计算统计数据：
\begin{方程}
\xi = k\cdot \dfrac{\left|\bar{z}\right|^2}{s^2}
\end{方程}
与 $\bar{z}=\dfrac{1}{k}\sum_{i=1}^k z_i$ 和 $s^2 = \dfrac{1}{k-1}\sum_{i=1}^k \left|z_i-\bar{z}\right|^2$&lt; /p&gt;
我知道 $\xi\sim F&#39;_{2,2(k-1)}(\lambda)$ 是一个非中心 $F$ 分布，分子自由度为 $2$， $2(k-1)$ 分母自由度和与 $\lambda$ &quot;&gt;$\mu$。
当原假设 $\mu=0$ 被固定的预定义 p 值拒绝时，算法停止（获得成功）$\alpha$。
对于给定的 $\mu$ 和 $\alpha$，算法停止所需的迭代次数$k$？
到目前为止，我已经得到了一个粗略的近似值，考虑到如果算法在第 k 次迭代中获得成功，那么如果我进行第 (k+1) 次迭代，它肯定会继续获得成功，即对于大型 $\mu$ 来说确实如此，但对于较小的则不然。考虑到这一点，我发现了以下成功迭代次数的累积分布的近似值：
\begin{方程}
CDF(k) = 1-g_k(h_k^{-1}(1-\alpha))
\end{方程}
其中 $g_k$ 是 $F&#39;_{2,2(k-1)} 的累积分布(\lambda)$ 和 $h_k$ 是 $F_{2,2(k -1)}$（集中式 F 分布）。
我认为如果我发现 $P(\xi\geq\xi_{thresh}\ \text{in iteration}\ k\ |\ \xi&lt; \xi_{thresh}\ \text{对于每次迭代}\ i，其中 $\xi_{thresh}$ 是统计值这给出了所需的 p 值，但我不知道如何计算它。]]></description>
      <guid>https://stats.stackexchange.com/questions/634911/distribution-of-the-number-of-iterations-to-achieve-success</guid>
      <pubDate>Thu, 14 Dec 2023 14:34:09 GMT</pubDate>
    </item>
    <item>
      <title>矩阵的导数</title>
      <link>https://stats.stackexchange.com/questions/634910/derivatives-of-matrices</link>
      <description><![CDATA[考虑矩阵正态分布的多重响应数据$Y_{n\times m}\sim\text{Normal}(\mathbf{M},\mathbf{U}, \mathbf{V})$，其中 $\mathbf{U}=\mathbf{I}_n$ 是行与  是跨列的方差（假设对称且正定）。） $\mathbf{Y}$ 也可以表示为 $\mathbf{y}=\text{vec}(\ mathbf{Y}) \sim \text{正常}(\mathbf{m}=\text{vec}(\mathbf{M}),\mathbf{I}_n\otimes\mathbf{V})$ 使得相应的对数似然为
$$ f(\mathbf{y}|\mathbf{V},\mathbf{m}) = -\dfrac{nm}{2}\log(2\pi)- \dfrac{1}{2}\log|\mathbf{I}_n\otimes\mathbf{V}|-\dfrac{1}{2}(\mathbf{y}-\mathbf{m})^{\素数}(\mathbf{I}_n\otimes\mathbf{V})^{-1}(\mathbf{y}-\mathbf{m}).$$
假设参数化$\mathbf{V}=\mathbf{LDL}^{\prime}$，其中 $\mathbf{L}$ 是一个对角线上有 1 的下三角矩阵，而 $\mathbf{D}$ 是一个严格对角矩阵正元素，在最简单的情况下 $m=2$ 我们有
$$\mathbf{V} = \left[\begin{array}{cc}V_{11} &amp; V_{12}\\
                                V_{12} &amp; V_{22}
\end{数组}\right]=
\left[\begin{array}{cc}1 &amp; 0\\
                                L_{12} &amp; 1
\end{array}\right]\left[\begin{array}{cc}D_{11} &amp; 0\\
                                0 &amp; D_{22}
\end{array}\right]\left[\begin{array}{cc}1 &amp; L_{12}\\
                                0 &amp; 1
\end{array}\right].$$
我想估计 $\mathbf{V}$ （即 $L_{12}$， $D_{11}$ 和 $D_{22}$）使用变分贝叶斯方法，其潜在的可以使用先验的选择
\begin{方程}
L_{12}\sim \text{正常}(0, c),\\
log(D_{ii})\sim\text{正态}(0,b),\;i=1.2
\end{方程}
带有 $c$ 和 $b$ 常量。对于像梯度下降这样的方法，我需要对数后验的梯度
\begin{方程}
f(L_{12}, D_{11}, D_{22}|\mathbf{y}) = -\dfrac{nm}{2}\log(2\pi)-\dfrac{1}{2}\ log|\mathbf{I}_n\otimes\mathbf{LDL}^{\prime}|-\dfrac{1}{2}(\mathbf{y}-\mathbf{m})^{\prime}(\ mathbf{I}_n\otimes\mathbf{LDL}^{\prime})^{-1}(\mathbf{y}-\mathbf{m}) \\
-\dfrac{1}{2}\log(2\pi c) -\dfrac{L_{12}^2}{2c} -\log(2\pi b)-\sum_{i=1}^2 \dfrac{D_{ii}^2}{2b}
\end{方程}
关于 $L_{12}$、$D_{11}$ 和 $D_{22}$。虽然我熟悉链式法则和恒等式的使用 $\dfrac{\partial\log|\mathbf{X}|}{\partial\mathbf{X}}= 2\mathbf{X}^{-1}-\text{diag}(\mathbf{X})$ 和 $\dfrac{\partial\mathbf{X }^{-1}}{\partial\mathbf{X}}=-\mathbf{X}^{-1}\dfrac{\partial\mathbf{X}}{\partial\mathbf{X}}\mathbf {X}^{-1}$，我在计算 LDL 参数化和克罗内克乘积时遇到困难。我希望获得一些有关如何明确计算它们的参考或指导。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/634910/derivatives-of-matrices</guid>
      <pubDate>Thu, 14 Dec 2023 14:23:43 GMT</pubDate>
    </item>
    <item>
      <title>如何解释使用子集数据构建的模型中的非显着性？</title>
      <link>https://stats.stackexchange.com/questions/634905/how-can-i-interpret-non-significance-in-models-built-with-subsetted-data</link>
      <description><![CDATA[我正在进行修订，并且要求我分别针对男性和女性重新运行我的模型。当我这样做时，我在女性的一些测试中失去了统计显着性，但在男性中却没有，但我如何确定这是由于功效较低还是由于效应大小确实不显着？我以为我可以运行事后功耗分析，但似乎没有提供比我已经完成的测试更多的信息（https://stat.uiowa.edu/sites/stat.uiowa.edu/files/techrep/tr378.pdf），所以我不知道该去哪里。对于所有疾病级别，队列中的男性和女性人数都不同。特别是，对照组中的女性较少，但大多数疾病组中的女性较多，我不确定统计功效会受到怎样的影响。 
这是我运行的完整线性混合模型的示例：
lmer(y ~ 疾病.状态 + 性别 + (1 | id), dt)

在新模型中，我按性别对数据进行子集化，并将其作为固定效应丢弃
lmer(y ~疾病.state + (1 | id), dt[性别==“男性”])
lmer(y ~ 疾病.状态 + (1 | id), dt[性别 == “女性”])

摘自固定效应表，注意三个模型之间的疾病状态IJ 和 KL 的差异。
完整模型
                    估计标准。误差df t值Pr(&gt;|t|)
(截距) 1.727e+00 6.836e-03 5.281e+03 252.592＜ 2e-16 ***
疾病.状态AB -5.219e-02 7.495e-03 4.193e+03 -6.963 3.85e-12 ***
疾病.状态CD -4.389e-02 8.012e-03 3.867e+03 -5.478 4.58e-08 ***
疾病状态EF -7.440e-03 9.951e-03 2.928e+03 -0.748 0.454733
疾病状态GH -4.768e-03 9.950e-03 2.772e+03 -0.479 0.631822
疾病状态IJ -2.365e-02 8.991e-03 3.217e+03 -2.631 0.008553 **
疾病状态KL -2.743e-02 7.820e-03 3.956e+03 -3.507 0.000458 ***
疾病状态MN -2.407e-02 1.890e-02 2.309e+03 -1.273 0.203073


女性亚群
                     估计标准。误差df t值Pr(&gt;|t|)
(截距) 1.715e+00 1.036e-02 3.778e+03 165.575＜ 2e-16 ***
疾病.状态AB -3.119e-02 1.149e-02 2.833e+03 -2.714 0.00669 **
疾病.状态CD -5.219e-02 1.246e-02 2.490e+03 -4.190 2.88e-05 ***
疾病状态EF 4.034e-03 1.677e-02 1.710e+03 0.241 0.80995
疾病状态GH 5.971e-03 1.446e-02 1.834e+03 0.413 0.67974
疾病状态IJ -1.061e-02 1.268e-02 2.334e+03 -0.837 0.40263
疾病状态KL -1.214e-02 1.150e-02 2.853e+03 -1.056 0.29126
疾病状态MN -1.036e-02 2.138e-02 1.545e+03 -0.485 0.62784

男性亚群
固定效果：
                     估计标准。误差df t值Pr(&gt;|t|)
(截距) 1.763e+00 8.168e-03 2.422e+03 215.803＜ 2e-16 ***
疾病状态AB -7.123e-02 1.009e-02 1.531e+03 -7.059 2.53e-12 ***
疾病.状态CD -3.409e-02 1.056e-02 1.484e+03 -3.228 0.001272 **
疾病状态EF -1.437e-02 1.249e-02 1.205e+03 -1.150 0.250397
疾病状态GH -1.061e-02 1.405e-02 1.057e+03 -0.756 0.450089
疾病状态IJ -3.359e-02 1.391e-02 1.101e+03 -2.414 0.015937 *
疾病状态KL -4.284e-02 1.152e-02 1.321e+03 -3.719 0.000208 ***
疾病状态MN -4.120e-02 4.776e-02 7.962e+02 -0.863 0.388624

]]></description>
      <guid>https://stats.stackexchange.com/questions/634905/how-can-i-interpret-non-significance-in-models-built-with-subsetted-data</guid>
      <pubDate>Thu, 14 Dec 2023 13:47:48 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用单层感知器和 sigmoid 函数来预测不可分类的标签？ （不使用任何感知器库）</title>
      <link>https://stats.stackexchange.com/questions/634902/is-it-possible-to-predict-non-classifiable-label-using-single-layer-perceptron-a</link>
      <description><![CDATA[想象一下预测 BMI 指数（如 1、2、3、4、5）并以体重和身高作为输入。我知道用其他方法可以轻松完成。另外我必须使用 sigmoid 函数，而且我对此很陌生。我似乎找不到这个问题的答案。
据我所知，到目前为止，感知器只是线性可分的，并且 sigmoid 函数给出的值在 0 和 1 之间。我不知道如何对索引值 1,2,3,4,5 进行分类，它们是BMI指数。

没有感知器或除 numpy 和 pandas 之外的任何库
仅使用 sigmoid 函数。

导入 pandas 作为 pd
将 numpy 导入为 np


df = pd.read_csv(&#39;bmi.csv&#39;)


X = df[[&#39;身高&#39;, &#39;体重&#39;]].values
y = df[&#39;Index&#39;].values / 5.0 # 标准化目标

#
X = (X - np.mean(X, 轴=0)) / np.std(X, 轴=0)

X = np.c_[X, np.ones(X.shape[0])]


np.随机.种子(42)
权重 = np.random.uniform(低=-0.5, 高=0.5, 大小=X.shape[1])

学习率 = 0.1

迭代次数 = 10000

对于 _ 在范围内（num_iterations）：
    对于范围内的 i(X.shape[0])：
        # 前向传递
        Weighted_sum = np.dot(X[i], 权重)
        输出 = 加权和
        错误 = y[i] - 输出

        权重 += 学习率 * 误差 * X[i]

test_input = np.array([174, 96])
test_input = (test_input - np.mean(X[:, :2], axis=0)) / np.std(X[:, :2], axis=0)
test_input = np.append(test_input, 1)

Predicted_output = np.dot(test_input, 权重)
预测体重 = 预测输出 * 5.0

print(“预测体重指数：”,predicted_bmi)

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/634902/is-it-possible-to-predict-non-classifiable-label-using-single-layer-perceptron-a</guid>
      <pubDate>Thu, 14 Dec 2023 13:19:33 GMT</pubDate>
    </item>
    </channel>
</rss>