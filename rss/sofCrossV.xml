<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 01 Nov 2024 01:21:45 GMT</lastBuildDate>
    <item>
      <title>$R^2$ 与相互信息之间的联系</title>
      <link>https://stats.stackexchange.com/questions/656573/connection-between-r2-and-mutual-information</link>
      <description><![CDATA[将 MI 解释为“通过添加一些信息消除的不确定性量”，我希望与 $R^2$ 有某种联系，它是“通过添加一些信息解释的方差量”。
特别是，$I(X,Y) = H(Y)-H(Y|X)$，其表述不当，即“您对 $Y$ 一开始有多不确定” - “在了解 $X$ 之后，您对 $Y$ 有多不确定”
另一方面，$R^2 = 1-\frac{\sum (y_i - f(x_i))^2}{\sum (y_i - \bar{y})^2}$，对我来说，这可能是错误的，它有点假设 $p(Y|X) \sim N(0, \sigma_1^2)$ 其中 $\sigma_1^2 = N^{-1}\sum (y_i - f(x_i))^2$ 和 $p(Y)\sim N(0, \sigma_2^2)$ 其中 $\sigma_2^2 = N^{-1}\sum (y_i - \bar{y})^2$... 这给我们留下了 $R^2 = 1-Var[p(y|x)]/Var[p(y)]$
现在，如果我们定义 $\hat{R^2} = \frac{Var[p(y)]}{Var[p(y|x)]} \propto R^2$（以非线性方式成比例），我会说它看起来像这样：
$$
I(X,Y) \stackrel{?}{=} \alpha\ln \hat{R^2} = \alpha(\ln(Var[p(y)]) -\ln(Var[p(y|x)])),\,\, \text{for some }\alpha \in \mathbb{R}^+
$$
事实上，高斯分布的熵是 $\ln c\sigma^2$
换句话说，如果我们假设 $p(y)$ 和 $p(y|x)$ 是，那么 $R^2$（或者至少是其虚构的兄弟 $\hat{R^2}$）和相互信息之间似乎确实存在联系高斯
我是不是做错了什么/说了什么胡编乱造的话？]]></description>
      <guid>https://stats.stackexchange.com/questions/656573/connection-between-r2-and-mutual-information</guid>
      <pubDate>Fri, 01 Nov 2024 01:00:27 GMT</pubDate>
    </item>
    <item>
      <title>通过 R 中 udpipe 包中的 udpipe_annotate 生成的句法网络解释</title>
      <link>https://stats.stackexchange.com/questions/656571/interpretation-of-syntactic-network-generated-through-udpipe-annotate-from-udpip</link>
      <description><![CDATA[我正在尝试使用 udpipe 在 R 中对语音数据进行句法网络分析。
以下是存储在 ordered.txt 文件中的示例数据。
你叫什么名字？
我叫什么名字？
我叫 Neeraj。

以下是我的代码片段：
# 加载库
library(udpipe)
library(igraph)
library(ggraph)

# 加载转录本（假设您已经将文本读入变量）
transcript &lt;- readLines(&quot;ordered.txt&quot;)

# 预处理文本：清理和标记（您可以根据需要修改清理）
transcript_clean &lt;- gsub(&quot;(unintelligible|\\.|\\?|,|!|:)&quot;, &quot;&quot;, transcript) # 删除标点符号和难以理解的标记

# 加载预先训练的英语模型进行句法分析
ud_model &lt;- udpipe_download_model(language = &quot;english&quot;)
udpipe_model &lt;- udpipe_load_model(ud_model$file_model)

# 执行句法解析
parsed_transcript &lt;- udpipe_annotate(udpipe_model, x = transcript_clean)
parsed_df &lt;- as.data.frame(parsed_transcript)

# 检查句法解析结果
head(parsed_df)

# 使用 head 依赖关系创建句法网络
edges &lt;- parsed_df[!is.na(parsed_df$head_token_id), c(&quot;token&quot;, &quot;head_token_id&quot;, &quot;dep_rel&quot;)]
colnames(edges) &lt;- c(&quot;from&quot;, &quot;to&quot;, &quot;relation&quot;)

# 构建图表
syntactic_graph &lt;- graph_from_data_frame(edges, focused = TRUE)

# 可视化句法网络
ggraph(syntactic_graph, layout = &quot;fr&quot;) +
geom_edge_link(aes(label = relation), arrow = arrow(length = unit(4, &#39;mm&#39;))) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_minimal()

此代码生成如下所示的网络。

在此代码中，使用 parsed_df 创建边，具体使用列token、head_token_id 和 dep_rel。但是，我无法正确解释网络。在右下角，节点“whatandneeraj连接到名为 0（表示根）的节点，其中 head_token_id 为 0，因为这两个词在语法上不依赖于任何其他词。此外，udpipe_annotate` 对文本进行词形还原，结果派生词被转换为其基本形式，例如，is 和 was 都转换为其基本形式“be”。但是，在网络中，它们都是单独的节点。我该如何解决这个问题？
此外，在左下角，我看到 My 连接到标记为 2 的节点，而我原本期望“my”连接到单词节点“name”如下面的parsed_df的输出截图所示。
]]></description>
      <guid>https://stats.stackexchange.com/questions/656571/interpretation-of-syntactic-network-generated-through-udpipe-annotate-from-udpip</guid>
      <pubDate>Thu, 31 Oct 2024 22:59:25 GMT</pubDate>
    </item>
    <item>
      <title>互相关 SD</title>
      <link>https://stats.stackexchange.com/questions/656570/cross-correlation-sd</link>
      <description><![CDATA[是否有已知的最佳实践或数学上定义良好的方法来计算互相关的连续 SD？或者您只是在每个采样点计算 SD？我很好奇，因为出于重要性的目的，例如当信号变得明显不同或不再明显不同时，您需要应用多个测试校正，我只是想知道这在连续时间内如何发挥作用？
这是在 numpy 中绘制它的模拟：
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import relate

# 生成用于可视化的合成数据
np.random.seed(0)
signal_1 = np.sin(np.linspace(0, 10, 1000)) + 0.1 * np.random.normal(size=1000)
signal_2 = np.sin(np.linspace(0, 10, 1000) + np.pi / 4) + 0.1 * np.random.normal(size=1000)

# 计算互相关
cross_corr = relate(signal_1, signal_2, mode=&#39;full&#39;)
lags = np.arange(-len(signal_1) + 1, len(signal_2))

# 计算 1000 个 bootstrap 样本的标准差
bootstrap_samples = 1000
sample_sd = np.zeros(len(cross_corr))

for i in range(bootstrap_samples):
# 为 bootstrap 生成随机样本
sampled_signal_1 = signal_1 + np.random.normal(scale=0.1, size=len(signal_1))
sampled_signal_2 = signal_2 + np.random.normal(scale=0.1, size=len(signal_2))
sampled_corr =相关（sampled_signal_1，sampled_signal_2，mode=&#39;full&#39;）
sample_sd += (sampled_corr - cross_corr) ** 2

sample_sd = np.sqrt(sample_sd / bootstrap_samples)

# 绘制带有 SD 的互相关
plt.figure(figsize=(10, 6))
plt.plot(lags, cross_corr, label=&#39;Cross-correlation&#39;)
plt.fill_between(lags, cross_corr - sample_sd, cross_corr + sample_sd, color=&#39;gray&#39;, alpha=0.3, label=&#39;SD over 1000 samples&#39;)
plt.xlabel(&#39;Lags&#39;)
plt.ylabel(&#39;Cross-correlation&#39;)
plt.title(&#39;带有标准差的互相关偏差&#39;)
plt.legend()
plt.grid()
plt.show()

请注意，另一个 slack 上发布了一个关于此问题的问题，但从未得到回答，而且写得很糟糕：https://stackoverflow.com/questions/78669859/how-to-calculate-the-confidence-intervals-for-a-time-lagged-cross-correlation]]></description>
      <guid>https://stats.stackexchange.com/questions/656570/cross-correlation-sd</guid>
      <pubDate>Thu, 31 Oct 2024 22:25:00 GMT</pubDate>
    </item>
    <item>
      <title>检测峰值是否及时出现</title>
      <link>https://stats.stackexchange.com/questions/656569/test-for-presence-of-peak-in-time</link>
      <description><![CDATA[我有许多基因的 RNA-Seq 计数数据，这些数据通常用负二项式建模，并随时间测量。我想找出哪些基因具有“峰值”模式。
处理此类数据的方法是具有负二项式家族的 GAM。但是，它捕获了随时间变化的不同基因模式。例如，这里我对 gene_2 感兴趣，它在特定时间点附近达到峰值，但我对 gene_1 不感兴趣：尽管它随时间变化，但它不是峰值模式。两者在 GAM 拟合中都具有显著的 p 值。

当然，在许多情况下，我有数千个基因需要测试，因此有几万个测试，其中大约三分之一我预计是显著的。我不知道先验脉冲的确切形状，有时可能更宽或更窄。
问题：我如何测试具有这种“脉冲”形状的基因？零形状可以是随时间恒定的基因，也可以是变化但不出现峰值的基因（如 gene_1）。
想法：
我首先想到的是调整 mgcv::gam 中使用的样条基础进行拟合，但找不到合适的方法，也找不到形状先验的平滑器。
我还考虑过使用 GLM 来拟合二次和三次多项式并比较它们的 AIC（即我们是否“需要”三次多项式），但在这两种情况下，AIC 都会随着三次多项式而降低，我不确定有没有更好的方法来进行这种比较。
也许另一种方法可能是某种形式的拟合优度，但我不确定如何进行。计算到模拟的“峰值”的 Wasserstein 距离形状？
最后一个想法可能是对拟合的曲线进行聚类并识别正确的聚类（例如使用 {funHDDC），我还没有探索这个想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/656569/test-for-presence-of-peak-in-time</guid>
      <pubDate>Thu, 31 Oct 2024 22:16:32 GMT</pubDate>
    </item>
    <item>
      <title>保留或归纳包含愿意或不愿意回答的数据的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/656568/what-would-be-the-best-way-to-retain-or-impute-data-containing-willing-or-not-wi</link>
      <description><![CDATA[我想在调查中填补缺失数据。
在我的数据集中，参与者可以选择不回答某些个人问题（例如年龄、家庭背景），从而导致数据有意缺失和无意缺失。鉴于这种结构，建议采用哪些填补策略来确保数据完整性并尽量减少偏差？
我最初的方法是使用 Little 的 MCAR 测试来对数值进行测试。如果数据被确认为 MCAR，单一填补方法 EM（期望最大化）填补可能会有效，因为它们会引入最小的偏差。如果测试表明数据为非 MCAR，我们可以假设 MAR，根据我们对数据的假设，MNAR 的可能性较小，从而使 EM 填补仍然可行。
这种方法也适用于分类响应，尽管数据的结构至关重要，因为有些值是故意缺失的。鉴于此，首先根据参与者是否同意分享信息对数据进行细分，然后在这些子组内应用归因分析是否合理？
]]></description>
      <guid>https://stats.stackexchange.com/questions/656568/what-would-be-the-best-way-to-retain-or-impute-data-containing-willing-or-not-wi</guid>
      <pubDate>Thu, 31 Oct 2024 22:10:07 GMT</pubDate>
    </item>
    <item>
      <title>如何找到 Beta_1 帽子和 Beta_3 帽子之间相关性的估计值</title>
      <link>https://stats.stackexchange.com/questions/656567/how-to-find-the-estimate-of-the-correlation-between-beta-1-hat-and-beta-3-hat</link>
      <description><![CDATA[我正在研究多元线性回归，并致力于寻找 Beta_1 帽子和 Beta_3 帽子之间相关性的估计值。
给定回归模型 y = B_0 + Beta_1x_1 + Beta_2x_2 + Beta_3*x_3 + 15 个案例的误差。我们有 MSE s^2 = 3。我们有
(X^T X)^(-1) =
[0.5 0.3 0.2 0.6]
[0.3 6.0 0.5 0.4]
[0.2 0.5 0.2 0.7]
[0.6 0.4 0.7 3.0]
我正在寻找 Corr(Beta_1 帽、Beta_3 帽) 的估计值。请帮忙，因为我不知道该使用哪个公式。]]></description>
      <guid>https://stats.stackexchange.com/questions/656567/how-to-find-the-estimate-of-the-correlation-between-beta-1-hat-and-beta-3-hat</guid>
      <pubDate>Thu, 31 Oct 2024 21:59:15 GMT</pubDate>
    </item>
    <item>
      <title>根据实际值和预测值得出倍数</title>
      <link>https://stats.stackexchange.com/questions/656566/deriving-a-multiple-based-on-actuals-and-forecast-values</link>
      <description><![CDATA[就上下文而言，我们正在使用 DeepAR 模型进行需求规划预测。目前的预测往往低估了实际需求。有人建议我们使用更高的分位数来高估需求。尽管如此，我认为我们不应该向另一个方向走得太远，所以我的评估是，我们应该让预测超过实际需求，但前提是它不低于实际需求的几倍。如果这清楚的话请告诉我。
现在，我需要以某种方式使用数字得出这个倍数。作为第一步，我计算了预测值和实际值之间的绝对差，然后我可以得到一些指标，如平均值、中位数绝对偏差和标准偏差，它们分别是
平均值：10661.739321234914
中位数绝对偏差：181.05746332806666
标准偏差：391088.08675914136

我有点困惑，不知道该如何制定一个倍数。我原本打算只使用 1.5 或 2 作为倍数，但我需要量化我的推理，否则它只是凭空而来。任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/656566/deriving-a-multiple-based-on-actuals-and-forecast-values</guid>
      <pubDate>Thu, 31 Oct 2024 21:57:18 GMT</pubDate>
    </item>
    <item>
      <title>如何处理非常罕见的检测事件的数据？</title>
      <link>https://stats.stackexchange.com/questions/656565/how-to-analyze-data-with-very-rare-detection-events</link>
      <description><![CDATA[我正在分析几个样本中按大小排列的颗粒。我需要确定两组样本（每组 n=50）之间的平均颗粒数是否存在统计差异。
数据是通过测量落入特定尺寸箱中的颗粒来收集的。例如，&gt;5um、&gt;15um、&gt;30um 等。对于最大尺寸箱（&gt;500um），很少检测到颗粒。在 100 个样本中，大约有 20 个检测到颗粒；其余的没有。对于我的特定样本，每个样本检测到的 &gt;500um 颗粒从未超过一个。这导致数据不符合 Anderson-Darling 正态分布。对于所有其他颗粒尺寸，分布为正态分布。
我希望能够对每个颗粒尺寸箱中的所有样本进行方差分析，以确定平均值是否显著不同。当然，如果数据是非正态的，这种方法就不适用了。
是否可以假设，不管样本数据如何，较大粒径粒子群的实际分布也像较小粒径粒子一样遵循正态分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/656565/how-to-analyze-data-with-very-rare-detection-events</guid>
      <pubDate>Thu, 31 Oct 2024 21:49:40 GMT</pubDate>
    </item>
    <item>
      <title>Metropolis-Hastings 从以子集约束为条件的分布中抽样</title>
      <link>https://stats.stackexchange.com/questions/656564/metropolis-hastings-to-sample-from-a-distribution-conditioned-on-a-subset-constr</link>
      <description><![CDATA[我有一个分布$p(\mathbf{y}) = \prod_{i=1}^n p(y_i|y_{&lt;i})$。我对从条件分布中抽取样本很感兴趣
$$
p(\mathbf{y}| \mathcal{C}_{p}) \propto p(\mathbf{y}, \mathcal{C}_{p})\{\mathbf{y} \in \mathcal{C}_{p}\}
$$
其中 $\mathcal{C}_{p}$ 是根据某些标准对分布 $p(\mathbf{y})$ 进行的限制。例如，$\mathcal{C}_{p}$ 可以是 $p(\mathbf{y})$ 到 100 个最可能实现的限制。既然我们无法提前知道子集 $\mathcal{C}_{p}$，那么如何为该目标分布设计马尔可夫链呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/656564/metropolis-hastings-to-sample-from-a-distribution-conditioned-on-a-subset-constr</guid>
      <pubDate>Thu, 31 Oct 2024 21:11:20 GMT</pubDate>
    </item>
    <item>
      <title>生存树中多路分裂的对数秩检验统计量</title>
      <link>https://stats.stackexchange.com/questions/656563/log-rank-test-statistic-for-multi-way-splitting-in-survival-trees</link>
      <description><![CDATA[在生存树中，对数秩检验统计量最常用于分割选择。这涉及选择产生最大对数秩检验统计量的二元分割。
这假设具有相等组大小的对数秩检验统计量值与具有不等组大小的对数秩检验统计量值相当，因为根据当前候选分割点的位置，生成的子节点的大小会有所不同。
现在我感兴趣的是执行多路分割，其中每个节点被分割成两个以上的子节点。在这里，我想使用两个以上组的对数秩检验的检验统计量来选择多路分割的分割点，以便子节点在生存方面差异最大。
但我不确定这种方法是否有效。这是因为我不知道不同相对组大小（总观察次数相同）的对数秩检验统计量的可比性是否也适用于两个以上组的对数秩检验。然而，后者对于选择多路分割是必要的，而不偏向于强平衡或强不平衡的划分。
我很感激对此的任何猜测或见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/656563/log-rank-test-statistic-for-multi-way-splitting-in-survival-trees</guid>
      <pubDate>Thu, 31 Oct 2024 20:27:26 GMT</pubDate>
    </item>
    <item>
      <title>回归与显性分析</title>
      <link>https://stats.stackexchange.com/questions/656561/regression-ad-dominance-analysis</link>
      <description><![CDATA[我想知道是否有人可以通过这个例子帮助验证我的主导分析方法：
我经营一家工厂，生产小部件，我的流程非常手动（自动化程度很低）。我们的生产基于客户的订单，每天都在变化。我的关键指标之一是每小时吞吐量 (TPH)，即制造的小部件数量/工作小时数（包括直接/间接工人的总小时数）。我有一个生产力团队，他们不断改进流程，使其更有效率（流程杠杆）。我还知道数量（订单数量）是我的朋友，因为我的手动流程具有容量，当我的数量增加时，我不必雇用额外的经理、主管、管理员等（我获得了数量杠杆）。
因此，TPH = 小部件数量/总工作小时数
我想知道流程改进和数量对 TPH 的影响。首先，我对数据 (Y) TPH = f(xWidgets, xHours) 进行回归分析。正如预期的那样，这产生了 100% R-sq (Adj)，Widgets 和 Hours 都具有统计意义，并且 VIFS 较低。结果有点符合预期，因为 TPH 是 Widgets 和 Hours 的乘积 (TPH = # Widgets/Total Hours)。
然后我运行优势分析，结果返回 70% Widgets 和 30% Hours。因此，我将其理解为 R-Sq(adj) 中 70% 的方差来自 Widget Volume（Volume Leverage）的变化，而 R-Sq(adj) 中 30% 的方差来自 Hours（Process Leverage）。
我的方法有什么问题吗？我可以看出回归可能有问题，因为（TPH = 小部件数量/总工作小时数），但优势分析应该没问题。
对此有什么想法吗？非常感谢任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/656561/regression-ad-dominance-analysis</guid>
      <pubDate>Thu, 31 Oct 2024 19:42:01 GMT</pubDate>
    </item>
    <item>
      <title>系统分组码的校验符号是独立同分布的</title>
      <link>https://stats.stackexchange.com/questions/656560/the-check-symbols-of-a-systematic-block-code-are-independent-and-identically-dis</link>
      <description><![CDATA[以下假设是否正确：对于任何信息符号的 pmf，系统分组码的校验符号根据均匀 pmf 是 iid 的？
假设我们有一个系统分组码，它采用 4 个信息位（例如，0 或 1）并添加 2 个控制位。如果信息符号具有任意分布（例如，0 的概率为 70%，1 的概率为 30%），则添加到此代码的控制符号将独立且均匀地生成（例如，0 的概率为 50%，1 的概率为 50%）。]]></description>
      <guid>https://stats.stackexchange.com/questions/656560/the-check-symbols-of-a-systematic-block-code-are-independent-and-identically-dis</guid>
      <pubDate>Thu, 31 Oct 2024 19:40:39 GMT</pubDate>
    </item>
    <item>
      <title>有向无环图等价物</title>
      <link>https://stats.stackexchange.com/questions/656559/directed-acyclic-graphs-equivalents</link>
      <description><![CDATA[我试图理解等效 DAG 是如何创建的。
我指的是 Richard McElrteth 的《统计再思考（第二版）》一书。第 5 章有一个练习：

5H1. 在离婚示例中，假设 DAG 为：M → A → D。图中隐含的条件独立性是什么？数据是否与之一致？

隐含的条件独立性将是 D _||_ M | A。
Jake Thompson 对这些练习的解决方案指出，等效 DAG 是：

M -&gt; A -&gt; D，
M &lt;- A -&gt; D 和
M &lt;- A &lt;- D

我的问题 - 为什么 DAG M -&gt; A &lt;- D 不等同于原始 DAG M -&gt; A -&gt; D？我理解必须保留条件独立性 (D _||_ M | A)，但如果 M &lt;- A -&gt; D 被视为等价（其中 M 不以任何间接方式“连接”到 D），那么为什么 M -&gt; A &lt;- D 不等价？]]></description>
      <guid>https://stats.stackexchange.com/questions/656559/directed-acyclic-graphs-equivalents</guid>
      <pubDate>Thu, 31 Oct 2024 19:32:15 GMT</pubDate>
    </item>
    <item>
      <title>寻找参考资料/资源来帮助向同事解释为什么设计是伪复制的</title>
      <link>https://stats.stackexchange.com/questions/656558/looking-for-references-resources-to-help-explain-why-a-design-is-pseudoreplicate</link>
      <description><![CDATA[我和一位同事正在开展一个项目，该项目涉及对 15 个不同地点进行采样，我们在每个地点收集了 3 个重复样本（以捕捉空间变异性，而不是在精确位置进行重复测量）。每个地点都分为三组（A、B 或 C），我们感兴趣的是测试某些变量的平均值是否因地点而异 - 这是一种经典的单因素方差分析方法。设计不平衡（A 组和 B 组 n = 4 个地点，C 组 n = 7 个地点），但这不是问题所在。我提出了一个问题，即将每个重复视为独立并对 45 个单独样本进行方差分析是伪重复，我们不应该这样做。相反，我们应该在方差分析中使用每个地点内 3 个重复的平均值；因此，我们将有 15 个样本点根据上述样本大小分组。不幸的是，一些科学家仍然从未听说过伪重复，我的担忧被置之不理，对 45 个样本的全套进行了分析。在继续进行该项目之前，我想带回一些适当的材料来支持我的主张，并继续进行适当的分析。
是否有一些经典或广受欢迎的参考资料或资源提供了类似的例子，解释了为什么这是伪重复以及在这种情况下处理方差分析的适当方法？我发现了一些与医学研究更相关的内容，这很好，但我希望有更多实地生物学/生态学背景。
我也欢迎社区的任何解释和/或建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/656558/looking-for-references-resources-to-help-explain-why-a-design-is-pseudoreplicate</guid>
      <pubDate>Thu, 31 Oct 2024 18:48:45 GMT</pubDate>
    </item>
    <item>
      <title>群体敏感性的超几何近似及其非线性性质</title>
      <link>https://stats.stackexchange.com/questions/656545/hypergeometric-approximation-of-herd-sensitivity-and-its-non-linear-nature</link>
      <description><![CDATA[我最近一直在探索 Cannon 2001 年论文“感觉与敏感性”中描述的方程在群体敏感性方面的应用（我喜欢这个名字）。


我一直在寻找用两种不同的协议测试假设的群体的方法（每种协议都有不同的测试敏感性），然后希望将两种测试协议的结果结合起来以获得一种群体敏感性。我计算了两个群体敏感度，然后将它们并行组合。我试图理解的一个问题是，我认为我遗漏了一个非线性组件，它会导致群体敏感度的损失，而这超出了仅用测试敏感度差异来解释的范围。我进一步探索了这一点，计算了 300 只动物群测试 100 只动物的群体敏感度，然后计算了测试 50 只动物（具有相同的测试敏感度）的两个群体敏感度并将它们并行组合。因此，尽管测试了相同数量的动物（100 只）并且测试敏感度相同，但我得到的群体敏感度较低。考虑到群体敏感性曲线，我认为这是有道理的。

然而，我正在努力寻找一种方法来量化或估计这种群体敏感性的“损失”，因为了解由于采用不同的不太敏感的测试协议而导致群体敏感性下降的程度会很有用。任何建议或意见都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/656545/hypergeometric-approximation-of-herd-sensitivity-and-its-non-linear-nature</guid>
      <pubDate>Thu, 31 Oct 2024 14:57:33 GMT</pubDate>
    </item>
    </channel>
</rss>