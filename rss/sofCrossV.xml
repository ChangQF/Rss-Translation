<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 24 Dec 2024 15:16:41 GMT</lastBuildDate>
    <item>
      <title>为什么在半监督 VAE 模型中将目标 𝑦 y 用作编码器的输入？</title>
      <link>https://stats.stackexchange.com/questions/659156/why-is-the-target-y-used-as-an-input-to-the-encoder-in-a-semi-supervised-vae</link>
      <description><![CDATA[正如标题所述，我理解 Kingma 的原始论文中方程 (6-7) 的数学推导。但是，由于 𝑦 已在模型中用作分类器的目标，那么将 𝑦 用作编码器的输入的目的是什么？这会不会是多余的？似乎从编码器的输入中删除 𝑦 在实践中也是可行的。]]></description>
      <guid>https://stats.stackexchange.com/questions/659156/why-is-the-target-y-used-as-an-input-to-the-encoder-in-a-semi-supervised-vae</guid>
      <pubDate>Tue, 24 Dec 2024 13:53:10 GMT</pubDate>
    </item>
    <item>
      <title>在具有许多零值的数据中选择正确的相关方法</title>
      <link>https://stats.stackexchange.com/questions/659150/picking-the-right-correlation-method-in-data-that-has-many-zero-values</link>
      <description><![CDATA[我想计算我的数据中两个基因之间的相关性。到目前为止，我所做的是计算 Pearson 或 Spearman 相关性（我更依赖 Spearman，因为基因之间没有线性关系）。
但是 - 许多细胞对基因 1、基因 2 或两者的表达为零，这导致相关性不准确和偏差。
所以我有一些选择 -

我可以只保留表达两个基因的细胞（这将删除大量细胞），然后重新计算相关性。
我应该保留零，因为它是生物学的一部分
使用对零不太敏感的其他方法，例如余弦相似度？

例如，这里有一个图 - 每个点是一个细胞，X 轴是基因 1 的表达，Y 轴是基因 2 的表达：
]]></description>
      <guid>https://stats.stackexchange.com/questions/659150/picking-the-right-correlation-method-in-data-that-has-many-zero-values</guid>
      <pubDate>Tue, 24 Dec 2024 11:42:54 GMT</pubDate>
    </item>
    <item>
      <title>何时在图学习管道（PyTorch Geometric）中执行节点/边图特征提取？</title>
      <link>https://stats.stackexchange.com/questions/659149/when-to-perform-node-edge-graph-feature-extraction-in-graph-learning-pipeline-p</link>
      <description><![CDATA[我有一个 CSV 文件，可以将其转换为 PyG 图形数据对象，用于边缘分类任务。在此之前，我想到使用 NetworkX 库添加一些功能。
但是，由于创建图形后，我将把它拆分为 train/val/test，然后使用数据加载器，我不确定基于图形的预处理应该在拆分之前完成，还是在拆分之后（在创建数据加载器之前）完成，还是在数据加载器构造内部/之后完成。
如果答案是在数据加载器构造内部/之后，这是否意味着我必须为我想要添加的每个功能实现自定义转换，基本上将图形转换为 networkx 图，提取特征，然后将图形重新转换为 pyg？最好的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659149/when-to-perform-node-edge-graph-feature-extraction-in-graph-learning-pipeline-p</guid>
      <pubDate>Tue, 24 Dec 2024 11:37:31 GMT</pubDate>
    </item>
    <item>
      <title>如何为由另外两个类组成的类设计网络和损失函数？</title>
      <link>https://stats.stackexchange.com/questions/659148/how-to-design-a-network-and-loss-function-for-classes-composed-of-two-other-cla</link>
      <description><![CDATA[给定一个包含三个类别的图像数据集，A、B 和 C，其中 C 是 A 和 B 的组合，我们希望训练一个分类器来预测：

如果只有 A，则为 A
如果只有 B，则为 B
如果 A 和 B 都存在，则为 C。

我们如何设计最终的分类层以及损失函数？
我考虑过对 C 类进行阈值处理，即使使用可学习的阈值，但这会受到数据集中类别分布的严重影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/659148/how-to-design-a-network-and-loss-function-for-classes-composed-of-two-other-cla</guid>
      <pubDate>Tue, 24 Dec 2024 11:28:42 GMT</pubDate>
    </item>
    <item>
      <title>如何选择一个固定的 $x_{t-1}$ 值来可视化 MLE 之后的条件密度 $f(x_t \mid x_{t-1})$？</title>
      <link>https://stats.stackexchange.com/questions/659146/how-to-choose-a-fixed-value-of-x-t-1-for-visualizing-conditional-density-f</link>
      <description><![CDATA[假设我已经对某个数据集进行了最大似然估计，以找到某个条件密度函数 $f(x_t\mid x_{t-1})$ 的参数，其中 RHS 将取决于 $x_{t-1}$ 的某个值。
如果我要绘制数据的直方图并与 MLE 找到的密度叠加，我将如何选择要修复哪个 $x_{t-1}$ 值进行绘图？或者在这种情况下绘图时的便利性是否不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/659146/how-to-choose-a-fixed-value-of-x-t-1-for-visualizing-conditional-density-f</guid>
      <pubDate>Tue, 24 Dec 2024 10:05:01 GMT</pubDate>
    </item>
    <item>
      <title>可视化多种样品类型和杂质水平的 PCA 结果</title>
      <link>https://stats.stackexchange.com/questions/659145/visualizing-pca-results-with-multiple-sample-types-and-impurity-levels</link>
      <description><![CDATA[我正在对一个数据集执行主成分分析 (PCA)，该数据集包含四种材料 (a、b、c、d) 的样本，这些样本的杂质水平各不相同 (10%、20%、30% 和 40%)。此外，还有一个纯样本 (p)。
我打算使用 R 创建一个分数图，以根据这些样本的主要成分直观地显示这些样本的分离情况。我希望在图中有效地表示样本类型 (a、b、c、d、p) 和杂质水平 (10%、20%、30%、40%)。
我正在寻找有关如何在分数图中以最佳方式直观地编码此双重信息 (样本类型和杂质水平) 的建议。是否有既定的最佳实践或建议用于在 PCA 得分图中表示多个分类变量？
其他详细信息
• 数据有 17 列（a、b、c、d 及其级别以及纯样本）和 949 行。
任何见解或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659145/visualizing-pca-results-with-multiple-sample-types-and-impurity-levels</guid>
      <pubDate>Tue, 24 Dec 2024 09:54:49 GMT</pubDate>
    </item>
    <item>
      <title>训练损失波动很大，而验证损失没问题，可能是什么问题？</title>
      <link>https://stats.stackexchange.com/questions/659144/the-training-loss-fluctuates-a-lot-while-the-validation-loss-is-ok-what-could</link>
      <description><![CDATA[我正在训练一个神经网络 (CNN) 以完成回归任务（图像中的对象面积估计）。我的训练损失总是波动很大，而我的验证损失与训练损失相比还算可以。]]></description>
      <guid>https://stats.stackexchange.com/questions/659144/the-training-loss-fluctuates-a-lot-while-the-validation-loss-is-ok-what-could</guid>
      <pubDate>Tue, 24 Dec 2024 09:26:23 GMT</pubDate>
    </item>
    <item>
      <title>这是正确的吗？为我的回归模型设置一个基线变量[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659142/is-this-correct-set-a-baseline-variable-for-my-regression-model</link>
      <description><![CDATA[请帮帮我！我不确定如何为我的回归模型设置基线变量。我正在尝试使用以下变量来预测房屋的转售价值。：
分类变量
城镇 - 其中 26 个分为 5 个区域（防止过度拟合） - 5 个虚拟变量（东北、东部、中部、北部、西部）
flattype - 数组（[&#39;1 ROOM&#39;, &#39;2 ROOM&#39;, &#39;3 ROOM&#39;, &#39;4 ROOM&#39;, &#39;5 ROOM&#39;, &#39;EXECUTIVE&#39;, &#39;MULTI-GENERATION] - 6 个虚拟变量
连续变量
floor_area 平方米 - 最小 31 和最大 366.7
剩余租约 - 转换为月份 min_lease, max_lease - (495, 1173)
转售价格
我已为我的回归模型，我没有在模型中包含 north 和 flat_type_room_1 - 它会自动将 north 和 flat_type_room_1 设置为基线模型吗？：
# 定义因变量（转售价格）

Y = new_data_with_dummies[&#39;resale_price&#39;]

# 通过提取数值数据定义自变量

independent_columns = [

&#39;floor_area_sqm&#39;, &#39;remaining_lease_months&#39;,

&#39;region_West&#39;, &#39;region_East&#39;,

&#39;region_Central&#39;, &#39;region_Northeast&#39;,

&#39;flat_type_ROOM_2&#39;, &#39;flat_type_ROOM_3&#39;, &#39;flat_type_ROOM_4&#39;,

&#39;flat_type_ROOM_5&#39;, &#39;flat_type_EXECUTIVE&#39;, &#39;flat_type_MULTI-GENERATION&#39; #north 和flat_type_room_1 未包含在模型中

]

# 将独立变量提取到普通的 NumPy 数组中

X = np.column_stack([new_data_with_dummies[col] for col in independent_columns])

# 添加常数（截距）

X = sm.add_constant(X)

# 使用适当的变量名称拟合多元线性回归模型

linear_model = sm.OLS(Y, X)

result = linear_model.fit()

# 显示模型摘要

print(result.summary(xname=[&#39;const&#39;] + independent_columns))
]]></description>
      <guid>https://stats.stackexchange.com/questions/659142/is-this-correct-set-a-baseline-variable-for-my-regression-model</guid>
      <pubDate>Tue, 24 Dec 2024 04:51:21 GMT</pubDate>
    </item>
    <item>
      <title>如何开始使用 Python 中的项目反应理论[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659132/how-to-get-started-with-item-response-theory-in-python</link>
      <description><![CDATA[我有一个大型 CSV 文件，其中包含（String studentId、String questionId、bool isCorrect）。问题都是小学的基本数学知识，questionIds 指的是一组类似的问题。例如，我们有这样的 questionId

OPlusO（包含 2+3、5+4 等练习）
OPlusT（包含 2+10、20+4、30+7 等练习）
OPlusOWithCarry（7+8、5+9 等）
Times2（3x2、7x2 等）

一个学生可以对一个 questionId 有多个答案，我们假设所有学生练习都是在一周内完成的。 （我们有一年多的数据）
在第一阶段，我想确定问题 ID 的难度并评估学生的能力。
我认为 IRT 模型在这里很有用，所以我想开始使用它来获得一些实践经验。
但我不确定从哪里/如何开始。最好使用 Python，因为我习惯了，但其他（命令行）工具也可以。我在 Linux 上。
ChatGPT 和 Claude 都让我误以为几行代码就足够了，但都没有给出一个可行的示例。
提前谢谢，
Marc]]></description>
      <guid>https://stats.stackexchange.com/questions/659132/how-to-get-started-with-item-response-theory-in-python</guid>
      <pubDate>Mon, 23 Dec 2024 17:27:05 GMT</pubDate>
    </item>
    <item>
      <title>跨栏模型等同于零膨胀模型吗？</title>
      <link>https://stats.stackexchange.com/questions/659119/are-hurdle-models-equivalent-to-zero-inflated-models</link>
      <description><![CDATA[换句话说，障碍模型可以转换为零膨胀模型吗？
我正在查看障碍模型的维基百科页面。据我理解，障碍模型只是零概率，对于非零情况，分布严格为非零。
零膨胀模型是零概率，对于其他情况，分布包括零。
所以你可以采用零膨胀模型，将零概率分解为单一情况，并将其称为障碍模型，对吗？我遗漏了什么吗？
它们似乎都能够形成相同的总概率分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/659119/are-hurdle-models-equivalent-to-zero-inflated-models</guid>
      <pubDate>Mon, 23 Dec 2024 10:49:34 GMT</pubDate>
    </item>
    <item>
      <title>元分析中嵌套数据的模型简化</title>
      <link>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</link>
      <description><![CDATA[我正在对子组中不同程度的异质性进行荟萃分析。由于数据结构是嵌套的（效应大小嵌套在研究中），我通过添加研究的随机效应和研究内的效应大小来考虑这一点。轮廓似然图在其估计值处达到峰值。
比较具有不同程度异质性的模型和具有共同异质性估计值的模型的似然比检验是显著的。然而，在获得 $ \tau^2_\text{between} $ 和 $ \tau^2_\text{within} $ 的置信区间 (CI) 后，除了一个之外，$ \tau^2_\text{within} $ 的所有 CI 的下限均为零。一个显著的估计值仍然是适中的。
在这种情况下，将模型简化为仅在研究层面具有随机效应的两级模型是否合适，从而仅考虑研究之间的异质性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</guid>
      <pubDate>Sun, 22 Dec 2024 20:41:46 GMT</pubDate>
    </item>
    <item>
      <title>在评估 GLM 模型时，AIC 值或预测显著性的 p 值更重要吗？</title>
      <link>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</guid>
      <pubDate>Sat, 21 Dec 2024 15:14:21 GMT</pubDate>
    </item>
    <item>
      <title>使用麦当劳 Omega 作为非加权总和评分的可靠性度量是合理的</title>
      <link>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</link>
      <description><![CDATA[在最近的文献中，报告麦当劳欧米茄作为可靠性估计值显然比报告系数 alpha 更受青睐（例如 McNeish，2017）。一个经常给出的论点是，系数 alpha（或 Cronbach&#39;s alpha）假设（本质上）tau-euqivalent 测量模型，即因子载荷必须相等，而麦当劳欧米茄允许不同的载荷。由于对 omega 有多种看法，为了简单起见，我们只关注单维尺度上的总 omega，如 McNeish (2017) 所指定的那样：

（其中 $\lambda_i$ 是因子载荷，$\theta_{ii}$ 是第 i 项的误差/残差方差）
在文章中，McNeish 写道：

Omega (McDonald, 1970, 1999）是常用的复合信度测量方法，可用于多种软件程序。Omega 专为同类量表而设计，其中项目与被测构造的相关程度各不相同（即，在因子分析设置中，不会假设负载相等）。换句话说，不假设 tau 等价。当量表中的项目按单位加权以形成总量表分数但量表本身为同类时，复合信度是合适的（Bentler，2007；Geldhof 等人，2014）。单位加权量表意味着量表的总分是通过将各个项目的原始分数（或反向编码的原始分数，如果适用）相加来计算的：每个项目的权重相等。

我觉得这违反直觉：例如，假设 CFA 表明同类模型（自由载荷）比更严格的 tau 等效模型更适合样本数据，因此我们决定使用 omega 而不是系数 alpha。然而，后续分析将使用基于同等权重项目计算得出的总和/平均分数，即使我们刚刚在 CFA 中表明这种类型的测量模型不能很好地拟合我们的数据。
我的问题：
有人可以提供一些合理的解释，为什么对于由同等权重项目组成的分数报告麦当劳的 omega 是有意义的？

来源：
McNeish，D.（2017 年）。感谢系数 alpha，我们将从这里开始。心理方法，23(3)，412–433。https://doi.org/10.1037/met0000144]]></description>
      <guid>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</guid>
      <pubDate>Fri, 20 Dec 2024 12:24:36 GMT</pubDate>
    </item>
    <item>
      <title>防止时间序列数据拆分中的数据泄露</title>
      <link>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</link>
      <description><![CDATA[我正在研究机械系统的故障检测问题，目标是确定故障类型。我使用的数据集对于每种类型的故障（目标标签）都有三种大小，每种故障大小都有四种不同的工作条件，如下图所示。请注意，数据集中的每个样本都是时间序列，由于样本数量太少而且太长，因此需要将每个样本分成固定长度的块。现在的问题是如何将每个块分配给训练集或测试集，以确保公平和无偏见的评估。

在之前的研究中，常见的做法是将所有块随机分成训练集和测试集。

使用这种方法，神经网络模型通常在测试集上实现近乎完美的性能。然而，这种方法似乎存在根本缺陷，因为将近似平稳的信号分成块会导致来自同一信号的块高度相似，而相似的块可能最终出现在两个集合中，从而导致严重的数据泄漏。为了说明这种数据泄漏，我将 t-SNE 算法应用于这些块。

在此图中，每种颜色对应特定的故障类型和故障大小。请注意，来自同一样本的块紧密聚集在一起。以下是放大版的图：

我认为应该根据故障大小来拆分块。例如，故障大小为 1 和 2 的样本块应包含在训练集中，而故障大小为 3 的样本块应包含在测试集中。这可确保测试集中不存在来自训练信号的任何信息。

现在我想问：

我关于数据泄露的说法正确吗？如果正确，是否有其他方法可以更严格地证明数据泄露，例如使用相似性指标或其他可视化？
您如何看待提议的拆分方法？基于故障大小的拆分是否足以防止数据泄露？如果不是，您会推荐哪些替代拆分策略来确保公平评估？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</guid>
      <pubDate>Tue, 17 Dec 2024 15:38:37 GMT</pubDate>
    </item>
    <item>
      <title>基于相关性的特征消除的优化算法[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658075/optimized-algorithms-for-correlation-based-feature-elimination</link>
      <description><![CDATA[背景：我有一个包含近一百万行和 2000 列的大型数据框。我正在尝试使用变量之间的相关性进行特征消除。当然，问题在于，对于一​​组 n 个特征，我们需要 nC2 或 n*(n-1)/2 个组合之间的相关性，这本身就使其成为 O(n^2) 操作。
基础数据：全部为数值。
所以我想知道我们是否可以使用一些分而治之的策略来优化这一点，如下所示：

计算 20 个批次（每个批次 100 列）之间的相关性
消除高度相关的特征（阈值 &gt; 95%）
组合剩余的特征（大约 1000 个），再次分成 20 个批次
重复上述过程，直到达到固定的列阈值（我们可以一起处理，例如 200 个）
从中计算最后一次相关性并删除相关特征

我想知道如果此方法有效，或者是否有进一步优化的方法可用于此目的。我还想知道这是否适用于不同类型的相关性，如斯皮尔曼、肯德尔等。
假设：此方法做出了这个重要假设：

如果 f1 和 f2 的相关度 &gt;95%，f2 和 f3 的相关度也 &gt;95%，那么我们假设 f1 和 f3 的相关度也 &gt;95%。

我不确定这是否有具体的理论基础，并希望听听您对如何证明不同类型的相关性的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/658075/optimized-algorithms-for-correlation-based-feature-elimination</guid>
      <pubDate>Sat, 30 Nov 2024 19:29:22 GMT</pubDate>
    </item>
    </channel>
</rss>