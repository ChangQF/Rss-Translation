<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 28 Oct 2024 21:16:11 GMT</lastBuildDate>
    <item>
      <title>R 中的对数变换[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656432/logarithmic-transformation-in-r</link>
      <description><![CDATA[我想知道如何对我的数据进行对数转换。我的因变量是“花费”，我的预测变量是“收入”。但我陷入了这样一个境地：我发现我的数据存在异方差，现在我必须对其进行转换。]]></description>
      <guid>https://stats.stackexchange.com/questions/656432/logarithmic-transformation-in-r</guid>
      <pubDate>Mon, 28 Oct 2024 20:45:29 GMT</pubDate>
    </item>
    <item>
      <title>如果聚类内的样本大小不一致，如何正确计算方差估计值？</title>
      <link>https://stats.stackexchange.com/questions/656430/how-is-the-variance-estimate-calculated-correctly-if-there-are-unequal-sample-si</link>
      <description><![CDATA[我有一个聚类数据集。所有聚类的样本大小都不相等。我想计算聚类稳健方差估计，特别是考虑到聚类内样本大小的不相等。我尝试了一些方法，但不确定是否正确。由于每个聚类的样本数量不同，使用与聚类大小成比例的缩放因子 sqrt(ni/N) 或 (ni/N) 来调整它们对方差估计的贡献是否正确？ （注：其中 ni 是聚类 𝑖 中的观测数，𝑁 是观测总数）
谢谢。
cv.init&lt;-cv.glmnet(X.a, y.a, lambda=seq(2, 0.1, -0.1)*sqrt(2*log(p)/N))
beta.hat&lt;-coef(cv.init, s=cv.init$lambda.min)[-1] 
res&lt;-y.a-X.a %*% beta.hat
lam.seq&lt;-seq(2, 0.1, -0.1)*sqrt(2*log(p)/N)
beta.db.sd &lt;-rep(NA,length=length(coord))
beta.db &lt;-rep(NA,length=length(coord))

for(j in 1:length(coord)){
col.j&lt;-coord[j]

cv.x&lt;-cv.glmnet(X.a[,-col.j], X.a[,col.j], lambda=lam.seq)
gam.j&lt;- coef(cv.x, s=cv.x$lambda.min)[-1]
wj.mlm &lt;- X.a[,col.j]- X.a[,-col.j]%*%gam.j
denom &lt;- sum(wj.mlm * X.a[, col.j]) / N
beta.db[j] = beta.hat[col.j] + sum( wj.mlm * res)/(N*denom)

# 聚类稳健方差估计
psi_i &lt;- wj.mlm * res / (N*denom)
S &lt;- numeric(n)
for (i in seq_len(n)) {
cur.grp = cluster_ids[i]
idx &lt;- which(grp == cur.grp)
ni &lt;- length(idx)
S[i] &lt;- sqrt(ni/N)*sum(psi_i[idx])
}
# 自由度调整
G &lt;- n
var_beta_j &lt;- (G / (G - 1)) * sum(S^2)
beta.db.sd[j] &lt;- sqrt(var_beta_j)
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/656430/how-is-the-variance-estimate-calculated-correctly-if-there-are-unequal-sample-si</guid>
      <pubDate>Mon, 28 Oct 2024 19:42:04 GMT</pubDate>
    </item>
    <item>
      <title>不确定研究场景中测试什么、如何测试以及潜力</title>
      <link>https://stats.stackexchange.com/questions/656429/unsure-as-to-what-tests-how-and-potential-in-a-research-scenario</link>
      <description><![CDATA[有三个教室，里面的学生年级不同。我想分析一下这些变量中哪些影响了考试得 0 分的可能性。这些因素包括：年级（8、9 或 10）和压力水平范围（0 到 3）。对于得分为 0 的学生，我想从统计上比较这些因素。我该怎么做？我有 Excel 和 Jamovi（一款 R 软件）。我主要想将其制作成最多两个图表，最重要的是找出得分为 0 分的学生在压力水平和年龄之间是否存在显著差异。这是我为正在进行的一个项目想出的一个类比，但我不允许分享——但这是我遇到的相同统计问题。我的数据如下所示：测试分数（连续小数变量）-&gt; 分数列表。压力水平（序数变量，0 1 2 或 3）。年级（序数）8、9 或 10]]></description>
      <guid>https://stats.stackexchange.com/questions/656429/unsure-as-to-what-tests-how-and-potential-in-a-research-scenario</guid>
      <pubDate>Mon, 28 Oct 2024 19:07:42 GMT</pubDate>
    </item>
    <item>
      <title>从未知函数的样本中学习概率分布</title>
      <link>https://stats.stackexchange.com/questions/656428/learning-a-probability-distribution-from-samples-drawn-from-unknown-function</link>
      <description><![CDATA[我想从数据中学习一些概率分布$p$（例如，使用核密度估计、正则化流，无论你最喜欢的机器学习模型是什么）。
如果我有一个数据集$D = [x_1, \dots , x_N]$，其中$x_{[0,\dots,N]} \sim p(x)$，如果我正在训练某个模型$\hat{p}_{\theta}$（其中$\theta$是模型参数），我会做一些事情，比如最小化负对数似然，即优化：
$$\arg\min_{\theta} \mathbb{E}_{p(x)}[-\log \hat{p}_{\theta}(x)]$$
其中
$$\mathbb{E}_{p(x)}[-\log\hat{p}_\theta(x)] \approx \sum_{i=0}^{N} -\log \hat{p}_{\theta}(x_i)$$
但是，我目前的情况是不知道数据来自哪个分布，但可以访问 p 下每个数据点的可能性。也就是说，我有：
$$D = [\langle x_1, p(x_1)\rangle, \dots \langle x_N, p(x_N)\rangle]$$
我不知道$x_1, \dots x_N$是在哪个分布下生成的（具体来说，从一些未知的有偏差分布中生成大量样本，然后实验者通过确定性顺序贝叶斯优化过程收集这些“好”样本的子集，然后通过一些昂贵的模拟计算出可能性$p(x_i)$）。
在这种情况下，我还能学到一些关于$p$的知识吗？
因为附注：我知道如果我知道其他分布是什么（假设 $x_i$ 由 q(x) 生成），我可以通过重要性抽样学到一些东西。即，我可以优化：
$$\arg \min_{\theta} E_{q(x)}[-\log \hat{p}_{\theta}(x)\frac{p(x)}{q(x)}]$$
但鉴于我掌握的信息绝对比这少……我还能用这些数据做什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656428/learning-a-probability-distribution-from-samples-drawn-from-unknown-function</guid>
      <pubDate>Mon, 28 Oct 2024 18:57:48 GMT</pubDate>
    </item>
    <item>
      <title>皮特曼相对效率</title>
      <link>https://stats.stackexchange.com/questions/656427/pitman-relative-efficiency</link>
      <description><![CDATA[我遵循 Van Der Vaart 在《渐近统计学》第 14.1 章中给出的 Pitman 相对效率的定义。给定一个用于检验零假设 $\theta=0$ 的检验统计量序列 $T_n$（随样本大小变化），以及一个用于检验备选假设序列 $\theta_n=h/\sqrt{n}$，假设
\begin{align}
\frac{\sqrt{n}(T_n - \mu(\theta_n))}{\sigma(\theta_n)} \leadsto N(0,1)
\end{align&gt;
沿着测量序列 $\theta_n$ 分布。然后$\mu&#39;(0)/\sigma(0)$被定义为&quot;测试斜率&quot;。给定两个满足上述假设的测试统计数据$T_1$和$T_2$，Pitman相对效率就是测试斜率的比率，$\mu_1&#39;(0)/\sigma_1(0)*\sigma_2(0)\mu_2&#39;(0)$。例如，如果测试正态分布 $N(\theta,1)$ 的均值 $\theta$，
$$
\sqrt{n}(\overline{X}-\theta_n) \leadsto N(0,1)
$$
沿着 $\theta_n$，因此测试斜率为 1。但是，我们不能只对 $T_2$ 取一个 $\sqrt{\theta}$ 的估计量，其中 $\mu(\theta)=\sqrt{\theta}$，这样$\mu&#39;(0)=\infty$，这会比平均值效率高出无数倍吗？我误解了 Pitman 效率的定义吗？或者我们无法构建这种类型的估计量，即 $\mu(\theta)=\sqrt{\theta}$？或者 Pitman 效率只是一种不同于通常所说的平均值最高效的效率衡量标准？]]></description>
      <guid>https://stats.stackexchange.com/questions/656427/pitman-relative-efficiency</guid>
      <pubDate>Mon, 28 Oct 2024 18:46:05 GMT</pubDate>
    </item>
    <item>
      <title>以和的范围为条件的负关联</title>
      <link>https://stats.stackexchange.com/questions/656426/negative-association-conditioned-on-range-of-sum</link>
      <description><![CDATA[假设$X_1, \ldots, X_n$是边缘独立的随机变量。然后有条件地给定$S := \sum_{i=1}^n X_i$，可以证明$(X_1,\ldots,X_n)$是负相关的。为清楚起见，负关联的定义如下。
定义：$X_1, \ldots,X_k$ 被称为负关联的，如果对于 $\{1,\ldots,k\}$ 中的任何两个不相交子集 $A_1$ 和 $A_2$，
$$Cov(f_1(X_i, i\in A_1), f_2(X_j, j\in A_2)) \leq 0$$
对于任何两个增函数 $f_1$ 和 $f_2$。
有关负关联的更多性质（尤其是开头提到的结果的证明），可在 Kumar Joag-Dev 和 Frank Proschan 撰写的题为“随机变量的负关联及其应用”的文章中找到。
我的问题是，对于任何非平凡的 $t$，在给定 $\{S&gt;t\}$ 的情况下，$(X_1,\ldots,X_n)$ 是否条件性地负关联？请注意，与一开始对 $\{S=s\}$ 进行条件化不同，我在这里对 $\{S&gt;t\}$ 进行条件化。
编辑：对于我的用例，每个随机变量都略微遵循高斯分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/656426/negative-association-conditioned-on-range-of-sum</guid>
      <pubDate>Mon, 28 Oct 2024 18:45:17 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归中的排列检验，哪种方法是正确的？</title>
      <link>https://stats.stackexchange.com/questions/656424/permutation-test-in-multiple-linear-regression-which-way-is-correct</link>
      <description><![CDATA[我正在拟合线性回归模型$$Y = \beta_0+ \beta_1 Z + \beta_2 X$$响应$Y$和协变量$X$是连续变量，$Z$是0/1二分处理组指标，均为$N \times 1$向量。我想要获得$\beta_1$的置换分布。在排列中，下列哪一项是正确的：
(1) 随机排列 $Y$，并获取 1000 个排列中 $\beta_1$ 的分布
(2) 随机排列 $Z$，并获取 1000 个排列中 $\beta_1$ 的分布
(3) 令 $Z(X)$ 为在 $X$ 上拟合 $Z$ 的残差向量，令 $Y(X)$ 是将 $Y$ 拟合于 $X$ 所得的 残差。 
然后对 $Z(X)$ 进行 1000 次置换，并记录 $Y(X)$ 对 $Z(X)$ 进行回归时 $Z(X)$ 的 1000 个回归系数。
(4) 对 $Y(X)$ 对 $Z$ 进行回归，对 $Z$ 进行 1000 次置换，并记录 1000 个回归系数。这与比较“X 调整值”的平均值相同$Y$ 在 2 个组中的分布。
我认为 (3) 是正确的方法，因为它保留了 $X$ 与 $Y$ 和 $Z$ 的关系。因此 在置换之前，我应该从 $Z$ 和 $Y$ 中清除 $X$ 的影响。但 (4) 对我来说也并非完全不合理。我找不到合适的参考资料来讨论这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/656424/permutation-test-in-multiple-linear-regression-which-way-is-correct</guid>
      <pubDate>Mon, 28 Oct 2024 17:20:46 GMT</pubDate>
    </item>
    <item>
      <title>人均分析中比率的虚假相关性</title>
      <link>https://stats.stackexchange.com/questions/656422/spurious-correlation-of-ratios-in-per-capita-analyses</link>
      <description><![CDATA[我试图弄清楚比率的虚假相关性如何影响变量为人均指标的分析。
假设我有一个回归
$$
\text{人均GDP}_{it} = \alpha + \beta \cdot \text{人均二氧化碳}_{it}
$$
$$
\ln(\text{人均GDP}_{it}) = \alpha + \beta \cdot \ln(\text{人均二氧化碳}_{it})
$$
$$
\ln(\text{GDP}) = \alpha + \beta \cdot \ln(\text{二氧化碳}) + \gamma \cdot \ln(\text{人口})
$$
如果我发现 beta 在第一个回归中显著，那么这是否可能是虚假相关性？第二个呢？第三个呢？
许多人均指标使其更容易解释，但我想知道我应该使用哪种修复方法。
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656422/spurious-correlation-of-ratios-in-per-capita-analyses</guid>
      <pubDate>Mon, 28 Oct 2024 16:18:54 GMT</pubDate>
    </item>
    <item>
      <title>为什么方差趋向于 sigma^2/n？</title>
      <link>https://stats.stackexchange.com/questions/656421/why-does-the-variance-tend-to-sigma2-n</link>
      <description><![CDATA[设 $Y_1, Y_2, \ldots, Y_n$ 为 $n$ 个个体的收入，其中 $E(Y_i) = \mu$ 且 $\text{Var}(Y_i) = \sigma^2$ 适用于所有 $i = 1, 2, \ldots, n$。这 $n$ 个个体组成 $m$ 个组，每个组的大小为 $k$。众所周知，同一组中的个体是相关的，但不同组中的两个个体始终是独立的。假设当个体相关时，所有对的相关系数都相同。
考虑随机变量 $\bar{Y} = \frac{1}{n} \sum_{i=1}^n Y_i$ 当 $m$ 很大但 $k$ 有限时，$\bar{Y}$ 的极限方差为
选项：

(A) $ 0$
(B) $\frac{1}{k}$
(C)​​ $1$
(D) $\frac{\sigma^2}{k}$

根据一些计算，我计算出 $\text{Var}(\bar{Y}) = \frac{\sigma^2}{n}(1+(k-1)r) $(r 是相关系数)。基于此，$n \rightarrow \infty$ 方差项必须趋向于零，但当我查阅 chatGPT 时，它说方差不为零，因为组成员之间存在相关性。这是真的吗？如果是，为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/656421/why-does-the-variance-tend-to-sigma2-n</guid>
      <pubDate>Mon, 28 Oct 2024 16:02:25 GMT</pubDate>
    </item>
    <item>
      <title>极简模型如何能在 MNIST 上实现更高的准确率？</title>
      <link>https://stats.stackexchange.com/questions/656420/how-can-minimalist-models-achieve-even-higher-accuracy-on-mnist</link>
      <description><![CDATA[我最近看到了一个有趣的讨论，关于一个简单的逻辑回归模型如何在 MNIST 数据集上实现约 92% 的分类准确率（参考：一个简单的逻辑回归模型如何在 MNIST 上实现 92% 的分类准确率？）。
对于线性模型，784 个神经元（每个像素一个）似乎是最小配置。然而，我一直在探索我们可以在多大程度上进一步推动简约模型，同时仍然实现高性能。我开发了一个只有 702 个参数的神经网络，它在 MNIST 上实现了 98.2% 的准确率。您可以在此处找到我的模型的实现：702 参数 MNIST 模型。
我很好奇是否有其他极简方法（例如具有很少参数的神经网络）可以实现超过 92% 的准确率，可能接近 98-99%，而无需诉诸高度复杂的架构。
具体来说，我正在寻找：

极简神经网络或其他模型的示例，这些模型在 MNIST 上实现高精度，参数少于 1,000 个。
帮助此类模型保持高性能同时保持计算效率的技术或技巧（例如，特殊正则化、权重初始化或激活函数）。

任何见解或参考文献，探讨这种简约而又强大的建模方向将受到极大的赞赏！]]></description>
      <guid>https://stats.stackexchange.com/questions/656420/how-can-minimalist-models-achieve-even-higher-accuracy-on-mnist</guid>
      <pubDate>Mon, 28 Oct 2024 15:24:20 GMT</pubDate>
    </item>
    <item>
      <title>使用 `mgcv` 或 `scam` 进行符号约束样条</title>
      <link>https://stats.stackexchange.com/questions/656419/sign-constrained-splines-with-mgcv-or-scam</link>
      <description><![CDATA[我目前正在尝试解决将 GAM 模型拟合到我的数据的问题，通过 R 中的 scam 使用以下公式：
y ~ s(x1, bs = &#39;mpd&#39;, k = 12) + s(x2, bs = &#39;cc&#39;) + s(x3, bs = &#39;bs&#39;, m = 1)
我的响应变量 y 始终为正，我需要

与 x1 相关的平滑应该是单调递减的。
与 x2 相关的平滑应该是循环的。
x3 平滑可以是分段线性的。

我遇到的问题是 我需要所有平滑（包括截距）始终为非负，并且我希望能够之后单独使用它们。
我原本想自己简单地对优化问题进行编码，但这似乎有点过头了。另外，我还想到了修改损失函数以对任何负值添加惩罚的可能性，但我不确定如何朝这个方向进行。
我也尝试过重新排列最小值并应用移位，但有时这是不可能的，否则会导致错误大量增加。
最后，我还尝试通过以下方式修改公式：
y ~ exp(s(x1, bs = &#39;mpd&#39;, k = 12)) + exp(s(x2, bs = &#39;cc&#39;)) + exp(s(x3, bs = &#39;bs&#39;, m = 1))
但显然这在 mgcv 或 scam 中是不可能的。]]></description>
      <guid>https://stats.stackexchange.com/questions/656419/sign-constrained-splines-with-mgcv-or-scam</guid>
      <pubDate>Mon, 28 Oct 2024 15:19:55 GMT</pubDate>
    </item>
    <item>
      <title>如何确定样本中某个混淆元素是否仍然属于同一个总体（由样本和用于价值计算的样本定义）？</title>
      <link>https://stats.stackexchange.com/questions/656418/how-to-determine-if-an-obfuscated-element-of-the-sample-is-still-in-the-same-pop</link>
      <description><![CDATA[我想确定新值 X 属于我的总体的概率。问题是我不仅使用样本来定义我的总体，而且我的值也是利用样本创建的。
更具体地说：我有一个由大约 400 个类似程序组成的样本。我想将我的总体定义为所有与这 400 个程序执行类似操作的程序。
我可以通过度量来计算两个程序之间的相似性得分。因此，对于我的样本（大小为 N）中的任何程序 p_i，我都可以计算 N-1 个分数，然后进一步计算这些分数的均值 m_i 的 N-1 倍。
现在我想知道给定的程序（实际上是从样本中的一个程序派生出来的）是否属于我的总体（如果它仍然接近其他程序）。所以我认为我需要一个假设检验作为其中的一部分。
或者，我也愿意接受这样的想法，即只衡量某些程序与我的总体/样本的差异。
现在我的想法是计算所有 N 个均值 (m_i´s) 并将它们视为分布的随机变量。 （我不确定它们是否服从正态分布，但不知何故，我认为我可以说它们是服从正态分布的，这要归功于中心极限定理的魔力，而且我的样本量大于 30。1. 这是真的吗？）
然后我可以计算新混淆程序与样本中所有其他程序之间的 N（2. 不是 N-1，这会是个问题吗？）分数。
我认为我现在可以计算 z 分数，作为输入程序与我的分布相差多远的度量（它仍然是相同分布的可能性有多大），但该程序不是我的样本的一部分，所以我不知道这是否有效。
那么 3. 这种方法有效吗？ 和 4. 有没有更好/有效的方法？。
此外，只有在可能的情况下，我才需要论证我的方法是有效的，所以如果你能提供任何答案的来源，那将为我提供很大的帮助。
注意：这不是我尝试的第一件事，我查阅了各种文献和 ChatGPT。我阅读了关于学生化、置信区间、有限总体和 Bootstrap 抽样的内容。然而，我非常不确定这些方法是否适用，因为不幸的是，我的问题显然根本不是“教科书”。
非常感谢您花时间阅读这篇文章，我将不胜感激您提供的任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/656418/how-to-determine-if-an-obfuscated-element-of-the-sample-is-still-in-the-same-pop</guid>
      <pubDate>Mon, 28 Oct 2024 15:15:44 GMT</pubDate>
    </item>
    <item>
      <title>使用非参数检验时，要报告配对样本的哪些描述性统计数据？</title>
      <link>https://stats.stackexchange.com/questions/656398/what-descriptive-statistics-to-report-for-a-paired-sample-when-using-a-nonparame</link>
      <description><![CDATA[我有两个变量，A 和 B（配对样本，前后），我需要进行配对样本非参数检验，因为 A 和 B 之间的差异分布不正常（配对值之间的差异的正态性假设不成立）。大约有 14 条记录。我的问题是：为了在表格中提供描述性统计数据，我是否应该提供 A 和 B 的中位数和 IQR，因为我们正在进行配对样本非参数检验，或者我应该首先分别检查每个变量的分布，如果它们遵循正态分布，则在表格中提供平均值和 SD 的值？]]></description>
      <guid>https://stats.stackexchange.com/questions/656398/what-descriptive-statistics-to-report-for-a-paired-sample-when-using-a-nonparame</guid>
      <pubDate>Mon, 28 Oct 2024 08:38:31 GMT</pubDate>
    </item>
    <item>
      <title>小样本观察的重要性</title>
      <link>https://stats.stackexchange.com/questions/656371/significance-of-an-observation-in-a-small-sample</link>
      <description><![CDATA[在 10000 人的群体中，我测试了 30 个人，发现他们全都患有一种疾病。基于这个样本量，我能否进行一些统计测试，以找出在 30 个受试个体都患有这种疾病的情况下，人口中可能患有这种疾病的比例是多少？
我正在进行类似 Cochrane 测试的测试，以找到给定重要性的样本量，但我无法找到上述问题的确切解决方案]]></description>
      <guid>https://stats.stackexchange.com/questions/656371/significance-of-an-observation-in-a-small-sample</guid>
      <pubDate>Sun, 27 Oct 2024 11:06:11 GMT</pubDate>
    </item>
    <item>
      <title>变分推理描述的难解性问题中的混淆[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656368/confusion-in-intractability-issue-described-by-variational-inference</link>
      <description><![CDATA[（已在 reddit 上发布了更长的版本）
我阅读 VAE 论文 已经有一段时间了，并查阅了各种资料，以便对指定的难解性问题有清晰的了解。然而，在试图理解它时，我仍然面临很多困惑。我会解释，但这里只是一些符号，以确保我们的观点一致：

z - 维度为 M 的潜在变量
Z - 表示潜在变量集 z 的随机变量
x - 输入变量（比如说图像）
X - 输入图像数据集

目标是了解潜在空间 Z 的分布，以便从该空间采样时，可以使用某个函数 f(z)（神经网络）生成新的数据点 x&#39;，该函数也属于 P(X) 的输入分布。因此，问题建模如下：

P(Z|X) = P(Z) * P(X|Z) / P(X)

然后，作者声称 P(Z|X) 是难解的，因为 P(X) 是难解的。从高层次上讲，我想了解难解性方面，所以我的问题是：

为什么 P(Z) 在这里不可解？事实上，P(Z) 甚至都不知道，那么为什么它不被认为是难解的？
我假设，P(X|Z) 可以通过应用 f(Z) 来计算，因此如果 P(Z) 是可解的，那么 P(X|Z) 也可以被认为是可解的？
为什么 P(X) 在这里令人担忧？就像它不是可以在整个 P(Z|X) 中假设为常数的某个归一化因子吗？

此外，如果有人可以通过举例而不是仅使用抽象符号来解释这一点以增加清晰度，那将非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/656368/confusion-in-intractability-issue-described-by-variational-inference</guid>
      <pubDate>Sun, 27 Oct 2024 06:04:08 GMT</pubDate>
    </item>
    </channel>
</rss>