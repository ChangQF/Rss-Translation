<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 05 Oct 2024 03:21:06 GMT</lastBuildDate>
    <item>
      <title>SLR 中 $\beta_1$ 方差推导错误</title>
      <link>https://stats.stackexchange.com/questions/655349/error-in-derivation-of-variance-of-beta-1-in-slr</link>
      <description><![CDATA[我试图推导下面简单线性回归的斜率参数的方差，但是我遇到了一个我不知道如何解决的问题。定义$y_i=\beta_0+\beta_1\cdot x_i+\epsilon_i$，其中$\epsilon_i\sim N(0,\sigma^2)$。让$\hat\beta_0$和$\hat\beta_1$成为截距和斜率参数的最小二乘估计量。我的推导如下：
$
\begin{align*} \\ 
Var(\hat\beta_1) = Var\left(\frac{\sum(x_i-\overline{x})(y_i-\overline{y})}{\sum(x_i-\overline{x})^2} \right) \\
\text{* 因为 x 是固定的，所以它们在此推导中充当常数} \\
= \frac{1}{(\sum(x_i-\overline{x})^2)^2}\sum(x_i-\overline{x})Var(y_i-\overline{y}) \\
= \frac{1}{(\sum(x_i-\overline{x})^2)^2}\sum(x_i-\overline{x})[Var(y_i)-Var(\overline{y})] \\
= \frac{1}{(\sum(x_i-\overline{x})^2)^2}\sum(x_i-\overline{x})\left[\sigma^2-\frac{\sigma^2}{n}\right] \\
= \frac{1}{(\sum(x_i-\overline{x})^2)^2}\left[\sigma^2-\frac{\sigma^2}{n}\right]\cdot\sum(x_i-\overline{x}) \\
= \frac{\left[\sigma^2-\frac{\sigma^2}{n}\right]}{\sum(x_i-\overline{x})}\ne\frac{\sigma^2}{\sum(x_i-\overline{x})}
\end{align*}
$
我唯一的想法是，我忘记考虑 $y_i$ 和 $\overline{y}$ 之间的协方差，但我认为这只是 0。任何见解都将不胜感激！
编辑：我知道有一种方法可以将 $\hat\beta_1$ 定义为一些常数的线性组合，但我很好奇是否有一个简单的修复步骤]]></description>
      <guid>https://stats.stackexchange.com/questions/655349/error-in-derivation-of-variance-of-beta-1-in-slr</guid>
      <pubDate>Sat, 05 Oct 2024 03:18:17 GMT</pubDate>
    </item>
    <item>
      <title>错误类型和不确定性的术语：内在的？拟合的？</title>
      <link>https://stats.stackexchange.com/questions/655348/terminology-for-types-of-errors-and-uncertainty-intrinsic-fitting</link>
      <description><![CDATA[假设我有一系列给定变量$x_i$、$i=1,\ldots,n-1$和响应$y_i$，我们探索模型$y_i\sim \text{Normal}(\alpha x_i,\sigma^2)$，其中$y_i$独立于$y_j$，其中$i\neq j$。
我们使用最大似然法拟合参数 $\alpha$ 和 $\sigma$。
假设我们希望在给定 $x_n$ 的情况下预测 $y_n$。显然，对 $y_n$ 的最佳预测将是 $\alpha_\text{MLE}\,x_n$。据我所知，至少有两种类型的不确定性：

模型固有的不确定性，即 $\sigma$。我们不能指望以比$\sigma$更高的精度预测$y_n$，这类似于“观测误差”。
不确定性源于 MLE 估计量具有由预期 Fisher 信息给出的方差，与似然函数的二阶导数或曲率最大相关。这可以通俗地称为$\alpha_\text{MLE}$的“拟合误差/不确定性”。当然，这个“误差”会传播到$y_n$的最佳估计量，从而产生另一个不确定性来源。

这两种不确定性的正确术语是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655348/terminology-for-types-of-errors-and-uncertainty-intrinsic-fitting</guid>
      <pubDate>Sat, 05 Oct 2024 00:35:51 GMT</pubDate>
    </item>
    <item>
      <title>已知有限总体与所有可能的引导样本均值的方差</title>
      <link>https://stats.stackexchange.com/questions/655345/variance-of-known-finite-population-from-all-possible-bootstrap-sample-means</link>
      <description><![CDATA[我知道这个问题没有什么实际意义，但我被问到这个问题，并为此苦思了一天。
如果我们从小的/有限的总体 N 中取出所有可能的引导样本大小为 n 的集合，并仅保留样本均值，我们能得到总体方差吗？我们当然有样本均值，所以我们可以得到均值的方差和样本均值的均值。
设 N = 10，n = 3；可能样本均值的引导集是一个大小为 220 的集合。我们有 220 个均值，其中袋装均值当然等于真实总体均值。但我们如何才能从中获得总体方差？这可能吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655345/variance-of-known-finite-population-from-all-possible-bootstrap-sample-means</guid>
      <pubDate>Fri, 04 Oct 2024 23:40:51 GMT</pubDate>
    </item>
    <item>
      <title>加权惩罚岭回归</title>
      <link>https://stats.stackexchange.com/questions/655343/weighted-penalty-ridge-regression</link>
      <description><![CDATA[假设您有数据 $(x_1,y_1) \dots, (x_n,y_n)$，其中每个 $x$ 都是 $d$ 维。假设您希望最小化岭回归目标 $1/n \sum_i^n (y_i - x_i \beta)^2 + \sum_j^d \lambda_j \beta_j^2$，因此我们可以分别惩罚解决方案的每个坐标。如果非正则化解中每个 $\lambda = 0$ 都在（严格）正象限中，我们能否证明，当我们改变每个坐标的每个 $\lambda &gt;0$ 值时，解空间“覆盖”正象限中所有点的原点？
例如，对于（严格）正象限中的某个点，任何通往原点并留在正象限中的路径都必须与某个 $\lambda$ 值的解空间相交？例如，在 1 维和 2 维中，很明显解空间覆盖原点，但要将其形式化并扩展到更高维度，我遇到了麻烦。我可以提出某种稠密性论证吗？就像我可以找到截距，当我改变每个 $\lambda \to \infty$ 形成解空间的边界时。我可以说解空间是密集的，并且边界上的每个点对于某个 $\lambda$ 值都是“可实现的”吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655343/weighted-penalty-ridge-regression</guid>
      <pubDate>Fri, 04 Oct 2024 23:04:07 GMT</pubDate>
    </item>
    <item>
      <title>使用事后均值分离检验进行置换多元方差分析后确定哪些变量导致组间差异</title>
      <link>https://stats.stackexchange.com/questions/655341/determining-which-variables-drive-group-differences-after-a-permutational-multiv</link>
      <description><![CDATA[我有一个数据框，里面有几列不同的变量（有分类预测变量和几个不同的数字响应变量）。我做了方差的置换多元变量分析，然后做了适当的事后分析，以确定哪些组对实际上存在显著差异。
我想进一步深入研究这些结果，并确定哪些响应变量导致了分析发现的组间差异。我认为应该有一种方法可以确定（使用向量载荷）哪些向量与每对显著不同的组的显著组差异方向最一致。
虽然我有兴趣编写一个算法来找出每个变量在驱动这些组差异方面的重要性，但我的最终问题要复杂一些。是否有统计分析可以告诉我哪些变量或哪些变量显著地驱动了组间差异？换句话说，如果我知道组 A 和 B 有显著差异，并且某些变量与这种差异的方向更一致（从组 A 的质心到组 B 的质心的方向），我如何将 p 值放在每个变量上以确定是否有任何变量特别强烈地驱动组 A 和组 B 之间的差异？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655341/determining-which-variables-drive-group-differences-after-a-permutational-multiv</guid>
      <pubDate>Fri, 04 Oct 2024 20:49:45 GMT</pubDate>
    </item>
    <item>
      <title>检查聚合频率数据是否符合泊松分布</title>
      <link>https://stats.stackexchange.com/questions/655340/checking-if-aggregate-frequency-data-is-poisson</link>
      <description><![CDATA[我随机地将每份保单的索赔数量建模为泊松分布（方差 = 均值）或负二项分布（方差 &gt; 均值）。
我想从一些数据中做一个简单的检查，看看分布是泊松分布还是负二项分布，但观察结果基于不同的基础投资组合或保单集合，我不知道单个保单的结果。在这种情况下，我无法确定是否有一个好的方法可以检查均值是否等于方差，或者我可以对泊松分布进行一些类似的检查。
假设我有投资组合 P_1、P_2、... P_n，每个投资组合包含 m_1、m_2、.... m_n 份保单。我知道每个投资组合的索赔总数，c_1、c_2、...c_n，但我不知道每个保单的索赔总数。
我可以将每份保单的平均索赔计算为 sum(c_i) / sum(m_i)。不过，我认为我无法在保单级别计算方差，以便进行通常的检查，看看方差是否等于平均值​​。我是否可以对平均值和方差进行其他一些简单的检查，以验证分布是否可能是泊松分布？或者其他一些简单的检查？
感谢您的阅读。]]></description>
      <guid>https://stats.stackexchange.com/questions/655340/checking-if-aggregate-frequency-data-is-poisson</guid>
      <pubDate>Fri, 04 Oct 2024 20:34:06 GMT</pubDate>
    </item>
    <item>
      <title>仅建模一个变量时 lrm.fit 中的奇异信息矩阵</title>
      <link>https://stats.stackexchange.com/questions/655339/singular-information-matrix-in-lrm-fit-when-only-modelling-one-variable</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655339/singular-information-matrix-in-lrm-fit-when-only-modelling-one-variable</guid>
      <pubDate>Fri, 04 Oct 2024 19:36:44 GMT</pubDate>
    </item>
    <item>
      <title>正则化逻辑回归与 XGBoost 的比较</title>
      <link>https://stats.stackexchange.com/questions/655338/comparing-regularized-logistic-regression-and-xgboost</link>
      <description><![CDATA[您知道任何有用的指标，可以比较 XGBoost 和正则化逻辑回归吗？我正在寻找一些可以像 AIC / BIC 一样惩罚模型复杂性的东西，或者以某种方式深入了解应用 XGBoost 时的权衡。应用 XGBoost 时，预测性能当然会更好，因为在 GBDT 之上进行了大量优化。我认为这并没有真正考虑到与逻辑回归相比所需的额外复杂性。]]></description>
      <guid>https://stats.stackexchange.com/questions/655338/comparing-regularized-logistic-regression-and-xgboost</guid>
      <pubDate>Fri, 04 Oct 2024 19:27:02 GMT</pubDate>
    </item>
    <item>
      <title>计算机根据高斯分布生成的样本是否有偏差？</title>
      <link>https://stats.stackexchange.com/questions/655335/are-samples-generated-by-a-computer-from-a-gaussian-distribution-biased</link>
      <description><![CDATA[最近我一直在阅读一些关于高斯过程的博客，它们使用协方差矩阵$\Sigma$来生成一系列点$(x_1, x_2 ...x_n)$，这些点组合在一起看起来像一个实函数。
但是，我不太明白为什么会出现这种现象。我的意思是，一切都是概率性的，对吧？因此可能存在一些噪声样本 - 一系列$(x_1, x_2 ...x_n)$，当放在一起时，它们看起来不像任何平滑函数，但似乎不会发生这种情况？
此外，关于计算机如何从高斯$\mathcal{N}$分布生成样本，我听说过重新参数化技巧：$x\sim \mathcal{N}(\mu, \sigma) \rightarrow x = \mu + \sigma \epsilon$，其中$\epsilon \sim \mathcal{N}(0, 1)$。但是，我们只能确保 $x$ 遵循 $\mathcal{N}$ 分布，并非使用此技巧可以正确生成 $\mathcal{N}$ 分布中的每个样本，对吗？我的意思是，这种关系是单向的，那么我们是否会偏向某些样本？]]></description>
      <guid>https://stats.stackexchange.com/questions/655335/are-samples-generated-by-a-computer-from-a-gaussian-distribution-biased</guid>
      <pubDate>Fri, 04 Oct 2024 18:56:35 GMT</pubDate>
    </item>
    <item>
      <title>关于最小充分统计量和最小充分 $\sigma$-代数的问题</title>
      <link>https://stats.stackexchange.com/questions/655334/question-about-minimal-sufficient-statistics-and-minimal-sufficient-sigma-alg</link>
      <description><![CDATA[我得出了一个关于最小充分统计数据的矛盾，但我无法确定问题出在哪里。
考虑统计模型$(\mathbb{R},\mathfrak{B}_\mathbb{R},\{P_\theta\}_{\theta\in \mathbb{R}})$，其中$P_\theta$是由密度函数$f_\theta:\mathbb{R}\to \mathbb{R}$引起的概率测度，由$f_\theta (x):=\left(\frac{2}{\pi}\right)^{1/2}e^{-\frac{(x-\theta)^2}{2}}\mathbf{1}_{[\theta,\infty)}(x)$。
很容易看出，由 $T(x):=x$ 给出的 $T:\mathbb{R}\to \mathbb{R}$ 是最小充分统计量，这意味着，使用 [1] 的定理 4，$\sigma (T):=\{T^{-1}(B):B\in\mathfrak{B}_\mathbb{R}\}$ 是最小充分$\sigma$-代数。因此，利用[2]的定理 1，我们可以得出结论：$\otimes _{i=1}^n\sigma (T)$是$(\mathbb{R}^n,\mathfrak{B}_{\mathbb{R}^n},\{P_\theta^{\otimes n}\}_{\theta\in \mathbb{R}})$的最小充分$\sigma$-代数。
因此，$S:\mathbb{R}^n\to $S(x):=x$ 给出的 \mathbb{R}^n$ 是 w.r.t 的最小充分统计数据。 $(\mathbb{R}^n,\mathfrak{B}_{\mathbb{R}^n},\{P_\theta^{\otimes n}\}_{\theta\in \mathbb{R}})$ 因为 $\sigma (S)=\otimes _{i=1}^n\sigma (T)$（这是 [1] 定理 4 证明中发现的一个论证的结果）。
您还可以证明 $\tilde T:\mathbb{R}^n\to \mathbb{R}^2$ 由 $\tilde T(x):=(\overline x,x_{(1)})$ 给出是足够的（最小）w.r.t. $(\mathbb{R}^n,\mathfrak{B}_{\mathbb{R}^n},\{P_\theta^{\otimes n}\}_{\theta\in \mathbb{R}})$，这意味着存在一个函数 $g:\mathbb{R}^2\to \mathbb{R}^n$，使得 $S=g(\tilde T)$ $\{P_\theta^{\otimes n}\}_{\theta\in\mathbb{R}}$-a.e.。然而，我认为这是荒谬的。

有人能确定在哪里吗问题？
感谢您的关注！

编辑：
使用 [[3]3] 的定理 1，您可以直接证明 $S$ 是一个充分最小统计量。
我现在刚刚意识到的一件事：由于 $S$ 是充分最小的，因此每个充分统计量 $\tilde S:\mathbb{R}^n\to\mathbb{R}^m$ 对于所有 $m\in\mathbb{N}$ 也是充分最小的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655334/question-about-minimal-sufficient-statistics-and-minimal-sufficient-sigma-alg</guid>
      <pubDate>Fri, 04 Oct 2024 18:54:28 GMT</pubDate>
    </item>
    <item>
      <title>Brunner-Munzel 检验的问题 - 只有排名才重要</title>
      <link>https://stats.stackexchange.com/questions/655333/issue-with-brunner-munzel-test-only-the-rankings-matter</link>
      <description><![CDATA[当使用非参数 Brunner-Munzel 检验在两个总体之间进行测试时，我注意到检验统计量
$BM = \frac{\bar{R}_2-\bar{R}_1}{Ns}$
其中 $\bar{R}_i$ 是汇总排名 $R_{ij}$ 的平均值，$N$ 是总体规模 $n_1$ 和 $n_2$ 的总和，并且 $s = \sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}$ 其中 $s_i^2$ 是展示位置 $P_{ij}$ 的样本方差，其中 $P_{ij}=\frac{R_{ij} - R_{ij}^{*}}{N - n_i}$，其中 $R_{ij}^{*}$ 是 $x_{ij}$ 在 $X_i$ 中的总体内排名。因此，如果您将 $\begin{bmatrix}1\\1\\1\\1\\1\\1 \end{bmatrix}$ 与 $\begin{bmatrix}1\\1\\1\\1\\1\\2 \end{bmatrix}$ 进行比较，则得到的检验统计量与将 $\begin{bmatrix}1\\1\\1\\1\\1\\1 \end{bmatrix}$ 与 $\begin{bmatrix}1\\1\\1\\1\\1\\1000 \end{bmatrix}$ 进行比较时得到的检验统计量完全相同。
我的问题是：

我认为第二种情况应该比第一种情况“更加不同”，我的直觉正确吗？
是否有某种替代测试、方法或手段可以纠正这种情况？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655333/issue-with-brunner-munzel-test-only-the-rankings-matter</guid>
      <pubDate>Fri, 04 Oct 2024 18:44:03 GMT</pubDate>
    </item>
    <item>
      <title>限制求解线性方程的随机变量的方差</title>
      <link>https://stats.stackexchange.com/questions/655332/bounding-the-variance-of-random-variables-which-solve-a-linear-equation</link>
      <description><![CDATA[考虑一个矩阵 $\boldsymbol{M} : \mathbb{R}^{N\times N}$，其中每个元素 $M_{ij}$ 都是连续的 i.i.d. 随机变量，其分布不明确，但均值和方差已知。考虑一个类似的向量 $\vec{v} : \mathbb{R}^{N \times 1}$，其分布为 i.i.d。随机变量 $V_i$，它们与所有 $M_{ij}$ 均不相关。最后，考虑一组可能相关的变量 $\Theta_i$，它们满足
$$
\sum_{j} M_{ji} \Theta_j = V_i,
$$
或者等效地，用向量 $\vec{\theta}$ 表示的线性方程包含 $\Theta_i$,
$$
\boldsymbol{M} \, \vec{\theta} = \vec{v}。
$$
我试图根据 $M_{ij}$ 和 $V_i$ 的方差和均值来表达、近似或限制每个 $\Theta_i$ 的方差。唉，我不知道如何开始，而且 Delta 方法 等技术的应用受到阻碍，因为我无法表达 $\boldsymbol{M}$ 的逆。一般而言，$\boldsymbol{M}$ 可能是不可逆的，在这种情况下，我会考虑使用 TSVD 或 Tikhonov 正则化来近似 $\vec{\theta}$ 解。
欢迎提出任何和所有想法！]]></description>
      <guid>https://stats.stackexchange.com/questions/655332/bounding-the-variance-of-random-variables-which-solve-a-linear-equation</guid>
      <pubDate>Fri, 04 Oct 2024 17:57:13 GMT</pubDate>
    </item>
    <item>
      <title>使用 polr() 解释比例优势逻辑回归的系数</title>
      <link>https://stats.stackexchange.com/questions/655330/interpreting-coefficients-from-proportional-odds-logistic-regression-with-polr</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655330/interpreting-coefficients-from-proportional-odds-logistic-regression-with-polr</guid>
      <pubDate>Fri, 04 Oct 2024 17:38:37 GMT</pubDate>
    </item>
    <item>
      <title>关于无偏性的定义及其与 MSE 的联系</title>
      <link>https://stats.stackexchange.com/questions/655327/regarding-the-definition-of-unbiasedness-and-connections-to-mse</link>
      <description><![CDATA[我的印象是，无偏估计量的定义总是针对单个参数。是否有理由认为该定义不能扩展到参数向量？例如，是否有理由我们不说$(\overline{X}, S^2)^T$是$(\mu, \sigma^2)$的无偏估计量？我看不出有什么理由不这样做。似乎您可以定义一个向量版本的偏差：$\text{bias}(\underline{\hat{\theta_n}})=E(\underline{\hat{\theta_n}})-\underline\theta$，并且 MSE 的偏差-方差分解等事实应该成立。我这里遗漏了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655327/regarding-the-definition-of-unbiasedness-and-connections-to-mse</guid>
      <pubDate>Fri, 04 Oct 2024 16:29:26 GMT</pubDate>
    </item>
    <item>
      <title>在确定不确定性时，何时应使用变量的标准差与该变量的误差传播？</title>
      <link>https://stats.stackexchange.com/questions/655344/when-do-i-use-standard-deviation-of-a-variable-vs-error-propagation-of-that-var</link>
      <description><![CDATA[假设我有 2 个量要测量，$x$ 和 $y$。它们没有不确定性，但我可以进行重复测量，通过标准偏差确定它们的不确定性。然后假设我想找到 $z = x - y$ 及其不确定性。如果我对 $x$ 和 $y$ 分别进行 $n$ 次测量，那么找到 $z$ 的不确定性的最佳方法是什么？
我想到的第一种方法是对 $z$ 进行 $n$ 次估计，即 $z_k = x_k - y_k$，然后 $z$ 将是该集合的平均值；不确定性将是集合的标准差（？）。
第二种方法是对$x$和$y$的所有估计值取平均值，并使得$z = x_{avg} - y_{avg}$；根据误差传播公式，不确定性为 $\sigma_z = \sqrt{\sigma_{x_{avg}}^2 + \sigma_{y_{avg}}^2}$，其中 $\sigma_{x_{avg}}$ 为 $x$ 所有估计值的标准差，而 $\sigma_{y_{avg}}$ 为 $y$ 所有估计值的标准差。
估计 $z$ 的两种方法为 $z$ 给出了相同的公式：在第一种方法中，我们有$\frac{\sum_{k = 1}^{n}\left(x_k-y_k\right)}{n}$，在第二种方法中，我们有$\frac{\sum_{k=1}^{n}x_k}{n} - \frac{\sum_{k=1}^{n}y_k}{n} = \frac{x_1\ +\ x_2\ +\ \dots\ +\ x_n\ -\ y_1\ -\ y_2\ -\ \dots\ -\ y_n}{n} = \frac{\sum_{k = 1}^{n}\left(x_k-y_k\right)}{n}$。但是，除非我的代码不准确（可以给出一个例子，但我认为没有必要），否则我会在这两种方法之间得到略有不同的不确定性。我的问题是：为什么会这样，我应该使用哪种方法，以及为什么，如果两种方法都用的话？]]></description>
      <guid>https://stats.stackexchange.com/questions/655344/when-do-i-use-standard-deviation-of-a-variable-vs-error-propagation-of-that-var</guid>
      <pubDate>Fri, 04 Oct 2024 04:14:06 GMT</pubDate>
    </item>
    </channel>
</rss>