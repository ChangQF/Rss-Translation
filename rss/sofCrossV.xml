<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 14 Jan 2025 03:16:53 GMT</lastBuildDate>
    <item>
      <title>使用 multcomp::glht() 和 mice::pool() 时出现新错误</title>
      <link>https://stats.stackexchange.com/questions/659995/new-error-using-multcompglht-and-and-micepool</link>
      <description><![CDATA[我正在重新审视涉及使用 missRanger::missRanger()、multcomp::glht()（导出效果的线性组合）、mice::pool() 和 broom.mixed::tidy() 进行多重插补的旧代码。虽然它以前可以工作，但现在当我尝试创建整洁表或以其他方式提取结果时，它会失败。我使用下面的 mtcars 重现了错误。
# 0. PACKAGES

library(tidyverse)
library(mice)
library(broom.mixed)
library(missRanger)

# 1. DATA
# 设置 mtcars 数据集的 20% 缺失
mtcars_miss &lt;-
generateNA(mtcars, 
p = 0.2, 
seed = 2024)

# 生成 5 个插补
mtcars_i &lt;- 
replicate(9, 
missRanger(mtcars_miss, 
num.tree = 500, 
pmm.k = 3, 
verbose = 0, 
seed = 2024), 
simplify = FALSE)

# 2.不使用线性组合的分析
mtcars_mod &lt;- 
lapply(mtcars_i, 
function(x)
glm(mpg ~ hp * wt + am, 
data = x))

pool(mtcars_mod)

pool(mtcars_mod) |&gt; 
tidy(conf.int = TRUE)

# 3. 线性组合分析
mtcars_lin &lt;- 
lapply(mtcars_i, 
function(x)
multcomp::glht(glm(mpg ~ hp * wt + am, 
data = x), 
linfct = c(&quot;hp = 0&quot;, 
&quot;`hp:wt` = 0&quot;, 
&quot;hp + `hp:wt` = 0&quot;)) |&gt; 
summary())

pool(mtcars_lin)

pool(mtcars_lin) |&gt; 
tidy(conf.int = TRUE)

最后一块生成以下错误消息。正如我上面提到的，这是一个新的错误，当我在 2024 年 10 月运行代码时没有出现。我不知道原因是什么，因为pool（）参数的输出为标准模型和具有线性效果组合的模型创建了 mipo。

data.frame(..., check.names = FALSE) 中的错误：
参数意味着不同的行数：0, 3

关于哪个包导致了这个问题，有什么想法吗？或者我该如何解决这个问题？它同时发生在 glm() 和 glmmTMB() 模型函数中。]]></description>
      <guid>https://stats.stackexchange.com/questions/659995/new-error-using-multcompglht-and-and-micepool</guid>
      <pubDate>Tue, 14 Jan 2025 02:55:08 GMT</pubDate>
    </item>
    <item>
      <title>如何正确考虑集群随机试验中的聚类</title>
      <link>https://stats.stackexchange.com/questions/659991/how-to-properly-account-for-clustering-in-cluster-randomized-trial</link>
      <description><![CDATA[假设我们进行了一项集群随机试验，以检验以下假设：在降低 24 个月时的死亡风险方面，主动干预XYZ优于标准治疗。
100 个站点（集群）被随机分配，50 个分配到XYZ，50 个分配到常规护理；每个 site 招募（比如说）100 名患者。
这可以是一个示例数据集（仅用于说明目的），其中 cov1、cov2、... 是用作协变量的基线因子/变量：
set.seed(1) 
df &lt;- data.frame(
patient_id=c(1,2,3,4,5,6,7,8,9,10),
site=c(1,1,2,1,2,3,4,3,3,5),
治疗=c(“XYZ”、“XYZ”、“标准”、“XYZ”、“标准”、“标准”、“标准”、“XYZ”、“标准”、“标准”、“标准”、“XYZ”)，
死亡=c(0,0,0,1,0,1,1,0,0,0)，
时间=c(720,740,721,456,650,580,720,719,702,688)，
cov1=样本(34:100,10)，
cov2=c(&quot;是&quot;,&quot;是&quot;,&quot;是&quot;,&quot;是&quot;,&quot;否&quot;,&quot;是&quot;,&quot;是&quot;,&quot;否&quot;,&quot;是&quot;),
cov3=c(&quot;男性&quot;,&quot;男性&quot;,&quot;女性&quot;,&quot;女性&quot;,&quot;女性&quot;,&quot;女性&quot;,&quot;男性&quot;,&quot;女性&quot;)
)

patient_id 地点 治疗 死亡 时间 cov1 cov2 cov3
1 1 1 XYZ 0 720 93 是 男性
2 2 1 XYZ 0 740 64 是 男性
3 3 2 标准 0 721 58 是 男性
4 4 1 XYZ 1 456 75 是 女性
5 5 2 标准 0 650 87 否 女性
6 6 3 标准 1 580 73 否 女性
7 7 4 XYZ 1 720 82 是 女性
8 8 3 标准 0 719 38 是 男性
9 9 3 标准 0 702 94 否 女性
10 10 5 XYZ 0 688 92 是 女性

假设我们想使用 Cox 回归模型分析 XYZ 是否确实与随访期间的死亡率降低有关。我们需要考虑聚类，使用 site 变量 - 问题是，在集群随机试验的背景下，我们如何才能恰当地做到这一点？
有许多可能的方法（例如此处所述）；虽然其他地方已经介绍了cluster、strata和frailty之间的区别，但我不太确定我是否理解了这如何应用于集群随机试验（例如我上面解释过的虚构示例）。
我们可以考虑 3 个主要选项：

简单地调整site（在我看来不是最优的，也不合适，但首先可以考虑）：

coxph(Surv(time, death) ~ treatment+site+cov1+cov2+..., data=df)

使用 cluster 参数：

coxph(Surv(time, death) ~ treatment+cov1+cov2+..., cluster(site), data=df)

使用 frailty 参数：

coxph(Surv(time, death) ~ treatment+cov1+cov2+..., frailty(site), data=df)
这 3 个选项中的哪一个可以提供最合适的方法来检验开头提出的假设（即 XYZ 在减少死亡方面优于标准治疗），同时适当地考虑聚类？在集群随机试验的背景下，对模型 #2 和 #3 的解释的主要区别是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659991/how-to-properly-account-for-clustering-in-cluster-randomized-trial</guid>
      <pubDate>Mon, 13 Jan 2025 23:07:59 GMT</pubDate>
    </item>
    <item>
      <title>充分统计数据的因式分解定理</title>
      <link>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics</link>
      <description><![CDATA[根据因式分解定理（Fisher-Neyman），我们得到一个统计量$ T(X) $充分当且仅当存在因式分解：$ f(x|\theta) = g(T(x)|\theta)h(x) $。符号遵循 Casella/Berger 第 276 页。
Casella/Berger 在离散情况下给出了证明，并指出具体因式分解的形式为：$ P(X=x | {\theta}) = P(T(X) = T(x) | {\theta})P(X=x | T(X) = T(x)) $
我的问题是：我们可以将这种解释应用于连续情况吗？它总是成立吗？因此：$ f(x|\theta) = f(T(x)|\theta)f(x|T(x)) $ 其中 $f$ 表示相应的 pdf？]]></description>
      <guid>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics</guid>
      <pubDate>Mon, 13 Jan 2025 22:52:25 GMT</pubDate>
    </item>
    <item>
      <title>使用接受的治疗而非随机分组进行约束纵向数据分析 (cLDA)</title>
      <link>https://stats.stackexchange.com/questions/659986/constrained-longitudinal-data-analysis-clda-using-treatment-received-rather-th</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659986/constrained-longitudinal-data-analysis-clda-using-treatment-received-rather-th</guid>
      <pubDate>Mon, 13 Jan 2025 21:05:21 GMT</pubDate>
    </item>
    <item>
      <title>估计受影响的人数（医疗问题）</title>
      <link>https://stats.stackexchange.com/questions/659985/estimate-the-number-of-affected-individuals-medical-problem</link>
      <description><![CDATA[我的问题可以用医学术语来描述。一个人口为 N 的国家有 C 个人患有特定疾病。然而，这种疾病未被充分诊断，我的目标是估计受影响个体的真实数量 T。
为此，我使用了患有这种疾病的人作为样本；至关重要的是，对于他们每个人，我都知道一项测试的结果，该结果显示该疾病是否被成功诊断。城市和农村地区的成功率不同，我运行了 logit 回归：
logit(P(diagnosed = 1) = β0 + β1(urban / Rural)，
这为我提供了城市成功率 u 和农村成功率 r 的估计值。最后，我将人口 N 分为城市和农村部分，并得出受影响个人数量的修正估计值：
N = U + R，
T = U / u + R / r。
这个解决方案有效，但我之前没有处理过医疗问题，并且相信这个问题很常见并且有一个经过验证的解决方案。我不想重新发明自行车，如果能得到建议或参考，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659985/estimate-the-number-of-affected-individuals-medical-problem</guid>
      <pubDate>Mon, 13 Jan 2025 21:01:20 GMT</pubDate>
    </item>
    <item>
      <title>正交和非正交特征</title>
      <link>https://stats.stackexchange.com/questions/659983/orthogonal-and-non-orthogonal-features</link>
      <description><![CDATA[我的理解是，PCA 是一种对可能非正交的特征进行正交化（将输出称为主成分而不是特征）的技术。但是，在我看过的视频以及这个可视化工具中，特征空间的维度在开始时始终具有正交基，因此 PCA 是从一个正交基到另一个正交基的角度保持变换，而不是正交化技术。
当特征被称为非正交时，这是否意味着特征空间的维度由非正交基生成，然后 PCA 对其进行正交化，或者仅仅意味着数据点在由正交基生成的特征空间上相关？这两种几何视图之间是否存在明显的同构性，以便可以互换使用？
例如，假设我们对比两个独立进行的回归分析。我正在创建一个回归来预测 Bearth 表面上随机选择的位置的温度，而您正在创建一个回归来预测 Schmearth 表面上随机选择的位置的温度。我在 Bearth 的同一个城市放置了四个温度传感器，而您在 Schmearth 的四个大陆上分别放置了一个温度传感器。在每个星球上随机跳跃的第五个温度传感器的测量值是相应的预测目标。为了避免时间序列分析的额外复杂性，温度传感器不会对测量值进行时间戳记，但它们会将五个同时进行的测量值相互关联，以便它们输出的是一组数据点（每个数据点 1 个目标测量值和 4 个特征测量值），就像基本回归所需的那样。
事实是，Bearth 的温度在其地理范围内波动很大，而 Schmearth 的温度则不会。然而，我们每个人的训练数据最终都会出现高度相关性。我认为描述这个问题的方式是，我的特征具有很多多重共线性，这是由于我冗余放置了温度传感器造成的，而你的特征几乎没有多重共线性，但你的星球在其地理范围内的温度范围客观上较小，因此波动性主要是由于（未测量的）季节性而发生在数据点之间，而不是固定数据点的特征之间。
这两个回归之间的差异是否由特征空间中的（非）正交性（或甚至（非）线性）捕获？这是直观的，因为温度传感器的位置和特征空间的形状在逻辑上都先于训练数据点的存在。PCA 能否尽可能地解释这种差异？如果可以，我们是否必须手动识别和建模输入到 PCA 的特征空间中的多重共线性，或者即使我们没有认真考虑温度传感器位置的影响，PCA 是否会自动对其进行校正？如果没有，那么是否存在与此类似的环境，其中可以使用像 Gram-Schmidt（真正正交化非正交基）之类的东西来做我想用 PCA 做的事情？]]></description>
      <guid>https://stats.stackexchange.com/questions/659983/orthogonal-and-non-orthogonal-features</guid>
      <pubDate>Mon, 13 Jan 2025 20:37:46 GMT</pubDate>
    </item>
    <item>
      <title>重复测量设计中评估基因-代谢物关系的指导</title>
      <link>https://stats.stackexchange.com/questions/659981/guidance-on-evaluating-gene-metabolite-relationships-in-repeated-measures-design</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659981/guidance-on-evaluating-gene-metabolite-relationships-in-repeated-measures-design</guid>
      <pubDate>Mon, 13 Jan 2025 20:11:27 GMT</pubDate>
    </item>
    <item>
      <title>不同分析中的变量标准化</title>
      <link>https://stats.stackexchange.com/questions/659980/standardization-of-variables-across-different-analyses</link>
      <description><![CDATA[变量标准化
我正在为我的心理学学士学位进行一项研究，需要有关标准化变量以供分析的建议。我的变量是乐观、压力和 4 个独立的弹性子维度，以及整体弹性。
为了计算整体弹性变量，我总结了各个弹性子维度的标准化 z-总和分数（由于项目范围和响应量表不同，我进行了标准化）。我的分析包括：
3 个简单线性回归（测试总体适应力、乐观和压力之间的主要影响）
4 个层次回归（调节分析） - 测试 4 个独立子维度的调节效应（我也已经在每次分析中标准化了调节变量，因为我想比较每个子维度对因变量的影响强度）
1 个中介分析（测试总体适应力作为乐观-压力关系中的中介）
我的问题是：
我是否还需要在我的分析中标准化其他变量（其他预测因子、因变量），因为我已经使用了其他 z 分数变量（总体适应力变量和独立子维度）？
任何见解或建议都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/659980/standardization-of-variables-across-different-analyses</guid>
      <pubDate>Mon, 13 Jan 2025 20:01:25 GMT</pubDate>
    </item>
    <item>
      <title>如何比较多层模型中固定效应和随机效应之间的贡献？</title>
      <link>https://stats.stackexchange.com/questions/659976/how-to-compare-the-contribution-between-a-fixed-effect-and-a-random-effect-in-a</link>
      <description><![CDATA[假设我有一个包含三个变量的数据集：$y$，我想要了解的结果；$x$，与$x$共变的变量，但我们可以假设它是完美测量的；$g$，分组变量，用于标识测量所属的多个群集（例如，主题）之一。我用多级（分层）回归模型拟合数据，形式为
$$y_i = (\beta_0 + b_{0,g[i]}) + (\beta_1 + b_{1, g[i]})x_i + \varepsilon_i$$
其中 $i = 1, \ldots, n$ 索引数据集中的观测值，$g[i]$ 是观测值 $i$ 的变量 $g$ 的值。
在 lme4 表示法中，该模型为 y ~ 1 + x + (1 + x | g)，允许每个簇有自己的斜率和截距，同时计算总斜率和截距。
我想用这个模型回答的问题是对于解释结果变量，哪个更重要：$x$ 的影响还是聚类间变异性？
我认为回答这个问题的一个实用方法可能是划分方差（如果这很重要，可以假设误差分布是正态的），但我真的不知道该怎么做。我知道，如果我拟合一个非分层模型，即 y ~ 1 + x，方差可以划分为回归可以解释的部分和不能解释的部分。
我还知道，当我拟合模型 y ~ 1 + x + (1 + x | g) 时，我会估计由按 g 分组的随机效应解释的方差分量。从这个模型中，是否可以将方差分解为由固定效应解释的部分、由随机效应解释的部分和残差变异性？如果可以，我该怎么做？
有没有更好的方法来回答这个问题？我认为对解释方差进行划分是一种直观的方式，可以说明一个变量“更重要”比其他的要好，但如果有更好的衡量标准，那也是可以的。
举一个具体的例子，我在 R 中模拟了一个遵循此模型的数据集，并且所有模型参数都是可估计的。
set.seed(101)
n_subjects &lt;- 20
x_values_per_subject &lt;- c(0.1, 0.25, 0.5, 0.75)
x &lt;- rep(x_values_per_subject, times = n_subjects)
g &lt;- rep(1:n_subjects, each = length(x_values_per_subject))
global_b0 &lt;- 5
individual_b0 &lt;- rnorm(n_subjects, global_b0, 5)
global_b1 &lt;- -2
individual_b1 &lt;- rnorm(n_subjects, global_b1, 3)
residual_variance &lt;- 1
mu &lt;- global_b0 + individual_b0[g] +
(global_b1 + individual_b1[g]) * x
error_variate &lt;- rnorm(length(mu), 0, residual_variance)
y &lt;- mu + error_variate
observed_data &lt;- data.frame(x, g, y)

此外，这里有一些简单的代码来可视化组级轨迹。
plot(
NULL, NULL,
xlim = range(x_values_per_subject),
ylim = range(observed_data$y),
xlab = &quot;x&quot;, ylab = &quot;y&quot;
)
for (i in unique(observed_data$g)) {
this_g &lt;- subset(observed_data, g == i)
lines(this_g$x, this_g$y, type = &quot;b&quot;)
}

拟合这两个模型都很容易。
library(lme4)
simple_model &lt;- lm(y ~ 1 + x, data = perceived_data)
multilevel_model &lt;- lme4::lmer(y ~ 1 + x + (1 + x | g), data = perceived_data, REML = FALSE)

当我比较这两个模型时，我发现这两个模型对固定效应的点估计值相同，尽管由于我们已经考虑了聚类的额外变化，x 固定效应的标准误差要小得多。如果我们使用 ANOVA 或 AIC 来比较模型，多层级模型显然要好得多。
summary(simple_model)
summary(multilevel_model)
anova(multilevel_model, simple_model)

因此，给定这两个模型，我如何确定 x 的固定效应是否比集群间变异更重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/659976/how-to-compare-the-contribution-between-a-fixed-effect-and-a-random-effect-in-a</guid>
      <pubDate>Mon, 13 Jan 2025 19:01:20 GMT</pubDate>
    </item>
    <item>
      <title>Y 变量具有不同对比度规范的逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/659975/logistic-regression-with-different-contrast-specification-for-y-variable</link>
      <description><![CDATA[我试图理解使用 polr 函数为结果变量指定不同的对比度如何影响 R 中比例几率逻辑回归模型的结果。为了说明问题，我使用了示例数据集“申请研究生院”，可从此处获取。
我的 DV 是变量“apply”。它是一个具有 3 个级别的有序因子。级别为“不太可能”、“有点可能”和“非常可能”，编码为 1、2 和 3。
我的 IV 是变量“pared”。它是一个二元因子变量。级别编码为 0/1，表示至少有一位父母拥有研究生学位。
下面，我指定了两个模型，它们仅在对比应用于 IV（pared）和 DV（apply）的方式上有所不同。
library(MASS)
library(haven)
dat &lt;- read_dta(&quot;https://stats.idre.ucla.edu/stat/data/ologit.dta&quot;)
dat$apply &lt;- factor(dat$apply, ordered=T)
dat$pared &lt;- factor(dat$pared, ordered=F) # 治疗对比
contr_poly &lt;- contr.poly(length(unique(dat$apply))) # 多项式对比
对比（dat$应用）&lt;- contr_poly

dat1 &lt;- dat
scaled_contr_poly &lt;- (contr_poly - apply(contr_poly, 2, mean))/apply(contr_poly, 2, sd)
对比（dat1$应用）&lt;- scaled_contr_poly # 缩放多项式对比
对比（dat1$pared）&lt;- contr.sum(length(unique(dat1$pared))) # 总和对比

x &lt;- polr(apply ~ pared, data = dat, Hess=TRUE) # 非缩放
summary(x)

y &lt;- polr(apply ~ pared, data = dat1, Hess=TRUE) #缩放
summary(y)



对于系数“pared1”，我可以取模型 y 中获得的估计值，然后将其乘以 2，得到模型 x 中获得的估计值
因为，如果预测因子父母​​教育（pared）使用总和对比：1，-1
logit(P &lt;= j | xi = 1) = beta(j0) + eta(1) # 对比为 -1
logit(P &lt;= j | xi = 0) = beta(j0) - eta(1) # 对比为 1
其中 eta(i) = -beta(i)
logit(P &lt;= j | xi = 1) - logit(P &lt;= j | xi = 0) = 2*eta(1)
更多详情 此处
我无法弄清楚如何将 y 结果中获得的截距转换为 x 结果中获得的截距。
如果“apply”是 IV 而不是 DV，我会做类似下面的事情，但对我来说不起作用。
scale_multiplier &lt;- apply(scaled_contr_poly, 2, sd)/apply(contr_poly, 2, sd)
apply1 * scale_multiplier[1]
apply2 * scale_multiplier[2]

其中，apply1 和 apply2 是模型中的 beta 系数。
任何帮助都非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659975/logistic-regression-with-different-contrast-specification-for-y-variable</guid>
      <pubDate>Mon, 13 Jan 2025 18:52:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么皮尔逊残差和离差残差比正态残差变化更小？</title>
      <link>https://stats.stackexchange.com/questions/659966/why-are-pearson-and-deviance-residuals-less-variable-than-normal-residuals</link>
      <description><![CDATA[我正在阅读 Agresti 的分类数据分析（第 3 版），第 141 页写道：“当模型成立时，皮尔逊和偏差残差的变化小于标准正态分布，因为它们将 $y_i$ 与拟合均值 $\hat \mu_i$ 进行比较，而不是与真实均值 $\mu_i$ 进行比较...&quot;。我不太明白这句话。对于正态线性回归，残差是 $y_i - \hat y_i$，我们不是也使用预测均值作为 $\hat y_i$ 吗？有人可以解释一下 Agresti 是什么意思吗？
编辑：所指的“模型”是 GLM。 Agresti 在这里讨论了 GLM 的残差，并表示它们不像正态线性模型中的残差那样多变。]]></description>
      <guid>https://stats.stackexchange.com/questions/659966/why-are-pearson-and-deviance-residuals-less-variable-than-normal-residuals</guid>
      <pubDate>Mon, 13 Jan 2025 16:36:37 GMT</pubDate>
    </item>
    <item>
      <title>这个问题只能用贝叶斯来解决吗？</title>
      <link>https://stats.stackexchange.com/questions/659942/can-this-problem-only-be-solved-using-bayesian</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659942/can-this-problem-only-be-solved-using-bayesian</guid>
      <pubDate>Mon, 13 Jan 2025 04:46:48 GMT</pubDate>
    </item>
    <item>
      <title>以下最大似然均值和方差结果对所有分布都成立吗？</title>
      <link>https://stats.stackexchange.com/questions/659933/does-the-following-maximum-likelihood-mean-and-variance-result-hold-for-all-dist</link>
      <description><![CDATA[给定一个概率分布$p(x \,|\, \mu, \sigma^{2})$，以及从分布$p(x \,|\, \mu, \sigma^{2})$中抽取$n$个独立同分布样本$x_{1}, \ldots, x_{n}$，我们可以得到一个似然函数$P(\vec{x} \,|\, \mu, \sigma^{2}) = \prod_{j} p(x_{j} \,|\, \mu, \sigma^{2})$。
假设 $p$ 为高斯分布。根据我对 Bishop 的模式识别和机器学习的阅读，给定$\vec{x}$和$p$为高斯分布的知识，最大化$P(\vec{x} | \mu, \sigma^{2})$的$\mu, \sigma^{2}$的值是
\begin{align}\tag{$*$}
\mu_{\text{ML}} = \frac{1}{n}\sum_{j=1}^{n} x_{j} \quad\text{ 和 }\quad \sigma^{2}_{\text{ML}} = \frac{1}{n}\sum_{j=1}^{n} (x_{j} - \mu_{\text{ML}})^{2}。
\end{align&gt;
也就是说，$\mu, \sigma^{2}$ 的最大似然值分别是样本的算术平均值和（有偏、未校正的）方差。
现在的问题是，在我看来，这个结果 $(*)$ 仅适用于 $p$ 为高斯的情况。我的问题是，这个结果$(*)$是否适用于所有概率分布$p(x \,|\, \mu, \sigma^{2})$，还是只适用于高斯分布？如果它适用于所有分布，那么证明（或参考证明）是什么？如果它不适用于所有分布，那么反例是什么？
一般来说，$(*)$适用于哪一类分布？当$(*)$成立时，是否有一个优雅的表征？]]></description>
      <guid>https://stats.stackexchange.com/questions/659933/does-the-following-maximum-likelihood-mean-and-variance-result-hold-for-all-dist</guid>
      <pubDate>Sun, 12 Jan 2025 21:57:04 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归假设和 Box-Tidwell 检验</title>
      <link>https://stats.stackexchange.com/questions/659774/logistic-regression-assumptions-and-box-tidwell-test</link>
      <description><![CDATA[我正在做一个逻辑回归，它只包括两个数字独立变量（年龄和受影响器官的总和）和其他分类变量。当我对这些数字变量执行 Box-Tidwell 检验时，它告诉我结果的对数和变量“器官总和 (p &lt;0.05)”之间没有线性关系。
我的问题是，我是否绝对需要从回归中删除这个变量，或者我是否可以使用另一种技术。我刚刚读到样条应该是一个选项，我已经执行了。然而，我没有在科学工作中解释和报告这一点的经验。我甚至读过一篇关于诊所样条的《自然》文章，但我发现很难理解。你能帮我吗？
esplenicos$Angiogenic &lt;- relevel(esplenicos$Angiogenic, ref = &quot;Yes&quot;)
levels(esplenicos$Angiogenic)

regressão_logistica &lt;- glm(Angiogenic ~ Breed2 + Age + Sex + 
Number_cavities + SumAffected_organs, data = esplenicos,
family = binomial())

esplenicos$logAgeInt &lt;- log(esplenicos$Age) * esplenicos$Age
esplenicos$logSumaffectedorganInt &lt;- 
log(esplenicos$SumAffected_organs) * esplenicos$SumAffected_organs

regressão_logistica2 &lt;- glm(血管生成 ~ Breed2 + 年龄 + 
    受影响器官总数 + 性别 + 腔数 + 
    logSumaffectedorganInt + logAgeInt，数据 = esplenicos， 
    家庭=二项式())
摘要（regressão_logistica2）

logito &lt;- regressão_logistica$linear.predictors
esplenicos$logito &lt;-logito
一瞥(esplenicos)

ggplot(esplenicos, aes(logito, SumAffected_organs)) +
geom_point（大小= 0.5，阿尔法= 0.5） +
geom_smooth(method = &quot;loess&quot;) +
theme_classic()


我包括了 Box-Tidwell 检验的输出，该输出对于器官总和具有显著性，以及结果与器官总和变量的对数图。

]]></description>
      <guid>https://stats.stackexchange.com/questions/659774/logistic-regression-assumptions-and-box-tidwell-test</guid>
      <pubDate>Thu, 09 Jan 2025 14:53:13 GMT</pubDate>
    </item>
    <item>
      <title>使用加权逻辑回归对重复数据进行误差估计的校正因子</title>
      <link>https://stats.stackexchange.com/questions/659641/correcting-factor-for-error-estimation-with-weighted-logistic-regression-on-dupl</link>
      <description><![CDATA[假设一个数据集被复制，但第一份副本被分配了一组概率权重$w_1$（与抽样无关），而第二份副本具有另一组权重$w_2$，其中权重独立于抽样得出，并且$\sum_j w_j=1$其中$1,\dots,j,\dots,J$和$J&gt;2$和$w_j&lt;1 \text{ } \forall j$。 主要问题：

我是否应该将每个权重乘以 1/2 以纠正数据重复？

上下文
假设对于每个观察值 1 到 N，您有概率估计 $p_a=P(race=a)$、$p_b=P(race=b)$、$p_c=P(race=c)$，其中 $\sum_{r=\{a,b,c\}}p_r=1$ 和一些二元结果变量 $y$，并且我们希望估计逻辑回归 $\text{logit }y\sim \beta_0 + \beta_1 D^{r}+X\beta$ 其中 X 是一组控制因素，$D^r$ 是治疗组的虚拟变量（假设 &#39;b&#39; 为治疗组，&#39;a&#39; 为对照组）。
为此，我上面的一些高阶专家估计了一个加权逻辑回归，其中
\begin{align}
\text{logit }\begin{pmatrix}
y \\
y \\
\end{pmatrix} &amp;= \beta_0+\beta_1\begin{pmatrix}
D^{b} \\
D^{b} \\
\end{pmatrix}
+ \begin{pmatrix} X \\ X\\ \end{pmatrix} \beta
\end{align&gt;
其中 $$\text{weights} =\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$$ 且 $D^b_{1\dots N}$=1 且 $D^b_{(N+1)\dots 2N}=0$（基本上，第一个 1...N 堆栈具有虚拟 $D^b=1$ 且第二个 (N+1)...2N 具有虚拟 $D^b=0$。
问题：通常情况下，每个观测值的权重为 1/2 应该可以解决因重复数据集而产生的误差估计问题。这是否仍然适用于权重的使用？例如，我可以这样做 $\text{weights} =\frac{1}{2}\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$ 吗？或者这些权重是否没有意义？
推理尝试
似乎如果，例如，$p_a=.5$ 和 $p_b=.5$，无论这有多不可能，那么我们本质上是在应用考虑数据重复的权重，因此额外的 $\frac{1}{2}$ 权重乘法将是错误的。
请原谅我草率的符号，希望它足以传达这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/659641/correcting-factor-for-error-estimation-with-weighted-logistic-regression-on-dupl</guid>
      <pubDate>Tue, 07 Jan 2025 04:28:49 GMT</pubDate>
    </item>
    </channel>
</rss>