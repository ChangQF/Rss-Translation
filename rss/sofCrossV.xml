<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 03 Dec 2023 09:12:38 GMT</lastBuildDate>
    <item>
      <title>逻辑回归中的变量选择</title>
      <link>https://stats.stackexchange.com/questions/632925/variable-selection-in-logistic-regression</link>
      <description><![CDATA[所以我尝试在 R studio 中制作多元逻辑回归模型。我不知道该怎么做。对我来说似乎有意义的是根据响应单独对每个预测变量进行建模，看看是否有任何个体意义。如果单个预测变量和响应之间没有关系，为什么我要将其添加到我的模型中？
然后，我会创建一个仅包含单独显着的预测变量的模型，然后运行 ​​AIC/BIC 或 ridge/lasso 以减少或删除不显着的预测变量。我所得到的将是我的最终模型。
我只是想知道这是否是构建多元回归的明智方法，如果不是，还有什么更好的方法。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/632925/variable-selection-in-logistic-regression</guid>
      <pubDate>Sun, 03 Dec 2023 06:47:13 GMT</pubDate>
    </item>
    <item>
      <title>使用倾斜决策树理解聚类</title>
      <link>https://stats.stackexchange.com/questions/632924/understanding-clustering-using-oblique-decision-tree</link>
      <description><![CDATA[我想了解以下关于以下代码的帖子。
https://www.kaggle.com /competitions/optiver-realized-volatility-prediction/discussion/276137#1559582
首先，对维度为 [ time ids x stock ids ] 的特征数组（例如收益）进行主成分分析 (PCA)。有112只股票。输出是另一个包含 PC 的数组 c。该数组的维度为 [ 库存 ID x 主成分 ]。所有 112 个主成分均已选择。 c 是 sklearn 中 PCA 函数输出的转置。
p = otree_clusters(c, depth=3) # c 的形状为 [112 x 112]

def get_cut(X):
    y = X
    X = np.hstack((X, np.ones((X.shape[0], 1))))
    y2 = np.sum(y**2, axis=1, keepdims=True)/2
    y = np.hstack((y, y2, 0*y+1, y2 + 1))
    yX = np.matmul(y.T, X)

    minkowski = -np.ones((y.shape[1],1))
    明可夫斯基[-1,0] = +1.0
 
    A = np.matmul(yX.T, minkowski*yX)
    
    Ao = np.expand_dims(A[:-1,-1],1)
    Aoo = A[-1,-1]
    A = A[:-1,:-1] - np.matmul(Ao, Ao.T)/Aoo
    
    lam, v = sp.linalg.eigh(A, eigvals=(0,0))
    v = np.vstack((v, -np.dot(Ao[:,0],v)/Aoo))
    
    c = np.matmul(X, v) &gt; 0.0

    返回 c[:,0]


def otree_clusters(X, 最大深度):
    集合 = np.zeros((X.shape[0])).astype(int)
    对于范围内的 k（最大深度）：
        新集 = 0*集
        
        对于范围内的 kk(np.max(组)+1)：
            b = 集合==kk
            Xs = X[b, :] #x[特征 x 组件]
            c = get_cut(Xs)
            new_sets[b] = 2*sets[b] + c
        集 = 新集
        
    返回集

基本上，我想了解 otree_clusters() 函数如何计算 p。我相信 p 是股票集群的某个截止值？该函数的输入是 c。
在 get_cut(X) 函数中，用 1 和平方和等扩充矩阵 y 有何意义？
y = np.hstack((y, y2, 0*y+1, y2 + 1))
    yX = np.matmul(y.T, X)

同样，找到特征值与解决以下优化有什么关系？
我想了解这个函数内部发生了什么以及它如何链接到 $min(v, b)[ \sum_{ij} [ || y_i - y_j ||^2 * ( x_i . v + b ) * ( x_j . v + b ) ] ] $
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/632924/understanding-clustering-using-oblique-decision-tree</guid>
      <pubDate>Sun, 03 Dec 2023 06:20:01 GMT</pubDate>
    </item>
    <item>
      <title>给定总体的美元价值，所需的样本量所需的显着性和功效[关闭]</title>
      <link>https://stats.stackexchange.com/questions/632921/given-a-population-of-dollar-values-sample-size-needed-for-required-significanc</link>
      <description><![CDATA[我有一个研究问题，其中有大样本的存款金额分布。它足够大，足以被视为人口。我正在进行实验前分析，以确定我是否有足够的样本量来观察治疗带来的显着提升。
我试图重现一个标准样本量计算，我在几个参考文献中读过，包括这个链接。根据我的理解，这种方法假设数据呈正态分布，最终的实验将使用 2 边 Z 检验。

问题是我发现的存款数据呈对数正态分布，因此我应用了以 10 为底的对数转换以使其更加正态分布。结果是我对 $\mu_1-\mu_2$ 的解释是对数转换数据的均值差异。因此，如果我将其转换回来，这个提升将表示为相对比率，而不是平均值的绝对差。
我想知道对美元值使用对数变换来计算样本量是否有效。我得到的其他建议方法包括使用曼惠特尼 U 检验，但我不确定如何为此进行实验前样本量计算。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/632921/given-a-population-of-dollar-values-sample-size-needed-for-required-significanc</guid>
      <pubDate>Sun, 03 Dec 2023 02:17:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么简化回归模型与完全回归模型中相同系数的方差更小？</title>
      <link>https://stats.stackexchange.com/questions/632917/why-is-the-variance-smaller-for-the-same-coefficient-in-a-reduced-regression-mod</link>
      <description><![CDATA[假设我们有两个 $\beta$ 估计器。
$\beta$ 表示所有一整套系数，数据帧中的每个协变量都有一个。
$\beta$ 可以拆分为 $\beta_p$ 和 $\beta_r$，其中 $p$ 表示功能子集，$r$  是删除的协变量。
因此我们估计两个模型，$y = X_p \beta_p$ 和 $y = X\beta$跨度&gt;.
我们将 $\hat{\beta_p}$ 表示为简化模型的系数估计。 $\hat{\beta_p}{\star}$ 是我们在估计完整模型时仅对简化模型中的系数进行的估计。 
因此：
$Var(\hat{\beta_p}) = \sigma^2(X_p&#39;X_p)^{-1}$
$Var(\hat{\beta}) = \sigma^2(X&#39;X)^{-1}$
我的问题是，为什么会这样
$Var(\hat{\beta_p}{\star}) - Var(\hat{\beta_p})$ 是半正定的吗？为什么简化估计量的方差较低？
似乎因为公式是相同的，只是完整模型的自由度较少，所以方差会增加。
但是方差应该根据 $E[s^2] = \sigma^2$ 来估计，我们可以根据 $E[\epsilon&#39;\epsilon]$。我不清楚这如何与上述正半定关系或具有较低方差的简化模型联系起来。
另一种想法更多的是方差分量方法，我们假设完整模型的方差 $Var(\hat{y})$ 由由上面删除的回归量和子集模型回归量（r 和 p）添加的方差。因此，不包含删除的回归量添加的方差的子集模型具有较低的方差（但可能存在一些偏差）。
请帮助我理解此处的偏差与方差权衡，以及它如何与每个模型的$s^2$估计联系起来]]></description>
      <guid>https://stats.stackexchange.com/questions/632917/why-is-the-variance-smaller-for-the-same-coefficient-in-a-reduced-regression-mod</guid>
      <pubDate>Sat, 02 Dec 2023 23:39:17 GMT</pubDate>
    </item>
    <item>
      <title>这是范德法特《渐近统计》一书第 75 页定理 5.52 的错字吗？</title>
      <link>https://stats.stackexchange.com/questions/632915/is-this-a-typo-on-p-75-theorem-5-52-of-the-book-asymptotic-statistics-by-van</link>
      <description><![CDATA[设$\Theta$为紧度量空间，$\theta \in \Theta.$ 让 $m_{\theta}:\mathbb{R}^d\ 到 \mathbb{R}: x\mapsto m_{\theta}(x)$是由 $\theta \in \Theta.$ 索引的可测量函数族 让 $P(f):=E [f(X)],$ 其中 $X:\Omega \to \mathbb{R}^d, f:\mathbb{R}^d\to \ mathbb{R}.$ 因此，下面的 $P(m_{\theta}-m_{\theta_0})$ 应该是 $E[m_{\theta}(X)-m_{\theta_0}(X)].$ 另请参阅：
$$\theta_0:= arg max_{\theta \in \Theta} P(m_\theta(X))= arg max_{\theta \in \Theta} E [m_{\theta}(X)].$$
我必须研究《渐近统计 (2000)&quot;作者：Van der Vaart，我正在 P.75 上查看这个定理：（我认为）这里 $\theta_0$ 是参数 $\theta$ 最大化最大似然估计。下面，

在我看来，第一行中的 sup 是一个拼写错误，因为 LHS 上的数量是非正数，并且受到严格负数的限制，但是，在$\theta=\theta_0,$ LHS 上的数量达到 $0,$，这不是 $\le C\delta^{\alpha}.$ 那么他是打算在这里写inf而不是sup吗？ 
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/632915/is-this-a-typo-on-p-75-theorem-5-52-of-the-book-asymptotic-statistics-by-van</guid>
      <pubDate>Sat, 02 Dec 2023 23:13:52 GMT</pubDate>
    </item>
    <item>
      <title>暴露组不同随访时间的生存分析</title>
      <link>https://stats.stackexchange.com/questions/632910/survival-analysis-with-different-follow-up-times-in-exposure-groups</link>
      <description><![CDATA[我被要求帮助分析一些复发事件生存数据（使用 Anderson-Gill 模型），研究疾病的两种不同亚型（主要协变量）之间的疾病复发风险，并调整其他协变量。一切都好。
然后我被告知，亚型组在观察的时间段内存在系统性差异 - 一组的随访时间比另一组短。那么问题是，生存模型如何解释观察时间较长的群体有更大的机会发生更多事件？
我一直在尝试思考这是否违反了任何审查假设（独立的、非信息性的），但我认为没有？但我也无法清楚地回答他们的问题？有人可以帮忙吗？
（此问题相关：Cox 模型分组跟进时间不同)]]></description>
      <guid>https://stats.stackexchange.com/questions/632910/survival-analysis-with-different-follow-up-times-in-exposure-groups</guid>
      <pubDate>Sat, 02 Dec 2023 21:05:16 GMT</pubDate>
    </item>
    <item>
      <title>指数原假设的排列检验：真的很糟糕吗？</title>
      <link>https://stats.stackexchange.com/questions/632907/permutation-test-for-exponential-null-hypothesis-really-bad</link>
      <description><![CDATA[找到了在指数分布样本下检验零假设的好公式，我想看看效果如何排列测试可以完成这项工作。假设没有错误，答案似乎是：非常糟糕！排列测试真的这么弱，还是这里出了问题？
挑战：给定指数分布变量的两个样本集 {x} 和 {y}，计算 p&lt; /em&gt;-原假设 $H_0$ 下的值（即，p = 如果抽取两个样本集，则观察到这些样本的概率来自相同的指数分布）。
正如上面链接的答案中所述，我们有两个很好的测试统计数据：

F 统计数据：F = &lt; span class=&quot;math-container&quot;&gt;$\frac{\bar{x}}{\bar{y}} \sim F(n_x, n_y)$
A 似然比检验统计量 L = $\frac{\mathcal{L}(H_0)}{\mathcal{L}(H_1)}$

为了测试结果，我选择查看大小为 9 的样本。我使用以下代码通过模拟在原假设下生成了 L 的抽样分布： 
将 numpy 导入为 np
从 scipy.stats 导入 permutation_test，percentileofscore

def LRTstat(x, y):
    “”“指数分布的似然比检验统计量”“”
    mx = np.mean(x)
    我的 = np.mean(y)
    m0 = np.mean(np.concatenate((x, y)))
    # 这些样本在均值相等的原假设下的可能性：
    L0 = np.prod(expon.pdf(np.concatenate((x, y)), 尺度=m0))
    # 这些样本在不同均值的备择假设下的可能性：
    L1 = np.prod(expon.pdf(x,scale=mx)) * np.prod(expon.pdf(y,scale=my))
    返回 L0 / L1

nx, ny = (9, 9)
纳西姆 = 10_000
L = np.zeros(nsim) # 似然比模拟
对于我在范围内（nsim）：
    x = np.random.exponential(size=nx)
    y = np.random.exponential(size=ny)
    L[i] = LRTstat(x, y)

现在，对于任何样本，我使用两种统计数据计算 p 值，如下所示：
# 生成随机样本
x = np.random.exponential(size=nx)
y = np.random.exponential(size=ny,scale=0.5) # 违反零假设使其变得有趣
mx = np.mean(x)
我的 = np.mean(y)
Fstat = mx/my
F_CDF = f.cdf(Fstat, nx*2, ny*2)
F_p = 2*min(F_CDF, 1-F_CDF)
LRT_p = 分数百分位数(L, LRTstat(x, y))/100
print(f&#39;样本 ({n1}) MeanX: {np.mean(x):.2f}\t({n2}) MeanY: {np.mean(y):.2f}\n&#39;
      f&#39;F 统计: {Fstat:.1f};\tCDF={F_CDF:.1%};\tp={F_p:.1%}\n&#39;
      f&#39;LRT统计：{LRTstat(x, y):.3f};\tp={LRT_p:.1%}&#39;)

因此该代码的典型结果是：
样本 (9) MeanX: 1.26 (9) MeanY: 0.36
F统计：3.5；累积分布函数=99.5%； p=1.1%
轻轨统计：0.036； p=1.3%

这两种方法的p值差异绝不会大于 1%。
现在，对于相同的样本数据，我使用 scipy 实现。我给它 10,000 次迭代，这是本例中排列空间的 20%（9+9 个样本）。这是代码：
res = permutation_test((x, y), LRTstat, vectorized=False,
                       n_resamples=10_000，替代=&#39;双面&#39;）
print(f&#39;排列 p={res.pvalue:.1%}&#39;)

在这种情况下，它显示p=15%，这比其他测试给出的 &lt;2% 高很多！我通过代码运行了一千多个测试，排列 p 值到处都是：几乎总是比 L 的其他测试大得多&gt; 值 &lt; 0.8，而且常常是荒谬的。 L = 0.14 的一种情况给出 p=96%！
此典型或预期性能是此应用程序中的排列测试吗？这是一个特别糟糕的应用程序吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/632907/permutation-test-for-exponential-null-hypothesis-really-bad</guid>
      <pubDate>Sat, 02 Dec 2023 20:51:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么简单线性回归模型中的估计系数具有分布？</title>
      <link>https://stats.stackexchange.com/questions/632895/why-do-the-estimated-coefficients-in-a-simple-linear-regression-model-have-a-dis</link>
      <description><![CDATA[当我们进行 OLS 时，据我了解，我们会进行所有导数以获得一些 $\beta_0$ 和  $\beta_1$ 最小化 SSE（观测数据和估计响应 $y_i$-hat 之间无法解释的错误）。既然我们已经优化了 SSE 并获得了 $\beta_0$ 和 $\beta_1$ 的值，那么为什么他们被视为随机变量？

它们有一个标准误差，因此有一个方差，我们还可以在这里看到一个 t 值。因此它们都有一个分布，我不明白为什么会这样。]]></description>
      <guid>https://stats.stackexchange.com/questions/632895/why-do-the-estimated-coefficients-in-a-simple-linear-regression-model-have-a-dis</guid>
      <pubDate>Sat, 02 Dec 2023 17:38:26 GMT</pubDate>
    </item>
    <item>
      <title>除了 John Uebersax 的文章之外，还有哪些关于贝叶斯无条件功效分析的好资源？</title>
      <link>https://stats.stackexchange.com/questions/632870/what-are-some-good-resources-on-bayesian-unconditional-power-analysis-besides-j</link>
      <description><![CDATA[我参考了文章“贝叶斯无条件功效分析”作者：John S. Uebersax (2007)。
我想进一步探讨这个主题。我还没有检查 Uebersax 文章提到的参考文献，但我想知道是否还有其他关于该主题的好的参考文献或资源。
我优先（但不一定）寻找使用数值示例的资源，以检查我是否没有误解某些公式或算法。]]></description>
      <guid>https://stats.stackexchange.com/questions/632870/what-are-some-good-resources-on-bayesian-unconditional-power-analysis-besides-j</guid>
      <pubDate>Sat, 02 Dec 2023 07:41:42 GMT</pubDate>
    </item>
    <item>
      <title>将中心极限定理应用于分段 PDF</title>
      <link>https://stats.stackexchange.com/questions/632793/applying-the-central-limit-theorem-to-a-piecewise-pdf</link>
      <description><![CDATA[对于大小为 1296 的大样本，我们正在研究由分段概率密度函数定义的独立且同分布的随机变量 $f(x) = \frac{1}{ 3} (I_{(0,1)}(x) + I_{(3,5)}(x))$
(a) 我试图找到 $ Y = |X_1 - 2| 的累积分布函数 (CDF) $。我的方法是用 Y 求出 X，代入 pdf，然后考虑绝对值，在各个区间内对 PDF 进行积分。如果有人能够审查我的方法并纠正任何可能的错误，我将不胜感激。
(b) 对于如此大的样本，我被要求使用中心极限定理来近似 $ P\left(\sum_{i=1}^{1296} X_i \leq 3600\right) $.我知道中心极限定理保证 $X$ 的总和将服从正态分布，但是我如何找到此正态分布的参数：$\mu, \sigma$?]]></description>
      <guid>https://stats.stackexchange.com/questions/632793/applying-the-central-limit-theorem-to-a-piecewise-pdf</guid>
      <pubDate>Fri, 01 Dec 2023 13:15:11 GMT</pubDate>
    </item>
    <item>
      <title>接受概率的推导来自 Linero, Yang (2018)</title>
      <link>https://stats.stackexchange.com/questions/632742/derivation-of-acceptance-probability-from-linero-yang-2018</link>
      <description><![CDATA[我想知道这篇论文如何贝叶斯回归树集成适应于
平滑度和稀疏度 作者：Linero &amp; Yang (2018) 推导了 $\sigma$ 的接受概率。
作者给出了 $\sigma$ 半柯西先验，$\sigma \sim \operatorname{Cauchy}_ {+}(0, \widehat{\sigma}_{\text {lasso }})$。要更新 $\sigma$，他们说了以下内容：
&lt;块引用&gt;
设 $R=\left(R_1, \ldots, R_n\right)$ 为残差，$R_i =Y_i-f\left(X_i\right)$。请注意，在 $\sigma^{-2}$ 的平坦先验下， $\sigma 的完整条件^{-2}$ 是 $\mathrm{Ga}(N / 2+$ $1,\ |R\|^2 / 2$ ）。我们在平坦先验下使用这个全条件作为 $\sigma^{-2}$ 的提案分布；调整变换的雅可比行列式后，接受概率变为
$$
A\left(\sigma \rightarrow \sigma^{\prime}\right)=\frac{\operatorname{柯西}_{+}\left(\sigma^{\prime} \mid 0, \widehat{\sigma }_{\text {套索}}\right) \sigma^{\prime 3}}{\text { 柯西 }_{+}\left(\sigma \mid 0, \widehat{\sigma}_{\text {套索}}\right)\sigma^3}\wedge 1。
$$

我得到了它的雅可比行列式，但我想知道他们如何设法从 $\sigma^{-2}$ 的伽玛分布得到$\sigma$ 的半柯西分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/632742/derivation-of-acceptance-probability-from-linero-yang-2018</guid>
      <pubDate>Thu, 30 Nov 2023 19:57:09 GMT</pubDate>
    </item>
    <item>
      <title>空模型似然如何高于拟合模型似然</title>
      <link>https://stats.stackexchange.com/questions/632086/how-can-null-model-likelihood-be-higher-than-fitted-model-likelihood</link>
      <description><![CDATA[据我所知，在拟合 GLM 时，对于相同的训练集，与空模型（仅具有截距）相比，拟合模型应该始终具有更高的可能性。当我运行小型模拟时，我遇到了相反情况的情况。有什么解释吗？
Tt 归结为离散参数的使用，Pearson 与 MLE。使用色散参数的 MLE，问题就消失了。
库(statmod)


is_null_higher &lt;- FALSE
计数 &lt;- 0

while (!is_null_higher) {
  计数 &lt;- 计数 + 1
  x &lt;- rnorm(1000)
  y &lt;- rtweedie(1000, mu=3, phi=2, power=1.5)
  
  df &lt;- data.frame(&#39;y&#39; = y,
                   &#39;x&#39; = x)
  
  model_full &lt;- glm(y ~ x, data=df, family=tweedie(var.power=1.5, link.power=0))
  model_null &lt;- glm(y ~ 1, data=df, family=tweedie(var.power=1.5, link.power=0))
  
  s_null &lt;- 摘要(model_null)
  s_full &lt;- 摘要(model_full)
  
  full_lik &lt;- logLiktweedie(model_full, s_full$分散)
  null_lik &lt;- logLiktweedie(model_null, s_null$分散度)
  
  is_null_higher &lt;- full_lik &lt;空值
  打印（计数）
}

glue::glue(&#39;似然全 - {full_lik}，似然空 - {null_lik}&#39;)

结果是：
&lt;前&gt;&lt;代码&gt;&gt; glue::glue(&#39;似然全 - {full_lik}，似然空 - {null_lik}&#39;)
满似然 - -2335.92720478971，空似然 - -2335.92037260135
]]></description>
      <guid>https://stats.stackexchange.com/questions/632086/how-can-null-model-likelihood-be-higher-than-fitted-model-likelihood</guid>
      <pubDate>Wed, 22 Nov 2023 18:31:18 GMT</pubDate>
    </item>
    <item>
      <title>瑞利变量的假设检验</title>
      <link>https://stats.stackexchange.com/questions/631922/hypothesis-tests-for-rayleigh-variables</link>
      <description><![CDATA[给定来自参数未知的两个瑞利分布随机变量的样本，$X \sim R(\sigma_x), Y \sim R(\sigma_y)$,我们可以使用哪些测试来确定它们的参数（$\sigma_x, \sigma_y$）是否不同以及不同程度如何？
对于瑞利变量，我们对参数 $\sigma$ 以及估计的置信区间有一个封闭形式的无偏 MLE。我们还有一个方便的事实，即瑞利参数的平方是方差，因此我们可以采用一般的同方差性检验。
是否有特定于瑞利分布的测试或技术？]]></description>
      <guid>https://stats.stackexchange.com/questions/631922/hypothesis-tests-for-rayleigh-variables</guid>
      <pubDate>Tue, 21 Nov 2023 02:38:16 GMT</pubDate>
    </item>
    <item>
      <title>GARCH 部分如何影响 ARMA-GARCH 过程的 ACF/PACF？</title>
      <link>https://stats.stackexchange.com/questions/595204/how-does-the-garch-part-affect-the-acf-pacf-of-an-arma-garch-process</link>
      <description><![CDATA[我需要一些帮助来拟合 ARMA-GARCH 模型。
我正在分析每日时间序列。我不明白 GARCH 的顺序如何影响 ACF 或 PACF 图。我的意思是：当我使用 GARCH(1,1)+ARMA(1,1) 而不是 GARCH(2,1)+ARMA(1,1) 时，我应该在 ACF 图中注意到什么区别？当我修改 GARCH 或/和 ARMA 阶数时，ACF 图的哪“部分”应该改变？]]></description>
      <guid>https://stats.stackexchange.com/questions/595204/how-does-the-garch-part-affect-the-acf-pacf-of-an-arma-garch-process</guid>
      <pubDate>Wed, 09 Nov 2022 19:35:33 GMT</pubDate>
    </item>
    <item>
      <title>非连续时间序列预测</title>
      <link>https://stats.stackexchange.com/questions/579501/non-continuous-time-series-forecasting</link>
      <description><![CDATA[我有以下时间序列，其中包含过去 12 个月的数据以及 24 个月的数据：-
时间销售
2021-06-30 0.00
2021-07-31 64.40
2021-08-31 82.61
2021-09-30 93.37
2021-10-31 97.74
2021-11-30 98.56
2021-12-31 103.01
2022-01-31 104.97
2022-02-28 108.55
2022-03-31 115.36
2022-04-30 123.87
2022-05-31 122.36（第12个月观察）
2023-05-31 978.88（第24个月观察，是第12个月观察销售额的8倍）

这里，第 24 个月销售额的价值可能是 2 倍到 8 倍之间的 strong&gt;销售额出现在第 12 个月。预测第 13 个月到第 23 个月的销售额期间（2022-06-30 至 2023-04-30），我希望在这11的预测销售值中保持原始规模em&gt; 个月和 24 月份销售额，否则 23 之间会存在很大差异&lt; /sup&gt; 月销售额和第 24 月销售额。在这里，需要关注的一点是，需要作为模型输入的时间序列不是连续的，从上面提到的数据样本可以看出，我需要执行反向预测这11个月，因为我已经有24个月的数据。
任何有关如何解决此问题的帮助/建议/建议将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/579501/non-continuous-time-series-forecasting</guid>
      <pubDate>Tue, 21 Jun 2022 15:36:16 GMT</pubDate>
    </item>
    </channel>
</rss>