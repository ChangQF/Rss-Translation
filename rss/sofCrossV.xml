<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 May 2024 18:19:25 GMT</lastBuildDate>
    <item>
      <title>纵向分析</title>
      <link>https://stats.stackexchange.com/questions/648231/longitudinal-analysis</link>
      <description><![CDATA[我有一个问题。假设我想分析某个变量“X”是否影响疾病“D”的发病率，但我没有基线时关于“D”的信息。如果我使用生存分析，我必须删除基线时患有 D 的所有人，然后才能执行事件发生时间模型。在这种情况下，我无法做到这一点。是否有某种模型假设基线时变量“X”的分布相似，然后研究在随访期间如何演变？为了看看变量“X”是否影响“D”？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648231/longitudinal-analysis</guid>
      <pubDate>Wed, 29 May 2024 18:00:46 GMT</pubDate>
    </item>
    <item>
      <title>衡量预测不足和预测过度程度的指标有所不同</title>
      <link>https://stats.stackexchange.com/questions/648230/metrics-that-weighs-under-forecasting-and-over-forecasting-differently</link>
      <description><![CDATA[我有多个使用不同回顾期的移动平均预测。我使用 MAPE 测量准确度。在所有选项中，我想选择表现最佳的移动平均。但是，我希望对预测不足的惩罚比预测过度的惩罚要多一些，因为如果预测不足，业务风险会很大。显然 MAPE 不允许我这样做。有什么方法可以让我做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/648230/metrics-that-weighs-under-forecasting-and-over-forecasting-differently</guid>
      <pubDate>Wed, 29 May 2024 17:50:54 GMT</pubDate>
    </item>
    <item>
      <title>具有聚类 SE 或 GLMER 的 GLM</title>
      <link>https://stats.stackexchange.com/questions/648228/glm-with-clustered-se-or-glmer</link>
      <description><![CDATA[我正在对 113 名受试者进行行为经济学实验，每人回答从 10 个问题中随机挑选出的 6 个问题。我的因变量是二进制的（错误 = 0 或错误 = 1），我正在使用逻辑回归。我不知道在具有个体随机效应的 GMLER 或 GLM 之间选择什么，然后在个体层面上聚类 SE。我认为两者都可以控制个体内相关性 + GMLER 还会增加个体间变异性。我尝试了这两种模型，但得到了非常不同的结果，我不确定如何解释它以及选择哪种模型......特别是我不明白为什么我的所有系数在 GMLER 中都是显著的，但在 GLM 中却不是。这是否意味着随机效应捕获了部分无法解释的方差？因此 GMLER 是一个更好的模型？感觉我的 p 值“好得令人难以置信”......感谢您的帮助
我使用 GLM（上）和 GLMER（下）进行了两次逻辑回归，并比较了结果。我得到了非常不同的标准错误和 p 值...我应该相信哪一个？
 # glm
model2 &lt;- glm(Error ~ Complexity + Response_time +Response_time:Complexity, family = binomial(&quot;logit&quot;), data = B)
clustered_se2 &lt;- coeftest(model2, vcov. = vcovCR(model2, cluster = B$Individual, type = &quot;CR2&quot;))
p_values2 &lt;- clustered_se2[, 4]

# glmer
model &lt;- glmer(Error ~ Complexity + Response_time +Response_time:Complexity+ (1 | Individual), family = binomial(&quot;logit&quot;), data = B)

结果如下：

]]></description>
      <guid>https://stats.stackexchange.com/questions/648228/glm-with-clustered-se-or-glmer</guid>
      <pubDate>Wed, 29 May 2024 17:12:49 GMT</pubDate>
    </item>
    <item>
      <title>有限小数可以是离散变量吗？</title>
      <link>https://stats.stackexchange.com/questions/648227/can-a-finite-decimal-number-be-a-discrete-variable</link>
      <description><![CDATA[如果我有一个数组{0.1, 0.2, 0.3, 0.4, 0.5}，这是一个离散数组吗？其中的值是离散值吗？（我有这个疑问，因为很多资料表明离散值通常是整数）
例如：如果将骰子面值除以 10，可能值的样本空间{0.1, 0.2, 0.3, 0.4, 0.5, 0.6}是否仍被视为离散的？]]></description>
      <guid>https://stats.stackexchange.com/questions/648227/can-a-finite-decimal-number-be-a-discrete-variable</guid>
      <pubDate>Wed, 29 May 2024 16:43:16 GMT</pubDate>
    </item>
    <item>
      <title>CHE 模型与两级模型的比较</title>
      <link>https://stats.stackexchange.com/questions/648224/comparing-a-che-model-with-to-a-two-level-model</link>
      <description><![CDATA[我正在做一个三级荟萃分析，我想比较一个三级相关和分层效应模型（其中效应在研究之间嵌套）和一个两级模型（其中研究级别的方差被限制为 0）。我可以使用下面的方差分析比较这两个模型吗？
che.model.6 &lt;- rma.mv(yi =es,
V = V.8,
random = ~ 1 | study/es.id,
data =pression,
sparse = TRUE)
che.model.60 &lt;- rma.mv(yi =es,
V = V.8,
random = ~ 1 | study/es.id,
data =pression,
sparse = TRUE,
sigma2 = c(0, NA))
anova(che.model.60, che.model.6)]]></description>
      <guid>https://stats.stackexchange.com/questions/648224/comparing-a-che-model-with-to-a-two-level-model</guid>
      <pubDate>Wed, 29 May 2024 16:22:41 GMT</pubDate>
    </item>
    <item>
      <title>是否存在无需实证检验的基于欧几里得距离的相似度准确度测量策略？</title>
      <link>https://stats.stackexchange.com/questions/648223/are-there-strategies-for-measuring-accuracy-of-euclidean-distance-based-similari</link>
      <description><![CDATA[我有一些主题，每个主题都有大约 200 个特征。这些特征向量存储在向量数据库中，其中使用欧几里得距离的相似性搜索来查找与给定向量相似的主题。
不幸的是，我没有地面实况数据。我有什么方法可以验证我的相似性分数是否准确吗？我曾考虑使用聚类算法来获得哪些向量相似/不相似的另一种观点，但由于 KNN 之类的算法也使用距离度量，我觉得我实际上并没有验证任何东西。抱歉问了这样一个开放式的问题，但我很感激任何想法。提前谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/648223/are-there-strategies-for-measuring-accuracy-of-euclidean-distance-based-similari</guid>
      <pubDate>Wed, 29 May 2024 16:14:47 GMT</pubDate>
    </item>
    <item>
      <title>梯度提升的历史</title>
      <link>https://stats.stackexchange.com/questions/648222/on-the-history-of-gradient-boosting</link>
      <description><![CDATA[我最近做了一些工作，改变了流行的梯度提升决策树 (GBDT) 以用于回归，我正致力于为现代算法建立理论基础。这里有一篇论文，我倾向于阅读 Jerome Friedman (1999) 的论文：贪婪函数近似：梯度提升机。简介中介绍了一个很好的背景知识，我找到了我认为是 GBDT 回归的通用算法，复制在此处，即算法 2。

我的问题现在变得明显了。在 for 循环中，我们有三行。第一行只是根据分阶段学习器计算直到该步骤的梯度。$h(\textbf{x},\textbf{a})$ 是参数化函数（回归树），它适合每个阶段的残差。这种拟合发生在第二行。在这一行中，参数 $\rho_m$ 也正在优化，然后在最后一步中使用它来缩放对函数 $F$ 的更新。
我解释 $\rho_m$ 的方式是我们现在在流行的 GBDT 库（如 XGBoost 或 LightGBM）中所说的学习率。$\rho_m$ 在训练开始时设置为固定值，它不会像本算法一样在每个步骤中进行优化。这是为什么？有没有重要的论文讨论为什么要进行这种简化？这个算法让我们觉得我们应该在每个阶段调整学习率，而不是保持固定。我只是想知道为什么我们似乎在现代 GBDT 实现中丢失了这个细节？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/648222/on-the-history-of-gradient-boosting</guid>
      <pubDate>Wed, 29 May 2024 16:03:53 GMT</pubDate>
    </item>
    <item>
      <title>分析 FAERS 纵向数据的工作流程</title>
      <link>https://stats.stackexchange.com/questions/648221/workflow-to-analyse-faers-longitudinal-data</link>
      <description><![CDATA[FDA 不良事件报告系统 (FAERS) 数据是一个数据库，其中包含提交给 FDA 的不良事件和用药错误报告的信息。它从 2004 年到 2024 年每季度发布一次。每份报告由多个数据集组成，例如 DEMO24Q1、DRUG24Q1、REAC24Q1（2024 年第一季度）或 DEMO12Q2、DRUG12Q2、REAC12Q2（2012 年第二季度），它们可以通过变量 primaryid 链接起来。我想确定 2004 年至 2024 年与一种药物相关的所有不良事件。
我建议的下载、导入和准备数据的工作流程：

从 FAERS 网站下载并解压缩所有文件
将每个单独的文件导入 R
通过 primaryid 连接 DEMO、DRUG、REAC 文件
使用 rbind 将每个季度的连接数据合并为一个大文件

这是一个好的工作流程吗？在执行连接之前，我应该 rbind 数据吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648221/workflow-to-analyse-faers-longitudinal-data</guid>
      <pubDate>Wed, 29 May 2024 15:56:29 GMT</pubDate>
    </item>
    <item>
      <title>如何从事后检验（多重比较）输出估计效应大小？</title>
      <link>https://stats.stackexchange.com/questions/648220/how-to-estimate-effect-sizes-from-posthoc-test-multiple-comparison-output</link>
      <description><![CDATA[在 MATLAB 中应用单因素方差分析（不平衡）和事后（HSD）分析后，我为每个比较提供了均值差异的估计值和 95% 的置信区间，举个例子，它可能看起来像这样（最后一列除外，见下文）：



治疗 1
治疗 2
下限
差异
上限
P 值
&quot;效果大小&quot;




3
4
-7.331684264
-2.613425854
2.104832556
0.506628583
1.107792591


3
5
-7.401851955
-2.903169074 
1.595513807
0.354639196
1.290675138


3
6
-13.85293007
-8.895622981
-3.938315891
0.000144039
3.588893252



我想要按照 Cohen&#39;s d 的精神，从 HSD 输出中计算标准化效应大小（该统计数据似乎是直观的，即使有多种 替代方案，例如$\eta^2$）。经过相当多的困惑之后，我偶然发现了一些关于分母中 SD 项的合适选择的想法：

根据样本和标准公式计算出的值（例如 Lakens 2013 中的公式 1，实际上这可能是我所用到的错误公式），例如使用免费软件 MATLAB 实用程序 (computeCohen_d)
使用方差分析的均方误差的平方根作为差异 SD 的估计值，这篇文章中的答案似乎建议了这种方法
与 95% CI 相关的 SD； CI 括号应等于 4xSD

最后两种方法提供的值相似，这令人鼓舞，我倾向于继续使用最后一种方法，但我隐约感觉到我做错了，因为计算出的“效应大小”（参见上面的最后一列）很大，即使相关的 p 值没有表明有显著的影响。
因此，我要么没有正确解释正确计算的效应大小（因为大小不需要与 p 相关，不应解释为表示重要性）​​，要么反之亦然（我使用错误的输入 SD 计算效应大小），或者两者兼而有之。如果我理解正确，效应大小与样本大小一起影响分析的功效。因此，我计算的大“效应”可能表明我不需要大样本就能找到显著的影响。大致就是这样吗？
您能帮我弄清楚要使用哪个 SD，以及如何正确解释效果大小吗？
参考
Lakens，D.（2013 年）。计算和报告效果大小以促进累积科学：t 检验和方差分析的实用入门。心理学前沿，4(863)。doi:10.3389/fpsyg.2013.00863]]></description>
      <guid>https://stats.stackexchange.com/questions/648220/how-to-estimate-effect-sizes-from-posthoc-test-multiple-comparison-output</guid>
      <pubDate>Wed, 29 May 2024 15:53:37 GMT</pubDate>
    </item>
    <item>
      <title>调整变量估计值的解释</title>
      <link>https://stats.stackexchange.com/questions/648217/interpretation-of-estimates-for-adjusted-variables</link>
      <description><![CDATA[我已经开始使用 DAG 来改进我的回归模型的构建，并且我想知道是否有意义地解释我在模型中调整的变量所获得的估计值？假设我有以下 DAG，我想知道 X1 对 Y 的影响。根据 ggdag，我的最小调整集是 {X3, X4, X5}。

如果我建立以下回归模型：$ Y = \beta_1 X_1 + \beta_3 X_3 + \beta_4 X_4 + \beta_5 X_5$，唯一有意义的估计是 X1 的估计，即 $\beta_1$，对吧?
另一方面，如果我想知道 X5 的影响，我必须使用另一个回归模型，在该模型中，我调整 {X1, X3, X4} 以获得 $\beta_5$ 的无偏值，对吗？

附加问题：表达式“控制 X”、“执行 X”和“调整 X”都是同义词，意味着在我的模型中包含 X 作为预测变量，对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648217/interpretation-of-estimates-for-adjusted-variables</guid>
      <pubDate>Wed, 29 May 2024 15:11:42 GMT</pubDate>
    </item>
    <item>
      <title>计算数据点不能被回归模型解释的置信度</title>
      <link>https://stats.stackexchange.com/questions/648216/calculate-the-confidence-that-the-data-point-is-not-explained-by-the-regression</link>
      <description><![CDATA[我有 $n$ 个独立变量 $x_i$ 和因变量 $y_i$，其中 $x$ 和 $y$ 都存在不确定性。我进行了线性回归，得到一个模型 $\hat y = \beta x$。
现在我想使用这个回归模型来确定底层系统动态（又称 $\beta$）何时发生变化。我计算新点的残差，以查看它们与我的模型的偏差。我可以绘制残差图，并看到残差在某一点上增加了很多。
但“很多”意味着什么？我想计算这个残差不能用数据的方差来解释的概率。我认为这是系统中某些东西已经改变的置信度。
我的想法是，我可以用
$$
s_r = \sqrt{\frac{\sum (y_i - \hat y)}{n - 2}},
$$
计算回归的标准差，然后使用正态概率密度函数对每个点使用概率。
但这似乎非常幼稚，并且假设我的回归曲线是实际的真实关系。我没有考虑到如果新值远离我的第一个值，模型自然会很糟糕。这让我想到了置信度和预测带，但我不知道如何使用它来获得新点不合适的概率。
此外，我完全忽略了输入的已知不确定性。]]></description>
      <guid>https://stats.stackexchange.com/questions/648216/calculate-the-confidence-that-the-data-point-is-not-explained-by-the-regression</guid>
      <pubDate>Wed, 29 May 2024 15:10:18 GMT</pubDate>
    </item>
    <item>
      <title>合并调查权重</title>
      <link>https://stats.stackexchange.com/questions/648215/combining-survey-weights</link>
      <description><![CDATA[我有一个年度调查，设计上有些复杂。样本框架按季度抽取并重叠。每个季度的样本都会从下一季度的框架中移除。样本按地理区域分层。调查的前任所有者将样本视为自加权样本。然而，多个框架表明存在多重性问题。此外，只有约 6-7% 的样本做出回应，因此无回应也可能是一个问题。
我根据 Hartley (1962) 的工作计算了多重性调整，从而解决了这些问题。我还使用了逻辑回归来估计无回应概率。最后，我一直在考虑进行调整以适应我的样本框架；特别是按年龄和种族。
我唯一的问题是我是否正确地结合了权重。这是我目前的方法：
最终权重 = (1/(抽样概率 * 无响应概率)) * 多重调整
这看起来正确吗？
对这个“最终”权重进行分级是否仍然合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/648215/combining-survey-weights</guid>
      <pubDate>Wed, 29 May 2024 14:43:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的准确度会波动一段时间然后停滞不前？[重复]</title>
      <link>https://stats.stackexchange.com/questions/648214/why-is-my-accuracy-fluctuating-for-a-while-and-then-stuck</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648214/why-is-my-accuracy-fluctuating-for-a-while-and-then-stuck</guid>
      <pubDate>Wed, 29 May 2024 14:28:49 GMT</pubDate>
    </item>
    <item>
      <title>线性回归结果的解释</title>
      <link>https://stats.stackexchange.com/questions/648213/interpretation-of-linear-regression-results</link>
      <description><![CDATA[我运行了一个具有 2 个 IV（均为二分法）的线性回归模型，其中存在交互作用：
y = a + b1x1 + b2x2 + b3x1x2

该模型和 x1 均显著。因此，我运行了第二个模型：
y = a + b1x1

这次，模型和 x1 均不显著。
在这两种情况下，均未违反假设。
我应该如何解释结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/648213/interpretation-of-linear-regression-results</guid>
      <pubDate>Wed, 29 May 2024 14:26:50 GMT</pubDate>
    </item>
    <item>
      <title>在仅截距和 AR-NN 模型之间进行选择：是否有理由不使用 RMSE/MAE 最低的模型？</title>
      <link>https://stats.stackexchange.com/questions/648194/choosing-between-intercept-only-and-ar-nn-models-justified-to-not-use-the-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/648194/choosing-between-intercept-only-and-ar-nn-models-justified-to-not-use-the-model</guid>
      <pubDate>Wed, 29 May 2024 08:36:00 GMT</pubDate>
    </item>
    </channel>
</rss>