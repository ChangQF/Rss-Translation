<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 02 Feb 2025 12:28:27 GMT</lastBuildDate>
    <item>
      <title>VAR模型、数据对数变换及Granger因果关系检验</title>
      <link>https://stats.stackexchange.com/questions/660871/var-model-logarithm-transformation-of-data-and-granger-causality-test</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660871/var-model-logarithm-transformation-of-data-and-granger-causality-test</guid>
      <pubDate>Sun, 02 Feb 2025 11:46:59 GMT</pubDate>
    </item>
    <item>
      <title>caret 包中的 varImp 不适用于 bagEarth</title>
      <link>https://stats.stackexchange.com/questions/660870/varimp-from-caret-package-not-working-for-bagearth</link>
      <description><![CDATA[我有一个函数，用于训练许多不同的模型。在函数中，我使用 caret 中的训练：
mod = caret::train(x=X, y=train$Y, trControl=control, preProcess=&quot;zv&quot;, tuneLength=4, method=model) 
我想跟踪 x 中的每个变量对拟合模型的重要性。环顾四周，varImp() 似乎是最佳选择。对于我尝试过的大多数模型，它都按预期工作 (varImp(mod) )。但是，当我使用 varImp 和 method = &quot;bagEarth&quot; 时，我收到以下错误：
Error in .(var) : could not find function &quot;.&quot;
查看 caret 文档，似乎表明 varImp 函数适用于 bagEarth。我尝试查找是否有其他人遇到过此问题，但没有找到任何问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/660870/varimp-from-caret-package-not-working-for-bagearth</guid>
      <pubDate>Sun, 02 Feb 2025 11:46:48 GMT</pubDate>
    </item>
    <item>
      <title>ECDF 的两个定义 - 为什么使用 1/(n+1) 而不是 1/n，尤其是对于 QQ 图？</title>
      <link>https://stats.stackexchange.com/questions/660866/two-definitions-of-the-ecdf-why-use-1-n1-instead-of-1-n-especially-for-qq</link>
      <description><![CDATA[在 QQ 图的上下文中，我遇到了 ECDF 的两种不同定义：第一个定义是$$F(x)=\frac{1}{n}\sum_{i=1}^n1_{[X_i,\infty[}(x)$$
第二个定义是
$$F(x)=\frac{1}{n+1}\sum_{i=1}^n1_{[X_i,\infty[}(x).$$
这两个定义都在维基百科文章中提到，虽然第一个定义对我来说似乎更自然，但第二个定义在我的 R 类中用于 QQ 图。$^1$ 此答案似乎也承认这两个定义都在实际中使用。
这两个定义分别有什么优点？

$^1$ 为了将样本 $x$ 的 ECDF 与 $n=\operatorname{length}(x)$ 与某个 CDF $F$ 进行比较，我们设置 $x&#39;=\operatorname{sort}(x)$ 和 $p=(1:n)/(n+1)$ 然后我们绘制 $(x&#39;,F^{-1}(p))$.]]></description>
      <guid>https://stats.stackexchange.com/questions/660866/two-definitions-of-the-ecdf-why-use-1-n1-instead-of-1-n-especially-for-qq</guid>
      <pubDate>Sun, 02 Feb 2025 10:30:22 GMT</pubDate>
    </item>
    <item>
      <title>什么决定了伯努利变量概率分布的平均值，其中概率是动态的和后载的？</title>
      <link>https://stats.stackexchange.com/questions/660865/what-determines-the-mean-of-a-probability-distribution-of-bernoulli-variables-wh</link>
      <description><![CDATA[抱歉，标题太笨拙了，我觉得我缺乏统计学背景知识，无法更好地描述我的问题。
这个问题涉及 gacha 游戏。对于那些不熟悉的人来说，它基本上就是赌博。由于出版商所在国家/地区的法规，他们必须提供有关赔率和机制的确切详细信息。
在我正在研究的特定系统中，第 1-58 次试验的成功概率为 0.6%。从第 59 次试验到第 80 次试验，成功概率不断增加，直到第 80 次试验，成功概率为 100%。它所运行的确切函数尚未说明，但我认为它是线性增加的。所述的“总体”包括此概率回溯在内的成功概率为 1.89%。
将本系统中的赌博视为概率为 1.89% 的几何分布，可得出 1 次成功需要 53 次试验的平均值，这是社区中用于获得 1 个所需单位所需的平均掷骰次数的公认值。
这怎么理解呢？如果平均而言，人们需要赌博 53 次才能获得成功，那么平均而言，人们在任何一次掷骰子的成功概率仅为 0.6% 时获胜。在这种概率下，53 次投掷中至少有 1 次成功的概率只有 27% 左右。
这不符合我的直觉，所以我用 Python 做了一个快速而粗略的模拟，假设从 58-80 次试验中概率呈线性增加，但没错，平均值大约是 53。
当概率迅速接近 100% 时，为什么平均值不在 58-80 范围内？
为什么可以使用“总体”概率将这种后载分布建模为简单的几何分布？
任何帮助我理解这一点的人都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660865/what-determines-the-mean-of-a-probability-distribution-of-bernoulli-variables-wh</guid>
      <pubDate>Sun, 02 Feb 2025 09:38:42 GMT</pubDate>
    </item>
    <item>
      <title>限制高斯 S 型函数期望的近似误差</title>
      <link>https://stats.stackexchange.com/questions/660861/bounding-the-approximation-error-of-the-expectation-of-the-sigmoid-of-a-gaussian</link>
      <description><![CDATA[我想限制$\mathbb{E}_x[\sigma(x)],$的近似误差 $\sigma(x):=1/(1+\exp(-x)),$ $x\sim\mathcal{N}(\mu,v)$:
$$\mathbb{E}_x[\sigma(x)]=\sigma(\mu)+\sum_{k=1}^\infty \frac{\sigma^{(k)}(\mu)}{k!}\mathbb{E}[(x-\mu)^k].$$
由于$\mathbb{E}[(x-\mu)^k]=v^k(k-1)!!,$ 这简化为 $$\mathbb{E}_x[\sigma(x)]=\sigma(\mu)+\sum_{k=1}^\infty \frac{v^k\sigma^{(k)}(\mu)}{k!!}.$$
事实上，看起来 $\frac{\sigma^{(k)}(\mu)}{k!!}$ 发散，但这意味着期望发散，而我真的不这么认为。我哪里做错了？
编辑：看来方差在这里至关重要，对于 .05 左右及以下的值，项（至少最多 140 个项，这是我可以计算而不会溢出的极限）不会爆炸。这种期望确实只存在于某些方差中吗？对我来说似乎违反直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/660861/bounding-the-approximation-error-of-the-expectation-of-the-sigmoid-of-a-gaussian</guid>
      <pubDate>Sat, 01 Feb 2025 23:55:33 GMT</pubDate>
    </item>
    <item>
      <title>根据图或现有距离矩阵进行双聚类</title>
      <link>https://stats.stackexchange.com/questions/660858/biclustering-from-a-graph-or-an-existing-distance-matrix</link>
      <description><![CDATA[如果我们有一组测量值，例如各种条件下的基因表达，则有两种常见方法：

计算列之间的距离（例如基因表达谱之间的相似性），并应用算法（层次聚类、k-medoids 等）来查找相似列的聚类。
使用双聚类（又称共聚类）同时对列（基因）和行（条件）进行聚类。这些算法通常不使用显式（面向用户）距离。

如果我已经有一个距离矩阵，其中每个样本代表一个基因条件组合，形式为：
 A1 A2 B1 B2 . . .
A1 0 .1 .7 .1
A2 .1 0 .9 .2
B1 .7 .9 0 .4
B2 .1 .2 .4 0
.
.
.

是否有可用的方法可以同时对原始数据矩阵（不存在，因为我这里有距离）的“行”（A、B、...）和“列”（1、2、...）进行聚类。
也许更有帮助的表述是将其视为（加权）图，其中每个节点都有两个特征，是否有方法可以同时对这些标签进行聚类？]]></description>
      <guid>https://stats.stackexchange.com/questions/660858/biclustering-from-a-graph-or-an-existing-distance-matrix</guid>
      <pubDate>Sat, 01 Feb 2025 21:55:51 GMT</pubDate>
    </item>
    <item>
      <title>最小二乘估计量投影视图中的帽子矩阵的维数</title>
      <link>https://stats.stackexchange.com/questions/660854/dimensionality-of-the-hat-matrix-in-the-projection-view-of-the-least-squares-est</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660854/dimensionality-of-the-hat-matrix-in-the-projection-view-of-the-least-squares-est</guid>
      <pubDate>Sat, 01 Feb 2025 18:28:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么不同的转换分布（分组频率、非分组频率）的平均值不同？</title>
      <link>https://stats.stackexchange.com/questions/660850/why-is-the-mean-different-in-different-converted-distributions-grouped-frequenc</link>
      <description><![CDATA[所以我的老师给出了以下问题：-
下表列出了某学校 10 年级 30 名学生在 100 分的数学试卷中获得的分数。求出学生获得分​​数的平均值。
\begin{array}{|c|c|}
\hline
\text{获得分数} &amp; 10 &amp; 20 &amp; 36 &amp; 40 &amp; 50 &amp; 56 &amp; 60 &amp; 70 &amp; 72 &amp; 80 &amp; 88 &amp; 92 &amp; 95 \\
\hline
\text{学生人数} &amp; 1 &amp; 1 &amp; 3 &amp; 4 &amp; 3 &amp; 2 &amp; 4 &amp; 4 &amp; 1 &amp; 1 &amp; 2 &amp; 3 &amp; 1 \\
\hline
\end{array
我的第一次尝试：-
$$
\bar{x} = \frac{(10 \times 1) + (20 \times 1) + (36 \times 3) + (40 \times 4) + (50 \times 3) + (56 \times 2) + (60 \times 4) + (70 \times 4) + (72 \times 1) + (80 \times 1) + (88 \times 2) + (92 \times 3) + (95 \times 1)}{30}
$$
$$
\bar{x} = \frac{10 + 20 + 108 + 160 + 150 + 112 + 240 + 280 + 72 + 80 + 176 + 276 + 95}{30}
$$
$$
\bar{x} = \frac{1779}{30}
$$
$$
\bar{x} = 59.3
$$
我的第二种方法：-
上述方法很好，但涉及大量计算和求和，因此忘记进位等的可能性会增加，所以我想到将这个未分组的频率分布转换为类大小为 20 的分组频率分布。
因此，这是我的表格制作。
\begin{array}{|c|c|}
\hline
\text{类别间隔} &amp; \text{频率}(f_i) &amp; \text{类别标记}(X_i) &amp; U_i = (X_i - A) / h &amp; f_iU_i \\
\hline
0 - 20 &amp; 1 &amp; 10 &amp; -2 &amp; -2 \\
\hline
20 - 40 &amp; 4 &amp; 30 &amp; -1 &amp; -4 \\
\hline
40 - 60 &amp; 9 &amp; 50 = A &amp; 0 &amp; 0 \\
\hline
60 - 80 &amp; 9 &amp; 70 &amp; 1 &amp; 9 \\
\h行
80 - 100 &amp; 80 - 100 7&amp; 90&amp; 2 &amp; 14 \\
\h行
\text{总计} &amp; 30、&amp;&amp;&amp; 17 \\
\hline
\end{array
现在使用步进偏差法找到平均值
$$
\bar{x} = A + \frac{\sum f_i U_i}{\sum f_i} \cdot (\text{class size})
$$
$$
\bar{x} = 50 + \frac{17}{30} \cdot 20
$$
$$
\bar{x} = 61.33333\ldots
$$
我的疑问：-
虽然我使用第一种方法得到了正确的答案（答案是$59.3$），为什么第二个答案的偏差约为 $2.0333\ldots$，尽管我计算了数据并正确完成了计算部分。我哪里做错了？
我们可以将未分组的频率分布转换为这样的分组频率分布吗？如果是，那么我们必须遵循某些规则吗？如果不是，那么为什么我们不能这样做呢。
我是一名来自印度的$10$班学生，但我对数学很好奇，我喜欢用不同的方法做同样的事情，因此我尝试用这个问题做实验。所以，如果你能以一种简单的方式给出答案，那就太好了😃，否则，如果你包括一些新东西，我不介意学习。
谢谢你抽出时间。
欢迎提供反馈。]]></description>
      <guid>https://stats.stackexchange.com/questions/660850/why-is-the-mean-different-in-different-converted-distributions-grouped-frequenc</guid>
      <pubDate>Sat, 01 Feb 2025 16:12:26 GMT</pubDate>
    </item>
    <item>
      <title>样本均值与自举均值相同，但 T 检验拒绝原假设</title>
      <link>https://stats.stackexchange.com/questions/660844/sample-mean-is-same-as-bootstrapped-mean-but-t-test-rejects-null-hypothesis</link>
      <description><![CDATA[我有 2 个样本（每个样本有大约 8500 个数据点）。我进行了引导（有替换）并绘制了平均差异的分布：

然后，我计算了 2 个样本的实际平均差异，结果是-5.53
我的理解表明，这意味着我的样本之间没有显着差异。但是，当我进行 T 检验时，我得到p_value=0.048
有人可以解释这是怎么可能的吗？据我理解，这本质上就是 T 检验所做的工作 - 创建均值差异分布并检查样本之间的实际均值差异在该分布范围内的可能性。
每个样本的原始分布都非常右偏，但我认为 8500 的样本量可以弥补这一点。此外，我进行了 Levene 检验，两个样本之间的方差没有差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/660844/sample-mean-is-same-as-bootstrapped-mean-but-t-test-rejects-null-hypothesis</guid>
      <pubDate>Sat, 01 Feb 2025 11:34:50 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用 Beta 回归还是 Box Cox 变换线性回归？</title>
      <link>https://stats.stackexchange.com/questions/660815/should-i-use-beta-regression-or-box-cox-transformed-linear-regression</link>
      <description><![CDATA[我的响应变量是态度分数，它是比例分数（总分/最高分），因此是连续的，范围从 0 到 1。最初，我认为 Beta 回归是一个不错的选择，因此我对分数进行了调整，以便没有真正的 0 或 1。
attitude_self$prop_score &lt;- pmin(pmax(attitude_self$prop_score, 0.001), 0.999)
我的模型如下，AIC 值为 -607：
beta_model &lt;- betareg(prop_score ~ age + group + gender + PerceivedKnowledge, 
data =itude_self, link = &quot;logit&quot;)

然而，经过进一步检查，似乎 prop_score 并不遵循真正的 beta 分布。我检查了分布/密度、偏度和峰度，并进行了 fitdist() 和 Kolmogorov-Smirnov (KS) 检验以测试拟合度。

偏度(prop_score)
[1] -2.792165
峰度(prop_score)
[1] 15.89607

fitdist(prop_score, &quot;beta&quot;)
通过最大似然法拟合分布“beta”
参数：
估计标准差。错误
shape1 2.6511869 0.17474578
shape2 0.7264323 0.03847695

&gt; ks.test(prop_score, &quot;pbeta&quot;, shape1 = 2.65, shape2 = 0.73)

渐近单样本 Kolmogorov-Smirnov 检验

数据：prop_score
D = 0.19366，p 值 &lt; 2.2e-16
备选假设：双侧

然后我使用 Box-Cox 变换对响应变量进行变换，并使用线性回归。
得到的 AIC 较低，为 -900，残差如下：

我转向变换后的线性回归而不是 beta 回归是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/660815/should-i-use-beta-regression-or-box-cox-transformed-linear-regression</guid>
      <pubDate>Fri, 31 Jan 2025 16:53:16 GMT</pubDate>
    </item>
    <item>
      <title>解析简单门控 RNN 随时间反向传播的解法</title>
      <link>https://stats.stackexchange.com/questions/660789/analytically-solving-backpropagation-through-time-for-a-simple-gated-rnn</link>
      <description><![CDATA[考虑以下简单的门控 RNN：
\begin{aligned}
c_{t} &amp;= \sigma\bigl(W_{c}\,x_{t} + W_{z}\,z_{t-1}\bigr)
\\[6pt]
z_{t} &amp;= c_{t} \,\odot\, z_{t-1} \;\;+\;\; 
(1 - c_{t}) \,\odot\,\bigl(W_{x}\,x_{t}\bigr)。
\end{aligned&gt;
这里，
$$
x_{t}\in \mathbb{R}^{n}, \quad
z_{t}\in \mathbb{R}^{m}, \quad
c_{t}\in \mathbb{R}^{m}, 
$$
和
$$
W_{c}\in \mathbb{R}^{m\times n},\, 
W_{z}\in \mathbb{R}^{m\times m},\,
W_{x}\in \mathbb{R}^{m\times n}。
$$
门$c_{t}=\sigma(\cdot)$是元素级 S 型函数。
我们让损失为
$$
\ell \;=\;\sum_{t=1}^{K}\;\ell_{t}\,\bigl(z_{t}\bigr)
$$
因此每个$z_{t}$都对$\ell$有贡献。
我们试图在给定$\frac{\partial \ell_t}{\partial z_t}$的情况下找到$\frac{\partial \ell}{\partial W_x}$。我们可以从以下公式开始：
$$
\frac{\partial \ell}{\partial W_{x}} =
\sum_{t=1}^{K} \left(\frac{\partial \ell_t}{\partial z_{t}} \cdot
\frac{\partial z_{t}}{\partial W_{x}} \right)
$$
并且我们必须找到$\frac{\partial z_{t}}{\partial W_{x}}$。为了方便起见，我们可以将每个 $z_t$ 视为多个变量的函数 $f$：
$$
f(U, z_{\text{prev}}, c_t, x_t) = c_t \odot z_{\text{prev}} + (1 - c_t)\,\odot\,(U \, x_t)
$$
然后
$$
z_t = f(W_x, z_{t-1}, c_t, x_t)
$$
然后我们有
$$
\frac{\partial z_t}{\partial W_x} = \underbrace{\Bigl(\frac{\partial f}{\partial U}\Bigr)}_{\text{direct}} + 
\Bigl(\frac{\partial f}{\partial z_{\text{prev}}}\Bigr)
\frac{d\,z_{t-1}}{d W_x} + 
\Bigl(\frac{\partial f}{\partial c_t}\Bigr) \frac{\partial c_t}{\partial W_x}
$$
我在此处的公式下添加了注释“direct”，以强调 $W_x$ 影响 $z_t$ 的两种方式：

存在直接影响，因为 $W_x$ 明确出现在 $z_t$
存在间接影响，因为 $W_x$ 还会影响 $z_{t-1}$ 和 $c_t$ 的值，而这会影响 $z_t$

让我们定义
\begin{align*}
\varepsilon_t &amp;= \frac{\partial f}{\partial U}(W_x, z_{t-1}, c_t, x_t) \\
\delta_t &amp;= \frac{\partial \ell}{\partial z_t} 
\end{align*&gt;
如何我如何证明以下说法？
\begin{align*}
\frac{\partial \ell}{\partial W_{x}} = \sum_{t=1}^{K} \delta_t \varepsilon_t
\end{align*&gt;
我可以使用 PyTorch 验证它，但我正在寻找分析证明。]]></description>
      <guid>https://stats.stackexchange.com/questions/660789/analytically-solving-backpropagation-through-time-for-a-simple-gated-rnn</guid>
      <pubDate>Fri, 31 Jan 2025 03:12:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么一个预测区间比另一个大？</title>
      <link>https://stats.stackexchange.com/questions/660694/why-is-one-prediction-interval-bigger-than-the-other</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660694/why-is-one-prediction-interval-bigger-than-the-other</guid>
      <pubDate>Wed, 29 Jan 2025 03:12:53 GMT</pubDate>
    </item>
    <item>
      <title>比较偏好与 3 个价值观（包括中性）的差异</title>
      <link>https://stats.stackexchange.com/questions/660691/comparing-differences-in-preference-with-3-values-including-neutral</link>
      <description><![CDATA[比较包括中性在内的 3 个值的偏好差异
场景：分析具有 3 个值的偏好数据（例如：您更喜欢哪个：足球、棒球还是没有偏好（即中性）？）
主要研究问题：

是否大于中性？
足球比棒球更受欢迎还是反之亦然？

奇怪的是，与连续数据不同，我没有看到很多关于这种情况的强烈建议。
我的问题是：
哪种统计数据最适合分析具有 3 个值（例如足球、中性、棒球）的偏好数据？
如果答案依赖于“弥补”预期值（例如，将响应分为 3 个值（33%，33%，33%），那么您建议使用什么值（或它们的计算）？（注意：我不喜欢 33%，33%，33%，因为不喜欢任何一个与喜欢其中一个的结果不同（参见上述主要研究问题）。
其他注意事项：
只是指出它不是因子设计（就像我们比较 2 个成功率，例如球队 1 的胜/负与球队 2 的胜/负），所以我们不能通过“平均”足球和棒球的成功来计算预期值。
我的数据集中的响应数量可能非常低。在一个例子中，当足球 = 12 和棒球 = 13 时，卡方显着。
McNemar 检验：Sauro/MeasuringU 推荐此检验。虽然它适用于名义变量，它采用 2x2 形式，并带有成对样本（重复测量）。因此，他的建议似乎适用于其他场景。
我考虑过的选项：
选项 A1 - 中性预期 = 观察值
首先，目测（或置信区间）中性和足球/棒球之间的差异。
其次，将中性预期值设置为等于观察值。将剩余的预期值分为足球和棒球（50/50 分割）以“删除”中性，但保持样本量。 （例如，见图片）



偏好
观察到的
预期的




足球
36
(58/2) =29


中立
42
42


棒球
22
(58/2) =29



一个问题似乎是统计数据本身，因为尝试解释它确实很棘手。就像，“在消除中性反应的影响后，参与者对足球和棒球的偏好不同（或没有不同）。”
选项 A2。中性与其他以及中性预期 = 观察到
除了上面的第一步，要么 (A2a) 取足球和棒球中较大的一个，(A2b) 将足球和棒球加在一起，看看它们加起来是否不同于中性，或者 (A2c) 取足球和棒球的平均值，看看该平均值是否不同于中性。一个问题是 A2a、A2b 和 A2c 的可解释性是……它们很难解释和/或需要大量语言来解释。然后使用上面的第二步。因此，可解释性问题与 A1 相同。
选项 B1 - 置信区间与预期值的重叠[不完整解决方案]
计算置信区间并与预期值进行比较。与上述问题相同：如何计算对 3 个值有意义的预期值（我认为 33,33,33 不是）。那么预期值是什么？
选项 B2 - 置信区间与 3 个观察值的重叠
类似于使用置信区间来目测连续数据之间的差异
选项 C。您的建议！
想法、意见、建议？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660691/comparing-differences-in-preference-with-3-values-including-neutral</guid>
      <pubDate>Wed, 29 Jan 2025 02:28:17 GMT</pubDate>
    </item>
    <item>
      <title>对数变换 SD 的转换</title>
      <link>https://stats.stackexchange.com/questions/636675/conversion-of-log-transformed-sd</link>
      <description><![CDATA[在对一些研究工作的荟萃分析中，文献中经常以对数转换的形式报告平均值及其对应的标准差。
问题是：我怎样才能将 SD 转换回正常值，有没有什么公式或方程式可以帮助解决这个问题？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/636675/conversion-of-log-transformed-sd</guid>
      <pubDate>Thu, 11 Jan 2024 21:31:20 GMT</pubDate>
    </item>
    <item>
      <title>蒙特卡洛随机失分的不确定性分数</title>
      <link>https://stats.stackexchange.com/questions/594819/uncertainty-score-from-monte-carlo-dropout</link>
      <description><![CDATA[当使用神经网络进行多类分类时，有些情况下估计网络预测类别的不确定性很有用。估计不确定性的一种主要方法是蒙特卡洛 dropout，由 Gal 等人 提出。
让 $f(y|x)$ 表示神经网络对输入 $x$ 的 softmax 输出，类别为 $y$。他们的方法是使用 dropout 来训练 $f$，在测试时保持 dropout 启用，并通过从 $f(y|x)$ 中抽取一些样本来估计 $\mathbb{E}[f(y|x)]$ 和 $\textrm{Var}[f(y|x)]$，即通过在输入 $x$ 上运行神经网络几次并计算输出的平均值和标准差。到目前为止，这一切都说得通，但我不清楚如何从中获得不确定性分数。
如果我想要一个分数来衡量网络对 $x$ 类别的预测的不确定性，那么从这些信息中获得不确定性分数的标准方法是什么？本文似乎没有提出任何特定方法。本文描述了如何估计后验预测分布，但没有描述如何从中获得不确定性分数。
我可以想象到多种可能性，即如何从通过蒙特卡洛 dropout 获得的后验预测分布中构建不确定性分数：

我们可以使用后验预测分布中预测类别的概率作为我们的不确定性分数，即 $\max_y \mathbb{E}[f(y|x)]$。

我们可以使用后验预测分布的熵作为我们的不确定性分数，即
$$H(\mathbb{E}[f(\cdot|x)]) = - \sum_y \mathbb{E}[f(y|x)] \log \mathbb{E}[f(y|x)].$$

我们可以使用正态近似来估计未来对神经网络的评估将输出与预测类别相同的类别的概率。具体来说，我们可以将$p(y|x)$近似为高斯$\mathcal{N}(\mu_y,\sigma_y^2)$，其平均值$\mu_y = \mathbb{E}[f(y|x)]$，方差$\sigma_y^2 = \textrm{Var}[f(y|x)]$。对于二分类器，让 $y$ 为测试时预测的类（即 $y=\arg\max_{y&#39;} \mathbb{E}[f(y&#39;|x)]$），$\neg y$ 为另一个类。那么，分类器的未来评估也将输出 $y$ 的概率为 $u=\Pr[X\ge 0]$，其中 $X \sim \mathcal{N}(\mu_y-\mu_{\neg y},\sigma^2_y+\sigma^2_{\neg y})$。我们可以通过误差函数估计 $u$，然后使用 $u$ 作为我们的不确定性分数。（对于多类分类器，我们可以通过对 $y$ 以外的类的所有 logit 求和并将其视为单个其他类 $\neg y$ 的 logit，使用二类 softmax，并估计这些 softmax 输出的正态分布，从而简化为二类分类器。）


在我看来，所有这些都是合理的选择。什么是公认的做法？使用 Monte Carlo dropout 获得不确定性分数的标准方法是什么？如果没有标准，哪种方法最有效？]]></description>
      <guid>https://stats.stackexchange.com/questions/594819/uncertainty-score-from-monte-carlo-dropout</guid>
      <pubDate>Sun, 06 Nov 2022 05:02:16 GMT</pubDate>
    </item>
    </channel>
</rss>