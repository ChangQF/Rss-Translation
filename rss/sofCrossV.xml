<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 27 Mar 2024 03:15:18 GMT</lastBuildDate>
    <item>
      <title>当预测变量增加时预测二元结果</title>
      <link>https://stats.stackexchange.com/questions/643620/predicting-binary-outcome-when-predictor-variable-increases</link>
      <description><![CDATA[假设我有一个包含大量观测值的简单数据集，每个观测值都有一个连续数值变量 $x$ 和一个二进制数值变量 $y$（值为 0 表示不满意，1 表示满意）。
当平均值 $x 时，如何预测我的观察中有多少会满足 $y=1$我的数据集中的 $ 增加了，比如 50%？
我正在考虑从逻辑回归模型开始，但我不确定如何继续。
任何指导将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/643620/predicting-binary-outcome-when-predictor-variable-increases</guid>
      <pubDate>Wed, 27 Mar 2024 00:36:18 GMT</pubDate>
    </item>
    <item>
      <title>对比两种不同方法的可信区间</title>
      <link>https://stats.stackexchange.com/questions/643619/contrasting-credible-intervals-with-two-different-approaches</link>
      <description><![CDATA[我有一个数据集，我以两种方式使用 bmrs 进行建模：1) 多年来的趋势和 2) 几十年之间的比较。我通过两种不同的方式从这两个模型中获得了可信区间，两种方法之间的 CI 范围存在相当大的差异。我怎么知道哪个是正确的？
图书馆(tidyverse)
图书馆（tidybayes）
图书馆（brms）

设置.种子(42)
df &lt;- data.frame(x = rep(seq(1970, 1999, 1),each = 20),
                 a = 样本(字母[1:3], 200, 替换 = TRUE)) %&gt;%
  变异(y = (x/100)^2 + rnorm(600, 1, 2),
         yc = 比例（y，中心 = TRUE，比例 = TRUE），
         d = as.factor(paste(str_sub(x, -2, -2), &quot;0s&quot;, sep = &quot;&quot;)))

m1 &lt;- brm(yc ~ x, data = df) # 模型 1 具有跨年趋势
m2 &lt;- brm(yc ~ d, data = df) # 模型 2 比较数十年的值

不同(df, a, x) %&gt;%
  add_predicted_draws(m1) %&gt;%
  median_qi() %&gt;% # 计算中位数和 95% CI
  重命名（估计 = .预测，loCI = .lower，hiCI = .upper） %&gt;%
  ggplot() +
  geom_boxplot(data = df, aes(x = x, y = yc, group = x)) + # 原始数据
  geom_ribbon(aes(x = x, ymin = loCI, ymax = hiCI), col = “grey80”, alpha = 0.2) + # 95% CI
  geom_line(aes(x = x, y = 估计)) + # 中值估计
  facet_wrap(~a)

terior_summary(m2) %&gt;% data.frame() %&gt;% # 获取值
  rownames_to_column(var = &quot;pred&quot;) %&gt;% 过滤器(grepl(&quot;b_&quot;, pred)) %&gt;%
  mutate(ycF = if_else(grepl(“b_I”, pred), Estimate, Estimate + min(Estimate)), # 十年调整
         loCI = if_else(grepl(“b_I”, pred), Q2.5, Q2.5 + min(估计)),
         hiCI = if_else(grepl(“b_I”, pred), Q97.5, Q97.5 + min(估计))) %&gt;%
  切片(rep(row_number(), 3)) %&gt;%
  变异(d =rep(c(“70s”,“80s”,“90s”), 3),
         a = 代表(字母[1:3], 每个 = 3)) %&gt;%
  ggplot() +
  geom_boxplot(data = df, aes(x = d, y = yc, col = d)) + # 原始数据
  geom_linerange(aes(x = d, ymin = loCI, ymax = hiCI), 线宽 = 0.6) + # 95% CI
  geom_point(aes(x = d, y = ycF), shape = 1, size = 2) + # 中值估计
  facet_wrap(~a)

情节#1

情节#2
]]></description>
      <guid>https://stats.stackexchange.com/questions/643619/contrasting-credible-intervals-with-two-different-approaches</guid>
      <pubDate>Wed, 27 Mar 2024 00:20:12 GMT</pubDate>
    </item>
    <item>
      <title>反事实招聘决定的影响</title>
      <link>https://stats.stackexchange.com/questions/643618/impact-of-counterfactual-hiring-decisions</link>
      <description><![CDATA[作为我的小部件公司的招聘经理，为了决定是否让申请人参加面试，我进行了智商测试。如果申请人的测试分数高于 110 分，我会让他们参加招聘经理的面试，否则他们会立即被拒绝。
我的公司多年来一直这样做，因此有大量关于有多少候选人在后续面试中通过和失败的数据。
现在，我想增加成功申请者的数量，所以我想知道如果我也让所有智商测试达到 110 或声称拥有学士学位的申请者通过会发生什么在他们的应用程序中。对于这个问题，假设我有以前申请者的记录，并且我知道他们是否声称自己拥有学士学位（尽管当时这不是他们录取面试的标准）。
在反事实场景下，我可以采用什么方法来预测申请者的成功率，其中使用智商&gt;110或学士学位（而不是仅使用智商测试，我有实际数据）。这种方法的局限性/假设是什么？
答案应该考虑到智商测试结果和学士学位的存在作为因变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/643618/impact-of-counterfactual-hiring-decisions</guid>
      <pubDate>Wed, 27 Mar 2024 00:12:37 GMT</pubDate>
    </item>
    <item>
      <title>计算 R 中的 Marten 协方差返回非正定矩阵</title>
      <link>https://stats.stackexchange.com/questions/643617/calculating-marten-covariance-in-r-returns-matrices-that-are-not-positive-defini</link>
      <description><![CDATA[在 R 中，我试图计算 Marten 协方差矩阵，其输入是随机创建的距离矩阵。然而，我经常最终得到的协方差矩阵不是正定的，这没有什么意义。
起初，我在 StackOverflow 上问过这个问题的一个版本，但那里的一些评论让我确信代码没有错误。此外，我被告知虽然 Marten 协方差矩阵在理论上显然总是正定的，但实际上可能并非如此。
那时，我意识到这成为一个更适合 CrossValidated 的问题。所以，我想要理解的是如何确保在实践中生成正定的Marten协方差矩阵。
也许 Marten 方程参数之间存在特定关系来确保这一点？也许还有其他技巧 - 例如，有关确保正定性的更一般性问题实践通常通过简单地向距离矩阵的零对角线添加一个微小的常数来回答 - 这并不能解决我的问题。
作为参考，以下是我生成随机距离矩阵的方法：
nrows &lt;- 100
ncols &lt;- 100
d &lt;- 矩阵(runif(nrows*ncols, 0, 1), ncols, nrows)
# 强制对称：
d[下.tri(d)] &lt;- t(d)[下.tri(d)]
diag(d) &lt;- 0.000000000001 # 而不是零以避免数值问题
# 检查我们是否有正确的距离矩阵：
范围(d)

然后我遵循维基百科的 Marten 协方差公式：

# 计算Marten协方差矩阵：
西格玛 &lt;- 1
v &lt;- 3
p &lt;- 5
项 1 &lt;- (2**(1-v))/(gamma(v))
项 2 &lt;- (sqrt(2*v)*(abs(d)/p))**v
term3 &lt;- besselK(sqrt(2*v)*(abs(d)/p), nu = v)
m &lt;- (sigma**2)*term1*term2*term3

但是，当我检查 Marten 协方差矩阵的特征值时，我发现它不是一个正定矩阵，它应该是：
g &lt;- eigen(m, only.values=TRUE)
print(min(g$values)) # 应该大于零，但实际上是大约。 -0.15
print(sum(g$values&lt;0)/length(g$values)) # 因此，这应该为零，但实际上是大约。 0.46

令我惊讶的是，得出非正定 Marten 协方差矩阵是如此容易，然后我对如何确保正定性感到困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/643617/calculating-marten-covariance-in-r-returns-matrices-that-are-not-positive-defini</guid>
      <pubDate>Tue, 26 Mar 2024 23:00:18 GMT</pubDate>
    </item>
    <item>
      <title>我的模型是否过度拟合或者我的训练过程是否错误？</title>
      <link>https://stats.stackexchange.com/questions/643612/is-my-model-overfitting-or-is-my-training-process-wrong</link>
      <description><![CDATA[我正在使用 CatBoost 分类器预测多类概率。
我有一个平衡的数据集，大约有 4000 行、13 个特征、4 个目标类标签。数据集有一些异常值，我决定不删除它们。
我在分割数据时使用 random_state=42 ，并在超参数调整和使用最佳找到的超参数进行模型评估期间将其用作 CatBoost 参数。
我的模型训练和评估步骤：

将数据按 0.7:0.15:0.15 的比例分层划分为训练集、验证集和测试集。
使用 Optuna 执行超参数调整，使用 LogLoss 作为评估指标（在训练集上进行训练，在 val 集上进行评估），并使用 (X_val, y_val) 作为模型的 eval_set 来执行早期停止轮次 在超参数调整期间。
使用训练集上找到的最佳超参数来拟合模型 (model.fit(X_train, y_train))
预测 X_train 和 X_test 的概率：model.predict_proba(X_train) 和 model.predict_proba(X_test)
比较训练集和测试集的指标，结果如下：


&lt;标题&gt;


对数丢失
AUC-ROC
Brier 分数
ECE


&lt;正文&gt;

火车
0.30
0.99
0.07
0.05


测试
0.55
0.94
0.08
0.02



这些结果是否表明我的模型过度拟合，或者我的训练和评估步骤有问题？
LogLoss 的差异似乎很严重（我认为这是过度拟合的迹象），AUC-ROC 和 Brier Score 似乎大部分都很好（我认为？），而 ECE 在测试集上变得更好，我觉得很奇怪在过度拟合的情况下。此外，验证集上最好的 Optuna 试验 LogLoss 与我在超参数调整后在测试集上评估模型时得到的结果几乎相似。]]></description>
      <guid>https://stats.stackexchange.com/questions/643612/is-my-model-overfitting-or-is-my-training-process-wrong</guid>
      <pubDate>Tue, 26 Mar 2024 22:30:05 GMT</pubDate>
    </item>
    <item>
      <title>如何使用学习模型绝对误差的箱线图来比较\评估学习模型的性能？</title>
      <link>https://stats.stackexchange.com/questions/643610/how-boxplot-over-absolute-error-of-learning-models-could-be-used-to-compare-eval</link>
      <description><![CDATA[最近翻了这篇代表评测的论文通过 Boxplot 在 $Absolute~Error~(AE)$ 上显示单个数据集中各种模型的性能，如下所示：

&lt;标题&gt;




&lt;正文&gt;

图。图 12：我们的方法和 M1 先前研究的基线方法的箱线图。 参考



通常我们使用 $Mean~Absolute~Error~(MAE)$ 或 $Mean~Square~Error~( MSE)$等进行不同模型比较。
我已经检查了这篇文章：用示例解释箱线图但仍然有一些注意事项像：

集中趋势 中央趋势趋势 &amp; 中位数：定义和用途
变异性 变异性测量&lt; /a&gt;
偏度：偏态分布

我的问题：

如何解释这一表述？ （知道误差越低，模型就越好）
这是否意味着不使用 $mean$ 或 $average$ 进行误差计算，例如$Mean~Absolute~Error~(MAE)$ 通过条形图，可以在学习过程中收集所有误差估计并绘制箱线图？那么哪些额外信息可以翻译 MAE 上的经典条形图无法翻译的内容？

我不明白它背后的好处和逻辑是什么。
&lt;小时/&gt;
可能相关的帖子：

绝对误差作为评估模型的工具
根据平均绝对误差箱线图删除异常值以改进回归模型是否作弊&lt; /里&gt;
可以使用误差估计箱线图得出模型方差吗？
数据集上模型性能的“绝对”基准
平均绝对误差与总绝对误差
最低“推荐”值箱线图的样本大小？不同样本量的箱线图
我们应该如何用小样本绘制箱线图？
]]></description>
      <guid>https://stats.stackexchange.com/questions/643610/how-boxplot-over-absolute-error-of-learning-models-could-be-used-to-compare-eval</guid>
      <pubDate>Tue, 26 Mar 2024 21:49:55 GMT</pubDate>
    </item>
    <item>
      <title>非欧几里德空间上 k 中心点的间隙统计量的等效项</title>
      <link>https://stats.stackexchange.com/questions/643599/equivalent-of-gap-statistic-for-k-medoids-on-non-euclidean-spaces</link>
      <description><![CDATA[我有一个带有加权边的连通图。我想使用聚类算法将图划分为社区。我选择了 K-medoids，并在距离矩阵上运行它，其中距离 = 1 / (1 + 边权重)。
如果特征空间是欧几里得空间，我可以模拟特征上的均匀分布并计算“间隙统计量”作为真实数据上 k-medoids 的损失与模拟数据上 k-medoids 的损失之间的差异。但这个空间不是欧几里得空间，我认为我无法模拟均匀分布并计算间隙统计量。
如何选择最佳的簇数？]]></description>
      <guid>https://stats.stackexchange.com/questions/643599/equivalent-of-gap-statistic-for-k-medoids-on-non-euclidean-spaces</guid>
      <pubDate>Tue, 26 Mar 2024 19:41:15 GMT</pubDate>
    </item>
    <item>
      <title>时间序列模型规范</title>
      <link>https://stats.stackexchange.com/questions/643598/time-series-model-specification</link>
      <description><![CDATA[我想在 R 中运行回归分析来解释我的 DV g_law_tot 的变化，即从 t-1 到 t 的总预算增长率。我有 1994 年到 2023 年的年度数据。我有一些政治、制度和经济变量作为 IV。我对预测不感兴趣，只是想了解哪些是预算年度百分比变化最相关的解释因素。时间序列是正确的选择吗？我如何了解哪种特定模型最适合我的情况？我迷失在太多的视频、阅读材料和博客中。
这是我的 df：
df &lt;- 结构(列表(年份 = c(1994, 1995, 1996, 1997, 1998, 1999, 2000,
2001、2002、2003、2004、2005、2006、2007、2008、2009、2010、2011、
2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022,
2023), end_legislative_term = c(0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0),
    技术官僚 = c(0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0), C_enpp = c(7.88,
    7.88、6.07、6.07、6.07、6.07、6.07、5.45、5.45、5.45、5.45、
    5.45、5.09、5.09、3.08、3.08、3.08、3.08、3.08、3.52、3.52、
    3.52、3.52、3.52、4.38、4.38、4.38、4.38、5.64、5.64)、leading_ch = c(0,
    1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,
    0, 1, 0, 1, 0, 1, 0, 1, 0, 1), 转向中心 = c(0, 0,
    0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,
    1, 1, 1, 0, 0, 0, 0, 0, 0), gpd_growth = c(2.683230835, 1.266540391,
    1.830276287、1.810314719、1.625659888、3.78691271、1.951454556、
    0.25403202、0.13847967、1.424073911、0.817498767、1.790934831、
    1.486917388、-0.962084833、-5.280713695、1.713274462、0.707045938、
    -2.980514474、-1.841095694、-0.004870179、0.778657835、1.293374251、
    1.667491666、0.926246385、0.482993514、-8.974277401、8.313634284、
    3.724824143, 0.691742081, NA), g_law_tot = c(13.1533324313674,
    6.60474423446604、-11.8440505854976、2.8432575110453、10.6431848644662、
    7.29624633255459、2.81686804707955、-0.0275394074771063、
    -0.570750090159, -0.192522133860973, -0.553271817228385,
    -2.94082586015983、4.28422079688282、5.5247420527077、-4.450067276262、
    -0.0110042515499731, -3.47617754038942, -0.98458875847075,
    2.91395911842109、4.04542948833524、5.56044089389971、-2.05342343455547、
    -0.0998891519709444、2.70233019929693、2.48770368114364、
    2.31876491767493、15.1682979912092、6.53052765440996、4.09519458060663、
    -4.94486838456369)), row.names = c(NA, -30L), class = c(“tbl_df”,
“tbl”、“data.frame”））
]]></description>
      <guid>https://stats.stackexchange.com/questions/643598/time-series-model-specification</guid>
      <pubDate>Tue, 26 Mar 2024 19:33:31 GMT</pubDate>
    </item>
    <item>
      <title>不同回归模型中相同 X 的 p 值的 FDR</title>
      <link>https://stats.stackexchange.com/questions/643595/fdr-for-p-values-of-the-same-x-accross-different-regression-models</link>
      <description><![CDATA[我有 3 个 X 变量和 44 个 Y：

年龄（连续）(X)
性别（二进制）(X)
microRNA（连续）(X)（感兴趣的变量）
大脑区域（连续）(Y)

我们的问题是，在控制年龄和性别的影响的情况下，microRNA 是否可以预测大脑区域。我对每个 Y 执行了一系列回归模型来解决我们的问题。
我的主管说，因为我们的 Y 变量并不完全独立，所以我们必须纠正 beta 系数的 p 值。
我想执行 FDR 程序，但我有点困惑：
1- 我应该对所有 p 值（年龄、性别和 microRNA）执行 FDR 程序，还是应该对每个 X 变量分别执行？ （请注意，年龄和性别对我们来说都不重要，将其输入模型只是为了控制其影响。）
2- 纠正来自不同回归模型的一组 p 值是否有意义？我分别修正了每个模型的贝塔系数，但我的主管不同意。
Edit1：请注意，我们的研究问题需要对每个 Y 变量进行单独分析，不能将其作为解决方案进行更改。
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/643595/fdr-for-p-values-of-the-same-x-accross-different-regression-models</guid>
      <pubDate>Tue, 26 Mar 2024 19:15:26 GMT</pubDate>
    </item>
    <item>
      <title>依赖预测变量的回归、动物研究样本量</title>
      <link>https://stats.stackexchange.com/questions/643592/regression-with-depended-predictors-animal-study-sample-size</link>
      <description><![CDATA[我有几个问题需要帮助，

我的预测因素之一是治疗和控制。另一个预测因素是剂量。治疗组有 4 种剂量水平，而对照组只有一种。我仍然可以使用回归、模型治疗/对照和剂量作为两个预测因子吗？包含交互效果更好吗？

同样，一种预测基因型有两个水平：TG 和 WT。治疗和对照均可适用于 TG 动物，而 WT 动物仅接受治疗。我应该使用两个预测变量还是将它们合并为一个，例如TG 处理、TG 对照、WT 处理？

是功率分析的标准样本量计算，或新开发的方法，例如Hsieh 1998，适用于动物研究吗？由于种族原因，人们试图尽可能减少动物研究的样本量。线性回归的一般规则，每个变量 10 个观察值，不应该适用于动物，对吗？


谢 F. Y.、布洛赫 D. A. 和拉森医学博士（1998）。线性和逻辑回归样本量计算的简单方法。医学统计，17(14), 1623–1634。]]></description>
      <guid>https://stats.stackexchange.com/questions/643592/regression-with-depended-predictors-animal-study-sample-size</guid>
      <pubDate>Tue, 26 Mar 2024 18:59:21 GMT</pubDate>
    </item>
    <item>
      <title>更好的功能来适应类似日志的数据？</title>
      <link>https://stats.stackexchange.com/questions/643589/better-function-to-fit-log-like-data</link>
      <description><![CDATA[我正在尝试将双参数函数拟合为如下所示的数据（黑点，x 刻度为对数）：

我能找到的最合适的是 $arctan$，由 MSE 测量。我测试的所有七个函数和Python代码如下所示。
是否有更好的函数来适应我可能忽略的这些数据？
&lt;小时/&gt;
&lt;前&gt;&lt;代码&gt;
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt


def main():
    x = np.array([0.033, 0.062, 0.104, 0.210, 0.424, 0.861, 1.040, 1.133, 1.935, 3.803, 6.289, 11.519, 29.118])
    y = np.array([
        0.077、0.149、0.187、0.229、0.299、0.419、0.469、0.499、0.679、0.806、
        0.888, 0.928, 0.956])

    N = 100
    对于 i，func in enumerate((f1, f2, f3, f4, f5, f6, f7))：
        beta_opt、alpha_opt、delta_old = np.nan、np.nan、np.inf
        对于 np.linspace(0., 2, N) 中的 alpha：
            对于 np.linspace(0., 5, N) 中的 beta：
                y_fit = func(x, 阿尔法, 贝塔)
                delta = np.square(y - y_fit).sum()
                如果 delta &lt;增量_旧：
                    beta_opt, alpha_opt = 贝塔, 阿尔法
                    delta_old = 增量
        x0 = np.linspace(0.01, 30, 100)
        y0 = func(x0, alpha_opt, beta_opt)
        plt. 绘图（
            x0, y0, ls=&#39;:&#39;, lw=2,
            label=“f{}, alpha={:.3f}, beta={:.3f}, MSE={:.3f}”.format(i+1, alpha_opt, beta_opt, delta_old))

    plt.scatter(x, y, c=&#39;k&#39;)
    plt.xscale(&#39;日志&#39;)
    plt.图例()
    plt.show()

def f1(x, 阿尔法, 贝塔):
    返回 alpha + beta*np.log(x)

def f2(x, 阿尔法, 贝塔):
    返回 alpha*np.tanh(x*beta)

def f3(x, 阿尔法, 贝塔):
    返回 alpha + beta*np.tanh(x)

def f4(x, 阿尔法, 贝塔):
    返回 1/(alpha+beta*np.exp(-x))

def f5(x, 阿尔法, 贝塔):
    返回 alpha + 1/(1+beta*np.exp(-x))

def f6(x, 阿尔法, 贝塔):
    返回 alpha - np.exp(-beta*x)

def f7(x, 阿尔法, 贝塔):
    返回 alpha + beta*np.arctan(x)


如果 __name__ == &#39;__main__&#39;:
    主要的（）
]]></description>
      <guid>https://stats.stackexchange.com/questions/643589/better-function-to-fit-log-like-data</guid>
      <pubDate>Tue, 26 Mar 2024 18:57:16 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 的 ar() 和 lm() 之间的系数差异？</title>
      <link>https://stats.stackexchange.com/questions/643573/difference-in-coefficients-between-ar-and-lm-using-r</link>
      <description><![CDATA[当我使用 ar(method=&quot;ols&quot;) 时，它应该返回与 lm() 相同的结果，对吗？它没有：
&lt;前&gt;&lt;代码&gt;# AR
设置.种子(12345)
n &lt;- 100
y &lt;- as.numeric(arima.sim(列表(ar = 0.6), n = n))
model_ar &lt;- ar(y, method = &quot;ols&quot;, order.max = 1, demean = TRUE, aic = FALSE)
model_lm &lt;- lm(y[2:n] ~ y[1:(n - 1)])

c(model_ar$x.intercept, model_ar$ar) # 查看 coefs ar
model_lm$coefficients # 查看系数 lm()

结果：斜率相同，截距不同。为什么？如何手动复制 ar() 结果？
&lt;前&gt;&lt;代码&gt;# 结果：
# r$&gt; c(model_ar$x.intercept, model_ar$ar) # 查看 coefs ar
# [1] -0.009013242 0.532853591

# r$&gt; model_lm$系数 # 查看系数 lm()
#（截取）y[1:(n - 1)]
# 0.2478445 0.5328536

（类似问题此处和这里但它们不一样.他们询问的是 arima() 而不是 ar()，或者问题是关于 coef 的重要性，而不是估计。）]]></description>
      <guid>https://stats.stackexchange.com/questions/643573/difference-in-coefficients-between-ar-and-lm-using-r</guid>
      <pubDate>Tue, 26 Mar 2024 15:17:24 GMT</pubDate>
    </item>
    <item>
      <title>在重复测量实验中使用两个中介进行 R 中介分析（受试者内设计）</title>
      <link>https://stats.stackexchange.com/questions/643570/mediation-analysis-in-r-with-two-mediators-in-a-repeated-measure-experiment-wit</link>
      <description><![CDATA[我目前面临挑战，非常感谢您的帮助。我正在尝试使用 R 在受试者内设计实验中对两个中介进行中介分析。以下是我的情况的简要概述：
研究问题：我正在研究自变量（可以取绿色、黄色或红色值）和单个因变量之间的关系。
中介分析：我的分析涉及两个中介，我想了解这些中介如何影响自变量和因变量之间的关系。
之前的尝试：最初，我尝试使用 R 中的 PROCESS 函数进行中介分析。然而，我遇到了困难，因为该函数没有考虑重复测量，而这在我的研究设计中至关重要。
当前方法：经过进一步探索，我发现了中介包。虽然这个函数似乎很有希望处理重复的测量，但我不确定它是否可以容纳两个中介的分析。同样，我不确定 lameer 函数在这种情况下的功能。
如果您能指导如何进行此分析，我将不胜感激。任何关于合适的 R 包或用两个中介进行中介分析的方法的见解或建议，特别是在重复测量的研究中，都将非常有价值。
非常感谢您考虑我的请求。非常感谢您的专业知识和帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/643570/mediation-analysis-in-r-with-two-mediators-in-a-repeated-measure-experiment-wit</guid>
      <pubDate>Tue, 26 Mar 2024 14:32:26 GMT</pubDate>
    </item>
    <item>
      <title>是否可以计算多元线性回归中特定 beta 系数的功效？</title>
      <link>https://stats.stackexchange.com/questions/643560/is-it-possible-to-calculate-the-power-for-a-specific-beta-coefficient-in-a-multi</link>
      <description><![CDATA[我想进行多元线性回归，其中我只对解释一个 beta 系数感兴趣，但我将调整两个额外的协变量（即总共三个变量）。是否有可能计算出我给定 150 个样本量的功效，以在给定这两个其他协变量的情况下检测我感兴趣的解释变量中的标准化 beta 系数（比方说）0.3？如果是这样，我需要哪些额外信息？是否有 R 包或代码可以为我运行计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/643560/is-it-possible-to-calculate-the-power-for-a-specific-beta-coefficient-in-a-multi</guid>
      <pubDate>Tue, 26 Mar 2024 12:40:47 GMT</pubDate>
    </item>
    <item>
      <title>比较具有不同预测概率的不公平抛硬币序列</title>
      <link>https://stats.stackexchange.com/questions/643537/comparing-sequence-of-unfair-coin-flips-with-different-predicted-probabilities</link>
      <description><![CDATA[假设我们有 $n$ 个独立硬币，每个硬币正面朝上的概率未知且不同。我们有一台神奇的机器，可以猜测每枚硬币正面朝上的概率。对于 $n=5$ 硬币，其猜测可能类似于 0.03, 0.45, 0.17, 0.91, 0.76。然后，我们将每枚硬币翻转一次并记录结果，可能是正面、反面、反面、正面、正面。我们的问题：是否有统计测试可以评估机器的准确性？
我的第一个直觉是像 Pearson 那样的卡方检验，或者可能是 G 检验，如果正面朝上，我们的观察值为 1，否则为 0。然而，数据不是分类的，观测值的总和也不是已知的常数。我还考虑了柯尔莫哥洛夫-斯米尔诺夫检验来比较预期与观察到的结果，但概率分布都不是。
我不确定如何用数学方式表达我的偏好，但我会尝试定性地表达它们：

编辑：机器对 $p=0.5$ 的任何预测都应该被解释为机器有证据表明，具有该概率的硬币中有 50% 会出现正面，如果具有该概率的硬币出现正面的比例非常接近 50%，则应获得相应奖励；这并不意味着机器毫无头绪并且在正面/反面方面矛盾
准确度主要取决于正面比率：例如，当机器对一组硬币的猜测为 0.2 时，如果 5 枚中有 1 枚正面朝上，或者 50 枚中有 11 枚正面朝上，我们就应该认为它是准确的，但是如果 5 个头中有 3 个落地则不准确
真实概率可能不是从 0 到 1 均匀分布
可选：准确性应该能够合理地容忍单一的、极不可能发生的事件

很抱歉，如果之前有人问过类似的问题，我对这个网站和统计数据都很陌生，但希望这个问题足够清楚。
编辑：作为对已发布答案的回应，我们不寻找伯努利正确的评分规则。要了解原因，假设我们的机器预测所有 100 个硬币的 $p=0.5$。在情况 A 中，50 个硬币正面朝上，在情况 B 中，95 个硬币正面朝上。显然，机器在情况 A 中的预测能力更好，这一点应该在我们的测试中得到体现。然而，例如，对数损失和 Brier 评分规则在两种情况下都会返回相同的分数：
$$\text{对数损失分数，情况 A}=-\frac{1}{100}\left(\sum_{n=0}^{50}\ln0. 5+\sum_{n=51}^{100}\ln(1-0.5)\right)\约0.69$$
$$\text{对数损失分数，情况 B}=-\frac{1}{100}\left(\sum_{n=0}^{95}\ln0. 5+\sum_{n=96}^{100}\ln(1-0.5)\right)\约0.69$$
$$\text{Brier分数，情况A}=\frac{1}{100}\left(\sum_{n=0}^{50}(1-0.5)^ 2+\sum_{n=51}^{100}(0-0.5)^2\right)=0.25$$
$$\text{Brier分数，情况B}=\frac{1}{100}\left(\sum_{n=0}^{95}(1-0.5)^ 2+\sum_{n=96}^{100}(0-0.5)^2\right)=0.25$$
机器的预测应该进行总体评估。机器的单独预测不应根据其单独的相应结果进行评估。]]></description>
      <guid>https://stats.stackexchange.com/questions/643537/comparing-sequence-of-unfair-coin-flips-with-different-predicted-probabilities</guid>
      <pubDate>Tue, 26 Mar 2024 08:23:50 GMT</pubDate>
    </item>
    </channel>
</rss>