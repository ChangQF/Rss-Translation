<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 18 Jan 2025 01:12:04 GMT</lastBuildDate>
    <item>
      <title>如何根据诊断图改进线性模型</title>
      <link>https://stats.stackexchange.com/questions/660185/how-to-improve-linear-model-based-on-diagnostic-plots</link>
      <description><![CDATA[我一直在处理包含五个变量和一个响应的数据集，如下所示：
.CSV 文件
使用 Python，我从以下代码开始：
import statsmodels.api as sm
import numpy as np
X = subset[[&#39;X1&#39;, &#39;X2&#39;, &#39;X3&#39;, &#39;X4&#39;]]
y = subset[&#39;Y&#39;]
X = sm.add_constant(X)
model = sm.OLS(y, X)
result = model.fit()
plt.figure(figsize=(8, 6))
plt.scatter(fitted_values, residuals, color=&#39;blue&#39;, edgecolors=&#39;k&#39;, alpha=0.7)
plt.axhline(y=0, color=&#39;red&#39;, linestyle=&#39;--&#39;)
plt.title(&#39;残差 x 预测值&#39;)
plt.xlabel(&#39;预测值&#39;)
plt.ylabel(&#39;残差&#39;)
plt.show()

给出模型摘要：

我不知道如何处理“残差 x 预测图”的结果。在探索性分析过程中，我发现这些变量与 Y 有中等相关性，因此我选择它们来构建初始模型。从该图中，我们可以说方差不是恒定的吗？此外，从这种模式中，我们可以获得有关如何改进模型的任何见解吗？

我尝试对 X 变量应用对数或 box-cox 变换，但它并没有改变变量散点图的可视化。我考虑过应用加权最小二乘法，例如，对 Y 大于 100 的位置赋予较低的权重，但图并没有改善，模式几乎相同。或者如果它真的是一个非线性问题，我想如果一些机器学习方法在这里可以更好地发挥作用，但我首先想尝试基本方法。
如果有人能提供一些想法/代码来处理这种情况，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660185/how-to-improve-linear-model-based-on-diagnostic-plots</guid>
      <pubDate>Fri, 17 Jan 2025 20:39:09 GMT</pubDate>
    </item>
    <item>
      <title>评估混合模型聚类和分类的准确性</title>
      <link>https://stats.stackexchange.com/questions/660184/evaluating-accuracy-of-mixture-model-clustering-and-categorisation</link>
      <description><![CDATA[我正在运行混合模型，我没有自由参数，我只是让它评估给定数据点属于一个集群的可能性。另外，我有一个关于这些值的基本事实，但模型从未见过。我想测试模型是否成功预测了数据点集群的可能性。您建议哪些指标最适合此目的？
交叉熵 RMSE MAE 和其他指标是好的指标吗？
（我知道经典模型比较 - 例如，BIC、AIC、WAIC CV_LOO 等等，但我不是在测试我的模型是否是最佳模型，而是在测试它是否能够预测聚类）]]></description>
      <guid>https://stats.stackexchange.com/questions/660184/evaluating-accuracy-of-mixture-model-clustering-and-categorisation</guid>
      <pubDate>Fri, 17 Jan 2025 19:23:57 GMT</pubDate>
    </item>
    <item>
      <title>帮助理解吉布斯采样问题？</title>
      <link>https://stats.stackexchange.com/questions/660183/help-understanding-gibbs-sampling-problem</link>
      <description><![CDATA[我正在努力理解一个特定的问题，并设计了一个类似的场景
如果我要分析三组就读寄宿学校的学生，每组学生分别在两个教室中的一个，并住在三个宿舍中的一个，那么这些数据可以可视化为如下所示的有向无环图。
如果一名教职员工试图找出每个组、房间和宿舍对特定学生结果的影响，他们将如何做，以及可以以何种确定性收集这些信息？
假设成绩遵循某种偏态分布$P(\Theta_G = \theta_G, \Theta_R = \theta_R, \Theta_D = \theta_D)$其中$\theta_G\in\{1,2,3\}$
这个过程中边际是如何计算的，是否必须使用吉布斯抽样，还是可以通过代数过程，如何完成？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660183/help-understanding-gibbs-sampling-problem</guid>
      <pubDate>Fri, 17 Jan 2025 18:53:38 GMT</pubDate>
    </item>
    <item>
      <title>季节性虚拟变量回归。为什么我们要在这个回归中使用时间趋势？或者说，在什么情况下我们应该使用时间趋势？</title>
      <link>https://stats.stackexchange.com/questions/660180/regression-with-seasonal-dummies-why-do-we-use-time-trend-in-this-regression-o</link>
      <description><![CDATA[我的导师希望我用季节性虚拟变量进行回归分析。
我有 DPPI 指数（土耳其国内生产者价格指数），这是月度数据。
首先，我需要用截距项和 11 个虚拟变量进行回归分析。
其次，我需要用 12 个虚拟变量进行不带截距项的回归分析。
在这两种情况下，我都应该包括时间趋势项吗？在哪种情况下，或者为什么包括时间趋势项？
或者，我应该同时使用和不使用时间趋势项进行这两个回归分析吗？
我的最后一个问题是我需要分析残差。为此，我应该对残差应用哪些测试或图？
请与我分享您的想法。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660180/regression-with-seasonal-dummies-why-do-we-use-time-trend-in-this-regression-o</guid>
      <pubDate>Fri, 17 Jan 2025 18:42:39 GMT</pubDate>
    </item>
    <item>
      <title>在高斯 - 马尔可夫假设中，给定预测变量的误差条件期望等于协方差[重复]</title>
      <link>https://stats.stackexchange.com/questions/660178/conditional-expectation-of-errors-given-predictors-equals-covariance-in-gauss-ma</link>
      <description><![CDATA[在此视频的 2:08 处，谈到 OLS 中的高斯-马尔可夫假设，Ben Lambert 说$\mathbb{E}(​​u_i|x_i)=0$ 等同于$Cov(u_i, x_i)=0$，用数学符号表示为$\mathbb{E}(​​u_i|x_i)=0 \Leftrightarrow Cov(u_i, x_i)=0$。
这是为什么？
你如何证明这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/660178/conditional-expectation-of-errors-given-predictors-equals-covariance-in-gauss-ma</guid>
      <pubDate>Fri, 17 Jan 2025 18:35:59 GMT</pubDate>
    </item>
    <item>
      <title>使用对数链接解释 GLM 模型中的系数</title>
      <link>https://stats.stackexchange.com/questions/660177/interpretation-of-the-coefficients-in-a-glm-model-using-the-log-link</link>
      <description><![CDATA[当在 GLM 设置中使用对数链接时，目标均值和线性预测器通过以下方式关联：
$$
\mu = e^{\beta_0}\prod_{i=1}^p e^{\beta_i X_i}
$$
我的学习手册说，当 $X_j$ 是具有系数 $\beta_j$ 的数字预测器时，我们可以用以下方式描述 $X_j$ 和 $\mu$ 之间的关联

当所有其他变量保持不变时，$X_j$ 的单位增加与乘法增加相关目标均值增加 $e^{\beta_j}$ 倍，即
$$
\text{new} \ \mu = e^{\beta_j} \times \ \text{old} \ \mu \tag{1}
$$

我不确定作者是如何得出这个解释的。我认为这个过程看起来像是这样的
$$
\frac{\partial \mu}{\partial X_j} = \beta_j \times e^{\beta_0}\prod_{i=1}^p e^{\beta_i X_i} = \beta_j \times \text{old} \ \mu \tag{2}
$$
所以
$$
\text{new} \ \mu = \text{old} \ \mu + \frac{\partial \mu}{\partial X_j} = \text{old} \ \mu + \beta_j \times \text{old} \ \mu = (\text{old} \ \mu )(1 + \beta_j) \tag{3}
$$
显然，$(1)$ 和 $(3)$ 完全不同，所以我不确定我的错误是什么。我在 $(2)$ 或 $(3)$ 中的工作是否不正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/660177/interpretation-of-the-coefficients-in-a-glm-model-using-the-log-link</guid>
      <pubDate>Fri, 17 Jan 2025 18:31:37 GMT</pubDate>
    </item>
    <item>
      <title>条件与边际：概率、可能性和模型</title>
      <link>https://stats.stackexchange.com/questions/660175/conditional-vs-marginal-probability-likelihood-and-models</link>
      <description><![CDATA[我很难理清这些想法。
1) 条件概率与边际概率：这是我最了解的一个，它依赖于概率的基本定律。
如果我们有两个连续随机变量 $X$ 和 $Y$。
$X$ 的边际概率密度函数，表示为 $f_X(x)$，是通过对 $Y$ 所有可能值的联合 PDF 进行积分获得的：
$$f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) dy$$
给定 $Y=y$，$X$ 的条件概率密度函数：
$$f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}$$
$$f_{X|Y}(x|y) = \frac{f_{Y|X}(y|x)f_X(x)}{f_Y(y)}$$
到目前为止一切正常。
2) 条件似然与边际似然：这个我也理解，因为它是一个第一部分的扩展。
我可以定义一个联合似然函数$L(\theta, \phi|X)$为：
$$L(\theta, \phi|X) \propto f_X(X|\theta, \phi)$$
从这里，边际似然和条件似然可以写成：
$$L_M(\theta|X) = \int_{-\infty}^{\infty} L(\theta, \phi|X) d\phi$$
$$L_C(\theta|X,\phi) = L(\theta, \phi|X)$$
3) 条件模型与边际模型（第 1 部分） 事情开始让我感到困惑。我以前听说过“条件和边际”这两个术语用于混合效应回归模型。例如，在纵向/聚类模型的背景下，我听说过以下内容：

像 GEE（一般估计方程）这样的回归框架被称为边际模型，因为它们估计整个总体的边际平均值。虽然 GEE 能够在估计阶段使用数据中存在的聚类级相关性，但最终模型无法在聚类级别提供任何统计推断。 GEE 只能描述整个人口层面上正在发生的事情。

$$ \text{logit}(P(Y_{ij} = 1|X_{ij})) = X_{ij}\beta^* $$

另一方面，混合/随机效应等回归框架被称为条件模型，因为它们可以通过其随机效应结构在集群级别提供统计推断。举例来说，聚类级别均值可以看作是条件均值（即以聚类为条件）。

$$ \text{logit}(P(Y_{ij} = 1|X_{ij}, b_i)) = X_{ij}\beta + b_i $$
我认为在我看来这一切都是合理的。
4) 条件模型与边际模型（第 2 部分）：我感到困惑的根源来自这里：https://en.wikipedia.org/wiki/Conditional_logistic_regression。虽然我并没有完全理解这一点，但这似乎是一种固定效应回归，我们不再对估计集群级别效应感兴趣。相反，我们似乎根据某些集群级别信息集来匹配人员，以避免变量混淆。这是维基百科上关于条件逻辑回归的一个示例 - 这次我们不是估计聚类级别的影响（就像在随机影响中所做的那样），而是对它们进行匹配以控制它们的影响：
$$P(Y_{i1}=1, Y_{i2}=0|X_{i1},X_{i2}, Y_{i1}+Y_{i2}=1) = \frac{\exp(\beta^TX_{i1})}{\exp(\beta^TX_{i1}) + \exp(\beta^TX_{i2})}$$
因此，似乎在所有这些情况下，被条件化的术语及其条件化方式都会发生变化。
我说得对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660175/conditional-vs-marginal-probability-likelihood-and-models</guid>
      <pubDate>Fri, 17 Jan 2025 17:36:04 GMT</pubDate>
    </item>
    <item>
      <title>采用交错干预且无对照组的混合效应中断时间序列分析</title>
      <link>https://stats.stackexchange.com/questions/660174/mixed-effects-interrupted-time-series-analysis-with-staggered-intervention-and-n</link>
      <description><![CDATA[我有在不同时间点在不同县（集群）实施的干预措施的数据。我该如何评估干预措施的影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/660174/mixed-effects-interrupted-time-series-analysis-with-staggered-intervention-and-n</guid>
      <pubDate>Fri, 17 Jan 2025 17:20:45 GMT</pubDate>
    </item>
    <item>
      <title>如何用 SE 和 P 值计算每 100,000 个比率之间的差异</title>
      <link>https://stats.stackexchange.com/questions/660173/how-to-calculate-the-difference-between-2-rates-per-100-000-with-se-and-p-value</link>
      <description><![CDATA[我有一个数据集，其中包含每年记录的每 100,000 人口年龄调整死亡率及其针对特定疾病的标准误差 (SE)。数据来自 CDC Wonder 数据库。
我旨在通过计算差异、构建置信区间 (CI) 和确定此差异的 p 值来比较两个特定年份之间的死亡率。
此外，我旨在通过以下方式计算相对比率变化：
$$
\text{相对变化} = \frac{(\text{第 2 年比率} - \text{第 1 年比率})}{\text{第 2 年比率}}
$$
这在统计上合适吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660173/how-to-calculate-the-difference-between-2-rates-per-100-000-with-se-and-p-value</guid>
      <pubDate>Fri, 17 Jan 2025 16:46:06 GMT</pubDate>
    </item>
    <item>
      <title>伪似然与似然的比较</title>
      <link>https://stats.stackexchange.com/questions/660172/pseudolikelihood-compared-to-likelihood</link>
      <description><![CDATA[假设我们有一个离散多元概率分布，其密度$f_{\theta}(X=(x_1,\ldots,x_n))=\frac{g_{\theta}(X=(x_1,\ldots,x_n))}{Z}$取决于某个参数$\theta$。我特意以这种形式将其写出，以表示 Z 是难以计算的归一化常数（它也可能依赖于$\theta$）。这种分布的伪似然函数（为简单起见，针对单个数据点）是否定义为：
$$
PL_{\theta}(X=(x_1,\ldots,x_n)) = \prod_{i}f_{\theta}(X_i=x_i | X_j=x_j, i \neq j)
$$
如果是这样，则由此得出的公式在我看来有点奇怪，因为：
$$
= \prod_{i}\frac{g_{\theta}(X)}{\sum_{X_i=a}g_{\theta}(X_1=x_1,\ldots,X_i=a,\ldots)}
$$
调用分母 $Z_i(X)$ 可得到：
$$
\log(PL_{\theta}(X=(x_1,\ldots,x_n))) = n \log(g_{\theta}(X)) - \sum_i \log( Z_i(a))
$$
而真实可能性为
$$
\log(L_{\theta}(X=(x_1,\ldots,x_n))) = \log(g_{\theta}(X)) - \log(Z)
$$
我不知道为什么伪对数可能性可以替代对数可能性。我确实知道计算起来比可能性容易得多，但我无法理解为什么这是一个可接受的估计值。原始文章（格点数据的统计分析）在这方面没有太大帮助，维基百科上的文章也很简短。我知道现在人们可能更喜欢蒙特卡洛方法，但我仍然想了解一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/660172/pseudolikelihood-compared-to-likelihood</guid>
      <pubDate>Fri, 17 Jan 2025 16:25:55 GMT</pubDate>
    </item>
    <item>
      <title>加权交叉熵的理论依据</title>
      <link>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</link>
      <description><![CDATA[假设我们正在构建一个二元分类模型，可以将其视为学习函数
$$ p : X \mapsto [0, 1] $$
其中$p(X) := \mathbb{P}(Y=1|X)$，而$\hat{p}$是某种机器学习模型（例如神经网络）。
常用的损失函数是最小化$p$和$\hat{p}$之间的负交叉熵：
$$ l(p, \hat{p}) = -y\log \hat{p}(x) - (1-y)\log(1-\hat{p}(x))$$
这当然相当于模型$Y|X \sim Bernoulli(p(X))$的最大似然估计。
在某些情况下，结果高度不平衡，这使得训练在实践中变得困难。例如，如果数据是垃圾邮件分类，其中只有 1% 的结果是垃圾邮件，那么很容易收敛到一个简单的解决方案/局部最优，它只为每个观察设置$p(X) \approx 0$。理论上，在大样本量和全局最优的情况下，这不是问题 - 但在实践中，这可能是一个大问题。
解决这个问题的一种常见方法是使用“加权交叉熵”损失，其中权重与观察到的频率成比例。例如，
$$w_0 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=0\}}, w_1 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=1\}} $$
损失为
$$ l^{weighted}(p, \hat{p}) = -w_1y\log\hat{p}(x) - w_0(1-y)\log(1-\hat{p}(x)) $$
其中直觉是稀有类别的权重更高，因此模型“更加关注”对这些观察结果。

通过最小化这个加权损失函数找到的最优函数 $\hat{p}^{weighted}$ 是否有任何已知的理论性质，还是纯粹是启发式的？在全局最优值中，最优 $\hat{p}$ 和 $\hat{p}^{weighted}$ 相比如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</guid>
      <pubDate>Fri, 17 Jan 2025 09:25:45 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归中的虚拟变量与虚拟变量交互作用</title>
      <link>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</link>
      <description><![CDATA[我正在 R 中进行泊松回归，以估计按年龄组和病毒分类的死亡人数，其中相互作用的项是因子：
model &lt;- glm(death_count ~ strain * cohort + age + year,
family = poisson(link = &quot;log&quot;),
offset = log(exposure),
data = df)

我的 df 是面板数据，其中包含每年特定年龄的死亡人数。每年都以特定病毒为特征，每个年龄分配一个群体。我试图找出以病毒 C 为特征的年份中死亡人数减少的统计意义。以下是简化的回归输出：
 估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -15.39575 0.07621 -202.012 &lt; 2e-16 ***
病毒A -1.29389 0.08358 -3.516 0.000437 ***
病毒B 2.80059 0.06230 12.851 &lt; 2e-16 ***
病毒C 4.22142 0.05298 60.800 &lt; 2e-16 ***
群组X -2.99472 0.02494 -39.890 &lt; 2e-16 ***
群组Y -1.76074 0.02747 -27.691 &lt; 2e-16 ***
群组Z -1.31331 0.03499 -8.953 &lt; 2e-16 ***
病毒A：群组X 1.39666 0.07366 5.385 7.24e-08 ***
病毒B：群组X 1.21714 0.05685 3.820 0.000134 ***
病毒C：群组X -3.97906 0.03390 -28.883 &lt; 2e-16 ***
病毒A：队列Y 1.24520 0.10246 2.393 0.016701 * 
病毒B：队列Y 1.05056 0.07980 0.634 0.526360 
病毒C：队列Y -1.43923 0.03422 -12.836 &lt; 2e-16 ***
virusA:cohortZ 0.12472 0.13408 0.930 0.352274 
virusB:cohortZ -0.33748 0.11851 -2.848 0.004404 ** 
virusC:cohortZ -1.13441 0.04187 -3.210 0.001327 ** 

我知道没有交互项的系数是与参考组相比的，但我听说在泊松回归中，交互项并不那么简单。
我有兴趣解释为什么与队列 Y 和 Z 相比，队列 X 感染病毒 C 的死亡率减少幅度最大。我不太明白如何理解交互系数，我也不明白为什么截距为负。如果没有偏移量，截距 = 0.18252，我无法理解这一点，因为我认为添加偏移量会将 DV 变成速率。]]></description>
      <guid>https://stats.stackexchange.com/questions/660136/dummy-by-dummy-interaction-in-poisson-regression</guid>
      <pubDate>Fri, 17 Jan 2025 00:16:33 GMT</pubDate>
    </item>
    <item>
      <title>在 Anderson-Gill 模型中，tstart 和 tstop 可以相同吗？</title>
      <link>https://stats.stackexchange.com/questions/660134/can-tstart-and-tstop-be-the-same-in-an-anderson-gill-model</link>
      <description><![CDATA[我正在处理事件发生时间数据，并使用 R 中生存包的 coxph() 函数中实现的 Anderson-Gill 模型。在此模型中，时间间隔由 tstart（开始时间）和 tstop（停止时间）定义，我需要了解如何处理 tstart == tstop 的间隔。
具体来说，我想知道：
在 Anderson-Gill 模型中，tstart 和 tstop 相同是否有效？
如果不是，零长度间隔的含义是什么，应该如何处理？
例如，考虑以下数据集：



id
tstart
tstop
event




1
0
10
1


1
10
10
1


2
5
5
1



当我尝试使用 coxph(Surv(tstart, tstop, event) ~ 1, data = my_data)，我收到有关 tstart == tstop 的警告。我理解零长度间隔并不代表有意义的风险时间，但我想确认解决这种情况的最佳方法。
我应该如何处理这些情况？我应该：排除 tstart == tstop 的行？为 tstop 添加一个小值（例如，tstop = tstart + 1e-5）？还有其他推荐的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660134/can-tstart-and-tstop-be-the-same-in-an-anderson-gill-model</guid>
      <pubDate>Thu, 16 Jan 2025 23:19:41 GMT</pubDate>
    </item>
    <item>
      <title>进行缺失数据插补是否会导致观测值之间的依赖性？</title>
      <link>https://stats.stackexchange.com/questions/660127/does-doing-missing-data-imputation-lead-to-dependency-between-observations</link>
      <description><![CDATA[当对数据集的所有观测值进行插补时，这是否会导致观测值之间的依赖性？那么假设观测值是独立的统计模型是否不够充分？
我理解，在观测值中的变量之间当然存在关系/依赖性。我对观测值之间的依赖性很好奇。
两个观测值$y_i$和$y_j$，它们是独立随机抽样的，因此$y_i \perp\!\!\perp y_j$。 $y_i$ 缺失，并且使用 $y_j$ 或更多观测值的函数来输入 $y_i$
例如，$K$ 个最近邻域。根据不缺失的 $X$ 找到 $K$ 个最近的观测值，然后将其归结为 $y_i = 1/K\sum_j^K y_j$。
$y_i$ 是 $K$ 个观测值 $y$ 变量的函数，这是否意味着 $y_i$ 和 $K$ 个观测值 $y$ 是相关的？]]></description>
      <guid>https://stats.stackexchange.com/questions/660127/does-doing-missing-data-imputation-lead-to-dependency-between-observations</guid>
      <pubDate>Thu, 16 Jan 2025 20:41:13 GMT</pubDate>
    </item>
    <item>
      <title>BAM mgcv 算法的收敛性</title>
      <link>https://stats.stackexchange.com/questions/660053/convergence-of-bam-mgcv-algorithm</link>
      <description><![CDATA[在之前的文章中，我描述了 mgcv 的 BAM 算法的可重复性问题，并得到了非常有用的反馈：BAM mgcv 算法的可重复性
然而，可重复性并不是我观察到的唯一问题。在某些例子中，我还发现 bam() 无法收敛。
最小可重现示例
以下内容基于由协变量 x、y 和目标变量 z 组成的 20,000 个数据点的数据集，可在此处下载：https://drive.google.com/file/d/14ltM1Z4O9WW7h1jkrAp52v4meiauGsME/view?usp=sharing
以下代码尝试将基于 bam() 的空间平滑拟合到上述数据集：
set.seed(1) # 不确定这是否有区别，但设置种子以防万一

模型 &lt;- mgcv::bam(z ~ s(x, y, k = 500),
数据 = 数据集,
家庭 = tw(link=log),
方法 = &quot;fREML&quot;)

但返回以下警告消息：
警告消息：
在 bgam.fit(G, mf, chunk.size, gp, scale, gamma, method = method, :
算法没有收敛

相比之下，以下代码适合标准 gam 模型而不会引发收敛警告：
set.seed(1) #不确定这是否有区别，但设置种子以防万一

模型 &lt;- mgcv::gam(z ~ s(x, y, k = 500),
数据 = 数据集,
家庭 = tw(link=log),
方法 = &quot;REML&quot;) 

总结和问题
这是已知的 bam() 行为吗？除了简单地切换回 gam() 之外，还能做些什么来确保收敛？我曾尝试使用 maxit 关键字增加 IRLS 迭代次数，但没有成功。
我推测我的数据的“质量”可能相当差，因此有人可能会说，mgcv 很难将波动的空间平滑拟合到它并不完全令人惊讶。另一方面，gam() 似乎没有问题，因此绝对有可能实现所需的收敛。]]></description>
      <guid>https://stats.stackexchange.com/questions/660053/convergence-of-bam-mgcv-algorithm</guid>
      <pubDate>Wed, 15 Jan 2025 10:11:29 GMT</pubDate>
    </item>
    </channel>
</rss>