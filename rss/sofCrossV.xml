<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 31 Jan 2025 12:31:20 GMT</lastBuildDate>
    <item>
      <title>当比例风险假设不成立时，如何用重复测量来模拟事件发生时间</title>
      <link>https://stats.stackexchange.com/questions/660801/how-to-model-time-to-event-with-repeated-measures-when-proportional-hazards-assu</link>
      <description><![CDATA[我的数据：
我每天对两个连续变量进行测量，直到他们移民或死亡。
我的目标：
我想使用我的两个每日指标来预测移民时间。
我的模型：
我已经对预测因子进行了 Box Cox 转换和缩放。我已对状态 = 1 的死亡个体和状态 = 2 的移民个体进行了编码。days 是从研究开始到死亡或移民之间的天数。
例如：



ID
metric1
metric2
days
status




A
0.428
-1.42
267
2


A
0.204
-1.97
267
2


A
0.168
-2.65
267
2



我已经开始使用简单的 CoxPH 模型：
coxph(Surv(days, status) ~ metric1 = metric2, data=df)

测试比例风险假设会返回一个显著的全局 p 值。我只能假设这与我的度量随着时间的推移逐渐增加到渐近线有关，而移民的可能性随着年龄的增长而增加，但死亡的可能性却减小。
我的下一步努力：
我发现了许多处理随时间变化数据的建议方法。这些方法包括使用 tt() 拟合时间变换、在 coxme 中添加随机效应、将预测因子与时间交互、使用联合建模以及添加层或集群。
我的问题：
由于似乎有如此多的选项被平等地提倡，我正在寻找建议，以确定是否存在“最佳”选项，如果有，那么在我的情况下是哪一个。]]></description>
      <guid>https://stats.stackexchange.com/questions/660801/how-to-model-time-to-event-with-repeated-measures-when-proportional-hazards-assu</guid>
      <pubDate>Fri, 31 Jan 2025 11:37:17 GMT</pubDate>
    </item>
    <item>
      <title>无法理解本文使用的评估方法</title>
      <link>https://stats.stackexchange.com/questions/660799/cant-understand-the-evaluation-approach-used-in-this-paper</link>
      <description><![CDATA[在这篇论文中，提出了两种深度学习模型：Hybrid-AttUnet++ 和 EH-AttUnet++。第一个模型 Hybrid-AttUnet++ 只是一个经过修改的 U-net 模型，第二个模型是五种不同的 Hybrid-AttUnet++ 模型的集成方法，如论文中所述（第 7 页）：

为了提高系统的性能和稳健性，我们提出了一种由五个 Hybrid-AttUnet++ 模型组成的集成方法，如图 9 所示。为了确保模型多样性（这对集成性能至关重要），我们使用了 k 倍交叉验证技术，其中 k（折叠数）设置为 5。为了创建分区，我们首先将数据集随机分成五个折叠。在这些折叠中，一个用于验证，其余四个用于训练。然后，我们创建了五个具有不同训练/验证子集的分割。对于这五个分割中的每一个，Hybrid-AttUnet++ 都从头开始训练。训练后，使用这些模型进行单独的预测。然后，使用集成方法对五个训练模型的预测取平均值。

因此，他们简单地使用了 5 倍交叉验证，并从 5 个模型中分别创建一个 Hybrid-AttUnet++ 基线模型。我不明白的是评估过程。第 8 页：

为了评估我们的方法，我们使用 80% 的组合数据集作为训练数据，其余数据集作为测试数据，执行 5 倍交叉验证。然后计算五倍交叉验证的平均结果，并在表 3 中总结。

因此，这意味着对 80% 的数据集执行了 5 倍交叉验证，其余 20% 用作测试集。因此，我期望找到一个表格来展示在 20% 测试集上取得的结果，但是，本文有三个表格来展示结果：

表 3 展示了两种模型在 5 倍交叉验证上取得的结果：Hybrid-AttUnet++ 和集成方法 EH-AttUnet++，这对我来说很奇怪，因为 EH-AttUnet++ 已经是从 5 倍交叉验证中开发的，那么它们如何在 5 倍交叉验证上再次进行评估，作者是否只是使用了两次 5 倍交叉验证，一次开发基线模型，另一次重新训练每个分割的集成方法（我不这么认为，因为重新训练整个模型（集成方法）是没有意义的）？

表 4 再次与 5 倍交叉验证相关。

表 5 说明了每次折叠的性能指标仅适用于 EH-AttUnet++，而不适用于 Hybrid-AttUnet++。


总结一下，我的问题如下：
1- 他们的评估方法有 20% 的测试集，在这个测试集上究竟取得了什么结果？还是我遗漏了什么？
2- 集成方法 EH-AttUnet++ 是使用 5 倍交叉验证开发的，其中为每个分割创建了一个基线 Hybrid-AttUnet++。在表 3-5 中，使用 5 倍交叉验证评估了这种集成模型的性能，这对我来说没有意义，因为他们是如何做到的？他们是否再次使用了 5 倍交叉验证，但每个分割都使用了整个 EH-AttUnet++（因此他们每个分割再次重新训练 5 个模型）？我认为最好的方法是使用 20% 的测试集来评估它？]]></description>
      <guid>https://stats.stackexchange.com/questions/660799/cant-understand-the-evaluation-approach-used-in-this-paper</guid>
      <pubDate>Fri, 31 Jan 2025 11:24:49 GMT</pubDate>
    </item>
    <item>
      <title>如果 BatchNorm 的主要好处是损失景观平滑，那么为什么我们使用 z 分数标准化而不是最小-最大？</title>
      <link>https://stats.stackexchange.com/questions/660796/if-the-main-benefit-of-batchnorm-is-loss-landscape-smoothing-why-do-we-use-z-sc</link>
      <description><![CDATA[根据最近的论文，BatchNorm 之所以有效的主要原因是它可以平滑损失景观。因此，如果主要的好处是平滑损失景观，那么我们为什么需要均值减法呢？也许方差正则化为损失景观的好处做了大部分繁重的工作？为什么不使用其他类型的正则化，因为它们可以达到相同的效果，比如最小-最大正则化。请注意，如果内部协变量偏移是主要问题，我理解为什么我们需要 z 分数正则化。]]></description>
      <guid>https://stats.stackexchange.com/questions/660796/if-the-main-benefit-of-batchnorm-is-loss-landscape-smoothing-why-do-we-use-z-sc</guid>
      <pubDate>Fri, 31 Jan 2025 10:00:40 GMT</pubDate>
    </item>
    <item>
      <title>重新缩放特征增加了其进入 LASSO 模型的机会</title>
      <link>https://stats.stackexchange.com/questions/660795/rescaling-feature-increases-its-chances-to-be-in-lasso-model</link>
      <description><![CDATA[假设我们将 LASSO 回归拟合到一个数据集，该数据集具有 $100$ 个特征 $(X_1, \dots X_{100})$。现在，我们通过乘以 $10$（例如 $X_1$）来重新缩放其中一个特征，然后使用相同的正则化参数重新拟合 LASSO 回归。 $X_1$ 是否更有可能被纳入模型？
考虑到以下情况，我猜答案是否定的，但由于不太正式，我不确定

当将 $X_1$ 乘以 $10$ 时，我们将其在 OLS 中的系数除以 $10$。从示意图上看，LASSO 是通过最小化目标函数直到它达到 L1 范数的界限而获得的。我想到这种情况，其中 $\beta_{\text{LASSO}}$ 首先接近（$0.5,0.5$）。实际上，确切的值并不重要，但很明显 $X_1$ 将包含在模型中。然而，在将 $X_1$ 的 OLS 系数除以 10 后，相同的过程将不可避免地将新的 $\beta_{\text{LASSO}}$ 带到 $\approx(0,1)$，它将不会被包括在内。]]></description>
      <guid>https://stats.stackexchange.com/questions/660795/rescaling-feature-increases-its-chances-to-be-in-lasso-model</guid>
      <pubDate>Fri, 31 Jan 2025 09:55:29 GMT</pubDate>
    </item>
    <item>
      <title>李克特类型调查和深度学习</title>
      <link>https://stats.stackexchange.com/questions/660794/likert-type-survey-and-deep-learning</link>
      <description><![CDATA[我是数据新手。我有一个问题，我研究过但找不到明确的答案。我有使用各种李克特类型收集的调查数据，我想将深度学习应用于这些调查数据。但我应该以李克特形式原封不动地使用这些数据，还是应该使用简单平均值等方法将其连续化并以此方式进行分析？据我所知，在经典分类算法中使用李克特类型不是问题，但我不确定深度学习。如果你能帮助我，我会非常高兴。]]></description>
      <guid>https://stats.stackexchange.com/questions/660794/likert-type-survey-and-deep-learning</guid>
      <pubDate>Fri, 31 Jan 2025 09:31:25 GMT</pubDate>
    </item>
    <item>
      <title>在估算缺失值时，变量之间的时间关系重要吗？</title>
      <link>https://stats.stackexchange.com/questions/660792/does-the-temporal-relationship-between-variables-matter-when-imputing-missing-va</link>
      <description><![CDATA[我现在的情况是，我有多个变量，包含缺失值，在时间 $t0$ 测量，还有一些变量在时间 $t1$ 测量，这可能是几年后。
我需要在 $t0$ 时为变量填补缺失值，为此我将使用当时可用的任何信息。是否也有必要使用时间上在之后出现的变量的信息？我知道关于是否包括响应变量的讨论，但在这种情况下，变量之间的关系具有明显的方向性。]]></description>
      <guid>https://stats.stackexchange.com/questions/660792/does-the-temporal-relationship-between-variables-matter-when-imputing-missing-va</guid>
      <pubDate>Fri, 31 Jan 2025 08:07:24 GMT</pubDate>
    </item>
    <item>
      <title>测试两个 AUC 之间的差异</title>
      <link>https://stats.stackexchange.com/questions/660793/testing-the-difference-between-two-aucs</link>
      <description><![CDATA[测试两个 AUC 之间的差异似乎很简单。有一些相关来源，例如这个和其中的链接。
我有一个非常简单的两个 ROC 案例，类似于此示例：
。
使用梯形规则计算 AUC 非常容易。但是，差异检验假设计算了方差，我无法理解如何做到这一点。方差是什么？我拥有的数据就是这样（当然，数据是聚合的）：
命中 FalseAlarms
0.0 0.0
0.9 0.3
1.0 1.0

如何使用上述输入数据在 R 中解决这个问题？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660793/testing-the-difference-between-two-aucs</guid>
      <pubDate>Fri, 31 Jan 2025 06:19:27 GMT</pubDate>
    </item>
    <item>
      <title>只有神经微分方程的输出才重要</title>
      <link>https://stats.stackexchange.com/questions/660790/only-output-of-neural-ode-matters</link>
      <description><![CDATA[我有一个神经 ODE 问题，形式如下：
$\dot{X}(\theta)$ = $f(\theta)$
其中 $f$ 是一个神经网络。
我想积分得到 $X(2\pi)$。
我没有数据来匹配 $\theta$ 的中间值。
只需要匹配最终目标 $X(2\pi)$。
这是一个神经 ODE 问题吗？或者有更好的方法来构建它？]]></description>
      <guid>https://stats.stackexchange.com/questions/660790/only-output-of-neural-ode-matters</guid>
      <pubDate>Fri, 31 Jan 2025 05:17:06 GMT</pubDate>
    </item>
    <item>
      <title>解析简单门控 RNN 随时间反向传播的解法</title>
      <link>https://stats.stackexchange.com/questions/660789/analytically-solving-backpropagation-through-time-for-a-simple-gated-rnn</link>
      <description><![CDATA[考虑以下简单的门控 RNN：
\begin{aligned}
c_{t} &amp;= \sigma\bigl(W_{c}\,x_{t} + W_{z}\,z_{t-1}\bigr)
\\[6pt]
z_{t} &amp;= c_{t} \,\odot\, z_{t-1} \;\;+\;\; 
(1 - c_{t}) \,\odot\,\bigl(W_{x}\,x_{t}\bigr)。
\end{aligned&gt;
这里，
$$
x_{t}\in \mathbb{R}^{n}, \quad
z_{t}\in \mathbb{R}^{m}, \quad
c_{t}\in \mathbb{R}^{m}, 
$$
和
$$
W_{c}\in \mathbb{R}^{m\times n},\, 
W_{z}\in \mathbb{R}^{m\times m},\,
W_{x}\in \mathbb{R}^{m\times n}。
$$
门$c_{t}=\sigma(\cdot)$是元素级 S 型函数。
我们让损失为
$$
\ell \;=\;\sum_{t=1}^{K}\;\ell_{t}\,\bigl(z_{t}\bigr)
$$
因此每个$z_{t}$都对$\ell$有贡献。
我们试图在给定$\frac{\partial \ell_t}{\partial z_t}$的情况下找到$\frac{\partial \ell}{\partial W_x}$。我们可以从以下公式开始：
$$
\frac{\partial \ell}{\partial W_{x}} =
\sum_{t=1}^{K} \left(\frac{\partial \ell_t}{\partial z_{t}} \cdot
\frac{\partial z_{t}}{\partial W_{x}} \right)
$$
并且我们必须找到$\frac{\partial z_{t}}{\partial W_{x}}$。为了方便起见，我们可以将每个 $z_t$ 视为多个变量的函数 $f$：
$$
f(U, z_{\text{prev}}, c_t, x_t) = c_t \odot z_{\text{prev}} + (1 - c_t)\,\odot\,(U \, x_t)
$$
然后
$$
z_t = f(W_x, z_{t-1}, c_t, x_t)
$$
然后我们有
$$
\frac{\partial z_t}{\partial W_x} = \underbrace{\Bigl(\frac{\partial f}{\partial U}\Bigr)}_{\text{local}} + 
\Bigl(\frac{\partial f}{\partial z_{\text{prev}}}\Bigr)
\frac{d\,z_{t-1}}{d W_x} + 
\Bigl(\frac{\partial f}{\partial c_t}\Bigr) \frac{\partial c_t}{\partial W_x}
$$
其中 $W_x$ 对 $z_t$ 有“局部”或直接影响，以及通过 $z_{t-1}$ 和 $c_t$ 有间接影响。让我们定义
\begin{align*}
\varepsilon_t &amp;= \frac{\partial f}{\partial U}(W_x, z_{t-1}, c_t, x_t) \\
\delta_t &amp;= \frac{\partial \ell}{\partial z_t} 
\end{align*&gt;
如何证明以下说法？
\begin{align*}
\frac{\partial \ell}{\partial W_{x}} = \sum_{t=1}^{K} \delta_t \varepsilon_t
\end{align*&gt;
我可以使用 PyTorch 验证它，但我正在寻找分析证明。]]></description>
      <guid>https://stats.stackexchange.com/questions/660789/analytically-solving-backpropagation-through-time-for-a-simple-gated-rnn</guid>
      <pubDate>Fri, 31 Jan 2025 03:12:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 emmeans() 从 coxph() 估计随时间变化的 HR</title>
      <link>https://stats.stackexchange.com/questions/660788/using-emmeans-to-estimate-time-varying-hrs-from-coxph</link>
      <description><![CDATA[emmeans() 非常棒，我使用它进行了很多事后估计。但是，我想知道是否有办法从指定了协变量-时间交互的 coxph() 模型中获得 HR（如果想要努力考虑潜在的非比例风险）。
我找到了一种估算协变量-协变量交互项的 HR 的方法，但找不到任何关于时间-协变量交互项的方法。
如能得到任何帮助，我将不胜感激。以下是一些虚拟代码：
library(survival)
library(emmeans)
set.seed(123)
# 创建数据
df &lt;- data.frame(time = round(runif(100, min = 1, max = 70)), 
status = round(runif(100, min = 0, max = 1)),
drug = round(runif(100, min = 0, max = 1)),
age40 = round(runif(100, min = 0, max = 1)), 
stringsAsFactors = FALSE)

# 具有协变量-协变量相互作用的模型
mod1 &lt;- coxph(Surv(time, status) ~ drug * age40, data = df)
summary(mod1)

# 估计因子组合的 HR
emmeans(mod1, ~ drug + age40, type = &quot;unlink&quot;) |&gt; 对(rev = T) |&gt; 摘要(infer = T)

# 具有时间协变量相互作用的模型
mod2 &lt;- coxph(Surv(time, status) ~ drug + tt(drug), tt = function(x,t,...) x*t, data = df)
摘要(mod2)

# 估计不同观察时间的 HR？
emmeans(...

# 这可能吗？

编辑：
我应该补充一下，如果不使用 emmeans()，还有其他方法吗（除了根据模型方程手动计算 HR）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660788/using-emmeans-to-estimate-time-varying-hrs-from-coxph</guid>
      <pubDate>Fri, 31 Jan 2025 02:05:34 GMT</pubDate>
    </item>
    <item>
      <title>组合预测因子是否总能改善 AUC？</title>
      <link>https://stats.stackexchange.com/questions/660787/does-combining-predictors-always-improve-auc</link>
      <description><![CDATA[我有两个独立的预测因子，x₁ 和 x₂，以及一个二元结果 y。
模型 1：使用 x₁ 预测 y
模型 2：使用 x₂ 预测 y
模型 3：使用两个预测因子之和 (x₃ = x₁ + x₂) 预测 y

我的预期是，通过将预测因子相加来组合至少会实现两个单独模型的更高 AUC。但是，我发现情况并非总是如此。
例如：
当 AUC(x₁) = 0.59 和 AUC(x₂) = 0.59 时，组合模型实现 AUC(x₃) = 0.63（更好）。
但当 AUC(x₁) = 0.59 且 AUC(x₂) = 0.54 时，组合模型 AUC(x₃) = 0.58，这比单独使用 x₁ 更差。

组合模型的 AUC 低于单个模型之一，这在统计上有效吗？如果是，这背后的原因是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660787/does-combining-predictors-always-improve-auc</guid>
      <pubDate>Fri, 31 Jan 2025 01:36:54 GMT</pubDate>
    </item>
    <item>
      <title>为什么在之前的抛硬币过程中，下一次抛硬币的不确定性会随着测量次数的增加而增加？</title>
      <link>https://stats.stackexchange.com/questions/660769/why-does-the-uncertainty-of-the-next-coin-flip-given-previous-flips-goes-up-with</link>
      <description><![CDATA[我对与给定先前抛硬币的抛硬币预测后验相关的一些事情有点困惑。假设我在 N 次抛硬币中看到 k 次正面，我想找出下一次抛硬币是正面的概率。我不仅想量化下一次抛硬币是正面的概率，还想量化我对它是否会是正面的不确定性。如果我假设一个均匀的先验并做一些数学运算，我可以得出下一次抛硬币的预期值为
$$
E_p[E_H[H|p]] = \frac{k+1}{N+2}
$$
方差的期望值为
$$
E_p[Var_H[H|p]] = \frac{(k+1)(N-k+1)}{(N+2)(N+3)}。
$$
但是当我尝试几个 k 和 N 的值，使 k=N/3 保持不变时，我注意到不确定性会随着翻转次数的增加而增加。
 k N E[E[H|p]] E[Var[H|p]]
1 3 0.400000 0.200000
2 6 0.375000 0.208333
4 12 0.357143 0.214286
8 24 0.346154 0.217949
16 48 0.340000 0.220000

为什么我获得更多数据时不确定性会增加？这似乎不正确。我猜想使用方差的期望值作为不确定性的代理肯定是有缺陷的，但我不知道更好的指标是什么。如果是这样的话，您能否在下一次抛硬币时提出一个更好的不确定性指标，以符合不确定性应该随着数据增加而减少的直觉？否则这里还有其他问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660769/why-does-the-uncertainty-of-the-next-coin-flip-given-previous-flips-goes-up-with</guid>
      <pubDate>Thu, 30 Jan 2025 17:24:09 GMT</pubDate>
    </item>
    <item>
      <title>前瞻性和回顾性数据（偏差、研究设计）</title>
      <link>https://stats.stackexchange.com/questions/660754/prospective-and-retrospective-data-bias-study-design</link>
      <description><![CDATA[我们正在开展一项关于癌症治疗中治疗转换效果的研究，旨在评估转换后 3 个月和 6 个月的结果。
几周前，我们开始前瞻性地收集患者数据，包括那些在基线时转换到新疗法的患者。然而，在研究正式开始之前，相当多的患者已经转换了疗法。为了增加样本量，我们希望前瞻性地跟踪这些早期患者，但他们的基线（转换时间）可能需要回顾性地进行评估。
值得注意的是，早期和晚期转换者的治疗方案和测量是相同的。
鉴于此，我们的关键问题是：

是否可以结合前瞻性和回顾性观察？
我们如何在纳入早期患者的同时最大限度地减少偏见？
您对改进我们的研究设计有什么建议吗？**

非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/660754/prospective-and-retrospective-data-bias-study-design</guid>
      <pubDate>Thu, 30 Jan 2025 06:31:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么必须估计线性回归模型中的参数值？</title>
      <link>https://stats.stackexchange.com/questions/660750/why-must-the-values-of-the-parameters-in-a-linear-regression-model-be-estimated</link>
      <description><![CDATA[我不明白为什么在线性回归模型中无法找到参数 α 和 β 的真实值。为什么它们总是需要估计？
我读到它与包含其他变量的误差项有关（$x_2,x_3 ...$），但我并不完全理解。]]></description>
      <guid>https://stats.stackexchange.com/questions/660750/why-must-the-values-of-the-parameters-in-a-linear-regression-model-be-estimated</guid>
      <pubDate>Thu, 30 Jan 2025 04:46:11 GMT</pubDate>
    </item>
    <item>
      <title>为什么一个预测区间比另一个大？</title>
      <link>https://stats.stackexchange.com/questions/660694/why-is-one-prediction-interval-bigger-than-the-other</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660694/why-is-one-prediction-interval-bigger-than-the-other</guid>
      <pubDate>Wed, 29 Jan 2025 03:12:53 GMT</pubDate>
    </item>
    </channel>
</rss>