<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 17 Jul 2024 01:06:52 GMT</lastBuildDate>
    <item>
      <title>CSF 的值必须为 0 和最低可能值吗？</title>
      <link>https://stats.stackexchange.com/questions/651199/does-csf-must-have-value-0-and-lowest-possible-value</link>
      <description><![CDATA[假设 $F$ 是实值随机变量的 CDF。我知道 $F(- \infty) = 0$，因为 RV 不能取小于该值的值。
但我考虑的是一个 RV，其值肯定来自 $[0, 1]$。$F(0)$ 是否必然为 0？更具体地说，我可以在 $x = 0$ 处有某种“点质量”，以便 $x &lt; 的 CDF 为零0$，某个数 $k \in (0, 1)$ 在 0 处连续，直到在 1 之前或 1 处达到 1？
相关的 PDF 是什么？我设想一种这样的形式：$\delta(x) + f(x)$，其中 $\delta$ 是狄拉克-德尔塔函数。但是如何在 PDF 公式中指定 $k$ 的确切值？这是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/651199/does-csf-must-have-value-0-and-lowest-possible-value</guid>
      <pubDate>Tue, 16 Jul 2024 23:10:48 GMT</pubDate>
    </item>
    <item>
      <title>截距估计与 glm 和 glmm 相比有很大不同</title>
      <link>https://stats.stackexchange.com/questions/651198/intercept-estimates-very-different-comparing-glm-and-glmm</link>
      <description><![CDATA[有人能解释以下令人费解的现象吗？我正在使用 R 的 lme4 包中的 glmer 拟合二项式 glmm。数据集中的二元响应变量的平均值约为 0.1。当我使用必要的随机效应拟合仅截距的 glmm 时，我得到的截距估计值毫无意义：
&gt; history.glmer.c.9 &lt;- glmer(contaminated ~ (1|ID), family = binomial, data = inspected)
&gt; summary(history.glmer.c.9) 
通过最大似然法（拉普拉斯近似）拟合的广义线性混合模型 [&#39;glmerMod&#39;]
族：二项式（logit）
公式：污染 ~ (1 | ID)
数据：已检查

AIC BIC logLik 偏差 df.resid 
32730.4 32748.5 -16363.2 32726.4 64539 

缩放残差：
最小 1Q 中位数 3Q 最大 
-2.2088 -0.0049 -0.0049 -0.0049 4.1520 

随机效应：
组名称方差标准差
ID。 （截距）591.6 24.32 
观察数：64541，组：ID，51445

固定效应：
估计标准误差 z 值 Pr(&gt;|z|) 
（截距）-10.60404 0.07398 -143.3 &lt;2e-16 ***
---
有效代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

我认为这个截距估计值太低了 - 我期望在 -2 左右，这是我从仅截距 glm 中得到的结果。
&gt; history.glm.c.9 &lt;- glm(contaminated ~ 1, family = binomial, data = inspected)
&gt; summary(history.glm.c.9) 

调用：
glm(formula = contaminated ~ 1, family = binomial, data = inspected)

系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -1.87428 0.01159 -161.7 &lt;2e-16 ***
---
符号代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

（二项式系列的分散参数取为 1）

零偏差：64540 个自由度上的 50618
残差偏差：64540 个自由度上的 50618
AIC：50620

Fisher 评分迭代次数：4

值得注意的评论

AIC 表明 glmm 比 glm 更适合（32730
cf 50620）。
我使用 glmmTMB 得到了相同的截距估计，所以我不认为这只是 glmer。
组成员严重偏斜（见下表）；绝大多数组都是单例。
ICC 非常高，但单例污染率（即单个单元组的污染率）与较大组的污染率大致相同。
组级别的失败率也约为 0.1。

&gt;表（表（已检查$ID））

1 2 3 4 5 6 7 8 9 10 11 12 13 14 
582847 35629 7137 3268 1609 828 492 296 195 99 66 72 20 13 
15 16 17 19 25 26 
6 5 8 2 1 1 

感谢您的任何见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/651198/intercept-estimates-very-different-comparing-glm-and-glmm</guid>
      <pubDate>Tue, 16 Jul 2024 22:57:37 GMT</pubDate>
    </item>
    <item>
      <title>结合不同分位数的信息</title>
      <link>https://stats.stackexchange.com/questions/651194/combining-information-from-different-quantiles</link>
      <description><![CDATA[我有许多“主要”高斯分布（实际上是高斯核心和较长的尾部）。我对这些分布的宽度感兴趣。
鉴于我不知道尾部的数量，并且最终我要与对不同内分位数有效的模型进行比较，我使用不同的估计量（RMS、MAD，...）估计这些分布的宽度。我正在组合不同的估计量（例如，如下所示：https://hal.science/hal-00936024v4/file/A-general-procedure-to-combine-estimators.pdf）并获取每个分位数的值及其相关误差。
值及其误差如下所示。分位数为 90 意味着我考虑内部 90% 分位数，丢弃左侧 5% 的尾部数据和右侧 5% 的尾部数据。



分位数
值
误差




80
0.376
0.012


85
0.379
0.011


90
0.378
0.012


93
0.39
0.012


95
0.389
0.013


97
0.396
0.014


98
0.39
 0.015


99
0.394
0.017


100
0.39
0.016



我现在的问题是：如何将不同分位数的值和相关误差结合起来，以期获得较小的误差？可以做到吗？有什么注意事项吗？这些错误是否相关？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651194/combining-information-from-different-quantiles</guid>
      <pubDate>Tue, 16 Jul 2024 22:14:58 GMT</pubDate>
    </item>
    <item>
      <title>评估癌症监测中新生物标志物的实施和性能</title>
      <link>https://stats.stackexchange.com/questions/651193/assessing-the-implementation-and-performance-of-a-new-biomarker-in-cancer-survei</link>
      <description><![CDATA[在旨在检测高风险人群中特定类型癌症的监测计划中，生物标志物 A 和超声 (US) 每半年使用一次。如果 A 或 US 返回阳性结果，则进行确认测试。
一项新研究旨在评估另一种生物标志物 G，与 US 一起使用。由于在 G 的性能得到验证之前我们无法改变标准途径，因此研究中的所有参与者都将接受 A、G 和 US 的测试。如果这些测试中的任何一个返回阳性结果，患者将接受确认测试。由于确认测试的成本高昂，因此不会对所有指标测试结果为阴性的患者进行该测试（部分验证）。
生物标志物 G 结合 A 以及其他成分来检测癌症。因此，G 和 A 是相关的，尽管相关程度未知。一项研究表明，G 比单独的 A 具有更高的灵敏度。根据荟萃分析的数据，G 似乎也比 A 和 US 的组合具有更高的灵敏度和特异性。但是，没有研究直接比较过 G/G+US 与 A/A+US。
这种比较对于评估测试准确性和成本效益至关重要。直观来看，G+US 的灵敏度会比 A+US 更好，尽管考虑到 A 的高特异性，G+US 的特异性可能会更低。但是，这个假设需要进行测试，并且需要对样本量进行论证才能申请补助金。
问题：
将这项研究简化为比较 G 与 A 是否合适？
展示 G+US 优于 A+US 的最佳方法是什么？我们应该专注于比较这两种组合的灵敏度吗？或者，考虑到 G 包括 A，是否有一种方法可以显示 G 在检测准确性方面的附加值？
这种比较需要多大的样本量？
如果比较灵敏度是合适的，那么最佳的样本量计算方法是什么？
我找到了吴 (2024) 的一篇论文，题为“当金标准随机缺失时，比较两种筛选测试的样本量计算” (doi: 10.1002/sim.10109)，提出了简化的样本量计算，用于比较配对诊断测试和部分验证，包括那些指数测试为阴性的人没有接受验证的情况。所有方法都考虑了两个指数测试之间的相关性。然而，当指数测试之间的相关性很高时，一种方法被认为是不合适的，这可能与我们的情况有关。这是相关研究的链接：(https://www.sciencedirect.com/science/article/pii/S0167947308003782)。我不确定这是否也适用于其他方法。
对这些问题的任何见解都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/651193/assessing-the-implementation-and-performance-of-a-new-biomarker-in-cancer-survei</guid>
      <pubDate>Tue, 16 Jul 2024 21:36:30 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型逆条件概率在以 x_0 导数为条件时易于处理</title>
      <link>https://stats.stackexchange.com/questions/651189/diffusion-model-reverse-conditional-probability-is-tractable-when-conditioned-on</link>
      <description><![CDATA[
有人能帮我理解$\widetilde{\beta}$和${\tilde\mu_t{(x_t, x_0)}}$是如何得出的吗？
在我看来，指数项是一个二阶多项式项，它看起来并不像$\frac{(x - \mu)^2}{2\sigma^2}$形式的高斯函数。
来源：https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#reverse-diffusion-process]]></description>
      <guid>https://stats.stackexchange.com/questions/651189/diffusion-model-reverse-conditional-probability-is-tractable-when-conditioned-on</guid>
      <pubDate>Tue, 16 Jul 2024 20:37:53 GMT</pubDate>
    </item>
    <item>
      <title>绘制连续变量的风险比、95% 可信区间</title>
      <link>https://stats.stackexchange.com/questions/651187/plot-hazard-ratio-95-ci-with-a-continous-variable</link>
      <description><![CDATA[R 可以生成这样的图形吗？
x 轴 = 年龄（连续），y 轴 = 每个计数的风险比？
我们的数据集：mydata，事件 = 死亡，事件发生时间 = 年，变量 = 年龄，组 = 治疗 (1) vs 对照 (0)
]]></description>
      <guid>https://stats.stackexchange.com/questions/651187/plot-hazard-ratio-95-ci-with-a-continous-variable</guid>
      <pubDate>Tue, 16 Jul 2024 20:00:34 GMT</pubDate>
    </item>
    <item>
      <title>从“nlme”阻止“gls”的引导实现</title>
      <link>https://stats.stackexchange.com/questions/651186/block-bootstrap-implementation-for-gls-from-nlme</link>
      <description><![CDATA[我有几个时间序列数据（天）的数据集，其中有些天有实验干预，其中一些数据集覆盖多个站点。我也有匹配的日级和站点级协变量。
要以混合效应方式（跨站点随机）分析这些数据，我可以使用 nlme 中的 lme，以固定效应方式（仅将站点视为自身或单个站点）分析这些数据，我可以使用 gls。因为我假设站点内误差存在序列相关性，所以我使用了这两个函数的 correlation 参数。
不过，我不太确定正态性，这就是我研究引导方法的原因。lmeresampler 包实现了“随机效应块引导”方法（Chambers &amp; Chandra 2013）适用于 lme，但没有相应的“固定效应块引导法”（我认为它只是每个组的块引导法）适用于 gls。
我的问题：是否有一个 R 包可以对 gls 执行 lmeresampler 对 lme 执行的操作？
我搜索了很多，但没有找到任何合适的东西。例如，rms 中的 Gls 具有内置引导法，但文档没有解释它是否可以处理序列相关性。boot 包中有 tsboot，但它是为纯时间序列模型设计的，而不是线性模型中的错误。我可能可以自己做点什么，但我不想 (a) 重新发明轮子和 (b) 犯错误。
或者，我还对除（随机效应）块引导之外的其他方法感兴趣，这些方法可以统一应用于 lme 和 gls 拟合。
虽然这个问题主要与软件/实现有关，但我认为需要统计专业知识才能理解或回答，因此（接近）主题。如果不是这种情况，请将我引导到其他地方。

玩具示例数据，gv 是“site”变量：
set.seed(123)
time &lt;- 0 : 9
data0 &lt;- data.frame(time) |&gt;
突变（
iv = as.numeric（时间 &gt;= 5），
dv = iv + as.vector（arima.sim（n = 10，list（ar = c（0.5）））），
gv = 0
）
data1 &lt;- data.frame（时间）|&gt;
mutate(
iv = as.numeric(time &lt; 5),
dv = 2 * iv + as.vector(arima.sim(n = 10, list(ar = c(0.5)))),
gv = 1
)
data &lt;- bind_rows(data0, data1)

混合效应分析和随机效应块引导：
lme_data &lt;- lme(
fixed = dv ~ 1 + iv,
random = ~ 1 | gv,
correlation = corAR1(form = ~ time | gv),
data = data
)
boot_lme_data &lt;- reb_bootstrap(
lme_data,
.f = extract_parameters,
B = 1000,
reb_type = 1
)
confint(boot_lme_data, type = &quot;perc&quot;)

固定效应分析，但没有块引导：
gls_data &lt;- gls(
model = dv ~ 1 + iv + gv,
correlation = corAR1(form = ~ time | gv),
data = data
)
boot_gls_data &lt;- # ???
]]></description>
      <guid>https://stats.stackexchange.com/questions/651186/block-bootstrap-implementation-for-gls-from-nlme</guid>
      <pubDate>Tue, 16 Jul 2024 19:55:07 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型中的多层建模与广义线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/651184/multilevel-modeling-in-linear-mixed-models-versus-generalized-linear-mixed-model</link>
      <description><![CDATA[我正在分析一个包含多个离散和连续结果变量 (DV) 的数据集。对于连续 DV，我打算使用在 SPSS 中处理的线性混合模型 (LMM)。对于离散变量，我有几个 DV 的评级范围是 1-100，其他 DV 的评级范围是 1-10。有人建议我对这些离散变量使用广义线性混合模型 (GLMM)。我知道其中一个主要原因是这些值不能低于 1，也不能高于 10。对于我的分析，这些限制实际上并不重要，因为我感兴趣的是一组预测因子（哪些预测因子具有较大的统计显著系数）导致的增加或减少量。超过限值（1-10 评级的负值和大于 10 的值）似乎并不重要，只有预测因子系数才重要。我对 GLMM 了解得越多，就越明白，使用不同的链接函数（logit、probit 等）解释系数可能是一个挑战。例如，根据分布和特定的预测因子集重新调整 1 级方差。考虑到这一点，有三个 (3) 个问题：

如果变量被视为“近似连续”，并且不关心下限或上限值，也不关心保留离散值（分数 OK），那么可以使用 LMM 完成离散 DV（1-100 或 1-10 评级量表）的分析吗？
如果仍然需要 GLMM，那么使用“线性模型”是否可行？目标分布（具有正态分布和身份链接）是否能更直接地解释重要的预测系数，更像 LMM，具有一致缩放的 1 级残差？
哪种目标分布链接/链接函数最适合 1-100 和 1-10 评分量表数据？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651184/multilevel-modeling-in-linear-mixed-models-versus-generalized-linear-mixed-model</guid>
      <pubDate>Tue, 16 Jul 2024 19:50:51 GMT</pubDate>
    </item>
    <item>
      <title>利用语义分割量化叶片病害</title>
      <link>https://stats.stackexchange.com/questions/651183/quantification-of-leaf-disease-with-semantic-segmentation</link>
      <description><![CDATA[我正在尝试使用原始图像和相应掩模的数据集来量化叶片疾病。我有两种方法：

用于叶片和患病区域的语义分割的训练-测试模型
使用训练后的模型预测图像，并使用严重程度指数公式计算患病区域和叶片的百分比

第二种方法是&quot;

用于叶片和患病区域的语义分割的训练-测试模型，并提供每片叶片患病区域的百分比
使用训练后的模型预测图像和百分比

哪种方法更合适、更准确？]]></description>
      <guid>https://stats.stackexchange.com/questions/651183/quantification-of-leaf-disease-with-semantic-segmentation</guid>
      <pubDate>Tue, 16 Jul 2024 19:47:30 GMT</pubDate>
    </item>
    <item>
      <title>关于 R 的 lme4 混合效应模型公式的建议 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/651181/advice-on-mixed-effect-model-formula-for-rs-lme4</link>
      <description><![CDATA[我对混合效应模型和 lme4 还不熟悉，非常希望得到一些建议。
我的研究问题：哪些因素决定了企业每天的在线评论数量？
数据是横截面的，观察结果是企业。
因变量：在线评论数量（感兴趣的是其比率 = 每天的评论数量）
自变量要么与业务相关，要么与位置相关，如下表所示。除了集中度，位置因素不是我感兴趣的，因此被作为控制因素。
这是 4 行数据的样本。还有一些与企业和地点相关的变量，为了简洁起见，我省略了它们：

由于我的一个焦点独立变量（竞争对手的集中度）是在邮政编码级别，并且这些企业嵌套在邮政编码中（因此可以共享集中度值），所以我决定使用混合效应模型，将邮政编码作为随机效应。此外，由于因变量是计数，我决定使用泊松或负二项回归，以天数为偏移量。我在 R 中使用 lme4，我的问题主要围绕下面的公式以及它是否合理。以下是我对它的每个组成部分的推理和相关问题。我对混合效应还不熟悉，所以我问这些问题是为了确认我的理解。
公式：
在线评论数量 ~ 价格 * 集中度 + 提供的服务数量 + 偏移量（在线评论时间跨度的对数）+ (1|邮政编码) + (1|价格)

我需要将企业 ID 作为随机效应吗？(1|企业 ID)
价格 * 集中度：两者都是关键变量，我对它们的相互作用很感兴趣（例如，当集中度较低时，低价可能会增加评论数量，但当集中度较高时可能不会增加）。但集中度不是与业务相关的因素，而是与位置相关的因素。将其作为固定效应包括在内是否违反了观察独立性的假设？我应该改为 (1 + 价格 | 邮政编码) 吗？但这将与邮政编码有关，而不是直接与集中度有关
与上述问题相关，我如何控制人口密度和房屋中位价？我是否应该将它们添加为固定效应，即使它们是基于位置的，或者它们的效果已经被 (1|邮政编码) 捕获？
请随时解决您看到的任何其他问题，甚至可以重写公式来为我澄清问题。
]]></description>
      <guid>https://stats.stackexchange.com/questions/651181/advice-on-mixed-effect-model-formula-for-rs-lme4</guid>
      <pubDate>Tue, 16 Jul 2024 18:55:35 GMT</pubDate>
    </item>
    <item>
      <title>如何提高 LSTM 等深度学习时间序列预测模型的性能？[重复]</title>
      <link>https://stats.stackexchange.com/questions/651180/how-to-improve-performance-of-deep-learning-timeseries-forecasting-model-like-ls</link>
      <description><![CDATA[我有 5 年（2019 年 6 月 - 2024 年 6 月）的历史数据。数据为每日和 csv 文件格式。我有 4 个特征：数据、AQI、原始浓度、NowCast 浓度。我试图仅根据这些特征预测未来 AQI。我尝试了以下模型：

LSTM/LSTM-CNN/LSTM-RNN
Prophet/ARIMA/SARIMA

对于 Prophet/ARIMA/SARIMA，我在测试集和训练集上的模型性能都很差。
对于 LSTM/LSTM-CNN/LSTM-RNN，我的 R2 分数停留在 0.81。我尝试了网格搜索、退出、提前停止，但性能保持在 0.70 到 0.80 之间。我甚至尝试了不同的数据集（具有相同的特征），但性能仍然相同。我还能做什么？这是我最简单的模型，并进行了以下测试评估
均方误差 (MSE)：0.01
,R2 分数：0.80
,平均绝对误差 (MAE)：0.05
df[&#39;Date&#39;] = pd.to_datetime(df[&#39;Date&#39;])
df.set_index(&#39;Date&#39;, inplace=True)

# 指定特征
X = [0, 1, 2] # 输入特征的索引 (AQI、原始浓度、NowCast 浓度)
Y = [0] # 输出特征的索引 (AQI)

# 用于为 LSTM 创建序列的函数
def create_sequences(data, seq_length, input_features, output_features):
X, y = [], []
for i in range(len(data) - seq_length):
# 输入序列 (X) 从索引 i 到 i +指定特征的 seq_length
X.append(data[i:i + seq_length, input_features].astype(np.float32)) 
# 输出序列 (y) 是指定特征的下一个值 (i + seq_length)
y.append(data[i + seq_length, output_features].astype(np.float32)) 

return np.array(X), np.array(y)

# 设置序列长度并将数据拆分为训练集和测试集
seq_length = 30
train_size = int(len(df) * 0.8)
train_data = df.iloc[:train_size].values
test_data = df.iloc[train_size:].values

# 为 LSTM 创建序列
train_X, train_y = create_sequences(train_data, seq_length, X, Y)
test_X, test_y = create_sequences(test_data, seq_length, X, Y)

# 将数据转换为 PyTorch 张量
train_X = torch.tensor(train_X, dtype=torch.float32)
train_y = torch.tensor(train_y.reshape(-1, 1), dtype=torch.float32) # 重塑以匹配输出大小
test_X = torch.tensor(test_X, dtype=torch.float32)
test_y = torch.tensor(test_y.reshape(-1, 1), dtype=torch.float32) # 重塑以匹配输出大小

# 定义 LSTM 模型
class LSTMModel(nn.Module):
def __init__(self, input_size, hidden_​​size, num_layers, output_size):
super(LSTMModel, self).__init__()
self.hidden_​​size = hidden_​​size
self.num_layers = num_layers
self.lstm = nn.LSTM(input_size, hidden_​​size, num_layers, batch_first=True)
self.fc = nn.Linear(hidden_​​size, output_size)

def forward(self, x):
h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_​​size).to(x.device)
c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_​​size).to(x.device)
out, _ = self.lstm(x, (h0, c0))
out = self.fc(out[:, -1, :])
return out

# 初始化模型参数
input_size = len(X) # 输入特征数量（AQI、Raw Conc.、NowCast） Conc.)
hidden_​​size = 100
num_layers = 2
output_size = 1 # 预测 AQI

# 初始化模型、损失函数和优化器
model = LSTMModel(input_size, hidden_​​size, num_layers, output_size)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# 训练模型
num_epochs = 200
train_losses = []

for epoch in range(num_epochs):
model.train()
optimizer.zero_grad()
output = model(train_X)
loss = criterion(outputs, train_y)
loss.backward()
optimizer.step()
train_losses.append(loss.item())

if (epoch+1) % 10 == 0:
print(f&#39;Epoch [{epoch+1}/{num_epochs}]，损失：{loss.item():.4f}&#39;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/651180/how-to-improve-performance-of-deep-learning-timeseries-forecasting-model-like-ls</guid>
      <pubDate>Tue, 16 Jul 2024 18:52:23 GMT</pubDate>
    </item>
    <item>
      <title>可以针对两点进行假设检验吗？</title>
      <link>https://stats.stackexchange.com/questions/651179/can-hypothesis-testing-be-done-on-two-points</link>
      <description><![CDATA[我为一些岛屿设置了以下内容（每个岛民的数据均可用，整个人口的数据也可用）：

2000 年：

成年人口总数：260,000；
健康成年人数量：250,000
患病成年人数量：10,000
健康率：250,000/260,000 = 0.961


2001 年：

成年人口总数：265,000；
健康成年人数量：261,000
患病成年人数量： 4,000
健康率：261,000/265,000 = 0.984



我想看看 2000 年岛上的健康率与 2001 年岛上的健康率在统计上是否有差异。
我的问题是只有两个比率可供比较，因此样本量为 2（即使每个比率本身都是根据大量人口计算的）。
即使只有两个点可供比较，这里还能进行假设检验吗？

附言：如果只有 2 个点而没有单独的数据 - 假设检验将不起作用？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651179/can-hypothesis-testing-be-done-on-two-points</guid>
      <pubDate>Tue, 16 Jul 2024 18:35:54 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助理解随时间变化的优势比示例</title>
      <link>https://stats.stackexchange.com/questions/651177/need-help-understanding-odds-ratio-over-time-example</link>
      <description><![CDATA[我正尝试重新创建一篇论文，该论文比较了重复急诊就诊（即同一患者在过去 12 个月内因同一原因再次就诊）与单次急诊就诊的频率和特征。其中，“使用逻辑回归计算了随时间推移重复急诊就诊与单次急诊就诊的概率。给出了未调整的优势比；未控制其他变量。”没有提供其他详细信息。
在他们展示比值比的部分中，他们展示了一个聚类条形图，显示了 2018-2022 年每年的急诊就诊次数（单次或重复）的百分比。5 年来，每年重复就诊的百分比略有增加。他们给出的未调整的几率比为 1.108“这表明，每年，个人重复急诊就诊而不是单次急诊就诊的几率增加 11% (p&lt;.001)。&quot;
这是否意味着，为了获得未调整的几率比，我应该运行逻辑回归，其中独立变量是急诊就诊的年份，因变量为 0/1（单次/重复）？我很难理解这种情况下独立变量是什么。
我确实尝试过这个（使用 sklearn.LogisticRegression），得到的几率比是 0.99，这没有意义。我认为我应该将年份向量转换为 1-5 而不是 2018-2022，对吗？
我是不是错得离谱？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651177/need-help-understanding-odds-ratio-over-time-example</guid>
      <pubDate>Tue, 16 Jul 2024 18:28:36 GMT</pubDate>
    </item>
    <item>
      <title>Cox 比例风险模型的功效分析</title>
      <link>https://stats.stackexchange.com/questions/651176/power-analysis-for-the-cox-proportional-hazards-model</link>
      <description><![CDATA[我正在尝试根据一项小型研究计算出 RCT 所需的样本量，该研究研究了指数手术后的再次手术。在这项小型研究中，有 1000 名患者，第 1 组有 700 名，第 2 组有 300 名患者。第 1 组中有 20 名再次手术，第 2 组中有 30 名再次手术。但是，第 1 组的 10 年生存率为 15%，第 2 组的 10 年生存率为 12%。因此，大多数患者不再面临再次手术的风险。我想知道如何计算 RCT 所需的样本量，以 1:1 随机分配，并观察如果对患者进行 10 年的随访，考虑到随访期间的死亡，各组之间的风险比是否会降低 0.10？我的 stata 代码目前如下所示
power cox, hratio(0.90) alpha(0.05) power(0.80)]]></description>
      <guid>https://stats.stackexchange.com/questions/651176/power-analysis-for-the-cox-proportional-hazards-model</guid>
      <pubDate>Tue, 16 Jul 2024 18:17:39 GMT</pubDate>
    </item>
    <item>
      <title>将五点李克特量表转换为均匀量表</title>
      <link>https://stats.stackexchange.com/questions/651175/converting-five-point-likert-scale-to-uniform-scale</link>
      <description><![CDATA[*我正在开展一个荟萃分析项目，其中包括来自不同出版物的平均值和 SD 值。它们有不同的尺度。一些是基于 0 到 100 的视觉模拟量表计算的分数平均值和 SD。一些是基于 1 到 10 的视觉模拟量表，增量为 0.5，其他是基于李克特量表（5 分制，1 到 5）的分数平均值和 SD。
所以我考虑重新缩放平均值和 SD 值（标准化平均值和 SD 的值并获取平均值和 SD 的新值）以分析和比较它们。我应该怎么做？*]]></description>
      <guid>https://stats.stackexchange.com/questions/651175/converting-five-point-likert-scale-to-uniform-scale</guid>
      <pubDate>Tue, 16 Jul 2024 18:16:09 GMT</pubDate>
    </item>
    </channel>
</rss>