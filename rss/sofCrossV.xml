<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 09 Apr 2024 21:13:40 GMT</lastBuildDate>
    <item>
      <title>平衡面板的差异：添加固定效应不会改变系数？</title>
      <link>https://stats.stackexchange.com/questions/644672/diff-in-diff-with-balanced-panel-adding-fixed-effects-does-not-change-coefficie</link>
      <description><![CDATA[我正在尝试在 Stata 中运行双重差异模型。我的因变量是订单量，每个观察值是 1 家商店，并且我的面板非常平衡（每家商店 20 个季度，6K 对照商店，4K 处理商店）。我正在运行以下回归：
reghdfe 命令 treat post treat_post, noabsorb cluster(chain)
如果我添加固定效应（时间、个人或其他任何因素），我的 treat、post 和 treat_post 系数根本不会改变。例如，以下回归都给出具有相同标准误差的相同系数：
reghdfe 命令 treat treat_post、absorb(date) cluster(chain)
reghdfe 订单发布后 treat_post、absorb(store_id_number) cluster(chain)
reghdfe 订单 treat_post、absorb(date store_id_number) cluster(chain)
根据我的理解，treat_post 的系数应该每次都改变，因为我包含了不同的固定效应？我做错了什么，可能会发生什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644672/diff-in-diff-with-balanced-panel-adding-fixed-effects-does-not-change-coefficie</guid>
      <pubDate>Tue, 09 Apr 2024 20:41:08 GMT</pubDate>
    </item>
    <item>
      <title>如何测试多国数据集的统计显着性？</title>
      <link>https://stats.stackexchange.com/questions/644671/how-to-test-for-statistical-significance-on-a-multi-country-dataset</link>
      <description><![CDATA[我正在尝试使用来自 7 个国家/地区的数据，使用 Welch 2 样本 t 检验 [R 中的 t.test()] 来测试治疗组和对照组之间的统计显着性。 7 个国家中有 6 个具有统计显着性结果，但当我汇总数据集以测试多国水平的显着性时，我得到了很高的 p 值。当数据汇总到多国数据集中时，是否有更好的方法来准确衡量治疗效果？
我想知道我发现每个国家/地区的 p 值较低（7 个国家/地区中的 6 个国家/地区）但汇总时 p 值较高的原因是否是因为国家/地区之间的起点和终点差异很大。附件是一个箱线图，说明了我想要描述的内容。
是否有一种方法可以“校准”测试多国统计显着性之前的值？
]]></description>
      <guid>https://stats.stackexchange.com/questions/644671/how-to-test-for-statistical-significance-on-a-multi-country-dataset</guid>
      <pubDate>Tue, 09 Apr 2024 20:40:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么不是所有损失函数都有 1/2 因子？</title>
      <link>https://stats.stackexchange.com/questions/644670/why-dont-all-loss-functions-have-the-1-2-factor</link>
      <description><![CDATA[我一直在阅读glmnet vignette，因为我对标准化数据时 $1/2N$ 因子与应用于 $\lambda$ 的缩放之间的关系 -似乎许多 R 包的执行方式并不一致。
对于我的问题；为什么只有线性损失函数应用 $1/2N$ 因子，而其他函数则使用 $1/N$ 因子跨度&gt;因素？]]></description>
      <guid>https://stats.stackexchange.com/questions/644670/why-dont-all-loss-functions-have-the-1-2-factor</guid>
      <pubDate>Tue, 09 Apr 2024 20:21:52 GMT</pubDate>
    </item>
    <item>
      <title>GKgamma 函数为表现完美的参与者返回 NaN</title>
      <link>https://stats.stackexchange.com/questions/644669/gkgamma-function-returns-nan-for-participants-with-perfect-performance</link>
      <description><![CDATA[我要求参与者回答一系列记忆问题，并评估他们对每个问题准确性的信心。数据框看起来像这样：
set.seed(10)
内存1&lt;-rep(1，时间=100)
内存2&lt;-样本(0:1, 900, 替换=TRUE)
内存&lt;-c(内存1,内存2)
置信度&lt;-样本(0:100, 1000, 替换=TRUE)
id&lt;-rep(1:10，每个=100)
df&lt;-data.frame(内存、置信度、id)

我这样估计每个参与者的伽玛系数：
gamma&lt;-df %&gt;%
    group_by(id) %&gt;%
    总结（
    分辨率 = GKgamma(表(内存, 置信度))$gamma)

这工作正常，但由于一名参与者具有完美的记忆表现（他们正确回答了所有记忆问题），GKgamma 为该参与者返回 NaN。有办法解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644669/gkgamma-function-returns-nan-for-participants-with-perfect-performance</guid>
      <pubDate>Tue, 09 Apr 2024 20:20:41 GMT</pubDate>
    </item>
    <item>
      <title>固定效应回归：reghdfe 与带有假人的 reg</title>
      <link>https://stats.stackexchange.com/questions/644668/fixed-effects-regression-reghdfe-vs-reg-with-dummies</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644668/fixed-effects-regression-reghdfe-vs-reg-with-dummies</guid>
      <pubDate>Tue, 09 Apr 2024 20:05:24 GMT</pubDate>
    </item>
    <item>
      <title>生成每个 ID 具有多个记录的合成数据</title>
      <link>https://stats.stackexchange.com/questions/644667/generating-synthetic-data-with-multiple-records-per-id</link>
      <description><![CDATA[我想生成一个合成数据集，其中每个 ID 有多个记录，并且每个 ID 的记录之间保持自我一致性。
例如，想象一个数据集，其中 ID 是一家杂货店，每条记录是该商店在给定日期内各种商品的销售额。换句话说，多个时间序列。您可以想象，虽然所有商店都有全球趋势，但也有商店级别的趋势，而现实的数据集不仅必须保留全球趋势，还必须保留商店级别的趋势。也许 A 店在周末出售的薯条较多，而 B 店周末出售的薯条较少，但饼干较多。
对虚假记录 IID 进行采样的合成数据模型只能保留全球销售趋势（“周五薯条的销量通常比饼干多”）。复杂性又提高了一步的模型，例如 LSTM，可以保留在所有商店中表达的时间趋势（“如果饼干在时间 t-1 的销量少于薯片，那么它们在时间 t 的销量通常会更高”）。但是，我如何制作一个模型，让这些趋势在每个商店都有所不同（“在某些商店，薯片在周六的销量通常超过饼干，但在其他商店却恰恰相反”）？
我的一个想法是使用领域知识/集群将商店分配给 N 个“配置文件”之一，然后使用该配置文件作为功能。该模型自然能够捕获依赖性。也就是说，这种方法需要手动定义 N 并创建一组有限的配置文件。我正在寻找限制较少的东西，并且可以检测到比我手动检测到的更微妙的配置文件（如果存在）。
希望我已经很好地解释了我的问题 - 请随时要求澄清。相关论文的链接将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644667/generating-synthetic-data-with-multiple-records-per-id</guid>
      <pubDate>Tue, 09 Apr 2024 19:47:01 GMT</pubDate>
    </item>
    <item>
      <title>在现实世界中识别数字的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/644666/what-is-the-best-way-of-recognising-digits-in-the-real-world</link>
      <description><![CDATA[我花了很长时间从头开始实现神经网络（作为学习练习）。我在 MNIST 上的训练取得了良好的结果（测试数据超过 98%）。
与许多其他人一样，我尝试将我的模型应用于新用户绘制的数字，但我真的很难获得良好的结果（准确度 &lt; 50%）。
我做过的事情：

我正在拍摄 280 x 280 像素的 8 位灰度图像，
缩小至 28 x 28 像素。我正在使用 Qt 的缩放函数
并应用平滑变换。

我更改了图像，使其符合 MNIST 格式（黑色
背景即 0)

然后我将其转换为向量（逐行）。

我将对数归一化应用于相同的向量
我在 MNIST 训练时应用了标准化。


MNIST 图像和用户绘制的图像看起来比较相似。
这里是否缺少一些东西 - 我应该采取一些预处理步骤？或者 MNIST 样本的代表性不够？如果是后者，是否有更好的数据集可供使用（商业 OCR 公司使用什么）？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/644666/what-is-the-best-way-of-recognising-digits-in-the-real-world</guid>
      <pubDate>Tue, 09 Apr 2024 19:46:28 GMT</pubDate>
    </item>
    <item>
      <title>收敛的概率几乎确定，而现实中的概率为 0</title>
      <link>https://stats.stackexchange.com/questions/644665/almost-sure-probability-in-convergence-versus-0-probability-in-reality</link>
      <description><![CDATA[我对概率分布收敛的含义有一些疑问。考虑这个示例问题：对于抛出 $6x$ 次的公平骰子，对于整数 $x$，将 $y$ 定义为看到每个结果 $x$ 次的概率。
我之前的想法是，大数定律说 $$\underset{x \rightarrow \infty}{\lim} y = 1 \tag{1} $$
但情况似乎更加复杂。我们可以以封闭形式计算 $y$：
$$y = \dfrac{(6x)!}{6^{6x} (x!)^6} \quad \Rightarrow \quad \underset{x \rightarrow \infty} {\lim} y = 0\tag{2}$$
上面的问题让我想到了第二个例子，你们中的一些人可能更喜欢这个例子。
让我们在 $\{0, 1\}$ 的支持下定义随机变量 $X$ span&gt;，这样 $\mathbb{P}(X = 1) = 1/6$ 和 $\mathbb{ P}(X = 0) = 5/6$。使用定义
$$\bar{X}_n = \frac{1}{6n}\sum_1^{6n} X_i$$
我们有那个
$$\mathbb{P}(\bar{X}_n = 1/6) = {6n \选择 n}\left( \dfrac{1}{6} \right) ^n\left(\dfrac{5}{6} \right)^{5n}$$
由此可见
$$\underset{n \rightarrow \infty}{\lim}\mathbb{P}(\bar{X}_n = 1/6) = 0 \tag{3}$ $
现在，根据维基百科页面，根据大数定律，
$$\mathbb{P}( \underset{n \rightarrow \infty}{\lim} \bar{X}_n = 1/6) = 1 \tag{4}$ $
这说明了等式之间明显矛盾的原因。 (1) 和 (2) - 极限和概率的顺序不同。在我看来，两个方程。 （3）和（4）是有效的，这对我来说似乎很奇怪。我希望这两个方程应该具有相同的值。
是等式。 3 有效吗？如果是这样，为什么应该等式。 4 也有效吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644665/almost-sure-probability-in-convergence-versus-0-probability-in-reality</guid>
      <pubDate>Tue, 09 Apr 2024 19:42:46 GMT</pubDate>
    </item>
    <item>
      <title>在序列分析中将左侧缺失值视为无效</title>
      <link>https://stats.stackexchange.com/questions/644663/treat-left-missing-values-as-void-in-sequence-analysis</link>
      <description><![CDATA[我正在使用 Traminer 进行序列分析，并且有从 51 岁到 75 岁的就业序列。但是，由于一些参与者在 51 岁之后进入调查，因此某些序列开始较晚（留下缺失值）。我也有一些权利缺失，以及一些内部缺失的空白。
我想将内部缺失间隙视为附加状态，将左右间隙视为空隙。但是，如果我设置选项“DEL”对于左侧缺失值，序列会向左移动，而空白会出现在右侧。
对于如何处理留下的缺失间隙，以便将它们设置为无效而不改变序列，您有什么建议吗？我担心在使用 indel 成本时，移位序列会严重扭曲时间。
这是我的代码：
States_Wide.seq &lt;- seqdef(
                   States_Wide, # 选择数据
                   var = 2:26, # 包含序列的列
                   字母表=状态_字母表，
                   开始=51，左=“DEL”，右=“DEL”，间隙=“6”，缺失=NA，void=“%”，
                   xt步长 = 4)
]]></description>
      <guid>https://stats.stackexchange.com/questions/644663/treat-left-missing-values-as-void-in-sequence-analysis</guid>
      <pubDate>Tue, 09 Apr 2024 19:35:03 GMT</pubDate>
    </item>
    <item>
      <title>寻找关键数量</title>
      <link>https://stats.stackexchange.com/questions/644662/finding-a-pivotal-quantity</link>
      <description><![CDATA[0
我正在课堂上解决这个问题，其设置如下：
令 X 为 beta(θ,1) pdf 的单个观测值。
(b) 找到一个关键量，并用它来建立一个与(a)部分的区间具有相同置信系数的 CI。
在(a)部分我得到了e^{-1/2} - e^{-1} =.239。
我们在课堂上使用的书指出，对枢轴的一个很好的猜测是 $T=X^{\theta}$，我们应该使用它设置具有相同配置的 CI。系数。但我不明白为什么在这种情况下它是一个很好的支点。]]></description>
      <guid>https://stats.stackexchange.com/questions/644662/finding-a-pivotal-quantity</guid>
      <pubDate>Tue, 09 Apr 2024 19:09:48 GMT</pubDate>
    </item>
    <item>
      <title>当 p->1 在预测变量范围最大值时，二项式 gam 的置信区间异常大</title>
      <link>https://stats.stackexchange.com/questions/644661/abnormally-large-confidence-interval-with-binomial-gam-when-p-1-at-max-of-predi</link>
      <description><![CDATA[我正在运行一个游戏（R 中的 mgcv）来模拟时间对二项式响应（正样本或负样本）的非线性影响。这是此类模型的一个最小示例：
gam&lt;- gam(pcr ~ s(rel_time, k=7), family = binomial(link=“logit”), data=df)

对于其中一个物种，在预测变量范围 (rel_time) 的最后四分之一内仅存在正样本，因此 p 的预测实际值与预期的非常接近 1。然而，我也得到了异常大的预测置信区间（参见预测值图，以及下面的抖动观察结果）。

这就是我从模型计算预测值的方法：
new_data &lt;- data.frame(rel_time= seq(from=-33, to=710, by=1))

gam_pred &lt;- bind_cols(new_data, as.data.frame(predict(gam, newdata = new_data, se.fit = TRUE)))

test3_pred$fit_r&lt;- plogis(test3_pred$fit)
test3_pred$up&lt;- plogis(test3_pred$fit+2*test3_pred$se.fit)
test3_pred$向下&lt;- plogis(test3_pred$fit-2*test3_pred$se.fit)

看来威尔逊置信区间应该是正确的选择（关于二项式估计 0 或 1 的置信区间，但我不知道在从 gam 进行预测时如何计算它。
我尝试过不同的链接功能，但没有太大效果。
如果我运行一个简单的 glm，问题就会消失，但显然这是没有选择的。
顺便说一句：如果我不指定 k 小于 8，p 的估计值也会变得奇怪，并且下降到 0.2 左右，尽管只有正值：

从图中可以看出，采样间隔在采样周期的后半部分更长。当 k 不同时，我不相信这种变化是由于同一问题引起的。
如果需要，我可以共享数据。
如果有人可以提供有关如何处理此问题的建议，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/644661/abnormally-large-confidence-interval-with-binomial-gam-when-p-1-at-max-of-predi</guid>
      <pubDate>Tue, 09 Apr 2024 18:58:29 GMT</pubDate>
    </item>
    <item>
      <title>条件似然指数分布</title>
      <link>https://stats.stackexchange.com/questions/644660/conditional-likelihood-exponential-distribution</link>
      <description><![CDATA[设 $X_1, ... X_n$ 为 iid Exp($\lambda$)，其中 $\lambda &gt; 0$.
如果我们以某种方式被告知所有 $ 的最大似然估计 (MLE) 如何变化X_i$超出了他们的平均值？
（即：让我们以事件 $\{X_i &gt; E[X_i] | i = 1, ..., n\}$ 为条件）&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/644660/conditional-likelihood-exponential-distribution</guid>
      <pubDate>Tue, 09 Apr 2024 18:41:23 GMT</pubDate>
    </item>
    <item>
      <title>选择最合适的统计检验来比较属于两组的多个自变量</title>
      <link>https://stats.stackexchange.com/questions/644659/selecting-the-most-appropriate-statistical-test-for-comparison-of-multiple-indep</link>
      <description><![CDATA[我想比较两个地区的饮用水化学成分。一个地区流行一种疾病，而另一个地区几乎没有这种疾病。我测量了这两个村庄等量饮用水样本中 10 种化学物质的浓度。因此，我有两组饮用水，一组与疾病有关，另一组与疾病无关。比较这两组样品中化合物浓度的最佳统计检验是什么？我可以使用多重 t 检验（即 Welch t 检验）吗？如果是这样，是否需要对阿尔法通胀进行修正？如果不是，单向方差分析是否更合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/644659/selecting-the-most-appropriate-statistical-test-for-comparison-of-multiple-indep</guid>
      <pubDate>Tue, 09 Apr 2024 18:36:52 GMT</pubDate>
    </item>
    <item>
      <title>在测量函数的凸性方面，标准差和函数的二阶导数有什么区别？</title>
      <link>https://stats.stackexchange.com/questions/644655/what-is-the-difference-between-standard-deviation-and-the-second-derivative-of-a</link>
      <description><![CDATA[不确定这是否适合另一个 Stack Exchange，如果适合，请随意重定向。
正如标题所示 - $f(x)$ 与 $x= 之间的标准差有什么区别1,2,3...$ 以及函数的二阶导数来衡量函数的凸性？
对于某些上下文，我正在尝试构建函数凸性的度量（例如 $f(x)$ 的二阶导数），但我希望拥有一些非功能性的东西 - 这样我就可以避免 $x$ 的内生性，类似于一阶和二阶导数对于 $x$。
我知道这个问题的措辞可能不是最好的，请随时提出问题以进行澄清，我们很乐意提供更多详细信息。
--- 编辑 ---
$f(x)$ 的标准差是指计算 $f 值的标准差(1), f(2), f(3) ...$
因此，如果我们将 $f(x)$ 视为多项式，则较低的标准差意味着 $f(x)$ 都是相同的，我们有一些“平坦”的非凸多项式。这种逻辑反之亦然——较高的标准偏差将使“不太平坦”的结果变得“不那么平坦”。更加凸的多项式。
例如，如果我们有一个多项式 $f(x) = x^4$ 与一个  $g(x) = x^2$ 并且两者都在区间 $[-3,7]$ 内，即 $[-3,7]$ 的 class=&quot;math-container&quot;&gt;$f(x)$ 将低于 $g(x)$。]]></description>
      <guid>https://stats.stackexchange.com/questions/644655/what-is-the-difference-between-standard-deviation-and-the-second-derivative-of-a</guid>
      <pubDate>Tue, 09 Apr 2024 18:07:45 GMT</pubDate>
    </item>
    <item>
      <title>如何在内核技巧中找到K？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/644654/how-to-find-k-in-kernel-trick</link>
      <description><![CDATA[当使用所谓的“内核技巧”时，如何找到内核？这是 来自 quora 的一个例子：
&lt;块引用&gt;
简单示例：x = (x1, x2, x3); y = (y1, y2, y3)。那么对于函数 f(x) = (x1x1, x1x2, x1x3, x2x1, x2x2, x2x3, x3x1, x3x2, x3x3)，核是 K(x, y ) = ()^2。 

&lt;块引用&gt;
让我们插入一些数字以使其更直观：假设 x = (1, 2, 3); y = (4, 5, 6)。然后：
f(x) = (1, 2, 3, 2, 4, 6, 3, 6, 9)
f(y) = (16, 20, 24, 20, 25, 30, 24, 30, 36)
&lt;f(x)，f(y)&gt; = 16 + 40 + 72 + 40 + 100+ 180 + 72 + 180 + 324 = 1024

&lt;块引用&gt;
很多代数。主要是因为f是3维空间到9维空间的映射。

&lt;块引用&gt;
现在让我们使用内核：
K(x, y) = (4 + 10 + 18 ) ^2 = 32^2 = 1024
结果相同，但计算要容易得多。

她怎么知道选择$K(x,y)=(&lt;x,y&gt;)^2？$是否有一种算法可以遵循懂吗？或者这只是反复试验？还是一组启发式方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/644654/how-to-find-k-in-kernel-trick</guid>
      <pubDate>Tue, 09 Apr 2024 17:44:34 GMT</pubDate>
    </item>
    </channel>
</rss>