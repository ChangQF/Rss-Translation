<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 13 Nov 2024 01:15:09 GMT</lastBuildDate>
    <item>
      <title>重复测量方差分析/线性混合效应模型和缺失数据</title>
      <link>https://stats.stackexchange.com/questions/657171/repeated-measures-anova-linear-mixed-effects-model-and-missing-data</link>
      <description><![CDATA[我正在开展一项研究，测量 4 个时间点的幸福感，旨在确定整体幸福感是否有所增加。四个时间点所需的样本量为 24，三个时间点所需的样本量为 28。但是，我需要帮助来留住参与者。以下是详细情况：
调查 1：24 名参与者
调查 2：36 名参与者（调查 1 中有 8 名参与者）
调查 3：60 名参与者（调查 2 中有 24 名参与者，调查 1 中没有参与者）
调查 4：100 名参与者（与之前的调查有部分重叠）
为了分析数据，我只考虑那些至少完成了调查 2、3 或 4 中的两项调查的人。结果有 36 名参与者，大约 20% 的数据缺失。由于缺失数据超过 50%，我已排除调查 1 的参与者。
我的问题是：
仅包括完成调查 2-4 中至少两项调查的参与者是否具有统计意义？
我应该估算缺失数据并使用重复测量方差分析吗？还是线性混合效应模型可以更好地处理缺失数据？
我的模型很简单：
幸福感得分 - 因变量，时间 - 自变量。
任何建议都将不胜感激！我感谢您提供的任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/657171/repeated-measures-anova-linear-mixed-effects-model-and-missing-data</guid>
      <pubDate>Tue, 12 Nov 2024 23:06:25 GMT</pubDate>
    </item>
    <item>
      <title>加权 RMS 差异是否有一个普遍接受的定义？</title>
      <link>https://stats.stackexchange.com/questions/657170/is-there-a-commonly-accepted-definition-for-weighted-rms-difference</link>
      <description><![CDATA[假设有两个数据集 $x$ 和 $y$，均包含 $n$ 个数据点：$\{x_1,...,x_n\}$ 和 $\{y_1,...,y_n\}$，两个数据集之间最广泛认可的差异度量之一是它们的 RMS 差异，其定义很简单：
$$\mathbf{RMSD}=\sqrt{\frac{1}{n}\sum_{i=1}^n{(x_i-y_i)^2}}$$
如果已知某些数据点对对于由于领域特定的原因，可以通过将每对与权重关联起来来表示：$\{w_1,...,w_n\}$，其中 $w_i$ 为正实数。
因此，在这种情况下，人们将使用加权 RMSD 作为差异度量。但据我所知，wRMSD 没有普遍接受的定义，有两个合理的候选者：

加权差异的 RMS：$\sqrt{\frac{1}{n}\sum_{i=1}^n{[w_i(x_i-y_i)]^2}}$
加权平方差的均根：$\sqrt{\frac{1}{n}\sum_{i=1}^n{w_i(x_i-y_i)^2}}$

我的问题是，这两个公式是否普遍被接受为“加权 RMSD”或以其他名称命名？如果不是，那么这两个公式中的哪一个更适合用作两个数据集之间的差异统计量？]]></description>
      <guid>https://stats.stackexchange.com/questions/657170/is-there-a-commonly-accepted-definition-for-weighted-rms-difference</guid>
      <pubDate>Tue, 12 Nov 2024 22:35:28 GMT</pubDate>
    </item>
    <item>
      <title>模型堆叠的复杂性</title>
      <link>https://stats.stackexchange.com/questions/657169/model-stacking-intricacies</link>
      <description><![CDATA[我尝试使用模型堆叠方法，在训练集上训练基础模型后收集基础模型的结果。
但是，我发现自己有一个问题，那就是当我在验证集上训练元模型时，是否应该在基础模型训练中包含使用的特征。
我看到的优点是元模型可以使用特征以基础模型未看到的方式“调整”基础模型的结果，但缺点是通过基本上重新引入我在基础模型训练期间所做的相同信号而引入噪音。此外，我使用简单的对数回归作为我的元模型。
最后，如果我还打算对二元分类进行建模以尽量减少负对数损失，那么使用基础模型的概率预测或纯分类预测（我的数据集属于哪个类别）是否更有意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/657169/model-stacking-intricacies</guid>
      <pubDate>Tue, 12 Nov 2024 22:29:55 GMT</pubDate>
    </item>
    <item>
      <title>当比率有意义时，对治疗组与对照组进行统计比较</title>
      <link>https://stats.stackexchange.com/questions/657168/statistical-comparison-of-treatment-vs-control-when-ratio-is-meaningful</link>
      <description><![CDATA[我遇到了一个统计问题，不知道您是否愿意帮助我。我做过一个实验，测量了植物叶片中的荧光信号（来自标记蛋白），我想找出激素处理是否会使该信号与对照相比增强。我已进行了 4 次运行，每株植物有 3 个相等的叶片样本（rep），但不知何故实验条件（溶液年龄、机器、植物批次等）导致每次运行中获得的值之间存在相当大的差异。请参阅下面的一些数据；请注意，对照和处理条件实际上是不同的植物，因此数据不成对：
运行处理信号表示
1 对照 4.27 1
1 对照 3.85 2
1 对照 3.93 3
1 激素 5.14 1
1 激素 5.37 2
1 激素 4.13 3
2 对照 4.94 1
2 对照 4.43 2
2 对照 6.04 3
2 激素 9.42 1
2 激素 7.98 2
2 激素 5.95 3
3 对照 20.26 1
3 对照 19.98 2
3 对照 16.46 3
3 激素 24.06 1
3 激素 18.78 2
3 激素 17.56 3
4 对照 15.93 1
4 对照 12.99 2
4 对照12.71 3
4 激素 17.28 1
4 激素 18.39 2
4 激素 17.76 3

如您所见，实验运行 1 和 2 中的信号值与 3 和 4 有很大不同。然而，在运行中，激素治疗似乎一直在增加信号。我们从这四个实验运行的其他数据中看到了非常相似的结果。
我想对这两种治疗进行统计比较，但仅仅进行成对测试不会有太大帮助。我可以尝试控制实验运行引起的信号变化，方法是将激素值除以每次运行的对照值的平均值，以获得平均比率：
运行治疗平均值_信号
1 对照 1.00
1 激素 1.21
2 对照 1.00
2 激素 1.52
3 对照 1.00
3 激素 1.07
4 对照 1.00
4 激素 1.28

...但是，我正在将平均比率与对照进行比较...所有值都是 1.00（因此变化为零）。感觉好像我错过了什么，但我不知道是什么。任何帮助都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/657168/statistical-comparison-of-treatment-vs-control-when-ratio-is-meaningful</guid>
      <pubDate>Tue, 12 Nov 2024 22:13:15 GMT</pubDate>
    </item>
    <item>
      <title>我如何理解赌徒谬误？[重复]</title>
      <link>https://stats.stackexchange.com/questions/657166/how-can-i-understand-the-gamblers-fallacy</link>
      <description><![CDATA[假设你掷骰子 500 次。在这 500 次中你不可能永远掷出 6，不是吗？
但同时，每次掷骰子都是独立的，平均掷出 6 的概率只有 1/6。
那么... 认为第 501 次掷骰子“不太可能”不是 6 是对还是错？我只是很难解开这个谜团。]]></description>
      <guid>https://stats.stackexchange.com/questions/657166/how-can-i-understand-the-gamblers-fallacy</guid>
      <pubDate>Tue, 12 Nov 2024 20:43:54 GMT</pubDate>
    </item>
    <item>
      <title>排序样本的含义</title>
      <link>https://stats.stackexchange.com/questions/657161/meaning-of-sorted-samples</link>
      <description><![CDATA[假设您有一组来自某个分布的有限样本。
您取出这些样本，按值从小到大排序，然后制作图表。像这样：

横轴是排序位置（任意），纵轴是样本值。
我的问题是：这个形状说明了样本来自的分布是什么？我很想说它是累积分布函数的逆函数，但我无法证明这一点。
我知道它能说明很多关于分布的信息，因为我已经非常习惯阅读这些图表（因为在 Excel 2007 中制作直方图很麻烦）。例如，对于上图，我可以看到底层分布是一条钟形曲线，右尾较短，左尾较长。]]></description>
      <guid>https://stats.stackexchange.com/questions/657161/meaning-of-sorted-samples</guid>
      <pubDate>Tue, 12 Nov 2024 19:55:05 GMT</pubDate>
    </item>
    <item>
      <title>从专家判断中选择最佳类别样本的适当统计分析是什么？</title>
      <link>https://stats.stackexchange.com/questions/657160/whats-the-appropriate-statistical-analysis-for-selecting-best-category-exemplar</link>
      <description><![CDATA[我正在寻求有关适当统计分析的建议，以便根据我正在进行的虚假新闻实验中的专家判断选择最佳类别样本。
我的研究背景：

我构建了 39 个虚假新闻刺激。
11 位专家评委将每个刺激归类为 7 个可能的类别之一（名义数据）。类别 A、B、C、D、E、F 和“以上都不是”。结果是一个 39×11 矩阵（429 个单元格），其中每个单元格包含 7 个可能的类别之一。
我的目标是从六个类别中每个类别中选择总共 24 个最佳/最具代表性的样本。如果某些类别最终变得不平衡，或者最终出现一个没有任何刺激的类别，这都没关系。

当前分析：

我计算了 Fleiss&#39; Kappa 与 39 个刺激的总体一致性。
然后对于刺激选择，我开发了一个“一致性指数”，该指数减去第一个投票最多的类别的百分比减去第二个投票最多的类别（目的是“惩罚”刺激的模糊性）。


例如，如果 70% 的人投票给 A 类，15% 的人投票给 B 类，其余的人分布在其他类别中，则刺激获得 55 个百分点。
如果类别之间有平局，则刺激获得 0 分。


再次计算“最佳”24 个刺激子集的 Fleiss&#39; Kappa。

问题：

我没有关于我最终使用的“一致性指数”的参考资料，也找不到任何使用类似方法或存在类似问题的手册或论文，即必须找到类别的最佳代表。
Fleiss&#39; Kappa 用于估计多个评估者之间的一致性，但使用完整的数据集（具有 429 个值的矩阵）。据我了解，我需要为每个刺激单独估计一个指数。
当我在 RStudio 中修改 Fleiss&#39; Kappa 包以计算每个刺激的 kappa 时，我最终没有得到一个显著的 p 值（可能是因为每个刺激只有 11 个值，并且 Fleiss&#39; Kappa 不打算以这种方式使用）。
大多数系数都关注评估者之间的一致性，但我需要关注的是，其中哪一个刺激被大多数人认为是其类别的最佳典范。

问题：

选择最佳类别典范的适当统计分析是什么？
什么是分析这种类型数据的最合适的系数？ （我的意思是第二步）
是否有既定的方法，可根据多位评委的分类选择最佳类别范例？
Fleiss&#39; Kappa 是否以这些方式正确使用并考虑到这些目标？

我是认真的，感谢您提供的任何指导或相关参考资料，我将不胜感激。另外，真的希望我在这里提出的研究问题能够说清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/657160/whats-the-appropriate-statistical-analysis-for-selecting-best-category-exemplar</guid>
      <pubDate>Tue, 12 Nov 2024 19:38:12 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA：对于通货膨胀数据，对数差分比二阶差分更好吗？</title>
      <link>https://stats.stackexchange.com/questions/657158/arima-log-differencing-is-better-tnan-two-order-differencing-on-inflation-data</link>
      <description><![CDATA[我正在尝试对通货膨胀数据执行 ARIMA
我可以看到：

我需要两个顺序差分才能获得平稳性数据
并且只需要一个对数差分即可获得平稳性。
在对数差分中，我有两个数据下降，然后在 2020 年出现大幅飙升
在两次差分中，我首先出现大幅飙升，然后在 2020 年出现低点
两者在 ADF 测试中的 p 值几乎相同（约为 .01）。

在这种情况下，最好的差分方法是什么，以获得更好的 ARIMA？（我在 Rstudio 中工作）谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/657158/arima-log-differencing-is-better-tnan-two-order-differencing-on-inflation-data</guid>
      <pubDate>Tue, 12 Nov 2024 19:08:03 GMT</pubDate>
    </item>
    <item>
      <title>进行“最大 p 值估计”而不是最大似然估计</title>
      <link>https://stats.stackexchange.com/questions/657156/doing-maximum-p-value-estimation-instead-of-maximum-likelihood</link>
      <description><![CDATA[每当我们进行最大似然估计时，我们都会寻找最大化数据概率密度的参数。另一方面，当我们计算 p 值时，我们会查看获得至少与数据一样极端的事物的尾部概率。这种不匹配通常会导致数据在其自己的 MLE 参数上无法通过假设检验。
是否有一种技术可以最大化 p 值而不是最大化似然？这意味着我们正在寻找使我们的样本“最典型”的参数而不是最有可能。
当然，有很多不同的方法可以做到这一点 - 不同的尾部概率、检验统计量等。但任何直接最大化从样本的某些充分统计量中得出的尾部概率（而不仅仅是最大化密度）的基本方向都会很有趣。
例如，假设我们从 $[0, \theta]$ 均匀地抽取一个 $X$，并且我们想要估计 $\theta$。MLE 只是 $\hat \theta = X$。但是，假设我们使用双侧假设检验，以 $\hat theta$ 的值作为零假设，则 $X$ 是一个极端异常值，p 值为 0。选择 $\hat \theta$ 来最大化该 p 值，则会得到 $\hat \theta = 2X$，在这种情况下也与 MVUE 一致。]]></description>
      <guid>https://stats.stackexchange.com/questions/657156/doing-maximum-p-value-estimation-instead-of-maximum-likelihood</guid>
      <pubDate>Tue, 12 Nov 2024 18:04:13 GMT</pubDate>
    </item>
    <item>
      <title>柯西分布数据的模型比较</title>
      <link>https://stats.stackexchange.com/questions/657142/model-comparison-on-data-with-cauchy-distribution</link>
      <description><![CDATA[我感兴趣的是确定状态位置对磁场的依赖性。状态位置是通过将缩放的柯西分布拟合到表示每个磁场值的状态的峰值来确定的。然后构建一个似然函数，该函数由各个柯西分布及其拟合中位数和伽马值组成。

其中  表示磁场函数，该函数模拟峰值位置对磁场的依赖性，并通过最大化可能性，确定  中的拟合参数。
我想测试  的三个模型。
零假设是 B 独立的：
第一个替代方案添加了一个线性项：
第二个替代方案有一个二次项而不是线性项：
我想获得零假设的 p 值，然后确定如果零假设被拒绝，哪个备选假设更适合。为此，我研究了似然比检验和威尔克斯定理，该定理将检验统计量  近似为卡方分布

但是，我不确定结果是否可信，因为我只有 46 个不同磁场值的峰值位置。
为了获得实际分布，我对由 46 对峰值位置和磁场组成的全样本进行了非参数引导替换它是在 (B, ) 处拍摄的。这导致原始数据集上的测试统计量围绕测试统计量呈近似对称分布。这是有道理的，因为我预计某些数据点的残差会比其他数据点小。
为了使引导程序工作，我认为我需要在每个磁场值下多次运行相同的测量。这样，我将获得每个磁场的峰值位置分布，可以在引导程序期间重新采样。不幸的是，我无法进行更多测量，所以我正在寻找其他选择。]]></description>
      <guid>https://stats.stackexchange.com/questions/657142/model-comparison-on-data-with-cauchy-distribution</guid>
      <pubDate>Tue, 12 Nov 2024 13:53:40 GMT</pubDate>
    </item>
    <item>
      <title>广义加性模型中的平滑因子相互作用</title>
      <link>https://stats.stackexchange.com/questions/657140/smooth-factor-interactions-in-generalized-additive-models</link>
      <description><![CDATA[我目前正在尝试理解 GAM 模型中的平滑因子相互作用，但我很难理解主效应和交互效应之间的分离。考虑以下简单函数：
$$
f(x) = \sin(x) + A + A\times \cos(x), 
$$
其中 $A$ 是取值为 0 或 1 的因子变量。
对我来说，将不同的术语视为：
$\sin(x)$：协变量 x 的主要影响
$A$：因子变量的主要影响
$A\times\cos(x)$：A 和 x 之间的相互作用。
我现在构建一个合成数据集，如下所示如下：
data &lt;- expand.grid(x = seq(0,10), A = c(0,1))
data$y &lt;- sin(data$x) + data$A + data$A*cos(data$x)
data$A &lt;- as.factor(data$A)

我使用一个简单的交互模型来拟合这些：
model &lt;- mgcv::gam(y ~ s(x) + A + ti(x, by = A),
data = data,
family = gaussian(),
method = &quot;REML&quot;)

我天真的期望是这个模型能够准确恢复上面的主要和交互效应。但这不是我从模型摘要或结果平滑中看到的。我的模型规范是否错误，或者我误解了平滑因子相互作用？
系列：高斯

链接函数：身份

公式：
y ~ s(x) + A + ti(x, by = A)

参数系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.12829 0.07626 1.682 0.126 
A1 0.96205 0.10785 8.920 7.28e-06 ***
---
显著性。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df F p 值 
s(x) 6.675 7.738 12.784 0.000457 ***
ti(x):A0 2.666 2.827 5.253 0.028219 * 
ti(x):A1 1.342 1.474 0.892 0.406407 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

排名：18/19
R-sq.(adj) = 0.937 偏差解释 = 97.2%
-REML = 19.568 尺度估计 = 0.063974 n = 22

s(x):

ti(x,A=0):

ti(x,A=1)
]]></description>
      <guid>https://stats.stackexchange.com/questions/657140/smooth-factor-interactions-in-generalized-additive-models</guid>
      <pubDate>Tue, 12 Nov 2024 12:23:29 GMT</pubDate>
    </item>
    <item>
      <title>执行单样本加权 t 检验的自由度是多少</title>
      <link>https://stats.stackexchange.com/questions/657139/what-are-the-degrees-of-freedom-for-performing-a-1-sample-weighted-t-test</link>
      <description><![CDATA[我对一批生命中的死亡经历进行了 7 年的观察。我假设每年的经历与其他年份无关。对于每一年，我们都有一个预期死亡人数和一个实际死亡人数。我想对实际死亡人数与预期死亡人数的比率进行加权 t 检验，以检验 A/E 是否不等于 1。
权重表示该年经验的可信度。
我可以计算加权样本均值 x_bar，本文 (https://seismo.berkeley.edu/~kirchner/Toolkits/Toolkit_12.pdf) 解释了如何获取加权样本方差。
我还可以通过将 root(n) 替换为 root(权重平方和/权重平方和) 来计算适当的检验统计量。
我的问题与临界值和自由度有关。我不确定如何计算自由度。我的直觉是自由度应该只是 6，因为我们有 7 个独立观察值，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/657139/what-are-the-degrees-of-freedom-for-performing-a-1-sample-weighted-t-test</guid>
      <pubDate>Tue, 12 Nov 2024 12:21:52 GMT</pubDate>
    </item>
    <item>
      <title>带样条协变量的逻辑回归模型</title>
      <link>https://stats.stackexchange.com/questions/657144/logistic-regression-model-with-splines-covariates</link>
      <description><![CDATA[我正在尝试在 R 中建立一个逻辑回归模型，并使用样条函数检查某些协变量是否可能遵循非线性分布。
我使用的数据集是威斯康星州乳腺癌：
例如，我通过执行以下操作检查了 fractal_dimension_mean 列的线性
fit.splines.fractal &lt;- lrm(diagnosis ~ 
rcs(fractal_dimension_mean, 4), data=data)
print(fit.splines.fractal) # 非线性

我得到了这个：
Coef S.E. Wald Z Pr(&gt;|Z|)
截距 -2.4383 0.4609 -5.29 &lt;0.0001
fractal_dimension_mean -2.1338 0.4876 -4.38 &lt;0.0001
fractal_dimension_mean&#39; 9.3886 2.3722 3.96 &lt;0.0001 
fractal_dimension_mean&#39;&#39; -23.0268 6.2039 -3.71 0.0002

现在据我所知，这个变量的分布似乎是非线性的，因此我应该考虑将此列的复数形式添加到模型中。
所以我所做的就是创建一个函数来添加这些变量的复杂形式，并尝试对模型变量使用前向选择方法：
spline_vars &lt;- c(&quot;texture_se&quot;, &quot;fractal_dimension_mean&quot;)

# formula:
formula &lt;- as.formula(paste(
&quot;diagnosis ~&quot;, 
paste(
lapply(names(data), function(var) {
if (var %in% spline_vars) {
paste0(&quot;rcs(&quot;, var, &quot;, 4)&quot;) # rcs() for splines
} else if (var != &quot;diagnosis&quot;) {
var # 保留变量而不进行变换
}
}), 
collapse = &quot; + &quot;
)
))

model_null &lt;- glm(diagnosis ~ 1, data = data, family = binomial) # 空模型
model_full &lt;- glm(formula, data = data, family = binomial) # 完整模型

# 正向选择
model_forward &lt;- stepAIC(model_null, scope = list(lower = model_null, 
upper = model_full), direction = &quot;forward&quot;)
summary(model_forward)

现在，由于经过转换的变量的重要性，我认为模型会将它们作为协变量，但与使用不经过转换的前向选择方法相比，我获得了更大的 AIC 和对数似然。我做错了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657144/logistic-regression-model-with-splines-covariates</guid>
      <pubDate>Tue, 12 Nov 2024 12:02:15 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助 F 统计要求</title>
      <link>https://stats.stackexchange.com/questions/657134/need-help-f-statistics-requirment</link>
      <description><![CDATA[我做论文的时候卡在F检验，之前用0.05或者5%的概率值，但是检验结果不够或者超出条件，现在想试试用0.1或者10%的概率值来满足条件。
我的问题是，10%的概率值有没有依据或者参考，这个概率值一定要是5%吗？有参考资料的请帮忙，谢谢
我现在在eviews 10上使用面板模型]]></description>
      <guid>https://stats.stackexchange.com/questions/657134/need-help-f-statistics-requirment</guid>
      <pubDate>Tue, 12 Nov 2024 10:18:11 GMT</pubDate>
    </item>
    <item>
      <title>如何对各组进行比较，同时考虑所有组的每日波动？</title>
      <link>https://stats.stackexchange.com/questions/657074/how-to-compare-groups-while-accounting-for-daily-fluctuations-in-all-groups</link>
      <description><![CDATA[有一项新技术可以从地表水中获取和储存热量：
在夏季，一台机器将湖中的热水泵送到热交换器。热量被转移到地下水库（例如，在冬季可用于加热建筑物）。
在某些情况下，在热交换器前放置过滤器，以防止水生生物和碎屑穿过或堵塞热交换器。
因此，这台机器有 2 或 3 个部件：泵、热交换器和（可能）过滤器。
在机器之前和每个机器部件之后都有关于水的化学参数的数据。例如：叶绿素 a 浓度或溶解氧浓度。
每两周在机器内/周围的至少两个位置测量一次化学参数。测量一个位置和另一个位置之间间隔 30 分钟。
现在，我想知道是否有任何机器部件影响化学参数。例如：叶绿素浓度是否会因过滤器、热交换器和/或泵而下降？如果会，下降多少？
问题在于，天然湖泊中的化学参数波动很大。叶绿素浓度可能在几分钟内很高，而在下几分钟内很低。而且某一天的浓度可能通常高于另一天。这实际上没有简单的（线性）模式。
我不知道我是否可以校正一天中的变化。
为了校正天之间的变化，我想我需要分别比较每个机器部件在每个测量日的测量值。例如，2024 年 11 月 11 日，过滤后的叶绿素 a 浓度明显低于湖中的浓度，但在 2024 年 9 月 8 日和 2024 年 10 月 5 日则并非如此。
但是，我如何使用所有这些 p 值来得到一个答案：过滤器是否降低了叶绿素 a 浓度？]]></description>
      <guid>https://stats.stackexchange.com/questions/657074/how-to-compare-groups-while-accounting-for-daily-fluctuations-in-all-groups</guid>
      <pubDate>Mon, 11 Nov 2024 12:00:47 GMT</pubDate>
    </item>
    </channel>
</rss>