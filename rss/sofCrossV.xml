<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 18 Jun 2024 01:04:40 GMT</lastBuildDate>
    <item>
      <title>当事件发生的可能性较低时，相关系数较高，这是如何发生的？</title>
      <link>https://stats.stackexchange.com/questions/649417/correlation-coefficent-is-higher-when-likelihood-of-an-event-is-lower-how-does</link>
      <description><![CDATA[我有不同的变量，我感兴趣的是它们是否会影响通过/失败率。
为了了解我可以使用哪些变量作为领先指标，我提取了不同的变量，例如“辅导”、“学生”、“高收入家庭”。
由于通过失败变量是二进制的，变量辅导、学生和高收入也是二进制的，所以我提取了 phi 系数。
我还将通过/失败率视为辅导、学生或高收入存在的条件概率。
对于某些变量，即使条件概率的平均值使得当学生存在变量时通过的可能性更大，但相关性较低。
这可能吗？有人能解释一下这是怎么发生的吗？还是我的数学有问题？
]]></description>
      <guid>https://stats.stackexchange.com/questions/649417/correlation-coefficent-is-higher-when-likelihood-of-an-event-is-lower-how-does</guid>
      <pubDate>Mon, 17 Jun 2024 23:56:06 GMT</pubDate>
    </item>
    <item>
      <title>帮助进行 PSD 图形解释和时间序列分析</title>
      <link>https://stats.stackexchange.com/questions/649415/help-with-psd-graph-interpretation-and-time-series-analysis</link>
      <description><![CDATA[我对时间序列分析还很陌生，目前正在研究它。我最近的工作需要我处理由 VASP AIMD 生成的时间序列。我尝试了功率谱密度分析和 ARMA 建模，但没有成功。我想知道是否有人有见解或以前解决过类似的问题。
我尝试上传一些图像，但由于某种原因我无法上传。]]></description>
      <guid>https://stats.stackexchange.com/questions/649415/help-with-psd-graph-interpretation-and-time-series-analysis</guid>
      <pubDate>Mon, 17 Jun 2024 23:35:55 GMT</pubDate>
    </item>
    <item>
      <title>需要对具有聚类的分层随机样本进行复杂样本分析</title>
      <link>https://stats.stackexchange.com/questions/649414/need-of-complex-sample-analysis-for-a-stratified-random-sample-with-clusters</link>
      <description><![CDATA[我在一篇横断面论文中介绍了我们的集群随机 RCT 的基线结果。横断面研究采用分层随机抽样设计，以集群为抽样单位。共有来自 2 个层次的 30 个集群，参与者总数为 481 人。我进行了双变量和多变量逻辑回归分析（不是复杂样本分析）。我们一开始没有计算抽样权重。
在这样的研​​究设计中不进行复杂样本分析是一个很大的统计缺陷吗？如果有人可以指导我，我该如何解决这个问题，那就太好了。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649414/need-of-complex-sample-analysis-for-a-stratified-random-sample-with-clusters</guid>
      <pubDate>Mon, 17 Jun 2024 23:32:54 GMT</pubDate>
    </item>
    <item>
      <title>具有平方项的 AR(1) 的协方差平稳性？</title>
      <link>https://stats.stackexchange.com/questions/649413/covariance-stationarity-for-an-ar1-with-squared-terms</link>
      <description><![CDATA[我有一个简单但令人费解的问题。我熟悉如何确定 AR(p) 过程的平稳性：查看特征方程的单位根。如果我们的 AR(p) 过程中有更高的项会怎样？
假设我们有一个时间序列，并希望使用线性和二次项来估计 AR(1) 过程：
$y_t=\beta_0 +\beta_1 y_{t-1}+\beta_2 y_{t-1}^2 +\epsilon_t$。为简单起见，我们假设$\mathbb{E}[\epsilon_t],\mathbb{E}[\epsilon_t^2]&lt;\infty$。
问题：如何确定该序列是否为弱平稳？
非常感谢您提供的任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/649413/covariance-stationarity-for-an-ar1-with-squared-terms</guid>
      <pubDate>Mon, 17 Jun 2024 22:53:01 GMT</pubDate>
    </item>
    <item>
      <title>使用贝叶斯估计器根据游戏次数调整胜率</title>
      <link>https://stats.stackexchange.com/questions/649411/adjust-winrates-based-on-number-of-games-played-using-bayesian-estimator</link>
      <description><![CDATA[我正在根据在线视频游戏的胜率对他们进行排序，但我试图使用他们获得该胜率的游戏数量。其背后的想法是，尽管理论上 9 胜 1 负 (0.9) 比 17 胜 2 负 (~0.89) 的胜率更高，但后者更令人印象深刻，因为玩家能够在更多游戏中保持这一胜率，从而使其更有意义和令人印象深刻。
我的数据集各不相同，我想我需要提到我正在处理的两个类别，因为我认为它可能会影响整体问题，因为我正在尝试开发一种适用于这两种情况的方法。因此，这些数据集基本上是庞大玩家群 (这里指的是数百万) 的子集，每个数据集都包含游戏中特定角色的玩家胜负情况。玩家需要使用某个角色玩过至少 10 场游戏才能出现在相应的子集中。每个子集最多可包含 5000 名玩家（即他们的获胜次数和失败次数）。最多可包含 5000 名玩家这一事实非常重要，因为这意味着当子集包含 $&lt;5000$ 名玩家时，它包含使用该角色玩过 10 场以上游戏的全部玩家群体（即优秀和玩家），而当子集恰好包含 $5000$ 名玩家时，这意味着它本身是一个更大子集的子集，该子集包含使用该角色玩过 10 场以上游戏的玩家（即最佳玩家）。在第二种情况下，我无法获取缺失的统计数据（其大小、平均值、方差……等），也不知道这 5000 名玩家是如何选择的，除了选择大致使用胜率以及其他统计数据。总结一下，当其规模低于$&lt;5000$角色的总玩家数时，当子集包含少于 5000 名玩家时，他们的胜率可能是好或坏，因为它代表了频谱的实际整体，而当子集包含恰好 5000 名玩家时，他们的胜率很可能是好的，因为它代表了频谱的较高部分，但实际频谱大小未知。
这里有两个数据样本来说明我的意思：


请注意，排名会根据使用的胜率而变化，每个 x 并不对应同一个玩家。
到目前为止，我在 Reddit 帖子 上发现了贝叶斯估计器，尽管起初我以为这是一种晦涩难懂的技术，但我还是尝试了一下，并根据新修改的胜率对我的数据进行了排序，最终它在我的数据上运行良好，尽管我并不真正理解为什么或如何。基本上，我从数据集中计算出它的总获胜次数$W$、总失败次数$L$、它的整体胜率$\overline{r}=\frac{W}{W+L}$、它的整体胜率方差、一个因子$f=\frac{\overline{r}(1-\overline{r})}{v}-1$和两个参数$\alpha=\overline{r}\times f$和$\beta=(1-\overline{r})\times f$。然后我计算每个新的胜率$\frac{w+\alpha}{w+\alpha+l+\beta}$。
它有效吗？如果有效，这是解决这类问题的方法吗？
排序后，我需要从最好的（因此是第一个排序步骤）到最不适合我的问题进行处理，所以我需要某种阈值，但由于我不太明白我在上一步做了什么，我很难解释这一点，因此设置了那个阈值。在处理原始胜率时，设置它非常容易，因为这个值实际上代表了我熟悉的东西，并且可以轻松设置阈值，但由于这个新指标是动态生成的，我有点不知所措，甚至当我考虑我的数据集的性质时，我想知道它会如何影响新的胜率以及我需要解释它们的方式。
我唯一的想法是使用新的调整胜率进行排序，但仍然使用更“通用”的正常胜率，所以我真的不需要再费心去理解这个新的胜率了，只要确保它在我在文章开头提到的两种情况下排名很好就可以了。]]></description>
      <guid>https://stats.stackexchange.com/questions/649411/adjust-winrates-based-on-number-of-games-played-using-bayesian-estimator</guid>
      <pubDate>Mon, 17 Jun 2024 22:06:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 piecewiseSEM 中的 glmmTMB 拟合的零通胀模型摘要</title>
      <link>https://stats.stackexchange.com/questions/649410/summary-of-the-zero-inflation-model-fitted-with-glmmtmb-from-piecewisesem</link>
      <description><![CDATA[最近我一直在使用 R 中的 piecewiseSEM 包研究结构方程模型。模型中指定了五条路径，但其中有些路径的数据被发现是零膨胀的。因此，我专门使用 glmmTMB 包对那些存在零膨胀问题的路径进行建模。
然后我为 SEM 运行 summary()，检查每条路径的系数，发现 SEM 中零膨胀模型的系数与 glmmTMB 中条件模型的系数相同。在这种情况下，我如何才能从 piecewiseSEM 的摘要中获得零膨胀模型输出？或者这是否意味着我只能从 SEM 中获得条件模型的摘要结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/649410/summary-of-the-zero-inflation-model-fitted-with-glmmtmb-from-piecewisesem</guid>
      <pubDate>Mon, 17 Jun 2024 21:46:18 GMT</pubDate>
    </item>
    <item>
      <title>了解加速故障时间分析中频率派和贝叶斯参数威布尔模型之间的差异</title>
      <link>https://stats.stackexchange.com/questions/649408/understanding-discrepancies-between-frequentist-and-bayesian-parametric-weibull</link>
      <description><![CDATA[目前正在识别一个贝叶斯威布尔生存 AFT 模型，该模型等同于 R 中 Survival 包的 survreg() 威布尔 AFT 模型结果。我偶然发现了此出版物，我正在尝试使用低信息先验匹配 survreg 结果。我还没有成功。
这两个模型是否等效（bayewei 与 freqwei）？如果是，为什么结果不同，我如何获得可比较的结果？
 mc&lt;- structure(list(V1 = c(5.3, 6.8, 5.7, 3.7, 6, 6.3, 7.9, 5.9, 7.6, 
7.1, 6, 6.9, 6.1, 8.8, 5.6, 6.1, 5, 6.6, 5.6, 6.1), 
V2 = structure(c(1L, 
1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 
2L, 2L, 2L), levels = c(&quot;0&quot;, &quot;1&quot;), class = &quot;factor&quot;), 
V3 = c(0, 
0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1), 
X = c(1.65, 
1.79, 1.77, 2.74, 4.62, -0.86, 2.7, 3.47, 1.95, 4.3, 2.52, 1.95, 
2.78, 2.7, 4.25, -0.19, 3.76, 0.68, 1.48, -0.06), 
时间 = c(38.863, 
24.2, 120.373, 16.5, 115.533, 8.613, 106.997, 105.71, 105.963, 
35.42, 107.613, 14.113, 105.82, 14.377, 99.253, 34.793, 96.657, 
94.347, 91.19, 8.613), 
Status = c(0, 0, 0, 1, 0, 1, 0, 0, 0, 
1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1)), 
row.names = c(1L, 2L, 4L, 
5L, 7L, 9L, 11L, 12L, 14L, 20L, 21L, 24L, 25L, 31L, 32L, 33L, 
37L, 40L, 41L, 42L), class = &quot;data.frame&quot;)

library(rjags)
library(survival)

BayesSurv&lt;-function(form=&quot;X&quot;, data=mc, model=&quot;weibull&quot;,
Prior_mu=0, Prior_prec=1,var,
eventvariable=&quot;Status&quot;,
timevariable=&quot;Time&quot;,
niter=10000, nthin=10,nburn=1000){
.formula &lt;- reformulate(form)
data$event&lt;-data[,eventvariable]
data$time&lt;-data[,timevariable]
X &lt;- model.matrix(object=.formula, data = data)

time_un &lt;- 数据$time[data$event==1]
cen_un &lt;- 数据$time[data$event==1]
is.censored_un &lt;- rep(0, length(cen_un))
X_un &lt;- X[data$event==1, ]

cen_cen &lt;- 数据$time[data$event==0]
time_cen &lt;- rep(NA, length(cen_cen))
is.censored_cen &lt;- rep(1, length(cen_cen))
X_cen &lt;- X[data$event==0, ]

time &lt;- c(time_un, time_cen)
cen &lt;- c(cen_un, cen_cen)
is.censored &lt;- c(is.censored_un, is.censored_cen)
Xnew &lt;- rbind(X_un, X_cen)

cat(&quot;model{ 
for(i in 1:n){
is.censored[i]~dinterval(time[i],cen[i])
time[i]~dweib(alpha,lambda[i])
lambda[i]&lt;-exp(-mu[i]*alpha)
mu[i]&lt;-inprod(beta[],X[i,])}

#先验分布
for(l in 1:(Nbetas)){
beta[l]~dnorm(mu.betaMain[l],prec.betaMain[l])}
alpha ~ dunif(0, 10)
}&quot;,file = &quot;AFT.txt&quot;)

d.jags &lt;- list(n = nrow(X), time = time, cen = cen, X = Xnew, is.censored = is.censored, Nbetas = ncol(X),mu.betaMain=prior_mu,prec.betaMain=prior_prec)
i.jags &lt;- function() list(beta = rnorm(ncol(X),sd = 1), alpha = runif(1,min = 0.1,max = 10))
p.jags &lt;- c(&quot;beta&quot;, &quot;alpha&quot;)

m1 &lt;- rjags::jags.model(data = d.jags, file = &quot;AFT.txt&quot;, inits = i.jags, n.chains = 1)

# 老化和更新
update(m1, nburn)
res &lt;- coda.samples(m1, variable.names = p.jags, n.iter = niter, thin = nthin)
results &lt;- as.mcmc(do.call(rbind, res))

return(results)
}

freqwei&lt;-summary(survreg(Surv(Time,Status)~V1 + V2 + V3 + X, data=mc))

outn&lt;-BayesSurv(form=&quot;V1 + V2 + V3 + X&quot;,prior_mu=c(0,rep(0,5)),prior_prec=c(rep(0.001,5)),
data = mc,niter = 20000)
bayewei=summary(outn)
bayewei

BOut&lt;-cbind(freqwei$coefficients,
bayewei[2]$quantiles[,3][-1])
BOut
]]></description>
      <guid>https://stats.stackexchange.com/questions/649408/understanding-discrepancies-between-frequentist-and-bayesian-parametric-weibull</guid>
      <pubDate>Mon, 17 Jun 2024 21:04:44 GMT</pubDate>
    </item>
    <item>
      <title>什么使得统计数据对于蒙特卡罗模拟有效？</title>
      <link>https://stats.stackexchange.com/questions/649407/what-makes-a-statistic-valid-for-monte-carlo-simulation</link>
      <description><![CDATA[不久前，我读了Garland 等人 (1993) 研究两组动物（比如食草动物和食肉动物）在某些特征的平均值上是否存在差异，比如它们寻找食物所穿越的领地面积。Garland 等人采取的方法1993 年是进行蒙特卡罗模拟方差分析，我们根据零模型模拟两种特征的演变，然后为每个结果数据集计算方差分析 F 统计量以获得 F 统计量的正确零分布，以便我们可以看到我们的真实数据集的 F 统计量是否在前 5% 并因此具有显著性。
这一切都很好，但最初我认为一个令人满意的方法是简单地测量每个模拟的两个组之间的平均差异，并创建这些差异的分布或它们的绝对值。然后，如果实际数据的差异在前 5% 之内，我就会知道这些组存在显著差异。
我现在明白，特定方法不适用于该特定问题，因为它没有考虑两个组中的差异，这意味着一些具有前 5% 差异的组实际上并不显著，因为它们异常高的方差意味着组之间的差异实际上并不足以证明称这两个组存在显著差异。但一般来说，我如何知道我为测试某事而开发的统计数据是否正确？必须遵循哪些规则？
例如，在我当前的问题中，我有两个不同的进化模型可以对数据负责。我的想法是根据两个竞争模型模拟一组数据集，然后对于每个假设集，通过对相似值进行分箱来创建直方图，然后将观察到的数据集与每个直方图中的正确箱进行匹配，并使用真实数据集匹配的两个箱的相对高度来判断一个模型或另一个模型生成数据的相对可能性。
例如，假设我有两只动物，每只动物有两个测量值，饮食中蛋白质的百分比（0-100%）和领土长度（0-100 公里），我的第一个模型假设 4 个观测值来自具有零相关性、平均值为 0 和标准差为 1 的多元正态分布，我的第二个模型假设 4 个观测值的向量来自具有零相关性、平均值为零和标准差为 sqrt(2) 的多元正态分布。然后，在这种情况下，我将从两个分布中各抽取 10,000 个样本，然后通过计数对它们进行分类，例如，有多少模拟结果的第一维值在 0 到 0.1 之间，它们的第二维值也在这个范围内，等等。然后，如果我的真实数据集是 (0.01,0.09,0.08,0.08)，我可以看到，第一个假设的相关箱中可能有 10 个样本，而第二个假设下的同一个箱中只有两个样本，因此得出结论，第一个假设更好地解释了数据。但当然，我不知道这是否是一种有效的方法，因为我不了解如何使用蒙特卡罗测量和测试哪些类型的事物。
感谢您的帮助。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/649407/what-makes-a-statistic-valid-for-monte-carlo-simulation</guid>
      <pubDate>Mon, 17 Jun 2024 20:56:32 GMT</pubDate>
    </item>
    <item>
      <title>离群值稳健主成分分析的解释是什么？</title>
      <link>https://stats.stackexchange.com/questions/649406/what-is-the-interpretation-of-outlier-robust-principal-component-analysis</link>
      <description><![CDATA[有一组方法称为“稳健”主成分分析（此处，“稳健”表示能够抵抗异常值的影响）。一个例子是 Hubert 等人的“ROBPCA：一种稳健主成分分析的新方法”，摘自 Technometrics（2005 年）：https://doi.org/10.1198/004017004000000563。特别是在那篇论文中，一部分观测值（例如 75%）用于估计主成分，因为这些观测值被视为非异常值。然后，本文提出了旨在识别候选异常值的方法。
如果调查发现的异常值，我可以看到拥有一种可以帮助识别异常值的 PCA 方法的价值。如果某些异常值被认为不适合包含在其余数据中（可能是因为它们代表受污染的结果，或者来自与其他数据差异太大而无法归为一类的群体），则可以将其删除。但是，假设某些被识别为“异常值”的观察结果被判定为样本内，不应修改或排除。那么，我对使用生成的 PC 来替代传统（假设非稳健）PC 感到紧张。有理论可以解释传统 PC 的含义以及与群体相关的估计值。我不知道稳健 PC 的类似物是什么，它们在估计什么，以及它们所估计的内容是否可取或有意义。
因此，假设稳健 PCA 识别为“异常值”的观测值保留在样本中。稳健 PCA 在总体中的估计是什么，为什么我要关心它？为什么我应该继续使用稳健 PCA？]]></description>
      <guid>https://stats.stackexchange.com/questions/649406/what-is-the-interpretation-of-outlier-robust-principal-component-analysis</guid>
      <pubDate>Mon, 17 Jun 2024 20:17:26 GMT</pubDate>
    </item>
    <item>
      <title>平均值的不确定性</title>
      <link>https://stats.stackexchange.com/questions/649405/uncertainty-of-mean</link>
      <description><![CDATA[假设我有 $N$ 个测量值，每个测量值的误差估计为 $\delta$，即 $x_1\pm\delta,x_2\pm\delta,\dots,x_N\pm\delta$。估计平均值误差 $(x_1+x_2+\dots +x_N)/N$ 的最佳方法是什么？我是否需要以某种方式应用平均值的标准误差 (SEM)？
更新：为了更准确地说明我的情况，我使用蒙特卡洛模拟估计了网格中每个像素的概率。现在我想估计网格某些区域的平均概率（总概率）。 $x_i$ 是感兴趣区域中的不同像素，$\delta$ 由蒙特卡洛迭代次数给出。]]></description>
      <guid>https://stats.stackexchange.com/questions/649405/uncertainty-of-mean</guid>
      <pubDate>Mon, 17 Jun 2024 19:49:53 GMT</pubDate>
    </item>
    <item>
      <title>维也纳证券交易所的机器学习：预测 ATX 指数的炒作并对顶级上市公司进行情绪分析 [重复]</title>
      <link>https://stats.stackexchange.com/questions/649404/ml-on-vienna-stock-exchange-predicting-hypes-for-the-atx-index-and-conducting-s</link>
      <description><![CDATA[大家好，很高兴认识你们！:)
我是这个论坛的新手...
我想练习机器学习，创建一个模型，预测 ATX 指数（奥地利交易指数）的股票炒作情况，并检测 3 个不同短期跨度（6 个月、1 年、2 年）的顶级上市公司。
要预测炒作情况，想法是使用特定时间跨度的某个正回报，例如半年内 30% 或一年内至少 60%。
然后，我想检测维也纳证券交易所主要推动 ATX 上涨和下跌的关键股票上市公司，例如检查在考虑两个连续时间跨度（例如 6 个月和 1 年或 1 年和 2 年）时 5 家顶级上市公司是否以及如何变化。
对于第二部分，我将使用情绪分析。
为了检测 ATX 炒作，我尝试基于 ATX 时间序列（每日回报）构建随机森林分类器，但我担心结果可能不准确，因为每日回报总是随机的。
我的问题是：
-您是否知道如何预测给定时间跨度（例如 6 个月、1 年和 2 年）内 ATX 的炒作，而不依赖于每日回报？
-您是否建议任何可靠的来源，我可以在哪里找到足够的材料来对维也纳证券交易所的顶级上市公司进行情绪分析？我不确定在哪里可以找到关于奥地利股票的足够和完整的文本内容来进行情绪分析。
我期待与您讨论这些主题 :)
非常感谢
BR
Jasmine]]></description>
      <guid>https://stats.stackexchange.com/questions/649404/ml-on-vienna-stock-exchange-predicting-hypes-for-the-atx-index-and-conducting-s</guid>
      <pubDate>Mon, 17 Jun 2024 18:56:18 GMT</pubDate>
    </item>
    <item>
      <title>对于理想的卡尔曼滤波器，我认为 NEES 测试通过，但 NIS 测试没有通过？</title>
      <link>https://stats.stackexchange.com/questions/649403/for-an-ideal-kalman-filter-i-have-that-the-nees-test-passes-but-nis-test-does-n</link>
      <description><![CDATA[抱歉，这更像是一个调试问题，但我已经在这个本应简单的 NIS 测试上卡了很长时间。如果有人知道任何涵盖 NIS 测试理论或实施的资料，我一定会很感激任何链接。
所以，我只是在一个玩具问题上运行一个非常直接的卡尔曼滤波器来检查我的理解。我有 LTI 离散系统
$x_{k+1}=F x_k+w_k$
$y_k=Hx_k+v_k$
其中 $w_k \sim N(0,\sigma_w^2)$ 和 $v_k \sim N(0,\sigma_v^2)$ 分别是白过程和测量噪声，协方差为 $Q$ 和 $R$。
这些用于生成真实状态$x_k$和获得的测量值$y_k$（我只是在 MATLAB 中使用 mvnrnd 来获取白噪声样本）。
然后，我还运行了简单的卡尔曼滤波方程。有了初始状态误差协方差 $\hat{P}_0$ 和初始校正状态向量 $\hat{x}_0$，我就可以使用这些函数向前积分
$\tilde P_k=\hat{P}_{k-1}$
$\tilde x_k=F \hat{x}_{k-1}$
$K_k=\tilde P_k H^T (H \tilde P_k H^T +R )^{-1}$
$\hat{P}_k=(1-K_k H) \tilde P_k (1-K_k H)^T + K_k R K_k^T$
$\hat{x}_k=\tilde{x}_k+K_k(y_k-H \tilde x_k) $
然后，我按照此处讲义中的第 2.2.3 节执行 NIS 测试以确定其一致性：
https://www.robots.ox.ac.uk/~ian/Teaching/Estimation/LectureNotes2.pdf
为此，我制定了创新协方差
$S_k=H \hat{P}_k H^T + R$
我从中得出归一化创新误差
$e_k=[H(x_k-\hat{x}_k)]^T S_k^{-1} [H(x_k-\hat{x}_k)]$。
进行 $N$ 次蒙特卡洛试验，测量值有 $m$ 个元素，我可以得到每个 $k^{th}$ 次时间步长的平均归一化创新误差，即 $\bar{e}_k$，从我看到的资料来看，我们应该有 $N \bar{e}_k$ 遵循 Chi具有 $N*m$ 自由度的平方分布。
因此，显然 $\alpha=0.05$ 时，我应该有大约 95% 的 $\bar{e}_k$ 位于使用 MATLAB 命令获得的 $[r_1,r_2]$ 范围内
$r_1=chi2inv(alpha/2,N*m)/N$
$r_2=chi2inv(1-alpha/2,N*m)/N$
但是，我的 $\bar{e}_k$ 总是远低于计算出的错误界限。我做了非常相似的 NEES 测试，这些测试都顺利通过了，我仔细检查了讲义和其他资料，确保我计算出的卡方界限与讲义中的相匹配，我甚至尝试了 $P$ 和 $S$ 的多种不同表达式，但到目前为止，NIS 测试都没有奏效。我想知道以上是否正确，有人有 NIS 测试的资料吗？再次抱歉提出这个杂乱无章的调试问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/649403/for-an-ideal-kalman-filter-i-have-that-the-nees-test-passes-but-nis-test-does-n</guid>
      <pubDate>Mon, 17 Jun 2024 18:47:32 GMT</pubDate>
    </item>
    <item>
      <title>如果 R2 不适用于随机森林等非线性 ML 算法，那么可以使用 Pearson 或 Spearman 相关性作为性能指标吗？</title>
      <link>https://stats.stackexchange.com/questions/649402/if-r2-is-not-appropriate-for-non-linear-ml-algorithms-such-as-random-forests-ca</link>
      <description><![CDATA[R2 不适用于非线性模型，例如随机森林 (RF) 模型。
https://arxiv.org/pdf/1611.03063
R 平方真的是非线性模型的无效指标吗？
https://statisticsbyjim.com/regression/r-squared-invalid-nonlinear-regression/
使用 $R^2$ 进行 RF
R2 可以被视为 Pearson 相关系数的扩展，即如果您对 Pearson r 求平方，则 r2 == R2。
在不使用 R2 的情况下，使用 Pearson r 或 Spearman Rho 或 Kendall Tau 作为相关系数来表示结果中的测试/真实值与预测值之间的对应关系是否合理？使用 R2 的主要问题是 R2 和残差的假设在非线性应用中不成立，但 Spearman Rho（非参数相关系数）可以接受或合理使用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649402/if-r2-is-not-appropriate-for-non-linear-ml-algorithms-such-as-random-forests-ca</guid>
      <pubDate>Mon, 17 Jun 2024 18:24:48 GMT</pubDate>
    </item>
    <item>
      <title>用于时间序列数据处理的 CNN 矩阵形状</title>
      <link>https://stats.stackexchange.com/questions/649400/cnn-matrices-shape-for-time-series-data-processing</link>
      <description><![CDATA[我想请教您有关使用 CNN 分析 60000x16 数据（单输入）的建议 - 来自 16 个通道的时间序列记录。我对此做了一些研究，我最初的想法是使用带有 CONV2D 层的 CNN，输入大小等于上述大小。
首先，我想请教您选择内核大小的一般建议 - 互联网上存在不同的意见 - 非方形内核是不受欢迎的选择（是吗？），但对于这样的数据来说似乎是合理的。
人们也经常说，200 x 8 的过滤器大小不太可能起作用，因为尺寸不同，而且 CNN 中的特征选择不应该在不同通道之间混合。
另一方面，在分析我的记录时，我可以看到数据中的大多数变化在前约 2000 个样本后就很明显了，而每 10 个样本进行一次检查似乎毫无意义。我还确信记录的频道之间存在某种关系。
我很高兴得到任何指导，因为我对 NN 主题还不熟悉。提前谢谢 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/649400/cnn-matrices-shape-for-time-series-data-processing</guid>
      <pubDate>Mon, 17 Jun 2024 18:15:59 GMT</pubDate>
    </item>
    <item>
      <title>如何使用机器学习自动识别新数据集中的列标题？</title>
      <link>https://stats.stackexchange.com/questions/649399/how-to-automatically-identify-column-headers-in-new-datasets-using-machine-learn</link>
      <description><![CDATA[我有一个包含车辆数据的数据集，其中包含标题（示例）：

我收到了包含类似车辆数据但没有列标题的新数据集：

我需要创建一个算法，根据带有标题的数据集提供的分类法识别这些新数据集并为其分配列标题。以下是一些挑战：

某些值可能不会出现在训练数据集中（例如，新文件中的“tesla”）。
列集可能不完全匹配；没有标题的文件可能包含更少或更多的列。

不同文件的列类型可能不同（例如，“id”是字符串而不是整数）。

问题不仅仅是实体/属性识别。

一些变量是相关的（例如，“fuel_type”与“engine_size”/“is_electric”）。

最好，解决方案应该使用最少的启发式方法并利用机器学习来适应不断变化的数据。


以下是迄今为止所做的工作：

转置数据集以创建一个狭长的数据框，每行由列名和相应的值组成：



在所有值上应用了 ~40 个特征（例如，字数、字符长度、is_text、is_bool、列聚合，如最小值、最大值、平均值、熵）。

在此数据集上训练随机森林分类器（多类分类问题）。

对于测试数据集，运行相同的预处理和特征创建，然后对每个值进行分类。

按未知列对预测进行分组，并从特异性最高的列开始分配已知列名（类似于 tf-idf）。


此解决方案存在一些问题：

对数据集进行透视会丢失单个车辆内的相关性（例如，“engine_size = 0”和“is_electric = T”被独立处理）。

该解决方案事后分配列，导致某些列可能过度表示，并且缺乏对所有变量的同时优化。


你遇到过类似的问题吗？你知道有什么工具或解决方案可以帮到你吗？任何建议或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/649399/how-to-automatically-identify-column-headers-in-new-datasets-using-machine-learn</guid>
      <pubDate>Mon, 17 Jun 2024 18:06:37 GMT</pubDate>
    </item>
    </channel>
</rss>