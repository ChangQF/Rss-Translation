<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 29 Aug 2024 06:23:12 GMT</lastBuildDate>
    <item>
      <title>如何正确地从样本协方差中“减去”已知的协方差分量？回归</title>
      <link>https://stats.stackexchange.com/questions/653533/how-to-properly-subtract-a-known-covariance-component-from-a-sample-covariance</link>
      <description><![CDATA[我遇到一种情况，其中观察到的随机变量$X_i$是两个独立（但未观察到）变量的总和，$$X_i = S_i + N_i,$$（例如，您观察到的是随机信号加上随机噪声）。
我有$X_i$的样本，并且我还知道$N_i$的分布（它是多元高斯分布，均值为 0，协方差已知但非对角线）。如何估计 $S_i$ 之间的协方差？
我的天真尝试：
由于 $S_i$ 和 $N_i$ 是独立的，$\mathrm{Cov}(X) = \mathrm{Cov}(S) + \mathrm{Cov}(N)$。我可以取 $X_i$ 的样本，计算样本协方差，然后减去 $N$ 的已知协方差矩阵，从而得出 $S$ 协方差的估计值。问题在于，在样本量有限的情况下，$X$ 的样本协方差并不是 $\mathrm{Cov}(X)$ 的完美测量，当我进行减法时，我最终得到的 $\mathrm{Cov}(S)$ 的估计值不是正定的。
这似乎可能是一个简单的统计问题，我不知道要搜索的术语。有没有一种简单、可靠的方法来“减去”来自测量样本协方差的已知分量，可产生有效（即正定）协方差估计？
（如果有帮助的话，我很乐意假设 $S_i$ 是多元高斯分布。不幸的是，变量的维度约为 $1500$，因此用 $1500^2 \approx 2$ 百万个自由参数对 $S$ 的协方差矩阵进行参数化并尝试同时拟合它们似乎是一项艰巨的任务。）]]></description>
      <guid>https://stats.stackexchange.com/questions/653533/how-to-properly-subtract-a-known-covariance-component-from-a-sample-covariance</guid>
      <pubDate>Thu, 29 Aug 2024 05:55:10 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 模型预测 - 95% 预测区间</title>
      <link>https://stats.stackexchange.com/questions/653532/arima-model-forecasting-95-prediction-intervals</link>
      <description><![CDATA[我目前正在学习时间序列预测和 ARIMA 模型。对于这个问题，我将仅使用 AR(1) 模型示例 $X_t = \phi X_{t-1} + \varepsilon_t$ 并假设我们预测 $X_{t+1}$
我遇到的一个资源是 [预测：原理与实践][1] (Hyndman 和 Athanasopoulos)，其中指出：

第一个预测区间很容易计算。如果 $\hat{\sigma}$ 是残差的标准差，则 95% 的预测区间由 $\hat{y}_{T+1|T} \pm 1.96 \hat{\sigma^2}$ 给出


这似乎意味着，在计算预测区间（或预测区间）时，我们纯粹考虑未来误差项中的方差/不确定性，这些方差/不确定性将“破坏”我们的$X_{t+1}$ 预测

但是，当阅读 CrossValidated 上的这个答案时：ARIMA 预测置信区间，它似乎表明$Var(X_{T+1}) = Var(\phi) + Var(\varepsilon_{T+1})$。 请注意，问题标题为置信区间，据我所知，它与参数估计有关，而不是预测，但 OP 似乎在询问预测/预测区间

第二个来源似乎表明预测区间包含 AR 参数的方差以及未来误差项的方差

我的问题是如何协调此处的差异，以及计算 $X_{t+1}$ 预测的预测区间的正确方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/653532/arima-model-forecasting-95-prediction-intervals</guid>
      <pubDate>Thu, 29 Aug 2024 05:03:20 GMT</pubDate>
    </item>
    <item>
      <title>MANOVA - 单变量 Wilks 的 Lambda 检验（R 解释）</title>
      <link>https://stats.stackexchange.com/questions/653530/manova-univariate-wilks-lambda-test-r-interpretation</link>
      <description><![CDATA[我正在运行一个具有 2 个因变量和 2 个连续预测变量的 MANOVA 模型。 （仅供参考 - STATA 将此称为 MANCOVA，并要求在每个预测因子前面删除“c。”以表示每个预测因子在 manova 运行期间都是连续缩放的。无论如何，R 将直接接受连续变量，因此使用 manova 命令在 R 中运行 MANCOVA 不会出现问题） - 本质上是 MVNREG。
使用 UC-Irvine ML Repository Wine 数据集，模型为：
model &lt;- lm(cbind(alcohol, hue) ~ flavanoids + ash, na.action=na.exclude, data=wine)
wine.manova=manova(model)

我试图了解使用这两种方法时 Wilks&#39; Lambda 对黄烷类化合物预测因子的 F 近似值之间的差异：
方法1
library(car)
lh.out &lt;- linearHypothesis(model, hypothesis.matrix = c(&quot;flavanoids = 0&quot;))
lh.out

结果如下：

方法 2
以及基于命令的 Wilks&#39; 值
summary(wine.manova,&#39;Wilks&#39;)

输出如下：

尽管 p 值相同，但我试图理解为什么 Wilks&#39; Lambda 的 F 值在基于所有响应变量的黄酮类化合物预测因子的两次零系数检验中有所不同。结果表明，当有更多预测因子或因变量时，这两次 Wilks&#39; Lambda 计算之间的差异更大。
仅供参考 - 当将 R 与 STATA 进行基准测试时，几乎不可能在 STATA 中获得上述方法 2 下列出的表格结果，而方法 1 的结果很容易从 STATA 中获得。]]></description>
      <guid>https://stats.stackexchange.com/questions/653530/manova-univariate-wilks-lambda-test-r-interpretation</guid>
      <pubDate>Thu, 29 Aug 2024 02:58:38 GMT</pubDate>
    </item>
    <item>
      <title>率最差于 $\frac{1}{n}$ 的最小方差估计量示例</title>
      <link>https://stats.stackexchange.com/questions/653527/example-of-minimum-variance-estimator-with-rate-worst-than-frac1n</link>
      <description><![CDATA[考虑 $n$ 个 i.i.d. 观测值，该观测值来自分布 $p(X| \theta)$。假设我们有兴趣根据此数据估算 $\theta$。
我对一个示例感兴趣，该示例将表明：

存在一个 $\theta$ 的一致估计量。用 $\hat{\theta}$ 表示它。换句话说，我希望这个问题得到明确的定义。
“最佳”（最小方差）的方差不会以通常的$\frac{1}{n}$速度收敛，而是以较慢的速度收敛。

文献中有相当多的结果表明，至少 MLE（在适当的）规律性条件下以$\frac{1}{n}$速度收敛。在我看来，如果存在这样的例子，那么对于这种设置，Fisher 信息必须为零。]]></description>
      <guid>https://stats.stackexchange.com/questions/653527/example-of-minimum-variance-estimator-with-rate-worst-than-frac1n</guid>
      <pubDate>Thu, 29 Aug 2024 01:50:17 GMT</pubDate>
    </item>
    <item>
      <title>如何比较多组计数数据（数百万或零，差异很大）？</title>
      <link>https://stats.stackexchange.com/questions/653526/how-do-i-compare-multiple-groups-of-count-data-that-are-either-millions-or-zero</link>
      <description><![CDATA[我有三个独立的组：治疗组、药物 1 和药物 2。对于每个组，我都有 CFU 中的细菌计数。我不太擅长统计，所以请耐心听我说。我知道我不能使用方差分析，因为分布不正常，有些计数相距很远，而且有相当多的零（虽然不是太多）。组内的方差也不相等，样本量也不相等。
我看过一些论文，建议使用负二项分布、泊松分布或其他一些分布。我的问题是：有没有针对这种情况的推荐方法？我如何比较不同类别的模型以确定哪个更好？我主要使用 R。有没有办法在 R 中测试多种方法并让它建议最佳（或接近最佳）模型？这种方法是否适合我的情况？或者我应该不要太担心并使用非参数检验？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653526/how-do-i-compare-multiple-groups-of-count-data-that-are-either-millions-or-zero</guid>
      <pubDate>Thu, 29 Aug 2024 01:08:06 GMT</pubDate>
    </item>
    <item>
      <title>如何使用高相关模型选择 A/B 测试样本</title>
      <link>https://stats.stackexchange.com/questions/653520/how-to-select-sample-for-a-b-testin-with-high-correlated-models</link>
      <description><![CDATA[嗨，我正在对两个机器学习模型进行 A/B 测试，这两个模型会为每个客户提供一个分数。这两个模型具有很高的相关性。我担心，如果采用模型 A，选择样本，然后选择模型 B 的样本，例如，这可能会在我的测试中产生偏差（剩余的总体将拥有低“质量”的客户，因为这两个模型具有很高的相关性）。有什么关于如何克服这个问题的想法吗？我也会很感激任何参考资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/653520/how-to-select-sample-for-a-b-testin-with-high-correlated-models</guid>
      <pubDate>Thu, 29 Aug 2024 00:16:55 GMT</pubDate>
    </item>
    <item>
      <title>在 brms 中使用求和项拟合非线性贝叶斯回归</title>
      <link>https://stats.stackexchange.com/questions/653519/fitting-nonlinear-bayesian-regression-with-a-summation-term-in-brms</link>
      <description><![CDATA[我正在尝试为多个猎物拟合 Holling II 型曲线的参数。其形式如下：
$$
\frac{dP_i}{dt} = \frac{a_iP_i}{1 +\sum_j{a_jh_jP_j}}
$$
其中 $P_i$ 是猎物种类的密度 $i$，$a_i$ 是“攻击率”，$h_i$ 是“处理时间”。我有 $\frac{dP_i}{dt}$ 和 $P_i$ 的数据，因此想对每个 $a_i$ 和 $h_i$ 的参数值进行后验分布采样。
如果物种数量相对较少，那么为每个 $P$ 设置虚拟变量并以此方式进行拟合可能很简单，但如果存在许多不同的 $P_i$，这种方法就站不住脚了。假设我们有数百种猎物，我们希望 $a_i$ 和 $h_i$ 符合随机效应。有没有办法在 r 中使用 brms 来指定这一点？
描绘如下内容：
 bf(dP ~ (a * P)/(1 + T),
a ~ (1|species),
T ~ sum(a * h * P),
h ~ (1|species),
nl = TRUE)
]]></description>
      <guid>https://stats.stackexchange.com/questions/653519/fitting-nonlinear-bayesian-regression-with-a-summation-term-in-brms</guid>
      <pubDate>Wed, 28 Aug 2024 23:47:35 GMT</pubDate>
    </item>
    <item>
      <title>三角相关？</title>
      <link>https://stats.stackexchange.com/questions/653518/triangular-correlations</link>
      <description><![CDATA[正如我在 https://stats.stackexchange.com/a/652022/11887 上的回答中所使用的，三角相关似乎是一个有用的概念/术语，可以得到更多的使用。但搜索后我发现它没什么用，下面是一些例子。也许还有其他术语在使用？一些文献中的例子：


这是学生课程成绩与（y 轴）缺课率的关系，似乎缺课率给出了成绩的近似上限。来自 Othmar W Winkler 的论三角相关。他说

尽管缺课和学期成绩之间存在明显的关系，但使用线性回归计算的相关系数为 r = -.18024。对此进行解释$R^2 = .03249$似乎表明，了解缺课百分比几乎无法解释这些课程成绩分散的 3%。

如果没有图表，这似乎非常具有误导性。该论文中的另一个例子：

他将其包括进来是为了展示来自科学而非社会科学的例子。摘自
&quot;Shake hole, A morphometric Field Project for Sixth-Form Geographers&quot; Geography, Vol. 65 pt. 3, July 1980, No. 288&quot;（我无法通过互联网搜索找到它）。其他有趣的例子可以在 Richard R. Hake 的 互动参与与传统方法：对入门物理课程力学测试数据的六千名学生调查中找到。

应该如何分析和呈现这些数据？相关系数似乎没什么用...还有其他例子吗？是否使用了其他术语？]]></description>
      <guid>https://stats.stackexchange.com/questions/653518/triangular-correlations</guid>
      <pubDate>Wed, 28 Aug 2024 23:41:28 GMT</pubDate>
    </item>
    <item>
      <title>价值迭代 GridWorld 中的终端状态与奖励的价值</title>
      <link>https://stats.stackexchange.com/questions/653516/value-of-terminal-state-vs-reward-in-value-iteration-gridworld</link>
      <description><![CDATA[我看到很多帖子说终端状态的值始终为 0，但很多价值迭代的例子将奖励（在终端）指定为值。例如，在下面的网格世界中，我们将 +1 和 -1 作为终端状态的值。

这取决于我们如何定义奖励吗？上面的例子是否是奖励仅取决于离开的状态的情况？或者它也适用于奖励取决于进入状态的情况？
我倾向于认为，如果我们将奖励定义为取决于进入状态 s&#39;，则终止状态的值不应该是其相关奖励（如上例所示）。但如果是这种情况，算法如何知道为相邻状态分配导致终止状态的操作？]]></description>
      <guid>https://stats.stackexchange.com/questions/653516/value-of-terminal-state-vs-reward-in-value-iteration-gridworld</guid>
      <pubDate>Wed, 28 Aug 2024 23:12:19 GMT</pubDate>
    </item>
    <item>
      <title>我如何对系数进行随机效应建模</title>
      <link>https://stats.stackexchange.com/questions/653509/how-can-i-model-with-random-effect-on-the-coefficient</link>
      <description><![CDATA[简单线性回归模型为：$$y= a x + b$$
然而，在实际数据中：

存在随机效应（误差或变化）；
当 $x$ 增加时，随机效应的绝对值会成比例增加。
因此它看起来像 $$y = ax + b + ex$$ 或 $$y = (a + e) x + b$$ 但 $e$ 是随机效应。
对这种建模有什么建议吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653509/how-can-i-model-with-random-effect-on-the-coefficient</guid>
      <pubDate>Wed, 28 Aug 2024 20:29:44 GMT</pubDate>
    </item>
    <item>
      <title>对零膨胀连续数据进行假设检验的可靠方法</title>
      <link>https://stats.stackexchange.com/questions/653504/reliable-method-for-hypothesis-testing-on-zero-inflated-continuous-data</link>
      <description><![CDATA[我正在测试新流程对网站销售业绩的影响。测试对以下方面的影响非常简单：

转化率（以交易结束的会话数除以总会话数） - 通过 z 检验近似的二项式
平均订单价值（总收入除以以交易结束的会话数） - t 检验。

棘手的部分是测试每个会话的平均收入，因为我们最终得到零膨胀分布。问题并不独特，所以我找到了很多方法：障碍模型、零膨胀泊松/负二项式、两部分模型、引导和贝叶斯角度。
您有什么建议，哪种方法在实践中可靠？为了解决这个问题，我们假设转化率为 60%，订单价值均匀分布在 \$40 到 \$80 之间。]]></description>
      <guid>https://stats.stackexchange.com/questions/653504/reliable-method-for-hypothesis-testing-on-zero-inflated-continuous-data</guid>
      <pubDate>Wed, 28 Aug 2024 19:39:13 GMT</pubDate>
    </item>
    <item>
      <title>Metropolis Hastings 连锁店价值停滞不前</title>
      <link>https://stats.stackexchange.com/questions/653492/metropolis-hastings-chain-getting-stuck-at-high-values</link>
      <description><![CDATA[我是 Metropolis-Hastings 算法的新手。我正尝试将其实现为逆伽马分布 $p(x,\alpha,\beta)=\frac{\beta^\alpha}{\Gamma(\alpha)}(\frac{1}{x})^{\alpha+1} e^{\frac{-\beta}{x}}$。我面临的问题是，有时我的链会卡在高值。我使用对数正态步骤，因为点应该始终为正。由于分布仅在 $\alpha&gt;1$ 时才具有预期值，因此我将 $x_0$ 设置为 p.d.f 的最大值。我测试了一些 $\sigma$ 的值，20 左右似乎不错，但我只测试了 $\alpha=1,\beta=1$
我该怎么做才能避免这种情况？
我的代码：
def Metropolis(n,sigma,alpha,beta):
x_0=beta/(alpha+1)
target = lambda x: 1/(x**(alpha+1))*np.exp(-beta/x)
lognormal = lambda x,y:np.exp(-(np.log(x)-y)**2/(2*sigma**2))/(sigma*x*np.sqrt(2*np.pi))
x=[x_0]
for c in range(n):
x_now=x[c]
x_star=np.random.lognormal(x_now,sigma)
alpha=np.min([1,(target(x_star)*lognormal(x_now,x_star))/(target(x_now)*lognormal(x_star,x_now))])
u=np.random.uniform()
如果 u&lt;=alpha:
x.append(x_star)
否则:
x.append(x_now)
###绘图###
x_max=np.max(x)
fig, axs = plt.subplots(1,2)
fig.set_figheight(10)
fig.set_figwidth(10)
t=np.linspace(0.01,x_max)
axs[0].plot(x,range(n+1))
line = axs[1].hist(x,range=[0,x_max],bins=100,density=True)
max_hist=np.max(line[0])
max_target=np.max(target(t))
scale=max_hist/max_target
axs[1].plot(t,scale*target(t))
axs[0].grid()
axs[1].grid()
axs[0].set_xlim(0,x_max)
Metropolis(20000,20,1,1)

此图显示了我运行代码时通常会发生的情况。您可以看到它在一段时间内停留在高值，但又恢复了。

这显示了有时会发生的一些不良模拟

正如建议的那样，以下是建议值的图。由于 $\sigma$ 很大，建议值通常超出比例。但减少$\sigma$也无济于事。
]]></description>
      <guid>https://stats.stackexchange.com/questions/653492/metropolis-hastings-chain-getting-stuck-at-high-values</guid>
      <pubDate>Wed, 28 Aug 2024 15:46:44 GMT</pubDate>
    </item>
    <item>
      <title>如何进行数据驱动的样本量选择</title>
      <link>https://stats.stackexchange.com/questions/653472/how-to-perform-data-driven-choice-of-sample-size</link>
      <description><![CDATA[假设我想比较两个回归模型的结果。一个是参考模型，另一个是新模型，我想知道新模型是否表现更好。每个模型都用皮尔逊相关性进行评估，假设数据集是依赖的，并且测试数据相同，我想得到配对差异的置信区间，看看它是否包含零。
但我事先不知道差异的方差，也不知道正确的样本量是多少，所以我想到了以下方法：
min_diff_to_detect
all_pearsons_ref = []
all_pearsons_new = []
alpha = 0.05

循环直到循环中断 -&gt;对于当前循环 n：
train_ref、train_new、test_data = get_new_data_split()

ref_model = train_ref_model(train_ref)
pearson_ref = assess( ref_model(test_data) )
all_pearsons_ref.append(pearson_ref)

new_model = train_new_model(train_new)
pearson_new = assess( new_model(test_data) )
all_pearsons_new.append(pearson_new)

Differences = all_pearsons_new - all_pearsons_ref # 成对差异
confidence_interval = compute_CI(0, np.std(differences), n, alpha)

如果 min_diff_to_detect 不在 confidence_interval 中：
如果 np.mean(differences) 不在 confidence_interval 中：
返回 are_different
返回are_not_different

train_data 是依赖的，而 test_data 对于两个模型是相同的。这个想法是使用数据来寻找最佳循环数 N。否则 N 将被猜测，并且可能太小而没有足够的统计能力，或者太大而需要太长时间进行训练。
但是，方差在早期循环中也有可能波动很大，从而导致 min_diff_to_detect 可能被错误检测。后一点可以通过在评估 if 条件之前引入最小循环数来缓解，但这感觉很武断，最终，我不知道这种方法是否有效。
我也知道 bootstrapping，但它需要大量的训练才能有效。
那么，第一个 if 条件可以改进以避免错误吗？最终，这是一种有效的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653472/how-to-perform-data-driven-choice-of-sample-size</guid>
      <pubDate>Wed, 28 Aug 2024 07:32:11 GMT</pubDate>
    </item>
    <item>
      <title>两个 AR(1) 过程之和的持久性</title>
      <link>https://stats.stackexchange.com/questions/653465/persistence-of-the-sum-of-two-ar1-processes</link>
      <description><![CDATA[考虑一个时间序列 $y_t$，它可以分解为两个组成部分的总和：
$$y_t = x_{1,t} + x_{2,t} $$
假设每个组成部分都是独立的，并遵循平稳 AR(1) 过程：
$$\begin{align*} 
x_{1,t} &amp;= \phi_1 x_{1,t-1} + \varepsilon_{1,t} \\
x_{2,t} &amp;= \phi_2 x_{2,t-1} + \varepsilon_{2,t} \\
\end{align*}$$
其中：
$$\begin{align*} 
\varepsilon_{1,t} &amp;\sim N \left (0,\sigma_1^2 \right ) \\
\varepsilon_{2,t} &amp;\sim N \left (0,\sigma_2^2 \right ) \\
\end{align*}$$
我使用模拟来生成一系列长序列 $X_1$、$X_2$ 以及它们的和 $Y$。然后，我估计 $y_t$ 的 AR(1) 模型
$$y_t = \phi_y y_{t-1} + \varepsilon_{y,t}$$
在我的模拟/估计中，我发现 $\phi_y$ 的估计值是 $\phi_1$ 和 $\phi_2$ 的加权平均值，其中每个成分的 $\phi_i$ 的权重由其无条件方差的比例决定。也就是说，我发现：
$$
\hat{\phi}_y \approx \left ( \frac{\frac{\sigma_1^2}{1-\phi_1^2}}{\frac{\sigma_1^2}{1-\phi_1^2} +\frac{\sigma_2^2}{1-\phi_2^2}} \right ) \phi_1 + \left ( \frac{\frac{\sigma_2^2}{1-\phi_2^2}}{\frac{\sigma_1^2}{1-\phi_1^2} +\frac{\sigma_2^2}{1-\phi_2^2}} \right ) \phi_2
$$
我知道Lütkepohl (1984)（虽然我还没有获得副本），据称证明了$y_t$遵循平稳 ARMA 过程。
是否有人知道以下任一证明（或能够推导出证明）：

$y_t$遵循 AR(1) 过程。
$\phi_y \equiv \left ( \frac{\frac{\sigma_1^2}{1-\phi_1^2}}{\frac{\sigma_1^2}{1-\phi_1^2} +\frac{\sigma_2^2}{1-\phi_2^2}} \right ) \phi_1 + \left ( \frac{\frac{\sigma_2^2}{1-\phi_2^2}}{\frac{\sigma_1^2}{1-\phi_1^2} +\frac{\sigma_2^2}{1-\phi_2^2}} \right ) \phi_2$

最后，有谁知道任何相关的证明涉及更一般的情况，当$\varepsilon_{1,t}$和$\varepsilon_{2,t}$ 是相关的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653465/persistence-of-the-sum-of-two-ar1-processes</guid>
      <pubDate>Wed, 28 Aug 2024 02:09:13 GMT</pubDate>
    </item>
    <item>
      <title>在 Metropolis-Hastings 算法的这种特殊情况下应该使用哪个提议函数？</title>
      <link>https://stats.stackexchange.com/questions/653457/which-proposal-function-should-be-used-in-this-particular-case-of-the-metropolis</link>
      <description><![CDATA[作为我研究的一部分，我想应用 Metropolis-Hastings 来从某些后验分布中抽样。更准确地说，数据来自存在审查制度的多元正态分布，而先验具有正态-逆威沙特分布（协方差矩阵具有逆威沙特分布，而以协方差矩阵为条件的均值具有正态分布）。Metropolis-Hastings 算法的一个可能的提议分布是使用先验分布本身，因为从中抽样很容易。然而，接受率通常很低，算法发展得相当慢。话虽如此，我想知道是否有人可以就这个问题为我提供一些指导，也就是说，我有兴趣知道先验分布的选择是否可接受，以及是否存在另一种更有效的提议分布。
任何帮助都值得赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/653457/which-proposal-function-should-be-used-in-this-particular-case-of-the-metropolis</guid>
      <pubDate>Tue, 27 Aug 2024 23:45:06 GMT</pubDate>
    </item>
    </channel>
</rss>