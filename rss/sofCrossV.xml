<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 18 Sep 2024 21:15:08 GMT</lastBuildDate>
    <item>
      <title>得出后验多元正态分布</title>
      <link>https://stats.stackexchange.com/questions/654565/derive-the-posterior-multivariate-normal-distribution</link>
      <description><![CDATA[我在阅读 Bartholomew、Knott 和 Moustaki 所著的潜在变量模型和因子分析：一种统一方法（作者：Bartholomew、Knott 和 Moustaki）一书时有一个疑问。这里是：
假设$\mathbf{x}=(x_1, x_2, ..., x_p)^T$，其中所有$x$都是随机变量，并且$\mathbf{x} \sim \mathcal{N}_p(\boldsymbol \mu, \boldsymbol \Sigma)$。
此外，$\mathbf{y}$是一组$q$个潜在变量，并且$\mathbf{y} \sim \mathcal{N}_q(\mathbf{0}, \mathbf{I})$。
最后，我们还有
$\mathbf{x|y} \sim \mathcal{N}_p(\boldsymbol{\mu+\Lambda y}, \boldsymbol{\Psi})$，其中 $\boldsymbol{\Lambda}$ 是 p*q 矩阵，$\boldsymbol{\Psi}$ 是方差的对角矩阵。
我知道通过迭代期望和迭代方差公式，可以很容易地得到另一种表达 $\mathbf{x}$ 分布的方式，结果是 $\mathbf{x} \sim \mathcal{N}_p(\boldsymbol{\mu}, \boldsymbol{\Lambda \Lambda^{&#39;}+\Psi})$.
但我不知道如何才能达到下面的后验分布：
$\mathbf{y|x} \sim \mathcal{N}_q(\boldsymbol{\Lambda^{&#39;}\Sigma^{-1}(x-\mu)}, (\boldsymbol{\Lambda^{&#39;}\Psi^{-1}\Lambda + I})^{-1})$.
我试过贝叶斯公式：
$f(y|x)=\frac{f(x|y)f(y)}{f(x)}$ 但我对代入后的计算结果并不乐观...
有人能帮我得出那个后验分布吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654565/derive-the-posterior-multivariate-normal-distribution</guid>
      <pubDate>Wed, 18 Sep 2024 19:08:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 G Power 根据 2 x 2 x 2 重复测量方差分析计算样本量</title>
      <link>https://stats.stackexchange.com/questions/654564/calculating-sample-size-based-on-a-2-x-2-x-2-repeated-measures-anova-using-g-pow</link>
      <description><![CDATA[我计划进行 2 (A：a1，a2) x 2 (B：b1，b2) x 2 (C：c1，c2) 重复测量方差分析，其中 A 和 B 是受试者内因素，而 C 是受试者间因素。
在 G Power 中，我假设“组数”= 2（由于受试者间因素有 2 个级别；c1、c2）和“测量次数”= 4（因为 a1、a2、b1、b2 将在所有参与者中进行测量）？
我还输入了以下内容：

效果大小 f= 0.25
α = 0.05
1-β = 0.95
重复测量之间的相关性=0.5（默认）
非球面相关性=1 （默认）

那么我得到的总样本量是 36。对于 2x2x2 重复测量方差分析来说，这似乎是一个非常小的样本量？尤其是每组只有 18 名参与者。
或者由于两个受试者内因素（A 和 B），“测量次数”应该是 2？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654564/calculating-sample-size-based-on-a-2-x-2-x-2-repeated-measures-anova-using-g-pow</guid>
      <pubDate>Wed, 18 Sep 2024 19:05:47 GMT</pubDate>
    </item>
    <item>
      <title>在多元回归中具有显著性，但在单回归中不具有显著性[重复]</title>
      <link>https://stats.stackexchange.com/questions/654563/significance-in-multiple-regression-but-not-in-single-regression</link>
      <description><![CDATA[我首先运行多元回归：y ~ a + b + x，发现 a 和 b 都显著 (p&lt;0.005)。
然后，对于 a = a_1、a_2、....、a_n 的每个子组，我运行 y ~ b + x，发现 b 不显著。这怎么可能发生？我知道相反的情况（在单回归中显著，但在多元回归中不显著）很常见。

我读过这个问答，但我不明白共线性是否能完全解释这一点。如果 a 和 b 共线，它们怎么会都有这么小的 p 值？
其他引用的问答也不完全与此相同。其他问答是关于添加其他变量（除 a 和 b 之外）使某事从不显著变为显著，但我的问题不涉及其他变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/654563/significance-in-multiple-regression-but-not-in-single-regression</guid>
      <pubDate>Wed, 18 Sep 2024 19:05:09 GMT</pubDate>
    </item>
    <item>
      <title>关于离散时间生存分析的修改问题（固定间隔，固定效应时间）</title>
      <link>https://stats.stackexchange.com/questions/654562/a-modified-question-about-discrete-time-survival-analysis-with-fixed-intervals</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654562/a-modified-question-about-discrete-time-survival-analysis-with-fixed-intervals</guid>
      <pubDate>Wed, 18 Sep 2024 18:54:52 GMT</pubDate>
    </item>
    <item>
      <title>将预测结果恢复为原始比例</title>
      <link>https://stats.stackexchange.com/questions/654561/back-transforming-the-predictions-to-original-scale</link>
      <description><![CDATA[嗨，我一直在使用 R 分析相机陷阱数据。我使用鹿鼠作为模型物种。
我使用对数和平方转换变量运行了 globel 模型。然后我使用 MuMIn 包生成候选模型，并使用 AICcmodavg 包和 delta AIC&lt;2; 进行模型平均
# 测试仅治疗类型对北方红背田鼠检测的影响
glmm1 &lt;- glmmTMB(fdeermouse ~ ftreatment +logvol+logshrub+sqrtleaflitter+sqrtgrass+fdecayclass+logvol:fdecayclass+ (1|flocation), family = &quot;binomial&quot;, data = stb, na.action = na.fail)

summary(glmm1)


library(MuMIn)
aaa &lt;- dredge(glmm1)
library(AICcmodavg)
modelaverage &lt;- model.avg(aaa, subset = delta &lt; 2, fit = TRUE)
summary(modelaverage)

# 计算模型平均参数的 95% 置信区间
conf_intervals &lt;- confint(modelaverage, level = 0.95)

# 打印置信区间
conf_intervals

输出：

调用：
model.avg(object = get.models(object = aaa, subset = delta &lt; 
2))

组件模型调用：
glmmTMB(formula = fdeermouse ~ &lt;4 unique rhs&gt;, data = stb, family = binomial, ziformula = 
~0, dispformula = ~1, na.action = na.fail)

组件模型：
df logLik AICc delta weight
145 5 -174.61 359.34 0.00 0.41
1456 6 -174.23 360.65 1.31 0.21
1245 6 -174.27 360.74 1.39 0.21
1345 6 -174.48 361.14 1.80 0.17

术语代码：
cond(fdecayclass) cond(ftreatment) cond(logshrub) cond(logvol) 
1 2 3 4 
cond(sqrtgrass) cond(sqrtleaflitter) 
5 6 

模型平均系数：
(全平均值) 
估计标准差误差调整 SE z 值 Pr(&gt;|z|) 
cond((Int)) -2.57346 1.06834 1.07101 2.403 0.0163 * 
cond(fdecayclasslate) 3.71279 0.59884 0.60044 6.183 &lt;2e-16 ***
cond(logvol) 0.91237 0.38515 0.38618 2.363 0.0182 * 
cond(sqrtgrass) 0.34480 0.15939 0.15982 2.157 0.0310 * 
cond(sqrtleaflitter) 0.03024 0.09537 0.09553 0.317 0.7516 
cond(ftreatmentStubbing) 0.10451 0.35029 0.35090 0.298 0.7658 
cond(logshrub) 0.01723 0.09216 0.09236 0.187 0.8520 

(条件平均值) 
估计标准差误差调整 SE z 值 Pr(&gt;|z|) 
cond((Int)) -2.5735 1.0683 1.0710 2.403 0.0163 * 
cond(fdecayclasslate) 3.7128 0.5988 0.6004 6.183 &lt;2e-16 ***
cond(logvol) 0.9124 0.3852 0.3862 2.363 0.0182 * 
cond(sqrtgrass) 0.3448 0.1594 0.1598 2.157 0.0310 * 
cond(sqrtleaflitter) 0.1410 0.1637 0.1641 0.859 0.3902
cond(ftreatmentStubbing) 0.5085 0.6258 0.6274 0.810 0.4177 
cond(logshrub) 0.1028 0.2046 0.2052 0.501 0.6165 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

2.5 % 97.5 %
cond((Int)) -4.67259415 -0.4743205
cond(fdecayclasslate) 2.53593842 4.8896351
cond(logvol) 0.15546160 1.6692700
cond(sqrtgrass) 0.03155787 0.6580342
cond(sqrtleaflitter) -0.18066153 0.4627388
cond(ftreatmentStubbing) -0.72123450 1.7382390
cond(logshrub) -0.29934332 0.5048548

现在我想将预测值回原始比例，并绘制鹿鼠与体积和衰减类别之间的检测概率。

非常感谢您的支持。谢谢

]]></description>
      <guid>https://stats.stackexchange.com/questions/654561/back-transforming-the-predictions-to-original-scale</guid>
      <pubDate>Wed, 18 Sep 2024 18:23:30 GMT</pubDate>
    </item>
    <item>
      <title>频率论者对假设检验的正确解释是什么？[重复]</title>
      <link>https://stats.stackexchange.com/questions/654560/what-is-the-correct-frequentist-interpretation-of-hypothesis-testing</link>
      <description><![CDATA[我理解频率论者对置信水平为 X% 的置信区间的解释（我认为）：想象一下，随机抽取许多样本，并按照程序计算所有样本的置信区间。X% 的区间将包含真实参数。
但是，当我尝试以类似的方式解释假设检验时，我感到很困惑。我觉得应该有类似的解释，因为检查值 $\mu_0$ 是否在 95% 的置信区间内，在数学上与检查您是否会拒绝 $H_0: \mu = \mu_0$ 的假设相同。
我的思维过程是定义假设检验的程序，想象重复多次，看看我们正确的频率是多少。然而，我们正确的频率取决于真正的$\mu$是什么，这导致我感到困惑。
标准的频率学派解释是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654560/what-is-the-correct-frequentist-interpretation-of-hypothesis-testing</guid>
      <pubDate>Wed, 18 Sep 2024 18:14:12 GMT</pubDate>
    </item>
    <item>
      <title>拟合非平稳 AR(1) 过程</title>
      <link>https://stats.stackexchange.com/questions/654559/fitting-a-non-stationary-ar1-process</link>
      <description><![CDATA[几乎所有的时间序列文献都是在尝试拟合任何内容之前对非平稳时间序列进行差分。
假设我们想要拟合自回归过程生成的数据：
$$X_{t+1} = aX_t + e_t$$
并且我们知道$a &gt; 1$。直接拟合有什么问题？残差会不会通过单位根检验并且不自相关？当$a = 1$时会怎样？核心问题是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654559/fitting-a-non-stationary-ar1-process</guid>
      <pubDate>Wed, 18 Sep 2024 17:06:25 GMT</pubDate>
    </item>
    <item>
      <title>样本均值还是 James-Stein 估计量？</title>
      <link>https://stats.stackexchange.com/questions/654558/sample-mean-or-james-stein-estimator</link>
      <description><![CDATA[我有一个简单的实际问题，我将其发布在 Quant Finance SE 中（也发布在这里，因为我没有得到答案）。
假设我们有 $n\geq3$ 个股票金融时间序列（相关或不相关）（例如，$n$ 只股票的 10 个不同收益时间序列，每个序列都有 $T$ 个观测值）。目标是估计每个金融时间序列的平均值，即$\hat{\mu}_{i}$，$i=1,2,...n$。
显然，最直接的方法是计算每个系列的样本平均值，即$\hat{\mu}_{i}=\frac{x_1+x_2+...x_T}{T}$，其中$i=1,2,...n$。然而，James-Stein 估计量表明，如果 $n\geq3$，那么最好将所有这些 $n$ 金融时间序列汇集在一起​​，然后集体估计均值向量。
您会使用哪种方法，为什么？据我所知，对于这样一个简单的问题，所有从业者都使用第一种方法（样本均值），我不知道有谁应用了第二种方法。因此，这是否意味着这是由于 James-Stein 更像是一个理论结果，并且几乎不适用或不太受欢迎？如果不是，那么为什么不使用 James-Stein 呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/654558/sample-mean-or-james-stein-estimator</guid>
      <pubDate>Wed, 18 Sep 2024 16:40:58 GMT</pubDate>
    </item>
    <item>
      <title>计算二项式 GLM 中变量子集解释的变化</title>
      <link>https://stats.stackexchange.com/questions/654557/computing-the-variation-explained-by-a-subset-of-the-variables-in-a-binomial-glm</link>
      <description><![CDATA[我正在处理自然语言数据。具体来说，我正在研究一种含义可以用两种方式表达的情况，例如我知道这是真的与我知道那那是真的。在这个假设的例子中，我的因变量是二进制的（那与零），我有两个独立变量：主句的人称（第一人称​​我与第二人称与第三人称）和主句中使用的动词（知道与认为与相信与...）。对于每个组合，我都从语料库中收集了出现的次数：



人
动词
# 那个
# 零




1
知道
345
246


...
...
...
...



我想测试的假设是，that 和 zero 之间的选择取决于 Person 变量（具体来说，第一人称的 that ： zero 的比率高于其他两个人称的）。我假设主句中的动词可能具有独立效果（例如 know），目前我对此不感兴趣。
为此，我使用 R 拟合二项式 GLM：
# 生成示例值：
data &lt;- data.frame(Person=rep(c(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;), 10), Verb=sort(rep(LETTERS[0:10], 3)), Freq_that=sample(100:500, 30), Freq_zero=sample(100:500, 30))

data$Person &lt;- relevel(as.factor(data$Person), ref=&quot;1&quot;)
model &lt;- glm(formula = cbind(Freq_that, Freq_zero) ~ Person + Verb, family = binomial, data = data)

show(summary(model))

这给了我如下输出：
调用：
glm(formula = cbind(Freq_that, Freq_zero) ~ Person + Verb, family = binomial, 
data = data)

偏差残差：
最小值 1Q 中位数 3Q 最大值 
-10.3545 -3.5826 -0.6237 2.9716 12.2818 

系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -0.63602 0.05389 -11.802 &lt; 2e-16 *** 人2 -0.05256 0.03686 -1.426 0.153811 人3 0.18248 0.03542 5.151 2.59e-07 *** 动词B 0.77175 0.07130 10.824 2e-16 *** 动词 C 0.45441 0.06509 6.981 2.93e-12 *** 动词 D 0.81523 0.06510 12.523 2e-16 *** 动词E 0.65077 0.06957 9.354 &lt; 2e-16 ***
VerbF 0.41065 0.07201 5.703 1.18e-08 ***
VerbG 1.20326 0.07008 17.169 &lt; 2e-16 ***
VerbH 0.19839 0.06627 2.994 0.002755 ** 
VerbI 0.08633 0.07340 1.176 0.239525 
VerbJ 0.23047 0.06540​​ 3.524 0.000425 ***
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（二项式系列的分散参数取为 1）

零偏差：29 个自由度上的 1516.69
残差偏差：18 个自由度上的 898.06
AIC：1125.4

Fisher 评分迭代次数：4

现在，据我了解：

Person3 的 $p$ 值表示有显著影响（相对于第一人称），而 Person2 的 $p$ 值则不表示。
VerbB 到 VerbJ 的系数并不那么有趣，因为它们与任意选择的 VerbA。
我可以使用 exp(model$coefficients) 计算 Person3 的几率比：$1.200$。这表明，使用 that（而不是零）在第三人称中实际上比在第一人称中高出约 20%（与预测相反 - 当然这些是随机数据）。
我可以使用零偏差和残差来计算此模型解释的变异量，即 $1 - \frac{898.06}{1516.69} = 0.41$。

但是，最后一个数字捕获了整个模型解释的变异量。我还对仅由 Person2 和 Person3 解释的变化量感兴趣：有多少变化是由人称差异引起的，又有多少是由动词引起的？我该如何计算这个？
起初我以为我可以拟合一个没有动词变量的模型（formula = cbind(Freq_that, Freq_zero) ~ Person），但这给了我不同的系数，所以这不可能是正确的。
我认为这与计算逻辑回归中预测变量解释的方差是同一个问题，但答案对于我的理解水平来说不够详细。]]></description>
      <guid>https://stats.stackexchange.com/questions/654557/computing-the-variation-explained-by-a-subset-of-the-variables-in-a-binomial-glm</guid>
      <pubDate>Wed, 18 Sep 2024 15:57:46 GMT</pubDate>
    </item>
    <item>
      <title>非中心广义卡方的 R 代码[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654555/r-code-for-non-central-generalized-chi2</link>
      <description><![CDATA[我正在寻找 R 中的一些代码，这些代码允许我获得广义非中心卡方分布的密度和累积概率。
有什么建议吗？
谢谢，
Juan]]></description>
      <guid>https://stats.stackexchange.com/questions/654555/r-code-for-non-central-generalized-chi2</guid>
      <pubDate>Wed, 18 Sep 2024 15:49:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么项目反应理论不依赖于代表性样本，或者为什么它是“样本独立的”？</title>
      <link>https://stats.stackexchange.com/questions/654551/why-does-item-response-theory-not-depend-on-a-representative-sample-or-why-is-i</link>
      <description><![CDATA[多种资源描述了项目反应理论 (IRT) 并将其与传统测试理论 (CTT) 进行了比较，指出 CTT 依赖于代表性样本，而 IRT 则不然。

样本独立性：传统统计数据都依赖于样本，并且无法用于不同的样本；而 IRT 的结果与样本无关。在线性变换内。两个不同能力水平的样本可以轻松转换为同一量表。
项目属性不依赖于代表性样本。


这些资源似乎将此陈述为两种理论和建模方法之间的事实区别，但我不明白为什么这必然是正确的。项目参数在不同人群之间可能存在不同差异，难道不是这样吗？这种说法的重点是，如果没有发生差异项目功能 (DIF)，那么您可以有信心地说它不依赖于代表性样本吗？但是，如果这是对那条的解释，我仍然不明白，因为 CTT（即 SEM、CFA）也涉及测量不变性的测试。
有人能帮我理解为什么 IRT 不依赖于代表性样本或“样本独立”吗？
资源：
https://www.publichealth.columbia.edu/research/population-health-methods/item-response-theory
https://assess.com/what-is-item-response-theory/]]></description>
      <guid>https://stats.stackexchange.com/questions/654551/why-does-item-response-theory-not-depend-on-a-representative-sample-or-why-is-i</guid>
      <pubDate>Wed, 18 Sep 2024 14:47:00 GMT</pubDate>
    </item>
    <item>
      <title>使用螺旋桨计算细胞比例是否显著</title>
      <link>https://stats.stackexchange.com/questions/654540/calculating-if-cell-proportions-are-significant-using-propeller</link>
      <description><![CDATA[我正在使用 propeller，https://rdrr.io/github/Oshlack/speckle/man/propeller.anova.html，来计算肥大细胞与对照组细胞比例之间的显著性。我的模型设计如下。
design &lt;- model.matrix(~0 + grp + md_subset$batch)

我理解不设置截距就没有基线水平，所有分类变量都表示为单独的列。所以我总共有 10 个样本，3 个对照组和 7 个肥大组，它们分 4 个批次完成。我的设计矩阵如下所示：

我对设计矩阵有几个问题。首先，为什么我的设计矩阵中没有 2 列，一列表示条件，该行是否用 0 表示控制，1 表示肥大，一列表示批次，行中用 1、2、3 或 4 表示，因为它们有 4 个批次？我看到的是每个条件都有自己的列，每个批次也是如此。在我看来这像是热编码，但为什么在这种情况下这是必要的？其次，如果热编码是必要的，并且这就是每个变量都有单独列的原因，那么为什么批次 1 列不存在，因为我的样本 3（第 3 行）是批次 1？这个设计矩阵是否不会考虑批次 1 的影响？
最后，当我运行它时，我得到如下输出：
propeller.anova(prop.transformed, design=design, coef=c(1,2,3,4,5), robust=TRUE,
trend=FALSE, sort=TRUE)



首先，使用设计运行此程序是否意味着我正在查看条件之间每种细胞类型的比例在控制批次效应时有多显著？我之所以问这个问题，是因为根据我的理解，通常在回归分析中，~ 之后的第一个变量是您要测试的变量，任何其他变量都是您想要控制的混杂因素。然而，在 DESeq2 或 edgeR 等包中，我看到控制的混杂因素首先出现，最后一个变量是您要测试响应变量与之相关的变量。此外，这里的 p 值和 F 统计量是否显示了条件对比例的影响有多大，以及它是否显著？标记为 PropMean.* 的每一列表示不同细胞类型的该变量的系数？
我很感激任何帮助和澄清，因为我认为我主要理解但希望得到一些帮助和建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/654540/calculating-if-cell-proportions-are-significant-using-propeller</guid>
      <pubDate>Wed, 18 Sep 2024 09:48:03 GMT</pubDate>
    </item>
    <item>
      <title>$\mathbb{E}(​​|X|)$ 和 $\mathbb{E}(​​|X|+|Y|)$ 的展开</title>
      <link>https://stats.stackexchange.com/questions/654527/expansion-of-mathbbex-and-mathbbexy</link>
      <description><![CDATA[给定一个数值随机变量$X$和$Y$，我对$\mathbb{E}(​​|X|)$和$\mathbb{E}(​​|X| + |Y|)$的展开式有点困惑。
对于 $\mathbb{E}(​​|X|)$，是否
$$\mathbb{E}(​​|X|)= \lim_{n \to \infty}\frac{|X_1|+|X_2|+...|X_n|}{n}$$
或
$$\mathbb{E}(​​|X|)= \lim_{n \to \infty}\frac{|X_1+X_2+...X_n|}{n}?$$
类似地，对于 $\mathbb{E}(​​|X| + |Y|)$，是否
$$\mathbb{E}(​​|X| + |Y|)=\lim_{n \to \infty}\frac{|X_1|+|X_2|+...|X_n|+|Y_1|+...|Y_n|}{n}$$
或
$$\mathbb{E}(​​|X| + |Y|)=\lim_{n \to \infty}\frac{|X_1+X_2+...X_n|+|Y_1+...Y_n|}{n}?$$]]></description>
      <guid>https://stats.stackexchange.com/questions/654527/expansion-of-mathbbex-and-mathbbexy</guid>
      <pubDate>Wed, 18 Sep 2024 05:59:43 GMT</pubDate>
    </item>
    <item>
      <title>对零假设下 p 值的均匀分布感到困惑</title>
      <link>https://stats.stackexchange.com/questions/654484/confused-about-the-uniform-distribution-of-p-values-under-the-null-hypothesis</link>
      <description><![CDATA[我目前正在学习一门生物信息学入门课程，我对零假设下（当零假设为真时）p 值的均匀分布感到困惑。
已经广泛证明和讨论过，在正确的条件下，当零假设成立时，p 值是均匀分布的，正如这篇文章所解释的那样：为什么 p 值在零假设下是均匀分布的？。
我的困惑更多的是关于这个想法背后的直觉和实际意义。
例如，让我们考虑一个简单的（尽管是离散的）场景：抛硬币。如果掷出正面的概率（表示为&quot;1&quot;）为 $p = 0.3$，且我们进行 $1000$ 次抛掷，我们预计大多数情况下掷出正面的次数约为 $300$ 次。因此，我们预计在大多数情况下 p 值将在 $P(X &lt; 300)$ 左右（左尾 p 值，其中 $X$ 是二项式（$1000$，$p$）变量）。
但是，这似乎与 p 值在零假设下应均匀分布的想法相矛盾。如果 p 值是均匀的，那么所有 p 值是否都应该具有同等可能性，而不是聚集在某个值附近？
有人可以解释为什么这个均匀分布在这个例子中仍然成立，或者我是否误解了一些基本的东西？
我已运行以下模拟作为示例：
library(ggplot2)

n_experiments &lt;- 100000 # 实验次数（抛硬币）
n_trials &lt;- 100000 # 每个实验的试验次数
p &lt;- 0.3 # 获得“1”（成功）的概率

# 模拟实验
set.seed(123) # 为了可重复性
results &lt;- rbinom(n_experiments, n_trials, p) # 每个实验中 1 的数量

# 计算每个实验的 p 值
p_values &lt;- sapply(results, function(x) pbinom(x, n_trials, p))

# 创建用于绘图的数据框
df &lt;- data.frame(Experiment = 1:n_experiments, 
Number_of_1s = results, 
p_value = p_values)

# 绘制“1”的数量直方图
ggplot(df, aes(x = Number_of_1s)) +
geom_histogram(binwidth = 1, fill = &#39;skyblue&#39;, color = &#39;black&#39;) +
labs(title = &quot;100 次实验中 1 的数量直方图&quot;, 
x = &quot;1 的数量&quot;, 
y = &quot;频率&quot;) +
theme_minimal()

# 绘制 p 值的直方图
ggplot(df, aes(x = p_value)) +
geom_histogram(binwidth = 0.01, fill = &#39;coral&#39;, color = &#39;black&#39;) +
labs(title = &quot;100 次实验中的 p 值直方图&quot;, 
x = &quot;p 值&quot;, 
y = &quot;频率&quot;) +
theme_minimal()

我发现以下预期结果对我来说感觉矛盾，值的分布不均匀，但 p 值的分布是均匀的。

]]></description>
      <guid>https://stats.stackexchange.com/questions/654484/confused-about-the-uniform-distribution-of-p-values-under-the-null-hypothesis</guid>
      <pubDate>Tue, 17 Sep 2024 13:24:56 GMT</pubDate>
    </item>
    <item>
      <title>R 中混合效应模型 (lme) 的 III 型方差分析对比</title>
      <link>https://stats.stackexchange.com/questions/654447/contrasts-for-type-iii-anova-on-mixed-effects-model-lme-in-r</link>
      <description><![CDATA[我正在使用 R 中的 nlme 运行一系列混合效应模型。这是我的最终模型的示例：
M1.Final &lt;- lme(Response ~Treatment * Species, random = ~1|ID, 
data = data, method=&quot;REML&quot;)

我运行了初始 II 型方差分析来解释不平衡设计（每个处理的范围为 9-25 个样本），并得到了以下结果：
Anova(M1.Final, type = 2)

Chisq Df Pr(&gt;Chisq) 
Treatment 152.1071 4 &lt; 2.2e-16 ***
物种 1.9636 1 0.161130 
治疗：物种 15.2138 4 0.004278 ** 

由于治疗：物种相互作用显著，我认为 III 型方差分析比 II 型方差分析更合理。我知道要运行 III 型方差分析，您必须更改模型的对比度。我想检查并确保我做得正确。只在 ANOVA 命令中更改对比度可以吗，还是我需要在 lme 命令中更改它？即这是否正确：
type3 &lt;- list(Treatment = contr.sum, Species = contr.sum)

Final_Anova &lt;- Anova(M1.Final,contras = type3,type=3)
print(Final_Anova)

Chisq Df Pr(&gt;Chisq) 
(截距) 106.6099 1 &lt; 2.2e-16 ***
Treatment 151.0898 4 &lt; 2.2e-16 ***
物种 0.0406 1 0.840396 
治疗：物种 15.2138 4 0.004278 ** 


这是交互图：

更新：听起来你应该在 lme 中指定对比。我试过了，但得到了一个奇怪的输出，所以我不确定我做错了什么：
test &lt;- lme(Response ~Treatment * Species, random = ~1|ID, 
data = data, method=&quot;REML&quot;,contras = type3)
Anova(test, type = 3)

(Intercept) 1575.8 1 &lt; 2.2e-16 ***
Treatment 0 
Species 0 
Treatment:Species 0 


编辑：听起来，如果存在显著的相互作用，则 III 型不一定是必要的。如果能对如何在这种情况下选择 ANOVA 类型提供任何见解，我们将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654447/contrasts-for-type-iii-anova-on-mixed-effects-model-lme-in-r</guid>
      <pubDate>Mon, 16 Sep 2024 17:45:12 GMT</pubDate>
    </item>
    </channel>
</rss>