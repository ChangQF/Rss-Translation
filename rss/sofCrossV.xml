<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 May 2024 09:16:55 GMT</lastBuildDate>
    <item>
      <title>根据预测中的解释方差在仅截距模型和 AR-NN 模型之间进行选择：是否合理？</title>
      <link>https://stats.stackexchange.com/questions/648194/choosing-between-intercept-only-and-ar-nn-models-based-on-explained-variance-in</link>
      <description><![CDATA[我创建了两个自回归模型用于预测：一个基本的仅截距模型和一个 AR-NN（自回归神经网络）模型。基于 70/30 训练测试分割的递归一步前进伪样本外 RMSE，这两个模型表现出类似的性能，仅截距模型表现略好。附图显示了预测：黑线 = 真实测试数据，红线 = 仅截距预测，蓝线 = AR-NN 预测。仅截距 RMSE = 0.018，RMSE AR-NN = 0.0209
但是，与 AR-NN 模型相比，仅截距模型无法解释其预测中的方差。
鉴于此，选择 AR-NN 模型是否有意义，因为它能够解释未来预测中的更多方差？是否应使用测试数据集中两个模型的解释方差作为证明这种偏好的标准？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648194/choosing-between-intercept-only-and-ar-nn-models-based-on-explained-variance-in</guid>
      <pubDate>Wed, 29 May 2024 08:36:00 GMT</pubDate>
    </item>
    <item>
      <title>置信区间 ODE 岭回归</title>
      <link>https://stats.stackexchange.com/questions/648192/confidence-intervals-ode-ridge-regression</link>
      <description><![CDATA[我想找到 L2 正则化的最小二乘损失的置信区间。我只找到了线性问题，但在我的例子中，我想估计 ODE 参数。有人处理过同样的问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648192/confidence-intervals-ode-ridge-regression</guid>
      <pubDate>Wed, 29 May 2024 08:27:07 GMT</pubDate>
    </item>
    <item>
      <title>过程 (Hayes) 逻辑回归输出解释 - 优势比</title>
      <link>https://stats.stackexchange.com/questions/648191/process-hayes-logistic-regression-output-interpretation-odds-ratio</link>
      <description><![CDATA[我使用 SPSS 中的 PROCESS 宏运行了逻辑回归，并且是使用 PROCESS 运行此模型的新手。我正在执行中介分析。根据我的理解，我需要报告比值比 (OR)，但我似乎无法在 PROCESS 输出中找到它可能在何处？或者我必须计算它吗？任何帮助都将不胜感激，我尝试四处寻找但找不到任何东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/648191/process-hayes-logistic-regression-output-interpretation-odds-ratio</guid>
      <pubDate>Wed, 29 May 2024 08:16:55 GMT</pubDate>
    </item>
    <item>
      <title>非正态变量的标准差和方差的替代方法</title>
      <link>https://stats.stackexchange.com/questions/648190/alternatives-of-sd-and-variance-for-non-normal-variable</link>
      <description><![CDATA[我有一个每年都在跟踪的变量。虽然它确实表现出单峰行为（每年），但它在任何情况下都不符合正态分布，所以我想知道作为离散度描述统计的替代方案有哪些。我考虑的是四分位距，但我认为可能有更好的选择。
此变量的值来自非常规的每日采样，即每月有一定数量的非恒定数据可用。另一方面，在我快速的互联网搜索中，我发现更多关于非参数统计测试的参考资料用于推断，但并不完全用于测量变异性。我发现最接近的方法是使用四分位距或引用切比绍夫不等式，但我没有找到一篇文章具体解释哪些统计数据可以作为非正态分布变量的替代方案。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648190/alternatives-of-sd-and-variance-for-non-normal-variable</guid>
      <pubDate>Wed, 29 May 2024 08:15:16 GMT</pubDate>
    </item>
    <item>
      <title>AR(1) 的手动 MLE 产生了一个奇怪的初始值 $y_0$</title>
      <link>https://stats.stackexchange.com/questions/648189/manual-mle-of-ar1-yields-a-weird-initial-value-y-0</link>
      <description><![CDATA[我正在尝试手动实现 AR(1) 模型中参数的最大似然估计 (MLE)
$$
y_t = c + \varphi_1 y_{t-1} + \varepsilon_t
$$
其中 $\text{Var}(\varepsilon_t)=\sigma^2$。我将我的结果与 forecast 包中的 Arima 获得的结果进行比较（基于 stats 包中的 arima）。

我的可能性略高于 Arima。
除了初始值 $y_0$ 之外，估计值并不相同，但相当接近。我的估算器给出的值似乎太高（高于 $y$ 的范围），并且远离 Arima 的更合理值。

我尝试了几个不同的手动 MLE 起始值，但每次都得到相同的结果。
我做错了什么？
library(fpp2) # 示例数据集所需

# AR(1) 的对数似然
loglik &lt;- function(pars){
c &lt;- pars[&quot;c&quot; ] # 常数
phi1 &lt;- pars[&quot;phi1&quot; ] # 斜率
sigma2 &lt;- pars[&quot;sigma2&quot;] # 误差方差
y0 &lt;- pars[&quot;y0&quot; ] # 时间序列的初始值
T &lt;- length(y)
e &lt;- rep(NA,T)
e[1] &lt;- y[1] - ( c + phi1*y0 )
for(t in 2:T){
e[t] &lt;- y[t] - ( c + phi1*y[t-1] )
}
Li &lt;- dnorm(e, mean=0, sd=sqrt(sigma2))
loglik &lt;- sum(log(Li))
return(loglik)
}

y &lt;- diff(log(oil)) # 1966-2013 年沙特阿拉伯石油产量年度变化百分比

# 优化 loglik 函数
opars &lt;- c(c=0, phi1=0, sigma2=var(y), y0=mean(y)) # 参数的初始值
#opt &lt;- optim(par=opars, fn=loglik, method=&quot;BFGS&quot;, control=list(fnscale=-1)) # 无界优化
opt &lt;- optim(par=opars, fn=loglik, method=&quot;L-BFGS-B&quot;, control=list(fnscale=-1), 
lower=c(-Inf,-0.99,1e-10,-Inf), 
upper=c( Inf, 0.99,Inf , Inf)) # 有界优化，-0.99&lt;=phi1&lt;=0.99 且 0&lt;sigma2
opt$convergence # 值为 0 表示优化算法正确收敛
optres &lt;- c(opt$par, logL=opt$value) # 主要结果为单个向量

# 与 `forecast::Arima` 进行比较相同数据的收益
m1 &lt;- Arima(y, order=c(1,0,0), method=&quot;CSS-ML&quot;)
m1 &lt;- Arima(y, order=c(1,0,0), method=&quot;ML&quot; )
chat &lt;- unname(m1$coef[2]*(1 - m1$coef[1])) # 用 mu 的估计值表示的 c 估计值
phi1hat &lt;- unname(m1$coef[1])
y0hat &lt;- (y[1] - chat - m1$residuals[1]) / phi1hat # y0 的估计值
m1par &lt;- c(c=chat, phi1=phi1hat, sigma2=m1$sigma2, y0=y0hat) 
m1res &lt;- c(m1par, logL=m1$loglik) # 单个向量中的主要结果

# 打印出来并将手动 ML 估计值与 `Arima` 中的估计值进行比较
估计值 &lt;- rbind(optres,m1res)
rownames(估计值) &lt;- c(&quot;Manual&quot;,&quot;Arima&quot;)
print(round(估计值, 数字=6))
]]></description>
      <guid>https://stats.stackexchange.com/questions/648189/manual-mle-of-ar1-yields-a-weird-initial-value-y-0</guid>
      <pubDate>Wed, 29 May 2024 08:09:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么对于两个比例的合并检验，只能用于假设检验，而不能用于置信区间？</title>
      <link>https://stats.stackexchange.com/questions/648188/why-is-it-for-the-pooled-test-of-two-proportions-it-can-only-be-used-for-a-hypo</link>
      <description><![CDATA[我在此处看到，使用 2 比例的合并检验时，只能得出假设检验，而不能得出置信区间。这是为什么？它还说当 $H_0: p_1-p_2=0$ 时使用合并，但这是否意味着当 $H_0: p_1-p_2=a$ 时，其中 $a\neq 0$ 我们会使用合并？如果是，为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/648188/why-is-it-for-the-pooled-test-of-two-proportions-it-can-only-be-used-for-a-hypo</guid>
      <pubDate>Wed, 29 May 2024 07:35:38 GMT</pubDate>
    </item>
    <item>
      <title>回归模型中的嵌套变量，其中因子具有多个级别</title>
      <link>https://stats.stackexchange.com/questions/648187/nested-variable-in-regression-model-where-factor-has-multiple-levels</link>
      <description><![CDATA[我遇到一种情况，我有一个因子变量 $F$ 和一个连续变量，例如 $X$。因子变量有三个级别，例如 (&#39;x&#39;、&#39;y&#39;、&#39;z&#39;)，并且 $X$ 仅在值为 $x$ 或 $y$ 时才定义。特别是，&#39;z&#39; 被编码为 NA。
如何在 R 中模拟这种情况？此答案建议这样做：
y ~ A + (A %in c(&#39;x&#39;, &#39;y&#39;)):X


如果所有 $X4 均为正，则我必须将 NA 设置为某个值（例如 -1） - 对吗，否则模型求解算法将无法处理这个问题？
公式规范似乎不起作用？现在我要开始做这件事吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648187/nested-variable-in-regression-model-where-factor-has-multiple-levels</guid>
      <pubDate>Wed, 29 May 2024 07:24:13 GMT</pubDate>
    </item>
    <item>
      <title>Nagelkerke R2 cv.glm [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648185/nagelkerke-r2-cv-glm</link>
      <description><![CDATA[我为青蛙占有率制作了二项式 GLM，为丰度制作了负二项式 GLM。我使用 MAE 和 Nagelkerke R2 作为指标来评估顶级模型的拟合优度。我现在正尝试使用 LOO 交叉验证模型，并计算交叉验证模型的 Nagelkerke R2 以评估模型是否过度拟合。我没有找到任何关于如何做到这一点的建议，所以我不得不依靠 chatgpt 来编写代码。经过无数次尝试后，这个代码给了我一个结果（其中一个模型的 R2 为 0.577，交叉验证模型的值为 0.579）。这是我使用的代码，如果任何比我更了解 R 的人可以确认它是正确的，或者建议一种更好的方法来实现它。
加载必要的包
library(boot)
假设您的数据集称为 surveystandardised
拟合 GLM
m_alt_bio6 &lt;- glm(formula = Frogs_TF ~ alt_s + Bio6_s, family = &quot;binomial&quot;, data = surveystandardised)
定义一个函数来计算 Nagelkerke R²
nagelkerke_r2 &lt;- function(model, data) {
LLf &lt;- logLik(model)
LL0 &lt;- logLik(glm(Frogs_TF ~ 1, data = data, family = binomial))
n &lt;- nrow(data)
R2 &lt;- 1 - exp((2 / n) * (LL0 - LLf))
R2_max &lt;- 1 - exp(2 * LL0 / n)
nagelkerke &lt;- as.numeric(R2 / R2_max)
return(nagelkerke)

初始化一个向量来存储每个折叠的 Nagelkerke R²
nagelkerke_r2_values &lt;- numeric(nrow(surveystandardised))
执行 LOO 交叉验证
for (i in 1:nrow(surveystandardised)) {
创建不包括第 i 个观察值的训练数据
train_data &lt;- surveystandardised[-i, ]
test_data &lt;- surveystandardised[i, , drop = FALSE]
在训练数据上拟合模型
fold_model &lt;- glm(Frogs_TF ~ alt_s + Bio6_s, data = train_data, family = binomial)
计算折叠的 Nagelkerke R²
nagelkerke_r2_values[i] &lt;- nagelkerke_r2(fold_model, train_data)

计算所有折叠的平均 Nagelkerke R²
mean_nagelkerke_r2 &lt;- mean(nagelkerke_r2_values)
mean_nagelkerke_r2]]></description>
      <guid>https://stats.stackexchange.com/questions/648185/nagelkerke-r2-cv-glm</guid>
      <pubDate>Wed, 29 May 2024 06:20:57 GMT</pubDate>
    </item>
    <item>
      <title>如何在加权 Cox 模型中手动分配权重？</title>
      <link>https://stats.stackexchange.com/questions/648184/how-can-you-manually-assign-weights-in-a-weighted-cox-model</link>
      <description><![CDATA[引用 Lin 等人 (2020) 的一项研究，

&quot;当使用 MaxCombo 检验时，治疗效果估计值取为与 p 值最小的加权对数秩检验相对应的加权 Cox 模型获得的估计 HR。&quot;

我想问：

如何在 R 中比较两种治疗方法时使用 maxcombo；以及
如何在加权 cox 模型中手动输入权重？

谢谢你的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/648184/how-can-you-manually-assign-weights-in-a-weighted-cox-model</guid>
      <pubDate>Wed, 29 May 2024 06:01:16 GMT</pubDate>
    </item>
    <item>
      <title>我们什么时候需要将隔离项作为 ergm 模型的一部分添加以及如何解释系数</title>
      <link>https://stats.stackexchange.com/questions/648181/when-are-we-required-to-add-isolates-as-part-of-the-ergm-model-and-how-to-interp</link>
      <description><![CDATA[最近，我尝试通过使用 ERGM 对公司网络进行建模来执行网络分析。当我研究要添加到模型中的一些流行术语时，我遇到了隔离术语，因此我想知道我应该如何解释隔离术语的系数（当它是负数或正数时）
我正在阅读以下链接以帮助进行解释，但它不包括对 ergm 术语的解释。https://github.com/eehh-stanford/SNA-workshop/blob/master/ergm-predictions.md#more-realistic-change-statistics]]></description>
      <guid>https://stats.stackexchange.com/questions/648181/when-are-we-required-to-add-isolates-as-part-of-the-ergm-model-and-how-to-interp</guid>
      <pubDate>Wed, 29 May 2024 04:41:40 GMT</pubDate>
    </item>
    <item>
      <title>条件概率分布中的概率灵敏度</title>
      <link>https://stats.stackexchange.com/questions/648179/probability-sensitivity-in-conditional-probability-distribution</link>
      <description><![CDATA[我阅读了这篇文章，其中使用 copula 构建了基于某些气候变量的径流条件概率分布。例如，下图显示了对应于低、中、高降水量的径流条件分布（分别为$25$百分位数、$50$百分位数和$75$百分位数）。

本文还提出了一种敏感性指数，他们称之为总概率敏感性（TPS）指数，并将其定义为
$$TPS= \int F(v|u_i)-F(v|u_j)dv$$
我认为公式中存在一个小错误，因为它不是确定的积分。从结果中我们可以看到，TPS 基本上是两个条件 CDF 函数之间的区域。
这使得他们能够分析径流对气候变量变化的概率敏感性。
我还没有找到以这种方式定义概率敏感性的其他上下文。我想知道概率敏感性的概念和以这种方式定义它是否众所周知，或者它是否是作者想出的东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/648179/probability-sensitivity-in-conditional-probability-distribution</guid>
      <pubDate>Wed, 29 May 2024 02:12:27 GMT</pubDate>
    </item>
    <item>
      <title>线性回归中的 Z 分数和标准误差</title>
      <link>https://stats.stackexchange.com/questions/648177/z-score-and-standard-error-in-linear-regression</link>
      <description><![CDATA[我正在阅读《统计学习要素》，在线性回归章节中，我无法理解以下内容：
我们已经从 $N$ 个数据点估计了回归参数 $\beta_1, ..., \beta_p$。
已确定 $\hat{\beta} \sim N(\beta, (X^T X)^{-1}\sigma^2)$，其中 $\beta$ 是 $\hat{\beta}$ 的真实值，$X$ 是数据矩阵。 $\sigma^2$ 是 $Y$ 相对于其均值的方差，即 $Y = X\beta + \epsilon$, $\epsilon \sim N(0, \sigma^2)$。
现在，作者计算 $z_j = \frac{\hat{\beta}_j}{\hat{\sigma}\sqrt{(X^TX)^{-1}_{jj}}}$。
此外，方差估计为 $\hat{\sigma}^2 = \frac{1}{N-p-1}RSS$。
现在，这或多或少清楚了，但是我应该也通过将 $\hat{\beta}_j$ 除以其标准误差来获得相同的 $z_j$。换句话说，它应该成立
$SE(\hat{\beta}_j) = \hat{\sigma}\sqrt{(X^TX)^{-1}_{jj}}$。但相反，我得到了以下结果：
$SE(\hat{\beta}_j) = \frac{\sqrt{(X^TX)^{-1}_{jj}}\sigma}{\sqrt{N}} = \frac{\sqrt{(X^TX)^{-1}_{jj}(N-p-1)}\hat{\sigma}}{\sqrt{N}}$
其中我使用了 $(N-p-1)\hat{\sigma} \sim \sigma^2\mathcal{X}^2_{N-p-1}$
因此 $\sqrt{N-p-1}$ 因子有些不对劲，我担心我从根本上误解了一些东西这里。
编辑：我可能犯了一个错误，第二种情况下的正确标准错误可能是
$\frac{\sqrt{(X^TX)^{-1}_{jj}}\hat{\sigma}}{\sqrt{N}}$
因为$\hat{\sigma}$估计的是$\sigma$。但我仍然不明白为什么$\sqrt{N}$仍然在那里。]]></description>
      <guid>https://stats.stackexchange.com/questions/648177/z-score-and-standard-error-in-linear-regression</guid>
      <pubDate>Wed, 29 May 2024 00:19:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么 GLM 拟合与使用逻辑函数的直接拟合不同</title>
      <link>https://stats.stackexchange.com/questions/648147/why-glm-fit-is-different-from-direct-fit-using-logistic-function</link>
      <description><![CDATA[我在我的数据中发现，使用逻辑函数的直接拟合比使用带有逻辑链接函数的二项分布的 GLM 拟合得到不同的、更好的 (R^2) 拟合结果。我天真地期望得到相同的结果，但现在无法解释为什么情况并非如此。
正如下面评论中指出的那样，这可能是由于不同的最小化程序造成的。
假设 fit 和 glm 使用的最小化相同，是否可以期望相同的拟合结果？
以下示例假设相同的最小化程序。
这里有一些 matlab 代码来说明这个问题
直接拟合
x = [-50.4 -39.6 -29.7 -21.6 -18.0 -14.4 -9.9 -8.1 -6.3 -3.6 -1.8 0.0 
1.8 3.6 6.3 8.1 9.9 14.4 18.0 21.6 29.7 39.6 50.4]&#39;;
y = [0.0 0.0 0.0 0.0 0.1 0.1 0.2 0.2 0.2 0.3 0.3 0.4 0.5 0.5 0.6 0.6 
0.7 0.8 0.9 0.9 1.0 1.0 1.0]&#39;;

ft=fittype(&#39;exp(b0+b1*x)/(1 + exp(b0+b1*x))&#39;, &#39;indep&#39;, &#39;x&#39;);
stp=[-0.5 0.1];
[mo, gf] = fit(x, y, ft, &#39;StartPoint&#39;, stp);

mo = 
一般模型：
mo(x) = exp(b0+b1*x)/(1 + exp(b0+b1*x))
系数（95% 置信区间）：
b0 = -0.4201 (-0.4983, -0.3419)
b1 = 0.1268 (0.1167, 0.1368)

GLM 部分
data=table(y,x);

modelspec{1}=&#39;y ~ x&#39;;
mdl1 = fitglm(data, modelspec{1},...
&#39;Distribution&#39;, &#39;binomial&#39;, &#39;Link&#39;,&#39;logit&#39;);

广义线性回归模型：
logit(y) ~ 1 + x
分布 = 二项式

估计系数：
估计 SE tStat pValue 
________ ________ ________ ________

(截距) -0.42089 0.60619 -0.69432 0.48748
x 0.13401 0.060266 2.2236 0.026175

差异并不大，但很明显，尤其是当人们期望结果相同时。
这是另一个数据示例（这个是不对称的，我知道拟合将是对称的）。
y=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.5, 1.0, 
1.0, 1.0, 1.0, 1.0, 0.7, 0.9, 0.7, 0.8, 0.8, 1.0];

结果
mo = 
一般模型：
mo(x) = exp(b0+b1*x)/(1 + exp(b0+b1*x))
系数（95% 置信区间）：
b0 = 0.07416 (-0.793, 0.9413)
b1 = 1.606 (-0.1469, 3.359)

mdl1 = 
广义线性回归模型：
logit(y) ~ 1 + x
分布 = 二项式

估计系数：
估计 SE tStat pValue 
________ ________ ________ ________

（截距） -0.35437 0.61901 -0.57247 0.567
x 0.14666 0.066227 2.2145 0.026791

这里的差异很大。
有没有简单的解释说明为什么输出不同？
（我使用 nlsLM 和 glm 在 R 中检查了相同的数据，得到了相同的结果）]]></description>
      <guid>https://stats.stackexchange.com/questions/648147/why-glm-fit-is-different-from-direct-fit-using-logistic-function</guid>
      <pubDate>Tue, 28 May 2024 12:20:41 GMT</pubDate>
    </item>
    <item>
      <title>具有分类变量数据的最佳模型 lmer</title>
      <link>https://stats.stackexchange.com/questions/648146/best-model-for-data-with-categorical-variables-lmer</link>
      <description><![CDATA[我有一些数据，由几分钟内的连续因变量和几个分类自变量组成。我拟合了这个模型，但在 Stack Overflow 上，当我询问拟合 predict() 函数的问题时，有人建议我的模型可能构建得不太好（我的其他问题）。
这是模型：
model &lt;- lmer(minutes_after_sunrise ~ forest * forest_strata * habitat +
(1 | forest_strata), data = data)

minutes_after_sunrise 是检测到物种的给定分钟，以分钟为单位进行数据处理（我也有负数，日出前几分钟，但没有将它们包括在这个模型中），森林是站点A 和 B，森林地层是森林的垂直部分（从地面到树冠，A 和 B 共有 6 层）和栖息地（两个类别），即森林 A 和 B 内的不同栖息地，它们也具有地层，因此一切都非常嵌套。我曾考虑将地层作为固定效应，但说实话，我对这些模型没有太多经验，所以它很可能完全错误。有人能告诉我什么才是最合适的吗？
我想知道的是，日出后的几分钟在森林 A 和 B 之间是否有所不同，以及地层和栖息地等其他元素也可能如何发挥作用。由于只有分类数据，我发现很难处理这个模型。
我的数据示例，我有大约 78,000 行这样的数据。
]]></description>
      <guid>https://stats.stackexchange.com/questions/648146/best-model-for-data-with-categorical-variables-lmer</guid>
      <pubDate>Tue, 28 May 2024 11:47:00 GMT</pubDate>
    </item>
    <item>
      <title>如何根据具有不同季节性（和其他影响）的其他时间序列来模拟时间序列？</title>
      <link>https://stats.stackexchange.com/questions/648143/how-to-simulate-a-time-series-based-on-other-time-series-that-have-different-sea</link>
      <description><![CDATA[我有一份特定区域内一组房屋的太阳能生产数据时间序列列表，我需要模拟该地区新房的太阳能生产与时间曲线。总产量之和应该相似，因为它们位于相似的位置，因此，全年因素（例如季节、辐照度等）将相等。但是，每个时间序列也具有不同的属性，例如不同时段的峰值（取决于房屋和面板的方向），以及特定时段阴影造成的其他影响。因此，一个时间序列可能在早上达到峰值，而另一个时间序列可能在下午达到峰值。由于这种异质性，我不能只取所有这些时间序列中每个 X 分钟间隔的平均值，因为我可能会得到不切实际的平坦生产曲线。除了位置之外，我对这栋新房子的当地因素（方向等）一无所知，所以我无法使用这些信息。
我想过去除每栋房子的季节性（我确实有足够的数据来适应每栋房子的不同模型），对去除季节性的所有时间序列取平均值，然后模拟一组时间序列，并将不同的季节性参数应用于这个平均时间序列。然后我可以随机选择每一天的曲线，并将所有日子拼接起来，最终得到完整的时间序列。我的问题是这是否可靠，以及如何选择季节性参数来创建每条曲线？
我想到的另一种选择是随机选择一条实际生产曲线，而不是去除所有曲线的季节性并计算平均值，但这可能会增加估计误差？
我愿意听取建议。我有统计学背景，但我从来没有真正处理过那么多时间序列。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648143/how-to-simulate-a-time-series-based-on-other-time-series-that-have-different-sea</guid>
      <pubDate>Tue, 28 May 2024 11:01:38 GMT</pubDate>
    </item>
    </channel>
</rss>