<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 28 Oct 2024 18:23:13 GMT</lastBuildDate>
    <item>
      <title>多元线性回归中的排列检验，哪一个是正确的？</title>
      <link>https://stats.stackexchange.com/questions/656424/permutation-test-in-multiple-linear-regression-which-is-correct</link>
      <description><![CDATA[我正在拟合线性回归模型$$Y = \beta_0+ \beta_1 Z + \beta_2 X$$响应$Y$和协变量$X$是连续变量，$Z$是0/1二分处理组指标，均为$N \times 1$向量。我想要获得$\beta_1$的置换分布。在排列中，下列哪一项是正确的：
(1) 随机排列 $Y$，并获取 1000 个排列中 $\beta_1$ 的分布
(2) 随机排列 $Z$，并获取 1000 个排列中 $\beta_1$ 的分布
(3) 令 $Z(X)$ 为在 $X$ 上拟合 $Z$ 的残差向量，令 $Y(X)$ 是将 $Y$ 拟合于 $X$ 所得的 残差。 
然后对 $Z(X)$ 进行 1000 次置换，并在对 $Y(X)$ 进行 $Z(X)$ 回归时，记录 $Z(X)$ 的 1000 个回归系数。
我认为 (3) 是正确的方法，因为它保留了 $X$ 与 $Y$ 和 $Z$ 的关系。因此在排列之前，我应该从$Z$和$Y$中清除$X$的影响，但我找不到适当讨论此问题的良好参考资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/656424/permutation-test-in-multiple-linear-regression-which-is-correct</guid>
      <pubDate>Mon, 28 Oct 2024 17:20:46 GMT</pubDate>
    </item>
    <item>
      <title>人均分析中比率的虚假相关性</title>
      <link>https://stats.stackexchange.com/questions/656422/spurious-correlation-of-ratios-in-per-capita-analyses</link>
      <description><![CDATA[我试图弄清楚比率的虚假相关性如何影响变量为人均指标的分析。
假设我有一个回归
$$
\text{人均GDP}_{it} = \alpha + \beta \cdot \text{人均二氧化碳}_{it}
$$
$$
\ln(\text{人均GDP}_{it}) = \alpha + \beta \cdot \ln(\text{人均二氧化碳}_{it})
$$
$$
\ln(\text{GDP}) = \alpha + \beta \cdot \ln(\text{二氧化碳}) + \gamma \cdot \ln(\text{人口})
$$
如果我发现 beta 在第一个回归中显著，那么这是否可能是虚假相关性？第二个呢？第三个呢？
许多人均指标使其更容易解释，但我想知道我应该使用哪种修复方法。
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656422/spurious-correlation-of-ratios-in-per-capita-analyses</guid>
      <pubDate>Mon, 28 Oct 2024 16:18:54 GMT</pubDate>
    </item>
    <item>
      <title>为什么方差趋向于 sigma^2/n？</title>
      <link>https://stats.stackexchange.com/questions/656421/why-does-the-variance-tend-to-sigma2-n</link>
      <description><![CDATA[设 $Y_1, Y_2, \ldots, Y_n$ 为 $n$ 个个体的收入，其中 $E(Y_i) = \mu$ 且 $\text{Var}(Y_i) = \sigma^2$ 适用于所有 $i = 1, 2, \ldots, n$。这 $n$ 个个体组成 $m$ 个组，每个组的大小为 $k$。众所周知，同一组中的个体是相关的，但不同组中的两个个体始终是独立的。假设当个体相关时，所有对的相关系数都相同。
考虑随机变量 $\bar{Y} = \frac{1}{n} \sum_{i=1}^n Y_i$ 当 $m$ 很大但 $k$ 有限时，$\bar{Y}$ 的极限方差为
选项：

(A) $ 0$
(B) $\frac{1}{k}$
(C)​​ $1$
(D) $\frac{\sigma^2}{k}$

根据一些计算，我计算出 $\text{Var}(\bar{Y}) = \frac{\sigma^2}{n}(1+(k-1)r) $(r 是相关系数)。基于此，$n \rightarrow \infty$ 方差项必须趋向于零，但当我查阅 chatGPT 时，它说方差不为零，因为组成员之间存在相关性。这是真的吗？如果是，为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/656421/why-does-the-variance-tend-to-sigma2-n</guid>
      <pubDate>Mon, 28 Oct 2024 16:02:25 GMT</pubDate>
    </item>
    <item>
      <title>极简模型如何能在 MNIST 上实现更高的准确率？</title>
      <link>https://stats.stackexchange.com/questions/656420/how-can-minimalist-models-achieve-even-higher-accuracy-on-mnist</link>
      <description><![CDATA[我最近看到了一个有趣的讨论，关于一个简单的逻辑回归模型如何在 MNIST 数据集上实现约 92% 的分类准确率（参考：一个简单的逻辑回归模型如何在 MNIST 上实现 92% 的分类准确率？）。
对于线性模型，784 个神经元（每个像素一个）似乎是最小配置。然而，我一直在探索我们可以在多大程度上进一步推动简约模型，同时仍然实现高性能。我开发了一个只有 702 个参数的神经网络，它在 MNIST 上实现了 98.2% 的准确率。您可以在此处找到我的模型的实现：702 参数 MNIST 模型。
我很好奇是否有其他极简方法（例如具有很少参数的神经网络）可以实现超过 92% 的准确率，可能接近 98-99%，而无需诉诸高度复杂的架构。
具体来说，我正在寻找：

极简神经网络或其他模型的示例，这些模型在 MNIST 上实现高精度，参数少于 1,000 个。
帮助此类模型保持高性能同时保持计算效率的技术或技巧（例如，特殊正则化、权重初始化或激活函数）。

任何见解或参考文献，探讨这种简约而又强大的建模方向将受到极大的赞赏！]]></description>
      <guid>https://stats.stackexchange.com/questions/656420/how-can-minimalist-models-achieve-even-higher-accuracy-on-mnist</guid>
      <pubDate>Mon, 28 Oct 2024 15:24:20 GMT</pubDate>
    </item>
    <item>
      <title>使用 `mgcv` 或 `scam` 进行符号约束样条</title>
      <link>https://stats.stackexchange.com/questions/656419/sign-constrained-splines-with-mgcv-or-scam</link>
      <description><![CDATA[我目前正在尝试解决将 GAM 模型拟合到我的数据的问题，通过 R 中的 scam 使用以下公式：
y ~ s(x1, bs = &#39;mpd&#39;, k = 12) + s(x2, bs = &#39;cc&#39;) + s(x3, bs = &#39;bs&#39;, m = 1)
我的响应变量 y 始终为正，我需要

与 x1 相关的平滑应该是单调递减的。
与 x2 相关的平滑应该是循环的。
x3 平滑可以是分段线性的。

我遇到的问题是 我需要所有平滑（包括截距）始终为非负，并且我希望能够之后单独使用它们。
我原本想自己简单地对优化问题进行编码，但这似乎有点过头了。另外，我还想到了修改损失函数以对任何负值添加惩罚的可能性，但我不确定如何朝这个方向进行。
我也尝试过重新排列最小值并应用移位，但有时这是不可能的，否则会导致错误大量增加。
最后，我还尝试通过以下方式修改公式：
y ~ exp(s(x1, bs = &#39;mpd&#39;, k = 12)) + exp(s(x2, bs = &#39;cc&#39;)) + exp(s(x3, bs = &#39;bs&#39;, m = 1))
但显然这在 mgcv 或 scam 中是不可能的。]]></description>
      <guid>https://stats.stackexchange.com/questions/656419/sign-constrained-splines-with-mgcv-or-scam</guid>
      <pubDate>Mon, 28 Oct 2024 15:19:55 GMT</pubDate>
    </item>
    <item>
      <title>如何确定样本中某个混淆元素是否仍然属于同一个总体（由样本和用于价值计算的样本定义）？</title>
      <link>https://stats.stackexchange.com/questions/656418/how-to-determine-if-an-obfuscated-element-of-the-sample-is-still-in-the-same-pop</link>
      <description><![CDATA[我想确定新值 X 属于我的总体的概率。问题是我不仅使用样本来定义我的总体，而且我的值也是利用样本创建的。
更具体地说：我有一个由大约 400 个类似程序组成的样本。我想将我的总体定义为所有与这 400 个程序执行类似操作的程序。
我可以通过度量来计算两个程序之间的相似性得分。因此，对于我的样本（大小为 N）中的任何程序 p_i，我都可以计算 N-1 个分数，然后进一步计算这些分数的均值 m_i 的 N-1 倍。
现在我想知道给定的程序（实际上是从样本中的一个程序派生出来的）是否属于我的总体（如果它仍然接近其他程序）。所以我认为我需要一个假设检验作为其中的一部分。
或者，我也愿意接受这样的想法，即只衡量某些程序与我的总体/样本的差异。
现在我的想法是计算所有 N 个均值 (m_i´s) 并将它们视为分布的随机变量。 （我不确定它们是否服从正态分布，但不知何故，我认为我可以说它们是服从正态分布的，这要归功于中心极限定理的魔力，而且我的样本量大于 30。1. 这是真的吗？）
然后我可以计算新混淆程序与样本中所有其他程序之间的 N（2. 不是 N-1，这会是个问题吗？）分数。
我认为我现在可以计算 z 分数，作为输入程序与我的分布相差多远的度量（它仍然是相同分布的可能性有多大），但该程序不是我的样本的一部分，所以我不知道这是否有效。
那么 3. 这种方法有效吗？ 和 4. 有没有更好/有效的方法？。
此外，只有在可能的情况下，我才需要论证我的方法是有效的，所以如果你能提供任何答案的来源，那将为我提供很大的帮助。
注意：这不是我尝试的第一件事，我查阅了各种文献和 ChatGPT。我阅读了关于学生化、置信区间、有限总体和 Bootstrap 抽样的内容。然而，我非常不确定这些方法是否适用，因为不幸的是，我的问题显然根本不是“教科书”。
非常感谢您花时间阅读这篇文章，我将不胜感激您提供的任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/656418/how-to-determine-if-an-obfuscated-element-of-the-sample-is-still-in-the-same-pop</guid>
      <pubDate>Mon, 28 Oct 2024 15:15:44 GMT</pubDate>
    </item>
    <item>
      <title>两个输出的指标和损失问题[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656415/metrics-and-loss-problem-for-two-output</link>
      <description><![CDATA[我的自定义损失和指标出现了问题。我的目的是用图像训练一个 CNN 模型，并使用图像中物体的角度方向的切线，我有一列表示切线是正还是负。最后我有两个输出，一个是切线（回归），另一个是（分类）。现在当我写 model.evaluate 时，我把回归写为第一个出现的东西，但它并没有作为第一个出现。我不确定它们是否以某种方式被反转了。因为我无法找到我得到的奇怪结果的解释。这是我的代码：
 # 自定义损失和度量函数
@keras.utils.register_keras_serializable(package=&quot;Custom&quot;)

def angular_loss(y_true, y_pred):
angles_true = tf.math.atan(y_true) * 180.0 / np.pi
angles_pred = tf.math.atan(y_pred) * 180.0 / np.pi
return tf.abs(angles_true - angles_pred)

@keras.utils.register_keras_serializable(package=&quot;Custom&quot;)
def rmse_degrees(y_true, y_pred):
a = tf.constant(np.pi)
angles_true = tf.math.atan(y_true) * 180.0 / a
angles_pred = tf.math.atan(y_pred) * 180.0 / a
b = tf.square(angles_true - angles_pred)
return tf.reduce_mean(b)
# 定义模型
input_image = Input(shape=X_train_images.shape[1:], name=&#39;input_image&#39;)
x = layer.Conv2D(32, (3, 3),activation=&#39;relu&#39;)(input_image)
x = layer.MaxPooling2D((2, 2))(x)
x = layer.Dropout(0.3)(x)
x = layer.Conv2D(64, (3, 3),activation=&#39;relu&#39;)(x)
x = layer.MaxPooling2D((2, 2))(x)
x = layer.Dropout(0.3)(x)
x = layer.Flatten()(x)
x = layer.Dense(128,activation=&#39;relu&#39;)(x) # 中间密集层
x = layer.Dropout(0.3)(x)

output_regression = layer.Dense(1,activation=&#39;linear&#39;,name=&#39;reg_output&#39;)(x)
output_classification = layer.Dense(1,activation=&#39;sigmoid&#39;,name=&#39;cls_output&#39;)(x)
model = keras.Model(inputs=input_image,outputs=[output_regression,output_classification])
model.summary()
model.save(&quot;modelfinal3.keras&quot;)
# 编译模型

model.compile(
optimizer = RMSprop(learning_rate=0.0001),
loss={
&#39;reg_output&#39;: angular_loss,
&#39;cls_output&#39;: &#39;binary_crossentropy&#39;
},
metrics={
&#39;reg_output&#39;: [rmse_degrees],
&#39;cls_output&#39;: [&#39;accuracy&#39;]
}
)

# 定义 ModelCheckpoint 回调以保存最佳模型
callbacks = [
keras.callbacks.ModelCheckpoint(&quot;modelfinal3.keras&quot;, monitor=&quot;reg_output_loss&quot;, save_best_only=True , mode=&#39;min&#39;),
keras.callbacks.EarlyStopping(monitor=&#39;reg_output_loss&#39; , waiting = 8 ,mode=&#39;min&#39; )
]

# 在没有验证数据的情况下训练模型
history = model.fit(
X_train_images,{&#39;reg_output&#39; : Y1_regression ,&#39;cls_output&#39; : Y2_classification} ,
epochs= 10 ,
batch_size= 64,
callbacks=callbacks
)

test_model =keras.models.load_model(&quot;modelfinal3.keras&quot;, custom_objects ={&#39;angular_loss&#39;: angular_loss, &#39;rmse_degrees&#39;: rmse_degrees })
results = test_model.evaluate(X_test_images, {&#39;reg_output&#39; : Y1_regression_test ,&#39;cls_output&#39; : Y2_classification_test },return_dict=True )

print(results)

&#39;在此处输入代码结果
30/30 ━━━━━━━━━━━━━━━━━━━━━ 51s 2s/步 - cls_output_accuracy：0.6618 - cls_output_loss：9.0815 - loss：14.4716 - reg_output_loss：5.3914 - reg_output_rmse_degrees：2806.2744

Epoch 7/10
30/30 ━━━━━━━━━━━━━━━━━━━━━━━ 53s 2s/步 - cls_output_accuracy：0.6401 - cls_output_loss：8.9781 - 损失：14.7173 - reg_output_loss：5.7363 - reg_output_rmse_degrees：2787.8420
Epoch 8/10
30/30 ━━━━━━━━━━━━━━━━━━━━━━ 51s 2s/步 - cls_output_accuracy：0.6524 - cls_output_loss：9.0007 - 损失：14.5403 - reg_output_loss：5.5401 - reg_output_rmse_degrees： 2789.3442
时代 9/10
30/30 ━━━━━━━━━━━━━━━━━━━━━━ 51s 2s/步 - cls_output_accuracy：0.6674 - cls_output_loss：9.4412 - 损失：14.7438 - reg_output_loss：5.3030 - reg_output_rmse_degrees：2844.9971
时代 10/10
30/30 ━━━━━━━━━━━━━━━━━━━━━ 52s 2s/步 - cls_output_accuracy：0.6610 - cls_output_loss：9.3189 - 损失：14.7248 - reg_output_loss：5.4059 - reg_output_rmse_degrees：2828.9368
11/11 ━━━━━━━━━━━━━━━━━━━━━━━ 2s 142ms/步 - cls_output_accuracy： 1.0000 - cls_output_loss：9.4424 - loss：9.4928 - reg_output_loss：1.1921e-07 - reg_output_rmse_degrees：2435.0107
{&#39;cls_output_accuracy&#39;：1.0，&#39;cls_output_loss&#39;：8.932900428771973，&#39;loss&#39;：9.235373497009277，&#39;reg_output_loss&#39;：1.1920930376163597e-07，&#39;reg_output_rmse_degrees&#39;：2396.7568359375
进程已完成，退出代码为 0&#39;]]></description>
      <guid>https://stats.stackexchange.com/questions/656415/metrics-and-loss-problem-for-two-output</guid>
      <pubDate>Mon, 28 Oct 2024 14:40:00 GMT</pubDate>
    </item>
    <item>
      <title>多元模型需要随机截距吗？</title>
      <link>https://stats.stackexchange.com/questions/656412/is-a-random-intercept-necessary-for-multivariate-models</link>
      <description><![CDATA[我正在使用 brms 将 height 和 weight 建模为贝叶斯多变量模型中的联合结果，使用 mvbind(height, weight) ~ x。由于两个回答都来自同一个受试者，是否有必要添加随机截距 (1 | subject) 来解释重复测量？
我的数据如下所示：
+-------+-------+-------+
|subject|weight |height |
+-------+-------+-------+
|S1 | 65 | 1.3 |
+-------+-------+-------+
|S2 | 75 | 1.7 |
+-------+-------+-------+
|S3 | 80 | 1.8 |
+-------+-------+-------+
|... | ... | ... |
+-------+-------+-------+
]]></description>
      <guid>https://stats.stackexchange.com/questions/656412/is-a-random-intercept-necessary-for-multivariate-models</guid>
      <pubDate>Mon, 28 Oct 2024 13:29:31 GMT</pubDate>
    </item>
    <item>
      <title>从非独立样本进行估计？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656411/estimation-from-non-independent-samples</link>
      <description><![CDATA[假设 $X_1,X_2,...$ 是具有未知均值和方差的 iid 高斯 rv。然后从估计理论中，我们知道如何估计 $n$ 个样本的均值和方差。现在我对这个问题进行了概括。假设 $X = (X_1,\cdots,X_n\cdots)$ 是一个高斯过程，使得边际 $X_i$ 相同。那么从样本中，您能估计均值和方差吗？如何估计？]]></description>
      <guid>https://stats.stackexchange.com/questions/656411/estimation-from-non-independent-samples</guid>
      <pubDate>Mon, 28 Oct 2024 13:04:15 GMT</pubDate>
    </item>
    <item>
      <title>了解负部分依赖值</title>
      <link>https://stats.stackexchange.com/questions/656405/understanding-negative-partial-dependency-values</link>
      <description><![CDATA[负部分依赖值（例如随着输入的增加从 -0.7 变为 -0.5）对于参数来说意味着什么？
这是否意味着该参数与输出呈负相关，还是意味着预测通常低于平均值？
]]></description>
      <guid>https://stats.stackexchange.com/questions/656405/understanding-negative-partial-dependency-values</guid>
      <pubDate>Mon, 28 Oct 2024 10:08:51 GMT</pubDate>
    </item>
    <item>
      <title>使用非参数检验时，要报告配对样本的哪些描述性统计数据？</title>
      <link>https://stats.stackexchange.com/questions/656398/what-descriptive-statistics-to-report-for-a-paired-sample-when-using-a-nonparame</link>
      <description><![CDATA[我有两个变量，A 和 B（配对样本，前后），我需要进行配对样本非参数检验，因为 A 和 B 之间的差异分布不正常（配对值之间的差异的正态性假设不成立）。大约有 14 条记录。我的问题是：为了在表格中提供描述性统计数据，我是否应该提供 A 和 B 的中位数和 IQR，因为我们正在进行配对样本非参数检验，或者我应该首先分别检查每个变量的分布，如果它们遵循正态分布，则在表格中提供平均值和 SD 的值？]]></description>
      <guid>https://stats.stackexchange.com/questions/656398/what-descriptive-statistics-to-report-for-a-paired-sample-when-using-a-nonparame</guid>
      <pubDate>Mon, 28 Oct 2024 08:38:31 GMT</pubDate>
    </item>
    <item>
      <title>将对数应用于指数和线性拟合[重复]</title>
      <link>https://stats.stackexchange.com/questions/656374/applying-a-log-to-exponential-and-linear-fitting</link>
      <description><![CDATA[我使用或不使用线性变换来拟合一些数据。
这不应该给出与此问题中所示的相同结果：指数回归方法之间的差异。但在这里，在转换时，我通过添加权重来考虑误差传播。
我仍然得到不同的结果。哪里错了？
代码如下：
# 清除环境
rm(list=ls())

# 生成 x 值和 y 值
x_values_exp &lt;- c(0.1, 0.2, 0.5, 1, 2, 3, 4) 
y_values_exp &lt;- c(9, 8.5, 7.5, 6.4, 5.2, 4.7, 4.5)
# 创建数据框
my_data &lt;- data.frame(x = x_values_exp, y = y_values_exp)

# 使用未知权重拟合非线性模型 (exp)
mod_exp &lt;- nls(y ~ A * exp(B * x), data = my_data, start = list(A = 1, B = 1))

# 估计误差在 mod_exp 上（因为我有 2 个参数，所以是 2）
residuals &lt;- residuals(mod_exp)
y_error_estimated &lt;- sqrt(sum(residuals^2)/(length(residuals)-2))
my_data$y_error_estimated &lt;- y_error_estimated

# 应用 log
y_lin &lt;- log(y_values_exp)
# 我必须计算 y 上的相应误差（使用误差传播）
y_lin_errors &lt;- y_error_estimated / y_values_exp
my_data$y_lin_errors &lt;- y_lin_errors

# 拟合线性模型（使用转换后的数据并考虑估计误差）
mod_lin&lt;- nls(log(y) ~ A + B * x, data = my_data, start = list(A = 1, B = 1), weights = 1/(y_lin_errors^2))

# 打印
log( coef(mod_exp)[1]) # log
coef(mod_lin)[1] # lin

结果如下：
&gt; log( coef(mod_exp)[1]) # log
A 
2.151668 
&gt; coef(mod_lin)[1] # lin
A 
2.154402 

使用
y_lin_errors &lt;- y_error_estimated / predict(mod_exp)

如评论 (Sextus Empiricus) 中所述，结果更佳：
&gt; log( coef(mod_exp)[1]) # log
A 
2.151668 
&gt; coef(mod_lin)[1] # lin
A 
2.150832 

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/656374/applying-a-log-to-exponential-and-linear-fitting</guid>
      <pubDate>Sun, 27 Oct 2024 11:52:18 GMT</pubDate>
    </item>
    <item>
      <title>小样本观察结果的重要性</title>
      <link>https://stats.stackexchange.com/questions/656371/significance-of-an-observation-in-a-small-sample</link>
      <description><![CDATA[在 10000 人的群体中，我测试了 30 个人，发现他们全都患有一种疾病。基于这个样本量，我能否进行一些统计测试，以找出在 30 个受试个体都患有这种疾病的情况下，人口中可能患有这种疾病的比例是多少？
我正在进行类似 Cochrane 测试的测试，以找到给定重要性的样本量，但我无法找到上述问题的确切解决方案]]></description>
      <guid>https://stats.stackexchange.com/questions/656371/significance-of-an-observation-in-a-small-sample</guid>
      <pubDate>Sun, 27 Oct 2024 11:06:11 GMT</pubDate>
    </item>
    <item>
      <title>变分推理描述的难解性问题中的混淆[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656368/confusion-in-intractability-issue-described-by-variational-inference</link>
      <description><![CDATA[（已在 reddit 上发布了更长的版本）
我阅读 VAE 论文 已经有一段时间了，并查阅了各种资料，以便对指定的难解性问题有清晰的了解。然而，在试图理解它时，我仍然面临很多困惑。我会解释，但这里只是一些符号，以确保我们的观点一致：

z - 维度为 M 的潜在变量
Z - 表示潜在变量集 z 的随机变量
x - 输入变量（比如说图像）
X - 输入图像数据集

目标是了解潜在空间 Z 的分布，以便从该空间采样时，可以使用某个函数 f(z)（神经网络）生成新的数据点 x&#39;，该函数也属于 P(X) 的输入分布。因此，问题建模如下：

P(Z|X) = P(Z) * P(X|Z) / P(X)

然后，作者声称 P(Z|X) 是难解的，因为 P(X) 是难解的。从高层次上讲，我想了解难解性方面，所以我的问题是：

为什么 P(Z) 在这里不可解？事实上，P(Z) 甚至都不知道，那么为什么它不被认为是难解的？
我假设，P(X|Z) 可以通过应用 f(Z) 来计算，因此如果 P(Z) 是可解的，那么 P(X|Z) 也可以被认为是可解的？
为什么 P(X) 在这里令人担忧？就像它不是可以在整个 P(Z|X) 中假设为常数的某个归一化因子吗？

此外，如果有人可以通过举例而不是仅使用抽象符号来解释这一点以增加清晰度，那将非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/656368/confusion-in-intractability-issue-described-by-variational-inference</guid>
      <pubDate>Sun, 27 Oct 2024 06:04:08 GMT</pubDate>
    </item>
    <item>
      <title>R 中回归输出中删除变量</title>
      <link>https://stats.stackexchange.com/questions/656349/dropped-variable-in-regression-output-in-r</link>
      <description><![CDATA[我正在运行线性回归，试图预测结果 y，这是一个数值型连续变量，基于一个具有三个级别（A、B、C）的变量和另外三个变量，这些变量表示参与者被分配标签 A、B 和 C 的概率。
当我运行模型摘要时，其中一个概率变量的行填充了 NA。我猜这是因为 R 假设这 3 个变量可以构成 1（它们的概率相加等于 1），然后它将其排除在参考类别之外。但是，我不明白如何解释输出，我可以找到科学参考。有人对此有什么见解吗？
我期望我会为所有三个概率变量都有一个系数。我假设我可以转移参考类别，但这似乎太费力了，我不知道这是否是解决这个问题的唯一方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/656349/dropped-variable-in-regression-output-in-r</guid>
      <pubDate>Sat, 26 Oct 2024 13:32:30 GMT</pubDate>
    </item>
    </channel>
</rss>