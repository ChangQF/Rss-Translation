<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 18 Apr 2024 06:19:00 GMT</lastBuildDate>
    <item>
      <title>比较股票的基本面分析和技术分析</title>
      <link>https://stats.stackexchange.com/questions/645279/compare-fundamental-analysis-and-technical-analysis-of-stocks</link>
      <description><![CDATA[我必须为大学的一门课程做作业。我必须找到技术分析和基本面分析的股票评估结果不同的公司。我的教授向我展示了如何使用基本分析，即使用移动平均线，看看应该在哪几天使用 50 和 200 平均线买入或卖出股票。然后用基本面分析来看看该股票是否应该出售？但我不明白如何使用基本面分析来查看股票一天的市盈率、市盈率等数值。谁能给我解释一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645279/compare-fundamental-analysis-and-technical-analysis-of-stocks</guid>
      <pubDate>Thu, 18 Apr 2024 05:52:01 GMT</pubDate>
    </item>
    <item>
      <title>改进逻辑回归，其中多个信号单独产生相同的精度，并且将它们组合起来不会改进模型</title>
      <link>https://stats.stackexchange.com/questions/645277/improving-a-logistic-regression-where-multiple-signals-separately-yield-the-same</link>
      <description><![CDATA[我有一个逻辑回归来估计事件发生的概率。大约有 10,000 个数据点，大约有 20 个模型特征。模型的特征各不相同；它们的成对相关性大致在 [-0.5, 0.5] 范围内。
如果我分别对 20 个特征中的每一个特征进行逻辑回归建模，则其中 15 个特征的准确度约为 64-66%，并且具有相似的 BCE。对于其他 5 个，单个模型的准确率较低。
当我将所有 20 个特征组合到一个模型中时，准确性和 BCE 并没有提高。
这对我来说是违反直觉的 - 我希望将这些特征组合成一个更大的模型会提高准确性，因为特征之间的相互作用或创建更精确的“过滤器”的能力（例如，如果两个特征都意味着事件应该发生）。我还尝试过更复杂的模型，例如神经网络或基于 CART 的模型，但准确性仍然没有提高。
我想知道根本解释可能是什么，我如何进一步调试，以及我可以采取哪些步骤来尝试改进我的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/645277/improving-a-logistic-regression-where-multiple-signals-separately-yield-the-same</guid>
      <pubDate>Thu, 18 Apr 2024 05:48:14 GMT</pubDate>
    </item>
    <item>
      <title>确定逻辑回归中数字 x 变量和二元 y 标签的优势比在组之间是否不同（即性别或种族）</title>
      <link>https://stats.stackexchange.com/questions/645275/determining-if-odds-ratio-for-a-numerical-x-variable-and-binary-y-label-in-logis</link>
      <description><![CDATA[我见过人们问过类似的问题，但我仍然不太清楚最好的建议是什么 - 我正在查看一个二元因变量和多个自变量（其中一些是分类变量，例如种族或性别或其他人口统计变量，其中一些是数字的）。如何确定数值变量 x1 和二进制 y 之间的关联/优势比在不同性别群体或不同种族群体之间是否不同。我很好奇看一下简单逻辑回归（仅将 x1 作为依赖项）和多重逻辑回归（使用 x 以及其他已进行单热编码的分类/数字人口统计变量）的区别以每个变量中最大的类别作为参考）。
分析这个问题的最佳方法是什么？将人群分为几组（即女性患者与男性患者，或白人患者与黑人患者与亚洲患者）并为每个组运行逻辑回归来比较优势比是一个坏方法吗？卡方检验？其他的？非常感谢任何建议/解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/645275/determining-if-odds-ratio-for-a-numerical-x-variable-and-binary-y-label-in-logis</guid>
      <pubDate>Thu, 18 Apr 2024 05:02:14 GMT</pubDate>
    </item>
    <item>
      <title>为什么多元线性回归在预测时间方面比单层神经网络表现更好？</title>
      <link>https://stats.stackexchange.com/questions/645274/why-multiple-linear-regression-perform-better-than-single-layer-neural-network-i</link>
      <description><![CDATA[我正在研究预测机器组件的故障时间。
响应是机器部件的故障时间，输入是位置信息（由整数组成）。
我将神经网络模型拟合为具有 100 个节点的一个线性层。此外，我还拟合了多元线性回归并预测了故障时间。
基于多元线性回归的MSE为0.43，基于神经网络的MSE为0.64-0.67。然而，神经网络有更多的参数，可以捕获更复杂的数据信息，它应该比线性回归更好，不是吗？
完整样本量为19319，训练量为14489，测试量为4830。
在将输入输入神经网络之前，我对输入进行了标准化。神经网络模型的详细内容如下。
类 Net(torch.nn.Module):
  def __init__(self, n_feature, size_hidden, n_output):
    超级（网络，自我）.__init__()
    self.hidden = torch.nn.Linear(cols, size_hidden)
    self.predict = torch.nn.Linear(size_hidden, n_output)

def 前向（自身，x）：
    输出 = self.predict(self.hidden(x))
    返回输出

列=7
n_输出=1
净=净（列，100，n_output）.cuda（）

优化器= torch.optim.RAdam（net.parameters（），lr = 0.001，betas =（0.9，0.999），eps = 1e-08，weight_decay = 0.9，foreach =无）
优化器 = torch.optim.Adam(net.parameters(), lr=0.001)

标准 = torch.nn.MSELoss(size_average=True)

批量大小 = 200 或 500 或 1000 或 3000 或 5000

我尝试了 Adam、RAdam、SGD 等各种学习率 0.001 和 0.01 的优化器。如果学习率为0.01，则不收敛。
此外，对于所有不同的批量大小，性能相似。]]></description>
      <guid>https://stats.stackexchange.com/questions/645274/why-multiple-linear-regression-perform-better-than-single-layer-neural-network-i</guid>
      <pubDate>Thu, 18 Apr 2024 04:48:01 GMT</pubDate>
    </item>
    <item>
      <title>ARMA$\left(2,2\right)$ 模型的方差</title>
      <link>https://stats.stackexchange.com/questions/645272/variance-of-arma-left2-2-right-model</link>
      <description><![CDATA[&lt;块引用&gt;
如果 $Y_t = 5 + 2Y_{t-1} - 1.7Y_ 则求 $Var(∇Y_t)$ {t-2} + 0.7Y_{t-3} + e_t - 0.5e_{t-1} + 0.25e_{t-2}$。

我已将其减少为 $∇Y_t = 5 + ∇Y_{t-1} - 0.7∇Y_{t-2} + e_t - 0.5e_{t- 1} + 0.25e_{t-2}$。现在，假设 $W_t = ∇Y_t - \mu$，其中 $\mu$ 是某个常数，我们可以将其改造成 ARMA$\left(2,2\right)$ 模型：$$W_t = W_{t-1} - 0.7W_{t-2} + e_t - 0.5e_{t-1} + 0.25e_{t-2}$$
将模型分解为 AR/MA 特征多项式形式：
$(1 - B_1 + 0.7B_1^2)W_t = (1 - 0.5B_2 + 0.25B_2^2)e_t$，我们找到所有根$|B_1|&gt;1$ 和 $|B_2|&gt;1$，因此满足平稳和可逆的要求。因此，$E(W_t) = 0$，因此 $Var(∇Y_t) = Var(W_t) = E( W_t^2) = E\left(W_t(W_{t-1} - 0.7W_{t-2} + e_t - 0.5e_{t-1} + 0.25e_{t-2}) \right)$。我无法进一步简化它。]]></description>
      <guid>https://stats.stackexchange.com/questions/645272/variance-of-arma-left2-2-right-model</guid>
      <pubDate>Thu, 18 Apr 2024 02:42:08 GMT</pubDate>
    </item>
    <item>
      <title>多实例时间序列数据区间分类</title>
      <link>https://stats.stackexchange.com/questions/645270/classification-of-intervals-in-time-series-data-of-multiple-instances</link>
      <description><![CDATA[我有一个问题正在尝试解决。我有来自心电图的信号数据（随时间变化的经典信号数据）。这里有一个接近的例子：https://github.com/jjongjjong/ECG_segmentation_1DUnet
我主要对识别心电图数据中的片段（t 波、QRS 等）感兴趣。
因此数据来自多个患者（重复测量或独立患者），每个患者都有自己的元数据。输出是一个one-hot编码的x轴（时间），指示要分类的间隔（比上一个链接中的数据更简单）
我的想法是，我需要一个具有简单层或两个卷积层的神经网络，然后是循环层或变压器层。据我所知，添加状态保持层对于解决这个问题是一个好主意，但似乎很难实现。
那么我如何实现具有患者特征的神经网络以获得感兴趣的输出？]]></description>
      <guid>https://stats.stackexchange.com/questions/645270/classification-of-intervals-in-time-series-data-of-multiple-instances</guid>
      <pubDate>Thu, 18 Apr 2024 01:51:17 GMT</pubDate>
    </item>
    <item>
      <title>事后效应大小与 p 值是否冗余？</title>
      <link>https://stats.stackexchange.com/questions/645269/is-the-post-hoc-effect-size-redundant-with-the-p-value</link>
      <description><![CDATA[为了简单起见，假设我们正在对 2 个正态分布总体进行 2 样本 t 检验，从中收集 2 个 i.i.d 样本。 （首先；我们可以稍后扩展到更复杂的情况）。我们知道，一项研究的事后观察功效完全由观察到的 p 值决定。请参阅此处，或此处，以及此网站上的多个参考。
然后，事后我们得到了计划的 $\alpha$ （传统上为 0.05），实际样本大小 $N $ 和 p 值 $p$。但从 $p$ 中我们可以获得电源 ($1-\beta$)，如链接。我们有观察到的标准差 ($sd$)。我将其插入任何功耗分析软件中，它将给出研究所支持的最小效应：我们称之为 $\delta$。我们观察到了效果 ($\delta&#39;$)。
认为 $\delta&#39;$ 与 $p$？ （正如功率与 p 的链接所示）。也许用 $\delta&#39;=\delta$ 来表示 $p$=.05？ （即功率=50%）。或者事后效应大小是一个随机变量吗？在这种情况下，它的分布可能是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/645269/is-the-post-hoc-effect-size-redundant-with-the-p-value</guid>
      <pubDate>Thu, 18 Apr 2024 01:40:12 GMT</pubDate>
    </item>
    <item>
      <title>给定回归参数的点估计的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/645268/confidence-interval-over-point-estimate-given-regression-parameters</link>
      <description><![CDATA[在贝叶斯分析中，当 PDF 不难处理时（经常），通常会对海报分布进行采样。如果样本的长度为 $n$ 则 $range(1,n)$ 中的每个索引都对应从该（通常是多维的）分布中获取有效样本。在简单线性回归的背景下，斜率、截距和噪声是后验分布的三个维度（假设没有超先验）。
要计算给定点周围的可信分布$P(\hat{y}|x, \beta_0, \beta_1)$，可以运行模拟其中可以对 $range(1,n)$ 中的索引进行采样并检索参数值；随后，可以计算 $\hat{y}$ 的值并将其附加到数组中。最后，可以根据需要对数组进行排序和处理（例如 95% 的可信区间。）
我的问题是，频率统计的类似过程是什么？即使斜率或系数具有统计显着性并且每个的置信区间已知，这也不是模型参数之间的联合分布。因此，我怀疑无法独立地从每个置信区间中采样参数来计算点估计的分布。
这可以通过Frequentist工具包实现吗？或者问这样的问题纯粹是贝叶斯构造，而频率论者除了知道参数值的含义是什么以及它们是否重要之外不会感兴趣？]]></description>
      <guid>https://stats.stackexchange.com/questions/645268/confidence-interval-over-point-estimate-given-regression-parameters</guid>
      <pubDate>Thu, 18 Apr 2024 00:18:14 GMT</pubDate>
    </item>
    <item>
      <title>缩放二元逻辑回归的优势比</title>
      <link>https://stats.stackexchange.com/questions/645255/scaling-the-odds-ratio-of-a-binary-logistic-regression</link>
      <description><![CDATA[简单说一下 - 简而言之，我正在开展一项有关年龄和婚姻的研究。
我发现，通过二元逻辑回归（因变量是否已婚），年龄的优势比为 1.01（p &lt; 0.001 时显着）。注：年龄范围为 18 岁（最年轻的受访者）到 82 岁（最年长的受访者）。
我很确定我的解释是正确的：“在所有其他控制不变的情况下，年龄每增加一年，结婚的可能性就会增加 1%”。我的困惑是，我最初将此解释为基本上具有统计显着性结果的指示，但实质性价值较低（假设只有 1%）。
但我发现有些人可能会调整他们的优势比 - 即。表明年龄增加 20 岁意味着结婚的可能性增加 1.01^20 = 1.22。这表明 40 岁的人结婚的可能性比 20 岁的人高 22%。
这是正确的吗？在我看来，你可以简单地按比例放大它并假设优势比在所有情况下保持不变，这似乎是误导？如果是这样的话，那么这个发现对“现实生活”的影响可能比我想象的更大？]]></description>
      <guid>https://stats.stackexchange.com/questions/645255/scaling-the-odds-ratio-of-a-binary-logistic-regression</guid>
      <pubDate>Wed, 17 Apr 2024 18:51:52 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何分析配对且重复测量的数据？</title>
      <link>https://stats.stackexchange.com/questions/645244/how-should-i-analyze-data-that-is-paired-and-also-repeatedly-measured</link>
      <description><![CDATA[我在 11 天内从同一受试者 (n=10) 收集数据，每天在两种条件下进行测量：训练后立即 (D0) 和训练后 30 分钟 (D30)。数据是有序的，范围从 1 到 10。我想了解训练后立即进行的测量和训练后 30 分钟进行的测量之间是否存在差异。我应该如何分析这些数据，我应该使用哪种测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/645244/how-should-i-analyze-data-that-is-paired-and-also-repeatedly-measured</guid>
      <pubDate>Wed, 17 Apr 2024 17:06:04 GMT</pubDate>
    </item>
    <item>
      <title>单变量特征选择[关闭]</title>
      <link>https://stats.stackexchange.com/questions/645107/univariate-feature-selction</link>
      <description><![CDATA[在决策树机器学习中，特征选择是构建决策树模型的重要步骤，因为它有助于识别要包含在模型中的最相关变量。单变量特征选择涉及根据个体重要性来选择特征。
使用基于信息增益标准的决策树机器学习算法的单变量特征选择，可以使用什么统计技术来检测大型数据集中的模式和关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/645107/univariate-feature-selction</guid>
      <pubDate>Tue, 16 Apr 2024 03:33:19 GMT</pubDate>
    </item>
    <item>
      <title>在 F1 分数和精确召回曲线下面积 (AUPRC) 之间选择正确的评估指标</title>
      <link>https://stats.stackexchange.com/questions/645005/choosing-the-correct-evaluation-metric-between-f1-score-and-area-under-the-preci</link>
      <description><![CDATA[我们目前正在致力于从卫星图像中检测特定物体（例如家禽养殖场、医院）。我们已将该问题建模为二值图像分类任务（即将图像分类为农场/非农场），并使用梯度加权类激活图 (CAM) 来进一步定位图像内的对象。我们这样做是为了避免手动注释对象周围的边界框的高成本，因为获取二进制标签要便宜得多。到目前为止，CAM 非常适合本地化对象，无需边界框注释。
对于图像分类任务，我们首先优化 F1 分数，将概率阈值设置为默认值 0.5。但我们后来意识到，由于最佳阈值取决于最终用户对误报和漏报的容忍度，因此优化精确召回曲线下的面积 (AUPRC) 实际上可能会更好。当我们集成人机交互验证时，我们目前正在开发一个用户界面，用户可以根据他们有多少预测资源在现场验证来动态更改阈值。
现在，可调整阈值的范围是从 0.5 到 1.0，因为我们只为正预测生成 CAM，即概率 &gt; 的预测。 0.5 为正类。为所有预测生成 CAM 似乎没有意义（即使是那些对正类的置信度分数较低的预测），因为它的计算量很大，并且不太可能产生有意义的输出，因为这些低概率图像可能不包含该对象.
有了这个，优化 AUPRC 是否仍然有意义，还是应该继续优化 F1 分数？我们是否应该根据我们独特的用例生成自己的自定义性能指标？谢谢！
编辑：鉴于我们只为概率 &gt; 的预测生成 CAM。 0.5，仅考虑概率 &gt; 来计算 AUPRC 是否有意义？ 0.5？]]></description>
      <guid>https://stats.stackexchange.com/questions/645005/choosing-the-correct-evaluation-metric-between-f1-score-and-area-under-the-preci</guid>
      <pubDate>Sun, 14 Apr 2024 19:23:28 GMT</pubDate>
    </item>
    <item>
      <title>通过具有时空相关性的二元测量进行重复横截面调查来预测未观察年份的区域水平比率</title>
      <link>https://stats.stackexchange.com/questions/644832/predicting-area-level-rates-during-an-unobserved-year-from-repeated-cross-sectio</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/644832/predicting-area-level-rates-during-an-unobserved-year-from-repeated-cross-sectio</guid>
      <pubDate>Thu, 11 Apr 2024 19:28:44 GMT</pubDate>
    </item>
    <item>
      <title>“RV系数”与典型相关性的关系</title>
      <link>https://stats.stackexchange.com/questions/644742/rv-coefficient-relationship-to-canonical-correlation</link>
      <description><![CDATA[规范相关性解决以下问题：
&lt;块引用&gt;
给定矩阵 $X$ 和 $Y$，$X$ 与 $Y$ 的列的线性组合最相关，这种相关性是什么？&lt; /p&gt;

我遇到了一个“RV系数”，旨在概括之间的皮尔逊相关性单变量随机变量到多元随机变量。
$$
\Sigma_{XY} = \mathbb E\left[XY^T\right]
$$
$$
\text{COVV}\left(X, Y\right) = \text{Trace}\left(\Sigma_{XY} \Sigma_{YX}\right)
$$
$$
\text{VAV}\left(X\right) = \text{Trace}\left(
\Sigma_{XX}^2
\正确的）
$$
$$
\text{RV}\left(X, Y\right) = \dfrac{
\text{COVV}\left(X, Y\right)
}{
\sqrt{
\text{VAV}\left(X\right)\text{VAV}\left(Y\right)
}
}
$$
这似乎是通常 Pearson 相关性的一个足够合理的向量模拟，$\rho\left(X, Y\right) = \dfrac{\text{COV}\左(X, Y\right)}{\sqrt{\text{VAR}\left(X\right)\text{VAR}\left(Y\right)}}$。
但是这个 $RV$ 系数不仅仅是 $X$ 和$Y$，即$X$边距与$Y$ 边距？ （也许规范相关性的某些函数等于 $RV$ 系数。）
在我编写的一些代码中，情况似乎并非如此。
set.seed(2024)

# R 没有原生矩阵追踪函数吗？
#
tr &lt;- 函数(M){
  d &lt;- 暗淡(M)
  n &lt;- d[1]
  m &lt;- d[2]
  s &lt;-rep(NA, n)
  对于 (1:n 中的 i){
    s[i] &lt;- M[i, i]
  }
  返回（总和）
}
a &lt;- 矩阵(seq(1, 9), 3, 3)

sigma_xy &lt;- 函数(X, Y){
  P &lt;- 比例（X，比例 = F） %*% t（比例（Y，比例 = F））
  返回（cov（P））
}

covv &lt;- 函数（X，Y）{
  m1 &lt;- sigma_xy(X, Y)
  m2 &lt;- sigma_xy(Y, X)
  返回（tr（m1％*％m2））
}

vav &lt;- 函数(X){
  返回（covv（X，X））
}

rv &lt;- 函数（X，Y）{
  返回（
    covv(X,Y)/
      开方（
        vav(X) * vav(Y)
      ）
  ）
}

N &lt;- 100
p &lt;- 5
X &lt;- 矩阵(rnorm(N*p), N, p)
Y &lt;- 7*X + 9 + 矩阵(rnorm(N, 0, 2), N, p)

rv(X,Y)#0.92489
rv(X,Y)^2 # 0.8554215
cancor(X, Y)$cor[p] # 0.8504828
cancor(X, Y)$cor[p]^2 # 0.723321

平方 $RV$ 值接近规范相关性，但它们的不同足以让我不确定。例如，差异是否可以通过特定的估计程序来解释，例如样本协方差计算中的分母在一个地方而不是另一个地方？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/644742/rv-coefficient-relationship-to-canonical-correlation</guid>
      <pubDate>Wed, 10 Apr 2024 17:52:26 GMT</pubDate>
    </item>
    <item>
      <title>适用于具有上限的时间数据的统计模型？</title>
      <link>https://stats.stackexchange.com/questions/644540/appropriate-stats-model-for-time-data-with-an-upper-limit</link>
      <description><![CDATA[我正在努力为我的数据集的一部分确定统计方法。任何想法/见解将不胜感激。
受试者（分为两个类别组）每天有一个小时的时间玩游戏，持续多天。如果他们在 5 分钟内没有参与游戏，游戏就会提前终止。
我的因变量记录了每个受试者每天玩游戏的时间。然而，它的上限为 1 小时，因为游戏会自动终止。此外，只有当受试者因不活动而超时时，他们的总游戏时间才少于一小时。
我想构建一个类似于“Gameplay_time ~ Date * Group + (1|Subject)”的模型，但上限为 1 小时。
我的主要问题是在测试的任何一天中玩游戏的时间是否存在群体差异。

您认为处理此数据集的适当方法是什么？我最初的想法是单膨胀 Beta 回归，但这导致了看似虚假的结果。
拆分问题是否更好？例如，对“Timed_Out”（是/否）与“Group”（两个级别）进行卡方检验会更好吗？然后，如果不重要，则删除玩了 1 小时的受试者，并在缩减的数据集上拟合 GLMM。
]]></description>
      <guid>https://stats.stackexchange.com/questions/644540/appropriate-stats-model-for-time-data-with-an-upper-limit</guid>
      <pubDate>Mon, 08 Apr 2024 06:01:34 GMT</pubDate>
    </item>
    </channel>
</rss>