<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 06 Jan 2025 03:25:22 GMT</lastBuildDate>
    <item>
      <title>减少 MLP 过度拟合以提高特征重要性</title>
      <link>https://stats.stackexchange.com/questions/659597/reducing-mlp-overfitting-for-feature-importance</link>
      <description><![CDATA[我正在一个数据集上训练 MLP，数据集的特征数量 &gt;&gt; 样本数量。出于某些原因，至少有一个隐藏层的 MLP 是我唯一考虑的架构。毫不奇怪，即使是最简单的 MLP，我也会出现严重的过度拟合（训练 AUROC 很快达到 1）。
我的 Xs 也不太能描述 ys：即使我有无限数量的样本，我也不会期望超过测试 AUROC ~0.7。
我的目标不是训练一个好的预测模型，而是训练最好的模型，然后在下游分析中研究最重要的特征。由于我正在处理特征重要性，因此对我来说，尽可能减少过度拟合至关重要。
问题是：l1/l2 正则化和 dropout 等标准技术是否允许尽可能减少过度拟合，还是它们的能力有限？我不介意包含具有非常高丢失概率的丢失层，但我真的想避免必须考虑更少的特征。我知道提前停止，但我真的不想在一个时期后停止。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659597/reducing-mlp-overfitting-for-feature-importance</guid>
      <pubDate>Mon, 06 Jan 2025 03:13:45 GMT</pubDate>
    </item>
    <item>
      <title>使用 rep() 会导致向量比“times”参数更短[迁移]</title>
      <link>https://stats.stackexchange.com/questions/659593/using-rep-results-in-vector-shorter-than-times-argument</link>
      <description><![CDATA[我正在一个循环中工作，我需要将一个字符串复制一定次数。随着循环的进行，复制的次数需要增加，我从向量中提取该值。我的循环卡在需要复制“ES”56 次的迭代上，因为 rep() 函数只复制了 55 次。这是一个更大任务的一部分，但我已将其精简为失败的部分。
在对此进行故障排除时，我发现只有当我需要复制“ES”的次数从百分比向量中引用时才会发生这种情况。如果我将 x 指定为值本身，它会正常工作，并生成完整的 56 长度向量。但是当从序列中提取 x 时，它只生成一个长度为 55 的向量。
# 这将生成一个长度为 56 的向量
x &lt;- 0.14
y &lt;- 400
test &lt;- rep(&quot;ES&quot;,times=x*y) 
length(test)
class(x)

# 这将生成一个长度为 55 的向量
x &lt;- seq(0.02,0.50,0.02)[7]
y &lt;- 400
rep(&quot;ES&quot;,times=x*y)
length(test)
class(x)

变量 x 在两个实例中都属于“numeric”类。经过大量测试，我发现唯一可行的方法是将 x 转换为字符，然后再将其转换回数字。
i &lt;- seq(0.02,0.50,0.02)
x &lt;- as.character(i[7])
x &lt;- as.numeric(x)
y &lt;- 400
rep(&quot;ES&quot;,times=x*y)

有人能解释为什么会发生这种情况吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659593/using-rep-results-in-vector-shorter-than-times-argument</guid>
      <pubDate>Mon, 06 Jan 2025 01:23:19 GMT</pubDate>
    </item>
    <item>
      <title>抛硬币能给假设检验提供任意的$\alpha$吗？</title>
      <link>https://stats.stackexchange.com/questions/659589/can-flipping-a-coin-give-a-hypothesis-test-an-arbitrary-alpha</link>
      <description><![CDATA[以下假设检验是否符合所有定义？

选择一个 $\alpha$（通常为 $0.05$）
设 $A := \lceil -\log_2(\alpha) \rceil$（其中 $\lceil x \rceil$ 是大于或等于 $x$ 的最小整数）
抛硬币 $A$ 次
如果其中一次抛出的是正面，则维持原假设
如果全部都是反面，则拒绝原假设假设

此检验的显著性水平为$\alpha$。它对所有备选假设的功效也为$\alpha$，因此效率很低。]]></description>
      <guid>https://stats.stackexchange.com/questions/659589/can-flipping-a-coin-give-a-hypothesis-test-an-arbitrary-alpha</guid>
      <pubDate>Sun, 05 Jan 2025 22:58:56 GMT</pubDate>
    </item>
    <item>
      <title>在进行 A/B 测试时，假设检验有助于做出决策吗？</title>
      <link>https://stats.stackexchange.com/questions/659587/does-hypothesis-testing-help-make-a-decision-in-case-of-an-a-b-test</link>
      <description><![CDATA[我根据大型语言模型 (LLM) 的最新进展开发了一个文本生成管道。用户可以输入一个主题，然后我的复杂管道会生成一篇文章。我通过询问用户对每篇文章 (C-SAT) 的 5 分制序数表的满意程度来衡量用户满意度。
我实施了一个管道变体，在某些地方使用更便宜、更愚蠢的 LLM。我进行了 A/B 测试，以确定管道的当前版本和更便宜的版本之间的差异。假设平均 C-SAT 为 3.9 比 3.8，那么更便宜的版本的 C-SAT 分数低 0.1。现在，我必须决定是否引入新版本的管道以降低成本并承担降低平均 C-SAT 的风险。
我想知道 C-SAT 的下降是否足以让我放弃削减成本。
Q1：在这种情况下，假设检验有意义吗？
Q2：如果有意义，那么总体是什么？现在知道了未来文章的数量。此外，其中一个版本将不会继续。这是否意味着我不能应用测试？
测试的结果将是反对零假设的证据。假设我的零假设是“A 和 B 样本的总体分布均值相等”。从原始问题的角度来看（“如果 C-SAT 的下降足以让我放弃削减成本”），这样的 H0 是一个中间问题。
Q3：我怎么知道找到这样一个中间问题的答案有助于我找到原始问题的答案？]]></description>
      <guid>https://stats.stackexchange.com/questions/659587/does-hypothesis-testing-help-make-a-decision-in-case-of-an-a-b-test</guid>
      <pubDate>Sun, 05 Jan 2025 22:33:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们将标准误差定义为忽略偏差（与包含偏差的 MSE 不同）？</title>
      <link>https://stats.stackexchange.com/questions/659583/why-do-we-define-the-standard-error-to-ignore-bias-unlike-mse-which-includes-bi</link>
      <description><![CDATA[为什么估计量$\hat \theta$的标准误差定义为$$se = \sqrt{Var(\hat \theta)}$$，而不是$$se = \sqrt {MSE(\hat \theta)} = \sqrt{Bias^2(\hat \theta) + Var(\hat \theta)}.$$
也就是说，标准误差应该是均方误差的平方根。当然，如果估计量是无偏的，那就没有区别了。但无论如何，我能想到，如果估计量有偏差，那么我们使用标准误差的地方，偏差需要成为误差的一部分。
例如，考虑执行 Wald 检验。如果我们愿意增加偏差，我们总是可以得出任意低方差的 $\sigma^2$ 估计量。例如，给定 $\hat \sigma^2$，定义 $$\hat \sigma_1^2 = (1-t)\hat \sigma^2 + tk$$，对于任意常数 $t,k$ 将给出这样的估计量。如果我们使用它来执行 Wald 检验，我们可以通过降低 se 来获得我们想要的任何 $\alpha$，而无需真正改进测试。
如果 se 的定义包括偏差，这个问题就会得到解决 - 这会与 标准 错误 一词更加一致。我们为什么不这样做呢？

更新 - 与假设检验的相关性
撇开术语不谈，这里有一个有影响力的问题：在我们的估计量确实有偏差的情况下，我们应该在假设检验中使用 标准错误 还是上述定义？有些情况下，这会对测试结果产生影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/659583/why-do-we-define-the-standard-error-to-ignore-bias-unlike-mse-which-includes-bi</guid>
      <pubDate>Sun, 05 Jan 2025 21:17:49 GMT</pubDate>
    </item>
    <item>
      <title>梦幻篮球：重新思考球员的价值</title>
      <link>https://stats.stackexchange.com/questions/659577/fantasy-basketball-rethinking-player-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659577/fantasy-basketball-rethinking-player-value</guid>
      <pubDate>Sun, 05 Jan 2025 20:56:33 GMT</pubDate>
    </item>
    <item>
      <title>如何实现全卷积神经网络（FCN）用于多类分类任务？</title>
      <link>https://stats.stackexchange.com/questions/659573/how-can-a-fully-convolutional-neural-network-fcn-be-implemented-for-a-multicla</link>
      <description><![CDATA[在网络上我看到的几乎所有资料中，FCN 主要用于分割等问题（例如具有各种上采样层的 U-net），所以我的问题是，考虑到它们能够处理不同分辨率的图像，如何使用这些网络进行简单的多类分类任务。
我能想到的唯一解决方案是 FCN 产生具有 c 个通道（其中 c 是类别数）的特定热图体积，然后是 GAP，然后是 softmax。还有其他完全卷积方法吗？我读到过一种称为“卷积化”的过程，它可以让你在这种情况下重用预先训练的 CNN（非完全卷积）的权重，但我真的不明白它是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/659573/how-can-a-fully-convolutional-neural-network-fcn-be-implemented-for-a-multicla</guid>
      <pubDate>Sun, 05 Jan 2025 20:08:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么交互项虚拟变量的个体显著性取决于基类/省略类，而联合显著性却不取决于基类/省略类？</title>
      <link>https://stats.stackexchange.com/questions/659572/why-is-individual-significance-of-interaction-term-dummies-dependent-on-the-base</link>
      <description><![CDATA[我不认为我可以展示数据，但在线性回归模型中，除了其他几个变量外，我还有一个连续变量年龄和分类变量健康之间的交互项。健康有 5 个类别。当我以不同的类别为基础运行模型时，每个非省略类别的个体显著性检验 p 值差异很大（例如，当“优秀”健康为基础时，年龄和“一般”健康之间的交互作用显著，达到 95%，但当“较差”健康为基础时，它并不单独显著），但联合显著性检验 p 值始终相同（显著性达到 95%）。
此外，交互项的输出系数会发生变化，但使用“margins”和“marginsplot”的图形的实际斜率不会发生变化Stata 中的命令。
因此
regressdependentvar c.age##ibx.healthother_variable1other_variable2testparm c.age#ibx.healthmargins,at(age=(16(1)80)health=(12345))atmeansmarginsplot 产生相同的联合显著性和相同的图形，但每个交互项的个体显著性 p 值和系数不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/659572/why-is-individual-significance-of-interaction-term-dummies-dependent-on-the-base</guid>
      <pubDate>Sun, 05 Jan 2025 20:03:09 GMT</pubDate>
    </item>
    <item>
      <title>比较参数曲线：基于傅里叶级数的相似度度量</title>
      <link>https://stats.stackexchange.com/questions/659553/comparing-parametric-curves-fourier-series-based-similarity-metric</link>
      <description><![CDATA[使用傅里叶级数开发参数曲线的相似度度量
我正在探索使用傅里叶级数表示法在 xy 平面上比较参数曲线的方法。我的目标是开发一种能够最好地捕捉曲线“形状”的相似度度量。以下是我正在考虑的一些想法：
背景：

xy 平面上的参数曲线表示为复函数：
$z(t) = x(t) + iy(t)$
其中 $x(t)$ 和 $y(t)$ 是曲线的参数方程，$t \in (0, 1)$。

此复函数可表示为傅里叶级数：
$z(t) = \sum_{n=-\infty}^{\infty} c_n e^{2\pi int}$

傅里叶系数$c_n$的计算方法如下：
$c_n = \int_0^1 z(t) e^{-2\pi int} dt$

这些系数包含幅度和相位信息：
$c_n = |c_n|e^{i\phi_n}$
其中$|c_n|$为幅度，$\phi_n$为相位。

首先，我们将傅里叶级数标准化为具有能量 1：
$\sum_{n=-N}^{N} |c_n|^2 = 1$


当前考虑事项：

相位信息：我认为相位对于确定曲线形状至关重要。是否有证据表明情况并非如此？

相关工作：

一些现有方法比较功率谱密度（忽略相位）
这些方法通常将 PSD 视为概率密度
两个离散傅里叶变换的相似性
比较傅里叶空间中的两个分布



潜在方法：

分离幅度和相位比较：

分别比较功率谱密度和相位谱密度
将两者视为概率分布
使用上述相关工作中的方法


笛卡尔形式的余弦相似性：

以平坦笛卡尔形式写入傅里叶系数（自然包括幅度和相位信息）
应用余弦相似性
优点：自然在 -1 和 1 之间有界
缺点：对于接近 0 或负值的分数的解释不明确


笛卡尔形式的 L1/L2 距离：

与方法 2 类似，但使用 L1 或 L2 距离而是



问题：
是否有一种原则性的方法，可以使用傅里叶级数表示法来开发 xy 平面上参数曲线的相似性度量，该度量法可以同时考虑幅度和相位信息？
我特别想了解这些方法与我可能忽略的任何其他方法之间的权衡。]]></description>
      <guid>https://stats.stackexchange.com/questions/659553/comparing-parametric-curves-fourier-series-based-similarity-metric</guid>
      <pubDate>Sun, 05 Jan 2025 08:49:43 GMT</pubDate>
    </item>
    <item>
      <title>如何计算独立拍卖实验中销售额、退货和退货率变化的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/659552/how-to-compute-confidence-intervals-for-changes-in-sales-returns-and-return-ra</link>
      <description><![CDATA[问题
假设我正在组织一场汽车拍卖会，并进行两个独立的实验：

拍卖会 A 进行了 1000 次。
拍卖会 B 进行了 1000 次。
（例如，我更换了拍卖会 B 中的拍卖师，并想测量其效果。）

以下是观察到的结果：




拍卖会 A
拍卖会 B
符号




数量运行
1000
1000
常数 $ n_A $ 和 $ n_B $


售出数量
500
600
随机变量 $ S_A $ 和 $ S_B $


（售出和）退回数量
200
300
随机变量$ R_A $ 和 $ R_B $



根据这些数据，增量（我感兴趣的）如下：

销售数量增加了 20%：从 500 增加到 600。
退货数量增加了 50%：从 200 增加到 300。
退货率增加了 25%：从 40%（$ \frac{200}{500} $）增加到 50%（$ \frac{300}{600} $)。

问题 1：增量的置信区间
如何计算 95% 置信水平下每个增量的置信区间？例如：

销售数量增量，例如 $[+16\%, +27\%]$。
退货数量增量，例如 $[+42\%, +53\%]$。
退货率增量，例如 $[-5\%, +41\%]$。


我目前的方法（针对 #1）：
计算销售数量增量的置信区间：

我假设 $ S_A \sim \text{Binomial}(n_A, p^s_A) $ 和 $ S_B \sim \text{Binomial}(n_B, p^s_B) $，其中 $ p^s_A $ 和 $ p^s_B $ 是拍卖 A 或拍卖 B 中拍卖成交的概率 ($ p^s_A = 50\%, p^s_B = 60\% $)。
然后，我计算置信区间如下：
$$
\Delta S \pm z_{\alpha/2} \sqrt{\text{Var}(\Delta S)}
$$
其中：
$$
\text{Var}(\Delta S) = \text{Var}(S_A) + \text{Var}(S_B),
$$
并且：
$$
\text{Var}(S_A) = n_A p^s_A (1 - p^s_A), \quad \text{Var}(S_B) = n_B p^s_B (1 - p^s_B)。
$$
这种方法有意义吗？


我的挑战（针对 #2 和 #3）：
计算回报数量和回报率的增量置信区间：

我假设 $ R_A \mid S_A \sim \text{Binomial}(S_A, p^r_A) $，对于 $ R_B $ 也是如此。
我应该如何计算 $ \text{Var}(R_A) $ 和 $ \text{Var}(R_B) $？

我是否应该将观察到的销售数量（$ s_A $ 和 $ s_B $）视为常数（如第一种情况下的 $ n_A $ 和 $ n_B $）？
或者我应该将销售数量（$ S_A $ 和 $ S_B $）视为随机变量，并使用总方差定理计算 $ \text{Var}(R_A) $：
$$
\text{Var}(R_A) = \mathbb{E}[\text{Var}(R_A \mid S_A)] + \text{Var}(\mathbb{E}[R_A \mid S_A])?
$$



如能提供关于这些计算的任何指导或替代方法的建议，我们将不胜感激！

备注

我特别关心我的假设（例如，将观测值视为常数而不是随机变量）是否正确。
我希望得到任何相关统计方法或框架的指引，以便更好地处理这些类型的分析。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659552/how-to-compute-confidence-intervals-for-changes-in-sales-returns-and-return-ra</guid>
      <pubDate>Sun, 05 Jan 2025 06:07:41 GMT</pubDate>
    </item>
    <item>
      <title>加权可能性间接模拟可靠性？</title>
      <link>https://stats.stackexchange.com/questions/659550/weighted-likelihood-to-indirectly-model-reliability</link>
      <description><![CDATA[对于纵向回归问题，我可能认为，与信息较少的受试者相比，我观察到的具有更多观察结果的受试者的数据更可靠（情况可能并非总是如此，但假设如此）。这里，可以使用回归权重，以便在模型中考虑到这种感知可靠性吗？

这是针对$i^{th}$主题的基本纵向/随机效应模型：
$$y_{ij} = X_{ij}\beta + u_i + \epsilon_{ij}$$
$$u_i \sim N(0, \sigma^2_u)$$
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon)$$
我看到这种权重格式经常用于最小二乘回归（$n_i$ 是受试者 $i$ 的测量次数，$N$ 是受试者总数):
$$w_i = \frac{n_i}{\sum_{k=1}^N n_k}$$
最后，修改似然函数以包含权重（我不确定哪个更好 - 单个受试者级别权重或单个观察级别权重）：
$$L(\beta, \sigma^2_u, \sigma^2_\epsilon) = \prod_{i=1}^N f(y_i|\beta, \sigma^2_u, \sigma^2_\epsilon)^{w_i}$$
$$L(\beta, \sigma^2_u, \sigma^2_\epsilon) = \prod_{i=1}^N \prod_{j=1}^{n_i} f(y_{ij}|\beta, \sigma^2_u, \sigma^2_\epsilon)^{w_i}$$
从这个来看，似乎即使有了这些权重，这些权重似乎也不会影响方差。使用多层次建模/随机效应中采用的一般方法，也许可以将方差修改为（$I$ 是一个单位矩阵，而$J$ 是一个 1 的矩阵 - 这意味着单个受试者的方差取决于所有受试者的未加权方差加上基于该受试者测量次数的单个受试者的加权方差）。这样做，我们实际上在个体层面上将随机效应引入模型：
$$\epsilon_{ij} \sim N(0, \sigma^2_\epsilon / n_i)$$
$$Var(y_i) = \sigma^2_u J_{n_i} + (\sigma^2_\epsilon/n_i) I_{n_i}$$
$$Y_i \sim MVN(X_i\beta, V_i)$$
这现在使得可能性（更复杂 - 但最小二乘解可用于固定效应估计）：
$$f(y_i|\beta, \sigma^2_u, \sigma^2_\epsilon) = (2\pi)^{-n_i/2}|V_i|^{-1/2}\exp\left(-\frac{1}{2}(y_i - X_i\beta)^T V_i^{-1}(y_i - X_i\beta)\right)$$
$$\ell(\beta, \sigma^2_u, \sigma^2_\epsilon) = -\frac{1}{2}\sum_{i=1}^N \left[n_i\log(2\pi) + \log|V_i| + (y_i - X_i\beta)^T V_i^{-1}(y_i - X_i\beta)\right]$$
$$\hat{\beta} = \left(\sum_{i=1}^N X_i^T V_i^{-1} X_i\right)^{-1} \left(\sum_{i=1}^N X_i^T V_i^{-1} y_i\right)$$
我可以看到，在这个最终设置中，固定效应估计和方差都受到每个受试者可用的观察次数的影响。 （下一部分超出了我的理解范围，但我听说随机效应是使用 RMLE 估计的）

假设数学是正确的，在纵向研究中，基于每个受试者可用的测量次数的权重可以用来隐式地解释可靠性？
结束语：最后，看起来只需使用基本的多级建模方法就可以解决所有问题，并根据每个受试者的观察次数间接地考虑他们的贡献……]]></description>
      <guid>https://stats.stackexchange.com/questions/659550/weighted-likelihood-to-indirectly-model-reliability</guid>
      <pubDate>Sun, 05 Jan 2025 03:44:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么这么多问题是线性的以及如何解决非线性问题？</title>
      <link>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</link>
      <description><![CDATA[我这学期选修了一门深度学习 Python 课，我们正在学习线性代数。
上一节课，我们从头开始“发明”了梯度下降的线性回归（之前在课上做过最小二乘），我们讨论了定义假设、损失函数、成本函数等。
为什么许多问题可以看作是线性的，而“只是试图找到方程 Ax = b 的解”？
可以通过最小二乘或训练神经网络等方法来实现这一点。
在现实世界中，大多数问题都不是线性的。
由于线性代数仅适用于线性函数，那么如何解决这些问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659536/why-are-so-many-problems-linear-and-how-would-one-solve-nonlinear-problems</guid>
      <pubDate>Sat, 04 Jan 2025 19:41:00 GMT</pubDate>
    </item>
    <item>
      <title>Mann-Whitney-U 和 Mood 的独立样本中值检验是分析两个文化样本差异的正确方法吗？</title>
      <link>https://stats.stackexchange.com/questions/659534/is-a-mann-whitney-u-and-moods-median-test-for-independent-samples-the-correct-m</link>
      <description><![CDATA[第一个问题，如果太长，我深表歉意。我设计了一个双语问卷，用他们的母语对两个不同国籍的人进行调查，试图在一个通用的文化尺度上区分他们的态度水平。由于时间限制，无法进行预测试，语言 1 的 C.-α = 0,546（n = 112），语言 2 的 C.-α = 0,774（n = 74），语言 1 的总体辨别能力很差，但语言 2 的辨别能力很好。语言 1 产生了一个非参数样本，语言 2 产生了一个参数样本，通过对独立样本进行 Kolmogorov-Smirnov 检验进行测试。对改进的问卷进行了双重检查（每种语言删除了不同的项目），结果仍然相同。
我通过应用 Mann-Whitney-U 测试了均值差异的假设，通过应用情绪中位数检验测试了中位数的假设。两者都给出了被拒绝的零假设，因此结果很重要。这是使用混合参数和非参数独立样本进行测试的正确方法吗？
考虑到语言 1 版问卷的低 cronbach&#39;s alpha 和判别力，有没有办法计算错误发现的可能性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659534/is-a-mann-whitney-u-and-moods-median-test-for-independent-samples-the-correct-m</guid>
      <pubDate>Sat, 04 Jan 2025 17:49:50 GMT</pubDate>
    </item>
    <item>
      <title>统计学中帽子符号的混淆</title>
      <link>https://stats.stackexchange.com/questions/659390/confusion-on-the-hat-symbol-in-statistics</link>
      <description><![CDATA[学习统计学中的不同符号让我感到困惑。
在基本的线性回归中，我们写：
$$Y = \beta_0 + \beta_1 X + \epsilon$$
$$\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 X$$
$$\hat{\epsilon} = y - \hat{y}$$
这是因为误差仅存在于理论模型中，上限位于估计值之上，而残差（$\hat{\epsilon}$）取决于估计量，因此它有一个上限。
除此之外，我越来越困惑。
例如，关于 $Y$ 的边际分布，这两个陈述是否正确？

$$Y \sim N(X^T \beta, \sigma^2) \implies E(Y) = X^T \beta$$
$$Y \sim N(X^T \hat{\beta}, \hat{\sigma}^2) \implies E(Y) = X^T \beta$$

关于 $Y$ 的条件分布，这两个陈述是否正确？

$$E(Y \mid X) = \beta_0 + \beta_1 X$$
$$E(Y \mid X, \beta, \sigma^2) = \beta_0 + \beta_1 X$$
$$E(Y \mid X, \hat{\beta}, \hat{\sigma}^2) = \beta_0 + \beta_1 X$$

一般来说，我知道一旦你对左边的某个东西取期望，右边就会失去帽子。但我想知道，也许这些陈述中的一些实际上是等价的，只是陈述 1)（在条件和边际陈述中）是简写符号，而其他陈述实际上等同于 1)？
如能帮助澄清有关帽子符号和期望的困惑，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659390/confusion-on-the-hat-symbol-in-statistics</guid>
      <pubDate>Tue, 31 Dec 2024 02:39:46 GMT</pubDate>
    </item>
    <item>
      <title>在处理现实世界数据时，统计推断中关于总体分布存在的错误假设的后果</title>
      <link>https://stats.stackexchange.com/questions/659382/consequences-of-the-false-assumption-about-the-existence-of-a-population-distrib</link>
      <description><![CDATA[统计推断方法，例如统计假设检验，假设观察到的数据是从总体分布中抽样的。对于现实世界的数据，这是一个很大的简化。例如，imdb.com 上特定电影的评分不是从任何分布中抽样的。相反，它们是多种因素的组合，如演员阵容、演技、声音、观众的情绪等。
据我所知，只要我们能够评估这些假设引入了什么错误，对数据做出错误的假设是完全可以的。例如，我们在机器学习中有一个朴素贝叶斯模型，它假设在给定目标类的情况下，特征是条件独立的。对于许多数据集来说，这是错误的。但我们有一个测试集，即整个数据集的一部分，它使我们能够评估建立在错误假设基础上的这种模型的错误。
在统计假设检验的情况下，我们没有提供评估此类错误的方法。据我所知，当测试集缺失时，统计推断方法的任何结果（例如拒绝零假设）都会受到未知大小的误差的影响，从而使结果完全无用。
我大胆地说统计假设检验对现实世界数据无用，对吗？还是我在这里遗漏了什么？
--编辑--
由于这个问题缺乏明确的目标，并且包含一个偷来的概念谬误，我对其进行了改进，并将其移至此处，以便清晰起见。]]></description>
      <guid>https://stats.stackexchange.com/questions/659382/consequences-of-the-false-assumption-about-the-existence-of-a-population-distrib</guid>
      <pubDate>Mon, 30 Dec 2024 21:21:18 GMT</pubDate>
    </item>
    </channel>
</rss>