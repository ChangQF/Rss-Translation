<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 06 Sep 2024 09:16:55 GMT</lastBuildDate>
    <item>
      <title>（高斯） copula 模拟中给定相关参数与经验相关之间的差距</title>
      <link>https://stats.stackexchange.com/questions/653956/gap-between-the-given-correlation-parameter-and-the-empirical-correlation-in-ga</link>
      <description><![CDATA[现在我尝试用我希望的相关矩阵作为初始参数来模拟正常的 copula。我发现经验相关性通常低于输入的初始参数。
为了简化问题，我们考虑一个初始参数为 0.5 的双变量高斯 copula。
我在 R 中创建了以下代码作为说明：
converg_corr_copula &lt;- function(num_sim, n, param){

result &lt;- data.frame(matrix(ncol=2))[-1,]
names(result) &lt;- c(&quot;seed&quot;,&quot;corr_emp&quot;)

for (i in 1:n){

set.seed(i)
cp_gaus &lt;- normalCopula(param = param, dim = 2,dispstr = &quot;un&quot;)
copula_sim &lt;- rCopula(n = num_sim, copula = cp_gaus) %&gt;% as.data.frame()
result[nrow(result)+1,] &lt;- c(i,cor(copula_sim)[2])

}

return(c(mean(result$corr_emp),sd(result$corr_emp)))
}

lapply(c(1e2,1e3,1e4,1e5,1e6,1e7), converg_corr_copula, n = 50, param = 0.5)


从结果中，我们可以看到经验值以 0.48 为中心，标准差随着模拟次数的增加而减小。
你们当中有人知道为什么会这样吗？提前谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653956/gap-between-the-given-correlation-parameter-and-the-empirical-correlation-in-ga</guid>
      <pubDate>Fri, 06 Sep 2024 09:16:25 GMT</pubDate>
    </item>
    <item>
      <title>通过重复测量估计比例</title>
      <link>https://stats.stackexchange.com/questions/653954/estimating-a-proportion-from-repeated-measurements</link>
      <description><![CDATA[我正在对一种罕见皮肤病的病例系列进行简单的描述性研究。目的是描述该群体中的维生素 A 缺乏症。我们有 12 名患者（8 名男性，4 名女性），总共进行了 101 次维生素 A 测量（平均每位患者就诊 8.4 次）。有一个定义维生素 A 缺乏症的临床阈值，我们将测量结果二分以报告维生素 A 缺乏症的患病率。
总共 21/101 次测量（20.8%）显示维生素 A 缺乏症。围绕该比例计算一个简单的 95% 置信区间假设测量结果是独立的，这并不完全正确。我的问题是，我如何调整患者内的重复测量？如果我没记错的话，这只会影响置信区间，而不会影响估计的比例，对吗？
我正在考虑一个具有二分结果的 GEE 模型（例如 R 中的 geeglm），它也可以调整患者的性别。这是否合适？我如何从这样的模型中获得总体比例和调整后的置信区间？
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653954/estimating-a-proportion-from-repeated-measurements</guid>
      <pubDate>Fri, 06 Sep 2024 07:14:57 GMT</pubDate>
    </item>
    <item>
      <title>平均随访时间</title>
      <link>https://stats.stackexchange.com/questions/653952/mean-follow-up-time</link>
      <description><![CDATA[*我正在使用 R 中的 pmsampsize 函数来计算 cox 比例风险模型（试点研究）的样本量。我需要输入 meanfup 的值（type=&quot;s&quot; 选项）指定模型开发数据集中个人预期的平均（均值）随访时间。但我仍然不确定如何计算平均（均值）随访时间。任何建议都将不胜感激。
例如：假设包括 T0、T3、T6、T9、T12、....、T24（月）患者的信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/653952/mean-follow-up-time</guid>
      <pubDate>Fri, 06 Sep 2024 06:55:48 GMT</pubDate>
    </item>
    <item>
      <title>如何解释两个模型在后验预测检验中的模型拟合度（这两个模型都捕获了 1sigma 中的观测值）？</title>
      <link>https://stats.stackexchange.com/questions/653951/how-to-interpret-model-fit-in-posterior-predictive-checks-between-two-models-tha</link>
      <description><![CDATA[我有两个模型旨在解释单个观察到的测量值$x_{obs}$：
具有 26 个参数的简单模型$f_1(\theta)$。
具有 31 个参数的复杂模型$f_2(\theta)$。
这两个模型都被认为代表了观察背后的数据生成过程，这意味着它们定义了可能性。两者使用的噪声模型是相同的。我使用贝叶斯推理，特别是基于模拟的推理 (SBI)，为每个模型获得后验分布 $p(\theta|x_{\rm obs})$，在两种情况下均使用多变量均匀先验 $p(\theta)$。我的目标是确定哪种模型更适合观察到的测量值。
在执行贝叶斯推理后，我从后验分布中抽样，对两种模型进行后验预测检查 (PPC)。以下是结果摘要：
两种模型的后验预测分布 (PPD) 都在其 1-sigma 间隔内捕获观察到的测量值。
但是，与复杂模型的 PPD 相比，简单模型的 PPD 分布范围要窄得多。
复杂模型的 PPD 还包括 2 到 3 西格玛区域内的一些非物理值，这可能是由于其先验所致。
接下来，我对这两个模型进行了贝叶斯因子 (BF) 比较，结果表明，这两个假设的偏好程度相同（即，贝叶斯因子并不强烈偏向任何一个模型）。
此外，全局覆盖图表明，两个后验分布都经过了良好的校准，这意味着没有过度拟合或欠拟合的证据。
我的解释问题：
场景 A：这是否意味着两个模型与观察结果的一致性相同（因为它们的 PPD 适合数据），但由于贝叶斯因子对两者都不利，因此应该优先选择更简单的模型？
场景 B：或者，复杂模型的 PPD 分布范围较大（以及包含非物理值）是否表明复杂模型的后验应该被认为不太合适，即使贝叶斯因子没有显示出对更简单模型的强烈偏好？
提前感谢您的反馈！]]></description>
      <guid>https://stats.stackexchange.com/questions/653951/how-to-interpret-model-fit-in-posterior-predictive-checks-between-two-models-tha</guid>
      <pubDate>Fri, 06 Sep 2024 06:28:56 GMT</pubDate>
    </item>
    <item>
      <title>什么时候直线不再足够好地近似指数曲线？</title>
      <link>https://stats.stackexchange.com/questions/653948/when-does-a-line-no-longer-approximate-an-exponential-curve-sufficiently-well</link>
      <description><![CDATA[我有一个有点复杂的问题，作为一个没有数据分析或强大统计科学背景的人，我正在寻找建议/推荐，以找到最好的数据分析“工具”或方法来完成我需要的工作。
为了便于理解，我正在分析极光中一种随时间呈指数级增长的现象。我正在手动选择事件并目测初始和最终时间来提取我的亮度值（此处为𝑦轴）。我正在使用地面成像仪并从平均像素数中提取亮度值。我有许多事件，目前有 13 个，我将它们绘制在下面。
我的目标是找到亮度的增长率，这对于找出导致这种特定类型极光的确切等离子体不稳定性非常重要。为此，我只需根据等离子体不稳定性线性相位计算增长率。换句话说，当绘制对数线性时，您只会看到线性相位中的一条直线，而当该线开始偏离时，这将表示非线性相位，而不再是相同的极光现象。非线性阶段可能是极光的快速变亮，也可能是极光开始消退。
我现在设置的代码是将所有事件的所有曲线放在对数线性图中，并在两个点之后为每个点计算最佳拟合线，然后在最佳拟合线超出公差（即低于$r^2$=0.85）后，下一个点被标记为非线性。
这听起来很棒，但在某些事件中，亮度在前几个时间步骤中会下降，因为我选择的极光图像中的像素在事件发生之前会变得稍微暗一些（即我在选择开始时间（$t_0$事件时很马虎）。
有没有一种我可以使用箱车平均法的方法以确保不会发生这种情况，还是应该对数据应用高斯滤波器（尽管时间序列中没有很多数据点），然后对这些平滑点进行分析？
我还将对所有事件进行背景减法，以便将它们标准化为 0.1 作为背景值（以时间序列中最小的亮度作为背景），使图看起来更美观。
所有事件均以线性-线性方式绘制。亮度与时间。线性阶段为蓝色，绿色虚线显示过渡，然后红线为非线性增长。

]]></description>
      <guid>https://stats.stackexchange.com/questions/653948/when-does-a-line-no-longer-approximate-an-exponential-curve-sufficiently-well</guid>
      <pubDate>Fri, 06 Sep 2024 02:51:42 GMT</pubDate>
    </item>
    <item>
      <title>具有时间序列和泄漏的 PCA</title>
      <link>https://stats.stackexchange.com/questions/653947/pca-with-time-series-and-leakage</link>
      <description><![CDATA[我有以下代码，用于时间序列数据的带有 PCA 和移动窗口的简单统计因子模型：
def moving_window_PCA(X):
tscv = TimeSeriesSplit(n_splits=10)
error_start = np.inf
prediction = None
testset = None
for train_index, test_index in tscv.split(X):

train, test = X.iloc[train_index], X.iloc[test_index]

pca = PCA(n_components = 10)
X_fitted = pca.fit_transform(train)

linreg = LinearRegression()
linreg.fit(X_fitted, train)

pred = pca.transform(test)
pred = linreg.predict(pred)
error = mean_squared_error(test, pred)

if error &lt;= error_start:
prediction = pred
testset = test
return prediction, testset

它与我的数据非常吻合，我知道它一定存在泄漏。但我看不出代码中泄漏发生的位置。我是否缺少有关 PCA 的基本知识？我正尝试将模型拟合到 10 个时间序列。即使我减少 n_components 并使用 Ridge 而不是 LinearRegression，我仍然得到好得令人难以置信的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/653947/pca-with-time-series-and-leakage</guid>
      <pubDate>Fri, 06 Sep 2024 02:08:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么置信度 > 50% 还不是“足够好”？</title>
      <link>https://stats.stackexchange.com/questions/653946/why-isnt-a-confidence-level-of-anything-50-good-enough</link>
      <description><![CDATA[我上过研究生水平的统计学课程，所以问这个问题感觉自己很蠢，但我不明白 95% 置信度背后的含义。（请对我好一点。）
我目前正在对两张图片进行 A/B 测试，用于营销。测试将运行并收集数据，直到它能够在 95% 的置信度下做出决定。
当前置信率为 76.55%，其中 A 的点击率为 2.5%，B 的点击率为 4.55%。
由于 A 和 B 在 50% 的置信度下大致相等（一个设计没有显示出比另一个更好），为什么我要等到 95% 的置信度？在 50% 的置信度下，我选择哪种设计并不重要，而在 76.55% 的置信度下，我已经显示 B 的表现优于 A。
我想我不明白为什么我现在不能做出决定。如果是在制药情况下进行测试，比如生死攸关场景中的药物，我觉得我应该等待 95%，但对于像图像选择这样低风险的事情...]]></description>
      <guid>https://stats.stackexchange.com/questions/653946/why-isnt-a-confidence-level-of-anything-50-good-enough</guid>
      <pubDate>Fri, 06 Sep 2024 01:33:52 GMT</pubDate>
    </item>
    <item>
      <title>如何计算多个 MCMC 链的积分自相关时间 (IAT)？</title>
      <link>https://stats.stackexchange.com/questions/653944/how-to-calculate-integrated-autocorrelation-time-iat-for-multiple-mcmc-chains</link>
      <description><![CDATA[我正在并行运行多个马尔可夫链蒙特卡罗 (MCMC) 链，并且我想计算整体样本的积分自相关时间 (IAT)。虽然我理解如何基于自相关函数 $ \rho(t) $ 计算单个链的 IAT，但我不确定如何处理多个链。
以下是我不清楚的一些具体要点：

我是否应该分别计算每个链的自相关函数 $\rho(t)$，然后对各个链的 IAT 取平均值？
如果链未达到相同的平稳分布（例如，如果 R-hat 统计量远离 1），推荐的方法是什么？

任何参考资料或示例实现（使用 Python 或 R）也会有所帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/653944/how-to-calculate-integrated-autocorrelation-time-iat-for-multiple-mcmc-chains</guid>
      <pubDate>Fri, 06 Sep 2024 01:02:25 GMT</pubDate>
    </item>
    <item>
      <title>风力发电 PDF</title>
      <link>https://stats.stackexchange.com/questions/653943/wind-generation-pdf</link>
      <description><![CDATA[我有实时风力发电和风力发电预测的历史。利用这些信息，是否可以得出方差或标准差等指标？
我不认为风力发电呈正态分布，但我怀疑它可能呈对数正态分布。有没有办法计算统计数据，显示根据历史数据预测的误差可能有多大，或者实时发电量与预测发电量之间的偏差有多大？]]></description>
      <guid>https://stats.stackexchange.com/questions/653943/wind-generation-pdf</guid>
      <pubDate>Fri, 06 Sep 2024 00:17:04 GMT</pubDate>
    </item>
    <item>
      <title>基于 eviews 的货币政策 ARDL 模型研究</title>
      <link>https://stats.stackexchange.com/questions/653931/ardl-model-on-monetary-policy-study-on-eviews</link>
      <description><![CDATA[我实际上正在撰写关于货币政策传导的硕士论文，我对我的 ARDL 方法的结果表示怀疑。我有 4 个模型（1 个基准和 3 个替代方案）
有人可以看一下吗？我想知道结果是否正常。此外，我们如何解释 ARDL 上的边界测试？
我的导师说没问题，但他实际上并没有阅读它。]]></description>
      <guid>https://stats.stackexchange.com/questions/653931/ardl-model-on-monetary-policy-study-on-eviews</guid>
      <pubDate>Thu, 05 Sep 2024 18:45:28 GMT</pubDate>
    </item>
    <item>
      <title>将因子变量纳入 GAM 时产生的矛盾解释</title>
      <link>https://stats.stackexchange.com/questions/653909/contradicting-interpretations-when-including-factor-variables-into-gam</link>
      <description><![CDATA[我建立的模型是这样的：
bam(n ~ s(age, k = 10, m = 2) + 
s(hh_size, k = 7, m = 2) +
s(age, by = pp, k = 10, bs = &quot;tp&quot;, m = 1) +
s(hh_size, by = pp, k = 7, bs = &quot;tp&quot;, m = 1) +
(employment_2cat + weekend + region + marital_2cat + education_2cat)* period * place + 
s(token, k = 864, bs = &quot;re&quot;) + 
s(Bundesland, k = 16, bs = &quot;re&quot;), data = halle_data, family = nb(), method = &quot;fREML&quot;,
drop.unused.levels = FALSE)
# pp 是时期和地点之间的相互作用。

拟合模型后，使用 summary() 获得参数系数。应用 emmeans()、pairs() 和 contrast() 来获取时期和地点对每个因子变量的影响。但结果似乎不对。

从模型的summary()结果来看，可以解释为“未就业”与“就业”相比，联系人数的对数增加25.5%。但从pairs()的结果来看，就业似乎与更高级别的联系有关。对于周末变量，也出现了这种相互矛盾的解释。

从 summary() 的结果来看，周末的联系人数量比工作日多。但从pairs()的结果来看，工作日发生的接触比周末多。
------- 更新：summary(model)中的年龄和可视化 -------


这部分是关于模型中数值变量的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/653909/contradicting-interpretations-when-including-factor-variables-into-gam</guid>
      <pubDate>Thu, 05 Sep 2024 12:19:33 GMT</pubDate>
    </item>
    <item>
      <title>如何解释统计上不显著的估计并排除较大的影响？</title>
      <link>https://stats.stackexchange.com/questions/653890/how-to-interpret-statistically-non-significant-estimates-and-rule-out-large-effe</link>
      <description><![CDATA[我正在做回归分析，并获得了一个统计上不显著的点估计。从经济角度来看，不显著的结果在我的语境中是有意义的，但我想确保这一发现不是由于缺乏效力。相反，我想确认这种影响确实接近于零，而不仅仅是统计上不显著。
我的目标是做出这样的陈述：“...从置信区间来看，我们可以排除大于 1-1.4 个月的预期寿命增加的影响”，正如 Meghir、Palme 和 Simeonova (2018) 所做的那样，或者“这些影响通常可以限制在零附近的一个狭窄区间内”，正如 Cesarini 等人 (2016) 所提到的那样。
根据我的点估计及其置信区间，我如何自信地解释结果以做出类似的陈述？具体来说，我该如何量化估计的精度以排除较大的影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/653890/how-to-interpret-statistically-non-significant-estimates-and-rule-out-large-effe</guid>
      <pubDate>Thu, 05 Sep 2024 07:29:33 GMT</pubDate>
    </item>
    <item>
      <title>simr 模拟是否需要响应变量/因变量数据？</title>
      <link>https://stats.stackexchange.com/questions/653886/is-response-variable-dependent-variable-data-required-for-simr-simulation</link>
      <description><![CDATA[我正在使用 simr 进行线性混合效应模型的功效分析。我见过的大多数示例都使用来自试点研究的数据进行模拟，但我还没有任何数据。我的问题是：

使用 simr 进行功效分析时，因变量/响应变量的数据是否必要？
我尝试使用没有因变量的数据集运行模拟，似乎有效。这种方法有效吗？
如果因变量/响应变量的数据确实是必要的，我应该生成随机值吗？如果是这样，我应该如何处理？

以下是我当前的代码，以防有帮助。
library(dplyr)
library(tidyr)
library(simr)

# 设置参数
n_subjects &lt;- 100
n_events &lt;- 24

# 检索架构的平衡 &amp;平衡频率的条件
counterbal &lt;- read.csv(&quot;counterbalance.csv&quot;)
conditions &lt;- expand.grid(
distance = c(&quot;close&quot;, &quot;far&quot;),
direction = c(&quot;antecedent&quot;, &quot;consequence&quot;)
)

# 随机将平衡组分配给参与者
get_subj_data &lt;- function(subj_id) {
temp &lt;- data.frame(subject = rep(subj_id, n_events))
temp$event &lt;- 1:n_events
counter &lt;- sample(1:4, 1)
temp$conditions &lt;- counterbal[[paste0(&quot;Counter&quot;, counter)]]
temp$distance &lt;- conditions$distance[temp$conditions]
temp$direction &lt;- conditions$direction[temp$conditions]
return(temp)
}

df &lt;- data.frame()

for (i in 1:n_subjects) {
subj_data &lt;- get_subj_data(i)
df &lt;- rbind(df, subj_data)
}

# H1 - 主效应 T(consq) &gt; T(ante)
# 此处指定效应大小！不是系数！
fixed &lt;- c(0.5, 0.5, 0.5, 0.5)
rand &lt;- list(0.2, 0.1) # 不确定这是什么
res &lt;- 2

model &lt;- makeLmer(latency ~ direction * distance + (1|subject) + (1|event),
fixef=fixed, VarCorr=rand, sigma=res, data=df)
model

# 方向模拟？
sim_direction &lt;- powerSim(model, nsim=100, test = fcompare(~ distance))
sim_direction

这给了我以下输出：
&gt; sim_direction
模型比较的功效，（95% 置信区间）：
100.0% (96.38, 100.0)

测试：似然比
与 ~distance + [re] 的比较

基于 100 次模拟，（0 个警告，0 个错误）
alpha = 0.05，nrow = 2400

已用时间：0 小时 0 分 12 秒
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/653886/is-response-variable-dependent-variable-data-required-for-simr-simulation</guid>
      <pubDate>Thu, 05 Sep 2024 03:38:48 GMT</pubDate>
    </item>
    <item>
      <title>比较敏感性和特异性——保持一个稳定以便与另一个进行比较？</title>
      <link>https://stats.stackexchange.com/questions/653882/comparison-sensitivity-and-specificity-hold-one-stable-for-comparison-of-the-o</link>
      <description><![CDATA[给定两个二元诊断测试 T1 和 T2，我想比较这两个测试在提供给一组受试者时的敏感性和特异性。每个受试者都会接受两个测试，因此我对敏感性或特异性进行了配对比较。McNemar 测试似乎最适合这种情况。
有人建议，要比较两个测试之间的敏感性，我需要找到每个测试提供相同特异性值的分数截止值，然后我可以将敏感性与 McNemar 测试进行比较。也有人提出相反的建议 - 要比较特异性，敏感性必须相同。
鉴于这是对两个不同测试的验证，每个测试都有一个特定的分数截止值，该值是在测试开发期间确定的。似乎应该比较在这些预定截止值下观察到的敏感性和特异性，而不是调整截止值以使敏感性或特异性相同，然后比较另一个。
我的解释正确吗？在我看来，应该通过每个测试在预定截止值下观察到的敏感性和特异性来进行这种比较。还是我误解了？]]></description>
      <guid>https://stats.stackexchange.com/questions/653882/comparison-sensitivity-and-specificity-hold-one-stable-for-comparison-of-the-o</guid>
      <pubDate>Thu, 05 Sep 2024 02:11:04 GMT</pubDate>
    </item>
    <item>
      <title>在轮盘赌中，出现长红色序列的频率是否低于出现短红色序列的频率？</title>
      <link>https://stats.stackexchange.com/questions/653816/in-roulette-is-the-frequency-of-getting-long-sequences-of-reds-lower-than-that</link>
      <description><![CDATA[在一场无限期的轮盘游戏中，与连续 10 次出现红色相比，连续 100 次出现红色的概率（可能每百万次旋转才出现一次）要小得多，这样说对吗？
如果出现一长串红色的概率会随着序列变长而降低，那么为什么认为在一长串红色之后出现黑色的可能性更大会被视为赌徒谬误？如果 101 次出现红色的序列比 100 次出现红色的序列出现的可能性更小，那么为什么认为当前序列更有可能是 100 次出现红色并因此下一轮旋转将是黑色是错误的？
编辑：
我知道这些都是独立事件，概率没有记忆，因此必须保持不变。我在问，这一事实如何与较长序列出现频率较低的说法相一致。
此外，我并不是说根据大数定律，它应该平衡，因此下一次旋转更有可能是黑色。我是说，我们更有可能处于 100 个红色的序列而不是 101 个红色的序列，因为它发生的频率更高，并且如果更有可能假设现在是较短的序列而不是较长的序列，那么从逻辑上讲，下一次旋转更有可能是黑色不是吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653816/in-roulette-is-the-frequency-of-getting-long-sequences-of-reds-lower-than-that</guid>
      <pubDate>Tue, 03 Sep 2024 23:44:05 GMT</pubDate>
    </item>
    </channel>
</rss>