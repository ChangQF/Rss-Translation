<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 26 May 2024 01:06:56 GMT</lastBuildDate>
    <item>
      <title>工具变量是否需要工具和治疗之间的独立性？</title>
      <link>https://stats.stackexchange.com/questions/647993/does-an-instrumental-variable-require-independence-between-the-instrument-and-tr</link>
      <description><![CDATA[如果以下条件成立，则工具变量 Z 是 T（治疗）的合法工具：

Z 对 Y 具有完全由 T 介导的因果效应（即 Z 对 Y 没有直接影响，因果关系流必须至少通过 T）
Z 没有到 Y 的后门路径。
单调性（工具中的值越高，治疗被采用的值也就越高）
第一阶段确实存在（Z 和 T 之间存在非零相关性）。

但是，如果我们有以下 DAG，会发生什么？

C 是治疗和工具之间的混杂变量。Z 是否仍然是 T 的合法工具？我以为答案是否定的，但根据 https://dagitty.net/dags.html#
...C 和 Z 都是 T 的合法工具。我可以看到 C 是合法的工具，因为所有因果路径都通过 T（直接或由 Z 介导）。但是，如果不先对 C 进行调节，Z 怎么可能仍然是 T 的工具呢？我可以通过 C 跳到 T。大多数来源似乎表明 T 和 Z 必须是 d 分离的，但我只是想验证这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/647993/does-an-instrumental-variable-require-independence-between-the-instrument-and-tr</guid>
      <pubDate>Sun, 26 May 2024 00:19:40 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分析理论的数学导论</title>
      <link>https://stats.stackexchange.com/questions/647992/mathematical-introduction-to-theory-of-time-series-analysis</link>
      <description><![CDATA[假设读者具有很强的随机微积分背景（包括并超越连续时间随机过程，如鞅和马尔可夫链等、Levy 过程的构造、Ito 积分的构造、随机微分方程的弱解...）统计理论（包括但不限于统计决策理论、线性模型和广义线性模型理论、假设检验理论以及大量著名定理的证明......）。时间序列分析理论的数学入门有哪些参考资料？]]></description>
      <guid>https://stats.stackexchange.com/questions/647992/mathematical-introduction-to-theory-of-time-series-analysis</guid>
      <pubDate>Sat, 25 May 2024 23:01:58 GMT</pubDate>
    </item>
    <item>
      <title>高原分布---中心周围的分布非常平坦？</title>
      <link>https://stats.stackexchange.com/questions/647990/altiplano-distribution-distributions-very-flat-around-the-center</link>
      <description><![CDATA[（来自Facebook帖子，参考在最后）
“大家都知道”函数 $x \mapsto \exp\left(-1/x^2 \right)$ 是无限可微的，但不是（实）解析的，因为它的所有零处的导数为 0，因此其麦克劳林级数同样为零。该函数在原点处非常平坦。如果我们水平翻转它，我们会得到一个密度函数，我将其称为 Altiplano 分布：
$$
f(x)= \frac{1 - e^{-1/x^2}}{2\sqrt{\pi}}
$$
这可以以通常的方式扩展到位置规模系列：

这个分布没有期望，事实上它的尾部接近柯西尾部。事实上，洛朗级数展开（无穷大）表明尾部的行为（一阶）为 $x^{-2}$。
其他有趣的围绕中心分布非常平坦的例子？之前提到过这个特定的发行版？
此示例参考
Dr. 的 Facebook 帖子墨西哥国立自治大学的阿图罗·埃尔德利。拥有 Facebook 帐户的人可能可以找到它。]]></description>
      <guid>https://stats.stackexchange.com/questions/647990/altiplano-distribution-distributions-very-flat-around-the-center</guid>
      <pubDate>Sat, 25 May 2024 22:14:10 GMT</pubDate>
    </item>
    <item>
      <title>蒙特卡洛不确定性传播</title>
      <link>https://stats.stackexchange.com/questions/647989/monte-carlo-uncertainty-propagation</link>
      <description><![CDATA[我熟悉测量不确定度表达指南（GUM）。该方法允许人们计算非统计来源的相关性。一个很好的例子是使用相同的仪器（即卡尺）测量立方体的体积。当卡尺分别持续低于或高于测量长度、宽度和高度时，系统效应将相互关联。
但是如何使用蒙特卡罗方法做到这一点呢？我一直在摆弄系动词，所以我对它们很熟悉。]]></description>
      <guid>https://stats.stackexchange.com/questions/647989/monte-carlo-uncertainty-propagation</guid>
      <pubDate>Sat, 25 May 2024 21:51:22 GMT</pubDate>
    </item>
    <item>
      <title>Metropolis-Hastings 算法是否存在停止标准？</title>
      <link>https://stats.stackexchange.com/questions/647988/does-a-stopping-criterion-exist-for-the-metropolis-hastings-algorithm</link>
      <description><![CDATA[我计算了用 Metropolis Hastings 估计的 24 个参数的总均方根误差，我运行了该算法 100.000 次迭代，并且随着链向前，它达到了全局最小值，但随着它的继续，更多的样本到达了，所以RMSE 开始增加。

所以我的问题是 Metropolis-Hastings 算法是否存在停止标准？所以我可以在 25000 次迭代时停止？
我使用粒子边缘都会黑斯廷斯来构建马尔可夫链并使用粒子滤波器来计算可能性。]]></description>
      <guid>https://stats.stackexchange.com/questions/647988/does-a-stopping-criterion-exist-for-the-metropolis-hastings-algorithm</guid>
      <pubDate>Sat, 25 May 2024 21:13:01 GMT</pubDate>
    </item>
    <item>
      <title>确定强制选择绩效有效性测试的机会水平</title>
      <link>https://stats.stackexchange.com/questions/647986/determining-chance-level-for-forced-choice-performance-validity-tests</link>
      <description><![CDATA[心理学家，尤其是神经心理学家，使用表现有效性测试 (PVT) 来检测可能故意在能力测试（例如记忆测试）中表现不佳的个人，因为诊断出的认知缺陷可能会导致期望的结果（从考生的角度来看），例如残疾赔偿金。
假设您有一个包含 60 项的强制选择 PVT。无精神疾病的人的中位错误分数为 1，而患有严重精神障碍（例如精神分裂症）的人的中位错误分数为 5。根据交叉验证的研究，指定 9 或更高的分数来识别掩饰，即可能是假装。当然，心理学家不应仅根据一项 PVT 分数就得出此人装病的结论。
但是，如果错误分数如此之高，以至于偶然获得分数的几率非常低怎么办？换句话说，这个人必须非常努力才能反复给出错误的答案。
示例：申请残疾福利的受试者的错误分数为 39。
仅通过掷硬币，在我们假设的 60 项强制选择 PVT 中，您产生 39 或更高错误分数的几率有多大？]]></description>
      <guid>https://stats.stackexchange.com/questions/647986/determining-chance-level-for-forced-choice-performance-validity-tests</guid>
      <pubDate>Sat, 25 May 2024 20:52:48 GMT</pubDate>
    </item>
    <item>
      <title>如何修复 Lin (1989) 近似高斯 CDF 中的错误？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647982/how-to-fix-errors-in-lins-1989-approximation-to-the-gaussian-cdf</link>
      <description><![CDATA[我的 python 代码不适用于高斯 CDF 的 Lin (1989) 近似（如国际科学与工程研究杂志，6(4)，2015 年 4 月 ISSN 2229-5518，近似标准正态分布中所述）分布函数（Ramu Yerukala 和 Naveen Kumar Boiroju）
def lin_phi(x, mu=0, sigma=1):
    z = (x - mu) / 西格玛
    如果 z &gt;= 0：
        返回 1 - 0.5 * math.exp(-0.72 * z - 0.42 * z * z)
    别的：
        返回 0.5 * 数学表达式(0.72 * 绝对值(z) + 0.42 * z * z)

当我运行它时，低于平均值的结果是错误的（太大）：
对于范围 (20) 内的 x：
    print(f&quot;x = {x-10:3} cdf = {round(lin_phi(x-10, mu=0,sigma=3),3)}&quot;)

x = -10 cdf = 586.117
x = -9 cdf = 189.967
x = -8 cdf = 67.594
x = -7 cdf = 26.404
x = -6 cdf = 11.323
x = -5 cdf = 5.331
x = -4 cdf = 2.755
x = -3 cdf = 1.563
x = -2 累积分布函数 = 0.974
x = -1 累积分布函数 = 0.666
x = 0 累积分布函数 = 0.5
x = 1 累积分布函数 = 0.625
x = 2 累积分布函数 = 0.743
x = 3 累积分布函数 = 0.84
x = 4 cdf = 0.909
x = 5 cdf = 0.953
x = 6 cdf = 0.978
x = 7 累积分布函数 = 0.991
x = 8 cdf = 0.996
x = 9 累积分布函数 = 0.999

我尝试了多种变体，但没有成功。
仅供参考：这是 mac/os 上的 Python 3.13。但我认为这与此无关。]]></description>
      <guid>https://stats.stackexchange.com/questions/647982/how-to-fix-errors-in-lins-1989-approximation-to-the-gaussian-cdf</guid>
      <pubDate>Sat, 25 May 2024 20:13:10 GMT</pubDate>
    </item>
    <item>
      <title>有人可以帮我用数学公式表达以下内容，并将其链接到参考材料吗？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647981/can-someone-please-help-me-formulate-the-following-mathematically-and-link-it-t</link>
      <description><![CDATA[如果有人能够“识别”以下所暗示的统计学中的既定观点，并帮助我以标准方式表述它，并为我研究这个确切的主题提供参考，我将不胜感激。
想象一下解决这个问题：
&lt;块引用&gt;
让我们假设，根据一些消息来源，美国黑人的平均预期寿命为 72.8 岁，白人的平均预期寿命为 76.4 岁。确定哪些现实因素导致了这种差异。

&lt;小时/&gt;
在我看来，解决这个问题的一个好方法是在制定实际模型之前制定一个理想模型。
通过理想模型，我的意思是，通过分析和逻辑思维，它似乎代表了情况的逻辑现实。
我所说的实用模型是指第二阶段的独立问题，即找到一种策略来可接受地接近构建理想的逻辑模型。
我个人认为这是一个很好的策略，因为理想的模型可以让您清楚地概念性地理解逻辑上正确的答案会是什么样子。在我们探索在实践层面上与理想模型的距离有多近之前，我们应该对此充满信心。
如果我们不这样做，我们就会冒着以临时方式工作的风险，在这种方式下，我们建立了一个模型，用于对世界做出新的推论，但我们没有理由解释为什么它在认识论上代表了世界。世界，而不是一个“随机”模型，其推论对世界做出了错误的判断。
&lt;小时/&gt;
下一个问题是“因果关系”的本质。我一直倾向于一种逻辑模型，其中“现实世界因果关系”相当于“逻辑蕴涵”。
例如，假设黑人的肾脏疾病发病率相对较高。
有必要建立一个本体论，以便逻辑地表达诸如“人体存在一种可界定的状态，称为‘患有肾脏疾病’；在任何特定时刻，平均而言，比白人更多的黑人‘患有肾脏疾病’。”
也许不可避免地要用到概率的概念。我认为如果概率总是可以从非概率事实计算出来那就太酷了 - 有点像拉普拉斯守护进程，如果世界模型足够详细，我们可以做出一系列推论，例如，“与人 P 相关的方面 X左肾的值为 V1。根据[在此插入物理定律]，人 P 的某些方面的属性 Y 在时间 t 将具有值 V2。”然后我们可以使用这些事实来计算一个事物的状态数量，以反映该事物的实例将继续具有该状态的“概率”。
理想的模型基本上是世界的形式逻辑模型。
&lt;小时/&gt;
一旦我们理解了理想模型，就应该更容易认识到需要了解哪些偶然事实，以便逻辑地计算我们世界中的其他一些偶然价值。例如，假设我们世界中的某个物理定律是固定的，因此必然是正确的。然而，存在一个可能的世界，其中黑人的平均预期寿命是71.3岁，另一个可能的世界是85岁，等等。为了计算我们这个世界的预期寿命，我们希望能看到哪些参数值该计算取决于使用我们理想模型的形式。
&lt;小时/&gt;
最后，我们开始思考如何实际获取这些数据。我们的逻辑模型旨在从全知的角度来代表世界。我们可能不会是无所不知的，因此我们必须评估给定的数据对我们的模型的各种值的支持程度。
最后，我们可以用一个代数公式，根据我们无法获得的某些数据值来明确预期寿命，而不是完美地计算预期寿命。对于我们确实获得的数据，我们可以将其代入这些变量进行计算。
&lt;小时/&gt;
但是，我们想向后执行上述操作。找出黑人与白人的预期寿命很容易。我们想要推断本体中的哪些因素会发挥作用，然后通过替换经验数据来更新模型，从而获得相关事物的值。通过这种方式，我们能够更接近地了解哪些偶然因素（例如社会压力水平、平均收入、医疗机构的治疗）与解释观察到的预期寿命差异更相关。
如果有我可以阅读的文本来查看此统计策略的示例，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/647981/can-someone-please-help-me-formulate-the-following-mathematically-and-link-it-t</guid>
      <pubDate>Sat, 25 May 2024 19:03:16 GMT</pubDate>
    </item>
    <item>
      <title>预测已知曲线的模拟数据</title>
      <link>https://stats.stackexchange.com/questions/647960/predicting-simulated-data-for-a-known-curve</link>
      <description><![CDATA[我在研究问题上遇到了障碍，确实需要利用您的专业知识。
我有一条通过推断已知拟合实验数据创建的预先存在的曲线。如下所示，x 轴是给予样品的热量，y 轴是热量与响应的响应概率。

我有另一个数据集，我必须估计其衰减函数。对于样品“i”，总热量定义为
$$
H_{i} = H_{0}\exp^{-kt} + H_{已知} \quad{(1)}
$$
其中 $H_{0}$、t 和 $H_{known}$ 是已知的条款。 “k”是指是未知术语
从等式 1 生成的 $H_{i}$ 及其所有样本的已知二元响应然后进行分箱以获得 H 和响应概率。
下面，我展示了一个示例图，其中绿点作为新数据，并带有随机选取的“k”点。价值。绿色模拟数据

我的问题是未知“k”的估计在公式 1 中，它最小化了绿点和蓝色曲线之间的差异。
有人可以建议一种理想的方法来估计“k”]]></description>
      <guid>https://stats.stackexchange.com/questions/647960/predicting-simulated-data-for-a-known-curve</guid>
      <pubDate>Sat, 25 May 2024 13:34:44 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 convLSTM2D 对可变输入形状进行训练？</title>
      <link>https://stats.stackexchange.com/questions/647949/how-to-train-with-convlstm2d-on-variable-input-shape</link>
      <description><![CDATA[我正在使用 4 过滤器对 72x72 图像的时间序列进行分类（就像 RGB）。如果我的所有样本都具有相同的时间步长（或纪元数），那么事情就会很好地进行。然而，实际上我每个样本都有不同数量的时间步长。 （这是在天文学中，我无法随意获取数据。）但是当我尝试包含不同的时间步长时，我收到错误。请查看 MWC。
N=2000
train_data_arr=np.random.rand(N, 11, 72, 72, 4)
train_label=np.repeat(np.random.randint(2,size=N)[:, np.newaxis], 11,axis=1)
Ntot,dum=train_label.shape;打印(Ntot,dum)

#===可变数据形状====
def select_random_time_epochs(数据、标签、max_time_steps=11):
    变量数据 = []
    变量标签 = []
    对于 zip（数据，标签）中的 d、l：
        #时间步数 = 11
        time_steps = np.random.randint(1, max_time_steps + 1)
        variable_data.append(d[:time_steps])
        variable_labels.append(l[:time_steps])
    返回变量数据、变量标签
train_data_var, train_label_var = select_random_time_epochs(train_data_arr, train_label)

#====数据生成器======
def make_generator（数据，标签）：
    def 生成器():
        对于 zip（数据，标签）中的 d、l：
            产量 d, l
    返回发电机

train_ds = tf.data.Dataset.from_generator(
    生成器=make_generator(train_data_var, train_label_var),
    输出类型=（tf.float32，tf.int32），
    output_shapes=(tf.TensorShape([无, 72, 72, 4]), tf.TensorShape([无]))
）
批量大小 = 32
train_ds = train_ds.batch(batch_size)

#===型号===
输入形状 = (无, 72, 72, 4)  
模型 = tf.keras.Sequential()
model.add(输入(形状=input_shape))
model.add(ConvLSTM2D(32, (9, 9), 激活=&#39;relu&#39;, padding=&#39;valid&#39;, return_sequences=True, data_format=&#39;channels_last&#39;))
model.add(BatchNormalization())
model.add(TimeDistributed(MaxPooling2D((2, 2), data_format=&#39;channels_last&#39;)))
model.add(TimeDistributed(Flatten()))
model.add(TimeDistributed(Dense(64,activation=&#39;relu&#39;)))
model.add(TimeDistributed(Dense(1,activation=&#39;sigmoid&#39;)))
model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])
模型.summary()

model.fit(train_ds, epochs=20)

如果我将时间步长固定为 11（在函数 select_random_time_epochs() 中），则一切正常。但是当我使用可变数量的时间步长时，我收到错误：
无法批处理组件 0 中具有不同形状的张量。第一个元素的形状为 [3,72,72,4]，元素 3 的形状为 [6,72,72 ,4]。

我知道它无法处理 32 个批次内的可变时间步长。实际上，当我设置 batch_size = 1 时，上面的代码可以工作，但这需要太多时间，而且很可能永远不会融合到真实的用例场景中。
所以我的问题如下。

假设我完全不需要任何填充。当批次内的样本具有不同形状时，是否有更快的方法来实现 model.fit() ？否则，我可以动态批处理具有相同时间步长的样本吗？这是唯一的方法吗？评估可能不遵循同一批次分布的测试数据时会出现问题吗？

现在来到 padding 选项：tensorflow.keras.layers.Masking 是否真的能够处理我在缺失时期放置的“坏图像” ？换句话说，Masking 或其他东西可以完全使填充值变得无关吗？


重要的一点：我必须使用生成器来避免立即在 GPU 上加载数据，因为我的实际数据很大（字面上是天文数字）。
另外，以下线程讨论了 LSTM 的变量输入，但我的用例稍微复杂一些。
https://stackoverflow.com/questions/63663399/how -处理lstm的可变长度数据
https://stackoverflow.com /questions/38189070/how-do-i-create-a-variable-length-input-lstm-in-keras]]></description>
      <guid>https://stats.stackexchange.com/questions/647949/how-to-train-with-convlstm2d-on-variable-input-shape</guid>
      <pubDate>Sat, 25 May 2024 08:54:08 GMT</pubDate>
    </item>
    <item>
      <title>如何估计很小比例的置信区间？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/647947/how-to-estimate-the-confidence-interval-of-a-very-small-proportion</link>
      <description><![CDATA[我想估计很小比例的置信区间。假设我有 1000 人的简单随机样本，有 4 个人回答了“是”这个问题。人们可能想利用正态性假设并使用基本公式计算置信区间
$$
CI ± z * \sqrt{p^ * (1-p)/n)}
$$
然而，要保持这一点，通常会施加以下限制： $n * p ≥ 5$ 和 $n * (1- p) ≥ 5$，在本例中违反了。
因此，我的问题是：如果我想说：“在 95% 的置信度下，回答“是”的人数比例小于 x%”。如何找到 $x$？]]></description>
      <guid>https://stats.stackexchange.com/questions/647947/how-to-estimate-the-confidence-interval-of-a-very-small-proportion</guid>
      <pubDate>Sat, 25 May 2024 08:51:01 GMT</pubDate>
    </item>
    <item>
      <title>估计 N 个循环后裂纹长度超过阈值的概率</title>
      <link>https://stats.stackexchange.com/questions/647514/estimate-the-probability-that-a-crack-length-exceeds-a-threshold-value-after-n-c</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647514/estimate-the-probability-that-a-crack-length-exceeds-a-threshold-value-after-n-c</guid>
      <pubDate>Sat, 18 May 2024 17:35:26 GMT</pubDate>
    </item>
    <item>
      <title>在标准回归分析中利用二分网络信息</title>
      <link>https://stats.stackexchange.com/questions/647198/utilizing-bipartite-network-information-in-standard-regression-analysis</link>
      <description><![CDATA[我的一般性问题的要点是，当目标是使用标准回归模型进行节点级分析时，是否有一些有用的方法可以利用有关嵌入在二分网络中的个体之间关系的信息。
我的主要目标是确定解释特定人群中的个人是否接种疫苗的因素。我有两个数据集：

1.) 包含具有多个个体级别变量（例如年龄、性别、疫苗接种状态等）的不同个体的数据集。
2.) 一个数据集，其中包含有关哪个人去看哪个医生的信息。

由于该数据集中的医生之间没有直接关系，个人之间也没有直接关系，因此它本质上是一个二分网络。使用第一个数据集的信息来预测疫苗接种状态可以使用各种模型轻松完成，没有任何问题。我的问题是我不确定如何使用第二个数据集。这是我到目前为止的想法：

A) 聚合医生级别的信息（患者的平均年龄、过去接种疫苗的患者比例等）并将其合并到第一个数据集是我能想到的最简单的方法。然而，由于人们可能（而且通常确实）在给定时间点去看多个医生，因此需要另一个级别的聚合。例如。必须取医生级别变量的平均值（或最大值、最小值等）才能得到每人一个值。
B) 创建二分网络，提取节点级属性（例如接近度、中心性等），并将这些属性用作节点级回归中的预测变量。

这两个选项看起来都有点“hacky”。对我来说，所以我想知道是否有更正式的方法来结合我所拥有的两种信息。如果有人有任何想法或能指出我在文学方面的正确方向，我会非常高兴。任何意见都将受到高度赞赏。]]></description>
      <guid>https://stats.stackexchange.com/questions/647198/utilizing-bipartite-network-information-in-standard-regression-analysis</guid>
      <pubDate>Tue, 14 May 2024 10:09:55 GMT</pubDate>
    </item>
    <item>
      <title>为了估计综合控制方法中的权重，使用什么结果和对称矩阵的线性组合？</title>
      <link>https://stats.stackexchange.com/questions/646989/for-estimating-weights-in-the-synthetic-control-method-what-linear-combination</link>
      <description><![CDATA[我正在阅读比较案例研究论文的综合控制方法，并在第 12 页上。第 5 节说明了如何估计综合控制权重。以下是论文中方法的总结。我对两点很困惑：

为什么对干预前结果的线性组合给予如此大的灵活性？ （即可以是平均值，可以等于最后的结果）
我一直认为 $X_1$ 和 $X_0$ 是协变量，但它似乎包括协变量和干预前结果。这是为什么
在衡量差异时，为什么要引入$V$？这对我来说似乎完全超出了我的范畴，这是优化理论中的技术吗？

&lt;块引用&gt;
设 $W$ 为正权重求和的 $(J \times 1)$ 向量致一：
$$W = (w_2, \ldots, w_{J+1})^{\top}, \quad w_2 + \cdots + w_{J+1} =
&gt; 1.$$
$W$ 的每个值代表一个加权平均值的综合控制
可用的控制区域。观察感兴趣的结果
处理组 ($Y_{1t}$) 和对照组 ($Y_{jt}$)
区域，其中 $j = 2, \ldots, J + 1$。
设 $(T_0 \times 1)$ 向量 $K = (k_1, \ldots, k_{T_0 })^{\top}$
定义干预前结果的线性组合：
$$\bar{Y}_{K_i} = \sum_{s=1}^{T_0} k_s Y_{is}.$$
考虑 $M$ 这样的线性组合，$K_1, \ldots, K_M$。让：
$$X_1 = (Z_1^{\top}, \bar{Y}_{K_1}^{1}, \ldots,\bar{Y}_{K_M }^{1})^{\top},$$
一个 $(k \times 1)$ 的预干预特征向量
处理区域，其中 $k = r + M$。类似地， $X_0$ 是一个 $(k \times J)$ 矩阵，包含相同的控制变量地区，与
$j$-第列为：
$$(Z_j^{\top}, \bar{Y}_{K_1}^{j}, \ldots, \bar{Y}_{K_M}^ {j})^{\top}.$$
其中 $Z_i$ 是观察到的协变量向量。
向量$W^{\ast}$最小化$X_1$和&lt;之间的距离跨度类=“数学容器”&gt;$X_0
&gt; W$，使用
$$\| X_1 - X_0 W \|_V = \sqrt{(X_1 - X_0 W)^{\top} V (X_1 - X_0 W)},$$
其中 $V$ 是对称正半定矩阵。 $V$ 的最佳选择
为 $X_0$ 和 $X_1$ 中变量的线性组合分配权重，以最小化
综合控制估计量的 MSE。
]]></description>
      <guid>https://stats.stackexchange.com/questions/646989/for-estimating-weights-in-the-synthetic-control-method-what-linear-combination</guid>
      <pubDate>Fri, 10 May 2024 15:30:06 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯信息准则如何用于模型选择？</title>
      <link>https://stats.stackexchange.com/questions/597516/how-does-the-bayesian-information-criterion-work-for-model-selection</link>
      <description><![CDATA[我知道我们可以使用不同模型的 BIC 值来确定哪个模型对数据的预测效果最好。但是，我对用于确定哪个模型优于另一个模型的标准有些困惑。
对于 BIC，差值为 2 被视为一个模型优于另一个模型的积极证据，差值大于 10 则表明一个模型优于另一个模型的证据非常有力。
假设一个模型的 BIC 为 7461，另一个模型的 BIC 为 7508。这两个模型相差 47。因此，我们可以得出结论，BIC 为 7461 的模型对数据的解释效果最好。以下是我对这一结论/解释的疑问：

BIC 数值的单位是什么？
在解释时，我们必须考虑两个模型之间的差异比例吗？
无论 BIC 值如何，差异 2 是否总是表示一个模型优于另一个模型的积极证据？例如，BIC(1) = 10 vs BIC(2) = 12 的差异为 2，而 BIC(2) 的比例是 1.2（12/10）倍，而 BIC(1) = 7461 和 BIC(2) = 7508 相差 47，但 BIC(2) 的比例是 1.006（7508/7461）倍。
BIC 的单位重要吗？或者，无论 BIC 值有多大或多小，差异 2 是否总是意味着积极证据？
]]></description>
      <guid>https://stats.stackexchange.com/questions/597516/how-does-the-bayesian-information-criterion-work-for-model-selection</guid>
      <pubDate>Wed, 30 Nov 2022 19:48:38 GMT</pubDate>
    </item>
    </channel>
</rss>