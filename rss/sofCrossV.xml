<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 25 Apr 2024 09:14:44 GMT</lastBuildDate>
    <item>
      <title>评估生存分析中的比例风险假设</title>
      <link>https://stats.stackexchange.com/questions/645788/assessing-proportional-hazards-assumption-in-survival-analysis</link>
      <description><![CDATA[我有一个问题，我正在使用生存分析来研究吸烟与肺癌之间的关系，协变量是血压、体重指数和性别。吸烟满足 ph 假设，协变量 BP、BMI 满足比例风险假设，但性别不满足。现在我使用时间函数 tt 来获取协变量性别以满足 ph 假设。
所以我的问题是：此时，与吸烟暴露对应的系数不就是我需要的ln(HR)吗？不需要考虑协变量性别的时间效应吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645788/assessing-proportional-hazards-assumption-in-survival-analysis</guid>
      <pubDate>Thu, 25 Apr 2024 08:27:08 GMT</pubDate>
    </item>
    <item>
      <title>是否有可能当样本量 $n$ 较小时，一个估计器的表现优于其他估计器，但当 $n$ 较大时，一个估计器的表现却比其他估计器差？</title>
      <link>https://stats.stackexchange.com/questions/645786/is-it-possible-that-one-estimator-performs-better-than-others-when-sample-size</link>
      <description><![CDATA[是否有任何例子表明，当样本量 $n$ 较小时，一个估计器的性能优于其他估计器，但当 $n$ 时，一个估计器的性能比其他估计器差&quot;&gt;$n$很大吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645786/is-it-possible-that-one-estimator-performs-better-than-others-when-sample-size</guid>
      <pubDate>Thu, 25 Apr 2024 07:46:31 GMT</pubDate>
    </item>
    <item>
      <title>Xgboost 自定义目标函数。如何修改权重？</title>
      <link>https://stats.stackexchange.com/questions/645785/xgboost-custom-objective-function-how-to-modify-the-weights</link>
      <description><![CDATA[我有一个 xgboost 的自定义目标函数：
def custom_objective(y_true, y_pred, x = 3000):

    pred_probs = 1.0 / (1.0 + np.exp(-y_pred))

    top_x_indices = np.argsort(pred_probs)[-x:]

    #权重数组：前 x 个实例的权重较高
    权重 = np.ones_line(y_true)
    权重[top_x_indices] = 10

    梯度 = (pred_probs - y_true) / (pred_probs*(1 - pred_probs))
    
    hess = (2 * pred_probs**2 - 3 * pred_probs + 1 + y_true - 2 * y_true * pred_probs) / (pred_probs * (1 - pred_probs))**2

    返回 grad * 权重，hess * 权重

这个想法是将前 3000 个样本的权重设置得更高，因为只有最高分数才会用于生产。
问题是它每次分配相同的权重，并且权重在构建下一棵树时不会更新。如何在训练过程中将给定简单的实际权重放入自定义目标函数中？如果我能做到这一点，那么我可以将 top3000 的权重设置得更高，例如将这些权重乘以 10。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/645785/xgboost-custom-objective-function-how-to-modify-the-weights</guid>
      <pubDate>Thu, 25 Apr 2024 07:30:53 GMT</pubDate>
    </item>
    <item>
      <title>关于何时选择贝叶斯分析与频率分析的参考</title>
      <link>https://stats.stackexchange.com/questions/645784/references-on-when-to-choose-bayesian-vs-frequentist-analysis</link>
      <description><![CDATA[我正在寻找讨论和比较贝叶斯分析与频率分析在各种情况下的优缺点的参考资料。
如果有意义的话，我会特别有兴趣了解人们如何在研究的设计阶段确定这种事情（例如，我会对参考文献感兴趣，如果有的话，讨论是否存在研究设计的实际限制可能会在计划分析中排除贝叶斯或频率论方法）。然而，我不仅仅对从研究设计角度讨论该问题的参考文献感兴趣，因此这将是一个很好的补充，我很高兴获得讨论其他方面的参考文献。
我知道我的要求相当广泛，并且从业者之间可能存在不同的方法，当然也存在分歧，但我的问题是出于好奇，而不是为了解决我当前面临的特定问题。这就是为什么我询问参考文献，以更好地理解现有的论点。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/645784/references-on-when-to-choose-bayesian-vs-frequentist-analysis</guid>
      <pubDate>Thu, 25 Apr 2024 07:01:57 GMT</pubDate>
    </item>
    <item>
      <title>CUPED 与 Diff-in-Diff</title>
      <link>https://stats.stackexchange.com/questions/645780/cuped-vs-diff-in-diff</link>
      <description><![CDATA[我最近遇到了“CUPED”，这是一种回归调整技术，用于在实验中创建无偏估计量。同样，我事先熟悉差异中的差异（DiD）。
据我了解，DiD 假设治疗组和对照组以相同的速度变化；在实验开始之前，治疗和控制的手段可能会有所不同。但是，我们对治疗组的变化（同时考虑现有趋势）和对照组的变化（仅考虑现有趋势）感兴趣。
CUPED 似乎完成了同样的事情。但我听说，它不是对趋势差异进行建模，而是试图解释趋势，以便在没有治疗暴露的情况下，对治疗组进行校正以匹配对照组。并且这种调整通过实验进行，使得治疗组和对照组可以直接进行比较。 （这是真的吗？）
此外，我还有几个问题。

CUPED 是否假设治疗组和对照组均存在非零趋势？
如果 [1]，CUPED 是否呈现相同的趋势？
CUPED 的调整是否需要实验开始前后的数据（如 DiD）？或者 CUPED 是否使用纯粹的实验前面板数据来进行调整？
治疗组和对照组都接受调整吗？

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/645780/cuped-vs-diff-in-diff</guid>
      <pubDate>Thu, 25 Apr 2024 01:36:40 GMT</pubDate>
    </item>
    <item>
      <title>R 与 Hayes 的 PROCESS 宏的中介包？</title>
      <link>https://stats.stackexchange.com/questions/645777/mediation-package-for-r-vs-hayes-process-macro</link>
      <description><![CDATA[我是调解的初学者，我很好奇 和 Hayes 的 PROCESS 宏 R。
这些软件的工作原理相似还是会导致不同的结果？两者之间有主要区别吗？
我想使用中介包，因为它提供了通过置信区间中介的比例，但我想知道两者之间是否还有其他差异可以帮助我做出决定。]]></description>
      <guid>https://stats.stackexchange.com/questions/645777/mediation-package-for-r-vs-hayes-process-macro</guid>
      <pubDate>Thu, 25 Apr 2024 01:04:48 GMT</pubDate>
    </item>
    <item>
      <title>如何从 $p(y|x)$ 和 $p(y)$ 中获取给定样本 $p(x)$？</title>
      <link>https://stats.stackexchange.com/questions/645776/how-to-obtain-px-given-samples-from-pyx-and-py</link>
      <description><![CDATA[这里，假设 $p(y\mid x)$ 和 $p(y)$ 太复杂，无法得到封闭形式，我们只能从中抽取样本。有什么方法可以从 $p(x)$ 中估计或抽取样本吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645776/how-to-obtain-px-given-samples-from-pyx-and-py</guid>
      <pubDate>Thu, 25 Apr 2024 00:42:02 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中对 JSON 文档进行分类？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/645775/how-do-i-classify-json-documents-in-python</link>
      <description><![CDATA[我有一组 JSON 文档，可以（手动）将其分类为“桶” A、B、C、D 等。桶的数量是有限的（而且很小，也许是 10 个）。
我如何使用 Python 实现同样的事情？根据我的搜索，我相信我可以在 SciKit learn 中使用 SVM...但这就是我所能得到的。
如果我不得不猜测，我首先需要最小化 JSON 以删除“与分类无关的字段” （例如，诸如 id 字段之类的字段始终是唯一的）。但也许“模型”无论如何，你能弄清楚这一点并忽略它吗？
也许我需要以某种方式告诉模型 JSON 中的哪些字段很重要 - 但到那时，我不妨只做一个美化的循环和 if 语句？
如您所知，我是机器学习的新手。我很高兴被告知：先去学习 X、Y 和 Z。]]></description>
      <guid>https://stats.stackexchange.com/questions/645775/how-do-i-classify-json-documents-in-python</guid>
      <pubDate>Wed, 24 Apr 2024 23:24:55 GMT</pubDate>
    </item>
    <item>
      <title>与 PROCESS 的中介 - 为什么我的 b 路径不重要但我的 lm 重要？</title>
      <link>https://stats.stackexchange.com/questions/645748/mediation-with-process-why-is-my-b-path-insignificant-but-my-lm-significant</link>
      <description><![CDATA[我目前正在撰写学士论文，并使用 PROCESS（模型 4）进行调解。我的 IV 是自我慈悲，我的 DV 是一般心理健康，我的调解者是孤独。我有点困惑，因为我的 b 路径在我的中介模型中微不足道 ($b = 0.12$)，但是当我使用单独的线性模型来测试 a 和b 路径，因为我对结果感兴趣，我意识到我对路径 a 得到了几乎相同的结果，但对路径 b 却没有得到相同的结果。以孤独感为 IV、一般心理健康为 DV 的线性模型似乎很重要 ($b = 0.19*$)。
这是怎么来的？如果有人能给我解释一下那就太好了！]]></description>
      <guid>https://stats.stackexchange.com/questions/645748/mediation-with-process-why-is-my-b-path-insignificant-but-my-lm-significant</guid>
      <pubDate>Wed, 24 Apr 2024 16:44:03 GMT</pubDate>
    </item>
    <item>
      <title>手动预测 ARIMA(0,0,1) 模型 - MA 元素存在问题</title>
      <link>https://stats.stackexchange.com/questions/645739/forecasting-arima0-0-1-model-by-hand-trouble-with-ma-elements</link>
      <description><![CDATA[我在预测固定 ARIMA(0,0,1) 时间序列时遇到问题。我目前对该过程进行了 500 个观察，并希望预测未来的三个时期。
使用 Stata 软件，我可以使用以下两行代码轻松创建静态和动态预测：
预测 yiv_static, xb //静态预测
预测 yiv_dynamic, xb 动态(501) //动态预测

当我尝试“手动”验证这些预测时，就会出现此问题。我当前的流程是：
关于ARIMA(0,0,1)模型，我使用方法来估计：
y_t = c&#39; - Theta * ε_t-1

其中c&#39;为调整常数； c&#39; = c * (1 + θ)
Theta 为 0.8289
ε_t计算为εt=yt+θ*ε_t−1（等于第一周期的1.060531）
有人有这方面的经验吗？如果您感兴趣，我当前的 Stata 代码如下所示：
arima yiii 如果 t&lt;=500, arima(0,0,1)
标量 cons_iii = _b[_cons]
标量 cons_adj_iii = cons_iii * (1 + Theta1_iii)
标量 Theta1_iii = [ARMA]_b[L1.ma]

gen yiii_error = yiii 如果 _n == 1
如果 _n &gt; 则替换 yiii_error = yiii + Theta1_iii * L1.yiii_error 1

gen yiii_static_veri = cons_adj_iii + Theta1_iii * L1.yiii_error // 手动静态预测
]]></description>
      <guid>https://stats.stackexchange.com/questions/645739/forecasting-arima0-0-1-model-by-hand-trouble-with-ma-elements</guid>
      <pubDate>Wed, 24 Apr 2024 15:24:55 GMT</pubDate>
    </item>
    <item>
      <title>倾向匹配不影响系数的显着性</title>
      <link>https://stats.stackexchange.com/questions/645738/propensity-matching-does-not-affect-significance-of-coefficients</link>
      <description><![CDATA[我的回归如下：
$$ y = \alpha + \mu L + \beta_1 x + \beta_2 x^2 + \varepsilon $$
其中 L 是虚拟变量，x 是控制变量。
当我运行回归时，$x$ 和 $x^2$ 都很重要。我使用 $L$、$x$ 和 $x^2$。匹配样本的回归结果仅对 $x^2$ 有意义，对 $x$ 有意义span&gt; 消失。
你能帮我解释一下这个结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645738/propensity-matching-does-not-affect-significance-of-coefficients</guid>
      <pubDate>Wed, 24 Apr 2024 15:02:31 GMT</pubDate>
    </item>
    <item>
      <title>多层模型和随机效应：仍然困惑</title>
      <link>https://stats.stackexchange.com/questions/645725/multi-level-models-and-random-effects-still-confused</link>
      <description><![CDATA[我知道有很多关于多级模型、随机效应、固定效应等解释的帖子。但在阅读完这些内容并观看由 Prof. Mikko Rönkkö（芬兰于韦斯屈莱大学），我对某些具体方面仍然感到困惑。
最重要的是：我们什么时候真正需要随机效应模型。 YouTube 系列，以及这些 两篇文章似乎暗示，如果我只对模型固定部分的平均效果感兴趣，我不需要随机即使数据是分层的，也可以使用效应模型，因为在这种情况下，聚类标准误差就足够了。仅当我对聚类之间的方差感兴趣时，我才需要采用随机效应模型。这是正确的吗？
我认为通过一个模仿我正在使用的数据的示例来理解所有这些对我来说是最容易的：

鉴于有汇总的横截面调查数据，其中个人
受访者分布在多个国家，并且调查是多次进行的
多年来每个国家的次数。

研究问题旨在查明国家层面的变量（例如 GDP）是否会影响受访者回答有关生活满意度问题的方式。但我只对 GDP 对生活满意度的总体影响感兴趣。

在此示例中，我是否需要随机效应模型（如果假设成立）？或者对标准错误进行聚类就足够了吗？我在这里测量什么效果？之间的效果？

]]></description>
      <guid>https://stats.stackexchange.com/questions/645725/multi-level-models-and-random-effects-still-confused</guid>
      <pubDate>Wed, 24 Apr 2024 10:07:43 GMT</pubDate>
    </item>
    <item>
      <title>用于比较海洋生态系统海拔和沉积物沉积变化的韦尔奇方差分析：没有正态分布和异质性的大型 DEM [关闭]</title>
      <link>https://stats.stackexchange.com/questions/645607/welch-anova-for-comparisons-of-elevation-altered-sediment-accretion-of-sea-eco</link>
      <description><![CDATA[我正在研究瓦登海内两个不同生态系统的海拔特征和沉积物堆积效应，这些生态系统受到一种物种（生态系统一）的生物入侵和本地物种（生态系统二）的迁移的影响。使用通过 2020 年和 2022 年无人机飞行的运动结构 (SfM) 生成的高分辨率数字高程模型 (DEM)，我的目标是量化这些生态系统之间的高程差异以及对沉积物堆积的影响。我的 DEM 从数据记录到生成 (SfM) 均经过统一处理，从而获得精确的分辨率。对于这一步，我只关注高程值。不考虑任何错误、重新采样或转换。
由于瓦登海一种物种的生物入侵和一种本土物种的迁移，原始生态系统转变为新的生态系统。了解这两个物种可以在哪里生活并与周围环境相互作用至关重要，因为这两个生态系统都会影响它们的环境。在这里，我重点关注相对于当地平均海平面的海拔，并量化这些生态系统增强的周围沉积物堆积。为了说明生态系统对沉积物堆积的影响是否不同，我想知道这两个生态系统影响的沉积物是否存在显着差异。我想量化生态系统/地点之间的差异程度和分歧程度，以说明平均值是否“显着不同”。 p 值 &lt; 0.05。我没有遵循一定的门槛。
首先，我想比较生态系统的手段，以确定它们的生活条件在海拔方面是否存在显着差异。生态系统适合生活在哪个海拔高度？它们是否有最佳的生活区（特定海拔处的丰度最高）？
其次，正如我所提到的，生态系统不同程度地影响周围的沉积物堆积（垂直增长/体积变化）。因此，我想通过比较沉积物的沉积结果来了解它们对沉积物沉积的影响是否存在显着差异。
我计划采用统计测试来评估生态系统之间海拔和沉积物堆积差异的显着性。到目前为止我的方法是：

正态分布：鉴于数据集规模较大且高程数据非正态分布，我将跳过正态性测试并在补充材料中提供相应的直方图和 Q-Q 图以供参考。

方差同质性：大数据集使得 Levene 的检验变得不必要。此外，描述性统计的标准差也不同。

均值检验：Welch t 检验（两组：生态系统 1 与生态系统 2）和 Welch 方差分析（研究地点 1、研究 2 与研究地点 3……）。我有非正态分布的数据和方差的异质性，并且我有兴趣比较平均值；因此，我决定使用韦尔奇选项。 Friedman 检验将用于分析海拔的时间变化。


在本研究中，“显着差异”的定义如下：
a. H0：生态系统的海拔平均值没有差异（p&lt;0.05）。
b. H1：他们不同。

事后：Games-Howell 测试。

我寻求有关这种方法是否适合或需要调整的指导。我将非常感谢有关这些主题的任何参考或建议。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/645607/welch-anova-for-comparisons-of-elevation-altered-sediment-accretion-of-sea-eco</guid>
      <pubDate>Tue, 23 Apr 2024 07:57:56 GMT</pubDate>
    </item>
    <item>
      <title>Kruskal-Wallis 真的是随机优越性的良好测试吗？</title>
      <link>https://stats.stackexchange.com/questions/645594/is-kruskal-wallis-really-a-good-test-of-stochastic-superiority</link>
      <description><![CDATA[经过大量阅读/谷歌搜索后，我得出的结论是，Kruskal-Wallis 检验 (K-W) 是随机优越性检验（或者同等地，随机等效性检验）。拒绝零意味着至少 1 个总体随机优于至少另一个 1 个总体（例如，来自维基百科，“显着的 Kruskal-Wallis 检验表明至少一个样本随机支配另一个样本”。）
随机优越性的一个有趣属性是它不是传递属性。
所以，为了好玩（？），我从 Efron 的骰子中创建了 4 个样本（非传递性！）。我将这些值重复了 6 次，每次的样本量为 48。为了避免如此多的联系，我向每个样本添加了少量高斯噪声 ($N(0,.1)$)。这给了我下面的 4 个样本 &lt; a href=&quot;https://i.sstatic.net/Q4cVzCnZ.bmp&quot; rel=&quot;nofollow noreferrer&quot;&gt;
然后我对这 4 个样本进行了 Kruskal-Wallis 测试。 p 值为 0.974。当然不重要...
我还运行了 Dunn MCT，它表明没有显着的组间差异（当然，考虑到 p 值）。
然后我运行了全部 6 项 Mann-Whitney U 测试。我使用了 Sidak 的 MCC，它为我提供了 6 次比较的调整后的 $\alpha&#39;=0.0085$（Bonferroni 为 0.00833）。样本 A 随机优于 B，B 优于 C，C 优于 D，D 又优于 A（正如我们从 Efron 的骰子中所期望的那样）。其他 2 个（A-C 和 B-D）没有显示出显着性。对于所有显着的 M-W U 检验，p 值为 $0.005 &lt; 0.0085$)。
这给我留下了一个不重要的 K-W，尽管有 4 个重要的 M-W U。你相信哪一个？ （我知道我相信 M-W U 测试，fwiw）
我知道，挥手地说，K-W 测试的统计量类似于 F 测试，但基于等级。但通过“模糊”将各组放在一起，是否不会丢失各个样本的特定形状差异，从而使它们随机不同？
这是否意味着 K-W 不是一个很好的随机优越性综合检验？那么它测试什么？
更新于 2024 年 4 月 23 日
我又进行了一些测试。

首先是仅包含前 2 个样本（A 和 B）的 K-W。 p=0.005（就像 M-W U 一样，正如预期的那样。
然后使用前 3 个样本（A、B 和 C）进行 K-W。 p=0.456 (?)
所以 K-W 告诉我 A 和 A 之间有区别。 B（注：我故意没有指定差异是什么：随机优势、中位数、分布、???。但 A 和 B 之间存在a差异）。但是，当我添加第三个样本时，这种显着差异消失了？
考虑到添加更多组时 K-W 可能会失去功效 (??)，因此我将样本大小增加了四倍，达到每组 192 个。对这 4 个变量重新运行 K-W，得到 p=0.828。 A 和 A 之间的 M-W U B（例如）给出 p=0.000000016
然后，为了看看 K-W 无法找到显着性是否是因为随机优越性的非传递性，我保留了样本 A 和 A 。 B 的大小为 198，但降低了 C&amp;D（包含非传递值）为 48。这个新的 K-W 检验给出的 p 值为 0.007。终于！

K-W 发生了什么？为什么？
更新于 2024 年 4 月 24 日
经过深入研究，我发现了这篇内容非常丰富的论文“Kruskal-Wallis，多重比较和 Efron Dice”，Bruce M. Brown 和 Thomas P. Hettmansperger https://api.semanticscholar.org/CorpusID:55698326很好地解释了这种情况。
这个问题与随机优越性的非传递性有关。当存在这种非传递性情况时（作者称之为“循环性”，但对我来说这给出了错误的图像，所以我将坚持使用繁琐的“非传递性”），K-W 测试的威力就会减弱，有时戏剧性地，就像我的问题的例子一样。
我怀疑“非传递性”是否存在。需要极端的“石头/剪刀/布”。输入我在原始问题中使用的内容。我认为它们可以更加微妙，如下例所示：我们有 3 个样本 A、B 和 B。 C（每个 5 个样本）。[![K-W 计数器示例][2]][2]
因为样本量（非常）小，所以可以直接查看所有的成对比较。 “节拍”是指“节拍”。 B 在 25 次中有 23 次，并且 B“击败”了 25 次。 C 20 次（满 25 次）。人们会期望A轻松击败C吗？但这种情况在 25 次中只发生了 20 次。严格的传递性属性尚未得到尊重。 2 个样本 K-W 检验 (A,B) 显着 (p=0.028)，但 3 个样本 K-W 检验 (A,B,C) 显着，p=0.061。]]></description>
      <guid>https://stats.stackexchange.com/questions/645594/is-kruskal-wallis-really-a-good-test-of-stochastic-superiority</guid>
      <pubDate>Tue, 23 Apr 2024 02:36:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 Metafor 的 rma.mv 和稳健方差估计时的异质性和 ICC</title>
      <link>https://stats.stackexchange.com/questions/645446/heterogeneity-and-icc-when-using-metafors-rma-mv-and-robust-variance-estimation</link>
      <description><![CDATA[我正在对具有多种依赖性来源的标准化均值差异进行荟萃分析（测量相同结构的多个结果、多个对照组、二元组的结果（例如，单独的患者-护理者和丈夫-妻子评分）以及多个结果）时间点（发布和后续））。
我使用 metafor::rma.mv 结合 RVE (metafor::robust) 构建 3 级模型（随机 = ~1|study/effectsize）。我对恒定相关性的不同假设进行了敏感性分析。正如预期的那样，在 rho = 0.5、0.6、0.7、0.8 或 0.9 范围内，汇总效应和标准误差几乎相同，具有显着效应的相同推论。
但是，方差分量和异质性不受 RVE 影响，并且对于不同的相关值而言是不同的。例如，当假设 rho 为 0.5 时，I^2 的范围为 41.24 (95% CI = [3.68, 74.16])，第 3 级为 39.13，到 52.71 [30.97, 75.86]，当假设 rho 为 0.5 时，第 3 级为 11.69为 0.9.，Q 也受到类似的影响。 （在通过重新参数化模型的随机部分来计算置信区间时，这篇文章对我非常有帮助：https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2017-September/000195.html ）。预测区间也不同。
问题1：
我想知道是否有人对异质性的集群鲁棒性推断有什么建议？我正在使用多模型方法进行主持人分析以解释异质性（https://www .metafor-project.org/doku.php/tips:model_selection_with_glmulti_and_mumin)。
然而，敏感性分析表明，尽管分析之间都很重要，但我实际上并不知道真正的异质性有多少。
问题2：
我想知道拟合模型后计算出的 ICC 是否可以用来指示模型的“正确”程度。常数相关性的初始猜测是？
例如，
rma_mv_model$sigma2[1]/ sum(rma_mv_model$sigma2) 
或“rho”将模型重新参数化为 rma.mv 时生成的值
随机 = ~factor(effectsize)|研究]]></description>
      <guid>https://stats.stackexchange.com/questions/645446/heterogeneity-and-icc-when-using-metafors-rma-mv-and-robust-variance-estimation</guid>
      <pubDate>Sat, 20 Apr 2024 13:26:36 GMT</pubDate>
    </item>
    </channel>
</rss>