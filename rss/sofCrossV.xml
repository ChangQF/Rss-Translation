<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 08 Aug 2024 06:22:49 GMT</lastBuildDate>
    <item>
      <title>SKLearn 如何得出 LASSO 系数？</title>
      <link>https://stats.stackexchange.com/questions/652475/how-does-sklearn-derive-lasso-coefficients</link>
      <description><![CDATA[我正在尝试使用 SciPy 优化来推导 SKLearn 的 LASSO 系数，只是为了了解 SKLearn 的内部工作原理。但是，我无法使参数匹配。
import numpy as np
from sklearn.linear_model import Lasso

from sklearn.datasets import load_iris
iris = load_iris()
X, y = iris.data[:,0:3], iris.data[:,3]

lasso_reg = Lasso(alpha=1)
lasso_reg.fit(X, y)

得出 lasso_reg.coef_ = array([ 0. , -0. , 0.09270611]) 和 lasso_reg.intercept_ = 0.8509437849691903
当我尝试自己推导这些时，我试图最小化：
def lasso_min(params):
return sum((y - params[0] - np.matmul(X, params[1:]))**2) + lam * sum([abs(val) for val in params[1:]])

使用：
lam = 1
from scipy import optimize
sol = optimize.minimize(lasso_min, [0,0,0,0])

这给了我 sol.x = array([-0.29598937, -0.14396059, 0.16120468, 0.49060031])
即使我增加 lam 的值，我也无法将系数正则化为 0。有人能解释一下我在这里做错了什么吗？我认为这是我的代码中一些非常基本的东西，而不是缺乏更深层次的理解？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652475/how-does-sklearn-derive-lasso-coefficients</guid>
      <pubDate>Thu, 08 Aug 2024 03:29:09 GMT</pubDate>
    </item>
    <item>
      <title>生成似然估计误差线的有效方法</title>
      <link>https://stats.stackexchange.com/questions/652473/efficient-methods-for-generating-error-bars-on-likelihood-estimates</link>
      <description><![CDATA[假设我有一些似然函数，我已经将其最大化以获得最有可能生成一些实验数据的参数。我现在想要这些数量的误差线。我有什么选择？
我能想到的一个选择是查看最大似然附近的 Hessian 矩阵，给出一个协方差矩阵，其中我假设似然分布是高斯分布。这可能没问题，但似乎假设太多了。
另一个选择是使用 MCMC 方法对似然函数进行采样，然后分析样本以获得置信区间。这相当严格，但当似然函数的评估成本很高时，计算成本非常高。
在我的似然函数评估成本很高的情况下，还有哪些其他选项可以提供值得信赖的误差线/置信区间？]]></description>
      <guid>https://stats.stackexchange.com/questions/652473/efficient-methods-for-generating-error-bars-on-likelihood-estimates</guid>
      <pubDate>Thu, 08 Aug 2024 01:52:03 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的目标规范化恶化了性能指标</title>
      <link>https://stats.stackexchange.com/questions/652472/target-normalization-on-neural-network-worsens-performance-metrics</link>
      <description><![CDATA[我正在实现一个基于傅里叶神经算子的神经网络来预测几个流体流动变量。这是我的设置：

输入：4 个单值和 1 个 2D 输入（全部连续）
输出：6 个 2D 输出（全部连续）
架构：将 4 个单值参数嵌入 2D 输入，然后是几层傅里叶运算符
损失函数：均方误差 (MSE)
验证：5 倍交叉验证
其他指标：R 平方 (R2)、平均绝对误差 (MAE) 和均方根误差 (RMSE)
输入训练数据是 z 分数标准化的

我观察到以下情况：

对目标进行标准化会显著降低性能指标。
对输入进行标准化似乎不会影响模型的性能。
当我不规范目标时，损失和其他指标似乎有所改善。但是，将目标与模型输出绘制在一起
并没有显示出明显的改善。

问题：

这种行为正常吗？
我以为 R2 是尺度不变的，但当我规范目标时，它也会变得更糟。为什么会发生这种情况？
在这种情况下，我应该使用哪些指标来可靠地衡量模型的性能？

这是训练过程中损失函数和其他指标的样子，粉红线是经过归一化的目标。

这是使用标准化目标时目标与输出的图。

这是在训练中使用非标准化目标的相同图。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652472/target-normalization-on-neural-network-worsens-performance-metrics</guid>
      <pubDate>Thu, 08 Aug 2024 00:32:09 GMT</pubDate>
    </item>
    <item>
      <title>为什么 $\xi X$ 和 $\xi |X|$ 具有相同的分布？</title>
      <link>https://stats.stackexchange.com/questions/652471/why-xi-x-and-xi-x-have-the-same-distribution</link>
      <description><![CDATA[让 $\xi$ 成为 Rademacher 随机变量或对称伯努利随机变量。
让 $X$ 成为另一个独立于 $\xi$ 的随机变量。
我想证明 $\xi X$ 和 $\xi |X|$ 具有相同的分布。
我的第一个尝试是证明它们具有相同的分布函数。事实上，让 $a \geq 0$，
\begin{align}
P(\xi|X| \leq a) &amp;= \frac{1}{2} P(|X| \leq a) + \frac{1}{2}P(|X| \geq - a)\\\\
&amp;= \frac{1}{2}P(|X| \leq a) + \frac{1}{2}\\\\
&amp;= \frac{1}{2}(P(X\leq a) - 1 + P(X \geq -a)) + \frac{1}{2}\\\\
&amp;= \frac{1}{2}P(X \leq a) + \frac{1}{2}P(X \geq - a)\\\\
&amp;= P(\xi X \leq a)
\end{align&gt;
我相信这证明了当 $a$ 为正时的情况。但是，当我尝试 $a &lt; 0$ 时，这种方法没有任何效果。]]></description>
      <guid>https://stats.stackexchange.com/questions/652471/why-xi-x-and-xi-x-have-the-same-distribution</guid>
      <pubDate>Thu, 08 Aug 2024 00:00:31 GMT</pubDate>
    </item>
    <item>
      <title>DNN 分位数回归</title>
      <link>https://stats.stackexchange.com/questions/652466/dnn-quantile-regression</link>
      <description><![CDATA[我有一个 PyTorch 模型，其目的是根据输入预测输出的分位数。在这种情况下，输出是机器维护的服务时间（分钟）。输入详细说明了机器及其使用情况的各种属性。
平均时间和中位数时间比 90% 分位数范围（第 5 到第 95 个百分位数）更不重要。这些输出可帮助我们有效地安排维护活动而不会超负荷。
当前的问题是，无论训练和测试集数据的输入如何，该模型都会产生相同的百分位数。我需要它更有效地适应非线性，这是神经网络的卖点。
这是一个纯预测模型。系数和因果陈述的解释超出了范围；同样，贝叶斯模型可以解释给定后验链时输出的变化。但是，我目前没有考虑其他方法。
除了前言之外，下面是我的 PyTorch 模型
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

class QuantileNet(nn.Module):
def __init__(self, input_size=36, hidden_​​sizes=[20, 10], output_size=5):
super(QuantilePDWNet, self).__init__()
self.fc1 = nn.Linear(input_size, hidden_​​sizes[0])
self.fc2 = nn.Linear(hidden_​​sizes[0], hidden_​​sizes[1])
self.fc3 = nn.Linear(hidden_​​sizes[1], output_size)
self.relu = nn.ReLU()

def forward(self, x):
x = x.to(dtype=torch.float)
x = self.relu(self.fc1(x))
x = self.relu(self.fc2(x))
x = self.fc3(x)
return x

接下来是用于预测百分位数的损失函数
def loss_function(output, target):
p05 = output[:, 0]
p25 = output[:, 1]
p50 = output[:, 2]
p75 = output[:, 3]
p95 = output[:, 4] 

p05_error = target - p05 
p05_loss =火炬.其中（p05_error&lt;； 0.0, 0.95*(1-p05_error), 0.05*p05_error)

p25_error = 目标 - p25 
p25_loss = torch.where(p25_error &lt; 0.0, 0.75*(1-p25_error), 0.25*p25_error)

p50_error = 目标 - p50 
p50_loss = torch.where(p50_error &lt; 0.0, 0.50*(1-p50_error), 0.50*p50_error) 

p75_error = p75 - 目标 
p75_loss = torch.where(p75_error &lt; 0.0, 0.75*(1-p75_error), 0.25*p75_error)

p95_error = p95 -目标 
p95_loss = torch.where(p95_error &lt; 0.0, 0.95*(1-p95_error), 0.05*p95_error) 

return torch.mean(p05_loss + p25_loss + p50_loss + p75_loss + p95_loss)

据我从文献综述中所知，分位数损失函数已正确实现。它使用不对称惩罚，其中对较低百分位数的高估受到高度惩罚，对高百分位数的低估受到高度惩罚；无论高估/低估如何，中位数都会受到同等的权重。
就上下文而言，我有 36 个输入特征和 250 万行。
我的分位数损失是问题的根源吗？
我的 DNN 应该只是有更多的层和复杂性吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652466/dnn-quantile-regression</guid>
      <pubDate>Wed, 07 Aug 2024 22:21:55 GMT</pubDate>
    </item>
    <item>
      <title>如何验证 R 中函数预测的预测？</title>
      <link>https://stats.stackexchange.com/questions/652463/how-to-validate-the-predictions-from-the-function-forecast-in-the-r</link>
      <description><![CDATA[动机
当模型遇到以前未见过的数据时，我们常常有兴趣评估模型的性能。我正在测试 ARIMA 模型来分析一些数据，并希望确保我理解 prediction::forecast 函数的内部工作原理。
数据生成
为了执行此任务，我从 AR(2) 生成数据并将其存储为时间序列对象 ts。
set.seed(123)
z= vector(length = 48)
z[1] = 10
z[2] = 10

for (i in 3:48) {
z[i] = 5 + 1.0*foo[i-1] - 0.70*foo[i-2] + rnorm(n = 1, sd = 1)
}

ts &lt;- as.ts(z, frequency = 1)

# 如果您想查看数据及其 ACF，请运行以下行
# par(mfrow = c(1,2))
# plot(ts, main = &quot;时间序列 Y&quot;, ylab = &quot;值&quot;)
# Acf(ts, main = &quot;时间序列 Y 的 ACF&quot;)
# par(mfrow=c(1,1))

建模
然后我使用函数 forecast::auto.arima 来建模数据。我对模型的唯一限制是它不应考虑任何季节性。请注意，我仅使用 y 的前 24 个值来拟合模型，即我采用了 50/50 分割。
fit &lt;- auto.arima(y = ts[1:24], seasonal = FALSE)

# 要查看调整后的参数和逆 AR 根，请运行以下行
# summary(fit)
# plot(fit)

预测
使用模型 fit，我可以轻松预测 h 步。下面的两行代码将准确显示
fit_forecasts = Forecast(fit, h = 24)
plot(fit_forecast)
abline(v = 25, lwd = 2, lty = 2, col = &quot;grey30&quot;)

如果我检查第一个预测值 $y_{25}$，我会得到 7.339453。
fit_forecasts$mean[1]

验证第一个一步预测，$y_{25}$
我想手动计算这个值，以便更好地了解引擎盖下的情况。拟合模型的系数为$\phi_1 = 0.9380345$和$\phi_2 = -0.7773760$。截距为$y_0 = 7.3359679$。因此，模型为
$$
y_{t+1} = y_0 + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \eta_{t+1} = 7.3359679 + 0.9380345y_{t-1} -0.7773760y_{t-2} + \eta_{t+1},
$$
其中 $\eta$ 为创新。鉴于我在前 24 个数据点上拟合了模型，第一个一步预测可以表示为
$$
y_{25} = 7.3359679 + 0.9380345y_{24} -0.7773760y_{23} + \eta_{25}
$$
已知 $y_{23}$ 和 $y_{24}$ 分别为 $5.779341$ 和 $6.049662$，我们可以解出 $y_{25}$
\begin{align}
y_{25} &amp;= 7.3359679 + 0.9380345 \times 6.049662 -0.7773760 \times 5.779341 + \eta_{25}\\
y_{25} &amp;= 8.518039 + \eta_{25}
\end{align&gt;
我到此为止了：我不知道 $\eta_{25}$ 的值是什么，所以我无法计算 $y_{25}$。我从 forecast 调用的结果中知道 $y_{25} = 7.339453$，因此，我可以将创新计算为 $\eta_{25} = 7.339453 - 8.518039 = -1.178586$，但我不想计算创新。理想情况下，我会得到采样的创新，这样我就可以计算预测值。
我检查了 fit$residuals，但这些是拟合模型的 &quot;残差。即 x 减去拟合值。&quot;，根据 forecast 包手册。
问题
我的目标是将 $y_{25}, ..., y_{48}$ 提供给 fit，以查看模型如何处理在训练期间从未见过的数据，但首先我想了解如何进行预测。我找不到任何地方的采样创新序列。如果预测是按照模型的期望值计算的，并且创新的均值为零，则$\mathbb{E}[\eta_{25}] = 0$，但即便如此，我仍然不知道如何手动计算$y _{25} = 7.339453$。
我该怎么做？]]></description>
      <guid>https://stats.stackexchange.com/questions/652463/how-to-validate-the-predictions-from-the-function-forecast-in-the-r</guid>
      <pubDate>Wed, 07 Aug 2024 21:15:51 GMT</pubDate>
    </item>
    <item>
      <title>在什么情况下多任务学习是合理的？</title>
      <link>https://stats.stackexchange.com/questions/652462/under-which-circumstances-is-multi-task-learning-sensible</link>
      <description><![CDATA[给定某些任务，其样本为 $y_1(\vec{x}), ... y_n(\vec{x})$
我们何时可以期望多任务学习成为一种明智的方法（即比训练 n 个独立模型产生“更好”的结果）？
我确实理解以下内容：

寻找任务 1..n 的“良好”性能本质上是一个多目标优化问题，因此将有无数个帕累托最优解（无可比拟的好解，需要额外的无差异曲线来选择单个最佳优化解）
虽然这是一个艰难的多目标优化问题，但我可以想象这样一种情况，即所有任务的条件均值估计量都通过多目标学习得到改进，或者在保持无偏的情况下方差更小（在引导测试训练数据集时）。也许这在某种意义上类似于 Cramer Rao 边界 https://en.m.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound

现在对于神经网络和基于梯度下降的优化，我想到了以下想法：

虽然在实践中，人们训练“嵌入模型”然后将它们与不同任务 1..n 的任务头连接起来，如果只有这种联合嵌入（一个共同的神经主干）的存在有助于在所有任务中实现更好的性能，这似乎很幸运（尽管这可以隐式地作为一种正则化，但它更像是一种负担，避免在公共主干中为给定任务提取最佳特征……）
当目标 1..n 之间存在高协方差结构时，多任务学习是否应该最有益（所以我应该在开始多目标学习模型之前检查这一点）
通过多维高斯负对数似然损失利用目标中的这种协方差结构是否有益？

还有什么需要考虑的？
PS：https://openreview.net/forum?id=SylzhkBtDB “理解和改进多任务学习中的信息传递”似乎相关，但提出了不同的观点]]></description>
      <guid>https://stats.stackexchange.com/questions/652462/under-which-circumstances-is-multi-task-learning-sensible</guid>
      <pubDate>Wed, 07 Aug 2024 21:13:30 GMT</pubDate>
    </item>
    <item>
      <title>通过分析车辆轨迹来聚类/查找罚单中的模式[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652461/clustering-finding-patterns-in-tickets-analysing-vehicle-traces</link>
      <description><![CDATA[我正在从事一个涉及分析汽车 CAN 总线跟踪数据的项目。目标是根据 ECU 通信跟踪从票证（公司的票证工具）中聚类出类似的问题。详情如下：
数据：

格式：.blf（二进制日志格式）用于主票，.asc（ASCII）用于从票
大小：大文件，每个约 350MB
内容：时间戳、通道、协议、消息 ID、解码信号等。

当前方法：

解析 .blf 和 .asc 文件
识别主动传输的 ECU 信号
从时间序列数据中提取特征
使用 PCA 降维
使用 K-means 进行聚类

挑战：

有效处理大文件
识别相关信号聚类
处理主从票证之间的不同时间戳
选择适当的特征来聚类 ECU 通信模式

问题：

从 ECU 跟踪中聚类时间序列数据的有效技术是什么？
如何优化大型 .blf 和 .asc 文件的处理？
是否有适合汽车 CAN 总线数据的特定特征提取方法？
在此背景下验证聚类结果的好方法是什么？

任何见解、改进建议或资源都将不胜感激！
技术堆栈：Python、pandas、scikit-learn
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/652461/clustering-finding-patterns-in-tickets-analysing-vehicle-traces</guid>
      <pubDate>Wed, 07 Aug 2024 20:54:23 GMT</pubDate>
    </item>
    <item>
      <title>用于比较评论者的贝叶斯分层模型</title>
      <link>https://stats.stackexchange.com/questions/652465/bayesian-hierarchical-model-for-comparing-reviewers</link>
      <description><![CDATA[我正在撰写一篇关于评估人们专业知识的研究论文。
我有 21 位受访者，每人回答了 10 个问题。
现在我已要求 4 组评审员（每组由 3 人组成）对答案进行 1 到 5 之间的评分（5 分最高）。
我已使用 Fless&#39; Kappa 来测量同一组评审员之间的评审员间信度。
不幸的是，一位评审员要求我加入贝叶斯分层模型来解释评审员之间的差异，并提供评审员一致性的概率度量。这将使我们能够更细致地了解评审员的行为和人类判断中固有的不确定性，而当前方法中使用线性尺度过于简单化了这些不确定性。
在我看来，这过于复杂了。
我想检查来自不同背景的人是否可以评估同一主题的人。我不认为使用贝叶斯分层模型来比较评论者有什么好处。
我正在尝试执行此测试，但尽管如此，我还是想礼貌地回复评论者，这不是此模型的用例，Fleiss kappa 就足够了。
你能帮助我，或者证明我错了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652465/bayesian-hierarchical-model-for-comparing-reviewers</guid>
      <pubDate>Wed, 07 Aug 2024 19:59:16 GMT</pubDate>
    </item>
    <item>
      <title>我需要对 2 Ivs 和 2 DV 进行什么分析？</title>
      <link>https://stats.stackexchange.com/questions/652456/what-analysis-do-i-need-for-2-ivs-and-2-dvs</link>
      <description><![CDATA[我认为我需要 MANOVA，但我可能需要 ANCOVA，然后仅在实验组内进行 ANOVA。
我认为它是干预组内的 2x2 因子独立测量 ANOVA。我没有任何等价的句子可以用于 MANOVA，因为我之前从未写过 MANOVA
我有 2 个 IV：
IV1 有 2 个级别：对照组和干预组
IV2 是干预组中的个性特征，因为这是一个次要假设
我有 2 个相关的 DV：
DV1 是儿童自我评价的幸福感得分随时间的变化（1 个分数在实验开始时，另一个分数在实验结束时）
DV2 儿童父母评价的幸福感得分随时间的变化（1 个分数在实验开始时，另一个分数在实验结束时）
我可以将幸福感得分分为各种不同的子分数（希望、幸福、乐观、价值）
我的假设是：
H0- 实验组和对照组之间的幸福感改善随时间没有显著差异
H1- 与对照组相比，干预组的幸福感得分将显着改善
H2- 干预组的具体幸福感得分显着改善希望、幸福、乐观和价值
H3- 干预组的改善程度在具有特定人格特质的人中会更高。
我很高兴被告知我完全错了，因为我的论文的分析部分总是花费最长的时间来写，我感到完全迷失了。提前谢谢 :)

Chat GPT 说：
根据您的假设，此分析策略涉及使用 MANOVA、ANCOVA、ANOVA 和回归分析的组合来彻底评估您的干预效果和关于自然相关性的次要假设。
重新审视假设：
H1：使用 MANOVA 评估总体差异并跟进特定 DV 变化的 ANOVA。
H2：使用因子 ANOVA 评估子量表差异。
H3：使用干预组内的方差分析或回归分析自然相关性的影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/652456/what-analysis-do-i-need-for-2-ivs-and-2-dvs</guid>
      <pubDate>Wed, 07 Aug 2024 19:41:25 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用混合逻辑分析 DCE</title>
      <link>https://stats.stackexchange.com/questions/652448/analysing-dce-with-mixed-logit-in-r</link>
      <description><![CDATA[我正在通过调查进行离散选择实验 (DCE)。我的研究基于具有不同属性级别/类型的护肤产品。总共有四个属性（每个属性有 3 个级别/类型），我生成了 81 种不同的产品。我将它们分成 3 个不同的调查（每个调查有 9 个选择集，每个选择集有 3 种产品可供选择，受访者只能选择其中一种）。此外，他们还回答了有关他们的人口统计和对某些品牌（我在产品设计中使用的品牌）的熟悉程度的问题。这些是协变量（年龄组、收入组、居住地区、对 6 个不同品牌的使用熟悉程度）。
我以长格式扩展了数据（总共 2430 行，因为每个受访者考虑了超过 27 种具有不同属性级别的产品，总共有 90 名受访者）。我使用这段代码放入 mlogit 模型中：
expanded_data &lt;- expand_data %&gt;%
mutate(
Age = as.factor(Age),
Income = as.factor(Income),
Region = as.factor(Region),
CeraVe = as.factor(CeraVe),
Maybelline = as.factor(Maybelline),
LOreal = as.factor(LOreal),
LaMer = as.factor(LaMer),
Chanel = as.factor(Chanel),
Dior = as.factor(Dior),
Price = as.factor(Price),
Packaging = as.factor(Packaging),
Quality = as.factor(Quality),
Brand = as.factor(Brand),
ProductChoiceBinary = as.logical(ProductChoiceBinary)
)

mlogit_data &lt;- mlogit.data(expanded_data, 
choice = &quot;ProductChoiceBinary&quot;, 
shape = &quot;long&quot;, 
id.var = &quot;UniqueChoiceID&quot;, 
alt.var = &quot;ProductID&quot;)

complex_model &lt;- mlogit(ProductChoiceBinary ~ 价格 + 包装 + 质量 + 品牌 | 年龄 + 收入 + 地区 + CeraVe + Maybelline + LOreal + LaMer + Chanel + Dior, 
data = mlogit_data, 
random = ~ 价格 + 包装 + 质量 + 品牌 | UniqueChoiceID)

但是这个错误一直出现：“solve.default(H, g[!fixed]) 中的错误：Lapack 例程 dgesv：系统完全是奇异的：U[1,1] = 0”
我已经检查过没有多重共线性，这可能是数据结构的问题。但是，我的时间不多了，我真的需要结果。有人知道哪里出了问题，我该怎么办？
我不确定如何在此处上传我的结构图像。我的数据结构为 2430 行和 19 列（RespondentID、问题、产品、年龄、地区、收入、CeraVe、Maybelline、LOreal、LaMer、Chanel、Dior、ProductChoice、价格、包装、质量、品牌、ProductChoiceBinary、UniqueChoiceID）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652448/analysing-dce-with-mixed-logit-in-r</guid>
      <pubDate>Wed, 07 Aug 2024 14:52:46 GMT</pubDate>
    </item>
    <item>
      <title>Surpyval Weibull 拟合优度</title>
      <link>https://stats.stackexchange.com/questions/652447/surpyval-weibull-goodness-of-fit</link>
      <description><![CDATA[我一直在使用 surpyval 将一些校准数据拟合到威布尔分布。我想评估拟合优度，但我不知道该怎么做。我以前使用过“可靠性”库，它有一个 KS 检验，但我不知道如何在 Surpyval 中执行此操作（可靠性不支持区间删失数据）。代码：
import surpyval as surv
import matplotlib.pyplot as plt
#sample data
Fail = [1,1,3,1,5,1,1,2,1,1,1,1,1]
Type = [1,1,1,2,1,1,2,1,1,2,1,2,1,2,1]
Time = [1820,1987,2176,[2373.0, 2542.0],2373,2731,[2920.0, 3093.0],2920,3279,[3472.0, 3641.0],3472,[3829.0, 4009.0],3829]

model = surv.Weibull.fit(x = Time, c =类型，n = 失败)
model.plot()
plt.show()

libraries:
matplotlib 3.6.0
numpy 1.26.0
scipy 1.14.0
surpyval 0.10.10

包含完整数据集的图。
我的完整数据集有左、右和区间数据。任何其他拟合优度方法/知识都会非常有帮助，并且包括对图像的任何见解。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652447/surpyval-weibull-goodness-of-fit</guid>
      <pubDate>Wed, 07 Aug 2024 14:49:15 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 模型的群体稳定性指数 [重复]</title>
      <link>https://stats.stackexchange.com/questions/652443/population-stability-index-for-xgboost-model</link>
      <description><![CDATA[计算 XGBoost 模型的种群稳定性指数是否有意义？
我将原始值分为 2 到 5 组，并以此方式训练模型。
我认为，如果变量 1 有组 1、组 2 和组 3，一棵树可以拆分为 &gt;组 2，而另一棵树可以拆分为 &gt;**=**组 2。
这样，每棵树都可以对变量 1 进行不同的拆分，并且无法进行 PSI，否则就没有多大意义了。
这样对吗？
编辑：问题没有重复，在这里我问计算 PSI 是否有意义，另一个问题是如何进行计算。]]></description>
      <guid>https://stats.stackexchange.com/questions/652443/population-stability-index-for-xgboost-model</guid>
      <pubDate>Wed, 07 Aug 2024 13:55:48 GMT</pubDate>
    </item>
    <item>
      <title>具有给定标准差的样本的分布均值分布</title>
      <link>https://stats.stackexchange.com/questions/652435/distribution-of-the-mean-of-distributions-for-samples-with-a-given-standard-devi</link>
      <description><![CDATA[我有一个正态分布 $N(0, \sigma^2)$。如果我开始从该分布中选择所有分布 $N(\mu, \sigma^2/2)$，则平均值 $\mu$ 的分布参数是什么：$N(0, ?)$？标准差是多少？
换句话说，如果有一组 $N(\mu, \sigma^2/2)$ 分布，它们共同构成 $N(0, \sigma^2)$ 分布，那么 $\mu$ 的分布应该是什么？有两个极值点。如果我选​​择具有相同标准差 $\sigma^2$ 的分布，则会出现这种情况。在这种情况下，$\mu$ 的标准差将趋向于零，n-&gt;inf。如果我从 $N(0, \sigma^2)$ 中选择一个点，那么 $\mu$ 的标准差将等于 $\sigma^2$。]]></description>
      <guid>https://stats.stackexchange.com/questions/652435/distribution-of-the-mean-of-distributions-for-samples-with-a-given-standard-devi</guid>
      <pubDate>Wed, 07 Aug 2024 11:47:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么不使用FFT和使用FFT的自相关计算会给出不同的结果？</title>
      <link>https://stats.stackexchange.com/questions/651749/why-are-the-autocorrelation-computations-without-fft-and-with-fft-giving-differe</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651749/why-are-the-autocorrelation-computations-without-fft-and-with-fft-giving-differe</guid>
      <pubDate>Thu, 25 Jul 2024 14:36:20 GMT</pubDate>
    </item>
    </channel>
</rss>