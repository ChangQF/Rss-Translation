<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 30 Jan 2025 09:17:12 GMT</lastBuildDate>
    <item>
      <title>前瞻性和回顾性数据（研究设计）</title>
      <link>https://stats.stackexchange.com/questions/660754/prospective-and-retrospective-data-study-design</link>
      <description><![CDATA[我们正在开展一项关于癌症治疗中治疗转换效果的研究，旨在评估转换后 3 个月和 6 个月的结果。
几周前，我们开始前瞻性地收集患者数据，包括那些在基线时转换到新疗法的患者。然而，在研究正式开始之前，相当多的患者已经转换了疗法。为了增加样本量，我们希望前瞻性地跟踪这些早期患者，但他们的基线（转换时间）可能需要回顾性地进行评估。
值得注意的是，早期和晚期转换者的治疗方案和测量是相同的。
鉴于此，我们的关键问题是：

是否可以结合前瞻性和回顾性观察？
我们如何在纳入早期患者的同时最大限度地减少偏见？
您对改进我们的研究设计有什么建议吗？**

非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/660754/prospective-and-retrospective-data-study-design</guid>
      <pubDate>Thu, 30 Jan 2025 06:31:15 GMT</pubDate>
    </item>
    <item>
      <title>使用 Baum-Welch 进行 HMM 学习</title>
      <link>https://stats.stackexchange.com/questions/660753/hmm-learning-with-baum-welch</link>
      <description><![CDATA[我正在尝试从头开始为 HMM 学习实现 Baum-Welch 算法，我有两个问题：

我读到过，可以将数值优化应用于算法以减少运算次数，具体方法是消除期望最大化步骤中的分母。我相信这可以通过归纳法来证明，但我不确定如何正式处理它。有人可以提供一些见解或为我指出这方面的严格参考吗？

为了解决算法中的数值下溢，我们可以使用基于对数的计算或缩放。我的理解是前者速度较慢，但​​仍仅用于向后兼容。对数方法还有其他优势吗？会比缩放更受青睐吗？


提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660753/hmm-learning-with-baum-welch</guid>
      <pubDate>Thu, 30 Jan 2025 05:53:36 GMT</pubDate>
    </item>
    <item>
      <title>PCA 中的标准化与非标准化：它如何影响聚类结果？</title>
      <link>https://stats.stackexchange.com/questions/660752/standardization-vs-non-standardization-in-pca-how-does-it-affect-clustering-re</link>
      <description><![CDATA[我正在研究聚类，有一个问题，即在应用 PCA 之前是否要对数据进行标准化。当我不进行标准化时，轮廓得分为 47.5，而当我进行标准化时，它为 34。我还注意到，在标准化之前，百分比最高的特征向量来自具有最大值的变量。此外，当根据聚类查看多变量箱线图时，我可以观察到低幅度变量之间的更多差异。但是，当我进行标准化时，这些变量之间的差异变得不那么明显。即使变量的百分比范围相同，但有些变量的变异性比其他变量高得多。您能帮助我了解在这种情况下标准化是否必要以及标准化如何影响聚类结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660752/standardization-vs-non-standardization-in-pca-how-does-it-affect-clustering-re</guid>
      <pubDate>Thu, 30 Jan 2025 05:32:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么必须估计线性回归模型中的参数值？</title>
      <link>https://stats.stackexchange.com/questions/660750/why-must-the-values-of-the-parameters-in-a-linear-regression-model-be-estimated</link>
      <description><![CDATA[我不明白为什么在线性回归模型中无法找到参数 α 和 β 的真实值。为什么它们总是需要估计？
我读到它与包含其他变量的误差项有关（$x_2,x_3 ...$），但我并不完全理解。]]></description>
      <guid>https://stats.stackexchange.com/questions/660750/why-must-the-values-of-the-parameters-in-a-linear-regression-model-be-estimated</guid>
      <pubDate>Thu, 30 Jan 2025 04:46:11 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证来选择岭回归参数 $k$：如果 $\mathbf x_i$ 和 $y_i$ 的平均值在测试/训练集上可能为非零怎么办？</title>
      <link>https://stats.stackexchange.com/questions/660749/use-cross-validation-to-select-ridge-regression-parameter-k-what-if-mean-of</link>
      <description><![CDATA[考虑一个回归模型$$ Y= X\beta+ u.\tag{$\star$} $$
$Y$是一个长度为$n$的列向量，包含$n$个观测值。
$X$是一个$n\times p$矩阵，每行对应一个观测值，每列对应一个特征。
$\beta$是回归系数。
$u$是一个长度为$n$的列向量，包含误差。
对于参数为 $k&gt;0$ 的岭回归，$\beta$ 的估计值为 $$\hat\beta= (X^TX +kI)X^TY .$$
我知道正则化参数 $k$ 的选择可以通过交叉验证来选择，例如论文 变量选择与数据增强之间的关系以及预测方法。
我的问题是，假设我们使用十倍交叉验证，数据集的子集为 $S_1,\cdots, S_{10}$。
$(\star)$ 的右侧没有均值项 $\mu$ 的原因是数据 $X,Y$ 被标准化为具有零均值。
但是当应用交叉验证时（例如，使用 $S_{10}$ 进行测试，使用其他数据进行训练），
则 $\cup_{i=1}^9 S_i$ 中的 $\mathbf x_i$ 和 $y_i$ 的均值可能不为零。
$S_{10}$ 中的 $\mathbf x_i$ 和 $y_i$ 的平均值也可能为非零。
那么我们如何仍然使用公式 $$\hat\beta= (X^TX +kI)X^TY$$ 来计算 $\cup_{i=1}^9 S_i$ 上的 $\hat\beta$，以及使用 $$ \sum\nolimits_{(\mathbf x_i, y_i)\in S_{10}} \|y_i- \langle \hat\beta, \mathbf x_i \rangle\|^2 $$
作为测试集 $S_{10}$ 上的误差？
我认为均值项 $\mu$ 也应该考虑。]]></description>
      <guid>https://stats.stackexchange.com/questions/660749/use-cross-validation-to-select-ridge-regression-parameter-k-what-if-mean-of</guid>
      <pubDate>Thu, 30 Jan 2025 04:05:46 GMT</pubDate>
    </item>
    <item>
      <title>这是生态谬误吗？</title>
      <link>https://stats.stackexchange.com/questions/660748/is-this-the-ecological-fallacy</link>
      <description><![CDATA[
使用历史数据，我有一个模型，它根据一些个人特征/协变量告诉我单个单位在某个 $t$ 后存活的概率：

$$\hat{S}_j(t) = [\hat{S}_0(t)]^{\exp(x_j^{new^T}\hat{\beta})}$$

现在，$n$ 个新单位进来，我只有它们的预测因子（与之前相同的预测因子），即它们都还活着。
一般来说，每天要花费 $j$ 美元来维持这些 $n$ 个单位活着。
一旦单位不再活着，就不会产生任何相关成本。此外，单位死亡也不会产生任何相关成本。

我想估算一下这些 $n$ 单位明年会花多少钱。我正在尝试推导成本函数
使用预期值，我为每个新单元和所有新单元定义了一个预期成本函数（如果需要，我可以展示我的工作）：
$$E[\text{Cost}_i] = j\int_0^T tf_i(t)dt + jTS_i(T)$$
$$E[\text{Total Cost}] = \sum_{i=1}^n \left(j\int_0^T tf_i(t)dt + jTS_i(T)\right)$$
我不禁想到，我使用旧模型来估计新数据的成本，可能会陷入类似生态谬误的东西。这是因为我实际上是在为每个单独的单元恢复单独的生存函数，这可能会导致非常不稳定的预测。
例如，我认为如果我的历史模型非常简单（例如，仅包含 A 类与 B 类的预测变量），那么我可以使用这个旧模型来预测新数据中所有 A 类和所有 B 类的预期成本（即所有 A 类单元的单一生存曲线和所有 B 类单元的单一生存曲线……然后通过将它们相加来估算成本）。旧模型将有足够的 A 类与 B 类的成本和时间数据，因此可以更好地推断新数据。
但如果我开始在历史模型中包含更多变量，我感觉我会开始将自己局限在特定领域，历史模型将变得更适合仅提供对历史数据的推断，而不太适合新数据。
这是正确的想法吗？我是否陷入了生态谬误，或者我的做法是否正确？
我个人的观点是，我需要做一些探索性数据分析，看看旧数据与新数据的相似程度，然后决定历史模型是否适合新数据……但这不是一种明确的方法，我也不确定如何客观地做到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/660748/is-this-the-ecological-fallacy</guid>
      <pubDate>Thu, 30 Jan 2025 03:44:49 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中为不规则测量的功能数据制作功能箱线图？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660744/how-to-make-a-functional-boxplot-in-r-for-irregularly-measured-functional-data</link>
      <description><![CDATA[我有一个重复测量数值结果，其中结果是在不同时间点为每个患者测量的。
函数箱线图是可视化此类数据的一种方法，其中阴影区域表示曲线的中间 50% 以及第 10 和第 90 百分位数曲线（或您想要的任何百分位数）。
如何在 R 中为不规则测量的数据（即在每个患者的不同时间点测量结果）制作函数箱线图？我找到了一些 R 函数，但它们似乎要求在同一时间点对所有患者测量结果：

https://rdrr.io/cran/fda/man/fbplot.html

源论文：https://www.tandfonline.com/doi/abs/10.1198/jcgs.2011.09224


https://rdrr.io/cran/rainbow/man/fboxplot.html

来源论文：https://www.tandfonline.com/doi/abs/10.1198/jcgs.2009.08158



一种方法是将数据插入/归纳到一个共同的时间点网格中。但是，我不确定最好的方法是什么。
以下是一些您可以使用的示例数据：
# 设置可重复性的种子
set.seed(42)

# 患者人数
n_patients &lt;- 100

# 创建一个列表来存储每个患者的时间点和结果
time_points_list &lt;- list()
outcome_list &lt;- list()

# 为每个患者生成数据
for (i in 1:n_patients) {
# 每个患者的时间点的随机数（介于 5 和 10 之间）
n_time_points &lt;- sample(5:10, 1)

# 生成介于 0 和 1 之间的随机时间点（不规则时间点）
time_points &lt;- sort(runif(n_time_points, 0, 1))

# 生成结果数据（例如，带有随机噪声的正弦数据）
outcomes &lt;- sin(2 * pi * time_points) + rnorm(n_time_points, sd = 0.1) # 带有噪声的一些结果

# 将时间点和结果存储在列表中
time_points_list[[i]] &lt;- time_points
outcome_list[[i]] &lt;- results
}

# 现在，组装数据框，调整不同数量的时间点
patient_id &lt;- rep(1:n_patients, times = sapply(time_points_list, length)) # 按时间点数重复每个患者 ID
time_point &lt;- unlist(time_points_list) # 取消列出所有患者的时间点
outcome &lt;- unlist(outcome_list) # 取消列出所有患者的结果

# 将数据合并到数据框中
patient_data &lt;- data.frame(
patient_id =patient_id,
time_point =time_point,
outcome =outcome
)

# 查看数据集的前几行
head(patient_data)

``` 
]]></description>
      <guid>https://stats.stackexchange.com/questions/660744/how-to-make-a-functional-boxplot-in-r-for-irregularly-measured-functional-data</guid>
      <pubDate>Wed, 29 Jan 2025 23:15:30 GMT</pubDate>
    </item>
    <item>
      <title>赔率加倍和赔率之间有什么关系</title>
      <link>https://stats.stackexchange.com/questions/660741/what-is-the-relationship-between-doubling-your-chances-in-odds</link>
      <description><![CDATA[我正在向学生介绍赔率，我想展示概率和赔率之间的区别
我举的例子是一个游戏，如果你抛出公平的硬币并且至少有一个正面，你就赢了。我们可以通过抛 $n$ 枚硬币来增加获胜的机会。
$$
P(\text{Winning}) = 1 - \textrm{Binomial}(n = n, k = 0, p = .5)
$$



n
$P(\text{Winning})$
赔率




1
.5
1:1


2
.75
3:1


3
.875
7:1


4
.9375
15:1



我想向学生们展示从这个例子中可以清楚地看出，即使你抛两枚硬币，获胜的机会也不会翻倍。
我想讨论一下随着硬币数量的增加，赔率是如何变化的，并将其转化为我们如何看待外行人所说的“加倍机会”。
$$
Odds_{n+1} = 2* Odds_{n} + 1
$$
当我们有 1 枚硬币到 2 枚硬币时，我们获胜的机会就会翻倍，也就是大约翻倍了我们的赔率。额外的硬币会继续使我们的赔率翻倍。
但是当我们有 2 枚硬币到 4 枚硬币时，我们的机会就会翻倍，但这不会导致赔率翻倍。我可能遗漏了更高的关系，无法将赔率转化为增加获胜机会的想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660741/what-is-the-relationship-between-doubling-your-chances-in-odds</guid>
      <pubDate>Wed, 29 Jan 2025 21:36:07 GMT</pubDate>
    </item>
    <item>
      <title>干预后测试群体的相似性 - 收敛还是方差？</title>
      <link>https://stats.stackexchange.com/questions/660725/testing-a-groups-similarity-after-an-intervention-convergence-or-variance</link>
      <description><![CDATA[我感兴趣的是测试一个群体在干预后是否变得更加相似。例如，假设我有一个连续变量干预前后的分数列表，该连续变量被合理地假设为正常。我感兴趣的是看看在经历这次干预后，这个群体是否变得更加相似。我不需要知道他们的平均值是否发生了变化，但我认为我需要了解的是他们的变异是如何变化的。（因此，如果我预期的结果已经实现，那么干预后该群体的方差就会减小，这表明该群体在结果变量上已经在某种程度上趋向于相似的分数）。
我最初的想法是 (1) 通过将参与者视为“评估者”并查看干预后的 ICC 是否比干预前更高来建立某种类间相关性。或者，(2) 方差分析来检验两组之间的差异。
与本论坛的许多人相比，我的统计知识相对有限 - 因此，如果您能提供任何链接或参考资料，以便我可以进一步阅读建议的方法，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660725/testing-a-groups-similarity-after-an-intervention-convergence-or-variance</guid>
      <pubDate>Wed, 29 Jan 2025 16:08:10 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中 ELBO 推导的澄清</title>
      <link>https://stats.stackexchange.com/questions/660708/clarification-on-the-elbo-derivation-in-diffusion-models</link>
      <description><![CDATA[我正在阅读一篇关于去噪扩散模型的论文，第 10 页有以下 ELBO 推导。
$$
\begin{aligned}
\log p(\mathbf{x}_0) &amp;= \log \int p(\mathbf{x}_{0:T}) \, d\mathbf{x}_{1:T} \\
&amp;= \log \int \frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} q(\mathbf{x}_{1:T} | \mathbf{x}_0) \, d\mathbf{x}_{1:T} \\
&amp;= \log \mathbb{E}_{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \left[ \frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \right] \\
&amp;\geq \mathbb{E}_{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \right] \\
&amp;= \mathbb{E}_{q(\mathbf{x}_{1:T} | \mathbf{x}_0)} \left[ \log \frac{p(\mathbf{x}_T) \prod_{t=1}^{T} p_\theta (\mathbf{x}_{t-1} | \mathbf{x}_t)}{\prod_{t=1}^{T} q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right]
\end{aligned}
$$
我只是想澄清一下几件事。$x_0$ 是随机变量 $X_0$ 的实现吗？如果是，$q(x_{0:T})$ 是否意味着 $x_0$ 是实现，而其余的 $x_{1:T}$ 是随机变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/660708/clarification-on-the-elbo-derivation-in-diffusion-models</guid>
      <pubDate>Wed, 29 Jan 2025 11:54:19 GMT</pubDate>
    </item>
    <item>
      <title>非参数方法检查观测值是否与平均值不同</title>
      <link>https://stats.stackexchange.com/questions/660705/non-parametric-method-to-check-if-observations-are-different-than-mean</link>
      <description><![CDATA[我有一个随机变量的独立观测列表，我想检查这个变量的平均值是否与某个固定数字不同。我该怎么做？
分布不一定是正态的，甚至不是对称的。
有人建议我使用置换检验，但阅读更多内容后，我明白它是用来比较两个分布，而不是一个分布和一个固定数字。虽然我可以说另一个分布是固定的，但这不会有问题吗，因为方差当然是不同的？我的意思是，我想知道这个测试是否可以发现方差而不是平均值的差异，这不是我想要的。]]></description>
      <guid>https://stats.stackexchange.com/questions/660705/non-parametric-method-to-check-if-observations-are-different-than-mean</guid>
      <pubDate>Wed, 29 Jan 2025 10:39:34 GMT</pubDate>
    </item>
    <item>
      <title>Somers 的二元结果 D，Python 与 SAS</title>
      <link>https://stats.stackexchange.com/questions/660697/somers-d-for-binary-outcome-python-vs-sas</link>
      <description><![CDATA[我正在尝试在编程语言之间迁移。 SAS 和 Python 似乎对 Somers&#39; D 的定义并不一致。在此示例中，x 被视为独立变量，而 y 是二元结果（因变量）。
以下是使用 scipy.stats.somersd 计算 Somers&#39; D 的 Python 代码片段，并与精心手动计算的 Somers&#39; D 进行交叉检查，结果为
$$\frac{C-D}{C+D+T},$$
其中 $C$、$D$ 和 $T$ 分别是一致、不一致和并列对的数量：
import scipy

def manual_somers_d(x, y):
# 初始化计数
C = 0
D = 0
T_Y = 0

# 计算 X 和 Y 中的一致、不一致对和关系
for i in range(len(x)):
for j in range(i + 1, len(x)):
if x[i] &lt; x[j] and y[i] &lt; y[j]: # 一致
C += 1
elif x[i] &gt; x[j] and y[i] &gt; y[j]: # 一致
C += 1
elif x[i] &lt; x[j] and y[i] &gt; y[j]: # 不一致
D += 1
elif x[i] &gt; x[j] and y[i] &lt; y[j]: # 不一致
D += 1
elif y[i] == y[j] and x[i] != x[j]: # Y 中一致（但 X 中不一致）
T_Y += 1

# 计算 Somers 的 D
return (C - D) / (C + D + T_Y)

x = [1,2,3,4,5]
y = [0,1,0,1,1]

print(manual_somers_d(x, y))
print(scipy.stats.somersd(x, y).statistic)

两种计算均得出相同结果 (0.4)。
但是，当针对同一数据集移至 SAS 时，计算结果将返回 Somers 的 D 值 2/3：
数据示例;
输入 x y;
数据线;
1 0
2 1
3 0
4 1
5 1
;
运行;

proc logistic data=example;
model y = x;
ods output Association=assoc;
运行;

proc print data=assoc;
运行;

顺便说一句，这与上面代码中计算 scipy.stats.somersd(y,x) 相同（切换变量）
一些观察：

文档 scipy.stats.somersd 指出 (x,y) 是 y 依赖于 x 的正确顺序。
模型语句文档 (SAS) 指出 model y = x 表达了相同的意思。

我在文档中遇到了错误吗？为什么值不匹配？]]></description>
      <guid>https://stats.stackexchange.com/questions/660697/somers-d-for-binary-outcome-python-vs-sas</guid>
      <pubDate>Wed, 29 Jan 2025 07:58:34 GMT</pubDate>
    </item>
    <item>
      <title>比较偏好与 3 个价值观（包括中性）的差异</title>
      <link>https://stats.stackexchange.com/questions/660691/comparing-differences-in-preference-with-3-values-including-neutral</link>
      <description><![CDATA[比较包括中性在内的 3 个值的偏好差异
场景：分析具有 3 个值的偏好数据（例如：您更喜欢哪个：足球、棒球还是没有偏好（即中性）？）
主要研究问题：

是否大于中性？
足球比棒球更受欢迎还是反之亦然？

奇怪的是，与连续数据不同，我没有看到很多关于这种情况的强烈建议。
我的问题是：
哪种统计数据最适合分析具有 3 个值（例如足球、中性、棒球）的偏好数据？
如果答案依赖于“弥补”预期值（例如，将响应分为 3 个值（33%，33%，33%），那么您建议使用什么值（或它们的计算）？（注意：我不喜欢 33%，33%，33%，因为不喜欢任何一个与喜欢其中一个的结果不同（参见上述主要研究问题）。
其他注意事项：
只是指出它不是因子设计（就像我们比较 2 个成功率，例如球队 1 的胜/负与球队 2 的胜/负），所以我们不能通过“平均”足球和棒球的成功来计算预期值。
我的数据集中的响应数量可能非常低。在一个例子中，当足球 = 12 和棒球 = 13 时，卡方显着。
McNemar 检验：Sauro/MeasuringU 推荐此检验。虽然它适用于名义变量，它采用 2x2 形式，并带有成对样本（重复测量）。因此，他的建议似乎适用于其他场景。
我考虑过的选项：
选项 A1 - 中性预期 = 观察值
首先，目测（或置信区间）中性和足球/棒球之间的差异。
其次，将中性预期值设置为等于观察值。将剩余的预期值分为足球和棒球（50/50 分割）以“删除”中性，但保持样本量。 （例如，见图片）



偏好
观察到的
预期的




足球
36
(58/2) =29


中立
42
42


棒球
22
(58/2) =29



一个问题似乎是统计数据本身，因为尝试解释它确实很棘手。就像，“在消除中性反应的影响后，参与者对足球和棒球的偏好不同（或没有不同）。”
选项 A2。中性与其他以及中性预期 = 观察到
除了上面的第一步，要么 (A2a) 取足球和棒球中较大的一个，(A2b) 将足球和棒球加在一起，看看它们加起来是否不同于中性，或者 (A2c) 取足球和棒球的平均值，看看该平均值是否不同于中性。一个问题是 A2a、A2b 和 A2c 的可解释性是……它们很难解释和/或需要大量语言来解释。然后使用上面的第二步。因此，可解释性问题与 A1 相同。
选项 B1 - 置信区间与预期值的重叠[不完整的解决方案]
计算置信区间并与预期值进行比较。与上述问题相同：如何计算对 3 个值有意义的预期值（我认为 33,33,33 不是）。那么预期值是什么？
选项 B2 - 置信区间与 3 个观察值的重叠
类似于使用置信区间来目测连续数据之间的差异
选项 C。您的建议！
想法、意见、建议？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660691/comparing-differences-in-preference-with-3-values-including-neutral</guid>
      <pubDate>Wed, 29 Jan 2025 02:28:17 GMT</pubDate>
    </item>
    <item>
      <title>具有 beta geom 分布分位数函数的 CDF</title>
      <link>https://stats.stackexchange.com/questions/660681/cdf-with-beta-geom-distribution-quantile-function</link>
      <description><![CDATA[我有一个带 CDF 的 beta 几何 (BG) 分布：
$$F(x) = \Bigg( 1 - \frac{\text{B}(a,b+x)}{\text{B}(a,b)} \Bigg)
\quad \quad \quad 
\text{for } x \geqslant 0,$$
其中 $\text{B}$ 是 beta 函数。有没有办法在不借助数值方法和求根算法的情况下找到上述分布的分位数。我知道 beta 分布与 F 分布相关，我正在尝试看看我们是否可以找到与 BG 分布的类似关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/660681/cdf-with-beta-geom-distribution-quantile-function</guid>
      <pubDate>Tue, 28 Jan 2025 20:03:16 GMT</pubDate>
    </item>
    <item>
      <title>$\ell_1$ 惩罚分位数回归的收敛速度为 $\sqrt{\frac{s\log (p \vee n)}{n}}$</title>
      <link>https://stats.stackexchange.com/questions/660611/rate-of-convergence-of-ell-1-penalized-quantile-regression-is-sqrt-fracs</link>
      <description><![CDATA[在标准 LASSO 文献中，您经常会遇到 LASSO 估计量以 $\sqrt{\frac{s\log p}{n}}$ 的速率收敛（例如，参见此帖子）。
一种相关方法是 $\ell_1$ 惩罚分位数回归，这意味着您将 $\ell_1$ 惩罚（如在 Lasso 中）添加到分位数回归损失。这样，你就可以估算给定$X$的$Y$的条件分位数，同时将一些系数缩小为零以用于变量选择或正则化目的。设置如下：
$$
\hat{\beta} = \arg \min_{\beta} \sum_{i=1}^n \rho_\tau (y_i - x_i^\top \beta) + \lambda \|\beta\|_1,
$$
其中

$\rho_\tau(u) = u(\tau - \mathbb{I}\{u &lt; 0\})$ 是分位数损失，调整残差的权重，
$\lambda$ 控制惩罚强度，
$\|\beta\|_1 = \sum_{j=1}^p |\beta_j|$ 是鼓励稀疏性的 $\ell_1$-惩罚。

此方法理论的主要参考文献是 Belloni 和 Chernozhukov (2011) 在《统计年鉴》中。
在他们的论文中（例如，请参阅摘要、第 2.6 节或定理 2 了解完整结果），他们提到估计量以 $\sqrt{\frac{s\log (p \vee n)}{n}}$ 的速率收敛，其中 $\vee$ 用于表示 $p$ 和 $n$ 中的最大值。它们甚至可以在一组紧凑的分位数指标上均匀地实现这一结果。
因此，与标准 LASSO 速率相比，我们现在可以看到对数中有 $p \vee n$。对于许多有趣的制度，即 $p &gt; n$，这将给出与标准 LASSO 相同的速率。
有人知道为什么现在 $p$ 和 $n$ 存在最大值吗？任何见解都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660611/rate-of-convergence-of-ell-1-penalized-quantile-regression-is-sqrt-fracs</guid>
      <pubDate>Mon, 27 Jan 2025 14:01:25 GMT</pubDate>
    </item>
    </channel>
</rss>