<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 20 Nov 2024 18:23:27 GMT</lastBuildDate>
    <item>
      <title>ECM：添加 I(0) 变量</title>
      <link>https://stats.stackexchange.com/questions/657571/ecm-adding-i0-variable</link>
      <description><![CDATA[我有一个 ECM 模型，其中长期关系是 $y$ 和 $x_1$ 之间的关系，它们都是 I(1) 且是协整的，即
$y(t) = a + b.x_1(t) +\epsilon(t)$
对于这个长期关系，我想添加 $x_2$，即 I(0)。将 $x_2$ 添加到短期响应中是没有意义的。业务逻辑表明 $x_2$ 应该影响 $y$，而不是 $\Delta y$。换句话说，如果没有 $x_1$，$y$ 将由 $x_2$ 驱动，在这种情况下 $y$ 将为 I(0)。构建没有 $x_2$ 的模型是没有意义的，而包括 $x_2$ 是短期响应也是没有意义的。直觉是 $x_2$ 影响 $y$。所以我专注于长期方程。
从数学上讲，
$y(t) = a + b.x_1(t) + c.x_2(t) + \mu(t)$
听起来正确。$y$ 和 $x_1$ 是协整的，因此添加 $x_2$ 应该不会产生影响。残差仍为 I(0)。这与教科书/经典 ECM 框架背道而驰，所以我的问题是：

您认为这种类型的方程有什么问题吗？
我在哪里可以找到有关该主题的文献？文献重点关注 I(1) 过程，我找不到有关添加 I(0) 变量的参考资料。
或者，我可以用 $x_1$ 构建 LT，然后将残差 $\epsilon$ 回归到 $x_2$（两者都是 I(0)），然后转到短期分量吗？这样做，什么会是错误的？
您会建议什么替代方法？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657571/ecm-adding-i0-variable</guid>
      <pubDate>Wed, 20 Nov 2024 17:58:00 GMT</pubDate>
    </item>
    <item>
      <title>熵平衡入门</title>
      <link>https://stats.stackexchange.com/questions/657570/primer-on-entropy-balancing</link>
      <description><![CDATA[我搜索了互联网，但无论如何也找不到关于熵平衡的全面入门书。
我目前正在清理数据，以便为队列研究中的那部分人群创建权重，我将对其进行分析。我目前正在玩弄 R 中的 WeightIt 包。小插图包含一些很棒的信息，但我正在寻找更多信息。
我对这个过程有几个一般性的问题，例如：

我的主要“问题”是，我可以访问无数的全民登记数据（教育、社会经济地位、生活条件、精神病诊断、医生就诊等）。所以我不确定最好包括哪些内容以及如何操作变量（以及哪些可能是多余的甚至有害的）。本质上：这里有任何可以指导我的过程的一般技巧吗？

包括许多变量（最终会导致更多具有 NA 的行）和选择较少的变量（许多 NA 似乎会导致权重的方差较大）之间的权衡是什么。

如何交叉验证权重？我正在考虑查看队列样本是否与一系列变量的总体具有相似的相关性。

还有其他方法可以评估权重的表现如何吗？


我知道这些问题最终必须由我在研究的背景下解决，但这就是我寻找一些可以帮助我指导过程的入门知识的原因。
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657570/primer-on-entropy-balancing</guid>
      <pubDate>Wed, 20 Nov 2024 17:39:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么嵌套方差分析之间的 f 统计量会发生变化？</title>
      <link>https://stats.stackexchange.com/questions/657568/why-does-the-f-statistic-change-between-nested-anovas</link>
      <description><![CDATA[我对方差分析表中 p 值的理解是，它给出了在一系列越来越大的模型中附加预测因子的重要性。因此，我期望在具有 2 个预测因子的模型上运行的方差分析表的前 2 行与使用相同数据和第 3 个预测因子运行的方差分析表的前 2 行相同。但是 R 的 anova.lm 做了一些不同的事情：
+ n &lt;- 10
+ y &lt;- rnorm(n)
+ X &lt;- matrix(rnorm(3*n),ncol=3)
+ anova(lm(y~X[,1] + X[,2]))
+ anova(lm(y~X[,1] + X[,2] + X[,3]))
+
方差分析表

响应：y
Df 总和 平方 均值 平方 F 值 Pr(&gt;F)
X[, 1] 1 0.3082 0.3082 0.1901 0.6760
X[, 2] 1 3.3563 3.3563 2.0704 0.1934
残差 7 11.3473 1.6210
&gt; 方差分析表

响应：y
Df 总和 平方 均值 平方 F 值 Pr(&gt;F)
X[, 1] 1 0.3082 0.3082 0.1631 0.7003
X[, 2] 1 3.3563 3.3563 1.7767 0.2309
X[, 3] 1 0.0131 0.0131 0.0069 0.9363
残差 6 11.3342 1.8890

第二张表第二行的 F 统计量来自哪里？平方和与 df 与第一个表中的相同，因此 F 统计量的分母在两个表中必须不同。如果两者都只是在包含 $\beta_0$ 和 $\beta_1$ 的模型中测试 $\beta_2=0$，那为什么会这样呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/657568/why-does-the-f-statistic-change-between-nested-anovas</guid>
      <pubDate>Wed, 20 Nov 2024 17:01:52 GMT</pubDate>
    </item>
    <item>
      <title>从概率密度函数到总体简单线性回归函数的转变[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657566/the-shift-from-the-probability-density-function-to-the-population-simple-linear</link>
      <description><![CDATA[从概率密度函数转换为总体简单线性回归函数时：

β 如何从函数的展开转换为函数的斜率？

x_i 如何从 DV 值集转换为 IV 值集？

α 如何从 PDF 的起点转换为总体简单线性回归函数中的点截距？


注释：

总体简单线性回归函数：
]]></description>
      <guid>https://stats.stackexchange.com/questions/657566/the-shift-from-the-probability-density-function-to-the-population-simple-linear</guid>
      <pubDate>Wed, 20 Nov 2024 16:25:32 GMT</pubDate>
    </item>
    <item>
      <title>这是什么意思：“OLS 比 GLS 更为稳健”？</title>
      <link>https://stats.stackexchange.com/questions/657565/what-does-this-mean-ols-is-more-robust-than-gls</link>
      <description><![CDATA[我正在读一本书，书中写道：

当误差不遵循 OLS 假设时，OLS 是一致的，并且
通常比 GLS 更稳健...&quot;

我知道稳健回归 - 我们抑制异常值影响的回归（通常用于$y$来自重尾分布的情况）。
OLS 比 GLS 更稳健是什么意思？]]></description>
      <guid>https://stats.stackexchange.com/questions/657565/what-does-this-mean-ols-is-more-robust-than-gls</guid>
      <pubDate>Wed, 20 Nov 2024 16:00:57 GMT</pubDate>
    </item>
    <item>
      <title>对于前测/后测设置，我应该使用原始分数、标准分数还是标准分数来进行学生 t 检验？</title>
      <link>https://stats.stackexchange.com/questions/657564/for-a-pre-test-post-test-setting-should-i-use-the-raw-score-the-scaled-score-o</link>
      <description><![CDATA[我有点迷茫。我正在做一个旨在评估教育干预效果的项目。为此，在干预前后对同一组进行标准化测试（前测/后测）。样本很小，只有 35 个人。问题是测试有三种类型的分数：原始分数、量表分数和标准分数（取决于学生的年龄）。我计划进行 Shapiro-Wilk 检验来评估数据的正态性。如果分布为正态，我将使用学生 t 检验来评估干预的有效性，但我不确定我会使用什么分数：原始分数、量表分数还是标准分数？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/657564/for-a-pre-test-post-test-setting-should-i-use-the-raw-score-the-scaled-score-o</guid>
      <pubDate>Wed, 20 Nov 2024 15:31:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 MC 估计得出一个期望大于另一个期望的概率</title>
      <link>https://stats.stackexchange.com/questions/657563/probability-that-one-expectation-is-larger-than-another-expectation-using-mc-est</link>
      <description><![CDATA[考虑一个期望$a=\int f(\boldsymbol{x})p(\boldsymbol{x})d\boldsymbol{x}$和一个期望$b=\int g(\boldsymbol{x})q(\boldsymbol{x})d\boldsymbol{x}$。
对于给定的少量样本$f(\boldsymbol{x}_i), \boldsymbol{x}_i \sim p(\boldsymbol{x})$和$g(\boldsymbol{x}_j), \boldsymbol{x}_j \sim q(\boldsymbol{x})$，是否存在非参数方法来计算概率$P(b&gt;a)$?]]></description>
      <guid>https://stats.stackexchange.com/questions/657563/probability-that-one-expectation-is-larger-than-another-expectation-using-mc-est</guid>
      <pubDate>Wed, 20 Nov 2024 15:10:32 GMT</pubDate>
    </item>
    <item>
      <title>多项式 glm(m)，其预测因子随项目/响应组合而变化</title>
      <link>https://stats.stackexchange.com/questions/657562/multinomial-glmm-with-predictors-varying-over-item-response-combinations</link>
      <description><![CDATA[我有多项数据，其中有 4 个项目（类别）和许多响应。对于每个响应，多项的大小可以超过一（即响应可能是 c(10,20,3,0)）。
我想要拟合的预测因子可能仅随项目而变化，也可能随项目/响应组合而变化。MCMCglmm 可以通过使用索引项目级别的术语“特征”以简单的方式拟合此类模型。但是，数据集很大（&gt;400 万个响应），因此非 MCMC 方法会更好。
有谁知道可以拟合此类模型的 R 包 - 最好也具有随机效应。]]></description>
      <guid>https://stats.stackexchange.com/questions/657562/multinomial-glmm-with-predictors-varying-over-item-response-combinations</guid>
      <pubDate>Wed, 20 Nov 2024 14:16:44 GMT</pubDate>
    </item>
    <item>
      <title>如何从回归模型中消除由于共线性和多重共线性（线性、泊松和负二项式）引起的变量</title>
      <link>https://stats.stackexchange.com/questions/657561/how-to-eliminate-variables-from-regression-models-due-to-collinearity-and-multic</link>
      <description><![CDATA[由于相关性值较高，我试图从回归模型（线性、泊松和负二项式）中消除变量。R 代码如下
pairs.panels(a12, cex.cor = 4, cex.labels = 4, cex.axis = 2, method = &quot;pearson&quot;)
pairs.panels(a12, cex.cor = 4, cex.labels = 4, cex.axis = 2, method = &quot;spearman&quot;)
pairs.panels(a12, cex.cor = 4, cex.labels = 4, cex.axis = 2, method = &quot;Kendall&quot;) 

因为我的变量值不遵循正态分布，所以我主要考虑 Spearman 方法中的值。我看到一个值高于 0.7（例如 0.77），还有一些值高于 0.6。
我不确定我对消除变量的方法的想法是否正确。
我会的

我将删除与我的目标变量（响应、因变量）具有较低相关值的变量（两个相关变量之间）
我使用 AIC 和 BIC 来查找具有最佳值的模型（最低 AIC、BIC）
我应用 LASSO、贝叶斯模型平均（BMA 包）、统计等效签名（SES、MXM 包）
我还在这里找到了一个有趣的信息：https://www.statalist.org/forums/forum/general-stata-discussion/general/650016-decide-which-variables-to-be-omitted-in-ols-regression

您有什么参考或意见可以给我吗？我对上述这些方法不太确定]]></description>
      <guid>https://stats.stackexchange.com/questions/657561/how-to-eliminate-variables-from-regression-models-due-to-collinearity-and-multic</guid>
      <pubDate>Wed, 20 Nov 2024 14:11:19 GMT</pubDate>
    </item>
    <item>
      <title>使用整个人口统计数据时，p 值、置信区间和标准误差是否仍然相关？[重复]</title>
      <link>https://stats.stackexchange.com/questions/657560/when-using-entire-population-statistics-are-p-values-confidence-intervals-and</link>
      <description><![CDATA[我正在使用 OLS 回归分析 UNCITRAL 下的全套仲裁案件（整个总体，而不仅仅是样本）。由于我拥有每个案件的数据，我想知道 p 值（$p$）、置信区间（$CIs$）和标准误差（$SE$）等传统指标是否仍然有意义。这些指标是否仅适用于样本数据，还是在处理整个总体时仍然有用？如果不是，那么在这种情况下解释结果的最佳方法是什么？
此外，如果我的模型中有时间固定效应，这重要吗？
请注意，我不想谈论未来案件，只想解释一些历史结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/657560/when-using-entire-population-statistics-are-p-values-confidence-intervals-and</guid>
      <pubDate>Wed, 20 Nov 2024 13:41:15 GMT</pubDate>
    </item>
    <item>
      <title>使用样条和交互作用在 Cox 回归中设置参考</title>
      <link>https://stats.stackexchange.com/questions/657559/setting-a-reference-in-cox-regression-with-splines-and-interaction</link>
      <description><![CDATA[我运行一个 cox 回归，其中连续变量为年龄，分类变量为性别。该模型包括连续变量的样条线和两者之间的相互作用。我想选择参考点，即相对风险为 1 的预测因子组合。让我们选择 80 岁和女性作为参考。目前我做了以下事情：

我对两种性别的 age 范围进行预测，并将它们保存在名为 pred 的对象中。
我对 80 岁的女性进行预测，并将它们保存在名为 ref 的对象中。
我从 pred 中减去 ref，并将结果保存为 pred_adjusted。
我使用 exp(pred_adjusted) 计算指数函数，以获得点估计以及置信区间。

在 R 中，它看起来像这样：
library(survival); library(splines)
# 拟合模型。
fit &lt;- coxph(Surv(futime, death) ~ sex * ns(age, 3), data= flchain)
# 预测范围和要预测的组。
data_new &lt;- expand.grid(age= seq(min(flchain$age), max(flchain$age), 1), sex= levels(flchain$sex))
# 预测。
pred &lt;- predict(fit, data_new, se= TRUE)
# 计算置信区间。
pred &lt;- pred$fit + outer(pred$se, c(0, -1.96, 1.96), &#39;*&#39;)
# 预测参考。
ref &lt;- predict(fit, newdata= data.frame(sex=&quot;F&quot;, age= 80))
# 减去并 exp()。
res &lt;- exp(pred-ref)

结果数据如下所示：

正如预期的那样，80 岁女性的相对风险为 1。尽管如此，我不确定这是否是设置参考的方法。我读过这个，但它使用了survival::pspline，出于某些原因我不想使用它。使用survival::pspline的方法与splines::ns完全不同，结果也略有不同，因此，我无法从源头推断我是否正确。我也读过这个，但它涵盖了一个更简单的情况。因此，我不确定我的做法是否正确。任何帮助都感激不尽！
该图是使用此代码绘制的：
plot_data &lt;- cbind.data.frame(data_new, setNames(data.frame(exp(pred-ref)), nm= c(&quot;fit&quot;, &quot;lower&quot;, &quot;upper&quot;)))
library(ggplot2)
ggplot(plot_data, aes(x= age, y= fit)) +
geom_line(aes(col= sex)) +
geom_ribbon(aes(ymin= lower, ymax= upper, fill= sex), alpha= .1) +
scale_y_continuous(trans= &quot;log10&quot;) +
labs(y= &quot;Relative risk (axis log10 scaled)&quot;) +
geom_hline(yintercept= 1, lty= 2）
]]></description>
      <guid>https://stats.stackexchange.com/questions/657559/setting-a-reference-in-cox-regression-with-splines-and-interaction</guid>
      <pubDate>Wed, 20 Nov 2024 13:39:39 GMT</pubDate>
    </item>
    <item>
      <title>因果中介分析、中介变量和 CMAverse</title>
      <link>https://stats.stackexchange.com/questions/657558/causal-mediation-analysis-mediators-and-cmaverse</link>
      <description><![CDATA[我正在开展一项非随机研究，以评估两种治疗方法之间并发症发生率的差异。观察到的两组并发症发生率差异很大（22% vs. 50%）。为了解释潜在的混杂因素，我实施了多变量二项逻辑回归。使用有向无环图 (DAG) 根据临床情况确定潜在混杂因素。在收集的变量中，我还确定了三个潜在介质：胆囊切除术、全身麻醉 和 治疗方法。所有这些都是分类变量（胆囊切除术和全身麻醉是二元变量，而治疗方法有三个级别）。尽管它们与治疗有显著相关性（Fisher 精确检验 p &lt; 0.05），但只有胆囊切除术与并发症有很强的相关性（Fisher 精确检验 p &lt; 0.01）。
问题 1：即使这些变量与我的人群的结果没有统计学相关性，我是否可以将所有这些变量都视为中介变量？
问题 2：胆囊切除术与一种治疗高度相关（除一例外，所有病例均发生在对照组中）。我还能将其视为中介变量吗？如果不是，那么将其排除在中介分析之外的正确方法是什么？
我尝试使用 R 包 CMAverse 实施中介分析，但当我将胆囊切除术作为中介时，估计值过高。
以下是中介分析的代码：
mediators_used &lt;- c(&quot;General_Anesthesia&quot;, &quot;cholecystectomy&quot;, &quot;treatment_approach&quot;)
mreg &lt;- list(&quot;logistic&quot;, &quot;logistic&quot;, &quot;multinomial&quot;) 
mval &lt;- list(&quot;Yes&quot;, &quot;Yes&quot;, &quot;Open&quot;) 

# 10 个引导用于说明
mediator_analysis &lt;- cmest(data = mediator_df, 
model = &quot;rb&quot;, 
exposure = &quot;Treatment_type_tumor_near_gallbladder&quot;, 
outcome = &quot;complications&quot;, 
mediator = mediators_used,
basec = c(&quot;Treatment_type_tumor_near_gallbladder&quot;, &quot;sex&quot;, &quot;comorbidities&quot;, &quot;Systemic_treatment_prior_local_treatment&quot;, &quot;Segments_treated_per_session&quot;, &quot;Metastasis_size_at_treatment_mm&quot;, &quot;min_distance_gallblad_mm&quot;), # &quot;ASA&quot;, &quot;age&quot;, &quot;bmi&quot;, &quot;stage_binary&quot; （删除高相关性）
EMint = TRUE，# 表示存在暴露-介质相互作用的逻辑值
mreg = mreg，
yreg = “logistic”，
yval = list（“Yes”），# 估计因果关系对风险/比值比量表的影响的结果值（当结果为分类时使用）
astar = “Resection”，# 暴露的控制值。
a = “MWA”，# 暴露的有效值。
mval = mval，# 指定介质中每个变量的值的列表，变量受控制
estimation = “imputation”，
inference = “bootstrap”，
nboot = 10，# 增加到 100 或 200
multimp = TRUE，
args_mice = list(maxit = 50，method = &quot;polyreg&quot;, seed = 123)
)

提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/657558/causal-mediation-analysis-mediators-and-cmaverse</guid>
      <pubDate>Wed, 20 Nov 2024 13:29:22 GMT</pubDate>
    </item>
    <item>
      <title>如何在多重插补数据集中执行 1：n 匹配？</title>
      <link>https://stats.stackexchange.com/questions/657557/how-to-perform-1n-matching-in-a-multiple-imputation-data-set</link>
      <description><![CDATA[我使用 R 中的 MatchThem 包来匹配多重插补数据集，
m.out &lt;- 
matchthem(follow ~ sex + age_at_onset + ……,
data = imputed_data,
approach = &quot;across&quot;,
method = &quot;nearest&quot;,
ratio = 2
)

但是，我发现 MatchIt 中的 ratio 参数在这里无效 - &quot;警告：参数 &#39;ratio&#39; 未与 &#39;method = NULL&#39; 一起使用，将被忽略。&quot;
我的数据集中的曝光（即 &quot;follow&quot;）比率为 655:1189，因此我需要匹配几乎1:2。不这样做将导致大量宝贵样本的损失。是否可以在MatchThem或其他地方进行1:n匹配？如果没有自动化软件工具，我会考虑重新采样数据集以构建1：1数据集然后进行匹配。这可行吗？
顺便说一句，我发现我也无法调整匹配的严格性，即卡尺。
有人有处理这两个问题的经验吗？
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657557/how-to-perform-1n-matching-in-a-multiple-imputation-data-set</guid>
      <pubDate>Wed, 20 Nov 2024 13:05:46 GMT</pubDate>
    </item>
    <item>
      <title>差异分析中的结果水平 vs 治疗水平 vs 固定效应水平</title>
      <link>https://stats.stackexchange.com/questions/657555/outcome-level-vs-treatment-level-vs-fixed-effects-level-in-difference-in-differe</link>
      <description><![CDATA[我对应该在事件研究（Callaway 和 Santanna 2021）规范中包含哪些控制措施感到有些困惑。
我的一个模型试图了解公共设施的开放（治疗是市政级别的）对市政级别结果的影响。我担心随时间变化的共同创始因素，如市政 GDP、市政人口增长等，可能会影响治疗城市的结果。市政年份固定效应会解释这些吗？或者我应该在模型中实际插入这些协变量？
另一个模型类似，但试图评估公共设施推出（市政）对个人层面结果的影响（例如，如果该人受雇等）。由于结果比治疗更细致，市政 GDP 增长等因素是否是个问题？市政年份固定效应是必要的吗？
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/657555/outcome-level-vs-treatment-level-vs-fixed-effects-level-in-difference-in-differe</guid>
      <pubDate>Wed, 20 Nov 2024 11:59:59 GMT</pubDate>
    </item>
    <item>
      <title>预测多元时间序列的所有特征的多个步骤</title>
      <link>https://stats.stackexchange.com/questions/657540/forecasting-multiple-steps-of-a-multivariate-time-series-for-all-features</link>
      <description><![CDATA[我正在开展一个项目，其中有 100 个长度为 1-10 分钟的多个时间序列（每 0.1 秒采样一次）。每个时间序列都是人类情绪的记录，存储为 7 个特征的向量，每个特征对应于该时间戳所见情绪的百分比（例如 t=4.2 秒，[0.5,0.2,0.1,0,0.2,0,0] 代表 50% 高兴、20% 悲伤、10% 惊讶等）。因此，1 分钟长的时间序列将存储为 600x7 矩阵（600 个时间步长，7 个特征）。
我的目标是设计一个机器学习模型，该模型对我拥有的 100 个时间序列进行训练，并预测接下来 10 秒的情绪（要决定要预测多少秒，但我将在本文中使用 10 秒）。
数据预处理：对 100 个时间序列中的每一个使用不重叠的段来生成我的训练和测试数据（80-20 分割）。因此，每个 xTrain 由 600 个时间步长组成，相应的 yTrain 是接下来的 100 个时间步长。我通过随机分割整个时间序列而不是它们的片段来确保训练集和测试集之间没有数据泄漏。即在 100 个时间序列中，没有一个时间序列具有 xTrain 中的段和 xTest 中的不同段
我想知道哪种类型的机器学习模型最适合用于此目的？
我考虑过 LSTM，但我发现的所有研究论文都只使用 LSTM 来 1. 预测多个特征的下一个值或 2. 预测单个特征未来的多个时间步（通过递归地将单步预测输入模型或一次性输入）——没有一篇 LSTM 论文同时做到了这两者。]]></description>
      <guid>https://stats.stackexchange.com/questions/657540/forecasting-multiple-steps-of-a-multivariate-time-series-for-all-features</guid>
      <pubDate>Wed, 20 Nov 2024 02:41:54 GMT</pubDate>
    </item>
    </channel>
</rss>