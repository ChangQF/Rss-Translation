<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 03 Jan 2024 03:15:44 GMT</lastBuildDate>
    <item>
      <title>使用 TWFE 方法调整 diff-in-diff 中的时不变协变量</title>
      <link>https://stats.stackexchange.com/questions/636030/adjusting-for-time-invariant-covariates-in-diff-in-diff-using-twfe-approach</link>
      <description><![CDATA[我正在计划进行一项交错的双重差异分析，以检验县级卫生政策变化的影响。该政策在不同的县实施的时间不同，还有很多县根本没有实施。我有很多县的数据，只有一小部分县实施了该政策。
我想利用 TWFE 模型（我已经阅读了许多对此方法的批评，但至少想实现它，即使它不是我的最终分析模型），但我对这种方法感到困惑，因为我也想要针对县级协变量调整我的模型。似乎在 TWFE 模型中这是不可能的，因为任何时不变的县级协变量都将与特定于县的固定效应完全共线，但我一直在阅读声称调整基线协变量以满足并行的资料来源趋势假设是 TWFE diff-in-diff 中的常见做法（例如）。
这是实现该模型的 R 代码示例，其中 Outcome 是我的结果变量，TimeToTreat 是政策实施之前或之后的月数，Treated 是实施该政策的县的虚拟变量，Time 是结果测量的时间， CountyID 标识县（哈哈）：
model.twfe &lt;- feols(结果 ~
                    i(治疗时间，已治疗，参考=-1) |时间+县ID，
                    集群 = ~CountyID,
                    数据 = 玩具数据）

这似乎按预期工作。但是，如果我尝试在模型公式中添加额外的项，这些项是县（例如地区）的时不变特征，它们会自动从模型中删除，以实现完美的共线性。
我在这里缺少什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/636030/adjusting-for-time-invariant-covariates-in-diff-in-diff-using-twfe-approach</guid>
      <pubDate>Wed, 03 Jan 2024 02:11:00 GMT</pubDate>
    </item>
    <item>
      <title>高维概率中的引理 3.2.4：各向同性随机向量</title>
      <link>https://stats.stackexchange.com/questions/636029/lemma-3-2-4-in-high-dimensional-probability-isotropic-random-vectors</link>
      <description><![CDATA[书中高维概率中的引理 3.2.4 指出，对于 $\mathbb{R}^n$ 中的两个独立的各向同性随机向量（这意味着 $EXX^T = I_n$)，我们有 $E\langle X,Y\rangle^2 = n$，其中 $\langle X,Y\rangle = X^T Y$。
为了证明这一点，我们计算 $E(E(\langle X,Y\rangle^2\mid Y))$。我们得到 $E(\langle X,Y\rangle^2\mid Y) = \Vert Y\Vert_2^2$ 和 $E(\Vert Y\Vert_2^2) = n$。
我不明白的是在哪里使用了独立性假设。总期望定律不需要独立性的假设，所以对我来说，如果不假设 $X$ 和  的独立性，证明就可以了类=“数学容器”&gt;$Y$。



引文：Vershynin, R. (2020)。高维概率。加州大学欧文分校。]]></description>
      <guid>https://stats.stackexchange.com/questions/636029/lemma-3-2-4-in-high-dimensional-probability-isotropic-random-vectors</guid>
      <pubDate>Wed, 03 Jan 2024 01:29:12 GMT</pubDate>
    </item>
    <item>
      <title>如何估计 OLS 中的系数（所有步骤）[重复]</title>
      <link>https://stats.stackexchange.com/questions/636026/how-to-estimate-the-coefficients-in-ols-all-steps</link>
      <description><![CDATA[我是学士。数学毕业生，喜欢（尝试）利用自己的时间自学统计学，因为我买不起硕士学位。
当我无法从根本上理解某些东西如何以及为何起作用时，这真的让我很困扰，因此在这篇文章中，我想提供如何使用线性回归中的最小二乘法导出系数的每一步。这里的大多数人可能比我更了解这类事情，但看到这一切结合在一起很令人满意，我希望它也适合你。
这涵盖了多变量（n 维）情况，因为 1 变量情况只是其更简单的版本。最后有一个简单的R例子，说明从头开始得到的结果是正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/636026/how-to-estimate-the-coefficients-in-ols-all-steps</guid>
      <pubDate>Tue, 02 Jan 2024 22:30:07 GMT</pubDate>
    </item>
    <item>
      <title>分解时间序列</title>
      <link>https://stats.stackexchange.com/questions/636025/decomposition-time-series</link>
      <description><![CDATA[我正在研究一款游戏的每日数据集，其中包含 2013-2023 年玩家高峰期的信息。这是我第一次尝试应用分解来查看时间序列组件的行为。后来我想使用一些模型进行预测，我应用了 ADF 测试，它显示该序列是平稳的。我有一些问题需要确定哪些值更适合每日数据的周期参数。
这是整个系列的全部内容

我使用了 statsmodelsseasonal_decompose()，周期值为 365，这是使用加法和乘法模型获得的结果。
加法模型：

乘法模型：

针对年、月、日等不同类型的时间序列数据，应该如何选择周期？]]></description>
      <guid>https://stats.stackexchange.com/questions/636025/decomposition-time-series</guid>
      <pubDate>Tue, 02 Jan 2024 21:45:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么解码器网络中每个注意力层周围都有一个残差连接，然后是一个层归一化步骤？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636024/why-is-there-a-residual-connection-around-each-attention-layer-followed-by-a-lay</link>
      <description><![CDATA[我在测验中得到了以下问题，看来我的答案不正确。我不明白为什么：
为什么解码器网络中的每个注意层周围都有一个残差连接，然后是一个层归一化步骤？

答案：
帮助提高可解释性。
加快训练速度，并显着减少整体处理时间。
打破后支撑的对称性。
在培训期间帮助并行计算组件。

我回答“打破后向传播的对称性。”，但他们的回答似乎是错误的！
我不明白为什么我的答案是错误的。另外，我不明白其他答案怎么可能是正确的！]]></description>
      <guid>https://stats.stackexchange.com/questions/636024/why-is-there-a-residual-connection-around-each-attention-layer-followed-by-a-lay</guid>
      <pubDate>Tue, 02 Jan 2024 21:03:04 GMT</pubDate>
    </item>
    <item>
      <title>用于小样本和功效计算的线性混合模型方差分析的非参数方法</title>
      <link>https://stats.stackexchange.com/questions/636023/nonparametric-way-to-perform-anova-of-linear-mixed-model-for-small-sample-and-po</link>
      <description><![CDATA[我有一个小数据，其中有 3 个组（A、B、C），每组有 5 名参与者。所有这些参与者在 7 项不同的考试中每项都被测量 6 次，因此每个参与者总共得到 6*7=42 分。构建了一个简单的线性混合模型 mylmm&lt;-lmer(score ~1+group+exam+group*exam+(1|participant), data = mydata)。我可以使用 anova(mylmm) 和多重比较函数获得分组、考试和交互的方差分析结果和事后成对比较。
但是数据很小（只有5个参与者）并且mylmm的残差不正常，所以威力不足。我知道使用 robustlmm 的稳健混合模型和使用 lmeresampler 的残差引导混合模型。但是，我无法使用这些包执行方差分析和多重比较。有人可以帮我解决以下问题吗？实在是太感谢了。

是否有方法和可用的 R 软件包来执行线性混合模型的引导方差分析（和事后比较）？
是否还需要计算 bootstrap 或非参数方差分析的功效？如果可以的话，功率怎么计算？
我还了解对齐排名转换方差分析。这种方法在这里有效吗，特别是对于小数据？另外，如何计算功率？
还有另一个相关但不太重要的问题。对于直接从 lme 构建的模型（无需引导），我能够使用 simr 和 anova 方法来计算测试组、考试和交互的功效。 simr 是否也可用于查找事后成对比较的功效？谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/636023/nonparametric-way-to-perform-anova-of-linear-mixed-model-for-small-sample-and-po</guid>
      <pubDate>Tue, 02 Jan 2024 20:23:38 GMT</pubDate>
    </item>
    <item>
      <title>拟合值与实际值较差</title>
      <link>https://stats.stackexchange.com/questions/636021/poor-fitted-vs-actual-values</link>
      <description><![CDATA[我正在使用 BART 模型（贝叶斯加性回归树）来预测控制 388 个特征的结果（21,384 个观察值）的相对风险，并且我得到的实际值与拟合值图非常差，与任何 I&#39; 都不同。之前在其他模型中已经得到过不同的结果。
DV = 记录的相对风险 + 1 人口普查区层面的租户驱逐率。我的第一个模型（未显示）使用原始相对风险（风险是与该州所有其他区域相比的区域驱逐率），但我的拟合效果不佳，因此最后一轮我将 DV 转换为 log(RR +1)，其中在记录之前将 +1 添加到所有 RR 值，以避免由于大量零而出现无穷大。
IV = 388 个变量中除一个之外的所有变量都是连续的。变量涉及住房市场、人口统计、建筑环境、地方政策以及与驱逐相关的其他变量。
目标 = 拟合该国其他地区的相对风险预测值，这些地区没有基于相应地区控制措施的数据。
流程 = 我从基线数量的控件（最多包含 388 个）开始，运行交叉验证的 BART 模型以获得最佳超参数，然后使用这些参数循环 20 个 BART 模型每个都用不同的种子来找到最重要的变量，在查看几个变量重要性因素后减少变量。然后我重复这个过程，直到找到满意的模型集。最后一次模型迭代的 R^2 约为 0.64，RMSE 约为 0.28。
问题我该如何改进这个模型？

编辑：澄清情节。这些是可信的区间点。蓝色表示在可信范围内，红色表示在可信范围外。这里我们的覆盖率是 45.06%。我之前遇到的最差情况是 95%（绘图看起来大部分是蓝色）。]]></description>
      <guid>https://stats.stackexchange.com/questions/636021/poor-fitted-vs-actual-values</guid>
      <pubDate>Tue, 02 Jan 2024 19:25:43 GMT</pubDate>
    </item>
    <item>
      <title>竞争获胜的概率</title>
      <link>https://stats.stackexchange.com/questions/636020/probability-of-victory-in-competition</link>
      <description><![CDATA[我想象这样一个场景：两支球队互相比赛并取得历史胜率。 $1$ 团队相当出色，赢得了 $60\%$ 的比赛。然而，$2$ 团队确实非常出色，赢得了 $90\%$ 的比赛。当两队相遇时，每队获胜的概率是多少？
我尝试使用多变量方法解决此问题，但事实证明这不是一个多变量问题。只有两种结果： $1)$ $\text{团队 1 获胜，团队 2 失败}$ ，或 $2)$ $\text{团队 2 获胜，团队 1 失败}$。这是伯努利分布（a 的简单变体）： $P(\text{队伍 1 获胜，队伍 2 失败}) = p$ 和 $P(\text{团队 2 获胜，团队 1 失败}) = 1 - p$。
应该如何计算$p$？
在上述情况下，我认为两支球队中较差的一支球队的获胜概率一定小于其历史胜利概率$0.6$。然而，由于更好的球队面对的是一支相当不错的球队（赢多于输），因此它的胜利概率也必须低于其历史比率 $0.9$.
我的幼稚方法是将概率计算为“团队拥有的胜利概率的比例” （正如我所说的）。
$$
P(\text{队伍 1 获胜，队伍 2 失败}) = \dfrac{0.6}{0.6 + 0.9} = 0.4\\
P(\text{队伍 2 获胜，队伍 1 失败}) = \dfrac{0.9}{0.6 + 0.9} = 0.6
$$
这个计算有多合理？]]></description>
      <guid>https://stats.stackexchange.com/questions/636020/probability-of-victory-in-competition</guid>
      <pubDate>Tue, 02 Jan 2024 19:20:49 GMT</pubDate>
    </item>
    <item>
      <title>R 中累积发生函数的详细输出</title>
      <link>https://stats.stackexchange.com/questions/636018/detailed-output-of-a-cumulative-incidence-function-in-r</link>
      <description><![CDATA[我会先说我不是受过训练的统计学家，所以请保持温和。我正在使用 R 构建累积发生函数曲线，用于多个感兴趣时间点的单臂评估。感兴趣的结果是“事件”，“死亡”作为竞争风险（第三个选项被“审查”）。我使用了“tidycmprsk”包和“cuminc”函数来创建曲线（代码如下）。我的合作者要求我输出分析中每个时间点的累积发生率（和 95% CI）以及发生过事件、经过审查或仍然符合资格的患者数量。输出 (tidyCumInc) 在设定的时间点为我提供了一些信息，但没有提供事件的数量。有谁知道我可以获得我想要的输出吗？
非常感谢您提前抽出时间。
比尔
── cuminc() ──────────────────────────────────────────── ────────────────────────
• 故障类型“死亡”
时间n.风险估计标准误差95% CI
500 2,507 0.250 0.005 0.240, 0.260
1,000 633 0.369 0.007 0.356, 0.382
1,500 163 0.432 0.008 0.416, 0.447
2,000 54 0.456 0.009 0.439, 0.473
2,500 18 0.465 0.009 0.447, 0.483
3,000 6 0.480 0.011 0.458, 0.501
• 失败类型“结果”
时间n.风险估计标准误差95% CI
500 2,507 0.260 0.005 0.250, 0.270
1,000 633 0.382 0.007 0.368, 0.395
1,500 163 0.439 0.008 0.424, 0.455
2,000 54 0.469 0.009 0.451, 0.486
2,500 18 0.495 0.010 0.475, 0.514
3,000 6 0.495 0.010 0.475, 0.514
## 使用“tidycmprsk”包的累积发生率函数
图书馆（tidycmprsk）
库（ggsurvfit）

tidyCumInc &lt;- cuminc(Surv(时间, 事件) ~ 1,
                     数据=数据测试，
                     罗 = 0)
整洁的公司

# 绘制 CIF 曲线
cuminc(Surv(时间，事件) ~ 1，数据 = DATA_TEST，rho = 0) %&gt;%
  ggcuminc() +
  add_confidence_interval() +
  添加风险表()

]]></description>
      <guid>https://stats.stackexchange.com/questions/636018/detailed-output-of-a-cumulative-incidence-function-in-r</guid>
      <pubDate>Tue, 02 Jan 2024 18:27:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么在分析语料库时使用每百万计数的日志？</title>
      <link>https://stats.stackexchange.com/questions/636016/why-use-log-per-million-count-when-analyzing-corpora</link>
      <description><![CDATA[这对你来说可能是一个微不足道的问题，但请告诉我，因为我没有统计学背景。所以我对语料库语言学很好奇，尤其是在这个例子中如何使用语料库来证明简洁法则，也称为Zip&#39;f缩写法则。简而言之，该定理假设单词越短，它们在语言中出现的频率越高。当然，可视化对于证明定理非常有意义，所以我从维基百科上看到了这个可视化：

x 轴代表单词字符长度，y 轴代表单词数，以每百万对数计数。
我的问题是，为什么要使用每百万对数计数？是为了标准化，以便在分析中很好地代表计数较少的单词吗？任何对此有见解的人以及一些小读物，我们将不胜感激。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/636016/why-use-log-per-million-count-when-analyzing-corpora</guid>
      <pubDate>Tue, 02 Jan 2024 17:53:22 GMT</pubDate>
    </item>
    <item>
      <title>了解蒙特卡罗积分中的重要性采样</title>
      <link>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/635943/understanding-importance-sampling-in-monte-carlo-integration</guid>
      <pubDate>Mon, 01 Jan 2024 05:16:12 GMT</pubDate>
    </item>
    <item>
      <title>我怎样才能得到最好的模型？探索性 LMM</title>
      <link>https://stats.stackexchange.com/questions/635717/how-can-i-get-a-best-model-an-exploratory-lmm</link>
      <description><![CDATA[我想询问线性混合模型及其在我的数据集中的应用。该数据集包含一个表示为 V 的因变量 (DV)，以及三个相关的人口统计变量（例如，标记为 d1-d3 的年龄和性别） ），单个主体内变量标识为wi，单个主体间变量标识为bw。变量id表示数据集中唯一的主题标识符。
现在，我将初始完整模型设置为：
V ~ d1 * d2 * d3 * wi * bw + (1 + wi | id)

然后我使用 step() 来识别最能解释“V”变化的模型，从而找到一个复杂的模型，例如：
V ~ d1 + d2 + d3 + wi + bw + (1 + wi | id) + d1:d2 + d1:d3 + ...

每个变量有 13 种组合。然后我评估了模型与这个复杂模型的拟合程度。它有很多固定效应，但只有一些显示出统计显着性（例如 d1、d1:wi 和 d2:wi:bw） .
我可以相信这个模型并得出显着的固定效应（d1、d1:wi 和 d2:wi:bw）的结论吗DV 的重要因素是什么？是否有更好的方法来查找哪些变量或其相互作用对 DV 很重要？请注意，数据集有 65 个主题，因此我想知道 step() 找到的模型是否有太多解释变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/635717/how-can-i-get-a-best-model-an-exploratory-lmm</guid>
      <pubDate>Wed, 27 Dec 2023 17:01:04 GMT</pubDate>
    </item>
    <item>
      <title>如何识别样本正态分布的直方图</title>
      <link>https://stats.stackexchange.com/questions/635958/how-to-recognize-my-histogram-chart-for-normal-distribution-of-samples</link>
      <description><![CDATA[我完成了一个行动研究项目，并使用 DART 提高了学生的阅读理解能力。我只是为了结果而比较手段。现在我要写一篇文章，我将应用 $t$ 测试以获得更好的结果。我正在使用 Google Sheets 检查样本的正态分布。我制作了一个图表，但不明白。
我把全班分成了两组，即对照组（不进行治疗）和实验组（进行治疗）。我制作了图表只是为了检查对照组的结果，但我无法理解分布是否正常。查看下图，请说明它是否显示正态分布。
我上传了一张图像，仅显示对照组的结果：
]]></description>
      <guid>https://stats.stackexchange.com/questions/635958/how-to-recognize-my-histogram-chart-for-normal-distribution-of-samples</guid>
      <pubDate>Mon, 25 Dec 2023 11:08:59 GMT</pubDate>
    </item>
    <item>
      <title>如何激励人工智能做出危险的预测</title>
      <link>https://stats.stackexchange.com/questions/633338/how-to-incentivise-ai-to-make-risky-predictions</link>
      <description><![CDATA[我正在尝试构建一个天气预报人工智能。我有一个包含每天峰值温度的数据集。我用 MSE 作为损失函数来训练它，效果相当好。但我确实注意到，它往往更喜欢“安全”的东西。预测，即该时期平均温度附近的预测。我也对做出正确的意外预测感兴趣，因此我一直在尝试激励它做出风险更高的预测，但我没有运气。
我尝试使用指数和高阶多项式损失函数而不是平方，认为值的更快增加会奖励精确性。我尝试通过扩大平均温度附近预测的损失来惩罚安全预测。我尝试用阶跃函数包围平均温度。我不知道还能尝试什么，也不知道在线搜索答案的术语。]]></description>
      <guid>https://stats.stackexchange.com/questions/633338/how-to-incentivise-ai-to-make-risky-predictions</guid>
      <pubDate>Thu, 07 Dec 2023 18:26:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 Box-Cox 变换特征作为输入降低了回归模型的 $R^2$ 分数</title>
      <link>https://stats.stackexchange.com/questions/577798/using-box-cox-transformed-features-as-input-decreased-the-r2-score-of-a-regre</link>
      <description><![CDATA[我正在构建一个回归模型，以使用房屋特征（艾姆斯住房数据集）来预测房屋销售价格。我通过两种方式准备了功能集：
案例1。
我对所有数值特征进行了 Box-Cox 变换，并对分类特征进行了 one-hot 编码。
案例2。
我按原样使用了数值特征集，并对分类特征进行了 one-hot 编码。
我对两个特征集应用了线性回归，并且在案例 1（数字特征被转换）中得到了非常非常低的 $R^2$ 值。在案例 2 中，对于任何列车测试组合，它总是大于 0.85，而在案例 1 中，它永远不会超过 0.5。
由于线性回归假设特征是条件独立且正态分布的，而 Box-Cox 有助于使特征接近正态分布，我认为执行 Box-Cox 会提高我的 $R^2 $。谁能帮助我理解为什么应用于 Box 转换数据的模型会急剧下降？]]></description>
      <guid>https://stats.stackexchange.com/questions/577798/using-box-cox-transformed-features-as-input-decreased-the-r2-score-of-a-regre</guid>
      <pubDate>Sun, 05 Jun 2022 20:31:08 GMT</pubDate>
    </item>
    </channel>
</rss>