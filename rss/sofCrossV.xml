<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 11 Sep 2024 18:21:15 GMT</lastBuildDate>
    <item>
      <title>Xgboost 回归中的样本权重</title>
      <link>https://stats.stackexchange.com/questions/654221/sample-weights-in-xgboost-regression</link>
      <description><![CDATA[我正在尝试使用 xgboost 的 XGBRegressor 来拟合回归模型，在训练期间，我会对最近的数据进行加权，而不是过去的数据。我想知道 xgboost 的 sample_weight 是如何工作的。
我知道对于基于树的模型，拟合基本上是将数据拆分成各种节点/桶，然后对桶内的观测值取平均值。在这里，我希望对 xgboost 更了解的人可以解释样本权重是如何发挥作用的。我相信在大多数回归中，样本权重只是在拟合过程中计算损失函数时观测值的乘数。如果 xgboost 就是这种情况，那么虽然 sample_weight 会影响算法如何选择分割，但在取每个桶内的平均值时，它仍然会对所有观测值进行相同的加权。有人知道这是真的吗？有没有办法在 xgboost 中指定我想在节点/桶内取平均值时减少某些观测值的权重？]]></description>
      <guid>https://stats.stackexchange.com/questions/654221/sample-weights-in-xgboost-regression</guid>
      <pubDate>Wed, 11 Sep 2024 17:49:42 GMT</pubDate>
    </item>
    <item>
      <title>冷卡归因能解决类别不平衡问题吗？</title>
      <link>https://stats.stackexchange.com/questions/654220/can-cold-deck-imputation-used-to-address-class-imbalance</link>
      <description><![CDATA[如果您有使用冷牌插补法解决数据集中的类别不平衡问题的经验，能否分享更多细节或参考文献？
为了便于理解，下面是 wiki 上对冷牌插补法的描述。
热牌插补法
一种曾经很常见的插补方法是热牌插补法，即从随机选择的类似记录中插补缺失值。术语“热牌”可以追溯到穿孔卡片上数据的存储，表示信息提供者与接收者来自同一数据集。这叠卡片之所以“热”，是因为它目前正在被处理。
一种热牌插补法称为“最后观察结转法”（简称 LOCF），它涉及根据多个变量中的任何一个对数据集进行排序，从而创建有序数据集。然后，该技术找到第一个缺失值，并使用缺失数据之前的单元格值来插补缺失值。对下一个有缺失值的单元格重复该过程，直到所有缺失值都已估算。在常见情况下，案例是对某个人或其他实体的变量进行重复测量，这代表了这样一种信念：如果测量缺失，最好的猜测是它与上次测量时相比没有变化。众所周知，这种方法会增加增加偏见和可能得出错误结论的风险。因此，不建议使用 LOCF。
冷卡
相比之下，冷卡估算是从另一个数据集中选择捐赠者。由于计算机能力的进步，更复杂的估算方法通常取代了原始的随机和排序的热卡估算技术。这是一种用过去调查中类似项目的响应值替换的方法。它可用于测量时间间隔的调查。]]></description>
      <guid>https://stats.stackexchange.com/questions/654220/can-cold-deck-imputation-used-to-address-class-imbalance</guid>
      <pubDate>Wed, 11 Sep 2024 16:59:33 GMT</pubDate>
    </item>
    <item>
      <title>我如何确定我的生态 GLMM 是否构建准确？</title>
      <link>https://stats.stackexchange.com/questions/654219/how-do-i-determine-if-my-ecological-glmm-is-accurately-constructed</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654219/how-do-i-determine-if-my-ecological-glmm-is-accurately-constructed</guid>
      <pubDate>Wed, 11 Sep 2024 16:42:13 GMT</pubDate>
    </item>
    <item>
      <title>CATE/ITE 估计值是否应该呈正态分布？</title>
      <link>https://stats.stackexchange.com/questions/654218/are-cate-ite-estimates-supposed-to-be-normally-distributed</link>
      <description><![CDATA[我正在做提升建模，并预测一群人的 ITE。当我绘制这些图表时，我应该期望它们呈正态分布吗？我尝试过的一个模型的预测是双峰甚至三峰的，我不确定这是否不应该发生。]]></description>
      <guid>https://stats.stackexchange.com/questions/654218/are-cate-ite-estimates-supposed-to-be-normally-distributed</guid>
      <pubDate>Wed, 11 Sep 2024 16:41:24 GMT</pubDate>
    </item>
    <item>
      <title>对信号随时间变化的方差进行建模</title>
      <link>https://stats.stackexchange.com/questions/654217/modeling-time-varying-variance-of-a-signal</link>
      <description><![CDATA[我有一个信号，其方差随时间变化
通过观察发现，当其他一些变量（我们称之为输入特征）从一个值急剧转变为另一个值时，方差的这些波动就会出现。我真的不知道如何对这个信号进行建模。我曾考虑将其建模为高斯过程 (GP)，其中均值和方差取决于输入变量，但我真的不知道 Python 中有哪些可用于此类“GP”的工具。我知道有 GPy 包，但我没有找到任何文档，其中方差/平均值实际上是作为其他输入变量的函数建模的。
你有什么想法吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654217/modeling-time-varying-variance-of-a-signal</guid>
      <pubDate>Wed, 11 Sep 2024 16:27:38 GMT</pubDate>
    </item>
    <item>
      <title>非正态方差分析残差</title>
      <link>https://stats.stackexchange.com/questions/654215/non-normal-anova-residuals</link>
      <description><![CDATA[我正在分析一些数据，但遗憾的是，除了这是一次奶牛泌乳试验之外，我无法对此发表太多评论。残差具有非正态分布，Kolmogorov-Smirnov 检验的 p 值为 &lt; 0.0001。
Q-Q 图和直方图如下。Q-Q 图令人担忧，但在调查数据时，我无法确定是否真的存在问题。大多数具有负残差的数据点都处于泌乳早期（试验从第 7 天开始）。我认为这只是表明模型对一些泌乳早期数据进行了高估，因为当我查看奶牛的个体泌乳曲线时，我没有看到任何不正常的数据点。这是为客户准备的，我确实需要与他们一起检查数据是否全部正确，但只要数据正确，我认为保留这些数据是合理的。我不喜欢无缘无故地删除数据，方差分析对偏离正态性具有稳健性。总而言之，这不到数据点的 5%，与正态钟形曲线相比，残差的分布看起来根本不令人担忧。
我只是想在这里发帖，看看这是否是调查的合理结论，至少考虑到我能够提供的信息。谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654215/non-normal-anova-residuals</guid>
      <pubDate>Wed, 11 Sep 2024 15:59:41 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 估计高斯时间序列数据中的参数的问题 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/654213/issues-with-estimating-parameters-in-gaussian-time-series-data-using-r</link>
      <description><![CDATA[我正在从事一个涉及高斯噪声的时间序列数据的项目，并且遇到了参数估计的问题。具体来说，我估计的参数 $\psi$ 与数据生成中使用的真实值存在很大差异。
我使用 R 中的以下函数生成高斯噪声数据：
simulate_data_gaussian &lt;- function(T, a0, b0, psi0, sigma0) {
epsilon &lt;- rnorm(T - 1, mean = 0, sd = sigma0)
y &lt;- numeric(T)
e &lt;- numeric(T)
e[1] &lt;- rnorm(1, mean = 0, sd = sigma0)
y[1] &lt;- a0 + b0 * 1 + e[1]
for (t in 2:T) {
e[t] &lt;- psi0 * e[t-1] + epsilon[t-1]
y[t] &lt;- a0 + b0 * t + e[t]
}
return(y)
}

我使用这个目标函数来估计参数 $a$、$b$ 和 $\psi$:
f_objective &lt;- function(a, b, psi, y, T) {
residuals &lt;- y[2:T] - a - b * (2:T) - psi * (y[1:(T-1)] - a - b * (1:(T-1)))
return(sum(residuals^2) / T)
}

模拟的完整代码是以下：
# 模拟数据（高斯）
set.seed(123)
T &lt;- 100 # 样本大小
a0 &lt;- 1
b0 &lt;- 2
psi0 &lt;- 0.5
sigma0 &lt;- 1
y &lt;- mock_data_gaussian(T, a0, b0, psi0, sigma0)

# 目标函数 f(a,b,psi)
f_objective &lt;- function(a, b, psi, y, T) {
residuals &lt;- y[2:T] - a - b * (2:T) - psi * (y[1:(T-1)] - a - b * (1:(T-1)))
return(sum(residuals^2) / T)
}

# a 和 b 的解析解psi
solve_ab_psi &lt;- function(psi, y, T) {
# 为 a 和 b 构建线性方程组
A &lt;- matrix(0, nrow = 2, ncol = 2)
b_vec &lt;- numeric(2)

for (t in 2:T) {
A[1, 1] &lt;- A[1, 1] + 1 + psi^2
A[1, 2] &lt;- A[1, 2] + t + psi * (t - 1)
A[2, 1] &lt;- A[2, 1] + t + psi * (t - 1)
A[2, 2] &lt;- A[2, 2] + t^2 + (t - 1)^2

b_vec[1] &lt;- b_vec[1] + y[t] + psi * y[t-1]
b_vec[2] &lt;- b_vec[2] + t * y[t] + (t - 1) * psi * y[t-1]
}

# 求解 a(psi) 和 b(psi)
solution &lt;- resolve(A, b_vec)
a_psi &lt;- solution[1]
b_psi &lt;- solution[2]

return(c(a_psi, b_psi))
}

# 计算 f(a(psi), b(psi), psi) 的函数
f_psi &lt;- function(psi, y, T) {
ab &lt;- resolve_ab_psi(psi, y, T)
a_psi &lt;- ab[1]
b_psi &lt;- ab[2]
return(f_objective(a_psi, b_psi, psi, y, T))
}

# 生成 psi 值并评估f(psi)
psi_values &lt;- seq(-1, 1, by = 0.01)
f_values &lt;- sapply(psi_values, f_psi, y = y, T = T)

# 绘制 f(psi)
library(ggplot2)
df &lt;- data.frame(psi = psi_values, f_value = f_values)
ggplot(df, aes(x = psi, y = f_value)) +
geom_line() +
labs(title = &quot;Objective Function f(a(psi), b(psi), psi)&quot;, 
x = expression(psi), y = &quot;f(psi)&quot;) +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5))

结果估计如下图所示：

问题：尽管使用 $\psi_0=0.5$ 生成数据，但我估计的 $\psi$ 与 $0.5$ $(0.98)$ 存在显著差异。我验证了生成的数据和目标函数，但差异仍然存在。
问题：有人能帮我理解为什么估计的$\psi$与真实值$\psi_0$不同吗？我的估计过程可能出了什么问题？我应该考虑哪些常见的陷阱或调试步骤？]]></description>
      <guid>https://stats.stackexchange.com/questions/654213/issues-with-estimating-parameters-in-gaussian-time-series-data-using-r</guid>
      <pubDate>Wed, 11 Sep 2024 15:32:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么卷积神经网络使用 2d 滤波器</title>
      <link>https://stats.stackexchange.com/questions/654211/why-does-convolutional-neural-network-use-a-2d-filter</link>
      <description><![CDATA[给定 C、H、W 的输入，其中 C 是通道，过滤器的大小为 X、Y，并分别在每个通道上滑动。为什么大小为 C、X、Y 的过滤器不在整个 3d 形状上滑动？
我知道 3D 卷积的存在，但我不认为这就是它。]]></description>
      <guid>https://stats.stackexchange.com/questions/654211/why-does-convolutional-neural-network-use-a-2d-filter</guid>
      <pubDate>Wed, 11 Sep 2024 14:57:57 GMT</pubDate>
    </item>
    <item>
      <title>使用小数据集的弹性网络回归</title>
      <link>https://stats.stackexchange.com/questions/654208/elastic-net-regression-with-small-datasets</link>
      <description><![CDATA[我有一个包含 18 个案例和 10 个预测因子的数据集。其中一些预测因子高度相关，这意味着我正在处理多重共线性。
我想进行回归分析，发现弹性网络回归是一种很好的方法。但是，它适合这么小的数据集吗？或者我应该考虑其他方法（或者根本不进行回归分析）？
此外，我尝试使用 R 进行弹性网络回归（训练函数），但我不确定在这么小的数据集中将 tunelength 参数设置为哪个值。
任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654208/elastic-net-regression-with-small-datasets</guid>
      <pubDate>Wed, 11 Sep 2024 14:10:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 T 分布进行参数引导置信区间：使用哪个样本大小？</title>
      <link>https://stats.stackexchange.com/questions/654207/using-t-distribution-for-parametric-bootstrap-confidence-intervals-which-sample</link>
      <description><![CDATA[我对 bootstrap 置信区间的计算有疑问。我的原始样本量相对较小，但在组内应用 bootstrap 重采样后，我获得了钟形分布。基于此，我认为使用参数方法计算置信区间是合理的。
我决定使用 T 分布方法，其公式为：
$$CI = \bar{X} \pm t_{\alpha/2, \, n-1} \times \frac{s}{\sqrt{n}}$$
我的问题是：在计算置信区间时，我应该使用什么值来表示
𝑛
n？它应该是我原始样本的大小，还是引导迭代的次数（例如，如果我使用了 1000 次迭代，𝑛 应该等于 1000）？
提前感谢您的见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/654207/using-t-distribution-for-parametric-bootstrap-confidence-intervals-which-sample</guid>
      <pubDate>Wed, 11 Sep 2024 14:08:09 GMT</pubDate>
    </item>
    <item>
      <title>高斯等周边界的直观解释是什么？</title>
      <link>https://stats.stackexchange.com/questions/654205/what-is-the-intuitive-explanation-of-gaussian-isoperimetric-bound</link>
      <description><![CDATA[这取自 V.Bentkus (2003) 的论文（第 386 页）：&quot; 论 Berry–Esseen 边界对维度的依赖性&quot;。
假设 $\mathcal{A}$ 表示所有可测子集的类 $A\subset \mathbf{R}^d$。对于任何 $\mathbf{x}\in \mathbf{R}^d$ 和 $A\subset \mathbf{R}^d$，我们将 $\mathbf{x}$ 和 $A$ 之间的距离定义为：$$\rho_A(\mathbf{x})=\inf_{\mathbf{y}\in A}\|\mathbf{y}-\mathbf{x}\|.$$ 另定义，$$B_{\varepsilon}(\mathbf{x}):=\{\mathbf{y}\in \mathbf{R}^d:\|\mathbf{y}-\mathbf{x}\|\leq \varepsilon\}.$$
对于某些 $\varepsilon&gt;0$，我们还将集合 $A$ 的 $\varepsilon$-邻域定义为：$$A^{\varepsilon}:=\{\mathbf{x}\in \mathbf{R}^d:\rho_A(\mathbf{x})\leq \varepsilon\}$$ 和 $$A^{-\varepsilon}:=\{\mathbf{x}\in A:B_{\varepsilon}(\mathbf{x})\subset A\}$$
在 (1.2) 中，Bentkus 定义，对于任何 $d$ 维标准高斯随机向量 $\mathbf{Y}$，存在某个等周常数 $a_d(\mathcal{A})$ 依赖于 $d$ 和 $\mathcal{A}$，使得：$$P(\mathbf{Y}\in A^{\varepsilon}\setminus A)\leq \varepsilon a_d(\mathcal{A})\; \text{and}\; P(\mathbf{Y}\in A\setminus A^{-\varepsilon})\leq \varepsilon a_d(\mathcal{A}).$$
我的问题如下：
(1) 有谁能帮我直观地理解为什么这些概率可以被$\varepsilon a_d(\mathcal{A})$所限制？ （技术证明非常复杂）
(2) 我知道 $\{A^{\varepsilon}\setminus A\}\cup \{A\setminus A^{-\varepsilon}\}$ 只不过是 $(\partial{A})^{\varepsilon}$，即 $\varepsilon$ 边界的邻域，只要我们研究 $\mathbf{R}^d$。但是，我们分别如何识别或可视化这些集合 $A^{\varepsilon}\setminus A$ 和 $A\setminus A^{-\varepsilon}$？如果您可以提供任何简单的例子！！
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654205/what-is-the-intuitive-explanation-of-gaussian-isoperimetric-bound</guid>
      <pubDate>Wed, 11 Sep 2024 13:30:45 GMT</pubDate>
    </item>
    <item>
      <title>离散时间生存模型（输出）</title>
      <link>https://stats.stackexchange.com/questions/654204/discrete-time-survival-model-output</link>
      <description><![CDATA[这两个函数中哪一个更适合离散时间生存分析？假设数据集中有 8 个时间点。输出需要包含时间的单个估计值和每个时间级别的单独估计值？简而言之：我需要将时间或因素（时间）纳入分析吗？
Gompertz_Model_Baseline &lt;- glm(formula = event ~ Time,
family = binomial(link = &quot;cloglog&quot;),
data = Scania_PersonPeriod_Train)

summary(Gompertz_Model_Baseline)

系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -4.168556 0.072451 -57.54 &lt;2e-16 ***
时间 0.072376 0.004185 17.30 &lt;2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

第二个模型：
Gompertz_Model_Baseline &lt;- glm(formula = event ~ factor(Time),
family = binomial(link = &quot;cloglog&quot;),
data = Scania_PersonPeriod_Train)

summary(Gompertz_Model_Baseline)

系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -4.0762 0.1961 -20.784 &lt; 2e-16 ***
因子（时间）2 0.2717 0.2640 1.029 0.303511 
因子（时间）3 -0.1942 0.3018 -0.643 0.519926 
因子（时间）4 0.1789 0.2774 0.645 0.518810 
因子（时间）5 0.3349 0.2701 1.240 0.214988 
因子（时间）6 0.3844 0.2701 1.423 0.154699 
因子（时间）7 0.3722 0.2748 1.355 0.175537 

]]></description>
      <guid>https://stats.stackexchange.com/questions/654204/discrete-time-survival-model-output</guid>
      <pubDate>Wed, 11 Sep 2024 12:00:28 GMT</pubDate>
    </item>
    <item>
      <title>Hopfield 网络的概率分布</title>
      <link>https://stats.stackexchange.com/questions/654203/probability-distribution-for-hopfield-network</link>
      <description><![CDATA[如何证明具有随机逻辑激活规则的 Hopfield 网络具有与玻尔兹曼分布相对应的状态概率分布。
我不需要所有的技术细节，而是需要概念层面的理解。]]></description>
      <guid>https://stats.stackexchange.com/questions/654203/probability-distribution-for-hopfield-network</guid>
      <pubDate>Wed, 11 Sep 2024 11:43:27 GMT</pubDate>
    </item>
    <item>
      <title>使用候补名单控制设计的干预研究的适当回归分析</title>
      <link>https://stats.stackexchange.com/questions/654200/appropriate-regression-analysis-for-intervention-study-using-waiting-list-contro</link>
      <description><![CDATA[考虑一个具有以下设计的随机试验：在基线测量（$T_0$）后，受试者被随机分为对照组（$G_0$）和干预组（$G_1$）。干预组接受治疗，而对照组则在候补名单上（未接受治疗）。在$T_1$，对两个组进行评估。在第二个时期，候补名单上的对照组现在接受治疗，并在$T_2$再次接受评估。干预组不参与第 2 阶段。下图说明了该设计：

我想回答以下问题（在图中用相应数字标记）：

比较两组在 $T_1$ 时的均值。
比较对照组在 $T_2$ 时的均值与干预组在 $T_1$ 时的均值。
比较对照组在 $T_2$ 时的均值与干预组在 $T_1$ 时的均值。 class=&quot;math-container&quot;&gt;$T_2$ 与 $T_1$（组内）的回归模型。

Q1：您认为哪种回归模型最适合回答这些问题？
由于重复测量的性质，我想到了一种混合模型，形式如下：
$$
y = (\beta_0 + b_0) + \beta_1T_1 + \beta_2T_2G_0+ \beta_3T_1G_1
$$
其中 $T_1$ 和 $T_2$ 是时间点的指标，$G_0$ 和 $G_1$ 是对照组和干预组的指标，$b_0$ 是随机截距。该模型强制在 $T_0$ 处拟合均值对于两个组相同，这在设计上是合理的（随机化发生在第一次测量之后）。
如果我的推理正确，那么我的三个问题可以通过以下系数或对比测试来回答：

$\beta_3 = 0$
$\beta_1 + \beta_3 -\beta_2 = 0$
$\beta_1 - \beta_2 = 0$

我进行了一些模拟，似乎证实了我的想法（如果有兴趣，我可以发布代码），但我想知道是否有更简单的方法来参数化问题。
问题 2：这听起来合理吗？或者是否有更简单的参数化方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/654200/appropriate-regression-analysis-for-intervention-study-using-waiting-list-contro</guid>
      <pubDate>Wed, 11 Sep 2024 11:23:42 GMT</pubDate>
    </item>
    <item>
      <title>相对熵不对称性的证明（KL 散度）$D(p∥q) \neq D(q∥p)$ [重复]</title>
      <link>https://stats.stackexchange.com/questions/654199/proof-of-asymmetry-of-relative-entropy-kl-divergence-dp%e2%88%a5q-neq-dq%e2%88%a5p</link>
      <description><![CDATA[与实际距离度量不同，相对熵不是对称的，因为

$D(p(x)∥q(x)) \neq D(q(x)∥p(x))$。事实证明，许多信息度量都可以用相对熵来表示。
我想知道证明$D(p∥q) \neq D(q∥p)$的方法和程序。]]></description>
      <guid>https://stats.stackexchange.com/questions/654199/proof-of-asymmetry-of-relative-entropy-kl-divergence-dp%e2%88%a5q-neq-dq%e2%88%a5p</guid>
      <pubDate>Wed, 11 Sep 2024 10:40:38 GMT</pubDate>
    </item>
    </channel>
</rss>