<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 09 Sep 2024 09:18:40 GMT</lastBuildDate>
    <item>
      <title>条件逻辑模型与时间离散生存模型</title>
      <link>https://stats.stackexchange.com/questions/654078/a-conditional-logistic-model-vs-time-discrete-survival-model</link>
      <description><![CDATA[我认为，当时间具有离散格式时，条件逻辑模型和 Cox 比例风险之间存在区别。但是，根据 R 中的 coxph {survival} 和以下出版物，他们似乎认为这两种方法是等效的。如果您能对此作出澄清，我将不胜感激。
Lachin，JM 使用**条件逻辑（离散 Cox PH）**回归模型的评分检验对多重匹配病例对照研究进行样本量评估。Stat Med。2008 

此外，在 R 中的生存包中，提到
使用“精确偏似然”方法，Cox 偏似然等同于匹配逻辑回归的偏似然。 （clogit 函数使用 coxph 代码进行拟合。）当时间尺度是离散的并且只有几个唯一值时，它在技术上是合适的，一些
包将此称为“离散”选项。还有一个由 Prentice 提出的“精确边际似然”，但这里没有实现。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654078/a-conditional-logistic-model-vs-time-discrete-survival-model</guid>
      <pubDate>Mon, 09 Sep 2024 08:46:14 GMT</pubDate>
    </item>
    <item>
      <title>当相关固定效应不显著时，随机斜率是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/654075/is-random-slope-meaningful-when-the-relevant-fixed-effect-is-not-significant</link>
      <description><![CDATA[我正在使用以下语法构建一个线性混合模型：
y ~ run + (1 + run |subjects)

摘要如下：

run的固定效应不显著。
我想知道不同受试者的run的随机斜率是否有意义。我想利用不同受试者的这些斜率来与其他受试者的特征相关联。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654075/is-random-slope-meaningful-when-the-relevant-fixed-effect-is-not-significant</guid>
      <pubDate>Mon, 09 Sep 2024 08:08:54 GMT</pubDate>
    </item>
    <item>
      <title>估计 OLS 回归中的相关特征</title>
      <link>https://stats.stackexchange.com/questions/654074/estimating-correlated-features-in-ols-regression</link>
      <description><![CDATA[我获得了由其他人拟合的以下 OLS 的相当大的 $y$ 和 ${\beta}_{i}$ 样本集：
$y$ = $\sum({\beta}_{i} x_i)$ + α + ε
我想估计 $x_i$（例如 $\hat{x_i}$）。假设原始模型的作者在拟合上述模型方面做得不错，我是否正确地使用以下方法估计$\hat{x_i}$：
$\hat{x_i}$ = $\frac{Cov({\beta}_{i}, y)}{Var({\beta}_{i})}$
如果有人告诉我，对于所有i, j，$Corr(x_i,x_j) \neq 0$，即$\hat{x_i}$ 是有偏差的，即存在多重共线性class=&quot;math-container&quot;&gt;$x_i$。如果这是有偏差的，那么获得 $\hat{x_i}$ 的最佳方法是什么？
如果 $mean(\alpha) = 0$（或不）会发生什么？
可以安全地假设不存在缩放问题，即 x 和 y 在同一尺度上。然而，它们是肥尾的。]]></description>
      <guid>https://stats.stackexchange.com/questions/654074/estimating-correlated-features-in-ols-regression</guid>
      <pubDate>Mon, 09 Sep 2024 07:42:02 GMT</pubDate>
    </item>
    <item>
      <title>分位数回归用于比较不同时间点的两个群体</title>
      <link>https://stats.stackexchange.com/questions/654073/quantile-regression-to-compare-two-populations-at-different-time-points</link>
      <description><![CDATA[我试图比较两个不同人群（例如，2001 年和 2011 年）在同一变量上的表现。它们是不同的、独立的人群（这不是纵向研究；而是代表该人群的两个横断面研究）。我们已经计算了适用于两个样本的抽样权重。
我想知道我的方法是否正确：我想使用分位数回归检查我的变量是否从 2001 年到 2011 年在不同百分位数上发生了变化。
我的问题如下：

使用 R，我可以在分位数回归中使用这些预先计算的样本权重变量吗？

如果我根据性别对样本进行分层，我不再需要在回归模型中控制性别？


提前非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654073/quantile-regression-to-compare-two-populations-at-different-time-points</guid>
      <pubDate>Mon, 09 Sep 2024 07:24:21 GMT</pubDate>
    </item>
    <item>
      <title>元分析相当于单尾单样本 t 检验</title>
      <link>https://stats.stackexchange.com/questions/654070/meta-analysis-equivalent-of-a-one-tail-one-sample-t-test</link>
      <description><![CDATA[我正在执行元分析，比较两种测试方法：传统 (TRAD) 方法和新实验 (EXP) 方法。作为二次分析，我想查看从 0-10 李克特量表获得的最大测量值，我们称之为“评级 A”。在 TRAD 中，评级 A 是通过让参与者在测试结束时提供评级而获得的。在 EXP 中，评分量表用于指导测试，当量表达到 10 时测试终止，因此 EXP 的最大值始终为 10，并且没有方差。
通常，在一项主要研究中，这将通过单尾单样本 t 检验来评估 TRAD 的样本平均值是否小于 10。
是否有等效的元分析方法，我可以取 TRAD 的 A 级评分的平均值和方差并将其与定义值（即 10）进行比较？本质上，我想测试 TRAD 的 A 级评分在各研究中的平均值是否小于 10，即量表的最大值。
话虽如此，鉴于量表有上限，我并不认为这是一种合适的分析。是否有任何理由认为这种方法不合适，或者是否有其他方法可以进行这种分析？
主要分析是使用 R 和 metafor 进行的。]]></description>
      <guid>https://stats.stackexchange.com/questions/654070/meta-analysis-equivalent-of-a-one-tail-one-sample-t-test</guid>
      <pubDate>Mon, 09 Sep 2024 03:50:11 GMT</pubDate>
    </item>
    <item>
      <title>如何限制浅层神经网络的泛化误差？</title>
      <link>https://stats.stackexchange.com/questions/654068/how-to-bound-generalization-error-of-a-shallow-nn</link>
      <description><![CDATA[我有一个使用 ReLU 训练的单隐藏层 NN。总共有 2N+d 个参数（N 是节点数，d 是维数）。训练此 NN 的样本大小正好是 N。
现在，在这种特殊情况下，我有一种方法可以确保优化误差正好为 0（即平方损失为 0）
由于参数数量和样本大小之间的特殊关系，我很难限制泛化误差。请给我一些提示。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654068/how-to-bound-generalization-error-of-a-shallow-nn</guid>
      <pubDate>Mon, 09 Sep 2024 02:17:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么较小的权重有助于泛化？</title>
      <link>https://stats.stackexchange.com/questions/654067/why-does-having-a-smaller-set-of-weight-help-with-generalization</link>
      <description><![CDATA[当我第一次学习机器学习时，我了解到我们需要使用 l2 正则化来提高泛化能力。原因基于 Chris Bishop 教科书中的多项式回归实验，作者展示了过度拟合的多项式的权重具有较大的权重，这将对测试数据产生错误的预测（这里的论点是，较大的权重将与数据相乘得到一个较大的预测）。正则化将降低权重的大小。
但是，这种（较小的权重 = 更好的泛化）见解是否真的可以推广到多项式回归的范围之外？例如，具有较小权重的神经网络必须表现更好吗？即使在多项式回归的背景下，我也不太确定。例如，我想将百万富翁的年龄与他们的收入联系起来。我的权重必须很大。小权重在这里实际上没有意义。
同样的论点出现在关于双下降和隐式正则化的文献中。据说双下降法有效，因为 SGD 隐式地在过度参数化的状态下找到了最小范数权重。但问题又来了：为什么小的权重集可以转化为更好的泛化？
有人可以对此发表意见吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654067/why-does-having-a-smaller-set-of-weight-help-with-generalization</guid>
      <pubDate>Mon, 09 Sep 2024 02:07:10 GMT</pubDate>
    </item>
    <item>
      <title>如何获得高斯和的 LRT 和 ROC（高斯项的数量具有泊松分布）？</title>
      <link>https://stats.stackexchange.com/questions/654066/how-to-obtain-lrt-and-roc-of-sum-of-gaussians-with-number-of-gaussian-terms-has</link>
      <description><![CDATA[若
$$
y = \sum_{i=0}^n x_i
$$
其中$x_i$为独立同分布随机变量，其密度为高斯分布$N(0, \sigma^2)$。总和中的变量数是具有泊松分布的随机变量：
$$
\Pr(n = k) = \frac{\lambda^k e^{-\lambda}}{k!}, \quad k = 0, 1, \ldots
$$
我们想在两个假设之间做出决定：
$$
H_1 : n \leq 1 \quad \text{and} \quad H_0 : n &gt; 1
$$.
我想获得 LRT（并尽可能简化它）。然后，我想获得 ROC 曲线（检测概率与误报概率）？
首先，我们有：
（H_1）下的似然：
在（H_1）下，（n）可以是 0 或 1。因此，（H_1）下（y）的概率分布是两个高斯的混合：
$$
f_{Y|H_1}(y) = e^{-\lambda} \delta(y) + \frac{\lambda e^{-\lambda}}{1!} \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{y^2}{2\sigma^2}}
$$
其中（ \delta(y) ) 是狄拉克 delta 函数，表示 ( n = 0 ) 时概率质量为零。
( H_0 ) 下的可能性：
( H_0 ) 下，( n &gt; 1 )。 ( H_0 ) 下的 ( y ) 概率分布是 $n \geq 2$ 的高斯加权和：
$$
f_{Y|H_0}(y) = \sum_{k=2}^{\infty} \frac{e^{-\lambda} \lambda^k}{k!} \frac{1}{\sqrt{2\pi k\sigma^2}} e^{-\frac{y^2}{2k\sigma^2}}
$$
似然比检验 (LRT)：
LRT 统计量定义为：
$$
\Lambda(y) = \frac{f_{Y|H_1}(y)}{f_{Y|H_0}(y)}
$$
然后，我卡在这里了；我怎样才能进一步简化它以获得 ROC？]]></description>
      <guid>https://stats.stackexchange.com/questions/654066/how-to-obtain-lrt-and-roc-of-sum-of-gaussians-with-number-of-gaussian-terms-has</guid>
      <pubDate>Mon, 09 Sep 2024 02:07:03 GMT</pubDate>
    </item>
    <item>
      <title>重复测量与独立方差分析用于比较针对参与者特定数据训练的机器学习模型</title>
      <link>https://stats.stackexchange.com/questions/654065/repeated-measures-vs-independent-anova-for-comparing-machine-learning-models-tr</link>
      <description><![CDATA[我有一个机器学习项目，其中我在包含来自多个参与者的数据的单个数据集上训练多个模型（例如，模型 A、模型 B、模型 C）。每个参与者的数据都用于训练所有三个模型，从而产生每个模型的特定于参与者的实例（例如，参与者 1 有模型 A1、B1、C1）。
我评估每个模型（A、B、C）在保留测试集上对每个参与者的准确性。
我的目标是比较这些模型（A、B、C）在所有参与者中的整体准确性。我目前对任何交互作用不感兴趣。
我应该使用重复测量方差分析还是独立方差分析进行此分析？
假设：
我们假设方差分析的必要假设（正态性、方差齐性）得到满足。如果不满足，我们准备使用非参数替代方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/654065/repeated-measures-vs-independent-anova-for-comparing-machine-learning-models-tr</guid>
      <pubDate>Mon, 09 Sep 2024 01:42:56 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn PLS 属性 X_scores、X_weights、X_Loadings 含义</title>
      <link>https://stats.stackexchange.com/questions/654062/sklearn-pls-attributes-x-scores-x-weights-x-loadings-meaning</link>
      <description><![CDATA[尝试阅读 sci-kit 文档，但文档很短，帮助不大。有人能用通俗易懂的术语来描述通过 sklearn 进行偏最小二乘回归 PLS 的 X 和 Y 分数、权重和载荷吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654062/sklearn-pls-attributes-x-scores-x-weights-x-loadings-meaning</guid>
      <pubDate>Sun, 08 Sep 2024 22:19:14 GMT</pubDate>
    </item>
    <item>
      <title>主教高斯基</title>
      <link>https://stats.stackexchange.com/questions/654060/bishop-gaussian-basis</link>
      <description><![CDATA[在 Christopher Bishop 所著的模式识别与机器学习一书中，他在第 3.3.2 节“预测分布”中说道

如果我们使用局部基函数（如高斯函数），那么在远离基函数中心的区域中，预测方差（3.59）中第二项的贡献将变为零，只留下噪声贡献$\beta^{−1}$。因此，
当在基函数所占区域外进行外推时，模型对其预测非常有信心，这通常是不受欢迎的行为。

但就在本段之前，它说

请注意，预测不确定性取决于$x$，并且在数据点的邻域中最小。还要注意，随着观察到更多的数据点，不确定性水平会降低。

在图中，当远离数据点时，方差似乎很高。]]></description>
      <guid>https://stats.stackexchange.com/questions/654060/bishop-gaussian-basis</guid>
      <pubDate>Sun, 08 Sep 2024 21:42:32 GMT</pubDate>
    </item>
    <item>
      <title>样本量计算的假设检验与置信区间</title>
      <link>https://stats.stackexchange.com/questions/654055/hypothesis-testing-vs-confidence-intervals-for-sample-size-calculation</link>
      <description><![CDATA[假设我们正在审计一个低风险集团，该集团的历史平均逃税额为 \$7,883，审计时的标准差为 \$27,274。我的目标是确定平均逃税额是否接近于零。使用 t 检验，假设平均逃税额为零（双侧，$\alpha = 0.05$，功效 = 0.8），双侧检验所需的样本量为 96，单侧检验所需的样本量为 76。我假设备择假设下的平均值和标准差就是历史数据所显示的。
但是，如果我使用置信区间 $\bar{x} \pm 1.96 * \frac{\sigma}{\sqrt{n}}$ 进行计算并将下限设置为接近零，则求解 $n$ 得到的样本量为 46。
使用样本量 46 来确定零是否在置信区间内有效，从而否定了假设检验所建议的更大样本量的需要吗？如果不是，为什么这种方法是错误的？]]></description>
      <guid>https://stats.stackexchange.com/questions/654055/hypothesis-testing-vs-confidence-intervals-for-sample-size-calculation</guid>
      <pubDate>Sun, 08 Sep 2024 20:43:37 GMT</pubDate>
    </item>
    <item>
      <title>是否可以对多项研究的总体方差取平均值以用于样本量计算？</title>
      <link>https://stats.stackexchange.com/questions/654048/can-population-variance-from-multiple-studies-be-averaged-to-use-for-a-sample-si</link>
      <description><![CDATA[想象一下，您正在计划一项临床试验，以评估一种新疗法对改善慢性中风患者 VO2peak 的有效性。根据 Jin 等人的初步研究，您使用 Jin 等人报告的 VO2peak 方差估计试验所需的样本量。
来自 Jin 等人的数据：

VO2peak 方差：2.5 ml/kg/min
估计样本量：每组 40 名参与者

但是，您后来发现，您的试点研究中的方差比 Jin 等人的估计值高得多。
来自其他研究的数据：

DaCun：方差 = 10 ml/kg/min
Mac：方差 = 15 ml/kg/min
Len：方差 = 20 ml/kg/min
Ive：方差 = 18 ml/kg/min
Glob：方差 = 25 ml/kg/min

修订方法：
现在，您不再仅仅依赖 Jin 等人的方差估计，而是包括来自这些其他研究的数据：

来自其他研究的平均方差：(10 + 15 + 20 + 18 + 25) / 5 = 17.6 ml/kg/min

修订样本量计算：使用这个更高的平均方差，您可以计算出一个新的样本量估计值。


结果：

新的样本量估计：每组 80 名参与者（基于更高的平均方差）

这是一种可接受的方法吗？计算样本量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654048/can-population-variance-from-multiple-studies-be-averaged-to-use-for-a-sample-si</guid>
      <pubDate>Sun, 08 Sep 2024 17:52:41 GMT</pubDate>
    </item>
    <item>
      <title>使用蒙特卡洛实验验证异方差和自相关稳健 SE 的一致性</title>
      <link>https://stats.stackexchange.com/questions/654007/verifying-consistency-of-heteroscedasticity-and-autocorrelation-robust-ses-with</link>
      <description><![CDATA[我试图通过蒙特卡洛实验证明 R 的 sandwich 包中给出的默认 HAC 标准误差的一致性。我使用的线性模型定义为 $Y = X + \varepsilon$，其中 $X_i \sim N(1,1)$，$X\perp\varepsilon$，以及 $\varepsilon \sim N(\mathbf 0, \Sigma)$，其中
$ \boldsymbol\Sigma_{ij} = \rho^{|i-j|}$，其中 $\rho \in (-1,1)$。如果 $\hat{\beta}$ 是 OLS 估计量，我们可以将其渐近方差简化如下：
$$ \text{Avar}(\hat {\beta}) = \text{E}[X&#39;X]^{-1}X&#39;\Sigma X(X&#39;X)^{-1} = \frac{1}{2n(1-\rho)} - \frac{\rho(1-\rho^n)}{2n^2(1-\rho)^2}.$$
我已经通过以下蒙特卡洛实验验证了这个数学公式：
library(mvnfast)
library(tidyverse)
library(sandwich)

set_Sigma_ij &lt;- function(i, j, rho){
rho^abs(i-j)
}

generate_Sigma &lt;- function(rho, n){
expand_grid(i = 1:n, j = 1:n) %$% 
map2_dbl(i, j, \(i,j) set_Sigma_ij(i,j, rho)) %&gt;% 
matrix(nrow = n) 
}

draw_ols_realization &lt;- function(n, rho){
eps &lt;- rmvn(
n = 1, 
mu = rep(0, n), 
sigma = generate_Sigma(rho = rho, n = n)
) %&gt;% 
as.numeric()
X &lt;- rnorm(n = n, mean = 1, sd = 1)
Y &lt;- X + eps
lm(Y ~ X - 1) %&gt;% 
coef()
}

true_avar_ols &lt;- function(n, rho){
(1/(2*n*(1-rho))) - (rho*(1-rho^n)) / (2*n^2 * (1-rho)^2)
}

numerical_avar_ols &lt;- function(N, n, rho){
1:N %&gt;% 
map_dbl(\(t) draw_ols_realization(n, rho)) %&gt;% 
var()
}

# 插入几个值以确认（对于足够大的 n）
true_avar_ols(n = 140, rho = 0.8)
numerical_avar_ols(N = 1e4, n = 140, rho = 0.8)

当我确认 HAC 标准误差（或者更确切地说是相应的协方差矩阵）始终估计 $\text{Avar}(\hat {\beta})$ 时，结果没有多大意义。这是我的代码：
estimate_avar_beta &lt;- function(n, rho, X, Y){
estimate_model &lt;- lm(Y[1:n] ~ X[1:n] - 1) 
tibble(
standard = as.numeric(vcov(estimated_model)),
HAC = as.numeric(vcovHAC(estimated_model)),
sample_size = n
)
}

# 估计固定 (Y, X) 的 Avar(OLS)，同时让 n 增长
estimate_avar_beta_over_n &lt;- function(n_vals, rho){
eps &lt;- rmvn(
n = 1, 
mu = rep(0, max(n_vals)), 
sigma = generate_Sigma(rho = rho, n = max(n_vals))
) %&gt;% 
as.numeric()
X &lt;- rnorm(n = max(n_vals), mean = 1, sd = 1)
Y &lt;- X + eps
n_vals %&gt;% 
map_df(\(n) HAC_SEs(n, rho, X, Y))
}

# 现在执行此操作 N 次 
draw_N_estimates_avar_beta_over_n &lt;- function(N, n_vals, rho){
1:N %&gt;% 
map_df(\(t) draw_HAC_SEs_over_n(n_vals, rho))
}

结果 &lt;- draw_N_estimates_avar_beta_over_n(
N = 1e2, 
n_vals = (1:10)*100, 
rho = 0.9
)

vcovHAC 给出的估计值似乎不一致。
我在这里做错了吗？如果是，是什么？ n = 1000 的样本量是否太小？我对 $\text{Avar}(\hat {\beta})$ 的表达是否不正确？我是不是犯了一个愚蠢的错误，盯着这个看了一个多小时后才发现？提前谢谢大家！]]></description>
      <guid>https://stats.stackexchange.com/questions/654007/verifying-consistency-of-heteroscedasticity-and-autocorrelation-robust-ses-with</guid>
      <pubDate>Sat, 07 Sep 2024 16:51:28 GMT</pubDate>
    </item>
    <item>
      <title>（高斯） copula 模拟中给定相关参数与经验相关之间的差距</title>
      <link>https://stats.stackexchange.com/questions/653956/gap-between-the-given-correlation-parameter-and-the-empirical-correlation-in-ga</link>
      <description><![CDATA[现在我尝试用我希望的相关矩阵作为初始参数来模拟正常的 copula。我发现经验相关性通常低于输入的初始参数。
为了简化问题，我们考虑一个初始参数为 0.5 的双变量高斯 copula。
我在 R 中创建了以下代码作为说明：
converg_corr_copula &lt;- function(num_sim, n, param){

result &lt;- data.frame(matrix(ncol=2))[-1,]
names(result) &lt;- c(&quot;seed&quot;,&quot;corr_emp&quot;)

for (i in 1:n){

set.seed(i)
cp_gaus &lt;- normalCopula(param = param, dim = 2,dispstr = &quot;un&quot;)
copula_sim &lt;- rCopula(n = num_sim, copula = cp_gaus) %&gt;% as.data.frame()
result[nrow(result)+1,] &lt;- c(i,cor(copula_sim)[2])

}

return(c(mean(result$corr_emp),sd(result$corr_emp)))
}

lapply(c(1e2,1e3,1e4,1e5,1e6,1e7), converg_corr_copula, n = 50, param = 0.5)


从结果中我们可以看出，经验值以 0.48 为中心，标准差随着模拟次数的增加而减小。
[[1]]
[1] 0.48122020 0.06987925

[[2]]
[1] 0.47687772 0.02583187

[[3]]
[1] 0.481539045 0.007837956

[[4]]
[1] 0.48220804 0.00260011

[[5]]
[1] 0.4827420303 0.0008324203

[[6]]
[1] 0.4826076828 0.0002399406

请问有人知道为什么会这样吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653956/gap-between-the-given-correlation-parameter-and-the-empirical-correlation-in-ga</guid>
      <pubDate>Fri, 06 Sep 2024 09:16:25 GMT</pubDate>
    </item>
    </channel>
</rss>