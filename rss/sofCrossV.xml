<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 23 Jan 2025 06:23:10 GMT</lastBuildDate>
    <item>
      <title>使用 Shapley 值分析特征对低估和高估的影响</title>
      <link>https://stats.stackexchange.com/questions/660399/analysis-of-features-impact-on-under-prediction-and-over-prediction-using-shapl</link>
      <description><![CDATA[请告诉我我的理解是否正确。

您可以将上面的图片视为 Shapley 力图。箭头表示特征从基值推动预测的方向。在我的 xgboost 回归模型（用于预测未来的实际波动率）中，我为每个样本实例获得了不同的基值。
我想识别预测不足的样本实例中的坏特征和好特征。坏特征会导致预测不足并将预测推向左侧。好的特征通过将预测推向右侧来防止低估。
我将低估的实例分为具有低于和高于基准值的基本事实的实例。
对于低于基准值的基本事实实例，青色箭头方向表示真正试图将预测向上推从而防止低估的好特征。然后，我简单地将这些实例上每个特征的 SHAP 值相加，并将每个特征的总 SHAP 值从高到低（从下向上）排序，如下所示。

对于高于基准值的基本事实实例，红色箭头方向表示真正试图将预测向下推从而导致低估的坏特征。然后，我只需对这些实例中的每个特征的 SHAP 值求和，并将每个特征的总 SHAP 值从低到高（从下向上）排序，如下所示。

我推理出真正好的特征和坏特征的方式正确吗？
我可以做任何改进吗？
当我尝试对过度预测实例执行相同操作时。我注意到一个问题。如图所示，防止低估的相同特征会导致过度预测。我该如何推理？我想从两个集合（即防止低估的集合和导致高预测的集合）中找到互斥的特征，并将它们标记为好特征和坏特征。您能否澄清这种方法是否正确？如果这种方法不合理，请建议其他方法。谢谢。

我的想法是丢弃坏特征并找到好特征的相互作用，然后将它们包括在内以改善低估和高预测的情况。]]></description>
      <guid>https://stats.stackexchange.com/questions/660399/analysis-of-features-impact-on-under-prediction-and-over-prediction-using-shapl</guid>
      <pubDate>Thu, 23 Jan 2025 05:47:51 GMT</pubDate>
    </item>
    <item>
      <title>这是重复测量吗？如何在 Kruskal-Wallis 检验中考虑这一点？</title>
      <link>https://stats.stackexchange.com/questions/660398/is-it-a-repeated-measure-how-to-allow-for-this-in-kruskal-wallis-test</link>
      <description><![CDATA[我正在尝试确定分析数据的最佳方法。因此，我正在观察接受兽医手术的动物，这些动物的身体两侧都会留下小伤口。我正在测试 4 种不同的伤口处理策略（每种治疗方法 20 只动物）。手术后的第二天对动物进行了检查以评估伤口，每个伤口的评分为 1-5（1=最好，5=最差），因此反应可以归类为序数。因此，每只动物最终都会得到 2 个分数，这是重复测量吗（即使它是在同一时间测量的并且是相同的治疗方法）？我计划使用 Kruskal-wallis 检验来比较治疗组，但如果这是重复测量，我该如何将其考虑在内？或者有更好的测试吗？
数据示例（总共有 80 只动物）



动物 ID
治疗
左分数
右分数




1
C
3
4


2
K
1
3


3
P&lt; /td&gt;
4
4


4
T
3
3


5
K
3
2


]]></description>
      <guid>https://stats.stackexchange.com/questions/660398/is-it-a-repeated-measure-how-to-allow-for-this-in-kruskal-wallis-test</guid>
      <pubDate>Thu, 23 Jan 2025 04:42:23 GMT</pubDate>
    </item>
    <item>
      <title>Metropolis-Hastings 算法和接受概率</title>
      <link>https://stats.stackexchange.com/questions/660394/metropolis-hastings-algorithm-and-acceptance-probability</link>
      <description><![CDATA[根据我从维基百科中了解到的内容，在 Metropolis-Hastings 算法中，我们希望构建转移概率密度，以满足详细的平衡：
$P(x^{\prime},x) \pi(x)=P(x|x^{\prime})\pi(x^{\prime}) $
在上面的等式中，$\pi$ 是我们想要从中抽样的概率密度分布，$P$ 是转移概率密度。
原因是在马尔可夫链随机游走中构造上述转移概率密度，我们最终达到稳定状态，然后访问每个状态的次数与我们感兴趣的分布成正比。
通过将转移概率密度分为两部分来证明算法的合理性：

选择候选状态$x^\prime$的提议概率密度$g(x^\prime|x)$。
接受$A(x^\prime, x)$的概率（我不确定是概率密度还是概率质量）。
因此$P(x^\prime |x)=g(x^\prime|x)A(x^\prime, x)$。
接受概率分配如下：
$A(x^\prime, x) = min(1, \frac{\pi(x^\prime)g(x|x^\prime)}{\pi(x)g(x^\prime|x)})$。

这是我的问题：
算法将 $A$ 与 0 到 1 之间的随机数进行比较，以决定是否转换到状态 $x^\prime$。
但是，转换概率密度为 $P$。
我不明白这样一个不使用 $P$ 进行跳跃的马尔可夫链如何能够具有与 $\pi$ 成比例的静止状态。
算法使用 $A$ 进行跳跃的方式就好像 $A$ 是转移概率密度一样。
换句话说，我期望我们计算 $P$，然后将其与 0 到 1 之间的随机数进行比较。
我认为我错了，因为 $P$ 有一个数字，可以通过将其与均匀随机数进行比较来进行马尔可夫链模拟。实际上，构建 $P$ 仍然无法明确我们可能跳转到哪个状态，因此将这个概率密度分解为选择候选状态然后计算接受度的步骤。选择候选状态并根据接受度概率决定是否跳转的过程与构建所有 $P$ 然后以某种方式进行跳转的过程相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/660394/metropolis-hastings-algorithm-and-acceptance-probability</guid>
      <pubDate>Wed, 22 Jan 2025 23:45:05 GMT</pubDate>
    </item>
    <item>
      <title>为什么混合效应模型（lme）与固定效应模型（fixest）相比较慢？</title>
      <link>https://stats.stackexchange.com/questions/660393/why-is-mixed-effects-model-lme-slow-compared-to-fixed-effects-model-fixest</link>
      <description><![CDATA[我对固定效应建模的计量经济学方法还不熟悉。我刚刚尝试了我的第一个模型，但对所实现的速度感到难以置信。
这是我们的中断时间序列模型的混合效应模型规范：
##混合效应模型
m &lt;- nlme::lme(
specific_language_of_interest ~ 
work_experience + #随时间变化的控制变量 
latest_twitter_follower_count + latest_twitter_total_tweets + ##随时间不变的控制变量
time + event + time:event, ## 中断时间序列变量，时间整数范围从 0 到 1800 天
random = ~ time|user_id, corAR1(form = ~time | user_id), weights = varExp(form = ~time), method = &#39;REML&#39;, ## 用于解决异方差和自相关的模型参数
data = df)

以下是固定效应规范中的可比模型：
pdat &lt;- panel(df, ~user_id + time)
fixest_m &lt;- feols(specific_language_of_interest ~
               work_experience + #control variable that are time-variant
                       time + event + time:event | user_id，## 中断时间序列变量和固定效应
data = pdat)

lme() 混合效应模型需要大约 8-10 小时才能收敛，而使用 fixest 的固定效应模型则需要不到一秒钟。
由于我是计量经济学领域的新手，我不确定我是否做错了什么。这两个模型确实不等价吗？如果它们是等价的，为什么 fixest 比 lme 快这么多？]]></description>
      <guid>https://stats.stackexchange.com/questions/660393/why-is-mixed-effects-model-lme-slow-compared-to-fixed-effects-model-fixest</guid>
      <pubDate>Wed, 22 Jan 2025 22:36:00 GMT</pubDate>
    </item>
    <item>
      <title>我可以针对不同的独立变量（特征）使用不同的核函数吗？我应该这样做吗？</title>
      <link>https://stats.stackexchange.com/questions/660389/can-i-use-different-kernel-functions-for-different-independent-variables-featur</link>
      <description><![CDATA[我正在使用核回归来模拟多个独立变量和一个因变量之间的非线性关系。我了解核函数和带宽选择，但我想知道是否有可能或有益地对不同类型的独立变量使用不同的核函数。
例如：

特征 1：连续变量（例如，以平方米为单位的大小）。
特征 2：离散变量（例如，房间数量）。

使用以下方法是否有意义：

特征 1（连续）使用 高斯核？
特征 2（离散）使用 三角核？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660389/can-i-use-different-kernel-functions-for-different-independent-variables-featur</guid>
      <pubDate>Wed, 22 Jan 2025 18:35:03 GMT</pubDate>
    </item>
    <item>
      <title>计算或估计稀疏编码模型（即 LASSO、基追踪等）中数据的边际似然</title>
      <link>https://stats.stackexchange.com/questions/660383/computing-or-estimating-marginal-likelihood-of-data-in-sparse-coding-model-i-e</link>
      <description><![CDATA[我有一个模型，它将波形表示为字典中元素的稀疏线性组合。这是使用平方欧几里得误差和$\ell_1$正则化建模的，相当于具有拉普拉斯先验的高斯似然。这本质上是一个贝叶斯 LASSO，在这种情况下也称为“基础追踪”。
我想根据模型计算某些数据的可信度。具体来说，给定一个数据点$y$，我们的字典能多好地稀疏地表示$y$？ $y$ 的边际似然将提供一个清晰的理论答案，但对于大型字典来说，评估所需的积分似乎很难。
是否有任何简单的闭式表达式？
或者，是否有任何好的近似值或相关的标量可以可靠地估计边际似然？
或者，是否有另一种方法来量化“可信度”（例如，MLE 的似然）？
最后，如果其他稀疏线性模型简化了这个计算，我愿意接受建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/660383/computing-or-estimating-marginal-likelihood-of-data-in-sparse-coding-model-i-e</guid>
      <pubDate>Wed, 22 Jan 2025 16:51:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 Anderson-Darling 假设检验 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/660382/using-anderson-darling-hypothesis-test</link>
      <description><![CDATA[我有一个自定义 PDF 分布函数。我想测试自定义 PDF 分布函数是否适合数据，并将其与其他内置分布（如正态分布、威布尔分布、莱斯分布、中上分布和瑞利分布）进行比较。自定义 pdf 函数如下所示
function pdf_values = bivariate_pdf_r(r, phi, mr, mi, sr, si, cf)

% 定义正值的自定义 PDF 函数
f = @(r, phi) r&#39;.* (1 / (2 * pi * sr * si * sqrt(1 - cf^2))) .* ...
exp((-1 / (2 * (1 - cf^2))) * (((r .* cos(phi) - mr).^2 / sr^2) + ...
((r .* sin(phi) - mi).^2 / si^2) - 2 * cf * (r .* cos(phi) - mr) .* (r .* sin(phi) - mi) / (sr * si)));

% 在样本点处评估函数
pdf_values = f(r, phi);
end
]]></description>
      <guid>https://stats.stackexchange.com/questions/660382/using-anderson-darling-hypothesis-test</guid>
      <pubDate>Wed, 22 Jan 2025 16:35:51 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么估算器来估计不同名称的数量？</title>
      <link>https://stats.stackexchange.com/questions/660372/what-estimator-of-the-number-of-distinct-names-should-i-use</link>
      <description><![CDATA[我有 $N$ 个信封，每个信封都包含一张写有姓名的便条。有些姓名出现在多张便条上。总共有 $X$ 个不同的姓名。
为了弄清 $X$ 是什么，我打开 $n$ 个信封，找到 $x$ 个不同的姓名。
我应该使用什么 $X$ 估计量？理想情况下，我希望得到 $X$ 的估计量，并带有置信区间。
编辑：我不知道姓名计数遵循什么分布。但我知道我打开的信封中重复了多少次。如果有帮助的话，可以假设单个名字的最大出现次数比$N$小得多（&lt;1%）。]]></description>
      <guid>https://stats.stackexchange.com/questions/660372/what-estimator-of-the-number-of-distinct-names-should-i-use</guid>
      <pubDate>Wed, 22 Jan 2025 11:25:23 GMT</pubDate>
    </item>
    <item>
      <title>是否可以拥有在集群内变化的 2 级变量？</title>
      <link>https://stats.stackexchange.com/questions/660355/can-you-have-a-level-2-variable-that-varies-within-a-cluster</link>
      <description><![CDATA[我正在尝试创建一个包含 1 级和 2 级预测因子的 2 级回归模型。但是，我的一个预测因子是非自均值变量。
这个非自均值的解释：假设它与回答“是”的问题数量有关（总共 5 个问题，因此范围是 0-5），我们将其命名为“N_Yes”。对于集群 A，假设我们有 n 个参与者。我会将这 n 个人的 N_Yes 加起来，得到 S_Yes = sum(N_Yes)（对于整个集群来说，这是相同的）。然后，对于这个集群中的每个参与者，他们的非自均值 = (S_Yes - N_Yes)/(n-1)。因此，基本上，这会导致集群中所有人的平均值，不包括该参与者本人。
所以我的问题是，您能否将这个非自身平均值作为 2 级回归模型中的 2 级预测变量（如 R 中的 lme4 或类似模型）？到目前为止，我看到的所有内容都表明 2 级变量不应该在集群内变化。如果模型可以在 2 级使用此变量运行，它会正常运行，还是会成为您不想做的事情？您将如何处理这种情况？
使用这种奇怪方法的理由：我想调查一些问题的“同伴效应”，这涉及估计一个人周围环境的平均水平，不包括自己。这对于大型集群来说可能微不足道，但对于少于 15 个且有异常值的集群，它可能很有意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/660355/can-you-have-a-level-2-variable-that-varies-within-a-cluster</guid>
      <pubDate>Wed, 22 Jan 2025 04:42:19 GMT</pubDate>
    </item>
    <item>
      <title>给定时间序列数据集中，输出与输入相比时间偏移不规则</title>
      <link>https://stats.stackexchange.com/questions/660346/irregular-time-shifts-of-output-compared-to-inputs-in-given-time-series-data-set</link>
      <description><![CDATA[我有一些具有多个特征的时间序列数据。输出发生了偏移（我的意思是，输出值的时间与相应的输入发生了偏移，而且偏移不规律）。我对偏移量有一些了解，但并不准确。有没有办法使用长短期记忆 (LSTM) 神经网络来考虑这些不规则的偏移？或者在训练 LSTM 模型之前有什么预处理可以提供帮助？]]></description>
      <guid>https://stats.stackexchange.com/questions/660346/irregular-time-shifts-of-output-compared-to-inputs-in-given-time-series-data-set</guid>
      <pubDate>Tue, 21 Jan 2025 21:56:41 GMT</pubDate>
    </item>
    <item>
      <title>确保回归参数估计值始终为正</title>
      <link>https://stats.stackexchange.com/questions/660343/making-sure-that-a-regression-parameter-estimate-is-always-positive</link>
      <description><![CDATA[我有兴趣了解如何完成以下任务：

假设我有两个变量 $X_t$ 和 $Y_t$ 的月度数据。我有兴趣为 $Y_t$ 创建一个 ARIMAX 模型，该模型依赖于 $Y_t$ 和 $X_t$ 的旧版本。我可以像这样编写基本的 ARIMAX 模型：
$$ y_t = c + \phi_1y_{t-1} + \beta x_{t-1} + \epsilon_t $$
但是，我希望此模型具有以下属性：假设其他所有条件都相同，$X_{t-1}$ 的较大值必须产生 $Y_t$ 的较大值，而 $X_{t-1}$ 的较小值则不能产生。从数学上讲，我认为这可以理解为 $\beta$ 必须始终为正。我希望模型尊重这一事实。
$$ \frac{\partial y_t}{\partial x_{t-1}} = \beta &gt; 0 $$
$$ y_t = c + \phi_1y_{t-1} + \beta x_{t-1} + \epsilon_t $$
$$ \text{subject to: } \beta &gt; 0 $$
我想知道我们如何在模型中强制执行这一点。我天真地想到了两种方法：


基本约束：我不确定如何为这个 ARIMAX 模型写出基本可能性，但它应该是这样的：

$$ L(c, \phi_1, \beta|\textbf{y},\textbf{x}) $$
如果我希望 $\beta$ 为正，我应该能够写出一个受约束的可能性并使用拉格朗日函数来解决这个问题：
$$ \log L(c, \phi_1, \beta|\textbf{y},\textbf{x}) $$
$$ \beta \geq \epsilon $$
$$ \mathcal{L} = \log L(c, \phi_1, \beta|\textbf{y},\textbf{x}) + \lambda(\beta - \epsilon) $$

贝叶斯方法：我认为，如果我策略性地选择先验，我就可以确保 $\beta$ 始终为正。使用贝叶斯原理，我写了联合先验和后验：

$$ P(\theta) = P(\beta)P(c)P(\phi_1)P(\sigma^2) $$
$$ P(\theta|\textbf{y},\textbf{x}) = \frac{L(\theta|\textbf{y},\textbf{x})P(\theta)}{\int L(\theta|\textbf{y},\textbf{x})P(\theta)d\theta} $$
然后在$\beta$上，我可以放置一个先验，例如半正态（https://en.wikipedia.org/wiki/Half-normal_distribution) 以确保正性，但我不确定要使用哪些其他分布作为其他参数的先验。我认为 $\sigma^2$ 上的先验也需要是具有正支持的分布，因为方差不能为负。

我不确定这些方法是否可行且合乎逻辑。社区能否就此提供一些建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/660343/making-sure-that-a-regression-parameter-estimate-is-always-positive</guid>
      <pubDate>Tue, 21 Jan 2025 21:16:28 GMT</pubDate>
    </item>
    <item>
      <title>如何训练具有较小ECE（预期校准误差）的模型？</title>
      <link>https://stats.stackexchange.com/questions/660282/how-to-train-a-model-with-a-small-ece-expected-calibration-error</link>
      <description><![CDATA[如果我们训练一个具有交叉熵损失的深度学习模型，我们期望该模型具有较低的交叉熵损失。有没有办法训练模型，使模型获得较小的预期校准误差，同时保持负对数似然较小？或者有没有好的后处理方法来降低 ECE，同时保持交叉熵损失较小？]]></description>
      <guid>https://stats.stackexchange.com/questions/660282/how-to-train-a-model-with-a-small-ece-expected-calibration-error</guid>
      <pubDate>Mon, 20 Jan 2025 19:19:42 GMT</pubDate>
    </item>
    <item>
      <title>R 中的生存回归问题：处理非删失数据和模型收敛问题</title>
      <link>https://stats.stackexchange.com/questions/660263/issues-with-survival-regression-in-r-handling-non-censored-data-and-model-conve</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660263/issues-with-survival-regression-in-r-handling-non-censored-data-and-model-conve</guid>
      <pubDate>Mon, 20 Jan 2025 09:37:55 GMT</pubDate>
    </item>
    <item>
      <title>需要有关时间序列分析中使用的数据的帮助</title>
      <link>https://stats.stackexchange.com/questions/660195/need-help-regarding-the-data-used-in-time-series-analysis</link>
      <description><![CDATA[我是时间序列的初学者。我试图通过获取过去 10 年的月度数据来预测棉花作物的价格。但价格数据仅适用于 1 月至 5 月，然后是 11 月和 12 月。由于棉花在这里是季节性作物，因此没有其他月份的市场数据。那么在这种情况下，我该如何进行时间序列分析，以及我应该采取多少个最小数据点来运行模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/660195/need-help-regarding-the-data-used-in-time-series-analysis</guid>
      <pubDate>Sat, 18 Jan 2025 10:11:48 GMT</pubDate>
    </item>
    <item>
      <title>数据中的季节性问题</title>
      <link>https://stats.stackexchange.com/questions/659240/seasonality-problem-in-a-data</link>
      <description><![CDATA[我有一个系列。我在 J-demetra 做季节性测试。数据是每月的，从 2003:01 到 2024:07。

我该如何处理这个季节性？请建议方法或程序？]]></description>
      <guid>https://stats.stackexchange.com/questions/659240/seasonality-problem-in-a-data</guid>
      <pubDate>Thu, 26 Dec 2024 19:23:11 GMT</pubDate>
    </item>
    </channel>
</rss>