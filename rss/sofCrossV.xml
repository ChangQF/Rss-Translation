<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 25 Jan 2024 12:27:05 GMT</lastBuildDate>
    <item>
      <title>我正在尝试为学校作业做 MLE，为什么我会收到此错误：[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637733/i-am-trying-to-do-mle-for-school-assignment-why-could-i-be-getting-this-error</link>
      <description><![CDATA[ #1) 找到最佳拟合分布参数
最佳拟合（macamil2data）
# {&#39;loglaplace&#39;: {&#39;c&#39;: 1.0603278885766216,
#&#39;位置&#39;：-0.04671203840594998，
#&#39;规模&#39;：10.230045114772532}}

#2) 使用所述参数计算 pdf
def loglaplace_loglikelihood（参数，数据）：
    c，loc，比例=参数
    返回 stats.loglaplace.logpdf(data, c=c, loc=loc, scale=scale).sum()

#3) 最小化使用所述参数
初始参数 = [1.0603278885766216, -0.04671203840594998, 10.230045114772532]
结果=最小化（loglaplace_loglikelihood，initial_params，args =（macamil2data））

打印（结果）

 消息：由于精度损失，不一定能实现所需的误差。
  成功：假
   状态：2
      乐趣：楠
        x: [ 5.127e+03 -1.765e+05 -1.945e+03]
      尼特：2
      江淮：【楠楠楠】
 hess_inv：[[ 6.876e-01 -1.388e+01 5.195e-02]
            [-1.388e+01 5.437e+02 5.473e+00]
            [ 5.195e-02 5.473e+00 1.000e+00]]
     NFEV：464
     新值：116


macamil2数据=
0.916666
1
3.3
3.38333
3.68333
4.16667
4.2
6.08333
6.61667
7.03333
7.5
7.85
8.15
9.08333
9.35
10.0833
10.1833
10.4333
11.2833
14.2
16.5333
20.0333
23.8333
30.35
30.5167
32.4667
37.1
40.8167
45.6
52
70.0667
70.5333
85.2333
130.967
]]></description>
      <guid>https://stats.stackexchange.com/questions/637733/i-am-trying-to-do-mle-for-school-assignment-why-could-i-be-getting-this-error</guid>
      <pubDate>Thu, 25 Jan 2024 11:17:30 GMT</pubDate>
    </item>
    <item>
      <title>计算无偏归一化自相关函数时是否更改平均值/标准差？</title>
      <link>https://stats.stackexchange.com/questions/637732/do-you-change-the-mean-standard-deviation-when-calculating-the-unbiased-normal</link>
      <description><![CDATA[我正在尝试计算无偏归一化自相关函数。我认为这个领域有点复杂，因为不同的来源似乎使用不同的术语来描述相同的事物，并且使用相同的术语来描述不同的事物，所以我会尽力具体说明我的意思。
我想对离散时间序列 $x[n]=(x_1,x_2,x_3...x_N)$ 作为函数执行自相关时间滞后 $\tau$，其中 $\tau$ 是一个整数。我会使用的自相关函数是
$$\mathrm{AC}[\tau]=\frac{1}{N-\tau}\sum_{n=1}^{N} \frac{(x[ n]-\bar{x})*(x[n+\tau]-\bar{x})}{\sigma_x^2}$$
其中 $\bar{x}=\frac{1}{N}\sum_{n=1}^N x[n]$ 和 $\sigma_x=\sqrt{\frac{1}{N}\sum_{n=1}^N(x[n]-\bar{x})^2}$ 是分别为平均值和标准差$^\mathrm{*}$。
对于 $\tau=0$ 来说，没有时间滞后，信号与其自身完美重叠，并且值归一化为 1。对于滞后 &lt; span class=&quot;math-container&quot;&gt;$\tau=1$，信号每一侧没有不再重叠的元素，对于 $\tau =2$现在有两个不重叠的元素，等等
我的问题是，我是否应该使用 $\bar{x}$ 和 $\sigma_x 相同的值$ 对于所有 $\tau$，或者我应该重新计算 $\bar{x}$ 和 $\sigma_x$ 仅包含重叠的元素？因此，在下图中，当 $\tau=2$ 时，我是否应该仅使用元素 3-11 和 1-9 重新计算平均值和标准差？&lt; /p&gt;
$\tau$ = 0、1 和 2。
我的直觉是不，并对所有 $\tau$ 使用元素 1-11，但是当我这样做时，我不再具有绑定的自相关函数-1 到 1 之间，请参阅下面我的具体示例。
$\tau$ 使用相同的均值和标准差，且不受 1 和 -1 的限制。这里注意，x 轴中的 $\tau$ 不是元素数量，而是时间。由于采样频率为4MHz，4个元件的位移为1$\mu$s。 $N$=4096 在此示例中。
*我知道，如果我使用时间序列的样本而不是整个时间序列，我应该在计算中除以 $N-1$标准差，但在我的工作中 N&gt;&gt;1，所以为了简单起见，我将其省略）。]]></description>
      <guid>https://stats.stackexchange.com/questions/637732/do-you-change-the-mean-standard-deviation-when-calculating-the-unbiased-normal</guid>
      <pubDate>Thu, 25 Jan 2024 11:04:31 GMT</pubDate>
    </item>
    <item>
      <title>什么测试可以比较干预前后的结果？</title>
      <link>https://stats.stackexchange.com/questions/637731/what-test-for-comparing-results-before-and-after-an-intervention</link>
      <description><![CDATA[我正在写一篇论文，其中我们向医生展示了一组患者的一些实验室结果，并要求他盲目地对诊断说“是”或“否”。然后，我告诉他患者的病史和其他重要信息，请他看相同的实验室结果，并请他再次进行诊断。有了这些信息，我可以构建两个 2x2 列联表，其中包含真阳性和阴性以及假阳性和阴性，以获得每个列联表的敏感性和特异性结果。
我想看看这些变化是否具有统计显着性。我应该使用什么测试来计算它？我知道分布不是正态的，所以我想应该使用非参数检验。我看了一点，认为麦克尼马斯的测试是合适的，但我不知道如何根据两个列联表来计算它。有什么帮助吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/637731/what-test-for-comparing-results-before-and-after-an-intervention</guid>
      <pubDate>Thu, 25 Jan 2024 10:55:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Welch 的 t 检验结果与 Welch 的方差分析不同？</title>
      <link>https://stats.stackexchange.com/questions/637730/why-do-welchs-t-test-results-differ-from-welchs-anova</link>
      <description><![CDATA[我有 Python 中三种不同浆果类型之间海拔的数据（Raspberry、Sunberry、Cranberry），以下是数据：&lt; /p&gt;
 高程作物站点
0 6.38606 R 1
1 3.86458 R 2
2 3.52326 S 3
3 4.74866 R 4
4 4.84225 S 5
………………
163 5.01838 R 8
164 4.91557 S 9
165 5.05761 R 10
166 3.83972 R 11
167 3.83046 R 12

以及有关群组的一些一般统计数据：
&lt;前&gt;&lt;代码&gt;意思是：
参考值：1.938
小号：4.419
C：3.892

标准差：
参考值：2.542
小号：2.046
C：1.987

观测点数量
R：n = 11
小号：n = 6
C：n = 5

我假设它们生长的平均海拔是不同的，我想对此进行测试。我知道方差和组大小不同，因此我选择手动对每个组比较进行 Welch t 检验。然而，当我使用韦尔奇的方差分析测试来比较所有三组时，我得到了不同的结果。这是代码：
导入 pandas 作为 pd
导入 scipy.stats 作为统计数据
将 pingouin 导入为 pg

df = pd.read_csv(&#39;路径/to/data.csv&#39;)

print(stats.ttest_ind(df[df[&#39;Crop&#39;] == &#39;R&#39;].Elevation.dropna(), df[df[&#39;Crop&#39;] == &#39;S&#39;].Elevation.dropna(), equal_var =错误的））
print(stats.ttest_ind(df[df[&#39;Crop&#39;] == &#39;R&#39;].Elevation.dropna(), df[df[&#39;Crop&#39;] == &#39;C&#39;].Elevation.dropna(), equal_var =错误的））
print(stats.ttest_ind(df[df[&#39;Crop&#39;] == &#39;S&#39;].Elevation.dropna(), df[df[&#39;Crop&#39;] == &#39;C&#39;].Elevation.dropna(), equal_var =错误的））

# 执行 Welch 方差分析
welch_result = pg.welch_anova(data = df, dv = &#39;高程&#39;, Between = &#39;作物&#39;)

# 显示 Welch 方差分析结果
print(&quot;韦尔奇方差分析结果：&quot;)
打印（welch_结果）

# 使用 Games-Howell 测试进行成对比较
tukey_results = stats.pairwise_tukey(data = df, dv = &#39;海拔&#39;, Between = &#39;作物&#39;)

# 显示成对比较
print(&quot;\n成对比较（Tukey 测试）：&quot;)
打印（tukey_结果）

测试结果不同：
韦尔奇的 t 检验
Ttest_indResult（统计量= -2.084，p值= 0.06）
Ttest_indResult（统计量= -1.591，p值= 0.14）
Ttest_indResult（统计量= 0.4319，p值= 0.68）

韦尔奇方差分析 w.图基-克莱默
成对比较（Tukey 测试）：
   A B 均值(A) 均值(B) diff se T p-tukey 对冲
0 C R 3.89297 1.93853 1.95444 0.127238 1.536054 0.299653 0.771389
1 C S 3.89297 4.41998 0.52701 0.138132 -0.381527 0.923255 -0.238423
2 R S 1.93853 4.41998 2.48145 0.120228 -2.063948 0.127460 -0.987895

韦尔奇方差分析 w.游戏豪厄尔
   A B 均值(A) 均值(B) ... T df pval 对冲
0 C R 3.89297 1.93853 ... 1.591293 10.313845 0.292242 0.771389
1 C S 3.89297 4.41998 ... -0.431931 8.735549 0.903374 -0.238423
2 R S 1.93853 4.41998 ... -2.084965 12.385126 0.133544 -0.987895

为什么会发生这种情况？
值得相信哪一个：来自 Welch 的方差分析，而不是一遍又一遍地使用 Welch 的 T 检验进行手动成对比较？
干杯]]></description>
      <guid>https://stats.stackexchange.com/questions/637730/why-do-welchs-t-test-results-differ-from-welchs-anova</guid>
      <pubDate>Thu, 25 Jan 2024 10:42:20 GMT</pubDate>
    </item>
    <item>
      <title>不确定数据的二项式检验</title>
      <link>https://stats.stackexchange.com/questions/637729/binomial-test-with-uncertin-data</link>
      <description><![CDATA[我获得了人口中某些元素是否具有某些特征的观察数据。我想看看携带该特征的概率是否小于某个阈值。这可以通过某种显着性水平 $\alpha$ 的二项式检验轻松完成。
问题是观察结果存在一定的不确定性。有一定概率 $\gamma$ 该特征未被注意到。因此，我的数据中不具有该特征的元素数量将被高估。我的问题是如何将不确定性 $\gamma$ 纳入我的测试中，从而使显着性水平 $\ alpha$ 被保留。]]></description>
      <guid>https://stats.stackexchange.com/questions/637729/binomial-test-with-uncertin-data</guid>
      <pubDate>Thu, 25 Jan 2024 10:40:06 GMT</pubDate>
    </item>
    <item>
      <title>Z 测试没有相关样本量，因为我有高斯概率分布</title>
      <link>https://stats.stackexchange.com/questions/637728/z-test-with-no-relevant-sample-size-as-i-have-a-gaussian-probability-distributio</link>
      <description><![CDATA[我有两条高斯曲线，没有样本，这些本质上只是概率分布。所以我可以对它们进行高斯拟合，或者对数据进行加权平均值和加权方差，并且我得到了均值和方差值。
我想计算某种度量来描述两条高斯曲线的差异。当然，首先想到的是 z 检验，因为它同时考虑了两条曲线之间均值的变化和方差，并吐出一个 z 值来描述它。这正是我想要的（因为最终我想比较我在不同条件下计算的 2 条高斯曲线的 z 值）。问题是 z 检验方程中有样本数，这与我的情况无关。有没有办法做到这一点，或者我可以使用其他指标吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/637728/z-test-with-no-relevant-sample-size-as-i-have-a-gaussian-probability-distributio</guid>
      <pubDate>Thu, 25 Jan 2024 10:33:48 GMT</pubDate>
    </item>
    <item>
      <title>通过多重比较控制 II 类错误</title>
      <link>https://stats.stackexchange.com/questions/637726/controlling-type-ii-error-with-multiple-comparisons</link>
      <description><![CDATA[在我不想拒绝零假设的情况下，我对如何对多重比较进行校正感到困惑。
我正在做多个方差分析，我想证明各组之间没有显着差异。经过多次比较，我想调整测试结果。然而，典型的方法是为了控制 I 类错误（当 H0 为真时意外地拒绝它）而设计的，但在这种情况下我关心的是 II 类错误（意外地接受 H0&lt; /code&gt; 当它为 false 时）。
我的问题有两个：

我的统计设计有意义吗？ （您是否曾经设计过一个实际上不想拒绝零假设的测试？）
如果是，如果我的目标是控制 II 类错误，我应该如何调整多重比较测试的结果？

似乎等价测试可能是解决这两个问题的方法，但从未使用过它，我不确定如何将其应用于多个组，或者它是否是最好的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/637726/controlling-type-ii-error-with-multiple-comparisons</guid>
      <pubDate>Thu, 25 Jan 2024 09:54:50 GMT</pubDate>
    </item>
    <item>
      <title>选择关键变量的多元统计标准</title>
      <link>https://stats.stackexchange.com/questions/637725/multivariate-statistical-criterion-to-select-key-variables</link>
      <description><![CDATA[我有一个包含多个预测变量的复杂数据集 $X_i$ ($i=1,...,m $）和几个结果变量 $Y_j$ $(j=1,...,n$&lt; /跨度&gt;）。问题在于许多预测变量彼​​此相关，并且结果变量也相关。我希望有一个强大的程序来区分重要的预测变量和输出变量（即哪些预测变量能够更好地解释每个输出变量，以及哪些输出变量通常更可预测）。我在 $X_i$ 上尝试了 PCA，但它似乎过于重视最相关的 $X_i$ span&gt; 变量，无论它们对 $Y_j$ 的解释力如何（老实说，这是有道理的，因为算法没有考虑 $Y_j$)。我还查看了参考书目，并看到了大量的方法：典型相关分析、多元回归、逐步回归、套索……但来源对每种方法的功效声称存在很大差异。那么有没有一种强大、广泛的方法来解决这个问题呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/637725/multivariate-statistical-criterion-to-select-key-variables</guid>
      <pubDate>Thu, 25 Jan 2024 08:52:48 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中提取 DCC-GARCH 模型的标准残差？模型的诊断测试？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637724/how-to-extract-the-standard-residuals-of-a-dcc-garch-model-in-r-diagnostics-tes</link>
      <description><![CDATA[在 R 中形成 DCC Garch 模型后，模型的诊断测试（例如多元 Ljung 统计）需要有关模型残差的信息。我对从 DCC garch 模型中提取残差的命令有疑问。
下面的命令正确吗？
res=残差(dcc.fit)
此外，R 中用于序列相关的 L-jung Box 统计和 DCC Garch 模型的 ARCH 测试统计的命令是什么？下面的命令正确吗？
mq(res,lag=10,adj=0)
ArchTest(res)
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/637724/how-to-extract-the-standard-residuals-of-a-dcc-garch-model-in-r-diagnostics-tes</guid>
      <pubDate>Thu, 25 Jan 2024 08:14:05 GMT</pubDate>
    </item>
    <item>
      <title>如何证明强化学习中策略 π 下轨迹的概率 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637720/how-can-i-prove-probability-of-the-trajectory-under-policy-%cf%80-in-reinforcement-le</link>
      <description><![CDATA[
我可以证明 $P(A_t, S_{t+1}, ... , S_T|S_t$~$\pi) = \Pi^{T-1}_{k=t}\pi(A_k|S_k)p(S_{k+1}|S_k,A_k)$
但我无法证明 $P(A_t, S_{t+1}, ... , S_T|S_t,A_{t:T-1}$~ $\pi) = \Pi^{T-1}_{k=t}\pi(A_k|S_k)p(S_{k+1}|S_k,A_k)$ 
假设 $T = t+1$ 然后 $P(A_t, S_{t+1}|S_t, A_t) =\pi(A_t|S_t)p(S_{t+1}|S_t,A_t)$
我认为 $\pi(A_t|S_t)p(S_{t+1}|S_t,A_t) = p(A_t, S_{t+1}|S_t)$
那么 $P(A_t, S_{t+1}|S_t,A_t) = p(A_t, S_{t+1}|S_t)$ 是这样吗？ 
我很困惑，请帮助我......]]></description>
      <guid>https://stats.stackexchange.com/questions/637720/how-can-i-prove-probability-of-the-trajectory-under-policy-%cf%80-in-reinforcement-le</guid>
      <pubDate>Thu, 25 Jan 2024 06:18:03 GMT</pubDate>
    </item>
    <item>
      <title>寻求调解和 SEM 最佳实践参考</title>
      <link>https://stats.stackexchange.com/questions/637719/seeking-references-for-mediation-and-sem-best-practices</link>
      <description><![CDATA[序言
最近，一位同事向我提供了一个数据集$^1$，他们希望用该数据集来比较使用结构方程模型 (SEM) 的多个中介模型。我一直拟合的模型很简单，比如X -&gt; Y-&gt; Z，使用 lavaan 一切进展顺利。
问题
我对验证性因素分析 (CFA) 有相当多的了解，但对当前涉及调解和 SEM 的最佳实践几乎一无所知。有人能给我一些好的最新参考资料吗？我并不是在寻找“介绍”。但涵盖最佳实践的文章。谢谢！
$^1$ 我的数据集的特征对我的问题来说并不是特别重要，尽管这三个因素中的每一个都用 4 Likert 量表来衡量是否有帮助项目（即总共 12 个项目），每个项目有 5 个回答选项。]]></description>
      <guid>https://stats.stackexchange.com/questions/637719/seeking-references-for-mediation-and-sem-best-practices</guid>
      <pubDate>Thu, 25 Jan 2024 05:56:20 GMT</pubDate>
    </item>
    <item>
      <title>给定缺陷率，需要测试的最少样本数量是多少才能确认问题已以 90% 的置信度得到解决？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/637717/given-a-defect-rate-what-is-the-minimum-number-of-samples-need-to-be-tested-to</link>
      <description><![CDATA[例如，我们在测试的 1000 个随机样本中发现了 13 个缺陷。现在问题已解决。为了确认缺陷率在 90% 的置信度下降低到 0.1%，我们需要测试的最少样本数量是多少？ （我们事先不知道这个缺陷。我们认为这个问题是随机发生的。我们没有明确的根本原因以及问题是否真正得到解决。这就是为什么我们依靠统计观察来确定问题是否得到解决） .]]></description>
      <guid>https://stats.stackexchange.com/questions/637717/given-a-defect-rate-what-is-the-minimum-number-of-samples-need-to-be-tested-to</guid>
      <pubDate>Thu, 25 Jan 2024 03:29:05 GMT</pubDate>
    </item>
    <item>
      <title>SPSS 中 PROCESS 4.2 中的简单中介分析。结果变量是二元的，中介变量是连续的，IV 是二元的</title>
      <link>https://stats.stackexchange.com/questions/637715/simple-mediation-analysis-in-process-4-2-in-spss-the-outcome-variable-is-binary</link>
      <description><![CDATA[在第一个模型中，IV (X) 显着预测中介变量 (M)。
在第二模型中，中介显着预测了结果变量 (Y)，但 IV (X) 未预测结果变量 (Y)。
在第三模型中，X 对 Y 的直接影响不显着。 X对Y的间接影响显着。
我记得几年前进行中介分析时，IV（系数）的数量在添加中介后会减少。这表明中介调节了 IV 和结果之间的关系。然而，这里第二模型中的IV(X)的系数数与第三模型中的相同。此外，IV 和结果变量的关系一开始就应该很重要。在我的调解中，这始终是不重要的。我记得过去写道“当将中介输入模型时，DV 的显着 IV 效应变得不显着”。在这里，我不能这样说，因为 PROCESS 根本没有显示 IV 和 DV 之间的显着关系。因此，我什至不知道如何解释结果。我应该回到进行中介分析的旧方法吗？简单明了。]]></description>
      <guid>https://stats.stackexchange.com/questions/637715/simple-mediation-analysis-in-process-4-2-in-spss-the-outcome-variable-is-binary</guid>
      <pubDate>Thu, 25 Jan 2024 02:58:46 GMT</pubDate>
    </item>
    <item>
      <title>具有嵌套数据的随机截距与随机斜率线性混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/637705/random-intercept-vs-random-slope-linear-mixed-effects-model-with-nested-data</link>
      <description><![CDATA[我读过很多关于线性混合效应 (LME) 模型中的随机截距与随机斜率的内容，但我对如何在嵌套数据方面考虑它们感到困惑。我看过其他帖子（例如，参见此处&lt; /a&gt;），但很难找到与我的数据中存在的嵌套类型相匹配的示例。这类似于我之前的问题 此处，但我想将其作为一个单独的问题，因为这更关注数据的嵌套方面。
就背景而言，我有一项涉及 15 个受试者的研究。每个受试者（在不同的一天）穿着不同的鞋子执行任务。我有 5 双不同的鞋子（被视为分类变量 A、B、C、D、E）。他们上午执行该任务 10 次，下午执行 10 次。这意味着我总共有 15 名受试者 * 5 只鞋子 * 一天 2 次 * 10 次测量/会话 = 1500 次观察。我想了解这双鞋和一天中的时间最终如何影响他们在任务中的表现。
本研究中的数据本质上嵌套在多个级别：1）鞋子嵌套在受试者内，2）一天中的时间嵌套在鞋子内。从网上阅读来看，解释这种嵌套的一种常见方法似乎是在 LME 模型中使用嵌套的随机截距项。就我而言，我认为看起来如下：
Y ~ 鞋子 + TimeOfDay + (1|主题/鞋子/TimeOfDay)
但是，从我对随机斜率的解读来看，我不清楚这个仅截距模型是否能够解释不同随机效应变量之间的相关性。例如，我认为可以合理地假设鞋子对每个主题的影响可能会有所不同。类似地，一天中的时间对每个主题的影响可能会有所不同。因此，我考虑的另一种随机斜率模型如下：
Y ~ 鞋 + TimeOfDay +（鞋 + TimeOfDay | 主题）
这里需要注意的一点是，Shoe 和 TimeOfDay 都是分类变量，这本身就让我对使用随机斜率感到困惑。
我的问题如下：

第一个模型和第二个模型在处理数据的嵌套性质方面有什么根本区别？
通常更喜欢其中一种吗？做出这一决定时会考虑哪些因素？
因为 Shoe 和 TimeOfDay 都是分类变量，所以会发生什么变化吗？在大多数情况下，我看到连续变量使用随机斜率，因此不确定当它们是分类变量时它是否仍然有意义。
]]></description>
      <guid>https://stats.stackexchange.com/questions/637705/random-intercept-vs-random-slope-linear-mixed-effects-model-with-nested-data</guid>
      <pubDate>Thu, 25 Jan 2024 01:39:27 GMT</pubDate>
    </item>
    <item>
      <title>随机安慰剂对照试验的样本量计算示例</title>
      <link>https://stats.stackexchange.com/questions/637697/example-of-sample-size-calculation-for-a-randomized-placebo-controlled-trial</link>
      <description><![CDATA[我正在尝试在以下文章中重现样本大小的计算：


n = 每组所需的样本量
p1 = 阿奇霉素组的死亡比例
p2 = 安慰剂组的死亡比例
p1-p2 = 临床显着差异 = 0.15（或 15%）

如何根据提供的信息确定p1和p2？]]></description>
      <guid>https://stats.stackexchange.com/questions/637697/example-of-sample-size-calculation-for-a-randomized-placebo-controlled-trial</guid>
      <pubDate>Wed, 24 Jan 2024 23:07:10 GMT</pubDate>
    </item>
    </channel>
</rss>