<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 30 Nov 2024 12:31:48 GMT</lastBuildDate>
    <item>
      <title>如何区分互动与中介？</title>
      <link>https://stats.stackexchange.com/questions/658060/how-to-distinguish-interaction-from-mediation</link>
      <description><![CDATA[我一直在思考我作为一项随机临床试验的一部分进行的分析。这项研究包括三次重复测量，每个个体被跟踪三次。然而，我的问题不是关于模型的纵向方面，而是关于所涉及的理论和统计概念。
具体来说，我分析了一个感兴趣的生物标记，它可能受到参与者体重的影响。在我的模型中，我测试了性别和体重之间的相互作用，以及其他协变量。以下是模型设置：
#sexo_s1:sex
#i_huleptin: 感兴趣的生物标志物
# peso1:weight
#grupo_int_v00: 临床试验组

lme_leptin &lt;- lme(i_huleptin ~ sexo_s1*peso1 + edad_s1 + poly(time, 2)*grupo_int_v00 + p17_total, 
random = ~ poly(time, 2)|paciente, control=lmeControl(opt=&quot;optim&quot;),
data = dat_longer, subset = !is.na(i_huleptin))
summary(lme_leptin)
res_lme_leptin &lt;- as.data.frame(coef(summary(lme_leptin)))

现在，这就是我感到困惑的地方：我对中介分析了解一点，中介解释了 X（独立变量）影响 Y（结果）的机制或途径。然而，从概念上讲，中介和交互对我来说似乎很相似。例如，在交互中，我们测试 X1 和 Y 之间的关系是否取决于
X2。从统计上讲，我知道这两种分析是不同的，但我不确定何时应用中介分析而不是交互分析。
更复杂的是，我的研究涉及重复测量，我不确定中介是否适用于这种情况。这可能是一个单独的问题，但我非常感谢您对这些观点的任何见解或指导。
非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/658060/how-to-distinguish-interaction-from-mediation</guid>
      <pubDate>Sat, 30 Nov 2024 08:22:14 GMT</pubDate>
    </item>
    <item>
      <title>如何最好地预测显示水平变化和方波类型噪声行为的时间序列</title>
      <link>https://stats.stackexchange.com/questions/658059/how-to-best-forecast-a-time-series-showing-level-changes-and-square-wave-kind-of</link>
      <description><![CDATA[这是 2019 年 3 月至 12 月每隔 1 分钟测量一次的交流电力数据。我想对时间序列进行建模，但样本外预测基本上是恒定的。我从 EDA 中发现了以下内容：

每个工作日的上午 8 点到下午 5 点功率较高，其余时间功率较低。
周六和周日功率较低，其他日子功率较高。

因此，似乎在小时级别和天级别存在季节性。
数据图及其季节性分解如下所示，

我尝试使用带有 exog 变量的 ARIMA 作为一天中的小时和一周中的天，以及带有季节性周期的 SARIMA。由于数据量太大，我暂时无法得到结果。
寻找一些关于如何解决这个问题的指示。
如果我想预测分钟级数据，我是否仍需要平滑数据。在我看来，ARIMA/SARIMA 不起作用，基于 ML 的方法可能更适合。
ARIMA 模型非常适合输入样本，但输出样本只是一个常数值，根本没有跟踪模式。
我是时间序列的新手，很乐意根据需要提供其他信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/658059/how-to-best-forecast-a-time-series-showing-level-changes-and-square-wave-kind-of</guid>
      <pubDate>Sat, 30 Nov 2024 07:05:56 GMT</pubDate>
    </item>
    <item>
      <title>包括两组用于元分析池的后测设计研究？</title>
      <link>https://stats.stackexchange.com/questions/658055/include-two-groups-post-test-design-study-for-meta-analysis-pool</link>
      <description><![CDATA[我是荟萃分析的新手，目前正在尝试寻找干预对服务用户的影响。
我发现的大多数研究都是 RCT 或准实验研究，采用 2 组事前事后测试设计。但是，有几项研究是 2 组事后测试设计，没有可用的事前测试数据。我想知道我是否可以将这个事后测试设计研究纳入荟萃分析池？或者只是将事后测试设计研究排除在荟萃分析之外？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658055/include-two-groups-post-test-design-study-for-meta-analysis-pool</guid>
      <pubDate>Sat, 30 Nov 2024 05:04:19 GMT</pubDate>
    </item>
    <item>
      <title>在没有相关系数 r 值的情况下进行组内荟萃分析</title>
      <link>https://stats.stackexchange.com/questions/658054/performing-within-group-meta-analysis-without-access-to-correlation-coefficient</link>
      <description><![CDATA[这个想法是对干预的单组研究进行荟萃分析，其中存在连续结果变量的基线测量和干预后测量。结果变量始终以相同的尺度进行测量，并且没有研究涉及对照组。计划是计算平均增益。
我遇到的问题是，我理解，在处理组内、干预前后情景时，计算我需要进行荟萃分析的效应大小的标准误差“需要”相关 r 值。这些 r 值从未在文献中报告过，必须进行估算，这似乎非常成问题。我有没有选择在没有相关 r 项的情况下进行荟萃分析？
我所拥有的只是干预前时间 1 的平均值、sd 和 n，以及干预后时间 2 的平均值、sd 和 n。
我正在使用 metafor 在 R 中工作 - 正在走“4a”路径。]]></description>
      <guid>https://stats.stackexchange.com/questions/658054/performing-within-group-meta-analysis-without-access-to-correlation-coefficient</guid>
      <pubDate>Sat, 30 Nov 2024 05:02:06 GMT</pubDate>
    </item>
    <item>
      <title>假设两个变量的条件独立，则它们的条件是独立的</title>
      <link>https://stats.stackexchange.com/questions/658052/conditional-independence-of-two-variables-assuming-their-conditionals-are-indepe</link>
      <description><![CDATA[设 $X, Y, Z$ 为随机变量。众所周知，$X \mathbin{\bot} Y$ 并不意味着 $X \mathbin{\bot} Y \mathbin{|} Z$，反之亦然。但是，如果随机变量 $X \mathbin{|}Z$ 与 $Y\mathbin{|}Z$ 独立，这是否意味着 $X \mathbin{\bot} Y\mathbin{|}Z$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658052/conditional-independence-of-two-variables-assuming-their-conditionals-are-indepe</guid>
      <pubDate>Sat, 30 Nov 2024 01:14:14 GMT</pubDate>
    </item>
    <item>
      <title>解释一致性概率：排除同等结果和平局的作用</title>
      <link>https://stats.stackexchange.com/questions/658051/interpreting-concordance-probability-exclusion-of-equal-outcomes-and-role-of-ti</link>
      <description><![CDATA[一致概率 $P(C)$ 定义为模型预测概率正确对两个观察结果进行排序的可能性。它考虑了三种类型的成对比较：

一致对：当 $\hat{p}(X_i) &gt; \hat{p}(X_j)$ 和 $Y_i &gt; Y_j$，或 $\hat{p}(X_i) &lt; \hat{p}(X_j)$ 和 $Y_i &lt; Y_j$。
不一致对：当 $\hat{p}(X_i) &gt; \hat{p}(X_j)$ 且 $Y_i &lt; Y_j$，或 $\hat{p}(X_i) &lt; \hat{p}(X_j)$ 且 $Y_i &gt; Y_j$.
平局：当 $\hat{p}(X_i) = \hat{p}(X_j)$.

该公式通过添加其贡献的一半来合并平局：
$$
P(C) = \frac{\text{一致对的数量} + 0.5 \times \text{平局数量}}{\text{其中 } Y_i \neq Y_j} 的对总数。
$$
设：

$C$ = 一致对的数量，
$D$ = 不一致对的数量，
$T$ = 并列对的数量。

可比对的总数为 $C + D + T$，并且 $P(C)$ 变为：
$$
P(C) = \frac{C + 0.5T}{C + D + T}。
$$

问题：
在计算一致性概率$P(C)$时，我们通过为它们分配 0.5 的权重来包含平局。但是，我们仍然排除$Y_i = Y_j$的对。

如何将$P(C)$解释为“概率”当它仅以 $Y_i \neq Y_j$ 为条件时？
此外，包含 $0.5 \times \text{ties}$ 是否足以证明将其称为概率，还是仅仅是处理排名歧义的启发式方法？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658051/interpreting-concordance-probability-exclusion-of-equal-outcomes-and-role-of-ti</guid>
      <pubDate>Fri, 29 Nov 2024 23:44:55 GMT</pubDate>
    </item>
    <item>
      <title>机器学习主题如何融入传统本科统计课程的估算？</title>
      <link>https://stats.stackexchange.com/questions/658050/how-do-machine-learning-topics-fit-into-a-traditional-undergraduate-statistics-c</link>
      <description><![CDATA[我最近在教本科生统计学入门课程，但根据项目主任的要求，需要在其中添加一些机器学习材料。我想知道将机器学习材料（偏差-方差权衡、过拟合和欠拟合、训练和测试、正则化和模型选择、性能评估）注入估计主题（传统材料包括矩估计量、MLE、无偏性、效率、不确定性量化）的适当方法是什么，以及如何组织这一部分的好方法是什么？
我觉得很难以一种井井有条、合乎逻辑的方式组织这种机器学习和统计学元素的混合。如果你能建议一个合理的安排这两个主题，那就太好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/658050/how-do-machine-learning-topics-fit-into-a-traditional-undergraduate-statistics-c</guid>
      <pubDate>Fri, 29 Nov 2024 23:33:07 GMT</pubDate>
    </item>
    <item>
      <title>事后分析有相互作用但没有主效应</title>
      <link>https://stats.stackexchange.com/questions/658049/post-hoc-analysis-whith-interaction-but-no-main-effects</link>
      <description><![CDATA[
我正在审查一种情况，其中有两个因素（杀虫剂、除草剂），每个因素都有两个水平（不存在、存在）。杀虫剂或除草剂没有主效应，但存在交叉相互作用。
假设我使用 Tukeys-HSD 事后检验 - 4 意味着这通常会导致 6 次成对比较和相应的 p 值调整。在我概述的没有主效应但有显著交叉相互作用的情况下，事后检验的次数是否应该减少，因为只有 4 次比较具有潜在意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/658049/post-hoc-analysis-whith-interaction-but-no-main-effects</guid>
      <pubDate>Fri, 29 Nov 2024 22:20:45 GMT</pubDate>
    </item>
    <item>
      <title>推导指数族中的尺度参数</title>
      <link>https://stats.stackexchange.com/questions/658038/deriving-scale-parameter-in-exponential-family</link>
      <description><![CDATA[以下内容摘自 Casella &amp; Berger 的《统计推断》（2024 年版）第 98 页：

第 3.3 节中介绍的几个家族要么是尺度家族，要么有尺度家族
作为子家族。如果 α 是固定值且 β 是尺度参数，则这些家族为伽马家族，如果 µ = 0 且 σ 是尺度参数，则这些家族为正态家族，指数家族，如果 µ = 0 且 σ 是尺度参数，则这些家族为双指数家族。在每种情况下，标准 pdf 都是通过将尺度参数设置为 1 获得的 pdf。然后，该家族的所有其他成员都可以证明为定义 3.5.4 中的形式。

这是第 3.5.4 页上出现的定义 3.5.4。 97:

定义 3.5.4 设 $f(x)$ 为任意 pdf。则对于任意 $\sigma &gt; 0$，pdf 家族 $(1/\sigma)f(x/\sigma)$，由参数 $\sigma$ 索引，被称为具有标准 pdf $f(x)$ 的尺度家族，而 $\sigma$ 被称为该家族的尺度
参数。

因此，我一直在试图证明 $\mathbf{\theta}$ 是尺度指数家族的尺度参数，其 pdf 给出为 $f(x|\mathbf{\theta})=h(x)c(\mathbf{\theta})\exp{\sum_{i=1}^{k}w_{i}(\mathbf{\theta})t_{i}(x)}$ 在第 90 页。另请参阅第 90 页。 92,

这里 $h(x) \geq 0$ 和 $t_{1}(x), \cdots ,t_{k}(x)$ 是观测 $x$ 的实值函数（它们不能依赖于 $\mathbf{θ}$ ），而 $c(\mathbf{θ}) \geq 0$ 和 $w_{1}(\mathbf{θ}), \cdots , w_{k}(\mathbf{θ})$ 是可能的向量值
参数$\mathbf{θ}$（它们不能依赖于$x$）。上一节中介绍的许多常见家族
都是指数家族。这些包括连续家族——正态、伽马和贝塔；和离散族——二项式、泊松和负二项式。

我很难证明这一点，因为关于$h(x)$和$t_{i}(x)$的信息并不多，我是否可以将指数族 pdf 写为$(1/\sigma)f(x/\sigma)$。
所以我的问题是$\theta$是否真的是指数族的比例参数，如果是，如何根据定义证明它？]]></description>
      <guid>https://stats.stackexchange.com/questions/658038/deriving-scale-parameter-in-exponential-family</guid>
      <pubDate>Fri, 29 Nov 2024 18:11:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么卡方检验会给出不直观的结果？</title>
      <link>https://stats.stackexchange.com/questions/658020/why-is-the-chi-square-test-giving-unintuitive-results</link>
      <description><![CDATA[我正在对不同年龄组之间的变量分布进行卡方检验。数据在 R 中如下所示：
 a &lt;- c(66,97, 48)
b &lt;- c(145,174,58)
c &lt;- c(129,128,58)

M &lt;- data.frame(cbind(a,b,c))
colnames(M) &lt;- c(&quot;18-34&quot;, &quot;35-49&quot;,&quot;50-66&quot;)
rownames(M) &lt;- c(&quot;Below avg&quot; , &quot;Average&quot;,&quot;Above avg&quot;)
view(M)

绘制时，最年轻组的数据分布与中间组相似，与最年长组不同。

如果我进行整体卡方检验，我会得到一个不显著的差异：
X-squared = 8.6905, df = 4, p-value = 0.06932

但是，如果我成对比较年龄组，我会得到最小和中间之间的显著差异，而不是最小和最年长之间的显著差异。
数据：M[, 1:2]
X-squared = 6.0153, df = 2, p-value = 0.04941

数据：M3[, c(1, 3)]
X-squared = 5.2093，df = 2，p 值 = 0.07393

我认为这与每个年龄组的参与者数量不平衡有关，尽管每个组的总体观察数量相当大。但我不确定是否以及如何解释这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/658020/why-is-the-chi-square-test-giving-unintuitive-results</guid>
      <pubDate>Fri, 29 Nov 2024 09:07:03 GMT</pubDate>
    </item>
    <item>
      <title>应使用哪种显著性检验来检验均值差异？如何确定？</title>
      <link>https://stats.stackexchange.com/questions/658011/which-significance-test-to-use-for-a-difference-of-means-how-to-be-sure</link>
      <description><![CDATA[我有两个数据集，其中包含这项运动在美国进行的所有官方记录比赛。一个数据集是女子队的，另一个是男子队的。我试图测试男子队是否平均得分更高，我相信他们得分更高。
从数据集中，我将比赛限制为过去二十年的比赛，并且仅限于锦标赛比赛。这给出了大约 200 场比赛的女子样本和大约 300 场比赛的男子样本。我假设比赛在性别内是相互独立的，而不是在性别之间配对的。
然后我合并数据集并添加性别列。因此，这个新数据集有大约 500 行，其中有一列表示该比赛/行是男子比赛还是女子比赛。
我应该选择哪种假设检验，或者现在做出这个选择是否为时过早？
显著性水平：5%
零假设：均值之间没有差异。
备选假设：男性平均得分高于女性平均得分。
我现在在 R 中复制/模拟（？）这个数据集 5000 次，每次计算女性和男性的平均得分，然后取差值。我认为这个差值就是我所谓的检验统计量，我认为所有这 5000 个都可以用来可视化零分布。
在 R 中绘制所有这些差异会显示一个钟形直方图。我相信这是零分布的图，因此假设差异为 0。
因此：观测值是独立的，每组 200 和 300 个样本的数据集足够大，并且检验统计量遵循正态分布。因此，我可以使用非参数方差分析检验来获取 p 值。此检验不要求零分布为正态。但我认为我也可以使用双样本 t 检验，因为事实上，我的底层/零分布是正态的、独立的且较大的。我的想法正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658011/which-significance-test-to-use-for-a-difference-of-means-how-to-be-sure</guid>
      <pubDate>Fri, 29 Nov 2024 00:11:48 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在研究一个重复测量数据集。该研究的目的是观察机构特征 (X) 对由于某种医疗状况 (Y) 导致的几家医疗机构的死亡人数的影响。Y 表示在跨越多年的时间段内每周测量的死亡人数。X 表示在整个研究过程中在多个时间点（每周、每季度、研究开始/结束）测量的连续/分类变量。变量 Y 是零膨胀的，并且由于在模型中包含太多预测因子而导致数值问题。
我的一组 X 变量 (u1、u2、...、un) 与一组其他变量 (v1、v2、...、vn) 相关。这使我无法在同一模型中同时建模 U（总共约 50 个）和 V（总共约 5 个）变量。因此，我对 U 变量进行了建模，并选择了对 Y 有显著影响的 U 变量子集。对于这个子集，我执行了 PCA，并在最终模型中使用了 PCA 分数和 V 变量。我相信这样做可以让它们（U 变量和 V 变量的 PCA 分数）彼此不相关，同时在估计 V 变量时会纳入 U 变量的净效应。
我的最终目标是获得与时间无关的 V 变量预测。
在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法涉及以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 之间的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除非数字变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不均等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    <item>
      <title>如何重新表示概率向量，而不使其值超出 [0, 1] 的界限？</title>
      <link>https://stats.stackexchange.com/questions/657526/how-to-re-mean-a-vector-of-probabilities-without-having-values-beyond-the-0-1</link>
      <description><![CDATA[假设我们有一个概率向量 $x$。其平均值为 $\bar{x}$。现在，假设我们想将向量重新平均为 0 到 1 之间的任意值。这是某个给定的比例 $p$。
我想要做的是从 $x$ 转到 $x&#39;$，其中 $\bar{x&#39;} = p$。但是，这些表示概率，因此也需要满足 $x&#39; \in [0, 1]$。此外，$x&#39;$ 需要保留 $x$ 的相对排序。
实现此目的的一种方法是简单地降低变量的平均数并重新添加 $p$：
$x&#39; = x - \bar{x} + p$
但是，这会强制值低于 0 或高于 1，因此不再表示概率。
实现此目的的另一种方法是将 $x$ 和 $p$ 都带入逻辑空间，在那里重新定义含义，然后将其带回。为了简便起见，我使用 $logit$ 作为逻辑函数，使用 $invlogit$ 作为其逆函数：
$x&#39; = invlogit(logit(x) - \overline{logit(x)} + logit(p))$
但是，概率空间中的平均值将不再是 $p$。
如何重新表示概率向量，而不使值超出 [0, 1] 的界限？
以下是 R 中的演示。
remean &lt;- function(x, p) x - mean(x) + p

remean_logit &lt;- function(x, p) {
x &lt;- qlogis(x)
x &lt;- x - mean(x) + qlogis(p)
return(plogis(x))
}

set.seed(1839)
p &lt;- .56
x &lt;- runif(1000)

summary(x) # 平均值为 .497
summary(remean(x, p)) # 平均值正确，但最大值 &gt; 1
summary(remean_logit(x, p)) # 值在 0 和 1 之间，但平均值不正确
]]></description>
      <guid>https://stats.stackexchange.com/questions/657526/how-to-re-mean-a-vector-of-probabilities-without-having-values-beyond-the-0-1</guid>
      <pubDate>Tue, 19 Nov 2024 19:56:55 GMT</pubDate>
    </item>
    <item>
      <title>GLM：在日志 special.gammaln 中遇到无效值</title>
      <link>https://stats.stackexchange.com/questions/630757/glm-invalid-value-encountered-in-log-special-gammaln</link>
      <description><![CDATA[我以前从未使用过 GLM，所以我想得到一些关于如何使用它的提示，以及我是否遗漏了任何步骤。
我的挑战：
我想知道产品的价格是否受到我可以衡量的其他变量的正面或负面影响：

一天内持续生产产品的机器的生产时间
一天生产一件产品需要多少时间
一天每件产品的人力成本是多少
一天生产多少件产品

我认为使用 GLM 可以帮助我理解这一点。但是，我有两个疑问：

在选择 GLM 的族类型之前，我是否应该研究变量的分布？
我使用 Python 来执行 GLM，但收到警告：


RuntimeWarning：在 log special.gammaln(n -
y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +
RuntimeWarning 中遇到无效值：在 log n * np.log(1 - mu +
1e-20)) * var_weights 中遇到无效值

但我不明白这是什么意思。

我应该如何解释结果？按照教程操作时，系数比我得到的结果更易于解释（例如 0.67）


--- 为了可重复性，以下是我使用的代码 ---
# 创建 Numpy 数组 
array = np.array([[4, 441, 25, 4, 17], 
[10, 444, 49, 8, 9], 
[3, 483, 12, 2, 38],
[2,447,10,1,43],
[4,423,22,3,19],
[3,19,19,3,1],
[18,445,111,17,4],
[7,423,42,7,10],
[9,426,53,8,8],
[12,378,54,8,7],
[36,450,225,36,2],]) 

# 创建列名列表 
column_values = [&#39;CONST&#39;, &#39;ACTUAL_PRODTIME&#39;, &#39;TIME_LOGO&#39;, &#39;COST_PPL_LOGO&#39;, &#39;LOGO&#39;] 

# 创建数据框 
df = pd.DataFrame(data = array, 
columns = column_values) 

model = smf.glm(
formula = &quot;CONST ~ ACTUAL_PRODTIME + TIME_LOGO + COST_PPL_LOGO + LOGO&quot;,
data = df, 
family = sm.families.Binomial())
# 拟合模型
result = model.fit()

# 显示和解释结果
print(result.summary())
]]></description>
      <guid>https://stats.stackexchange.com/questions/630757/glm-invalid-value-encountered-in-log-special-gammaln</guid>
      <pubDate>Wed, 08 Nov 2023 14:12:14 GMT</pubDate>
    </item>
    <item>
      <title>使用蒙特卡洛方法模拟似然比检验 (LRT) p 值</title>
      <link>https://stats.stackexchange.com/questions/603132/simulating-likelihood-ratio-test-lrt-pvalue-using-monte-carlo-method</link>
      <description><![CDATA[我正在尝试弄清楚我的任务，使用蒙特卡罗方法模拟 lrt 测试 p 值输出。据我所知，lrt 测试应该测试“更好”、更准确的模型。
我知道如何执行这样的测试：
嵌套 &lt;- glm(finalgrade~absences,data=grades)
复杂 &lt;- glm(finalgrade~absences+age,data=grades)
lrtest(嵌套，复杂)

从那里我可以返回我的 p 值并执行一些计算，如 I 型和 II 型错误或测试的功效，并查看它如何根据模拟次数而变化。
我的问题是我应该如何模拟随机数据。它不一定是成绩或学校相关的东西，这只是我理解的一个展示。
我正在考虑制作一个有 3 到 4 列的数据框，其中 1 列是依赖值 (0,1)，其余是从正态分布或某个不同分布生成的随机数。
但我不知道这种方法是否会产生可理解的结果，或者这是否有意义。
我查看了这个函数 function，但它并没有真正帮助我理解任何东西。
我想出了这样的东西：
library(lmtest)
n &lt;- 1000
depentend = sample(c(0,1), replace=TRUE, size=n)

pvalue &lt;- c()
for(i in 1:1000) {
independend_x = rnorm(n, mean = 2,sd = 0.2)
independend_y = rnorm(n, mean = 7,sd = 0.5)

nested &lt;- lm(depentend~independend_x)
complex &lt;- lm(depentend~independend_x + independend_y)
lrtest(nested, complex)

pvalue &lt;- c(pvalue, as.numeric(lrtest(nested, complex)[5][2,1]))
}

但我不知道这是否是正确的方向。
如果有人能帮助我理解如何模拟蒙特卡罗采样方法的数据，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/603132/simulating-likelihood-ratio-test-lrt-pvalue-using-monte-carlo-method</guid>
      <pubDate>Wed, 25 Jan 2023 14:50:21 GMT</pubDate>
    </item>
    </channel>
</rss>