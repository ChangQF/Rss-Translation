<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 04 May 2024 12:23:09 GMT</lastBuildDate>
    <item>
      <title>为什么在线计算器中的 Dunn 检验拒绝原假设，而我的手动计算却无法拒绝原假设？</title>
      <link>https://stats.stackexchange.com/questions/646484/why-does-the-dunns-test-in-online-calculator-rejects-the-null-hypothesis-while</link>
      <description><![CDATA[根据我自己的手动计算 Dunn 的测试在 Google 表格中，使用 YouTube 视频中的公式，我设法计算出相同的测试统计数据作为在线计算器。
但是，使用同一 YouTube 视频中的临界值表 (k=3, a=0.05)，我未能拒绝第一对数据 (2.34&lt;2.394) 的假设，而在线计算器的结果成功拒绝第一对的原假设。关于第二对和第三对，我收到与在线计算器相同的关于原假设的决定，但我们似乎对第一对有不同意见。
您可以在下图中看到在线计算器 Dunn 测试的结果： 
他们的临界值似乎比我的（9.38）高，但他们能够成功拒绝原假设。这怎么发生的？为什么他们成功地拒绝了原假设，而我却失败了，即使我们有相同的检验统计量？
如果计算后向下滚动在线计算器，它会显示“下面的 R 代码将产生相同的结果：”
if(!&quot;MultNonParam&quot; %in%installed.packages()){install.packages(&quot;MultNonParam&quot;)}
库（MultNonParam）
if(!&quot;dunn.test&quot; %in%installed.packages()){install.packages(&quot;dunn.test&quot;)}
库（dunn.test）
x1 &lt;- c(14,24,19,14,12,6,14,13,14,25,16,14,12,12,9)
x2 &lt;- c(19,20,30,15,15,21,19,9,20,12,22,22,17,21,25)
x3 &lt;- c(11,29,13,18,14,4,2,19,9,13,21,8,16,16,11)
列表1=列表(x1,x2,x3)
克鲁斯卡尔.测试（列表1）
邓恩.测试（列表1）
nreps &lt;- c(15,15,15)
移位 &lt;- c(0,0.3,0.6)
kwpower(nreps,班次,&#39;正常&#39;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/646484/why-does-the-dunns-test-in-online-calculator-rejects-the-null-hypothesis-while</guid>
      <pubDate>Sat, 04 May 2024 11:50:33 GMT</pubDate>
    </item>
    <item>
      <title>与病理分布的卷积</title>
      <link>https://stats.stackexchange.com/questions/646483/convolution-with-a-pathological-distribution</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/646483/convolution-with-a-pathological-distribution</guid>
      <pubDate>Sat, 04 May 2024 11:39:39 GMT</pubDate>
    </item>
    <item>
      <title>有限事件集上不重复的事件链的概率</title>
      <link>https://stats.stackexchange.com/questions/646476/probability-of-chain-of-events-over-a-finite-set-of-event-with-no-repetition</link>
      <description><![CDATA[我正在尝试解决一个我怀疑与我不熟悉的其他问题相似的问题。我希望得到进一步阅读的指导。问题如下：
我们可以采取一组有限的操作$\mathcal{A}=\{A_i\}_{i=1}^n$。&lt; br /&gt;
我们从一个遵循分布 $ P_x$ 的随机变量 $ X$ 开始。然后，我们将随机选择且不重复的一系列操作应用于 $ X$ 以创建一个新的随机变量 $ Y $ 遵循分布 $ P_Y$。 
令 $Z_0, \ldots, Z_n$ 为在此过程中创建的随机变量链，其中 $Z_0=X$  和 $Z_n=Y$。
我可以计算转换概率$p(Z_{j}|Z_{j-1},A_i)$。
我有兴趣计算特定观察对 $p(Y=y|X=x)$ 的可能性  $(x,y)$.
由于该过程涉及所有步骤和所有操作排列的边缘化，因此我也在寻找蒙特卡洛可能性的估计过程，因为它很容易从$p(Z_{j}|Z_{j-1}, A_i)$。
您知道这个问题是否与我可以查看的已知问题相似吗？还有其他建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646476/probability-of-chain-of-events-over-a-finite-set-of-event-with-no-repetition</guid>
      <pubDate>Sat, 04 May 2024 08:36:58 GMT</pubDate>
    </item>
    <item>
      <title>关于均匀分布的阶次统计的练习</title>
      <link>https://stats.stackexchange.com/questions/646475/exercise-about-order-statistics-from-uniform-distribution</link>
      <description><![CDATA[我正在尝试解决有关顺序统计的练习。
练习如下：

让$U_{(1)}&lt; \ldots &lt;U_{(n)}$ 是均匀分布 U(0,1) 的顺序统计量。
证明 $(-\log[U_{(r)}/U_{(r+1)}]^r) \overset{\underset{\mathrm{d}}{}}{=}Z_{n-r+1}$ 其中 $Z_1, Z_2, \ldots ,Z_n$ 是来自 $\rm Exp(1).$ 的 iid

解决方案首先表明 $(-\log U_{(r)}) \overset{\underset{\mathrm{d}}{}}{=}\frac{1}{n}Z_1+\cdots+\frac{1}{r}Z_{n-r+1}$ 其中 $Z_1,\ldots,Z_n$ 是 iid 的，来自 $\rm Exp(1) $，到目前为止我也理解了。
然后解决方案说 $(-\log[U_{(r)}/U_{(r+1)}]) \overset{\underset{\mathrm{d}}{}}{=}(\frac{1}{n}Z_1+\cdots+\frac{1}{r}Z_{n-r+1})-(\frac{1}{n}Z_1+\cdots+\frac{1}{r+1}Z_{n-r})=\frac{1}{r}Z_{n-r+1}$。因此$(-\log[U_{(r)}/U_{(r+1)}]^r) \overset{\underset{\mathrm{d}}{}}{=}Z_{n-r+1}$。
但是我们可以做这样一个简单的减法吗？
无论如何，我知道这个结论是正确的，从一个著名的(?)结果来看

(这是霍格的著名著作《数理统计学导论》中的练习之一。)
由此，我们可以知道$(-\log U_{(r)}) \overset{\underset{\mathrm{d}}{}}{=}X_{(n-r+1)}$ 其中 $X_1,\dots,X_n$ 来自 Exp(1)。并且 $(-\log[U_{(r)}/U_{(r+1)}]^r) \overset{\underset{\mathrm{d}}{}}{=}r(X_{(n-r+1)}-X_{(n-r)})\overset{\underset{\mathrm{d}}{}}{=}\mathrm{Exp}(1)。$
但是我无法理解解决方案中的减法声明。]]></description>
      <guid>https://stats.stackexchange.com/questions/646475/exercise-about-order-statistics-from-uniform-distribution</guid>
      <pubDate>Sat, 04 May 2024 06:05:34 GMT</pubDate>
    </item>
    <item>
      <title>2组与协变量的比较</title>
      <link>https://stats.stackexchange.com/questions/646473/comparison-of-2-groups-with-covariate</link>
      <description><![CDATA[我比较了两组，发现他们的测试成绩有显着差异。然而，我也发现他们的平均年龄有显着差异。我想看看在去除年龄的影响后，各组之间的分数是否仍然存在显着差异。分数和年龄之间的相关性非常小，0.03。
一种选择是使用 ANCOVA，但在我看来，这是有点过时的技术。
我的另一个选择是使用回归模型，但我无法弄清楚模型，具体来说我的 DV 是什么，我的 IV 是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/646473/comparison-of-2-groups-with-covariate</guid>
      <pubDate>Sat, 04 May 2024 05:26:46 GMT</pubDate>
    </item>
    <item>
      <title>总体 KMO 与因子解释的方差之间的关系</title>
      <link>https://stats.stackexchange.com/questions/646472/relationship-between-overall-kmo-and-variance-explained-by-factors</link>
      <description><![CDATA[Kaiser–Meyer– 的维基百科页面Olkin 检验 表示 KMO“是对可能是共同方差的变量之间方差比例的度量。”
因此，您会看到人们的总体 KMO 为 0.9，然后他们说“这意味着共同因素可以解释我观察到的变量中 90% 的变异性”。
其他问题已经讨论了 KMO。据我所知，高 KMO 意味着完全相关性相对于部分相关性更大。从这个问题我知道对于因子来说这是有道理的分析中，我们不应该希望相对于完全相关的高偏相关，因为高偏相关意味着存在仅加载两个变量的因素。
但是，我不明白这如何映射到整体 KMO 衡量“可能是共同方差的变量之间的方差比例”的想法。根据维基百科。
为什么是可能是共同方差的变量之间的方差比例？这个“可能”取决于什么假设？
获取总体 KMO 值不需要指定要提取的因子数量。但是，如果因子数量等于变量数量，则所有 100% 的方差都由因子解释，那么因子解释的方差量不是由我们提取的因子数量决定吗？我知道实际上计算机程序一般不会允许有那么多的因素。]]></description>
      <guid>https://stats.stackexchange.com/questions/646472/relationship-between-overall-kmo-and-variance-explained-by-factors</guid>
      <pubDate>Sat, 04 May 2024 04:30:44 GMT</pubDate>
    </item>
    <item>
      <title>Matplotlib 图表将不会显示 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/646471/matplotlib-chart-will-not-display</link>
      <description><![CDATA[如果这是一个错误的论坛，我们深表歉意。她是 Python 和数据科学初学者，正在使用 matplotlib 制作基本图表。我在 Mac OS 上使用 Visual Studio Code。
一般来说，我可以创建一个使用 matplotlib 绘制图表的 Python 脚本。我直接在 VSC 的终端窗口中从 VS Code 运行脚本。当我调用绘图的 show() 方法时，输出会在其自己的窗口中弹出。
此代码不会向我显示图表：
&lt;前&gt;&lt;代码&gt;plot_lm_1 = plt.figure(1)

plot_lm_1.set_fightheight(8)
plot_lm_1.set_figwidth(12)
plot_lm_1.axes[0] = sns.residplot(x=model_fitted_y, y=model_residuals,
                          低=真，
                          scatter_kws={&#39;alpha&#39;: 0.5},
                          line_kws={&#39;颜色&#39;: &#39;红色&#39;, &#39;lw&#39;: 1, &#39;alpha&#39;: 0.8})
plot_lm_1.axes[0].set_title(&#39;残差与拟合&#39;)
plot_lm_1.axes[0].set_xlabel(&#39;拟合值&#39;)
plot_lm_1.axes[0].set_ylabel(&#39;残差&#39;)

plot_lm_1.show()

调试语句显示已到达最后一行。但绘图窗口中什么也没有显示。我确信这非常简单 - 提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/646471/matplotlib-chart-will-not-display</guid>
      <pubDate>Sat, 04 May 2024 03:23:56 GMT</pubDate>
    </item>
    <item>
      <title>如何证明多变量情况（即维度 $d\ge 2$）的后验概率？</title>
      <link>https://stats.stackexchange.com/questions/646469/how-to-prove-the-posterior-probability-for-multivariate-case-i-e-dimension-d</link>
      <description><![CDATA[假设有 $k$ 个组，$\pi_1, \pi_2, \cdots, \pi_k$，组 $\pi_i$ 的概率密度函数为 $f_i(\boldsymbol{x})$&lt; /span&gt;，其中 $\boldsymbol x\in R^d$。样本 $\boldsymbol{x}$ 属于组 $\pi_i$ 的先验概率表示为为 $p_i$，其中 $i=1,2, \cdots, k$，且满足条件为 $p_1+p_2+\cdots+p_k=1$。利用贝叶斯理论，可以证明后验概率（即样本$\boldsymbol{x}$属于$\pi_i$ 鉴于 $\boldsymbol{x}$ 已知）的 $\boldsymbol属于 $\pi_i$ 的 {x}$ 计算如下
$$
P\left(\pi_i \mid \boldsymbol{x}\right)=\frac{p_i f_i(\boldsymbol{x})}{\sum_{j=1}^k p_j f_j(\boldsymbol{x})} , \quad i=1,2, \cdots, k。 \标签{1}
$$
当$d=1$时，根据贝叶斯公式
&lt;块引用&gt;
定理（贝叶斯公式）如果事件 $A_1, A_2, \cdots, A_n$ 互斥且 $B$ 是它们并集 $\bigcup_{j=1}^n A_j$ 的子集，那么当$P(B)&gt;0$，则认为
$$
P\left(A_j \mid B\right)=\frac{P\left(A_j\right) P\left(B \mid A_j\right)}{\sum_{i=1}^n P\left(A_i \right) P\left(B \mid A_i\right)}, \quad 1 \leq j \leq n。
$$

我们有
$$
\开始{对齐}
P\left(\pi_i\mid x\right) &amp; =\lim _{\Delta x \rightarrow 0+} P\left(\pi_i \mid x
当$d\ge 2$时如何证明(1)？]]></description>
      <guid>https://stats.stackexchange.com/questions/646469/how-to-prove-the-posterior-probability-for-multivariate-case-i-e-dimension-d</guid>
      <pubDate>Sat, 04 May 2024 02:35:25 GMT</pubDate>
    </item>
    <item>
      <title>softmax 与 3D 图形中的向量归一化相同吗？</title>
      <link>https://stats.stackexchange.com/questions/646480/is-softmax-the-same-as-vector-normalization-in-3d-graphics</link>
      <description><![CDATA[我刚刚发现了机器学习中的softmax 函数。它从数字向量中创建均匀的概率分布，这意味着所有数字最多为 1。
这听起来很像向量标准化 给出 3D 图形中长度为 1 的向量（线性代数）。
谁能解释一下这两者之间的区别吗？我希望这不是一个愚蠢的问题，我能得到答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/646480/is-softmax-the-same-as-vector-normalization-in-3d-graphics</guid>
      <pubDate>Sat, 04 May 2024 00:42:58 GMT</pubDate>
    </item>
    <item>
      <title>阅读多元 Logistic 回归中的箱线图</title>
      <link>https://stats.stackexchange.com/questions/646456/reading-boxplots-in-multiple-logistic-regression</link>
      <description><![CDATA[假设逻辑回归的范例，我在理解一些并行箱线图建议的特定模型时遇到一些困难。例如，这里：

我被告知建议的模型是：
$$\text{log(odds)} = \beta 0 + \beta 1(\text{AHigh}) + \beta 2(\text{AHigh} \times X)$$
换句话说，只有分类变量 ($\text{A=High/Low}$) 和交互项，而不是连续变量 ($X$），但我不确定为什么。 $Y=1$ 组的平均 $X$ 值明显高于 $Y=1$ 组=&quot;math-container&quot;&gt;$Y=0$ 组，那么它不应该很重要吗？什么表明分类变量显着？我该如何判断交互项是否重要？还有第二个情节我同样感到困惑 - 这里建议什么模型？
]]></description>
      <guid>https://stats.stackexchange.com/questions/646456/reading-boxplots-in-multiple-logistic-regression</guid>
      <pubDate>Fri, 03 May 2024 20:48:45 GMT</pubDate>
    </item>
    <item>
      <title>分析无替换抽样与替换抽样中的累积分布函数</title>
      <link>https://stats.stackexchange.com/questions/646199/analyzing-cumulative-distribution-functions-in-sampling-without-replacement-vs</link>
      <description><![CDATA[最初询问数学。
我正在研究 $N$ 位的总体，包括 $K$ 位和 $N-K$ 个零。对于不放回采样 $n$ 位，情况符合超几何分布。这些 $n$ 位的总和 $S_n$ 得出 $n\frac{K}{N}$ 和方差 $n \frac{K}{N} \frac{N-K}{ N}\frac{N-n}{N-1}$。相反，通过替换对 $n&#39;$ 位进行采样与二项分布对齐，总和为 $S_{n&#39;}$  均值为 $n&#39;\frac{K}{N}$ ，方差为 $n &#39; \frac{K}{N} \frac{N-K}{N}$。
为了进行分析，我绘制了归一化和 $\frac{S_n}{n}$ 和 $\frac{S_{n&#39;}}{n&#39;}$，考虑 $n&#39;$ 的值在 &lt; 范围内span class=&quot;math-container&quot;&gt;$\left[n,\lfloor n\frac{N-1}{N-n}\rfloor\right]$。我观察到，对于超过 $\frac{K}{N}$ 的标准化总和，二项式 CDF 始终低于超几何 CDF。 $n&#39;&gt;n\frac{N-1}{N-n}$ 的趋势跟踪时间更长。
如果 $X$ 是一个超几何分布，其中 n 次从规模为 $N 的总体中进行无替换的抽取$ 与 $K$ 成功，并且 $Y$ 是二项式分布 $B(n&#39;,K/N)$，那么 $n&#39;$ 的最大值是多少=&quot;math-container&quot;&gt;$F_Y(f n&#39;)\leq F_X(f n)$ 代表 $f\geq K/N$？&lt; /strong&gt;.
我认为最大 $n&#39;= \lfloor n\frac{N-1}{N-n}\rfloor$。
这是 $\frac{K}{N}=0.5$ 的动画，其中 $N=50$  其中二项式试验的数量固定为 $n&#39;=n\frac{N-1}{N-n}=21$ 和超几何试验的数量固定为 $n=15$。标记为绿色的部分是归一化总和大于 $p=\frac{K}{N}$ 的区域。在此区域中，二项式 CDF 低于超几何 CDF。

我很好奇分布 CDF 之间的这种关系是否是一种公认​​的现象。值得注意的是，如果 $n&#39;。也许这在某种程度上是相关的？有谁知道有关该主题的相关研究文章吗？
这是用于生成这些图的 Mathematica 代码，可针对不同的 $p=K/N$ 值进行调整：
操纵[Nx = 10^2;
 n = 30；
 x = p Nx;
 ListPlot[{表[{k/Floor[二项式试验],
     CDF[BinomialDistribution[Floor[二项式试验], p], k]}, {k, 1,
     地板[二项式试验]}],
   表[{k/n,
     CDF[HypergeometricDistribution[n, Floor[x], Nx], k]}, {k, 1,
     n}]}，已加入 -&gt;正确，PlotRange -&gt;全部，
  情节图例 -&gt; {“垃圾箱”，“炒作”}，
  结语 -&gt; {RGBColor[0, 1, 0, 0.25], 矩形[{p, 0}, {1, 1}], 红色,
    Line[{{p, 0}, {p, 1}}]}], {二项式试验, n, n (Nx - 1)/(Nx - n),
   1}, {p, 10^-2, 1}]


有人有可以解释这种模式的见解或参考吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646199/analyzing-cumulative-distribution-functions-in-sampling-without-replacement-vs</guid>
      <pubDate>Tue, 30 Apr 2024 13:14:46 GMT</pubDate>
    </item>
    <item>
      <title>当备择假设不是原假设的补集时接受备择假设</title>
      <link>https://stats.stackexchange.com/questions/645828/accepting-the-alternative-hypothesis-when-it-is-not-the-complement-of-the-null</link>
      <description><![CDATA[在查看假设检验文献时，我注意到在完成测试后有不同的方式来表达你的结论。
当测试未能拒绝时，似乎存在强烈的共识，即我们不能说我们“接受无效”这是有充分理由的。这主要源于假设检验基本上是“给定特定显着性水平的矛盾证明”的想法。如果我们未能在空值下拒绝（即，在给定空值的情况下，数据不是非常“极端”，但这仍然不意味着空值是真的）。​​
当检验被拒绝时，我们通常会说“在 $\alpha$% 显着性水平上，我们可以说 $H_1$ 得出什么结论。我知道所有这些结论都不是“证据”。并且仅保持在特定显着性水平 $\alpha$ 下，这是限制测试的 I 类错误的结果。我区分两种情况：

$H_1$ 是 $H_0$ 的补集（这当然取决于底层参数空间）。一个例子是我们测试 $H_0: \theta =0 $ 与 $H_1: \theta \ 的经典案例neq 0.$ 我认为大多数人会说，当你的测试在这里被拒绝时，你可以说 $H_0$ 不正确，因此 $H_1$ 必须为 true。请注意，后者对于经典示例来说并不是一个非常有力的主张，因为它几乎包含整个参数空间。尽管如此，当零也是一个复合假设时，我认为我们仍然可以说，当 $H_1$ 是 $H_1$。

$H_1$ 不是 $H_0$ 的补集。一个典型的例子是简单的 null 和简单替代方案，但底层参数空间还包含其他值。在这里，我想说的是，当我们拒绝时，我们不能得出替代方案，我们只能说 null 不为真。


大家对以上说法有异议或者有其他想法吗？我认为这一切都归结于这样一个事实：我们正在处理随机数据，很难对底层 DGP 做出明确的声明。但是，对于政策建议等，我们仍然想提出某种主张，这就是我问这个问题的原因。
编辑：在标准 NHST 框架中，备择假设始终是原假设的补集。因此，第(2)点的表述并不完善。感谢所有提供有用见解的评论。]]></description>
      <guid>https://stats.stackexchange.com/questions/645828/accepting-the-alternative-hypothesis-when-it-is-not-the-complement-of-the-null</guid>
      <pubDate>Thu, 25 Apr 2024 15:38:13 GMT</pubDate>
    </item>
    <item>
      <title>如何对两个不同事件的到达时间进行建模？</title>
      <link>https://stats.stackexchange.com/questions/626209/how-can-you-model-the-arrival-times-of-2-different-events</link>
      <description><![CDATA[我正在研究泊松过程并使用指数分布来模拟事件的到达时间。
例如，一个人到达公交车站的可能性。然后，在简单的情况下，我想对公交车的到达进行建模，并为此使用另一个指数。
我想的是如果发生其他事情怎么办。
例如，这个人改变了主意并决定步行。
在这种情况下，简单地说：

有人到达
发生以下情况之一，以先到者为准

公交车来了
某人感到无聊并决定步行



我可以想象上述情况是独立的，也可以是不独立的情况 - 即，如果这个人已经等了 1 小时，他们更有可能感到无聊。
你会如何处理这个问题？
我想到的一种方法是模拟每一“分钟”。会发生什么。即公共汽车到达的一些可能性，然后他们感到无聊并创建状态转换类型设置的一些可能性。]]></description>
      <guid>https://stats.stackexchange.com/questions/626209/how-can-you-model-the-arrival-times-of-2-different-events</guid>
      <pubDate>Mon, 11 Sep 2023 14:47:04 GMT</pubDate>
    </item>
    <item>
      <title>GPT-2 中神经元的计算：了解方法</title>
      <link>https://stats.stackexchange.com/questions/617654/calculation-of-neurons-in-gpt-2-understanding-the-methodology</link>
      <description><![CDATA[在 OpenAI 最近的更新中，他们提到在 GPT-2 模型中发现了 N 个神经元。这一发现提出了一个问题：他们是如何得出这个计算的？在他们的出版物中，他们没有明确提及确定神经元数量背后的方法。
经过进一步调查，我发现了一组公式，这些公式通常用于估计 GPT-2 等基于 Transformer 的模型中的神经元和参数数量。这些公式虽然 OpenAI 没有具体提及，但为理解计算提供了一个很好的起点。
公式如下：
$$\text{神经元}= H * A * L$$
$$\text{参数} = A * (H^2 / A) * L$$
这里，“H”是表示隐藏尺寸，“A” “L”指模型中注意力头的数量，“L”表示模型中注意力头的数量。表示模型中的层数。
值得注意的是，这些公式对模型架构做出了某些假设。他们假设每个注意力头和层中的神经元数量是恒定的，但实际情况可能并非如此。此外，它们没有考虑 Transformer 模型特有的其他架构元素，例如位置编码和前馈网络。
虽然所提供的公式提供了估计神经元数量的通用方法，但有必要考虑具体的模型架构并参考实际的实现细节以获得更准确的计算。
考虑到这一点，谁能更详细地说明 OpenAI 如何计算 GPT-2 模型中的 N 个神经元？ OpenAI 是否明确提到了他们的方法或提供了对该过程的更多见解？如果对此主题有任何进一步的澄清，我们将不胜感激。
预先感谢您的投入和专业知识！]]></description>
      <guid>https://stats.stackexchange.com/questions/617654/calculation-of-neurons-in-gpt-2-understanding-the-methodology</guid>
      <pubDate>Fri, 02 Jun 2023 10:15:07 GMT</pubDate>
    </item>
    <item>
      <title>给定线性组合的法线乘积的条件期望</title>
      <link>https://stats.stackexchange.com/questions/611331/conditional-expectation-of-product-of-normals-given-a-linear-combination</link>
      <description><![CDATA[我的任务是解决资格考试的问题，但我对这个问题有点迷失。
&lt;块引用&gt;
设$\eta$和$\xi$为两个独立的标准高斯随机变量。查找 $\mathbb{E}(​​\xi\eta \mid \xi - 2\eta)$。

我的尝试：
我的主要想法是证明 $\operatorname{Cov}(\xi-2\eta,\xi+2\eta)=0$，使得两者独立，因为它们是高斯​​分布的。但是，通过上面的计算，您会得到 $\operatorname{Cov}(\xi-2\eta,\xi+2\eta)=\operatorname{Var}(\xi)-4 \operatorname{Var}(\eta)\neq 0$。或者，我的想法是显示 $\operatorname{Cov}(\xi-\eta,\xi+\ eta)=0$，这是正确的。但是 $\xi-\eta \perp \xi+\eta \implies \xi-2\eta \perp \xi+2\eta$ 吗？主要思想是在你展示 $\xi-2\eta \perp \xi+2\eta 之后
$，写入 $\mathbb{E}(​​\eta\xi \mid \xi-2\eta)=\mathbb{E}(​​\frac{1}{ 8}[\xi+2\eta]^{2}+\frac{1}{8}[\xi-2\eta]^{2}\mid \xi-2\eta)
$
并继续。
感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/611331/conditional-expectation-of-product-of-normals-given-a-linear-combination</guid>
      <pubDate>Fri, 31 Mar 2023 00:52:59 GMT</pubDate>
    </item>
    </channel>
</rss>