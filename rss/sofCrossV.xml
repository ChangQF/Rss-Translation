<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 31 Jul 2024 15:16:05 GMT</lastBuildDate>
    <item>
      <title>如何更好地分析二进制和对数尺度数据之间的相关性？</title>
      <link>https://stats.stackexchange.com/questions/652090/how-to-better-analyze-the-correlation-between-binary-and-log-scaled-data</link>
      <description><![CDATA[假设我有两个数据集，如图所示：

data1 是一个由零和一组成的数组，而 data2 是一个实数数组（以对数刻度显示，范围从 10^-12 到 10^5）。
这些数据集之间似乎可能存在某种负相关性。使用 Pearson 的 R，我获得了 -0.0583 的相关系数，p 值为 6.595e-172，表明存在弱负相关性。
我正在寻找一种更可靠的统计方法来描述这些数据集之间的关系，因为 Pearson 相关性可能无法完全捕捉我们视觉上观察到的内容。
我考虑过 Spearman 等级相关性 和 点双序列相关性，但不确定最佳方法或如何进行。您能否就最合适的统计测试或分析提供指导，以更好地理解这种关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/652090/how-to-better-analyze-the-correlation-between-binary-and-log-scaled-data</guid>
      <pubDate>Wed, 31 Jul 2024 14:41:14 GMT</pubDate>
    </item>
    <item>
      <title>Dunnet 是事后检验吗？我应该先进行方差分析吗？</title>
      <link>https://stats.stackexchange.com/questions/652087/is-dunnets-a-post-hoc-test-should-i-perform-anova-first</link>
      <description><![CDATA[我读到 Dunnett 检验基本上是一种事后检验，应该在方差分析（统计显著性）之后进行。
运行此简单代码：
rm(list=ls())
# 加载包
if (!require(DescTools)) install.packages(&#39;DescTools&#39;)
if (!require(ggplot2)) install.packages(&#39;ggplot2&#39;)

# 创建样本数据集
set.seed(1)
data &lt;- data.frame(
treatment = rep(c(&quot;Control&quot;, &quot;Treatment1&quot;, &quot;Treatment2&quot;, &quot;Treatment3&quot;), each = 20),
response = c(rnorm(20, mean = 5, sd = 1),
rnorm(20, mean = 5.1，sd = 1)，
rnorm(20，平均值 = 5.4，sd = 1)，
rnorm(20，平均值 = 4.4，sd = 1))
)

boxplot(数据$response ~data$treatment)


# 执行 ANOVA
anova_model &lt;- aov(response ~ treatment，数据 =数据）
summary(anova_model)

给出：
 Df Sum Sq Mean Sq F 值 Pr(&gt;F) 
treatment 3 11.15 3.715 4.433 0.00632 **
Residuals 76 63.69 0.838 
---
Signif.代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

这告诉我，我的数据中的组均值之间存在统计上的显著差异（查看图表，我会说 Treatment2 和 Treatment3 的均值之间）。
# 执行 Dunnett 检验
DunnettTest(x=data$response, g=data$treatment)

给出：
 Dunnett 检验用于将几种治疗方法与对照组进行比较：
95% 家族置信水平

$Control
diff lwr.ci upr.ci pval 
Treatment1-Control -0.09699539 -0.7908913 0.596900528 0.9750 
治疗2-对照 0.34827290 -0.3456230 1.042168819 0.4880 
治疗3-对照 -0.68878697 -1.3826829 0.005108952 0.0522 . 

---
Signif. 代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

这告诉我，治疗组和对照组的平均值均值均无差异。因此，方差分析在这里毫无帮助，因此我想知道为什么应该先进行方差分析。]]></description>
      <guid>https://stats.stackexchange.com/questions/652087/is-dunnets-a-post-hoc-test-should-i-perform-anova-first</guid>
      <pubDate>Wed, 31 Jul 2024 14:02:50 GMT</pubDate>
    </item>
    <item>
      <title>SAS 在这里做什么以及什么时候它是可以的或有用的？</title>
      <link>https://stats.stackexchange.com/questions/652085/what-is-sas-doing-here-and-when-is-this-ok-or-useful</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652085/what-is-sas-doing-here-and-when-is-this-ok-or-useful</guid>
      <pubDate>Wed, 31 Jul 2024 13:56:02 GMT</pubDate>
    </item>
    <item>
      <title>R interact_plot 的 Python 替代品</title>
      <link>https://stats.stackexchange.com/questions/652083/python-alternative-to-r-interact-plot</link>
      <description><![CDATA[是否有一个 Python 包可以对所有连续和参考级不涉及交互的分类变量进行均值中心化，以便更容易解释交互图中的预测值。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/652083/python-alternative-to-r-interact-plot</guid>
      <pubDate>Wed, 31 Jul 2024 13:41:59 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归：具有多个级别的分类预测器 - 适当的组大小</title>
      <link>https://stats.stackexchange.com/questions/652082/logistic-regression-categorical-predictor-with-many-levels-appropriate-group</link>
      <description><![CDATA[我正在估计一个包含 11 个组的分类预测因子的逻辑回归模型。我想知道我是否可以/应该排除其中一些组（D-K，也许还有 C；见下文），因为每个事件的 n 较小。组 D-K 反正没那么有趣，我最感兴趣的是 A、B 和 C 的比较。这是我的数据分布（A-K：组；Y/N：事件）：
 Y N
A 96 246
B 13 103
C 2 69
D 1 6
E 2 4
F 1 3
G 1 2
H 1 1
I 0 1
J 0 1
K 0 1
]]></description>
      <guid>https://stats.stackexchange.com/questions/652082/logistic-regression-categorical-predictor-with-many-levels-appropriate-group</guid>
      <pubDate>Wed, 31 Jul 2024 13:19:13 GMT</pubDate>
    </item>
    <item>
      <title>使用 LME4 建模干预研究，参与者仅嵌套在一个组中的子组中</title>
      <link>https://stats.stackexchange.com/questions/652075/modelling-intervention-study-using-lme4-and-participants-are-nested-in-subgroups</link>
      <description><![CDATA[我们使用以下变量进行了行为改变现场实验：
两个时间点（T0，T1）
两组（干预组与对照组）
个人 ID（第 1 组中 n = 62，第 2 组中 n = 53）
研讨会 ID（8 个研讨会）
我们正在使用此模型分析 lme4 中的数据
这是我们的模型：
lmer(DV_T1 ~ 1 + group + DV_T0 + (1|workshop_id), data=df)

但是，只有第 1 组的参与者嵌套在子组中（而不是对照组参与者），因此为了模拟研讨会日的随机效应，我们为所有对照组参与者创建了一个假子组。这种随机效应结构（让所有对照组参与者参加同一个“研讨会日”）可能会反映出主组效应（干预组与对照组），从而掩盖干预组的部分主效应。
您认为这是一个问题吗？是否有办法以不同的方式对随机子组效应进行建模？]]></description>
      <guid>https://stats.stackexchange.com/questions/652075/modelling-intervention-study-using-lme4-and-participants-are-nested-in-subgroups</guid>
      <pubDate>Wed, 31 Jul 2024 11:22:22 GMT</pubDate>
    </item>
    <item>
      <title>帮助解决过度拟合问题 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/652074/help-in-overfitting</link>
      <description><![CDATA[我有一个关于街道垃圾报告的数据集。X 数据是特征（时间、地点类型、星期几、人口数量……），y 数据是目标函数（报告数量）。我尝试运行 LR、RF、XGBOOST。我认为 RF 最适合这个，但我的模型过度拟合严重。可能存在什么问题？
输入：
# 将数据拆分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 线性回归
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)
y_train_pred_lin = lin_reg.predict(X_train)
y_test_pred_lin = lin_reg.predict(X_test)

# 计算线性回归的指标
r2_train_lin = r2_score(y_train, y_train_pred_lin)
r2_test_lin = r2_score(y_test, y_test_pred_lin)
rmse_train_lin = np.sqrt(mean_squared_error(y_train, y_train_pred_lin))
rmse_test_lin = np.sqrt(mean_squared_error(y_test, y_test_pred_lin))
std_dev_lin = np.std(y_test_pred_lin)

print(f&#39;NO NAN COLUMNS\nTARGET = NUM​​_OF_REPORTS\n&#39;)
print(f&#39;线性回归 R² (训练): {r2_train_lin}&#39;)
print(f&#39;线性回归 R² (测试): {r2_test_lin}&#39;)
print(f&#39;线性回归 RMSE (训练): {rmse_train_lin}&#39;)
print(f&#39;线性回归 RMSE (测试): {rmse_test_lin}&#39;)
print(f&#39;线性回归 Std Dev (测试预测：{std_dev_lin}\n&#39;)

# 随机森林回归
rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg.fit(X_train, y_train)
y_train_pred_rf = rf_reg.predict(X_train)
y_test_pred_rf = rf_reg.predict(X_test)

# 计算随机森林回归的指标
r2_train_rf = r2_score(y_train, y_train_pred_rf)
r2_test_rf = r2_score(y_test, y_test_pred_rf)
rmse_train_rf = np.sqrt(mean_squared_error(y_train, y_train_pred_rf))
rmse_test_rf = np.sqrt(mean_squared_error(y_test, y_test_pred_rf))
std_dev_rf = np.std(y_test_pred_rf)

print(f&#39;随机森林回归 R² (训练): {r2_train_rf}&#39;)
print(f&#39;随机森林回归 R² (测试): {r2_test_rf}&#39;)
print(f&#39;随机森林回归 RMSE (训练): {rmse_train_rf}&#39;)
print(f&#39;随机森林回归 RMSE (测试): {rmse_test_rf}&#39;)
print(f&#39;随机森林回归 Std Dev (测试预测): {std_dev_rf}\n&#39;)

# XGBoost 回归
xgb_reg = XGBRegressor(n_estimators=100, random_state=42)
xgb_reg.fit(X_train, y_train)
y_train_pred_xgb = xgb_reg.predict(X_train)
y_test_pred_xgb = xgb_reg.predict(X_test)

# 计算 XGBoost 回归的指标
r2_train_xgb = r2_score(y_train, y_train_pred_xgb)
r2_test_xgb = r2_score(y_test, y_test_pred_xgb)
rmse_train_xgb = np.sqrt(mean_squared_error(y_train, y_train_pred_xgb))
rmse_test_xgb = np.sqrt(mean_squared_error(y_test, y_test_pred_xgb))
std_dev_xgb = np.std(y_test_pred_xgb)

print(f&#39;XGBoost 回归 R² (训练): {r2_train_xgb}&#39;)
print(f&#39;XGBoost 回归 R² (测试): {r2_test_xgb}&#39;)
print(f&#39;XGBoost 回归 RMSE (训练): {rmse_train_xgb}&#39;)
print(f&#39;XGBoost 回归 RMSE (测试): {rmse_test_xgb}&#39;)
print(f&#39;XGBoost 回归 Std Dev (测试预测): {std_dev_xgb}&#39;)

输出：
无 NAN 列
TARGET = NUM​​_OF_REPORTS

线性回归R²（训练）：0.10573816392383817
线性回归 R²（测试）：0.044441054774484345
线性回归 RMSE（训练）：2.4015104249313883
线性回归 RMSE（测试）：2.5370768911543746
线性回归标准差（测试预测）：0.8559452250173416

随机森林回归 R²（训练）：0.8228802919142462
随机森林回归 R²（测试）：0.1949840010493391
随机森林回归 RMSE（训练）： 1.0687732406167612
随机森林回归 RMSE（测试）：2.3286656888108603
随机森林回归标准差（测试预测）：1.6023216006593008

XGBoost 回归 R²（训练）：0.8755993651481643
XGBoost 回归 R²（测试）：0.0892023732129813
XGBoost 回归 RMSE（训练）：0.8957017569346305
XGBoost 回归 RMSE（测试）：2.4769419787295774
XGBoost 回归标准差（测试预测）： 1.8632863759994507
]]></description>
      <guid>https://stats.stackexchange.com/questions/652074/help-in-overfitting</guid>
      <pubDate>Wed, 31 Jul 2024 11:02:11 GMT</pubDate>
    </item>
    <item>
      <title>对于李克特量表的两个分类变量应该使用什么假设检验？</title>
      <link>https://stats.stackexchange.com/questions/652073/what-hypothesis-test-should-be-used-for-two-categorical-variables-in-likert-scal</link>
      <description><![CDATA[我来举个例子。
假设我在一家医院进行了一项健康调查。我问了两个问题。第一个问题是：“我吃药来改善睡眠”，第二个问题是：“我早上感觉不舒服”。我对这两个问题都获得了大约 100 个答复。
这两个问题的答案范围从 1 到 5：(1) 从不，(2) 很少，(3) 有时，(4) 经常，(5) 总是。（李克特量表）
也就是说，我有 100 行答案，范围从 1 到 5。一个有序分类变量。
在这种情况下，我想测试吃药来改善睡眠和早上感觉不舒服之间是否存在关系。我正在考虑使用卡方检验。
我的零假设是 H0：变量“我服药以睡好觉”和“我早上感觉不舒服”是独立的。换句话说，睡得好和感觉不舒服之间没有关联。
我的备选假设 H1：变量“我服药以睡好觉”和“我早上感觉不舒服”不是独立的。换句话说，服药和早上感觉不舒服之间存在显著关联。
如果我再进行一次关于心理健康的调查，问题 1：“我没有什么可期望的”，问题 2：“我作为一个人没有任何价值”，回答量表相同……测试结果还会一样吗？卡方检验？]]></description>
      <guid>https://stats.stackexchange.com/questions/652073/what-hypothesis-test-should-be-used-for-two-categorical-variables-in-likert-scal</guid>
      <pubDate>Wed, 31 Jul 2024 10:37:54 GMT</pubDate>
    </item>
    <item>
      <title>时间序列 AR(1) 预测与具有外生变量的 AR(1) 预测与随机森林预测，为什么性能如此不同？</title>
      <link>https://stats.stackexchange.com/questions/652072/prediction-of-a-time-series-ar1-vs-ar1-with-exogenous-variables-vs-random-fo</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652072/prediction-of-a-time-series-ar1-vs-ar1-with-exogenous-variables-vs-random-fo</guid>
      <pubDate>Wed, 31 Jul 2024 09:27:44 GMT</pubDate>
    </item>
    <item>
      <title>对测量标准误差（SEM）的困惑</title>
      <link>https://stats.stackexchange.com/questions/652069/confusion-about-standard-error-of-measurement-sem</link>
      <description><![CDATA[问题是这样的：我想要“在使用不可靠的测量方法时，估计尝试根据观察到的分数预测真实分数时产生的错误”（心理测试理论，Gulliksen，1950 年）。例如，我可能想要评估运动员的耐力，但由于生物变异性和其他因素（受试者错误、温度等），同一受试者在两次测试之间的测试结果可能会随机变化。
假设此测试的可靠性为 $R$。这可能已被评估为 ICC，如本文或其他方法中所述，这与此处无关。
从理论上讲，SEM 是对同一主题进行大量重复测量的标准差。当然，这不切实际，所以使用其他方法。
许多在线资源，包括本网站上的一些答案，都声称，当使用已知可靠性的方法来对一组受试者进行单次测试时，SEM 的计算方法如下：
$$SEM = \sigma_x*\sqrt{1 - R}$$
其中 $\sigma_x$ 是观察到的组标准差，而 $ICC$ 是测试的可靠性。这就是我感到困惑的地方，因为我不明白使用组 SD 来估计从观察到的分数预测单个人的真实分数时产生的误差的理由。例如，如果进行一个思想实验，我们知道测量误差约为 2 个测试单位，但组的标准差很大，比如 30 个单位，那么我们就无法使用组平均值对误差进行良好的估计。
我的困惑进一步加深，因为在 Gulliksen 的书中，NCME 教学模块也引用了该书，书中使用了另一个公式：
$$SE = \sigma_x \sqrt{R}\sqrt{1-R}$$
并称为估计标准误差，看似我应该用在我身上的那个。
但事情还没有结束。 其他 来源表明 SEM 也可以通过其他方式计算，例如：
$$SEM = \frac{\sigma_{diff}}{\sqrt{2}}$$
其中 $\sigma_{diff}$ 是进行重测信度研究时观察到的分数差异的标准差，这看起来是一个完全不同的量。这对我来说更直观，因为我们没有使用组方差来估计个体水平误差的问题，而是使用差异的方差。
那么我实际上想使用哪个量来实现我的目标，即在已知信度的情况下估计从观察到的分数预测真实分数时产生的误差（最终通过在个体测量值周围设置置信区间）？如果公式涉及$\sigma_x$，那么使用组级统计数据来估计个体水平误差的理由是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652069/confusion-about-standard-error-of-measurement-sem</guid>
      <pubDate>Wed, 31 Jul 2024 08:35:44 GMT</pubDate>
    </item>
    <item>
      <title>比率的平均值 - 所有可能的组合[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652066/average-of-ratios-out-of-all-possible-combinations</link>
      <description><![CDATA[我有一个非常愚蠢的问题 :)
我有两个变量，$X$ 和 $Y$，它们是独立观察的。我想知道比率的估计值，$Z=X/Y$，使用比率的平均值。
我可以计算$x_1/y_1$、$x_1/y_2$、...、$x_1/y_m$、...$x_n/y_m$的所有可能组合并取这些样本的平均值，因此$$\bar{r}=\frac{1}{n\cdot m}\sum_{i}^{n}\sum_{j}^{m}\frac{x_i}{y_j} \ ?$$在我看来，这有点像引导程序，但我无法理解这里的潜在错误。由于 $X$ 和 $Y$ 的长度不同且不太长，我希望这种方法可以给出更好的估计。]]></description>
      <guid>https://stats.stackexchange.com/questions/652066/average-of-ratios-out-of-all-possible-combinations</guid>
      <pubDate>Wed, 31 Jul 2024 08:04:02 GMT</pubDate>
    </item>
    <item>
      <title>有什么好的统计方法可以在众多选择中预测出一个选择？</title>
      <link>https://stats.stackexchange.com/questions/652065/what-is-a-good-statistical-method-to-predict-a-choice-among-a-bundle-of-choices</link>
      <description><![CDATA[我有一个数据集，其中包含大约 20000 个观测值和大约 100 个预测变量。有 4 个因变量表示 4 个可能的选择，如果选择了该选项，则变量取值为“1”，如果未选择该选项，则变量取值为“0”。所有预测变量都是备选方案。目标是开发一个模型来最好地预测一组选择中的选择。
模型的评估由 Logloss 完成，Logloss 由LogLoss 公式提供。
我知道我可以使用多项选择和可能的随机森林（如果我错了，请纠正我）。有哪些好的统计模型可以解决这个问题，我可以使用哪些方法来降低我的 Logloss 值。
任何处理此类问题的经验都会有很大帮助。谢谢！
到目前为止，我已经尝试了多项式，但我正在寻找其他可能的统计模型和方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/652065/what-is-a-good-statistical-method-to-predict-a-choice-among-a-bundle-of-choices</guid>
      <pubDate>Wed, 31 Jul 2024 07:31:19 GMT</pubDate>
    </item>
    <item>
      <title>有哪些方法可以从随机变量的复杂表达式中估计随机变量的分析 PDF？</title>
      <link>https://stats.stackexchange.com/questions/652061/what-are-some-methods-to-estimate-analytical-pdf-of-random-variable-from-an-intr</link>
      <description><![CDATA[假设我有一个服从 t 分布 ($\mu$) 的随机变量 $y$，一个服从伽马分布 ($\alpha,\beta$) 的随机变量 $x$，以及一个服从 $[-\pi,\pi]$ 上的均匀随机变量 $\theta$，$w\sim\mathcal{N}(0,\sigma^2)$ 服从高斯分布。我需要找到 $h$ 的分布，如下所示
$$h=x^2|{cos}^{-1}\theta|y+y^5{|{sin}^{-1}\theta|}^2x+\frac{x}{y}+w$$
我曾尝试使用常规随机变量变换来求解 PDF，但表达式过于复杂，无法以解析形式求解。
我不想要这个问题的确切答案，因为我更想知道当随机变量变换如此复杂时使用的方法。在数值上，可能使用核方法。但是，如果需要解析表达式，它们可能是近似的，例如 PDF 的界限或使用扰动的某些解决方案，该怎么办？是否可以应用一些通用近似来找到解析解？有相同的参考吗？
假设所有随机变量都是独立的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652061/what-are-some-methods-to-estimate-analytical-pdf-of-random-variable-from-an-intr</guid>
      <pubDate>Wed, 31 Jul 2024 06:44:02 GMT</pubDate>
    </item>
    <item>
      <title>隔离森林是否需要规范化实时数据？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652034/normalizing-live-data-necessary-for-isolation-forests</link>
      <description><![CDATA[我正在研究一个使用孤立森林检测实时数据异常的模型。我不确定是否需要对数据进行归一化，或者如何实时进行归一化。目标是识别特定的异常，特别是当值明显高于平均值并长期超过管道直径时。数据表示管道中的水深，每个管道的直径从 10 以下到 110 以上不等。在过去的例子中，700 多根管道中几乎没有异常，主要发生在直径较小的管道中，峰值在 113 左右。我担心的是，如果不进行归一化，这些峰值可能会被视为直径为 114 的管道的正常值，或者在这些情况下正常值将被视为异常值。我不确定是否需要归一化，或者孤立森林是否可以自动调整这些变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/652034/normalizing-live-data-necessary-for-isolation-forests</guid>
      <pubDate>Tue, 30 Jul 2024 21:41:53 GMT</pubDate>
    </item>
    <item>
      <title>混合模型的经验法则</title>
      <link>https://stats.stackexchange.com/questions/652027/rule-of-thumb-for-mixed-model</link>
      <description><![CDATA[假设我们有 $n$ 个 $(X,Y)$ 对的观测值，其中 $X$ 是实数（可能是向量），而 $Y$ 是实数。我们想要一个线性模型。一个经验法则是，除截距外，可学习参数的数量不应超过 $\frac{n}{10}$。并不是说如果每个可学习参数只有 $9$ 个观测值，我们就不会这样做，但这是一种防止过度拟合的方法。
混合模型是否有类似的经验法则？举一个简单的例子，假设 $X \in \mathbb{R}^n$ 和 $Y \in \mathbb{R}^n$ 是数据，我们得到一个名为 patient 的类，它是一个 factor，级别为 $k$。我们希望进行随机截距：
lmer(Y ~ X + (1 |patient))

是否有类似的经验法则可以防止关于可学习参数数量、$n$、$k$ 和每个患者的观察次数的过度拟合？]]></description>
      <guid>https://stats.stackexchange.com/questions/652027/rule-of-thumb-for-mixed-model</guid>
      <pubDate>Tue, 30 Jul 2024 18:51:22 GMT</pubDate>
    </item>
    </channel>
</rss>