<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 04 Jun 2024 09:17:07 GMT</lastBuildDate>
    <item>
      <title>从独立负二项式构造狄利克雷多项式</title>
      <link>https://stats.stackexchange.com/questions/648595/construction-of-dirichlet-multinomial-from-independent-negative-binomials</link>
      <description><![CDATA[我有一个数据集，其中包含 ISO3 国家代码、年份（从 2010 年到 2019 年）、死亡原因类别（共 24 个类别）和死亡人数。各种原因的死亡人数总数是固定的。我的目标是预测 2020-2023 年期间每个国家/原因组合的预期死亡人数。
我的想法是使用 R 中的 gam 函数运行独立的负二项回归模型，因为我的数据明显过度分散：
for (i in unique(df$iso3)) {

for (j in unique(df$cause)) {

whichs &lt;- which(df$iso3 == i &amp; df$cause == j)

temp &lt;- df[whichs, ]

model &lt;- gam(deaths ~ s(year), data = temp, family = nb(theta = NULL, link = &quot;log&quot;))

pred &lt;- predict(model, se.fit = TRUE, type = &quot;response&quot;, newdata = data.frame(year = c(2020,2021,2022,2023)))

}

}


为了确保各种原因的死亡人数总和等于已知且固定的总数，我似乎需要从这些独立的负二项式中构建一个狄利克雷多项式。请参阅此参考资料：https://arxiv.org/pdf/2001.04343 &quot;狄利克雷多项分布相当于一组独立的负二项分布，具有相同的尺度参数，以它们的总和为条件&quot;。这是正确的做法吗？
如果是这样，我不确定我需要在 R 中做什么来应用它。我尝试了以下代码中的不同 theta 值，但各种原因的死亡人数总和并未达到固定总数 + 设置定义的 theta 值会影响模型拟合。
model &lt;- gam(deaths ~ s(year), data = temp, family = nb(theta = **NULL**, link = &quot;log&quot;))

我该怎么办？一种简单的方法是重新调整预期的死亡人数（按原因计算），使其与固定总数相匹配，但我希望正确地做事。]]></description>
      <guid>https://stats.stackexchange.com/questions/648595/construction-of-dirichlet-multinomial-from-independent-negative-binomials</guid>
      <pubDate>Tue, 04 Jun 2024 08:47:19 GMT</pubDate>
    </item>
    <item>
      <title>双变量 von Mises 分布的 CF（特征函数）有封闭形式吗？</title>
      <link>https://stats.stackexchange.com/questions/648592/is-there-a-closed-form-of-the-cf-characteristic-function-of-a-bivariate-von-mi</link>
      <description><![CDATA[双变量冯·米塞斯分布的 CF（特征函数）是否有封闭形式？
如果我有两个参数遵循冯·米塞斯分布，但我的两个参数会混合在一起，那么我应该转到双变量冯·米塞斯分布，还是可以只使用冯·米塞斯分布进行计算？
附言：如果不清楚，请见谅，这是我第一次使用它！]]></description>
      <guid>https://stats.stackexchange.com/questions/648592/is-there-a-closed-form-of-the-cf-characteristic-function-of-a-bivariate-von-mi</guid>
      <pubDate>Tue, 04 Jun 2024 08:14:32 GMT</pubDate>
    </item>
    <item>
      <title>纵向和事件发生时间数据的联合模型与具有时间依赖性协变量的生存分析</title>
      <link>https://stats.stackexchange.com/questions/648590/joint-models-for-longitudinal-and-time-to-event-data-vs-survival-analysis-with-a</link>
      <description><![CDATA[我需要一些帮助来理解具有时间依赖性协变量的生存分析（cox 回归）与纵向和事件发生时间数据联合模型（R 中的 JM 包）之间的区别。您能否通过一个实际示例解释这两种方法之间的区别。]]></description>
      <guid>https://stats.stackexchange.com/questions/648590/joint-models-for-longitudinal-and-time-to-event-data-vs-survival-analysis-with-a</guid>
      <pubDate>Tue, 04 Jun 2024 06:41:09 GMT</pubDate>
    </item>
    <item>
      <title>如何根据一组百分位数重建正态分布？</title>
      <link>https://stats.stackexchange.com/questions/648589/how-can-i-reconstruct-a-normal-distribution-from-a-set-of-percentiles</link>
      <description><![CDATA[我有一个正态分布变量的第 3、10、50、90 和 97 个百分位数值，我希望生成一个数据集，使我能够查询其他百分位数值（例如，第 67 个百分位数值）。
我（天真地，我敢肯定）尝试了以下操作，但失败了：
underlying_data = np.random.normal(loc=0.0, scale=1.0, size=[1000])

percentiles = np.percentile(underlying_data, [3, 10, 50, 90, 97])

#

generated_data = []

for i in range(3):
generated_data.append(underlying_data[0])

for i in range(7):
generated_data.append(underlying_data[1])

for i in range(80):
generated_data.append(underlying_data[2])

for i in range(7):
generated_data.append(underlying_data[3])

for i in range(3):
generated_data.append(underlying_data[4])

print(&quot;from underground distribution: &quot;, np.percentile(np.array(underlying_data), [67]))
print(&quot;from generated distribution: &quot;, np.percentile(np.array(generated_data), [67]))

输出：
from underground distribution: [0.44470627]
from generated distribution: [-0.73888881]
]]></description>
      <guid>https://stats.stackexchange.com/questions/648589/how-can-i-reconstruct-a-normal-distribution-from-a-set-of-percentiles</guid>
      <pubDate>Tue, 04 Jun 2024 06:25:11 GMT</pubDate>
    </item>
    <item>
      <title>具有时间依赖性协变量的前瞻性纵向研究</title>
      <link>https://stats.stackexchange.com/questions/648588/a-prospective-longitudinal-study-with-time-depenent-covariate</link>
      <description><![CDATA[我的问题类似于
用于治疗比较的多变量 Cox 回归的样本量计算。
我有一个为期三年的前瞻性纵向研究。该研究的目的是看看事件变量是否可以通过时间依赖性协变量来预测（我们有可能在模型中还包括第二个时间依赖性协变量）。我们已经辨别出时间生存率，因为患者每四个月来诊所做一次测试，所以时间点数量有限。我们将有审查数据。（这项研究没有试点数据）。
这项研究可以采用什么样的设计，如何计算样本量？]]></description>
      <guid>https://stats.stackexchange.com/questions/648588/a-prospective-longitudinal-study-with-time-depenent-covariate</guid>
      <pubDate>Tue, 04 Jun 2024 05:33:46 GMT</pubDate>
    </item>
    <item>
      <title>使用多项式判别法确定 Rademacher 复杂度的界限</title>
      <link>https://stats.stackexchange.com/questions/648587/bound-on-rademacher-complexity-using-polynomial-discrimination</link>
      <description><![CDATA[这是 Wainwright 的高维统计教科书中的引理 4.14，它指出给定一类函数$\mathcal{F}$具有$v$阶多项式判别性，则对于所有整数$n$和$x_1^n = (x_1, \dots, x_n)$，我们有界限
$$
E_{\epsilon} \left[ \sup_{f \in \mathcal{F}} \left| \frac{1}{n} \sum_{i=1}^n \epsilon_i f(x_i) \right| \right] \leq 4D(x_1^n) \sqrt{\frac{v \log (n + 1)}{n}},
$$
其中 $D(x_1^n)$ 是集合 $\mathcal{F}(x_1^n)/n$ 的 $l_2$-半径。
证明留作练习，但对于我来说，如何解决这个问题并不是那么明显。我非常感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/648587/bound-on-rademacher-complexity-using-polynomial-discrimination</guid>
      <pubDate>Tue, 04 Jun 2024 04:07:34 GMT</pubDate>
    </item>
    <item>
      <title>R(k+1，n+1)<R(k，n)？</title>
      <link>https://stats.stackexchange.com/questions/648586/rk1-n1-rk-n</link>
      <description><![CDATA[“在 n+1 次试验中至少有 k+1 次成功的概率小于在 n 次试验中至少有 k 次成功的概率”是否正确？不正确？无法评估？
https://i.sstatic.net/xVrrLbJi.png]]></description>
      <guid>https://stats.stackexchange.com/questions/648586/rk1-n1-rk-n</guid>
      <pubDate>Tue, 04 Jun 2024 03:35:46 GMT</pubDate>
    </item>
    <item>
      <title>在绘制平滑缩放的 Schoenfeld 残差图时，哪些情况下应该转换时间？</title>
      <link>https://stats.stackexchange.com/questions/648579/in-which-cases-should-the-time-be-transformed-when-plotting-the-smoothed-scaled</link>
      <description><![CDATA[我之前问过这个问题，但没有得到任何答案，所以我现在重新发布它。
我旨在解决 R 中的参数 transform = &#39;&#39;，特别是关于用于评估比例风险 (PH) 假设的平滑缩放 Schoenfeld 残差检验/图。我想从统计上了解每个转换的作用，以及在哪些情况下应该转换时间以可视化残差图。
我知道默认值是 transform = &#39;km&#39;，但也有其他可用选项：
transform=&#39;log&#39;
transform=&#39;rank&#39;
transform=&#39;identity&#39;

我相信我已经掌握了每个选项的含义。如果我的理解不正确，请纠正我：
log 用于强调早期事件，因为它为它们分配了更大的权重。
rank 用于突出显示晚期事件，因为它为它们分配了更大的权重。
identity 表示未经任何修改的原始时间数据。
但是，我不确定 km 到底做了什么。虽然它似乎可以平滑时间，但我不确定它的含义。
我的具体问题：

从统计的角度来看，有人可以用简单的英语详细说明每个转换背后的细节吗？
在哪种情况下我应该使用每个转换来评估 R 中的 cox.zph() 测试/绘图？
每个转换都会为 PH 假设产生不同的 p 值。我应该“信任”哪个 p 值根据所选的转换？

提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648579/in-which-cases-should-the-time-be-transformed-when-plotting-the-smoothed-scaled</guid>
      <pubDate>Mon, 03 Jun 2024 22:27:43 GMT</pubDate>
    </item>
    <item>
      <title>不带前瞻偏差的 Seasonal_decompose</title>
      <link>https://stats.stackexchange.com/questions/648568/seasonal-decomposition-with-no-look-ahead-bias</link>
      <description><![CDATA[我正在预测某种产品的需求。需求数据框包含高趋势成分和一些季节性，为此我不会太复杂，而是使用 方法 seasonal_decompose(demand_df, model = “additive”, two_sided = False)，来自 statsmodels。我希望通过此方法获得的成分不具有任何类型的前瞻偏差，但我认为设置 two_sided = False 是不够的，因为每个月的季节性成分是恒定的，这对于数据的时间演变没有意义。有人对如何尽可能真实地分解时间序列有什么建议吗（即给定日期的序列的每个成分仅使用截至该日期的数据）。如果设置 two_sided = False 就足够了，请让我知道某种数学解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/648568/seasonal-decomposition-with-no-look-ahead-bias</guid>
      <pubDate>Mon, 03 Jun 2024 19:12:06 GMT</pubDate>
    </item>
    <item>
      <title>混合模态 MANOVA 还是其他？</title>
      <link>https://stats.stackexchange.com/questions/648565/mixed-modal-manova-or-something-else</link>
      <description><![CDATA[我再次请求您的帮助。我正在制定研究计划，但有点困惑。我有一个随机对照试验 (RCT)，用于测试治疗干预的有效性，具体设置如下：

干预是二元的（安慰剂和实验）。
我还可以访问二元变量血清状态（血清阳性和血清阴性）。
还有两个因变量（夫妻满意度和治疗依从性）。
我还将在 3 个时间点（基线、后测和 6 个月）进行测量。

我的想法是
三个独立变量（干预组、血清状态和时间）和两个因变量（每个伴侣的满意度得分和仅一个伴侣的自我报告治疗依从性）。
我的问题是，使用混合模型 MANOVA 是否合适？我该如何在网上搜索它，以便获得一些资源，告诉我应该如何在论文中写它（我找到了几个名字，但我不确定我是否走在正确的轨道上）？谢谢，我希望这是有意义的。]]></description>
      <guid>https://stats.stackexchange.com/questions/648565/mixed-modal-manova-or-something-else</guid>
      <pubDate>Mon, 03 Jun 2024 18:59:00 GMT</pubDate>
    </item>
    <item>
      <title>如何为每个进入自适应临床试验的新患者更新随机化概率？</title>
      <link>https://stats.stackexchange.com/questions/648562/how-the-randomisation-probability-is-updated-for-each-new-patient-entering-adapt</link>
      <description><![CDATA[免责声明：您可能需要阅读整篇论文才能回答这个问题：)
我正在阅读这篇论文，以了解自适应临床试验。在“统计方法”部分的第 1723 页中，我们可以看到

当
每个新患者进入试验时，都会计算 qk ，定义为 Pr(mk &lt; m0
data)，其中 k = 1, 2；和 r ，定义为 Pr(m1 &lt; m2 data)，以评估停止规则并调整随机化概率。

我对计算 Pr(mk &lt; m0 ; data) 特别感兴趣。有人知道它是如何计算的吗？举个简单的例子。
让我困惑的是：患者 1 于 2001 年 4 月 3 日入组，患者 2 于 2001 年 4 月 11 日入组。现在，即使我们不知道患者 1 是否成功（根据为患者成功而设定的试验规则，我们只能在 50 天后才知道），但 arm1 和 arm2 的概率会更新。]]></description>
      <guid>https://stats.stackexchange.com/questions/648562/how-the-randomisation-probability-is-updated-for-each-new-patient-entering-adapt</guid>
      <pubDate>Mon, 03 Jun 2024 18:21:02 GMT</pubDate>
    </item>
    <item>
      <title>重复测量方差分析问题</title>
      <link>https://stats.stackexchange.com/questions/648560/repeated-measures-analysis-of-variance-question</link>
      <description><![CDATA[我有以下数据集。
My_Data &lt;- data.frame(Sampling_Date = rep(1:4, each = 12), Block = rep(1:3, length.out = 48), Treatment = rep(LETTERS[1:4], each = 3, length.out = 48), Response = abs(rnorm(48, 10, 1)))

我正在做重复测量方差分析。每个区块包含四个图，其中区块中的每个图都接受不同的处理。这些图在一年内被重复采样。我想知道在 R 中对这些数据进行建模的最合适方法是什么。这是我根据所读内容得出的结论。
Model &lt;- aov(Response ~ (Treatment * as.factor(Sampling_Date)) + Error(as.factor(Block) / (Treatment * as.factor(Sampling_Date))), data = My_Data)
summary(Model)

在此模型输出中，每个主效应和交互项都有自己的误差项，这本质上是主效应或感兴趣的交互与阻塞（复制）变量的相互作用。
我有几个问题。
首先，此模型的工作方式是否合适？换句话说，这些误差项是否适用于每个不同的主效应和交互？如果是，那么为什么？
其次，我是否需要考虑混合效应模型，以便可以将块视为随机变量？由于区块本质上只是我们的复制变量，我认为它不应该包含在模型中。
第三，何时以及为什么要考虑球形度？这取决于我们将采样日期视为数字变量还是分类变量吗？
第四，如果我将采样日期视为数字变量，模型将如何变化？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648560/repeated-measures-analysis-of-variance-question</guid>
      <pubDate>Mon, 03 Jun 2024 17:20:53 GMT</pubDate>
    </item>
    <item>
      <title>负二项模型中的有偏 MLE</title>
      <link>https://stats.stackexchange.com/questions/648514/biased-mles-in-negative-binomial-models</link>
      <description><![CDATA[我发现负二项模型的最大似然参数是有偏的。下面提供了一个示例代码。这正常吗？有没有办法获得无偏估计？
&gt; set.seed(3)
&gt; z &lt;- 2
&gt; a &lt;- 100
&gt; b &lt;- 100
&gt; theta &lt;- 15
&gt; 
&gt; negloglik &lt;- function(p,x,y){
+ if(any(p&lt;=0)) return(NA)
+ a &lt;- p[1]
+ b &lt;- p[2]
+ z &lt;- p[3]
+ theta &lt;- p[4]
+ -sum(dnbinom(y, mu=(a*x^z)/(b+x^z), size=theta, log=TRUE))
+ }
&gt; 
&gt; nsim &lt;- 1000
&gt; ppp &lt;- matrix(NA,nsim,4)
&gt; for(i in 1:nsim){
+ x &lt;- round(rep(seq(3,30,by=5),each=5))
+ y &lt;- rnbinom(length(x), mu=((a*x^z)/(b+x^z)), size=theta)
+ ppp[i,] &lt;- optim(c(a,b,z,theta),negloglik,x=x,y=y)$par
+ }
&gt; 
&gt; # MLE（预期）
&gt; apply(ppp,2,mean)
[1] 105.135854 123.325672 2.054681 19.150245
&gt; 
&gt; # 偏差
&gt;应用（ppp，2，平均值）-c（a，b，z，theta）
[1] 5.13585361 23.32567187 0.05468069 4.15024470
]]></description>
      <guid>https://stats.stackexchange.com/questions/648514/biased-mles-in-negative-binomial-models</guid>
      <pubDate>Mon, 03 Jun 2024 04:32:10 GMT</pubDate>
    </item>
    <item>
      <title>根据胜率和游戏数量计算启发式</title>
      <link>https://stats.stackexchange.com/questions/648496/computing-heuristic-from-winrate-and-number-of-games</link>
      <description><![CDATA[我需要根据玩家的表现（以游戏数量和这些游戏的胜率表示）对大量玩家（MOBA 游戏）进行排序。
我使用简单的阈值根据胜率减少了初始玩家集，但玩家仍然太多，所以我需要通过消除“幸运”玩家来找到精英中的精英。玩家（那些胜率高但比赛场次不足以证明他们是促成胜利的主要因素的玩家）。
在这个阶段我不想再使用阈值了，因为我觉得既然我的列表中的玩家现在变少了，他们的排序现在应该是相关的，以便找到精英中的精英。
这是一个真实的样本，用来说明我正在处理的数据类型：

我试过$winrate\times \text{log}(games)$，但即使它对极端值有效（成功将（38, 92）放在顶部，但放置得太多了较低（50, 83）。
直观地说，我会说我正在寻找的启发式方法表明，上一个例子中的最佳球员是（38, 92），（50, 83），（18, 95）......我想你看到了模式。
说到模式，我也试图自己对它们进行排名，以便能够为每个“级别”的表现绘制“回归”线，但最终我变得更加困惑，因为我最终得到了一个非常针对问题的解决方案，因为它适合这组特定的数据点，而我不知道如何概括它。
我不是在这个领域工作，所以我不习惯那种东西，因此自己找不到解决方案，但我想我至少可以理解它，所以如果你有任何关于此类场景的已知技术的参考，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/648496/computing-heuristic-from-winrate-and-number-of-games</guid>
      <pubDate>Sun, 02 Jun 2024 19:05:28 GMT</pubDate>
    </item>
    <item>
      <title>基因变异的事件时间分析：是否要根据年龄进行调整？</title>
      <link>https://stats.stackexchange.com/questions/648473/time-to-event-analysis-for-genetic-variants-whether-or-not-to-adjust-for-age</link>
      <description><![CDATA[据我了解，当人们有兴趣研究暴露与事件发生时间结果之间的关联（在 Cox PH 回归的背景下）时，暴露的性质决定了如何制定结果。例如，假设我有一群来自普通人群的个体，他们在某个时间跨度（这里指 2000 年至 2004 年之间）参加了一项研究，并一直被跟踪到 2020 年。此数据集被左截断。例如，受试者 5 在入组前就已确诊。针对 5 名假设参与者的整体研究如下所示：

我有两个问题，如果有人能纠正我，我将不胜感激：

如果我有兴趣研究遗传变异与特定结果的事件发生时间之间的关联，我会在我的模型中考虑发病年龄和出生日期之间的差异，因为在这种情况下感兴趣的暴露（遗传变异）在出生时就存在，并且不会随时间而变化。但是，如果感兴趣的暴露是生物标志物（例如 ALT 水平），那么事件发生时间将是发病年龄和入组日期之间的差异，因为每个受试者的暴露都是在他们参加研究时测量的。我的理解正确吗？

在上述两种情况下，如何将年龄视为协变量？例如，在暴露是遗传变异的情况下，最近的可扩展方法（例如此处）未根据年龄进行调整：



对于所有疾病，我们使用前四个主成分 (PC) 和性别作为协变量。

或者来自本文：

我们没有包括任何年龄或出生年份的协变量，因为这些与我们的表型直接相关。

但是关于感兴趣的暴露何时与时间相关（例如 ALT）。此外，如果人们有兴趣解释其他时间依赖性协变量（例如仅在入组时基线测量的 BMI）的影响，而感兴趣的暴露是遗传变异，那么最合适的方法是什么？
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/648473/time-to-event-analysis-for-genetic-variants-whether-or-not-to-adjust-for-age</guid>
      <pubDate>Sun, 02 Jun 2024 12:36:11 GMT</pubDate>
    </item>
    </channel>
</rss>