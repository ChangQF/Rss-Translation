<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 29 Jul 2024 21:16:43 GMT</lastBuildDate>
    <item>
      <title>何时遗漏变量偏差不为零？</title>
      <link>https://stats.stackexchange.com/questions/651968/when-is-ommitted-variable-bias-non-zero</link>
      <description><![CDATA[我刚刚阅读了关于遗漏变量偏差的维基百科页面：[wiki for OVB][1]，我对该页面的主要声明之一感到困惑，即预期遗漏变量偏差只有当遗漏变量与任何回归变量的相关性为零时才为 0。
但是，他们给出的遗漏变量偏差方程是：
$$\widehat{\beta}= \beta +(X&#39;X)^{-1}X&#39;z\gamma + (X&#39;X)^{-1}X&#39;\epsilon, $$
其中 $X$ 是我们的 $N \times p$ p 回归变量矩阵，$z$ 是我们的 $N \times 1$ 省略的变量，$\widehat{\beta}$ 是省略 $z$ 的系数估计，$\beta$ 是包括 $z$ 的估计，$\gamma$ 是完全回归中 $z$ 的回归系数，$\epsilon$ 是残差。
与文章所说的相反，这个等式似乎表明，只要 内积 $X&#39;z$ 为非零，当它们不相关时则为非零。这非常不同，因为回归量和省略变量 $z$ 均不被认为是中心化/零均值的。
例如，假设回归量 $X$ 和省略变量 $z$ 是伯努利 R.V.，其中 $p=.5$。那么项 $(X&#39;X)^{-1}$ 是一个矩阵，其期望在对角线上为 $N$，在其他地方为 $\frac{1}{4}N$，而项 $X&#39;z$ 的期望为 $[\frac{1}{4}N,...,\frac{1}{4}N]^T$。显然，尽管这些变量都不相关，但它们乘积的期望不为 0。
那么，维基百科文章该部分的整体观点是否错误？在一般情况下，我们的回归量不是中心化的，均值为 0 的变量，即使回归量都是不相关的，我们也不能忽略变量偏差吗？
任何有助于理解这种明显不一致的帮助都将不胜感激。
-Paul
[1]: https://en.wikipedia.org/wiki/Omitted-variable_bias]]></description>
      <guid>https://stats.stackexchange.com/questions/651968/when-is-ommitted-variable-bias-non-zero</guid>
      <pubDate>Mon, 29 Jul 2024 20:55:16 GMT</pubDate>
    </item>
    <item>
      <title>MPGVAE 如何计算其重建损失？</title>
      <link>https://stats.stackexchange.com/questions/651966/how-does-mpgvae-calculate-its-reconstruction-loss</link>
      <description><![CDATA[我最近偶然看到了图形反卷积生成论文，其中作者提出 MPGVAE 作为图形的生成模型。他们将其作为 GraphVAE 的一种改进，其主要优点之一是它们不需要在训练期间进行昂贵的（近似）图形匹配来匹配输出和输入图形以计算重建损失。
不过，我想知道他们确定损失的替代方法是什么。如果我理解正确的话，它们将输入图编码为单个图级潜在表示，然后从那里再次解码为单独的节点和边缘特征向量。但是，如何确保输出节点的顺序与输入相匹配，以便可以正确比较图 $G$ 和 $\tilde{G}$？]]></description>
      <guid>https://stats.stackexchange.com/questions/651966/how-does-mpgvae-calculate-its-reconstruction-loss</guid>
      <pubDate>Mon, 29 Jul 2024 20:43:26 GMT</pubDate>
    </item>
    <item>
      <title>从未归一化的伽马共轭先验生成样本</title>
      <link>https://stats.stackexchange.com/questions/651965/generating-samples-from-the-unnormalized-gamma-conjugate-prior</link>
      <description><![CDATA[维基百科将以下内容列为伽马分布的非正则化共轭先验，其中两个参数$\alpha,\beta$都未知：
$$
\frac{p^{\alpha-1} e^{-\beta q}}{\Gamma(\alpha)^r \beta^{-\alpha s}}
$$
查看Miller 的论文，似乎我甚至可以采用$s=r=n$，尽管这对我其余的问题并不重要。
给定有效的超参数$p&gt;0,r=s&gt;0,q&gt;0$（例如$p^{1/r} &lt;q/r$，如论文所述），我想生成许多（比如一百万）随机样本$(\alpha_i,\beta_i)_{i=1}^N$ 来自此分布。理想情况下，我希望样本准确且独立，但我无法使用 维基百科上列出的任何方法。
我相信我确实设法为下面的问题编写了 Metropolis-Hastings 的正确实现，但这存在样本相关的问题。
我非常感谢帮助编写一个精确且有效的独立样本采样算法。例如，在拒绝采样中，这应该涉及非规范化 PDF 上的一些智能界限。任何这样的方法都可以。谢谢。
import numpy as np
import scipy.special as sp
import matplotlib.pyplot as plt

# 定义未规范化的 PDF
def unnormalized_pdf(alpha, beta, n, p, s):
return (beta**(alpha*n)) * (p**(alpha-1)) * np.exp(-s*beta) / (sp.gamma(alpha)**n)

# Metropolis-Hastings 算法
def metropolis_hastings(n_samples, n, p, s, alpha_init=1.0, beta_init=10.0, suggestions_std=0.5):
samples = np.zeros((n_samples, 2))
alpha_current = alpha_init
beta_current = beta_init

for i in range(n_samples):
alpha_proposal = np.abs(np.random.normal(alpha_current,proposal_std))
beta_proposal = np.abs(np.random.normal(beta_current,proposal_std))

acceptance_ratio = (unnormalized_pdf(alpha_proposal,beta_proposal,n,p,s)/
unnormalized_pdf(alpha_current,beta_current,n,p,s))

如果 np.random.rand() &lt;接受率：
alpha_current = alpha_proposal
beta_current = beta_proposal

samples[i, :] = [alpha_current, beta_current]

返回样本

# 初始化参数
alpha = 1.0
beta = 10.0
n = 10

# 从伽马分布中抽取样本
gamma_samples = np.random.gamma(alpha, 1.0/beta, n)

# 设置 s 和 p
s = np.sum(gamma_samples)
p = np.prod(gamma_samples)

# MCMC 的样本数量
n_samples = 1000000

# 运行 Metropolis-Hastings 算法
samples = metropolis_hastings(n_samples, n, p, s)

# 绘制样本
plt.figure(figsize=(10, 6))
plt.scatter(samples[:, 0], samples[:, 1], s=0.1, alpha=0.5)
plt.xlabel(&#39;Alpha&#39;)
plt.ylabel(&#39;Beta&#39;)
plt.title(&#39;(Alpha, Beta) 对的样本&#39;)
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/651965/generating-samples-from-the-unnormalized-gamma-conjugate-prior</guid>
      <pubDate>Mon, 29 Jul 2024 20:19:43 GMT</pubDate>
    </item>
    <item>
      <title>对于非常倾斜的二元独立变量，哪种分析最好？</title>
      <link>https://stats.stackexchange.com/questions/651963/what-analysis-is-best-with-a-binary-independent-variable-that-is-very-skewed</link>
      <description><![CDATA[我有一个二元独立变量（1 = 事件发生，0 = 事件未发生）和一个连续调节变量。我的因变量是连续的。我想测试参与特定事件是否会比不参与特定事件时预测更高的心理结果分数，我也想测试调节效应。我的样本量在 350-450 个观察值之间（出于匿名目的，细节保持模糊）。
我的独立变量中的 1 的数量非常少（7% 的观察值 = 1，93% = 0）。我读到独立变量的偏斜不是一个大问题，但这似乎是一个相当大的问题——是吗？我可以不管这个偏斜如何都运行线性回归分析吗，或者在这种情况下另一种测试更合适？我想到了一个 MANOVA，但我不确定在这种情况下它和回归之间的优缺点，或者我是否必须将我的连续调节器转换为 MANOVA 的二进制（高/低）变量。TIA！]]></description>
      <guid>https://stats.stackexchange.com/questions/651963/what-analysis-is-best-with-a-binary-independent-variable-that-is-very-skewed</guid>
      <pubDate>Mon, 29 Jul 2024 19:42:32 GMT</pubDate>
    </item>
    <item>
      <title>简单随机抽样是对抽象概率测度空间中的概率测度的假设吗？</title>
      <link>https://stats.stackexchange.com/questions/651959/is-simple-random-sampling-an-assumption-on-the-probability-measure-in-the-abstra</link>
      <description><![CDATA[我想知道我对简单随机抽样含义的直觉是否正确。
假设我们有一个抽象概率测度空间$(\Omega, \mathcal{A}, \mathbb{P})$，
某个可测空间$(\mathbb{R}, \mathcal{B}(\mathbb{R}))$，以及一个映射$X$，它是一个有效的随机变量，写为$X : \Omega \rightarrow \mathcal{B}(\mathbb{R})$。然后，$\mathbb{P}_{X}$ 是由 $X$ 引起的 $\mathbb{P}$ 的 前推测度，它是概率测度 $\mathbb{P}_{X} : \mathcal{B}(\mathbb{R}) \rightarrow [0, 1]$。因此，$\mathbb{P}_{X}$ 是 $X$ 的 概率分布测度，而
$(\mathbb{R}, \mathcal{B}(\mathbb{R}), \mathbb{P}_{X})$ 是 具体 的概率测度空间（即，如下所示）。

这样说对吗即：

我们为 $\mathbb{P}_{X}$ 选择的函数形式是我们对总体（即样本空间 $\Omega$）中测量值 $X$ 分布的假设？

简单随机抽样机制（即均匀分布）是我们对 $\{\omega\}$ 元素（例如，人）在 $\Omega$ 中的概率的假设？换句话说，我们是否假设$\mathbb{P}$是有限总体的均匀分布，即$\mathbb{P}(\{\omega\}) = \frac{1}{|\Omega|}$？


我的背景是心理学，在我的阅读中，我没有遇到任何作者描述与我上面的第二个问题一致的简单随机抽样——重点似乎在$\mathbb{P}_{X}$上。假设上面的第二个问题是正确的，这不就等于说

事件$\{\omega\} \in \mathcal{A}$的发生（即，无论它对一个人意味着什么...）与其被选为样本$\{\omega_{1}, \omega_{2}, \omega_{3}, ...\} \subseteq \Omega$的一部分的概率相同吗？

我希望这是有道理的，我将不胜感激任何意见和直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/651959/is-simple-random-sampling-an-assumption-on-the-probability-measure-in-the-abstra</guid>
      <pubDate>Mon, 29 Jul 2024 17:45:24 GMT</pubDate>
    </item>
    <item>
      <title>测量逻辑核函数变换后的准确率</title>
      <link>https://stats.stackexchange.com/questions/651958/measuring-the-accuracy-after-transforming-function-in-logistic-kernel</link>
      <description><![CDATA[我有一个使用高斯核和逻辑核的非参数估计器。假设使用高斯核的估计定义为 $E_G$，逻辑核定义为 $R_L$。随着样本量的增加，我发现 $E_G$ 的 MSE（均方误差）正在减小。当谈到 $E_G$ 时，我收到的输出为
&quot;**标量幂中遇到溢出
return np.exp(-z)/(1+np.exp(-z)**2)**2,RuntimeWarning: 标量除法中遇到无效值
return np.exp(-z)/(1+np.exp(-z)**2)**2,IntegrationWarning: 检测到舍入误差的发生，这会阻止
实现所请求的容差。错误可能被低估了。&quot;。
如果我们使用 sigmoid 函数，那么可以控制溢出，但它也包含错误，在这种情况下，比较 $E_G$ 和 $E_L$ 是否公平。]]></description>
      <guid>https://stats.stackexchange.com/questions/651958/measuring-the-accuracy-after-transforming-function-in-logistic-kernel</guid>
      <pubDate>Mon, 29 Jul 2024 17:38:36 GMT</pubDate>
    </item>
    <item>
      <title>中期分析如何改变非劣效性分析所需的样本量？</title>
      <link>https://stats.stackexchange.com/questions/651957/how-does-interim-analysis-change-sample-size-needed-for-non-inferiority-analyses</link>
      <description><![CDATA[我正在测量试验 1 与试验 2，并进行非劣效性分析以确保试验 1 不会明显差于试验 2。这涉及测试 4 个假设（即，4 个测量中性能差异的 95% 置信区间的上限必须小于 15%）。
团队希望进行中期分析。我建议不要这样做，因为除非我们很幸运并且具有完美的一致性，否则我们肯定无法拒绝这 4 个假设，因为否则置信区间将太宽而无法拒绝 &gt;15% 的增量。
此外，如果我们进行中期分析，我们可能会被要求增加样本量。但在这种情况下，样本量调整究竟如何计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/651957/how-does-interim-analysis-change-sample-size-needed-for-non-inferiority-analyses</guid>
      <pubDate>Mon, 29 Jul 2024 17:28:50 GMT</pubDate>
    </item>
    <item>
      <title>既然我们现在拥有无限的计算能力（相对于历史规范），我们是否需要使用统计方法而不是模拟？</title>
      <link>https://stats.stackexchange.com/questions/651956/since-we-now-have-unlimited-computation-power-relative-to-historical-norms-do</link>
      <description><![CDATA[Allen Downey 于 2016 年撰写了一篇博客文章，标题为“仍然只有一个测试”，其中讨论了运行模拟相对于传统统计测试的优势。它认为，由于计算速度现在比历史标准快了数万倍，因此统计中的传统分析方法不再有意义。例如，当 t 检验于 1908 年被发现时，它非常有用，因为所有计算都是手工完成的。但如今，iPhone 运行统计计算的速度比 1908 年人类手工计算的速度快约 10 万倍。
引用 Downey 的话：

当计算速度慢且成本高时，这些分析方法是必要的，但随着计算变得更便宜、更快，它们的吸引力就降低了，因为：

它们不灵活：如果您使用标准测试，则必须使用特定的测试统计量和零假设的特定模型。您可能不得不使用不适合您问题领域的测试统计量，只是因为它适合分析。如果您试图解决的问题不适合现成的模型，那么您就倒霉了。

它们不透明：零假设是一个模型，这意味着它是对世界的简化。对于任何现实世界场景，都存在许多基于不同假设的可能模型。在大多数标准测试中，这些假设都是隐含的，很难知道某个模型是否适合特定场景。


模拟方法最重要的优势之一是它们使模型明确化。当您创建模拟时，您不得不考虑您的建模决策，而模拟本身会记录这些决策。

他还在这篇博文中提供了此类模拟的实际示例。这让我感到疑惑：

在当今的计算能力如此强大的情况下，为什么我们仍然要运行传统的统计测试，而不是创建明确的模型并运行数百万次模拟来找出观察结果的真实 p 值？
是否还存在传统统计方法优于模拟的情况？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651956/since-we-now-have-unlimited-computation-power-relative-to-historical-norms-do</guid>
      <pubDate>Mon, 29 Jul 2024 16:59:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 eventdd 进行事件研究 - 解释</title>
      <link>https://stats.stackexchange.com/questions/651955/event-study-with-eventdd-interpretation</link>
      <description><![CDATA[我对实现这类模型还很陌生，所以这可能是一个基本问题，但我希望你能帮助我。
我试图了解复制对论文引用计数的影响。为此，我的论文导师建议我绘制一个事件研究。
我的数据是一个看起来像这样的面板：

其中，paper_id是论文，replicated是处理，lenght n_authors m_authors m_share是每篇论文的附加特征，不会随时间而变化。这个小组非常不平衡（有些论文有 20 年的引用，因为它们是很久以前发表的，有些论文有 4 年的引用，因为它们是最近发表的）。有些论文从未被复制过（因此 replicated=0）
我相信我应该实现的模型应该是这样的：

其中 years_since_rep 在事件发生前为负数，在事件发生后为正数。
我遇到了 eventdd 命令，我将其实现如下：
set more off
clear all

ssc install matsort
ssc install eventdd, replace
net install eventdd, from(&quot;https://raw.githubusercontent.com/damiancclarke/eventdd/master&quot;)替换

*导入数据集
import excel &quot;C:\Users\User\Desktop\clean_pandat.xlsx&quot;, firstrow

*声明面板数据
encode paper_id, gen(P_id) /*将 paper_id 字符串转换为数字*/

xtset P_id year

generate timeToTreat = year- rep_year
*删除一些异常值后
drop if rep_year &gt; 2021 &amp; !missing(rep_year) //57 个 obs 被删除
drop if paper_id == &quot;Pool_1972&quot; //52 个 obs 被删除
drop if paper_id == &quot;Hirschman_1967&quot; //57 个 obs 被删除

eventdd 引用重复 i.year, timevar(timeToTreat) method(,cluster(P_id)) graph_op(ytitle(&quot;Citations per Year&quot;))

我的结果如下：


我的问题是：

我以为结果表中只应出现滞后和领先，但我还得到了各年的系数。通常情况是这样吗？
我看到只有最后的领先是显著的。这是否意味着，重复对引用几乎没有影响？
鉴于这似乎很重要，但领先并不重要，那么重复的系数是否相关？
我认为此命令不允许泊松回归。但是，由于我的因变量引用是计数非负变量，因此实现包含泊松模型的模型是否更合适？

我希望我的问题清楚。感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/651955/event-study-with-eventdd-interpretation</guid>
      <pubDate>Mon, 29 Jul 2024 16:50:14 GMT</pubDate>
    </item>
    <item>
      <title>分层抽样加权平均值计算中缺失组的处理</title>
      <link>https://stats.stackexchange.com/questions/651954/handling-missing-groups-in-stratified-sampling-for-weighted-mean-calculation</link>
      <description><![CDATA[我使用分层样本进行了一项统计调查，以测量意大利学生对特定主题的知识。人口根据以下类别分层：地区（城市和农村）、性别（男性、女性和其他）、区域（北部、南部和中心）和学校类型（高中、技术和专业）。这导致 2 * 3 * 3 * 3 = 54 个组组合。
但是，有些组没有回应，这会扭曲权重估计，从而扭曲分数的加权平均值。每个单位的权重计算为组样本大小的倒数。我想知道如何处理没有回应的组以获得正确的估计值。
此外，性别中的“其他”类别仅由 8 个单位代表（约占抽样人口的 2%）。我该如何处理这种情况？
数据模拟可以帮助您（语言 R）：
 library(dplyr)
library(tidyr)

# 数据模拟
set.seed(42)
data &lt;- data.frame(
Region = sample(c(&quot;North&quot;, &quot;Center&quot;, &quot;South&quot;), 300, replace = TRUE),
Area = sample(c(&quot;Urban&quot;, &quot;Rural&quot;), 300, replace = TRUE),
Gender = sample(c(&quot;Male&quot;, &quot;Female&quot;, &quot;Other&quot;), 300, replace = TRUE, prob = c(0.49, 0.49, 0.02)),
Type = sample(c(&quot;High School&quot;, &quot;Technical&quot;, &quot;专业&quot;), 300, replace = TRUE),
Score = runif(300, 60, 100)
)

# 缺失类别
data &lt;- data %&gt;%
filter(!(Region == &quot;北部&amp; 地区 == &quot;城市&amp; 类型 == &quot;专业&quot;))

# 检查并完成缺失组
data_complete &lt;- data %&gt;%
group_by(Region, 地区, 性别, 类型) %&gt;%
summarise(
size = n(),
weight = if_else(size == 0, 0, 1 / size)
) %&gt;%
ungroup() %&gt;%
complete(Region, 地区, 性别, 类型, fill = list(size = 0, weight = 0))

# 组缺失
data_complete %&gt;%
过滤器（大小 == 0）
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/651954/handling-missing-groups-in-stratified-sampling-for-weighted-mean-calculation</guid>
      <pubDate>Mon, 29 Jul 2024 16:43:19 GMT</pubDate>
    </item>
    <item>
      <title>你能将多个滞后变量的 SHAP 值相加吗？</title>
      <link>https://stats.stackexchange.com/questions/651953/can-you-sum-the-shap-values-of-multiple-lagged-variables</link>
      <description><![CDATA[我想评估用于预测计数结果 $Y$ 的梯度提升机模型的特征重要性。数据是时间序列，我在模型中引入了预测因子的滞后形式，例如：$X$、$X_{-t1}$、$X_{-t2}$、$X_{-t3}$ 都是模型特征的一部分，其中 $X$ 是给定的预测因子，$t$ 是三个时刻的滞后时间。我的问题是，当我通过平均边际 SHapley Additive exPlanations (SHAP)（因此对每个特征取平均值）评估特征重要性时，我可以将 $X$ 和所有 $X$ 滞后特征相加为一个唯一的 SHAP 值吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651953/can-you-sum-the-shap-values-of-multiple-lagged-variables</guid>
      <pubDate>Mon, 29 Jul 2024 16:40:20 GMT</pubDate>
    </item>
    <item>
      <title>均匀分布中的无偏估计量</title>
      <link>https://stats.stackexchange.com/questions/651951/unbiased-estimators-in-uniform-distributions</link>
      <description><![CDATA[变量 $x$ 在区间 $(a-1,a+1)$ 内均匀分布，其中 $a$ 的值未知。对 $x$ 的一次观察给出了值 $x_1$。
如何（有证据）使用 $x_1$ 的这个值来确定 $a$ 的无偏估计值，并确定 $a$ 的 $99\%$ 置信限度？]]></description>
      <guid>https://stats.stackexchange.com/questions/651951/unbiased-estimators-in-uniform-distributions</guid>
      <pubDate>Mon, 29 Jul 2024 16:07:54 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 VAR 脉冲响应及其置信区间</title>
      <link>https://stats.stackexchange.com/questions/651950/how-to-var-calculate-impulse-responses-and-their-confidence-intervals</link>
      <description><![CDATA[我正在尝试弄清楚如何在实践中计算脉冲响应，因为我在互联网上找到的所有材料都给出了纯理论解释，这对我来说很难理解。我可以简单地运行 VAR(x_1 + 1, x_2, x_3) - VAR(x_1, x_2, x_3) 并准确获得脉冲响应吗？我尝试将此类脉冲响应与 statsmodels.VAR.impulse_responses 进行比较，它们似乎相等。如果是这样，那么我该如何计算它们的置信区间？我可以简单地取 (1 - B)^(-1) 并计算其标准误差吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651950/how-to-var-calculate-impulse-responses-and-their-confidence-intervals</guid>
      <pubDate>Mon, 29 Jul 2024 16:01:55 GMT</pubDate>
    </item>
    <item>
      <title>确保至少遇到 1 只动物的概率的圆的半径</title>
      <link>https://stats.stackexchange.com/questions/651945/radius-of-circle-to-ensure-certain-probability-of-encountering-at-least-1-animal</link>
      <description><![CDATA[我正在尝试计算一个圆的半径，在这个圆中，至少有一只已知密度的动物以一定的概率出现。为简单起见，我们假设动物呈连续的圆形均匀分布。
首先，我知道动物密度 (D) 是丰度 (N) 与面积 (A) 之比，
$$
D = \frac{N}{A}
$$
我知道圆面积与半径 (R) 的关系方程，
$$
D = \frac{N}{\pi R^2}
$$
重新排列为 $R$，
$$
R^2 = \frac{N}{\pi D}
$$
这就是我有点迷茫的地方。举个例子，我们假设 $D = 5$（意味着每 100 公里有 5 只动物$^2$ 或每公里有 0.05 只动物$^2$），我将概率设置为 10%。那么半径应该是，
$$
R = \sqrt{\frac{0.10}{0.05\pi}}
$$
那么半径为 ~0.80 公里的圆有 10% 的概率遇到至少 1 只动物（再次假设连续圆形均匀分布）？]]></description>
      <guid>https://stats.stackexchange.com/questions/651945/radius-of-circle-to-ensure-certain-probability-of-encountering-at-least-1-animal</guid>
      <pubDate>Mon, 29 Jul 2024 15:13:55 GMT</pubDate>
    </item>
    <item>
      <title>麦克尼马尔检验需要经过多少次试验才会得出错误结果？</title>
      <link>https://stats.stackexchange.com/questions/651944/how-many-trials-until-mcnemars-test-gives-an-incorrect-result</link>
      <description><![CDATA[（虽然这个问题的表述方式像是一道考试题，但这是我完全自己编造的一道题。）
L 先生是一名机器学习研究生，致力于构建会玩游戏的人工智能。他们通过让两个人工智能相互对战来测试它们。每场比赛都会有一个模型获胜，另一个模型失败，他们只是记录每个模型在测试过程中获胜的次数。
L 先生是一名机器学习研究生，致力于构建会玩游戏的人工智能。他们通过让两个人工智能相互对战来测试它们。每场比赛都会有一个模型获胜，另一个模型失败，他们只是记录每个模型在测试过程中获胜的次数。
 L 不太擅长统计，所以他们使用 ChatGPT 并了解 McNemar 检验来计算结果是否具有统计意义。
具体来说：
def mcnemars_test(w1, w2):
n10 = w1 # 玩家 1 获胜
n01 = w2 # 玩家 2 获胜

# 计算检验统计量（使用 Yates 连续性校正）
chi2_stat = (abs(n01 - n10) - 1)**2 / (n01 + n10)

# 从自由度为 1 的卡方分布计算 p 值
p_value = stats.chi2.sf(chi2_stat, df=1)

return chi2_stat, p_value

但是，由于 L 先生是毕业生学生担心发表，他们希望确保他们的结果具有统计意义。因此，他们决定继续让人工智能玩游戏，直到结果具有统计意义（p&lt;0.05）。
假设 L 先生失败了，两个人工智能实际上是等价的。平均而言，L 先生需要让人工智能玩多少场游戏，McNemar 的测试才会返回结果，即数据由性能相同的模型生成的概率小于 5%（p&lt;0.05）？
额外加分 #1：我们已经回答了“平均而言”L 先生需要玩多少场游戏的问题，但分布是什么样的？如果 L 先生进行了 $n$ 次试验，那么观察到显著结果的概率是多少（尽管模型相同）？
额外加分 #2：如果 L 先生真的想确保他们的结果显著，因此他们使用 p&lt;0.01 作为截止值，会怎样？那么平均需要多少场游戏？一般情况下，p
我问这个问题是因为我被告知，对于统计测试，您应该事先确定试验次数，然后使用测试，并且增加测试次数直到获得显著结果就是 p-hacking 并破坏测试。但是，我实际上还没有看到过关于这种 p 值操纵有多严重的计算，而且我不知道如何凭空计算这样的事情。
我的直觉是，额外积分 #1 (EC#1) 实际上相当容易回答，我只是没有清楚地考虑它，主要问题只是 EC#1 的预期值，所以它也可能很容易回答。但是，我真的不确定 EC#2。]]></description>
      <guid>https://stats.stackexchange.com/questions/651944/how-many-trials-until-mcnemars-test-gives-an-incorrect-result</guid>
      <pubDate>Mon, 29 Jul 2024 15:10:13 GMT</pubDate>
    </item>
    </channel>
</rss>