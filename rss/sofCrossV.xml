<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 21 May 2024 09:16:31 GMT</lastBuildDate>
    <item>
      <title>证明输出的交叉熵随着输入的 KL 散度的减小而减小</title>
      <link>https://stats.stackexchange.com/questions/647674/prove-decreasing-cross-entropy-of-outputs-with-decreasing-kl-divergence-of-input</link>
      <description><![CDATA[我试图证明不等式$H(gt, y) &gt; H(gt,y_1)&gt; H(gt, y_2)$，假设 $D_{KL}(x, x_1) &gt; D_{KL}(x_1, x_2)$,
其中 $y = f(x)$，$gt$ - 基本事实，$D_{KL}$ - KL 散度，$H$ 是交叉熵，$f()$ 是一个单调函数。
假设将 $x$ 平滑到 $x_1$ 的水平后，交叉分类器 $f()$ 的熵损失减小，直到平滑之间的 KL 散度停止减小。
我尝试通过用 KL 散度表示交叉熵来证明这一点，但我总是陷入最初的 $D_{KL}(x, x_1) &gt; D_{KL}(x_1, x_2)$]]></description>
      <guid>https://stats.stackexchange.com/questions/647674/prove-decreasing-cross-entropy-of-outputs-with-decreasing-kl-divergence-of-input</guid>
      <pubDate>Tue, 21 May 2024 06:35:31 GMT</pubDate>
    </item>
    <item>
      <title>多重插补后的 Bootstrap 标准误差</title>
      <link>https://stats.stackexchange.com/questions/647673/bootstrap-standard-errors-after-multiple-imputation</link>
      <description><![CDATA[按照鲁宾规则进行多重插补，我计算了汇总估计值，在本例中为组平均值，其中汇总标准误。
我用引导程序检查了这一点，假设合并的标准错误是正确的，引导程序标准错误小得多。
由于引导标准误差相当保守，我怀疑我们不能简单地使用引导估计的标准差作为标准误差。我们如何正确引导标准错误？
我很高兴在下面提供一个 R 语言的最小示例。
&lt;前&gt;&lt;代码&gt;&gt; ## 插补
&gt;米。 &lt;- 20
&gt; imp &lt;- mouse::mice(iris2, m=m., print=FALSE, seeds=42) ## 估算
警告信息：
记录的事件数量：1
&gt; long &lt;- mouse::complete(imp, action=&#39;long&#39;) ## 组合
&gt; r0 &lt;- do.call(&#39;rbind&#39;, by(long, ~ .imp, \(x) tapply(x$Sepal.Length, x$物种,意思是）））
&gt; colMeans(r0) ## 估计值
    云芝
  4.981452 5.971290

&gt; ## 分析计算估计值和标准误差
&gt; MV &lt;- by(long, ~ .imp, \(x)
+ sapply(c(平均值=平均值, var=var), \(f)
+ tapply(x$Sepal.Length, x$物种, f))) |&gt;
+ 简化2数组()
&gt; Q &lt;- rowMeans(MV[, 1, ]) ## 计算均值估计值
&gt; U &lt;- rowMeans(MV[, 2, ]) ## 在方差内计算
&gt; B &lt;- rowSums(((MV[, 1, ] - Q)^2))/(m. - 1) ## 计算方差
&gt; T &lt;- U + (1 + 1/m.)*B ## 计算总方差
&gt; cbind(估计=Q, &#39;标准误差&#39;=sqrt(T))
           估计标准。错误
山毛榉 4.981452 0.3923879
杂色 5.971290 0.5775910


&lt;前&gt;&lt;代码&gt;&gt; ## 引导程序标准错误
&gt; R &lt;- 999
&gt; b &lt;- pbmcapply::pbmclapply(seq_len(R), \(i) {
+ 尝试捕获（{
+米。 &lt;- 20
+ imp &lt;- mouse::mice(iris2[sample.int(nrow(iris2), Replace=TRUE), ],
+ m=m., print=FALSE)
+ long &lt;- mouse::complete(imp, action=&#39;long&#39;)
+ r0 &lt;- do.call(&#39;rbind&#39;, by(long, ~ .imp, \(x)
+ tapply(x$Sepal.Length, x$物种, 平均值)))
+ 列均值(r0)
+ }, 错误=\(e) 数组(dim=c(1, 2)))
+ }, mc.cores=7L)
&gt; B＜-b|＞ do.call(what=&#39;rbind&#39;)
&gt; MatrixStats::colSds(B, na.rm=TRUE) |&gt; t()|&gt; `rownames&lt;-`(&#39;引导标准错误&#39;)
                         云芝
引导标准。错误 0.06895931 0.1079427


&lt;前&gt;&lt;代码&gt;&gt; ## 引导发行版
&gt; par(mfrow=c(1, 2))
&gt; hist(B[, &#39;setosa&#39;], &#39;fd&#39;); hist(B[, &#39;杂色&#39;], &#39;fd&#39;)


&lt;小时/&gt;
数据：
&lt;前&gt;&lt;代码&gt;&gt; iris2 &lt;- 子集(iris, Species %in% c(&#39;setosa&#39;, &#39;versicolor&#39;)) |&gt; as.matrix()
&gt;设置.种子(42)
&gt; iris2[sample.int(length(iris2), length(iris2)*.4)] &lt;- NA
&gt; iris2 &lt;- type.convert(as.data.frame(iris2), as.is=TRUE)
]]></description>
      <guid>https://stats.stackexchange.com/questions/647673/bootstrap-standard-errors-after-multiple-imputation</guid>
      <pubDate>Tue, 21 May 2024 06:28:45 GMT</pubDate>
    </item>
    <item>
      <title>中期分析会发生什么？</title>
      <link>https://stats.stackexchange.com/questions/647672/what-happens-at-interim-analysis</link>
      <description><![CDATA[我想了解中期分析期间/之后在操作上发生了什么？

如果试验符合预先设定的疗效边界，该研究在 IA 时是非盲的，并且结果会公开公布？仍然可以收集一段时间的安全吗？ IA后至最终结果是否会收集疗效？
如果试验未达到预先设定的功效边界，谁会进行必要的设计调整？向进行试验的团队宣布什么？只是试验没有达到预先设定的界限？
]]></description>
      <guid>https://stats.stackexchange.com/questions/647672/what-happens-at-interim-analysis</guid>
      <pubDate>Tue, 21 May 2024 05:48:32 GMT</pubDate>
    </item>
    <item>
      <title>了解 Chinchilla 复制研究中的 Log-Sum-Exp (LSE) 运算符，e 是集合还是 exp？</title>
      <link>https://stats.stackexchange.com/questions/647669/understanding-the-log-sum-exp-lse-operator-in-chinchilla-replication-study-is</link>
      <description><![CDATA[我正在尝试了解 Log-Sum-Exp (LSE) 运算符在 Chinchilla 复制研究中的使用，特别是论文“Chinchilla Scaling：一种复制尝试”中引用的运算符。贝西罗格鲁等人（2024）。在该研究中，LSE 用于损失参数模型的拟合过程。不过，e似乎并不是作为自然对数的标准底，而是作为参数的一组初始值。
为什么 e 是一组值 {-1, =0.5, ..., 1} 而不是 Chinchilla 复制研究中 LSE 运算符上下文中的标准指数函数？ p&gt;
上下文：
Chinchilla复制论文定义参数模型和拟合过程如下：
$$
L(N,D) = E + A N^{-\alpha} + B D^{-\beta}
$$
在龙猫复制研究中，LSE函数的使用如下：
[
\min_{a,b,e,\alpha,\beta} \sum_{\text{Run } i} \text{Huber}_\delta \left( \text{LSE}(a \alpha \log N_i, b \beta \log D_i, e) - \log L_i \right)
]
这里，LSE不是传统的log-sum-exp，而是将这些对数项与参数结合起来的函数
𝑒
e 从集合 {-1, -0.5, ..., 1} 初始化
为什么会有差异？
在这项具体研究中，e 用作从一组值初始化的参数，以优化拟合过程。这与 log-sum-exp 函数中 e 的传统用法不同，其中 e 是自然对数的底数。 e 的集合 {-1, -.5, ..., 1} 的选择允许研究人员探索不同的初始化并找到模型的最佳参数。
我希望这有助于阐明 e 在龙猫复制研究中的使用。如果您还有其他问题或需要更多详细信息，请告诉我！
&lt;小时/&gt;
将 numpy 导入为 np
从 scipy.optimize 导入最小化
从 sklearn.metrics 导入mean_squared_error

# 定义参数模型
def model_loss(N, D, E, A, alpha, B, beta):
    返回 E + (A / (N ** alpha)) + (B / (D ** beta))

# 定义Huber损失函数
def huber_loss(delta, pred, 实际):
    diff = np.abs(预测值 - 实际值)
    return np.where(diff &lt; delta, 0.5 * diff ** 2, delta * (diff - 0.5 * delta))

# 示例数据（N：模型大小，D：训练标记数量，L：观察到的损失）
数据 = [
    {&#39;N&#39;：1e6，&#39;D&#39;：1e9，&#39;L&#39;：2.0}，
    {&#39;N&#39;：1e7，&#39;D&#39;：1e10，&#39;L&#39;：1.5}，
    # 根据需要添加更多数据点
]

# 将数据转换为 numpy 数组
N = np.array([d[&#39;N&#39;] for d in data])
D = np.array([d[&#39;D&#39;] for d in data])
L = np.array([d[&#39;L&#39;] for d in data])

# 定义优化目标函数
def 目标（参数）：
    E、A、alpha、B、beta = 参数
    L_pred = model_loss(N、D、E、A、α、B、β)
    返回 np.sum(huber_loss(0.1, L_pred, L))

# 初始参数网格
参数网格 = {
    ‘E’: [0, 0.5, 1],
    ‘A’: [100, 200, 300],
    “阿尔法”：[0.3，0.5，0.7]，
    ‘B’: [1000, 2000, 3000],
    “测试版”：[0.3，0.5，0.7]，
    ‘e’: [-1, -0.5, 0, 0.5, 1]
}

# 执行网格搜索
最佳参数=无
最佳损失 = 浮动（&#39;inf&#39;）
对于 param_grid[&#39;E&#39;] 中的 E：
    对于 param_grid[&#39;A&#39;] 中的 A：
        对于 param_grid[&#39;alpha&#39;] 中的 alpha：
            对于 param_grid[&#39;B&#39;] 中的 B：
                对于 param_grid[&#39;beta&#39;] 中的 beta：
                    对于 param_grid[&#39;e&#39;] 中的 e：
                        参数 = (E, A, alpha, B, beta)
                        损失=目标（参数）
                        如果损失&lt;最佳损失：
                            最佳损失 = 损失
                            最佳参数 = 参数

print(&quot;最佳参数：&quot;, best_params)
print(&quot;最佳损失：&quot;, best_loss)

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/647669/understanding-the-log-sum-exp-lse-operator-in-chinchilla-replication-study-is</guid>
      <pubDate>Tue, 21 May 2024 04:37:11 GMT</pubDate>
    </item>
    <item>
      <title>基础模型 ANOVA 和 Kruskal-Wallis</title>
      <link>https://stats.stackexchange.com/questions/647667/underlying-model-anova-and-kruskal-wallis</link>
      <description><![CDATA[单向方差分析 (Yij= u + ti + Eij) 的基础模型是否与 Kruskal-Wallis 检验完全相同，因为 KW 是非参数方差分析等效项，还是有不同的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/647667/underlying-model-anova-and-kruskal-wallis</guid>
      <pubDate>Tue, 21 May 2024 04:28:39 GMT</pubDate>
    </item>
    <item>
      <title>在匹配中，上限混杂因素是改善与高度倾斜的连续混杂因素匹配的平衡的合法方法吗？</title>
      <link>https://stats.stackexchange.com/questions/647666/in-matching-are-capped-confounders-a-legitimate-method-of-improving-balance-for</link>
      <description><![CDATA[在匹配（或类似的混杂控制方法，例如加权）中，“上限度量”被定义为“上限度量”。 “合法的”改善高度倾斜的连续混杂因素平衡的方法？
上限指标是在线实验中常用的方差减少方法（Kohavi et al., 2014），但用于结果变量（我不熟悉 CUPED 中是否使用上限）。上限是指将某个百分位数（例如 99）之后的所有值设为相同。最终我明白这是一种偏差-方差权衡，并且平衡减少方法已经存在，例如卡尺（偏差的权衡），但在某些情况下，我认为在处理非常高的偏差时，上限也是合理的（&gt;20+ 偏度系数）由于极右尾部，但我想检查文献中是否有一些合理性，以便我不使用无效的方法（我还无法找到有关此主题的任何内容）。&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/647666/in-matching-are-capped-confounders-a-legitimate-method-of-improving-balance-for</guid>
      <pubDate>Tue, 21 May 2024 04:24:19 GMT</pubDate>
    </item>
    <item>
      <title>Quantile 函数的 Numpy 实现[重复]</title>
      <link>https://stats.stackexchange.com/questions/647659/numpy-implementation-of-the-quantile-function</link>
      <description><![CDATA[我正在尝试围绕有限样本的分位数函数的实现，特别是在 numpy 中（这样做的主要原因：我正在研究保角预测）。我可能遗漏了一些明确的内容，欢迎任何人指出我的明显错误！
假设我们观察值 $\mathcal{X} = \{x_1, x_2 \ldots x_n\}$ 并且我们想要计算 $p \in [0, 1]$ 观察样本的分位数。因此，我们将这个有限样本的分位数函数表示为 $Q(q, \mathcal{X})$。
如果我检查分位数的维基百科页面 (https://en.wikipedia.org/wiki/分位数），我们将分位数定义如下：
$Q(p, \mathcal{X}) := x: P(X
我不是 100% 确定如何解释“$P(X”这里。我认为这是对 e.c.d.f 的引用。 (https://en.wikipedia.org/wiki/Empirical_distribution_function) $\mathcal{X}$。即，“$P(X”可操作为样本中小于 $x$ 的点的比例。因此，我们得到以下等效定义：
$Q(p, \mathcal{X}) = \text{sup}\{x \in \mathbb{R} : \text{ecdf}_\mathcal{ X}(x)＜ p\}$。
到目前为止一切都很好，我相信。假设 $\mathcal{X} = \{2,3,4,10 \}$。现在让我们检查 numpy 的实现：
将 numpy 导入为 np
v = np.array([2,3,4,10])
q_third = np.quantile(v, 1/3) # 3
断言 q_third == 3 # 这是真的！分位数正好是 3

我在这里不知所措。 numpy 告诉我 $Q(\frac{1}{3}, \{2,3,4,10 \}) = 3$。根据上面的定义，我预计 $Q(\frac{1}{4}, \{2,3,4,10 \}) = 3$ 。事实上，上面的定义是不明确的。据我了解，$ Q(\frac{1}{3}, \{2,3,4,10 \})$。
在线性插值（numpy 中的默认方法）下，我们可以假设 $Q(\frac{1}{3}, \{2 ,3,4,10 \}) \neq Q(\frac{1}{3}, \{2,3,4,10 \})$。所以，要么是我，要么是 numpy 错了。我倾向于认为 numpy 在这里一定是正确的，但我无法发现我的错误。如果有人能给我解释一下，我将不胜感激。
我承认有一个类似的问题（分位数的定义&lt; /a&gt;），但该问题的答案只是报告了上面相同的维基百科定义并引用了 R （与此上下文无关）。对我的示例中应用的逻辑 numpy 的解释（希望与我使用的符号相同）将被接受作为答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/647659/numpy-implementation-of-the-quantile-function</guid>
      <pubDate>Mon, 20 May 2024 23:52:30 GMT</pubDate>
    </item>
    <item>
      <title>统计测试以查看一组是否大于另一组</title>
      <link>https://stats.stackexchange.com/questions/647653/statistical-test-to-see-whether-one-group-is-larger-than-the-other</link>
      <description><![CDATA[我有一个数据集，其中包含 2020 年至 2023 年 2 组中提供的福利的百分比。我可以使用任何统计测试来测试 A 组的百分比是否大于 B 组的百分比吗？每组的样本量为 4，因此非常小。
集团年份 Number_of_plans Plans_with_benefits 百分比
2020 51 51 100
2021 160 160 100
个 2022 220 220 100
2023 320 320 100
乙 2020 4472 1617 40
乙 2021 4905 1876 42
乙 2022 4905 2205 46
乙 2023 5082 2496 49.1
]]></description>
      <guid>https://stats.stackexchange.com/questions/647653/statistical-test-to-see-whether-one-group-is-larger-than-the-other</guid>
      <pubDate>Mon, 20 May 2024 21:43:01 GMT</pubDate>
    </item>
    <item>
      <title>比较两个延迟测量组的方法</title>
      <link>https://stats.stackexchange.com/questions/647647/method-to-compare-two-latency-measurement-groups</link>
      <description><![CDATA[我有两个服务器软件 (DNS) 测量（或者更确切地说是两组或更多组测量）。
测量结果不服从正态分布，非常偏向0-1毫秒范围。
举个例子：

总计为 41178744
延迟如下所示：

&lt;前&gt;&lt;代码&gt; 37 ▽ 延迟: (2001) [24673509, 12560724, 360898, 248331, 173744, 137900, 116894, 102247, 84900, 76741, 76066, 62945, 56794, 53765、51767、51180、49078、48807、 48590, 48472, 47094, 45483, 43727, 40700, 38913, 37…, …]
    38[0]：24673509
    39[1]：12560724
    40[2]：360898
    41[3]：248331
    42[4]：173744
    43[5]：137900
    44[6]：116894
    45[7]：102247
    46[8]：84900
    47[9]：76741
    48[10]：76066
    49[11]：62945
    50[12]：56794
    51[13]：53765
    52[14]：51767
    53[15]：51180
    54[16]：49078
    55[17]：48807
    56[18]：48590
    57[19]：48472
    58[20]：47094
    [...]

大约有 2001 个桶。
生成的数据如下所示：

请注意，图表已“向下”倾斜。对于对数刻度，请参阅 https:/ /blog.apnic.net/2017/11/24/dns-performance-metrics-logarithmic-percentile-histogram/ 进行解释。
我几乎可以通过肉眼看出 main 分支的所有测量值都是相似的，而 each-qpcache-heavy 分支的所有测量值则不然，但我是几乎不知道如何使用统计方法来测试差异。
我使用以下代码将延迟数据转换回 python 中的完整数据集：
def gen_data_from_json(json):
    sum = json[&#39;stats_sum&#39;]
    数据 = []
    毫秒 = 1
    对于 sum[&#39;latency&#39;] 中的响应：
        对于 x 在范围内（resp）：
            数据.追加（毫秒）
        毫秒 += 1
    返回数据

我已经尝试过 Kolmogorov-Smirnov 检验，但失败了（即使在 main1 和 main2 组之间，p 值始终为 0.0）。
我尝试使用 Boxcox 对数据进行标准化，然后使用单向方差分析（和双向 t 检验），但 p 值再次仅为 0.0。
上述文章建议：
基于对数百分位直方图的监控/报警
&lt;块引用&gt;
如上所述，这些图表的形状非常稳健——例如，临时异常值几乎不会出现。只有网络或服务器条件的真正变化才会使图表移动。这使得这些百分位数特别适合监测。对最慢性能“1%”和“0.1%”设置限制既敏感又具体：它会检测到所有真正的问题，并且它检测到的所有问题都是真正的问题。

所以，也许我可以采取这条路线，从每组中选择最慢的 1%，然后使用它们。
举个例子，如果我只取结果字段中的最后一个值（即在 &lt;2000 毫秒内未回答的查询）：
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt;打印（main_per）
[284243, 292413, 271626, 294025, 285524]
&gt;&gt;&gt;&gt;&gt;打印（每个_每个）
[910587, 898288, 894027, 892618, 879973]
&gt;&gt;&gt;&gt;&gt; stats.shapiro(main_per)
ShapiroResult（统计=0.9037228358106117，p值=0.4308025315693231）
&gt;&gt;&gt;&gt;&gt; stats.shapiro(each_per)
ShapiroResult（统计=0.9700229533553387，p值=0.8754009192891016）
&gt;&gt;&gt;&gt;&gt; stats.f_oneway(main_per,each_per)
F_onewayResult(统计=9280.58639361942，p值=1.505113310148663e-13)

或者，我可能可以在所有毫秒桶上执行此操作，但我不确定是否需要这样做。
但我不是统计学家，可能有一些更聪明的方法来处理这种倾斜的数据。
编辑：我可能应该补充一点，如果我们可以通过比较每个分支的两次运行来摆脱困境，那么这将为我们节省一些在 AWS 上的时间。因此，如果这可以做成多步骤，也会很有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/647647/method-to-compare-two-latency-measurement-groups</guid>
      <pubDate>Mon, 20 May 2024 20:53:04 GMT</pubDate>
    </item>
    <item>
      <title>通过连续交互省略分类中的连续变量</title>
      <link>https://stats.stackexchange.com/questions/647636/omit-continuous-variable-in-categorical-by-continuous-interaction</link>
      <description><![CDATA[我试图了解在本规范中排除收入的主要影响是否有效。无论个体是男性还是女性，性别都是 0/1 变量。收入和净资产是连续的。
净资产 = β0+β1×性别+β2×(性别×收入)+ϵ
根据https://stats.oarc.ucla.edu/stata/faq/what-happens-if-you-omit-the-main-effect-in-a- gression-model-with-an-interaction/，它似乎被正确指定。但其他帖子是表明它指定错误。
回归将产生两个交互项和一个对性别的主效应。据OARC网站称，这两个估计不应该“简单”吗？斜率是按性别划分的收入对因变量的影响之间的关系吗？包括完整的交互作用会产生两组之间的差异，但有时显示简单的斜率可能会更清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/647636/omit-continuous-variable-in-categorical-by-continuous-interaction</guid>
      <pubDate>Mon, 20 May 2024 19:07:51 GMT</pubDate>
    </item>
    <item>
      <title>R 中 VAR 脉冲响应的 MSE</title>
      <link>https://stats.stackexchange.com/questions/647633/mse-of-var-impulse-responses-in-r</link>
      <description><![CDATA[我在 R 中使用 vars 库。如何计算使用 irf 函数生成的脉冲响应的 MSE？ irf 函数返回脉冲响应系数矩阵以及下置信区间和上置信区间。是否有其他方法可以计算我生成的脉冲响应的 MSE？]]></description>
      <guid>https://stats.stackexchange.com/questions/647633/mse-of-var-impulse-responses-in-r</guid>
      <pubDate>Mon, 20 May 2024 18:53:54 GMT</pubDate>
    </item>
    <item>
      <title>当某些类别的观测值非常少时比较系数和置信区间（逻辑回归）</title>
      <link>https://stats.stackexchange.com/questions/647607/comparing-coefficients-and-confidence-intervals-when-some-categories-have-very-f</link>
      <description><![CDATA[我正在将逻辑回归模型（具有多个预测变量）拟合到结果是成功或失败的数据。我的数据点在 100,000 范围内。我的大多数变量都是分类变量，但类别大小不相等且非常倾斜 - 大多数类别占 &gt; 90% 的数据点，而每个少数类别大约只占 1-2% 的数据点。
运行逻辑回归模型后，我获得了每个校准类别变量的系数以及相关的置信区间。我学会了如何解释逻辑系数中的系数回归此处，以及如何将置信区间纳入概率计算此处。
与具有较少观测值的类别相对应的分类变量具有较大的系数，这意味着该类别的成功概率较高（其他条件相同）。较小样本量导致的不确定性似乎也可以通过所述变量系数的更宽置信区间来捕获。
我面临的问题是：与主要情况相比，大多数类别的观测值较少（~1%），以这种方式比较系数和置信区间是否有意义？当少数情况下的系数较大，并且置信区间（系数以及概率）不重叠时，似乎很容易得出少数类别具有更高成功率的结论。鉴于这些类别的观察数量较少，这个结果可能是随机的结果。
TL；博士：
当处理观测数量严重倾斜的类别时，置信区间的变化是一个很好的衡量标准，还是有更好的方法在比较回归系数时考虑每个类别的大小差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/647607/comparing-coefficients-and-confidence-intervals-when-some-categories-have-very-f</guid>
      <pubDate>Mon, 20 May 2024 10:44:45 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归模型的单边似然比检验？</title>
      <link>https://stats.stackexchange.com/questions/647549/one-sided-likelihood-ratio-test-for-a-logistic-regression-model</link>
      <description><![CDATA[我需要对逻辑回归模型的一个参数运行单方面测试：
$H_0$：$\beta = 0$
$H_1$：$\beta \geq 0$
我想避免与 Wald 等效的方法，因为已知这些方法在逻辑回归方面存在问题。 （Piegorsch，1990）表明基于单边似然比的检验对于 glms 是可能的。有在 R 中实现过吗？
如果不是，以下是实施测试的合法方法（对于 alpha = 0.05）吗？

使用confint计算两侧90%置信区间；请注意，从 R 4.4.0 开始，它使用 MASS 中的轮廓似然方法。
将 CI 的下端替换为 -∞，以获得单边置信区间。
如果 CI 排除 0，则拒绝 H0。

Piegorsch W.W. (1990)。二分响应下广义线性模型的单边显着性检验。生物识别学，46(2), 309–316。]]></description>
      <guid>https://stats.stackexchange.com/questions/647549/one-sided-likelihood-ratio-test-for-a-logistic-regression-model</guid>
      <pubDate>Sun, 19 May 2024 12:39:11 GMT</pubDate>
    </item>
    <item>
      <title>估计 N 个循环后裂纹长度超过阈值的概率</title>
      <link>https://stats.stackexchange.com/questions/647514/estimate-the-probability-that-a-crack-length-exceeds-a-threshold-value-after-n-c</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647514/estimate-the-probability-that-a-crack-length-exceeds-a-threshold-value-after-n-c</guid>
      <pubDate>Sat, 18 May 2024 17:35:26 GMT</pubDate>
    </item>
    <item>
      <title>轻松估计标准误差[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647502/estimate-standard-errors-effortlessly</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647502/estimate-standard-errors-effortlessly</guid>
      <pubDate>Sat, 18 May 2024 14:27:38 GMT</pubDate>
    </item>
    </channel>
</rss>