<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 07 Apr 2024 09:13:25 GMT</lastBuildDate>
    <item>
      <title>贝叶斯观点中的“数据是固定的”和频率论观点中的“数据是随机的”在数学上谈论的是同一件事吗？</title>
      <link>https://stats.stackexchange.com/questions/644489/are-data-are-fixed-in-bayesian-viewpoint-and-data-are-random-in-frequentist</link>
      <description><![CDATA[在我看来，在贝叶斯推理和频率推理中，观测数据$x$被建模为随机变量的观测值$X$ 遵循一定的概率分布。因此，当我遇到这两个语句时 - “数据已固定”从贝叶斯观点来看，“数据是随机的”。从频率论的角度来看，我发现它们很难理解，因为它似乎表明对数据概念的解释存在差异。
读了一些资料后，似乎“数据是固定的”是指观察到的数据$x$是固定的，“数据是随机的”是指随机变量&lt; span class=&quot;math-container&quot;&gt;$X$ 是随机的。这两个陈述中的“数据”所指的并不是同一件事。不确定我的解释是否正确。欢迎您的建议。如果我的解释是正确的，那么这两个陈述是否多余/令人困惑？]]></description>
      <guid>https://stats.stackexchange.com/questions/644489/are-data-are-fixed-in-bayesian-viewpoint-and-data-are-random-in-frequentist</guid>
      <pubDate>Sun, 07 Apr 2024 08:18:40 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 mlexperiments 和 mllrnrs 对多变量 lightgbm 机器学习模型进行交叉验证</title>
      <link>https://stats.stackexchange.com/questions/644487/how-to-do-cross-validation-for-multi-variate-lightgbm-machine-learning-model-usi</link>
      <description><![CDATA[我尝试使用轻型 GBM 模型来拟合多元时间序列。为了构建模型，我使用 mlexperiments 和 mllrnrs。

使用 timetk 和 Sample 分割时间序列

 分割 &lt;- 生产 %&gt;%time_series_split(date_var = newdate,assess=&quot;4 个月&quot;,cumulative = TRUE)
训练 &lt;- rsample::training(splits)%&gt;% select(-newdate)
测试 &lt;- rsample::testing(splits)%&gt;% select(-newdate)


创建时间序列折叠

fold_list&lt;- splitTools::create_timefolds(y = unlist(train_y),k = 5L, use_names = T, type =c (“扩展”))


设置参数和参数网格

#必需的学习者参数，未优化
learner_args &lt;- 列表(
  最大深度=-1L，
  详细 = -1L，
  目标=“回归”，
  公制＝“l2”
）

为mlexperiments::MLCrossValidation 和mlexperiments::MLNestedCV 所需的预测函数和性能指标设置参数
predict_args &lt;- NULL
Performance_metric &lt;- metric(“rmse”)
Performance_metric_args &lt;- NULL
return_models &lt;- TRUE

网格搜索所需
parameter_grid &lt;- Expand.grid(
  bagging_fraction = seq(0.6, 0.8, .2),
  特征分数 = seq(0.6, 0.8, .2),
  min_data_in_leaf = seq(20, 40, 4),
  学习率 = seq(0.1, 0.2, 0.1),
  num_leaves = seq(2, 20, 4))

optim_args &lt;- 列表（
  iters.n = ncores,
  卡帕 = 3.5，
  acq=“ucb”；
）


调整模型

 调谐器 &lt;- mlexperiments::MLTuneParameters$new(
  学习者 = mllrnrs::LearnerLightgbm$new(
        metric_optimization_higher_better = FALSE)，策略 = “网格”，ncores = ncores，seed = 种子)

    调谐器$parameter_grid &lt;-parameter_grid
调谐器$learner_args &lt;- learner_args
调谐器$set_data(x = train_x,y = train_y)
tuner_results_grid &lt;-tuner$执行(k = 3)

在此之前我可以完美地运行代码。
但是当我开始进行交叉验证时
验证器 &lt;- mlexperiments::MLNestedCV$new(
+ 学习者 = mllrnrs::LearnerLightgbm$new(
+ metric_optimization_higher_better = FALSE
+ ),
+策略=“网格”，
+ 折叠列表 = 折叠列表,
+ k_tuning = 3L,
+ ncores = ncores,
+ 种子 = 种子
+)
&gt;验证器 &lt;- mlexperiments::MLNestedCV$new(
+ 学习者 = mllrnrs::LearnerLightgbm$new(
+ metric_optimization_higher_better = FALSE
+ ),
+策略=“网格”，
+ 折叠列表 = 折叠列表,
+ k_tuning = 3L,
+ ncores = ncores,
+ 种子 = 种子
+)
&gt;验证器$parameter_grid &lt;-parameter_grid
&gt;验证器$learner_args &lt;- learner_args
&gt; validator$split_type &lt;- &quot;分层&quot;
&gt;验证器$predict_args &lt;-predict_args
&gt;验证器$performance_metric &lt;- Performance_metric
&gt;验证器$performance_metric_args &lt;- Performance_metric_args
&gt;验证器$return_models &lt;- return_models
&gt;验证器$set_data(
+ x = 火车_x,
+ y = 火车_y
+)
&gt; validator_results &lt;- validator$execute()

我收到一个错误
&lt;块引用&gt;
CV 折叠：kdry::mlh_subset(private$x, train_index) 中的 Fold1 错误：
ids 必须是整数

当我检查验证器环境时，我发现......
我的代码中的以下行
fold_list = Fold_list

不工作。 mlexperiment 和 mllrns 尚未准备好接受时间序列分割输出，每次折叠都有样本内和样本外。
如何解决这个问题。为什么 mlexperiment 和 mllrns 不支持时间序列分割？]]></description>
      <guid>https://stats.stackexchange.com/questions/644487/how-to-do-cross-validation-for-multi-variate-lightgbm-machine-learning-model-usi</guid>
      <pubDate>Sun, 07 Apr 2024 06:57:48 GMT</pubDate>
    </item>
    <item>
      <title>估计 2 个随机变量的商</title>
      <link>https://stats.stackexchange.com/questions/644486/estimation-of-a-quotient-of-2-random-variables</link>
      <description><![CDATA[我是一名数学家，统计学知识为零。那么问题来了
假设我有 3 个随机变量，$X$（噪声图像的像素矩阵），$Y$ （去噪未知图像的像素矩阵），$Z$（高斯噪声的像素矩阵），通过$$X=Y.Z$$
实际上，$X$ 数据是已知的，由特定审查员收集。审查器具有未知的噪声特征，由 $Z$ 表示。 $Z$ 的均值和方差已知，我们可以做出合理的假设 $Z$ 独立于 $X$ 和 $Y$。
估计 $Y$ 的最佳方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644486/estimation-of-a-quotient-of-2-random-variables</guid>
      <pubDate>Sun, 07 Apr 2024 06:48:46 GMT</pubDate>
    </item>
    <item>
      <title>每个分类因素还是所有分类因素的对比？</title>
      <link>https://stats.stackexchange.com/questions/644485/contrasts-by-each-categorical-factor-or-by-all</link>
      <description><![CDATA[我有以下模型：
Cmic_mg_cm2 ~ 组*样本日期 +mean_ph +mean_shan_veg +mean_tree_shandiv + (1|图)
group 和sample_date 都是分类因子变量
我用它来检查以下问题：
对于给定的样本日期，各组之间是否存在差异？
给定组的样本日期之间是否存在差异？
协变量是否有影响？
该模型纯粹用于推断，而不是用于预测 - 包含随机效应来处理采样的伪复制。
当检查与 R emmeans 包的对比时，可以选择检查所有配对，仅检查“组”。对并且仅“sample_date”对。我的问题是，哪个更有效，因为当然将所有对组合起来会导致更多的多次测试，因此在对此进行调整时会受到更高的惩罚。]]></description>
      <guid>https://stats.stackexchange.com/questions/644485/contrasts-by-each-categorical-factor-or-by-all</guid>
      <pubDate>Sun, 07 Apr 2024 05:34:52 GMT</pubDate>
    </item>
    <item>
      <title>使用回归似然从回归中复制 t 或 F 检验</title>
      <link>https://stats.stackexchange.com/questions/644482/replicate-t-or-f-test-from-regression-using-regression-likelihoods</link>
      <description><![CDATA[我听说我们用来获取回归结果显着性的 t 检验和 F 检验是从似然比检验得出的，但我在复制 t/F 的 p 值时遇到了麻烦对回归似然进行似然比检验的检验
使用底部的数据集，
在 R 中运行这三个回归：
withCov&lt;-lm(Y~X)
logLik(withCov) # &#39;log Lik。&#39; -61.98043（df=3）
与Int&lt;-lm(Y~1)
logLik(withInt) # &#39;log Lik.&#39; -63.18456（df=2）
有无&lt;-lm(Y~0)
logLik(withNone) # &#39;log Lik.&#39; -65.32909（df=1）

例如，当我对 beta_1 的显着性进行似然比检验时，我得到
1-pchisq(2*(logLik(withCov)-logLik(withInt)),df = 1)
# 0.1206958
＃ 相比于
摘要（withCov）
称呼：
lm(公式 = Y ~ X)

残差：
     最小 1Q 中值 3Q 最大
-1.98508 -0.44415 -0.02294 0.59907 1.66593

系数：
            估计标准。误差t值Pr(&gt;|t|)
（截距）-0.2568 0.1206 -2.129 0.0384 *
X -0.2045 0.1329 -1.53​​9 0.1304
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残余标准误差：48 自由度上为 0.8531
多重 R 平方：0.04702，调整 R 平方：0.02717
F 统计量：1 和 48 DF 上为 2.369，p 值：0.1304

虽然值很接近，但 0.1304 显然与 0.1206958 不同。
对于似然比检验的所有 6 种组合，我无法从 lm 恢复任何 p 值。
我做错了什么？谢谢！
下面的 R 代码设置 X 和 Y 变量：
&lt;预&gt;&lt;代码&gt;X&lt;-c(0.147462983739098,-0.552822250273655,0.0791413008277721,1.64705442993914,0.68248797132517,-0.315633973636888,1. 40047872456033,0.776033233883272,-0.343689753439294,-0.526351059575156,0.275611183793461,1.7751174954305,-0.932913434395753,0 .163895795533468,-1.00807323166609,-0.434797856886559, 0.112072003876197,-0.319445372479459,1.6989373340732,0.639738727242407,0.02980494131095,0.564230726111237,1.61191604859755, -0.474733281647485,-1.46213462226689,-1.33823497263023,0.0771907623203949,-0.698998017227839,-0.775816444324552,1.46468840793 603,-0.0940659257837727,-1.85718512842644,0.109762500597346,0.293088069440979,-1.33774986808507,0.804321505460817,1.246387803 51287 ,-1.66909878637454,-0.107871283787089,-0.286526054190293,-1.30268476505327,0.241186917275982,0.0941940655245403,0.426156461 908492,-0.951908401332523,-0.782389908678191,0.436387212517629,0.491981905432585,0.863964246361868,-0.715853080383197)
Y＜-c(0.123592053622774，-0.156626343170975，-1.00704515111936，-0.333485064105835，0.539121555715671，0.0827543989201612，-1.381 38102448818,-0.510996824863877,1.40679987755037,-0.289587787513398,-1.00983646108717,0.20397559183913,-1.53​​795623798144,-0.37 4138120013244,0.753381985793875,-0.195106670583694,-0.395410227522805, 0.314058948313302,-0.567075906102368,-0.823999734395967,0.334195737940288,-0.382748868492066,-1.1924589353617,-2.1447830778 6596,0.198528331051895,0.616636192164357,-1.66623239116232,0.906880778089087,0.663909698659448,-0.96026161021686,-0.028951352 9973109,0.103477089026045,-0.517840007699842,-1.42770065687853,-1.18735568345121,0.441872906307648,- 0.814014579874374,-0.96658546843308,0.474244931448731,-0.975319336891573,-0.0672523439350411,-0.743286641930158,0.788159757 412595,1.23723123779866,-0.508581741865352,0.220065470600985,0.822051420773978,-0.383737198032438,-2.04890944754108,1.5555393 999865)
]]></description>
      <guid>https://stats.stackexchange.com/questions/644482/replicate-t-or-f-test-from-regression-using-regression-likelihoods</guid>
      <pubDate>Sun, 07 Apr 2024 01:59:46 GMT</pubDate>
    </item>
    <item>
      <title>无法获得 PLM“之间”模型的异方差稳健标准误差</title>
      <link>https://stats.stackexchange.com/questions/644479/unable-to-get-heteroskedasticity-robust-standard-errors-for-plm-between-model</link>
      <description><![CDATA[我目前正在平衡面板数据集上运行回归，其中我在 T=10 的时间段内观察了 +1000 个人。鉴于个体特定的自变量随着时间的推移保持不变，但个体之间存在差异，我决定选择 plm 的 Between 模型。
但是，当尝试计算异方差鲁棒标准误差时，我收到以下错误：
&lt;前&gt;&lt;代码&gt;&gt; coeftest(plm_ Between, vcov = vcovHC(plm_ Between, type = “HC2”))
vcovG.plm 中的错误（x，类型 = 类型，簇 = 簇，l = 0，内部 = 内部，：
模型必须是“随机”、“内部”、“池化”或“fd”模型。模型

我假设不支持之间估计器，但是我可以使用什么来获得稳健的标准错误？当在内部进行选择或合并时，确实会计算鲁棒误差 - 但这不是所需的模型......是否有其他方法来获得鲁棒SE？
疑问，如果我什至需要 Between 方法 - 我可以使用 lm(y ~ x1 + x2 + x3 + Factor(group_id) + Factor(year) 实现相同的分析吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644479/unable-to-get-heteroskedasticity-robust-standard-errors-for-plm-between-model</guid>
      <pubDate>Sun, 07 Apr 2024 00:48:31 GMT</pubDate>
    </item>
    <item>
      <title>哪种统计方法最适合 A/B 测试中的不同转化率？</title>
      <link>https://stats.stackexchange.com/questions/644483/which-statistical-approach-is-best-for-diverse-conversion-rates-in-an-a-b-test</link>
      <description><![CDATA[我们的软件初创公司为电子商务网站构建聊天机器人。聊天机器人与打开聊天机器人的顾客进行对话，目标是完成商店主要产品的销售。我们有大约 100 家活跃的电子商务商店使用我们的聊天机器人。聊天机器人对话要么会促成销售，要么不会，因此我们正在优化的指标是每个商店的转化率。
我们希望对所有商店的聊天机器人运行 A/B 测试，以衡量转化率的改进情况。我们的目标是进行变革，以最大限度地提高所有类型商店（大/小，无论什么产品类别）的整体转化率。
以下是使我们的场景变得棘手的主要考虑因素：

每家商店都有不同的内在转化率，因为我们的商店属于所有类型的类别并且具有不同的客户人口统计数据

我们只有 100 家活跃商店，样本量相当小。然而，在所有 100 家商店中，我们每周约有 30 万个唯一用户对话，其中约 1 万个对话发生了转化

商店的每周对话量和转化率差异很大。有些商店每周有 5 万次对话，而其他商店可能每周只有 1 万次。每家商店的平均每周对话次数和中位数分别为 2000 次和 230 次。

我们希望对聊天机器人进行更改，从而对所有商店产生积极影响


最好的方法是什么？分层建模？贝叶斯？常客？或者有什么特别的？]]></description>
      <guid>https://stats.stackexchange.com/questions/644483/which-statistical-approach-is-best-for-diverse-conversion-rates-in-an-a-b-test</guid>
      <pubDate>Sun, 07 Apr 2024 00:43:14 GMT</pubDate>
    </item>
    <item>
      <title>是否有统计测试来测试多个单独的方差分析或卡方检验中的任何一个是否具有统计显着性？</title>
      <link>https://stats.stackexchange.com/questions/644478/is-there-a-statistical-test-where-you-test-whether-any-of-multiple-separate-anal</link>
      <description><![CDATA[是否有统计测试来测试多个单独的方差分析或卡方检验中的任何一个是否具有统计显着性？]]></description>
      <guid>https://stats.stackexchange.com/questions/644478/is-there-a-statistical-test-where-you-test-whether-any-of-multiple-separate-anal</guid>
      <pubDate>Sun, 07 Apr 2024 00:32:16 GMT</pubDate>
    </item>
    <item>
      <title>标准化基于树的模型或逻辑回归的特征</title>
      <link>https://stats.stackexchange.com/questions/644477/standardise-features-for-a-tree-based-model-or-logistic-regression</link>
      <description><![CDATA[我试图了解是否应该标准化所有模型的功能以及何时这样做有意义。
下面的说法正确吗？如果是的话，请您稍微解释一下。
逻辑回归和基于树的算法（例如决策树、随机森林和梯度提升）对变量的大小不敏感。因此在拟合此类模型之前不需要标准化。
在上面的此链接中找到。&lt; /p&gt;
这是否意味着异常值不会影响基于树的算法？]]></description>
      <guid>https://stats.stackexchange.com/questions/644477/standardise-features-for-a-tree-based-model-or-logistic-regression</guid>
      <pubDate>Sun, 07 Apr 2024 00:13:52 GMT</pubDate>
    </item>
    <item>
      <title>解释流行病学模型的泊松 GAM</title>
      <link>https://stats.stackexchange.com/questions/644475/interpreting-poisson-gam-for-epidemiological-model</link>
      <description><![CDATA[我正在开展一个项目，调查 PM2.5（一种污染形式）与缺血性中风住院治疗（即每天收集的住院总人数）之间的关系。我的模型如下所示，结果图也是如此：
&lt;前&gt;&lt;代码&gt;库(mgcv)
gam_model &lt;- gam(行程 ~ s(PM2.5) +
        因素（地区）+
        ns(日期, df= 7) +
        偏移量（日志（人口）），
                 数据=区域数据，
                 家庭=泊松（链接=“日志”））

绘图（gam_model，trans = exp，xlab =“PM2.5”，ylab =“相对风险”，rug = TRUE）


因为我想根据相对风险（相对于零基线 PM2.5 水平）来解释模型，所以我设置了 trans = exp。然而，我不明白如何解释结果，该结果表明，PM2.5 时，因缺血性中风住院的相对风险较低 $\approx 20$ 比 0 低。我犯错了吗？
如果这是一个愚蠢的问题，我很抱歉，我对这一切都很陌生。]]></description>
      <guid>https://stats.stackexchange.com/questions/644475/interpreting-poisson-gam-for-epidemiological-model</guid>
      <pubDate>Sat, 06 Apr 2024 22:31:38 GMT</pubDate>
    </item>
    <item>
      <title>组合不相交数据集时的 OLS 回归系数范围</title>
      <link>https://stats.stackexchange.com/questions/644458/range-of-ols-regression-coefficient-when-combining-disjoint-datasets</link>
      <description><![CDATA[您将如何解决以下问题？
我们有两个不相交的数据集，$\mathbf{X}$ 和 $\mathbf{Y}$。我们可以将它们分成 $\mathbf{X}_1 (A\times 1)$, $\mathbf{X} _2 (B\times 1)$ 和 $\mathbf{Y}_1$、$\mathbf{ Y}_2$，使得 $\mathbf{X}_1$ 与 $\mathbf{X 连接}_2$ 等于 $\mathbf{X}$ （对于 $\mathbf{Y 也类似） }$）。 $\\$

给定系数 $\beta_1$ 和 $\beta_2$，范围和最佳值是多少系数的猜测$\beta$？
如果我们使用截距运行回归会怎样？

此外，假设 $(x, y)$ 对是从 a 中独立且同分布 (i.i.d.) 绘制的，请考虑相同的问题零均值二维高斯分布。
我的方法：
我首先使用以下属性：

$\mathbf{X}^\prime\mathbf{X} = \mathbf{X}_1^\prime\mathbf{X}_1 + \mathbf{ X}_2^\prime\mathbf{X}_2$

$\mathbf{X}^\prime\mathbf{Y} = \mathbf{X}_1^\prime\mathbf{Y}_1 + \mathbf{ X}_2^\prime\mathbf{Y}_2$

$\beta_1 = (\mathbf{X}_1^\prime\mathbf{X}_1)^{-1}(\mathbf{X}_1^ \prime\mathbf{Y}_1)$

$\beta_2 = (\mathbf{X}_2^\prime\mathbf{X}_2)^{-1}(\mathbf{X}_2^ \prime\mathbf{Y}_2)$


基于这些，我得出： $\beta = (\mathbf{X}_1^\prime\mathbf{X}_1 + \mathbf{X}_2^\prime \mathbf{X}_2)^{-1}(\mathbf{X}_1^\prime\mathbf{Y}_1 + \mathbf{X}_2^\prime\mathbf{Y}_2)$ 
但是，我不确定如何从这里继续。]]></description>
      <guid>https://stats.stackexchange.com/questions/644458/range-of-ols-regression-coefficient-when-combining-disjoint-datasets</guid>
      <pubDate>Sat, 06 Apr 2024 17:32:38 GMT</pubDate>
    </item>
    <item>
      <title>中心极限定理是关于多个样本还是只关于一个样本？</title>
      <link>https://stats.stackexchange.com/questions/644441/is-central-limit-theorem-about-multiple-samples-or-just-one</link>
      <description><![CDATA[我研究过 CLT，我的理解是多个样本将生成以总体平均值为中心的正态分布。然而，今天，Linkedin 上的一篇帖子称“CLT 表示足够大的样本具有与总体相同的特征”。准确吗？看来不是。帖子的作者是否犯了任何错误或者我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644441/is-central-limit-theorem-about-multiple-samples-or-just-one</guid>
      <pubDate>Sat, 06 Apr 2024 11:45:33 GMT</pubDate>
    </item>
    <item>
      <title>SEM 有 50% 缺失数据（由于项目在各种调查选票/浪潮中的分布）</title>
      <link>https://stats.stackexchange.com/questions/644413/sem-with-50-missing-data-due-to-distribution-of-items-over-various-survey-ball</link>
      <description><![CDATA[我想使用一般社会调查中调查的主要分类变量来测试多级中介（特别是测试关于社会阶级对右翼威权主义影响的可能中介因素的一些假设），为此，我将喜欢使用结构方程模型。但是，由于缺少数据，我对其可行性表示怀疑。
事实上，没有一个参与者拥有我想要包含的所有变量的数据，因为每个项目都是在不同的浪潮或选票中提出的。例如，我有一个项目仅在选票 A 和 B 中询问，第二个项目仅在选票 B 和 C 中出现，第三个项目在选票 A 和 C 中出现。因为我正在处理分类数据，所以我正在考虑Mplus 中的 WLSMV，使用成对删除。理论上，我可以绘制一个协方差矩阵，因为每个变量都与一次或另一次选票中的所有其他变量同时出现。对于每对变量（因此对于我需要的每个协方差），我至少有 900 名参与者（尽管总共有超过 10,000 名参与者）。因此，直观上，使用成对删除对我来说似乎不是很有问题，因为大多数缺失应该是 MCAR（它们是由某些选票/模块管理中的随机化造成的）——也许除了一些没有被询问的变量之外特别是年份/波浪。然而，当我读到这篇文章时，通常建议当缺失超过 10% 时（我远远超过了这里的阈值），成对删除是不合理的。
是否有一种处理缺失的方法可以让我估计这个模型，即使每个受访者都有大约 50% 的变量随机缺失数据？或者在我的情况下使用 SEM 不可行/不建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/644413/sem-with-50-missing-data-due-to-distribution-of-items-over-various-survey-ball</guid>
      <pubDate>Fri, 05 Apr 2024 19:08:50 GMT</pubDate>
    </item>
    <item>
      <title>我的总体规模为 500，想要测试 X 个样本，很可能会失败，我要测试多少个样本？</title>
      <link>https://stats.stackexchange.com/questions/644409/i-have-a-population-size-of-500-and-want-to-test-x-number-of-samples-with-high-p</link>
      <description><![CDATA[我无法测试所有 500 个科目是否不及格。我需要知道 500 门科目中我需要测试多少科目，以便有信心地了解所有科目的结果。
公式是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644409/i-have-a-population-size-of-500-and-want-to-test-x-number-of-samples-with-high-p</guid>
      <pubDate>Fri, 05 Apr 2024 17:23:13 GMT</pubDate>
    </item>
    <item>
      <title>不同样本量的 2 比例测试中的连续性校正</title>
      <link>https://stats.stackexchange.com/questions/644347/continuity-correction-in-a-2-proportion-test-with-different-sample-sizes</link>
      <description><![CDATA[在 2 个比例的检验中（二项式 -&gt; 正态），当样本大小不同时，连续性校正是什么样的？
通常，在 1 个样本测试中，我们将除以 $n$（样本大小）$\frac {1}{2}$ 术语。但是，对于不同的样本量，我们该怎么办？
为了了解更多背景信息，我们假设我们有一个来自离散分布 $F_{X}$ 的样本，其中 $ E(X)=\mu$ 和 $Var(X) = \sigma^2$，我们将通过 $\frac{\bar X - \mu}{\frac{\sigma}{\sqrt{n}}}\sim^a N(0,1)$。
我正在读的一本书指出，在这种情况下，我们应该使用以下连续性校正：
$P(\sum X_i \leq c) = P(\sum X_i \leq c+1/2) = P\left(\frac{\bar X - \mu}{ \frac{\sigma}{\sqrt{n}}} \leq \frac{(c+1/2)/n - \mu}{\frac{\sigma}{\sqrt{n}}}\right) $
最后一个表达式可以近似为 $\Phi\left(\frac{(c+1/2)/n - \mu}{\frac{\sigma}{\sqrt{ n}}}\右）$
无论$X$遵循泊松分布还是伯努利分布，都可以应用此方法...
我的问题涉及这种技术如何推广到 2 个离散总体的情况，$X_1 \sim F_1, X_2\sim F_2$ （目前都是伯努利） ...我将搜索看看它对于其他类型的分布（例如泊松分布）是否有意义）
$\frac{\bar X_1 - \bar X_2 - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma_1^2 }{n_1}+ \ frac{\sigma_2^2}{n_2}}}\sim^a N(0,1)$
与$n_1\neq n_2$。]]></description>
      <guid>https://stats.stackexchange.com/questions/644347/continuity-correction-in-a-2-proportion-test-with-different-sample-sizes</guid>
      <pubDate>Thu, 04 Apr 2024 21:11:25 GMT</pubDate>
    </item>
    </channel>
</rss>