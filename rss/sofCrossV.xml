<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 26 Jan 2024 09:14:30 GMT</lastBuildDate>
    <item>
      <title>测试 RxC 列联表中与 1 个序数变量的关联</title>
      <link>https://stats.stackexchange.com/questions/637805/testing-for-association-in-rxc-contingency-tables-with-1-ordinal-variable</link>
      <description><![CDATA[我目前正在尝试分析类似于以下示例的数据：
&lt;块引用&gt;
假设我有来自美国各州 (~10) 的一项调查的统计数据
他们的民众对当前州政府的感受
自当选以来一直在做的事情。该变量是序数变量（“Made
事情有些/更糟，事情大致相同，制造的东西
稍微/好多了”）。

我希望能够首先找出州和这个序数变量之间是否存在关联，如果存在关联，则得出“X Y Z 各州表现是否较差/”的结论比没有关联时的预期要好”。
我知道卡方检验可以完成第一项任务，但由于 Likert 变量是序数，我觉得这可能是“留下一些东西”就我能得到的结果而言。同样，我知道我可以分析卡方检验的残差来完成第二个任务，但我觉得这遇到了与上面相同的问题。
如果可能的话，我还担心要保持这种分析相对简单，因为观众不擅长统计。]]></description>
      <guid>https://stats.stackexchange.com/questions/637805/testing-for-association-in-rxc-contingency-tables-with-1-ordinal-variable</guid>
      <pubDate>Fri, 26 Jan 2024 08:48:09 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑回归中添加和解释协变量</title>
      <link>https://stats.stackexchange.com/questions/637804/adding-and-interpreting-covariates-in-logistic-regression</link>
      <description><![CDATA[我有一个数据集，我想在连续变量“A”和“A”之间进行逻辑回归。以及分类变量“B”。然而，我还想包括“年龄”和“性”在我的统计分析中，变量是混杂因素。你能解释一下我该如何在 R 中做到这一点吗？另外，如何在考虑协变量的影响的同时获得每个变量的调整后优势比？
这是正确的统计分析吗？我还应该包括这些变量之间的相互作用吗？
模型 &lt;- glm(B ~ A + 年龄 + 性别，数据 = 数据，家庭 = 二项式())

那我该如何正确解读呢？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/637804/adding-and-interpreting-covariates-in-logistic-regression</guid>
      <pubDate>Fri, 26 Jan 2024 08:32:45 GMT</pubDate>
    </item>
    <item>
      <title>ELI5 泊松分布</title>
      <link>https://stats.stackexchange.com/questions/637803/eli5-poisson-distribution</link>
      <description><![CDATA[我认为这是所有发行版中最难掌握的一个。
看起来它也会变形，例如。没有任何一张图可以描述它。
我知道它最相似的对等分布是二项式分布（两者都仅用于离散值）。
有人可以在这里提供更多信息并举例吗？

与二项式分布和正态分布的基本差异非常有帮助。
在现实世界中，泊松分布有哪些其他分布无法发挥作用的用例？谢谢！
]]></description>
      <guid>https://stats.stackexchange.com/questions/637803/eli5-poisson-distribution</guid>
      <pubDate>Fri, 26 Jan 2024 06:34:20 GMT</pubDate>
    </item>
    <item>
      <title>一个受试者可以在重复事件分析的风险集中多次出现吗？</title>
      <link>https://stats.stackexchange.com/questions/637801/can-a-subject-appear-multiple-times-in-a-risk-set-in-recurrent-event-analyses</link>
      <description><![CDATA[为了使 Cox 模型适合重复事件数据 (Andersen &amp; Gill)，使用 R 生存包，需要用户将数据转换为计数过程格式（请参阅 [1]）。
对于重复事件分析，一个主题可以在此数据集中出现多次。
我理解这是一种编程技巧，允许人们通过 cox 比例风险模型来拟合第一个事件时间的循环模型（可能使用三明治方差估计器，以补偿事件中的受试者内相关性）次）。
在首次事件发生时间的设置下，cox 模型的部分可能性可以用风险集来表示。在这种编程技巧下，如何在重复事件场景中填充风险集？计数过程格式是否会用于转移时间，将一个受试者的多个危险期视为实际上具有重叠危险期的多个受试者？
例如，假设某个主题在计数过程格式中出现 3 次，(0,15]、(15,40] 和 (40,100])，并且在每次间隔结束时都发生一个事件。
该数据是否会被拟合为三个不同的受试者，首次事件的时间分别为 15、25 和 60，并且在时间 15 时，受试者实际上在风险集中出现了 3 次？同样，相关性是通过分组折刀法或稳健的三明治方差估计来补偿的吗？
我试图以编程方式和直观地理解这一点，上面的间隔数据框会发生什么，将使用哪些转换以编程方式将其视为首次事件模型的时间？凭直觉，为什么它会这样工作？
谢谢。
[1] https://cran.r- project.org/web/packages/survival/vignettes/timedep.pdf]]></description>
      <guid>https://stats.stackexchange.com/questions/637801/can-a-subject-appear-multiple-times-in-a-risk-set-in-recurrent-event-analyses</guid>
      <pubDate>Fri, 26 Jan 2024 05:22:36 GMT</pubDate>
    </item>
    <item>
      <title>如何对提高里程时间所需的平均练习次数进行建模？</title>
      <link>https://stats.stackexchange.com/questions/637800/how-to-model-average-number-of-practice-runs-needed-to-improve-ones-mile-time</link>
      <description><![CDATA[假设我们的朋友想要提高他的里程时间。他跑了一英里 $n$ 次，然后根据他记录的 $n$ 英里时间构建了一个经验累积分布函数 (CDF)并发现他的 $0.7$ 分位数估计为 8 分钟。他现在想再跑一英里 $k$ 次。我们的朋友问：我们如何估计 $k$ 的平均值，以便在 $0.7$ 的情况下发生改进所有 $n+k$ 英里时间中的 span&gt; 分位数现在是 6 分钟？
这个问题实用吗？我们是否需要知道他的第一个 $n$ 英里时间的分布？我们是否通过建议他在第一次 $n$ 试验（或者可能在任何试验之后）后有所改善来引入依赖性？如果我们能够访问他的第一个 $n$ 英里时间，我们该如何解决这个问题？他的进步率必须是对数的，这样在足够的练习后 $0.7$ 分位数就不会变成 1 分钟。
感谢您的阅读！我感谢任何帮助:)]]></description>
      <guid>https://stats.stackexchange.com/questions/637800/how-to-model-average-number-of-practice-runs-needed-to-improve-ones-mile-time</guid>
      <pubDate>Fri, 26 Jan 2024 05:09:06 GMT</pubDate>
    </item>
    <item>
      <title>估计甜甜圈爱好者百分比的贝叶斯概率[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637799/bayesian-probabilities-for-estimating-the-percentage-of-donut-lovers</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637799/bayesian-probabilities-for-estimating-the-percentage-of-donut-lovers</guid>
      <pubDate>Fri, 26 Jan 2024 05:02:54 GMT</pubDate>
    </item>
    <item>
      <title>为什么BERT权重初始化的标准差默认为0.02</title>
      <link>https://stats.stackexchange.com/questions/637798/why-the-standard-deviation-of-the-bert-weight-initialization-is-0-02-by-default</link>
      <description><![CDATA[神经网络中权重初始化的目的是使各层计算输出的方差保持在1.0，这取决于各层所涉及的计算。
使用Xavier初始化初始化权重W对于 Transformer Architecture 中的自注意力矩阵乘法 X@W.T 将使用标准差 $\frac{1}{\sqrt{D}}$ 从 $N(\ mu=0,\sigma=\frac{1}{\sqrt{D}})$ 以便 假设 X 和 W 的维度均为 D 并且 X 服从正态分布，则乘积的方差为 1.0。
基于 Transformer 的 BERT 的维度 D 为 768，因此 $\sigma$ 预计为0.036。但 BertConfig 表示它正在使用 0.02。 0.02 来自哪里？

BertConfig

&lt;块引用&gt;
initializer_range（浮点型，可选，默认为 0.02）— 用于初始化所有权重矩阵的 truncated_normal_initializer 的标准差。
]]></description>
      <guid>https://stats.stackexchange.com/questions/637798/why-the-standard-deviation-of-the-bert-weight-initialization-is-0-02-by-default</guid>
      <pubDate>Fri, 26 Jan 2024 04:48:53 GMT</pubDate>
    </item>
    <item>
      <title>系统性风险检测的可解释模型的局限性</title>
      <link>https://stats.stackexchange.com/questions/637797/limitations-of-explainable-models-for-systemic-risk-detection</link>
      <description><![CDATA[与 2008 年金融危机之前使用的黑盒模型相比，我试图了解当代可解释的风险评估模型的功能和局限性。
许多人指责复杂的黑匣子模型未能发现导致 2008 年危机的系统性风险。然而，当前的最佳实践要求使用可解释的模型，通常基于线性回归或截尾的正态分布。这些模型通常根据有限的近期历史数据进行训练，例如落后当前时期一年或更长时间的 6-12 个月的数据。
我的问题是：考虑到这些限制，与 2008 年之前的黑盒模型相比，可解释的建模技术在检测多年来积累的系统性风险方面是否会明显更好？具体来说：
由于只能访问一年左右的历史数据，他们如何检测长期积累的风险？
由于分布中的尾部被截断，他们如何预测尾部事件和危机？
如果唯一的区别是可解释性，那么与黑盒模型相比，这如何改进样本外系统性风险检测？
我并不是要指责，而是要了解可解释的模型是否与危机前在给定典型数据约束的情况下进行风险检测的模型具有相同的概念限制。可解释建模中是否存在可以克服这些限制的最佳实践或技术？感谢引用该领域的研究。]]></description>
      <guid>https://stats.stackexchange.com/questions/637797/limitations-of-explainable-models-for-systemic-risk-detection</guid>
      <pubDate>Fri, 26 Jan 2024 02:10:19 GMT</pubDate>
    </item>
    <item>
      <title>R 中的中介 - 解释总效应、ACME 和 ADE（二元暴露、中介和结果）的绝对值</title>
      <link>https://stats.stackexchange.com/questions/637796/mediation-in-r-interpretating-the-absolute-value-of-total-effect-acme-and-ad</link>
      <description><![CDATA[我是中介分析的初学者。在我的研究中，暴露、中介和结果是二元的（0：否，1：是）。数据按单元聚类。我拟合了中介模型（M ~ E）和结果模型（O ~ E+M），并使用“mediate”命令进行中介分析。然而，我发现自己很难解释结果。


“总效应”、“ACME（平均）”和“ADE（平均）”的绝对值的含义是什么？这些值的指数不太可能是总效应、间接效应和直接效应的 OR。
是否可以根据中介的输出来估计总效应、间接效应和直接效应的 OR（95%CI）？

提前非常感谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/637796/mediation-in-r-interpretating-the-absolute-value-of-total-effect-acme-and-ad</guid>
      <pubDate>Fri, 26 Jan 2024 01:29:15 GMT</pubDate>
    </item>
    <item>
      <title>函数积分 微分熵</title>
      <link>https://stats.stackexchange.com/questions/637795/integral-over-functions-differential-entropy</link>
      <description><![CDATA[假设有一些功能：
\begin{方程}
f(t) = p(x)
\end{方程}
其中 $p(x)$ 是 $x$ 的 PDF，位于 $t$。一些示例是具有误差范围的线性回归或高斯过程（通常 $p(x)$ 是高斯分布），例如：

如何量化 $x \sim f(t) \ \ st. 的微分熵。 \ \t_1 &lt; t &lt; t_2$？
直觉上我会执行以下操作：
\begin{方程}
   \mathcal{H}(f(t) | t_1 &lt; t &lt; t_2) = \int_{t_1}^{t_2} H(f(t)) \; dt
\end{方程}
其中 $H(f(t))$ 是 $x$ 处的微分熵$t$。
如果我的表述不清楚。我希望量化 $x$ 在 $t$ 区间内的不确定性。这个有名字吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637795/integral-over-functions-differential-entropy</guid>
      <pubDate>Fri, 26 Jan 2024 01:09:44 GMT</pubDate>
    </item>
    <item>
      <title>层次逻辑回归总结的解释</title>
      <link>https://stats.stackexchange.com/questions/637794/interpretation-of-summary-of-a-hierarchical-logistic-regression</link>
      <description><![CDATA[我想知道我对此摘要的解释是否正确。
这是我用混合模型制作的分层逻辑回归，用于分析泛化梯度。我有固定效果和随机效果。
变量如下：
a) 组：组 CONTROL 为截距。另一组是 INTERV。它是一个 FACTOR 变量。
b) TIME：TIME = 1 是截距，是第一次收集数据的时间。另一个时间是 TIME = 2。它是一个 FACTOR 变量。
c) 相似性：它是一个数字变量。这是一种刺激与另一种刺激的相似性。
d) CHOICE：它是一个 INTEGER 变量。 “选择”是指可以是 0 或 1。
e) id：研究中每个受试者的标识号。这是一个因素。
我在R中使用的代码和摘要：
模型 &lt;- glmer(选择 ~ (1+相似度|id) + 组*时间*相似度，
                   数据=数据，
                   家庭=二项式（链接=“logit”），
                   控制= glmerControl（优化器=“bobyqa”），
                   nAGQ = 1)

概括：
                                 估计标准。误差z值Pr(&gt;|z|)
（截距）0.7344 0.3534 2.078 0.037666 *
组INTERV -2.3423 0.5218 -4.489 7.15e-06 ***
时间 0.2049 0.1018 2.012 0.044191 *
相似度 0.3790 0.1882 2.013 0.044063 *
组INTERV：时间 1.3925 0.2018 6.902 5.14e-12 ***
groupINTERV：相似度 -0.6144 0.2996 -2.050 0.040316 *
时间：相似度 0.3519 0.1056 3.332 0.000862 ***
组INTERV：时间：相似度 0.2337 0.1976 1.183 0.236840


在 TIME = 1、SIMILARITY = 0 的情况下，INTERV 组的 CHOICE 大于 CONTROL 组。

对照组的选择受到时间的积极影响（当 SIMILARITY = 0 时）

对于 CONTROL 组，在 TIME = 1 时，SIMILARITY 越大，CHOICE 越大。换句话说：对于控制组，在 TIME = 1 时，SIMILARITY 对 CHOICE 产生积极影响。

INTERV 组比 CONTROL 组更受 CHOICE 中时间的积极影响。

在 TIME = 1 时，CONTROL 组中的 SIMILARITY 效果大于 INTERV 组中的效果。

在两组中，时间的增加增加了相似性对选择的影响。

]]></description>
      <guid>https://stats.stackexchange.com/questions/637794/interpretation-of-summary-of-a-hierarchical-logistic-regression</guid>
      <pubDate>Fri, 26 Jan 2024 00:51:53 GMT</pubDate>
    </item>
    <item>
      <title>eta 平方的分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637787/distribution-of-eta-squared</link>
      <description><![CDATA[我正在尝试找到 eta 平方统计量的分布及其抽样分布的推导。
一篇较旧的论文 Murray, L. W., &amp;多瑟，D.A.（1987）。显着性差异有多显着？影响程度测量的问题。咨询心理学杂志。 https://psycnet.apa.org/journals/cou/34/1/ 68 声称它是 beta 分发的，并引用了一篇提交发表的论文，但我找不到该论文的踪迹。
有人有这方面的指点吗？我知道它当然可以模拟，但我更喜欢分析推导。]]></description>
      <guid>https://stats.stackexchange.com/questions/637787/distribution-of-eta-squared</guid>
      <pubDate>Thu, 25 Jan 2024 22:41:09 GMT</pubDate>
    </item>
    <item>
      <title>先前实验的贝叶斯使用</title>
      <link>https://stats.stackexchange.com/questions/637781/bayesian-use-of-previous-experiments</link>
      <description><![CDATA[假设我有两项研究，例如 $\mathcal{S}_1$ 和 $\mathcal{S}_2 $，带有各自的数据集$\mathcal{D}_1，\mathcal{D}_2$，参数 $\theta^{(1)}、\theta^{(2)}$ 和响应变量 $y, z$。我有以下问题：

如果我有兴趣使用第一项研究的响应 $y$ 作为第二项研究的协变量，这是推荐的方式我可以继续吗？对后验预测进行正态逼近并计算均值和方差并将其用作系数的先验是否有意义，例如 $\theta_y^{(2)}$ ，在第二项研究中？我遇到的主要问题是我的后验分布看起来并不正态。

此外，假设 $\mathcal{D}_2$ 有一组出现在  中的协变量$\mathcal{D}_1$。如果我想在第二个研究 $\theta_1$ 中包含有关 $\theta_1$ 子集的后验信息，建议采用哪种方式进行&quot;&gt;$\mathcal{S}_2$？

]]></description>
      <guid>https://stats.stackexchange.com/questions/637781/bayesian-use-of-previous-experiments</guid>
      <pubDate>Thu, 25 Jan 2024 21:50:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么贝叶斯回归的后验预测分布中包含噪声？</title>
      <link>https://stats.stackexchange.com/questions/637770/why-is-the-noise-included-in-the-posterior-predictive-distribution-in-bayesian-r</link>
      <description><![CDATA[假设以下模型：$y = b_0 + b_1 * x$，其中我们为$b_0设置了一些先验， b_1$。
让 $I$ 表示我们的历史数据，$x^*$ 表示未来的输入。&lt; /p&gt;
让 $p(b_0, b_1|I)$ 表示我们的后验。
然后我们可以将后验预测分布定义为 $p(y^*|I, x^*) = \int p(y^*|b_0, b_1, x^ *)p(b_0, b_1|I)$。
现在我的问题是，为什么我们还要对似然项中的噪声进行采样 $p(y^*|b_0, b_1, x^*)$ 和不仅仅是忽略它并仅使用后验样本来计算所需的数量？这个过程有名字吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637770/why-is-the-noise-included-in-the-posterior-predictive-distribution-in-bayesian-r</guid>
      <pubDate>Thu, 25 Jan 2024 20:23:48 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何结合“典型”和“昨天”的自我报告？</title>
      <link>https://stats.stackexchange.com/questions/637708/how-should-i-combine-typical-and-yesterday-self-reports</link>
      <description><![CDATA[我继承了一项长期调查，其中包含两种个人行为衡量标准。
编辑：澄清这与饮酒行为无关；事实并非如此，我只是用它来尝试和说明。它应该适用于每天/每周时间范围内的任何行为，例如回收、在壁炉中燃烧木材、看电影等。
好的，开始解决问题。

在调查中，有一个问题可以引出“典型”行为的特征：您通常每周有多少天做 X（喝酒、烧柴、看电影等）？&lt; /p&gt;

接下来的问题是，你昨天做了X吗？

还有一个问题是获取参与者的邮政编码。


之前的分析师拟合了如下逻辑模型：
X_yesterday ~ X_per_week

其中，X_yesterday 是二进制，X_per_week 是 1、2、... 或 7 天/周。 （回答“从不”的人被排除在回归之外，因为超过一半的人表示“从不”。）
然后，分析师使用拟合值进行后续分析，包括按其他数量进行缩放，然后进行 ZIP 级别聚合。
这似乎很有用，因为主要目标是估计邮政编码级别的比率，包括没有受访者报告昨天做过 X 的邮政编码（大约为邮政编码的 20%）。
这似乎也很有用，因为将“昨天”的问题作为衡量的黄金标准，结果表明人们夸大了他们做 X 的典型频率，大约为 10-30% .
我想了解更多关于以这种方式校准典型行为的自我报告的信息。您能推荐一些好的例子或参考资料吗？如果不明显，我不是统计学家，但我精通 R。玩具问题很好，尽管我很乐意提供更多详细信息，如果它有助于识别更接近真实本质的现实世界应用程序以及该数据集的规模。诊断提示也将受到欢迎。值得注意的是，之前的分析师没有以任何方式利用空间相关性（邮政编码）。
* 简化，因为它实际上是一组问题，但最终结果是估计的频率/比例（每周天数）。还有一个类似于“当你做 X 时，你做了多少 X”的问题，但我们暂时先把它放在一边？]]></description>
      <guid>https://stats.stackexchange.com/questions/637708/how-should-i-combine-typical-and-yesterday-self-reports</guid>
      <pubDate>Thu, 25 Jan 2024 02:34:46 GMT</pubDate>
    </item>
    </channel>
</rss>