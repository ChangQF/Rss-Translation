<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 08 Mar 2024 06:17:26 GMT</lastBuildDate>
    <item>
      <title>在线性回归中对冗余分组数据进行建模</title>
      <link>https://stats.stackexchange.com/questions/642117/modeling-redundant-grouped-data-in-linear-regression</link>
      <description><![CDATA[我开始对另一个词汇数据库进行验证性分析，但在对回归进行建模之前，我意识到我在 OSF 上预先注册的模型可能存在潜在问题。作为参考，我的先验指定模型很简单，它指定了两个主要效果以及它们之间的相互作用：
$$
\text{频率} = \beta_0 + \beta_1 \text{复杂度} + \beta_2 \text{脚本} + \beta_3 \text{复杂度} \times \text{脚本} + \epsilon
$$
其中“频率”是指“频率”。是字符频率，复杂性是字符的视觉复杂性，脚本是简体字或繁体字。因此，我们有一个数字 DV、一个数字 IV 和一个两级分类变量。对脚本争论不休的原因是传统脚本通常更复杂。作为示例，表示“身体”的词可以是“身体”。是繁体字“身体”和简体字“身体”。
然而，我没有深入考虑的主要问题是，众所周知，两个脚本也共享许多相同的角色。作为示例，表示“你”的词可以是“你”。是你吗，简体字和繁体字都有。这不是一个小问题，因为两个脚本之间可能有数百甚至数千个共享字符。由于这个问题，这些字符的复杂度和频率将完全相同，这在数据集中将是高度冗余的。
我的问题是如何对此类数据进行建模？我的想法是，按照我最初考虑的方式进行建模意味着两个脚本之间的几个观察结果将完全相同，但我并不完全确定是否合适。]]></description>
      <guid>https://stats.stackexchange.com/questions/642117/modeling-redundant-grouped-data-in-linear-regression</guid>
      <pubDate>Fri, 08 Mar 2024 05:06:51 GMT</pubDate>
    </item>
    <item>
      <title>是什么困扰着统计学家晚上？</title>
      <link>https://stats.stackexchange.com/questions/642115/what-haunts-statisticians-at-night</link>
      <description><![CDATA[我在 YouTube 上观看了这段名为“夜间困扰统计学家的事情”的视频：https://www.youtube.com/watch?v=SGGLkrJa9_w
@12:01，他们展示了一个带有混杂因素的回归模型示例：
$$Y = B_0 + B_1 X + B_2 C + \epsilon$$
我想知道，你如何估计上面等式中的$C$？是否可以使用 $C$ 编写标准 OLS 或 MLE 方程，并将 $C$ 估计为如果是 beta 回归系数？
在视频中，他们指出了这一点并表示“收集尽可能多的数据并将其粘贴到模型中并不是一个好主意”。对我来说，这就像写作（其中 $X_2$ 是与混杂因素相对应的变量，例如视频示例中的朋友或没有朋友）：
$$Y = B_0 + B_1 X_1 + B_2 X_2 + \epsilon$$
因此，如何在第一个方程中估计 $C$ ？您还能使用 OLS 和 MLE 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642115/what-haunts-statisticians-at-night</guid>
      <pubDate>Fri, 08 Mar 2024 02:24:54 GMT</pubDate>
    </item>
    <item>
      <title>如何从$E[X^n]$求概率？</title>
      <link>https://stats.stackexchange.com/questions/642113/how-to-find-probability-from-exn</link>
      <description><![CDATA[已知 $E[X^n] = \frac{2}{5}(-1)^n + \frac{2^{n+1} }{5}+\frac{1}{5}$，其中 $n=1,2,3,\ldots.$
我需要找到 $P(|X-\frac{1}{2}| &gt; 1)$。
我的方法是：
我打开了模不等式，并将该概率等同于 $1-P(\frac{-1}{2}。这只有在 X=0 且 X=1 时才会发生，所以这就是我需要找到的。所以，我想我可以使用期望并扩展它来找到 MGF，即 $
M_x(t) = \sum_{n=1}^{\infty} \frac{t^n}{n!}E(X^n).$
然后用它直接从我获得的总和中找到 PMF，或相应的概率。
但是，我被困在这里，无法继续。我的做法有错吗？如果不是，那么我应该如何进行？]]></description>
      <guid>https://stats.stackexchange.com/questions/642113/how-to-find-probability-from-exn</guid>
      <pubDate>Fri, 08 Mar 2024 02:07:19 GMT</pubDate>
    </item>
    <item>
      <title>校准图的 Y 轴：每个 X 的发生率与风险百分比</title>
      <link>https://stats.stackexchange.com/questions/642112/y-axis-of-calibration-plot-incidence-per-x-vs-percentage-at-risk</link>
      <description><![CDATA[我正在考虑通过在 x 轴上绘制风险的第 10 个百分位数与每 100,000 的发生率来显示 cox 比例风险模型的校准有多么错误。对于 x 中的每个 bin，我可以绘制预测发生率和观察到发生率的数据点，以比较它们每 100,000 人的发生率。然而，在文献中似乎更常见的是绘制风险百分比（或经历过该事件的百分比），以便您获得一个很好的 45 度角（理想模型）进行比较。
哪个是更好的选择？]]></description>
      <guid>https://stats.stackexchange.com/questions/642112/y-axis-of-calibration-plot-incidence-per-x-vs-percentage-at-risk</guid>
      <pubDate>Fri, 08 Mar 2024 01:18:00 GMT</pubDate>
    </item>
    <item>
      <title>按患者进行随机森林交叉验证</title>
      <link>https://stats.stackexchange.com/questions/642111/random-forest-cross-validaton-by-patient</link>
      <description><![CDATA[我有一个包含 10 名患者和 10 名对照者的各种特征的数据集。每个患者都有很多数据点。
当使用随机 70%-30% 训练测试分割或 10 K 折叠交叉验证时，随机森林在预测数据点是来自患者还是来自对照方面表现出色。
然后我意识到这是因为部分训练数据和测试数据重叠。也就是说，训练集中的一些数据点来自患者A，当然用这个模型来预测患者A自己的数据时，它是非常准确的。
我尝试按患者拆分数据并使用“LOOCV”，每次留下一名患者作为测试集。但是，当我这样做时，随机森林模型无法运行，因为在测试集中只有一个类别（即“患者”，并且没有“对照”）。
我使用R
rftrain &lt;- randomForest(group ~ person_id + 许多其他功能，
                    数据 = 火车，localImp = TRUE）

# 使用测试数据进行 Pyellowictive 模型评估
混乱 &lt;- 混乱矩阵（预测（rftrain，测试），测试$组，阳性=“患者”）
困惑

是否有更好的包或更好的方法来进行此评估？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642111/random-forest-cross-validaton-by-patient</guid>
      <pubDate>Fri, 08 Mar 2024 00:49:13 GMT</pubDate>
    </item>
    <item>
      <title>混合效应逻辑回归模型</title>
      <link>https://stats.stackexchange.com/questions/642108/mixed-effect-logistic-regression-model</link>
      <description><![CDATA[我对统计世界非常陌生，我需要一些帮助。我目前正在做一个实验，我必须分析数据，但老实说我对统计学一无所知（我曾尝试参加大学的一些课程，但它们只涉及描述性统计；我从有些书，但在很多情况下，很难找到真正的入门课程）。然而，根据我所了解到的情况，我了解到我需要运行混合效应逻辑回归模型。我有一个二元因变量（是/否）和不同的预测变量：

group_age（分为三个级别：20、30、40）
偏好（有两个级别：a、b）
季节（有两个级别：夏季、冬季）
天气（分两个级别：晴天、雨天）

作为随机效果，我有 id 和项目编号（每个参与者有 25 个 obs，并且所有项目都是相同的）。
如何选择正确的型号？在我的预测中，因变量受到 group_age、季节和天气以及季节和天气之间相互作用的影响。相反，我不认为变量偏好会影响结果，但我想对此进行控制。
是否可以使用 RStudio 中的包 glmulti 来找到正确的模型？我读过有关比较某些指数（例如 BIC 和 AIC）的必要性。但一般来说，例如，模型的 BIC 值是多少？例如，BIC 2700 是否太高？如果不同型号共享相同的 BIC/AIC 怎么办？
运行模型后，什么应该包含完整的统计分析？
对于这些愚蠢的问题，我真的很抱歉，但我认为一步一步地对段落进行阐述会对我有很大帮助，因为我没有“方法论”。 （或者我不知道在哪里可以学到它）。
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/642108/mixed-effect-logistic-regression-model</guid>
      <pubDate>Fri, 08 Mar 2024 00:10:42 GMT</pubDate>
    </item>
    <item>
      <title>根据查找事件的概率查找事件日期</title>
      <link>https://stats.stackexchange.com/questions/642106/find-event-date-given-the-probabilities-of-finding-an-event</link>
      <description><![CDATA[我有一组临床记录，其中包含每位患者的日期和一个 NLP 模型，该模型对记录中存在的特定事件给出 0.0 到 1.0 之间的分数。根据分数，确定事件发生日期的最佳方法是什么。
基本思想是，一旦事件发生，我们将在后续访问期间看到它至少在一段时间内被提及。
一种简单的方法是采用我们看到高概率的第一个日期，但鉴于基础数据不是很好，如果这样做，我们会失去一些精度。另一方面，我们只考虑具有多个高概率注释的患者，然后我们会错过一些可能是新患者且注释较少的患者。]]></description>
      <guid>https://stats.stackexchange.com/questions/642106/find-event-date-given-the-probabilities-of-finding-an-event</guid>
      <pubDate>Thu, 07 Mar 2024 23:51:51 GMT</pubDate>
    </item>
    <item>
      <title>pyimagesearch.com - 反向传播算法。在构建三角洲链时到底发生了什么？</title>
      <link>https://stats.stackexchange.com/questions/642105/pyimagesearch-com-backpropagation-algorithm-what-is-happening-exactly-when-bu</link>
      <description><![CDATA[在教程提供的代码中，您可以找到以下行：
delta = np.matmul(D[-1], self.W[层].T) * self.sigmoid_derivative(A[层])

这一行是算法中最让我困惑的部分。根据链式法则，这条线应该具有以下外观： ∂C/∂a1 * ∂a1/∂a0 * ∂a0/w0 ...但事实并非如此。它直接乘以权重矩阵，而不是与另一个导数。更具体地说，是对权重矩阵进行转置。我根本不知道这里发生了什么。据我理解，它实际上应该看起来像： delta = D[-1] * self.sigmoid_derivative(A[layer])
这对我来说才有意义。我不明白权重矩阵作为一个术语在那里做什么。而且特别是为什么它被转置。]]></description>
      <guid>https://stats.stackexchange.com/questions/642105/pyimagesearch-com-backpropagation-algorithm-what-is-happening-exactly-when-bu</guid>
      <pubDate>Thu, 07 Mar 2024 23:32:13 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Python包“fastkde”来预测每个给定数据点的密度？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/642104/how-to-use-python-package-fastkde-to-predict-density-at-each-given-data-point</link>
      <description><![CDATA[我正在尝试使用 包 fastkde 来估计样品的密度。作者举了一个例子
&lt;前&gt;&lt;代码&gt;“”“”演示第一个 README 示例。 ”“”
将 numpy 导入为 np
导入fastkde
将 matplotlib.pyplot 导入为 plt

#生成两个随机变量数据集（代表100,000对数据点）
N = int(1e5)
x = 50*np.random.normal(大小=N) + 0.1
y = 0.01*np.random.normal(大小=N) - 300

#进行自洽密度估计
PDF = fastkde.pdf(x, y, var_names = [&#39;x&#39;, &#39;y&#39;])

PDF.plot();

就我而言，我有一个包含 100,000 个观察值的示例 z。我想预测 w 中每个数据点的密度：
将 numpy 导入为 np
导入fastkde

N = int(1e5)
z = 50*np.random.normal(大小=N) + 0.1
w = 列表(范围(10, 0, -2))

您能详细说明一下如何做到这一点吗？非常感谢您的详细阐述！]]></description>
      <guid>https://stats.stackexchange.com/questions/642104/how-to-use-python-package-fastkde-to-predict-density-at-each-given-data-point</guid>
      <pubDate>Thu, 07 Mar 2024 22:40:23 GMT</pubDate>
    </item>
    <item>
      <title>Prophet 算法是否需要假期的历史数据来预测未来的假期？</title>
      <link>https://stats.stackexchange.com/questions/642102/does-prophet-algorithms-need-historical-data-with-holidays-to-foreacast-predicti</link>
      <description><![CDATA[我计划使用 Prophet 算法进行预测，因为它似乎非常适合季节性数据。
我正在专门阅读这篇有关假期影响的文章 https:/ /facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html
我想使用holidays来确保模型针对假期进行调整。
我的问题：我需要提供包含假期的历史数据吗？
例如，如果我的训练数据来自 2023 年 10 月至 12 月，我想对 1 月进行预测并确保针对 2024 年 1 月 3 日的年度假期进行调整。考虑到没有 2023 年 1 月的训练数据，这是否可能2023 年 1 月 3 日？
如果有人可以帮助我理解这一点 - 我将非常感激！谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642102/does-prophet-algorithms-need-historical-data-with-holidays-to-foreacast-predicti</guid>
      <pubDate>Thu, 07 Mar 2024 21:57:02 GMT</pubDate>
    </item>
    <item>
      <title>应该使用什么方法来比较不同GAM的拟合度？</title>
      <link>https://stats.stackexchange.com/questions/642101/what-method-should-be-used-to-compare-fit-of-different-gams</link>
      <description><![CDATA[我正在构建以下形式的 GAM（使用 R 的 mgcv 表示法），并希望比较每个模型之间的拟合度。
model1 &lt;- gam(dependent_var ~ metric +
                             s(纬度,经度) +
                             s(单位, bs = &#39;re&#39;),
                             数据 = df)
model2 &lt;- gam(dependent_var ~ metric2 +
                             s(纬度,经度) +
                             s(单位, bs = &#39;re&#39;),
                             数据 = df)

我通常会考虑使用 AIC 或 LRT 来比较拟合度，但请注意，模型之间的差异仅是 metric 和 metric2，即模型是不是彼此的截断版本。
我考虑过的另一个选择是构建训练和测试数据集，并比较测试数据集中的残差总和以比较拟合度。是否有正确的方法来使用两个未截断的 GAM 来比较拟合度？]]></description>
      <guid>https://stats.stackexchange.com/questions/642101/what-method-should-be-used-to-compare-fit-of-different-gams</guid>
      <pubDate>Thu, 07 Mar 2024 21:43:44 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么指标来比较概率预测任务上的多类分类器？</title>
      <link>https://stats.stackexchange.com/questions/642096/what-metrics-should-i-use-to-compare-multiclass-classifiers-on-probability-predi</link>
      <description><![CDATA[我有一个平衡的数据集，其中每个对象（歌曲）都有四个目标类标签之一（歌曲的情绪）。示例：

&lt;标题&gt;

ID
功能1
功能2
功能3
目标类


&lt;正文&gt;

0
0.5
0.11
125
乐观


1
0.23
0.75
136
悲伤



数据集有一些异常值，我决定不删除它们，因为它们不是测量误差。我想预测每个对象属于四个类别中每个类别的概率，例如：

&lt;标题&gt;

ID
乐观
悲伤
精力充沛
放松


&lt;正文&gt;

0
0.75
0.13
0.5
0.7


1
0.2
0.65
0.03
0.12



我计划在未知数据上使用这个分类器来构建音乐数据库。我想要预测概率的原因是，用户在数据库中搜索音乐时，可以在四种情绪之间进行选择，而不是选择四种情绪中的一种。
我想比较几个分类器，以便选择最适合此任务的分类器。到目前为止我决定比较随机森林、XGBoost、LightGBM、CatBoost。我正在使用 Optuna 来调整超参数，优化 LogLoss（这是正确的方法吗？）。调整超参数后，我还使用 sklearn CalibrateClassifierCV 在预拟合模型上执行等渗和逻辑校准。在评估了所有这些模型后，我一直在思考如何选择最好的模型。我正在计算LogLoss、AUC-ROC、Brier 分数和 ECE。 模型评估后我是否应该考虑 LogLoss？ AUC-ROC 和 Brier 分数比 ECE 更重要吗？ 经过几次评估后，逻辑校准后的随机森林似乎倾向于使用 AUC-ROC 和 LogLoss 给出最佳结果，而等渗随机森林或未校准的 XGBoost 往往会给出最佳结果。以获得更好的 Brier 分数。在比较除等渗校准后的 ECE 之外的所有这些指标时，CatBoost 往往表现最差。这些结果出乎我的意料，我确信 RandomForest 会优于所有其他模型，而 CatBoost 也会优于所有其他模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/642096/what-metrics-should-i-use-to-compare-multiclass-classifiers-on-probability-predi</guid>
      <pubDate>Thu, 07 Mar 2024 19:57:28 GMT</pubDate>
    </item>
    <item>
      <title>如何推导出协变量平衡倾向得分的 GMM 估计量？</title>
      <link>https://stats.stackexchange.com/questions/641993/how-to-derive-the-gmm-estimator-for-the-covariate-balancing-propensity-score</link>
      <description><![CDATA[Imai 和 Ratkovic (2014) 描述的协变量平衡倾向得分 (CBPS) 涉及使用倾向得分 $\pi_\beta(\mathbf{X}) = P(T = 1\vert\mathbf{X})$ 拟合逻辑回归广义矩方法 (GMM)，使用协变量平衡矩条件来增强逻辑回归的常用矩条件。由于矩条件比要估计的参数多（两倍），系统被过度识别。
以下是 Imai 和 Ratkovic 定义该方法的方式（此处针对平均治疗效果 [ATE]）：
由 $p$ 索引的每个系数的逻辑回归得分条件为
$$s_{\beta_p}(T, \mathbf{X}) = (T - \pi_\beta(\mathbf{X})) X_p$$
平衡力矩条件为
$$w_{\beta_p}(T, \mathbf{X}) = \frac{T - \pi_\beta(\mathbf{X})}{\pi_\beta( \mathbf{X})(1 - \pi_\beta(\mathbf{X}))} X_p$$
当我们叠加这些时，我们得到 GMM 矩条件：
$$g_\mathbf{\beta}(T, \mathbf{X}) = \left(\array{s_{\beta_p}(T, \mathbf{X}) \ \w_{\beta_p}(T, \mathbf{X})} \right)$$
和
$$\bar{g}_\mathbf{\beta}(T, \mathbf{X}) = \frac{1}{N}\sum_{i = 1}^ N{g_\mathbf{\beta}(T_i, \mathbf{X}_i)}$$
他们估计 $\hat{\beta}$ 为
$$\hat{\beta} = \mathop{\arg \min}\limits_{\beta} \bar{g}_\mathbf{\beta}(T, \mathbf {X})^T \Sigma_\beta (T, \mathbf{X})^{-1} \bar{g}_\mathbf{\beta}(T, \mathbf{X})$$
他们使用
$$
\Sigma_\beta (T, \mathbf{X}) = \frac{1}{N}\sum_{i = 1}^N \left(\array{
\pi_\beta(\mathbf{X})(1-\pi_\beta(\mathbf{X}))X_iX_i^T &amp; X_i X_i^T \\
X_i X_i^T &amp; \frac{X_i X_i^T}{\pi_\beta(\mathbf{X})(1-\pi_\beta(\mathbf{X}))}
} \正确的）
$$
我的问题是 $\Sigma_\beta (T, \mathbf{X})$ 的这个表达式是如何导出的？他们声称
&lt;块引用&gt;
我们发现该协方差估计量优于矩条件的样本协方差，因为后者不会惩罚大权重。

这似乎与通常的高效 GMM 权重矩阵不同，我认为它是
$$
\Sigma_\beta (T, \mathbf{X}) = \frac{1}{N}\sum_{i = 1}^Ng_\mathbf{\beta}(T_i, \mathbf{X}_i)g_\mathbf {\beta}(T_i, \mathbf{X}_i)^T
$$
但我发现这两者并不相等。那么这个公式从何而来呢？
更新
我通过实验发现$$
\Sigma_\beta (T, \mathbf{X}) = -\frac{1}{N}\sum_{i = 1}^Ng_\mathbf{\beta}(1, \mathbf{X}_i)g_\ mathbf{\beta}(0, \mathbf{X}_i)^T
$$
这是一条线索！此外，根据 @Pusto 的评论，作者指出派生表达式是通过“整合”处理变量 $T_i$ 以预处理协变量为条件找到的$X_i$”。我仍然不清楚这种积分应该如何工作，但我认为可能可以使用此描述推导出他们的估计量。]]></description>
      <guid>https://stats.stackexchange.com/questions/641993/how-to-derive-the-gmm-estimator-for-the-covariate-balancing-propensity-score</guid>
      <pubDate>Wed, 06 Mar 2024 19:11:04 GMT</pubDate>
    </item>
    <item>
      <title>我很难解释方差分析结果</title>
      <link>https://stats.stackexchange.com/questions/641992/i-have-difficulty-interpreting-anovas-results</link>
      <description><![CDATA[我有一个不同生长环境中基因型表现（这是我的自变量）的数据集。我想知道基因型和不同环境之间是否存在相互作用，以及无论环境如何，基因型是否可以彼此区分。
我在 python 中使用 statsmodels 和 anova.anova_lm 函数
基因型*环境交互作用的方差分析（1）结果如下：
 sum_sq df F PR(&gt;F)
基因型 0.408288 103.0 3.334366 3.181776e-15
环境 2.170352 8.0 228.204205 8.152433e-175
基因型：ENV 0.654210 824.0 0.667842 1.000000e+00
残差 4.277378 3598.0 NaN NaN

这被解释为基因型和环境的贡献在响应变量中显着，但 p 值为 1 时基因型和环境的相互作用并不显着。
但是，如果我仅使用基因型作为变量运行另一个方差分析 (2)，则会得到以下结果：
 sum_sq df F PR(&gt;F)
基因型 0.167824 103.0 0.8209 0.905164
残差 8.683694 4375.0 NaN NaN

p 值为 0.9 表明不同基因型之间没有显着差异。为什么基因型在这里对响应变量没有贡献，但在方差分析 1 中却有贡献？
最后，如果我运行另一个方差分析 (3)，仅考虑基因型和环境之间的相互作用，而不考虑它们各自的项，我会得到：
 sum_sq df F PR(&gt;F)
基因型：ENV 4.860024 935.0 4.372 3.325465e-215
残差 4.277378 3598.0 NaN NaN

解释是基因型和环境相互作用之间存在显着差异，这似乎与方差分析 1 中获得的结果相矛盾。
我想回答的是不同基因型的反应是否存在显着差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/641992/i-have-difficulty-interpreting-anovas-results</guid>
      <pubDate>Wed, 06 Mar 2024 19:01:00 GMT</pubDate>
    </item>
    <item>
      <title>MLE 渐近效率的充分条件</title>
      <link>https://stats.stackexchange.com/questions/641412/sufficient-conditions-for-asymptotic-efficiency-of-mle</link>
      <description><![CDATA[根据维基百科，最大似然估计是渐近有效的，即当样本量趋于无穷大时，它们达到了 Cramér-Rao 界。但这似乎需要一些规律性条件。
您能否给出或指出一组确保最大似然估计量渐近有效的条件？是否有不同的条件？条件是否会根据要估计的参数是标量参数还是多维参数而变化？]]></description>
      <guid>https://stats.stackexchange.com/questions/641412/sufficient-conditions-for-asymptotic-efficiency-of-mle</guid>
      <pubDate>Wed, 28 Feb 2024 18:32:22 GMT</pubDate>
    </item>
    </channel>
</rss>