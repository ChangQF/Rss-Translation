<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 08 Oct 2024 15:18:36 GMT</lastBuildDate>
    <item>
      <title>在时变生存模型中模拟时间固定混杂因素</title>
      <link>https://stats.stackexchange.com/questions/655473/simulating-time-fixed-confounder-in-time-varying-survival-model</link>
      <description><![CDATA[我试图在 R 中模拟具有随时间变化暴露的生存 Cox PH 设置。目标是评估时间固定混杂因素在暴露-结果关系中的影响。
我试图使用以下代码来定义一个纵向数据集，该数据集可以由组变量 (grp)（混杂因素）部分解释。然后，我使用这些数据模拟事件发生时间数据集，该数据集也由变量 grp 部分解释。
问题：grp 变量似乎没有发挥任何混杂效应，我不明白为什么。据我所知，将其从模型中排除应该会导致暴露系数的估计出现偏差，但它似乎没有这种影响。
我的尝试：
纵向数据的模拟（基于之前的问题）
########################################################################################
#SIMULATE SURVIVAL DATA WITH TIME_VARYING CONTINUOUS EXPOSURE
########################################################################################

set.seed(1234)

#Load包
library(MASS)
library(nlme)
library(survival)
library(PermAlgo)
library(data.table)
library(fastDummies)

### 设置个体数量
n &lt;- 10000

### 平均截距和斜率
beta0 &lt;- 10.0
beta1 &lt;- -2.0

### 真实自相关
ar.val &lt;- -.8

### 真实误差 SD、截距 SD、斜率 SD 和截距斜率相关
sigma &lt;- 1.5
tau0 &lt;- 2.5
tau1 &lt;- 2.0
tau01 &lt;- 0.3

### 可能观测值的最大数量（例如年数）
m &lt;- 10

### 模拟每个个体的观察次数
p &lt;- round(runif(n,4,m))
p &lt;- rep(m,n)

### 模拟观察时刻（假设每个人都有 10 个观察）
obs&lt;-rep(1:m, n)

### 设置带有 id 和二进制时间固定协变量 X1 的数据框
dat &lt;- data.frame(id=rep(1:n, times=p), obs=obs,
x1=rep(rbinom(n, 1, 0.3), each=m))

### 模拟混杂因素作为具有 4 个级别和相应值（grpnum）的组变量
grp&lt;-c(rep(1,n*0.2),
rep(2,n*0.3),
rep(3,n*0.4),
rep(4,n*0.1))
dat$grp&lt;-as.factor(grp)

grpnum&lt;-c(rnorm(n = n*0.2,mean = 0,sd = 3),
rnorm(n = n*0.3,mean=3,sd = 1),
rnorm(n = n*0.4,mean=-1,sd = 1),
rnorm(n = n*0.1,mean=-2,sd = 4))
dat$grpnum&lt;-grpnum

### 模拟截距和斜率的（相关）随机效应
mu &lt;- c(0,0)
S &lt;- matrix(c(1, tau01, tau01, 1), nrow=2)
tau &lt;- c(tau0, tau1)
S &lt;- diag(tau) %*% S %*% diag(tau)
U &lt;- mvrnorm(n, mu=mu, Sigma=S)

### 模拟 AR(1) 误差，然后模拟实际结果
dat$eij &lt;- c(sapply(p, function(x) arima.sim(model=list(ar=ar.val), n=x) * sqrt(1-ar.val^2) * sigma))
dat$yij &lt;- round((beta0 + rep(U[,1], times=p)) +
(beta1 + rep(U[,2], times=p)) * log(obs) * dat$grpnum + dat$eij ,2)

### 注意：使用 arima.sim(model=list(ar=ar.val), n=x) * sqrt(1-ar.val^2) * sigma
### 构造，使得真实误差 SD 等于 sigma

#定义纵向数据
dat&lt;-as.matrix(dat[c(&quot;x1&quot;,&quot;grp&quot;,&quot;yij&quot;)])

#从&quot;grp&quot; 定义虚拟变量列，因为 Permalgo 不接受因子
dat &lt;- dummy_cols(dat,select_columns = &quot;grp&quot;,remove_selected_columns = T)
dat &lt;- as.matrix(sapply(dat, as.numeric)) 


模拟以三个协变量为条件的事件时间
# 在调用算法的函数之前生成事件和审查时间的向量
# eventRandom &lt;- round(runif(n, 1,10),0)
censorRandom &lt;- round(runif(n, 1,10),0)

# 生成以三个协变量为条件的生存数据
data &lt;- permalgorithm(n, m, dat[,1:5], 
XmatNames=c(&quot;sex&quot;, &quot;exposure&quot;,&quot;grp1&quot;,&quot;grp2&quot;,&quot;grp3&quot;), 
eventRandom=eventRandom,
censorRandom=censorRandom,
betas=c(log(1.5), log(1.3), 
log(0.8), log(0.8),
log(1.5)))

#运行模型

#包括grp
coxph(Surv(Start, Stop, Event) ~ sex + Exposure + grp1 + grp2 + grp3 , data=data)

#不包括grp
coxph(Surv(Start, Stop, Event) ~ sex + Exposure , data=data)

#暴露系数不变!
]]></description>
      <guid>https://stats.stackexchange.com/questions/655473/simulating-time-fixed-confounder-in-time-varying-survival-model</guid>
      <pubDate>Tue, 08 Oct 2024 14:05:15 GMT</pubDate>
    </item>
    <item>
      <title>正态分布中给定百分位数的值的公式是什么[重复]</title>
      <link>https://stats.stackexchange.com/questions/655472/what-is-the-formula-for-the-value-of-a-given-percentile-in-a-normal-distribution</link>
      <description><![CDATA[我试图找出公式来返回百分位数 $p$ 的值，假设这些值呈正态分布，平均值为 $\mu$，标准差为 $\sigma$。
如果我没记错的话，该值由逆 CDF 函数给出，但我还想知道，如果给定样本量，我如何计算假设样本量为 $n$ 的数值周围的置信区间（比如 95%）。
我意识到这个问题与这个问题类似：公式是什么正态理论中均值的置信区间？，但这个问题没有公认的答案，在评论中反复出现。
同样，就我而言，我不是在寻找仅围绕均值的置信区间，而是围绕任意百分位数的置信区间。]]></description>
      <guid>https://stats.stackexchange.com/questions/655472/what-is-the-formula-for-the-value-of-a-given-percentile-in-a-normal-distribution</guid>
      <pubDate>Tue, 08 Oct 2024 13:27:33 GMT</pubDate>
    </item>
    <item>
      <title>两层细胞之间的空间关系 - 顶层会影响底层吗？</title>
      <link>https://stats.stackexchange.com/questions/655470/spatial-relationships-between-cells-of-two-layers-does-the-top-layer-influence</link>
      <description><![CDATA[
data &lt;- data.frame(
Layer = c(rep(&quot;TopLayer&quot;, 9), rep(&quot;BottomLayer&quot;, 9)),
CellNumber = rep(1:9, 2),
Rows = rep(1:3, each = 3, times = 2),
Columns = c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;A&quot;,&quot;B&quot;,&quot;C&quot;),
Organism_A = c(2384106527, 1536784094, 1539751217, 1523052513, 1590814987, 
1352107649, 1489242422, 1324947256, 1436861411,
28989707.78, 13804448.59, 9445083.257, 10938353.51, 6964463.102, 
3054182.127, 25332055.04, 6898327.535, 6106191.811),

Organism_B = c(2200824832, 689252420.8, 773417652.8, 781621554.2, 900596793.4,
799927709.2, 877576655.6, 882006114.1, 1185177471,
12995607.78, 3990189.403, 3478803.283, 4269672.447, 4336314.549, 
1772615.585, 9455652.995, 2166266.218, 3354112.17),

Organism_C = c(565141031.9, 407109923.1, 399919019.7, 515591332, 350369021.1, 
124343494, 236922640.3, 315508071.3, 388405241.6,
9021589.754, 1282827.48, 289038.1483, 1856107.588, 669560.0038, 
402480.99, 16047493.08, 4076703.421, 2540274.561),

Organism_D = c(13886816.39, 5917155.69, 9076079.724, 6364479.436, 6603299.193, 
2377757.035, 3409059.65, 5316280.163, 7019860.52,
589742.1374, 50374.84351, 24320.78487, 27717.46694, 33827.55107, 
17236.38709, 2966871.601, 3383635.365, 243522.6605),

Organism_E = c(81810916.23, 23506996.31, 33640850.07, 60426641.66, 39478621.87, 
18547510.22, 28971068.71, 30003359.9, 29142667.22,
13305779.94, 5571703.603, 2251696.156, 6018467.227, 1475516.435, 
267636.2172, 20126618.14, 28724649.18, 7349550.19))

您好，
我有两层，每层有 9 个单元格（第 1 行：3 和 A 列：C）。每个单元格内都有来自 5 种不同生物的值。我想知道彼此重叠的单元格之间是否存在连接。换句话说，是否存在空间模式？顶层会影响底层吗？
我能做到这一点吗？这是互相关的吗？有没有办法在空间上显示相似性？
我可以使用 R 或 Python。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655470/spatial-relationships-between-cells-of-two-layers-does-the-top-layer-influence</guid>
      <pubDate>Tue, 08 Oct 2024 13:08:11 GMT</pubDate>
    </item>
    <item>
      <title>如何根据不良残差特性自动过滤掉适合 auto.arima 函数的模型？</title>
      <link>https://stats.stackexchange.com/questions/655469/how-to-automatically-filter-out-models-fitted-with-auto-arima-function-based-on</link>
      <description><![CDATA[我正在寻找一种简单的方法来过滤掉 auto.arima 函数拟合的“坏”模型。
这些是具有不同参数的 SARIMA 模型，我所说的“好”模型是指具有良好残差属性的模型 - 即残差不应自相关且应为正态。到目前为止，我一直在目视检查每个模型的残差直方图、ACF 和 PACF 图，但对于超过 30 个模型来说，它太慢且容易出错。我想为每个模型添加数值测试，以便能够快速过滤掉不好的模型。
fit_models &lt;- function(...){
# 1. 运行 auto.arima 并捕获输出，然后创建包含拟合模型参数的表
# 2. 为每个模型重新拟合并将诊断图保存到输出目录
# 3. 缺失部分：对每个模型测试自相关和正态性
# 残差的数值并附加结果（“通过”或“未通过”）
# 作为摘要 df 中的额外列，其中包含模型参数和 BIC 值
}

我想添加类似这样的内容：
每个模型的残差的#
shapiro_pass &lt;- (shapiro.test(residuals)$p_value &gt; 0.05)
kol_smir_pass &lt;- (ks.test(residuals)$p_value &gt; 0.05)

# 将这些附加到模型摘要行

但我不知道如何轻松测试 ACF 和 PACF 值的显著性。]]></description>
      <guid>https://stats.stackexchange.com/questions/655469/how-to-automatically-filter-out-models-fitted-with-auto-arima-function-based-on</guid>
      <pubDate>Tue, 08 Oct 2024 12:32:03 GMT</pubDate>
    </item>
    <item>
      <title>解决多类阈值问题的最佳方法？</title>
      <link>https://stats.stackexchange.com/questions/655468/best-way-to-solve-a-multi-class-thresholding-problem</link>
      <description><![CDATA[我有一个多类分类问题，我将图像分为 n 个类和一个背景类。我目前正在尝试找出如何找到最佳阈值（针对每个类），以便获得最高的准确度（因此，查看混淆矩阵，我试图最大化主对角线上所有元素的总和）。阈值的作用是，如果对于检测，类 p 的置信度小于类 p 的阈值，则删除该检测。
因此，我知道对于二分类情况，您可以使用 ROC 曲线找出最佳阈值。但我不确定我是否可以对每个类都这样做，然后简单地组合我得到的所有单个阈值？
任何见解都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655468/best-way-to-solve-a-multi-class-thresholding-problem</guid>
      <pubDate>Tue, 08 Oct 2024 12:28:50 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制 PR 曲线？</title>
      <link>https://stats.stackexchange.com/questions/655465/how-is-a-pr-curve-plotted</link>
      <description><![CDATA[在阅读周志华的《机器学习》（第 34-35 页）时，我对绘制 PR 曲线的方法有点困惑，希望您能帮助我摆脱困惑。
书中写道：

最有可能为阳性的样本位于排名列表的顶部，而最不可能为阳性的样本位于底部。从排名列表的顶部开始，我们可以逐步将样本标记为正，以计算每次增量的准确率和召回率。

这是否意味着，如果我们说



样本
置信度
预测




Pos
0.9
pos


Pos
0.6
pos



我们有以下公式，
$$P=\frac{TP}{TP+FP}$$ $$R =\frac {TP} {TP+FN}$$
对于每一行，我们累计计算一个新的 P 和 R？例如，第一个图是 (1/(1+0), 1/(1+0))，然后第二行是 2？每个点是如何计算的？
我读过很多资料，其中提到了一个置信度阈值，每个图点都是一个不同的阈值，TP、FN 等的值是该阈值的整个集合？哪种方法是正确的？或者它们实际上是一样的？
感谢您的时间。]]></description>
      <guid>https://stats.stackexchange.com/questions/655465/how-is-a-pr-curve-plotted</guid>
      <pubDate>Tue, 08 Oct 2024 11:20:55 GMT</pubDate>
    </item>
    <item>
      <title>关于OLS子集选择实现的问题</title>
      <link>https://stats.stackexchange.com/questions/655464/question-regarding-an-implementation-of-ols-subset-selection</link>
      <description><![CDATA[在此网站上，我找到了最佳子集选择、前向逐步选择等的 Python 实现，用于在普通线性回归中选择一组预测变量。它应该是 James、Witten、Hastie 和 Tibshirani 所著 ISLP 书籍的补充。
拟合单个模型并计算相应 RSS 的函数如下
def processSubset(feature_set):
# 在 feature_set 上拟合模型并计算 RSS
model = sm.OLS(y,X[list(feature_set)])
regr = model.fit()
RSS = ((regr.predict(X[list(feature_set)]) - y) ** 2).sum()
return {&quot;model&quot;:regr, &quot;RSS&quot;:RSS}

以及实现前向逐步选择中一步的函数
def forward(predictors):

# 提取我们仍需要处理的预测变量
remaining_predictors = [p for p in X.columns if p not in predictors]

tic = time.time()

results = []

for p in remaining_predictors:
results.append(processSubset(predictors+[p]))

# 将所有内容包装在一个漂亮的数据框中
models = pd.DataFrame(results)

# 选择 RSS 最高的模型
best_model = models.loc[models[&#39;RSS&#39;].argmin()]

toc = time.time()
print(&quot;Processed &quot;, models.shape[0], &quot;models on&quot;, len(predictors)+1, &quot;predictors in&quot;, (toc-tic), &quot;seconds.&quot;)

# 返回最佳模型，以及有关该模型的一些其他有用信息
return best_model

在我看来，这不可能是正确的，因为默认情况下截距不包含在回归中？它本身被视为一个特征，因此在某些模拟数据上运行它会导致截距被包含在某个步骤中，这是最大的改进。我遗漏了什么吗？创建模型的行不应该是这样的
model = sm.OLS(y,sm.add_constant(X[feature_set]))

提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655464/question-regarding-an-implementation-of-ols-subset-selection</guid>
      <pubDate>Tue, 08 Oct 2024 10:42:42 GMT</pubDate>
    </item>
    <item>
      <title>r 中的箱线图，在箱内绘制的晶须[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655463/boxplot-in-r-whiskers-drawn-inside-the-box</link>
      <description><![CDATA[我使用 r 绘制箱线图，但晶须最终位于箱线内。
有人可以帮忙吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655463/boxplot-in-r-whiskers-drawn-inside-the-box</guid>
      <pubDate>Tue, 08 Oct 2024 09:54:45 GMT</pubDate>
    </item>
    <item>
      <title>持续治疗的自然直接/间接效应 - 因果中介</title>
      <link>https://stats.stackexchange.com/questions/655462/natural-direct-indirect-effect-for-continuous-treatment-causal-mediation</link>
      <description><![CDATA[我正在阅读因果中介的主题，并希望将其应用于具有所有连续变量、治疗中介相互作用并假设线性的案例。我想计算自然间接效应 (NIE) 和自然直接效应 (NDE)。这是我从此处阅读的内容中得出的当前理解。具有以下模型，包括治疗 T、中介 M、目标 Y 和控制 Cm 和 Cy：
中介模型：
$M = a_0 + a_1 * T + a_2 * C_m + e_m$
结果模型：
$Y = x_0 + x_1 * T + x_2 * M + x_3 * T * M + x_4 * C_y + e_y$
我们可以按以下方式估计这 2 种效应：
$NDE = (x_1 + x_3 * (a_0 + a_1 * T^* + a_2 * C_m)) * (T-T^*)$
$NIE = (a_1 * (x_2 + x_3 * T)) * (T-T^*)$
我不太明白的是连续情况下的 $T$ 和 $T^*$。我的方法是循环遍历 $T$ 的合理值范围，并得到 $T = T^* + 1$，然后将结果绘制为线图，作为取决于治疗水平的效果范围。这有意义吗，还是我缺少应对连续治疗的具体方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/655462/natural-direct-indirect-effect-for-continuous-treatment-causal-mediation</guid>
      <pubDate>Tue, 08 Oct 2024 09:46:10 GMT</pubDate>
    </item>
    <item>
      <title>使用广义线性模型对过度分散的二项式数据进行建模</title>
      <link>https://stats.stackexchange.com/questions/655461/modelling-overdispersed-binomial-data-using-generalised-linear-models</link>
      <description><![CDATA[我进行了一系列测试，每个测试涉及回答 10 个问题，这些问题分为正确/错误，每个测试大约有 36 名参与者，大致平均分为 3 个治疗组和一个对照组（分类预测因子）。我想确定治疗组分数（正确答案的总和，范围从 0（全部错误）到 10（全部正确））是否与无治疗对照组有显著差异。有两个协变量：参与者的预测试（二项式）分数和一个没有最大分数的计数变量（测试前治疗的发生率）。
然而，我的响应变量（测试分数）偶尔会过度分散（Pearson 卡方/df 大于 2 但小于 3），但没有任何基于设计的原因导致成功概率在试验之间有所不同。对于具有 logit 链接的普通二项式模型来说，这种过度分散程度是否太严重了？我读到，对于这些情况下的过度分散，拟二项式模型会更好，但我在 SPSS 中找不到这些选项。是否可以通过语法选项或任何其他方式在 SPSS 中使用拟二项式？（我以前从未使用过 R，担心学习曲线会太耗时。）我还读到，拟二项式方法就像使用缩放二项式，但由于我不知道拟二项式或缩放二项式模型包含什么，所以我真的不明白这是什么意思。缩放二项式方法可以在 SPSS 中完成吗？我认为选择负二项式模型没有意义，因为数据是固定次数试验中正确响应的总和。
我对在 SPSS 中运行这些 GLM 也有一些疑问。对于参数估计：如何确定好的最大步长减半和最大迭代次数？协方差矩阵应该使用哪种估计量？应该将最大 Fisher 评分迭代次数设置为多少？尺度参数方法是否应该固定？是固定偏差还是 Pearson 卡方？应该指定什么值？此外，对于收敛标准，应该选择参数估计的变化、对数似然的变化还是 Hessian 收敛？提供的最小值应该是多少？我在网上找不到有关如何选择这些内容的指南。
当我运行这些二项式 GLM 时，我偶尔会收到“已达到最大步长减半次数，但对数似然值无法进一步改善。显示最后一次迭代的输出。尽管出现上述警告，GENLIN 过程仍继续。显示的后续结果基于最后一次迭代。模型拟合的有效性不确定”消息。有什么想法可以解决这个问题吗？我想确保模型是有效的。
如能就这些方面提供任何建议，我将不胜感激！提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655461/modelling-overdispersed-binomial-data-using-generalised-linear-models</guid>
      <pubDate>Tue, 08 Oct 2024 08:18:20 GMT</pubDate>
    </item>
    <item>
      <title>寻找时间序列中最重要的每日模式</title>
      <link>https://stats.stackexchange.com/questions/655460/finding-the-most-important-daily-pattern-on-a-time-series</link>
      <description><![CDATA[我有多个星期来自不同测量点的多个小时时间序列测量值。我的目标是最终将测量点聚类为簇，但为了降低维度并改善聚类，我想首先尝试为每个时间序列找到具有代表性的每日模式。因此，比较每个时间序列的每日模式，找出是否有一些在多天内重复的清晰模式，然后将它们平均为一个具有代表性的每日模式。如果没有发现重复的每日模式，那么这个测量点可以标记为异常值。什么是好的和有效的方法？每天之间的正常欧几里德距离是一种选择，但由于偏移量小，可能不是最优的。DTW 可能效果更好，但对于大型数据集来说计算量太大。]]></description>
      <guid>https://stats.stackexchange.com/questions/655460/finding-the-most-important-daily-pattern-on-a-time-series</guid>
      <pubDate>Tue, 08 Oct 2024 08:10:49 GMT</pubDate>
    </item>
    <item>
      <title>成对 Welch T 检验、Kruskal Wallace 检验还是其他？</title>
      <link>https://stats.stackexchange.com/questions/655458/pairwise-welch-t-test-kruskal-wallace-or-other</link>
      <description><![CDATA[我正在进行一项分析化学实验，其中有 11 组实验（环境样本，11 个地点）、1 个实验室对照和 3 个现场对照。所有组对特定化学物质都有 3 个观察值，除了其中一个现场对照只有 2 个。
我想知道某个环境样本站点的观察值是否与对照不同。
我不确定最好的方法是什么，并且得到了完全不同的答案：
2 位博士导师
1 位研究生
1 位研究生研究员
要将一个站点与对照进行比较，我应该比较：
(a) 将 4 个对照合并为一个组，并对环境样本进行 Welch T 检验
(b) 将 3 个对照（无对照，只有两个重复）合并为一个组，并对环境样本进行 Welch T 检验
(c) 在 Kruskal-Wallace 检验中分析 3 个或 4 个对照 + 环境样本（3 个观察值通常不正常）
(d) 比较实验室控制与环境站点在 Welch T 检验中的比较
(e) 报告这些检验的多个结果？
使用显著性 P = 0.05，我已使用方法 A、C 和 D，并得出与我的假设截然不同的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/655458/pairwise-welch-t-test-kruskal-wallace-or-other</guid>
      <pubDate>Tue, 08 Oct 2024 00:22:38 GMT</pubDate>
    </item>
    <item>
      <title>如何缩放循环变量</title>
      <link>https://stats.stackexchange.com/questions/655443/how-to-scale-circular-variables</link>
      <description><![CDATA[我经常使用此处中的方法缩放非循环变量。如果我对循环数据使用相同的方法，截断会产生问题，例如数据在缩放时根据“方向”（减少/增加）出现巨大的“跳跃”......我希望这足够清楚。我读到这里，也许我正在尝试一个不可能完成的任务？！
问题：如何缩放循环变量（例如，循环变量在 0-1 范围内，我想将其缩放到 0.25-0.75 范围内）？
（我使用 R）
编辑：我有一个包含许多人签到时间的数据集。他们可以从 00:00 到 24:00 签到，如果他们必须从 08:00 到 20:00 签到，我想模拟他们的分布。
我知道近似值有些偏颇，但我想用它作为起点。如果我使用我链接的方法，就会出现问题，例如，如果签到时间接近“截止/极值”，1:59:59 将转换为 20:00，2:00:01 将转换为 08:00，仅仅因为几秒的差别就会在数据中产生巨大的“差距/跳跃”]]></description>
      <guid>https://stats.stackexchange.com/questions/655443/how-to-scale-circular-variables</guid>
      <pubDate>Mon, 07 Oct 2024 18:11:44 GMT</pubDate>
    </item>
    <item>
      <title>优化对数似然（针对具有自相关系统性风险的 Vasicek 损失模型）</title>
      <link>https://stats.stackexchange.com/questions/655313/optimizing-loglikelihood-for-vasicek-loss-model-with-autocorrelated-systemic-ri</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655313/optimizing-loglikelihood-for-vasicek-loss-model-with-autocorrelated-systemic-ri</guid>
      <pubDate>Fri, 04 Oct 2024 10:50:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么$P(X)$的后验计算很困难？</title>
      <link>https://stats.stackexchange.com/questions/655168/why-computation-of-px-is-hard-in-posterior</link>
      <description><![CDATA[设 $X$ 表示维度为 $d$ 的输入空间，$Z$ 表示大小为 $k$ 的输出空间。后验定义为
$$P(Z|X) = \frac{P(X|Z)P(Z)}{P(X)}$$
其中 $P(Z)$ 为先验，$P(X|Z)$ 表示似然值（可由神经网络或其他模型计算）。 $P(X)$ 的计算在高维中很难（难以处理）。
$$P(X)=\sum_{Z}P(X|Z)P(Z)$$
我不明白为什么 $P(X)$ 的计算很难？我认为难度意味着计算它的时间。当提到 $P(X)$ 难以处理时，是否意味着计算 $P(X)$ 的时间是无限的或非常大的？]]></description>
      <guid>https://stats.stackexchange.com/questions/655168/why-computation-of-px-is-hard-in-posterior</guid>
      <pubDate>Tue, 01 Oct 2024 11:47:55 GMT</pubDate>
    </item>
    </channel>
</rss>