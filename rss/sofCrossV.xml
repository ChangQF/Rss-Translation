<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 03 Apr 2024 12:24:05 GMT</lastBuildDate>
    <item>
      <title>lmer (lme4) 嵌套随机结构给出奇异拟合</title>
      <link>https://stats.stackexchange.com/questions/644184/lmer-lme4-nested-random-structure-gives-singular-fit</link>
      <description><![CDATA[我正在对一些反应时间数据运行以下模型：
m_EDSIT_GV_noENGvars &lt;- afex::lmer(RTlog ~ 版本 * (age + Latent_var_nor_proficiency + Nback_score) + 版本 * poss_domain * Language_group + (1+版本|项目) + (1+版本|语言) + ( 1+版本|语言：Participant_Private_ID)、数据=SPR_EDSIT_noENGvars_GV、控制 = lmerControl(optimizer = &quot;bobyqa&quot;),(calc.derivs = FALSE))

我收到了一个奇点警告，这似乎是由于包含语言的随机效应而引起的，而不是模型本身的复杂性，因为即使我使模型变得超级简单，我也会得到仅当我包含语言时发出警告，但当我省略它时则不会发出警告。
有关数据的一些背景信息：我感兴趣的主要变量是 Version、poss_domain、Language_group 之间的交互。我正在控制年龄、latent_var_nor_proficiency 和 Nback_score 与版本交互的影响。
共有三个 Language_groups：

ITASPA，由语言组成：“西班牙语”和“西班牙语”。和“意大利语”；
DUTENG，由语言“荷兰语”组成和“英语”；
TUR，仅包含土耳其语（我最初认为这是问题所在，但当我完全删除土耳其语时，我遇到了同样的问题）

我对 Language_groups 之间的差异感兴趣，而不仅仅是组内各个语言之间的潜在差异。因此，我想将语言作为随机效果包含在内，并且由于参与者嵌套在语言中（即每个参与者仅属于一种语言），因此我将其包含在上面的代码中：
&lt;代码&gt;(1+版本|语言) + (1+版本|语言:Participant_Private_ID),

但我也尝试过：
(1+版本|语言/Participant_Private_ID)

以及单独包含它们：
&lt;代码&gt;(1+版本|语言) + (1+版本|Participant_Private_ID)

但问题仍然存在。
这就是随机效果输出的样子。更正。 for Language 为 NaN，这似乎证实了问题所在。
随机效果：
 组名称方差标准差科尔
 语言：Participant_Private_ID（拦截）0.0788530881838231668 0.28080792044
                                 版本GV 0.0045642641055289347 0.06755933766 0.19
 项目（截距） 0.0008356029770342042 0.02890679811
                                 版本GV 0.0009195357201974827 0.03032384738 -0.75
 语言（拦截） 0.0000000000000000000 0.00000000000
                                 版本GV 0.0000000000000001909 0.00000001382 NaN
 剩余 0.1166423533975448623 0.34152943270

这是否意味着当 Language_group 位于模型中时，不可能将语言作为随机因素包含在内？您对如何测试 Language_group 的效果同时控制每个组内语言之间的差异有什么建议吗？
提前非常感谢您的任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/644184/lmer-lme4-nested-random-structure-gives-singular-fit</guid>
      <pubDate>Wed, 03 Apr 2024 11:54:44 GMT</pubDate>
    </item>
    <item>
      <title>学校项目数据分析</title>
      <link>https://stats.stackexchange.com/questions/644183/data-analysis-for-school-project</link>
      <description><![CDATA[我必须创建一项假设研究，重点关注 sBCMA（血液中可溶性 B 细胞成熟抗原）与多发性骨髓瘤 (MM) 患者骨髓细胞上 BCMA 表达之间的关系。我的主要目标是研究 MM 患者的 sBCMA 水平与骨髓细胞 BCMA 表达程度之间是否存在相关性。我假设较高水平的 sBCMA 与这些细胞上 BCMA 表达的增加有关。为此，我使用了三组 MM 患者，他们要么表现出高 sBCMA、中 sBCMA 或低 sBCMA。然后，我在每组中测量 BCMA 表达。
我知道我的实验需要皮尔逊相关分析。但是，我想知道是否需要额外的测试，例如 Kruskal-Wallis H 测试...？]]></description>
      <guid>https://stats.stackexchange.com/questions/644183/data-analysis-for-school-project</guid>
      <pubDate>Wed, 03 Apr 2024 11:46:43 GMT</pubDate>
    </item>
    <item>
      <title>混合效应澄清 - 生态学</title>
      <link>https://stats.stackexchange.com/questions/644182/mixed-effects-clarification-ecology</link>
      <description><![CDATA[我有一项实验的数据，该实验测量了多个地点的各种响应变量（例如土壤碳），每个地点都采用了 4 种不同处理方法中的一种。这些地点都分组在相似的景观中，但每个处理也分组在一起，即处理 A 的所有地点都在同一区域，处理 B 的所有地点都在同一区域，但该区域与处理 A 不同，等等。 p&gt;
简而言之，它是治疗 - 部位 - 测量的标准嵌套设计（每个部位多个）
在这种情况下，将站点 ID 添加为随机效应是否有意义，或者变量的固定效应（例如地面植被多样性）是否会更合适地解释这些站点的相似性/变化？
从数学角度来说，问题是：
y ~ x + b1 + b2 + ……
或者
y ~ x + (1|plot_id)]]></description>
      <guid>https://stats.stackexchange.com/questions/644182/mixed-effects-clarification-ecology</guid>
      <pubDate>Wed, 03 Apr 2024 11:39:50 GMT</pubDate>
    </item>
    <item>
      <title>差距统计中的数学公式问题</title>
      <link>https://stats.stackexchange.com/questions/644181/problem-with-mathematical-formulas-in-gap-statistic</link>
      <description><![CDATA[我正在研究文章“通过间隙统计估计数据集中的簇数”作者：R. Tibshirani、G. Walther 和 T. Hastie。
在这一部分中，我无法理解数学公式的来源以及 pn/12 和 2/p 对我来说意味着什么。
有人可以向我解释一下吗？
下面我把文章要求的部分贴出来：
]]></description>
      <guid>https://stats.stackexchange.com/questions/644181/problem-with-mathematical-formulas-in-gap-statistic</guid>
      <pubDate>Wed, 03 Apr 2024 11:33:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么 p 值为 $P(p≤\alpha | H=1)≤\alpha$ 而不是 $P(H=1 | p≤\alpha)$？</title>
      <link>https://stats.stackexchange.com/questions/644179/why-p-values-as-pp%e2%89%a4-alpha-h-1%e2%89%a4-alpha-and-not-ph-1-p%e2%89%a4-alpha</link>
      <description><![CDATA[这是我的问题，就好像我从 $p$ 值的定义开始 ($P(p ≤\alpha | H=1)≤\alpha$ ) 并应用贝叶斯规则我得出：
$$ P(p≤\alpha | H=1)=P(H=1 | p≤\alpha)\frac{P(p≤\alpha)}{P(H =1)} ≤\alpha $$
这样：
$$ P(H=1 | p≤\alpha) ≤\frac{\alpha}{P(p≤\alpha)} P(H=1)$$ 
在这种情况下，我们会知道，如果我们在数据中获得小于 $\alpha$ 的 p 值，我们可以自信地声明原假设如果 $\frac{\alpha}{P(p≤\alpha)} P(H=1)$ 很小，则为 false。
我看到的问题是，根据我研究的零假设，这种方法对我来说没有意义（什么是 $P(H=1)$对于 $H: X\sim N(0,1)$)。但同样地，由于对象定义不明确，这在数学上对我来说没有意义，经典定义对我来说也没有任何意义，因为我看不到它如何衡量拒绝的任何信心 $H$，因为它实际上很大程度上取决于 $p$ 值在  时的行为方式$H$ 为 false（例如，如果 $P(p≤\alpha | H=0)≤\alpha$ 也是如此，我们怎样才能甚至区分它们）。
我知道我的问题表述得不是很清楚，但我确实一直在尝试在脑海中获取$p-$值，但无法抓住本质其中。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644179/why-p-values-as-pp%e2%89%a4-alpha-h-1%e2%89%a4-alpha-and-not-ph-1-p%e2%89%a4-alpha</guid>
      <pubDate>Wed, 03 Apr 2024 11:22:58 GMT</pubDate>
    </item>
    <item>
      <title>如何利用不均匀通信进行二元预测</title>
      <link>https://stats.stackexchange.com/questions/644173/how-to-use-uneven-communication-for-binary-prediction</link>
      <description><![CDATA[我有一个传感器，可以捕获容器何时受到撞击。有了这个，我就有了一个数据集，其中包含设备何时通信且没有影响以及设备何时通信且有影响的数据。我面临的主要问题是，如果有影响，设备总是会进行通信，但如果是“无影响”，则设备始终会进行通信。在这种情况下，我似乎无法确定何时完成此通信的算法，即使它可能不是随机的。
我使用这个二进制数据集通过采样（下/上/SMOTE）训练了不同的模型。
这些模型在验证数据集中具有中等的性能结果（MCC&gt;0.25）。
出现以下问题：

如果我在实时场景中使用此模型，对于每次通信，我可以获得相同的结果吗？
数据可能不是相同分布的，因为我不知道“无影响情况”的算法。我应该处理/我该如何处理这个问题？
我将此问题视为二元分类问题。我可以用另一种方式来处理它吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/644173/how-to-use-uneven-communication-for-binary-prediction</guid>
      <pubDate>Wed, 03 Apr 2024 10:01:12 GMT</pubDate>
    </item>
    <item>
      <title>如何计算广义线性混合模型中每个变量的相对重要性（变量重要性）？</title>
      <link>https://stats.stackexchange.com/questions/644171/how-to-calculate-the-relative-importance-of-each-variablevariable-importance-i</link>
      <description><![CDATA[我正在使用glmm来分析鸟类追踪位点的密度与环境变量因素之间的关系（这是我的代码）；但我不确定如何评估不同变量的相对重要性（变量重要性）。剂量“vip”包有意义吗？您有什么建议吗？
TMB = glmmTMB(密度 ~ 森林+草地+水+build_up +高程 +(1|个人), ziformula=~.,family=“nbinom2”,数据）
]]></description>
      <guid>https://stats.stackexchange.com/questions/644171/how-to-calculate-the-relative-importance-of-each-variablevariable-importance-i</guid>
      <pubDate>Wed, 03 Apr 2024 09:23:46 GMT</pubDate>
    </item>
    <item>
      <title>RNA-Seq 分析的统计阈值：考虑治疗效果的交叉点</title>
      <link>https://stats.stackexchange.com/questions/644170/statistical-thresholds-for-rna-seq-analysis-considering-the-intersection-of-tre</link>
      <description><![CDATA[我正在进行一项 RNA 测序实验，涉及暴露于化学物质 A、B 和 A+B 的线虫，以观察由于暴露而导致的 mRNA 变化。我特别感兴趣的是确定 A+B 处理与单独处理 A 或 B（作为对照）相比的 mRNA 变化。
为了分析这一点，我使用了edgeR（一种统计方法）来分别比较A与A+B以及B与A+B，然后检查结果的交集（将A与A+B相交以及B与A+B相交） A+B）。
在我的方法中，我使用拦截方法，旨在识别 A 与 A+B 以及 B 与 A+B 中差异表达的转录本。我的问题涉及对每个单独分析（A 与 A+B 和 B 与 A+B）使用高于 0.05 的 p 值阈值的合理性。
为了进一步解释，我正在考虑概率乘法规则。如果事件 A 的概率为 1/2，事件 B 的概率相同为 1/2，则两个事件同时发生的概率计算为 (1/2)*(1/2) = 1/4。 
我很好奇是否可以在这里应用类似的原则。具体来说，如果我开始时每次单独分析的 p 值为 0.223，我是否可以将该值平方以获得截距的 p 值，从而得到 (0.223)^2 = 0.05？但是，我不确定在两次比较中使用相同的 A+B 读数可能会如何影响此计算。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644170/statistical-thresholds-for-rna-seq-analysis-considering-the-intersection-of-tre</guid>
      <pubDate>Wed, 03 Apr 2024 08:27:10 GMT</pubDate>
    </item>
    <item>
      <title>预测收集额外数据的好处</title>
      <link>https://stats.stackexchange.com/questions/644167/predict-benefit-of-gathering-additional-data</link>
      <description><![CDATA[我生成了数据，然后根据这些数据执行数千次独立测试，并在多重假设校正后寻找在 p 值阈值 0.01 时显着的数据。
这给出了有用的结果，但我经常被问到的一个问题是，我们是否可以使用生成的数据来预测，如果我们生成更多的数据，还有多少测试将是重要的。也就是说，如果我们将生成的数据增加 x%，我们就可以预测还有多少测试可能是重要的。
我的直觉是这是不可能的，但也许我可以以某种方式使用 p 值分布（及其与均匀值的偏差）来估计有多少可能在更大的深度上是显着的？我的另一个想法是对数据进行下采样，并尝试构建“显着测试数量”的经验曲线作为数据量的函数。]]></description>
      <guid>https://stats.stackexchange.com/questions/644167/predict-benefit-of-gathering-additional-data</guid>
      <pubDate>Wed, 03 Apr 2024 07:42:30 GMT</pubDate>
    </item>
    <item>
      <title>相对误差优化与对数尺度优化</title>
      <link>https://stats.stackexchange.com/questions/644166/optimization-of-relative-error-vs-optimization-on-log-scale</link>
      <description><![CDATA[我目前正在训练一个模型来预测房屋销售价格，$P$，作为一组特征的函数$\textbf{x}$。我选择的模型是对数指定的回归模型，其形式为：
\begin{align}
\ln(P) = f(\textbf{x}) \ \ \ (1)
\end{对齐}
我用普通最小二乘法拟合。
现在，对于我的应用程序来说，重要的通常不是绝对误差，而是相对误差。使用具体的错误措施，我例如通常对通过平均绝对相对误差进行良好测量的模型更感兴趣
\begin{align}
\varepsilon_{\text{rel}} = \frac{1}{N}\sum_{j} \| P_{j} - \hat{P} \|/P_{j} \ \ \ (2)
\end{对齐}
与更标准的平均绝对误差相反
\begin{align}
\varepsilon = \frac{1}{N}\sum_{j} \| P_{j} - \hat{P} \| \ \ \ (3)
\end{对齐}
我的问题如下：在什么意义上可以将对数尺度上的优化视为相当于模型相对误差的最小化？
为了详细说明是什么导致我提出这个问题，请考虑以下简单示例。假设我只有两个价格数据点 $P_{1} = 10, P_{2} = 100$ 并考虑最简单的模型，该模型仅使用数据点作为模型预测。很明显，使用对数转换可以减少总体相对误差 $\hat{P}_{\text{ln}} = \exp((\ln(100) + \ln(10))/2) \约 32$ 和 $\hat{P} = (100 + 10)/2 = 55$ ，其中前者具有较低的平均绝对相对误差（如（2）所示）。
回到我原来的问题，是否有更精确的数学方法来表达上述推理？我自己的尝试如下。假设训练了（1）中给出的形式的对数指定回归模型。这对应于最小化以下形式的最小二乘成本：
\begin{align}
C = \sum_{j}(\ln(P_{j}) – f(\textbf{x}_{j}))^2
\end{对齐}
现在，鉴于拟合函数接近于 $\ln(P_{j})$ 我们可以写成  $f(\textbf{x}_{j}) = \ln(P_{j} + \Delta P)$，其中 $\Delta P$ span&gt; 是一些小数字。对于第一个订单，我们然后找到
\begin{align}
C = \sum_{j}(\ln(P_{j}) – \ln(P_{j} + \Delta P))^2 = \sum_{j}(\ln((P_{j} + \Delta P)) P )/P_{j}))^2 = \sum_{j}(\ln((1 + \Delta P/P_{j}))^2 \近似 \sum_{j}(\Delta P/P_{ j})^2。
\end{对齐}
这表明，对数尺度上价格的一阶优化相当于相对误差的优化。上述推理是否有意义，或者是否有更简单、更优雅的方式来表达我想说的内容？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/644166/optimization-of-relative-error-vs-optimization-on-log-scale</guid>
      <pubDate>Wed, 03 Apr 2024 07:42:01 GMT</pubDate>
    </item>
    <item>
      <title>ARDL 包中的订单选择 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/644164/order-selection-in-the-ardl-package</link>
      <description><![CDATA[如何在 R 的 ARDL 包中选择正确的顺序？例如，在 dLagM 包中，您可以让包自动选择 ARDL 顺序。你能在 ARDL 包中做到这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644164/order-selection-in-the-ardl-package</guid>
      <pubDate>Wed, 03 Apr 2024 07:25:28 GMT</pubDate>
    </item>
    <item>
      <title>SVM优化目标是如何从铰链损失函数导出的？</title>
      <link>https://stats.stackexchange.com/questions/644163/how-is-the-svm-optimization-objective-derived-from-the-hinge-loss-function</link>
      <description><![CDATA[在 SVM 的背景下，铰链损失函数如下：
$$
\mathcal{L}(\mathbf{\vec w}, b\,; \mathbf{\vec x}^{(i)}, y^{(i)}) = \max(0, 1-y^ {(i)}(\mathbf{\vec w}\cdot \mathbf{\vec x}^{(i)} + b))
$$
相应的成本函数将给出为：
$$
J(\mathbf{\vec w}, b) = \frac{1}{2}\|\mathbf{\vec w}\|^{2}_{2} + C\sum_{i=1}^ {m}\max(0,1 - y ^{(i)}(\mathbf{\vec w}\cdot \mathbf{\vec x}^{(i)} + b))
$$
从这里我们可以将优化目标表述为：
$$
\min _{\mathbf{\vec w, b}} J(\mathbf{\vec w}, b) = \min _{\mathbf{\vec w}, b} \frac{1}{2}\ |\mathbf{\vec w}\|^{2}_{2} + C\sum_{i=1}^{m}\max(0, 1 - y ^{(i)}(\mathbf{\ vec w}\cdot \mathbf{\vec x}^{(i)} + b))
$$
但是，原始优化目标通常给出为：
$$
\开始{对齐}
&amp; \min _{\mathbf{\vec w}, b} \frac{1}{2} \|\mathbf{\vec w}\|^{2}_{2} \\
&amp; \text{s.t.}\; y ^{(i)}(\mathbf{\vec w} \cdot \mathbf{\vec x}^{(i)} + b) \ge 1\; \forall i\in\mathbb{N}_{m}
\结束{对齐}
$$
从这里我们可以使用拉格朗日乘子法和 KKT 条件导出双重优化目标
我的问题是上面制定的原始优化目标是如何从铰链成本函数导出的？
此外，为什么正则化常数不是原始优化目标的一部分，即使它是双重优化目标的一部分（作为约束）？]]></description>
      <guid>https://stats.stackexchange.com/questions/644163/how-is-the-svm-optimization-objective-derived-from-the-hinge-loss-function</guid>
      <pubDate>Wed, 03 Apr 2024 06:55:20 GMT</pubDate>
    </item>
    <item>
      <title>m=365 时 PM10 浓度预测的 SARIMA 模型存在问题</title>
      <link>https://stats.stackexchange.com/questions/644159/issue-with-sarima-model-for-pm10-concentration-forecasting-with-m-365</link>
      <description><![CDATA[我正在尝试构建 SARIMA（季节性自回归综合移动平均线）模型，用于根据五年的数据预测 PM10 浓度。但是，当我将季节性参数 m 设置为 365 时，我的代码似乎无法运行。
有人可以解释一下为什么我的代码没有以 m=365 运行并提出一个可能的解决方案吗？
提前致谢！
# 这是我的代码片段：
## 将数据集拆分为训练集和测试集

    `train_size = int(len(Alipur_df) * 0.8) # 80% 训练，20% 测试`
    `训练，测试 = Alipur_df[:train_size], Alipur_df[train_size:]`

## 将训练 DataFrame 转换为 numpy 数组

    `train_values = train[&#39;Alipur&#39;].values`
    `test_values = test[&#39;Alipur&#39;].values`

## 使用 auto_arima 找到 SARIMA 的最佳参数

    `auto_model = auto_arima(train[&#39;Alipur&#39;],seasonal=True,stationary=True,m=365,trac
]]></description>
      <guid>https://stats.stackexchange.com/questions/644159/issue-with-sarima-model-for-pm10-concentration-forecasting-with-m-365</guid>
      <pubDate>Wed, 03 Apr 2024 06:23:04 GMT</pubDate>
    </item>
    <item>
      <title>这是什么样的图表以及如何阅读它？</title>
      <link>https://stats.stackexchange.com/questions/644158/what-kind-of-chart-is-this-and-how-to-read-it</link>
      <description><![CDATA[我发现了这张既奇怪又有趣的图表。这是关于上述地区产生的一些文学作品。 x 轴是时间，y 轴是百分比。

前面的段落有如何阅读的提示，但我仍然迷失了。

阅读阿拉伯半岛的内容很简单，但是比如说伊拉克或伊朗呢？一个简单的演练将会有很大帮助。
这是标准图表还是作者的发明？]]></description>
      <guid>https://stats.stackexchange.com/questions/644158/what-kind-of-chart-is-this-and-how-to-read-it</guid>
      <pubDate>Wed, 03 Apr 2024 05:56:34 GMT</pubDate>
    </item>
    <item>
      <title>应该是一个关于熵的简单问题</title>
      <link>https://stats.stackexchange.com/questions/644153/supposed-to-be-a-simple-question-about-entropy</link>
      <description><![CDATA[假设有一个瓮，里面装有不同颜色的球。这是一个众所周知的计算瓮中球的熵的公式：
$H = - \sum P_i\cdot\log(P_i)$
其中 $P_i = \frac{M_i}{N}$，其中 $M_i$ 是$i^{th}$ 颜色的球的数量，N 是瓮中球的总数。
当每种颜色的球数量相同时，熵值最大；如果所有球颜色相同，则熵值为 0。
这是基本的。
现在假设我们再添加几个骨灰盒。现在如何计算熵？
直观上，如果每个瓮中每种颜色的球数量相同，则熵应该最大。
如果所有瓮都有相同数量的相同颜色的球（并且没有其他球），则熵应为 0。
在这两者之间，如果所有瓮都有相同数量的球，但每个瓮都有自己颜色的球，则存在一些熵；或者如果瓮里的球数量不是偶数或者有些瓮是空的等等。
我们可以使用上面的公式分别计算每个瓮的熵；我们可以使用类似的公式计算瓮之间的熵；我们可以尝试使用算术来组合这些熵，但我觉得一定有一个我很难弄清楚的优雅干净的公式。]]></description>
      <guid>https://stats.stackexchange.com/questions/644153/supposed-to-be-a-simple-question-about-entropy</guid>
      <pubDate>Wed, 03 Apr 2024 03:36:55 GMT</pubDate>
    </item>
    </channel>
</rss>