<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 14 Feb 2025 01:15:37 GMT</lastBuildDate>
    <item>
      <title>GAM 中的时间自相关性和季节性</title>
      <link>https://stats.stackexchange.com/questions/661354/temporal-autocorrelation-and-seasonality-in-gams</link>
      <description><![CDATA[我想检查/更好地了解如何在 GAM 中对季节性和自相关进行建模。
这是我的数据示例。

这是每月收集的计数数据，但我只想要年度趋势。请注意，此数据中只有一个站点。我想通过添加月度平滑来考虑季节性（或者可能是允许季节性跨年变化的交互，但我现在先不考虑这一点）。此外，我想考虑残差中的自相关 - 但我想有一个问题是添加月度平滑是否已经解决了这个问题？我应该同时做这两件事吗？
这是一个我很想知道的模型。
mgcv::gamm(n_days_vhe ~ s(year, bs = &quot;tp&quot;) +
s(month, bs = &quot;cc&quot;, k = 12), # 暂时保留交互作用
family = poisson(link = &quot;log&quot;),
data = .,
method = &quot;REML&quot;,
correlation = corARMA(form = ~ month, p =1))
这个模型有意义吗？
我担心我现在每年有 12 个（大部分）观测值，但模型不知道这些都来自同一个站点？我是否需要告诉它有关该分组的信息？
我需要这种相关性吗，还是可以通过月份平滑来解释？如果我确实需要它，表格应该在~月份级别吗？
感谢您的帮助！
]]></description>
      <guid>https://stats.stackexchange.com/questions/661354/temporal-autocorrelation-and-seasonality-in-gams</guid>
      <pubDate>Fri, 14 Feb 2025 00:22:46 GMT</pubDate>
    </item>
    <item>
      <title>训练 ML 模型，其中采样过程选择可能的阳性结果：卫生检查员问题</title>
      <link>https://stats.stackexchange.com/questions/661353/training-ml-models-where-sampling-process-selects-likely-positives-the-health-i</link>
      <description><![CDATA[我正在研究一个机器学习挑战，我认为这在监管/检查场景中很常见。设置如下：
假设一位卫生检查员管辖范围内有 20,000 家餐厅，但每月只能检查 30-50 家。他们自然会选择风险指标（投诉、违规历史）较高的餐厅进行检查。这会创建训练数据（约 300 次检查），其分布与整体餐厅群体非常不同。
设置：
训练数据：约 300 次检查，特意从高风险机构抽样
测试数据：需要对所有 20,000 家餐厅进行评分
功能：风险指标（离散化/分组以防止泄漏）
目标：二进制（通过/未通过检查）
目标：按风险对餐厅进行排名，以便将来进行检查
关键问题：
训练分布 ≠ 测试分布（按抽样过程设计）
来自有偏抽样的较小 n（约 300）
没有来自一般人群的标记样本
排名比绝对概率更重要
统计问题：

哪些方法可以最好地处理这种类型的故意分布偏移？

我们如何验证采样过程是否故意存在偏差？

哪些理论框架可以解决从故意存在偏差的样本中学习的问题？


有没有人遇到过类似的问题，即数据收集过程本身会产生分布偏移？基于树的模型在训练数据集上表现最佳，但我担心它们不能很好地推广到整个人群。]]></description>
      <guid>https://stats.stackexchange.com/questions/661353/training-ml-models-where-sampling-process-selects-likely-positives-the-health-i</guid>
      <pubDate>Fri, 14 Feb 2025 00:15:05 GMT</pubDate>
    </item>
    <item>
      <title>GLMM 将偏移模型与其他偏移和非偏移模型进行比较</title>
      <link>https://stats.stackexchange.com/questions/661346/glmm-comparing-offset-model-to-other-offset-and-non-offset</link>
      <description><![CDATA[我试图理解我对 GLMM 偏移项的解释以及不同偏移模型之间的进一步解释是否正确。
起点
从不同的陷阱 (Trt) 收集生物，这些陷阱在体积和开口直径等方面有所不同。
公式非偏移：
glmmTMB(Counts ~ Trt+salinity+(1|Group), family=truncated_nbinom2)

Counts 是发现的生物数量

Trt 是一个具有 5 个级别的因子变量（例如 A-E）

salinity 是一个连续的变量

Group 是一个具有 15 个级别的因子，代表 Trt 级别的重复块


在构建零截断负二项式 GLMM 并使用 emmeans 后，此模型返回每个 Trt 级别的计数平均估计值，并且可以对它们进行成对比较。
正如预期的那样，容量最大的容器包含的计数最高。
模型中的偏移量
但我也想知道计数率是否取决于体积或表面积。
因此，我在公式中添加了体积或表面积的偏移项：
glmmTMB(Counts ~ Trt+salinity+(1|Group),offset=log(Volume), family=truncated_nbinom2)
glmmTMB(Counts ~ Trt+salinity+(1|Group),offset=log(Area), family=truncated_nbinom2)
再次使用 emmeans（在 emmeans 调用中包含 offset=0），我现在可以得到每单位体积（ml）或表面积（mm²）的生物数量。
偏移比较 - 问题
查看总计数和偏移率之间的 Trt 级别的“层次结构”，以比较哪个偏移项是更好的“预测因子”，是否合理？总计数？
示例（虚构数字）：
非偏移结果：




TRT
估计




A
200


B
150


C
100


D
90


E
20




成交量偏移：




TRT
估计




A
10


B
8


C
5


E
4


D
0.5




表面偏移：




TRT
估计




E
90


D
70


C
55


B
42


A
33




如果这个比较合理，我的解释是体积比表面积更能预测。]]></description>
      <guid>https://stats.stackexchange.com/questions/661346/glmm-comparing-offset-model-to-other-offset-and-non-offset</guid>
      <pubDate>Thu, 13 Feb 2025 20:07:52 GMT</pubDate>
    </item>
    <item>
      <title>什么是“Methodenfehler nach Dahlberg”？（“根据达尔伯格的测量误差”）</title>
      <link>https://stats.stackexchange.com/questions/661344/what-is-the-methodenfehler-nach-dahlberg-measurement-error-according-to-dah</link>
      <description><![CDATA[有人问我这个问题，我不知道。但搜索后我发现了一份与此相关的博士研究清单（针对牙医）。维基百科（德语、英语）上没有答案。
有什么帮助吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661344/what-is-the-methodenfehler-nach-dahlberg-measurement-error-according-to-dah</guid>
      <pubDate>Thu, 13 Feb 2025 19:46:49 GMT</pubDate>
    </item>
    <item>
      <title>了解人们为何谎报身高（第二部分）</title>
      <link>https://stats.stackexchange.com/questions/661343/understanding-why-people-lie-about-their-height-part-2</link>
      <description><![CDATA[我感兴趣的是了解不同类型的人（例如不同年龄、不同性别、不同身高）在自我报告身高方面有何差异，以及可能存在哪些偏见。
我想象自己站在街上进行类似的实验（https://www.youtube.com/shorts/QY1TBC84UrU），我要求人们自我报告身高，测量他们的真实身高并获取一些关于他们的基本信息（例如性别、年龄）。我可以编写一个非常基本的模型：
$$d = h_r - h_t$$
$$d = \beta_0 + \beta_1h_t + \beta_2a + \beta_3g + \epsilon$$

$h_r$：报告身高
$h_t$：真实身高
$a$：年龄
$g$：性别（$g = 1$ vs $g = 0$)

我想添加以下注释：

这些是我的一些幼稚理论（建立人们如何谎报身高的统计模型）：



在许多文化中，人们认为男性身高较高更可取。因此，男性可能更有可能自我报告比实际身高更高的身高。
一般来说，身高较高的男性（即超过一定身高）可能通过自我报告比实际身高更高的身高而一无所获。
老年人可能更认为虚报身高对他们没有多大好处，因此可能更诚实



在这种情况下，我的数据很可能包含更多特定类型的人口统计数据（例如男性大学生）。

我如何才能让我的统计模型考虑到我对身高报告的幼稚理论以及某些人口统计数据在数据中得到更多反映的事实？。对于第一点，我认为贝叶斯方法可能会有用。对于第二点，我读过一些称为 Heckman 选择模型的内容，它可能与此相关。]]></description>
      <guid>https://stats.stackexchange.com/questions/661343/understanding-why-people-lie-about-their-height-part-2</guid>
      <pubDate>Thu, 13 Feb 2025 19:41:26 GMT</pubDate>
    </item>
    <item>
      <title>确定验证伯努利过程成功概率的样本量</title>
      <link>https://stats.stackexchange.com/questions/661341/determine-sample-size-for-validating-success-probability-of-bernoulli-process</link>
      <description><![CDATA[假设生产产品的过程具有某个恒定的缺陷率$d$，我想估计最小样本量$n$，以大于或等于$\alpha$的概率确认缺陷率低于某个临界阈值$d_c$。
就我而言，$d_c = 10^{-6}$。
我考虑使用伯努利过程对此进行建模。
使用 Hoeffding 不等式，误差幅度为 $2 \times 10^{-6}$ 和 $\alpha = 0.95$，我计算出我需要 $676385$ 个样本。
我还考虑过通过求解 $P(X \leq k) \geq \alpha$ 来对其进行建模，其中 $k = 1, p = 10^{-6}$ 为 $n$ 并得到大约 100 万（以及一些收敛问题）。
这些结果是否有效？它们是解决这个问题的最佳方法吗？我也考虑过使用功效分析，但我对备择假设是不同的固定概率而不是大于$d_c$的概率感到有些困惑。
鉴于到目前为止的所有结果都导致非常大的样本量（考虑到$d_c = 10^{-6}$，这在某种程度上是可以预料到的），这在行业中通常是如何做到的？测试数十万种产品似乎不可行。]]></description>
      <guid>https://stats.stackexchange.com/questions/661341/determine-sample-size-for-validating-success-probability-of-bernoulli-process</guid>
      <pubDate>Thu, 13 Feb 2025 18:55:18 GMT</pubDate>
    </item>
    <item>
      <title>请帮助我理解引导法在讨论结果中的用途</title>
      <link>https://stats.stackexchange.com/questions/661339/please-help-me-understand-the-use-of-bootstrapping-in-discussing-results</link>
      <description><![CDATA[我想请您帮忙，因为我的硕士论文进展不顺，而我的导师几乎没有时间陪我。我不明白在推理数据时如何使用引导重采样方法。
长话短说：我有循环数据（时间）的样本，我正在比较它们之间的重叠，从而得到一个指数。然后我对原始数据进行引导以获得 95% 的置信区间（以及使用引导数据获得的相同指数）。然后我计算了第 25、50 和 75 个百分位数（来自原始数据）来对获得的指数进行排序。
我的问题是：我应该使用“引导指数”来计算百分位数，并围绕所述引导指数进行排名和推理来讨论我的结果，还是应该坚持使用原始数据中的指数？
如果这听起来令人困惑，请告诉我，我会尽力解释得更好😊]]></description>
      <guid>https://stats.stackexchange.com/questions/661339/please-help-me-understand-the-use-of-bootstrapping-in-discussing-results</guid>
      <pubDate>Thu, 13 Feb 2025 17:44:24 GMT</pubDate>
    </item>
    <item>
      <title>两项指标增长率</title>
      <link>https://stats.stackexchange.com/questions/661338/growth-rate-of-two-indexes</link>
      <description><![CDATA[我有两个指数化的年度时间序列（消费者价格指数和平均工资指数）。
我的目标是获得这两个指数的加权增长率（每年），其中 40% 分配给消费者价格指数，60% 分配给平均工资指数。
我有两种潜在的计算方法：

简单地加权增长率并将它们相加，

加权相应的指数，然后计算增长率。


两种方法产生可比但不同的结果。
哪种方法是正确的/优于另一种方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/661338/growth-rate-of-two-indexes</guid>
      <pubDate>Thu, 13 Feb 2025 17:12:44 GMT</pubDate>
    </item>
    <item>
      <title>为不规则时间序列数据创建因果 DAG</title>
      <link>https://stats.stackexchange.com/questions/661337/creating-a-causal-dag-for-irregular-time-series-data</link>
      <description><![CDATA[我喜欢使用动态贝叶斯网络构建因果结构的想法，但不确定如何处理采样分辨率不规则的时间序列数据。具体来说，在有 2 支球队的运动场景中，数据是逐个事件的数据，这些事件（例如传球）从比赛开始到结束按顺序发生。最终，我想探索这些数据中干预的因果效应。
有人建议使用 SSM。据我所知，当它被离散化时，它可以表示为 DAG？然后我有一个结构来表示这些因果关系。
其他工作流程可能是：

此库：https://github.com/jakobrunge/tigramite

使用 ARIMA 消除时间序列数据的趋势，然后使用某种贝叶斯推理来捕获因果效应

使用 SSM 创建因果结构和贝叶斯推理来捕获因果效应

利用 CausalImpact 库

还有 GSP，然后使用图形信号作为因果模型（如 BART）的输入


虽然我建议使用 2 个库，我喜欢制定适当的因果工作流程，而不是让库做所有事情。这样我才能更好地理解因果推理。
我最初偶然发现了这篇有趣的论文：https://arxiv.org/pdf/2312.09604，它似乎不适用于不规则的采样分辨率。
还有对时间序列数据的分组，这会导致信息丢失。因果关系不会立即发生在这些数据中，因此将其分组为半秒或一秒可能会起作用。
我对因果推理还很陌生，所以欢迎任何批评或建议！
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661337/creating-a-causal-dag-for-irregular-time-series-data</guid>
      <pubDate>Thu, 13 Feb 2025 16:43:29 GMT</pubDate>
    </item>
    <item>
      <title>将高斯分布转换为不同的均值和协方差</title>
      <link>https://stats.stackexchange.com/questions/661330/transforming-a-gaussian-to-a-different-mean-and-covariance</link>
      <description><![CDATA[假设我有大量从高斯分布中抽取的样本$x_1 \sim\mathcal{N}(\mu_1, \Sigma_1)$。如果给我另一组参数$\mu_2$，$\Sigma_2$，我该如何将$x_1$转换为新的均值和协方差？
$x_1 - \mu_1 + \mu_2$会将均值转移到新的均值，但我对如何改变协方差有点困惑。
我脑海中浮现的可能是这样的：$x_1 - \mu_1$将分布转移到$\mathcal{N}(0, \Sigma_1)$。然后我们使用$\Sigma_1$计算白化变换，将数据转换为$\mathcal{N}(0, I)$。
最后，使用$\Sigma_2$以某种方式旋转/缩放数据。我对这一步有点困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/661330/transforming-a-gaussian-to-a-different-mean-and-covariance</guid>
      <pubDate>Thu, 13 Feb 2025 15:33:48 GMT</pubDate>
    </item>
    <item>
      <title>混合变量的多维尺度分析</title>
      <link>https://stats.stackexchange.com/questions/661321/multidimensional-scaling-for-mixed-variables</link>
      <description><![CDATA[我对以下问题感兴趣；假设我有一堆连续变量和分类变量。我希望通过考虑核函数来计算我的观察结果之间的差异。在这种情况下，为了简单起见，假设 $\boldsymbol{x} = (x^{cont}, x^{cat})^\intercal$，这样第一个组件就是连续变量的实现，第二个组件只取从 1 到 $\ell$ 的值，其中 $\ell$ 是这个分类变量的级别数。设两点$\boldsymbol{x}_1,\boldsymbol{x}_2$之间的相似度定义为$\delta(\boldsymbol{x}_1,\boldsymbol{x}_2) = \exp\left(-\frac{(x_1^{cont}-x_2^{cont})^2}{2\lambda^2}\right) + k^{cat}(x_1^{cat}, x_2^{cat})$，其中分类核$k^{cat}$定义为当$x_1^{cat}= x_2^{cat}$时等于正值$1-c$，否则等于 $c/(\ell-1)$（这实际上是 Aitchison-Aitken 核）。
现在我的问题是：如果我有这些差异，我显然不能使用经典多维缩放，但我不确定是否可以使用度量 MDS，或者我是否应该直接使用非度量 MDS。我在某处读到，如果我使用“欧几里得距离”，只要我的内核是正定的（这里就是这种情况），就可以做到这一点，然后我可以定义一个距离度量，如$d(\boldsymbol{x}, \boldsymbol{y}) = \sqrt{\delta(\boldsymbol{x},\boldsymbol{x}) + \delta(\boldsymbol{y},\boldsymbol{y}) - 2\delta(\boldsymbol{x},\boldsymbol{y})}$，它将是欧几里得的，所以在这种情况下我可以使用度量 MDS。但是，出于某种原因，我觉得这是错误的，我认为非度量 MDS 可能更可取。我在这里遗漏了什么？有人可以提供一些关于这个主题的更多见解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661321/multidimensional-scaling-for-mixed-variables</guid>
      <pubDate>Thu, 13 Feb 2025 12:23:50 GMT</pubDate>
    </item>
    <item>
      <title>输出概率的排名机器学习模型</title>
      <link>https://stats.stackexchange.com/questions/661285/machine-learning-model-for-ranking-that-outputs-probabilities</link>
      <description><![CDATA[传统上，用于排名的 ML 算法将特征作为输入，然后输出不具有自然概率解释的“相关性分数”。
例如，假设我们有三台笔记本电脑：“macbookAir”、“macbookPro”、“msSurface”，以及一堆客户偏好作为数据，并将其传递给 XGBoostRanker 等 ML 算法，然后它会为三台笔记本电脑中的每一台输出一个分数，得分最高的笔记本电脑就是客户最有可能购买的笔记本电脑。
我正在尝试识别一种输出排名概率的 ML 技术。即它输出
p_123 = P(&quot;macbookAir&quot; &lt; &quot;macbookPro&quot; &lt; &quot;msSurface&quot;)
p_132 = P(&quot;macbookAir&quot; &lt; &quot;msSurface&quot; &lt; &quot;macbookPro&quot;)
p_213 = P(&quot;macbookPro&quot; &lt; &quot;macbookAir&quot; &lt; &quot;msSurface&quot;)
p_231 = P(&quot;macbookPro&quot; &lt; &quot;msSurface&quot; &lt; &quot;macbookAir&quot;)
p_312 = P(&quot;msSurface&lt; &lt; &quot;macbookAir&quot; &lt; &quot;macbookPro&quot;)
p_321 = P(&quot;msSurface&quot; &lt; &lt; &quot;macbookPro&quot; &lt; &quot;macbookAir&quot;)
这样 p_123+p_132+p_213+p_231+p_312+p_321=1
我想问一下是否有任何 ML 算法可以做到这一点？如果没有，是否有任何方法可以将排名算法（例如 XGboost 排名器）的得分转换为上述排名概率？
在我最初的问题中，有许多不同的类别。我理解随着类别数量 n 的增加，难度会呈指数级增长，可能会有 n！种排名。但在我的问题中，我只关心前几个类别。所以我想问一下，至少存在一个 top-k 排名概率，我们可以预测概率 P(A&gt;B&gt;others)，从而降低难度。
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/661285/machine-learning-model-for-ranking-that-outputs-probabilities</guid>
      <pubDate>Wed, 12 Feb 2025 17:48:36 GMT</pubDate>
    </item>
    <item>
      <title>当 $\mathbf{X}'\mathbf{X}$“几乎不是一个单位相关矩阵”时，最小二乘法的性能较差，Hoerl 和 Kennard (1970)</title>
      <link>https://stats.stackexchange.com/questions/661240/poor-performance-of-least-squares-when-mathbfx-mathbfx-is-not-nearly-a</link>
      <description><![CDATA[上下文。
在 Hoerl 和 Kennard (1970) 所著的《岭回归：非正交问题的有偏估计》中，作者反复使用以下观察来激发对岭回归估计量的行为和属性的分析研究。从第 0 节：简介开始，

对于未知的 $\boldsymbol{\beta}$，通常的估计程序是高斯-马尔可夫——$\mathbf{Y} = \{y_v\}$ 的线性函数，这些函数无偏且方差最小。如果 $\mathbf{X}&#39;\mathbf{X}$ 为相关矩阵形式，且接近单位矩阵，则此估计程序是有效的。但是，如果 $\mathbf{X}&#39;\mathbf{X}$ 不接近单位矩阵，则最小二乘估计会受到许多“误差”的影响。当规范为$\mathbf{X} \boldsymbol{\beta}$是一个真实模型时，这些误差的结果至关重要。

在第 1 节：Brst 线性无偏估计的性质和第 3a 节：岭迹的定义中可以进一步找到相同的表述“$(\mathbf{X}&#39;\mathbf{X})$，当写为相关矩阵时，几乎不是一个单位矩阵&quot;。
在我读过的几乎所有关于岭回归估计量的现代介绍中，例如 Hastie 等人的论文。 （2010），它们都没有用“单位相关矩阵”的语言来表达。
相反，现代的表达方式倾向于将岭回归估计量作为用偏差换取方差减少的手段。更具体地说，通过分析最小二乘估计量$\sigma^2 (\mathbf{X}&#39;\mathbf{X})^{-1}$的方差何时可以通过$(\mathbf{X}&#39;\mathbf{X})^{-1}$的特征分解或奇异值分析“爆炸”。
问题。
1.有人能用论据澄清一下这里到底是什么意思吗？
2.这个单位相关矩阵论证是否与我们对误差$\mathbb{E}[\mathbf{e}\mathbf{e}&#39;] = \sigma^2I$的假设有关，即$\mathbf{Y}$上的各向同性协方差矩阵$\sigma^2I$？$^{[1]}$
$^{[1]}$从某种意义上说，最小二乘估计量对于我们关于误差具有各向同性协方差的建模假设的错误指定不具有鲁棒性？*

相关问题。
MathStackexchange 上也问过这个问题：
https://math.stackexchange.com/questions/2340791/ridge-regression-unit-matrix-hoerl-and-kennard-1970]]></description>
      <guid>https://stats.stackexchange.com/questions/661240/poor-performance-of-least-squares-when-mathbfx-mathbfx-is-not-nearly-a</guid>
      <pubDate>Tue, 11 Feb 2025 18:54:49 GMT</pubDate>
    </item>
    <item>
      <title>如何在 scikit learn 中模拟 R 的 selectNcomp？</title>
      <link>https://stats.stackexchange.com/questions/661232/how-might-i-emulate-rs-selectncomp-in-scikit-learn</link>
      <description><![CDATA[R 的 mvr 包有一个实用函数 selectNcomp，可通过实施启发式标准误差规则自动选择交叉验证 PLS 模型中的保留潜变量：
“方法“onesigma”仅返回最佳 CV 在绝对最佳值的一个标准误差范围内的第一个模型（Hastie、Tibshirani 和 Friedman，2009 年）。请注意，这里我们仅使用交叉验证残差的标准偏差，与用于计算误差测量本身的程序一致”
如何在 Python 中模仿此功能？从我的 SKlearn 网格搜索中，我可以获得验证所有折叠中每个选定潜变量的平均 RMSE，以及所有折叠的相关标准偏差，但我不确定如何/是否可以根据此信息计算标准误差，或者它是否确实与仅使用标准偏差作为限制有显著不同。
我不一定要求特定的编程指针，只是要求了解底层统计数据以及是否可以使用等效指标。这似乎更适合在这里问。
谢谢。
Hastie, T., Friedman, J. 和 Tibshirani, R. 统计学习要素：数据挖掘、推理和预测，Springer (2013)，第 10 次印刷，带更正，第 7.10 段。]]></description>
      <guid>https://stats.stackexchange.com/questions/661232/how-might-i-emulate-rs-selectncomp-in-scikit-learn</guid>
      <pubDate>Tue, 11 Feb 2025 15:21:13 GMT</pubDate>
    </item>
    <item>
      <title>分层 Cox 模型：为什么重采样数据的 C 指数比明显的 C 指数（tidymodels 和审查的 R 包）更好？</title>
      <link>https://stats.stackexchange.com/questions/661185/stratified-cox-model-why-is-c-index-on-resampled-data-better-than-apparent-c-in</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/661185/stratified-cox-model-why-is-c-index-on-resampled-data-better-than-apparent-c-in</guid>
      <pubDate>Mon, 10 Feb 2025 07:53:22 GMT</pubDate>
    </item>
    </channel>
</rss>