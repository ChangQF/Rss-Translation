<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 11 Apr 2024 18:16:39 GMT</lastBuildDate>
    <item>
      <title>在混合效应模型中，忽略截距斜率相关参数是否会导致 I 类误差增大？</title>
      <link>https://stats.stackexchange.com/questions/644822/in-a-mixed-effects-model-can-leaving-out-the-intercept-slope-correlation-parame</link>
      <description><![CDATA[我正在考虑在混合效应模型中省略截距斜率相关参数，以避免收敛问题（即，在 nlme::lme 中，random = list(~1|individual , ~0+时间|个人))。
“安全”吗？这样做的意义是不会导致相关固定斜率的 I 类错误概率夸大？
我已经为自己运行了一些模拟，看看完全忽略随机斜率（random = ~1|individual）肯定会增加错误发现的机会，但我没有信心关于使用模拟来检查相关性，因为完整模型 (random=~time|individual) 对于我的模拟数据经常无法收敛。
这个问题对于理解省略相关参数的含义有很大帮助，但它并没有解决 I 类错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/644822/in-a-mixed-effects-model-can-leaving-out-the-intercept-slope-correlation-parame</guid>
      <pubDate>Thu, 11 Apr 2024 18:09:06 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的 abc 包进行近似贝叶斯计算的不准确估计</title>
      <link>https://stats.stackexchange.com/questions/644821/inaccurate-estimates-with-approximate-bayesian-computation-using-the-abc-package</link>
      <description><![CDATA[我正在尝试使用近似贝叶斯计算（ABC）来校准参数，以获得接近文献中观察值的模型输出变量。为此，我使用 abc 包。
第一步，我使用 cv4abc 函数测试容差率选择对 ABC 估计值的影响。然而，结果表明，估计值并不准确，因为它们与真实值相差很大。我测试了几种类型的 ABC 算法（rejection、loclinear 和 neuralnet）和转换（none 和 &lt;代码&gt;日志）。我的代码可能做错了什么。因此，我们将非常感谢您提供任何帮助来了解导致估计不准确的原因。
这是我的数据集
文献中观察到的响应变量的范围是：min = 0.5，max = 2.5，mean = 1.5。
数据集中的模拟汇总统计数据为：simulated_rmse。对于数据集的每一行，我计算了模拟数据（列=“simulated_response”）和文献中观测值（即 1.5）之间的 RMSE。
数据集中要估计的模拟参数为：param_1 至 param_20。
观察到的汇总统计数据为 0（即 RMSE = 0）
以下是使用“拒绝”方法和“无”转换的参数图示例：

这是我的代码：
&lt;前&gt;&lt;代码&gt;库(abc)

数据 &lt;- read.csv(“C:/Users/Downloads/Test.csv”)
## 摘要（数据）

## 观察到的汇总统计数据
Observed_summary_statistics &lt;- 0

## 模拟汇总统计
Simulated_summary_statistics &lt;- data[, c(“simulated_RMSE”)]
## 摘要(simulated_summary_statistics)

## 模拟参数值
Simulated_pa​​rameters &lt;- data[, !(colnames(data) %in% c(“simulated_response”, “simulated_RMSE”))]
## 摘要（模拟参数）

## 运行“cv4abc” “abc”的函数包裹
cv_abc_rejection &lt;- abc::cv4abc(param=simulated_pa​​rameters, sumstat=simulated_summary_statistics, nval=100, tols=c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1), method=“拒绝”, transf=“ ;无”)
## 情节（cv_abc_rejection）
## 摘要(cv_abc_rejection)

cv_abc_rejection_log &lt;- abc::cv4abc(param =simulated_pa​​rameters, sumstat =simulated_summary_statistics, nval = 100, tols = c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1), method = “拒绝”, transf = “ ;日志”）
## 情节（cv_abc_rejection_log）
## 摘要(cv_abc_rejection_log)

cv_abc_loclinear &lt;- abc::cv4abc(param =simulated_pa​​rameters, sumstat =simulated_summary_statistics, nval = 100, tols = c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1), method = “loclinear”, transf = “ ;无”)
## 绘图（cv_abc_loclinear）
## 摘要(cv_abc_loclinear)

cv_abc_loclinear_log &lt;- abc::cv4abc(param =simulated_pa​​rameters, sumstat =simulated_summary_statistics, nval = 100, tols = c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1), method = “loclinear”, transf = “ ;日志”）
## 绘图（cv_abc_loclinear_log）
## 摘要(cv_abc_loclinear_log)

cv_abc_neuralnet &lt;- abc::cv4abc(param=simulated_pa​​rameters, sumstat=simulated_summary_statistics, nval=100, tols=c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1), method=“neuralnet”, transf=“ ;无”)
## 绘图（cv_abc_neuralnet）
## 摘要(cv_abc_neuralnet)

cv_abc_neuralnet_log &lt;- abc::cv4abc(param=simulated_pa​​rameters, sumstat=simulated_summary_statistics, nval=100, tols=c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1), method=“neuralnet”, transf=“ ;日志”）
## 绘图（cv_abc_neuralnet_log）
## 摘要(cv_abc_neuralnet_log)
]]></description>
      <guid>https://stats.stackexchange.com/questions/644821/inaccurate-estimates-with-approximate-bayesian-computation-using-the-abc-package</guid>
      <pubDate>Thu, 11 Apr 2024 18:02:42 GMT</pubDate>
    </item>
    <item>
      <title>马尔可夫决策过程中，如何理解剧集平均长度的计算？</title>
      <link>https://stats.stackexchange.com/questions/644820/in-markov-decision-process-how-to-understand-the-calculation-of-the-average-len</link>
      <description><![CDATA[在Sec。 RL: An Introduction (Sutton &amp; Barto)的13.2，平均剧集长度的概念是针对情景 MDP 和持续 MDP 进行了讨论。
在情景 MDP 中，情景的平均长度可以计算为策略 $\pi$ 下状态的平稳分布之和，表示为 &lt; span class=&quot;math-container&quot;&gt;$\sum_{s}d^{\pi}(s)$。在连续的MDP中，平均情节长度被定义为1。如何理解这两种情况下平均长度的计算？]]></description>
      <guid>https://stats.stackexchange.com/questions/644820/in-markov-decision-process-how-to-understand-the-calculation-of-the-average-len</guid>
      <pubDate>Thu, 11 Apr 2024 17:38:14 GMT</pubDate>
    </item>
    <item>
      <title>根据 Log 10 转换模型数据对预测 Y 进行反向转换</title>
      <link>https://stats.stackexchange.com/questions/644819/back-transformation-of-predicted-y-from-log-10-transformed-model-data</link>
      <description><![CDATA[我正在 Minitab 中使用一般线性模型进行分析。
我有两个问题。
我有两个响应变量，我使用 Log10 对其进行了转换，因为有一些正态性和顺序问题的残差图的证据，并且转换似乎很好地改善了这一点。 （我之前在这里得到过一些建议，非常感谢）
根据所有这些，我对 Log10 转换后的响应进行了分析，以获取有关各种因素的重要性和交叉效应等的一些详细信息。我还使用回归方程来预测 Y 值。现在，这些预测的 Y 值当然可以轻松地与变换后的 Y 值进行比较。但是对于这一部分我有疑问。

我对预测 Y 值进行反向变换（Minitab 中的反对数）有什么问题，即，为了将它们与原始未变换均值进行比较，作为评论 Y 值的方式，预测均值各种相关因素的模型？
这是否合法，因为我在某处读到，将原始算术平均值与我认为所谓的几何平均值进行比较存在问题，是否有直接的解决方法？
有人可以参考这方面的书籍或论文吗？
如果我想报告这些标准错误，我该如何进行反向转换？
]]></description>
      <guid>https://stats.stackexchange.com/questions/644819/back-transformation-of-predicted-y-from-log-10-transformed-model-data</guid>
      <pubDate>Thu, 11 Apr 2024 17:24:17 GMT</pubDate>
    </item>
    <item>
      <title>求前 k 个特征向量在空间上的投影</title>
      <link>https://stats.stackexchange.com/questions/644818/finding-the-projection-on-the-space-of-the-first-k-eigenvectors</link>
      <description><![CDATA[我有 100 个维度为 n 的向量。
我想找到它们在前 2 个特征向量生成的空间上的投影。
但我需要表达前 100 个向量的投影。
假设我已经计算了 2 个特征向量 PC1 和 PC2。
如何获取 PC1 和 PC2 生成的空间上的投影？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644818/finding-the-projection-on-the-space-of-the-first-k-eigenvectors</guid>
      <pubDate>Thu, 11 Apr 2024 17:00:40 GMT</pubDate>
    </item>
    <item>
      <title>当预测变量值按组平均时，使用随机森林是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/644816/does-it-make-sense-to-use-random-forest-when-predictor-values-are-averaged-by-gr</link>
      <description><![CDATA[简而言之：当预测变量按样本组进行平均时，使用随机森林来分析预测变量的重要性是否有意义？
我正在开展一个生态数据分析项目，涉及多个岛屿（150 个观测值，5 个岛屿）土壤细菌丰富度的多样性。然而，由于我们采样方法的限制，我们的预测变量（例如 pH 值）是对每个岛屿的样本进行平均，这意味着我有每个岛屿一个 pH 值和 50 个细菌丰富度值（每个岛屿的观察数量不平衡）岛）。
我希望使用随机森林 (RF) 来确定影响岛屿间细菌多样性的关键预测变量，但我不确定每个岛屿的平均预测变量是否会影响模型的有效性或可解释性。 RF 在这里仍然有效吗？平均预测变量是否需要进行任何调整？
注意：另一种选择是平均细菌丰富度并执行线性回归，但由于随机森林可以更“自然”地捕获非线性关系和相互作用。 （并且不假设线性模型限制），我想给这种方法一个机会。]]></description>
      <guid>https://stats.stackexchange.com/questions/644816/does-it-make-sense-to-use-random-forest-when-predictor-values-are-averaged-by-gr</guid>
      <pubDate>Thu, 11 Apr 2024 16:42:26 GMT</pubDate>
    </item>
    <item>
      <title>线性回归模型中置信区间的计算 - 正常还是学生？</title>
      <link>https://stats.stackexchange.com/questions/644814/calculation-of-confidence-intervals-in-linear-regression-model-normal-or-stude</link>
      <description><![CDATA[我正在使用一个非常简单的线性回归模型，其中要求我使用置信区间而不是 p 值（经典）
问题是我正在尝试两种方法来获得置信区间，这两种方法都在多个地方报告了
confint 函数使用学生 t 分布计算回归模型系数的置信区间。这些置信区间是不对称的，并且基于模型系数标准差的估计。
confint 函数使用学生 t 分布计算回归模型系数的置信区间。这些置信区间是不对称的，并且基于模型系数标准差的估计。
另一方面，get_CI 函数是一个手动函数，创建了 ad_hoc，通过将系数的标准误差乘以 1.96 来计算置信区间，这是对应于 95% 置信度的临界值标准正态分布中的水平。这基于模型系数正态分布的假设提供了对称且近似的置信区间。
我主要了解不同计算（std dev 或标准错误）的起源，但我看不到为什么我应该选择一个而不是另一个的原因，或者它们之间是否存在很大差异（就我而言，间隔几乎相同）
get_CI &lt;- 函数（模型）{
  摘要_模型 &lt;- 摘要（模型）
  df &lt;-summary_model$df[1]
  t_值 &lt;- qt(1 - 0.05/2, df)
  coeffs &lt;-summary_model$coefficients[, 1]
  se &lt;-summary_model$coefficients[, 2]
  下 &lt;- coeffs - t_value * se
  upper &lt;- coeffs + t_value * se
  CI &lt;- cbind(下、上)
  行名称(CI) &lt;- 行名称(summary_model$coefficients)
  回报（CI）
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/644814/calculation-of-confidence-intervals-in-linear-regression-model-normal-or-stude</guid>
      <pubDate>Thu, 11 Apr 2024 15:45:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么 MTSC 的 FCN 末尾的 GAP 有效？</title>
      <link>https://stats.stackexchange.com/questions/644809/why-does-gap-at-the-end-of-fcn-for-mtsc-work</link>
      <description><![CDATA[我有一个二元 MTSC（多元时间序列分类）问题，我训练 CNN，即 FCN（或全卷积网络）来根据多元时间序列预测 0 类或 1 类。 MTS 包含 57 个不同的特征，长度均为 24，从而形成一个 57 x 24 的数组。
我从这篇论文中获得了灵感，他们使用了 128 的 3 卷积堆栈，分别有 256 和 128 个滤波器，并以 GAP 层（全局平均池化）结束。
转发的工作原理如下：包含 57、24 个长系列的 57 x 24 数组经过排列，以便特征作为通道进入第一层。创建 128 个 1d 特征图，其中 256 个新特征图，然后是 128 个最终特征图。这会产生一个 128 x 24 的数组。应用 GAP 层，通过取均值在第二维上缩小数组，并返回 128 长的向量。然后将该向量输入到全连接层，该层通过 sigmoid 函数进行预测。
我的问题是：为什么在网络末端放置 GAP 层会起作用？它背后的逻辑/直觉是什么？我无法理解它。]]></description>
      <guid>https://stats.stackexchange.com/questions/644809/why-does-gap-at-the-end-of-fcn-for-mtsc-work</guid>
      <pubDate>Thu, 11 Apr 2024 15:10:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么选择术语“显着性”($a$) 来表示 I 类错误的概率？</title>
      <link>https://stats.stackexchange.com/questions/644808/why-was-the-term-signifiance-a-chosen-for-the-probability-of-type-i-error</link>
      <description><![CDATA[我目前正在学习“统计 1”作为我计算机科学学位的一部分，我很难理解“重要性”的概念。
我们获得了以下定义：
$H_0$ - 零假设
$H_1$ - 替代假设。
$R$ - $H_0$ 拒绝区
$\bar{R}$ - $H_0$ 无拒绝区
$\begin{对齐} \alpha &amp;= P(\text{I 型错误})\\&amp;=P_{H_0}(\text{拒绝 } H_0 ) \\&amp;= P_{H_0}(X\in R) \\&amp;; \end{对齐} $
虽然我相信我已经很好地掌握了这些定义以及它们与 p 值的关系，但术语“显着性”并不适用。我仍然感到困惑。
我理解某事物“具有统计显着性”的概念，但显着性水平越高，出错的风险就越大，这似乎违反直觉。直觉上，当某件事非常重要时，我预计风险会较低。
有人可以解释一下为什么“重要性”一词如此重要吗？被选中了？
对于那些正在寻找的人来说，这些是关于这些术语的统计含义的一些非常好的讨论。我正在寻找更直观的解释来解释为什么选择这个术语。
比较和对比，p -值、显着性水平和 I 类错误
显着性水平 alpha 与 1 类误差 alpha 之间的关系是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644808/why-was-the-term-signifiance-a-chosen-for-the-probability-of-type-i-error</guid>
      <pubDate>Thu, 11 Apr 2024 15:02:37 GMT</pubDate>
    </item>
    <item>
      <title>Mplus 如何使用 WLSMV 估计器处理缺失数据？</title>
      <link>https://stats.stackexchange.com/questions/644807/how-does-mplus-handle-missing-data-with-the-wlsmv-estimator</link>
      <description><![CDATA[我正在 Mplus 中使用 WLSMV 估计器，并且有缺失值。我指定了“type = wlsmv”并将缺失值编码为-99。当“TYPE=COMPLEX”时和WLSMV估计器，WLSMV如何处理Mplus中的缺失值？我读过几篇论文，其中一些提到 WLSMV 的默认选项作为成对存在/成对删除方法。这准确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644807/how-does-mplus-handle-missing-data-with-the-wlsmv-estimator</guid>
      <pubDate>Thu, 11 Apr 2024 14:42:03 GMT</pubDate>
    </item>
    <item>
      <title>RCT 中的组内差异与组间差异：如何处理？</title>
      <link>https://stats.stackexchange.com/questions/644806/within-group-vs-between-group-variance-in-an-rct-how-to-handle</link>
      <description><![CDATA[我有一个问题，当随机对照试验中组内方差与组间方差存在明显差异时，朴素治疗效果估计器可能会出错多远，以及我们实际上可以采取什么措施。
我正在进行一项实验，组内方差明显大于组间方差。为了给出一些数字，我们试图看看*组之间是否有 ~$2，但*组内*组方差是否为 ~$20。由于一系列操作原因，我无能为力来改变这一点。
问题在于，各组中的实验前差异可能已经达到 ~$1 或 ~$2。在这种情况下，我该如何估计治疗效果（组间差异）？
进行 RCT 时，治疗效果始终是治疗组和对照组之间的简单差异：
$$ \Delta_{ATE} = \frac{1}{n_T}\sum_{i\in n_T}Y_{i} - \frac{1}{n_C} \sum_{i\in n_C}Y_{i}$$
我们可以使用实验前的差异来提高此估计的精度（降低标准误差），但从根本上来说我们无法改变估计。
为了验证这一点，我模拟了简单差异、CUPED、差异中的差异、协方差的潜在分析和变化分析估计器。我发现，在预期中，估计量都具有相同的值（简单差异），但当基本上不存在组内方差时，它们的标准误差有所不同。当组间存在一些方差时，所有这些估计量都具有相同的标准误差。
这是正确的吗？在这种情况下是否有首选估计器，或者我无法做比简单差异更好的事情？会例如面板数据模型帮助（我对这些不太了解）？另外，未来这个案例的样本量指南是多少，我们目前一直在使用 Lehr 规则：
$$ N = 16\frac{\sigma^2}{\Delta^2}$$
估计样本大小。


我使用以下函数生成了数据：
导入 pandas 作为 pd
将 numpy 导入为 np
将seaborn导入为sns

defgenerate_data_v2(alpha, beta, gamma, delta, rng, Between_variation, N, seeds=42):
# 个人
我 = 范围(1, N+1)

# 治疗状态
d = rng.二项式(1, 0.5, N)

# 个体结果预处理
# 治疗前结果的产生具有一定的基本变化水平
y0 = alpha + beta*d + rng.normal(0, 1, N)

# 修改治疗后结果以纳入 Between_variation 控制
# 这将确保跨单元的处理后变化由 Between_variation 参数驱动
y1 = y0 + gamma + delta*d + rng.normal(0, Between_variation, N) * d # 放大处理单位的变异

# 生成数据帧
df = pd.DataFrame({&#39;i&#39;: i, &#39;ad_campaign&#39;: d, &#39;revenue0&#39;: y0, &#39;revenue1&#39;: y1})

返回df

df =generate_data_v2(alpha, beta, gamma, delta, rng, Between_variation=5, N=100)

results_no_group_var = 模拟（
    func=generate_data_v2, # 你的数据生成函数
    func_args={
        “阿尔法”：阿尔法，
        &#39;贝塔&#39;：贝塔，
        ‘伽玛’：伽玛，
        “增量”：0.0，
        &#39;rng&#39;：rng，
        “N”：N，
    &#39;变化之间&#39;：1，
    },
    K=K,
    x=&#39;收入0&#39;
）

results_group_var = 模拟（
    func=generate_data_v2, # 你的数据生成函数
    func_args={
        “阿尔法”：阿尔法，
        &#39;贝塔&#39;：贝塔，
        ‘伽玛’：伽玛，
        “增量”：0.0，
        &#39;rng&#39;：rng，
        “N”：N，
    &#39;变化之间&#39;：5，
    },
    K=K,
    x=&#39;收入0&#39;
）

sns.kdeplot(data=结果，x=“估计”，hue=“估计器”);
plt.title(&#39;模拟分布&#39;);
]]></description>
      <guid>https://stats.stackexchange.com/questions/644806/within-group-vs-between-group-variance-in-an-rct-how-to-handle</guid>
      <pubDate>Thu, 11 Apr 2024 14:38:13 GMT</pubDate>
    </item>
    <item>
      <title>发现数据中的自然分组结构</title>
      <link>https://stats.stackexchange.com/questions/644805/discovering-a-natural-grouping-structure-in-data</link>
      <description><![CDATA[我正在寻找使用稀疏组套索应用一些数据。此方法要求变量位于组内，因此我需要将组标签传递给模型。是否有一种有效的方法将变量分组？我研究过 kmeans 聚类，但我的数据集很大，因此我只能查看最多 10 个聚类左右，这在分组结构中粒度不够。
我看过一篇应用奇异值分解的论文，但我不确定它如何生成分组结构。]]></description>
      <guid>https://stats.stackexchange.com/questions/644805/discovering-a-natural-grouping-structure-in-data</guid>
      <pubDate>Thu, 11 Apr 2024 14:38:02 GMT</pubDate>
    </item>
    <item>
      <title>OLS 回归的此应用程序的名称/术语是什么</title>
      <link>https://stats.stackexchange.com/questions/644803/what-is-the-name-terminology-for-this-application-of-ols-regression</link>
      <description><![CDATA[我没有统计背景，并被指示按照以下步骤填写缺失的数据。我想知道这个特定方法是否有一个名称，以便我可以了解更多它及其假设。
给定来自与感兴趣的站点距离不同的多个站点的数据集。每个站的数据集的完整性各不相同。通过应用 OLS 回归预测缺失值，估算感兴趣站的缺失数据。使用 OLS 回归优于其他模型的动机是为了“简单性”

按照邻近的顺序遍历站点（因为较近的站点可能与兴趣点具有更强的相关性）

在每次迭代中，使用所选站点作为预测数据集 (X) 和感兴趣的站点作为目标数据集 (y) 创建 OLS 模型。使用模型来估算缺失的目标值。


通过对每个站点数据集执行指定的过程，应该会为感兴趣的站点创建一个扩展且更完整的数据集

这是应用 OLS 回归的有效方法吗（即结果有意义）吗？这种 OLS 回归的应用有具体的名称吗？或者我们应该使用其他回归模型来完成类似的事情？]]></description>
      <guid>https://stats.stackexchange.com/questions/644803/what-is-the-name-terminology-for-this-application-of-ols-regression</guid>
      <pubDate>Thu, 11 Apr 2024 14:13:23 GMT</pubDate>
    </item>
    <item>
      <title>最常用的加权方法的主要优点和缺点是什么？</title>
      <link>https://stats.stackexchange.com/questions/644802/what-are-the-main-pros-and-cons-of-the-most-commonly-used-weighting-methods</link>
      <description><![CDATA[在观察研究中生成平衡权重的方法有很多（例如，参见许多方法在令人惊叹的 WeighIt 包中实现。
我看过一些关于为什么人们更喜欢使用匹配/加权而不是混杂因素回归，但我从未找到关于最广泛使用的加权方法的优缺点的论文或讨论。

有人可以解释一下最常用的加权方法的优缺点吗？（例如（广义）线性模型、增强建模、熵平衡、能量平衡等？）李&gt;
在评估治疗效果或统计调查中的非受访者时，这些优点和缺点是否具有可比性？

非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644802/what-are-the-main-pros-and-cons-of-the-most-commonly-used-weighting-methods</guid>
      <pubDate>Thu, 11 Apr 2024 14:06:42 GMT</pubDate>
    </item>
    <item>
      <title>一维自动编码器作为聚类工具？</title>
      <link>https://stats.stackexchange.com/questions/644800/1-dimensional-autoencoder-as-a-clustering-tool</link>
      <description><![CDATA[我正在寻找一些“似乎”的参考资料（因为我更喜欢坐在巨人的肩膀上......）好好工作...
当我们进行聚类来分析一些数据、了解其结构（在我的例子中是为了了解人们在某些调查中表达的偏好）时，这在某种程度上就像在由类数给出的离散空间上进行降维。&lt; /p&gt;
但我也可以在输出中运行具有单一维度的自动编码器，并打印结果编码数据的密度。然后我可以看到人们调查的答案如何组合在一起。
在我的研究中，我检索到的密度与簇分配的密度非常相似，但具有更多“细节”。是在连续空间上的编码......
这是一条死亡鲑鱼的巧合，还是对您来说有意义？
编辑：我已经在 Iris 数据集上尝试过，并得到了相同的结果。一维自动编码器输出的密度显示存在一个明显分离的模态，而其他两个模态在它们之间有点合并，这确实是Iris 数据集的结构...]]></description>
      <guid>https://stats.stackexchange.com/questions/644800/1-dimensional-autoencoder-as-a-clustering-tool</guid>
      <pubDate>Thu, 11 Apr 2024 13:46:49 GMT</pubDate>
    </item>
    </channel>
</rss>