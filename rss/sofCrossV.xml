<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 19 Oct 2024 01:14:40 GMT</lastBuildDate>
    <item>
      <title>二进制时间序列数据的置信带</title>
      <link>https://stats.stackexchange.com/questions/655991/confidence-bands-for-binary-time-series-data</link>
      <description><![CDATA[上下文：我有二进制数据 $x_{it}\in\{0,1\}$，其中 $i\in\{1,...,N\}$ 表示试验索引，而 $t\in\{1,...,T\}$ 表示时间索引（在试验之间独立；不在时间之间独立）。这是我运行的模拟（$N$ 次，每次 $T$ 个周期），我没有对随机过程 $\{x_{\cdot t}\}_{t=1}^T$ 的明确描述。
我的问题：我可视化了 $x_{\cdot,t}$ 在时间 $t$ 之后始终保持在 1 的频率，并绘制了每个 $t$ 的图表。我还想绘制一个“置信区间”，但我不知道如何/是否可以做到这一点。
我目前的工作：对于每个$(i,t)$，$S_{it} = \prod_{\tau=t}^{T}x_{i\tau}$ 编码事件，即对于所有$\tau\geq t$，$x_{i\tau}=1$。我在每个 $t$ 上绘制了 $\frac{1}{N}\sum_{n=1}^N 1\{S_{\cdot t}=1\}$，以可视化 $x_{\cdot t}$ 在 $t$ 时间之后保持为 1 的频率。（这正确吗？）关于可视化置信区间，我曾尝试查找有关如何对“生存曲线”进行可视化的指南（因为我所绘制的内容似乎与此相关），但我不知道它们是否适用（即使如此，我也不完全确定如何将迄今为止找到的方法转化为我的问题）。任何指导都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/655991/confidence-bands-for-binary-time-series-data</guid>
      <pubDate>Fri, 18 Oct 2024 22:58:48 GMT</pubDate>
    </item>
    <item>
      <title>高效 Net V2 M ONNX 模型在小输入上的推理速度明显较慢</title>
      <link>https://stats.stackexchange.com/questions/655990/efficient-net-v2-m-onnx-model-infers-significantly-slower-on-small-input</link>
      <description><![CDATA[当我将 Efficient net v2 m 模型从 Pytorch 转换为 Onnx 以适应不同大小的输入时，我注意到一种奇怪且无法解释的行为。我希望从这个社区找到对我的观察的解释。
在我的 RTX 4090 上，1280X1280 大小图像上的 ONNX 模型在 35 毫秒内推断出批处理大小为 1。当我将图像大小缩小到大约 192X192（批处理大小相同为 1）时，运行时间几乎保持不变。这是可以理解的，因为固定开销占主导地位，例如初始化时间、线程池预热、与 GPU 之间的低效数据传输，最重要的是，计算库针对 GPU 上的矢量化和 SIMD 指令进行了优化。
然而，令人困惑的是，一旦我开始将输入图像大小减小到 192X192 以下，运行时间就会急剧增加。对于 64X64 图像，批处理大小为 1 时运行时间为 &gt;100ms。我完全理解为什么在较小的图像上推理不应该更快，但我不明白为什么它会更慢（而且慢得多）。
当我增加较小图像的批处理大小时，每批的运行时间会大幅改善（不仅仅是每幅图像的运行时间）。对于批处理大小为 16 的图像，推理 192X192 图像每批需要 25 毫秒（每幅图像不到 2 毫秒），而批处理大小为 1 时则需要 &gt;100ms。同样，我对此没有任何解释。固定开销和优化的 SIMD 矢量化将决定每幅图像的摊销运行时间应该随着批处理大小的增加而改善。但是，我观察到整个批次的运行时间也得到了改善。
对于较大的图像（例如 1280X1280），增加批次大小会增加每个批次的运行时间（尽管是亚线性的，这是完全可以预料的 - 随着批次大小的增加，每个图像的运行时间仍然会缩短到一定限度，之后，对于几乎无法放入 GPU 内存的更高批次大小，每个图像的运行时间也会增加约 10%）。
但是在 CPU 上运行时，处理时间会随着输入大小的增加而单调增加，正如预期的那样。
当我要求它对所有输入进行处理时，我已经验证了 ONNX 模型在 GPU 上成功运行。事实上，对于小输入，CPU 推理时间比 GPU 更快（这是可以理解的，因为有固定的 I/O 和其他开销）
注意：由于我在整个实验过程中将动态轴设置为 None，因此我为具有不同输入大小的同一 torch 模型保存了多个版本的 ONNX 模型。使用或不使用 onnx-sim 几乎不会对运行时间产生影响（处理速度差异小于 10-15%）。我在 C++ 中以 OrtCUDAProviderOptions 作为执行提供程序运行 onnx 模型，使用或不使用 GraphOptimizationLevel 几乎没有区别。
神经网络的输出对于所有输入都符合预期，因此我不希望我的代码中出现任何错误。
TL;DR我的 ONNX 模型对于中等大小图像的运行速度比 GPU 上的小图像更快。对于较小的图像，增加批次大小会大幅减少每批次的处理时间（而不仅仅是 SIMD 并行化所预期的每张图像的摊销时间）。]]></description>
      <guid>https://stats.stackexchange.com/questions/655990/efficient-net-v2-m-onnx-model-infers-significantly-slower-on-small-input</guid>
      <pubDate>Fri, 18 Oct 2024 21:24:44 GMT</pubDate>
    </item>
    <item>
      <title>从探索性数据分析中得出的特征是否会导致 K 折交叉验证不准确？</title>
      <link>https://stats.stackexchange.com/questions/655988/do-features-derived-from-an-exploratory-data-analysis-lead-to-inaccurate-k-fold</link>
      <description><![CDATA[我对探索性数据分析、特征工程和使用 k 倍交叉验证的特征选择之间的相互作用有些困惑。如果有人能给我一些解释，我将不胜感激。
更具体地说，我想知道我尝试使用探索性数据分析找到合适的线性回归模型的情况。
假设我有一个大小为 n 的样本，每个观察值由 k 个变量组成。作为第一步，我将留出一个测试集进行最终模型评估。然后，为了了解我的反应与其他记录变量之间的关系，我会例如查看相关性，绘制数据以查看是否可能存在任何非线性关系。我还会考虑可能的相互作用。然后，我将根据我之前的观察结果创建不同的特征（多项式、平方根、交互等）。为了查看这些添加的特征是否真的改善了与基线相比的模型，我想对用于探索性数据分析的相同数据（即除先前为最终模型评估预留的观测值之外的所有观测值）执行 k 倍交叉验证。但是，我想知道这种方法是否有缺陷，因为我根据我的观察进行了特征工程，其中已经包括用于 k 倍交叉验证的完整数据，即每个步骤中遗漏的折叠。这不会导致数据泄露吗？因为我犯了一个类似的错误，就像我在对整个数据集执行特征工程时一样，即这通常会导致模型产生良好的 k 倍交叉验证结果，但在测试数据上结果不佳吗？如果是这样，检查我设计的特征是否确实相关的正确方法是什么？留出额外的验证集？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655988/do-features-derived-from-an-exploratory-data-analysis-lead-to-inaccurate-k-fold</guid>
      <pubDate>Fri, 18 Oct 2024 20:54:09 GMT</pubDate>
    </item>
    <item>
      <title>关于运行k均值聚类分析的问题</title>
      <link>https://stats.stackexchange.com/questions/655987/question-about-running-k-means-cluster-analysis</link>
      <description><![CDATA[在之前的分析中，我有 3 组受试者 - 组 x 有 35 名受试者，对照组 y 有 25 名受试者，对照组 z 有 25 名受试者。对于每组，我都有 6 种不同的生物标志物水平（我们可以将它们称为生物标志物 a、b、c、d、e 和 f）。我比较了各组之间每种生物标志物的水平，发现没有显著差异。但是，我有理由相信，组 x 中将存在有意义的受试者亚组，这些亚组的一种或多种代谢物水平将与一个或两个对照组不同。对于所有 85 名参与者，我还有其他数据，我认为这些数据可能与构建亚组有关 - 具体来说，我有 7 种不同类型的智商数据（我们将它们称为智商 a、b、c、d、e、f 和 g），以及两个人口统计变量，具体来说是年龄和受教育年限。现在我想要做的是对组 x 运行 k 均值聚类分析，以找到该组中涉及生物标记的任何有意义的子组 - 例如，我可能会发现两个聚类；一个聚类具有高水平的生物标记 d、低智商 b 和低受教育年限（我们称之为聚类 A），另一个聚类具有低水平的生物标记 e、高智商 f 和高年龄（我们称之为聚类 B）。然后，我们的想法是取每个聚类，并将该聚类中涉及的生物标记水平与两个对照组中这些生物标记的水平进行比较。例如，对于簇 A，我将比较组 x 中的生物标志物 d 水平与两个对照组中每个组的生物标志物 d 水平，如果我发现组 x 的生物标志物 d 水平与其中一个或两个对照组不同，那么我可以说组 x 中有一组受试者的生物标志物 d 水平高、智商 b 低、受教育年限低，其生物标志物 d 水平与其中一个或两个对照组不同。然后，​​对于簇 B，我将比较组 x 中的生物标志物 e 水平与两个对照组中每个组的生物标志物 e 水平，如果我发现组 x 的生物标志物 e 水平与其中一个或两个对照组不同，那么我可以说组 x 中有一组受试者的生物标志物 e 水平低、智商 f 高、年龄大，其生物标志物 e 水平与其中一个或两个对照组不同。
上述聚类分析似乎是一条不错的途径。但是，我对聚类分析完全是新手。有人告诉我，x 组中的 35 名受试者不足以运行 k 均值聚类分析，因为如果我对这么小的组运行它，我得到的任何结果很可能只是噪音。所以我需要更多的受试者才能进行聚类分析。不幸的是，我没有更多的 x 组受试者。所以，我想这样做，我想看看这是否是一种回答我的研究问题的有效方法。为了获得更多数据，我将在聚类分析中不仅包括来自 x 组的受试者，还包括来自对照组 y 和 z 的受试者。这样我就可以总共有 85 名受试者进行聚类分析，我想这应该足够了。然后假设我找到了上面提到的相同的两个簇，但包括了所有三个组的参与者（谁知道是否真的如此，但我们只是假设一个例子） - 假设对于簇 A，我们再次具有高水平的生物标志物 d、低智商 b 和低受教育年限，并且假设簇 A 有 12 个来自 x 组的受试者、2 个来自 y 组的受试者和 1 个来自 z 组的受试者；然后对于簇 B，我们再次具有低水平的生物标志物 e、高智商 f 和高年龄，并且簇 B 有 11 个来自 x 组的受试者、3 个来自 z 组的受试者和 1 个来自 y 组的受试者。然后，我想这样做：对于 A 组，我可以从组 x（n=12）中选取 12 名受试者，并将他们的生物标志物 d 水平与对照组 y（n=25）中的生物标志物 d 水平进行比较，然后将其与对照组 z（n=25）中的生物标志物 d 水平进行比较。同样，对于 B 组，我将从组 x（n=11）中选取 11 名受试者，并将他们的生物标志物 e 水平与对照组 y（n=25）中的生物标志物 e 水平进行比较，然后将其与对照组 z（n=25）中的生物标志物 d 水平进行比较。 所以我的问题是，这是否是一种有效且可行的方法，仍然能够运行聚类分析来回答我的研究问题，即 x 组中是否存在有意义的亚组，这些亚组在一个或多个生物标志物的水平上与一个或两个对照组不同。
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/655987/question-about-running-k-means-cluster-analysis</guid>
      <pubDate>Fri, 18 Oct 2024 20:39:41 GMT</pubDate>
    </item>
    <item>
      <title>两个随机变量之间差异的概率区间</title>
      <link>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</link>
      <description><![CDATA[如果 X1​ 在区间 [L1, R1] 内的概率为 95%，X2 在区间 [L2, R2] 内的概率为 95%，这是否意味着 X1−X2 在区间 [L1−R2, R1−L2] 内的概率将超过 95%？X1 和 X2 可能是相关的，也可能是独立的。
有人能为此提供证据或反例吗？
我很感激任何帮助解决问题的人！]]></description>
      <guid>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</guid>
      <pubDate>Fri, 18 Oct 2024 19:35:37 GMT</pubDate>
    </item>
    <item>
      <title>具有反射的离散布朗运动的表达式</title>
      <link>https://stats.stackexchange.com/questions/655982/expression-for-discrete-brownian-motion-with-reflection</link>
      <description><![CDATA[对于具有吸收状态的离散布朗运动，我们可以将位置分布表示为两个二项分布的线性和，如此处所述，其中 +1 和 -1 步的几率为 1:1，此处所述，用于更一般的几率不相等的情况。
具有反射墙的离散布朗运动的情况如何？
假设我们将时间 $t$ 的位置描述为 $X(t)$，起始位置为 $X(0) = 1$。有概率 $p$ 我们向前迈一步 $X(t+1) = X(t) + 1$ ，有概率 $1-p$ 我们向后迈一步 $X(t+1) = X(t) - 1$ ，除非 $X(t) = 0$ ，在这种情况下我们总是向前迈一步。]]></description>
      <guid>https://stats.stackexchange.com/questions/655982/expression-for-discrete-brownian-motion-with-reflection</guid>
      <pubDate>Fri, 18 Oct 2024 19:26:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 包 marginaleffects 进行编码比较和交互</title>
      <link>https://stats.stackexchange.com/questions/655981/coding-comparisons-and-interactions-with-the-r-package-marginaleffects</link>
      <description><![CDATA[我开始学习如何使用 R 包 marginaleffects，并希望得到一些特定应用方面的帮助。
为了说明，我们使用 afex 包中的数据集。变量 phase 是一个具有三个级别的因子：“fup”、“post”和“pre”。变量 age 是连续的。下面是使用 lme4 拟合的模型：
library(afex); library(lme4); library(phia)
data(obk.long, package = &quot;afex&quot;)
options(contrasts = c(&quot;contr.sum&quot;, &quot;contr.poly&quot;))
fm &lt;- lmer(value ~ phase * age + (1|id), data = obk.long)

我想使用 marginaleffects 复制以下七个比较和交互：

对比因子 phase 的前两个级别（“fup”与“post”）
在 phia 中，这是通过以下方式完成的：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), adjustment = &quot;none&quot;)


对比phase的前两个级别，其中age固定在 5.5
在phia中：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), covariates = c(age = 5.5), adjustment = &quot;none&quot;)


age的斜率（在phase的所有级别上取平均值）
在phia中：
testInteractions(fm, pairwise = NULL, slope = &quot;age&quot;, adjustment = &quot;none&quot;)


前两个级别之间的age斜率差异 (&quot;fup&quot; vs. &quot;post&quot;) 的 phase
在 phia 中：
testInteractions(fm, custom = list(phase = c(-1, 1, 0)), slope = &quot;age&quot;, adjustment = &quot;none&quot;)


phase 的三个级别之间的综合对比（例如 &quot;fup&quot; - &quot;pre&quot; 和 &quot;post&quot; - &quot;pre&quot;）
在 phia 中：
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))))


phase 三个级别的综合斜率比较（例如，&quot;fup&quot; 与 &quot;pre&quot; 以及 &quot;post&quot; 与 &quot;pre&quot; 的斜率差异）
在 phia 中：
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))), slope = &quot;age&quot;)


固定年龄的 phase 三个级别的综合对比（例如，&quot;fup&quot; - &quot;pre&quot;和“post” - “pre” 在 age = 5.5)
在 phia:
testFactors(fm, levels = testFactors(fm, levels = list(phase = rbind(diag(2), c(-1,-1)))), covariates = c(age = 5.5))



我的问题是：如何使用 marginaleffects 包对这七个效应进行编码？]]></description>
      <guid>https://stats.stackexchange.com/questions/655981/coding-comparisons-and-interactions-with-the-r-package-marginaleffects</guid>
      <pubDate>Fri, 18 Oct 2024 18:51:31 GMT</pubDate>
    </item>
    <item>
      <title>我们如何模拟在多层次/混合效应设置中在不同层次上变化的相关随机变量？</title>
      <link>https://stats.stackexchange.com/questions/655980/how-can-we-simulate-correlated-random-variables-that-vary-at-different-levels-in</link>
      <description><![CDATA[我非常熟悉从多元正态分布中生成相关随机变量。
这个问题是关于在多级设置中执行此操作，其中变量仅在分组变量的特定级别上变化。
假设我们有一个分组因子 - group，我们希望模拟 2 个随机变量，x1 和 x2，其中 x1 在较低级别变化，x2 在较高级别变化。假设下层有 100 个（n1 = 100）观测值，上层有 20 个不同的观测值（n2 = 20，但显然每个值都重复 5 次，因此组大小都相等（即每组 5 个）。
我们如何模拟 x1 和 x2，使得 sd(x1) = 5 和 sd(x2) = 3 以及 Cov(x1,x2) = 2？
我不需要任何代码。我有一些代码，但希望得到一些关于该方法的反馈，如下所示：
在这种模拟两级分层模型数据的方法中，我们旨在生成两个随机变量，x1 和x2，其中 x1 在较低（个体）水平上变化，而 x2 在较高（组）水平上变化。关键目标是确保 x1 和 x2 的标准差分别指定为 5 和 3，并且 x2 的扩展版本（在组内个体之间复制）和 x1 之间的协方差设置为 2（出于此模拟的目的）。该过程首先在组级别生成 x2，其中包含 20 个组的 20 个不同值，每个值的标准差为 3。然后，这些组级别值在每个组内的个体之间复制，以创建扩展的 x2。为了实现 x1 和 x2 之间所需的协方差，我们计算一个将 x1 与扩展的 x2 相关联的共享分量。此共享分量来自协方差公式，将所需的协方差除以扩展的 x2 的方差。然后，我们通过向共享分量添加独立噪声来生成 x1，确保 x1 的整体方差等于 5。此方法尝试允许跨层次结构级别控制相关数据的生成，从而确保正确的标准差和协方差。这是我实现此功能的代码。
# 参数
n1 &lt;- 1000 # 1 级（个体级）的观察总数
n2 &lt;- 200 # 2 级（组级）的组总数
group_size &lt;- n1 / n2 # 每个组的大小

# 所需的标准差和协方差
sd_x1 &lt;- 5
sd_x2 &lt;- 3
cov_x1_x2 &lt;- 2

# 模拟次数
n_sim &lt;- 100

vec_sd_1 &lt;- numeric(n_sim)
vec_sd_2 &lt;- numeric(n_sim)
vec_cov &lt;- numeric(n_sim)

set.seed(15)

for (i in 1:n_sim) {

# 1. 生成组级变量 x2（sd = 3）
x2_group &lt;- rnorm(n2, mean = 0, sd = sd_x2)

# 2. 为组中的每个个体复制 x2（扩展 x2）
x2 &lt;- rep(x2_group, each = group_size) # 这使得 x2 长度为 n1

# 3. 根据扩展的 x2 计算正确的共享组件
shared_component &lt;- cov_x1_x2 / var(x2) # 与扩展的 x2 相关的 x1 部分

# 4. 生成个体级随机变量 x1
x1 &lt;- x2 * shared_component + rnorm(n1, mean = 0, sd = sqrt(sd_x1^2 - shared_component^2 * var(x2)))

# 检查结果
group &lt;- rep(1:n2, each = group_size)

# 带有模拟数据的数据框
data &lt;- data.frame(group = factor(group), x1 = x1, x2 = x2)

vec_sd_1[i]&lt;- sd(data$x1)
vec_sd_2[i] &lt;- sd(data$x2)
vec_cov[i] &lt;- cov(data$x1, data$x2) 

}

mean(vec_sd_1) 
mean(vec_sd_2)
mean(vec_cov)

结果如下：
&gt;平均值（vec_sd_1） 
[1] 4.990359
&gt; 平均值（vec_sd_2）
[1] 2.994848
&gt; 平均值（vec_cov）
[1] 2.003473

看起来不错，任何反馈都会很感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/655980/how-can-we-simulate-correlated-random-variables-that-vary-at-different-levels-in</guid>
      <pubDate>Fri, 18 Oct 2024 18:23:10 GMT</pubDate>
    </item>
    <item>
      <title>引导样条构造</title>
      <link>https://stats.stackexchange.com/questions/655978/bootstrapping-spline-construction</link>
      <description><![CDATA[我想知道我们是否应该引导平滑样条的构造？
我正在 brms（和 mgcv）中用平滑项建模逻辑模型。执行 Bootstrap 时，按照惯例对数据集进行常规替换重采样可能会导致平滑构造中的破坏性错误，因为提供的数据点数量不足（由 mgcv::smooth.construct 引发）。
因此，我正在考虑一种贝叶斯风格的 Bootstrap（模仿包 bayesboot 的实现），其中，不是重新采样数据集，而是对每个观察值的权重进行采样，遵循狄利克雷分布并将其提供给 brms（或具有准二项式族的 mgcv）。但是，查看生成的代码让我感到疑惑。由于平滑项的构造仍然有效地使用了完整的训练特征空间而不是替代空间，这是否会导致对过度乐观的低估？另一方面，从 mgcv 代码来看，我认为 (!!) s(x) 的构造不依赖于结果 y（平滑系数依赖于结果 y，基本函数不依赖于结果 y）。因此，也许不对其进行引导确实更有意义？但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/655978/bootstrapping-spline-construction</guid>
      <pubDate>Fri, 18 Oct 2024 16:42:08 GMT</pubDate>
    </item>
    <item>
      <title>皂膜平滑器的 GAM 边界条件问题</title>
      <link>https://stats.stackexchange.com/questions/655976/issue-with-boundary-condition-in-a-gam-with-a-soap-film-smoother</link>
      <description><![CDATA[我目前正在尝试安装 GAM 来模拟湖中各种声学接收器检测到的鱼的数量。这些接收器放置在特定位置，具有唯一的经度和纬度。我希望模拟研究期间 4 个治疗组中每个接收器检测到的鱼的数量。我在 R 中使用 mgcv 完成了此操作，代码如下：
mod1 &lt;- gam(number_of_fish ~ treatment +
s(x, y, by = treatment, k = 15, bs = &quot;so&quot;,
xt = list(bnd = shap_bnd_ls, nmax = 1500)),
data = filter(fish_num_final_utm, study_fortnight == 0),
family = ziP(),
method = &quot;REML&quot;,
knots = lake_knots)

请注意，我使用的是从我的研究系统的 shapefile 生成的肥皂膜平滑器。
我添加了一个边界条件，以便模型知道预测湖边有 0 条鱼，如下所示。请注意，shap_bnd_ls 是我的边界列表。
shap_bnd_ls &lt;- lapply(nr,
function(n)
shap_bnd_ls[[n]] &lt;- c(
shap_bnd_ls[[n]],
list(f = rep(0, length(shap_bnd_ls[[n]]$x))
)
)
)

该模型似乎运行正常。但是，我认为边界条件没有正常工作。特别是，该模型似乎始终预测湖边的鱼数量为非零（见下文）。我尝试调整“k”值并使用正态泊松分布，但似乎仍然不起作用。

以下是湖面模型预测：

任何帮助，甚至是正确方向的推动都将不胜感激！
您可以找到数据、代码和shapefile 这里。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655976/issue-with-boundary-condition-in-a-gam-with-a-soap-film-smoother</guid>
      <pubDate>Fri, 18 Oct 2024 16:03:05 GMT</pubDate>
    </item>
    <item>
      <title>在具有对数链接的泊松 GEE 中对二进制结果进行反转编码时，P 值会发生变化，但逻辑 GEE 或 OLS 则不会</title>
      <link>https://stats.stackexchange.com/questions/655975/p-value-changes-when-invert-coding-of-binary-outcome-in-poisson-gee-with-log-lin</link>
      <description><![CDATA[我们在面板数据上运行具有二元结果（是/否）的回归模型。结果非常常见（93.6%=是，n=4231 个观察值中的 3961 个）。我们使用 GEE 模型来解释每个参与者的多个观察值。
当我们运行具有对数链接的泊松 GEE 模型（每个预测变量一个模型）时，p 值会根据结果是正编码（是=1）还是负编码（否=1）而有很大差异，并且某些结果会根据编码而变得重要。但是，当我们在相同变量上运行逻辑 GEE 模型时，基于正编码和负编码的 p 值没有差异。 （注意：对数二项式模型不收敛，因此我们无法测试这一点）。
如果结果的编码可以改变重要性，我们会担心泊松结果的有效性。
1.) 为什么泊松模型会产生不同的逆编码 p 值，但逻辑编码不会产生不同的 p 值？这是否与结果的普遍程度有关（如果编码为 Yes=1）？
2.) 如果使用一致的编码（例如，所有模型的 Yes=1），是否可以使用泊松 GEE 的结果？
模型的示例编码：
model1.poisson.yes = geeglm(formula = consequence_yes ~ binary_predictor1, 
id = uuid,
family = poisson(&quot;log&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

model1.poisson.no = geeglm(formula = consequence_no ~ binary_predictor1, 
id = uuid,
family = poisson(&quot;log&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

model1.logistic.yes = geeglm(formula = consequence_yes ~ binary_predictor1, 
id = uuid,
family = binomial(&quot;logit&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

model1.logistic.no = geeglm(formula = consequence_no ~ binary_predictor1, 
id = uuid,
family = binomial(&quot;logit&quot;), 
corstr = &quot;exchangeable&quot;,
data = df)

]]></description>
      <guid>https://stats.stackexchange.com/questions/655975/p-value-changes-when-invert-coding-of-binary-outcome-in-poisson-gee-with-log-lin</guid>
      <pubDate>Fri, 18 Oct 2024 16:02:55 GMT</pubDate>
    </item>
    <item>
      <title>使用样条函数绘制威布尔回归中的 HR</title>
      <link>https://stats.stackexchange.com/questions/655960/plot-hr-in-weibull-regression-with-splines</link>
      <description><![CDATA[我用样条函数（连续变量的四分位数）和 survreg 拟合了一个威布尔回归模型。
 fit &lt;- survreg(Surv(time, event) ~ bs(var1, knots=c(2,3,5)) + var2 + 
var3 + ...

我想给出一个带有 95%CI 的样条函数的 HR 图，有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655960/plot-hr-in-weibull-regression-with-splines</guid>
      <pubDate>Fri, 18 Oct 2024 13:02:13 GMT</pubDate>
    </item>
    <item>
      <title>出口数据的结构突变检测</title>
      <link>https://stats.stackexchange.com/questions/655931/structural-break-detection-in-export-data</link>
      <description><![CDATA[我正在查看挪威的出口数据，试图发现俄罗斯逃避制裁的行为。逃避制裁的行为是将商品出口到第三方国家，然后这些国家再将商品出口到俄罗斯。这些数据具有月度分辨率，并且在商品类别方面非常精细。我想知道是否有一种统计测试可以用来检测 2022 年 2 月之后出口与之前相比的显著变化。我想使用该测试来检查多个第三方国家/地区的每个出口类别，以便了解需要仔细研究的内容。
下面我绘制了基站（电信设备）出口到哈萨克斯坦的时间序列：

这是数据集中数据的典型示例。您可以看到大多数月度值为零，只有少数非零值。这些值是离散的，只有整数。]]></description>
      <guid>https://stats.stackexchange.com/questions/655931/structural-break-detection-in-export-data</guid>
      <pubDate>Thu, 17 Oct 2024 20:11:52 GMT</pubDate>
    </item>
    <item>
      <title>解释“百分比增加/减少”中的逻辑回归系数</title>
      <link>https://stats.stackexchange.com/questions/655930/interpreting-logistic-regression-coefficients-in-percentage-increase-decrease</link>
      <description><![CDATA[我理解，从逻辑回归来看（假设有两个预测因子）
$$\log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1x_1 + \beta_2 x_2$$
并且当 $x_1$ 为二进制时，可以按如下方式解释
$e^{\hat\beta_1} = \frac{odds(p|x_1 = 1)}{odds(p|x_1 = 0)}$
我读过一篇利用逻辑线性回归的论文，结果如下。
$$\log\left(\frac{p}{1-p}\right) = -1.86-0.15\times x_1 + 0.33\times x_2$$
$x_1$ 是连续变量，而 $x_2$ 是二进制变量。
据我所知，以下是作者对结果的解释。

$x_1$ 相对于均值每增加一个单位，$p$ 的概率就会下降 13%。
$x_2 = 1$ 对应于 $p$ 相对于 $x_2 = 0$ 增加 34%&gt;

我可以根据比值比来解释系数，但在讨论 p 的百分比增加/减少时，这个数字是如何得出的？
我已经努力理解了好几个小时，所以我真的需要一些帮助！提前谢谢您。
此外，有关该论文的更多信息，请访问https://www.jstor.org/stable/2657467。]]></description>
      <guid>https://stats.stackexchange.com/questions/655930/interpreting-logistic-regression-coefficients-in-percentage-increase-decrease</guid>
      <pubDate>Thu, 17 Oct 2024 20:02:14 GMT</pubDate>
    </item>
    <item>
      <title>计数值的统计检验</title>
      <link>https://stats.stackexchange.com/questions/655928/statistical-test-for-count-values</link>
      <description><![CDATA[我有 4 个故事，每个故事都有字数和复数词的数量：



故事
单词数
复数




1
356
45


2
273
23


3
303
28


4
289
42



我想知道是否可以进行统计测试以确定这些故事在字数方面是否存在显着差异，然后再进行另一项测试以确定这些故事在复数数量方面是否存在显着差异。
测试的目的是确保这些故事在阅读难度方面没有显着差异。这是一项心理学研究，我们需要确保故事难度中没有混淆。我们正在测试其他更相关的单词特征，但这些是连续值，我们可以对其进行其他测试。
我没有人口频率可以与之比较，以便使用 Fisher 精确检验，我认为我不能使用卡方检验，因为那里的计数似乎应该是相关的，例如测试一群人是否喜欢苹果、橘子或香蕉，而一个人不能选择两个选项，我有点困惑，不知道我可以在这里使用什么测试。]]></description>
      <guid>https://stats.stackexchange.com/questions/655928/statistical-test-for-count-values</guid>
      <pubDate>Thu, 17 Oct 2024 19:33:29 GMT</pubDate>
    </item>
    </channel>
</rss>