<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 20 Jul 2024 12:26:37 GMT</lastBuildDate>
    <item>
      <title>使用 lme4 在 R 中重复测量 HLM [关闭]</title>
      <link>https://stats.stackexchange.com/questions/651450/repeated-measures-hlm-in-r-using-lme4</link>
      <description><![CDATA[我进行了一项采用受试者内设计的实验。每个参与者与两个系统进行交互，每次交互后，都会用问卷调查相同的结构进行测量。参与者与系统交互的顺序是随机的，因此我有两个组（系统 1，然后是系统 2，然后是反之）。所以我的数据嵌套在每个参与者中，而每个参与者又嵌套在一个组中。
我现在想分析我收集的数据。我的研究模型如下：
系统影响结构 a；a 影响 b 和 c； b 和 c 影响 d
我有两个主要问题：

不可能创建一个使用 HLM 一次性计算所有依赖关系的模型，对吗？

我的测量 lmer(...) 的代码看起来如何？


a ~ system + (1|participant) + (1|group) -&gt;我想找出哪个系统产生更高的 a
b ~ a + (1|participant) + (1|group) + (1|system)
c ~ a + (1|participant) + (1|group) + (1|system)
d ~ b + c (1|participant) + (1|group) + (1|system) ]]></description>
      <guid>https://stats.stackexchange.com/questions/651450/repeated-measures-hlm-in-r-using-lme4</guid>
      <pubDate>Sat, 20 Jul 2024 10:59:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 LOOCV 中的正则化减少小型数据集的方差</title>
      <link>https://stats.stackexchange.com/questions/651449/reducing-variance-with-regularization-in-loocv-for-small-datasets</link>
      <description><![CDATA[我有一个小数据集，我正在考虑使用留一交叉验证 (LOOCV) 来评估我的模型。我理解，交叉验证通常是一种评估模型在未见数据上的表现的方法。
但是，我担心偏差-方差权衡。具体来说，使用 LOOCV 时，存在偏差低但方差高的风险。为了缓解这种情况，我正在考虑使用正则化模型（L1、L2 或 Elastic Net）来引入一些偏差并减少方差（在使用 loocv 时同时……）。
您能否提供任何实施此方法的提示或最佳实践？任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/651449/reducing-variance-with-regularization-in-loocv-for-small-datasets</guid>
      <pubDate>Sat, 20 Jul 2024 10:57:12 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用正则化方法作为特征选择方法，然后使用机器学习模型来分析数据？</title>
      <link>https://stats.stackexchange.com/questions/651448/would-it-be-possible-to-use-regularization-methods-as-a-feature-selection-method</link>
      <description><![CDATA[我的数据是具有超过 14000 个特征的 RNA-seq 数据，问题是二分类。那么总样本是 50 并且 p&gt;&gt;n。当我使用 Elasticnet 方法对训练和测试数据进行处理时，敏感度为 0.6，准确度为 0.5。当我使用 Elasticnet 作为特征选择，然后将随机森林或深度学习拟合到所选特征时，结果会更好。例如，在随机森林建模中，敏感度为 0.97，对于深度学习，敏感度为 0.84。所以，我的问题是，是否可以使用正则化方法作为特征选择方法，然后使用机器学习模型来分析分类问题中的数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/651448/would-it-be-possible-to-use-regularization-methods-as-a-feature-selection-method</guid>
      <pubDate>Sat, 20 Jul 2024 10:51:36 GMT</pubDate>
    </item>
    <item>
      <title>如何使用多个二维点云找到特征曲线？</title>
      <link>https://stats.stackexchange.com/questions/651447/how-can-i-find-a-characteristic-curve-using-multiple-2d-point-clouds</link>
      <description><![CDATA[我学的是机械工程，需要找到液压部件的特性。我有一个像这样的 2D 点云。
对于一条曲线，ChatGPT 建议使用间隔并计算每个间隔的平均值和标准差。像这样，你会得到一个特性。
问题是我也有几个测量值，我必须显示它们之间的偏差。 
如何使用多次测量找到特征？是否可以计算每条曲线的平均值和标准差，然后计算计算值的平均值和标准差？有人知道是否有关于这方面的论文吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651447/how-can-i-find-a-characteristic-curve-using-multiple-2d-point-clouds</guid>
      <pubDate>Sat, 20 Jul 2024 10:50:26 GMT</pubDate>
    </item>
    <item>
      <title>我如何根据条件概率解决这个问题</title>
      <link>https://stats.stackexchange.com/questions/651446/how-do-i-solve-this-problem-on-conditional-probability</link>
      <description><![CDATA[其中 x~ u(0,4)，P(X&gt;Y|X&lt;2Y) 是什么
我知道 X 位于下限 Y 和上限 2Y 之间，但我很难找出 P(X&lt;2Y)，因为我遇到的所有示例都没有严格处理变量。我的数学不是最强的，因为我很难从我见过的例子中概括出来。]]></description>
      <guid>https://stats.stackexchange.com/questions/651446/how-do-i-solve-this-problem-on-conditional-probability</guid>
      <pubDate>Sat, 20 Jul 2024 10:36:39 GMT</pubDate>
    </item>
    <item>
      <title>不可靠测量的方差分析</title>
      <link>https://stats.stackexchange.com/questions/651443/anova-with-unreliable-measure</link>
      <description><![CDATA[我正在做一些关于体育科学的文献综述，特别是训练对耐力的影响。
没有标准的耐力测试。有些测试包括间歇性收缩，直到筋疲力尽，然后测量最终的力量。
有些测试已成为研究的主题，以获得 ICC、LoA 或其他会话间可靠性指标，而有些则没有。有些被发现具有较低的 ICC（&lt;0.8）或非常大的 LoA（+/- 40%）。
我遇到过一些研究训练对耐力的影响的研究。他们对一组人进行耐力测试，然后让他们接受训练，并进行另一次耐力测试。然后他们进行单向方差分析以确定耐力是否有显著提高。但是，其中一些研究使用了尚未表征的耐力测试，从未进行过任何重测信度评估。
所以我的问题是：如果使用的测量方法不可靠或信度未知，方差分析能否得出显着差异的结论？
这对我来说似乎很奇怪，因为这就像使用不可靠的量表而不知道其标准误差一样。
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/651443/anova-with-unreliable-measure</guid>
      <pubDate>Sat, 20 Jul 2024 09:54:24 GMT</pubDate>
    </item>
    <item>
      <title>文献计量与共现分析</title>
      <link>https://stats.stackexchange.com/questions/651442/bibliometric-co-occurrence-analysis</link>
      <description><![CDATA[我对网络分析和文献计量学还很陌生。所以请原谅我的问题很愚蠢和基本。
我感兴趣的是了解期刊（学术）是如何相互关联的。每本期刊都有自己的目标和范围。从这些目标和范围中，我有关键词。使用这些关键字，我想确定哪些期刊是相关的（文献计量学/网络分析）。我将在下面举例说明。



期刊
关键词




A
盐；鸡肉；胡椒；粉；酱汁。


B
猫；老鼠；笼子；垃圾


C
鸡肉；汉堡；酱汁；面包


D
狗；猫；牛；宠物；动物；鸟


E
鸡肉；咖喱；酱汁


F
汉堡；面粉；糖；芝麻；盐


G
鸡肉；米饭；胡椒；盐



从下面的简单示例中，我们知道期刊 A、E、G 可以因为关键词共现而相关。我有 200 多种期刊需要分析。所以我想做网络分析。请注意，并非所有期刊都有相同数量的关键词。
希望得到一些反馈。
干杯。
到目前为止，我尝试使用 VOS 查看器，但没有成功。]]></description>
      <guid>https://stats.stackexchange.com/questions/651442/bibliometric-co-occurrence-analysis</guid>
      <pubDate>Sat, 20 Jul 2024 07:22:16 GMT</pubDate>
    </item>
    <item>
      <title>使用 glm.nb() R 包[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651441/using-the-glm-nb-r-package</link>
      <description><![CDATA[我想使用 glm.nb() 函数拟合负二项式数据。出于某种原因，我已经有了负二项分布的地面真实弥散参数，所以我只需要估计平均参数。我如何在 glm.nb() 函数中执行此操作，以便使用真实的弥散参数而不是估计的弥散参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/651441/using-the-glm-nb-r-package</guid>
      <pubDate>Sat, 20 Jul 2024 07:19:58 GMT</pubDate>
    </item>
    <item>
      <title>平均值的假设检验 - z 检验和 t 检验统计量的分布推导</title>
      <link>https://stats.stackexchange.com/questions/651439/hypothesis-tests-for-averages-derivation-of-distribution-of-z-test-and-t-test</link>
      <description><![CDATA[在测试平均值时，z 检验和 t 检验都具有相同形式的检验统计量 $T$:
$$T = \frac{\bar{X} - \mu_0}{\text{se}(\bar{X})}$$
在前者中，已知的总体标准偏差 $\sigma$ 用作分母，而在后者中，标准误差 $S = \hat{\sigma}/\sqrt{n}$ 与 $\hat{\sigma} = \sqrt{\frac{1}{n-1}\sum_{i\leq 一起使用N}(x-\bar{x})^2}$。z 检验统计量的分布为：$T_z \sim \Phi(0, 1)$，t 检验统计量的分布为：$T_t \sim t_{n-1}$
有没有推导为什么除以标准误差会得到 t 分布，而除以标准差会得到正态分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/651439/hypothesis-tests-for-averages-derivation-of-distribution-of-z-test-and-t-test</guid>
      <pubDate>Sat, 20 Jul 2024 06:08:32 GMT</pubDate>
    </item>
    <item>
      <title>成对回归与个体回归之间的关系</title>
      <link>https://stats.stackexchange.com/questions/651437/relationship-between-pairwise-regression-vs-individual-regression</link>
      <description><![CDATA[我想在成对回归和线性回归之间建立联系。我将在下面用一个例子解释成对回归和线性回归的含义，但这个例子只是为了解释我想做什么。
考虑这样一个场景：一所高中有 5 个教室，每个教室有 10 名学生。为简单起见，假设同一个教室里的每个人都互相认识，但不认识其他教室里的任何人。当学生毕业时，他们会决定去哪个州上大学。
我感兴趣的是，在同一个教室里的学生是否更有可能去同一个州上大学。为此，我为所有 50 名学生创建了一个学生对，结果有 50C2 = 1225 对。对于每一对，我可以构建一个指示变量 classmate，如果该对中的两个学生在同一个班级，则该变量等于 1；如果两个学生都去同一个州上大学，则该变量等于 1。
然后，我可以运行回归分析，将 same_college 与 classmate 进行回归，并将 comove 前面的系数解释为同学们去同一个州上大学的额外倾向。这就是我所说的成对回归。
但请注意，50 名学生创建了 1225 对。当样本变大时，这种情况很快就会失控。此外，我没有通过将数据集从个人级别转换为成对级别来插入任何新数据；这只是数据集的转换。**此外，这只研究一个学生如何影响该对中的另一个学生。它忽略了 3 组或更多组学生可能对决策产生不同于仅构建学生对的任何可能性。
问题：我想知道我是否可以从成对回归中检索相同的系数，而无需将数据集转换为成对级别。我很难弄清楚我可以在个体级别上运行的回归是什么，它将与成对级别的系数相匹配。
** 我相信这是一个双射变换，但如果不是，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/651437/relationship-between-pairwise-regression-vs-individual-regression</guid>
      <pubDate>Sat, 20 Jul 2024 02:47:30 GMT</pubDate>
    </item>
    <item>
      <title>分类独立变量[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651435/categorical-independent-variables</link>
      <description><![CDATA[我正在开展一项回顾性研究，有一些分类独立变量，我的结果变量也是分类变量。我想知道具有多个分类独立变量的卡方检验是否是最佳模型。你能帮助我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651435/categorical-independent-variables</guid>
      <pubDate>Sat, 20 Jul 2024 02:22:18 GMT</pubDate>
    </item>
    <item>
      <title>如何计算所需样本量以实现所需的假阴性率</title>
      <link>https://stats.stackexchange.com/questions/651434/how-to-calculate-required-sample-size-for-desired-false-negative-rate</link>
      <description><![CDATA[我正在尝试设计一个进行二元分类的系统。假阴性的成本很高，所以我想确保我已经进行了足够彻底的测试，以尽量减少这种可能性。我希望系统的假阴性率小于 1%，确定性为 95%。如果我预计真阳性率很小（大约 2%），我应该如何计算达到这一置信度所需的人口规模？ 单侧检验程序是此处适用的正确方程吗？
$$
N \geq \left ( \frac{z_{1-\alpha} \sqrt{p_0(1-p_0)} + z_{1-\beta} \sqrt{p_1(1-p_1)}}{p_1-p_0} \right ) ^2
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/651434/how-to-calculate-required-sample-size-for-desired-false-negative-rate</guid>
      <pubDate>Sat, 20 Jul 2024 01:48:58 GMT</pubDate>
    </item>
    <item>
      <title>在 FDR 之前过滤单侧检验</title>
      <link>https://stats.stackexchange.com/questions/651432/filter-one-sided-tests-before-fdr</link>
      <description><![CDATA[在这篇博文中，作者展示了一个“奇怪”的例子p 值直方图（“场景 C”）：

一种解释是，进行了单侧检验，而效果相反的检验给出的 p 值接近 1。他的建议是在计算 FDR 之前根据效果方向过滤掉检验。
但是，我知道，如果过滤方式不正确，在计算 FDR 之前进行预过滤可能会出现问题，例如讨论过的那样这里，当我们查看结果时，感觉按效果方向过滤是“作弊”。
现在，如果我在 R 中运行快速模拟（如下所示），过滤会导致 p 值分布在 0 到 0.5 之间，因此 p 值在 0 和 1 之间均匀的假设不再有效。那么，在计算 FDR 之前根据效果方向进行过滤是否正确？
此外，从经验上看我模拟中的 FDR 和功效，如果我在 p.adjust() 中指定测试总数，似乎我可以保持正确的 FDR 控制，同时仍获得一点功效。这是正确的做法吗？
模拟
set.seed(1)

## 生成数据 ----
real_means &lt;- c(
rep(0, 1000), # 无影响
runif(200, -1, 0), # 减少
runif(200, 0, 1) # 增加
)
labels &lt;- c(
rep(&quot;none&quot;, 1000),
rep(&quot;decreased&quot;, 200),
rep(&quot;increased&quot;, 200)
)

samples &lt;- lapply(real_means, \(mu) rnorm(30, mu, sd = 1))

## 计算 p 值和 fdr ----
p_values &lt;- sapply(samples, \(x) t.test(x, alternative = &quot;greater&quot;)$p.value )
p_values &lt;- setNames(p_values, labels)

hist(p_values, breaks = 70)




fdr &lt;- p.adjust(p_values, method = &quot;BH&quot;)

## 检查结果 ----
false_positives &lt;- sum( fdr[names(fdr) != &quot;increased&quot;] &lt; 0.05 )
predicted_positives &lt;- sum( fdr &lt; 0.05 )
true_positives &lt;- sum( fdr[names(fdr) == &quot;increased&quot;] &lt; 0.05 )
positives &lt;- sum( names(fdr) == &quot;increased&quot; )

# 错误发现率
false_positives / predicted_positives
#&gt; [1] 0.01234568

# 真正率
true_positives / positives
#&gt; [1] 0.4

## 带过滤 ----

direction_increasing &lt;- sapply(samples, \(x) mean(x) &gt;= 0 )

filtered_p_values &lt;- p_values[ direction_increasing ]

hist(filtered_p_values)



filt_fdr &lt;- p.adjust(filtered_p_values, method = &quot;BH&quot; )

false_positives &lt;- sum(filt_fdr[names(filt_fdr) != &quot;increased&lt;] &lt; 0.05 )
predicted_positives &lt;- sum(filt_fdr &lt; 0.05 )
true_positives &lt;- sum(filt_fdr[names(filt_fdr) == &quot;increased&lt;] &lt; 0.05 )
positives &lt;- sum(names(filt_fdr) == &quot;increased&lt; )

# 错误发现率
false_positives / predicted_positives
#&gt; [1] 0.04301075

# 真正率
true_positives / positives
#&gt; [1] 0.4863388

## 带过滤，但指定测试总数 ----

filt_fdr_with_n &lt;- p.adjust(filtered_p_values, method = &quot;BH&quot;, n = length(p_values) )

false_positives &lt;- sum( filt_fdr_with_n[names(filt_fdr_with_n) != &quot;increased&quot;] &lt; 0.05 )
predicted_positives &lt;- sum( filt_fdr_with_n &lt; 0.05 )
true_positives &lt;- sum( filt_fdr_with_n[names(filt_fdr_with_n) == &quot;increased&quot;] &lt; 0.05 )
positives &lt;- sum( names(filt_fdr_with_n) == &quot;increased&quot; )

# 错误发现率
false_positives / predictive_positives
#&gt; [1] 0.01234568

# 真阳性率
true_positives / positives
#&gt; [1] 0.4371585

于 2024-07-19 使用 reprex v2.1.0 创建]]></description>
      <guid>https://stats.stackexchange.com/questions/651432/filter-one-sided-tests-before-fdr</guid>
      <pubDate>Fri, 19 Jul 2024 22:21:49 GMT</pubDate>
    </item>
    <item>
      <title>分位数函数容易求解但 CDF 难以求解的分布示例</title>
      <link>https://stats.stackexchange.com/questions/651421/examples-of-distributions-with-easily-solvable-quantile-functions-but-hard-to-so</link>
      <description><![CDATA[我对概率分布的例子很感兴趣，其中分位数函数 $F^{-1}(p)$ 以闭式存在或易于计算，但累积分布函数 (CDF) $F(x)$ 不以闭式存在。特别是分位数函数易于求解但 CDF 难以求解或无法求解的例子，尤其是当分布用于实际应用时。任何例子都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/651421/examples-of-distributions-with-easily-solvable-quantile-functions-but-hard-to-so</guid>
      <pubDate>Fri, 19 Jul 2024 18:14:59 GMT</pubDate>
    </item>
    <item>
      <title>lmer - 如何解释随机因素之间的相关性？</title>
      <link>https://stats.stackexchange.com/questions/651416/lmer-how-to-interpret-correlation-between-random-factors</link>
      <description><![CDATA[我的模型：
DV ~ 1 + 时间 * IV + (1 + 时间 | 受试者 ID)

其中 IV 是受试者间独立变量，时间 是受试者内重复测量。DV 是因变量。该模型没有收敛警告/问题。
这是随机效应表：
随机效应：
组名称方差标准差校正
受试者 ID（截距）1541413 1241.5
时间 322490 567.9 -0.75
残差 3172063 1781.0

Q1。 “强”相关性（即 &gt; .7）是什么意思，我应该如何在分析中解释它？
Q2。如果相关性是“强”甚至是 1，我是否应该按时间降低随机斜率，只保留 Subject_ID 的随机截距？
Q3。如果相关性是“弱”的（即 &lt;.3），这是什么意思，我应该如何在分析中解释它？]]></description>
      <guid>https://stats.stackexchange.com/questions/651416/lmer-how-to-interpret-correlation-between-random-factors</guid>
      <pubDate>Fri, 19 Jul 2024 16:30:43 GMT</pubDate>
    </item>
    </channel>
</rss>