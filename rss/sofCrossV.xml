<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 16 Jul 2024 21:15:17 GMT</lastBuildDate>
    <item>
      <title>扩散模型逆条件概率在以 x_0 导数为条件时易于处理</title>
      <link>https://stats.stackexchange.com/questions/651189/diffusion-model-reverse-conditional-probability-is-tractable-when-conditioned-on</link>
      <description><![CDATA[
有人能帮我理解$\widetilde{\beta}$和${\tilde\mu_t{(x_t, x_0)}}$是如何得出的吗？
在我看来，指数项是一个二阶多项式项，它看起来并不像$\frac{(x - \mu)^2}{2\sigma^2}$形式的高斯函数。
来源：https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#reverse-diffusion-process]]></description>
      <guid>https://stats.stackexchange.com/questions/651189/diffusion-model-reverse-conditional-probability-is-tractable-when-conditioned-on</guid>
      <pubDate>Tue, 16 Jul 2024 20:37:53 GMT</pubDate>
    </item>
    <item>
      <title>绘制连续变量的风险比、95% 可信区间</title>
      <link>https://stats.stackexchange.com/questions/651187/plot-hazard-ratio-95-ci-with-a-continous-variable</link>
      <description><![CDATA[R 可以生成这样的图形吗？
x 轴 = 年龄（连续），y 轴 = 每个计数的风险比？
我们的数据集：mydata，事件 = 死亡，事件发生时间 = 年，变量 = 年龄，组 = 治疗 (1) vs 对照 (0)
]]></description>
      <guid>https://stats.stackexchange.com/questions/651187/plot-hazard-ratio-95-ci-with-a-continous-variable</guid>
      <pubDate>Tue, 16 Jul 2024 20:00:34 GMT</pubDate>
    </item>
    <item>
      <title>从“nlme”阻止“gls”的引导实现</title>
      <link>https://stats.stackexchange.com/questions/651186/block-bootstrap-implementation-for-gls-from-nlme</link>
      <description><![CDATA[我有几个时间序列数据（天）的数据集，其中有些天有实验干预，其中一些数据集覆盖多个站点。我也有匹配的日级和站点级协变量。
要以混合效应方式（跨站点随机）分析这些数据，我可以使用 nlme 中的 lme，以固定效应方式（仅将站点视为自身或单个站点）分析这些数据，我可以使用 gls。因为我假设站点内误差存在序列相关性，所以我使用了这两个函数的 correlation 参数。
不过，我不太确定正态性，这就是我研究引导方法的原因。lmeresampler 包实现了“随机效应块引导”方法（Chambers &amp; Chandra 2013）适用于 lme，但没有相应的“固定效应块引导法”（我认为它只是每个组的块引导法）适用于 gls。
我的问题：是否有一个 R 包可以对 gls 执行 lmeresampler 对 lme 执行的操作？
我搜索了很多，但没有找到任何合适的东西。例如，rms 中的 Gls 具有内置引导法，但文档没有解释它是否可以处理序列相关性。boot 包中有 tsboot，但它是为纯时间序列模型设计的，而不是线性模型中的错误。我可能可以自己做点什么，但我不想 (a) 重新发明轮子和 (b) 犯错误。
或者，我还对除（随机效应）块引导之外的其他方法感兴趣，这些方法可以统一应用于 lme 和 gls 拟合。
虽然这个问题主要与软件/实现有关，但我认为需要统计专业知识才能理解或回答，因此（接近）主题。如果不是这种情况，请将我引导到其他地方。

玩具示例数据，gv 是“site”变量：
set.seed(123)
time &lt;- 0 : 9
data0 &lt;- data.frame(time) |&gt;
突变（
iv = as.numeric（时间 &gt;= 5），
dv = iv + as.vector（arima.sim（n = 10，list（ar = c（0.5）））），
gv = 0
）
data1 &lt;- data.frame（时间）|&gt;
mutate(
iv = as.numeric(time &lt; 5),
dv = 2 * iv + as.vector(arima.sim(n = 10, list(ar = c(0.5)))),
gv = 1
)
data &lt;- bind_rows(data0, data1)

混合效应分析和随机效应块引导：
lme_data &lt;- lme(
fixed = dv ~ 1 + iv,
random = ~ 1 | gv,
correlation = corAR1(form = ~ time | gv),
data = data
)
boot_lme_data &lt;- reb_bootstrap(
lme_data,
.f = extract_parameters,
B = 1000,
reb_type = 1
)
confint(boot_lme_data, type = &quot;perc&quot;)

固定效应分析，但没有块引导：
gls_data &lt;- gls(
model = dv ~ 1 + iv + gv,
correlation = corAR1(form = ~ time | gv),
data = data
)
boot_gls_data &lt;- # ???
]]></description>
      <guid>https://stats.stackexchange.com/questions/651186/block-bootstrap-implementation-for-gls-from-nlme</guid>
      <pubDate>Tue, 16 Jul 2024 19:55:07 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型中的多层建模与广义线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/651184/multilevel-modeling-in-linear-mixed-models-versus-generalized-linear-mixed-model</link>
      <description><![CDATA[我正在分析一个包含多个离散和连续结果变量 (DV) 的数据集。对于连续 DV，我打算使用在 SPSS 中处理的线性混合模型 (LMM)。对于离散变量，我有几个 DV 的评级范围是 1-100，其他 DV 的评级范围是 1-10。有人建议我对这些离散变量使用广义线性混合模型 (GLMM)。我知道其中一个主要原因是这些值不能低于 1，也不能高于 10。对于我的分析，这些限制实际上并不重要，因为我感兴趣的是一组预测因子（哪些预测因子具有较大的统计显著系数）导致的增加或减少量。超过限值（1-10 评级的负值和大于 10 的值）似乎并不重要，只有预测因子系数才重要。我对 GLMM 了解得越多，就越明白，使用不同的链接函数（logit、probit 等）解释系数可能是一个挑战。例如，根据分布和特定的预测因子集重新调整 1 级方差。考虑到这一点，有三个 (3) 个问题：

如果变量被视为“近似连续”，并且不关心下限或上限值，也不关心保留离散值（分数 OK），那么可以使用 LMM 完成离散 DV（1-100 或 1-10 评级量表）的分析吗？
如果仍然需要 GLMM，那么使用“线性模型”是否可行？目标分布（具有正态分布和身份链接）是否能更直接地解释重要的预测系数，更像 LMM，具有一致缩放的 1 级残差？
哪种目标分布链接/链接函数最适合 1-100 和 1-10 评分量表数据？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651184/multilevel-modeling-in-linear-mixed-models-versus-generalized-linear-mixed-model</guid>
      <pubDate>Tue, 16 Jul 2024 19:50:51 GMT</pubDate>
    </item>
    <item>
      <title>利用语义分割量化叶片病害</title>
      <link>https://stats.stackexchange.com/questions/651183/quantification-of-leaf-disease-with-semantic-segmentation</link>
      <description><![CDATA[我正在尝试使用原始图像和相应掩模的数据集来量化叶片疾病。我有两种方法：

用于叶片和患病区域的语义分割的训练-测试模型
使用训练后的模型预测图像，并使用严重程度指数公式计算患病区域和叶片的百分比

第二种方法是&quot;

用于叶片和患病区域的语义分割的训练-测试模型，并提供每片叶片患病区域的百分比
使用训练后的模型预测图像和百分比

哪种方法更合适、更准确？]]></description>
      <guid>https://stats.stackexchange.com/questions/651183/quantification-of-leaf-disease-with-semantic-segmentation</guid>
      <pubDate>Tue, 16 Jul 2024 19:47:30 GMT</pubDate>
    </item>
    <item>
      <title>关于 R 的 lme4 混合效应模型公式的建议</title>
      <link>https://stats.stackexchange.com/questions/651181/advice-on-mixed-effect-model-formula-for-rs-lme4</link>
      <description><![CDATA[我对混合效应模型和 lme4 还不熟悉，非常希望得到一些建议。
我的研究问题：哪些因素决定了企业每天的在线评论数量？
数据是横截面的，观察结果是企业。
因变量：在线评论数量（感兴趣的是其比率 = 每天的评论数量）
自变量要么与业务相关，要么与位置相关，如下表所示。除了集中度，位置因素不是我感兴趣的，因此被作为控制因素。
这是 4 行数据的样本。还有一些与企业和地点相关的变量，为了简洁起见，我省略了它们：

由于我的一个焦点独立变量（竞争对手的集中度）是在邮政编码级别，并且这些企业嵌套在邮政编码中（因此可以共享集中度值），所以我决定使用混合效应模型，将邮政编码作为随机效应。此外，由于因变量是计数，我决定使用泊松或负二项回归，以天数为偏移量。我在 R 中使用 lme4，我的问题主要围绕下面的公式以及它是否合理。以下是我对它的每个组成部分的推理和相关问题。我对混合效应还不熟悉，所以我问这些问题是为了确认我的理解。
公式：
在线评论数量 ~ 价格 * 集中度 + 提供的服务数量 + 偏移量（在线评论时间跨度的对数）+ (1|邮政编码) + (1|价格)

我需要将企业 ID 作为随机效应吗？(1|企业 ID)
价格 * 集中度：两者都是关键变量，我对它们的相互作用很感兴趣（例如，当集中度较低时，低价可能会增加评论数量，但当集中度较高时可能不会增加）。但集中度不是与业务相关的因素，而是与位置相关的因素。将其作为固定效应包括在内是否违反了观察独立性的假设？我应该改为 (1 + 价格 | 邮政编码) 吗？但这将与邮政编码有关，而不是直接与集中度有关
与上述问题相关，我如何控制人口密度和房屋中位价？我是否应该将它们添加为固定效应，即使它们是基于位置的，或者它们的影响已经被 (1|邮政编码) 捕获？
(1|价格)：我不确定这一点。价格只有 4 个级别，我认为这对于随机效应来说太少了？我可以根据价格概念化企业集群。这个行业中价格相似的企业相互竞争激烈。所以，我添加了它来排除基于集群的价格效应。
我说邮政编码和价格是“交叉的”对吗？也就是说，所有邮政编码都有相同的“低”、“中”、“高”和“非常高”价格水平。如果是，那是否意味着我应该在那里使用 (1|price)，即使它只有 4 个级别？
我说邮政编码和价格不是嵌套的，因为所有邮政编码中都存在相同级别的价格，所以 (1|zipcode\price) 是错误的，对吗？
我考虑过添加 (1 + price|concentration_categorical ) 作为随机效应，让价格的影响在浓度类别内变化，但浓度的范围很小（第 75 个百分位数为 4.7），我无法将其归类为 3-4 个以上类似大小的类别。对 (1 + price|concentration_categorical ) 有什么想法？
请随时解决您看到的任何其他问题，甚至可以重写公式来帮我理清思路。
]]></description>
      <guid>https://stats.stackexchange.com/questions/651181/advice-on-mixed-effect-model-formula-for-rs-lme4</guid>
      <pubDate>Tue, 16 Jul 2024 18:55:35 GMT</pubDate>
    </item>
    <item>
      <title>如何提高 LSTM 等深度学习时间序列预测模型的性能？[重复]</title>
      <link>https://stats.stackexchange.com/questions/651180/how-to-improve-performance-of-deep-learning-timeseries-forecasting-model-like-ls</link>
      <description><![CDATA[我有 5 年（2019 年 6 月 - 2024 年 6 月）的历史数据。数据为每日和 csv 文件格式。我有 4 个特征：数据、AQI、原始浓度、NowCast 浓度。我试图仅根据这些特征预测未来 AQI。我尝试了以下模型：

LSTM/LSTM-CNN/LSTM-RNN
Prophet/ARIMA/SARIMA

对于 Prophet/ARIMA/SARIMA，我在测试集和训练集上的模型性能都很差。
对于 LSTM/LSTM-CNN/LSTM-RNN，我的 R2 分数停留在 0.81。我尝试了网格搜索、退出、提前停止，但性能保持在 0.70 到 0.80 之间。我甚至尝试了不同的数据集（具有相同的特征），但性能仍然相同。我还能做什么？这是我最简单的模型，并进行了以下测试评估
均方误差 (MSE)：0.01
,R2 分数：0.80
,平均绝对误差 (MAE)：0.05
df[&#39;Date&#39;] = pd.to_datetime(df[&#39;Date&#39;])
df.set_index(&#39;Date&#39;, inplace=True)

# 指定特征
X = [0, 1, 2] # 输入特征的索引 (AQI、原始浓度、NowCast 浓度)
Y = [0] # 输出特征的索引 (AQI)

# 用于为 LSTM 创建序列的函数
def create_sequences(data, seq_length, input_features, output_features):
X, y = [], []
for i in range(len(data) - seq_length):
# 输入序列 (X) 从索引 i 到 i +指定特征的 seq_length
X.append(data[i:i + seq_length, input_features].astype(np.float32)) 
# 输出序列 (y) 是指定特征的下一个值 (i + seq_length)
y.append(data[i + seq_length, output_features].astype(np.float32)) 

return np.array(X), np.array(y)

# 设置序列长度并将数据拆分为训练集和测试集
seq_length = 30
train_size = int(len(df) * 0.8)
train_data = df.iloc[:train_size].values
test_data = df.iloc[train_size:].values

# 为 LSTM 创建序列
train_X, train_y = create_sequences(train_data, seq_length, X, Y)
test_X, test_y = create_sequences(test_data, seq_length, X, Y)

# 将数据转换为 PyTorch 张量
train_X = torch.tensor(train_X, dtype=torch.float32)
train_y = torch.tensor(train_y.reshape(-1, 1), dtype=torch.float32) # 重塑以匹配输出大小
test_X = torch.tensor(test_X, dtype=torch.float32)
test_y = torch.tensor(test_y.reshape(-1, 1), dtype=torch.float32) # 重塑以匹配输出大小

# 定义 LSTM 模型
class LSTMModel(nn.Module):
def __init__(self, input_size, hidden_​​size, num_layers, output_size):
super(LSTMModel, self).__init__()
self.hidden_​​size = hidden_​​size
self.num_layers = num_layers
self.lstm = nn.LSTM(input_size, hidden_​​size, num_layers, batch_first=True)
self.fc = nn.Linear(hidden_​​size, output_size)

def forward(self, x):
h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_​​size).to(x.device)
c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_​​size).to(x.device)
out, _ = self.lstm(x, (h0, c0))
out = self.fc(out[:, -1, :])
return out

# 初始化模型参数
input_size = len(X) # 输入特征数量（AQI、Raw Conc.、NowCast） Conc.)
hidden_​​size = 100
num_layers = 2
output_size = 1 # 预测 AQI

# 初始化模型、损失函数和优化器
model = LSTMModel(input_size, hidden_​​size, num_layers, output_size)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# 训练模型
num_epochs = 200
train_losses = []

for epoch in range(num_epochs):
model.train()
optimizer.zero_grad()
output = model(train_X)
loss = criterion(outputs, train_y)
loss.backward()
optimizer.step()
train_losses.append(loss.item())

if (epoch+1) % 10 == 0:
print(f&#39;Epoch [{epoch+1}/{num_epochs}]，损失：{loss.item():.4f}&#39;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/651180/how-to-improve-performance-of-deep-learning-timeseries-forecasting-model-like-ls</guid>
      <pubDate>Tue, 16 Jul 2024 18:52:23 GMT</pubDate>
    </item>
    <item>
      <title>可以针对两点进行假设检验吗？</title>
      <link>https://stats.stackexchange.com/questions/651179/can-hypothesis-testing-be-done-on-two-points</link>
      <description><![CDATA[我为一些岛屿设置了以下内容（每个岛民的数据均可用，整个人口的数据也可用）：

2000 年：

成年人口总数：260,000；
健康成年人数量：250,000
患病成年人数量：10,000
健康率：250,000/260,000 = 0.961


2001 年：

成年人口总数：265,000；
健康成年人数量：261,000
患病成年人数量： 4,000
健康率：261,000/265,000 = 0.984



我想看看 2000 年岛上的健康率与 2001 年岛上的健康率在统计上是否有差异。
我的问题是只有两个比率可供比较，因此样本量为 2（即使每个比率本身都是根据大量人口计算的）。
即使只有两个点可供比较，这里还能进行假设检验吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651179/can-hypothesis-testing-be-done-on-two-points</guid>
      <pubDate>Tue, 16 Jul 2024 18:35:54 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助理解随时间变化的优势比示例</title>
      <link>https://stats.stackexchange.com/questions/651177/need-help-understanding-odds-ratio-over-time-example</link>
      <description><![CDATA[我正尝试重新创建一篇论文，该论文比较了重复急诊就诊（即同一患者在过去 12 个月内因同一原因再次就诊）与单次急诊就诊的频率和特征。其中，“使用逻辑回归计算了随时间推移重复急诊就诊与单次急诊就诊的概率。给出了未调整的优势比；未控制其他变量。”没有提供其他详细信息。
在他们展示比值比的部分中，他们展示了一个聚类条形图，显示了 2018-2022 年每年的急诊就诊次数（单次或重复）的百分比。5 年来，每年重复就诊的百分比略有增加。他们给出的未调整优势比为 1.108“这表明，每年，个人重复急诊就诊而不是单次急诊就诊的几率增加 11% (p&lt;.001)。&quot;
这是否意味着，为了获得未调整的优势比，我应该运行逻辑回归，其中独立变量是急诊就诊的年份，因变量为 0/1（单次/重复）？我很难理解这种情况下独立变量是什么。
我确实尝试过这个（使用 sklearn.LogisticRegression），得到了 0.99 的优势比，这没有意义。我认为我应该将年份向量转换为 1-5 而不是 2018-2022，对吗？
我离题太远了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651177/need-help-understanding-odds-ratio-over-time-example</guid>
      <pubDate>Tue, 16 Jul 2024 18:28:36 GMT</pubDate>
    </item>
    <item>
      <title>Cox 比例风险模型的功效分析</title>
      <link>https://stats.stackexchange.com/questions/651176/power-analysis-for-the-cox-proportional-hazards-model</link>
      <description><![CDATA[我正在尝试根据一项小型研究计算出 RCT 所需的样本量，该研究研究了指数手术后的再次手术。在这项小型研究中，有 1000 名患者，第 1 组有 700 名，第 2 组有 300 名患者。第 1 组中有 20 名再次手术，第 2 组中有 30 名再次手术。但是，第 1 组的 10 年生存率为 15%，第 2 组的 10 年生存率为 12%。因此，大多数患者不再面临再次手术的风险。我想知道如何计算 RCT 所需的样本量，以 1:1 随机分配，并观察如果对患者进行 10 年的随访，考虑到随访期间的死亡，各组之间的风险比是否会降低 0.10？我的 stata 代码目前如下所示
power cox, hratio(0.90) alpha(0.05) power(0.80)]]></description>
      <guid>https://stats.stackexchange.com/questions/651176/power-analysis-for-the-cox-proportional-hazards-model</guid>
      <pubDate>Tue, 16 Jul 2024 18:17:39 GMT</pubDate>
    </item>
    <item>
      <title>将五点李克特量表转换为均匀量表</title>
      <link>https://stats.stackexchange.com/questions/651175/converting-five-point-likert-scale-to-uniform-scale</link>
      <description><![CDATA[*我正在开展一个荟萃分析项目，其中包括来自不同出版物的平均值和 SD 值。它们有不同的尺度。一些是基于 0 到 100 的视觉模拟量表计算的分数平均值和 SD。一些是基于 1 到 10 的视觉模拟量表，增量为 0.5，其他是基于李克特量表（5 分制，1 到 5）的分数平均值和 SD。
所以我考虑重新缩放平均值和 SD 值（标准化平均值和 SD 的值并获取平均值和 SD 的新值）以分析和比较它们。我应该怎么做？*]]></description>
      <guid>https://stats.stackexchange.com/questions/651175/converting-five-point-likert-scale-to-uniform-scale</guid>
      <pubDate>Tue, 16 Jul 2024 18:16:09 GMT</pubDate>
    </item>
    <item>
      <title>灌注分析算生存分析吗？</title>
      <link>https://stats.stackexchange.com/questions/651173/perfusion-analysis-counts-as-survival-analysis</link>
      <description><![CDATA[在灌注分析中，患者被注射一定剂量的药物。机器会随着时间的推移检测患者体内的药物剂量。换句话说，每个患者的数据是时间点 $0=t_0 &lt; t_1 &lt; \cdots &lt; t_N$ 和剂量 $y_1, \ldots, y_N$，其中 $y_i \in [0, \infty)$ 表示时间 $t_i$ 时患者体内的剂量。 （通常，$y_i$ 也可以是某种间接的剂量测量值。）根据具体情况，可能只有一名患者或多名患者，或者患者被分成几组等。我们只强调一个假设：给定时间 $t$，任何患者在时间 $t$ 的剂量都是随机的，因此这不是机器学习任务。
当我们绘制所有对 $(t_i,y_i)$ 时，形状通常看起来像一些集中在 $[0, \infty)$ 上的分布的概率密度函数（例如对数正态分布、威布尔分布、指数分布，...）
统计学家的任务通常是调查趋势，推断例如剂量何时达到峰值，剂量何时上升等。解决问题的一种方法是与客户交谈，根据信念拟合概率密度函数，然后查看任务。
例如，假设只有一名患者，我们想要估计剂量何时达到峰值。我们可以说在与客户讨论后，用对数正态分布的概率密度函数拟合数据，选择参数以最小化最小二乘，然后查看拟合的最大值。
问题：统计员的任务名称是什么？这样的任务算生存分析吗？时间序列分析？我倾向于称之为生存分析，但我不确定，因为在这种情况下，生存分析中的典型工具似乎不可用。]]></description>
      <guid>https://stats.stackexchange.com/questions/651173/perfusion-analysis-counts-as-survival-analysis</guid>
      <pubDate>Tue, 16 Jul 2024 18:14:45 GMT</pubDate>
    </item>
    <item>
      <title>有限的结果事件。方法的选择</title>
      <link>https://stats.stackexchange.com/questions/651170/limited-outcome-events-choice-of-method</link>
      <description><![CDATA[我正在对罕见事件进行研究。我比较了两个组 A（n=50）和 B（n=200），但我发现结果事件比预期的要少，A（n=12），B（n=4）。我可以将这些数据用于任何有意义的目的吗？还是统计不确定性太大？我打算进行多变量分析（cox reg），但如果变量超过 1-2 个，这将失败？
谨致问候，
H]]></description>
      <guid>https://stats.stackexchange.com/questions/651170/limited-outcome-events-choice-of-method</guid>
      <pubDate>Tue, 16 Jul 2024 17:57:08 GMT</pubDate>
    </item>
    <item>
      <title>汇集参与者数据以解决每种情况的试验数量有限问题</title>
      <link>https://stats.stackexchange.com/questions/651169/pooling-participant-data-to-resolve-limited-trials-per-condition-issues</link>
      <description><![CDATA[问题：在一项实验任务中，有 4 种条件，每种条件只有 2 次试验，因此每个参与者有 8 次观察。通常，我们使用信号检测理论 (SDT) 来计算描述性统计数据，例如命中率 (H) 或 d prime(d’)，然后执行推断统计（例如，对 4 种条件的准确度进行重复测量方差分析）。但是，每个参与者每个条件的试验次数很少，因此无法准确计算这些统计数据。SDT 标准要求，对于给定的统计数据（例如命中率 H），要被视为有效且呈正态分布，每个条件的试验次数 (N) 必须满足不等式 NH &gt; 5 和 N(1-H) &gt; 5. 每种情况只有两次试验，这些条件无法满足。
可能的解决方案：为了解决这个问题，我正在考虑两个潜在的解决方案（第二个解决方案似乎是第一个解决方案的更好版本）：

将 200 名参与者分成 25 组，每组 8 人，将他们的回答结合起来形成“宏观参与者”。每个宏观参与者每个条件将有 16 次试验，从而可以有效计算 SDT 描述性统计数据。然后可以对这些进行常规分析，例如，使用 ANOVA 比较 4 种条件下的表现。
使用受 Bootstrap 启发的重采样方法来创建宏观参与者：随机抽样 10,000 组 8 名参与者（有替换）以形成 10,000 名宏观参与者，用于计算 SDT 统计数据，然后用于推断统计。

我的问题是：

这样的解决方案在统计上有效吗？

如果有效，第二种方法（使用 Bootstrap）是否更可取？

这种方法是否有特定的名称，我可以使用它来查找更多参考资料？ （或相关关键词，如池化、合并、合并、聚合等）

我们如何解决每个宏观参与者内部的数据依赖性问题？


提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/651169/pooling-participant-data-to-resolve-limited-trials-per-condition-issues</guid>
      <pubDate>Tue, 16 Jul 2024 17:40:02 GMT</pubDate>
    </item>
    <item>
      <title>稳定逆概率加权 (IPW) 的夹心方差估计量或基于引导的方差</title>
      <link>https://stats.stackexchange.com/questions/651142/sandwich-variance-estimator-or-bootstrap-based-variance-for-stabilized-inverse-p</link>
      <description><![CDATA[多篇已发表的论文将 IPW 描述为类似于拥有多个相同个体副本的种群。因此，在提供权重的后续分析中，应使用夹心方差估计量或基于 bootstrap 的方差来计算和校正相关性。老实说，我不相信这一点，因为它是一个伪种群，而不是实际种群。
对于稳定的二元暴露 IPTW 权重，总样本量与预加权相同（即没有人为地增加样本量）。这是否意味着不需要使用夹心方差估计量或基于 bootstrap 的方差？如果是，二元结果是否需要它？]]></description>
      <guid>https://stats.stackexchange.com/questions/651142/sandwich-variance-estimator-or-bootstrap-based-variance-for-stabilized-inverse-p</guid>
      <pubDate>Tue, 16 Jul 2024 10:39:54 GMT</pubDate>
    </item>
    </channel>
</rss>