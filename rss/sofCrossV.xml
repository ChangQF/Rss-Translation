<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 26 Aug 2024 12:30:04 GMT</lastBuildDate>
    <item>
      <title>为什么我们在核（SVM）环境中使用点积？</title>
      <link>https://stats.stackexchange.com/questions/653330/why-we-use-dot-product-in-the-context-of-kernels-svm</link>
      <description><![CDATA[如果数据包含非线性模式，则可以改变数据的维度，然后找到分离超平面。这可以通过 SVM 框架内的核函数来实现。此处 展示了此技术的出色可视化效果。
我确实明白，例如，如果数据是一维的，然后将数据的维度更改为二维，就可以看到如何用线分隔数据。例如，$X=\{x_1, x_2, ... x_n\}$ 数据可以转换为 $\{X,Y\}=\{(x_1,x_1^2), (x_2,x_2^2), ..., (x_n,x_n^2)\}$，然后以 2D 形式用线分隔。更正式地，可以对 2D 数据应用 $\phi(\cdot)$ 变换，以将其映射到 3D，方式如下：
$$\phi(x,y)=(x^2,\sqrt2xy,y^2).$$
这种转换对我来说很有意义。但是，据充分证明，这种映射技术成本高昂，因此我们应用所谓的核，它隐式地执行相同的操作。核函数应用于 2 个点，即 $(x^{(1)}, y^{(1)})$ 和 $(x^{(2)}, y^{(2)})$。为什么不分别转换每个点？在这种情况下，点积有什么关系？核技术与上面描述的映射有何相同之处？我看不出它们之间的联系。]]></description>
      <guid>https://stats.stackexchange.com/questions/653330/why-we-use-dot-product-in-the-context-of-kernels-svm</guid>
      <pubDate>Mon, 26 Aug 2024 12:25:14 GMT</pubDate>
    </item>
    <item>
      <title>原始数据不具有季节性，但同一数据的对数的一阶差分存在季节性问题</title>
      <link>https://stats.stackexchange.com/questions/653328/no-seasonality-in-the-original-data-while-there-exist-seasonality-problem-in-the</link>
      <description><![CDATA[我正在研究 PPI 数据。当我检查原始数据中是否存在季节性时，没有季节性问题。
但是，当我对 PPI 数据的自然对数取一阶差分形式时，我检测到了季节性问题的存在。
这正常吗？为什么会出现这样的问题？我将使用一阶差分形式。那么，我应该对一阶差分形式进行去季节性处理吗？
请与我分享您的想法和知识。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/653328/no-seasonality-in-the-original-data-while-there-exist-seasonality-problem-in-the</guid>
      <pubDate>Mon, 26 Aug 2024 12:22:25 GMT</pubDate>
    </item>
    <item>
      <title>对于时间相关的序列数据集（例如随时间推移的故障记录），有哪些适当的数据拆分技术？</title>
      <link>https://stats.stackexchange.com/questions/653327/what-are-the-appropriate-data-splitting-techniques-for-time-dependent-sequential</link>
      <description><![CDATA[我正在处理一个时间相关的顺序数据集，具体来说是一段时间内机器故障的记录。我的数据集包括来自多台机器的传感器的数据，直到它们发生故障并需要准备；修复后，机器会再次发送数据。我想开发一个机器学习模型来根据这些数据预测剩余的使用寿命。
我理解，将数据集随机拆分为训练集、验证集和测试集可能会导致过度拟合问题，因为如果拆分不遵循事件的时间顺序，训练集和测试集中可能会有共同的数据点。
考虑到我的数据具有时间依赖性，拆分数据集以确保我的模型能够很好地推广到未见过的数据的最合适技术是什么？我曾经想过对数据集进行划分

按照机器，为每个数据集保留一些。
按照时间段，为每个数据集保留修复和分解之间的一些时间段。

但是，在这种情况下，是否有标准的数据划分技术？]]></description>
      <guid>https://stats.stackexchange.com/questions/653327/what-are-the-appropriate-data-splitting-techniques-for-time-dependent-sequential</guid>
      <pubDate>Mon, 26 Aug 2024 11:06:47 GMT</pubDate>
    </item>
    <item>
      <title>成功概率的无偏估计</title>
      <link>https://stats.stackexchange.com/questions/653325/unbiased-estimate-of-success-probability</link>
      <description><![CDATA[通常，我们假设独立性来估计成功概率，即在抛硬币示例中正面朝上的概率。意味着我们抛硬币$n$次，看看有多少次正面，该比率是正面朝上概率的无偏估计。
然而在现实生活中，这些事件总是不独立的。例如，由于某些环境原因，如果出现正面，那么下一个结果也可能是正面的可能性更高。
所以我的问题是，对于这种不相关情况，样本比率是否仍然是成功概率的无偏估计？或者，我们需要对样本比率进行一些相关性调整以获得成功概率的无偏估计？
任何见解或书籍/在线参考资料都将非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653325/unbiased-estimate-of-success-probability</guid>
      <pubDate>Mon, 26 Aug 2024 10:59:09 GMT</pubDate>
    </item>
    <item>
      <title>多元时间序列中异常检测的统计方法[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653324/statistical-approach-for-anomaly-detection-in-multivariate-time-series</link>
      <description><![CDATA[我正在研究运动实验的异常检测问题（相同类型的运动），并需要有关统计方法的建议（没有 ML，因为我没有足够的数据）。以下是上下文：
数据集：

在相同电机上进行 46 次实验
每次实验 4 个阶段，每个阶段的运行次数不定
每次运行 35 个步骤测量 12 个特征（每次运行 35x12 数据帧）
阶段 1-3 在一台机器上，阶段 4 在另一台机器上
15 个电机标记为“运行”，2 个电机标记为“非运行”，其余电机未标记

过程：

阶段 1：电机预热（3-5 次运行）
阶段 2-3：通过铣削去除质量（相同过程，不同平面）（3-11 次运行）
阶段 4：在另一台机器上测试（无铣削） （3-7 次运行）
最终分类的声学测试（细节和数据与此无关。仅分类）

限制：

由于数据有限，更喜欢统计方法而不是机器学习
许多特征在运行和阶段之间高度相关

问题：

哪些统计方法适合在此多阶段过程中进行异常检测？我脑子里很乱，这是我的第一个异常检测项目。
是否应针对每个阶段单独执行异常检测？
如何处理每个阶段的可变运行次数？
是否有特定的统计测试（例如 A/B 测试）可能在这里有用？
那么孤立森林、K 均值、聚类、PCA、高斯分布呢？

如上所述，我想分别检测每个特征中的异常。理想情况下，找到特征之间的相关性，并推断当特征 5 遵循特定模式时，特征 1 中正在发生特定模式。这是我的第一个项目，考虑到大量的数据，这是令人难以承受的，很难想象正确的方法。也许首先将数据减少到 6 个特征，因为我怀疑 4 个特征与我拥有的 2 个加速特征相关。
如能就构建此分析或应用特定统计技术提出任何建议（数据预处理和构建的步骤、要使用的算法和统计方法等），我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653324/statistical-approach-for-anomaly-detection-in-multivariate-time-series</guid>
      <pubDate>Mon, 26 Aug 2024 08:51:13 GMT</pubDate>
    </item>
    <item>
      <title>数据集是否足以进行回归分析？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653323/is-data-set-enough-for-regression-analysis</link>
      <description><![CDATA[我需要对我的论文（面板数据）进行回归分析，但是我的数据集非常小。我只有 6 家公司需要研究（11 年的年度数据），而我所研究的行业实际上只有 7 家公司。您能否解释一下为什么 6 家公司不足以进行这种回归分析？或者也许您有有用的资料供我阅读。]]></description>
      <guid>https://stats.stackexchange.com/questions/653323/is-data-set-enough-for-regression-analysis</guid>
      <pubDate>Mon, 26 Aug 2024 08:33:10 GMT</pubDate>
    </item>
    <item>
      <title>是否采用方差分析 (虚拟变量交互) 的“嵌套”模型</title>
      <link>https://stats.stackexchange.com/questions/653322/nested-model-or-not-for-anova-dummy-variable-interaction</link>
      <description><![CDATA[我正在尝试学习，但发现有点奇怪。假设我们有两个回归模型，其中只有虚拟变量取值为 0 或 1。假设 $a+b+c+d$ 是 $1$ 第一个模型的系数，而 $a+b+(c:d)$ 是
$2$ 第二个模型的系数（即，我们排除虚拟变量 $c$ 和 $d$ 的主要影响的交互作用）。
第二个模型是否嵌套在第一个模型中，因此适合方差分析？我知道嵌套模型不是单一定义，但我的问题具体是针对 ANOVA。
我是新手，但我的论点是 $\textbf{yes}$:
为了证明 $a + b + c \cdot d$ 嵌套在 $a + b + c + d$ 中，我们需要证明 $a$、$b$、$c$ 和 $c$ 的所有可能值，$a + b + c \cdot d \leq a + b + c + d$ class=&quot;math-container&quot;&gt;$d$，其中每个变量可以是 0 或 1。
$\textbf{情况 1：}$ $c = 0$ 或 $d = 0$
如果 $c = 0$ 或 $d = 0$，则 $c \cdot d = 0$，因此表达式简化为
$$
a + b + 0 = a + b。
$$
另一方面，$a + b + c + d$ 简化为 $a + b + c + d$，这显然大于或等于 $a + b$。因此，
$$
a + b + c \cdot d \leq a + b + c + d。
$$
$\textbf{案例 2：}$ $c = 1$ 和 $d = 1$
如果 $c = 1$ 和 $d = 1$ 都成立，则 $c \cdot d = 1$，从而得出表达式
$$
a + b + 1。
$$
表达式 $a + b + c + d$ 变为
$$
a + b + 1 + 1 = a + b + 2，
$$
所以$a + b + 1 \leq a + b + 2$。因此，
$$
a + b + c \cdot d \leq a + b + c + d
$$
在这种情况下也成立。]]></description>
      <guid>https://stats.stackexchange.com/questions/653322/nested-model-or-not-for-anova-dummy-variable-interaction</guid>
      <pubDate>Mon, 26 Aug 2024 08:32:24 GMT</pubDate>
    </item>
    <item>
      <title>如何指定具有两个调节器（分类和连续）的回归三向交互作用[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653321/how-to-specify-a-regression-with-two-moderators-categorical-and-continuous-3-w</link>
      <description><![CDATA[在一个有两个调节器（连续变量和 2 级分类变量）的项目中，当我主要对三向交互本身感兴趣时，我不确定是否需要 Hayes（模型 3）指定的以下所有交互。
Hayes 规范：Y=b0​+b1​X+b2​M1+b3​M2+b4​(X×M1)+b5​(X×M2)+b6​(M1×M2)+b7​(X×M1×M2)+e
可以更简约一点，省去 b6(M1 x M2) 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653321/how-to-specify-a-regression-with-two-moderators-categorical-and-continuous-3-w</guid>
      <pubDate>Mon, 26 Aug 2024 08:32:18 GMT</pubDate>
    </item>
    <item>
      <title>以稳定人格特质作为预测因子的纵向模型</title>
      <link>https://stats.stackexchange.com/questions/653320/longitudinal-model-with-stable-personality-trait-as-predictor</link>
      <description><![CDATA[我们计划使用稳定的人格特质进行纵向分析，以预测特定技能随时间的发展。最初，我想运行一个交叉面板模型，以测试该技能是否也会随时间影响人格特质。但是，我逐渐意识到交叉面板模型（CLPM 或 RI-CLPM）不适合进行此类分析，因为这些模型不模拟稳定特质：

Asendorpf 可能对以下过程感兴趣：稳定的预测因子（例如父母高估）影响从每一波到下一波结果变化的量或可能性。 RI-CLPM 和 STARTS 模型等模型无法捕捉稳定特征对每次波动变化的因果影响。

来源：https://journals.sagepub.com/doi/10.1177/25152459231158378
然后，作者引用了其他论文，这些论文指定了尝试这样做的模型，例如 Bollen 和 Brand 的方法：https://pubmed.ncbi.nlm.nih.gov/34914469/
但是，我不太确定我是否完全理解了这篇论文。因此，下面我描述了我感兴趣的模型。请给我反馈，看看这是否有意义。
我感兴趣的模型是 T1 时的性格特征预测 T2 和 T3 时的技能水平，同时控制技能水平的时间不变稳定方差（以解释不是由我们感兴趣的性格特征引起的方差）。
我将附上 SEM 模型的粗略说明，其中方块是问卷项目，圆圈是潜在变量，η 表示我们不感兴趣的时间不变方差（与 RI-CLPM 中控制的相同）。我们假设技能水平在 T1 时接近于零（因此技能和特征之间没有先前的关系）。这是否是一个合适的模型来检验我们的假设，即人格特质的受试者间差异会影响这种特定技能的发展？

我在这里只包括人格特质 T1，但我们也会在后续 T 中测量该特质。鉴于对跨面板模型的批评，我不确定是否适合包括假设的“稳定”特征的后续测量，以及如何将其包含在模型中而不会引起复杂化。]]></description>
      <guid>https://stats.stackexchange.com/questions/653320/longitudinal-model-with-stable-personality-trait-as-predictor</guid>
      <pubDate>Mon, 26 Aug 2024 07:46:37 GMT</pubDate>
    </item>
    <item>
      <title>ADADELTA 论文问题关于分母是 Hessian 近似的说法</title>
      <link>https://stats.stackexchange.com/questions/653318/adadelta-paper-question-about-the-claim-that-the-denominator-is-a-hessian-approx</link>
      <description><![CDATA[在论文ADADELTA：一种自适应学习率方法中，在第 3.2 节的末尾，声明

... [提议的] 方法与 Schaul 等人的方法相关，因为对 Hessian 进行了一些近似，但通过利用过去更新的信息，每次迭代只需要一次梯度计算。

在 Schaul 等人的论文中，分母包括项
|diag(Ht)|

这显然是 Hessian 对角线的幅度。
然而，在 Adadelta 论文中，分母项由以下公式给出
RMS[g]t = √(E[g^2]t + eps)

其中 E[g^2]t 定义为
E[g^2]t = ρ E[g^2]t−1 + (1 − ρ) g^2

我不明白 E[g^2]t 如何可描述为 Hessian 的某种近似值。
Hessian 的近似方法之一是通过有限差分，例如
g[t] - g[t-1]

平方
h[t]^2 = (g[t])^2 + (g[t-1])^2 - 2(g[t])(g[t-1))

这可能是为了稳定性而求动量平均值并求平方根。我认为这可能与 RMS[g]t 的数字有很大不同
我完全看不出 Hessian 是如何参与其中的。我遗漏了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653318/adadelta-paper-question-about-the-claim-that-the-denominator-is-a-hessian-approx</guid>
      <pubDate>Mon, 26 Aug 2024 07:20:59 GMT</pubDate>
    </item>
    <item>
      <title>解释 GAM 输出中的随机效应：高斯分位数</title>
      <link>https://stats.stackexchange.com/questions/653308/interpreting-random-effect-in-gam-output-gaussian-quantiles</link>
      <description><![CDATA[模型运行良好。对于因子，解释效果更容易。对于因子水平被分配了随机效应的变量，输出/图并不直观。我试图解释的图包括因子水平作为点、y 轴上的效应和 x 轴上的高斯分位数。有一条直线穿过这些点，看起来是线性正的。
如何解释这些因子变量的图？穿过这些点的线是什么意思？图顶部的 8.8 是什么意思？非常感谢任何解释方面的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653308/interpreting-random-effect-in-gam-output-gaussian-quantiles</guid>
      <pubDate>Sun, 25 Aug 2024 22:22:54 GMT</pubDate>
    </item>
    <item>
      <title>Clopper-Pearson 区间的渐近一致性</title>
      <link>https://stats.stackexchange.com/questions/653299/asymptotic-consistency-of-the-clopper-pearson-interval</link>
      <description><![CDATA[我有一系列随机变量 $X_n \sim Bin(n,p)$，我想声明对于每个置信水平 $c \in (0,1)$，$ClopperPearsonLower(X_n, n, c)$ 都以概率收敛到 $p$，也就是说对于每个 $\epsilon&gt;0$：$Pr[|ClopperPearsonLower(X_n, n,c) - p| &gt; \epsilon]\stackrel{n\to\infty}{\longrightarrow}0$。
这是真的吗？如果是这样，我很乐意提供一本可以参考的书。]]></description>
      <guid>https://stats.stackexchange.com/questions/653299/asymptotic-consistency-of-the-clopper-pearson-interval</guid>
      <pubDate>Sun, 25 Aug 2024 17:01:22 GMT</pubDate>
    </item>
    <item>
      <title>R 平方因果推断</title>
      <link>https://stats.stackexchange.com/questions/653295/r-squared-causal-inference</link>
      <description><![CDATA[我想知道在评估系数时，较低的 R 平方值是否会造成问题。我的人群被分为两组（A 和 B），我想评估它们之间在因变量方面是否存在显著差异。我在回归中加入了几个控制变量，但 R 平方值非常低（&lt;0.05）。我应该担心这个问题吗？添加更多控制变量是否明智？
假设我想在学术期刊上发表结果，这会造成问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653295/r-squared-causal-inference</guid>
      <pubDate>Sun, 25 Aug 2024 15:42:45 GMT</pubDate>
    </item>
    <item>
      <title>积极性假设和条件可交换性</title>
      <link>https://stats.stackexchange.com/questions/653289/positivity-assumption-and-conditional-exchangeability</link>
      <description><![CDATA[让我们想象一个简单的传统场景：A &lt;--- L ---&gt; Y 和 A ---&gt; Y。因此，我们有暴露 A（治疗和未治疗）和结果 Y。L 代表混杂因素。对于我的具体问题，它需要一个多维 L（即多个变量）。此外，我们可以假设这些协变量 L 足以调整 A 和 Y 之间的所有混杂因素（条件可交换性）。我的目标是估计 ATE {E(Y^1 - Y^0)}。
我继续使用任何类型的去偏机器学习，允许我估计 E(Y^1) 和 E(Y^0)。完成后，我会取一个简单的差值。到目前为止，一切都很好。
然而，在查看结果后，我决定调查逆概率权重（1/接受治疗的概率），并意识到有些人接受治疗的机会很小。因此，积极性假设（几乎肯定）被违反。根据我的理解，这个假设意味着每个人，无论其协变量如何，接受每个治疗水平的概率都是非零的。它确保对于 L 的每个级别，都有治疗和控制条件的数据。
然而，考虑到我们可以假设条件可交换性，这种情况似乎很奇怪。换句话说，为了使条件可交换性成为有意义且可测试的条件，它预先假定在数据中观察到的每个 L 级别必须同时具有治疗和未治疗的个体。如果不是这种情况（即违反积极性），那么协变量空间 L 的子集将无法观察，从而无法验证潜在结果是否确实与治疗分配无关。如果不是这种情况，我不明白什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/653289/positivity-assumption-and-conditional-exchangeability</guid>
      <pubDate>Sun, 25 Aug 2024 12:26:59 GMT</pubDate>
    </item>
    <item>
      <title>R 中非平方列联表中名义数据的配对检验</title>
      <link>https://stats.stackexchange.com/questions/653275/paired-test-on-nominal-data-in-a-non-squared-contingency-table-in-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653275/paired-test-on-nominal-data-in-a-non-squared-contingency-table-in-r</guid>
      <pubDate>Sat, 24 Aug 2024 16:41:06 GMT</pubDate>
    </item>
    </channel>
</rss>