<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 16 Aug 2024 18:20:47 GMT</lastBuildDate>
    <item>
      <title>左偏分布的中位数和平均值之间的关系[重复]</title>
      <link>https://stats.stackexchange.com/questions/652936/relationship-between-median-and-mean-of-a-left-skewed-distribution</link>
      <description><![CDATA[问题
如果我从图形上看到我的分布是左偏的。如何具体（仍然定性地）得出平均值小于中位数的结论？至少在非病理性例子中？
可能存在重复，但接受的答案或其他答案并没有解决我的疑问，事实上他们专注于说，这个说法在最一般的环境中是不正确的。
想法
当我尝试查找它时，我总是发现一个论点说，由于数据是左偏的，尾部向左偏得很远，一些异常值会使平均值比中位数下降更多。但这听起来只是重申了我的疑问。为什么如果平均值降低，它会低于中位数？]]></description>
      <guid>https://stats.stackexchange.com/questions/652936/relationship-between-median-and-mean-of-a-left-skewed-distribution</guid>
      <pubDate>Fri, 16 Aug 2024 17:43:57 GMT</pubDate>
    </item>
    <item>
      <title>使用 CVXPY 解决逻辑回归问题</title>
      <link>https://stats.stackexchange.com/questions/652935/solving-logistic-regression-using-cvxpy</link>
      <description><![CDATA[我正在尝试使用 CVXPY 库编写逻辑回归模型。到目前为止，我编写的代码“有效”，因为它可以执行，不会产生任何错误消息并提供解决方案。但是，此解决方案与 scikit-learn 逻辑回归实现提供的解决方案不匹配。
我知道 scikit-learn 实现默认包含 L2 惩罚，在下面的代码示例中，您将看到我将其更改为 None。我还从 sklearn 模型中删除了截距。但解决方案仍然不匹配：
import cvxpy as cp
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression

X, y = make_classification(n_features=10, random_state=42)

sk = LogisticRegression(penalty=None, fit_intercept=False)
sk.fit(X, y)
print(sk.coef_)

这将产生输出：
[[-13.46939518 -7.09935934 19.41989522 -10.36990818 3.76335965
2.84616038 3.32474461 -2.84162961 3.13246888 1.08887971]]

现在，cvxpy 实现：
beta = cp.Variable(X.shape[1])
log_likelihood = cp.sum(cp.multiply(y, X @ beta) - cp.logistic(X @ beta))
problem = cp.Problem(cp.Maximize(log_likelihood/X.shape[0]))
problem.solve()
beta = beta.value
print(beta)

产生解决方案：
[-31.38130594 -10.72178524 44.07489985 -34.06127916 8.01950276
5.96941765 9.6143194 -7.88785049 12.96349703 -0.13264449]
]]></description>
      <guid>https://stats.stackexchange.com/questions/652935/solving-logistic-regression-using-cvxpy</guid>
      <pubDate>Fri, 16 Aug 2024 17:28:02 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用卡方统计量来根据 60,000 个值的经验数据集评估理论 PDF 吗？</title>
      <link>https://stats.stackexchange.com/questions/652934/can-i-use-the-chi-square-statistic-to-evaluate-theoretical-pdfs-against-an-empir</link>
      <description><![CDATA[我有一个包含 60,000 个数值的数值模拟数据集。
我正在测试 4 个理论 PDF（gamma、beta、Weibull 和对数正态）与该数据的拟合度，其中分布的参数是根据数据估算的。
我可以使用卡方统计量来比较这些分布的拟合优度吗？或者卡方统计量不适合此目的，尤其是考虑到我的数据集很大？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652934/can-i-use-the-chi-square-statistic-to-evaluate-theoretical-pdfs-against-an-empir</guid>
      <pubDate>Fri, 16 Aug 2024 17:15:30 GMT</pubDate>
    </item>
    <item>
      <title>斜率误差是否更能代表线性拟合的变异性或拟合优度 (R2)？</title>
      <link>https://stats.stackexchange.com/questions/652932/error-of-the-slope-that-is-more-representative-of-the-variability-around-the-lin</link>
      <description><![CDATA[我有 2 个不同长度的数据集，一个比另一个大得多（图片中的绿松石点）。我用一条没有截距的线来拟合它们，因此斜率是唯一的自由参数。拟合程序返回斜率误差。绿松石点的斜率误差（标准误差）比黑色点的斜率误差低得多。我知道这是由于样本量大。但是黑点的 R2 高于绿松石点。有没有办法得到反映 R2 行为的斜率误差估计？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652932/error-of-the-slope-that-is-more-representative-of-the-variability-around-the-lin</guid>
      <pubDate>Fri, 16 Aug 2024 15:32:40 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯 Cramer-Rao 下限计算的困惑</title>
      <link>https://stats.stackexchange.com/questions/652931/confusion-on-bayesian-cramer-rao-lower-bound-calculation</link>
      <description><![CDATA[我正在研究 Cramer-Rao 下限 (CRLB)，并利用先前的知识来了解非视距 (NLOS) 造成的额外长度。我正在阅读的文章是关于非视距环境中使用先前信息的地理定位准确性和非视距环境中无线地理定位的分析。两篇文章均来自同一作者，并讨论了类似的事情。扩展CRB算法的公式为
$J = \frac{1}{c^2}\left( \begin{bmatrix} H_{NL}\Lambda_{NL}H_{NL}^T+H_{L}\Lambda_{L}H_{L}^T &amp; H_{NL}\Lambda_{NL} \\ \Lambda_{NL}H_{NL} &amp; \Lambda_{NL}+c^2\Omega \end{bmatrix} \right)$,
其中$H_{NL}$和$H_{L}$分别是NLOS和LOS基站的角度矩阵。 $\Lambda$ 表示从接收信号计算出的对角矩阵 $\text{diag}8\pi^2\beta^2\cdot R_b$。$\Omega = \text{diag}(\sigma^2_l)$ 是 NLOS 延迟的先验已知协方差矩阵。该方程在第一篇文章中显示为方程 (20)(21)，在第二篇文章中显示为方程 (50)。
由于定位只关心 (x,y) 位置，因此只考虑上部子矩阵，这意味着 NLOS 延迟 $\sigma^2_l$ 的先验知识对计算没有太大影响。论文中还提到，当先验NLOS延迟的方差非常大时，即$\sigma^2_l \rightarrow +\infty$，$H_{NL}\Lambda_{NL}H_{NL}^T$会减小；如果$\sigma^2_l \rightarrow 0$，NLOS部分可以视为LOS估计值。
让我困惑的是，这些论文仍然没有告诉我如何在先验NLOS延迟知识的情况下计算CRB。例如，总共有10个接收雷达，我知道其中2个是LOS，其余8个是NLOS。并且根据先前的知识，我知道 NLOS 延迟分布为 $\sigma^2 = 0.5$。因此，定位 CRB 的计算应为 $H_{NL}\Lambda_{NL}H_{NL}^T+H_{L}\Lambda_{L}H_{L}^T$（考虑 8+2 个接收器）或 $H_{L}\Lambda_{L}H_{L}^T$（仅考虑 2 个 LOS）？如果方差为 1 或 2 甚至 10，情况会怎样？
对我来说，“先前知识”似乎不能用来计算CRB，但也给出了一些雷达信息不应该在计算中考虑的判断。]]></description>
      <guid>https://stats.stackexchange.com/questions/652931/confusion-on-bayesian-cramer-rao-lower-bound-calculation</guid>
      <pubDate>Fri, 16 Aug 2024 15:26:14 GMT</pubDate>
    </item>
    <item>
      <title>混合模型估计[重复]</title>
      <link>https://stats.stackexchange.com/questions/652930/mixed-model-estimates</link>
      <description><![CDATA[数据集 obk.long 有 3 个治疗级别，为什么在使用 afex 运行混合模型时，它只返回治疗 1 和治疗 2 的估计值，而不返回治疗 3 的估计值？
m2 &lt;- hybrid(value ~ treatment + (1|id), obk.long)
coef(summary(m2))

估计标准差。误差 df t 值 Pr(&gt;|t|)
(截距) 5.4833333 0.3751349 13 14.616965 1.898692e-09
treatment1 -1.2833333 0.5321164 13 -2.411753 3.138653e-02
treatment2 0.7666667 0.5645824 13 1.357936 1.975866e-01
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/652930/mixed-model-estimates</guid>
      <pubDate>Fri, 16 Aug 2024 13:18:26 GMT</pubDate>
    </item>
    <item>
      <title>mgcv：绘制因子平滑的置信带（bs =“fs”）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652928/mgcv-plot-confidence-bands-for-factor-smooths-bs-fs</link>
      <description><![CDATA[我遇到了以下问题：绘制游戏时，通常会将置信带添加到平滑曲线中。但是，这不适用于因子平滑，即 bs =“fs”。相反，当使用和为零的平滑交互时，即 bs =“sz”，生成的图包含置信带。
此外，对于 bs =“fs”，plot-object 的参数 se 为 FALSE，而对于 bs =“sz”，则为 FALSE。标准错误被保存了。
有人知道如何解决这个问题吗？
使用 factor.smooth 帮助页面中的模拟数据的小示例：
library(mgcv)
set.seed(0)

# 模拟数据：
f0 &lt;- function(x) 2 * sin(pi * x)
f1 &lt;- function(x,a=2,b=-1) exp(a * x)+b
f2 &lt;- function(x) 0.2 * x^11 * (10 * (1 - x))^6 + 10 * (10 * x)^3 * (1 - x)^10
n &lt;- 500;nf &lt;- 25
fac &lt;- sample(1:nf,n,replace=TRUE)
x0 &lt;- runif(n);x1 &lt;- runif(n);x2 &lt;- runif(n)
a &lt;- rnorm(nf)*.2 + 2;b &lt;- rnorm(nf)*.5
f &lt;- f0(x0) + f1(x1,a[fac],b[fac]) + f2(x2)
fac &lt;- factor(fac)
y &lt;- f + rnorm(n)*2

# bs = &quot;fs&quot;
model1 &lt;- gam(y~s(x0)+ s(x1,fac,bs=&quot;fs&quot;,k=5) + s(x2,k=20))
plot1 &lt;- plot(model1, pages=1, se = TRUE)
head(plot1[[2]]$se)

# bs = &quot;sz&quot;
model2 &lt;- gam(y~s(x0)+ s(x1,fac,bs=&quot;sz&quot;,k=5) + s(x2,k=20))
plot2 &lt;- plot(model2, pages=1, se = TRUE)
head(plot2[[2]]$se)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652928/mgcv-plot-confidence-bands-for-factor-smooths-bs-fs</guid>
      <pubDate>Fri, 16 Aug 2024 12:39:34 GMT</pubDate>
    </item>
    <item>
      <title>混合因子分析仪：似然函数的正确表达？</title>
      <link>https://stats.stackexchange.com/questions/652926/mixture-of-factor-analyzers-correct-expression-for-likelihood-function</link>
      <description><![CDATA[我正在阅读这些笔记关于混合因子分析器，其中描述了以下生成模型：

数据$x$的条件分布（在第 3 节，方程 9）表示为：
$$
P(x \mid z, \omega_j) = \mathcal{N}(\mu_j+\Lambda_j z, \Psi)
$$
其中 $\omega_j$ 表示 $j$ 个因子分析器（或者混合成分，如果我们可以这样称呼它）的索引，并且 $z \mid \omega_j \sim \mathcal{N}(0,I)$。
我的问题是：我说 $x \mid \omega_j \sim \mathcal{N}(\mu_j, \Lambda_j \Lambda_j^\top + \Psi)$ 是否正确？如果我想找到最有可能生成 $x$ 的混合成分，我会最大化以下函数：
$$
L(\omega_j) = P(x \mid \omega_j) = \mathcal{N}(x ; \mu_j, \Lambda_j \Lambda_j^\top+ \Psi) 
$$
对吗？
如果正确，为什么 $P(\omega_j)$ 在这个似然函数中不重要？
这个表达式看起来很像高斯混合模型中的后验推断，即找到每个聚类对给定数据的“责任”。当然，除了在这种情况下，协方差矩阵具有稀疏结构，并且我正在寻找最大似然估计量（我想？）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652926/mixture-of-factor-analyzers-correct-expression-for-likelihood-function</guid>
      <pubDate>Fri, 16 Aug 2024 11:53:45 GMT</pubDate>
    </item>
    <item>
      <title>估计未知分布分位数的高置信上限</title>
      <link>https://stats.stackexchange.com/questions/652924/estimating-high-confidence-upper-bound-for-quantile-of-unknown-distribution</link>
      <description><![CDATA[我获得了一个分布未知的随机变量 $\mathbb R$ 上的 $X$。
我想确定获得 X 的 $1-\alpha$ 分位数的高置信上限 $\hat Q_{1-\alpha}$ 所需的最小样本量 $n$。
具体来说，我对高百分位数感兴趣，比如第 95 或第 99 个百分位数。
对于给定的置信水平 $1-\epsilon$，我想确保 $\Pr(\Pr(X&gt;\hat Q_{1-\alpha})&lt;\alpha) \geq 1-\epsilon$，而不管 $X$ 的分布如何。
虽然这个问题看起来很笼统，但我不确定如何使用经典统计方法来解决它。
直观地说，我会从我的样本中估计 $1-\alpha$ 分位数。
使用 bootstrapping 等方法，我也可以获得该参数的置信区间。
但是，我不确定如何根据基础样本的大小$n$准确量化这些方法的不确定性。
我的问题有两个方面。
首先，是否有统计工具可以回答这个问题并根据样本大小估计参数估计器的置信度？我似乎缺乏查找相关信息的统计背景。如果能提供来源或关键字来为我指明正确的方向，我将不胜感激。
其次，我知道这个问题可以用 PAC-Learning 的方法来解决。
但是，尽管这个问题相对普遍，但我也找不到使用这种界限的例子。
我怀疑有更好的工具来回答这个问题，或者这个问题一开始就不是很有趣，因为人们可以简单地假设某种分布，然后使用参数方法。
如果有人能告诉我这两个假设是否正确，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/652924/estimating-high-confidence-upper-bound-for-quantile-of-unknown-distribution</guid>
      <pubDate>Fri, 16 Aug 2024 11:09:53 GMT</pubDate>
    </item>
    <item>
      <title>使用缺失的消费者数据进行偏好映射</title>
      <link>https://stats.stackexchange.com/questions/652923/preference-mapping-using-missing-consumer-data</link>
      <description><![CDATA[我正在使用基于 R 中 SensoMineR 包中的 carto() 函数的感官和消费者喜好数据进行偏好映射分析。
结构

感官数据：每行代表一个产品，每列代表所有产品特定属性的给定分数，
消费者数据：每行代表一个产品，每列代表许多消费者的给定总体喜好分数。

但是由于设计原因，我的消费者数据缺少一些案例，因为每个消费者只对 3 种产品进行评分。在这种情况下，数据集中填充了许多 NA。并且 carto 函数会抛出错误
Error in `[&lt;-.data.frame`(`*tmp*`, missing, value = c(NA_real_, NA_real_, : 
新列会在现有列后留下空洞
此外：警告消息：
在 mean.default(MatH, na.rm = TRUE) 中：
参数不是数字或逻辑：返回 NA

我以为我可以使用这 3 个产品喜好分数的平均值来估算给定消费者的 NA。这是一种合法的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652923/preference-mapping-using-missing-consumer-data</guid>
      <pubDate>Fri, 16 Aug 2024 10:59:39 GMT</pubDate>
    </item>
    <item>
      <title>如何按年龄、性别和身高调整数据</title>
      <link>https://stats.stackexchange.com/questions/652921/how-to-adjust-data-by-age-sex-and-height</link>
      <description><![CDATA[以下是一个完全虚构的例子（基于真实的例子），因此它没有意义。
我有一个包含 100 个受试者的数据库，其中有他们的年龄、性别、身高、公司职位（初级、中层管理和高层管理）和认知测试（结果范围为 0-20）。然而，我发现这三组在年龄、性别和身高方面存在统计上的显著差异，所以我想纠正他们的认知分数测试，根据这些差异进行调整。我该怎么做？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652921/how-to-adjust-data-by-age-sex-and-height</guid>
      <pubDate>Fri, 16 Aug 2024 10:14:10 GMT</pubDate>
    </item>
    <item>
      <title>非参数和半参数 cif</title>
      <link>https://stats.stackexchange.com/questions/652920/non-parametric-and-semi-parametric-cif</link>
      <description><![CDATA[我最近尝试使用 {survival 来深入了解竞争风险分析。
使用的数据来自 {survival。
library(survival)
library(ggsurvfit)

mgus2$etime &lt;- with(mgus2, ifelse(pstat==0, futime, ptime))
event &lt;- with(mgus2, ifelse(pstat==0, 2*death, 1))
mgus2$event &lt;- factor(event, 0:2, labels=c(&quot;censor&quot;, &quot;pcm&quot;, &quot;death&quot;))

我使用非参数方法计算了累积发生率函数，并得出了事件或死亡在时间的概率t。
可以通过 summary_mfit2$lower 和 summary_mfit2$upper 显示概率的置信区间。
此外，我绘制了累积发生率函数：
mfit2 &lt;- survfit(Surv(etime, event) ~ sex, data=mgus2)

summary_mfit2 &lt;- summary(mfit2, times=c(20))

&gt; summary_mfit2
调用：survfit(formula = Surv(etime, event) ~ sex, data = mgus2)

sex=F 
time n.risk n.event Pr((s0)) Pr(pcm) Pr(death)
20 540 93 0.852 0.0175 0.130

sex=M 
time n.risk n.event Pr((s0)) Pr(pcm) Pr(death)
20 621 137 0.818 0.0106 0.171

ggcuminc(mfit2, consequence = c(&quot;pcm&quot;)) +
add_confidence_interval()

接下来，我尝试了半参数方法，如下所示：
cfit1 &lt;- coxph(Surv(etime, event) ~ sex, mgus2, id=id)

dummy &lt;- expand.grid(sex = c(&quot;F&quot;, &quot;M&quot;))

csurv &lt;- survfit(cfit1, newdata = dummy)

temp &lt;- summary(csurv, times = c(20))

&gt; temp 
调用：survfit(formula = cfit1, newdata = dummy)

数据 1 
时间 n.风险 n.事件 Pr((s0)) Pr(pcm) Pr(死亡) 
20.0000 1161.0000 230.0000 0.8668 0.0111 0.1221 

数据 2 
时间 n.风险 n.事件 Pr((s0)) Pr(pcm) Pr(死亡) 
20.0000 1161.0000 230.0000 0.8388 0.0102 0.1510 

问题：

由于只使用了一个二元协变量（性别），使用半参数模型是否有意义方法还是应该使用非参数方法？
当有人描述使用特定原因的 cox ph 风险比时，我的理解是指使用半参数方法来模拟风险，还是我错了？
非参数方法为时间 t 的风险提供 CI。如何为半参数方法推导出这些 CI？
如果推导出 CI，如何绘制半参数对象 csurv 的置信区间？函数 ggcuminc() 不起作用，使用基本函数 plot()（确实有效）很麻烦。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652920/non-parametric-and-semi-parametric-cif</guid>
      <pubDate>Fri, 16 Aug 2024 09:18:11 GMT</pubDate>
    </item>
    <item>
      <title>主成分（或旋转 PC）可以用作广义线性混合模型中的响应变量吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652863/can-principal-components-or-rotated-pcs-be-used-as-response-variable-in-genera</link>
      <description><![CDATA[旋转主成分是否可以用作 GLMM 中的响应变量？
我进行了一项涉及 40 名参与者的受试者内实验，每位参与者都面临两种情况。参与者完成了四次包含九个 5 点李克特量表问题的调查：实验开始时两次（每种情况一次），实验结束时两次（每种情况之后）。条件交替呈现（ABAB...AB），每个参与者的起始条件随机化。
李克特量表响应是我分析中的因变量，而预测因子是条件（二元变量）和阶段（调查是在开始还是结束）。参与者被纳入随机效应。
鉴于调查问题的子组针对两个不同的方面（感知学习和用户体验），并且李克特量表响应高度相互关联，我执行了 PCA 以降低维度并确保响应变量是独立的。前两个主成分占数据方差的 70% 以上。
我当前的模型公式是：
PC（或旋转的 PC）~ 条件 * 阶段 + (1 | 参与者)

但是，我正在考虑旋转主成分以提高可解释性。我的具体问题是：
在 GLMM 中使用旋转的主成分作为响应变量是否合适？如果我选择这样做，我应该注意哪些潜在问题？
如果您对这种方法的适用性有任何见解或建议，我们将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652863/can-principal-components-or-rotated-pcs-be-used-as-response-variable-in-genera</guid>
      <pubDate>Thu, 15 Aug 2024 12:18:57 GMT</pubDate>
    </item>
    <item>
      <title>R 中的二元预测分类，预测因子由多个值组成</title>
      <link>https://stats.stackexchange.com/questions/652858/binary-predictive-classification-in-r-with-predictors-consisting-of-multiple-va</link>
      <description><![CDATA[由于维度问题，我目前正在努力构建二元 glm 预测分类器。
我有一个包含 N 个样本的数据集，其中每个样本都有 M 个条目（基因）的值，并且是病例或对照。但是，每个基因由 1 ... k 个数据点组成，每个数据点都是一个数值，范围从 0 到 1，代表与基因重叠的 CpG 位点的甲基化。并且每个基因的数据点数量依次变化（因此意味着每个基因由不同大小的数据框表示）。分类器应该是二进制的，根据通过交叉验证选择的一组预测因子（基因）的值将样本分配为病例/对照。
我之前构建了二元预测分类器，其中每个样本的一个值代表一个基因（即来自 NxM 数据框），但我不知道如何处理当前情况，其中我的 NxM 数据框中的每个 1...M 列实际上可以说是 NxK 数据框而不是 Nx1 列。
我曾想过通过从 N 个样本中的每一个的 1...k 数据点中取出中值来将 NxK 数据框表示为 Nx1 列，或者通过选择 NxK 数据框中的一列来表示数据框（基于适合我的研究问题的选择标准），但理想情况下，我希望在构建分类器时指向代表基因的 NxK 数据框。
有人有这种类型的经验吗问题，如果可以，是否有可能从预测器的数据框构建一个预测分类器，其中预测器依次指向单独的数据框？
如果没有，我从每个样本的 1...k 个数据点中取出中值的方法是否有效？
我之前构建过分类器，其中每个基因都由一个值表示，但我没有处理此类问题的经验。]]></description>
      <guid>https://stats.stackexchange.com/questions/652858/binary-predictive-classification-in-r-with-predictors-consisting-of-multiple-va</guid>
      <pubDate>Thu, 15 Aug 2024 10:04:31 GMT</pubDate>
    </item>
    <item>
      <title>具有趋势和季节性的时间序列数据中的因果推断</title>
      <link>https://stats.stackexchange.com/questions/652855/causal-inference-in-time-series-data-with-trend-and-seasonality</link>
      <description><![CDATA[各位统计学家大家好，
我有一个关于时间序列数据中的因果推断和影响评估的问题，特别是在处理趋势、季节性和政策干预或结构性中断时。
在横截面数据中，我们通常应用 OLS 或非参数模型（如 KNN）来估计独立变量 𝑋 和 𝑍 对因变量 𝑌 的影响。然后，对于 OLS，我会检查假设；对于 KNN，我会检查 𝑌 与预测变量 𝑋 和 𝑍 之间的关系，而无需假设参数形式。
但是，我将处理时间序列数据，其中 𝑌、𝑋 和 𝑍 是同时显示趋势和季节性模式的月度序列。此外，在研究期间的中间可能存在已知的政策干预/趋势中断。
我的问题是：

哪些模型最适合估计时间序列数据中的因果关系，特别是在处理趋势、自相关和结构中断时？

我正在考虑对数据进行季节性调整，但我该如何处理趋势成分？由于趋势存在时均值不是恒定的，我应该采取什么方法来处理这个问题？

我如何将政策干预或趋势突破纳入我的因果分析？

这些时间序列模型做出了哪些假设，我如何在因果推断的背景下验证这些假设？


我不是一个铁杆统计学家，所以如果你能推荐任何相关的资料或教科书来解释这些概念——最好是用 R 中的实际例子/代码——那就太好了。任何指导或参考都将不胜感激。
提前感谢您的见解和帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/652855/causal-inference-in-time-series-data-with-trend-and-seasonality</guid>
      <pubDate>Thu, 15 Aug 2024 10:03:20 GMT</pubDate>
    </item>
    </channel>
</rss>