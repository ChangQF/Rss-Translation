<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 19 Apr 2024 09:14:43 GMT</lastBuildDate>
    <item>
      <title>连续混合物分布</title>
      <link>https://stats.stackexchange.com/questions/645366/continuous-mixture-distribution</link>
      <description><![CDATA[我目前正在研究负二项分布的推导，该分布是泊松分布和伽马分布连续混合的结果，用于回归目的。
为了获得整个条件分布，需要整合未观察到的异质性的影响：
$$f(y_i \mid x_i) = \int_{0}^{\infty} h(y_i \mid x_i, \nu_i) \omega(\nu_i \mid x_i) \, d\nu_i
$$
这可以例如如果选择 $\omega(\nu_i \mid x_i)$ 作为 Gamma 分布，则可以完成此操作，但也有其他可能性。
我的问题是，整合 $\nu_i$ 等干扰的影响意味着什么？是否可以通过一个简单的例子来直观地了解这里发生的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/645366/continuous-mixture-distribution</guid>
      <pubDate>Fri, 19 Apr 2024 08:58:10 GMT</pubDate>
    </item>
    <item>
      <title>用于测试随时间推移以及两种条件之间是否存在显着差异的正确统计量是什么？</title>
      <link>https://stats.stackexchange.com/questions/645365/what-is-the-correct-statistic-to-test-whether-there-is-a-significant-difference</link>
      <description><![CDATA[我正在进行一项研究，使用受试者内重复测量设计来检查焦虑水平随时间的变化。参与者经历两种情况：显着的积极和显着的消极。在第一个图像中，他们观看 2 个中性图像，然后观看 3 个正显着图像，然后再次观看 2 个中性图像（2 nt、3 sp、2nt）。对于他们每个人，他们需要提供从 1 到 10 的焦虑等级。在第二种情况下，他们看到 2 个中性图像，然后是 3 个显着的负面图像，然后再次看到 2 个中性图像（2 nt、3 sn、2nt） 。这一系列试验重复了 180 次。
焦虑评级数据分为 7 个时间段（对应于序列中连续试验的数量）。我想统计分析每个条件下的焦虑水平是否随时间段发生显着变化，以及每个时间段内两种条件之间的焦虑水平是否存在显着差异。我怎样才能实现这一点，测试这一点的正确统计模型是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/645365/what-is-the-correct-statistic-to-test-whether-there-is-a-significant-difference</guid>
      <pubDate>Fri, 19 Apr 2024 08:40:47 GMT</pubDate>
    </item>
    <item>
      <title>完美校准输出的布赖尔技能得分悖论？</title>
      <link>https://stats.stackexchange.com/questions/645364/paradox-of-brier-skill-score-of-perfectly-calibrated-output</link>
      <description><![CDATA[给定结果，$y \in \{0,1\}$ 并输出 $o = f(x ) \in \mathbb R, o \in [0,1]$，我对模型 $f$ 完美建模的情况感兴趣变量$Y$。
由于 $Y$ 是伯努利，这意味着
$$
P(Y=1\中X=x)=f(x)\\
P(Y=0\中X=x)=1-f(x)
$$
因此
$$
E\左[Y\中X=x\右]=f(x)
$$
和
\begin{align}
\运算符名称{Var}(Y|X=x)
&amp;=E\left[Y^2\mid X=x\right]-(E\left[Y\mid X=x\right])^2\\
&amp;=E\left[Y\mid X=x\right]-(E\left[Y\mid X=x\right])^2\\
&amp;=f(x)-f(x)^2=f(x)(1-f(x))
\end{对齐}
如果我们模拟这种情况下的数据，并计算 Brier 技能得分 (BSS)，我们会看到：
将 numpy 导入为 np
将 pandas 导入为 pd
从plotnine导入*

def BSS_simulation(n):
    f = np.random.uniform(0, 1, n)
    y = np.random.binomial(1, f)
    yhat = y.mean()
    brier_f = ((y - f)**2).mean()
    brier_yhat = ((y - yhat)**2).mean()
    bss = 1 - brier_f / brier_yhat
    返回BSS

n = 1000
n_sim = 1000
bss = [BSS_simulation(n) for _ in range(n_sim)]

df_bss = pd.DataFrame({“BSS”: bss})
（
    ggplot(df_bss, aes(x=“BSS”))
    + geom_histogram(bins=30)
    + 主题_bw()
    + 主题(figure_size=(5, 3))
    + labs(title=“Brier技能评分模拟”, x=“BSS”, subtitle=f“平均 BSS: {np.mean(bss):.2f}”)
）


对于我来说，这个结果是出乎意料的。
事实上，完美校准的预测并不能实现 $BSS=1$。
然而，证明获得 $BSS=1$ 的唯一方法是 if $f(x )=y$ 对于每个预测，即模型 $f$ 的 Brier 分数为零。
我为下面仓促做出（且缺​​乏严谨性）的推导表示歉意，但我相信我们可以证明（假设 $f$ 是统一的并且普遍存在正类是 $\bar y = 0.5$，尽管我相信给定 $f$ 可以更严格地定义它)
$$E[(y-f)^2]=\int (y-f)^2 df = \int f(1-f) df = \left。 \frac{3f^2-2f^3}{6}\right|_{f=0}^{f=1}=\frac{3-2}{6}=1/6$$ 
还有
$$E[(y-\bar y)^2]=\bar y (1 - \bar y) = 1/2 \cdot 1/2 = 1/ 4$$
然后技能分数变为
$$\text{BSS} = 1 - \frac{1/6}{1/4} = 1 - \frac23=\frac13$$&lt; /p&gt;
这是否意味着当我们完全捕获数据生成过程时，Brier 技能还远未达到 1？]]></description>
      <guid>https://stats.stackexchange.com/questions/645364/paradox-of-brier-skill-score-of-perfectly-calibrated-output</guid>
      <pubDate>Fri, 19 Apr 2024 08:24:26 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 在 QI 宏中签署了等级测试</title>
      <link>https://stats.stackexchange.com/questions/645363/wilcoxon-signed-rank-test-in-qi-macros</link>
      <description><![CDATA[我需要一些帮助来理解 wilcoxon 签名等级测试。我正在使用此测试来比较两个分析仪。我们在两台分析仪上运行相同样本的 PT（凝血酶原时间），结果是非参数的。我对 QI 宏应用程序运行了 wilcoxon 符号秩检验，计算出数据集（每个点）之间差异的列显示所有数据点上的差异为 1 或小于 1。然而，该检验仍然拒绝了两个数据集之间的数据没有不同的原假设。
与其他测试进行比较时，差异小于0.1。
在另一个数据集中（同样是非参数），即使数据集之间的差异 &gt;1，检验也能够拒绝原假设。
有人能够解释为什么会这样吗？我是否使用了错误的测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/645363/wilcoxon-signed-rank-test-in-qi-macros</guid>
      <pubDate>Fri, 19 Apr 2024 08:22:28 GMT</pubDate>
    </item>
    <item>
      <title>系统 GMM 对于任何加权矩阵都会产生相同的结果</title>
      <link>https://stats.stackexchange.com/questions/645362/system-gmm-yields-identical-results-for-any-weighting-matrix</link>
      <description><![CDATA[我正在估计 R 中看似不相关的回归 (SUR) 系统。每个方程都有一个唯一的回归量和一个公共回归量。我正在使用 gmm::sysGmm 并尝试不同的权重矩阵。无论权重矩阵如何，我都会得到相同的结果（点估计、标准误差和我能看到的任何其他结果）。我认为这是不正确的。
无论我使用哪种类型的协方差矩阵估计器，这种现象都会持续存在：MDS、CondHom 或 HAC。无论我使用无限制估计还是限制其中一个系数在方程中相等，它都仍然存在。
问题：为什么系统 GMM 通过 gmm::sysGmm 对于任何加权矩阵都会产生相同的结果？
库(gmm)
库（系统适配）

# 生成并准备数据
n &lt;- 1000 # 样本量
m＜-100#“第二部分”的长度样本的
N &lt;- 3 # 方程数
设置.种子(321); x &lt;- 矩阵(rnorm(n*N),ncol=N); colnames(x) &lt;-paste0(“x”,1:N) # 生成回归量
dummy &lt;- c(rep(0,n-m),rep(1,m))#生成一个公共回归器
x &lt;- cbind(x,dummy) # 包含公共回归器和其余回归器
设置.种子(123); y &lt;- 矩阵(rnorm(n*N),ncol=N); colnames(y) &lt;- Paste0(“y”,1:N) # 因变量的占位符
for(i in 1:N){
 y[,i] &lt;- i + sqrt(i)*x[,i] - i*虚拟 + y[,i]*15*sqrt(i)
 # y[,i] 是 x[,i] 和虚拟变量的线性函数，
 # 加上一个带有方程特定方差的误差项
}
data1 &lt;- as.data.frame(cbind(y,x)) # 创建所有数据（y 和 x）的数据框

# 创建模型方程和力矩条件
eqSystem_g = eqSystem_h &lt;- list()
for(i in 1:N){
 eqSystem_g[[i]] &lt;- as.formula(assign(paste0(&quot;eq&quot;,i), value=paste0(&quot;y&quot;,i,&quot; ~ x&quot;,i,&quot; + dummy&quot;) )) # 定义 SUR 的线性方程
 eqSystem_h[[i]] &lt;- as.formula(assign(paste0(&quot;eq&quot;,i), value=paste0( &quot;~ x&quot;,i,&quot; + dummy&quot;))) # 定义矩条件对于高斯模型
}

# 估计 WLS 类型的权重矩阵，用作 GMM 中用户指定的权重矩阵
m0 &lt;- systemfit(公式=eqSystem_g，方法=“OLS”，数据=data1)
OLSmat &lt;- diag(diag(m0$residCov)); Wmat &lt;- 求解(OLSmat)

# 选择GMM中协方差矩阵的类型
vc1＜-“MDS”
vc1＜-“CondHom”
vc1＜-“HAC”
#vc1 &lt;-“TrueFixed”

# 在限制估计和非限制估计之间进行选择
cec1=NULL # 无限制
cec1=3 # 限制虚拟变量的系数在方程中相等

# 使用不同的权重矩阵“sysGmm”估计模型：identity、“optimal”并手动指定
m1a &lt;- sysGmm(g=eqSystem_g, h=eqSystem_h, wmatrix=“ident” ,weightsMatrix=NULL, vcov=vc1, crossEquConst=cec1, data=data1);摘要(m1a)
m1b &lt;- sysGmm(g=eqSystem_g, h=eqSystem_h, wmatrix=“最佳”,weightsMatrix=NULL, vcov=vc1, crossEquConst=cec1, data=data1);摘要(m1b)
m1c &lt;- sysGmm(g=eqSystem_g, h=eqSystem_h,weightsMatrix=Wmat, vcov=vc1, crossEquConst=cec1, data=data1);摘要(m1c)

相关：
* 通过 systemfit 与 sysGmm 估计的 SUR：不同的标准误差 
* 为什么 systemfit 对于 OLS 和 WLS 会产生相同的结果？  
* 为什么在交叉方程限制下，systemfit 会产生不同的 OLS 和 WLS 结果？ ]]></description>
      <guid>https://stats.stackexchange.com/questions/645362/system-gmm-yields-identical-results-for-any-weighting-matrix</guid>
      <pubDate>Fri, 19 Apr 2024 07:51:09 GMT</pubDate>
    </item>
    <item>
      <title>我们如何应用敏感性分析来比较两个衡量干预效果的 ARIMA 模型？</title>
      <link>https://stats.stackexchange.com/questions/645360/how-can-we-apply-sensitivity-analysis-in-comparing-two-arima-models-both-measur</link>
      <description><![CDATA[我有一个从基线（4 个月）和干预期间（4 个月）收集的 8 个月期间报告率数据集。目标是确定干预措施是否具有显着效果。我使用 ARIMA 模型来比较观测值和预测值。所有差异均不显着。然而，干预期间第三个月的比率似乎是一个严重的异常值，因此需要使用 SPSS ARIMA 建模中的敏感性分析来比较包含该比率的模型和排除该比率的另一个模型。我以前从未经历过这种情况，需要您的帮助。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/645360/how-can-we-apply-sensitivity-analysis-in-comparing-two-arima-models-both-measur</guid>
      <pubDate>Fri, 19 Apr 2024 06:13:05 GMT</pubDate>
    </item>
    <item>
      <title>在 Heckman 2 步模型中指定回归量的条件是什么</title>
      <link>https://stats.stackexchange.com/questions/645359/what-are-the-conditions-to-specify-the-regressors-in-heckman-2-step-model</link>
      <description><![CDATA[我在解释 STATA 命令 Twostep Heckman 模型以及向模型添加固定效应时遇到问题。
我的分析基于面板数据集，我想解决在上学之前死亡的个体的选择偏差，并且需要理解以下结果的解释，我的因变量是教育（连续变量），自变量是家庭规模。我在这个例子中只包含了 2 个变量。我想添加固定效果并使用 R 复制相同的效果。
我想知道如何在 R studio 概率回归中运行它，然后提取预测值，计算米尔斯比率并使用固定效应（集群和月份固定效应）运行模型。
希望图片清晰
谢谢
]]></description>
      <guid>https://stats.stackexchange.com/questions/645359/what-are-the-conditions-to-specify-the-regressors-in-heckman-2-step-model</guid>
      <pubDate>Fri, 19 Apr 2024 05:41:27 GMT</pubDate>
    </item>
    <item>
      <title>我们能否通过贝叶斯推理的适当评分规则获得可评估的概率预测，而不评估边际可能性？</title>
      <link>https://stats.stackexchange.com/questions/645358/can-we-get-probabilistic-predictions-evaluable-by-proper-scoring-rules-from-baye</link>
      <description><![CDATA[假设我们有一个输入向量 $X=[x_0,\dots, x_{n-1}]$ 和一个输出向量， $Y=[y_0, \dots, y_{n-1}]$。
我们希望在给定新输入 $\hat{y}$ 的情况下预测新输出的分布  &quot;&gt;$\帽子{x}$。
贝叶斯推理为我们提供了一种通过后验预测分布来做到这一点的方法，在本例中为
$$p(\hat{y}|\hat{x}, X, Y)=\int p(\hat{y}|\hat{x}, \theta)p(\theta|X,Y)\text{d}\theta$$
后验进一步定义为
$$p(\theta|X,Y)=\frac{p(Y|X,\theta)p(\theta)}{\int p(Y|X,\ θ)p(\θ)\text{d}\theta}.$$
当没有封闭形式时，$p(\theta|X,Y)$ 的分母有时很难或耗时地进行数值计算或共轭先验，有没有一种方法能够在不评估分母的情况下获得某种密度预测，然后可以通过适当的评分规则（例如负向对数分数）进行评估？
对于密度预测 $f_{\hat{y}}(y)$ 和观测值 $y$：
$$L(y, f_{\hat{y}}) = -\text{log}(f_{\hat{y}}(y)).$ $
我觉得我们会遇到密度预测不是真实密度的问题（即不积分到 1），这会给我们在使用它评估评分规则时提供不正确的评估，即使我们仍然可以在技术上计算它.]]></description>
      <guid>https://stats.stackexchange.com/questions/645358/can-we-get-probabilistic-predictions-evaluable-by-proper-scoring-rules-from-baye</guid>
      <pubDate>Fri, 19 Apr 2024 03:59:34 GMT</pubDate>
    </item>
    <item>
      <title>关于样本矩的术语澄清</title>
      <link>https://stats.stackexchange.com/questions/645352/terminology-clarification-about-sample-moments</link>
      <description><![CDATA[根据 MathWorld (链接)：“样本原始矩是无偏估计量人口原始时刻”。
维基百科（链接）说：
...可以使用 $k$&lt; 来估计总体的第 $k$ 个原始矩/span&gt;-第一个原始样本时刻
$$\frac{1}{n}\sum_{i = 1}^{n} X^k_i$$
应用于从总体中抽取的$X_1\dots X_n$样本。
这让我感到困惑，因为据我了解，估计量是统计数据（link）用于估计一些参数。因此，它们是随机变量的函数。但文章中发现的表达式似乎是随机变量结果的函数，而不是变量本身的函数。
我倾向于认为“样本时刻”是指一个“样本时刻”。是可以直接从样本计算的“东西”（或者据我从 这个答案）。这意味着，从特定的值来看。人们可以定义一个统计量，然后通过用特定结果替换随机变量来修改它，并执行计算。但我感觉这和原来的物体不一样。
任何人都可以向我澄清这些细微的差异，以了解什么是“样本时刻”吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645352/terminology-clarification-about-sample-moments</guid>
      <pubDate>Fri, 19 Apr 2024 01:22:58 GMT</pubDate>
    </item>
    <item>
      <title>似然比检验的拒绝区域（均匀分布）</title>
      <link>https://stats.stackexchange.com/questions/645350/rejection-region-for-the-likelihood-ratio-test-uniform-distribution</link>
      <description><![CDATA[让 $x_1 ... x_n$ 从均匀分布中采样 $f(x;\theta) = (1/\theta), \theta; &gt;0, x \in [0,\theta].$
找到假设的似然函数后：
$H_0 : \theta = \theta_0 ~\textrm{vs} ~H_A : \theta \neq \theta_0$
到目前为止我发现比率测试是
$\Lambda(\theta)= (\bar{X}/\theta_0)^n$ 其中 $\bar{ X}$是x采样的最大值。
如果我不尝试定义拒绝区域，我会稍微迷失，我是否定义与此比率测试相关的 c 或将其定义为 X 估计值的函数？我仍然对统计数据有疑问，在此先感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/645350/rejection-region-for-the-likelihood-ratio-test-uniform-distribution</guid>
      <pubDate>Fri, 19 Apr 2024 00:12:00 GMT</pubDate>
    </item>
    <item>
      <title>余弦相似度与替代点积缩放</title>
      <link>https://stats.stackexchange.com/questions/645343/cosine-similarty-vs-alternative-dot-product-scaling</link>
      <description><![CDATA[假设我有一个特定的度量存储在两个向量a和b中，我使用余弦相似度来度量两个向量之间的相似度。
形式上，余弦相似度表示为：
$$ \cos\theta =\frac{a\cdot b}{\|a\|\|b\|}= \frac{\sum_{i=1}^{ n}{a_i b_i}}{\sqrt{\sum_{i=1}^{n}a_i^2} \cdot\sqrt{\sum_{i=1}^{n}b_i^2}}$$&lt; /跨度&gt;
在阅读时，我发现了一篇帖子 关于两个向量之间的相似性。一个答案如下：
&lt;块引用&gt;
我在比较 2 个向量（速度）时遇到了类似的问题。我目前使用两个向量的点积除以最大向量长度的平方。这样做的优点是，在测量“相似性”时还考虑了方向和大小。该公式给出 -1 到 +1 之间的数字。如果向量相同，您将获得 +1。如果方向相差超过 180 度，结果为负。

这被指定为：相似度 = dotproduct(a, b) / max(norm(a),norm(b))^2
因此，在上面的符号中，可以表示为：
$$ = \frac{\sum_{i=1}^{n}{a_i b_i}}{\max\left(\sqrt{\sum_{i=1) }^{n}a_i^2},\sqrt{\sum_{i=1}^{n}b_i^2}\right)^2}$$
考虑到正则余弦相似度也在区间 $[-1,1 中，与正则余弦相似度相比，这种点积的替代缩放有什么优点]$？这是点积的标准缩放吗？如果是，这种方法通常被称为什么？最后，使用一些示例数据，与余弦相似度相比，替代点积缩放似乎会导致相似度稍低（请参见下面的代码示例），这告诉我什么？
&lt;小时/&gt;
&lt;前&gt;&lt;代码&gt;n &lt;- 10

设置.种子(123)
a &lt;- rnorm(n)
b &lt;- rnorm(n)

余弦 &lt;- 函数(a, b) {
  总和（a * b）/（sqrt（总和（a * a））* sqrt（总和（b * b）））
}

替代&lt;-函数（a，b）{
  sum(a*b) / max(sqrt(sum(a*a)), sqrt(sum(b*b)))^2
}

余弦（a，b）
[1]0.5801971

替代方案（a，b）
[1] 0.5232835
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/645343/cosine-similarty-vs-alternative-dot-product-scaling</guid>
      <pubDate>Thu, 18 Apr 2024 22:05:19 GMT</pubDate>
    </item>
    <item>
      <title>变换后的正态分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/645325/distribution-of-transformed-normal</link>
      <description><![CDATA[假设 $X$ 是正态分布，均值 $\mu$ 和标准差 $\sigma$ 和 $\Phi$ 是标准正态分布函数。 $\Phi(X)$ 的分布是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/645325/distribution-of-transformed-normal</guid>
      <pubDate>Thu, 18 Apr 2024 16:26:58 GMT</pubDate>
    </item>
    <item>
      <title>目前最好的可解释回归模型</title>
      <link>https://stats.stackexchange.com/questions/645321/the-best-interpretable-regression-model-currently</link>
      <description><![CDATA[我正在寻求有关表格数据的可解释回归模型的建议。我正在寻找能够在复杂性和可解释性之间取得平衡的方法——比简单的线性回归或决策树更复杂的方法。
虽然我知道 SHAP、LIME 和 TabNet 等流行选项，但我有兴趣探索其他最先进的方法。
主要要求包括：

高精度：性能应可与更复杂的模型相媲美。
可解释的预测：模型应提供有关其如何进行预测的见解。

您能否建议一些符合这些条件的型号名称？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/645321/the-best-interpretable-regression-model-currently</guid>
      <pubDate>Thu, 18 Apr 2024 15:51:18 GMT</pubDate>
    </item>
    <item>
      <title>基于概率分布而非数据集的 k 均值聚类</title>
      <link>https://stats.stackexchange.com/questions/645286/k-means-clustering-on-a-probability-distribution-instead-of-a-dataset</link>
      <description><![CDATA[通常，聚类算法（例如 $k$-means）在数据集上定义如下：if $ D$ 是一个数据集，将 $D$ 划分为集合 $\{S_1, \dots , S_n\}$ 最小化 $$\sum_{i=1}^n |S_i| 给出的簇内平方和\text{Var} (S_i) = \sum_{i=1}^n \frac{1}{|S_i|} \sum_{x, y\in S_i}\lVert x-y\rVert.$$我想知道是否可以参考概率分布定义 $k$-means 算法 $\mu$  而不是数据集 $D$。例如，假设我们的数据集仅由根据以下概率分布分布的 2d 点的集合组成（其中深色表示低概率）：

然后，如果我们使用 $k$ - 表示有 2 个簇的聚类，我们（很可能）会得到一个以 -1 为中心的簇，另一个以 1 为中心的簇。我是想知道我们是否可以在分布本身上定义聚类算法，并将输入空间分割成 Voronoi cells 不参考数据集。换句话说，我想找到两件事： 1. 一个目标函数 $f$ 评估输入空间相对于给定分布的给定 Voronoi 分区2. 针对给定分布最小化目标函数的方法。
我希望它与 $k$ 保持一致 - 在以下意义上意味着目标函数。假设我们有 IID 随机变量 $Z_1, \dots, Z_m$ 根据 $\mu$ 分布，这样$\{Z_1(\omega), \dots, Z_m(\omega)\}$ 是根据 $\mu$ 对于任何随机结果$\omega$。然后令 $\mathcal{V}(\omega)$ 为由 $k$-表示此数据集上的算法，并让 $SS(\omega)$ 成为此数据集上此分区的簇内平方和。然后我想要属性 $$\mathbb{E}[f(\mathcal{V})] = \mathbb{E}[SS].$$
这样做的目的是提供一种方法来量化给定理论输入分布的$k$均值的适用性。例如，如果将聚类作为分类任务，则可以计算出簇内距离的预期总和以及预期错误率等数量。]]></description>
      <guid>https://stats.stackexchange.com/questions/645286/k-means-clustering-on-a-probability-distribution-instead-of-a-dataset</guid>
      <pubDate>Thu, 18 Apr 2024 08:06:04 GMT</pubDate>
    </item>
    <item>
      <title>我应该什么时候进行标准化，在回归之前还是之后？</title>
      <link>https://stats.stackexchange.com/questions/645188/when-should-i-standardize-before-or-after-a-regression</link>
      <description><![CDATA[我有一个面板数据集，我的因变量是长期合同农场工人的 Logit 转换比例。我对两个变量的影响特别感兴趣，即农业中的田园重点（以变量“田园”为代表）和马的存在（以“马”为代表）。这些变量的影响随着时间的推移而变化，我运行一个带有交互项的模型：
模型 &lt;- lm(logitshare ~ 田园 + 田园:因子(年份) + 马 + 马:因子(年份) +
            其他变量，数据= mydata）

我需要比较变量的相对重要性并使用两种方法，在运行回归之前或之后进行标准化。结果明显不同。
。
“模型”列显示了对非标准化系数运行回归并使用 lm.beta 进行事后标准化的情况。 ModelST 在使用 R 的 scale 函数转换的系数上运行。哪种方法更可靠？]]></description>
      <guid>https://stats.stackexchange.com/questions/645188/when-should-i-standardize-before-or-after-a-regression</guid>
      <pubDate>Tue, 16 Apr 2024 23:50:11 GMT</pubDate>
    </item>
    </channel>
</rss>