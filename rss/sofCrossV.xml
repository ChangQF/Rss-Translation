<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 25 Sep 2024 03:24:42 GMT</lastBuildDate>
    <item>
      <title>3 种条件下刺激效果比较</title>
      <link>https://stats.stackexchange.com/questions/654875/comparing-stimulation-efficacy-under-3-conditions</link>
      <description><![CDATA[我有一个数据集，其中比较了 3 种药物条件（药物 a、药物 b、药物 a+b），我的读数是培养皿中对药物有反应的细胞数量。药物 a 和药物 b 有 4 种不同的剂量浓度，因此实际上我们总共有 16 种组合。我在 5 种不同的培养皿中完成了这项工作。
我想确定不同水平的药物 a+b 条件在统计上是否与仅药物 a 或仅药物 b 不同。
最好的测试形式是某种重复测量克鲁斯卡尔沃利斯法吗？
提前谢谢大家]]></description>
      <guid>https://stats.stackexchange.com/questions/654875/comparing-stimulation-efficacy-under-3-conditions</guid>
      <pubDate>Wed, 25 Sep 2024 02:10:33 GMT</pubDate>
    </item>
    <item>
      <title>使用插值逻辑函数避免数值不稳定性</title>
      <link>https://stats.stackexchange.com/questions/654874/avoiding-numerical-instability-with-interpolating-logistic-function</link>
      <description><![CDATA[我目前正在尝试将三个数据点 $(x_0,y_0)$、$(x_1,y_1)$ 和 $(x_1,y_1&#39;)$ 插入到类似逻辑的函数中，其中 $y_1&#39;$ 是 $(x_1,y_1)$ 处的斜率。该函数为
$$
f(x) = \frac{L}{1+C\cdot\exp(-kx)}
$$
其中 $C$ 可以是负数也可以是正数。分配 $k$、$C$ 和 $L$ 的解决方案得出
$$
\begin{align*}
k &amp;= \frac{y_1(y_1-y_0)W_n(\Phi) + y_1&#39;y_0(x_1-x_0)}{y_1(y_1-y_0)(x_0-x_1)}\\
C &amp;= \frac{y_1 - y_0}{y_0\cdot \exp(-k x_0) - y_1 \cdot \exp(-k x_1)}\\
L &amp;= y_1 (1 + C \cdot \exp(-k x_1))
\end{align*}
$$
$W_n$ 是 Lambert W 函数，其中 $n$ 为 $0$ 或 $-1$，具体取决于单独的条件，并且
$$
\Phi = \frac{y_1&#39; y_0 \cdot \exp\left(\frac{y_1&#39; y_0 (x_0-x_1)}{y_1 (y_1-y_0)}\right) (x_0-x_1)}{y_1 (y_1-y_0)}
$$
我遇到的问题是，我有很多情况，其中 $k$ 和 $L$ 的数量级为 $\mathcal{O}(10^{-15})$ 或更小。这导致最终的逻辑拟合在数值上非常不稳定，通常会提供阶梯状函数，此处以红色显示（忽略蓝色）。

其中 $k=5.4138\times 10^{-16}$，$L=-5.9212\times 10^{-17}$，以及 $C=-1$。
我想知道是否有任何方法可以重写我如何表达逻辑函数本身，或者如何表达 $k$、$C$ 和 $L$ 的解，从而在拟合中恢复一些精度。
编辑：$C$ 的公式错误。现在已修复]]></description>
      <guid>https://stats.stackexchange.com/questions/654874/avoiding-numerical-instability-with-interpolating-logistic-function</guid>
      <pubDate>Wed, 25 Sep 2024 01:13:58 GMT</pubDate>
    </item>
    <item>
      <title>我怎么知道我可以跨不同的分类行做出这些推断？</title>
      <link>https://stats.stackexchange.com/questions/654873/how-do-i-know-i-can-make-these-inferences-across-separate-categorical-rows</link>
      <description><![CDATA[我正在学习非常基础的统计学，从双向频率表开始。但是，我对此有很多不确定性，因为似乎有很多...假设，但从未解释过。
附件是问题的 PNG

根据此表，“似乎”准确地...表明意大利人“更有可能”拥有棕色或淡褐色的眼睛。
但为什么允许我比较两个完全不同的类别？我不需要注意样本量吗？我不需要知道样本是否随机吗？我不需要知道有多少百分比的人拥有双重国籍吗？我怎样才能获取两个完全不同的行频，然后对它们进行比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/654873/how-do-i-know-i-can-make-these-inferences-across-separate-categorical-rows</guid>
      <pubDate>Wed, 25 Sep 2024 01:08:31 GMT</pubDate>
    </item>
    <item>
      <title>用于池化逻辑回归的 R 包？</title>
      <link>https://stats.stackexchange.com/questions/654871/r-package-for-pooled-logit-regression</link>
      <description><![CDATA[我有包含二元结果变量的调查数据。数据是纵向的：不是面板数据，而是汇总数据。
理想情况下，我希望 glm 允许汇总，或者 plm 允许逻辑模型。有没有可以结合这两种功能的软件包？
祝好，]]></description>
      <guid>https://stats.stackexchange.com/questions/654871/r-package-for-pooled-logit-regression</guid>
      <pubDate>Tue, 24 Sep 2024 23:40:41 GMT</pubDate>
    </item>
    <item>
      <title>量化变异性变化的因果效应</title>
      <link>https://stats.stackexchange.com/questions/654868/quantifying-the-causal-effect-of-change-in-variability</link>
      <description><![CDATA[假设有一台木材切割机。当我们调整机器时，机器的精度会增加。这意味着机器应该切割 $\mu$ 英寸的块，但有误差 $\epsilon$。调整时，误差的变化性会降低。
我想了解调整机器的因果效应。
利用 Rubin 因果模型，我们可以指定观察到的块英寸的潜在结果并进行对比。
$$
Y(0) = \mu + \epsilon(0) 
$$
$$
Y(1) = \mu + \epsilon(1) 
$$
潜在误差的差异是特定块调整的因果效应。
$$
Y(1) - Y(0) = \epsilon(1) - \epsilon(0)
$$
假设误差分布如下
$$
\epsilon(1) \sim N(0, \sigma_t^2) 
$$
$$
\epsilon(0) \sim N(0, \sigma_c^2)
$$
现在我们不观察单个潜在结果，因此我们取期望值：
$$
{\bf E}[\epsilon(1)] - {\bf E}[\epsilon(0)] = 0
$$
期望值为零，表示没有因果关系，这不表明变异性发生了变化。我该如何在潜在结果框架中设置这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/654868/quantifying-the-causal-effect-of-change-in-variability</guid>
      <pubDate>Tue, 24 Sep 2024 22:35:35 GMT</pubDate>
    </item>
    <item>
      <title>两个独立伽马变量的最大值</title>
      <link>https://stats.stackexchange.com/questions/654867/maximum-of-two-independent-gamma-variables</link>
      <description><![CDATA[设 $X_1$、$X_2$ 为具有不同伽马分布的两个独立随机变量，并且 $X = \max\{X_1, X_2\}$。
$X$ 的分布有已知结果吗？实际上我只需要知道 $\mathrm E[X]$（精确值或近似值）。
如果没有已知结果，我仍然会发现考虑两个分布具有相同尺度（或速率）参数（但形状参数不同）的特殊情况很有用。]]></description>
      <guid>https://stats.stackexchange.com/questions/654867/maximum-of-two-independent-gamma-variables</guid>
      <pubDate>Tue, 24 Sep 2024 22:11:33 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证和测试集准确率之间的差异</title>
      <link>https://stats.stackexchange.com/questions/654864/discrepancy-between-cross-validation-and-test-set-accuracy</link>
      <description><![CDATA[我正在研究一个名为 Spaceship Titanic 的 kaggle 数据集，目前遇到了一个让我很困惑的问题。
出于某种原因，我无法可靠地使用 5 倍 cv 准确度作为测试集准确度的代表。我的意思是，举个例子，当我从数据集中删除一个特定特征时，我的 cv 准确度从 0.7923 增加到 0.8048。但是，我的测试集准确度从 0.8026 降低到 0.7961。同样，当我根据 cv 准确度优化超参数时，我的测试集准确度会下降。
什么可能导致这种差异？此外，是否有任何建议让我以这样的方式进行验证，即其准确度的变化直接反映到测试集，不一定是幅度方面，而是方向方面？]]></description>
      <guid>https://stats.stackexchange.com/questions/654864/discrepancy-between-cross-validation-and-test-set-accuracy</guid>
      <pubDate>Tue, 24 Sep 2024 21:15:09 GMT</pubDate>
    </item>
    <item>
      <title>一个数据集来自多个分布</title>
      <link>https://stats.stackexchange.com/questions/654863/one-data-set-drown-from-multiple-distributions</link>
      <description><![CDATA[我不清楚如何拟合至少从视觉上看是从多个分布中提取的数据集。
我尝试使用 GaussianMixture，但结果看起来并不令人信服。我不擅长统计，也不想争辩说它是错误的，但这不是我所期望的。代码在这里：
import numpy as np
from pylab import *
from sklearn.mixture import GaussianMixture
from pylab import concatenate, normal
import pandas as ps

from scipy.stats import norm

df = ps.read_csv(&#39;Book6.csv&#39;)
multimodal_dist = df.E.to_numpy()

weights = np.ones_like(multimodal_dist)/float(len(multimodal_dist))
y, x, _=hist(multimodal_dist, bins=np.arange(df[&#39;E&#39;].min(), df[&#39;E&#39;].max()+1)-0.5, alpha=.5, weights=weights, label=&#39;data&#39;)

components = 2

gm = GaussianMixture(n_components=components)
gm.fit(multimodal_dist.reshape(-1, 1))

means = gm.means_
standard_deviations = gm.covariances_**0.5 
weights = gm.weights_ 

new_X = np.linspace(min(multimodal_dist), max(multimodal_dist), 100)

对于 zip(means, standard_deviations, weights) 中的平均值、标准差、权重：
print(weight,mean, std)
pdf = 2*weight * norm.pdf(new_X, mean, std)
plt.plot(new_X.reshape(-1, 1), pdf.reshape(-1, 1), alpha=0.8)

pdf_full = np.zeros(len(new_X))
对于 i 在范围(components) 中：
pdf_full = pdf_full + weights[i] * norm.pdf(new_X, means[i], standard_deviations[i])

plt.plot(new_X.reshape(100,1), 2*pdf_full.reshape(-1, 1))

plt.show()

我根据 GaussianMixture 拟合系数生成的图是

整体曲线确实看起来正确，但底层分布不是我所期望的。
我期望的图是手动拟合的，没有统计支持，但我认为，应该是这样的：

我的期望是错误的，还是我没有使用好的方法，或者误用了它们？首先，在这两种情况下，我的标准化都是手动完成的。我不明白如何标准化我的拟合以匹配分布。
数据在这里。]]></description>
      <guid>https://stats.stackexchange.com/questions/654863/one-data-set-drown-from-multiple-distributions</guid>
      <pubDate>Tue, 24 Sep 2024 20:55:32 GMT</pubDate>
    </item>
    <item>
      <title>Excel 中带有 ARIMA(1, 0, 1) 误差计算的手动回归模型</title>
      <link>https://stats.stackexchange.com/questions/654862/manual-regression-model-with-arima1-0-1-errors-calculation-in-excel</link>
      <description><![CDATA[我试图在 Excel 中复制带有 ARIMA(1, 0, 1) 误差的回归模型，但似乎无法匹配 R 中看到的结果。
假设我有一个带有 ARIMA(1, 0, 0) 误差的回归模型。这将被定义为：
$\hat{Y_t} = (\beta_1)*X_1+(\beta_2)*X_2+\hat{e_t}$
其中
$\hat{e_t} = (ar1)*e_{t-1}$
并且
${e_t} = (ar1)*e_{t-1} + u$
我理解如何实现这一点，这里的 ar1 项只是乘以前一期的残差 $(Y_{t-1} - \hat{Y}_{t-1})$
但是，当我将移动平均项添加到我的 ARIMA 误差中时，我似乎无法匹配结果。
对于 ARIMA(1, 0, 1) 误差，我相信误差公式现在是：
$\hat{e_t} = (ar1)*e_{t-1}+ (ma1)*u_{t-1}$
或者
${e_t} = (ar1)*e_{t-1}+ (ma1)*u_{t-1} + u$
我需要根据以下内容计算我的 $u$：
$u = {e_t}-(ar1)*e_{t-1} -(ma1)*u_{t-1} $
但是我如何获取第一个 $u_{t-1}$ 值？
我似乎陷入了无限循环试图弄清楚这一点。如果有人可以提供一个简单的 Excel 示例，那将非常有帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/654862/manual-regression-model-with-arima1-0-1-errors-calculation-in-excel</guid>
      <pubDate>Tue, 24 Sep 2024 20:48:04 GMT</pubDate>
    </item>
    <item>
      <title>使用下限日期作为预测模型的特征是一个好主意吗？</title>
      <link>https://stats.stackexchange.com/questions/654860/is-using-floored-dates-as-a-feature-in-predictive-models-a-good-idea</link>
      <description><![CDATA[我正在开展一个预测建模项目，并考虑使用 Floored Date 功能来捕获数据中更广泛的时间模式。这个想法是使用 Python 中特定于日期的函数（如 pd.Timestamp.floor）将观察日期四舍五入到指定的粒度 G（例如，天、周、月）。这种方法旨在简化时间信息，减少来自确切日期的噪音，防止数据泄漏过度拟合，同时仍能捕捉不同时间尺度上的重要趋势。
我的问题：

在预测模型中使用底数日期作为特征是一种好的做法吗？
其他人是否在实际应用中探索或验证过这种方法？
在实施此功能时，我应该注意哪些潜在的陷阱或最佳实践？

其他详细信息：
定义：
底数日期功能使用 pd.Timestamp.floor 等函数将观察日期四舍五入到指定的粒度 G。例如，如果 G 设置为“W”（表示周），则所有日期都会向下舍入到各自周的开始时间。
class DateFloorTransformer(BaseEstimator, TransformerMixin):
def __init__(self, column, granularity=&#39;D&#39;):
self.column = column
self.granularity = granularity

def fit(self, X, y=None):
return self

def transform(self, X):
X = X.copy()
X[self.column] = X[self.column].dt.floor(self.granularity)
return X

# 定义管道
pipeline = Pipeline([
(&#39;date_floor&#39;, DateFloorTransformer(column=&#39;date&#39;)),
(&#39;model&#39;, RandomForestTree())
])

# 初始化 GridSearchCV
grid_search = GridSearchCV(
estimator = pipeline,
cv = TimeSeriesSplit(n_splits=5),
param_grid = {
&#39;date_floor__granularity&#39;: [&#39;D&#39;, &#39;7D&#39;, &#39;W&#39;, &#39;M&#39;]
})

动机：

简化：降低日期数据的精度以关注更广泛的时间趋势，最大限度地减少来自确切日期的噪音，同时捕捉不同时间尺度上的重要模式。
可调粒度：粒度 G（例如，‘D’ 代表天，‘W’ 代表周，‘M’ 代表月）可以使用时间序列交叉验证进行优化，以找到最佳的时间聚合级别进行预测。

优点（我认为）：

捕获时间模式：有助于识别趋势，而不会用确切的日期细节压倒模型。
粒度灵活性：可以根据数据调整 G 以适应不同的时间尺度。
降噪：丢弃可能引入噪音并导致过度拟合的不必要的时间精度。
平衡长期和短期趋势：允许模型在选定的时间尺度上学习广泛的模式和波动。

缺点（以及如何解决）：

丢失细粒度的时间信息：由于舍入，重要的细节可能会丢失。

解决方案：包括额外的时间特征，如星期几、月份或特殊事件指标，以捕捉更精细的模式。


过度拟合历史数据：模型可能会过度拟合过时的趋势。

解决方案：使用时间序列交叉验证选择最佳 G，并实施监控机制来检测概念漂移。


粒度选择挑战：不合适的 G 可能会错过相关模式。

解决方案：进行探索性数据分析以了解固有周期并系统地测试不同的粒度。


概念漂移敏感性：如果趋势随时间变化，模型可能无法捕捉到新模式。

解决方案：监控模型随时间的性能，并在检测到重大变化时重新训练模型。


数据泄露风险：处理不当可能导致数据泄露。

解决方案：使用时间序列交叉验证方法确保基于时间的训练测试分割正确。



我对使用下限日期作为预测模型特征的任何经验、研究或最佳实践特别感兴趣。非常感谢您的见解和建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/654860/is-using-floored-dates-as-a-feature-in-predictive-models-a-good-idea</guid>
      <pubDate>Tue, 24 Sep 2024 19:31:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 simr 计算线性混合模型中计划对比的功率和样本大小？</title>
      <link>https://stats.stackexchange.com/questions/654818/calculate-power-and-sample-size-for-planned-contrasts-in-linear-mixed-models-usi</link>
      <description><![CDATA[我使用 lmerTest 包在 R 中建立了一个线性混合模型，其中有三个分类因子（A 有 3 个级别，B 有 8 个级别，C 有 2 个级别）和一个针对主题的随机效应。我有兴趣使用 simr 对 B 的两个特定计划水平对比进行功效分析。可以吗？
例如，我们分别用 B1、B2、B3 和 B4 表示因子 B 的水平 1、2、3、4，用 A1 表示因子 A 的水平 1。我们需要以下对比的功效。

比较 B1 和 B2，比较 B3 和 B4，控制所有其他变量（如果模型不包含交互项）
比较 B1 和 B2，并在特定 A 水平 A2 比较 B3 和 B4（如果考虑 A 和 B 之间的交互）

我理解 simr 可以模拟模型中所有固定效应的功效和样本大小，因此我们可以通过将 B 的参考水平设置为 B1 来将 B1 与 B 的所有其他水平进行比较。但我不确定如何设置它来计算上述特定对比的功效。我也知道 emmeans 可以设置和计算事后对比，但有没有办法将它与 simr 集成以进行功效分析和大小调整？如果没有，那么适当的方法是什么？
有人可以分享使用 simr 模拟这些计划对比的功效和样本大小的经验吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654818/calculate-power-and-sample-size-for-planned-contrasts-in-linear-mixed-models-usi</guid>
      <pubDate>Tue, 24 Sep 2024 03:16:21 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归——证明 B1=B2=B3=B4</title>
      <link>https://stats.stackexchange.com/questions/654782/multiple-linear-regression-proving-b1-b2-b3-b4</link>
      <description><![CDATA[给定 y = Bo +B1X1 +B2X2 +B3X3+ B4X4 + e
问题问：使用一般线性假设来展示如何测试：
a) Ho：B1=B2=B3=B4
b) Ho：B1=B2，B3=B4
给定照片中的解决方案，我正在寻找对上述问题部分 a) 和 b) 的解决方案的解释。
具体来说，在解决方案 a 和 b 中，此解决方案中的矩阵布局的原因是什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/654782/multiple-linear-regression-proving-b1-b2-b3-b4</guid>
      <pubDate>Mon, 23 Sep 2024 14:18:02 GMT</pubDate>
    </item>
    <item>
      <title>各变量不平等问题的统计检验</title>
      <link>https://stats.stackexchange.com/questions/654774/statistical-test-for-unequal-questions-for-each-variable</link>
      <description><![CDATA[我们正在进行的定量研究是测试独立变量和因变量之间的相关性。对于我们的问卷，我们收集了人口统计数据（性别、年龄和年级）。我们在研究人员制作的问卷中使用了李克特量表。它有 5 个独立变量问题和 10 个因变量问题。它通过了可靠性测试。数据不是成对的。
我想知道是否有可能测试这些变量之间的相关性？我只知道每个变量的问题数量应该相等，但我们无法为独立变量创建更多问题。如果可能的话，我们可以使用哪些统计测试？
如果我仍隐瞒一些信息，我深表歉意，因为我仍然需要咨询我们的研究顾问，看我们是否被允许披露这些信息。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654774/statistical-test-for-unequal-questions-for-each-variable</guid>
      <pubDate>Mon, 23 Sep 2024 12:21:15 GMT</pubDate>
    </item>
    <item>
      <title>使用观察到的效应量计算功效时样本量不一致</title>
      <link>https://stats.stackexchange.com/questions/654762/inconsistency-in-sample-size-from-power-calculation-using-the-observed-effect-si</link>
      <description><![CDATA[我最初的目标是确认我的功效计算的输入是正确的。
为此，我使用了从分析中获得的数字，并将它们放入 R 的功效计算函数 power.t.test() 中。
我的预期是，我将获得与研究中使用的样本量相同的样本量（假设我使用来自分析的输入参数）。然而，始终存在微小的差异。造成这种差异的原因是什么？
详细信息
我的直觉告诉我，如果观察到的效应大小（差异和残差标准误差）与真实效应大小（$H_A$）相对应，那么在未来的一半实验中，我们应该得到比观察到的更小的 p 值，而在一半实验中，我们应该得到比观察到的更大的 p 值。因此，我们应该在具有观察到的参数（包括 p 值作为显着性水平）的功效分析中获得 50% 的功效。

或者，我也可以固定 50% 的功效，并且应该获得与观察到的相同的样本量。
下面是分析的输出，我从中获取了输入参数。
set.seed(1)
sample_size &lt;- 5
dat &lt;- data.frame(y = rnorm(sample_size*2, mean = rep(c(0,1), each = sample_size), sd = 0.8),
x = rep(c(&quot;a&quot;, &quot;b&quot;), each = sample_size))
(s &lt;- summary(lm(y ~ x, data = dat)))
## 
## 调用：
## lm(formula = y ~ x, data = dat)
## 
## 残差：
## 最小值 1Q 中位数 3Q 最大值 
## -0.7719 -0.5415 0.1018 0.3348 1.1728 
## 
## 系数：
## 估计标准误差 t 值 Pr(&gt;|t|) 
## (截距) 0.1034 0.2962 0.349 0.7360 
## xb 1.0047 0.4189 2.398 0.0433 *
## ---
## 显著性代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1 &#39; &#39; 1
## 
## 残差标准误差：8 个自由度上的 0.6623
## 多重 R 平方：0.4183，调整后的 R 平方：0.3456 
## F 统计量：1 和 8 DF 上的 5.752，p 值：0.04329

p 值除以 2，这样它就对应于单侧检验。
power.t.test(delta = 1.004693, sd = 0.662344, sig.level = 0.04328541/2,
power = 0.5, alternative = &quot;one.sided&quot;)
## 
## 双样本 t 检验功效计算 
##
## n = 4.759026
## delta = 1.004693
## sd = 0.662344
## sig.level = 0.02164271
## power = 0.5
## alternative = one.sided
## 
## 注意：n 是*每个*组中的数字

正如您在输出中看到的那样，样本大小略有偏差 ≈ 0.25（n = 4.76 而不是 5）。如果我针对不同的样本量重复模拟，我会得到以下图片

差异始终为 0.25（采样量越大，方差越小）。
问题

为什么功效计算会导致样本量较小？我的直觉有什么问题？
为什么是 0.25？也许与自由度以及残差标准误差（$\frac{SSR}{n-2}$）的估计方式有关？
]]></description>
      <guid>https://stats.stackexchange.com/questions/654762/inconsistency-in-sample-size-from-power-calculation-using-the-observed-effect-si</guid>
      <pubDate>Mon, 23 Sep 2024 08:36:54 GMT</pubDate>
    </item>
    <item>
      <title>基于汇总数据的平均差异</title>
      <link>https://stats.stackexchange.com/questions/654693/mean-difference-based-on-summary-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654693/mean-difference-based-on-summary-data</guid>
      <pubDate>Sat, 21 Sep 2024 11:32:47 GMT</pubDate>
    </item>
    </channel>
</rss>