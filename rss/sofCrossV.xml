<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 24 Jan 2025 15:17:10 GMT</lastBuildDate>
    <item>
      <title>解释变量是共线的，但我无法删除它们</title>
      <link>https://stats.stackexchange.com/questions/660482/explanatory-variables-are-collinear-but-i-can-t-remove-them</link>
      <description><![CDATA[我试图使用逻辑回归模型，根据价格和其他解释变量估计我们（装修公司）的报价被接受的可能性。但是，由于我的公司没有定量定价策略（主要使用他们的直觉 - 他们是老派的），我必须包括解释变量，如油漆表面积、石膏板的计量等。
但是，所需的材料数量以及所需的劳动力数量很可能与价格高度相关/直接相关。
我想知道我可以使用什么技术来消除多重共线性。
我问过尝试根据解释变量估计价格。然后在逻辑回归模型中使用它，只使用估计的价格，但被告知这被称为“禁止回归”
有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660482/explanatory-variables-are-collinear-but-i-can-t-remove-them</guid>
      <pubDate>Fri, 24 Jan 2025 14:58:11 GMT</pubDate>
    </item>
    <item>
      <title>如何提取和比较两个混合效应模型的预测值分布？</title>
      <link>https://stats.stackexchange.com/questions/660480/how-to-extract-and-compare-the-distribution-of-predicted-values-of-two-mixed-eff</link>
      <description><![CDATA[我有 6 天的 100 个样本（每天 100 个观测值，总共 600 个观测值）。我尝试将混合模型拟合到数据中。还有一次，我尝试将混合模型仅用于从相同数据中获取的两天观测值（例如：第 1 天和第 2 天的观测值 - 总共 200 个观测值）。我知道数据中存在人与人之间的差异会导致错误。我尝试使用混合效应模型将其消除。现在，我的问题是如何提取响应变量的分布？如何比较两个混合模型的分布？一般来说，有什么建议可以消除数据中的人与人之间的差异吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660480/how-to-extract-and-compare-the-distribution-of-predicted-values-of-two-mixed-eff</guid>
      <pubDate>Fri, 24 Jan 2025 14:45:03 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Google Colab 上的 AWQ 量化阿拉伯语预训练 LLM？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660477/how-to-quantize-an-arabic-pretrained-llm-using-awq-on-google-colab</link>
      <description><![CDATA[我想在 Google colab 上运行一个预训练的阿拉伯语模型来生成文本，并在需要时使用 AWQ 对其进行量化。我尝试了许多模型，但总是出现与 AWQ 相关的错误。您能否给我推荐一些资源（代码）来运行和量化使用 AWQ 的阿拉伯语 LLM？]]></description>
      <guid>https://stats.stackexchange.com/questions/660477/how-to-quantize-an-arabic-pretrained-llm-using-awq-on-google-colab</guid>
      <pubDate>Fri, 24 Jan 2025 14:17:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用+-h计算梯度时误差会更小？</title>
      <link>https://stats.stackexchange.com/questions/660475/why-is-the-error-smaller-using-h-to-calculate-gradients</link>
      <description><![CDATA[这里他们说：

这需要您评估损失函数两次以检查梯度的每个维度（因此成本大约是原来的 2 倍），但梯度近似结果要精确得多。要看到这一点，您可以使用 f(x+h)
和 f(x−h) 的泰勒展开式，并验证第一个公式的误差为 O(h)
，而第二个公式的误差项仅为 O(h2)
（即它是二阶近似）。

上下文：与 f(x+h) - f(h) 比较
问题
证明这一点应遵循哪些数学步骤？
我尝试计算该系列，但无法将其与他们的段落匹配。]]></description>
      <guid>https://stats.stackexchange.com/questions/660475/why-is-the-error-smaller-using-h-to-calculate-gradients</guid>
      <pubDate>Fri, 24 Jan 2025 13:13:48 GMT</pubDate>
    </item>
    <item>
      <title>竞争风险模型外部验证的校准曲线：为什么需要互补对数-对数变换？</title>
      <link>https://stats.stackexchange.com/questions/660474/calibration-curve-for-external-validation-of-competing-risks-model-why-the-need</link>
      <description><![CDATA[我想制作一条平滑的校准曲线，以从外部验证竞争风险模型。我遵循本文中提出的建议：
https://diagnprognres.biomedcentral.com/articles/10.1186/s41512-021-00114-6
标题为：“竞争风险模型的图形校准曲线和校准指标”的部分。
这建议在我们想要从外部验证的模型的预测风险（概率）的互补对数对数的样条上拟合观察到的生存率（时间、事件）的竞争风险模型（例如原因特定 Cox 模型、Fine-Gray 模型等）。假设有足够多的事件，我理解使用样条函数实现非线性的好处。但为什么在拟合模型之前需要对独立变量进行互补对数-对数变换？]]></description>
      <guid>https://stats.stackexchange.com/questions/660474/calibration-curve-for-external-validation-of-competing-risks-model-why-the-need</guid>
      <pubDate>Fri, 24 Jan 2025 13:11:41 GMT</pubDate>
    </item>
    <item>
      <title>具有可训练基线风险的 Cox 模型</title>
      <link>https://stats.stackexchange.com/questions/660473/cox-model-with-trainable-baseline-hazard</link>
      <description><![CDATA[我正在研究生存分析，并使用 Cox 比例风险模型。在大多数实现中，使用部分似然估计模型参数，然后使用 Breslow 估计量（或类似方法）估计基线风险函数。
但是，我想知道：
为什么我们不最大化完全似然，联合估计模型参数和基线风险函数？
例如，如果我们将基线风险建模为分段常数函数，原则上我们可以最大化回归系数和基线风险的完全似然。这似乎可以提供一种更直接的估计方法。
完全似然方法不常用的理论或实际原因/含义是什么？这种方法是否在文献中得到研究或实施？如果是，我在哪里可以找到相关论文或参考文献？]]></description>
      <guid>https://stats.stackexchange.com/questions/660473/cox-model-with-trainable-baseline-hazard</guid>
      <pubDate>Fri, 24 Jan 2025 12:47:28 GMT</pubDate>
    </item>
    <item>
      <title>哪些损失函数可以用 Lipschitz 梯度微分？</title>
      <link>https://stats.stackexchange.com/questions/660471/which-loss-functions-are-differentiable-with-lipschitz-gradient</link>
      <description><![CDATA[我正在阅读一篇优化论文，该论文要求损失函数具有 Lipschitz 梯度可微分性。我发现一些资料表明线性和逻辑回归的损失函数满足这一点，但我无法找到有关 GLM 系列其他成员的任何资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/660471/which-loss-functions-are-differentiable-with-lipschitz-gradient</guid>
      <pubDate>Fri, 24 Jan 2025 12:41:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 Kaplan-Meier 解决方法计算累积发生率？</title>
      <link>https://stats.stackexchange.com/questions/660468/compute-cumulative-incidence-with-workaround-kaplan-meier</link>
      <description><![CDATA[我们能否通过这种方式计算累积发生率函数：为除关注事件之外的竞争事件的所有人分配最大跟进时间，并在该时间点对其进行审查。然后在此转换后的数据集上计算关注事件的 KM。然后 1-KM 将呈现累积发生率函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/660468/compute-cumulative-incidence-with-workaround-kaplan-meier</guid>
      <pubDate>Fri, 24 Jan 2025 12:02:41 GMT</pubDate>
    </item>
    <item>
      <title>我们可以在序数数据上使用重测信度吗？数据输入为 0,1,2</title>
      <link>https://stats.stackexchange.com/questions/660462/can-we-use-test-retest-reliability-on-ordinal-data-the-data-is-entered-with-0-1</link>
      <description><![CDATA[我需要有人解释如何对序数数据 (0、1、2) 执行重测信度，其中 0 = 尝试失败，1 = 1 次成功尝试，2 = 2 次成功尝试。&quot;]]></description>
      <guid>https://stats.stackexchange.com/questions/660462/can-we-use-test-retest-reliability-on-ordinal-data-the-data-is-entered-with-0-1</guid>
      <pubDate>Fri, 24 Jan 2025 10:18:24 GMT</pubDate>
    </item>
    <item>
      <title>对分类响应变量和比例作为解释变量进行建模/显着性检验</title>
      <link>https://stats.stackexchange.com/questions/660457/modelling-significance-testing-for-a-categorical-response-variable-and-proportio</link>
      <description><![CDATA[我是一名初学研究生，正在尝试首次建模。我正在努力寻找适合我的变量的正确模型。我的结果相当简单，所以我担心我可能会忽略最简单的解决方案。
-我有一个具有三个级别的分类响应变量（这些类别是根据个体的生长特征而分为“慢”、“中”和“快”的类别）。这些类别虽然有名称，但都是名义上的，因为它们不是由单个变量定义的。
-解释变量是这些个体所经历的良好和不良喂养周的比例，范围从 0-1。每个个体生长了多个星期，并且根据喂养质量（在之前的分析步骤中确定）将每个单独的星期分配为良好或不良。例如，一只生长了 8 周的动物可能经历了 3 个好周和 5 个坏周，因此好周的比例为：3/8 = 0.375。
我想知道本周质量比例是否能解释个体属于哪个类别。
尝试：
所以我的第一个想法是使用 GLM 来模拟分类响应变量，但据我所知，GLM 主要用于计数（泊松系列）或比例/二元（二项式）响应变量。问题当然是我的解释变量是一个比例，而不是我的响应。如果我运行以比例为响应的模型，它与所有经过检查的假设完全吻合，这很糟糕，因为这不是我希望我的分析测试的内容。
我研究过多项逻辑回归，有人告诉我它可能适用于我的变量。但考虑到我的结果很简单，它似乎很复杂。我只想比较组之间的平均值，而不是从一个类别转移到另一个类别的对数几率（我理解多项式是如何工作的）。
因此，我尝试了 Kruskal-Wallis 检验，因为我的比例不遵循正态性，因为它们是有界的。
我想我是在向比我更了解的人寻求确认。多项式方法可能是我想要的，但 Kruskal-Wallis 检验似乎不错，但它是一个简单的测试。只是我对我为这些数据选择的模型并不完全有信心，所以我不能选择一种方法而不是另一种方法。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/660457/modelling-significance-testing-for-a-categorical-response-variable-and-proportio</guid>
      <pubDate>Fri, 24 Jan 2025 03:40:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么在复协方差中共轭第二个变量？</title>
      <link>https://stats.stackexchange.com/questions/660451/why-conjugate-second-variable-in-complex-covariance</link>
      <description><![CDATA[除了历史/传统原因之外，是否有任何实际原因可以解释为什么两个复变量 $z$ 和 $w$ 的协方差应该写成
$$\mathrm{Cov}[z,w] = \mathrm{E}[(z-\mathrm{E}[z])(w-\mathrm{E}[w])^\ast]\quad\cdots(1)$$
而不是
$$\mathrm{Cov}[z,w] = \mathrm{E}[(z-\mathrm{E}[z])^\ast(w-\mathrm{E}[w])]\quad\cdots(2)$$
?
符号 (2) 与物理学中用于矢量的符号更一致，因为考虑 $\mathbf{z}\cdot\mathbf{w} = \mathbf{w}^{H}\mathbf{z}$ 是违反直觉的。同样，在互相关的情况下，当应用卷积定理时，共轭是第一个参数。
例如，符号 (1) 在 维基百科 中被简单提及：

请注意定义中第二个因子的复杂共轭。

这根本不能解释原因。
这是历史事实吗？或者是否有任何实际理由来共轭第二个变量？此外，符号 (1) 在文本和计算机代码中有多“普遍”？]]></description>
      <guid>https://stats.stackexchange.com/questions/660451/why-conjugate-second-variable-in-complex-covariance</guid>
      <pubDate>Fri, 24 Jan 2025 02:09:13 GMT</pubDate>
    </item>
    <item>
      <title>SelectKBest 中的 f_classif 和 f_regression 给出的分数是多少？</title>
      <link>https://stats.stackexchange.com/questions/660448/what-is-the-score-given-by-f-classif-and-f-regression-in-selectkbest</link>
      <description><![CDATA[我试图了解 Scikit-Learn 包中的 SelectKBest。它为每个预测变量给出一个分数（均使用 f_classif 和 f_regression）。但是，这似乎不是 F-score（精确度和召回率的调和平均值），因为它通常大于 1（有时大于 1000）。 SelectKBest 给出的分数到底表示什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660448/what-is-the-score-given-by-f-classif-and-f-regression-in-selectkbest</guid>
      <pubDate>Fri, 24 Jan 2025 01:11:28 GMT</pubDate>
    </item>
    <item>
      <title>如何让 simsurv 与自定义风险函数一起工作</title>
      <link>https://stats.stackexchange.com/questions/660436/how-to-get-simsurv-to-work-with-a-custom-hazard-function</link>
      <description><![CDATA[我试图在非比例风险（即时间相关效应）假设下模拟 Royston-Parmar 模型的生存数据。
我为 R 中的 simsurv 函数定义了一个自定义风险函数。但是我收到错误，uniroot 求解器无法运行，因为端点处的 f() 值不是相反的符号。
我研究了我定义的 logcumhazard 函数的作用。结果表明，总体风险不是单调的，并且有很多振荡。如果我用 0 代替 x，它会变得平滑和单调。我尝试了很多不同的事情，比如改变样条系数、真实系数、时间相关效应、将基函数移位为正值、将其改为风险函数。我不确定我还能做什么。有没有办法修复这个问题或者让它工作？
模型：
logH(t, x) = spline(t, gamma) + X * beta1 + beta2 * log(t)
H_t &lt;- function(t, x, betas) {
shift = 2
gamma0 = 2; gamma1 = -0.2; gamma2 = 0.2; gamma3 = 0.3
tde = 0.5
基础 &lt;- ns(t, df = 4)
baseline_hazard = gamma0 * basis[,1] + gamma1 * basis[,2] + gamma2 * basis[,3] + gamma3 * basis[,4]
time_effect &lt;- betas[&quot;geo&quot;] * x + tde * log(t+0.1)
hazard &lt;- baseline_hazard + time_effect
return(hazard)
}
cov &lt;- data.frame(id = 1:N, geo = rnorm(N, 5, 0.5))

true = log(3)
dat &lt;- simsurv(logcumhazard = H_t,
betas = c(geo = true),
x = cov,
maxt = 10,
interval = c(1e-6, 12))

错误stats::uniroot(rootfn_cumhazard, cumhazard = cumhazard, x = x_i, : 
端点处的 f() 值不为相反符号

查看这些图以了解我对风险波动的理解。
N = 1000
t = seq(1e-6, 12, length.out = 1000)
betas = c(geo = true)
plot(t, H_t(t, cov$geo, betas), type = &#39;l&#39;)
plot(t, baseline_hazard)
plot(t, time_effect)

注意：我尝试过没有自定义风险函数的 simsurv，但它不适用于我的应用程序。]]></description>
      <guid>https://stats.stackexchange.com/questions/660436/how-to-get-simsurv-to-work-with-a-custom-hazard-function</guid>
      <pubDate>Thu, 23 Jan 2025 20:21:05 GMT</pubDate>
    </item>
    <item>
      <title>多次模拟的总体平均值和标准差</title>
      <link>https://stats.stackexchange.com/questions/660435/aggregate-mean-and-standard-deviation-from-multiple-simulations</link>
      <description><![CDATA[编辑：
我有一个作物模型，我用它来模拟全国每个地区的作物总产量。地区级产量也有标准差。我如何从这些数据中得出国家级总产量以及国家级标准差。]]></description>
      <guid>https://stats.stackexchange.com/questions/660435/aggregate-mean-and-standard-deviation-from-multiple-simulations</guid>
      <pubDate>Thu, 23 Jan 2025 19:20:40 GMT</pubDate>
    </item>
    <item>
      <title>是否可以汇总 AIC/BIC 值以进行参与者级模型比较？</title>
      <link>https://stats.stackexchange.com/questions/660262/is-it-possible-to-aggregate-aic-bic-values-for-participant-level-model-compariso</link>
      <description><![CDATA[我有一个数据集，其中包含来自数百名参与者的情绪时间序列数据，他们每个人都参加了生态瞬时评估 (EMA) 研究。由于每个参与者的事件时间完全不同，我决定使用 R 中的药代动力学建模包 (mrgsolve) 生成的复杂非线性模型分别拟合每个参与者的数据。
我使用 nloptr 根据从先验知识得出的初步猜测来推导参数。由于呈现的模型数量庞大，手动优化每个模型的参数并不切实际。相反，我使用合理但未优化的参数值运行这些模型，这实际上效果很好，因为每个参与者对事件的情绪反应模式大致相似。
对于每个模型，我的零假设是数据纯粹由噪声组成。我的备选假设是，药代动力学衍生的模型在模拟参与者的情绪反应方面优于噪声模型。到目前为止，药代动力学模型似乎在几乎（但不是所有）情况下都产生了更优的 RSS 和 AIC/BIC 值。
有没有办法批量测试药代动力学建模方法产生更优的建模结果的假设，表明其所基于的模型优于噪声的零假设？例如，如果 95%（或其他百分比）的药代动力学模型产生比基于噪声的模型更优的拟合结果，这可以用来证明统计意义吗？或者是否有另一种基于指标的方法来测试这个假设，例如比较每个参与者的每个模型之间的 AIC 和 BIC 值，并将这些值汇总到所有参与者中？]]></description>
      <guid>https://stats.stackexchange.com/questions/660262/is-it-possible-to-aggregate-aic-bic-values-for-participant-level-model-compariso</guid>
      <pubDate>Mon, 20 Jan 2025 08:21:49 GMT</pubDate>
    </item>
    </channel>
</rss>