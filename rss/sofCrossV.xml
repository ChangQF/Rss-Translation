<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 24 Dec 2024 12:32:11 GMT</lastBuildDate>
    <item>
      <title>在具有许多零值的数据中选择正确的相关方法</title>
      <link>https://stats.stackexchange.com/questions/659150/picking-the-right-correlation-method-in-data-that-has-many-zero-values</link>
      <description><![CDATA[我想计算我的数据中两个基因之间的相关性。到目前为止，我所做的是计算 Pearson 或 Spearman 相关性（我更依赖 Spearman，因为基因之间没有线性关系）。
但是 - 许多细胞对基因 1、基因 2 或两者的表达为零，这导致相关性不准确和偏差。
所以我有一些选择 -

我可以只保留表达两个基因的细胞（这将删除大量细胞），然后重新计算相关性。
我应该保留零，因为它是生物学的一部分
使用对零不太敏感的其他方法，例如余弦相似度？

例如，这里有一个图 - 每个点是一个细胞，X 轴是基因 1 的表达，Y 轴是基因 2 的表达：
]]></description>
      <guid>https://stats.stackexchange.com/questions/659150/picking-the-right-correlation-method-in-data-that-has-many-zero-values</guid>
      <pubDate>Tue, 24 Dec 2024 11:42:54 GMT</pubDate>
    </item>
    <item>
      <title>何时在图学习管道（PyTorch Geometric）中执行节点/边图特征提取？</title>
      <link>https://stats.stackexchange.com/questions/659149/when-to-perform-node-edge-graph-feature-extraction-in-graph-learning-pipeline-p</link>
      <description><![CDATA[我有一个 CSV 文件，可以将其转换为 PyG 图形数据对象，用于边缘分类任务。在此之前，我想到使用 NetworkX 库添加一些功能。
但是，由于创建图形后，我将把它拆分为 train/val/test，然后使用数据加载器，我不确定基于图形的预处理应该在拆分之前完成，还是在拆分之后（在创建数据加载器之前）完成，还是在数据加载器构造内部/之后完成。
如果答案是在数据加载器构造内部/之后，这是否意味着我必须为我想要添加的每个功能实现自定义转换，基本上将图形转换为 networkx 图，提取特征，然后将图形重新转换为 pyg？最好的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659149/when-to-perform-node-edge-graph-feature-extraction-in-graph-learning-pipeline-p</guid>
      <pubDate>Tue, 24 Dec 2024 11:37:31 GMT</pubDate>
    </item>
    <item>
      <title>如何为由另外两个类组成的类设计网络和损失函数？</title>
      <link>https://stats.stackexchange.com/questions/659148/how-to-design-a-network-and-loss-function-for-classes-composed-of-two-other-cla</link>
      <description><![CDATA[给定一个包含三个类别的图像数据集，A、B 和 C，其中 C 是 A 和 B 的组合，我们希望训练一个分类器来预测：

如果只有 A，则为 A
如果只有 B，则为 B
如果 A 和 B 都存在，则为 C。

我们如何设计最终的分类层以及损失函数？
我考虑过对 C 类进行阈值处理，即使使用可学习的阈值，但这会受到数据集中类别分布的严重影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/659148/how-to-design-a-network-and-loss-function-for-classes-composed-of-two-other-cla</guid>
      <pubDate>Tue, 24 Dec 2024 11:28:42 GMT</pubDate>
    </item>
    <item>
      <title>如何选择一个固定的 $x_{t-1}$ 值来可视化 MLE 之后的条件密度 $f(x_t \mid x_{t-1})$？</title>
      <link>https://stats.stackexchange.com/questions/659146/how-to-choose-a-fixed-value-of-x-t-1-for-visualizing-conditional-density-f</link>
      <description><![CDATA[假设我已经对某个数据集进行了最大似然估计，以找到某个条件密度函数 $f(x_t\mid x_{t-1})$ 的参数，其中 RHS 将取决于 $x_{t-1}$ 的某个值。
如果我要绘制数据的直方图并与 MLE 找到的密度叠加，我将如何选择要修复哪个 $x_{t-1}$ 值进行绘图？或者在这种情况下绘图时的便利性是否不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/659146/how-to-choose-a-fixed-value-of-x-t-1-for-visualizing-conditional-density-f</guid>
      <pubDate>Tue, 24 Dec 2024 10:05:01 GMT</pubDate>
    </item>
    <item>
      <title>可视化多种样品类型和杂质水平的 PCA 结果</title>
      <link>https://stats.stackexchange.com/questions/659145/visualizing-pca-results-with-multiple-sample-types-and-impurity-levels</link>
      <description><![CDATA[我正在对一个数据集执行主成分分析 (PCA)，该数据集包含四种材料 (a、b、c、d) 的样本，这些样本的杂质水平各不相同 (10%、20%、30% 和 40%)。此外，还有一个纯样本 (p)。
我打算使用 R 创建一个分数图，以根据这些样本的主要成分直观地显示这些样本的分离情况。我希望在图中有效地表示样本类型 (a、b、c、d、p) 和杂质水平 (10%、20%、30%、40%)。
我正在寻找有关如何在分数图中以最佳方式直观地编码此双重信息 (样本类型和杂质水平) 的建议。是否有既定的最佳实践或建议用于在 PCA 得分图中表示多个分类变量？
其他详细信息
• 数据有 17 列（a、b、c、d 及其级别以及纯样本）和 949 行。
任何见解或建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659145/visualizing-pca-results-with-multiple-sample-types-and-impurity-levels</guid>
      <pubDate>Tue, 24 Dec 2024 09:54:49 GMT</pubDate>
    </item>
    <item>
      <title>训练损失波动很大，而验证损失没问题，可能是什么问题？</title>
      <link>https://stats.stackexchange.com/questions/659144/the-training-loss-fluctuates-a-lot-while-the-validation-loss-is-ok-what-could</link>
      <description><![CDATA[我正在训练一个神经网络 (CNN) 以完成回归任务（图像中的对象面积估计）。我的训练损失总是波动很大，而我的验证损失与训练损失相比还算可以。]]></description>
      <guid>https://stats.stackexchange.com/questions/659144/the-training-loss-fluctuates-a-lot-while-the-validation-loss-is-ok-what-could</guid>
      <pubDate>Tue, 24 Dec 2024 09:26:23 GMT</pubDate>
    </item>
    <item>
      <title>这是正确的吗？为我的回归模型设置一个基线变量</title>
      <link>https://stats.stackexchange.com/questions/659142/is-this-correct-set-a-baseline-variable-for-my-regression-model</link>
      <description><![CDATA[请帮帮我！我不确定如何为我的回归模型设置基线变量。我正在尝试使用以下变量来预测房屋的转售价值。：
分类变量
城镇 - 其中 26 个分为 5 个区域（防止过度拟合） - 5 个虚拟变量（东北、东部、中部、北部、西部）
flattype - 数组（[&#39;1 ROOM&#39;, &#39;2 ROOM&#39;, &#39;3 ROOM&#39;, &#39;4 ROOM&#39;, &#39;5 ROOM&#39;, &#39;EXECUTIVE&#39;, &#39;MULTI-GENERATION] - 6 个虚拟变量
连续变量
floor_area 平方米 - 最小 31 和最大 366.7
剩余租约 - 转换为月份 min_lease, max_lease - (495, 1173)
转售价格
我已为我的回归模型，我没有在模型中包含 north 和 flat_type_room_1 - 它会自动将 north 和 flat_type_room_1 设置为基线模型吗？：
# 定义因变量（转售价格）

Y = new_data_with_dummies[&#39;resale_price&#39;]

# 通过提取数值数据定义自变量

independent_columns = [

&#39;floor_area_sqm&#39;, &#39;remaining_lease_months&#39;,

&#39;region_West&#39;, &#39;region_East&#39;,

&#39;region_Central&#39;, &#39;region_Northeast&#39;,

&#39;flat_type_ROOM_2&#39;, &#39;flat_type_ROOM_3&#39;, &#39;flat_type_ROOM_4&#39;,

&#39;flat_type_ROOM_5&#39;, &#39;flat_type_EXECUTIVE&#39;, &#39;flat_type_MULTI-GENERATION&#39; #north 和flat_type_room_1 未包含在模型中

]

# 将独立变量提取到普通的 NumPy 数组中

X = np.column_stack([new_data_with_dummies[col] for col in independent_columns])

# 添加常数（截距）

X = sm.add_constant(X)

# 使用适当的变量名称拟合多元线性回归模型

linear_model = sm.OLS(Y, X)

result = linear_model.fit()

# 显示模型摘要

print(result.summary(xname=[&#39;const&#39;] + independent_columns))
]]></description>
      <guid>https://stats.stackexchange.com/questions/659142/is-this-correct-set-a-baseline-variable-for-my-regression-model</guid>
      <pubDate>Tue, 24 Dec 2024 04:51:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的不确定性估计没有给出预期的结果？</title>
      <link>https://stats.stackexchange.com/questions/659140/why-does-my-uncertainty-estimation-not-give-the-expected-result</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659140/why-does-my-uncertainty-estimation-not-give-the-expected-result</guid>
      <pubDate>Tue, 24 Dec 2024 01:14:03 GMT</pubDate>
    </item>
    <item>
      <title>如何开始使用 Python 中的项目反应理论[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659132/how-to-get-started-with-item-response-theory-in-python</link>
      <description><![CDATA[我有一个大型 CSV 文件，其中包含（String studentId、String questionId、bool isCorrect）。问题都是小学的基本数学知识，questionIds 指的是一组类似的问题。例如，我们有这样的 questionId

OPlusO（包含 2+3、5+4 等练习）
OPlusT（包含 2+10、20+4、30+7 等练习）
OPlusOWithCarry（7+8、5+9 等）
Times2（3x2、7x2 等）

一个学生可以对一个 questionId 有多个答案，我们假设所有学生练习都是在一周内完成的。 （我们有一年多的数据）
在第一阶段，我想确定问题 ID 的难度并评估学生的能力。
我认为 IRT 模型在这里很有用，所以我想开始使用它来获得一些实践经验。
但我不确定从哪里/如何开始。最好使用 Python，因为我习惯了，但其他（命令行）工具也可以。我在 Linux 上。
ChatGPT 和 Claude 都让我误以为几行代码就足够了，但都没有给出一个可行的示例。
提前谢谢，
Marc]]></description>
      <guid>https://stats.stackexchange.com/questions/659132/how-to-get-started-with-item-response-theory-in-python</guid>
      <pubDate>Mon, 23 Dec 2024 17:27:05 GMT</pubDate>
    </item>
    <item>
      <title>跨栏模型等同于零膨胀模型吗？</title>
      <link>https://stats.stackexchange.com/questions/659119/are-hurdle-models-equivalent-to-zero-inflated-models</link>
      <description><![CDATA[换句话说，障碍模型可以转换为零膨胀模型吗？
我正在查看障碍模型的维基百科页面（https://en.wikipedia.org/wiki/Hurdle_model）。据我理解，障碍模型只是零概率，对于非零情况，则是严格非零分布。
零膨胀模型是零概率，对于其他情况，则是包含零的分布。
所以你可以采用零膨胀模型，将零概率分解为单一情况，然后将其称为障碍模型，对吗？我遗漏了什么吗？
它们似乎都能够形成相同的总概率分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/659119/are-hurdle-models-equivalent-to-zero-inflated-models</guid>
      <pubDate>Mon, 23 Dec 2024 10:49:34 GMT</pubDate>
    </item>
    <item>
      <title>简单线性回归中的 F 检验</title>
      <link>https://stats.stackexchange.com/questions/659114/f-test-in-simple-linear-regression</link>
      <description><![CDATA[我试图理解 F 检验对简单线性回归 (SLR) 模型有效性的检验，但我对此有几个问题：

为什么我们要用 SSR 除以独立变量的数量（SLR 为 1），用 SSE 除以自由度的数量（SLR 为 n-2）？为什么不用两者除以独立变量的数量，这样我们就可以计算出与独立变量相对应的平均解释/未解释变异性？

在 $\beta_1 = 0$ 的零假设下，检验统计量的 F 分布如何？

]]></description>
      <guid>https://stats.stackexchange.com/questions/659114/f-test-in-simple-linear-regression</guid>
      <pubDate>Mon, 23 Dec 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>在评估 GLM 模型时，AIC 值或预测显著性的 p 值更重要吗？</title>
      <link>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</guid>
      <pubDate>Sat, 21 Dec 2024 15:14:21 GMT</pubDate>
    </item>
    <item>
      <title>基于相关性的特征消除的优化算法[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658075/optimized-algorithms-for-correlation-based-feature-elimination</link>
      <description><![CDATA[背景：我有一个包含近一百万行和 2000 列的大型数据框。我正在尝试使用变量之间的相关性进行特征消除。当然，问题在于，对于一​​组 n 个特征，我们需要 nC2 或 n*(n-1)/2 个组合之间的相关性，这本身就使其成为 O(n^2) 操作。
基础数据：全部为数值。
所以我想知道我们是否可以使用一些分而治之的策略来优化这一点，如下所示：

计算 20 个批次（每个批次 100 列）之间的相关性
消除高度相关的特征（阈值 &gt; 95%）
组合剩余的特征（大约 1000 个），再次分成 20 个批次
重复上述过程，直到达到固定的列阈值（我们可以一起处理，例如 200 个）
从中计算最后一次相关性并删除相关特征

我想知道如果此方法有效，或者是否有进一步优化的方法可用于此目的。我还想知道这是否适用于不同类型的相关性，如斯皮尔曼、肯德尔等。
假设：此方法做出了这个重要假设：

如果 f1 和 f2 的相关度 &gt;95%，f2 和 f3 的相关度也 &gt;95%，那么我们假设 f1 和 f3 的相关度也 &gt;95%。

我不确定这是否有具体的理论基础，并希望听听您对如何证明不同类型的相关性的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/658075/optimized-algorithms-for-correlation-based-feature-elimination</guid>
      <pubDate>Sat, 30 Nov 2024 19:29:22 GMT</pubDate>
    </item>
    <item>
      <title>没有真实标签的模型比较</title>
      <link>https://stats.stackexchange.com/questions/657699/model-intercomparison-with-no-ground-truth-labels</link>
      <description><![CDATA[领域是天气建模。我有 4 个不同的模型，其中一个是我的，而其他 3 个是独立模型，我认为这些模型相对熟练（即比随机模型好得多）。每个模型在 1000 个感兴趣的空间位置（我将它们称为节点）中的每一个上预测一个值。遗憾的是，每个节点的真实值是无法测量的，因此无法明确地说出哪个模型最好。
但是，我可以说我的模型的预测（模型 A）与其他模型的相关性比任何其他模型都更好：




A
B
C
D




A
1
0.636338
0.571829
0.569591


B
0.636338
1
0.251786
0.283723


C
0.571829
0.251786
1
0.299746


D
0.569591
0.283723
0.299746
1



模型 A 比其他任何模型都更善于预测模型 B，A 与 C 和 A 与 D 也是如此。由于每个模型的预测都是一些预测的组合“真实”信号和一些噪音/错误，我假设我更好的整体相关性意味着我的模型可能比任何其他模型捕获更多的“真实”信号和更少的噪音。
这是一个有效的结论吗？如果是这样，有没有办法量化它，或者我可以引用一个参考资料来支持这个说法？]]></description>
      <guid>https://stats.stackexchange.com/questions/657699/model-intercomparison-with-no-ground-truth-labels</guid>
      <pubDate>Fri, 22 Nov 2024 20:20:57 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中使用 clogit 函数计算 R 平方</title>
      <link>https://stats.stackexchange.com/questions/642639/how-to-calculate-r-squared-after-using-clogit-function-in-r</link>
      <description><![CDATA[我尝试使用 R 中的 mice 包进行多次插补后，使用 clogit 函数计算逻辑回归模型的 R 平方值。以下是该模型的代码：
fitt2 &lt;- with(imp30, 
clogit(Prognosis ~ stromal_TILs + hair_follicles + 
Upward_scatter, strata(Set_ID)))
summary(pool(fitt2), conf.int = TRUE, exponentiate = TRUE)

mice 包中的 pool.r.squared() 似乎仅适用于 lm()。我如何获得此模型的 R 平方值？]]></description>
      <guid>https://stats.stackexchange.com/questions/642639/how-to-calculate-r-squared-after-using-clogit-function-in-r</guid>
      <pubDate>Tue, 12 Mar 2024 14:04:41 GMT</pubDate>
    </item>
    </channel>
</rss>