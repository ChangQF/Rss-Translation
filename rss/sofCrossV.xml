<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 07 Aug 2024 12:29:56 GMT</lastBuildDate>
    <item>
      <title>具有给定标准差的样本的分布均值分布</title>
      <link>https://stats.stackexchange.com/questions/652435/distribution-of-the-mean-of-distributions-for-samples-with-a-given-standard-devi</link>
      <description><![CDATA[我有一个正态分布 $N(0, \sigma^2)$。如果我开始从该分布中选择所有分布 $N(\mu, \sigma^2/2)$，则平均值 $\mu$ 的分布参数是什么：$N(0, ?)$？标准差是多少？
换句话说，如果有一组 $N(\mu, \sigma^2/2)$ 分布，它们共同构成 $N(0, \sigma^2)$ 分布，那么 $\mu$ 的分布应该是什么？有两个极值点。如果我选​​择具有相同标准差 $\sigma^2$ 的分布，则会出现这种情况。在这种情况下，$\mu$ 的标准差将趋向于零，n-&gt;inf。如果我从 $N(0, \sigma^2)$ 中选择一个点，那么 $\mu$ 的标准差将等于 $\sigma^2$。]]></description>
      <guid>https://stats.stackexchange.com/questions/652435/distribution-of-the-mean-of-distributions-for-samples-with-a-given-standard-devi</guid>
      <pubDate>Wed, 07 Aug 2024 11:47:55 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 中的分割值代表什么含义？</title>
      <link>https://stats.stackexchange.com/questions/652434/what-does-the-values-in-the-splits-from-xgboost-mean</link>
      <description><![CDATA[我已经使用 caret 包在 R 中训练了一个 XGBoost 模型。
变量中的值被分为 2 到 5 组。
我已经成功提取了所有分割，但分割值不是原始分组值，而是其他值。

我能以某种方式找到此分割的真实值吗？
模型中的这个值到底是什么？
这个值与分组值相对应吗？




变量
分割条件
XGB 值
真实值




Var1
lessThan
-132.25705
97.71 或-152.46


Var1
greaterOrEqual
-132.25705
97.71 或 -152.46


Var2
lessThan
-48.036224
55.853485 或 -14.946478


]]></description>
      <guid>https://stats.stackexchange.com/questions/652434/what-does-the-values-in-the-splits-from-xgboost-mean</guid>
      <pubDate>Wed, 07 Aug 2024 11:33:38 GMT</pubDate>
    </item>
    <item>
      <title>在精确匹配中丢弃观察结果后，如何解决解释/普遍性方面的潜在问题？</title>
      <link>https://stats.stackexchange.com/questions/652433/how-to-adress-potential-issues-with-interpretation-generalizability-after-discar</link>
      <description><![CDATA[如果观测值没有完全匹配，则将其丢弃，这可能会导致匹配样本中的协变量分布与原始样本不同。
我假设在某种程度的差异下（如果我错了，请纠正我），这种差异会影响对发现的可能解释，例如，ATE 不能再被解释为原始样本的 ATE。发现的有效性将仅限于匹配样本。如果意图是从样本推广到总体，这尤其成问题，因为现在我甚至不能再从匹配样本推广到原始样本，更不用说推广到总体了。
有没有办法判断匹配样本和原始样本是否差异太大？如果是这样，是否有策略来解决这个问题，或者我应该切换到不会丢弃（尽可能多的）观测值的匹配方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/652433/how-to-adress-potential-issues-with-interpretation-generalizability-after-discar</guid>
      <pubDate>Wed, 07 Aug 2024 11:32:17 GMT</pubDate>
    </item>
    <item>
      <title>帮助解释 GLM 交互效应（带偏移的泊松）</title>
      <link>https://stats.stackexchange.com/questions/652431/help-interpreting-glm-interaction-effect-poisson-with-offset</link>
      <description><![CDATA[我使用泊松 glm 和偏移变量对计数变量进行了建模。我正在研究取样年份对“老年人”（&gt; 年龄 x）与年轻人（&lt; 年龄 x）相比执行行为的次数的影响。偏移变量是 ln（观察时间）。我加入了一个交互项，因为我预计老年人类别中的个体比年轻人类别中的个体经历更严重的生物衰老，因此多年来应该表现出更严重的关系。我的模型输出似乎就是这种情况：
固定效应：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -0.57004 0.10661 -5.347 8.96e-08 ***
Year_Scaled -0.12309 0.07831 -1.572 0.1160 
OldY -0.19841 0.14128 -1.404 0.1602 
Year_Scaled:OldY -0.21954 0.09609 -2.285 0.0223 * 

我想估计交互作用对随时间变化的比率的影响大小。但我该怎么做呢？到目前为止，我已经构建了以下方程来估计每年“老年”个体的比率：
exp(Intercept + YEAR*(Year_Scaled:OldY)) = 该年的比率
我不确定的是，我是否需要在此方程中包含不显著的项？我知道我的交互项的显著性与年轻个体的斜率有关，所以我是否需要调整我的方程来解释这个斜率？例如。
exp(Intercept + YEAR*(Year_Scaled + Year_Scaled:OldY)) = 当年的比率
同样，我是否也需要考虑旧组的截距，即使它并不显著？
exp(Intercept + OLDY + YEAR*(Year_Scaled + Year_Scaled:OldY)) = 当年的比率。
我想我想得太多了，但我需要一些建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/652431/help-interpreting-glm-interaction-effect-poisson-with-offset</guid>
      <pubDate>Wed, 07 Aug 2024 10:29:13 GMT</pubDate>
    </item>
    <item>
      <title>某个因素的主要影响是什么？</title>
      <link>https://stats.stackexchange.com/questions/652428/whats-the-main-effect-for-a-factor</link>
      <description><![CDATA[这是我在这里的第一个问题。补充一点背景信息：我正在研究实验设计，在因子主效应部分遇到了麻烦。我了解到，如果您有 $k$ 个因子，每个因子有 $2$ 个级别，例如0 和 1，重复 $n$ 次，那么因子 $A$ 的主效应为
$$
\delta A = \frac{[A1]-[A0]}{2 n}
$$
其中 $[A1]$ 是 $A=1$ 等情况下的结果总和。
第一个问题，为什么会这样？我的意思是为什么是这样而不是相反？即
$$
\delta A = \frac{[A0]-[A1]}{ 2n}
$$
第二个问题，当一个因子有两个以上的水平时，它的主要影响是什么？
第三个问题，在我的笔记中，我有因子“i”在水平“q”上的主要影响是
$$
\delta_{iq}=m_{iq}-m
$$
其中 $m$ 显然是所有实验的平均值，而 $m_{iq}$ 是因子 $i$ 等于水平 $q$ 的实验的平均值。如果这是真的，那么我不明白为什么第一个是正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652428/whats-the-main-effect-for-a-factor</guid>
      <pubDate>Wed, 07 Aug 2024 09:09:59 GMT</pubDate>
    </item>
    <item>
      <title>用于评估特征解释力的逻辑回归——分数和置信度的解释</title>
      <link>https://stats.stackexchange.com/questions/652427/logistic-regression-for-evaluating-explanatory-power-of-features-interpretatio</link>
      <description><![CDATA[我需要帮助来确定我的分析是否合理。
我的目标是评估一组特定特征对于二元分类问题的解释力。
我目前的策略是：

选择不相关且具有统计意义的特征（t 检验）
使用这些特征拟合逻辑回归模型 (sklearn)
通过查看系数来比较特征的强度
通过从决策函数中获取置信度值和分数来评估这些特征的解释力 - 在训练数据上测试模型。

这是我不确定的地方。我的直觉告诉我，在训练数据上进行测试总是错误的（呃）。但我的大脑告诉我，在这种情况下这样做是有意义的。我想知道根据我的特征提供的信息，有多少数据点是可以区分的 - 而不是它对看不见的数据会做出什么反应。
大致来说，这是我的思考过程：

高置信度，高分 =&gt; 特征很好
高置信度，低分 =&gt; 特征具有误导性
低置信度，高分 =&gt; 特征具有信息性但不是那么强
低置信度，低分 =&gt; 特征没有信息性

这个分析方案合理吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652427/logistic-regression-for-evaluating-explanatory-power-of-features-interpretatio</guid>
      <pubDate>Wed, 07 Aug 2024 08:51:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAM 调查多个时期之间的受试者内部差异</title>
      <link>https://stats.stackexchange.com/questions/652425/using-gam-to-investigate-the-within-subject-variation-between-several-periods</link>
      <description><![CDATA[我的研究问题是分析个体内（受试者内）接触模式的异质性，并确定封锁前和封锁期间稳定接触行为的决定因素。由于接触模式与参与者的年龄和接触地点有关，因此下图显示了研究人群的接触模式。

如图所示，由于按位置分层的联系人数和年龄之间的关联似乎遵循不同的模式，因此联系数据按位置分层。并根据不同地点建立模型。
首先我建立一个初步模型来估计theta
prelim_model &lt;- gam(n ~ s(age, by = period, k = 5) + 
s(token, bs = &quot;re&quot;) + s(Bundesland, bs = &quot;re&quot;), 
data = data_education, 
family = nb())

theta_est &lt;- prelim_model$family$getTheta(TRUE) 
theta_est 

因为我想根据period和within-subject考察变量对接触人数的影响，在比较了AIC和BIC之后，最终的模型是这样的：
gam(n ~ s(age, by = period, k = 3) + period * sex + s(hh_size, by = period, k = 3) + 
period * employment_2cat + period * education_2cat + period * marital_2cat + 
period * weekend + period * region + period * Transportation_2cat + period + 
s(token, bs = &quot;re&quot;) + s(Bundesland, bs = &quot;re&quot;), 
data = data_education, 
family = nb(theta = theta_est)) # 使用我从初步模型中获得的 theta



从结果来看：

婚姻状况在统计上不显著
两个交互项在统计上都不显著
年龄对联系人数量有显著的非线性影响
家庭规模仅在第 3 期对联系人数量有显著的非线性影响
个人行为对联系次数有很大影响。

我使用 DHARMa 残差和 gam.check 来检查模型


我的问题如下：

我按照位置划分数据集，然后单独建立模型，这种方法合理吗？
我已经尝试过其他方法，包括泊松分布的GLMM，ng分布的GLMM，ng分布的零膨胀模型。当我使用 DHARMa 残差检查模型时，结果更糟糕。
由于分析结果中截距、周期 2、周期 3 的标准误差较大，且与 QQ 图残差存在显著差异，并且如 gam.check 的结果所示，我应该如何改进模型？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652425/using-gam-to-investigate-the-within-subject-variation-between-several-periods</guid>
      <pubDate>Wed, 07 Aug 2024 08:36:29 GMT</pubDate>
    </item>
    <item>
      <title>聚类后​​我可以使用方差分析吗？</title>
      <link>https://stats.stackexchange.com/questions/652423/can-i-use-anova-after-clustering</link>
      <description><![CDATA[我正在帮助某人分析植物物种的数据。他们将一个城镇划分为大小相等的方块，并收集每个方块中生长的杂草物种的数据。我使用聚类分析 (Ward.D2) 根据物种组成对方块进行分组。结果看起来很合理。有关于大多数物种生态特征的数据（埃伦伯格值等）。我现在可以进行第二次分析，将埃伦伯格值应用于每个聚类中的物种，并使用方差分析来查看哪些埃伦伯格值（例如氮、pH）在划分方块时最重要吗？或者还有其他方法可以做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/652423/can-i-use-anova-after-clustering</guid>
      <pubDate>Wed, 07 Aug 2024 08:28:23 GMT</pubDate>
    </item>
    <item>
      <title>如何测试“无显着差异”？ [重复]</title>
      <link>https://stats.stackexchange.com/questions/652420/how-to-test-for-no-significant-difference</link>
      <description><![CDATA[我的公司从事游戏开发。我们正在尝试测试在特定位置添加更多广告是否会对玩家参与度产生不利影响（减少游戏时间、留存率等）。
你们能就如何进行和分析 A/B 测试给我一些建议吗？通常，我们测试并使用 t 检验来分析显著差异，而不是反过来，所以我在这里有点困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/652420/how-to-test-for-no-significant-difference</guid>
      <pubDate>Wed, 07 Aug 2024 06:52:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的不相关回归量的回归中存在遗漏变量偏差？</title>
      <link>https://stats.stackexchange.com/questions/652416/why-is-there-omitted-variable-bias-in-my-regression-of-uncorrelated-regressors</link>
      <description><![CDATA[我正在对伯努利不相关变量运行 LASSO 回归，即每个变量都有 $\frac{1}{2}$ 的概率取值为 0 或 1。我的理解是，在这种情况下不应该有遗漏的变量偏差。但是，当我省略一些变量时，剩余的回归量之一似乎会随着其他变量的省略而不断变大。这个回归量恰好是迄今为止系数最大的回归量。
有人能帮我理解为什么在这种情况下会有遗漏的变量偏差吗？我能想到的唯一其他会使模型无效的原因是假设残差与回归量不相关。这也许是在省略其他变量时最大系数持续变大的原因吗？
或者原因更可能与 LASSO 正则化有关？我的理解是，LASSO 将小系数缩小到 0，但可以通过使大系数更大来进行“补偿”。那么这也适用于省略的变量偏差吗？即，在套索回归中，如果我们删除一些具有大系数的回归量，正则化是否会导致剩余的一些系数按比例变大？
编辑：
我尝试运行没有 LASSO 正则化的回归，当省略一些变量时，我仍然看到该首项系数中的偏差。所以我认为它一定来自与残差的相关性？
保罗]]></description>
      <guid>https://stats.stackexchange.com/questions/652416/why-is-there-omitted-variable-bias-in-my-regression-of-uncorrelated-regressors</guid>
      <pubDate>Wed, 07 Aug 2024 02:57:16 GMT</pubDate>
    </item>
    <item>
      <title>随机向量中乘积变量的独立性</title>
      <link>https://stats.stackexchange.com/questions/652408/independence-of-product-variables-in-random-vectors</link>
      <description><![CDATA[考虑一个随机向量$U = (U_1,U_2)$，其中$U_1$和$U_2$是独立且同分布的。设$X =(X_1,X_2)$，其中$X_1$和$X_2$是相关随机变量。
假设$X = (X_1,X_2)$和$U = (U_1,U_2)$是独立的。定义 $Z_1 = X_1 U_1$ 和 $Z_2 = X_2 U_2$。当前的问题是确定变量 $Z_1$ 和 $Z_2$ 是否独立。
尝试：
为了调查 $Z_1$ 和 $Z_2$ 的独立性，我们需要分析它们的联合分布。令 $f_{Z_1,Z_2}(z_1,z_2)$ 表示 $Z_1$ 和 $Z_2$ 的联合分布。我们可以将此联合分布表示为：
$$f_{Z_1,Z_2}(z_1,z_2) = \int_{-\infty}^{\infty} f_{X_1,X_2}(z_1/u_1,z_2/u_2) \, f_{U_1,U_2}(u_1,u_2) \, du_1 \, du_2.$$
如果此表达式不能分解为 $Z_1$ 和 $Z_2$ 的边际分布的乘积，则 $Z_1$ 和 $Z_2$ 不是独立。
有反例吗？或者这是真的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652408/independence-of-product-variables-in-random-vectors</guid>
      <pubDate>Tue, 06 Aug 2024 23:18:05 GMT</pubDate>
    </item>
    <item>
      <title>当 f 不服从正态分布时，误差传播的方差公式是否有用？</title>
      <link>https://stats.stackexchange.com/questions/652401/is-the-variance-formula-for-error-propagation-useful-when-f-is-not-normally-dist</link>
      <description><![CDATA[我对不同的属性进行了 n 次测量。例如，物体的重量和体积 (n=2)。
由于测量结果存在不确定性，我将其建模为
n 个独立随机变量 $X_i$，它们呈正态分布，未知 $\mu_i$。然而，不确定性是由我的仪器决定的。例如，我的体重可能只能精确到克。
在这种情况下，我会说不确定性是 $\pm 0.5 g$。
因此，我假设 $\sigma_i = 0.25 g$，因为这意味着有 95% 的置信度
$$ 
\mu_i - 2\sigma_i &lt;= xi &lt;= \mu_i + 2\sigma_i
$$
其中 $\mu_i$ 是实际重量，$x_i$ 是测量重量。
我有一个函数 f，它是 $X_i$ 的非线性组合。
例如$f=密度 = 重量/体积$。
方差公式 (1) 指出：
$$
\sigma_f^2 \approx \Sigma_{i=1}^N (\frac{\partial f}{\partial X_i}\sigma_i)^2 
$$
假设 f 的泰勒展开式收敛。
但是由于 f 通常不是正态分布，$\sigma_f$ 有多大用处？
当然，我可以找到范围：
$$
-2\sigma_f &lt;= f &lt;= 2\sigma_f
$$
但我不知道这是 95% 还是 5% 的置信区间。
1 不确定性传播]]></description>
      <guid>https://stats.stackexchange.com/questions/652401/is-the-variance-formula-for-error-propagation-useful-when-f-is-not-normally-dist</guid>
      <pubDate>Tue, 06 Aug 2024 21:13:07 GMT</pubDate>
    </item>
    <item>
      <title>方程数多于解的线性方程组</title>
      <link>https://stats.stackexchange.com/questions/652385/system-of-linear-equations-with-more-equations-than-solutions</link>
      <description><![CDATA[如何确定方程数多于解数的线性方程组的解？
例如，我有产品 A、B 和 C，以及同事数 D。每天 n_D 个同事会生产 n_A 份产品 A、n_B 份产品 B 和 n_C 份产品 C。每件产品的生产需要时间 t_A、t_B 和 t_C。一天的时间是 t_D。
因此，搜索的方程式是 n_A * t_A + n_B * t_B + n_C * t_C = n_D * t_D。
我有数千行，其中包含 n_A、n_B、n_C 和 n_D 的条目。时间 t_D 是常数（一天）。如何计算时间 t_A...t_C？如果我的数据表恰好有三行，我就可以精确地解方程式。如果有更多行，我应该能够以某种方式计算每个的平均值和标准差，对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652385/system-of-linear-equations-with-more-equations-than-solutions</guid>
      <pubDate>Tue, 06 Aug 2024 15:51:51 GMT</pubDate>
    </item>
    <item>
      <title>通过优化拟合优度参数设置数据过滤器[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652380/setting-data-filters-by-optimizing-on-goodness-of-fit-parameter</link>
      <description><![CDATA[我不是数学家、统计学家或数据科学家，但我是一个试图将时间序列分析应用到我的科学领域的人。所以请原谅我的问题中的任何无知：D
数据和统计模型
我有一个性能数据的时间序列，其中包含季节性成分、大量噪音和我们想要提取的趋势信号。趋势信号通常被认为是线性的，尽管众所周知这通常是一种简化。在我的领域，已经测试了各种统计模型来提取线性趋势信号。最常用的方法之一是同比 (YoY) 方法，它本质上考虑了数据的季节性。
过滤的必要性
为了减少噪音以帮助确定潜在的趋势信号，可能需要应用各种数据过滤器。在这个研究领域，还没有一种既定的方法来设置这些参数，到目前为止，这都取决于分析师的判断，尽管过滤可能会显著影响最终的估计值。所需的过滤器还取决于获取性能数据的系统；不同的系统有不同的噪声源等。过滤通常是在 5 分钟、15 分钟或每小时分辨率的原始数据上进行的，然后再汇总为每日、每周或每月的值，然后对其应用 YoY。
我的方法
目前，我正在研究一种通过最小化/最大化可以从数据集中提取的一些参数来设置过滤器参数的方法；与目前最先进的方法相比，这种方法可能更具可重复性、自动化和独立于分析师。这构成了一个多维优化问题，我借助贝叶斯优化解决了这个问题。
问题
我现在试图找出选择应用于数据的过滤器和过滤器参数的最佳优化参数是什么。由于历史原因，我首先最小化置信区间（通过引导法在 YoY 方法中确定）。即算法搜索给出最低置信区间的过滤器/过滤器值组合，并将此过滤器组合的趋势估计作为最佳估计。然而，置信区间不是准确度的度量，而准确度是我的主要目标。相反，我现在正在考虑将以下内容作为替代优化参数：

R 平方（计算 YoY 与过滤数据相比的最佳趋势线）- 在我看来，与作为精度度量的置信区间相比，R 平方是拟合精度的更直接度量。
调整后的 R 平方 - 应该比 R 平方有所改进，因为它会惩罚过于激进的过滤，这会导致 YoY 方法只留下很少的数据点，从而可以防止过度拟合数据子集。
赤池信息准则 - 我的理解是，这应该能够给出给定数据集的不同统计模型的相对质量，我认为这相当于评估相同数据的不同过滤变体的相同统计模型的相对质量（？）。使用 AICc 而不是 AIC 似乎适合惩罚激进的过滤。
某种形式的交叉验证。虽然我相信这可能是合适的，但我想知道这对这个问题来说是否太复杂了（？）。

所以，我当然可以测试所有这些，看看哪个看起来效果最好。但在我开始之前，我想从任何真正精通数据科学和统计学的人那里得到以下方面的意见
问题
从理论或根本原因来看，所提出的任何参数对于当前的问题来说是否更好或更坏？为什么？
如果您需要更多信息来了解我的问题和/或对我的问题提供意见，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/652380/setting-data-filters-by-optimizing-on-goodness-of-fit-parameter</guid>
      <pubDate>Tue, 06 Aug 2024 13:00:29 GMT</pubDate>
    </item>
    <item>
      <title>John A.Rice 著作《数理统计与数据分析》中的练习 39</title>
      <link>https://stats.stackexchange.com/questions/652424/exercise-39-of-john-a-rice-book-mathematical-statistics-and-data-analysis</link>
      <description><![CDATA[我正在学习 John A. Rice 的《数理统计与数据分析》一书。在第 4 章中，我遇到了一个很难解决的练习，如果能给我一点提示，我将不胜感激。
练习 39：
假设要对长度为 $N = 1,000,000$ 的 DNA 片段进行散弹枪测序，片段长度为 $L_F = 1000$。

a. 需要多少个片段才能使单个位点被覆盖的概率大于 0.99？
b.有了这种选择，您预计会错过多少个站点？

让 $x$ 为片段数。我相信我应该根据 $x$ 估计站点至少出现在一个片段中的概率。如果站点 $s$ 位于前 $10^6 - 10^3$ 个位置内，则左端点位于 $s-1000$ 和 $s$ 之间的所有片段都将包含站点 $s$，右端点位于 $s + 1$ 和 $s + 1000$ 之间的所有片段也将包含站点。但是，我不确定如何对这些片段端点的分布进行建模。如能提供任何指导，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/652424/exercise-39-of-john-a-rice-book-mathematical-statistics-and-data-analysis</guid>
      <pubDate>Mon, 05 Aug 2024 19:12:37 GMT</pubDate>
    </item>
    </channel>
</rss>