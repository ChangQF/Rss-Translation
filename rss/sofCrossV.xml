<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 17 Apr 2024 15:16:49 GMT</lastBuildDate>
    <item>
      <title>是否有某种多级 KNN/ML 模型可以用来确定哪些用户会购买特定产品？</title>
      <link>https://stats.stackexchange.com/questions/645235/is-there-some-sort-of-multilevel-knn-ml-model-i-can-use-to-figure-out-which-user</link>
      <description><![CDATA[我想知道是否有某种多层次模型可以用来识别特定产品的可能买家或创建相似的受众群体。
问题是我有 1000 种产品和大约 100 万用户。为每种产品创建一个模型在计算上是不可行的。
我想到的结构是第一级是产品，下一级是数据库中的所有用户。
我可以使用某种机器学习算法来实现这一目标吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645235/is-there-some-sort-of-multilevel-knn-ml-model-i-can-use-to-figure-out-which-user</guid>
      <pubDate>Wed, 17 Apr 2024 15:01:00 GMT</pubDate>
    </item>
    <item>
      <title>在无意识统计学家定律中， $p(Y=y_1) = p(X\in g^{-1}(y_1))$ 是约定还是可以导出？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/645234/in-the-law-of-the-unconscious-statistician-is-py-y-1-px-in-g-1y-1</link>
      <description><![CDATA[对于无意识统计学家定律，我不太确定。
设 $X$ 为随机变量，$Y=g(X)$ 为另一个随机变量一个。
当我们修复 $y$ 时，例如 $y=4$，我们有 &lt; span class=&quot;math-container&quot;&gt;$p(Y=4)=p(X=4)+p(X=5)$。
为什么我们有这个？这是一个约定吗？即我们修复 $p(Y=y_1) = p(X\ing g^{-1}(y_1))$ 吗？或者是否可以从假设中推导出来？
我怀疑提出的第二个假设是否可能，因为我们只是从假设 $Y=g(X)$ 开始。
]]></description>
      <guid>https://stats.stackexchange.com/questions/645234/in-the-law-of-the-unconscious-statistician-is-py-y-1-px-in-g-1y-1</guid>
      <pubDate>Wed, 17 Apr 2024 14:46:26 GMT</pubDate>
    </item>
    <item>
      <title>关于包含自变量的问题</title>
      <link>https://stats.stackexchange.com/questions/645233/question-about-including-an-independent-variable</link>
      <description><![CDATA[我正在寻求有关是否在我的分析中包含自变量“吸烟”（是/否）的建议。
目标是研究 COVID-19 对女性建筑工人的影响。结果变量是受试者（女性建筑工人）在 COVID-19 期间是否受雇（是/否）。
该数据集包含来自美国 13 个随机招募地点的数据，全部由女性组成。由于主题嵌套在站点内，我假设变量“吸烟状态”（是/否）也嵌套在站点内。
事实上，变量“吸烟状况”（是/否）高度不平衡（90% 否，10% 是）。在执行简单的双变量分析（吸烟状况与工作地点（美国 13 个地点））时，地点与吸烟的交叉表显示，大多数女性（与 10 个地点相关）对吸烟表示“不”，只有随机变化其余 3 个站点中女性的回答。
理论上，在新冠肺炎期间吸烟与就业之间存在密切关系（是/否）。然而，鉴于该变量高度不平衡的性质，我正在考虑是否在我的分析中包含变量“吸烟状况”。
非常感谢您的意见或建议。提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/645233/question-about-including-an-independent-variable</guid>
      <pubDate>Wed, 17 Apr 2024 14:37:31 GMT</pubDate>
    </item>
    <item>
      <title>比较 beta 回归模型与随机效应的最佳诊断特征是什么？</title>
      <link>https://stats.stackexchange.com/questions/645230/what-is-the-best-diagnostic-fearure-for-comparing-beta-regression-model-with-ran</link>
      <description><![CDATA[我已经进行了两次具有两种随机效应的建模实验。结果如下；
&lt;前&gt;&lt;代码&gt;型号 1

betareg(公式 = 男性比例 ~ a + b + c + d | 农场, 数据 = 数据,
    类型=“ML”）

标准化加权残差2：
    最小 1Q 中值 3Q 最大
  -3.08 -0.7751 -0.04 0.887 2.451

系数（带有 logit 链接的平均模型）：
             估计标准。误差z值Pr(&gt;|z|)
（截距）-0.07 0.01 -8.4 2.5e-16 ***
-0.08 0.01 -7.6 4.3e-15 ***
b 0.12 0.01 10.02＜ 2.3e-16***
c -0.04 0.01 -3.14 0.00312 **
d 0.07 0.01 4.3 2.21e-06 ***

Phi系数（带对数链接的精度模型）：
            估计标准。误差z值Pr(&gt;|z|)
(截距) 4.68113 0.16 33.40 &lt;2e-16 ***
农场 0.10 0.01 6.967 &lt;2e-16 ***
---
西尼夫。代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1&#39;&#39;1

估计器类型：ML（最大似然）
对数似然：7 Df 上为 1007
伪 R 平方：0.201
迭代次数：14 (BFGS) + 3（Fisher 评分）

型号2

betareg(公式 = 男性比例 ~ a + b + c + d | 年，
    数据=数据，类型=“ML”）

标准化加权残差2：
    最小 1Q 中值 3Q 最大
  -2.42 -0.83 -0.09 0.67 3.42

系数（带有 logit 链接的平均模型）：
             估计标准。误差z值Pr(&gt;|z|)
（截距）-0.05 0.08 -6.30 5.43e-10 ***
-0.09 0.02 -7.36 8.64e-13 ***
b 0.13 0.02 11.12＜ 2e-16 ***
c 0.03 0.01 1.4 0.0617 。
d -0.004 0.015 -0.317 0.851

Phi系数（带对数链接的精度模型）：
              估计标准。误差z值Pr(&gt;|z|)
（截距）-51.60 10.25 -7.654 2.46e-11 ***
      年 0.04 0.005 7.51 8.21e-12 ***
---
西尼夫。代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1&#39;&#39;1

估计器类型：ML（最大似然）
对数似然：7 Df 上的 994
伪 R 平方：0.22
迭代次数：15 (BFGS) + 4（Fisher 评分）

我的推断是，尽管模型 2 的伪 R2 值稍好，但相对较高的 phi 系数、较高的对数似然以及模型 1 中预测变量与响应变量的强关联，使得模型 1 优于模型2.这个推论对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645230/what-is-the-best-diagnostic-fearure-for-comparing-beta-regression-model-with-ran</guid>
      <pubDate>Wed, 17 Apr 2024 13:50:17 GMT</pubDate>
    </item>
    <item>
      <title>是否有可能建立一个仅具有一种混合物先验的混合模型？</title>
      <link>https://stats.stackexchange.com/questions/645229/is-it-possible-to-have-a-mixture-model-with-a-prior-on-only-one-mixture</link>
      <description><![CDATA[我有一个由指数和逻辑混合（两者都有协变量）组成的混合模型，我使用 EM 算法对其进行估计，但是当将模型拟合到新数据集时，逻辑部分存在一些可分离性问题。我发现这篇论文（Gelman 2008，DOI：10.1214/08-AOAS191），似乎添加一个先前的（他们建议Cauchy(0, 2.5)) 到逻辑回归可以解决问题，但我不明白如何仅在逻辑混合上实现先验。我希望获得一些有关如何执行此操作或是否可以估计的提示？]]></description>
      <guid>https://stats.stackexchange.com/questions/645229/is-it-possible-to-have-a-mixture-model-with-a-prior-on-only-one-mixture</guid>
      <pubDate>Wed, 17 Apr 2024 13:44:13 GMT</pubDate>
    </item>
    <item>
      <title>spss中序数回归中负系数的解释</title>
      <link>https://stats.stackexchange.com/questions/645228/interpretation-of-negative-coefficients-in-ordinal-regression-in-spss</link>
      <description><![CDATA[我在 spss 中为 Likert 量表中的数据构建了序数回归 (logit)。我将自变量放入因子中，而不是协变量中。据我了解，这应该用序数尺度来完成。
如何正确解读SPSS中的输出结果？
结果示例：
因变量 = [1] coef = -4.56
因变量 = [2] coef = -2.33
...
因变量 = [5] coef = -0,84
因子 1 = [1] coef = -1,2
因子 1 = [2] coef = -0,8
...
因子 1 = [5] coef = 0^a
因子 2 = [1] coef = -0,8
因子 2 = [2] coef = -0,4
...
因子 2 = [5] coef = 0^a
因子 3 = [1] coef = - 1,22
因子 3 = [2] coef = - 0,99
...
因子 3 = [5] coef = 0^a
我是否正确理解负系数表明，如果您在因子中选择低分，则在因变量中标记较低分数的概率会增加？
因变量中的负系数意味着什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/645228/interpretation-of-negative-coefficients-in-ordinal-regression-in-spss</guid>
      <pubDate>Wed, 17 Apr 2024 13:38:05 GMT</pubDate>
    </item>
    <item>
      <title>如何计算出有多少项目会超出错误阈值？</title>
      <link>https://stats.stackexchange.com/questions/645225/how-do-i-figure-out-how-many-items-i-should-expect-to-exceed-my-error-threshold</link>
      <description><![CDATA[让我解释一下我正在使用哪些数字，然后我会解释问题。

我计算了一家商店去年所有商品的第 99 个百分位预测误差阈值。
然后，我报告过去两周内错误大于该阈值的项目数。 （无论是一天还是十四天，如果预测误差大于阈值，就会被标记。）

好的，就这样了。问题是，我想知道，在统计上，如何在给定计算方法的一般细节的情况下计算将标记的预期项目数量，以便我可以看到何时出现偏差。
我想到了泊松，因为这基本上是一个到达率问题，但这在我的脑海中感觉是循环的，因为 λ 是我开始想要的，而且我不确定我会使用什么无论如何，对于其余参数。
我的经理认为会是 1%，但我认为这是天真的地将一年内计算的 99% 的交易预测为未来 2 周内的到达率。如果这是真的，你会期望 1% 的物品会触发一天、一周、一个月，这显然是不可能的，对吧？时间越长，触发的项目就越多，时间越短，触发的项目就越少。我不确定这两周时间是否是用于计算阈值的数据的一部分是否相关？
我可以通过什么统计方法来确定预期比例？
澄清编辑：我已经在我的数据上运行了这个，所以我知道我的具体案例的基线是什么。但我不知道如何计算一般情况下触发的预期项目数。我只是想知道你会如何做到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/645225/how-do-i-figure-out-how-many-items-i-should-expect-to-exceed-my-error-threshold</guid>
      <pubDate>Wed, 17 Apr 2024 12:59:24 GMT</pubDate>
    </item>
    <item>
      <title>OLS 与 ARCH 对条件平均参数的不同估计</title>
      <link>https://stats.stackexchange.com/questions/645224/different-estimates-of-conditional-mean-parameters-from-ols-vs-arch</link>
      <description><![CDATA[考虑安全性的市场模型$i$：
$$
R_{i,t}=\alpha_i + \beta_i R_{m,t} + e_{i,t}。
$$
我用OLS方法估计了参数。
 coef std err t P&gt;|t| [0.025 0.975]
-------------------------------------------------- ----------------------------
常量 0.0219 0.040 0.548 0.584 -0.056 0.100
指数 1.2734 0.028 44.718 0.000 1.218 1.329

不过，对于每日频率，误差项显示 ARCH 效应，因此我使用 GARCH(1,1) 模型。
garch = arch_model(Y, X,mean=“LS”, vol=“GARCH”, p=1, q=1, dist=“t”, rescale=False)
results_garch = garch.fit()

输出：
 coef std err t P&gt;|t| 95.0% 浓度国际。
-------------------------------------------------- ---------------------------
常量 -0.0240 2.971e-02 -0.809 0.418 [-8.226e-02,3.418e-02]
指数 1.2203 4.473e-02 27.284 6.517e-164 [ 1.133, 1.308]
                              波动率模型
=================================================== =========================
                 coef std err t P&gt;|t| 95.0% 浓度国际。
-------------------------------------------------- ------------------------
欧米茄 0.4857 0.267 1.816 6.935e-02 [-3.847e-02, 1.010]
α[1] 0.1344 5.834e-02 2.304 2.123e-02 [2.007e-02, 0.249]
贝塔[1] 0.6634 0.155 4.275 1.913e-05 [ 0.359, 0.968]

$\hat\beta_{\text{ARCH}}$（系统风险，1.2203）低于$\hat\beta_{\text{OLS}}$ (1.2734) 具有相同的安全性？我认为它只是改变了标准错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/645224/different-estimates-of-conditional-mean-parameters-from-ols-vs-arch</guid>
      <pubDate>Wed, 17 Apr 2024 12:49:25 GMT</pubDate>
    </item>
    <item>
      <title>正常 RV 的标准差依赖于另一个正常 RV 的置信区间</title>
      <link>https://stats.stackexchange.com/questions/645223/confidence-interval-for-a-normal-rv-that-its-std-is-dependent-on-another-normal</link>
      <description><![CDATA[问题：
假设 $X\sim\mathcal{N}(\mu_X,a),Y\sim\mathcal{N}(\mu_Y,b\cdot\mu_X)$&lt; /span&gt; 其中 $a$ 和 $b$ 已知，但 $\mu_X$ 和 $\mu_Y$ 不是。根据对 $X$ 和 $\mu_Y$ 给出什么置信区间=“数学容器”&gt;$Y$？
假设：
$X&gt;0$（其负值可以忽略不计）。如果您愿意，它是截断正态分布。
我的尝试：
由于 $\mu_X$ 未知，并且仅 $a$ 已知，给定 $x$ 来自 $X$，我们知道 $d_1 \%$ 置信度（例如 $d_1=95$），$x\in[\mu_X- a\cdot Z_{d_1},\infty]$，或者换句话说，我们可以绑定 $\mu_X\leq x+a\cdot Z_{d_1}$&lt; /span&gt;，以及相应的 $Z$-score。
这意味着有了 $d_1\%$ 置信度，我们可以限制 $Y$ 的标准差span&gt;: $\sigma_Y\leq b\cdot(x+a\cdot Z_{d_1})$。
现在从 $Y$ 给出 $y$，在我们有 $\mu_X$，我们可以说，有了$d_2\%$的信心，
\begin{方程}\mu_y\in[y-b\cdot(x+a\cdot Z_{d_1})\cdot Z_{\frac{d_2+100}{2}}, y+b\cdot(x+a\cdot Z_{d_1})\cdot Z_{\frac{d_2+100}{2}}]\end{方程}
总置信度为 $100\cdot\frac{d_1}{100}\cdot\frac{d_2}{100}\%$。
有关我的尝试的问题：

我觉得最后一部分不准确，我从上面限制了 $\sigma_y$，那么我是否需要对 $\sigma_y$ 或者我可以只使用一种概率分布 $\mathcal{N}(\mu_y, b\cdot(x+a \cdot Z_{d_1}))$?
我见过使用两个置信区间的不同方法，例如 这个问题使用Delta方法。但是，由于它不是两个参数的乘积，而是一个参数是另一个参数的函数，所以我不知道该怎么做。

提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/645223/confidence-interval-for-a-normal-rv-that-its-std-is-dependent-on-another-normal</guid>
      <pubDate>Wed, 17 Apr 2024 12:11:55 GMT</pubDate>
    </item>
    <item>
      <title>了解 PROC LOGISTIC (SAS) SCORE 语句中的 PRIOR 选项</title>
      <link>https://stats.stackexchange.com/questions/645222/understanding-prior-option-in-score-statement-for-proc-logistic-sas</link>
      <description><![CDATA[假设我有一个二元响应，我想使用协变量 $x$ 上的逻辑回归进行建模。使用 PROC LOGISTIC 拟合模型将拟合模型的 MLE 系数
$$
\text{logit}(\pi) = \alpha + \beta&#39; x
$$
其中 $\pi = \pi(x) = \mathbb{P}(y=1|x)$。
如果我们在训练数据集上构建这个模型，我们可以使用 OUTMODEL 来保存模型信息。假设我们想要获得新数据集的预测概率，我们可以使用 INMODEL 和 SCORE 语句对该数据集进行评分。
现在，我注意到 SCORE 语句中有一个选项 PRIOR/PRIOREVENT，它允许指定事件的先验概率 $y=1$。我明白为什么这很有用；例如，如果训练数据集中的类别比例与现实中的真实比例非常不同（例如罕见疾病分类）。
SAS 文档说“通过指定正确的先验，可以适当调整后验概率。”因此，使用此选项应该调整预测概率。
我的问题是：如何进行调整？
我有以下理论的灵感来自这篇文章，但在 SAS 文档中找不到任何内容来证实这一点：
&lt;块引用&gt;
令 $p_\text{train}$ 为训练数据中事件的比例，
并令 $p_\text{prior}$ 为事件的先验概率。然后
在对数赔率级别，我们进行调整： $$ \alpha + \beta&#39; x +
 \left(\frac{p_\text{先验}}{1-p_\text{先验}} - \frac{p_\text{train}}{1-p_\text{train}}\right)。 $$ 换句话说，我们调整后的
预测（后验）概率变为 $$
 \text{logit}^{-1}(\alpha + \beta&#39; x + \left(\frac{p_\text{先验}}{1-p_\text{先验}} - \frac{p_\text{训练}}{1-p_\text{训练}}\right))。 $$
]]></description>
      <guid>https://stats.stackexchange.com/questions/645222/understanding-prior-option-in-score-statement-for-proc-logistic-sas</guid>
      <pubDate>Wed, 17 Apr 2024 12:08:34 GMT</pubDate>
    </item>
    <item>
      <title>累积发生率函数和 cox 回归结果相反</title>
      <link>https://stats.stackexchange.com/questions/645219/opposite-results-from-cumulative-incidence-function-and-cox-regression</link>
      <description><![CDATA[我对握力 (HGS) 与认知障碍之间的关联感兴趣。我的暴露是 HGS（二进制为正常编码 0 和弱编码 1），感兴趣的事件是认知障碍（将 MMSE &lt; 24 定义为认知障碍编码 1）。我的队列如下图所示，第 1 波到第 6 波，对所有第 1 波到第 6 波进行了 MMSE 测量，但 HGS 仅针对第 3 波到第 6 波。我可以说参与者可能有不同的纳入时间（包括在不同的波次）。所以，我所做的是：


我在第 3 波之前排除了患有 MMSE 的个体，因为我没有第 1 波和第 2 波的 HGS 测量值。然后，我排除了在自己的基线上存在认知障碍的个体，以确保他们没有认知障碍处于基线。

我将时间定义为年龄。如果事件从未发生，则编码为 0，并且如果死亡发生在 fup 结束之前，则定义竞争死亡风险并编码为 2。如果事件发生在 fup 期间，编码为 1。

HGS 被定义为随时间变化的协变量。如下表所示：



首先提取在纳入时具有正常 HGS 的个体，并在 fup 结束之前获得弱 HGS。
示例：ID 1 的患者在 75 岁时进入研究，在 81 岁时 HGS 较弱，并在 85 岁时发生该事件。ID 2 的患者在 76 岁时进入研究，在 79 岁时 HGS 较弱，但到最后一次随访时，他已经 88 岁了，还没有经历过该事件。

然后我对 HGS 状态的累积发生函数进行了分层。


和考克斯回归。不违反 PH 假设。


然而，从考克斯我得到HR&gt;图 1 显示 HGS 较弱的人出现认知障碍的风险较高。但我从累积发生率曲线中看到的是完全相反的。我想知道有人可以指导我为什么吗？我错过了什么？我可能有什么不朽的时间偏见吗？或者可能是其他问题？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/645219/opposite-results-from-cumulative-incidence-function-and-cox-regression</guid>
      <pubDate>Wed, 17 Apr 2024 11:41:57 GMT</pubDate>
    </item>
    <item>
      <title>自变量t.test比较与一类线性回归模型的区别？</title>
      <link>https://stats.stackexchange.com/questions/645218/difference-between-a-comparison-of-independent-variables-t-test-and-linear-regre</link>
      <description><![CDATA[问题是，我正在尝试获得根据干预措施分为两组的患者的几个变量（食物、血液化学分析...）的置信区间。到目前为止，我一直在获取 p 值，但我们正在向置信区间迈进
这里存在数学疑问，也许它非常基本，但我完全监督了。
到目前为止我所做的事情是
#being dat 数据库
# 变量1是定量的、连续的、正态分布的
# 类别有 2 个类别，但对于某些分析将是 3 个
pvalue &lt;- car::Anova(lm(variable1 ~category), dat), type=2)$`Pr(&gt;F)`[1]

#pval &lt; 0.05
[1] 0.02088357

#走向置信区间

模型 &lt;- lm(变量 1 ~ 类别), dat)
CI1 &lt;- sprintf(“%.2f”,confint(model)[2,])

sprintf(“%.2f”,confint(lm(模型))[2,])
[1]《3.94》 “46.76”


但我认为我可以轻松地应用独立样本的 t.test 进行相同的操作，认为独立样本的 t.test = 1 个因子的方差分析类似于或等于一个预测变量类别的 lm
#being dat 数据库
J&lt;-t.test(subset(dat,category==“0”)[[“variable”]],subset(dat,category==“1”)[[“d_carnicos_v01”]],配对=F)

J$conf.int
[1] -46.768318 -3.933538
p 值 = 0.02091


我或多或少理解回归倾向于量化一个变量如何随预测变量变化。但我认为成为一个类别就像方差分析
所以：

为什么使用回归模型或 t.test 时统计显着性会有所不同？我想我简化了一些不太明显的步骤（对我来说）
模型的方差分析显示 p 值为 0.02，而区间不包含零。我真的不明白那里的问题的要点，对模型进行方差分析是继承的事情（我没有质疑，错误），但我认为这是正确的并且类似于获取协变量的 conf.int 或兴趣因素
]]></description>
      <guid>https://stats.stackexchange.com/questions/645218/difference-between-a-comparison-of-independent-variables-t-test-and-linear-regre</guid>
      <pubDate>Wed, 17 Apr 2024 11:40:25 GMT</pubDate>
    </item>
    <item>
      <title>是否在confint.svyglm()中指定ddf</title>
      <link>https://stats.stackexchange.com/questions/645214/whether-to-specify-ddf-in-confint-svyglm</link>
      <description><![CDATA[我有一个主要问题是关于是否在 confint.svyglm() 中指定 ddf。使用下面的两个规格会产生略有不同的置信区间。具体来说，我的问题是：

是否最好使用ddf =degf(m$survey.design)？
第二个问题是：哪种方法更可取，Wald 还是 likelihood？

任何想法将不胜感激！
图书馆（调查）
数据（API）

dclus2&lt;-svydesign(id=~dnum+snum, fpc=~fpc1+fpc2, data=apiclus2)
m&lt;-svyglm(I(comp.imp==“是”)~stype*emer+ell, design=dclus2, family=拟二项式)

confint(m, method=“Wald”, parm=c(“ell”,“emer”), ddf = NULL )
confint(m, method=“Wald”, parm=c(“ell”,“emer”), ddf =degf(m$survey.design ) )

confint(m, method=“like”, parm=c(“ell”,“emer”), ddf = NULL )
confint(m, method=“like”, parm=c(“ell”,“emer”), ddf =degf(m$survey.design ) )
]]></description>
      <guid>https://stats.stackexchange.com/questions/645214/whether-to-specify-ddf-in-confint-svyglm</guid>
      <pubDate>Wed, 17 Apr 2024 11:12:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么 SARIMA(0,0,0)(0,1,1)_12 模型的滞后 12 时间序列的差异遵循步骤 12 的 MA(1) 模式？</title>
      <link>https://stats.stackexchange.com/questions/645207/why-the-differenced-at-lag-12-time-series-of-a-sarima0-0-00-1-1-12-model-fol</link>
      <description><![CDATA[我试图理解为什么季节性差异序列的 ACF 揭示了原始序列的 MA 结构的 AR。
例如：
以下几行创建 SARIMA(0,0,0)(0,1,1)_12 时间序列
库(astsa)
ts.value = sarima.sim(D=1, sma=-0.6, S=12, n=200)

该系列的典型情节如下：

从 ACF 图中，我们识别出该序列的 12 个周期。 PACF 图进一步验证了这一说法。
现在，以下几行计算同一系列的第一个季节性差异
ts.value.D1 &lt;- diff(ts.value, lag = 12, Differences = 1)

差分级数对应的图如下。

从 12 差分序列的 ACF 图可以看出，滞后 12 处存在显着的自相关。由于我们知道 MA(1) 模型具有单个非零 ACF 值，因此我们得出结论，原始序列来自 SARIMA(0,0,0)(0,1,1)_12 模型。
这种行为似乎是合理的，但我不清楚这种观察背后的理论。
也就是说，为什么 SARIMA(0,0,0)(0,1,1)_12 模型的滞后 12 时间序列的差分应该遵循步骤 12 的 MA(1) 模式？
注释：

对于 AR(1) 模型可以轻松报告类似的评论。
我发现一篇文章有​​类似言论，但没有给出理论解释。
]]></description>
      <guid>https://stats.stackexchange.com/questions/645207/why-the-differenced-at-lag-12-time-series-of-a-sarima0-0-00-1-1-12-model-fol</guid>
      <pubDate>Wed, 17 Apr 2024 09:19:14 GMT</pubDate>
    </item>
    <item>
      <title>统计方法确定阈值</title>
      <link>https://stats.stackexchange.com/questions/645196/statistical-method-to-determine-threshold</link>
      <description><![CDATA[我有多个样品（包括一个对照样品）的每个细胞的增殖评分。我想确定在我的治疗样本中增殖的细胞相对于对照细胞的百分比是多少。对于如何进行有什么建议吗？
我的想法是使用 Otsu 方法根据样本中细胞的增殖评分找到每个样本的客观阈值。这将找到一个增殖评分阈值，将细胞分为两组，增殖组和非增殖组。然后我可以计算该样本中正在增殖的细胞的百分比。我可以对包括对照在内的每个样本执行此操作，并将处理样本中的细胞增殖百分比与对照进行比较。这听起来合理还是有更好的方法来解决这个问题？感谢任何想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/645196/statistical-method-to-determine-threshold</guid>
      <pubDate>Wed, 17 Apr 2024 04:36:36 GMT</pubDate>
    </item>
    </channel>
</rss>