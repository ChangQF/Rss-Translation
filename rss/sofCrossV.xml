<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 31 Aug 2024 09:15:55 GMT</lastBuildDate>
    <item>
      <title>为什么我们使用 KL 散度而不是交叉熵？</title>
      <link>https://stats.stackexchange.com/questions/653664/why-are-we-using-kl-divergence-over-cross-entropy</link>
      <description><![CDATA[我读过这个问题
为什么我们在 t-SNE 目标函数中使用 Kullback-Leibler 散度而不是交叉熵？
我无法完全理解答案。
如果我们使用 KL 散度作为损失，它不是与使用交叉熵具有相同的效果吗？当 KL 散度很大时，交叉熵也很大，反之亦然。两者的变化量也没有太大区别。此外，KL 散度还有更多项需要计算，即熵。
从这个角度来看，我找不到使用 KL 散度而不是交叉熵的理由。
有人能帮我吗？
（+ 如果 KL 散度真的比交叉熵更好（对于损失函数），我也很好奇为什么有些任务仍在使用交叉熵）]]></description>
      <guid>https://stats.stackexchange.com/questions/653664/why-are-we-using-kl-divergence-over-cross-entropy</guid>
      <pubDate>Sat, 31 Aug 2024 08:48:16 GMT</pubDate>
    </item>
    <item>
      <title>聚类混合数据类型：算法选择、距离测量和特征加权</title>
      <link>https://stats.stackexchange.com/questions/653662/clustering-mixed-data-types-algorithm-selection-distance-measurement-and-feat</link>
      <description><![CDATA[我有一个包含 74,000 条记录的数据库，其中包含 29 个特征。其中 14 个特征是分类特征，并且为 0 或 1，而其他 15 个特征是连续特征，并且已在 0 和 1 之间进行归一化和缩放。我还执行了一些数据清理，并删除了大约 0.4% 的数据以消除异常值。我想运行一个聚类模型，将数据划分为 3 或 4 个聚类。我有以下问题：

如果我有一个包含分类特征和连续特征的相当大的数据库，我应该使用什么算法？
当我同时具有分类特征和连续特征时，我应该如何测量特征之间的距离？
其中三个特征更重要，我想为它们分配更多权重。我应该使用多少权重？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653662/clustering-mixed-data-types-algorithm-selection-distance-measurement-and-feat</guid>
      <pubDate>Sat, 31 Aug 2024 07:46:55 GMT</pubDate>
    </item>
    <item>
      <title>如何概括半参数模型中无偏估计量的非渐近 Cramer-Rao 下界？</title>
      <link>https://stats.stackexchange.com/questions/653661/how-to-generalise-non-asymptotic-cramer-rao-lower-bound-for-unbiased-estimators</link>
      <description><![CDATA[我们都知道经典的 Cramer-Rao 界限，它指定了参数模型中任何无偏估计量的方差的下限。请注意，这个界限是非渐近的，因为它对所有样本数 $n$ 都有效，并且不需要考虑渐近方差。
我对半参数模型进行了调查，但我发现的所有半参数文献都只考虑估计量的渐近方差下限。
因此，我想知道是否有可能在半参数模型中获得 Cramer-Rao 界限的对应项。这个方差下限只能对所有无偏估计量有效，但应该是非渐近的。
欢迎任何相关的想法和文献！]]></description>
      <guid>https://stats.stackexchange.com/questions/653661/how-to-generalise-non-asymptotic-cramer-rao-lower-bound-for-unbiased-estimators</guid>
      <pubDate>Sat, 31 Aug 2024 07:36:55 GMT</pubDate>
    </item>
    <item>
      <title>谱分解后无法反转“重组”矩阵</title>
      <link>https://stats.stackexchange.com/questions/653655/cannot-invert-recomposed-matrix-after-spectral-decomposition</link>
      <description><![CDATA[请耐心听我说完，因为我对线性代数了解不多，对数值线性代数了解就更少了。我正在尝试编写一个 R 函数，该函数在某个时候分解样条基的惩罚矩阵，使得 $K = LL&#39;$。可以使用此矩阵 $L$ 将样条基分解为惩罚部分和非惩罚部分，其中惩罚部分通过计算 $XL(L&#39;L)^{-1}$ 形成，其中 $X$ 是样条基。分解 $K = L&#39;L$ 通常是解析式，但我尝试使用 R 中的 eigen() 函数，通过取 $Q\Lambda^{1/2} = L$ 对任何惩罚矩阵执行此操作。但是，R 抱怨计算 $(L&#39;L)^{1/2}$ 不起作用（系统是计算奇异的），即使我知道 L 的实际形式，并且 $(L&#39;L)^{1/2}$ 肯定是可逆的。
尝试通过 SVD 进行分解也没有用。由于惩罚矩阵不是正定的，因此 cholesky 分解也不起作用。我发现的一个解决方法是使用“Matrix”包中的 nearPD() 函数。在我做的一个小模拟中，这个函数运行得很好，但我不知道它是否适用于更复杂的惩罚矩阵。这里是否有任何准确或被认为是良好实践的方法，可以分解 $K$，以便计算 $(L&#39;L)^{1/2}$？
代码示例：
# 库
library(splines2)
library(Matrix)

# 一些数据
x &lt;- rnorm(10000)
xs &lt;- bSpline(x, df = 22, 截距 = TRUE)

# 构建差异和惩罚矩阵
diff_mat &lt;- t(matrix(c(rep(c(1, -2, 1, rep(0, ncol(xs) - 2)), ncol(xs) - 3), 1, -2, 1), ncol = ncol(xs) - 2))
penalty_mat &lt;- t(diff_mat) %*% diff_mat

# 谱分解
p_eig &lt;- eigen(penalty_mat)
p_diff &lt;- p_eig$vectors %*% sqrt(diag(p_eig$values))

# 这不起作用
pen_mat &lt;- p_diff %*% resolve(t(p_diff) %*% p_diff)

# 这确实有效
pen_mat &lt;- p_diff %*% resolve(nearPD(t(p_diff) %*% p_diff)$mat)
]]></description>
      <guid>https://stats.stackexchange.com/questions/653655/cannot-invert-recomposed-matrix-after-spectral-decomposition</guid>
      <pubDate>Sat, 31 Aug 2024 01:38:45 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯估计和有偏估计</title>
      <link>https://stats.stackexchange.com/questions/653653/bayesian-estimation-and-biased-estimators</link>
      <description><![CDATA[我刚刚学习了非贝叶斯与贝叶斯参数估计。我自己的总结：
非贝叶斯：当参数的统计数据不可用时，CRLB 适用于无偏估计量，但存在有偏估计量优于无偏估计量的情况。
贝叶斯：MMSE 是条件均值，它总是无偏的。贝叶斯 CRLB 也适用于无偏估计量。因此，有偏估计量始终满足贝叶斯 CRLB 并且表现不如无偏 MMSE。
两个问题：
有人可以确认上述我的理解吗？
贝叶斯估计问题中有有偏估计量的良好激励示例吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653653/bayesian-estimation-and-biased-estimators</guid>
      <pubDate>Sat, 31 Aug 2024 01:09:18 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归下推导 MSE($\hat{\beta}$)</title>
      <link>https://stats.stackexchange.com/questions/653651/deriving-mse-hat-beta-under-linear-regression</link>
      <description><![CDATA[我能够推导出 MSE，但是推导过程中有一部分我不太明白。这是我得到的结果：
事实：

$\mathbb{E}(​​\hat{\beta})=\hat{\beta}\space$（无偏估计量）
$\text{Cov}(\hat{\beta})= \sigma^2[(X^TX)^{-1}] $

根据定义，
$$MSE = \mathbb{E}[||\hat{\beta}-\beta||^2] $$
$$= \space \mathbb{E}[(\hat{\beta}-\beta)^T(\hat{\beta}-\beta)]$$
由于 $\hat{\beta}$ 是无偏的，
$$ \boldsymbol{= \text{tr}[\text{Cov}(\hat{\beta})]} *$$
$$= \text{tr}[\sigma^2(X^T X)^{-1}]$$
$\sigma^2$ 是标量，因此可以分解出来，
$$= \sigma^2 tr[(X^T X)^{-1}] $$
我感到困惑的是行 $*$，我不确定我们是如何得到方程式 $ \text{tr}[\text{Cov}(\hat{\beta})] $。以下是我目前所理解的：
通过偏差-方差分解，
$$ \space \mathbb{E}[(\hat{\beta}-\beta)^T(\hat{\beta}-\beta)]=\mathbb{V}(\hat{\beta})+[\mathbb{E}(​​\hat{\beta})-\beta]^T[\mathbb{E}(​​\hat{\beta})-\beta]$$
我们的估计量是无偏的，因此 $\mathbb{E}(​​\hat{\beta})-\beta= 0$。因此，
$$\mathbb{E}[(\hat{\beta}-\beta)^T(\hat{\beta}-\beta)]=\mathbb{V}(\hat{\beta})$$

首先，$\mathbb{V}(\hat{\beta})$ 应该是一个标量，但对我来说这真的没什么意义，这让我想到了下一个问题...
我假设 $V(\hat{\beta}) = \text{tr}[\text{Cov}(\hat{\beta})]$。这是为什么呢？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653651/deriving-mse-hat-beta-under-linear-regression</guid>
      <pubDate>Sat, 31 Aug 2024 00:13:56 GMT</pubDate>
    </item>
    <item>
      <title>Kendall tau-c 永远不可能是 1？</title>
      <link>https://stats.stackexchange.com/questions/653646/kendall-tau-c-can-never-be-1</link>
      <description><![CDATA[我有一个按 5 分制评分的系统（4=非常好，3=好，2=一般，1=差，0=非常差）。现在，我想将它们转换为二进制分数，所以我想设置一个阈值，然后将它们转换为 1/0 分数。我的直觉是，5 分制分数和二进制分数应该始终具有完美的等级相关性，即等级相关性为 1。（信息丢失是另一回事。）
我使用 Kendall tau-c，因为它旨在测量不同数量的可能结果（5 对 2）之间的等级相关性。但我发现在以下最简单的例子中，相关性并不相同，并且远离 1。
print(scipy.stats.kendalltau([0, 0, 0, 0, 1], [0, 1, 2, 3, 4], variant=&#39;c&#39;)) # 1 if &gt;= 4 and 0 o.w.
print(scipy.stats.kendalltau([0, 0, 0, 1, 1], [0, 1, 2, 3, 4], variant=&#39;c&#39;)) # 1 if &gt;= 3 and 0 o.w.
打印（scipy.stats.kendalltau（[0, 0, 1, 1, 1]，[0, 1, 2, 3, 4]，variant=&#39;c&#39;））# 1 如果 &gt;= 2 且 0 o.w.
打印（scipy.stats.kendalltau（[0, 1, 1, 1, 1]，[0, 1, 2, 3, 4]，variant=&#39;c&#39;））# 1 如果 &gt;= 1 且 0 o.w.

输出
SignificanceResult(statistic=0.64, pvalue=0.15729920705028516)
SignificanceResult(statistic=0.96, pvalue=0.0832645166635504)
SignificanceResult(statistic=0.96, pvalue=0.0832645166635504)
SignificanceResult(statistic=0.64, pvalue=0.15729920705028516)

这似乎表明，无论我如何调整阈值或设计二进制转换器，我都无法使 Kendall tau-c 达到 1。我完全理解 Kendal tau-b 不应该是 1情况，但我的理解是，矩形调整的目标是纠正这种情况，以便相关性在完美情况下可以达到 1。
这是一个错误还是一个功能？并且，还有其他一些等级相关性变体可以在这种情况下产生 1 的相关性？]]></description>
      <guid>https://stats.stackexchange.com/questions/653646/kendall-tau-c-can-never-be-1</guid>
      <pubDate>Fri, 30 Aug 2024 19:45:11 GMT</pubDate>
    </item>
    <item>
      <title>这是在同一维度上使用许多不同评估进行聚类的正确方法吗？</title>
      <link>https://stats.stackexchange.com/questions/653643/is-this-the-right-approach-to-cluster-using-many-different-evaluations-on-the-sa</link>
      <description><![CDATA[我正在做一个项目，想把政党分成两组。我想利用调查中许多受访者的回答，他们指出了每个政党在左右尺度上的位置。我对我的数据使用了 k 均值聚类，得到了非常合理的工作结果。但是，鉴于我对任何类型的聚类方法都很陌生，而且我在网上找不到任何在聚类中处理类似数据结构的示例，我想确保我做的是正确的。所以，我的问题是：

下面的方法是否是处理我的数据格式的有效方法？
我现在使用的是两个集群，这是我想要的，但我也想确保我没有完全偏离将政党强行放入它们不适合的集群。有没有办法在事后验证集群的数量？我熟悉肘形图和其他估计理想聚类数的方法，但我正在寻找一种方法来评估/评分我已经完成的聚类。

# Party Dataset
df &lt;- data.frame(&quot;Party A&quot; = c(2,3,4,3,3),
&quot;Party B&quot; = c(3,3,4,5,4),
&quot;Party C&quot; = c(4,5,6,7,6),
&quot;Party D&quot; = c(5,6,7,8,7),
&quot;Party E&quot; = c(6,7,8,NA,8))

# Transpose Dataframe
df &lt;- as.data.frame(t(df)) %&gt;% 
mutate_all(as.numeric) 

#找出所有缺失值
ind &lt;- which(is.na(df), arr.ind=TRUE)
# 用行均值替换
df[ind] &lt;- rowMeans(df, na.rm = TRUE)[ind[,1]]

# 删除空行
df &lt;- na.omit(df)

# 缩放
df &lt;- scale(df)

# 删除缩放数据中缺失值的案例
t &lt;- t[,colSums(is.na(t))&lt;nrow(t)]

# 使用 2 个 kmeans 中心进行聚类
km.res &lt;- kmeans(df, 2, nstart = 25)
]]></description>
      <guid>https://stats.stackexchange.com/questions/653643/is-this-the-right-approach-to-cluster-using-many-different-evaluations-on-the-sa</guid>
      <pubDate>Fri, 30 Aug 2024 16:28:01 GMT</pubDate>
    </item>
    <item>
      <title>基于模拟随机事件概率平均值的预期泊松二项分布</title>
      <link>https://stats.stackexchange.com/questions/653630/expected-poisson-binomial-distribution-based-on-average-of-simulated-random-even</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653630/expected-poisson-binomial-distribution-based-on-average-of-simulated-random-even</guid>
      <pubDate>Fri, 30 Aug 2024 15:25:44 GMT</pubDate>
    </item>
    <item>
      <title>MANOVA - 单变量 Wilks 的 Lambda 检验（R 解释）</title>
      <link>https://stats.stackexchange.com/questions/653530/manova-univariate-wilks-lambda-test-r-interpretation</link>
      <description><![CDATA[我正在运行一个具有 2 个因变量和 2 个连续预测变量的 MANOVA 模型。 （仅供参考 - STATA 将此称为 MANCOVA，并要求在每个预测因子前面删除“c。”以表示每个预测因子在 manova 运行期间都是连续缩放的。无论如何，R 将直接接受连续变量，因此使用 manova 命令在 R 中运行 MANCOVA 不会出现问题） - 本质上是 MVNREG。
使用 UC-Irvine ML Repository Wine 数据集，模型为：
model &lt;- lm(cbind(alcohol, hue) ~ flavanoids + ash, 
na.action=na.exclude, data=wine)
wine.manova=manova(model)

我试图理解使用两者时 Wilks&#39; Lambda 对黄烷类化合物预测因子的 F 近似值之间的差异方法：
方法 1
library(car)
lh.out &lt;- linearHypothesis(model, 
hypothesis.matrix = c(&quot;flavanoids = 0&quot;))
lh.out

结果如下：

方法 2
以及基于命令的 Wilks 值
summary(wine.manova,&#39;Wilks&#39;)

输出为：

尽管 p 值相同，但我试图理解为什么 Wilks&#39; Lambda 的 F 值在基于所有响应变量的黄酮类化合物预测因子的两次零系数检验中有所不同。结果表明，当预测变量或因变量较多时，Wilks Lambda 的这两次计算之间的差异较大。
仅供参考 - 当将 R 与 STATA 进行基准测试时，几乎不可能在 STATA 中获得上述方法 2 下列出的表格结果，而方法 1 的结果可轻松从 STATA 中获得。]]></description>
      <guid>https://stats.stackexchange.com/questions/653530/manova-univariate-wilks-lambda-test-r-interpretation</guid>
      <pubDate>Thu, 29 Aug 2024 02:58:38 GMT</pubDate>
    </item>
    <item>
      <title>如何比较多组计数数据（数百万或零，差异很大）？</title>
      <link>https://stats.stackexchange.com/questions/653526/how-do-i-compare-multiple-groups-of-count-data-that-are-either-millions-or-zero</link>
      <description><![CDATA[我有三个独立的组：治疗组、药物 1 和药物 2。对于每个组，我都有 CFU 中的细菌计数。我不太擅长统计，所以请耐心听我说。我知道我不能使用方差分析，因为分布不正常，有些计数相距很远，而且有相当多的零（虽然不是太多）。组内的方差也不相等，样本量也不相等。
我看过一些论文，建议使用负二项分布、泊松分布或其他一些分布。我的问题是：有没有针对这种情况的推荐方法？我如何比较不同类别的模型以确定哪个更好？我主要使用 R。有没有办法在 R 中测试多种方法并让它建议最佳（或接近最佳）模型？这种方法是否适合我的情况？或者我应该不要太担心并使用非参数检验？]]></description>
      <guid>https://stats.stackexchange.com/questions/653526/how-do-i-compare-multiple-groups-of-count-data-that-are-either-millions-or-zero</guid>
      <pubDate>Thu, 29 Aug 2024 01:08:06 GMT</pubDate>
    </item>
    <item>
      <title>如何使用高相关模型选择 A/B 测试样本</title>
      <link>https://stats.stackexchange.com/questions/653520/how-to-select-sample-for-a-b-testing-with-high-correlated-models</link>
      <description><![CDATA[嗨，我正在对两个机器学习模型进行 A/B 测试，这两个模型会为每个客户提供一个分数。这两个模型具有很高的相关性。我担心，如果采用模型 A，选择样本，然后选择模型 B 的样本，例如，这可能会在我的测试中产生偏差（剩余的人口将拥有低“质量”的客户，因为这两个模型具有很高的相关性）。
关于如何克服这个问题，有什么想法吗？我也很感激任何参考资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/653520/how-to-select-sample-for-a-b-testing-with-high-correlated-models</guid>
      <pubDate>Thu, 29 Aug 2024 00:16:55 GMT</pubDate>
    </item>
    <item>
      <title>得到一个不显著的 log(theta) 意味着什么？</title>
      <link>https://stats.stackexchange.com/questions/653505/what-does-getting-a-non-significant-logtheta-mean</link>
      <description><![CDATA[我在 R 中运行一个简单的模型，测试鱼密度（单位体积的鱼数量）是否取决于该区域的深度。有很多区域没有鱼，所以我使用 zeroinflated 模型（R 中的包 pscl::zeroinfl）。
模型 &lt;- zeroinfl(FishDensity ~Depth, data = myData, dist = &quot;negbin&quot;, 
na.action = na.omit)

这些是结果：
计算模型系数（带对数链接的 negbin）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 5.33750 0.24254 22.007 &lt;2e-16 ***
深度 0.03446 0.01367 2.521 0.0117 * 
Log(theta) 0.08603 0.14003 0.614 0.5390 

零膨胀模型系数（带 logit 链接的二项式）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 1.893173 0.288799 6.555 5.55e-11 ***
深度 0.007084 0.016472 0.430 0.667 

在计数模型系数中，我得到了一个不显著的 log(theta)。
这是什么意思？我应该放弃这个模型吗？
深度本身很重要。
我是统计学新手，所以请尝试用简单的术语解释它。]]></description>
      <guid>https://stats.stackexchange.com/questions/653505/what-does-getting-a-non-significant-logtheta-mean</guid>
      <pubDate>Wed, 28 Aug 2024 20:09:05 GMT</pubDate>
    </item>
    <item>
      <title>如何从给定分布的所有可接受个体群体中进行抽样？</title>
      <link>https://stats.stackexchange.com/questions/652851/how-to-sample-from-all-admissible-populations-of-individuals-from-a-given-distri</link>
      <description><![CDATA[问题描述
下文中，“人口”一词指生态意义上的个体种群。
假设我们得到一个可接纳种群的集合 $S \subset \mathcal{P}(T^N)$，并按以下方式抽取这些可接纳种群 $s = (x_1, \dots, x_n) \in S $ 个个体 $x_i \in T$：

首先，我们从 $\{ 0,...,N \} $ 上的均匀分布中抽取一个种群大小 $n$。
然后，我们抽取 $n$ 个个体 $x_i$ 来自给定的随机变量 $X$ 并将它们添加到集合 $s$。
最后，我们检查总体是否可接受，如果 $s \in S$，则情况就是如此。如果是，我们就完成了，如果不是，我们重复该过程，直到找到可接受的总体。

我想以有效的方式模拟结果样本。然而，在前两个步骤中获得可接受总体的概率很小，这就是为什么在实践中使用概述的方法不可行。
我们可以使用 $\emptyset \in S$。我想考虑任何域 $T$ 的一般情况，但在我的特定应用中，$T \subseteq [1, \dots, m] \times [a, b]$ 其中 $m \in \mathbb{N}^+$ 和 $a,b\in \mathbb R$。具体来说，集合 $S$ 是无限的，并且仅通过可接纳性检查隐式定义。可接纳性检查表现为“某种程度上连续”，这意味着如果两个群体彼此“相似”，则它们很可能都是可接纳的或都是不可接纳的。后一个陈述旨在激发下面尝试的解决方案，但对于我的实际问题来说并不需要。
尝试的解决方案
我解决这个问题的方法是使用 Metropolis-Hastings 类型的算法：

从一些可接受的种群 $s_0$ 开始。
以 $0.5$ 的概率，从 $X$ 中抽取一个新的个体 $x$ 添加到种群中。

否则，从种群中随机移除一个个体（如果种群不为空）。


检查新状态是否可接受。如果是，则接受该步骤；否则保留最后可接受的群体。
经常重复此过程。

问题
为了使此过程有效，我们需要提案分布平衡。也就是说，对于转换 $s_j \rightarrow s_{j+1}$，它成立
$$P(s_{j+1} | s_j) = P(s_j | s_{j+1}).$$
但是，当我删除一个个体时，$P(s_{j+1} | s_j) = \frac{1}{2 |s_j|} $，而添加一个个体需要更多信息：$P(s_j | s_{j+1}) = 0.5 P(X = x)$，如果 $x$ 是新个体。将其纳入算法将导致小群体占主导地位（如果 $X$ 具有连续域，则将变得困难）。因此，我认为我有一个误解。
我有以下问题：

提出的算法是否产生了所需的样本？
如果是，为什么？我如何用数学证明/表达这一点？||如果不是，我需要如何调整算法？（再次，对证明的提示会很棒。）

背景
种群可能代表相互竞争有限资源的有机体种群。我的目标是从我们在自然界中可以找到的所有种群中抽样（根据某种竞争模型）。根据物种和个体的大小，它们可能占据不同的生态位，使许多个体得以生存。然而，如果在同一领域有强大的竞争对手，一些个体可能会消亡。]]></description>
      <guid>https://stats.stackexchange.com/questions/652851/how-to-sample-from-all-admissible-populations-of-individuals-from-a-given-distri</guid>
      <pubDate>Thu, 15 Aug 2024 09:42:18 GMT</pubDate>
    </item>
    <item>
      <title>用于建模财务回报的 AR(1) 过程的时间缩放</title>
      <link>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</link>
      <description><![CDATA[过程：
考虑一个均值为零的 AR(1) 过程，*
$\lambda_t = \kappa \cdot \lambda_{t-1} + \omega_t$，
其中 $\kappa = 0.9$，$\omega \sim N(0, \sigma_{\omega}^2)$，并且 $\sigma_{\omega}^2 = 0.00027$。 $\lambda_0$ 的初始值取自平稳分布 $N \left(0, \frac{\sigma_{\omega}^2}{(1-\kappa^2)} \right)$
我使用此过程生成长度为 $T=672$ 的样本。
* 我知道，对于股票收益建模而言，均值为零是不现实的，但我的问题并不取决于此选择。

上述时间序列应解释为每月收益（以百分点表示），即 672 个月的观测值。
问题：
什么是合适的参数值生成总共 14,112 个每日观测值（即$672 \times 21$，如果我们假设一个月内有 21 个交易日）以符合上述（每月）流程？月回报率是给定月份内所有 21 天回报率的累计乘积。
尝试（在 R 中）：
DAYS &lt;- 21
T &lt;- 672
kappa &lt;- 0.9
variance_omega &lt;- 0.00027

get_init_lambda &lt;- function(variance) return(rnorm(n = 1, mean = 0, sd = sqrt(variance / (1-(kappa)^2))))

#### 月度分析

set.seed(1234)

lambda_T &lt;- vector(mode = &quot;numeric&quot;, length = T)

lambda_shock &lt;- rnorm(T, mean = 0, sd = sqrt(variance_omega))

lambda_T[1] &lt;- kappa * get_init_lambda(variance_omega) + lambda_shock[1]
for(i in 2:T) lambda_T[i] &lt;- kappa * lambda_T[i-1] + lambda_shock[i]

acf(lambda_T)$acf[2]
# [1] 0.9064949 # 符合预期

var(lambda_T)
# [1] 0.001547795

#### 每日分析

set.seed(1234)

kappa_daily &lt;- 0.90 # ??? 如何设置 kappa_daily，使月收益 AC = 0.9？

lambda_T_daily &lt;- vector(mode = &quot;numeric&quot;, length = T * DAYS)

lambda_shock_daily &lt;- rnorm(T * DAYS, mean = 0, sd = sqrt(variance_omega / DAYS))

lambda_T_daily[1] &lt;- kappa_daily * get_init_lambda(variance_omega / DAYS) + lambda_T_daily[1]
for(i in 2:(T * DAYS)) lambda_T_daily[i] &lt;- kappa_daily * lambda_T_daily[i-1] + lambda_shock_daily[i]

# 检索月末指数；假设每个月有 21 个交易日
begin_month &lt;- seq(1, T * DAYS, 21)
end_month &lt;- c(tail(begin_month, -1) - 1, T * DAYS)

lambda_monthly_aggregate &lt;- vector(mode = &quot;numeric&quot;, length = T)

for(i in 1:T){
month_ind &lt;- (begin_month[i]):(end_month[i])

daily_ret_within_month &lt;- 0.01*lambda_T_daily[month_ind] # 收益以 % 表示
monthly_return &lt;- 100*(cumprod(1+daily_ret_within_month) - 1) # 累计每日收益

lambda_monthly_aggregate[i] &lt;- monthly_return[DAYS] # 检索累计。 21 天后返回
}

# 与上述值不相同：自相关性太低，mth 方差返回值太高！
&gt; acf(lambda_monthly_aggregate)$acf[2]
[1] 0.2988249

var(lambda_monthly_aggregate)
[1] 0.01494742

]]></description>
      <guid>https://stats.stackexchange.com/questions/652799/time-scaling-of-ar1-process-for-modelling-financial-returns</guid>
      <pubDate>Wed, 14 Aug 2024 16:01:50 GMT</pubDate>
    </item>
    </channel>
</rss>