<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 15 May 2024 15:13:34 GMT</lastBuildDate>
    <item>
      <title>基于“排序均匀分布”和 beta 分布的常数近似</title>
      <link>https://stats.stackexchange.com/questions/647292/constant-approximation-based-on-sorted-uniform-distribution-and-beta-distribut</link>
      <description><![CDATA[让 $X_1, X_2 \stackrel{\text{iid}}{\sim}\mathrm{Uniform}(0,1)$ 然后排序 &lt; span class=&quot;math-container&quot;&gt;$X_1,X_2$ 得到 $X_{(1)} $X_{(1)} &lt; X_{(2)}$。
根据$X_{(i)}$的pdf，我们知道$X_{(1)} \sim \mathrm{Beta}(1,2)$ 和 $X_{(2)} \sim \mathrm{Beta}(2,1)$ span&gt;，其中 $\mathbb{E}(​​X_{(1)}) = \frac{1}{3}$ 和 $\mathbb{E}(​​X_{(2)}) = \frac{2}{3}$。
考虑函数 $f(x) = x$ 的以下分段常数近似。

在 $(0, 1)$$x_1, x_2$ &gt; 然后对它们进行排序以获得 $x_{(1)}$ 和 $x_{(2)}$ span&gt;, $x_{(1)} &lt; x_{(2)}$。将期望表示为 $\mathbb{E}_1(\|f - c\|_2^2) = \mathbb{E}_1(\displaystyle\int_{x_{(1 )}}^{x_{(2)}} (f(t)-c)^2 \; dt)$，其中 $c = \frac{1 {x_{(2)}-x_{(1)}}\displaystyle\int_{x_{(1)}}^{x_{(2)}} f(t)\; dt$ 是一个常数。

来自 $\mathrm{Beta}(1,2) 的示例 $y_{(1)}$ )$ 和 $y_{(2)}$ 来自 $\mathrm{Beta}(2,1 ）$。将期望表示为 $\mathbb{E}_2(\|f - c\|_2^2) = \mathbb{E}_2(\displaystyle\int_{y_{(1 )}}^{y_{(2)}} (f(t)-c)^2 \; dt)$，其中 $c = \frac{1 {y_{(2)}-y_{(1)}}\displaystyle\int_{y_{(1)}}^{y_{(2)}} f(t)\; dt$ 是一个常数。


（注：$\mathbb{E}_1$ 和 $\mathbb{E}_2$ 的定义 相同；唯一的区别是获取点的方法$x_{(i)}, y_{(i)}$。）
比较 $\mathbb{E}_1(\|f - c\|_2^2)$ 和 $ \mathbb{E}_2(\|f - c\|_2^2)$。通过数值实验观察到 $\mathbb{E}_1(\|f - c\|_2^2) $\mathbb{E}_1(\|f - c\|_2^2) &lt; \mathbb{E}_2(\|f - c\|_2^2)$。这个结果让我很困惑。
我希望它们相等，因为 $x_{(i)}$ 和 $y_{(i) }$ 来自与上面讨论的相同的 Beta 发行版。
这是因为$x_{(1)} \;\mathrm{and}\; x_{(2)}$ 不独立？如果是，$x_{(1)}$ 和 $x_{(2)}$ 的 pdf 或 cdf 是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647292/constant-approximation-based-on-sorted-uniform-distribution-and-beta-distribut</guid>
      <pubDate>Wed, 15 May 2024 15:11:32 GMT</pubDate>
    </item>
    <item>
      <title>解释 GAM 拦截（R 中 mccv 的 bam() 函数）</title>
      <link>https://stats.stackexchange.com/questions/647289/interpreting-gam-intercept-mccvs-bam-function-in-r</link>
      <description><![CDATA[我对 GAM 非常陌生（坦率地说，对于一般的回归模型），我很难理解在使用 R 中 mgcv 包中的 bam() 函数时得到的模型摘要，更具体地说，什么是截距估计表示。
我的数据集包含一项实验的瞳孔大小数据，其中参与者接受了 4 个“lang”中的 1 个语言刺激。状况。数据是在 3 个不同地点收集的。实验中的每次试验持续 3500 毫秒，在数据集中分为 50 毫秒的时间段。我正在使用 bam() 函数，因为我的数据集相当大。 “位置”、“语言”、“主题”和“项目”是因子变量。瞳孔大小和时间是连续变量。包括注视坐标，以考虑基于注视位置的瞳孔大小变化。
我想将瞳孔大小的变化视为语言和位置随时间相互作用的函数。主题和项目作为随机效果包含在内：
m1 &lt;- bam(瞳孔 ~ lang * 位置 + s(时间, by = 位置, k = 10) + s(时间,
by = lang, k = 10) + s(Gaze_X, Gaze_Y) + s(时间, 主题,
bs = “fs”, m = 1) + s(时间, 项目, bs = “fs”, m = 1),
数据 = df，离散 = T)

查看此模型的摘要，我得到以下信息：
参数系数：
                      估计标准。误差t值Pr(&gt;|t|)
(截距)-113.5409 12.3626 -9.184＜ 2e-16 ***
朗英诺 13.0750 5.5122 2.372 0.0177 *
郎NNBM 19.4937 1.4779 13.190 &lt; 2e-16 ***
挪威语 -8.6308 5.5121 -1.566 0.1174
位置北 29.3542 15.5140 1.892 0.0585 。
位置西 -8.7713 17.0011 -0.516 0.6059
langEngNor:位置北 15.6711 1.9726 7.944 1.95e-15 ***
langNNBM：位置北 25.8995 1.9713 13.138 &lt; 2e-16 ***
langNorEng:位置北 -0.5177 1.9737 -0.262 0.7931
langEngNor：位置西 15.9085 2.1683 7.337 2.19e-13 ***
langNNBM:位置西 15.5085 2.1690 7.150 8.68e-13 ***
langNorEng：位置West 20.6320 2.1707 9.505 &lt; 2e-16 ***

据我了解，截距估计 (-113) 应该对应于时间 bin 0ms，因子变量设置为参考水平（位置 East，lang BMNN）。问题在于，从图表来看，在整个试验过程（3500 毫秒）中，瞳孔大小从未低于 0。那么截距估计在这里意味着什么？
我非常感谢任何建议/信息！]]></description>
      <guid>https://stats.stackexchange.com/questions/647289/interpreting-gam-intercept-mccvs-bam-function-in-r</guid>
      <pubDate>Wed, 15 May 2024 13:46:10 GMT</pubDate>
    </item>
    <item>
      <title>嵌套、交叉或两者随机效果</title>
      <link>https://stats.stackexchange.com/questions/647287/nested-crossed-or-both-random-effects</link>
      <description><![CDATA[我正在使用二项式响应变量构建 GLMM 模型，但在确定要使用哪种组合或嵌套或交叉效果时遇到困难。我的情况如下：
1.) 我有物种观察的公民科学数据，其中包括公民科学家观察员的 ID。
2.) 我附近有气象监测站，其中有我正在使用的重要预测变量。这些站具有唯一的 ID。
3.) 从天气监测站收集的数据与公民科学家提交观察结果的时间相匹配。
总而言之，我有独特的气象站，独特的公民科学家在多个独特的气象站进行观测，并且这些观测发生在不同的时间。]]></description>
      <guid>https://stats.stackexchange.com/questions/647287/nested-crossed-or-both-random-effects</guid>
      <pubDate>Wed, 15 May 2024 13:28:35 GMT</pubDate>
    </item>
    <item>
      <title>rfImpute 函数的输出有何含义？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647283/what-is-the-meaning-of-the-output-for-rfimpute-function</link>
      <description><![CDATA[库（随机森林）
数据（虹膜）
iris.na &lt;- 鸢尾花
设置.种子(111)
## 人为地删除一些数据值。
对于 (i in 1:4) iris.na[样本(150, 样本(20, 1)), i] &lt;- NA
设置.种子(222)
iris.imput &lt;- rfImpute(物种 ~ ., iris.na)

]]></description>
      <guid>https://stats.stackexchange.com/questions/647283/what-is-the-meaning-of-the-output-for-rfimpute-function</guid>
      <pubDate>Wed, 15 May 2024 12:35:57 GMT</pubDate>
    </item>
    <item>
      <title>多元有限元回归的 reghdfe 和 Fixst 之间的区别？</title>
      <link>https://stats.stackexchange.com/questions/647282/difference-between-reghdfe-and-fixest-for-a-multiple-fe-regression</link>
      <description><![CDATA[我使用fixst 估计以下方程：
$$
Y_{i,f,s,t} = \beta_1 treat_i + \beta_2 post_t + \beta_3 treat_i*post_t + \alpha_i + \alpha_{s,t} + \alpha_{f,t} + \epsilon_{i,f ，英石}
$$
其中 i 是个体，f 是个体出生年份，s 是面积，t 是年份。我正在研究影响某些个人的政策的效果（treat_i 固定在个人层面）。我想控制一个人出生年份的差异趋势（非线性，这对我的规范很重要，因为年龄影响多年来不同），以及按主题领域的差异趋势，这就是为什么我将它们作为两个固定的原因效果，以及单独的 FE。
以下是我如何在 R 中使用fixst 来估计这一点：
feols(y ~ treat*post | individual + subject_area^year +first_year^year, data=df)
问题是，当我同时包含按年份和科目的 FE 时，该模型会为我提供 beta1 的估计值，而该估计值应由单个 FE 吸收。标准误差很大（使得 P 值 = 0.99，并且该系数无法从 0 辨别），但我很困惑为什么模型首先会估计它。
事实上，当我在 Stata 中运行相同的回归时，并未估计系数，因为它与 FE 共线。两个包的兴趣系数 beta3 是相同的。以下是我使用 reghdfe 估计的方法：
reghdfe y treat##post，吸收（个人subject_area##yearfirst_year##year）集群（个人）
你知道幕后发生了什么吗？我认为问题可能源于小组规模较小，但我想知道为什么 Fixst 会估计系数（而 reghdfe 不会）？]]></description>
      <guid>https://stats.stackexchange.com/questions/647282/difference-between-reghdfe-and-fixest-for-a-multiple-fe-regression</guid>
      <pubDate>Wed, 15 May 2024 12:30:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么物理学家使用 sigma 而生物学家使用 p 值/后验概率？</title>
      <link>https://stats.stackexchange.com/questions/647284/why-do-physicists-use-sigma-while-biologists-use-p-values-posterior-probabilitie</link>
      <description><![CDATA[我从事生物数据分析工作，熟悉使用数学来确定检验统计量，以及将该检验统计量与阈值进行比较以评估假设。使用具有 $p$ 值的频率框架和使用具有后验概率的贝叶斯框架都很常见。这些测试统计量可能非常小，大约为 $10^{-6}$ 的数量级，因此谈论指数是最方便的。在发生多次测试并且讨论的是名义测试统计数据而不是校正后的测试统计数据的情况下尤其如此。
在物理学中，至少在科普媒体中，显着性阈值通常用 $σ$ 来讨论，实验结果达到 5 或六个 $σ$ 阈值被普遍接受。我的理解是，这是检验统计数据与原假设预测值之间有多少观察到的标准偏差。
在频率论框架下，假设检验统计量呈正态分布，则 $p$ 值和 $σ$ 直接相关。在 R 中，这将是 p_value = pnorm(-sigma) ，其中五个 $σ$ 大致对应于 $3·10^{-7}$ 和 6 到 $10^{-9}$。
造成这种差异的原因是什么？
这种方法的最大缺点似乎是偏态分布的问题，其中检验统计量更有可能在平均值的一侧而不是另一侧处于一定数量的标准差内，但我确信它们已经想到了。重尾分布可能存在类似的问题。
这也让我想知道如何使用贝叶斯数学，并且物理论文毫无价值 a quick google 提出不要谈论 sigma，并且突出包括与生物学的交叉点。
值得注意的是，普遍接受的阈值有很大不同，5％在许多生物领域很常见，而5西格玛的0.00003％。这很可能是相关的，但似乎并不能回答问题，因为人们可以只谈论指数并且数字是相似的。至于为什么如此严格是 这个问题涵盖了。
为了说明我的意思，请采用“希格斯凹凸” ，这表明了希格斯水手长的存在。显然，分析很复杂，但是 采用简单的案例单个 bin 是每 GeV 的事件数量，平均值约为 1000。在这个事件数量下，这种分布可以通过正态近似很好地建模，并且观察到的计数预计将对称分布在均值和 sigma 的表现与基于泊松分布的 p 值非常相似。
如果这些预期值接近 10，则事实并非如此。在空阈值下使用基于 sigma 的阈值更有可能因高计数而不是低计数而导致错误拒绝（我认为）。
这似乎是分析方法的一个负面特征，而 p 值或基于后验概率的阈值则不具备这一特征。由于满足假设时这些方法是等效的，因此基于 sigma 的方法似乎只有缺点。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647284/why-do-physicists-use-sigma-while-biologists-use-p-values-posterior-probabilitie</guid>
      <pubDate>Wed, 15 May 2024 11:59:47 GMT</pubDate>
    </item>
    <item>
      <title>重复测量、混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/647278/the-repeated-measures-mixed-effects-models</link>
      <description><![CDATA[我的数据集包含接受过干预或安慰剂治疗的参与者，结果是唾液流（连续），并在 0、4 和 12 个月时进行测量。结果变量 ($Y_{i}$) 是因变量，使用多级重复测量随机效应模型，以参与者为随机效应因子，时间（以3 个水平，包括基线）作为基于限制最大似然 (REML) 模型的固定效应因素。
该统计模型将保存从基线（包括基线）起 12 个月内所有评估点的所有时间间比较，从而可以评估平均效果以及从基线到随后 12 个月的时间轨迹向上。
以下内容是否包含上述内容？
模型 &lt;- lmer(UnstimSalivaFlow ~ GROUP * MONTH + (1|PtID), data = data)

此外，我希望输出分别为 group_intervention 和 group_placebo 中相对于基线的变化，并报告为最小二乘均值，包括组的 p 值。]]></description>
      <guid>https://stats.stackexchange.com/questions/647278/the-repeated-measures-mixed-effects-models</guid>
      <pubDate>Wed, 15 May 2024 11:29:03 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用 GLS corCAR1 控制个人和家庭内的自相关？</title>
      <link>https://stats.stackexchange.com/questions/647276/is-it-possible-to-control-for-autocorrelation-within-individuals-and-families-us</link>
      <description><![CDATA[我有一个双胞胎样本，并重复测量了 BMI。我想确定某种营养素的摄入量是否与 BMI 轨迹相关。我一直在 R 中的 nlme 包中使用 GLS。我使用了 correlation = corCAR1(form = ~age|twinID) 但意识到这并没有考虑到自相关家庭 (famID)。是否可以同时控制 twinID 和 famID 自相关？我尝试过 correlation = corCAR1(form = ~age|twinID/famID) 和 correlation = corCAR1(form = ~age|famID/twinID) 但这没有什么区别到输出。]]></description>
      <guid>https://stats.stackexchange.com/questions/647276/is-it-possible-to-control-for-autocorrelation-within-individuals-and-families-us</guid>
      <pubDate>Wed, 15 May 2024 11:08:44 GMT</pubDate>
    </item>
    <item>
      <title>张量流keras模型的梯度[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647270/the-gradient-of-the-tensor-flow-keras-model</link>
      <description><![CDATA[我使用 ANN 来解决使用 Python 预测银行部门客户流失的问题。如果我们将 ANN 视为接受输入向量 $x$ 并返回输出 $f(x)$ 的函数&gt;，这个函数$f&#39;(x)$的梯度是多少？我们如何在Python中计算它？有这方面的图书馆吗？或任何预先准备的代码？
我使用的数据集是来自kaggle的“Churn_Data.xlsx”，我将其转换为xlsx格式...
https://www.kaggle.com/code/kmalit /银行客户流失预测
数据准备代码如下...
导入io
df = pd.read_excel(io.BytesIO(upoaded[&#39;Churn_Data.xlsx&#39;]))
df = df.drop(columns=[&#39;行号&#39;, &#39;CustomerId&#39;, &#39;姓氏&#39;], axis=1)

数据集 = pd.get_dummies(data=df, drop_first=True)

x = dataset.drop(columns=&#39;已退出&#39;)
y = 数据集[&#39;已退出&#39;]

从 sklearn.model_selection 导入 train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)

x_train.shape、x_test.shape、y_train.shape、y_test.shape


训练和测试数据的大小如下...
&lt;前&gt;&lt;代码&gt;((8000, 11), (2000, 11), (8000,), (2000,))

from sklearn.preprocessing import StandardScaler

sc = 标准缩放器()

x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

现在为了构建 ANN 顺序模型，我编写了这段代码......
#构建模型

模型 = tf.keras.models.Sequential()

# 第一个输入层

model.add(tf.keras.layers.Dense(单位=6，激活=&#39;relu&#39;，input_dim=11))

# 第二个输入层

model.add(tf.keras.layers.Dense(单位=6,激活=&#39;relu&#39;))

# 第三输入层

model.add(tf.keras.layers.Dense(单位=1,激活=&#39;sigmoid&#39;))

# 编译模型

model.compile（优化器=&#39;adam&#39;，损失=&#39;binary_crossentropy&#39;，指标=&#39;准确性&#39;）
模型.summary()

# 将模型拟合到数据集

model.fit(x_train, y_train.to_numpy(), batch_size=10, epochs=20)

#评估模型

test_loss, test_accuracy = model.evaluate(x_test, y_test.to_numpy())

print(&#39;测试准确度:{}&#39;.format(test_accuracy))

现在如何找到每个点的梯度（就像训练数据中的向量）？]]></description>
      <guid>https://stats.stackexchange.com/questions/647270/the-gradient-of-the-tensor-flow-keras-model</guid>
      <pubDate>Wed, 15 May 2024 09:47:49 GMT</pubDate>
    </item>
    <item>
      <title>比较人类估计和算法对标准化分数的估计</title>
      <link>https://stats.stackexchange.com/questions/647269/comparing-human-estimates-and-algorithm-on-normalized-score</link>
      <description><![CDATA[通过一种算法，我们想要预测一个度量值$Y$，该度量值会因不同的项目$i=1,\ldots,n$而变化。数量$y_i$已由$N$人工注释者估算，我们想要计算算法的性能分数。
相对于人类平均值的均方误差或绝对误差（MSE、MAE）不是算法准确性的良好指标，因为$y_i$可能会有很大差异，例如，对于$y_i=50$，误差为 5 是好的，但对于$y_i=6$，误差很差。为了使 $y_i$ 的规模具有可比性，并处理人工估计中的方差，我们考虑为每个算法结果计算一个 z 分数*)，然后对所有 z 分数取平均值。然而，这样做的问题是，对于某些项目，人为之间的方差为零。
*) 其中 $z=\frac{y_{alg} \;-\; \overline{y_i}}{\hat{\sigma}_i}$ 其中 $\overline{y_i}$ 和 $\hat{\sigma}_i$ 是根据人工结果估计的。
对于这种情况，是否存在一些既定的“标准化错误”？请注意，我们感兴趣的不是 p 值，即是否存在差异，而是差异的强度。]]></description>
      <guid>https://stats.stackexchange.com/questions/647269/comparing-human-estimates-and-algorithm-on-normalized-score</guid>
      <pubDate>Wed, 15 May 2024 09:22:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么机器学习模型要学习概率分布以及为什么它很重要？</title>
      <link>https://stats.stackexchange.com/questions/647266/why-do-ml-models-learn-probability-distributions-and-why-does-it-matter</link>
      <description><![CDATA[我知道这个问题很愚蠢，但我已经阅读和编写神经网络有一段时间了，研究了反向传播等。
但是，我认为我从未理解过神经网络建模的概率分布是什么？
我确实知道它们是频率与特征图，但我为什么了解数据集中 L 形边界的数量会有帮助呢？
当然，我也没有看到线性回归学习任何这些（我寻找一个非常简单的案例来分析。）
如果可能的话，您的概念解释是什么？您能给我推荐一些针对这方面的初学者的文章吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647266/why-do-ml-models-learn-probability-distributions-and-why-does-it-matter</guid>
      <pubDate>Wed, 15 May 2024 08:46:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中编写普通联结函数？</title>
      <link>https://stats.stackexchange.com/questions/647258/how-to-write-a-function-for-the-normal-copula-in-r</link>
      <description><![CDATA[如何在 R 中为普通联结函数编写以下函数？
$$
C_\theta(u, v)=\Phi_\theta\left(\Phi^{-1}(u), \Phi^{-1}(v)\right),
$$
其中 $\Phi$ 是 $N(0,1)$ cdf，$\Phi^{-1}$ 是 $\Phi$ 和 $\Phi_\theta$ 是具有相关性的二元标准正态 CDF $\theta$。
我尝试过这样写，但效果不好，因为最终当我尝试查找对数似然值时，它不会返回任何值。
pcopula.fam1 &lt;- 函数(u, v, a) {
  返回(exp(-(qnorm(u)^2-2*a*qnorm(u)*qnorm(y)+qnorm(y)^2)/(2*(1-a^2)))/(2 *pi))
}

弗兰克系动词
这就是我为 Frank 联结函数编写函数的方式，但我仍坚持使用上面描述的普通联结函数。
pcopula.fam1&lt;-function(u,v,a){
  - (1/a) * log(1 + ((exp(-a*u)-1) * (exp(-a*v)-1))/(exp(-a)-1))
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/647258/how-to-write-a-function-for-the-normal-copula-in-r</guid>
      <pubDate>Wed, 15 May 2024 07:19:23 GMT</pubDate>
    </item>
    <item>
      <title>面包篮中的面包新鲜度，R 中的多级分析； 2个时间点</title>
      <link>https://stats.stackexchange.com/questions/647250/bread-freshness-in-bread-basket-multi-level-analysis-in-r-2-time-points</link>
      <description><![CDATA[这是我第一次尝试多层次分析。
我的研究问题是；
面包篮内不同类型面包（6级）的新鲜度在两个时间点（4-8天）内如何变化，取决于面包师的技能（4级），以及调整每个篮子之间的相互相关性，因为一个篮子可能是用比另一个篮子质量更高的原料制成的？

样本大小 = 2 个时间点内 300 个面包篮（总共 600 个观察值），每次观察 6 种面包类型。

V1：id - 每个面包篮的 ID（每个 id 有 6 个相关的面包类型）

V2：新鲜 - 因变量：面包的新鲜度（连续，0-100）

V3：技能 - 面包师的技能（4 级有序因子）（李克特量表）

V4：类型 - 面包类型（标称 6 级，每个 id）

V5：时间 - 自烘烤以来的时间（连续，范围为 4-8 天）

V6-V8 其他协变量（咖啡馆的温度、烤箱条件、# 烘焙辅助蚂蚁）


更简单地说，面包师的技能（固定）如何改变时间对面包篮中每种面包的新鲜度的影响，以及这些影响（新鲜度技能）的差异在统计上是否不同跨类型的面包？
我一直在 R 中使用 lme4 包，以 fresh 作为响应变量，但是我有点不确定哪些变量应该视为随机效应，哪些变量是固定的。我相信 type 会嵌套在篮子 ids 中，以说明制作时可用的成分。这就是我所在的位置：
模型 &lt;- lmer(新鲜 ~ 技能 * 时间 + 类型 + V6 + V7 + V8 + (1|类型) + (时间|id), 数据 = 数据)&lt; /em&gt;
我们感兴趣的主要预测因素是面包师的技能。我认为技能不应被视为随机效应，因为它在每个篮子的所有面包类型中都是恒定的。
我很感激任何关于如何解决这个问题的建议。这比我习惯的要复杂一些，因此任何关于要采取的步骤的指示或类似分析的参考，将不胜感激。谢谢！
此插图仅显示两种类型的面包，每个篮子有 6 个面包。我需要编辑它，因为独特的面包类型应该位于列中，就像数据集中的变量一样，为每个id分成六组。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647250/bread-freshness-in-bread-basket-multi-level-analysis-in-r-2-time-points</guid>
      <pubDate>Wed, 15 May 2024 02:42:28 GMT</pubDate>
    </item>
    <item>
      <title>面板数据残差的正态性</title>
      <link>https://stats.stackexchange.com/questions/647218/normality-of-residuals-in-panel-data</link>
      <description><![CDATA[我从包含面板数据（按国家/地区）的样本中运行了包含国家/地区和年份固定效应的线性回归。
由于我使用的是 OLS，我的残差是否必须在整个样本中看起来近似正态分布，或者每个国家/地区的残差是否必须看起来像这样？因此，问题是：正态性假设是否适用于整个样本或每个单独实体的模型残差？]]></description>
      <guid>https://stats.stackexchange.com/questions/647218/normality-of-residuals-in-panel-data</guid>
      <pubDate>Tue, 14 May 2024 14:43:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么将 IQR 数据分为 4 个部分，而不是每个部分 20 或 10 个百分比？</title>
      <link>https://stats.stackexchange.com/questions/647182/why-divide-data-into-4-parts-for-iqr-and-not-into-parts-of-20-or-10-percentages</link>
      <description><![CDATA[为什么将数据分为 4 个部分以进行 IQR，而不是分成更多部分，例如每个部分 20% 或 10%？
我知道四分位距的定义是 25%，但这不是我的问题。
我认为丢弃 IQR 的 50% 数据来删除异常值太浪费数据了。但总得有个理由吧？]]></description>
      <guid>https://stats.stackexchange.com/questions/647182/why-divide-data-into-4-parts-for-iqr-and-not-into-parts-of-20-or-10-percentages</guid>
      <pubDate>Tue, 14 May 2024 06:25:10 GMT</pubDate>
    </item>
    </channel>
</rss>