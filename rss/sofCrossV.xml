<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 15 Feb 2024 12:23:25 GMT</lastBuildDate>
    <item>
      <title>统计上显着差异</title>
      <link>https://stats.stackexchange.com/questions/639338/statistically-significant-difference</link>
      <description><![CDATA[我正在阅读一篇医学论文，其中写道：“
“6个月时，IPC组的呼吸困难有统计学上显着的改善，IPC组和滑石粉组之间的VAS评分平均差异为-14.0毫米（95% CI，-25.2至-2.8）毫米；P = .01)”
但是，我认为由于 -14 位于 -25.2 到 -2.8 的 CI 范围内，因此这在统计上不显着。
我错了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639338/statistically-significant-difference</guid>
      <pubDate>Thu, 15 Feb 2024 11:06:48 GMT</pubDate>
    </item>
    <item>
      <title>受两种相互作用的处理影响的两个变量之间的非线性关系</title>
      <link>https://stats.stackexchange.com/questions/639337/nonlinear-relation-between-two-variables-as-affected-by-two-interacting-treatmen</link>
      <description><![CDATA[我通过实验测试了 6 个重复 x 2 个基因型（分类）x 3 个物种（分类）的因变量 y（连续）和自变量 x（连续）之间的关系（= 处理 A），这些重复在 3 个不同的预处理中生长。 -处理过的土壤（分类，=处理 B），产生 108 株植物。该实验同时在不同的温室（GH）中进行，基因型-土壤组合随机分布。我主要想知道 y 和 x 之间的关系在土壤 (a) 之间是否不同。我还想知道当每个物种的两个植物品种在同一土壤中生长时，y 和 x 之间的关系是否不同 (b)。我想将温室视为潜在的随机效应。

我可以像这样安装 y~x：
(一)
unique_soils &lt;- unique(d_sub$Soil)
for（unique_soils 中的土壤）{
  sub_data &lt;- d_sub[d_sub$Soil == 土壤, ]
  拟合 &lt;- nls(y ~ SSlogis(x, asymp, infl, 斜率1), data = sub_data)
  model_list[[paste(&quot;fit_&quot;, 土壤, sep = &quot;&quot;)]] &lt;- 拟合
}

(b)
unique_soils &lt;- unique(d_sub$Soil)
unique_Genotypes &lt;- unique(d_sub$Genotype)
for（unique_soils 中的土壤）{
  sub&lt;- d_sub[d_sub$Soil == 土壤, ]
  for (unique_Genotypes 中的基因型) {
  sub_data &lt;- sub[sub$Genotype == Genotype, ]
  拟合 &lt;- nls(y ~ SSlogis(x, asymp, infl, 斜率1), data = sub_data)
  model_list[[paste(&quot;fit_&quot;, Genotype,&#39;_&#39;,soil, sep = &quot;&quot;)]] &lt;- 拟合
  }
}

我的表格如下所示（示例）：
&lt;前&gt;&lt;代码&gt;&gt;头（d_sub）
        ID 基因型 土壤 GH y x 物种
1 311019 物种B_基因型A 土壤A 1 0.1542170 1.482907 物种B
2 311019 物种B_基因型A 土壤A 1 0.2033631 1.715033 物种B
3 311019 物种 B_基因型 A 土壤 A 1 0.2762349 2.365915 物种 B

如果土壤和同一土壤中生长的同一物种的基因型之间的 y 和 x 之间的关系存在统计差异，那么最好的测试方法是什么？
我在想：

使用方差分析来比较生成的模型是否彼此存在显着差异。我不确定这是否有效，因为我的模型是非线性的。
创建一个以土壤和基因型作为交互因子的 nlme（我没有找到如何在 R 中对其进行编码）。
提取拟合参数asymp、infl、slope1并使用统计检验在处理之间相互比较。我不知道如何解释拟合参数的标准误差/置信区间。

感谢您分享您的意见！]]></description>
      <guid>https://stats.stackexchange.com/questions/639337/nonlinear-relation-between-two-variables-as-affected-by-two-interacting-treatmen</guid>
      <pubDate>Thu, 15 Feb 2024 11:06:33 GMT</pubDate>
    </item>
    <item>
      <title>在比例赔率模型中，当两个相邻类别合并在一起时，估计参数（斜率）会发生变化，即使它们不应该发生变化</title>
      <link>https://stats.stackexchange.com/questions/639335/in-a-proportional-odds-model-when-two-adjacent-categories-are-pooled-together</link>
      <description><![CDATA[在几篇文章中，我指出，当使用比例赔率（PO 或累积 Logit）模型时，由于斜率参数保持不变，因此很自然会折叠相邻的结果类别。目前，我使用 R 中的 clm 函数，语法如下：clm &lt;- clm(response ~ time + Group, data=DatasetLong)。我的响应变量包含四个级别：0、1、2 和 3。在检查模型摘要后，我观察到以下输出：
公式：响应~时间+组
数据：数据集长

系数：
       估计标准。误差z值Pr(&gt;|z|)
时间 0.1268 0.0432 2.94 0.0033 **
第4组 0.0923 0.2746 0.34 0.7369
第 5 组 1.3196 0.2858 4.62 3.9e-06 ***
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

阈值系数：
    估计标准。误差z值
0|1 0.926 0.330 2.80
1|2 2.560 0.362 7.07
2|3 6.007 0.677 8.87
（197 个观察因缺失而被删除）

比我尝试折叠级别 0 和 1 (DatasetLong$response2 &lt;- recode_factor(DatasetLong$response, &quot;0&quot;=&quot;1&quot;)并拟合相同的模型：clm2 &lt;- clm(response2 ~ time + Group, data=DatasetLong)，其中response2现在只有3个级别：1,2,3。根据“可折叠性下不变”属性，我假设对时间、Group4 和 Group5 的估计相同。但是，我的摘要（clm2）输出是：
&lt;前&gt;&lt;代码&gt;摘要(clm2)
公式：响应2~时间+组别
数据：数据集长

系数：
       估计标准。误差z值Pr(&gt;|z|)
时间 0.0597 0.0550 1.09 0.27774
第4组 -0.0217 0.4029 -0.05 0.95712
第 5 组 1.3584 0.3595 3.78 0.00016 ***
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

阈值系数：
    估计标准。误差z值
1|2 2.117 0.452 4.69
2|3 5.569 0.730 7.62
（197 个观察因缺失而被删除）

对于时间的估计，Group4和Group5完全不同。我哪里出错了？]]></description>
      <guid>https://stats.stackexchange.com/questions/639335/in-a-proportional-odds-model-when-two-adjacent-categories-are-pooled-together</guid>
      <pubDate>Thu, 15 Feb 2024 10:45:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 bootstrap 比较两种机器学习模型的性能</title>
      <link>https://stats.stackexchange.com/questions/639334/using-bootstrap-to-compare-performance-of-two-machine-learning-models</link>
      <description><![CDATA[我有一个二元分类问题，以及两个 ML 模型 $A$ 和 $B$。我使用 ROC 曲线下面积 (AUROC) 评估这些模型的性能。我想评估模型 $A$ 是否明显优于模型 $B$。我的测试集相当小（156 个样本）。由于它是从未知分布（我无权访问）中抽​​取的，因此是随机的，因此 AUROC 结果也有些随机。统计测试应该告诉我结果的差异是否可能是由于更好的模型（“统计显着性”），或者是否很可能是由于测试数据的特定选择。
我有以下使用引导测试的方法：

我绘制 $n$ 个引导样本 $i\in\{1,...,n\}$测试集的，例如$n=1000$。
对于每个引导样本$i$，我计算$\text{AUROC}^A_i$和 $\text{AUROC}^B_i$，以及它们的区别 $d_i = \text{AUROC}^A_i - \text{AUROC}^B_i$。
根据差异分布$d_i$，我计算了 bootrap 置信区间
如果该区间完全高于零或低于零，则性能差异具有统计显着性，如果该区间包含零，则不显着。

这是测试性能差异的好方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639334/using-bootstrap-to-compare-performance-of-two-machine-learning-models</guid>
      <pubDate>Thu, 15 Feb 2024 10:20:46 GMT</pubDate>
    </item>
    <item>
      <title>我的结果发生了重大变化，在前期出现了相反的迹象。这是一个问题吗？</title>
      <link>https://stats.stackexchange.com/questions/639331/i-have-a-significant-change-in-my-outcome-with-the-opposite-sign-in-the-lead-per</link>
      <description><![CDATA[假设变量 x 对 y 有负显着影响。滞后即变量 L1.x 对 y 也有显着的负面影响。但我得到了一个对 y 在未来一段时间内有显着影响的积极迹象，即 Lead1.x。我的身份识别总是有问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/639331/i-have-a-significant-change-in-my-outcome-with-the-opposite-sign-in-the-lead-per</guid>
      <pubDate>Thu, 15 Feb 2024 09:46:58 GMT</pubDate>
    </item>
    <item>
      <title>每次使用相同的估算分类数据运行 cfa.mi 模型时，我都会得到非常不同且不一致的模型拟合指数和测试统计数据</title>
      <link>https://stats.stackexchange.com/questions/639330/i-get-very-different-and-inconsistent-model-fit-indices-and-test-statistics-ever</link>
      <description><![CDATA[我正在尝试测试我的单潜在因子模型中的测量不变性。我有 24 个问题编码为“正确”和“不正确”我的数据中有 3 个不同的组。每组的样本量约为 200 个。
由于存在一些缺失数据，据我所知，我无法使用 WLSMV 估计器运行 CFA 模型。因此，我首先使用 Amelia 包估算数据，然后尝试运行 semTools 包中的 cfa.mi 函数，如runMI功能说明。
我的问题是，每次运行配置或度量模型、拟合指数（CFI、TLI、RMSEA）和模型测试统计数据都会产生非常不同的结果（我保持估算数据集相同）。
这是我正在运行的代码：
&lt;代码&gt;
data_mck &lt;- MCK_DATA_
data_mck &lt;- data_mck[,1:32]
设置.种子(12345)
Amelia.imputation＜- amelia(data_mck[,-c(14,15,16,17,18)]，m＝20，idvars＝“ID”，ords＝c(“Q1”，“Q2A”) 、“Q3A”、“Q3B”、“Q3C”、“Q5”、“Q6”、“Q8A”、“Q8B”、“Q8C”、“Q10”、“Q12B” 、“Q13A”、“Q13B”、“Q13C”、“Q17A”、“Q18B”、“Q19A”、“Q19B”、“Q19C”、“Q19D”、“Q20A” 、“Q22”、“Q23”），p2s = FALSE，incheck = T）
imps_mck &lt;- Amelia.imputation$imputations

## 这里我有 20 个估算数据集和 24 个二元问题 ###
for (i in 1: 20) { imps_mck[[i]]$COUNTRY &lt;- 因子(imps_mck[[i]]$COUNTRY) }
### 数据集中有 3 个不同的组（国家）###

model_mck &lt;- &#39;MCK =~ Q1+Q2A+Q3A+Q3B+Q3C+Q5+Q6+Q8A+Q8B+Q8C+Q10+Q12B+Q13A+Q13B+Q13C+Q17A+Q18B+Q19A+Q19B+Q19C+Q19D+ Q20A+Q22+Q23’

cfa.configural &lt;- cfa.mi(model_mck、数据 = imps_mck、估计器 =“WLSMV”、组 =“国家”、有序 = TRUE)
摘要（cfa.configural，fit.measures = TRUE，标准化 = TRUE）

cfa.metric &lt;- cfa.mi(model_mck，数据 = imps_mck，估计器 =“WLSMV”，组 =“国家”，有序 = TRUE，
group.equal =“负载”）
摘要（cfa.metric.amelia_mck_wout_Q9，fit.measures = TRUE，标准化= TRUE）

cfa.scalar&lt;- cfa.mi(model_mck，数据= imps_mck，估计器=“WLSMV”，组=“国家”，有序= TRUE，
group.equal = c(“载荷”,“截距”))
摘要（cfa.scalar，fit.measures = TRUE，标准化 = TRUE）

### 当我从 R 环境中删除并重新运行它们时，所有模型都会给出非常不同且不一致的拟合指数和测试统计数据 ###

lavTestLRT.mi(cfa.metric, h1=cfa.configural)


我的代码有什么问题吗？我在群聊和其他平台上都找不到任何信息。如果有人能看一下并提供帮助，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/639330/i-get-very-different-and-inconsistent-model-fit-indices-and-test-statistics-ever</guid>
      <pubDate>Thu, 15 Feb 2024 09:23:57 GMT</pubDate>
    </item>
    <item>
      <title>我们能否报告仅测量一次但其分布是通过贝叶斯方法获得的数量的可信度或置信区间？</title>
      <link>https://stats.stackexchange.com/questions/639329/can-we-report-a-credibility-or-confidence-interval-for-a-quantity-measured-only</link>
      <description><![CDATA[假设您使用贝叶斯方法计算感兴趣数量 $X$ 的概率密度函数 (pdf)，给定其测量值$x$（仅测量一次）以及有关实验的一些其他假设/约束/知识。
然后您可以使用该 pdf 来计算 $X_{exp}$ 的预期值（pdf(X) * X 在整个域）和某个间隔，例如$X_{left} $X_{left} &lt; X_{exp} &lt; X_{right}$ 会产生 pdf 积分的给定百分比？
为什么会有疑问？因为进行实验的人认为：

报告 $n = 1$ 的不确定性没有任何意义
实验重复的变异性通常比贝叶斯概率密度函数产生的变异性大得多，因此人们会出现（在他们看来荒谬的）情况，即随着实验的增多，不确定性可能增加运行。
（注：确实，测定中使用的生物材料的行为可能会有所不同，具体取决于其来源、处理方式等，因此，如果在不同的实验运行中使用不同行为的材料，结果确实可能会有很大差异）。

我的反驳是，如果我们对 $n = 1$ 使用 pdf 导出的区间，我们并没有做出任何虚假陈述：我们只是说，基于根据在这个单一实验中收集的证据，该特定批次的生物材料的“真实”值$X$被认为介于如此这般的界限。
如果下次我们进行实验时，生物材料的行为会非常不同，从而导致 $X_{exp}$ 非常不同，IMO 这并不是对先前声明的伪造，但这只是两批物料实际不均匀的表现。
这只是因为我们决定将不同生物材料的不同实验运行视为“相同”数量的测量，即我们对所有$X_{进行平均exp}$ 的，我们面临的风险是 $n&gt;1$ 的不确定性比 $n=1$。
这种明显的矛盾只是我们自己选择从不同且可能不兼容的实验中汇总数据的结果；还是我错了？
此外，即使使用测量的 $x$，而不是贝叶斯派生的 $X$。
因此，事实上，我认为使用贝叶斯方法，通过生成 pdf，能够报告一些合理推导的不确定性估计（顺便说一句，更频繁）$n = 1$ 种情况，而坚持测量 $x$ 仅允许在  时报告不确定性$n&gt; 1 美元，更糟糕的是，实验中使用的特定批次材料成为人质，可能导致置信区间被高估或低估。
我真的很高兴听到这个专家社区对这个主题的看法，这个主题在我们公司引起了相当多的讨论和争议。]]></description>
      <guid>https://stats.stackexchange.com/questions/639329/can-we-report-a-credibility-or-confidence-interval-for-a-quantity-measured-only</guid>
      <pubDate>Thu, 15 Feb 2024 09:14:12 GMT</pubDate>
    </item>
    <item>
      <title>中心极限定理不适用的可能原因？</title>
      <link>https://stats.stackexchange.com/questions/639328/possible-reason-for-the-central-limit-theorem-not-to-apply</link>
      <description><![CDATA[我有一个多生成器进程，每分钟生成约 1200 个数据点，由约 80 个进程组成，这些进程或多或少均匀地贡献了数据点。理论上，每个奇异过程应该产生相同的测量结果，实际上它们有所不同，但不是极端的。由于数据量很大，每分钟都会对这些数据点进行平均并保存。附图中提供了一些示例 KDE 图。
现在我计划以过程能力和控制图的形式将统计过程控制应用到这个过程中。然而，大多数这些方法都需要某种形式的正态性才能成为有效的措施。我假设 1200 人的组大小应该足以让 CLT 保持不变，这样我的平均值呈正态分布，但事实并非如此。
我的分布更窄，不是 68.27% 的数据在 1 个标准差内，而是大约 76%。然而，2 或 3 个标准差内的数据量更接近。我尝试转换数据，但无法使其更正常。
由于非参数控制图并不是真正流行的东西，我想确保我没有做出任何导致这一点的错误假设。我相信问题在于我的数据点不是独立同分布的。因为它们在时间上是相关的，因为过程变化既不是完全随机的也不是瞬时的。这是一个合理的假设吗？如果是这样，我还可以做一些进一步的事情吗？我已经计划对数据应用基于百分位的分析，这些数据对于过程能力有详细记录，但在控制图的情况下却没有那么多。
]]></description>
      <guid>https://stats.stackexchange.com/questions/639328/possible-reason-for-the-central-limit-theorem-not-to-apply</guid>
      <pubDate>Thu, 15 Feb 2024 09:11:03 GMT</pubDate>
    </item>
    <item>
      <title>执行蒙特卡罗后 Chi2/dof 会变成不同的值吗？</title>
      <link>https://stats.stackexchange.com/questions/639327/chi2-dof-going-to-a-different-value-after-doing-a-monte-carlo</link>
      <description><![CDATA[我写信给你是因为我今天完全沉浸在工作中。一段时间以来，我一直在研究有点复杂的多线性回归，但我面临着一个我的大脑似乎无法处理的问题。一定是我做错了什么，非常愚蠢，但我已经找了三天了，却找不到任何解释。
因此，在我的基线中，我使用某些恒星的几个特征对它们执行多线性回归，但主要是它们的星等 (m) 和它们的不确定性 (sig_m &gt;)，对应于天文学标准 1-sigma 不确定度。
这条基线给了我很好的结果，与预期的物理现象非常相关，而且从统计上看，我的拟合度的卡方 (chi2/dof) 降低为 1.05，所以我很高兴。&lt; /p&gt;
为了更好地估计我的拟合参数，尤其是它们的不确定性，我决定对这些恒星的星等进行蒙特卡罗并随机重新绘制它们。
因此，在进行拟合之前，我将每一颗恒星一颗一颗地取出，并根据正态分布重新分配一个新的星等 (new_m) ~N(m, &lt; em&gt;sig_m），其中 m 是其旧震级（从基线开始），sig_m 是其不确定性。对于每个新模拟，我都保持 sig_m 不变。
我最终根据我的原始数据集以这种方式生成了 1000 个数据集。我对这 1000 个新数据集再次执行相同的拟合，令人惊讶的是：我的卡方完全改变了。
这 1000 个新拟合中的每个自由度卡方 (chi2/dof) 约为 2.5，与我的基线完全不同（参见附图）。我完全不明白为什么会发生这种情况。无论我如何转动大脑，我的脑子里都没有任何意义。
某处一定存在一些愚蠢的错误，但我不明白为什么会发生这种情况，为什么与我的 1000 个新拟合相比，我的基线是唯一的异常值，唯一的区别是平局 ~N(m, sig_m ）...
预先感谢您的帮助！
]]></description>
      <guid>https://stats.stackexchange.com/questions/639327/chi2-dof-going-to-a-different-value-after-doing-a-monte-carlo</guid>
      <pubDate>Thu, 15 Feb 2024 09:09:47 GMT</pubDate>
    </item>
    <item>
      <title>CI 的 p 值？</title>
      <link>https://stats.stackexchange.com/questions/639326/p-values-from-cis</link>
      <description><![CDATA[有没有办法从使用 quantile 函数提取的 CI 中计算 p 值？
bs1 &lt;- 复制(1000, sd(样本(c(10,23,21,12,14,14,13,14,15,25), 10, 替换=TRUE)))
bs2 &lt;- 复制(1000, sd(样本(c(10,11,10,13,13,13,14,19,12,23), 10, 替换=TRUE)))

CI &lt;- 分位数(bs1 - bs2, prob = c(0.025, 0.975))
]]></description>
      <guid>https://stats.stackexchange.com/questions/639326/p-values-from-cis</guid>
      <pubDate>Thu, 15 Feb 2024 08:55:11 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯因子的封闭式表达</title>
      <link>https://stats.stackexchange.com/questions/639325/closed-form-expression-of-bayes-factor</link>
      <description><![CDATA[设置
让数据$\sim N(\mu, \sigma^2)$，我们考虑$\sigma^ 2$已知。
先前：$\mu \sim N(m_0, \sigma^2 / n_0)$。
&lt;小时/&gt;
问题
我正在尝试计算$A / B$，其中

$A = p(数据 | \mu = m_0, \sigma^2)$
$B = \int p(data | \mu, \sigma^2) \,\, p(\mu | m_0, n_0, \sigma^2) \, \, d\mu$

你能帮我得到下面的结果吗？
&lt;小时/&gt;
回答
]]></description>
      <guid>https://stats.stackexchange.com/questions/639325/closed-form-expression-of-bayes-factor</guid>
      <pubDate>Thu, 15 Feb 2024 08:28:01 GMT</pubDate>
    </item>
    <item>
      <title>ANOVA、ANCOVA、线性混合效应模型</title>
      <link>https://stats.stackexchange.com/questions/639324/anova-ancova-linear-mixed-effect-model</link>
      <description><![CDATA[我通过实验测试了因变量_y（连续）和自变量_x（连续）之间的关系，对 3 个物种（分类）的 2 个植物品种（分类）进行 10 个重复，每个品种（= 处理 A）在 3 种不同的预处理条件下生长。处理过的土壤（分类，=处理 B）。该实验同时在不同的温室（GH）中进行，植物-土壤组合随机分布。
我主要想知道 y 和 x 之间的关系在土壤之间是否不同。我还想知道每个物种的两种植物品种在同一土壤中生长时是否存在差异。我想将温室视为潜在的随机效应。
我是否进行：

方差分析，例如：lm(y ~ x + A*B, data = dat)
ANCOVA ? （如何？）
线性混合效应模型，例如：lme(y ~ x + A * B, random = ~ 1 | GH, data = dat)

感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/639324/anova-ancova-linear-mixed-effect-model</guid>
      <pubDate>Thu, 15 Feb 2024 08:08:12 GMT</pubDate>
    </item>
    <item>
      <title>多重测试中的“可互换性”是什么意思？</title>
      <link>https://stats.stackexchange.com/questions/639323/what-does-exchangeability-mean-in-multiple-testing</link>
      <description><![CDATA[在计算生物学中控制错误发现的方法的实用指南&lt; /a&gt;，作者提到了“可交换性”：

根据Wiki，“可交换性”的定义是：
在统计学中，随机变量的可交换序列（有时也可以互换）[1] 是一个序列 X1, X2, X3, ...（可能是有限或无限长），其联合概率分布不当有限多个出现的序列中的位置发生变化时，就会发生变化。 
如果我将定义应用到论文中，是否意味着 p 值的分布顺序并不重要？这是什么意思？我觉得这很令人困惑。由于每个假设检验的相应 p 值应该与顺序相关，因为它们正在测试不同的变量？另外，“检测发现的能力在所有测试中具有相同的可能性”是什么意思？是否有可能进行假设检验，即使它们具有相同的零假设（即 H0：系数为零），但测试之间的能力也不相等对于每个测试。）
（我知道假设检验的依赖结构可能会导致功效不平等，但我仍然无法理解。您介意提供一些例子吗？例如模拟？）
您能否提供一份参考文献列表？我目前正在寻求扩大我对多重测试主题的理解。非常感谢您的帮助。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/639323/what-does-exchangeability-mean-in-multiple-testing</guid>
      <pubDate>Thu, 15 Feb 2024 07:56:39 GMT</pubDate>
    </item>
    <item>
      <title>如何解释线性模型中残差变量的系数？</title>
      <link>https://stats.stackexchange.com/questions/639321/how-to-interpret-the-coefficient-of-a-residualized-variable-in-a-linear-model</link>
      <description><![CDATA[我正在拟合线性模型，数据中存在很强的多重共线性。因此，我决定残差一个回归变量以减少多重共线性，并再次拟合模型。变量残差前后的贝塔系数相同。但这次系数的解释应该有所不同吗？如何正确解释？
任何有关残差技术的参考文献将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/639321/how-to-interpret-the-coefficient-of-a-residualized-variable-in-a-linear-model</guid>
      <pubDate>Thu, 15 Feb 2024 07:45:13 GMT</pubDate>
    </item>
    <item>
      <title>AR 模型中 $p$ 值的引导调整可以应用于分布式滞后模型吗？</title>
      <link>https://stats.stackexchange.com/questions/639320/can-bootstrap-adjustment-for-p-value-in-ar-model-be-applied-to-distributed-lag</link>
      <description><![CDATA[在Wang “时间序列中的多重测试校正： Rolling window Analysis with applications of GWASmethods”（2022），作者提到 bootstrap 最小值 $p$-value 可以应用于拟合的残差AR 模型（第 26 页）。是否可以将其应用于以每日死亡人数作为因变量、以 21 个滞后的温度作为自变量的 DLM？
等式为：
$$
每日 Death_t \sim \beta_0 + \beta_1 Temp_{t-1} + \dots + \beta_{21} Temp_{t-21} + u_t
$$
我想对 $Temp_{t-i}$ 的所有滞后变量执行多次更正。]]></description>
      <guid>https://stats.stackexchange.com/questions/639320/can-bootstrap-adjustment-for-p-value-in-ar-model-be-applied-to-distributed-lag</guid>
      <pubDate>Thu, 15 Feb 2024 07:38:49 GMT</pubDate>
    </item>
    </channel>
</rss>