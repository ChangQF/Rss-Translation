<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 04 Apr 2024 15:13:46 GMT</lastBuildDate>
    <item>
      <title>我是否正确理解如何执行顺序二进制分区？</title>
      <link>https://stats.stackexchange.com/questions/644316/do-i-understand-correctly-how-to-perform-sequential-binary-partition</link>
      <description><![CDATA[我正在处理地球化学数据。假设我有一种矿物的化学分析结果，其中含有以下元素：A、B、C、X、Y、Z。X、Y 和 Z 是属于同一族的元素（假设它们是稀土元素），但 A、B、C 不是。下面我描述了我对其工作原理的理解。
在第一步中，将我的成分分为两组会很方便：[A，B，C] 和 [X，Y，Z]（因为在地质学中将稀土与其他元素分开是有意义的）。据我了解，我将元素编码为 1 和 -1，例如：

&lt;标题&gt;


一个
B
C
X
Y
Z


&lt;正文&gt;

S1
1
1
1
-1
-1
-1



但是，我们假设除此之外，所有元素彼此之间没有任何共同点。因此，执行进一步的步骤来分区我的数据，我将其他元素分为任意组。因此，我可以在 XYZ 组内执行分区为 [X] 和 [Y, Z]，第二步可能如下所示：

&lt;标题&gt;


一个
B
C
X
Y
Z


&lt;正文&gt;

S2
0
0
0
1
-1
-1



然后，我可以应用相同的推理来划分 XYZ 组和 ABC 组的其余部分，我会得到如下结果：

&lt;标题&gt;


一个
B
C
X
Y
Z


&lt;正文&gt;

S1
1
1
1
-1
-1
-1


S2
0
0
0
1
-1
-1


S3
0
0
0
0
1
-1


S4
1
1
-1
0
0
0


S5
0
1
-1
0
0
0



那么，我的说法正确吗？我还了解到，每次分析单独的数据集时，我都可以从头开始为特定数据集执行 SBP，以使等距对数比的解释更加方便 - 我的看法也是对的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644316/do-i-understand-correctly-how-to-perform-sequential-binary-partition</guid>
      <pubDate>Thu, 04 Apr 2024 15:08:28 GMT</pubDate>
    </item>
    <item>
      <title>对连续的泊松点过程进行建模，其中第二个过程仅在第一个过程有 x 个计数后才开始</title>
      <link>https://stats.stackexchange.com/questions/644315/modelling-consecutive-poisson-point-processes-where-the-second-starts-only-afte</link>
      <description><![CDATA[我想模拟一种情况，其中有两个连续的具有不同事件发生率的泊松点过程，并且第二个过程仅在第一个过程达到累积事件计数后才开始 $ x$.
最终，我有兴趣知道第二个进程在时间  之前具有累积事件计数 $y$ 的概率$T$，我认为等于在时间 $ 发生事件计数 $\ge y$ 的概率T$.
我目前的想法是：

表达第一个进程恰好具有$x$的概率$P(A)$可变时间 $t$ 发生的事件，其中 $0 \le t \le T$。
然后，表达第二个进程具有 $\ge 的条件概率 $P(B|A)$ y$ 个事件，时间为 $T$，其经过时间为 $T-t$ .
然后，概率 $P(B)=P(B|A) \times P(A)$ 可以写成 $t$
最后，感兴趣的概率是所有可能 $t$&lt; 的 $P(B)$ 之和。 /span&gt;，我可以通过 $\int_{0}^{T} P(B) \,dt$ 获得

我的问题是：

我是在重新发明轮子吗？是否已经有任何既定的方法来模拟这种情况？
我是否正确，特别是将 $P(A)$ 定义为恰好具有 $x 的概率$ 事件，而不是 $\ge x$？
是否有更简单/更优雅的替代方案来模拟这种情况？最终我想对有 3 个连续进程的情况进行建模。

非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644315/modelling-consecutive-poisson-point-processes-where-the-second-starts-only-afte</guid>
      <pubDate>Thu, 04 Apr 2024 15:01:07 GMT</pubDate>
    </item>
    <item>
      <title>非二项分布的 glmmTMB 模型：模型收敛问题</title>
      <link>https://stats.stackexchange.com/questions/644314/glmmtmb-model-with-non-binomial-distribution-model-convergence-problem</link>
      <description><![CDATA[我需要一些帮助来解决我遇到的一些建模问题。
我有一个数据集，我试图确定哪些变量正在影响配子囊的产生。
我在此附上我的数据集“gametocysts_data”（请保密数据）：https://docs.google.com/spreadsheets/d/1KSm93oqAypclffqC2gtyNjbAFAtccKFl/edit?usp=sharing&amp;ouid=101060992924354550050&amp;rtpof=true&amp;sd=true
到目前为止我已经进行了以下分析：
清除 NA 中的数据
gametocysts_data &lt;- na.omit(gametocysts_data)
gametocysts_data &lt;- droplevels(gametocysts_data)
str(配子囊_数据)
小标题[176×9]（S3：tbl_df / tbl / data.frame）
 $ 治疗：因子有 2 个级别“未治疗”、“治疗”：1 1 2 2 1 1 2 2 1 1 ...
 $ R ：带 2 个级别“1”、“2”的因子：1 2 1 2 1 2 1 2 1 2 ...
 $ Box_Id ：带 4 个级别“NonTreated_1”的因子，..： 1 2 3 4 1 2 3 4 1 2 ...
 $ Dpi ：因子 w/ 9 个级别“1”、“2”、“3”、“4”、..： 1 1 1 1 2 2 2 2 3 3 ...
 $ Cricket_Age：因子 w/ 44 个级别“19”、“20”、“21”、..： 1 1 1 1 2 2 2 2 3 3 ...
 $ 粪便：数量 [1:176] 95 67 90 134 83 90 153 230 122 77 ...
 $ Faeces_ind : 数字 [1:176] 1.056 0.753 0.909 1.396 0.943 ...
 $ N_ind : 数字 [1:176] 90 89 99 96 88 86 95 93 84 76 ...
 $ 配子囊: num [1:176] 0 0 0 0 0 0 14 13 0 0 ...

#Dpi 和 cricket_age 是我感兴趣的时间变量，并将它们视为分类变量，因为我有兴趣查看不同时间点的比较。
另一方面，我也有兴趣看看每个人产生的粪便（Faeces_ind）和受试者测试的数量（N_ind）是否会对包囊产生产生显着影响。
查看变量 distrib
hist(treatment_data$Gametocysts)
options(na.action = &quot;na.fail&quot;) # 防止将模型拟合到不同的数据集，这是 dredge() 所需的

Full_model_gametodata &lt;- glmmTMB(Gametocysts ~ Treatment + Dpi + Cricket_Age + Faeces_ind + N_ind + (1|Box_Id), data = gametocysts_data, nbinom2(link = &quot;log&quot;))
诊断（完整模型）
#模型看起来不错！

检查型号
摘要（Full_model_gametodata）
fixef(完整模型游戏数据)
图书馆(MuMIn)
疏浚（Full_model_gametodata）

我用 dredge() 确定的最佳模型是这个，但我最终遇到了以下错误消息：
final_model &lt;- glmmTMB(Gametocysts ~ Treatment + Dpi + Cricket_Age + Faeces_ind + (1|Box_Id), data = gametocysts_data, nbinom2(link = &quot;log&quot;))
#从排名不足的条件模型中删除列：Dpi2、Dpi3、Dpi4、Dpi5、Dpi6、Dpi7、Dpi8、Dpi9、Box_IdTreated_2
#Warning：模型收敛问题；奇异收敛 (7)

诊断（最终模型）
#名称错误(pp) &lt;- nn :
#&#39;names&#39;属性[58]必须与向量[49]长度相同

并且摘要返回 NaN：
估计标准。误差z值Pr(&gt;|z|)
（截距）-101.8983 NaN NaN NaN
治疗已治疗 23.3855 NaN NaN NaN
Cricket_Age20 81.8572 NaN NaN NaN
Cricket_Age21 82.5677 南 南 南
ETC

我知道错误来自我的数据，但我需要帮助才能更好地理解导致问题的原因。我已经尝试研究如何解决收敛问题，但如果用我的数据来说明它会很棒。
问题是因为 Dpi 和 Cricket_Age 不独立吗？ （Dpi 与板球年龄相关）。我还有分类和数值解释变量的混合；不知道这个说法是否正确。
我也有一些重复。
感谢您的时间和帮助。
爱德华]]></description>
      <guid>https://stats.stackexchange.com/questions/644314/glmmtmb-model-with-non-binomial-distribution-model-convergence-problem</guid>
      <pubDate>Thu, 04 Apr 2024 14:44:59 GMT</pubDate>
    </item>
    <item>
      <title>Pitman-Koopman-Darmois 定理对于离散随机变量是否有效？</title>
      <link>https://stats.stackexchange.com/questions/644313/is-pitman-koopman-darmois-theorme-valid-for-discrete-random-variables</link>
      <description><![CDATA[我对 Pitman-Koopman-Darmois 定理感兴趣。
我很难找到这个定理的简单严格版本，因为我很难找到来源。
这篇有用的帖子 为定理提供了三个来源：

Pitman 的一篇：皮特曼，E.J.G. (1936) 足够的统计数据和内在准确性，《剑桥哲学会报》，32, 567-579。
Koopman 的一篇：库普曼，B.O. (1936) 关于承认足够统计量的分布，美国数学会汇刊，卷。 39、第3号。
Darmois 的一篇：Darmois, G. (1935) Sur les lois de probabilité à 详尽的估计，Comptes Rendus de l&#39;Académie des Sciences, 200, 1265-1266。

（还有一个来自 Don Fraser 的参考，我之所以发布它，是因为它似乎有点有争议）
Darmois 的最后一个参考文献没有提供任何证明，而只是对该定理的简短非正式陈述。我认为该定理在作者的其他出版物中得到了证明，但我在网上找不到。
Pitman 的第一个参考文献提供了证明，但没有明确说明结果。而且我发现它不够严谨，符号松散，假设没有明确表述，还有一些“……很明显……”的内容。我发现这一点根本不明显。
Koopman的参考文献清晰而严谨（仅在足够的统计量为2维的特定情况下给出证明），但定理的陈述有点技术性，仅处理连续的一维实随机变量。
因此我的问题是，Pitman-Koopman-Darmois 对于离散随机变量也有效吗？
更一般地说，还有其他参考文献来陈述和证明这个定理吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644313/is-pitman-koopman-darmois-theorme-valid-for-discrete-random-variables</guid>
      <pubDate>Thu, 04 Apr 2024 14:36:43 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯认为样本是固定的吗？</title>
      <link>https://stats.stackexchange.com/questions/644312/does-bayesian-regard-samples-as-fixed</link>
      <description><![CDATA[来自 zedstatistics 的关于置信区间的视频表示样本从贝叶斯观点来看是固定的。但我怀疑这个说法是否正确，因为不可能构造后验概率 $P(\theta | X)$ if $X$ 不被视为 r.v.下面附上视频中此类讨论的摘录，供参考：
]]></description>
      <guid>https://stats.stackexchange.com/questions/644312/does-bayesian-regard-samples-as-fixed</guid>
      <pubDate>Thu, 04 Apr 2024 14:28:31 GMT</pubDate>
    </item>
    <item>
      <title>在python中提取html页面中没有标签的部分</title>
      <link>https://stats.stackexchange.com/questions/644311/extract-section-of-html-page-in-python-where-there-arent-tags</link>
      <description><![CDATA[发布在错误的论坛上，需要 30 个字符才能保存。]]></description>
      <guid>https://stats.stackexchange.com/questions/644311/extract-section-of-html-page-in-python-where-there-arent-tags</guid>
      <pubDate>Thu, 04 Apr 2024 14:28:21 GMT</pubDate>
    </item>
    <item>
      <title>寻找随机变量变换的集合</title>
      <link>https://stats.stackexchange.com/questions/644308/finding-the-set-for-random-variable-transformations</link>
      <description><![CDATA[我正在阅读《All of Statistics》一书，在第 2.12 节中，关于几个随机变量的变换，作者列出了查找变换的三个步骤。即使使用单变量转换，我也在努力解决这个问题。正文内容如下：
鉴于 $X$ 和 $Y$ 是随机变量，$\text{let }Z = r(X, Y)$。
列出的执行转换的第一步是：

对于每个 $z$，找到集合 $A_z = \{(x,y) : r(x , y) \le z \}$。

作者然后使用这个集合来查找 CDF。
$$
\开始{对齐}
F_Z &amp;= \mathbb{P}(Z \le z)\\
&amp;= \mathbb{P}(r(X, Z) \le z)\\
&amp;= \mathbb{P}(\{(x,y); r(x,y) \le z\})\\
&amp;= \int\int_{A_z}f_{X,Y}(x,y)\;dx\;dy
\结束{对齐}
$$
最后，他通过微分CDF找到了PDF。
我似乎被困在第一步了。有人可以更直观地解释一下这在实践中是如何运作的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644308/finding-the-set-for-random-variable-transformations</guid>
      <pubDate>Thu, 04 Apr 2024 14:22:20 GMT</pubDate>
    </item>
    <item>
      <title>二项式逻辑回归和组间比较</title>
      <link>https://stats.stackexchange.com/questions/644307/binomial-logistic-regression-and-inter-group-comparison</link>
      <description><![CDATA[我有兴趣探索两个分类变量之间的关系：“种族”和“种族”。和“疾病”，每个都有两个级别。我的主要假设是具有“A 族裔”的个体可能表现出“疾病”。此外，我想包括“年龄”作为混杂变量。我的数据集还包含三种类型的主题：“学生”、“教师”和“经理”。主要问题是“种族”之间的这种关联是否与“种族”相关。和“疾病”这三种不同类型的科目是不同的。例如，该协会“更强大”。在“学生”中比“老师”和“经理”。统计分析应该做什么？我应该在这三组中的每一组中使用二项式逻辑回归，并比较优势比吗？有没有办法获得“p值”？进行比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/644307/binomial-logistic-regression-and-inter-group-comparison</guid>
      <pubDate>Thu, 04 Apr 2024 14:09:49 GMT</pubDate>
    </item>
    <item>
      <title>每次折叠的回归指标计算与 k 折叠交叉验证结束时的计算[重复]</title>
      <link>https://stats.stackexchange.com/questions/644306/regression-metrics-calculation-for-each-fold-vs-calculation-at-the-end-of-k-fold</link>
      <description><![CDATA[当我在 k 折交叉验证期间计算拟合指标时，我偶然发现了一个小事实。请参考以下图片：
计算每次折叠的 R² 或其他拟合指标的方法：

收集预测后最后计算拟合指标的方法：

对于分类准确性，我可以看到这不会成为问题，因为计算准确性是正确预测的计数除以观察总数。保证每次折叠的平均分类精度等于预测每次折叠的类别时计算的分类精度。
对于回归，拟合指标是数字，我假设它们的平均值不相等。我尝试过使用两个数据集的实际示例，发现最后计算拟合指标通常比平均每次折叠的结果能提供更好的结果（例如，更高的拟合优度）。
有人可以给我一些提示吗？我尝试查看这里的历史，但找不到类似的问题。 Google 并没有引导我到任何地方，事实上，我设法找到了应用这两种方法的示例。
从数学上来说，正确的方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/644306/regression-metrics-calculation-for-each-fold-vs-calculation-at-the-end-of-k-fold</guid>
      <pubDate>Thu, 04 Apr 2024 13:54:42 GMT</pubDate>
    </item>
    <item>
      <title>在 R 语言中使用随机森林代理模型的贝叶斯优化需要很长时间才能完成</title>
      <link>https://stats.stackexchange.com/questions/644305/bayesian-optimization-using-randomforest-surrogate-model-in-r-language-is-taking</link>
      <description><![CDATA[我正在运行贝叶斯优化来优化目标函数，其中预测验证集与数据集初始输出平均值之间的差异保持在最小限度；然而，这需要很长时间才能完成。时间已经快到 24 小时了，但仍在运行。现在，我在另一个环境中运行相同的代码，我大幅缩小了超参数的范围，并通过特征选择缩小了训练集的维度，但几乎快要一个小时了。以下是这两种情况的代码说明，希望有人能帮助我：
&lt;前&gt;&lt;代码&gt;**第一种情况**；时间：18点，仍在运行；尺寸：29 个特征；样本量； 4000

#定义目标函数
optimization_objective &lt;- function(ntree,mtry,nodesize) {
  
  # 使用指定的超参数训练随机森林模型
  模型 &lt;- randomForest(y_train ~ ., data = X_train, ntree = ntree, mtry = mtry, 节点大小 = 节点大小)
  

  # 对训练集进行预测
  预测 &lt;- 预测（模型，X_test）

  # 计算预测和output_mean之间的平均绝对误差
  错误 &lt;- 平均值（abs（预测 - output_mean））
  
  # 返回误差的负数作为分数
  返回（-错误）
}

# 定义贝叶斯优化的搜索空间
边界 &lt;- 列表（
  ntree = c(100, 1000), # 树的数量范围
  mtry = c(1, ncol(X_train)), # 采样变量数量范围
  Nodesize = c(1, 100) # 最小节点大小的范围
）

# 执行贝叶斯优化
opt_result &lt;- 贝叶斯优化（optimization_objective，
                                   界限=界限，
                                   初始点 = 5,
                                   n_iter = 10)


**第二个案例**；时间：1小时，仍在运行；尺寸：4 个特征；样本量； 400


#定义目标函数
optimization_objective &lt;- function(ntree,mtry,nodesize) {
  
# 从 params 中提取超参数
  
# 使用指定的超参数训练随机森林模型
  模型 &lt;- randomForest(y_train ~ ., data = X_train, ntree = ntree, mtry = mtry, 节点大小 = 节点大小)
  
 # 对训练集进行预测
  预测 &lt;- 预测（模型，newdata = X_train）
  
  &gt;计算预测和output_mean之间的平均绝对误差
  错误 &lt;- 平均值（abs（预测 - output_mean））
  
  # 返回误差的负数作为分数
  返回（-错误）
}

# 定义贝叶斯优化的搜索空间
边界 &lt;- 列表（
  ntree = c(10, 50), # 树的数量范围
  mtry = c(1, ncol(X_train)), # 采样变量数量范围
  nodesize = c(1, 10) # 最小节点大小的范围
）

# 执行贝叶斯优化
opt_result &lt;- 贝叶斯优化（optimization_objective，
                                   界限=界限，
                                   初始点 = 5,
                                   n_iter = 2)

预先非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/644305/bayesian-optimization-using-randomforest-surrogate-model-in-r-language-is-taking</guid>
      <pubDate>Thu, 04 Apr 2024 13:27:11 GMT</pubDate>
    </item>
    <item>
      <title>在 Python 中生成相关的伯努利样本 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/644304/generate-correlated-bernoulli-samples-in-python</link>
      <description><![CDATA[假设我有 $M$ 伯努利分布，参数为 $p_i$，成对相关 $\rho_{ij}$ 表示 $i\neq j$。我想从联合分布中生成 $N$ 样本。 $M=2$ 的情况已解决此处。 此处提出了 R 中的类似问题。答案使用 R 中的 bindata 包。
我正在尝试按照本文实施采样方法.
我的问题是关于论文的通用算法，而不是具体的包。
作为初学者，我正在实现第 7 页中描述的 3 x 3 示例。
我从 $L(-\mu_A, -\mu_B, \rho_{AB })$。从图 2 来看，我的 $p_{AB}$ 值似乎与论文的方法一致。
如果 $A$ 和 $B$ 是两个伯努利变量，那么它们的协方差应该是 &lt; span class=&quot;math-container&quot;&gt;$p_{AB} - p_{A}p_{B}$。但是，这样做与作者在示例中报告的协方差矩阵不匹配，并且生成的样本也不具有所需的相关性。
我想了解我做错了什么。
这是我的代码（如果有帮助的话）：
将 numpy 导入为 np
从 scipy.stats 导入范数，multivariate_normal

def L(x, y, cov_matrix):
    # 计算联合概率P(X &gt; x, Y &gt; y)
    平均值 = np.array([0, 0])
    x_marginal = multivariate_normal.cdf([x, np.inf], 均值=均值, cov=cov_matrix)
    y_marginal = multivariate_normal.cdf([np.inf, y], 均值=均值, cov=cov_matrix)
    xy = multivariate_normal.cdf([x, y], 均值=均值, cov=cov_matrix)
    P_AB = 1-(x_marginal + y_marginal - xy)
    返回P_AB

defcompute_covariance_entry(p1, p2, rho):
    # 将边际概率转换为等效的标准正态平均值
    mu1 = 范数.ppf(p1)
    mu2 = 范数.ppf(p2)
    
    # 构造一对变量的 2x2 协方差矩阵
    cov_matrix = np.array([[1, rho], [rho, 1]])
    
    # 使用 L 函数求标准正态变量的联合概率
    P_AB = L(-mu1, -mu2, cov_matrix)
    
    # cov 输入正确吗？
    cov_entry = (P_AB - p1 * p2)
    返回 cov_entry

defsample_joint_bernoulli(ps, rhos, N):
    # 计算 p 的正态分布平均值
    M = 长度（ps）
    cov_matrix = np.ones((M, M))
    对于范围 (3) 内的 i：
        对于范围 (i+1, 3) 内的 j：
            cov_entry =compute_covariance_entry(ps[i], ps[j], rhos[i][j])
            cov_matrix[i, j] = cov_entry
            cov_matrix[j, i] = cov_entry
    
    平均值=norm.ppf(ps)

    # 从多元正态分布中采样 N 次
    Normal_samples = np.random.multivariate_normal(意思, cov_matrix, size=N)

    # 转换为二进制结果
    伯努利样本 = (normal_samples &gt; 0).astype(int)

    返回伯努利样本

def validate_samples(样本):
    样本平均值 = np.平均值（样本，轴=0）

    # 计算经验相关矩阵
    experience_corr_matrix = np.corrcoef(样本.T)

    返回样本均值、经验校正矩阵

ps = [0.2, 0.5, 0.8]
N = 1000000
罗 = [
    [1.，-0.25，-0.0625]，
    [-0.25, 1, 0.25],
    [-0.625, 0.25, 1.]
]

# 从联合伯努利分布生成样本
样本=sample_joint_bernoulli(ps, rhos, N)

# 通过计算经验相关矩阵和样本均值来验证样本
样本均值、经验校正矩阵 = validate_samples(样本)

print(&quot;样本均值：&quot;,sample_mean)
print(&quot;经验相关矩阵：&quot;)
打印（经验校正矩阵）

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/644304/generate-correlated-bernoulli-samples-in-python</guid>
      <pubDate>Thu, 04 Apr 2024 13:21:41 GMT</pubDate>
    </item>
    <item>
      <title>给定多个数据集的最大似然估计和方差贝叶斯推断</title>
      <link>https://stats.stackexchange.com/questions/644303/maximum-likelihood-estimation-and-bayesian-inference-of-variance-given-multiple</link>
      <description><![CDATA[
我目前正在解决一个问题，我有多个正态分布数据集 $X_1,...,X_n$ ，每个数据集都有自己的平均值 $\bar x_i $ 但都具有相同的方差$\sigma$。各组之间的样本大小有所不同，对于某些 $X_i$ 也可能达到 1。现在我想估计 $\sigma^2 $ （$\bar x_i $ 未知） 。这样做的最好方法是什么？
$\bar\sigma^2 =1/(N-1)\sum_{i=1}^n\sum_{x\in X_i} (x-\bar x_i)^ 2$，
其中 $N$ 是样本总数。至少在它们是 1 个样本数据集 $X_i$ 的情况下，这会低估方差，然后 $(x-\ bar x_i)^2=0$，这不会提供有关方差的信息。 
标准化看起来应该像 $1/(N-n)$ 吗？
此外，如果我想将其扩展到贝叶斯推理方法，对数似然函数会是什么样子。我认为默认的看起来像
$\sum_{i=1}^n\sum_{x\in X_i} \frac{(x-\bar x_i)^2}{\sigma^2}-N* log(\sigma\sqrt{2\pi})$, 
这可能也会低估 $\sigma$。
我的想法是将 $N$ 替换为 $\hat N$，这是样本总数在具有超过 1 个样本的数据集中。这足够了吗？
编辑：
$X_i$ 的真实均值都是未知的，但在 MLE 的情况下由  估计
$\bar x_i=1/n\sum_{x\in X_i}x$。 （应该还是MLE）
在贝叶斯推理的情况下，我还想将它们作为未知变量处理，即 $\bar x_i$ 也应该通过推理过程导出。]]></description>
      <guid>https://stats.stackexchange.com/questions/644303/maximum-likelihood-estimation-and-bayesian-inference-of-variance-given-multiple</guid>
      <pubDate>Thu, 04 Apr 2024 12:51:21 GMT</pubDate>
    </item>
    <item>
      <title>绘制对数转换后的数据，但对原始数据运行统计？</title>
      <link>https://stats.stackexchange.com/questions/644302/plotting-log-transformed-data-but-running-statistics-on-raw-data</link>
      <description><![CDATA[我打算比较八组平均值之间的差异。仅当我绘制（在箱形图中）对数转换数据时，某些平均值之间的差异才可见。但是，我不确定是否还应该对日志转换后的数据进行单向方差分析统计？我担心的是，当我对对数转换数据进行单向方差分析时，与对原始数据进行统计相比，组之间的显着性不同。
数据是每组 12 只动物的细菌计数。计数数据呈正态分布。
]]></description>
      <guid>https://stats.stackexchange.com/questions/644302/plotting-log-transformed-data-but-running-statistics-on-raw-data</guid>
      <pubDate>Thu, 04 Apr 2024 12:43:54 GMT</pubDate>
    </item>
    <item>
      <title>使用嵌套 cv 和 bootstrap auc 置信区间选择分类模型</title>
      <link>https://stats.stackexchange.com/questions/644300/select-classification-model-using-nested-cv-and-bootstrap-auc-confidence-interva</link>
      <description><![CDATA[我的目标是从 55 个分类模型中找到最好的 1 个模型。
我首先在 55 个模型上运行嵌套 cv，看看哪个模型具有更好的泛化能力。以AUC评分作为评价指标。
但是，几个模型的测试分数差异并不大，大约在0.001或0.002左右，并且当所有这些模型都执行嵌套CV时，训练分数和测试分数之间的差异只有1%到3%。
所以，我觉得单独使用nested cv方法很难只选择一个最好的模型，所以我打算使用bootstrap而不是cv来比较性能相似的模型和模型之间的auc置信区间是否存在差异。选择置信区间较大的模型。由于我们没有做CV，所以数据被分为train:valid:test 6:2:2。我计划使用 t 检验或方差分析来比较 auc 置信区间。
但是，我不知道这是否是选择模型的合适方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/644300/select-classification-model-using-nested-cv-and-bootstrap-auc-confidence-interva</guid>
      <pubDate>Thu, 04 Apr 2024 12:28:31 GMT</pubDate>
    </item>
    <item>
      <title>您应该如何在训练-测试-验证拆分中拆分数据</title>
      <link>https://stats.stackexchange.com/questions/644299/how-should-you-split-up-data-in-a-train-test-validation-split</link>
      <description><![CDATA[我发现，在使用训练-测试-验证数据拆分时，通常建议首先将数据拆分为训练数据集和测试数据集，然后进一步将训练数据集拆分为训练数据集和验证数据集。不建议先拆分为训练数据集和测试数据集，然后再将测试数据集拆分为测试数据集和验证数据集。我想这与防止数据泄露有关，但我不完全确定。为什么会这样？
目前，我正在开发一个多标签 CNN 模型来根据屏幕截图预测视频游戏的标签，其中我将有大约 400 个类（标签）作为输出（一个视频游戏可以有多个标签）。对于最不频繁的类，只有大约 10 个实例。我将对数据进行分层训练测试分割以维持类别比例（尽管由于类别的协变，这有些困难），并且我担心如果我进一步分割训练数据集，这可能会导致某些类别测试或验证集中的内容不会出现在训练数据集中。在这种情况下，将测试数据集拆分为测试集和验证集是否有效？
如果能澄清这些问题，我们将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644299/how-should-you-split-up-data-in-a-train-test-validation-split</guid>
      <pubDate>Thu, 04 Apr 2024 12:25:58 GMT</pubDate>
    </item>
    </channel>
</rss>