<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Sat, 12 Apr 2025 12:31:53 GMT</lastBuildDate>
    <item>
      <title>做i.i.d.假设扩展到现代序列模型（例如RNN）中独立生成序列的数据集？</title>
      <link>https://stats.stackexchange.com/questions/663978/do-i-i-d-assumptions-extend-to-datasets-of-independently-generated-sequences-in</link>
      <description><![CDATA[在具有横截面数据的标准机器学习设置中，通常假设数据点是独立且相同分布的（i.i.d.），这些数据点（i.i.d.）从某些固定的数据生成过程（DGP） $ d $ d $ ：
 $$
（x_i，y_i）\ sim d，\ quad \ text {i.i.d。 } i = 1，\ dots，n。
$$ &lt; /span&gt; 
这种假设基于许多理论结果，包括融合保证经验风险最小化和学习参数的一致性。
现在考虑一个不同的结构：
每个训练样本本身都是序列：
 $$
x^{（i）} =（x^{（i）} _ 1，x^{（i）} _ 2，\ dots，x^{（i）} _ t），_ t），
$$ 
序列被采样为：
 $$
\ {x^{（i）} _ t \} _ {t = 1}^t \ sim d，\ quad \ text {for} i = 1，\ dots，n，n，
$$ 
其中每个序列 $ X^{（i）} $ 是由相同的数据生成过程独立绘制的 $ d $ 。但是，给定序列内的元素可能表现出内部依赖性，例如时间相关性，自回归结构或远距离依赖性。
问题：

在现代序列模型的背景下，尤其是基于RNN的体系结构，例如LSTMS和SEQ2SEQ模型 - 可以经典的I.I.D.每个样品之​​间的假设 有意义地扩展到此设置，其中每个训练样本都是独立于固定DGP生成的依赖序列？

这种结构在实践中很常见 - 例如，在机器翻译，时间序列预测或顺序决策中 - 在其中对模型进行了序列的培训，并有望在每个序列中捕获复杂的内部动力学。
A related discussion here mentions that models like LSTMs can learn long-term, nonlinear dependencies and may even adapt to non-stationarity.但是，该讨论更具经验性，我有兴趣了解古典理论框架（例如，基于I.I.D.假设的学习理论）适用或在这种情况下自然扩展。
任何理论见解，直觉或参考都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/663978/do-i-i-d-assumptions-extend-to-datasets-of-independently-generated-sequences-in</guid>
      <pubDate>Sat, 12 Apr 2025 11:22:00 GMT</pubDate>
    </item>
    <item>
      <title>解释多个日志线性回归系数</title>
      <link>https://stats.stackexchange.com/questions/663968/interpretation-of-multiple-log-linear-regression-coefficients</link>
      <description><![CDATA[我正在对市场上的消费者行为进行研究。由于分析，获得了以下回归方程：
Ln(Sales) = 4,688 - 0,072Cat_Sel_Rat + 0,811Discount – 0,339Ln(Price) + 0,134Ln(Rew_Photo) + 0,005Photos + 0,164Rew_Video – 0,172Sign + 0,086Valance_Cat + 0,086Video
在哪里：
LN（销售）=销售数量的对数
cat_sel_rat =卖方的类别取决于评分（低，中，高）
折扣=折扣金额
ln（价格）=价格的对数
ln（rew_photo）=与照片的评论数量的对数
照片=产品配置文件中的照片数量
rew_video =视频在评论中的存在
标志=销售的可用性
valance_cat =产品等级类别，具体取决于评级（低，中，高）
视频=产品配置文件中的视频存在
我怀疑我正确解释了系数。例如，我这样做。当卖方的评级转移到更高的类别（例如，从低至中等），销售数量，所有其他情况相同，平均下降约为7.27％。随着折扣增加1个单位，所有其他情况相同的销售量增加了约81.15％。当价格上涨1％时，销售数量（所有其他情况）相同，平均下降约为0.34％。随着照片的评论数量增加了1％，其他所有情况相同的销售量平均增加了约0.13％。]]></description>
      <guid>https://stats.stackexchange.com/questions/663968/interpretation-of-multiple-log-linear-regression-coefficients</guid>
      <pubDate>Sat, 12 Apr 2025 10:47:41 GMT</pubDate>
    </item>
    <item>
      <title>在Egarch过程中时刻的实际存在条件是什么？</title>
      <link>https://stats.stackexchange.com/questions/663967/what-is-the-actual-existence-condition-for-moments-in-the-egarch-process</link>
      <description><![CDATA[我遇到了 $ m $   -  th-th-ther级无条件矩 $ \ epsilon_t $ 在Egarch进程中定义为Egarch进程的不同存在条件
 $$ \ epsilon_t = \ sigma_t \ eta_t $$   $$ \ eta_t \ eta_t \ sim iid（0,1）
 $$
\ ln（\ sigma_t^2）= \ omega + \ sum_ {i = 1}^{q} \ alpha_ {i} [\ theta \ eta_ {t-i}+\ gamma（| \ eta_ {t-i} | -e | -e | \ eta_ {t-i} |）] 
$$ 
通常， $ \ eta_ {t} $ 需要使 $ m $   -  ther-ther-tord-dord-ordor monk。但是，尽管Teräsvirta（2009）以及Massimo和Manuela（2018）指出，必要和足够的条件是 $ \ sum_ {J = 1}^{p}^{p} \ beta_ { class =“ Math-Container”&gt; $ \ sum_ {j = 1}^{p} \ beta_ {j}＆lt; 1 $ 。显然，这两种条件都可以根据参数值带来广泛不同的结果。因为 $ \ sum_ {j = 1}^{p} \ beta_ {j}＆lt; 1 $ 应确保 $ \ epsilon_t $ ， $ \ epsilon_t $ 如果存在 $ m $  -th订单时刻，则应关注。对于此处考虑的Egarch模型，应该足够的是， $ \ eta_ {t} $ 具有有限的 $ m $  $ m $  -th-dord-dord-dorder mist。因此，第二个条件似乎很简单。显然，第一个条件建立在功率序列扩展中系数的正方形符号性， $ \ alpha（z）/（1- \ beta（z））$ ， $ \ alpha（z）= alpha（z）= \ sum _ = \ sum _} z^i $ 和 $ \ beta（z）= \ sum_ {i = 1}^{p} \ beta_ {i} z^i $ 。有人可以澄清这个问题吗？
参考：
 He，Changli（2000）。矩和指数GARCH（P，Q）过程的自相关结构。
 Massimo，Guidolin和Manuela，Pedio（2018）。财务应用的时间序列。
teräsvirta，蒂莫（2009）。单变量GARCH模型的简介
 Zivot，Eric（2009）。分析单变量GARCH模型的实际问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/663967/what-is-the-actual-existence-condition-for-moments-in-the-egarch-process</guid>
      <pubDate>Sat, 12 Apr 2025 10:45:39 GMT</pubDate>
    </item>
    <item>
      <title>对训练模型的可靠评估比启发式政策需要更多的发作</title>
      <link>https://stats.stackexchange.com/questions/663963/credible-evaluation-of-trained-model-needs-far-more-episodes-than-heuristic-poli</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/663963/credible-evaluation-of-trained-model-needs-far-more-episodes-than-heuristic-poli</guid>
      <pubDate>Sat, 12 Apr 2025 09:28:30 GMT</pubDate>
    </item>
    <item>
      <title>RCT中的基线随机化如何解决随着时变的混杂因素的潜在偏差？</title>
      <link>https://stats.stackexchange.com/questions/663924/how-does-baseline-randomisation-in-an-rct-address-potential-bias-from-time-varyi</link>
      <description><![CDATA[在RCT测量随着时间的时间的测量结果（例如1年）的情况下，外部因素（潜在的时间变化混杂因素）可能会在随机分组后出现。 
我的理解是，基线随机化使一开始平均等效的治疗组和对照组，包括未观察到的因素，这些因素可能影响可能影响这些未来时间变化的因素的易感性或反应。因此，即使出现了这些因素，比较群体之间的结果差异仍然可以产生平均治疗效果（ATE）的公正估计，假设管理诸如差异损耗之类的问题。本质上，在基线时概率地处理了时变混杂的潜力。
专家可以在这里确认对随机化如何解释随机化后时间变化的因素是否正确的理解是正确的吗？具体：

 确实否定了明确建模或
调整在试验期间出现和不同的因素，提供
它们是外部冲击，不是直接由治疗引起的
差异（影响对治疗的反应除外）？

 基于这种鲁棒性的关键假设是什么
在RCT框架中反对时变的混杂？

]]></description>
      <guid>https://stats.stackexchange.com/questions/663924/how-does-baseline-randomisation-in-an-rct-address-potential-bias-from-time-varyi</guid>
      <pubDate>Fri, 11 Apr 2025 20:18:11 GMT</pubDate>
    </item>
    <item>
      <title>为什么，在进行假设检验时，我们是否考虑概率P（示出null的样本证据）而不是P（null给出的样本证据）？</title>
      <link>https://stats.stackexchange.com/questions/663922/why-when-conducting-a-hypothesis-testing-do-we-consider-the-probability-psamp</link>
      <description><![CDATA[我们知道，通常，条件概率p（a | b）和p（b | a）并不相等，也不能立即从另一个中推导。
为什么，为什么我们是否通过发现获得样本证据（或更极端）的概率进行假设检验，因为零假设是正确的，而实际上我们实际上假设是正确的是样本证据本身，而我们不知道无效。  
我确实知道我们的目标不是证明无效的，因为我们只是试图反驳或不反驳它，所以这种区别不是我问题的本质。
我认为，作为试图回答我自己的问题的一种尝试，如果我们假设样本证据是正确的，那么进行分析要困难得多，因为人口分布并不集中在样本证据中。
感谢您的任何见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/663922/why-when-conducting-a-hypothesis-testing-do-we-consider-the-probability-psamp</guid>
      <pubDate>Fri, 11 Apr 2025 19:01:08 GMT</pubDate>
    </item>
    <item>
      <title>*描述性 *建模的可变选择策略</title>
      <link>https://stats.stackexchange.com/questions/663882/variable-selection-strategy-for-descriptive-modeling</link>
      <description><![CDATA[我目前正在使用两个描述性 COX模型。目的是确定与接触不同治疗的两名患者同类群体中与结果相关的变量。最初的模型具有专家推荐的30个变量（重要的患者特征和可能与结果相关的变量）。最后，某些变量与结果没有显着相关。这可能是一个有趣的结果。
来自shmueli的论文此页面）

 [描述性建模]旨在以紧凑的方式汇总或表示数据结构。与解释性建模不同，在描述性建模中，对基本因果理论的依赖是不存在的，或以较不正式的方式纳入。 （...）拟合回归模型，如果用于捕获因变量和自变量之间的关联而不是因果推理或预测。

考虑到这个目标，我想知道我是否完全需要变量选择？

如果是，您能建议制定策略吗？ DAG似乎是因果推论的共识，但这不是我的目标，因此我不确定这是否有意义。我不想依靠自动模型选择。
如果否，我是否可以引用有信誉的来源？

此外，我认为在这两个模型中具有相同的变量都将更容易进行解释/比较（而不是统计意义）。这有意义吗？
 this 相关问题不关注描述性建模。]]></description>
      <guid>https://stats.stackexchange.com/questions/663882/variable-selection-strategy-for-descriptive-modeling</guid>
      <pubDate>Fri, 11 Apr 2025 10:46:06 GMT</pubDate>
    </item>
    <item>
      <title>泊松二项式变量的极限除以试验数</title>
      <link>https://stats.stackexchange.com/questions/663831/limit-of-a-poisson-binomial-variable-divided-by-the-number-of-trials</link>
      <description><![CDATA[说有 $ n $ 贷款，其中每个贷款 $ j $ 具有 $ p_j $ 的1年默认概率。假设贷款违约是彼此独立的。然后，我们知道默认值 $ s_n $ 遵循Poisson二项式分布。我对默认的部分 $ s_n/n $ 当 $ n $ 转到无限时。是否有 $ \ lim_ {n \ rightarrow \ infty} s_n/n $ ？的闭合形式分布]]></description>
      <guid>https://stats.stackexchange.com/questions/663831/limit-of-a-poisson-binomial-variable-divided-by-the-number-of-trials</guid>
      <pubDate>Thu, 10 Apr 2025 20:26:47 GMT</pubDate>
    </item>
    <item>
      <title>确定模型中的滞后？</title>
      <link>https://stats.stackexchange.com/questions/663824/determining-lags-in-model</link>
      <description><![CDATA[我正在与乡村假人一起运行一个合并的OLS，以查看HC是否对FDI的吸收有影响。 1970- 2019年的2个国家 /地区。但是，我面临模型中滞后的问题。我想滞后外国直接投资和HC（外国直接投资），但是我的第一个HC滞后引入了高于100以上的高度共线性。因此，我决定将其排除在模型之外。但是，当我包含FDI的滞后时，最多3个滞后，多重共线性约为10，并且由于完美的共线性而省略了滞后3，并且再次存在自相关。因此，我决定摆脱滞后1和2的模型，仅包括滞后3。
这似乎摆脱了自相关和多重共线性的模型！此外，我想提一下，我没有与假人相互作用，因为当我这样做时，我有非常重要的自相关问题。
尽管该模型不包含前2个滞后？现在可以使用该模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/663824/determining-lags-in-model</guid>
      <pubDate>Thu, 10 Apr 2025 16:52:56 GMT</pubDate>
    </item>
    <item>
      <title>分类的几何平均值计算</title>
      <link>https://stats.stackexchange.com/questions/663800/calculation-of-geometric-mean-for-classification</link>
      <description><![CDATA[考虑二进制分类，几何均值定义为 $ \ sqrt {\ text {precision} \ times} \ times \ text {recember}} = \ sqrt {\ sqrt {\ frac {\ frac {tp} {tp+fp} { } $ 。但是可以有不同的TP/FP/FN值。例如，对于SVM，有一个ROC曲线，ROC曲线上的不同点具有不同的TP/FP/FN值。因此，我的问题是我们应该使用哪个TP/FP/FN值来计算几何平均值？或者我们应该计算ROC曲线上的所有可能的几何平均值并获得平均几何值？]]></description>
      <guid>https://stats.stackexchange.com/questions/663800/calculation-of-geometric-mean-for-classification</guid>
      <pubDate>Thu, 10 Apr 2025 10:19:24 GMT</pubDate>
    </item>
    <item>
      <title>建模响应是可能审查值的总和</title>
      <link>https://stats.stackexchange.com/questions/663795/modelling-a-response-that-is-the-sum-of-possibly-censored-values</link>
      <description><![CDATA[一些同事的套件约有10个变量，代表样本中的化合物。某些变量中的某些值将被审查，低于所使用的实验室过程的检测极限。虽然主要的重点是建模如何单独地在不同处理下随着时间的流逝而单独进行一些变量，但我的同事们现在想要每个观察中这10个变量的总和的模型，我将在此处称为 total 。。
我知道估计平均值时审查数据的问题，我们一直在使用零增强的伽马模型和TOBIT模型作为单独建模主要响应变量的手段。。
但是，我不确定如何进行建模 total 响应，因为我不确定人们甚至首先要计算总和。从生物学上讲，这些以下检测极限值并没有真正增加我们具有一些审查值的样本中的总数。将这些值视为零会导致相同的偏差和不一致问题，以替代估算值的估计值的审查值？
是否有任何既定方法来处理此类数据？例如，我们可以以某种方式将这些审查的观测值的值算，然后在模型中使用这些值。我忽略了这样的问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663795/modelling-a-response-that-is-the-sum-of-possibly-censored-values</guid>
      <pubDate>Thu, 10 Apr 2025 07:48:58 GMT</pubDate>
    </item>
    <item>
      <title>为了表征人口的比例，第一个已知的示例是什么？</title>
      <link>https://stats.stackexchange.com/questions/663769/what-is-the-first-known-example-of-a-proportion-being-calculated-to-characterize</link>
      <description><![CDATA[标题或多或少会钉上它。当第一个基于某种数据收集的人口比例（又名患病率）的第一个记录使用人口比例（又称患病率）时，我真的很感兴趣。我想这可能是非常非常旧的（例如，来自古代美索不达米亚或次大陆的某个地方，也许是中国），但是如果只是几个世纪前出现的第一个记录的例子就不会感到惊讶。&gt; 。
可能是生病，拥有马的人口的比例。由“人口”我的意思是，人类的民众在城市国家，军队，王国，国家等的规模上]]></description>
      <guid>https://stats.stackexchange.com/questions/663769/what-is-the-first-known-example-of-a-proportion-being-calculated-to-characterize</guid>
      <pubDate>Wed, 09 Apr 2025 18:46:13 GMT</pubDate>
    </item>
    <item>
      <title>使用乘以数据的模型性能</title>
      <link>https://stats.stackexchange.com/questions/619994/model-performance-with-multiply-imputed-data</link>
      <description><![CDATA[我想知道如何使用Hosmer-lemeshow测试进行校准图，并在R中多次插入R后进行ROC曲线AUC。
我还尝试了PSFMI软件包中的pool_performance函数，但显示了以下错误。
  cut.default中的错误（pred，notile（pred，c（seq（0，1，1，1/groups_cal）））））： 
  “休息”不是唯一的
 
您能告诉我是否可以使用此功能用于模型性能，并使用乘以估算的数据集，否则R代码和示例更好？]]></description>
      <guid>https://stats.stackexchange.com/questions/619994/model-performance-with-multiply-imputed-data</guid>
      <pubDate>Wed, 28 Jun 2023 13:27:31 GMT</pubDate>
    </item>
    <item>
      <title>基于R函数的重复度量的非结构化模型与随机斜率模型LMER，LME和GLS</title>
      <link>https://stats.stackexchange.com/questions/616155/unstructured-model-vs-random-slope-model-for-repeated-measures-based-on-r-functi</link>
      <description><![CDATA[这是重复度量的数据集：
 库（LME4）
图书馆（NLME）

d = read.delim（&#39;http：//dnett.github.io/s510/repeatedmeasures.txt&quot;）
d  $ program = factor（d $  program）
d  $ subj = factor（d $  subj）
d  $ timef =因子（d $ 时间）
 
我已经使用GLS函数构建了一个非结构化模型，我正在尝试使用R函数拟合的随机斜率（或随机斜率 +截距）模型来重现结果，该模型由R函数LMER或LME拟合。这是代码和输出：
 GLS功能：
 ＆gt; d.gls＆lt;  -  gls（强度〜程序 * timef，data = d，
+相关= corsymm（form = 〜1 | subj），，
+重量= Varident（form = 〜1 | timef））
＆gt; getVarcov（d.gls）
边际差异协方差矩阵
       [，1] [，2] [，3] [，4] [，5] [，6] [，7]
[1，] 8.7801 8.7571 8.9656 8.1984 8.6781 8.2203 8.4169
[2，] 8.7571 9.4730 9.4631 8.5686 9.2012 8.7307 8.6875
[3，] 8.9656 9.4631 10.7080 9.9266 10.6660 10.0700 10.2140
[4，] 8.1984 8.5686 9.9266 10.0770 10.6000 9.8987 10.0430
[5，] 8.6781 9.2012 10.6660 10.6000 12.0950 11.3440 11.3640
[6，] 8.2203 8.7307 10.0700 9.8987 11.3440 11.7560 11.6500
[7，] 8.4169 8.6875 10.2140 10.0430 11.3640 11.6500 12.7100
  标准偏差：2.9631 3.0778 3.2723 3.1745 3.4778 3.4287 3.5651 
＆gt; loglik（d.gls）
“ log lik。” -617.4479（DF = 49）
 
 lmer函数：
 ＆gt; d.lm＆lt;  -  lmer（强度〜程序 * timef +（0 +timef | subj），d，control = lmercontrol（check.nobs.vs.vs.nre =＆quort =; nighore;
    警告消息：
    在CheckConv（attr（opt，opt，&#39;derivs; quot;），opt  $ par，ctrl = control $  checkconv，：
      模型无法与Max | Grad |收敛= 0.00271822（TOL = 0.002，组件1）
    ＆gt; #varcorr（d.lm）
    ＆gt; as.matrix（matrix :: bdiag（varcorr（d.lm））））
              TimeF2 TimeF4 TimeF6 TimeF8 TimeF8 TimeF10 TimeF12 TimeF14
    TimeF2 8.534639 8.756711 8.965454 8.198261 8.677920 8.220413 8.416961
    TimeF4 8.756711 9.227384 9.462754 8.568308 9.201094 8.730927 8.687653
    TimeF6 8.965454 9.462754 10.462654 9.926419 10.665922 10.070205 10.213872
    TimeF8 8.198261 8.568308 9.926419 9.832025 10.599504 9.898893 10.043531
    TimeF10 8.677920 9.201094 10.665922 10.599504 11.849795 11.344650 11.364012
    TimeF12 8.220413 8.730927 10.070205 9.898893 11.344650 11.511176 11.650515
    TimeF14 8.416961 8.687653 10.213872 10.043531 11.364012 11.650515 12.465186
    ＆gt; loglik（d.lm）
    “ log lik。” -617.4479（DF = 50）
 
 LME功能超级慢，无法收敛。我的问题是：

考虑到GLS功能不会产生警告，而LMER功能确实可以相信GLS结果而不是LMER结果？
 GLS和LMER的两个模型是否是相同的非结构化模型？如果没有，为什么它们的日志可能性是相同的（-617）？如果是，为什么差异估计是不同的？
是否可以使用LME/LMER函数重现GLS非结构化模型？

 更新
我能够通过 lme（）通过不同的优化器“：”生成结果。
 ＆gt; d.lme＆lt;  -  lme（强度〜程序 * timef，随机=〜-1+timef | subj，d，control = lmecontrol（maxiter = 50，msmaxiter = 50，msverbose = true，opt opt =&#39;opt =&#39;opt =&#39;opt =&#39;opt =&#39;opt =&#39;opt&#39;））
初始值1202.821021 
迭代10值1202.809062
迭代20值1202.789065
最终值1202.784342 
融合
＆gt; #varcorr（d.lme）
＆gt; getVarcov（d.lme）
随机效应方差协方差矩阵
        TimeF2 TimeF4 TimeF6 TimeF8 TimeF8 TimeF10 TimeF12 TimeF14
TimeF2 8.5759 8.7549 8.9628 8.1949 8.6764 8.2180 8.4140
TimeF4 8.7549 9.2691 9.4601 8.5649 9.1991 8.7284 8.6841
TimeF6 8.9628 9.4601 10.5030 9.9229 10.6630 10.0680 10.2100
TimeF8 8.1949 8.5649 9.9229 9.8725 10.5970 9.8965 10.0400
TimeF10 8.6764 9.1991 10.6630 10.5970 11.8910 11.3420 11.3600
TimeF12 8.2180 8.7284 10.0680 9.8965 11.3420 11.5510 11.6480
TimeF14 8.4140 8.6841 10.2100 10.0400 11.3600 11.6480 12.5060
  标准偏差：2.9285 3.0445 3.2408 3.1421 3.4483 3.3987 3.5363 
＆gt; loglik（d.lme）
“ log lik。” -617.4481（DF = 50）
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/616155/unstructured-model-vs-random-slope-model-for-repeated-measures-based-on-r-functi</guid>
      <pubDate>Wed, 17 May 2023 17:33:19 GMT</pubDate>
    </item>
    <item>
      <title>重复的高参数调整是否会导致过度拟合？</title>
      <link>https://stats.stackexchange.com/questions/611690/is-repeated-hyperparameter-tuning-can-lead-to-overfitting</link>
      <description><![CDATA[我正在为分类器执行超参数调整。完成后，我正在更新超参数搜索空间，并再次重新调整超参数。我重复几次这个过程。除了用于高参数优化的验证集外，我还使用单独的测试集进行最终评估。
这是一个好方法，还是会导致过度拟合？
我要求使用一般案例，而不是我的私人情况，但是我的超参数调整方法是Optuna，分类器是catboost。另外，在每个Optuna迭代中，安装catboost时，我在同一验证集上使用早期停止。
相关代码附加在下面。
  def目标（自我试验）：
                
        参数，p = get_catboost_params（试用，self.categorical_features）
        clf = catboostClassifier（verbose = 200，Random_seed = 42，eval_metric =&#39;auc&#39;，auto_class_weights =&#39;balanced&#39;，** params）
        clf.fit（self.x_train，self.y_train，eval_set =（self.x_val，self.y_val），fround_stopping_rounds = p，cat_features = self.categorical_features）
        y_val_prob = clf.predict_proba（self.x_val）[：，1]
        auc_score = roc_auc_score（self.y_val，y_val_prob）
                  
        返回auc_score

 def Optimize_hyperParameters（self）：

        研究= optuna.create_study（方向=“最大化”）
        study.ptimize（self.Objective，n_trials = self.n_trials）
        self.best_params = study.best_params
        afirs_params = self.get_trial_params（研究）
        trials_params.to_csv（“ optuna_result.csv”）
     
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/611690/is-repeated-hyperparameter-tuning-can-lead-to-overfitting</guid>
      <pubDate>Mon, 03 Apr 2023 15:25:42 GMT</pubDate>
    </item>
    </channel>
</rss>