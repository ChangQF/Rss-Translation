<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 19 Aug 2024 15:16:48 GMT</lastBuildDate>
    <item>
      <title>为什么 R 或 Eviews 中的 arima() 无法为 ARMA(1,1) 提供准确的 ML 估计量？为什么我的代码可以给出更好的估计？</title>
      <link>https://stats.stackexchange.com/questions/653013/why-arima-in-r-or-eviews-cant-provide-accurate-ml-estimators-for-an-arma1-1</link>
      <description><![CDATA[我模拟了一个遵循 ARMA(1,1) 模型的时间序列，具体来说就是 y(t)=2+0.8y(t-1)+e(t)-0.4e(t-1)。我根据精确似然函数编写了一些代码来执行最大似然估计 (MLE)。代码如下
library(numDeriv)
#生成一个时间序列
n &lt;- 50
set.seed(123)
epsilon=rnorm(n,0,1)
y=c(1:n)

for(i in 2:n)
{
y[i]=2+0.8*y[i-1]+epsilon[i]-0.4*epsilon[i-1]
}
#--------------------------------------------------------

llk &lt;- function(miu,alpha,beta,sigma2){
mean = miu /(1-alpha)
sigma_total = (1 + (alpha+beta)^2/(1-alpha)) * sigma2 #方差
log_likelihood &lt;- sum(dnorm(y, mean, sigma_total, log = TRUE)) 
return(-log_likelihood)
}

library(bbmle)
lower_bounds &lt;- c(miu = -Inf, alpha = -1, beta = -1, sigma2 = 0)
fit_norm &lt;- mle2(llk, start = list(miu=0.1,alpha=0.1,beta=-0.1,sigma2=0.25)
summary(fit_norm)

运行结果为：
系数：
估计标准误差z值Pr(z) 
miu 2.4832e+00 1.2019e+00 2.0661 0.03882 * 
alpha 7.2875e-01 1.2790e-01 5.6977 1.214e-08 ***
beta -9.0982e-05 2.3149e-01 -0.0004 0.99969 
sigma2 1.4708e+00 1.4708e-01 9.9998 &lt; 2.2e-16 ***

然而，当我使用 R 或 Eviews 中的 arima() 函数估算模型时，我注意到：（1）从两个软件包获得的结果之间有细微的差异。但我自己的结果和软件的结果之间存在显着差异。（2）与从软件获得的估计值相比，我的 MLE 估计更接近真实参数。“
为什么？
R 的结果是
arma_model&lt;-arima(y,order=c(1,0,1))
arma_model$coef
ar1 ma1 截距 
0.9493775 -0.1092253 7.7225015 

Eviews 的结果是
 变量系数 
C 7.513484
AR(1) 0.968957
MA(1) -0.199021
SIGMASQ 1.326798
]]></description>
      <guid>https://stats.stackexchange.com/questions/653013/why-arima-in-r-or-eviews-cant-provide-accurate-ml-estimators-for-an-arma1-1</guid>
      <pubDate>Mon, 19 Aug 2024 14:33:18 GMT</pubDate>
    </item>
    <item>
      <title>纪元 (epoch) 与数据复制相同吗？</title>
      <link>https://stats.stackexchange.com/questions/653012/are-epochs-the-same-as-data-duplication</link>
      <description><![CDATA[时期，即对原始数据重复训练的次数，对于神经网络来说是绝对必要的，因为神经网络的参数通常比原始实例多得多。
对于具有许多参数的其他 ML 方法，使用时期的方法论地位是什么？它们是否用于（我称之为）类技术，如随机森林？通过“方法论地位”，我隐藏了我的真实意图。也就是说，为什么不将时期用于普通的逻辑回归或决策树？为什么不将每个额外的时期视为数据增强，但使用相同的实例？如果建议重复数据以减少偏差，我觉得任何统计学家都会感到恶心。 ML 建模者会毫不犹豫地无限期地增加 epoch，直到训练/测试准确率开始变差（甚至可能到那时也不会变差！）。
那么

在传统预测模型中使用 epoch（基本重复实例）可以吗（只要考虑到过度拟合）？
另一方面，一个 epoch 是否应该成为 NN 训练的标准，或者更确切地说，将重复数据作为增强技术是否存在各种统计问题？

注意：这可能是一个很难回答的问题，因为它需要了解两种不同文化中的原理，即统计学和机器学习中的原理，即使它们本质上在做同样的事情。]]></description>
      <guid>https://stats.stackexchange.com/questions/653012/are-epochs-the-same-as-data-duplication</guid>
      <pubDate>Mon, 19 Aug 2024 14:12:29 GMT</pubDate>
    </item>
    <item>
      <title>回归中的独立指标变量在改变类别数量时变得显著</title>
      <link>https://stats.stackexchange.com/questions/653011/independent-indicator-variable-in-regression-becomes-significant-when-changing-t</link>
      <description><![CDATA[我正在使用二元响应变量运行逻辑回归。无论我是否使用家庭作为指示变量，家庭规模都会产生微小的正向但不显著的影响。
当将家庭规模视为具有 3 个级别的分类变量（单户、中型或大型家庭）来检查其是否有影响时，与排除的类别（单户）相比，两个包含的虚拟变量都具有很强的显著性和正向性。为什么会这样？
假设不仅家庭规模会对结果产生积极影响，而且家庭规模也会产生积极影响。我也将家庭规模视为分类变量，因为它在数据集中只能采用 7 个不同的值。
（我有大量观察值和其他预测因子。）
非常感谢您的帮助，br]]></description>
      <guid>https://stats.stackexchange.com/questions/653011/independent-indicator-variable-in-regression-becomes-significant-when-changing-t</guid>
      <pubDate>Mon, 19 Aug 2024 13:47:05 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测</title>
      <link>https://stats.stackexchange.com/questions/653008/time-series-forecast</link>
      <description><![CDATA[我一直想向预测领域的专家询问一个关于我正在进行的预测项目的迫切问题。我正在建立一个模型来预测地下水厚度，任务是使用地表温度、降水等外生变量。鉴于使用季节和日历特征作为外生变量在预测范围内始终可用，但地表温度、降水等外生变量则不可用。我是否必须递归预测地表温度和降水等外生变量，然后才能继续预测地下水厚度？我非常感谢您的意见。期待很快收到您的来信。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/653008/time-series-forecast</guid>
      <pubDate>Mon, 19 Aug 2024 11:53:55 GMT</pubDate>
    </item>
    <item>
      <title>计算缺失值数据的趋势</title>
      <link>https://stats.stackexchange.com/questions/653006/computing-trends-on-data-with-missing-value</link>
      <description><![CDATA[我正在收集一些用户的反馈。无法保证所有用户都会提供反馈。因此，在每个时间段内，都会有很多没有反馈值的反馈表。
我想确定通过表单收集的反馈值的趋势和异常值。考虑到大部分数据缺失，计算它们的最佳方法是什么。
缺失值影响问题的方式之一是“坏”或“好”反馈数量的减少并不一定意味着反馈发生变化。回复表单的人数可能较少。在这种情况下，我该如何处理缺失数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/653006/computing-trends-on-data-with-missing-value</guid>
      <pubDate>Mon, 19 Aug 2024 11:22:57 GMT</pubDate>
    </item>
    <item>
      <title>包含一些随机和固定效应因素的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/653005/linear-mixed-models-with-some-factors-included-as-both-random-and-fixed-effects</link>
      <description><![CDATA[我目前正在分析一项实地试验的数据，该试验最初设计用于双向方差分析。该试验涉及两个因素——土壤（2 个级别）和植物（2 个级别），在区块设计中重复 6 次。该试验包括三个采样时间和两个土壤深度的数据。
考虑到随时间和不同深度重复测量，我担心双向方差分析所需的独立性假设。虽然对每个采样和深度进行单独的双向方差分析是一种选择，但它会导致统计能力的损失，并阻碍不同采样和深度之间的交叉比较，这对我的研究至关重要。
为了应对这些挑战，我正在考虑使用具有以下结构的线性混合模型：
soil_carbon ~ (SOILPLANTDEPTH*TIME) + (1|BLOCK) + (1|PLOT) + (1|PLOT:SAMPLING) + (1|PLOT:DEPTH)
模型说明：
(SOILPLANTDEPTH*TIME)：该术语表示研究的固定效应之间的相互作用。
(1|BLOCK)：阻塞的随机效应
1|PLOT)：不同地块的随机效应
(1|PLOT:SAMPLING)：嵌套在 PLOT 中的 SAMPLING。考虑到采样总是在同一图中完成的事实。
（1|PLOT:DEPTH）：PLOT 内嵌套的 DEPTH。考虑到每个图中采样的深度不同。
具体问题：
a) 鉴于随机效应中的 SAMPLING 和 DEPTH 嵌套在 PLOT 内，这些因素是否也可以作为固定效应包含在模型中？我的目标是比较不同级别的深度和采样。它们应该同时包含在随机效应和固定效应中，还是只包含在随机效应中？
b) 为了检验固定效应的显著性，我正在考虑使用似然比检验来简化模型。这种方法适用于线性混合模型吗？
如果您对分析这些数据有任何其他建议或推荐，我将非常感谢您的见解。
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/653005/linear-mixed-models-with-some-factors-included-as-both-random-and-fixed-effects</guid>
      <pubDate>Mon, 19 Aug 2024 11:21:13 GMT</pubDate>
    </item>
    <item>
      <title>使用通过降维变换观察到的样本计算或从后验中进行采样</title>
      <link>https://stats.stackexchange.com/questions/653004/computing-or-sampling-from-a-posterior-with-samples-observed-through-a-dimension</link>
      <description><![CDATA[设 $\boldsymbol \theta$ 为参数向量，已知先验 $\pi(\boldsymbol \theta)$。
设 $\boldsymbol x_1,...,\boldsymbol x_n$ 为 i.i.d. 样本，已知 $\boldsymbol x|\boldsymbol \theta$。
问题是我们观察的不是 $\boldsymbol x_i$，而是 $\boldsymbol g(\boldsymbol x_i)$。这里$\boldsymbol g$是一个降维变换。如何用数值方法计算后验$\pi(\boldsymbol \theta | \boldsymbol g(\boldsymbol x_1),...,g(\boldsymbol x_n))$或高效地从中采样？
这里有一个简单的例子。对于一个矩形，宽度$w\sim {\rm Uniform}(0, a)$和长度$l\sim {\rm Uniform}(0,b)$，并且$(a,b)$遵循已知的先验。
但是我们无法观察到$(w,l)$。相反，我们可以观察面积$s = w\cdot l$。
如何用数字方式计算后验$\pi(a,b|s)$或从中抽样？]]></description>
      <guid>https://stats.stackexchange.com/questions/653004/computing-or-sampling-from-a-posterior-with-samples-observed-through-a-dimension</guid>
      <pubDate>Mon, 19 Aug 2024 10:18:07 GMT</pubDate>
    </item>
    <item>
      <title>平均预测和边际效应相互作用之间的差异</title>
      <link>https://stats.stackexchange.com/questions/652978/difference-between-average-predictions-and-interactions-in-marginal-effects</link>
      <description><![CDATA[我有一个固定效应模型，其中我对分类变量随时间变化的边际效应感兴趣。以下是一个示例，说明我正在做什么：
library(fixest)
library(marginaleffects)
library(ggplot2)

# 设置可重复性的种子
set.seed(123)

# 观察次数
n &lt;- 500 # 10 个时间点，每个时间点 50 次观察

# 模拟数据
data &lt;- data.frame(
ID = 1:n,
Time = factor(rep(1:10, each = 50)), # 10 个时间点，每个时间点 50 次观察
Category = factor(rep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), length.out = n)), # 3 级分类独立变量
Control1 = rnorm(n, mean = 50, sd = 10), # 具有一定变化的连续控制变量
Control2 = sample(0:1, n, replace = TRUE) # 具有随机分配的二元控制变量
)

# 二元结果变量，设计为随类别和时间变化
data$Outcome &lt;- rbinom(n, 1, prob = plogis(0.5 + 0.3 * as.numeric(data$Category) - 0.2 * as.numeric(data$Time) + 0.05 * data$Control1 - 0.1 * data$Control2))

# 使用固定效应拟合模型
model &lt;- feglm(
Outcome ~ Category + Control1 + Control2 |时间，
数据 = 数据，
家庭 = 二项式 (&quot;logit&quot;)
)

# 模型摘要
summary(model)

# 按类别和时间获取平均预测
预测 &lt;- avg_predictions(model, by = c(&quot;类别&quot;, &quot;时间&quot;))

# 显示预测
print(predictions)

# 绘制带有置信区间的预测
ggplot(predictions, aes(x = 时间, y = 估计, 颜色 = 类别, 组 = 类别)) +
geom_line(size = 1) +
geom_point(size = 2) +
geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = 类别), alpha = 0.2, 颜色 = NA) +
labs(title = &quot;按类别随时间变化的预测概率&quot;,
x = &quot;时间&quot;,
y = &quot;预测概率&quot;) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))

我有两个问题：

绘制类别变量在时间变量值上的边际效应与将每个时间变量与每个类别交互并绘制这些交互的边际效应之间有什么区别？我理解包括交互会假设效果可能会受到时间的影响，但如果数据表明如此，边际效应方法不会显示相同的结果吗？例如，如果时间 =3 类别 A 的结果可能性明显高于基线，即使没有交互项，这也可能会反映在数据中，对吗？
无论是否添加交互项（类别*时间），逐步分析每个类别的时间条件效应的正确方法是什么？例如，如果我想确定时间 =3、类别 A、时间=4、类别= A、时间= 5、类别的值，以与上一次相比估计的变化为准
]]></description>
      <guid>https://stats.stackexchange.com/questions/652978/difference-between-average-predictions-and-interactions-in-marginal-effects</guid>
      <pubDate>Sun, 18 Aug 2024 16:47:17 GMT</pubDate>
    </item>
    <item>
      <title>如果获得的样本量比功效分析中显示的大得多，该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</link>
      <description><![CDATA[老实说，我们没想到这一点——毕竟我们一切都是按照剧本做的。
我们计划对一些心理问题进行研究，我们将问卷输入到 Qualtrics，在 G*Power 的帮助下，我们进行了功效分析以获得最小样本量，最后我们在互联网上发布了该研究的链接。然后样本量激增。几天后，我们检查了我们设法收集了多少观察结果，结果发现数量增加了四倍（所以我们匆忙停止收集数据）。功效分析表明 N = 500，我们得到了 N = 2000（当然是 2000 多）。开心吗？不，我们离幸福还很远。
问：现在我们有一个问题，如何处理超大样本（记住超强研究）。
想法是：

在第 500 次观察时截断——丢弃其余数据（听起来像是在浪费数据）
在第 500 次观察时截断，使用其余数据作为复制研究（听起来很狡猾，我们实际上没有进行复制研究，数据来自原始研究）
从我们的大数据（N = 2000）中抽取样本 - 不放回抽样，样本由N = 500 次观察组成（并丢弃休息）。
... 大家还有其他想法吗？你们遇到过这种情况吗？你们做了什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</guid>
      <pubDate>Sun, 18 Aug 2024 14:54:41 GMT</pubDate>
    </item>
    <item>
      <title>IRLS 可以处理不平等约束吗？否则我应该使用什么？</title>
      <link>https://stats.stackexchange.com/questions/652968/can-irls-deal-with-inequallity-constrains-what-should-i-use-otherwise</link>
      <description><![CDATA[我有一组观察到的数据点$p_i = (a_i,b_i)$和一个公共常数$c$。理论上，这些点应该遵循以下方程：
$$a_i = b_i + x_1 + x_2(b_i + c)$$
我的目标是找到最小化误差的最佳$(x_1, x_2)$。 $(x_1, x_2)$ 的值受到以下约束：
$$ -w \leq x_1 \leq w$$
$$-1 \leq x_2 \leq w - 1$$
我尝试制定以下问题：
$$\min_x f(x) = \Sigma_i^{N-1} (a_i - b_i - x_1 - x_2(b_i + c))^2$$
或者
$$\min_x f(x) = \left\|\overrightarrow{\alpha} - x_1 - x_2\overrightarrow{\beta}\right\|_2^2$$
$$S.T. -w \leq x_1 \leq w$$
$$-1 \leq x_2 \leq w - 1$$
我得到的原始解决方案利用了迭代加权最小二乘 (IRLS)，忽略了约束。然而，这给了我们不可行的解决方案。
IRLS 算法是否可以适应不等式约束？否则，这个问题的最佳优化器或回归是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652968/can-irls-deal-with-inequallity-constrains-what-should-i-use-otherwise</guid>
      <pubDate>Sun, 18 Aug 2024 10:43:07 GMT</pubDate>
    </item>
    <item>
      <title>估计未知分布分位数的高置信上限</title>
      <link>https://stats.stackexchange.com/questions/652924/estimating-high-confidence-upper-bound-for-quantile-of-unknown-distribution</link>
      <description><![CDATA[我获得了一个分布未知的随机变量 $\mathbb R$ 上的 $X$。
我想确定获得 X 的 $1-\alpha$ 分位数的高置信上限 $\hat Q_{1-\alpha}$ 所需的最小样本量 $n$。
具体来说，我对高百分位数感兴趣，比如第 95 或第 99 个百分位数。
对于给定的置信水平 $1-\epsilon$，我想确保 $\Pr(\Pr(X&gt;\hat Q_{1-\alpha})&lt;\alpha) \geq 1-\epsilon$，而不管 $X$ 的分布如何。
虽然这个问题看起来很笼统，但我不确定如何使用经典统计方法来解决它。
直观地说，我会从我的样本中估计 $1-\alpha$ 分位数。
使用 bootstrapping 等方法，我也可以获得该参数的置信区间。
但是，我不确定如何根据基础样本的大小$n$准确量化这些方法的不确定性。
我的问题有两个方面。
首先，是否有统计工具可以回答这个问题并根据样本大小估计参数估计器的置信度？我似乎缺乏查找相关信息的统计背景。如果能提供来源或关键字来为我指明正确的方向，我将不胜感激。
其次，我知道这个问题可以用 PAC-Learning 的方法来解决。
但是，尽管这个问题相对普遍，但我也找不到使用这种界限的例子。
我怀疑有更好的工具来回答这个问题，或者这个问题一开始就不是很有趣，因为人们可以简单地假设某种分布，然后使用参数方法。
如果有人能告诉我这两个假设是否正确，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/652924/estimating-high-confidence-upper-bound-for-quantile-of-unknown-distribution</guid>
      <pubDate>Fri, 16 Aug 2024 11:09:53 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用已知范围但未知平均值生成正态分布的变量</title>
      <link>https://stats.stackexchange.com/questions/652807/generating-a-normally-distributed-variable-using-a-known-range-but-an-unknown-m</link>
      <description><![CDATA[我想生成一个具有已知范围（例如 $10.4\text{–}16.6$）但不知道平均值的 100 个数据点的正态分布变量。要使用 rnorm，我需要平均值和标准差。如果我假设它是精确的中点（平均值${} = (10.4 + 16.6) \cdot 0.5 = 13.5).$，我可以估计平均值，并对 sd 进行一些类似的估计（sd${} = (13.5 - 10.4) /2 = 1.55).$，然后我可以使用 rnorm 函数
rnorm (n=100, 平均值 = 13.5, sd = 1.55)

但结果变量的范围超出了我的初始范围 $10.4\text{–}16.6.$，我想看看是否有更好的方法来生成这个变量并强制以保持我预期的范围。]]></description>
      <guid>https://stats.stackexchange.com/questions/652807/generating-a-normally-distributed-variable-using-a-known-range-but-an-unknown-m</guid>
      <pubDate>Wed, 14 Aug 2024 18:22:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么 ARIMA 对相同数据进行预测时，会指出数据在一个预测持续时间内是白噪声，而没有指出它在另一个持续时间内不是白噪声</title>
      <link>https://stats.stackexchange.com/questions/652789/why-arima-on-same-data-says-data-is-white-noise-for-one-forecast-duration-while</link>
      <description><![CDATA[我正在对我的数据运行 ARIMA 模型。我有 2021 年 1 月的每周数据。当我运行 12 周预测时，ARIMA 给出了最佳参数值 (0,0,0)，表明数据是白噪声。但是当我使用相同的数据并运行 8 周的预测时，最佳参数值是 (4,0,4)，这意味着数据不是白噪声。
有人可以告诉我预测持续时间是如何使数据变成白噪声的吗？
所以这就是我进行预测的方式：
数据从 2021 年 1 月到 2024 年 7 月。
训练数据：2021 年 1 月 1 日至 2024 年 2 月 11 日。
测试数据：2024 年 2 月 18 日至 2024 年 5 月 6 日。
我使用以下方法循环遍历大量 p、d、q 值：
params = {
&#39;p&#39; : [0,1,2,3,4,5],
&#39;d&#39; : [0,1,2,3,4,5],
&#39;q&#39; : [0,1,2,3,4,5]
}

for vals in product(*params.values()):
comb = dict(zip(params.vals)

然后我将 comb 传递到执行 ARIMA 的函数中。
完成上述步骤后，我根据测试值与预测值的最低 RMSE 分数选择最佳 p、d、q 值。并将它们传递到未来 12 周的预测中：
现在训练数据：2021 年 1 月 1 日至 2024 年 5 月 13 日
测试数据：2024 年 5 月 13 日至 2024 年 7 月 29 日]]></description>
      <guid>https://stats.stackexchange.com/questions/652789/why-arima-on-same-data-says-data-is-white-noise-for-one-forecast-duration-while</guid>
      <pubDate>Wed, 14 Aug 2024 14:08:01 GMT</pubDate>
    </item>
    <item>
      <title>nlme 交叉随机效应和自回归协方差结构</title>
      <link>https://stats.stackexchange.com/questions/652764/nlme-crossed-random-effects-and-autoregressive-covariance-structure</link>
      <description><![CDATA[我想问您两个具体问题，关于一个模型，其中要考虑交叉随机效应和自回归协方差结构（AR1 --&gt;
因此使用包 nlme 而不是 lme4）。这是基于一项为期 16 周的饲养试验（2x2 因子设计），试验中有 32 头奶牛，每头奶牛有 16 个测量点（每周测量间隔）。

如何在 nlme 中实现两个非嵌套随机效应（在 lme4 中：+ (1|animal) + (1|experimental_week )）？

因为 random = list(one1 = pdMat (~ animal - 1), one2 = pdMat (~experimental_week - 1))，其中 one1 和 one2 是“辅助”变量，为 1（对于每个观察值）？来源：r - 在 lmer 和 nlme:lme 中建模随机结构 - 交叉验证 (stackexchange.com)
或者其他：random = list(animal = pdMat (~1),experimental_week = pdMat (~1)) ?
或者其他？
因此必须选择正确的 pdMat 对象 (pdDiag, pdIdent, ...)。


如何正确解释自回归协方差结构？

correlation = corAR1(0.99, form = ~ 1)
或者 correlation = corAR1(form = ~experimental_week |动物)



目前我有这样的情况：
new_model_1 &lt;- lme(
fixed = ECM ~ Index, 
random = list(Animal = pdDiag(~Animal), experiment_week = pdDiag(~experimental_week)),
data = data1,
correlation = corAR1(0.99, form = ~ 1), na.action = na.omit)
summary(glht(new_model_1,test = adapted(&quot;BH&quot;)))
]]></description>
      <guid>https://stats.stackexchange.com/questions/652764/nlme-crossed-random-effects-and-autoregressive-covariance-structure</guid>
      <pubDate>Wed, 14 Aug 2024 06:23:18 GMT</pubDate>
    </item>
    <item>
      <title>两个样本是否来自同一个二项分布？</title>
      <link>https://stats.stackexchange.com/questions/652524/are-2-samples-from-the-same-binomial-distribution</link>
      <description><![CDATA[我有 2 个从二项分布中抽取的样本。我的零假设是 2 个样本来自同一分布。如何拒绝 p &lt; 0.05 的零假设？
具体案例：

样本 #1：n=5,665,657，k=7
样本 #2：n=7,954,069，k=6

（n 为样本大小，k 为成功次数）
我的问题因重复而被关闭，其中包含指向 3 个已回答问题的链接。这些问题很有帮助，我将总结它们如何部分回答了我最初的问题，以及它们如何没有提供完整的答案。

第一个问题（测试两个二项分布是否在统计上彼此不同）看起来确实与我的非常相似，但观察到的比例接近 0.5，而我的具体情况高度不平衡（即比例接近 0）。我不知道这是否重要。

接受的答案使用 z 检验。


第二个问题（有没有针对没有正态近似的两个二项分布的假设检验？）与我的问题类似，但它假定正态/泊松分布不是好的近似值。我不知道我的情况是否符合这一点。

可接受的答案是使用 Fisher 精确检验，但第二个答案解释说这是一个糟糕的选择（即使有效）。


第三个问题（R 中的精确两个样本比例二项式检验（和一些奇怪的 p 值））与我的类似，但样本量要小得多，观察到的比例接近 0.5。同样，我不确定这是否适合我的情况。

接受的答案支持使用 R 的 prop.test，它利用卡方检验统计量。


在我的问题评论中：

Henry 还建议使用 Barnard 检验。
kjetil 建议使用泊松近似。



我已经尝试了上面提到的所有测试。结果如下：



测试名称
Python
p 值




双尾双比例合并 z 检验
statsmodels.stats.proportion.proportions_ztest
0.370


Fisher 精确检验
scipy.stats.fisher_exact
0.408


卡方测试
scipy.stats.chi2_contingency
0.539


Barnard 测试
scipy.stats.barnard_exact
0.631


E 测试
scipy.stats.poisson_means_test
0.397



我剩下的问题是：这些测试中的哪些是无效的、有效但不是很好，或者在我的案例中可以使用（即样本非常大、非常不平衡）？]]></description>
      <guid>https://stats.stackexchange.com/questions/652524/are-2-samples-from-the-same-binomial-distribution</guid>
      <pubDate>Fri, 09 Aug 2024 08:05:45 GMT</pubDate>
    </item>
    </channel>
</rss>