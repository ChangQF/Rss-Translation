<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Wed, 05 Mar 2025 21:18:28 GMT</lastBuildDate>
    <item>
      <title>如何处理这个非常非正常的响应变量？</title>
      <link>https://stats.stackexchange.com/questions/662239/how-do-i-handle-this-very-non-normal-response-variable</link>
      <description><![CDATA[在R中，我想使用重复的测量分析与混合回归模型分析基于1）周的响应变量（平均蜜蜂授粉得分）的平均值（平均蜜蜂授粉得分）如何基于1）周，2）蜂巢数量，3）杀菌剂剂量，4）4）剂量剂量的昆虫剂 +位置的随机效应。
这是我最初认为写模型的方式：
 mod＆lt;  -  lmer（平均〜周 +蜂箱 +杀菌剂 +杀虫剂 +（1 |位置），data = pp22_wide）
问题是我的响应变量“平均”实际上并不像连续价值，而是离散变量也不是。它在1543个数据点中只有5个唯一值。
唯一（pp22_wide $均值）
1.50 2.75 3.00 1.25 2.50 
长度（pp22_wide $均值）
1543 
因此，您可以想象它通常不会分散，因此不符合我的模型假设，我不能相信模型输出，因为它不是一个好的。我尝试在日志刻度上进行转换，取平方根或立体，这无助于使我的数据更正态分布。
有关如何处理此问题或应该运行哪种模型的建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/662239/how-do-i-handle-this-very-non-normal-response-variable</guid>
      <pubDate>Wed, 05 Mar 2025 20:59:57 GMT</pubDate>
    </item>
    <item>
      <title>当iv和DV之间的二次关系时，用于持续变量的统计能力分析</title>
      <link>https://stats.stackexchange.com/questions/662238/statistical-power-analyss-for-moderation-of-continious-variables-when-a-quadric</link>
      <description><![CDATA[当IV和DV之间具有连续变量的二次关系时，如何运行统计能力分析？？]]></description>
      <guid>https://stats.stackexchange.com/questions/662238/statistical-power-analyss-for-moderation-of-continious-variables-when-a-quadric</guid>
      <pubDate>Wed, 05 Mar 2025 20:09:47 GMT</pubDate>
    </item>
    <item>
      <title>Python频率分析 - 拟合度良好，尽管有多种分布</title>
      <link>https://stats.stackexchange.com/questions/662235/python-frequency-analysis-aic-of-infinity-for-several-distributions-despite-a</link>
      <description><![CDATA[ 0 
我正在对许多雪数据进行频率分析，这些雪数据有时在年度最大值系列中具有（有效）零值。
为了帮助指导分布的选择，我正在计算包​​括AIC和BIC在内的拟合统计数据的一些优点。我发现，即使对于显然合理的分布拟合，我的数据中的零观察结果也会在计算AIC/BIC时产生问题。计算零观测值的概率返回零，其log为-Inf，因此log -libielies是-inf，而AIC和BIC最终是无限的。即使我为输入数据中的零值分配了很小的非零值，这似乎也会发生。
下面的最低可再现示例。我想知道是否有某种可辩护的解决方法可以在发生这种情况的情况下获得代理AIC/BIC（经常使用Weibull，但偶尔有其他分布 -  GEV  -  GEV）。）。
 导入numpy作为NP
导入lmoments3.Dist作为LD
导入matplotlib.pyplot作为PLT

data = np.Array（[[279，244，226，216，216，300，208，267，267，239，277，277，277，135，79，201，15，15，198，231，231，231，251，277，277，277，168 ,,
      43、53、160、366、163、239、287、197、117、0、208]）

数据[data == 0] = 1E-07

return_periods = np.Array（[[1.1111，1.2500，1.4286,2,3,5,10,20,50,50,100,200,1000]）

＃将GEV分布适合数据
params = ld.gev.lmom_fit（数据）
＃计算给定返回期的分位数
分位数= ld.gev.ppf（1-1 / return_periods，** params）

＃计算数据的Cunnane绘图位置
n = len（数据）
sorted_data = np.sort（数据）
等级= np.Arange（1，N + 1）
经验性_cdf =（排名-0.4） /（n + 0.2）＃cunnane绘图位置
data_return_periods = 1 /（1-经验性_cdf）

＃绘制分位数图
plt.figure（无花果=（8，6））
plt.plot（return_periods，分位数，标记=&#39;o&#39;，linestyle =&#39; - &#39;，color =&#39;b&#39;，label =&#39;gev nterials&#39;）
plt.scatter（data_return_periods，sorted_data，color =&#39;r&#39;，label =&#39;输入数据（cunnane）&#39;）
plt.xscale（&#39;log&#39;）
plt.yscale（&#39;linear&#39;）
plt.xlabel（&#39;返回期（年）&#39;，fontsize = 12）
plt.ylabel（&#39;分数值&#39;，fontsize = 12）
plt.title（&#39;带有输入数据（cunnane）的GEV分布的片段图&#39;，fontsize = 14）
plt.grid（true，wher =; bot bot d of bots; ls =;  - 
plt.legend（）
plt.show（）



n = len（数据）
经验性_cdf =（np.Arange（1，n + 1）-0.4） /（n + 0.2）＃cunnane绘图位置
return_periods = 1 /（1-经验性_cdf）＃将CDF转换为返回周期


logpdf_values = ld.gev.logpdf（sorted_data，** params）
pdf_values = ld.gev.pdf（sorted_data，** params）
log_likelihood = np.sum（logpdf_values）
打印（f＆quot“ log似然：{log_likelihood}＆quot”）
k = len（params）＃模型中的参数数

aic = 2 * k -2 * log_likelione
bic = k * np.log（n）-2 * log_likelione

打印（f＆quot; aic：{aic}＆quot;）
打印（f＆quot; bic：{bic}＆quot;）
 
  &lt;img alt =“ Quantiles”]]></description>
      <guid>https://stats.stackexchange.com/questions/662235/python-frequency-analysis-aic-of-infinity-for-several-distributions-despite-a</guid>
      <pubDate>Wed, 05 Mar 2025 17:35:07 GMT</pubDate>
    </item>
    <item>
      <title>使用三角洲方法的帮助</title>
      <link>https://stats.stackexchange.com/questions/662231/help-using-the-delta-method</link>
      <description><![CDATA[我有以下信息：

  $ r_1 $  =第一年的响应计数
  $ r_5 $  =响应计数5 
  $ p_1 $  = 1年的人口
  $ p_5 $  = 5年级的人口
  $ \ text {rate} _1 = \ frac {r_1} {p_1} $  = 1年中的速率=速率
  $ \ text {rate} _5 = \ frac {r_5} {p_5} $  = rate 5 pear in 5年

我将百分比更改定义为：
  $$ \ text {百分比cange} = \ frac {\ text {速度} _5  -  \ text {速度} {rese} _1} {\ text {rese} _1} _1} _1} \ times times 100 \％$ $ $ $ $ $ $ pas&gt;     我想计算此百分比变化的置信区间。由于价格 $ \ text {rate} _1 $ 和 $ \ text {rate {速度} _5 $ 可以被视为二项式分布的比例，我希望使用大量群体使用正常的分布，我可以大致使用这些分布。      
我认为我需要使用Delta方法来解决此问题，因为我们具有随机变量的比例。我定义一个函数 $$ g = \ frac {\ text {rate} _5- \ text {rate} _1} {\ text {rese} _1} _1} $$
 i然后以 $ g $ 相对于两个费率的第一个衍生物：
  $$ \ frac {\ partial g} {\ partial \ text {速度} _5} = \ frac {1} {1} {\ text {速度} _1 _1} $$
  $$ \ frac {\ partial g} {\ partial \ text {rese} _1} =  -  \ frac {\ frac {\ text {rese} _5} _5} {\ text {\ text {rese}
这部分使我感到困惑，但是我认为 $ g $ 的差异然后可以近似为（通过delta方法，我相信协方差术语应该是 $ 0 $  $ 0 $ 出于逻辑的原因）：）
  $$ \ text {var}（g）\ of \左（\ frac {\ frac {\ partial g} {\ partial \ partial \ text {速度} _5} _5} _5} \ right） \ text {rate} _1} \ right）^2 \ text {var}（\ text {速度} _1）$$  
对于二项式比例，差异为：
  $$ \ text {var}（\ text {速度} _1）= \ frac {\ frac {\ text {速度} _1 \ times \ times（1  -  \ text {速度} _1）}
  $$ \ text {var}（\ text {rese} _5）= \ frac {\ frac {\ text {速度} _5 \ times（1  -  \ text {rese} {速度} _5）}
所以当我将所有内容结合在一起时：
  $$ \ text {var}（g）\ of左右（\ frac {1} {1} {\ text {速度} _1} _1} \ right）^2 \ frac {\ frac {\ frac {\ text {rese} \ left（ -  \ frac {\ text {rate} _5} {\ text {速度} _1^2} \ right）^2 \ frac {\ frac {\ text {速度} _1 _1 \ times（1  -  \ text}
  $$ \ text {var}（g）\ of frac {\ frac {\ text {速度} _5 \ times（1- \ text {速度} _5）} {p_5 \ times \ times \ times \ text \ text} \ text {rate} _1 \ times（1  -  \ text {速度} _1）}} {p_1 \ times \ text \ text {速度} _1^4} $$
  $$ \ text {var}（g）\ of of frac {\ frac {\ text {rate} _5 \ times（1  -  \ text {速度} _5）} {p_5 \ times \ times \ times \ text \ text {速度} _1^2} _1^2} _1^2} + frac \ frac \ frac \ frac \ frac \ frac \ f act \ text {速度} _1）}} {p_1 \ times \ text {速度} _1^3} $$  
最后，我可以使用标准CLT近似值：
在
在
  $$ \ text {ci} _ {95 \％} = \ frac {\ frac {\ text {速度} _5  -  \ text {rate} _1} _1} {\ text {\ text {rese} \ sqrt {\ frac {\ text {速度} _5 \ times（1  -  \ text {速度} _5）} {p_5 \ times \ times \ text {速率} _1^2} + \ frac { \ text {rate} _1^3}} $$  
这是正确的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/662231/help-using-the-delta-method</guid>
      <pubDate>Wed, 05 Mar 2025 16:38:50 GMT</pubDate>
    </item>
    <item>
      <title>了解相关因素模型中的不合适</title>
      <link>https://stats.stackexchange.com/questions/662229/understanding-misfit-within-correlated-factors-model</link>
      <description><![CDATA[我正在研究一个正在评估量表的项目。我遇到了一个问题，尽管分别拟合了两个CFA模型并实现了良好的合适，但当相关的因子模型中，它的适合度较差。我很难理解对模型的含义。
让我举个例子。我有两个子量表。

 cfa的子量表1χ2（2）= 10.59，p＆lt; .001，cfi = .97，tli = .92，rmsea = .08，srmr = .02 
 cfa的子量表2χ2（5）= 15.91，p = .007，cfi = .99，tli = .98，rmsea = .06，srmr = .02 
 CFA用于子量表的相关因素模型：χ2（43）= 244.88，P＆lt; .001，cfi = .87，tli = .84，rmsea = .08，srmr = .07。

我们可以从中解释什么实质性含义？截至目前，我将其解释为相关因素模型并不能很好地符合数据。然后，我会查看不同类型的模型（即层次结构和双分离器），以查看它们的合适。但这对我来说是程序性的，我无法真正表达出为什么。
我不确定为什么我有这种天真的直觉，如果两个模型分别非常合适，那么它们应该很好地融合在一起。如果有人有任何文章/章节讨论涉及解释的因素模型的理论含义，我将非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/662229/understanding-misfit-within-correlated-factors-model</guid>
      <pubDate>Wed, 05 Mar 2025 16:12:10 GMT</pubDate>
    </item>
    <item>
      <title>使用分段软件包计算突破点</title>
      <link>https://stats.stackexchange.com/questions/662227/break-point-calculation-using-segmented-package</link>
      <description><![CDATA[我目前正在处理一个曲线拟合问题，我需要找到曲线的断点。我最初使用两步方法，通过使用AVG_PREDICTIONS拟合结果模型两倍，因为我尝试过的SEG.FIT函数不处理花键项。
是否有更有效的方法来找到涉及花键的曲线的断点？我是否错过了可以更有效地处理它的更简单的方法或方法？任何建议或建议将不胜感激！
我的代码看起来像这样：
 库（dplyr）
图书馆（花键）
图书馆（Marginaleffects）
图书馆（ggplot2）
图书馆（分段）

d＆lt;  -  my_dataset

d  $ binary_outcome＆lt;  - 因子（d $  binary_outcome）

fit＆lt;  -  glm（binary_outcome〜splines :: ns（x_axis_variable，df = 5，intercept = t），
           数据= D，
           family =“二项式”

values＆lt;  -  with（d，seq（d  $ x_axis_variable，na.rm = true）， 
                      max（d $  x_axis_variable，na.rm = true），
                      length.out = nrow（d）））

p＆lt;  -  avg_predictions（fit，
                     变量= list（x_axis_variable = values），
                     byfun =函数（...）qnorm（平均（...）），
                     变换= pnorm）

fit.lm＆lt;  -  glm（估计〜x_axis_variable，data = p，family = quasibinomial）

seg.fit＆lt;  - 分割（fit.lm，seg.z = 〜x_axis_variable，npsi = 1）

断点＆lt;  - 摘要（seg.fit）$ psi [，&#39;es; est。]
打印（断点）

ggplot（p，aes（x = x_axis_variable，y = estime）） +
  geom_point（alpha = 0.5）+
  ＃GEOM_RIBBON（AES（ymin = conf.low，ymax = conf.high），
  ＃alpha = .3，
  ＃fill =&#39;slategray＆quot”）+
  geom_line（aes（y = predict（seg.fit，type，type =＆quote; worlds; quots; quot; quot; quot; quot＆quot =; blue; blue; quot;） +
  geom_vline（Xintercept = brekaspoint，color =; red＆quort; lineType =; dished＆quot; quot; quot; quot＆quot; span class =“ Math-Container”&gt;```
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662227/break-point-calculation-using-segmented-package</guid>
      <pubDate>Wed, 05 Mar 2025 15:40:28 GMT</pubDate>
    </item>
    <item>
      <title>NLP用于提取临床信息？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/662226/nlp-for-extracting-clinical-information</link>
      <description><![CDATA[我有一个PDF文档，其中包含IBD患者的医疗信息。该文件包括医院，医生和临床病史的数据。我需要提取特定的治疗信息，并在具有三列的表中组织它：治疗，开始日期和结束日期。
这是挑战：

相关信息通常以从日期开始的行（通常包括年度和月份）进行组织，但有时包括或包括当天的日期）。 
在同一行中的某个地方，出现了处理名称或描述。
在许多情况下，一行可能会参考多种治疗方法（例如，一种治疗开始，另一种治疗方法），这些参考文献可以以不同的顺序出现。
简单的关键字搜索不够，因为可能的日期格式，治疗参考以及区分每种治疗的开始/结束日期的需求。

由于这些复杂性，我认为基于NLP的方法对于解析PDF内容，理解上下文并提取正确的信息部分是必要的（即哪个日期对应于哪种治疗方法）。我的目标是在Python中实现解决方案，可能会使用可以处理这些细微差别的相关NLP库。
问题：

 您会推荐哪些工具，库或方法来解析PDF文档并在NLP的帮助下提取结构化数据？

 当可能出现在同一条线上时，我如何可靠地识别并将正确的日期（开始/结束）与相应的处理配对？

 对于医学文本提取，是否有任何最佳实践或现有框架（例如，Spacy，Hugging Face等）在这种情况下可能特别有用？

 我应该如何处理边缘案例，例如日期格式不同的行或包含多个日期格式的行的行？


我不是在寻找完整的解决方案实现。我只想对最有效的方法，工具和一般策略进行指导，以便我自己构建它。任何建议，参考或最佳实践都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/662226/nlp-for-extracting-clinical-information</guid>
      <pubDate>Wed, 05 Mar 2025 15:21:40 GMT</pubDate>
    </item>
    <item>
      <title>估计人口预测事件总数的置信度或预测间隔</title>
      <link>https://stats.stackexchange.com/questions/662225/estimating-confidence-or-prediction-intervals-for-the-total-number-of-predicted</link>
      <description><![CDATA[ i具有特异性事件率来自人群a ，并将其应用于人口B 中的相应地层，以估计预测事件的数量。在将这些预测的事件概括为获得总体B中估计事件的总数（类似于标准化的死亡率）之后，我想在此总估计中计算一个间隔（95％的预测或置信区间？）。间隔应适用于绝对数量的事件，而不是比例或速率。
如何计算此间隔？
为了更明确，这是一个示例数据集：
  age_gr sex pop_a ev速率pop_b ** prediction_events **    
20-30 M 2000 34 0.017 500 8.5 
31-40 M 3000 52 0.017 1000 17.3    
41-50 M 4000 76 0.019 1500 28.5    
51-60 M 5000 120 0.024 2000 48.0    
20-30 F 2500 30 0.012 750 9.0 
31-40 F 3500 47 0.013 1250 16.8    
41-50 F 4500 85 0.019 1750 33.1    
51-60 F 5500 115 0.021 2250 47.0    
 
总人口_b = 11000 
 总预测人口中的事件_b = 208.2  
  95％间隔？=  ]]></description>
      <guid>https://stats.stackexchange.com/questions/662225/estimating-confidence-or-prediction-intervals-for-the-total-number-of-predicted</guid>
      <pubDate>Wed, 05 Mar 2025 14:58:22 GMT</pubDate>
    </item>
    <item>
      <title>确定混合模型设计的最小样本量，每个人都有多次观察</title>
      <link>https://stats.stackexchange.com/questions/662224/determination-of-minimum-sample-size-for-a-mixed-model-design-with-multiple-obse</link>
      <description><![CDATA[我想使用一个连续响应变量和两个相互作用的预测指标的混合模型来估计一项研究的样本量，该研究估计了群体和处理的相互作用：一组个人和治疗。小组是一个无序的分类因素，每个级别具有三个级别和十个人。治疗是有序因素（三个不同的温度）。分组因素是实验个体。每个人都应接受三种相同的治疗方法。首先冷却，然后平均，然后热。但是，我可以迭代地做到这一点。
每个人将在每种治疗中度过一天。我想知道我需要在每种治疗中观察每个人需要多少天，但是我不确定我在PWR和SIMR软件包中发现的正式方法。
事先感谢
我使用软件包SIMR添加了替代方案。在这里，尽管我不确定我对其进行了很好的编码（我是否应该为每个组添加不同的手段？在依据变量中）。我认为我应该添加几天，直到模型没有产生单一的拟合度为止，但这似乎还取决于我在进行实验之前才有的方差数据。另外，结果并不能清楚地回答我的问题：我需要多少天。
加载必要的库
 库（LME4）
图书馆（SIMR）
 
定义混合模型
假定具有组的随机拦截模型和治疗为固定效应
 模型＆lt;  -  lmer（响应〜组 *治疗 +（1 |个体）， 
data = your_data）
 
模拟数据
  set.seed（123）
n_individuals＆lt;  -  30＃每个组个人数量
N_Groups＆lt; -3
n_treatments＆lt; -2
n_days＆lt;  -  12＃天数初始猜测
 
创建一个数据框
  your_data＆lt;  -  expliv.grid（
个人=因子（1：（n_印度 * n_groups）），），
处理=因子（1：n_处理），
day =因子（1：n_days）
）
your_data $ group＆lt;  - 因子（rep（1：n_groups，每个= n_individuals * n_treatments * n_days / n_groups）））
 
模拟响应变量
  your_data $ with＆lt;  -  with（your_data，rnorm（nrow（your_data）），均值= 6，sd = 2））
 
将模型适合模拟数据
 模型＆lt;  -  lmer（响应〜组 *治疗 +（1 |个体）， 
data = your_data）
 
执行功率分析，指定固定效果
  power_analysis＆lt;  -  powersim（型号，固定（组：治疗; 
100）
 
打印结果
  print（power_analysis）
 
预测指标“组：治疗”（95％置信区间）的功率：
20.00％（2.52，55.61）
测试：Kenward Roger（软件包PBKRTEST）
基于10个模拟（0个警告，0个错误）
alpha = 0.05，nrow = 2160 
时间过去：0 H 0 M 37 S 
 nb：结果可能是观察到的功率计算]]></description>
      <guid>https://stats.stackexchange.com/questions/662224/determination-of-minimum-sample-size-for-a-mixed-model-design-with-multiple-obse</guid>
      <pubDate>Wed, 05 Mar 2025 14:46:11 GMT</pubDate>
    </item>
    <item>
      <title>VECM或VAR模型给定变量-3是协调的I（1），两个是固定的i（0）[重复]</title>
      <link>https://stats.stackexchange.com/questions/662220/vecm-or-var-model-given-variables-3-are-cointegrated-i1-and-two-are-stationa</link>
      <description><![CDATA[我正在运行一个具有五个变量的模型。 3是协调的，而2是静止的。我想运行一个VAR/VEC模型以获取IRF和方差分解数据。但是，我不确定我应该使用哪个两个，因为我已经在网上看到了矛盾的结果。任何帮助将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/662220/vecm-or-var-model-given-variables-3-are-cointegrated-i1-and-two-are-stationa</guid>
      <pubDate>Wed, 05 Mar 2025 14:03:12 GMT</pubDate>
    </item>
    <item>
      <title>添加索引模型$ e（y \ mid x）= \ alpha + g（\ beta^t x）$中的$ g $约束</title>
      <link>https://stats.stackexchange.com/questions/662217/constraint-on-g-in-the-additive-index-model-ey-mid-x-alpha-g-betat-x</link>
      <description><![CDATA[在带有协变量的加法索引模型中
  $$ e（y \ mid x）= \ alpha + g（\ beta^t x）\ ,, $$  
其中 $ \ beta $ 是一个单位向量， $ g：\ mathbb r \ to \ mathbb r $ 是 $ g（0 $ g（0）= 0 $ 
假设我希望使用立方B-Splines估算 $ g（\ cdot）$ 。我写
  $$ g（t）= \ sum_ {i} c_i b_i（t）\ ,, $$  
其中 $ b_i $ 是 $ i $  th cutcic b-spline Bastine bastin untuct in Unknown系数But it is not clear to me how $g(0)=0$ translates in terms of the $c_i$&#39;s, because $B_i(0)$ depends on the value of the knots in my spline, which in turn depends on the data  $ x $ 。我假设约束 $ g（0）= 0 $ 是使参数 $ \ alpha $ 识别。是否可以对 $ c_i $ &#39;s？强加相应的约束]]></description>
      <guid>https://stats.stackexchange.com/questions/662217/constraint-on-g-in-the-additive-index-model-ey-mid-x-alpha-g-betat-x</guid>
      <pubDate>Wed, 05 Mar 2025 12:51:01 GMT</pubDate>
    </item>
    <item>
      <title>R中有没有办法测试COX模型回归系数的时间变化功能形式的优点？</title>
      <link>https://stats.stackexchange.com/questions/662228/is-there-a-way-in-r-to-test-the-goodness-of-my-time-varying-functional-form-for</link>
      <description><![CDATA[如果我适合像
m＆lt;  -  coxph（surv（时间，状态）〜x + tt（x），tt =函数（x，t，…）x*g（t））&gt;
我怎么知道我选择的G（t）（也可能是花键）是否好？
我的两个猜测是

在cox.zph的转换参数中使用相同的g（t）
使用roversplit制作我的数据集的长期版本，将COX模型与I（x*g（time））作为协变量，然后使用Cox.zph 检查测试

我不确定其中两个。因为在1中。我只是在修改残差图的时间尺度，而在2中。我真的不明白测试的内容。
有什么建议吗？
检查G（t）使用（说）P-Splines时是否调整非比例性？是否有用？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/662228/is-there-a-way-in-r-to-test-the-goodness-of-my-time-varying-functional-form-for</guid>
      <pubDate>Wed, 05 Mar 2025 11:38:43 GMT</pubDate>
    </item>
    <item>
      <title>比较2个分布时，将一个样本中的额外数据合并？</title>
      <link>https://stats.stackexchange.com/questions/662210/incorporating-extra-data-from-one-sample-when-comparing-2-distributions</link>
      <description><![CDATA[给定我有3个样本 $ x_1^{（1）}，\ dots，x_n^{（1）} \ sim p_x $ ， $ x_1^{（2）  $ y_1，\ dots，y_n \ sim p_y $   - 让我们假设 $ p_x $ 与 $ p_y $ 。我想进行测试（例如，t检验，kolmogorov smirnov测试等），以表明样品 $ \ {x_1^{（2）}，\ dots，x_n^{（2）} {（2）} \} $ span&gt; span  $ \ {y_1，\ dots，y_n \} $ 。
在此处保留确切的测试通用，我进行了3种不同类型的2样品测试：

 测试1：测试 $ \ {x_1^{（2）}，\ dots，x_n^{（2）} \} $  fit  $ \ \ {y_1 clast，
 测试2： testing  $ \ {x_1^{（2）}  -  x_1^{（1）}，\ dots，x_n^{（2）}  -  x_n^{（2）}  -  x_n^{（1）} {（1）}} $ 反对 $ \ {y_1-x_1^{（1）}，\ dots，y_n-x_n^{（1）} \} $ 通过选择的测试。
 测试3： testing  $ \ {x_1^{（1）}，\ dots，x_n^{（1）} \} \ cup \ cup \ {x_1^{（x_1^{（2）}，\ dots，\ dots，\ dots，\ dots，\ dots，\ dots，\ dots，\ dots，\ dots，x_n^=  $ \ {y_1，\ dots，y_n \} $ 通过选择的测试。

进行2个样本KS测试的实验：

 无检测：我使用 $ p_x \ sim n（0,1）$ 和 $ p_y \ sim n（0,1） class =“ Math-Container”&gt; $ n = 1000 $ 并运行模拟 $ 100 $  times。令FPR为假阳性率，FNR为假负率。结果是：test1 fpr = 0.04，test2 fpr = 0.0，test3 fpr = 0.02。
 得到检测：我使用 $ p_x \ sim n（0,1）$ 和 $ p_y \ sim n（0,1.1.1）$  $ n = 1000 $ 并运行模拟 $ 100 $  times。结果是：test1 fnr = 0.83，test2 fnr = 0.98，test3 fnr = 0.75。

似乎测试3给出了FPR-FNR权衡取得的最佳结果，测试2给出了最佳FPR。这是真的的理论/数学原因吗？谢谢。也可以奏效。
用于测试的代码：
 导入numpy作为NP
从scipy.stats导入ks_2samp

np.random.seed（0）

def ks_test（sample1，sample2，sig_lvl）：
    _，p_val = ks_2samp（Sample1，Sample2）
    如果p_val＆lt; sig_lvl：
        返回true
    别的：
        返回false
    
＃FPR测试
FPR1 = 0
FPR2 = 0
FPR3 = 0
sig_lvl = 0.05
对于我的范围（100）：
    x1_samples = np.random.normal（0，1，1000）
    x2_samples = np.random.normal（0，1，1000）
    y_samples = np.random.normal（0，1，1000）
    test1 = ks_test（x2_samples，y_samples，sig_lvl）
    test2 = ks_test（x2_samples-x1_samples，y__samples-x1_samples，sig_lvl）
    x_sample = np.concatenate（（x1_samples，x2_samples），axis = 0）
    test3 = ks_test（x_sample，y__samples，sig_lvl）
    如果test1：
        FPR1 += 1
    如果test2：
        FPR2 += 1
    如果test3：
        FPR3 += 1
打印（fpr1＆quot＆quot fpr1 / 100）
打印（fpr2＆quot＆quot fpr2 / 100）
打印（fpr3＆quot; fpr3 / 100）

＃FNR测试
FNR1 = 0
FNR2 = 0
FNR3 = 0
sig_lvl = 0.05
对于我的范围（100）：
    x1_samples = np.random.normal（0，1，1000）
    x2_samples = np.random.normal（0，1，1000）
    y_samples = np.random.normal（0，1.1，1000）
    test1 = ks_test（x2_samples，y_samples，sig_lvl）
    test2 = ks_test（x2_samples-x1_samples，y__samples-x1_samples，sig_lvl）
    x_sample = np.concatenate（（x1_samples，x2_samples），axis = 0）
    test3 = ks_test（x_sample，y__samples，sig_lvl）
    如果test1 == false：
        FNR1 += 1
    如果test2 == false：
        FNR2 += 1
    如果test3 == false：
        FNR3 += 1
打印（fnr1＆quot; fnr1 / 100）
打印（fnr2＆quot; fnr2 / 100）
打印（fnr3＆quot; fnr3 / 100）
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662210/incorporating-extra-data-from-one-sample-when-comparing-2-distributions</guid>
      <pubDate>Wed, 05 Mar 2025 07:40:39 GMT</pubDate>
    </item>
    <item>
      <title>RMSE与非线性模型选择的AIC</title>
      <link>https://stats.stackexchange.com/questions/662208/rmse-vs-aic-for-non-linear-model-selection</link>
      <description><![CDATA[想知道有人在使用RMSE与AIC选择“最合适的”模型时是否可以在协议（或分歧）方面可以提出建议？这些指标显然正在测量不同的事物，我得到了RMSE的直觉，但对于AIC而言，这可能是如何相关的，如果有的话。
我通常使用AIC评估模型拟合。对于我目前正在进行的项目，我们正在比较 nls（）模型的单指数拟合。我被要求将RMSE视为适合度量指标。有趣的是，我发现单模型的AIC较低，但RMSE较高。
您是否应该期望他们都指向相同的方向？
 ＆gt; qpcr :: rmse（nls_mod_mono）
[1] 147.9371
＆gt; AIC（nls_mod_mono）
[1] 95.82016

＆gt; qpcr :: rmse（nls_mod_bi）
[1] 141.389
＆gt; AIC（nls_mod_bi）
[1] 99.18635
 ]]></description>
      <guid>https://stats.stackexchange.com/questions/662208/rmse-vs-aic-for-non-linear-model-selection</guid>
      <pubDate>Wed, 05 Mar 2025 06:48:40 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何方法可以计算或说明每个样本的自动相关，每个样本只有2个观察结果？</title>
      <link>https://stats.stackexchange.com/questions/662183/is-there-any-way-to-calculate-or-account-for-auto-correlation-of-many-samples-th</link>
      <description><![CDATA[森林碳已经针对100多个独立地点进行了测量，并且在相距10年的两个时间点上测量了每个地点。在观察1中，每个地点都有一定数量的碳，它们独立于其他每个地点。但是，在观察2中，理论上应与该地点观察1测得的碳量相关。
是否有任何方法可以通过在所有站点之间的观测值之间纳入碳的变化来计算观测1和观察2之间的相关性？
另外，是否可以在线性回归模型中说明这种理论自动相关？
编辑：
这是一些示例数据，是我的数据和我的意图的体面表示。
  set.seed（42）
n_sites＆lt;  -  100＃站点数量
c1＆lt;  -  abs（rnorm（n_sites，平均= 50，sd = 30））＃初始碳（t = 0）是随机分布的
c2＆lt;  -  c1 *（0.9 + rnorm（n_sites，平均值= 0，sd = 0.02））＃t = 10的碳与C1 +一些噪声自动相关
site_temps＆lt;  -  rnorm（n_sites，平均值= 15，sd = 5）＃每个站点都有其自己的基线温度
＃用长格式创建数据框架
df＆lt;  -  data.frame（
  站点= rep（1：n_sites，每个= 2），＃每个站点都有2个时间段
  时间= rep（c（0，10），times = n_sites），＃timeSteps 0和10
  temp = rep（site_temps，每个= 2） + rnorm（2 * n_sites，平均值= 0，sd = 1）＃添加位点内部变化到基线温度
）％＆gt;％
  ＃分配长格式的碳值，其中碳值略微取决于温度
  group_by（site）％＆gt;％
  突变（碳= ifelse（time == 0，c1 [site] *（temp^0.01），c2 [site] *（temp^0.01）））％＆gt;％
  突变（deltac =碳 - 第一（碳））％＆gt;％
  ungroup（）
 
这是示例数据的样子：
  我正在创建一个线性模型来查看碳和气候变量之间的相关性：
 模型＆lt;  -  lm（碳〜TEMP，DF）
摘要（模型）
 
这给碳的温度显着影响
  lm（公式=碳〜Temp，data = df）
系数：
            估计标准。错误t值pr（＆gt; | t |）    
（截距）63.3868 5.6790 11.162＆lt; 2e-16 ***
温度-0.7653 0.3586 -2.134 0.0341 *  
 
但是，当我向模型添加deltac时，这种重要效果被掩盖：
  lm（公式=碳〜Temp + deltac，data = df）

系数：
            估计标准。错误t值pr（＆gt; | t |）    
（截距）55.5996 5.9006 9.423＆lt; 2E-16 ***
温度-0.6308 0.3540 -1.782 0.0763。  
Deltac -2.0674 0.5160 -4.006 8.77E -05 ***
 
我将其解释为意味着该数据集中有足够的自相关以掩盖气候变量在分析中的影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/662183/is-there-any-way-to-calculate-or-account-for-auto-correlation-of-many-samples-th</guid>
      <pubDate>Tue, 04 Mar 2025 18:45:12 GMT</pubDate>
    </item>
    </channel>
</rss>