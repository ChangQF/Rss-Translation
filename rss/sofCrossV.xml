<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 02 Dec 2024 21:16:46 GMT</lastBuildDate>
    <item>
      <title>通过后验分布模拟先验</title>
      <link>https://stats.stackexchange.com/questions/658175/priors-to-simulate-from-posterior-distribution</link>
      <description><![CDATA[我尝试使用 STAN 从自定义分布中进行模拟，总体而言，我得到的模拟结果很糟糕，虽然链似乎混合得很好，但估计的参数没有意义，因为它们拟合得不好（基本上我想拟合单变量分布），我尝试了不同类型的先验和值，但没有一个模拟结果很好。我得到非常好结果的唯一情况是当我使用以 MLE 为中心的先验时，它在这种情况下工作得很好，但我的问题是，这样做合法吗？使用类似的方法合法吗？通过其他方法估计或了解参数值并替换该值？或者在这种情况下我还能如何选择我的先验？我将不胜感激任何与此主题相关的参考资料。我使用一些先验知识保留了一些结果。
使用 $q \sim Beta(5,0.2)$、$\alpha \sim Cauchy(\hat{\alpha}_{MLE},1)$、$a \sim \mathcal{G} (1,0.1)$ 和 $b \sim \mathcal{G} \sim (3,1)$ 可以正常工作。
 mean se_mean sd 
q 0.9600508 0.001773112 0.07945101 
alpha 1055.8202394 2.329177339 58.17198671 
a 0.1829996 0.001408920 0.03831904 
b 3.0902087 0.015930948 0.43511936 

使用 $q \sim Beta(5,0.2)$、$\alpha \sim Cauchy(0,1)$、$a \sim \mathcal{G} (1,0.1)$ 和 $b \sim \mathcal{G} \sim (3,1)$ 效果非常糟糕。
 mean se_mean sd 
q 0.9670122 0.001136417 0.06654238 
alpha 18.0333259 1.329136597 47.74554985 
a 0.7961252 0.008062306 0.27315337 
b 5.0700071 0.037936643 1.35981564 

$q \in (0,1)$; $\alpha,a,b &gt; 0$.]]></description>
      <guid>https://stats.stackexchange.com/questions/658175/priors-to-simulate-from-posterior-distribution</guid>
      <pubDate>Mon, 02 Dec 2024 21:14:32 GMT</pubDate>
    </item>
    <item>
      <title>在约束 x 和 y 的情况下，简单线性回归的斜率和截距之间是否存在虚假相关性？</title>
      <link>https://stats.stackexchange.com/questions/658172/is-there-a-spurious-correlation-between-slope-and-intercept-of-a-simple-linear-r</link>
      <description><![CDATA[我试图确定是否可以使用简单线性回归的 y 截距来预测斜率，但我想确认 y 截距是否与斜率存在虚假相关性。当 x 值和 y 值只能在某个范围内时，会发生这种情况吗？我发现之前的一个帖子提到“在简单线性回归中，估计的斜率和截距之间的相关性与解释变量的平均值的符号相反。即，如果解释变量的平均值是正的，则估计系数之间的相关性将为负，反之亦然。”]]></description>
      <guid>https://stats.stackexchange.com/questions/658172/is-there-a-spurious-correlation-between-slope-and-intercept-of-a-simple-linear-r</guid>
      <pubDate>Mon, 02 Dec 2024 20:44:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Jaynes 的多维 $A_p$ 分布采用这种形式？</title>
      <link>https://stats.stackexchange.com/questions/658170/why-does-jaynes-multi-dimensional-a-p-distribution-take-this-form</link>
      <description><![CDATA[在 Jaynes 的《概率论：科学的逻辑》第 18 章：http://www.med.mcgill.ca/epidemiology/hanley/bios601/GaussianModel/JaynesProbabilityTheory.pdf中，他引入了$A_p$分布作为概率分配$P(A|E)$的“内部结构”，使得$P(A|E)$只是$A_p$密度的一阶矩。我有点明白为什么 $A_p$ 以这种方式引入 1D 分布。但在第 18.10 节中，他引入了 K 维 $A_p$ 密度：

我不太明白为什么它采用这种形式的 delta 函数。有人能解释一下为什么它采用这种形式吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658170/why-does-jaynes-multi-dimensional-a-p-distribution-take-this-form</guid>
      <pubDate>Mon, 02 Dec 2024 20:30:07 GMT</pubDate>
    </item>
    <item>
      <title>AUC与交叉熵的关系</title>
      <link>https://stats.stackexchange.com/questions/658169/relationship-between-auc-and-cross-entropy</link>
      <description><![CDATA[我理解 AUC 衡量的是模型对受试者进行排名的能力（请参阅 [https://stats.stackexchange.com/questions/190216/why-is-roc-auc-equivalent-to-the-probability-that-two-randomly-selected-samples]）。
相比之下，二元交叉熵（或对数损失）衡量的是预测概率的校准。
基于这一区别，优化一个指标（例如交叉熵）不一定会导致另一个指标（例如 AUC）的最佳结果。然而，许多模型使用交叉熵作为主要目标函数，并且仍然获得不错/很好的 AUC 分数。此外，当交叉熵损失最小化时（即预测概率为正样本为 1，负样本为 0），AUC 也是最优的。
因此，我的问题是

交叉熵损失是否可以部分分解为排名组件？
交叉熵和 AUC 是否表现出一定程度的相关性？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658169/relationship-between-auc-and-cross-entropy</guid>
      <pubDate>Mon, 02 Dec 2024 20:24:01 GMT</pubDate>
    </item>
    <item>
      <title>最小绝对偏差 – 几何直觉</title>
      <link>https://stats.stackexchange.com/questions/658168/least-absolute-deviations-geometric-intuition</link>
      <description><![CDATA[我最近接触到了关于最小二乘 (OLS) 回归的几何直觉：
结果变量 Y 的向量不在 X_1、X_2、...、X_p-1 的线性跨度内：

正交向量 y-X(Bhat) 可最小化误差向量的 l^2 范数并解决最小二乘问题。
我的问题是：对于最小绝对偏差 (LAD) 问题，我们想要最小化 l^1 范数，对于哪种投影可以解决 LAD 问题，是否有任何直觉？它不一定是上面的正交向量（并且 LAD 解不一定是唯一的）。
这实际上更像是一个线性代数问题：如果我们想要最小化 l^1 范数，投影会是什么样子？]]></description>
      <guid>https://stats.stackexchange.com/questions/658168/least-absolute-deviations-geometric-intuition</guid>
      <pubDate>Mon, 02 Dec 2024 19:56:06 GMT</pubDate>
    </item>
    <item>
      <title>如何处理 1-5 星评级中的偏见？</title>
      <link>https://stats.stackexchange.com/questions/658166/how-to-handle-bias-in-1-5-star-ratings</link>
      <description><![CDATA[我和一位朋友讨论了我在一家健康保险公司的不愉快经历，为了支持我的印象，我向她指出 trustpilot 给它的分数很低。
有 70 条评论，分布如下：{1：61、2：3、3：0、4：1、5：5}（星级：投票数）。
她的回答是：“哦，但是只有 70 条评论，所以它不算数”。
我最初的想法是 70 不是一个很小的数字；从多项分布来看，如果人们实际上总体上对这家保险公司感到满意，那么随机获得如此负面结果的可能性就很小。
经过进一步思考，我发现问题可能不在于评论的数量，而在于数据收集过程中可能存在的偏见。
由于这不是真正随机选择的调查结果，而是自发报告的结果，数据是否真的代表了整体客户群体？
例如，对保险公司更满意的人是否不太可能留下评论，反之亦然，不太满意的人是否更有可能报告他们的不满？
假设是这样，是否有任何已知的方法或途径可以减少这种偏见？
例如能否根据某种概率分布对评论进行加权？
下面是一些更多信息，仅用于说明我的进一步研究和思考过程。
我看到了一些关于贝叶斯平均值估计的帖子，例如这个，事实上，根据上述数据得出的 trustpilot 平均评分并不是通过简单的算术平均值得到的。
但是，我不确定这是否解决了我在这里讨论的偏见问题，因为它似乎更侧重于比较具有相同纯算术平均值但基于不同评论总数的评分对。从这个意义上讲，我当然不得不同意有必要进行纠正。但它是否解决了数据收集部分？
我正在讨论的保险公司示例的平均分数（不考虑贝叶斯校正或 trustpilot 所做的任何其他校正）是：
$$\frac {\sum_{n=1}^5 {votes(n) \cdot n}} {\sum_{n=1}^5 {votes(n)}} = \frac {61 \cdot 1+3 \cdot 2+ 0 \cdot 3 + 1 \cdot 4+5 \cdot 5} {70} = \frac {48} {25} \approx 1.37$$
我猜测偏差校正可能看起来像一个非常简单的例子：假设我们知道对保险公司的看法为“n 星”的人写评论的概率与 $\frac 1 n$ 成比例。
那么 $PMF(n)$ 将是 $\frac 1 n \cdot \frac {60} {137}$。
这意味着如果 $x(n)$ 人投了 $n$ 颗星，那么实际考虑该评分的人数将成比例增加 $\frac 1 {PMF(n)}$。 （顺便说一句，这是我边写边编的，如果我错了，请纠正我：这篇文章的目的是就此事征求建议）。
如果我没有记错的话，根据这个逻辑修正后的平均值将是：
$$\frac {\sum_{n=1}^5 {votes(n) \cdot n \cdot \frac 1 {PMF(n)}}} {\sum_{n=1}^5 {votes(n) \cdot \frac 1 {PMF(n)}}} = \frac {\sum_{n=1}^5 {votes(n) \cdot n^2}} {\sum_{n=1}^5 {votes(n) \cdot n }} = \frac {61 \cdot 1^2 + 3 \cdot 2^2 + 0 \cdot 3^2 + 1 \cdot 4^2 + 5 \cdot 5^2} {61 \cdot 1+3 \cdot 2+ 0 \cdot 3 + 1 \cdot 4+5 \cdot 5} = \frac {103} {48} \approx 2.14$$
我的看法是：由于对保险公司满意度较高的人不太可能撰写评论和投票，因此这种方法会给他们的投票赋予更大的权重，以更好地接近如果有可能从所有人那里获得投票，则会获得的平均水平。
这有意义吗？
根据上述问题，是否有任何旨在减少自发报告与设计民意调查可能导致的偏差的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/658166/how-to-handle-bias-in-1-5-star-ratings</guid>
      <pubDate>Mon, 02 Dec 2024 19:29:10 GMT</pubDate>
    </item>
    <item>
      <title>IV 估计、直接和间接影响</title>
      <link>https://stats.stackexchange.com/questions/658165/iv-estimation-direct-and-indirect-effects</link>
      <description><![CDATA[假设我有一个如下设置，其中 $y_i$ 是感兴趣的结果，而 $x_i$ 是某个内生回归量。目的是估计 $\beta$。现在假设有一个变量 $z_i$ 与 $x_i$ 相关，而与误差 $\varepsilon_i$ 不相关。下面，通常假设 IV 估计仅在 $\gamma=0$ 时才有效。也就是说，该工具对结果没有直接影响。
$$ y_i = a + \beta x_i + \gamma z_i+ \varepsilon_i $$
$$ x_i = b + \delta z_i + u_i $$
$$ E[z_i, \varepsilon] = 0 $$
$$ E[z_i, x_i] \neq 0 $$
$$ E[x_i, \varepsilon_i] \neq 0 $$
我的问题是，无论如何运行 IV 估计并将该工具作为协变量包含在第二阶段回归？系数估计似乎不会有偏差。问题是否在于解释？最后，这是否有助于理解该工具对结果的间接影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/658165/iv-estimation-direct-and-indirect-effects</guid>
      <pubDate>Mon, 02 Dec 2024 19:00:17 GMT</pubDate>
    </item>
    <item>
      <title>生态时间统计分析问题</title>
      <link>https://stats.stackexchange.com/questions/658163/ecological-temporal-statistical-analysis-question</link>
      <description><![CDATA[我在同一地点连续三个时间段内收集了无放回的动物样本：深海中相隔七年（例如，没有已知的季节性）。我想知道病毒感染的平均差异是否会随时间发生显着变化。数据不正常。我是否应该将其视为独立的（无放回采样，尽管随着时间的推移，没有固有的模式，例如季节性会导致变化），因此进行 Kruskal Wallis 检验？或者我是否需要将数据视为依赖的，因为尽管动物的采样没有放回，但它们来自同一种群？如果是后者，我们是不是说，虽然没有对任何动物进行过采样，但移除一个个体在理论上可能会影响种群中另一个动物的病毒感染？可以将数据的时间方面视为独立的吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658163/ecological-temporal-statistical-analysis-question</guid>
      <pubDate>Mon, 02 Dec 2024 18:40:25 GMT</pubDate>
    </item>
    <item>
      <title>使用调查包计算 glm 模型时 R 平方的替代方法</title>
      <link>https://stats.stackexchange.com/questions/658161/alternative-to-r-squared-when-calculating-glm-model-using-survey-package</link>
      <description><![CDATA[我正在使用欧洲社会调查撰写我的硕士论文。数据需要加权，因此我必须使用 survey 包及其 svyglm 函数进行回归分析，而不是使用普通的 lm（我正在使用 R/RStudio）。回归本身运行良好，但是 svyglm 没有给出 R 平方的任何值。那么这里最好的解决方法是什么？
我读过关于伪 R 平方的文章（这也是 ChatGPT 建议的哈哈），但我认为它基于最大似然。但是，当尝试计算 Nagelkerkes R 平方时，RStudio 向我发出了一条警告消息，我的 svyglm 对象未使用最大似然计算。我没有在回归调用中指定任何非高斯族参数，因为我想计算一个线性模型，这就是文档建议的这里
尽管如此，我还是得到了一个值，但它与没有加权的 lm 模型中的值有很大不同：没有权重和抽样设计，R 平方为 0.03，从 svyglm 模型计算出的 Nagelkerkes R 平方为 0.79。即使加权改变了这个值，但如此巨大的差异肯定是这里出了问题。
你在这里建议什么方法？我应该坚持使用伪 R 平方吗？如果是，那用哪一个？或者我应该尝试提取残差平方和和总平方和来手动计算标准 R 平方？
感谢您的建议！
PS：对于那些说我应该跳过它的人：在之前的一篇论文中，我的讲师批评我在使用调查包时没有报告 R 平方。所以我必须找到一种方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/658161/alternative-to-r-squared-when-calculating-glm-model-using-survey-package</guid>
      <pubDate>Mon, 02 Dec 2024 18:02:18 GMT</pubDate>
    </item>
    <item>
      <title>当一个变量具有季节性而另一个变量不具有季节性时，协整</title>
      <link>https://stats.stackexchange.com/questions/658158/cointegration-when-one-variable-is-seasonal-and-another-is-not</link>
      <description><![CDATA[我有两个变量：一个具有 12 个月的季节性模式，另一个是季节性调整的。我需要进行 10 年的长期预测。为此，如果存在协整，可以尝试误差修正模型。
这些经验策略是否有效？

在协整方程中使用季节性（作为因变量）和非季节性（独立变量）？在这种情况下，残差可能是具有季节性模式的白噪声。那么，它们不是平稳的吗？

估计与季节性虚拟变量（类似于控制变量）的协整关系。在这种情况下，我的残差表现出与均衡水平的波动，并且可以是平稳的。


我发现的大多数论文在 ECM 模型的预测中都使用季节性序列或季节性调整。如果我需要预测因变量的趋势和季节性波动怎么办……]]></description>
      <guid>https://stats.stackexchange.com/questions/658158/cointegration-when-one-variable-is-seasonal-and-another-is-not</guid>
      <pubDate>Mon, 02 Dec 2024 17:22:31 GMT</pubDate>
    </item>
    <item>
      <title>对PCA的质疑：为什么载荷常常被忽视？</title>
      <link>https://stats.stackexchange.com/questions/658157/doubts-about-pca-why-are-loadings-often-overlooked</link>
      <description><![CDATA[我对 PCA 的存在性存有疑虑。我经常看到它用于遗传学，在遗传学中，你研究的基因组可能你并不完全了解它们的功能。在这种情况下，PCA 用于捕获数据集中的潜在变异性并生成新的不相关变量（主成分）。
但是，当将 PCA 应用于具有已知有形变量的数据集时（尤其是当目标是降低维度或可视化异常值时），我注意到很少对这些变量的负载进行后续分析。在我的特定情况下，我使用有形变量，并且我经常有兴趣了解它们之间的关系以及它们在成分中的权重。然而，在大多数研究中，我只发现解释方差的百分比，仅此而已。
这让我很疑惑：为什么不更多地强调解释负载？载荷对于理解原始变量的行为方式及其对主成分的贡献是否不重要？对我来说，载荷对于解释变量之间的关系以及确定它们对变异性的影响似乎至关重要。我是否遗漏了什么，或者这只是 PCA 分析中一个未被充分探索的领域？
我希望我的问题有意义。提前感谢您的见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/658157/doubts-about-pca-why-are-loadings-often-overlooked</guid>
      <pubDate>Mon, 02 Dec 2024 17:07:52 GMT</pubDate>
    </item>
    <item>
      <title>从 R 中的多个 ROC 曲线中选择最佳预测因子</title>
      <link>https://stats.stackexchange.com/questions/658159/select-best-predictor-from-multiple-roc-curves-in-r</link>
      <description><![CDATA[这是我的数据
structure(list(USI3 = structure(c(2L, 1L, 2L, 2L, 1L, 2L, 1L, 
1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L), levels = c(&quot;non&quot;, 
&quot;oui&quot;), class = &quot;factor&quot;), SBEcl3 = structure(c(4L, 3L, 3L, 1L, 
3L, 4L, 4L, 1L, 2L, 4L, 4L, 2L, 1L, 4L, 2L, 2L, 3L, 2L, 4L, 4L
), levels = c(&quot;Q3&quot;, &quot;Q1&quot;, &quot;Q2&quot;, &quot;Q4&quot;), 类 = &quot;因素&quot;), VBEcl3 = 结构(c(3L, 
2L, 1L, 3L, 1L, 3L, 3L, 1L, 2L, 3L, 3L, 2L, 1L, 3L, 2L, 2L, 1L, 
2L, 3L, 3L), 级别 = c(&quot;Q2&quot;, &quot;Q1&quot;, &quot;Q3&quot;), 类 = &quot;因素&quot;), 
SOFA3 = 结构(c(1L, 2L, 3L, 3L, 1L, 3L, 2L, 3L, 3L, 1L, 
2L, 2L, 2L, 1L, 2L, 3L, 1L, 2L, 2L, 2L), 水平 = c(&quot;Q1&quot;, 
&quot;Q2&quot;, &quot;Q3&quot;), 类别 = &quot;因子&quot;, LACTATES3 = 结构(c(2L, 
3L, 1L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 2L, 1L, 1L, 3L, 
3L, 3L, 1L, 1L), 水平 = c(&quot;Q1&quot;, &quot;Q2&quot;, &quot;Q3&quot;), 类别 = &quot;因子&quot;, 
SBE3 = c(5.88755625371722, -5.83367949101861, -5.16855590395164, 
    1.94584567145157、-4.46237190410756、2.92799867956303、6.99250801087927、 
    0.414319711015225、-16.1438604651896、5.80900771418004、5.08271450621078、 
    -7.1973116153256、-1.30327738092311、4.05722685252242、-15.2431163349488、 
-18.1380051674948, -4.84876594310452, -11.5092300657808, 
9.46936571654563, 16.4607368929384), VBE3 = c(4.83306549999999, 
-5.17690968000001, -3.96411408000001, 4.33224666999999, -3.45727284, 
1.75496799999999, 7.36360999999999, 0.618853640000002, -17.29309464, 
    5.33871410999998、6.48677951999998、-4.91616858000001、-0.740172520000016、 
    6.13709857999999、-15.35942096、-18.24841597、-3.61614233000002、 
    -12.1641, 10.34413375, 19.15572), SOF3 = c(2, 5, 6, 6, 2, 
    6, 4, 8, 14, 1, 3, 5, 3, 2, 4, 11, 2, 5, 4, 4), LACT3 = c(1.9, 
3.4, 1.4, 0.8, 1.9, 18.4, 0.5, 2.2, 10.8, 0.8, 2.4, 7.1, 
1.9, 1.5, 1.1, 19, 3.1, 4.7, 1.1, 1), RL3 = 结构(c(2L, 
2L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 
1L, 2L, 1L, 1L), 水平 = c(&quot;非&quot;, &quot;是&quot;), 类别 = &quot;因子&quot;), 
OXYGENE3 = 结构（c（2L，2L，2L，2L，1L，2L，2L，2L，1L， 
2L，2L，2L，2L，1L，1L，2L，1L，2L，1L，2L，2L），级别 = c（“非”， 
“是”），类 = “因素”），NEW3 = c（5，6，8，6，2，11，6， 
7，6，7，12，5，10，2，1，10，5，4，4，8），AGE3 = c（88，53， 
71，73，58，71，83，77，58，77，35，75， 57, 64, 68, 52, 58, 
81, 78, 77), ATB3 = 结构(c(2L, 2L, 1L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L), 水平 = c(&quot;非&quot;, 
&quot;是&quot;), 类别 = &quot;因素&quot;), SEXE3 = 结构(c(1L, 1L, 2L, 
2L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L, 
1L, 1L), levels = c(&quot;Femme&quot;, &quot;Homme&quot;), class = &quot;factor&quot;)), row.names = c(NA, 
20L), class = &quot;data.frame&quot;)

#Packages
library(ggplot2)
library(dplyr)
library(caret)
library(plotROC)
library(pROC)
library(ROCR)

#3 回归模型
modele1 &lt;- glm(USI3 ~ SBEcl3 + AGE3 + SEXE3 + RL3 + ATB3 + OXYGENE3 + NEW3 , data = data3, family = binomial)
modele2 &lt;- glm(USI3 ~ LACTATES3 + AGE3 + SEXE3 + RL3 + ATB3 + OXYGENE3 + NEW3 , data = data3, family = binomial)
modele3 &lt;- glm(USI3 ~ SOFA3 + AGE3 + SEXE3 + RL3 + ATB3 + OXYGENE3 + NEW3 , data = data3, family = binomial)

#预测模型
predict(modele1)
predict(modele2)
predict(modele3)

#3 ROC 曲线
rocs &lt;- list()
rocs[[&quot;modele1&quot;]] &lt;- roc(data3$USI3, predict(modele1))
rocs[[&quot;modele2&quot;]] &lt;- roc(data3$USI3, predict(modele2))
rocs[[&quot;modele3&quot;]] &lt;- roc(data3$USI3, predict(modele3))
ggroc (rocs, legacy.axes = TRUE)

#Results

我想确定预测 USI 入院风险（USI3）的最佳判别分数（SBE3、LACT3、SOF3）。我将这些连续变量转化为定性变量，并将它们纳入我的模型中。我从我的回归模型中做出预测，这些预测非常差（AUC1 = 0.74，AUC2 = 0.72，AUC3 = 0.79)。
这种方法对你来说合适吗？如何有更好的预测？你还有其他方法可以建议给我吗？如何使用ROC曲线分析提前选择ICU入院的不同预测因素的阈值？
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658159/select-best-predictor-from-multiple-roc-curves-in-r</guid>
      <pubDate>Mon, 02 Dec 2024 16:54:32 GMT</pubDate>
    </item>
    <item>
      <title>在 R 函数 rank_trace 中，是否存在一个共同的阈值来接受排名？</title>
      <link>https://stats.stackexchange.com/questions/658156/in-the-r-function-rank-trace-does-there-exist-a-common-threshold-value-to-accep</link>
      <description><![CDATA[在用于降阶回归的 R 包 rrr（文档）中，有一个函数 rank_trace。
它返回一个图，其中回归系数矩阵的每个秩都对应一个点。
通常，如果该点接近原点$(0,0)$，那么我们更希望这个等级是可以接受的。
我的问题是，例如在$p$值中，如果$p&gt;0.05$，即$0.05$是$p$的阈值，我们通常愿意接受一个假设。
尽管我知道这个界限不是通用的，但我仍然想知道，在处理数据（例如，来自试验）时，$\max\{x,y\}$是否存在任何共同的阈值，其中$(x,y)$是对应于某个等级的点，可以接受这个等级？]]></description>
      <guid>https://stats.stackexchange.com/questions/658156/in-the-r-function-rank-trace-does-there-exist-a-common-threshold-value-to-accep</guid>
      <pubDate>Mon, 02 Dec 2024 16:31:36 GMT</pubDate>
    </item>
    <item>
      <title>“最近 k 个合作伙伴”的抽样分布</title>
      <link>https://stats.stackexchange.com/questions/658155/sampling-distribution-for-most-recent-k-partners</link>
      <description><![CDATA[我正在尝试开发一个贝叶斯模型，以了解在分层为群体的人群中，伙伴关系如何形成/结束。挑战：我们只有最近 $k=3$ 个合作伙伴（非代表性样本 - 但那是另一个故事）的数据（群体成员、持续时间以及合作关系是否持续）。这是我目前所得到的（问题在最后）：

让 $N_i$ 为 $i$ 组的真实人口规模。
让 $f_{ij}$ 为 $i$ 组中的个人与 $j$ 组中的个人建立伙伴关系的平均每人比率。

那么 $F_{ij} = f_{ij} N_i = f_{ji} N_j$ 就是在人口层面形成伙伴关系的总比率，它是对称的（尽管 $f_{ij}$ 不是）。


让 $d_{ij}$ 成为 $i$ 组和 $j$ 组之间伙伴关系的平均持续时间（必须是对称的）。

那么 $X_{ij} = f_{ij} d_{ij}$ 就是对于组 $i$ 中的每个个体，与 $j$ 建立积极伙伴关系的预期数量。



问题：对于组 $i$ 中的个体，我们如何定义概率分布 $\theta_{j|i,k}$，从而得到组索引 $j$ 的“最近”事件？ $k=3$ 合作伙伴会被抽签吗？
假设：是否只是：
$j~\sim~\theta_{j|i,k} = \frac{X_{ij}}{\sum_j X_{ij}}$
不依赖于$k$？我还担心这不会使用任何有关合作关系是否持续的信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/658155/sampling-distribution-for-most-recent-k-partners</guid>
      <pubDate>Mon, 02 Dec 2024 16:26:20 GMT</pubDate>
    </item>
    <item>
      <title>使用 PC 分数对存在/不存在数据进行建模</title>
      <link>https://stats.stackexchange.com/questions/658153/modelling-presence-absence-data-with-pc-scores</link>
      <description><![CDATA[我有一些动物数量与环境变量的 PCA 分数的数据，如下所示。计数数据中的 .5 是因为有两个人计数，然后我们取了平均值。
 data &lt;- data.frame(
pc1 = c(0.1, 0.3, 0.5, 2.7, 0.9, 1.1, 0.3, 1.5, 1.7, 2.9),
pc2 = c(3.1, 1.3, 2.7, 2.7, 2.1, 1.3, 2.3, 3.5, 1.7, 3.9),
count = c(0,1.5, 0, 0, 2.5, 0, 0, 1, 0.5, 0)
)

我想测试 PC 分数（环境变量）是否对计数有影响。
我使用：
lm.count &lt;- lm(count ~ pc1 + pc2, data)
summary (lm.count)

输出：
调用：
lm(formula = count ~ pc1 + pc2, data)

残差：
最小值 1Q 中位数 3Q 最大值 
-1.3547 -0.3614 -0.2009 0.5609 1.8412 

系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 1.300000 0.241209 5.390 0.000163 ***
pc1 0.004687 0.158655 0.030 0.976920 
pc2 -0.118962 0.170177 -0.699 0.497848 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：12 个自由度上的 0.9342
多重 R 平方：0.0392，调整后的 R 平方：-0.1209
F 统计量：2 和 12 DF 上的 0.2448，p 值：0.7867

但我想知道大量的零计数信息是否会扭曲数据并意味着使用此模型是不正确的。 Chat GTP 建议我尝试使用逻辑模型来表示存在和不存在：
logistic_model &lt;- glm(count &gt; 0 ~ pc1 + pc2, family = binomial, data = data)
summary(logistic_model)

输出：
调用：
glm(formula = count &gt; 0 ~ pc1 + pc2, family = binomial, data = data)

偏差残差：
最小 1Q 中位数 3Q 最大 
-2.2854 0.3479 0.5064 0.5594 0.7567 

系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 1.98844 0.83717 2.375 0.0175 *
pc1 0.37118 0.52065 0.713 0.4759 
pc2 0.05496 0.52303 0.105 0.9163 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（二项式系列的分散参数取为 1）

零偏差：14 个自由度上的 11.780
残差偏差：12 个自由度上的 11.239
AIC：17.239

Fisher 评分迭代次数：5

这样好些了吗？模型摘要完全不显著，但当将模型预测与 PC1 轴绘制在一起时，相关性几乎完美。所以我确信有些事情出错了。。
这是代码（最后是真实数据图）：
predicted_probs &lt;- predict(logistic_model, type = &quot;response&quot;)
data$predicted_probs &lt;- predict_probs

plot(data$pc1, data$predicted_probs,
xlab = &quot;pc1&quot;, ylab = &quot;Predicted Probability of counts &gt; 0&quot;,
main = &quot;Logistic Regression: Predicted Probability vs PC1&quot;,
pch = 19, col = &quot;blue&quot;)

我觉得模型重要性和绘制的预测之间的不匹配表明有些事情出错了。也许模型是正确的，但绘图是错误的？或者反过来。但如果没有相关性，我预计图中的点会到处都是。
这是图：
]]></description>
      <guid>https://stats.stackexchange.com/questions/658153/modelling-presence-absence-data-with-pc-scores</guid>
      <pubDate>Mon, 02 Dec 2024 16:19:25 GMT</pubDate>
    </item>
    </channel>
</rss>