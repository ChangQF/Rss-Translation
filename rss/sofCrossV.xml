<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 31 Aug 2024 03:16:41 GMT</lastBuildDate>
    <item>
      <title>谱分解后无法反转“重组”矩阵</title>
      <link>https://stats.stackexchange.com/questions/653655/cannot-invert-recomposed-matrix-after-spectral-decomposition</link>
      <description><![CDATA[请耐心听我说完，因为我对线性代数了解不多，对数值线性代数了解就更少了。我正在尝试编写一个 R 函数，该函数在某个时候分解样条基的惩罚矩阵，使得 $K = LL&#39;$。可以使用此矩阵 $L$ 将样条基分解为惩罚部分和非惩罚部分，其中惩罚部分通过计算 $XL(L&#39;L)^{-1}$ 形成，其中 $X$ 是样条基。分解 $K = L&#39;L$ 通常是解析式，但我尝试使用 R 中的 eigen() 函数，通过取 $Q\Lambda^{1/2} = L$ 对任何惩罚矩阵执行此操作。但是，R 抱怨计算 $(L&#39;L)^{1/2}$ 不起作用（系统是计算奇异的），即使我知道 L 的实际形式，并且 $(L&#39;L)^{1/2}$ 肯定是可逆的。
尝试通过 SVD 进行分解也没有用。由于惩罚矩阵不是正定的，因此 cholesky 分解也不起作用。我发现的一个解决方法是使用“Matrix”包中的 nearPD() 函数。在我做的一个小模拟中，这个函数运行得很好，但我不知道它是否适用于更复杂的惩罚矩阵。这里是否有任何准确或被认为是良好实践的方法，可以分解 $K$，以便计算 $(L&#39;L)^{1/2}$？
代码示例：
# 库
library(splines2)
library(Matrix)

# 一些数据
x &lt;- rnorm(10000)
xs &lt;- bSpline(x, df = 22, 截距 = TRUE)

# 构建差异和惩罚矩阵
diff_mat &lt;- t(matrix(c(rep(c(1, -2, 1, rep(0, ncol(xs) - 2)), ncol(xs) - 3), 1, -2, 1), ncol = ncol(xs) - 2))
penalty_mat &lt;- t(diff_mat) %*% diff_mat

# 谱分解
p_eig &lt;- eigen(penalty_mat)
p_diff &lt;- p_eig$vectors %*% sqrt(diag(p_eig$values))

# 这不起作用
pen_mat &lt;- p_diff %*% resolve(t(p_diff) %*% p_diff)

# 这确实有效
pen_mat &lt;- p_diff %*% resolve(nearPD(t(p_diff) %*% p_diff)$mat)
]]></description>
      <guid>https://stats.stackexchange.com/questions/653655/cannot-invert-recomposed-matrix-after-spectral-decomposition</guid>
      <pubDate>Sat, 31 Aug 2024 01:38:45 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯估计和有偏估计</title>
      <link>https://stats.stackexchange.com/questions/653653/bayesian-estimation-and-biased-estimators</link>
      <description><![CDATA[我刚刚学习了非贝叶斯与贝叶斯参数估计。我自己的总结：
非贝叶斯：当参数的统计数据不可用时，CRLB 适用于无偏估计量，但存在有偏估计量优于无偏估计量的情况。
贝叶斯：MMSE 是条件均值，它总是无偏的。贝叶斯 CRLB 也适用于无偏估计量。因此，有偏估计量始终满足贝叶斯 CRLB 并且表现不如无偏 MMSE。
两个问题：
有人可以确认上述我的理解吗？
贝叶斯估计问题中有有偏估计量的良好激励示例吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653653/bayesian-estimation-and-biased-estimators</guid>
      <pubDate>Sat, 31 Aug 2024 01:09:18 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归下推导 MSE($\hat{\beta}$)</title>
      <link>https://stats.stackexchange.com/questions/653651/deriving-mse-hat-beta-under-linear-regression</link>
      <description><![CDATA[我能够推导出 MSE，但是推导过程中有一部分我不太明白。这是我得到的结果：
事实：

$\mathbb{E}(​​\hat{\beta})=\hat{\beta}\space$（无偏估计量）
$\text{Cov}(\hat{\beta})= \sigma^2[(X^TX)^{-1}] $

根据定义，
$$MSE = \mathbb{E}[||\hat{\beta}-\beta||^2] $$
$$= \space \mathbb{E}[(\hat{\beta}-\beta)^T(\hat{\beta}-\beta)]$$
由于 $\hat{\beta}$ 是无偏的，
$$ \boldsymbol{= \text{tr}[\text{Cov}(\hat{\beta})]} *$$
$$= \text{tr}[\sigma^2(X^T X)^{-1}]$$
$\sigma^2$ 是标量，因此可以分解出来，
$$= \sigma^2 tr[(X^T X)^{-1}] $$
我感到困惑的是行 $*$，我不确定我们是如何得到方程式 $ \text{tr}[\text{Cov}(\hat{\beta})] $。以下是我目前所理解的：
通过偏差-方差分解，
$$ \space \mathbb{E}[(\hat{\beta}-\beta)^T(\hat{\beta}-\beta)]=\mathbb{V}(\hat{\beta})+[\mathbb{E}(​​\hat{\beta})-\beta]^T[\mathbb{E}(​​\hat{\beta})-\beta]$$
我们的估计量是无偏的，因此 $\mathbb{E}(​​\hat{\beta})-\beta= 0$。因此，
$$\mathbb{E}[(\hat{\beta}-\beta)^T(\hat{\beta}-\beta)]=\mathbb{V}(\hat{\beta})$$

首先，$\mathbb{V}(\hat{\beta})$ 应该是一个标量，但对我来说这真的没什么意义，这让我想到了下一个问题...
我假设 $V(\hat{\beta}) = \text{tr}[\text{Cov}(\hat{\beta})]$。这是为什么呢？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653651/deriving-mse-hat-beta-under-linear-regression</guid>
      <pubDate>Sat, 31 Aug 2024 00:13:56 GMT</pubDate>
    </item>
    <item>
      <title>了解 XGboost 早期轮次的预测</title>
      <link>https://stats.stackexchange.com/questions/653649/understanding-predictions-from-early-rounds-of-xgboost</link>
      <description><![CDATA[我有一个数据集，我正在通过 xgboost 使用伽马回归进行建模。目标变量的平均值约为 13,000。如果我以 nrounds = 20 运行 xgb.train，我的拟合指标会得到如下改进：
[1] eval-gamma-nloglik:19068.589753 train-gamma-nloglik:19214.349747 
[2] eval-gamma-nloglik:14126.776741 train-gamma-nloglik:14234.760451 
[3] eval-gamma-nloglik:10465.869439 train-gamma-nloglik:10545.868618 
[4] eval-gamma-nloglik:7753.880010 train-gamma-nloglik:7813.146760 
[5] eval-gamma-nloglik:5744.865650 train-gamma-nloglik:5788.775051 [6] eval-gamma-nloglik:4256.630570 train-gamma-nloglik:4289.161127 [7] eval-gamma-nloglik:3154.190101 train-gamma-nloglik ：3178.297719 [8] eval-gamma-nloglik：2337.566473 train-gamma-nloglik：2355.427432 [9] eval-gamma-nloglik：1732.674952 train-gamma-nloglik：1745.907601 [10]    eval-gamma-nloglik：1284.639146 train-gamma-nloglik：1294.441921 [11] eval-gamma-nloglik：952.802399 train-gamma-nloglik：960.065419 [12] eval-gamma-nloglik：707.048396 train-gamma-nloglik： 712.430466 [13] eval-gamma-nloglik:525.066581 train-gamma-nloglik:529.055224 [14] eval-gamma-nloglik:390.324413 train-gamma-nloglik:393.284621 [15]    eval-gamma-nloglik:290.585986 train-gamma-nloglik:292.780028 [16] eval-gamma-nloglik:216.774041 train-gamma-nloglik:218.400892 [17] eval-gamma-nloglik:162.168768 train-gamma-nloglik:16 3.375479 [18] eval-gamma-nloglik:121.791626 train-gamma-nloglik:122.687146 [19] eval-gamma-nloglik:91.956086 train-gamma-nloglik:92.619277 [20] eval-gamma-nloglik:69.927169 train-gamma-nloglik:70.418368 

如果我对验证集进行预测，20 轮后该模型的平均预测为 194 - 相对于目标变量的大小（平均值为 13,000），这似乎很荒谬。直到大约 50 轮后，我才得到相对于目标变量大小的合理结果。我对算法的理解是，Tree 0 至少应该产生一个合理的模型，即使它基本上只是一个没有实际分割的截距，因为选择了一个坏变量作为它的覆盖。
我是否遗漏了关于提升树如何工作的某些内容，或者这只是一个教训，即如果 nrounds 太低，该模型基本上毫无意义，比仅截距模型更糟糕？]]></description>
      <guid>https://stats.stackexchange.com/questions/653649/understanding-predictions-from-early-rounds-of-xgboost</guid>
      <pubDate>Fri, 30 Aug 2024 21:01:01 GMT</pubDate>
    </item>
    <item>
      <title>“Fisher 互相关变换”的含义</title>
      <link>https://stats.stackexchange.com/questions/653647/meaning-of-fisher-transformation-of-cross-correlations</link>
      <description><![CDATA[我正在阅读一篇论文，其中指出（https://www.nature.com/articles/s41598-023-41960-2）：

在 SUSY 中，互相关是分段计算的；时间序列被切成例如 30 秒持续时间的段，并且每个段内的互相关是在一定范围的滞后 L 内计算的。许多研究中的默认值是选择最大滞后高达 ± 3 s 或 ± 5 s，以便考虑 6 秒或 10 秒窗口内的所有互相关，即互相关范围 L。段大小和窗口大小是 SUSY 中的基本参数。因此，这种操作化包括同时（L = 0）相关以及时间滞后的（交叉）相关。为了允许聚合，所有交叉相关都必须使用 Fisher 的 Z 变换进行转换。

我不确定我是否理解从交叉相关到 Fisher 的 Z 变换的跳跃：Fisher 的变换不是基于 Pearson 相关系数吗？将 Fisher 的 Z 变换应用于交叉相关意味着什么？特别是，Fisher 的 Z 变换实际上只对 -1 和 1 之间的 R 值有意义，而交叉相关系数的情况并非如此。]]></description>
      <guid>https://stats.stackexchange.com/questions/653647/meaning-of-fisher-transformation-of-cross-correlations</guid>
      <pubDate>Fri, 30 Aug 2024 19:46:23 GMT</pubDate>
    </item>
    <item>
      <title>Kendall tau-c 永远不可能是 1？</title>
      <link>https://stats.stackexchange.com/questions/653646/kendall-tau-c-can-never-be-1</link>
      <description><![CDATA[我有一个按 5 分制评分的系统（4=非常好，3=好，2=一般，1=差，0=非常差）。现在，我想将它们转换为二进制分数，所以我想设置一个阈值，然后将它们转换为 1/0 分数。我的直觉是，5 分制分数和二进制分数应该始终具有完美的等级相关性，即等级相关性为 1。（信息丢失是另一回事。）
我使用 Kendall tau-c，因为它旨在测量不同数量的可能结果（5 对 2）之间的等级相关性。但我发现在以下最简单的例子中，相关性并不相同，并且远离 1。
print(scipy.stats.kendalltau([0, 0, 0, 0, 1], [0, 1, 2, 3, 4], variant=&#39;c&#39;)) # 1 if &gt;= 4 and 0 o.w.
print(scipy.stats.kendalltau([0, 0, 0, 1, 1], [0, 1, 2, 3, 4], variant=&#39;c&#39;)) # 1 if &gt;= 3 and 0 o.w.
打印（scipy.stats.kendalltau（[0, 0, 1, 1, 1]，[0, 1, 2, 3, 4]，variant=&#39;c&#39;））# 1 如果 &gt;= 2 且 0 o.w.
打印（scipy.stats.kendalltau（[0, 1, 1, 1, 1]，[0, 1, 2, 3, 4]，variant=&#39;c&#39;））# 1 如果 &gt;= 1 且 0 o.w.

输出
SignificanceResult(statistic=0.64, pvalue=0.15729920705028516)
SignificanceResult(statistic=0.96, pvalue=0.0832645166635504)
SignificanceResult(statistic=0.96, pvalue=0.0832645166635504)
SignificanceResult(statistic=0.64, pvalue=0.15729920705028516)

这似乎表明，无论我如何调整阈值或设计二进制转换器，我都无法使 Kendall tau-c 达到 1。我完全理解 Kendal tau-b 不应该是 1情况，但我的理解是，矩形调整的目标是纠正这种情况，以便相关性在完美情况下可以达到 1。
这是一个错误还是一个功能？并且，还有其他一些等级相关性变体可以在这种情况下产生 1 的相关性？]]></description>
      <guid>https://stats.stackexchange.com/questions/653646/kendall-tau-c-can-never-be-1</guid>
      <pubDate>Fri, 30 Aug 2024 19:45:11 GMT</pubDate>
    </item>
    <item>
      <title>Y 值不确定的模型</title>
      <link>https://stats.stackexchange.com/questions/653642/models-with-uncertainty-in-y</link>
      <description><![CDATA[假设我有变量 y 的预测因子 x1、x2、x3...xn 的数据。我基本上使用贝叶斯分析估算了 y，这意味着我对 y 的每个值都有一个后验分布。为了计算从 x1 到 xn 预测 y 的后续模型，同时保持 y 的不确定性，我通常会使用 brms 包中的 brm_multiple 函数之类的函数，它允许我们从后验分布的不同 y 值计算相同的模型，然后最后将它们组合成相同的模型。不幸的是，我有太多数据，贝叶斯方法不可行。
我该如何用频率统计做类似的事情？有没有办法运行一堆模型，然后在最后合并这些模型，或者可能将每个 y 作为原始模型中的分布，等等？
以下是 R 代码，用于生成采用我所说的形式的玩具数据集：
# 设置种子以实现可重复性
set.seed(42)

# 使用预测器创建玩具数据
n &lt;- 100
x1 &lt;- rnorm(n)
x2 &lt;- rnorm(n, mean = 3)
x3 &lt;- rnorm(n, mean = -2)

# 模拟 y 的后验样本（例如，来自后验分布的 5 个样本）
y_post_1 &lt;- 2 + 1.5*x1 - 0.7*x2 + 0.5*x3 + rnorm(n)
y_post_2 &lt;- 2 + 1.5*x1 - 0.7*x2 + 0.5*x3 + rnorm(n)
y_post_3 &lt;- 2 + 1.5*x1 - 0.7*x2 + 0.5*x3 + rnorm(n)
y_post_4 &lt;- 2 + 1.5*x1 - 0.7*x2 + 0.5*x3 + rnorm(n)
y_post_5 &lt;- 2 + 1.5*x1 - 0.7*x2 + 0.5*x3 + rnorm(n)

# 合并为一个数据框
toy_data &lt;- data.frame(x1, x2, x3, y_post_1, y_post_2, y_post_3, 
y_post_4, y_post_5)

# 显示数据集的前几行
head(toy_data)
]]></description>
      <guid>https://stats.stackexchange.com/questions/653642/models-with-uncertainty-in-y</guid>
      <pubDate>Fri, 30 Aug 2024 18:46:37 GMT</pubDate>
    </item>
    <item>
      <title>对不平衡样本进行加权以反映人口分布</title>
      <link>https://stats.stackexchange.com/questions/653637/weighting-imbalanced-sample-to-reflect-population-distribution</link>
      <description><![CDATA[我有一个具有某些特征（V1 ~ 地区，V2 ~ 职业类型）的人口（pop），所有预测因子都是分类的。我有另一个数据集，其中仅包含人口的一部分~ 50%，并带有指示变量（例如家庭收入 - 连续，财产所有权 - 二元）。链接 2 个数据集后，最终样本（样本）的 V1 和 V2 交集分布与人口（d1，d2）不同，因此样本和人口在指示变量上的汇总统计数据不同。这对分析来说是个问题，所以我需要以某种方式平衡样本，使变量 V1 和 V2 的交集相似。
有人告诉我，我不应该从样本中删除数据，而是要为样本中的实例分配权重，但我不知道该怎么做。有什么好的统计方法可以做到这一点吗？
感谢您的帮助。
pop &lt;- do.call(cbind.data.frame, list(sample(c(&quot;a&quot;, &quot;b&quot;), 
replace = TRUE, size = 200, prob = c(0.5, 0.5) ), 
sample(c(&quot;d&quot;, &quot;e&quot;), replace = TRUE, size = 200, 
prob = c(0.5, 0.5)), 
sample(c(&quot;g&quot;, &quot;h&quot;), replace = TRUE, size = 200, 
prob = c(0.5, 0.5) ) ))

colnames(pop) &lt;- c(&quot;V1&quot;, &quot;V2&quot;)

sample &lt;- do.call(cbind.data.frame, 
list(sample(c(&quot;a&quot;, &quot;b&quot;), replace = TRUE, size = 100, 
prob = c(0.7, 0.3) ), 
sample(c(&quot;d&quot;, &quot;e&quot;), replace = TRUE, size = 100, 
prob = c(0.3, 0.7)), 
sample(c(&quot;g&quot;, &quot;h&quot;), replace = TRUE, size = 100, 
prob = c(0.5, 0.5) ) ))

colnames(sample) &lt;- c(&quot;V1&quot;, &quot;V2&quot;)

d1 &lt;- prop.table(table(paste0(pop$V1, pop$V2)))

d2 &lt;- prop.table(table(paste0(sample$V1, sample$V2)))
]]></description>
      <guid>https://stats.stackexchange.com/questions/653637/weighting-imbalanced-sample-to-reflect-population-distribution</guid>
      <pubDate>Fri, 30 Aug 2024 17:46:01 GMT</pubDate>
    </item>
    <item>
      <title>这是在同一维度上使用许多不同评估进行聚类的正确方法吗？</title>
      <link>https://stats.stackexchange.com/questions/653643/is-this-the-right-approach-to-cluster-using-many-different-evaluations-on-the-sa</link>
      <description><![CDATA[我正在做一个项目，想把政党分成两组。我想利用调查中许多受访者的回答，他们指出了每个政党在左右尺度上的位置。我对我的数据使用了 k 均值聚类，得到了非常合理的工作结果。但是，鉴于我对任何类型的聚类方法都很陌生，而且我在网上找不到任何在聚类中处理类似数据结构的示例，我想确保我做的是正确的。所以，我的问题是：

下面的方法是否是处理我的数据格式的有效方法？
我现在使用的是两个集群，这是我想要的，但我也想确保我没有完全偏离将政党强行放入它们不适合的集群。有没有办法在事后验证集群的数量？我熟悉肘形图和其他估计理想聚类数的方法，但我正在寻找一种方法来评估/评分我已经完成的聚类。

# Party Dataset
df &lt;- data.frame(&quot;Party A&quot; = c(2,3,4,3,3),
&quot;Party B&quot; = c(3,3,4,5,4),
&quot;Party C&quot; = c(4,5,6,7,6),
&quot;Party D&quot; = c(5,6,7,8,7),
&quot;Party E&quot; = c(6,7,8,NA,8))

# Transpose Dataframe
df &lt;- as.data.frame(t(df)) %&gt;% 
mutate_all(as.numeric) 

#找出所有缺失值
ind &lt;- which(is.na(df), arr.ind=TRUE)
# 用行均值替换
df[ind] &lt;- rowMeans(df, na.rm = TRUE)[ind[,1]]

# 删除空行
df &lt;- na.omit(df)

# 缩放
df &lt;- scale(df)

# 删除缩放数据中缺失值的案例
t &lt;- t[,colSums(is.na(t))&lt;nrow(t)]

# 使用 2 个 kmeans 中心进行聚类
km.res &lt;- kmeans(df, 2, nstart = 25)
]]></description>
      <guid>https://stats.stackexchange.com/questions/653643/is-this-the-right-approach-to-cluster-using-many-different-evaluations-on-the-sa</guid>
      <pubDate>Fri, 30 Aug 2024 16:28:01 GMT</pubDate>
    </item>
    <item>
      <title>基于模拟随机事件概率平均值的预期泊松二项分布</title>
      <link>https://stats.stackexchange.com/questions/653630/expected-poisson-binomial-distribution-based-on-average-of-simulated-random-even</link>
      <description><![CDATA[设置
设$Y(t)$为一个随时间变化的随机变量$t=\{1,...,T\}$，$g$为一个非线性函数，$g(Y(t))\in(0,1)$，$\{n_{t}\}_{t=1}^{T}$为每个时间戳$t$的观测次数。
在每个时间戳$t$，根据一个二项分布为 $f_{B}(x,n_{t},g(Y(t)))={n_{t}\choose x}g(Y(t))^{x}(1-g(Y(t)))^{n-x}$，因此在所有时间戳 $t=\{1, \dotsc,T\}$ 中总共发生 $x$ 个事件的概率为 $t=\{1, \dotsc,T\}$ 为 $$f_{B}(x,\{n_{t}\}_{t=1}^{T},\{g(Y(t))\}_{t=1}^{T})=f_{B}(\cdot,n_{1},g(Y(1)))*\cdots*f_{B}(\cdot,n_{T},g(Y(T)))(x)=(*)_{t=1}^{T}f_{B}(\cdot,n_{t},g(Y(t)))(x)$$ 目前，$f_{B}(x,\{n_{t}\}_{t=1}^{T},\{g(Y(t))\}_{t=1}^{T})$ 由 $M$ 次模拟 $Y(t)$，针对每个时间戳 $t$，并取平均值 $$f_{B}(x,\{n_{t}\}_{t=1}^{T},\{g(Y(t))\}_{t=1}^{T})=\frac{1}{M}\sum_{m=1}^{M}(*)_{t=1}^{T}f_{B}(\cdot,n_{t},g(Y_{m}(t)))(x)\stackrel{?}{=}\mathbb{E}\{(*)_{t=1}^{T}f_{B}(\cdot,n_{t},g(Y_{m}(t)))(x)\}$$
现在，由于 $g(\cdot)=\Phi(\cdot)$（遵循多周期 Vasicek 模型），我发现$g(Y(t))=\Phi(Y(t))$ 具有确定性闭式表达式 $h(t)$，因此似乎可以直接计算所有时间戳上 $x$ 事件的概率。
问题
因此，我的问题是，以下等式是否成立，为什么（不成立）？ $$\frac{1}{M}\sum_{m=1}^{M}(*)_{t=1}^{T}f_{B}(\cdot, n_{t}, g(Y_{m}(t)))(x)\stackrel{?}{=}(*)_{t=1}^{T}f_{B}(\cdot, n_{t}, h(t))(x)$$ 因为 $\mathbb{E}\{\theta(X)\}\neq\theta(\mathbb{E}\{X\})$ 对于任何非线性函数 $\theta(\cdot)$ 我怀疑上述等式是否成立，因为输入 $g(Y_{m}(t))$ 转换为 $f_{B}(\cdot,n_{t},g(Y_{m}(t)))$ 是复杂的，而且明显是非线性的。另一方面，目前似乎正在采用标量的期望，而当前方法从一开始就是错误的。
R 中的回测
下面的 R 中的回测（可以在基础 R 中运行）似乎表明上述等式不成立。
# 通过卷积计算泊松二项分布的函数
convolve.binomial &lt;- function(p) {
n &lt;- length(p) + 1
z &lt;- c(1, rep(0, n-1))
for (p in p) z &lt;- (1-p)*z + p*c(0, z[-n])
return(z)
}

N &lt;- seq(1:10) # 每年的观察次数从 1 增加到 10
T &lt;- length(N) # 数量年
M &lt;- 1e6 # 假设 1e6 足够，则模拟次数

# 驱动非线性函数 h(t) = p_vas 的变量
p &lt;- 0.25
gamma &lt;- 0.20
rho &lt;- 0.12
x0 &lt;- -2 # 类似于 t_{0} = 0 时的衰退
alpha &lt;- 1 / sqrt(1 - rho)
beta &lt;- sqrt(rho) * alpha

# 闭式时间点违约概率 h(t)
p_vas &lt;- pnorm((alpha * qnorm(p) - beta * x0 * gamma ^ (1:T)) / 
sqrt(1 + beta ^ 2))

# 通过基于闭式时间点的周期分布 
# 违约概率
p_vas_dist &lt;- convolve.binomial(rep(p_vas, N))

# 模拟违约时间点概率
p_sim &lt;- x &lt;- matrix(rep(0, M * T), M, T)
p_sim_dist &lt;- matrix(rep(0, M * (sum(N) + 1)), M, sum(N) + 1)

# t_{1} = 1 的模拟
x[, 1] &lt;- rnorm(M, gamma * x0, 1)
p_sim[, 1] &lt;- pnorm((qnorm(p) - sqrt(rho) * x[,1]) / sqrt(1 - rho))

# t_{2} = 2, \dotsc, t_{N} = T 的模拟
for(j in 2:T){
for(i in 1:M){
x[i,j] &lt;- x[i,j - 1] * gamma + sqrt(1 - gamma ^ 2) * rnorm(1)
}
p_sim[,j] &lt;- pnorm(alpha * qnorm(p) - beta * x[,j])
}

# 根据模拟时间点计算周期分布
# 违约概率
for(i in 1:M){
p_sim_dist[i,] &lt;- convolve.binomial(rep(p_sim[i,], N))
}

# 根据模拟时间点计算周期分布平均值
# 违约概率
p_sim_dist &lt;- colSums(p_sim_dist) / M

(p_sim &lt;- colSums(p_sim) / M)
(p_vas)

绘图(p_vas_dist,type=&#39;l&#39;)
线(p_sim_dist) 
]]></description>
      <guid>https://stats.stackexchange.com/questions/653630/expected-poisson-binomial-distribution-based-on-average-of-simulated-random-even</guid>
      <pubDate>Fri, 30 Aug 2024 15:25:44 GMT</pubDate>
    </item>
    <item>
      <title>利用混合样本确定生物学重复</title>
      <link>https://stats.stackexchange.com/questions/653624/determining-biological-replicates-with-pooled-samples</link>
      <description><![CDATA[我们小组有一个长期存在的方案，其中汇集了多个组织纯化样本。这是因为每只动物的组织很少。然后对该池进行多次采样，并测量感兴趣的结果。每次测量都被视为推理分析的独立数据点。虽然这些单个样本可能是“重复”，但它们作为生物重复的状态充其量是高度可疑的。它们看起来可能是伪重复。
即，用两种药物治疗动物。提取的组织被合并到两个池中。每个池采样 x 次。然后通过药物治疗分析这些样品，每次治疗 n = x。
应该如何调整这种设计？目前没有办法只使用一只动物的组织进行测定。必须将组织组合起来。
如果我们使用更多动物并创建多个池，那么每个池可以采样几次，以解释因组合动物而引入的变化。这将使用混合级别模型进行建模。每个池是否都是一个单一的生物学重复，并且池中的每个样本都是随机效应内的聚类？
因此，两种治疗方法，每种治疗方法有 M 只动物。组织提取物组合成 P 个池，每个池采样 N 次。模型中每个治疗方法的 n = P，单个样本按 P 聚类。
还有其他方法可以做到这一点吗？
（这是我最近问过的一个问题的重述，但措辞不当且令人困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/653624/determining-biological-replicates-with-pooled-samples</guid>
      <pubDate>Fri, 30 Aug 2024 14:35:33 GMT</pubDate>
    </item>
    <item>
      <title>MANOVA - 单变量 Wilks 的 Lambda 检验（R 解释）</title>
      <link>https://stats.stackexchange.com/questions/653530/manova-univariate-wilks-lambda-test-r-interpretation</link>
      <description><![CDATA[我正在运行一个具有 2 个因变量和 2 个连续预测变量的 MANOVA 模型。 （仅供参考 - STATA 将此称为 MANCOVA，并要求在每个预测因子前面删除“c。”以表示每个预测因子在 manova 运行期间都是连续缩放的。无论如何，R 将直接接受连续变量，因此使用 manova 命令在 R 中运行 MANCOVA 不会出现问题） - 本质上是 MVNREG。
使用 UC-Irvine ML Repository Wine 数据集，模型为：
model &lt;- lm(cbind(alcohol, hue) ~ flavanoids + ash, 
na.action=na.exclude, data=wine)
wine.manova=manova(model)

我试图理解使用两者时 Wilks&#39; Lambda 对黄烷类化合物预测因子的 F 近似值之间的差异方法：
方法 1
library(car)
lh.out &lt;- linearHypothesis(model, 
hypothesis.matrix = c(&quot;flavanoids = 0&quot;))
lh.out

结果如下：

方法 2
以及基于命令的 Wilks 值
summary(wine.manova,&#39;Wilks&#39;)

输出为：

尽管 p 值相同，但我试图理解为什么 Wilks&#39; Lambda 的 F 值在基于所有响应变量的黄酮类化合物预测因子的两次零系数检验中有所不同。结果表明，当预测变量或因变量较多时，Wilks Lambda 的这两次计算之间的差异较大。
仅供参考 - 当将 R 与 STATA 进行基准测试时，几乎不可能在 STATA 中获得上述方法 2 下列出的表格结果，而方法 1 的结果很容易从 STATA 中获得。]]></description>
      <guid>https://stats.stackexchange.com/questions/653530/manova-univariate-wilks-lambda-test-r-interpretation</guid>
      <pubDate>Thu, 29 Aug 2024 02:58:38 GMT</pubDate>
    </item>
    <item>
      <title>如何比较多组计数数据（数百万或零，差异很大）？</title>
      <link>https://stats.stackexchange.com/questions/653526/how-do-i-compare-multiple-groups-of-count-data-that-are-either-millions-or-zero</link>
      <description><![CDATA[我有三个独立的组：治疗组、药物 1 和药物 2。对于每个组，我都有 CFU 中的细菌计数。我不太擅长统计，所以请耐心听我说。我知道我不能使用方差分析，因为分布不正常，有些计数相距很远，而且有相当多的零（虽然不是太多）。组内的方差也不相等，样本量也不相等。
我看过一些论文，建议使用负二项分布、泊松分布或其他一些分布。我的问题是：有没有针对这种情况的推荐方法？我如何比较不同类别的模型以确定哪个更好？我主要使用 R。有没有办法在 R 中测试多种方法并让它建议最佳（或接近最佳）模型？这种方法是否适合我的情况？或者我应该不要太担心并使用非参数检验？]]></description>
      <guid>https://stats.stackexchange.com/questions/653526/how-do-i-compare-multiple-groups-of-count-data-that-are-either-millions-or-zero</guid>
      <pubDate>Thu, 29 Aug 2024 01:08:06 GMT</pubDate>
    </item>
    <item>
      <title>如何使用高相关模型选择 A/B 测试样本</title>
      <link>https://stats.stackexchange.com/questions/653520/how-to-select-sample-for-a-b-testing-with-high-correlated-models</link>
      <description><![CDATA[嗨，我正在对两个机器学习模型进行 A/B 测试，这两个模型会为每个客户提供一个分数。这两个模型具有很高的相关性。我担心，如果采用模型 A，选择样本，然后选择模型 B 的样本，例如，这可能会在我的测试中产生偏差（剩余的人口将拥有低“质量”的客户，因为这两个模型具有很高的相关性）。
关于如何克服这个问题，有什么想法吗？我也很感激任何参考资料。]]></description>
      <guid>https://stats.stackexchange.com/questions/653520/how-to-select-sample-for-a-b-testing-with-high-correlated-models</guid>
      <pubDate>Thu, 29 Aug 2024 00:16:55 GMT</pubDate>
    </item>
    <item>
      <title>得到一个不显著的 log(theta) 意味着什么？</title>
      <link>https://stats.stackexchange.com/questions/653505/what-does-getting-a-non-significant-logtheta-mean</link>
      <description><![CDATA[我在 R 中运行一个简单的模型，测试鱼密度（单位体积的鱼数量）是否取决于该区域的深度。有很多区域没有鱼，所以我使用 zeroinflated 模型（R 中的包 pscl::zeroinfl）。
模型 &lt;- zeroinfl(FishDensity ~Depth, data = myData, dist = &quot;negbin&quot;, 
na.action = na.omit)

这些是结果：
计算模型系数（带对数链接的 negbin）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 5.33750 0.24254 22.007 &lt;2e-16 ***
深度 0.03446 0.01367 2.521 0.0117 * 
Log(theta) 0.08603 0.14003 0.614 0.5390 

零膨胀模型系数（带 logit 链接的二项式）：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 1.893173 0.288799 6.555 5.55e-11 ***
深度 0.007084 0.016472 0.430 0.667 

在计数模型系数中，我得到了一个不显著的 log(theta)。
这是什么意思？我应该放弃这个模型吗？
深度本身很重要。
我是统计学新手，所以请尝试用简单的术语解释它。]]></description>
      <guid>https://stats.stackexchange.com/questions/653505/what-does-getting-a-non-significant-logtheta-mean</guid>
      <pubDate>Wed, 28 Aug 2024 20:09:05 GMT</pubDate>
    </item>
    </channel>
</rss>