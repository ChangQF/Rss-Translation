<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 19 Jul 2024 03:20:28 GMT</lastBuildDate>
    <item>
      <title>Hausman 测试结果报告</title>
      <link>https://stats.stackexchange.com/questions/651380/hausman-test-reults-report</link>
      <description><![CDATA[我一直在研究一个使用多级回归模型的研究项目，目前正在研究如何呈现豪斯曼检验结果。我见过一些论文，作者提到进行测试但没有包括数字，只是说随机效应模型更合适。
我想知道在稿件中分别报告每个模型的豪斯曼检验结果是否是标准做法。我知道如果测试不显著（p &gt; 0.05），则意味着随机效应模型更合适。但我很好奇是否通常还会报告测试值和其他统计细节，如卡方值，以支持这一结论。顺便说一下，我有八个模型]]></description>
      <guid>https://stats.stackexchange.com/questions/651380/hausman-test-reults-report</guid>
      <pubDate>Fri, 19 Jul 2024 01:33:38 GMT</pubDate>
    </item>
    <item>
      <title>如何进行分部求和？</title>
      <link>https://stats.stackexchange.com/questions/651379/summation-by-parts-how</link>
      <description><![CDATA[在这个问题中
whuber 评论说，这个答案中使用的技术是分部求和：

离散情况，假设 $X \ge 0$ 取非负整数
值。然后我们可以将期望写为 $$\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\P}{\mathbb{P}} \E X = \sum_{k=0}^\infty k \P(X=k) $$ 现在，我们首先将其写为双和，然后
改变求和的顺序。观察到 $k = \sum_{j=0}^{k-1} 1$
（$k=0$ 的情况给出的上限小于下限，我们将其视为空和，即零）。这给出了 $$ 
\E X = \sum_{k=0}^\infty \sum_{j=0}^{k-1} 1 \cdot \P(X=k) $$ 现在，在这个双重和中，我们首先对 $j$ 求和，这显然等于 $\infty$。
观察到在内部求和中，指标满足不等式
$$
0 \le j \le k-1 $$ 解 $k$ 可得 $ k \ge j+1$，这又给出了新的内部和中的求和极限：$$ \E X = \sum_{j=0}^\infty \sum_{k=j+1}^\infty \P(X=k) = \sum_{j=0}^\infty \P(X &gt; j) $$ 这就是结果。连续的情况类似。

我去维基百科试图理解他的评论，但我不明白。

假设$\{f_k\}$和$\{g_k\}$是两个序列。那么，
$$
\sum_{k=m}^{n} f_k (g_{k+1} - g_k) = (f_{n+1} g_{n+1} - f_m g_m) - \sum_{k=m}^{n} g_{k+1} (f_{k+1} - f_k)。
$$

重新排列总数与分部求和有何关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/651379/summation-by-parts-how</guid>
      <pubDate>Fri, 19 Jul 2024 01:25:52 GMT</pubDate>
    </item>
    <item>
      <title>给定协方差矩阵的最大条件熵</title>
      <link>https://stats.stackexchange.com/questions/651377/max-conditional-entropy-given-a-covariance-matrix</link>
      <description><![CDATA[随机向量 $(X,Y)$ 分布在 $\mathbb{R}^n \times \mathbb{R}^m$ 上，均值为零，协方差为 $\Sigma \in \mathbb{R}^{n\times m}_+.$
哪些分布可达到 $h(Y|X)$ 的最大值？多元高斯分布就足够了吗？
病态/非标准分布是什么样子的？
类似但不完全的事实：

当且仅当 $Y$ 是联合高斯分布时，$h(Y)$ 的最大值才可达到。
在那些具有固定条件协方差 $K_{Y|X} = E[(Y-E[Y|X])(Y-E[Y|X])&#39;]$ 的 $(X,Y)$ 中，$h(Y|X)$ 的最大值在联合高斯分布中达到（El Gamal 和Kim，第 2.2 节，方程 2.7）。（充分，非必要）
如果 $m=1$，则通过联合高斯分布达到最大值。（充分，非必要）
https://tselab.stanford.edu/mirror/ee376a_winter1617/Lecture_18.pdf
]]></description>
      <guid>https://stats.stackexchange.com/questions/651377/max-conditional-entropy-given-a-covariance-matrix</guid>
      <pubDate>Thu, 18 Jul 2024 23:32:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的卡方检验的 p 值这么高？</title>
      <link>https://stats.stackexchange.com/questions/651374/why-is-my-pvalue-for-chisquared-test-so-high</link>
      <description><![CDATA[我从值 = [0, 1] 中抽样，概率 = [.25, .75]。
我得到 25019 个零和 74981 个一。然而，通过卡方检验结果如下：
statistic=0.0196，pvalue=0.889
这似乎与我的直觉不符。
也许这是使用 Fisher 精确检验的原因？我应该使用 KS 测试来获取频率吗？
这是我的代码
N = 100000
values = [np.random.choice([0, 1], p=[.25, .75]) for _ in range(N)]
one_count = sum(values)
zero_count = len(values) - one_count
test_stat = (N*.75 - one_count)**2/(N*.75) + (N*.25 - zero_count)**2/(N*.25)
print(test_stat, 1 - stats.chi2.cdf(test_stat, 1))
]]></description>
      <guid>https://stats.stackexchange.com/questions/651374/why-is-my-pvalue-for-chisquared-test-so-high</guid>
      <pubDate>Thu, 18 Jul 2024 22:58:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么第一个主成分的特征值比其余主成分高得多？</title>
      <link>https://stats.stackexchange.com/questions/651370/why-is-the-amount-of-eigenvalue-of-the-first-principal-component-is-much-higher</link>
      <description><![CDATA[我有 16 个水质参数的时间序列，在使用 zscore 方法对其进行标准化后，我进行了主成分分析。这些是我的特征值 [7.62675203795075
2.25806327090482
1.72428547604366
1.44517173004117
1.30223669986535
1.18683140226834
1.01121663757535
0.840810909788259
0.68 3733271693109
0.641289626275986
0.427483271093487
0.367733123021385
0.243180116969796
0.216284282138318
0.132868635217870
0.0705244464795644]。

可以看到，第一个主成分的特征值和其余主成分相差很大，这是我在以前的研究中没有见过的，而且是随着间隔变小而减小的。是什么因素导致了结果这样？是不是我的数据不适合做主成分分析？我还做了KMO检验，结果是0.91。]]></description>
      <guid>https://stats.stackexchange.com/questions/651370/why-is-the-amount-of-eigenvalue-of-the-first-principal-component-is-much-higher</guid>
      <pubDate>Thu, 18 Jul 2024 21:47:30 GMT</pubDate>
    </item>
    <item>
      <title>定制配电配件</title>
      <link>https://stats.stackexchange.com/questions/651369/customized-distribution-fitting</link>
      <description><![CDATA[我有一个连续手术时长的样本，想将分布拟合到这个样本，从而生成相应的随机数。使用 Python 中的 scipy 库，我可以拟合各种分布，但得到的分布通常具有较高的 SSE（平方误差和）。
我正在探索是否有任何机器学习算法可以帮助我拟合自定义分布，提供类似于适形预测模型的下限和上限区间，或提供其他相关解决方案。
注意：我已经开发了一个预测模型，可以为每个患者提供个性化的手术时长预测。我正在考虑机器学习方法是否可以为样本中的每个患者提供个性化的分布集，而不是将一般分布拟合到整个样本。原因是我相信我可以利用我掌握的每位患者的其他信息（例如年龄、健康状况、手术类型、优先级），这样我就可以为患者创建更准确的不确定性集。
您能否列出一些好的潜在选项并附上参考资料，让我阅读它们的用例和实现？]]></description>
      <guid>https://stats.stackexchange.com/questions/651369/customized-distribution-fitting</guid>
      <pubDate>Thu, 18 Jul 2024 21:30:02 GMT</pubDate>
    </item>
    <item>
      <title>预测区间准确度与均方误差之间的权衡</title>
      <link>https://stats.stackexchange.com/questions/651367/tradeoff-between-prediction-interval-accuracy-mean-squared-error</link>
      <description><![CDATA[我的目标是量化气候协变量与 GDP 回归模型中的预测不确定性。我从一个模型开始，该模型以温度作为三次多项式，国家固定效应（$\alpha_i$}，年份固定效应（$\theta_t$）和国家增量时间趋势（$\gamma_i$）。
$$ 
GDP_{it} = \beta_1 * Temp_{it} + \beta_2 * Temp^2_{it} + \beta_3 * Temp^3_{it} + \alpha_i + \theta_t + \gamma_i
$$
我使用一些保留数据来收集上述模型的样本外均方误差。我还使用样本外预测的标准误差来构建 95% 的预测间隔，然后检查实际 Y（GDP）值在这些间隔内的实际百分比作为预测间隔准确度。
样本外 MSE：0.017
预测间隔准确度：0.577

为了使预测间隔准确度更接近 95% 的目标，我尝试了一个具有更高次数多项式时间趋势的不同模型，如下所示：
$$ 
GDP_{it} = \beta_1 * Temp_{it} + \beta_2 * Temp^2_{it} + \beta_3 * Temp^3_{it} + \alpha_i + \theta_t + \gamma_i + \gamma^2_i + \gamma^3_i
$$
样本外 MSE： 0.018
预测区间准确度：0.722

由于预测区间更宽，预测区间准确度大大提高，这可能是因为模型在训练数据中纳入了更多方差。但是，可能由于额外的模型复杂性导致过度拟合，第二个模型的 MSE 高于第一个模型。
我的问题与这个特定示例关系不大，而是与我普遍观察到的这种现象关系较大。我想知道：

是否存在一个单一的潜在现象，可以解释为什么增加模型复杂度会导致预测区间更接近 95% 的目标，同时增加模型的 MSE，或者这些本质上是独立的观察结果？

如果我的目标是尽可能量化模型不确定性，那么如何正确考虑以更高质量（在这种情况下意味着更宽）的预测区间换取随后的 MSE 增加？

]]></description>
      <guid>https://stats.stackexchange.com/questions/651367/tradeoff-between-prediction-interval-accuracy-mean-squared-error</guid>
      <pubDate>Thu, 18 Jul 2024 20:44:03 GMT</pubDate>
    </item>
    <item>
      <title>如何证明 Kendall 分布函数（或 Kendall 测量）的这种关系</title>
      <link>https://stats.stackexchange.com/questions/651366/how-to-prove-this-relation-for-kendalls-distribution-function-or-kendalls-mea</link>
      <description><![CDATA[肯德尔分布函数 (Nelsen, 2006, 第 163 页) 或肯德尔测度 (Salvadori et al., 2007, 第 148 页) 或肯德尔函数 (Joe, 2014, 第 419–422 页) 是 $U=(u,v)$ 的累积分布函数 (CDF)，其中 $U$ 服从 copula 分布：$U\sim C(u,v)$。设 $Z$ 为 $C(u,v) : Z=C(u,v)$ 的随机变量，则 Kendall 函数定义为
$$F_K(z;C)=Pr(Z\leq z;U\sim C(u,v))$$
Joe (2014) 没有明确列出可直接计算任何 $C(u,v)$ 的 $F_K(z)$ 表达式，而 Nelsen (2006, p. 163) 仅列出了阿基米德 copulas 的形式。Salvadori 等人。 (2007，等式 3.47，第 147 页) 也列出了阿基米德形式；然而，Salvadori 等人。 (2007，方程 3.49，第 148 页) 还列出了一种可直接计算的形式，适用于任何 $C(u,v)$，如下所示：
$$F_K(z)=z+\int_{z}^{1} \frac{\partial C(u,t)}{\partial u} du$$
其中 $t=C^{(-1)}(u,z)$，适用于 $0 \leq z \leq 1$。
我的问题：Salvadori 如何为 Kendall 函数推导出这种形式？]]></description>
      <guid>https://stats.stackexchange.com/questions/651366/how-to-prove-this-relation-for-kendalls-distribution-function-or-kendalls-mea</guid>
      <pubDate>Thu, 18 Jul 2024 20:08:21 GMT</pubDate>
    </item>
    <item>
      <title>样本外 RMSE 大于标准差的模型是否有任何价值？</title>
      <link>https://stats.stackexchange.com/questions/651365/is-there-any-value-in-models-that-have-a-larger-out-of-sample-rmse-than-a-standa</link>
      <description><![CDATA[我使用各种回归模型、弹性网络和偏最小二乘回归 (PLSR) 根据 x 值预测 y 值。为了量化模型的性能，我们使用均方根误差 (RMSE)。
我们对整个 x 和 y 数据进行回归，以及循环式预测（类似于交叉验证）。在这种循环式预测中，本质上会遗漏一定比例的 x 和 y 数据，比如 5%，模型在剩余 95% 的 x 和 y 数据上进行训练，并预测剩余的 5%。然后，遗漏接下来 5% 的 x 和 y 数据，并使用剩余的 95% 来训练模型并预测保留的 5%。这个过程会反复进行，直到所有 y 数据都被预测为样本外数据。
我担心的是 RMSE 相对于 y 的标准偏差。当使用循环法预测 y 时，样本外 RMSE 总是大于实验 y 本身的标准差。当完全基于 x 和 y 训练模型（非循环方式）时，样本内 RMSE 明显小于 y 的标准差。
据我所知，这意味着当预测样本外 y 的值时，猜测 y 为已知 y 的平均值比使用我们的回归更准确，并且我们应该使用更少的组件/参数/复杂性。
即使这些回归对样本外的预测很差，并且 RMSE 高于标准差，它们是否有任何价值或有效性？]]></description>
      <guid>https://stats.stackexchange.com/questions/651365/is-there-any-value-in-models-that-have-a-larger-out-of-sample-rmse-than-a-standa</guid>
      <pubDate>Thu, 18 Jul 2024 20:02:57 GMT</pubDate>
    </item>
    <item>
      <title>重新创建`lm`分类回归</title>
      <link>https://stats.stackexchange.com/questions/651363/recreate-lm-categorical-regression</link>
      <description><![CDATA[考虑以下代码，它使用来自正确模型的数据，使用两个分类变量和一个连续变量的 lm 进行回归，没有交互作用：
set.seed(12345)

n &lt;- 100
X1 &lt;- as.factor(sample(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), n, replace = TRUE))
X2 &lt;- as.factor(sample(c(&quot;d&quot;, &quot;e&quot;), n, replace = TRUE))
X3 &lt;- rnorm(n, mean = 0, sd = 1)

effeta &lt;- 1
effetb &lt;- 2
effetc &lt;- 3
effetd &lt;- 4
effete &lt;- 5

Y &lt;- 10 + 3*X3 + effeta*(X1 == &quot;a&quot;) + effetb*(X1 == &quot;b&quot;) + effetc*(X1 == &quot;c&quot;) + effetd*(X2 == &quot;d&quot;) + effete*(X2 == &quot;e&quot;) + rnorm(n, mean = 0, sd = 1)

model &lt;- lm(Y ~ X1 + X2 + X3)
print(summary(model))

输出为：
调用：
lm(formula = Y ~ X1 + X2 + X3)

残差：
最小值 1Q 中位数 3Q 最大值
-2.74679 -0.60571 0.06521 0.67873 1.85143

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 15.06741 0.20151 74.773 &lt; 2e-16 ***
X1b 0.95913 0.23994 3.997 0.000127 ***
X1c 1.96010 0.23637 8.292 7.26e-13 ***
X2e 1.08521 0.18887 5.746 1.10e-07 ***
X3 3.03324 0.09537 31.804 &lt; 2e-16 ***
---
显著性代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

残差标准误差：95 自由度上的 0.9327
多重 R 平方：0.9194，调整后的 R 平方：0.916
F 统计量：4 和 95 DF 上的 270.8，p 值：&lt; 2.2e-16

目标是从数学上理解到底发生了什么，然后在 R 中重现它。更具体地说：

可以说 X3 系数的估计是正确的。在线来源表明 lm 将以一个级别为参考，将其效果设置为零。在一般情况下，如何提前预测哪个变量将作为参考？也许是按字母顺序？一旦估计了效果，我们如何知道它们是正确的？
虽然没有参考，但我相信 R 使用虚拟变量将分类观察结果写入矩阵中，将所有内容组合在一起，就像 Searle 中提到的那样，然后进行多元线性回归。在这种情况下，我该如何写下这样的矩阵？

让我们用 $x_3 \in \mathbb{R}^n$ 代替 x3。然后：
\begin{equation*}
x_3 =
\begin{bmatrix}
x_{1,3} \\
x_{2,3} \\
\vdots \\
x_{n,3}
\end{bmatrix}
\end{equation*&gt;
要对分类变量进行盲目计算，可以这样写：
\begin{equation*}
x_1 =
\begin{bmatrix}
x_{1,1a} &amp;&amp; x_{1,1b} &amp;&amp; x_{1,1c} \\
x_{2,1a} &amp;&amp; x_{2,1b} &amp;&amp; x_{2,1c} \\
\vdots &amp;&amp; \vdots &amp;&amp; \vdots\\
x_{n,1a} &amp;&amp; x_{n,1b} &amp;&amp; x_{n,1c} \\
\end{bmatrix};
x_2 =
\begin{bmatrix}
x_{1,1d} &amp;&amp; x_{1,1e} \\
x_{2,1d} &amp;&amp; x_{2,1e}\\
\vdots &amp;&amp; \vdots \\
x_{n,1d} &amp;&amp; x_{n,1e} \\
\end{bmatrix}
\end{equation*&gt;
两个矩阵中的所有元素均为 $0$ 或 $1$。
然后输入：
\begin{equation*}
X =
\begin{bmatrix}
1 &amp;&amp;x_{1,1a} &amp;&amp; x_{1,1b} &amp;&amp; x_{1,1c} &amp;&amp; x_{1,1d} &amp;&amp; x_{1,1e} &amp;&amp; x_{1,3} \\
1 &amp;&amp; x_{2,1a} &amp;&amp; x_{2,1b} &amp;&amp; x_{2,1c} &amp;&amp; x_{2,1d} &amp;&amp; x_{2,1e} &amp;&amp;x_{2,3} \\\\
\vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots \\
1 &amp;&amp; x_{n,1a} &amp;&amp; x_{n,1b} &amp;&amp; x_{n,1c} &amp;&amp; x_{n,1d} &amp;&amp; x_{n,1e} &amp;&amp; x_{n,3}
\end{bmatrix}
\end{equation*
这样我们就可以进行回归分析 lm(Y~X)。但这显然不是实际发生的情况。我如何去掉一些列才能得到实际发生的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/651363/recreate-lm-categorical-regression</guid>
      <pubDate>Thu, 18 Jul 2024 19:45:11 GMT</pubDate>
    </item>
    <item>
      <title>在验证性因子分析中将权重固定为 1 - 如何获得重要性 (p) 值？</title>
      <link>https://stats.stackexchange.com/questions/651362/fixed-weights-to-1-in-confirmatory-factor-analysis-how-significance-p-value</link>
      <description><![CDATA[我有一个与此主题有些相关的问题。
我现在明白了为什么在验证分析中应该将 1 的值固定到其中一条路径上，我也明白可以使用各种技巧来释放这个参数。但我感兴趣的问题是，如何用标准化解决方案计算固定路径到 1 的统计显著性。
让我们考虑一个来自这里的例子，我将使用 R 中的 Lavaan 包的示例。
library(lavaanPlot)
library(foreign) 
library(lavaan)

dat &lt;- read.spss(&quot;https://stats.idre.ucla.edu/wp-content/uploads/2018/05/SAQ.sav&quot;, to.data.frame=TRUE, use.value.labels = FALSE)

m1a &lt;- &#39; f =~ q03 + q04 + q05&#39;
onefac3items_a &lt;- cfa(m1a, data=dat) 
summary(onefac3items_a) 

这里，正如您在摘要中看到的，没有统计意义，因为路径 f~q03 是固定的。
潜在变量：
估计 Std.Err z 值 P(&gt;|z|)
f =~ 
q03 1.000 
q04 -1.139 0.073 -15.652 0.000
q05 -0.945 0.056 -16.840 0.000

摘要相同标准化：
summary(onefac3items_a,standardized=TRUE)
(...)

潜在变量：
估计 Std.Err z 值 P(&gt;|z|) Std.lv Std.all
f =~ 
q03 1.000 0.583 0.543
q04 -1.139 0.073 -15.652 0.000 -0.665 -0.701
q05 -0.945 0.056 -16.840 0.000 -0.551 -0.572

但是，当使用标准化解决方案函数时，我得到了 p 值。怎么回事，为什么？这怎么可能呢？
standardizedsolution(onefac3items_a)
lhs op rhs est.std se z pvalue ci.lower ci.upper
1 f =~ q03 0.543 0.022 25.120 0 0.500 0.585
2 f =~ q04 -0.701 0.024 -29.710 0 -0.747 -0.655
3 f =~ q05 -0.572 0.022 -26.105 0 -0.615 -0.529

同样，当我使用 plot 时，我得到了显著性星号。
lavaanPlot(model = onefac3items_a, coefs=T, covs=T, stars = c(&quot;covs&quot;,&quot;latent&quot;,&quot;regress&quot;), stand=T)

我不完全理解这种机制。为什么一条固定的、没有计算系数的路径突然与标准化解具有统计意义？这里使用了什么方法？是程序简单地改变了固定路径的位置，例如，我们暂时将路径 f~q04 固定为 1 来计算 f~q03 的系数，还是方法完全不同？
附加问题：在 AMOS 中可以实现相同的效果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651362/fixed-weights-to-1-in-confirmatory-factor-analysis-how-significance-p-value</guid>
      <pubDate>Thu, 18 Jul 2024 19:36:32 GMT</pubDate>
    </item>
    <item>
      <title>链式分类器中的阈值选择</title>
      <link>https://stats.stackexchange.com/questions/651361/threshold-selection-in-chain-classifier</link>
      <description><![CDATA[想象一组 $m$ 个分类器和 $N$ 个先例，每个分类器分配一个阈值 $\theta_{i,j}$，这意味着，如果分类器 $j$ 上先例 $i$ 的阈值 $t_j$ 大于 $\theta_{i,j}$，则先例通过分类器：$t_j&gt;\theta_{i,j}$
如果先例通过一个分类器，它将进入下一个分类器。在通过所有分类器后，先例被标记为$+$，如果先例被链中至少 1 个分类器丢弃，则标记为$-$。
问题是，如何为每个$m$分类器选择阈值$t_i$，以使真阳性率最大化，而假阳性率低于某个$T$？
我尝试在互联网上搜索阈值选择算法、常见的机器学习库，并将问题表述为混合整数问题，以便通过某些求解器进行求解，可惜没有成功（目前等待数学 Stackexchange)]]></description>
      <guid>https://stats.stackexchange.com/questions/651361/threshold-selection-in-chain-classifier</guid>
      <pubDate>Thu, 18 Jul 2024 19:18:37 GMT</pubDate>
    </item>
    <item>
      <title>如何使用自定义标签进行 NER</title>
      <link>https://stats.stackexchange.com/questions/651357/ner-with-custom-tags-how-to-approach</link>
      <description><![CDATA[我正在为文档构建一个“字段标记器”。基本上，一个文档（在我的情况下是提案或销售报价）会包含大量分散的实体，我们希望将每个实体与最能描述它的字段/标记进行匹配。问题是，尽管具有描述性，但字段/标签列表并不完全与现有的 NER 实体和类别类型一致。
例如，在我的案例中，一些字段/标签（标签）包括：“所有权”、“帐户类型”、“主要竞争对手”、“帐户名称”、“帐户来源”、“行业”、“帐号”、“金额”、“比较名称”、“主要合作伙伴帐户 ID”、“活跃”、“名称”、“有未结活动”、“概率 (%)”、“所有者别名”、“所有者 ID”、“有订单项”、“说明”、“帐户站点”、“预期金额”、“帐户说明”、“帐户评级”、“员工”。此类事物具有一定程度的语义含义，但可能并不多。
例如，如果文档是文本：
&quot;ABC Company&gt;&gt; 的 &lt;&lt;$500,000&gt;&gt; 机会计划于 &lt;&lt;2024 年 7 月 30 日&gt;&gt; 结束。&quot;

在此阶段，我们可以假设实体已被标记，因此我们不必处理识别原始文档中的实体究竟是什么，我希望该工具系统地检查每个标记的实体并将它们与最合适的字段/标签匹配。
由于缺乏训练数据，我最初的方法是使用零样本文本分类方法，使用 facebook/bart-large-mnli，系统地遍历实体，传递字段/标签列表作为标签，并提示要求分类。问题是我不确定模型是否在语义上理解标签本身的含义。更糟糕的是，我不确定如何将上下文传递给模型，因为简单地将其添加到提示中，一刀切地使预测变得更糟（公司名称等，之前被正确识别，开始被视为日期等）。
没有训练数据是一个限制，所以我的目标反映了这一点。它只是构建一个至少表现良好的工具。例如，如果根据模型的概率分布，最佳标签位于前 5 个最有可能的标签中，我会认为这是一个成功的分类。
有人能建议一种方法，或提供如何调整我现有的方法的建议，以获得更好的结果吗？我该如何提供上下文以增强预测？任何帮助都将不胜感激]]></description>
      <guid>https://stats.stackexchange.com/questions/651357/ner-with-custom-tags-how-to-approach</guid>
      <pubDate>Thu, 18 Jul 2024 17:17:07 GMT</pubDate>
    </item>
    <item>
      <title>生存分析中的差异随访期是否存在问题？</title>
      <link>https://stats.stackexchange.com/questions/651355/is-differential-follow-up-periods-in-survival-analysis-a-problem</link>
      <description><![CDATA[我希望比较两种不同手术方法的术后死亡率。由于技术进步，其中一种手术方法仅在另一种手术方法实施五年后才实施。然而，这两种技术现在都已普遍实施。因此，我有一组患者的随访期比另一组患者滞后五年左右。在进行 Kaplan Meier 生存分析或使用 Cox 回归计算风险比时，这是否存在问题？Kaplan Meier 图显示一种干预措施比另一种干预措施长五年。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/651355/is-differential-follow-up-periods-in-survival-analysis-a-problem</guid>
      <pubDate>Thu, 18 Jul 2024 16:58:38 GMT</pubDate>
    </item>
    <item>
      <title>回归中人为平衡结果是否会导致校准不佳？如果是，如何显示校准不佳？</title>
      <link>https://stats.stackexchange.com/questions/651342/does-artificially-balancing-outcomes-in-regression-lead-to-poor-calibration-if</link>
      <description><![CDATA[在“分类”问题中，经常会出现不平衡类别。为了解决看似存在的问题（尽管我认为这通常不是问题），从业者通常会对少数类别进行过度采样，要么通过合成全新的点（例如，SMOTE），要么通过添加/删除点来平衡类别。
很容易说明这会如何破坏预测并导致预测过高，例如在下面的模拟中。
library(rms)
set.seed(2024)
N &lt;- 10000

# 模拟不平衡逻辑回归的数据
#
x &lt;- rnorm(N, -3, 1)
z &lt;- x
p &lt;- 1/(1 + exp(-z))
y &lt;- rbinom(N, 1, p)

# 人为平衡样本（这可能是“ROSE”或类似的东西）
#
N0 &lt;- table(y)[1]
idx &lt;- which(y == 1)
x0 &lt;- x[y == 0]
x1 &lt;- sample(x[y == 1], N0, replace = T)
x_balanced &lt;- c(x0, x1)
y_balanced &lt;- rep(c(0, 1), c(N0, N0))

# 对平衡数据和原始数据运行逻辑回归
#
L_balanced &lt;- glm(y_balanced ~ x_balanced, family = binomial)
L_orig &lt;- glm(y ~ x, family = 二项式)

# 根据每个逻辑回归对原始数据进行预测
#
preds_balanced &lt;- predict(L_balanced, data.frame(x_balanced = x), type = &quot;response&quot;)
preds_orig &lt;- predict(L_orig , data.frame(x = x), type = &quot;response&quot;)
summary(preds_balanced)
summary(preds_orig)

# 检查每个模型的校准：预测概率是否与事件发生的现实相符
#
par(mfrow = c(2, 1))
rms::val.prob(preds_balanced, y) # 校准糟糕：预测值过高
rms::val.prob(preds_orig, y) # 校准良好
par(mfrow = c(1, 1))


图表显示，原始数据的逻辑回归具有良好的校准性，所有预测概率或多或少与事件发生的现实相符。另一方面，平衡模型的预测结果令人难以置信，例如，事件发生概率实际上更像是 $0.2$，但预测概率为 $0.8$。两种模型的 ROCAUC 相同，因此缺乏校准甚至不会导致类别更好地分离。
出于这个和其他原因，统计学通常对人为平衡数据持悲观看法。
这是具有分类结果的“分类”。那么在具有数值结果的回归问题中呢，所有这些结果可能都不同？我怀疑，如果人为地平衡倾斜的结果以使罕见事件看起来像是常规事件，从而导致大预测缺乏可信度，也会出现类似的行为。在“分类”中案例中，图表显示，人工平衡意味着不应认真对待 $0.8$ 这样的预测，因为真实概率实际上更像是 $0.2$。我想象一个具有人工平衡的回归会给出高预测，而真实分布远离这些高值，因此预测为高的值可能只是“狼来了”，但我很难证明这一点。
在回归案例中会发生什么？我是否正确地认为，回归中人工平衡结果会导致校准不佳？如果是这样，如何显示校准不佳？]]></description>
      <guid>https://stats.stackexchange.com/questions/651342/does-artificially-balancing-outcomes-in-regression-lead-to-poor-calibration-if</guid>
      <pubDate>Thu, 18 Jul 2024 13:54:43 GMT</pubDate>
    </item>
    </channel>
</rss>