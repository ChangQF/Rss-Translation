<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 29 Dec 2024 03:26:20 GMT</lastBuildDate>
    <item>
      <title>平方和与叉积 (SSCP) 矩阵的逆</title>
      <link>https://stats.stackexchange.com/questions/659323/inverse-of-sums-of-squares-and-cross-products-sscp-matrix</link>
      <description><![CDATA[在《应用线性回归》一书的第 3 章中，Weisberg 提出，已校正 SSCP 矩阵的逆$(\chi^T\chi)^{-1}$是未校正 SSCP 矩阵的逆$(X^TX)^{-1}$的第一行和第一列以外的所有元素。这是为什么呢？
$\chi$ 就是 $X$，但没有截距，并且从每列中减去了相应的平均值，仅供参考。]]></description>
      <guid>https://stats.stackexchange.com/questions/659323/inverse-of-sums-of-squares-and-cross-products-sscp-matrix</guid>
      <pubDate>Sun, 29 Dec 2024 02:08:49 GMT</pubDate>
    </item>
    <item>
      <title>AP 统计调查</title>
      <link>https://stats.stackexchange.com/questions/659322/ap-statistics-survey</link>
      <description><![CDATA[请填写我们的 AP 统计项目的调查表！请在重定向后保存链接。谢谢！
表格 (https://www.allocate.monster/GOKZTQWQ)]]></description>
      <guid>https://stats.stackexchange.com/questions/659322/ap-statistics-survey</guid>
      <pubDate>Sun, 29 Dec 2024 01:28:57 GMT</pubDate>
    </item>
    <item>
      <title>关于如何从直方图创建 PDF/正态分布的问题</title>
      <link>https://stats.stackexchange.com/questions/659321/question-regarding-how-to-create-a-pdf-normal-distribution-from-histogram</link>
      <description><![CDATA[我有一个关于概率密度函数、直方图和正态分布的理论问题，我只需要有人确认我的描述（尽管很基础）是否正确。
如果我的书面版本看起来令人困惑，我已在此解释下附上我的问题图片。

据我所知，如果我有一个直方图，其中 y 轴上有频率密度，那么为了将这些 y 值转换为概率密度，

我会做频率密度/N（这与写频率/N*类宽度相同），因此，当我们计算条形的面积时，我们将得到一个概率值，因为它将是（频率/N*类宽度）*类宽度，并且类宽度取消以留下频率/N，即概率。
我们对每个条形都这样做，然后如果我们将这些面积相加，我们会得到 1，正态分布本质上是相同的想法，但类宽度接近于 0。显然我们不会总是得到一个正态分布，但我这样说只是为了强调这本质上就是我们得到平滑曲线的方式。

但是当我必须考虑比例常数 k 时，就会产生混淆
因为直方图通常采用条形面积 = K * 频率的形式，顺便说一句，当我在这里提到条形面积时，我指的是 Y 轴显示频率密度而不是 pdf 的情况。
那么我描述的整个过程将如何工作，我们只是在这个过程中取消 K 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659321/question-regarding-how-to-create-a-pdf-normal-distribution-from-histogram</guid>
      <pubDate>Sun, 29 Dec 2024 01:14:31 GMT</pubDate>
    </item>
    <item>
      <title>OLS 怎么会有遗漏变量偏差？OLS 不是应该总是消除内生性吗？</title>
      <link>https://stats.stackexchange.com/questions/659320/how-can-there-be-omitted-variable-bias-in-ols-shouldnt-ols-always-eliminate-en</link>
      <description><![CDATA[OLS 中怎么会存在遗漏变量偏差（OMS）？难道所有回归都不能在没有内生性的情况下计算吗？
作为介绍，这是 Greene（计量经济学分析，第 8 版）关于 OMB 的条目：

重新表述问题：为什么 $b$ 不捕获调用 $X$ 对 $y$ 的影响并使误差项不相关？
例如 - 假设正确指定的模型 ($R^2 = 1$) 和 $x_1$:
$ y = \beta.x_1 + \gamma.x_2$
$x_2= \delta.x_1 + w$
因此，我们看到 $x_1$ 和 $x_2$ 是相关的。
现在让我们使用 OLS 对 $y$ 进行回归：
$E[y\,|x_1] = a + b.x_1+ \epsilon$
由于 $x_2$ 应该位于 $\epsilon$ 上，$b$ 应该具有 OMB，对吗？这里有一个反对意见。
让我们重新表述 $y$ 的方程式：
$y = (\beta +\gamma.\delta).x_1 + \delta.w$
因此，回归量可以重新表述为 $x_1$ 和不相关的 $w$。如果是这样，为什么回归中会有 OMB？]]></description>
      <guid>https://stats.stackexchange.com/questions/659320/how-can-there-be-omitted-variable-bias-in-ols-shouldnt-ols-always-eliminate-en</guid>
      <pubDate>Sun, 29 Dec 2024 00:55:52 GMT</pubDate>
    </item>
    <item>
      <title>解决数学问题的一般方法</title>
      <link>https://stats.stackexchange.com/questions/659316/general-approach-to-solving-math-problems</link>
      <description><![CDATA[我有一个数学函数 f(x,y) -&gt; z。我想要一个 ml 模型来学习近似任何 x,y 的 f。我尝试了一种转换器方法，其中输入文件只是一堆方程式，但它似乎不太有效/通用。是否有任何适合解决复杂数学方程式的好方法或模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/659316/general-approach-to-solving-math-problems</guid>
      <pubDate>Sun, 29 Dec 2024 00:25:15 GMT</pubDate>
    </item>
    <item>
      <title>SPSS 和 R 中 95% 置信区间的差异</title>
      <link>https://stats.stackexchange.com/questions/659314/difference-between-95-confidence-intervals-in-spss-and-r</link>
      <description><![CDATA[当我在 SPSS 中计算数据集的 95% CI（Kaplan Meier 曲线）时，它会给出一组值，而在 R 中，它会给出另一组值。
我尝试通过添加 conf.type = &quot;log&quot; 或 conf.type = &quot;plain&quot; 等进行补偿...
好吧，我一个接一个地尝试了每一个，但它仍然与 SPSS 中的不匹配。
有人可以指导我吗？我做错了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659314/difference-between-95-confidence-intervals-in-spss-and-r</guid>
      <pubDate>Sat, 28 Dec 2024 23:47:21 GMT</pubDate>
    </item>
    <item>
      <title>是否可以通过观察损失函数的变化来建立特征的正交性？</title>
      <link>https://stats.stackexchange.com/questions/659313/can-orthogonality-of-features-be-established-by-observing-changes-in-the-loss-fu</link>
      <description><![CDATA[假设我有一个回归或分类问题，并收集了大量数据。我的假设是，如果我选择 $2$ 个正交（或者可能是正交标准？）特征，那么每个特征都应将损失减少一定数值，而与引入它们的顺序无关。例如，如果我从空特征集开始，并合并特征 A 可将损失减少 $10$，那么如果我从特征 B 开始合并特征 A 也应将损失减少 $10$，当且仅当特征 A 和特征 B 是正交的。我可能从这样的事实中得到了这种直觉：概率独立性意味着$\Pr(A)\Pr(B) = \Pr(A\ |\ B)\Pr(B)$，而损失函数似乎或多或少是概率的概念概括（如果除以最大可能损失，$0-1$损失就是一个概率）。
或者，我假设我可能需要将均匀随机数据提供给特征，作为其正交性测试的一部分。
至少在某些条件下，这个范围内的任何情况都是正确的吗？或者您是否总是必须使用相关矩阵或类似工具来确定正交性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659313/can-orthogonality-of-features-be-established-by-observing-changes-in-the-loss-fu</guid>
      <pubDate>Sat, 28 Dec 2024 23:45:25 GMT</pubDate>
    </item>
    <item>
      <title>使用高负 NLL 损失来规范流量</title>
      <link>https://stats.stackexchange.com/questions/659312/normalizing-flow-with-highly-negative-nll-loss</link>
      <description><![CDATA[我正在按照 Zuko“从数据训练”教程来训练神经样条流。我的目标是近似函数分布。
因此，我的每个函数样本实际上都是 20 个样条系数。如果我可以学习这些系数的分布，那么我就可以近似函数分布。总的来说，我使用 100K 个样本来拟合流。每个样本有 20 个维度。
它目前不起作用，流样本看起来不像我数据中的函数。此外，我的 NLL 损失为负，通常在 -30 左右。这意味着平均而言，我的样本密度在 exp(30) 的数量级上？！
这似乎对我的数据过度拟合，但我的训练/测试损失几乎相等。但我的采样函数仍然是垃圾。
这是我的训练循环的代码：
def train(samples):

train_ratio = 25.0/26.0
total_samples = samples.size(0)
indices = torch.randperm(total_samples)

train_size = int(train_ratio * total_samples)
train_indices = indices[:train_size]
test_indices = indices[train_size:]

train_samples, test_samples = samples[train_indices], samples[test_indices]

num_features = samples.shape[1]
flow = zuko.flows.NSF(features=num_features, transforms=5, hidden_​​features=(64, 128, 256))
# flow = zuko.flows.MAF(features=num_features, transforms=32)

num_epochs = 10000
optimizer = torch.optim.Adam(flow.parameters(), lr=1e-3)

ms = [int(0.2*num_epochs), int(0.7*num_epochs), int(0.9*num_epochs)]
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, miles=ms, gamma=0.1)

for epoch in range(num_epochs):
train_loss = -flow().log_prob(train_samples).mean()
train_loss.backward()

optimizer.step()
optimizer.zero_grad()
scheduler.step()

with torch.no_grad():
test_loss = -flow().log_prob(test_samples).mean()

lr = optimizer.param_groups[-1][&#39;lr&#39;]
print(f&#39;Epoch [{epoch + 1}/{num_epochs}], LR: {lr:.6f}, Train: {train_loss.item():.8f}, Test: {test_loss.item():.8f}&#39;)

return flow

这导致 400 个 epoch 之后训练和测试损失分别约为 -45 和 -44，这对我来说似乎很荒谬。]]></description>
      <guid>https://stats.stackexchange.com/questions/659312/normalizing-flow-with-highly-negative-nll-loss</guid>
      <pubDate>Sat, 28 Dec 2024 22:42:29 GMT</pubDate>
    </item>
    <item>
      <title>区间变量与名义变量之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/659311/correlation-between-interval-and-nominal-variables</link>
      <description><![CDATA[我确实需要一些帮助来分析我的数据。我有一个带有村庄大小（以公顷为单位）的数字变量和一个带有四种土壤类型的分类变量。我想使用 R 研究土壤类型是否与村庄大小有关。我已经绘制了箱线图，但现在我想得到一些关联度量。我读过这里的一些答案，建议使用 ANOVA 的 Eta（相关比）。我的尺寸数据不是正态分布的，所以我怀疑我是否可以使用它。在包 rstatix 中，函数 kruskal_effsize 也给出了 eta-squared 的值，但基于 H。根据 rstatix 文档“...eta-squared...表示独立变量解释的因变量方差百分比。”使用这个度量来得出关于两个变量之间关系的一些结论是否正确？
如果有人可以对此进行解释，我将不胜感激。谢谢 Kelly Lee
我已获得所有 Eta 值，但我需要知道是否可以使用它们。]]></description>
      <guid>https://stats.stackexchange.com/questions/659311/correlation-between-interval-and-nominal-variables</guid>
      <pubDate>Sat, 28 Dec 2024 21:32:21 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA(12,0,0) - 缺少第 14 个参数？拟合值 <> 已计算</title>
      <link>https://stats.stackexchange.com/questions/659310/arima12-0-0-missing-14th-param-fitted-values-calculated</link>
      <description><![CDATA[我在 R 中创建了一个 ARIMA(12, 0, 0) 模型。我计算出的拟合值为
$$\hat{y}(t) = \phi_1 y(t-1) + \phi_2 y(t-2) + \ldots + \phi_{12} y(t-12) + \text{intercept}$$
将我的计算结果与模型的最后 10 个拟合值进行比较，结果存在恒定的差异（这 10 个差异是相同的）。为什么会有差异？为了弄清楚这一点，我遇到了这个等式
$$ \text{AIC} = 2k - 2\ln(L) $$
其中 k 是参数的数量，L 是最大似然。当我求解 k 时，我得到的结果是 14，而预期结果是 13（12 个滞后和一个截距）。第 14 个参数是什么？我在 R 中哪里可以找到它？它能解释错误吗？重现该问题的代码如下：
library(readxl)
library(curl)
library(dplyr)
url &lt;- &quot;https://img1.wsimg.com/blobby/go/e5e77e0b-59d1-44d9-ab25-4763ac982e53/downloads/e1fcc664-eaa1-48ed-b682-88e0c33db496/ie_data.xls?ver=1733242673788&quot;
temp_file &lt;- tempfile(fileext = &quot;.zip&quot;)
curl_download(url, temp_file)
shiller_data &lt;- suppressWarnings(suppressMessages({
read_excel(
temp_file,
sheet = &quot;Data&quot;,
range = &quot;A8:V1856&quot;,
col_types = c(
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;skip&quot;,
&quot;numeric&quot;,
&quot;skip&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;,
&quot;numeric&quot;
)
)
}))
colnames(shiller_data) &lt;- c(
&quot;Date&quot;,
&quot;SPCompP&quot;,
&quot;D&quot;,
&quot;E&quot;,
&quot;CPI&quot;,
&quot;DateFraction&quot;,
&quot;LongRateGS10&quot;,
&quot;RealP&quot;,
&quot;RealD&quot;,
&quot;RealTRP&quot;,
&quot;RealE&quot;,
&quot;RealTRScaledE&quot;,
&quot;CAPE&quot;,
&quot;TRCAPE&quot;,
&quot;ExcessCAPEYld&quot;,
&quot;BondReturns&quot;,
&quot;RealBondReturns&quot;,
&quot;StockRealRet10Y&quot;,
&quot;BondRealRet10Y&quot;,
&quot;ExcessRealRet10Y&quot;
)

DateFraction2Date &lt;- function(dateFraction) {
y = floor(dateFraction)
m = ceiling((dateFraction - y)*12) + 1
idx &lt;- m &gt; 12
y[idx] &lt;- y[idx] + 1
m[idx] &lt;- 1
out &lt;- as.Date(paste0(y, &quot;-&quot;,m,&quot;-1&quot;), format = &quot;%Y-%m-%d&quot;) - 1
return(out) 
}

shiller_data &lt;- shiller_data %&gt;% mutate(Date1 = DateFraction2Date(DateFraction))
通货膨胀 &lt;- shiller_data$CPI[2:nrow(shiller_data)]/shiller_data$CPI[1:(nrow(shiller_data) -1)] - 1 
inflation_ts &lt;- ts(inflation, start = c(lubridate::year(shiller_data$Date1[2]), lubridate::month(shiller_data$Date1[2])), 频率 = 12)

window_data &lt;- indication_ts[1:360]
ar_model &lt;- Arima(window_data, order = c(12, 0, 0))
fitted10 &lt;- ar_model$fitted[351:360]
calcFitted10 &lt;- numeric(10)
for (i in 351:360) {
calcFitted10[i-350] &lt;- sum(window_data[(i-12):(i-1)] * ar_model$coef[12:1]) + ar_model$coef[13]
}
fitted10 - calcFitted10
implied_pa​​rams &lt;- (ar_model$aic - ar_model$loglik*-2)/2

本例中的数据来自 Shiller 的 CAPE 数据。
摘要：为什么不是

fitted10 - calcFitted10

全为零？是因为

implied_pa​​rams

等于 14，而我只使用了 13 个系数？
我读过类似问题和这个问题，但还没搞清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/659310/arima12-0-0-missing-14th-param-fitted-values-calculated</guid>
      <pubDate>Sat, 28 Dec 2024 20:40:40 GMT</pubDate>
    </item>
    <item>
      <title>低拉姆齐重置检验 p 值 (LinReg)</title>
      <link>https://stats.stackexchange.com/questions/659306/low-ramsey-reset-test-p-value-linreg</link>
      <description><![CDATA[我正在为入门计量经济学课程做我的期末项目。我正在使用 Python 中的简单线性回归对二手保时捷 911 价格进行建模。令人困扰的是 RESET 测试的低 p 值，尽管我尝试使用交互项（里程 x 年数）、二次幂（里程^2）等。如果我使用 Y 变量（价格）对数的对数线性模型，则会出现最低的 RESET p 值和最高的 R^2，因此这似乎是目前最合适的。有什么改进的想法吗？ RESET 测试真的那么重要吗？
以下是代码以防万一：
Y = df[&quot;log_price&quot;]
X = df[[&quot;IS911&quot;, &quot;IS964&quot;, &quot;IS993&quot;, &quot;IS996&quot;, &quot;IS997&quot;, &quot;IS991&quot;, &quot;Special&quot;, &quot;S&quot;, &quot;RS&quot;, &quot;Turbo&quot;, &quot;GT&quot;, &quot;Targa&quot;, &quot;Cabriolet&quot;, &quot;Automat&quot;, &quot;Power&quot;, &quot;Mileage&quot;, &quot;CylCap&quot;]]
X = sm.add_constant(X)
model5= sm.OLS(Y, X).fit()
print(model5.summary())

from statsmodels.stats.diagnostic import linear_reset
reset_test = linear_reset(model5, power=3)
print(&quot;P-hodnota:&quot;, reset_test.pvalue)

返回： 
R^2 = 0.857 (Adj. R^2 = 0.856) 
所有变量均具有统计学意义 
RESET p 值：0.00022819301719425838 
使用的变量： 
虚拟变量：IS911、IS964、IS993、IS996、 IS997、IS991、Special、S、RS、Turbo、GT、Targa、Cabriolet、Automat（如果为真则为 1，否则为 0）
连续变量：功率、里程、CylCap]]></description>
      <guid>https://stats.stackexchange.com/questions/659306/low-ramsey-reset-test-p-value-linreg</guid>
      <pubDate>Sat, 28 Dec 2024 18:52:34 GMT</pubDate>
    </item>
    <item>
      <title>回归模型</title>
      <link>https://stats.stackexchange.com/questions/659301/regression-model</link>
      <description><![CDATA[我正在尝试运行一个回归模型。对于该模型，我根据城市居民人数对因变量 (Y) 进行加权。请问我是否应该将居民人数作为模型中的独立变量 (X) 也包括在内？非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659301/regression-model</guid>
      <pubDate>Sat, 28 Dec 2024 18:10:08 GMT</pubDate>
    </item>
    <item>
      <title>如果我们知道总体分布不正常，那么创建参考 Z 分布的置信区间是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/659299/does-it-make-sense-to-create-a-confidence-interval-referencing-the-z-distributio</link>
      <description><![CDATA[我正在学习生物学学位的入门统计学课程，在学习如何生成总体均值的置信区间时，我开始怀疑，如果我们知道原始总体不服从正态分布，这样做是否有意义。据我所知，CLT 在这种情况下没有任何用处，因为我们关心的是创建一个置信区间，其假定机会与原始概率分布（即总体的概率分布）一致。
我遗漏了什么吗？如果没有，评估引用此类理论分布来构建置信区间的正确性的程序是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659299/does-it-make-sense-to-create-a-confidence-interval-referencing-the-z-distributio</guid>
      <pubDate>Sat, 28 Dec 2024 15:19:07 GMT</pubDate>
    </item>
    <item>
      <title>无意识统计学家的条件密度定律</title>
      <link>https://stats.stackexchange.com/questions/659281/law-of-the-unconscious-statistician-for-conditional-density</link>
      <description><![CDATA[根据这个答案，无意识统计学家的定律意味着
$$E[h(X) \mid Z=z]=\int h(x) g(x\mid z) ~\mathrm{d}x.$$
但是
$$E[h(X \mid Y) \mid Z=z]呢？$$
这是真的吗
$$E[h(X \mid Y) \mid Z=z] = \int h(x \mid y) g(x\mid z) ~\mathrm{d}x?$$
我之所以问这个问题，是因为我目前正在研究条件得分函数 $\frac{\partial}{\partial \beta}\log h_{Y \mid X, \mathrm{B}}(y \mid x, \beta)$，当对相关参数 $\beta^*$ 的真实值进行评估时，该函数的均值应为零。
编辑：以下是有关 $y$ 和 $z$ 的作用的更多信息。在某些规律性条件下，无意识统计学家的定律意味着
\begin{equation*}
\begin{split}
E\left[ \frac{\partial}{\partial \theta} \log f_{X \mid \Theta}(x \mid \theta) \mid \Theta = \theta^* \right] 
&amp;= \int \left(\frac{\partial}{\partial \theta} \log f_{X \mid \Theta} (x \mid \theta)\right) f_{X \mid \Theta}(x \mid \theta^*) \, \mathrm{d}x \\
&amp;= \int \frac{\partial f_{X \mid \Theta}(x \mid \theta)}{\partial \theta}\frac{1}{f_{X \mid \Theta}(x \mid \theta)}f_{X \mid \Theta}(x \mid \theta^*) \, \mathrm{d}x。
\end{split}
\end{equation*&gt;
因此，
$$ E\left[\frac{\partial}{\partial \theta} \log f_{X \mid \Theta}(x \mid \theta^*) \mid \Theta = \theta^*\right] = \int \frac{\partial f_{X \mid \Theta}(x \mid \theta^*)}{\partial \theta} \, \mathrm{d}x = \frac{\partial}{\partial \theta} \int f_{X \mid \Theta}(x \mid \theta^*) \, \mathrm{d}x = \frac{\partial}{\partial \theta} [1] =0。 $$
现在我试图证明
$$E\left[\frac{\partial}{\partial \theta} \log g_{Y \mid \mathbf{X}, \Theta}(y \mid \mathbf{x}, \theta^*) \mid \Theta = \theta^*\right] = 0,$$
其中 $g_{Y \mid \mathbf{X}, \Theta}(y \mid \mathbf{x}, \theta^*)$ 是与 $y$ 对 $\mathbf{x}$.]]></description>
      <guid>https://stats.stackexchange.com/questions/659281/law-of-the-unconscious-statistician-for-conditional-density</guid>
      <pubDate>Fri, 27 Dec 2024 23:25:10 GMT</pubDate>
    </item>
    <item>
      <title>$\text{U}(0, \theta)$ 中 ${θ}/{2}$ 的置信区间</title>
      <link>https://stats.stackexchange.com/questions/659276/confidence-interval-for-%ce%b8-2-in-textu0-theta</link>
      <description><![CDATA[我试图找到 ${\theta}/{ 2}$ 的置信区间，置信度为 $1-\alpha$（使用 $p_1 = \alpha$ 和 $p_2 = 1$ 处的分位数）。因此，我采用 ${\hat{\theta}}/{2} = {X_{(n)}}/{2}$ 的无偏估计量。然后从我们在课堂上学到的知识：
$$\mathbb{P} \bigg( \dfrac{cX_{(n)}}{2\theta} \leqslant q_{p_1} \bigg)
= \mathbb{P} \bigg( \dfrac{X_{(n)}}{\theta} \leqslant \dfrac{2q_{p_1}}{c} \bigg)
= \alpha
= \bigg( \dfrac{2q_{p_1}}{c} \bigg)^n,$$
这意味着 $q_{p_1}=\tfrac{c}{2}\alpha^{{1}/{n}}$ 并且对于 $q_{p_2}$ 将给我们 $q_{p_2} = {c}/{2}$。由此得出：
$$\mathbb{P} \bigg( \dfrac{c}{2}\alpha^{{1}/{n}} \leqslant \dfrac{cX_{(n)}}{\theta} \leqslant \dfrac{c}{2} \bigg)
= \mathbb{P} \bigg( X_{(n)} \leqslant \dfrac{\theta}{2} \leqslant \dfrac{X_{(n)}}{\alpha^{{1}/{n}}} \bigg)
= 1-\alpha,$$
因此得出的 CI 为：
$$\dfrac{\theta}{2} \in \bigg[ X_{(n)}, \dfrac{X_{(n)}}{\alpha^{{1}/{n}}} \bigg].$$
这看起来正确吗？还是我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659276/confidence-interval-for-%ce%b8-2-in-textu0-theta</guid>
      <pubDate>Fri, 27 Dec 2024 21:45:01 GMT</pubDate>
    </item>
    </channel>
</rss>