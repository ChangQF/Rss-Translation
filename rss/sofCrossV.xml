<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 21 May 2024 06:21:11 GMT</lastBuildDate>
    <item>
      <title>中期分析会发生什么？</title>
      <link>https://stats.stackexchange.com/questions/647672/what-happens-at-interim-analysis</link>
      <description><![CDATA[我想了解中期分析期间/之后在操作上发生了什么？

如果试验符合预先设定的疗效边界，该研究在 IA 时是非盲的，并且结果会公开公布？仍然可以收集一段时间的安全吗？ IA后至最终结果是否会收集疗效？
如果试验未达到预先设定的功效边界，谁会进行必要的设计调整？向进行试验的团队宣布什么？只是试验没有达到预先设定的界限？
]]></description>
      <guid>https://stats.stackexchange.com/questions/647672/what-happens-at-interim-analysis</guid>
      <pubDate>Tue, 21 May 2024 05:48:32 GMT</pubDate>
    </item>
    <item>
      <title>了解 Chinchilla 复制研究中的 Log-Sum-Exp (LSE) 运算符，e 是集合还是 exp？</title>
      <link>https://stats.stackexchange.com/questions/647669/understanding-the-log-sum-exp-lse-operator-in-chinchilla-replication-study-is</link>
      <description><![CDATA[我正在尝试了解 Log-Sum-Exp (LSE) 运算符在 Chinchilla 复制研究中的使用，特别是论文“Chinchilla Scaling：一种复制尝试”中引用的运算符。贝西罗格鲁等人（2024）。在该研究中，LSE 用于损失参数模型的拟合过程。不过，e似乎并不是作为自然对数的标准底，而是作为参数的一组初始值。
为什么 e 是一组值 {-1, =0.5, ..., 1} 而不是 Chinchilla 复制研究中 LSE 运算符上下文中的标准指数函数？ p&gt;
上下文：
Chinchilla复制论文定义参数模型和拟合过程如下：
$$
L(N,D) = E + A N^{-\alpha} + B D^{-\beta}
$$
在龙猫复制研究中，LSE函数的使用如下：
[
\min_{a,b,e,\alpha,\beta} \sum_{\text{Run } i} \text{Huber}_\delta \left( \text{LSE}(a \alpha \log N_i, b \beta \log D_i, e) - \log L_i \right)
]
这里，LSE不是传统的log-sum-exp，而是将这些对数项与参数结合起来的函数
𝑒
e 从集合 {-1, -0.5, ..., 1} 初始化
为什么会有差异？
在这项具体研究中，e 用作从一组值初始化的参数，以优化拟合过程。这与 log-sum-exp 函数中 e 的传统用法不同，其中 e 是自然对数的底数。 e 的集合 {-1, -.5, ..., 1} 的选择允许研究人员探索不同的初始化并找到模型的最佳参数。
我希望这有助于阐明 e 在龙猫复制研究中的使用。如果您还有其他问题或需要更多详细信息，请告诉我！
&lt;小时/&gt;
将 numpy 导入为 np
从 scipy.optimize 导入最小化
从 sklearn.metrics 导入mean_squared_error

# 定义参数模型
def model_loss(N, D, E, A, alpha, B, beta):
    返回 E + (A / (N ** alpha)) + (B / (D ** beta))

# 定义Huber损失函数
def huber_loss(delta, pred, 实际):
    diff = np.abs(预测值 - 实际值)
    return np.where(diff &lt; delta, 0.5 * diff ** 2, delta * (diff - 0.5 * delta))

# 示例数据（N：模型大小，D：训练标记数量，L：观察到的损失）
数据 = [
    {&#39;N&#39;：1e6，&#39;D&#39;：1e9，&#39;L&#39;：2.0}，
    {&#39;N&#39;：1e7，&#39;D&#39;：1e10，&#39;L&#39;：1.5}，
    # 根据需要添加更多数据点
]

# 将数据转换为 numpy 数组
N = np.array([d[&#39;N&#39;] for d in data])
D = np.array([d[&#39;D&#39;] for d in data])
L = np.array([d[&#39;L&#39;] for d in data])

# 定义优化目标函数
def 目标（参数）：
    E、A、alpha、B、beta = 参数
    L_pred = model_loss(N、D、E、A、α、B、β)
    返回 np.sum(huber_loss(0.1, L_pred, L))

# 初始参数网格
参数网格 = {
    ‘E’: [0, 0.5, 1],
    ‘A’: [100, 200, 300],
    “阿尔法”：[0.3，0.5，0.7]，
    ‘B’: [1000, 2000, 3000],
    “测试版”：[0.3，0.5，0.7]，
    ‘e’: [-1, -0.5, 0, 0.5, 1]
}

# 执行网格搜索
最佳参数=无
最佳损失 = 浮动（&#39;inf&#39;）
对于 param_grid[&#39;E&#39;] 中的 E：
    对于 param_grid[&#39;A&#39;] 中的 A：
        对于 param_grid[&#39;alpha&#39;] 中的 alpha：
            对于 param_grid[&#39;B&#39;] 中的 B：
                对于 param_grid[&#39;beta&#39;] 中的 beta：
                    对于 param_grid[&#39;e&#39;] 中的 e：
                        参数 = (E, A, alpha, B, beta)
                        损失=目标（参数）
                        如果损失&lt;最佳损失：
                            最佳损失 = 损失
                            最佳参数 = 参数

print(&quot;最佳参数：&quot;, best_params)
print(&quot;最佳损失：&quot;, best_loss)

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/647669/understanding-the-log-sum-exp-lse-operator-in-chinchilla-replication-study-is</guid>
      <pubDate>Tue, 21 May 2024 04:37:11 GMT</pubDate>
    </item>
    <item>
      <title>基础模型 ANOVA 和 kruskal-wallis</title>
      <link>https://stats.stackexchange.com/questions/647667/underlying-model-anova-and-kruskal-wallis</link>
      <description><![CDATA[单向方差分析 (Yij= u + ti + Eij) 的基础模型是否与 Kruskal-wallis 检验完全相同，因为 KW 是非参数方差分析等效项，还是有不同的模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/647667/underlying-model-anova-and-kruskal-wallis</guid>
      <pubDate>Tue, 21 May 2024 04:28:39 GMT</pubDate>
    </item>
    <item>
      <title>在匹配中，上限混杂因素是改善与高度倾斜的连续混杂因素匹配的平衡的合法方法吗？</title>
      <link>https://stats.stackexchange.com/questions/647666/in-matching-are-capped-confounders-a-legitimate-method-of-improving-balance-for</link>
      <description><![CDATA[在匹配（或类似的混杂控制方法，例如加权）中，“上限度量”被定义为“上限度量”。 “合法的”改善高度倾斜的连续混杂因素平衡的方法？
上限指标是在线实验中常用的方差减少方法（Kohavi et al., 2014），但用于结果变量（我不熟悉 CUPED 中是否使用上限）。上限是指将某个百分位数（例如 99）之后的所有值设为相同。最终我明白这是一种偏差-方差权衡，并且平衡减少方法已经存在，例如卡尺（偏差的权衡），但在某些情况下，我认为在处理非常高的偏差时，上限也是合理的（&gt;20+ 偏度系数）由于极右尾部，但我想检查文献中是否有一些合理性，以便我不使用无效的方法（我还无法找到有关此主题的任何内容）。&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/647666/in-matching-are-capped-confounders-a-legitimate-method-of-improving-balance-for</guid>
      <pubDate>Tue, 21 May 2024 04:24:19 GMT</pubDate>
    </item>
    <item>
      <title>具有隐藏变量的时间序列预测</title>
      <link>https://stats.stackexchange.com/questions/647665/time-series-prediction-with-hidden-variables</link>
      <description><![CDATA[我每 10 秒采样一次时间序列数据。我想使用当前时间的输入变量以及过去 10 个滞后来预测提前 5 步的目标变量 𝑦。我的问题是有一个未观察到的隐藏变量影响目标变量𝑦。我如何推断这个隐藏的未观察变量并改进我的预测？我想使用 Python 进行编码。
我使用了 theano 和 arviz。但我不确定正确的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/647665/time-series-prediction-with-hidden-variables</guid>
      <pubDate>Tue, 21 May 2024 02:47:54 GMT</pubDate>
    </item>
    <item>
      <title>Quantile 函数的 Numpy 实现[重复]</title>
      <link>https://stats.stackexchange.com/questions/647659/numpy-implementation-of-the-quantile-function</link>
      <description><![CDATA[我正在尝试围绕有限样本的分位数函数的实现，特别是在 numpy 中（这样做的主要原因：我正在研究保角预测）。我可能遗漏了一些明确的内容，欢迎任何人指出我的明显错误！
假设我们观察值 $\mathcal{X} = \{x_1, x_2 \ldots x_n\}$ 并且我们想要计算 $p \in [0, 1]$ 观察样本的分位数。因此，我们将这个有限样本的分位数函数表示为 $Q(q, \mathcal{X})$。
如果我检查分位数的维基百科页面 (https://en.wikipedia.org/wiki/分位数），我们将分位数定义如下：
$Q(p, \mathcal{X}) := x: P(X
我不是 100% 确定如何解释“$P(X”这里。我认为这是对 e.c.d.f 的引用。 (https://en.wikipedia.org/wiki/Empirical_distribution_function) $\mathcal{X}$。即，“$P(X”可操作为样本中小于 $x$ 的点的比例。因此，我们得到以下等效定义：
$Q(p, \mathcal{X}) = \text{sup}\{x \in \mathbb{R} : \text{ecdf}_\mathcal{ X}(x)＜ p\}$。
到目前为止一切都很好，我相信。假设 $\mathcal{X} = \{2,3,4,10 \}$。现在让我们检查 numpy 的实现：
将 numpy 导入为 np
v = np.array([2,3,4,10])
q_third = np.quantile(v, 1/3) # 3
断言 q_third == 3 # 这是真的！分位数正好是 3

我在这里不知所措。 numpy 告诉我 $Q(\frac{1}{3}, \{2,3,4,10 \}) = 3$。根据上面的定义，我预计 $Q(\frac{1}{4}, \{2,3,4,10 \}) = 3$ 。事实上，上面的定义是不明确的。据我了解，$ Q(\frac{1}{3}, \{2,3,4,10 \})$。
在线性插值（numpy 中的默认方法）下，我们可以假设 $Q(\frac{1}{3}, \{2 ,3,4,10 \}) \neq Q(\frac{1}{3}, \{2,3,4,10 \})$。所以，要么是我，要么是 numpy 错了。我倾向于认为 numpy 在这里一定是正确的，但我无法发现我的错误。如果有人能给我解释一下，我将不胜感激。
我承认有一个类似的问题（分位数的定义&lt; /a&gt;），但该问题的答案只是报告了上面相同的维基百科定义并引用了 R （与此上下文无关）。对我的示例中应用的逻辑 numpy 的解释（希望与我使用的符号相同）将被接受作为答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/647659/numpy-implementation-of-the-quantile-function</guid>
      <pubDate>Mon, 20 May 2024 23:52:30 GMT</pubDate>
    </item>
    <item>
      <title>通过连续交互省略分类中的连续变量</title>
      <link>https://stats.stackexchange.com/questions/647636/omit-continuous-variable-in-categorical-by-continuous-interaction</link>
      <description><![CDATA[我试图了解在本规范中排除收入的主要影响是否有效。无论个体是男性还是女性，性别都是 0/1 变量。收入和净资产是连续的。
净资产 = β0+β1×性别+β2×(性别×收入)+ϵ
根据https://stats.oarc.ucla.edu/stata/faq/what-happens-if-you-omit-the-main-effect-in-a- gression-model-with-an-interaction/，它似乎被正确指定。但其他帖子是表明它指定错误。
回归将产生两个交互项和一个对性别的主效应。据OARC网站称，这两个估计不应该“简单”吗？斜率是按性别划分的收入对因变量的影响之间的关系吗？包括完整的交互作用会产生两组之间的差异，但有时显示简单的斜率可能会更清楚。]]></description>
      <guid>https://stats.stackexchange.com/questions/647636/omit-continuous-variable-in-categorical-by-continuous-interaction</guid>
      <pubDate>Mon, 20 May 2024 19:07:51 GMT</pubDate>
    </item>
    <item>
      <title>在较高 SNR 下的较低误码概率估计精度</title>
      <link>https://stats.stackexchange.com/questions/647634/precision-of-estimates-of-lower-bit-error-probabilities-at-higher-snr</link>
      <description><![CDATA[对于我的无线通信大学实验室，我使用 AWGN（加性高斯白噪声）模拟了一个简单的未编码 BPSK（二进制相移键控）信道，以使用 MLE（最大似然估计）估计 BER（误码率），如下所示一种介绍性任务。间接设置从 -20dB 到 +10dB 的每个 SNR（信噪比）的蒙特卡罗运行次数 $N_{\mathrm{MC}}$通过目标错误计数$N_{\mathrm{err}}$。查看带有对数缩放 y 轴的结果图，威尔逊得分置信区间的大小似乎仅受 $N_{\mathrm{err}}$ 影响。

直观上，这是有意义的，因为宽度随 $\frac{1}{\sqrt{N_{\mathrm{MC}}}}$ 缩放。鉴于这是一个如此简单的信道模型，我们还知道真正的 BER 是 $Q(\sqrt{2 \mathrm{SNR}})$ 和 MLE只是收敛到它以获得足够大的样本量。到目前为止一切都很好，但我还注意到，在查看蒙特卡罗运行结果与 SNR 的比较时，对于固定的 $N_{\mathrm{err} ，较高的 SNR 下的 BER 较低}$ 需要更大的样本量才能发生足够的错误事件。 
鉴于此任务的目的可能是教我们如何在估计精度和计算负载之间进行权衡，我现在很困惑，较高 SNR 下的较大样本量是否实际上意味着对那些低 BER 估计的置信度较高。另一方面，它也感觉违反直觉，因为较低的概率显然需要更大的样本量来估计。如果低 BER/高 SNR 估计确实更精确，那么对数图上的对称相对误差线是否有意义？我认为在这种情况下，绝对误差线不会在视觉上产生误导。
编辑：根据要求解释缩写词]]></description>
      <guid>https://stats.stackexchange.com/questions/647634/precision-of-estimates-of-lower-bit-error-probabilities-at-higher-snr</guid>
      <pubDate>Mon, 20 May 2024 19:05:26 GMT</pubDate>
    </item>
    <item>
      <title>使用 F 检验进行受限模型与非受限模型的错误答案</title>
      <link>https://stats.stackexchange.com/questions/647630/using-f-test-for-restricted-model-vs-unrestricted-wrong-answer</link>
      <description><![CDATA[在学习计量经济学时，我遇到了这个问题，但我找不到正确的答案：
假设家庭在食品上的支出百分比与家庭总支出和规模呈线性关系：$$\text{wfood}_i = \beta_1 + \beta_2 \text{totexp}_i + \beta_3 \text{size}_i$$使用 F 检验对受限和非受限模型检验一个假设$H_0$，即系数$\beta_1, \beta_2, \beta_3$不依赖于$\text{sex}_i$。备选假设是 $\beta_1, \beta_2, \beta_3$ 中至少有一个会发生变化。
我使用
$$F=\frac{(RSS_R-RSS_{UR})/r}{RSS_{UR}/(n-k_{UR})} \sim F_{r, k_{UR}}$$
测试受限模型（第一个）与不受限制的模型（添加 $+\beta_4\text{sex(woman)}_i$），但得到了错误的 F 统计量值（我必须选择其中一个变体，但那里没有这样的值；预期值为 $2.4$ 或 $24.4$）。
我该怎么做：
library(Ecdat)
data(&quot;BudgetFood&quot;)

b &lt;- na.omit(BudgetFood)
model_r &lt;- lm(data = b, wfood ~ totexp + size)
model_ur &lt;- lm(data = b, wfood ~ totexp + size + sex)

r &lt;- 2
n &lt;- count(b)$n
k_UR &lt;- 4

RSS_UR &lt;- deviance(model_ur)
RSS_R &lt;- deviance(model_r)

Fstatistic &lt;- ((RSS_R - RSS_UR) / r) / (RSS_UR / (n - k_UR))

Fstatistic # 0.145555

qf(0.975, r, n - k_UR) # 3.689447

我很感激任何想法。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/647630/using-f-test-for-restricted-model-vs-unrestricted-wrong-answer</guid>
      <pubDate>Mon, 20 May 2024 18:17:57 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归模型的单侧似然比检验？</title>
      <link>https://stats.stackexchange.com/questions/647549/one-sided-likelihood-ratio-test-for-a-logistic-regression-model</link>
      <description><![CDATA[我需要对逻辑回归模型的一个参数进行单侧检验：
$H_0$：$\beta = 0$
$H_1$：$\beta \geq 0$
我想避免使用 Wald 等效方法，因为这些方法在逻辑回归中存在问题。（Piegorsch，1990）表明，基于单侧似然比的检验对于 glms 是可行的。有没有在 R 中实现过？
如果没有，以下是实现检验的合法方法吗（对于 alpha = 0.05）？

使用 confint 计算双侧 90% 置信区间；请注意，自 R 4.4.0 起，它使用 MASS 的轮廓似然法。
用 -∞ 替换 CI 的下限以获得单侧置信区间。
如果 CI 不包括 0，则拒绝 H0。

Piegorsch W. W. (1990)。二分响应下广义线性模型的单侧显着性检验。生物统计学，46(2)，309–316。]]></description>
      <guid>https://stats.stackexchange.com/questions/647549/one-sided-likelihood-ratio-test-for-a-logistic-regression-model</guid>
      <pubDate>Sun, 19 May 2024 12:39:11 GMT</pubDate>
    </item>
    <item>
      <title>如何衡量关系的强度</title>
      <link>https://stats.stackexchange.com/questions/647513/how-to-measure-the-strength-of-relationship</link>
      <description><![CDATA[我想使用单变量 $x$ 来预测单变量 $y$。两者都是近似正常时间序列。
当我对 $x$ 的滞后值运行 $y$ 的 OLS 时，我得到了显着的结果t-stat (~5) 但 R2 较低 (&lt; 1%)。
鉴于 R2 较低，我试图确定是否应该依赖较大的 $x$ 来预测较大的 $y$，或者如果其中大部分只是噪音。
因此，我在 $sign(x)$ 上运行了另一个 $y$ 的 OLS。在这种情况下，t-stat 和 R2 都略低。
两个回归的残差都非常正常——没有异方差或自相关。 Durbin Watson 和 jarque bera 都通过了。
我使用的方法有什么问题吗？或者有更好的方法来确定噪声与信号的行为？]]></description>
      <guid>https://stats.stackexchange.com/questions/647513/how-to-measure-the-strength-of-relationship</guid>
      <pubDate>Sat, 18 May 2024 17:30:07 GMT</pubDate>
    </item>
    <item>
      <title>哪种分布的 RV 乘积能够很好地逼近正态分布？</title>
      <link>https://stats.stackexchange.com/questions/647474/product-of-rvs-of-which-distribution-approximates-normal-well</link>
      <description><![CDATA[假设我有 $N$ i.i.d.分布为 $Q$ 的随机变量，均值约为 1。即 $R_1, R_2,\ldots,R_N \sim Q$。我希望 $\prod_{i=1}^N R_i$ 近似于正态随机变量。
$Q$ 的一些候选分布是什么，以便我得到一个合理的近似值 $N$ 变得更大？]]></description>
      <guid>https://stats.stackexchange.com/questions/647474/product-of-rvs-of-which-distribution-approximates-normal-well</guid>
      <pubDate>Sat, 18 May 2024 07:11:25 GMT</pubDate>
    </item>
    <item>
      <title>Cox 模型中的三次样条</title>
      <link>https://stats.stackexchange.com/questions/647461/cubic-splines-in-cox-model</link>
      <description><![CDATA[我写在这里是因为我对 Cox 模型中用于测试连续变量线性度的三次样条有疑问。我读到通常选择的结是数量。如果改变结，你会发现不同的结果吗？我读到，与节数相关的选择很重要。如果您选择的结与样本大小相比过多，则可能会出现过度拟合。我想知道结的位置。如果我改变结的位置，这会影响结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647461/cubic-splines-in-cox-model</guid>
      <pubDate>Sat, 18 May 2024 01:21:57 GMT</pubDate>
    </item>
    <item>
      <title>从高斯分布中获取的一式三份样本中观测值分布的分布</title>
      <link>https://stats.stackexchange.com/questions/647422/distribution-of-a-spread-of-observations-in-triplicate-sample-taken-from-gaussia</link>
      <description><![CDATA[假设从具有已知均值和 SD 的高斯分布中随机抽取一式三份样本。每个样本中 3 个可能的观测值对之间的最大绝对差应该是什么分布（一式三份的范围）？]]></description>
      <guid>https://stats.stackexchange.com/questions/647422/distribution-of-a-spread-of-observations-in-triplicate-sample-taken-from-gaussia</guid>
      <pubDate>Fri, 17 May 2024 11:25:49 GMT</pubDate>
    </item>
    <item>
      <title>了解 PROC LOGISTIC (SAS) SCORE 语句中的 PRIOR 选项</title>
      <link>https://stats.stackexchange.com/questions/645222/understanding-prior-option-in-score-statement-for-proc-logistic-sas</link>
      <description><![CDATA[假设我有一个二元响应，我想使用协变量 $x$ 上的逻辑回归进行建模。使用 PROC LOGISTIC 拟合模型将拟合模型的 MLE 系数
$$
\text{logit}(\pi) = \alpha + \beta&#39; x
$$
其中 $\pi = \pi(x) = \mathbb{P}(y=1|x)$。
如果我们在训练数据集上构建这个模型，我们可以使用 OUTMODEL 来保存模型信息。假设我们想要获得新数据集的预测概率，我们可以使用 INMODEL 和 SCORE 语句对该数据集进行评分。
现在，我注意到 SCORE 语句中有一个 PRIOR/PRIOREVENT 选项，它允许指定事件的先验概率 $y=1$。我明白为什么这很有用；例如，如果训练数据集中的类别比例与现实中的真实比例非常不同（例如罕见疾病分类）。
SAS 文档说“通过指定正确的先验，可以适当调整后验概率。”因此，使用此选项应该调整预测概率。
我的问题是：如何进行调整？
我有以下理论的灵感来自这篇文章，但在 SAS 文档中找不到任何内容来证实这一点：
&lt;块引用&gt;
令 $p_\text{train}$ 为训练数据中事件的比例，
并令 $p_\text{prior}$ 为事件的先验概率。然后
在对数赔率级别，我们进行调整： $$ \alpha + \beta&#39; x +
 \left(\log\left(\frac{p_\text{先验}}{1-p_\text{先验}}\right) - \log\left(\frac{p_\text{train}}{1- p_\text{train}}\right)\right)。 $$ 换句话说，我们调整后的
预测（后验）概率变为 $$
 \text{logit}^{-1}(\alpha + \beta&#39; x + \left(\log\left(\frac{p_\text{先验}}{1-p_\text{先验}}\right) - \log\left(\frac{p_\text{train}}{1-p_\text{train}}\right)\right)。

编辑：我发现这里 SAS给出了调整后的概率为：
$$
\mathbb{P}(y=i|x) = \frac{\mathbb{P}_0(y=i|x)\cdot \frac{p_n(y=i)}{p_0(y=i)}} {\sum_j \mathbb{P}_0(y=j|x)\cdot \frac{p_n(y=j)}{p_0(y=j)}},
$$
其中 $p_0(y=i)$ 是旧类概率（来自训练集中的比例），$p_n (y=i)$ 是用 PRIOR 指定的新先验，$\mathbb{P}_0$ 表示未经调整的预测概率。
我觉得这个表达很有趣，我认为它实际上可能等同于我上面建议的答案，但我没有证据。然而，我们可以采用这个表达式，用它来计算赔率，简化并应用贝叶斯规则，得到（调整后的）赔率 = 数据似然比乘以 $y 的赔率比$ 之前。对我来说（考虑到前面链接的文章）这表明它们是等效的。]]></description>
      <guid>https://stats.stackexchange.com/questions/645222/understanding-prior-option-in-score-statement-for-proc-logistic-sas</guid>
      <pubDate>Wed, 17 Apr 2024 12:08:34 GMT</pubDate>
    </item>
    </channel>
</rss>