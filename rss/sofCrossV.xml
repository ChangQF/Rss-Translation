<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 05 Feb 2025 03:20:08 GMT</lastBuildDate>
    <item>
      <title>GLMMadaptive 中零膨胀 Beta 负二项式的自定义密度函数</title>
      <link>https://stats.stackexchange.com/questions/660976/custom-density-function-for-zero-inflated-beta-negative-binomial-in-glmmadaptive</link>
      <description><![CDATA[我注意到，在 GLMMadaptive R 包的 hybrid_model 函数中，可以编写自定义密度函数。我正尝试为 零膨胀 beta 负二项式 (ZIBNB) 模型定义密度函数，并且有几个问题。
具体来说，我想知道该模型是否可以估计两组独立的固定效应。对于 beta 负二项式模型的计数分量，假设 r 是固定的，则需要估计 $\alpha$ 和 $\beta$。
如果模型有四个协变量，那么我希望估计 alpha 的四个参数和 beta 的四个参数。我意识到要包含一组额外的参数，我需要指定 n_phi，但是当我设置 n_phi &gt; 1，我遇到了与矩阵计算相关的错误。
有人遇到过类似的问题或对如何在此情况下正确指定多个固定效应有什么建议吗？任何建议都将不胜感激！
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660976/custom-density-function-for-zero-inflated-beta-negative-binomial-in-glmmadaptive</guid>
      <pubDate>Wed, 05 Feb 2025 02:22:49 GMT</pubDate>
    </item>
    <item>
      <title>如何匹配均值、方差和偏度</title>
      <link>https://stats.stackexchange.com/questions/660974/how-to-do-matching-on-mean-variance-and-skewness</link>
      <description><![CDATA[我正在分析一项政策对结果 y 的影响。但是，混杂因素 x 也可能影响 y，并在治疗组和对照组中显示不同的模式。
在对 y 运行组虚拟变量回归之前，我试图执行匹配方法来平衡治疗组和对照组。
我应该如何设置匹配以在混杂因素 x 的均值、方差和偏度上创建相似的治疗组和对照组？
数据看起来像
library(ggplot2)
library(sn)
set.seed(1)
x1 &lt;- rsn(n = 1000, xi = 3, omega = 3, alpha = 5) 
x2 &lt;- rsn(n = 1000, xi = 2, omega = 2, alpha = 0) 
df &lt;- data.frame(
x = c(x1, x2),
y = rnorm(2000),
group = rep(c(&quot;treated&quot;, &quot;control&quot;), each = 1000)
)
ggplot(df, aes(x = x, fill = group)) +
geom_density(alpha = 0.5) +
theme_minimal() 


提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/660974/how-to-do-matching-on-mean-variance-and-skewness</guid>
      <pubDate>Wed, 05 Feb 2025 00:00:03 GMT</pubDate>
    </item>
    <item>
      <title>泊松回归的大 O 复杂度是多少？</title>
      <link>https://stats.stackexchange.com/questions/660970/what-is-the-big-o-complexity-of-poisson-regression</link>
      <description><![CDATA[我发现几个类似的问题提到了 O(n p2)，但没有一个问题引用了来源。有谁知道有哪篇文章提供了大 O 复杂度并证明了它的合理性？]]></description>
      <guid>https://stats.stackexchange.com/questions/660970/what-is-the-big-o-complexity-of-poisson-regression</guid>
      <pubDate>Tue, 04 Feb 2025 22:03:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么标准误差总是零</title>
      <link>https://stats.stackexchange.com/questions/660967/why-is-standard-error-always-zero</link>
      <description><![CDATA[假设，我想确定每次抛硬币时是否都是正面。所以我设计了一个实验，其中$N=5$。所以我抛了 5 次，得到了 5 次正面。
我想测量我的置信区间，所以我需要标准误差。
$\hat p=1$
$SE=0$
置信区间是$(1,1)$。
但直观上看这是胡说八道，对吧？我的信心难道不应该随着$N$的增加而增加吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660967/why-is-standard-error-always-zero</guid>
      <pubDate>Tue, 04 Feb 2025 21:12:38 GMT</pubDate>
    </item>
    <item>
      <title>AR 流程偏差和其他问题</title>
      <link>https://stats.stackexchange.com/questions/660965/ar-process-skew-and-other-moments</link>
      <description><![CDATA[我读过这篇文章：分析 ACF 和 PACF 图，评论中指出数据有左偏，这对 AR 过程来说是一个问题。
我想知道为什么这是一个问题，以及在时间序列上能够执行 ACF 图并得出该时间序列是具有统计意义的自回归的结论的一般条件是什么。
我的猜测是，偏斜意味着您有更多机会在分布的左侧拥有数据，因此您可能会发现虚假相关性？因为数据更有可能位于分布的同一侧，而如果偏斜为 0，情况就不是这样。
所以我的猜测是，我们不希望时间序列的分布有任何不对称。因此，我会直观地说，要执行 AR 分析，以便我们可以以一定的统计意义说该过程是 AR，我们需要始终：$E[X^n]$ 当 $n$ 为奇数时等于 $0$。我的直觉正确吗？如果是，有办法证明吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660965/ar-process-skew-and-other-moments</guid>
      <pubDate>Tue, 04 Feb 2025 19:37:09 GMT</pubDate>
    </item>
    <item>
      <title>shap 如何计算单个预测的特定变量值的目标移动量？</title>
      <link>https://stats.stackexchange.com/questions/660962/how-shap-calculates-the-movement-amount-of-target-for-a-specific-variable-value</link>
      <description><![CDATA[在 shap 瀑布图（或 force_plot）中，对于每个单独的预测，特定变量值将概率或目标移动到一定量，例如，在下图中，chlorides = 0.171 将 f(x) 移动 -0.32。
f(x) = E(f(x)) + 该个体所有变量的 shap 值之和

该个体的氯化物移动 -0.32 背后的原理是什么？ shap 如何计算 chlorides = 0.171 的移动为 -0.32，假设另一个人，chlorides = 0.8 的移动为 +0.45？
假设这是 xgboost 的 shap 解释。
https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/waterfall.html
谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660962/how-shap-calculates-the-movement-amount-of-target-for-a-specific-variable-value</guid>
      <pubDate>Tue, 04 Feb 2025 18:25:31 GMT</pubDate>
    </item>
    <item>
      <title>实现扩散生成模型进行数据增强，但训练损失值太高</title>
      <link>https://stats.stackexchange.com/questions/660969/implementing-a-diffusion-generative-model-for-data-augmentation-but-training-los</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660969/implementing-a-diffusion-generative-model-for-data-augmentation-but-training-los</guid>
      <pubDate>Tue, 04 Feb 2025 16:56:25 GMT</pubDate>
    </item>
    <item>
      <title>在嵌套的 cv 中选择任意替代模型都可以吗？</title>
      <link>https://stats.stackexchange.com/questions/660958/is-it-okay-to-select-any-of-the-surrogate-models-in-nested-cv</link>
      <description><![CDATA[假设我选择嵌套 cv 中的任意一个获胜的替代模型（理论上，如果你进行 k 次外折叠，你就可以有 k 个替代模型）为了简化事情，假设我选择第一个模型并只报告所有折叠的平均值作为其性能估计。我的理由如下

唯一真正的随机性来源是外循环的训练/测试分割

一旦我们选择了训练/测试分割，获胜模型和测试集性能错误就会得到修复。

通过对称性，这意味着每个性能错误对于剩余的 k-1 个循环都是相同分布的。


但这是否意味着对这些 k 个测试集性能错误中的每一个进行平均（即使它是不同的算法 + 训练集）会给我们一个关于第一个获胜模型的泛化错误的无偏估计？
我知道更“严格”的程序是使用 cv 在整个数据集上重新执行模型选择程序，然后在完整数据集上重新训练所选算法，但想知道这种推理是否仍然正确
我明白了嵌套 cv 测量更像是您的模型生产程序，但由于第一个外循环中的第一个模型是通过对您的模型生产程序的估计创建的，因此平均性能估计仍然有效，不是吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660958/is-it-okay-to-select-any-of-the-surrogate-models-in-nested-cv</guid>
      <pubDate>Tue, 04 Feb 2025 15:34:00 GMT</pubDate>
    </item>
    <item>
      <title>对称狄利克雷序统计量的一阶矩</title>
      <link>https://stats.stackexchange.com/questions/660955/the-first-moment-of-symmetric-dirichlet-order-statistics</link>
      <description><![CDATA[设 $\mathbf q\in[0,1]^n$ 为服从对称狄利克雷分布的随机向量，其参数为 $\alpha$:
$$
\mathbf{q}\sim \operatorname{Dir}(\alpha,\cdots,\alpha).
$$
将 $q_{(i)}$ 定义为 $\mathbf{q}$ 的 $i$ 阶统计量，按升序排列：
$$
q_{(1)}\le\cdots\le q_{(n)}.
$$
问题。 $E[q_{(i)}]$ 是什么？
我们可以将 $q_i$ 表示为
$$
q_i=\frac{z_i}{\sum_{k=1}^nz_k}
$$
对于 i.i.d. $z_i\sim\operatorname{Gamma}(\alpha,\lambda)$。
当 $\alpha=1$ 时，$E[q_{(i)}]$ 的表达式很简单。 Rényi 的表述表明
$$
z_{(i)}=\sum_{k=1}^i\frac{d_i}{n-k+1}
$$
其中 i.i.d. $d_i\sim\operatorname{Exp}(\lambda)$ 和 $\sum_{k=1}^nd_k=\sum_{k=1}^nz_k$。现在我们有
$$
q_{(i)}=\frac{z_{(i)}}{\sum_{k=1}^nz_k}=\sum_{k=1}^i\frac1{n-k+1}\underbrace{\frac{d_i}{\sum_{t=1}^nd_t}}_{=:D_i}。
$$
由于
$$
(D_1,\cdots,D_n)\sim\operatorname{Dir}(1,\cdots,1),
$$
$D_i$ 的一阶矩为
$$
E[D_i]=\frac1n,
$$
且
$$
E[q_{(i)}]=\frac1n\sum_{k=1}^i\frac1{n-k+1}。
$$
我试图将其推广到任何 $\alpha&gt;0$。我发现一些论文从伽马分布中得出了顺序统计的一阶矩。但在 $q_{(i)}$ 的表达式中，分子 $z_{(i)}$ 和分母 $\sum_{k=1}^nz_k$ 显然不是独立的；我需要推导出 $q_{(i)}$ 整体的矩。
如能得到任何帮助，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660955/the-first-moment-of-symmetric-dirichlet-order-statistics</guid>
      <pubDate>Tue, 04 Feb 2025 14:44:07 GMT</pubDate>
    </item>
    <item>
      <title>使用小样本校正对后双套索估计残差进行校正</title>
      <link>https://stats.stackexchange.com/questions/660954/using-small-sample-correction-for-estimated-residuals-in-post-double-lasso</link>
      <description><![CDATA[后双重选择是一种在高维稀疏模型中对低维参数进行推理的方法。原始论文之一由Belloni、Chernozhukov 和 Hansen (2014) 在 ReStud 中撰写。他们考虑了一个部分线性模型：
\begin{align*} 
y_i &amp;= d_i \alpha_0 + g(z_i) + \zeta_i, &amp;E[\zeta_i | z_i, d_i] = 0 \\
d_i &amp;= m(z_i) + \nu_i, &amp;E[\nu_i | z_i] = 0。
\end{align*&gt;
用他们的话来说，该方法可以总结如下：

在第一步中，我们选择一组可用于预测治疗$d_i$的控制变量。此步骤有助于通过查找与治疗密切相关的控制变量（因此可能是重要的混杂因素）来确保模型选择后推断的有效性。
在第二步中，我们通过选择预测$y_i$的控制变量来选择其他变量。此步骤有助于确保我们已捕获感兴趣的方程中的重要元素，理想情况下有助于保持残差方差较小，并提供额外的机会来找到重要的混淆因素。
在最后一步中，我们通过$y_i$对治疗$d_i$的线性回归以及在两个变量选择步骤中选择的变量集的并集来估计感兴趣的治疗效果$\alpha_0$。

他们的主要理论结果如下图所示。这里 $\widehat{s}$ 表示上述算法中回归步骤 3 中包含的回归量的数量（即步骤 1 和 2 的并集）。

可以看出，为了估计估计量的方差，人们使用 $\widehat{\zeta}_i$ 和 $\widehat{\nu}_i$ 来估计残差。为了估计 $\widehat{\zeta}_i$，我们使用了小样本偏差校正，类似于用于估计经典样本方差的偏差校正。这在高维设置中很有意义，因为可以想象 $\widehat{s}$ 可能接近 $n$。当使用$\widehat{s} \geq n$时，甚至可以得到全为零的残差，这将为模型中的真实误差提供非常差的估计。
有谁知道或直觉为什么不应用这种偏差校正$\widehat{\nu}_i$？我们还针对此回归采用了变量选择，并且非零回归量的数量可能相对接近$n$？
我的问题与此帖子有关，但略有不同，因为该问题侧重于特定的 stata 实现，而我的问题是关于不使用偏差校正$\widehat{\nu}_i$背后的直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/660954/using-small-sample-correction-for-estimated-residuals-in-post-double-lasso</guid>
      <pubDate>Tue, 04 Feb 2025 14:07:16 GMT</pubDate>
    </item>
    <item>
      <title>如何比较联合概率分布？</title>
      <link>https://stats.stackexchange.com/questions/660951/how-to-compare-joint-probability-distributions</link>
      <description><![CDATA[假设我有两类数据，以成对的列表形式给出：
$$
\begin{align}
D&amp;=\{(d_1,t_1),(d_2,t_2),\cdots,(d_N,t_N)\}\\
\tilde{D}&amp;=\{(\tilde{d}_1,\tilde{t}_1),(\tilde{d}_2,\tilde{t}_2),\cdots,(\tilde{d}_\tilde{N},\tilde{t}_\tilde{N})\}
\end{align}
$$
对于任意长度 $N,\tilde{N}$。假设 $d_i,\tilde{d}_i$ 是误差值（某种度量），$t_i,\tilde{t}_i$ 是时间点。我怀疑 $D$ 中的数据与 $\tilde{D}$ 中的数据相比，在较晚的时间点，其误差会更大。但是，我想量化这一点，并以某种统计显著的方式表明情况确实如此。
最好的方法是什么？如何比较这些联合分布？我听说过配对 $t$ 检验，但我想知道是否还有其他方法我应该考虑，因为我具体假设在以后的时间点会出现更高的错误。
我不太熟悉统计学，所以如果有我应该尝试的自然测试，我提前道歉。任何指导都将不胜感激！
编辑：作为一个激励性的例子，以下是一个展示 $D$ (蓝色) 和 $\tilde{D}$ (红色) 示例的图表。作为参考，我并不期望这些特定数据会以任何特定的方式表现，但我想以统计显著的方式测试和形式化比较。
]]></description>
      <guid>https://stats.stackexchange.com/questions/660951/how-to-compare-joint-probability-distributions</guid>
      <pubDate>Tue, 04 Feb 2025 13:33:26 GMT</pubDate>
    </item>
    <item>
      <title>我应该在我的分析中报告 q 值还是调整后的 p 值？</title>
      <link>https://stats.stackexchange.com/questions/660943/should-i-report-q-values-or-adjusted-p-values-in-my-analysis</link>
      <description><![CDATA[我目前正在处理一个涉及多重假设检验的数据集，我对是否要报告 q 值或调整后的 p 值 (p.adjust) 有点困惑。我了解技术差异，但我不确定哪一个更适合在我的结果中呈现。我很感激任何有关这方面的指导。
我目前的理解：
调整后的 p 值 (p.adjust)：这是针对多重比较进行校正的 p 值。它表示在零假设下，根据执行的测试次数进行调整后，观察到至少与获得的结果一样极端的结果的概率。
示例：对于我的第一个测试，p.adjust 为 0.02，这意味着只有当我接受校正后的 2% 的显着性水平时，它才会被视为显着。
q 值：这测量了错误发现率 (FDR)，表示在所有被声明为显著的结果中预期的假阳性比例。
示例：第一次测试的 q 值为 0.01，这意味着如果我将所有 q ≤ 0.01 的结果视为显著，则其中约 1% 预计为错误发现。
鉴于此，报告 q 值或调整后的 p 值是否更有意义？是否存在其中一种优于另一种的特定场景？
在 miRNA 分析的背景下，目标通常是识别一组差异表达的 miRNA 以进行进一步的生物学解释。我有 111 个 miRNA，它们在不同途径中具有不同的相互作用。从一个考虑了对我们研究有意义的协变量的详细模型中，我们选择了 15 个 miRNA 来考虑我们模型的重要性。这 15 个 miRNA 被描述为调节几种途径中的基因，产生不同的重要性指标（padj、qvalue……）
提前感谢您的任何见解！如有需要，请进一步说明。]]></description>
      <guid>https://stats.stackexchange.com/questions/660943/should-i-report-q-values-or-adjusted-p-values-in-my-analysis</guid>
      <pubDate>Tue, 04 Feb 2025 11:48:14 GMT</pubDate>
    </item>
    <item>
      <title>计算平均变化（平均差异）和 SD 变化</title>
      <link>https://stats.stackexchange.com/questions/660939/calculate-the-mean-change-mean-difference-and-sd-change</link>
      <description><![CDATA[我想估计手术前后细胞密度的平均变化（平均差异）和 SD 变化。

有些研究没有直接提供这些值。相反，他们报告了平均年度细胞损失（细胞/平方毫米/年）及其 SD，如下所示：

o 0–1 年：228.1 ± 319.7
o 1–2 年：93.1 ± 129.3
o 2–3 年：80.7 ± 125.3
o 3–4 年：47.8 ± 83.3
o 4–5 年：18.7 ± 93.5
假设初始细胞计数为 mean_baseline = 2148 ± 604，是否有可能估计整个 0–5 年期间而不是每个年份的 mean_final 和 SD_final 或 mean_change 和 SD_change？

其他一些研究报告mean_baseline，例如 1968.2 ± 719.0，并指出 24 个月后，细胞损失为 14.6 ± 5.0%（百分比和百分比的 SD）。在这种情况下，是否可以计算 mean_final 和 SD_final 或 mean_change（平均差异）和 SD_change？

这些方法在统计上是否不正确？
提前感谢您的时间和宝贵的指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/660939/calculate-the-mean-change-mean-difference-and-sd-change</guid>
      <pubDate>Tue, 04 Feb 2025 08:00:12 GMT</pubDate>
    </item>
    <item>
      <title>什么不是马尔可夫链？</title>
      <link>https://stats.stackexchange.com/questions/660919/what-is-not-a-markov-chain</link>
      <description><![CDATA[不久前我学习了马尔可夫链，它对我来说很有意义。如果系统状态之间的转换和这些转换的概率不依赖于系统的先前状态，那么系统所遵循的任何过程都被归类为马尔可夫链。但后来我学习了高阶马尔可夫链，据我所知，它总是可以表示为一阶马尔可夫链，尽管这在实践中可能并不理想，因为这种表示将具有更多节点。所以现在我想知道哪些过程不能表示为马尔可夫链。]]></description>
      <guid>https://stats.stackexchange.com/questions/660919/what-is-not-a-markov-chain</guid>
      <pubDate>Mon, 03 Feb 2025 20:09:37 GMT</pubDate>
    </item>
    <item>
      <title>最小二乘估计量投影视图中的帽子矩阵的维数</title>
      <link>https://stats.stackexchange.com/questions/660854/dimensionality-of-the-hat-matrix-in-the-projection-view-of-the-least-squares-est</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660854/dimensionality-of-the-hat-matrix-in-the-projection-view-of-the-least-squares-est</guid>
      <pubDate>Sat, 01 Feb 2025 18:28:03 GMT</pubDate>
    </item>
    </channel>
</rss>