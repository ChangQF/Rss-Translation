<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 05 Sep 2024 12:31:20 GMT</lastBuildDate>
    <item>
      <title>将因子变量纳入 GAM 时产生的矛盾解释</title>
      <link>https://stats.stackexchange.com/questions/653909/contradicting-interpretations-when-including-factor-variables-into-gam</link>
      <description><![CDATA[我建立的模型是这样的：
bam(n ~ s(age, k = 10, m = 2) + 
s(hh_size, k = 7, m = 2) +
s(age, by = pp, k = 10, bs = &quot;tp&quot;, m = 1) +
s(hh_size, by = pp, k = 7, bs = &quot;tp&quot;, m = 1) +
(employment_2cat + weekend + region + marital_2cat + education_2cat)* period * place + 
s(token, k = 864, bs = &quot;re&quot;) + 
s(Bundesland, k = 16, bs = &quot;re&quot;), data = halle_data, family = nb(), method = &quot;fREML&quot;,
drop.unused.levels = FALSE)
# pp 是时期和地点之间的相互作用。

拟合模型后，使用 summary() 获得参数系数。应用 emmeans()、pairs() 和 contrast() 来获取时期和地点对每个因子变量的影响。但结果似乎不对。

从模型的summary()结果来看，可以解释为“未就业”与“就业”相比，联系人数的对数增加25.5%。但从pairs()的结果来看，就业似乎与更高级别的联系有关。这种相互矛盾的解释也出现在周末变量中。

从 summary() 的结果来看，周末的接触次数比工作日多。但从 pairs() 的结果来看，工作日的接触次数比周末多。]]></description>
      <guid>https://stats.stackexchange.com/questions/653909/contradicting-interpretations-when-including-factor-variables-into-gam</guid>
      <pubDate>Thu, 05 Sep 2024 12:19:33 GMT</pubDate>
    </item>
    <item>
      <title>在面板数据中筛选出有/无振荡模式的样本的好方法？</title>
      <link>https://stats.stackexchange.com/questions/653908/good-method-for-sorting-out-samples-with-without-oscillation-pattern-in-panel-da</link>
      <description><![CDATA[我有生物医学面板数据。一些变量是时间序列（约 320 名参与者的血液测试），样本很少（约 20-100 个），其他变量随时间固定（年龄、身高……）。在某个时间点有干预，我想研究它对时间序列的影响。一些序列在图形上似乎在干预后立即呈现出振荡模式（X 轴上约为 0，原因不明），而其他序列则没有。有什么好方法可以将振荡序列与非振荡序列隔离开来以调查发生了什么？我目前正在尝试使用一阶和二阶导数，但无济于事。
]]></description>
      <guid>https://stats.stackexchange.com/questions/653908/good-method-for-sorting-out-samples-with-without-oscillation-pattern-in-panel-da</guid>
      <pubDate>Thu, 05 Sep 2024 11:25:28 GMT</pubDate>
    </item>
    <item>
      <title>brms 中 CAR 的稀疏邻接矩阵？</title>
      <link>https://stats.stackexchange.com/questions/653907/sparse-adjacency-matrix-for-car-in-brms</link>
      <description><![CDATA[我想在 R 包 brms 中拟合一个模型。我的数据由空间多边形组成，我想使用条件自回归来解释自相关。这在 brms 中是可能的，但需要空间邻接矩阵 M。我的问题是我有太多多边形，而我的 M 无法装入内存。
有没有办法在 brms 中使用稀疏矩阵表示？
我的代码：
fit &lt;- brms::brm(
formula = eco_stat_2 ~
shannon + LoadTPArea + LoadTN_Are +
lu_r_urb + lu_r_agr + hy_maf_abs + hy_bfi_abs +
msPAFP5EC5 + car(M = neighbours, type = &quot;escar&quot;),
data = data,
data2 = list(neighbors = neighbours2),
family =cumulative(&quot;logit&quot;),
cores = 6
)

我已经尝试使用 shape2mat() 创建稀疏 M来自 geostan，它创建了 M 的 ngCMatrix 版本。使用此 M 运行上述模型返回错误：
validate_car_matrix(get_from_data2(M, data2)) 中的错误：
此类“ngCMatrix”对象没有 namen“x”的插槽
]]></description>
      <guid>https://stats.stackexchange.com/questions/653907/sparse-adjacency-matrix-for-car-in-brms</guid>
      <pubDate>Thu, 05 Sep 2024 10:50:59 GMT</pubDate>
    </item>
    <item>
      <title>比较同一模型对不同数据集回归的参数</title>
      <link>https://stats.stackexchange.com/questions/653906/compare-parameters-of-same-model-regressed-to-different-data-sets</link>
      <description><![CDATA[我正在寻找解决我提出的问题的指导：如何评估不同的数据集是否具有不同的回归参数，同时考虑相同的模型。
上下文是对 3 个不同样本进行的实验。我事先不知道这些样本是否来自不同的材料，而这正是我想通过查看回归参数的差异来评估的。
实验包括改变施加到样本上的力水平，并在该力水平下对给定的材料属性进行 N 次测量。然后我们取平均值和标准偏差。测试了八个力水平，从而得出八个不同的材料属性值。材料属性预计取决于遵循线性模型的力水平，并且这种线性模型描述的依赖性本身可以被视为材料的特性。这就是为什么我专注于比较样本在回归参数方面的差异，而不仅仅是在不同力水平上测量的属性的平均值。
完成所有实验后，最终输出是三个数据集，每个数据集包含八个不同力水平的八对平均值和标准偏差，以及拟合的线性模型。下面我给出了一个 Python 代码，它非常接近地模拟了我拥有的真实数据集。添加的噪声是任意选择的，以在视觉上模拟真实数据。
import numpy as np
import matplotlib.pyplot as plt

#这是为了模拟材料如何真正依赖于力水平
#当然，这个定律在现实世界中是未知的
def trueSampleDependencyOnForce (X, alfa, beta):
return alfa*X+beta

np.random.seed(42)

######### 实验数据（例如，此处人工生成）

#这是独立变量
X_forceApplied = np.arange(1,9,1)+np.random.normal(0,0.2,8)

#这些是在不同力水平下测量的材料特性
Y_propA_noise = np.random.normal(0,0.3,8)+1.5
Y_propA_error = (Y_propA_noise)**2
Y_propA = trueSampleDependencyOnForce(X_forceApplied, 0.5, 15)+Y_propA_noise

Y_propB_noise = np.random.normal(0,0.3,8)+1.2
Y_propB_error = (Y_propB_noise)**2
Y_propB = trueSampleDependencyOnForce(X_forceApplied, 0.75, 20)+Y_propB_noise

Y_propC_noise = np.random.normal(0,0.3,8)+1.5
Y_propC_error = (Y_propC_noise)**2
Y_propC = trueSampleDependencyOnForce(X_forceApplied, 0.85, 18)+Y_propC_noise

#绘制实验图数据
plt.errorbar(X_forceApplied,Y_propA,yerr=Y_propA_error,fmt=&quot;X&quot;,capsize=5,label=&quot;样本 A&quot;)
plt.errorbar(X_forceApplied,Y_propB,yerr=Y_propB_error,fmt=&quot;o&quot;,capsize=5,label=&quot;样本 B&quot;)
plt.errorbar(X_forceApplied,Y_propC,yerr=Y_propC_error,fmt=&quot;v&quot;,capsize=5,label=&quot;样本 C&quot;)

########## 我正在为每个组拟合一个线性模型
from scipy.optimize import curve_fit

def regressingModel(x, a, b):
return a *x + b

params_A, 协方差 = curve_fit(regressingModel, X_forceApplied, Y_propA, p0=(1,1), sigma=Y_propA_error, absolute_sigma=True)
Y_fit_A = regressingModel(X_forceApplied,*params_A)
params_B, 协方差 = curve_fit(regressingModel, X_forceApplied, Y_propB, p0=(1,1), sigma=Y_propB_error, absolute_sigma=True)
Y_fit_B = regressingModel(X_forceApplied,*params_B)
params_C, 协方差 = curve_fit(regressingModel, X_forceApplied, Y_propC, p0=(1,1), sigma=Y_propC_error, absolute_sigma=True)
Y_fit_C = regressingModel(X_forceApplied,*params_C)

#绘制拟合模型
plt.plot(X_forceApplied,Y_fit_A, c=&quot;C0&quot;,linestyle=&quot;--&quot;,label=&quot;A-fit&quot;)
plt.plot(X_forceApplied,Y_fit_B, c=&quot;C1&quot;,linestyle=&quot;--&quot;,label=&quot;B-fit&quot;)
plt.plot(X_forceApplied,Y_fit_C, c=&quot;C2&quot;,linestyle=&quot;--&quot;,label=&quot;C-fit&quot;)

plt.legend()
plt.xlabel(&quot;力水平（牛顿）&quot;)
plt.ylabel(&quot;材料特性&quot;)

代码的最终输出如下所示，与我手头的数据集在视觉上相似：

因此，总结一下问题：

比较线性模型以了解它们在统计上是否不同的最佳方法是什么？
如果它们不同，如​​何知道哪个样本与哪个样本不同？本质上，可以运行什么事后检验？

附加问题：对于遵循另一种依赖关系到强制级别的另一个属性（例如，Y 通过 $Y=aX^2+bx+c$ 或 $Y=alog(X)$ 依赖于 X），您提出的方法会有所改变吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653906/compare-parameters-of-same-model-regressed-to-different-data-sets</guid>
      <pubDate>Thu, 05 Sep 2024 10:29:25 GMT</pubDate>
    </item>
    <item>
      <title>做t检验时，样本标准差应该用样本均值减去原假设均值来估计吗？</title>
      <link>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</link>
      <description><![CDATA[以 t 检验为例，检验实数样本$x_i$是否来自均值为 0 的分布（$H_0:\mu=0, H_a:\mu \neq 0$）。检验统计量将是$t=\frac{\bar{x}}{s/\sqrt{n}}$。
我的问题是$s^2=\frac{\Sigma_i(x_i - \bar{x})^2}{n-1}$还是$s^2=\frac{\Sigma_i x_i^2}{n}$。
在大多数文本中我看到前者，但在财务数据的背景下我有时看到后者。两者似乎也都有意义，前者使用正态样本标准差公式，后者使用零假设，也不再需要贝塞尔校正。
两者的优缺点是什么，有没有更合适的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</guid>
      <pubDate>Thu, 05 Sep 2024 10:20:49 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待最近的统一理论？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653904/what-do-you-think-about-this-recent-unified-theory</link>
      <description><![CDATA[最近，有一篇关于天体粒子物理学的论文发表，题为“从黎曼几何和普朗克尺度形式论量子物理和广义相对论的同一起源”，声称统一了量子理论和广义相对论。这是一个链接
https://www.sciencedirect.com/science/article/abs/pii/S0927650524001130
然而，当我浏览这篇论文时。有很多值得怀疑的地方，例如添加不同阶的张量和方程 1 中的 Ricci 张量的定义。
希望有人能帮助我澄清这些观点，因为我自己可能会错过一些东西。
PS。这是预印本
https://www.researchgate.net/publication/379310936_On_the_same_origin_of_quantum_physics_and_general_relativity_from_Riemannian_geometry_and_Planck_scale_formalism]]></description>
      <guid>https://stats.stackexchange.com/questions/653904/what-do-you-think-about-this-recent-unified-theory</guid>
      <pubDate>Thu, 05 Sep 2024 10:12:48 GMT</pubDate>
    </item>
    <item>
      <title>生成AR序列时的回填是什么？</title>
      <link>https://stats.stackexchange.com/questions/653902/what-is-backfilling-when-generating-an-ar-sequence</link>
      <description><![CDATA[我正在阅读这篇论文：从非平稳数据中提取周期
我希望在本文中重新创建蒙特卡罗模拟。
在执行此操作之前，我有一个疑问。
第 8 页有脚注 9，作者在其中说：

我们使用 100 个观测值回填了 $ \epsilon_t $。这是为了确保创新序列与 AR(1) 生成机制一致。

我没听懂。有人可以向我解释一下怎么做吗？回填到底是什么？
下面是我如何使用 R 编程语言生成与本文模拟中类似的 AR1 序列，其长度为 216，自回归参数为 .34：
arima.sim(model =list(ar=.34,order=c(1,0,0)),n=216)

我如何回填？有人能帮我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653902/what-is-backfilling-when-generating-an-ar-sequence</guid>
      <pubDate>Thu, 05 Sep 2024 09:56:54 GMT</pubDate>
    </item>
    <item>
      <title>核SHAP——贡献函数估计</title>
      <link>https://stats.stackexchange.com/questions/653900/kernel-shap-estimation-of-contribution-function</link>
      <description><![CDATA[我一直在阅读 Christoph Molnar 的关于可解释机器学习的在线书籍 (链接)
如果我们有
$$\sum_{S \subseteq M} \bigg((v(S) - (\phi_0 + \sum_{j \in S} \phi_j)\bigg)^2 K(M,S)
$$
其中 $S$ 是特征集，$M$ 是联盟中的特征集，$K$ 是 Shapley内核将衡量损失。
Molnar 在 (link) 中讨论了如何近似 $v(S)$，贡献函数定义为
$$v(S)=E[f(x)|x_S=x^*_S]$$
Molnar 在他的书中使用了略有不同的符号：$$v(S)=E[f(x)|x_j=x^*_j]$$ 指的是联盟向量中的索引 $j$，我发现它不太精确。
Molnar 说

从边际分布中抽样意味着忽略现有特征和缺失特征之间的依赖结构。因此，KernelSHAP 遭受与所有基于置换的解释方法相同的问题。估计过分重视不可能的情况。结果可能变得不可靠。但有必要从边际分布中抽样。解决方案是从条件分布中抽样，这会改变价值函数，从而改变 Shapley 值作为解决方案的游戏。因此，Shapley 值具有不同的解释：例如，当使用条件抽样时，模型可能根本没有使用的特征可以具有非零 Shapley 值。对于边际博弈，这个特征值总是会得到
0 的 Shapley 值，因为否则它会违反 Dummy
公理。

我不明白为什么 Molnar 说“必要的”。我还找到了一些资料，例如这个，其中他们确实讨论了使用 copula 和 VAEAC 来估计条件分布$p(x_{\overline{S}}|x_S=x^*_S$ in
$$
v(S) = E[f(x)|x_S=x^*_S)] 
= E[f(x_{\overline{S}},x_S)|x_s=x^*_S] =
\int f(x_{\overline{S}},x^*_S)p(x_{\overline{S}}|x_S=x^*_S) dx_{\overline{S}}
$$
我理解，如果您从边际中抽样，那么您将从联盟中移除特征的 shap 游戏中获得更好的近似值。但是，正如 Molnar 自己所说，使用边际会过分重视不可能的值，并且贡献函数的估计变得不可靠。因此，使用边际分布不仅没有必要，而且最终是不正确的吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/653900/kernel-shap-estimation-of-contribution-function</guid>
      <pubDate>Thu, 05 Sep 2024 09:32:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 OLS 估计协整向量</title>
      <link>https://stats.stackexchange.com/questions/653897/estimating-a-cointegration-vector-using-ols</link>
      <description><![CDATA[我一直在阅读《汉密尔顿》，刚刚遇到了以下概念。

要估计协整向量，首先将第一个分量设置为 1。然后，执行线性回归以估计其余系数。这些系数是通过将每个时间序列与我们将系数设置为 1 的时间序列进行回归来估计的。

用更数学的术语来说，我们有一组时间序列 $y_t^i$。我们可以从这些单独的时间序列中创建一个向量，$\vec{y}_t$。
假设存在一个向量 $\vec{a}$，即协整向量。该向量描述了每个时间序列所需的权重，以便它们的线性组合创建协整时间序列。
要执行上述过程，假设$a_0=1$。然后，在时间序列$y_t^i$和$y_t^0$之间执行 OLS。梯度产生系数$a_i$的估计值。
我的问题是为什么？我在哪里可以找到这个证明，或者更详细的解释？]]></description>
      <guid>https://stats.stackexchange.com/questions/653897/estimating-a-cointegration-vector-using-ols</guid>
      <pubDate>Thu, 05 Sep 2024 09:04:32 GMT</pubDate>
    </item>
    <item>
      <title>最终仅将单位视为 DiD 中的控制？</title>
      <link>https://stats.stackexchange.com/questions/653896/only-having-eventually-treated-units-as-controls-in-did</link>
      <description><![CDATA[我正在写一篇统计学论文，我对此有一个想法，如果能得到一些意见，我将不胜感激。
Callaway 和 SantAnna 在他们的 R 包 DiD 中有一个选项，可以只使用从未治疗过的单位，或者尚未（最终）治疗过的单位和从未治疗过的单位作为对照。
该包还可以选择将协变量添加到模型中，以使平行趋势假设在协变量值条件下得到满足。如果治疗和未治疗单位之间的特征存在差异，并且这些特征同时影响结果变量随时间的变化，这将非常有用。
我的想法是，如果治疗和未治疗（从未治疗）单位之间的特征存在差异，那么是否合理地将尚未（最终）治疗过的单位作为对照，而不是将协变量添加到模型中？我知道这会缩小对照组的规模，而且不可能估计最后接受治疗的组的治疗效果，但这种方法还有其他潜在的缺点吗？
/Robert]]></description>
      <guid>https://stats.stackexchange.com/questions/653896/only-having-eventually-treated-units-as-controls-in-did</guid>
      <pubDate>Thu, 05 Sep 2024 08:51:06 GMT</pubDate>
    </item>
    <item>
      <title>来自“掷骰子和弃牌”游戏的概率问题</title>
      <link>https://stats.stackexchange.com/questions/653895/probability-problem-from-the-game-dice-fold</link>
      <description><![CDATA[我想知道是否有人可以给出这个问题的分析解决方案：

你从一个骰子开始。
你掷骰子，如果结果为 &lt;5，那么你输了骰子，而如果结果为 &gt;= 5，你将获得一个额外的骰子，这样你现在有 2 个骰子。
你继续一个接一个地掷所有骰子，直到没有剩余的骰子。

为了清楚起见：假设你现在有 2 个骰子，你掷其中一个并得到 4。由于 4&lt;5，你输了那个骰子，只剩下一个骰子。如果你得到 6，你将获得一个额外的骰子，这样你现在有 3 个骰子。当你没有骰子时，游戏结束。
所有骰子都有均匀的概率得到 1-6。让 $X$ 成为代表您掷骰子次数的随机变量。$E[X]$ 和 $Var[X]$ 分别是什么？
您拥有的骰子数量的两种可能顺序是：1 2 1 0（您掷了 3 次）和 1 2 3 2 1 0（您掷了 5 次）。
我在 R 中进行了模拟，结果表明 $E[X]=3$ 和 $Var[X]=24$，但我似乎无法通过分析证明这一点。我的模拟代码如下：
library(purrr)

set.seed(102)

number_of_simulation &lt;- 10^6
roll &lt;- 0
number_of_dice &lt;- 1
simulation_number &lt;- 1
simulation_result &lt;- c()

for(simulation_number in 1:number_of_simulation){
while (number_of_dice&gt;0){
roll &lt;- roll + number_of_dice
roll_result &lt;- rdunif(number_of_dice,1,6)
number_of_dice &lt;- 2*sum(roll_result&gt;4)
}
simulation_result[simulation_number] &lt;- roll
simulation_number &lt;- simulation_number + 1
roll &lt;- 0
number_of_dice &lt;- 1
}

mean(simulation_result)
var(simulation_result)

注意
这个问题来自 Steam 上 2Q24 发布的一款游戏“Dice &amp; Fold”。起始角色叫 Jack。他的技能是掷 2 个骰子，前提是您可以给他一个大于 4 的骰子。游戏中有一个饰品，每当您使用技能时，它都会为您提供 +2 治疗。如果我们将所有骰子都用于此技能，我们获得的治疗量的预期值是 $2E[X]$ 乘以我们在回合开始时拥有的骰子数量。因此，这个问题就出现了。]]></description>
      <guid>https://stats.stackexchange.com/questions/653895/probability-problem-from-the-game-dice-fold</guid>
      <pubDate>Thu, 05 Sep 2024 08:49:26 GMT</pubDate>
    </item>
    <item>
      <title>使用 statsmodels.tsa.seasonal 进行季节性分解</title>
      <link>https://stats.stackexchange.com/questions/653894/seasonal-decompose-with-statsmodels-tsa-seasonal</link>
      <description><![CDATA[您能帮我理解使用
statsmodels.tsa.seasonal import MSTL进行季节性分解的结果吗？
在阅读了一篇使用它的文章后，我第一次尝试使用它，并试图更好地理解它是如何工作的，以及如何更接近我期望的结果。
我希望 -

趋势图值为 0。
seasonal7 图定期从 1 变为 7。
seasonal13 图定期从 1 变为 13。
残差图值应为 0。

我刚刚意识到趋势 + 季节性图 + 残差应该产生观察值。
所以我猜我的期望通常是合理的，但由于我的系列中没有趋势，趋势分析会搞乱分析？
结果被认为足够好，因为残差低于 1% 或类似的标准，所以算法不会尝试改进它？]]></description>
      <guid>https://stats.stackexchange.com/questions/653894/seasonal-decompose-with-statsmodels-tsa-seasonal</guid>
      <pubDate>Thu, 05 Sep 2024 08:39:46 GMT</pubDate>
    </item>
    <item>
      <title>数据与名义变量效应的相关性</title>
      <link>https://stats.stackexchange.com/questions/653893/data-correlation-with-effect-of-nominal-variables</link>
      <description><![CDATA[这是我的问题
我有一个包含 4 个相关列的数据集，其中包含以下信息：

主要独立变量（它是一个名义变量，它可以采用离散值，但假设有无数个不同的值，在我的数据集中它需要 300 多个值）
第二个独立变量（它是一个名义变量，但它只能采用 4 个不同的值，比如 a、b、c 和 d）
执行测试的用户（它是一个名义变量，它可以采用有限数量的值，具体取决于运行测试的人数）
测试结果，以 [0, 10] 范围内的数字表示

现在，我的问题如下。有没有办法确定我的数据之间是否存在任何相关性？例如，我能否知道，从统计学上来说，user1 是否总是获得比 user2 更高的结果？或者，将第二个独立变量值设置为 a 时进行的测试是否总是返回比将第二个独立变量值设置为 c 时更高的值？
希望我的问题足够清楚。顺便说一句，如果需要，请随时问我任何问题。
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/653893/data-correlation-with-effect-of-nominal-variables</guid>
      <pubDate>Thu, 05 Sep 2024 08:23:24 GMT</pubDate>
    </item>
    <item>
      <title>假设反复掷骰子。令 X 为第一次出现所有面所需的掷骰次数。求概率质量函数</title>
      <link>https://stats.stackexchange.com/questions/653892/suppose-a-die-is-rolled-repeatedly-let-x-be-the-no-of-rolls-needed-to-get-all</link>
      <description><![CDATA[假设一个骰子满足 $P(\{i\})=P_i, i=1,...,6.$ 假设上述骰子重复且独立地投掷。假设 $X$ 为第一次出现所有面所需的投掷次数。因此，$\text{Min}X=6.$ 找到概率质量函数 (pmf)。
我尝试按如下方式解决问题：
让 $p$ 为 pmf。
如果 $k$ 为使所有面都出现所需的骰子掷数，则 $$p(k)=P\{X=k\}.$$
如果 $k\lt 6$ 则 $p(k)=0.$
因此，我们假设 $k\geq 6.$
设 $E$ 为掷骰子 $k$ 次，使所有面都出现的事件。
因此，$p(k)=P\{X=k\}=P(E).$
设 $E_i$ 为掷骰子 $i$ 面至少在 $k$ 次掷骰子中出现一次的事件，其中 $1\leq i\leq 6.$
因此，$E=\cap_{i=1}^6 E_i.$
因此，$P(E)=P(\cap_{i=1}^6E_i)=1-P(\cup_{i=1}^6 E_i^c)=1-(\sum_{i=1}^6P(E_i^c)-\sum_{i_1&lt;i_2}P(E_{i_1}^c\cap E_{i_2}^c)+\sum_{i_1&lt;i_2&lt;i_3}P(E_{i_1}^c\cap E_{i_2}^c \cap E_{i_3}^c)-....+(-1)^5P(E_1\cap E_2\cap ...\cap E_6))\tag 1$
我们注意到，

$P(E_i^c)=(1-P_i)^k,$

$P(E_{i_1}^c\cap E_{i_2}^c)=(1-(P_{i_1}+P_{i_2}))^k,$ $i_1&lt;i_2$

$P(E_{i_1}^c\cap E_{i_2}^c\cap E_{i_3}^c)=(1-(P_{i_1}+P_{i_2}+P_{i_3}))^k,$ $i_1&lt;i_2&lt;i_3$


$\cdots$

$P(E_1^c\cap\cdots E_6^c)=0.$

将这些值代入$(1)$中，我们得到，
$$P(E)=P(\cap_{i=1}^6E_i)=1-P(\cup_{i=1}^6 E_i^c)=1-(\sum_{i=1}^6P(E_i^c)-\sum_{i_1&lt;i_2}P(E_{i_1}^c\cap E_{i_2}^c)+\sum_{i_1&lt;i_2&lt;i_3}P(E_{i_1}^c\cap E_{i_2}^c \cap E_{i_3}^c)-....+(-1)^5P(E_1^c\cap E_2^c\cap ...\cap E_6^c))=1-(\sum_{i=1}^6(1-P_i)^k-\sum_{i_1&lt;i_2}(1-(P_{i_1}+P_{i_2}))^k+\sum_{i_1&lt;i_2&lt;i_3}(1-(P_{i_1}+P_{i_2}+P_{i_3}))^k-....+(-1)^5.0)$$
因此，$$p(k)=1-\big [\sum_{i=1}^6(1-P_i)^k-\sum_{i_1&lt;i_2}(1-(P_{i_1}+P_{i_2}))^k+\sum_{i_1&lt;i_2&lt;i_3}(1-(P_{i_1}+P_{i_2}+P_{i_3}))^k-....+(-1)^4\sum_{i_1&lt;i_2&lt;i_3&lt;i_4&lt;i_5}(1-(P_{i_1}+P_{i_2}+\cdots+P_{i_5}))^k\big ]$$

上述解决方案有效吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653892/suppose-a-die-is-rolled-repeatedly-let-x-be-the-no-of-rolls-needed-to-get-all</guid>
      <pubDate>Thu, 05 Sep 2024 08:11:07 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分析的单位根检验 - 特征方程的推导</title>
      <link>https://stats.stackexchange.com/questions/653891/unit-root-tests-for-timeseries-analysis-derivation-of-the-characteristic-equat</link>
      <description><![CDATA[以下方程描述了一个时间序列过程。
$${\displaystyle y_{t}=a_{1}y_{t-1}+a_{2}y_{t-2}+\cdots +a_{p}y_{t-p}+\varepsilon _{t}}$$
为了确定此过程是否包含单位根，我们求解特征方程。
为了写下特征方程，我们将符号 $y_{t-n}$ 交换为滞后算子的表达式，使得 $y_{t-n}=L^ny_t$，并删除项 $\varepsilon_t$.
$${\displaystyle y_{t}=a_{1}Ly_{t}+a_{2}L^2y_{t}+\cdots +a_{p}L^py_{t}}$$
这相当于
$${\displaystyle y_{t}-a_{1}Ly_{t}-a_{2}L^2y_{t}-\cdots -a_{p}L^py_{t}}=0.$$
然后我们分解出$y_t$，并求解$L$
$${\displaystyle 1-a_{1}L-a_{2}L^2-\cdots -a_{p}L^p}=0.$$
我的问题是为什么？我正在寻找更详细的证明，以解释我们为什么采取这些步骤。
这里有几件事我觉得有点奇怪。 $L$ 是一个运算符，因此将其与 $y_t$ 分开没有多大意义。
具体来说，我并不反对 $L$ 可以像这样分解为括号
$${\displaystyle (1-a_{1}L-a_{2}L^2-\cdots -a_{p}L^p})y_t=0$$
但是，将运算符 $L$ 解释为变量并求解 $L$ 似乎令人不安。]]></description>
      <guid>https://stats.stackexchange.com/questions/653891/unit-root-tests-for-timeseries-analysis-derivation-of-the-characteristic-equat</guid>
      <pubDate>Thu, 05 Sep 2024 07:57:33 GMT</pubDate>
    </item>
    </channel>
</rss>