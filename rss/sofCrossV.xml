<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 11 Mar 2024 09:14:49 GMT</lastBuildDate>
    <item>
      <title>创建具有特定比例的二元向量</title>
      <link>https://stats.stackexchange.com/questions/642284/creating-a-binary-vector-with-specific-proportion-of-ones</link>
      <description><![CDATA[我想生成一个大小为 $n=20$ 的二元向量，其比例等于 $\压裂{3}{20}$
binary_vector &lt;- rbinom(20, 1, 0.15)

但是为什么这并不总是给出 0.15 的固定比例：
&lt;预&gt;&lt;代码&gt;[1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 # 5%
[1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 # 0%
[1] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 # 15%
[1] 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 # 20%
]]></description>
      <guid>https://stats.stackexchange.com/questions/642284/creating-a-binary-vector-with-specific-proportion-of-ones</guid>
      <pubDate>Mon, 11 Mar 2024 09:13:35 GMT</pubDate>
    </item>
    <item>
      <title>拉丁方设计的用处</title>
      <link>https://stats.stackexchange.com/questions/642283/usefulness-of-latin-square-design</link>
      <description><![CDATA[我想了解拉丁方设计的用处。假设有两个块因子，每个因子有三个块。共有三个实验组：A、B、C。拉丁方设计的一种实现是：
&lt;前&gt;&lt;代码&gt;&gt;设计1＜-c(“A”、“B”、“C”、“B”、“C”、“A”、“C”、“A”、“B”) ）
&gt;矩阵(设计1,3,3)
     [,1] [,2] [,3]
[1，]“A” “B” “C”
[2，]“B” “C” “A”
[3，]“C” “A” “B”

在此设计中，行和列代表块因子。该设计假设三个因素之间不存在相互作用。但是，如果我们假设不存在交互作用，则可以在不使用拉丁方设计的情况下估计三个因素的影响，如design2
&lt;前&gt;&lt;代码&gt;&gt;设计2＜-c(“A”、“B”、“C”、“B”、“C”、“A”、“C”、“A”、“A”) ）
&gt;矩阵(设计2,3,3)
     [,1] [,2] [,3]
[1，]“A” “B” “C”
[2，]“B” “C” “A”
[3，]“C” “A” “A”

在design2中，实验组B没有出现在第三行第三列中，但我们仍然可以估计块效应和实验效果。我想知道拉丁方设计的主要优点。
&lt;前&gt;&lt;代码&gt;&gt; y &lt;- rnorm(9,1,1)
&gt;设计1＜-因子(c(“A”、“B”、“C”、“B”、“C”、“A”、“C”、“A”、“)” B”））
&gt; design2＜-factor(c(“A”、“B”、“C”、“B”、“C”、“A”、“C”、“A”、“)” A”））
&gt; design3＜-factor(c(“A”、“B”、“C”、“B”、“C”、“A”、“A”、“A”、“)” A”））
&gt; blk1＜-因子(c(“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“blk1”) T3”））
&gt; blk2＜-因子(c(“A1”、“A1”、“A1”、“A2”、“A2”、“A2”、“A3”、“A3”、”) A3”））
&gt;
&gt;方差分析(lm(y~design1+blk1+blk2))
方差分析表

响应：是
          Df Sum Sq Mean Sq F 值 Pr(&gt;F)
设计1 2 4.2330 2.11652 2.4836 0.2871
块1 2 0.2355 0.11775 0.1382 0.8786
块2 2 0.6779 0.33897 0.3978 0.7154
残差 2 1.7044 0.85221
&gt;方差分析(lm(y~design2+blk1+blk2))
方差分析表

响应：是
          Df Sum Sq Mean Sq F 值 Pr(&gt;F)
设计2 2 2.97039 1.48520 1.0063 0.4984
块1 2 0.49651 0.24825 0.1682 0.8560
块2 2 0.43222 0.21611 0.1464 0.8723
残差 2 2.95177 1.47589
&gt;方差分析(lm(y~design3+blk1+blk2))
方差分析表

响应：是
          Df Sum Sq Mean Sq F 值 Pr(&gt;F)
设计3 2 2.8600 1.43001 0.8500 0.5405
块1 2 0.1706 0.08530 0.0507 0.9517
块2 2 0.4554 0.22772 0.1354 0.8808
残差 2 3.3648 1.68241
]]></description>
      <guid>https://stats.stackexchange.com/questions/642283/usefulness-of-latin-square-design</guid>
      <pubDate>Mon, 11 Mar 2024 09:07:47 GMT</pubDate>
    </item>
    <item>
      <title>Caperaa Fougeres Genest 非参数尾部依赖性估计器的 R 代码</title>
      <link>https://stats.stackexchange.com/questions/642282/r-code-for-nonparametric-tail-dependence-estimator-of-caperaa-fougeres-genest</link>
      <description><![CDATA[任何人都可以帮助我如何使用 R 代码来估计 Caperaa Fougeres Genest 的非参数尾部依赖性估计器。我尝试过使用 gofEVCopula() 函数，但它只能计算极值 copula。然而，我在许多论文中发现，他们能够使用其他类型的 copula 进行计算，而不仅限于 copula 的极值类。]]></description>
      <guid>https://stats.stackexchange.com/questions/642282/r-code-for-nonparametric-tail-dependence-estimator-of-caperaa-fougeres-genest</guid>
      <pubDate>Mon, 11 Mar 2024 07:43:14 GMT</pubDate>
    </item>
    <item>
      <title>如何应对堆叠 DiD 中的预趋势违规？</title>
      <link>https://stats.stackexchange.com/questions/642281/how-to-cope-with-pre-trend-violations-in-a-stacked-did</link>
      <description><![CDATA[我想使用双重差分方法来分析多个事件。由于事件发生在不同的时间，因此交错或堆叠的 DiD 方法将是合适的。就我而言，我有很多观察结果，并且还想查看交互，这对于堆叠 DiD 来说似乎更容易。然而，我现在面临的问题是我必须控制违反治疗前趋势的情况。我已经分别为每个实验尝试了匹配方法，然后合并了数据，但我丢失了很多观察结果。另外，逆概率加权似乎是一个可行的选择。然而，如何将其合并到堆叠式 DiD 方法中尚不清楚。如果没有标准化，不同事件的权重将会不同。
是否可以将 IPW 或其他形式的加权与堆叠式 DiD 结合起来？我将非常感谢您提供提示、片段和参考资料！现在，我将使用 Weightit 单独权衡每个实验，使用固定的单独 DiD 进行估计，然后汇总结果。这一切是否可以在单个 Stacked DiD 中完成，即更优雅？]]></description>
      <guid>https://stats.stackexchange.com/questions/642281/how-to-cope-with-pre-trend-violations-in-a-stacked-did</guid>
      <pubDate>Mon, 11 Mar 2024 07:08:52 GMT</pubDate>
    </item>
    <item>
      <title>ValidError，输入无效，x 为常量</title>
      <link>https://stats.stackexchange.com/questions/642280/validerror-invalid-input-x-is-constant</link>
      <description><![CDATA[我该如何调查数据并进行预处理？我正在尝试使用 pvalue 对协整对进行热图分析。
执行协整对分析
cointegrated_pa​​irs = [] correlation_matrix = np.zeros((len(tickers), len(tickers))) 对于 i，枚举（tickers）中的ticker1：对于 j，枚举（tickers）中的ticker2：如果 i != j: p_value = cointegration_test(returns[ticker1], returns[ticker2]) #如果 p_value &lt; 则出现错误0.01: cointegrated_pa​​irs.append((ticker1,ticker2))correlation_matrix[i,j] = returns[ticker1].corr(returns[ticker2])
错误消息“输入无效，x 对于股票对 (GME, GME) 来说是常量”表示该对的线性回归模型中的外生变量 (x) 是常量。这意味着该变量不会因观察而变化，这可能会导致模型估计和解释出现问题。
我尝试继续使用 for i, ticker1 in enumerate(tickers)：
对于 j，枚举（tickers）中的ticker2：
如果我！= j：
p_value = cointegration_test(返回[ticker1], 返回[ticker2])
p_values.loc[ticker1,ticker2] = p_value
但之前，我成功地运行了热图分析，没有任何问题，我不明白为什么这次 GME，GME 协整返回错误。]]></description>
      <guid>https://stats.stackexchange.com/questions/642280/validerror-invalid-input-x-is-constant</guid>
      <pubDate>Mon, 11 Mar 2024 07:03:55 GMT</pubDate>
    </item>
    <item>
      <title>溢出效应作为购买力平价（PPP）的检验</title>
      <link>https://stats.stackexchange.com/questions/642279/spillovers-as-test-of-purchasing-power-parity-ppp</link>
      <description><![CDATA[VAR 的变换系数产生脉冲响应，可用于在 Diebold 和 Yilmaz (DY) 2012 年论文“给予比接受更好”。在记录即期汇率和价格指数差异的二方程 VAR 中测试相对购买力平价的背景下，是否有将 DY 溢出解释为购买力平价的确认/拒绝的现成解释，包括比例性和对称性假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/642279/spillovers-as-test-of-purchasing-power-parity-ppp</guid>
      <pubDate>Mon, 11 Mar 2024 04:52:14 GMT</pubDate>
    </item>
    <item>
      <title>一阶、二阶、三阶差分背后的直觉是什么以及何时使用它们？</title>
      <link>https://stats.stackexchange.com/questions/642277/what-is-the-intuition-behind-the-first-second-third-order-differencing-and-whe</link>
      <description><![CDATA[我正在处理时间序列数据，出于好奇，我对数据进行了第一个第二个三阶差分。我怎么在使用它们时不太熟悉？
第二个问题是其背后的直觉。第一个订单非常清楚，这就是区别。
$$\begin{方程} \begin{对齐}
\Delta X_t &amp;= X_t - X_{t-1}。
\end{对齐} \end{方程}$$
第二个描述这里是给定时间点的序列曲率。
$$\begin{方程} \begin{对齐}
\Delta^2 X_t = \Delta (\Delta X_t)
&amp;= \Delta (X_t-X_{t-1}) \\[6pt]
&amp;= \Delta X_t - \Delta X_{t-1} \\[6pt]
&amp;= (X_t-X_{t-1})-(X_{t-1}-X_{t-2}) \\[6pt]
&amp;= X_t - 2X_{t-1} + X_{t-2}。 \\[6分]
\end{对齐} \end{方程}$$
但我实际上不知道第三个区别是什么意思？何时使用第一、第二和第三个差异？
$$\begin{方程} \begin{对齐}
\Delta^3 X_t = \Delta (\Delta^2 X_t)
&amp;= \Delta (X_t - 2X_{t-1} + X_{t-2}) \\[6pt]
&amp;= \Delta X_t - 2\Delta X_{t-1} + \Delta X_{t-2} \\[6pt]
&amp;= (X_t - X_{t-1}) - 2(X_{t-1} - X_{t-2}) + (X_{t-2} - X_{t-3}) \\[6pt ]
&amp;= X_t - 3X_{t-1} + 3X_{t-2} - X_{t-3}。 \\[6分]
\end{对齐} \end{方程}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/642277/what-is-the-intuition-behind-the-first-second-third-order-differencing-and-whe</guid>
      <pubDate>Sun, 10 Mar 2024 23:22:58 GMT</pubDate>
    </item>
    <item>
      <title>有哪些关于如何避免作为统计学家被用来为不诚实项目提供虚假可信度的好书？</title>
      <link>https://stats.stackexchange.com/questions/642275/what-are-some-good-books-on-how-to-avoid-as-a-statistician-being-used-to-lend</link>
      <description><![CDATA[我的意思是，例如，公司或组织对严肃的数据分析驱动的决策并不真正感兴趣，而是雇用或雇用统计学家试图为“结果”提供虚假的可信度。在实际进行任何认真的数据分析之前就已经决定了。另一个例子可能是一家公司篡改他们提供给他们雇用的统计学家的数据，试图让公司看起来不错。
对于那些试图诚实地完成工作而不被操纵的人来说，是否有关于如何处理这种情况的参考？
我想这是许多领域的专家可能有一天或以后必须面对的一个问题，但我想知道是否有一些参考文献专门从统计学家或数据分析师/科学家的角度来解决这个问题。
谢谢。
--
编辑：
我不完全确定为什么这个问题被关闭。我的问题很笼统，我给出的例子只是说明，也许并不完美。我心里没有更具体的例子，这就是我首先问这个问题的原因：如果我已经具体知道如何操纵统计学家，我想我不需要关于这个主题的参考资料。我认为对细节的无知是导致某人容易受到操纵的原因之一。
在我看来，这个问题只能由对该领域的出版物有充分了解的人来回答，这就是为什么我的第一个想法是在这里问它（否则，我不知道我还能在哪里问它，但如果我的问题保持关闭，我会很高兴得到建议）。
行为准则很有趣并且绝对相关，但我认为他们缺乏而我正在寻找的是“案例研究”例子。因此，如果你愿意，我会发现有趣的是有点像针对统计学家的行为准则，但有详细的现实生活例子，而不仅仅是列出原则。有这样的书吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642275/what-are-some-good-books-on-how-to-avoid-as-a-statistician-being-used-to-lend</guid>
      <pubDate>Sun, 10 Mar 2024 22:27:39 GMT</pubDate>
    </item>
    <item>
      <title>固定效应回归会由于聚合 FE 较多的共线性而降低估计值，但聚合 FE 较少的情况则不会</title>
      <link>https://stats.stackexchange.com/questions/642274/fixed-effects-regression-drops-estimates-due-to-collinearity-for-more-aggregated</link>
      <description><![CDATA[我正在使用带有一些不同设置的 fixest 包在 r 中运行固定效应回归。我无法提供复制错误的数据，因为数据集太大，并且子集会导致其他错误，但一般格式如下：
库（修复）

fmla1 &lt;- as.formula(“DV ~ 因子(Var):(Var2) + Var2 | 州 + 年份”)
fmla2 &lt;- as.formula(“DV ~ 因子(Var):(Var2) + Var2 | 年”)
fmla3 &lt;- as.formula(“DV ~ 因子(Var):(Var2) + Var2 | 状态”)
fmla4 &lt;- as.formula(&quot;DV ~ 因子(Var):(Var2) + Var2 | 城市 + 年份&quot;)
fmla5 &lt;- as.formula(&quot;DV ~ 因子(Var):(Var2) + Var2 | city_year&quot;)

reg1 &lt;- feols(数据 = df, fml = fmla1)
reg2 &lt;- feols(数据 = df, fml = fmla2)
reg3 &lt;- feols(数据 = df, fml = fmla3)
reg4 &lt;- feols(数据 = df, fml = fmla4)
reg5 &lt;- feols(数据 = df, fml = fmla5)


其中固定效应变量state是观测状态的一个因子，year是年份的一个因子，city是一个城市的因子，city_year 是城市年固定效应的因子。 Var2是具有三个类别的因子变量，其中参考水平为“a”。 Var 是另一个因子，范围为 -10 到 10 的整数。两者相互作用，无需对 Var 进行基线估计，因为当 Var2 = =“a”，Var 始终为 0。因此，为了避免共线性，我只对交互作用和 Var2 进行估计。
当我运行这些模型时，前 3 个模型不起作用。我收到如下错误消息：
由于共线性，变量“Var0:Var2a”已被删除（请参阅 $collin.var）。


但是，对于reg4和reg5，不会出现这样的错误。
我试图了解这是如何发生的，并确定 reg4 和 reg5 的结果是否可信。
如上所述，对于 Var2 == “a” 的观察结果，Var 是完全共线的。所以我可以看到多重共线性问题是如何引起的。但当使用城市和城市年份固定效应时，它也是共线的，没有任何下降。
城市和城市年的固定效应明显低于国家固定效应，也就是说城市年和城市年的固定效应将被国家吸收。因此，两个规范下的变量和固定效应之间不应该存在相同的关系吗？对于 Var2 == “a” 的共线情况，没有增加任何变化，这些对只是简单地划分为比州更多的城市，并且全部具有相同的值。
对于其他上下文，根据 Var2 级别将 Var 级别分配给给定州和年份的所有观测值。例如，在 1880 年，如果 Var2 == &quot;b&quot;，则所有这些观测值的 Var 均为 3。因此 Var 的变化code&gt; 发生在州一级（并且通过扩展统一对待该州内的所有城市）。
通过此设置，当治疗分配（Var1 的值）发生在州级别时，为什么我可以在城市级别估计具有固定效应的模型，而不是在州级别？如果在存在州 FE 的情况下与 Var2 交互时 Var 会下降，那么假设它是一个子州单位，那么当使用 city 时不应该发生完全相同的情况吗？ 
如果没有，任何人都可以提出一个例子，说明这种设计会发生并且是合法的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/642274/fixed-effects-regression-drops-estimates-due-to-collinearity-for-more-aggregated</guid>
      <pubDate>Sun, 10 Mar 2024 21:57:44 GMT</pubDate>
    </item>
    <item>
      <title>前门调节之谜</title>
      <link>https://stats.stackexchange.com/questions/642270/front-door-adjustment-riddle</link>
      <description><![CDATA[我有一个关于前门调整的具体案例的问题。
假设 $T\rightarrow M\rightarrow Y$ 和 $T\leftarrow C\rightarrow Y$，所以$C$ 是混杂变量，$M$ 是中间变量。
那么前门调整公式为：
$$P(y|do(t)) = \sum_{m}P(m|do(t))P(y|do(m))=\sum_mP(m |t)\sum_{t&#39;}P(y|m,t&#39;)P(t&#39;).$$
我的问题是：以下说法正确吗？最后我得到了一个非常奇怪的结果，所以我认为我在某个地方做错了，但我找不到它。
假设 $T$ 和 $M$ 之间的因果关系是确定性的，即 $M = f(T)$ 对于某些 $f$ 那么如果我将其代入上面的公式中，所有除了 $m=f(t)$ 之外，外部总和的元素为零，因此我得到 $m= f(t)$:
$$P(y|do(t))=\sum_{t&#39;}P(y|m,t&#39;)P(t&#39;)=\sum_{t&#39;:m =f(t&#39;)}P(yμm,t&#39;)P(t&#39;)=\sum_{t&#39;:m=f(t&#39;)}P(yμm)P(t&#39;)=P( y|m)\sum_{t&#39;:m=f(t&#39;)}P(t&#39;).$$
例如，如果 $f(x)=x$，则 $P(y|do(t)) = P (y|m)P(m)=P(y|t)P(t)$，我认为这是错误的。
以上计算正确吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642270/front-door-adjustment-riddle</guid>
      <pubDate>Sun, 10 Mar 2024 18:27:05 GMT</pubDate>
    </item>
    <item>
      <title>被高斯噪声破坏的均匀分布的估计</title>
      <link>https://stats.stackexchange.com/questions/642254/estimation-of-a-uniform-distribution-corrupted-by-gaussian-noise</link>
      <description><![CDATA[问题定义
我有一个由 $m$ 观测值 $y^{(1)},\dots,y 组成的数据集^{(m)} \in \mathbb{R}^2$ 生成如下
\begin{方程*}\begin{对齐}
y &amp;= z + v \换行符
z&amp; \sim\mathcal{U}([a,b]) \换行符
v&amp; \sim\mathcal{N}(0_{2\times1}, \sigma_v^2 I_2)
\结束{对齐}
\end{方程*}
这里 $z$ 均匀分布在连接顶点 $[\begin{array}{cc}a &amp; 的线上。 0 \end{array}]$, $[\begin{array}{cc}b &amp; 0\end{array}]$ 与 $b&gt;a$，而 $v$ 是具有各向同性协方差的零均值高斯变量 $\sigma_v^2 I_2$ ($I_2$是 $2\times 2$ 单位矩阵）。两个组件 $z$ 和 $v$ 是独立的。
给定数据集$y^{(1)},\dots, y^{(m)}$，我想估计参数$a$ 和 $b$ 定义生成 $z 的段$.
我的尝试
对于 $\sigma_v\triangleq 0$，即没有高斯噪声，如果我没记错的话，$a$ 和 $b$ 应该是
\begin{方程}\begin{对齐}
\hat{\alpha} &amp;triangleq \min_{j=1,\dots,m} [\begin{array}{cc} 1 &amp; 0 \end{array}] y^{(j)} \newline
\hat{\beta} &amp;triangleq \max_{j=1,\dots,m} [\begin{array}{cc} 1 &amp; 0 \end{数组}] y^{(j)}
\结束{对齐}
\标签{$\星星$}
\end{方程}
现在，如果 $\sigma_v$ 是“小”与段长度 $b-a$ 相比，那么上面的估计应该效果很好。随着 $\sigma_v$ 与 $b-a$ 变得相当，我预计估计精度会下降。
我正在考虑一种启发式修正如下
\begin{方程*}\begin{对齐}
\hat{\alpha} &amp;triangleq \min_{j=1,\dots,m} [\begin{array}{cc} 1 &amp; 0 \end{array}] y^{(j)} +\sigma_v\newline
\hat{\beta} &amp;triangleq \max_{j=1,\dots,m} [\begin{array}{cc} 1 &amp; 0 \end{array}] y^{(j)} -\sigma_v
\结束{对齐}
\end{方程*}
因为由于高斯噪声 $v$，最小值和最大值可能会超过 $a$ 和 $b$。
问题
我的解决方案远非严格，我什至不确定它是否有意义。我的问题如下：

基于一些可靠的原则，是否可以修正估计 $(\star)$ 以考虑 $v$?
如果我的方法不起作用，我们如何估算$a$、$b$？&lt; /里&gt;
]]></description>
      <guid>https://stats.stackexchange.com/questions/642254/estimation-of-a-uniform-distribution-corrupted-by-gaussian-noise</guid>
      <pubDate>Sun, 10 Mar 2024 11:22:56 GMT</pubDate>
    </item>
    <item>
      <title>违反广义加性模型 (GAM) 中的假设</title>
      <link>https://stats.stackexchange.com/questions/642125/violation-of-assumptions-in-generalized-additive-models-gams</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/642125/violation-of-assumptions-in-generalized-additive-models-gams</guid>
      <pubDate>Fri, 08 Mar 2024 07:53:52 GMT</pubDate>
    </item>
    <item>
      <title>神经网络分类 - 针对类概率而不是类本身</title>
      <link>https://stats.stackexchange.com/questions/639435/neural-network-classification-targetting-class-probability-and-not-the-class-t</link>
      <description><![CDATA[假设我有一个二元分类问题；我想从一堆特征中预测两个类 $A$ 和 $B$ 。
但是，我还得到了它属于 $A$ 类的（预测 - 将接近准确）概率和它属于 $B$。假设分别为 $0.78, 0.22$。我想在我的问题中瞄准这些概率。
如果我只是走 $BinaryCrossentropy()$ 损失的标准路线，那么网络对我想要定位的这些概率一无所知。
现在这会变成更多的回归问题吗？或者也许是一个分类问题，但具有自定义损失函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/639435/neural-network-classification-targetting-class-probability-and-not-the-class-t</guid>
      <pubDate>Fri, 16 Feb 2024 13:13:08 GMT</pubDate>
    </item>
    <item>
      <title>我是否需要为每个使用重新参数化技巧的 PDF 获取额外的雅可比行列式日志？</title>
      <link>https://stats.stackexchange.com/questions/620657/do-i-need-to-take-additional-log-det-jacobians-for-every-pdf-that-uses-the-repar</link>
      <description><![CDATA[考虑具有重新参数化功能的 - ELBO 目标，该目标也用于 VAE 中：$$
\mathcal L_{\theta,\phi}(x)=\log p_\theta(X|Z)+\log p_\theta(Z) +\log q_\phi(Z)
$$
重新参数化技巧利用 $g(\epsilon, \phi)$ 使得 $\epsilon$&lt; /span&gt; 不依赖于 $\phi$，因此我们可以推动梯度来优化 ELBO（单个蒙特卡洛样本）。
现在由于变量的转换，我需要采取$$
\log q_\phi(Z)=\log p(\epsilon) +\log\left|\det \frac{\partial Z}{\partial \epsilon} \right|
$$
&lt;小时/&gt;
我的问题是，我是否需要为术语 $\log p_\theta(Z)$ 添加另一个雅可比对数？
$P_\theta(Z)$ 是 $Z$ 的先验。我从 $g(\epsilon,\phi)$ 中采样 $Z$ 以使 ELBO 可反向传播。然而，在 VAE 的常用算法中（如 Kingma 的算法），$P_\theta(Z)$ 没有雅可比对数

此外，如果我采用 $p_\theta(Z)$ 的雅可比行列式对数，雅可比行列式的对数将像 ELBO 中那样取消]]></description>
      <guid>https://stats.stackexchange.com/questions/620657/do-i-need-to-take-additional-log-det-jacobians-for-every-pdf-that-uses-the-repar</guid>
      <pubDate>Thu, 06 Jul 2023 02:56:55 GMT</pubDate>
    </item>
    <item>
      <title>解释三个生存曲线的单个 p 值</title>
      <link>https://stats.stackexchange.com/questions/615899/interpreting-single-p-value-for-three-survival-curves</link>
      <description><![CDATA[假设我使用 R 和 ggsurvplot() 函数绘制三个生存曲线，如下所示：

然后，ggsurvplot() 返回单个 p 值。根据我的阅读，这个 p 值是从零假设的分数测试中得出的，即 cox 模型中的三个生存曲线之间根本没有差异。
如何实际解释这一点？例如，可以说绿色曲线明显不同，或者在这种情况下优于蓝色或红色曲线吗？我很难解释这一点，因为绿色和红色看起来很相似，但蓝色和其他两条曲线之间似乎存在显着差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/615899/interpreting-single-p-value-for-three-survival-curves</guid>
      <pubDate>Mon, 15 May 2023 10:19:47 GMT</pubDate>
    </item>
    </channel>
</rss>