<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 11 Oct 2024 03:26:47 GMT</lastBuildDate>
    <item>
      <title>如何对 e^-x / (1-e^-1) 进行逆变换，0<x<1 以实现重要性采样</title>
      <link>https://stats.stackexchange.com/questions/655631/how-to-inverse-transform-e-x-1-e-1-0x1-for-importance-sampling</link>
      <description><![CDATA[示例 5.10 使用 R (Rizzo) 进行统计计算 
使用重要性抽样估计以下内容 
$$\int_{0}^{1}\frac{e^-x}{1+x^2}$$
$f_3(x)=\frac{e^{-x}}{1-e^{-1}}, 0&lt;x&lt;1$
u &lt;- runif(m) #f3，逆变换方法
x &lt;- - log(1 - u * (1 - exp(-1)))
fg &lt;- g(x) / (exp(-x) / (1 - exp(-1)))
theta.hat &lt;- mean(fg)
se &lt;- sd(fg)

$u=\frac{e^{-x}}{1-e^{-1}}$ 
$u(1-e^{-1})=e^{-x}$ 
$log\left(u(1-e^{-1})\right)=-x$ 
$-log\left(u(1-e^{-1})\right)=x$ 
$-log\left(1 - u(1-e^{-1})\right)=x$ 从何而来？如果 U 和 (1-U) 应该是相同的分布，那么为什么当我使用 x &lt;- - log(u * (1 - exp(-1))) 时会得到错误的输出？]]></description>
      <guid>https://stats.stackexchange.com/questions/655631/how-to-inverse-transform-e-x-1-e-1-0x1-for-importance-sampling</guid>
      <pubDate>Fri, 11 Oct 2024 03:06:15 GMT</pubDate>
    </item>
    <item>
      <title>既然使用了扁平化操作，为什么 CNN 不会遇到与矢量化图像相同的问题？</title>
      <link>https://stats.stackexchange.com/questions/655628/given-that-a-flattening-operation-is-used-why-is-it-that-a-cnn-does-not-have-th</link>
      <description><![CDATA[因此，使用 CNN 的一个主要动机是，如果我们要矢量化图像，然后将其输入到标准多层感知器中，则该矢量化图像将丢失像素之间的空间信息。
但是，在 CNN 中，矢量化例程（称为展平）也用于将最终输出矢量化为可用于输入完全连接或 softmax 层的内容。
CNN 中的展平操作如何不会遇到与矢量化图像相同的问题？每次我们展平时，一些跨通道信息是否会丢失？]]></description>
      <guid>https://stats.stackexchange.com/questions/655628/given-that-a-flattening-operation-is-used-why-is-it-that-a-cnn-does-not-have-th</guid>
      <pubDate>Fri, 11 Oct 2024 01:16:30 GMT</pubDate>
    </item>
    <item>
      <title>关于方差膨胀因子的问题（变量似乎相关，但方差膨胀因子并不高）</title>
      <link>https://stats.stackexchange.com/questions/655627/question-on-variance-inflation-factor-variables-seem-correlated-but-vif-is-not</link>
      <description><![CDATA[我正在尝试运行以下回归分析

再分配偏好 = 债务/金融资产 + 债务/房地产资产 + 其他一些控制 + e。

2. 再分配偏好 = 债务/金融资产 + 金融资产 + 其他一些控制 + e。

第一个方程有两个具有相同分子的比率变量。

第二个方程有一个比率变量和一个水平变量，水平变量是该比率变量的分母。
直观地讲，这两个方程可能存在一些问题，因为变量是相关的。但是当我计算 VIF 时，最多是 1.5-2。我认为这意味着它们仍然有中等相关性，但问题不大。

这是否意味着运行这些回归分析是可以的？或者我应该仍然遵循我的直觉，而不是将它们都包含在同一个模型中。]]></description>
      <guid>https://stats.stackexchange.com/questions/655627/question-on-variance-inflation-factor-variables-seem-correlated-but-vif-is-not</guid>
      <pubDate>Thu, 10 Oct 2024 23:51:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么似然函数的对数很重要？[重复]</title>
      <link>https://stats.stackexchange.com/questions/655626/why-is-the-logarithm-of-the-likeilhood-function-significant</link>
      <description><![CDATA[在最大似然法中，我们经常使用似然函数的对数，而不是直接使用似然函数。原因之一是它对于用于最大化似然函数的数值优化方法来说很方便。然而，从理论上讲，它似乎不仅仅只是“方便”。

最大似然估计量呈渐近正态分布，其协方差矩阵由 Fisher 信息矩阵的逆 $\mathcal{I}^{-1}$ 给出。然而 $\mathcal{I}$ 是根据对数似然而不是似然性定义的
同样，Cramer-Rao 边界再次涉及根据对数似然而不是似然性定义的 Fisher 信息。

因此，研究似然的对数而不是似然性似乎具有一定的理论意义。有人能提供关于为什么会这样的看法或直觉吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655626/why-is-the-logarithm-of-the-likeilhood-function-significant</guid>
      <pubDate>Thu, 10 Oct 2024 23:33:19 GMT</pubDate>
    </item>
    <item>
      <title>分析生物标志物数据以检测病理（和共同病理）的方法</title>
      <link>https://stats.stackexchange.com/questions/655625/methods-to-analyze-biomarker-data-to-detect-pathologies-and-co-pathologies</link>
      <description><![CDATA[我正在尝试进行分析以确定哪些生物标记物能够检测出特定病理。我正在研究 4 种不同的病理，但问题是它们经常同时发生。因此，如果我将人们分成几组，而不是 4 组，最终我会得到 12 个不同的组。每组有 1-3 种病理，样本量变得非常小（每组 2-15 种）。这使得标准的分组分析不太可行，但我不确定如何以其他方式梳理出这些分类变量如何影响生物标记物水平以及如何确定多种病理的影响。
这项研究的主要问题只是寻找生物标记物来检测独特的病理。但次要的、可能更有趣的问题是确定某人是否患有病理 #1，是否也可以使用生物标记物来检测共同病理 #2。如果有人对如何开始解决这个问题有任何建议或资源，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/655625/methods-to-analyze-biomarker-data-to-detect-pathologies-and-co-pathologies</guid>
      <pubDate>Thu, 10 Oct 2024 22:51:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么 $H(Y|X) \le H(Y)$</title>
      <link>https://stats.stackexchange.com/questions/655621/why-hyx-le-hy</link>
      <description><![CDATA[假设我们有 100 张牌，其中 98 张两面都是白色，一张两面都是黑色，最后一张一面是白色，另一面是黑色。
如果我问“我看到的是哪一面”，我们有 $p(F) \sim Be(0.985)$，因为我们有 3 张黑面和 197 张白面。因此，$H(F) \approx 0.0808$
现在，假设我知道另一面是黑色。然后 $p(F|F&#39;=black) \sim Be(0.5)$, $H(F|F&#39;=black) = 1$
因此，在我看来，额外的信息似乎增加了熵，但信息论明确指出 $H(Y|X) \le H(Y)$，因此知道另一面的颜色不应该让我更加不确定
因此，我的结论是，我严重误解/遗漏了一些东西，有什么想法吗？我应该考虑平均条件熵而不是特定情况吗？...]]></description>
      <guid>https://stats.stackexchange.com/questions/655621/why-hyx-le-hy</guid>
      <pubDate>Thu, 10 Oct 2024 21:04:25 GMT</pubDate>
    </item>
    <item>
      <title>事件发生后定义治疗的差异-差异法</title>
      <link>https://stats.stackexchange.com/questions/655620/difference-in-difference-with-treatment-defined-after-event</link>
      <description><![CDATA[我正在写一篇使用差异-差异设计方法的科学论文，但这不是标准的 DID 设置。
考虑一下我们在多个时间段收集多个公司观察结果的情况。在 $t=0$ 时发生一个事件。到目前为止，一切都很基本。现在偏离标准设置：不知道哪些公司属于治疗组和对照组，治疗组被定义为那些可观察特征 $x$ 从事件前到事件后从 $0$ 变为 $1$ 的公司。控制公司是那些特征 $x$ 保持在 $0$ 的公司。
这是 DID 设计的常见/已知版本吗？如果是，如果您能给我提供一些文献，我会很高兴，因为我还没有找到任何接近这个的文献。]]></description>
      <guid>https://stats.stackexchange.com/questions/655620/difference-in-difference-with-treatment-defined-after-event</guid>
      <pubDate>Thu, 10 Oct 2024 20:42:08 GMT</pubDate>
    </item>
    <item>
      <title>ICC计算</title>
      <link>https://stats.stackexchange.com/questions/655618/icc-calculation</link>
      <description><![CDATA[我有 200 名学生的数据，每名学生回答了两个文本问题，每个文本包含三个问题。对于文本 1，20 名评分员每人评分 10 名学生。对于文本 2，15 名新评分员和 5 名文本 1 中的评分员每人评分 10 名学生。这意味着每个学生只被评分一次。在这种情况下，我该如何计算 ICC？
有任何 SPSS 或 R 解决方案吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/655618/icc-calculation</guid>
      <pubDate>Thu, 10 Oct 2024 19:34:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么具有不同标准差的正态分布比其等效正态分布更适合另一个正态分布？</title>
      <link>https://stats.stackexchange.com/questions/655612/why-a-normal-distribution-with-a-different-standard-deviation-better-fits-anothe</link>
      <description><![CDATA[代码很简单：
vector_sd3 &lt;- rnorm(n = 100, mean = 15, sd = 3)
vector_sd3b &lt;- rnorm(n = 100, mean = 15, sd = 3) # 等效向量
vector_sd1 &lt;- rnorm(n = 100, mean = 15, sd = 1) # 均值相同但标准差较低
sum(abs(vector_sd3 - vector_sd3b))

返回的值高于；
sum(abs(vector_sd3 - vector_sd1))

我尝试运行多次，但仍然得到 vector_sd1 的较低 sd，较低sum(abs(vector_sd3 - vector_sd1)) 是
直观地看，我们会认为相反，有人能解释一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655612/why-a-normal-distribution-with-a-different-standard-deviation-better-fits-anothe</guid>
      <pubDate>Thu, 10 Oct 2024 15:56:52 GMT</pubDate>
    </item>
    <item>
      <title>选择零值计数数据进行组间显著性差异的统计检验</title>
      <link>https://stats.stackexchange.com/questions/655609/selecting-statistical-test-for-significant-difference-between-groups-from-count</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655609/selecting-statistical-test-for-significant-difference-between-groups-from-count</guid>
      <pubDate>Thu, 10 Oct 2024 15:41:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么简单回归中的最小二乘估计量的方差取决于预测变量？</title>
      <link>https://stats.stackexchange.com/questions/655507/why-variance-of-least-square-estimator-in-simple-regression-is-conditional-on-pr</link>
      <description><![CDATA[我是统计学新手，现在正在阅读 Sanford Weisberg 的《应用线性回归》一书。我可能问了一个无意义的问题，但为什么简单回归中的最小二乘估计量$\hat{\beta_0}$和$\hat{\beta_1}$的方差是$Var(\hat{\beta_0} |X)$和$Var(\hat{\beta_1} |X)$，而不是$Var(\hat{\beta_0})$和$Var(\hat{\beta_0})$？
假设我们有随机变量$X$和$Y$；并且我们有实现$x_i$和$y_i$。我使用样本预测器$\mathbf{x} = (x_1,x_2,...x_n)$和响应$\mathbf{y} = (y_1,y_2,...y_n)$估计了这些参数$\beta_0$和$\beta_1$。因此，我认为 $\hat{\beta_0}$ 和 $\hat{\beta_1}$ 的变异性应该来自于从 $X$ 中抽样加上以 $X$ 为条件的 $Y$ 的随机误差。然而，使用$Var(\hat{\beta_0} |X)$和$Var(\hat{\beta_1} |X)$表明变异性仅来自$Y$的随机误差。
同样的问题也出现在估计量$\hat{\beta_0}$和$\hat{\beta_1}$的无偏性的证明上。本书证明了$E(\hat{\beta_0}|X)=\beta_0$和$E(\hat{\beta_1}|X)=\beta_1$，但我认为目标应该是$E(\hat{\beta_0})$和$E(\hat{\beta_1})$。]]></description>
      <guid>https://stats.stackexchange.com/questions/655507/why-variance-of-least-square-estimator-in-simple-regression-is-conditional-on-pr</guid>
      <pubDate>Wed, 09 Oct 2024 02:24:46 GMT</pubDate>
    </item>
    <item>
      <title>成对 Welch T 检验、Kruskal-Wallis 还是其他？</title>
      <link>https://stats.stackexchange.com/questions/655477/pairwise-welch-t-test-kruskal-wallis-or-other</link>
      <description><![CDATA[我正在进行一项分析化学实验，其中有 11 组实验（环境样本，11 个地点）、1 个实验室对照和 3 个现场对照。所有组对特定化学物质都有 3 个观察值，除了其中一个现场对照只有 2 个。
我想知道某个环境样本站点的观察值是否与对照不同。
我不确定最好的方法是什么，并且得到了完全不同的答案：2 位博士导师
1 位研究生 1 位研究生研究员
要将一个站点与对照进行比较，我应该比较：
(a) 将 4 个对照合并为一个组，并对环境样本进行 Welch T 检验
(b) 将 3 个对照（无对照，只有两个重复）合并为一个组，并对环境样本进行 Welch T 检验
(c) 在 Kruskal-Wallis 检验中分析 3 个或 4 个对照 + 环境样本（3 个观察值通常不正常）
(d) 将实验室对照与环境站点的 Welch T 检验
(e) 报告这些检验的多个？
使用显著性 P = 0.05，我已经完成了方法 A、C 和 D，并得出了与我的假设截然不同的答案。
编辑：


为清晰起见，请进行编辑：
响应变量是测量的感兴趣的化学物质的环境浓度，可用于 11 个站点、3 个现场控制和一个实验室控制，重复 3 = 44 个观察值 + (1) 个丢失的重复值。这适用于 8 种化合物，总共提供 352 个测量值。
数据是非正态的，因为不同的站点产生不同的测量值，并且在这么小的样本中污染不遵循正态分布（一些站点污染严重，大多数没有），但如果对同一化合物的同一样本进行重复测试，用于测量此类浓度的机器应该产生高斯分布。
仪器具有最低检测限 (LOD)，这导致数据集中出现许多 0，根据我的经验，到目前为止，这限制了数据转换为正态性的能力。
我不确定如何在此处列出整个数据集，但我在此处包含了一个箱线图，其中包括单个化合物在多个站点的 Kruskal-Wallis 结果，因为这是讨论的重点。
]]></description>
      <guid>https://stats.stackexchange.com/questions/655477/pairwise-welch-t-test-kruskal-wallis-or-other</guid>
      <pubDate>Tue, 08 Oct 2024 15:48:31 GMT</pubDate>
    </item>
    <item>
      <title>DHARMa 残差模式</title>
      <link>https://stats.stackexchange.com/questions/655401/dharma-residual-pattern</link>
      <description><![CDATA[我正在尝试使用具有 beta 分布的 glmmTMB 来建模行为（如另一篇文章中所建议的那样）。我的模型由几个固定因素和两个随机效应（物种和个体）组成。我已经通过使用以下方法转换因变量解决了 0-1 问题：
参考文献：Smithson, M., &amp; Verkuilen, J. 更好的柠檬榨汁机？具有 beta 分布因变量的最大似然回归。心理学方法，11，54–71（2006 年）。DOI：10.1037/1082-989X.11.1.54
在使用 DHARMa 检查残差后，我注意到以下模式。我正在建模几种行为，并为每种行为获得类似的模式。我还对二分变量运行了二项式 GLMM，没有遇到任何问题。

我的问题是：

我该如何解决残差中的这些模式？
我对图的解释正确吗？根据我的理解，该模型低估了低预测值的残差，而高估了高预测值的残差，这意味着它无法准确地模拟因变量的低值和高值。我是对的，还是我完全误解了这一点？

提前非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655401/dharma-residual-pattern</guid>
      <pubDate>Sun, 06 Oct 2024 15:30:48 GMT</pubDate>
    </item>
    <item>
      <title>使用 Lan DeMets alpha 支出函数方法计算临界值</title>
      <link>https://stats.stackexchange.com/questions/655363/critical-values-calculation-using-lan-demets-alpha-spending-function-approach</link>
      <description><![CDATA[我需要计算 2 阶段设计的临界值，其中第一阶段是在 0.7 信息分数下进行的中期分析，第二阶段是在 1.0 信息分数下进行的最终分析。使用具有 O’Brien-Fleming 边界的 Lan DeMets alpha 支出函数进行计算，总 I 型错误为 0.05。
这可以在 SAS 中调用 proc seqdesign 过程或在 R 中使用 ldBounds 函数来实现。
SAS：

proc seqdesign;
design method = errfuncobf
alt = twosided
nstages = 2
info = cum(0.7 1)
alpha = 0.05
;
run;

分别为中间值和最终值给出临界值 2.43799 和 1.99993
proc seqdesign 输出
R:
obf_bounds &lt;- ldBounds(c(0.7, 1), alpha = 0.05)
summary(obf_bounds)

与 SAS 程序中的临界值相同

临界值通过求解
Pr{|Z1| &lt; 来确定c1, . . . , |Zk−1| &lt; ck−1, Zk ≥ z} = π_k / 2, k = 1, . . . , K

Jennison 和 Turnbull 编写的《应用于临床试验的组序贯方法》教科书中描述了求解该方程的迭代算法。
我的问题是如何从上面的示例中获取第一个临界值 c1，即 2.43799。

在我看来，临界值是从方程 Pr{Z1 ≥ z} = π_1 / 2 中获得的，它是正态分布的第 (1-π_1 / 2) 个百分位数，其中 π_1 由 Lan DeMets alpha 消耗函数给出，O’Brien-Fleming 边界在适当的信息分数级别上进行评估。 f(t) = min{2 − 2(zα/2/√t), α} 在 0.7 信息分数下求值可得出 π_1 = 0.01914964。
但是，(1-0.01914964/2) 百分位数是 2.342605，这不是正确的数字（正确的数字是 2.43799）。
我非常感谢大家的评论，指出了上述 c1 计算逻辑中的差距。]]></description>
      <guid>https://stats.stackexchange.com/questions/655363/critical-values-calculation-using-lan-demets-alpha-spending-function-approach</guid>
      <pubDate>Fri, 04 Oct 2024 22:51:03 GMT</pubDate>
    </item>
    <item>
      <title>在预测预测概率时计算 fenegbin 对象的置信区间</title>
      <link>https://stats.stackexchange.com/questions/655328/computing-confidence-intervals-for-fenegbin-object-when-predicting-predicted-pro</link>
      <description><![CDATA[如果能得到一些帮助，计算通过 fixest::fenegbin 估计的负二项模型的预测概率的置信区间，并且考虑到大量的固定效应，我将非常感激。该模型如下所示：
model &lt;- fenegbin(CountVariable~ X1*X2| date_fe, data = data)
summary(model)

我预测如下：
# 用于绘图或预测的交互项序列
X1_seq &lt;- seq(min(data$X1, na.rm = TRUE), 
max(data$X1, na.rm = TRUE), 
length.out = 200)
X2_seq &lt;- seq(min(data$X2, na.rm = TRUE), 
max(data$X2, na.rm = TRUE), 
length.out = 200)

selected_dates &lt;- unique(data$date_fe) # 根据需要进行调整

# 创建用于预测的数据框
pred_data_expanded &lt;- expand.grid(X1_seq = X1,
X2_seq = X2,
date_fe = selected_dates) 
# 仅当 date_fe 相关时才包含此行

# 生成预测和置信区间
preds &lt;- predict(model, newdata = pred_data_expanded)

我遇到的问题是无法使用 fixest 计算负二项模型的置信区间：
preds &lt;- predict(model, newdata = pred_data_expanded, type=&#39;response&#39;, 
se.fit = TRUE)
predict.fixest(model, newdata = pred_data_expanded, 
type = &quot;response&quot;, : 
预测的标准误差目前仅适用于
OLS 模型，抱歉。

问题是，在我的领域，用置信区间展示预测概率非常常规，而不用置信区间展示预测概率则非常不常规。仅具有高统计显著性的模型可能不够用...
如果有人以前遇到过这个问题或有建议，我洗耳恭听！]]></description>
      <guid>https://stats.stackexchange.com/questions/655328/computing-confidence-intervals-for-fenegbin-object-when-predicting-predicted-pro</guid>
      <pubDate>Fri, 04 Oct 2024 15:03:11 GMT</pubDate>
    </item>
    </channel>
</rss>