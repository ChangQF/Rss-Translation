<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 06 Dec 2023 15:15:15 GMT</lastBuildDate>
    <item>
      <title>计算时间序列何时达到 s 特定值</title>
      <link>https://stats.stackexchange.com/questions/633219/calculate-when-a-time-series-will-reach-s-specific-value</link>
      <description><![CDATA[我有一个日级粒度的时间序列：
&lt;前&gt;&lt;代码&gt;日期。价值
2023-10-01 78945
2023-10-02 78990
2023-10-03 79005
2023-10-04 78999
...

虽然存在一些波动，但总体趋势是增加的，我们希望估计该值何时达到阈值，例如 90000。
虽然像 Holt-Winters、ARIMA 这样的标准时间序列模型非常适合预测，但我不确定如何使用它们来获得准确的“跑道”。就像在这个例子中一样。
一种方法是计算增长率并假设线性增长并找到时间，但正确计算增长率也是一个问题。
所以，我有两个问题：

是否有标准方法来计算时间序列何时达到特定值？
如何正确衡量增长率？

一项附加要求：
突然的峰值（荒谬的增加和减少）不应突然减少/增加跑道。]]></description>
      <guid>https://stats.stackexchange.com/questions/633219/calculate-when-a-time-series-will-reach-s-specific-value</guid>
      <pubDate>Wed, 06 Dec 2023 15:12:05 GMT</pubDate>
    </item>
    <item>
      <title>使用系数计算倾向得分</title>
      <link>https://stats.stackexchange.com/questions/633218/calculate-propensity-scores-using-coefficients</link>
      <description><![CDATA[我想使用逻辑模型的系数来计算倾向得分，该模型是使用此数据的随机样本计算的：
库（钴）
lalonde &lt;- cbind(lalonde)

该模型的系数：
coefs &lt;- data.frame(
  变量= c(“年龄”、“教育程度”、“已婚”、“无学位”、“re74”、“re75”、“re78”)，
  系数 = c(0.00353307260, 0.17793493995, -1.80187766260, 1.23640426679, -0.00007437231, 0.00007213403, 0.00002055623)
）

如何根据 lalonde 数据的系数计算倾向得分？
我知道包含计算倾向分数的软件包。
我只是感兴趣如何在给定系数的情况下应用它。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/633218/calculate-propensity-scores-using-coefficients</guid>
      <pubDate>Wed, 06 Dec 2023 14:59:27 GMT</pubDate>
    </item>
    <item>
      <title>小样本的中值插补或案例删除</title>
      <link>https://stats.stackexchange.com/questions/633217/median-imputation-or-case-deletion-for-small-samples</link>
      <description><![CDATA[我陷入了两难的境地。我有来自 4 组动物的不同蛋白质的数据集，其特征有两个因素：年龄（3 或 12 个月）和特定基因的存在（KO 或 WT）。对于每种因素组合（3m、KO；12m KO；3m WT；12m WT），我有 6 次测量（即 6 只动物），但其中一组只有 5 次测量。这使我无法进行对齐排名变换，然后执行非参数因子 (ANOVA) 分析。相反，如果 (a) 我将样本减少到每组 5 个数据点，或者 (b) 如果我用同一组 5 个数据点的中位数替换缺失的数据点，则该分析在技术上有效。我真的不知道哪一个是更好的解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/633217/median-imputation-or-case-deletion-for-small-samples</guid>
      <pubDate>Wed, 06 Dec 2023 14:50:44 GMT</pubDate>
    </item>
    <item>
      <title>多重共线性和分类变量</title>
      <link>https://stats.stackexchange.com/questions/633214/multicollinearity-and-categorical-variables</link>
      <description><![CDATA[在对分类变量进行回归时，为了避免多重共线性，需要降低一级。这一点其实很清楚：
假设我有一个二元分类变量（A，B）和以下数据：
id、猫、y
1 A y_1
2 由 y_2
3 y_3
4 y_4
...

其中 id 只是目标变量、设计矩阵（带截距）的索引，设计矩阵将如下所示（删除 A 并将其设置为基准水平）：
id、拦截、cat_B、y
1 1 0 y_1
2 1 1 y_2
3 1 1 y_3
4 1 0 y_4
...

这是完全有道理的，因为如果我们保留 A 和 B 的指示符，A 的列 (cat_A) 将线性依赖于列 (cat_B)，并且矩阵不可逆。
我不明白的是，如果我们没有拦截，我们不必下降一级，我们有以下内容：
&lt;前&gt;&lt;代码&gt; id、cat_A、cat_B、y
    1 1 0 y_1
    2 0 1 y_2
    3 1 1 y_3
    4 1 0 y_4
    ...

现在可以进行线性回归了。 Cat_A 列和 Cat_B 列仍然线性相关。为什么这不再是问题了？]]></description>
      <guid>https://stats.stackexchange.com/questions/633214/multicollinearity-and-categorical-variables</guid>
      <pubDate>Wed, 06 Dec 2023 14:37:36 GMT</pubDate>
    </item>
    <item>
      <title>如果你先走与最后走相比，让某个人成为秘密圣诞老人的可能性是否会降低，降低多少？</title>
      <link>https://stats.stackexchange.com/questions/633212/does-the-likelihood-of-getting-a-certain-person-in-secret-santa-decrease-if-you</link>
      <description><![CDATA[感觉有点愚蠢，但这里是：
这个秘密圣诞老人有 6 个人，其中一个是 X 人，另一个是 Y 人。所有的名字都放在帽子里，每个人上来从帽子里取一个名字。如果这个名字是他们自己的，他们就会把它放回去并重新绘制，直到它是别人的名字。然后，下一个人也做同样的事情。绘制的名称不会被替换。
如果X先走，他知道Y的名字的机会有多大？如果 X 排在最后，那么 X 得到 Y 名字的机会有多大？
提前感谢您的帮助，这让我很伤脑筋，这真是令人尴尬]]></description>
      <guid>https://stats.stackexchange.com/questions/633212/does-the-likelihood-of-getting-a-certain-person-in-secret-santa-decrease-if-you</guid>
      <pubDate>Wed, 06 Dec 2023 14:16:12 GMT</pubDate>
    </item>
    <item>
      <title>完整的案例分析、多重插补或工具变量分析？</title>
      <link>https://stats.stackexchange.com/questions/633211/complete-case-analysis-multiple-imputation-or-instrumental-variable-analysis</link>
      <description><![CDATA[我进行了一项小型研究，所有参与者都参加了心理干预，并完成了术前、术后和随访的测量。大约。参加人数 40 人，其中约5家未完成后续措施。
我怀疑数据是随机丢失的（即参与者忘记了有后续行动，没有检查电子邮件等），但不想排除干预本身存在一些问题的可能性他们没有完成。
使用多重插补或工具变量分析等方法是否合适，而不是通过使用完整的案例分析来冒引入偏差和进一步减少小样本的风险？
我对这些方法不太熟悉 - 关于哪种方法可能是“最佳”或替代方案有什么指导吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/633211/complete-case-analysis-multiple-imputation-or-instrumental-variable-analysis</guid>
      <pubDate>Wed, 06 Dec 2023 14:12:07 GMT</pubDate>
    </item>
    <item>
      <title>如何将 glmnet 模型的截距限制为正？</title>
      <link>https://stats.stackexchange.com/questions/633209/how-can-you-constrain-the-intercept-of-a-glmnet-model-to-be-positive</link>
      <description><![CDATA[如果我使用 lower.limits = 0 参数，由于某种原因它不适用于拦截。我找不到任何关于为什么或如何执行此操作的文档。有任何想法吗？下面是一个可重现的示例。正如您所看到的，仍然存在负拦截。
# 加载包
图书馆（glmnet）

# 生成数据
设置.种子(12345)
n &lt;- 1000
X &lt;- cbind(1, runif(n, 0, 10), runif(n, 10, 20))
y &lt;- -20 + X %*% c(2, 3, 4) + rnorm(n, 0, 1)
colnames(X) = c(“截距”, “x1”, “x2”)

# 运行套索模型
模型 &lt;- glmnet(
    X，
    是，
    alpha = 0.5, # 弹性网
    标准化 = T,
    lambda = 10^seq(-10, 2, 长度 = 10),
    下限 = 0
）

# 通过BIC计算lambda
beta &lt;- as.matrix(model$beta)
beta[&quot;intercept&quot;, ] &lt;- model$a0 # 添加拦截

＃ 展示
贝塔

＃ 结果
                s0 s1 s2 s3 s4 s5 s6 s7 s8 s9
截距 57.93445 6.057752 -16.678764 -17.897615 -17.954596 -17.957241 -17.957364 -17.957370 -17.957370 -17.957370
x1 0.00000 1.929682 2.963308 3.018680 3.021269 3.021389 3.021395 3.021395 3.021395 3.021395
x2 0.00000 2.772042 3.923162 3.984883 3.987769 3.987903 3.987909 3.987909 3.987909 3.987909
]]></description>
      <guid>https://stats.stackexchange.com/questions/633209/how-can-you-constrain-the-intercept-of-a-glmnet-model-to-be-positive</guid>
      <pubDate>Wed, 06 Dec 2023 13:53:59 GMT</pubDate>
    </item>
    <item>
      <title>如何从 mgcv 包中的 GAM 模型计算相对风险？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/633206/how-to-calculate-relative-risk-from-gam-model-in-mgcv-package</link>
      <description><![CDATA[我有每日空气污染参数 PM10、PM2.5 CO、NO2、SO2 和 O3。我还有每天的入院人数。考虑到周末和节假日的影响，我想使用广义加性模型（GAM）来探讨每日入院病人量与空气污染参数之间的关系。我想使用 mgcv 包。如何获得每种污染物的总体相对风险和95%CI？
我不知道它是否正确，但这是我使用的代码：
install.packages(“mgcv”)

库（mgcv）

数据=read.csv2(file.choose(),header=TRUE)

data$date &lt;- as.Date(data$date, format=&quot;%d.%m.%Y&quot;)


数据$weekend &lt;- 因子(data$weekend)


数据$holiday &lt;- 因子(data$holiday)

模型 &lt;- gam(adm ~ s(PM10, k = 5) + s(PM2.5, k = 5) + s(CO, k = 5) + s(NO2, k = 5) + s(SO2, k = 5) + s(O3, k = 5) + 周末 + 假期，家庭 = quasipoisson(link = &quot;log&quot;)，data = 数据，method = &quot;REML&quot;)

pred &lt;- Predict.gam（模型，类型=“响应”）

相对风险 &lt;- exp(pred$fit)

但是，当我查看结果时，它单独计算 365 天的 RR。
如何获得如这篇文章中表4的结果？每种污染物只有一次RR计算。]]></description>
      <guid>https://stats.stackexchange.com/questions/633206/how-to-calculate-relative-risk-from-gam-model-in-mgcv-package</guid>
      <pubDate>Wed, 06 Dec 2023 13:38:51 GMT</pubDate>
    </item>
    <item>
      <title>我可以在没有假设的情况下使用 p 值吗？</title>
      <link>https://stats.stackexchange.com/questions/633205/can-i-use-p-values-without-hypothesis</link>
      <description><![CDATA[我一直在写我的硕士论文，其中包括一项调查，其结果已经通过了各种测试。我的论文的不同寻常之处在于我根本没有假设，使其成为描述性统计分析。然而，我提出假设只是为了计算 p 值以测量显着性阈值（1%、5% 和 10%）。与此同时，我的导师提醒我缺乏假设，强调我不应该有任何假设。
我的问题是，我可以在不使用假设的情况下使用这些信息吗？这意味着在没有假设的情况下，显着性阈值的信息是否有任何价值，我可以重新表述它们，使它们看起来像“声明”吗？而不是假设？我不想浪费所有这些工作和信息，但如果无法使用它们，我对此无能为力。]]></description>
      <guid>https://stats.stackexchange.com/questions/633205/can-i-use-p-values-without-hypothesis</guid>
      <pubDate>Wed, 06 Dec 2023 13:35:57 GMT</pubDate>
    </item>
    <item>
      <title>R 中的混合效应模型，在重复中进行子采样</title>
      <link>https://stats.stackexchange.com/questions/633215/mixed-effects-model-in-r-with-subsampling-in-replicates</link>
      <description><![CDATA[我正在 r 中研究混合效应模型，其中我有 2 次处理、5 次重复和每个位点的二次采样。不过，我无权访问原始子采样数据，我只知道每次重复的平均效应大小、每次重复的子样本数量以及每次重复的汇总方差。
我正在试验这段代码。考虑到我的实验设计和数据限制，这是否有效？
模型 &lt;- lmer(EffectSize ~ Treatment + (1 | Replication) + (1 | Replication:Subsampling),
数据=数据，
权重 = 1/方差）]]></description>
      <guid>https://stats.stackexchange.com/questions/633215/mixed-effects-model-in-r-with-subsampling-in-replicates</guid>
      <pubDate>Wed, 06 Dec 2023 13:28:36 GMT</pubDate>
    </item>
    <item>
      <title>我有 3 个完全连接层的神经网络。除了第 3 个 FC 层之外，手动进行反向传播，所有 FC 层偏差梯度都出现错误 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/633202/i-have-neural-network-of-3-fully-connected-layers-doing-backpropagation-manuall</link>
      <description><![CDATA[神经网络：
self.fc1 = nn.Linear(1024, 512)
self.bn1 = nn.BatchNorm1d(512)
self.drop1 = nn.Dropout(0.4)
self.fc2 = nn.Linear(512, 256)
self.bn2 = nn.BatchNorm1d(256)
self.drop2 = nn.Dropout(0.4)
self.fc3 = nn.Linear(256, num_class=10)

转发函数如下所示：
def fc1_hook_fn(grad):
       fc1_x.grad = grad.clone()
def bn1_hook_fn(grad):
       bn1_x.grad = grad.clone()
def relu1_hook_fn(grad):
       relu1_x.grad = grad.clone()
def drop1_hook_fn(grad):
       drop1_x.grad = grad.clone()

fc1_x = self.fc1(x)
fc1_x.register_hook(fc1_hook_fn)

bn1_x = self.bn1(fc1_x)
bn1_x.register_hook(bn1_hook_fn)

relu1_x = F.relu(bn1_x)
relu1_x.register_hook(relu1_hook_fn)

drop1_x,mask1 = self.dropout_layer(relu1_x, 0.4)
drop1_x.register_hook(drop1_hook_fn)

def fc2_hook_fn(grad):
       fc2_x.grad = grad.clone()

def bn2_hook_fn(grad):
       bn2_x.grad = grad.clone()

def relu2_hook_fn(grad):
       relu2_x.grad = grad.clone()

def drop2_hook_fn(grad):
       drop2_x.grad = grad.clone()

fc2_x = self.fc2(drop1_x)
fc2_x.register_hook(fc2_hook_fn)

bn2_x = self.bn2(fc2_x)
bn2_x.register_hook(bn2_hook_fn)

relu2_x = F.relu(bn2_x)
relu2_x.register_hook(relu2_hook_fn)
       
drop2_x, mask2 = self.dropout_layer(relu2_x, 0.4)
drop2_x.register_hook(drop2_hook_fn)

def fc3_hook_fn(grad):
       fc3_x.grad = grad.clone()

fc3_x = self.fc3(drop2_x)
fc3_x.register_hook(fc3_hook_fn)
 
x = F.log_softmax(fc3_x, -1)

然后我应用 log_softmax 和 nll_loss。
我使用以下几行直接打印权重和偏差梯度
对于 classifier.named_pa​​rameters() 中的名称、参数：
        print(f&#39;参数名称是:{name}&#39;)
        print(f&#39;参数形状为:{param.shape}&#39;)
        param.register_hook(lambda grad, name=name: print(name, grad)) # 注册一个钩子来打印渐变

现在我将反向传播编写如下，以将权重和偏差梯度与手动计算相匹配。在训练中使用了adam优化器。但据我所知，adam 优化器只是用于更新权重和偏差，与此步骤计算的偏差梯度无关[param.register_hook(lambda grad, name=name: print(name, grad))]。如果我错了，请告诉我。
# 向后传递

dz3 = softmax(fc3) # fc3 是第 3 个 FC 层的输出
m = drop2.shape[0]

dz3[距离（米），目标] -= 1
dz3 /= 米
dW3 = np.dot(dz3.T, drop2) # drop2 是第二个 dropout 层的输出
db3 = np.sum(dz3, axis=0, keepdims=True)


# 损失与 fc3 输入的导数的导数
dX3 = np.dot(dz3, fc3_权重)
dDropout2 = dX3 * (掩码2/0.6)
dRelu2 = dDropout2 * np.where(bn2 &gt; 0, 1, 0) #bn2 是第二个batchnorm层的输出

def batchnorm_backward(dout, x, gamma, beta, epsilon=1e-05):
    N, D = x.形状
    x_minus_mean = x - np.mean(x, 轴=0)
    print(f&#39;x_minus_mean 形状为：{x_minus_mean.shape}&#39;)
    var = np.var(x, 轴=0)
    sqrt_var_plus_eps = np.sqrt(var + epsilon)
    inv_sqrt_var_plus_eps = 1.0 / sqrt_var_plus_eps

    dx_归一化 = dout * gamma
    print(f&#39;dx_normalized 形状是:{dx_normalized.shape}&#39;)

    dvar = np.sum(dx_normalized * x_minus_mean, axis=0) * -0.5 * inv_sqrt_var_plus_eps**3
    dmean = np.sum(dx_normalized * -inv_sqrt_var_plus_eps, axis=0) + dvar * np.sum(-2.0 * x_minus_mean, axis=0) / N

    dx = dx_归一化 * inv_sqrt_var_plus_eps + dvar * 2.0 * x_minus_mean / N + dmean / N

    dgamma = np.sum(dout * (x - np.mean(x, axis=0)) / sqrt_var_plus_eps, axis=0)
    dbeta = np.sum(dout, 轴=0)

dbn2_x, dbn2_w, dbn2_b = batchnorm_backward(dRelu2, fc2, bn2_weights, bn2_bias, epsilon=1e-5) #fc2 是第二个 FC 层的 O/P
dW2 = np.dot(dbn2_x.T, drop1) #drop1 是第一个 dropout 层的 O/P
db2 = np.sum(dbn2_x, axis=0, keepdims=True)

dX2 = np.dot(dbn2_x, fc2_权重)

到目前为止，除了 db2（第二个 FC 层的偏差梯度）值之外，一切都是正确的，我不明白我做错了什么。我在卷积层的 BP 偏差梯度中也面临类似的问题。请有人帮助我可能出错的地方。谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/633202/i-have-neural-network-of-3-fully-connected-layers-doing-backpropagation-manuall</guid>
      <pubDate>Wed, 06 Dec 2023 13:24:24 GMT</pubDate>
    </item>
    <item>
      <title>当分布具有很长的尾部时，我应该使用基于均值的偏度度量还是基于中位数的偏度度量？</title>
      <link>https://stats.stackexchange.com/questions/633201/should-i-use-a-mean-based-measure-of-skewness-or-a-median-based-measure-of-skewn</link>
      <description><![CDATA[我知道基于均值的偏度度量会受到异常值的影响，并且只有一个异常值就可以显着改变均值。但是，如果分布具有很长的尾部，我应该使用基于均值的偏度度量还是基于中值的偏度度量来衡量分布的对称性？
事实上，我认为长尾可能会通过显着改变均值而产生与异常值类似的效果，但我不确定。]]></description>
      <guid>https://stats.stackexchange.com/questions/633201/should-i-use-a-mean-based-measure-of-skewness-or-a-median-based-measure-of-skewn</guid>
      <pubDate>Wed, 06 Dec 2023 13:23:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么 RKHS 的概念在核岭回归中有用？</title>
      <link>https://stats.stackexchange.com/questions/633195/why-is-the-concept-of-rkhs-useful-in-kernel-ridge-regression</link>
      <description><![CDATA[我看到的核岭回归引入的方式如下。给定数据 $(X,Y)$，您希望拟合 RKHS &lt; 中的函数 $f$ span class=&quot;math-container&quot;&gt;$\mathcal{H}$ 以最小化一些经验损失 $\sum_i L(f(x_i), y_i)$ 加上正则化项 $\lambda ||f||^2$，其中 $|| \c点 || $ 是与 RKHS 相关的规范。
然后根据“表示定理”得出这样的目标的最小化器是 $\{ k(x_i, \cdot ) \}_i$ 的线性组合，其中 $k$ 是与 RKHS 关联的内核，因此寻找最小值就简化为线性回归。
我不明白的是，抽象出 RKHS 概念有什么意义？似乎很难知道 RKHS 中的功能实际上“是什么样子”，以及惩罚规范到底会产生什么效果。如果您从“表示定理”开始，似乎更容易理解人们实际上在做什么。形式，因为函数 $k(x_i, \cdot)$ 可以可视化为凹凸函数等。]]></description>
      <guid>https://stats.stackexchange.com/questions/633195/why-is-the-concept-of-rkhs-useful-in-kernel-ridge-regression</guid>
      <pubDate>Wed, 06 Dec 2023 12:55:33 GMT</pubDate>
    </item>
    <item>
      <title>Bootstrapping 如何解释统计数据的不确定性？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/633194/how-can-bootstrapping-explain-the-uncertainty-of-a-statistic</link>
      <description><![CDATA[我一直在阅读有关引导的内容，以及抽样分布，并发现人们使用这些技术来描述不确定性很奇怪。
据我了解，抽样分布显示了通过对样本进行放回重新抽样来测量的样本统计数据的不确定性。
因此，如果您引导样本，您真正得到的是统计数据的统计数据，具有不确定性界限。
但我们肯定只关心原始统计数据，因为它是总体参数的估计。我们想知道原始统计数据的不确定性界限，因为它告诉我们有关总体的一些信息。那么，为什么我们要关心原始统计量的统计量的不确定性界限呢？
这如何告诉我们有关总体参数的信息？
这里已经有一个对此问题的外行答案：
向外行解释引导为何有效
我的问题是上述问题的延伸。我想在更深的数学层面上了解它是如何工作的，最好有经验证据。]]></description>
      <guid>https://stats.stackexchange.com/questions/633194/how-can-bootstrapping-explain-the-uncertainty-of-a-statistic</guid>
      <pubDate>Wed, 06 Dec 2023 12:53:02 GMT</pubDate>
    </item>
    <item>
      <title>不平衡数据的精确率和召回率的置信区间</title>
      <link>https://stats.stackexchange.com/questions/633193/confidence-intrervals-of-precision-and-recall-with-unmbalanced-data</link>
      <description><![CDATA[虚构的示例：有两个模型可以预测一种罕见的癌症（发生率为 80.000 分之一或 0,001%）。为了评估这些模型的性能，我们根据过去两年的标记数据计算这两个模型的精度（和召回率）。从 450 万名患者中，我们知道他们是否患有癌症，并获得每周的血液检查信息。对于阳性病例，我们使用诊断前最接近的血液检查结果作为预测因子，对于阴性病例，我们采用随机一周的结果。模型对患者进行评分，并按从高到低的顺序排列。仅检查前 1000 名。
一种模型的精度（= 有多少次检查得出阳性病例）高于另一种模型（见图）。为了增强这个结论的强度，我想添加置信区间并测试差异的显着性。

我尝试计算排名前 1000 名的检查精度，并使用以下混淆矩阵：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

模型 1
实际+
实际 -


&lt;正文&gt;

预测+
25
975


预测 -
53
4498947




精度 = 2.5%
95% CI = [2.49%, 2.501%]
使用：
$ p \pm z * \sqrt(p(1-p)/n) $
;其中 p = 0.025； z = 1.96； n = 4.5*10^6

&lt;表类=“s-表”&gt;
&lt;标题&gt;

模型 2
实际+
实际 -


&lt;正文&gt;

预测+
47
953


预测 -
31
4498969




精度 = 4.7% [CI: 4.68%,4.72%]
我仍然有以下问题：

我们是否应该报告置信区间，因为我们研究的是整个患者群体。我选择“是”的理由是（1）数据并不完美，因此计算肯定不准确，（2）我们希望将结果外推到未来的案例，所以这两年的数据只是较大人群的一部分， (3) 并非所有可用的数据点都被使用，在每个案例 104 个可用的每周数据点中，我们只使用一个。这可以看作是一个样本。我反对的理由是（1）所使用的 4,5 个数据点确实构成了一个大样本，因此暗示了估计的可靠性，并且（2）任何计算置信区间的方法都可能变得复杂，这会引入新的不确定性并降低可解释性。 
如果 CI 有用，上面的计算是否正确？或者样本量应该是1000？还是 bootstrap CI 更好？但由于类别不平衡，我们需要对 1 进行过采样以避免出现没有正例的样本，然后考虑这种过采样。这些结果是不是太复杂而缺乏可信度？

这些问题似乎非常小众且针对具体情况，因此也欢迎任何关于如何以及在哪里进一步寻找答案的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/633193/confidence-intrervals-of-precision-and-recall-with-unmbalanced-data</guid>
      <pubDate>Wed, 06 Dec 2023 12:49:44 GMT</pubDate>
    </item>
    </channel>
</rss>