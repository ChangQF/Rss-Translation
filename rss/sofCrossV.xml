<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 17 May 2024 09:16:13 GMT</lastBuildDate>
    <item>
      <title>GLMM 的置信区间</title>
      <link>https://stats.stackexchange.com/questions/647410/confidence-interval-for-glmm</link>
      <description><![CDATA[我正在为我的学士论文进行 GLMM，我想知道如何计算以及报告模型估计的置信区间是否常见。
这是我根据数据拟合的模型：
glmer(response_time ~ 1 + 饥饿评级 + 篮子大小 + 饥饿评级:篮子大小 + (1|prolific_id), data = GLMM_data, family=“inverse.gaussian”(link=&#39;identity&#39;), control = glmerControl(优化器=“bobyqa”,optCtrl=list(maxfun=2e9),calc.derivs = FALSE))
]]></description>
      <guid>https://stats.stackexchange.com/questions/647410/confidence-interval-for-glmm</guid>
      <pubDate>Fri, 17 May 2024 08:55:11 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型中嵌套项的灵活协方差结构</title>
      <link>https://stats.stackexchange.com/questions/647407/flexible-covariance-structure-of-the-nested-term-in-linear-mixed-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647407/flexible-covariance-structure-of-the-nested-term-in-linear-mixed-model</guid>
      <pubDate>Fri, 17 May 2024 08:15:21 GMT</pubDate>
    </item>
    <item>
      <title>具有稳健方差估计的多级荟萃分析的离群值和影响力分析</title>
      <link>https://stats.stackexchange.com/questions/647405/outlier-and-influential-analysis-for-multilevel-meta-analysis-with-robust-varian</link>
      <description><![CDATA[我正在进行三级元分析，其中数据中有不同的依赖结构。我通过近似 var-cov 矩阵来对依赖关系进行建模，然后估计三级模型，然后应用稳健的方差估计来计算我的结果（如此处所建议的：https://wviechtb.github.io/metafor/reference /misc-recs.html#general-workflow-for-meta-analysiss-involving-complex-dependency-structs)
我想通过运行异常值和有影响力的诊断来对模型进行一些敏感性分析。然而，大多数所提出的诊断方法不适用于“robust.rma”。对象。
到目前为止，我通过计算稳健模型的库克距离和帽子值进行了一些模型诊断（例如，https://wviechtb.github.io/metafor/reference/influence.rma.mv.html）。但就我而言，这些“唯一”是向我提供有影响力案例的信息，而不是异常值。
使用稳健模型时检查异常值的最佳方法是什么？下面的两个选项是检查异常值的明智方法吗？

根据该消息来源，一种可能但相当保守的方法是将所有研究标记为离群值，其置信区间与汇总效应的置信区间不重叠。 （参见：https://cjvanlissa .github.io/Doing-Meta-Analysis-in-R/detecting-outliers-influenceial-cases.html）。

按照建议（例如）对非鲁棒模型执行异常值诊断是否是一个可行的选择？作者：Viechtbauer &amp;张（2010；10.1002/jrsm.11）。我的方法是根据非稳健模型识别异常值 --&gt;排除异常值 --&gt;在没有异常值的情况下重新运行整个分析（即近似 var-cov 矩阵、估计三级模型、对研究子集应用稳健方差估计）。


或者还有其他更优雅的方法来做到这一点吗？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/647405/outlier-and-influential-analysis-for-multilevel-meta-analysis-with-robust-varian</guid>
      <pubDate>Fri, 17 May 2024 07:03:07 GMT</pubDate>
    </item>
    <item>
      <title>如何确定 FE 性能中的辛普森悖论是否会导致错误下降、延迟上升</title>
      <link>https://stats.stackexchange.com/questions/647404/how-to-figure-out-if-simpsons-paradox-in-fe-performance-where-errors-go-down-l</link>
      <description><![CDATA[根据问题，当我一对一查看页面时，我们的延迟似乎与以前大致相同，有点不太好 - 勉强可以通过。
但是在最近发布之后，我们的错误率下降到了之前错误的五分之一左右。
所有用户的延迟时间增加了一倍多。许多其他性能统计数据也恶化了。
我们看不到任何会影响性能的因素。
所以我在想，可能很多早期犯错的人现在都留下来了，但表现不佳，但我在个人分析上没有任何问题。
我怎样才能开始解决这个问题？
我不认为这只是重做如何解决辛普森悖论问题，因为我在这方面非常没有受过教育，这更像是在用户出错时识别混杂变量，现在我们的错误减少了，如何计算找出在给出这些假设之前哪些人会犯错误？
希望这是可以理解的。]]></description>
      <guid>https://stats.stackexchange.com/questions/647404/how-to-figure-out-if-simpsons-paradox-in-fe-performance-where-errors-go-down-l</guid>
      <pubDate>Fri, 17 May 2024 06:59:56 GMT</pubDate>
    </item>
    <item>
      <title>方差分析事后 Tukey 的结果显着，而 welch-ANOVA 事后 Dunnett T3 的结果不显着</title>
      <link>https://stats.stackexchange.com/questions/647402/significant-results-from-anova-post-hoc-tukeys-insignificant-with-welch-anova</link>
      <description><![CDATA[我使用事后 Tukey 进行了单向方差分析测试来查看多重比较，并获得了非常显着的结果，但注意到方差分析的 F 值很高。各组中的 SD 不相等，因此我使用事后 Dunnett 的 T3 进行 Welch-ANOVA（以解释不相等的方差）。您期望从值和条形图中显着的一些结果（例如我的最高浓度）尽管与其他显着浓度相比远高于我的最低浓度，但实际上却微不足道。努力理解这是怎么回事？希望有人能给我解释一下，谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/647402/significant-results-from-anova-post-hoc-tukeys-insignificant-with-welch-anova</guid>
      <pubDate>Fri, 17 May 2024 06:58:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么 WinBUGS 中的硬币与积分不同</title>
      <link>https://stats.stackexchange.com/questions/647401/why-is-coin-different-from-poin-in-winbugs</link>
      <description><![CDATA[我有以下 WinBUGS 模型和感兴趣的输出密度。我想了解为什么硬币的密度与点的密度不同。理解这一点将有助于我理解BUGS中的其他事情。
&lt;前&gt;&lt;代码&gt;型号{
    y＜-1
    ############################
    y ~ dbern(theta.true)
    theta.true &lt;- theta[硬币]
    硬币 ~ dcat(p[])
    点 ~ dcat(p[])
    对于（1:3中的i）{
        p[i] &lt;- 1/3；
        θ[i] &lt;- 0.25*i；
        coin.prob[i] &lt;- equals(coin,i);
    }

]]></description>
      <guid>https://stats.stackexchange.com/questions/647401/why-is-coin-different-from-poin-in-winbugs</guid>
      <pubDate>Fri, 17 May 2024 06:54:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么 $\epsilon (X - X')$ 和 $(X - X')$ 具有完全相同的分布？</title>
      <link>https://stats.stackexchange.com/questions/647400/why-epsilon-x-x-and-x-x-have-exactly-the-same-distribution</link>
      <description><![CDATA[设 $\epsilon \in \{-1, 1\}$ 为 Rademacher 随机变量，
$X$ 是一个随机变量，$X&#39;$ 是 $X$。
为什么 $\epsilon (X - X&#39;)$ 和 $(X - X&#39;)$ 有相同的分布？
鉴于 $X-X&#39;$ 围绕 $0$ 对称，直观上这是正确的，但如何证明呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/647400/why-epsilon-x-x-and-x-x-have-exactly-the-same-distribution</guid>
      <pubDate>Fri, 17 May 2024 05:35:50 GMT</pubDate>
    </item>
    <item>
      <title>多状态生存分析</title>
      <link>https://stats.stackexchange.com/questions/647398/multi-state-survival-analysis</link>
      <description><![CDATA[我想知道我的用例是否适合这个问题。我有一群零售消费者，我想对他们的购买间隔进行建模。因为它是一个在线平台，所以我们还可以观察他们购买期间的其他行为，例如浏览、查看优惠等。消费者可以多次购买，我们无法观察他们何时完全不再是消费者。下面是一个可能的状态转换图，基本上您可以从一种状态转换到另一种状态，如果一个状态在另一个状态之后重复，也可能是它本身。

我正在考虑将其建模为一个多状态生存分析问题，可能的事件是购买、浏览、查看优惠......没有明确的死亡事件。由于不同的事件也可能发生多次，因此这也是一个经常出现的问题。这是一种合适的方法吗？它是否能够对不同的事件序列进行建模，或者我是否必须将自动功能纳入其中？任何有关此问题的相关阅读资源也将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/647398/multi-state-survival-analysis</guid>
      <pubDate>Fri, 17 May 2024 02:46:46 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyMC 中的新数据点对后验进行重新采样</title>
      <link>https://stats.stackexchange.com/questions/647397/re-sampling-the-posterior-with-a-new-data-point-in-pymc</link>
      <description><![CDATA[我有一些数据
X = np.array([1.0, 2.0, 3.0, 4.0, 5.0])
y = np.array([0, 1, 0, 1, 1])

我适合模特
以 pm.Model() 作为模型：
    X_shared = pm.Data(“X_data”, X)
    beta_0 = pm.Normal(“beta_0”, mu=0, sigma=1)
    beta_1 = pm.Normal(“beta_1”, mu=0, sigma=1)
    mu = beta_0 + beta_1 * X_shared
    p = pm.math.sigmoid(mu)
    y_obs = pm.Bernoulli(“y_obs”, p=p, 观察=y)
    跟踪 = pm.sample(100)

现在我想根据新的数据点重新采样后验
型号：
    pm.set_data({“X_data”: [1.69]})
    y_new_simulated = pm.sample_posterior_predictive(trace).posterior_predictive.y_obs
    y_new_obs_name = f“y_new_obs_1” # 为伯努利变量创建一个唯一的名称
    y_new_obs = pm.Bernoulli(y_new_obs_name, p=pm.math.sigmoid(beta_0 + beta_1 * 1.69), 观察=y_new.posterior_predictive.y_obs)
    new_trace = pm.sample(100)

但我收到广播错误：
ValueError：不允许运行时广播。

我的目标是尝试找出新数据点 X（并假装我们没有观察到 y 而必须模拟它）通过比较来添加信息旧痕迹和新痕迹]]></description>
      <guid>https://stats.stackexchange.com/questions/647397/re-sampling-the-posterior-with-a-new-data-point-in-pymc</guid>
      <pubDate>Fri, 17 May 2024 02:31:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的 nls() 对非常嘈杂的数据进行非线性回归</title>
      <link>https://stats.stackexchange.com/questions/647394/non-linear-regression-with-very-noisy-data-with-nls-in-r</link>
      <description><![CDATA[我正在尝试将噪声数据拟合到具有两个我想估计的参数的特定模型。不幸的是，模型拟合很糟糕，噪声也增加了。我可以做些什么来改善这种契合度吗？
公式/模型如下所示：
model_form &lt;- as.formula(y ~ 1/((1/i)-(r*x)))
下面我创建了一些数据的示例。 噪声只是随机的附加噪声，也出现在我的真实数据集中（生物起源）。如果没有此噪音，nls() 拟合效果良好，最终估计 r 和 i 足够好。但随着噪声的增加，尽管热图中存在可见的模式，但模型拟合和参数估计很差。
使用示例参数 i 和 r 创建样本数据（这些参数实际上未知，但仅限于特定的已知区间）：
## 创建示例数据
my_i &lt;- 0.5 # i 参数示例
my_r &lt;- 100 # r 参数示例
d &lt;- data.frame(x=c(-rexp(500,rate=10),
                    seq(-1,0,length.out = 500))) %&gt;%
    突变（y=抖动（1/（（1/my_i）-（my_r * x）），1000））
噪声 &lt;- data.frame(x=runif(1000,-1,0),
                    y=runif(1000,0,0.5))
d &lt;-bind_rows(d,噪声)

以下函数使用上面的 model_form 将该数据拟合为 nls。
fitPlot &lt;- 函数（数据）{
    适合 &lt;- nls(model_form,数据,
               开始=列表(r=10,i=0.3))

    fit_r &lt;- 摘要(fit)$coefficients[&quot;r&quot;,1]
fit_i &lt;- 摘要(fit)$系数[“i”,1]

    预测 &lt;- data.frame(x=seq(-1,0,length.out=1000)) %&gt;%
        变异(y=1 / (1/fit_i - fit_r * x))

    p &lt;- ggplot(数据)+
        geom_bin2d(aes(x,y),bins=14)+
        geom_line(数据=预测,aes(x,y))+
        注释（“标签”，x=-0.7，y=0.5，
                 标签=paste0(“r:”,fit_r,”, i:”,fit_i))
    p
}

拟合图(d)


尽管随机添加了噪声，但函数生成的主要模式（靠近 0 和 x 轴）在热图中仍然可见。我希望模型能够很好地适应这个地方。
此时我能做些什么吗？我已经尝试过了

具有可能的 i 和 r 值的网格搜索 = 与 nls 相同的结果
optim具有不同的优化方法，具有最小化SS的功能
nlrob 来自使用不同方法的Robustbase

我在这一点上迷失了，不知何故必须有一种方法来创建一个强大的模型？不知何故，我需要减少对异常值的惩罚，但是怎么做呢？欢迎任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/647394/non-linear-regression-with-very-noisy-data-with-nls-in-r</guid>
      <pubDate>Thu, 16 May 2024 23:02:58 GMT</pubDate>
    </item>
    <item>
      <title>什么统计方法可以评估已知测量误差变量的影响？</title>
      <link>https://stats.stackexchange.com/questions/647368/what-statistical-method-for-assessing-the-effect-of-a-known-measurement-error-va</link>
      <description><![CDATA[我有 95 个受试者的数据集的大量重复测量数据。
这些数据涉及形态学的医学成像测量。
医学成像是一种棘手的数据 - 由于受试者位置的随机差异，在不同日期拍摄的同一身体部位可能看起来完全不同。
因此，我对每张图像进行了额外的测量，以显示（并量化）图像之间身体位置的差异。
这意味着除了形态测量之外，我现在还有2 个明确的“测量误差”测量（我将其称为 MEM）。
我可以假设我所有的形态测量都受到这些已知 MEM 的影响。但还会有其他类型的测量误差（可能是空间误差），我没有（也许不能？）直接量化。
我怀疑某些形态测量比其他测量更容易受到 MEM（和看不见的 MEM）的影响。
在理想的世界中 - 形态测量不会随时间变化 - 它们将保持不变。因此我们可以假设形态的波动很大程度上是由测量误差驱动的。
如果我观察测量值的变化，我会发现 MEM 发生了很大变化。我的形态测量也是如此：

（单个受试者随时间的 7 个观察结果。MEM 是虚线。形态测量是实线。所有值都已标准化）
目前，我正在尝试找出哪种类型的分析可以帮助我找出 MEM 对整体测量误差的贡献。特别是哪些形态测量受 MEM 影响最大。
由于这些误差很大程度上是空间误差，因此随着 3D 空间中位置和方向的变化，不同测量之间可能会发生交互。
我能想到的就是查看某些测量值变化的峰值，看看变化的峰值是否与 MEM 中的峰值相关。
任何人都可以建议一种方法来解决这个问题吗？能否指定 LMER 来探索这个问题？
非常感谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/647368/what-statistical-method-for-assessing-the-effect-of-a-known-measurement-error-va</guid>
      <pubDate>Thu, 16 May 2024 15:42:47 GMT</pubDate>
    </item>
    <item>
      <title>倾向评分匹配后的亚组分析</title>
      <link>https://stats.stackexchange.com/questions/647356/subgroup-analyses-after-propensity-score-matching</link>
      <description><![CDATA[假设倾向得分已经匹配群组。
倾向评分模型中包含的变量之一是性别。
主要cox模型研究两种药物缓解癌症的比较效果。
这是我一直在寻找的主要效果：
coxph(Surv(时间，状态) ~ 药物，数据 = 数据)

现在我想研究一种可能的调节（按性别）。
选项 1：
我可以使用上面的原始队列来调查可能的调节：
coxph(Surv(时间，状态) ~ 药物：性别，数据 = 数据)

因此，我有两个模型：一个用于主效应估计，一个用于调节。\
选项 2：
根据格林＆amp; Stuart (2014)，估计单独的倾向评分模型可以显示出最佳的平衡。
因此，我创建了两个数据集（男性和女性）并分别计算了匹配的倾向得分。
接下来，我组合了两个匹配的数据集并计算：
coxph(Surv(时间，状态) ~ 药物：性别，数据 = 数据)

由于我使用卡尺进行了 1:1 匹配，因此原始数据和组合分层方法确实具有不同的样本量，因为并非每个人都获得了匹配的参考。
问题：

对于选项 1，使用 drug:sex 计算主要效果 drug 的一个模型和可能直接调节的一个模型是否合法？或者我是否需要将两者作为 drug*sex 包含在一个模型中？

对于选项 2，我是否需要计算组合样本中的主效应？或者我是否使用组合数据只是为了调查调节并使用我的原始数据集来产生主要效果？

]]></description>
      <guid>https://stats.stackexchange.com/questions/647356/subgroup-analyses-after-propensity-score-matching</guid>
      <pubDate>Thu, 16 May 2024 13:46:38 GMT</pubDate>
    </item>
    <item>
      <title>当使用人类身高的正态近似值时，两个身高未知但大致相等的人都很高的概率是多少？</title>
      <link>https://stats.stackexchange.com/questions/647354/when-using-normal-approximations-of-human-height-whats-the-probability-two-peo</link>
      <description><![CDATA[基本上，我看到了一张两个身高大致相等的人的照片，并突然想到“他们都很高的可能性有多大？”。这就是我想回答的问题。
我承认我的想法可能犯了错误，但我认为这只是我不知道如何进行最后一步。
我在数学上思考这个问题的方式是，我们可以假设高度的法线，即 $X \sim N(\mu_X,\sigma^2_X), Y \sim N (\mu_Y,\sigma^2_Y)$，因此我的问题是：
$$\mathbb{P}(X = x_1 = Y = y_1 \pm \frac{\epsilon}{2} \space \cap \space x_1 &gt; \mu_X \space \cap \space y_1 &gt; \mu_Y)$$
其中 $\epsilon$ 是一些小的正常数，代表视觉等效的限制，例如如果约翰身高 181 厘米，亨利身高 182 厘米，当你站在一起时，你真的能看出他们的身高不同吗？我认为不是，因此 $\epsilon$。
现在，虽然我怀疑一起拍照的两个人实际上并没有独立的高度，但我可以假设他们是独立的，因此：
$$\mathbb{P}(X = x_1 = Y = y_1 \pm \frac{\epsilon}{2}) \cdot\mathbb{P}(x_1 &gt; ; \mu_X)\cdot \mathbb{P}(y_1 &gt; \mu_Y)$$
我相信最后两个可以简单地计算为 $\mathbb{P}(x_1 &gt; \mu_X) = \mathbb{P}(X &gt; \mu_X)$  = 1 - rnorm(mu, mu, sigma) （使用 R）但我不知道如何做第一个，特别是在 $X = 的情况下Y$，这是如果两个人都是男性或都是女性时我会做出的假设。特别是，起点似乎是这样的：
$$\mathbb{P}(X &gt; Y) =&gt; X - Y \sim N(\mu_X - \mu_Y, \sigma_X^2 - \sigma_Y^2) $$
但当 $X = Y 时，显然会是 $X - Y \sim N(0, 0)$ $，我不知道如何使用。我更不知道如何合并我的 $\epsilon$ 广泛的视觉等价区间。]]></description>
      <guid>https://stats.stackexchange.com/questions/647354/when-using-normal-approximations-of-human-height-whats-the-probability-two-peo</guid>
      <pubDate>Thu, 16 May 2024 13:02:16 GMT</pubDate>
    </item>
    <item>
      <title>动态广义帕累托分布的推导</title>
      <link>https://stats.stackexchange.com/questions/647345/derivation-of-a-dynamical-generalized-pareto-distribution</link>
      <description><![CDATA[我目前正在阅读一篇关于使用峰值阈值法进行资产回报尾部指数估计的硕士论文论文。在本文中，作者介绍了广义帕累托分布的累积分布函数 (1)
$$ G_{\xi,\beta}(x) = 1 - \left(1 + \xi*\frac{x - \mu}{\beta}\right)^ {-1/\xi} if \xi \neq 0 $$ 我理解这一点，但后来作者引入了 GDP 条件 cdf 的重写版本，称为动态 CDF (2)。
$$ G_{t}^{\gamma}(r_{t}|F_{t-1}) = 1 - \left(1 + \frac{r_{t} - \gamma}{\alpha_{t}}\right)^{-\zeta_{t}} $$
我迷失在从（1）到（2）的步骤之间。我不明白他们如何推导出新函数，我不确定他们如何推断 $ 的比率$ \beta*\zeta_{t} = \alpha_{t} $$ 我似乎缺少一些步骤。引用的论文无助于提供更多信息
重写函数的论文摘录
非常感谢任何帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/647345/derivation-of-a-dynamical-generalized-pareto-distribution</guid>
      <pubDate>Thu, 16 May 2024 07:58:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用泊松和高斯族对泊松数据进行 glm 拟合几乎没有差异？</title>
      <link>https://stats.stackexchange.com/questions/647325/why-is-there-little-difference-in-glm-fit-using-poisson-and-gaussian-family-for</link>
      <description><![CDATA[我一直对模拟泊松分布数据的玩具回归问题感到困惑，并希望受过更多统计学教育的人可以帮助我对以下观察结果有一些了解。
使用的库
库(tidyverse)
图书馆（牛区）
图书馆（扫帚）
库（基于模型）
库（参数）
图书馆（ggbeeswarm）

数据生成
我使用 rpois 模拟了两种场景的计数值：

交通事故计数，其中 lambda 与交通量成线性比例。
当 lambda 按交通量指数缩放时的交通事故计数。

# 观察值
n_obs = 10

# 生成日志相关数据
流量 = log(c(1, 2, 4, 7, 10, 15))
日志数据=小标题（
  流量=流量_流量，
  lambda=exp(0.43*体积+0.2)
) %&gt;%
  逐行 %&gt;%
  mutate(accident_counts = list(rpois(n_obs, lambda = lambda))) %&gt;%
  突变（observed_avg_accidents = 平均值（accident_counts））

# 生成线性相关数据
线性数据=小标题（
  流量=流量_流量，
  拉姆达 = 0.43*体积 + 0.2
) %&gt;%
  逐行 %&gt;%
  mutate(accident_counts = list(rpois(n_obs, lambda = lambda))) %&gt;%
  突变（observed_avg_accidents = 平均值（accident_counts））

建模
我为每个数据集拟合了两个 glms。一种使用gaussian族，另一种使用poisson族。我对日志数据使用了“log”链接器，对线性数据使用了“identity”链接器。
# 适合
proc_list = 列表(
  日志=列表（数据=log_data，链接器=“日志”），
  线性=列表（数据=线性_数据，链接器=“身份”）
）
模型 = 地图（proc_list，函数（proc）{
  泊松模型 &lt;- glm(
    事故计数 ~ 数量，
    数据 = proc$data %&gt;% unnest(accident_counts),
    家庭=泊松（链接= proc $链接器），
  ）
  高斯模型 = glm(
    事故计数 ~ 数量，
    数据 = proc$data %&gt;% unnest(accident_counts),
    族=高斯(link=proc$linker),
    开始=c(1, 1)
  ）
  返回（列表（“泊松”= poisson_model，“高斯”= gaussian_model））
})

结果
&lt;代码&gt;&gt; Compare_models(unlist(模型，递归=FALSE))

参数|对数泊松 |对数高斯 |线性泊松|线性高斯
-------------------------------------------------- ----------------------------------------------------------
（拦截）| 0.01（-0.40，0.43）| -0.03 (-0.59, 0.53) | 0.39（0.06，0.73）| 0.43（-0.08，0.94）
卷 | 0.52（0.32，0.72）| 0.54（0.30，0.79）| 0.36（0.13，0.59）| 0.34（0.05、0.62）
-------------------------------------------------- ----------------------------------------------------------
观察| 60| 60| 60| 60

可视化
# 创建可视化网格并预测值
viz_grid = modelbased::visualization_matrix(tibble(volume=traffic_volume)) %&gt;% as_tibble
增强=map_df（unlist（模型，递归= FALSE），函数（.x）{
  增强（.x，newdata = viz_grid，type.predict =“响应”）
}, .id=&quot;型号&quot;)

# 单独的模型和数据标签
增强=增强%&gt;%
  split(“模型”, c(“数据”, “回归”), sep=&quot;\\.&quot;)

p = map_df(proc_list, ~.x$data, .id=&quot;数据&quot;) %&gt;%
  解除嵌套（事故计数）%&gt;%
  ggplot(aes(体积, 事故计数)) +
  # geom_violin(调整=1.5) +
  geom_quasirandom() +
  几何点（
    data=~.x %&gt;% unique(数据、体积、observed_avg_accidents),
    aes（数量，observed_avg_accidents），
    颜色＝“红色”
  ) +
  geom_line(数据=增强，aes(体积，.fitted，颜色=回归)) +
  facet_wrap(~data, labeller=label_both) +
  主题灰色(base_size=16)
p %&gt;% ggsave(file=“temp.pdf”, w=8, h=4)


问题
为什么无论家庭功能如何，拟合基本上没有差异？我故意选择了少量的观察值和相对较小的 lambda 值，希望使用高斯拟合家庭会崩溃。但这并没有发生。如果这里的数据生成过程真的是泊松分布，那么族函数的选择不会影响拟合吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647325/why-is-there-little-difference-in-glm-fit-using-poisson-and-gaussian-family-for</guid>
      <pubDate>Wed, 15 May 2024 23:10:11 GMT</pubDate>
    </item>
    </channel>
</rss>