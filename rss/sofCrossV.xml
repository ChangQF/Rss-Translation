<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 22 Sep 2024 06:21:26 GMT</lastBuildDate>
    <item>
      <title>ARDL-ECM 是否对 STATA 进行因果关系检验？</title>
      <link>https://stats.stackexchange.com/questions/654719/does-an-ardl-ecm-have-a-causality-test-on-stata</link>
      <description><![CDATA[我试图估计不同变量对 FDI 的影响，我发现我应该找到因果关系，通常使用 Granger 或 Wald 检验。
我一直在互联网上搜索，但似乎没有在 STATA 上找到命令，但它仅适用于 VAR/VEC]]></description>
      <guid>https://stats.stackexchange.com/questions/654719/does-an-ardl-ecm-have-a-causality-test-on-stata</guid>
      <pubDate>Sun, 22 Sep 2024 05:49:49 GMT</pubDate>
    </item>
    <item>
      <title>生物统计学作业帮助 - 置信区间/概率</title>
      <link>https://stats.stackexchange.com/questions/654717/biostatistics-homework-help-confidence-intervals-probability</link>
      <description><![CDATA[有人能帮我解决这个问题吗？我很困惑，因为我不知道该如何处理这样的问题？
NHS 正在调查一种旨在降低血液胆固醇水平的新饮食干预措施的有效性。在一项试点研究中，他们的目标是确保参与者的胆固醇水平平均降低至少 0.25 mmol/L，概率最多为 90%。
确定他们需要的最小样本量，以确保他们能够满足此标准。
提示：他们的数据服从正态分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/654717/biostatistics-homework-help-confidence-intervals-probability</guid>
      <pubDate>Sun, 22 Sep 2024 02:44:52 GMT</pubDate>
    </item>
    <item>
      <title>关联卡方检验、特​​征工程和选择书，第 2 章</title>
      <link>https://stats.stackexchange.com/questions/654715/chi-squared-test-of-association-feature-engineering-and-selection-book-chapter</link>
      <description><![CDATA[在 Kuhn &amp; Johnson 的 feat.engineering/stroke-tour 中，有一个列联表，如下所示：

但我尝试自己手动和用计算器计算卡方，结果为 0.9818，p 值约为 0.32。这是书中$p=0.42$的勘误表吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654715/chi-squared-test-of-association-feature-engineering-and-selection-book-chapter</guid>
      <pubDate>Sun, 22 Sep 2024 00:48:22 GMT</pubDate>
    </item>
    <item>
      <title>如何检测是否有人正在使用 WDA_EXCLUDEFROMCAPTURE [关闭]</title>
      <link>https://stats.stackexchange.com/questions/654714/how-to-detect-if-someone-is-using-wda-excludefromcapture</link>
      <description><![CDATA[我想知道您是否可以使用应用程序来检测使用 WDA_EXCLUDEFROMCAPTURE 的任何内容
并且将显示，这是为了竞争性服务器，并检测作弊者在他们不值得时赚钱和诈骗。]]></description>
      <guid>https://stats.stackexchange.com/questions/654714/how-to-detect-if-someone-is-using-wda-excludefromcapture</guid>
      <pubDate>Sun, 22 Sep 2024 00:04:44 GMT</pubDate>
    </item>
    <item>
      <title>一个具有多个预测因子的逻辑回归模型或多个具有一个预测因子的模型？</title>
      <link>https://stats.stackexchange.com/questions/654712/one-logistic-regression-model-w-multiple-predictors-or-multiple-models-with-one</link>
      <description><![CDATA[我认为这是解决我的问题的一个草率方法，甚至可能完全无效，但我正在尝试拟合一个逻辑回归模型，其中有一些空值（NA，因为我在 R 中执行此操作）。空值是由于数据收集不完整造成的，因此我对任何类型的插补方法都非常犹豫，因为在我看来，这（我认为）类似于伪造我的数据。我只好删除具有空值的观察值，但这可能意味着删除很多对一个预测变量有用的观察值，因为它们缺少另一个预测变量的值。
作为一个极其简化的示例，假设我有以下数据集：
data &lt;- data.frame(
&quot;Gender&quot; = c(&quot;Man&quot;, &quot;Woman&quot;, &quot;Woman&quot;, NA, &amp;​​quot;Woman&quot;),
&quot;Race&quot; = c(&quot;White&quot;, &quot;Black&quot;, NA, &amp;​​quot;Black&quot;, &quot;White&quot;),
&quot;State&quot; = c(&quot;Sad&quot;, &quot;Happy&quot;, &quot;Sad&quot;, &quot;Happy&quot;, &quot;Sad&quot;)
)

如果我想看看性别 和 种族 可以预测 州，我的第一个想法是建立一个类似这样的模型：
州 ~ 性别 + 种族

但是，如果我通过删除这些观察值来处理 NAs，我会从 性别 中删除一个有效数据点，从 种族 中删除一个有效数据点，剩下 3 个观察值。
如果我决定建立两个单独的模型，我可能会得到类似这样的结果：
州 ~ 性别
州 ~ 种族

现在，如果我删除 NA 观察值，我仍然有 4 个 性别 观察值和 4 个 种族 观察值，而不是每个 3 个。但从统计学上讲，这是愚蠢的做法吗？将其拆分成两个独立模型会有什么损失？我所失去的比获得的观察结果更重要吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654712/one-logistic-regression-model-w-multiple-predictors-or-multiple-models-with-one</guid>
      <pubDate>Sat, 21 Sep 2024 22:47:47 GMT</pubDate>
    </item>
    <item>
      <title>如何使用条件分位数找到经验分布？</title>
      <link>https://stats.stackexchange.com/questions/654710/how-to-find-empirical-distribution-using-conditional-quantiles</link>
      <description><![CDATA[我已经估算了条件分位数，具体来说是 [0.05, 0.25, 0.50, 0.75, 0.95]。现在我想通过分位数进行插值以获得条件 CDF。问题是我没有最大值和最小值来完全支持我的分布。如何平滑这些边缘以获得完整的 CDF？]]></description>
      <guid>https://stats.stackexchange.com/questions/654710/how-to-find-empirical-distribution-using-conditional-quantiles</guid>
      <pubDate>Sat, 21 Sep 2024 22:16:51 GMT</pubDate>
    </item>
    <item>
      <title>为问题和答案生成上下文</title>
      <link>https://stats.stackexchange.com/questions/654708/generating-context-for-questions-and-answers</link>
      <description><![CDATA[一般问题概述：
我需要微调问答模型，以便从约 5 页的文档中提取问题的答案，但我只有问题和答案的对，没有上下文。
这些文档是非结构化的文本，每个文档包含约 20 个问题的答案 + 一些不重要的文本。所有文档都有非常相似的主题（它们都是数据管理计划）。问题和答案通常至少有一句话长。
问题和答案示例：

问：项目将生成/收集哪些类型和格式的数据？


答：因此，生成的数据类型和格式列表很长，包括但不限于：格式化/未格式化的文本 Mov MP4 二进制 HDF5 Xlsx Jpg VTK PDB PSF PRMTOP XTC PDF PNG EPS DICOM C3D VTK



问：数据的来源是什么？


答：数据来自许多不同的来源。非模拟数据通常用于构建模型，可以源自临床数据管理系统或 DICOM 图像存储。&quot;


查看更多问题此处（不仅仅是这些问题，但都与此类似）。
可用数据
我的数据集由问题和答案组成（大约 1 万对），我需要生成上下文来微调问答模型。
我还有大约 1000 份未标记的文档，每个文档都有自由文本，每个文本包含大约 20 个问题的答案。我的目标是训练模型，以便从此类文档中提取答案（我有一些带标签的文档，将用于评估，但不足以进行训练）。
问题：
如何通过将我的答案作为输入并用类似于我的目标文档的文本围绕它来生成上下文，同时仍然知道答案在哪里。]]></description>
      <guid>https://stats.stackexchange.com/questions/654708/generating-context-for-questions-and-answers</guid>
      <pubDate>Sat, 21 Sep 2024 20:07:09 GMT</pubDate>
    </item>
    <item>
      <title>证明：高斯核作为无限维特征空间中的内积</title>
      <link>https://stats.stackexchange.com/questions/654689/proof-the-gaussian-kernel-as-an-inner-product-in-infinite-dimensional-feature-s</link>
      <description><![CDATA[证明对于正整数 $d $，$ \mathbb{R}^d $ 上的高斯核：
\begin{equation}
k(x, x&#39;) = \exp(-\gamma \|x - x&#39;\|^2) \tag{1}
\end{equation&gt;
对于 $\gamma &gt; 0 $，可以表示为无限维特征空间中的内积。
为此，首先证明如果 $ k&#39; $ 是 $ X $ 上的核，则对于 $ \phi: X \to \mathbb{R} $，成立：
\begin{equation}
k&#39;&#39;(x, x&#39;) = \phi(x)k&#39;(x, x&#39;)\phi(x&#39;) \tag{2}
\end{equation&gt;
也是 $ X$ 上的核。我不太清楚如何展示它，但我认为我应该使用指数幂级数 $exp(x)=\sum_{i=0}^{\infty}\frac{x^i}{i!}$。有人能帮忙吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654689/proof-the-gaussian-kernel-as-an-inner-product-in-infinite-dimensional-feature-s</guid>
      <pubDate>Sat, 21 Sep 2024 09:38:05 GMT</pubDate>
    </item>
    <item>
      <title>关于双变量分布的估计</title>
      <link>https://stats.stackexchange.com/questions/654493/on-estimation-of-bivariate-distribution</link>
      <description><![CDATA[我正在处理一个非负、绝对连续的双变量随机向量，其累积分布函数为$F(x, y)$，我正在尝试使用 Epanechnikov 核来估计$$\int_0^{t_1}F^2(x_1,t_2)dx_1$$，$k(u)=\frac{3}{4}(1-u^2),|u|\leq1$，它的 cdf 定义为$K(z)=\int_0^z k(u)du=\frac{1}{4}(3z-z^3)$。对此的估计定义为
$$\widehat{I}=\frac{1}{n^2h_1^2h_2^2}\int_0^{t_1}\left(\sum_{i=1}^n K\left(\frac{x_1-X_{1i}}{h_1}\right)K\left(\frac{t_2-X_{2i}}{h_2}\right)\right)^2dx_1$$
其中 $K(z)=\int_0^z k(x)dx$ 为 ，$k$ 为核。
更多详情请参见此处。
我在模拟中使用双变量 Gumbel 分布。下面是我的代码，但是我在为双变量数据选择合适的带宽时遇到了困难，我得到的估计值与真实值有显著差异。
library(stats)
library(ks)
n &lt;- 40
lambda1 = 2
lambda2 = 0.5
theta = 0.5

for (i in 1:100) {
X1 &lt;- rexp(n, lambda1)
term=1+lambda1*theta*X1
X2 = rgamma(n, (runif(n) &gt; 1 - theta/term)+ 1,(
lambda2*term)
h1 &lt;- 0.5
h2 &lt;- 0.55
t1 &lt;- 0.2
t2 &lt;- 0.3

epan_kernel_cdf &lt;- function(u) {
0.25 * (3 * u - u^3)
}

积分1 &lt;- sapply(X1, function(Xi) h1 * epan_kernel_cdf((t1 - Xi) / h1))
积分2 &lt;- sapply(X2, function(Yi) h2 * epan_kernel_cdf((t2 - Yi) / h2))

被积函数 &lt;- function(x1) {
kernel_cdf_values &lt;- sapply(X1, function(X1) epan_kernel_cdf((x1 - X1) / h1))
prod_kernel &lt;- kernel_cdf_values * 积分2
sum_kernel &lt;- sum(prod_kernel)
(sum_kernel)^2
}

x_vals &lt;- seq(0, t1, length.out = 10000)
dx &lt;- x_vals[2] - x_vals[1]
sum_approx &lt;- sum(sapply(x_vals, integrand)) * dx
estimated_value &lt;- (1/(n^2*h1^2*h2^2))*sum_approx
true_value &lt;- 0.98

bias[i] &lt;-estimated_value[1] - true_value
MSE[i] &lt;-mean((estimated_value[1] - true_value[1])^2)
}

bias
MSE
bias1 &lt;-mean(bias)
bias1
MSE1 &lt;-mean(MSE)
MSE1

我遇到的一些具体问题面临：

为我的双变量数据选择合适的带宽。
我的估计值与真实值 (0.98) 相差甚远。

如能提供任何关于如何改进带宽选择或我应该在代码中进行的其他调整的见解或建议，我将不胜感激。提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654493/on-estimation-of-bivariate-distribution</guid>
      <pubDate>Tue, 17 Sep 2024 16:55:15 GMT</pubDate>
    </item>
    <item>
      <title>最大对数似然拟合中优化参数的置信区域</title>
      <link>https://stats.stackexchange.com/questions/654427/confidence-regions-of-optimized-parameters-in-maximum-log-likelihood-fits</link>
      <description><![CDATA[我正在使用数值优化算法来最大化对数似然函数，$\mathcal{L}$。对数似然函数具有固定数量的参数，$\{\theta_i\}$。这些参数通过优化算法进行优化，以最大化对数似然函数，从而获得参数$\theta_i$值的最佳估计值。
我知道可以推导或计算$\Delta \mathcal{L}$的一些临界值，这些临界值可用于获取参数$\theta_i$的置信区域。
但是，我不知道如何找到这些信息，或者在哪里可以找到这些信息。
我浏览了Casella和Berger的统计推断，希望找到$\Delta \mathcal{L}$的值表，或者某种计算此类值表的方法。我期望在区间估计一章中找到它，但没有。如果信息在那里，那么我不明白我在读什么，因此它超出了我的理解范围。
有人能指出我正确的方向吗？
以下是一些进一步的信息：

由于$\mathcal{L}$是参数$\theta_i$的函数，通过改变$\theta_i$的值，我们也会改变$\mathcal{L}$的值。
参数$\hat{\theta}_i$的最佳估计值是通过最大化$\mathcal{L}$。
如果我们想要估计与 $\theta_i$ 相关的置信区域，我们可以改变 $\theta_i$ 的其中一个值，直到对数似然函数 $\mathcal{L}$ 的值改变某个临界值 $\Delta \mathcal{L}$。
$\Delta \mathcal{L}$ 的值取决于参数 $i$ 的数量和目标置信水平。
例如，置信度越大，该值越大带。
如果我们想要 99% CL，那么所需的 $\Delta \mathcal{L}$ 值将大于我们估计 95% CL 区域时的值。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654427/confidence-regions-of-optimized-parameters-in-maximum-log-likelihood-fits</guid>
      <pubDate>Mon, 16 Sep 2024 13:03:01 GMT</pubDate>
    </item>
    <item>
      <title>具有随时间变化的协变量（生存）的研究</title>
      <link>https://stats.stackexchange.com/questions/654405/a-study-with-a-time-varying-covariate-survival</link>
      <description><![CDATA[我们正在进行一项研究，定期对患者进行癌症复发检测。每四个月安排一次检查（T0、T4、T8、T12、T16、T20）。
以下数据可能具有适合采用离散时间格式的生存分析的结构。如果不正确，请告诉我。
ID TIME EVENT GENDER 
1 T0 0 M 
1 T4 0 M 
1 T8 0 M 
1 T12 1 M 
2 T0 0 F 
2 T4 1 F 
3 T0 0 M 
3 T4 0 M 
3 T8 1 M 
4 T0 0 F 
4 T4 1 F 

现在我们需要向模型中添加一个随时间变化的协变量，即吸烟。
每次预约时都会询问患者的吸烟习惯。
现在，我想知道当模型中存在因变量协变量时，以下数据结构是否合适。另外，可以使用以下函数：glm(event ~ Time + Gender + smoke, family = binomial(link = cloglog))吗？
 ID TIME EVENT GENDER SMOKE 
1 T0 0 M 0 
1 T4 0 M 1 
1 T8 0 M 1 
1 T12 1 M 1 
2 T0 0 F 0 
2 T4 1 F 1 
3 T0 0 M 0 
3 T4 0 M 0 
3 T8 1 M 0 
4 T0 0 F 0 
4 T4 0 F 0 


第二个问题是：当协变量变化的相对时间和事件时间间隔不一样时，我们还能使用上述公式吗？如果没有，我们如何创建具有适当结构的数据集，以及应该使用哪种统计模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/654405/a-study-with-a-time-varying-covariate-survival</guid>
      <pubDate>Sun, 15 Sep 2024 20:00:50 GMT</pubDate>
    </item>
    <item>
      <title>马丁格尔 $M(t) =N(t)-\int_0^t \lambda(v) Y(v) \,d v$ 的对应滤波是什么？</title>
      <link>https://stats.stackexchange.com/questions/654276/what-is-the-corresponding-filtration-of-the-martingale-mt-nt-int-0t-lam</link>
      <description><![CDATA[我找到了与数量 $M(t) =N(t)-\int_0^t \lambda(v) Y(v) \,d v$相对应的三种不同的过滤表达式：
这是第一个：定义 $N_T(t)=I(T \leq t)$ 和 $Y_T(t) = I\{T\ge t\}$。
\begin{align}
\mathcal{F}_t=\sigma\left\{N_T(u), Y_T\left(u^+\right), Z ; 0 \leq u \leq t\right\}
\end{align&gt;
我在论文Luo, Xu &quot;Doubly robust inference for hazard ratio under informative censoring with machine learning&quot;中找到了它（2022）。 具体来说，在第 4 页的方程 (2) 之后。第 12 页这里 也找到了相同的符号。
这是第二个：定义 $X=\min(T,C)$，以及 $\delta = I(T&lt;C)$。
\begin{align}
\mathcal{F}_t=\sigma\left\{I_{\{X \leq u, \delta=1\}}, I_{\{X \leq u, \delta=0\}}: 0 \leq u \leq t\right\}
\end{align&gt;
我在 Fleming, T.R. and Harrington, D.P. (1991) 一书中找到了它。第 1.3 章 马丁格尔 $M=N-A$ 第 25 页。
这是第三个：
\begin{align}
\mathcal{F}_t=\sigma(I(T \leq u), I(C \leq v): u \leq t, v \leq t)
\end{align
这来自我的生存课讲座，未发布在任何公共网站上。但我可以引用幻灯片

回想一下我们之前介绍的计数过程符号，包括 $N(t), Y(t)$，暂时不包括协变量 $Z$。令 $A(t)=\int_0^t \alpha(u) d u=\int_0^t Y(u) \lambda(u) d u . A(t)$ 称为 $N(t)$ 的补偿器。定义 $\mathcal{F}_t$ 为 $\sigma$-代数（集合的集合）或过滤，表示截至时间 $t$ 的所有信息（历史）。更准确地说，让
$$
\mathcal{F}_t=\sigma(I(T \leq u), I(C \leq v): u \leq t, v \leq t)
$$
然后，可以证明（下一页）
$$
M(t)=N(t)-A(t)
$$
是关于$\mathcal{F}_t$的${\text { 鞅 }}$，即$E\left\{M(t) \mid \mathcal{F}_{t-}\right\}=M(t-)$，或者等效地，$E\left\{d {\left.M(t) \mid \mathcal{F}_{t-}\right\}}=0\right.$，其中 $d M(t)=M(t)-M(t-)$。

第一和第三个过滤由未完全观察到的指标生成，而第二过滤由以 $X$ 和 $\delta$ 形式编写的指标生成，这些指标是可观察的。请问哪种过滤最适合使用？
到目前为止，我们都是在独立审查假设 $T \!\perp\!\!\!\perp C$ 下讨论的。但是，假设$T \not\!\perp\!\!\!\perp C$，最合适的过滤器是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654276/what-is-the-corresponding-filtration-of-the-martingale-mt-nt-int-0t-lam</guid>
      <pubDate>Thu, 12 Sep 2024 16:31:48 GMT</pubDate>
    </item>
    <item>
      <title>距离加权平均值 - 如何处理同一位置的样本</title>
      <link>https://stats.stackexchange.com/questions/654264/distance-weighted-mean-how-to-handle-samples-at-the-same-location</link>
      <description><![CDATA[在 R 中，我正在计算某个区域中多个样本的社区组成差异。为了全面衡量社区的差异，我希望对距离较近的样本赋予比距离较远的样本更大的权重。为此，我有一个包含样本间差异的矩阵：
&gt; dissimilarity_m
1 2
2 0.7258861 
3 0.9378651 0.9253090

以及显示空间距离的矩阵：
&gt; dist_m
1 2
2 0.000000000 
3 0.009437432 0.009437432

但是，我现在正在努力寻找如何最好地计算加权平均值。到目前为止，我已经使用了
dist_mean_weighed &lt;- weighted.mean(dissimilarity_m, w = 1/dist_m)

但我想知道反距离 1/w 是否是一个很好的近似值。此外，如果两个样本位于同一位置且 w = 0（我的所有样本都使用坐标记录，这些坐标不是米级分辨率，因此几个样本的距离为零），这当然不起作用。
R 中是否有更好的近似值或更有用的函数？]]></description>
      <guid>https://stats.stackexchange.com/questions/654264/distance-weighted-mean-how-to-handle-samples-at-the-same-location</guid>
      <pubDate>Thu, 12 Sep 2024 09:41:10 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中进行数据拟合时，如何处理区间数据（具有无限上限）？</title>
      <link>https://stats.stackexchange.com/questions/654300/how-do-i-deal-with-interval-data-having-infinite-upper-limit-when-doing-data-f</link>
      <description><![CDATA[我从一份政府报告中提取了住房建筑面积（​​平方米 (sqm.)）的数据。第一类指建筑面积低于 5 平方米，最后一类指建筑面积为 200 平方米或以上。
鉴于下限和上限有点模糊，我怀疑在进行数据拟合时这些会产生重大影响。实际上，没有零平方米甚至 1 平方米的房屋；此外，人们可以拥有非常宽敞的地板面积，但在给定的数据中，超过 200 平方米的面积限制并没有得到很好的确定。
category &lt;- c(&quot;&lt; 5&quot;, &quot;5 - 9&quot;, &quot;10 - 19&quot;, &quot;20 - 29&quot;, &quot;30 - 49&quot;, 
&quot;50 - 69&quot;, &quot;70 - 89&quot;, &quot;90 - 119&quot;, &quot;120 - 149&quot;, &quot;150 - 199&quot;, 
&quot;&gt; 200&quot;)
count &lt;- c(13676, 48589, 111144, 174631, 203851, 124424, 82277, 
54410, 31702, 16239, 14516)

对于数据拟合，我尝试生成 Cullen 和 Frey 图。我假设我无法处理区间数据，因此我将区间转换为中点。请注意，对于下限和上限，我只是假设它们是 5 平方米。和 200 平方米，虽然我不确定这是否是一个合理的假设，因为概率分布在稍后模拟时会产生误导，即会产生零或接近零的值或远远超过 200 的值。
# 步骤 1：安装必要的软件包
install.packages(&quot;fitdistrplus&quot;)
install.packages(&quot;moments&quot;)

# 步骤 2：加载软件包
library(fitdistrplus)
library(moments)

# 步骤 3：准备数据
类别 &lt;- c(&quot;&lt; 5&quot;, &quot;5 - 9&quot;, &quot;10 - 19&quot;, &quot;20 - 29&quot;, &quot;30 - 49&quot;, 
&quot;50 - 69&quot;, &lt;70 - 89&quot;, &lt;90 - 119&quot;, &lt;120 - 149&quot;, &lt;150 - 199&quot;, 
&gt; 200&quot;)
count &lt;- c(13676, 48589, 111144, 174631, 203851, 124424, 82277, 
54410, 31702, 16239, 14516)

# 使用中点近似
中点 &lt;- c(5, (5+9)/2, (10+19)/2, (20+29)/2, (30+49)/2, (50+69)/2, 
(70+89)/2, (90+119)/2, (120+149)/2, (150+199)/2, 200)

# 根据计数值重复中点
data &lt;- rep(midpoints, count)

# 步骤 4：Cullen 和 Frey 图测试
descdist(data, discrep = FALSE, boot = 1000)

Cullen 和 Frey 图测试表明分布为 Beta。本能地，我认为楼面面积的概率分布最有可能是对数正态的。不确定的上限和下限是否可能影响 Cullen 和 Frey 图的结果？
总结：
当我有区间数据并且想要找到给定数据集的最佳拟合概率分布时，我该如何处理不确定的上限和下限？]]></description>
      <guid>https://stats.stackexchange.com/questions/654300/how-do-i-deal-with-interval-data-having-infinite-upper-limit-when-doing-data-f</guid>
      <pubDate>Thu, 12 Sep 2024 00:26:16 GMT</pubDate>
    </item>
    <item>
      <title>R 调查包与 R 统计包中的 AIC 不同</title>
      <link>https://stats.stackexchange.com/questions/654245/different-aic-in-r-survey-package-vs-r-stats-package</link>
      <description><![CDATA[使用 svyglm()$aic 而不是使用 stats::AIC(model) 时，我得到的 AIC 值不同。我知道这个话题之前已经在这里讨论过了。但是，没有详细解释这种差异 — “仅”建议使用一种方法而不是另一种方法。我怀疑这与这个有关，但不幸的是我的统计数据不够强大，无法完全理解并得出结论。
如果有人能帮我一下，告诉我哪种方法是正确的（如果有的话）以及原因，我将不胜感激。如下例所示，这两种方法可以产生截然不同的结果，甚至改变对哪种模型似乎更合适的解释。
最小示例：
library(survey)

df &lt;- data.frame(
y = c(1.2, 2.4, 3.1, 4.5, 5.6, 6.3, 8.6),
a = c(0.5, 1.3, 1.7, 2.2, 3.1, 3.8, 4.0),
b = c(2.1, 2.7, 3.3, 3.8, 4.2, 4.5, 5.1),
weights = c(0.7, 1.4, 0.9, 1.1, 1.0, 0.8, 1.2)
)

weighted &lt;- svydesign(ids = ~1，数据 = df，权重 = ~weights)

A &lt;- svyglm(y ~ a + b，设计 = 加权，系列 = &quot;gaussian&quot;)

B &lt;- svyglm(y ~ a，设计 = 加权，系列 = &quot;gaussian&quot;)

AIC(A,B)[,2]
[1] 19.29119 17.03959
&gt; c(A$aic,B$aic)
[1] 15.06302 17.45406

我使用的是 R 4.4.1 和 survey 4.4-2]]></description>
      <guid>https://stats.stackexchange.com/questions/654245/different-aic-in-r-survey-package-vs-r-stats-package</guid>
      <pubDate>Wed, 11 Sep 2024 16:18:26 GMT</pubDate>
    </item>
    </channel>
</rss>