<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Sep 2024 06:23:26 GMT</lastBuildDate>
    <item>
      <title>对框内的线段进行采样</title>
      <link>https://stats.stackexchange.com/questions/653827/sampling-line-segments-within-a-box</link>
      <description><![CDATA[我有点不知道从哪里开始解决我遇到的采样问题，所以任何方向都会有所帮助。我本质上想在一个边界正方形内采样长度相同的线段。想象一下把一根针扔进一个方形圆柱体，看看它是如何落地的（一遍又一遍）。
如果正方形的边小于线段的长度，你可以想象分布是X形的。我想了解随着正方形的增长，这种情况是如何变化的。卷积在这里如何应用？
可能相关：https://math.stackexchange.com/questions/4796686/probability-of-line-segments-intersecting-on-a-plane-a-generalization-to-buffo?rq=1]]></description>
      <guid>https://stats.stackexchange.com/questions/653827/sampling-line-segments-within-a-box</guid>
      <pubDate>Wed, 04 Sep 2024 04:29:24 GMT</pubDate>
    </item>
    <item>
      <title>计算高斯混合模型 Fisher 信息矩阵中的期望值</title>
      <link>https://stats.stackexchange.com/questions/653826/computing-expectations-in-fisher-information-matrix-for-gaussian-mixture-models</link>
      <description><![CDATA[考虑一个具有 $K$ 个分量的高斯混合模型 (GMM)：
$p(x) = \sum_{k=1}^K \pi_k \mathcal{N}(x; \mu_k, \Sigma_k)$
其中 $\pi_k$ 为混合系数，$\mu_k$ 为均值向量，$\Sigma_k$ 为协方差矩阵。
职责 $\gamma_k(x)$ 定义为：
$\gamma_k(x) = \frac{\pi_k \mathcal{N}(x; \mu_k, \Sigma_k)}{\sum_{j=1}^K \pi_j \mathcal{N}(x; \mu_j, \Sigma_j)}$
在计算此 GMM 的 Fisher 信息矩阵 (FIM) 时，我遇到了两种类型的期望：

$\mathbb{E}[\gamma_k(x)\gamma_l(x)]$

$\mathbb{E}[\gamma_k(x)\gamma_l(x)f(x)]$，其中 $f(x)$ 可以是类似 $(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k)$ 的表达式


问题：

是否有更精确的表达式或方法来计算 $\mathbb{E}[\gamma_k(x)\gamma_l(x)]$，尤其是当组件分离不充分时？

我该如何计算 $\mathbb{E}[\gamma_k(x)\gamma_l(x)f(x)]$？是否有针对此类术语的分析方法或标准近似值？

文献中是否有成熟的技术可用于在 GMM 的 FIM 背景下处理此类期望？


如能提供任何见解、参考资料或解决策略，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653826/computing-expectations-in-fisher-information-matrix-for-gaussian-mixture-models</guid>
      <pubDate>Wed, 04 Sep 2024 04:13:05 GMT</pubDate>
    </item>
    <item>
      <title>低 $R^2$ 谜题</title>
      <link>https://stats.stackexchange.com/questions/653822/low-r2-puzzle</link>
      <description><![CDATA[我进行了一项实验，并使用数据拟合了一个基本的线性回归模型。上图显示了拟合结果。$R^2$ 非常低，表明几乎没有解释力（调整后的 $R^2$ 甚至更低）。但是，当我绘制每组 x 值的 y 值平均值时，我可以非常清楚地看到线性关系。第 7 组的平均值比第 2 组的平均值高很多。通常我会根据 F 统计量（2.253）、$R^2$、解释变量的 t 统计量等指标来抛弃这种回归。但很明显，它告诉我，组数越高，效果就越好。组平均值的差异很明显，而且随着组数的增加而增加。我有点困惑。是回归分析让我失望了，还是我对结果的解释是错误的？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653822/low-r2-puzzle</guid>
      <pubDate>Wed, 04 Sep 2024 02:50:44 GMT</pubDate>
    </item>
    <item>
      <title>在轮盘赌中出现长序列红色的概率是否低于短序列红色的概率？</title>
      <link>https://stats.stackexchange.com/questions/653816/is-the-rate-of-getting-a-long-sequence-of-reds-in-a-roulette-is-lower-than-short</link>
      <description><![CDATA[在一场无限期的轮盘游戏中，与连续 10 次出现红色相比，连续 100 次出现红色的概率（可能每百万次旋转才出现一次）要小得多，这样说对吗？
如果出现一长串红色的概率会随着序列变长而降低，那么为什么认为在一长串红色之后出现黑色的可能性更大会被视为赌徒谬误？如果 101 次出现红色的序列比 100 次出现红色的序列出现的可能性更小，那么为什么认为当前序列更有可能是 100 次出现红色并因此下一轮旋转将是黑色是错误的？
编辑：
我知道这些都是独立事件，概率没有记忆，因此必须保持不变。我在问，这一事实如何与较长序列出现频率较低的说法相一致。
此外，我并不是说根据大数定律，它应该平衡，因此下一次旋转更有可能是黑色。我是说，我们更有可能处于 100 个红色的序列而不是 101 个红色的序列，因为它发生的频率更高，并且如果更有可能假设现在是较短的序列而不是较长的序列，那么从逻辑上讲，下一次旋转更有可能是黑色不是吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653816/is-the-rate-of-getting-a-long-sequence-of-reds-in-a-roulette-is-lower-than-short</guid>
      <pubDate>Tue, 03 Sep 2024 23:44:05 GMT</pubDate>
    </item>
    <item>
      <title>双尾 F 检验中左侧 Fcrit 值有什么意义？</title>
      <link>https://stats.stackexchange.com/questions/653815/whats-the-point-of-the-left-fcrit-value-in-a-2-tailed-f-test</link>
      <description><![CDATA[在双尾 F 检验中，有 2 个临界值，对吗？一个在右边，一个在左边。
您可以使用 F 表获得右边的 F 值，通过获取其他 F-crit 值的倒数获得左边的 F 值。
但我的问题是，由于大多数 Fcrit 值都大于一，那么大多数 Fcrit 值的倒数难道不会小于一吗？
而且由于 F 统计量在顶部具有较大的方差，这是否意味着它几乎没有可能小于左侧的 Fcrit 值？
所以我的问题是，如果 F 统计量几乎没有可能落在那里，那么左侧 Fcrit 值或下拒绝域的意义何在？
我认为左侧 Fcrit 值有意义的唯一方法是，我们使用 F 统计量的倒数来检查它是否会落入下拒绝域。很像在左尾 F 检验中所做的那样。
但我看过的所有关于双尾 F 检验的视频，一旦证明它不属于上拒绝域，就停止了。我真的觉得我在这里错过了一步。]]></description>
      <guid>https://stats.stackexchange.com/questions/653815/whats-the-point-of-the-left-fcrit-value-in-a-2-tailed-f-test</guid>
      <pubDate>Tue, 03 Sep 2024 23:29:49 GMT</pubDate>
    </item>
    <item>
      <title>为多元分布生成准随机数</title>
      <link>https://stats.stackexchange.com/questions/653814/generate-quasi-random-numbers-for-a-multivariate-distribution</link>
      <description><![CDATA[Sobol 或 Holton 等算法在超立方体 $[0,1]^d$ 中提供准随机数（即，这些数字在均匀分布的意义上“看起来”是随机的，但它们是确定性的）。让 $$x_1, x_2, ..., x_n$$ 成为此类伪随机数的序列。对于特定分布（例如正态分布）的任何分布函数 $F$，$$F^{-1}(x_1), F^{-1}(x_2), ..., F^{-1}(x_n)$$ 都是按照 $F$ 分布的准随机数。
如果 $F$ 是正态分布的分布函数，其均值为 $\mu$，方差-协方差矩阵为 $\Sigma$，则 $$F^{-1}(x_i) = C\Phi^{-1}(x_i) + \mu,$$，其中 $F$ class=&quot;math-container&quot;&gt;$\Phi^{-1}$ 是标准正态函数的分位数函数，该函数逐个分量应用于向量 $x_i$，而 $C$ 是 $\Sigma$ 的 Cholesky 分解。也就是说，我可以轻松生成具有多元正态分布的准随机向量。
现在我想生成具有多元 t 分布的准随机向量。可以通过 $$\sqrt{\frac{k}{\chi}}C\Phi^{-1}(x_i) + \mu,$$ 生成具有多元 t 分布且自由度为 $k$ 的随机向量，其中 $\chi$ 是具有 $k$ 自由度的卡方分布随机变量。通过设置 $\chi = \mathcal X^{-1}_k(y)$，其中 $\mathcal X^{-1}_k$ 表示具有 $k$ 自由度的卡方分布的分位数函数。 $y$ 是什么？嗯，这正是我的问题。问题是，如果我选择 $x_i$ 的第一个元素作为 $y$，那么 $y$ 和 $x_i$ 显然不再独立，这与生成具有多元 t 分布的随机数的算法相矛盾。当然，我可以随机选择一个 $i$ 和一个 $j$（组件），但这样我就可以首先生成随机数，而这并不是我想要的（这个问题是重要性抽样集成问题的一部分）。一个显而易见的解决方案是直接计算$F^{-1}(x_i)$。但是，$F^{-1}$没有封闭形式，因此很难近似。
还有其他解决方案可以帮助我实现我想要的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653814/generate-quasi-random-numbers-for-a-multivariate-distribution</guid>
      <pubDate>Tue, 03 Sep 2024 22:36:46 GMT</pubDate>
    </item>
    <item>
      <title>当尝试找到离散数据的四分位数时，我们是否四舍五入到最接近的整数？</title>
      <link>https://stats.stackexchange.com/questions/653812/when-trying-to-find-the-quartiles-for-discrete-data-do-we-round-to-the-nearest</link>
      <description><![CDATA[我有 2 个案例：
首先，我想找到集合数据的第一个四分位数：1,2,3,4,5。
通常我们计算四分位数如下：
现在 $Q_1 = \frac{2+1}{2} = 1.5$。
但他们从未说明它是连续的（即数据是身高、体重等的集合）还是离散的（即人数、进球数等）
但假设 他们确实说明它是离散的，我们是保留 $Q_1 = 1.5$ 不变，还是四舍五入到2？
第二
当尝试找到分组离散数据的四分位数时，我们是否要四舍五入到最接近的整数？
我找不到一个明确的答案，即我们是否对分组离散数据进行四舍五入（当使用累积频率图查找四分位数时）
示例：前 16 天每天编程时收到的错误数记录在频率表中。
（此数据的示例可以是：0,1,1,8,7,9, 10,11,11,11,19,15, 21,25,29,35）
（y 轴为 c.频率，x 轴为错误）
$Q_1 = 6.5$，我们四舍五入到 7，还是保留 6.5？

如果您能就这个问题提供任何见解，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653812/when-trying-to-find-the-quartiles-for-discrete-data-do-we-round-to-the-nearest</guid>
      <pubDate>Tue, 03 Sep 2024 21:41:09 GMT</pubDate>
    </item>
    <item>
      <title>非中心卡方分布的下尾界</title>
      <link>https://stats.stackexchange.com/questions/653811/lower-tail-bound-for-noncentral-chi-squared-distribution</link>
      <description><![CDATA[非中心卡方随机变量 $Z$ 的形式为
$$
Z = \sum_{i=1}^k X_i^2
$$
其中 $(X_1, X_2, \ldots, X_i, \ldots, X_k)$ 是 $k$ 独立的，正态分布，均值为 $\mu_i$，方差为 1。
我正在寻找 $Z$ 的下尾界，也就是说，我想证明
$$
P(|Z - \mathbb{E}[Z]| &gt; t|) \geq ce^{-c&#39; t^2}
$$
其中 $c, c&#39;&gt;0$ 是依赖于 $k$ 和 $\mu_i$ 的常数。]]></description>
      <guid>https://stats.stackexchange.com/questions/653811/lower-tail-bound-for-noncentral-chi-squared-distribution</guid>
      <pubDate>Tue, 03 Sep 2024 21:32:16 GMT</pubDate>
    </item>
    <item>
      <title>如何计算标量随机变量和向量随机变量之间的互信息？</title>
      <link>https://stats.stackexchange.com/questions/653810/how-to-compute-mutual-information-between-a-scalar-random-variable-and-a-vector</link>
      <description><![CDATA[我有一个向量随机变量 $X = (x_1, x_2... x_n)$，其中每个 $x_i$ 都有一个离散值。我还有一个离散标量随机变量 $Y = y$。两者之间的相互信息有定义吗？如果是，我该如何计算两者之间的相互信息？如果没有，是否有其他针对我的情况定义的度量标准，并且可以类似地应用于相互信息？]]></description>
      <guid>https://stats.stackexchange.com/questions/653810/how-to-compute-mutual-information-between-a-scalar-random-variable-and-a-vector</guid>
      <pubDate>Tue, 03 Sep 2024 21:22:25 GMT</pubDate>
    </item>
    <item>
      <title>从偏斜分布中均匀抽取</title>
      <link>https://stats.stackexchange.com/questions/653780/drawing-uniformly-from-a-skewed-distribution</link>
      <description><![CDATA[是否有方法可以从倾斜的总体中抽取样本，使样本均匀分布？
例如，如果我想显示身高和工资之间的相关性，但总体中身材矮小的人居多，则热图将显得倾斜，不会提供任何信息。
这是一种不好的做法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653780/drawing-uniformly-from-a-skewed-distribution</guid>
      <pubDate>Tue, 03 Sep 2024 04:12:16 GMT</pubDate>
    </item>
    <item>
      <title>如何确定双差分设计中未治疗组的治疗时间</title>
      <link>https://stats.stackexchange.com/questions/653633/how-to-determine-the-treatment-time-for-untreated-in-difference-in-differences-d</link>
      <description><![CDATA[我正在使用差异-差异 (DiD) 设计估计治疗启动对健康结果的影响。时间线是相对于治疗日期而不是日历时间定义的。对于治疗组，索引时间 (t=0) 是每个人开始治疗的日期，治疗前期最多为 3 年，治疗后期最多为治疗后 3 年。
我的挑战是确定对照组（未开始治疗的人）的伪治疗日期，以类似地定义他们的治疗前期和治疗后期。
我正在考虑根据治疗组中治疗启动日期的分布随机为对照组分配伪治疗日期。具体来说，我计划根据关键变量对参与者进行分层，并在每个层内，从治疗组中观察到的诊断和治疗开始之间的持续时间进行替换抽样，为该层的对照组分配一个伪治疗日期。
我的问题是：

有没有更好的方法来分配伪治疗日期？
如果这种方法有效，我如何计算由于对照组伪治疗日期的随机性而导致的不确定性？通过改变这些日期进行敏感性分析是否足够？
是否有任何参考文献或研究讨论过这种方法或类似的问题？我在术语方面遇到困难，希望得到有关寻找什么的指导。

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653633/how-to-determine-the-treatment-time-for-untreated-in-difference-in-differences-d</guid>
      <pubDate>Fri, 30 Aug 2024 16:12:41 GMT</pubDate>
    </item>
    <item>
      <title>混合因子分析仪：似然函数的正确表达？</title>
      <link>https://stats.stackexchange.com/questions/652926/mixture-of-factor-analyzers-correct-expression-for-likelihood-function</link>
      <description><![CDATA[我正在阅读这些笔记关于混合因子分析器，其中描述了以下生成模型：

数据$x$的条件分布（在第 3 节，方程 9）表示为：
$$
P(x \mid z, \omega_j) = \mathcal{N}(\mu_j+\Lambda_j z, \Psi)
$$
其中 $\omega_j$ 表示 $j$ 个因子分析器（或者混合成分，如果我们可以这样称呼它）的索引，并且 $z \mid \omega_j \sim \mathcal{N}(0,I)$。
我的问题是：我说 $x \mid \omega_j \sim \mathcal{N}(\mu_j, \Lambda_j \Lambda_j^\top + \Psi)$ 是否正确？如果我想找到最有可能生成 $x$ 的混合成分，我会最大化以下函数：
$$
L(\omega_j) = P(x \mid \omega_j) = \mathcal{N}(x ; \mu_j, \Lambda_j \Lambda_j^\top+ \Psi) 
$$
对吗？
如果正确，为什么 $P(\omega_j)$ 在这个似然函数中不重要？
这个表达式看起来很像高斯混合模型中的后验推断，即找到每个聚类对给定数据的“责任”。当然，除了在这种情况下，协方差矩阵具有稀疏结构，并且我正在寻找最大似然估计量（我想？）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652926/mixture-of-factor-analyzers-correct-expression-for-likelihood-function</guid>
      <pubDate>Fri, 16 Aug 2024 11:53:45 GMT</pubDate>
    </item>
    <item>
      <title>是否存在基于最大概率的决策树杂质度量？</title>
      <link>https://stats.stackexchange.com/questions/618457/is-there-a-decision-tree-impurity-metric-based-on-maximum-of-probabilities</link>
      <description><![CDATA[我试图理解决策树学习中的杂质指标，特别是基尼杂质。对基尼杂质的假设之一提出质疑让我想到了另一种杂质测量方法，这对我来说更有意义，但我在网上找不到太多关于它的信息。
假设我们有一个分类问题，有 $ K $ 个类。为了决定根据哪个属性进行拆分，我们假装已经完成了拆分，并对子节点的杂质测量结果进行加权求和。我们对每个属性重复此操作，并选择使加权和最小化的属性。
假设子节点处类的相对频率为 $ p_1, \dots, p_K $。那么子节点的基尼不纯度为 $ 1 - \sum_{i=1}^{K} p_i^2 $。我对此的合理解释是，如果我们根据概率分布随机地为子节点分配一个类，那么基尼系数就是该节点上新的随机示例被错误分类的概率。
但是我们为什么要随机分配节点的类别呢？当然，最好的选择是分配该节点上相对频率最高的类别。那么，新的随机示例被错误分类的概率为 $ 1 - \max_{i=1}^{K} p_i $。这给出了一种新的杂质类型。
我遇到了一种称为 Tsallis 熵的东西，它有一个参数 $ q $。在极限 $ q \rightarrow 1 $ 下，Tsallis 熵收敛到 Shannon 熵。对于 $ q = 2 $，它等于基尼不纯度。上面定义的新不纯度与极限 $ q \rightarrow \infty $ 有关。
是否有任何“明显”的理论原因可以解释为什么这种基于最大值的不纯度比主流的 Shannon 熵和基尼不纯度更差？还是只是因为其他不纯度是先发明的，并且在实践中表现良好，所以没有必要寻找其他东西？]]></description>
      <guid>https://stats.stackexchange.com/questions/618457/is-there-a-decision-tree-impurity-metric-based-on-maximum-of-probabilities</guid>
      <pubDate>Sun, 11 Jun 2023 10:11:04 GMT</pubDate>
    </item>
    <item>
      <title>使用两个单侧 t 检验 (TOST) 的置信水平和 alpha</title>
      <link>https://stats.stackexchange.com/questions/587079/confidence-level-and-alpha-with-two-one-sided-t-tests-tost</link>
      <description><![CDATA[我正在做一项非劣效性研究：两组完成一项测试（可能得分为 0-30 分）。我已经有了 B 组的测试结果。我想使用两个单侧 t 检验 (TOST) 调查 A 组的表现是否不逊于 B 组。
我选择了 alpha=5% 和 95% CI。要获得这个，使用 TOST，我必须指定 90% CI / alpha=10%。评估非劣效性时，我只会查看较低的 CI，因此，我的双侧 90% CI 将对应于单侧 95%（和 alpha=5%）。
我的问题是：1) 这是否正确理解？如果是：2) 我该如何正确地表述它？我最初的想法是这样的：“双侧 90% CI，alpha=0.10，对应于单侧 95%CI，alpha=0.05）。
感谢您的时间。]]></description>
      <guid>https://stats.stackexchange.com/questions/587079/confidence-level-and-alpha-with-two-one-sided-t-tests-tost</guid>
      <pubDate>Mon, 29 Aug 2022 09:42:52 GMT</pubDate>
    </item>
    <item>
      <title>按变量主题提取 PCA，而不是为整个数据集提取 PCA</title>
      <link>https://stats.stackexchange.com/questions/521146/extracting-pca-by-variable-themes-instead-of-extracting-pca-for-the-whole-datase</link>
      <description><![CDATA[我正在使用一个包含超过 4,000 个数值变量和 300,000 个观测值的大型数据集。我想使用 PCA 来降低它的维度，但我无法将我的数据集读入 R，因为我没有足够的内存。这些变量按主题分开，例如家庭、人员、参考人员等。如果我按主题提取数值变量的 PCA 并将其用于机器学习模型进行预测，而不是提取整个数据集的 PCA，这在理论上是否错误？]]></description>
      <guid>https://stats.stackexchange.com/questions/521146/extracting-pca-by-variable-themes-instead-of-extracting-pca-for-the-whole-datase</guid>
      <pubDate>Fri, 23 Apr 2021 15:07:24 GMT</pubDate>
    </item>
    </channel>
</rss>