<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 01 Feb 2024 21:12:16 GMT</lastBuildDate>
    <item>
      <title>如何将拉普拉斯分布表示为指数分布和正态分布的混合[重复]</title>
      <link>https://stats.stackexchange.com/questions/638348/how-to-express-a-laplace-distribution-as-a-mixture-of-an-exponential-and-normal</link>
      <description><![CDATA[我在不同的贝叶斯论文中看到，重写拉普拉斯分布的常见技巧是利用该分布可以表示为指数分布和高斯分布的混合这一事实。虽然此结果用于贝叶斯套索论文 (https://people.eecs.berkeley.edu/~jordan/courses/260-spring09/other-readings/park-casella.pdf）我很难掌握一般结果。作者提到了 Andrews 和 Mallows 1974 年的原始论文。我想使用这个结果来计算变分贝叶斯上下文中的一些最优分布，但我坚持分布中出现的绝对值。我已经在这里发布了一个问题，到目前为止没有答案： 计算贝叶斯图形套索模型中协方差参数的最佳变分分布
欢迎任何帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/638348/how-to-express-a-laplace-distribution-as-a-mixture-of-an-exponential-and-normal</guid>
      <pubDate>Thu, 01 Feb 2024 21:07:06 GMT</pubDate>
    </item>
    <item>
      <title>确认点过程模型的有效性</title>
      <link>https://stats.stackexchange.com/questions/638347/confirming-the-validity-of-a-point-process-model</link>
      <description><![CDATA[我有一个关于我为生物点模式生成的点过程模型的问题，该模型在不同尺度上表现出排斥和吸引力。我对该模型的目标是生成模拟点模式，然后将其与其他组的模拟模式一起用于组间假设检验。
我已经将分层盖尔点过程模型拟合到数据中，以尝试捕获这些交互，但我不确定我是否正确解释了模型拟合，并希望深入了解模型是否合理地拟合数据我的目的。我对点形态分析还是个新手，所以确认非常有帮助。我在下面附上了几张诊断图以供参考 - 看起来原始残差总和接近于零 [-.1512]，相对拟合强度与实际强度的范围接近 1 [0.509, 1.17] 并且 qqplot，Gres和 Kres 图在 100 次模拟的 95% 置信区间内 [见下文]。我唯一担心的是 G 残差函数在 r 范围约 2-3um 处有一些非常接近 95% 带的偏差，并且在大 r 距离处 K 残差图有一些偏差，尽管它仍在范围内置信带。我试图通过改变参数和尝试不同的混合模型来纠正这个问题，但收效甚微。我是否正确解释了该模型与数据的拟合程度？



]]></description>
      <guid>https://stats.stackexchange.com/questions/638347/confirming-the-validity-of-a-point-process-model</guid>
      <pubDate>Thu, 01 Feb 2024 20:49:39 GMT</pubDate>
    </item>
    <item>
      <title>关于加速我的自定义神经网络的提示？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638345/tips-on-speeding-up-my-custom-neural-net</link>
      <description><![CDATA[我构建了一个动态大小的神经网络框架，用于多类分类——只是为了加强我对深层网络的理解。我正在训练和预测我的网络来对 MNIST 数字进行分类——从我在网上看到的情况来看，这应该不是一项太难的任务。但即使经过一两个小时的训练，它在验证集上达到的最高准确度也约为 50%。
我在最后一层使用带有 softmax 的 sigmoid 激活，并使用带有反向传播的批量 GD 来计算梯度并逐步迈向最小值。我已经检查了几次反向传播的数学，这对我来说似乎是正确的，但仍然需要相当长的时间来训练相当低的精度。如果有人对我如何加速训练或指出代码中的任何错误有任何建议，我将不胜感激。
我在下面包含了我的代码片段：
主要代码：
data = pd.read_csv(&#39;data/mnist.csv&#39;)

网络 = 神经网络(2, [20, 10], 784)

train_data，test_data = train_test_split（数据，test_size = 0.2，random_state = 42）

network.stochasticGD（train_data，batch_size = 1，max_iter = 10000）

测试 = test_data.to_numpy()[:, :300]
print(“准确度：”, 100 * network.getAccuracy(test_data.to_numpy()))


反向传播函数：
 def cross_entropy_grad(self, ypred, y):
        返回 ypred - y # 10 x b
    
    def backProp(self, ypred, y_one_hot):
        
        错误 = self.cross_entropy_grad(ypred, y_one_hot) # 10 x b
        
        对于 enumerate(self.layers[::-1]) 中的 i、l：
            如果我！= 0：
                错误 = 错误 * l.deriv(l.z)
            错误 = l.backProp(错误, self.alpha)

Layer.backprop方法：
 def backProp(self, dz, alpha): # 节点 x 批次
 
        dW = np.dot(dz, self.lastx.transpose()) / self.size
        db = np.sum(dz, 1).reshape(self.size, 1) / self.size
        
        dx = np.dot(self.weights.transpose(), dz) #输入x批次
        
        self.weights = self.weights - alpha * dW
        self.b = self.b - alpha * db
        
        返回dx


Layer.forward 道具方法：
 def frontProp(self, x):
        
        self.lastx = x
        
        self.one_vector = np.ones(shape=(1, len(x[0]))) # 1 x 输入大小
        
        # 节点 x 批量大小
        self.z = np.dot(self.weights, x) + self.b.dot(self.one_vector)
        
        如果 np.any(np.isnan(self.z)) 或 np.any(np.isinf(self.z))：
            打印（自我.z）
            raise ValueError(“Z 计算”)
        
        self.a = self.activ(self.z)
        

批量GD方法：
 def stochasticGD(self, train_data, max_iter = 100, batch_size = 3):
        
        train_arr = train_data.to_numpy()
        
        
        对于范围内的历元（max_iter）：
            
            # 如果纪元% self.updateRate == 0:
            # self.updateVarRate(纪元)
                
            批次索引 = []
            
            对于范围内的 i（batch_size）：
                batch_indx.append(random.randint(0, len(train_data) - 1))
                
            x_train = []
            y_train = []
            
            对于batch_indx中的i：
                数据 = train_arr[i]
                y_val = 数据[0]
                数据 = np.delete(数据, 0)
                
                                
                y_one_hot = np.zeros(10)
                y_one_hot[y_val] = 1
                
                y_train.append(y_one_hot)
                x_train.append(数据)
                
            x_train = np.array(x_train) # 784 x b
            y_train = np.array(y_train) # b x 10
            
            y_train = y_train.transpose() # 10 x b

                                    
            输出 = self.forwardProp(x_train)
            self.backProp(输出, y_train)
            

                
            
            如果纪元 % 1 == 0:
                print(&#39;纪元:&#39;, 纪元)
                print(&quot;准确率：&quot;, 100 * self.getAccuracy(train_arr))
                print(&quot;利率：&quot;, self.varRate)
            #print(np.sum(输出，轴=0))

]]></description>
      <guid>https://stats.stackexchange.com/questions/638345/tips-on-speeding-up-my-custom-neural-net</guid>
      <pubDate>Thu, 01 Feb 2024 19:43:12 GMT</pubDate>
    </item>
    <item>
      <title>目标函数的连续性</title>
      <link>https://stats.stackexchange.com/questions/638344/continuity-of-objective-function</link>
      <description><![CDATA[例如，在 GARCH(1,1) 时间序列中，我们将有一个结构
$$X_t=\epsilon_t\sigma_t$$
其中 $\epsilon_t,t\in\mathbb{Z}$ 是白噪声，并且
$$\sigma_t^2=\omega+\alpha X_t^2+\beta \sigma_{t-1}$$
对于 $\omega、\alpha、\beta&gt;0$、$\beta&lt;1$。通过参数假设，我们将得到一个函数
$$\sigma^2_t(\theta)=\omega+\alpha X_t^2+\beta \sigma^2_{t-1}$$ 作为目标函数，对于 $\theta=(\omega,\alpha, \beta)$，$\theta$ 应该位于 $\mathbb{R}^3$ 中的紧凑集合中，这保证 $\omega, \ alpha, \beta&gt;0$, $\beta&lt;1$..
设 $X_t$ 具有小于 1 的有限矩，但具有无限均值。我的问题是，我们如何证明 $\sigma_t$ 在 $\theta$？我还没有找到任何关于这个问题的讨论，好像它是那么明显。 $\sigma_t$ 是一些随机变量的无限和，即
$$\sigma^2_t(\theta)=\sum_{j=0}^\infty\beta^j(\omega+\alpha X_{t-j}^2)$$&lt; /跨度&gt;
如果我理解正确的话，我可以用主导收敛定理来证明连续性。不幸的是，GARCH 级数的第一个矩并不总是存在，因此很难找到可积函数 $g(X_t,X_{t-1},...)$&lt; /span&gt; 为所有 $j$&lt; 绑定 $\beta^j(\omega+\alpha X_t^2)$ /跨度&gt;。但根据马尔可夫不等式，如果 $X_t$ 具有正矩，则该和确实收敛。那么在这种情况下这个总和应该是连续的吗？有人可以给我提示来显示它是连续还是不连续吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638344/continuity-of-objective-function</guid>
      <pubDate>Thu, 01 Feb 2024 19:38:55 GMT</pubDate>
    </item>
    <item>
      <title>在 GAMM 中保持“低”基础维度的含义</title>
      <link>https://stats.stackexchange.com/questions/638343/implications-of-keeping-a-low-basis-dimension-in-gamm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/638343/implications-of-keeping-a-low-basis-dimension-in-gamm</guid>
      <pubDate>Thu, 01 Feb 2024 19:31:15 GMT</pubDate>
    </item>
    <item>
      <title>确定两家公司之间的默认相关性值</title>
      <link>https://stats.stackexchange.com/questions/638342/determining-values-for-default-correlation-between-two-companies</link>
      <description><![CDATA[我是一名大学统计学本科二年级学生，正在为拉丁美洲的一家银行 IDB 从事一个现实生活项目。不过这个项目确实超出了我的水平，我需要一些帮助。
正如标题所示，我需要确定拉丁美洲任意两家公司之间的默认相关系数值，但我已经研究了一段时间，但不知道从哪里开始。
这些是要求：

基于经验数据的方法。

该方法应足够详细，以便第三方在很少监督的情况下可以复制。

数据输入应来自公开来源。

计算机代码应使用开源编程语言（最好是 R）生成

最终交付成果应包括：方法说明以及详细步骤、数据文件和程序代码脚本。

最终相关性估计值应具有可接受的统计显着性水平。


我将使用的数据将是基本数据，例如股本回报率或信用评级，我可以在雅虎财经上找到此类数据。
到目前为止，默顿模型看起来很有前途，我喜欢使用 Copulas 和其他技术的外观 - 但对于我的专业知识来说，它们看起来太复杂了。目前还有许多其他模型可以做到这一点，例如 Credit+ 或 CreditMetrics，但这些都是非常复杂的行业标准。
任何建议都会非常有帮助。我只是想要一种强大且不一定复杂的方法。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/638342/determining-values-for-default-correlation-between-two-companies</guid>
      <pubDate>Thu, 01 Feb 2024 19:13:42 GMT</pubDate>
    </item>
    <item>
      <title>MCMC样本的众数是否等于后验的MAP？</title>
      <link>https://stats.stackexchange.com/questions/638341/does-the-mode-of-mcmc-samples-equal-the-map-of-the-posterior</link>
      <description><![CDATA[如果我有来自后验的数百万个 MCMC 样本，这些样本中最常见的值（即这些样本的直方图的峰值）至少在原则上应该始终等于最大后验（MAP）估计通过优化得到？
换句话说，样本模式和最大后验是两种目标相同数量的方法，还是在某些情况下它们可能不同（是否取决于采样的属性）例如算法）？]]></description>
      <guid>https://stats.stackexchange.com/questions/638341/does-the-mode-of-mcmc-samples-equal-the-map-of-the-posterior</guid>
      <pubDate>Thu, 01 Feb 2024 19:01:03 GMT</pubDate>
    </item>
    <item>
      <title>使用精确匹配时，是否建议进行治疗-协变量交互来估计平均治疗效果？</title>
      <link>https://stats.stackexchange.com/questions/638339/is-it-adviced-to-do-treatment-covariate-interactions-to-estimate-the-average-tre</link>
      <description><![CDATA[我使用的方法与 MatchIt 包中的方法完全相同。在 MatchIt 的小插图中，建议运行治疗-协变量交互作用，以解释协变量之间的治疗异质性。我对此有两个问题，

我认为这也建议用于精确匹配，而不仅仅是在未完美实现平衡时？

就我而言，我使用匹配是为了利用跨国和横截面数据使来自两个国家群体的移民更具可比性。为了确保控制单位在与治疗单位相同的东道国和时间接受采访，除了几个协变量之外，我还匹配了东道国和年份。当使用治疗-协变量相互作用来解释效果异质性时，这些相互作用是否应该排除国家和时间，因为它们在技术上不是治疗前的，在这种情况下是迁移前的任何东西？


提前致谢！
库(MatchIt)

  matobj_list &lt;- matchit(治疗 ~ a + b+ c + d + 东道国 + 年，
                                数据= df_mat，方法=“精确”）

  matched.dat &lt;- match.data(matobj_list, data = df_mat)

  ## 匹配后的估计
  # 所有协变量交互作用
  lm(y ~ 治疗 *(a + b + c + d + 东道国 + 年份), 数据 = 匹配的.dat, 权重 = 权重)

  ＃＃ 或者
  lm(y ~ 治疗 *(a + b + c + d) + 东道国 + 年份，数据 =matched.dat，权重 = 权重）
 
]]></description>
      <guid>https://stats.stackexchange.com/questions/638339/is-it-adviced-to-do-treatment-covariate-interactions-to-estimate-the-average-tre</guid>
      <pubDate>Thu, 01 Feb 2024 18:37:24 GMT</pubDate>
    </item>
    <item>
      <title>均匀分布矩法</title>
      <link>https://stats.stackexchange.com/questions/638337/method-of-moments-of-uniform-distribution</link>
      <description><![CDATA[设 $x_1=2, x_2 = 1, x_3 = \sqrt5, x_4 = \sqrt2$ 为来自 a 的大小为 4 的随机样本的观测值均匀分布$U(-\theta, \theta)$，其中$\theta&gt;0$。那么$\theta$的矩估计方法是？
a) 1
b) 2
c) 3
d) 4
我处理这个问题的方式是：
moment的第一种方法是 $\bar{X}$ = $\sum X_i/n$ = ($2+1+\sqrt5+\sqrt2)/4 = 1.66$。
$U(-\theta, \theta)$ 的期望值 = ($-\theta+\theta)/2 = 0$。我无法进一步解释。
请帮助我。]]></description>
      <guid>https://stats.stackexchange.com/questions/638337/method-of-moments-of-uniform-distribution</guid>
      <pubDate>Thu, 01 Feb 2024 18:34:22 GMT</pubDate>
    </item>
    <item>
      <title>比较泊松回归的结果</title>
      <link>https://stats.stackexchange.com/questions/638334/comparing-results-from-poisson-regressions</link>
      <description><![CDATA[我有一个数据集，其中包含计数数据（y 变量）、一个感兴趣的主要变量（表示为 x_1 的因子）和几个我希望控制的变量（表示为 x_i 的因子和数字）。
假设 y 是体育场内的座位数。假设这个体育场有三层座位 - 低价位（多）、中价位（少）和高价位（少）。
与我正在撰写的论文类似的论文在同一组 x 变量上运行了 4 个独立的泊松回归，其中 y 分别为#所有座位、#低价座位、#中价座位、#高价座位，以及正在比较每个模型中的 x_1 系数，以测试其对低、中、高价座位数量的影响。 （座位总数等于低、中、高座位数之和。）
我想知道这是否有两个可能的问题？

回归均使用原始座位数，而不是每个部分的座位数除以座位数。这是错误的吗？
以这种方式使用 4 个单独的回归是否合理，或者是否有更合理的方法？

由于这是一个理论问题，我认为（希望）不提供数据也可以。]]></description>
      <guid>https://stats.stackexchange.com/questions/638334/comparing-results-from-poisson-regressions</guid>
      <pubDate>Thu, 01 Feb 2024 18:16:14 GMT</pubDate>
    </item>
    <item>
      <title>具有词嵌入和余弦相似度的局部敏感哈希 (LSH)</title>
      <link>https://stats.stackexchange.com/questions/638333/locality-sensitive-hashing-lsh-with-word-embeddings-and-cosine-similarity</link>
      <description><![CDATA[我想问一下LSH算法结合Word Embeddings和Cosine Comparison来识别相似文档的方法。
首先，我对我的句子进行标记以创建标记列表。然后，我应用预先训练的 GloVe 模型来生成每个令牌的嵌入。如果一个句子有 5 个单词，那么我将有 5 *(1,300) 个嵌入向量，其中 300 是嵌入向量的大小。为了缩小每个句子的范围，我通过取mean()值来平均嵌入。因此 (5,300) 向量变为 (1,300) 嵌入向量。
有了每个句子的嵌入，我应用 sklearn.manifold.LocallyLinearEmbedding 来查找嵌入的非线性 PCA 分量。然后，我将缩小尺寸的嵌入输入到高斯随机投影仪。 随机预测是该方法的起点。
根据这些随机投影，我仅保留正值 (&gt;0)，然后创建哈希桶。每个存储桶都是一个字符串表示形式，例如“1001”、“0001”等。每个文档都属于一个存储桶。
现在是棘手的部分。每次有新文档出现时，我都会重新应用上述步骤将其分配到哈希桶中。该存储桶内的文档被视为其邻居。我想计算这些邻居的cosine_similarity()（新文档和现有文档之间）；如果相似度 &gt; 0.9，则新文档是实现此相似度的文档的副本。
我使用低维词嵌入计算 cosine_similarity（LocallyLinearEmbedding 算法的结果）。但是，我不确定这是否是比较两个文档的正确输入。如果不是，那么还有什么合适的输入可以在新文档与其同一哈希桶内的邻居之间生成有意义的余弦相似度？]]></description>
      <guid>https://stats.stackexchange.com/questions/638333/locality-sensitive-hashing-lsh-with-word-embeddings-and-cosine-similarity</guid>
      <pubDate>Thu, 01 Feb 2024 18:05:38 GMT</pubDate>
    </item>
    <item>
      <title>区分奇怪的人群</title>
      <link>https://stats.stackexchange.com/questions/638332/distinguishing-the-odd-population-out</link>
      <description><![CDATA[我正在尝试确定“特殊”的地方n 个人口中的人口。
我有来自 n 个人群的样本。我知道每个样本是从哪个人群中抽取的，例如
人口测量
1.4
乙1.2
1.2
1.3
...


来自 n-1 总体的样本是从相同的正态分布中抽取的，其平均值为 $\mu_{default}$ 和方差$\sigma^2_{default}$。
一个群体是“特殊的”其样本是从不同的正态分布中抽取的，均值 $\mu_{special}$ 和方差 $\sigma^2_ {特殊}$。
$\mu_{special}$ &gt; $\mu_{default}$ 但我对差异一无所知。 （实际上 $\sigma^2_{special}$ 可能接近 $\sigma^2_{default}$&lt; /span&gt; 但如果可能的话我不想做出这样的假设。）

我的目标是找到每个群体都是特殊的概率；也就是说，如果种群被命名为 a、b 和 c，我可以计算
p(a 是特殊的 | 数据)
p(b 是特殊的 | 数据)
p(c 是特殊的 | 数据)

使得所有概率加起来为 1。
我可以对每个人群与其他人群进行韦尔奇 t 检验数据以查找每个总体的 p 值。这给了我很好的结果，但我不知道有什么合理的方法可以将这些 p 值转换为我在上面寻找的概率。]]></description>
      <guid>https://stats.stackexchange.com/questions/638332/distinguishing-the-odd-population-out</guid>
      <pubDate>Thu, 01 Feb 2024 17:57:05 GMT</pubDate>
    </item>
    <item>
      <title>具有成分暴露变量的多组结构方程模型 (SEM)</title>
      <link>https://stats.stackexchange.com/questions/638331/multi-group-structural-equation-model-sem-with-compositiona-exposure-variable</link>
      <description><![CDATA[我写这篇文章是因为我有一个关于如何处理我正在设计的 SEM 的问题。我正在进行一项（国家之间）比较研究，研究住房条件如何调节工作条件和健康之间的关系。因此，工作（暴露 = E）、生活条件（中介 = M）和健康（结果 = O）。到目前为止很简单，问题出在工作状态指示器上。在这种情况下，我使用工作的临时性（拥有永久/临时合同）作为更好/更差工作条件的指标。然而，不同国家的临时性人群却有很大不同。在北欧国家，临时性仅限于非常脆弱的群体，而在南方国家，这是一种更为普遍的现象。这意味着回归估计捕获了成分效应，而不是上下文的影响（这对我来说很重要）。我该如何解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/638331/multi-group-structural-equation-model-sem-with-compositiona-exposure-variable</guid>
      <pubDate>Thu, 01 Feb 2024 17:50:17 GMT</pubDate>
    </item>
    <item>
      <title>PDF 的名称？ - 将单位圆上的均匀概率分布投影到 x 轴</title>
      <link>https://stats.stackexchange.com/questions/638330/name-of-pdf-projecting-uniform-probability-distribution-on-the-unit-circle-to</link>
      <description><![CDATA[考虑半径为 r 的圆上的均匀概率分布，即 $\{(x,y) \in \mathbb{R}^2: x^2 + y^ 2 = r^2 \}$。如果我们希望投影到x轴上，我们可以考虑圆上的每个点贡献 $\delta(x- rcos(\theta))$。然后对 $\theta$ 的所有可能值进行平均，得到以下分布：
$Pr(x) = \frac{1}{\pi\sqrt{r^2-x^2}}$
有趣的是，Pr(x) 的傅立叶变换恰好是第一类零阶贝塞尔函数，即 $J_0(2\pi r f)$ 
问题：这个分布 Pr(x) 叫什么？
我清楚地记得它有一个专门的维基百科页面，并且它是以某个数学家的名字命名的。编辑：它相当于区间 (-r,r) 上的 反正弦 分布，但是我可以发誓我见过它有自己的页面，但名称不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/638330/name-of-pdf-projecting-uniform-probability-distribution-on-the-unit-circle-to</guid>
      <pubDate>Thu, 01 Feb 2024 17:16:20 GMT</pubDate>
    </item>
    <item>
      <title>使用迭代期望定律计算我想计算 Y, E(Y) 的平均值</title>
      <link>https://stats.stackexchange.com/questions/638328/using-law-of-iterated-expectations-calculate-i-want-to-calculate-mean-of-y-ey</link>
      <description><![CDATA[我深入了解了计算条件均值和
给定 X 时 Y 的方差，分别表示为 E(Y|X) 和 Var(Y|X)。在此基础上
知识，我想用相同的联合概率来回答后续问题
分布 f(x, y)：

我想回答我使用 R 所做的问题，但我不确定我是否正确。也许我的问题是针对 Stack Overflow 的，但我也愿意接受非 R 答案。最重要的是验证正确性。
• E(Y |X = 0) = 1
• E(Y |X = 1) = 3/4
• 变量 (Y |X = 0) = 1/2
• 变量 (Y |X = 1) = 11/16
• Cov(X, Y ) = −1/16
A) 使用迭代期望定律（即 E(Y ) = E(E(Y |X))），得出
Y，E(Y)。
# 给定概率
px &lt;- c(4/8, 4/8)
# 给定条件期望
EY_X0 &lt;- 1
EY_X1 &lt;- 3/4

# 计算E(Y)
EY &lt;- sum(px * c(EY_X0, EY_X1))
安永
]]></description>
      <guid>https://stats.stackexchange.com/questions/638328/using-law-of-iterated-expectations-calculate-i-want-to-calculate-mean-of-y-ey</guid>
      <pubDate>Thu, 01 Feb 2024 17:11:18 GMT</pubDate>
    </item>
    </channel>
</rss>