<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 11 Nov 2024 03:21:48 GMT</lastBuildDate>
    <item>
      <title>针对极高维度（约 14,000 个特征）的具有加权重要性的快速特征选择</title>
      <link>https://stats.stackexchange.com/questions/657060/fast-forward-feature-selection-with-weighted-importance-for-very-high-dimension</link>
      <description><![CDATA[我正在处理一个包含 14,000 个特征的数据集，我想为每个特征拟合一个模型，以便我可以使用其他特征对其进行回归。但是，我相信只有一小部分（大约 10-15 个特征）与每个模型相关。
我的挑战是找到一个满足以下标准的特征选择算法：

前向选择：我更喜欢一种根据特征重要性迭代添加特征的方法，因为这符合我对小而相关的子集的期望。
速度和效率：算法需要具有计算效率，特别是因为我计划重复执行特征选择。理想情况下，它针对大型数据集的重复使用进行了优化（就像图形 LASSO 是 LASSO 的优化版本一样）。
加权特征重要性：与 LASSO 惩罚类似，我希望能够在选择过程中加权各个特征的重要性。

在过去的两周里，我一直在探索图形 LASSO。虽然它可以为高维数据提供快速计算并允许加权惩罚，但不幸的是，它在我的笔记本电脑上仍然太慢了。欢迎大家提出所有想法和建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/657060/fast-forward-feature-selection-with-weighted-importance-for-very-high-dimension</guid>
      <pubDate>Mon, 11 Nov 2024 02:08:38 GMT</pubDate>
    </item>
    <item>
      <title>估计 Fisher 信息为 0 的回归系数？</title>
      <link>https://stats.stackexchange.com/questions/657057/estimating-regression-coefficients-where-the-fisher-information-is-0</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657057/estimating-regression-coefficients-where-the-fisher-information-is-0</guid>
      <pubDate>Mon, 11 Nov 2024 00:51:27 GMT</pubDate>
    </item>
    <item>
      <title>证明当 $X_1,\cdots,X_n\sim U(0,\theta)$ 时检验最有效</title>
      <link>https://stats.stackexchange.com/questions/657054/prove-that-a-test-is-most-powerful-when-x-1-cdots-x-n-sim-u0-theta</link>
      <description><![CDATA[设$X_1,\cdots,X_n\sim U(0,\theta),\theta &gt;0$为独立随机变量。我想证明 $\phi :\mathbb{R}^n\to [0,1]$ 由 $\phi (x):=\begin{cases}1,&amp;\theta _0&lt;x_{(n)}\vee x_{(n)}\leq \theta _0\alpha ^{1/n}\\0,&amp;\text{otherwise}\end{cases}$ 给出，是 $\alpha\in (0,1)$ 级别最强的测试，可测试 $H:\theta=\theta _0$ vs $K:\theta =\theta _1&gt;\theta _0$。

我能够证明 $\phi$ 具有级别 $\alpha$。为了证明 $\phi$ 最强大，我尝试使用 Neyman-Pearson 引理，但失败了。
首先，我尝试找到一个常数 $k\geq 0$，使得对于所有 $x\in\mathbb{R}^n$，$\phi (x)=\begin{cases}1,&amp;f_{\theta_1}(x)&gt;kf_{\theta_0}(x)\\0,&amp;\text{otherwise}\end{cases}$ 成立，以便使用 NP 引理的&quot;充分性&quot; 部分。我知道，通过 $k=(\theta _1/\theta _0)^n$ 我们可以得出结论，给定任意 $x\in\mathbb{R}^n$，不等式 $f_{\theta_1}(x)&gt;kf_{\theta_0}(x)$ 意味着 $\phi (x)=1$。但是，我无法证明，给定 $x\in\mathbb{R}^n$，等式 $\phi (x)=1$ 意味着 $f_{\theta_1}(x)&gt;kf_{\theta_0}(x)$。

我的问题是：如何证明测试 $\phi$ 对测试 $H:\theta=\theta _0$ 与 $K:\theta =\theta _1&gt;\theta _0$ 最有效。]]></description>
      <guid>https://stats.stackexchange.com/questions/657054/prove-that-a-test-is-most-powerful-when-x-1-cdots-x-n-sim-u0-theta</guid>
      <pubDate>Sun, 10 Nov 2024 23:12:49 GMT</pubDate>
    </item>
    <item>
      <title>对于 t 分布，df = n-1。n 代表什么？</title>
      <link>https://stats.stackexchange.com/questions/657053/for-a-t-distribution-df-n-1-what-does-n-represent</link>
      <description><![CDATA[根据 2 人的建议从 Math Stack Exchange 交叉发布。
我知道 $t$ 分布有一个参数：自由度 (df) 的数量。
我还知道 $\mathrm{df} = n - 1$。
但是，$n$ 究竟代表什么？
我听说过几种含义：

&quot;数据集中的数据点数量。&quot; 这听起来不对。如果我有 $100$ 个数据点，但 $t$ 分布（其中 $\mathrm{df}=50$）比 $\mathrm{df}=99$ 更能模拟该分布，那么我为什么要强制 $\mathrm{df}$ 为 99？

&quot;您用来从样本平均值 $\bar{x}$ 定义 $t$ 统计量的正态随机变量的数量。&quot; 这听起来也不对。我知道
$$t = \frac{\bar{x} - \mu}{s / \sqrt{n}}.$$
然而，这看起来更像是一个数学关系，而不是$t$的定义。如果我不从正态随机变量开始会怎样？

]]></description>
      <guid>https://stats.stackexchange.com/questions/657053/for-a-t-distribution-df-n-1-what-does-n-represent</guid>
      <pubDate>Sun, 10 Nov 2024 22:38:03 GMT</pubDate>
    </item>
    <item>
      <title>非参数直方图密度估计量的渐近偏差是多少？</title>
      <link>https://stats.stackexchange.com/questions/657051/what-is-the-asymptotic-bias-of-the-nonparametric-histogram-density-estimator</link>
      <description><![CDATA[我试图推导非参数直方图密度估计量的渐近偏差表达式，以便将其与核密度估计量的偏差进行比较。在符号方面，直方图定义为$\hat{h}(x)=(nl_n)^{-1}\sum^n_{i=1}I(a_n\leq x\leq b_n)$，其中$l_n=b_n-a_n$，$I$表示指示函数（也许这很简单，但我对此事不太熟悉）。我收到了一个提示，提示我需要假设极限 $(a_n - x)/l_n$ 和 $(b_n-x)/l_n$ 的存在。
到目前为止，我已经将估计值的期望表达为：
$E[\hat{h}(x)]=(l_n)^{-1}Pr(a_n\leq x\leq b_n)$。然后，我使用泰勒展开式围绕 $x$ 获得：
$f(u)\approx f(x)+f&#39;(x)(u-x)$。
因此我这样写，
$E[\hat{h}(x)]=(l_n)^{-1}Pr(a_n\leq x\leq b_n) \approx (l_n)^{-1}\int^{b_n}_{a_n} f(x)+f&#39;(x)(u-x)du$。
然而，我在这里卡住了。我猜想，对边界上的第一项 ($f(x)$) 进行积分将得出 $\int^{b_n}_{a_n}f(x)du=f(x)l_n$，这是由于 $b_n$、$a_n$ 和 $l_n$ 之间的关系。然后，$l_n$ 被抵消，剩下 $f(x)$。这是密度的真实值，所以我认为积分第二项 ($\int^{b_n}_{a_n} f&#39;(x)(u-x)du$) 必定构成偏差。
我是否使用了极限存在的假设？ 我如何计算积分中的第二项？我希望能够将其与核估计进行比较，该估计等于 $\frac{h^2}{2}f&#39;&#39;(x)\mu_2(K)$。是否有第二项的表示（我可以进一步开发它）以便能够这样做？
顺便说一句，我知道我已经从泰勒展开式中省略了 O(.)（为了方便）。
如果有人能帮助我，我将不胜感激。提前感谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/657051/what-is-the-asymptotic-bias-of-the-nonparametric-histogram-density-estimator</guid>
      <pubDate>Sun, 10 Nov 2024 22:08:19 GMT</pubDate>
    </item>
    <item>
      <title>时间序列平稳性和消除虚假相关性的严格证明</title>
      <link>https://stats.stackexchange.com/questions/657049/rigorous-proofs-on-stationarity-and-reduction-of-spurious-correlations-in-time-s</link>
      <description><![CDATA[我理解时间序列分析中的平稳性至关重要，尤其是对于推断而言，因为它有助于降低伪回归的风险。在非平稳序列中，由于方差或均值的变化，相关性更有可能显得显著，从而导致对因果关系的误导性推断。
是否有严格的证明或理论解释支持这一点？具体来说，为什么随时间变化的非恒定方差会增加伪相关的可能性？平稳性如何增强暗示因果关系的相关性的可靠性？任何数学见解或参考资料都会有所帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/657049/rigorous-proofs-on-stationarity-and-reduction-of-spurious-correlations-in-time-s</guid>
      <pubDate>Sun, 10 Nov 2024 21:34:25 GMT</pubDate>
    </item>
    <item>
      <title>Excel中PDF的离散化</title>
      <link>https://stats.stackexchange.com/questions/657047/discretization-of-pdf-in-excel</link>
      <description><![CDATA[我正在尝试使用 excel 计算对数正态分布的期望值，不知道我做得对不对。我有 0 到 1 之间的一千个 X 步长，我用 LOGNORM.DIST 计算 PDF，平均值为 -3.5，标准差为 1.17183，因此期望值为 0.06 -&gt; Exp(mu+st.dev^2/2)。
现在，如果我对 x 和 p(x) 进行求和，我会得到 0.0579，所以我想知道我在离散化 PDF 的积分中遗漏了什么]]></description>
      <guid>https://stats.stackexchange.com/questions/657047/discretization-of-pdf-in-excel</guid>
      <pubDate>Sun, 10 Nov 2024 21:29:03 GMT</pubDate>
    </item>
    <item>
      <title>具有一般解释因素的预测校准</title>
      <link>https://stats.stackexchange.com/questions/657045/forecast-calibration-with-a-general-explanatory-factor</link>
      <description><![CDATA[我正在考虑对特朗普​​政府未来两年的执政情况做出一系列基于概率的预测。预测将是一系列命题，例如：

20% 的联邦将禁止堕胎。

这个想法是为了测试我的校准，即理想情况下，我的 20% 预测中的 20% 应该会实现，我的 50% 预测中的 50% 应该会实现，等等。
当我试图思考我的预测时，我很快遇到了一个潜在的问题，即所有预测都有一个共同的因素——我对 DJT 性格的评估。也许他最感兴趣的是赢得选举和获得掌声，在这种情况下，实施他的政策议程可能会几乎一事无成。或者他是一个有远见的人，之前被房间里的各种成年人所阻碍，而这些成年人这次不会在场。如果这种思路是正确的，那么我可能会在一个方向上完全出错，或者在另一个方向上完全出错。 （我觉得这会不公平地搞砸我的校准，因为我已经预见到了这个问题）。
我的问题是，是否有人对我如何将这个共同因素整合到我的预测集中有什么建议？
我的第一个想法是指定每个预测与这个因素的关系，如果一个预测成真，那么将增加所有其他预测的概率（每个命题指定的某个量）。当我试图找出如何做到这一点的细节时，不幸的是我被卡住了。有人对我如何做到这一点有什么建议吗？或者可以告诉我有人做过类似的事情吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657045/forecast-calibration-with-a-general-explanatory-factor</guid>
      <pubDate>Sun, 10 Nov 2024 20:44:40 GMT</pubDate>
    </item>
    <item>
      <title>有一个与用作随机效应的变量重叠的预测因子可以吗？</title>
      <link>https://stats.stackexchange.com/questions/657042/would-it-be-okay-to-have-a-predictor-that-overlaps-with-the-variable-used-as-a-r</link>
      <description><![CDATA[我将使用基于国家紧密度指数（数字）的预测因子，因此每个国家都有一个值。我将在 50 个国家/地区收集数据，但我预计不同国家/地区的参与者数量会有很大差异（预计每个国家/地区的最低参与者数量为 100 名）。
因此，我正在考虑将国家/地区添加为随机效应（因子）。但大多数国家/地区都有独特的预测因子值，其中五个国家/地区的紧密度得分相同。
我担心这可能会使模型变得奇异或扰乱结果，假设国家/地区的随机效应最终可能会吞噬预测因子的大部分可变性。这是我应该担心的事情吗？ （我还没有数据，但我知道结果变量将是二分的）。
数据预期结构示例：
participant_id consequence_variable tightness country 
x01 1 -0.2 USA 
x01 0 -0.2 USA 
x01 0 -0.2 USA 
x01 1 -0.2 USA 
x02 1 -0.2 USA 
x02 1 -0.2 USA 
x02 0 -0.2 USA 
x02 1 -0.2 USA 
x03 1 0.3 UK 
x03 1 0.3 UK 
x03 1 0.3 UK 
x04 0 0.5 FR 
x04 1 0.5 FR 
x04 1 0.5 FR
x04 0 0.5 FR 

预期模型：
glmer(outcome_variable ~ tightness + (1 | contestant_id) + (1 | country), data, family=binomial)
我想看看在紧密度较高的国家，对某些规范（结果）的遵守是否更为普遍。]]></description>
      <guid>https://stats.stackexchange.com/questions/657042/would-it-be-okay-to-have-a-predictor-that-overlaps-with-the-variable-used-as-a-r</guid>
      <pubDate>Sun, 10 Nov 2024 18:48:49 GMT</pubDate>
    </item>
    <item>
      <title>假设检验的 p 值</title>
      <link>https://stats.stackexchange.com/questions/657034/p-values-for-hypothesis-testing</link>
      <description><![CDATA[直观地讲，标准假设检验（其中检验统计量呈正态分布或近似正态分布）中的 p 值被认为是“在假设零假设成立的情况下，观察到至少与统计学家观察到的值一样极端的值的概率”。
我的问题来自“至少一样极端的部分”。这是由于使用了检验统计量的值的 CDF 的补集。这意味着我们正在考虑我们没有观察到的检验统计量的其他更极端（且不相关）的值。为什么使用检验统计量的 pdf 还不够？我担心在拒绝零假设时，我们正在考虑与特定检验无关的极端值。]]></description>
      <guid>https://stats.stackexchange.com/questions/657034/p-values-for-hypothesis-testing</guid>
      <pubDate>Sun, 10 Nov 2024 15:42:55 GMT</pubDate>
    </item>
    <item>
      <title>显示两个变量在数年内变化的最佳方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/657033/best-way-to-display-two-variables-changing-over-the-span-of-a-number-of-years</link>
      <description><![CDATA[我试图在 y 轴上显示某个城市的中位租金及其人口，x 轴上显示年份。
我的第一反应是使用气泡图，其中 y 轴对应人口，x 轴对应年份，每个气泡的体积与中位租金相关。但这在视觉上模糊了人口与年份的关系。
有没有更好的方法可以做到这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/657033/best-way-to-display-two-variables-changing-over-the-span-of-a-number-of-years</guid>
      <pubDate>Sun, 10 Nov 2024 15:26:18 GMT</pubDate>
    </item>
    <item>
      <title>使用分类器预测作为具有受试者内数据的独立变量？</title>
      <link>https://stats.stackexchange.com/questions/656964/using-classifier-prediction-as-independent-variable-with-within-subjects-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656964/using-classifier-prediction-as-independent-variable-with-within-subjects-data</guid>
      <pubDate>Fri, 08 Nov 2024 17:05:16 GMT</pubDate>
    </item>
    <item>
      <title>“最好的测试是无偏见的”这一说法的证明</title>
      <link>https://stats.stackexchange.com/questions/656832/proof-of-the-statement-the-best-test-is-unbiased</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656832/proof-of-the-statement-the-best-test-is-unbiased</guid>
      <pubDate>Wed, 06 Nov 2024 12:41:53 GMT</pubDate>
    </item>
    <item>
      <title>变分自动编码器 - 手工制作的示例</title>
      <link>https://stats.stackexchange.com/questions/656806/variational-autoencoders-handcrafted-example</link>
      <description><![CDATA[在学习变分自动编码器 (VAE) 时，我想提出一个手工制作的小例子来帮助彻底理解它们。为此，假设我知道我的样本来自五维高斯$\mathbf{X}=(X_1,\dots,X_5)$，其中$X_2\sim\mathcal{N}(1,1)$和$X_5\sim\mathcal{N}(-1,4)$是独立的，并且$X_1=X_2$，$X_3=X_5$和$X_4=X_2+X_5$。进一步假设我们即将学习的 VAE 具有两个潜在维度。在这种情况下（如果我错了请纠正我），我预计潜在空间$\mathbf{Z}$实际上只是二维高斯$(X_2,X_5)$，因为观测数据中的所有其他随机变量完全依赖于这两个变量，并且它们是独立的。
$\textbf{Question(s) (1):}$我是否正确地认为，给定一些样本$\mathbf{x}=(x_2,x_5)$，我们理想情况下会得到$\mathbf{Z}|\mathbf{x}$只是$(x_2,x_5)$本身？例如，一个学习良好的编码器是否会产生一些结果，当从非常接近$(x_2,x_5)$的样本中进行采样时？
我不确定，因为我认为$\mathbf{Z}|\mathbf{x}$应该是一个分布，并且为了“保证”输出$(x_2,x_5)$，我们可能需要类似$p(\mathbf{z}|\mathbf{x})=\delta(z_1-x_2)\delta(z_2-x_5)$的东西，其中$\delta$是狄拉克函数。我对这里的严格细节有点困惑，所以非常感谢您的帮助。
$\textbf{问题 (2):}$ 在实践中，我理解 $\mathbf{Z}|\mathbf{x}$ 由某个正态分布近似，其参数由某个神经网络（编码器）输出。我想在这种情况下，一个“好的”编码器输出一个正态分布的参数是有意义的，该正态分布的均值以 $(x_2,x_5)$ 为中心，协方差矩阵是对角线，对角线元素相对较小（例如 $0.01$ 左右）。这种直觉是否正确，是否符合学习编码器在实践中的表现？
$\textbf{Note:}$ 在我的屏幕上，正态分布的“\mathcal{N}”显示为方框。如果读者您也遇到同样的情况，请知道每个方框实际上都是与正态分布有关的通常“N”符号。]]></description>
      <guid>https://stats.stackexchange.com/questions/656806/variational-autoencoders-handcrafted-example</guid>
      <pubDate>Tue, 05 Nov 2024 21:59:13 GMT</pubDate>
    </item>
    <item>
      <title>具有双向相互作用和额外控制措施的随机截距模型方程</title>
      <link>https://stats.stackexchange.com/questions/656593/random-intercept-model-equation-with-two-way-interaction-and-extra-control-measu</link>
      <description><![CDATA[我正在尝试弄清楚如何用方程式表达以下模型。
结果在每个个体中重复 30 次。结果可以属于一个组（2 级因子），并且在 30 次重复测量中有 3 个条件（每种 10 个）。因此，我想测试组、条件及其相互作用的固定效应。作为随机效应，我包括每个个体的截距。现在有一个额外的连续控制测量（或协变量），它在条件和个体之间变化，但在每次测量之间不变。在这种情况下，以下方程式正确吗？
Y(ijk) = β0 + β1 组（i）+ β2 条件（j）+ β3 ( 组（i） × 条件（j） )+ β4 控制测量（ij）+ u（i）+ ϵ（ijk）
​]]></description>
      <guid>https://stats.stackexchange.com/questions/656593/random-intercept-model-equation-with-two-way-interaction-and-extra-control-measu</guid>
      <pubDate>Fri, 01 Nov 2024 14:16:33 GMT</pubDate>
    </item>
    </channel>
</rss>