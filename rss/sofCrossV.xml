<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 01 Feb 2025 01:18:14 GMT</lastBuildDate>
    <item>
      <title>线性回归中 y 的正态分布和多元正态分布之间的区别？</title>
      <link>https://stats.stackexchange.com/questions/660833/difference-between-normal-and-multivariate-normal-distribution-for-y-in-linear-r</link>
      <description><![CDATA[大家好：）（在线性回归中）我假设当 y 属于正态分布时，是因为只有一个变量，就像一个简单的线性回归，例如 y = b0+b1x1+e 而当有更多变量时，y 属于 mvn 分布，我们将讨论多元线性回归。
有人可以证实这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660833/difference-between-normal-and-multivariate-normal-distribution-for-y-in-linear-r</guid>
      <pubDate>Sat, 01 Feb 2025 00:07:14 GMT</pubDate>
    </item>
    <item>
      <title>当所选模型未赢得所有外部折叠时解释嵌套 CV 结果</title>
      <link>https://stats.stackexchange.com/questions/660831/interpreting-nested-cv-results-when-selected-model-didnt-win-all-outer-folds</link>
      <description><![CDATA[在嵌套交叉验证中，我看到了一个有趣的场景，我希望更好地理解它：
使用 4 倍外部 CV，我的模型选择过程总体上选择了模型 A（它在内部 CV 循环中平均表现最佳）。但是，查看单个外折：

模型 A 只赢得了 4 个外折中的 2 个
其他模型赢得了剩余的 2 个折

在报告模型 A 在新数据上的预期性能时，我们使用所有外折结果的平均值 - 包括其他模型表现更好的 2 个折。
（值得一提的是，当我在完整数据集上重新执行模型选择过程时，模型 A 总体上获胜，但这些指标将是有偏估计量，因此无法报告）
问题：

为什么在估计模型 A 的性能时包含未选择模型 A 的外折结果是有效的？
如何说服那些可能对“混合其他模型的指标”感到不安的利益相关者
是否有一些我们可以使用数学基础来证明这一点？

我正在考虑类似这样的问题：$$\mathbb{E}[\text{Loss}(\text{Model A}(X), Y)| \text{Model A 由选择程序选择}] $$ 其中 $X$ 是训练数据。我很想深入了解数学细节，以及如何使用它来证明模型选择程序和嵌套 cv 本身的合理性。我理解为什么它会给出无偏估计，但很难说服不熟悉这个概念的技术受众。
这个问题这里解释了是什么，但我正在寻找更正式的理由来解释为什么，因为有必要向技术受众证明这种方法的有效性，而且直观地看，他们不相信对所有外循环的结果取平均是可以的，即使它与您选择的模型不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/660831/interpreting-nested-cv-results-when-selected-model-didnt-win-all-outer-folds</guid>
      <pubDate>Fri, 31 Jan 2025 23:09:25 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证来确定因子分析中的因子数量：为什么不是因子越多，可能性就越大？</title>
      <link>https://stats.stackexchange.com/questions/660830/use-cross-validation-to-determine-number-of-factors-in-factor-analysis-why-the</link>
      <description><![CDATA[考虑因素分析模型
\begin{方程*}
\开始{数组}{cccccccccc}
X &amp;=&amp; \mu&amp;+&amp; L&amp;\cdot&amp; f&amp; + &amp;u \\
p\乘以 1 &amp; &amp; p\times 1 &amp;&amp;p\times k&amp; &amp; k\times 1 ＆amp; &amp; p\times 1
\end{array} 
\end{equation*
其中 $\mu$ 为平均值，$L$ 是因子载荷矩阵，$f\sim N(0, I_k)$ 是因子，$u\sim N(0,\Psi)$ 是误差，其中 $\Psi$ 是对角矩阵。
在一些论文中，作者使用交叉验证来确定因子的数量$k$。
我读了代码，发现代码做了如下操作：
(1) 固定一个整数$k$。
&lt; p&gt;(2) 将数据集 $S$ 拆分为 $10$ 折叠，$S_1,\cdots, S_{10}$.
(3) 对于每个 $S_i$，使用$S\backslash S_i$来训练因子分析模型$\mu_i, L_i, \Psi_i$ .
(4) 计算对数似然
\begin{equation*}
f(i,k)= \sum\nolimits_{x\in S_i}\log p(x|\mu_i, L_iL_i^T+\Psi_i)
\end{equation *
其中 $p(x|\mu,\Sigma)$ 是多元正态分布的概率密度函数，其均值为 $\mu$ 和协方差矩阵 $\Sigma$。
在 $f$ 的参数中，$i$ 是测试集的索引，$k$ 是因子的数量。
(5) 计算对数似然的平均值 $\bar f(k)= \frac{1}{10}\sum_{i=1}^{10} f(i,k)$.
乍一看，我怀疑代码可以工作，因为我的直觉告诉我，肯定更大的$k$ 有更大的$\bar f(k)$。
并且，如果 $L$ 是一个 $p\times k$ 矩阵，并且该矩阵与模型拟合得很好，那么$l&gt;k$ 因子也很好地拟合了模型，因为我们可以构造 $p\times l$ 因子载荷矩阵为 $(L&#39;,\mathbf 0)&#39;$。
但当我运行代码时，我发现可能会发生 $\bar f(k)$ 没有增加。
我想知道为什么$\bar f(k)$没有像我直觉所想的那样增加。
举一个数值例子，我将该代码用于一个数据集，其中包含 $156$ 次试验和每次试验 $21$ 个特征。
当 $k=2,3,4,5,6$，对应的$\bar f(k)$为分别
\begin{equation*}
1000\times ( -2.7518, -2.7509, -2.7485, -2.7506, -2.7502 )。
\end{equation*
$k=4$ 具有最大值 $\bar f(k)$ .]]></description>
      <guid>https://stats.stackexchange.com/questions/660830/use-cross-validation-to-determine-number-of-factors-in-factor-analysis-why-the</guid>
      <pubDate>Fri, 31 Jan 2025 22:47:06 GMT</pubDate>
    </item>
    <item>
      <title>glm 和（偏差）残差与拟合值的图[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660829/glm-and-plot-of-deviance-residuals-vs-fitted-value</link>
      <description><![CDATA[您能验证这些是否正确吗？

使用包括 Gamma 的 GLM（您期望异方差）或正态分布（您期望同方差），您不应该能够看到偏差残差和目标方差随均值变化之间的任何直接联系。

即使在具有 Gamma 分布的 GLM 中发现异方差，您仍然应该看到偏差残差的均匀分布。您无法从偏差残差与拟合值的图中看出异方差性。

使用具有正态分布的 GLM，您必须看到同方差性，这样才不会违反正态假设（即目标的方差不应随均值而变化），但同样，您无法在偏差残差与拟合值的图中看到同方差性。

使用 MLR，您必须看到同方差性，这样才不会违反正态假设（即目标的方差不应随均值而变化），您可以在残差与拟合值的图中看到同方差性。

均匀分布意味着偏差残差（GLM）和残差（MLR）的变异性应在拟合值范围内保持一致

我认为残差的分布和假设都会发生变化需要恒定方差（例如在具有正态分布的 MLR 和 GLM 中）。否则，模型可能需要调整（例如对数变换、添加预测因子，甚至切换到另一个分布）。但是，在 GLM（非正态分布）中，预计会改变传播（Gamma），因此它本身并不表示存在问题。

]]></description>
      <guid>https://stats.stackexchange.com/questions/660829/glm-and-plot-of-deviance-residuals-vs-fitted-value</guid>
      <pubDate>Fri, 31 Jan 2025 22:34:43 GMT</pubDate>
    </item>
    <item>
      <title>样本与总体平均治疗效果抽样变异性</title>
      <link>https://stats.stackexchange.com/questions/660828/sample-vs-population-average-treatment-effect-sampling-variability</link>
      <description><![CDATA[我读到Gerber 和 Green 2012 年的田野实验时，了解到了随机化推断的概念，即在进行随机化实验时，可以有两个推断目标。其样本平均治疗效果与研究参与者的有限群体有关。以及与研究参与者所取样的人群相关的人口平均治疗效果。
我的问题是关于如何估计这两个量的抽样变异性。
将平均治疗效果估计量定义为以下形式，其中 $Y_i(t=0)$ 和 $Y_i(t= 1)$ 分别是如果给予治疗 $t = 0$、治疗 $t=1$，则观察 $i$ 的潜在结果：
$$
ATE = \mathbb{E} [Y_i(1)] - \mathbb{E} [Y_i(0)]
$$
该数量是通过假设稳定单位值假设 (SUTVA) 的样本平均值估算的。其中 $t_i$ 是观察到的处理分配，处理时为 1，未处理时为 0。 $N$ 是观测总数，$m$ 是处理过的观测数。
$$
\widehat{ATE} = \frac{1}{m}\sum_{i=1}^m{Y_i(1)|}t_i=1 + \frac{1}{N-m}\sum_{i=m+1}^N{Y_i(0)|t_i = 0}
$$
$\widehat{ATE}$ 的方差如下：
$$
\text{Var}[\widehat{ATE}] = \frac{1}{N-1}\left [\frac{(N-m) \text{Var}[Y_i(1)]}{m} + \frac{m \text{Var}[Y_i(0)]}{N-m} + 2\text{Cov}(Y_i(0), Y_i(1))\right] 
$$
我从现场实验 Gerber and Green 2012 eq 3.4 中得到了方差公式
在教科书中，这种变异性的特点是基于随机化推理。变异性来自随机分配，导致潜在结果的样本平均值不同。
我们没有观察到$\text{Cov}(Y_i(0), Y_i(1))$，因此我们可以估计方差如下：
$$
\widehat{\text{Var}}[\widehat{ATE}] = \frac{\widehat{\text{Var}}[Y_i(1)]}{m} + \frac{\widehat{\text{Var}}[Y_i(0)]}{N-m}
$$
在教科书中，这种变异性是真实抽样方差的保守估计。教科书提到，在以下情况下，该变异性估计量是无偏的：

治疗效果对每个人都是恒定的，或者，
实验中的样本是较大总体的随机样本，推论以此为基础。

总体平均治疗效果的方差为 Gerber and Green 2012 实地实验 等式 11.1：
$$
\text{Var}[\widehat{PATE}] = \frac{\text{Var}[Y_i(1)]}{m} + \frac{\text{Var}[Y_i(0)]}{N-m}
$$
我的问题是，如果治疗效果对每个人都是恒定的，那么为什么$\widehat{\text{Var}}[\widehat{ATE}] = \text{Var}[\widehat{PATE}]$]]></description>
      <guid>https://stats.stackexchange.com/questions/660828/sample-vs-population-average-treatment-effect-sampling-variability</guid>
      <pubDate>Fri, 31 Jan 2025 21:39:56 GMT</pubDate>
    </item>
    <item>
      <title>对此有任何封闭的公式吗？</title>
      <link>https://stats.stackexchange.com/questions/660826/is-there-any-closed-formula-for-this</link>
      <description><![CDATA[在某些假设下，Robins-Monro 算法是回归函数的顺序根估计方法；即形式为
$$
f(\theta) = \mathbb{E}[z|\theta] = \int_{D}zp(z|\theta)dz 的函数。
$$
其中一个假设（我认为？）是 ${f(\theta)}$ 的单调性。
我想知道如果我们将该算法应用于一个更奇怪的示例，例如（非常）嘈杂的正弦函数，会发生什么：
$$
z = \sin(\theta) + x,\ x\sim \mathcal{N}(0,1)。
$$
这里，${f(\theta) = \sin(\theta)}$ 有无穷多个根。我编写了一个模拟程序来跟踪给定各种起始值 ${\theta_0}$ 时发生的情况，使用 R.M. 更新规则
$$
\theta_N = \theta_{N-1} \pm \frac{1}{N}z(x_N,\theta_{N-1})。
$$
似乎，如果上面使用负号，我们会收敛到形式为 ${2n\pi}$ 的根，如果使用正号，我们会收敛到形式为 ${n\pi}$ 的根。我限制只查看形式为 ${2n\pi}$ 的根，因此我使用
$$
\theta_N = \theta_{N-1} - \frac{1}{N}z(x_N,\theta_{N-1})。
$$
花了相当长一段时间才生成大量数据来观察结果，但我发现，给定一个根${\widehat{\theta} = 2n\pi}$和一个起始值${\theta_0}$，我们大致有
$$
p(\widehat{\theta}|\theta_0)\approx \frac{1}{1+e^{-3(\pi - |\widehat{\theta}-\theta_0|)}}。
$$
下面给出了 ${\widehat{\theta} = 0}$ 和 ${-2\pi \leq \theta_0\leq 0}$ 的图：

当 ${\theta_0}$ 距离 ${\widehat{\theta}}$ 不太远或太近时，此近似效果非常好，但似乎在“端点”。即使在这些奇怪的极端情况下生成更多数据后，我的逻辑曲线近似似乎也会在这些端点处失效，并且偏离了数量级。我想我还应该指出，如果我们在总和中使用我的近似值
$$
\sum_{n \in \mathbb{N}}p(\widehat{\theta} = 2n\pi|\theta_0)
$$
它不会收敛到$1$（经过几个项后，它略高于 1）。
我的问题是：有没有办法得出概率${p(\widehat{\theta}|\theta_0)}$的解析解？我的另一个不安是，从技术上讲，我认为，即使经过 10,000 次迭代，我们仍然可能最终转向不同的根（这种可能性极小）。]]></description>
      <guid>https://stats.stackexchange.com/questions/660826/is-there-any-closed-formula-for-this</guid>
      <pubDate>Fri, 31 Jan 2025 20:30:13 GMT</pubDate>
    </item>
    <item>
      <title>以调整后的 $R^2$ 作为变量选择标准的问题</title>
      <link>https://stats.stackexchange.com/questions/660824/problem-with-adjusted-r2-as-criterion-for-variable-selection</link>
      <description><![CDATA[我在研究线性回归时遇到了一个问题。在《复杂问题的平面答案》（Christensen，2020）一书中，他提到：

如果$F$统计量大于1，则删除变量将增加残差均方。根据调整后的$R^2$标准，不应删除该变量。但是，除非$F$值大大大于1，否则可能应该删除这些变量。调整后的$R^2$标准往往会在模型中包含太多变量。

我正试图从数学上理解这一点。我已经完成了这个并设法自己得出：
$$R^2 = 1 - \frac{1}{1 + F\cdot \frac{p-1}{n-p}}$$
其中$p = k + 1$，随后调整后的 R^2 为：
$$\bar{R}^2 = 1 - \frac{n - 1}{n - p + F\cdot (p - 1)}$$
给定一个完整模型$M_k$具有 $k$ 个预测因子，以及一个候选模型 $M_p$，该模型具有 $p$ 个预测因子，$p &lt; k$，我理解 $F$-检验用于测试 $M_k$ 中的附加预测因子是否显著降低残差平方和。我的问题是：

为什么作者在讨论调整后的 $R^2$ 的弱点时引入 $F$ 检验来证明调整后的 $R^2$ 实际上在模型中包含了太多预测因子？我可以理解这种直觉，因为虽然调整后的 $R^2$ 会因为额外的复杂性（即更多的预测因子）而惩罚模型，但它不会因为预测因子的大小而惩罚它们。因此，任何减少残差平方和的预测因子，无论减少大小，都将被包括在内。我如何从上面的等式中理解这一点？或者还有什么我应该研究的？
据我所知，当 $F &gt; 1$，这意味着额外的预测因子显著降低了残差平方和，因此应该将它们包括在模型中（即，完整模型 $M_k$ 优于 $M_p$）。然而，Christensen 提到，除非 $F &gt;&gt; 1$，否则可能应该删除这些变量。从我所学的知识来看，如果 $F$ 显著（在本例中为 $&gt; 1$），则完整模型比简化模型解释的方差要大得多。既然根据检验它已经具有统计显著性，那为什么 $F &gt; 1$ 不足以根据克里斯滕森的观点确立这一事实？
如果我从我推导的模型中理解这一点，我是否应该只考虑 $F$ 而保持其他 ($n, p$) 不变？

谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660824/problem-with-adjusted-r2-as-criterion-for-variable-selection</guid>
      <pubDate>Fri, 31 Jan 2025 19:00:24 GMT</pubDate>
    </item>
    <item>
      <title>与子集相比，glmer（）模型中固定效应对较大数据集的放大效果</title>
      <link>https://stats.stackexchange.com/questions/660823/amplified-effect-of-fixed-effects-in-glmer-model-for-larger-dataset-compared-t</link>
      <description><![CDATA[我正在用相同的变量将一系列模型拟合到不同形式的数据中。我选择了 GLMM，因为我的数据中有一些结构层次，这对于理解变化可能很重要。当我将模型拟合到较小的数据子集时，我遇到的唯一问题是一些收敛/优化问题，因为响应变量非常小——我进行了平方根变换以避免这个问题，因为我没有遇到任何问题。关系不显著（这是我们预期的）。然而，我们决定在“合并”版本的数据上拟合模型（即一个数据框中的所有子集）。当我这样做时，我必须对数据进行平方根变换以避免收敛问题，就像以前一样。但现在最佳拟合模型显示响应和预测变量之间存在强烈的负相关关系。这对我来说毫无意义，因为与子集数据的所有关系都是完全平坦且不显著的。为什么 GLMM 会预测与更多数据点之间存在强烈的负相关关系？这和转换有关吗？这是不好的做法吗？
以下是我拟合的模型类型的一些示例：
合并数据（无子集）——最佳模型
m1 &lt;- glmer(transformedY ~ scale(X) + (1 | Z) + (1 | W),
family = Gammma(link = &quot;log&quot;), data = d)
#scale(X) 估计 = -1.1341, pval ~0
#随机效应：Z 方差 = 1.76056，Z Std. dev = 1.3269；
# W 方差 = 0.09249，W Std. dev = 0.3041 

数据子集 -- 最佳模型
m2 &lt;- glmer(transformedY ~ scale(X) + (1 | Z) + (1 | Q),
family = Gamma(link = &quot;log&quot;), 
data = ds)
#scale(X) 估计 = -0.02805, p val = 1, 
#随机效应：Z 方差 = 0.061329，Z Std. dev = 0.2476；
# Q 方差 = 0.020675，Q Std. dv = 0.1438 

注意：Q 和 W 都以略有不同的单位来测量时间。
我假设它与池中的随机效应有关，这些随机效应吸收了太多的变化并以某种方式放大了固定效应，即使这种关系不是那么强？但这些随机效应是有意义的并且包含结构，所以我不想忽视这一点。有什么建议或资源可以配合使用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660823/amplified-effect-of-fixed-effects-in-glmer-model-for-larger-dataset-compared-t</guid>
      <pubDate>Fri, 31 Jan 2025 17:08:18 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用 Beta 回归还是 Box Cox 变换线性回归？</title>
      <link>https://stats.stackexchange.com/questions/660815/should-i-use-beta-regression-or-box-cox-transformed-linear-regression</link>
      <description><![CDATA[我的响应变量是态度分数，它是比例分数（总分/最高分），因此是连续的，范围从 0-1。最初，我认为 Beta 回归会是一个不错的选择，所以我对分数进行了调整，以便没有真正的 0 或 1。
attitude_self$prop_score &lt;- pmin(pmax(attitude_self$prop_score, 0.001), 0.999)
我的模型如下，AIC 值为 -607：
beta_model &lt;- betareg(prop_score ~ age + group + gender + PerceivedKnowledge, 
data =itude_self, link = &quot;logit&quot;)

然而，经过进一步检查，似乎 prop_score 并不遵循真正的 beta 分布。我检查了分布/密度、偏度和峰度，并进行了 fitdist() 和 Kolmogorov-Smirnov (KS) 检验以测试拟合度。

偏度(prop_score)
[1] -2.792165
峰度(prop_score)
[1] 15.89607

fitdist(prop_score, &quot;beta&quot;)
通过最大似然法拟合分布“beta”
参数：
估计标准差。错误
shape1 2.6511869 0.17474578
shape2 0.7264323 0.03847695

&gt; ks.test(prop_score, &quot;pbeta&quot;, shape1 = 2.65, shape2 = 0.73)

渐近单样本 Kolmogorov-Smirnov 检验

数据：prop_score
D = 0.19366，p 值 &lt; 2.2e-16
备选假设：双侧

然后我使用 Box-Cox 变换对响应变量进行变换，并使用线性回归。
得到的 AIC 较低，为 -900，残差如下：

我转向变换后的线性回归而不是 beta 回归是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/660815/should-i-use-beta-regression-or-box-cox-transformed-linear-regression</guid>
      <pubDate>Fri, 31 Jan 2025 16:53:16 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑回归中，预测变量严重偏斜可以吗？还是应该进行变换？</title>
      <link>https://stats.stackexchange.com/questions/660818/is-it-ok-to-have-highly-skewed-predictors-in-a-logistic-regression-or-should-th</link>
      <description><![CDATA[我有 7 个预测变量和一个二进制 y。我在 r 中使用逻辑回归，想知道我的 4 个变量高度偏斜是否重要？我可以对它们进行对数变换以减少偏斜，虽然这肯定不是正常的，而且这会稍微提高我的分类准确性，但这通常可以做到吗，还是我应该不进行变换以降低准确性但提高可解释性？我的模型不是用于预测的，但我也希望它是准确的，所以这是逻辑回归的假设吗？此外，如果我对它们进行对数转换，这对于解释模型的输出意味着什么？
我的代码：
at_least1 &lt;- glm(
at_least_1 ~ log(no_of_employees) + log(board_size) +
sqrt(relative_board_size) + log(company_age) + 
average_age + FTSE, 
data = company_data, 
family = binomial(link = &quot;logit&quot;)
)

尝试了转换和不转换预测变量。不转换时，预测准确率为 0.7051，而随机准确率为 0.4999。转换后，准确率为 0.7690576。]]></description>
      <guid>https://stats.stackexchange.com/questions/660818/is-it-ok-to-have-highly-skewed-predictors-in-a-logistic-regression-or-should-th</guid>
      <pubDate>Fri, 31 Jan 2025 16:39:19 GMT</pubDate>
    </item>
    <item>
      <title>在估算缺失值时，变量之间的时间关系重要吗？</title>
      <link>https://stats.stackexchange.com/questions/660792/does-the-temporal-relationship-between-variables-matter-when-imputing-missing-va</link>
      <description><![CDATA[我现在的情况是，我有多个变量，包含缺失值，在时间 $t_0$ 测量，还有一些变量在时间 $t_1$ 测量，这可能是几年后。
我需要在 $t_0$ 时估算变量中的缺失值，为此我将使用当时可用的任何信息。是否还应该使用时间上在之后出现的变量的信息？我知道关于是否包括响应变量的讨论，但在这种情况下，变量之间的关系具有明显的方向性。目标（下游分析）是估计时间 0 时的一些暴露对时间 $1.$ 时的一些结果的因果影响。结果在估算过程中用于估算其他变量，但本身不会被估算。]]></description>
      <guid>https://stats.stackexchange.com/questions/660792/does-the-temporal-relationship-between-variables-matter-when-imputing-missing-va</guid>
      <pubDate>Fri, 31 Jan 2025 08:07:24 GMT</pubDate>
    </item>
    <item>
      <title>测试两个 AUC 之间的差异</title>
      <link>https://stats.stackexchange.com/questions/660793/testing-the-difference-between-two-aucs</link>
      <description><![CDATA[测试两个 AUC 之间的差异似乎很简单。有一些相关来源，例如这个和其中的链接。
我有一个非常简单的两个 ROC 案例，类似于此示例：
。
使用梯形规则计算 AUC 非常容易。但是，差异检验假设计算方差，我无法理解如何做到这一点。方差是什么？我拥有的数据就是这样（数据当然是聚合的）：
命中 FalseAlarms
0.0 0.0
0.9 0.3
1.0 1.0

如何使用上述输入数据在 R 中解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/660793/testing-the-difference-between-two-aucs</guid>
      <pubDate>Fri, 31 Jan 2025 06:19:27 GMT</pubDate>
    </item>
    <item>
      <title>如果这些变量也包含在随机效应结构中，如何检验固定效应的显著性？</title>
      <link>https://stats.stackexchange.com/questions/660766/how-to-test-for-significance-of-fixed-effects-if-those-variables-are-also-includ</link>
      <description><![CDATA[我对混合效应模型有一个更一般/更实际的问题。我绝对不是这方面的专家，只是注意到一些似乎不对劲的地方。我想知道当固定效应也包含在模型的随机效应结构中时，是否可以测试该效应的显著性？
我将使用 R 中的 glmmTMB() 举例说明我的问题。假设您有一个模型，其中 Y 是二项分布（0 或 1）响应，X1 和 X2 是固定效应，g 是随机阻断变量。探索了最佳随机效应结构（使用 AIC 和 LRT），发现对于 g 的每个级别，Y~X1 的随机截距和斜率都很重要。最终模型如下所示：final_model&lt;-glmmTMB(Y ~ X1 + X2 + (1+X1|g), family=binomial(link=&quot;logit&quot;), data=dat)
下一步是获取固定效应的检验统计量和 p 值（换句话说，得出结论，它们是否显著影响响应 Y）。我知道有多种方法可以做到这一点，从不好的（例如，Wald 检验）到更好的（例如，似然比检验），再到最好的（例如，模拟？）。假设您正在使用似然比检验（例如，使用 drop1() 命令）。由于这种方法涉及拟合简化（或嵌套）模型进行比较，这是否会产生一个问题，即其中一个简化模型不包括 X1，但 X1 仍然是随机效应结构的一部分？换句话说，这是否会导致某些简化模型被错误指定？我尝试在 R 中运行此类测试并得到了结果，但我不确定是否要相信它。如果简化模型确实指定错误，那么您如何测试固定效应的显著性？由于它是随机效应结构的一部分，因此它永远无法从模型中移除。
***更新：为了回应一些评论，以下是我尝试过的一些测试。
在这里，我尝试移除 g 的随机斜率。final_model 的 AIC 明显较低，LRT 的结果表明模型非常不同（p&lt;0.001），final_model 的对数似然最接近于零。总体而言，这表明随机斜率可以解释变化，应将其纳入模型中。
no_slope_model&lt;-glmmTMB(Y ~ X1 + X2 + (1|g), family=binomial(link=&quot;logit&quot;), data=dat)
anova(final_model, no_slope_model, test=&quot;LRT&quot;)
AICtab(final_model, no_slope_model) 

在这里，我尝试使用 drop1() 命令，该命令从我的最终模型中顺序删除固定效应，以获得测试统计数据和 p 值。此测试运行时没有错误或警告，并提供了我需要的统计数据（例如：对于 X1 chisq=42.6，p&lt;0.01）。
drop1(final_model, test=&quot;Chisq&quot;)

但是，如果我手动重新创建 drop1() 所做的事情，那么问题就会变得更加明显。见下文，简化模型不会将 X1 作为固定效应，但 Y~X1 的随机斜率适合 g 的每个级别。这种方法产生与上述完全相同的 Chisq 和 p 值。
no_X1_model&lt;-glmmTMB(Y ~ X2 + (1+X1|g), family=binomial(link=&quot;logit&quot;), data=dat)
anova(final_model, no_X1_model, test=&quot;LRT&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/660766/how-to-test-for-significance-of-fixed-effects-if-those-variables-are-also-includ</guid>
      <pubDate>Thu, 30 Jan 2025 16:20:30 GMT</pubDate>
    </item>
    <item>
      <title>比较偏好与 3 个价值观（包括中性）的差异</title>
      <link>https://stats.stackexchange.com/questions/660691/comparing-differences-in-preference-with-3-values-including-neutral</link>
      <description><![CDATA[比较包括中性在内的 3 个值的偏好差异
场景：分析具有 3 个值的偏好数据（例如：您更喜欢哪个：足球、棒球还是没有偏好（即中性）？）
主要研究问题：

是否大于中性？
足球比棒球更受欢迎还是反之亦然？

奇怪的是，与连续数据不同，我没有看到很多关于这种情况的强烈建议。
我的问题是：
哪种统计数据最适合分析具有 3 个值（例如足球、中性、棒球）的偏好数据？
如果答案依赖于“弥补”预期值（例如，将响应分为 3 个值（33%，33%，33%），那么您建议使用什么值（或它们的计算）？（注意：我不喜欢 33%，33%，33%，因为不喜欢任何一个与喜欢其中一个的结果不同（参见上述主要研究问题）。
其他注意事项：
只是指出它不是因子设计（就像我们比较 2 个成功率，例如球队 1 的胜/负与球队 2 的胜/负），所以我们不能通过“平均”足球和棒球的成功来计算预期值。
我的数据集中的响应数量可能非常低。在一个例子中，当足球 = 12 和棒球 = 13 时，卡方显着。
McNemar 检验：Sauro/MeasuringU 推荐此检验。虽然它适用于名义变量，它采用 2x2 形式，并带有成对样本（重复测量）。因此，他的建议似乎适用于其他场景。
我考虑过的选项：
选项 A1 - 中性预期 = 观察值
首先，目测（或置信区间）中性和足球/棒球之间的差异。
其次，将中性预期值设置为等于观察值。将剩余的预期值分为足球和棒球（50/50 分割）以“删除”中性，但保持样本量。 （例如，见图片）



偏好
观察到的
预期的




足球
36
(58/2) =29


中立
42
42


棒球
22
(58/2) =29



一个问题似乎是统计数据本身，因为尝试解释它确实很棘手。就像，“在消除中性反应的影响后，参与者对足球和棒球的偏好不同（或没有不同）。”
选项 A2。中性与其他以及中性预期 = 观察到
除了上面的第一步，要么 (A2a) 取足球和棒球中较大的一个，(A2b) 将足球和棒球加在一起，看看它们加起来是否不同于中性，或者 (A2c) 取足球和棒球的平均值，看看该平均值是否不同于中性。一个问题是 A2a、A2b 和 A2c 的可解释性是……它们很难解释和/或需要大量语言来解释。然后使用上面的第二步。因此，可解释性问题与 A1 相同。
选项 B1 - 置信区间与预期值的重叠[不完整解决方案]
计算置信区间并与预期值进行比较。与上述问题相同：如何计算对 3 个值有意义的预期值（我认为 33,33,33 不是）。那么预期值是什么？
选项 B2 - 置信区间与 3 个观察值的重叠
类似于使用置信区间来目测连续数据之间的差异
选项 C。您的建议！
想法、意见、建议？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660691/comparing-differences-in-preference-with-3-values-including-neutral</guid>
      <pubDate>Wed, 29 Jan 2025 02:28:17 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归系数是否均匀收敛，均匀收敛的速度是多少？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660579/does-logistic-regression-coefficient-uniformly-converge-and-what-is-the-rate-of</link>
      <description><![CDATA[假设我有一个回归方程
$$y = 1\{X\beta + \xi\}, \text{ where } \xi \sim \text{Logistic}(0,1).$$
将估计量表示为 ($\hat{\beta}$)。我是否得到了均匀收敛结果：
$$\sup_{\beta \in \Theta} |\hat{\beta} - \beta| \to 0 \text{ in probability}?$$
更好的是，我能得到一个比率吗？例如：
$$\sup_{\beta \in \Theta} \sqrt{n}|\hat{\beta} - \beta| = O_P(1).$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660579/does-logistic-regression-coefficient-uniformly-converge-and-what-is-the-rate-of</guid>
      <pubDate>Sun, 26 Jan 2025 20:42:50 GMT</pubDate>
    </item>
    </channel>
</rss>