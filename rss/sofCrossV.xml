<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 30 Jan 2024 06:18:12 GMT</lastBuildDate>
    <item>
      <title>线性模型的加权最小二乘法</title>
      <link>https://stats.stackexchange.com/questions/638085/weighted-least-squares-for-a-linear-model</link>
      <description><![CDATA[背景
我有一个二维数据集 $\{y_i, x_i\}_{i=1}^N$ 在坐标 $y,x$。我试图用简单的模型来拟合数据集
$$\tag{*}y=mx$$
其中 $m$ 是必须从数据集中学习的（标量）参数。最小二乘估计器给出了一个简单的解决方案，它选择 $m$ 作为
$$\hat{m}_1\triangleq \arg \min_m \sum_{i=1}^N (y_i-m x_i)^2=\frac{X&#39;Y}{ X&#39;X}
$$
与 $X\triangleq[x_1,\dots, x_N]&#39;$, $Y\triangleq [y_1, \dots, y_N]&#39;$ 和 $&#39;$ 表示转置运算符。该解决方案运行良好，并且计算速度极快（只是几个标量乘积的比率！）。但是，为了提高估计的准确性，我只想将注意力集中在相关点的子集上，因为我知道作为一个点 $(y_i, x_i)$&lt; /span&gt; 远离原点则变得不可靠。因此，我想简单地用加权策略替换以前的估计策略，即选择 $m$ 作为
$$
\hat{m}_2 \triangleq \arg \min_m \sum_{i=1}^N w_i (y_i-m x_i)^2
$$
其中权重例如为 $w_i\triangleq 1/\sqrt{x_i^2 + y_i^2}$。
问题
由于拟合模型的具体形式$(*)$，我们有
$$
\hat{m}_2 \triangleq \arg \min_m \sum_{i=1}^N (\tilde{y}_i-m \tilde{x}_i)^2=\frac{\tilde{X}&#39;\波浪线{Y}}{\波浪线{X}&#39;\波浪线{X}}=\frac{X&#39; W Y}{X&#39;W X}
$$
其中 $\tilde{X}\triangleq [\sqrt{w_1}x_1,\dots,\sqrt{w_N}x_N]&#39;$, $\tilde{Y}\triangleq [\sqrt{w_1}y_1,\dots,\sqrt{w_N}y_N]&#39;$ 和 $W\ triangleq \textrm{diag}(w_1,\dots,w_N)$。问题是，从数字上看，我发现 $\hat{m}_2=\hat{m}_1$ ，因此权重在估计过程中没有影响。 
我不确定我的计算或代码实现中是否犯了一些错误，但我对这种现象的理解如下。如果 $w_i\neq 0$，则点 $(y_i, x_i)$ 替换为新的 $(\tilde{y}_i, \tilde{x}_i)$，与 $( y_i, x_i)$。因此， $(\tilde{y}_i, \tilde{x}_i)$ 与 $(y_i, x_i)$ ，因此， $(\tilde{y}_i, \tilde{x}_i)$ 执行的信息是相同的正如 $(y_i, x_i)$ 执行的那样。因此，估计过程独立于权重值。
另一方面，我不明白两件事：

假设所有 $w_i\neq 0$ 为所有 $i$，我不明白为什么
$$\tag{**}\frac{X&#39;W Y}{X&#39; W X}=\frac{X&#39; Y}{X&#39;X}$$
就像 $W$ 在除法中取消一样，但我不明白为什么这应该是真的（如果是真的）。​​
假设 $(**)$ 为真。那么，考虑到某些数据集点应该具有“低影响力”，我该如何估计 $m$ 呢？估算的最终价值？
]]></description>
      <guid>https://stats.stackexchange.com/questions/638085/weighted-least-squares-for-a-linear-model</guid>
      <pubDate>Tue, 30 Jan 2024 04:12:25 GMT</pubDate>
    </item>
    <item>
      <title>SMOTE 和顺序特征选择顺序</title>
      <link>https://stats.stackexchange.com/questions/638083/smote-and-sequential-feature-selection-order</link>
      <description><![CDATA[早上好，
我正在执行以下过程：
分割训练测试数据集
X_train、X_test、y_train、y_test = train_test_split(X_pre、y、random_state=0、stratify=y、train_size=training_fraction)
应用 SMOTE 或其他平衡算法
X_impulated_train_df, y_train = Balancing_algorithm.fit_resample(X_impulated_train_df, y_train)
应用顺序特征选择
sss = StratifiedShuffleSplit(n_splits=8, test_size=0.2, random_state=42)
&lt;前&gt;&lt;代码&gt; sfsLR = SFS(估计器=lr1,
                                   k_features=&#39;最佳&#39;,
                                   前进=布尔_sfs，
                                   浮动=假，
                                   得分=&#39;f1&#39;,
                                   简历=SSS)

sfs = sfs.fit(X_ADASYN3, labels6)
selected_feature_indices = 列表(sfs.k_feature_idx_)
sfsFinal = X_ADASYN3.iloc[:, selected_feature_indices]
sfsFinal.columns = X_ADASYN3.columns[selected_feature_indices]
进行超参数调整
pipeline_lr = 管道([(&#39;lr2&#39;,lr2)])
管道.fit（sfsFinal，标签6）
pipeline_lr = 管道([(&#39;lr2&#39;,lr2)])
lr_grid_search = GridSearchCV(估计器=pipe_lr,
param_grid=lr_param_grid,
得分=&#39;f1&#39;,
简历=sss）
我的问题是：我将 SMOTE 应用于我的完整数据集，但不仅仅针对交叉验证的训练集。这是必须的吗？如果是这样，我如何将其合并到我的代码中？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/638083/smote-and-sequential-feature-selection-order</guid>
      <pubDate>Tue, 30 Jan 2024 03:54:13 GMT</pubDate>
    </item>
    <item>
      <title>解释为什么优势比 1 独立 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638082/explain-why-odds-ratio-1-independence</link>
      <description><![CDATA[我想知道如何证明
优势比 1 意味着独立性。
预先感谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/638082/explain-why-odds-ratio-1-independence</guid>
      <pubDate>Tue, 30 Jan 2024 02:33:49 GMT</pubDate>
    </item>
    <item>
      <title>表格数据上的超维计算与梯度提升和神经网络</title>
      <link>https://stats.stackexchange.com/questions/638081/hyperdimensional-computing-versus-gradient-boosting-and-nn-on-tabular-data</link>
      <description><![CDATA[我一直在尝试学习超维计算（又名矢量符号架构）。那里没有太多资源。我找到了一些例子，但我自己的实验似乎无法得到很好的结果。我发现的最接近的是超维计算教程中的配方示例
我想做的实验是目前正在 Kaggle 上运行的使用银行流失数据集进行二元分类。这似乎是一个简单的二元分类问题。我首先尝试了神经网络并得到了 0.87506。我使用 CatBoost 获得了 0.89176 的分数。虽然这些都是不错的结果，但我想看看 HDC 是如何工作的。不幸的是我的分数是 0.73927。我不知道这是因为 HDC 无法解决此类问题，还是我只是不明白如何正确编码它。
这是我的 HDC 算法的描述：
构建模型（训练）：

为每列创建种子向量。
为每行创建向量。

为每个单元格值创建向量。

二进制列的 True/False 种子向量。
分类列中每个类别的种子向量。
连续的列被分成大小相等的容器。每个 bin 都有一个种子向量。


列向量和值向量之间的绑定运算，得到单元向量。
对所有单元向量进行捆绑操作以获得行向量。


为两个输出分类（已退出和未退出）中的每一个创建向量。

按退出列中的值对所有行向量进行分组。
对于每个组，对所有向量运行捆绑操作以获得代表该类的向量。



查询模型（测试）：

对于每一行（也称为测试用例）：

生成行向量（与上面的步骤 2 相同）。这将是查询向量。
执行查询向量与第 3 步中的两个分类向量之间的余弦相似度。
哪个分类向量更接近，就决定测试用例获得什么标签。


计算准确度（选择正确向量的测试用例数量）/测试用例数量。

我仍然不确定何时绑定以及何时捆绑。我不确定排列是否会发挥作用。我认为它不适用于这种特殊类型的问题。
我尝试过不同的尺寸。 10k 似乎是一个常见的数字，所以我期待它会很好。看来我可以使用 1k 并且看不到准确性有任何显着变化。
我的算法有什么明显错误的地方吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638081/hyperdimensional-computing-versus-gradient-boosting-and-nn-on-tabular-data</guid>
      <pubDate>Tue, 30 Jan 2024 02:33:13 GMT</pubDate>
    </item>
    <item>
      <title>澄清“理解训练深度前馈神经网络的难度”的论点[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638075/clarifying-the-arguments-of-understanding-the-difficulty-of-training-deep-feedf</link>
      <description><![CDATA[编辑：
根据 Sycorax 的评论，我假设方程 (4) 是方程 (4) 的“直接结果”。假设“制度”下 $f$ 的相对线性度我们的投入。我仍然对证明前一段的假设的合理性感兴趣，并且理想地希望看到一些关于为什么我们假设线性制度的讨论。 （请原谅我可能的误解，但是如果我们达到饱和，我们不是进入了非线性部分吗？或者说我们正在强迫自己脱离线性部分，这是不可取的？）
&lt;小时/&gt;
我决定尝试推动这篇论文“理解训练深度前馈神经网络”。 （这篇论文在训练章节的“机器学习实践”中作为参考，考虑到它的简洁性和我的数学背景，我想我应该尝试一下它作为练习。）在第 4.2 节挂断。
主要是，我无法理解所介绍的设置，这是我希望密切关注的主要部分。作者提到了“线性机制”。或线性激活，鉴于上一节的重点是非线性激活函数，这让我感到困惑；他们的 $f$ 是否应该被视为线性？特别是，方程 $(4)$ 和 $(5)$ 是如何遵循的？ （作为理由的前面的段落对我来说非常不清楚。）在这种情况下，成本函数是否完全通用？]]></description>
      <guid>https://stats.stackexchange.com/questions/638075/clarifying-the-arguments-of-understanding-the-difficulty-of-training-deep-feedf</guid>
      <pubDate>Tue, 30 Jan 2024 01:12:08 GMT</pubDate>
    </item>
    <item>
      <title>两个独立置信区间之间的关系以及这两个样本的置信区间（平均值、标准差、n）</title>
      <link>https://stats.stackexchange.com/questions/638071/relationship-between-two-independent-confidence-intervals-and-the-confidence-int</link>
      <description><![CDATA[我试图了解何时存在“统计上显着的差异”以及影响的大小。
想象一下，我们有一种新药，并且有一项随机对照试验（RCT）。结果是（越多越好）。我们无法访问原始数据。
安慰剂：

N = 33
平均值 = 85
标准偏差 = 14

新药：

N = 33
平均值 = 94
标准偏差 = 13

本文显示了这些结果以及 p 值，即 p = 0.001。论文的结论是，结果存在统计学上的显着差异。
我用t-student分布计算了个体置信区间（CI）并得到（下限，上限）：
安慰剂：（80.04，89.96）
新药：(89.39, 98.61)
在个体 CI 中，安慰剂和新药之间存在交叉点。换句话说，在此计算中，结果不存在统计上的显着差异。
不过，我还计算了两个均值之差的置信区间，结果是：
（-15.77432892，-2.225671077）
通过此结果，可以注意到结果之间存在统计上的显着差异。
完成所有这些计算后，结果是否存在统计上的显着差异？
为什么单个置信区间与两个均值之间差异的置信区间有不同的解释？]]></description>
      <guid>https://stats.stackexchange.com/questions/638071/relationship-between-two-independent-confidence-intervals-and-the-confidence-int</guid>
      <pubDate>Tue, 30 Jan 2024 00:02:54 GMT</pubDate>
    </item>
    <item>
      <title>计算具有交互作用的实验中的样本量</title>
      <link>https://stats.stackexchange.com/questions/638070/calculate-sample-size-in-an-experiment-with-interactions</link>
      <description><![CDATA[我需要进行功耗分析，但我不确定我做得是否正确。最初，我有四个单元，每个单元将分为两半。在单元 1 和 2 中，将施加刺激 (S)，而在单元 3 和 4 中，将不施加刺激 (NS)。这些单位的每一半将接受两种治疗中的一种：治疗 1 (T1)，即对照，以及治疗 2 (T2)。这些处理的具体应用如图所示。

在单元 1 中，处理 1 将应用于侧 1，处理 2 将应用于侧 2。对于单元 2，处理安排相反。单元 3 和单元 4 将遵循相同的模式，在各自的侧面进行交替处理。
在我的实验中，（通过机器）施加力并测量所有单元的每一侧。我的想法是，我需要测量切割单元所需的力。目的是检验以下假设：

$H_0:$ 处理 1 和 2 所施加的力没有差异 ($T_1 = T_2$）。

$H_1:$ 处理 1 施加的力大于处理 2 施加的力 ($ T_1 &gt; T_2$）。


然后，我需要测试治疗2在有刺激和无刺激的情况下是否有差异。

$H_0:$ 处理 2 有或没有刺激时施加的力没有差异（ $T_2 \times S = T_2 \times S$)。

$H_1:$ 处理 2 和刺激时施加的力小于处理 2 无刺激时施加的力 ($T_2 \times S &lt; T_2 \times S $)。


我从文献中找到了文章的平均值、标准差和样本量，但我不确定如何计算效应大小以及如何确定正确的样本量（考虑 $0.80$ 和显着性水平 $a = 0.05$）。在我的示例中，我有四个单元，但我需要计算出需要重复实验多少次（即，我需要重复这组四个单元多少次）。
我最初使用 R 中 pwr 包中的 pwr.anova.test 函数计算了此值，但我不确定结果是否正确。谁能建议我可以用来计算样本量的任何方法？或者我使用的方法听起来正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638070/calculate-sample-size-in-an-experiment-with-interactions</guid>
      <pubDate>Mon, 29 Jan 2024 22:54:54 GMT</pubDate>
    </item>
    <item>
      <title>二元 Cox 比例风险模型仿真</title>
      <link>https://stats.stackexchange.com/questions/638069/two-component-cox-proportional-hazards-model-simulation</link>
      <description><![CDATA[在我读过的一篇文章中，他们进行了一项模拟研究：
&lt;块引用&gt;
在此模拟中，我们从以下内容生成 $T_i$
特定组的线性变换模型： $$H(T_i) = \beta_{k,1}
X_{i,1} + \beta_{k,2} X_{i,2} + \varepsilon_i, i = 1, 2, \ldots, n;
 \quad k = 1, 2 $$ 其中 $ H(t) = \log\left(2(e^{4t} - 1)\right)$&lt; /span&gt; 和
$\varepsilon_i $遵循标准极值分布。在
这种情况下，线性变换模型相当于Cox
比例风险模型。我们从两部分生成样本
具有混合权重的 Cox 比例风险模型 $ \pi_1 =
 \frac{1}{3}$、$\pi_2 = \frac{2}{3}$ 和 $ \beta_1
 = (-3, -2)^T$, $\beta_2 = (1, 1)^T$。协变量 $X_i$ 由均值为零的多元正态分布生成
和一阶自回归结构 $ \Sigma = (\sigma_{st})$
其中 $ \sigma_{st} = 0.5^{|s - t|}$ 对于 $ s，t = 1， 2 美元。审查
时间是根据 $[0, C]$ 上的均匀分布生成的，其中 $C$
选择实现 $5\%$ 和 $25\%$ 的审查比例。

我的问题是，我将如何生成生存时间？这是我的方法：
转换函数：我首先反转转换模型来模拟生存时间。
$$
        H(t) = \log(2(e^{4t} - 1)), \\
        H^{-1}(y) = \frac{1}{4} \log\left(\frac{e^y}{2} + 1\right)。
  $$
模型参数：
该模型涉及两个具有混合权重的组件
$$\pi_1 = \frac{1}{3}, \quad \pi_2 = \frac{2}{3},
$$
和参数向量 $$ \beta_1 = (-3, -2)^{\top}, \quad \beta_2 = (1, 1)^{\top}$$
协变量生成：
$\Sigma$ 是协变量变量的协方差矩阵，因此，协变量是根据多元正态分布 (MVN) 生成的
$$\Sigma = \begin{pmatrix} 1 &amp; 0.5\\0.5&amp; 1 \end{pmatrix}, \\
        X \sim \text{MVN}(\mu = (0, 0)^{\top}, \Sigma)$$
小组分配和生存时间模拟：
$$\text{group}_i = \begin{cases} 1 &amp; \text{如果 } U_i &lt; \pi_1 \\ 2 &amp; \text{否则} \end{cases}$$，其中
$$ U_i \sim \text{统一}(0, 1)$$
$$H(T_i) = \begin{cases} \beta_1 \cdot X_i + \epsilon_i &amp; \text{如果组}_i = 1
\\ \beta_2 \cdot X_i + \epsilon_i &amp; \text{如果组}_i = 2 \end{案例}。
$$
其中 $$\epsilon_i \sim \text{极值分布}(0, 1)$$
生存时间：
因此，可以使用以下方法生成生存时间
$$
    T= H^{-1}(H(T_i))。
  $$
审查：
$$
    C_i \sim \text{统一}(0, c), \\
    \text{观察到的 } T_i = \min(T_i, C_i), \\
    \delta_i = \begin{cases} 1 &amp; \text{if } T_i \leq C_i \\ 0 &amp; \text{其他} \end{案例}。
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/638069/two-component-cox-proportional-hazards-model-simulation</guid>
      <pubDate>Mon, 29 Jan 2024 22:50:52 GMT</pubDate>
    </item>
    <item>
      <title>高斯后验/后验预测平均值[重复]</title>
      <link>https://stats.stackexchange.com/questions/638068/gaussian-posterior-posterior-predictive-mean</link>
      <description><![CDATA[我对后验分布和后验预测分布之间的差异有点困惑。我知道后验是参数的分布，而后验预测是数据的分布。
对于高斯先验和似然，后验均值将等于后验预测分布的均值，我的假设是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/638068/gaussian-posterior-posterior-predictive-mean</guid>
      <pubDate>Mon, 29 Jan 2024 22:42:58 GMT</pubDate>
    </item>
    <item>
      <title>协变量作为预测变量的固有部分</title>
      <link>https://stats.stackexchange.com/questions/638067/a-covariate-as-an-inherent-part-of-predictor</link>
      <description><![CDATA[我想比较两种疾病类别的脑容量：年轻发病与老年发病。我知道，一般来说，年龄是脑容量的协变量。也就是说，年龄越大，大脑越小。然而，根据定义，它也是我的分组变量的一部分。无论我做什么，老发病组的年龄 $&gt; 50$ 岁，另一个是 $&gt; 岁20 岁。我是否仍然应该将年龄作为协变量，或者是否有任何其他模型可以克服这种高年龄组关系/定义？]]></description>
      <guid>https://stats.stackexchange.com/questions/638067/a-covariate-as-an-inherent-part-of-predictor</guid>
      <pubDate>Mon, 29 Jan 2024 22:28:18 GMT</pubDate>
    </item>
    <item>
      <title>伽玛分布随机变量的矩参考[重复]</title>
      <link>https://stats.stackexchange.com/questions/638064/reference-for-moments-of-gamma-distribution-random-variable</link>
      <description><![CDATA[我想要一个参考来解释具有伽玛分布的形状和尺度参数的伽玛随机变量的 $n^{th}$ 矩，具体如下力矩方程
\begin{方程}
E[X^n]=\theta^n \prod_{i=1}^n(k+i+1)
\end{方程}]]></description>
      <guid>https://stats.stackexchange.com/questions/638064/reference-for-moments-of-gamma-distribution-random-variable</guid>
      <pubDate>Mon, 29 Jan 2024 22:13:21 GMT</pubDate>
    </item>
    <item>
      <title>关于高斯过程分类器优化最佳实践的建议？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/638063/advice-on-gaussian-process-classifier-optimisation-best-practises</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/638063/advice-on-gaussian-process-classifier-optimisation-best-practises</guid>
      <pubDate>Mon, 29 Jan 2024 22:06:32 GMT</pubDate>
    </item>
    <item>
      <title>显示分层和回归之间等效性的示例</title>
      <link>https://stats.stackexchange.com/questions/638058/example-showing-equivalence-between-stratification-and-regression</link>
      <description><![CDATA[在回归中使用对照来估计治疗对结果的影响背后的直觉的一种方式是分层。当控制 Z 时，我们会查看具有相似 Z 水平的观测值之间 X 和 Y 之间的关系，如 此处
&lt;块引用&gt;
最简单的方法（也是您提出的）是对数据进行分层，以便获得具有相似特征的子组 - 然后可以使用一些方法将这些结果汇总在一起以获得单个“答案”。如果您想要控制的变量数量非常少，那么这种方法是有效的，但正如您所正确发现的那样，当您将数据分割成越来越小的块时，这种方法很快就会崩溃......一种更常见的方法是包括您想要在回归模型中控制的变量...您将得到的估计...将是其他协变量水平内不耐烦的影响 - 回归允许您基本上平滑没有太多数据的地方（分层方法的问题），尽管应该谨慎行事。

我一直在努力使用模拟数据在 R 中设计一个示例，以显示分层和回归之间的等价性。也就是说，您可以得到相同的答案，要么控制 Z，要么仅在 Z = 0 或 Z = 1 之间拟合 X 和 Y 之间的模型（另一个问题：这会产生两个估计；如何组合？）
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/638058/example-showing-equivalence-between-stratification-and-regression</guid>
      <pubDate>Mon, 29 Jan 2024 20:50:18 GMT</pubDate>
    </item>
    <item>
      <title>BERT 的均值池化是否需要使用注意力掩模？</title>
      <link>https://stats.stackexchange.com/questions/638049/is-it-necessary-to-use-attention-mask-for-mean-pooling-for-bert</link>
      <description><![CDATA[我正在开展一个项目，涉及使用“emilyalsentzer/Bio_ClinicalBERT”分析临床文本。来自 Hugging Face 变形金刚库的模型。我的目标是从模型中提取有意义的句子嵌入以用于下游任务。我知道 BERT 嵌入的几种池化策略，但我不确定哪种策略对我的特定用例最有效。
普遍的方法是使用 CLS 令牌进行嵌入。然而，受到最近一篇使用均值池和最佳层选择算法的论文的启发，我&#39;一直在考虑最后一个隐藏状态层的平均池化。许多存储库的常见做法是直接计算最后一层的平均值。但我相信，这可能会忽略一个关键方面：注意力面具。
直观上，在池化之前，首先将最后一个隐藏状态与注意掩码相乘，有效地过滤掉填充序列似乎更准确。根据我的理解，这将确保只有重要的令牌嵌入才会对平均值做出贡献。
这种将注意力掩模纳入均值池的修改方法是否比典型的直接均值计算更有效？我正在寻求有关此方法是否可以提高下游应用程序的句子嵌入质量的见解。
代码示例
导入 torch.nn 作为 nn
从 Transformer 导入 AutoModel、AutoTokenizer

项目_dim = 512
bert_model = AutoModel.from_pretrained(“emilyalsentzer/Bio_ClinicalBERT”，output_hidden_​​states=True)
tokenizer = AutoTokenizer.from_pretrained(“emilyalsentzer/Bio_ClinicalBERT”)
tokenizer.model_max_length = 256
projection_head = nn.Linear(768, proj_dim)

defmean_pooling(model_output,attention_mask):
    token_embeddings = model_output[0] # model_output 的第一个元素包含所有 token 嵌入
    input_mask_expanded=attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    返回 torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)

# 用法示例
输出= bert_model（input_ids=input_ids，attention_mask=attention_mask）
嵌入=mean_pooling（输出，attention_mask）
]]></description>
      <guid>https://stats.stackexchange.com/questions/638049/is-it-necessary-to-use-attention-mask-for-mean-pooling-for-bert</guid>
      <pubDate>Mon, 29 Jan 2024 19:58:48 GMT</pubDate>
    </item>
    <item>
      <title>Cronbach alpha - 描述性统计</title>
      <link>https://stats.stackexchange.com/questions/638045/cronbach-alpha-descriptive-statistics</link>
      <description><![CDATA[我根据斯滕伯格的投资理论研究了思维方式。我使用了 TSI 问卷来衡量思维方式的偏好。问题是，对于某些类型的思维方式，我的克伦巴赫阿尔法得分很低。示例如下：

本地类型的思维方式，包含六项，可靠性为$a = 0.545$
君主风格（$7$ 项），$a = 0.638$
寡头（$6$ 项），$a = 0.636$
无政府主义（$7$ 项），$a = 0.647$
全球（$6$ 项），$a = 0.648$。

有 $13$ 个量表，其中 $6$ 的 Cronbach alpha 系数较低。我应该怎么办？我该如何解释这一点？这是否意味着我的研究结果无效？
我使用Pearson的$r$来计算量表之间的相关性，它显示了量表之间良好的相关性。我该如何解释这些结果？我希望我说得足够清楚，因为我的英语不太好。 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/638045/cronbach-alpha-descriptive-statistics</guid>
      <pubDate>Mon, 29 Jan 2024 19:11:59 GMT</pubDate>
    </item>
    </channel>
</rss>