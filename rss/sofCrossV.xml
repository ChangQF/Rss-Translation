<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 03 Jul 2024 03:17:15 GMT</lastBuildDate>
    <item>
      <title>有限数据集的对象检测</title>
      <link>https://stats.stackexchange.com/questions/650371/object-detection-for-finite-dataset</link>
      <description><![CDATA[考虑以下场景

如果我想训练一个模型来检测和计算这些方块：

这些方块永远不会不同。它们看起来总是一模一样，大小也完全相同，永远不会有某种重叠或障碍，也不会改变颜色等 - 它们总是完全相同。
但是反复训练同一张图片（因为您会使用其他什么图片来制作数据集？它永远不会改变），它无法正确识别这些框。如果您拍摄图像并制作扭曲的版本以便获得数据集，它仍然无济于事。
我该如何针对这种简单的场景训练算法？或者对象检测（或分类，如果我们包括标记的对象，那么我们将有 2 个类）是否仅适用于可以“在视觉上改变/扭曲”的事物，而不适用于始终相同的事物？
我一直在尝试查找有关它的文献、论文和文章，但我不知道这个问题叫什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/650371/object-detection-for-finite-dataset</guid>
      <pubDate>Wed, 03 Jul 2024 03:04:12 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们要使用零假设下假设的值来计算比例的标准差？</title>
      <link>https://stats.stackexchange.com/questions/650370/why-do-we-compute-the-standard-deviation-of-the-proportion-using-the-value-assum</link>
      <description><![CDATA[在计算 2 类误差时，为什么即使我们将备择假设作为可能的真实值，我们也要使用零假设下的假设值来计算标准差？
如果零假设 u = 20，备择假设 u = 24，且采样 x = 21，则 H0σ（基于零假设计算）。我们通过“(x-24)/H0σ”计算 2 类误差。我的问题是为什么不使用 H1σ...？
示例案例 - https://www.youtube.com/watch?v=BJZpx7Mdde4]]></description>
      <guid>https://stats.stackexchange.com/questions/650370/why-do-we-compute-the-standard-deviation-of-the-proportion-using-the-value-assum</guid>
      <pubDate>Wed, 03 Jul 2024 00:31:40 GMT</pubDate>
    </item>
    <item>
      <title>加权风险比</title>
      <link>https://stats.stackexchange.com/questions/650369/the-weighted-hazard-ratio</link>
      <description><![CDATA[有人能帮我弄清楚如何在 R 中获得真实加权风险比吗？特别是对于 Flemming &amp; Harrington 家族权重。一个简单的例子可能会很有帮助。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/650369/the-weighted-hazard-ratio</guid>
      <pubDate>Tue, 02 Jul 2024 23:49:16 GMT</pubDate>
    </item>
    <item>
      <title>稀疏、有序、二进制向量的相似度测量，对真值的权重更大</title>
      <link>https://stats.stackexchange.com/questions/650367/similarity-measure-for-sparse-ordered-binary-vectors-with-more-weighting-to-t</link>
      <description><![CDATA[我有两个稀疏、有序的二进制向量。向量的大小约为 ~100。
我的印象是余弦相似度对于稀疏、有序的二进制向量很有用。就我的目的而言，它很好，但并不是我所寻找的。
假设我有两组向量对：A =：{{0,0,0}, {0,0,0}} 和 B =：{{1,1,1}, {1,1,1}}。 (A1, A2) 和 (B1, B2) 之间的余弦相似度相同，因为两对是相同的，但是，我想要一个对 B 更重要的度量，因为它对 1 的观察更多。
我可以通过总结向量中 1 的数量，然后将其乘以余弦相似度来创建一个基本的度量。
我只是好奇是否有一个更深思熟虑（可能准确）的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/650367/similarity-measure-for-sparse-ordered-binary-vectors-with-more-weighting-to-t</guid>
      <pubDate>Tue, 02 Jul 2024 23:18:58 GMT</pubDate>
    </item>
    <item>
      <title>加权平均值的误差是多少？</title>
      <link>https://stats.stackexchange.com/questions/650364/what-is-the-error-on-the-weighted-mean</link>
      <description><![CDATA[我正在组合直方图中的箱体。我有一些代码使用此公式来计算加权平均值的误差：
$$\sigma = \frac{\sqrt{\sum \frac{w_{i}(w_{i}\sigma_{i}^{2}+x_{i}^{2})}{\sum w_{i}}-(\frac{\sum w_{i}x_{i}}{\sum w_{i}})^{2}}}{\sqrt{\sum w_{i}}}$$
有人能告诉我这是如何得出的吗？我在哪里可以找到有关此公式的更多信息？]]></description>
      <guid>https://stats.stackexchange.com/questions/650364/what-is-the-error-on-the-weighted-mean</guid>
      <pubDate>Tue, 02 Jul 2024 23:08:17 GMT</pubDate>
    </item>
    <item>
      <title>GLMM 适用于非高斯数据</title>
      <link>https://stats.stackexchange.com/questions/650362/glmm-for-not-so-gaussian-data</link>
      <description><![CDATA[我遇到了 GLMM 问题，希望您能给我一些建议。
因此，基本上，我有来自三个独立组（变量：子文件夹）的显微镜实验数据，这些组嵌套在 4 个实验重复（变量：文件名）中：在 4 个单独的实验中一起测量了一组细胞。
下图显示了三个实验组的值，每个测量值的颜色代表每个实验。
我想比较实验组之间的差异（我知道在这种情况下非常明显）。因此，我使用 glmmTMB 中的 GLMM 来建模此数据集：m &lt;- glmmTMB(mean_new_deltaR ~ subfolder+(1 | file_name), dispformula=~ subfolder, data=mean_deltaR)，然后使用 emmeans。由于方差肯定不均匀，因此我使用 dispformula 进行建模。但是，当我使用 DHAMRa 进行诊断时，残差看起来不太好。有什么真诚的方法吗？稳健 GLM 是一种选择吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/650362/glmm-for-not-so-gaussian-data</guid>
      <pubDate>Tue, 02 Jul 2024 22:16:27 GMT</pubDate>
    </item>
    <item>
      <title>对 Fisher 评分算法的困惑</title>
      <link>https://stats.stackexchange.com/questions/650359/confusion-over-fisher-scoring-algorithm</link>
      <description><![CDATA[给定一个概率模型$f(X;\theta)$和一组 i.i.d.观测值$x_1,\ldots,x_n$我们假设这些观测值来自某个真实参数$f(X; \theta_0)$，我们可以使用牛顿法进行最大似然估计：
$$
\theta_{t+1} = \theta_t + \eta (\nabla^2 \ell(\theta_t))^{-1} \nabla \ell(\theta_t)
$$
其中$\eta$表示步长，$\ell(\theta) = \sum_{i=1}^n \log f(x_i;\theta)$
另一方面另一方面，Fisher 评分算法用 Fisher 信息矩阵代替了对数似然的 Hessian，$\nabla^2 \ell(\theta)$
$$
\mathcal{I}(\theta) = - \mathbb{E}_{X \sim f(X;\theta)} \nabla^2 \ell(\theta)
$$
因此，Fisher 评分算法是
$$
\theta_{t+1} = \theta_t + \eta (\mathcal{I}(\theta_t))^{-1} \nabla \ell(\theta_t)
$$
我的问题是：鉴于一般而言，Fisher 评分算法的迭代次数$\theta_t$ 并不接近 MLE 和真实参数 $\theta_0$，为什么 Fisher 信息矩阵 $\mathcal{I}(\theta_t) = - \mathbb{E}_{X \sim f(X;\theta_t)} \nabla^2 \ell(\theta_t)$ 是 Hessian 的合理近似值？具体而言，在我看来，对分布 $X \sim f(X;\theta_t)$ 取期望根本不会对在观测值 $x_1,\ldots,x_n \sim f(X; \theta_0)$ 处评估的对数似然的 Hessian 矩阵产生良好的估计，除非 $\theta_t$ 已经接近 MLE，从而接近真实参数值。]]></description>
      <guid>https://stats.stackexchange.com/questions/650359/confusion-over-fisher-scoring-algorithm</guid>
      <pubDate>Tue, 02 Jul 2024 21:33:58 GMT</pubDate>
    </item>
    <item>
      <title>相关矩阵定义[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650357/correlation-matrix-definition</link>
      <description><![CDATA[为什么相关矩阵有这么多定义？
例如，在关于 ICA 的书中 https://www.cs.helsinki.fi/u/ahyvarin/papers/bookfinal_ICA.pdf 有一个定义，指出在相关矩阵中，有元素对应于随机向量第 i 个元素和第 j 个元素乘积的期望值。其他一些来源引入了不同的定义，例如基于 -1 和 1 之间的归一化相关系数。]]></description>
      <guid>https://stats.stackexchange.com/questions/650357/correlation-matrix-definition</guid>
      <pubDate>Tue, 02 Jul 2024 21:28:59 GMT</pubDate>
    </item>
    <item>
      <title>非独立同分布数据的 MLE 收敛</title>
      <link>https://stats.stackexchange.com/questions/650355/convergence-of-mle-for-non-iid-data</link>
      <description><![CDATA[考虑使用 MLE 计算以下 2 种情况下的最佳模型参数 $\theta$：

数据生成过程独立但不相同：

$L(y;\theta) = \prod_{i=2}^{n} f_{i}(y_i;\theta)$。

数据生成过程具有顺序依赖性，可能不平稳：

$L(y;\theta) = \prod_{i=2}^{n} f_{i}(y_i|y_{i-};\theta) f_{1}(y_1)$。
下标 $i$ 表示每个项 $f$ 的分布可能不同。如果模型指定得当，MLE 是否会收敛于 1. 和 2.？是否有任何证据证明 1. 和 2. 收敛（或不收敛）？]]></description>
      <guid>https://stats.stackexchange.com/questions/650355/convergence-of-mle-for-non-iid-data</guid>
      <pubDate>Tue, 02 Jul 2024 20:40:12 GMT</pubDate>
    </item>
    <item>
      <title>饶-布莱克威尔定理</title>
      <link>https://stats.stackexchange.com/questions/650354/rao-blackwell-theorem</link>
      <description><![CDATA[我无法理解 Rao-Blackwell 定理。特别是，我不明白为什么结果估计量是参数所有无偏估计量之间方差最小的估计量。该定理的证明只是表明结果估计量的方差小于我用于条件的估计量的方差。
请帮助我
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/650354/rao-blackwell-theorem</guid>
      <pubDate>Tue, 02 Jul 2024 20:37:46 GMT</pubDate>
    </item>
    <item>
      <title>简单随机抽样和组内比较</title>
      <link>https://stats.stackexchange.com/questions/650339/simple-random-sampling-and-in-group-comparison</link>
      <description><![CDATA[我们正在我们的托管网站上进行 A/B 测试，我们出售四种不同的计划（A、B、C 和 D）。我们网站的访问者被随机分配到基本 UI（控制）或修改后的 UI（变体）。在分配之前，我们不知道访问者购买特定计划的意图。
我的问题是：分配后，比较每个组内每个计划的购买率是否有效？例如，我们可以比较看到原始 UI 的用户和看到修改后的 UI 的用户之间的计划 A 的购买率吗？
提前感谢您的见解！
PS：我主要关心的是确保任何观察到的购买行为变化都是由于 UI 更改本身造成的，而不是因为 UI 更改影响了用户切换计划。具体来说，我们如何确定计划 A 的购买量增加或减少是由于 UI 更改造成的，而不是因为新 UI 导致用户改变了他们原来的购买意图？]]></description>
      <guid>https://stats.stackexchange.com/questions/650339/simple-random-sampling-and-in-group-comparison</guid>
      <pubDate>Tue, 02 Jul 2024 17:05:50 GMT</pubDate>
    </item>
    <item>
      <title>不同条件边际对的均匀联合分布</title>
      <link>https://stats.stackexchange.com/questions/650328/equal-joint-distribution-for-different-conditional-marginal-pairs</link>
      <description><![CDATA[设$(\Omega, \mathcal{A}, \mathbb{P})$为概率空间，设$X:(\Omega, \mathcal{A})\rightarrow (\mathcal{X}, \mathcal{F})$和$Y:(\Omega, \mathcal{A})\rightarrow (\mathcal{Y}, \mathcal{G})$为随机变量。
现在我知道了最常用的结果
$$\mathbb{P}_{X,Y}(A, B) = \int_A \mathbb{P}_{Y|X=x}(B)d\mathbb{P}_X$$
并且
$$\mathbb{P}_{X,Y}(A, B) = \int_B \mathbb{P}_{X|Y=y}(A)d\mathbb{P}_Y.$$
我感兴趣的是，在更一般的环境中，我们何时可以判断这样构建的联合分布是否相等？即，上述两个条件和两个边际的结构是什么，使得它们通过上述两个方程产生相同的联合分布？
更准确地说：设 $\mu$ 为（常规）条件分布，使得 $\mu(A,y)$ 是 $A\in \mathcal{F}$ 中的概率测度和 $y\in \mathcal{Y}$ 中的可测函数。设 $\nu$ 是 $\mathcal{X}$ 上的边际分布。此外，让 $\rho$ 成为（常规）条件分布，使得 $\rho(B,x)$ 是 $B\in \mathcal{G}$ 中的概率测度和 $x\in \mathcal{X}$ 中的可测函数，并让 $\eta$ 成为 $\mathcal{Y}$ 上的边际分布。
在什么情况下联合分布
$$\int_A \mu(A, y) d\nu(y)$$
且
$$\int_B \rho(B, x) d\eta(x)$$
相等吗？
也许是一个密切相关的问题：如果我只有 $\int_A \mu(A, y) d\nu(y)$，我如何确定 $\mathcal{Y}$ 上的条件和 $\mathcal{X}$ 上的边际分布，从而给出相同的联合分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/650328/equal-joint-distribution-for-different-conditional-marginal-pairs</guid>
      <pubDate>Tue, 02 Jul 2024 14:46:10 GMT</pubDate>
    </item>
    <item>
      <title>需要 Bonferroni 校正吗？回归预测一个结果</title>
      <link>https://stats.stackexchange.com/questions/650323/bonferroni-correction-necessary-regression-to-predict-one-outcome</link>
      <description><![CDATA[大家好，我正在做一个项目，其中我在基线和一个 IV 上有多个预测因子。我试图看看是否有任何 DV 可以很好地预测 IV（连续）上的得分。这个想法是使用许多线性回归模型，每个模型都有一个 DV。我们只是想看看是否有任何预测因子有潜力，所以它相当具有探索性，但基于某种理论，我们将变量缩小到几个。问题是，由于我正在做单独的模型（技术上每个模型都有自己的假设），我是否需要对多次测试进行校正？为什么或为什么不？我的样本量很小。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650323/bonferroni-correction-necessary-regression-to-predict-one-outcome</guid>
      <pubDate>Tue, 02 Jul 2024 14:33:13 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的权重初始化——每个观察值的权重应该不同还是相同？</title>
      <link>https://stats.stackexchange.com/questions/650320/weight-initialisation-for-neural-networks-should-they-be-different-for-each-ob</link>
      <description><![CDATA[我正在实现一个带有前馈和反向传播的神经网络，并使用梯度下降来更好地理解事物的工作原理。
在设置了整个算法之后，我仍然有很大的疑问。当我初始化权重时，我会这样做，以便网络的每个节点都有自己的初始分配权重。我对数据集中的每个样本都这样做，这意味着对于每个样本，我都会初始化不同的权重。这是正确的吗，还是所有样本的初始权重都应该相同？
举个例子来澄清我的问题：假设我有一个非常简单的网络，只有输入层和输出层。输入有 2 个节点。数据集有 2 个观测值。我现在要做的是，对于每个观测值，我初始化 2 个权重并将它们分配给输入节点，这样最终我就有了 4 个不同的权重。我是否应该只初始化 2 个权重并将它们分配给两个观测中的相应节点，以便两个节点在所有观测中都具有相同的权重值？
我现在正在做什么：
-observation1
-node1：weight1
-node2：weight2
-observation2
-node1：weight3
-node2：weight4

我想知道我应该做什么：
-observation1
-node1：weight1
-node2：weight2
-observation2
-node1：weight1
-node2：weight2
]]></description>
      <guid>https://stats.stackexchange.com/questions/650320/weight-initialisation-for-neural-networks-should-they-be-different-for-each-ob</guid>
      <pubDate>Tue, 02 Jul 2024 14:06:35 GMT</pubDate>
    </item>
    <item>
      <title>确定检验统计量的 p 值，该值不按照零假设下的常见分布进行分布</title>
      <link>https://stats.stackexchange.com/questions/650363/determining-the-p-value-of-a-test-statistic-which-is-not-distributed-according</link>
      <description><![CDATA[目前，我正在使用 R 语言进行一个项目，该项目旨在识别大型数据集中的龙王事件（大量异常值）。这些异常值出现在英格兰的城市规模中，其中伦敦是异常值。
我遇到的问题是，我正在使用 Spencer Wheatly 和 Didier Sornette 的论文“具有指数和帕累托尾部的样本中的多重异常值检测：挽救内向方法和检测龙王”中描述的测试统计数据。具体来说，问题是这些测试统计数据不遵循零假设（数据集中不存在异常值）下的通常分布。上面提到的参考文献确实提到了其他论文，这些论文似乎应该阐明分布函数，但这些论文似乎不太适用，因为它们要么非常过时，要么没有讨论原始参考文献中的检验统计量。
我现在所做的是进行模拟，其中我运行了许多不同的零假设情况并对其使用了检验统计量，然后使用 R 中的 ecdf 函数经验地计算了分布函数。这给了我一个可靠的经验分布函数，我不得不相信。不幸的是，我计算的 p 值似乎不太合理。这是因为当我计算明显包含异常值的样本的 p 值时，p 值不足以拒绝零假设。因此，我认为我一定是误解了什么或做错了什么。
我原本希望能够复制原始参考文献中的图表（例如第 10 页），但迄今为止无法做到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/650363/determining-the-p-value-of-a-test-statistic-which-is-not-distributed-according</guid>
      <pubDate>Tue, 02 Jul 2024 12:59:36 GMT</pubDate>
    </item>
    </channel>
</rss>