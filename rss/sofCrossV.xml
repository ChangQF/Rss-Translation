<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 15 Apr 2024 21:14:27 GMT</lastBuildDate>
    <item>
      <title>如何处理这种非常嵌套的数据</title>
      <link>https://stats.stackexchange.com/questions/645089/how-to-deal-with-this-very-nested-data</link>
      <description><![CDATA[编辑：我认为这正在做我需要做的事情？
lm.mymod &lt;- lmer(score ~ session_n (1 + session_n|subject_ID) + 性别 + Predictor_1 + Predictor_2, data = data)

我运行了很多模型，但我非常非常困惑。
我已附上与我的结构相匹配的示例数据图像。我每次对话都有一个分数（分数是我的结果变量）。对于每次对话，我都会对感兴趣的预测变量进行多次测量（如图所示 predictor_1）。我对 predictor_1 的测量是在细粒度范围内进行的，因此每个 conversation_id 有 200 行。受试者将有多个对话（每个 conversation_id 都是唯一的）和 session_n 最多 20 个。我对我的 predictor_ns 的效果感兴趣，session_n 和性别。我知道我需要对 client 进行随机拦截，但我觉得我需要某种方法来捕获我对每个 conversation_id 进行重复测量的事实。我的一些预测变量可以比我的结果变量更细粒度地捕获吗？
我的初始模型：
lm.mymod &lt;- lmer(分数 ~ (1|subject_ID) + 性别 + session_n + Predictor_1 + Predictor_2, data = data)

我认为这是不对的 - 性别和 session_n 的影响非常强大，因为它把它当作我对这些的测量比实际做的更多。
我觉得最简单的事情就是在 conversation_id 上平均我的 predictor_ns - 但有没有办法可以以嵌套的方式表示它？
这看起来很合理，但未能收敛，我认为 b/c 对于每个 conversation_id 只有一个分数值：
lm.mymod &lt;- lmer(分数 ~ (1|subject_ID / Conversation_id) + 性别 + session_n + Predictor_1 + Predictor_2, data = data)

我对 session_n 的固定效果感兴趣（我希望它随着我的分数而增加），所以我不想这样做：
lm.mymod &lt;- lmer(分数 ~ (1|subject_ID) + (1|session_n) + 性别 + Predictor_1 + Predictor_2, data = data)

我非常感谢任何帮助或指导。我现在可能只是对 conversation_id 进行平均。
]]></description>
      <guid>https://stats.stackexchange.com/questions/645089/how-to-deal-with-this-very-nested-data</guid>
      <pubDate>Mon, 15 Apr 2024 20:48:56 GMT</pubDate>
    </item>
    <item>
      <title>涉及 $\chi^2$ 距离的假设检验上限</title>
      <link>https://stats.stackexchange.com/questions/645087/hypothesis-testing-upper-bound-involving-chi2-distance</link>
      <description><![CDATA[在此[注]https://www.stat。 cmu.edu/~larry/=stat705/Lecture27.pdf，作者在第4节中提供了一些涉及总变差距离和Hellinger距离的假设检验的上限。并且他还提到也存在这样的界限涉及 $\chi^2$ 距离，但本注释中未提供。
有人可以提供一些相关参考吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645087/hypothesis-testing-upper-bound-involving-chi2-distance</guid>
      <pubDate>Mon, 15 Apr 2024 20:20:35 GMT</pubDate>
    </item>
    <item>
      <title>如何模拟两个定义点之间的路径，同时定义总体步长方差？</title>
      <link>https://stats.stackexchange.com/questions/645086/how-can-i-simulate-the-path-between-two-defined-points-but-also-define-the-overa</link>
      <description><![CDATA[正如问题中所述。我想知道是否可以模拟两个固定点之间的随机游走（始终从 A 开始并在 B 结束），其中还定义了步长差异的方差。
示例：$A=100$、$B=125$
并且每一步的差值的总方差为5
我认为需要一些最小步骤数，这是 B-A 的函数，但我不确定如何考虑模拟它。
我短暂地偶然发现了布朗桥，但看起来我只能定义直接级别的标准偏差，而不能定义增量步骤。]]></description>
      <guid>https://stats.stackexchange.com/questions/645086/how-can-i-simulate-the-path-between-two-defined-points-but-also-define-the-overa</guid>
      <pubDate>Mon, 15 Apr 2024 19:46:56 GMT</pubDate>
    </item>
    <item>
      <title>具有不等方差和预先计划与事后的多重调整</title>
      <link>https://stats.stackexchange.com/questions/645082/multiplicity-adjustment-w-unequal-variance-pre-planned-vs-post-hoc</link>
      <description><![CDATA[这个问题的（唯一）答案说
&lt;块引用&gt;
如果您的因子的每个类别中数据的变异性是
非常数，这将使......你的多重性调整无效
事后 p 值。

为什么允许不等方差的韦尔奇检验不能与 错误发现率控制程序 或系列错误率控制程序？
这个答案也说
&lt;块引用&gt;
您是否会担心全局方差分析 p 值
因此取决于你的多重比较是否
预先计划好的。如果是，您可以忽略全局方差分析 p 值。
如果他们不是，你就不能。与计算机时代无关
有了它，真的。

如果多重比较是预先计划的，为什么很重要？为什么不能预先计划将它们全部进行比较（使用计算机）？
（FWIW，我希望这是对引用答案的评论，但没有足够的声誉。）]]></description>
      <guid>https://stats.stackexchange.com/questions/645082/multiplicity-adjustment-w-unequal-variance-pre-planned-vs-post-hoc</guid>
      <pubDate>Mon, 15 Apr 2024 19:01:08 GMT</pubDate>
    </item>
    <item>
      <title>我可以在扩散模型中使用更简单的损失函数（例如直接似然损失）吗？</title>
      <link>https://stats.stackexchange.com/questions/645081/can-i-use-a-simpler-loss-function-e-g-direct-likelihood-loss-in-diffusion-mod</link>
      <description><![CDATA[训练扩散模型时，可以选择定义损失函数。常见的包括根据高斯分布的均值或噪声定义损失函数。但它总是从最大化预测 x0 为或接近实际 x0 的可能性开始。然后需要数学推导来用平均值或噪声来表达损失。
我的问题是我们可以直接使用（负）可能性作为损失吗？ IE。在训练步骤中，我们知道 Xt 并尝试预测 Xt-1，然后对于每个像素 (i, j) 如果预测的 &lt; code&gt;Xt-1(i,j) != 实际的 Xt-1(i,j) 那么这就会导致损失。我所描述的只是训练/收敛速度慢还是不正确？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/645081/can-i-use-a-simpler-loss-function-e-g-direct-likelihood-loss-in-diffusion-mod</guid>
      <pubDate>Mon, 15 Apr 2024 18:49:38 GMT</pubDate>
    </item>
    <item>
      <title>变量重要性图 - 逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/645078/variable-importance-plots-logistic-regression</link>
      <description><![CDATA[在R中生成变量重要性图，对于逻辑回归，可以直接使用函数varImp来生成重要性吗？是否需要进行训练/测试分开？例如，假设它是一个普通的逻辑回归模型，没有创建训练/测试分割，那么 varImp() 仍然有效吗？或者R中还有其他函数需要使用吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645078/variable-importance-plots-logistic-regression</guid>
      <pubDate>Mon, 15 Apr 2024 18:26:15 GMT</pubDate>
    </item>
    <item>
      <title>XGB Predict_proba 估计与叶子总和不匹配</title>
      <link>https://stats.stackexchange.com/questions/645075/xgb-predict-proba-estimates-dont-match-sum-of-leaves</link>
      <description><![CDATA[当在二元分类中使用 XGB 模型时，我观察到由 predict_proba 给出的测试估计接近但不等于我通过对相应叶子的输出求和而获得的结果每个观察值，然后使用逻辑函数 $\frac{e^x}{1+e^x}$。为什么会出现这种情况？我没有考虑到什么？如何使用树的各个输出重新创建 predict_proba 的结果？
我的代码（基于 XGB 文档页面中给出的示例）首先拟合模型：
from sklearn.datasets import load_iris
从 xgboost 导入 XGBClassifier
从 sklearn.model_selection 导入 train_test_split
数据 = load_iris()
X_train, X_test, y_train, y_test = train_test_split(数据[&#39;数据&#39;][数据[&#39;目标&#39;]!=2],
数据[&#39;目标&#39;][数据[&#39;目标&#39;]！=2]，test_size=.2，random_state=42）
# 创建模型实例
bst = XGBClassifier(n_estimators=5, max_深度=2,learning_rate=0.5,
目标=&#39;二进制：逻辑&#39;，colsample_bytree=0.3）
# 拟合模型
bst.fit(X_train, y_train)

完成此操作后，我能够检索模型的各个树并将它们硬编码到函数中以获取数组中的树输出：
def empiric_model(X):
    # t0,...,t4 是树，f0, f1, f2 是特征
    t0 = -0.952112317 if (X[&#39;f2&#39;]&lt;3).all() else 0.869410515
    t1 = -0.462368667 if (X[&#39;f0&#39;]&lt;5.5).all() else 0.51116854
    t2 = -0.571811914 if (X[&#39;f2&#39;]&lt;3).all() else 0.569128871
    t3 = 0.403415382 if (X[&#39;f1&#39;]&lt;3).all() else 0.0914318636 if ((3&lt;=X[&#39;f1&#39;])&amp;(X[&#39;f1&#39;]&lt;3.0999999)).all () else -0.11495477 if ((3.0999999&lt;=X[&#39;f1&#39;])&amp;(X[&#39;f1&#39;]&lt;3.4000001)).all() else -0.417713255
    t4 = 0.318558067 if (X[&#39;f1&#39;]&lt;3).all() else 0.0555250905 if ((3&lt;=X[&#39;f1&#39;])&amp;(X[&#39;f1&#39;]&lt;3.20000005)).all ()否则-0.309806734
    返回 np.array([t0, t1, t2, t3, t4])

然后我比较了 bst.predict_proba(X_test)[:,1] 以及转换为概率的叶子输出的总和。比较结果如下图所示：
# 每个测试观察的叶输出总和
empirics = np.array([empiric_model(pd.DataFrame(X_test[i:i+1,:], columns=[&#39;f0&#39;,&#39;f1&#39;,&#39;f2&#39;,&#39;f3&#39;])).sum() for我在 np.arange(X_test.shape[0])])
# 使用逻辑函数将其转换为概率
empiric_probas = np.exp(经验)/(1+np.exp(经验))
Predicted_probas = bst.predict_proba(X_test)[:,1]
plt.scatter(x=np.arange(empiric_probas.size), y=empiric_probas, c=&#39;b&#39;, label=&#39;empiric&#39;)
plt.scatter(x=np.arange(empiric_probas.size), y=predicted_probas, c=&#39;r&#39;, label=&#39;预测&#39;)
plt.xticks(np.arange(empirico_probas.size))
plt.yticks(np.arange(0,1.1,0.2))
plt.legend(loc=&#39;中右&#39;)


我将明确显示这些值：
empiric_probas 是：
数组([0.9353348, 0.9353348, 0.86878725, 0.13712985, 0.06216319,
   0.08233362、0.06216319、0.9353348、0.06216319、0.06216319、
   0.14927792、0.11448531、0.9353348、0.14927792、0.9353348、
   0.06216319、0.9353348、0.8905786、0.13712985、0.08233362])

而predicted_probas是：
数组([0.9411262, 0.9411262, 0.8354762, 0.1493973, 0.06825472,
   0.06825472、0.06825472、0.9411262、0.06825472、0.06825472、
   0.16242756、0.12502052、0.9411262、0.16242756、0.9411262、
   0.06825472, 0.9411262, 0.89994967, 0.1493973, 0.06825472])

正如您所看到的，它们相似但不相等。]]></description>
      <guid>https://stats.stackexchange.com/questions/645075/xgb-predict-proba-estimates-dont-match-sum-of-leaves</guid>
      <pubDate>Mon, 15 Apr 2024 17:13:03 GMT</pubDate>
    </item>
    <item>
      <title>f检验和t检验之间的关系[重复]</title>
      <link>https://stats.stackexchange.com/questions/645073/relationship-between-f-test-and-t-test</link>
      <description><![CDATA[我正在解决一个问题，我应该从给定方差分析表（如下）的 f 检验中得出 t 检验统计量。根据我的理解，当我们进行f检验时，我们使用方差来确定一组中是否存在差异，而对于t检验，我们是比较个体均值差异，t检验可以通过以下方式获得： f 检验的平方根。
所以，如果我想找到下面农药和植物类型的相互作用项的 t 统计量，我可以简单地取表中给出的 ftest 的平方根吗？如果是这样，我如何确定度数这个 t 统计量的自由度是多少？我只是想更好地理解两者之间的关系。
]]></description>
      <guid>https://stats.stackexchange.com/questions/645073/relationship-between-f-test-and-t-test</guid>
      <pubDate>Mon, 15 Apr 2024 16:33:57 GMT</pubDate>
    </item>
    <item>
      <title>如何计算加权平均值作为集中趋势的度量？</title>
      <link>https://stats.stackexchange.com/questions/645071/how-to-compute-a-weighted-mean-as-a-measure-of-central-tendency</link>
      <description><![CDATA[假设我有一式三份的数据点，如下所示
$$
L=\begin{p 矩阵}
p_{11} &amp; p_{12} &amp; p_{13}\\
p_{21} &amp; p_{22} &amp; p_{23}\\
&amp; \vdots &amp;\\
p_{n1} &amp; p_{n2} &amp; p_{n3}
\end{p 矩阵}
$$
过滤这些数据的最佳方法是什么，以便我删除异常值并最终得到最佳拟合值的向量
$$
\tilde{L}=(\tilde{p}_1,\tilde{p}_2,\cdots,\tilde{p}_n)
$$
想法：例如，如果我有情节

我自然可以取这些值的平均值（蓝色）

但显然，在 $n=5$ 我有一个潜在的异常值，可以将其删除以获得更好的拟合。 根据整个数据集为每个三次重复分配加权平均值（可能基于三次重复之间的平均标准差）的理想技术是什么？我听说过库克距离，但我不太确定如何在这里应用它.
有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/645071/how-to-compute-a-weighted-mean-as-a-measure-of-central-tendency</guid>
      <pubDate>Mon, 15 Apr 2024 15:46:47 GMT</pubDate>
    </item>
    <item>
      <title>选择样本进行卡方独立性检验</title>
      <link>https://stats.stackexchange.com/questions/645069/choosing-a-sample-for-a-chi-square-test-of-independence</link>
      <description><![CDATA[对于我正在处理的数据集，我有大约 2000 个观察值。有一些分类变量和一个二分结果变量。
我正在尝试获取预测变量。我可以使用整个数据集（而不是样本）来开发卡方独立性检验来确定两个分类变量之间的关联吗？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/645069/choosing-a-sample-for-a-chi-square-test-of-independence</guid>
      <pubDate>Mon, 15 Apr 2024 15:40:57 GMT</pubDate>
    </item>
    <item>
      <title>非平稳性和面板数据</title>
      <link>https://stats.stackexchange.com/questions/645063/non-stationarity-and-panel-data</link>
      <description><![CDATA[当我们回归两个独立的非平稳时间序列时，就会发生虚假回归：
$$y_t = y_{t-1} + u_t \qquad x_t = x_{t-1} + v_t \qquad \operatorname{corr}(y_t, x_t) = 0$$
那么如果我们进行以下回归
$$y_t = \beta_1 x_t + \varepsilon_t$$
我们预计系数 $\beta_1$ 具有统计显着性，概率高于 5%。
但是，如果我们做面板数据，我们通常会遇到类似的问题：
$$y_{it} = \beta_1 x_{it} + \varepsilon_{it}$$
那么，当 $y_{it}$ 和 $x_{it}$ 时会发生什么不相关，但数据集中的所有单位也是 RW？
&lt;小时/&gt;
问题
使用（大多是短的）面板数据时，非平稳性假设有多重要？它与时间序列相同吗？或者我们可以期望添加的单位来缓解问题（即使这两个变量对于所有单位来说都是非平稳的）？
面板数据的经典方法（Pooled、FD、FE、RE）能否解决面板数据的非平稳性问题（例如，FD 具有差异性，因此它应该可以缓解该问题在某种程度上的非平稳性）以及如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/645063/non-stationarity-and-panel-data</guid>
      <pubDate>Mon, 15 Apr 2024 13:48:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么差分白噪声会导致 $-0.5$ 的自相关？</title>
      <link>https://stats.stackexchange.com/questions/645047/why-does-differencing-white-noise-induce-autocorrelation-of-0-5</link>
      <description><![CDATA[我很好奇以下问题。让我们有一个由白噪声给出的变量，
$$y_t \sim \operatorname{NID}(0,1).$$
假设我们对其进行了区分，
$$\Delta y_t = y_t - y_{t-1}.$$
现在，如果我们测量 $\Delta y_t$ 的 ACF，我们会发现第一个滞后与 $-0.5$。
问题是：为什么要$-0.5$，特别是？]]></description>
      <guid>https://stats.stackexchange.com/questions/645047/why-does-differencing-white-noise-induce-autocorrelation-of-0-5</guid>
      <pubDate>Mon, 15 Apr 2024 11:26:39 GMT</pubDate>
    </item>
    <item>
      <title>如何分解条件后验概率？</title>
      <link>https://stats.stackexchange.com/questions/645029/how-to-decompose-the-conditional-posterior-prob</link>
      <description><![CDATA[我现在正在学习贝叶斯推理。我经常遇到的一个问题是，当我需要计算或简化后验概率时，我不知道应该如何开始，根据我所拥有的。
例如，假设 $$ y\mid\mu, \sigma^2 \sim N(\mu_j, \sigma^2)$$
和 $$ \mu_j \sim N(\theta, \tau^2) $$
其中 $y_i\mid\mu_j,\sigma^2 $ 是 iid，$\mu_j\mid\theta, \tau ^2$ 是独立同分布。
如何分解 $p(\mu_j \mid \sigma^2, \tau^2, \theta,y)$ 和 $p(\theta \mid \sigma^2, \tau^2, \mu,y)$?
即 $p(\mu_j \mid \sigma^2, \tau^2, \theta,y) \propto ?$
如果你想用其他例子来解释分解后验分布的一般方法，那也会有很大帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/645029/how-to-decompose-the-conditional-posterior-prob</guid>
      <pubDate>Mon, 15 Apr 2024 02:41:06 GMT</pubDate>
    </item>
    <item>
      <title>我的 glmer 输出有我的固定效应被分成我的因变量的多个因素，我不知道为什么</title>
      <link>https://stats.stackexchange.com/questions/645028/my-glmer-output-has-my-fixed-effects-are-being-split-into-the-multiple-factors-o</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/645028/my-glmer-output-has-my-fixed-effects-are-being-split-into-the-multiple-factors-o</guid>
      <pubDate>Mon, 15 Apr 2024 02:16:28 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归系数标准误的计算/推导</title>
      <link>https://stats.stackexchange.com/questions/645013/working-out-derivation-of-standard-error-of-coefficient-in-logistic-regression</link>
      <description><![CDATA[让我们保持简单，只使用简单 Logistic 回归，其中只有 1 个连续自变量。
即Log(P/1-P)=B0 + B1X1
如何计算得出 B1 系数的标准误差？或者公式是什么样的？我还希望看到不涉及线性代数和矩阵的解决方案。
我猜它看起来不会像简单线性回归中 B1 系数的标准误差公式，即 √(s^2 / (Xi - Xbar)^2)
或者会吗？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/645013/working-out-derivation-of-standard-error-of-coefficient-in-logistic-regression</guid>
      <pubDate>Sun, 14 Apr 2024 21:32:48 GMT</pubDate>
    </item>
    </channel>
</rss>