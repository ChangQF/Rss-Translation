<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 18 Sep 2024 15:18:00 GMT</lastBuildDate>
    <item>
      <title>为什么项目反应理论不依赖于代表性样本，或者为什么它是“样本独立的”？</title>
      <link>https://stats.stackexchange.com/questions/654551/why-does-item-response-theory-not-depend-on-a-representative-sample-or-why-is-i</link>
      <description><![CDATA[多种资源描述了项目反应理论 (IRT) 并将其与传统测试理论 (CTT) 进行了比较，指出 CTT 依赖于代表性样本，而 IRT 则不然。

样本独立性：传统统计数据都依赖于样本，并且无法用于不同的样本；而 IRT 的结果与样本无关。在线性变换内。两个不同能力水平的样本可以轻松转换为同一量表。
项目属性不依赖于代表性样本。


这些资源似乎将此陈述为两种理论和建模方法之间的事实区别，但我不明白为什么这必然是正确的。项目参数在不同人群之间可能存在不同差异，难道不是这样吗？这种说法的重点是，如果没有发生差异项目功能 (DIF)，那么您可以有信心地说它不依赖于代表性样本吗？但是，如果这是对那条的解释，我仍然不明白，因为 CTT（即 SEM、CFA）也涉及测量不变性的测试。
有人能帮我理解为什么 IRT 不依赖于代表性样本或“样本独立”吗？
资源：
https://www.publichealth.columbia.edu/research/population-health-methods/item-response-theory
https://assess.com/what-is-item-response-theory/]]></description>
      <guid>https://stats.stackexchange.com/questions/654551/why-does-item-response-theory-not-depend-on-a-representative-sample-or-why-is-i</guid>
      <pubDate>Wed, 18 Sep 2024 14:47:00 GMT</pubDate>
    </item>
    <item>
      <title>如何在以下问题中微调集成级超参数？</title>
      <link>https://stats.stackexchange.com/questions/654550/how-to-fine-tune-an-ensemble-level-hyper-parameter-in-the-following-problem</link>
      <description><![CDATA[我有一个相对较小的数据集，包含 4000 个实例。我打算使用集成方法进行分类。我的集成由 5 个不同的分类器组成，并且我有一个集成级超参数 S。
我计划按照以下步骤训练和评估我的集成模型：

将初始数据集分为 70% 训练、15% 验证和 15% 测试。
使用 5 倍交叉验证在训练数据集上训练每个分类器（在每种情况下，在 4 个折叠上进行训练并评估 1 个保留折叠的准确性）。
根据每个分类器在所有 5 个保留折叠（即整个训练数据集）中的平均准确性，确定每个分类器的权重。在权重计算公式中有一个集成级超参数S，初始化为[0,1]内的随机值。
为了微调S，使用上一步计算出的分类器权重，评估集成模型在验证数据集上的性能。更改S的值，根据新的S值重新计算分类器权重，并重新评估集成模型在验证数据集上的性能，并重复，直到集成性能最大化或达到特定的迭代次数。
在确定S的最终值和相应的分类器权重后，评估集成模型在测试数据集（未见数据）上的性能。

我担心的是，超参数S的微调是在每次迭代中使用整个验证数据集进行的。例如，将验证数据集拆分为 3 个子集（考虑到我的数据集很小），然后针对 S 的每个值评估集成在所有 3 个子集中的平均性能，这样是否更合适？或者我上面描述的初始方法是否足够（考虑到数据集的大小较小）？]]></description>
      <guid>https://stats.stackexchange.com/questions/654550/how-to-fine-tune-an-ensemble-level-hyper-parameter-in-the-following-problem</guid>
      <pubDate>Wed, 18 Sep 2024 14:19:20 GMT</pubDate>
    </item>
    <item>
      <title>使用不同的数据集时是否允许使用交叉验证？</title>
      <link>https://stats.stackexchange.com/questions/654548/is-it-allowed-to-use-cross-validation-when-working-with-different-datasets</link>
      <description><![CDATA[如果我有两个具有相同特征但来自不同主题的数据集，并且我想在第一个数据集上训练模型（例如 SVM）并在第二个数据集上测试它，我应该如何计算性能（例如准确度）？我可以在训练和测试过程中使用 K 折交叉验证吗？还是应该只在同一数据集上训练和测试时使用 K 折交叉验证？我的意思是，在数据集上训练模型并在另一个数据集上测试时使用交叉验证是否可以接受？]]></description>
      <guid>https://stats.stackexchange.com/questions/654548/is-it-allowed-to-use-cross-validation-when-working-with-different-datasets</guid>
      <pubDate>Wed, 18 Sep 2024 13:18:29 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 0 至 1 范围内变量的优势比</title>
      <link>https://stats.stackexchange.com/questions/654542/how-to-interpret-odds-ratio-for-variables-that-range-from-0-to-1</link>
      <description><![CDATA[我该如何解释逻辑回归模型中变量的几率比，该变量是一个“比率”，即介于 0 和 1 之间的值？在这种情况下，单位是什么？
例如，假设我正在对篮球投篮数据进行建模，如果球员投篮成功，我的响应变量等于 1，如果投篮失败，则等于 0。此外，我有一个解释变量，即球队到那时为止的投篮准确率，这个变量的范围是 0 到 1。那么，我该如何解释这个变量的系数的几率比？因为我不能说它会增加 1 个单位，因为变量不能超过大于 1 的值。请问有什么关于如何解释这一点的提示吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654542/how-to-interpret-odds-ratio-for-variables-that-range-from-0-to-1</guid>
      <pubDate>Wed, 18 Sep 2024 11:35:11 GMT</pubDate>
    </item>
    <item>
      <title>异方差方差预测常数不应该是</title>
      <link>https://stats.stackexchange.com/questions/654541/heteroscedastic-variance-prediction-constant-where-it-should-not-be</link>
      <description><![CDATA[我正在尝试预测数据集中的异方差噪声。我已经设置了一个 FPN，将方差视为一个附加类。我的数据集是空中语义分割无人机数据集。这是模型：
class FPN(nn.Module):
def __init__(self,coder_name=&quot;resnet34&quot;,coder_weights=&quot;imagenet&quot;,in_channels=1,activation=None,decoder_dropout=0.3):
super(FPN,self).__init__()
self.base_model = smp.FPN(
encoder_name=encoder_name,
encoder_weights=encoder_weights,
in_channels=in_channels,
classes=2,
activation=activation,
decoder_dropout=decoder_dropout
)

def forward(self,x):
mean,var = torch.split(self.base_model(x),1,dim=1)
var = torch.nn. functional.softplus(var)
return torch.cat((mean,var), dim=1)

损失函数是 pytorch 的标准 NLL-Gaussian Loss：
class CustomGaussianLoss(base.Loss):
def __init__(self):
super(CustomGaussianLoss, self).__init__()
self.gaussian_nll_loss = nn.GaussianNLLLoss()

def forward(self, input, target):
mean, var = torch.split(input, 1, dim=1)

loss = self.gaussian_nll_loss(mean, target, var)
return loss 

然而，在第一个 epoch 之后，方差总是预测为每个像素的常数 0.69。像素值在 0 和 1 之间缩放。有趣的是，0.69 大致是数据集跨像素的方差。
鉴于这个数据集，这一切对我来说毫无意义。即使方差大致恒定（但事实并非如此），量级也是完全错误的。有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654541/heteroscedastic-variance-prediction-constant-where-it-should-not-be</guid>
      <pubDate>Wed, 18 Sep 2024 10:38:14 GMT</pubDate>
    </item>
    <item>
      <title>使用螺旋桨计算细胞比例是否显著</title>
      <link>https://stats.stackexchange.com/questions/654540/calculating-if-cell-proportions-are-significant-using-propeller</link>
      <description><![CDATA[我正在使用 propeller，https://rdrr.io/github/Oshlack/speckle/man/propeller.anova.html，来计算肥大细胞与对照组细胞比例之间的显著性。我的模型设计如下。
design &lt;- model.matrix(~0 + grp + md_subset$batch)

我理解不设置截距就没有基线水平，所有分类变量都表示为单独的列。所以我总共有 10 个样本，3 个对照组和 7 个肥大组，它们分 4 个批次完成。我的设计矩阵如下所示：

我对设计矩阵有几个问题。第一，为什么我的设计矩阵中没有 2 列，一列表示条件，该行是否用 0 表示控制，1 表示肥大，一列表示批次，行中用 1、2、3 或 4 表示，因为它们有 4 个批次？我看到的是每个条件都有自己的列，每个批次也是如此。在我看来这像是热编码，但为什么在这种情况下这是必要的？第二，如果热编码是必要的，并且这就是每个变量都有单独列的原因，那么为什么批次 1 列不存在，因为我的样本 3（第 3 行）是批次 1？这个设计矩阵是否不考虑批次 1 的影响？
最后，当我运行它时，我得到如下输出：
propeller.anova(prop.transformed, design=design, coef=c(1,2,3,4,5), robust=TRUE,
trend=FALSE, sort=TRUE)


首先，使用设计运行它是否意味着我正在查看在控制批次效应的情况下，条件之间每种细胞类型的比例有多大？我之所以问这个问题，是因为在我的理解中，通常在回归分析中，~ 之后的第一个变量是您要测试的变量，任何其他变量都是您想要控制的混杂因素。但是，在 DESeq2 或 edgeR 等包中，我看到控制的混杂因素首先出现，最后一个变量是您要测试响应变量与之相关的变量。此外，这里的 p 值和 F 统计量是否显示了条件对比例的影响有多大以及它是否显着？并且标记为 PropMean.* 的每一列表示不同细胞类型的该变量的系数？
我很感激任何帮助和澄清，因为我认为我主要理解但需要一些帮助和建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/654540/calculating-if-cell-proportions-are-significant-using-propeller</guid>
      <pubDate>Wed, 18 Sep 2024 09:48:03 GMT</pubDate>
    </item>
    <item>
      <title>当缺少时间点时，emmeans 和 mmrm</title>
      <link>https://stats.stackexchange.com/questions/654539/emmeans-and-mmrm-when-there-are-missing-timepoints</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654539/emmeans-and-mmrm-when-there-are-missing-timepoints</guid>
      <pubDate>Wed, 18 Sep 2024 09:27:00 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归与均值和方差相比，哪个估计更有效，为什么？</title>
      <link>https://stats.stackexchange.com/questions/654538/logistic-regression-versus-mean-and-variance-which-estimate-is-more-efficient-a</link>
      <description><![CDATA[让
$$\begin{array}{}
Y_i &amp; \sim&amp; Bernoulli(0.5) \\
X_i|Y_i &amp;\sim&amp; N(\mu_{Y_i},\sigma^2)
\end{array}$$
在这种情况下，我们可以考虑独立的观测对 $X_i,Y_i$，遵循逻辑回归模型，其中 $Y_i$ 具有条件伯努利分布，并且
$$P(Y_i=1|X_i=x) = \frac{1}{1+e^{-(a+bx)}}$$
其中 $a = \frac{\mu_1^2-\mu_0^2}{2\sigma^2}$ 和 $b=\frac{\mu_0-\mu_1}{\sigma^2}$
因此，我们可以用两种不同的方法估计这些参数$a$和$b$

执行逻辑回归。
直接用假设的正态分布估计$\mu_i$和$\sigma$，然后计算参数$a$和$b$。

这两种方法不会给出相同的结果。哪种方法最有效（具有预期平方误差）？

进一步澄清我的问题。这也是为了理解。
以下是一个模拟，表明均值和方差的估计导致较小的误差。它可以回答这个问题。

但它是通用的吗？
为什么逻辑回归不能达到同样的效果？
关于 $X_i$ 分布的知识增加了什么样的信息，是否可以将其纳入逻辑回归（例如通过增加权重）以使其表现更好？

set.seed(1)

sim = function(n, mu) {

Y = rbinom(n,1,0.5)
X = rnorm(n,Y*mu,1)

mod = glm(Y~X, family = binomial)
glm_est = mod$coefficients

m = c(mean(X[Y==0]),mean(X[Y==1]))
V = (sum((X-m[Y+1])^2)/(n-2))

mm_est = c(-diff(m^2)/2/V,
diff(m)/V)

return(c(glm_est,mm_est))
}

mu = 1
z = replicate(10^3,sim(200,mu))

true_a = -mu^2/2
true_b = mu

### glm_errors
mean((z[1,]-true_a)^2) # 0.03592216
mean((z[2,]-true_b)^2) # 0.03245813

### gaussian_mm_errors
mean((z[3,]-true_a)^2) # 0.01323784
mean((z[4,]-true_b)^2) # 0.03075781
]]></description>
      <guid>https://stats.stackexchange.com/questions/654538/logistic-regression-versus-mean-and-variance-which-estimate-is-more-efficient-a</guid>
      <pubDate>Wed, 18 Sep 2024 08:55:29 GMT</pubDate>
    </item>
    <item>
      <title>基于Gershgorin定理的实现方法</title>
      <link>https://stats.stackexchange.com/questions/654537/implement-method-based-on-gershgorin-s-theorem</link>
      <description><![CDATA[有人能帮忙实现（在 Python 中）一个函数/算法吗？该函数/算法利用 Gershgorin 定理通过返回磁盘中心/特征值和半径来定位矩阵的特征值。我曾尝试查看 https://github.com/HowDoIUseThis/GershgorinCircles/blob/master/EAprox.py，但似乎不是我真正想要的。它似乎还为其他矩阵示例提供了错误的图表，但也许你们中的任何一个人都可以使用其中的想法来解决这个问题。格什戈林定理可在此处找到 https://mathworld.wolfram.com/GershgorinCircleTheorem.html]]></description>
      <guid>https://stats.stackexchange.com/questions/654537/implement-method-based-on-gershgorin-s-theorem</guid>
      <pubDate>Wed, 18 Sep 2024 08:53:45 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 R 中的逐次试验数据运行重复测量方差分析？</title>
      <link>https://stats.stackexchange.com/questions/654535/how-can-i-run-a-repeated-measures-anova-in-r-with-trial-by-trial-data</link>
      <description><![CDATA[我需要帮助设置数据集并在 R 中运行重复测量方差分析。我当前的数据集是 41 个受试者的试验数据。有一列表示受试者 ID（1-41），一列表示受试者所属的组（“置信度”或“定位”），一列表示相位（“前”或“后”），一列表示滞后位置（1-7），一列表示准确度（0 或 1）。每个受试者有 140 行：其中 70 行来自受试者“前”试验，70 行来自受试者“后”试验。在每组 70 行中，7 个滞后位置（1-7）各有 10 行。准确度是因变量。
我尝试过许多不同的方法，但我认为方差分析一直将数据视为每次试验都是不同的受试者。残差或 DenDF 中的 df 会返回 5166 或 5673 之类的数字，具体取决于我尝试的方法。我对 R 和运行方差分析还很陌生，正在尝试复制已经完成的分析。阶段 * 组 * 滞后的残差 df 应该是 234，而不是 5,000+]]></description>
      <guid>https://stats.stackexchange.com/questions/654535/how-can-i-run-a-repeated-measures-anova-in-r-with-trial-by-trial-data</guid>
      <pubDate>Wed, 18 Sep 2024 00:53:18 GMT</pubDate>
    </item>
    <item>
      <title>估计玩硬币 1 的后验概率</title>
      <link>https://stats.stackexchange.com/questions/654521/estimating-the-posterior-probability-of-playing-coin-1</link>
      <description><![CDATA[假设某人有两枚硬币，正面朝上的概率为 $p_1$，正面朝上的概率为 $p_2$，而正面朝上的概率为 $p_2\le p_1$。该人正在抛硬币，并且可能会以 $\gamma$ 的概率从掷硬币 1 切换到掷硬币 2，但是一旦他们开始掷第二枚硬币，他们就不会再切换回掷第一枚硬币。我们看到了结果，但是我们不知道该人是掷第一枚硬币还是掷第二枚硬币。假设我们不知道$p_1$、$p_2$和$\gamma$的确切值，我们如何计算该人所玩的硬币是第二枚硬币的后验概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/654521/estimating-the-posterior-probability-of-playing-coin-1</guid>
      <pubDate>Wed, 18 Sep 2024 00:18:40 GMT</pubDate>
    </item>
    <item>
      <title>如果病例总数有限，则确定抽样规模[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654503/sampling-size-determination-if-total-number-of-cases-is-finite</link>
      <description><![CDATA[我正在尝试确定每个月应审核多少个案例，以便样本量准确代表每年收到的案例总数。
尝试审核员工调查的内容。1400 个案例无法审核，那么审核内部程序和流程内容的合理数量是多少。这是否类似于随机抽样汽车零件以检测公差并尝试根据正在制造的零件总数确定抽样数量？
每年收到 1400 份调查。我使用 calculator.net 样本量计算器来确定样本量。 https://www.calculator.net/sample-size-calculator.html?type=1&amp;cl=95&amp;ci=5&amp;pp=50&amp;ps=1400&amp;x=Calculate
今年的答案是 302 个样本。
25/月。
4 个团队。
6/团队
这种方法正确吗？所以每个团队每个月应该审查 6 个案例？]]></description>
      <guid>https://stats.stackexchange.com/questions/654503/sampling-size-determination-if-total-number-of-cases-is-finite</guid>
      <pubDate>Tue, 17 Sep 2024 19:11:49 GMT</pubDate>
    </item>
    <item>
      <title>关于双变量分布的估计</title>
      <link>https://stats.stackexchange.com/questions/654493/on-estimation-of-bivariate-distribution</link>
      <description><![CDATA[我正在处理一个具有累积分布函数$F(x, y)$的非负、绝对连续的双变量随机向量，并且我正在尝试使用 Epanechnikov 核来估计$$\int_0^{t_1}F^2(x_1,t_2)dx_1$$。对此的估计定义为
$$\widehat{I}=\frac{1}{n^2h_1^2h_2^2}\int_0^{t_1}\left(\sum_{i=1}^n K\left(\frac{x_1-X_{1i}}{h_1}\right)K\left(\frac{t_2-X_{2i}}{h_2}\right)\right)^2dx_1$$
我在模拟中使用双变量Gumbel分布。下面是我的代码，但我很难为双变量数据选择合适的带宽，而且我得到的估计值与真实值有显著差异。
library(stats)
library(ks)
n &lt;- 40
lambda1 = 2
lambda2 = 0.5
theta = 0.5

for (i in 1:100) {
X1 &lt;- rexp(n, lambda1)
X2 = rgamma(n, (runif(n) &gt; 1 - theta/(1 + lambda1 * theta)) + 1, lambda2 * (1 + lambda1 * theta * X1))
sigma1 &lt;- sd(X1)
sigma2 &lt;- sd(X2)
h1 &lt;- 0.5
h2 &lt;- 0.55
t1 &lt;- 0.2
t2 &lt;- 0.3

epan_kernel_cdf &lt;- function(u) {
0.25 * (3 * u - u^3)
}

积分1 &lt;- sapply(X1, function(Xi) h1 * epan_kernel_cdf((t1 - Xi) / h1))
积分2 &lt;- sapply(X2, function(Yi) h2 * epan_kernel_cdf((t2 - Yi) / h2))

被积函数 &lt;- function(x1) {
kernel_cdf_values &lt;- sapply(X1, function(X1) epan_kernel_cdf((x1 - X1) / h1))
prod_kernel &lt;- kernel_cdf_values * 积分 2
sum_kernel &lt;- sum(prod_kernel)
(sum_kernel)^2
}

x_vals &lt;-seq(0,t1,length.out = 10000)
dx &lt;-x_vals[2]-x_vals[1]
sum_approx &lt;-sum(sapply(x_vals,integrand))*dx
estimated_value &lt;-(1/(n^2*h1^2*h2^2))*sum_approx
true_value &lt;-0.98

bias[i] &lt;-estimated_value[1]-true_value
MSE[i] &lt;-mean((estimated_value[1]-true_value[1])^2)
}

bias
MSE
bias1 &lt;-mean(bias)
bias1
MSE1 &lt;- 平均值 (MSE)
MSE1

我面临的一些具体问题：

为我的双变量数据选择合适的带宽。
我的估计值与真实值 (0.98) 相差甚远。

如果您能提供任何关于如何改进带宽选择或我应该在代码中进行的其他调整的见解或建议，我将不胜感激。提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654493/on-estimation-of-bivariate-distribution</guid>
      <pubDate>Tue, 17 Sep 2024 16:55:15 GMT</pubDate>
    </item>
    <item>
      <title>比较具有和不具有交互项的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/654485/comparing-linear-mixed-models-with-and-without-interaction-terms</link>
      <description><![CDATA[我想比较具有和不具有交互项的不同模型，看看哪一个最适合我的数据。我只是想检查我的方法是否正确。
我像这样构建我的模型
my_model &lt;- lmer(myoutcome ~ predictor1 + predictor2 + 
predictor3 + covariate1 + (1 | ParticipantID), data = mydata)

my_model2 &lt;- lmer(myoutcome ~ predictor1*predictor2 + 
predictor1*predictor3 + predictor2*predictor3 + covariate1 +
(1 | ParticipantID), data = mydata)

my_model3 &lt;- lmer(myoutcome ~ predictor1*predictor2*predictor3 + 
covariate1 + (1 | ParticipantID), data = mydata)

然后，我会像这样比较它们，看看添加二向和三向交互项是否会改善模型。
anova(my_model, my_model2, my_model3)

我还在考虑简约性、AICc 和对数似然等因素。
我有以下问题：

将所有双向交互项都包含在单个模型中是否正确？
在更复杂的模型中同时指定主效应和交互作用是否正确？ （因此 predictor1*predictor2 而不是 predictor1:predictor2
如果我对所有双向交互都不感兴趣，我是否可以将 my_model2.1 &lt;- lmer(myoutcome ~ predictor1*predictor2 + predictor3 + covariate1 + (1 | ParticipantID), data = mydata) 之类的模型与 model3 进行比较？
我还应该将我的协变量包括在我的交互模型中吗？
在报告主要影响和交互作用时，我被教导要报告第一个模型的主要影响，并且只报告交互模型的交互影响。但是我现在质疑这是否正确。例如，使用上述方法，我得到了以下仅具有固定效应的模型摘要（model_mainef）

 估计 2.5% 97.5% t val. d.f. p

（截距）2.93 2.60 3.25 17.49 99.21 0.00
predictor1 0.04 -0.25 0.34 0.29 66.86 0.78
predictor2 1.07 0.65 1.49 4.96 69.07 0.00
predictor3 0.22 0.04 0.41 2.40 71.43 0.02
covariate1 -0.23 -0.58 0.12 -1.30 69.20 0.20

此摘要包含一个双向交互 (model_int)

Est. 2.5% 97.5% t 值 d.f. p

（截距）2.61 2.27 2.94 15.18 112.75 0.00
预测器1 0.72 0.35 1.09 3.84 68.01 0.00
预测器2 1.70 1.22 2.18 6.94 112.40 0.00
预测器3 0.22 0.04 0.40 2.43 72.87 0.02
协变量1 -0.24 -0.58 0.10 -1.37 70.89 0.17
预测器1：预测器2 -1.32 -1.83 -0.81 -5.05 66.26 0.00

anova(model_mainef, model_int)

npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) 
model_mainef 7 406.98 427.37 -196.49 392.98 
model_int 8 385.94 409.24 -184.97 369.94 23.043 1 1.584e-06 ***


我们可以看到，在仅有固定效应的模型中不显著的变量之一（第二行），在将交互项纳入模型后变得显著（它是交互中的变量之一）。报告结果时，我应该使用第一个还是第二个表中的值？请注意，我不是在谈论解释 - 因为交互作用无论如何都符合主效应，我只是想知道哪些数据应该包含在我的结果表中 :)
提前致谢！
编辑：我有一个 2x2 混合组研究设计，其中一个组间变量（2 个级别）和一个组内变量（2 个级别），因此我使用混合建模。我收集了用于验证性假设检验（即推断统计）的数据]]></description>
      <guid>https://stats.stackexchange.com/questions/654485/comparing-linear-mixed-models-with-and-without-interaction-terms</guid>
      <pubDate>Tue, 17 Sep 2024 13:38:00 GMT</pubDate>
    </item>
    <item>
      <title>运行 G*Power 以使用泊松回归计算样本量的指南</title>
      <link>https://stats.stackexchange.com/questions/654459/guidance-on-running-gpower-to-calculate-the-sample-size-using-poisson-regressio</link>
      <description><![CDATA[我正在写一篇论文，以确定远程学习之前和远程学习之后的具体纪律处分数量（5 个计数因变量）是否存在差异（具有 2 个级别的分类自变量）。我计划使用泊松回归进行分析。我想我知道尾部、误差和功效。其他输入我不确定。我不确定 exp、基准利率、平均暴露、r² 其他 x 和 x parm π 应该输入什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/654459/guidance-on-running-gpower-to-calculate-the-sample-size-using-poisson-regressio</guid>
      <pubDate>Tue, 17 Sep 2024 02:25:56 GMT</pubDate>
    </item>
    </channel>
</rss>