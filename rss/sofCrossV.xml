<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 10 Jan 2025 21:15:19 GMT</lastBuildDate>
    <item>
      <title>BIBD 块内分析问题</title>
      <link>https://stats.stackexchange.com/questions/659837/bibd-intrablock-analysis-issue</link>
      <description><![CDATA[我很难理解 Peter W. M. John 所著《实验的统计设计和分析》中平衡不完全区组设计部分提出的这个问题。问题如附图所示。
示例问题第 1 部分
示例问题第 2 部分
为了便于复制我的问题，下面是值表，其中每行是一个块，每组 4 个连续行组成一个组：



处理
值
处理
值




A
38
B
29


C
49
D
&lt; td&gt;28


E
32
F
29


G
64
H
32


A
37
C
27


B
37
H
50


D
90
E
89


F
28
G
71


A
15
D
23


B
 47
G
64


C
35
F
39


E
22
H
18


A
3
E
13


B&lt; /td&gt;
45
C
36


D
11
G
24


F
39
H
37


A
23
F
39

&lt; tr&gt;
B
21
D
14


C
18
H
10


E
23
G
53


A
66
G
68


B
23
F
46


C
22
E
28


D
23
H
39


A
28
H
30


B
10
E
40


C
32
G
33


D
18
F
23



我在计算块的 SS（块内）时遇到了特别困难。根据前面的块内分析部分，方程应该是：
$$
\begin{equation}
k^{-1}\sum_{j}B_j^2-G^2/N
\end{equation}
$$
其中 k 是块的图，B 是每个块的治疗观察值的总和，G 是治疗观察值的全局总和，N 是观察值总数。我只能得到 ~15,405。
我很难看出我哪里做错了。治疗 SS 的块内方程运行良好，块间分析中调整后的块 SS 也运行良好。我还通过计算值获得了正确的块内错误！我感觉我漏掉了某个公式，但仔细阅读了整章后，我还是不知道在哪里。任何帮助我都感激不尽。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659837/bibd-intrablock-analysis-issue</guid>
      <pubDate>Fri, 10 Jan 2025 18:28:21 GMT</pubDate>
    </item>
    <item>
      <title>偏最小二乘回归 - 解释 X 的方差高于 100%</title>
      <link>https://stats.stackexchange.com/questions/659831/partial-least-squares-regression-explained-variance-for-x-above-100</link>
      <description><![CDATA[我正在使用 58 个参数（股票价格、历史回报、利率、国债收益率、商品……等）对标准普尔 500 指数的每日回报进行建模。
我使用偏最小二乘法创建了一个回归模型。
我的模型总共有 58 个组件，从 50 个组件开始，独立变量的解释方差超过 100%。
可能是什么原因造成的？
如果您需要更多信息，请告诉我。
编辑：
我使用 pls 包中的 plsr 函数实现了 PLSR：
dfAnalysisNumeric = read.csv(&quot;dfAnalysisNumeric.csv&quot;)[,-1]

plsrModel = plsr(indexReturn_t~.,data=dfAnalysisNumeric,
validation =&quot;CV&quot;,
scale=TRUE,
center=TRUE)
summary(plsrModel)

dfAnalysisNumeric 是我的数据集。我将其导出为 csv 文件。
这是链接：https://mega.nz/file/3ZsWDJpa#oueRGUqrVnyWqEIMdvU0mZYBjkAW57xklxkjbpTD_nQ
谢谢您的帮助！
]]></description>
      <guid>https://stats.stackexchange.com/questions/659831/partial-least-squares-regression-explained-variance-for-x-above-100</guid>
      <pubDate>Fri, 10 Jan 2025 16:48:36 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中分析具有连续且有很多零的响应变量的数据集？</title>
      <link>https://stats.stackexchange.com/questions/659832/how-to-analyze-a-dataset-with-a-response-variable-thats-continuous-and-has-a-lo</link>
      <description><![CDATA[我正在尝试分析 R 中含有大量零的数据集，我想在模型中包含随机效应。数据被视为来自 Biolog Ecoplates 的吸光度水平或平均孔显色 (AWCD)。简而言之，我想知道 4 种不同处理方式（变暖、干旱、变暖 + 干旱和环境）之间的 AWCD/吸光度是否存在差异。
我想知道如何为这些数据找到合适的分布，或者以可以处理这些零的方式对其进行转换。我尝试过对数和平方根转换。我考虑过非参数检验，如 Kruskal-Wallis，但它不能包括随机效应。我也考虑过零膨胀模型，但那不适用于连续变量？
如果数据是正态的，那么这就是我想要的模型结构：
lmm &lt;- lmer(Absorbence ~ Subplot_Descriptions + (1|Rep/Footprint_Location), data = biolog168_limited)
这是我的数据子集：
dput(biolog168_limited[57:77,])
structure(list(Footprint_Location = c(7L, 7L, 7L, 7L, 7L, 7L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), 
Rep = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), Subplot_Descriptions = c(&quot;warmed&quot;, 
&quot;warmed&quot;, &quot;warmed&quot;, &quot;warmed&quot;, &quot;warmed&quot;, &quot;warmed&quot;, &quot;drought&quot;, 
&quot;drought&quot;, &quot;drought&quot;, &quot;drought&quot;, &quot;drought&quot;, &quot;drought&quot;, &quot;drought&quot;, 
&quot;drought&quot;, &quot;drought&quot;, &quot;drought&quot;, &quot;干旱&quot;, &quot;干旱&quot;, &quot;干旱&quot;, 
&quot;干旱&quot;, &quot;干旱&quot;), SampleID_Hour = c(&quot;AN-REX-6-2_168&quot;, 
&quot;AN-REX-6-2_168&quot;, &quot;AN-REX-6-2_168&quot;, &quot;AN-REX-6-2_168&quot;, &quot;AN-REX-6-2_168&quot;, 
&quot;AN-REX-6-2_168&quot;, &quot;AN-REX-7-1_168&quot;, &quot;AN-REX-7-1_168&quot;, &quot;AN-REX-7-1_168&quot;, 
“AN-REX-7-1_168”, “AN-REX-7-1_168”, “AN-REX-7-1_168”, “AN-REX-7-1_168”, 
“AN-REX-7-1_168”, “AN-REX-7-1_168”, “AN-REX-7-1_168”, “AN-REX-7-1_168”, “AN-REX-7-1_168”, 
“AN-REX-7-1_168”, “AN-REX-7-1_168”, “AN-REX-7-1_168”, “AN-REX-7-1_168”, “AN-REX-7-1_168”
), 孔 = c(&quot;D6&quot;、&quot;B6&quot;、&quot;D7&quot;、&quot;B5&quot;、&quot;E5&quot;、&quot;E7&quot;、&quot;H2&quot;、&quot;G4&quot;、 
&quot;D2&quot;、&quot;G2&quot;、&quot;D1&quot;、&quot;D4&quot;、&quot;A3&quot;、&quot;F3&quot;、&quot;A2&quot;、&quot;E3&quot;、&quot;F4&quot;、&quot;B4&quot;、 
&quot;H1&quot;、&quot;B2&quot;、&quot;C1&quot;)，吸光度 = c(0.293, 0.123, 0.125, 1.381, 
0, 0.828, 0.014, 0.003, 0.006, 0, 0.365, 1.327, 1.203, 0.015, 
0, 1.821, 0.634, 1.136, 0.002, 0.015, 0.257)), row.names = 57:77, class = &quot;data.frame&quot;)

以下是整个数据集的直方图：
]]></description>
      <guid>https://stats.stackexchange.com/questions/659832/how-to-analyze-a-dataset-with-a-response-variable-thats-continuous-and-has-a-lo</guid>
      <pubDate>Fri, 10 Jan 2025 16:40:03 GMT</pubDate>
    </item>
    <item>
      <title>我想知道如何赢得飞行员游戏[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659830/i-should-like-to-have-knowledge-how-to-be-winning-aviator-game</link>
      <description><![CDATA[我想知道如何在不损失大量金钱的情况下赢得飞行员预测游戏💰]]></description>
      <guid>https://stats.stackexchange.com/questions/659830/i-should-like-to-have-knowledge-how-to-be-winning-aviator-game</guid>
      <pubDate>Fri, 10 Jan 2025 16:16:15 GMT</pubDate>
    </item>
    <item>
      <title>确保 Fisher 信息矩阵严格正定的条件</title>
      <link>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</link>
      <description><![CDATA[Fisher 信息矩阵定义为：
$$I(\theta):=E\left[\frac{\partial\log f(X;\theta)}{\partial \theta} \mid\theta\right]$$
其中 $f$ 是似然函数。
我正在寻找充分条件 - 最好是关于 $f$ 或 $\log f$ - 以确保 Fisher 矩阵严格正定。
正定性是证明最大似然估计量 (MLE) 渐近一致性的众所周知的临界条件。因此，这一探究具有重要意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</guid>
      <pubDate>Fri, 10 Jan 2025 14:33:43 GMT</pubDate>
    </item>
    <item>
      <title>同一研究中重叠复合终点估计率的相关性</title>
      <link>https://stats.stackexchange.com/questions/659823/correlation-of-estimated-rates-for-overlapping-composite-endpoints-from-the-same</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659823/correlation-of-estimated-rates-for-overlapping-composite-endpoints-from-the-same</guid>
      <pubDate>Fri, 10 Jan 2025 13:36:24 GMT</pubDate>
    </item>
    <item>
      <title>竞争风险情景中 Kaplan-Meier 估计的偏差</title>
      <link>https://stats.stackexchange.com/questions/659822/bias-in-kaplan-meier-estimate-in-competing-risk-scenario</link>
      <description><![CDATA[在阅读了其他地方的大量材料和这里的帖子后，我仍然无法完全理解为什么在竞争风险的情况下，基于 Kaplan-Meier 的累积风险估计（针对特定事件）通常被认为是“有偏差的”或“错误的”，并且累积发生率函数是首选。我理解，如果其他竞争事件（例如死亡和主要关注的事件）不是独立的（共享共同的预测因子），这可能是偏见的来源并影响估计的可解释性。然而，基于 KM 的估计原则上被认为是有偏差的，即使不同事件的发生不能用相同的预测因子来解释。
从 KM 得出的累积概率似乎反映了事件特定的风险，这可能比代表 CIF 所代表的各种影响的数量更有趣。例如，在 Covid 大流行期间，总体死亡率较高，因此竞争风险的负担更高，这将反映在 CIF 中。这似乎不是对事件特定风险负担非常有用的估计。]]></description>
      <guid>https://stats.stackexchange.com/questions/659822/bias-in-kaplan-meier-estimate-in-competing-risk-scenario</guid>
      <pubDate>Fri, 10 Jan 2025 12:42:05 GMT</pubDate>
    </item>
    <item>
      <title>对于 OLS 假设，随机样本是否需要 IID</title>
      <link>https://stats.stackexchange.com/questions/659821/does-random-sample-need-to-be-iid-for-ols-assumption</link>
      <description><![CDATA[假设要为 OLS 回归 创建样本，我分 2 个阶段 在不同的总体中抽样数据。例如，在一个总体中，我有 5000 个数据点，我从该总体中选择了 1000 个数据。而在另一个总体中，有 3000 个数据点，我从该总体中选择了 500 个数据。
然后我 组合 2 个抽样数据集（因此，组合数据集有 1500 个数据点），并构建横截面 OLS 回归。
我的问题是，在这种情况下，随机样本的 OLS 假设 是否得到满足？对于随机样本，我们是否需要数据为 IID？
在另一个抽样选项中，我有相同的 2 个数据总体。但是对于 1 个样本，我进行了 分层抽样，而对于另一个样本，我进行了 简单随机抽样。然后 合并 2 个抽样数据集。
在进行 OLS 回归时，随机样本假设在这种抽样方法下是否成立？
随机样本假设取自 Wooldridge 的计量经济学入门。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659821/does-random-sample-need-to-be-iid-for-ols-assumption</guid>
      <pubDate>Fri, 10 Jan 2025 11:50:05 GMT</pubDate>
    </item>
    <item>
      <title>相关性/巧合性测量中的统计数据[重复]</title>
      <link>https://stats.stackexchange.com/questions/659798/statistics-in-correlation-coincidence-measurement</link>
      <description><![CDATA[我从事实验物理工作，对所谓的“巧合”测量中使用的某些统计模型感到困惑。
为了说明背景，我们有可以检测单个粒子（在我的情况下是光子）存在的探测器。您可以想象一束连续的光子撞击探测器。总检测周期被分成非常小的时间段，当它检测到光子撞击传感器时，它会在任何给定的时间段输出 1，如果没有，则输出 0。在某些光源（例如激光器）中，数字统计遵循泊松分布 - 在任何时间段检测到光子的概率与所有其他时间段的概率无关。对于一个探测器，这是一个“单个”测量。当我们有两个探测器和两个光源时，“巧合”事件是每个探测器在同一时间箱中输出 1，即它们同时在各自的路径中检测到一个光子（以时间箱的分辨率为准）。
以下是问题的概述：
假设我们有两个探测器 $1$ 和 $2$。每个探测器都有一个光源输出一束光子。每个光源和每个探测器彼此独立。将每个探测器上的时间段称为$t_1,\ldots,t_N$（所有时间段的持续时间相同，即$t_1=t_2=\cdots=t_n=\Delta t$），总实验时间窗口称为$T=\sum^{N}_{i=1}t_i$。假设每个光源都遵循泊松统计，并且每个探测器实验窗口中的总计数平均值为 $R_1T$ 和 $R_2T$（$R_1$ 和 $R_2$ 是光源已知的固定发射率）。此外，假设 $R_1\Delta t\ll1$ 和 $R_2\Delta t\ll1$，因此我们几乎总是在任何时间段内得到 $0$ 或 $1$。另外假设 $T/\Delta t$ 非常大。我将在每个探测器上随机获得 $1$ 和 $0$ 的组合，如果我多次重复实验，每个探测器上的总计数将有一个大致等于平均值​​平方根的标准差。
我的问题是，巧合计数（当两个探测器在同一时间段上记录 $1$ 时为 $1$，否则为 $0$）是否也遵循泊松分布？我想我知道如何找到实验的平均巧合计数，应该是
$R_CT=T\Delta tR_1R_2$
（$R_C$ 是巧合中的固定计数率）。在许多论文中，巧合计数被假定具有泊松统计量，这是有道理的，因为获得巧合计数的概率在不同时间应该是彼此独立的。
但是，我也可以将巧合计数的数量表示为每个探测器上的单个计数的乘积，其中单个计数本身是泊松的 - 但两个泊松的乘积不是泊松的。
编辑：
为进一步说明，预期的巧合计数如下
$C=R_CT=(\Delta t/T)S_1S_2$
其中 $S_1=R_1T$ 和 $S_2=R_2T$，并且 $S$ 对应于探测器上的预期单数计数。
有人告诉我，一旦我在 $T$ 时间段内测量了 $S_1$ 和 $S_2$，我就可以简单地使用标准误差传播技术 (https://en.wikipedia.org/wiki/Propagation_of_uncertainty#:~:text=.-,Simplification,-%5Bedit%5D)（并假设单数大致为泊松分布）来获得$C$ 中的不确定性，但是我不确定这如何量化巧合事件的统计数据，因为这个新的不确定性似乎有一个 $\sqrt{C(\Delta t/T)(S_1+S_2)}$ 的因素，而不是 $\sqrt{C}$。]]></description>
      <guid>https://stats.stackexchange.com/questions/659798/statistics-in-correlation-coincidence-measurement</guid>
      <pubDate>Thu, 09 Jan 2025 21:09:36 GMT</pubDate>
    </item>
    <item>
      <title>样本均值平方与样本均值平方之间的方差</title>
      <link>https://stats.stackexchange.com/questions/659789/difference-in-variance-between-sample-mean-of-squares-and-square-of-sample-mean</link>
      <description><![CDATA[假设我们有独立同分布的随机变量 $X_1 \ldots X_N$，我们从中计算样本均值 $\overline{X}$。我对数量 $Var[\overline{X^2}]$ 和 $Var[\overline{X}^2]$ 感兴趣。前者可以用来估计或限制后者吗？
在上面，我使用 $Var$ 来表示其参数的方差，将参数视为随机变量。例如，在此符号中，平均值的经典结果是 $Var[\overline{X}] = Var[X]/N$。
我的尝试 #1：
对于第一个方差，可以用期望的形式写成
$$ Var[\overline{X^2}] = \frac{1}{N} Var[X^2] = \frac{1}{N} (E[X^4]-E[X^2]^2)$$
对于第二个，我们使用以下事实：$E(X) - \overline{X}$ 很小，因此
$$ Var[f(\overline{X})] \sim Var[f(E[X]) + f&#39;(E[X])\cdot(\overline{X}-E[X])] = f&#39;(E[X])^2 \cdot Var[\overline{X}] = \frac{f&#39;(E[X])^2}{N} \cdot Var[X] = \frac{f&#39;(E[X])^2}{N} \cdot (E[X^2]-E[X]^2)$$
得出
$$ Var[\overline{X}^2] \sim \frac{4}{N} E[X]^2 \cdot (E[X^2]-E[X]^2)$$
我得出的两个表达式不是立即可比较的，但 4 这个因子让我怀疑 $Var[\overline{X^2}] &gt; Var[\overline{X}^2]$..？这个说法的证明肯定会回答我的问题。
我的尝试 #2：
按照 Xi&#39;an 的建议，我已经用数字方式研究了我的问题。我的 matlab 代码和结果图如下所示：
%计算不同分布的 Var(SM(X^2)) 和 Var(SM(X)^2) 并
%绘制不同 N 的结果。这里 SM 是 N 个样本的样本均值。

fig = figure;
Ax = [subplot(2,1,1),subplot(2,1,2)];
axes(Ax(1)); hold on;
axes(Ax(2)); hold on;

%计算方差的试验次数（尽可能大）
V = 1e4;

%样本大小
N = unique(round(logspace(0,3,20)));

%生成随机数的函数
F = {@rand, @randn, @(sz1,sz2)exprnd(1,sz1,sz2), @(sz1,sz2)betarnd(5,1,sz1,sz2)};
Fs = {&#39;x&#39;,&#39;+&#39;,&#39;o&#39;,&#39;^&#39;};

for iF = 1:numel(F)
%预先分配用于保存结果的空间
R1 = NaN(size(N));
R2 = NaN(size(N));

%循环遍历所有样本大小
for iN = 1:numel(N)
%生成随机数，行是试验，列是样本
X = F{iF}(V,N(iN));
%计算方差
R1(iN) = var(mean(X.^2,2));
R2(iN) = var(mean(X,2).^2);
end

%绘制曲线
plot(Ax(1),N,R1,[&#39;r-&#39;,Fs{iF}]);
plot(Ax(1),N,R2,[&#39;b-&#39;,Fs{iF}]);
plot(Ax(2),N,R2./R1,[&#39;k-&#39;,Fs{iF}]);
结束

% 格式化轴
set(Ax(1),&#39;XScale&#39;,&#39;log&#39;,&#39;YScale&#39;,&#39;log&#39;)
xlabel(Ax(1),&#39;$N$&#39;,&#39;Interpreter&#39;,&#39;latex&#39;)
ylabel(Ax(1),&#39;蓝色：$Var[\overline{X}^2]$~~~~红色：$Var[\overline{X^2}]$&#39;,&#39;Interpreter&#39;,&#39;latex&#39;)

set(Ax(2),&#39;XScale&#39;,&#39;log&#39;)
xlabel(Ax(2),&#39;$N$&#39;,&#39;Interpreter&#39;,&#39;latex&#39;)
ylabel(Ax(2),&#39;$Var[\overline{X}^2]/Var[\overline{X^2}]$&#39;,&#39;Interpreter&#39;,&#39;latex&#39;)


图中，标绘点和 &#39;x&#39; 来自 $[0,1]$ 上的均匀分布，&#39;+&#39; 来自正态分布，&#39;o&#39; 来自参数为 $1$ 的指数分布，并且 $\Delta$ 取自参数为 $(5,1)$ 的 Beta 分布。结果如下：

对于正态分布、均匀分布和指数分布，$Var[\overline{X}^2] &lt; Var[\overline{X^2}]$。事实上，对于正态分布，$Var[\overline{X}^2]/Var[\overline{X^2}] \to 0$ 等于 $N \to \infty$。
我能够找到一个违反不等式的分布，绘制的 beta 分布结果为 $Var[\overline{X}^2] \lesssim 1.2 \cdot Var[\overline{X^2}]$。然而，我仍然期望存在某个常数$C$，使得对于任何概率分布，$Var[\overline{X}^2] \lesssim C \cdot Var[\overline{X^2}]$。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659789/difference-in-variance-between-sample-mean-of-squares-and-square-of-sample-mean</guid>
      <pubDate>Thu, 09 Jan 2025 17:06:04 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归假设和 Box-Tidwell 检验</title>
      <link>https://stats.stackexchange.com/questions/659774/logistic-regression-assumptions-and-box-tidwell-test</link>
      <description><![CDATA[我正在做一个逻辑回归，它只包括两个数字独立变量（年龄和受影响器官的总和）和其他分类变量。当我对这些数字变量执行 Box-Tidwell 检验时，它告诉我结果的对数和变量“器官总和 (p &lt;0.05)”之间没有线性关系。
我的问题是，我是否绝对需要从回归中删除这个变量，或者我是否可以使用另一种技术。我刚刚读到样条应该是一个选项，我已经执行了。然而，我没有在科学工作中解释和报告这一点的经验。我甚至读过一篇关于诊所样条的《自然》文章，但我发现很难理解。你能帮我吗？
esplenicos$Angiogenic &lt;- relevel(esplenicos$Angiogenic, ref = &quot;Yes&quot;)
levels(esplenicos$Angiogenic)

regressão_logistica &lt;- glm(Angiogenic ~ Breed2 + Age + Sex + Number_cavities + 
SumAffected_organs, data = esplenicos,
family = binomial())

esplenicos$logAgeInt &lt;- log(esplenicos$Age) * esplenicos$Age
esplenicos$logSumaffectedorganInt &lt;- log(esplenicos$SumAffected_organs）*      
esplenicos$SumAffected_organs

regressão_logistica2 &lt;- glm(血管生成 ~ Breed2 + 年龄 + SumAffected_organs+ 性别 +      
Number_cavities + logSumaffectedorganInt + logAgeInt，数据 = esplenicos，
                   家庭=二项式())
摘要（regressão_logistica2）

logito &lt;- regressão_logistica$linear.predictors
esplenicos$logito &lt;-logito
一瞥（esplenicos）

ggplot(esplenicos, aes(logito, SumAffected_organs)) +
geom_point（大小= 0.5，阿尔法= 0.5） +
geom_smooth(method = &quot;loess&quot;) +
theme_classic()


我包括了 Box-Tidwell 检验的输出，该检验对器官总和具有显著性，以及结果与器官总和变量的对数图。

]]></description>
      <guid>https://stats.stackexchange.com/questions/659774/logistic-regression-assumptions-and-box-tidwell-test</guid>
      <pubDate>Thu, 09 Jan 2025 14:53:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么标准差比平均值绝对偏差更受青睐？</title>
      <link>https://stats.stackexchange.com/questions/659643/why-is-standard-deviation-preferred-over-absolute-deviations-from-the-mean</link>
      <description><![CDATA[第一部分
在探索了各种资源和论坛之后，我了解到标准差是一种广泛使用的离散度测量方法，通常比绝对平均偏差更受欢迎（我个人认为后者更简单、更直观），原因如下：
1. 方差的加性：
同意。
2. 平均值最小化平方偏差之和，而中位数（有时不是唯一的）最小化绝对偏差之和：
有点同意，但我不完全理解为什么在这里实现最小值是相关的。有人能解释一下为什么这个属性在选择离散度测量方法时很重要吗？
3.平方偏差在 𝑥 = 0 时可微分，而绝对偏差则不可微分：
有点同意，但我还是不明白为什么可微分性如此重要。这个属性在哪些方面有实际用途？
第二部分
我的独立想法/问题：
方差定义为与平均值的平方偏差的平均值，标准偏差是其平方根（“实际 SD”）。但是，如果标准偏差是平方偏差的平方根的平均值，那不是更有意义吗？ （我提议的是标准差的新定义“建议的 SD”）
(1 / n) * √ Σ((xᵢ - μ)²) 而不是 √(Σ (xᵢ - μ)² / n)

我的理由如下：
平方偏差主要是为了确保：

所有值都是正数。
偏差越大，权重越大。
平均值是使平方偏差之和最小化的数字。

绝对平均偏差达到点 (1)，绝对中位数偏差达到点 (1) 和 (3)。在这些情况下，我们将偏差相加，然后除以 𝑛 得到平均值。
但是，在方差和标准差的情况下，类似的“平均值”就是方差本身。但方差作为一个数字并不能直观地传达分布的扩展。这就是为什么我们要取方差的平方根来得到标准差。
所以，我的问题是：
为什么不使用&quot;建议 SD&quot;作为分散度的度量？
&quot;建议 SD&quot;有什么缺陷？
&quot;实际 SD&quot;为什么比&quot;建议 SD&quot;更适合作为分散度的度量？]]></description>
      <guid>https://stats.stackexchange.com/questions/659643/why-is-standard-deviation-preferred-over-absolute-deviations-from-the-mean</guid>
      <pubDate>Tue, 07 Jan 2025 05:23:59 GMT</pubDate>
    </item>
    <item>
      <title>使用加权逻辑回归对重复数据进行误差估计的校正因子</title>
      <link>https://stats.stackexchange.com/questions/659641/correcting-factor-for-error-estimation-with-weighted-logistic-regression-on-dupl</link>
      <description><![CDATA[假设一个数据集被复制，但第一个副本被分配了一组概率权重（与采样无关），而第二个副本具有另一组权重，其中权重与我们复制数据的事实无关。 主要问题：

我是否应该将每个权重乘以 1/2 以纠正数据重复？

上下文
假设对于每个观察值 1 到 N，您有概率估计 $p_a=P(race=a)$、$p_b=P(race=b)$、$p_c=P(race=c)$，其中 $\sum_{r=\{a,b,c\}}p_r=1$ 和一些二元结果变量 $y$，并且我们希望估计逻辑回归 $\text{logit }y\sim \beta_0 + \beta_1 D^{r}+X\beta$ 其中 X 是一组控制因素，$D^r$ 是治疗组的虚拟变量（假设 &#39;b&#39; 为治疗组，&#39;a&#39; 为对照组）。
为此，我上面的一些高阶专家估计了一个加权逻辑回归，其中
\begin{align}
\text{logit }\begin{pmatrix}
y \\
y \\
\end{pmatrix} &amp;= \beta_0+\beta_1\begin{pmatrix}
D^{b} \\
D^{b} \\
\end{pmatrix}
+ \begin{pmatrix} X \\ X\\ \end{pmatrix} \beta
\end{align&gt;
其中 $$\text{weights} =\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$$ 且 $D^b_{1\dots N}$=1 且 $D^b_{(N+1)\dots 2N}=0$（基本上，第一个 1...N 堆栈具有虚拟 $D^b=1$ 且第二个 (N+1)...2N 具有虚拟 $D^b=0$。
问题：通常，每个观测值的权重为 1/2 应该可以解决因重复数据集而产生的误差估计问题。这是否仍然适用于权重的使用。例如，我可以这样做 $\text{weights} =\frac{1}{2}\begin{pmatrix} p_b \\ p_a \\ \end{pmatrix}$ 还是这些权重没有意义？
请原谅我潦草的符号，希望它足以传达这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/659641/correcting-factor-for-error-estimation-with-weighted-logistic-regression-on-dupl</guid>
      <pubDate>Tue, 07 Jan 2025 04:28:49 GMT</pubDate>
    </item>
    <item>
      <title>glmmTMB 在我的模型中返回以下消息，且不包含交互：“从秩不足条件模型中删除列”</title>
      <link>https://stats.stackexchange.com/questions/659838/glmmtmb-returns-the-following-message-in-my-model-without-interactions-droppin</link>
      <description><![CDATA[我正在运行的模型如下：
glmmTMB(data=bd, prop_inf~ais+grupo+(1|ano)+(1|bloque)+(1|parcela), 
family=&quot;tweedie&quot;)

prop_inf 是一个比例，值范围从 0 到 1，所有解释变量都是分类变量。问题不在于随机效应因素，因为如果我运行模型 prop_inf ~ ais + grupo，glmmTMB 仍然会返回错误。变量“ais”有 31 个级别，分布在 3 个“grupo”级别中：10 个“ais”级别属于“grupo_1”级别，另外 10 个“ais”级别属于“grupo_2”级别，其余 11 个“ais”级别属于“grupo_3”级别。
我想执行 Anova 检验（我知道我需要使用“car”库）来评估因素“ais”和“grupo”的重要性。运行 Anova(model) 时，car 库不会返回因素“grupo”的 Chisq 值。]]></description>
      <guid>https://stats.stackexchange.com/questions/659838/glmmtmb-returns-the-following-message-in-my-model-without-interactions-droppin</guid>
      <pubDate>Mon, 06 Jan 2025 16:29:10 GMT</pubDate>
    </item>
    <item>
      <title>在比较两个过程的输出时如何解释抽样变异性</title>
      <link>https://stats.stackexchange.com/questions/659519/how-to-account-for-sampling-variability-when-comparing-outputs-of-two-process</link>
      <description><![CDATA[我有一个粉末批次（起始批次），其粒度分布 (PSD) 已知。从这个批次中，我抽取两个单独的样本，用于工艺的两种不同方法（方法 A 和方法 B）。我想比较这两种方法的输出，看看它们是否产生粉末输出 PSD 结果。
但是，由于输入粉末批次 A 具有粒度分布（粒度范围），我采集的每个样本仅代表整体分布的一个子集，这可能会影响两种方法的输出结果。鉴于此，在比较方法 A 和 B 的输出时，我应该如何解释样本之间的粒度差异？
我是否应该通过考虑批次的整体 PSD（即粒度分布的平均值和标准差）来调整结果，并以某种方式将其计入两种方法的输出 PSD？]]></description>
      <guid>https://stats.stackexchange.com/questions/659519/how-to-account-for-sampling-variability-when-comparing-outputs-of-two-process</guid>
      <pubDate>Sat, 04 Jan 2025 05:02:37 GMT</pubDate>
    </item>
    </channel>
</rss>