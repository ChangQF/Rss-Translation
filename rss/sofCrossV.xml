<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 26 Dec 2023 18:16:25 GMT</lastBuildDate>
    <item>
      <title>对于一个定量自变量和多个定量因变量使用什么分析？</title>
      <link>https://stats.stackexchange.com/questions/635664/what-analysis-to-use-for-one-quantitative-independent-variable-and-multiple-quan</link>
      <description><![CDATA[我的数据基于调查回复。自变量根据 1 到 5 之间的三个李克特问题进行聚合（IV 将这三个问题相加并除以 3）。四个因变量是 1 到 5 之间的李克特问题。
显而易见（但可能有争议）的解决方案是运行四个简单的线性回归模型，每个因变量一个。然而，我担心的是仅凭偶然就能发现显着的结果。
我研究了多元多元线性回归，但这种分析需要多个 IV，这对我的情况没有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/635664/what-analysis-to-use-for-one-quantitative-independent-variable-and-multiple-quan</guid>
      <pubDate>Tue, 26 Dec 2023 17:38:14 GMT</pubDate>
    </item>
    <item>
      <title>治疗和结果在不同水平上汇总时的因果推断</title>
      <link>https://stats.stackexchange.com/questions/635663/causal-inference-when-treatment-and-outcome-are-aggregated-at-different-levels</link>
      <description><![CDATA[考虑这样一种情况：治疗是美国州级政策（一些州采用了该政策，而另一些州则没有），结果是个人对美国各州调查的反应。为了使这种情况不那么抽象，我们假设该政策是枪支改革立法，而结果是个人对安全的看法。因此，治疗和结果会在不同级别上汇总。
我立刻就发现了这种方法的一个问题，因为它涉及到识别要调整的混杂因素。例如，在这种情况下，意识形态似乎是一个明显的混杂因素，但意识形态以什么方式聚合？国家的意识形态构成将影响通过枪支改革立法的可能性，个人的意识形态将影响他们对安全的看法，但一个人的意识形态将影响他们对安全的看法。国家和个人的意识形态是两个独立（但相关）的概念。而且，如果是这样的话，这就是“意识形态”吗？甚至是一个混杂因素？
天真地说，我可以说：
枪支改革$\leftarrow$意识形态$\rightarrow$安全认知
但这并不是真的，不是吗？因为，我实际上假设的是两种完全独立的意识形态衡量标准：
枪支改革$\leftarrow$国家意识形态构成
安全认知$\leftarrow$个人意识形态
人们如何处理诸如此类的情况，其中问题似乎完全是由治疗和结果之间的不同聚合程度驱动的？一个明显的做法可能是对结果的响应进行平均并崩溃到州一级，但这有一个严重的缺点，即严重减少 N。有没有办法在不重新聚合的情况下继续前进？]]></description>
      <guid>https://stats.stackexchange.com/questions/635663/causal-inference-when-treatment-and-outcome-are-aggregated-at-different-levels</guid>
      <pubDate>Tue, 26 Dec 2023 16:55:05 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 网络中的反向传播 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/635662/backpropagation-in-lstm-network</link>
      <description><![CDATA[我们如何在 LSTM 反向传播中实际得出这个方程？ （如果我们假设 W 作为串联权重） ]]></description>
      <guid>https://stats.stackexchange.com/questions/635662/backpropagation-in-lstm-network</guid>
      <pubDate>Tue, 26 Dec 2023 16:12:07 GMT</pubDate>
    </item>
    <item>
      <title>使用核密度估计来估计分布之间的距离</title>
      <link>https://stats.stackexchange.com/questions/635658/the-usage-of-kernel-density-estimate-for-distance-between-distributions</link>
      <description><![CDATA[Scipy 的 kde 对象允许集成函数乘以另一个 KDE。我认为这意味着用于估计两个分布之间的距离。据我了解，为了保持一致的度量，在积分之前需要平方根，类似于 Bhattacharyya 距离的定义。那么，这个输出是什么？我可以用它来测量分布之间的距离吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635658/the-usage-of-kernel-density-estimate-for-distance-between-distributions</guid>
      <pubDate>Tue, 26 Dec 2023 14:21:51 GMT</pubDate>
    </item>
    <item>
      <title>排除和不排除单个观测值的 OLS 解</title>
      <link>https://stats.stackexchange.com/questions/635657/solution-of-ols-with-and-without-excluding-a-single-observation</link>
      <description><![CDATA[在普通最小二乘法 (OLS) 中，输入矩阵 $X$ 的最佳拟合解（大小 $p \次 N$ -- N 个样本和 p 个特征）和输出向量 $y$ （大小为 $N $) 是
$\hat \beta = (X^T X)^{-1} X^T y$。
现在假设我从矩阵 $X$ 中排除行 i 以及相应的 $y $，即从观察结果中排除一个样本。我们将新数量称为 $X_{-i}$ 和 $y_{-i}$ 并求解再次求解 OLS 问题，并类似地将新解决方案命名为 $\hat \beta _{-i}$。
我的问题是这两个解决方案之间是否有任何关系？我可以从 $\hat \beta $ 到 $\hat \beta _{-i}$ 通过某个公式？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/635657/solution-of-ols-with-and-without-excluding-a-single-observation</guid>
      <pubDate>Tue, 26 Dec 2023 13:20:08 GMT</pubDate>
    </item>
    <item>
      <title>为什么数据中的不同值会极大地影响PCA和模型的训练</title>
      <link>https://stats.stackexchange.com/questions/635653/why-different-values-in-the-data-greatly-affect-the-pca-and-the-training-of-the</link>
      <description><![CDATA[我有与目标关联的稀疏数据，这是模拟数据的代码
make_feature &lt;- function(target, null_var=0){
  v &lt;-rep(null_var, length(target))
  j &lt;- 样本（长度（目标），1）
  v[j] &lt;- 目标[j]
  v
}

库（矩阵）
库（随机森林）
设置.种子(2)

目标 &lt;- 样本(c(1,2),50,替换 = T)
数据 &lt;- sapply(1:200,\(x) make_feature(target))

稀疏数据&lt;-矩阵（数据，稀疏= TRUE）

...
&lt;前&gt;&lt;代码&gt;稀疏数据

[42，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[43，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[44，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 2. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[45，]。 。 。 。 。 。 。 1. 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[46，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[47，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 2. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[48，]。 。 。 。 。 2. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[49，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 2. 。 。 。 2. 。 。 。 ......
[50，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......

然后我进行 PCA 并训练模型
pca_sparse_data &lt;- prcomp(sparse_data)$x

时间 &lt;- 1:40
时间 &lt;- 41:50

rf &lt;- randomForest(as.factor(target[tr])~., data=pca_sparse_data[tr,], ntree=100)

模型运行良好
cbind.data.frame(orig = target[ts],
                  pred = 预测(rf, pca_sparse_data[ts,]))


   原始预测
1 1 1
2 1 1
3 1 1
4 2 2
5 1 1
6 1 1
7 2 2
8 2 2
9 2 2
10 1 1

但是当我稍微用其他值替换数据中的值时，模型就会停止工作
new_sparse_data &lt;-稀疏数据

new_sparse_data[sparse_data==1] &lt;- -1
new_sparse_data[sparse_data==2] &lt;- 1

..
&lt;前&gt;&lt;代码&gt;new_sparse_data

[42，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 -1。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[43，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[44，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[45，]。 。 。 。 。 。 。 -1。 。 。 。 。 -1。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[46，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[47，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[48，]。 。 。 。 。 1. 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......
[49，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 1. 。 。 。 1. 。 。 。 ......
[50，]。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 -1。 。 。 。 。 。 。 。 -1。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 。 ......

训练新模型
new_pca_sparse_data &lt;- prcomp(new_sparse_data)$x
 new_rf &lt;- randomForest(as.factor(target[tr])~., new_pca_sparse_data[tr,], ntree=100)
 cbind.data.frame(orig = target[ts],
                  pred = 预测(new_rf, new_pca_sparse_data[ts,]))


   原始预测
1 1 1
2 1 1
3 1 2
4 2 2
5 1 1
6 1 2
7 2 2
8 2 1
9 2 2
10 1 2

为什么新模型的表现如此差？]]></description>
      <guid>https://stats.stackexchange.com/questions/635653/why-different-values-in-the-data-greatly-affect-the-pca-and-the-training-of-the</guid>
      <pubDate>Tue, 26 Dec 2023 11:45:53 GMT</pubDate>
    </item>
    <item>
      <title>OLS 估计量中受控变量的确切含义</title>
      <link>https://stats.stackexchange.com/questions/635649/exact-meaning-of-controlled-variables-in-terms-of-the-ols-estimators</link>
      <description><![CDATA[考虑一个二回归量线性回归模型：
$$Y=\beta_0+\beta_1X+\beta_2D+u$$
其中 $X$ 是连续的，$D$ 是二进制的。
在这种情况下，我们说我们已经控制了$D$。
在这里，我想知道“控制”的确切含义。
在提出我的想法之前，请考虑三个估计器。
首先，让 $\widehat{\beta}_1$ 为使用上述二回归模型的 OLS 估计器。
其次，让 $\widehat{\beta}_{11}$ 和 $\widehat{\beta} _{10}$ 是仅使用 $D=1$ 和 $D 样本的 OLS 估计器=0$，分别基于
$$Y=\alpha_0+\alpha_1X+e$$
如果 $\widehat{\beta}_1$ 是 $\widehat{\beta}_ 的加权平均值{11}$ 和 $\widehat{\beta}_{10}$，术语“受控”非常有效，因为 $\widehat{\beta}_{11}$ 和 $\widehat{\beta}_{ 10}$ 是在控制 $D$ 时估算的。
但是，我不确定这个想法是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/635649/exact-meaning-of-controlled-variables-in-terms-of-the-ols-estimators</guid>
      <pubDate>Tue, 26 Dec 2023 10:33:53 GMT</pubDate>
    </item>
    <item>
      <title>使用 t 统计量调查​​高于机会的测试性能</title>
      <link>https://stats.stackexchange.com/questions/635645/investigating-above-chance-test-performance-using-t-statistics</link>
      <description><![CDATA[我正在阅读一篇研究论文，遇到一种情况，研究人员调查参与者的测试表现是否高于偶然性。我很好奇如何以及为何进行这种类型的分析，如果有人能提供一些解释，我将不胜感激。
在这种情况下，126 名参与者被分为两组。每个小组都接受不同类型的语言训练。然后，两组完成相同的后测试，其中包括六个目标测试项目（加上一些干扰项）。对于每个目标测试项目，参与者看到两张图片，他们必须选择与测试者所说的句子相匹配的图片。测试者说出的六个句子中，三个句子包含训练中出现的动词，另外三个句子包含新动词。参与者完成此后测试两次，或分两个部分（训练课程 1 —&gt; 后测试 1 —&gt; 培训课程 2 —&gt; 后测试 2）。然后将测试分数提交给 2x2x2 方差分析，将训练条件作为主体间因素，将动词类型（训练与新颖）和块（1 与 2）作为主体变量内的变量。
在描述方差分析结果后，研究人员报告说，对于包含块一中两个条件的训练动词的句子，参与者选择的目标图片明显多于预期，t(120) = 3.7, p &lt; .001，块 2，t(120) = 8.5，p &lt; .001.此外，对于新颖的句子，这两个条件的表现均高于第二个块中的机会水平，t(120) = 4.1，p &lt; 4.1。 .001，但不在第一个块中，t(120) = 1.8，p = .07。
研究人员表示，上述几率大于 50%。
我的问题是：

如何对这样的超概率测试性能进行分析？我猜研究人员使用了 SPSS，尽管没有直接说明。我是否需要在 SPSS 中输入任何值，或者是否需要选择特定命令来对 8 个条件 (2x2x2) 中的每一个执行此类分析？

鉴于已经使用方差分析分析了感兴趣的变量（训练类型、动词类型和块）对分数的影响，调查测试表现是否高于机会的目的可能是什么像这样的研究吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/635645/investigating-above-chance-test-performance-using-t-statistics</guid>
      <pubDate>Tue, 26 Dec 2023 09:20:10 GMT</pubDate>
    </item>
    <item>
      <title>当基于树的模型通常比线性模型效果更好时，为什么我们要使用线性模型？</title>
      <link>https://stats.stackexchange.com/questions/635642/why-do-we-use-linear-models-when-tree-based-models-often-work-better-than-linear</link>
      <description><![CDATA[在监督机器学习中，特别是在 Kaggle 中，通常会发现树模型通常优于线性模型。即使在基于树的模型中，通常 XGBoost 的性能也优于 RandomForest，而 RandomForest 的性能又优于 DecisionTrees。
如果这不是真的，那么请随时纠正这个假设。
这些只是我的观察，不知何故，很多人都同意这个观点。
为什么我们应该使用线性模型，例如线性回归或逻辑回归？具体来说，什么时候它们的性能不如基于树的模型，并且比基于树的模型有更多的要求？
对于基于树的模型，可以提出关于使用 DecisionTrees 而不是 RandomForest 或 XGBoost 的类似问题。
在某些情况下应该首选线性模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/635642/why-do-we-use-linear-models-when-tree-based-models-often-work-better-than-linear</guid>
      <pubDate>Tue, 26 Dec 2023 06:59:42 GMT</pubDate>
    </item>
    <item>
      <title>阐明称为“内核”或“贝叶斯”的各种回归方法之间的差异</title>
      <link>https://stats.stackexchange.com/questions/635574/clarifying-the-difference-between-various-regression-methods-called-kernel-or</link>
      <description><![CDATA[我想了解四种回归类型之间的成对关系：贝叶斯线性回归、高斯过程回归、核回归 (Nadaraya-Watson) 和核岭回归。我在阅读机器学习的高斯过程这本书时遇到了所有这些问题，并且想要一种清晰简洁的方法来区分它们。
这是我目前的理解，欢迎指正。贝叶斯线性回归处理 $\hat{\beta}$ 回归系数（通常设置为 OLS 最优估计器 $\hat{\beta}= (X^TX)^{-1}X^T y$) 作为随机变量，其分布是先验（我们选择的）的函数，并且数据（这鼓励它采用上面的 OLS 形式，如果这是我们的损失函数）。高斯过程回归只是贝叶斯线性回归，其中函数的先验是高斯过程（它是由均值函数和协方差函数定义的函数空间上的分布）。
然后，我对核回归的理解是，核是一个“相似度函数”。数据点之间，因此形式为 $\hat{y}(x) = \frac{\sum_i K(x, x_i)y_i}{\sum_i K(x, x_i)}$ 作为加权平均值似乎使用起来很直观。但是内核 ridge 回归给出了形式为 $K_{x, X}(K_{X,X} + \lambda I)^{- 的估计量1}y$。这似乎与带有岭罚分的传统核回归（N-W 类型）不同。此外，我看到高斯过程回归输出与其“后验平均值”相同的估计量。现在 $K$ 是协方差内核，因此 GPR（这是 BLR 的特殊情况？）相当于 KRR？
这四个简单方法之间的关系我不清楚。非常感谢一些澄清，谢谢。技术细节越多越好。]]></description>
      <guid>https://stats.stackexchange.com/questions/635574/clarifying-the-difference-between-various-regression-methods-called-kernel-or</guid>
      <pubDate>Sun, 24 Dec 2023 08:26:18 GMT</pubDate>
    </item>
    <item>
      <title>什么是样品近似硬度的度量？</title>
      <link>https://stats.stackexchange.com/questions/635494/what-is-a-measure-of-hardness-of-approximation-by-samples</link>
      <description><![CDATA[假设有一个很大的实数向量$\mathbf{x}$，我想估计某个聚合函数$f(\mathbf{x})$ 通过从总体中抽取一小部分样本$\mathbf{x}$。我想知道需要多少样本才能获得给定大小（例如 1%）的 95% 置信区间。样本数量可能取决于函数 $f$：较大的数字表示 $f$ 是“通过采样更难近似”。这个样本数的术语是什么？在哪里可以找到有关哪些函数 $f$ 更容易/更难近似的数据？
我想到的一个术语是样本复杂度，但从我所看到的来看，它不一样：它测量从给定的函数类别中学习函数所需的训练样本数量。就我而言，函数是固定且给定的，我想知道将函数值估计到给定精度所需的样本数。]]></description>
      <guid>https://stats.stackexchange.com/questions/635494/what-is-a-measure-of-hardness-of-approximation-by-samples</guid>
      <pubDate>Fri, 22 Dec 2023 12:09:45 GMT</pubDate>
    </item>
    <item>
      <title>$E[X|X^3-3X]=0$</title>
      <link>https://stats.stackexchange.com/questions/635492/exx3-3x-0</link>
      <description><![CDATA[用 $f(x) 证明 $E[X|X^3-3X]=0$ =\frac{|x^2-1|}{4}$ 是区间 $X$ 的密度函数数学容器&quot;&gt;$[-2,2]$。
我的尝试：
设 $Y=X^3-3X$ 和 $x_1, x_2, x_3$ $x^3-3x=y$ 的根。
\begin{聚集*}
P_{X\circ Y}(A\times B)=P_\Omega(X\in A\cap Y\in B)=\int_{Y\in B}I_A(x)f(x)dx=\\
=\int_B\sum_{i=1}^3I_A(x_i)f(x_i)/|3x_i^2-3|dy=\int_B\frac{\sum I_A(x_i)f(x_i)/|3x_i^2- 3|}{\sum f(x_i)/|3x_i^2-3|}dP_Y
\end{聚集*}
从哪里：
$$P_{X/Y}(y)(A)=P_\Omega[X\in A|Y=y]=\frac{1}{3}\sum I_A (x_i)$$
所以：
$$E[X|Y=y]=\frac{1}{3}\sum x_i=0$$]]></description>
      <guid>https://stats.stackexchange.com/questions/635492/exx3-3x-0</guid>
      <pubDate>Fri, 22 Dec 2023 11:30:22 GMT</pubDate>
    </item>
    <item>
      <title>Copula 确保一支球队获胜而另一支球队失败（伯努利裕度）</title>
      <link>https://stats.stackexchange.com/questions/635266/copula-to-ensure-one-team-wins-and-the-other-loses-bernoulli-margins</link>
      <description><![CDATA[$1$ 团队的历史胜率为 $p_1$。
$2$ 团队的历史胜率为 $p_2$。
即将举行的比赛由 $1$ 队对阵 $2$ 队，并且不能以平局结束（一一方获胜，另一方失败）。
虽然这并不完全正确，但假设每支球队获胜的时间序列为$iid$（因此没有球员受伤、进步等）。 
我想知道游戏结果的联合分布。看来我可以使用伯努利$(p_1)$和伯努利$(p_2)$的边距。对于联结，我想我可以使用具有“相关性”的高斯联结。 $-1$ 的参数，以便伯努利裕度始终具有相反的结果。然而，当我模拟这个时，我没有观察到这样的行为。
库（copula）
设置.种子(2023)

# 以 -1 作为“相关性”的高斯关联函数范围
#
cop &lt;- copula::normalCopula(-1)

# 使用伯努利（二项式）边距定义联合分布
#“警察”作为系词
# 这里有两支优秀的球队，分别赢得了 90% 和 80% 的比赛
#
joint_dis &lt;- copula::mvdc(
  警察，
  c(“二项式”,“二项式”),
  列表（
    列表（大小= 1，概率= 0.9），
    列表（大小 = 1，概率 = 0.8）
  ）
）

# 模拟十场比赛
#
X &lt;- copula::rMvdc(10, joint_dis)

# 十中九是 (1, 1) 两队获胜的结果
# 嗯？
#
X

十个模拟游戏中有九个给出了 (1, 1) 结果，我将其解释为平局（但奇怪的是，没有任何 (0, 0) 结果，即使在一百万个模拟游戏中）。
因此，使用具有“相关性”的高斯关联函数参数设置为 $-1$ 不会强迫任何人失败（$0$ 的伯努利结果）。&lt; /p&gt;
如果这个高斯系词不起作用，那什么可以呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/635266/copula-to-ensure-one-team-wins-and-the-other-loses-bernoulli-margins</guid>
      <pubDate>Tue, 19 Dec 2023 16:13:54 GMT</pubDate>
    </item>
    <item>
      <title>您是否应该模拟混杂因素对其他混杂因素的影响来测试估计器？</title>
      <link>https://stats.stackexchange.com/questions/635194/should-you-simulate-the-effect-of-confounders-on-other-confounders-to-test-an-es</link>
      <description><![CDATA[想象一下，我正在尝试模拟数据生成过程，其中我对 $Y$ 做出以下假设：
$Y$ = $X$(0.15) + $Z_1$(0.23) + $Z_2$(0.08) + $Z_3$(0.19) + $Z_4$(0.05) + 错误
此外，考虑到我对几个估计器感兴趣，并且我正在尝试找出哪个估计器恢复了 0.15 的定义治疗效果最好。然而，$X$ 被几个变量混淆，所以我相应地调整它们。
我很清楚的是，对于我认为是混杂因素的变量，我需要模拟每个混杂因素对治疗和结果的影响大小。例如，如果 $Z_1$ 对 $Y$ 的影响为 0.23，我还需要在 $X$ 上模拟 0.04 的效果，否则，它不会是一个混杂因素。
然而，在更复杂的数据生成过程中，混杂因素可能会影响其他混杂因素本身的价值。也就是说，将每个混杂因素定义为与其他感兴趣的混杂因素完全外生的分布可能是不合适的。
例如，不要说 $Z_1$ 只是一个平均值为 $\mu 的正态分布变量$ 和标准差 $\sigma$，我也可以说 $Z_2$ 对 $Z_1$ 的影响为 0.33，$Z_3$ 对 $Z_3$ 的影响为 0.07 span class=&quot;math-container&quot;&gt;$Z_1$。
为了实现这个假设模拟的目标（测试不同的估计器，看看哪个估计器能最好地恢复治疗效果），是否有必要定义每个混杂因素对另一个混杂因素的影响？或者，只要我指定每个混杂因素对结果和治疗的影响，模拟分析就可以进行了吗？
一方面，我看到了全面详细说明系统中所有变量的假设数据生成过程的好处。然而，另一方面，我发现我将进一步的假设嵌入到对不感兴趣的效应大小的分析中存在问题（即我没有实际兴趣了解/思考如何 $ Z_3$ 可能会影响 $Z_1$、$Z_2$、$Z_4$ 等）。]]></description>
      <guid>https://stats.stackexchange.com/questions/635194/should-you-simulate-the-effect-of-confounders-on-other-confounders-to-test-an-es</guid>
      <pubDate>Mon, 18 Dec 2023 15:08:33 GMT</pubDate>
    </item>
    <item>
      <title>经验基函数</title>
      <link>https://stats.stackexchange.com/questions/623344/empirical-basis-functions</link>
      <description><![CDATA[初步
考虑 $n$ 个个体，每个个体都有观察到的数据$ Z_i, i = 1, \ldots, n$。对于每个单独的 $i$，纵向预测变量 $Z_i = \{Z_i(t_{i1}), \ldots, Z_i(t_{i,R_i})\}$ 是在有限数量的观测次数下测量的 $t_i = (t_{i1}, \ldots, t_{i ,R_i})$。我们可以将有限网格定义为 $\bigcup_{i=1}^{n} t_i$，覆盖样本的所有唯一观察时间，其中 $\tau = \max (\bigcup_{i=1}^{n} t_i)$。
文章说：
从任意一组平滑基函数开始 $\psi_1(t), \ldots, \psi_K(t)$ 来表征函数预测器，其中 &lt; span class=&quot;math-container&quot;&gt;$K$ 表示基函数的总数。该基函数集合可以是例如通过传统FPCA方法估计的经验基函数，但可以灵活地扩展到其他基函数。然后，函数数据可以用矩阵表示法重写为 $(Z_1(t), \ldots, Z_n(t))^T = \bf{\lambda}\bf{\psi }(t)$，其中 $\bf{\lambda} = (\lambda_1, \ldots, \lambda_n)^T$，其中 $\lambda_i = (\lambda_{i,1}, \ldots, \lambda_{i,K})^T$ 和 $\bf{\psi}(t) = (\psi_1(t), \ldots, \psi_K(t))^T$, $t \in [0，\tau]$。
$\bf{M}$ 的维度为 $K \times K$，其中$(k, k&#39;)$ 条目为 $\langle \psi_k(t), \psi_{k&#39;} ( t) \rangle$ 为 $k, k&#39; \in K$，$t \in [0 , \tau]$.
我的问题：
如您所见，$Z_{i}$ 是不规则且稀疏的。所以，如果我们用矩阵表示法来写它，那么里面就会有 NA。例如，
&lt;前&gt;&lt;代码&gt; ####
  设置.种子(123)
  # 观察数量
  n &lt;- 10
  # 底层函数
  f &lt;- 函数(t) {
    罪恶(t)
  }
  # 生成不规则且稀疏的函数数据
    Z &lt;- 矩阵(NA, nrow = n, ncol = 11)
    for (i in 1:n) {
    # 生成随机观察时间
    R &lt;- 样本（3:10，大小 = 1）
    t &lt;- 排序（样本（0:10，大小=R））
    # 在这些时间对函数进行采样
    y &lt;- f(t) + rnorm(length(t), sd = 0.1) # 添加一些噪音
    
    ＃ 返回
    Z[i, 匹配(t, c(0:10))] &lt;- y
    }
    列名(Z) &lt;- 0:10

所以，我的理解 $\bf{\lambda}$ 是一个矩阵 $n \times K$&lt; /span&gt; 和 $\bf{M}$ 是 $K \times K$。所以，传统 FPCA 方法估计的经验基函数就是特征函数，但如果是这样，我就不能有 $K$ 特征函数随后无法获得系数矩阵 $\bf{\lambda}$ （或分数）即 $n \times K $]]></description>
      <guid>https://stats.stackexchange.com/questions/623344/empirical-basis-functions</guid>
      <pubDate>Sun, 06 Aug 2023 20:56:16 GMT</pubDate>
    </item>
    </channel>
</rss>