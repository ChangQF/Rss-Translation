<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 23 Oct 2024 09:17:59 GMT</lastBuildDate>
    <item>
      <title>对于时间序列来说，样本外验证是否也应该超出时间范围？</title>
      <link>https://stats.stackexchange.com/questions/656180/should-out-of-sample-validation-also-be-out-of-time-for-time-series</link>
      <description><![CDATA[简介
在训练模型时，“样本”通常是指用于拟合模型的数据，因此...
样本：用于训练模型的数据
样本外：未用于训练模型的数据
超出时间：未用于训练模型的数据，晚于用于训练模型的数据
有时规定您必须对模型进行“样本外”和“超出时间”验证。但不清楚什么是“超出时间”已经是“样本外”了。
解释 1
这里的解释是进行两次独立的验证运行：

对“及时”的“样本外”数据进行验证
对同样“样本外”的“时间外”数据进行验证


我认为这里最大的缺陷是“样本外”验证将是“及时的”，因此绩效指标可能会被夸大。例如，如果“及时”期间是在 covid 期间，那么您将获得“样本外”验证结果，表明您在这些未见过的客户上做得很好，而实际上，该模型在生产环境中对未见过的客户的表现会很糟糕。
解释 2
这里的解释是，报告“及时”和“样本外”数据中的任何数字都没有意义，因为这些数字实际上并没有说明现实世界的表现。相反，向监管机构报告的所有验证数字都是过时的。

仅对“样本外”数据进行“过时”的验证。这是对现实世界表现的最保守的估计。这也是通用性的最佳指标。这里的“样本外”也指甚至没有“及时”进入训练样本的客户。
对所有“超出时间”的进行验证数据，因为这是对近期业绩的最佳估计，因为客户群在近期（例如未来 2-3 年）通常相当稳定。


根据这种解释，您报告的最保守的数字很可能最能反映现实世界的表现并反映普遍性（例如对未见过的客户）。
问题
您会使用哪种解释？您认为这两种解释同样有效吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656180/should-out-of-sample-validation-also-be-out-of-time-for-time-series</guid>
      <pubDate>Wed, 23 Oct 2024 07:39:33 GMT</pubDate>
    </item>
    <item>
      <title>逆协方差估计的样本要求</title>
      <link>https://stats.stackexchange.com/questions/656179/sample-requirements-for-inverse-covariance-estimation</link>
      <description><![CDATA[我有一个输入信号矩阵 $X$，其形状为 4 x N，每行包含相同的信号，但具有恒定的时间延迟（与阵列信号处理相关）
$$X[i, :] = X(t-i\tau)$$
我的目标是找到信号的逆协方差矩阵，
$$ R^{-1} = (XX^H)^{-1}$$
我想知道的是，是否有任何统计方法可以找到使矩阵可逆所需的最小时间样本和最大样本，直到信号不再平稳。
该应用是无线通信，因此在基带，$\mu_i = 0$ 或接近于零，因此被忽略。]]></description>
      <guid>https://stats.stackexchange.com/questions/656179/sample-requirements-for-inverse-covariance-estimation</guid>
      <pubDate>Wed, 23 Oct 2024 06:37:14 GMT</pubDate>
    </item>
    <item>
      <title>关于多元密度函数的估计</title>
      <link>https://stats.stackexchange.com/questions/656177/on-estimation-of-multivariate-density-function</link>
      <description><![CDATA[设$(X,Y)$为非负绝对连续随机向量，概率密度函数为$f(x,y)$。然后，$f$ 的核密度估计量由以下公式给出：
$$k(x,y)=\frac{1}{nh_xh_y}\sum_{i=1}^n K\left(\frac{x-x_i}{h_x},\frac{y-y_i}{h_y}\right),$$
其中 $h_x$ 和 $h_y$ 表示带宽参数。
使用一些数据，我估计了核密度估计量：
library(ks)

# 您对 X 和 Y 的缩放数据
X &lt;- c(0.95230999, 0.00596125, 0.00298063, 0.89716841, 0.16244411, 0.01490313, 
0.1609538, 0.16244411, 0.29508197, 0.05812221, 0.5633383, 0.60804769, 
0.05365127, 0.30849478, 1, 0.04023845, 0.12965723, 0.37853949, 0, 0.57824143)

Y &lt;- c(0.01195652, 0.27318841, 0.21557971, 0.12318841, 0.21630435, 0.22572464, 
0.03550725, 0.32971014, 0.13007246, 0.22644928, 0.22427536, 0, 
1, 0.54311594, 0.36775362, 0.18152174, 0.0884058, 0.19565217, 
0.08514493, 0.0807971)

# 将 X 和 Y 合并成一个矩阵
data_matrix &lt;- cbind(X, Y)

# 使用插件方法选择带宽 (Hpi)
H &lt;- Hpi(x = data_matrix) # 插件带宽选择方法
print(H)
kde_result &lt;- kde(x = data_matrix, H = H)
plot(kde_result, cont = c(50, 75, 95)) # 50%、75% 和 95% 水平的轮廓

我的问题是“我们如何估计 $$\frac{\partial}{\partial x} F(x,t),$$ 其中 $F$ 是联合分布函数，$t$ 是某个正实数。]]></description>
      <guid>https://stats.stackexchange.com/questions/656177/on-estimation-of-multivariate-density-function</guid>
      <pubDate>Wed, 23 Oct 2024 06:20:09 GMT</pubDate>
    </item>
    <item>
      <title>如果包含两个变量之间的相互作用，是否也需要单独包含这两个变量？[重复]</title>
      <link>https://stats.stackexchange.com/questions/656176/if-you-include-an-interaction-between-two-variables-do-you-need-to-include-the</link>
      <description><![CDATA[假设我有：

模型 1：具有交互作用和主效应的回归模型：
$$ Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3(X_1 \times X_2) + \epsilon $$

模型 2：仅具有交互作用的相同回归模型：
$$ Y = \beta_0 + \beta_3(X_1 \times X_2) + \epsilon $$


使用模型 2（即忽略主效应）是否合适？我从未见过这种情况，所以我猜不合适 - 这样做有什么原因吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656176/if-you-include-an-interaction-between-two-variables-do-you-need-to-include-the</guid>
      <pubDate>Wed, 23 Oct 2024 05:44:00 GMT</pubDate>
    </item>
    <item>
      <title>动态计算 Johansen 协整检验的一组临界值</title>
      <link>https://stats.stackexchange.com/questions/656175/dynamically-calculate-a-set-of-critical-values-for-johansen-cointegration-test</link>
      <description><![CDATA[Johansen 检验中计算迹统计或最大特征值的公式涉及将特征值乘以观测值数量 (T)。

这意味着如果观测值数量足够大，例如 1K、10K、100K，迹统计可能会超过临界值。这会错误地找到不存在的协整。
有没有办法调整迹统计或临界值的公式，或者在 EVD 之上应用额外的矩阵变换以更好地匹配特征值和临界值？]]></description>
      <guid>https://stats.stackexchange.com/questions/656175/dynamically-calculate-a-set-of-critical-values-for-johansen-cointegration-test</guid>
      <pubDate>Wed, 23 Oct 2024 05:03:05 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 Arima 函数错误地包含了一个额外的 MA 项</title>
      <link>https://stats.stackexchange.com/questions/656174/arima-function-in-r-incorrectly-including-an-additional-ma-term</link>
      <description><![CDATA[在拟合 ARIMA 模型时（使用来自预测包的 Arima 函数），有一个额外的隐藏 MA 项。
library(astsa)
library(forecast)
set.seed(99)
simul_sarima &lt;- 5 + sarima.sim(ar=0.0, d=0, ma=-.3, sar=0.8, D=0, sma=-.2, S=12, n=1200)
fit_sarima &lt;- Arima(simul_sarima, order=c(0,0,1), seasonal=c(1,0,1))
summary(fit_sarima)
print(fit_sarima$model$phi)
print(fit_sarima$model$theta)

ARIMA(0,0,1)(1,0,1)[12] 具有非零均值 

ma1 sar1 sma1 均值
-0.2904 0.7911 -0.234 4.9963

Phi:
0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.7911284

Theta:
-0.29039562 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 -0.23395825 0.06794045

Phi 没问题：
AR12 = 0.7911284
Theta 有：
MA1 = -0.29039562;
MA12 = -0.23395825;
MA13 = 0.06794045
为什么是 MA13 项？
我已经手动计算了预测。他们正在考虑这个最后的 MA13 任期。]]></description>
      <guid>https://stats.stackexchange.com/questions/656174/arima-function-in-r-incorrectly-including-an-additional-ma-term</guid>
      <pubDate>Wed, 23 Oct 2024 03:39:13 GMT</pubDate>
    </item>
    <item>
      <title>证明“离散化”故障率的单调性</title>
      <link>https://stats.stackexchange.com/questions/656173/prove-the-monotone-property-of-discretized-failure-rate</link>
      <description><![CDATA[设 $F$ 为非负连续随机变量的累积分布函数，$f$ 为相应的概率密度函数。则 $F$ 的故障率为 $h(t)=f(t)/(1-F(t))$, $t\geq 0$。假设 $t\mapsto h(t)$ 不递减。现在我构建一个离散化的故障率，如下所示。
设$\lambda&gt;0$，且$m\equiv m(\lambda)$为满足$\lambda$的整数值函数，该函数满足$\lim_{\lambda\to\infty}m/\lambda\to\infty$。由 $\lambda$ 参数化的离散化故障率构造为
$$
\tilde h_\lambda(i) = \frac{F(i/\lambda)-F((i-1)/\lambda)}{1-F((i-1)/\lambda)}, \quad i=1,\ldots,m.
$$
由于 $t\mapsto h(t)$ 不减，我预计当 $\lambda$ 足够大时，上面构造的 $\tilde h_\lambda(i)$ 在 $i$ 中不减。也就是说，存在 $\lambda_0$，使得对于所有 $\lambda&gt;\lambda_0$，$\tilde h_\lambda(i)$ 在 $i=1,\ldots,m(\lambda)$ 中不减。
这是真的吗？或者我们需要对 $F,f,h$ 进行任何正则性条件吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656173/prove-the-monotone-property-of-discretized-failure-rate</guid>
      <pubDate>Wed, 23 Oct 2024 02:56:42 GMT</pubDate>
    </item>
    <item>
      <title>如何获得谱范数的收敛速度</title>
      <link>https://stats.stackexchange.com/questions/656172/how-to-get-the-convergence-rate-for-the-spectral-norm</link>
      <description><![CDATA[读了一些论文后，我发现，如果我们想获得用谱范数衡量的估计误差，试图控制诱导的$L_1$范数，$\|A\|_{L_1}=\underset{1\le j\le n}{\max}\sum_{i=1}^{n}|a_{ij}|$，是一种常见的方法。

有没有直接控制谱范数的方法？
什么内在原因使得用谱范数估计收敛速度看起来比其他范数更困难？
]]></description>
      <guid>https://stats.stackexchange.com/questions/656172/how-to-get-the-convergence-rate-for-the-spectral-norm</guid>
      <pubDate>Wed, 23 Oct 2024 02:54:49 GMT</pubDate>
    </item>
    <item>
      <title>在多元回归中，为什么添加一个变量的交互项会增加该变量的 beta 分数和重要性？</title>
      <link>https://stats.stackexchange.com/questions/656159/in-multiple-regressions-why-would-adding-interaction-terms-of-one-variable-incr</link>
      <description><![CDATA[我有一份修改并重新提交的稿件 - 审阅者要求我们为其中一个变量添加额外的交互项，比如变量 A（虚拟编码）。我将此变量的交互项：AxB、AxC、AxD 等（一些虚拟编码，一些连续）添加到新块中的新回归模型中。虽然没有多少交互项对结果变量（连续）具有显著性，但这使得变量 A 在新模型中极其显著且具有较高的标准化 beta 分数（但在没有交互项的原始回归模型中，变量 A 与因变量的相关性非常弱，在某些情况下不显著）
为什么会发生这种情况，这是一个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656159/in-multiple-regressions-why-would-adding-interaction-terms-of-one-variable-incr</guid>
      <pubDate>Tue, 22 Oct 2024 19:00:11 GMT</pubDate>
    </item>
    <item>
      <title>cdf $F(x)$ 的完全充分统计量概念</title>
      <link>https://stats.stackexchange.com/questions/656151/concept-of-complete-sufficient-statistic-for-the-cdf-fx</link>
      <description><![CDATA[我正在学习 Hogg 和 McKean 的《数理统计学导论》。在 $7.7$ 节末尾，他们讨论了多参数情况的完备性、充分性等，并提到（特别是在示例 $7.7.5.$ 中）给定随机样本 $\{X_i\}_{i=1}^n$ 的顺序统计量 $\{Y_i\}_{i=1}^n$ 已知，则条件分布与 cdf $F(x)$ 无关。然后他们提到

因此，根据充分性的定义，顺序统计量对于$F(x)$是充分的。

我很难理解这句话。到目前为止，充分性是针对从中抽取随机样本的分布的参数定义的。因此，在充分性定义（定义 $7.2.1$）中，作者提到

... 那么 $Y_1$ 就是 $\theta$ 的充分统计量...&quot;

其中 $f(x;\theta)$ 是从中抽取样本的 pdf 或 pmf。现在，我们突然开始谈论cdf 的充分统计量。这从未被定义过。
如果你拿枪指着我的头，我会证实这一点，说“由于条件分布不依赖于 cdf，因此它不能依赖于用于定义 cdf 的任何参数。”但令我感到不安的是，作者们没有给出正式定义，却突然谈论“cdf 的充分统计量”。
这对你来说明显吗？既然我已经知道我们也可以有“cdf 的充分统计量”，那么充分性究竟是如何定义的呢？最重要的是，如何定义完整性和充分性以使其适用于 cdf/pdf/参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/656151/concept-of-complete-sufficient-statistic-for-the-cdf-fx</guid>
      <pubDate>Tue, 22 Oct 2024 15:41:26 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中对二维数据进行聚类</title>
      <link>https://stats.stackexchange.com/questions/656145/clustering-two-dimensional-data-in-r</link>
      <description><![CDATA[我在一个数据框中有 35 个线性模型（b 是截距，a 是系数）：
xy &lt;- structure(list(b = c(2045.08, 2045.58, 2045.33, 2045.29, 2045.39, 
1991.67, 2053.54, 2048.3, 2049.76, 2003.74, 2021.51, 1984.74, 
2038.64, 2053.64, 2011.17, 2039.31, 1891.7, 1745.42, 1712.83, 
1119.93, 1097.59, 1629.34, 1638.34, 1038.81, 1673.84, 1663.97, 
784.72, 885.24, 1800.33, 1723.93, 1017.47, 1014.38, 1651.5, 2969.72, 
3254.87), a = c(2.48, 2.36, 2.42, 2.43, 2.4, 3.67, 2.29, 2.41, 
2.38, 2.69, 2.55, 2.84, 2.47, 2.35, 2.68, 2.52, 3.4, 4.33, 4.53, 
8.05, 8.18, 4.94, 4.89, 8.51, 4.7, 4.76, 9.94, 9.36, 4.04, 4.48, 
8.63, 8.19, 4.82, -1.94, -2.52)), row.names = c(NA, -35L), class = &quot;data.frame&quot;)

其中一些非常相似，我想通过聚类来减少模型数量。

数据看起来高度相关。
我尝试过 kmeans()，但它会为密集的点云生成许多聚类，并为视觉上分离的点生成一个聚类points.
kmeans(xy, 12)$centers |&gt; points(pch = 3, col = &quot;red&quot;)


可以看出，所有小于 1500 的 b 值都只有一个聚类。两个高 b 值也是如此。而 2000 左右的 b 值在视觉上密集的云被分成了几个聚类。
还有其他方法可以对此类数据进行聚类吗？
编辑：在我的情况下，3 个聚类是不够的。我的目标不是平均数据，而是丢弃相似的数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/656145/clustering-two-dimensional-data-in-r</guid>
      <pubDate>Tue, 22 Oct 2024 14:53:15 GMT</pubDate>
    </item>
    <item>
      <title>推导 DDIM 下的扩散模型得分</title>
      <link>https://stats.stackexchange.com/questions/656118/deriving-the-score-of-a-diffusion-model-under-ddim</link>
      <description><![CDATA[我试图理解扩散噪声预测模型$\epsilon_\theta(x_t)$（预测添加到样本中的噪声）与得分函数之间的线性关系是如何得出的$$\nabla_{x_t}\log p_\theta (x_t) = -\frac{1}{\sqrt{1-\bar{\alpha_t}}}\epsilon_\theta(x_t)$$，如(Dhariwal and Nichol 2021)中公式 11 所示
Lilian Weng 的博客写道，给定一个定义的前向噪声过程$q(x_t\mid x_0)\sim N(\sqrt{\bar{\alpha_t}}x_0, (1-\bar{\alpha_t})I)$我们有
$\nabla_{x_t}\log q(x_t) = \mathbb{E}_{q(x_0)}\left[\nabla_{x_t}q(x_t\mid x_0)\right]= \mathbb{E}_{q(x_0)}\left[-\frac{\epsilon_\theta(x_t,t)}{\sqrt{1-\bar{\alpha_t}}}\right]=-\frac{\epsilon_\theta(x_t,t)}{\sqrt{1-\bar{\alpha_t}}}$.
虽然这一系列等式似乎恢复了所需的等式 11，但我很难理解第一个等式，$\nabla_{x_t}\log q(x_t) = \mathbb{E}_{q(x_0)}[\nabla_{x_t}q(x_t|x_0)]$]]></description>
      <guid>https://stats.stackexchange.com/questions/656118/deriving-the-score-of-a-diffusion-model-under-ddim</guid>
      <pubDate>Tue, 22 Oct 2024 05:21:41 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何加权分位数回归中不确定性未知的点？</title>
      <link>https://stats.stackexchange.com/questions/656053/how-should-i-weight-points-for-which-the-uncertainties-are-unknown-in-a-quantile</link>
      <description><![CDATA[背景
我正在尝试分析来自不同实验研究的汇编数据，并希望得到有关如何在分位数回归中思考加权点的建议。
我并不是想做经典的荟萃分析。相反，我想对响应 $Y$ 执行分位数回归，该回归是两个连续预测变量 $X_1$ 和 $X_2$（均在实验中操纵）的函数。我的目标是获得 $X_1$ 和 $X_2$ 对 $Y$ 的 ~90 分位数的影响的最佳参数估计值（平均值/中位数不具有科学意义）。
但是，在某些情况下，我只能访问每个治疗的平均值（不是原始数据），因此我认为我需要加权点。我对加权最小二乘法的经验有限，在分位数回归方面则一无所知。我理解，在更简单的回归中，典型的方法是仅用 1/方差加权均值。但是，这并非适用于所有情况。
问题

在仅报告均值的研究中，约 1/3 没有报告相关的不确定性（SD/SE/方差）。我应该如何权衡这些点？
许多研究使用没有重复的回归设计。这在科学和统计上是合理的，但同样：我应该如何权衡这些点？
第二个问题，输入会很好但不是必需的：当我计算所有报告具有不确定性的平均值的案例的 1/方差时，我得到的值相差 2-3 个数量级。我认为这大大低估了权重较高的案例中的不确定性，可能是因为方差通常是从很少的测量中估计出来的。

解决这些问题的最佳方法是什么？在分位数回归的背景下，是否存在任何其他复杂因素？
可能不相关，但有其他背景
理想情况下，实验将使用回归设计，并在 $X_1$ 和 $X_2$ 的一致值范围内测量 $Y$。但是，实验不仅在 $X_1$ 和 $X_2$ 的值方面存在很大差异，而且在级别数量方面也存在很大差异 - 有些实验仅使用 1 或 2 个级别的 $X_1$ 和 $X_2$。
此外，理想情况下，人们应该考虑研究和物种层面的变化。我在这里完全忽略了这些，因为我认为它们不是那么重要的问题。但我很高兴在混合/分层模型的背景下也回答了这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/656053/how-should-i-weight-points-for-which-the-uncertainties-are-unknown-in-a-quantile</guid>
      <pubDate>Sun, 20 Oct 2024 19:06:46 GMT</pubDate>
    </item>
    <item>
      <title>Python 中 1：1 比率的二项式检验[关闭]</title>
      <link>https://stats.stackexchange.com/questions/656037/binomial-test-in-python-for-11-ratio</link>
      <description><![CDATA[我收集了如下的性别比例数据：
 公司 A 公司 B 公司 C
部门 女性 男性 女性 男性 女性 男性
艺术 98 2 95 5 80 20
工程 2 98 30 70 10 90
家政 100 0 90 10 70 30

现在，我的老师要求我做一个二项式检验（然后是卡方检验），以确定性别比例是否与 1:1 有统计学上的显著差异。我该如何在 Python 中做到这一点？
我尝试在这里阅读有关这个​​概念的内容：
https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/hypothesis-testing/hypothesis-testing-with-the-binomial-distribution.html
但我不确定如何具体实现它以及在哪里使用哪些变量。因为我有 3 个不同的变量：性别、公司名称和部门。或者我应该跳过部门，对不同公司进行一般比例比较？
我猜这里可能有几种不同的方法，所以我愿意听取建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/656037/binomial-test-in-python-for-11-ratio</guid>
      <pubDate>Sun, 20 Oct 2024 13:39:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么经验贝叶斯估计量没有像预期的那样占据主导地位？</title>
      <link>https://stats.stackexchange.com/questions/655839/why-is-the-empirical-bayes-estimator-not-dominating-like-its-supposed-to</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655839/why-is-the-empirical-bayes-estimator-not-dominating-like-its-supposed-to</guid>
      <pubDate>Wed, 16 Oct 2024 03:58:04 GMT</pubDate>
    </item>
    </channel>
</rss>