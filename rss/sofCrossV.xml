<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 01 May 2024 03:17:37 GMT</lastBuildDate>
    <item>
      <title>如何将带有 copula 的 ARMA-MGARCH 与数据拟合</title>
      <link>https://stats.stackexchange.com/questions/646264/how-to-fit-an-arma-mgarch-with-a-copula-to-data</link>
      <description><![CDATA[我知道 R 包，但我试图理解将多变量模型拟合到多个股票收益的过程。
假设我们有 3 个股票收益，并且我们认为它们具有依赖性，尤其是在尾部。我们决定使用 MLE 将单变量 arma-garch 拟合到每个收益（我知道这个过程）。然后我们决定使用 t-copula 来找到它们的依赖性。这个校准的过程是什么？我们是否应该将实际股票收益观测值放入其 CDF 中以获得统一观测值？或者我们应该从拟合模型中生成新的观测值，然后将它们放入 CDF 中？我们如何“校准” copula？
然后，我们如何使用 copula 和校准的单变量 arma-garch 模型来模拟观测值？
此外，这与仅校准多变量 arma-garch 模型（如 DCC）然后使用 copula 找到它们的依赖关系有何不同。
网上的所有信息都使用生成的合成数据，因此很难区分什么是真实观测值，什么是生成的观测值，或者只是使用 R 包。]]></description>
      <guid>https://stats.stackexchange.com/questions/646264/how-to-fit-an-arma-mgarch-with-a-copula-to-data</guid>
      <pubDate>Wed, 01 May 2024 02:23:41 GMT</pubDate>
    </item>
    <item>
      <title>随机变量的“坎坷”收敛[关闭]</title>
      <link>https://stats.stackexchange.com/questions/646261/bumpy-convergence-of-random-variables</link>
      <description><![CDATA[考虑序列$\left\{\dfrac{\sin(n)}{n}\right\}_{n = 1}^{\infty}$&lt; /span&gt;.
这收敛到零。然而，仅仅因为一个点位于零的 $\varepsilon$ 范围内，并不意味着每个后续点都在 $\ varepsilon$ 为零。例如， $\left\vert\dfrac{\sin(6)}{6}\right\vert &lt; \left\vert\dfrac{\sin(7)}{7}\right\vert$。 $n=6$ 处的序列比 $n=7$ 处的序列更接近于零。
这个数字没有上限。
当然，序列收敛到零，但是在序列中存在“颠簸”。一路上。这些颠簸变得越来越低，使得序列能够收敛，但在趋向于零的过程中存在颠簸。
也许这些颠簸可以通过序列 $
\左边\{
d\left(0, \dfrac{\sin(n)}{n}\right)
\right\}_{n = 1}^{\infty}
$ 不会单调减少到零（其中 $d$ 是某个度量，即 $\ mathbb R$ 在这种情况下），即使序列从点 $k&gt;1$ 开始，而不是点 $1$。
是否有类似“颠簸”的概念？存在于随机变量的收敛中，要么几乎肯定存在于概率中，要么存在于分布中？]]></description>
      <guid>https://stats.stackexchange.com/questions/646261/bumpy-convergence-of-random-variables</guid>
      <pubDate>Wed, 01 May 2024 00:56:16 GMT</pubDate>
    </item>
    <item>
      <title>变量选择策略</title>
      <link>https://stats.stackexchange.com/questions/646260/variable-selection-strategies</link>
      <description><![CDATA[我想在创建模型的背景下了解有关变量选择的当前最佳实践方法的更多信息。我对套索、引导计算变量包含频率等现代方法没有太多经验，并且一直对使用逐步选择方法感到内疚 - 主要是在预测环境中，但想改变这一点。通过阅读，我得到的总体感觉是，数据驱动的变量选择（有偏差的系数、小 SE/p 值等）引起的所有问题都是因为人们正在测试许多不同的模型而发生的。如果模型是预先指定的并且在评估后没有更改，这些不会是问题吗？
如果模型可以大致分为：

解释/因果 - 变量选择应仅由背景知识/理论驱动，并且最好得到有向非循环图的支持。该模型是预先指定的并且不会改变。您希望能够解释所得系数的“效果”。

预测 - 在这里您可以从许多潜在模型中选择一个，因为您只真正关心预测性能，而不关心单个系数。通常，由于这个原因，不会预先指定模型。因此，像套索这样的东西就可以了，因为它提供了一些变量选择元素以及优化预测性能（但我的理解是你不能轻易解释套索系数）。

描述性 - 包含 1. 和 2. 的元素 - 您对预测感兴趣，但也对系数“效果”的解释感兴趣。在这里您还可以从众多潜在模型中选择一种。我有兴趣知道在这种情况下进行变量选择的良好通用指南是什么？我找到的最接近的解决方案是计算引导包含频率并选择那些最常出现（达到某个阈值）的变量。或者这也不能否定问题吗？


任何提示将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/646260/variable-selection-strategies</guid>
      <pubDate>Wed, 01 May 2024 00:35:00 GMT</pubDate>
    </item>
    <item>
      <title>渐近无偏 + 渐近零方差 = 一致？</title>
      <link>https://stats.stackexchange.com/questions/646259/asymptotic-unbiasedness-asymptotic-zero-variance-consistent</link>
      <description><![CDATA[此处，Ben 表明无偏估计量 $\hat渐近方差为零的参数 $\theta$ 的 \theta$ 收敛于 $ 的概率\theta$。也就是说，$\hat\theta$ 是 $\theta$ 的一致估计量。
我们应该能够将条件放宽到渐近无偏性，这是有道理的：$\underset{n\rightarrow\infty}{\lim} \mathbb E\left[\hat\theta_n - \theta\right] = 0$。这似乎符合估计器接近真实参数值的精神......
...但是数学以前就让我感到惊讶。
我们可以将条件放宽到渐近无偏吗？证据是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/646259/asymptotic-unbiasedness-asymptotic-zero-variance-consistent</guid>
      <pubDate>Wed, 01 May 2024 00:32:23 GMT</pubDate>
    </item>
    <item>
      <title>如何理解实数（或其他无界集合）上的均匀分布？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/646258/how-to-make-sense-of-a-uniform-distribution-over-the-real-numbers-or-on-some-ot</link>
      <description><![CDATA[“选择一个随机实数，”看起来足够无害。但仔细想想，这似乎行不通。这样的 CDF 必须具有恒定的斜率，但又具有 $\underset{x\rightarrow -\infty}{\text{lim}} F_X(x)= 0$ 和 $\underset{x\rightarrow +\infty}{\text{lim}} F_X(x)= 1$。
每条斜线都不符合这些限制条件。
每条水平线至少不满足一个限制条件。
所以看起来 $U\left(-\infty, \infty\right)$ 是无意义的。同时，“选择一个随机实数”，看起来很基本。
能否将$U\left(-\infty, \infty\right)$变得形式化，也许通过一些测度论的技巧？]]></description>
      <guid>https://stats.stackexchange.com/questions/646258/how-to-make-sense-of-a-uniform-distribution-over-the-real-numbers-or-on-some-ot</guid>
      <pubDate>Wed, 01 May 2024 00:05:59 GMT</pubDate>
    </item>
    <item>
      <title>当样本比例恒定并且样本量增加时概率降低的直觉</title>
      <link>https://stats.stackexchange.com/questions/646256/intuition-behind-probability-decrease-when-sample-fraction-is-constant-and-sampl</link>
      <description><![CDATA[假设 $X \sim Binomial(n_1,p)$ 和 $Y \sim Binomial(n_2, p) $ 含义相同（可以直接比较），选择 $n_1 =16$ 和 $例如，n_2=64$。这些数字可以是任何保留以下内容的数字：
我们希望理论样本分数在 $X$ 和 $Y$ 之间保持恒定，让我们说$\frac{1}{8}$。
可以很容易地证明并证明 $P(X &gt; 2) &gt; P(Y &gt; 16)$ 以及 $P(X=2)&gt;P(Y=16)$ （注意恒定样本分数）。但凭直觉，为什么这是真的呢？
（请注意，我可能会将统计数据与纯概率混淆）
首先，我尝试考虑我们想要的观测数量和期望之间的距离，随着我们以绝对量级而非相对量级增加样本量，期望值会变得更大。
然后我想到了方差。 $\frac{Var(Y)}{Var(X)} = 4$ 这意味着理论数据的间隔更大，样本量更大。我认为 $X$ 的绝对大小低于 $Y$ 和 $X$ 更集中在中心，它比 $Y$ 获得更高的概率，但我不相信这一点.
我也试图想一个例子，它是高度近似的，因为它远非完美的二项式。假设您有一个 8 人家庭。其中 1 人感染新冠病毒的概率感觉高于 80 亿人中的 10 亿人。
如果你们能帮助我直观地理解这一点，我会非常高兴。]]></description>
      <guid>https://stats.stackexchange.com/questions/646256/intuition-behind-probability-decrease-when-sample-fraction-is-constant-and-sampl</guid>
      <pubDate>Tue, 30 Apr 2024 23:20:17 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn 中的average_ precision_score 指标如何用于非概率预测分数</title>
      <link>https://stats.stackexchange.com/questions/646252/how-does-average-precision-score-metric-in-scikit-learn-work-for-non-probability</link>
      <description><![CDATA[Scikit-learn 有一个 AP 指标函数此处
y_score（预测）的描述如下：- 目标分数，可以是正类的概率估计、置信度值或决策的非阈值度量
因此 y_score 的简单概率分数的情况很容易理解，如下所示。
y_true = np.array([0, 0, 1, 1])
y_scores = np.array([0.1, 0.4, 0.35, 0.8])
平均精度分数（y_true，y_scores）

其值为 0.83
但不清楚的是如何处理像下面这样的非概率值
y_true = np.array([1, 0, 0, 1])
y_scores = np.array([3.4, 12.1, 8.35, 0.8])
平均精度分数（y_true，y_scores）

AP值为0.416。在计算指标之前这些值是否转换为某种概率值？
然后，当我们使用负值作为分数时，y_scores = np.array([-3.4, -12.1, -8.35, -0.8]) 然后给出 AP 值为 1.0
与正值相比，为什么使用负值会改变 AP 指标。]]></description>
      <guid>https://stats.stackexchange.com/questions/646252/how-does-average-precision-score-metric-in-scikit-learn-work-for-non-probability</guid>
      <pubDate>Tue, 30 Apr 2024 22:13:32 GMT</pubDate>
    </item>
    <item>
      <title>如何将分层线性模型随机效应转化为SEM路径图？</title>
      <link>https://stats.stackexchange.com/questions/646251/how-to-translate-hierarchical-linear-model-random-effects-into-sem-path-diagram</link>
      <description><![CDATA[我一直在努力翻译随机斜率和截距以及随机变量，并将它们理解为追求路径模型的潜在变量。
例如，这里是嵌套在学校中的学生的随机斜率和随机截距模型。使用层次表示法：
$$
Y_{ij} = \beta_{0j} + \beta_{1j} X_{ij} + e_{ij}
$$
$$
\beta_{0j} = \gamma_{00} + U_{0j}
$$
$$
\beta_{1j} = \gamma_{10} + U_{1j}
$$
将其转换为路径图，我有潜在变量 $U_{0j}$ 随机截距和 $U_{1j }$ 表示随机斜率。我不确定如何将它们连接到学生级别的图表的其他部分。
]]></description>
      <guid>https://stats.stackexchange.com/questions/646251/how-to-translate-hierarchical-linear-model-random-effects-into-sem-path-diagram</guid>
      <pubDate>Tue, 30 Apr 2024 21:55:22 GMT</pubDate>
    </item>
    <item>
      <title>如何调整我的 glmmTMB 模型来解决几个问题？即协变量、参考水平、随机因素和零通胀模型</title>
      <link>https://stats.stackexchange.com/questions/646250/how-to-tweak-my-glmmtmb-model-to-address-several-items-i-e-covariates-referen</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/646250/how-to-tweak-my-glmmtmb-model-to-address-several-items-i-e-covariates-referen</guid>
      <pubDate>Tue, 30 Apr 2024 21:35:21 GMT</pubDate>
    </item>
    <item>
      <title>自变量使用什么时间窗口？</title>
      <link>https://stats.stackexchange.com/questions/646248/what-time-window-to-use-for-independent-variables</link>
      <description><![CDATA[我在不同日期有 10000 个列表。我的 y 变量是上市前 7 天发生的亏损交易的百分比 &gt; 0 是 30% 或更多，然后 1 则为 0。现在，在上市之前也可能发生损失。当我在列出之前为决策树选取 x 变量时，它可能与损失日期重叠。这可以接受吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/646248/what-time-window-to-use-for-independent-variables</guid>
      <pubDate>Tue, 30 Apr 2024 21:25:08 GMT</pubDate>
    </item>
    <item>
      <title>如何描述 glm 泊松回归模型的 emmeans p 值</title>
      <link>https://stats.stackexchange.com/questions/646246/how-to-describe-emmeans-p-value-for-a-glm-poisson-regression-model</link>
      <description><![CDATA[描述计算泊松回归中特定预测变量的 p 值（通过 emmeans 对函数计算）的统计检验的正确术语是什么？
即
emmeans(~ glm(formula = ...), family=poisson) %&gt;%
     对 -&gt;产生 p 值。

用于计算这些的统计测试是什么？
另外：默认情况下测试是双面还是单面？]]></description>
      <guid>https://stats.stackexchange.com/questions/646246/how-to-describe-emmeans-p-value-for-a-glm-poisson-regression-model</guid>
      <pubDate>Tue, 30 Apr 2024 21:13:52 GMT</pubDate>
    </item>
    <item>
      <title>统计证据和样本量背景下的第二代 P 值</title>
      <link>https://stats.stackexchange.com/questions/646241/second-generation-p-values-in-the-context-of-statistical-evidence-and-sample-siz</link>
      <description><![CDATA[我目前正在研究统计分析，并且遇到了 Blume 等人提出的第二代 P 值 (SGPV) 的概念。我知道这些用于确定数据的统计显着性，但我很难理解它们与统计证据和样本量的关系。
SGPV 旨在提供观测数据与指定统计模型之间兼容性的直接测量。这似乎解决了对 P 值的一些批评。当我通读时，我有以下问题：

这个概念如何影响样本量？我们都知道，传统上我们主要使用 p 值来计算样本量。
现在，如果 SGPV 解决了 p 值的挑战，那么我们如何才能根据 SGPV 来估计样本量？知道如何计算样本量吗？
我知道 Blume 等人的论文中给出的 SGPV 的功效，但我试图看看是否可以根据功效函数计算样本大小，但 n 似乎是非线性的，使得很难使用n作为样本量计算的主题。如果有人清楚地了解如何使用幂函数来计算样本量，我会很高兴。

在您贡献的背景下，如果有人有使用 r 函数来实现上述结果的想法，欢迎他们帮助我理解这个概念并将其应用到我的研究中。
参考文献：
第二代 p 值：改进的严谨性、再现性和准确性统计分析的透明度。
补充或替换 p:
第二代 p 值简介]]></description>
      <guid>https://stats.stackexchange.com/questions/646241/second-generation-p-values-in-the-context-of-statistical-evidence-and-sample-siz</guid>
      <pubDate>Tue, 30 Apr 2024 20:14:54 GMT</pubDate>
    </item>
    <item>
      <title>如何确定样本大小来确定一段时间内的趋势？</title>
      <link>https://stats.stackexchange.com/questions/646239/how-do-i-determine-sample-size-for-determining-a-trend-over-time</link>
      <description><![CDATA[我想描述电池如何随着时间的推移而退化。由于电池内的化学物质，它们会自然衰减，导致电池多年来能量减少。我想弄清楚这种衰变是什么样的。
我有很多一批生产的电池。为了弄清楚电池有多少能量，我需要进行破坏性测试，因此这些电池只能采样一次。此外，由于其化学性质，每个电池预计都会与同一批次生产的其他电池略有不同。
我计划每月对大约 15 个电池进行采样，以了解这些年来电池的能量如何自然下降。但是，我不知道如何从数学上计算出适合我的目的的每月采样量。是否有任何方法可用于找出样本量以确定趋势？]]></description>
      <guid>https://stats.stackexchange.com/questions/646239/how-do-i-determine-sample-size-for-determining-a-trend-over-time</guid>
      <pubDate>Tue, 30 Apr 2024 19:50:36 GMT</pubDate>
    </item>
    <item>
      <title>查找离散感知器的权重和偏差</title>
      <link>https://stats.stackexchange.com/questions/646225/find-weights-and-bias-of-discrete-perceptron</link>
      <description><![CDATA[我正在准备考试，遇到了这个我无法解决的问题。
如何找到相应的权重和偏差。
我知道它是一个感知器，所以激活函数是 sigmoid = 1 / (1 + e^-x)
我尝试使用数据点并形成方程，例如 u = 2w1 + 0w2 + b 等，然后 f(u) = 1/(1 + e^(2w1 + b) ）等，但没有取得任何进展。
]]></description>
      <guid>https://stats.stackexchange.com/questions/646225/find-weights-and-bias-of-discrete-perceptron</guid>
      <pubDate>Tue, 30 Apr 2024 17:15:02 GMT</pubDate>
    </item>
    <item>
      <title>将数据拟合到马尔萨斯指数模型</title>
      <link>https://stats.stackexchange.com/questions/646224/fitting-data-to-a-malthusian-exponential-model</link>
      <description><![CDATA[我有一些来自酵母生长指数阶段的数据，我想将其拟合到指数（马尔萨斯）生长模型或曲线，因此计算增长率（及其误差）和任何拟合优度指标。我一直在浏览 R 中的一些库，但大多数都使用逻辑参数模型或线性模型进行拟合。
有人知道 R 中的一个库可以让我使用马尔萨斯增长模型进行拟合吗？
我想要拟合的数据具有以下形式，每一列都属于一个重复，我想拟合它们中的每一列以获得其单独的增长率。
时间 Lev_NP4 Lev_NP4 Lev_NP4 Lev_NP4
           1 2 3 4
           1 1 1 1
0 6.804 10.242 1.756 8.666
10 6.056 11.887 2.180 9.315
20 7.580 11.681 2.083 10.387
30 8.074 15.904 2.277 11.458
40 7.770 16.321 2.257 13.394
50 8.173 16.958 2.453 14.149
60 7.780 17.233 2.524 15.687
70 8.034 18.534 2.630 16.015
80 9.090 17.923 2.749 15.972
90 3.137 20.148 4.356 17.789
100 3.929 19.205 4.212 17.395
110 3.771 20.506 4.710 18.831
120 3.770 22.257 4.872 14.073
130 4.183 21.989 5.151 12.110
140 3.863 20.855 5.513 12.661
150 4.314 22.081 5.748 14.499
160 5.087 23.145 6.509 14.622
170 5.995 23.185 5.926 14.066
180 6.028 23.847 6.813 14.892
190 5.599 24.778 7.156 14.894
200 6.105 24.550 7.664 15.870
210 6.955 23.927 7.590 13.659
220 10.762 25.918 7.724 15.050
230 12.164 26.139 0.805 15.332
240 10.017 26.603 0.567 17.344
]]></description>
      <guid>https://stats.stackexchange.com/questions/646224/fitting-data-to-a-malthusian-exponential-model</guid>
      <pubDate>Tue, 30 Apr 2024 17:11:37 GMT</pubDate>
    </item>
    </channel>
</rss>