<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 20 Oct 2024 09:16:26 GMT</lastBuildDate>
    <item>
      <title>多臂老虎机问题的 epsilon-贪婪算法的遗憾界</title>
      <link>https://stats.stackexchange.com/questions/656031/regret-bound-of-epsilon-greedy-algorithm-for-multi-armed-bandit-problem</link>
      <description><![CDATA[考虑$1$-亚高斯 MAB，其中$n\geq 2$，考虑$\epsilon$-贪婪算法：首先选择每个臂一次，然后选择$A_t=\arg\max \hat \mu_i(t-1)$，其中 pr。 $1-\epsilon_t$，否则随机均匀选择一个臂。
我们想要证明，假设$\Delta_{\min}=\min\{\Delta_i:\Delta_i&gt;0\}$，其中$\Delta_i= \max \mu_j-\mu_i$，并让$\epsilon_t=\min\{1,\frac{Cn}{t\Delta_{\min}^2}\}$，其中$C$是足够大的通用常数，证明存在$C’&gt;0$通用标准差。
$$R_T\leq C&#39;\sum_{i=1}^n(\Delta_i+\frac{\Delta_i}{\Delta_{\min}}\log\max\{e,\frac{T\Delta_{\min}^2}{n}\}).$$
我的想法是分别分析每个 arm 的遗憾，即 arm $i$ 被选中的次数的期望，并将其分为探索部分和开发部分，在第一部分中，每个 arm 都有机会以 pr. $\epsilon_t/n$ 被选中，而在开发部分，我们可以选择一个时间阈值 $t$ s.t。当$T&gt;t$时，次优臂将以足够小的概率被选中。但是，我不知道如何选择正确的方法来达到与此问题相同的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/656031/regret-bound-of-epsilon-greedy-algorithm-for-multi-armed-bandit-problem</guid>
      <pubDate>Sun, 20 Oct 2024 08:41:53 GMT</pubDate>
    </item>
    <item>
      <title>寻找 $3\theta_2^2$ 的 MVUE 的技术背后的动机</title>
      <link>https://stats.stackexchange.com/questions/656030/motivation-behind-the-technique-to-find-mvue-of-3-theta-22</link>
      <description><![CDATA[这个问题来自 Hogg 和 McKean 的《数理统计学导论》。
练习 7.7.11。
让 $X_1,X_2,\cdots,X_n$ 成为来自 $N(\theta_1,\theta_2)$ 分布的随机样本。
(a) 证明 $E[(X_1 − \theta_1)^4] = 3\theta_2^2.$
(b) 找到 $3\theta_2^2$ 的 MVUE。
我的尝试：
$N(\theta_1,\theta_2)$ 的联合完全充分统计量是 $(\overline{X},S^2)$、样本均值和样本方差。与此处或此处所做的类似，很容易证明（对于部分 (b)）
$$T = \cfrac{3(n-1)^2\Gamma\left(\frac{n-1}{2}\right)}{16\Gamma\left(\frac{n+7}{2}\right)}S^4,$$其中$S^2=\frac{\sum_{i=1}^n(X_i-\overline{X})^2}{n-1},$给定随机样本的方差样本。对于部分 (a)，众所周知，我们可以使用 mgf 技术找到中心矩（例如，参见此处）。
我的问题：为什么作者要问部分 (a)？通常，他们这样做是为了引导读者找到解决部分 (b) 的方法。最初，我以为他们要我们猜测一个函数 $T$，使得 $\mathbb{E}(​​T) = 3\theta_2^2$ 并且 T 是 $\theta_1$ 和 $\theta_2$ 的联合完全统计量函数 $\pmb{Y}$。 这样自然会使 $T$ 成为 $3\theta_2^2$ 的 MVUE。具体来说，他们在上一节相关部分中提到（第 $448$ 页）
&quot;第 $7.3$ 和 $7.4$ 节中概述的 Rao–Blackwell、Lehmann–Scheffe 理论自然延伸到这种向量情况。简而言之，假设 $\delta = g(\pmb{\theta})$ 是感兴趣的参数，并且 $\pmb{Y}$ 是 $\pmb{\theta}$ 的充分和完整统计向量。让 $T$ 成为 $\pmb{Y}$ 函数的统计数据，例如 $T = T(\pmb{Y})$。如果 $E(T) = \delta$，则 $T$ 是 $\delta$ 的唯一 MVUE。&quot;
那么部分 (a) 如何促使我们猜测此函数 $T$？]]></description>
      <guid>https://stats.stackexchange.com/questions/656030/motivation-behind-the-technique-to-find-mvue-of-3-theta-22</guid>
      <pubDate>Sun, 20 Oct 2024 07:03:17 GMT</pubDate>
    </item>
    <item>
      <title>Anova.glm 程序 - glm 的 II 型和 III 型设置之间的结果不同，但 lm 的相同吗？</title>
      <link>https://stats.stackexchange.com/questions/656029/anova-glm-procedure-results-different-between-type-ii-and-type-iii-settings-fo</link>
      <description><![CDATA[当使用 Anova 确定一般线性模型中因素的重要性时，众所周知，当设计平衡时，II 型和 III 型设置将产生相同的结果。
但是，当应用于广义线性模型并使用偏差作为离散度度量时，即使设计平衡，II 型和 III 型设置也会产生不同的结果（当使用 car 包中的 Anova.glm() 函数时）。我想知道为什么会这样...？
我使用 R 中的以下代码进行了实验：
library(car)
FacA=c(&quot;A1&quot;,&quot;A2&quot;) ### 因子 A 的两个级别
FacB=c(&quot;B1&quot;,&quot;B2&quot;,&quot;B3&quot;) ### 因子 B 的三个级别

dft=c()
for (nA in 1:length(FacA)){
for (nB in 1:length(FacB)){
FacA0=FacA[nA]
FacB0=FacB[nB]
y=rpois(n=10,lambda=10) ## n = 10 观测值服从泊松分布
df0=c()
df0=data.frame(A=FacA0,B=FacB0,y=y)
dft=rbind(dft,df0)
}
}

### 因此 dft 是平衡设计的模拟 df 

mt2=glm(y~A+B+A:B,contrasts=list(A=&quot;contr.sum&quot;,B=&quot;contr.sum&quot;),family=poisson(link=&quot;log&quot;),data=dft)
mt3=lm(y~A+B+A:B,contrasts=list(A=&quot;contr.sum&quot;,B=&quot;contr.sum&quot;),data=dft)

############# mt3 上的方差分析，它是lm
Anova(mt3,type=&quot;II&quot;)
Anova(mt3,type=&quot;III&quot;) 
##### 它们会给出相同的结果

############# mt2 上的 Anova，它是一个 glm
Anova(mt2,type=&quot;II&quot;)
Anova(mt2,type=&quot;III&quot;) 

#### 它们不同

那么这是否意味着即使在平衡设计中，Anova.glm() 的 II 型和 III 型设置通常也会给出不同的结果？我不太明白为什么会这样，因为 mt2 中的设计矩阵是正交的……那么 II 型和 III 型在分割分散方面有什么区别？]]></description>
      <guid>https://stats.stackexchange.com/questions/656029/anova-glm-procedure-results-different-between-type-ii-and-type-iii-settings-fo</guid>
      <pubDate>Sun, 20 Oct 2024 05:12:57 GMT</pubDate>
    </item>
    <item>
      <title>在训练时向特征添加随机空值是否会使模型对这些特征的“敏感度”降低？</title>
      <link>https://stats.stackexchange.com/questions/656028/does-adding-random-null-values-to-features-at-train-time-make-models-less-sensi</link>
      <description><![CDATA[我知道可以设置几个超参数，使模型对信号的“敏感度”降低，从而提高模型的稳健性，并使其在样本外泛化方面表现更好。
但我感兴趣的是通过修改数据，使模型对某些特征的敏感度降低的方法，具体来说，就是随机将特征值更改为空值和/或随机值。我感兴趣的是使模型（梯度提升树，如 LGBM）更能抵御对抗性攻击
随机用空值/缺失值（甚至随机值）替换某些特征值会有所帮助吗？
我的直觉是，某些特征中随机出现的随机/缺失值会使模型不那么信任这些特征——从而降低特征重要性，使模型在生产中不易受到这些特征的对抗性攻击。
这有意义吗？我在文献中找不到太多关于这方面的内容。我知道dropout，它使模型变得更愚蠢，以实现正则化，但它改变的是权重/神经元，而不是数据本身。此外，我从未在深度神经网络的范围之外提到过这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/656028/does-adding-random-null-values-to-features-at-train-time-make-models-less-sensi</guid>
      <pubDate>Sun, 20 Oct 2024 05:08:04 GMT</pubDate>
    </item>
    <item>
      <title>假设 x 和 y 不相关，给定 sigma_x、sigma_y，如何计算径向方差？</title>
      <link>https://stats.stackexchange.com/questions/656027/how-do-i-compute-radial-variance-given-sigma-x-sigma-y-given-that-x-and-y-are-u</link>
      <description><![CDATA[给定 sigma_x、sigma_y，且 sigma_xy = 0。
如何将协方差矩阵的坐标系从笛卡尔坐标系转换为极坐标系，并以此计算 sigma_rho？]]></description>
      <guid>https://stats.stackexchange.com/questions/656027/how-do-i-compute-radial-variance-given-sigma-x-sigma-y-given-that-x-and-y-are-u</guid>
      <pubDate>Sun, 20 Oct 2024 05:07:42 GMT</pubDate>
    </item>
    <item>
      <title>既然 AlexNet 可以放在 1 GB 的内存中，为什么还要将其分成两个 GPU，每个 GPU 的内存大小为 3GB？</title>
      <link>https://stats.stackexchange.com/questions/656026/why-was-alexnet-split-on-two-gpus-each-of-memory-size-3gb-when-it-can-fit-on-1-g</link>
      <description><![CDATA[在8.1. 深度卷积神经网络（AlexNet）— 深入学习一书中，它声称：

在最后的卷积层之后，有两个巨大的全连接层，有 4096 个输出。这些层需要近 1GB 的模型参数。由于早期 GPU 的内存有限，最初的 AlexNet 采用了双数据流设计，这样它们的两个 GPU 中的每一个都可以只负责存储和计算其一半的模型。幸运的是，现在 GPU 内存相对充足，所以我们很少需要在 GPU 上拆分模型（我们版本的 AlexNet 模型在这方面与原始论文有所不同）。

在原始论文中，他们只是说

单个 GTX 580 GPU 只有 3GB 内存，这限制了可以在其上训练的网络的最大大小。事实证明，120 万个训练示例足以训练太大而无法在一个 GPU 上容纳的网络。因此，我们将网络分散到两个 GPU 上。

所以我想准确计算它应该占用多少内存。
该网络有 6000 万个参数和 650,000 个 float32 格式的神经元。它通过动量梯度下降训练，批量大小为 128。因此，在训练期间，每个参数对应 3 个参数（参数本身、梯度、动量）。这样就有了 1.8 亿个参数，也就是 720 MB。
它还需要存储 128 张图像的激活模式，因此就有 $0.65 \times 128 = 83$ 百万个参数，也就是 332 MB。
总共大约有 1 GB，比单个 GPU 上的 3GB 要低得多。
那么，为什么他们将 AlexNet 分成两半，并声称它不适合单个 GPU？]]></description>
      <guid>https://stats.stackexchange.com/questions/656026/why-was-alexnet-split-on-two-gpus-each-of-memory-size-3gb-when-it-can-fit-on-1-g</guid>
      <pubDate>Sun, 20 Oct 2024 04:48:22 GMT</pubDate>
    </item>
    <item>
      <title>理解条件独立性的因式分解，摘自 Kevin Murphy 第 2 册</title>
      <link>https://stats.stackexchange.com/questions/656014/understanding-the-factorization-of-conditional-independence-from-kevin-murphy-bo</link>
      <description><![CDATA[我正在阅读 Kevin Murphy 的新书 2（高级主题），我想澄清一个简单的推导。在第 156-157 页，对概率图模型进行了分解。 pgm 显示如下

在下面显示的概率模型中：
$$
p(\theta, D) = p(\theta_x)p(\theta_y) \prod_{n=1}^{N} p(y_n \mid \theta_y)p(x_n \mid y_n, \theta_x) \tag{4.38}
$$
由此可知：
$$
p(\theta, D) = \left[ p(\theta_y) \prod_{n=1}^{N} p(y_n \mid \theta_y) \right] \left[ p(\theta_x) \prod_{n=1}^{N} p(x_n \mid y_n, \theta_x) \right] \tag{4.39}
$$
下一步写为：
$$
p(\theta, D) = \left[ p(\theta_y) p(D_y \mid \theta_y) \right] \left[ p(\theta_x) p(D_x \mid \theta_x) \right] \tag{4.40}
$$
其中：
$$
D_y = \{y_n\}_{n=1}^{N} \quad \text{and} \quad D_x = \{x_n, y_n\}_{n=1}^{N}。
$$
我的问题是：等式 $(4.40)$ 能否从 $(4.39)$ 得出？具体来说，方程$(4.40)$表明联合概率项$p(x_n, y_n \mid \theta_x)$，而不是$(4.39)$中的条件项$p(x_n \mid y_n, \theta_x)$。
我理解以下说法是正确的：
$$
p(x_n \mid y_n, \theta_x) = \frac{p(x_n, y_n \mid \theta_x)}{p(y_n \mid \theta_x)}。
$$
但是，除非我们假设 $y_n$ 和 $\theta_x$ 是独立的，否则方程 $(4.40)$ 怎么能成立呢？根据 d 分离规则，观察 $x_n$ 会使 $y_n$ 和 $\theta_x$ 相互依赖。有人能解释一下从 $(4.39)$ 到 $(4.40)$ 的转变的有效性吗？
PS：我已经在 math.stackoverflow 上问过这个问题，但没有得到任何答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/656014/understanding-the-factorization-of-conditional-independence-from-kevin-murphy-bo</guid>
      <pubDate>Sat, 19 Oct 2024 17:56:27 GMT</pubDate>
    </item>
    <item>
      <title>MNAR（非随机缺失）不是一个无法证明的假设吗？</title>
      <link>https://stats.stackexchange.com/questions/656010/isnt-mnar-missing-not-at-random-just-an-unprovable-hypothesis</link>
      <description><![CDATA[如果参与者在干预或安慰剂分配后在研究中退出，并且我们根据这些退出结果分析数据，我们是否只能识别关联而不是因果关系，因为我们使用的是病例对照设计，其中病例是退出者，非病例是非退出者？
此外，除了随机分配的治疗（如药物或安慰剂）之外，难道不可能找到 MNAR 对任何变量的决定因素吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656010/isnt-mnar-missing-not-at-random-just-an-unprovable-hypothesis</guid>
      <pubDate>Sat, 19 Oct 2024 17:40:43 GMT</pubDate>
    </item>
    <item>
      <title>什么时候 bagging 实际上会导致更高的方差？</title>
      <link>https://stats.stackexchange.com/questions/656007/when-can-bagging-actually-lead-to-higher-variance</link>
      <description><![CDATA[根据线性回归的高斯-马尔可夫假设，普通最小二乘估计 (OLS) 在所有无偏线性估计中具有最小方差。
在这种情况下，“Bagging”也是线性和无偏的，因此其方差必须严格更差。基于零独立变量（即只有一个偏差项）的情况，我的直觉是，当随机采样数据的模型数量趋于无穷大时，方差接近 OLS。
在决策树的设置中，与使用单个决策树相比，从 bagging（随机森林）获得的方差更低，这并不让我感到惊讶。但考虑到线性回归的情况，我看到的对此的解释似乎证明太多了。应满足哪些条件才能确保 bagging 不会使方差恶化？]]></description>
      <guid>https://stats.stackexchange.com/questions/656007/when-can-bagging-actually-lead-to-higher-variance</guid>
      <pubDate>Sat, 19 Oct 2024 15:28:15 GMT</pubDate>
    </item>
    <item>
      <title>两个随机变量之间差异的概率区间</title>
      <link>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</link>
      <description><![CDATA[假设 X1 和 X2 是两个随机变量，其中 X1 有 95% 的概率位于区间 [L1, R1] 内，X2 有 95% 的概率位于区间 [L2, R2] 内。这是否意味着差值 X1 - X2 有超过 95% 的概率位于区间 [L1 - R2, R1 - L2] 内？此外，X1 和 X2 可以是相关的，也可以是独立的。
(1) 有人可以澄清概率界限是否适用于这种情况吗？或者这个说法的反例。
(2) 如果有反例，是否有其他条件可以添加以使其成立？]]></description>
      <guid>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</guid>
      <pubDate>Fri, 18 Oct 2024 19:35:37 GMT</pubDate>
    </item>
    <item>
      <title>条件不平衡独立变量在回归中是一个问题吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655709/are-conditional-unbalanced-independent-variables-an-issue-in-regression</link>
      <description><![CDATA[这是一个非常具体的问题，无缘无故关闭了...
描述
我有一个具有以下特征的数据集：

Y：平衡的二元因变量（例如 50% 就业/50% 失业）
X1：平衡的二元自变量（例如 50% 治疗/50% 控制）
X2：分类自变量（例如国家）

X1 是感兴趣的变量，目标是估计 X1 对 Y 的因果影响，而不是预测。
可以观察到 X2 和 X1 以及 X2 和 Y 之间的相关性（或关系，因为变量不是度量）。
问题
如果我将 X1 和 X2 分组（例如按国家/地区进行治疗和未治疗），我可以观察到子组不平衡。在某些子组中，接近 100% 的数据来自某个 x1 类（例如治疗组），在其他子组中，接近 100% 的数据来自不同的类（例如未治疗组），在某些子组中，数据在 x2 方面是 50%/50% 平衡的。换句话说，有些子组是纯粹的。
问题：

从数学角度来看，条件子组不平衡（或在极端情况下是纯粹性）是否会成为 x1 系数/估计量及其重要性的问题？如果一个条件子组是纯粹的（例如由 100% 控制或治疗单位组成），会发生什么？

Peter Floms 的回答暗示这可能是一个分离问题。但是，从我的角度来看，分离是一种现象，定义为预测因子完美地分裂/预测独立变量。但在这种情况下，条件子组中没有方差，但结果中有方差，因此它不是完美地分割因变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/655709/are-conditional-unbalanced-independent-variables-an-issue-in-regression</guid>
      <pubDate>Sun, 13 Oct 2024 00:15:01 GMT</pubDate>
    </item>
    <item>
      <title>如何制作两个完全负相关的增长几何布朗运动（GBM）系列？（不可能）</title>
      <link>https://stats.stackexchange.com/questions/655735/how-to-make-two-perfectly-negatively-correlated-growing-geometric-brownian-motio</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655735/how-to-make-two-perfectly-negatively-correlated-growing-geometric-brownian-motio</guid>
      <pubDate>Fri, 11 Oct 2024 23:13:17 GMT</pubDate>
    </item>
    <item>
      <title>固定效应回归模型中模型非常不稳定，变量大多不显著</title>
      <link>https://stats.stackexchange.com/questions/648072/very-unstable-model-and-mostly-insignificant-variables-in-fixed-effects-regressi</link>
      <description><![CDATA[我的目标是通过几个公司和宏观经济控制变量来找出欧盟排放许可价格对公司自由现金流的影响。我为此使用的数据集涵盖了大约 500 家公司和 2005 年至 2022 年的数据。
我在 R 中建立了一个单向固定效应模型（内部），并尝试用它来估计模型。它导致了以下结果，这些结果还可以，但在我看来没有意义，因为我确信一些变量应该有显著的影响，比如 GDP 增长。
我可以做什么/调查什么，看看我估计模型的方式是否有错误？我是否需要以某种方式转换变量（尝试过对数、标准化、差分等方法）？
R 输出：
模型内的单向（个体）效应

调用：
plm(formula = FCFF ~ GDP_Growth + INTANGIBLE_ASSETS + REVENUE + 
DEPRECIATION + TOTAL_ASSETS + Patents_Filed + Exchange_Rate_EUR.CNY + 
Inflation + Oil_Price + Lead_Spot + EU_ETS_Future + EU_ETS_Spot, 
data = data, model = &quot;within&quot;)

平衡面板：n = 511，T = 18，N = 9198

残差：
最小值 第 1 区 中位数 第 3 区 最大值。
-5609351.5 -5784.3 -676.8 3676.6 7938700.2 


Signif.代码：0 ‘’ 0.001 ‘’ 0.01 ‘’ 0.05 ‘.’ 0.1 ‘ ’ 1

总平方和：3.5016e+14 

残差平方和：2.8466e+14 

R 平方：0.18705 

调整 R 平方：0.13814 

F 统计量：12 和 8675 DF 上的 166.339

p 值：&lt; 2.22e-16

编辑/更新：
不确定我是否需要提出新问题或只是编辑帖子，所以只是先尝试​​编辑。
我对模型做了一些更改，包括使用新的、更好的数据集和标准化变量。我还稍微改变了边界内的变量，使它们之间不产生共线性。这导致了以下更新的结果。然而，R 平方仍然出奇地低。而且 p 值似乎有点好得令人难以置信。
不确定现在我是否可以使用这样的结果。
更新的数据输出：
]]></description>
      <guid>https://stats.stackexchange.com/questions/648072/very-unstable-model-and-mostly-insignificant-variables-in-fixed-effects-regressi</guid>
      <pubDate>Mon, 27 May 2024 12:34:17 GMT</pubDate>
    </item>
    <item>
      <title>解释 emmeans R 中 cld 输出的字母</title>
      <link>https://stats.stackexchange.com/questions/646903/interpreting-letters-from-cld-output-from-emmeans-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/646903/interpreting-letters-from-cld-output-from-emmeans-r</guid>
      <pubDate>Thu, 09 May 2024 00:26:12 GMT</pubDate>
    </item>
    <item>
      <title>过度参数化对局部最小值的影响</title>
      <link>https://stats.stackexchange.com/questions/583697/the-effect-of-over-parameterization-on-local-minima</link>
      <description><![CDATA[在阅读一些关于深度学习模型中过度参数化的论文时，我还读到“过度参数化是一种引入额外维度的简单方法，有助于使局部最小值成为鞍点，因此优化器不太可能停留在局部最小值，并且可以找到全局最小值。”
我的问题是，过度参数化和更多维度如何帮助将局部最小值变成鞍点？我搜索了很多，但没有找到任何证明或例子来说明这一点。提前谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/583697/the-effect-of-over-parameterization-on-local-minima</guid>
      <pubDate>Fri, 29 Jul 2022 23:07:14 GMT</pubDate>
    </item>
    </channel>
</rss>