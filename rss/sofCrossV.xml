<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 10 Oct 2024 12:33:13 GMT</lastBuildDate>
    <item>
      <title>同一研究中对不同变量进行不同的变换</title>
      <link>https://stats.stackexchange.com/questions/655597/different-transformations-to-different-variables-in-the-same-study</link>
      <description><![CDATA[在创建综合指数时，我可以对不同的变量使用不同的转换来解决同一研究中的偏斜和异常值吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655597/different-transformations-to-different-variables-in-the-same-study</guid>
      <pubDate>Thu, 10 Oct 2024 12:27:02 GMT</pubDate>
    </item>
    <item>
      <title>如何扩展 Greenwald Khanna 来维持值的错误界限？</title>
      <link>https://stats.stackexchange.com/questions/655596/how-to-extend-greenwald-khanna-to-maintain-an-error-bound-on-the-values</link>
      <description><![CDATA[Greenwald-Khanna 算法是一种节省空间的方法，用于估计数据流中的分位数，提供等级错误保证，使得任何返回值的等级都在数据集中真实等级的ϵN 范围内。
例如，假设我通过向其中输入 $N$ 个值来构建 GK 摘要。然后我可以向它询问任何分位数，比如 95% 分位数，算法将返回原始数据集中的值 $v_i$，其排名在真实第 95 分位数的 ϵN 范围内。
但 GK 无法告诉我有关值中可能存在错误的任何信息，只能告诉我排名。
那么我的问题是。是否有人扩展了 GK 算法来跟踪“值错误”？如果没有，如何处理它？&lt;​​/p&gt;
对我来说，值错误取决于摘要中的相邻元素。似乎有可能在添加元素、压缩或合并摘要等情况下保持值误差的界限...
获取值 $v_i$ 的误差上限就像查看相邻元组一样简单，即：$e_v \leq \max(v_{i+1} - v_i, v_i - v_{i-1})
$。但是修改算法以保持值误差保证似乎更具挑战性。]]></description>
      <guid>https://stats.stackexchange.com/questions/655596/how-to-extend-greenwald-khanna-to-maintain-an-error-bound-on-the-values</guid>
      <pubDate>Thu, 10 Oct 2024 12:00:09 GMT</pubDate>
    </item>
    <item>
      <title>是否存在功率变换（Box-Cox，Yeo-Yohnson）变换的简单估计，可以在 O（n）中计算？</title>
      <link>https://stats.stackexchange.com/questions/655595/is-there-a-simple-estimate-for-power-transform-box-cox-yeo-yohnson-transform</link>
      <description><![CDATA[因此，幂变换定义了一些函数 $f(\lambda,y)$，然后我们尝试找到 $\lambda$，假设 $f(\lambda|\mathbf{y}) \sim Normal(\mu,\sigma)$。
这通常通过 MLE 完成，然后使用一些迭代优化算法。
作为实现，您可以调用类似 scipy.stats.boxcox 或 sklearn.preprocessing.power_transform 的东西。
但这对于我正在做的事情来说计算速度太慢了。我想在不同的数据上循环运行它很多次。
所以我在想也许可以有一个近似公式，它会牺牲完整 MLE 迭代算法的一些精度，但能很快给我至少一个半合理的解决方案（即可能不是最优的，但至少比没有转换要好）。]]></description>
      <guid>https://stats.stackexchange.com/questions/655595/is-there-a-simple-estimate-for-power-transform-box-cox-yeo-yohnson-transform</guid>
      <pubDate>Thu, 10 Oct 2024 11:50:26 GMT</pubDate>
    </item>
    <item>
      <title>寻找一本关于使用置信度或预测区间进行时间序列异常检测的书</title>
      <link>https://stats.stackexchange.com/questions/655593/looking-for-a-book-regarding-outlier-anomaly-detection-in-time-series-using-conf</link>
      <description><![CDATA[很久以前，我读过一本书/一篇论文，作者描述了如何使用模型及其置信/预测区间来检测异常值并用预测值替换它们。
它有一个很好的时间序列图来演示这一点，如果我没记错的话，间隔是褐色的。
如果我没记错的话，这本书的章节是关于如何通过使用间隔检测异常值来用差异值替换异常值的。
过去几年我一直在寻找这本书的章节/文章，但再也找不到了。所以，我希望有人能指出这一点，并告诉我这本书/文章的名字。
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655593/looking-for-a-book-regarding-outlier-anomaly-detection-in-time-series-using-conf</guid>
      <pubDate>Thu, 10 Oct 2024 09:34:54 GMT</pubDate>
    </item>
    <item>
      <title>“可预测性”的概念（预测中）</title>
      <link>https://stats.stackexchange.com/questions/655592/the-notion-of-predictability-in-forecasting</link>
      <description><![CDATA[寻找思想伙伴来帮助我理清一个想法。
假设我是一名预报员，我面前有几个具有二元结果的事件——例如，抛硬币失败、两名候选人的选举、曼城和利物浦之间的英超联赛。
我正在寻找一种“可预测性”的衡量标准。也就是说，非常宽泛地说，是一种难以预测这些事件的结果。如果我从结果分布的角度来考虑这些，我相信这与该分布的熵相一致。如果我有关于结果的过去数据，我当然可以估计该分布，计算熵，并测量不确定性。
但是，如果我没有过去的数据，而我只知道，让我们重载一个术语，“自由度”在这些事件中，我能说说我预测结果的能力吗？
也就是说，直观地说，抛硬币感觉是我所举例子中最不可预测的——它的采样过程感觉比其他的更“随机”。在选举案例中，有一个明显的趋势导致事件发生，有许多指标/相关因素可供借鉴，感觉更容易预测。足球比赛的感觉也类似，尽管事件本身、比赛是 22 个人的复杂安排和决定、博弈论等，因此感觉介于两者之间。
当然，这些都是预感！我只是让你感受一下我正在思考的概念。我很好奇我们有什么工具可以根据这些例子的“可预测性”或做出准确预测的难度来排序它们。
也许，一个相关的想法是奇偶性：在足球比赛中，奇偶性意味着球队在所有方面都有相同的获胜机会（例如，由于球员、策略、信息的相似性）。奇偶性可能意味着最大难度/最小可预测性状态——它是随机的！因此完全可以建模。但是，二元结果事件不需要奇偶校验就可以达到最低限度的可预测性，就像弯曲硬币的情况一样。
提前致谢，期待您的想法。
编辑：我认为我正在寻找的内容可能与算法概率有关，尽管这是我不熟悉的主题！话虽如此，事件原因的数量（或复杂性？）可能是我正在寻找的重要方面。]]></description>
      <guid>https://stats.stackexchange.com/questions/655592/the-notion-of-predictability-in-forecasting</guid>
      <pubDate>Thu, 10 Oct 2024 09:33:58 GMT</pubDate>
    </item>
    <item>
      <title>选择偏差与混杂偏差的定义</title>
      <link>https://stats.stackexchange.com/questions/655590/definition-of-selection-bias-vs-confounding-bias</link>
      <description><![CDATA[我一直在学习因果推理，读过 Pearl&#39;s Primer 和“假如……”的第一部分和第二部分。
我的印象是“存在混淆”的定义是
如果
$$\exists (t,y) s.t. \mathbb{P}(Y^t=y) \neq \mathbb{P}(Y=y|t).$$，则 (T,Y) 被称为混淆。
我进一步的印象是，混淆因素，粗略地说，是我们必须调整的变量。这意味着，虽然混杂因素有明确的定义，但一般来说混杂因素没有明确的定义，因为有多个有效的变量集可以调整（或者说定义至少有点复杂，大致是这样的：如果一个变量与其他变量一起可以调整偏差（对我来说，这意味着允许我们计算因果效应），那么它就是混杂因素）。我认为 Tyler VanderWeele 有一篇关于这个的论文，但那不是重点。对我来说，所有偏差都是混杂偏差。
我经常遇到区分选择偏差和混杂偏差的资源，这让我很困惑。对我来说，SCM 框架（即 Pearl 入门书中的解释）似乎涵盖了所有场景。他们似乎还说，必须区别对待这两者。
在简单情况下（例如，当有三个变量，其中一个是共同原因/共同结果时），很明显，当我们不以共同原因为条件时，就会发生混杂偏差，而当我们以碰撞变量（共同结果）为条件时，就会发生选择偏差。总的来说，我不确定。我们能把选择偏差看作流经碰撞变量的任何关联路径吗？
选择偏差的正式定义是什么（我可能误解了混杂偏差是什么）？
应该如何区别对待它们？
非常感谢您澄清这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/655590/definition-of-selection-bias-vs-confounding-bias</guid>
      <pubDate>Thu, 10 Oct 2024 07:51:04 GMT</pubDate>
    </item>
    <item>
      <title>如果 $X^2$ 和 $Y^2$ 独立，那么 $X$ 和 $Y$ 何时独立</title>
      <link>https://stats.stackexchange.com/questions/655587/if-x2-and-y2-are-independent-when-are-x-and-y-independent</link>
      <description><![CDATA[假设 $X^2$ 和 $Y^2$ 为连续独立随机变量，支持实数。$X$ 和 $Y$ 是否独立且支持实数，还是需要附加条件？一个例子是 $X^2$ 和 $Y^2$ 是两个独立的 $\chi^2(1)$ 随机变量。
我必须证明
$$\mbox{Prob}(X \le x ,Y \le y) = \mbox{Prob}(X \le x) \mbox{Prob}(Y \le y) \quad \mbox{对于任何 $x$, $y$ 实数}。$$
我知道
$$\mbox{Prob}(X^2\le x,Y^2 \le y) = \mbox{Prob}(X^2 \le x) \mbox{Prob}(Y^2 \le y) \quad \mbox{对于任何 $x$, $y$ 实数},$$
因此，
$$\mbox{Prob}(-\sqrt{x} \le X \le \sqrt{x} ,-\sqrt{y} \le Y \le \sqrt{y})= \mbox{Prob}(-\sqrt{x} \le X \le \sqrt{x}) \mbox{Prob} (-\sqrt{y} \le Y \le \sqrt{y}) \quad \mbox{对于任何 $x$, $y$ 非负实数}。$$
我不确定如何从这里开始。我是否应该要求期望值为 0 的对称随机变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/655587/if-x2-and-y2-are-independent-when-are-x-and-y-independent</guid>
      <pubDate>Thu, 10 Oct 2024 07:03:18 GMT</pubDate>
    </item>
    <item>
      <title>如何建立 Piegorsch、Weinberg 和 Margolin（1988）中剂量反应关系的二项回归模型？</title>
      <link>https://stats.stackexchange.com/questions/655582/how-to-formulate-a-binomial-regression-model-for-the-dose-response-relationship</link>
      <description><![CDATA[我正在尝试将逻辑回归模型应用于二项式比例数据。具体来说，我正在研究 $Biometrics$ 论文“探索多因素比例表中的简单独立作用”，作者是 Piegorsch、Weinberg 和 Margolin (1988)。
以下是论文中的数据，关于暴露于两种药剂 TNF 和 IFN 后分化的细胞数量。在两种药剂的 16 种组合中，每种组合都暴露了 200 个细胞。

我正在尝试根据暴露于 TNF 和 IFN 来模拟反应的分布。
在论文中，我看到作者将解释变量 TNF 和 IFN 建模为因子，每个因子包含 4 个级别。
但是，我正在尝试使用基于 TNF 和 IFN 剂量的连续解释变量。我尝试使用平方根、对数和正弦函数转换解释变量，并尝试了 logit 和 cloglog 链接。
残差图似乎没有表明模型拟合度足够。
除其他外，我尝试的模型如下：
$$
\log\left( \frac{\pi_i}{1 - \pi_i} \right) = \beta_0 + \beta_1 \text{TNF}_i + \beta_2 \text{IFN}_i + \beta_3 \log(\text{TNF}_i + 1) + \beta_4 \log(\text{IFN}_i + 1)
$$
我的偏差残差图如下所示：

使用 cloglog 链接，我有：
$$
\log\left( -\log(1 - \pi_i) \right) = \beta_0 + \beta_1 \text{TNF}_i + \beta_2 \text{IFN}_i + \beta_3 \log(\text{TNF}_i + 1) + \beta_4 \log(\text{IFN}_i + 1)
$$
以下是我对 cloglog 的偏差残差链接：

除了对数转换，我还尝试了 TNF 和 IFN 的平方根以及 TNF 和 IFN 的正弦。
我这里遗漏了什么吗？或者我可以做些不同的事情？如果您能分享有关在此处建模剂量反应关系的任何建议或意见，我将不胜感激。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655582/how-to-formulate-a-binomial-regression-model-for-the-dose-response-relationship</guid>
      <pubDate>Thu, 10 Oct 2024 03:39:28 GMT</pubDate>
    </item>
    <item>
      <title>概率/标准正态分布作业帮助</title>
      <link>https://stats.stackexchange.com/questions/655578/probability-standard-normal-distribution-homework-help</link>
      <description><![CDATA[我在家庭作业中被这个问题难住了，想知道是否有人可以提供一些关于如何解决这个问题的建议？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655578/probability-standard-normal-distribution-homework-help</guid>
      <pubDate>Thu, 10 Oct 2024 01:56:25 GMT</pubDate>
    </item>
    <item>
      <title>证明 $\mathbb{E} (|X-Y|) = 0 \implies X^2 = Y^2$</title>
      <link>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</link>
      <description><![CDATA[$\boxed{\text{设 } X,Y \text{ 为任意随机变量。证明如果 } \mathbb{E}(​​|X-Y|) = 0，\text{则 } X^2 = Y^2。}$
我们有 $\mathbb{E}(​​|X-Y|) = 0$，我认为如果我能以某种方式证明 $X=Y$，那么它直接意味着 $X^2 = Y^2$，但我不知道如何实现。
附言：这不是任何形式的家庭作业，我只是在大学概率课程的往期考试中看到了这个问题，想尝试一下。]]></description>
      <guid>https://stats.stackexchange.com/questions/655565/proof-of-mathbbe-x-y-0-implies-x2-y2</guid>
      <pubDate>Wed, 09 Oct 2024 19:54:07 GMT</pubDate>
    </item>
    <item>
      <title>所有相关性荟萃分析</title>
      <link>https://stats.stackexchange.com/questions/655563/all-correlations-meta-analysis</link>
      <description><![CDATA[我是 MetaSEM 的新手。我正在尝试进行一个简单的元分析（我只想分析 2 个相关性；见图）。
在这里您可以找到我使用的一些模拟数据的代码，但如果没有回归，我就无法让它工作（除非我添加回归系数，否则它会永远工作下去）。这应该是一个简单的模型，但我被卡住了。我只想要两个协方差，我已经将所有方差固定为一个。换句话说，我只想对 S-D 和 I-D 之间的相关性进行元分析。
S 和 D、S 和 I 以及 D 和 I 之间的相关性存储在此处：
rSD &lt;- c(0.85, 0.8, 0.90, 0.78, 0.70,NA,NA,NA,NA,NA)
rSI &lt;- c(NA,NA,NA,NA,NA,0.85,NA,NA,NA,NA)
rDI &lt;- c(NA,NA,NA,NA,NA,0.60, 0.50, 0.55, 0.60, 0.55)

rSI 可能是 al NA，因为我对这种相关性不感兴趣。
我读过关于 SEM 和 RAM 模型的文章，我认为这个模型是可以识别的，应该很容易拟合。任何帮助和指导都将不胜感激。
library(metaSEM)
source(&quot;http://www.suzannejak.nl/MASEM_functions.R&quot;)

rSD &lt;- c(0.85, 0.8, 0.90, 0.78, 0.70,NA,NA,NA,NA,NA)
rSI &lt;- c(NA,NA,NA,NA,NA,0.85,NA,NA,NA,NA)
rDI &lt;- c(NA,NA,NA,NA,NA,0.60, 0.50, 0.55, 0.60, 0.55)

N &lt;- c(10000,40000, 30000, 10000, 10000,20000,10000, 50000, 10000, 10000 )

数据 &lt;- as.data.frame(cbind(rSD,rSI,rDI, N))

nvar &lt;- 3
varnames &lt;- c(&quot;S&quot;,&quot;D&quot;, &quot;I&quot;)
labels &lt;- list(varnames,varnames)

cormatrices &lt;- readstack(data[,c(2,1,3)], no.var = nvar, var.names = varnames, diag = FALSE)

n &lt;- data$N

pattern.na(cormatrices, show.na=F)
pattern.n(cormatrices, n=n)

my.df &lt;- Cor2DataFrame(cormatrices, n, acov = &quot;weighted&quot;)

## 使用指定模型lavaan 语法
模型 &lt;-
&#39;

# 协方差
D ~~ I
D ~~ S
# 方差

D ~~ 1*D
S ~~ 1*S
I ~~ 1*I
&#39;

RAM1 &lt;- lavaan2RAM(model, obs.variables=varnames)
RAM1

## 创建具有隐式对角线约束的模型隐含相关结构
M0 &lt;- create.vechsR(A0=RAM1$A, S0=RAM1$S)

## 创建异质性方差-协方差矩阵
T0 &lt;- create.Tau2(RAM=RAM1, RE.type=&quot;Diag&quot;, Transform=&quot;expLog&quot;, RE.startvalues=0.05)

## 拟合模型
mx.fit0 &lt;- osmasem(model.name=&quot;No moderator&quot;, Mmatrix=M0, Tmatrix=T0, data=my.df)

## 查看结果
summary(mx.fit0, fitIndices = TRUE)
VarCorr(mx.fit0)

]]></description>
      <guid>https://stats.stackexchange.com/questions/655563/all-correlations-meta-analysis</guid>
      <pubDate>Wed, 09 Oct 2024 19:33:34 GMT</pubDate>
    </item>
    <item>
      <title>在风险函数的定义中，$\leq$ 应该放在哪里？</title>
      <link>https://stats.stackexchange.com/questions/655562/where-should-the-leq-go-in-the-definition-of-the-hazard-function</link>
      <description><![CDATA[我在几本教科书和在线资源中都看到过两种风险函数定义。
定义 1。这里例如。
$$h(t) = \lim_{\epsilon \to 0+}\dfrac{P(t &lt; T \leq t + \epsilon \mid T &gt; t)}{\epsilon},$$
定义 2。这里例如。
$$h(t) = \lim_{\epsilon \to 0+}\dfrac{P(t \leq T &lt; t + \epsilon \mid T \geq t)}{\epsilon}.$$
我推测如果 $T$ 是绝对连续的，那么它们是等价的。但是，是否存在它们不同的情况？如果有，哪一个是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/655562/where-should-the-leq-go-in-the-definition-of-the-hazard-function</guid>
      <pubDate>Wed, 09 Oct 2024 18:40:31 GMT</pubDate>
    </item>
    <item>
      <title>协方差对 LDA 函数的影响</title>
      <link>https://stats.stackexchange.com/questions/655524/influence-of-covariance-on-the-lda-functions</link>
      <description><![CDATA[我试图理解线性判别分析 (LDA) 在数据集中的行为，其中某个变量与许多其他变量高度相关，但为了简单起见，假设这个特定变量 变量 1 - 表现出微小的类方差（例如，合并方差为 0.01，组的平均距离向量为 0.09）。尽管该变量在 LDA 加载中的权重出奇的高，但它根本无法有效地区分类别。
相比之下，我已经确定了另一个变量，变量 2，它充当了近乎完美的判别器（它的合并方差为 0.1，因此比变量 1 大一个数量级，类均值之间的距离向量为 0.77，但与其他变量不相关。
我注意到，在 LDA 加载中，相关性高、判别性低的变量比强判别器变量 2 的权重更大。这让我开始质疑 LDA 在确定变量重要性时如何处理相关性和协方差。具体来说，我正在努力寻找协方差如何影响 LDA 模型背后的数学原理，以及相关变量可能掩盖真正重要判别器识别的潜在“临界点”。决定相关性/协方差如何变化的边界条件是什么是否会影响 LDA 作为识别最佳判别器的工具的有效性？
我的看法是，方差只是简单地缩放生成的 LDA 向量，而当协方差不为 0 时，它们会旋转生成的向量，我怀疑这就是变量 1 比变量 2 获得更多权重的地方，因为变量 1 解释或解决了更多来自其他变量的噪声，因为它们具有相关性。无论如何，这些都是我的想法，但我现在需要一些信息来让整个故事有意义，以便更好地理解 lda 的实际工作原理以及何时应该谨慎解释其结果。谢谢！
附注：我自然假设两个类的协方差矩阵相等。我的问题是关于具有冗余信息的变量之间的强关系的影响。]]></description>
      <guid>https://stats.stackexchange.com/questions/655524/influence-of-covariance-on-the-lda-functions</guid>
      <pubDate>Wed, 09 Oct 2024 11:11:13 GMT</pubDate>
    </item>
    <item>
      <title>如何模拟随时间变化的响应数据？</title>
      <link>https://stats.stackexchange.com/questions/655516/how-to-simulate-response-data-that-varies-over-time</link>
      <description><![CDATA[我正在模拟一些数据以进行功效分析，我们将在实验环境中测试儿童的反应时间，看看这是否能预测以后的语言技能。孩子们将根据第三个变量分组（此处为组）。我们将使用的统计模型如下所示：语言 ~ RT * 时间点 + 组。
我在创建RT变量时遇到了一些困难，因此它随着时间的推移而变化，并且与受试者相关。它应该随着时间的推移而增加，效果为 0.2，但当然这会因参与者而异，有些人的增幅较大，有些人的增幅较小（假设抖动效果为 0.1）。类似地，有些参与者的总体观看时间会更长，有些则更短。
我们目前的代码大致如下：

# 首先指定模型中每个变量的值
SimulatedData &lt;- function(
MeanIntrpct = 37.5, # 基线语言分数
MeanSlope = 14.63, # 组对语言分数的总体影响
Group = 0.39, # 组对语言分数的估计影响
time_slope = .2, # 时间点对反应时间的估计影响
n_subjects = 60, # 受试者数量
n_timepoints = 3, # 时间点数量
RandIntrpct_subjects = 0.2, # 受试者的随机截距
RandSlope_subjects = 0.2, # 受试者的随机斜率
Randslope_subject_time = 0.1 # 时间的抖动效应受试者之间
){

# 模拟数据以反映我们的受试者

SimulatedSubjects &lt;- faux::rnorm_multi(
n = n_subjects, 
mu = 0, 
sd = c(RandIntrcpt_subjects, RandSlope_subjects, Randslope_subject_time), 
varnames = c(&quot;RandIntrcpt_subjects_StdDev&quot;, &quot;RandSlope_subjects_StdDev&quot;, 
&quot;RandSlope_subjects_time_StdDev&quot;)) %&gt;%
mutate(ChildID = faux::make_id(nrow(.), &quot;S_&quot;),
Group = sample(c(1, 2), 60, replace= T)) # 将一半参与者分配到组 1/组 2

#模拟数据以反映时间点

时间点 &lt;- data.frame(Timepoint = seq_len(n_timepoints))

# 创建组合数据框 - 模拟受试者与时间点交叉

SimulatedSubjectsAndStimuli &lt;- crossing(SimulatedSubjects, timepoints)

# 模拟 RT 数据，60 个受试者 * 3 个时间点 = 180 行

SimulatedSubjectsAndStimuli &lt;- SimulatedSubjectsAndStimuli %&gt;%
mutate(RT = runif(n_subjects*n_timepoints, min = -0.5, max = 0.5))

}

SimulatedData &lt;- SimulatedData()

SimulatedData &lt;- SimulatedData()

&gt; head(模拟数据)
# A tibble: 6 × 7
RandIntrcpt_subjects_StdDev RandSlope_subjects_StdDev RandSlope_subjects_time_StdDev ChildID 组时间点 RT
&lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;
1 -0.584 0.0153 -0.137 S_42 1 1 -0.452 2 -0.584 0.0153 -0.137 S_42 1 2 -0.265 3 -0.584 0.0153 -0.137 S_42 1 3 -0.0435 4 -0.412 -0.157 0. 169 S_15 1 1 -0.491 5 -0.412 -0.157 0.169 S_15 1 2 -0.176 6 -0.412 -0.157 0.169 S_15 1 3 0.152 


正如您在数据输出中看到的那样，RT 会随时间变化，但不会朝任何预期的方向变化；它是随机的。如何模拟功率分析的数据来表示我们预期的随时间变化类型（即，随时间延长的观察时间，与受试者相关）？]]></description>
      <guid>https://stats.stackexchange.com/questions/655516/how-to-simulate-response-data-that-varies-over-time</guid>
      <pubDate>Wed, 09 Oct 2024 08:09:21 GMT</pubDate>
    </item>
    <item>
      <title>我们如何阻止贝叶斯估计过度自信？</title>
      <link>https://stats.stackexchange.com/questions/655504/how-do-we-stop-bayesian-estimates-from-being-overconfident</link>
      <description><![CDATA[我今天发布了一个关于小样本回归策略的问题。我认为贝叶斯回归可能是一个不错的选择：用于校正小样本的贝叶斯回归
有一件事我很好奇，我读到贝叶斯推理的优势在于它可以防止在我们对数据没有信心或样本量较小的情况下估计值出现非常大的方差。在这种情况下，与数据相比，估计值可以向先验收缩，从而与非贝叶斯方法相比，降低了参数估计值的方差。
我只是想知道，我们如何防止/我们如何知道贝叶斯方差的减少不是明显低估方差？在我看来，唯一要做的就是选择一个非常大的先验（例如非信息先验）来反映我们的不确定性，然而这样做似乎会将方差拉回到非贝叶斯方向。除此之外，听起来没有免费的午餐，而且贝叶斯推理只有在你真正对自己的先验选择有信心的情况下才有优势？]]></description>
      <guid>https://stats.stackexchange.com/questions/655504/how-do-we-stop-bayesian-estimates-from-being-overconfident</guid>
      <pubDate>Wed, 09 Oct 2024 01:10:00 GMT</pubDate>
    </item>
    </channel>
</rss>