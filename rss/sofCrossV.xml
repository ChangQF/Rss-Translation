<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 14 Dec 2024 01:19:41 GMT</lastBuildDate>
    <item>
      <title>在计算评估样本权重时使用训练集还是测试集？</title>
      <link>https://stats.stackexchange.com/questions/658698/use-training-or-testing-set-when-calculating-sample-weights-for-evaluation</link>
      <description><![CDATA[我有一个机器学习模型，它是根据不代表总体类别频率的数据构建的。多数类别实际上是欠采样的，因此它在总体中比数据更常见。在评估时，我想将样本权重传递给 sklearns 指标，如 precision_score。我想弥补我对某些类别欠采样的事实，并了解如果将模型应用于总体和在那里观察到的频率类别，它将如何表现。幸运的是，我有一个估计的总体频率，可以从中计算我的样本权重。
 # 示例频率，但它们的总和为 1
population_frequencies = {
0: 0.8
1: 0.2
}
# 获取数据中的频率
data_frequencies = df_train[&#39;target&#39;].value_counts(normalize=True).to_dict()
# 数据频率显示 0 仍然是多数类别，但未达到总体中观察到的程度。
# 假设为 {0 : 0.6, 1 : 0.4}。

# 计算类别权重
eval_weights = {cls:population_frequencies[cls] / data_frequencies[cls]
for cls in data_frequencies}

# 获取样本权重
sample_weights = [evel_weights[label] for label in df_test[&#39;target&#39;]]

# 计算精度
precision_score(y_pred, y_test, sample_weights=sample_weights)


因此，样本权重的目的是解释我们的数据中 0 类采样不足的事实。当出现假阳性时，即当真实类别为 0 时预测为 1，当模型应用于总体时，这种情况发生的频率可能会更高。 eval_weights 描述了使数据频率反映其人口等价物所需的调整。
我的问题是，我认为所使用的 data_frequencies 应该仅从训练数据的 value_counts 中得出，因为使用测试数据中的任何部分信息都代表数据泄漏。评估指标应反映模型在看不见的数据上的表现，并且测试集信息必须保持完全隔离，直到最终评估。这是正确的吗？我找不到可靠的来源来支持仅使用训练集频率，但直观上对我来说这是有意义的。]]></description>
      <guid>https://stats.stackexchange.com/questions/658698/use-training-or-testing-set-when-calculating-sample-weights-for-evaluation</guid>
      <pubDate>Sat, 14 Dec 2024 00:19:13 GMT</pubDate>
    </item>
    <item>
      <title>解释负二项残差图</title>
      <link>https://stats.stackexchange.com/questions/658692/interpreting-negative-binomial-residual-plot</link>
      <description><![CDATA[我对圣巴巴拉 125 个街区的自行车事故数据进行了负二项回归。该方程如下所示：
MASS::glm.nb(Crashes ~ network coverage + network density + 
交叉口密度 + 复杂度 + offset(log(number of bike trips))

我得到了一个带有曲线的残差图，如下图所示。这是否意味着关系是非线性的？我不知道该如何处理：我应该添加非线性项还是应该尝试其他模型，还是其他？如果有人可以对此有所启发，那就太好了。谢谢。

编辑：我尝试了 DHARMa 的残差图这是我得到的图：
]]></description>
      <guid>https://stats.stackexchange.com/questions/658692/interpreting-negative-binomial-residual-plot</guid>
      <pubDate>Fri, 13 Dec 2024 20:44:28 GMT</pubDate>
    </item>
    <item>
      <title>拟合非线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/658694/fitting-a-nonlinear-mixed-model</link>
      <description><![CDATA[我试图拟合一个非线性混合模型 (nLMM)，以测试某些生物的丰度是否受到导致丰度显著增加的事件后的采样期的影响。
数据显示了一条重要的曲线，这些生物的丰度在事件发生后激增（事件发生在采样期：-1 和 1 之间），但随后下降。
我试图构建一个非线性混合模型，但我发现理解如何构建模型非常具有挑战性（例如，model &lt;- lmer(abundance ~ samples_period + (1 | rep), data = data）。我非常感谢任何帮助来确定丰度是否受到采样期的影响。
data &lt;- data.frame(
abundant = c(79, 72, 58, 61, 88, 123, 119, 96, 67, 78, 143, 75, 105, 46, 58, 
127, 173, 181, 67, 120, 64, 30, 49, 47, 104, 83, 146, 118, 53, 
98, 223, 257, 255, 292, 354, 133, 129, 140, 27, 55, 68, 148, 
122, 132, 77, 121, 108, 109),
rep = c(&quot;T1&quot;, &quot;T2&quot;, &quot;T3&quot;, &quot;T1&quot;, &quot;T2&quot;, &quot;T3&quot;, “T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T3”、“T1”、“T2”、“T3”、“
“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“ “T3”, “T1”, “T2”, “T3”, 
“T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”),
sampling_period_consecutive = c(1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 
6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 10, 10, 
10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 
14, 14, 15, 15, 15, 16, 16, 16),
采样周期 = c(-5, -5, -5, -4, -4, -4, -3, -3, -3, -2, -2, -2, -1, -1, 
-1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 
6, 11, 11, 11, 22, 22, 22, 34, 34, 34, 46, 46, 58, 
58, 58)
)

]]></description>
      <guid>https://stats.stackexchange.com/questions/658694/fitting-a-nonlinear-mixed-model</guid>
      <pubDate>Fri, 13 Dec 2024 19:32:50 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost/XGBRanker 用于乘积概率而不是排名分数</title>
      <link>https://stats.stackexchange.com/questions/658687/xgboost-xgbranker-to-product-probabilities-instead-of-ranking-scores</link>
      <description><![CDATA[我有一个学生考试成绩的数据集，如下所示：
班级 ID 班级规模 学生编号 智商 学习时间 分数
1 3 3 101 10 98
1 3 4 99 19 80
1 3 6 130 3 95
2 4 4 93 5 50
2 4 5 103 9 88
2 4 8 112 12 99
2 4 1 200 10 100 

我想建立一个机器学习模型，尝试使用 IQ 和 Hours_Studied 预测谁将成为班级第一名（即最高 Score），对于任何给定的 Class_ID特征。
由于这是一个排名问题，因此自然的一类学习模型是使用 XGBoost 中的 XGBRanker 或 lightgbm 中的 LGBMRanker。
这是我使用 xgboost 的代码：
from sklearn.model_selection import GroupShuffleSplit
import xgboost as xgb

gss = GroupShuffleSplit(test_size=.40, n_splits=1, random_state = 7).split(df, groups=df[&#39;Class_ID&#39;])

X_train_inds, X_test_inds = next(gss)

train_data = df.iloc[X_train_inds]
X_train = train_data.loc[:, ~train_data.columns.isin([&#39;Class_ID&#39;,&#39;Student_Number&#39;,&#39;Score&#39;])]
y_train = train_data.loc[:, train_data.columns.isin([&#39;Score&#39;])]

groups = train_data.groupby(&#39;Class_ID&#39;).size().to_frame(&#39;Class_size&#39;)[&#39;Class_size&#39;].to_numpy()

test_data = df.iloc[X_test_inds]

X_test = test_data.loc[:, ~test_data.columns.isin([&#39;Student_Number&#39;,&#39;Score&#39;])]
y_test = test_data.loc[:, test_data.columns.isin([&#39;Score&#39;])]

model = xgb.XGBRanker( 
tree_method=&#39;hist&#39;,
device=&#39;cuda&#39;,
booster=&#39;gbtree&#39;,
objective=&#39;rank:pairwise&#39;,
enable_categorical=True,
random_state=42, 
learning_rate=0.1,
colsample_bytree=0.9, 
eta=0.05, 
max_depth=6, 
n_estimators=175, 
subsample=0.75 
)

model.fit(X_train, y_train, group=groups, verbose=True)

def predict(model, df):
return model.predict(df.loc[:, ~df.columns.isin([&#39;Class_ID&#39;,&#39;Student_Number&#39;])])

predictions = (X_test.groupby(&#39;Class_ID&#39;)
.apply(lambda x: predict(model, x)))

代码运行良好，具有合理的预测能力。但是，输出是“相关性得分”列表，而不是概率列表。但似乎 XGBRanker 和 LGBMRanker 都没有属性 predict_proba，该属性返回获得班级最高分的概率。
所以我的问题是，有没有办法将 相关性得分 转换为概率，或者是否有其他自然类别的排名模型可以处理此类问题？
编辑在这个问题中，我只关心最终名列前茅的人（或者可能是前三名），所以排名并不是那么重要（例如，知道学生 4 排名第 11 位，学生 8 排名第 12 位并不那么重要），所以我想一种方法是在 xgboost 中使用分类而不是排名。但我想知道还有其他方法吗。]]></description>
      <guid>https://stats.stackexchange.com/questions/658687/xgboost-xgbranker-to-product-probabilities-instead-of-ranking-scores</guid>
      <pubDate>Fri, 13 Dec 2024 19:11:11 GMT</pubDate>
    </item>
    <item>
      <title>对偏斜响应变量进行建模</title>
      <link>https://stats.stackexchange.com/questions/658686/modelling-a-skewed-response-variable</link>
      <description><![CDATA[我有一个生物标志物比率（淀粉样蛋白 42/40），我在建模方面遇到了问题。这是一个生物标志物与另一个生物标志物的比例，它在诊断痴呆症方面很重要。我将其用作暴露和结果，但显然，当我将变量视为结果时，这种变量的分布更成问题。如果您能就您对此类数据使用了哪些建模方法提出建议，我将不胜感激。这些是 Gamma 对数链接模型的残差图。

]]></description>
      <guid>https://stats.stackexchange.com/questions/658686/modelling-a-skewed-response-variable</guid>
      <pubDate>Fri, 13 Dec 2024 19:02:18 GMT</pubDate>
    </item>
    <item>
      <title>对点对之间的变化与纵向回归进行建模？</title>
      <link>https://stats.stackexchange.com/questions/658685/modelling-the-change-between-pairs-of-points-vs-longitudinal-regression</link>
      <description><![CDATA[
这是基本的纵向模型（混合效应），用于解释个体群体中重复测量之间的相关性：

$$ y_{it} = X_{it}\beta + Z_{it}b_i + \epsilon_{it} $$
其中：

$y_{it}$ 是受试者 $i$ 在时间 $t$ 的结果
$X_{it}$ 表示具有相应参数 $\beta$ 的固定效应设计矩阵
$Z_{it}$ 是具有特定于主题的随机效应的随机效应设计矩阵 $b_i$
$\epsilon_{it}$ 表示误差项
$ b_i \sim N(0, \Sigma_b) $
$ \epsilon_{it} \sim N(0, \sigma^2) $


一阶差分回归对两个观测值之间的差异进行建模，从而可以最大限度地减少时间不变遗漏变量偏差的影响：

$$ \Delta y_{it} = \Delta X_{it}\beta + \Delta \epsilon_{it} $$
其中：

$\Delta y_{it} = y_{it} - y_{i,t-1}$ 表示结果的变化
$\Delta X_{it} = X_{it} - X_{i,t-1}$ 表示预测变量的变化
$\Delta \epsilon_{it} = \epsilon_{it} - \epsilon_{i,t-1}$ 是差分误差项

我只是想知道是否可以将这两个模型结合起来以创建一个混合模型效果一阶差分回归模型？例如：
$$ \Delta y_{it} = \Delta X_{it}\beta + Z_{it}b_i + \Delta \epsilon_{it} $$
$$ b_i \sim N(0, \Sigma_b) $$
$$ \Delta \epsilon_{it} \sim N(0, 2\sigma^2) $$
在统计学中可以这样做吗？结合两全其美 - 允许一般相关结构，同时控制某些类型的遗漏变量偏差？]]></description>
      <guid>https://stats.stackexchange.com/questions/658685/modelling-the-change-between-pairs-of-points-vs-longitudinal-regression</guid>
      <pubDate>Fri, 13 Dec 2024 18:47:14 GMT</pubDate>
    </item>
    <item>
      <title>非参数回归：开创性论文</title>
      <link>https://stats.stackexchange.com/questions/658688/non-parametric-regression-seminal-papers</link>
      <description><![CDATA[这个问题主要是参考文献的问题，无法客观回答，因为文献推荐本质上取决于个人偏好。我希望它仍然可以。
我想问一下，您认为非参数回归中的开创性/重要论文是什么？这个问题的背景是，我正在对非参数回归的某个特定方面进行研究，但对它总体上不太了解。在深入研究某个特定方向之前，我想提出一些建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/658688/non-parametric-regression-seminal-papers</guid>
      <pubDate>Fri, 13 Dec 2024 16:58:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么机器学习课程中的回归主要关注梯度下降，尽管我们有闭式估计量$(X'X)^{-1}X'Y$？[重复]</title>
      <link>https://stats.stackexchange.com/questions/658672/why-do-machine-learning-courses-on-regression-mostly-focus-on-gradient-descient</link>
      <description><![CDATA[在许多在线机器学习课程和视频（例如 Andrew Ng 的 Coursera 课程）中，当谈到回归（例如对特征 $X$ 进行 $Y$ 回归）时，虽然我们有回归系数 $\widehat{\beta}=(X&#39;X)^{-1}X&#39;Y$ 的闭式估计量，并且基于此我们可以得出 $X_i=x$ 的预测为 $x&#39;\widehat{\beta}$。这很简单，不需要数值优化。我的问题是：

鉴于闭式回归估计器（和预测器）的简单性，为什么机器学习课程通常会忽略它，而只关注梯度下降？

以这种方式教授回归有什么优点？

此外，梯度下降在实际性能方面的相对优点是什么？

]]></description>
      <guid>https://stats.stackexchange.com/questions/658672/why-do-machine-learning-courses-on-regression-mostly-focus-on-gradient-descient</guid>
      <pubDate>Fri, 13 Dec 2024 14:08:57 GMT</pubDate>
    </item>
    <item>
      <title>当 $X\sim \operatorname{Beta}(\alpha,\beta)$ 时，$Y=-\log(X)$ 的分布</title>
      <link>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658666/distribution-of-y-logx-when-x-sim-operatornamebeta-alpha-beta</guid>
      <pubDate>Fri, 13 Dec 2024 11:02:03 GMT</pubDate>
    </item>
    <item>
      <title>多参数最大似然估计的渐近正态性证明</title>
      <link>https://stats.stackexchange.com/questions/658664/proof-for-asymptotic-normality-for-mle-with-multiple-parameters</link>
      <description><![CDATA[我有一个问题，关于如何证明多个 MLE 估计量的渐近性质。您在网上找到的大多数资源都提供了仅估计一个参数的情况的证明（例如此处：https://gregorygundersen.com/blog/2019/11/28/asymptotic-normality-mle/）。在这个证明中，将参数方面的均值定理应用于似然的一阶导数，得到类似$(\hat{\theta} - \theta_0) = - \frac{L_n&#39;(\theta_0)}{L_n&#39;&#39;(\tilde{\theta})}$的表达式，然后将渐近结果应用于似然。我将这种证明扩展到多参数情况的问题是均值定理仅适用于标量函数。对于矢量值函数，只有不等式成立，参见例如。 https://en.wikipedia.org/wiki/Mean_value_theorem#Mean_value_theorem_for_vector-valued_functions。
有人能告诉我如何证明多个参数的渐近正态性吗？当然，如果能提供参考，我也非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658664/proof-for-asymptotic-normality-for-mle-with-multiple-parameters</guid>
      <pubDate>Fri, 13 Dec 2024 10:29:14 GMT</pubDate>
    </item>
    <item>
      <title>与回归分析相比，生存分析在预测方面有哪些优势？</title>
      <link>https://stats.stackexchange.com/questions/658656/are-there-any-advantages-of-survival-analysis-over-regression-for-prediction</link>
      <description><![CDATA[我最近遇到了生存分析，它似乎对于模拟事件发生时间和/或处理审查非常有用。文献中激励性的例子很有意义，例如在临床试验中，我们可能会有参与者退出，或者那些可能经历了不良影响但研究提前结束的人。
在我的应用程序中，我使用机器学习对事件发生时间进行建模并将其视为回归问题。然而，审查在这里并不是一个真正的问题，我想知道生存分析是否会比标准回归方法提供任何优势。
为了简化设置，假设我们有来自小部件工厂的数据。小部件发生故障的平均时间为$\bar{Y} = 40$天（最多 100 天），而数据集可以追溯到几年前，并且有几百万个观察值。因此，确实存在一些右删失，但考虑到数据的大小，这相对微不足道。我们还观察到小部件级协变量 $X$，它们会影响故障时间。
目前，我只是将其建模为非参数回归问题，即学习函数 $f : X \to Y$，该函数可最小化 $L^2$ 经验风险/MSE。如果这里的目标只是预测故障时间 $Y$，而不考虑推理，那么生存分析是否会比回归方法有任何优势？]]></description>
      <guid>https://stats.stackexchange.com/questions/658656/are-there-any-advantages-of-survival-analysis-over-regression-for-prediction</guid>
      <pubDate>Fri, 13 Dec 2024 01:17:45 GMT</pubDate>
    </item>
    <item>
      <title>适合我的数据进行因果关系检验的算法/测试</title>
      <link>https://stats.stackexchange.com/questions/658654/algorithms-tests-that-suit-my-data-for-causal-relationship-examination</link>
      <description><![CDATA[我有来自两个环境变量的观测数据，这些数据是在 18 个采样点和 20 个不同日期收集的。我想测试我的数据中两个变量之间是否存在因果关系。请注意，由于我的数据是观测数据，因此无法对其进行操纵，并且没有假定的有向无环图 (DAG)。基于这些条件，我想知道哪种算法或测试最适合我的数据？
我相信 Peter-Clark (PC) 算法可能适合我的数据，因为它可以用于表格数据，但我正在寻找更多算法/测试来检查因果关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/658654/algorithms-tests-that-suit-my-data-for-causal-relationship-examination</guid>
      <pubDate>Fri, 13 Dec 2024 00:05:20 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用函数 HSD.test 作为 R 中双向方差分析的事后检验吗？</title>
      <link>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</link>
      <description><![CDATA[我已经进行了双向方差分析与交互作用（编辑），现在我想进行事后检验。我有 2 个因素，并且都只有 2 个类别。我找到了 agricolae 包中的 HSD.test 函数，我非常喜欢它为您提供了组和有关组间差异的字母。但我不确定这个函数是否可以用于两个因素，或者它是否仅在您有单向方差分析时才有效。有人知道吗？
编辑：我进行了方差分析来检验一个假设，即这两个因素都不会对连续因变量产生影响。我拒绝了这个假设，现在我想知道这 4 个组之间的差异。我应该如何测试它？]]></description>
      <guid>https://stats.stackexchange.com/questions/658651/can-i-use-the-function-hsd-test-as-a-post-hoc-test-for-two-way-anova-in-r</guid>
      <pubDate>Thu, 12 Dec 2024 23:05:32 GMT</pubDate>
    </item>
    <item>
      <title>高斯对数似然值究竟如何计算？</title>
      <link>https://stats.stackexchange.com/questions/658636/how-is-gaussian-log-likelihood-value-calculated-exactly</link>
      <description><![CDATA[我检查了这些 R 函数 glm.fit() gaussian()$aic stats:::logLik.glm() 和 stats:::logLik.lm()，发现 stats:::logLik.glm() 报告的对数似然值是根据 gaussian()$aic 计算的，其定义为
function (y, n, mu, wt, dev) 
{
nobs &lt;- length(y)
nobs * (log(dev/nobs * 2 * pi) + 1) + 2 - sum(log(wt))
}

stats:::logLik.lm() 报告的对数似然值使用以下公式计算。
0.5 * (sum(log(w)) - N * (log(2 * pi) + 1 - log(N) + 
log(sum(w * res^2))))

这两个公式在高斯家族中得出相同的 logLik 和 AIC。我理解 $AIC = -2 \ln{L} + 2df$ 并且可以重现与基本函数 logLik() 相同的结果，但我不知道为什么要以上述方式计算它们。使用基于经典公式的对数密度值总和，如“正态分布 - 最大似然估计”中所示https://www.statlect.com/fundamentals-of-statistics/normal-distribution-maximum-likelihood，我得到了不同的对数似然值，无法识别我的计算和默认输出之间的关系。请参阅以下最小示例。
Data &lt;- data.frame(
y = c(0.2, 0.2, 0.3), 
n = c(10, 20, 30)
)

# GLS 模型
with(Data, sum(y * n)/sum(n)) # 0.25
summary(Model &lt;- glm(y ~ 1, weights = n, data = Data))
&quot;估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.25000 0.03536 7.071 0.0194 *
(高斯族的分散参数取为 0.075)
零偏差：2 个自由度上的 0.15
残差偏差：2 个自由度上的 0.15
AIC：-5.1731&quot;
with(Model, Prior.weights)
&quot; 1 2 3 
10 20 30 &quot;
with(Model, weights)
&quot; 1 2 3 
10 20 30 相同，无迭代重新加权&quot;

# 默认函数
logLik(Model)
&quot;4.58654 (df=2)&quot;
AIC(模型)
&quot;-5.17308 因为 -2 * 4.58654 + 2 * 2 == -5.17308&quot;
with( # 基于 gaussian()$aic 和 glm.fit()
模型，nobs(模型) * (log(deviance/nobs(模型) * 2 * pi) + 1) + 
2 - sum(log(weights)))
&quot;-7.17308
-7.17308 + 2*1 == -5.17308 是报告的 AIC
logLik 源自 AIC 测量&quot;

# OLS 模型
summary(模型 &lt;- lm(y ~ 1, weights = n, data = Data))
logLik(模型)
&quot;4.58654 (df=2) 与上文相同&quot;
AIC(Model)
&quot;-5.17308 与上文相同&quot;
with(Model, 0.5 * (
sum(log(weights)) - nobs(Model) * (
log(2 * pi) + 1 - log(nobs(Model)) + log(sum(weights * residuals^2)))))
&quot;4.58654 为报告的 logLik&quot;

# 手动计算
with(Model, sum(prior.weights * log(
dnorm(y, mean = coef(Model), sd = sigma(Model)))))
&quot;21.5717&quot;
with(Model, sum(weights) * (-1/2 * log(2 * pi)))
&quot;-55.13631&quot;
带有（模型，总和（权重）*（-1/2 * log（sigma（模型）^2）））
“77.70801”
带有（模型，（-1/（2 * sigma（模型）^2））* 总和（权重*（y - coef（模型））^2））
“-1
-55.13631 + 77.70801 - 1 == 21.5717”
with(Model, sum(weights * (y - coef(Model))^2))

答案和更新
常规高斯密度函数是
$f_a = \frac{1}{\sqrt{2\pi\sigma^2}}\exp{-\frac{(y_i − \hat{y}^2_i)}{2\sigma^2}}$
但当有权重时，它就变成
$f_b = \frac{1}{\sqrt{2\pi\sigma^2/w_i}}\exp{-\frac{(y_i − \hat{y}^2_i)}{2\sigma^2/w_i}}$
这表明底层正态分布的方差为 $\sigma^2/w_i$。直观地看，它类似于计算为$SD/\sqrt{n}$的平均标准误差，这表明组大小（即权重）越大，误差方差$s^2/n$越小。
基于gaussian()$aic的stats:::logLik.lm()和stats:::logLik.glm()都使用$N\sigma^2 = \sum{w_i(y_i - \hat{y}^2_i)}$来取消上面的$\sigma$项。但是，我不明白为什么默认不使用$(N-p)\sigma^2 = \sum{w_i(y_i - \hat{y}^2_i)}$。这就是$\sigma$在lm()和glm()中的导出方式，它对应于残差方差的无偏估计，而不是低估残差方差的最大似然估计量。]]></description>
      <guid>https://stats.stackexchange.com/questions/658636/how-is-gaussian-log-likelihood-value-calculated-exactly</guid>
      <pubDate>Thu, 12 Dec 2024 17:03:36 GMT</pubDate>
    </item>
    <item>
      <title>是否存在计算边际效应的标准方法？</title>
      <link>https://stats.stackexchange.com/questions/658594/is-there-a-standard-way-to-calculate-marginal-effects</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658594/is-there-a-standard-way-to-calculate-marginal-effects</guid>
      <pubDate>Wed, 11 Dec 2024 21:11:19 GMT</pubDate>
    </item>
    </channel>
</rss>