<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 18 Aug 2024 06:20:26 GMT</lastBuildDate>
    <item>
      <title>关于易犯的统计建模错误的书籍/资料</title>
      <link>https://stats.stackexchange.com/questions/652963/books-materials-about-easy-to-make-statistical-modeling-mistakes</link>
      <description><![CDATA[是否有书籍或网页汇总了容易犯的统计错误？有时我觉得应用基本模型而不犯错误比学习花哨的模型更重要。
我指的是一些常见的错误，例如
重叠数据的回归
重叠数据的时间序列回归
（省略）去趋势以消除季节性
为什么我们在进行时间序列分析时要从数据中去趋势或消除季节性？
直接使用样本协方差矩阵而不缩小
https://quant.stackexchange.com/questions/11564/why-shrink-the-covariance-matrix]]></description>
      <guid>https://stats.stackexchange.com/questions/652963/books-materials-about-easy-to-make-statistical-modeling-mistakes</guid>
      <pubDate>Sat, 17 Aug 2024 23:31:47 GMT</pubDate>
    </item>
    <item>
      <title>变形金刚操作顺序 [重复]</title>
      <link>https://stats.stackexchange.com/questions/652962/transformers-operations-order</link>
      <description><![CDATA[哪个更好？

A) 添加注意，然后添加 FFN。因此，我认为当今版本的 Transformers 强制 FFN 纠正注意影响并完成 FFN 工作。也许这是有意为之，但我从未在任何地方读到过它。
B) 我认为应该将“Attentionned”X 输入（来自基线）输入 FFN，然后将 FFN 从“Attentionned”基线计算出的微小变化应用于基线。这样，就没有“噪音”来自注意力机制，应用于基线。
但也许我错了，注意力机制不应该被解释为噪音，而应该被解释为有用的信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/652962/transformers-operations-order</guid>
      <pubDate>Sat, 17 Aug 2024 21:34:20 GMT</pubDate>
    </item>
    <item>
      <title>如何总结一组时间（秒）来突出主要的活动模式？</title>
      <link>https://stats.stackexchange.com/questions/652961/how-to-summarize-a-set-of-times-seconds-to-highlight-the-main-activity-pattern</link>
      <description><![CDATA[我必须分析大量关于各个城市公园鸟类鸣叫活动的音频记录；每条记录都通过 BirdNET 进行处理，软件会返回一个数据集，其中包含它识别出的某个物种（例如黑鸟）的每首鸟鸣的开始/结束时间（以秒为单位）。从 0:00 开始，到 9.00 结束。像这样：
|Start.sec | End.sec |
| -------- | -------------- |
|0.1 | 3.2|
| 10.5|11.6|
|28.9| 36.2|
|....|....|
|100756.1|100763.2|
等等，直到记录结束。每个公园/地点一个数据集。
现在，我必须研究鸣叫活动的时间模式与每个公园相关的一些独立变量（交通噪音、人造光……）之间的可能相关性；所以我认为我应该选择并计算一些总结每个站点记录的因变量，这样我就可以将它们放入相关模型中。
但是，有人告诉我“困难的部分是弄清楚要使用哪些变量”。我很困惑，我以为这会很简单？
我打算取每个开始时间（秒）的频率分布，然后计算平均值/中位数/众数/也许四分位数。
不对吗？我还考虑过使用“最活跃的时间”通过找到包含最大元素数量的 3600 秒长的间隔，但我不明白它是否会更准确，也无法想象它会与统计模式有很大差异的情况。
我有点困惑/绝望，因为我对统计学还很陌生……但这是我的论文工作，我觉得它比我第一次做科学分析时预期的要先进。
我正在尽可能多地阅读，但如果能给我一个正确的方向的小小推动，我将不胜感激。
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/652961/how-to-summarize-a-set-of-times-seconds-to-highlight-the-main-activity-pattern</guid>
      <pubDate>Sat, 17 Aug 2024 21:03:17 GMT</pubDate>
    </item>
    <item>
      <title>混合效应模型与广义估计方程对于有限重复测量和非正态分布</title>
      <link>https://stats.stackexchange.com/questions/652960/mixed-effects-model-versus-generalized-estimating-equation-for-limited-repeated</link>
      <description><![CDATA[我的数据集对患者进行了纵向测量，其数值结果偏斜。大约一半的患者测量 2 次或更少，而其余患者测量 3 次或更多。我还看到数据集中治疗组存在影响结果的显著模式（治疗前、接受治疗、最近完成的治疗和 6 个月后停止治疗）。
我目前的方法是利用 GEE 对 4 种不同的治疗状态（治疗前、接受治疗、最近完成的治疗和 6 个月后停止治疗）进行聚类，而不是对患者特定 ID 使用聚类，因为在样本有限的情况下无法形成 ID 的趋势。此外，结果缺乏正态分布违反了线性混合效应所需的假设。
我对模型选择实践有几个基本问​​题：

每个患者需要的重复测量次数是否最少，才能可靠地利用线性混合效应？在样本有限的情况下（有些患者没有重复测量），捕获的患者特定随机效应是否不可靠？
如果您根据治疗暴露状态创建聚类，每个聚类都有 20 多个 GEE 样本，那么是否会将治疗状态作为后续模型的潜在协变量删除？

谢谢，如果有相关条目可供参考，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/652960/mixed-effects-model-versus-generalized-estimating-equation-for-limited-repeated</guid>
      <pubDate>Sat, 17 Aug 2024 19:01:44 GMT</pubDate>
    </item>
    <item>
      <title>高维统计引理 7.24 的证明：非渐近观点</title>
      <link>https://stats.stackexchange.com/questions/652959/proof-of-lemma-7-24-in-high-dimensional-statistics-a-non-asymptotic-viewpoint</link>
      <description><![CDATA[引理是定理 7.16 证明的一部分。
定理 7.16 指出（设 $\rho^2(\Sigma)$ 为 $\Sigma$ 的最大对角线项）
设 $X \in \mathbb{R}^{n \times d}$ 且每行 $x_i \in \mathbb{R}^d$ 独立于 $N(0, \Sigma)$。则有通用常数 $c_1 &lt; 1 &lt;c_2$ 使得
$$\frac{\lVert X \theta\rVert_2^2}{n} \geq c_1 \lVert \sqrt{\Sigma}\theta\rVert_2^2 - c_2 \rho^2(\Sigma) \frac{\log d}{n} \lVert \theta \rVert_1^2$$
对于所有 $\theta \in \mathbb{R}^d$，概率至少为 $1-\frac{e^{-n/32}}{1-e^{-n/32}}$
我们定义 $g(t) = 2 \rho(\Sigma) \sqrt{\frac{\log d}{n}} t$ 并且我们让 $\mathcal{E} = \{ X \in \mathbb{R}^{n \times d} \colon \inf_{\theta \in \Theta} \frac{\lVert X \theta \rVert_2}{\sqrt{n}} + 2 g(\lVert \theta \rVert_1) \leq \frac{1}{4} \}$，其中 $\Theta = \{\theta \in \mathbb{R}^d \colon \lVert \sqrt{\Sigma} \theta \rVert_2 = 1 \}$.
我们希望对 $P(\mathcal{E})$ 设置上限。
对于一对 $(r_l, r_i)$，$0 \leq r_l &lt; r_u$，定义
$K(r_l, r_u) = \{ \theta \in \Theta \colon g(\lVert \theta \rVert_1) \in [r_l, r_u] \}$ 和 $A(r_l, r_u) = \{X \in \mathbb{R}^{n \times d} \colon \inf_{\theta \in K(r_l, r_u)} \frac{\lVert X \theta \rVert_2}{\sqrt{n}} \leq \frac{1}{2}-2r_u \}$。
引理表明
对于任意对 $0 \leq r_l &lt; r_u$，我们有 $P(A(r_l, r_u)) \leq e^{\frac{-n}{32}} e^{\frac{-n}{2} r_u^2}$。此外，对于 $\mu = \frac{1}{4}$，$\mathcal{E} \subseteq A(0, \mu) \cup (\cup_{l = 1}^\infty A(2^{l-1}\mu, 2^l \mu))$
设 $X \in \mathcal{E}$。设 $\theta$ 使得 $\frac{\lVert X \theta \rVert_2}{\sqrt{n}} + 2g(\lVert \theta \rVert_1) \leq \frac{1}{4}$。然后书中说，对于 $l = 1, 2, \ldots, $，如果 $\theta \in K(2^{l-1}\mu, 2^l \mu)$。
$\frac{\lVert X \theta \rVert_2}{\sqrt{n}} \leq \frac{1}{4}-2g(\lVert \theta \rVert_1) \leq \frac{1}{2} - 2(2^{l-1} \mu) = \frac{1}{2}-2^l \mu$。
但对于 $l =2$，$\frac{1}{2} - 2^l \mu = -\frac{1}{2}$，其中 $\frac{\lVert X \theta \rVert_2}{\sqrt{n}}\geq 0$。这对我来说毫无意义。我这里遗漏了什么？
谢谢。



]]></description>
      <guid>https://stats.stackexchange.com/questions/652959/proof-of-lemma-7-24-in-high-dimensional-statistics-a-non-asymptotic-viewpoint</guid>
      <pubDate>Sat, 17 Aug 2024 17:44:57 GMT</pubDate>
    </item>
    <item>
      <title>嵌套研究设计 - 是否有必要限制 betadisper 中的排列？</title>
      <link>https://stats.stackexchange.com/questions/652958/nested-studydesign-necessary-to-restrict-permutations-in-betadisper</link>
      <description><![CDATA[我的研究设计如下：8 个地点，每个地点有 5 种森林类型（地块）（D、DB、B、FB、F）。在每个地块中我都采集了蜘蛛样本并进行了识别。我使用 Morisita-Horn 指数进行了 NMDS。
此外，我想检查社区组成的差异是否具有统计学意义。为此，由于嵌套研究设计，我使用了具有限制排列的 adonis2。使用以下代码，我确保排列只允许在位置内进行，而不允许在位置之间进行。
CTRL.t &lt;- how(within = Within(type = &quot;free&quot;),
plots = Plots(type = &quot;none&quot;),
blocks = matrix_plot$location,
nperm = 999,
observer = TRUE)

然后我使用了 adonis2
adonis2(matrix_plot[,2:49] ~ location + stand,
data = matrix_plot,
method=&quot;horn&quot;,
permutations = CTRL.t)

返回了一个显著的 p 值
&gt; adonis2(matrix_plot[,2:49] ~ location + stand,
+ data = matrix_plot,
+ method=&quot;horn&quot;,
+ permutations = CTRL.t)
简化模型下 adonis 的置换检验
按顺序添加项（从第一个到最后一个）
块：matrix_plot$location
置换：自由
置换数：999

adonis2(formula = matrix_plot[, 2:49] ~ location + stand, data = matrix_plot, permutations = CTRL.t, method = &quot;horn&quot;)
Df SumOfSqs R2 F Pr(&gt;F) 
location 7 2.8907 0.27866 2.0473 0.009 **
stand 4 1.8350 0.17689 2.2743 0.009 **
残差 28 5.6479 0.54445 
总计 39 10.3736 1.00000 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

我现在的问题是：当我想使用 vegan 中的 betadisper () 来确定站立类型的影响是由于分散还是位置影响时，我是否也必须限制排列？
到目前为止，我像这样使用 betadisper
dispersion_stands&lt;- betadisper(horn_dist, matrix_plot$stand, type=&quot;centroid&quot;)

并使用与上面相同的代码限制排列。对于 permutest
permutest(dispersion_stands, permutations = CTRL.t)

这是否必要且正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/652958/nested-studydesign-necessary-to-restrict-permutations-in-betadisper</guid>
      <pubDate>Sat, 17 Aug 2024 16:17:08 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用卡方统计量来根据 60,000 个值的经验数据集评估理论 PDF 吗？</title>
      <link>https://stats.stackexchange.com/questions/652934/can-i-use-the-chi-square-statistic-to-evaluate-theoretical-pdfs-against-an-empir</link>
      <description><![CDATA[我有一个包含 60,000 个数值模拟值的数据集。
我正在测试 4 个理论 PDF（gamma、beta、Weibull 和对数正态）与该数据的拟合度，其中分布的参数是根据数据估算的。
我可以使用卡方统计量来比较这些分布的拟合优度吗？或者卡方统计量不适合此目的，尤其是考虑到我的数据集很大？]]></description>
      <guid>https://stats.stackexchange.com/questions/652934/can-i-use-the-chi-square-statistic-to-evaluate-theoretical-pdfs-against-an-empir</guid>
      <pubDate>Fri, 16 Aug 2024 17:15:30 GMT</pubDate>
    </item>
    <item>
      <title>了解何时使用负二项式 GLMM</title>
      <link>https://stats.stackexchange.com/questions/652909/understanding-when-to-use-a-negative-binomial-glmm</link>
      <description><![CDATA[我有 16 只鸟（191978、191984、191977、191980、191986、201446、191983、201447、211598、211590、211595、191981、211591、201441、201445、211592）。其中有 6 只雄性和 10 只雌性。数据集名为 Gbirds_sex。我有它们重访释放地点的次数（visitIdx）。我还有（timeInside）列来显示在释放地点内的停留时间。我想在 R 中进行统计分析，看看性别是否会影响重访次数 (visitIdx) 和停留时间 (timeInside)。我不知道哪种测试效果最好，以及它的 R 代码是什么。LLM，GLM。我应该使用随机截距吗？
我试过这些：
#1
#visitIdx 是一个计数变量，因此
# 用泊松分布拟合 GLMM
library(lme4)
model_glmm &lt;- glmer(visitIdx ~ sex + (1 | id), family =
poisson(), data = Gbirds_sex)
summary(model_glmm)
#2
#residenceTime 是连续的 - 使用高斯族。
# 使用高斯响应分布和随机 
# 截距拟合每个个体的 GLMM
model_timeInside_Gaussian &lt;- lm(timeInside ~ sex, data = 
Gbirds_sex)
summary(model_timeInside_Gaussian)

但是，分散度很高 (2.8)
我现在应该使用：
library(glmmTMB)
model_glmm_nb &lt;- glmmTMB(visitIdx ~ sex + (1 | id), 
family = nbinom2(), data = Gbirds_sex)
summary(model_glmm_nb)

关于 timeInside：
首先，我运行了一个 GLM：
拟合使用高斯族对“timeInside”进行 GLM，以“性别”作为预测因子
glm_timeInside &lt;- glm(timeInside ~ sex, data = Gbirds_sex)
summary(glm_timeInside)

其次，我检查了过度分散：
residual_deviance &lt;- deviance(glm_timeInside)
df_residual &lt;- df.residual(glm_timeInside)

计算过度分散统计量
overdispersion_statistic &lt;- residual_deviance / df_residual
print(overdispersion_statistic)

第三，由于分散度较高（7），我运行了 GLMM， timeInside 作为响应变量，sex 作为固定效应，id 作为随机效应
glmm_timeInside &lt;- lmer(timeInside ~ sex + (1|id), data = Gbirds_sex)
summary(glmm_timeInside)

这不适合

边界（奇异）拟合：请参阅 help(&#39;isSingular&#39;)

下一步是准高斯 GLM 吗？它不提供 AIC 值（“NA”）可以吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652909/understanding-when-to-use-a-negative-binomial-glmm</guid>
      <pubDate>Fri, 16 Aug 2024 03:05:07 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用已知范围但未知平均值生成正态分布的变量</title>
      <link>https://stats.stackexchange.com/questions/652807/generating-a-normally-distributed-variable-using-a-known-range-but-an-unknown-m</link>
      <description><![CDATA[我想生成一个具有已知范围（例如 $10.4\text{–}16.6$）但不知道平均值的 100 个数据点的正态分布变量。要使用 rnorm，我需要平均值和标准差。如果我假设它是精确的中点（平均值${} = (10.4 + 16.6) \cdot 0.5 = 13.5).$，我可以估计平均值，并对 sd 进行一些类似的估计（sd${} = (13.5 - 10.4) /2 = 1.55).$，然后我可以使用 rnorm 函数
rnorm (n=100, 平均值 = 13.5, sd = 1.55)

但结果变量的范围超出了我的初始范围 $10.4\text{–}16.6.$，我想看看是否有更好的方法来生成这个变量并强制以保持我预期的范围。]]></description>
      <guid>https://stats.stackexchange.com/questions/652807/generating-a-normally-distributed-variable-using-a-known-range-but-an-unknown-m</guid>
      <pubDate>Wed, 14 Aug 2024 18:22:10 GMT</pubDate>
    </item>
    <item>
      <title>如果 $X$ 和 $Y$ 是独立随机向量，则 $X_{i}|X_{i-}$ 和 $Y_{i}|Y_{i-}$ 是否独立？</title>
      <link>https://stats.stackexchange.com/questions/652257/if-x-and-y-are-independent-random-vectors-is-x-ix-i-and-y-iy-i</link>
      <description><![CDATA[假设 $X$ 和 $Y$ 是独立的随机向量，$X_i|X_{i-}$ 是否独立于 $Y_{i}|Y_{i-}$？其中 $i-$ 包含随机向量中不存在于 $i$ 中的元素。基本上我想知道的是$X_i|X_{i-}$是否可以表示为$X$的函数因为独立随机向量的函数是独立的。
示例：
让我们考虑一个三维随机向量$[X_1, X_2, X_3]$，$X_i|X_{i-}$可以是以下任意一个随机向量 - $[X_1 | X_2=x_2, X_3=x_3]$, $[X_1, X_2 | X_3=x_3]$, $[X_1, X_3 | X_2=x_2]$ ...等等...
让我们具体看一下第一个，它是一个一维随机向量 $[X_1 | X_2=x_2, X_3=x_3]$，我们将其称为 $Z$
$$
Z = f(X_1,X_2=x_2,X_3=x_3)
$$
以上内容正确吗？如果可以的话我将非常感激任何相关证据。]]></description>
      <guid>https://stats.stackexchange.com/questions/652257/if-x-and-y-are-independent-random-vectors-is-x-ix-i-and-y-iy-i</guid>
      <pubDate>Sat, 03 Aug 2024 19:50:21 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归参数的经验贝叶斯收缩</title>
      <link>https://stats.stackexchange.com/questions/652160/empirical-bayes-shrinkage-of-logistic-regression-parameters</link>
      <description><![CDATA[我一直在使用 DESeq2 和 limma 来识别数据集中的差异表达基因。我想使用逻辑回归模型对二元变量（例如突变）进行类似操作。
在 DESeq2 和 limma 中，每个基因都由单独的模型拟合。他们使用经验贝叶斯收缩来调节线性模型的残差方差，借用基因（模型）之间的信息，并使用小样本量改进参数估计。
这种方法可以应用于逻辑回归吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652160/empirical-bayes-shrinkage-of-logistic-regression-parameters</guid>
      <pubDate>Thu, 01 Aug 2024 16:23:36 GMT</pubDate>
    </item>
    <item>
      <title>将当前年份与五年平均值进行比较，当前年份是否应包括在平均值中？</title>
      <link>https://stats.stackexchange.com/questions/652154/comparing-current-year-to-five-year-average-should-current-year-be-included-in</link>
      <description><![CDATA[我经常计算我的数据的五年平均值，并将其与当前年份进行比较。我意识到，对于 2023 年，我会找到 2019-2023 年的平均值，并将其与 2023 年的值进行比较。这是正确的吗？或者平均值应该是过去 5 年（2018-2022 年）的平均值，这样 2023 年就不会影响该值？
举个例子，如果过去 6 年的数据是
(2018,1)、(2019,2)、(2020,3)、(2021,4)、(2022,5)、(2023,6)
我目前的方法是五年平均值为 4，2023 年有 50% 的差异。
2018-2022 年的平均值为 3，2023 年有 100% 的差异。
哪种方法更正确？这个决定还取决于其他因素吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652154/comparing-current-year-to-five-year-average-should-current-year-be-included-in</guid>
      <pubDate>Thu, 01 Aug 2024 13:20:12 GMT</pubDate>
    </item>
    <item>
      <title>如何选择度量学习的输出向量大小？</title>
      <link>https://stats.stackexchange.com/questions/622655/how-to-choose-the-output-vector-size-for-metric-learning</link>
      <description><![CDATA[在度量学习中，例如，MNIST 图像，CNN 将 28 x 28 图像投影到 $d$ 维向量中，该向量将传递给度量学习损失函数：如果这些向量来自同一个数字，则最小化它们之间的欧几里得距离或余弦距离，如果它们来自不同的数字，则最大化距离。
现在我正在做机器学习（度量学习），我面临的问题是：如何最好地选择输出向量的大小，$d$？
因为，如果我选择大尺寸：我必须有更多的学习周期才能获得足够的结果
而且我认为：如果我选择小尺寸，那么有可能无法创建最终向量以明确区分不同组中的对象。
我应该怎么做？
我怎么知道输出向量大小不够？
这样的特征（维度）只能选择，或者也许存在某种估计公式，或者至少存在取决于图像大小的参数数量的上限？]]></description>
      <guid>https://stats.stackexchange.com/questions/622655/how-to-choose-the-output-vector-size-for-metric-learning</guid>
      <pubDate>Sat, 29 Jul 2023 18:55:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 代码计算信用评分的基尼系数、准确度和 AUROC</title>
      <link>https://stats.stackexchange.com/questions/616618/calculation-of-the-gini-coefficient-accuracy-and-auroc-for-credit-scoring-using</link>
      <description><![CDATA[我有以下数据，我想计算 GINI 和 Accuracy 以进行模型验证。但我尝试使用 Python 代码计算 GINI 和 Accuracy，但似乎不正确。我想通过计算借款人累计数量、商品累计数量和坏账累计数量来计算 AUC、GINI 和 Accuracy。
因为我想在 Microsoft Excel 和 Python 中实现这一点，因此尝试计算但没有成功
以下是代码：
# code 1
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

data = {
&quot;Decile&quot;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
&quot;No.借款人”：[100, 300, 200, 300, 600, 200, 700, 800, 900, 1000],
“好借款人”：[80, 160, 140, 220, 500, 1000, 560, 640, 1500, 800],
“坏借款人”：[20, 140, 60, 80, 1000 ,1000 ,1400 ,1600 ,7500 ,200]
}
good_borrowers = data[&#39;好借款人&#39;]
bad_borrowers = data[&#39;坏借款人&#39;]

total_borrowers = [good_borrowers[i] + bad_borrowers[i] for i in range(len(good_borrowers))]
cumulative_good_borrowers = [sum(good_borrowers[:i+1]) for i in range(len(good_borrowers))]
cumulative_bad_borrowers = [sum(bad_borrowers[:i+1]) for i in range(len(bad_borrowers))]

cumulative_good_borrower_ratio = [cumulative_good_borrowers[i]/total_borrowers[i] for i in range(len(total_borrowers))]
cumulative_bad_borrower_ratio = [cumulative_bad_borrowers[i]/total_borrowers[i] for i in range(len(total_borrowers))]

fpr,tpr,_ = roc_curve(data[&#39;Decile&#39;],累积良好借款人比率)
roc_auc = auc(fpr,tpr)
gini = (2 * roc_auc) -1

print(&quot;AUC: &quot;, roc_auc)
print(&quot;GINI: &quot;, gini)

#code 2: 
import numpy as np
import matplotlib.pyplot as plt

# 创建一个数据框来存储每个十分位数中的借款人、好借款人和坏借款人的数量。
data = {
&quot;十分位数&quot;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
&quot;No.借款人”：[100, 300, 200, 300, 600, 200, 700, 800, 900, 1000],
“好借款人”：[80, 160, 140, 220, 500, 100, 560, 640, 150, 800],
“坏借款人”：[20, 140, 60, 80, 100, 100, 140, 160, 750, 200]
}

# 计算 ROC 曲线。
fpr = []
tpr = []
for decile in range(0, len(data[&quot;Decile&quot;])):
good_borrowers_in_decile = data[&quot;Good Borrowers&quot;][decile]
bad_borrowers_in_decile = data[&quot;Bad Borrowers&quot;][decile]
total_borrowers_in_decile = good_borrowers_in_decile + bad_borrowers_in_decile
fpr.append(bad_borrowers_in_decile / total_borrowers_in_decile)
tpr.append(good_borrowers_in_decile / total_borrowers_in_decile)

# 绘制 ROC 曲线。
plt.plot(fpr, tpr)
plt.xlabel(&quot;假阳性率&quot;)
plt.ylabel(&quot;真阳性率&quot;)
plt.title(&quot;ROC 曲线&quot;)
plt.show()

# 计算 AUC。
auc = np.trapz(tpr,fpr)
print(&quot;AUC:&quot;, auc)

# 计算准确率。
accuracy = (sum(data[&quot;好借款人&quot;]) + sum(data[&quot;坏借款人&quot;])) / sum(data[&quot;借款人数量&quot;])
print(&quot;准确率:&quot;, accuracy)

# 计算基尼系数。
#gini = 1 - np.sum((np.array(data[&quot;No. Borrowers&quot;]) * (np.array(data[&quot;No. Borrowers&quot;]) -1))) / (np.prod(np.array(data[&quot;No. Borrowers&quot;])) **2)
def gini(data):
borrowers = np.array(data[&quot;No. Borrowers&quot;])
if 0 in borrowers:
return None
gini = 1 - np.sum((borrowers * (borrowers -1))) / (np.prod(borrowers) **2)
return gini
gini(data)
print(&quot;Gini 系数:&quot;, gini)


数据:





十分位
借款人数量
优质借款人
不良借款人




1
100
80
20


2
300
160
140


3 
200
140
60


4
300
220
80


5
600
500
100


6
200
100
100


7
700
560
140


8
800
640
160


9
900
150
750


10
1000
800
200




希望这有帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/616618/calculation-of-the-gini-coefficient-accuracy-and-auroc-for-credit-scoring-using</guid>
      <pubDate>Mon, 22 May 2023 21:09:43 GMT</pubDate>
    </item>
    <item>
      <title>如何使用逆高斯解释广义线性模型的 beta 系数</title>
      <link>https://stats.stackexchange.com/questions/611157/how-to-interpret-beta-coefficients-of-a-generalized-linear-model-using-inverse-g</link>
      <description><![CDATA[我制作了一个具有逆高斯链接的广义线性模型。
glm(lone_total ~ class + age + basic_needs_covered_id,
data = mod_data_lone,
family = gaussian(link = &quot;inverse&quot;)
)

我选择这个家族和链接是因为诊断图对于 inverse.gaussian(link=&quot;1/mu^2&quot;) 或 Gamma(link=&quot;log&quot;) 来说很糟糕（参见下图中结果变量的分布）
具有以下系数的结果：
 系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 0.784873 0.066836 11.743 &lt; 2e-16 ***
class2 -0.070565 0.067936 -1.039 0.300 
class3 0.171242 0.203703 0.841 0.401 
age 0.003912 0.003444 1.136 0.257 
basic_needs_covered_id -0.110093 0.026307 -4.185 4.1e-05 ***

如何解释估算值？我尝试将它们解释为来自伽马或泊松模型的 beta 值，或者对它们运行 log() 和 exp()，但对我来说没有任何意义。
数据描述
&gt; str(mod_data_lone)
&#39;data.frame&#39;: 229 obs. 5 个变量：
$ lone_total : num 0.01 3 3 1 1 1 0.01 3 0.01 0.01 ...
$ class : 具有 3 个级别“1”、“2”、“3”的因子：3 2 1 3 1 1 1 1 1 2 ...
$ age : num -14.44 -8.27 7.38 NA 13.99 ...
$ basic_needs_covered_id: num 0 4 0 2 1 2 0 1 0 1 ...
$ education_id : num 6 8 6 6 6 2 6 6 6 6 ...

下图显示了条形图和密度分布以及按观测类别划分的均值：

-
我得到的另一个表格如下，其中显示了不同类型的 B（对我来说这些都没有什么意义……）

-
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/611157/how-to-interpret-beta-coefficients-of-a-generalized-linear-model-using-inverse-g</guid>
      <pubDate>Wed, 29 Mar 2023 17:07:20 GMT</pubDate>
    </item>
    </channel>
</rss>