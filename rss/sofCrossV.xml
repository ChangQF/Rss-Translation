<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 11 Feb 2025 21:15:44 GMT</lastBuildDate>
    <item>
      <title>模拟退火逃离最佳解决方案并导致更糟糕的结果</title>
      <link>https://stats.stackexchange.com/questions/661245/simulated-annealing-escaping-from-best-solution-and-ending-worse</link>
      <description><![CDATA[我的问题是关于模拟退火，以及 SA 对适应度函数得分的期望。
我将跳过介绍我试图解决的更大问题，因为我的问题只关注对 SA 的正确理解。
我的老师告诉我，在寻找新候选人时，适应度函数得分不能先“大幅”提高，然后（超过初始得分）“大幅”下降。
如下所示：

请忽略荷兰语标题。
我确信适应度函数是正确的，并且我正在正确应用 SA。
但是，我的老师希望看到具有更多负指数特征的图表。
我的问题是：这个图表是否表明我做错了什么，或者您无法得出这个结论？
再次运行算法时，我得到了另一个输出：

我的问题与代码无关，但如果您有兴趣，可以查看我的项目：https://github.com/jorawesome/SA_mtsp]]></description>
      <guid>https://stats.stackexchange.com/questions/661245/simulated-annealing-escaping-from-best-solution-and-ending-worse</guid>
      <pubDate>Tue, 11 Feb 2025 20:20:46 GMT</pubDate>
    </item>
    <item>
      <title>如何估计方程的参数（负指数），而无需明确的 x 和 y 数据点</title>
      <link>https://stats.stackexchange.com/questions/661242/how-to-estimate-the-parameter-of-an-equation-negative-exponent-without-having</link>
      <description><![CDATA[我有 x1 vs. x2 和 y1 vs. y2 的比率（或 %changes），等等。初始 x 值很重要，因此它是一个非线性函数（负指数），形式为：y = c(1-e^(px))
也就是说，我需要估计最小化残差的 &quot;p&quot; 值。&quot;c&quot;是已知的。
例如，
当 x1 (0.02) 变为 x2 (0.03) 时，我知道 y 的百分比变化是 40%
当 x3 (0.04) 变为 x4 (0.08) 时，我知道 y 的百分比变化是 100%...
等等，我在两个 x 值之间有一系列 y 的百分比变化。
除了自己蛮力猜测参数值之外，还有其他想法吗？非常感谢，我真的需要帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/661242/how-to-estimate-the-parameter-of-an-equation-negative-exponent-without-having</guid>
      <pubDate>Tue, 11 Feb 2025 19:33:22 GMT</pubDate>
    </item>
    <item>
      <title>关于使用稳健标准误差与聚类标准误差的说明</title>
      <link>https://stats.stackexchange.com/questions/661241/clarification-on-using-robust-vs-clustered-standard-errors</link>
      <description><![CDATA[我刚刚开始学习稳健标准误差和聚类标准误差。虽然我理解它们之间的区别，但我很难确定何时使用其中一种或同时使用两种。如果有聚类，我知道我应该使用聚类标准误差，但仅此一项就足够了吗？包括稳健标准误差会不会是多余的？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661241/clarification-on-using-robust-vs-clustered-standard-errors</guid>
      <pubDate>Tue, 11 Feb 2025 19:30:13 GMT</pubDate>
    </item>
    <item>
      <title>当 $\mathbf{X}'\mathbf{X}$ 不是“单位相关矩阵”时，最小二乘法性能较差，Hoerl 和 Kennard (1970)</title>
      <link>https://stats.stackexchange.com/questions/661240/poor-performance-of-least-squares-when-mathbfx-mathbfx-is-not-a-unit-co</link>
      <description><![CDATA[在阅读 Hoerl 和 Kennard (1970) 所著的 岭回归：非正交问题的有偏估计时，作者反复使用以下观察来激发对岭回归估计量的行为和属性的分析研究，

对于未知的 $\boldsymbol{\beta}$，通常的估计程序是高斯-马尔可夫——$\mathbf{Y} = \{y_v\}$ 的线性函数，这些函数无偏且方差最小。如果 $\mathbf{X}&#39;\mathbf{X}$ 为相关矩阵形式，且接近单位矩阵，则此估计程序是有效的。但是，如果 $\mathbf{X}&#39;\mathbf{X}$ 几乎不是单位矩阵，最小二乘估计值就会对许多“错误”敏感。当规定 $\mathbf{X} \boldsymbol{\beta}$ 为真实模型时，这些错误的结果至关重要。

在我读过的几乎所有关于岭回归估计量的现代介绍中，例如 Hastie 等人的文章。 （2010），它们都没有用“相关矩阵”的语言来表达。
相反，现代的表示倾向于通过对$(\mathbf{X}&#39;\mathbf{X})^{-1}$进行特征分解或奇异值分析，来激励岭回归估计量以偏差换取最小二乘估计量$\sigma^2 (\mathbf{X}&#39;\mathbf{X})^{-1}$的方差降低。
1. 有人能用论据澄清一下这里到底是什么意思吗？
2.这个单位相关矩阵参数是否与我们对误差$\mathbb{E}[\mathbf{e}\mathbf{e}&#39;] = \sigma^2I$的以下假设有关，即$\mathbf{Y}$上的各向同性协方差矩阵$\sigma^2I$？$^{[1]}$

$^{[1]}$从最小二乘估计量对我们的建模假设（即误差具有各向同性协方差）的错误指定不具有稳健性的意义上？*]]></description>
      <guid>https://stats.stackexchange.com/questions/661240/poor-performance-of-least-squares-when-mathbfx-mathbfx-is-not-a-unit-co</guid>
      <pubDate>Tue, 11 Feb 2025 18:54:49 GMT</pubDate>
    </item>
    <item>
      <title>哪种统计检验最合适？</title>
      <link>https://stats.stackexchange.com/questions/661239/which-statistical-test-is-most-appropriate</link>
      <description><![CDATA[我的假设实验是对照药物试验。每个人都有诊断结果，并被分为 3 组（对照组 - 继续他们通常的应对策略，治疗组 - 药物和安慰剂 - 服用糖丸）。我有他们的年龄、性别、体重指数、身高、体重、血压以及健康焦虑评分的数据。他们在两个不同的时间点进行了测量 - 时间点 1 是基线，时间点 2 是 6 个月。在这里最合适的统计测试是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/661239/which-statistical-test-is-most-appropriate</guid>
      <pubDate>Tue, 11 Feb 2025 18:50:07 GMT</pubDate>
    </item>
    <item>
      <title>这个账户在 1 个月后被耗尽并且余额为零的概率是多少？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/661238/what-is-the-probability-that-this-account-will-be-depleted-and-its-balance-will</link>
      <description><![CDATA[我想设计一个交易机器人
需要这样编程，使它每笔交易承担 5% 的风险
胜负比相等
每笔交易的盈利和亏损金额相等
我想知道如果这个账户在一年内每月进行 20 笔交易，它归零并失去余额的可能性有多大？每月和每三个月账户亏损的百分比是多少]]></description>
      <guid>https://stats.stackexchange.com/questions/661238/what-is-the-probability-that-this-account-will-be-depleted-and-its-balance-will</guid>
      <pubDate>Tue, 11 Feb 2025 18:17:03 GMT</pubDate>
    </item>
    <item>
      <title>部分斯皮尔曼相关性有三种不同的计算方法，每种方法都会得到不同的估计值 - 该使用哪一种？</title>
      <link>https://stats.stackexchange.com/questions/661236/partial-spearman-correlations-done-three-different-ways-each-get-different-estim</link>
      <description><![CDATA[据我所知，有三种不同的方法可以进行 Spearman 偏相关。
方法 1 = 来自这里 (https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/partsp)：“从这个等价性可以看出，Spearman 偏相关等于两个变量的秩对偏变量的秩的线性回归残差之间的 Pearson 相关”
方法 2 = 或者，使用原始数据，对 x 和 z（协变量）进行回归，对 y 和 z 进行回归，从这些模型中获得残差，然后对这些模型运行 Spearman 相关，应该会得到相似的值。
方法3 = 最后，R 中的 ppcor 包使用协方差矩阵（https://pmc.ncbi.nlm.nih.gov/articles/PMC4681537/）。
使用 Pearson（不是 spearman），方法 2 和方法 3 的结果相同，如下所示，https://rpubs.com/KwonPublishing/249631。
但是，下面显示方法 1、2 和 3 都获得了 spearman 偏相关系数的不同相关性估计 相关性。 那么哪一个是最正确的呢？
x_data &lt;- as.data.frame(matrix(runif(50, min=-3, max=3), ncol=5, nrow=10))
y_data &lt;- as.data.frame(matrix(runif(50, min=-3, max=3), ncol=5, nrow=10)) 

z_data &lt;- data.frame(age = c(56, 65, 78, 23, 41, 45, 67, 43, 29,31),
sex=c(2,1,2,1,1,2,2,2,2,2),
days=c(0,0,0,1,1,2,2,3,3,6))

##方法 1 对排序后的 x、y 和 z 数据进行回归，获得残差，然后计算它们之间的皮尔逊 

rx1 &lt;- rank(x_data$V1)
ry1 &lt;- rank(y_data$V1)
rz &lt;- data.frame(apply(z_data, 2, function(x) rank(x)))

residuals_x &lt;- residuals(lm(rx1 ~ rz$age + rz$sex + rz$days))
residuals_y &lt;- residuals(lm(ry1 ~ rz$age + rz$sex + rz$days))

spearman_partial_1 &lt;- cor(residuals_x, residuals_y, method = &quot;pearson&quot;)
spearman_partial_1 ##-0.708

##方法 2 分别对 x 和 y 进行 z 回归，提取残差，然后运行斯皮尔曼相关

residuals_x1 &lt;- residuals(lm(x_data$V1 ~ z_data$age + z_data$sex + z_data$days))
residuals_y1 &lt;- residuals(lm(y_data$V1 ~ z_data$age + z_data$sex + z_data$days))

spearman_partial_2 &lt;- cor(residuals_x1, residuals_y1, method=&quot;spearman&quot;)
spearman_partial_2 #-0.4909

##方法 3 使用 ppcor 包，该包着眼于使用协方差矩阵来加速上述 

residuals_3 &lt;- pcor.test(x_data$V1, y_data$V1, z_data[, c(&quot;age&quot;, &quot;sex&quot;, &quot;days&quot;)])
residuals_3$estimate #-0.6253
]]></description>
      <guid>https://stats.stackexchange.com/questions/661236/partial-spearman-correlations-done-three-different-ways-each-get-different-estim</guid>
      <pubDate>Tue, 11 Feb 2025 16:22:55 GMT</pubDate>
    </item>
    <item>
      <title>LOOCV 设置中的嵌套线性模型比较和回归参数测试？</title>
      <link>https://stats.stackexchange.com/questions/661235/nested-linear-model-comparison-and-regression-parameter-testing-in-loocv-setting</link>
      <description><![CDATA[假设以下情况：需要对多个样本进行荟萃分析，其中一个样本相当小。
我们有两个嵌套模型，一个包含所有需要处理的技术和其他混杂因素（似乎没有争议），第二个包含上述混杂因素以及实际感兴趣的预测因素。
预测因素的数量接近最小样本的样本量，其他样本几乎大一个数量级。此外，我们还有一些（仍然可以忍受？）共线性问题。
整个过程是在高吞吐量设置下完成的，因此我们面临着严峻的多重测试挑战（约 100 万个结果测量）。这通常是通过计算 FWER 或 FDR 来解决的。
但是：可能由于过度拟合，即使经过多次测试校正，我们在小样本中仍然有很多显著的发现，我不相信它们（几乎可以肯定这些是假阳性，因为它们不会出现在较大的样本中）。在我建议对一个较大的样本进行一些敏感性分析（将其剥离到相同的不足样本量）之后，那里的情况是一样的：突然出现许多不可信的微小 p 值，经受住了多次测试校正和最终元分析的偏差结果。使用 rlm（来自 R 中的 MASS 包；遵循分析计划）并没有改善已经怀疑的情况。
当被要求帮助时，我的第一个想法是求助于留一交叉验证（loocv），并根据从 loocv 获得的保留样本预测误差而不是常规线性模型残差对两个模型进行 F 检验比较。乍一看，这似乎有效，并且据称显示了更为现实的画面。
我现在面临的挑战是：使用 loocv 方法，如何获得单个感兴趣的预测因子的合理参数估计（回归 beta）以及此估计的适当标准误差，可用于元分析？]]></description>
      <guid>https://stats.stackexchange.com/questions/661235/nested-linear-model-comparison-and-regression-parameter-testing-in-loocv-setting</guid>
      <pubDate>Tue, 11 Feb 2025 16:14:21 GMT</pubDate>
    </item>
    <item>
      <title>因果关系 - 单组前测后测（准实验）设计</title>
      <link>https://stats.stackexchange.com/questions/661233/causality-one-group-pretest-posttest-quasi-experimental-design</link>
      <description><![CDATA[我进行了一项（准）实验研究，采用单组前测后测设计，以检验旨在培训参与者在求职面试中使用特定非语言线索的干预措施是否能有效提高面试表现。
配对 t 检验显示，干预后的面试表现得分明显高于干预前。但是，我想确定这种改善是否真正归因于干预的有效性，而不仅仅是实践效果。
为了评估这一点，我在干预前后测量了面试表现和非语言线索的使用情况（均作为连续变量进行测量）。如果参与者在干预后比干预前更多地使用有针对性的非语言线索，则该干预将被视为有效。
大多数关于实验设计中的中介作用的研究都包括对照组，但我的设计没有对照组。鉴于此，我正在寻找适当的统计方法来测试非语言线索的增加使用是否有助于提高面试表现。如有任何关于如何对此进行建模的建议，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/661233/causality-one-group-pretest-posttest-quasi-experimental-design</guid>
      <pubDate>Tue, 11 Feb 2025 15:30:11 GMT</pubDate>
    </item>
    <item>
      <title>如何在 scikit learn 中模拟 R 的 selectNcomp？</title>
      <link>https://stats.stackexchange.com/questions/661232/how-might-i-emulate-rs-selectncomp-in-scikit-learn</link>
      <description><![CDATA[R 的 mvr 包有一个实用函数 selectNcomp，可通过实施启发式标准误差规则自动选择交叉验证 PLS 模型中的保留潜变量：
“方法“onesigma”仅返回最佳 CV 在绝对最佳值的一个标准误差范围内的第一个模型（Hastie、Tibshirani 和 Friedman，2009 年）。请注意，这里我们仅使用交叉验证残差的标准偏差，与用于计算误差测量本身的程序一致”
如何在 Python 中模仿此功能？从我的 SKlearn 网格搜索中，我可以获得验证所有折叠中每个选定潜变量的平均 RMSE，以及所有折叠的相关标准偏差，但我不确定如何/是否可以根据此信息计算标准误差，或者它是否确实与仅使用标准偏差作为限制有显著不同。
谢谢。
Hastie, T.、Friedman, J. 和 Tibshirani, R.《统计学习要素：数据挖掘、推断和预测》，Springer（2013 年），第 10 次印刷，附有更正，第 7.10 段。]]></description>
      <guid>https://stats.stackexchange.com/questions/661232/how-might-i-emulate-rs-selectncomp-in-scikit-learn</guid>
      <pubDate>Tue, 11 Feb 2025 15:21:13 GMT</pubDate>
    </item>
    <item>
      <title>基于偏差特征的预测建模</title>
      <link>https://stats.stackexchange.com/questions/661231/predictive-modeling-on-biased-features</link>
      <description><![CDATA[我想用于建模的一些特征具有如下分布：

我的数据中经常出现的特征值很高。我可以轻松识别导致这种极化的数据点子集。这里没有现象，这些只是与大城市相关的样本。问题是我应该如何解决这个问题。我应该为大城市建立一个单独的模型吗？或者你会建议最小化极性的转换吗？我知道预测建模没有通用的方法，但也许你对这样的数据集有一些经验和良好的做法。你对如何将这些特征纳入模型有什么建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/661231/predictive-modeling-on-biased-features</guid>
      <pubDate>Tue, 11 Feb 2025 15:19:07 GMT</pubDate>
    </item>
    <item>
      <title>匹配和 AIPW/倾向评分方法</title>
      <link>https://stats.stackexchange.com/questions/661229/matching-and-aipw-propensity-score-methods</link>
      <description><![CDATA[在运行基于倾向得分 (PS) 的匹配算法后，人们是否经常运行增强逆概率加权或双重稳健方法来估计治疗效果？就此而言，人们是否经常在通用匹配算法之后使用基于倾向得分的估计程序？
我的直觉告诉我，当使用基于 PS 的匹配算法时，人们会通过重新估计匹配样本的倾向得分而引起偏差，所以这似乎不是一个好主意。
Ho 等人的一篇论文 (https://gking.harvard.edu/files/matchp.pdf) 认为匹配会降低模型依赖性，因此在匹配后使用基于 PS 的估计方法可能不是常见的做法。很高兴能听取其他人对此的想法：
先进行匹配，然后进行 AIPW 是一种好的做法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661229/matching-and-aipw-propensity-score-methods</guid>
      <pubDate>Tue, 11 Feb 2025 15:04:38 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用卡方还是 Mcnemar</title>
      <link>https://stats.stackexchange.com/questions/661223/should-i-use-chi-squared-or-mcnemar</link>
      <description><![CDATA[我是一名博士生，不可否认，统计学是我的弱项。我正在制定一份提案，必须说明我将对假设数据进行什么测试。我计划看看注意力控制组和干预组之间是否存在差异。参与者将被随机分配到各个组中。每个参与者将进行基线评估。注意力控制组和干预组将参加关于该主题的相同教育。干预组将参加模拟以练习该技能。然后，每个参与者将进行事后评估。我想看看模拟组在干预后是否有更准确的评估结果。评估要么正确，要么不正确。我想比较干预前后两组之间的正确评估数量。我认为由于每个参与者都贡献了两个评估，这是配对数据，我应该进行 McNemars 检验。但是，我的第一稿有卡方，我正在重新考虑自己。我应该更改我提议进行的测试吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661223/should-i-use-chi-squared-or-mcnemar</guid>
      <pubDate>Tue, 11 Feb 2025 13:06:08 GMT</pubDate>
    </item>
    <item>
      <title>如何在 K 均值聚类中获取较小的最优 K 值</title>
      <link>https://stats.stackexchange.com/questions/661222/how-to-get-a-smaller-number-of-optimal-k-in-k-means-clustering</link>
      <description><![CDATA[我想在大小为 $5000$ 的数据集上进行 k 均值聚类，以获得 $k$ 的较小最优值（$k≤5$）。我已使用 BIC 和 Gap 统计量来确定最优聚类数，两种方法均表明最优 $k$ 为 $7$ 或更高。我想知道我是否可以进行调整（例如，通过将 $s(k+1)$ 乘以因子 $c&gt;1$ 或将其作为 BIC 中的惩罚项包括在内），以便获得较小的 $k$ 最佳值。
以下是我为计算 Gap 统计量和 BIC 而执行的计算：
BIC 计算
$$\text{BIC}=n\ln(\frac{W}{n})+m\ln(n)$$
其中 $W$ 是簇内总平方和，
$m$ 是模型中自由参数的数量，$n$ 是数据点的总数。
最优的 $k$ 是 BIC 值最小的那个。
差距统计
$$\text{Gap}(k)≥\text{Gap}(k+1)−s(k+1)$$
其中 $\text{Gap}(k)=\frac{1}{B}\sum_{b=1}^{B}\ln(W_{k} ^{∗(b)})−\ln(W_k)$。
这里 $W_k$ 是 k 个簇的簇内弥散度，$W_{k} ^{∗(b)}$ 是 $W_{k} ^{∗(b)}$ 是 k 个簇的簇内弥散度。 class=&quot;math-container&quot;&gt;$b^\text{th}$ 参考数据集（来自总共 $B$ 参考数据集）从没有明显聚类的分布生成，用于 $k$ 个聚类。
如果我犯了任何错误，如果有其他方法可以获取较小的聚类数，或者我可以做任何修改，请告诉我。]]></description>
      <guid>https://stats.stackexchange.com/questions/661222/how-to-get-a-smaller-number-of-optimal-k-in-k-means-clustering</guid>
      <pubDate>Tue, 11 Feb 2025 12:53:35 GMT</pubDate>
    </item>
    <item>
      <title>R 中的权重参数 GLM</title>
      <link>https://stats.stackexchange.com/questions/661237/weight-argument-glm-in-r</link>
      <description><![CDATA[我有一个心理物理学实验，我正在根据对比度测量参与者是否能看到刺激。
我的逻辑回归有两个选项。1) 使用原始数据（0 和 1）来表明他们是否看到了刺激。
但是，我所依据的分析论文对转换后的数据运行二项式（概率单位）GLM，其中考虑了假阳性率。因此，选项 2) 是遵循该论文，让结果变量取 0 到 1 之间的值。
这样，我的数据点就会少很多，因为它们会根据刺激参数折叠起来，从而得到转换后的结果变量。
所以问题是：我可以使用 R 的 GLM 中的权重参数来指定每个单独的转换数据点代表多少次试验吗？
抱歉解释得这么长，但我认为一些背景知识是相关的。
我已经尝试了这两个选项，以及使用没有权重的转换结果变量，它们都产生了不同的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/661237/weight-argument-glm-in-r</guid>
      <pubDate>Tue, 11 Feb 2025 12:10:09 GMT</pubDate>
    </item>
    </channel>
</rss>