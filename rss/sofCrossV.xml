<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 15 Jan 2025 09:17:07 GMT</lastBuildDate>
    <item>
      <title>L2 惩罚 cox 比例风险回归的统计推断</title>
      <link>https://stats.stackexchange.com/questions/660048/statistical-inference-for-l2-penalized-cox-proportional-hazard-regression</link>
      <description><![CDATA[首先，感谢您阅读我的问题。这是我第一次在这个平台上提问，所以如果某些要求没有得到满足，我深表歉意。
我试图使用 cox 比例风险生存分析来估计多个预测因子（HR 及其 95% CI 和 p 值）对直肠癌复发概率的影响。
由于我的数据集规模小（140 个观测值）且事件计数低（7 个事件），我决定使用 glmnet 包中的岭回归。Lasso 并不可取，因为我想保留所有预测因子，因为我有证据表明它们对复发的重要性。
我搜索了文献并了解到，虽然惩罚模型的统计推断以前由于惩罚引入的偏差而并不可取，但现在已被诸如“hdi”和“selectiveInference”之类的包克服，用于 Lasso 型回归，“lmridge”用于 L2 惩罚线性回归。
我的问题如下：

有没有什么方法可以对 Cox 比例模型上的岭回归进行统计推断。到目前为止，我还没有找到任何具有此功能的文章或 R 包
如果岭回归的统计推断仍然不可接受，我该如何解释 glmnet() 提供的 HR

这是我用于拟合模型的代码：
set.seed(10)
y &lt;- with(df_cox, Surv(df_cox$recurrencetime, df_cox$recurrence)) # 响应变量
x &lt;- model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1] # 预测器
df_cox = model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1] # 预测器
df_cox = model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1]
cv_model &lt;- cv.glmnet(
x, y,
family = &quot;cox&quot;,
alpha = 0, # 弹性网络 (alpha = 0.5 是套索和脊线的混合)
nfolds = 10 # 10 倍交叉验证
)
best_lambda &lt;- cv_model$lambda.min

# 使用最佳 lambda 拟合最终模型
final_model &lt;- glmnet(x, y, family = &quot;cox&quot;, alpha = 0, lambda = best_lambda)
]]></description>
      <guid>https://stats.stackexchange.com/questions/660048/statistical-inference-for-l2-penalized-cox-proportional-hazard-regression</guid>
      <pubDate>Wed, 15 Jan 2025 07:30:52 GMT</pubDate>
    </item>
    <item>
      <title>PSM-DiD 模型及其相关密度图的问题</title>
      <link>https://stats.stackexchange.com/questions/660044/issues-with-psm-did-model-and-its-related-density-plot</link>
      <description><![CDATA[作为项目的一部分，我正在尝试使用 R 中的 MatchIt 包实现 PSM-DiD 模型。我对此非常陌生，因此无法找出代码到底哪里出了问题，因为在运行初始 Logit 模型以及随后的匹配模型后，我得到的倾向得分结果都是错误的。
我的数据的简要说明：
变量：Under14（处理期限；1 表示年龄 &lt; 14，否则为 0），Post1986（毕业后；1 表示年份 &lt;= 1986，否则为 0），LIT（结果），其他协变量 - AGE、SEX、FAMSIZE、NCHILD、URBAN、YEAR、STATE（最后 2 个变量不太相关）。
据我所知，倾向得分是条件概率，因此该模型应该正确给出输出（倾向变量）。但是，处理单元的倾向得分接近 0（2.22e-16），而对照组的倾向得分接近 1，这对我来说没有意义。
这是我用于计算倾向得分的代码：
# 步骤 1：根据“Under14”变量分配组（处理组或对照组）
temp$group &lt;- with(temp, ifelse(Under14 == 1, &quot;Treated&quot;, &quot;Control&quot;))
temp$group &lt;- factor(temp$group, levels = c(&quot;Treated&quot;, &quot;Control&quot;))

# 步骤 2：拟合逻辑回归模型以估计倾向得分
logit_model &lt;- glm(group ~ URBAN + AGE + SEX + NCHILD + FAMSIZE, family = binomial, data = temp)
summary(logit_model)

# 步骤 3：计算预测概率（倾向得分）
temp$propensity &lt;- predict(logit_model, type = &quot;response&quot;)

并对匹配模型执行此操作：
# 步骤 4：使用倾向得分和最近邻匹配执行匹配
psm &lt;- matchit(group ~ URBAN + AGE + SEX + NCHILD + FAMSIZE, method = &quot;nearest&quot;, distance = temp$propensity, data = temp)

# 步骤 5：提取匹配数据
matched_data &lt;- match.data(psm)

# 步骤 6：在匹配数据上拟合 DiD 模型
# 组：治疗组或对照组
# Post1986：治疗后指标
# 交互项：组 * Post1986
did_model &lt;- lm(LIT ~ group * Post1986, data = matching_data, weights = weights)
summary(did_model)

这是 DiD 输出（系数表示 groupControl，出于某种我不明白的原因，也就是说，处理过的系数缺失了）：
输出

它为所有单元赋予权重 1；因此，最终的 DiD 模型不会给出所需的输出。0 和 1 值也存在于最终数据集匹配数据中。我对自己的方法可能存在的问题感到困惑。如果有人能指出错误，那将非常有帮助。
此外，我还想制作倾向得分匹配前后的核密度图，如下所示：
密度图

任何帮助都将不胜感激。我知道我的问题很长，但我完全卡住了。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660044/issues-with-psm-did-model-and-its-related-density-plot</guid>
      <pubDate>Wed, 15 Jan 2025 05:31:06 GMT</pubDate>
    </item>
    <item>
      <title>如何给回归模型添加约束？</title>
      <link>https://stats.stackexchange.com/questions/660042/how-to-add-constraints-to-a-regression-model</link>
      <description><![CDATA[这可能是一个简单的问题，但我确实把它复杂化了。我想创建一个满足这两个条件的回归模型：

条件 1：在自然界中，我相信响应变量永远不会超出范围 $y=c_1, c_2$（两个常数）。
条件 2：我还相信响应变量会随着协变量的增加而增加。
如何创建一个反映这一点的回归模型？

使用基础微积分，我编写了一个模型：
$$\eta = X\beta$$
$$y = g(\eta) = c_1 + \frac{c_2 - c_1}{1 + e^{-\eta}}$$
现在，验证条件1：

当$\eta \to -\infty$时：
$$\lim_{\eta \to -\infty} y = c_1 + \frac{c_2 - c_1}{1 + e^{-\eta}}$$
$$= c_1 + \frac{c_2 - c_1}{1 + \infty}$$
$$= c_1 + 0$$
$$= c_1$$

当$\eta \to \infty$时：
$$\lim_{\eta \to \infty} y = c_1 + \frac{c_2 - c_1}{1 + e^{-\eta}}$$
$$= c_1 + \frac{c_2 - c_1}{1 + 0}$$
$$= c_1 + (c_2 - c_1)$$
$$= c_2$$


我们还可以看到，一般来说，$\eta$的所有值都会导致$c_1,c_2$之间的响应。
如果我们定义$t = \frac{1}{1 + e^{-\eta}}$，对于任何实数 $\eta$:，我们可以看到分母 $1 + e^{-\eta}$ 始终为正，因为 $e^{-\eta}$ 始终为正。因此，$t$ 始终为正。我们可以操纵$t$并写入：
$$t = \frac{1}{1 + e^{-\eta}}$$
$$t = \frac{1}{1 + e^{-\eta}} \cdot \frac{e^\eta}{e^\eta}$$
$$t = \frac{e^\eta}{e^\eta + e^{\eta-\eta}}$$
$$e^{\eta-\eta} = e^0 = 1$$
$$t = \frac{e^\eta}{e^\eta + 1}$$
由于分子和分母都是正数，且分母总是大于分子，我们知道 $0 &lt; t &lt; 1$。因此，$y = c_1 + (c_2 - c_1)t$，其中 $0 &lt; t &lt; 1$。
条件 2：现在，为了表明响应总是随着协变量的增加而增加（单调性）。使用链式法则，我们可以将导数写为：
$$\frac{dy}{dx_j} = (c_2 - c_1)\frac{e^{-\eta}}{(1 + e^{-\eta})^2}\beta_j$$
从这个导数中，我可以看到：

$(c_2 - c_1)$ 为正（即 $c_2 &gt; c_1$）
$e^{-\eta}$ 始终为正（指数始终为正）
$(1 + e^{-\eta})^2$始终为正（和的平方为正）

如果 $\beta_j$ 始终为正，那么我认为单调性会得到尊重。但我认为需要为此添加额外的约束？
有没有更简单的方法来制作一个尊重这两个条件的回归模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/660042/how-to-add-constraints-to-a-regression-model</guid>
      <pubDate>Wed, 15 Jan 2025 03:54:24 GMT</pubDate>
    </item>
    <item>
      <title>具有动态输入特征的时间序列预测</title>
      <link>https://stats.stackexchange.com/questions/660041/time-series-forecast-with-dynamic-input-features</link>
      <description><![CDATA[在 $T$ 期间，我想要预测目标变量 $V_{T+1}, ..., V_{T+60}$。我的独立变量是 $X$ 和 $f_1, ..., f_{60}$。$f_i$ 实际上是 $i$ 之前对变量 $f$ 的预测。因此，在训练数据中，对于 $t$ 期间，所有 $f_1, ..., f_{60}$ 值均可用。然而，在 $T$ 期间，当我想要预测 $V_{T+1}, ..., V_{T+60}$ 时，可用的 $f_i$ 与训练数据不同。例如，在 $T+60$ 期间，只有 $f_{60}$ 的值可用。我该如何正确设置我的预测模型，使训练数据与此保持一致？我正在使用 Temporal Fusion Transformer 模型。]]></description>
      <guid>https://stats.stackexchange.com/questions/660041/time-series-forecast-with-dynamic-input-features</guid>
      <pubDate>Wed, 15 Jan 2025 03:24:53 GMT</pubDate>
    </item>
    <item>
      <title>拟二项式/拟泊松回归和异方差标准误差</title>
      <link>https://stats.stackexchange.com/questions/660033/quasibinomial-quasipoisson-regression-and-heteroskedastic-standard-errors</link>
      <description><![CDATA[在进行拟二项式或拟泊松回归时，使用异方差稳健标准误差（例如 HC1）是否有意义？我还没有看到太多关于这方面的讨论，如果能提供任何文献，我将不胜感激。在我看来，由拟似然估计的离散度已经用于调整 SE，因此不再需要额外的调整。]]></description>
      <guid>https://stats.stackexchange.com/questions/660033/quasibinomial-quasipoisson-regression-and-heteroskedastic-standard-errors</guid>
      <pubDate>Tue, 14 Jan 2025 23:32:02 GMT</pubDate>
    </item>
    <item>
      <title>估计不同伯努利试验间巧合平均值的不确定性</title>
      <link>https://stats.stackexchange.com/questions/660025/estimating-the-uncertainty-in-the-mean-of-coincidences-between-separate-bernoull</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660025/estimating-the-uncertainty-in-the-mean-of-coincidences-between-separate-bernoull</guid>
      <pubDate>Tue, 14 Jan 2025 19:44:20 GMT</pubDate>
    </item>
    <item>
      <title>通过 RKHS 实现的 SVM 解决方案的平滑度</title>
      <link>https://stats.stackexchange.com/questions/660011/smoothness-of-svm-solution-via-rkhs</link>
      <description><![CDATA[我试图将 RKHS 的 SVM 视图与 SVM 解决方案的平滑性联系起来：
经典原始函数由以下公式给出：
\begin{aligned}
\text{最小化} \quad &amp; \frac{1}{2} \|\mathbf{w}\|^2, \quad \mathbf{w} \in \mathbb{R}^d, \, b \in \mathbb{R}, \\
\text{受制于} \quad &amp; y_i (\mathbf{w}^\top \mathbf{x}_i + b) \geq 1, \quad i = 1, \dots, n, \\
&amp; \mathbf{x}_i \in \mathbb{R}^d, \, y_i \in \{-1, 1\}。
\end{aligned&gt;
我们知道：
$\mathbf{w} = \sum_{i=1}^n \alpha_i y_i \mathbf{x}_i$
现在使用内核 $k$ 和一些相关特征图 $\phi(x$) 进行重构
$\mathbf{w} = \sum_{i=1}^n \alpha_i y_i \phi(\mathbf{x}_i)$
$\|\mathbf{w}\|^2 = \mathbf{w}^\top \mathbf{w} = \sum_i \sum_j \alpha_i \alpha_j y_i y_j \phi(\mathbf{x}_i)^\top \phi(\mathbf{x}_j)
= \sum_i \sum_j \alpha_i \alpha_j y_i y_j k(\mathbf{x}_i, \mathbf{x}_j)
= \|f\|^2_{H}.$
因此最小化 $||\mathbf{w}||$ 与最小化 $||f||_H$ 相同。
并且由于对于任何 $f \in H$ 和任意对 $x,x&#39; \in X$
$
|f(\mathbf{x}) - f(\mathbf{x}&#39;)| = |\langle f, K_{\mathbf{x}} - K_{\mathbf{x}&#39;} \rangle_{H}|
\leq \|f\|_{H} \cdot \|K_{\mathbf{x}} - K_{\mathbf{x}&#39;}\|_{H}
= \|f\|_{H} \cdot d_K(\mathbf{x}, \mathbf{x}&#39;),
$
$||f||_H$ 在某种程度上控制了平滑度。那么，这是否是 SVM 优化平滑解决方案的一个论点？]]></description>
      <guid>https://stats.stackexchange.com/questions/660011/smoothness-of-svm-solution-via-rkhs</guid>
      <pubDate>Tue, 14 Jan 2025 14:11:39 GMT</pubDate>
    </item>
    <item>
      <title>对序数、相关特征进行降维，并附加连续特征</title>
      <link>https://stats.stackexchange.com/questions/660005/dimension-reduction-on-ordinal-related-features-with-additional-continuous-feat</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660005/dimension-reduction-on-ordinal-related-features-with-additional-continuous-feat</guid>
      <pubDate>Tue, 14 Jan 2025 13:26:13 GMT</pubDate>
    </item>
    <item>
      <title>连续随机变量的充分统计量的因式分解定理</title>
      <link>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics-in-case-of-continuous-random-var</link>
      <description><![CDATA[根据因式分解定理（Fisher-Neyman），我们得到一个统计量$ T(X) $充分当且仅当存在因式分解：$ f(x|\theta) = g(T(x)|\theta)h(x) $。符号遵循 Casella/Berger 第 276 页。
Casella/Berger 在离散情况下给出了证明，并指出具体因式分解的形式为：$ P(X=x | {\theta}) = P(T(X) = T(x) | {\theta})P(X=x | T(X) = T(x)) $
我的问题是：我们可以将这种解释应用于连续情况吗？它总是成立吗？因此：$ f(x|\theta) = f(T(x)|\theta)f(x|T(x)) $ 其中 $f$ 表示相应的 pdf？]]></description>
      <guid>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics-in-case-of-continuous-random-var</guid>
      <pubDate>Mon, 13 Jan 2025 22:52:25 GMT</pubDate>
    </item>
    <item>
      <title>泊松过程可以变成泊松过程回归吗？</title>
      <link>https://stats.stackexchange.com/questions/659931/can-a-poisson-process-be-made-into-a-poisson-process-regression</link>
      <description><![CDATA[这是我正在考虑的概念验证问题。
数据格式如下（模拟数据）：
patient_id dob gender hospital_visit age_at_visit
1 2019-06-21 F 2024-03-13 4
1 2019-06-21 F 2024-05-22 4
1 2019-06-21 F 2024-07-11 5
1 2019-06-21 F 2024-09-19 5
1 2019-06-21 F 2024-10-02 5
1 2019-06-21 F 2024-10-30 5
1 2019-06-21 F 2024-11-13 5
1 2019-06-21 F 2024-12-15 5
1 2019-06-21 F 2024-12-17 5
2 2007-12-13 M 2024-01-27 16
2 2007-12-13 M 2024-02-09 16
2 2007-12-13 M 2024-06-10 16
3 2024-02-01 M 2024-06-28 0
4 2014-04-12 F 2024-08-17 10
4 2014-04-12 F 2024-12-21 10
5 2010-02-20 F 2024-02-03 13
5 2010-02-20 F 2024-02-21 14
5 2010-02-20 F 2024-03-17 14
5 2010-02-20 F 2024-03-31 14
5 2010-02-20 F 2024-04-09 14

我定义了 2 个泊松过程：一个标准泊松过程（速率恒定）和一个（加速）泊松过程，其中速率函数随着更多事件的发生而变化（$r$ 是速率，$n$ 是已经发生的事件数发生):
$$ \quad\textbf{标准泊松分布：} \quad P(N(t) = k) = \frac{(\lambda t)^k e^{-\lambda t}}{k!} $$
$$ \quad\textbf{标准泊松过程：} \quad P(N(t) = 0) = e^{-\lambda t} $$
$$ \quad\textbf{加速泊松分布：} \quad P(N(t) = k) = \frac{(\lambda_n t)^k e^{-\lambda_n t}}{k!} $$
$$ \quad\textbf{速率增长函数：} \quad \lambda_n = \lambda_0 \cdot (1+r)^n $$
$$ \quad\textbf{加速泊松过程：} \quad P(N(t) = 0) = e^{-\lambda_n t} $$
很明显，当我们模拟和可视化它们时，我们可以看到两者之间的差异（在 R 中）：

我想知道这是否可以用于创建某人下次住院的模型，因为我们知道他已经住院了多少次（假设我们只在患者住院时进行协变量测量）。
我认为这在我们认为未来住院取决于患者过去住院次数的情况下很有用 - 这样，住院频率越高的人住院间隔时间就越短。
例如，我们可以定义这样的风险模型吗？
$$ \ln[h(t|n, X)] = \ln(\lambda_0) + n\ln(1+r) + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p $$
$$h(t) = \lim_{\Delta t \to 0} \frac{P(t \leq T &lt; t + \Delta t | T \geq t)}{\Delta t}$$
或者也许是对数对数链接？
$$ \log(-\log(1 - P(\text{readmission in }[t, t+\Delta t]|n, X))) = \beta_0 + \beta_n n + X\beta $$
$$ \log(-\log(1 - P(\text{readmission in }[t, t+\Delta t]|n))) = \log(\lambda_0) + n\log(1+r) + \log(\Delta t) $$
$$ \log(-\log(1 - P(\text{readmission in }[t, t+\Delta t]|n, X))) = \beta_0 + \beta_n n + X\beta + \log(\Delta t) $$
或者仅仅是一个纯随机过程？
$$ \log(\lambda_n) = \beta_0 + \beta_1n + X\beta $$
$$ \lambda_n = e^{\beta_0 + \beta_1n + X\beta} $$
$$ P(\text{readmission in }[t, t+\Delta t]|n,X) = 1 - e^{-\lambda_n\Delta t} = 1 - e^{-e^{\beta_0 + \beta_1n + X\beta}\Delta t} $$
我不明白如何对此类问题进行建模，因为它涉及纵向分析、随机过程和生存分析的概念。有什么关于如何开始的提示吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659931/can-a-poisson-process-be-made-into-a-poisson-process-regression</guid>
      <pubDate>Sun, 12 Jan 2025 21:26:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 SARIMA 模型中，时间序列的差分无助于使其平稳？</title>
      <link>https://stats.stackexchange.com/questions/659898/why-does-differencing-of-time-series-not-help-to-make-it-stationary-in-the-sarim</link>
      <description><![CDATA[我在 SARIMA 模型中差分后无法获得平稳时间序列。
我是时间序列分析的初学者，但我读到时间序列 Y_t = \nabla^d (1-L^s)^D X_t 应该是平稳时间序列。然而，在用值 s=12 和不同的 d 和 D 值进行差分后，我的时间序列似乎不是平稳分析 ACF 函数。我也尝试过一开始 lambda=0 的 Box–Cox 变换，但同样没用。
这是我的原始数据
 (data_ts)
它是非平稳的。
经过 lambda = 0 的 Box-Cox 变换之后
data_bc &lt;- BoxCox(data_ts, lambda=0)


这是 ACF 函数：

然后我尝试对我的时间序列进行差分，结果如下：
ts_plot(diff(data_bc))
Acf(diff(data_bc))

.
。
在我看来，它可以是平稳的，但从 ACF 来看，它不是。可能是因为季节性？所以我尝试对滞后 s=12 的时间序列进行差分，然后再次进行差分（s=12、d=1、D=1）。
ts_plot(diff(diff(data_bc, lag=12)))
Acf(diff(diff(data_bc, lag=12)))



再次分析 ACF 函数，它似乎不是平稳的。我错了吗？那我该怎么办？
Box-Cox 变换、差分、消除季节性。我希望得到平稳时间序列。]]></description>
      <guid>https://stats.stackexchange.com/questions/659898/why-does-differencing-of-time-series-not-help-to-make-it-stationary-in-the-sarim</guid>
      <pubDate>Sat, 11 Jan 2025 14:36:19 GMT</pubDate>
    </item>
    <item>
      <title>确保 Fisher 信息矩阵严格正定的条件</title>
      <link>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</link>
      <description><![CDATA[Fisher 信息矩阵定义为：
$$I(\theta):=E\left[\left(\frac{\partial\log f(X;\theta)}{\partial \theta}\right)^2 \mid\theta\right]$$
其中 $f$ 是似然函数。
我正在寻找充分条件 - 最好是关于 $f$ 或 $\log f$ - 以确保 Fisher 矩阵严格正定。
正定性是证明最大似然估计量 (MLE) 渐近一致性的众所周知的临界条件。因此，本次调查具有重要意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</guid>
      <pubDate>Fri, 10 Jan 2025 14:33:43 GMT</pubDate>
    </item>
    <item>
      <title>分析一个条件涉及内生分配而另一个条件涉及外生分配的设计是否有效？</title>
      <link>https://stats.stackexchange.com/questions/659803/is-it-valid-to-analyze-a-design-where-one-condition-involves-endogenous-and-anot</link>
      <description><![CDATA[我正在使用彩票设置进行一项实验，其中向参与者提供有关风险和奖励的信息。
设计包括两个因素：

条件：在一种条件下（自由序列），参与者可以选择信息的顺序（先有风险还是先有奖励）。在另一个（固定序列）中，它们被分配顺序（先有风险还是先有回报）。

序列顺序：人们首先看到的是风险还是回报。


这导致了 2（固定序列 vs. 自由序列）x 2（先有风险 vs. 先有回报）的设计。
因变量 (DV)：参与者对后续结果的兴趣（二进制：0/1）。
分析计划：
我们计划使用逻辑回归来预测 DV，预测因子如下：

条件（固定序列 vs. 自由序列）
序列顺序（先有风险 vs. 先有回报）
交互项（条件 × 序列顺序）

关键问题：
在“自由序列”条件下，参与者选择先查看风险还是先查看回报，从而使序列顺序具有内生性。在“固定序列”条件下，序列顺序是外生的（随机分配）。序列顺序的这种性质差异（内生与外生）是否会导致分析无效？如果是，我在测试假设时如何解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/659803/is-it-valid-to-analyze-a-design-where-one-condition-involves-endogenous-and-anot</guid>
      <pubDate>Fri, 10 Jan 2025 01:35:56 GMT</pubDate>
    </item>
    <item>
      <title>R 中带有测量误差的优化函数（矩量模拟法）</title>
      <link>https://stats.stackexchange.com/questions/659682/optimizing-function-with-measurement-error-in-r-simulated-method-of-moments</link>
      <description><![CDATA[统计学中的一个常见问题是假设一个总体，模拟许多样本，并找到与所需统计数据集最接近（在 MSE 意义上）的参数。为了说明，下面是如何找到与 AR1 过程匹配的参数的草图。（这只是一组广泛问题的说明 --- 这个特定问题是 AR1 并不重要。）

NT &lt;- 50
match &lt;- c(intercept=0.2, ar1=0.90, expsigma=(-0.1))

sim.and.est.1 &lt;- function(i, p) {

## 模拟某个过程，比如 true ar1
set.seed(i); e &lt;- rnorm(NT, 0, exp(p[3]))
s &lt;- c( 0.2, numeric(NT-1) )
for (t in 2:NT) s[t] &lt;- p[1] + p[2]*s[t-1] + e[t]

## 估计 OLS ar1
a &lt;- lm.fit( cbind(1, s[1:(NT-1)]), s[2:NT] )
c( coef(a), expsigma= log(sd(resid(a)) ))
}

mcsapply &lt;- function( iter, fun, ... ) { 
simply2array(mclapply( iter, fun, ... )) }
penalty &lt;- function( a, b ) mean( (a-b)^2 )

result &lt;- optim(par=c(1.0, 0.0, 0.05),
fn=function( guess3, MC=1000 ) {
## message( paste( p3, collapse=&quot; &quot; ) )
simsests &lt;- 
t(mcsapply( 1:MC, function(i) sim.and.est.1(i, guess3) ))
thisone &lt;- colMeans( simsests )
ov &lt;- penalty( thisone , match )

## 如果我们接近，则抽样更多
if (ov &lt; 1e-2) {
## 增加精度
simsests &lt;- rbind(simsests, 
t(mcsapply( 1:MC*5, function(i) sim.and.est.1(i+MC, guess3) )))
thisone &lt;- colMeans( simsests )
ov &lt;- penalty( thisone , match )
}
ov
},
method=&quot;Nelder-Mead&quot;)

print(result)

R 中是否有更好的方法来处理具有测量误差的函数优化？

我试图处理这样的想法：远离最佳值，我不需要在函数本身中采样那么多点。它完全是临时的。
我也尝试重新启动 Nelder-Mead，但即使从局部最优开始似乎也没有减少其迭代次数（函数评估）。

是否有更适合手头任务的优化器？
我在这里做的事情可以做得更好吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659682/optimizing-function-with-measurement-error-in-r-simulated-method-of-moments</guid>
      <pubDate>Tue, 07 Jan 2025 17:01:55 GMT</pubDate>
    </item>
    <item>
      <title>混合模型中部分合并聚类估计消失或超出总体估计</title>
      <link>https://stats.stackexchange.com/questions/658964/partial-pooled-cluster-estimates-going-away-or-beyond-grand-estimates-in-mixed-m</link>
      <description><![CDATA[我认为我对混合模型中部分池化的主要目标和特征有相当好的理解。然而，部分池化的实际执行中有一些细节与我期望从各个集群得到的行为相冲突。例如，在下面我将链接的所有三个演示中，使用了各种表达式来表明特定于集群的截距和斜率估计应该向样本中相应的总体估计移动（也允许保持静止）。但是，如果您仔细跟踪集群估计从无池化到部分池化版本的一些可视化运动，您就会看到集群估计实际上如何沿着各个轴远离总体估计。在某些情况下，集群估计值也可能超出总体估计值。
https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/
https://towardsdatascience.com/when-mixed-effects-hierarchical-models-fail-pooling-and-uncertainty-77e667823ae8
https://m-clark.github.io/posts/2019-05-14-shrinkage-in-mixed-models/
至少定义集群截距重新定位的公式（参见上面的中间链接和此视频讲座）表明，单个集群的移动范围应限制在初始无合并位置和总体估计值之间（据我所知，如有必要，请纠正我）。但是，上述相互矛盾的观察结果是否与同一模型中随机截距和斜率的存在及其相关性有关？还没有拿尺子，但我的直觉告诉我，虽然聚类估计值可以沿着单个轴发散，但也许在部分池化期间整体斜边会变小。错误：我实际上拿了尺子，通过从屏幕上测量，由于部分池化，至少有一个整体距离增加了（参见最后列出的网站、df = create_data(sd_int = .25, sd_slope = 1) 的图和右上角的一个聚类）。
如果观察到的行为不是由错误引起的，而且我没有误解什么，那么原因能否从直观的实际意义上得到解释。为什么这种行为是有益的，尽管它似乎与部分池化的主要原则不一致。为什么不让所有的聚类估计值都沿着截距和斜率轴更接近总体估计值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658964/partial-pooled-cluster-estimates-going-away-or-beyond-grand-estimates-in-mixed-m</guid>
      <pubDate>Thu, 19 Dec 2024 12:35:28 GMT</pubDate>
    </item>
    </channel>
</rss>