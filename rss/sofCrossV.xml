<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 28 Nov 2024 06:26:34 GMT</lastBuildDate>
    <item>
      <title>以市场份额为因变量的面板回归模型</title>
      <link>https://stats.stackexchange.com/questions/657964/panel-regression-model-with-market-share-as-dependent-variable</link>
      <description><![CDATA[该数据集包含 6 年内不同银行的不同变量。我想了解这些变量与市场份额之间的关系。问题是市场份额是一场零和博弈。如果一家银行的市场份额增加，那么另一家银行的市场份额就会自动减少。我应该如何应对这种情况？我尝试过固定效应的 Logit 变换和向量自回归，但效果并不好。]]></description>
      <guid>https://stats.stackexchange.com/questions/657964/panel-regression-model-with-market-share-as-dependent-variable</guid>
      <pubDate>Thu, 28 Nov 2024 03:02:25 GMT</pubDate>
    </item>
    <item>
      <title>潜在类别分析中分类尺度概率的协方差矩阵</title>
      <link>https://stats.stackexchange.com/questions/657963/covariance-matrix-from-probabilities-of-categorical-scales-in-latent-class-analy</link>
      <description><![CDATA[对于如何从潜在类别分析中分类尺度的每个级别的概率中恢复协方差矩阵，我感到很困惑。
目前，我使用 bootstrap 方法。
在以下示例中（来自 poLCA 包），probs 包含基于 3 个类（矩阵的行）的 5 个项目（矩阵），每个尺度中有 3、2、3、4 和 3 个级别（矩阵中的列）。每个类的比例为 P。通过重新采样 nreps 次，我可以很好地估计协方差矩阵，但我想在不使用引导程序的情况下找到它。
set.seed(42)
probs &lt;- list(matrix(c(0.6, 0.1, 0.3,
0.6, 0.3, 0.1,
0.3, 0.1, 0.6),
ncol = 3,byrow = TRUE), # 条件响应概率到 Y1
matrix(c(0.2, 0.8,
0.7, 0.3,
0.3, 0.7),
ncol = 2, byrow = TRUE), # 条件响应概率到 Y2
matrix(c(0.3, 0.6, 0.1,
0.1, 0.3, 0.6,
0.3, 0.6, 0.1),
ncol = 3,byrow = TRUE), # 条件响应概率到 Y3
matrix(c(0.1, 0.1, 0.5, 0.3,
0.5, 0.3, 0.1, 0.1,
0.3, 0.1, 0.1, 0.5),
ncol = 4,byrow = TRUE), # 条件响应概率到 Y4
matrix(c(0.1, 0.1, 0.8,
0.1, 0.8, 0.1,
0.8, 0.1, 0.1),
ncol = 3,
byrow = TRUE)) # 条件响应概率到 Y5
nreps &lt;- 1000
bootS &lt;- array(0, dim=c(length(probs),length(probs),nreps))
n &lt;- 500
P &lt;- c(.33,.34,.33)
for(i in 1:nreps){
D &lt;- poLCA.simdata(N = n,
probs = probs,
P = P)$dat
bootS[,,i] &lt;- cov(D)# - S
}
S &lt;- apply(bootS, c(1, 2), mean)
round(S,4)
[,1] [,2] [,3] [,4] [,5]
[1,] 0.8044 0.0404 -0.0783 0.1052 -0.1370
[2,] 0.0404 0.2407 -0.0710 0.1134 0.0229
[3,] -0.0783 -0.0710 0.5008 -0.1729 -0.0005
[4,] 0.1052 0.1134 -0.1729 1.4484 0.0447
[5,] -0.1370 0.0229 -0.0005 0.0447 0.6642

我想知道是否有办法根据 probs 计算 S。如果是，如何在 R 中实现？
谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/657963/covariance-matrix-from-probabilities-of-categorical-scales-in-latent-class-analy</guid>
      <pubDate>Thu, 28 Nov 2024 01:51:24 GMT</pubDate>
    </item>
    <item>
      <title>将 PCA 应用于多个个体时间序列数据集</title>
      <link>https://stats.stackexchange.com/questions/657962/apply-pca-to-multi-individual-time-series-dataset</link>
      <description><![CDATA[假设我有 50 个用户的时间序列数据，每个用户有 20 个特征：User1_ts(F1,...F20)、User2_ts(F1,...F20)、...User50_ts(F1,...F20)。F20 是我要估计的目标变量，每个时间序列的长度可能不同。目前，我正在构建一个 AI 模型来估计 F20。训练数据集基于与每个用户相关的每个 ts 的 70% 的连接。而训练集是通过应用 90 天的时间窗口和一天切片来构建的。
我的问题与应用 PCA 来减少空间的方法有关：应该何时应用 PCA？

滚动之前？
滚动之后？
还有其他吗？

我找不到任何研究论文或其他链接来澄清这个方面。]]></description>
      <guid>https://stats.stackexchange.com/questions/657962/apply-pca-to-multi-individual-time-series-dataset</guid>
      <pubDate>Thu, 28 Nov 2024 01:21:42 GMT</pubDate>
    </item>
    <item>
      <title>神经网络使用反向传播可以学习布尔公式吗？</title>
      <link>https://stats.stackexchange.com/questions/657961/learnability-of-boolean-formulae-by-neural-networks-using-back-propagation</link>
      <description><![CDATA[我一直在研究神经网络和布尔公式。从我的努力来看，神经网络似乎通常无法使用反向传播来学习布尔公式。这在直觉上是有道理的，因为布尔公式的输出可以根据输入值表现出巨大的变化，因此会有很多不连续性，从而导致局部最优。
另一方面，我也明白任何布尔公式都可以用神经网络来表示，所以神经网络没有内在原因不能表示，因此可能学习任意的布尔公式。问题似乎出在学习算法上，所有通用的机器学习算法似乎都会陷入局部最优，无论我使用梯度下降、进化算法、期望最大化等，因为它们都基于局部增量改进是通向全局最优解的途径这一前提。
话虽如此，我也知道还有其他类型的算法，如 Quine-McCluskey 和 Espresso，它们可以从真值表中得出最小布尔公式。随后可以使用这些算法生成一个神经网络，该神经网络嵌入从真值表中得出的最小布尔公式算法。然而，据我所知，这些都是非常具体的算法，专门针对布尔公式，在更通用的机器学习环境中没有使用。
所以，这让我想到了我的问题。是否有任何证据表明神经网络能够或不能使用反向传播和梯度下降或任何其他通用机器学习算法来学习任意布尔公式？
我检查了 Cross Validated，并在 Google 上搜索了这个问题，但未能找到任何明确的答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/657961/learnability-of-boolean-formulae-by-neural-networks-using-back-propagation</guid>
      <pubDate>Thu, 28 Nov 2024 01:09:53 GMT</pubDate>
    </item>
    <item>
      <title>帮助我将多元线性回归模型中的两个假设结合起来进行方差分析比较！</title>
      <link>https://stats.stackexchange.com/questions/657960/help-me-to-combine-two-hypotheses-in-a-multiple-linear-regression-model-for-anov</link>
      <description><![CDATA[我目前正在研究多元线性回归并使用股票市场数据进行实践。我的数据集包括：

因变量 (Y)：标准普尔 500 指数价格

自变量：

黄金价格 (X1)

铜价 (X2)

表现最佳的行业 (X3)：分类变量，编码如下：

XLK（技术）或 XLE（能源）= 1

所有其他行业 = 0


我有两个假设想要测试：

铜价 (X2) 与 XLK/XLE（X3=1）相互作用，但与其他行业不相互作用(X3=0)。
黄金价格 (X1) 与任何表现最佳的行业 (X3) 均无关联。

我想将这两个假设合并为一个模型，并使用 R 中的 anova(full_model, Reduced_model) 创建一个简化模型，以便与完整模型进行比较。但是，我不确定如何构建简化模型以反映这两个假设。
full_model &lt;- lm(SP500_Adj_Close ~ Gold_Price + Copper_Price + Performing_Sector_Dummy + 
Gold_Price:Performing_Sector_Dummy + Copper_Price:Performing_Sector_Dummy)

以上是我的完整模型。如果我错了，请纠正我。
您能帮我构建简化模型并指导我如何适当地测试这些假设吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657960/help-me-to-combine-two-hypotheses-in-a-multiple-linear-regression-model-for-anov</guid>
      <pubDate>Thu, 28 Nov 2024 01:08:11 GMT</pubDate>
    </item>
    <item>
      <title>如何根据 DNN 的特定层来调制图像</title>
      <link>https://stats.stackexchange.com/questions/657954/how-do-you-modulate-an-image-according-to-specific-layers-of-a-dnn</link>
      <description><![CDATA[我的实验室使用 DNN（VGG、CLIP）来处理自然物体（狗、树等）图像的相似性。我想通过对特定层的信息进行加扰（使用某种增益函数）来调整某些图像，然后在调整后重新可视化图像。有人做过这种事情吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657954/how-do-you-modulate-an-image-according-to-specific-layers-of-a-dnn</guid>
      <pubDate>Wed, 27 Nov 2024 20:01:37 GMT</pubDate>
    </item>
    <item>
      <title>从逻辑模型中取预测概率的总和？</title>
      <link>https://stats.stackexchange.com/questions/657953/taking-the-sum-of-predicted-probabilities-from-logit-model</link>
      <description><![CDATA[我正在使用 logit 模型来预测学生通过特定课程的概率。我运行 logit，为样本中的学生生成预测概率，并希望将模型与观察到的通过率进行比较。我创建了分类表并执行了一些其他检查。
有人向我建议的一种方法是对样本（以及感兴趣的子组内）的所有预测概率求和，以将预测的通过次数与观察到的通过次数进行比较。直观地讲，这对我来说很有意义。将预测概率相加将产生模型在我的样本中预测的预期事件总数，这似乎是合理的。然而，当我试图找到同行评审的论证时，我却一无所获，无法找到使用这种方法的经过验证的例子。
我的问题是：将我的样本和样本子组的预测概率相加，以将预期事件计数与观察到的事件计数进行比较是否合适？如果合适，这种方法是否在任何信誉良好的来源中得到验证或使用？]]></description>
      <guid>https://stats.stackexchange.com/questions/657953/taking-the-sum-of-predicted-probabilities-from-logit-model</guid>
      <pubDate>Wed, 27 Nov 2024 19:57:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么稳定分布在 $\alpha=2$ 时变为高斯分布？</title>
      <link>https://stats.stackexchange.com/questions/657952/why-does-the-stable-distribution-become-gaussian-at-alpha-2</link>
      <description><![CDATA[我很难理解为什么稳定分布在$\alpha=2$时变成高斯分布。在我的课程中，似乎这个想法是从分布的尾部行为来看这一点。从维基百科上看，尾部行为（对于较大的 x）可以用以下公式来表示：
$$
{\displaystyle f(x)\sim {\frac {1}{|x|^{1+\alpha }}}\left(c^{\alpha }(1+\operatorname {sgn}(x)\beta )\sin \left({\frac {\pi \alpha }{2}}\right){\frac {\Gamma (\alpha +1)}{\pi }}\right)} 
$$
在 $\alpha=2$ 时，这变为与 $\frac{1}{x^3}$ 成比例的项，这似乎没有意义，因为对于高斯分布，预期的尾部行为将是某种指数。
我是否遗漏了什么，或者这个方程对 $\alpha=2$ 不成立 - 如果成立，发生了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/657952/why-does-the-stable-distribution-become-gaussian-at-alpha-2</guid>
      <pubDate>Wed, 27 Nov 2024 18:35:51 GMT</pubDate>
    </item>
    <item>
      <title>帕累托分布的矩</title>
      <link>https://stats.stackexchange.com/questions/657943/moments-of-the-pareto-distribution</link>
      <description><![CDATA[考虑一个随机变量 $Y$，使得
$$
(1) \quad E(\max\{0,Y\}^P)&lt;\infty \text{ for some $p&gt;0$}
$$
$Y$ 是否可以具有帕累托分布，如果可以，那么形状参数 $\alpha$ 受到哪些限制？
我的疑问： (1) 的充分条件是 $E(|Y|) &lt; \infty$（我认为），仅当形状参数 $\alpha$ 大于 1 时，它才适用于帕累托分布。但是，(1) 弱于 $E(|Y|) &lt; \infty$。因此，我不确定它是否对 $\alpha$ 施加了类似的条件。
尝试：按照以下建议，假设 $Y$ 是帕累托分布，其形状参数为 $\alpha$，最小值为 $y_m&gt;0$。然后
$$
E(\max\{0,Y\}^p)=E(Y^p)
$$
因此，(1) 当且仅当 $E(Y^p)&lt;\infty$ 成立，这又要求 $\alpha&gt;p$。这是正确的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657943/moments-of-the-pareto-distribution</guid>
      <pubDate>Wed, 27 Nov 2024 16:20:56 GMT</pubDate>
    </item>
    <item>
      <title>Ngram 模型不合适？</title>
      <link>https://stats.stackexchange.com/questions/657932/ngram-model-is-improper</link>
      <description><![CDATA[标准二元模型（例如定义于此处）基于以下原则在语料库$V$上定义概率分布：

单词$w$的边际概率定义为其在$V$中的计数除以$V$中的单词总数（计算重复次数）：$P(w) = \text{count}(w) / |V|$
一个单词跟随另一个单词的条件概率直观地定义为二元组计数与第一个单词计数之比：$p(w_2|w_1) = \text{count}(w_1 w_2) / \text{count}(w_1)$
（马尔可夫假设）：一个句子（一个单词序列）的概率可以通过链式法则计算：$p(w_1 w_2 ... w_n) = p(w_1) p(w_2|w_1) p(w_3|w_1 w_2)... \approx p(w_1) p(w_2|w_1) p(w_3|w_2) ...$

然而，这似乎并没有定义一个适当的概率分布。例如，取一个语料库 $V = \text{&quot;foo bar baz&quot;}$。然后，取所有可能的二元组上定义的联合分布 $w_1 w_2$。根据我们的原则：
\begin{equation}
p(w_1 w_2) = p(w_1) p(w_2|w_1) = [\text{count}(w_1) / 3][\text{count}(w_1 w_2) / \text{count}(w_1)]
\end{equation&gt;
如果 $w_1 w_2$ 不在语料库中，则显然 $p(w_1 w_2) = 0$。因此，联合分布中唯一非零的条目是 $p(\text{foo bar}) = p(\text{bar baz}) = 1/3$。这些的总和是$2/3 \neq 1$，那么这种分配是否不合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/657932/ngram-model-is-improper</guid>
      <pubDate>Wed, 27 Nov 2024 13:18:18 GMT</pubDate>
    </item>
    <item>
      <title>理解基于启发式的异常值检测：对评分、加权和有效性的关注</title>
      <link>https://stats.stackexchange.com/questions/657911/understanding-heuristic-based-outlier-detection-concerns-about-scoring-weighti</link>
      <description><![CDATA[我正在尝试理解《计算机与安全》杂志上新发表的异常值检测算法背后的数学和方法论。该算法使用基于启发式的方法，将基于密度和距离的评分与经验权重相结合。
无监督异常值检测 (OD) 算法通常涉及：

异常值评分：分配“异常值分数”以污染率（例如 contamination=0.05）作为超参数来决定阈值。
基于几何的方法：使用降维技术（例如 PCA、LDA）来投影数据，以便更好地分离类别（例如 矩阵轮廓、矩阵分解）

在他们使用 核高度估计函数 (KHE) (!) 和一些数学不清楚的步骤后，我总结了 GitHub 问题，最终，新算法提出了一个评分公式（公式 #18）：
$$
E(O, W)=\sum_{i=1}^n\left(s_i \cdot s_{c i} \cdot \omega_i\right)^3
$$
其中 $s_i$、$s_{c i}$ 和 $\omega_i$ 是分数成分和权重。作者根据经验设定了权重$\omega_{density}=0.8$和$\omega_{distance}=0.2$（公式 15）。

我的问题：
评分和加权的数学有效性：

将异常值分数、置信度分数和权重组合起来是否有意义，如公式 18 所示？
组合分数的三次变换能否提高检测准确率，还是会引入不必要的偏差？

加权中的人为因素：

作者根据经验设定了权重（$\omega_{density}=0.8$ 和 $\omega_{distance}=0.2$）以提高准确性。但是，这种手动参数调整是否会破坏 OD 算法的无监督性质？

如果没有明确的统计或实验推理，如何证明这些权重的合理性？


权重的可解释性（$\omega_{density}$ &gt; $\omega_{distance}$）：

作者优先考虑基于密度的评分。在异常值检测中，密度比距离更重要，这是否有任何理论或实验依据？

这种权重不平衡是否会引起偏差，尤其是在偏离正态性的不平衡数据集中（例如非高斯分布）？



附加说明：

我在 pyod 存储库中提出了一个 GitHub 问题，总结了本文的方法和有待进一步讨论的问题。
所提出方法的影响是在论文的图 4 中进行了可视化，显示了不同评分组合下的结果。但是，尚不清楚这些结果是否适用于所呈现的数据集之外的结果。


参考文献：

Chris Kuo 的《异常检测手册》：讨论了无监督异常检测中的评分和污染率。
如何测试无监督学习方法进行异常检测？
]]></description>
      <guid>https://stats.stackexchange.com/questions/657911/understanding-heuristic-based-outlier-detection-concerns-about-scoring-weighti</guid>
      <pubDate>Wed, 27 Nov 2024 03:48:42 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在处理一个重复测量数据集，需要进行降维。在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法涉及以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 之间的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除非数字变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不均等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    <item>
      <title>正态性假设 - qqplot 解释</title>
      <link>https://stats.stackexchange.com/questions/657859/normality-assumption-qqplot-interpretation</link>
      <description><![CDATA[我目前正在从事一个涉及评估多个变量分布的项目，并且我正在使用 Q-Q 图作为分析的一部分。虽然我已经为这些变量生成了 Q-Q 图。确实，我已经研究了很长时间，但我仍然想在这里听取意见。这些变量的样本量接近 70，目的是在纵向分析的几个变量之间进行独立 t 检验。我可以提出，shapiro 和 ks-test 拒绝正态性假设。
如果您能指导我准确解释它们以评估正态性并识别任何偏离高斯分布的情况，我将不胜感激。这些生物标志物通常在尾部变得更重，但我不会进行变换。欢迎任何评论！
编辑：如您所见，我对变量进行了 3 次测量。正如我之前所说，我的主要计划是比较 2 样本测试（_v00 与 _v66 相比，以及 _v66 与 _v01 相比），但我专注于正态性假设。








]]></description>
      <guid>https://stats.stackexchange.com/questions/657859/normality-assumption-qqplot-interpretation</guid>
      <pubDate>Tue, 26 Nov 2024 10:45:29 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的回归中的 HAC（Newey-West）标准误差小于普通标准误差？</title>
      <link>https://stats.stackexchange.com/questions/657795/why-are-the-hac-newey-west-standard-errors-smaller-than-the-ordinary-standard</link>
      <description><![CDATA[我用时间序列进行回归分析，然后进行了 Breusch-Godfrey（BG）检验和 White 检验。检验结果表明，自相关和异方差同时存在。因此，我选择使用 HAC（Newey-West）标准误差进行分析。我惊讶地发现，HAC（Newey-West）标准误差比普通标准误差要小。为什么会这样？在这种情况下，我应该使用哪种标准误差？]]></description>
      <guid>https://stats.stackexchange.com/questions/657795/why-are-the-hac-newey-west-standard-errors-smaller-than-the-ordinary-standard</guid>
      <pubDate>Mon, 25 Nov 2024 10:09:08 GMT</pubDate>
    </item>
    <item>
      <title>没有真实标签的模型比较</title>
      <link>https://stats.stackexchange.com/questions/657699/model-intercomparison-with-no-ground-truth-labels</link>
      <description><![CDATA[领域是天气建模。我有 4 个不同的模型，其中一个是我的，而其他 3 个是独立模型，我认为这些模型相对熟练（即比随机模型好得多）。每个模型在 1000 个感兴趣的空间位置（我将它们称为节点）中的每一个上预测一个值。遗憾的是，每个节点的真实值是无法测量的，因此无法明确地说出哪个模型最好。
但是，我可以说我的模型的预测（模型 A）与其他模型的相关性比任何其他模型都更好：




A
B
C
D




A
1
0.636338
0.571829
0.569591


B
0.636338
1
0.251786
0.283723


C
0.571829
0.251786
1
0.299746


D
0.569591
0.283723
0.299746
1



模型 A 比其他任何模型都更善于预测模型 B，A 与 C 和 A 与 D 也是如此。由于每个模型的预测都是一些预测的组合“真实”信号和一些噪音/错误，我假设我更好的整体相关性意味着我的模型可能比任何其他模型捕获更多的“真实”信号和更少的噪音。
这是一个有效的结论吗？如果是这样，有没有办法量化它，或者我可以引用一个参考资料来支持这个说法？]]></description>
      <guid>https://stats.stackexchange.com/questions/657699/model-intercomparison-with-no-ground-truth-labels</guid>
      <pubDate>Fri, 22 Nov 2024 20:20:57 GMT</pubDate>
    </item>
    </channel>
</rss>