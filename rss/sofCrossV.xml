<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 Jan 2025 21:15:16 GMT</lastBuildDate>
    <item>
      <title>我可以使用稀疏分析来估计捕获样本方差所需的最小样本量吗</title>
      <link>https://stats.stackexchange.com/questions/660738/can-i-use-rarefaction-analysis-to-estimate-the-minimum-sample-size-needed-to-cap</link>
      <description><![CDATA[在生态学中，稀疏分析可用于估计发现种群中所有物种所需的最小样本量。我想知道这是否可用于估计捕获种群特定参数方差所需的最小样本量。
假设我有一个包含 100 个数据点的样本（假设这是种群）。要生成稀疏曲线，我可以将样本量从 1 增加到 100。在每个样本量 n 下，我可以从原始样本中随机生成 10000 个样本（大小 = n），并计算这 10000 个样本的平均方差。然后绘制平均方差与样本量的关系。我的问题是：似乎无论我有什么样的原始样本，覆盖 95% 种群方差所需的样本量总是相同的：大约 16 个样本。这对我来说似乎有点奇怪。
我的稀疏曲线代码：
sample_size = data.shape[0]

data_n_variance = [] #初始化列表以存储不同样本大小下该特定参数测量值的平均方差

#为 10000 次引导生成随机种子以实现可重复性
rng = np.random.RandomState(seed=42)
seed_list = rng.choice(10000, size=10000, replace=True)

for i in range(1, sample_size+1):
subsample_i_variance = [] #初始化列表以存储特定样本大小下 10000 个随机生成的子样本的方差

for j in range(10000):
rng = np.random.RandomState(seed=seed_list[j])
subsample = rng.choice(data, size=i, replace=False)
subsample_i_variance.append(np.var(subsample))

data_n_variance.append(sum(subsample_i_variance)/10000)

用于确定最小样本量的代码
for i in range(1, sample_size+1):
if data_n_variance[i] &gt; 0.95*data_n_variance[-1]:
print(i)
break

我尝试模拟两个不同的原始样本，最小样本量相同
正态分布：
data = np.random.normal(loc=100, scale=10, size=100)

双峰分布：
data1 = np.random.poisson(lam=1, size=60)
data2 = np.random.normal(loc=1000, scale=100, size=40)
data = np.concatenate((data1, data2))

我也尝试使用样本方差而不是总体方差（N-1 vs. N）来计算方差，但在这种情况下，稀疏曲线不再是增长曲线（先增加然后稳定）]]></description>
      <guid>https://stats.stackexchange.com/questions/660738/can-i-use-rarefaction-analysis-to-estimate-the-minimum-sample-size-needed-to-cap</guid>
      <pubDate>Wed, 29 Jan 2025 20:47:42 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归中，拟合残差与回归量正交</title>
      <link>https://stats.stackexchange.com/questions/660737/in-linear-regression-are-fitted-residuals-orthogonal-to-regressors</link>
      <description><![CDATA[我正在研究伍尔德里奇的《计量经济学分析》中的回归问题。回归量被视为随机的。他说，最小二乘估计一致性的一个基本假设是“总体正交性条件”（“假设 OLS.1”），即
$$
E(x&#39;u)=0。
$$
此处的线性模型为$y = \beta&#39;x + u$，其中$u$是误差项的符号，prime 表示矩阵转置。
我的问题是，在此模型下，通过最小二乘估计获得的拟合残差$\hat u$是否与回归量$x$不相关，即$E(x&#39;\hat u)=0$。]]></description>
      <guid>https://stats.stackexchange.com/questions/660737/in-linear-regression-are-fitted-residuals-orthogonal-to-regressors</guid>
      <pubDate>Wed, 29 Jan 2025 20:13:21 GMT</pubDate>
    </item>
    <item>
      <title>根据列联表计算两种评级方法之间的差异度量</title>
      <link>https://stats.stackexchange.com/questions/660736/compute-a-measure-of-difference-between-two-rating-methods-from-contingency-tabl</link>
      <description><![CDATA[四位评分员 A、B、C、D 将 10 条记录分为 3 类 a、b、c；请参阅下面代码中的 tb1。
这与 Gwet, K. L. (2014) 中的表 2.26 类似。评分员间信度手册：衡量评分员之间一致性程度的权威指南（第 4 版）。马里兰州盖瑟斯堡：高级分析。
它给出 Fleiss&#39; kappa=0.47。
在第二个但独立的评分程序中，盲测的相同评分员生成 tb2，其中 a 和 b 被交换。正如预期的那样，它给出了相同的 kappa，即使除了未交换的 c 之外评级不同。
当我使用 Kwet 的 t 检验时，这两个被认为是相等的，因为 kappa 的值是。这不是我想要的，因为 tb2 不同。
如何计算来自两个原始表的两种方法之间的这种成对比较的差异度量？
library(irrCAC)
if (!exists(&quot;ttest.fleiss&quot;))
source(&quot;https://www.agreestat.com/software/r/new/paired.ttest.r&quot;)

tb1 = structure(
list(
record = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
A = c(&quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;),
B = c(&quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;c&quot;, &quot;c&quot;, &quot;c&quot;),
C = c(&quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;c&quot;, &quot;c&quot;),
D = c(&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;)
),
class = c(&quot;tbl_df&quot;, &quot;tbl&quot;, &quot;data.frame&quot;),
row.names = c(NA, -10L)
)

print(tb1)
#&gt; 记录 A B C D
#&gt; 1 1 b b b a
#&gt; 2 2 b b b b
#&gt; 3 3 b b b b
#&gt; 4 4 b b a b
#&gt; 5 5 b b b c
#&gt; 6 6 a b a a
#&gt; 7 7 a a a a
#&gt; 8 8 c c a b
#&gt; 9 9 c c c b
#&gt; 10 10 c c c c

tb2 = 结构（
列表（
记录 = c（1、2、3、4、5、6、7、8、9、10），
A = c（“a”，“a”，“a”，“a”，“a”，“a”，“b”，“b”，“c”，“c”，“c”，“c”），
B = c（“a”，“a”，“a”，“a”，“a”，“a”，“a”，“a”，“b”，“c”，“c”，“c”），
C = c（“a”， &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;),
D = c(&quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;c&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;c&quot;)
),
class = c(&quot;tbl_df&quot;, &quot;tbl&quot;, &quot;data.frame&quot;),
row.names = c(NA, -10L)
)

# 不含 &quot;record&quot;列

cat(&quot;____\nTable 1\n&quot;)
#&gt; ____
#&gt; 表 1
fleiss.kappa.raw(tb1[,-1])$est[-8]
#&gt; coeff.name pa pe coeff.val coeff.se conf.int p.value
#&gt; 1 Fleiss&#39; Kappa 0.6666667 0.375 0.46667 0.15881 (0.107,0.826) 0.0165266

cat(&quot;____\nTable 2\n&quot;)
#&gt; ____
#&gt; 表 2
fleiss.kappa.raw(tb2[,-1])$est[-8]
#&gt; coeff.name pa pe coeff.val coeff.se conf.int p.value
#&gt; 1 Fleiss&#39; Kappa 0.6666667 0.375 0.46667 0.15881 (0.107,0.826) 0.0165266

ttest.fleiss(tb1[,-1], tb2[,-1])
#&gt; 配对 T 检验用于检验 2 个 Fleiss 一致性系数之间的差异
#&gt; --------------------------------------------------------------------------------
#&gt; Fleiss Kappa 系数：（组 1：0.4666667）--（组 2：0.4666667）
#&gt; 差异的标准误差：0
#&gt;测试统计量：T= NaN 
#&gt; P 值：NaN

我注意到这类似于
比较不同类别的评分者之间的评分者间一致性
主要区别在于原始帖子提到了“专家”和“非专家”，但我有一个完全配对的设计，在两种情况下都是相同的评分者。]]></description>
      <guid>https://stats.stackexchange.com/questions/660736/compute-a-measure-of-difference-between-two-rating-methods-from-contingency-tabl</guid>
      <pubDate>Wed, 29 Jan 2025 18:27:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么当发现因素很重要时，比较字母没有差异？</title>
      <link>https://stats.stackexchange.com/questions/660735/why-comparison-letters-do-not-differ-when-factor-was-found-significant</link>
      <description><![CDATA[我使用&quot;lmer&quot;在 r 中运行了一系列包含两个因素的模型函数，还测试了因子相互作用。
例如：
model &lt;- lmer(parameter ~ factor1*factor2 + (1|ID_repeated), data=db)
summary(model)
joint_tests(model)
AIC(model)
shapiro.test(resid(model))

然后，我对重要因子（或当重要时对它们的相互作用）进行了成对比较测试，以查看该因子的哪些情况不同。
mcp&lt;-emmeans(model,~factor, method=&quot;tukey&quot;,adjustment=&quot;bonferroni&quot;)
cld(mcp, Letters=&quot;ABCDE&quot;, reversed=TRUE, sort=FALSE)

在两种情况下，mcp&lt;-emmeans 没有显示不同的字母，即使那些根据模型结果，因子是显著的。
例如，在以下情况下，交互作用是显著的，但这并未从我运行比较时得到的字母中显现出来。

模型术语 df1 df2 F.ratio p.value
因子1 1 18 0.574 0.4584
因子2 4 72 57.563 &lt;.0001
因子1：因子2 4 72 2.825 0.0309

因子1因子2 emmean SE df lower.CL upper.CL .group
A 2000 0.582 0.154 72.7 0.275 0.890 b 
B 2000 0.670 0.154 72.7 0.362 0.977 b 
A 2005 0.622 0.154 72.7 0.314 0.929 b 
B 2005 0.437 0.154 72.7 0.129 0.744 b 
A 2010 0.616 0.154 72.7 0.309 0.924 b 
B 2010 0.534 0.154 72.7 0.227 0.842 b 
A 2015 0.966 0.154 72.7 0.659 1.273 b 
B 2015 1.026 0.154 72.7 0.719 1.334 b 
A 2020 1.917 0.154 72.7 1.610 2.224 a 
B 2020 2.556 0.154 72.7 2.249 2.863 a 

你能帮我理解为什么会发生这种情况以及我做错了什么吗？
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/660735/why-comparison-letters-do-not-differ-when-factor-was-found-significant</guid>
      <pubDate>Wed, 29 Jan 2025 18:16:14 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM 交叉验证</title>
      <link>https://stats.stackexchange.com/questions/660732/lightgbm-crossvalidation</link>
      <description><![CDATA[我正在调整 LightGBM 模型以进行一些时间序列预测，我正在使用交叉验证。我有很多不同的特征（日期特征、滞后、超前等）想要尝试。同时，我还需要弄清楚要使用哪些超参数。我尝试了一些，得到了一些不错的结果，但我的执行过程似乎不是最佳的。
如果我从尝试一些特征开始，如果我没有一些合适的超参数，我将无法真正知道它们是否有效。反过来说，如果我使用了错误的特征，似乎也很难确定我拥有正确的超参数集。那么该怎么办？
我是否找到一组有限的特征并尝试基于这些特征找到一些好的超参数？我应该调整哪些超参数，以及调整到什么深度？]]></description>
      <guid>https://stats.stackexchange.com/questions/660732/lightgbm-crossvalidation</guid>
      <pubDate>Wed, 29 Jan 2025 18:06:35 GMT</pubDate>
    </item>
    <item>
      <title>当响应变量是派生值时处理模型假设</title>
      <link>https://stats.stackexchange.com/questions/660731/dealing-with-model-assumptions-when-your-response-variable-is-a-derived-value</link>
      <description><![CDATA[首先我要说的是，在使用线性模型方面，我是个新手。
我正在处理的运动数据如下所示：



id
location
treatment
size
totaldist
dailydist
firstdaydist
Days跟踪




1
site1
soft
1.2
75
4.2
5
18


2
site1
sof t
1.3
50
2.7
2
18


3
site1
困难
1.1
200
11.1
25
18


4
site2
软
0.6
0
0
0
15


5
site2
硬
0.2
500
27.8
100
18


6
site2
soft
0.7
20
1.3
1
15



其中我为每个动物 id 计算了平均距离值（totaldist、dailydist、firstdaydist）。这些距离值基于未在此处包括的单个观测值（GPS 点）的计算。
我已设置了一系列线性模型（例如 fit &lt;- lm(totaldist ~ treatment+location+size+Days tracked, data=df) 来检查这些预测因子对距离值的影响。在此过程中，我注意到我的一些模型不能很好地满足线性模型的假设，但对这些数据进行转换感觉很奇怪，因为它是派生数据，而不是“原始”（原始观测）数据。
我的问题：如果这种格式合适，是否有办法对这些数据进行线性模型处理，或者我需要重新考虑我的数据格式？我更感兴趣的是了解因素（treatment、location、size、Days tracked）如何影响这些派生/汇总值（totaldist 等）比我更了解单个观测值之间距离的原始数据。
如果有讨论这种情况的资源，请告诉我。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660731/dealing-with-model-assumptions-when-your-response-variable-is-a-derived-value</guid>
      <pubDate>Wed, 29 Jan 2025 18:03:17 GMT</pubDate>
    </item>
    <item>
      <title>如何使用表示定理（不直接调用 KKT）证明核 SVM 解是稀疏的？</title>
      <link>https://stats.stackexchange.com/questions/660730/how-to-show-kernel-svm-solutions-are-sparse-using-the-representer-theorem-witho</link>
      <description><![CDATA[在软边缘 SVM 的核化形式中，目标是
$$
\min_{\alpha \in \mathbb{R}^n} \biggl[
\tfrac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i\,\alpha_j\,k(x_i, x_j)
\;+\;
C \sum_{i=1}^n \max\bigl(0,\,1 - y_i\,f_\alpha(x_i)\bigr)
\biggr],
$$
其中
$$
f_\alpha(x) \;=\; \sum_{j=1}^n \alpha_j\,k(x_j, x)。
$$
根据表示定理，最优解 $f^*$ 也具有这种形式。通常，从原始对偶分析中，我们知道 $y_i f^*(x_i) &gt; 1$ 时 $\alpha_i = 0$（即，对于严格位于边界之外的点）。
我的问题：我们能否在此展示这种稀疏性，即 $\alpha_i = 0$，而不是明确依赖 KKT 条件？]]></description>
      <guid>https://stats.stackexchange.com/questions/660730/how-to-show-kernel-svm-solutions-are-sparse-using-the-representer-theorem-witho</guid>
      <pubDate>Wed, 29 Jan 2025 17:12:42 GMT</pubDate>
    </item>
    <item>
      <title>去趋势时间序列：感兴趣的空间变量是否应包括在去趋势步骤中？</title>
      <link>https://stats.stackexchange.com/questions/660728/detrending-a-time-series-should-spatial-variables-of-interest-be-included-in-th</link>
      <description><![CDATA[我对时间序列数据还不熟悉，对时间序列去趋势化感兴趣，然后用去趋势化的数据进行多元线性回归，但我对时间序列的位置部分（纬度）有点迷茫。简而言之，包含在“去趋势化”数据中的变量是否可以包含在后续分析中？我很难理解这在统计上是否合理。
举例来说：我有季节性事件（一年中鸟类目击日）在时间（年份）和空间（纬度）上的观察数据，以及每个特定时间点（年份、月份、纬度）的平均温度数据。我感兴趣的是，随着这些不同地点的季节性温度变化，鸟类观测次数可能会增加或减少（那么，在春季或夏季气温升高的情况下，我们在北纬地区看到的鸟类是否比南纬地区多？）。
在查看了数据的年度趋势并阅读了时间序列数据后，似乎最直接的方法是：

首先使用回归对我的观测和温度数据进行去趋势处理（观察：观测日期 ~ 年份和温度数据：温度 ~ 年份）
然后使用残差作为回归中的数据来评估我的问题（去趋势的观测日期 ~ 去趋势的春季温度 + 去趋势的夏季温度 + 纬度 + 所有 2 向和 3 向交互作用）

但是，由于这些模式可能会在空间上发生变化，我现在想知道初始去趋势步骤是否也需要纬度（观察：观测日期 ~ 年份+ 纬度 + 年份 x 纬度和温度数据：温度 ~ 年份 + 纬度 + 年份 x 纬度）。
如果是这种情况，1）从统计角度来看，我是否仍可以在主模型中包含纬度，因为它是一个感兴趣的变量？如果是……2）如果我们在去趋势步骤中控制纬度的变化，纬度是否仍可以解释为主模型中的空间/纬度差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/660728/detrending-a-time-series-should-spatial-variables-of-interest-be-included-in-th</guid>
      <pubDate>Wed, 29 Jan 2025 16:34:48 GMT</pubDate>
    </item>
    <item>
      <title>干预后测试群体的相似性 - 收敛还是方差？</title>
      <link>https://stats.stackexchange.com/questions/660725/testing-a-groups-similarity-after-an-intervention-convergence-or-variance</link>
      <description><![CDATA[我感兴趣的是测试一个群体在干预后是否变得更加相似。例如，假设我有一个连续变量干预前后的分数列表，该连续变量被合理地假设为正常。我感兴趣的是看看在经历这次干预后，这个群体是否变得更加相似。我不需要知道他们的平均值是否发生了变化，但我认为我需要了解的是他们的变异是如何变化的。（因此，如果我预期的结果已经实现，那么干预后该群体的方差就会减小，这表明该群体在结果变量上已经在某种程度上趋向于相似的分数）。
我最初的想法是 (1) 通过将参与者视为“评估者”并查看干预后的 ICC 是否比干预前更高来建立某种类间相关性。或者，(2) 方差分析来检验两组之间的差异。
与本论坛的许多人相比，我的统计知识相对有限 - 因此，如果您能提供任何链接或参考资料，以便我可以进一步阅读建议的方法，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660725/testing-a-groups-similarity-after-an-intervention-convergence-or-variance</guid>
      <pubDate>Wed, 29 Jan 2025 16:08:10 GMT</pubDate>
    </item>
    <item>
      <title>排序相关性的概括</title>
      <link>https://stats.stackexchange.com/questions/660724/generalization-of-ranking-correlation</link>
      <description><![CDATA[我有一个系统，它产生了 $n$ 个输出，并且两个注释者对它们进行了评判。每个注释者都生成了一个 $n$ 项的排序列表。我通过计算排序相关性（具体来说是 Spearmans $\rho$）来测量它们的相关性，它产生了一个值，比如 $x$（以及 p 值）。
我们能对 $x$ 的普遍性说些什么？如果系统生成 $p$ 个新输出，我可以说，如果注释者对这 $n+p$ 个项目进行了排名，那么排名相关性仍然会是 $\approx x$ 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660724/generalization-of-ranking-correlation</guid>
      <pubDate>Wed, 29 Jan 2025 16:06:22 GMT</pubDate>
    </item>
    <item>
      <title>模型复杂性导致收益递减的引文</title>
      <link>https://stats.stackexchange.com/questions/660719/citations-for-diminishing-returns-from-model-complexity</link>
      <description><![CDATA[显而易见，随着统计或机器学习模型的复杂度不断提高，您可以获得更好的性能（例如，在预测准确性方面），但每增加一个单位复杂度，性能的提升就会逐渐减弱。例如，在普通最小二乘法的背景下，采用没有交互项的模型并添加所有一阶交互项所获得的性能提升通常会大于添加所有二阶交互项所获得的性能提升，尽管前一种情况下添加的项数要少得多。
这一点与增加训练集大小带来的收益递减有关，但略有不同。同样，过度拟合的危险也是如此：即使您使用单独的测试集等正确评估模型，并添加防止过度拟合的措施（例如正则化），您仍然应该预期复杂性带来的收益递减。
您能推荐一些好的论文或教科书章节来引用这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660719/citations-for-diminishing-returns-from-model-complexity</guid>
      <pubDate>Wed, 29 Jan 2025 15:22:17 GMT</pubDate>
    </item>
    <item>
      <title>如何为 Cox-PH 模型选择概率分布？</title>
      <link>https://stats.stackexchange.com/questions/660718/how-to-select-a-probability-distribution-for-the-cox-ph-model</link>
      <description><![CDATA[我正在尝试学习如何从 Cox-PH 生存模型模拟生存时间。我写了 Cox-PH 模型、生存函数（来自 Cox-PH）和累积风险的公式（如何从 Cox-PH 回归中恢复生存函数？）：
$$ h(t|\mathbf{x}) = h_0(t)\exp(\mathbf{x}^T\boldsymbol{\beta}) $$
$$ S(t|\mathbf{x}) = [S_0(t)]^{\exp(\mathbf{x}^T\boldsymbol{\beta})} $$
$$ H(t|\mathbf{x}) = H_0(t)\exp(\mathbf{x}^T\boldsymbol{\beta}) $$
似乎我们需要利用以下关系（累积风险是否始终呈指数分布？）：
$$ H(T|\mathbf{x}) \sim \text{Exp}(1) $$
基于这些先决条件，以下是我对如何从拟合的Cox-PH：

生成一个随机指数：
$$ E \sim \text{Exp}(1) $$

求解方程中的 $T$：
$$ H_0(T)\exp(\mathbf{x}^T\boldsymbol{\beta}) = E $$
$$ T = H_0^{-1}(E\exp(-\mathbf{x}^T\boldsymbol{\beta})) $$


这就是我感到困惑的地方。似乎您仍然需要为基线风险选择分布？ （即用于反演）
下面我尝试通过写出指数分布和威布尔分布的风险来继续这一过程，并写出模拟生存时间的公式：
$$ h_0(t) = \lambda $$
$$ H_0(t) = \lambda t $$
$$ T = \frac{E}{\lambda\exp(\mathbf{x}^T\boldsymbol{\beta})} $$
$$ h_0(t) = \lambda\gamma t^{\gamma-1} $$
$$ H_0(t) = \lambda t^{\gamma} $$
$$ T = \left(\frac{E}{\lambda\exp(\mathbf{x}^T\boldsymbol{\beta})}\right)^{1/\gamma} $$
那么，我们应该根据什么来选择基线风险的概率分布？我认为这是半参数 Cox-PH 模型的全部优势，即不需要选择概率分布（例如在估计参数时）。但似乎如果我们想从 Cox-PH 模拟生存时间，仍然需要选择分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/660718/how-to-select-a-probability-distribution-for-the-cox-ph-model</guid>
      <pubDate>Wed, 29 Jan 2025 15:18:52 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 lavaan 中的 SEM 修改指数？</title>
      <link>https://stats.stackexchange.com/questions/660722/how-to-interpret-modification-indices-for-a-sem-in-lavaan</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660722/how-to-interpret-modification-indices-for-a-sem-in-lavaan</guid>
      <pubDate>Wed, 29 Jan 2025 15:17:23 GMT</pubDate>
    </item>
    <item>
      <title>r 面板数据 - 哪个标准误差 - Driscoll-Kraay，Beck-Katz，还是减少偏差的线性化估计量？</title>
      <link>https://stats.stackexchange.com/questions/660717/r-panel-data-which-standard-error-driscoll-kraay-beck-katz-or-bias-reduced</link>
      <description><![CDATA[使用面板数据（不平衡），我想知道应该对以下 plm 使用哪种标准误差来理解事件的影响（跨用户相同）：
m = plm(y ~ x + time + event + time:event, 
data=df, 
index=c(&quot;user_id&quot;, &quot;date&quot;),
model=&quot;within&quot;, 
effect = &quot;individual&quot;)

数据包括嵌套在 800 多个用户中的 ~400,000 个观察值，其中几个用户的观察值很少，而其他用户的观察值则很多。
为了解释异方差和自相关，不确定我们是否应该使用 Driscoll-Kraay 标准误差、Beck-Katz 或 CR2 偏差减少线性化估计器：
lmtest::coeftest(m, vcov = vcovSCC(m, type = &#39;HC1&#39;)) ##Driscoll-Kraay
lmtest::coeftest(m, vcov = vcovBK(m, type = &#39;HC1&#39;)) ##Beck-Katz
clubSandwich::coef_test(m, vcov = &quot;CR2&quot;, cluster = df$user_id) ##Bell &amp; McCaffrey (2002); Pustejovsky &amp; Tipton (2017) 

虽然幸运的是，感兴趣的变量的重要性对于假设检验来说并没有太大变化，但不确定哪一个最适合使用。
它们是否都解决了异方差性和自相关性问题，但只是在解决方式上有所不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/660717/r-panel-data-which-standard-error-driscoll-kraay-beck-katz-or-bias-reduced</guid>
      <pubDate>Wed, 29 Jan 2025 15:08:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 构建和预测每日功能曲线（电力供应）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660716/build-and-forecast-daily-functional-curves-electricity-supply-in-python</link>
      <description><![CDATA[我正在处理一个大型电力市场数据集（约 9700 万行），时间跨度从 2022 年 12 月 1 日到 2024 年 12 月 20 日。主要列如下：
[&#39;PURPOSE_CD&#39;, &#39;STATUS_CD&#39;, &#39;UNIT_REFERENCE_NO&#39;, &#39;INTERVAL_NO&#39;, &#39;BID_OFFER_DATE_DT&#39;, &#39;QUANTITY_NO&#39;, &#39;AWARDED_QUANTITY_NO&#39;, &#39;ENERGY_PRICE_NO&#39;, &#39;MERIT_ORDER_NO&#39;, &#39;PARTIAL_QTY_ACCEPTED_IN&#39;, &#39;ADJ_QUANTITY_NO&#39;, &#39;ZONE_CD&#39;, &#39;AWARDED_PRICE_NO&#39;, &#39;OPERATORE&#39;]

我已过滤掉 OPERATORE == 的行&quot;Bilateralista&quot;（这些对应于不通过市场的双边合同，因此它们具有“虚假”或未知的价格）。我还只保留 PURPOSE_CD == &quot;OFF&quot;（官方报价）的行。我已将日期字段 BID_OFFER_DATE_DT 转换为适当的日期时间（格式 &#39;%Y%m%d&#39;）。
接下来，对于每个日期和每个小时（由 INTERVAL_NO 给出），我按 ENERGY_PRICE_NO 对数据进行分组并求和 QUANTITY_NO。然后我按价格排序并计算累计数量以构建供应曲线的“阶梯”版本。由于我需要更平滑的表示，我应用样条/核平滑将这些阶跃函数转换为连续、非递减曲线$S(p)$。因此，本质上，对于每一天和每小时，我最终得到一个一维函数$S_t(p)$，其中$t$表示时间（天 + 小时），$p$表示价格轴。
我的目标：

以时间序列的方式预测这些剩余供应曲线（平滑函数）。
理想情况下，我希望实现函数自回归模型（如 FAR(1) 或类似模型）或广义加性模型 (GAM) 方法，将每条每日/每小时曲线视为函数时间序列中的观测值。我很好奇是否有现有的 Python 库或工作流程可以更直接地处理：

函数自回归模型，或
函数 GAM（其中每个函数都是响应），或
推荐使用 Python 进行函数时间序列预测的“最佳实践”方法。



问题：

鉴于我已经为每个时间点建立了平滑的、非递减的供应曲线，哪种建模方法（函数自回归、函数数据的 GAM 或其他方法）最适合将这些曲线预测为时间序列？
是否有任何 Python 库或生态系统（类似于 R 中的 FDA 包）提供现成的函数时间序列建模方法（例如 FAR(1)、FPCA 等）？
如果不，您是否建议在曲线上实施 PCA 以降低维数，然后在主成分上使用标准时间序列模型（ARIMA、VAR 甚至神经网络）？
在现实世界中，像这样的高频数据集中构建功能预测时，我应该记住哪些实际考虑因素（例如，训练/测试拆分、性能指标、处理缺失的小时/日期）？

谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660716/build-and-forecast-daily-functional-curves-electricity-supply-in-python</guid>
      <pubDate>Wed, 29 Jan 2025 14:51:20 GMT</pubDate>
    </item>
    </channel>
</rss>