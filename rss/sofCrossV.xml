<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 20 Jan 2024 01:01:13 GMT</lastBuildDate>
    <item>
      <title>我使用的假设检验是什么，或者我应该更改什么以适应“常见”假设检验？</title>
      <link>https://stats.stackexchange.com/questions/637282/what-is-the-hypothesis-test-ive-used-or-what-should-i-change-to-fit-a-common</link>
      <description><![CDATA[我与几位教授进行了讨论，并在互联网（和chatgpt）上进行了搜索，试图改进我所使用的方法的描述，或者寻找更好的方法。我希望更广泛的受众能够提供一些建议。
我正在尝试比较两种分类方法的性能。我的观点是，当中值性能指标的 95% CI 重叠时，这些方法在性能上是等效的。
存在一些挑战，包括使 Mann–Whitney U 检验等标准方法无法实现的挑战：

没有基本事实，因此分类指标是 Cohen 的 kappa。
对于当前技术（样本 A），只有少数（小型）研究计算了记录中的 kappa，更糟糕的是，访问该数据是被禁止的。这意味着我只有当前技术的摘要统计数据。
对于我的技术，我确实为每个记录提供了一个 kappa 值，因此我可以对此样本（样本 B）进行任意数量的测试。但对于每个记录，我只能计算一个 kappa 值（因为每个记录仅由一个人分类）。

鉴于限制，我做了以下操作：

对于样本 A，我有中值以及第一和第三四分位数 kappa，并通过假设正态性并使用已知的 IQR 和样本大小计算了 95% 置信区间。
对于样本 B，我有每个记录的 kappa 值，因此我执行引导来获取中值和 95% CI。
通过这些，我发现样本 A 和样本 B 的 95% CI 重叠，因此我无法拒绝 H0。

与我交谈过的教授们认为，这项技术虽然富有创意，但还是可以接受的。我担心的是，由于限制，我使用的技术似乎没有一个简单的名称。]]></description>
      <guid>https://stats.stackexchange.com/questions/637282/what-is-the-hypothesis-test-ive-used-or-what-should-i-change-to-fit-a-common</guid>
      <pubDate>Fri, 19 Jan 2024 23:56:04 GMT</pubDate>
    </item>
    <item>
      <title>49 名工程师的平均工资为 3200 美元。样本方差为 144。在 20% 显着性水平下构建平均工资的置信区间 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/637281/the-mean-salary-for-49-engineers-is-3200-usd-the-sample-variance-is-144-constr</link>
      <description><![CDATA[
49 名工程师的平均工资为 3200 美元。样本方差为 144。构建平均工资在 20% 显着性水平下的置信区间。

2）从 10000 名学生中随机选择 101 名学生进行身高分析。所选学生的平均身高为170厘米，标准差为12厘米。构建学生平均身高的 90% 置信区间。
3）1982-2020年平均利率为10.5%。样本标准方差为 5%。利率呈正态分布。构建下一年利率的 90% 置信区间。
4) 公司的样本回报率为 10%，25 个月的样本的标准方差为 144。求显着性水平为 10% 的置信区间]]></description>
      <guid>https://stats.stackexchange.com/questions/637281/the-mean-salary-for-49-engineers-is-3200-usd-the-sample-variance-is-144-constr</guid>
      <pubDate>Fri, 19 Jan 2024 23:35:59 GMT</pubDate>
    </item>
    <item>
      <title>对于离散 $X_n$，如果 $X_n \stackrel{d}{\to} U$，则 $P_e \to 1$，其中 $P_e$ 是最佳贝叶斯误差，$U$ 是均匀的</title>
      <link>https://stats.stackexchange.com/questions/637279/for-discrete-x-n-if-x-n-stackreld-to-u-does-p-e-to-1-where-p-e-is</link>
      <description><![CDATA[考虑以下设置。令 $ \{X_n\}_{n=1}^\infty \subseteq [-1,1] $ 为离散随机数收敛为分布中的连续均匀随机变量的变量。
令 $Y_n = X_n +Z_n$ 其中 $Z_n$ 是独立于 $X_n$。
因为 $X_n$ 是离散的，所以来自观察 $X_n$ 的最大后验估计量-container&quot;&gt;$Y_n$ 由下式给出
\begin{align}
\widehat{X}_n = \arg \max_{x} p_{X_n|Y_n}(x|Y_n)
\end{对齐}
其中 $p_{X_n|Y_n}$ 是条件 pmf。错误概率定义为
\begin{align}
P_{n}^{(e)}= \mathbb{P} [\widehat{X}_n \neq X_n]
\end{对齐}
我的问题：我们能否证明 $\lim_{n \to \infty} P_{n}^{(e)} = 1$ ？
对于上限，我们可以使用次优估计器随机选择 $X_n$ 的支撑点之一，这意味着
\begin{align}
P_e \le 1 - \max_{x} p_{X_n}(x)
\end{对齐}
显然，上限收敛于 $1$。我想不出一个好的下限。]]></description>
      <guid>https://stats.stackexchange.com/questions/637279/for-discrete-x-n-if-x-n-stackreld-to-u-does-p-e-to-1-where-p-e-is</guid>
      <pubDate>Fri, 19 Jan 2024 23:17:01 GMT</pubDate>
    </item>
    <item>
      <title>输入和准备数据[关闭]</title>
      <link>https://stats.stackexchange.com/questions/637275/entering-and-preparing-data</link>
      <description><![CDATA[我不断收到一条错误，内容如下：“性别”中包含意外的字符串：“F”“M”。我目前正在参加一门使用 R 的课程，但我以前从未使用过这个软件，我非常困惑。
]]></description>
      <guid>https://stats.stackexchange.com/questions/637275/entering-and-preparing-data</guid>
      <pubDate>Fri, 19 Jan 2024 22:29:29 GMT</pubDate>
    </item>
    <item>
      <title>我可以假设这是一个 GMM 吗？</title>
      <link>https://stats.stackexchange.com/questions/637274/can-i-assume-that-this-is-a-gmm</link>
      <description><![CDATA[我正在尝试找到以下分布的参数的 MLE：
$$f(x) = a \ \mathcal{N}(\mu_a, 1) + \beta \ \mathcal{N}(\mu_\beta, 1) $$
取对数可能性会使事情变得有点复杂。我知道这是混合高斯的一个常见问题，通常通过将 $a, b$ 视为潜在变量并应用 EM 算法来处理。这允许日志输入总和，因为样本将属于第一个或第二个分布，从而取消另一个项。
就上下文而言，这就是我正在讨论的要点：
$$\log \mathcal{L}(\mu_a, \mu_b ; x) = \sum\limits_{i=1}^{i=N} \log \左(a\frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}(x_i-\mu_a)^2} + b\frac{1}{\sqrt{2 \pi}} e^{-\frac{1}{2}(x_i-\mu_b)^2} \right) $$
但是，这样做有效吗？如果分布以高斯分布的线性组合形式给出，那么可以公平地说每个样本都来自两个高斯分布之一吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/637274/can-i-assume-that-this-is-a-gmm</guid>
      <pubDate>Fri, 19 Jan 2024 21:43:22 GMT</pubDate>
    </item>
    <item>
      <title>PR曲线什么时候比ROC曲线更能提供信息？</title>
      <link>https://stats.stackexchange.com/questions/637273/when-is-pr-curve-more-informative-than-roc-curve</link>
      <description><![CDATA[我正在阅读论文A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks  第 2 节讨论了 AUROC 与 AUPR 的特性。文中的一些结论让我感到困惑，希望得到澄清
&lt;块引用&gt;
因此，随机正例检测器对应于 50% AUROC，而“完美”分类器对应于 100%。
AUROC 回避了阈值选择的问题，精确率-召回率曲线下面积 (AUPR) 也回避了这一问题，有时它被认为提供了更多信息（Manning &amp; Schütze，1999）。这是因为当正类别和负类别的基本费率差异很大时，AUROC 并不理想，并且 AUROC 会针对这些不同的正和负基本费率进行调整。因此，AUPR 是我们的第二个评估指标。

因此，在 ROC 中，随机检测器对应于对角线，完美的分类器具有 100% 的面积。
对于 PR，基线取决于真实类别的概率。例如，如果 P(T = 0.9)，则不熟练的预测器的面积已经达到 90%。
那么为什么作者得出这样的结论：公关有时能提供更多信息？ 
我认为最让我困惑的段落是
&lt;块引用&gt;
这是因为当正类和负类的基本费率差异很大时，AUROC 并不理想，并且 AUPR 会针对这些不同的正类和负类基本费率进行调整。

据维基百科所述（https://en.wikipedia.org/wiki/Base_rate)，基本率基本上是一个类别的概率。难道是我理解错了？]]></description>
      <guid>https://stats.stackexchange.com/questions/637273/when-is-pr-curve-more-informative-than-roc-curve</guid>
      <pubDate>Fri, 19 Jan 2024 21:34:39 GMT</pubDate>
    </item>
    <item>
      <title>执行参数估计的数据数量</title>
      <link>https://stats.stackexchange.com/questions/637269/number-of-data-to-perform-parameter-estimation</link>
      <description><![CDATA[我发现了一篇相当旧的帖子（对于给定的估计技术和参数，样本应该有多大？）关于通过线性回归技术执行参数估计时所需数据数量的粗略估计。我遵循了那篇文章中提到的来源，但提到的来源似乎没有引用所写的每个参数建议 20 个数据。我希望有人能够指出一个来源，更深入地讨论在通过线性回归技术进行参数估计时通常需要/建议多少数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/637269/number-of-data-to-perform-parameter-estimation</guid>
      <pubDate>Fri, 19 Jan 2024 20:45:07 GMT</pubDate>
    </item>
    <item>
      <title>组套索优化</title>
      <link>https://stats.stackexchange.com/questions/637268/group-lasso-optimization</link>
      <description><![CDATA[我读到，对于群套索，为了求解零次梯度方程，一种方法是保持所有块向量固定，表示为 $\{\hat\theta_k, k \ ne j\}$，然后求解 $ \hat \theta_j$。此过程对应于在组套索目标函数上采用块坐标下降。考虑到问题的凸性和块可分离的惩罚，保证收敛到最优解（Tseng 1993）。当所有 $\{\hat\theta_k, k \ne j\}$ 保持不变时，方程变为：
\begin{方程}
-\mathrm{\it{Z}}_{j}^{T}(r_{j}-\mathrm{\it{Z}}_{j}\widehat{\theta}_{j})+\ lambda\widehat{s}_{j}=0,
\end{方程}
根据次梯度 $\hat s_j$ 所满足的条件，即欧氏范数的次梯度，我们必须有 $\hat \theta = 0$ 如果$||Z_j^Tr_j||_2 $||Z_j^Tr_j||_2 &lt; \lambda$，否则最小化器 $\hat \theta_j$ 必须满足：
\begin{方程}
\widehat{\theta}_{j}=\left(\mathbf{Z}_{j}^{T}\mathbf{Z}_{j}+{\frac{\lambda}{||\widehat{ \theta}_{j}||_{2}}} I \right)^{-1}\mathbf{Z}_{j}^{T}r_{j}。
\end{方程}
需要注意的是，上述方程缺少 $\hat \theta_j$ 的封闭式解，除非 $ Z_j$ 是正交的。在这种特殊情况下，我们有简单的更新：
\begin{方程}
\widehat{\theta}_{j}=({1-\frac{\lambda}{||Z_j^Tr_j||_2})_{+} Z_j^Tr_j}
\end{方程}
其中 $(t)_+ := max\{0,t\}$ 是函数的正部分。
我不明白最后这个公式是从哪里来的。当我们具有正交性时会发生什么？我们如何定义方程 3？]]></description>
      <guid>https://stats.stackexchange.com/questions/637268/group-lasso-optimization</guid>
      <pubDate>Fri, 19 Jan 2024 20:35:51 GMT</pubDate>
    </item>
    <item>
      <title>基于多重线性回归模型输出和蒙特卡罗模拟的先验 BPN</title>
      <link>https://stats.stackexchange.com/questions/637267/prior-bpn-based-on-multi-linear-regression-model-output-and-monte-carlo-simulati</link>
      <description><![CDATA[在道路事故预测：贝叶斯分层方法中的第286页&lt; /a&gt; 纸。
本文描述了贝叶斯置信网络 (BPN) 的构建和参数学习，特别关注创建先验 BPN 并将其更新为后验 BPN 所涉及的步骤：

之前的 BPN 构建：
先前的 BPN 最初是使用回归分析的结果构建的。
应用Genie 2.0的推理引擎构建网络并计算边际概率分布函数。
利用回归系数的估计分布和误差项的协方差矩阵进行蒙特卡罗模拟，建立响应变量Y的预测概率密度函数，将其离散为48个状态，然后填充条件概率表之前的 BPN。
模拟还用于将结果推断到没有观察到的区域。

后 BPN 更新：
EM算法将先验BPN更新为后验BPN。
使用开发数据集中的信息将风险指示变量和响应变量的观察结果记录在列联表中。
参数学习使用贝叶斯推理和 EM 算法，其经验因素几乎不赋予先验信息任何权重。
仅更新开发数据集中具有可用信息的先前 BPN 的域。


&lt;小时/&gt;
我的问题：
我们最初是否使用蒙特卡洛模拟来填充“概率”？在条件概率表 (CPT) 中并建立先验 BPN（即，在生成的 Y 响应变量的分布下查找 X 值的所有组合的频率通过蒙特卡洛模拟），然后使用数据集作为证据来更新和学习进一步的参数和概率，从而得到后验 BPN？
或者
我们是否从头开始使用数据集来用概率填充 CPT，并通过从蒙特卡罗模拟生成的 Y 分布下从头开始查找数据集中出现的频率来学习参数和概率（即，找到X值组合的频率，从而找到模拟Y下的条件概率，以填充初始CPT“概率”和单元格）？
非常感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/637267/prior-bpn-based-on-multi-linear-regression-model-output-and-monte-carlo-simulati</guid>
      <pubDate>Fri, 19 Jan 2024 20:15:01 GMT</pubDate>
    </item>
    <item>
      <title>如何比较多类输出是否不同？</title>
      <link>https://stats.stackexchange.com/questions/637266/how-to-compare-if-multi-class-outputs-are-different</link>
      <description><![CDATA[我正在测试不同的多类（16 类）分类模型（ANN、DNN、DL 等），总体准确度从 0.75 到 0.92 不等。尽管 0.92 大于 0.75，有没有办法对输出进行统计比较？我不知道关联表是否可行，因为我也想将输出与原始标签进行比较。例如，在以下示例中：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

观测值
预测 1
预测 2


&lt;正文&gt;

A
A 
C


B
B 
B


A
A 
C


B
B 
B


B
B 
B


C
C 
C


B
C 
C


C
C 
A




如果预测1与观察值不同，或者预测2与观察值不同，我该如何确定&gt; 或预测1？为此目的合适的统计测试是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/637266/how-to-compare-if-multi-class-outputs-are-different</guid>
      <pubDate>Fri, 19 Jan 2024 19:47:31 GMT</pubDate>
    </item>
    <item>
      <title>存在多个相同预测时基尼系数/准确率与 roc_auc_score 之间的关系</title>
      <link>https://stats.stackexchange.com/questions/637264/relation-between-gini-coefficient-accuracy-ratio-and-roc-auc-score-when-there-ar</link>
      <description><![CDATA[我最近一直在研究与各种估计器相关的排名指标，并发现了一个与基尼系数相关的奇怪现象，我想更好地理解它。
我将从一些 Python 片段开始来说明背景和现象。假设有一组预测和一组与二元分类器相关的目标
（我将在这里生成垃圾数据，因为我的问题纯粹与指标相关）：
随机导入
target=[random.randint(0,1) for _ in range(0,100)]
pred=[random.uniform(0,1) for _ in range(0,100)]

使用下面的实现（取自https:// www.kaggle.com/code/batzner/gini-coefficient-an-intuitive-explanation)
def 基尼系数（实际、预测、cmpcol = 0、sortcol = 1）：
    断言( len(实际) == len(预测) )
    all = np.asarray(np.c_[实际, pred, np.arange(len(实际)) ], dtype=np.float)
    全部 = 全部[ np.lexsort((全部[:,2], -1*全部[:,1])) ]
    总损失 = all[:,0].sum()
    giniSum = all[:,0].cumsum().sum() / 总损失
    
    基尼和 -= (len(实际) + 1) / 2。
    返回基尼和 / 长度（实际）
 
def gini_normalized(a, p):
    返回基尼系数(a, p) / 基尼系数(a, a)

我们很容易验证经典结果
从 sklearn.metrics 导入 roc_auc_score
&gt;&gt;&gt;&gt;&gt; roc_auc_score(目标,预测)*2-1
0.1347402597402596
&gt;&gt;&gt;&gt;&gt; gini_normalized(目标,预测值)
0.13474025974025977

这符合已知的理论。然而，当我们的大量预测是相同的 - 但对应于不同的目标时 - 似乎我们不再具有上述对应关系。相反，roc_auc_score 似乎等于所有可能排列 pred 和 target 的方式的归一化基尼系数的平均值，这样 pred 将通过我们的排列按升序排序。让我用几个例子来说明
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt;基尼标准化([0,0,1],[0.1,0.9,0.9])
0.0
&gt;&gt;&gt;&gt;&gt;基尼标准化([0,1,0],[0.1,0.9,0.9])
1.0
&gt;&gt;&gt;&gt;&gt; roc_auc_score([0,1,0],[0.1,0.9,0.9])*2-1
0.5

&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt; gini_normalized([0,1,0,1,0,0],[0.5,0.7,0.1,0.9,0.9,0.9])
0.5
&gt;&gt;&gt;&gt;&gt; gini_normalized([0,1,0,0,1,0],[0.5,0.7,0.1,0.9,0.9,0.9])
0.25
&gt;&gt;&gt;&gt;&gt; gini_normalized([0,1,0,0,0,1],[0.5,0.7,0.1,0.9,0.9,0.9])
0.0
&gt;&gt;&gt;&gt;&gt; roc_auc_score([0,1,0,0,1,0],[0.5,0.7,0.1,0.9,0.9,0.9])*2-1
0.25
&gt;&gt;&gt;&gt;&gt; roc_auc_score([0,1,0,1,0,0],[0.5,0.7,0.1,0.9,0.9,0.9])*2-1
0.25
&gt;&gt;&gt;&gt;&gt; roc_auc_score([0,1,0,0,0,1],[0.5,0.7,0.1,0.9,0.9,0.9])*2-1
0.25

根据这些观察，我非常有兴趣听到与以下问题相关的任何答案/想法：

我的假设正确吗？也就是说，一般情况下，roc_auc_score 等于我们对 pred 排序方式进行平均的基尼系数平均值吗？
如果这是正确的，那么在这种情况下我们如何定义基尼系数？我们使用哪种排序方式，或者基尼系数实际上定义为平均值？
同样，我很想知道在有多种可能的排序方式的情况下我们如何定义累积准确率曲线和准确率（准确率似乎只是基尼系数的另一种定义）。&lt; /里&gt;
有人知道上述关系的参考资料（或者更好的是推导） - 如果事实证明是正确的吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/637264/relation-between-gini-coefficient-accuracy-ratio-and-roc-auc-score-when-there-ar</guid>
      <pubDate>Fri, 19 Jan 2024 18:57:45 GMT</pubDate>
    </item>
    <item>
      <title>如果主效应模型没有显着效应，那么检验交互效应还有意义吗？</title>
      <link>https://stats.stackexchange.com/questions/637258/is-it-meaningful-to-test-the-interaction-effect-if-there-is-no-significant-effec</link>
      <description><![CDATA[假设我们有一个包含两个协变量的线性回归模型，Y = b0 + b1x1 + b2x2。
存在三种可能的情况：

b1 和 b2 均显着。
要么 b1 重要而 b2 不重要，或者 b2 重要而 b1 不重要。
b1 和 b2 都不重要。

我的问题是，从统计上（不是理论上）来看，在哪种情况（场景）下进一步研究 x1 和 x2 之间的相互作用有意义？例如，研究模型 Y = b0 + b1x1 + b2x2 + b3x1x2。我看到很多人进一步研究场景1和场景2下的交互效果，但我不确定我们是否也应该尝试评估场景3的交互效果。]]></description>
      <guid>https://stats.stackexchange.com/questions/637258/is-it-meaningful-to-test-the-interaction-effect-if-there-is-no-significant-effec</guid>
      <pubDate>Fri, 19 Jan 2024 18:30:20 GMT</pubDate>
    </item>
    <item>
      <title>数学问题 - 选择的概率分布</title>
      <link>https://stats.stackexchange.com/questions/637257/maths-questions-probability-distribution-of-choices</link>
      <description><![CDATA[我需要帮助解决我正在解决的问题：
个人有 5 个选择：

选择 1：效用 = alpha * R1 + beta * C1 + random_shock_1(mu=0,sig=1)
选择 2：效用 = alpha * R2 + beta * C2 + random_shock_2(mu=0,sig=1)
选择 3：效用 = alpha * R3 + beta * C3 + random_shock_3(mu=0,sig=1)
选择 4：效用 = alpha * R4 + random_shock_4(mu=0,sig=1)
选择 5：效用 = beta * C4 + random_shock_5(mu=0,sig=1)

有大量 M 个人会选择实用性最高的选项。但是，它们各自具有不同的 alphas 和 betas，即偏好使用 R 或 C，其中  R1、R2等是不同的值，或者R和C1、C2等是不同的值C 又名常量。然而，alpha 和 beta 的分布是已知的（即我们知道两者的平均值和标准差）。
是否可以计算出选择每个选项的个人的预期比例？如果是的话怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/637257/maths-questions-probability-distribution-of-choices</guid>
      <pubDate>Fri, 19 Jan 2024 18:21:35 GMT</pubDate>
    </item>
    <item>
      <title>帮助解决 Machin 和其他人之间配对 T 检验样本量公式的分歧</title>
      <link>https://stats.stackexchange.com/questions/637249/help-on-diivergence-in-the-paired-t-test-sample-size-formula-between-machin-and</link>
      <description><![CDATA[对于前后研究，连续终点（假设正常）。我想检测 50 (mg/dL) 的差异，并且变化的 SD 可以轻松达到 20 mg/dL（例如）。根据 machin 等人的说法，问题是：
N 对 = 2*(Z1-a/2+Zb)^2/效应大小^2。 + 修正系数。基本上，看起来像 2 个样本 T 检验，但 SD 是内部的（小于并行研究中的总 SD）。我在另一本书中看到过这种方法。另一方面，我见过使用分子中没有 2 的公式进行样本量计算。我认为第一种方法真正询问了两种条件（交叉中的两种药物或前后中的两次药物）之间的均值差异，并且由于方差较小，样本也较小，而第二种方法更多的是单样本 T 检验空 0？哪种方法是理想的，哪种方法是正确的？或者如果两者都正确，那么陈述的区别是什么？我在后期看到了这两种方法，我认为交叉（忘记周期效应等）。其相关性是因为 N 是第二种方法的一半。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/637249/help-on-diivergence-in-the-paired-t-test-sample-size-formula-between-machin-and</guid>
      <pubDate>Fri, 19 Jan 2024 17:18:02 GMT</pubDate>
    </item>
    <item>
      <title>正交回归还是原始多项式回归？</title>
      <link>https://stats.stackexchange.com/questions/637248/orthogonal-or-raw-polynomial-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/637248/orthogonal-or-raw-polynomial-regression</guid>
      <pubDate>Fri, 19 Jan 2024 17:15:11 GMT</pubDate>
    </item>
    </channel>
</rss>