<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 20 May 2024 03:16:43 GMT</lastBuildDate>
    <item>
      <title>销售数据趋势</title>
      <link>https://stats.stackexchange.com/questions/647588/sales-data-trend</link>
      <description><![CDATA[我有历史销售数据，我想检查趋势（增加、减少或没有变化）。当我制作年度折线图时，线性方程的斜率是正的（表示增加），但是当我制作月度图表并显示线性方程时，斜率是负的（非常小，但为负）。我不确定这意味着什么，或者线性方程是否是分析我的销售数据的最佳方法。如果我不输入线性方程，就很难在我的销售数据中看到一个水平。]]></description>
      <guid>https://stats.stackexchange.com/questions/647588/sales-data-trend</guid>
      <pubDate>Mon, 20 May 2024 02:33:15 GMT</pubDate>
    </item>
    <item>
      <title>模型训练损失始终收敛于 1.35</title>
      <link>https://stats.stackexchange.com/questions/647587/model-training-loss-always-converge-to-1-35</link>
      <description><![CDATA[我正在尝试使用 RNN 创建多类分类模型。输入数据的序列长度为 90，由 5 个特征组成，归一化到 [0,1] 范围。
这是我尝试过的网络架构，它是具有减少训练损失的最小容量模型：
inputs = tf.keras.Input(shape=(sequence_length, feature_length))
x1 = tf.keras.layers.GRU(512)(输入)
x2 = tf.keras.layers.LayerNormalization()(x1)
输出 = tf.keras.layers.Dense(4, 激活 =“softmax”)(x2)
模型= tf.keras.Model（输入，输出）

我尝试过的最大模型有 3 个 GRU 层，每层有 1024 个单元。
令我困惑的是，无论模型容量如何，所有模型的训练损失都收敛到 1.35 左右。我不明白为什么这些模型无论其容量如何都会始终收敛到相似的值。
有谁知道为什么会出现此问题以及如何解决它？]]></description>
      <guid>https://stats.stackexchange.com/questions/647587/model-training-loss-always-converge-to-1-35</guid>
      <pubDate>Mon, 20 May 2024 01:46:55 GMT</pubDate>
    </item>
    <item>
      <title>两个子群体回归模型的刀切方差估计</title>
      <link>https://stats.stackexchange.com/questions/647584/jackknife-variance-estimate-for-a-regression-model-for-two-subpopulation</link>
      <description><![CDATA[考虑两个亚群体的回归模型
\begin{align}
Y_i&amp;=X_i+\epsilon_i, i=1,\ldots,n/2\\
Y_i&amp;=-X_i+\epsilon_i, i=n/2+1,\ldots,n \quad(1)
\end{对齐}
其中 $\{X_i\}$ 是 i.i.d.均值为零的随机变量。
我想使用折刀估计计算样本协方差的方差，其中样本协方差由 $$\hat{cov}((X_1,. ..,X_n),(Y_1,...,Y_n))=\frac{1}{n}\sum_{i=1}^{n}X_iY_i-\frac{1}{n}\sum_{i =1}^{n}X_i\frac{1}{n}\sum_{i=1}^{n}Y_i.$$
有趣的是，我发现两种不同的视角给出了不同的样本协方差方差。我们将模型写为
$$Y_i=\beta_iX_i+\epsilon_i$$
首先，我们将 $\beta_i$ 视为常量（对于 i=1,...,n/2 等于 1，对于 i=n 等于 -1 /2+1,...,n), 那么通过计算我们有
$$var(\hat{cov}((X_1,...,X_n),(Y_1,...,Y_n)))=\frac{1}{n} \{E(X^4)+E(\epsilon^2)-(E(X^2)^2)\}+o_p(\frac{1}{n})$$
其次，我们认为 $\beta_i$ 是来自分类分布的随机变量。 $P(\beta_i)=1)=P(\beta_i)=-1)=0.5$。那么通过计算我们有
$$var(\hat{cov}((X_1,...,X_n),(Y_1,...,Y_n)))=\frac{1}{n} \{E(X^4)+E(\epsilon^2)\}+o_p(\frac{1}{n})$$
这两个推导经过仿真验证，结果是正确的。当数据生成过程恰好来自（1）时，我认为我们应该使用第一个视角来估计方差。然而，当我使用折刀估计来近似协方差的方差时，它支持第二种观点。这很令人困惑，因为我实际上并没有通过将 $\beta$ 视为随机变量来生成数据。
这个现象有什么解释吗？如果我想要从第一个角度对协方差进行方差估计，即将回归系数视为常数，我可以通过使用子采样技术来实现吗？
这是模拟代码
&lt;前&gt;&lt;代码&gt;n=1000

#第一视角的方差估计
beta=c(代表(1,500),代表(-1,500))
veccov=NULL
for(i in 1:1000){
  x=rnorm(n,sd=1)
  y=x*beta+rnorm(n,sd=1)
  veccov=c(veccov,cov(x,y))
}

var(veccov)*n

#第二视角的方差估计
n=1000
veccov=NULL
for(i in 1:1000){
  β=样本(c(1,-1),n,替换=T)
  x=rnorm(n,sd=1)
  y=x*beta+rnorm(n,sd=1)
  veccov=c(veccov,cov(x,y))
}

var(veccov)*n

#100 倍折刀方差估计
#数据是从第一视角生成的
beta=c(代表(1,500),代表(-1,500))
veccov=NULL
for(i in 1:100){
  x=rnorm(n,0,sd=1)
  y=x*beta+rnorm(n,sd=1)
  
  covxyfull=cov(x,y)
  covxy=NULL
  for(j in 1:n){
    covxy=c(covxy,cov(x[-j],y[-j]))
  }
  
  jcovxy=n*covxyfull-(n-1)*covxy
  veccov=c(veccov,var(jcovxy))
}
均值（维可夫）
]]></description>
      <guid>https://stats.stackexchange.com/questions/647584/jackknife-variance-estimate-for-a-regression-model-for-two-subpopulation</guid>
      <pubDate>Mon, 20 May 2024 01:24:49 GMT</pubDate>
    </item>
    <item>
      <title>R 中具有异方差性的层次回归</title>
      <link>https://stats.stackexchange.com/questions/647581/hierarchical-regression-in-r-with-heterocedasticity</link>
      <description><![CDATA[我使用 lm 在 R 中执行了层次回归。我使用性能包通过统计和视觉方式评估了这些假设。从视觉上看，我观察到异方差性，尽管 Breuch-Pagan 是正确的。尽管如此，我想使用健壮的包来稳健地运行层次回归分析。我用 lmrob 做到了这一点，没有出现任何问题。关于系数 $R^2$ 和调整后的 $R^2$ 的结果实际上是相同的在非鲁棒模型中。但当我跑步时
anova(modelr1, modelr2, model3r, modelr4) 得到
关于 $F$ 的信息，我得到了非常不同的结果。我不明白为什么。有没有人在 R 中做过具有异方差性的层次回归并且可以帮助我
模型示例
mstep1 &lt;- lm (X ~ A + B + D + E, data=数据)
mstep2 &lt;- lm (X ~ A + B + D + E + F, data=数据)
mstep1r &lt;- lmrob (X ~ A + B + D + E, data=Data)
mstep2r &lt;- lmrob (X ~ A + B + D + E + F, data=Data)

方差分析（mstep1，mstep2，mstep3，mstep4）
方差分析表
Res.Df RSS Df Sq F 之和 Pr(&gt;F)
1 909 1728.1
2 908 1622.5 1 105.547 59.3509 3.456e-14 ***
3 907 1611.5 1 11.002 6.1866 0.01305 *
4 906 1611.2 1 0.319 0.1793 0.67212

```方差分析（mstep1r，mstep2r，mstep3r，mstep4r）
鲁棒 Wald 测试台
  伪Df Test.Stat Df Pr(&gt;chisq)
1933
2 934 0.019976 1 0.8876
3 934 0.019976 1 0.8876
4 934 0.019976 1 0.8876

````&gt; test_wald(mstep1,mstep2,mstep3,mstep4)
名称 |型号| df | df_diff | df_diff | F | p
-----------------------------------------------------------
mstep1 | LM | 909 | 909 | |
mstep2 | LM | 908 | 908 1.00 | 59.35 | 59.35 &lt; .001
mstep3 | LM | 907 | 907 1.00 | 6.19 | 0.013
mstep4 | LM | 906 | 906 1.00 | 0.18 | 0.18 0.672
模型被检测为嵌套的（就固定参数而言）并按顺序进行比较。
&gt; test_wald（mstep1r，mstep2r，mstep3r，mstep4r）
名称 |型号| df | df_diff | df_diff | F | p
------------------------------------------------
mstep1r |抱歉，暂无相关信息936 | 936 | |
mstep2r|抱歉，暂无相关信息935 | 935 1.00 | 65.63 | 65.63 &lt; .001
mstep3r | mstep3r |抱歉，暂无相关信息934 | 934 1.00 | 10.06 | 10.06 0.002
mstep4r | mstep4r |抱歉，暂无相关信息933 | 933 1.00 | |
模型被检测为嵌套的（就固定参数而言）并按顺序进行比较。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647581/hierarchical-regression-in-r-with-heterocedasticity</guid>
      <pubDate>Mon, 20 May 2024 00:11:02 GMT</pubDate>
    </item>
    <item>
      <title>创建模型来预测多年来多个变量的成本</title>
      <link>https://stats.stackexchange.com/questions/647575/creating-a-model-to-predict-costs-from-multiple-variables-over-the-course-of-yea</link>
      <description><![CDATA[因此，我有任何给定月份的故障数据集以及每个月因此损失的产品总成本。这个数据集跨越了多年，我想创建一个模型，将这两者联系起来并预测它的未来。
任何关于如何进行和学习什么的指示都会很棒。]]></description>
      <guid>https://stats.stackexchange.com/questions/647575/creating-a-model-to-predict-costs-from-multiple-variables-over-the-course-of-yea</guid>
      <pubDate>Sun, 19 May 2024 22:44:04 GMT</pubDate>
    </item>
    <item>
      <title>H0 和 H1 图中的 alpha 和 beta 的解释是什么？</title>
      <link>https://stats.stackexchange.com/questions/647564/what-is-the-interpretation-of-alpha-and-beta-within-the-plots-of-a-h0-and-h1</link>
      <description><![CDATA[阅读统计功效，他们得出以下结论：

并说：
&lt;块引用&gt;
在原假设（抽样分布 1）和备择假设（抽样分布 2）的情况下，说明统计检验的功效和显着性水平。

我不明白 $\alpha$ 和 $\beta$ 与图有何关系。您能给我一些提示吗？

这些高斯概率分布曲线（可能是任何其他曲线）是针对一组人（例如身高）的，还是针对许多组人的平均值的分布？ （仅以平均值为例。）
]]></description>
      <guid>https://stats.stackexchange.com/questions/647564/what-is-the-interpretation-of-alpha-and-beta-within-the-plots-of-a-h0-and-h1</guid>
      <pubDate>Sun, 19 May 2024 18:42:42 GMT</pubDate>
    </item>
    <item>
      <title>原假设是否需要是无差异的陈述？</title>
      <link>https://stats.stackexchange.com/questions/647557/does-the-null-hypothesis-need-be-a-statement-of-no-difference</link>
      <description><![CDATA[我只是想自学统计学的基础知识。而且我不完全理解零假设与备择假设。
我不明白的是：原假设可以是有方向性的陈述，还是必须始终是无差异的陈述？
例如，假设我们有组 1 和组 2：
$$H_0: \mu_1 = \mu 2$$
$$H_1: \mu_1 \neq \mu 2$$
与不同的声明
$$H_0: \mu_1 \leq \mu 2$$
$$H_1: \mu_1 \gt \mu 2$$
这两个语句都有效，因此 $H_0$ 可以具有方向性吗？
我已经与 ChatGPT 讨论过这个问题，但它出现了明显的矛盾。]]></description>
      <guid>https://stats.stackexchange.com/questions/647557/does-the-null-hypothesis-need-be-a-statement-of-no-difference</guid>
      <pubDate>Sun, 19 May 2024 15:53:10 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归模型的单边似然比检验？</title>
      <link>https://stats.stackexchange.com/questions/647549/one-sided-likelihood-ratio-test-for-a-logistic-regression-model</link>
      <description><![CDATA[我需要对逻辑回归模型的一个参数进行单侧检验：
$H_0$：$\beta = 0$
$H_1$：$\beta \geq 0$
我想避免使用 Wald 等效方法，因为这些方法在逻辑回归中存在问题。（Piegorsch，1990）表明，基于单侧似然比的检验对于 glms 是可行的。有没有在 R 中实现过？
如果没有，以下是实现检验的合法方法吗（对于 alpha = 0.05）？

使用 confint 计算双侧 90% 置信区间；请注意，自 R 4.4.0 起，它使用 MASS 的轮廓似然法。
用 -∞ 替换 CI 的下限以获得单侧置信区间。
如果 CI 不包括 0，则拒绝 H0。

Piegorsch W. W. (1990)。二分响应下广义线性模型的单侧显着性检验。生物统计学，46(2)，309–316。]]></description>
      <guid>https://stats.stackexchange.com/questions/647549/one-sided-likelihood-ratio-test-for-a-logistic-regression-model</guid>
      <pubDate>Sun, 19 May 2024 12:39:11 GMT</pubDate>
    </item>
    <item>
      <title>拉斯穆森方程 5.9</title>
      <link>https://stats.stackexchange.com/questions/647532/rasmussen-equation-5-9</link>
      <description><![CDATA[有人可以添加步骤来展示 Rasmussen（机器学习的高斯过程，麻省理工学院出版社，2006 年）如何从方程 5.9 的第 1 行得到第 2 行（第 114 页）吗？它正在计算对数似然的梯度。
\begin{equation}
\begin{aligned}
\frac{d}{d\theta_j} \log p(y|X, \theta) &amp;= \frac{1}{2}y^T K^{-1}\frac{dK}{d\theta_j}K^{-1}y - \frac{1}{2}\text{tr}(K^{-1}\frac{dK}{d\theta_j})\\
&amp;= \frac{1}{2}\text{tr}\Bigl((\alpha\alpha^T-K^{-1})\frac{dK}{d\theta_j}\Bigl)
\end{aligned}
\end{equation&gt;
其中：$\alpha=K^{-1}y$ 且 $K$ 是 PSD]]></description>
      <guid>https://stats.stackexchange.com/questions/647532/rasmussen-equation-5-9</guid>
      <pubDate>Sun, 19 May 2024 00:20:57 GMT</pubDate>
    </item>
    <item>
      <title>轻松估计标准误差[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647502/estimate-standard-errors-effortlessly</link>
      <description><![CDATA[我有一个未观察到的变量 $𝑧_𝑖$，以及它的三个观察到的估计值：$𝑤_𝑖、𝑥_𝑖、𝑦_𝑖$ 。误差 $𝑤_𝑖−𝑧_𝑖,𝑥_𝑖−𝑧_𝑖,𝑦_𝑖−𝑧_𝑖$ 为零均值，彼此独立且在  之间独立$𝑖$，但 $𝑖$ 之间的分布是相同的（尽管不一定在 $𝑤$ 之间） 、$𝑥$ 和 $𝑦$）。如果我有 $𝑁$
观察值 ($𝑖=1,…,𝑁$)，如何估计 $𝑤$ 的标准误差span&gt;、$𝑥$ 和 $𝑦$？
$W$ 和 $X$ 之间的差异的方差为 $\textrm{Var}(W-X) = \textrm{se}^2_W + \textrm{se}^2_X$ 在上述设置下，当  $N\rightarrow \infty$ 其中 $\textrm{se}$ 代表标准错误。这同样适用于“$X$”和“$Y$”和“$Y$ 和 $W$”。
所以我们有
$$
\开始{对齐}
\textrm{Var}(W-X) &amp;= \textrm{se}^2_W + \textrm{se}^2_X, \\
\textrm{Var}(X-Y) &amp;= \textrm{se}^2_X + \textrm{se}^2_Y,\\
\textrm{Var}(Y-W) &amp;= \textrm{se}^2_Y + \textrm{se}^2_W。
\结束{对齐}
$$
差异的方差（左侧）可以根据观察到的数据计算出来。该方程组是否提供标准误差的解？特别是，该系统的反演提供了解析解，但这真的解决了吗？
我特别想知道，因为如果确实如此，这样的解决方案将在实际应用中产生重大影响：在这样的应用中，我们想要估计/测量一些潜在的 $Z$ （既不是固定的也不是固定的，但可以根据测量的时间/地点而变化）通过使用我们的模型/假设/设备$X$；为了验证我们的 $X$，我们准备更可靠的数据（地面事实或测试数据）作为 $Y$&lt; /span&gt; （生成配对数据集 $\{(X_i, Y_i)\}_{i=1}^N$ 其中 $N$ 表示观察索引，例如时间戳和/或位置编号等）；这里我们知道 $X-Y$ 差异的标准差给出了复合标准误差 ($\textrm{Var} (X-Y) = \textrm{se}^2_X + \textrm{se}^2_Y$) 但无法分解为每个标准错误（特别对 $\textrm{ se}_X$）。上面的三个方程组告诉我们，只有引入一个新变量 $W$，$\textrm{se}_X$  是可以估计的，更令人惊讶的是， $W$ 不需要依赖于 $Z$ （不需要测量 $Z$），但可以是不相关的随机数。]]></description>
      <guid>https://stats.stackexchange.com/questions/647502/estimate-standard-errors-effortlessly</guid>
      <pubDate>Sat, 18 May 2024 14:27:38 GMT</pubDate>
    </item>
    <item>
      <title>将百分比组与对名义问题的回答进行比较[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647463/comparing-percentage-groups-with-responses-to-nominal-question</link>
      <description><![CDATA[我可以使用什么统计测试来查看问题的回答对于任何百分比的人群是否具有统计显着性？]]></description>
      <guid>https://stats.stackexchange.com/questions/647463/comparing-percentage-groups-with-responses-to-nominal-question</guid>
      <pubDate>Sat, 18 May 2024 02:06:06 GMT</pubDate>
    </item>
    <item>
      <title>ANCOVA 的功效分析</title>
      <link>https://stats.stackexchange.com/questions/647444/power-analysis-for-ancova</link>
      <description><![CDATA[我有兴趣使用 ANCOVA 进行实验设计和推理的功效分析。我看到问题A，B，C 在质量、适用性和答案方面有所不同；而我对权威的、可概括的答案感兴趣。
假设您正在设计一个实验来评估治疗带来的 KPI 提升。假设进行 2 个样本 2 边 T 检验时，功效分析表明，在给定样本量的情况下，MDE 比现有样本均值大 5%。用棒球来比喻，这就是全垒打！但你的球队只需要在垒上找一个击球手即可；理想情况下，您可以检测到更小的影响。
输入 ANCOVA，您基本上只需使用 OLS 回归来推断每个协变量以及治疗指示变量的系数，然后询问线性模型，如果治疗组和对照组在协变量方面相同，那么治疗组和对照组会有什么不同，隔离治疗效果如何？此过程减少了方差；伟大的！但您组织中的领导者自然会想知道权力以及权力有多大？
根据我的拼凑，仍然使用 OLS 模型。然而，您不能以治疗暴露为条件，因为尚未进行暴露。所以这只是自变量及其协变量的问题。
我理解预测区间是在给定线性模型残差的标准误差的情况下分布在模型预测周围的 95%（或 x%）置信区间。
据我了解，当问题是“考虑到这些协变量以及使用 ANCOVA 的意图时，我的能力是什么？”预测区间的平均值 (0) 和残差标准误差可用于功效分析。
这个理解正确吗？如果不是，那么在实践中如何计算协变量已被识别并且 ANCOVA 是预期推理算法的实验设计的功效？]]></description>
      <guid>https://stats.stackexchange.com/questions/647444/power-analysis-for-ancova</guid>
      <pubDate>Fri, 17 May 2024 18:46:59 GMT</pubDate>
    </item>
    <item>
      <title>寻找嘈杂多边形的角点</title>
      <link>https://stats.stackexchange.com/questions/647344/finding-the-corners-of-noisy-polygons</link>
      <description><![CDATA[我有一些多边形，例如如下所示：

如果我将一侧放大得非常近，您可以看到噪音。

数据是 x 坐标列表和相应的 y 坐标列表。
我想要一种能够找到更小、更简单、噪音更少的坐标列表的算法。
我认为多边形的边是线性方程的连续列表。
我读到了Lasso并决定尝试一下。
from sklearn.linear_model import Lasso
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

xs_name = &quot;xs.txt&quot;;
ys_name = &quot;ys.txt&quot;;

xs = np.loadtxt(xs_name).reshape(-1, 1)
ys = np.loadtxt(ys_name).reshape(-1, 1)

reg = 套索(alpha=0.1)
reg.fit(xs, ys)

供参考，xs 和 ys 如下所示：
xs

ys

但是我只得到一个系数
&lt;前&gt;&lt;代码&gt;reg.coef_
输出[31]：数组（[0.82647029]）

我希望获得每条识别线的系数列表。
我觉得我在概念上错过了一些东西。我什至不确定 Lasso 是否适合这项工作。
有谁知道我如何正确使用套索，或者指出我适合这项工作的正确工具。
&lt;小时/&gt;
编辑
x 坐标
坐标
我还认为值得一提的是，调查论文中也提到了 group lasso 破裂库
&lt;小时/&gt;
编辑
为了清楚起见，放大的区域用红色圈出

编辑
我在 R 中尝试自回归模型取得了一些成功
xs &lt;- read.table(&#39;xs.txt&#39;, sep=&quot;\n&quot;)
ys &lt;- read.table(&#39;ys.txt&#39;, sep=&quot;\n&quot;)

xs &lt;- as.numeric(as.character(unlist(xs)))
ys &lt;- as.numeric(as.character(unlist(ys)))

fastcp_xs &lt;- fastcpd::fastcpd.ar(xs, 3, r.progress = FALSE)
摘要（fastcp_xs）
情节（fastcp_xs）


但是，在这种情况下，这种方法的成功似乎主要是运气，因为在更多数据上尝试此方法会发现结果很糟糕。
在 ys 上尝试相同的方法：
fastcp_ys &lt;- fastcpd::fastcpd.ar(ys, 3, r.progress = FALSE)
摘要（fastcp_ys）
情节（fastcp_ys）


自回归模型无法检测 ys 的边缘。
fastcpd 库中的其他例程在我的情况下似乎给出了类似的糟糕结果。
我目前认为我最好的选择是某种形式的套索算法。因为套索的概念是拟合一系列直线。
这可能会变成线性规划问题。
也许我需要求助于使用类似 pyomo 的东西？]]></description>
      <guid>https://stats.stackexchange.com/questions/647344/finding-the-corners-of-noisy-polygons</guid>
      <pubDate>Thu, 16 May 2024 07:46:23 GMT</pubDate>
    </item>
    <item>
      <title>泊松分布与二项分布的卷积？</title>
      <link>https://stats.stackexchange.com/questions/609746/convolution-of-poisson-with-binomial-distribution</link>
      <description><![CDATA[假设我有一个激光器，它发射包含随机数量光子的光脉冲，这些光子遵循泊松分布。因此它具有每个脉冲的平均光子数。
这些脉冲通过滤波器，导致每个光子都有可能被吸收或传输。
我试图弄清楚滤波器后面的光子数量的分布是什么样的。这如何用数学来描述？
我知道得到的分布应该与泊松分布和二项式分布的某种组合有关。也许某种卷积？除此之外我一无所知，因为我只有基本的统计学知识。]]></description>
      <guid>https://stats.stackexchange.com/questions/609746/convolution-of-poisson-with-binomial-distribution</guid>
      <pubDate>Thu, 16 Mar 2023 21:03:30 GMT</pubDate>
    </item>
    <item>
      <title>$\mathbb{E}[Y|X]$ 和 $\mathbb{E}[Y|X=x]$ 之间的差异</title>
      <link>https://stats.stackexchange.com/questions/549684/difference-between-mathbbeyx-and-mathbbeyx-x</link>
      <description><![CDATA[设 $(\Omega, \mathcal{A}, \mathbb{P})$ 为概率空间，$X: \Omega \rightarrow \mathcal{X}$ 和 $Y: \Omega \rightarrow \mathcal{Y}$ 是随机变量。 
我有两个问题比较条件期望 $\mathbb{E}[Y|X]$ 和 $\ mathbb{E}[Y|X=x]$。
1.) $\mathbb{E}[Y|X=x]$ 和  有什么区别$\mathbb{E}[Y|X]$ 的数学性质是什么？即，它们从哪个空间映射到哪个空间，它们是哪些变量的函数以及它们是否可测量？
2.) 如果$X$和$Y$是绝对连续的实值随机变量并且相对于勒贝格测量 $\lambda \otimes \lambda 具有联合密度 $f_{X, Y}$ =\lambda^2$，则：
$$\mathbb{E}[Y|X=x] = \int y \, f_{Y|X=x}(y) \, \lambda(dy) = \ int y \, \frac{f_{X, Y}(x,y)}{f_X(x)}\lambda(dy).$$
我现在的问题是，对于 $\mathbb{E}[Y|X]$ 来说，这个方程会是什么样子？编写类似 $f_{Y|X=X}(y)$ 和 $f_{X 的内容是否有意义,Y}(X,y)$ 这些数量是否存在？即，我应该写
$$\mathbb{E}[Y|X] = \int y \, f_{Y|X=X} \lambda(dy) = \int y \, \frac{ f_{X, Y}(X,y)}{f_X(X)}\lambda(dy)$$?]]></description>
      <guid>https://stats.stackexchange.com/questions/549684/difference-between-mathbbeyx-and-mathbbeyx-x</guid>
      <pubDate>Mon, 25 Oct 2021 15:29:16 GMT</pubDate>
    </item>
    </channel>
</rss>