<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 25 Jan 2025 06:20:31 GMT</lastBuildDate>
    <item>
      <title>解释不相关但具有统计意义的 ODD 比率</title>
      <link>https://stats.stackexchange.com/questions/660515/interpreting-odds-ratios-that-are-irrelevant-yet-statistically-significant</link>
      <description><![CDATA[我有一个有点独特的数据集。
结果是一个二进制是/否变量。然而，结果非常不平衡。95% 是，5% 不是。
协变量 1：时间变量，从第 -200 天开始，到第 200 天结束，第 0 天是事件发生的那一天。-200、-199、-113、-14、0、11、25、89、135、200
协变量 2：事件，二进制变量，0（无事件）或 1（事件是）
如您所见，协变量 1（时间）和协变量 2（事件）高度相关。当时间为 -ve 时，事件为 0，当时间为 +ve 时，事件为 1。
当我拟合像这样的简单逻辑回归模型时
 glm(y ~ time + event + time*event, data= df, family=&quot;binomial&quot;)

这些是该模型的估计值
 项 优势比 S.E pvalue。
截距 0.02 0.04 0.051
时间 0.94 0.4 0.47
事件 1.01 0.3 0.9
时间*事件 1.001 0.0004 0.02

我不确定如何截取这些结果。从高层次来看，主要影响是直接的，时间的 OR 为 0.94 且不显著，事件的 OR 为 1.01 且不显著。
然而，时间和事件相互作用的 OR 是显著的，但 OR 实际上毫无意义。不确定如何理解这个总结结果。需要帮助把这些点连接起来。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660515/interpreting-odds-ratios-that-are-irrelevant-yet-statistically-significant</guid>
      <pubDate>Sat, 25 Jan 2025 05:51:09 GMT</pubDate>
    </item>
    <item>
      <title>如何从时间序列模型进行模拟？</title>
      <link>https://stats.stackexchange.com/questions/660513/how-to-simulate-from-time-series-models</link>
      <description><![CDATA[我想我知道如何模拟拟合的 ARIMA 时间序列模型的预测：
library(tidyverse)
library(forecast)
library(patchwork)

set.seed(123)

y_arima &lt;- rnorm(50, mean = 0, sd = 1)
ts_y_arima &lt;- ts(y_arima, frequency = 12)
arima_model &lt;- auto.arima(ts_y_arima)

n_ahead &lt;- 20
n_sims &lt;- 50

arima_sims &lt;- matrix(NA, nrow = n_sims, ncol = n_ahead)
for(i in 1:n_sims) {
arima_sims[i,] &lt;- mock(arima_model, nsim = n_ahead)
}

historical_data_arima &lt;- tibble(
time = 1:50,
value = y_arima,
type = &quot;Historical&quot;
)

arima_future &lt;- tibble(
time = rep(51:70, n_sims),
value = as.vector(t(arima_sims)),
simulation = rep(1:n_sims, each = n_ahead)
)

p1 &lt;- ggplot() +
geom_line(data = historical_data_arima, aes(x = time, y = value), 
color = &quot;black&quot;, size = 1) +
geom_line(data = arima_future, aes(x = time, y = value, group = simulation), 
alpha = 0.2, color = &quot;blue&quot;) +
geom_vline(xintercept = 50, linetype = &quot;dashed&quot;, color = &quot;red&quot;) +
labs(title = &quot;ARIMA Simulations&quot;,
x = &quot;Time&quot;, y = &quot;Y value&quot;) +
theme_minimal()


但我想知道，如何模拟 ARIMAX 模型的预测？我认为应该类似？例如假设我在整个预测过程中将协变量固定为一个常数值（例如 2）：
n_obs &lt;- 50
n_ahead &lt;- 20
n_sims &lt;- 50
future_x_value &lt;- 2
future_x &lt;- rep(future_x_value, n_ahead)

y &lt;- rnorm(n_obs, mean = 0, sd = 1)
x &lt;- rnorm(n_obs, mean = 1, sd = 0.5)

ts_y &lt;- ts(y, frequency = 12)
ts_x &lt;- ts(x, frequency = 12)

arimax_model &lt;- auto.arima(ts_y, xreg = ts_x)

arimax_sims &lt;- 矩阵（NA，nrow = n_sims，ncol = n_ahead）

for(i in 1:n_sims) {
arimax_sims[i,] &lt;- 模拟（arimax_model，nsim = n_ahead，xreg = future_x）
}

historical_data_arimax &lt;- tibble（
时间 = 1:n_obs，
值 = y
)

arimax_future &lt;- tibble（
时间 = rep((n_obs + 1):(n_obs + n_ahead), n_sims),
值 = as.vector(t(arimax_sims)),
模拟 = rep(1:n_sims, each = n_ahead)
)

p2 &lt;- ggplot() +
geom_line(数据 = historical_data_arimax, aes(x = 时间, y =值), 
color = &quot;black&quot;, size = 1) +
geom_line(data = arimax_future, aes(x = 时间, y = 值, group = 模拟), 
alpha = 0.2, color = &quot;green&quot;) +
geom_vline(xintercept = n_obs, linetype = &quot;dashed&quot;, color = &quot;red&quot;) +
labs(title = &quot;ARIMAX 模拟&quot;,
subtitle = paste(&quot;所有未来 X 值设置为&quot;, future_x_value),
x = &quot;时间&quot;, y = &quot;Y 值&quot;) +
theme_minimal()


这是正确的吗？（我想知道是否有办法让彩色模拟与黑色历史数据完全对齐，即消除间隙）]]></description>
      <guid>https://stats.stackexchange.com/questions/660513/how-to-simulate-from-time-series-models</guid>
      <pubDate>Sat, 25 Jan 2025 04:31:45 GMT</pubDate>
    </item>
    <item>
      <title>数据分割之前计算聚合特征算作数据泄漏吗？</title>
      <link>https://stats.stackexchange.com/questions/660511/is-computing-aggregated-features-before-data-splitting-count-as-data-leakage</link>
      <description><![CDATA[上下文：
我有一个对象的映射 3D 扫描数据集。每个数据点都按 (x, y, z) 坐标进行索引，并具有与之关联的多个特征。在将数据集拆分为训练集和测试集之前，我汇总了相邻数据点的特征值。例如我取数据点 x,y,z 的特征 f，并计算 3D 空间中相邻数据点的特征加权平均值 f_3d_avg。
用于计算一个数据点的特征加权平均值的虚拟 Python 代码：
x,y,z = data.index[0]
f = &#39;feature&#39;
f_sum = 0.0
weight_sum = 0.0

for i in range(z-1, z+2, 1):
for j in range(y-1, y+2, 1):
for k in range(x-1, x+2, 1):
weight = 1/(pow(x-k,2) + pow(y-j,2) + pow(z-i,2))
weight_sum += weight
f_sum += data.loc[(k,j,i), [f]] * 权重

f_3d_avg = f_sum/weight_sum

现在，数据集应该对每个特征 f 都有一个对应的特征 f_3d_avg。最后，我将数据拆分为训练集和测试集。
我的问题：
如果我在拆分数据后计算了 f_3D_avg，比如使用标准的 80-20 拆分，平均而言，5 个数据点中会有 1 个缺失，这会改变 f_3d_avg 的值。由于 f_3d_avg 值会根据拆分前或拆分后计算而有所不同，那么对拆分前计算的 f_3d_avg 进行训练是否算作数据泄漏？]]></description>
      <guid>https://stats.stackexchange.com/questions/660511/is-computing-aggregated-features-before-data-splitting-count-as-data-leakage</guid>
      <pubDate>Sat, 25 Jan 2025 03:47:59 GMT</pubDate>
    </item>
    <item>
      <title>较弱的“完整”统计定义</title>
      <link>https://stats.stackexchange.com/questions/660508/weaker-complete-statistic-definition</link>
      <description><![CDATA[为什么我们不定义充分统计量 $T(x)$ 的完备性，因为 $g(T(x))$ 依赖于所有函数 g 的 $\theta$？
定义
$$\mathbb{E}_\theta \left[ g(T(X)) \right] = 0 \quad \text{for all } \theta \quad \Rightarrow \quad g(T(X)) = 0 \quad \text{almost sure}$$
似乎更强。
此外，前一个定义似乎足以证明 Basu 定理，而且更直观？]]></description>
      <guid>https://stats.stackexchange.com/questions/660508/weaker-complete-statistic-definition</guid>
      <pubDate>Sat, 25 Jan 2025 00:29:55 GMT</pubDate>
    </item>
    <item>
      <title>使用皮尔逊卡方拟合优度检验来比较混合对数正态和逆伽马拟合数据</title>
      <link>https://stats.stackexchange.com/questions/660507/pearsons-chi-squared-goodness-of-fit-test-to-compare-mixed-log-normal-and-inver</link>
      <description><![CDATA[我有一些数据（非分类数据），我认为它们来自某些基础分布。数据严格为正值。从视觉上看，我认为逆伽马分布和 2 分量混合对数正态分布看起来都是数据的合理分布。我正在使用 Pearson 卡方拟合优度检验（通过 MATLAB 的 chi2gof 函数）来测试我是否应该接受或拒绝我的数据可能来自这些分布的零假设。
虽然 Pearson 卡方检验应该用于分类数据，但我读过许多在构建一些箱体后将其用于非分类数据的例子，这有点主观。关于这一点，我理解每个箱体的预期计数应该有 &gt;5 个计数才能使测试可靠，并且它们不需要均匀分布。但是，由于分箱会影响统计量的计算，我是否应该对每个分布的拟合优度检验使用相同的分箱边界，以便对它们进行最佳比较？
我还想能够说明哪种分布更适合。从视觉上看，混合对数正态分布看起来稍好一些，但我想避免过度拟合，因为有 6 个参数，而逆伽马只有两个参数。我还读到，较低的卡方统计量代表更好的分布，但是，卡方统计量不包含自由度的数量（这仅在从卡方统计量计算 p 值时使用），所以我假设这在比较具有不同数量参数的分布时不一定成立，就像我的情况一样。相反，合理的比较似乎是 p 值较高的分布可能更适合。这听起来对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660507/pearsons-chi-squared-goodness-of-fit-test-to-compare-mixed-log-normal-and-inver</guid>
      <pubDate>Sat, 25 Jan 2025 00:24:47 GMT</pubDate>
    </item>
    <item>
      <title>生存结果和连续中介的中介分析给出了较大的治疗效果估计</title>
      <link>https://stats.stackexchange.com/questions/660506/mediation-analysis-with-survival-outcome-and-continuous-mediation-giving-large-t</link>
      <description><![CDATA[在执行中介分析时，我收到了非常奇怪的输出。
具体来说，我正在使用 AFT 模型和连续变量（即身体质量指数）作为中介，对事件发生时间事件（即心肌梗死）的结果进行中介分析。
但是，在执行分析时，我收到了非常奇怪的治疗效果估计和置信区间，例如效果约为 31,100，95% CI（2,590.00；80,574.58）。
这是正常的吗？收敛过程中是否存在错误或类似情况？
我给你一个示例代码：
event=rep(c(0,1),700)
event=as.numeric(event)
time=as.numeric(c(1:1400))
predictor=as.numeric(rep(c(1,0,0,1),350))
mediator=c(1:1400)

reg=lm(mediator~predictor)

surv=survreg(Surv(event = event, time = time)~ predictor + mediator)

med=mediate(
model.y = surv, model.m = reg, treat = &quot;predictor&quot;, mediator = &quot;mediator&quot;, 
boot = FALSE, sims = 1000
)

摘要（med）
]]></description>
      <guid>https://stats.stackexchange.com/questions/660506/mediation-analysis-with-survival-outcome-and-continuous-mediation-giving-large-t</guid>
      <pubDate>Sat, 25 Jan 2025 00:19:15 GMT</pubDate>
    </item>
    <item>
      <title>如何从 Benjamini Hochberg 检验中获得总体 P 值？</title>
      <link>https://stats.stackexchange.com/questions/660505/how-to-obtain-an-overall-p-value-from-benjamini-hochberg-test</link>
      <description><![CDATA[我写信是为了询问如何将 Benjamini Hochberg 程序应用于独立样本 t 检验。我知道如何获得 SPSS 上每个参与者的校正 p 值。但是，我需要澄清的是，如何根据 Benjamini Hochberg 程序计算总体 p 值，类似于原始独立样本 t 检验提供 p 值的方式。
感谢您对这个问题的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/660505/how-to-obtain-an-overall-p-value-from-benjamini-hochberg-test</guid>
      <pubDate>Sat, 25 Jan 2025 00:02:49 GMT</pubDate>
    </item>
    <item>
      <title>内生控制变量</title>
      <link>https://stats.stackexchange.com/questions/660502/endogenous-control-variables</link>
      <description><![CDATA[假设一个由 OLS 估计的线性模型。假设 X1 是研究变量，并且是严格外生的。现在，假设添加了控制变量 X2 和 X3。假设 X2 和 X3 与误差项相关。
Pearson 的积差相关检验（在 X1 和 X2 之间以及 X1 和 X3 之间）是否足以证明 X2 和 X3 的内生性不会影响 X1 的系数估计（假设检验的相关性在统计上为零）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660502/endogenous-control-variables</guid>
      <pubDate>Fri, 24 Jan 2025 21:37:09 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归 CS229 斯坦福</title>
      <link>https://stats.stackexchange.com/questions/660499/logistic-regression-cs229-stanford</link>
      <description><![CDATA[我正在尝试从 Andrew Ng 在 YouTube 上的课程学习基本的机器学习。我们刚刚介绍了逻辑回归，我尝试自己使用课程中的 ds1_train.csv 数据集来实现该理论，该数据集可在此处找到。
这是数据的图，以及预期的决策边界（我在 Mathematica 中使用 LogitModelFit 找到）：https://i.imgur.com/aSavXMo.png（如果有更多代表可以在此处添加图片，我将不胜感激）。
预期的分类器是 $h_\theta(x)=\sigma(\theta^T x)$，其中$\sigma(z)=1/(1+e^{-z})$是通常的 S 形函数，并且$\theta=(6.26,-2.47,0.03)$。我尝试自己使用下降法重现参数的这个值，即我们通过迭代更新初始猜测
$$
\theta_j\leftarrow \theta_j+\alpha(y^{(i)}-h_\theta(x^{(i)}))x^{(i)}_j,\qquad j=0,1,2
$$
其中 $i$ 遍历所有数据点。这在课程讲义的第 5 节中有解释，可在此处找到 。。 （此处的公式没有解释如何处理索引 $i$，但 Ng 教授解释了两种方法，要么对所有 $i$ 求和，要么对其进行迭代，他称之为“批量下降”，应该对大型数据集运行得更快）。
上面的公式似乎没有收敛，我不确定我是否误解了算法，或者在实现它时犯了错误。
这是我在 Mathematica 中的代码（如果有帮助，我可以尝试翻译成 python，但希望代码本身足够容易理解）
data = Import[&quot;ds1_train.csv&quot;] // Rest; (* import dataset *)
X = {1, #[[1]], #[[2]]} &amp; /@ data; (* 前两列是 x，我们用 1 来增加截距 *)
Y = #[[3]] &amp; /@ data; (* 第三列是 y *)
σ[z_] := 1/(1 + E^-z); (* sigmoid *)

h[θ_, x_] := σ[θ . x]; (* 逻辑模型 *)

(* 现在我们迭代 10 次，初始猜测 θ = {0, 0, 0} *)
Nest[# + .1 Sum[(Y[[i]] - h[#, X[[i]]]) X[[i]], {i, 1, Length[X]}] &amp;, {0, 0, 0}, 10] // Quiet

迭代失败。知道我做错了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660499/logistic-regression-cs229-stanford</guid>
      <pubDate>Fri, 24 Jan 2025 21:23:03 GMT</pubDate>
    </item>
    <item>
      <title>建立依赖于估计数据的回归模型</title>
      <link>https://stats.stackexchange.com/questions/660498/making-a-regression-model-that-relies-on-estimated-data</link>
      <description><![CDATA[这是我一直在研究的问题。

给定：我有跨多个单位的测量值（由 $i$ 索引）：


响应变量 $Y$（0 到 1 之间的数字）在 $t_1 = 2015$ 和 $t_4 = 2019$ 两个时间点测量。
预测变量 $X$（正数，完全连续）在 $t_2 = 2016$ 和 $t_5 = 两个时间点测量2021$


目标：我想了解随着时间的推移，$X$ 的变化如何影响 $Y$ 的变化，但测量是在不同的时间点进行的。例如，$X$ 的急剧变化是否与 $Y$ 的急剧增加有关？

模型：我认为我们可以为 $X$ 建立一个混合效应模型（假设随时间呈线性变化）：


$$ X_i(t) = \alpha_0 + \alpha_1t + u_i + \epsilon_{it} $$
使用此模型，我们可以为所需的时间点插入值并计算变化：
$$ \Delta X_i = X_i(2019) - X_i(2015) $$
$$ \Delta Y_i = Y_{i,2019} - Y_{i,2015} $$
然后，经过以下转换，我们可以制作 Beta GLM：
$$ p_i = \frac{\Delta Y_i + 1}{2} $$
$$ p_i \sim \text{Beta}(\mu_i\phi, (1-\mu_i)\phi) $$
$$ \text{logit}(\mu_i) = \beta_0 + \beta_1\Delta X_i $$
$$ \text{logit}(\mu_i) = \log\left(\frac{\mu_i}{1-\mu_i}\right) $$
$$ E(p_i) = \mu_i $$

不确定性：我想到的一件事是，由于我正在插入 $X$，因此会有一些错误需要考虑。我想到使用随机效应模型中的误差分布并执行引导模拟（反复估计 GLM 参数）。

这种方法有意义吗？我可以像这样使用 bootstrap 方法吗？

Bootstrap 过程：

步骤 1：使用观察到的 $X$ 值 () 拟合混合效应模型：
$$ X_i(t) = \alpha_0 + \alpha_1t + u_i + \epsilon_{it} $$

步骤 2：对于每次 bootstrap 迭代 $b = 1, ..., B$：

生成新的随机效应和残差：
$$ u_i^{(b)} \sim N(0, \hat{\sigma}^2_u) $$
$$ \epsilon_{it}^{(b)} \sim N(0, \hat{\sigma}^2_\epsilon) $$

计算所需时间点的 bootstrapped $X$ 值：
$$ X_i^{(b)}(t) = \hat{\alpha}_0 + \hat{\alpha}_1t + u_i^{(b)} + \epsilon_{it}^{(b)} $$

计算 bootstrapped 变化：
$$ \Delta X_i^{(b)} = X_i^{(b)}(2019) - X_i^{(b)}(2015) $$
$$ \Delta Y_i = Y_{i,2019} - Y_{i,2015} \text{（由于这些是观察到的，因此保持不变）} $$

转换 Beta GLM 的变化：
$$ p_i = \frac{\Delta Y_i + 1}{2} $$

为此引导样本拟合 Beta GLM：
$$ p_i \sim \text{Beta}(\mu_i^{(b)}\phi^{(b)}, (1-\mu_i^{(b)})\phi^{(b)}) $$
$$ \text{logit}(\mu_i^{(b)}) = \beta_0^{(b)} + \beta_1^{(b)}\Delta X_i^{(b)} $$


完成所有引导迭代后，我们可以计算感兴趣参数的置信区间。对于任何参数 $\theta$（例如 $\beta_1$），$1-\alpha$ 置信区间将是：
$$ [\theta_{(\alpha/2)}, \theta_{(1-\alpha/2)}] $$
其中 $\theta_{(q)}$ 表示引导分布的第 $q$ 分位数。]]></description>
      <guid>https://stats.stackexchange.com/questions/660498/making-a-regression-model-that-relies-on-estimated-data</guid>
      <pubDate>Fri, 24 Jan 2025 20:52:48 GMT</pubDate>
    </item>
    <item>
      <title>定义“辅助信息”，但不引用辅助统计数据</title>
      <link>https://stats.stackexchange.com/questions/660486/define-ancillary-information-without-referencing-ancillary-statistics</link>
      <description><![CDATA[我正在寻找辅助信息的定义，但该定义本质上不是“辅助统计数据中的信息”。有趣的是，辅助信息的定义似乎很难找到。至少有一篇被广泛引用的辅助统计数据评论甚至没有包含该短语。我不喜欢上述定义，因为它不仅是循环的，而且还让我陷入矛盾。
即：完整统计数据没有辅助信息。因此，不完整统计数据必须具有一些辅助信息。然后，不完整的充分统计数据具有一些辅助信息，但该信息无法根据辅助统计数据来定义。如果可以的话，您可以根据辅助统计量来获得方差小于充分统计量的估计量。但充分统计量是最具信息量的度量……您看到了问题所在。]]></description>
      <guid>https://stats.stackexchange.com/questions/660486/define-ancillary-information-without-referencing-ancillary-statistics</guid>
      <pubDate>Fri, 24 Jan 2025 16:03:59 GMT</pubDate>
    </item>
    <item>
      <title>如何提取和比较两个混合效应模型的预测值分布？</title>
      <link>https://stats.stackexchange.com/questions/660480/how-to-extract-and-compare-the-distribution-of-predicted-values-of-two-mixed-eff</link>
      <description><![CDATA[我有 6 天的 100 个样本（每天 100 个观测值，总共 600 个观测值）。我尝试将混合模型拟合到数据中。还有一次，我尝试将混合模型仅用于从相同数据中获取的两天观测值（例如：第 1 天和第 2 天的观测值 - 总共 200 个观测值）。我知道数据中存在人与人之间的差异会导致错误。我尝试使用混合效应模型将其消除。现在，我的问题是如何提取响应变量的分布？如何比较两个混合模型的分布？一般来说，是否有任何建议可以消除数据中的人与人之间的差异？
以下代码适用于 lme4 包中的 6 天数据。
library(lmer)
long_nutt1 &lt;- nutt1 %&gt;%
pivot_longer(
cols = c(BCP1, BCP2, BCP3, BCP4, BCP5, BCP6),
names_to = &quot;Day&quot;,
values_to = &quot;BCP&quot;
)
long_nutt1 &lt;- long_nutt1 %&gt;%
mutate(ID = rep(1:(nrow(nutt1)), each = length(grep(&quot;^BCP&quot;, names(nutt1)))))
data_6days &lt;- long_nutt1
################### 6 天
model_6days &lt;- lmer(log(BCP) ~ 1 + (1 | ID), data = long_nutt1)
summary(model_6days)
REML [&#39;lmerMod&#39;] 拟合的线性混合模型
公式：log(BCP) ~ 1 + (1 | ID)
数据：long_nutt1
收敛时的 REML 标准：1494.1
缩放残差：
最小 1Q 中位数 3Q 最大
-3.0346 -0.5696 0.0553 0.6336 3.1517
随机效应：
组名称方差标准差。
ID（截距）0.1747 0.4180
残差 0.4940 0.7028
观察数：600，组：ID，107
固定效应：
估计标准误差 t 值
（截距）4.29281 0.04901 87.58]]></description>
      <guid>https://stats.stackexchange.com/questions/660480/how-to-extract-and-compare-the-distribution-of-predicted-values-of-two-mixed-eff</guid>
      <pubDate>Fri, 24 Jan 2025 14:45:03 GMT</pubDate>
    </item>
    <item>
      <title>尝试计算偏差校正的方差折刀估计</title>
      <link>https://stats.stackexchange.com/questions/660500/attempting-to-compute-a-bias-corrected-jackknife-estmation-of-the-variance</link>
      <description><![CDATA[我的任务是计算方差的偏差校正折刀估计量。到目前为止，我设法使用伪值平均法得到结果，但遗憾的是结果与贝塞尔校正估计量不匹配。这是我的尝试 - 你知道我可能在哪里犯了错误吗？

我的尝试 
2. 找到$T^*_{\text{jack},\sigma^2}$，即$\hat{\sigma}^2$的折刀偏差校正估计量。偏差减少了吗？减少了多少？
我们将估计的方差称为 $\theta \triangleq \hat \sigma^2$，并且 $\frac{1}{n-1}\sum_{i\neq j} x_i \triangleq \bar X_{(-j)} = \frac{n}{n-1} \bar X - \frac{1}{n-1} X_j$
$$T_{(-j)} =\frac{1}{n-1} \sum _{\substack{i=1 \\ i \neq j}}^n (X_i -\frac{1}{n-1}\sum_{s\neq j} X_s )^2 = \frac{1}{n-1} \sum _{\substack{i=1 \\ i \neq j}}^n (X_i - \bar{X}_{(-j)})^2 $$
$$T_{(-j)}(n-1) = \sum_{\substack{i = 1 \\ i \neq j}}^n \left(X_i - \frac{n\bar X - X_j}{n-1}\right)^2 $$$$= \left(\sum_{\substack{i = 1 \\ i \neq j}}X_i^2\right) - 2 \\\frac{(n\bar{X}-X_j)^2}{n-1} + \sum_{\substack{i = 1 \\ i \neq j}}^n\left(\frac{(n\bar{X}-X_j)}{n-1}\right)^2$$
$$T_{(-j)}(n-1) = \left(\sum_{\substack{i = 1 \\ i \neq j}}X_i^2\right) - 2 \cdot \frac{(n\bar{X}-X_j)^2}{n-1} + (n-1) \frac{(n\bar{X}-X_j)^2}{(n-1)^{2}}$$
$$T_{(-j)} = \frac{1}{n-1}\left(\sum_{\substack{i = 1 \\ i \neq j}}X_i^2\right) -\frac{(n\bar{X}-X_j)^2}{(n-1)^2}$$
$$\tilde T_{(j)} = n T_n - (n-1) T_{(-j)}$$
$$\tilde T_{(j)} = \sum_{i=1}^n (X_i-\bar X)^2 - \left(\sum_{\substack{i = 1 \\ i \neq j}}X_i^2\right) -\frac{(n\bar{X}-X_j)^2}{(n-1)}$$
$$=\left[\sum_{i=1}^n X_i^2\right] -n\bar X^2 -\left(\sum_{\substack{i = 1 \\ i \neq j}}X_i^2\right) -\frac{(n\bar{X}-X_j)^2}{(n-1)}$$
$$\tilde T_{(j)} = X_j^2 - n\bar X^2-\frac{(n\bar{X}-X_j)^2}{(n-1)} = X_j^2 - n\bar X^2-\frac{n^2\bar{X}^2 - 2n\bar X X_j + X_j^2}{(n-1)}$$
$$\tilde T_{(j)} = \frac{n-2}{n-1}X_j^2 -n\bar X^2 - \frac{n^2\bar{X}^2 - 2n\bar X X_j }{(n-1)}$$
$$T^*_{jack} = \frac{1}{n}\sum_j \tilde T_{(j)} = (\frac{1}{n}\sum_j\frac{n-2}{n-1}X_j^2) -n\bar X^2 - \frac{n^2 \bar X^2}{n-1} + \frac{2n\bar X^2}{n-1}$$
进一步简化 $\bar X$ 并不能让我得到预期系数，$X_j$ 也不能 - 我哪里做错了？抱歉，这个问题涉及太多代数。]]></description>
      <guid>https://stats.stackexchange.com/questions/660500/attempting-to-compute-a-bias-corrected-jackknife-estmation-of-the-variance</guid>
      <pubDate>Thu, 23 Jan 2025 20:12:19 GMT</pubDate>
    </item>
    <item>
      <title>子集选择成功与逻辑分布之间的联系</title>
      <link>https://stats.stackexchange.com/questions/660386/connections-between-subset-selection-success-and-logistic-distributions</link>
      <description><![CDATA[我是统计学新手，所以如果我遗漏了一些显而易见的东西，请不要起诉我。我最近在做一项作业，任务是分析以下带有子集选择的模型：
$$
y_i = \beta_1 x_{1, i} + \beta_2 x_{2,i} + \beta_3 x_{3,i} + \beta_4 x_{4,i} + u_i
$$
其中
$$(x_{k,i})_{k=1}^4 \sim \mathcal{N}(0, \Sigma)$$
$$
\Sigma = 
\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; \gamma &amp; \gamma\\
0 &amp; \gamma &amp; 1 &amp; \gamma\\
0 &amp; \gamma &amp; \gamma &amp; 1
\end{pmatrix}
$$
其中 $\gamma \in [-1, 1]$。此外，我们有 $\beta_2 = \beta_3 = \beta_4 = 2$，并且 $\beta_1 &gt; 2$。最后，$u_i$ 是 i.i.d。正态分布，均值为零，方差为 2，$i = 1, \ldots, N$。
我们的任务是确定 $\gamma$ 和 $\beta_1$ 的阈值，对于这些阈值，子集选择（子集大小等于 $1$）正确识别出最重要的协变量，即 $\beta_1$。
在此过程中，我设法得出以下曲线，对于 $N = 500$，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线，$\beta = 4$ 为第一个曲线。 class=&quot;math-container&quot;&gt;$\gamma = 0$ 第二个。
$\gamma$&quot; /&gt;
$\beta$&quot; /&gt;
在我看来，这些看起来非常符合逻辑！因此，我运行了一个简单的逻辑曲线拟合，模型如下：
$$
f(x) = \frac{A}{1 + \exp(-k(x - x_0))}
$$
我管理了以下参数
最适合 gamma 的逻辑函数是： 
A = 1.0011916177515001, x0 = 0.46613345213429164, k = -25.287773424878644
99% 置信区间： 
[[ 0.99834479 1.00403845]
[ 0.46495465 0.46731225]
[-25.94535303 -24.63019382]]
最适合 beta 的逻辑函数是： 
A = 1.0008861957715565, x0 = 4.131595820642967, k = 6.469500267867452
99% 置信区间： 
[[0.99799143 1.00378096]
[4.12631938 4.13687226]
[6.27646573 6.66253481]]

使用以下图表（不提供信息，只是漂亮）：


我不完全理解如何测量非线性最小二乘的拟合优度，但这些是非常严格的置信区间，所以这最终引出了我的问题。
这种行为有一个很好的理论解释吗？看来，正确识别具有子集选择的协变量的概率是具有这些神奇参数的逻辑分布。事实确实如此吗？它是渐近逻辑的吗？这实际上只是一个正态分布（我在写这篇文章时意识到了这一点）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660386/connections-between-subset-selection-success-and-logistic-distributions</guid>
      <pubDate>Wed, 22 Jan 2025 18:06:40 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么估算器来估计不同名称的数量？</title>
      <link>https://stats.stackexchange.com/questions/660372/what-estimator-of-the-number-of-distinct-names-should-i-use</link>
      <description><![CDATA[我有 $N$ 个信封，每个信封都包含一张写有姓名的便条。有些姓名出现在多张便条上。总共有 $X$ 个不同的姓名。
为了弄清 $X$ 是什么，我打开 $n$ 个信封，找到 $x$ 个不同的姓名。
我应该使用什么 $X$ 估计量？理想情况下，我希望得到 $X$ 的估计量，并带有置信区间。
编辑：我不知道姓名计数遵循什么分布。但是我知道我打开的信封中重复了多少次。如果有帮助的话，可以假设单个名字的最大出现次数比$N$小得多（&lt;1%）。
编辑 2：我想估计在任何信封中至少出现一次的名字总数。因此，如果信封包含 A、A、A、B、C，则将是 3 个名字。]]></description>
      <guid>https://stats.stackexchange.com/questions/660372/what-estimator-of-the-number-of-distinct-names-should-i-use</guid>
      <pubDate>Wed, 22 Jan 2025 11:25:23 GMT</pubDate>
    </item>
    </channel>
</rss>