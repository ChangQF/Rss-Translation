<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 28 Sep 2024 21:15:17 GMT</lastBuildDate>
    <item>
      <title>在线性混合效应模型中，随机效应的估计条件模式是否遵循 MVN？</title>
      <link>https://stats.stackexchange.com/questions/655058/do-estimated-conditional-modes-of-random-effects-follow-a-mvn-in-a-linear-mixed</link>
      <description><![CDATA[如果我们考虑由 Laird 和 Ware (1982) 提出的线性混合效应模型，模型中随机效应的条件均值（或众数）的估计值是否应遵循多元正态 (MVN) 分布？
这个问题与之前提出的问题不同（之前提出的问题为什么假设随机效应遵循正态分布）。]]></description>
      <guid>https://stats.stackexchange.com/questions/655058/do-estimated-conditional-modes-of-random-effects-follow-a-mvn-in-a-linear-mixed</guid>
      <pubDate>Sat, 28 Sep 2024 20:52:25 GMT</pubDate>
    </item>
    <item>
      <title>arima 模型和绘图之间存在差异</title>
      <link>https://stats.stackexchange.com/questions/655057/a-discrepancy-between-the-arima-model-and-plot</link>
      <description><![CDATA[我运行了 arima 模型并估算了拟合值。我在 arima 模型中的常数值为 153。由于时间变量 (t_centered) 以零为中心，因此常数表示零处的预测值。但是，时间中零处的红线徘徊在 185 左右。我只是想知道为什么 arima 模型的常数和时间中 0 处的绘制值之间存在差距。两者应该相似或相同。我的理解正确吗？
# 拟合 ARIMA 模型
arima(x = data[, &quot;dv&quot;], order = c(4, 0, 0), xreg = data[, c(&quot;t_centered &quot;, &quot; t_centered2&quot;, &quot;x1&quot;, &quot;t_centered_x1&quot;, &quot;t_centered2_x1&quot;, &quot;x2&quot;, &quot;x3&quot;, &quot;x4&quot;, &quot;x5&quot;)], include.mean = T)

# 估计拟合值
data$fitted_m_all = fitted(m_all)

# 绘制观察值和拟合值：
gall &lt;- ggplot(data, aes(x = t_centered, y = dv, color = x1) ) +
geom_point(color=“grey”,size=2.5) +
geom_smooth(method=“lm”, linewidth = 1.2, se=F, 
mapping=aes(y=fitted_m_all), formula=y~poly(x,2)) +
geom_vline(xintercept = 0, alpha = 1, 
linewidth = .5, linetype = “solid”, color=“black”) +
coord_cartesian(xlim = c(-30, 30), ylim = c(50, 250))+
theme_bw() + 
theme(legend.position=“none”)+
scale_colour_brewer(palette=“Set1”)+ 
labs(x = “Time”, y = &quot;Number&amp;;)
胆汁

]]></description>
      <guid>https://stats.stackexchange.com/questions/655057/a-discrepancy-between-the-arima-model-and-plot</guid>
      <pubDate>Sat, 28 Sep 2024 20:06:26 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯放射性碳测年法中不寻常的模型拟合度和收敛指标</title>
      <link>https://stats.stackexchange.com/questions/655056/unusual-model-fit-and-convergence-metrics-in-bayesian-radiocarbon-dating</link>
      <description><![CDATA[在考古学放射性碳测年中，贝叶斯方法基本上是唯一的方法。最常用的软件是 OxCal，虽然一般方法相当标准，但其模型诊断工具似乎相当独特。具体来说，我指的是一致性指数，它衡量先验和后验之间的兼容性，并用作模型拟合统计数据，以及收敛积分，据说可以测试 MCMC 算法的有效性。这两个指标都是在 OxCal 首个版本附带的论文中定义的（Bronk Ramsey 1995，引自下文第 429 页），但从未从理论上进行过激励，也从未与更典型的模型拟合或收敛统计数据相关联。

为了整合其他信息，OxCal 使用了一种称为 Gibbs Sampling 的技术，该技术涉及大量迭代。Buck 等人。 （1991）、Buck、Litton 和 Smith (1992) 和 Buck、Litton 和 Scott (1994) 对此进行了详细描述。我进行了扩展以改进模型一致性和收敛测试，这对于旨在公开发布的程序尤为重要。模型一致性测试基于一致性指数 $A$，对于先验分布 $p(t)$（考虑时间顺序模型之前的概率分布）和后验分布 $p&#39;(t)$（给定模型的分布），其定义为
$$
A = \frac{\int p(t) p&#39;(t) dt}{\int p(t) p(t) dt}
$$
合适的接受阈值约为 60%，其鉴别水平与 $\chi^2$ 测试的 5% 相似。还为整个模型定义了一个总体一致性指数，如下所示：
$$
A_{overall} = \left[ \prod_{i=1}^{n} A_{i} \right]^{\​​frac{1}{\sqrt{n}}}
$$
其中 $A_i$ 是 n 个事件中第 $i$ 个事件的一致性指数。该指数的阈值与此类似，为 60%。还需要进行收敛测试，以查看吉布斯抽样程序是否给出了真正具有代表性的结果。该程序使用累积概率分布 $P(t)$ 与最后一组迭代 $p(t)$ 之间的重叠积分 $C$ 执行此类测试
$$
C = \frac{ \left( \int p(t) P(t) dt \right)^2 }{ \int P^2(t) dt \int p^2 (t) dt }
$$
经验表明，如果该积分小于 95%，则算法可能不稳定，不应使用分析结果。吉布斯抽样对此类问题的另一个应用扩展是，在项目之间的年龄差距仅大致已知的情况下，纳入一种摆动匹配方法。

本文或（据我所知）其他地方没有给出进一步的解释。有谁知道更多关于这些指标背后的统计理论，以及为什么它们不用于其他领域？]]></description>
      <guid>https://stats.stackexchange.com/questions/655056/unusual-model-fit-and-convergence-metrics-in-bayesian-radiocarbon-dating</guid>
      <pubDate>Sat, 28 Sep 2024 20:04:04 GMT</pubDate>
    </item>
    <item>
      <title>这个实验设计叫什么？</title>
      <link>https://stats.stackexchange.com/questions/655055/what-is-this-experimental-design-called</link>
      <description><![CDATA[假设我从一个包含 2 种治疗方案的实验中收集数据：a_1 和 a_2。共有 3 个区块 b_1 至 b_3。
每个受试者只接受一种治疗（a_1 或 a_2，而不是两种）。
每个区块都接受两种治疗。
每种组合（受试者、区块、治疗）都会产生连续（时间）观察。



受试者
区块
治疗 a_1
治疗a_2




1
b_1
值



1
b_2
值



1
b_3
值



2
b_1

值


2
b_2

值


2
b_3

值



此表一直持续，直到覆盖所有受试者（人）。
我知道这不是 RCBD，因为并非每次都应用所有治疗。
这个实验设计的名称是什么？我需要找到一个公式来帮助计算样本量（尚未收集任何数据，这只是处于头脑风暴阶段）。]]></description>
      <guid>https://stats.stackexchange.com/questions/655055/what-is-this-experimental-design-called</guid>
      <pubDate>Sat, 28 Sep 2024 20:01:08 GMT</pubDate>
    </item>
    <item>
      <title>期望估计量的协方差矩阵</title>
      <link>https://stats.stackexchange.com/questions/655054/covariance-matrix-for-expectation-estimators</link>
      <description><![CDATA[我对一些物理量进行了测量，将它们表示为$x_1, \ldots, x_n$，并且我有一堆该数量的期望估计量
$\hat{x}_{k} = \frac{1}{k} \sum\limits_{i=1}^{k} x_i$，其中 k 从 1 到 n。
我想尝试从一组均值估计量中得出 BLUE（最佳线性无偏估计量），并将其与使用最大信息的估计量进行比较。
第一个问题，这些估计量的组合会比使用最大信息的估计量更好吗？为什么？
第二个问题，我知道建立 BLUE 估计量需要协方差矩阵，但是，对于这里的每个估计量，我们使用不同的样本大小，这使得协方差的计算变得不可能，有什么办法可以解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655054/covariance-matrix-for-expectation-estimators</guid>
      <pubDate>Sat, 28 Sep 2024 18:33:02 GMT</pubDate>
    </item>
    <item>
      <title>理解为什么 beta 分布适合我的数据</title>
      <link>https://stats.stackexchange.com/questions/655050/understanding-why-a-beta-distribution-fits-to-my-data</link>
      <description><![CDATA[显然，我的统计知识遇到了一些我无法理解的问题。
我有一组数据，基本上应该将图像分类为二元分类（假设年轻和年老，为了进一步讨论，我将它们标记为 0 和 1）。
不幸的是，我应该处理的这个数据集是一个直方图，x 轴是两个二元结果的（几乎）连续分数。例如，有数据点在 bin 0.65 中。我会将其解释为更多人在调查中表示该图像属于分类 1。
有趣的是，我是 beta 分布的新手，我拥有的数据与参数为 5.94 和 2.42 的 beta 分布非常吻合。
在过去几周里，我阅读了很多关于统计学、beta 分布和二项式联系的文章，但这完全令人费解。我真的很想知道为什么我得到的这个数据集显然遵循 beta 分布。
到目前为止，我的想法是，我有 n 张图像，对于每张图像，假设我有 k 个人问他们这个问题：“这张图片属于 0 类还是 1 类”。由于我现在对每张图片都有 k 个答案，我可以理解为什么结果会有分数（介于 0 和 1 之间，而不仅仅是 0 和 1）。我也可以理解这个问题可能遵循二项分布 - 但为什么结果遵循 beta 分布而不是二项分布？
我知道对于有经验的人来说这可能是一个简单的问题，但我到目前为止还没有接触过这些问题，并且想学习。
非常感谢您的见解]]></description>
      <guid>https://stats.stackexchange.com/questions/655050/understanding-why-a-beta-distribution-fits-to-my-data</guid>
      <pubDate>Sat, 28 Sep 2024 15:56:07 GMT</pubDate>
    </item>
    <item>
      <title>平衡协变量与 OLS 回归中无偏估计的相关性</title>
      <link>https://stats.stackexchange.com/questions/655049/relevance-of-balanced-covariates-for-unbiased-estimates-in-ols-regression</link>
      <description><![CDATA[在我所从事的经济学领域，我遇到的许多论文都严重依赖观察数据进行分析。然而，我注意到，研究人员很少明确指出其回归模型中的协变量或“控制变量”在治疗组和对照组之间是否平衡。
例如，考虑一项研究，该研究考察了研发 (R&amp;D) 支出对公司绩效的影响。通常，研究人员会收集被认为会影响绩效的各种公司特征的数据，并将其用作控制变量。然而，除了其他潜在偏见之外，人们似乎很少关注这些控制变量在从事研发的公司和不从事研发的公司之间是否平衡。研究人员似乎更专注于包括控制，而不是确保平衡。
最近，我偶然发现了一篇采用不同方法的论文。它研究了创始人的性别对因变量 Y 的影响。作者通过使用倾向得分匹配来解决潜在的协变量不平衡问题。他们创建了一个匹配样本，其中控制变量在拥有男性和女性创始人的公司之间没有显著差异，从而确保了两组之间的可比性。这似乎是一种处理潜在混杂因素的更严格的方法，我在其他研究中很少看到这种方法被应用。
回归中不平衡的协变量是否会引起偏差，或者为什么实现平衡是有利的？从理论上讲，回归模型考虑了控制变量的差异，但也许不平衡​​可能会导致更微妙的偏差或效率低下，而匹配方法可以更有效地解决这些问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/655049/relevance-of-balanced-covariates-for-unbiased-estimates-in-ols-regression</guid>
      <pubDate>Sat, 28 Sep 2024 15:13:55 GMT</pubDate>
    </item>
    <item>
      <title>本科生学习随机过程的书籍/课程</title>
      <link>https://stats.stackexchange.com/questions/655045/book-course-for-undergraduates-to-learn-stochastic-processes</link>
      <description><![CDATA[目前，我正在阅读有关去噪扩散概率模型的文章。我第一次听说 DDPM 的想法时，我在想“这是不可能的！至少在使用计算器实现时，因为我们以位的形式存储浮点数的方式存在限制。所以，当添加这么多噪音时，信息肯定全部丢失了，那么我们如何才能逆转它呢？”。
从这个角度看 DDPM 对理解没有好处。我注意到有一种叫做“SDE 和逆 SDE”的东西，这让我想到了随机过程，我想这就是我所有问题的答案。
不幸的是，微积分、线性代数和概率在我所在的大学里都是在非常基础的水平上教授的，所以尽管我尝试搜索和阅读了很多，但似乎所有资源都需要更高水平的理解。例如，我遇到了许多不熟悉的术语，如$\sigma$-代数、测量理论等...
有没有适合我的理解水平的材料？]]></description>
      <guid>https://stats.stackexchange.com/questions/655045/book-course-for-undergraduates-to-learn-stochastic-processes</guid>
      <pubDate>Sat, 28 Sep 2024 12:51:16 GMT</pubDate>
    </item>
    <item>
      <title>ECT 系数的 VECM 分析解释</title>
      <link>https://stats.stackexchange.com/questions/655040/vecm-analysis-interpretation-of-ect-coefficients</link>
      <description><![CDATA[我可以说 ect1 很重要，因为 91.42％ 的值在一个时期后恢复到平衡状态吗？即使 ect1 的结果合乎逻辑，我也不确定我是否可以做出任何可靠的解释，因为 ect2-8 的值不合逻辑，并且模型发现其中一些值很重要。
结果：
ect1 = -9.142e-01***
ect2 = 5.191e+01***
ect3 = -3.894e+00***
ect4 = -4.152e+00**
ect5 = 1.302e+00
ect6 = 6.827e+01
ect7 = 1.408e+01***
ect8 = 1.292e+04
模型多重 R 平方： 0.5309
我可以从这个模型中对 ect1 做出解释吗？或者鉴于模型结果，整个模型不可靠吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655040/vecm-analysis-interpretation-of-ect-coefficients</guid>
      <pubDate>Sat, 28 Sep 2024 10:13:02 GMT</pubDate>
    </item>
    <item>
      <title>如何操作 nlme 模型中的交叉和嵌套随机效应</title>
      <link>https://stats.stackexchange.com/questions/655051/how-to-manipulate-crossed-and-nested-random-effects-in-nlme-model</link>
      <description><![CDATA[我看过一些关于此问题的旧帖子，但我真的很挣扎。我正在拟合营养数据，我认为我的数据太大，无法发布，我尝试对数据进行子采样，以便在此处发布一个可行的示例，但当我减少数据时，模型无法运行。我正在使用这个威布尔函数，因为我通过 drm 分析确定它最适合我的数据。它看起来像这样：

数据包括 4 个地点 3 年内 4 棵树生长季节时间序列中不同树种/品种（不同点形状）的叶子中的营养浓度。在考虑随机效应并将模型移至 nlme 以解释它们时，我遇到了挑战。我认为应该将年份视为交叉随机效应，因为我在所有年份都使用了相同的站点/树。树应该嵌套在每个站点中，因为每个站点都采样了相同的 4 棵树（但每个站点的树都不同）。我知道设置交叉和嵌套的随机因素很有挑战性，我已经阅读了关于此问题的六篇帖子。从这个模型开始，我得到了嵌套在站点中的树的随机效应结果，结果是合理的，但我知道年份很重要：
m1 &lt;- nlme(
Nutrient ~ W1.4_function(Time, b, c, d, e), # 使用预定义的 W1.4 函数
data = data,
fixed = b + c + d + e ~ 1, # 所有参数的固定效应
random = b + c + e ~ 1 | Site/Tree, # 嵌套在站点中的树
start = start_values, # 使用优化的起始值
control = nlmeControl(msMaxIter = 200, opt = &quot;nlm&quot;) 
)

我不希望对威布尔参数 d 产生随机效应。当我像这样构建随机效应时，AIC 从 130 降至 -90：
m2 = nlme(
Nutrient ~ W1.4_function(Time, b, c, d, e), # 使用 W1.4 函数进行建模
data = data,
fixed = b + c + d + e ~ 1, # 所有参数的固定效应
random = list(Year = pdIdent(b + c + e ~ 1), # 年份作为交叉随机效应
Site = pdDiag(b + c + e ~ 1), # 
Tree = pdDiag(b + c + e ~ 1)), # 嵌套在站点内的树
start = start_values, # 使用优化的起始值
control = nlmeControl(msMaxIter = 200, opt = &quot;nlm&quot;) # 增加最大迭代次数

)
现在组是：
组数：
年份 站点 %in% 年份
3 12
树 %in% 站点 %in% 年份
32

现在看来，我有年份作为交叉效应，但也有嵌套在年份中的站点和嵌套在年份中的站点中的树。我并没有打算在年份中嵌套站点或树。我知道我需要使用 pdBlocked 和 pdDiag 来以某种方式获得交叉和嵌套的随机效应？我最好转向 lme4 方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655051/how-to-manipulate-crossed-and-nested-random-effects-in-nlme-model</guid>
      <pubDate>Fri, 27 Sep 2024 23:32:32 GMT</pubDate>
    </item>
    <item>
      <title>协变量斜率系数的多元回归置信区间</title>
      <link>https://stats.stackexchange.com/questions/655026/multiple-regression-confidence-intervals-for-slope-coefficient-of-a-covariate</link>
      <description><![CDATA[在构建这样的置信区间并评估其是否包含 0（用于 t 检验以查看协变量是否与回归相关）时，其他变量是否在某些水平上受到控制或保持不变（它们的平均值？）
Wackerley、Mendenhall 和 Schaffer 有以下问题。
考虑一般线性模型
$$Y = \beta_0 + \beta_1 x_1 + ... + \beta_k x_k + \epsilon$$
其中 $E(\epsilon) = 0$ 和 $V(\epsilon) = 0$。然后，他们要求验证 $E(\hat{\beta}_i) = \beta_i$ 和 $V(\hat{\beta}_i) = c_{ii}\sigma^2$，其中 $c_{ii}$ 是 $(X&#39;X)^{-1}$ 行 $i$ 和列 $i$ 中的元素
因此，在构建 $\beta_i$ 的 $100(1-\alpha)\%$ 置信区间时，他们有：$\hat{\beta}_i \pm t^{n-k-1}_{\frac{\alpha}{2}} S \sqrt{c_{ii}} $。这个区间的准确解释是什么，特别是当它与其他变量的情况相关时——它们是固定的还是在某种意义上受控制的？
我的问题出现是因为在陈述假设检验（t 检验以查看协变量是否显着）时，他们只陈述：
$$H_0: \beta_i = 0$$
$$H_a: \beta_i \neq 0$$
没有明确说明此测试是否控制其他变量或在某种程度上固定它们。执行此测试时其他变量究竟发生了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655026/multiple-regression-confidence-intervals-for-slope-coefficient-of-a-covariate</guid>
      <pubDate>Fri, 27 Sep 2024 19:16:42 GMT</pubDate>
    </item>
    <item>
      <title>GAM 中的高 GVIF</title>
      <link>https://stats.stackexchange.com/questions/655021/high-gvif-in-gam</link>
      <description><![CDATA[我的 GVIF 一直很高（带有 INF），在进行 GAM 分析后，我合并了大多数分类变量的级别。我还删除了一些变量，但 GVIF 仍然很高。请帮忙。下面是我的代码，我是新手，所以我的代码可能看起来有些奇怪。我只对我的连续变量应用了平滑处理。
gam_model &lt;- gam(log_HDDS~ s(log_obesogenic_share, k = 10) + 
s(sec_asset, k = 12) + 
s(SSIrecalcrounded, k = 7) +
s(House_h_age, k =8) +
s(time_to_clst_mrkt, k = 7) +
s(hh_mem_no, k = 7) +
s(educ, k = 7) +
factor(buying_food_who_grouped) +
factor(Marital_status) +
factor(loan) +
factor(ration_card_grouped) +
factor(main_occ_grouped) +
factor(Caste_Grouped) +
factor(transect_id) ,
family = gaussian(link = &quot;identity&quot;),
method = &quot;REML&quot;, 
select = TRUE, 
paraPen = list(log_obesogenic_share =list(diag(1)),
sec_asset= list(diag(1)),
SSIrecalcrounded = list(diag(1)),
House_h_age = list(diag(1)),
time_to_clst_mrkt = list(diag(1)),
hh_mem_no = list(diag(1)),
educ= list(diag(1))), 
data = diet_data)

这是我的 GVIF 结果：
vif(gam_model)
GVIF Df GVIF^(1/(2*Df))
factor(buying_food_who_grouped) 1.025172e+25 0 Inf
因素（婚姻状况） 1.025172e+25 0 Inf
因素（贷款） 1.025172e+25 0 Inf
因素（配给卡分组） 1.025172e+25 0 Inf
因素（主要人口分组） 1.025172e+25 0 Inf
因素（种姓分组） 1.025172e+25 0 Inf
因素（横断面 ID） 1.025172e+25 0 Inf
log_obesogenic_share 1.025172e+25 0 Inf
sec_asset 1.025172e+25 0 Inf
SSIrecalcrounded 1.025172e+25 0 Inf
House_h_age 1.025172e+25 0 Inf
time_to_clst_mrkt 1.025172e+25 0 Inf
hh_mem_no 1.025172e+25 0 Inf
educ 1.025172e+25 0 Inf
]]></description>
      <guid>https://stats.stackexchange.com/questions/655021/high-gvif-in-gam</guid>
      <pubDate>Fri, 27 Sep 2024 16:28:06 GMT</pubDate>
    </item>
    <item>
      <title>使用 simr 计算线性混合模型中计划对比的功率和样本大小？</title>
      <link>https://stats.stackexchange.com/questions/654818/calculate-power-and-sample-size-for-planned-contrasts-in-linear-mixed-models-usi</link>
      <description><![CDATA[我使用 lmerTest 包在 R 中建立了一个线性混合模型，其中有三个分类因子（A 有 3 个级别，B 有 8 个级别，C 有 2 个级别）和一个针对主题的随机效应。我有兴趣使用 simr 对 B 的两个特定计划水平对比进行功效分析。可以吗？
例如，我们分别用 B1、B2、B3 和 B4 表示因子 B 的水平 1、2、3、4，用 A1 表示因子 A 的水平 1。我们需要以下对比的功效。

比较 B1 和 B2，比较 B3 和 B4，控制所有其他变量（如果模型不包含交互项）
比较 B1 和 B2，并在特定 A 水平 A2 比较 B3 和 B4（如果考虑 A 和 B 之间的交互）

我理解 simr 可以模拟模型中所有固定效应的功效和样本大小，因此我们可以通过将 B 的参考水平设置为 B1 来将 B1 与 B 的所有其他水平进行比较。但我不确定如何设置它来计算上述特定对比的功效。我也知道 emmeans 可以设置和计算事后对比，但有没有办法将它与 simr 集成以进行功效分析和大小调整？如果没有，那么适当的方法是什么？
有人可以分享使用 simr 模拟这些计划对比的功效和样本大小的经验吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654818/calculate-power-and-sample-size-for-planned-contrasts-in-linear-mixed-models-usi</guid>
      <pubDate>Tue, 24 Sep 2024 03:16:21 GMT</pubDate>
    </item>
    <item>
      <title>这是对最大似然渐近偏差的正确解释吗？</title>
      <link>https://stats.stackexchange.com/questions/632156/is-this-a-correct-explanation-of-the-asymptotic-bias-of-maximum-likelihood</link>
      <description><![CDATA[我想确保我理解了，所以请批评以下内容：
在常规参数统计模型中，非线性最大似然估计是有偏差的。给定一些数据$y_i$、参数$x_k$，$\beta$的最大似然估计是$\beta$的值，该值最大化
\begin{equation*}
\prod_{i=1}^nf(y_i|x_k; \beta)\hspace{0.3cm} \text{or}\hspace{0.2cm} \sum_{i=1}^n \ln f(y_i|x_k; \beta)。
\end{equation*&gt;
将对数似然表示为
\begin{equation*}
l(\beta) = \sum_{i=1}^n \ln f(y_i|x_k; \beta)。
\end{equation*&gt;
估计的对数似然为
\begin{equation*}
l_n(\beta) = \frac{1}{n}\sum_{i=1}^n \ln f(y_i|x_k; \beta),
\end{equation*&gt;
最大似然估计是将分数设置为零的解
\begin{equation*}
\frac{\partial l_n(\hat{\beta)}}{\partial \beta}= \sum_{i=1}^n l&#39;_n(\beta)=\frac{1}{n}\sum_{i=1}^n l&#39;(\beta)=0。
\end{equation*
显然$l_n(\beta)$及其导数的尺度为$1/n$，因此可以写成$1/n$的幂级数。对真值进行泰勒展开 $\beta$
\begin{equation*}
\frac{\partial l_n(\hat{\beta)}}{\partial \beta} = \sum_{i=1}^n \frac{\partial l(\beta)}{\partial \beta_r} + (\hat{\beta}_s-\beta_s)\frac{\partial^2 l(\beta)}{\partial\beta_r\partial\beta_s} + \frac{1}{2}(\hat{\beta}_t - \beta_t)(\hat{\beta}_u - \beta_u)\frac{\partial^3l(\beta)}{\partial\beta_r\partial\beta_t\partial\beta_u} + ... =0。
\end{equation*&gt;
最大似然估计$\hat{\beta}$的偏差定义为$b(\beta)=\mathbb{E}(​​\hat{\beta} - \beta)$，因此渐近偏差可以写成
\begin{equation*}
b(\beta) = \frac{b_1(\beta)}{n} + \frac{b_2(\beta)}{n^2} + \frac{b_3(\beta)}{n^3} + ...,
\end{equation*&gt;
其中$n$是样本大小，假设相对于参数数量较大，$k$.]]></description>
      <guid>https://stats.stackexchange.com/questions/632156/is-this-a-correct-explanation-of-the-asymptotic-bias-of-maximum-likelihood</guid>
      <pubDate>Thu, 23 Nov 2023 12:00:22 GMT</pubDate>
    </item>
    <item>
      <title>什么时候 SEM 与多元回归相比几乎没有优势，并且两种方法之间没有区别？</title>
      <link>https://stats.stackexchange.com/questions/631610/when-does-sem-have-little-to-no-benefit-over-multiple-regression-and-there-is-a</link>
      <description><![CDATA[我对 SEM 及其相对于多元回归的优势的理解是：

模型比较：约束路径，或固定其他估计值的路径，或指定其他可能的模型以查看哪个更适合数据
多变量：与多元回归不同，SEM 可以同时估计多个结果
结合测量和结构模型：您可以同时估计潜在变量及其之间的因果关系
无误差：SEM 使用潜在变量模型来解释测量误差，在估计潜在变量得分时将误差/未解释的方差与观测变量中的共享/共同方差分开

这是我对 SEM 相对于多元回归在特定应用中的一些主要优势的粗略理解。话虽如此，如果有人采用一组 20 个基于调查的量表/构造测量，将它们作为 20 个潜在变量放入 SEM 中，预测另一份问卷是潜在变量，然后就此止步，我认为这与多元回归相比几乎没有什么优势。它不涉及模型比较（不限制路径，不测试替代模型），也不是多变量的（即，它只有一个结果）。我认为通过在测量模型中分离测量误差和共同方差来估计“无误差”潜在变量具有潜在优势。这是主要的好处吗？
我知道像这样的论文，它们表明称多元回归和 SEM 等同是一种神话，但我发现这对于没有模型比较的单变量回归案例来说可能难以信服。在这种情况下，推论似乎应该有效相同，即一堆综合分数预测单一结果。
我的问题大致是——SEM 何时与多元回归相比几乎没有优势，何时这种区别没有太大区别？此外，SEM 增加的混淆和复杂性何时比更简单、更容易理解的多元回归模型（例如单变量情况）几乎没有好处？
参考文献：
https://www.researchgate.net/post/What-is-the-difference-between-a-regression-analysis-and-SEM#:~:text=While%2C%20multiple%20regression%20is%20observed,based%20and%20variance%2Dbased%20methods.
http://faculty.cas.usf.edu/mbrannick/regression/SEM.html
SEM 中的回归程序与 SPSS 等统计软件包中的回归分析
https://www.quora.com/Which-is-better-regression-or-structural-equation-modeling-and-why
https://www.statisticssolutions.com/advantages-of-sem-over-regression/
https://www.youtube.com/watch?v=wHFrgp3SQMI&amp;t=67s]]></description>
      <guid>https://stats.stackexchange.com/questions/631610/when-does-sem-have-little-to-no-benefit-over-multiple-regression-and-there-is-a</guid>
      <pubDate>Fri, 17 Nov 2023 14:01:51 GMT</pubDate>
    </item>
    </channel>
</rss>