<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 08 Dec 2024 09:17:19 GMT</lastBuildDate>
    <item>
      <title>使用调查平均值从单个预测中得出估计值的难度</title>
      <link>https://stats.stackexchange.com/questions/658440/difficulty-in-deriving-a-estimator-using-survey-means-from-individual-forecasts</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658440/difficulty-in-deriving-a-estimator-using-survey-means-from-individual-forecasts</guid>
      <pubDate>Sun, 08 Dec 2024 07:58:33 GMT</pubDate>
    </item>
    <item>
      <title>我可以在 Cox PH 中使用年龄作为随时间变化的协变量吗？</title>
      <link>https://stats.stackexchange.com/questions/658439/can-i-use-age-as-a-time-varying-covariate-in-a-cox-ph</link>
      <description><![CDATA[我正在研究叛乱团体领导人在被迫下台之前会掌管叛乱团体多长时间。我有领导人年份数据，其中包含以下变量：

groupid = 每个团体的唯一 ID 号
leaderid = 每个领导人的唯一 ID 号
tenure = 领导人首次掌权以来的时间（从 0 开始计数）
forcedexit = 领导人被迫下台时取值为 1，其他年份取值为 0
groupage = 团体成立以来的时间（从 0 开始计数）

我的数据集中，叛乱团体活跃的每一年都有一行。数据通常如下所示：
 groupid leaderid forcedexit tenure groupage
&lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1 411 1 0 0 0
2 411 1 0 1 1
3 411 1 0 2 2
4 411 2 1 0 3
5 411 2 0 1 4
6 411 2 0 2 5
7 411 2 0 3 6
8 411 3 0 0 7
9 411 3 0 1 8
10 411 3 0 2 9

请注意，新领导人可以通过强制退出以外的方式上台，因此即使 forcedexit = 0，领导人也可能离职（例如，参见上述数据中的 leaderid = 3）。
我想测试一下在较老的群体中，领导人是否更难被罢免。我的直觉是运行 Cox PH 模型（我使用的是 R）：
mod &lt;- coxph(Surv(tenure, forcedexit) ~ groupage, data = df)
如果我运行这个，我会得到 groupage 系数的负且显著的估计值，这与我的直觉一致。但是，出于两个原因，我对这个结果持谨慎态度。
首先，我可以在 Cox PH 中使用 groupage 作为随时间变化的变量吗？我读过的大多数使用 Cox PH 的医学研究都使用不会随时间变化的年龄变量（例如，试验开始时的年龄）。我的 groupage 变量确实会随时间而变化。
其次，我担心 groupage 和 tenure 变量之间的关系出现了一些问题。某些 tenure 值在 groupage 的某些值下不可能存在。例如，tenure = 5 和 groupage = 0 永远不可能存在，因为必须存在该组才能由领导者负责。因此，较高的 groupage 值可能与较高的 tenure 值一起机械地出现。如果领导者要拥有较长的 tenure，则 groupage 也必须很长。
对这两个问题的任何想法都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658439/can-i-use-age-as-a-time-varying-covariate-in-a-cox-ph</guid>
      <pubDate>Sun, 08 Dec 2024 05:02:32 GMT</pubDate>
    </item>
    <item>
      <title>标准化回归模型的变量与回归模型中的权重？</title>
      <link>https://stats.stackexchange.com/questions/658437/standardizing-variables-for-a-regression-model-vs-weights-in-a-regression-model</link>
      <description><![CDATA[我在 R 中有一个纵向 GAM（一般加性模型）回归。
以下是模型和数据的一般形式（响应介于 0 和 1 之间）：
gam_model &lt;- gam(
response ~ 
te(time_var, var1) +
te(time_var, var2) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

state time_varpopulation var1 var2 response
state_1 2005-01-01 1000000 500000 10000 0.45
state_1 2005-02-01 1001000 520000 12000 0.47
state_1 2005-03-01 1002001 540000 11000 0.46
state_1 2005-04-01 1003002 560000 13000 0.48
state_2 2005-01-01 200000 100000 2000 0.42
state_2 2005-02-01 200200 105000 2400 0.44
state_2 2005-03-01 200400 110000 2200 0.43
state_2 2005-04-01 200600 115000 2600 0.45

我遇到的问题如下：

数据按州提供（多个州，1 个国家），但每个州的人口不同
这让我认为需要对模型进行一些处理，以防止人口较多的州对响应的影响比人口较少的州更大
我有每个州的人口

我正在考虑使用以下权重公式（我从这里得到这个想法https://www.nature.com/articles/s41598-024-54441-x）：
$$avg\_weight_s = \frac{1}{T}\sum_{t=1}^{T} \frac{\ln(population_{s,t})}{\frac{1}{N}\sum_{i=1}^{N} \ln(population_{i,t})}$$
其中：

$T$ 是时间段的总数
$N$ 是州的总数
$population_{s,t}$ 是 $t$ 时刻 $s$ 州的人口数
$population_{i,t}$ 表示每个州 $i$ 在时间 $t$ 的人口。

这让我考虑不同的模型选项：
# 选项 1：非标准化，无权重

gam_model &lt;- gam(
response ~ 
te(time_var, var1) +
te(time_var, var2) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

# 选项 2：标准化，无权重

gam_model &lt;- gam(
响应 ~ 
te(time_var, var1/population) +
te(time_var, var2/population) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

# 选项 3：未标准化，权重

gam_model &lt;- gam(
响应 ~ 
te(time_var, var1) +
te(time_var, var2) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
weights = avg_weight,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

# 选项 4：标准化，权重

gam_model &lt;- gam(
response ~ 
te(time_var, var1/population) +
te(time_var, var2/population) +
s(time_var, by = state) +
s(state, bs = &quot;re&quot;),
data = sample_data,
weights = avg_weight,
method = &quot;REML&quot;,
family = betar(link = &quot;logit&quot;)
)

我有点困惑，不知道这些选项中哪一个在逻辑上是正确的。我认为其中一些可能有点过度，而另一些则完全不正确。有办法解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658437/standardizing-variables-for-a-regression-model-vs-weights-in-a-regression-model</guid>
      <pubDate>Sun, 08 Dec 2024 04:38:44 GMT</pubDate>
    </item>
    <item>
      <title>带有 Adam 优化器网络的单层/单单元如何工作？</title>
      <link>https://stats.stackexchange.com/questions/658436/how-does-a-single-layer-single-unit-with-adam-optimizer-network-work</link>
      <description><![CDATA[我对 ML 还很陌生，正在尝试使用线性回归。我测试了 sklearn 的 LinearRegression 模型，然后想将结果与一个非常简单的神经网络进行比较。
我创建了一个具有 1 层和 1 个单元的 tensorflow Dense 网络，并带有“线性”激活函数。
我使用了“sgd”和“adam”优化器，并使用 MinMaxScaler 缩放了 x 数据
我得到了与 LinearRegression 模型截然不同的结果（预测和损失）。
我有两个问题：

具有线性激活的 1 层/1 个单元网络是否与 LinearRegression 相同？

SGD 预测非常接近，我正在用房价进行测试，所以我会得到相对接近的结果。目标值在 1000 左右，因此 y_train 数组中的 120,000 美元价格被设置为 120。但是，当我使用 Adam 优化器时，我得到的预测值非常低（不到 20）。我从 100 个 epoch 开始，然后增加到 1000 个，但仍然得到了类似的结果。我是不是在某个地方做错了什么，或者 Adam 优化器是否有限制或某些要求才能正常工作。

]]></description>
      <guid>https://stats.stackexchange.com/questions/658436/how-does-a-single-layer-single-unit-with-adam-optimizer-network-work</guid>
      <pubDate>Sun, 08 Dec 2024 03:47:10 GMT</pubDate>
    </item>
    <item>
      <title>当网络的接近中心性较低时会发生什么 - 外围节点会发生什么</title>
      <link>https://stats.stackexchange.com/questions/658435/what-happens-when-a-network-has-low-closeness-centrality-what-happens-to-nodes</link>
      <description><![CDATA[我有三十九个具有接近中心性得分的节点，但我不知道该如何处理没有得分的外围节点。]]></description>
      <guid>https://stats.stackexchange.com/questions/658435/what-happens-when-a-network-has-low-closeness-centrality-what-happens-to-nodes</guid>
      <pubDate>Sun, 08 Dec 2024 03:05:57 GMT</pubDate>
    </item>
    <item>
      <title>多重比较和交互图</title>
      <link>https://stats.stackexchange.com/questions/658430/multi-comparasion-and-interaction-plot</link>
      <description><![CDATA[我进行了 Kruskal Wallis 检验，以检查 2 个分类变量（独立变量）是否对 1 个连续变量有影响。在获得显著的 p 值后，我进行了事后检验。为了查看两个独立变量对因变量的相互作用，我绘制了相互作用图，但我不确定我的结果是否良好？或者我的策略是否让我得到错误的结果？

这是 colab，您可以在其中查看我的代码：
https://colab.research.google.com/drive/1OlTbHldb3guUTk-LEGRBlriSLi6O8RSw?usp=sharing]]></description>
      <guid>https://stats.stackexchange.com/questions/658430/multi-comparasion-and-interaction-plot</guid>
      <pubDate>Sun, 08 Dec 2024 00:10:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么在无监督学习中损失不被视为“监督信号”？</title>
      <link>https://stats.stackexchange.com/questions/658428/why-the-loss-is-not-considered-as-a-supervisory-signal-in-unsupervised-learnin</link>
      <description><![CDATA[据说监督学习与无监督学习的区别在于“监督信号”的存在，也就是标签。
然而，在这两种情况下，我们都有一个损失函数。损失难道不是一种引导优化和学习过程的“监督信号”吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658428/why-the-loss-is-not-considered-as-a-supervisory-signal-in-unsupervised-learnin</guid>
      <pubDate>Sat, 07 Dec 2024 22:00:31 GMT</pubDate>
    </item>
    <item>
      <title>适合的统计检验</title>
      <link>https://stats.stackexchange.com/questions/658420/suitable-statistical-test</link>
      <description><![CDATA[我有 2 个组 - 曾经在我的网站上活跃的人和从未活跃的人。活动是基于某些操作的指标 - 两组人都访问了网站。
每个组在网站上的第一周使用了一组功能（它是一种平台，人们是用户），我想知道哪些功能与“变得活跃”相关。
例如：
100 个活跃的人中有 20 个在该组中使用了功能 A 100 次，而总共使用了 3000 次功能。
在 50 位从未活跃过的用户中，有 3 位使用了功能 A，总共使用了 1500 次。



曾活跃
功能
使用的帐户
帐户总数
使用的功能
功能总使用量




1
A
20
100
100
3000


0
A
3
50
20
1500



我还可以添加特征使用情况的方差和标准差。
我可以在这里做什么测试来表明使用特征 A 的人与活跃度的相关性明显更高？
此外，它对账户比例本身进行任何测试并使用该测试声称特征 A 与活跃度显著相关是否有意义？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658420/suitable-statistical-test</guid>
      <pubDate>Sat, 07 Dec 2024 18:45:42 GMT</pubDate>
    </item>
    <item>
      <title>如果异常值少于数据点的 10％，您可以删除它们吗？</title>
      <link>https://stats.stackexchange.com/questions/658405/can-you-remove-outliers-if-they-are-less-than-10-of-the-datapoints</link>
      <description><![CDATA[我目前正在上我的第一堂数据分析课，我们会做一些简单的假设检验，比如 t 检验等。我们的老师告诉我们，只要异常值不超过样本量 n 的 10%，我们就可以删除它们。这准确吗？在我看来，这太过方法论化了，我不明白为什么我们要处理这样的每种情况。一般方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658405/can-you-remove-outliers-if-they-are-less-than-10-of-the-datapoints</guid>
      <pubDate>Sat, 07 Dec 2024 10:22:05 GMT</pubDate>
    </item>
    <item>
      <title>我对计数问题的解答可以被纠正吗？</title>
      <link>https://stats.stackexchange.com/questions/658393/can-my-solution-to-a-counting-problem-be-corrected</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658393/can-my-solution-to-a-counting-problem-be-corrected</guid>
      <pubDate>Fri, 06 Dec 2024 21:51:24 GMT</pubDate>
    </item>
    <item>
      <title>meta 与 metafor 对比例的三级荟萃分析结果不同</title>
      <link>https://stats.stackexchange.com/questions/658385/different-results-meta-vs-metafor-for-three-level-meta-analysis-of-proportions</link>
      <description><![CDATA[R 包“meta”有一个函数“metaprop”，用于对比例进行荟萃分析，参数“cluster”允许进行三级荟萃分析。R 文档（版本 8.0-1）对此进行了如下描述：

如果使用参数 cluster 并且至少一个 cluster 提供多个估计值，则使用三级随机效应荟萃分析模型 (Van den Noortgate et al., 2013)。在内部，调用 rma.mv 进行分析，并使用参数 type = &quot;rowsum&quot; 的 weights.rma.mv 计算随机效应权重。

函数“rma.mv”来自包“metafor”，有更多用于比较子组等的选项。所以我尝试直接在“metafor”中复制结果。虽然我可以复制点估计，但合并标准误差会存在细微差异（因此置信区间也不同）。有人知道是什么导致了这种差异吗？
我在下面提供了一个可重现的示例。
# 加载 R 包
library(meta) #version 8.0-1
library(metafor) #version 4.6-0

# 示例数据集
df &lt;- data.frame(
id = c(1:10),
study = c(&quot;A et al&quot;, &quot;A et al&quot;, &quot;B et al&quot;, &quot;B et al&quot;, &quot;C et al&quot;, &quot;C et al&quot;, 
&quot;D et al&quot;, &quot;D et al&quot;, &quot;E et al&quot;, &quot;E et al&quot;),
n_positive = c(51, 103, 122, 201, 160, 112, 6211, 6187, 2339, 2470),
n_total = c(124, 140, 306, 311, 229, 219, 13597, 12868, 5070, 5809) )
df &lt;- escalc(xi = n_positive, ni = n_total, measure = &quot;PLO&quot;, data = df)

# 使用 metaprop 进行分析
metaprop1 &lt;- metaprop(event = n_positive, n = n_total, cluster = study, data = df)
# 使用 rma.mv 进行分析
rma.mv1 &lt;- rma.mv(yi = yi, V = vi, random = ~ 1 | study/id, data = df)
# 使用 metaprop 进行分析rma.mv &amp; 与 metaprop 中相同的研究权重
rma.mv2 &lt;- rma.mv(yi = yi, V = vi, random = ~ 1 | study/id, data = df, W = metaprop1[[&quot;w.random&quot;]])

# 汇总估计值比较（以 logit 形式）
paste(metaprop1[[&quot;TE.random&quot;]], metaprop1[[&quot;seTE.random&quot;]])
# 0.0899361424942118 0.150816619366075
paste(rma.mv1[[&quot;beta&quot;]], rma.mv1[[&quot;se&quot;]])
# 0.0913959137416219 0.159661208321448
paste(rma.mv2[[&quot;beta&quot;]], rma.mv2[[&quot;se&quot;]])
# 0.0899361424942119 0.159663991953103

# 尽管产生了不同的合并 SE 
# metaprop 和 rma.mv 都使用了相同的研究方差，最多精确到 16 位小数 
summary( round(df$vi, 16) == round(metaprop1[[&quot;seTE&quot;]]^2, 16) )
# 对所有 10 个估计值都为 TRUE

P.S.以下是汇总结果以 95% 置信区间的比例表示。
# 汇总结果转换为具有 95% 置信区间的比例
paste0(
round( logit2p( metaprop1[[&quot;TE.random&quot;]]), 3)*100, &quot;% (&quot;,
round( logit2p( metaprop1[[&quot;TE.random&quot;]] - 1.96*metaprop1[[&quot;seTE.random&quot;]] ), 3)*100, &quot;% to &quot;,
round( logit2p( metaprop1[[&quot;TE.random&quot;]] + 1.96*metaprop1[[&quot;seTE.random&quot;]] ), 3)*100, &quot;%)&quot; )
# &quot;52.2% (44.9% 至 59.5%)&quot;
paste0(
round( logit2p( rma.mv1[[&quot;beta&quot;]]), 3)*100, &quot;% (&quot;,
round( logit2p( rma.mv1[[&quot;beta&quot;]] - 1.96*rma.mv1[[&quot;se&quot;]] ), 3)*100, &quot;% 至 &quot;,
round( logit2p( rma.mv1[[&quot;beta&quot;]] + 1.96*rma.mv1[[&quot;se&quot;]] ), 3)*100, &quot;%)&quot; )
# &quot;52.3% (44.5% 至 60%)&quot;
paste0(
round( logit2p( rma.mv2[[&quot;beta&quot;]]), 3)*100, &quot;% (&quot;,
round( logit2p( rma.mv2[[&quot;beta&quot;]] - 1.96*rma.mv2[[&quot;se&quot;]] ), 3)*100, &quot;% 至 &quot;,
round( logit2p( rma.mv2[[&quot;beta&quot;]] + 1.96*rma.mv2[[&quot;se&quot;]] ), 3)*100, &quot;%)&quot; )
# &quot;52.2% (44.4% 至 59.9%)&quot;
]]></description>
      <guid>https://stats.stackexchange.com/questions/658385/different-results-meta-vs-metafor-for-three-level-meta-analysis-of-proportions</guid>
      <pubDate>Fri, 06 Dec 2024 18:19:37 GMT</pubDate>
    </item>
    <item>
      <title>如何找到山脊“统计上”消散的点？</title>
      <link>https://stats.stackexchange.com/questions/658384/how-to-find-the-point-where-a-ridge-statistically-dissipates</link>
      <description><![CDATA[这是我感兴趣的表面 $\mathcal{M}$ 的图像。

表面是根据一系列曲线 $z=f_x(y)$（每条曲线都是某个物体的测量物理轮廓）估计的，并分配了 $x$ 个变量。我对点云$(x, y, f_x(y))$执行了双变量 Nadaraya-Watson 核回归，以获得平滑的$\mathcal{M}$。下面是 $z=f_x(y)$ 曲线的图像。

设 $m_x(y)$ 为 $\mathcal{M}$ 与 $yz$ 平行平面的交点曲线，其坐标为 $x$。 $m_x(y)$ 在较小的 $x$ 上表现出一个显著的峰值（局部最大值），但随着 $x$ 的增加，峰值逐渐消散。下面是两条曲线$m_{x_\mathrm{min}}(y)$和$m_{x_\mathrm{max}}(y)$的图像：

回到$\mathcal{M}$，这个突出的峰值的演化在表面上形成了一条脊线（下图中的绿线）。在某个临界点 $x_\mathrm{min} \leq x^* \leq x_\mathrm{max}$（大致在绿色虚线圆圈内），峰值不再存在，脊线停止。

我认为可以通过在脊线上设置初始点并计算 Hessian 矩阵的特征向量来跟踪连续脊线（绿线）。但我想知道：

我如何从统计学上判断给定$x=x^*$时脊线存在的概率（例如，$x_\mathrm{min}$上的$\sim100\%$和$x_\mathrm{max}$上的$\sim0\%$）？

我的第一个想法是将曲面拟合到参数模型（类似于分段回归）。但如果可能的话，我认为非参数方法会更好。
提前致谢！
（编辑）回答 whuber 和 Tim 的评论。]]></description>
      <guid>https://stats.stackexchange.com/questions/658384/how-to-find-the-point-where-a-ridge-statistically-dissipates</guid>
      <pubDate>Fri, 06 Dec 2024 16:27:10 GMT</pubDate>
    </item>
    <item>
      <title>考虑 HGAM 中的非独立性和自相关性</title>
      <link>https://stats.stackexchange.com/questions/658383/accounting-for-non-independence-and-autocorrelation-in-hgam</link>
      <description><![CDATA[我目前正在尝试拟合 HGAM，以模拟两种处理中鱼类日常活动模式的差异。数据是通过高分辨率遥测技术收集的，目前我已估算出三个湖泊（湖泊 A-C）中 30 条鱼（每种处理约 15 条）在约 35 个实验日内每小时（1-24）游动的总距离（米）。这些数据具有清晰的层次结构，我正尝试用随机效应来解释它（如果我的语法有误，请告诉我，因为我习惯于在 brms /lme4 中建模）。我正在为每个湖泊创建一个单独的模型，以降低模型复杂性。模型结构如下：
mod &lt;- gam(as.numeric(total_distance) ~ 
Treatment + exp_day_z + weight_z +
s(hour, by = Treatment, k = 22, bs = &quot;cc&quot;) + # 这是我感兴趣的交互
s(individual_ID, bs = &#39;re&#39;) + # 个体级随机截距
s(individual_ID, exp_day_z, bs = &#39;re&#39;) + # 实验日的个体级随机斜率（居中）
s(individual_ID, hour, bs = &#39;re&#39;), # 一小时的个体级随机斜率
data = filter(perch, lake == &#39;A&#39;),
method = &quot;REML&quot;,
knots=list(hour=c(0.5, 24.5)),
family = Gamma(link = &#39;log&#39;))

然而，残差中似乎仍然存在相当大的自相关性。

在阅读了 Eric Pedersen 的 HGAM 论文、观看了他的和Gavin Simpson的精彩教程，并阅读了一些较早的帖子，我决定在模型中尝试一个自回归项来解释这一点，如下所示：
perch &lt;- perch %&gt;%
allocate(individual_ID, exp_day, hour) %&gt;%
mutate(start = if_else(is.na(lag(individual_ID)) | individual_ID != lag(individual_ID), TRUE, FALSE))

mod2 &lt;- bam(as.numeric(total_distance) ~ 
Treatment + exp_day_z + weight_z +
s(hour, by = Treatment, k = 22, bs = &quot;cc&quot;) + 
s(individual_ID, bs = &#39;re&#39;) +
s(individual_ID, exp_day_z, bs = &#39;re&#39;) +
s(individual_ID, hour, bs = &#39;re&#39;),
data = filter(perch, lake == &#39;A&#39;),
method = &quot;fREML&quot;,
rho = 0.6,
AR.start = start,
discrete = TRUE,
knots=list(hour=c(0.5, 24.5)),
family = Gamma(link = &#39;log&#39;))

这似乎改善了残差自相关（注意：此 acf 图是使用 check_resid(mod2) 生成的，其中灰色条表示标准残差，黑色条表示标准化 AR1 校正残差）。

与我之前的模型相比，该模型似乎也产生了合理的预测，其 CI 略宽（注意：对比度是使用 marginaleffects 包中的 comparisons 函数估计的）。

我仍然对一些事情有点不确定：

我是否应该在同一个模型中包含随机效应和自回归项？
我的随机效应结构格式是否正确，其中小时和实验日是个体级随机斜率？
使用 bam() 函数时选择特定 rho 值的理由是什么？
最后，有点不相关，有没有办法从一个整体模型中获得湖泊和处理特定的平滑度，而不是分别对三个湖泊进行建模（我最初尝试使用 by =互动（治疗，湖泊）但这需要很长时间才能运行，但也许这是唯一的方法）？

如能提供任何帮助，我们将不胜感激！
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658383/accounting-for-non-independence-and-autocorrelation-in-hgam</guid>
      <pubDate>Fri, 06 Dec 2024 16:25:03 GMT</pubDate>
    </item>
    <item>
      <title>查找随机过程的方差</title>
      <link>https://stats.stackexchange.com/questions/658243/finding-the-variance-of-a-stochastic-process</link>
      <description><![CDATA[这是该问题的第二部分计算随机过程的均值和方差？
对于 Polya Urn 问题，我试图理解为什么方差的比率是：
$$\operatorname{Var}(X_n) = E[X_n](1-E[X_n]) \left(\frac{d}{w+b+d} - \frac{w+b}{w+b+d}\frac{1}{n}\right).$$
我知道一般方差公式是$E[X_n^2] - (E[X_n])^2$ 并且 $E[X_n] = \frac{w}{w+b}$。我只需要找到 $E[X_n^2]$。
当我们有 $n$ 个球时，如果我们抽出一个白球（概率 $X_{n-1}$），我们会添加 $d$ 个白球。如果我们抽到黑球（概率为$1-X_{n-1}$），我们添加$d$个黑球（$k$是前面步骤中添加的白球数量）。
$$ X_n = \begin{cases}
\frac{w + (k+1)d}{w+b+nd} &amp; \text{如果抽到白球} \\
\frac{w + kd}{w+b+nd} &amp; \text{如果抽出黑球}
\end{cases} $$
使用二阶总期望定律：
$$ E[X_n^2|X_{n-1}] = X_{n-1}\left(\frac{w + (k+1)d}{w+b+nd}\right)^2 + (1-X_{n-1})\left(\frac{w + kd}{w+b+nd}\right)^2 $$
通过扩展和替换：
$$ \left(\frac{w + (k+1)d}{w+b+nd}\right)^2 = \frac{w^2 + 2w(k+1)d + ((k+1)d)^2}{(w+b+nd)^2} $$
$$ \left(\frac{w + kd}{w+b+nd}\right)^2 = \frac{w^2 + 2wkd + (kd)^2}{(w+b+nd)^2} $$
$$ E[X_n^2|X_{n-1}] = X_{n-1}\frac{w^2 + 2w(k+1)d + ((k+1)d)^2}{(w+b+nd)^2} + (1-X_{n-1})\frac{w^2 + 2wkd + (kd)^2}{(w+b+nd)^2} $$
我尝试扩展再次：
$$ \begin{align*}
E[X_n^2|X_{n-1}] &amp;= \frac{X_{n-1}(w^2 + 2w(k+1)d + ((k+1)d)^2)}{(w+b+nd)^2} + \frac{(1-X_{n-1})(w^2 + 2wkd + (kd)^2)}{(w+b+nd)^2} \\
&amp;= \frac{w^2 + 2wkd + (kd)^2}{(w+b+nd)^2} + X_{n-1}\frac{2wd + 2d^2(k+1)}{(w+b+nd)^2}
\end{align*} $$
我知道我需要再次计算期望，这样 $E(E[X_n^2|X_{n-1}]) = E[X_n^2]$
但这就是我陷入困境的地方，不知道如何继续。我感觉自己在兜圈子。有什么想法可以继续吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658243/finding-the-variance-of-a-stochastic-process</guid>
      <pubDate>Wed, 04 Dec 2024 02:04:46 GMT</pubDate>
    </item>
    <item>
      <title>没有相关性但有依赖性是否意味着联合变量空间的对称性？</title>
      <link>https://stats.stackexchange.com/questions/595716/does-no-correlation-but-dependence-imply-a-symmetry-in-the-joint-variable-space</link>
      <description><![CDATA[我查看了这个问题的答案，它们似乎都具有某种形式的变量对称性。
我将介绍该问题中的示例，以便您了解我的意思。
硬币游戏示例
$Y = \pm X$ 和 $X = |Y|$（对称函数）
$x^2$ 和 $x$ 示例
均匀分布和均匀分布样本的平方均关于 y 轴对称。
圆示例
圆关于 X 轴和 Y 轴对称。 （也可以包含许多其他轴，但我不能 100% 地确定，如果您选择不同的轴，您将不会得到相关性，所以我只说 X 和 Y。）
汽车速度示例
与 $x$ 和 $x^2$ 的情况类似，$K$ 本质上是 $V^2$，而 $V$ 本质上是 $\pm \sqrt{K}$。再次强调，这两个函数都是对称的。
那么，0 相关性和依赖性是否意味着联合变量空间中存在对称性？有人能用数学方法描述这种对称性或提供数学证明来证明联合空间中存在对称性吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/595716/does-no-correlation-but-dependence-imply-a-symmetry-in-the-joint-variable-space</guid>
      <pubDate>Tue, 15 Nov 2022 01:22:14 GMT</pubDate>
    </item>
    </channel>
</rss>