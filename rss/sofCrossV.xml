<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 07 Nov 2024 03:23:20 GMT</lastBuildDate>
    <item>
      <title>使用 missMDA 进行 PCA 丢失数据</title>
      <link>https://stats.stackexchange.com/questions/656866/missing-data-using-missmda-for-pca</link>
      <description><![CDATA[我可能误解了该方法，但第一步中识别的维度数（在本例中为“nb”）应该与最后一个 PCA（res.pca？）中的维度数相匹配吗？
library(missMDA)
data(orange)
nb = estim_ncpPCA(orange,ncp.max=5)
res.comp = imputePCA(orange,ncp=2)
res.pca = PCA(res.comp$completeObs)

在我的数据中，使用 estim_ncpPCA(data) 时识别的组件数为 1，但 PCA 表明两个因子会更好。但我可能解释错了。
这是我的 PCA 的输出：

主成分分析
调用：psych::principal(r = res.imp$completeObs, nfactors = 2, rotate = &quot;oblimin&quot;)
基于相关矩阵的标准化载荷（模式矩阵）
TC1 TC2 h2 u2 com
QTH_VARIABLE_QUAL 0.65 0.45 0.55 1.0
QUW_VARIABLE_QUAL 0.79 0.61 0.39 1.0
QIW_VARIABLE_DJJ 0.41 0.30 0.70 1.6
QOW_VARIABLE_PTT 0.77 0.55 0.45 1.0
QQJ_INTEREST 0.41 0.51 0.61 0.39 1.9
WESCHLER_2020 0.78 0.63 0.37 1.0
SDQ_HYPERACTIVITY 0.84 0.64 0.36 1.0
VOCABULARY_TEXT 0.91 0.87 0.13 1.0

TC1 TC2
SS 载荷 2.47 2.18
比例变异 0.31 0.27
累积变异 0.31 0.58
解释比例 0.53 0.47
累计比例 0.53 1.00

成分相关性为 
TC1 TC2
TC1 1.00 0.43
TC2 0.43 1.00

平均项目复杂度 = 1.2
检验 2 个成分就足够的假设。

残差的均方根 (RMSR) 为 0.11 
经验卡方 98.01，概率 &lt; 0.000000000000004 

基于对角线外值的拟合 = 0.92

res.pca.imp$eig
特征值方差百分比累积方差百分比
comp 1 3.5232032 44.040041 44.04004
comp 2 1.1239440 14.049300 58.08934
comp 3 0.9686372 12.107965 70.19731
comp 4 0.7531068 9.413835 79.61114
comp 5 0.5761703 7.202128 86.81327
comp 6 0.5024870 6.281087 93.09436
comp 7 0.3649657 4.562071 97.65643
comp 8 0.1874858 2.343573 100.00000
]]></description>
      <guid>https://stats.stackexchange.com/questions/656866/missing-data-using-missmda-for-pca</guid>
      <pubDate>Wed, 06 Nov 2024 23:21:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 Quarto 输出多份 pdf 报告 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/656864/using-quarto-to-output-multiple-pdf-reports</link>
      <description><![CDATA[我编写了一些函数，它们接收 8 个独立的程序，并创建一个包含 8 个独立列表的对象，每个列表包含 9 个不同的图表。
total = lapply(dfs, \(i) {list(
age = table_fun(i, age, &#39;age&#39;, &quot;Age&quot;),
mil = table_fun(i, military, &#39;military&#39;, &#39;Veteran Status&#39;),

这样，下面的代码将为我提供第一个列表中的每个图表。
for (i in total[1]){
print(i)
}

然后我想使用 Quarto 为 8 个独立列表（每个程序）中的每一个输出 8 个独立的 pdf 报告。我该怎么做？
谢谢，
詹姆斯]]></description>
      <guid>https://stats.stackexchange.com/questions/656864/using-quarto-to-output-multiple-pdf-reports</guid>
      <pubDate>Wed, 06 Nov 2024 22:23:55 GMT</pubDate>
    </item>
    <item>
      <title>观察性研究中测量协变量的顺序 - 因果推断</title>
      <link>https://stats.stackexchange.com/questions/656860/order-in-which-covariates-are-measured-in-an-observational-study-causal-infere</link>
      <description><![CDATA[我想为 1 型糖尿病患者组建立 hba1c 水平模型。我有从登记册中提取的数据，我的目标是回答治疗干预是否会平​​均降低 hba1c 水平。我（试图）使用因果推理，其中平均治疗效果是使用潜在结果计算的。
因此，我的研究问题是
$$
E\{E (Y|A=1,W)-E(Y|A=0,W) \},
$$
其中 $Y$ 是结果，$A$ 是二元治疗，$W$ 是基线变量。
假设是
$$
\begin{array}{cllc}
1 &amp; \text{ 一致性：} &amp; A=a \Rightarrow Y=Y^a,\\
2 &amp; \text{ 可交换性：} &amp; A \perp Y^a|W (\perp \textit{read } \text{ &quot;独立性&quot;}),\\
3 &amp; \text{ 积极性：} &amp; P(A=a|W=w)&gt;0 \text{ when } P(W=w)&gt;0.
\end{array}
$$
我相信这些假设通常用于因果推理。
现在我提出我的问题，它按照数据测量的顺序进行。
正如我所写，数据来自注册表，而不是来自随机对照。因果链显然要求在治疗干预后（对于接受治疗的人）测量结果（hba1c 水平），而不是在治疗干预之前 - 因此尝试评估治疗效果毫无意义。此外，在观察到的结果之前测量基线变量。
但是对于我拥有的各种数据记录，治疗干预是在$\textit{before}$ 提供的，测量了一些基线变量（即非确定性变量，如血压等，会随时间变化）。因此，治疗效果有可能通过基线变量被隐藏或夸大。
有没有办法克服这个问题，因为我猜这个问题以前在寄存器分析中遇到过。
最好]]></description>
      <guid>https://stats.stackexchange.com/questions/656860/order-in-which-covariates-are-measured-in-an-observational-study-causal-infere</guid>
      <pubDate>Wed, 06 Nov 2024 21:09:25 GMT</pubDate>
    </item>
    <item>
      <title>我真的很困惑如何解释这个 GLM</title>
      <link>https://stats.stackexchange.com/questions/656859/im-really-confused-how-to-interpret-this-glm</link>
      <description><![CDATA[这是我第一次在 glm 上下文中处理二项式数据和不相关变量“x”，所以我很难理解。
这是我的数据，我希望使用互补对数对数链接和 R 函数 glm() 中的二项分布使用此数据拟合广义线性模型。
x,r,y
1.6907,59,6
1.7242,60,13
1.7552,62,18
1.7842,56,28
1.8113,63,52
1.8369,59,53
1.8610,62,61
1.8839,60,60


这是输出答案的正确 R 代码
&gt;响应 &lt;- cbind(y, r - y)
&gt; 模型 &lt;- glm(response ~ x, data = dat, family = binomial(link = &quot;cloglog&quot;))
&gt; summary(model)

我不明白 cbind(y, r-y) 的目的是什么，因为它是二项式的，我们不是要绘制从 0 到 1 的概率吗？这与 x 有什么联系？我想我漏掉了什么
有什么提示吗？
非常感谢]]></description>
      <guid>https://stats.stackexchange.com/questions/656859/im-really-confused-how-to-interpret-this-glm</guid>
      <pubDate>Wed, 06 Nov 2024 20:52:48 GMT</pubDate>
    </item>
    <item>
      <title>逐步向前/向后推算的数学依据</title>
      <link>https://stats.stackexchange.com/questions/656858/mathematical-justification-for-stepwise-forward-backward</link>
      <description><![CDATA[是否有任何参考资料以数学方式陈述并证明回归（尤其是逻辑回归）的逐步前向和后向变量选择？我找不到任何此类来源。]]></description>
      <guid>https://stats.stackexchange.com/questions/656858/mathematical-justification-for-stepwise-forward-backward</guid>
      <pubDate>Wed, 06 Nov 2024 20:22:49 GMT</pubDate>
    </item>
    <item>
      <title>卡方二项式或 t 检验是比较二分变量的正确检验吗？</title>
      <link>https://stats.stackexchange.com/questions/656855/is-a-binomial-of-chi-square-or-t-test-the-correct-test-to-compare-dichotomous-va</link>
      <description><![CDATA[您有一个 ML 模型，该模型输出二分变量 0 或 1 的一百万个观测值中的 100,000 个。您想要查看模型输出的 100,000 个观测值的分布是否与 100 万相似。您应用该模型 3 次，我们将它们称为 A、B 和 C，您将获得 3 组 100,000 个观测值。您想要测试它们是否具有与原始 1,000,000 相同的分布。您在 100,000 和 1,000,000 中的三个之间应用 T 检验，然后在 100,000 和 1,000,000 中的三个之间应用卡方检验，然后应用二项检验。t 检验和二项检验都认为 B 与整个集合相似，A 和 C 不同，但卡方表明只有 C 相似。那么，哪个模型最能近似这 1,000,000 行？]]></description>
      <guid>https://stats.stackexchange.com/questions/656855/is-a-binomial-of-chi-square-or-t-test-the-correct-test-to-compare-dichotomous-va</guid>
      <pubDate>Wed, 06 Nov 2024 19:30:40 GMT</pubDate>
    </item>
    <item>
      <title>相关组：混合效应作为因子模型</title>
      <link>https://stats.stackexchange.com/questions/656851/correlated-groups-mixed-effects-as-a-factor-model</link>
      <description><![CDATA[这已发布在量化交易所中，但没有人感兴趣，所以我想我可以在这里重新发布它。
我正在尝试建立一个 Fama-French 风格的基本因子模型。我有 FF 因子以及我的资产所属的行业。对于不熟悉 FF 的人，您可以将其视为一些基本因素（与通货膨胀或 GDP 相同）
该模型指定为：
$$
\mathbf{Y} = \mathbf{X}\beta + \mathbf{Z}\gamma + \epsilon 
$$
其中，$\mathbf{Y}$ 是 $N$ 资产和 $T$ 每周回报的横截面时间序列矩阵； $\mathbf{X}$ 是 Fama-French 因子（HML、SMB、WML 和 Market-RF 投资组合的每周回报）；$\mathbf{Z}$ 是随机效应矩阵。我有一个简单的案例，其中只有随机截距而没有随机斜率，即$\mathbf{Z}$ 是一个由 1 和 0 组成的矩阵，表示资产所属的行业。 $\epsilon$ 是分布为 $N(0,1)$ 的残差，$\gamma$ 是随机截距 $N(0,\mathbf{G})$，而 $\beta$ 是本例中通常的固定斜率（和一个固定截距）。
我们可以使用 statsmodels&#39; 混合线性模型 来拟合该模型。
数据框如下所示：

我们只需通过以下方式拟合模型：
md = smf.mixedlm(&quot;y ~ MktRF + SMB + HML + WML&quot;, X, groups=X[&quot;sector&quot;])
res = md.fit()

摘要如下所示。然而，结果很糟糕。残差和拟合值之间几乎存在完美的线性关系。


我怀疑协方差矩阵$\mathbf{G}$出了问题，因为它接近奇异值。关于这个问题，我读到的常见方法之一是，随机效应可能过度参数化，并且可能存在多重共线性。因此，我计算了（出于必要，做了一些填充）行业之间的相关性 - 我们的随机截距。

嗯，是的，这些组是相互关联的（尤其是一些组）。
问题：

我们能做些什么？我可以重新分组一些相关的行业，但这似乎不是一个好主意。例如，“金融”和“工业”的相关性很高，但这些是完全不同的组，可能与其他组具有不同的相关性。

协方差真的是个问题吗？也可能是其他原因？我读过这篇帖子，其中讨论了零方差并不一定意味着模型有问题，即可能没有组变异，所有变异都被残差变异捕获 - 但这仍然不能解释数据和残差之间的线性关系。

]]></description>
      <guid>https://stats.stackexchange.com/questions/656851/correlated-groups-mixed-effects-as-a-factor-model</guid>
      <pubDate>Wed, 06 Nov 2024 18:28:13 GMT</pubDate>
    </item>
    <item>
      <title>对俄罗斯的制裁可以在计量经济分析中作为虚拟变量来建模吗？</title>
      <link>https://stats.stackexchange.com/questions/656850/can-sanctions-against-russia-be-modeled-as-a-dummy-variable-in-econometric-analy</link>
      <description><![CDATA[我目前正在进行计量经济学分析，旨在评估对俄罗斯的制裁对 28 个欧盟国家可再生能源份额（占总能源的百分比）的影响。
我正在考虑将制裁建模为虚拟变量，其中：
0 表示未对俄罗斯实施制裁的时期（2014 年之前）。
1 表示实施制裁的时期（2014 年以后）。
我的因变量是这些国家在特定时间段内可再生能源的份额。
我有一个控制变量向量（GDP、能源价格和政策激励）。
我的问题是：
在这种情况下，使用虚拟变量来表示制裁是否合适？
是否有任何特定的计量经济学模型或技术可以推荐用于分析这种二元处理变量对可再生能源份额等连续结果变量的影响？
我很感激任何关于此类分析最佳实践的见解或建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/656850/can-sanctions-against-russia-be-modeled-as-a-dummy-variable-in-econometric-analy</guid>
      <pubDate>Wed, 06 Nov 2024 17:36:01 GMT</pubDate>
    </item>
    <item>
      <title>样本量越大，错误拒绝 0 假设的风险是否会越大？</title>
      <link>https://stats.stackexchange.com/questions/656828/does-the-risk-of-incorrectly-rejecting-the-0-hypothesis-increase-with-a-large-sa</link>
      <description><![CDATA[我经常看到类似这样的话：“如果样本量足够大，较小的效应量可以产生显著的结果”。我不太明白这一点。
对我来说，这听起来是这样的：增加样本量，你最终肯定会拒绝 0 假设（也就是说，如果你将样本量增加到一定大小，你 100% 肯定会拒绝 0 假设）。
重新阅读此主题。据我所知，鉴于我在统计学方面的经验，0 假设被正确拒绝。
决定在 ttest_1samp 测试的代码中检查这一点，使 popmean=15.03 与样本 (mean=15) 的差异非常小。滑块选择 N - 样本，分布实时重新绘制，垂直条是上限值（蓝色）和 p_value（橙色）。
在大约 N - 4000 之后，在大多数情况下，零假设被拒绝。更不清楚的是，在 popmean=15 时，零假设有时也会被拒绝（即均值相等）。
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import t, norm, ttest_1samp
from matplotlib.widgets import Slider

fig, ax = plt.subplots()
fig.subplots_adjust(bottom=0.25)

ax_n = fig.add_axes([0.25, 0.15, 0.65, 0.03])
s_n = Slider(ax_n, &quot;N&quot;, valmin=15, valmax=16000,valinit=30, valstep=1)
mu_0 = 15.03

rng = np.random.default_rng(1)

def update(val):
N = s_n.val
rvs = np.sort(norm.rvs(loc=15, scale=1, size=N, random_state=rng))
mu, std = np.mean(rvs), np.std(rvs)
z_values = (rvs - mu) / std
df = N - 1
pdf = t.pdf(rvs, loc=mu, scale=std, df=df)
tst = ttest_1samp(rvs, popmean=mu_0)
l, r = t.ppf(1 - 0.975, df=df), t.ppf(0.975, df=df)
ci = tst.confidence_interval(confidence_level=0.95)
ci = (ci - mu) / std
ax.clear()
ax.plot(z_values, pdf, lw=2, color=&quot;red&quot;)
ax.axvline(x=(mu_0 - mu) / std, color=&quot;green&quot;, label=&quot;mean 0&quot;)# 0 假设的平均值
ax.axvline(x=ci[0], linestyle=&quot;--&quot;, color=&quot;magenta&quot;, label=&quot;CI&quot;)
ax.axvline(x=ci[1], linestyle=&quot;--&quot;, color=&quot;magenta&quot;)
ax.axvline(x=l, linestyle=&quot;--&quot;, color=&quot;blue&quot;, label=&quot;alfa&quot;)# alfa
ax.axvline(x=r, linestyle=&quot;--&quot;, color=&quot;blue&quot;)# alfa
ax.axvline(x=t.ppf(tst[1]/2, df=df), linestyle=&quot;--&quot;, color=&quot;orange&quot;, label=&quot;p-value&quot;)#p-value
ax.axvline(x=-t.ppf(tst[1]/2, df=df), linestyle=&quot;--&quot;, color=&quot;orange&quot;)#p-value
ax.text(0, (np.max(pdf) + np.min(pdf))/2, &quot;p_value =&quot; + str(round(tst[1], 4)), fontsize=12)
ax.legend()

s_n.on_changed(update)
update(0)

plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/656828/does-the-risk-of-incorrectly-rejecting-the-0-hypothesis-increase-with-a-large-sa</guid>
      <pubDate>Wed, 06 Nov 2024 11:43:12 GMT</pubDate>
    </item>
    <item>
      <title>具有随机变化的生物时间序列数据：回归是否合适以及中心变量是否能消除年份效应</title>
      <link>https://stats.stackexchange.com/questions/656809/biological-time-series-data-with-random-variation-is-regression-suitable-and-ce</link>
      <description><![CDATA[我有多年树木作物的数据：产量、树冠体积等。还有 2 个因素（品种、管理）。
我试图找出我的一些变量之间是否存在相关性，例如树冠和产量。我接触过一位非常严格和严谨的统计学家。他提出了一些主张，我想知道这些主张是否完全正确，是否必须像他建议的那样严格遵守。现在，另一方面，我的老板正在挑战统计学家希望我这样做的方式，并希望我能说服他。统计学家的说法是：

我必须将数据居中（从每个数据点中减去年平均值并添加总体平均值）以消除年份效应。我的老板对此不满意，因为这意味着散点图中的值不再是真实值，并且具有误导性。此外，它还缩小了数据的范围。树冠体积和产量从早年的接近零上升到树木成熟时的很高数字。统计学家说，如果我不将数据集中，就会产生误导，因为产量的增加是由于年龄（即年份）而不是树冠。从生物学的角度来看，我认为这有点愚蠢，但我确实理解这个概念。

我无法拟合回归模型。原因显然是我的实验没有设计成解释变量被复制，因此没有错误。我的解释变量（树冠）是一个观察值，而不是设计值。他让我参考了一篇论文（Powers 2021，《应用生物学年鉴》编辑部），但在同一篇论文中写道：“在其他研究中，将研究由成对的观察值组成的收集数据，以考虑它们之间的关系，而不一定在每个级别都进行复制[就像我的实验中的情况一样]……重要的是评估所提出的关系的统计质量。首先，实际上，应该问是否真的需要拟合关系。&#39;这意味着拟合模型是一种选择，尽管并非总是最佳选择。而统计学家说这是错误的，就是这样。他引用了一本书（Draper 和 Smith 的《应用回归分析》）：“回归分析的一个假设是预测变量不受随机变化的影响”[在我看来它们是]。我的统计学书（Crawley 的《统计学。使用 R 的介绍》）说：“也许知道何时回归是合适的分析的最简单方法是看散点图是否是合适的图形。&#39;[在我看来，它绝对是]另一个重要的事实是，我所在领域的大量其他论文都在做同样的事情：将回归线拟合到像我这样的数据中。这就是我老板使用的论点：人们期望看到直线和 r2，而你需要有一个很好的理由来以不同的方式去做。统计学家建议我使用带有皮尔逊相关系数的散点图，但没有线。


我感觉自己陷入了进退维谷的境地（两个非常强大和自信的个性），我需要更多的解释/意见，才能感觉自己可以更好地辩论。]]></description>
      <guid>https://stats.stackexchange.com/questions/656809/biological-time-series-data-with-random-variation-is-regression-suitable-and-ce</guid>
      <pubDate>Tue, 05 Nov 2024 23:17:29 GMT</pubDate>
    </item>
    <item>
      <title>“分类数据”是“名义数据”的同义词吗？</title>
      <link>https://stats.stackexchange.com/questions/656778/is-categorical-data-a-synonym-of-nominal-data</link>
      <description><![CDATA[到目前为止，我一直认为名义数据是一种分类数据，而不是它的同义词。对我来说，分类数据包括序数数据，而不仅仅是名义数据。
截至 2024 年 11 月，维基百科说（粗体是我的）：

序数数据是一种分类统计数据类型，其中变量具有自然、有序的类别，并且类别之间的距离未知。

这似乎与 Alan Agresti 的分类数据分析简介（第二版，2007 年）一致。第 2 页：

分类变量有两种主要的测量尺度。 [...]
具有有序尺度的分类变量称为序数
变量。
具有无序尺度的分类变量称为
名义变量。

另一方面，CrossValidated 上的categorical-data 标签 表示（粗体是我的）：

分类（也称为名义）数据可以采用有限数量的
可能值，称为类别。分类值“标记”，它们不“测量”。 [...]
对于分析，分类值被视为抽象实体
没有任何数学结构，例如顺序或拓扑，
无论它们如何编码和存储。

加州大学洛杉矶分校统计方法和数据分析网站似乎同意 CrossValidated 的定义（粗体是我的）：

分类变量（有时称为名义变量）是具有两个或多个类别的变量，但类别没有内在顺序。 [...] 纯名义变量仅允许您分配类别，但您无法明确排序类别。

因此，这里似乎存在一些差异。虽然我一般对维基百科有点警惕，但我没有理由怀疑我提到的其他资源，特别是当它们的定义似乎不模棱两可时。
这是否反映了对“分类”定义缺乏共识？换句话说，“分类”是一个允许灵活使用的术语吗？还是我误解了某些内容或遗漏了一些可以调和这些不同参考资料的重要信息？
如果有的话，我还对（最好是学术性的）参考资料感兴趣，讨论“分类”的定义以及可能存在不同定义的问题。
我问这个问题的原因当然不是为了吹毛求疵，而是为了避免在阅读或与其他人讨论这个主题时可能出现的误解。]]></description>
      <guid>https://stats.stackexchange.com/questions/656778/is-categorical-data-a-synonym-of-nominal-data</guid>
      <pubDate>Tue, 05 Nov 2024 10:31:33 GMT</pubDate>
    </item>
    <item>
      <title>调整多项式拟合参数数量</title>
      <link>https://stats.stackexchange.com/questions/656772/adjusting-polynomial-fit-number-of-parameters</link>
      <description><![CDATA[我正在探索一种确定 Python 中多项式回归的最佳次数的方法。以下是我的方法：

我迭代地拟合次数增加的多项式（最高次数为 50），并计算每次拟合的调整后的 R²。

然后，我将逻辑函数拟合到这些调整后的 R² 值，以模拟拟合优度如何随多项式次数的变化。

最后，我确定在实际调整后的 R² 和逻辑模型的预测之间产生最大正残差的多项式次数，并将其选为最佳次数。


这种方法在统计上合理吗？是否有更成熟或计算效率更高的方法来确定回归分析中的多项式次数？
多项式似乎表现良好，我正在使用它来生成时间序列数据的趋势。
在我看来，由于参数次数高，它们似乎没有太多的预测能力，但它们可能对分析历史趋势有用。]]></description>
      <guid>https://stats.stackexchange.com/questions/656772/adjusting-polynomial-fit-number-of-parameters</guid>
      <pubDate>Tue, 05 Nov 2024 08:21:14 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 p 值？</title>
      <link>https://stats.stackexchange.com/questions/656852/how-to-interpret-p-value</link>
      <description><![CDATA[我有一个学生数据集，其中包含模拟期末考试和期末考试。
根据假设，

$H_0: \mu_{mock-final} = \mu_{final}$
$H_0: \mu_{mock-final} \ \neq \mu_{final}$

我首先使用双尾 t 检验 ttest_rel(scores.mock_final, scores.final)，显著性水平为 $5\%$，结果为 $t-stat, p-val = -5.503, 1.796 * 10^{-7}$
由于 $\ p-val &lt;&lt; 0.05$，我拒绝我的零假设，即 $\ \mu_{mock-final} \neq \mu_{final}$。
现在，我这样构建假设，

$H_0: \mu_{mock-final} &gt; \mu_{final}$
$H_0: \mu_{mock-final} \ &lt; \mu_{final}$

再次进行 t 检验，但这次使用 alternate = &#39;greater&#39;
ttest_rel(scores.mock_final, scores.final, alternative = &#39;greater&#39;)

得到 $t-stat, p-val = -5.503, 0.99999991$

现在，我应该从中解释什么？
我是否应该使用 alternate = &#39;less&#39; 来表示我的替代假设？
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/656852/how-to-interpret-p-value</guid>
      <pubDate>Tue, 05 Nov 2024 02:58:49 GMT</pubDate>
    </item>
    <item>
      <title>精确召回率下的时间依赖区域</title>
      <link>https://stats.stackexchange.com/questions/656744/time-dependent-area-under-the-precision-recall</link>
      <description><![CDATA[如何比较两个 cox 回归模型在多个时间点的时间相关精确召回率 (PR) 接收者操作曲线 (ROC) 值？
要比较两个时间相关的 AUC 值，我将使用 timeROC
R 库的 compare 函数。很长一段时间以来，我都认为 DeLong 的测试是一种替代方案，但它最初是为了比较标准（二元分类）AUROC 而开发的，其中结果是二元的并且与时间无关。然而，时间相关的 AUROC 结合了审查和事件发生时间信息。
PRROC R 库可以很好地计算 PR 曲线的时间相关 ROC 值（无统计比较），并且 usefun R 库的 pr.test 函数可以比较两个 PR 值（不依赖于时间！）。但是，没有记录良好的库可以将两者结合起来，以便对时间相关的 PRROC 进行统计比较。
有什么想法可以在 R 或 Python 中实现这一点吗？找不到任何其他解决此特定问题的线程。]]></description>
      <guid>https://stats.stackexchange.com/questions/656744/time-dependent-area-under-the-precision-recall</guid>
      <pubDate>Mon, 04 Nov 2024 19:29:36 GMT</pubDate>
    </item>
    <item>
      <title>具有删失协变量的风险——我应该使用哪种方法？</title>
      <link>https://stats.stackexchange.com/questions/656719/risk-with-censored-covariates-which-method-should-i-use</link>
      <description><![CDATA[TL;DR - 我的数据包括：

幼儿因家庭伤害而去医院的年龄。
幼儿爬行、走路和跑步的年龄记录。记录受到审查，因为有些幼儿在开始（例如）走路之前就到了医院。

我想预测“家庭伤害风险”。我应该怎么做？
现在更详细一点：我有因家庭伤害而去医院的幼儿的数据。每个幼儿每隔一段时间都会去社区的护士那里看望，护士会记录幼儿是否可以（A）爬行、（B）走路、（C）跑步。进展是单调的：走路的幼儿肯定可以爬行，而跑步的幼儿不会停止跑步。我认为幼儿年龄和达到上述活动水平 A、B 和 C 的年龄是家庭受伤风险的指标，因为活动能力更强的幼儿受伤的几率更高。
对于特定的幼儿，我想计算家庭受伤的风险指标。我的想法：

我当然无法计算受伤的概率$\Pr(injury)$，因为我没有未去过医院的幼儿的记录。
出于类似的原因，我不能天真地使用逻辑回归。
也许可以计算相对于某个基线年龄的优势比并使用罕见疾病近似值？但是，我该如何整合关于活动水平 A、B 和 C 的信息呢？
我认为 Cox 回归在这里不合适，因为我实际上并没有对事件发生时间进行建模。

请建议定义和查找幼儿“受伤风险”的方法。我也希望您能解释一下我提到的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/656719/risk-with-censored-covariates-which-method-should-i-use</guid>
      <pubDate>Mon, 04 Nov 2024 10:41:05 GMT</pubDate>
    </item>
    </channel>
</rss>