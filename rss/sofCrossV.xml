<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 17 Aug 2024 03:16:14 GMT</lastBuildDate>
    <item>
      <title>邻域搜索比近似邻域搜索更好吗？</title>
      <link>https://stats.stackexchange.com/questions/652945/is-neighbour-search-better-than-approximate-neighbour-search</link>
      <description><![CDATA[如果我有以下内容：
200k 个向量
在 100 个向量中查找最近邻居
我应该只使用 NN 并在请求时计算距离，还是使用向量数据库进行 ANN？
我可以在内存中保存 200k 个向量，但我只想在请求时从选定数量（n=100）中搜索最近的向量。
尝试在线搜索此答案。查找何时对 n 值使用 ANN。]]></description>
      <guid>https://stats.stackexchange.com/questions/652945/is-neighbour-search-better-than-approximate-neighbour-search</guid>
      <pubDate>Fri, 16 Aug 2024 22:07:45 GMT</pubDate>
    </item>
    <item>
      <title>如何根据残差图判断是否应包括交互项？</title>
      <link>https://stats.stackexchange.com/questions/652944/how-to-tell-if-an-interaction-term-should-be-included-based-on-residual-plot</link>
      <description><![CDATA[应用线性回归模型说：

此外，残差
应该针对回归模型中未包括的潜在交互作用的交互项绘制，例如针对$X_1X_2$、$X_1X_3$和$X_2X_3$，以查看模型中是否需要部分或全部
这些交互项。

但是我不确定我在图中寻找什么来确定是否应该包括给定的交互项。例如，在问题 6.10 中，$e$ 与 $X_1X_2$ 的图如下所示：

我看到两组（数据包括一个二进制编码变量 $X_3$），但该图看起来类似于 $e$ 与 $X_1$：

我如何知道 $X_1X_2$ 项是否重要？]]></description>
      <guid>https://stats.stackexchange.com/questions/652944/how-to-tell-if-an-interaction-term-should-be-included-based-on-residual-plot</guid>
      <pubDate>Fri, 16 Aug 2024 21:00:48 GMT</pubDate>
    </item>
    <item>
      <title>Python：获取两点/坐标之间的距离[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652940/python-get-distance-between-2-points-coordinates</link>
      <description><![CDATA[我想获取两点之间的行驶距离。我知道 Google Maps 有 API 并且存在其他解决方案，但如果可能的话，我想避免为此花钱。
我尝试了 openrouteservice（找不到足够的地址）和 Google Maps。
我每个月有大约 30,000 个地址，我想获取到这些地址的行驶距离和行驶时间。有人有不花钱的解决方案吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652940/python-get-distance-between-2-points-coordinates</guid>
      <pubDate>Fri, 16 Aug 2024 20:01:45 GMT</pubDate>
    </item>
    <item>
      <title>我的统计设计应该使用什么统计检验？</title>
      <link>https://stats.stackexchange.com/questions/652939/what-statistical-test-to-use-for-my-stats-design</link>
      <description><![CDATA[我想知道在以下情况下我可以使用什么统计测试：
假设我有 2 个不同的组 A（测试）和 B（控制），并且每个组中有 3 个不同的定价层级（P1 P2 P3）。一般来说，我想测试 A/B 的不同相关指标 C/D/E 之间是否存在统计意义。此外，我想测试不同组之间定价层的统计差异。我怀疑我是否可以将组治疗和定价视为 2 个独立变量？如果可以，Mancova 是否可行？我应该改用其他模型吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652939/what-statistical-test-to-use-for-my-stats-design</guid>
      <pubDate>Fri, 16 Aug 2024 18:59:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 CVXPY 解决逻辑回归问题</title>
      <link>https://stats.stackexchange.com/questions/652935/solving-logistic-regression-using-cvxpy</link>
      <description><![CDATA[我正在尝试使用 CVXPY 库编写逻辑回归模型。到目前为止，我编写的代码“有效”，因为它可以执行，不会产生任何错误消息并提供解决方案。但是，此解决方案与 scikit-learn 逻辑回归实现提供的解决方案不匹配。
我知道 scikit-learn 实现默认包含 L2 惩罚，在下面的代码示例中，您将看到我将其更改为 None。我还从 sklearn 模型中删除了截距。但解决方案仍然不匹配：
import cvxpy as cp
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression

X, y = make_classification(n_features=10, random_state=42)

sk = LogisticRegression(penalty=None, fit_intercept=False)
sk.fit(X, y)
print(sk.coef_)

这将产生输出：
[[-13.46939518 -7.09935934 19.41989522 -10.36990818 3.76335965
2.84616038 3.32474461 -2.84162961 3.13246888 1.08887971]]

现在，cvxpy 实现：
beta = cp.Variable(X.shape[1])
log_likelihood = cp.sum(cp.multiply(y, X @ beta) - cp.logistic(X @ beta))
problem = cp.Problem(cp.Maximize(log_likelihood/X.shape[0]))
problem.solve()
beta = beta.value
print(beta)

产生解决方案：
[-31.38130594 -10.72178524 44.07489985 -34.06127916 8.01950276
5.96941765 9.6143194 -7.88785049 12.96349703 -0.13264449]

编辑：
我的代码正在解决的对数似然公式是
$$
\ell(\beta)=\sum_{i=1}^m y_i \beta^T x_i-\log \left(1+\exp \left(\beta^T x_i\right)\right)
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/652935/solving-logistic-regression-using-cvxpy</guid>
      <pubDate>Fri, 16 Aug 2024 17:28:02 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用卡方统计量来根据 60,000 个值的经验数据集评估理论 PDF 吗？</title>
      <link>https://stats.stackexchange.com/questions/652934/can-i-use-the-chi-square-statistic-to-evaluate-theoretical-pdfs-against-an-empir</link>
      <description><![CDATA[我有一个包含 60,000 个数值的数值模拟数据集。
我正在测试 4 个理论 PDF（gamma、beta、Weibull 和对数正态）与该数据的拟合度，其中分布的参数是根据数据估算的。
我可以使用卡方统计量来比较这些分布的拟合优度吗？或者卡方统计量不适合此目的，尤其是考虑到我的数据集很大？
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652934/can-i-use-the-chi-square-statistic-to-evaluate-theoretical-pdfs-against-an-empir</guid>
      <pubDate>Fri, 16 Aug 2024 17:15:30 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯 Cramer-Rao 下限计算的困惑</title>
      <link>https://stats.stackexchange.com/questions/652931/confusion-on-bayesian-cramer-rao-lower-bound-calculation</link>
      <description><![CDATA[我正在研究 Cramer-Rao 下限 (CRLB)，并利用先前的知识来了解非视距 (NLOS) 造成的额外长度。我正在阅读的文章是关于非视距环境中使用先前信息的地理定位准确性和非视距环境中无线地理定位的分析。两篇文章均来自同一作者，并讨论了类似的事情。扩展CRB算法的公式为
$$J = \frac{1}{c^2}\left( \begin{bmatrix} H_{NL}\Lambda_{NL}H_{NL}^T+H_{L}\Lambda_{L}H_{L}^T &amp; H_{NL}\Lambda_{NL} \\ \Lambda_{NL}H_{NL} &amp; \Lambda_{NL}+c^2\Omega \end{bmatrix} \right),$$
其中$H_{NL}$和$H_L$分别是NLOS和LOS基站的角度矩阵。 $\Lambda$ 代表根据接收信号计算出的对角矩阵 $\operatorname{diag}8\pi^2\beta^2\cdot R_b$。$\Omega = \operatorname{diag}(\sigma^2_l)$ 是先前已知的 NLOS 延迟协方差矩阵。第一篇文章中方程为(20)(21)，第二篇文章中方程为(50)。
由于局部化只关心$(x,y)$位置，所以只考虑上子矩阵，这意味着先验NLOS延迟$\sigma^2_l$对计算没有太大影响。论文中还提到，当先验NLOS延迟的方差很大时，即$\sigma^2_l \rightarrow +\infty$，$H_{NL}\Lambda_{NL}H_{NL}^T$会减小；如果 $\sigma^2_l \rightarrow 0$，则 NLOS 部分可视为 LOS 估计值。
让我感到困惑的是，这些论文仍然没有告诉我如何在事先了解 NLOS 延迟的情况下计算 CRB。例如，对于总共 10 个 rx 雷达，我知道其中 2 个是 LOS，其余 8 个是 NLOS。并且根据先前的知识，我知道 NLOS 延迟呈分布，即 $\sigma^2 = 0.5$。因此，定位 CRB 的计算应该是 $H_{NL}\Lambda_{NL}H_{NL}^T+H_L \Lambda_L H_L^T$（考虑 $8+2$ 个接收器）或 $H_L\Lambda_{L}H_L^T$（仅考虑 2 个 LOS）？如果方差是 1 或 2 甚至 10，情况会怎样？
对我来说，“先验知识”似乎不用于计算 CRB，但也给出了一个判断，即某些雷达信息是否不应该在计算中考虑。]]></description>
      <guid>https://stats.stackexchange.com/questions/652931/confusion-on-bayesian-cramer-rao-lower-bound-calculation</guid>
      <pubDate>Fri, 16 Aug 2024 15:26:14 GMT</pubDate>
    </item>
    <item>
      <title>用类高斯因子近似高维积分的有效方法</title>
      <link>https://stats.stackexchange.com/questions/652919/efficient-methods-for-approximating-high-dimensional-integrals-with-gaussian-lik</link>
      <description><![CDATA[我正在寻找一种计算效率高的方法来近似地评估以下形式的高维积分：
$$\int f(\textbf{x}) \prod_i g_i(x_i) \, d\textbf{x}$$
其中 $f(\mathbf{x}) = (\mathbf{x}&#39;\mathbf{A}\mathbf{x})^{-k}$，其中 $k$ 是一个大整数，而 $\mathbf{x}$ 的维度通常为 $n &gt; 5,000$。函数$g_i(x_i)$是概率密度函数，可以用高斯分布$\mathcal{N}(x_i; \mu_i, \tau_i)$来近似，因为$g_i(x_i)$的拉普拉斯近似很容易推导。一般而言，$g_i(x_i)$ 可以假设为具有简单且易处理的单变量形式，并且易于从中采样。
到目前为止我尝试过的方法：

蒙特卡洛积分：虽然从 $g_i(x_i)$ 采样很简单，但收敛速度非常慢。一般而言，基于采样的方法可能不可行，因为计算成本高。

拉普拉斯近似：这种方法不切实际，因为$\mathbf{A}$的结构、$f(\mathbf{x})$的行为（当$\mathbf{x} = 0$时会飙升至无穷大）以及高维性使得以计算成本低廉的方式找到被积函数的模式非常具有挑战性。

关注$g_i(x_i)$：当所有$\tau_i$都很小时，拉普拉斯近似在近似被积函数模式$\mathbf{\mu}$下进行近似，甚至简单地使用$\int f(\mathbf{x}) \prod_i g_i(x_i) \, d\mathbf{x} \approx (\mathbf{\mu}&#39;\mathbf{A}\mathbf{\mu})^{-k}$都非常有效。但是，假设所有 $i$ 的 $\tau_i$ 都很小并不总是可行的。

直接近似：尝试近似随机变量 $g(\mathbf{x})$ 的高斯近似值 $\mathbf{x}&#39;\mathbf{A}\mathbf{x}$ 的密度，然后估计所得分布的第 $k$ 个负矩，这有点有效，但结果并不令人满意。


我很好奇，考虑到$g_i(x_i)$ 是（近似）高斯分布且独立的。考虑到此问题的结构，还有其他近似方法可能在计算上可行吗？如能提供任何替代方向的建议或提示，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/652919/efficient-methods-for-approximating-high-dimensional-integrals-with-gaussian-lik</guid>
      <pubDate>Fri, 16 Aug 2024 09:16:27 GMT</pubDate>
    </item>
    <item>
      <title>戴明回归和数值配方</title>
      <link>https://stats.stackexchange.com/questions/652796/deming-regression-and-numerical-recipes</link>
      <description><![CDATA[我试图对戴明回归进行分类，这意味着我想通过 x 和 y 坐标中都有“错误”的数据来拟合一个函数（一条直线）。我正在查看《数值方法》第 15.3 章，发现他们的方法的基础很神秘。
对我来说最令人费解的是他们选择最小化的优值函数：
\begin{equation}
\chi^{2} = \sum_{i=1}^{N} \frac{(y_{i} - a - b\cdot x_{i})^{2}}{\sigma_{yi}^{2} + b^{2}\cdot\sigma_{xi}^{2}}
\end{equation&gt;
这对我来说看起来不对。 $y_{i} - a - b\cdot x_{i}$ 是 y 中的残差。难道不应该有一个附加项，用于最小化线和 x 数据之间的平方距离吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652796/deming-regression-and-numerical-recipes</guid>
      <pubDate>Wed, 14 Aug 2024 15:31:13 GMT</pubDate>
    </item>
    <item>
      <title>如何计算生存模型中累积风险预测差异的置信区间？</title>
      <link>https://stats.stackexchange.com/questions/652760/how-do-i-compute-confidence-intervals-for-the-predicted-difference-in-cumulative</link>
      <description><![CDATA[我有以下数据：
library(cobalt)
library(tidycmprsk)
library(ggsurvfit)
library(gtsummary)

set.seed(123)
lalonde &lt;- cbind(lalonde, 
event = sample(c(0, 1), size = 614, replace = TRUE, 
prob = c(0.84, 0.16)), 
time = runif(614, min = 10, max = 365))
n &lt;- ceiling(0.05 * nrow(lalonde)) 
selected_indices &lt;- sample(1:nrow(lalonde), size = n)
lalonde[selected_indices, &quot;event&quot;] &lt;- 2

lalonde$event &lt;- factor(lalonde$event, levels = c(0, 1, 2),
labels = c(&quot;Censored&quot;, &quot;Event1&quot;, &quot;Event2&quot;))

我可以从累积发生率函数中得出绝对风险：
p &lt;- cuminc(Surv(time, event) ~ treat, lalonde) %&gt;% 
tbl_cuminc(
times = c(180, 230),
label_header = &quot;**{time}-day cuminc**&quot;) 

得出：
特征 180 天cuminc 230 天 cuminc
治疗 

0 8.1% (5.6%, 11%) 14% (11%, 19%)
1 9.1% (5.3%, 14%) 13% (8.2%, 20%)

如何计算指定时间点的置信区间风险差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/652760/how-do-i-compute-confidence-intervals-for-the-predicted-difference-in-cumulative</guid>
      <pubDate>Tue, 13 Aug 2024 08:25:01 GMT</pubDate>
    </item>
    <item>
      <title>在一个模型中，对同一个变量进行两次单独的交互可以吗？</title>
      <link>https://stats.stackexchange.com/questions/652621/is-it-okay-to-have-two-separate-interactions-with-the-same-variable-in-one-model</link>
      <description><![CDATA[我的主要模型是这样的：
model &lt;- brm(
bf(binary ~ categorical1 + categorical2 + (1 | id) + (1 | country)),
data = data,
family = bernoulli(link = &quot;logit&quot;),
Prior = Priors,
chains = 8, iter = 2000, seed = 345)

现在，作为探索性分析，我想测试国家和每个分类变量之间的相互作用，但我对 categorical1 和 categorical2 之间的相互作用不感兴趣。
我想知道这个模型是否过度拟合，我应该运行两个单独的模型吗？我该如何确定？
model &lt;- brm(
bf(binary ~ categorical1 * country + categorical2 * country + (1 | id)),
data = data,
family = bernoulli(link = &quot;logit&quot;),
Prior = Priors,
chains = 8, iter = 2000, seed = 345)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652621/is-it-okay-to-have-two-separate-interactions-with-the-same-variable-in-one-model</guid>
      <pubDate>Sun, 11 Aug 2024 16:28:28 GMT</pubDate>
    </item>
    <item>
      <title>传递偏好建模</title>
      <link>https://stats.stackexchange.com/questions/652118/modeling-transitive-preference</link>
      <description><![CDATA[我曾对 10 名受试者进行过两次偏好测试，向他们展示了所有六种成对组合（AB、BA、CB、BC、AC、CA）中的三个选项。
我需要确定以下内容：每个受试者是否有偏好；如果有，它是否是传递性的（例如，A&gt;B&gt;C，但不是 C&gt;A）和/或在两次测试中可重复；偏好有多强；以及选项的熟悉程度（熟悉或不熟悉）和/或类型（X、Y、Z）是否会对所有受试者和测试产生影响。
这是我目前的计划：

将每个受试者在每个选项上花费的时间加起来。对于每对比较（AB、BA、CA 等），受试者花费更多时间的选项将被视为首选选项。

创建函数来检查两个测试中偏好的传递性和可重复性。

使用重复测量方差分析或混合效应模型来评估偏好的强度，以分析在两个测试中花费在每个选项上的时间，并考虑偏好是否具有传递性和/或可重复性。具有传递性、可重复性且在首选选项上花费更多时间的案例将成为最强偏好的案例。

使用逻辑回归或广义线性混合模型 (GLMM) 分析熟悉度和选项类型对偏好结果的影响。


我想知道：

如何创建考虑传递性、可重复性和时间的偏好强度分数。

如何确定哪种统计方法最合适。

]]></description>
      <guid>https://stats.stackexchange.com/questions/652118/modeling-transitive-preference</guid>
      <pubDate>Wed, 31 Jul 2024 22:40:43 GMT</pubDate>
    </item>
    <item>
      <title>测量嵌入空间中的相似性？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651840/measuring-similarity-in-embedding-spaces</link>
      <description><![CDATA[就上下文而言，我一直在使用特征哈希对快速文本分类器进行处理，该分类器的特征数量非常少（2000 个，故意设置得非常少）。我注意到由于碰撞，一些结果有点不稳定，我想知道是否可以选择更好的哈希（改变哈希函数和随机密钥）以获得更“自然”的结果碰撞。
为了从经验上选择一个更好的哈希，我已经确定，对于给定的数据集，测量哈希特征与神经特征的分布的相似性。具体来说，我想捕获：

邻域保存得如何？
邻域之间的距离保存得如何？

这是我到目前为止尝试过的：

Kendall 的 Tau，捕获 1。但不是 2。计算成本也相对较高（在较旧的计算机上约为 20 秒）
Gromov-Wasserstein，查看分布而不是特定单词。与 1 的时间相似
求解两者之间的线性变换（最小二乘法）。不确定如何将其转换为有意义的指标（残差、幅度？）。成本是可变的。

除了测量嵌入空间相似性的方法之外，我还愿意接受其他方法来选择更好的哈希值]]></description>
      <guid>https://stats.stackexchange.com/questions/651840/measuring-similarity-in-embedding-spaces</guid>
      <pubDate>Fri, 26 Jul 2024 22:54:11 GMT</pubDate>
    </item>
    <item>
      <title>如何对 gam 全模型平均值进行诊断？</title>
      <link>https://stats.stackexchange.com/questions/651768/how-to-make-diagnostic-of-a-gam-full-model-averaged</link>
      <description><![CDATA[我想知道哪些变量对我的响应变量有显著影响（gam 模型中的 11 个变量，带有一些平滑项）。
我使用了打包的 MuMIn 中的函数 dredge，我的权重很低：当我使用 subset=cumsum(weight)&lt;=.95 时，我得到 72 个模型，权重在 0.03 和 0.01 之间，115 个模型，权重 = 0.00...因此，我正在查看 模型平均系数（全平均值） 以查看什么是重要的。

我实际上应该使用 subset=cumsum(weight)&lt;=.95 还是 subset=delta &lt; something？ （当 delta AIC = 3.63 时，权重 = 0.00）

如何诊断我的完整模型平均值？ DHARMa 不适用于模型平均值... 我是否必须对每个模型使用 DHARMa？或者有更好的解决方案吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/651768/how-to-make-diagnostic-of-a-gam-full-model-averaged</guid>
      <pubDate>Thu, 25 Jul 2024 18:29:47 GMT</pubDate>
    </item>
    <item>
      <title>随机过程背景下的渐近意义</title>
      <link>https://stats.stackexchange.com/questions/651711/meaning-of-asymptotic-in-the-context-of-stochastic-process</link>
      <description><![CDATA[因此，对于分数布朗运动，我将$k^{th}$ 变化定义为
$$ S_n = \frac{1}{n}\sum_{i = 1}^{n}{|B_{H}(i\times\frac{T}{n}) - B_{H}((i - 1)\times\frac{T}{n})|^k} $$
其中 T 是固定的，$B_H$ 是标准分数布朗运动
我正在写一篇关于这个的文献，我想用词准确，因为我对一些关于渐近性质的文献有点困惑。
假设我有一些估计量$\hat{H}$ 依赖于 $S_n$，通过行列式和可逆函数。我读过的文献提到了 $\hat{H}$ 关于 $n$ 的渐近性质（例如分布），适用于分数布朗运动 $B_H$。
所以我想知道：
&quot;对于分数布朗运动 $B_H$ 关于 $n$&quot; - 这是否意味着它考虑了 fBm 的特定实现？正如我所想，渐近性质考虑了估计量相对于样本大小的限制行为，并且在这种情况下增加$n$更像是在连续意义上思考？此外，我认为$S_n$是随机变量，而我理解的样本大小是指 fBm 路径的数量（至于每条路径，对于相同的真实$H$，$S_n$的值不同）]]></description>
      <guid>https://stats.stackexchange.com/questions/651711/meaning-of-asymptotic-in-the-context-of-stochastic-process</guid>
      <pubDate>Wed, 24 Jul 2024 22:23:56 GMT</pubDate>
    </item>
    </channel>
</rss>