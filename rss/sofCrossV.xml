<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 15 May 2024 06:19:48 GMT</lastBuildDate>
    <item>
      <title>在训练进行回归的神经网络模型时，将特征合并到损失函数中是个好主意吗？</title>
      <link>https://stats.stackexchange.com/questions/647252/is-it-a-good-idea-to-incorporate-a-feature-into-the-loss-function-when-training</link>
      <description><![CDATA[在训练进行回归的神经网络时，假设我有 3 个特征，称为“a”、“b”和“c”。相应的目标被称为“d”。理论上，当训练得当时，该模式将使用“a”、“b”、“c”等。成功预测“d”的值。然而，由于特征“c”是特征“c”。由“a”计算得出和“d”在训练期间，因此，在推理期间，“c”是“c”。不可用。
将功能“c”移至进入损失函数，那么模型是间接训练的吗？例如，损失函数类似于 MSE(y_pred, y_true) + opportunity_term * c?]]></description>
      <guid>https://stats.stackexchange.com/questions/647252/is-it-a-good-idea-to-incorporate-a-feature-into-the-loss-function-when-training</guid>
      <pubDate>Wed, 15 May 2024 04:28:29 GMT</pubDate>
    </item>
    <item>
      <title>面包篮中的面包新鲜度，R 中的多级分析； 2个时间点</title>
      <link>https://stats.stackexchange.com/questions/647250/bread-freshness-in-bread-basket-multi-level-analysis-in-r-2-time-points</link>
      <description><![CDATA[这是我第一次尝试多层次分析。
我的研究问题是；
面包篮内不同类型面包（6级）的新鲜度在两个时间点（4-8天）内如何变化，取决于面包师的技能（4级），以及调整每个篮子之间的相互相关性，因为一个篮子可能是用比另一个篮子质量更高的原料制成的？

样本数量 = 300 个面包篮
V1：id - 每个面包篮的 ID（每个 id 有 6 个相关的面包类型）
V2：新鲜 - 因变量：面包的新鲜度（连续，0-100）
V3：技能 - 面包师的技能（4 级有序因子）（李克特量表）
V4：类型 - 面包类型（标称 6 级，每个 id）
V5：时间 - 自烘烤以来的时间（连续，范围为 4-8 天）
V6-V8 其他协变量（咖啡馆温度、烤箱条件、# 烘焙辅助蚂蚁）

更简单地说，面包师的技能如何改变时间对面包篮中每种类型面包的新鲜度的影响，以及不同类型面包的影响（新鲜度技能）的差异在统计上是否不同面包？
我一直在 R 中使用 lme4 包，以 fresh 作为响应变量，但是我有点不确定哪些变量应该视为随机效应，哪些变量是固定的。我相信 type 会嵌套在篮子 ids 中，以说明制作时可用的成分。这就是我所在的位置：
模型 &lt;- lmer(新鲜 ~ 技能 * 时间 + 类型 + V6 + V7 + V8 + (1|类型) + (时间|id), 数据 = 数据)&lt; /em&gt;
我们感兴趣的主要预测因素是面包师的技能。我认为技能不应被视为随机效应，因为它在每个篮子的所有面包类型中都是恒定的。
我很感激任何关于如何解决这个问题的建议。这比我习惯的要复杂一些，因此任何关于要采取的步骤的指示或类似分析的参考，将不胜感激。谢谢！
此插图仅显示两种类型的面包，每个篮子有 6 个面包。我需要编辑它，因为独特的面包类型应该位于列中，就像数据集中的变量一样，为每个id分成六组。
]]></description>
      <guid>https://stats.stackexchange.com/questions/647250/bread-freshness-in-bread-basket-multi-level-analysis-in-r-2-time-points</guid>
      <pubDate>Wed, 15 May 2024 02:42:28 GMT</pubDate>
    </item>
    <item>
      <title>干头骨与活头骨测量调整</title>
      <link>https://stats.stackexchange.com/questions/647246/dry-skull-vs-live-skull-measurement-adjustments</link>
      <description><![CDATA[我正在研究一个数据集，其中包含博物馆藏品（样本数量的两倍）或活体标本（不太常见）的干燥头骨测量值。正如您可以想象的那样，由于肌肉、皮肤和毛皮的存在，活体标本平均要大几厘米。我可以使用哪些统计方法来校正这些较大的尺寸，以更好地适应干燥的头骨测量？头骨长度将用作更大模型中的变量。
我想到了 3 种可能的方法：

将头骨类型作为随机效应，以解释这些方法之间的差异

按性别和年龄减去每种头骨类型的预测长度或平均值之间的差异，但这似乎是一种粗略的方法。

使用从线性回归模型获得的残差直接调整测量的头骨尺寸。从活体样本的测量头骨尺寸中减去残差，有效地减小它们的尺寸以适应更“平均”的头骨尺寸。尺寸。


# 线性回归：
lm1 &lt;- lm(Skull_length ~ ns(Age, 3) + 性别 + Skull_code, data = Dataframe)

# 从线性回归模型中获取残差
残差 &lt;- 残差(lm1)

# 创建新的数据框用于预测
new_data &lt;- Expand.grid(年龄 = 0:30,
                        性别 = c(“M”, “F”),
                        Skull_code = as.factor(1))

# 使用每个模型预测头骨长度
Predicted_skull_df2 &lt;- new_data %&gt;%
  变异（预测头骨 = 预测（lm1，新数据 = .））

# 将残差添加到骷髅代码== 1（干骷髅）的平均骷髅长度上，因为骷髅代码== 2（活骷髅）
Growth_data &lt;- Growth_data %&gt;%
  left_join(预测_skull_df) %&gt;%
  mutate(Adjusted_skull2 = ifelse(Skull_code == 2, Predicted_skull + 残差, Skull_l))

#创建绘图以比较调整后的测量值与原始测量值
增长数据%&gt;%
  ggplot(aes(x = 年龄, y = Skull_l)) +
  geom_point(数据 = Growth_data %&gt;%
               过滤器（Skull_code == 1），aes（x = 年龄 - 0.2），颜色 =“黑色”，alpha = 0.5，大小 = 1）+
  geom_smooth(数据 = Growth_data %&gt;%
                过滤器（Skull_code == 1），颜色=“黑色”）+
  
  geom_point(数据 = Growth_data %&gt;%
               过滤器（Skull_code == 2），aes（x =年龄+ 0.2），颜色=“紫色”，alpha = 0.5，大小= 1）+
  geom_smooth(数据 = Growth_data %&gt;%
                过滤器（Skull_code == 2），颜色=“紫色”）+
  
  geom_point(aes(y = adjustment_skull_l), 颜色 = “红色”, alpha = 0.5, 大小 = 1) +
  geom_smooth(aes(y = adjustment_skull_l), color = “红色”)+
  主题(panel.background = element_rect(fill = &quot;white&quot;),
        axis.line = element_line(color = &quot;black&quot;),
        axis.text = element_text(face = &quot;bold&quot;, size = 9.5),
        axis.title = element_text(face = &quot;bold&quot;, size = 15)) +
  ylab(“头骨长度”) +
  ylim(180, 500)

]]></description>
      <guid>https://stats.stackexchange.com/questions/647246/dry-skull-vs-live-skull-measurement-adjustments</guid>
      <pubDate>Tue, 14 May 2024 22:02:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 mgcv 的 GAM 中的随机效应与使用 lme4 的 LMM 中的随机效应</title>
      <link>https://stats.stackexchange.com/questions/647242/random-effects-in-gams-with-mgcv-vs-random-effects-in-lmms-with-lme4</link>
      <description><![CDATA[这篇博客文章考虑了一个例子，其中GAM mgcv 包中的用于模拟随机效应：
m1_gam &lt;- gam(响应 ~ 治疗:transf_time +
                   s(主题, bs = &#39;re&#39;) +
                   s(主题, 传输时间, bs = &#39;re&#39;),
               数据 = 大鼠，方法 = &#39;REML&#39;）

估计系数：
（拦截）treatmentControl:transf_time
               68.607385 6.871130
治疗低:transf_time 治疗高:transf_time
                7.506897 7.313859

使用 lme4 包中的 LMM 也可以实现同样的效果：
m1_lmer &lt;- lmer(响应 ~ 处理:transf_time +
                    (1 | 主题) + (0 + 传输时间 | 主题),
                数据 = 大鼠）

估计系数：
（拦截）treatmentControl:transf_time
               68.607386 6.871128
治疗低:transf_time 治疗高:transf_time
                7.506897 7.313854

系数在数值上或多或少相等。我知道平滑和随机效果是相关的（例如，请参阅此 博客发布了解更多详情）。所以我认为将平滑器设置为bs = &#39;re&#39;始终与混合模型的结果一致。
在处理我当前的项目时，我注意到从不同模型获得的估计值之间存在显着差异。我有兴趣了解这些差异的更广泛原因。具体来说，您能否概述一下模型选择可能导致不同结果的一般情况？请注意，我想重点关注基本原则，而不是对我的特定数据集进行故障排除。]]></description>
      <guid>https://stats.stackexchange.com/questions/647242/random-effects-in-gams-with-mgcv-vs-random-effects-in-lmms-with-lme4</guid>
      <pubDate>Tue, 14 May 2024 21:41:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么缺少分母 df？为什么我的分子 df 被认为是无限的？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/647241/why-is-denominator-df-missing-why-is-my-numerator-df-deemed-infinite</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647241/why-is-denominator-df-missing-why-is-my-numerator-df-deemed-infinite</guid>
      <pubDate>Tue, 14 May 2024 21:19:27 GMT</pubDate>
    </item>
    <item>
      <title>如何对连续变量和两个因素之间的双向交互进行建模，而不是与 GAM 的三向交互建模？</title>
      <link>https://stats.stackexchange.com/questions/647240/how-do-you-model-the-two-way-interactions-between-a-continuous-variable-and-two</link>
      <description><![CDATA[举个例子，假设我试图根据连续变量（水温）和两个因素来模拟一些青蛙的活动水平：性别（M 或 F）和一天中的时间段（“ “夜晚”或“白天”）。我想知道无论一天中的什么时间，雄性和雌性的活动水平是否不同，以及无论性别如何，青蛙在夜间还是白天更活跃。我对不同性别之间的差异不感兴趣，这取决于一天中的时间，或者取决于性别的白天和黑夜之间的差异。以下模型是否正确可以测试（R 中 mgcv 包中的 gam 函数的语法）？
模型 = gam(活动 ~ 性别 + period_of_day + s(water_temp, by = sex) + s(water_temp, by = period_of_day), data = data, family = tw, method = REML)

我想知道我是否没有使用此语法两次包含 water_temp 的主要效果，但我对 GAM 很陌生，所以我不确定。
感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/647240/how-do-you-model-the-two-way-interactions-between-a-continuous-variable-and-two</guid>
      <pubDate>Tue, 14 May 2024 20:41:00 GMT</pubDate>
    </item>
    <item>
      <title>整体模型和二元预测器级别 2 与截距的 p 值相同（R 中的 lm 函数）</title>
      <link>https://stats.stackexchange.com/questions/647237/same-p-value-of-overall-model-and-binary-predictor-level-2-versus-intercept-lm</link>
      <description><![CDATA[我有一个响应变量 PC1（它是一系列观察结果的 PCA 分数）。我有一个响应变量 category，它有两个级别（HT 和 MT），基本上将观察结果分为两组。我在 R 中使用 lm 函数来找出 r 平方和 category 两个级别的差异。查看函数调用的结果：
调用：
lm(formula = PC1 ~ category, data = dims)

残差：
最小 1Q 中位数 3Q 最大 
-3.02263 -0.53187 -0.02024 0.60599 2.30848 

系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 0.10100 0.08248 1.225 0.2217 
categoryMT -0.20271 0.11684 -1.735 0.0838 .
---
Signif.代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：289 个自由度上的 0.9966
多重 R 平方：0.01031，调整后的 R 平方：0.006883

F 统计量：1 和 289 DF 上的 3.01，p 值：0.08382

categoryMT 的 p 值 (0.0838) 与最后一行显示的 p 值 (0.08382) 相同。为什么两个值相同？如果 category 有三个级别，情况会是这样吗？最后，对于这种特殊情况，我可以简单地报告 F 统计量、自由度和 F 统计量的 p 值来显示 categoryMT 与 Intercept（categoryHT）没有显著差异吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647237/same-p-value-of-overall-model-and-binary-predictor-level-2-versus-intercept-lm</guid>
      <pubDate>Tue, 14 May 2024 17:55:33 GMT</pubDate>
    </item>
    <item>
      <title>在具有伽玛对数链接的 GLM 模型中，如何解释具有连续响应的虚拟变量的负系数？</title>
      <link>https://stats.stackexchange.com/questions/647232/in-a-glm-model-with-a-gamma-log-link-how-to-interpret-a-negative-coefficent-of</link>
      <description><![CDATA[我对如何使用带有日志链接的 Gamma 系列解释 GLM 模型中的负系数有点困惑。
我的响应变量是连续的（没有零）且右偏，代表人均能源使用量。由于其分布，我使用带有日志链接的伽玛。我有一个二元自变量，其系数为负。这是我的 R 代码：
m5 &lt;- glm(dkw_cap ~ REF_YES + per_homeown + per_belowpov + per_bach, data = df2, family = Gamma(link=&#39;log&#39;))
摘要(m5)

称呼：
glm(公式 = dkw_cap ~ ST_YES + per_homeown + per_belowpov +
    per_bach，族= Gamma（链接=“log”），数据= df2）

系数：
             估计标准。误差t值Pr(&gt;|t|)
（截距）-4.9945 1.4115 -3.538 0.000446 ***
ST_是 -0.8079 0.3392 -2.382 0.017665 *
per_homeown 4.9634 1.4943 3.322 0.000971 ***
per_belowpov -2.3498 3.1457 -0.747 0.455461
per_bach -2.7391 1.9371 -1.414 0.158079
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（Gamma 系列的色散参数为 9.598368）

    零偏差：436 个自由度上为 995.64
残余偏差：432 个自由度上为 710.41
工商局：-1597

Fisher 评分迭代次数：25

我的困惑是如何解释与响应变量相关的 ST_YES 系数。
我读过，将截距的指数与系数相乘可以解决对数转换问题。
&lt;前&gt;&lt;代码&gt;exp(-4.9945) * exp(-0.8079)
[1] 0.003020297

假设 ST_YES 编码为 1=有树的街道，0=没有树的街道。
我如何解释这种关系？]]></description>
      <guid>https://stats.stackexchange.com/questions/647232/in-a-glm-model-with-a-gamma-log-link-how-to-interpret-a-negative-coefficent-of</guid>
      <pubDate>Tue, 14 May 2024 17:17:21 GMT</pubDate>
    </item>
    <item>
      <title>如何在 statsmodels (python) 中实现 VAR 脉冲响应函数的排序</title>
      <link>https://stats.stackexchange.com/questions/647227/how-to-implement-ordering-for-var-impulse-response-functions-in-statsmodels-pyt</link>
      <description><![CDATA[我正在尝试为 VAR 系统实现脉冲响应函数。但是，我不确定如何实现变量排序。这是否对应于数据框中列的顺序？我已经对此进行了更改，但没有对脉冲响应函数进行任何更改。请帮忙。]]></description>
      <guid>https://stats.stackexchange.com/questions/647227/how-to-implement-ordering-for-var-impulse-response-functions-in-statsmodels-pyt</guid>
      <pubDate>Tue, 14 May 2024 16:10:49 GMT</pubDate>
    </item>
    <item>
      <title>无“补偿”的拟合优度检验二项式随机变量</title>
      <link>https://stats.stackexchange.com/questions/647224/goodness-of-fit-test-binomial-random-variables-without-compensation</link>
      <description><![CDATA[设 $N_{1}, N_{2}\in\mathbb{N}^{+}$ 和随机变量 $X_{1}\sim B(N_{1},p_{1}),X_{2}\sim B(N_{2},p_{2})$ 具有原假设 &lt; span class=&quot;math-container&quot;&gt;$H_{0}:p_{1}=p_{1,0}, p_{2}=p_{2,0}$。
我想应用 GoF 测试，将 $H_{0}$ 视为 $X_{1} $ 和 $X_{2}$，但不允许“补偿” （在 $H_{0}$ 低估和高估之间）。应用泊松二项式检验时就会出现这种情况，例如，$X_{1}\leq p_{1,0}N_{1}$ 和 &lt; span class=&quot;math-container&quot;&gt;$X_{2}\geq p_{2,0}N_{2}$。但是，我希望 GoF 测试对 $X_{1}$ 和 $X_{2}$ 进行加权&gt; 根据 $N_{1}$ 和 $N_{2}$ ，例如， $N_{1}\gg N_{2}$、$X_{1}$ 驱动结果p 值大于 $X_{2}$。
我的第一个想法是根据 $N_{1}$ 和 $N_{2}$;然而，这似乎是“元分析”。没有任何证据。
接下来，我想到了“镜像” （如有必要）$X_{1}$ 或 $X_{2}$ 与 $p_{1,0}$ 或 $p_{2,0}$ 根据 $H_{0}$ 围绕 $\frac{1}{2}$，这样对于 $X_{1}$ 和 $X_{2}$、$H_{0 }$ 低估或高估，并且在应用泊松二项式检验时没有补偿。我即将通过 $$\mathbb{P}\{x\geq X|p_{0}\}=\mathbb{P} 证明镜像精确二项式测试是合理的\{x\leq \frac{N}{2}-(X-\frac{N}{2})|\frac{1}{2}-(p_{0}-\frac{1}{2} )\}=\mathbb{P}\{x\leq N-X|1-p_{0}\}=\mathbb{P}\{N-x\geq X|1-p_{0}\}$$，但我在那里并不安静，不知道从哪里开始证明在考虑 $X_{1}$ 和 $X_{2}$。
您对于合适的 GoF 检验还有其他建议吗？找到加权 p 值的任何证据吗？或者对证明镜像二项式分布之一的正确性有见解吗？谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/647224/goodness-of-fit-test-binomial-random-variables-without-compensation</guid>
      <pubDate>Tue, 14 May 2024 15:34:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么将 IQR 数据分为 4 个部分，而不是每个部分 20 或 10 个百分比？</title>
      <link>https://stats.stackexchange.com/questions/647182/why-divide-data-into-4-parts-for-iqr-and-not-into-parts-of-20-or-10-percentages</link>
      <description><![CDATA[为什么将数据分为 4 个部分以进行 IQR，而不是分成更多部分，例如每个部分 20% 或 10%？
我知道四分位距的定义是 25%，但这不是我的问题。
我认为丢弃 IQR 的 50% 数据来删除异常值太浪费数据了。但总得有个理由吧？]]></description>
      <guid>https://stats.stackexchange.com/questions/647182/why-divide-data-into-4-parts-for-iqr-and-not-into-parts-of-20-or-10-percentages</guid>
      <pubDate>Tue, 14 May 2024 06:25:10 GMT</pubDate>
    </item>
    <item>
      <title>对于什么样的分布，联合分布可以由边际分布和相关性唯一确定？</title>
      <link>https://stats.stackexchange.com/questions/647179/for-what-kind-of-distributions-the-joint-distribution-could-be-determined-uniqu</link>
      <description><![CDATA[假设 $X$ 和 $Y$ 来自同一分布$P$ 和 $\rho = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}} $ 是固定的。对于什么样的$P$我们可以唯一确定$X,Y$的联合分布？&lt; /p&gt;
我知道两个具有上述属性的分布，即

$P = N(\mu,\sigma^2)$，即正态分布
$P = Ber(p)$，即伯努利分布

此列表中还有其他发行版吗？或者我们可以用这个属性来描述分布吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647179/for-what-kind-of-distributions-the-joint-distribution-could-be-determined-uniqu</guid>
      <pubDate>Tue, 14 May 2024 01:35:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么 1/SE 或 1/方差通常用作回归中的权重？</title>
      <link>https://stats.stackexchange.com/questions/647146/why-are-1-se-or-1-variance-commonly-used-as-weights-in-regressions</link>
      <description><![CDATA[我第一次尝试进行荟萃分析，将简单实验处理的测量结果与多个物种的对照进行比较。我首先将混合效应模型拟合到从一组已发表的研究中收集的平均值。这工作得很好，但它当然忽略了一个事实，即平均值是用不同的精度水平估计的。听起来这是一个应该通过适当加权手段来解决的问题。其中几项研究发布了标准误差或其原始数据，因此我可以使用 SE 进行加权。
我的问题是：1/SE（或 1/ σ2）有什么特别之处？为什么不使用 2/SE、10/SE 或任何其他此类加权因子？
我很想问这个问题，因为由于一些研究使用了极其精确的仪器，SE 相差几乎两个数量级。精度越高显然越好，但对我来说，这些精确估计值与 100 次精确估计值相比并不明显。 （加权在拟合模型时还引入了一些算法问题，但这可能是可以解决的，我对概念论证更感兴趣）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647146/why-are-1-se-or-1-variance-commonly-used-as-weights-in-regressions</guid>
      <pubDate>Mon, 13 May 2024 14:37:12 GMT</pubDate>
    </item>
    <item>
      <title>导出平方样本相关性的期望和方差：delta 方法还是其他方法？</title>
      <link>https://stats.stackexchange.com/questions/647006/derive-the-expectation-and-variance-of-squared-sample-correlation-delta-method</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647006/derive-the-expectation-and-variance-of-squared-sample-correlation-delta-method</guid>
      <pubDate>Fri, 10 May 2024 23:28:30 GMT</pubDate>
    </item>
    <item>
      <title>AR(p) 的长期方差</title>
      <link>https://stats.stackexchange.com/questions/569666/long-term-variance-of-arp</link>
      <description><![CDATA[根据 Yule-Walker 方程，AR(p) 过程的长期方差为 $$\frac{\sigma^2}{1-\phi_1\ rho_1 \ldots - \phi_p\rho_p}$$
其中 AR(p) 定义为 $$Y_{t}=\delta + \phi_1 y_{t-1} \ldots + \phi_p y_{t-p} + \epsilon_t $ $
其中 $\sigma^2$ 表示所有白噪声过程 $\epsilon_t$ 的方差$t$。 $\rho_t$ 表示 $Y_t$ 与 $Y_{t-h}$。
该结果的推导如下。
令人困惑的是，我的 FRM 书指出 AR(p) 的长期方差等于：
$$\frac{\sigma^2}{1-\phi_1 \ldots - \phi_p}$$
这表明所有自相关性都必须为 1，这是不正确的。
我还发现结果表明长期方差应该是：
$$\frac{\sigma^2}{1-\phi_1^2 \ldots - \phi_p^2}$$
（例如：https://gregorygundersen.com/blog/2022/01 /06/自回归模型/）
哪个是正确的？
推导长期方差：
令 $\gamma_t$ 为自协方差
$Y_t$ 与 $Y_{t-h}$。
$$ \gamma_0=\phi_1\gamma_1 + \ldots + \phi_p\gamma_p + \sigma^2$$
使用 $\gamma_j=\rho_j\gamma_0$：
$$ \gamma_0= \phi_1\rho_1\gamma_0 \ldots + \phi_p\rho_p\gamma_0 + \sigma^2 $$]]></description>
      <guid>https://stats.stackexchange.com/questions/569666/long-term-variance-of-arp</guid>
      <pubDate>Wed, 30 Mar 2022 00:13:21 GMT</pubDate>
    </item>
    </channel>
</rss>