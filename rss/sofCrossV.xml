<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 31 Aug 2024 01:10:30 GMT</lastBuildDate>
    <item>
      <title>贝叶斯估计和有偏估计</title>
      <link>https://stats.stackexchange.com/questions/653653/bayesian-estimation-and-biased-estimators</link>
      <description><![CDATA[我刚刚学习了非贝叶斯与贝叶斯参数估计。我自己的总结：
非贝叶斯：当参数的统计数据不可用时，CRLB 适用于无偏估计量，但存在有偏估计量优于无偏估计量的情况。
贝叶斯：MMSE 是条件均值，它总是无偏的。贝叶斯 CRLB 也适用于无偏估计量。因此，有偏估计量始终满足贝叶斯 CRLB 并且表现不如无偏 MMSE。
两个问题：
有人可以确认上述我的理解吗？
贝叶斯估计问题中有有偏估计量的良好激励示例吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653653/bayesian-estimation-and-biased-estimators</guid>
      <pubDate>Sat, 31 Aug 2024 01:09:18 GMT</pubDate>
    </item>
    <item>
      <title>在线性回归下推导 MSE($\hat{\beta}$)</title>
      <link>https://stats.stackexchange.com/questions/653651/deriving-mse-hat-beta-under-linear-regression</link>
      <description><![CDATA[我能够推导出 MSE，但是推导过程中有一部分我不太明白。这是我得到的结果：
事实：

$\mathbb{E}(​​\hat{\beta})=\hat{\beta}\space$（无偏估计量）
$\text{Cov}(\hat{\beta})= \sigma^2[(X^TX)^{-1}] $

根据定义，
$$MSE = \mathbb{E}[||\hat{\beta}-\beta||^2] $$
$$= \space \mathbb{E}[(\hat{\beta}-\beta)^T(\hat{\beta}-\beta)]$$
由于 $\hat{\beta}$ 是无偏的，
$$ \boldsymbol{= \text{tr}[\text{Cov}(\hat{\beta})]} *$$
$$= \text{tr}[\sigma^2(X^T X)^{-1}]$$
$\sigma^2$ 是标量，因此可以分解出来，
$$= \sigma^2 tr[(X^T X)^{-1}] $$
我感到困惑的是行 $*$，我不确定我们是如何得到方程式 $ \text{tr}[\text{Cov}(\hat{\beta})] $。以下是我目前所理解的：
通过偏差-方差分解，
$$ \space \mathbb{E}[(\hat{\beta}-\beta)^T(\hat{\beta}-\beta)]=\mathbb{V}(\hat{\beta})+[\mathbb{E}(​​\hat{\beta})-\beta]^T[\mathbb{E}(​​\hat{\beta})-\beta]$$
我们的估计量是无偏的，因此 $\mathbb{E}(​​\hat{\beta})-\beta= 0$。因此，
$$\mathbb{E}[(\hat{\beta}-\beta)^T(\hat{\beta}-\beta)]=\mathbb{V}(\hat{\beta})$$

首先，$\mathbb{V}(\hat{\beta})$ 应该是一个标量，但对我来说这真的没什么意义，这让我想到了下一个问题...
我假设 $V(\hat{\beta}) = \text{tr}[\text{Cov}(\hat{\beta})]$。这是为什么呢？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653651/deriving-mse-hat-beta-under-linear-regression</guid>
      <pubDate>Sat, 31 Aug 2024 00:13:56 GMT</pubDate>
    </item>
    <item>
      <title>了解 XGboost 早期轮次的预测</title>
      <link>https://stats.stackexchange.com/questions/653649/understanding-predictions-from-early-rounds-of-xgboost</link>
      <description><![CDATA[我有一个数据集，我正在通过 xgboost 使用伽马回归进行建模。目标变量的平均值约为 13,000。如果我以 nrounds = 20 运行 xgb.train，我的拟合指标会得到如下改进：
[1] eval-gamma-nloglik:19068.589753 train-gamma-nloglik:19214.349747 
[2] eval-gamma-nloglik:14126.776741 train-gamma-nloglik:14234.760451 
[3] eval-gamma-nloglik:10465.869439 train-gamma-nloglik:10545.868618 
[4] eval-gamma-nloglik:7753.880010 train-gamma-nloglik:7813.146760 
[5] eval-gamma-nloglik:5744.865650 train-gamma-nloglik:5788.775051 [6] eval-gamma-nloglik:4256.630570 train-gamma-nloglik:4289.161127 [7] eval-gamma-nloglik:3154.190101 train-gamma-nloglik ：3178.297719 [8] eval-gamma-nloglik：2337.566473 train-gamma-nloglik：2355.427432 [9] eval-gamma-nloglik：1732.674952 train-gamma-nloglik：1745.907601 [10]    eval-gamma-nloglik：1284.639146 train-gamma-nloglik：1294.441921 [11] eval-gamma-nloglik：952.802399 train-gamma-nloglik：960.065419 [12] eval-gamma-nloglik：707.048396 train-gamma-nloglik： 712.430466 [13] eval-gamma-nloglik:525.066581 train-gamma-nloglik:529.055224 [14] eval-gamma-nloglik:390.324413 train-gamma-nloglik:393.284621 [15]    eval-gamma-nloglik:290.585986 train-gamma-nloglik:292.780028 [16] eval-gamma-nloglik:216.774041 train-gamma-nloglik:218.400892 [17] eval-gamma-nloglik:162.168768 train-gamma-nloglik:16 3.375479 [18] eval-gamma-nloglik:121.791626 train-gamma-nloglik:122.687146 [19] eval-gamma-nloglik:91.956086 train-gamma-nloglik:92.619277 [20] eval-gamma-nloglik:69.927169 train-gamma-nloglik:70.418368 

如果我对验证集进行预测，20 轮后该模型的平均预测为 194 - 相对于目标变量的大小（平均值为 13,000），这似乎很荒谬。直到大约 50 轮后，我才得到相对于目标变量大小的合理结果。我对算法的理解是，Tree 0 至少应该产生一个合理的模型，即使它基本上只是一个没有实际分割的截距，因为选择了一个坏变量作为它的覆盖。
我是否遗漏了关于提升树如何工作的某些内容，或者这只是一个教训，即如果 nrounds 太低，该模型基本上毫无意义，比仅截距模型更糟糕？]]></description>
      <guid>https://stats.stackexchange.com/questions/653649/understanding-predictions-from-early-rounds-of-xgboost</guid>
      <pubDate>Fri, 30 Aug 2024 21:01:01 GMT</pubDate>
    </item>
    <item>
      <title>“Fisher 互相关变换”的含义</title>
      <link>https://stats.stackexchange.com/questions/653647/meaning-of-fisher-transformation-of-cross-correlations</link>
      <description><![CDATA[我正在阅读一篇论文，其中指出（https://www.nature.com/articles/s41598-023-41960-2）：

在 SUSY 中，互相关是分段计算的；时间序列被切成例如 30 秒持续时间的段，并且每个段内的互相关是在一定范围的滞后 L 内计算的。许多研究中的默认值是选择最大滞后高达 ± 3 s 或 ± 5 s，以便考虑 6 秒或 10 秒窗口内的所有互相关，即互相关范围 L。段大小和窗口大小是 SUSY 中的基本参数。因此，这种操作化包括同时（L = 0）相关以及时间滞后的（交叉）相关。为了允许聚合，所有交叉相关都必须使用 Fisher 的 Z 变换进行转换。

我不确定我是否理解从交叉相关到 Fisher 的 Z 变换的跳跃：Fisher 的变换不是基于 Pearson 相关系数吗？将 Fisher 的 Z 变换应用于交叉相关意味着什么？特别是，Fisher 的 Z 变换实际上只对 -1 和 1 之间的 R 值有意义，而交叉相关系数的情况并非如此。]]></description>
      <guid>https://stats.stackexchange.com/questions/653647/meaning-of-fisher-transformation-of-cross-correlations</guid>
      <pubDate>Fri, 30 Aug 2024 19:46:23 GMT</pubDate>
    </item>
    <item>
      <title>Kendall tau-c 永远不可能是 1？</title>
      <link>https://stats.stackexchange.com/questions/653646/kendall-tau-c-can-never-be-1</link>
      <description><![CDATA[我有一个按 5 分制评分的系统（4=非常好，3=好，2=一般，1=差，0=非常差）。现在，我想将它们转换为二进制分数，所以我想设置一个阈值，然后将它们转换为 1/0 分数。我的直觉是，5 分制分数和二进制分数应该始终具有完美的等级相关性，即等级相关性为 1。（信息丢失是另一回事。）
我使用 Kendall tau-c，因为它旨在测量不同数量的可能结果（5 对 2）之间的等级相关性。但我发现在以下最简单的例子中，相关性并不相同，并且远离 1。
print(scipy.stats.kendalltau([0, 0, 0, 0, 1], [0, 1, 2, 3, 4], variant=&#39;c&#39;)) # 1 if &gt;= 4 and 0 o.w.
print(scipy.stats.kendalltau([0, 0, 0, 1, 1], [0, 1, 2, 3, 4], variant=&#39;c&#39;)) # 1 if &gt;= 3 and 0 o.w.
打印（scipy.stats.kendalltau（[0, 0, 1, 1, 1]，[0, 1, 2, 3, 4]，variant=&#39;c&#39;））# 1 如果 &gt;= 2 且 0 o.w.
打印（scipy.stats.kendalltau（[0, 1, 1, 1, 1]，[0, 1, 2, 3, 4]，variant=&#39;c&#39;））# 1 如果 &gt;= 1 且 0 o.w.

输出
SignificanceResult(statistic=0.64, pvalue=0.15729920705028516)
SignificanceResult(statistic=0.96, pvalue=0.0832645166635504)
SignificanceResult(statistic=0.96, pvalue=0.0832645166635504)
SignificanceResult(statistic=0.64, pvalue=0.15729920705028516)

这似乎表明，无论我如何调整阈值或设计二进制转换器，我都无法使 Kendall tau-c 达到 1。我完全理解 Kendal tau-b 不应该是 1情况，但我的理解是，矩形调整的目标是纠正这种情况，以便相关性在完美情况下可以达到 1。
这是一个错误还是一个功能？并且，还有其他一些等级相关性变体可以在这种情况下产生 1 的相关性？]]></description>
      <guid>https://stats.stackexchange.com/questions/653646/kendall-tau-c-can-never-be-1</guid>
      <pubDate>Fri, 30 Aug 2024 19:45:11 GMT</pubDate>
    </item>
    <item>
      <title>Y 值不确定的模型</title>
      <link>https://stats.stackexchange.com/questions/653642/models-with-uncertainty-in-y</link>
      <description><![CDATA[假设我有变量 y 的预测因子 x1、x2、x3...xn 的数据。我基本上使用贝叶斯分析估算了 y，这意味着我对 y 的每个值都有一个后验分布。为了计算从 x1 到 xn 预测 y 的后续模型，同时保持 y 的不确定性，我通常会使用 brms 包中的 brm_multiple 函数之类的函数，它允许我们从后验分布的不同 y 值计算相同的模型，然后最后将它们组合成相同的模型。不幸的是，我有太多数据，贝叶斯方法不可行。
我该如何用频率统计做类似的事情？有没有办法运行一堆模型，然后在最后合并这些模型，或者可能将每个 y 作为原始模型中的分布，等等？
以下是 R 代码，用于生成采用我所说的形式的玩具数据集：
# 设置种子以实现可重复性
set.seed(42)

# 使用预测器创建玩具数据
n &lt;- 100
x1 &lt;- rnorm(n)
x2 &lt;- rnorm(n, mean = 3)
x3 &lt;- rnorm(n, mean = -2)

# 模拟 y 的后验样本（例如，来自后验分布的 5 个样本）
y_post_1 &lt;- 2 + 1.5*x1 - 0.7*x2 + 0.5*x3 + rnorm(n)
y_post_2 &lt;- 2 + 1.5*x1 - 0.7*x2 + 0.5*x3 + rnorm(n)
y_post_3 &lt;- 2 + 1.5*x1 - 0.7*x2 + 0.5*x3 + rnorm(n)
y_post_4 &lt;- 2 + 1.5*x1 - 0.7*x2 + 0.5*x3 + rnorm(n)
y_post_5 &lt;- 2 + 1.5*x1 - 0.7*x2 + 0.5*x3 + rnorm(n)

# 合并为一个数据框
toy_data &lt;- data.frame(x1, x2, x3, y_post_1, y_post_2, y_post_3, 
y_post_4, y_post_5)

# 显示数据集的前几行
head(toy_data)
]]></description>
      <guid>https://stats.stackexchange.com/questions/653642/models-with-uncertainty-in-y</guid>
      <pubDate>Fri, 30 Aug 2024 18:46:37 GMT</pubDate>
    </item>
    <item>
      <title>对不平衡样本进行加权以反映人口分布</title>
      <link>https://stats.stackexchange.com/questions/653637/weighting-imbalanced-sample-to-reflect-population-distribution</link>
      <description><![CDATA[我有一个具有某些特征（V1 ~ 地区，V2 ~ 职业类型）的人口（pop），所有预测因子都是分类的。我有另一个数据集，其中仅包含人口的一部分~ 50%，并带有指示变量（例如家庭收入 - 连续，财产所有权 - 二元）。链接 2 个数据集后，最终样本（样本）的 V1 和 V2 交集分布与人口（d1，d2）不同，因此样本和人口在指示变量上的汇总统计数据不同。这对分析来说是个问题，所以我需要以某种方式平衡样本，使变量 V1 和 V2 的交集相似。
有人告诉我，我不应该从样本中删除数据，而是要为样本中的实例分配权重，但我不知道该怎么做。有什么好的统计方法可以做到这一点吗？
感谢您的帮助。
pop &lt;- do.call(cbind.data.frame, list(sample(c(&quot;a&quot;, &quot;b&quot;), 
replace = TRUE, size = 200, prob = c(0.5, 0.5) ), 
sample(c(&quot;d&quot;, &quot;e&quot;), replace = TRUE, size = 200, 
prob = c(0.5, 0.5)), 
sample(c(&quot;g&quot;, &quot;h&quot;), replace = TRUE, size = 200, 
prob = c(0.5, 0.5) ) ))

colnames(pop) &lt;- c(&quot;V1&quot;, &quot;V2&quot;)

sample &lt;- do.call(cbind.data.frame, 
list(sample(c(&quot;a&quot;, &quot;b&quot;), replace = TRUE, size = 100, 
prob = c(0.7, 0.3) ), 
sample(c(&quot;d&quot;, &quot;e&quot;), replace = TRUE, size = 100, 
prob = c(0.3, 0.7)), 
sample(c(&quot;g&quot;, &quot;h&quot;), replace = TRUE, size = 100, 
prob = c(0.5, 0.5) ) ))

colnames(sample) &lt;- c(&quot;V1&quot;, &quot;V2&quot;)

d1 &lt;- prop.table(table(paste0(pop$V1, pop$V2)))

d2 &lt;- prop.table(table(paste0(sample$V1, sample$V2)))
]]></description>
      <guid>https://stats.stackexchange.com/questions/653637/weighting-imbalanced-sample-to-reflect-population-distribution</guid>
      <pubDate>Fri, 30 Aug 2024 17:46:01 GMT</pubDate>
    </item>
    <item>
      <title>简单线性回归中的统计误差</title>
      <link>https://stats.stackexchange.com/questions/653635/statistical-error-in-simple-linear-regression</link>
      <description><![CDATA[首先我想说的是，我正在寻找一个简单的回归模型，而不是一个数学模型，来对这个术语进行更多的概念性理解。
在计量经济学中，简单的线性回归有一个“误差项”，称为mu，它表示“影响y的除x之外的因素，或未观察到的数据”。在统计学课上，这个术语被称为“统计误差”或“噪声”，被视为epsilon，这又是现实世界中我们的模型无法捕捉到的随机噪声。
在《统计学习简介》中，这个术语被称为“不可约误差”，是一个表示我们尚未测量的未测量变量的数量，或者只是现实世界数据中无法测量的变化。作者将这个术语与可约误差区分开来。
这就是我感到困惑的地方：在一个理论上完全确定的世界中，我们拥有无限量的数据，这个“不可约误差”在理论上是可以约化的吗？也就是说，如果在这个理论世界中，我们的协变量，大学 GPA，可以映射到我们的响应，比如“薪水”，那么这个术语在技术上可以为零吗？
我理解，在我们生活的世界中，数据总是存在不可测量的变化，我们永远无法获得无限量的数据或事先知道每一个协变量，因此会出现这个错误。但是假设我们有 5 个数据点，这是我们的“理论总体”，这个“不可约误差”会是零吗？术语消失？
例如，在《统计学习简介》中，他们有这张图片：

我对这张图片的困惑源于这个数据是模拟的，所以我们实际上知道真正的底层函数 f。但如果是这样的话，为什么还有错误？如果我们知道 f，为什么我们不能完美地将这个函数与数据拟合？如果这个数据是基于 f 模拟的，为什么模拟不会在函数 f 上产生数据点？
我知道这似乎是一个愚蠢的问题，但我试图理解这里的细微差别。非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653635/statistical-error-in-simple-linear-regression</guid>
      <pubDate>Fri, 30 Aug 2024 17:14:15 GMT</pubDate>
    </item>
    <item>
      <title>测试一个列表是否大于另一个列表</title>
      <link>https://stats.stackexchange.com/questions/653634/a-test-to-show-that-one-list-is-greater-than-another</link>
      <description><![CDATA[我已计算不同细胞类型中每个细胞的癌症干细胞评分 (NES)。可视化后，我可以看到恶性细胞的峰值比肝细胞的峰值具有更大的 NES。

我在 R 上运行了 Welch 双样本 t 检验，以查看其中一个的平均值是否大于另一个的平均值，但得到的 p 值 = 1。还有其他方法可以比较这两个列表以捕捉差异吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653634/a-test-to-show-that-one-list-is-greater-than-another</guid>
      <pubDate>Fri, 30 Aug 2024 16:57:54 GMT</pubDate>
    </item>
    <item>
      <title>这是在同一维度上使用许多不同评估进行聚类的正确方法吗？</title>
      <link>https://stats.stackexchange.com/questions/653643/is-this-the-right-approach-to-cluster-using-many-different-evaluations-on-the-sa</link>
      <description><![CDATA[我正在做一个项目，想把政党分成两组。我想利用调查中许多受访者的回答，他们指出了每个政党在左右尺度上的位置。我对我的数据使用了 k 均值聚类，得到了非常合理的工作结果。但是，鉴于我对任何类型的聚类方法都很陌生，而且我在网上找不到任何在聚类中处理类似数据结构的示例，我想确保我做的是正确的。所以，我的问题是：

下面的方法是否是处理我的数据格式的有效方法？
我现在使用的是两个集群，这是我想要的，但我也想确保我没有完全偏离将政党强行放入它们不适合的集群。有没有办法在事后验证集群的数量？我熟悉肘形图和其他估计理想聚类数的方法，但我正在寻找一种方法来评估/评分我已经完成的聚类。

提前谢谢您！
# Party Dataset
df &lt;- data.frame(&quot;Party A&quot; = c(2,3,4,3,3),
&quot;Party B&quot; = c(3,3,4,5,4),
&quot;Party C&quot; = c(4,5,6,7,6),
&quot;Party D&quot; = c(5,6,7,8,7),
&quot;Party E&quot; = c(6,7,8,NA,8))

# Transpose Dataframe
df &lt;- as.data.frame(t(df)) %&gt;% 
mutate_all(as.numeric)

# 找出所有缺失值
ind &lt;- which(is.na(df), arr.ind=TRUE)
# 用行均值替换
df[ind] &lt;- rowMeans(df, na.rm = TRUE)[ind[,1]]

# 删除空行
df &lt;- na.omit(df)

# 缩放
df &lt;- scale(df)

# 删除缩放数据中缺失值的案例
t &lt;- t[,colSums(is.na(t))&lt;nrow(t)]

# 使用 2 个 kmeans 中心进行聚类
km.res &lt;- kmeans(df, 2, nstart = 25)
]]></description>
      <guid>https://stats.stackexchange.com/questions/653643/is-this-the-right-approach-to-cluster-using-many-different-evaluations-on-the-sa</guid>
      <pubDate>Fri, 30 Aug 2024 16:28:01 GMT</pubDate>
    </item>
    <item>
      <title>差异设计中如何确定未处理组的处理时间</title>
      <link>https://stats.stackexchange.com/questions/653633/how-to-determine-the-treatment-time-for-untreated-in-difference-in-difference-de</link>
      <description><![CDATA[我正在使用差异-差异 (DiD) 设计估计治疗启动对健康结果的影响。时间线是相对于治疗日期而不是日历时间定义的。对于治疗组，索引时间 (t=0) 是每个人开始治疗的日期，治疗前期最多为 3 年，治疗后期最多为治疗后 3 年。
我的挑战是确定对照组（未开始治疗的人）的伪治疗日期，以类似地定义他们的治疗前期和治疗后期。
我正在考虑根据治疗组中治疗启动日期的分布随机为对照组分配伪治疗日期。具体来说，我计划根据关键变量对参与者进行分层，并在每个层内，从治疗组中观察到的诊断和治疗开始之间的持续时间进行替换抽样，为该层的对照组分配一个伪治疗日期。
我的问题是：

有没有更好的方法来分配伪治疗日期？
如果这种方法有效，我如何计算由于对照组伪治疗日期的随机性而导致的不确定性？通过改变这些日期进行敏感性分析是否足够？
是否有任何参考文献或研究讨论过这种方法或类似的问题？我在术语方面遇到困难，希望得到有关寻找什么的指导。

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653633/how-to-determine-the-treatment-time-for-untreated-in-difference-in-difference-de</guid>
      <pubDate>Fri, 30 Aug 2024 16:12:41 GMT</pubDate>
    </item>
    <item>
      <title>生存分析中的校准图</title>
      <link>https://stats.stackexchange.com/questions/653629/calibration-plot-in-survival-analysis</link>
      <description><![CDATA[我试图从校准的角度评估我的参数比例风险和加速失效模型。似乎有很多种方法可以总结校准，但它们只给出了一个总结指标，我认为这并不能很好地洞察模型的校准。
我更愿意使用校准图。在我最初的尝试中，我使用我的模型来预测审查时的结果（评估患者是否存在某种疾病的时间 - 现在让我们忽略区间审查），根据预测风险的分位数将患者安排到箱子中，然后简单地绘制观察值（箱子中经历事件的 N 名患者/箱子中的 N 名患者）与该分位数的平均风险。然后可以通过平滑器增强点图，但我认为这不是必要的。我也尝试过“引导”通过一次对 1/3 的人口进行 100 次重新采样，然后绘制平滑线。
但是，似乎（link）这种方法不是推荐的。我明白我应该估计所有患者在规定时间内（比如 1 年）的预期生存率，然后根据预期生存率创建分位数组，在每个组中创建一个 KM，并在与“观察到的”风险相同的间隔（1 年）内使用其预测，然后绘制平滑线。

我原来的方法完全不合适吗？
我对“正确”方法的理解正确吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653629/calibration-plot-in-survival-analysis</guid>
      <pubDate>Fri, 30 Aug 2024 15:23:40 GMT</pubDate>
    </item>
    <item>
      <title>利用混合样本确定生物学重复</title>
      <link>https://stats.stackexchange.com/questions/653624/determining-biological-replicates-with-pooled-samples</link>
      <description><![CDATA[我们小组有一个长期存在的方案，其中汇集了多个组织纯化样本。这是因为每只动物的组织很少。然后对该池进行多次采样，并测量感兴趣的结果。每次测量都被视为推理分析的独立数据点。虽然这些单个样本可能是“重复”，但它们作为生物重复的状态充其量是高度可疑的。它们看起来可能是伪重复。
即，用两种药物治疗动物。提取的组织被合并到两个池中。每个池采样 x 次。然后通过药物治疗分析这些样品，每次治疗 n = x。
应该如何调整这种设计？目前没有办法只使用一只动物的组织进行测定。必须将组织组合起来。
如果我们使用更多动物并创建多个池，那么每个池可以采样几次，以解释因组合动物而引入的变化。这将使用混合级别模型进行建模。每个池是否都是一个单一的生物学重复，并且池中的每个样本都是随机效应内的聚类？
因此，两种治疗方法，每种治疗方法有 M 只动物。组织提取物组合成 P 个池，每个池采样 N 次。模型中每个治疗方法的 n = P，单个样本按 P 聚类。
还有其他方法可以做到这一点吗？
（这是我最近问过的一个问题的重述，但措辞不当且令人困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/653624/determining-biological-replicates-with-pooled-samples</guid>
      <pubDate>Fri, 30 Aug 2024 14:35:33 GMT</pubDate>
    </item>
    <item>
      <title>与 lmm 相比，glmm 的假阳性率较低吗？</title>
      <link>https://stats.stackexchange.com/questions/653606/low-false-positive-rates-in-glmm-compared-to-lmm</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653606/low-false-positive-rates-in-glmm-compared-to-lmm</guid>
      <pubDate>Fri, 30 Aug 2024 09:45:18 GMT</pubDate>
    </item>
    <item>
      <title>对独立数据和非独立数据一起进行统计检验？</title>
      <link>https://stats.stackexchange.com/questions/653559/statistical-test-for-independent-and-non-independent-data-together</link>
      <description><![CDATA[目的
我想比较几位作者（研究 1 至 5）的研究结果中一些常见精神障碍 (CMD) 的患病率。所有研究都是观察性的。其中四个是横断面研究，一个是纵向研究（研究 4）。
问题
我不能使用独立性卡方检验，因为纵向研究违反了观察独立性的假设。
示例
下表显示了收集的数据的示例。



研究
n
CMD1 (%)
CMD2 (%)
CMD3 (%)




研究 1
54
NA
NA
26.0


研究 2
198
25.0
19.9
27.0


研究 3
278
38.0
40.0
25.0


研究 4 - T1
595
27.0
31.0
3.6


研究 4 - T2
504
21.0
33.0
3.4


研究 4 - T3
374
22.0
35.0
4.9


研究 5
208
20.3
NA
NA



主要问题

已知研究 4 是一项纵向研究，因此违反了观察独立性的假设，那么最适合检查 CMD1、CMD2 和 CMD3 研究之间是否存在统计学上显着差异的分析是什么？

次要问题

如果有多个分析，哪一个最适合，为什么？
我是否应该考虑贝叶斯检验而不是频率检验？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653559/statistical-test-for-independent-and-non-independent-data-together</guid>
      <pubDate>Thu, 29 Aug 2024 12:37:29 GMT</pubDate>
    </item>
    </channel>
</rss>