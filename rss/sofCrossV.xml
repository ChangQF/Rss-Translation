<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 03 Feb 2025 15:17:42 GMT</lastBuildDate>
    <item>
      <title>多级模型中随机截距的显著性检验</title>
      <link>https://stats.stackexchange.com/questions/660908/significance-testing-for-random-intercepts-in-multilevel-model</link>
      <description><![CDATA[我正在估算一个多级 Mundlak 式模型来预测学校内的学生表现。这涉及计算每个学校 j (u_j) 的随机截距。
当我估算 u_j 时，我想比较学校之间的这些截距作为增值衡量标准。我如何获得这些截距的置信区间？是否有进行这些计算的关键参考/信息来源？
我知道截距是使用收缩估计器估算的，该估计器考虑了小组中的不精确性。但在估算单个随机截距的标准误差时，如何解释这一点？
即，标准误差的基本公式是 Var(u_j)^2/sqrt(N_j)。但是，我不确定这是否考虑到了这样一个事实，即基于样本中其他组的信息，小 N 的估计值已经受到收缩的影响。
感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/660908/significance-testing-for-random-intercepts-in-multilevel-model</guid>
      <pubDate>Mon, 03 Feb 2025 12:12:25 GMT</pubDate>
    </item>
    <item>
      <title>赢家临床试验的减偏估计量</title>
      <link>https://stats.stackexchange.com/questions/660907/bias-reduced-estimator-for-play-the-winner-clinical-trial</link>
      <description><![CDATA[我正在尝试为一场“赢家必赢”的临床试验制作一个减少偏差的效应大小估计器。
问题是这样的：假设我们在第 2 阶段有两个实验组的结果，我们将它们称为 mA 和 mB，为简单起见，假设已知方差，即 mA~N(muA,1)、mB~N(muB,1)。为简单起见，假设我们与已知 mu0 = 0 的外部对照进行比较。
对于第 3 阶段，如果 mA&gt;mB，我们选择药物 A，如果 mB&gt;mA，我们选择药物 B。最终分析将是第 2 阶段和第 3 阶段数据的汇总分析。
在 H0：muA=muB=0 下，如果我们只是对 max(mA,mB) 和第 3 阶段数据进行简单的汇总，我们会在最终分析中得到正偏差。多重校正程序可以控制 1 类错误率，但我们还需要对 max(muA,muB) 估计进行偏差校正。有一些众所周知的特殊情况，例如，如果 mA&gt;&gt;mB 或 mA=mB 则没有问题，如果 muA=muB 则成为极值理论问题。但我想要更通用的东西。可能每个估计量在频率论意义上都会有偏差，但人们可以希望有一个可辩护的贝叶斯估计量。也许是因为我不擅长贝叶斯统计，但到目前为止我实现的所有估计量都给出了荒谬的结果。
有人知道相关研究吗？我在 Google Scholar 上找不到任何有用的东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/660907/bias-reduced-estimator-for-play-the-winner-clinical-trial</guid>
      <pubDate>Mon, 03 Feb 2025 12:06:15 GMT</pubDate>
    </item>
    <item>
      <title>逆条件累积分布函数</title>
      <link>https://stats.stackexchange.com/questions/660904/inverse-conditional-cdfs</link>
      <description><![CDATA[假设我有一个满足以下条件的条件 CDF 函数：
$\mathbb{P}\left ( Y\leq y| X=x\right )=\mathbb{P}\left ( Y\leq y|X=x&#39; \right ) +c$，其中 $c$ 表示所有概率都限制在单位间隔内。
说 $F^{-1}_{Y|X=x}(.)=F^{-1}_{Y|X=x&#39;}(F_{Y|X=x&#39;}(.)+c)$ 是否正确？我相信根据关于逆的直观推理，这是合理的，但我想确定一下。提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660904/inverse-conditional-cdfs</guid>
      <pubDate>Mon, 03 Feb 2025 11:14:28 GMT</pubDate>
    </item>
    <item>
      <title>Google 评分的误差估计</title>
      <link>https://stats.stackexchange.com/questions/660903/estimate-of-error-for-google-rating</link>
      <description><![CDATA[概述。
对于我的一个私人项目，我正在研究 Google 的评级系统。在那里，您可以为本地商店评级 1、2、3、4 或 5 星。我从我所在地区的一个相当大的设施获取了数据，并计算了平均评级 $m$，该评级与提交的评级数量 $n$ 以及其标准差 $s$ 有关。但是，我不确定在这种情况下使用标准差是否合理。这就是问题所在。
描述。
本地商店 Shop&#39;n&#39;Go（虚构）向我提供了其 Google 评级数据。假设商店不改变其政策、价格或员工，我认为商店的优劣反映在客户的平均评分中，这样在提交大量评分后，平均评分趋向于某个实际值$r$，介于$1$和$5$之间，即
$$\lim_{n \rightarrow \infty} m(n) = r$$
因此，我想预测这个值是什么，所以我计算了平均评分。但为了“估计平均值的准确性”，我还计算了标准差。
下图显示了 Shop&#39;n&#39;Go 的平均评分 $m(n)$ ($\color{blue}{\text{blue}}$) 和标准差 $s(n)$ ($\color{lightgrey}{\text{grey}}$) 与提交的评分数量的关系。可以看出，Shop&#39;n&#39;Go 的评分已超过 10,000 次。

问题陈述。
根据提交的大量评分，我预计平均值的误差很小。然而，事实证明，标准偏差的范围相当大；范围从大约 $5$ 颗星到 $3.5$ 颗星。我认为这种行为是由于客户倾向于给 $5$ 颗星（如果他们喜欢这家商店）或 $1$ 颗星（如果他们不喜欢这家商店）造成的。$\{2,3,4\}$ 颗星通常不常用。这个事实让我怀疑使用标准差的合理性，因为我认为它高估了误差。我猜想，更好更准确的估计与 $\{1,2,3,4,5\}$ 星级评分的分布有关，通常定性地采用与下图类似的形式。

我不太擅长统计，所以我不知道这个命题是否有意义。如果有意义，因此标准差不理想，那么在这种情况下，计算平均值误差的更好方法是什么？是否有任何已知的概率分布可以模拟这种情况或类似情况？如果不是，您认为适合以下分布的拟合函数是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660903/estimate-of-error-for-google-rating</guid>
      <pubDate>Mon, 03 Feb 2025 11:09:01 GMT</pubDate>
    </item>
    <item>
      <title>来自 python 库 linearmodels.panel.PanelOLS 的错误输出 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/660902/wrong-output-from-python-library-linearmodels-panel-panelols</link>
      <description><![CDATA[我正在使用 python linearmodels.panel.PanelOLS 运行回归，并发现当数据集很大（&gt;5 百万个观测值）时结果不正确 - 标准错误似乎正确，但系数完全不正确。
在下面的例子中，我创建了一个包含 10 百万个观测值和三列的数据集：
x：随机整数 0 或 1
const：1
y：x + N(0,1) * 100
然后使用 linearmodels.panelOLS、sm.OLS 和 pyfixest 运行回归。虽然后两个输出显示系数接近 1，但 linearmodels.panelOLS 生成不一致的输出。
### 创建数据集
# 创建一个包含 1000 万行的数据框，
# x 随机整数 0 或 1，
# y = x + N(0,1) * 100
import numpy as np
import pandas as pd

np.random.seed(0)
df = pd.DataFrame({&#39;x&#39;: np.random.randint(0, 2, 10000000),
&#39;const&#39;: 1,
&#39;index1&#39;: np.random.randint(0, 2, 10000000),
&#39;index2&#39;: np.random.randint(0, 2, 10000000),
&#39;y&#39;: np.random.normal(size=10000000) * 100})
df[&#39;y&#39;] = df[&#39;y&#39;] + df[&#39;x&#39;]
df = df.set_index([&#39;index1&#39;, &#39;index2&#39;])

### 使用 pyfixest 进行面板回归
import pyfixest as pf
df_reset = df.reset_index()# 重置索引（pyfixest 不适用于 MultiIndex）
est = pf.feols(&quot;y ~ 1+x&quot;, data=df_reset)# 使用 pyfixest 运行面板回归
print(est.summary())

### 使用 sm.OLS 进行面板回归
import statsmodels.api as sm
model = sm.OLS(df[&#39;y&#39;], df[[&#39;const&#39;, &#39;x&#39;]]).fit()
print(model.summary())

### 使用 PanelOLS 进行面板回归
from linearmodels.panel import PanelOLS
model = PanelOLS(df[&#39;y&#39;], df[[&#39;const&#39;, &#39;x&#39;]]).fit()
print(model.summary)

以下是 pyfixest 的输出

以下是 sm.OLS 的输出

以下是 PanelOLS 的输出

显然 PanelOLS 的系数与其他系数有很大不同，而标准误差却非常接近。

计算机规格：这个问题似乎只出现在一些计算机上，因为我尝试了一些其他计算机，但它在那里运行正常。如果有帮助，我的电脑（出现问题的地方）规格是：

CPU：第 13 代英特尔® 酷睿™ i9-13980HX 处理器
RAM：192 GB DDR5-5600MHz（SODIMM）-（4 x 48 GB）
GPU：NVIDIA RTX™ 3500 Ada 一代笔记本电脑 GPU 12GB GDDR6
存储：4 TB
系统：Windows 11 Pro 64

库版本：我尝试了 linearmodels 版本 5.3、5.4、6.0、6.1，它们都有问题。

样本大小：它似乎可以正确处理 &lt; 的数据集200 万次观察，但随着我将其扩大，它开始变得越来越错误。


任何建议都值得赞赏！提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660902/wrong-output-from-python-library-linearmodels-panel-panelols</guid>
      <pubDate>Mon, 03 Feb 2025 11:04:35 GMT</pubDate>
    </item>
    <item>
      <title>研究中的偏见</title>
      <link>https://stats.stackexchange.com/questions/660900/bias-in-a-study</link>
      <description><![CDATA[我正在进行一项没有对照组的单组研究，由于可用的前瞻性观察数量有限，我们的数据包括前瞻性和回顾性观察。研究的目的是将 T3（三个月）和 T6（六个月）的结果与基线进行比较，以评估在转换到新疗法后，与基线相比是否有任何改善。对第一种疗法反应不佳的参与者将被选中转换到新疗法。 一些病情较重的患者（回顾性数据）比其他患者更早改用新疗法（早于我们研究中的基线时间 T0）。
我想知道在本研究中，是否仍存在对结合前瞻性和回顾性数据产生的偏差的担忧，如果是，我们应该如何控制它？
*您是否也认为以下策略有助于控制偏差？ 使用多变量回归或倾向得分匹配调整混杂因素，采用混合效应 重复测量模型，进行敏感性分析，并将转换时间视为时间依赖性协变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/660900/bias-in-a-study</guid>
      <pubDate>Mon, 03 Feb 2025 10:36:31 GMT</pubDate>
    </item>
    <item>
      <title>用不同估计量的概率平均值来确定最终概率</title>
      <link>https://stats.stackexchange.com/questions/660899/determination-of-final-probability-as-an-average-of-probability-with-different-e</link>
      <description><![CDATA[如果标题与问题不符，请见谅。我不知道如何恰当地总结我的问题。
假设我有一个公式$f$，它描述了基于某些输入$x$的某个结果的概率。该公式具有参数$\eta$，因此$f = f(x;\eta)$。
给定一些数据$D$，可以通过最小化某些损失来确定参数$\hat \eta$的估计值。
但是，如果我们有不同的数据$D&#39;$，估计的参数就会不同。
基于此，似乎有$2+1$个选项：

选项 1：使用数据集 $D_1,\dots, D_n$ 计算估计量 $\hat{\eta}_1,\dots,\hat{\eta}_n$，并设置 $\hat{\eta_0} $ 平均值。

选项 2：定义


$$
\bar{f}(x) = \frac{1}{n} \sum_{i=1}^n f(x;\hat{\eta}_i) 。
$$

选项 3：受上述启发，考虑参数的分布 $p(\eta)$ 并设置

$$
f(x) = \int_H f(x;\eta)\, p(\eta) \, d\eta。
$$
由于数据稀缺，我认为选项 3 是最聪明的选项：为以 $\hat\eta$ 为中心的参数设置分布 $p$（计算方式与选项 1 相同），并计算结果的概率作为加权和。这也具有引入额外参数（如方差）的优势，然后可以针对特定问题进行微调。
我的问题是：

上述任何一种（特别是选项 3）是否有意义？如果有，是否有一个数学框架可以形式化这一点（特别是选项 3）？

参数在其空间上的分布积分让我想起了贝叶斯推理的参数公式；然而，由于缺乏先前的 $\Pi(\eta)$ 以及我缺乏该领域的专业知识，我不可能知道。]]></description>
      <guid>https://stats.stackexchange.com/questions/660899/determination-of-final-probability-as-an-average-of-probability-with-different-e</guid>
      <pubDate>Mon, 03 Feb 2025 10:19:05 GMT</pubDate>
    </item>
    <item>
      <title>时间序列模型 - 基于机器学习与传统方法 - 具有变化趋势和附加特征的案例</title>
      <link>https://stats.stackexchange.com/questions/660894/time-series-models-ml-based-vs-classical-methods-cases-with-changing-trends</link>
      <description><![CDATA[我是时间序列领域的新手，一直在阅读相关资料。似乎没有压倒性的共识支持使用 ML 或经典方法解决预测问题。ML 方法似乎在较高频率的时间序列或具有较高时间步长的时间序列中效果很好。但经典方法通常具有良好的预测性能。
我也在阅读 FB 的先知模型预印本，其中声称在许多业务问题中存在复杂的季节性模式和变化趋势。此外，可能还有更多特征可以为时间序列提供信息。例如，预测股票的回报可能需要其滞后交易量、价格的每周移动平均值等。
由于时间序列对时间的条件均值的非线性依赖，基于 ML 的方法（例如 xgboost）可以有效地捕获它。此外，在 ML 模型中包含其他特征是非常自然的。因此，直觉上，我会认为 ML 模型在各种业务预测问题中的表现都会优于传统模型。
那么，为什么对于许多业务问题，传统模型仍然优于 ML 模型呢？从经验丰富的预测从业者/专家那里获得见解会很棒。]]></description>
      <guid>https://stats.stackexchange.com/questions/660894/time-series-models-ml-based-vs-classical-methods-cases-with-changing-trends</guid>
      <pubDate>Mon, 03 Feb 2025 08:50:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么添加截距会改变 python 中的 roc_auc_score？</title>
      <link>https://stats.stackexchange.com/questions/660893/why-does-adding-an-intercept-change-roc-auc-score-in-python</link>
      <description><![CDATA[为什么在 python sklearn 中添加常数会改变 ROC AUC 的值？
import pandas as pd
from sklearn.datasets import make_classification
import statsmodels.api as sm
from sklearn.metrics import roc_auc_score

X, y = make_classification(n_samples=10000, n_features=2, n_informative=2, n_redundant=0, random_state=1)
X_const = sm.add_constant(X)

model1 = sm.Logit(y, X).fit()
model2 = sm.Logit(y, X_const).fit()

y_pred = model1.predict(X)
y_pred_c = model2.predict(X_const)

print(roc_auc_score(y, y_pred))
print(roc_auc_score(y, y_pred_c))

结果：
0.9425059793021525
0.9424627792866007
]]></description>
      <guid>https://stats.stackexchange.com/questions/660893/why-does-adding-an-intercept-change-roc-auc-score-in-python</guid>
      <pubDate>Mon, 03 Feb 2025 08:40:23 GMT</pubDate>
    </item>
    <item>
      <title>关于 IID 随机变量的有限集合和事件的有限集合的“填充概率”的一般公式</title>
      <link>https://stats.stackexchange.com/questions/660886/general-formula-for-the-filling-probability-with-respect-to-a-finite-collectio</link>
      <description><![CDATA[背景
给定一个有限 IID 离散随机变量集合 $\{X_i\}_{i=1}^n$，其概率质量函数为 $\Pr$，以及一组有限事件 $S = \{ E_j \}_{j=1}^m$，填充概率是至少观察一次 $E_j$ 的概率。
我认为填充概率与分配问题相关，在分配问题中，人们感兴趣的是增加 $n$，以便所有目标 $m$ 事件可能（在一定风险承受能力下）达到通过。
假设我得到了正确的表达式，我打算编写一个轻量级的 Python 包，使用 Rust 扩展，根据 $n$、$m$ 和 $S$ 中每个事件的概率来计算这个数量。
目标
我想要这个填充概率的通用公式。让我展示一下我的工作，以防我犯了错误。
尝试
首先，我认为定义一个事件 $A_j$ 会很有用，它是 不 观察事件 $E_j$ 的事件。我认为$\Pr \left[ \bigcup_{j=1}^m A_j \right]$对这个问题很有用，因为它符合我的直觉，即至少一个事件缺失的概率。所以我的计划是实现这个结果：
$$P(\text{每个 } E_j \text{ 至少被观察到一次}) = 1 - P\left(\bigcup_{j=1}^m A_j\right)$$
接下来我可以使用包含-排除原理将这个概率分解为一个有限和：
$$P\left(\bigcup_{j=1}^m A_j\right) = \sum_{k=1}^{m} (-1)^{k+1} \sum_{1 \leq j_1 &lt; j_2 &lt; \ldots &lt; j_k \leq m} P(A_{j_1} \cap A_{j_2} \cap \ldots \cap A_{j_k})$$
这给我们留下了计算联合概率的任务。我希望它们可以像这样计算：
$$P(A_{j_1} \cap A_{j_2} \cap \ldots \cap A_{j_k}) = \left(1 - \sum_{i \in \{j_1, j_2, \ldots, j_k\}} \Pr(X_i \in E_i) \right)^n$$
然后我们最终可以像这样计算填充概率：
$$P(\text{每个 } E_j \text{ 至少被观察到一次}) = 1 - \sum_{k=1}^{m} (-1)^{k+1} \sum_{1 \leq j_1 &lt; j_2 &lt; \ldots &lt; j_k \leq m} \left(1 - \sum_{i \in \{j_1, j_2, \ldots, j_k\}} \Pr(X_i \in E_i) \right)^n
$$
问题

我犯了什么错误吗？
有没有更好的方法？
有没有比“填充概率”更常规的名称？
]]></description>
      <guid>https://stats.stackexchange.com/questions/660886/general-formula-for-the-filling-probability-with-respect-to-a-finite-collectio</guid>
      <pubDate>Sun, 02 Feb 2025 22:55:55 GMT</pubDate>
    </item>
    <item>
      <title>限制高斯 S 型函数期望的近似误差</title>
      <link>https://stats.stackexchange.com/questions/660861/bounding-the-approximation-error-of-the-expectation-of-the-sigmoid-of-a-gaussian</link>
      <description><![CDATA[我想限制$\mathbb{E}_x[\sigma(x)],$的近似误差 $\sigma(x):=1/(1+\exp(-x)),$ $x\sim\mathcal{N}(\mu,v)$:
$$\mathbb{E}_x[\sigma(x)]=\sigma(\mu)+\sum_{k=1}^\infty \frac{\sigma^{(k)}(\mu)}{k!}\mathbb{E}[(x-\mu)^k].$$
由于$\mathbb{E}[(x-\mu)^k]=v^k(k-1)!!,$ 这简化为 $$\mathbb{E}_x[\sigma(x)]=\sigma(\mu)+\sum_{k=1}^\infty \frac{v^k\sigma^{(k)}(\mu)}{k!!}.$$
事实上，看起来 $\frac{\sigma^{(k)}(\mu)}{k!!}$ 发散，但这意味着期望发散，而我真的不这么认为。我哪里做错了？
编辑：看来方差在这里至关重要，对于 .05 左右及以下的值，项（至少最多 140 个项，这是我可以计算而不会溢出的极限）不会爆炸。这种期望确实只存在于某些方差中吗？对我来说似乎违反直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/660861/bounding-the-approximation-error-of-the-expectation-of-the-sigmoid-of-a-gaussian</guid>
      <pubDate>Sat, 01 Feb 2025 23:55:33 GMT</pubDate>
    </item>
    <item>
      <title>最小二乘估计量投影视图中的帽子矩阵的维数</title>
      <link>https://stats.stackexchange.com/questions/660854/dimensionality-of-the-hat-matrix-in-the-projection-view-of-the-least-squares-est</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660854/dimensionality-of-the-hat-matrix-in-the-projection-view-of-the-least-squares-est</guid>
      <pubDate>Sat, 01 Feb 2025 18:28:03 GMT</pubDate>
    </item>
    <item>
      <title>卡方检验是参数检验还是非参数检验？</title>
      <link>https://stats.stackexchange.com/questions/660848/is-a-chi-squared-test-a-parametric-or-non-parametric-test</link>
      <description><![CDATA[也许是一个微不足道的问题，但我一直收到一些相互矛盾的信息，这让我有些困惑。
首先，关于参数和非参数检验之间的区别似乎存在一些相互矛盾的信息。即，

一些来源表明，参数检验对样本所来自的总体分布的参数做出了假设（a，b）
其他来源表明，参数检验仅适用于正态分布的数据（a，b, c, d, e)

我个人认为第一个说法是正确的，而第二个说法不正确，但我希望对此有清晰的认识。
如果第一点是正确的，这就引出了我的第二个问题。我看到多个来源都这么说：

卡方检验是一种非参数检验（a、b、c）

但是我想知道为什么卡方检验是非参数的，如果像 Z 检验、t 检验、ANOVA 等参数检验一样，它假设总体分布遵循特定分布，不是吗？我认为卡方检验假设检验统计量来自卡方分布，因此由于它做出了分布假设，所以它是参数化的。但我肯定是误解了什么。有人能帮忙澄清一下吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660848/is-a-chi-squared-test-a-parametric-or-non-parametric-test</guid>
      <pubDate>Sat, 01 Feb 2025 16:00:09 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用 Beta 回归还是 Box Cox 变换线性回归？</title>
      <link>https://stats.stackexchange.com/questions/660815/should-i-use-beta-regression-or-box-cox-transformed-linear-regression</link>
      <description><![CDATA[我的响应变量是态度分数，它是比例分数（总分/最高分），因此是连续的，范围从 0 到 1。最初，我认为 Beta 回归是一个不错的选择，因此我对分数进行了调整，以便没有真正的 0 或 1。
attitude_self$prop_score &lt;- pmin(pmax(attitude_self$prop_score, 0.001), 0.999)

我的模型如下，AIC 值为 -607：
beta_model &lt;- betareg(prop_score ~ age + group + gender + PerceivedKnowledge, 
data =itude_self, link = &quot;logit&quot;)

然而，经过进一步检查，它似乎 prop_score 不遵循真正的 beta 分布。我检查了分布/密度、偏度和峰度，并进行了 fitdist() 和 Kolmogorov-Smirnov (KS) 检验以测试拟合度。

skewness(prop_score)
[1] -2.792165
峰度(prop_score)
[1] 15.89607

fitdist(prop_score, &quot;beta&quot;)
通过最大似然法拟合分布 &#39; beta &#39; 
参数：
估计标准差。错误
shape1 2.6511869 0.17474578
shape2 0.7264323 0.03847695

&gt; ks.test(prop_score, &quot;pbeta&quot;, shape1 = 2.65, shape2 = 0.73)

渐近单样本 Kolmogorov-Smirnov 检验

数据：prop_score
D = 0.19366，p 值 &lt; 2.2e-16
备选假设：双侧

然后我使用 Box-Cox 变换对响应变量进行变换，并使用线性回归。
得到的 AIC 较低，为 -900，残差如下：

我是否正确地转向了变换后的线性回归而不是 beta 回归？
更新
带有 topmodel 图的 Beta 模型
我再次将模型作为扩展支持 beta 回归运行，将响应值保留原样最初。AIC：-736 &amp;残差：

rootogram(beta_model)

pithist(beta_model)

qqrplot(beta_model)

wormplot(beta_model)

reliagram(beta_model)

稳健模型
我也尝试了一个稳健模型。 AIC：-865 和残差：



]]></description>
      <guid>https://stats.stackexchange.com/questions/660815/should-i-use-beta-regression-or-box-cox-transformed-linear-regression</guid>
      <pubDate>Fri, 31 Jan 2025 16:53:16 GMT</pubDate>
    </item>
    <item>
      <title>McNemar 检验是否适合前后比较？</title>
      <link>https://stats.stackexchange.com/questions/660806/is-mcnemars-test-suitable-for-before-after-comparisons</link>
      <description><![CDATA[如果我理解正确的话，McNemar 检验通常用于测试两个二元结果之间的依赖关系。Agresti 在《分类数据分析》（我相信是 2002 年版）中给出了两个与环境相关的问题的示例，受试者同时回答这些问题。我提供了我自己的示例，其中的数字被夸大了，以便进行演示：
 Q2
Q1 同意 不同意
同意 945 5
不同意 10 40

在这里，我可以看到 McNemar 的检验是有道理的：大多数人同意这两个陈述，一些人同意其中一个而不同意另一个，还有少数人不同意两者。这听起来很合理。 p 值为 0.2，即两个问题的同意率没有显著差异。
但是，McNemar 检验也用于比较前后结果，如 Agresti 书中早期版本 (1990) 中的示例。因此，让我们使用上述数字，但将它们视为受试者对一个问题的回答，但在两个不同的时间点，$T_1$ 和 $T_2$。在这两个时间点，他们可能“同意”或“不同意”：
 T2
T1 同意 不同意
同意 945 5
不同意 10 40

由于计数的巨大不平衡，我发现 McNemar 检验中暗示的情景难以置信。我们想看看受试者是否会随着时间的推移而改变主意，结果发现一组（$T_1$ 的“同意者”）几乎没有变化（~0.5%），而“不同意者”则发生了很大变化：在 $T_1$ 不同意的受试者中，约有 20% 在 $T_2$ 同意。我认为这是一个“显著”的差异，但由于表中的数字与第一个示例中的数字相同，因此 McNemar 的检验仍然不显著。
在 $H_0$ 下，非对角线单元格中的绝对数字需要相似，而不是百分比。为了得到相似的数字，“T1 同意者”需要以与“不同意者”不同的概率改变主意，但这两个概率必须相关。换句话说，$H_0$ 意味着两组之间存在某种信息交换。或者，换句话说，“非对角线概率之间没有差异”假设可能意味着行概率之间存在相当大且非常精确的差异。这对我来说似乎非常不随机 - 与人们对零假设的期望完全相反。
或者我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660806/is-mcnemars-test-suitable-for-before-after-comparisons</guid>
      <pubDate>Fri, 31 Jan 2025 14:13:43 GMT</pubDate>
    </item>
    </channel>
</rss>