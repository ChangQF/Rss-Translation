<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 21 Jul 2024 18:18:32 GMT</lastBuildDate>
    <item>
      <title>r 中的 Cocor 用于比较两个斯皮尔曼相关系数吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651484/cocor-in-r-to-compare-two-spearman-correlation-coefficients</link>
      <description><![CDATA[我可以在 r 中使用 Cocor 比较两个斯皮尔曼相关系数吗？以及比较两个类内相关系数 (ICC)？]]></description>
      <guid>https://stats.stackexchange.com/questions/651484/cocor-in-r-to-compare-two-spearman-correlation-coefficients</guid>
      <pubDate>Sun, 21 Jul 2024 15:43:51 GMT</pubDate>
    </item>
    <item>
      <title>生存分析中不相互排斥的竞争风险</title>
      <link>https://stats.stackexchange.com/questions/651481/competing-risks-that-are-not-mutually-exclusive-in-survival-analysis</link>
      <description><![CDATA[我有 5 种类型的事件可供主体体验。但是，并非所有这些事件都相互竞争：对于事件 A、B、C、D、E，A 的发生会阻止 B 的发生。B、D 和 E 相互排斥，而 C 的发生会阻止所有其他事件。我想使用 Aalen-Johansen 估计器估计每个事件的累积发生率，但我不确定如何处理和解释这些相互竞争的情况。]]></description>
      <guid>https://stats.stackexchange.com/questions/651481/competing-risks-that-are-not-mutually-exclusive-in-survival-analysis</guid>
      <pubDate>Sun, 21 Jul 2024 15:14:12 GMT</pubDate>
    </item>
    <item>
      <title>处理具有大量异常值的数据集[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651479/dealing-with-a-dataset-with-huge-outliers</link>
      <description><![CDATA[我正在研究一个少于 100 个样本、大约 20 个特征的数据集。这个数据集与医学物理领域中与肺和心脏等器官相关的参数的多元回归问题有关。这个数据集的奇怪之处在于与肺相关的目标值有关。事实上，肺在不同的人身上有很大的差异，因此，这种类型的目标值中存在大量异常数据，这导致其中出现大量过度拟合。你认为我该如何处理这个数据集？]]></description>
      <guid>https://stats.stackexchange.com/questions/651479/dealing-with-a-dataset-with-huge-outliers</guid>
      <pubDate>Sun, 21 Jul 2024 11:55:08 GMT</pubDate>
    </item>
    <item>
      <title>具有多个时间段的 Diff-in-Diff</title>
      <link>https://stats.stackexchange.com/questions/651478/diff-in-diff-with-multiple-time-periods</link>
      <description><![CDATA[这是我在这里的第一篇帖子，我还是个新手，希望这篇文章能说清楚。
背景：
对于我的硕士论文，我想估计重复对论文引用的影响。为此，我想比较曾经重复过的论文和没有重复过的论文的引用。
我的导师告诉我，考虑到我的因变量的性质（引用是一个非负计数数字），更合适的模型是交错式差异分析，并采用泊松回归。但是，他告诉我尝试初始的“简单”差异分析来查看结果，即使结果可能有偏差。
在我的数据集中，我有大约 80 篇在不同时间点重复的论文（因此是我的治疗组），以及 160 篇从未重复的论文（对照组）。为了确保可比性，我只选取在同一期刊、卷、期上发表、涉及相同主题或 JEL 代码的实证论文。以下是一个片段：

因此，如果我们查看一个简单的 DiD 方程，并将其应用于我的数据，这就是我想要估计的：

其中，replicated 是治疗虚拟变量（如果已复制则为 1，如果从未复制则为 0），d_time 是时间虚拟变量（before=0 并且after=1)。
我在这里看到的问题是，我的对照组没有“之后”，因为这些论文从未被复制过，而且我无法获取单个处理过的论文的“之后”，因为所有论文的处理年份都不同（有些重复，但一般是 15 年）。因此，我的时间虚拟变量的构造使我的对照组的 d_time 始终为 0（replicated=0），
如果我运行这样的模型，由于交互项和 d_time 之间存在完全共线性，因此我的交互项会被省略。我在这里遗漏了什么？
现在，我知道这是“基本” DiD 模型，由于我的数据的性质，这可能会导致一些规范问题。但我想在尝试任何其他更高级的方法之前实现它。有人有什么建议吗？
（我试图理解 Callaway 和 Sant&#39;Ana 关于交错方法的论文，但我无法理解该模型的实施和解释。因为据我所知，如果在另一篇论文之后进行处理，每篇经过处理的论文都可以作为对照论文（例如：2015 年的重复论文可以作为 2010 年重复论文的对照论文，依此类推）。但是，我只想比较从未重复的论文和重复的论文，因此我不确定这是否是最好的方法）]]></description>
      <guid>https://stats.stackexchange.com/questions/651478/diff-in-diff-with-multiple-time-periods</guid>
      <pubDate>Sun, 21 Jul 2024 11:49:31 GMT</pubDate>
    </item>
    <item>
      <title>使用未观察组件模型时，首选的程序和相关方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/651477/what-is-the-preferred-procedure-and-associated-methods-when-using-an-unobserved</link>
      <description><![CDATA[首先我要说的是，我的统计知识非常有限。如果您发现我的思维方式有任何错误，或者有任何好的初学者参考资料供我进一步阅读我将要描述的主题，请告诉我。
我有一个数据库，其中包含来自各个来源的按国家/地区每年的治理指标（对于那些感兴趣的人：世界银行的全球治理指标）。我想将其中一些指标组合在一起并创建一个综合指数。这需要为指标分配权重。鉴于各种来源和方法论的差异，主成分分析似乎不太合适。相反，我想到使用具有趋势成分的未观察成分模型 (UCM)，类似于全球治理指标。这样，我可以使用趋势来衡量一些潜在的治理概念。但是，由于我正在改变他们的程序，我必须自己弄清楚，而不是能够复制他们的步骤。
因此，我试图弄清楚在创建这个综合指数时要遵循哪些步骤。我有一个大概的提纲，但想知道一些更具体的步骤以及最适合执行它们的方法

标准化数据：所有数据都使用最小-最大方法标准化为 0-1 的范围
考虑缺失值：有很多缺失值，因为并非所有年份和所有国家都得到一致测量。我仍在尝试找出最佳处理方法
加权和聚合：要计算赋予值的权重，我想使用 UCM，这需要估计相关参数。我读过我可以使用 MLE 或贝叶斯方法，但我不知道在哪种情况下哪种方法更可取
根据 UCM 确定的权重，计算每个国家每年值的加权平均值

这些仍然很笼统，我想寻求帮助来充实这个过程。此外，如果您愿意成为我的陪练伙伴，向我提出一些更一般的问题，我也将不胜感激。
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/651477/what-is-the-preferred-procedure-and-associated-methods-when-using-an-unobserved</guid>
      <pubDate>Sun, 21 Jul 2024 11:46:20 GMT</pubDate>
    </item>
    <item>
      <title>b(n,p) 的峰度 - 二项分布</title>
      <link>https://stats.stackexchange.com/questions/651472/kurtosis-of-bn-p-binomial-distribution</link>
      <description><![CDATA[所以我遇到了这个问题，正在尝试解决。
我已经研究了好几个小时了。
这是为了找到二项分布的峰度。
到目前为止，我有 M’’’’(0) = $n[(n-1)(n-2)(n-3)p^4 + 6(n-1)(n-2)p^3 +7(n-1)p^2 + p]$
然后对于 $\frac{E(X^4) - 4\mu E(X^3) + 6\mu^2 E(X^2) - 4\mu^3 E(X) + \mu^4}{\sigma^4} =$
$\frac{n[(n-1)(n-2)(n-3)p^4 + 6(n-1)(n-2)p^3 +7(n-1)p^2 + p] - 4(n[(n-1)(n-2)p^3 +3(n-1)p^2 + p + 6(np)^2(np + n(n-1)p^2 - 4(np)^3 + (np)^4}{(\sqrt{np(1-p)})^4} =$
从那里我似乎无法得到 $\frac{1-6(1-p)}{np(1-p)}$。
我知道这都是简化，但我似乎无法正确理解。]]></description>
      <guid>https://stats.stackexchange.com/questions/651472/kurtosis-of-bn-p-binomial-distribution</guid>
      <pubDate>Sun, 21 Jul 2024 06:45:53 GMT</pubDate>
    </item>
    <item>
      <title>最近（>2015 年）关于变量误差模型的学术介绍有哪些？</title>
      <link>https://stats.stackexchange.com/questions/651471/what-is-a-good-recent-2015-academic-introduction-to-errors-in-variables-mode</link>
      <description><![CDATA[我知道这个资源 https://en.wikipedia.org/wiki/Errors-in-variables_models，但我不太相信维基百科上关于统计的文章，所以我正在寻找一些关于这个主题的学术参考资料。如果它能帮助我提出一些建议，我已经熟悉标准回归模型，对混合模型也有点了解。
你有什么好的建议吗？如果它只是教科书中的一章，只要它涵盖基础知识并（理想情况下）建议进一步的资源，我就会感兴趣。如果该资源是旧资源的新版本，我也会感兴趣。干杯，]]></description>
      <guid>https://stats.stackexchange.com/questions/651471/what-is-a-good-recent-2015-academic-introduction-to-errors-in-variables-mode</guid>
      <pubDate>Sun, 21 Jul 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>分数布朗运动参数估计中的偏差估计（逆转对数变换后）</title>
      <link>https://stats.stackexchange.com/questions/651469/bias-estimation-after-reversing-the-log-transformation-in-parameter-estimation</link>
      <description><![CDATA[我正在学习这两篇文献，
1 [分数布朗运动的模拟与识别：文献和比较研究 COEURJOLLY Jean-François]
2 [通过离散样本路径变化估计分数布朗运动的参数 JEAN-FRANÇOIS COEURJOLLY]
我坚持理解 fBm 的缩放参数 $C$ 的偏差。此参数 $C$ 是通过对数据进行对数变换（以获得线性）、执行 OLS 然后再变换回来获得的。
因此，$C$ 的估计量是一个有偏估计量。
我检查了作者如何估计偏差的代码，但我无法弄清楚作者到底在做什么，因为两篇文献中都没有提到偏差估计。
从代码中我可以看出，作者试图使用渐近方差来估计方差，但它与下面的方差公式并不完全匹配
我在下面粘贴了文献和代码的相关部分。代码似乎使用了 Digamma 函数的渐近展开。
所以我想问一下这里执行的是哪种偏差校正？如果可能的话，为什么 Digamma 函数的扩展在这里？

]]></description>
      <guid>https://stats.stackexchange.com/questions/651469/bias-estimation-after-reversing-the-log-transformation-in-parameter-estimation</guid>
      <pubDate>Sun, 21 Jul 2024 04:19:33 GMT</pubDate>
    </item>
    <item>
      <title>如何计算存在双零的 k 均值聚类？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651474/how-to-calculate-k-means-clustering-with-presence-of-double-zeroes</link>
      <description><![CDATA[我尝试使用具有双零的数据集来查找物种组合。当我运行测试时，结果不确定，并且似乎没有组是显著的。
我使用了 hellinger 变换和 chord 变换，并运行了 vegan 包中的 cascadeKM 函数，但 Calinski 标准似乎表明最佳聚类为 18 个组（这是我可以拥有的最大组数），而 SSI 标准似乎表明最佳聚类为 11 个组。
但是，当我运行 kendall.global 测试时，没有一个组是显著的？这些是否是用于我的物种丰度矩阵的最佳变换？这是否意味着没有物种彼此相关？]]></description>
      <guid>https://stats.stackexchange.com/questions/651474/how-to-calculate-k-means-clustering-with-presence-of-double-zeroes</guid>
      <pubDate>Sun, 21 Jul 2024 00:49:36 GMT</pubDate>
    </item>
    <item>
      <title>使用 LOOCV 中的正则化减少小型数据集的方差</title>
      <link>https://stats.stackexchange.com/questions/651449/reducing-variance-with-regularization-in-loocv-for-small-datasets</link>
      <description><![CDATA[我有一个小数据集，我正在考虑使用留一交叉验证 (LOOCV) 来评估我的模型。我理解，交叉验证通常是一种评估模型在未见数据上的表现的方法。
但是，我担心偏差-方差权衡。具体来说，使用 LOOCV 时，存在偏差低但方差高的风险。为了缓解这种情况，我正在考虑使用正则化模型（L1、L2 或 Elastic Net）来引入一些偏差并减少方差（在使用 loocv 时同时……）。
您能否提供任何实施此方法的提示或最佳实践？任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/651449/reducing-variance-with-regularization-in-loocv-for-small-datasets</guid>
      <pubDate>Sat, 20 Jul 2024 10:57:12 GMT</pubDate>
    </item>
    <item>
      <title>不可靠测量的方差分析</title>
      <link>https://stats.stackexchange.com/questions/651443/anova-with-unreliable-measure</link>
      <description><![CDATA[我正在做一些关于体育科学的文献综述，特别是训练对耐力的影响。
没有标准的耐力测试。有些测试包括间歇性收缩，直到筋疲力尽，然后测量最终的力量。
有些测试已成为研究的主题，以获得 ICC、LoA 或其他会话间可靠性指标，而有些则没有。有些被发现具有较低的 ICC（&lt;0.8）或非常大的 LoA（+/- 40%）。
我遇到过一些研究训练对耐力的影响的研究。他们对一组人进行耐力测试，然后让他们接受训练，并进行另一次耐力测试。然后他们进行单向方差分析以确定耐力是否有显著提高。但是，其中一些研究使用了尚未表征的耐力测试，从未进行过任何重测信度评估。
所以我的问题是：如果使用的测量方法不可靠或可靠性未知，方差分析能否得出显着差异的结论？
这对我来说似乎很奇怪，因为这就像使用不可靠的量表而不知道其标准误差一样。]]></description>
      <guid>https://stats.stackexchange.com/questions/651443/anova-with-unreliable-measure</guid>
      <pubDate>Sat, 20 Jul 2024 09:54:24 GMT</pubDate>
    </item>
    <item>
      <title>如何预测变换后的时间序列数据？</title>
      <link>https://stats.stackexchange.com/questions/651425/how-can-you-forecast-transformed-time-series-data</link>
      <description><![CDATA[我有包含趋势和季节性成分的时间序列数据。我使用以下方法从数据中删除了它：
 remove_seasonality &lt;- function(x) {
t &lt;- seq_along(x)
sin_term &lt;- sin(2 * pi * t / 52)
cos_term &lt;- cos(2 * pi * t / 52)
lm_model &lt;- lm(x ~ sin_term + cos_term)
residuals(lm_model)
}
subset_data_two$x_deseasonalized &lt;- remove_seasonality(subset_data_two$Nitrogen_Dioxide)
detrended_data &lt;- subset_data_two

split_data &lt;- function(data, train_or_test, prop) {
ordered_data &lt;- data[order(data$Date), ]
row_count &lt;- nrow(ordered_data)
train_size &lt;- round(prop * row_count)

if (train_or_test == &quot;train&quot;) {
train_data &lt;- ordered_data[1:train_size, ]
return(train_data)
} else if (train_or_test == &quot;test&quot;) {
test_data &lt;- ordered_data[(train_size + 1):row_count, ]
return(test_data)
} else {
stop(&quot;train_or_test 必须是 &#39;train&#39; 或 &#39;test&#39;&quot;)
}
}
training_data &lt;- split_data(detrended_data, &quot;train&quot;, 0.85)
test_data &lt;- split_data(detrended_data, &quot;test&quot;, 0.85)

# 3.0 拟合模型
fix &lt;- training_data[,c(&quot;Date&quot;, &quot;x_deseasonalized&quot;)]
fixed_tseries &lt;- read.zoo(fix)
three_plots(fixed_tseries, &quot;时间序列：从固定 x 到固定 x 的平稳序列&quot;)

fix_model &lt;- arima(fix$x_deseasonalized, order=c(1,0,1))
three_plots(fix_model$residuals, &quot;AR(1)MA(1) 时间序列&quot;)

# 4.0 预测
forecasted &lt;- Forecast(fix_model, h = 31)

然后我能够使用平稳数据拟合 ARMA(1,1) 模型。
我现在想预测 n 步。我知道 predict() 函数采用转换后的模型，并且我相信新的平稳 x 值 (data$x_fixed)，但我不知道在哪里应用原始趋势/季节性转换以使预测变得非平稳？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651425/how-can-you-forecast-transformed-time-series-data</guid>
      <pubDate>Fri, 19 Jul 2024 20:05:26 GMT</pubDate>
    </item>
    <item>
      <title>我有一个包含 18 个生物标志物特征和一个目标变量的数据集。我想找到对目标影响最大的特征</title>
      <link>https://stats.stackexchange.com/questions/651353/i-have-a-dataset-with-18-biomarker-features-and-a-target-variable-i-want-to-fin</link>
      <description><![CDATA[我有一些疾病生物标志物数据集，其中包含来自不同样本的 18 个生物标志物读数和一个显示疾病存在与否的目标变量（特征既有分类特征也有数值特征）。我想看看是否只使用对目标变量影响最大的特征会提高我的预测模型的性能——目前使用 scikit learn。
以下是数据等的一些细节。

这些是我拥有的肝病数据集，共有 4 个。它们都包含相同的 18 个生物标志物特征，其中包括“白蛋白水平”、“总胆固醇”、“性别”、“甘油三酯”等读数。

2.目标变量是二进制的，“0”= 无肝病，“1”= = 肝病。

我有一个用于训练的发现数据集和 3 个用于测试的验证数据集。因此准确度指标基于验证集中对疾病的正确预测。

我尝试应用浅层模型，包括使用 18 种生物标志物以及 MLP 的逻辑回归、梯度提升和随机森林。数据集非常不平衡，表现不如我希望的那样好，尤其是对于预测第 1 组。- 这就是我认为特征选择可以帮助减少噪音的原因。

我尝试过一种随机森林方法来查看每个特征在多大程度上降低了分割的杂质 - 虽然鉴于我经验不足，我不知道这是否是最好的方法。


有人可以建议如何做这件事的好方法吗？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/651353/i-have-a-dataset-with-18-biomarker-features-and-a-target-variable-i-want-to-fin</guid>
      <pubDate>Thu, 18 Jul 2024 16:31:46 GMT</pubDate>
    </item>
    <item>
      <title>交叉熵和 MLE 之间的联系</title>
      <link>https://stats.stackexchange.com/questions/650884/link-between-cross-entropy-and-mle</link>
      <description><![CDATA[有许多材料显示了MLE 和交叉熵之间的关系。
通常，这些是显示 I.I.D 数据生成过程 $D = (X,Y)$ 的关系所采取的步骤：
$$
L(D) = \prod_{i=1}^N p(x_i, y_i; \theta)
$$
将可能性除以 num。样本$N$，并在两边取$\log$，因为这两个操作都不会影响最优模型参数估计$\theta^*$
$$
\frac{1}{N} \times \log(L(D)) = \frac{1}{N} \times \sum_{i=1}^N log(p(x_i, y_i; \theta))
$$
最后，这相当于经验分布和模型分布之间的交叉熵。
$$
\frac{1}{N} \times \sum_{i=1}^N log(p(x_i, y_i; \theta)) = \mathbb{E}_{p_{data}}[log(p_{model}(x,y;\theta))]
$$
我有几个问题：

如果数据生成过程不是 I.I.D 会怎样？这种关系还成立吗？

为什么这种关系很特殊，它如何帮助参数估计？鉴于 MLE 和交叉熵都给出了完全相同的最佳模型参数 $\theta^*$。

]]></description>
      <guid>https://stats.stackexchange.com/questions/650884/link-between-cross-entropy-and-mle</guid>
      <pubDate>Thu, 11 Jul 2024 15:13:46 GMT</pubDate>
    </item>
    <item>
      <title>FDR 在一项基因表达实验中采用了两种类似的治疗方法 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/650719/fdr-in-a-gene-expression-experiment-with-two-similar-treatments</link>
      <description><![CDATA[给出以下实验。在三种条件下获得数千个基因的基因表达谱：两种具有相似表型效应的药物（= 治疗）和一个对照组。每个条件都重复。对每个基因和两个治疗对照组中的每一个进行差异基因表达测试（Wald 或似然比测试）。目的是比较药物：获得对两种药物和每种药物均有反应的基因列表。
直观地说，在一种治疗中具有相同 p 值但在另一种治疗中具有不同 p 值的两个基因应该具有不同的权重。这个想法是利用许多基因会同时对两种药物产生反应的事实。将同一基因的 p 值组合起来，控制 FDR，并将基因分为对两种药物均有反应的基因和仅对一种药物有反应的基因，正确的方法是什么？
编辑
我接受治疗特定组的模糊性（这是我从回复中提出的担忧中得出的结论），所以我想将问题缩小到“共享”基因：给定两种相似的治疗方法和一个共享的对照组，在特定的 FDR 截止值下，找到有证据表明两种治疗方法都有效的基因。
正如已经讨论过的，一种方法是简单地将 FDR 截止值分别应用于两种治疗方法的两个 p 值向量。这不是为联合假设检验而设计的，会丢弃真正的发现。一种解决方法可能是应用宽松的 FDR 截止值，但这仍然无法控制最终基因集的 FDR。
另一种方法概述如下：https://doi.org/10.1371/journal.pone.0063290 - 使用 Stouffer 检验（未加权 z 检验），作者声称即使在依赖性条件下（共享控制组），其表现也令人满意。我没有看到这种方法在文献中得到广泛应用。我的理解是，如果效果大小不同（治疗 1 和治疗 2 就是这种情况），加权 z 检验的效果会更好。
EDIT2
如何采用似然比检验方法，首先测试完整模型的效果：~ treatment1 + treatment2（其中 treatment1 和 treatment2 是二元因子）针对 ~1，对于那些通过 FDR 阈值的基因，通过将完整模型与简化的单一治疗模型（~ treatment1 和 ~ treatment2）进行比较并检查两种治疗的 LFC，探索两种治疗项的贡献？我不确定如何（甚至是否）调整第二次测试的结果：在某种程度上，我正在探索已经选择的模型的术语贡献。]]></description>
      <guid>https://stats.stackexchange.com/questions/650719/fdr-in-a-gene-expression-experiment-with-two-similar-treatments</guid>
      <pubDate>Tue, 09 Jul 2024 08:27:24 GMT</pubDate>
    </item>
    </channel>
</rss>