<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 05 Aug 2024 12:30:11 GMT</lastBuildDate>
    <item>
      <title>有没有办法可以处理缺失数据而无需插补？考虑 NA 值的模型</title>
      <link>https://stats.stackexchange.com/questions/652323/is-there-any-way-to-can-deal-with-missing-data-without-imputation-model-consid</link>
      <description><![CDATA[我的问题是如何使用 NA 值对数据进行建模，而无需进行插补。 有可能吗？ 优点和缺点是什么？ 问题是分类。]]></description>
      <guid>https://stats.stackexchange.com/questions/652323/is-there-any-way-to-can-deal-with-missing-data-without-imputation-model-consid</guid>
      <pubDate>Mon, 05 Aug 2024 10:39:57 GMT</pubDate>
    </item>
    <item>
      <title>针对具有严重不平衡和未标记正目标变量的数据集的模型建议</title>
      <link>https://stats.stackexchange.com/questions/652321/model-recommendations-for-dataset-with-massive-imbalance-and-positive-unlabeled</link>
      <description><![CDATA[我有一个大约 50,0000 行的数据集，我试图预测二元结果。
只有 0.3% 的数据有正标签，其余数据未标记。我很感激能有关于此数据集的提示和模型。
目标是预测其他潜在的正标签实例。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/652321/model-recommendations-for-dataset-with-massive-imbalance-and-positive-unlabeled</guid>
      <pubDate>Mon, 05 Aug 2024 09:44:09 GMT</pubDate>
    </item>
    <item>
      <title>比较两个回归模型？</title>
      <link>https://stats.stackexchange.com/questions/652320/comparing-two-regression-models</link>
      <description><![CDATA[我有两个测量值（C 和 D）的数据集，它们分别用于两个区域（A 和 B）。我将它们分别绘制在散点图上，以获得两个正相关的图。但我真正想要的是它们彼此之间的差异，与测量值之间的相关性无关，只是 A 和 B 站点之间的测量值有何不同。
我觉得我可以使用方差分析来比较平均值，但事实上，我比较整个图的大小，这样比较它们感觉更准确。
两者的回归模型然后比较它们是否有效，我不知道要进行什么统计测试来测试它们，甚至不知道如何在 R 中测试它们。我主要使用 Rcmdr，因此除非代码解释得非常透彻，否则我对它不是很熟悉。 Rcmdr 确实做了大部分测试，我想我可以指定要使用的模型，除非有人也帮助我，否则我可能只需要查找它。
如果我进行回归，我应该为回归做什么统计测试，我相信我的数据是非参数的，但我不确定我是否做了正确的测试并正确地进行了正态性测试，如果我必须这样做的话。
对不起，我一点也不擅长这些，只是想了解一下。
如果有人能回答这个乱七八糟的问题那就太好了！]]></description>
      <guid>https://stats.stackexchange.com/questions/652320/comparing-two-regression-models</guid>
      <pubDate>Mon, 05 Aug 2024 09:03:31 GMT</pubDate>
    </item>
    <item>
      <title>细胞比例或差异表达的变化？</title>
      <link>https://stats.stackexchange.com/questions/652319/change-of-cell-proportions-or-differential-expression</link>
      <description><![CDATA[假设给出了两种条件下的大量 RNA-Seq，以及各种细胞类型的典型基因表达谱。有人想比较两种条件下的细胞类型比例。
可以从批量数据中解卷积细胞类型比例（使用参考更容易），例如通过 CibersortX。

是否可以区分细胞类型比例的变化（两种条件下的细胞类型组成不同）和基因表达的变化（两种条件下的细胞类型相同，但基因表达模式在两种条件下发生了变化）？

从概念上讲，这如何可能？

]]></description>
      <guid>https://stats.stackexchange.com/questions/652319/change-of-cell-proportions-or-differential-expression</guid>
      <pubDate>Mon, 05 Aug 2024 08:39:21 GMT</pubDate>
    </item>
    <item>
      <title>在随机森林中添加尽可能多的预测因子是一个好主意吗？</title>
      <link>https://stats.stackexchange.com/questions/652315/is-it-a-good-idea-to-add-as-many-predictors-as-possible-in-a-random-forest</link>
      <description><![CDATA[在回归上下文中，回归方程的指定非常重要。当我们将不相关的预测因子添加到回归规范中时，可能会导致错误指定问题，从而损害模型的准确性。
我想知道，在随机森林框架中这是否是一个大问题？我的数据集中有很多预测因子，我应该将它们全部包括进去吗？如果不是，原因是什么？以及如何选择应该包括哪些预测因子？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652315/is-it-a-good-idea-to-add-as-many-predictors-as-possible-in-a-random-forest</guid>
      <pubDate>Mon, 05 Aug 2024 08:04:43 GMT</pubDate>
    </item>
    <item>
      <title>LOOCV 测试错误因手动“for() 循环”或 cv.glm() 而异</title>
      <link>https://stats.stackexchange.com/questions/652314/loocv-test-error-is-different-by-mannually-for-loop-or-cv-glm</link>
      <description><![CDATA[这是关于《统计学习简介及其在 R 中的应用》一书第 5 章中的第 7 个问题。以下是问题文本的一部分：


在第 5.3.2 和 5.3.3 节中，我们看到可以使用 cv.glm() 函数来计算 LOOCV 测试误差估计。
或者，可以仅使用 glm()
和 predict.glm() 函数以及 for 循环来计算这些数量。现在，您将采用这种方法来
计算Weekly数据集上简单逻辑回归模型的 LOOCV 误差。


解决方案 1：使用 glm()、predict.glm() 和 for 循环
library(ISLR2)
error &lt;- numeric(nrow(Weekly))

for (i in 1:nrow(Weekly)) {

fit &lt;- glm(Direction ~ Lag1 + Lag2,
data = Weekly[-i, ],
family = &quot;binomial&quot;)

# &quot;Up&quot;为 TRUE
p &lt;- predict(fit, 
newdata = Weekly[i,,drop = FALSE],
type = &quot;response&quot;) &gt; 0.5

# 错误：错误分类的项目
error[i] &lt;- ifelse(p, &quot;Down&quot;, &quot;Up&quot;) == Weekly$Direction[i]

}

# LOOCV 测试误差估计
mean(error)
# [1] 0.4499541

解决方案 2：直接使用 cv.glm()
library(boot)
fit2 &lt;- glm(Direction ~ Lag1 + Lag2,
data = Weekly,
family = &quot;binomial&quot;)

cv.err.fit2 &lt;- cv.glm(Weekly, fit2)

# LOOCV 测试误差估计
cv.err.fit2$delta[1]
# [1] 0.2464536

这是我的问题：
为什么解决方案 1和解决方案 2的 LOOCV 测试误差估计结果差别很大（0.4499541 V.S. 0.2464536）？它们应该是相同的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652314/loocv-test-error-is-different-by-mannually-for-loop-or-cv-glm</guid>
      <pubDate>Mon, 05 Aug 2024 07:04:20 GMT</pubDate>
    </item>
    <item>
      <title>如何使用三次样条函数的 NLME 复制拟合值计算？</title>
      <link>https://stats.stackexchange.com/questions/652313/how-to-replicate-fitted-value-calculation-using-nlme-with-cubic-splines</link>
      <description><![CDATA[我正在使用 R 中的 SITAR 拟合 nlme 模型，
library(sitar)
#&gt;正在加载所需包：nlme
ff &lt;- na.omit(berkeley[berkeley$sex == 2 &amp; berkeley$age &gt;= 8 &amp; berkeley$age &lt;= 18, 
c(&#39;id&#39;, &#39;age&#39;, &#39;height&#39;)])
fh1 &lt;- sitar(x = age, y = height, id = id, data = ff, df = 3, fixed = &quot;a + b + c&quot;, random = &quot;a&quot;)

根据 SITAR 的文档，它表示模型规范为：

在我的代码中，有 3 个固定效应，$\alpha_0、\beta_0、\gamma_0$ 和一个随机效应，$\alpha_i$。所以我的模型是：
$$y_{ij} = \alpha_0 + \alpha_i + h\left(\frac{age_{ij}-\beta_0}{exp(-\gamma_0)}\right) + \epsilon_{ij}$$
我想确保我理解如何计算 SITAR 的预测值。首先，predict.sitar 为我提供了以下内容
模型拟合的预测值：
ages &lt;- seq(0, 18, 0.1)
predicted_height &lt;- predict(fh1, newdata = data.frame(age = ages),, type = &quot;response&quot;, level = 0)
&gt; head(predicted_height)
301 301 301 301 301 301 
85.86228 86.40480 86.94732 87.48984 88.03236 88.57488 

手工计算的预测值：
这些是我估计的固定效应：
&gt; fixef(fh1)
s1 s2 s3 a b c 
35.1254398 55.2275889 32.2892681 124.2293895 -1.3156610 0.1576641 

我根据公式 (1) 获得自然三次样条拟合，即计算 $h\left(\frac{age_{ij}-\beta_0}{exp(-\gamma_0)}\right)$ 并将其存储在 basis 中。
basis &lt;- ns((ages - fixef(fh1)[5])/exp(-fixef(fh1)[6]), df = 3)

将所有内容放在一起：
predicted_height_hand_calculate &lt;- fixef(fh1)[4] + fixef(fh1)[1] * basis[, 1] + fixef(fh1)[2] * basis[, 2] + fixef(fh1)[3] * basis[, 3]
&gt; head(predicted_height_hand_calculate)
[1] 124.2294 124.5082 124.7871 125.0660 125.3449 125.6241

但是，这些与 predicted_height 不匹配。是什么导致了这种差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/652313/how-to-replicate-fitted-value-calculation-using-nlme-with-cubic-splines</guid>
      <pubDate>Mon, 05 Aug 2024 06:36:38 GMT</pubDate>
    </item>
    <item>
      <title>当相关系数为正时，copula 所求的条件期望是否严格增加，反之亦然？</title>
      <link>https://stats.stackexchange.com/questions/652311/is-conditional-expectation-evaluated-by-the-copula-strictly-increasing-when-the</link>
      <description><![CDATA[我使用 copula 来评估 $\mathbb{E}[Y|X]$，从我对一些 copula 的实验中，我观察到当随机变量具有正相关系数时，$\mathbb{E}[Y|X]$ 严格增加，而当它们负相关时，$\mathbb{E}[Y|X]$ 严格减少。此外，这篇文章中的条件期望图也显示了严格的行为。我想知道这是否正确以及如何证明这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/652311/is-conditional-expectation-evaluated-by-the-copula-strictly-increasing-when-the</guid>
      <pubDate>Mon, 05 Aug 2024 06:12:13 GMT</pubDate>
    </item>
    <item>
      <title>尝试定义一个迭代函数来使用不同的 n 值重复调用 KNeighboursClassifier</title>
      <link>https://stats.stackexchange.com/questions/652310/trying-to-define-an-iterative-function-to-repertitively-call-kneighboursclassifi</link>
      <description><![CDATA[当我运行代码并使用 KNN 而不调用函数时，如果 n 的值是固定的，则不会出现任何错误，准确度得分为 1.0。但是，我想绘制具有不同 n_neighbours 值的准确度得分图。为此，我创建了一个函数，该函数每次迭代都会使用不同的 n_neighbours 值调用分类器。



请帮忙。]]></description>
      <guid>https://stats.stackexchange.com/questions/652310/trying-to-define-an-iterative-function-to-repertitively-call-kneighboursclassifi</guid>
      <pubDate>Mon, 05 Aug 2024 06:00:06 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据超过 50% 的填补理由</title>
      <link>https://stats.stackexchange.com/questions/652307/justification-for-imputation-with-over-50-missing-data</link>
      <description><![CDATA[我希望就以下情况获得一些建议/想法：假设我有一项前瞻性观察性研究，旨在评估在两年的随访中 BMI 的变化（主要结果），该研究针对按照护理标准使用药物 A 和药物 B 的人群。重点不是比较 A 组和 B 组之间的 BMI，而是评估每个组内的 BMI 变化。
身高和体重收集的访问应该每六个月进行一次（基线、六个月、12 个月、18 个月和 24 个月），持续 24 个月。然而，由于退出率高，只有 40% 的参与者进行了完整的 24 个月随访，因此未达到主要结果的样本量目标。
考虑到研究的纵向性质，我考虑使用混合效应模型来解释参与者内部的相关性，其中
固定效应与时间（自基线以来的月份）、药物组及其相互作用有关。
随机效应：每个参与者的随机截距和斜率，以解释个体差异。
然而，研究人员也在推动缺失数据填补，但我不确定这是否可行，或者如何向监管机构证明这一点，因为我们必须填补超过 50% 的数据。
您将如何处理这种情况？这里是否需要填补，如果是，哪种填补方法最适合（也许是模式混合模型，因为缺失数据模式是 MNAR？）？您是否推荐我阅读一些关于其他人如何处理和解决类似问题的文章？
任何建议/参考都将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652307/justification-for-imputation-with-over-50-missing-data</guid>
      <pubDate>Mon, 05 Aug 2024 02:49:05 GMT</pubDate>
    </item>
    <item>
      <title>如果 $X$ 和 $Y$ 是独立随机向量，则 $X_{i}|X_{i-}$ 和 $Y_{i}|Y_{i-}$ 是否独立？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652257/if-x-and-y-are-independent-random-vectors-is-x-ix-i-and-y-iy-i</link>
      <description><![CDATA[假设 $X$ 和 $Y$ 是独立的随机向量，$X_i|X_{i-}$ 是否独立于 $Y_{i}|Y_{i-}$？其中 $i-$ 包含随机向量中不存在于 $i$ 中的元素。基本上我想知道的是$X_i|X_{i-}$是否可以表示为$X$的函数作为独立随机向量的函数是独立的。如果成立，我将不胜感激任何相关证明。
例如，对于三维随机向量 $(X_1, X_2, X_3)$，$(X_i|X_{i-})$ 可以是以下任意一个随机向量 - $(X_1 | X_2=x_2, X_3=x_3)$，$(X_1, X_2 | X_3=x_3)$，$(X_1, X_3 | X_2=x_2)$ ...]]></description>
      <guid>https://stats.stackexchange.com/questions/652257/if-x-and-y-are-independent-random-vectors-is-x-ix-i-and-y-iy-i</guid>
      <pubDate>Sat, 03 Aug 2024 19:50:21 GMT</pubDate>
    </item>
    <item>
      <title>在联合建模与单独建模中寻找真正的“致病”协变量</title>
      <link>https://stats.stackexchange.com/questions/652255/finding-the-true-causative-covariate-in-joint-versus-separate-modeling</link>
      <description><![CDATA[这是关于一些遗传分配的。
假设我们有两个随机协变量 (SNP) $X1,X2$，以及一个随机响应 $Y$（疾病）。我相信 $X1,X2$ 中只有一个对 $Y$ 具有“因果性”，
但不知道哪一个，目标是基于 $n$ 个 $X1$、$X2$、$Y$ 的随机样本，找出它是 $X1$。
为此，我们有两种可能的策略：
(I) 两个单变量模型：$Y\sim X_{1},Y\sim X_{2}$，并在它们之间进行选择（使用$p_{val}$ 比较或其他）。
(II) 单一回归模型 $Y\sim X_{1}+X_{2}$（并选择具有较低 $p$ 值或更高的模型）。
我需要在以下情况下证明/不证明使用每种策略的合理性：
(a) $X_1,X_2$ 是独立的（例如，两个 SNP 位于不同的染色体上）。
(b) $X_1,X_2$ 是正相关的（例如，两个相邻的 SNP）。

我尝试使用线性回归的基础知识，寻找at
$$
I:\hat{\beta}=X^{T}Y\ \ \ \ \ II:\hat{\beta}=\left(X^{T}X\right)^{-1}X^{T}Y
$$
由此我认为在情况 (a) 中没有太大区别，而在情况 (b) 中我们必须使用 II，因为方法 (I) 没有考虑协变量之间的相关性。但这是“预测”方面，而不是“因果”方面。因此我很难“形式化”这一点。

编辑
感谢大家的回答！
但我觉得我表达得不够清楚。

这个问题不是因果推理的问题，而是回归和建模的问题。我认为我的讲师在这个问题上更多的是指“联想”而不是“因果”。
作为建模者，我们知道其中一个是联想的。现在假设这是$X_1$。问题是哪种策略能更有效地找到它（从错误和功率方面来看）。
这应该是合理的理论问题，而不是实际问题。模拟的想法也是可以接受的。
非常感谢！
]]></description>
      <guid>https://stats.stackexchange.com/questions/652255/finding-the-true-causative-covariate-in-joint-versus-separate-modeling</guid>
      <pubDate>Sat, 03 Aug 2024 18:34:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么修改后的 z 分数没有发现明显的异常值？</title>
      <link>https://stats.stackexchange.com/questions/652217/why-does-modified-z-score-not-pick-up-an-obvious-outlier</link>
      <description><![CDATA[希望借鉴您对用于检测异常值的修改后的 z 分数的一些见解。
据我从研究中得知，当分布可能不正常（例如偏斜）时，修改后的 z 分数比 z 分数本身更能指示异常值。这是因为，如果分布不为正态分布，则使用中位数而不是均值，中位数是集中趋势的稳健估计量。
我正在针对一个值列表测试这两种算法以及其他一些异常值检测算法，其中我知道一个值是极端异常值。为了帮助我，我创建了一个小型 Python 程序，它根据该列表计算 z 分数和修改后的 z 分数，然后使用它来检查列表中的任何项目是否看起来像异常值。基本上，我检查了这些算法是否能成功检测到我知道存在的极端异常值。
为了检查我的数据的分布，程序创建了一个箱线图，异常值（值 = 200）非常明显。作为参考，该数据集的中位数为 58。

异常值 200 的修改后的 z 分数仅为 2.81，这大大低于被视为异常值的 3.5，因此它不会被标记为异常值。仅供参考，我使用 3.5，因为这似乎是最推荐的截止值。
异常值 200 的 z 分数为 3.40，这高于被视为异常值的 3.0，因此它确实被标记为异常值。仅供参考，我使用 3.0 作为截止值，因为这似乎最受欢迎。
我的问题是，为什么 z 分数算法可以检测到我的数据集中的异常值，而修改后的 z 分数算法却不能？这对我来说似乎是违反直觉的，尤其是当异常值从箱线图中显而易见时。
这是我的 Python，以防我犯了错误：
import matplotlib as plt
import numpy as np
from scipy.stats import zscore

def z_score_mod(obs):
# 修改后的 z-score = 0.6745(xi – x̃) / MAD
med = np.median(obs)
med_abs_dev = np.median(np.abs(obs - med))
z_score_mod = 0.6745 * ((obs - med) / med_abs_dev)
return z_score_mod

# 具有相当大的异常值 = 200 和索引 = 的观察列表13
list_of_obs = [58,71,11,18,90,97,15,53,39,22,62,51,10,200,20,64,94,71,73,18,95,96,92,38,26]

# 将观察列表转换为 numpy 数组
array_of_obs = np.array(list_of_obs)

# 创建箱线图以显示异常值
plt.pyplot.boxplot(array_of_obs)

median = np.median(array_of_obs)

# 计算每个数组项的修改后的 z 分数
array_of_z_score_mod = z_score_mod(array_of_obs)

# 对于生成的修改后的 z 分数，确定是否有任何异常值
array_of_outlier_evals = abs(array_of_z_score_mod) &gt; 3.5

# 索引 = 13 处的观测值 = 200 是否为异常值？
print(&#39;\r&#39;)
print(f&#39;索引位置 13 处的观察值 = {list_of_obs[13]}&#39;)
print(f&#39;修改后的 z 分数值 = {array_of_z_score_mod[13]:.2f}&#39;)
print(f&#39;在修改后的 z 分数阈值 3.5 处，值是否为异常值：{array_of_outlier_evals[13]}&#39;)

# 计算每个数组项的 z 分数
array_of_z_score = zscore(list_of_obs)

# 对于生成的 z 分数，确定是否有任何异常值
array_of_outlier_evals_2 = abs(array_of_z_score) &gt; 3

# 索引 = 13 处的观察值 = 200 是否为异常值？
print(&#39;\r&#39;)
print(f&#39;索引位置 13 处的观察值 = {list_of_obs[13]}&#39;)
print(f&#39;值的 z-score = {array_of_z_score[13]:.2f}&#39;)
print(f&#39;在 z-score 阈值 3.0 处，值是否为异常值：{array_of_outlier_evals_2[13]}&#39;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/652217/why-does-modified-z-score-not-pick-up-an-obvious-outlier</guid>
      <pubDate>Fri, 02 Aug 2024 17:17:52 GMT</pubDate>
    </item>
    <item>
      <title>调查（病例对照？）数据的生存分析</title>
      <link>https://stats.stackexchange.com/questions/652112/survival-analysis-for-survey-case-control-data</link>
      <description><![CDATA[我有一个数据集，其中包含大约 500 名患有大约 10 种不同疾病的患者，可能具有相关结果，以及 200 名健康对照者。患者数据来自医院，而对照数据来自志愿者，并且不匹配。我们有各种生活事件的全面记录，包括患者和对照者的具体日期（例如，首次非法使用毒品的年龄）和诊断日期。但是，没有可用的抽样权重。
作为第一步，我计划将 Cox 比例风险 (PH) 模型分别应用于每种疾病，使用出生作为时间参考（时间 = 0）。事件是二元的（无论是否诊断出疾病）。数据集包括大约 10 个潜在预测因子，例如性别、种族和教育程度，一些协变量可能与时间有关（例如，婚姻史和就业情况）。
(A) 鉴于病例抽样过多，我可以根据外部来源的患病率或发病率对样本进行加权吗？ （以前做过此类研究的论文链接将非常有帮助。）
(B) 即使这项研究不符合传统定义，它是否可以被视为病例队列研究？
(C) 虽然逻辑回归通常用于病例对照研究（仅产生比值比），但在生存分析中是否有类似的方法来处理此类数据？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652112/survival-analysis-for-survey-case-control-data</guid>
      <pubDate>Wed, 31 Jul 2024 19:36:40 GMT</pubDate>
    </item>
    <item>
      <title>用于在*单一*验证数据集上比较两个回归模型的性能指标的统计测试？</title>
      <link>https://stats.stackexchange.com/questions/518773/statistical-test-for-comparing-performance-metrics-of-two-regression-models-on-a</link>
      <description><![CDATA[基于单个保留（验证）数据集，应用统计假设检验来评估两个回归模型之间的模型性能指标（例如 MAE、MAPE、MSE）的适当方法是什么？
可能的方法
我想要做的是直接对观测值应用配对 t 检验（至少对于绝对误差 (AE) 或绝对百分比误差 (APE) 等具有有意义的相应观测水平测量的测量）。但是，这样做的问题似乎是我们可能会违反一些配对 t 检验的假设，例如

因变量可能不服从正态分布（当比较交叉验证分割的指标平均值时，它们会服从正态分布，请参阅 [上下文]，由于中心极限定理，我们可以在许多指标中信任它）
无法免受异常值的影响

不过，我想我需要多大程度上担心这些（t 检验不是相当稳健吗）？或者我们可以对测试进行哪些调整以使其仍然有效？使用 Wilcoxan 符号秩检验 是否是更好的方法... (发推文)？
优先选择简单、合理适当/可推广的方法，并使用不依赖于多次构建模型的保留数据性能...
上下文
基于保留数据预测的常见模型比较技术是使用 k 倍交叉验证构建多个模型，计算每个模型在 k 个保留集上的平均性能，然后使用配对 t 检验比较模型之间的性能（例如，来自 Rstudio 的 {tidymodels} 团队，请参阅 Feature Engineering..., 3.7 或 Tidy Models with R, 11.3）。
我经常使用此程序，并且喜欢它的简单性，但是我对它有一些担忧：

在进行简单的训练-验证拆分以进行评估时无法使用（因为只有一个保留集）
测试的功效似乎可能取决于拆分的数量，k
在 用于比较机器学习算法的统计显着性检验批评该方法缺乏独立性（因为训练集在k个模型之间大致相似），但仍然指出该方法很好，可能只是有一点较高的1型错误——这一点并没有太困扰我，因为我主要使用测试作为指标。

这个问题与点1.有关，我们使用单个验证集进行评估。我发现了很多关于模型比较中统计测试的交叉验证帖子，但大多数都是在交叉验证或其他重采样程序的背景下。
相关/后续问题

同样，我最近发推文关于使用简单方法（基于计算标准误差）在验证集中对模型性能估计添加置信区间，这种方法可以吗？还是有问题？
在进行 k 倍交叉验证的情况下，对训练集中的各个保留预测的误差进行配对 t 检验可以吗（即对 n 个观测样本进行测试，而不是对k 每个分割的平均误差）。然而，第 3 点和要点中的担忧让我在这里更加犹豫……（此外，与上述说明类似，某些指标无法在观察级别计算，例如在分类上下文中 ROC 曲线下的 AUC）。
]]></description>
      <guid>https://stats.stackexchange.com/questions/518773/statistical-test-for-comparing-performance-metrics-of-two-regression-models-on-a</guid>
      <pubDate>Thu, 08 Apr 2021 17:47:00 GMT</pubDate>
    </item>
    </channel>
</rss>