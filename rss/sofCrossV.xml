<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 04 Nov 2024 12:34:11 GMT</lastBuildDate>
    <item>
      <title>通过 svd 进行典型相关分析</title>
      <link>https://stats.stackexchange.com/questions/656720/canonical-correlation-analysis-via-svd</link>
      <description><![CDATA[为了我自己的理解，我尝试使用交叉积和 svd 重现 R CCA::cc 中的典型相关结果。我尝试了几种方法，但都无法正确执行，您能提供一些见解吗？
这是使用 CCA 包的代码：
library(CCA)
data(nutrimouse)
X=as.matrix(nutrimouse$gene[,1:10])
Y=as.matrix(nutrimouse$lipid)

X &lt;- scale(X) # 缩放并居中的 40x10 矩阵
Y &lt;- scale(Y) # 缩放并居中的 40x21 矩阵

res.cc &lt;- cc(X,Y)

我尝试过：
cp &lt;- crossprod(X, Y)
cca_svd &lt;- svd(cp)

我应该怎么做现在如何获取 X 和 Y 矩阵的典型相关系数和系数？
ChatGPT 给出了以下内容，但似乎不正确：
cp &lt;- crossprod(X, Y)

# 步骤 2：对交叉积执行 SVD
cca_svd &lt;- svd(cp)

# 步骤 3：计算典型相关
# 典型相关是来自 SVD 的奇异值
canonical_correlations &lt;- cca_svd$d^2 / (1 + cca_svd$d^2) # 针对典型相关进行调整

# 步骤 4：计算典型变量
# 典型变量可以从 U 和 V 矩阵中获得
U &lt;- cca_svd$u
V &lt;- cca_svd$v

# 典型变量
canonical_variates_X &lt;- X %*% U
canonical_variates_Y &lt;- Y %*% V

例如，ChatGPT 中的典型相关性为：
canonical_correlations
[1] 1.00 1.00 1.00 1.00 1.00 0.99 0.99 0.93 0.85 0.77

而上面的 CCA::cc 给出：
res.cc$cor
[1] 0.99 0.98 0.94 0.92 0.81 0.72 0.64 0.61 0.55 0.36
]]></description>
      <guid>https://stats.stackexchange.com/questions/656720/canonical-correlation-analysis-via-svd</guid>
      <pubDate>Mon, 04 Nov 2024 10:57:58 GMT</pubDate>
    </item>
    <item>
      <title>具有删失协变量的风险——我应该使用哪种方法？</title>
      <link>https://stats.stackexchange.com/questions/656719/risk-with-censored-covariates-which-method-should-i-use</link>
      <description><![CDATA[TL;DR - 我的数据包括：

幼儿因家庭伤害而去医院的年龄。
幼儿爬行、走路和跑步的年龄记录。记录受到审查，因为有些幼儿在开始（例如）走路之前就到了医院。

我想预测“家庭伤害风险”。我应该怎么做？
现在更详细一点：我有因家庭伤害而去医院的幼儿的数据。每个幼儿每隔一段时间都会去社区的护士那里看望，护士会记录幼儿是否可以（A）爬行、（B）走路、（C）跑步。进展是单调的：走路的幼儿肯定可以爬行，而跑步的幼儿不会停止跑步。我认为幼儿年龄和达到上述活动水平 A、B 和 C 的年龄是家庭受伤风险的指标，因为活动能力更强的幼儿受伤的几率更高。
对于特定的幼儿，我想计算家庭受伤的风险指标。我的想法：

我当然无法计算受伤的概率$\Pr(injury)$，因为我没有未去过医院的幼儿的记录。
出于类似的原因，我不能天真地使用逻辑回归。
也许可以计算相对于某个基线年龄的优势比并使用罕见疾病近似值？但是，我该如何整合关于活动水平 A、B 和 C 的信息呢？
我认为 Cox 回归在这里不合适，因为我实际上并没有对事件发生时间进行建模。

请建议定义和查找幼儿“受伤风险”的方法。我也希望您能解释一下我提到的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/656719/risk-with-censored-covariates-which-method-should-i-use</guid>
      <pubDate>Mon, 04 Nov 2024 10:41:05 GMT</pubDate>
    </item>
    <item>
      <title>如何对概率 $\Pr((U,V)\in A)$ 进行核平滑​​估计并显示其一致性？</title>
      <link>https://stats.stackexchange.com/questions/656718/how-to-do-kernel-smoothed-estimation-of-the-probability-pru-v-in-a-and-sh</link>
      <description><![CDATA[假设我有兴趣用随机样本$\{(U_i,V_i)\}_{i=1}^N$估计$p=\Pr((U,V)\in A)$的概率。最简单的方法是使用样本均值：$\widehat{p}=1/N\times \sum_{i=1}^N 1((U_i,V_i)\in A)$，即基于指示函数的相对频率估计量，弱大数定律保证$\widehat{p}$的一致性。但指示函数不平滑，我想要一个平滑的估计量。我知道 Nadaraya-Watson 核密度估计量，我正在考虑提出一些可能看起来类似的内容：$\widehat{p}_s=1/N\times \sum_{i=1}^N \frac{1}{h^2} k(\frac{(U_i,V_i)???}{h})????$，其中 $k(\cdot)$ 是核函数，$h$ 是带宽。我遇到了一个困难，不知道在核函数中要写什么（问号），因此不知道如何继续。
因此，我的问题是，如何为概率构建一个平滑估计量（基于核平滑）？什么时候是一致的？
如果您可以列出内核和带宽的条件，以便估计量对于感兴趣的概率是一致的，并在您的条件下证明其一致性，那就太好了。]]></description>
      <guid>https://stats.stackexchange.com/questions/656718/how-to-do-kernel-smoothed-estimation-of-the-probability-pru-v-in-a-and-sh</guid>
      <pubDate>Mon, 04 Nov 2024 10:25:09 GMT</pubDate>
    </item>
    <item>
      <title>时间序列模型中的递归一步预测</title>
      <link>https://stats.stackexchange.com/questions/656717/recursive-one-step-forecasting-in-timeseries-model</link>
      <description><![CDATA[我正在尝试为随机森林模型实施递归一步预测方法。
这个想法是以迭代方式获得 12 个月的预测，其中每个预测在下一个预测之前成为历史记录的一部分。
鉴于我没有重新训练模型，并且模型的误差在每个递归预测步骤中都会累积，我预计误差图会稳步增加。但是，没有这样的趋势。
我想知道实施过程中是否存在任何问题。我想在现实世界中测试模型的预测能力，我们迭代地预测下一个值（例如，如果我想进行 12 个月的预测）。
import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt

# 设置随机种子以实现可重复性
np.random.seed(1)

# 创建日期范围
date_rng = pd.date_range(start=&#39;2018-01-01&#39;, end=&#39;2024-12-31&#39;, freq=&#39;MS&#39;)
n_points = len(date_rng)

# 趋势成分（线性增长）
trend = np.linspace(100, 200, n_points)
seasonal = 20 * np.sin(2 * np.pi * np.arange(n_points) / 12)
cyclical = 30 * np.sin(2 * np.pi * np.arange(n_points) / (12 * 3))
noise = np.random.normal(0, 10, n_points)
values = trend + seasonal + cyclical + noise

df = pd.DataFrame({
&#39;date&#39;: date_rng,
&#39;value&#39;: values
})

# 格式化数据
df[&#39;year&#39;] = df[&#39;date&#39;].dt.year
df[&#39;month&#39;] = df[&#39;date&#39;].dt.month
df[&#39;value&#39;] = df[&#39;value&#39;].round(2)

# 构建时间特征
df.index = pd.to_datetime(df.date)
df[&#39;quarter&#39;] = df.index.quarter
df[&#39;month&#39;] = df.index.month
df[&#39;year&#39;] = df.index.year
df[&#39;sin_month&#39;] = np.sin(2 * np.pi * df.index.month / 12)
df[&#39;cos_month&#39;] = np.cos(2 * np.pi * df.index.month / 12)

# 构建滞后
num_lags = 12
lagged_columns = {f&#39;lag_{lag}&#39;: df[&#39;value&#39;].shift(lag) for lag in range(1, num_lags + 1)}
df = df.assign(**lagged_columns)
df.dropna(inplace=True)

# 简单移动平均线 (SMA)
sma_window_size = 12
df[f&#39;SMA_{sma_window_size}&#39;] = df[&#39;value&#39;].rolling(window=sma_window_size).mean()

# 指数移动平均线 (EMA)
ema_span_size = 9
df[f&#39;EMA_{ema_span_size}&#39;] = df[&#39;value&#39;].ewm(span=ema_span_size).mean()

# 拆分数据并拟合模型
split_point = &#39;2023-12-31&#39;

# 拆分为训练和测试
train = df.query(&#39;date &lt;= @split_point&#39;)
test = df.query(&#39;date &gt; @split_point&#39;)

# 创建训练特征和目标
X_train = train.drop(columns=[&#39;value&#39;, &#39;date&#39;])
y_train = train[&#39;value&#39;]

# 创建测试特征和目标
X_test = test.drop(columns=[&#39;value&#39;, &#39;date&#39;])
y_test = test[&#39;value&#39;]

rf_model = RandomForestRegressor(n_estimators=100, 
max_depth=10,
random_state=0)
rf_model.fit(X_train, y_train)

# 预测步骤数
num_forecasts = 12 
all_forecasts = {}

# 获取最后一个训练样本
X_last = train.iloc[[-1]].drop(columns=[col for col in train.columns.tolist() if col not in X_train.columns.tolist()]) # 删除不存在的标识符X_train

forecasts = []

for step in range(num_forecasts):

# 进行预测
y_pred = rf_model.predict(X_last.values.reshape(1, -1))[0]
Forecasts.append(y_pred)

# 更新滞后
X_last_series = pd.Series(X_last.iloc[0])
lags = X_last_series.filter(like=&#39;lag_&#39;).copy().shift(1, axis=0)
lags[&#39;lag_1&#39;] = y_pred
X_last_series.update(lags)

# 必要时更新季节性或静态特征
if &#39;month&#39; in X_last_series.index and &#39;quarter&#39; in X_last_series.index:
# 月份和季度
current_month = X_last_series[&#39;month&#39;] % 12 + 1

X_last_series[&#39;month&#39;] = current_month
X_last_series[&#39;quarter&#39;] = (current_month - 1) // 3 + 1

# 年份（如果月份回绕到 1 月，则增加）
if current_month == 1:
X_last_series[&#39;year&#39;] += 1

# 周期性特征（月份）的正弦变换
X_last_series[&#39;sin_month&#39;] = np.sin(2 * np.pi * current_month / 12)
X_last_series[&#39;cos_month&#39;] = np.cos(2 * np.pi * current_month / 12)

# 更新滚动特征
if f&#39;SMA_{sma_window_size}&#39; in X_last_series.index:
past_values = X_last_series.filter(like=&#39;lag_&#39;).values[:sma_window_size - 1]
X_last_series[f&#39;SMA_{sma_window_size}&#39;] = np.mean(np.append(past_values, y_pred))

if f&#39;EMA_{ema_span_size}&#39; in X_last_series.index:
ema_alpha = 2 / (ema_span_size + 1)
X_last_series[f&#39;EMA_{ema_span_size}&#39;] = ema_alpha * y_pred + (1 - ema_alpha) * X_last_series[f&#39;EMA_{ema_span_size}&#39;]

# 更新 X_last 以进行下一个预测步骤
X_last = X_last_series.to_frame().T

def calculate_mape(y_true, y_pred):
return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

steps_mape = []
for i in range(num_forecasts): 
steps_mape.append(calculate_mape(y_test[i], Forecasts[i]))

plt.plot(steps_mape)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/656717/recursive-one-step-forecasting-in-timeseries-model</guid>
      <pubDate>Mon, 04 Nov 2024 10:13:37 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 MBESS 包如何处理缺失值？</title>
      <link>https://stats.stackexchange.com/questions/656716/how-are-missing-values-dealt-with-in-the-mbess-package-in-r</link>
      <description><![CDATA[我目前正在用 R 计算我的量表的麦当劳 Omega。文献建议使用 MBESS 包中的 ci.reliability 函数来获取置信区间。但是，我还没有找到任何关于 MBESS 如何处理缺失值的文档。如果能提供关于此问题的任何信息，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/656716/how-are-missing-values-dealt-with-in-the-mbess-package-in-r</guid>
      <pubDate>Mon, 04 Nov 2024 09:52:19 GMT</pubDate>
    </item>
    <item>
      <title>当阳性事件案例样本量较少时，应如何抽样才能节省成本？</title>
      <link>https://stats.stackexchange.com/questions/656713/when-the-sample-size-of-positive-event-cases-is-small-how-should-the-cases-be-s</link>
      <description><![CDATA[有一个问题困扰了我很久，查阅了很多资料都没有找到准确的答案。我的问题是：假设我有10000个病人，其中只有100个死亡病人，9900个幸存病人，为了降低收集病历的成本，我打算从9900个幸存病人中随机抽取200个病人作为幸存组，然后和100个死亡病人合并，最终样本为300个病人。这种抽样方法可以接受吗？如果可以，这种抽样方法属于哪一类？是不是不等比例分层抽样？]]></description>
      <guid>https://stats.stackexchange.com/questions/656713/when-the-sample-size-of-positive-event-cases-is-small-how-should-the-cases-be-s</guid>
      <pubDate>Mon, 04 Nov 2024 08:36:45 GMT</pubDate>
    </item>
    <item>
      <title>收敛速度的平方 $\|\hat{A}-A\|_F^2$</title>
      <link>https://stats.stackexchange.com/questions/656712/square-of-the-convergence-rate-hata-a-f2</link>
      <description><![CDATA[在高维设置中，如果我们有一个估计量$\hat{A}\in\mathbb{R}^{n\times n}$，我们总是试图得到通过矩阵范数衡量的收敛速度，例如$\|\hat{A}-A\|_F$。
现在，如果我已经以很高的概率获得了收敛速度$\|\hat{A}-A\|_F\le c\sqrt{\frac{\log p}{n}}$，我是否可以直接获得收敛速度$\|\hat{A}-A\|_F^2\le c^2{\frac{\log p}{n}}$?
直觉上，我觉得这个结果是正确的。如果它成立，那么它对所有矩阵范数都成立吗？例如，Frobenius 范数和谱范数。]]></description>
      <guid>https://stats.stackexchange.com/questions/656712/square-of-the-convergence-rate-hata-a-f2</guid>
      <pubDate>Mon, 04 Nov 2024 08:21:18 GMT</pubDate>
    </item>
    <item>
      <title>因变量的水平可能会调节预测因子的影响</title>
      <link>https://stats.stackexchange.com/questions/656711/level-of-dependent-variable-may-moderate-the-effects-of-predictors</link>
      <description><![CDATA[这与我自己的数据无关，但我被要求就以下情况提供建议：
一位研究人员向一组参与者提供了某种自我报告工具。他们想看看分数中是否存在性别和年龄差异，但他们认为，对于在此工具上得分低于某个阈值（假设为 100 分）的参与者和高于该阈值的参与者，性别和年龄对分数的影响将有所不同，并希望对此进行调查。
我想到的唯一方法是创建一个二元变量，指示参与者的得分是低于还是高于 100 分，并包括性别和年龄与此变量之间的相互作用，但这不可能是正确的，因为基于因变量的变量肯定不应该作为预测因子？但有什么方法可以做到这一点，或者有什么办法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656711/level-of-dependent-variable-may-moderate-the-effects-of-predictors</guid>
      <pubDate>Mon, 04 Nov 2024 08:19:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 Bootstrap 与交叉验证来评估机器学习模型的预测性能</title>
      <link>https://stats.stackexchange.com/questions/656710/bootstrap-vs-crossvalidation-for-assessing-the-predictive-performance-of-a-machi</link>
      <description><![CDATA[我正在尝试在引导和交叉验证之间做出选择，以便彻底评估预测模型性能。
引导：

使用替换对数据进行采样，创建 B &gt; 1000（或更多）个不同的训练集，其中由于使用替换采样，每个观察结果都被独立处理！这意味着经验分布函数被用作抽取样本的真实世界分布的替代品。
动态使用袋外 (OOB) 观测值作为保留集：这消除了对单独保留集的需求，并且可以提供更可靠的样本外预测性能估计。
可能捕获更多真实世界方差（通过替换采样，即利用经验分布函数）

如果我必须评估两个不同的模型，我会

生成 B=1000 ... 训练数据集的引导重采样
在 B 个不同的袋外测试样本集上评估这两个模型
计算配对模型性能差异（性能模型 1 - 性能模型 2，其中差异取自相同的 OOB 测试集），配对将用于https://en.wikipedia.org/wiki/Variance_reduction
制作配对模型性能差异的直方图
如果模型性能的密度明显偏离 0，则其中一个模型优于另一个模型（由此也可以设计一些测试以获得 95% 的改进确定性...）

交叉验证：

将数据分成几部分，使用不同的部分进行训练和测试。
可以更有效率，尤其是在数据有限的情况下。
可能导致“相关”训练集，尤其是在 LOOCV 中（训练集几乎没有变化，除了一个观察值）

为了比较两个模型，我会做与 bootstrap 情况相同的事情（只是没有袋外测试样本，但在 LOOCV 的情况下，最大 N= 观察值不同的保留集）。
问题：
鉴于 bootstrap 可以在训练集中引入更多变化（通过替换重采样）并利用 OOB 数据进行验证，与交叉验证（本质上是无替换重采样）相比，它是否会提供更现实的样本外性能估计？尤其是潜在的“相关性” 交叉验证训练集之间是否存在重大问题？
PS：我尝试搜索 stackoverflow 并提出了类似的问题，但它们没有讨论 CV 训练集的潜在相关性问题：

Bootstrap 或 jack-knife 用于预测模型的交叉验证？（无答案）
了解用于验证和模型选择的 bootstrapping
交叉验证和引导法在估计预测误差方面的差异（没有明确的答案哪个更可靠）
交叉验证或引导法评估分类性能？（这个问题似乎很直接，但公认的答案主要涉及只有一个测试训练分割（CV 的退化形式，显然没有像 k 倍 CV 那样的多个测试训练分割），Frank Harell 有一个答案 https://stats.stackexchange.com/a/71189/298651 链接 https://hbiostat.org/doc/simval.html 得出一个结论“普通引导法优于或等于所有尝试过的交叉验证策略”，但这在他的回答中没有明确讨论...)
分类测试的交叉验证与随机抽样（没有明确的结论，无所谓，但有趣的论文？）
]]></description>
      <guid>https://stats.stackexchange.com/questions/656710/bootstrap-vs-crossvalidation-for-assessing-the-predictive-performance-of-a-machi</guid>
      <pubDate>Mon, 04 Nov 2024 07:58:08 GMT</pubDate>
    </item>
    <item>
      <title>带 Cholesky 分解的脉冲响应函数</title>
      <link>https://stats.stackexchange.com/questions/656709/impulse-response-function-with-cholesky-decomposition</link>
      <description><![CDATA[考虑以下 VAR 模型。
$A_0 y_t =\sum_{i=1}^{p} A_i y_{t-i} +\epsilon_t $
其中 $y_t =[oil_t, \pi^e_t, \pi_t ]$ 且 $\epsilon_t$ 是正交结构冲击向量。

以伴随形式定义上述方程。
$A_0 y_t =\sum_{i=1}^{p} A_i y_{t-i} +\epsilon_t $
$y_t =\sum_{i=1}^{p} A^{-1}_0A_i y_{t-i} +A^{-1}_0\epsilon_t $
$X_t =\Lambda X_{t-1}+v_t$
设 $E(v_t&#39; v_t)=\Omega$ , $\tilde{A_0^{-1}}=chol(\Omega)$ 和 $e_j$ 为行向量，第 $j$ 个元素为 1，其他元素为 0。
然后脉冲响应函数变量 $j$ 至 $10\%$ 水平石油冲击 $k$，$\Psi_j^k$ 为
$\Psi_j^k=e_j \Lambda^k \xi$
其中 $\xi=\frac{0.1 \times \tilde{A_0^{-1}}e_1&#39; }{e_1 \tilde{A_0^{-1}} e_1&#39;}$
我跟进了这一点：变量 $j$ 水平的脉冲响应 $k$ = $ e_j \Lambda^k$
但仍然无法理解如何解释 $\xi$ 的分子和分母。
$\tilde{A_0^{-1}}=chol(\Omega)$ 所以 $\Omega = \tilde{A_0^{-1}}\tilde{A_0^{-1}}&#39;$,
那么如果我们想从 var-cov 矩阵中得到导数，我们不应该使用 $\Omega$ 矩阵吗？
为什么 $\xi$ 使用 $\tilde{A_0^{-1}}$?]]></description>
      <guid>https://stats.stackexchange.com/questions/656709/impulse-response-function-with-cholesky-decomposition</guid>
      <pubDate>Mon, 04 Nov 2024 07:54:45 GMT</pubDate>
    </item>
    <item>
      <title>模拟和测试 MAR 缺失数据机制 - 检查我的逻辑</title>
      <link>https://stats.stackexchange.com/questions/656708/simulating-and-testing-mar-missing-data-mechanism-check-my-logic</link>
      <description><![CDATA[我想展示随机数据缺失的情况，因此我尝试模拟一些数据，并展示如何从理论上对其进行测试。我想检查：

我的模拟是合理的。
我测试 MAR 以及 MAR 类别内的 MCAR 的逻辑也是合理的。

任何帮助都将不胜感激。
library(tidyverse)
library(broom)

# 模拟
n &lt;- 1000 # 设置要模拟的观察结果数量
set.seed(1234) # 设置可重复性的种子
age &lt;- rnorm(n, 40, 10) # 生成年龄变量 - 平均值 = 40，标准差 = 10
sex &lt;- rbinom(n, 1, 0.5) # 生成性别变量 ~ 50% 女性 (0) 和 50% 男性 (1)

# 根据性别和年龄的附加效应从回归模型生成体重 - 平均而言，男性比女性重 5 公斤，年龄每增加一年，体重就会增加 3 公斤
# 因此，该模型并不现实 - 
# 当性别和年龄 = 0 时，体重 = 5，但由于假设体重随年龄线性增加，平均 70 岁女性体重为 215 公斤，男性体重为 220 公斤。年龄的二次函数更合适，但让我们保持简单...
体重 &lt;- 5 + 5 * 性别 + 3 * 年龄 + rnorm(n, 0, 1)

# 检查我们是否恢复了原始系数：
dat &lt;- data.frame(sex = sex, age = age, bodyweight = bodyweight)
summary(lm(bodyweight ~ age + sex , data = dat))

# 现在，让我们随机创建一些缺失值（其中体重的缺失值取决于性别）
# 已选择模型截距和系数，因此男性的缺失概率约为 12%，女性的缺失概率约为 73%
logodds_missing &lt;- 1 - 3 * 性别
odds_missing &lt;- exp(logodds_missing)
prob_missing &lt;- odds_missing/(1 + odds_missing)
binary_missing &lt;- rbinom(n, 1, prob_missing)
dat &lt;- cbind(dat, odds_missing = odds_missing, prob_missing = prob_missing, binary_missing = binary_missing)

# 使用制表法检查
table(dat$prob, dat$binary_missing)
# 这差不多是对的
0.119*515 # 给出 61 名男性缺失
0.731*485 # 给出 354 名女性缺失

# 测试缺失与性别之间的关联 (MAR)
# 步骤 1 - 测试缺失是否取决于性别
mod_sex &lt;- glm(binary_missing ~ sex, data = dat, family = &quot;binomial&quot;)
broom::tidy(mod_sex, exp = T) # 即男性体重缺失的概率比女性低约 95%，这是很显著的
# 第 2 步 - 现在测试缺失是否取决于每个性别类别中的体重 - 即缺失在类别中是随机的 (MCAR)
mod_females &lt;- glm(binary_missing ~ bodyweight, data = subset(dat, sex == 0), family = &quot;binomial&quot;)
tidy(mod_females, exp = T) # 即女性的缺失不取决于体重
mod_males &lt;- glm(binary_missing ~ bodyweight, data = subset(dat, sex == 1), family = &quot;binomial&quot;)
tidy(mod_males, exp = T) # 即男性的缺失不取决于体重

# 测试缺失与年龄之间的关联 (MCAR)
mod_age &lt;- glm(binary_missing ~ age, data = dat, family = &quot;binomial&quot;)
tidy(mod_age, exp = T) # 即缺失值与年龄无关

附言：我理解缺失数据机制的测试潜力有限，因为如果测试结果为阳性，则可能是 MNAR 和 MAR；如果测试结果为阴性，则可能是 MNAR 和 MCAR，但我只是想检查我在当前情况下所做的事情是否正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/656708/simulating-and-testing-mar-missing-data-mechanism-check-my-logic</guid>
      <pubDate>Mon, 04 Nov 2024 07:50:29 GMT</pubDate>
    </item>
    <item>
      <title>我的 R 版本不支持 pairwiseAdonis 包。我可以用什么来代替？</title>
      <link>https://stats.stackexchange.com/questions/656705/my-r-version-wont-support-the-pairwiseadonis-package-what-can-i-use-instead</link>
      <description><![CDATA[我试图在 R 4.4.2 中运行成对 adonis 测试以跟进重要的 adonis2 测试（vegan 包），但我一直收到此消息：
 install.packages(&quot;pairwiseAdonis&quot;,dependencies=TRUE, repos=&#39;http://cran.rstudio.com/&#39;)
在‘C:/Users/.../AppData/Local/R/win-library/4.4’中安装包
（因为未指定‘lib’）
install.packages 中出现警告：
包‘pairwiseAdonis’不适用于此版本的 R

此包的适用于您的 R 版本的版本可能在其他地方可用，
检查
https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages

是否有其他包可以这个测试？如果不是，我可以使用哪个测试来代替成对的 adonis？
如果这不是提出这个问题的合适平台，请告诉我哪个平台合适。]]></description>
      <guid>https://stats.stackexchange.com/questions/656705/my-r-version-wont-support-the-pairwiseadonis-package-what-can-i-use-instead</guid>
      <pubDate>Mon, 04 Nov 2024 07:18:20 GMT</pubDate>
    </item>
    <item>
      <title>线性回归中R^2与样本大小的关系</title>
      <link>https://stats.stackexchange.com/questions/656706/relationship-between-r2-and-sample-size-in-linear-regression</link>
      <description><![CDATA[假设你有一个包含 100 个数据点的训练样本，并将其分成两个大小相同的子样本。你对每个子样本运行 OLS 回归，并且两个 R 平方 = 0.3。如果你对整个训练样本重新运行 OLS 回归，R^2 的范围是多少？
直观地讲，答案可能是 [0,0.3]。但是，如何严格证明这一点？虽然 SSE1&#39; 和 SSE2&#39; 不能小于 SSE1 和 SSE2，但我们也可以证明 SST&#39;≥SST1+SST2。]]></description>
      <guid>https://stats.stackexchange.com/questions/656706/relationship-between-r2-and-sample-size-in-linear-regression</guid>
      <pubDate>Mon, 04 Nov 2024 06:54:59 GMT</pubDate>
    </item>
    <item>
      <title>测量可能为正数或负数的数据的相关性和百分比回报</title>
      <link>https://stats.stackexchange.com/questions/656704/measuring-correlation-and-percentage-returns-for-data-that-can-go-both-positive</link>
      <description><![CDATA[我试图测量两个随机变量 $X$ 和 $Y$ 之间的相关性。$X$ 是股票的当前头寸，其中 $X&gt;0$ 为多头（买入），$X&lt;0$ 为空头（卖出）。$Y$ 是股票的价格。
通常，要测量两只股票之间的相关性，您需要计算每只股票的百分比回报率（或对数回报率）并测量相关性 $\rho(r_X, r_Y)$。但在我的案例中，问题是 $X$ 是可能为负数甚至为 0 的位置。
出现的问题是，如果 $t$ 的位置为 $X_t=10$，然后卖空 15 只股票，$X_{t+1}=-5$，则收益将是 $$r_X=\frac{-5+10}{10}=\frac{1}{2}$$
我想，您可以使用该方法
$$r_X=-\frac{|-5|+|10|}{10}=-\frac{3}{2}$$
如果当前位置从未达到 0，则这在某种程度上有效。
$$r_X=-\frac{|-5|+|0|}{0}=\text{not used}$$
或一个小数字：
$$r_X=\frac{|10|+|0.001|}{0.001}=10,001$$
我开始认为百分比变化在这种情况下甚至没有用，因为百分比回报都是关于参考点的，从 2 到 4 与从 10 到 20 不一样（第二个是更大的移动数据集）。因此，最好使用头寸和股票收益的差异来计算相关性：
$$d_{X_{t+1}} = X_{t+1} - X_t$$
$$r_{Y_{t+1}} = \frac{Y_{t+1} - Y_t}{Y_t}$$
$$\rho(d_{X_{t+1}}, r_{Y_{t+1}})$$]]></description>
      <guid>https://stats.stackexchange.com/questions/656704/measuring-correlation-and-percentage-returns-for-data-that-can-go-both-positive</guid>
      <pubDate>Mon, 04 Nov 2024 05:16:38 GMT</pubDate>
    </item>
    <item>
      <title>二项式（logit 链接）模型的条件边际效应：是否存在正确的估计技术？</title>
      <link>https://stats.stackexchange.com/questions/656673/conditional-marginal-effects-from-binomial-logit-link-models-is-there-a-corre</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/656673/conditional-marginal-effects-from-binomial-logit-link-models-is-there-a-corre</guid>
      <pubDate>Sun, 03 Nov 2024 15:46:37 GMT</pubDate>
    </item>
    </channel>
</rss>