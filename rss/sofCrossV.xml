<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 17 Oct 2024 01:15:31 GMT</lastBuildDate>
    <item>
      <title>如何表明计数与每次计数的不同持续时间无关？</title>
      <link>https://stats.stackexchange.com/questions/655875/how-to-show-that-counts-are-not-associated-with-the-different-durations-over-whi</link>
      <description><![CDATA[科学背景
有一篇出版物[1] 包含相关数据：Zenodo，GitHub。Zenodo 数据缺少两列，而 GitHub 数据缺少几行。
该出版物/数据来自一项关于微塑料对沙蟹影响的实验。 64 只螃蟹被放在单独的罐子里，其中 32 只每四天在水中加入三根微塑料纤维，最多 71 天。
最后计算每只螃蟹体内（我想也包括螃蟹身上）的微塑料纤维数量（在 71 天之前死亡的螃蟹被冷冻）。这在线性混合效应模型中用作固定效应，称为“内化纤维数量”。
科学问题
“内化纤维数量”这个名称似乎不对。如果纤维被摄入然后排出怎么办？生存时间与纤维计数的图表没有显示出太多的关系：

问题
有什么方法可以表明计数与计数累积的不同持续时间之间存在/不存在显着关联？
我的尝试
模型
我在 R 中拟合了以下 GLM（名称根据 Zenodo 数据修改，txs = 治疗螃蟹的一半数据):
glm(num_of_Yellow_fibers_ingested ~ log(num_of_days_alive) + 1, family = poisson(), data = txs)
使用 summary() 得出的结果：



param
估计
标准差。错误
z 值
Pr(&gt;|z|)




(截距)
0.87576
0.69172
1.266
0.205


log(num_of_days_alive)
-0.07686
0.18669
-0.412
0.681



我将其解释为“不，没有太多由于估计值较小、标准误差较大以及 log(num_of_days_alive) 的 Pr() 较小，因此“计数与计数累积的不同持续时间之间的关联”。
我的理由
泊松结果听起来很合适，因为它是计数数据。光纤数量是有上限的，但我没有更好的主意。
我怀疑我可能只对这些数据使用了 lm(counts ~ time)，看看上面的图。
我使用 log(time) 作为预测因子，因为我读到这样做可以让你结合不同曝光时间的数据，系数表示速率随时间的变化。
相关代数：
$$ y \sim Poisson(\lambda)$$
$$\lambda = \mu/\tau$$
$$log(\lambda) = log(\mu/\tau)$$
$$log(\lambda) = log(\mu) - log(\tau) = \alpha + \beta*x$$
$$log(\mu) = log(\tau) + \alpha + \beta*x$$
其中 $\mu$ = 预期事件数，$\tau$ = 时间。
参考文献
[1] &quot;环境相关浓度的微塑料纤维对太平洋鼹鼠蟹 (Emerita analoga) 死亡率和繁殖的影响。&quot; Horn DA；Granek EF；Steele CL。2019 年。]]></description>
      <guid>https://stats.stackexchange.com/questions/655875/how-to-show-that-counts-are-not-associated-with-the-different-durations-over-whi</guid>
      <pubDate>Wed, 16 Oct 2024 23:50:23 GMT</pubDate>
    </item>
    <item>
      <title>对具有不断变化的协变量的多年研究中的个体进行调整率建模</title>
      <link>https://stats.stackexchange.com/questions/655872/modeling-adjusted-rates-for-individuals-in-multi-year-studies-with-changing-cova</link>
      <description><![CDATA[我试图估计一个人在多年研究期间至少离开公司一次的概率。我的数据按每行中的个人-公司-年份组合进行组织，二进制结果 1 或 0 表示该个人是否在当年离开该公司。个人可以在一年内与多家公司有关联，也可以只与一家公司有关联，并且他们可能在每一年中与不一家公司、一家公司或多家公司分离。
我想计算不同协变量子组（例如，在农村公司工作的个人或 22-34 岁的人）的调整后离职率。我创建了一个二元结果，表示一个人是否至少离职一次 (separation_once)，但这会导致非离职期间的协变量被错误归因于离职事件（即，如果一个人从农村公司离职，但没有从城市公司离职，他们仍然至少离职一次，因此城市公司将与离职相关联）。
我认识到，计算每个协变量子组（例如农村公司或年龄 22-34 岁）的调整率的目标与估计一个人在研究期间至少离开公司一次的概率并不完全相同。但是，我需要确保模型考虑到同一个体的多个观察结果并不独立的事实，所以我认为我可以使用广义估计方程 (GEE) 计算每个个体的调整率，然后对子组中所有个体的调整率进行平均。
有人知道我可以使用哪种模型来计算每个子组的调整率吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655872/modeling-adjusted-rates-for-individuals-in-multi-year-studies-with-changing-cova</guid>
      <pubDate>Wed, 16 Oct 2024 19:58:00 GMT</pubDate>
    </item>
    <item>
      <title>使用具有交互作用的分层 GAM</title>
      <link>https://stats.stackexchange.com/questions/655866/using-hierarchical-gams-with-interactions</link>
      <description><![CDATA[我尝试使用广义加性模型来了解不同浮游动物分类群的季节性周期如何响应气候异常。我想指定一个模型，其中每个分类群（n = 9）都有一个季节性周期，该周期会随气候变量和一年中的时间而变化。有些分类群不常被观察到，所以我想使用“全局趋势”来帮助对这些不常被观察到的分类群进行平滑拟合。气候变量是特定年份的值（每年测量一次）。每年从约 20 个湖泊测量浮游动物约 6 次。我的模型是
single.model.zoo &lt;- gam(count ~ group + 
s(julian_day, Climate_anomaly, m = 2) + 
s(julian_day, Climate_anomaly, by = group, bs = &quot;tp&quot;, m = 1) +
s(lake_id, bs = &quot;re&quot;) + 
s(year_f, bs = &quot;re&quot;),
family = tw(link=&quot;log&quot;),
method = &quot;REML&quot;, 
data = long)

这个模型是否按照我的想法运行？我结合了 Pedersen et al. 2019 中的几种方法，但我不确定这是否是创建此模型的正确方法。如能得到任何帮助，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/655866/using-hierarchical-gams-with-interactions</guid>
      <pubDate>Wed, 16 Oct 2024 16:50:39 GMT</pubDate>
    </item>
    <item>
      <title>评估多种应用上的无监督算法的方法？</title>
      <link>https://stats.stackexchange.com/questions/655865/methods-to-evaluate-unsupervised-algorithms-over-multiple-applications</link>
      <description><![CDATA[我在数据集 ${X_i}$ 上使用聚类算法 $A_{\mathbf{\theta}}$，超参数为 $\mathbf{\theta}$。即，对于 $X_0, X_1, X_2 \ldots$ 中的每一个，我应用 $A_\mathbf{\theta}$，并在该数据集上获得聚类。我知道有许多指标可用于评估单个数据集上的聚类质量。是否有特别适合评估多个数据集上的模型的指标？一种简单的方法可能是为单个数据集选择一个任意指标，然后对所有数据集进行聚合（总和/平均值/最小值）。还有其他指标可以考虑我的超参数的重复使用和在多个数据集上的模型选择吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655865/methods-to-evaluate-unsupervised-algorithms-over-multiple-applications</guid>
      <pubDate>Wed, 16 Oct 2024 15:44:21 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归无法生成分类协变量的系数</title>
      <link>https://stats.stackexchange.com/questions/655856/logistic-regression-failing-to-generate-coefficents-for-categorical-covariate</link>
      <description><![CDATA[我有一个二元目标变量，表示新销售机会的产生 (1) 或产生失败 (0)。机会可能恰好在前 60 天内有营销接触点 (mkt_flag=1)，也可能没有营销接触点 (0)。营销接触点自其日期起最多 60 天内可以“有效”地产生机会。这意味着我们可以有以下目标变量和预测变量组合：机会是 + 市场是。机会否 + 市场是。机会是 + 市场否。但是：有机会否 + 市场否的记录。频率表如下：
。
但是，当尝试在 SAS 中对包括 MKT 标志变量的机会目标进行建模时，我得到的 mkt 标志变量的估计值为“0”，这可能是由于 mkt 变量在目标上的分布。对于这种不平衡协变量分布的情况，有什么想法可以建模吗？目的是估计 mkt 标志变量与 opp 目标的关联。]]></description>
      <guid>https://stats.stackexchange.com/questions/655856/logistic-regression-failing-to-generate-coefficents-for-categorical-covariate</guid>
      <pubDate>Wed, 16 Oct 2024 11:54:20 GMT</pubDate>
    </item>
    <item>
      <title>对照组</title>
      <link>https://stats.stackexchange.com/questions/655838/control-and-comparison-group</link>
      <description><![CDATA[请原谅我的无知。我正在分析 5+7+2 =14 个研究队列的数据。每个队列的受试者数量不同。队列 1 有 35 名受试者，队列 2 有 47 名受试者，等等……
研究持续时间为 2000 年至 2004 年。
每个队列在不同时期贡献数据或参与研究。下面的图表大致显示了 2000 年至 2004 年期间每个队列贡献数据的持续时间。2002 年是干预期。单一干预。
我的问题是，

哪些队列是“控制”队列，
哪些队列是“比较”队列。

队列是仅在之前（蓝色）还是仅在之后（红色）、5 + 2、7 个队列、控制队列 提供数据？
那么在 2002 年之前和之后都提供数据的队列呢？它们是比较群组吗？7 个群组为绿色？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655838/control-and-comparison-group</guid>
      <pubDate>Wed, 16 Oct 2024 03:44:38 GMT</pubDate>
    </item>
    <item>
      <title>我对 t 检验和单尾检验有两种不同的表述</title>
      <link>https://stats.stackexchange.com/questions/655796/i-have-two-different-statements-for-the-t-test-and-the-single-tail-test</link>
      <description><![CDATA[我想检查一个组 (ct2) 的值是否大于 ct1 的值。为此，我应用了 T 检验，结果如下。
t = 5.194，df = 1.6778，p 值 = 0.05009
备选假设：均值的真实差异不等于 0
95% 置信区间：
-0.001132843 1.961132843
样本估计值：
x 的均值 y 的均值
2.10 1.12

我已将显著性水平 (alpha) 指定为 0.05。由于结果 p 值 = 0.05009 高于 0.05，根据 t 检验，均值的变化不应归类为显著。
但是，我已经在单尾检验中测试了这个样本，正如您在图中看到的，t 检验大于临界值！这表明零假设被拒绝，并且发生了变化。矛盾的说法怎么会出现？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655796/i-have-two-different-statements-for-the-t-test-and-the-single-tail-test</guid>
      <pubDate>Tue, 15 Oct 2024 09:58:49 GMT</pubDate>
    </item>
    <item>
      <title>正态分布中的 $\mathbb E[M\times\sum{X_i}]$ 是什么，其中 $M$ 是样本中位数？</title>
      <link>https://stats.stackexchange.com/questions/655794/what-is-mathbb-em-times-sumx-i-in-normal-distribution-m-being-the-samp</link>
      <description><![CDATA[给定 $X_{1},\ldots,X_{n}$ 标准正态分布的 iid 样本，设 $M=M(X_1,\ldots,X_n)$ 为该样本的中位数。$$\mathbb E\left[M(X_1,\ldots,X_n)\times\sum_{i=1}^n{X_i}\right]$$ 的值是多少]]></description>
      <guid>https://stats.stackexchange.com/questions/655794/what-is-mathbb-em-times-sumx-i-in-normal-distribution-m-being-the-samp</guid>
      <pubDate>Tue, 15 Oct 2024 09:25:52 GMT</pubDate>
    </item>
    <item>
      <title>神经元相关分析中 KS 检验结果与 CDF 可视化结果之间的差异</title>
      <link>https://stats.stackexchange.com/questions/655753/discrepancy-between-ks-test-results-and-cdf-visualizations-in-neuronal-correlati</link>
      <description><![CDATA[神经元相关性分析中 KS 测试结果与 CDF 可视化之间的差异
我正在分析对一组在不同日期测量的神经元成对计算的皮尔逊相关系数 (PCC) 值，然后重点关注我们可以称为“细胞 X”的子集。我的目标是确定这些 Cells X 是否表现出比其他神经元更高的 PCC 值。
方法论：

PCC 计算：我计算了所有神经元对的 PCC 值。
CDF 绘图：我绘制了 Cells X 和其余神经元的 PCC 值的累积分布函数 (CDF)，以直观地比较它们的分布。
统计测试：我应用了 Kolmogorov-Smirnov (KS) 检验来评估两个分布之间是否存在显着差异。

观察：
虽然 KS 检验得出的 p 值非常小，表明分布之间存在显着差异，但对 CDF 图的目视检查表明分布几乎相同，这让我对这些结果的解释感到非常困惑。

问题：

KS 测试的敏感性：当视觉评估表明相似时，KS 测试是否通常会产生显着结果？是什么原因导致了这种差异？
替代方法：鉴于这种情况，您会推荐哪些替代统计方法或可视化来更准确地评估这两组之间的差异？

我很感激关于如何进行此分析的任何见解或建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/655753/discrepancy-between-ks-test-results-and-cdf-visualizations-in-neuronal-correlati</guid>
      <pubDate>Mon, 14 Oct 2024 12:42:24 GMT</pubDate>
    </item>
    <item>
      <title>使用蒙特卡洛方法求解积分的倒数</title>
      <link>https://stats.stackexchange.com/questions/655526/find-the-solution-to-the-reciprocal-of-an-integral-using-monte-carlo</link>
      <description><![CDATA[我正在寻找使用蒙特卡洛方法求解积分倒数的解决方案。我发现以下论文无偏蒙特卡洛积分倒数估计（作者：Thomas E. Booth）提供了一种解决方案。不过，我对此并不十分满意，因为：

需要代理函数（有点烦人）
结果需要无限序列，即使使用俄罗斯轮盘赌终止，也可能需要大量样本

为了更清楚地说明这一点，我不想先评估整个 mc 模拟，然后取倒数，每个 mc 样本都应该直接评估积分的倒数。
所以，我正在寻找类似以下问题的解决方案
$\frac{1}{\int_{0}^{1}{x^2dx}} = 3$
还有其他解决方案可以实现这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655526/find-the-solution-to-the-reciprocal-of-an-integral-using-monte-carlo</guid>
      <pubDate>Wed, 09 Oct 2024 11:24:45 GMT</pubDate>
    </item>
    <item>
      <title>brms 中的 Priors 并未按我预期的方式工作</title>
      <link>https://stats.stackexchange.com/questions/655043/priors-in-brms-are-not-working-as-i-expect</link>
      <description><![CDATA[我是贝叶斯统计的新手，我正在尝试使用 brms 拟合一个简单的线性回归，并手动为每个参数设置先验，但它并没有像我预期的那样工作
这是我的代码
data_2 &lt;- structure(list(YearsExperience = c(1.1, 1.3, 1.5, 2, 2.2, 2.9, 3, 3.2, 3.2, 3.7, 3.9, 4, 4, 4.1, 4.5, 4.9, 5.1, 5.3, 5.9, 6, 
6.8, 7.1, 7.9, 8.2, 8.7, 9, 9.5, 9.6, 10.3, 10.5), Salary = c(39343L, 
46205L, 37731L, 43525L, 39891L, 56642L, 60150L, 54445L, 64445L, 
57189L, 63218L, 55794L, 56957L, 57081L, 61111L, 67938L, 66029L, 
83088L, 81363L, 93940L, 91738L, 98273L, 101302L, 113812L, 109431L, 
105582L, 116969L, 112635L, 122391L, 121872L)), class = &quot;data.frame&quot;, row.names = c(NA, 
-30L))

priors &lt;- c(
set_prior(&quot;normal(28700, 2000)&quot;, class = &quot;Intercept&quot;),
set_prior(&quot;normal(9006, 1000)&quot;, class = &quot;b&quot;, 
coef = &quot;YearsExperience&quot;),
set_prior(&quot;normal(0, 2000)&quot;, class = &quot;sigma&quot;, lb = 0) 
)

fit_brms &lt;- brm(Salary ~ YearsExperience, data = data_2, Prior=priors)

但是，当我绘制链时，例如，当先验分布远离负值时进行截距。而且我设置的先验并非完全不准确。

如果我使用默认先验进行拟合，效果很好。]]></description>
      <guid>https://stats.stackexchange.com/questions/655043/priors-in-brms-are-not-working-as-i-expect</guid>
      <pubDate>Fri, 27 Sep 2024 21:16:13 GMT</pubDate>
    </item>
    <item>
      <title>R 中地球化学数据的 PCA [关闭]</title>
      <link>https://stats.stackexchange.com/questions/654347/pca-on-geochemical-data-in-r</link>
      <description><![CDATA[在我的理学学士论文中，我必须对从沉积物岩心的 XRF 测量中得出的元素值（以 % 为单位）进行 PCA。我的数据集包含 29 个变量（代表测量的元素）中的每一个的 155 个观测值/值。
之前，我对任何与统计/编码相关的知识几乎一无所知，但我设法掌握了 R(studio) 的基础知识，并且对我的 PCA 结果非常满意。PC 似乎很有意义，因为它们可以很容易地根据它们对可能的地球化学过程的指示进行解释。
然后我偶然发现了常数和约束，并意识到我的数据的成分性质可能会给结果带来问题。我的指导教授向我保证这不会有问题，因为“XRF 测量是针对每个元素独立计算的，因此不会缩放到 100%”并且“对每个元素进行标准化也会解决常数和约束，因为元素加起来不再是 100%”。我认为，从我的研究来看，问题不在于所有变量（元素）都有一个统一的常数和值，而在于 % 的相对性质 - 将数据限制在封闭空间的值。虽然他积极从事该领域的工作，使用这些工具，显然知识更渊博，但那个答案并没有真正解决我的担忧。我将我的数据归类为组合和封闭是否正确？
我花了整整两天时间寻找解决方案，并摆弄了 clr() 和 ilr() 等对数转换。我的数据中有许多 0 表示“低于检测限”，在执行这些转换之前，我将其替换为较小的值。虽然我了解每种转换的基本优缺点，但对这些问题的讨论都是以数学和复杂的术语进行的，因此我很难确定对于我的具体情况什么是必要的，什么是不必要的。感觉这个问题对于像我这样没有任何统计背景的人来说太复杂了。
当我对我的数据执行 clr() 时（用小值替换 0 后），得到的 PC 与原始数据的原始 PC 大不相同，这真的让我对未来感到焦虑，因为数据是我论文的基础。这些 PC 似乎也不允许任何明显的解释。这么大的差异是可以预料的吗？在我读过的论文中，通常看起来差异是显而易见的，但至少一些相关性仍然存在。
这个问题的“现代”但最困难的解决方案似乎是 ilr()，然后对转换后的数据执行 PCA，然后将结果转换回 clr 空间。这在 R 中对我来说不起作用（当然可以提供详细信息，如果这实际上是我应该寻求的解决方案）。
下一步将采取 2 个元素之间的比率（来自原始数据），这些比率可能作为古气候等的代理。如果我理解正确的话，即使如此，百分比值的相对性质也可能是一个问题？同样，我已经计算了 Ti/Al 比率并将它们与我拍摄的岩心记录图片进行了比较。同样，结果是有意义的（例如，比率响应的方式可以解释为指示温暖/寒冷的气候）。
任何帮助我重回正轨的意见都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654347/pca-on-geochemical-data-in-r</guid>
      <pubDate>Fri, 13 Sep 2024 23:04:55 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯回归中是否允许强制参数值之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/653877/is-forcing-correlation-between-parameter-values-allowed-in-bayesian-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/653877/is-forcing-correlation-between-parameter-values-allowed-in-bayesian-regression</guid>
      <pubDate>Wed, 04 Sep 2024 23:24:30 GMT</pubDate>
    </item>
    <item>
      <title>关于 Elo 评分系统的起源以及如何找到它</title>
      <link>https://stats.stackexchange.com/questions/619127/on-the-cradle-of-the-elo-rating-system-and-how-to-find-it</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/619127/on-the-cradle-of-the-elo-rating-system-and-how-to-find-it</guid>
      <pubDate>Mon, 19 Jun 2023 09:31:48 GMT</pubDate>
    </item>
    <item>
      <title>如何正确运行 adonis 或 anosim 测试？</title>
      <link>https://stats.stackexchange.com/questions/598497/how-to-appropriately-run-an-adonis-or-anosim-test</link>
      <description><![CDATA[我的微生物组数据结构如下：



患者 ID
治疗
响应




P1
前。
是。


P1。
后。
是。


P2。
前。
否。


P2。
后。
否。



我想查看的地方对药物治疗有反应和无反应的患者之间的微生物组差异。我有大约 $40$ 名患者。
我已使用 phyloseq 生成 Bray-Curtis 距离矩阵：
bray_dist = phyloseq::distance(physeq, method=&quot;bray&quot;)

我现在想使用该距离矩阵来测试对药物治疗有反应和无反应的患者之间的差异。我在想这个：
adonis(bray_dist ~ sample_data(physeq)$Response, distance = &quot;bray&quot;, strata = sample_data(physeq)$Treatment)

这是正确的做法吗？上面的方法会分别测试前后样本吗？
使用 anosim 或 adonis 执行此操作的正确方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/598497/how-to-appropriately-run-an-adonis-or-anosim-test</guid>
      <pubDate>Fri, 09 Dec 2022 03:45:49 GMT</pubDate>
    </item>
    </channel>
</rss>