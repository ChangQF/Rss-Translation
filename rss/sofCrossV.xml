<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Fri, 07 Mar 2025 06:27:38 GMT</lastBuildDate>
    <item>
      <title>引导程序适用于非线性功能？</title>
      <link>https://stats.stackexchange.com/questions/662304/does-the-bootstrap-work-for-non-linear-functions</link>
      <description><![CDATA[这是我对统计中基本的引导方法的理解：


我们有一个原始样本**： $ \ mathbf {x} =（x_1，x_2，...，x_n）$ 。。
一般而言，我们定义一个引导程序样本**： $ \ Mathbf {X}}^*=（x_1^*，x_2^*，...，...，x_n^*）$ 。
每个 $ x_i^*$ 是从原始样本中随机选择的，概率 $ \ frac {1} {n} {n} $    
原始估计值： $ \ hat {\ theta} = S（\ Mathbf {x}）$   
 bootstrap估算： $ \ hat {\ theta}^* = s（\ Mathbf {x}^*）$   
生成   $ b $  bootstrap样本并计算 $ \ hat {\ theta}^*_ 1，\ hat {\ hat {\ theta}
引导分布代表这些值的传播
平均值： $ \ bar {\ theta}^* = \ frac {1} {b} {b} \ sum_ {b = 1}^b \ hat {\ theta}
标准错误： $ se _ {\ hat {\ theta}} = \ sqrt {\ frac {\ frac {1} {b-1} {b-sum_} \ sum_ {b = 1} \ bar {\ theta}^*）^2} $  


我对以下几点感到困惑：有一个数学证明，表明随着样品数量的增加，Bootstrap方法估计会收敛到它们的真实价值（ https://www.stat.cmu.edu/~larry/=sml/boot.pdf ）。但这仅适用于线性函数？ 
 i可以观察到线性函数的以下内容。

 i将线性函数定义为： $ g（x）= ax + b $ 。使用詹森的
不等式：
  $$ g（e [x]）= a \ cdot e [x] + b $$   $$ e [g（x）] = e [ax + b]
 b $$   $$ g（e [x]）= e [g（x）] $$   
对于引导程序，我使用相同的线性函数： $ g（x）= ax + b $ 。
原始示例估计值为 $ \ hat {\ theta} = g（\ bar {x}）= a \ bar {x}
 + b $ 。 Bootstrap估计值为 $ \ hat {\ theta} _ {boot} = \ frac {1} {b} {b} \ sum_ {i = 1}^b g（\ bar {x}}^*_ I）$ 。通过操纵：
  $$ \ hat {\ theta} _ {boot} = \ frac {1} {b} {b} {b} \ sum_ {i = 1}
 a \ left（\ frac {1} {b} \ sum_ {i = 1}^b \ bar {x}^*_ i \ right） + b $$
任何引导程序的期望值等于原始样本
平均（在第三个方程中，LHS使用bootstrap样品，而
RHS就像使用原始）：
  $$ e [\ bar {x}^*] = \ bar {x} $$
  $$ e [\ hat {\ theta} _ {boot}] = a \ cdot e [\ bar {x}^*] + b = a \ bar {x} + b = a \ bar {x} + b =
 \ hat {\ theta} $$  
  $$ e [g（\ bar {x}^*）] = g（e [\ bar {x}^*]）$    

对于非线性情况

如果我采用二次函数： $ g（x）= x^2 $ ，原始示例
估计为 $ \ hat {\ theta} = g（\ bar {x}）=（\ bar {x}）^2 $ 
Bootstrap估算为 $ \ hat {\ theta} _ {boot} = \ frac {1} {b} {b} \ sum_ {i = 1}^b
 g（\ bar {x}^*_ i）= \ frac {1} {b} {b} \ sum_ {i = 1}^b（\ bar {x}}^*_ i）^2 $ 。。
使用Jensen的不平等用于此凸功能，我想我可以看到
引导程序偏见：
  $$ e [g（x）] \ geq G（e [x]）$$
 （\ bar {x}）^2 $$  
  $$ e [\ hat {\ theta} _ {boot}] = e \ left [\ frac {1} {b} {b} \ sum_ {i = 1}^b
 （\ bar {x}^*_ i）^2 \ right] = \ frac {1} {b} {b} \ sum_ {i = 1}^b e [（\ bar {x}^*_ i）^2]
 \ geq（\ bar {x}）^2 = \ hat {\ theta} $$  

 这意味着与非线性函数相比，Bootstrap方法对线性函数的效果更好。这是为什么存在诸如偏见校正的加速bootstrap方法以解决标准bootstrap的缺点？ 的原因是为什么]]></description>
      <guid>https://stats.stackexchange.com/questions/662304/does-the-bootstrap-work-for-non-linear-functions</guid>
      <pubDate>Fri, 07 Mar 2025 03:41:49 GMT</pubDate>
    </item>
    <item>
      <title>进行模拟时如何修改身份协方差矩阵？</title>
      <link>https://stats.stackexchange.com/questions/662303/how-to-modify-an-identity-covariance-matrix-when-conducting-a-simulation</link>
      <description><![CDATA[我正在两个假设和零假设之间进行统计检验，我有标准的多元高斯 $ n（0，i）$   - 我正在测试分布的变化。我想在替代假设中更改协方差矩阵，以使协方差条目并非全部为零。一个关键条件是我希望将方差条目保留为1。
将整个协方差矩阵更改为所有的协方差矩阵都太极端了，这使得测试太容易了。我想进行增量更改。是否有一种明智的方法可以从身份矩阵开始对协方差矩阵进行增量更改（这也使方差为1）？]]></description>
      <guid>https://stats.stackexchange.com/questions/662303/how-to-modify-an-identity-covariance-matrix-when-conducting-a-simulation</guid>
      <pubDate>Fri, 07 Mar 2025 03:04:52 GMT</pubDate>
    </item>
    <item>
      <title>是否有标准方法来构建随机矩阵的随机表示？</title>
      <link>https://stats.stackexchange.com/questions/662301/is-there-a-standard-method-to-construct-stochastic-representations-for-random-ma</link>
      <description><![CDATA[正如标题所说，我想知道如何构建已知分布的随机矩阵的随机表示。由于它可能不存在一种通用方法，因此我非常感谢与该主题有关的参考，这将使我能够更好地理解构建随机表示的过程。任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/662301/is-there-a-standard-method-to-construct-stochastic-representations-for-random-ma</guid>
      <pubDate>Thu, 06 Mar 2025 23:50:57 GMT</pubDate>
    </item>
    <item>
      <title>相关系数增加</title>
      <link>https://stats.stackexchange.com/questions/662300/multiplying-correlation-coefficients</link>
      <description><![CDATA[想象一下这样的场景：
  a  - ＆gt; b（a导致b）
c  - ＆gt; D（C导致D）
b＆lt;  - ＆gt; D（B和D呈正相关）
 
所以图将是这样的：
  b＆lt; -------＆gt; d
|          |
|          |
|          |
A c
 
是否可以通过它们之间的间接路径来解释A和C的观察到的相关性（这是不可预见的）（因此A-＆gt; b＆lt;  - ＆gt; d＆lt; d＆lt; -c）？在这种情况下，是 corr（a，b）*corr（b，c）*corr（c，d）一个很好的预测器？
我在路径分析中知道类似的事情。但这不是路径分析，主要是因为我认为该系统不遵守赖特的规则。但是我想知道我的推理是否正确，还是乘以相关系数是没有意义的。]]></description>
      <guid>https://stats.stackexchange.com/questions/662300/multiplying-correlation-coefficients</guid>
      <pubDate>Thu, 06 Mar 2025 23:44:52 GMT</pubDate>
    </item>
    <item>
      <title>确定样品是否由两组组成</title>
      <link>https://stats.stackexchange.com/questions/662298/determining-if-sample-is-composed-of-two-groups</link>
      <description><![CDATA[说我有一个数据集，其中每一行都由测试分数和测试准备水平组成。得分是整数范围从0到100，包括包含在内，测试准备水平是一个具有三个可能值的分类变量（无测试准备，完整的测试准备和未知的测试准备）。
我强烈怀疑，测试准备水平未知的小组由做准备的人和没有做准备的人组成。我将如何证明或证明这一点？我最初的倾向是比较未知准备组的平均值与其他两个组的平均值之间的百分比差异，但我不确定。
如果有帮助，我已经使用了两个样本 t   - 检验来表明无准备和全准备群体的平均值是不同的（相当明显的是；  $ t_&gt; $ t_ {calc} {calc} \ 37 $ 。]]></description>
      <guid>https://stats.stackexchange.com/questions/662298/determining-if-sample-is-composed-of-two-groups</guid>
      <pubDate>Thu, 06 Mar 2025 22:59:36 GMT</pubDate>
    </item>
    <item>
      <title>关于统计学家与应用中统计方法论假设的关系有什么讨论？</title>
      <link>https://stats.stackexchange.com/questions/662295/what-discussion-exists-regarding-statisticians-relationship-to-statistical-meth</link>
      <description><![CDATA[这更像是一个哲学问题，也是一个要求参考的问题。 To those who follow statistical academic literature, there are papers that discuss philosophical issues in statistical practice, such as the difference在统计实践中的解释和预测之间href =“ https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-33/issue-1/the-future-of-of-data-analysis/10.1214/aoms/aoms/aoms/aoms/aoms/aoms/177704711.1177704711.我想找到有关哪些关系统计学家必须假设统计方法的论文。
这是关于假设的民间智慧：如果数据或方法符合方法中理论描述中概述的假设，那就很棒了。如果没有，那并不意味着该方法将无法正常工作；它仍然可以使用，甚至可能比满足假设的方法更有用。 In fact, there are situations where an approximation based on large-sample arguments (and thus &quot;assumes&quot; large samples) seems to work very well regardless in small-sample situations, better than methods with met assumptions (specifically, &lt;a href=&quot;https://doi.org/10.1080/00031305.1998.10480550&quot; rel=&quot;nofollow Noreferrer“&gt; Wilson分数间隔似乎是比“ Agresti-Couli置信度间隔”的“ Agresti-Couli置信区间”更好的间隔。您还会听到统计学家说 $ t $   - 检验通常比非参数测试更好的数据范围更广泛，即使非参数测试使用的假设更易于满足。总而言之，在很多情况下似乎违反了假设，但一种方法仍然是“最好的”。根据“最好的”定义使用。据说，甚至还有一些论文试图评估具有相同数据集的假设推断，将使用“污染”进行。方法。
讨论此主题的好哲学型论文是什么？像上面描述的论文基本上是进行数值研究，以表明即使在数学上不能证明一种方法是最佳使用方法，但实际上，它是最佳使用方法。也就是说，他们吸引了某种经验论点。是否有论文在更广泛或更深的层面上讨论这种推理？]]></description>
      <guid>https://stats.stackexchange.com/questions/662295/what-discussion-exists-regarding-statisticians-relationship-to-statistical-meth</guid>
      <pubDate>Thu, 06 Mar 2025 21:34:23 GMT</pubDate>
    </item>
    <item>
      <title>在GLMMTMBβ-二元模型中设置先验</title>
      <link>https://stats.stackexchange.com/questions/662294/setting-priors-in-a-glmmtmb-beta-binomial-model</link>
      <description><![CDATA[我有一个响应变量的蜗牛消耗，这是一个比例（蜗牛死亡的数量/每介子的蜗牛总数）。我有一些使所有蜗牛死亡或没有死亡的整个治疗方法。我的模型如下：
  m3＆lt;  -  glmmtmb（snail_cumpumption〜处理，data = snail_surv2，family = betabinomial，strige = tocal）
 
当我使用Emmeans软件包探索事后比较时，所有0或1的治疗方法之间的某些比较是没有意义的。例如，我的实验中的治疗7没有捕食者，因此该治疗中所有重复的蜗牛死亡率为0。与用所有蜗牛死亡或大多数蜗牛复制的治疗相比（大约1s或接近1秒），事后测试表明它们没有差异。在图表上查看它们，尽管它们在相对的端，标准误差条没有几乎重叠的地方。因此，我认为该模型并未正确处理所有0或1的处理方法。即使模型运行时我没有警告，这是否表示模型分离？
尝试修复我认为正在持续的模型分离问题，我为我的模型设定了先验：：
  m3＆lt;  -  glmmtmb（消费〜处理，data = snail_surv2，family = betabinomial，重量=总计）
    
cprior＆lt;  -  data.frame（prior = rep（＆quot; normal（0,3）＆quot; 2），
                         class = rep（＆quot; fixef＆quot; 2），
                         coef = c（＆quot）;
 
M3＆lt;  - 更新（M3，Priors = CPRIOR）
 
我认为这不是我的模型问题的正确先验，因为我仍然存在相同的事后问题（我从priors glmmtmb vignette中获得了此先前的代码（ https://cran.r-project.org/web/packages/glmmtmb/vignettes/priors.html ）。
我的事后问题持续存在的事实是否意味着我的先验代码对我的模型无法正常工作，或者设置先验不是解决此问题的正确方法（如果不是，您是否可以指出我可以指出另一种可能的方法）？如果先验是解决模型问题的正确方法，是否有更好的设置？]]></description>
      <guid>https://stats.stackexchange.com/questions/662294/setting-priors-in-a-glmmtmb-beta-binomial-model</guid>
      <pubDate>Thu, 06 Mar 2025 21:20:54 GMT</pubDate>
    </item>
    <item>
      <title>有关时间序列分析中定义的AIC/BIC的问题及其通过Shumway和Stoffer的应用</title>
      <link>https://stats.stackexchange.com/questions/662293/question-about-aic-bic-as-defined-in-time-series-analysis-and-its-applications-b</link>
      <description><![CDATA[在本书的第五版中，它们将AIC，AICC和BIC定义为：
  $ \ Mathrm {aic} = \ log \ hat {\ sigma} _k^2+\ frac {n+2 k} {n+2 k} {n}
  $ \ Mathrm {aicc} = \ log \ hat {\ sigma} _k^2+\ frac {n+k} {n-k-2} {n-k-2} $   
  $ \ Mathrm {bic} = \ log \ hat {\ sigma} _k^2+\ frac {k \ log n} {n} {n}
 BIC公式似乎与我一直在检查的其他来源一致。但是AIC似乎包括一个额外的术语“ n n＆quot”在惩罚的分子上，AICC似乎与其他地方有很大不同。
我缺少某些东西还是这些真正的错别字/错误？
编辑：我认为应该定义AIC/AICC的方式是：
  $ \ Mathrm {aic} = \ log \ hat {\ sigma} _k^2 + \ frac {2k} {2k} {n}
  $ \ Mathrm {aicc} = \ log \ hat {\ sigma} _k^2 + \ frac {2k（n-k）} {n（n-k-k-1）]]></description>
      <guid>https://stats.stackexchange.com/questions/662293/question-about-aic-bic-as-defined-in-time-series-analysis-and-its-applications-b</guid>
      <pubDate>Thu, 06 Mar 2025 21:06:52 GMT</pubDate>
    </item>
    <item>
      <title>关于时间序列的统一弱法律条件的问题</title>
      <link>https://stats.stackexchange.com/questions/662292/question-about-a-condition-for-the-uniform-weak-law-of-large-numbers-for-time-se</link>
      <description><![CDATA[ 我的设置：在“案例“）为依赖观察值（即时间序列）提供了大数均匀弱法（UWLLN）的有效性的条件。条件（iv）的条件之一指出：对于所有 $ \ theta_1，\ theta_2 \ in \ theta $  in \ theta $ ，有一个函数 \ begin {align}
（a）＆amp; \ quad | q_t（w_t，\ theta_1）-q_t（w_t，\ theta_2）| \ leq c_t（w_t）|| \ theta_1- \ theta_2 ||
\\
（b）＆amp; \ quad \ {c_t（w_t）\} _ t \ quad \ text {满足通常的wlln}。
\ end {align} 
其中

  $ \ theta $ 是紧凑的参数空间
  $ w_t $ 是载体，其中包含时间点的观察值 $ t $ ， $ w_t $ w_t $   $ W_1 =（X_1）$ ， $ W_2 =（x_1，x_2）$ 。这与具有远距离内存的模型相关，例如ma  $（q）$  -model。
  $ Q_T $ 是时间点 $ t $ ，例如。在时间点观察的可能性 $ t $ 。请注意：这不是总的可能性，只是在时间点上评估的单变量密度 $ t $ 。

 我的困惑：我想知道条件 $（a）$  and  $（b）$（b）$ 不仅会自动实现 $ q_t $ qu_t $  contance conter class =“ Math-Container”&gt; $ \ theta $ ？证明IDEA如下：因为 $ q_t $ 在 $ \ theta $ 和 $ \ theta $ span&gt; clast clast clast clast clast clast clast clast  $ q_T $ 是Lipschitz-continuule（以下来自 $ \ theta_1，\ theta_2 \ in \ theta $ ，有 $ k＆gt; 0 $ k＆gt; 0 $ 
 \ begin {align}
| q_t（w_t，\ theta_1）-q_t（w_t，\ theta_2）| \ leq k || \ theta_1- \ theta_2 ||
\ end {align} 
设置 $ c_t（w_t）$ 从条件 $（a）$（a）$（a）$  $ c_t（w_t） class =“ Math-Container”&gt; $ K $ 是确定性的，它也可以满足WLLN。 （严格地说，我应该写 $ k_t $ 而不是 $ k $ ，但是我只能选择 $ k = $ k = \ max_t k_t k_t $ 。
 我的问题：我缺少什么吗？我之所以问这个，是因为在原始论文中，提出了使用均值定理的建议。然后 $ c_t $ 是 $ \ theta $ ）的函数。我不明白为什么在论文中给出建议，而不是使用平滑度。特别是，因为定理下面有以下语句：
 ;因为大多数时间序列应用程序都涉及光滑的客观功能，因此应用定理4.2通常在于验证 $ \ {q_t（w_t，\ theta，\ theta）任何 $ \ theta \ in \ theta $ 。  
，但从它自动遵循的平滑度， $ c_t $ 可以选择为恒定，可以满足wlln。当然，必须检查 $ q_t $ 的wlln，这是定理中的另一个条件，当然必须检查。所以我想我缺少一些东西，但我不知道那是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/662292/question-about-a-condition-for-the-uniform-weak-law-of-large-numbers-for-time-se</guid>
      <pubDate>Thu, 06 Mar 2025 20:55:28 GMT</pubDate>
    </item>
    <item>
      <title>为什么跳过连接会导致神经网络中的损失景观极平滑？</title>
      <link>https://stats.stackexchange.com/questions/662291/why-do-skip-connections-cause-drastically-smoother-loss-landscapes-in-neural-net</link>
      <description><![CDATA[我正在阅读论文;由Hao Li等人。在本文中，作者使用过滤器归一化的随机方向可视化神经网络的损失景观。他们突出的一个引人注目的观察是如何极大地跳过​​连接（如在重新设备中）改善损失表面的平滑度：

“通过我们的可视化揭示的一个有趣的属性是，与没有跳过连接的网络相比，剩余网络产生的更平滑，凸丢失表面更多。＆quot“ 

我了解可视化这些表面的机制（将核心归一化的内核，创建随机方向等）。但是作者没有继续并为通过其方法获得的改进提供解释。
没有跳过连接，神经网络近似一些复杂的函数 $ f（x）$ 。但是有了跳过连接，该网络近似 $ f（x） + x $ ，如下所示：
    
作者出现的可视化清楚地显示了存在跳过连接时更平滑的景观：
   我的混乱是： 
为什么近似 $ f（x） + x $ （而不是直接近似 $ f（x）$ ）创建了一个非常更加更加更加更加更加更加更加更加更加更加顺畅，更简单的损失景观？这种巨大差异背后是否有直观的解释或数学推理？
 参考： 

 Hao Li，Zheng Xu，Gavin Taylor，Christoph Studer和Tom Goldstein。 ＆quot; 可视化神经网的损失景观。 神经信息处理系统的进步（Neurips），2018年。
]]></description>
      <guid>https://stats.stackexchange.com/questions/662291/why-do-skip-connections-cause-drastically-smoother-loss-landscapes-in-neural-net</guid>
      <pubDate>Thu, 06 Mar 2025 20:37:50 GMT</pubDate>
    </item>
    <item>
      <title>评估替代损失功能</title>
      <link>https://stats.stackexchange.com/questions/662289/evaluation-of-surrogate-loss-functions</link>
      <description><![CDATA[假设我们观察数据 $ x \ sim \ Mathcal {X}，y \ sim \ Mathcal {y} $  ，我们希望优化一些 martric   $ m：\ mathcal} \ Mathbb {r} $ 。
但是，该指标可能很难直接和任意地进行优化。在实践中，我们可能会使用替代损耗函数  $ l：\ nathcal {y} \ times \ times \ mathbb {r} \ to \ mathbb {r {r} $  $ l $ 应该类似于最小化 $ m $ 。。

例如：在二进制分类中（ $ \ mathcal {y} = \ { -  { -  1，1，1 \} $ ），我们可能有兴趣最小化由 $$ m（y，\ hat ^ y hat {y hat {y} y y span class =“ \ Mathbf {1} \ {sgn（\ hat {y}）\ neq y \} $$ 
众所周知的替代损失是SVM中使用的所谓铰链损失：
 $$ l（y，\ hat {y}）= \ max（1- \ hat {y}，0）$$ 
这是凸。其他损失包括二进制跨凝结，指数等。

现在我的问题如下。给定具有特定数据集的兴趣指标 $ m $ ，以及几种可能的替代损失 $ l_1，l_2，l_3，l_3，\ dots $ ，有一种评估的好方法class =“ Math-Container”&gt; $ M $ ＆quot？换句话说，我想确定“适合性”。  $ l_k $ 作为 $ m $ 的替代损失。正式的理论论点，合理的启发式方法或对论文的参考都受到了极大的欢迎。
我的想法是生成 $ \ hat {y} \ in \ mathbb {r} $ 的随机数，然后查看 $ l_k $  $ l_k $  和 $ L_K $ 是 $ M $ 的合理代理。这个想法可能有一些局限性/问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/662289/evaluation-of-surrogate-loss-functions</guid>
      <pubDate>Thu, 06 Mar 2025 19:47:54 GMT</pubDate>
    </item>
    <item>
      <title>仅在模型中包括一些协变量来回答一个研究问题，或者包括许多协变量来回答许多问题？</title>
      <link>https://stats.stackexchange.com/questions/662285/only-include-a-few-covariates-in-a-model-to-answer-a-single-research-question-o</link>
      <description><![CDATA[我一直在遵循dimitris rizopoulos的混合建模方法（ noreflow noreferrer“&gt; link ）用于时间的longitinal longitinal longitinal carnaine longitinal carbon 这是演示文稿中的过程dimitris概述：

考虑到可能
它们之间的非线性术语和/或相互作用 - 请勿删除这些条款和/或
这不是显着的
然后选择适当描述的适当随机效应结构
重复测量的相关性
最后，返回平均零件并排除非重要协变量

我现在的研究问题是：每个地点的累积年平均温度和降水是否会影响该地点估计碳的模型偏差？
要回答这个问题，我想出了以下模型：
  lme（data =加入，
    固定=偏见〜年度_meantemp_cum + younal_precip_cum +年龄，
    随机=〜时间段| nfi_plot）
 
但是，根据Dimitris的建议，我不确定是否还应包括与我的下一个研究问题相关的所有协变量：温度和降水极端是否会影响该站点估算碳的模型偏见？
在这种情况下，我可能会添加协变量 mintemp_coldest_qtr + maxtemp_warmest_qtr + steac_driest_qtr + steac_driest_qtr + steac_driest_qtr 。
所以我的问题是：您应该停止在模型中添加协变量，而是创建一个新的研究问题的哲学限制是什么？我什至应该首先将降水量和温度集中在一起，还是应该是两个单独的研究问题（和两个单独的模型）？]]></description>
      <guid>https://stats.stackexchange.com/questions/662285/only-include-a-few-covariates-in-a-model-to-answer-a-single-research-question-o</guid>
      <pubDate>Thu, 06 Mar 2025 19:18:06 GMT</pubDate>
    </item>
    <item>
      <title>适当的符号和方法在模型中使用固定（已知）截距或预测变量进行OLS？</title>
      <link>https://stats.stackexchange.com/questions/662253/proper-notation-and-methods-to-perform-ols-with-fixed-known-beforehand-interce</link>
      <description><![CDATA[如何在诸如威尔金森（Wilkinson）的符号中表达，模型中的术语具有固定的值和错误，而不是回归中的变量，而是保持恒定的态度？例如，我可能想在模型 $ y_i = \ y_i = \ alpha + sum_j \ sum_j \ beta_j x_j x_ x_ x_ {ij} $  $ \ alpha $ 。或者，我可能想保持固定的预测变量 $ \ beta_k $ ，其价值和不确定性事先已知。欢迎有关如何执行此操作的建议，尤其是标准，推荐或常见的建议。  wilkinson符号似乎是为了描述拟合常规的输入，而不是为了拟合某些标准，我可能会符合某种标准，并且我可能不知道该标准，并且我是否有误解，并且我是不对劲的，我是不对的。固定。
一个相关的第二个问题：如何使用固定的某些术语来实现LS回归，例如，当截距或预测变量具有事先已知的值和相关错误时？如果确切知道截距（无错误），则该解决方案很简单，减去它并拟合 $ y_i&#39;= y_i- \ alpha $ 。但这是不确定的，这是不合适的。同样，对于先验价值的协变量。这个问题包括使用哪种方法和哪种软件以常规方式实现。例如，MATLAB  lmfit 似乎不允许这样做。我正在研究 lsqlin ，但我不知道如何应用表达参数不确定的紧密约束（我想放宽了约束？）。我遇到了进行类似约束优化并实现贝叶斯方法的Python库，但这似乎比要求的要复杂得多。还是不可避免的复杂性？]]></description>
      <guid>https://stats.stackexchange.com/questions/662253/proper-notation-and-methods-to-perform-ols-with-fixed-known-beforehand-interce</guid>
      <pubDate>Thu, 06 Mar 2025 10:10:38 GMT</pubDate>
    </item>
    <item>
      <title>如何将分布的可能性与不同的传播进行比较？</title>
      <link>https://stats.stackexchange.com/questions/662250/how-to-compare-likelihood-of-distributions-with-different-spread</link>
      <description><![CDATA[当我们计算样品的可能性与分布相对于分布时，可能性数取决于分布的传播。
它使得直接不可能比较n个样品的可能性与n个分布的可能性：
 可能性（sample1，inter1）vs可能性（Sample1，distr1）... 。
如何使可能性数字标准化以使其可比？我们不知道发行的形式，它是经验的。
 简单示例：有两个正常分布，平均值= 0，sigma1 = 1，sigma2 = 2。我们从每个生成1000个样本，然后将可能性计算为：
  $均值（log（\ operatatorName {pdf}（x__ {i}）））。exp（）$ 。
我们将获得2个0.25和0.12的数字。这是不同的，即使我们知道“合适”在这两种情况下都是相同的。
一种可能的方法是通过乘以扩散（或sigma）将其归一化，对于正态分布，它似乎产生了近距离数字0.25和0.24。
我想知道这样的归一化程度有多好，是否有更好的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/662250/how-to-compare-likelihood-of-distributions-with-different-spread</guid>
      <pubDate>Thu, 06 Mar 2025 07:41:32 GMT</pubDate>
    </item>
    <item>
      <title>在部分相关分析中处理分类变量</title>
      <link>https://stats.stackexchange.com/questions/662090/handling-categorical-variables-in-partial-correlation-analysis</link>
      <description><![CDATA[我正在分析具有两个条件的实验的数据：野生型（WT）和突变基因型。每个基因型大约有25个样本。
对于每个样品，测量了〜15个基因和〜5代谢产物的表达。
目的是研究基因与代谢产物之间的关系，以及基因本身之间的关系。
但是，我注意到基因型之间的基因和代谢产物水平的主要差异。这意味着简单的相关分析将主要捕获基因型驱动的差异而不是真实的关联。
我遇到了部分相关（ ppcor :: pcor.test  in R），该在R）中计算两个变量之间的相关性，同时控制第三个变量（在这种情况下，基因型）。该方法可以应用于所有变量对，并在具有多测试校正的相关图中可视化。 Spearman的等级相关性（似乎是适当的选择）可以计算。
但是， ppcor 要求控制变量是数字的，而基因型为分类（WT/MUT）。
一种方法是将基因型编码为（0,1），但我不确定这种转换的含义。

 将基因型（WT，MUT）转换为（0,1）的统计后果是什么？？

 是否有任何有效性检查以确保此方法合适？

]]></description>
      <guid>https://stats.stackexchange.com/questions/662090/handling-categorical-variables-in-partial-correlation-analysis</guid>
      <pubDate>Mon, 03 Mar 2025 07:55:24 GMT</pubDate>
    </item>
    </channel>
</rss>