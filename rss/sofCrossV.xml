<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 10 Jan 2025 15:16:36 GMT</lastBuildDate>
    <item>
      <title>确保 Fisher 信息矩阵严格正定的条件</title>
      <link>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</link>
      <description><![CDATA[Fisher 信息矩阵定义为：
$$I(\theta):=E\left[\frac{\partial\log f(X;\theta)}{\partial \theta} \mid\theta\right]$$
其中 $f$ 是似然函数。
我正在寻找充分条件 - 最好是关于 $f$ 或 $\log f$ - 以确保 Fisher 矩阵严格正定。
正定性是证明最大似然估计量 (MLE) 渐近一致性的众所周知的临界条件。因此，这一探究具有重要意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</guid>
      <pubDate>Fri, 10 Jan 2025 14:33:43 GMT</pubDate>
    </item>
    <item>
      <title>同一研究中重叠复合终点估计率的相关性</title>
      <link>https://stats.stackexchange.com/questions/659823/correlation-of-estimated-rates-for-overlapping-composite-endpoints-from-the-same</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659823/correlation-of-estimated-rates-for-overlapping-composite-endpoints-from-the-same</guid>
      <pubDate>Fri, 10 Jan 2025 13:36:24 GMT</pubDate>
    </item>
    <item>
      <title>竞争风险情景中 Kaplan-Meier 估计的偏差</title>
      <link>https://stats.stackexchange.com/questions/659822/bias-in-kaplan-meier-estimate-in-competing-risk-scenario</link>
      <description><![CDATA[在阅读了其他地方的大量材料和这里的帖子后，我仍然无法完全理解为什么在竞争风险的情况下，基于 Kaplan-Meier 的累积风险估计（针对特定事件）通常被认为是“有偏差的”或“错误的”，并且累积发生率函数是首选。我理解，如果其他竞争事件（例如死亡和主要关注的事件）不是独立的（共享共同的预测因子），这可能是偏见的来源并影响估计的可解释性。然而，基于 KM 的估计原则上被认为是有偏差的，即使不同事件的发生不能用相同的预测因子来解释。
从 KM 得出的累积概率似乎反映了事件特定的风险，这可能比代表 CIF 所代表的各种影响的数量更有趣。例如，在 Covid 大流行期间，总体死亡率较高，因此竞争风险的负担更高，这将反映在 CIF 中。这似乎不是对事件特定风险负担非常有用的估计。]]></description>
      <guid>https://stats.stackexchange.com/questions/659822/bias-in-kaplan-meier-estimate-in-competing-risk-scenario</guid>
      <pubDate>Fri, 10 Jan 2025 12:42:05 GMT</pubDate>
    </item>
    <item>
      <title>对于 OLS 假设，随机样本是否需要 IID</title>
      <link>https://stats.stackexchange.com/questions/659821/does-random-sample-need-to-be-iid-for-ols-assumption</link>
      <description><![CDATA[假设要为 OLS 回归 创建样本，我分 2 个阶段 在不同的总体中抽样数据。例如，在一个总体中，我有 5000 个数据点，我从该总体中选择了 1000 个数据。而在另一个总体中，有 3000 个数据点，我从该总体中选择了 500 个数据。
然后我 组合 2 个抽样数据集（因此，组合数据集有 1500 个数据点），并构建横截面 OLS 回归。
我的问题是，在这种情况下，随机样本的 OLS 假设 是否得到满足？对于随机样本，我们是否需要数据为 IID？
在另一个抽样选项中，我有相同的 2 个数据总体。但是对于 1 个样本，我进行了 分层抽样，而对于另一个样本，我进行了 简单随机抽样。然后 合并 2 个抽样数据集。
在这种情况下，随机样本假设是否成立？
随机样本假设取自 Wooldridge 的计量经济学入门。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659821/does-random-sample-need-to-be-iid-for-ols-assumption</guid>
      <pubDate>Fri, 10 Jan 2025 11:50:05 GMT</pubDate>
    </item>
    <item>
      <title>二项式多层模型：如何“正确地”生成和解释响应尺度上的预测概率？</title>
      <link>https://stats.stackexchange.com/questions/659820/binomial-multi-level-model-how-to-correctly-generate-and-intepret-predicted-p</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659820/binomial-multi-level-model-how-to-correctly-generate-and-intepret-predicted-p</guid>
      <pubDate>Fri, 10 Jan 2025 11:43:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么因果参数不能提供最佳的预测性能？</title>
      <link>https://stats.stackexchange.com/questions/659818/why-causal-parameters-does-not-give-best-predictive-performance</link>
      <description><![CDATA[假设我们有一些协变量 $X$ 和目标 $Y$，它们来自线性因果模型。
我读到，估计因果参数可能会导致对测试数据的预测性能保守，而如果对测试数据的干预不是太极端，OLS 可能会提供更好的性能，因此我们通常更喜欢使用其他系数（如 OLS），这些系数与因果系数相比不那么保守。
但我不明白为什么会这样。如果我们知道因果模型（即生成数据的代理）的系数，为什么这些系数与来自“错误”模型（在某种意义上，它不是真正的底层模型）的其他一组系数相比表现不佳？我不明白这种直觉。]]></description>
      <guid>https://stats.stackexchange.com/questions/659818/why-causal-parameters-does-not-give-best-predictive-performance</guid>
      <pubDate>Fri, 10 Jan 2025 11:21:04 GMT</pubDate>
    </item>
    <item>
      <title>识别 PC 算法中的所有 v 结构</title>
      <link>https://stats.stackexchange.com/questions/659812/identifying-all-the-v-structures-in-the-pc-algorithm</link>
      <description><![CDATA[我对 PC 算法的最优性有一个简单的问题。
假设 PC 算法已经确定了图的骨架（即确定了所有边但没有确定它们的方向）。将此称为第 1 阶段。
据我了解，在第 1 阶段中删除边 (i,j) 的过程是选择一个条件集 C 并测试 $$X_i \perp\!\!\!\!\perp X_j | C.$$如果确认独立性，我们删除边并保存条件集 C。如果我们将 $Sep(X_i,X_j)$ 表示为满足此条件独立性的所有条件集的集合，我们可以说 $$C \in Sep(X_i,X_j)。$$ 然后我们继续处理其他边。
在第 2 阶段，我们开始通过识别 v 结构来定位边。假设 $$X-Y-Z$$ 形成一个 v 结构。如果我们保存的条件集 $C \in Sep(X,Z)$ 不包含 $Y$，则算法会识别它，因为这意味着没有依赖关系可以流经 Y。问题在于：我们只保存了我们遇到的 $Sep(X,Z)$ 中的第一个条件集，然后立即着手删除边。据我所知，这就是 PC 算法的重点：尽量减少我们必须进行的测试次数，并从小条件集开始。这是否意味着 $Sep(X,Z)$ 中还有其他我们不知道的集合？假设 $Y \in C$。难道不存在$C&#39;$，使得$Y \notin C&#39; \in Sep(X,Z)$，而这对我们来说是未知的，因此我们无法确定 v 结构的方向，尽管我们应该这样做？
如果我们实际上“缺少”v 结构，那么算法如何仍然是最优的，即恢复真实图的马尔可夫等价类？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659812/identifying-all-the-v-structures-in-the-pc-algorithm</guid>
      <pubDate>Fri, 10 Jan 2025 09:14:37 GMT</pubDate>
    </item>
    <item>
      <title>与夹层形式矩阵的 Frobenius 范数相关的不等式 [迁移]</title>
      <link>https://stats.stackexchange.com/questions/659811/inequality-related-to-the-frobenius-norm-of-sandwich-form-matrices</link>
      <description><![CDATA[我从一篇论文的证明中读到一个不等式。假设 $A, B, C, D$ 是矩阵，$\Vert \cdot \Vert$ 表示 Frobenius 范数，则 $\Vert A^{1/2}BA^{1/2} - C^{1/2}DC^{1/2} \Vert \lesssim \Vert B - D\Vert + \Vert A^{1/2} - C^{1/2}\Vert$。为什么这是正确的？]]></description>
      <guid>https://stats.stackexchange.com/questions/659811/inequality-related-to-the-frobenius-norm-of-sandwich-form-matrices</guid>
      <pubDate>Fri, 10 Jan 2025 08:41:47 GMT</pubDate>
    </item>
    <item>
      <title>21 世纪第一季度机器学习理论中最重要的成果是什么？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659810/what-are-the-most-important-results-in-machine-learning-theory-in-the-first-quar</link>
      <description><![CDATA[21 世纪已经过去了四分之一。在过去的 25 年里，机器学习取得了巨大的进步。很容易找到总结过去 25 年机器学习领域最重要成果的调查。然而，这些结果大多不是理论结果。
考虑到这一点，您认为 21 世纪第一季度机器学习理论领域最重要的成果是什么？以下是我提名的一些成果：

多臂老虎机的有限时间分析。由 [Auer et al., 2002] 发起的一系列研究（[Audibert and Bubeck, 2010]、[Zimmert and Seldin, 2018]）已使人们对多臂老虎机的有限时间行为有了几乎全面的了解。

在线优化领域的建立。由 [Zinkevich, 2003] 发起的一系列研究定义了基本问题（对抗性老虎机、在线凸优化）并建立了该领域的基本技术（在线次梯度下降、OMD、FTRL、FTPL...）。

差分隐私的概念。这一概念产生了一系列新问题和研究方向。特别有趣的是差异隐私、泛化和自适应数据分析之间的联系（[Dwork 等，2015]）。


这些是我提名的 21 世纪前 1/4 学习理论中最重要的结果。您认为还有哪些重要结果？我很想听听您的想法。]]></description>
      <guid>https://stats.stackexchange.com/questions/659810/what-are-the-most-important-results-in-machine-learning-theory-in-the-first-quar</guid>
      <pubDate>Fri, 10 Jan 2025 07:07:59 GMT</pubDate>
    </item>
    <item>
      <title>理解相关二元解释变量和分类结果的模型</title>
      <link>https://stats.stackexchange.com/questions/659809/models-for-understanding-correlated-binary-explanatory-variables-and-categorical</link>
      <description><![CDATA[给定一个由相关二元变量和分类结果组成的数据集，我的目标是了解结果如何依赖于二元变量。假设样本大小为 1e5 的数量级，特征数量为 1e2--1e3 的数量级。哪些模型或方法适合这种类型的分析？现实世界中的哪些数据集符合此描述？]]></description>
      <guid>https://stats.stackexchange.com/questions/659809/models-for-understanding-correlated-binary-explanatory-variables-and-categorical</guid>
      <pubDate>Fri, 10 Jan 2025 06:27:31 GMT</pubDate>
    </item>
    <item>
      <title>重复测量混合效应模型的设置</title>
      <link>https://stats.stackexchange.com/questions/659808/setup-for-mixed-effects-model-with-repeated-measures</link>
      <description><![CDATA[我正在开展一个项目，该项目涉及从参与者那里收集一些生物特征数据。以下是基本设置：

该研究共涉及 28 名参与者。
参与者被分为两组（“积极”组和“消极”组）。
每个参与者完成几项任务。任务有两种方法（“A”和“U”），每种方法都以多个方向（“左”、“上”、“右”）完成，并在每个方法/方向上重复多次试验。

我的研究问题是响应变量与以下内容有何关系：

组主效应
方法主效应
按方法分组交互效应

我想尝试使用线性混合模型方法来解决这些问题。我计划使用 R / lme4，但我也愿意接受其他方法。这是一个与我的结构相同的示例数据框：
set.seed(6538)

example_data &lt;-
tibble(
Participant = rep(rep(paste0(&quot;Subj&quot;, 1:28), each = 15), times = 2),
Direction = rep(rep(rep(c(&quot;Left&quot;, &quot;Up&quot;, &quot;Right&quot;), each = 5), times = 28), times = 2),
Trial = rep(1:5, times = 3*28*2),
Group = rep(rep(c(&quot;Positive&quot;, &quot;Negative&quot;), each = 210), times = 2),
Method = rep(c(&quot;A&quot;, &quot;U&quot;), each = 420),
Response = runif(840, 8, 12)
)

实际数据框中唯一的区别（除了随机响应数据）是一些参与者缺少第 4 次和第 5 次试验的数据。所有患者在每个方法和方向上至少有 3 次良好的试验。
在我看来：

参与者应该贡献随机效应
组、方法和方向都应该是固定效应
模型的合理开价可能是 lmer(Response ~ Group * Method + Direction + (1|Participant/Trial), data = example_data)

我有一些问题：

这看起来像是一个合理的开始吗？
通过以这种方式构建模型，我是否会放弃任何潜在的统计能力？
我还应该问自己哪些其他类型的问题指导我以不同的方式（或不）设置模型？
]]></description>
      <guid>https://stats.stackexchange.com/questions/659808/setup-for-mixed-effects-model-with-repeated-measures</guid>
      <pubDate>Fri, 10 Jan 2025 03:41:16 GMT</pubDate>
    </item>
    <item>
      <title>帮助决定哪种测试适合确定两个样本之间是否存在统计学上的显着差异[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659799/help-deciding-which-test-is-appropriate-for-determing-if-there-is-a-statisticall</link>
      <description><![CDATA[
编辑以下内容以进行澄清，也非常感谢您的意见。之前我一直在努力不让帖子太长而无法阅读*

我是一名学生，我的任务是建立一个模型，该模型根据患者的健康指标（包括血压、糖尿病、年龄、心率、BMI 等）预测慢性肾病的存在。
我有一个包含 3000 名患者的健康指标的数据集。
我相信这是课程模块为这个项目的目的而编造的数据。

在“清理”数据时，我注意到有几行在所有列中的参数都完全相同，甚至精确到小数点后一位。例如，患者 1 的性别、年龄、血压、心率、BMI、葡萄糖、胰岛素读数与患者 23、300、45、12 完全相同。或者患者 5 的指标与其他 4 个人的指标完全相同。
是的，我想知道是否是不同的人具有相同的指标，这是有可能的，但后来我可能开始想太多了。
我确信某些患者有重复/重复的值，因为正如我所说，它们完全相同，您会想知道这是否是多次 ppatient 输入

我想我会尝试变得聪明并删除我认为重复的数据。由此我提出了以下问题：
我想知道是否有一种方法可以证明删除它们不会对未来的分析和数据建模产生重大影响，方法是将旧数据中的变量均值和分布与重复数据和新清理数据进行比较。
最初，ChatGPT 和 Google 表示秩和检验中的 Wilcox 不成对 - 我认为这是有道理的，因为我的样本不是正态分布的并且不匹配 - 行数不同。
进一步阅读后发现，此测试仅适用于独立样本。我的样本在技术上是独立的，还是？
我甚至需要证明我的情况吗？我只能说我删除了重复项，然后就这样了吗？
Kolmogorov-Smirnov 检验是否更合适？
总之，很高兴能从您那里得到一些想法和您的意见。我实际上最初是按照之前的方式处理数据的，但想得太多了。我想我会保留数据并提及我的担忧。
很抱歉一开始没有说清楚！
再次感谢！
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659799/help-deciding-which-test-is-appropriate-for-determing-if-there-is-a-statisticall</guid>
      <pubDate>Thu, 09 Jan 2025 21:10:13 GMT</pubDate>
    </item>
    <item>
      <title>样本均值平方与样本均值平方之间的方差</title>
      <link>https://stats.stackexchange.com/questions/659789/difference-in-variance-between-sample-mean-of-squares-and-square-of-sample-mean</link>
      <description><![CDATA[假设我们有独立同分布的随机变量 $X_1 \ldots X_N$，我们从中计算样本均值 $\overline{X}$。我对数量 $Var[\overline{X^2}]$ 和 $Var[\overline{X}^2]$ 感兴趣。前者可以用来估计或限制后者吗？
在上面，我使用 $Var$ 来表示其参数的方差，将参数视为随机变量。例如，在此符号中，平均值的经典结果是 $Var[\overline{X}] = Var[X]/N$。
我的尝试 #1：
对于第一个方差，可以用期望的形式写成
$$ Var[\overline{X^2}] = \frac{1}{N} Var[X^2] = \frac{1}{N} (E[X^4]-E[X^2]^2)$$
对于第二个，我们使用以下事实：$E(X) - \overline{X}$ 很小，因此
$$ Var[f(\overline{X})] \sim Var[f(E[X]) + f&#39;(E[X])\cdot(\overline{X}-E[X])] = f&#39;(E[X])^2 \cdot Var[\overline{X}] = \frac{f&#39;(E[X])^2}{N} \cdot Var[X] = \frac{f&#39;(E[X])^2}{N} \cdot (E[X^2]-E[X]^2)$$
得出
$$ Var[\overline{X}^2] \sim \frac{4}{N} E[X]^2 \cdot (E[X^2]-E[X]^2)$$
我得出的两个表达式不是立即可比较的，但 4 这个因子让我怀疑 $Var[\overline{X^2}] &gt; Var[\overline{X}^2]$..？这个说法的证明肯定会回答我的问题。
我的尝试 #2：
按照 Xi&#39;an 的建议，我已经用数字方式研究了我的问题。我的 matlab 代码和结果图如下所示：
%计算不同分布的 Var(SM(X^2)) 和 Var(SM(X)^2) 并
%绘制不同 N 的结果。这里 SM 是 N 个样本的样本均值。

fig = figure;
Ax = [subplot(2,1,1),subplot(2,1,2)];
axes(Ax(1)); hold on;
axes(Ax(2)); hold on;

%计算方差的试验次数（尽可能大）
V = 1e4;

%样本大小
N = unique(round(logspace(0,3,20)));

%生成随机数的函数
F = {@rand, @randn, @(sz1,sz2)exprnd(1,sz1,sz2), @(sz1,sz2)betarnd(5,1,sz1,sz2)};
Fs = {&#39;x&#39;,&#39;+&#39;,&#39;o&#39;,&#39;^&#39;};

for iF = 1:numel(F)
%预先分配用于保存结果的空间
R1 = NaN(size(N));
R2 = NaN(size(N));

%循环遍历所有样本大小
for iN = 1:numel(N)
%生成随机数，行是试验，列是样本
X = F{iF}(V,N(iN));
%计算方差
R1(iN) = var(mean(X.^2,2));
R2(iN) = var(mean(X,2).^2);
end

%绘制曲线
plot(Ax(1),N,R1,[&#39;r-&#39;,Fs{iF}]);
plot(Ax(1),N,R2,[&#39;b-&#39;,Fs{iF}]);
plot(Ax(2),N,R2./R1,[&#39;k-&#39;,Fs{iF}]);
结束

% 格式化轴
set(Ax(1),&#39;XScale&#39;,&#39;log&#39;,&#39;YScale&#39;,&#39;log&#39;)
xlabel(Ax(1),&#39;$N$&#39;,&#39;Interpreter&#39;,&#39;latex&#39;)
ylabel(Ax(1),&#39;蓝色：$Var[\overline{X}^2]$~~~~红色：$Var[\overline{X^2}]$&#39;,&#39;Interpreter&#39;,&#39;latex&#39;)

set(Ax(2),&#39;XScale&#39;,&#39;log&#39;)
xlabel(Ax(2),&#39;$N$&#39;,&#39;Interpreter&#39;,&#39;latex&#39;)
ylabel(Ax(2),&#39;$Var[\overline{X}^2]/Var[\overline{X^2}]$&#39;,&#39;Interpreter&#39;,&#39;latex&#39;)


图中，标绘点和 &#39;x&#39; 来自 $[0,1]$ 上的均匀分布，&#39;+&#39; 来自正态分布，&#39;o&#39; 来自参数为 $1$ 的指数分布，并且 $\Delta$ 取自参数为 $(5,1)$ 的 Beta 分布。结果如下：

对于正态分布、均匀分布和指数分布，$Var[\overline{X}^2] &lt; Var[\overline{X^2}]$。事实上，对于正态分布，$Var[\overline{X}^2]/Var[\overline{X^2}] \to 0$ 等于 $N \to \infty$。
我能够找到一个违反不等式的分布，绘制的 beta 分布结果为 $Var[\overline{X}^2] \lesssim 1.2 \cdot Var[\overline{X^2}]$。然而，我仍然期望存在某个常数$C$，使得对于任何概率分布，$Var[\overline{X}^2] \lesssim C \cdot Var[\overline{X^2}]$。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659789/difference-in-variance-between-sample-mean-of-squares-and-square-of-sample-mean</guid>
      <pubDate>Thu, 09 Jan 2025 17:06:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么标准差比平均值绝对偏差更受青睐？</title>
      <link>https://stats.stackexchange.com/questions/659643/why-is-standard-deviation-preferred-over-absolute-deviations-from-the-mean</link>
      <description><![CDATA[第一部分
在探索了各种资源和论坛之后，我了解到标准差是一种广泛使用的离散度测量方法，通常比绝对平均偏差更受欢迎（我个人认为后者更简单、更直观），原因如下：
1. 方差的加性：
同意。
2. 平均值最小化平方偏差之和，而中位数（有时不是唯一的）最小化绝对偏差之和：
有点同意，但我不完全理解为什么在这里实现最小值是相关的。有人能解释一下为什么这个属性在选择离散度测量方法时很重要吗？
3.平方偏差在 𝑥 = 0 时可微分，而绝对偏差则不可微分：
有点同意，但我还是不明白为什么可微分性如此重要。这个属性在哪些方面有实际用途？
第二部分
我的独立想法/问题：
方差定义为与平均值的平方偏差的平均值，标准偏差是其平方根（“实际 SD”）。但是，如果标准偏差是平方偏差的平方根的平均值，那不是更有意义吗？ （我提议的是标准差的新定义“建议的 SD”）
(1 / n) * √ Σ((xᵢ - μ)²) 而不是 √(Σ (xᵢ - μ)² / n)

我的理由如下：
平方偏差主要是为了确保：

所有值都是正数。
偏差越大，权重越大。
平均值是使平方偏差之和最小化的数字。

绝对平均偏差达到点 (1)，绝对中位数偏差达到点 (1) 和 (3)。在这些情况下，我们将偏差相加，然后除以 𝑛 得到平均值。
但是，在方差和标准差的情况下，类似的“平均值”就是方差本身。但方差作为一个数字并不能直观地传达分布的扩展。这就是为什么我们要取方差的平方根来得到标准差。
所以，我的问题是：
为什么不使用&quot;建议 SD&quot;作为分散度的度量？
&quot;建议 SD&quot;有什么缺陷？
&quot;实际 SD&quot;为什么比&quot;建议 SD&quot;更适合作为分散度的度量？]]></description>
      <guid>https://stats.stackexchange.com/questions/659643/why-is-standard-deviation-preferred-over-absolute-deviations-from-the-mean</guid>
      <pubDate>Tue, 07 Jan 2025 05:23:59 GMT</pubDate>
    </item>
    <item>
      <title>在比较两个过程的输出时如何解释抽样变异性</title>
      <link>https://stats.stackexchange.com/questions/659519/how-to-account-for-sampling-variability-when-comparing-outputs-of-two-process</link>
      <description><![CDATA[我有一个粉末批次（批次 A），其粒度分布 (PSD) 已知。从这个批次中，我抽取两个单独的样本，用于工艺的两种不同方法（方法 A 和方法 B）。我想比较这两种方法的输出，看看它们是否产生粉末输出 PSD 结果。
但是，由于输入粉末批次 A 具有粒度分布（粒度范围），我采集的每个样本仅代表整体分布的一个子集，这可能会影响两种方法的输出结果。鉴于此，在比较方法 A 和 B 的输出时，我应该如何解释样本之间的粒度差异？
我是否应该通过考虑批次的整体 PSD（即粒度分布的平均值和标准差）来调整结果，并以某种方式将其计入两种方法的输出 PSD？]]></description>
      <guid>https://stats.stackexchange.com/questions/659519/how-to-account-for-sampling-variability-when-comparing-outputs-of-two-process</guid>
      <pubDate>Sat, 04 Jan 2025 05:02:37 GMT</pubDate>
    </item>
    </channel>
</rss>