<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 13 Sep 2024 15:17:37 GMT</lastBuildDate>
    <item>
      <title>1 类错误是否与线性模型的模型精度相关</title>
      <link>https://stats.stackexchange.com/questions/654329/are-type-1-errors-associated-with-model-accuracy-for-linear-models</link>
      <description><![CDATA[在讨论预测因子的统计显著性时，至少很少会提到模型准确性。但是，我的直觉是，我更愿意相信更准确的模型（可能存在训练误差，但理想情况下是保留集上的一些误差）中各个预测因子的重要性，而不是不太准确的模型。
首先，高误差可能表明某些线性模型的函​​数形式不正确，或者我们缺少重要的预测因子。
在检查系数显著性时，是否有任何文献或先前讨论过将第 1 类误差与模型准确性联系起来？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654329/are-type-1-errors-associated-with-model-accuracy-for-linear-models</guid>
      <pubDate>Fri, 13 Sep 2024 14:36:28 GMT</pubDate>
    </item>
    <item>
      <title>卷积问题</title>
      <link>https://stats.stackexchange.com/questions/654328/convolution-problem</link>
      <description><![CDATA[如果滤波器 h 的系数之和为零，则在与图像 f(m,n) 进行卷积后，对于什么填充，所得卷积图像的元素之和也为零？]]></description>
      <guid>https://stats.stackexchange.com/questions/654328/convolution-problem</guid>
      <pubDate>Fri, 13 Sep 2024 13:50:34 GMT</pubDate>
    </item>
    <item>
      <title>具有相关和层次效应的元回归中异常大的系数</title>
      <link>https://stats.stackexchange.com/questions/654327/oddly-large-coefficients-in-meta-regression-with-correlated-and-hierarchical-eff</link>
      <description><![CDATA[我正在执行元回归，以调查参与者特征和研究特征对发病率比 (IRR) 估计的影响。我有 10 项研究的数据，每项研究都为不同的年龄组、性别和风险窗口长度贡献了多个效应估计。我的数据描述可以在此处找到。
我使用了具有稳健方差估计 (RVE) 和小样本校正的随机效应元回归（包 metafor 和 clubSandwich）。我选择相关和分层效应作为 RVE 的工作模型。结果变量是 IRR 的对数。
由于解释变量在研究内部和研究之间都存在差异，我使用这些变量的研究平均值和以研究平均值为中心的值来估计研究间和研究内效应，正如 Yaremych (2023) 所建议的那样
变量“男性比例”(prop_male_guess) 有 5 个级别：0%、&lt;45%、45%-55%、&gt;55%、100%。下表显示了我的数据中每个级别的分布情况，对角线单元格是具有该级别的研究数量（效果大小）：

由于级别“&lt;45%&gt;”仅出现在 1 项研究中，因此我将其与级别“45-55&gt;”合并 -&gt; 新级别“大致相等”。
当我用“男性比例”拟合模型时作为预测因子，截距和系数变得异常大：
#加载数据并拟合模型
urlfile=&quot;https://raw.githubusercontent.com/trangtph/Meta_Regression/main/example_data.csv&quot;
mydata&lt;-read_csv(url(urlfile))

# 恒定采样相关工作模型
rho_const &lt;- 0.7
V &lt;- vcalc(var, cluster = study_id, obs = effect_id, data = mydata, rho = rho_const)

# 具有组均值中心的模型
model_sex &lt;- 
rma.mv(log_effect ~ 1 + prop_male_merge_roughly.equal.c + prop_male_merge_.55.c + prop_male_merge_100.c +
prop_male_merge_roughly.equal_m + prop_male_merge_.55_m + prop_male_merge_100_m, 
V = V, 
random = ~ 1 | study_id / effect_id,
data = mydata, sparse = TRUE)

model_sex_robust &lt;- robust(model_sex, cluster=study_id, clubSandwich=TRUE)

这是模型输出：
多变量荟萃分析模型 (k = 122; 方法：REML)

方差成分：

estim sqrt nlvls 固定因子 
sigma^2.1 0.1044 0.3231 10 无 study_id 
sigma^2.2 0.3511 0.5925 122 无 study_id/effect_id 

调节器检验 (系数 2:7)：¹
F(df1 = 6, df2 = 0) = 0.0000, p-val = NA


研究内效应（协变量以“.c”结尾）很好，但截距和研究间效应（协变量以“_m”结尾）异常大（截距 13.4 将转化为不可能的 IRR 660003）。
我的问题是：我该如何解释我的模型的奇怪行为？。我的一个猜测是水平之间的相关性：“&lt;45&quot;、&quot;45-55&quot; &quot;&gt;55&quot; 从未在研究中同时出现。但我不确定。
附带问题：我的模型的自由度相当低。正如 Tipton (2015) 中所述，DF &lt;4 的 p 值不应被信任。那么，有没有办法在 RVE 中生成可靠的标准误差和 p 值？
欢迎提出任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/654327/oddly-large-coefficients-in-meta-regression-with-correlated-and-hierarchical-eff</guid>
      <pubDate>Fri, 13 Sep 2024 13:46:27 GMT</pubDate>
    </item>
    <item>
      <title>如何计算给定数据估计值的最小均方误差 (MMSE)？</title>
      <link>https://stats.stackexchange.com/questions/654326/how-to-calculate-minimum-mean-square-error-mmse-of-an-estimated-value-from-the</link>
      <description><![CDATA[我觉得这个问题真的很基础，但我对方法论感到困惑。
我必须根据观测值$k(g)$估计一个参数$g$，我有 PDF $f(g|k)$。
已知最小均方误差 (MMSE) 估计量可由以下公式得出：
$$\hat{g}(k)=\int_{_-\infty}^{\infty} g~f(g|k)~\partial{d}g$$
这是我使用数值积分得出的，现在我有几个 $\hat{g}$ 值，它们分别对应于 $g$ 的各种值。
均方误差 (MSE) 由 $$\mathbb{E}_{G|K}[(g-\hat{g}(k))^2].$$ 给出
现在我的问题是：
要用数字方式计算 MSE 的平均值，我是否可以简单地将获得的数值平均为 $$\frac{1}{N}\Sigma(g-\hat{g}(h))^2$$，其中 $N$ 是可用的 $g$ 估计值的总数（总迭代次数）。但是，如果我的意思确实是这样的，那么平均值是如何给出的：
（连续）$$\int xf(x)\text{d}x$$ 和（离散）$$\Sigma_i x_i P(x=x_i),$$ 其中 PDF/PMF 也在计算平均值时被考虑。
我是否需要进行数值积分，因为$$\int_{-\infty}^{\infty}(g-\hat{g}(h))^2f(g|y)\partial g?$$ 但是，我不认为这会给出正确的值，因为对于给定的估计数值$\hat{g}(k)$，我将在整个范围内进行积分为给定值 $$ 的 $g$]]></description>
      <guid>https://stats.stackexchange.com/questions/654326/how-to-calculate-minimum-mean-square-error-mmse-of-an-estimated-value-from-the</guid>
      <pubDate>Fri, 13 Sep 2024 13:39:59 GMT</pubDate>
    </item>
    <item>
      <title>参数属性的假设检验</title>
      <link>https://stats.stackexchange.com/questions/654323/hypothesis-testing-a-property-of-parameters</link>
      <description><![CDATA[假设我有 $n$ 个 i.i.d 观测值 $X = (X_1,X_2,\cdots,X_n)$，它们由某个分布 $p(x;\theta)$ 生成，其中 $\theta \in \mathbb{R}^m$ 是我想从观测值中推断出的未知参数。
我已经执行了最大似然估计，使用似然函数 $L(X;\theta)$ 获得了 MLE 估计值 $\hat{\theta_{\text{MLE}}} \quad$。
我想检验一个假设，即真实参数 $\hat{\theta_{\text{MLE}}} \quad$。 class=&quot;math-container&quot;&gt;$\theta$ 满足某些属性，即 $\theta \in \Omega$。我只能通过计算来测试这一点，即它不是某些分析属性。对于任何 $\theta$，我都必须模拟一些复杂的系统来检查该属性是否成立。
如何在频率论框架中计算检验 $\theta \in \Omega$ 的假设 $H_1$？
我的第一次直观尝试是这样的：我们知道在某些条件下，MLE 估计是渐近正态分布的 $\hat{\theta_{\text{MLE}}} \sim N(\theta,I_n(\theta)^{-1})$，其中 $I_n$ 是费希尔信息矩阵。我可以通过评估 $\hat{\theta_{\text{MLE}}}$ 处的似然函数的 Hessian 并取其逆来估计这个协方差矩阵 - 将此数量表示为 $H(\hat{\theta_{\text{MLE}}})$。
现在是棘手的部分：然后我抽样说 $k$ 估计 $\theta^{&#39;}_k \sim N(\hat{\theta_{\text{MLE}}},H(\hat{\theta_{\text{MLE}}}))$，并使用我的复杂程序评估 $ \theta^{&#39;}_k \in \Omega$ 是否成立。然后我计算成功的次数，这就是我接受假设的信心，即$\alpha = \sum_{k} \mathbb{1}( \theta^{&#39;}_k \in \Omega) / k$。
是否有任何程序可以将我正在做的事情形式化？有没有更好的方法来解决这个问题？我应该说我无法再收集任何数据了。
干杯]]></description>
      <guid>https://stats.stackexchange.com/questions/654323/hypothesis-testing-a-property-of-parameters</guid>
      <pubDate>Fri, 13 Sep 2024 12:46:13 GMT</pubDate>
    </item>
    <item>
      <title>多项响应变量的虚拟编码</title>
      <link>https://stats.stackexchange.com/questions/654322/dummy-encoding-for-the-multinomial-response-variable</link>
      <description><![CDATA[我正在阅读 Fahrmeir 和 Tutz 合著的《基于广义线性模型的多元统计建模》一书中有关多项响应模型的内容。我试图理解书中的以下段落（第 3.1 章，第 70 页）：

对于本章中考虑的分类响应，基本分布是多项分布。假设响应变量 $Y$ 有 $k$ 个可能值，为简单起见，将其标记为 $1, ... , k$。有时，考虑 $Y\in \{1, 2, ..., k\}$ 会隐藏我们实际上有一个多变量响应变量的事实。通过考虑虚拟变量的响应向量 $y&#39; = (\tilde{y_1}, \tilde{y_2}... ,\tilde{y_q}), q = k - 1$，其分量为
$$
\begin{equation} \tag{3.1.1}
\tilde{y_r} = 
\begin{cases}
1 &amp; \text{if $Y = r$, $r = 1, ..., q$} \newline
0 &amp; \text{otherwise.}
\end{cases}
\end{equation}
$$
然后我们有
$$
Y = r \iff y = (0, ..., 1, ..., 0).
$$
概率通过以下公式简单连接起来：
$$P(Y = r) = P(y_r =1).$$

我对上述方程组中 $r$ 的使用感到困惑。方程 $Y = r$ 中的 $r$ 与方程 3.1.1 中的 $r$ 不同吗？因为，如果我们考虑$Y$，其中$k = 4$，那么对于$Y = 4$，$r &gt; q$，但考虑方程 3.1.1，$r \in \{1, 2, ..., q\}$，因此，$ r \le q$。]]></description>
      <guid>https://stats.stackexchange.com/questions/654322/dummy-encoding-for-the-multinomial-response-variable</guid>
      <pubDate>Fri, 13 Sep 2024 11:38:50 GMT</pubDate>
    </item>
    <item>
      <title>模拟退火回归模型中的迭代次数</title>
      <link>https://stats.stackexchange.com/questions/654321/number-of-iterations-in-simulated-annealing-regression-model</link>
      <description><![CDATA[我是机器学习模型应用的新手。我正在尝试应用模拟退火回归模型。现在的问题是我应该在回归控制和模拟退火控制中设置迭代次数，还是两者都设置？
代码如下：
# 设置并行后端
Mycluster &lt;- makeCluster(detectCores() - 2) # 使用可用核心减 2
registerDoParallel(Mycluster) # 注册并行执行

stime = system.time({
# 训练函数的回归控制
reg.ctrl &lt;- trainControl(method = &quot;LOOCV&quot;, 
number = 100, 
repeats = 5, 
allowParallel = TRUE)

# 模拟退火控制设置
safs.ctrl &lt;- safsControl(functions = caretSA, 
method = &quot;LOOCV&quot;, 
number = 100,
metric = c(internal = &quot;RMSE&quot;, external = &quot;RMSE&quot;),
maximize = c(internal = FALSE, external = FALSE),
holdout = 0.2,
improve = 5,
allowParallel = TRUE,
verbose = TRUE)

# 模拟退火特征选择
sa_100 &lt;- safs(x = MEs[, 1:dim(MEs)[[2]]],
y = gsva[1, ],
iters = 100,
metric = &quot;RMSE&quot;,
trControl = reg.ctrl,
safsControl = safs.ctrl)
})[3]

stime[1]

# 计算完成后停止集群
stopCluster(Mycluster)
registerDoSEQ() # 重置为顺序执行

我的意思是，我应该设置 number = 的参数吗100 在 trainControl() 和 safsControl() 函数中还是其中一个？或者只是在 safs() 函数中使用 iters = 100？
此外，我需要了解，回归控制和模拟退火控制之间有什么区别？]]></description>
      <guid>https://stats.stackexchange.com/questions/654321/number-of-iterations-in-simulated-annealing-regression-model</guid>
      <pubDate>Fri, 13 Sep 2024 11:34:06 GMT</pubDate>
    </item>
    <item>
      <title>SurvDisc 软件包（A 功能）</title>
      <link>https://stats.stackexchange.com/questions/654320/survdisc-package-a-function</link>
      <description><![CDATA[当我们对风险率只有一个估计值时，假设风险随时间呈线性变化，那么SurvDisc包中的以下函数是否可用于计算样本量？在这种情况下，没有对每个时间点的风险率 1,..., T(r) 进行单独的估计，因为我们没有假设风险随时间推移完全普遍存在。
SampleSizeDiscSurv(power=0.9,alpha=0.025,alternative=c(&quot;less&quot;,&quot;greater&quot;),beta0=0,
h0,h1,p0,p1,ties.method=c(&quot;efron&quot;,&quot;breslow&quot;,&quot;PrenticeGloeckler&quot;),
method=c(&quot;asymptotic&quot;,&quot;simulation&quot;),tol,AMV=NULL,nsim=10000,Nvec=NULL,
test=c(&quot;Wald&quot;,&quot;Score&quot;))

h0 
长度为 r-1 的向量包含时间 1、...、r-1 或相应时间间隔内对照组的假设风险率。假设为 r 个间隔，最后一个间隔为无限。

h1 
治疗组的假设风险率向量

p0 
处于风险集和对照组的概率向量。

p1 
处于风险集和治疗组的概率向量。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654320/survdisc-package-a-function</guid>
      <pubDate>Fri, 13 Sep 2024 11:28:30 GMT</pubDate>
    </item>
    <item>
      <title>关于生存建模中区间删失的澄清</title>
      <link>https://stats.stackexchange.com/questions/654313/a-clarification-on-interval-censoring-in-modeling-survival</link>
      <description><![CDATA[直到阅读 Vinh Nguyen 的 第 11 讲：区间删失和离散时间数据 (2012)，我才认为离散时间生存模型才是适合我们研究的统计方法。我的理解是离散时间生存分析 (Cox) 包括区间删失。然而，区间删失似乎是一种独立的技术（如果我错了，请纠正我）。现在，我有点困惑，区间审查方法或离散时间生存是否适合我的研究。
在我们的研究中，受试者每三个月（最多 18 个月）访问一次中心，在以下时间检查他们的疾病状态：T0、T3、T6、T9、T12、T15 和 T18。主要协变量 测试状态 是二元的且与时间相关（1 vs. 0）。事件是二元结果（1：健康状况下降，0：健康状况稳定）。这项研究是单一事件。数据可能看起来像这样：
ID TIME AGE EVENT TEST STATUS
1 0 45 0 0
1 3 45 1 1
2 0 46 0 0
2 3 46 0 1
2 6 46 0 0
2 9 46 1 1
3 0 34 0 0
3 3 34 0 0
3 6 34 0 1
3 9 34 0 1
3 12 34 0 0
3 15 34 0 1
3 18 34 1 0
]]></description>
      <guid>https://stats.stackexchange.com/questions/654313/a-clarification-on-interval-censoring-in-modeling-survival</guid>
      <pubDate>Fri, 13 Sep 2024 09:17:13 GMT</pubDate>
    </item>
    <item>
      <title>Keras 中的简单梯度下降[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654312/simple-gradient-descent-in-keras</link>
      <description><![CDATA[我正在通过在笔记本中构建自己的神经网络来练习神经网络。我正尝试将我的模型与 Keras 中的等效模型进行对比。我的模型似乎与其他简单的编码神经网络框架一样工作，例如：https://towardsdatascience.com/coding-neural-network-forward-propagation-and-backpropagtion-ccf8cf369f76
但是，随着我增加 epoch 的数量，Keras 模型的权重逐渐与我自己的权重不同。我正尝试使用简单的梯度下降来训练网络，批量大小等于整个训练集，将初始化权重设置为与我的模型中的初始化权重相同。 （我目前一直在 Iris 数据集上执行此操作，因此批处理大小 = 150。）
我感兴趣的是，这里 keras 中是否存在默认情况，这意味着我下面描述的模型与我的模型（或文章中描述的模型）的功能略有不同？比如批量标准化之类的？
从 tensorflow 导入 keras
从 tensorflow.keras.models 导入 Sequential
从 tensorflow.keras.layers 导入 Dense、Activation、Input

network_shape = np.array([4,20,10,1])
activations=[&quot;relu&quot;,&quot;relu&quot;,&quot;sigmoid&quot;]
model = Sequential()
model.add(Input(shape=(network_shape[0],)))
for i in range(len(activations)):
model.add(Dense(units=network_shape[i+1],activation=activations[i]))

model.set_weights(set_weights)

sgd = keras.optimizers.SGD(learning_rate=alpha,动量=0.0)
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=sgd)

model.fit(X.T, y.T, batch_size=150, epochs=n_iter, verbose=0, shuffle=False)

提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/654312/simple-gradient-descent-in-keras</guid>
      <pubDate>Fri, 13 Sep 2024 08:32:10 GMT</pubDate>
    </item>
    <item>
      <title>逆回归的无偏估计量</title>
      <link>https://stats.stackexchange.com/questions/654311/unbiased-estimator-of-the-reversed-regression</link>
      <description><![CDATA[假设我有随机变量 $X$ 和 $Y$。我对 $\mathbb{E}[Y | X]$ 的无偏估计量感兴趣，但我以另一种方式执行了回归，并得到 $\mathbb{E}[X |Y]$。在什么数据生成分布和进一步假设下，是否知道我可以构建一个无偏估计量 $\mathbb{E}[Y | X] = \beta \mathbb{E}[X |Y]$？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654311/unbiased-estimator-of-the-reversed-regression</guid>
      <pubDate>Fri, 13 Sep 2024 08:29:49 GMT</pubDate>
    </item>
    <item>
      <title>mmrm R 包：没有优化器导致模型拟合成功</title>
      <link>https://stats.stackexchange.com/questions/654310/mmrm-r-package-no-optimizer-led-to-a-successful-model-fit</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654310/mmrm-r-package-no-optimizer-led-to-a-successful-model-fit</guid>
      <pubDate>Fri, 13 Sep 2024 07:52:54 GMT</pubDate>
    </item>
    <item>
      <title>量化对异常值敏感的两个分布之间的差异</title>
      <link>https://stats.stackexchange.com/questions/654309/quantifying-the-discrepancy-between-two-distributions-with-sensitivity-to-outlie</link>
      <description><![CDATA[我在样本空间 $x \in \Omega$ 上有两个概率分布，分别表示为 $P:\Omega \mapsto \mathbb{R}$ 和 $Q:\Omega \mapsto \mathbb{R}$。这些分布出现在构建纠错码解码器的背景下。假设 $\Omega$ 表示所有可能错误的空间，而 $P(\cdot)$ 是一个错误模型，它为 $\Omega$ 中的每个错误事件分配一个概率。本质上，$P(\cdot)$ 捕获了所有不想要的效果。如果解码策略完全了解 $P(\cdot)$，则它可以发挥最佳性能。但是，$P(\cdot)$ 在实践中通常是未知的。相反，我们经常进行校准实验来推断一个模型 $Q(\cdot)$，该模型合理地近似了底层噪声过程 $P(\cdot)$。因此，了解$P(\cdot)$和$Q(\cdot)$之间的差异至关重要，尤其是在解码器的性能方面。
在错误校正中，众所周知，位于$P(\cdot)$尾部的$x \in \Omega$错误，即异常值，对解码器的性能有重大影响。例如，如果 $\Omega$ 表示独立的位翻转错误，其中每个位翻转发生的概率为 $p$，则关键异常值是具有较大汉明权重的错误（刚好超过代码距离的一半 $d$），概率约为 $p^{d/2}$。因此，$P(\cdot)$ 和 $Q(\cdot)$ 在异常值上紧密匹配至关重要，而对于非异常值错误，较大的差异更容易被接受。
在这种情况下，什么是合适的可区分性指标来量化 $P(\cdot)$ 和 $Q(\cdot)$ 之间的相关差异？以下常用指标似乎不适合这种特殊情况：

总变异距离 (TVD)：$\sup_{x \in \Omega} |P(x) - Q(x)|$。该指标主要由更可能发生事件的概率差异决定。例如，如果我们有两个误差$x_1, x_2 \in \Omega$，其中$P(x_1) = 0.9$、$Q(x_1) = 0.8$，以及$P(x_2) = 10^{-5}$、$Q(x_2) = 10^{-7}$，则 TVD 对估计$x_2$概率的显著误差不敏感。
Kullback-Leibler 散度 (KL 散度)： $ D(P || Q) = \sum_{x \in \Omega} P(x) \log \left( \frac{P(x)}{Q(x)} \right) $。与 TVD 一样，对于典型事件，KL 散度对 $P(x)$ 和 $Q(x)$ 的差异更为敏感。因此，它无法充分捕捉异常值的差异。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654309/quantifying-the-discrepancy-between-two-distributions-with-sensitivity-to-outlie</guid>
      <pubDate>Fri, 13 Sep 2024 07:37:11 GMT</pubDate>
    </item>
    <item>
      <title>下采样是否是一种比较不同样本量组间回归结果的有效方法？如果是，那么如何实现？</title>
      <link>https://stats.stackexchange.com/questions/654301/is-downsampling-a-valid-approach-to-compare-regression-results-across-groups-wit</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654301/is-downsampling-a-valid-approach-to-compare-regression-results-across-groups-wit</guid>
      <pubDate>Thu, 12 Sep 2024 23:50:58 GMT</pubDate>
    </item>
    <item>
      <title>仅具有一个连续预测变量和一个小样本量的二元逻辑回归：如何测试线性？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654296/binary-logistic-regression-with-only-one-continious-predictor-and-a-small-sample</link>
      <description><![CDATA[我有一个包含 10 个数据点的拟合二元模型。单个连续变量位于 [2.4, 4.4] 区间，有一个二元输出变量 Y。Y 包含 4 个 Y=1 的事件和 6 个 Y=0 的事件。在避免完全分离的情况下，建模效果很好。我使用了 Python。
我读过许多论文，其中指出需要检查逻辑回归的假设（(1)线性：线性预测器是否正确？，(2) logit 变换是将协变量与条件均值联系起来的正确函数，以及 (3) 方差是伯努利）。
我的问题如下：
只有一个预测器，如果有必要，检查线性的最佳方法是什么？我可以使用经典的 GOF 测试来做到这一点吗？它们基本上只是测试是否存在我遗漏的非线性或相互作用？
如果您需要有关我的模型的更多信息，请告诉我！]]></description>
      <guid>https://stats.stackexchange.com/questions/654296/binary-logistic-regression-with-only-one-continious-predictor-and-a-small-sample</guid>
      <pubDate>Thu, 12 Sep 2024 22:12:20 GMT</pubDate>
    </item>
    </channel>
</rss>