<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 11 Aug 2024 01:13:20 GMT</lastBuildDate>
    <item>
      <title>识别聚类以校正散点</title>
      <link>https://stats.stackexchange.com/questions/652598/identifying-clusters-to-correct-for-scatter</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652598/identifying-clusters-to-correct-for-scatter</guid>
      <pubDate>Sat, 10 Aug 2024 17:52:31 GMT</pubDate>
    </item>
    <item>
      <title>GLMM 用于推理与预测</title>
      <link>https://stats.stackexchange.com/questions/652596/glmm-for-inference-vs-prediction</link>
      <description><![CDATA[我正在使用线性混合模型 (LMM) 和广义线性混合模型 (GLMM) 的混合模型评估横断面重复测量数据。我看到很多地方都说 GLMM 主要用于预测结果变量值。我的研究主要是推断一组独立变量与结果变量之间的关系（推断），而不是预测值。当目标是推断而不是预测时，GLMM 是否仍然适用于连续/近似连续的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/652596/glmm-for-inference-vs-prediction</guid>
      <pubDate>Sat, 10 Aug 2024 17:09:12 GMT</pubDate>
    </item>
    <item>
      <title>单调变换的数学理论</title>
      <link>https://stats.stackexchange.com/questions/652595/mathematical-theory-of-monotone-transforms</link>
      <description><![CDATA[对于从总体 $ \mathcal{P}$ 中选取的一个服从分布 $P$ 的一个样本的 $n$ 个观测值 $X_1, \ldots, X_n$，假设我们观察到 $X_i = x_i \in \mathbb{R}$。从经验上讲，我们可以通过查看 QQ 图或运行正态性检验来检测 $P$ 是否不正态。当我们有理由怀疑$P$不是正常的时候，根据经验，我们可以应用某种单调变换（例如幂变换，特别是 Box-Cox 变换）来“使其看起来更正常”。这意味着我们将固定一个非减函数 $f: \mathbb{R} \to \mathbb{R}$ 并研究 $Y_i = f(X_i)$。
是否有任何数学理论表明，在适当选择的 $f$（特别是 Box-Cox 变换）下，$Y_i$ 的分布在某种数学意义上（例如累积分布函数之间的距离）更接近具有一定均值和方差的正态分布？这个问题的定量答案（参考）是最好的。定性答案也是可以接受的。我只是想知道这种变换是否纯粹是经验性的，还是有任何理论基础。
对我来说，听起来这种变换只能拉伸数据（非均匀地），使其集中在某个区域而不是其他区域，这肯定会使其更接近正态分布。对于所有非正态分布，某种算法是否可以确定一种变换使其更正态，这是另一回事。
这种变换的使用存在很多歧义。]]></description>
      <guid>https://stats.stackexchange.com/questions/652595/mathematical-theory-of-monotone-transforms</guid>
      <pubDate>Sat, 10 Aug 2024 16:14:20 GMT</pubDate>
    </item>
    <item>
      <title>xgboost 模型的超参数优化</title>
      <link>https://stats.stackexchange.com/questions/652593/hyperparameter-optimization-for-xgboost-model</link>
      <description><![CDATA[我正在尝试训练 xgboost 模型。准备好数据集后，我进行了训练/测试分割。为了加快训练过程，我想先使用网格搜索确定超参数的最佳范围，然后使用随机搜索训练模型。但我对得到的图表感到怀疑。例如，我获得了 max_depth 参数的验证图；
param_grid = {
&#39;max_depth&#39;: [1, 3, 5, 7, 10, 50, 100]
}

#model
xgb_model2 = xgb.XGBClassifier()

#grid_search
grid_search1 = GridSearchCV(xgb_model2, param_grid, cv=5,scoring = &quot;precision&quot;, error_score = &quot;raise&quot;, return_train_score=True)
grid_search1.fit(X_train, y_train)
results = pd.DataFrame(grid_search1.cv_results_)

max_depths = results[&#39;param_max_depth&#39;]
mean_train_scores = results[&#39;mean_train_score&#39;]
mean_test_scores = results[&#39;mean_test_score&#39;]

plt.figure(figsize=(10, 6))
plt.plot(max_depths, mean_train_scores, label=&#39;训练精度&#39;, marker=&#39;o&#39;)
plt.plot(max_depths, mean_test_scores, label=&#39;验证精度&#39;, marker=&#39;o&#39;)
plt.xlabel(&#39;最大深度&#39;)
plt.ylabel(&#39;精度&#39;)
plt.title(&#39;max_depth 对模型性能的影响&#39;)
plt.legend()
plt.grid(True)
plt.show()


我的顾问说这个图表可能是错的，但我认为不是。在我看来，根据图表，max_depth 参数本身无法解决过度拟合问题，但我可以将其解释为在进行随机搜索时尝试 max_depth 参数的 1-10 之间的值是合适的。图表或我的解释有误吗？
我的顾问期望是这样的;
]]></description>
      <guid>https://stats.stackexchange.com/questions/652593/hyperparameter-optimization-for-xgboost-model</guid>
      <pubDate>Sat, 10 Aug 2024 15:13:03 GMT</pubDate>
    </item>
    <item>
      <title>指定 TWFE 模型（有或无动态效应）的正确方法是什么？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652588/what-is-the-correct-way-to-specify-model-a-twfe-with-and-without-dynamic-effect</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652588/what-is-the-correct-way-to-specify-model-a-twfe-with-and-without-dynamic-effect</guid>
      <pubDate>Sat, 10 Aug 2024 10:57:00 GMT</pubDate>
    </item>
    <item>
      <title>使用弗里德曼检验对疫苗冰箱数据进行一天内的时间分析？</title>
      <link>https://stats.stackexchange.com/questions/652558/using-friedman-test-for-time-of-day-analysis-on-vaccine-fridge-data</link>
      <description><![CDATA[我参与了一个监测疫苗冰箱温度的项目，两年内每 30 秒收集一次数据。我想比较一天中不同时间的高温异常（高于 8°C）——夜间（下午 4 点至凌晨 12 点）、白天（上午 8 点至下午 4 点）和晚上（下午 4 点至凌晨 12 点）。
为了最好地捕捉这两年的总体趋势，我计划使用每个冰箱每个时期（夜间、白天、晚上）的异常中位数。我的想法是应用 Friedman 检验来分析基于这些中位数的三个时期内这些异常的频率是否存在显着差异。
这是 Friedman 检验的适当用法吗，使用中位数来反映趋势？如果不合适，有什么更好的方法建议吗？任何参考资料或示例都会非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/652558/using-friedman-test-for-time-of-day-analysis-on-vaccine-fridge-data</guid>
      <pubDate>Fri, 09 Aug 2024 17:41:40 GMT</pubDate>
    </item>
    <item>
      <title>计算分类变量乘以随机量的期望值</title>
      <link>https://stats.stackexchange.com/questions/652555/finding-the-expectation-of-a-categorical-variable-times-a-random-amount</link>
      <description><![CDATA[假设我们有 $J$ 张交易卡，每张卡的美元价值为 $u_{j}$，我可以抽 1 次。
$$
u_{j} \sim N(\mu,1)
$$
其中每张交易卡的价值都是独立且同分布的。
抽到交易卡的概率是 $u_{j}$ 的函数。
我们可以将其指定为 $J$ 张卡片的多项回归。
$$
\text{ln Pr}(C_i = j) = u_{j} - \text{ln} Z_i
$$
$$
Z_i = \sum_{j}^J e^{u_{j}}
$$
$Z_i$ 是一个标准化值，以确保概率加起来等于一。
其中 $C_i$ 是一个分类分布，其中每个概率 $p_j$ 都由上述公式给出。这也与多项分布相同，其中$n= 1$。
$$
C_i \sim Categorical(p_1^{[C_i = 1]} \cdots p_J^{[C_i = J]})
$$
卡片的随机值为：
$$
u_{1C_i} = \sum_j^J [C_i = j] * u_{j}
$$
如果我想知道抽一张卡片的美元金额的预期值。我该如何设置？
$$
{\bf E} (u_{C_i}) = \int u_{C_i} f_{pdf}(u_{C_i})
$$
我感兴趣的是设置积分或总和是什么样子？我知道它不会简化为一个很好的封闭形式答案。
我一直在努力解决如何处理$\text{Pr}(C_i = j)$的概率取决于集合$U = \{u_1, \cdots u_J\}$，而不仅仅是特定的$u_{j}$。
这个问题的动机问题与复杂的多项回归有关，其中存在随机 beta 系数。]]></description>
      <guid>https://stats.stackexchange.com/questions/652555/finding-the-expectation-of-a-categorical-variable-times-a-random-amount</guid>
      <pubDate>Fri, 09 Aug 2024 17:25:38 GMT</pubDate>
    </item>
    <item>
      <title>如果 PCA 无法对我的样本进行分组，但 K-means 可以完美地聚类它们，该怎么办？我的数据分析有问题吗？可能吗？</title>
      <link>https://stats.stackexchange.com/questions/652329/what-if-pca-is-unable-to-group-my-samples-but-k-means-perfectly-clusters-them</link>
      <description><![CDATA[我不是专家，但我目前正在使用无监督方法来更好地解释通过 DART-MS 分析获得的质谱数据。我还在学习。
事实证明，当我在 MetaboAnalyst 平台上分析我的数据时，我没有观察到通过 PCA 进行的区分，而 K-means 能够将我的样本聚类为两个不同的组，这与样本特征非常一致。
我已经多次检查了该协议。它在分析其他样本时效果很好，我的意思是“PCA 与 K-means 结果一致，两者一致。”
如果这是正确的，我们如何解释这种分歧？
PCA 结果

K-means 结果中，您可以看到样本 Q3、Q4、T2、T3、V3、V4、R3 和 R4 按预期分组：
]]></description>
      <guid>https://stats.stackexchange.com/questions/652329/what-if-pca-is-unable-to-group-my-samples-but-k-means-perfectly-clusters-them</guid>
      <pubDate>Mon, 05 Aug 2024 14:26:56 GMT</pubDate>
    </item>
    <item>
      <title>导出有界函数估计误差和的大 $O_p$</title>
      <link>https://stats.stackexchange.com/questions/651980/deriving-the-big-o-p-of-a-sum-involving-estimation-errors-of-bounded-functions</link>
      <description><![CDATA[假设 $\frac{1}{n}\sum_{i=1}^n\{f(X_i) - \hat{f}_n(X_i)\}^2$ 和 $\frac{1}{n}\sum_{i=1}^n\{g(X_i) - \hat{g}_n(X_i)\}^2$ 为 $O_p(a^2_n)$，其中 $a_n$ 为 $a_n = O(n^{-r}$)，其中 $r &gt; 1/4$。
假设 $Y_i$ 是二进制 0/1 随机变量，$f(\cdot)$ 介于 -1 和 1 之间（即，对于任何 $X_i$，$-1 \leq f(X_i) \leq 1$），并且 $g(\cdot)$ 介于 0 和 1 之间（即，对于任何 $X_i$，$0 \leq g(X_i) \leq 1$）。观测值 $i = 1, \ldots, n$ 是 i.i.d，而 $\hat{f}_n(\cdot)$ 和 $\hat{g}_n(\cdot)$ 是从这些观测值中获得的估计量。
对于，最大的 $O_p$ 是什么呢？
$$\frac{1}{n}\sum_{i=1}^n [(f(X_i) - \hat{f}_n(X_i))g(X_i) + (\hat{f}_n(X_i) - Y_i)(g(X_i) - \hat{g}_n(X_i))]^2?$$
展开平方，我们得到 3 项之和：
\begin{align*}
&amp;\frac{1}{n}\sum_{i=1}^n [(f(X_i) - \hat{f}_n(X_i))g(X_i) + (\hat{f}_n(X_i) - Y_i)(g(X_i) - \hat{g}_n(X_i))]^2\\
&amp;=\frac{1}{n}\sum_{i=1}^n \{f(X_i) - \hat{f}_n(X_i)\}^2g^2(X_i)+2(f(X_i) - \hat{f}_n(X_i))g(X_i)(\hat{f}_n(X_i) - Y_i)(g(X_i) - \hat{g}_n(X_i)) + (\hat{f}_n(X_i) - Y_i)^2(g(X_i) - \hat{g}_n(X_i))^2
\end{align*&gt;
项 1：$\frac{1}{n}\sum_{i=1}^n \{f(X_i) - \hat{f}_n(X_i)\}^2g^2(X_i)$
由于 $g(X_i)$ 有界，并且 $\frac{1}{n}\sum_{i=1}^n\{f(X_i)-\hat{f}_n(X_i)\}^2$ 为 $O_p(a^2_n)$，则 项 1 为 $O_p(a^2_n)$。
项 2：$\frac{2}{n}\sum_{i=1}^n (f(X_i) - \hat{f}_n(X_i))g(X_i)(\hat{f}_n(X_i) - Y_i)(g(X_i) - \hat{g}_n(X_i))$
由于$g(X_i) \leq 1$ 和 $|\hat{f}_n(X_i) - Y_i| \leq 2$，则我们有
\begin{align*}
&amp;\frac{2}{n}\sum_{i=1}^n (f(X_i) - \hat{f}_n(X_i))g(X_i)(\hat{f}_n(X_i) - Y_i)(g(X_i) - \hat{g}_n(X_i))\\ &amp;\leq C \sqrt{\left(\frac{1}{n}\sum_{i=1}^n \{f(X_i)-\hat{f}_n(X_i)\}^2\right)\left(\frac{1}{n}\sum_{i=1}^n \{g(X_i) - \hat{g}_n(X_i)\}^2\right)}\\
&amp;= O_p(a^2_n)
\end{align*&gt;
其中 $C$ 是某个正常数，不等式由柯西-施瓦茨定理成立。
第 3 项：$\frac{1}{n}\sum_{i=1}^n (\hat{f}_n(X_i) - Y_i)^2(g(X_i) - \hat{g}_n(X_i))^2$
因为 $|\hat{f}_n(X_i) - Y_i| \leq 2$
$$\frac{1}{n}\sum_{i=1}^n (\hat{f}_n(X_i) - Y_i)^2(g(X_i) - \hat{g}_n(X_i))^2 \leq \frac{4}{n}\sum_{i=1}^n (g(X_i) - \hat{g}_n(X_i))^2 = O_p(a^2_n)$$
总之，我们有
\begin{align*}
&amp;\frac{1}{n}\sum_{i=1}^n [(f(X_i) - \hat{f}_n(X_i))g(X_i) + (\hat{f}_n(X_i) - Y_i)(g(X_i) - \hat{g}_n(X_i))]^2\\ &amp;= O_p(a^2_n) + O_p(a^2_n) + O_p(a^2_n)\\
&amp;= O_p(a^2_n)
\end{align*&gt;
以上内容正确吗？我不太确定项 2和项 3，特别是关于分解$\hat{f}_n(X_i)-Y_i$。]]></description>
      <guid>https://stats.stackexchange.com/questions/651980/deriving-the-big-o-p-of-a-sum-involving-estimation-errors-of-bounded-functions</guid>
      <pubDate>Tue, 30 Jul 2024 02:22:39 GMT</pubDate>
    </item>
    <item>
      <title>处理具有许多变量和大量数据集的 Cox 模型中的非比例风险</title>
      <link>https://stats.stackexchange.com/questions/651252/dealing-with-non-proportional-hazards-in-a-cox-model-with-many-variables-and-a-l</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651252/dealing-with-non-proportional-hazards-in-a-cox-model-with-many-variables-and-a-l</guid>
      <pubDate>Wed, 17 Jul 2024 14:28:42 GMT</pubDate>
    </item>
    <item>
      <title>有哪些情况我们需要避免使用 IQR？</title>
      <link>https://stats.stackexchange.com/questions/633392/are-there-cases-where-we-need-to-avoid-the-usage-of-iqr</link>
      <description><![CDATA[让我们考虑一下四分位距 (IQR)、标准差 (SD) 和平均绝对差 (MAD)。我们知道&quot;最常见的稳健尺度测量之一是四分位距 (IQR)&quot;，而&quot;标准差受异常值的影响很大&quot;，其&quot;崩溃点为 0&quot;。此外，“平均绝对偏差是比标准偏差更稳健的离散度度量”。
当我在近似对称或中度偏斜的分布（没有异常值）中计算 IQR、SD 和 MAD 时，SD 和 MAD 给出的值相似（MAD 返回的值比 SD 略低），并且它们始终低于 IQR 值，并且与 IQR 值相对较远。
可能保留 IQR、SD 和 MAD 并没有什么错，因为它们只是“离散度”一词的不同定义，但如果一个人需要依赖一个数字来表示数据的离散度并问，“该分布的离散度是多少？”，我们应该说出 IQR、SD 和 MAD 的所有值吗？
或者我们应该 - 例如 - 丢弃 IQR，因为它离 SD 和 MAD 相当远，而只传达 SD 或 MAD，因为它们彼此相当接近？
从这个案例中，我会概括并问：是否存在我们需要避免使用 IQR 的情况？]]></description>
      <guid>https://stats.stackexchange.com/questions/633392/are-there-cases-where-we-need-to-avoid-the-usage-of-iqr</guid>
      <pubDate>Fri, 08 Dec 2023 11:24:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在有序 logit 和有序 probit 回归之间进行选择？</title>
      <link>https://stats.stackexchange.com/questions/594183/how-to-choose-between-ordered-logit-and-ordered-probit-regression</link>
      <description><![CDATA[如果因变量是离散序数，如 0-10，则适合使用有序对数或有序概率。它们相似，但解释不同，并且误差分布不同。有序对数服从逻辑分布，有序概率服从正态分布。有序对数有比值比，而有序概率没有。使用哪种方法没有显著差异。
以上是我从不同来源阅读和理解的内容。尽管我想绘制数据的分布图，看看它是服从逻辑分布还是正态分布。
为此，我发现可以绘制下面的图。那么我的问题是：这是在有序 logit 或有序 probit 之间进行选择的好方法吗？
library(effects)
library(fitdistrplus)

wvs.data = head(WVS) # 来自 effects 包的数据
wvs.data
贫困 宗教 学位 国家 年龄 性别
1 1 是 否 美国 44 男性
2 2 是 否 美国 40 女性
3 1 是 否 美国 36 女性
4 3 是 是 美国 25 女性
5 1 是 是 美国 39 男性
6 2 是 否 美国 80 女性

wvs.data$poverty = as.numeric(wvs.data$poverty)

fit1 &lt;- fitdist(wvs.data$poverty, &quot;norm&quot;)
fit2 &lt;- fitdist(wvs.data$poverty, &quot;logis&quot;)

par(mfrow=c(2,2))
denscomp(list(fit1, fit2),legendtext = c(&quot;Normal&quot;, &quot;Logistic&quot;), 
fitcol = c(&quot;green&quot;, &quot;blue&quot;)) 
qqcomp(list(fit1, fit2),legendtext = c(&quot;Normal&quot;, &quot;Logistic&quot;), 
fitcol = c(&quot;green&quot;, &quot;blue&quot;)) 
cdfcomp(list(fit1, fit2),legendtext = c(&quot;Normal&quot;, &quot;Logistic&quot;), 
fitcol = c(&quot;green&quot;, &quot;blue&quot;)) 
ppcomp(list(fit1, fit2),legendtext = c(&quot;Normal&quot;, &quot;Logistic&quot;), 
fitcol = c(&quot;green&quot;, &quot;blue&quot;))


par(mfrow=c(1, 1))
descdist(wvs.data$poverty, discrete = FALSE)
汇总统计
------
最小值：1 最大值：3 
中位数：1.5 
平均值：1.666667 
估计标准差：0.8164966
估计偏度：0.8573214 
估计峰度：2.7 

]]></description>
      <guid>https://stats.stackexchange.com/questions/594183/how-to-choose-between-ordered-logit-and-ordered-probit-regression</guid>
      <pubDate>Mon, 31 Oct 2022 18:44:00 GMT</pubDate>
    </item>
    <item>
      <title>Google 表格中的相关性分析（数值数据与分类数据）</title>
      <link>https://stats.stackexchange.com/questions/580798/correlation-analysis-numerical-vs-categorical-data-in-google-sheets</link>
      <description><![CDATA[我正在尝试使用 Google 表格查找分类数据和数值数据之间的相关性。CORREL 函数的结果为 0.041。
有人能帮忙从这里开始了解相关性是否有意义吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/580798/correlation-analysis-numerical-vs-categorical-data-in-google-sheets</guid>
      <pubDate>Sat, 02 Jul 2022 15:05:07 GMT</pubDate>
    </item>
    <item>
      <title>具有重叠事件的多元超几何分布</title>
      <link>https://stats.stackexchange.com/questions/545821/multivariate-hypergeometic-distribution-with-overlapping-events</link>
      <description><![CDATA[我有一副52 张扑克牌，我玩的游戏需要特定牌类的组合来组成组合。
例如：我抽5 张牌作为样本手牌，我需要恰好1 张杰克和1 张红心来组成组合。
我可以使用多元超几何分布，通过使用以下数字，找到打开 1 张随机杰克和 1 张随机红心的可能性：

手牌大小 n：5
牌组大小 M：52
成功杰克：1
可能的杰克：4
成功红心：1
可能的红心：13

结果是0.0020%（非常低，因为我只想要 1 张）。
问题是红心杰克在杰克和红心类别中都有可能成功，所以他会在组合中成功出现两次。

我该怎么做才能确保这种情况不会发生？
是否可以将红心杰克算作两个类别中的成功，这样我就不需要额外的红心或杰克了？

//编辑//
我想我已经掌握了窍门，但需要在实践中测试一下。
我仍然从 52 张牌 的牌堆中抽出 5 张牌 作为样本手牌。但现在我改变了标准，所以我需要

1 张红心（共 13 张）
1 张杰克（共 4 张）
1 张国王或王后（共 8 张）
1 张梅花或黑桃（共 26 张）
&quot;+ 1 个其他&quot;

据我所知，这将导致 24 个成功结果（4！如果我错了，请纠正我）。我不会在这里全部写出来，只是想知道我是否使用了正确的方法
成功的结果之一将由以下组合组成：
1 张红心（不是杰克、皇后或国王）、1 张梅花或黑桃杰克、1 张红心皇后和1 张梅花或黑桃国王或皇后。
$10\times 2\times 1\times 4 \times {52-10-1-31 \choose 1}=800$（-31 是因为它们此时都是重叠事件，除了 A-10 中的方块）
当我计算出所有 24 个结果时，概率将按以下方式计算：$\frac{800+outcome2+outcome3+.....outcome&#39;n}{2598960}$
这正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/545821/multivariate-hypergeometic-distribution-with-overlapping-events</guid>
      <pubDate>Fri, 24 Sep 2021 09:28:58 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 ICC 来衡量一组（或多或少）相关项目的评级者间一致性？</title>
      <link>https://stats.stackexchange.com/questions/524948/how-can-i-use-the-icc-as-a-measure-for-inter-rater-agreement-on-a-set-of-more-o</link>
      <description><![CDATA[我对使用 ICC 进行评分者间一致性测试有疑问。
我试图测试我的研究参与者（评分者）是否对一个虚构人物的性格做出类似的评分 - 想象一下性格概况 - 在各种区间尺度项目上（在我看来，这些项目是“案例”）。我使用 ICC(2,1)，绝对一致性，因为我想将其推广到来自同一人群（即一般人群）的其他评估者。
在我的分析中，我注意到当评估的项目较少时，ICC 总是会下降。
假设我的 50 位评估者首先根据 10 个社会价值观对他们的重要性对角色进行评估——ICC 相当不错！
但是当 50 位评估者根据 2 个项目（心理健康和身体健康）对角色的假定健康状况进行评估时，ICC 接近于零。
在后一种情况下，两个变量都高度相关，这可能与此有关。
所以，我的问题是：

案例数量较少（或数量太少）是否对 ICC 有害。
项目之间的高度相互相关性是否正确（案例）对 ICC 有负面影响吗？
如果是这样，创建高度相关变量的平均分数然后使用 ICC(2,k) 是否有意义？（尽管在我的例子中，这不起作用，因为它会给我留下一个项目（案例），而 ICC 不会计算它。

感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/524948/how-can-i-use-the-icc-as-a-measure-for-inter-rater-agreement-on-a-set-of-more-o</guid>
      <pubDate>Wed, 19 May 2021 12:19:03 GMT</pubDate>
    </item>
    </channel>
</rss>