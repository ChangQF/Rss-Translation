<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Mon, 11 Mar 2024 18:16:50 GMT</lastBuildDate>
    <item>
      <title>概率如何随长度变化？</title>
      <link>https://stats.stackexchange.com/questions/642334/how-does-probability-scale-with-length</link>
      <description><![CDATA[假设我们有一个单位长度的概率，即长度为 1 公里的电路段在一年内起火的概率为 0.01%。如果我们将长度加倍到 2 公里，我认为我们可以使用二项式分布来获得新段的点火概率。如何计算非整数倍数的着火风险？例如 1.25 公里路段还是 0.3 公里路段？预先感谢您的帮助:)]]></description>
      <guid>https://stats.stackexchange.com/questions/642334/how-does-probability-scale-with-length</guid>
      <pubDate>Mon, 11 Mar 2024 17:17:49 GMT</pubDate>
    </item>
    <item>
      <title>单次测量的方差</title>
      <link>https://stats.stackexchange.com/questions/642331/variance-of-a-single-measurement</link>
      <description><![CDATA[假设我有一个 $n$ 个数据点的集合：$x_i, y_i, i = 0, 。 ..、n-1$ 和 $x_0 &lt; x_1 &lt; ...&lt; x_{n-1}$。 $x_i$ 是独立数据，$y_i$ 是相关数据（测量值）。 
在线性回归和平滑样条的背景下，我已经看到了一些参考文献（如下所示），其中 $\sigma_i^2$ 的概念是“与每个测量相关的方差 $y_i$。”
例如，在 NR p781, eq (15.2.2) 中，讨论线性回归，卡方评价函数给出为：
$$\chi^2(a, b) = \sum_{i=0}^{n - 1}\left(\frac{y_i - a - bx_i}{\sigma_i } \右）^2$$
文本中的描述是“我们假设与每个测量$y_i$相关的不确定性$\sigma_i$” span&gt; 已知...”
同样，在 SS p 177 的 eq (2) 中，讨论平滑样条，最小化条件给出如下：
$$\sum_{i = 0}^{n - 1}\left(\frac{g(x_i) - y_i}{\delta y_i} \right)^2 \leq新元$
文本中的描述是“如果可用，应该使用 $\delta y_i$ 纵坐标标准差的估计值 $n$ 数据点，并且必须估计 $\sigma_i$ （或 $\delta y_i$），而不是事先知道或提供它们。
我的问题是，如何做到这一点？
我目前正在使用 $\sigma_i = |y_i - \bar{y}|$ 估算值，其中  $\bar{y}$ 是“最近邻居” $y_{i-1}$、$y_i$ 和 $y_{i+1}$，但这感觉不太对劲。如何更正确/准确地估计每个 $y_i$ 的 $\sigma_i$？
参考文献
[NR]：威廉等人出版社。 (2007)数值食谱，3e。剑桥大学出版社。
[SS]：赖因施，克里斯蒂安。 (1967)“通过样条函数进行平滑”，《数值数学》，10，第 177-183 页。]]></description>
      <guid>https://stats.stackexchange.com/questions/642331/variance-of-a-single-measurement</guid>
      <pubDate>Mon, 11 Mar 2024 17:10:35 GMT</pubDate>
    </item>
    <item>
      <title>视觉变压器过拟合，多次实验都无法找出原因</title>
      <link>https://stats.stackexchange.com/questions/642329/vision-transformer-overfitting-cannot-figure-the-reason-why-as-many-experiments</link>
      <description><![CDATA[我正在修改后的视觉变换器模型上训练大约 1000 个通道的成像数据。
预处理
我的样本数量有限，因为我只有 10 个可用图像 (~200x200x1000)，我已将这些图像转换为补丁，生成约 15k 个补丁，每个补丁都有关联的标签和通过上采样的平衡数据集。我还在通道上执行了 PCA 以降低维度。由于我使用的模型不接受小于通道数的补丁大小（例如 8x8x32），因此我对补丁进行了插值（例如 8x8x32 到 32x32x32）。当前集包含 6 个训练、2 个验证和 2 个测试。
培训
目前，这些是我迄今为止最好结果的训练和验证曲线。为这些结果生成的补丁大小为 8x8x25，50% 重叠，训练了 100 个周期：
训练损失
val 准确度
val 平衡精度
val f1
价值损失
问题&amp;尝试
我的问题是，了解如何推进这些结果。该模型似乎是基于验证指标进行训练和学习的。然而，当我将训练时间增加到 200 个 epoch 时，模型似乎始终稳定在 ~0.3-0.4 验证平衡精度，而训练则稳定在 ~0.9。
我尝试过的：

不同的补丁大小（4x4、8x8、16x16 等）
通过 PCA 实现不同的通道大小（8、16、32 等...）
生成补丁时的不同重叠（20%、50% 等）
降低学习率
降低权重衰减
辍学率增加
应用提前停止
平衡数据集
数据增强
权重衰减

这些是我尝试过提高性能的一些方法。然而，它反而导致了较差的表现，例如训练早期的稳定和更极端的波动。人们可以肯定地说我的模型过度拟合了。对于我拥有的数据集来说，这个模型是否太复杂了，因为它有大约 22M 参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/642329/vision-transformer-overfitting-cannot-figure-the-reason-why-as-many-experiments</guid>
      <pubDate>Mon, 11 Mar 2024 16:49:47 GMT</pubDate>
    </item>
    <item>
      <title>因果推理和倾向评分</title>
      <link>https://stats.stackexchange.com/questions/642327/causal-inference-and-propensity-score</link>
      <description><![CDATA[我试图理解鲁宾的因果模型，但我无法在某些概念之间建立联系。
因果推理的问题在于计算反事实，即知道在没有治疗/有治疗的情况下会出现什么结果。
因果效应是个体的（且不可观察），因此我们对两种总体效应更感兴趣：ATE 和 ATT。如果治疗分配是独立的，则消除选择偏差，因此 ATT=ATE（随机化）。在因果推理方法中，我们尝试重现随机化（尽可能控制选择偏差）。
为此，我们可以计算倾向得分并应用各种方法（匹配、IPTW、stratistifaction）。
我无法在 ATT/ATE 和倾向评分方法之间建立联系：

为什么逻辑回归（然后是匹配、IPTW 或分层）可以减少这种偏差？
这与反事实有何关系？我们不应该尝试估计一下吗？
为什么根据您要估算 ATT 还是 ATE 的不同而有不同的方法？因为如果你想消除偏差，那么 ATT=ATE。

在我看来，很难将这些方法与鲁宾的一般模型联系起来。
感谢您在这个问题上给我启发。]]></description>
      <guid>https://stats.stackexchange.com/questions/642327/causal-inference-and-propensity-score</guid>
      <pubDate>Mon, 11 Mar 2024 16:27:36 GMT</pubDate>
    </item>
    <item>
      <title>时间序列数据 - 确定最佳平均时间</title>
      <link>https://stats.stackexchange.com/questions/642326/time-series-data-determining-best-averaging-time</link>
      <description><![CDATA[我是处理时间序列数据的新手，需要一些指导来确定传感器的最佳平均时间。我有一个每 1 秒输出数据的传感器。我想确定最佳平均时间（例如 10 秒或 30 秒或 1 分钟）以获得稳定的读数并最大限度地减少数据噪声。我读过“艾伦方差”。我想知道是否有更好的统计数据可以使用。]]></description>
      <guid>https://stats.stackexchange.com/questions/642326/time-series-data-determining-best-averaging-time</guid>
      <pubDate>Mon, 11 Mar 2024 16:26:13 GMT</pubDate>
    </item>
    <item>
      <title>FD 估计器：手动一阶差分与 plm</title>
      <link>https://stats.stackexchange.com/questions/642325/fd-estimator-manual-first-differencing-versus-plm</link>
      <description><![CDATA[我正在研究面板数据的一阶差分 (FD) 估计器（仅两个时间段）。
我手动计算了每个变量（因变量和两个回归变量）的一阶差分，然后对一阶差分模型运行 OLS：
mydata$l_y &lt;- 滞后(mydata$y, -1)
mydata$l_x1 &lt;- 滞后(mydata$x1, -1)
mydata$l_x2 &lt;- 滞后(mydata$x2, -1)

mydata$delta_y &lt;- mydata$y - mydata$l_y
mydata$delta_x1 &lt;- mydata$x1 - mydata$l_x1
mydata$delta_x2 &lt;- mydata$x2 - mydata$l_x2

fd1 &lt;- lm(delta_y ~ 0 + delta_x1 + delta_x2, 数据 = mydata)
coeftest(fd1, vcov=vcovHC(fd1, 类型=“HC0”))

然后我从 R 上的 plm 包运行 FD 估计，但得到了完全不同的结果：
fd2 &lt;- plm(y ~ 0 + x1 + x2, data = mydata, model=“fd”)
coeftest(fd2, vcov=vcovHC(fd2, 类型=“HC0”))

我很难理解为什么估计值不同。任何提示将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/642325/fd-estimator-manual-first-differencing-versus-plm</guid>
      <pubDate>Mon, 11 Mar 2024 16:25:25 GMT</pubDate>
    </item>
    <item>
      <title>(1+X)^N 的 PDF，其中 X ~ 均匀(-0.01, 0.01)</title>
      <link>https://stats.stackexchange.com/questions/642324/pdf-of-1xn-where-x-uniform-0-01-0-01</link>
      <description><![CDATA[我想用以下代码模拟价格：
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

最终价格 = []

对于范围（1000）内的 i：
    安培=0.01
    长度 = 10000
    diff = np.random.uniform(-0.01, 0.01, 长度)
    价格 = np.cumprod(1 + diff)
    Final_price.append(价格[-1])

plt.hist（最终价格，bins=100）
plt.show()

最终价格具有以下分布：

&lt;小时/&gt;
我从这篇论文中找到了以下内容 对于问题 2。

更新
我用下面的代码运行了模拟，结果非常令人惊讶：在每一步，变化均匀分布在-1%和1%之间，但最后，810 / 1000最终小于1，并且190 比 1 大。这非常违反直觉
导入 matplotlib.pyplot 作为 plt
将 numpy 导入为 np

Y = []
对于范围（1000）内的 i：
    X = np.random.uniform(0.99, 1.01, 100000)
    Y.append(np.prod(X))
Y = np.array(Y)
更大 = 总和(Y &gt; 1)
较小 = 总和(Y &lt; 1)
plt.title(f&quot;大于 1: {bigger}, 小于 1: {smaller}&quot;)
plt.hist(Y, 100)
plt.show()

]]></description>
      <guid>https://stats.stackexchange.com/questions/642324/pdf-of-1xn-where-x-uniform-0-01-0-01</guid>
      <pubDate>Mon, 11 Mar 2024 16:20:46 GMT</pubDate>
    </item>
    <item>
      <title>帮助假设方差结果相等的 T 检验（p 值和 t 临界值不会得出相同的答案）</title>
      <link>https://stats.stackexchange.com/questions/642322/help-with-t-test-assuming-equal-variance-results-p-value-and-t-critical-value-n</link>
      <description><![CDATA[
|男性分数|女性分数|
| -------- | -------------- |
| 3.13 | 4.53
3.95 | 3.95 4.34
3.61 | 3.61 4.26
2.61 | 2.61 4.63
3.50 | 3.50 4.53
4.21 | 4.21 4.26
3.68 | 3.68 3.76
4.00 | 3.68
2.82 | 2.82 3.82
4.58 | 4.58 4.26
3.84 | 3.84 3.97
3.68 | 3.68 4.63
3.89 | 3.89 4.92
3.45 | 3.45 4.74
4.87 | 4.87 3.82
3.42 | 3.42
4.05 |
t 检验：假设方差相等的两个样本
男性平均得分 - 3.72291021671827 |女性平均得分 - 4.27719298245614
男性分数方差 - 0.32610090435066 |方差女性分数 - 0.152836037462076
观察男性得分 - 17 |观察女性得分 - 15
合并方差 0.245243966
假设平均差 0
DF 30
t统计-3.159565118
P(T&lt;=t) 一尾 0.001796723
t 关键单尾 1.697260887
P(T&lt;=t)二尾0.003593446
t 临界二尾 2.042272456
使用 p 值和负 t 值与 t 临界值，我的结果据说有显着差异，但使用正 t 值与 t 临界正值，结果并不显着。我做错了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/642322/help-with-t-test-assuming-equal-variance-results-p-value-and-t-critical-value-n</guid>
      <pubDate>Mon, 11 Mar 2024 16:03:29 GMT</pubDate>
    </item>
    <item>
      <title>GLM 交互作用图的解释</title>
      <link>https://stats.stackexchange.com/questions/642320/interpretation-of-interaction-plot-from-glm</link>
      <description><![CDATA[我正在 R 中进行调节分析。我的因变量是比率（Diffcount/totalcount），自变量是指数（连续），调节变量是分类变量（3 个级别）。我使用 MASS 中的 glm.nb 拟合了负二项式回归模型，并使用了如下所示的偏移项：
glm.nb(Diffcount~Index1*factor3 + offset(log(totalcount)), data = dt)

我使用 interactions 包中的 interact_plot 为该模型生成了交互图。
我真正困惑的是 y 轴的解释。该值是否代表比率（即 Diffcount/totalcount）、概率或其他内容？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642320/interpretation-of-interaction-plot-from-glm</guid>
      <pubDate>Mon, 11 Mar 2024 15:29:24 GMT</pubDate>
    </item>
    <item>
      <title>“偏差-方差权衡”和“一致模型选择”之间有什么关系？</title>
      <link>https://stats.stackexchange.com/questions/642287/whats-the-relationship-between-bias-variance-tradeoff-and-consistent-model-s</link>
      <description><![CDATA[我对“偏差-方差权衡”和“偏差-方差权衡”之间的关系感到非常困惑。和“一致的模型选择”。根据我目前的解释，处理“偏差-方差权衡”的最终目标是就是要有良好的样本外预测。也就是说，我们要避免过拟合（复杂模型，高方差）和欠拟合（简单模型，高偏差），以便我们的估计模型能够对我们的目标做出良好的预测 $ Y$ 在之前未使用过的全新数据集上使用回归器 $X$。在这个过程中，我们并不关心“真实模型”是什么。 $Y$ 和 $X$ 之间是。
另一方面，“一致的模型选择”假设 $Y$ 和 $X$ 之间存在真实关系，用 $Y=X^{*&#39;}\beta+\epsilon$ 对于某些 $\beta$，其中 $X^*$ 是 $X$ 的子集。目标是使用某些标准（例如 BIC）找出这个正确的模型（回归量的正确子集），众所周知，当样本量趋于无穷大时，该标准可以找到概率为 1 的正确模型。因此，在更强的假设下，一致模型选择的主题似乎是一个更狭窄的领域，并且具有完全不同的最终目标。
令我困惑的是，我经常看到 BIC 标准的说明是试图平衡偏差（样本拟合良好）和方差（模型复杂性）。这样的讨论似乎暗示 BIC 是为了改进样本外预测而构建的。就我个人而言，选择正确的模型与良好的样本外预测并没有太大关系。错误的模型在样本外预测方面也可能表现得同样好甚至更好。我的问题是，这些解释正确吗？如果是，那么当我们谈论在一致模型选择的背景下平衡偏差和方差时，我们实际上意味着什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/642287/whats-the-relationship-between-bias-variance-tradeoff-and-consistent-model-s</guid>
      <pubDate>Mon, 11 Mar 2024 09:36:40 GMT</pubDate>
    </item>
    <item>
      <title>溢出效应作为购买力平价（PPP）的检验</title>
      <link>https://stats.stackexchange.com/questions/642279/spillovers-as-test-of-purchasing-power-parity-ppp</link>
      <description><![CDATA[VAR 的变换系数产生脉冲响应，可用于在 Diebold 和 Yilmaz (DY) 2012 年论文“给予比接受更好”。考虑在记录的即期汇率和价格指数差异的二方程 VAR 中测试相对购买力平价。 DY 溢出是否有现成的解释作为购买力平价的确认/拒绝，包括比例性和对称性的假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/642279/spillovers-as-test-of-purchasing-power-parity-ppp</guid>
      <pubDate>Mon, 11 Mar 2024 04:52:14 GMT</pubDate>
    </item>
    <item>
      <title>一阶、二阶、三阶差分背后的直觉。何时使用它们？</title>
      <link>https://stats.stackexchange.com/questions/642277/intuition-behind-the-first-second-third-order-differencing-when-to-use-them</link>
      <description><![CDATA[我正在处理时间序列数据，出于好奇，我获取了数据的一阶、二阶和三阶差异。不过我不太清楚它们什么时候用？
我也想知道差异背后的直觉。第一个顺序很清楚；这就是区别。
$$\begin{方程} \begin{对齐}
\Delta X_t &amp;= X_t - X_{t-1}。
\end{对齐} \end{方程}$$
此处描述的第二个是给定时间点的序列曲率。
$$\begin{方程} \begin{对齐}
\Delta^2 X_t = \Delta (\Delta X_t)
&amp;= \Delta (X_t-X_{t-1}) \\[6pt]
&amp;= \Delta X_t - \Delta X_{t-1} \\[6pt]
&amp;= (X_t-X_{t-1})-(X_{t-1}-X_{t-2}) \\[6pt]
&amp;= X_t - 2X_{t-1} + X_{t-2}。 \\[6分]
\end{对齐} \end{方程}$$
但我实际上不知道第三个差异的含义以及何时使用第一、第二和第三个差异。
$$\begin{方程} \begin{对齐}
\Delta^3 X_t = \Delta (\Delta^2 X_t)
&amp;= \Delta (X_t - 2X_{t-1} + X_{t-2}) \\[6pt]
&amp;= \Delta X_t - 2\Delta X_{t-1} + \Delta X_{t-2} \\[6pt]
&amp;= (X_t - X_{t-1}) - 2(X_{t-1} - X_{t-2}) + (X_{t-2} - X_{t-3}) \\[6pt ]
&amp;= X_t - 3X_{t-1} + 3X_{t-2} - X_{t-3}。 \\[6分]
\end{对齐} \end{方程}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/642277/intuition-behind-the-first-second-third-order-differencing-when-to-use-them</guid>
      <pubDate>Sun, 10 Mar 2024 23:22:58 GMT</pubDate>
    </item>
    <item>
      <title>多重分位数回归的必要诊断</title>
      <link>https://stats.stackexchange.com/questions/642273/necessary-diagnostics-of-multiple-quantile-regression</link>
      <description><![CDATA[我想知道多分位数回归模型需要哪些统计数据。
我正在考虑创建一个模型，例如使用 quantreg R 包：
模型 &lt;- rq(y ~ x1 + x2 + x3, tau = seq(0.1, 0.9, by = 0.1), data = df, method=&#39;fn&#39;)

要获得所有 tau 中每个自变量的估计值、95% 置信区间和 $p$ 值，我只需使用摘要：
summary(model, se = “boot”)

并将结果报告为：

表格将显示上述所有结果
这些图显示了 tau 中自变量的估计系数，置信区间为 95%。

问题：

我的方法适合此类统计吗？
多重分位数回归模型是否需要任何诊断图或测试来证明其良好的结构？
]]></description>
      <guid>https://stats.stackexchange.com/questions/642273/necessary-diagnostics-of-multiple-quantile-regression</guid>
      <pubDate>Sun, 10 Mar 2024 21:53:08 GMT</pubDate>
    </item>
    <item>
      <title>分位数回归模型中的相互作用分析</title>
      <link>https://stats.stackexchange.com/questions/642272/analysis-of-interactions-in-quantile-regression-models</link>
      <description><![CDATA[我拥有一个 n ~10,000 的大型数据集。我的目标是使用 quantreg R 包中的 rq() 开发分位数回归模型。我选择的 tau 值范围为 0.1 到 0.9，增量为 0.1。
我正在考虑交互分析：我的模型包括分类自变量和连续自变量 - 总共 10 个变量。
问题：

我应该对每对因变量（总共 45 个）的潜在交互作用进行分析，还是只对理论上合理的交互作用进行分析？
我应该只分析变量对[例如，qr(y ~ a + b + a*b, data = data, tau=0.5)？] 还是整个模型中的交互？&lt; /里&gt;
是否应对所有感兴趣的 tau 值进行分析？
如何验证潜在的交​​互是否可以提高模型的性能？ AIC.rq() 合适吗？

我知道对大量交互进行分析可能会导致许多误报关联。我之前删除了表现出多重共线性的变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/642272/analysis-of-interactions-in-quantile-regression-models</guid>
      <pubDate>Sun, 10 Mar 2024 21:05:42 GMT</pubDate>
    </item>
    <item>
      <title>通过归一化方法改变的主成分可以用于通过 SVD 构造原始数据形状吗</title>
      <link>https://stats.stackexchange.com/questions/642025/can-principal-components-changed-by-a-normalization-method-be-used-to-construct</link>
      <description><![CDATA[我计划使用一种名为 Harmony 的算法，该算法专为数据标准化而设计，特别是在单细胞数据分析的背景。 Harmony 的运行方式是将主成分 (PC) 作为输入并输出校正后的主成分 (PC)。
通常，Harmony 应用于排名前 k 的 PC，以纠正批次效应或其他变异源。但是，我想保留标准化后的原始数据结构。为此，我会将从我的数据集生成的所有 PC 输入到 Harmony 中。我将使用奇异值分解 (SVD) 来生成所有可能的主成分。
矩阵A的SVD可以表示为：
$$
A = 美国V^T
$$
这里，U和V是正交矩阵，而S是包含奇异值的对角矩阵。为了创建PC，我将乘以U S，而不是执行k-rank近似子集PC正如我见过的所有使用和谐的方法一样。
这些PC将输入到和声，从而产生输出PC&#39;。
$$
PC \rightarrow 和谐 \rightarrow PC&#39;
$$
经过Harmony处理后，得到归一化的PC（PC&#39;）。我的假设是标准化分量 PC&#39; 可以等效地表示为修改矩阵 U&#39; 和 S&#39; 的乘积，这意味着：
$$
PC&#39; \equiv U&#39;S&#39; \equiv (US)&#39;
$$
最终目标是以标准化形式重建原始数据集，我认为可以通过以下方式实现：
$$
(美国)&#39; V^T = A&#39;
$$
我向社区提出的问题是：

考虑到 Harmony 标准化了 PC (PC -&gt; PC&#39;)，将标准化 PC (PC&#39;) 等同于 $(US)&#39;$ 然后使用它以标准化形式重建原始数据矩阵，如 $(US)&#39; V^T = A&#39;$?
我使用所有 PC 通过 Harmony 进行标准化并随后重建数据集的方法是否存在任何概念或数学缺陷？
]]></description>
      <guid>https://stats.stackexchange.com/questions/642025/can-principal-components-changed-by-a-normalization-method-be-used-to-construct</guid>
      <pubDate>Thu, 07 Mar 2024 02:27:39 GMT</pubDate>
    </item>
    </channel>
</rss>