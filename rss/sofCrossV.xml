<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 18 Sep 2024 18:21:37 GMT</lastBuildDate>
    <item>
      <title>频率论者对假设检验的正确解释是什么？</title>
      <link>https://stats.stackexchange.com/questions/654560/what-is-the-correct-frequentist-interpretation-of-hypothesis-testing</link>
      <description><![CDATA[我理解频率论者对置信水平为 X% 的置信区间的解释（我认为）：想象一下，随机抽取许多样本，并按照程序计算所有样本的置信区间。X% 的区间将包含真实参数。
但是，当我尝试以类似的方式解释假设检验时，我感到很困惑。我觉得应该有类似的解释，因为检查值 $\mu_0$ 是否在 95% 的置信区间内，在数学上与检查您是否会拒绝 $H_0: \mu = \mu_0$ 的假设相同。
我的思维过程是定义假设检验的程序，想象重复多次，看看我们正确的频率是多少。然而，我们正确的频率取决于真正的$\mu$是什么，这导致我感到困惑。
标准的频率学派解释是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654560/what-is-the-correct-frequentist-interpretation-of-hypothesis-testing</guid>
      <pubDate>Wed, 18 Sep 2024 18:14:12 GMT</pubDate>
    </item>
    <item>
      <title>拟合非平稳 AR(1) 过程</title>
      <link>https://stats.stackexchange.com/questions/654559/fitting-a-non-stationary-ar1-process</link>
      <description><![CDATA[几乎所有的时间序列文献都是在尝试拟合任何内容之前对非平稳时间序列进行差分。
假设我们想要拟合自回归过程生成的数据：
$$X_{t+1} = aX_t + e_t$$
并且我们知道$a &gt; 1$。直接拟合有什么问题？残差会不会通过单位根检验并且不自相关？当$a = 1$时会怎样？核心问题是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654559/fitting-a-non-stationary-ar1-process</guid>
      <pubDate>Wed, 18 Sep 2024 17:06:25 GMT</pubDate>
    </item>
    <item>
      <title>样本均值还是 James-Stein 估计量？</title>
      <link>https://stats.stackexchange.com/questions/654558/sample-mean-or-james-stein-estimator</link>
      <description><![CDATA[我有一个简单的实际问题，我将其发布在 Quant Finance SE 中（也发布在这里，因为我没有得到答案）。
假设我们有 $n\geq3$ 个股票金融时间序列（相关或不相关）（例如，$n$ 只股票的 10 个不同收益时间序列，每个序列都有 $T$ 个观测值）。目标是估计每个金融时间序列的平均值，即$\hat{\mu}_{i}$，$i=1,2,...n$。
显然，最直接的方法是计算每个系列的样本平均值，即$\hat{\mu}_{i}=\frac{x_1+x_2+...x_T}{T}$，其中$i=1,2,...n$。然而，James-Stein 估计量表明，如果 $n\geq3$，那么最好将所有这些 $n$ 金融时间序列汇集在一起​​，然后集体估计均值向量。
您会使用哪种方法，为什么？据我所知，对于这样一个简单的问题，所有从业者都使用第一种方法（样本均值），我不知道有谁应用了第二种方法。因此，这是否意味着这是由于 James-Stein 更像是一个理论结果，并且几乎不适用或不太受欢迎？如果不是，那么为什么不使用 James-Stein 呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/654558/sample-mean-or-james-stein-estimator</guid>
      <pubDate>Wed, 18 Sep 2024 16:40:58 GMT</pubDate>
    </item>
    <item>
      <title>计算二项式 GLM 中变量子集解释的变化</title>
      <link>https://stats.stackexchange.com/questions/654557/computing-the-variation-explained-by-a-subset-of-the-variables-in-a-binomial-glm</link>
      <description><![CDATA[我正在处理自然语言数据。具体来说，我正在研究一种含义可以用两种方式表达的情况，例如我知道这是真的与我知道那那是真的。在这个假设的例子中，我的因变量是二进制的（那与零），我有两个独立变量：主句的人称（第一人称​​我与第二人称与第三人称）和主句中使用的动词（知道与认为与相信与...）。对于每个组合，我都从语料库中收集了出现的次数：



人
动词
# 那个
# 零




1
知道
345
246


...
...
...
...



我想测试的假设是，that 和 zero 之间的选择取决于 Person 变量（具体来说，第一人称的 that ： zero 的比率高于其他两个人称的）。我假设主句中的动词可能具有独立效果（例如 know），目前我对此不感兴趣。
为此，我使用 R 拟合二项式 GLM：
# 生成示例值：
data &lt;- data.frame(Person=rep(c(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;), 10), Verb=sort(rep(LETTERS[0:10], 3)), Freq_that=sample(100:500, 30), Freq_zero=sample(100:500, 30))

data$Person &lt;- relevel(as.factor(data$Person), ref=&quot;1&quot;)
model &lt;- glm(formula = cbind(Freq_that, Freq_zero) ~ Person + Verb, family = binomial, data = data)

show(summary(model))

这给了我如下输出：
调用：
glm(formula = cbind(Freq_that, Freq_zero) ~ Person + Verb, family = binomial, 
data = data)

偏差残差：
最小值 1Q 中位数 3Q 最大值 
-10.3545 -3.5826 -0.6237 2.9716 12.2818 

系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -0.63602 0.05389 -11.802 &lt; 2e-16 *** 人2 -0.05256 0.03686 -1.426 0.153811 人3 0.18248 0.03542 5.151 2.59e-07 *** 动词B 0.77175 0.07130 10.824 2e-16 *** 动词 C 0.45441 0.06509 6.981 2.93e-12 *** 动词 D 0.81523 0.06510 12.523 2e-16 *** 动词E 0.65077 0.06957 9.354 &lt; 2e-16 ***
VerbF 0.41065 0.07201 5.703 1.18e-08 ***
VerbG 1.20326 0.07008 17.169 &lt; 2e-16 ***
VerbH 0.19839 0.06627 2.994 0.002755 ** 
VerbI 0.08633 0.07340 1.176 0.239525 
VerbJ 0.23047 0.06540​​ 3.524 0.000425 ***
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（二项式系列的分散参数取为 1）

零偏差：29 个自由度上的 1516.69
残差偏差：18 个自由度上的 898.06
AIC：1125.4

Fisher 评分迭代次数：4

现在，据我了解：

Person3 的 $p$ 值表示有显著影响（相对于第一人称），而 Person2 的 $p$ 值则不表示。
VerbB 到 VerbJ 的系数并不那么有趣，因为它们与任意选择的 VerbA。
我可以使用 exp(model$coefficients) 计算 Person3 的几率比：$1.200$。这表明，使用 that（而不是零）在第三人称中实际上比在第一人称中高出约 20%（与预测相反 - 当然这些是随机数据）。
我可以使用零偏差和残差来计算此模型解释的变异量，即 $1 - \frac{898.06}{1516.69} = 0.41$。

但是，最后一个数字捕获了整个模型解释的变异量。我还对仅由 Person2 和 Person3 解释的变化量感兴趣：有多少变化是由人称差异引起的，又有多少是由动词引起的？我该如何计算这个？
起初我以为我可以拟合一个没有动词变量的模型（formula = cbind(Freq_that, Freq_zero) ~ Person），但这给了我不同的系数，所以这不可能是正确的。
我认为这与计算逻辑回归中预测变量解释的方差是同一个问题，但答案对于我的理解水平来说不够详细。]]></description>
      <guid>https://stats.stackexchange.com/questions/654557/computing-the-variation-explained-by-a-subset-of-the-variables-in-a-binomial-glm</guid>
      <pubDate>Wed, 18 Sep 2024 15:57:46 GMT</pubDate>
    </item>
    <item>
      <title>非中心广义卡方的 R 代码</title>
      <link>https://stats.stackexchange.com/questions/654555/r-code-for-non-central-generalized-chi2</link>
      <description><![CDATA[我正在寻找 R 中的一些代码，这些代码允许我获得广义非中心卡方分布的密度和累积概率。
有什么建议吗？
谢谢，
Juan]]></description>
      <guid>https://stats.stackexchange.com/questions/654555/r-code-for-non-central-generalized-chi2</guid>
      <pubDate>Wed, 18 Sep 2024 15:49:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么项目反应理论不依赖于代表性样本，或者为什么它是“样本独立的”？</title>
      <link>https://stats.stackexchange.com/questions/654551/why-does-item-response-theory-not-depend-on-a-representative-sample-or-why-is-i</link>
      <description><![CDATA[多种资源描述了项目反应理论 (IRT) 并将其与传统测试理论 (CTT) 进行了比较，指出 CTT 依赖于代表性样本，而 IRT 则不然。

样本独立性：传统统计数据都依赖于样本，并且无法用于不同的样本；而 IRT 的结果与样本无关。在线性变换内。两个不同能力水平的样本可以轻松转换为同一量表。
项目属性不依赖于代表性样本。


这些资源似乎将此陈述为两种理论和建模方法之间的事实区别，但我不明白为什么这必然是正确的。项目参数在不同人群之间可能存在不同差异，难道不是这样吗？这种说法的重点是，如果没有发生差异项目功能 (DIF)，那么您可以有信心地说它不依赖于代表性样本吗？但是，如果这是对那条的解释，我仍然不明白，因为 CTT（即 SEM、CFA）也涉及测量不变性的测试。
有人能帮我理解为什么 IRT 不依赖于代表性样本或“样本独立”吗？
资源：
https://www.publichealth.columbia.edu/research/population-health-methods/item-response-theory
https://assess.com/what-is-item-response-theory/]]></description>
      <guid>https://stats.stackexchange.com/questions/654551/why-does-item-response-theory-not-depend-on-a-representative-sample-or-why-is-i</guid>
      <pubDate>Wed, 18 Sep 2024 14:47:00 GMT</pubDate>
    </item>
    <item>
      <title>如何在以下问题中微调集成级超参数？</title>
      <link>https://stats.stackexchange.com/questions/654550/how-to-fine-tune-an-ensemble-level-hyper-parameter-in-the-following-problem</link>
      <description><![CDATA[我有一个相对较小的数据集，包含 4000 个实例。我打算使用集成方法进行分类。我的集成由 5 个不同的分类器组成，并且我有一个集成级超参数 S。
我计划按照以下步骤训练和评估我的集成模型：

将初始数据集分为 70% 训练、15% 验证和 15% 测试。
使用 5 倍交叉验证在训练数据集上训练每个分类器（在每种情况下，在 4 个折叠上进行训练并评估 1 个保留折叠的准确性）。
根据每个分类器在所有 5 个保留折叠（即整个训练数据集）中的平均准确性，确定每个分类器的权重。在权重计算公式中有一个集成级超参数S，初始化为[0,1]内的随机值。
为了微调S，使用上一步计算出的分类器权重，评估集成模型在验证数据集上的性能。更改S的值，根据新的S值重新计算分类器权重，并重新评估集成模型在验证数据集上的性能，并重复，直到集成性能最大化或达到特定的迭代次数。
在确定S的最终值和相应的分类器权重后，评估集成模型在测试数据集（未见数据）上的性能。

我担心的是，超参数S的微调是在每次迭代中使用整个验证数据集进行的。例如，将验证数据集拆分为 3 个子集（考虑到我的数据集很小），然后针对 S 的每个值评估集成在所有 3 个子集中的平均性能，这样是否更合适？或者我上面描述的初始方法是否足够（考虑到数据集的大小较小）？]]></description>
      <guid>https://stats.stackexchange.com/questions/654550/how-to-fine-tune-an-ensemble-level-hyper-parameter-in-the-following-problem</guid>
      <pubDate>Wed, 18 Sep 2024 14:19:20 GMT</pubDate>
    </item>
    <item>
      <title>使用不同的数据集时是否允许使用交叉验证？</title>
      <link>https://stats.stackexchange.com/questions/654548/is-it-allowed-to-use-cross-validation-when-working-with-different-datasets</link>
      <description><![CDATA[如果我有两个具有相同特征但来自不同主题的数据集，并且我想在第一个数据集上训练模型（例如 SVM）并在第二个数据集上测试它，我应该如何计算性能（例如准确度）？我可以在训练和测试过程中使用 K 折交叉验证吗？还是应该只在同一数据集上训练和测试时使用 K 折交叉验证？我的意思是，在数据集中训练模型并在另一个数据集上测试时使用交叉验证是否可以接受？]]></description>
      <guid>https://stats.stackexchange.com/questions/654548/is-it-allowed-to-use-cross-validation-when-working-with-different-datasets</guid>
      <pubDate>Wed, 18 Sep 2024 13:18:29 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 0 至 1 范围内变量的优势比</title>
      <link>https://stats.stackexchange.com/questions/654542/how-to-interpret-odds-ratio-for-variables-that-range-from-0-to-1</link>
      <description><![CDATA[我该如何解释逻辑回归模型中变量的几率比，该变量是一个“比率”，即介于 0 和 1 之间的值？在这种情况下，单位是什么？
例如，假设我正在对篮球投篮数据进行建模，如果球员投篮成功，我的响应变量等于 1，如果投篮不中，则等于 0。此外，我有一个解释变量，即球队到那时为止的投篮准确率，这个变量的范围是 0 到 1。那么，我该如何解释这个变量的系数的几率比？因为我不能说它会增加 1 个单位，因为变量不能超过大于 1 的值。请问有什么关于如何解释这一点的提示吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654542/how-to-interpret-odds-ratio-for-variables-that-range-from-0-to-1</guid>
      <pubDate>Wed, 18 Sep 2024 11:35:11 GMT</pubDate>
    </item>
    <item>
      <title>异方差方差预测常数不应该是</title>
      <link>https://stats.stackexchange.com/questions/654541/heteroscedastic-variance-prediction-constant-where-it-should-not-be</link>
      <description><![CDATA[我正在尝试预测数据集中的异方差噪声。我已经设置了一个 FPN，将方差视为一个附加类。我的数据集是空中语义分割无人机数据集。这是模型：
class FPN(nn.Module):
def __init__(self,coder_name=&quot;resnet34&quot;,coder_weights=&quot;imagenet&quot;,in_channels=1,activation=None,decoder_dropout=0.3):
super(FPN,self).__init__()
self.base_model = smp.FPN(
encoder_name=encoder_name,
encoder_weights=encoder_weights,
in_channels=in_channels,
classes=2,
activation=activation,
decoder_dropout=decoder_dropout
)

def forward(self,x):
mean,var = torch.split(self.base_model(x),1,dim=1)
var = torch.nn. functional.softplus(var)
return torch.cat((mean,var), dim=1)

损失函数是 pytorch 的标准 NLL-Gaussian Loss：
class CustomGaussianLoss(base.Loss):
def __init__(self):
super(CustomGaussianLoss, self).__init__()
self.gaussian_nll_loss = nn.GaussianNLLLoss()

def forward(self, input, target):
mean, var = torch.split(input, 1, dim=1)

loss = self.gaussian_nll_loss(mean, target, var)
return loss 

然而，在第一个 epoch 之后，方差总是预测为每个像素的常数 0.69。像素值在 0 和 1 之间缩放。有趣的是，0.69 大致是数据集跨像素的方差。
鉴于这个数据集，这一切对我来说毫无意义。即使方差大致恒定（但事实并非如此），量级也是完全错误的。有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654541/heteroscedastic-variance-prediction-constant-where-it-should-not-be</guid>
      <pubDate>Wed, 18 Sep 2024 10:38:14 GMT</pubDate>
    </item>
    <item>
      <title>使用螺旋桨计算细胞比例是否显著</title>
      <link>https://stats.stackexchange.com/questions/654540/calculating-if-cell-proportions-are-significant-using-propeller</link>
      <description><![CDATA[我正在使用 propeller，https://rdrr.io/github/Oshlack/speckle/man/propeller.anova.html，来计算肥大细胞与对照组细胞比例之间的显著性。我的模型设计如下。
design &lt;- model.matrix(~0 + grp + md_subset$batch)

我理解不设置截距就没有基线水平，所有分类变量都表示为单独的列。所以我总共有 10 个样本，3 个对照组和 7 个肥大组，它们分 4 个批次完成。我的设计矩阵如下所示：

我对设计矩阵有几个问题。首先，为什么我的设计矩阵中没有 2 列，一列表示条件，该行是否用 0 表示控制，1 表示肥大，一列表示批次，行中用 1、2、3 或 4 表示，因为它们有 4 个批次？我看到的是每个条件都有自己的列，每个批次也是如此。在我看来这像是热编码，但为什么在这种情况下这是必要的？其次，如果热编码是必要的，并且这就是每个变量都有单独列的原因，那么为什么批次 1 列不存在，因为我的样本 3（第 3 行）是批次 1？这个设计矩阵是否不会考虑批次 1 的影响？
最后，当我运行它时，我得到如下输出：
propeller.anova(prop.transformed, design=design, coef=c(1,2,3,4,5), robust=TRUE,
trend=FALSE, sort=TRUE)



首先，使用设计运行此程序是否意味着我正在查看条件之间每种细胞类型的比例在控制批次效应时有多显著？我之所以问这个问题，是因为根据我的理解，通常在回归分析中，~ 之后的第一个变量是您要测试的变量，任何其他变量都是您想要控制的混杂因素。然而，在 DESeq2 或 edgeR 等包中，我看到控制的混杂因素首先出现，最后一个变量是您要测试响应变量与之相关的变量。此外，这里的 p 值和 F 统计量是否显示了条件对比例的影响有多大，以及它是否显著？标记为 PropMean.* 的每一列表示不同细胞类型的该变量的系数？
我很感激任何帮助和澄清，因为我认为我主要理解但希望得到一些帮助和建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/654540/calculating-if-cell-proportions-are-significant-using-propeller</guid>
      <pubDate>Wed, 18 Sep 2024 09:48:03 GMT</pubDate>
    </item>
    <item>
      <title>$\mathbb{E}(​​|X|)$ 和 $\mathbb{E}(​​|X|+|Y|)$ 的展开</title>
      <link>https://stats.stackexchange.com/questions/654527/expansion-of-mathbbex-and-mathbbexy</link>
      <description><![CDATA[给定一个数值随机变量$X$和$Y$，我对$\mathbb{E}(​​|X|)$和$\mathbb{E}(​​|X| + |Y|)$的展开式有点困惑。
对于 $\mathbb{E}(​​|X|)$，是否
$$\mathbb{E}(​​|X|)= \lim_{n \to \infty}\frac{|X_1|+|X_2|+...|X_n|}{n}$$
或
$$\mathbb{E}(​​|X|)= \lim_{n \to \infty}\frac{|X_1+X_2+...X_n|}{n}?$$
类似地，对于 $\mathbb{E}(​​|X| + |Y|)$，是否
$$\mathbb{E}(​​|X| + |Y|)=\lim_{n \to \infty}\frac{|X_1|+|X_2|+...|X_n|+|Y_1|+...|Y_n|}{n}$$
或
$$\mathbb{E}(​​|X| + |Y|)=\lim_{n \to \infty}\frac{|X_1+X_2+...X_n|+|Y_1+...Y_n|}{n}?$$]]></description>
      <guid>https://stats.stackexchange.com/questions/654527/expansion-of-mathbbex-and-mathbbexy</guid>
      <pubDate>Wed, 18 Sep 2024 05:59:43 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 R 中的逐次试验数据运行重复测量方差分析？</title>
      <link>https://stats.stackexchange.com/questions/654535/how-can-i-run-a-repeated-measures-anova-in-r-with-trial-by-trial-data</link>
      <description><![CDATA[我需要帮助设置数据集并在 R 中运行重复测量方差分析。我当前的数据集是 41 个受试者的试验数据。有一列表示受试者 ID（1-41），一列表示受试者所属的组（“置信度”或“定位”），一列表示相位（“前”或“后”），一列表示滞后位置（1-7），一列表示准确度（0 或 1）。每个受试者有 140 行：其中 70 行来自受试者“前”试验，70 行来自受试者“后”试验。在每组 70 行中，7 个滞后位置（1-7）各有 10 行。准确度是因变量。
我尝试过许多不同的方法，但我认为方差分析一直将数据视为每次试验都是不同的受试者。残差或 DenDF 中的 df 会返回 5166 或 5673 之类的数字，具体取决于我尝试的方法。我对 R 和运行方差分析还很陌生，正在尝试复制已经完成的分析。阶段 * 组 * 滞后的残差 df 应该是 234，而不是 5,000+]]></description>
      <guid>https://stats.stackexchange.com/questions/654535/how-can-i-run-a-repeated-measures-anova-in-r-with-trial-by-trial-data</guid>
      <pubDate>Wed, 18 Sep 2024 00:53:18 GMT</pubDate>
    </item>
    <item>
      <title>如果病例总数有限，则确定抽样规模[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654503/sampling-size-determination-if-total-number-of-cases-is-finite</link>
      <description><![CDATA[我正在尝试确定每个月应审核多少个案例，以便样本量准确代表每年收到的案例总数。
尝试审核员工调查的内容。1400 个案例无法审核，那么审核内部程序和流程内容的合理数量是多少。这是否类似于随机抽样汽车零件以检测公差并尝试根据正在制造的零件总数确定抽样数量？
每年收到 1400 份调查。我使用 calculator.net 样本量计算器来确定样本量。 https://www.calculator.net/sample-size-calculator.html?type=1&amp;cl=95&amp;ci=5&amp;pp=50&amp;ps=1400&amp;x=Calculate
今年的答案是 302 个样本。
25/月。
4 个团队。
6/团队
这种方法正确吗？所以每个团队每个月应该审查 6 个案例？]]></description>
      <guid>https://stats.stackexchange.com/questions/654503/sampling-size-determination-if-total-number-of-cases-is-finite</guid>
      <pubDate>Tue, 17 Sep 2024 19:11:49 GMT</pubDate>
    </item>
    <item>
      <title>比较具有和不具有交互项的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/654485/comparing-linear-mixed-models-with-and-without-interaction-terms</link>
      <description><![CDATA[我想比较具有和不具有交互项的不同模型，看看哪一个最适合我的数据。我只是想检查我的方法是否正确。
我像这样构建我的模型
my_model &lt;- lmer(myoutcome ~ predictor1 + predictor2 + 
predictor3 + covariate1 + (1 | ParticipantID), data = mydata)

my_model2 &lt;- lmer(myoutcome ~ predictor1*predictor2 + 
predictor1*predictor3 + predictor2*predictor3 + covariate1 +
(1 | ParticipantID), data = mydata)

my_model3 &lt;- lmer(myoutcome ~ predictor1*predictor2*predictor3 + 
covariate1 + (1 | ParticipantID), data = mydata)

然后，我会像这样比较它们，看看添加二向和三向交互项是否会改善模型。
anova(my_model, my_model2, my_model3)

我还在考虑简约性、AICc 和对数似然等因素。
我有以下问题：

将所有双向交互项都包含在单个模型中是否正确？
在更复杂的模型中同时指定主效应和交互作用是否正确？ （因此 predictor1*predictor2 而不是 predictor1:predictor2
如果我对所有双向交互都不感兴趣，我是否可以将 my_model2.1 &lt;- lmer(myoutcome ~ predictor1*predictor2 + predictor3 + covariate1 + (1 | ParticipantID), data = mydata) 之类的模型与 model3 进行比较？
我还应该将我的协变量包括在我的交互模型中吗？
在报告主要影响和交互作用时，我被教导要报告第一个模型的主要影响，并且只报告交互模型的交互影响。但是我现在质疑这是否正确。例如，使用上述方法，我得到了以下仅具有固定效应的模型摘要（model_mainef）

 估计 2.5% 97.5% t val. d.f. p

（截距）2.93 2.60 3.25 17.49 99.21 0.00
predictor1 0.04 -0.25 0.34 0.29 66.86 0.78
predictor2 1.07 0.65 1.49 4.96 69.07 0.00
predictor3 0.22 0.04 0.41 2.40 71.43 0.02
covariate1 -0.23 -0.58 0.12 -1.30 69.20 0.20

此摘要包含一个双向交互 (model_int)

Est. 2.5% 97.5% t 值 d.f. p

（截距）2.61 2.27 2.94 15.18 112.75 0.00
预测器1 0.72 0.35 1.09 3.84 68.01 0.00
预测器2 1.70 1.22 2.18 6.94 112.40 0.00
预测器3 0.22 0.04 0.40 2.43 72.87 0.02
协变量1 -0.24 -0.58 0.10 -1.37 70.89 0.17
预测器1：预测器2 -1.32 -1.83 -0.81 -5.05 66.26 0.00

anova(model_mainef, model_int)

npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) 
model_mainef 7 406.98 427.37 -196.49 392.98 
model_int 8 385.94 409.24 -184.97 369.94 23.043 1 1.584e-06 ***


我们可以看到，在仅有固定效应的模型中不显著的变量之一（第二行），在将交互项纳入模型后变得显著（它是交互中的变量之一）。报告结果时，我应该使用第一个还是第二个表中的值？请注意，我不是在谈论解释 - 因为交互作用无论如何都符合主效应，我只是想知道哪些数据应该包含在我的结果表中 :)
提前致谢！
编辑：我有一个 2x2 混合组研究设计，其中一个组间变量（2 个级别）和一个组内变量（2 个级别），因此我使用混合建模。我收集了用于验证性假设检验（即推断统计）的数据]]></description>
      <guid>https://stats.stackexchange.com/questions/654485/comparing-linear-mixed-models-with-and-without-interaction-terms</guid>
      <pubDate>Tue, 17 Sep 2024 13:38:00 GMT</pubDate>
    </item>
    </channel>
</rss>