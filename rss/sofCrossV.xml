<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 04 Oct 2024 15:18:28 GMT</lastBuildDate>
    <item>
      <title>通过 PCA 进行异常检测</title>
      <link>https://stats.stackexchange.com/questions/655323/anomaly-detection-by-pca</link>
      <description><![CDATA[我有一个使用 PCA 算法检测异常的项目，我已经编写了该算法。但是，我不知道如何识别异常。你能推荐一些文档或解释合适的算法来处理它吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655323/anomaly-detection-by-pca</guid>
      <pubDate>Fri, 04 Oct 2024 14:50:28 GMT</pubDate>
    </item>
    <item>
      <title>设置清除存档解决方案[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655322/set-up-purge-archive-solution</link>
      <description><![CDATA[我是一名资深的 IT 技术从业者，但总是喜欢尝试新事物，所以我接受了这个挑战，而这个领域我几乎一无所知。在这里寻求帮助 :-)
情况：
我们有一个大型生产环境，带有 SQL 服务器数据库。SQL 服务器数据库变得太大（而且昂贵），我们需要能够存档某些数据。（存档后，从生产环境中删除该数据）。
我们所有的软件都在 MS Azure 中运行，因此解决方案也需要在 Azure 中。
要求：

存档数据仍应可从存档外部查询（例如通过 api 从另一个应用程序查询）——不是很频繁，例如每月一次。
“实时”只有在我们 100% 确定数据在存档中时，才能删除数据
存档技术平台应该能够处理源系统元数据的变化（例如，列大小变化、列删除、添加列等）
存档数据将分部分写入（这意味着，存档过程将确定哪些记录可以存档，然后将它们写入“存档”存储并从源系统中删除）。例如，每个月都会运行存档过程。但是，在存档系统中，所有这些记录（来自同一源表）都应该可以作为“一个”进行查询。
成本和存档数据的轻松访问之间应该有一个良好的平衡

问题：
设置它的最佳方法是什么？我们应该使用什么样的“存档”资源和技术？ （数据湖、Lakehouse、数据仓库……）有太多不同的选择，我很难知道（以我对这个领域的有限了解）最好的解决方案是什么。
我们考虑导出（直接从源系统）.parquet 文件，然后在 delta lake 中处理它们（以应对可能的元数据更改）。但我不知道是否应该使用 Databricks、MS Fabric……？
因此，尽管我们试图完成的事情听起来并不难，但我真的很感激您对 1）要使用的技术和 2）归档过程中的不同步骤的建议。
提前感谢您能给我的任何见解！
-]]></description>
      <guid>https://stats.stackexchange.com/questions/655322/set-up-purge-archive-solution</guid>
      <pubDate>Fri, 04 Oct 2024 14:38:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 Spearman 相关性的互相关函数</title>
      <link>https://stats.stackexchange.com/questions/655321/cross-correlation-function-using-spearmans-correlation</link>
      <description><![CDATA[在互相关函数中使用 Spearman 相关性代替 Pearson 相关性是否“合法”？
基本上，我使用互相关函数来确定两个时间序列的滞后相关性。在查看我的结果后，由于我的数据的性质，我认为 Spearman 滞后分布可能是更好的选择，但我不确定这样做是否“合法”。
有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655321/cross-correlation-function-using-spearmans-correlation</guid>
      <pubDate>Fri, 04 Oct 2024 14:34:06 GMT</pubDate>
    </item>
    <item>
      <title>赌博问题 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/655318/gambling-question</link>
      <description><![CDATA[网站显示当前中奖某张刮刮卡的概率。
1 一等奖的概率是 1/1,143,602
2 二等奖的概率是 1/571,801
3 三等奖的概率是 1/285,900
4 四等奖的概率很低，但和一等奖一样，都是 1/1,143,602
5 五等奖的概率是 1/71,475
我的问题是，赢得前五名奖项的概率是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/655318/gambling-question</guid>
      <pubDate>Fri, 04 Oct 2024 12:16:41 GMT</pubDate>
    </item>
    <item>
      <title>我应该重点关注哪些主题来准备 Databricks 认证机器学习专业人员考试？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655316/what-topics-should-i-focus-on-to-prepare-for-the-databricks-certified-machine-le</link>
      <description><![CDATA[我计划参加 Databricks Certified Machine Learning Professional 认证考试，想知道在准备期间应该优先考虑的关键主题。我有机器学习经验，但我不确定 Databricks 机器学习功能的哪些特定领域将被测试。参加过考试或熟悉认证的人能否提供有关最重要的学习领域的见解？此外，是否有任何推荐的资源或与实际考试紧密相关的练习测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/655316/what-topics-should-i-focus-on-to-prepare-for-the-databricks-certified-machine-le</guid>
      <pubDate>Fri, 04 Oct 2024 12:02:10 GMT</pubDate>
    </item>
    <item>
      <title>SAP ABAP Cloud Backend Developer 考试疑问 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/655315/sap-abap-cloud-backend-developer-exam-doubt</link>
      <description><![CDATA[嗨，我刚刚看到这个 SAP ABAP Cloud Backend 考试 (C_ABAPD_2309) 的示例问题。这次考试主要是基于数据可视化，我对第二个问题及其答案有疑问

给定以下核心数据服务视图实体数据定义：
@AccessControl.authorizationCheck: #NOT_REQUIRED
DEFINE VIEW ENTITY demo_flight_info_join
AS SELECT FROM scarr AS a LEFT OUTER JOIN scounter AS c
LEFT OUTER JOIN sairport AS p
ON p.id = c.airport
ON a.carrid = c.carrid
{       a.carrid AS carrier_id,
p.id AS airport_id,
c.countnum AS counter_number
}



连接语句将按什么顺序执行？
请选择正确的答案。
a) sairport 将首先与 scounter 连接，结果将与 scarr 连接。
b) scarr 将首先与 scounter 连接，结果将与 sairport 连接。
c) scounter 将首先与 sairport 连接，结果将与 scarr 连接。
d) scarr 将首先与 sairport 连接，结果将与 scounter 连接。
提供的答案是“a”，但我觉得答案应该是“c”，有人能帮我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655315/sap-abap-cloud-backend-developer-exam-doubt</guid>
      <pubDate>Fri, 04 Oct 2024 11:40:16 GMT</pubDate>
    </item>
    <item>
      <title>给出以下配对观测值，执行 Wilcoxon 符号秩和检验：[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655314/perform-the-wilcoxon-signed-rank-sum-test-given-the-following-paired-observation</link>
      <description><![CDATA[数据
1
2
3
4
5
6
7
8
9
10
结果 1
12
6
9
15
13
17
8
13
8
10
结果2
10
6
10
13
12
14
6
13
9
11
对上述配对数据的绝对差异进行排序。
alpha=0.05 的临界值是多少？
-1.96 和 1.96
-2.576 和 2.576
4 和 32
6 和 30]]></description>
      <guid>https://stats.stackexchange.com/questions/655314/perform-the-wilcoxon-signed-rank-sum-test-given-the-following-paired-observation</guid>
      <pubDate>Fri, 04 Oct 2024 11:32:32 GMT</pubDate>
    </item>
    <item>
      <title>优化对数似然（针对具有自相关系统性风险的 Vasicek 损失模型）</title>
      <link>https://stats.stackexchange.com/questions/655313/optimizing-loglikelihood-for-vasicek-loss-model-with-autocorrelated-systemic-ri</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655313/optimizing-loglikelihood-for-vasicek-loss-model-with-autocorrelated-systemic-ri</guid>
      <pubDate>Fri, 04 Oct 2024 10:50:23 GMT</pubDate>
    </item>
    <item>
      <title>神经网络可以学习某些矩阵的元素关系吗？</title>
      <link>https://stats.stackexchange.com/questions/655311/can-a-neural-network-learn-element-wise-relationships-of-some-matrix</link>
      <description><![CDATA[假设我有一个矩阵数据集，我想根据矩阵元素之间的隐藏关系对其进行分类。例如，假设 $\Pi_{ij} A_{ij} = B$，如果 $B$ 相同，则它们共享一个标签。
神经网络是否能够学习这种关系并能够辨别不同产品的矩阵？]]></description>
      <guid>https://stats.stackexchange.com/questions/655311/can-a-neural-network-learn-element-wise-relationships-of-some-matrix</guid>
      <pubDate>Fri, 04 Oct 2024 10:13:09 GMT</pubDate>
    </item>
    <item>
      <title>在自动编码器中使用批量标准化进行图像重建是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/655310/does-it-make-sense-to-use-batch-normalization-in-autoencoders-for-image-reconstr</link>
      <description><![CDATA[我正在开发用于图像重建的自动编码器，我想听听您对在这种架构中使用批量标准化 (BN) 的看法。

在专注于图像重建的自动编码器的编码器和解码器层中应用 BN 有什么优势？
就性能和重建质量而言，批量标准化是否会对结果产生负面影响，尤其是在需要最终输出具有高精度的任务中？我读到过，在某些情况下，标准化可能会导致重建过程中关键信息的丢失，因为激活被修改并可能改变原始图像的特征。
是否存在您建议使用或避免使用其的特定情况或配置？

提前感谢您就此主题分享的任何建议或经验。]]></description>
      <guid>https://stats.stackexchange.com/questions/655310/does-it-make-sense-to-use-batch-normalization-in-autoencoders-for-image-reconstr</guid>
      <pubDate>Fri, 04 Oct 2024 08:19:48 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯定理适用于按特定顺序发生的事件</title>
      <link>https://stats.stackexchange.com/questions/655306/bayes-theorem-for-events-that-happen-in-a-particular-order</link>
      <description><![CDATA[我想了解如何使用贝叶斯定理来计算按特定顺序发生的事件的概率。我举个例子：假设我有一个梦想中的博士课程想进入（比如说，在 A 大学攻读统计学博士学位）。现在，我需要先攻读硕士学位，我收到了 B、C 和 D 三所大学的录取通知书。我想攻读硕士课程，这将最大限度地提高我进入 A 大学博士课程的机会。因此，设置以下事件：

B、C 和 D：就读 B/C/D 大学的理学硕士课程。
A：被 A 大学的博士课程录取。

因此，我想知道哪个条件概率最大。例如，$P(A|B)$。现在，为了做到这一点，我们可以使用贝叶斯定理。然而，让我困惑的是，$P(B|A)$ 是什么？事件 B 不依赖于事件 A，因为事件 A 不可能在 B、C 或 D 之一先发生的情况下发生。]]></description>
      <guid>https://stats.stackexchange.com/questions/655306/bayes-theorem-for-events-that-happen-in-a-particular-order</guid>
      <pubDate>Fri, 04 Oct 2024 05:42:17 GMT</pubDate>
    </item>
    <item>
      <title>在 2010 年代后期小程序流行之前，统计学家用什么来快速找到 p 值？</title>
      <link>https://stats.stackexchange.com/questions/655303/what-did-statisticians-use-to-quickly-find-p-values-before-applets-were-populari</link>
      <description><![CDATA[我是统计学专业的新生，今天我从教授那里得知，实际上，模拟样本重复的小程序直到 2010 年代末才出现，这让我非常惊讶，因为它们看起来很简单 - 就像已经存在一段时间的东西一样。在这些出现之前，用什么来快速找到 p 值？]]></description>
      <guid>https://stats.stackexchange.com/questions/655303/what-did-statisticians-use-to-quickly-find-p-values-before-applets-were-populari</guid>
      <pubDate>Fri, 04 Oct 2024 03:01:10 GMT</pubDate>
    </item>
    <item>
      <title>glmer 估计值为负，但应为正</title>
      <link>https://stats.stackexchange.com/questions/655300/glmer-estimate-is-negative-but-should-be-positive</link>
      <description><![CDATA[我正在为我的硕士论文研究寻找一个 glmer（论文完成之前我不能分享数据，所以我会尽量在描述中非常明确）。
但总结一下，我的因变量是一个二进制（exhaustbinary），其中 1 表示参与者做了这件事，0 表示参与者没有做这件事。
我的独立因素是年龄组（儿童或成人）和试验类型（对照或关键），其中有两个随机截距，分别是单个参与者（SubjectID）和单个试验（Item）。
查看代码：
agebytrialopt &lt;- glmer (ExhaustBinary ~ Agegroup * TrialType + 
(1|SubjectID) + (1|Item), data=df, family=&quot;binomial&quot;, 
control=glmerControl(optimizer=&quot;bobyqa&quot;, 
optCtrl=list(maxfun=100000)))

这一切都运行良好。
然而，在摘要和输出中，我得到了一些违反直觉的东西。
固定效果：
估计标准差。错误 z 值 Pr(&gt;|z|) 
(截距) 8.701 1.380 6.306 2.86e-10 ***
AgegroupChild -3.805 1.213 -3.137 0.0017 ** 
TrialTypeCritical -7.049 1.148 -6.140 8.23e-10 ***
AgegroupChild:TrialTypeCritical 6.493 1.201 5.409 6.35e-08 ***

基本上，当我们从儿童级别切换到成人级别时，与成人相比，儿童在排气二进制中更有可能获得 1 值。但是，根据 glmer 选择的名称，这应该意味着儿童与成人相比具有较低的“分数”。这与数据不符，他们的得分高于成年人。
与 TrialTypeCritical 相比，与对照组相比，关键试验在排气二进制中具有更多 0 值。因此，根据名称，关键试验应该比对照组具有较低的“分数”。这在直观上是真实/准确的，并且这里的负估计是有意义的。
我确实检查了因素中对比的虚拟代码，基本因素如下所示。
&gt; 对比（df$Agegroup）
儿童
成人 0
儿童 1

&gt;对比（df$TrialType）
严重
控制 0
严重 1

公平地说，我在过去 5 个小时里一直在研究这个问题，在开始手动设置对比之前，我想确保我正确地解释了这些估计值。
此外，由于我们确实有显著的相互作用，我已经进行了分解，并查看了 emmeans 等等，那里的一切都有意义，可以解释，我对那里的任何负/正翻转都没有问题。
任何关于我哪里出错的见解（无论是我对因素/水平和对数估计的理解，还是对比的工作原理，或者只是一般情况）都会有所帮助。
不过，为了清楚起见，glmer 是我们拥有的数据的最佳选择，我已经做了使用这种方法的所有理论论证，所以我不想回答关于为什么我选择使用glmer 或类似的东西。我只是需要帮助来了解 AgegroupChild 上的极性发生了什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/655300/glmer-estimate-is-negative-but-should-be-positive</guid>
      <pubDate>Thu, 03 Oct 2024 22:55:02 GMT</pubDate>
    </item>
    <item>
      <title>两个大型二进制数组之间的相关性</title>
      <link>https://stats.stackexchange.com/questions/655279/correlation-between-two-large-binary-arrays</link>
      <description><![CDATA[假设我有两个由 0 和 1 组成的大型数组，它们表示一维空间域中的位置，其中：
$$
X = \text{误差较大的位置}，\\
Y = \text{数据质量较差的位置}。
$$
这些成对的数组是布尔值，每个条目表示该位置的误差是较大还是数据质量较差。这些位置按空间顺序排列，这意味着相邻位置比非相邻位置更近。
我想了解高误差区域是否倾向于与数据质量较差的区域相关。鉴于数据的二元性质，卡方检验或phi 系数是否适合检验这种相关性，或者是否有更好的统计方法来解释空间结构？]]></description>
      <guid>https://stats.stackexchange.com/questions/655279/correlation-between-two-large-binary-arrays</guid>
      <pubDate>Thu, 03 Oct 2024 17:15:55 GMT</pubDate>
    </item>
    <item>
      <title>纵向分析结果中与基线的对数转换比率</title>
      <link>https://stats.stackexchange.com/questions/655273/log-transformed-ratio-to-baseline-as-an-outcome-in-longitudinal-analyses</link>
      <description><![CDATA[我必须分析变量 Y 的纵向数据（8 次访问），在文献中，大多数类似研究都对 Y&#39;=log(Y/Ybl) 进行建模，其中 Ybl 是 Y 的基线值，以获得不同组中不同时间的基线百分比变化估计值。
基线的 Y&#39; 始终等于 0，因此我从分析中排除了基线数据。但是，在这种情况下，截距和随机截距涉及第 2 周的访问，这是基线后的第一次访问。在我看来，这没有意义。
将对数转换后的比率建模为基线是一个好主意吗？
在这种情况下，我该怎么做才能有效且一致地编写模型？
（我正在使用 R）
以下是一些附加信息（感谢您的评论）：
模型为 Y&#39; = log(Ybl) + 治疗 + 访问 + 访问 * 治疗

对个人的随机影响（相关出版物中不再有精度）

使用此配置，模型无法收敛到我的数据。如前所述，根据定义，对于所有患者，Y&#39; = 0。]]></description>
      <guid>https://stats.stackexchange.com/questions/655273/log-transformed-ratio-to-baseline-as-an-outcome-in-longitudinal-analyses</guid>
      <pubDate>Thu, 03 Oct 2024 10:29:11 GMT</pubDate>
    </item>
    </channel>
</rss>