<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 09 Jul 2024 15:15:44 GMT</lastBuildDate>
    <item>
      <title>重复测量研究设计，患者退出血药浓度</title>
      <link>https://stats.stackexchange.com/questions/650744/repeated-measures-study-design-with-patient-drop-out-for-blood-concentrations</link>
      <description><![CDATA[我正在研究 100 名患者对某种药物的纵向反应（血药浓度变化过程）。这是一项回顾性研究。为此，我收集了服药后几分钟内的血药浓度。不幸的是，由于纵向反应只是部分调查，因此无法在所有时间点测量所有患者的血药浓度值。因此，我创建了两个图表进行评估：

5 个时间点上所有现有浓度的变化过程；这里我使用了 Mann-Whitney U 检验进行比较
在所有测量时间点进行分析的浓度变化过程；这里我使用了 Wilcoxon 符号秩检验。不幸的是，这里的病例数非常少，因为在所有时间点只有 20 名患者的测量值。

在审查中，我收到反馈，我应该使用重复测量研究设计进行分析，并让患者退出。在这里，我遇到的问题是，我不确定哪种统计方法适合这个问题。我使用 R 进行分析。
如果您有任何想法和建议，我将不胜感激！提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/650744/repeated-measures-study-design-with-patient-drop-out-for-blood-concentrations</guid>
      <pubDate>Tue, 09 Jul 2024 15:15:07 GMT</pubDate>
    </item>
    <item>
      <title>在 MVGAM 中，如何模拟 1 个连续变量（丰度）、1 个离散变量（天数）和 1 个因素（真核生物属）之间的相互作用</title>
      <link>https://stats.stackexchange.com/questions/650741/in-mvgam-how-can-i-model-an-interaction-between-1-continuous-variable-abundanc</link>
      <description><![CDATA[我正在从事微生物生态学研究，并试图在微生物初级演替的情况下模拟几个属的丰富程度对单个感兴趣的属随时间的影响。我已经创建了这个模型，但我真的不确定我是否理解得正确，尤其是关于相互作用。
我发现有几个主题讨论 1 个变量和因素，但没有 1 个连续变量（丰度）、一个离散变量（时间）和因素（属）

Alkanindiges 是包含我感兴趣的属的相对丰度的列
丰度是每天所有属的相对丰度
时间是天数（1-24）
生物反应器是我的实验三重奏（其中有 3 个）

我使用 CAR(1)，因为我预计前一天我感兴趣的属的丰度会对当天的丰度产生影响，但我缺少一些数据点。
这是完整的模型，我包含了数据的摘要我正在合作。如果您想要整个文件，我很乐意通过电子邮件发送给您！
非常感谢您抽出时间。
&#39;&#39;&#39;
mod_alk &lt;- mvgam( Alkanindiges ~ te(Abundance, time, by = Genus) + s(bioreactor, bs = &#39;re&#39;),
 trend_model = CAR(1),

noncentred = TRUE,

data = AHAPCN_train, 

chains = 4,

adapt_delta = 0.97,

max_treedepth = 14,

parallel = TRUE,

backend = &#39;cmdstanr&#39;,

family = Gamma(link = &#39;inverse&#39;)) 

&#39;&#39;&#39;
这是我的 df 的摘要。 NA 是因为我将丰度列分成了每个属的丰度的多个列。
]]></description>
      <guid>https://stats.stackexchange.com/questions/650741/in-mvgam-how-can-i-model-an-interaction-between-1-continuous-variable-abundanc</guid>
      <pubDate>Tue, 09 Jul 2024 14:16:22 GMT</pubDate>
    </item>
    <item>
      <title>评估随机搜索交叉验证：使用大型特征集调整 ElasticNet</title>
      <link>https://stats.stackexchange.com/questions/650740/assessing-random-search-cross-validation-tuning-in-elasticnet-with-large-featur</link>
      <description><![CDATA[我正在为一个包含超过 100,000 个变量的大型数据框估算 ElasticNet 模型，结果导致过度识别的情况。为了调整我的模型，我设置了一个超参数网格（alpha 和 l1 比率），确保它涵盖从完全密集到完全稀疏模型的组合，总共 10,100 种可能的组合。
鉴于详尽网格搜索不切实际，我选择了随机搜索交叉验证，其中随机选择了 1,000 个超参数组合。我现在关心的是评估从总共 10,100 个组合中随机选择的 1,000 个组合是否足以提供对模型在超参数空间中的表现的可靠理解。是否有任何既定的经验法则、理论指导或模拟可以指导我确定这一点？
补充：贝叶斯优化可能是一种更有意义的方法。但是，我缺乏使用 Python 实现 ElasticNet 模型的专业知识。有人能帮忙吗？
代码示例：
import numpy as np
from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit
from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_squared_error

# 生成合成数据（模拟您的 data_complete 和 y）
np.random.seed(42)
data_complete = np.random.rand(300, 100000) # 300 个观测值，100000 个变量
y = np.random.rand(300) # 目标变量的 300 个观测值

# 定义超参数网格
params = {
&#39;alpha&#39;: np.logspace(-5, 5, 100, end=True), # 100 个介于 e^-5 和 e^5 之间的值
&#39;l1_ratio&#39;: np.append(np.arange(0, 1.01, 0.01), 1.0) # 101 个介于 0 和 1 之间的值，包括 1.0
}

# 创建 Elastic Net Regressor 实例
regressor = ElasticNet()

# TimeSeriesSplit 交叉验证
tscv = TimeSeriesSplit(n_splits=5) # 根据需要调整分割数

# 随机搜索交叉验证
rs_cv = RandomizedSearchCV(regressor, params, n_iter=1000,scoring=&#39;neg_mean_squared_error&#39;, cv=tscv, verbose=1, n_jobs=4)
rs_cv.fit(data_complete, y)

# 最佳超参数
best_params = rs_cv.best_params_
best_alpha = best_params[&#39;alpha&#39;]
best_l1_ratio = best_params[&#39;l1_ratio&#39;]

print(f&quot;最佳 alpha: {best_alpha}&quot;)
print(f&quot;最佳 l1_ratio: {best_l1_ratio}&quot;)

# 使用最佳超参数拟合模型
best_enet = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio, random_state=42)
best_enet.fit(data_complete, y)

# 评估模型性能
y_pred = best_enet.predict(data_complete)
mse = mean_squared_error(y, y_pred)
print(f&quot;最终均方误差: {mse}&quot;)
]]></description>
      <guid>https://stats.stackexchange.com/questions/650740/assessing-random-search-cross-validation-tuning-in-elasticnet-with-large-featur</guid>
      <pubDate>Tue, 09 Jul 2024 14:06:09 GMT</pubDate>
    </item>
    <item>
      <title>如何测量二进制数据列表中分布的规律性？</title>
      <link>https://stats.stackexchange.com/questions/650739/how-do-i-measure-the-regularity-of-the-distribution-in-a-list-of-binary-data</link>
      <description><![CDATA[假设我有一个列表 list = [0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1]，它给出了某人在某一天是生病 (1) 还是没生病 (0) 的信息，由于该列表有 15 个元素，我考虑 1-15 天。现在我想确定如何“很好地”或者这些病假有规律地分布在这段时间内。
例如，规则的分布是
[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1]

不美观的分布是例如：
[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]

我考虑的是基尼系数或距离的标准差。但是我不知道如何处理第二个列表。
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]

这里，距离的标准差值为 0，但 1 的分布不太好。
还有什么其他可能性？]]></description>
      <guid>https://stats.stackexchange.com/questions/650739/how-do-i-measure-the-regularity-of-the-distribution-in-a-list-of-binary-data</guid>
      <pubDate>Tue, 09 Jul 2024 13:46:10 GMT</pubDate>
    </item>
    <item>
      <title>处理 Cox 回归中的分类变量</title>
      <link>https://stats.stackexchange.com/questions/650738/dealing-with-categorical-variables-on-cox-regression</link>
      <description><![CDATA[我试图将 Cox 回归模型拟合到我的事件发生时间数据，并有一个具有 5 个不同级别的分类变量。如果我不忽略其中一个级别，那么我将具有多重共线性，因此我假设我需要忽略一个类别作为“参考”类别。如果我忽略一个级别，那么我将如何解释得到的 cox 系数？忽略的类别有什么影响？它是否会导致基线风险？
我正在使用 Python 中 lifelines 库中的 CoxTimeVaryingFitter。]]></description>
      <guid>https://stats.stackexchange.com/questions/650738/dealing-with-categorical-variables-on-cox-regression</guid>
      <pubDate>Tue, 09 Jul 2024 13:32:30 GMT</pubDate>
    </item>
    <item>
      <title>元问题：理解相关性与效应大小</title>
      <link>https://stats.stackexchange.com/questions/650737/meta-question-understanding-correlation-vs-effect-size</link>
      <description><![CDATA[背景：我一直在研究一些关于解释幸福（幸福感）的因素的荟萃分析，因为我想检查某种哲学对幸福的主张，并且希望自己总体上幸福（谁不想呢：）。当然，这些荟萃分析揭示了幸福的不同协变量，它们具有不同的相关系数。
所以我想知道：根据这些研究，为了了解什么能长期带来最大的幸福感，我只需要关注相关系数的大小吗？还是我需要查看效果大小？或者还有什么需要注意的？我想我想知道我应该做些什么才能从我花费的一小时内获得最大的长期幸福感？]]></description>
      <guid>https://stats.stackexchange.com/questions/650737/meta-question-understanding-correlation-vs-effect-size</guid>
      <pubDate>Tue, 09 Jul 2024 13:14:35 GMT</pubDate>
    </item>
    <item>
      <title>预先筛选对于付费调查来说不是有害的吗？</title>
      <link>https://stats.stackexchange.com/questions/650734/is-prescreening-not-detrimental-for-paid-surveys</link>
      <description><![CDATA[像 Swagbucks 这样的调查网站通常有一个预筛选模式，其中会询问受访者诸如您的年收入、您是否拥有汽车等问题。据观察，大多数情况下，如果受访者选择表示较低收入、零汽车的选项，则受访者被取消资格，并且不会给受访者任何积分/奖励（确切地说，Swagbucks 给出 1 SB，但这比符合条件并完成调查的受访者少得多）。这应该会导致许多受访者选择更高的收入，从而扭曲调查结果。那么为什么这些调查不考虑这个事实并取消预筛选呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/650734/is-prescreening-not-detrimental-for-paid-surveys</guid>
      <pubDate>Tue, 09 Jul 2024 11:28:56 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn CCA：x_loadings_x 属性</title>
      <link>https://stats.stackexchange.com/questions/650733/scikit-learn-cca-x-loadings-x-attribute</link>
      <description><![CDATA[我正在使用 scikit-learn 的 CCA 进行典型相关分析。在执行常规步骤并调用 ca.x_loadings_ 后，我发现我得到的值大于 1。然而，我如何解释属性 x_loadings_ 应该代表什么，这与载荷是一种相关性相矛盾。属性 x_loadings_ 究竟代表什么？
n_comp = 3 #选择典型变量对的数量，最大值是 X 和 Y 维度的最小值
from sklearn.cross_decomposition import CCA

# 实例化 cca 对象并拟合
ca = CCA(n_components=n_comp)
ca.fit(x_standardized, y_standardized)
X_c, Y_c = ca.transform(x_standardized, y_standardized) #转换我们的数据集以获得典型变量

print(ca.x_loadings_)
print(ca.y_loadings_)
]]></description>
      <guid>https://stats.stackexchange.com/questions/650733/scikit-learn-cca-x-loadings-x-attribute</guid>
      <pubDate>Tue, 09 Jul 2024 11:28:15 GMT</pubDate>
    </item>
    <item>
      <title>Cook 在 R 中的多级模型的 d [关闭]</title>
      <link>https://stats.stackexchange.com/questions/650725/cooks-d-for-multi-level-model-in-r</link>
      <description><![CDATA[在 R 中，对于多级模型，是否可以使用 Cook 距离进行异常值诊断？如果可以，在计算多个并插入逐步预测变量时，我应该将其应用于哪个模型？
不幸的是，到目前为止，我在互联网搜索中只找到了一个 SPSS 命令。R 中还有其他方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650725/cooks-d-for-multi-level-model-in-r</guid>
      <pubDate>Tue, 09 Jul 2024 09:24:48 GMT</pubDate>
    </item>
    <item>
      <title>样本量对指标提升度的影响</title>
      <link>https://stats.stackexchange.com/questions/650716/impact-of-sample-size-on-metric-lift</link>
      <description><![CDATA[假设我们连续运行了三个随机用户拆分 AB 实验 exp_1、exp_2、exp_3。这三个实验的处理和控制完全相同。
Exp_1 在 2014 年 6 月 1 日至 2014 年 6 月 1 日期间运行了 2 周。 Exp_2 在 06/15-06/28 期间运行了 2 周，Exp_3 在 06/29-07/12 期间运行了 2 周。
Exp_1 有 2% 的用户参与了实验，Exp_2 有 50% 的用户参与了实验，Exp_3 有 100% 的用户参与了实验。
Exp_1 的主要指标提升的 95% CI 为 2.3% - 13.0%
Exp_2 的主要指标提升的 95% CI 为 6.2% - 8.4%
Exp_3 的主要指标提升的 95% CI 为 5.9% - 7.4%
从这些结果中，我们可以得出结论，所有三个实验都具有相同的指标提升吗？
如果是/否，为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/650716/impact-of-sample-size-on-metric-lift</guid>
      <pubDate>Tue, 09 Jul 2024 07:16:34 GMT</pubDate>
    </item>
    <item>
      <title>我对产权欺诈统计数据的解读是否正确？</title>
      <link>https://stats.stackexchange.com/questions/650708/am-i-interpreting-title-fraud-statistics-correctly</link>
      <description><![CDATA[每年有 10,000 起产权欺诈案件。99% 的诉讼都是庭外和解。
这是否意味着每年有 100 万人的房屋被盗或 10,000 人？我倾向于更高的数字，因为任何拥有房屋的人的产权都会被盗，这很合理，这就是为什么人们有抵押贷款让银行拥有房产的原因。]]></description>
      <guid>https://stats.stackexchange.com/questions/650708/am-i-interpreting-title-fraud-statistics-correctly</guid>
      <pubDate>Tue, 09 Jul 2024 03:10:51 GMT</pubDate>
    </item>
    <item>
      <title>贝塞尔修正的有效证明</title>
      <link>https://stats.stackexchange.com/questions/650702/efficient-proof-of-bessels-correction</link>
      <description><![CDATA[我刚刚开始学习统计学的基础知识，正在维基百科页面上阅读关于贝塞尔方差估计校正为何有效的证明。我理解了一切，除了以下计算的戏剧性简化（在此处重现）：

... 这里我们有（通过独立、对称抵消和平等分配）
$$... \mathbb{E} \Big[ \displaystyle\sum_{j=1}^n\sum_{l=1}^n (x_k - x_j)(x_k - x_l) \Big] = n(n-1)\mathbb{E}[X_1^2] - n(n-1)\mathbb{E}[X_1]^2$$

我不明白计算如何如此容易地进行。页面作者所说的“通过独立、对称抵消和平等分配”究竟是什么意思？]]></description>
      <guid>https://stats.stackexchange.com/questions/650702/efficient-proof-of-bessels-correction</guid>
      <pubDate>Tue, 09 Jul 2024 00:41:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 R STM 包分析评论评级-样本平衡问题</title>
      <link>https://stats.stackexchange.com/questions/650661/analyzing-review-rating-using-r-stm-package-sample-balance-issue</link>
      <description><![CDATA[对于在线评论数据集，其中一项任务是研究主题比例的差异（例如，主题为正面评论与负面评论）。由于在线评论评分呈正偏的J形分布/评分分布不平衡，学者倾向于平衡样本量，即随机选择正面评分评论（即4分和5分评分），使其数量等于或接近负面评分评论（即1分和2分评分）。类似于以下论文的做法：
论文1：酒店顾客抱怨什么？使用结构化主题模型进行文本分析
论文 2：药物消费者的声音：使用结构化主题模型进行在线文本评论分析
删除一些评级评论以实现平​​衡样本的原因是（摘自论文 2）：

...当在 STM 模型中使用评论极端值作为协变量时，首先过滤正面和负面评论以平衡正面和负面评论的样本量是必不可少的，这可以帮助我们更可靠地识别负面评论中出现次数明显多于正面评论的主题。

由于从数据集中删除样本始终是一种不好的做法，我的问题是：在以下情况下，删除一些评级评论以实现平​​衡样本是否合理考察 STM 模型中主题比例的差异？]]></description>
      <guid>https://stats.stackexchange.com/questions/650661/analyzing-review-rating-using-r-stm-package-sample-balance-issue</guid>
      <pubDate>Mon, 08 Jul 2024 08:17:13 GMT</pubDate>
    </item>
    <item>
      <title>关于测试可靠性对测试组合权重的影响的问题</title>
      <link>https://stats.stackexchange.com/questions/650558/question-on-the-effect-of-test-reliability-on-weighting-of-a-test-battery</link>
      <description><![CDATA[最初，测试组有 4 个部分：两个 100 项多项选择题测试、一个口语测试和一个论文测试。每个部分测量不同的主题。4 个部分中的每一个权重为 25%。
现在，每个多项选择题测试的测试长度已减少到 60 项（出于实际原因）。每个部分仍占 25%。
如果两个 MC 测试的可靠性降低到零，则两个 MC 测试测量的两个主题的权重将为零。（两个 MC 测试只会产生误差。）实际上，可靠性降低了，但并没有降低到零。
我的问题是，可靠性的变化对两个 MC 测试测量的两个主题的权重有何影响。我如何估计由于变化而导致的权重差异？
澄清：
原始权重是根据相关方的共识选择的。权重的改变是出于权宜之计。我试图确定新的测试组与原来的测试组相比，在组内每个测试的权重方面有何不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/650558/question-on-the-effect-of-test-reliability-on-weighting-of-a-test-battery</guid>
      <pubDate>Fri, 05 Jul 2024 22:15:38 GMT</pubDate>
    </item>
    <item>
      <title>NHST 中 p 值有其他统计数据吗？</title>
      <link>https://stats.stackexchange.com/questions/650539/are-there-alternative-statistics-to-a-p-value-in-nhst</link>
      <description><![CDATA[有时，当解释和激发 p 值的逻辑时，它会以以下方式发生：

引入随机样本的概念，同时需要考虑我们获得结果的可能性——仅仅是偶然的。
然后，人们在给定零假设的情况下反思实验结果的概率。
由于任何特定实验结果的概率（当存在多种可能性时）都非常小，因此建议使用获得我们得到的结果或“更极端的结果”的概率。

我对最后阶段的逻辑有些怀疑。尽管计算我们的结果或更极端的观察结果的概率是一种解决方案（对于在零假设下仅使用特定结果的概率的问题），但这并不一定需要使用它。
是否有人提出过替代统计数据，在给定零假设的情况下，哪个概率是拒绝（或不拒绝）零假设的考虑值？]]></description>
      <guid>https://stats.stackexchange.com/questions/650539/are-there-alternative-statistics-to-a-p-value-in-nhst</guid>
      <pubDate>Fri, 05 Jul 2024 16:43:57 GMT</pubDate>
    </item>
    </channel>
</rss>