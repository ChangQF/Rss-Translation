<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 23 Jan 2025 15:17:23 GMT</lastBuildDate>
    <item>
      <title>估计一组变量的概率密度函数</title>
      <link>https://stats.stackexchange.com/questions/660425/estimating-the-pdf-of-a-set-of-variables</link>
      <description><![CDATA[我正在研究以下子问题。我得到了一个完全加权图，$G = (V,E)$。$1 \leq u &lt; v \leq n$ 的边集 $E = \{X_{uv}\}$ 是一组随机变量，其中每个 $X_{uv} \sim U(0,1)$。
让 $i \in [1,n]$ 成为该图的一个顶点。我表示以下两个随机变量
$M_i$ = &quot;最小连接数$i$&quot;
$L_i$ = &quot;最大连接数$i$&quot;
&quot;最小连接数$i$&quot;表示存在另一个顶点$j \in [1,\ldots,n], j\neq i$ s.t.随机变量 $X_{ij}$（$i$ 和 $j$ 之间的边）是与顶点 $j$ 相关的所有随机变量中最小的一个，即 $X_{ij} = \min\{ X_{uv} \text{ s.t. } u=j \text{ 或 }v=j \}$。
我以类似的方式定义最大值，只是将上述定义中的 min 替换为 max。
通过积分，我发现，对于较小的 $n$ 值，$M_i$ 和 $L_i$ 都是 $Binomial(n-1,\frac{1}{n-1})$，而对于较大的 $n$ 值，它们都是 $Poisson(\lambda=1)$ 分布。
我感兴趣的是，$M_i$ 和 $L_i$ 都是 $Binomial(n-1,\frac{1}{n-1})$ ... class=&quot;math-container&quot;&gt;$M_i$ 和 $L_i$ 同时大于 1，因此渐近地我有
$P[$min$ \{M_i,L_i\} \geq 1] \rightarrow (1-e^{-1})^2$
而对于较小的 $n$ 值，我发现一个下限
$P[M_i \text{ and } L_i \geq 1] \geq 1-2(1-\frac{n-2}{n-1})^{n-1}$
现在，让我们用 $R = \{ X_{uv} \text{ s.t. 表示。 } u=i \text{ 或 } v=i \}$ 与顶点 $i$ 相关的所有边的集合。
如果此顶点实际上具有非空交集（最小$\{M_i, L_i\} \geq 1$），那么我将通过获取 $G&#39;= (V&#39;, E&#39;)$ 来缩小我的图，其中 $V&#39; = V \setminus \{i\}$ 和 $E&#39;= E \setminus R$。
我主要感兴趣的是断言 $E&#39;$ 仍将由 $\binom{n-1}{2}$ 个随机变量仍然均匀分布在 $(0,1)$ 中，或者表明删除的变量 $R$ 几乎就像一个随机样本。
对于 $f_R$，我计算了累积函数和概率密度函数。利用一个变量是最小值、一个是最大值，其他变量 $n-3$ 是均匀分布的事实，我得到
\begin{align*}
F_R(x_{min}, x_{max}, x_1, \ldots, x_{n-3} ) = 1 - (1-x_{min})^{n-1} x^{n-1}_{max} \prod_{p=1}^{n-3} x_p \\
f_R(x_{min},x_{max}) = (n-1) (1-x_{min})^{n-2} (n-1) x^{n-2}_{max} 
\end{align*&gt;
如何计算 $f_{E&#39; | R}$？它能帮助我估计 $E&#39;$ 是否呈均匀分布吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660425/estimating-the-pdf-of-a-set-of-variables</guid>
      <pubDate>Thu, 23 Jan 2025 14:05:30 GMT</pubDate>
    </item>
    <item>
      <title>比较两个小样本量相关样本的 Spearman 相关系数的正确方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/660424/what-is-the-right-way-to-compare-two-spearman-correlation-coefficients-of-depend</link>
      <description><![CDATA[我正在尝试找出正确的方法来比较两个或三个相关样本的 Spearman 相关系数。问题是我的基础数据的样本量非常小（$n = 11$）。
我发现我可以使用此网页中指定的方法测试具有一个共同变量的两个相关相关性之间的差异 - http://quantpsy.org/corrtest/corrtest2.htm。它使用 Fisher 的 r-to-z 变换将相关系数转换为 z 分数，然后使用 Steiger (1980) 方程 3 和 10 计算估计值的渐近协方差。
从阅读论文来看，它似乎基于多元相关分布的论证，我不确定这是否适用于 Spearman 相关。我猜它可能适用于大样本，但由于我的样本量为 $n = 11$，我不确定如何继续。另一种方法是以某种方式引导系数或重新采样它们，但我不确定如何做到这一点。
为了便于理解，我有三个数据集（$a$、$b$ 和 $c$）和两个相关系数 - $r_{ab}$ 和 $r_{ac}$，其中 $a$ 为共同变量。所有三个数据集的大小均为 $n=11$。最后，我想声明的是 $r_{ac}$ 明显大于 $r_{ab}$，因此我假设这是一个单尾检验。
有人能告诉我应该对相关系数进行哪种检验才能得出这个结论吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660424/what-is-the-right-way-to-compare-two-spearman-correlation-coefficients-of-depend</guid>
      <pubDate>Thu, 23 Jan 2025 13:47:42 GMT</pubDate>
    </item>
    <item>
      <title>修复 nlme/lme4 中的随机效应估计</title>
      <link>https://stats.stackexchange.com/questions/660422/fix-the-random-effects-estimates-in-nlme-lme4</link>
      <description><![CDATA[我想用 R 编写一个函数，将这篇论文的思想结合起来。它是关于计算混合模型的局部效应大小。更具体地说：计算模型每个预测变量的$f^2$。理论上，您可以使用 Cohen 方程（Cohen，1988，第 410 页，上述论文中的方程 (2) 也可用于此目的）：
$$f^2 = \frac{R^2_{AB} - R^2_A}{1 - R^2_{AB}}$$
其中 B 是感兴趣的预测因子，A 是其他预测因子的集合。您可以想象，您可能希望对混合模型中的每个预测因子都执行此操作。
因此，要计算预测因子 B 的 $f^2$，您需要两个模型：一个包含 A 和 B（完整模型），另一个仅包含 A（简化模型）。但是，正如论文作者所提到的：为了使这在混合模型中正常工作，您需要将简化模型的随机效应协方差估计值固定为从拟合完整模型中获得的估计值。
作者有一个 SAS 示例，在 PROC MIXED 中，您显然可以说 parms / parmsdata = VABex2ND hold=1,2,3;（第 5 页，右栏），其中 VABex2ND 是完整模型的随机效应协方差矩阵。现在，我不是 SAS 用户，也不打算将来成为用户，所以我希望在 R 中为此编写一些实现。但是，我找不到使用 nlme/lme4 预定义/修复混合模型中随机效应协方差估计值的方法。这有可能吗？
当然我可以使用贝叶斯方法，为随机效应协方差设置非常严格的先验。例如，使用 nlme 中的 Dialyzer 数据集来计算多元混合模型中变量 QB 的 $f^2$，如下所示：
library(nlme)
library(brms)

data(&quot;Dialyzer&quot;)

full_model &lt;- brm(rate ~ QB + index + pressure + (1 | Subject), data = Dialyzer)
ranef_variance &lt;- VarCorr(full_model)$Subject$sd[1]
fixed_prior &lt;- set_prior(paste0(&quot;normal(&quot;, ranef_variance, &quot;, 0.001)&quot;), 
class = &quot;sd&quot;,
group = &quot;Subject&quot;)
reduced_model &lt;- brm(rate ~ index + pressure + (1 | Subject),
data = Dialyzer,
Prior = fixed_prior)
VarCorr(full_model)
VarCorr(reduced_model) # 大约相同的随机效应方差，yaay
(bayes_R2(full_model)[1] - bayes_R2(reduced_model)[1]) / (1 - bayes_R2(full_model)[1])

但是，我现在想将事情保持在频率论框架内。此外，我不喜欢模型中每个潜在变量的漫长 Stan 编译时间。
tl;dr：有没有办法预定义/修复 nlme/lme4 中的随机效应协方差估计，而不是对它们进行估计？]]></description>
      <guid>https://stats.stackexchange.com/questions/660422/fix-the-random-effects-estimates-in-nlme-lme4</guid>
      <pubDate>Thu, 23 Jan 2025 13:21:39 GMT</pubDate>
    </item>
    <item>
      <title>样本来自两个分布之一的概率</title>
      <link>https://stats.stackexchange.com/questions/660421/probability-that-a-sample-comes-from-one-of-two-distributions</link>
      <description><![CDATA[假设我们有一个由 $n$ 个独立随机变量组成的数据样本，其中 $k$ 个样本来自分布 $f(x)$，而 $n−k$ 个样本来自分布 $g(x)$。现在，我想确定给定样本（例如 $x_i$）来自分布 $f(x)$ 的概率，给定整个样本集 $x_1, \dots, x_n$。贝叶斯定理是否可以结合先验概率（即 $k/n$ 和 $(n-k)/n$）来计算此概率
$$\mathbb{P}(x_i\sim f(x)\mid x_1, \dots, x_n)$$
以获得闭式解？]]></description>
      <guid>https://stats.stackexchange.com/questions/660421/probability-that-a-sample-comes-from-one-of-two-distributions</guid>
      <pubDate>Thu, 23 Jan 2025 13:07:11 GMT</pubDate>
    </item>
    <item>
      <title>线性模型和 SelectKBest 算法之间的主要区别是什么[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660420/what-is-major-difference-between-linear-model-and-selectkbest-algorithms</link>
      <description><![CDATA[我研究了 Scikit-Learn 库中的各种算法。
线性模型（线性/逻辑回归）和 SelectKBest 算法看起来都很简单高效。我可以在这两种算法中获得效果尺寸参数（系数或分数）和 P 值。
这两种算法之间的主要区别是什么？这两种算法最适合分析哪些类型的数据？感谢您的见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/660420/what-is-major-difference-between-linear-model-and-selectkbest-algorithms</guid>
      <pubDate>Thu, 23 Jan 2025 12:42:11 GMT</pubDate>
    </item>
    <item>
      <title>子样本中的基尼模型系数与整个人口的基尼系数</title>
      <link>https://stats.stackexchange.com/questions/660414/gini-model-coefficient-in-subsamples-vs-gini-coefficient-on-entire-population</link>
      <description><![CDATA[我有来自两个组的 17000 个观测值样本：我们将它们称为 X1 和 X2。
我计算了样本中某些变量的逻辑回归，并计算了基尼系数。
我得到的值为 0.496。
但是，当我使用同一模型计算模型在特定子组上的表现时，我得到的基尼值是 X1 = 0.442（13000 个观测值）和 X2 = 0.443（4000 个观测值）。
是否有可能得到这样的结果，或者我的代码是否有需要纠正的流程？如果可能，如何适当地衡量这两个组的估计差异与总体表现的比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/660414/gini-model-coefficient-in-subsamples-vs-gini-coefficient-on-entire-population</guid>
      <pubDate>Thu, 23 Jan 2025 11:42:30 GMT</pubDate>
    </item>
    <item>
      <title>事后功效低的非显著性调节、简单斜率分析合法吗？</title>
      <link>https://stats.stackexchange.com/questions/660410/non-significant-moderation-with-low-post-hoc-power-simple-slope-analysis-legit</link>
      <description><![CDATA[我正在写论文，对调节分析有一个问题：
我用 PROCESS 模型 1 进行了调节，发现连续 IV 的主效应显著。连续 MOD 的主效应不显著。交互项接近显著 (p = .060)。我进行了事后功效分析，发现为 0.58。我的 N 只有 17。我还进行了简单斜率分析，发现 IV 对 DV 的影响对于小 (B = -1.22, p &lt; 0.001) 和中等 MOD (B = -0.74, p = .015) 是显著的。，对于高 MOD (B = -0.26, p = 0.572) 则不显著。
到目前为止，我进行简单斜率分析的论据是，由于 N 和功效较小，我可能会忽略这种影响，出于探索目的，我进行了进一步的分析。今天我必须展示我的结果，有人注意到要仔细检查简单斜率分析是否合法，因为相互作用根本不显著。我在这个主题上找到的大部分信息表明，在发现不显著的相互作用后，我应该放弃它，不要继续进行进一步的分析。但就我而言，我已经非常接近显著，而且我的 PostHoc 功效很低。
我想知道我是否在科学上“被允许”进行简单的斜率分析，以及是否有任何论文/研究支持此程序或之前做过。
非常感谢大家的帮助！:)
BR
Erik]]></description>
      <guid>https://stats.stackexchange.com/questions/660410/non-significant-moderation-with-low-post-hoc-power-simple-slope-analysis-legit</guid>
      <pubDate>Thu, 23 Jan 2025 10:24:46 GMT</pubDate>
    </item>
    <item>
      <title>Cox 比例风险组可以重叠吗？</title>
      <link>https://stats.stackexchange.com/questions/660408/can-cox-proportional-hazards-groups-overlap</link>
      <description><![CDATA[我想有四个组 - 组 A、B、C、D。
我有 1 到 10 个人。
假设 1 和 2 个人在组 A，3 和 4 个人在组 B，5 和 6 个人在组 C，7、8、9 个人在组 D。
我可以将 10 个人分在组 A 和组 C 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660408/can-cox-proportional-hazards-groups-overlap</guid>
      <pubDate>Thu, 23 Jan 2025 09:59:43 GMT</pubDate>
    </item>
    <item>
      <title>多项逻辑模型的比例和置信区间</title>
      <link>https://stats.stackexchange.com/questions/660406/proportions-and-confidence-intervals-from-multinomial-logit-model</link>
      <description><![CDATA[我想在 GLMM 的背景下，从多项逻辑模型计算类别比例和相关置信区间。
我理解多项逻辑模型使用比值比，使用一个类别作为参考。可以通过对模型系数（及其标准误差）取幂，从多项逻辑模型中提取比值比（及其标准误差）。
还可以使用 softmax 函数轻松计算每个类别的估计比例（例如，参见 此答案）。
但是，我找不到任何关于从多项逻辑模型计算估计比例的标准误差的信息。到目前为止，我最好的猜测是使用不确定性传播，但据我了解，这意味着参考类的标准误系统地高于其他类，我觉得这很奇怪。
我知道可以从多项分布计算置信区间的可能性，如Glaz and Sison, 1999，但这并不能满足我的需求。
如能得到任何帮助或指点，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/660406/proportions-and-confidence-intervals-from-multinomial-logit-model</guid>
      <pubDate>Thu, 23 Jan 2025 09:40:21 GMT</pubDate>
    </item>
    <item>
      <title>Schmidt Phillips 单位根检验中的检验统计量和临界值</title>
      <link>https://stats.stackexchange.com/questions/660405/test-statistic-and-critical-value-in-schmidt-phillips-unit-root-test</link>
      <description><![CDATA[如果检验统计量小于临界值，我是否应该拒绝零假设？
################################## 
# Schmidt-Phillips 单位根检验 # 
##################################### 

调用：
lm(formula = sp.data)

残差：
最小值 1Q 中位数 3Q 最大值 
-4913 -767 30 778 4246 

系数：
估计标准差误差 t 值 Pr(&gt;|t|)
(截距) -74.9064695979 231.3977971931 -0.32 0.75
y.lagged -0.0040370944 0.0355241491 -0.11 0.91
trend.exp1 -1.9117515231 3.9829227560 -0.48 0.63
trend.exp2 0.0123064436 0.0201444114 0.61 0.54
trend.exp3 -0.0000210647 0.0000377040 -0.56 0.58
trend.exp4 0.0000000112 0.0000000233 0.48 0.63

残差标准误差：793 个自由度上的 1280
多重 R 平方：0.00676，调整后的 R 平方：0.000496

F 统计量：5 和 793 DF 上的 1.08，p 值：0.37

检验统计量的值为：-9.958

显著性水平为 0.05 的临界值为：-4.31
]]></description>
      <guid>https://stats.stackexchange.com/questions/660405/test-statistic-and-critical-value-in-schmidt-phillips-unit-root-test</guid>
      <pubDate>Thu, 23 Jan 2025 09:30:22 GMT</pubDate>
    </item>
    <item>
      <title>非劣效性临床试验</title>
      <link>https://stats.stackexchange.com/questions/660401/non-inferiority-clinical-trial</link>
      <description><![CDATA[根据之前的临床试验研究，我们认为非劣效性临床试验中的等效性边际为 10%。我们的主要结果呈非正态分布。变量的变换也是非正态的。分析是 Mann-Whitney，样本量为 600。当 10% 是从正态分布变量中获得时，如何获得主要结果的置信区间？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/660401/non-inferiority-clinical-trial</guid>
      <pubDate>Thu, 23 Jan 2025 06:44:11 GMT</pubDate>
    </item>
    <item>
      <title>比较两组之间的多重相关性时进行 Bonferroni 校正</title>
      <link>https://stats.stackexchange.com/questions/660400/bonferroni-correction-while-comparing-multiple-correlations-between-two-groups</link>
      <description><![CDATA[希望你们都一切顺利。我有一个关于 Bonferroni 校正的问题。我正在处理一个包含两个组的数据集：Alpha 和 Beta。此外，我有两组的六项血液化学测试结果，标记为 A、B、C、D、E 和 F。我计算了所有血液测试的成对相关性，结果得出了 15 个相关性（计算为 (6 * 5)/2）。这些相关性的一些示例包括 A.B、A.C、B.D 和 D.E。
接下来，我计划使用 ANCOVA 比较 Alpha 和 Beta 组之间的这些相关性。我的问题是，在这种情况下我是否应该应用 Bonferroni 校正。如果是这样，那是否意味着设置 α = 0.05/15？由于我正在比较两组之间的 15 个成对相关性，因此我不确定 Bonferroni 校正是否必要，因为我只比较了两组。我的想法正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660400/bonferroni-correction-while-comparing-multiple-correlations-between-two-groups</guid>
      <pubDate>Thu, 23 Jan 2025 06:39:38 GMT</pubDate>
    </item>
    <item>
      <title>使用 Shapley 值分析特征对低估和高估的影响</title>
      <link>https://stats.stackexchange.com/questions/660399/analysis-of-features-impact-on-under-prediction-and-over-prediction-using-shapl</link>
      <description><![CDATA[请告诉我我的理解是否正确。

您可以将上面的图片视为 Shapley 力图。箭头表示特征从基值推动预测的方向。在我的 xgboost 回归模型（用于预测未来的实际波动率）中，我为每个样本实例获得了不同的基值。
我想识别预测不足的样本实例中的坏特征和好特征。坏特征会导致预测不足并将预测推向左侧。好的特征通过将预测推向右侧来防止低估。
我将低估的实例分为具有低于和高于基准值的基本事实的实例。
对于低于基准值的基本事实实例，青色箭头方向表示好的特征，这些特征确实试图将预测向上推，从而防止低估。然后，我简单地将这些实例上每个特征的 SHAP 值相加，并将每个特征的总 SHAP 值从高到低（从下向上）排序，如下所示。我只从总共 200 个特征中选取前 75 个特征。

对于高于基准值的真实实例，红色箭头方向表示真正试图将预测向下推从而导致预测不足的不良特征。然后，我简单地将这些实例上每个特征的 SHAP 值相加，并将每个特征的总 SHAP 值从低到高（从下向上）排序，如下所示。我只从总共 200 个特征中选取前 75 个特征。

我推理出真正好的特征和坏特征的方式正确吗？
我可以做任何改进吗？
当我尝试对过度预测实例执行相同操作时，我注意到一个问题。正如这里所示，防止低估的相同特征会导致过度预测。我该如何推理？我想从两个集合（即防止低估的集合和导致过度预测的集合）中找到互斥的特征，并将它们标记为好特征和坏特征。您能否澄清这种方法是否正确？如果这不合理，请建议其他方法。谢谢。

编辑：我想到了一种新方法。我首先取（前 75 个）红色箭头特征与（前 75 个）黄色箭头特征的集合差异，以获得导致低估的非常糟糕的特征。我还可以取（前 75 个）青色箭头和（前 75 个）浅蓝色箭头（新添加）之间的集合差异，以获得防止低估的非常非常好的特征。是否会有所改善（防止低估的特征与导致过度预测的特征之间的重叠较少，同样，防止过度预测的特征与导致低估的特征之间的重叠较少）？
编辑：

我的想法是丢弃坏的特征并找到好特征的相互作用，然后将它们包括在内以改善低估和过度预测的情况。]]></description>
      <guid>https://stats.stackexchange.com/questions/660399/analysis-of-features-impact-on-under-prediction-and-over-prediction-using-shapl</guid>
      <pubDate>Thu, 23 Jan 2025 05:47:51 GMT</pubDate>
    </item>
    <item>
      <title>Metropolis-Hastings 算法和接受概率</title>
      <link>https://stats.stackexchange.com/questions/660394/metropolis-hastings-algorithm-and-acceptance-probability</link>
      <description><![CDATA[根据我从维基百科中了解到的内容，在 Metropolis-Hastings 算法中，我们希望构建转移概率密度，以满足详细的平衡：
$P(x^{\prime},x) \pi(x)=P(x|x^{\prime})\pi(x^{\prime}) $
在上面的等式中，$\pi$ 是我们想要从中抽样的概率密度分布，$P$ 是转移概率密度。
原因是在马尔可夫链随机游走中构造上述转移概率密度，我们最终达到稳定状态，然后访问每个状态的次数与我们感兴趣的分布成正比。
通过将转移概率密度分为两部分来证明算法的合理性：

选择候选状态$x^\prime$的提议概率密度$g(x^\prime|x)$。
接受$A(x^\prime, x)$的概率（我不确定是概率密度还是概率质量）。
因此$P(x^\prime |x)=g(x^\prime|x)A(x^\prime, x)$。
接受概率分配如下：
$A(x^\prime, x) = min(1, \frac{\pi(x^\prime)g(x|x^\prime)}{\pi(x)g(x^\prime|x)})$。

这是我的问题：
算法将 $A$ 与 0 到 1 之间的随机数进行比较，以决定是否转换到状态 $x^\prime$。
但是，转换概率密度为 $P$。
我不明白这样一个不使用 $P$ 进行跳跃的马尔可夫链如何能够具有与 $\pi$ 成比例的静止状态。
算法使用 $A$ 进行跳跃的方式就好像 $A$ 是转移概率密度一样。
换句话说，我期望我们计算 $P$，然后将其与 0 到 1 之间的随机数进行比较。
我认为我错了，因为 $P$ 有一个数字，可以通过将其与均匀随机数进行比较来进行马尔可夫链模拟。实际上，构建 $P$ 仍然无法明确我们可能跳转到哪个状态，因此将这个概率密度分解为选择候选状态然后计算接受度的步骤。选择候选状态并根据接受度概率决定是否跳转的过程与构建所有 $P$ 然后以某种方式进行跳转的过程相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/660394/metropolis-hastings-algorithm-and-acceptance-probability</guid>
      <pubDate>Wed, 22 Jan 2025 23:45:05 GMT</pubDate>
    </item>
    <item>
      <title>比较覆盖概率和间隔长度：BCa 与百分位数引导方法</title>
      <link>https://stats.stackexchange.com/questions/660390/comparing-coverage-probabilities-and-interval-lengths-bca-vs-percentile-bootst</link>
      <description><![CDATA[我进行了参数引导研究，使用 35、50 和 100 的样本量对四个参数评估覆盖概率。3 个参数来自具有指数分布的混合模型，并通过 EM 算法进行估计：$\theta_{j}^{(k+1)} =\frac{\sum_{i=1}^{n} h_{ij}^{(k)}t_{i:n}}{\sum_{i=1}^{n} h_{ij}^{(k)}}$，其中 $h_{ij}^{(k)}$ 是后验概率。因此，无法确定估计的偏差。
在研究中，我计算了百分位数 CI 和 BCa CI。该问题与混合模型中的两个指数尺度参数有关。结果表明，百分位数法的覆盖概率趋于保守，而 BCa 方法通常可实现更接近标称水平的覆盖概率（$1-\alpha$）。但是，百分位数法的平均间隔长度通常较短。例如，对于 90% CI，百分位数法的 $\theta_{2}$ 覆盖概率为 95.2%，BCa 法为 88.3%。但是，百分位数的平均间隔长度为 9.09，BCa 法为 10.52。
我怀疑这种差异是由于研究中使用的样本量较小造成的。我查阅的一篇参考文献提到，BCa CI 可调整偏差和偏斜度，除小样本外，一般都是准确的。我也知道最短的 CI 并不总是最好的。从覆盖概率的角度来看，在这种情况下，BCa 似乎优于百分位数方法。但与直觉相反，较短的 CI 也提供了更高的覆盖概率。我应该如何证明我认为 BCa 更好？
我查阅了经典书籍，例如 Efron, B., &amp; Tibshirani, R. J. (1994) An Introduction to the Bootstrap、Davison, A. C., &amp; Hinkley, D. V. (1997) Bootstrap Methods and Their Application，并搜索了一些论文以找到类似的现象或讨论。但是，我还没有找到解决这一特定观察的明确理由，尤其是较短的 CI 提供了更高的覆盖概率。
是否有人有见解或参考资料可以提供对这种行为的更深入了解？在此先感谢您的想法和指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/660390/comparing-coverage-probabilities-and-interval-lengths-bca-vs-percentile-bootst</guid>
      <pubDate>Wed, 22 Jan 2025 18:45:21 GMT</pubDate>
    </item>
    </channel>
</rss>