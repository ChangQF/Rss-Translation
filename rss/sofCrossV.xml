<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 28 Sep 2024 15:18:06 GMT</lastBuildDate>
    <item>
      <title>平衡协变量与 OLS 回归中无偏估计的相关性</title>
      <link>https://stats.stackexchange.com/questions/655049/relevance-of-balanced-covariates-for-unbiased-estimates-in-ols-regression</link>
      <description><![CDATA[在我所从事的经济学领域，我遇到的许多论文都严重依赖观察数据进行分析。然而，我注意到，研究人员很少明确指出其回归模型中的协变量或“控制变量”在治疗组和对照组之间是否平衡。
例如，考虑一项研究，该研究考察了研发 (R&amp;D) 支出对公司绩效的影响。通常，研究人员会收集被认为会影响绩效的各种公司特征的数据，并将其用作控制变量。然而，除了其他潜在偏见之外，人们似乎很少关注这些控制变量在从事研发的公司和不从事研发的公司之间是否平衡。研究人员似乎更专注于包括控制，而不是确保平衡。
最近，我偶然发现了一篇采用不同方法的论文。它研究了创始人的性别对因变量 Y 的影响。作者通过使用倾向得分匹配来解决潜在的协变量不平衡问题。他们创建了一个匹配样本，其中控制变量在拥有男性和女性创始人的公司之间没有显著差异，从而确保了两组之间的可比性。这似乎是一种处理潜在混杂因素的更严格的方法，我在其他研究中很少看到这种方法被应用。
回归中不平衡的协变量是否会引起偏差，或者为什么实现平衡是有利的？从理论上讲，回归模型考虑了控制变量的差异，但也许不平衡​​可能会导致更微妙的偏差或效率低下，而匹配方法可以更有效地解决这些问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/655049/relevance-of-balanced-covariates-for-unbiased-estimates-in-ols-regression</guid>
      <pubDate>Sat, 28 Sep 2024 15:13:55 GMT</pubDate>
    </item>
    <item>
      <title>本科生学习随机过程的书籍/课程</title>
      <link>https://stats.stackexchange.com/questions/655045/book-course-for-undergraduates-to-learn-stochastic-processes</link>
      <description><![CDATA[目前，我正在阅读有关去噪扩散概率模型的文章。我第一次听说 DDPM 的想法时，我在想“这是不可能的！至少在使用计算器实现时，因为我们以位的形式存储浮点数的方式存在限制。所以，当添加这么多噪音时，信息肯定全部丢失了，那么我们如何才能逆转它呢？”。
从这个角度看 DDPM 对理解没有好处。我注意到有一种叫做“SDE 和逆 SDE”的东西，这让我想到了随机过程，我想这就是我所有问题的答案。
不幸的是，微积分、线性代数和概率在我所在的大学里都是在非常基础的水平上教授的，所以尽管我尝试搜索和阅读了很多，但似乎所有资源都需要更高水平的理解。例如，我遇到了许多不熟悉的术语，如$\sigma$-代数、测量理论等...
有没有适合我的理解水平的材料？]]></description>
      <guid>https://stats.stackexchange.com/questions/655045/book-course-for-undergraduates-to-learn-stochastic-processes</guid>
      <pubDate>Sat, 28 Sep 2024 12:51:16 GMT</pubDate>
    </item>
    <item>
      <title>测量支持直方图/概率分布的差距</title>
      <link>https://stats.stackexchange.com/questions/655042/measure-gaps-in-support-of-histogram-probability-distributions</link>
      <description><![CDATA[我有一个 Groundtruth 分布（绿色图表），我想使用 xgboost 进行学习。下图中的红色图表显示了 xgboost 学习到的预测的分布。顺便说一下，分布是股票实际波动率的分布。
正如您在绿色图表中看到的，在 Groundtruth 的支持中存在“间隙”，其中没有数据点，即空白。我希望有一个数量可以将这些间隙测量为一个值，以便我可以比较不同分布的这个数量。我知道我可以进行对数变换以使这个分布更紧凑，间隙更少。
但是，我的目标是表明，只要这些间隙非常大或分布中存在许多间隙，xgboost 的预测就会很差。这是因为 xgboost 基本上对训练集的 Groundtruth 进行平均以进行预测。因此，如果平均值的输入来自相隔较大间隙的区间，那么它们可能会导致区间之间的不良预测。
请注意，每当我比较不同的直方图/分布时，我都可以保持箱大小不变（1000）。什么是衡量这些差距的合适数量，我如何在 python 中实现这一点？这些“GAPS”有数学名称吗？
谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/655042/measure-gaps-in-support-of-histogram-probability-distributions</guid>
      <pubDate>Sat, 28 Sep 2024 10:16:46 GMT</pubDate>
    </item>
    <item>
      <title>ECT 系数的 VECM 分析解释</title>
      <link>https://stats.stackexchange.com/questions/655040/vecm-analysis-interpretation-of-ect-coefficients</link>
      <description><![CDATA[我可以说 ect1 很重要，因为 91.42％ 的值在一个时期后恢复到平衡状态吗？即使 ect1 的结果合乎逻辑，我也不确定我是否可以做出任何可靠的解释，因为 ect2-8 的值不合逻辑，并且模型发现其中一些值很重要。
结果：
ect1 = -9.142e-01***
ect2 = 5.191e+01***
ect3 = -3.894e+00***
ect4 = -4.152e+00**
ect5 = 1.302e+00
ect6 = 6.827e+01
ect7 = 1.408e+01***
ect8 = 1.292e+04
模型多重 R 平方： 0.5309
我可以从这个模型中对 ect1 做出解释吗？或者鉴于模型结果，整个模型不可靠吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655040/vecm-analysis-interpretation-of-ect-coefficients</guid>
      <pubDate>Sat, 28 Sep 2024 10:13:02 GMT</pubDate>
    </item>
    <item>
      <title>有没有什么办法可以解决边界占用太多空间以适应 GP 的问题？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655037/any-solution-for-bounds-taking-so-much-space-to-fit-gp</link>
      <description><![CDATA[我引入了数据边界以适应 GP。但它占用了太多空间。有解决方案吗？
我正在使用占用空间较少的 RBF 内核，但如果有其他解决方案，我将不胜感激。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/655037/any-solution-for-bounds-taking-so-much-space-to-fit-gp</guid>
      <pubDate>Sat, 28 Sep 2024 09:05:49 GMT</pubDate>
    </item>
    <item>
      <title>3种不同药物的疗效比较</title>
      <link>https://stats.stackexchange.com/questions/655036/comparison-of-effectiveness-of-3-different-drugs</link>
      <description><![CDATA[我正在对 3 种不同的药物进行药物现场试验，以测量它们的功效/效果。每种药物只给予其自己的一组动物。在个体动物中，在药物干预之前和之后测量感兴趣的参数。我使用配对 T 检验来比较各自组中每种药​​物的治疗前后的平均差异。我的主管希望我从统计学上比较这 3 种药物中哪一种最有效。我可以使用哪种测试？PS：我不擅长统计]]></description>
      <guid>https://stats.stackexchange.com/questions/655036/comparison-of-effectiveness-of-3-different-drugs</guid>
      <pubDate>Sat, 28 Sep 2024 08:32:26 GMT</pubDate>
    </item>
    <item>
      <title>$f(x;c\theta)$ 的解释</title>
      <link>https://stats.stackexchange.com/questions/655035/interpretation-of-fxc-theta</link>
      <description><![CDATA[我试图理解符号 $f(x;c\theta)$ 的含义，其中 $c$ 是已知常数。例如，假设随机变量 $X$ 服从泊松分布。当我们写 $f_X(x;2\theta)$ 时，我们是否只是暗示 $X \sim \operatorname{Poission}(2\theta)$？或者我们认为 $f_X(x;\theta) = f_X(x)$ 并采用 $f(x;2\theta)$ 来表示当您用 $2\theta$ 替换 $f_X(x)$ 中出现的每个符号 $\theta$ 时得到的表达式？
换句话说，假设
$$X \sim \operatorname{Poisson}(2\theta)$$
以下哪个陈述是正确的？
$$f_X(x;2\theta) = \frac{(2\theta)^xe^{-2\theta}}{x!} \tag{1}$$
$$f_X(x;2\theta) = \frac{(2(2\theta))^xe^{-2(2\theta)}}{x!} \tag{2}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/655035/interpretation-of-fxc-theta</guid>
      <pubDate>Sat, 28 Sep 2024 06:04:13 GMT</pubDate>
    </item>
    <item>
      <title>我们可以将傅里叶变换应用于非平稳数据吗？</title>
      <link>https://stats.stackexchange.com/questions/655033/can-we-apply-fourier-transform-on-non-stationary-data</link>
      <description><![CDATA[
嗨，我正在尝试预测美国通货膨胀率。单位是一年前百分比变化。是否可以对独立数据使用傅里叶变换来创建新特征，同时知道它是非平稳的？如果可能的话，我还可以获得更多参考吗？我是时间序列的新手，但学过预测课程。]]></description>
      <guid>https://stats.stackexchange.com/questions/655033/can-we-apply-fourier-transform-on-non-stationary-data</guid>
      <pubDate>Sat, 28 Sep 2024 01:59:57 GMT</pubDate>
    </item>
    <item>
      <title>brms 中的 Priors 并未按我预期的那样工作</title>
      <link>https://stats.stackexchange.com/questions/655043/priors-in-brms-are-not-working-as-i-expect</link>
      <description><![CDATA[我是贝叶斯统计的新手，我正在尝试使用 brms 拟合一个简单的线性回归并手动设置每个参数的先验，但它没有像我预期的那样工作
这是我的代码
data_2 &lt;- structure(list(YearsExperience = c(1.1, 1.3, 1.5, 2, 2.2, 2.9, 
3, 3.2, 3.2, 3.7, 3.9, 4, 4, 4.1, 4.5, 4.9, 5.1, 5.3, 5.9, 6, 
6.8, 7.1, 7.9, 8.2, 8.7, 9, 9.5, 9.6, 10.3, 10.5), Salary = c(39343L,
46205L, 37731L, 43525L, 39891L, 56642L, 60150L, 54445L, 64445L, 
57189L, 63218L, 55794L, 56957L, 57081L, 61111L, 67938L, 66029L, 
83088L, 81363L, 93940L, 91738L, 98273L, 101302L, 113812L, 109431L, 
105582L, 116969L, 112635L, 122391L, 121872L)), 类= &quot;data.frame&quot;, row.names = c(NA, 
-30L))

priors &lt;- c(
set_prior(&quot;normal(28700, 2000)&quot;, class = &quot;Intercept&quot;),
set_prior(&quot;normal(9006, 1000)&quot;, class = &quot;b&quot;, coef = &quot;YearsExperience&quot;),
set_prior(&quot;normal(0, 2000)&quot;, class = &quot;sigma&quot;, lb = 0) 
)

fit_brms &lt;- brm(Salary ~ YearsExperience, data = data_2, Prior=priors)

但是，当我绘制链时，截距为负值，例如，当先验分布远离负值。而且我设置的先验并非完全不准确。
使用手动先验拟合的模型
如果我使用默认先验进行拟合，效果很好。]]></description>
      <guid>https://stats.stackexchange.com/questions/655043/priors-in-brms-are-not-working-as-i-expect</guid>
      <pubDate>Fri, 27 Sep 2024 21:16:13 GMT</pubDate>
    </item>
    <item>
      <title>具有斜率函数的用户指定值的边际效应</title>
      <link>https://stats.stackexchange.com/questions/655041/marginal-effects-at-user-specified-values-with-slopes-function</link>
      <description><![CDATA[我在使用 marginaleffects 包的 slope 函数估计用户指定值的边际效应时遇到了麻烦
假设我想用帕尔默企鹅数据集预测 body_mass_g
library(marginaleffects)

dat &lt;- read.csv(&quot;https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv&quot;)


这是我的函数。我想将 flipper_length 设置为 180，将 bill_length_mm  设置为 39 或 40。
mod.lm &lt;- lm(body_mass_g ~ bill_length_mm + flipper_length_mm + species,
data = dat)

slopes(
mod.lm,
newdata = datagrid(
flipper_length_mm = 180,
bill_length_mm = c(39,40)))



我知道有些地方不对劲，因为所有预测变量的估计值都是无论 bill_length_mm 的值设置为 39 还是 40，结果都是相同的。
我尝试使用 glm 二元结果变量运行类似的模型，它按预期工作。
dat$large_penguin &lt;- ifelse(dat$body_mass_g &gt; median(dat$body_mass_g, na.rm = TRUE), 1, 0)

mod &lt;- glm(large_penguin ~ bill_length_mm + flipper_length_mm + species,
data = dat, family = binomial)

slopes(
mod,
newdata = datagrid(
flipper_length_mm = 180,
bill_length_mm = c(39,40)))


为什么 lm 模型没有按预期运行，而 glm 模型却能？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/655041/marginal-effects-at-user-specified-values-with-slopes-function</guid>
      <pubDate>Fri, 27 Sep 2024 21:04:18 GMT</pubDate>
    </item>
    <item>
      <title>合并两个群体的均值和协方差矩阵</title>
      <link>https://stats.stackexchange.com/questions/655028/combining-mean-and-covariance-matrix-of-two-populations</link>
      <description><![CDATA[假设我有$X$个点$x_i$，位于$\mathbb{R}^N$中，分为两个子组$X_1$和$X_2$，大小分别为$n_1$和$n_2$。
如果我知道两个子组的均值$\mu_1, \mu_2$和协方差矩阵$\Sigma_1, \Sigma_2$，我该如何计算均值和总体协方差$X$？
我遇到了合并协方差的公式$$\frac{(n_1 - 1)\Sigma_1 + (n_2 - 1)\Sigma_2}{n_1 + n_2 - 2}$$
但我明白这依赖于两个总体具有相同均值和协方差的假设，我认为我这样假设是不安全的。首先，这似乎没有考虑到如果两个子群体相距甚远，我期望看到的协方差的变化。
我需要合并组 $X$ 的均值和协方差，就像我从单个元素 $x_i$ 的总体计算出来一样。这个公式是什么？（我发现找到我需要的公式出乎意料地困难）。如果 $n_1$ 和 $n_2$ 被视为实值权重，公式会改变吗（我认为不会）？]]></description>
      <guid>https://stats.stackexchange.com/questions/655028/combining-mean-and-covariance-matrix-of-two-populations</guid>
      <pubDate>Fri, 27 Sep 2024 20:10:12 GMT</pubDate>
    </item>
    <item>
      <title>协变量斜率系数的多元回归置信区间</title>
      <link>https://stats.stackexchange.com/questions/655026/multiple-regression-confidence-intervals-for-slope-coefficient-of-a-covariate</link>
      <description><![CDATA[在构建这样的置信区间并评估其是否包含 0（用于 t 检验以查看协变量是否与回归相关）时，其他变量是否在某些水平上受到控制或保持不变（它们的平均值？）
Wackerley、Mendenhall 和 Schaffer 有以下问题。
考虑一般线性模型
$$Y = \beta_0 + \beta_1 x_1 + ... + \beta_k x_k + \epsilon$$
其中 $E(\epsilon) = 0$ 和 $V(\epsilon) = 0$。然后，他们要求验证 $E(\hat{\beta}_i) = \beta_i$ 和 $V(\hat{\beta}_i) = c_{ii}\sigma^2$，其中 $c_{ii}$ 是 $(X&#39;X)^{-1}$ 行 $i$ 和列 $i$ 中的元素
因此，在构建 $\beta_i$ 的 $100(1-\alpha)\%$ 置信区间时，他们有：$\hat{\beta}_i \pm t^{n-k-1}_{\frac{\alpha}{2}} S \sqrt{c_{ii}} $。这个区间的准确解释是什么，特别是当它与其他变量的情况相关时——它们是固定的还是在某种意义上受控制的？
我的问题出现是因为在陈述假设检验（t 检验以查看协变量是否显着）时，他们只陈述：
$$H_0: \beta_i = 0$$
$$H_a: \beta_i \neq 0$$
没有明确说明此测试是否控制其他变量或在某种程度上固定它们。执行此测试时其他变量究竟发生了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655026/multiple-regression-confidence-intervals-for-slope-coefficient-of-a-covariate</guid>
      <pubDate>Fri, 27 Sep 2024 19:16:42 GMT</pubDate>
    </item>
    <item>
      <title>GAM 中的高 GVIF</title>
      <link>https://stats.stackexchange.com/questions/655021/high-gvif-in-gam</link>
      <description><![CDATA[我的 GVIF 一直很高（带有 INF），在进行 GAM 分析后，我合并了大多数分类变量的级别。我还删除了一些变量，但 GVIF 仍然很高。请帮忙。下面是我的代码，我是新手，所以我的代码可能看起来有些奇怪。我只对我的连续变量应用了平滑处理。
gam_model &lt;- gam(log_HDDS~ s(log_obesogenic_share, k = 10) + 
s(sec_asset, k = 12) + 
s(SSIrecalcrounded, k = 7) +
s(House_h_age, k =8) +
s(time_to_clst_mrkt, k = 7) +
s(hh_mem_no, k = 7) +
s(educ, k = 7) +
factor(buying_food_who_grouped) +
factor(Marital_status) +
factor(loan) +
factor(ration_card_grouped) +
factor(main_occ_grouped) +
factor(Caste_Grouped) +
factor(transect_id) ,
family = gaussian(link = &quot;identity&quot;),
method = &quot;REML&quot;, 
select = TRUE, 
paraPen = list(log_obesogenic_share =list(diag(1)),
sec_asset= list(diag(1)),
SSIrecalcrounded = list(diag(1)),
House_h_age = list(diag(1)),
time_to_clst_mrkt = list(diag(1)),
hh_mem_no = list(diag(1)),
educ= list(diag(1))), 
data = diet_data)

这是我的 GVIF 结果：
vif(gam_model)
GVIF Df GVIF^(1/(2*Df))
factor(buying_food_who_grouped) 1.025172e+25 0 Inf
因素（婚姻状况） 1.025172e+25 0 Inf
因素（贷款） 1.025172e+25 0 Inf
因素（配给卡分组） 1.025172e+25 0 Inf
因素（主要人口分组） 1.025172e+25 0 Inf
因素（种姓分组） 1.025172e+25 0 Inf
因素（横断面 ID） 1.025172e+25 0 Inf
log_obesogenic_share 1.025172e+25 0 Inf
sec_asset 1.025172e+25 0 Inf
SSIrecalcrounded 1.025172e+25 0 Inf
House_h_age 1.025172e+25 0 Inf
time_to_clst_mrkt 1.025172e+25 0 Inf
hh_mem_no 1.025172e+25 0 Inf
educ 1.025172e+25 0 Inf
]]></description>
      <guid>https://stats.stackexchange.com/questions/655021/high-gvif-in-gam</guid>
      <pubDate>Fri, 27 Sep 2024 16:28:06 GMT</pubDate>
    </item>
    <item>
      <title>glmmTMB 泊松模型的伪 R 平方 = 1 是否可能/是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/655017/is-a-pseudo-r-squared-of-glmmtmb-poisson-model-1-possible-does-it-make-sense</link>
      <description><![CDATA[我正在对动物行为数据运行多个 glmmTMB 模型。其中 2 个模型的伪 R2 为 1 或基本为 1。在我看来，这意味着该模型完美地解释了数据中的方差。这对我来说似乎不现实。没有办法，我捕获了影响焦点动物行为的所有变量。
关于我的数据：
这些模型基于类似的数据。本质上，我检查动物是否利用它们每天遇到的机会。所以我的数据是日期、动物 ID、动物年龄、遇到的机会、可用时间、机会的属性 1、机会的属性 2、使用机会的次数（可能是 0）。
例如，在第 1 天，鸟 A（0.5 岁）来到一棵具有属性 X 和 Y 的喂食树 C。鸟 A 在喂食树 C 周围待了 2 小时，并在其上进食 3 次（使用机会的次数）。每天的机会数量各不相同，可用时间必须大于 0，使用机会的次数可以为 0。属性不能为 0。我们想看看年龄和属性如何影响机会使用。
关于模型：
我正在 R 中运行一个带有二次项的泊松模型，其中 glmmTMB 的结构如下：
所有连续变量都是 z_transformed
model &lt;- glmmTMB( data=data, NrOppUsed ~ (age + age_squared) + prop1 + 
prop2 + (1|Animal ID) + (1|Animal ID nested in Day), 
offset=log(hours of available), family=poisson(link=&quot;log&quot;) )

R2：
我使用函数 r.squaredGLMM 是因为我会喜欢得到一个效果的衡量标准。
作为第一步，我很想了解，如果 R2 为 1 是否有意义，或者 glmmTMB 对此是否有我不知道的影响。
编辑：
这是只有一个属性变量的模型之一的模型输出：
&gt; summary(pois)
家族：泊松 ( log )
公式：oppuse ~ (age_z + age_z2) * prop1 + (1 | FollowNr)
数据：mydata
偏移：log(OpportunitiesH)

AIC BIC logLik 偏差 df.resid 
690.0 732.5 -335.0 670.0 509 

随机效应：

条件模型：
组名称方差标准差
FollowNr (截距) 0.9561 0.9778 
观察数：519，组：FollowNr，252

条件模型：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -3.85404 0.41505 -9.286 &lt; 2e-16 ***
age_z -0.55049 0.62194 -0.885 0.3761 
age_z2 0.09125 0.27845 0.328 0.7431 
prop1AM -25.67345 14.87040 -1.726 0.0843 . 
prop1O 2.65656 0.43172 6.153 7.58e-10 ***
age_z:prop1AM -119.54493 66.23843 -1.805 0.0711 . 
age_z:prop1O -1.21462 0.74712 -1.626 0.1040 
age_z2:prop1AM -125.25394 73.19725 -1.711 0.0870 . 
age_z2:prop1O -1.43462 0.56042 -2.560 0.0105 * 
---
Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

我用 DHARMA 检查了复杂性、过度分散、奇异性、共线性、残差分布，所有这些都很好。]]></description>
      <guid>https://stats.stackexchange.com/questions/655017/is-a-pseudo-r-squared-of-glmmtmb-poisson-model-1-possible-does-it-make-sense</guid>
      <pubDate>Fri, 27 Sep 2024 15:15:25 GMT</pubDate>
    </item>
    <item>
      <title>预测的可能性::Arima 与手动复制</title>
      <link>https://stats.stackexchange.com/questions/654959/likelihood-from-forecastarima-vs-manual-replication</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654959/likelihood-from-forecastarima-vs-manual-replication</guid>
      <pubDate>Thu, 26 Sep 2024 16:07:18 GMT</pubDate>
    </item>
    </channel>
</rss>