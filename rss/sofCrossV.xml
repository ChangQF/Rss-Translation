<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 05 Dec 2023 15:15:25 GMT</lastBuildDate>
    <item>
      <title>现实生活过程中群体内和群体间的差异？</title>
      <link>https://stats.stackexchange.com/questions/633119/within-group-and-between-group-variation-in-real-life-processes</link>
      <description><![CDATA[在统计过程控制 (SPC) 的背景下，控制图用于监控过程随时间的变化并检测平均值或变化的变化。传统的 Shewhart $\bar{X}$ 图表利用（理性）组方法来监控一段时间内的过程平均值。然而，假设之一是不存在组间差异。虽然这是流程的理想场景，但在现实世界中似乎并不现实。准确地说，传统图表中使用的底层模型是
$$X_{ij} = \mu + \varepsilon_{ij} \tag{M1},$$
其中 $\mu$ 是过程平均值， $\varepsilon_{ij} \sim N(0,\sigma^2 )$ 是一个随机变量。该模型未能考虑组间差异。
文章具有常见原因变异性的几个组成部分的统计过程控制（Woodall 和 Thomas，1995）讨论了这个主题，并附有一个示例。他们提出了模型
$$X_{ij} = \mu + \beta_{i}+\varepsilon_{ij} \tag{M2},$$
现在 $\beta_i \sim N(0,\sigma_{B}^2)$ 是一个随机变量，用于解释组间变异。它们还引用其他作者提出的其他具体例子。
然而，我想知道是否有关于这个主题的更大规模和/或更近期的研究。理想情况下，研究使用行业数据来表明通常存在组间差异。我将非常感谢任何参考或想法！]]></description>
      <guid>https://stats.stackexchange.com/questions/633119/within-group-and-between-group-variation-in-real-life-processes</guid>
      <pubDate>Tue, 05 Dec 2023 15:01:44 GMT</pubDate>
    </item>
    <item>
      <title>我可以在配对数据上使用 kmeans_</title>
      <link>https://stats.stackexchange.com/questions/633118/can-i-use-kmeans-on-paired-data</link>
      <description><![CDATA[我想看看治疗是否可以使用多个因变量使患者更接近对照。我可以做 kmeans 并查看对照组在治疗前是否与患者分开，但在治疗后聚集在一起吗？我可以报告这一点，还是观察结果不独立意味着我不能使用聚类？]]></description>
      <guid>https://stats.stackexchange.com/questions/633118/can-i-use-kmeans-on-paired-data</guid>
      <pubDate>Tue, 05 Dec 2023 14:57:58 GMT</pubDate>
    </item>
    <item>
      <title>离散和连续之间的相关系数：可能吗？</title>
      <link>https://stats.stackexchange.com/questions/633117/correlation-coefficient-between-discrete-and-continuous-is-it-possible</link>
      <description><![CDATA[衡量连续变量和离散变量之间的相关系数是否正确？我将其可视化，并且在我看来绝对不存在线性关系，这就是为什么我决定不可能计算它的相关系数。这是我正在处理的两个变量，显示在边际图上。 ]]></description>
      <guid>https://stats.stackexchange.com/questions/633117/correlation-coefficient-between-discrete-and-continuous-is-it-possible</guid>
      <pubDate>Tue, 05 Dec 2023 14:53:07 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用 mgcv 的 GAMM：参与者对分类变量的随机效应</title>
      <link>https://stats.stackexchange.com/questions/633116/gamm-using-mgcv-in-r-by-participant-random-effects-for-categorical-variables</link>
      <description><![CDATA[我正在使用 mgcv 拟合 GAMM。我有两个变量，一个是分类两级变量差异，另一个是连续变量Learning_stage。我希望参与者对差异产生随机效应，特别是随机斜率和截距。 stackoverflow 链接有一个答案，指出带有 bs=&#39;fs&#39; 的因子变量会导致每个因子水平的截距。如果我是正确的，带有 bs=&#39;re&#39; 的平滑函数应该给出随机斜率。
这是否意味着我需要添加术语 s(difference,participant, bs=&#39;re&#39;) 以及 s(difference,participant, bs=&#39;fs&#39;, m=1)？
目前定义的模型：
模型 &lt;- bam(误差 ~ 差异 + s(Learning_stage) + s(Learning_stage, by=difference) + s(Learning_stage, 参与者, bs=&#39;fs&#39;, m=1), data=data_for_gamm ）
]]></description>
      <guid>https://stats.stackexchange.com/questions/633116/gamm-using-mgcv-in-r-by-participant-random-effects-for-categorical-variables</guid>
      <pubDate>Tue, 05 Dec 2023 14:52:39 GMT</pubDate>
    </item>
    <item>
      <title>平滑尖峰需求预测的目标变量</title>
      <link>https://stats.stackexchange.com/questions/633115/smoothing-out-target-variable-for-spiky-demand-forecasting</link>
      <description><![CDATA[我正在尝试根据之前的需求、天气、大型人群聚集和类似的时空因素，使用机器学习来预测美国某个城市地区未来一小时的救护车需求。
我通过将时间划分为 1 小时的区间来对问题进行建模，因为这些短时间范围的预测应该提供最大的价值。我会每小时向潜在用户提供这些预测。我尝试了时间序列和回归方法，但由于我只预测未来的一个值，回归更容易实现，并且对特征的突然变化反应更好，而时间序列模型产生平滑的预测曲线，这对我没有帮助。 
但是，通过将需求按小时分箱，目标变量非常尖，并且在值 0、1、3、0 等之间突然跳跃 - 并且很难预测。
除了难以预测之外，分箱还会产生在实际应用中很糟糕的效果。
假设我有以下紧急情况：
12:45 - 1 辆救护车
14:01 - 3 辆救护车
14:45 - 1 辆救护车
对于每小时的垃圾箱 [12:00, 13:00)、[13:00, 14:00)、[14:00, 15:00)，需求为：
1, 0, 4。
但是，[14:00, 15:00) 的 4 辆救护车中的 3 辆非常接近 13:00。因此，如果我在 13:00 有一些特征可以反映需求的增加，则模型会感到困惑，因为需求发生在下一个垃圾箱中。
我的第一个问题是：我的方法正确吗？有没有一种简单的方法可以解决我遇到的问题？（要求接近垃圾箱限制）
与大学的一些同事交谈后，他们建议我尝试使用移动平均线来平滑需求曲线。因此，我可以将 3 在 14:01 的部分需求“分配”到其相邻的 bin，[12:00, 13:00)。
方法是：

将有关紧急情况的原始数据重新采样到 1 分钟的数据集中
应用 W 窗口大小的移动平均值（滚动平均值），假设 W=60
将结果移动 -30 ( =-W/2 )，以便将需求分配到左侧和右侧，直到发生时的分钟。

我的经验不是很丰富，所以我有一个简单的问题：
平滑目标需求曲线有意义吗？如果不是 MA，指数 MA 有帮助吗？ 我发现了一篇文章，评估预测性能时使用平滑目标变量，这表示预测平滑需求并不意味着预测常规需求。但如果我的项目上架，潜在客户就会使用我的模型 - 因为，如果我确实预测 [13:00, 14:00) 的值高于 0，基于平滑的需求，我仍然会获得一些价值根据预测，因为预测的需求将在一分钟后发生 - 14:01。
我的最后一个问题是关于转变的。创建训练数据集时，在一分钟内向左和向右分配需求是有意义的，以减轻分箱效应。如果 W=60 太大，我也可以将其降低到 W=5 - 这样，只有 14:00-14:04 区间内发生的需求才会分配到 [13:00, 14:00) bin .
但是当我创建推理样本时，似乎会丢失一些数据。如果我预测 [14:00, 15:00)，并且 13:55 中有 3 个需求，那么需求将分配到左侧垃圾箱和右侧垃圾箱。但是，因为我没有跟踪推理样本中的目标变量（这是我试图预测的），所以应该分配到右侧的部分将会丢失。或者，我可以将其作为另一个功能进行跟踪。
这种转变有意义吗？
很抱歉这篇文章很长，但我缺乏严格的培训，并且确实需要一些帮助来验证这些想法。尽管其中一些在方法论上可能不正确，但我要求您也看看我的模型的实际应用。我已经设法跟踪需求趋势并生成平滑的预测曲线。现在我更感兴趣的是预测突然增加并生成高需求警报。]]></description>
      <guid>https://stats.stackexchange.com/questions/633115/smoothing-out-target-variable-for-spiky-demand-forecasting</guid>
      <pubDate>Tue, 05 Dec 2023 14:43:49 GMT</pubDate>
    </item>
    <item>
      <title>基于具有边界条件的决策树的聚类</title>
      <link>https://stats.stackexchange.com/questions/633114/clustering-based-on-a-decision-tree-with-boundary-conditions</link>
      <description><![CDATA[我遇到的问题如下：

我的数据集包含多个连续值变量（目标变量）和多个离散值、分类变量和数值变量（预测变量）。
本质上，我必须简单地预测目标变量，但业务流程所有者对可解释性和可追溯性有很高的需求，并且不愿意接受针对给定实例给出唯一预测的预测模型。
他们表示，可接受的折衷方案是将数据集分组为例如20 个组，确定每个新的未见过的实例属于哪些组，然后将该组的平均值作为预测。 “规则”如何根据预测变量形成这些组应该是可以直观掌握的。
如果我基于连续值目标变量进行 KMeans 聚类，然后拟合例如以聚类为目标、离散值变量作为预测变量的决策树分类器，我将得到一个精度相对较差的决策树，但结构相当复杂，无法提供太多所需的可解释性。

我想知道是否有针对此类问题的术语，以及是否有一些基于决策树的方法，您可以在其中设置边界条件，例如a）最小拟合阈值和b）最大树深度，以及然后将在这些边界条件下以最佳方式形成簇。所以在这个问题中，“善”是指“善”。为了获得一组精确的规则和树的简单性，可以牺牲聚类的性能。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/633114/clustering-based-on-a-decision-tree-with-boundary-conditions</guid>
      <pubDate>Tue, 05 Dec 2023 14:35:10 GMT</pubDate>
    </item>
    <item>
      <title>如何对这个数据集进行建模？</title>
      <link>https://stats.stackexchange.com/questions/633113/how-to-model-this-dataset</link>
      <description><![CDATA[我正在使用一个数据集 (my_dataset)，该数据集由六组个人 (Team_ID) 组成，并带有一个因变量 Score 表示小组的表现得分（范围在 0 到 1 之间）。该数据集包括各种个人层面的特征，例如人口信息、教育、就业状况和收入。这是数据集的简化版本：
Team_ID &lt;- c(1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5, 5, 5, 6, 6)
分数＜-c(0.82、0.82、0.82、0.82、0.82、0.1、0.1、0.43、0.43、0.43、0.65、0.65、0.93、0.93、0.93、0.93、0.93、0.24、0.24)
截距 &lt;-rep(1, length(Team_ID))
D1 &lt;- c(1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
D2 &lt;- c(0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
D3 &lt;- c(0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0)
D4 &lt;- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0)
D5 &lt;- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0)
性别 &lt;- c(1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1)
年龄 &lt;- c(38, 39, 44, 60, 29, 18, 34, 19, 43, 56, 35, 25, 43, 31, 51, 55, 54, 28, 53)
Educ &lt;- c(2, 2, 1, 1, 4, 3, 5, 5, 1, 5, 1, 3, 1, 5, 3, 1, 1, 2, 2)
Emp_Unemp &lt;- c(1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1)
收入 &lt;- c(457.37, 1267.59, 3304.82, 1143.71, 2800.09, 1149.06, 1377.78, 1882.33, 2095.88, 2667.53, 592.9, 944.27, 1479.07, 1 764.27、1062.84、788.15、1882.96、1315.33、1410.25）
婚姻状态 &lt;- c(1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0)

my_dataset &lt;- data.frame(Team_ID, Score, Intercept, D1, D2, D3, D4, D5, Sex, Age, Educ, Emp_Unemp, Income, Marital_Status)

我想根据所提供的特征来估计个人对小组分数的贡献。我主要担心两个问题：

Score 的重复：从计量经济学的角度来看，Score 在每个组中重复的事实是否会引起担忧？我应该如何在建模过程中解决这个问题？请注意，我添加了组固定效果。
建模约束 Score：由于 Score 变量被限制在 0 和 1 之间并遵循正态分布，因此考虑到这一点，我如何正确地对该变量进行建模？ 
]]></description>
      <guid>https://stats.stackexchange.com/questions/633113/how-to-model-this-dataset</guid>
      <pubDate>Tue, 05 Dec 2023 14:23:35 GMT</pubDate>
    </item>
    <item>
      <title>ANCOVA 中回归斜率的同质性和协变量的共线性（特定）</title>
      <link>https://stats.stackexchange.com/questions/633111/homogeneity-of-regression-slopes-and-collinearly-of-covariates-in-ancova-specif</link>
      <description><![CDATA[感谢您为统计学习者提供如此出色的网站，我目前正在研究阶乘 ANCOVA，有两个问题：

我们是否需要测试交互效应回归斜率的同质性？我觉得答案是肯定的，但又有点怀疑。我的意思是，假设我有两个自变量，如果是阶乘方差分析，我还会在模型中包含一个交互效应，因此将有 3 个效应（2 个主要效应和 1 个交互效应）。当我们添加协变量时，我们应该测试回归斜率同质性的假设，我们肯定对主变量这样做，但是交互效应呢？我们可以将 X1X2Covariate 添加到模型中来测试它是否显着吗？

当我们有多个协变量时，我们通常会检查它们在模型中的共线性，我们可以将它们输入到正则线性回归模型中并检查 VIF 和公差，但是如果我们有一个分类协变量，我们是否应该检查它也是吗？


最诚挚的问候，尤利娅]]></description>
      <guid>https://stats.stackexchange.com/questions/633111/homogeneity-of-regression-slopes-and-collinearly-of-covariates-in-ancova-specif</guid>
      <pubDate>Tue, 05 Dec 2023 14:08:18 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.decomposition PCA fit_transform() 对于完全相同的数组返回不同的结果[重复]</title>
      <link>https://stats.stackexchange.com/questions/633110/sklearn-decomposition-pca-fit-transform-returns-different-results-for-the-exac</link>
      <description><![CDATA[如果 PCA 是一种确定性算法，为什么对同一数组进行两个单独的 PCA 运算的结果甚至彼此不接近？
编辑：
这不是符号问题（使用 abs() 进行比较）或舍入问题（相对容差设置为 0.5），因为某些组件彼此相距较远（参见“index: (1032, 94)”或“index” ：(1031, 96)”如下）。
导入操作系统
将 numpy 导入为 np
从 sklearn.decomposition 导入 PCA

ANOMALOUS_SIM_PATH = &#39;F:\\模拟&#39;
ARRAY_PATH = os.path.join(ANOMALOUS_SIM_PATH,f&#39;x_ano_all_frames.csv&#39;)

array1 = np.loadtxt(ARRAY_PATH, 分隔符=&#39;,&#39;, dtype=&#39;float64&#39;)
数组2 = 数组1

打印（数组1.形状）
打印（数组2.形状）
print((数组1 == 数组2).all())
    
pca = PCA(n_components=100)
pca1 = pca.fit_transform(array1)
pca2 = pca.fit_transform(array2)

差异元素数量 = 0
对于 row_idx，枚举（pca1）中的行：
    对于 col_idx，枚举（行）中的 ele：
        如果不是 math.isclose(abs(ele),abs(pca2[row_idx][col_idx]),rel_tol=5e-01):
            print(f&quot;索引: {(row_idx, col_idx)}&quot;)
            print(f&quot;pca1({abs(pca1[row_idx][col_idx])}) != pca2({abs(pca2[row_idx][col_idx])})\n&quot;)
            差异元素数量 += 1

打印（差异元素数量）

返回：
&lt;前&gt;&lt;代码&gt;(1310, 12800)
(1310, 12800)
真的

。
。
。
索引: (1031, 92)
pca1（0.12145175532743172）！= pca2（0.5621405441582706）

索引: (1031, 96)
pca1(2.3164349846263335)！= pca2(0.9747261872012252)

索引: (1031, 98)
pca1（0.05119788377587365）！= pca2（0.7088755416892464）

索引: (1032, 81)
pca1（0.06989350435644263）！= pca2（0.2852301464532744）

索引: (1032, 89)
pca1（0.28495036194592877）！= pca2（1.3319731591786539）

索引: (1032, 90)
pca1（1.04483454177602）！= pca2（0.38822823882364993）

索引: (1032, 94)
pca1（2.3367930839638844）！= pca2（0.9162623843701563）

索引: (1032, 95)
pca1（0.27313415621862785）！= pca2（0.7626759286144326）

索引: (1032, 96)
pca1（0.055941886220714554）！= pca2（1.5496023192278918）

索引: (1032, 99)
pca1(2.8958942540126653)！= pca2(0.626261628534446)

索引: (1033, 70)
pca1（0.21339758180112187）！= pca2（0.10490373211976906）

索引: (1033, 72)
pca1（0.19849374119073468）！= pca2（0.46316811926574625）

索引: (1033, 80)
pca1（0.6938482863541385）！= pca2（0.10018983330774708）

索引: (1033, 84)
pca1（0.3946980923756375）！= pca2（0.18650121989489932）

索引: (1033, 85)
pca1（0.32958237659688583）！= pca2（0.8372177307507211）
。
。
。

差异元素数量：12132
]]></description>
      <guid>https://stats.stackexchange.com/questions/633110/sklearn-decomposition-pca-fit-transform-returns-different-results-for-the-exac</guid>
      <pubDate>Tue, 05 Dec 2023 13:43:59 GMT</pubDate>
    </item>
    <item>
      <title>线性判别分析中的scalings_属性是什么？</title>
      <link>https://stats.stackexchange.com/questions/633105/what-is-the-scalings-attribute-in-linear-discriminant-analysis</link>
      <description><![CDATA[学习使用 sklearn 进行线性判别分析，对拟合模型的 scalings_ 属性有点困惑。 LDA分类器可以写为
$$\delta_k(x)=x^{T}\Sigma^{-1} \mu_k + C_k,$$
其中 $C_k$ 是一个不依赖于 $x$ 的常量。文档说缩放是预测变量的线性组合，所以我假设这是 $\Sigma^{-1} \mu_k$ 项。
但是，在拟合 LDA 分类器 lda.fit(X_train,Y_train) 并进行比较之后
np.lingalg.inv(lda.covariance_) @ lda.means_ 
lda.scalings_,
它们是不同的，我可以看到我错了，因为两个结果不一样。事实上，第一个结果是 $2 \times 2$ 矩阵，第二个结果是 $1 \times 2$&lt; /span&gt; 行向量。所以，不确定我的误解在哪里。感谢您的阅读。]]></description>
      <guid>https://stats.stackexchange.com/questions/633105/what-is-the-scalings-attribute-in-linear-discriminant-analysis</guid>
      <pubDate>Tue, 05 Dec 2023 12:57:18 GMT</pubDate>
    </item>
    <item>
      <title>如何计算零截断和一膨胀的泊松回归</title>
      <link>https://stats.stackexchange.com/questions/633107/how-to-compute-a-poisson-regression-zero-truncated-and-one-inflated</link>
      <description><![CDATA[我正在处理每次旅行的行程数据，将旅行视为一个人连续进行的各种旅行。我正在尝试用计数模型对此进行建模。我的因变量是每次旅行的出行次数，自变量是出行者的特征（年龄、性别等），或旅行本身的特征（汽车百分比、公共交通百分比等） ）。我正在研究 R 并使用 VGAM 包。
我想使用泊松和负二项式对这种情况进行建模，并且由于数据不包含 0（不存在 0 次旅行的旅行），因此我使用了两个模型零截断。我用过
vglm( y ~ x1 + x2 + ..., family = pospoisson(), data = DB)
vglm( y ~ x1 + x2 + ..., 族 = 正二项式, 数据 = DB)

效果不太好。 Poisson ZT 发送一些关于变量 Hauck-Donner 效应的警告，当我删除该警告时，截距出现错误。在负二项式 ZT 的情况下，它永远不会停止运行，当我强制停止时，最后一条消息是
边界附近的解；要么不需要拟合正 NBD，要么分布以值 1 为中心。
正如我所见，我有很多，当我做直方图时，它非常明显，所以我不仅需要泊松和在 0 处截断的负二项式，而且还需要计算效果该数据被夸大为 1。
在互联网上进行研究后，我没有找到任何直接可以帮助我做到这一点的东西，例如 VGAM 包，所以我寻求帮助。如果你知道一种用一对代码行来做到这一点的方法，那就太棒了，但我不知道我的要求是否太多。无论如何，任何帮助都会有所帮助。
即使对我提出的警告（Hauck-Donner 效应）进行一些澄清也会有所帮助，它们是否只影响警告所针对的变量的重要性，还是也影响其他变量？对于效果（测试版）也有同样的问题。泰斯姆。]]></description>
      <guid>https://stats.stackexchange.com/questions/633107/how-to-compute-a-poisson-regression-zero-truncated-and-one-inflated</guid>
      <pubDate>Tue, 05 Dec 2023 12:50:23 GMT</pubDate>
    </item>
    <item>
      <title>解决线性混合模型中随机效应的非正态性</title>
      <link>https://stats.stackexchange.com/questions/633104/addressing-non-normality-of-random-effects-in-linear-mixed-model</link>
      <description><![CDATA[我有一个范例，参与者在三种不同的刺激“条件”下完成反应时间任务。我为我的混合模型生成了两个对比。我制作了下面的图来评估随机效应的正态性。这里评估的随机效应是（条件|参与者）。

有人可以解释一下“随机效应分位数”和“标准正态分位数”（轴标签）的含义吗？

如何纠正非正态性？转型？稳健回归？这可能是由参与者异常值引起的吗？


]]></description>
      <guid>https://stats.stackexchange.com/questions/633104/addressing-non-normality-of-random-effects-in-linear-mixed-model</guid>
      <pubDate>Tue, 05 Dec 2023 12:39:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么完整的统计命名为“完整”？</title>
      <link>https://stats.stackexchange.com/questions/633103/why-are-complete-statistics-named-complete</link>
      <description><![CDATA[我明白为什么足够的统计数据被命名为“足够”，但是“完整”呢？统计数据？
这个定义来自 F.J. Samaniego，随机建模和统计数学，2014：如果对于所有函数 $T$ 是完整的=&quot;math-container&quot;&gt;$g$ 使得 $\mathbb{E}(​​g(T)) = 0$，我们有 $g(t) = 0$ 对于 $t$ -container&quot;&gt;$T$。
这个命名是否与 Lehmann-Scheffé 定理相关，该定理指出无偏估计量 $\hat\theta = g(T)$ 是 &lt; 的唯一 MVUE span class=&quot;math-container&quot;&gt;$\theta$ 如果 $T$ 足够且完整？]]></description>
      <guid>https://stats.stackexchange.com/questions/633103/why-are-complete-statistics-named-complete</guid>
      <pubDate>Tue, 05 Dec 2023 12:38:30 GMT</pubDate>
    </item>
    <item>
      <title>配对组的预测试后数据的多元方差分析相当于什么？</title>
      <link>https://stats.stackexchange.com/questions/633101/what-is-the-equivalent-of-manova-for-pretest-postest-data-for-paired-groups</link>
      <description><![CDATA[我如何测试仅针对实验组的焦虑和攻击行为的前测和后测差异？注意到我已经进行了多元方差分析，发现实验组和对照组在焦虑和攻击行为的后测结果上存在统计显着差异，现在我需要评估两次测量（前测后测）之间两个因变量的差异对照组。
重复测量多元方差分析是否正确？如果我对待预测试实验组和p]]></description>
      <guid>https://stats.stackexchange.com/questions/633101/what-is-the-equivalent-of-manova-for-pretest-postest-data-for-paired-groups</guid>
      <pubDate>Tue, 05 Dec 2023 12:29:09 GMT</pubDate>
    </item>
    <item>
      <title>当我们预期回报和波动时的成功概率</title>
      <link>https://stats.stackexchange.com/questions/633097/success-probability-when-we-have-expected-return-and-volatility</link>
      <description><![CDATA[我正在阅读《被随机性愚弄》，作者说，15% 的回报率和 10% 的波动性意味着一年内 93% 的成功率和任何特定秒内 50.02% 的成功率。
有人可以帮我理解这个计算吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/633097/success-probability-when-we-have-expected-return-and-volatility</guid>
      <pubDate>Tue, 05 Dec 2023 12:06:01 GMT</pubDate>
    </item>
    </channel>
</rss>