<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 22 May 2024 01:02:10 GMT</lastBuildDate>
    <item>
      <title>GridSearchCV 的表现比基线差</title>
      <link>https://stats.stackexchange.com/questions/647727/gridsearchcv-performs-worse-than-baseline</link>
      <description><![CDATA[我正在使用 scikit-learn 解决二元分类问题。我测试过的模型之一是 KNeighborsClassifier，我使用默认参数获得了 78% 的基线分数 (“recall_macro”)。此外
然后我运行一个 GridSearchCV 交叉验证器（使用包含默认值的参数网格，仅使用训练集，并针对我需要的评分指标），但我得到“优化的”得分71%。不仅如此，少数群体的召回率也从 59% 下降到 43%。
据我了解，GridSearchCV 运行的数据与模型所拟合的数据并不完全相同，因此可能存在轻微差异，但这似乎过多。我错过了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647727/gridsearchcv-performs-worse-than-baseline</guid>
      <pubDate>Wed, 22 May 2024 00:33:29 GMT</pubDate>
    </item>
    <item>
      <title>关于组合相对风险解释的问题</title>
      <link>https://stats.stackexchange.com/questions/647726/question-about-combined-relative-risk-interpretation</link>
      <description><![CDATA[我正在查看有关吸雪茄影响的评论，但我无法解释其中的一些结果。研究链接如下：研究
具体来说，我对下面的表 3 有疑问：
&lt;img alt=&quot;表 3&quot; src=&quot;https://i.sstatic.net/OlFWCFN1.png ” /&gt;
在 Primay 雪茄系列中，对于 50-64 岁、每天使用 1-2 支的人来说，RR 为 1.1。然而，综合值为 1.02 (0.97-1.07) (95% CI)。
我知道，每天吸烟 1-2 次的人的综合 CI 可以解释为相对于从不吸烟者，全因死亡率增加 2%，但这并不具有统计显着性。
我可以将组合 CI 单独推断到 50-64 组吗？换句话说，我可以说“50-64岁每天吸1-2支雪茄的人，相对于从不吸烟的人来说，全因死亡率增加了10%，但这种风险在统计上并不显着。”？]]></description>
      <guid>https://stats.stackexchange.com/questions/647726/question-about-combined-relative-risk-interpretation</guid>
      <pubDate>Wed, 22 May 2024 00:25:52 GMT</pubDate>
    </item>
    <item>
      <title>ShapeNet UAE KL 发散问题</title>
      <link>https://stats.stackexchange.com/questions/647724/shapenet-vae-kl-divergence-issues</link>
      <description><![CDATA[我正在尝试在 shapenet 上训练 VAE，但似乎无法使其工作。任何帮助或想法将不胜感激。现在的问题是，每当我应用 KL 散度损失时，网络似乎都会陷入高 KL 散度和高重建损失的困境。即使没有 KL 散度（普通自动编码器），重建也几乎是完美的。
问题设置：
输入：shapenet的64^3 TSDF
目前，我只是尝试使用大约（6.5k 椅子）的椅子类别
输出：64^3 TSDF-重建
网络架构：我主要使用与 AutoSDF，这是一个全3D卷积编码器和解码器，用于输出最终的TSDF矩阵。我尝试了各种潜在空间大小，但似乎都不起作用。
KL散度损失函数：
loss = -0.5 * torch.sum(1 + logvar.flatten(1) - mu.flatten(1).pow(2) -
                                    logvar.flatten(1).exp(), 暗淡=1)
损失 = torch.mean(损失, 暗淡=0)

其中 mu 和 logvar 是编码器的 3D 输出（尝试使用不同的潜在空间大小，如下所述）。
实验设置列表

(2*8*8*8)、(4*8*8*8*8)、(8*8* 的潜在空间8*8*8) (16*8*8*8*8) 、 (32*8*8*8) 和 ( 64*8*8*8)：它们似乎都不适用于 VAE 设置，但是 (16*8*8*8*8) 、 (32* 8*8*8) 和 (64*8*8*8) 在常规 AE 设置中效果良好。
在最终输出中添加线性层，以获得在一个实验中维度为 512 维、在另一个实验中维度为 1024 的 mu 和 logvar -&gt;让事情变得更糟
遵循此&lt;a href=&quot;https://stats.stackexchange.com/questions/332179/how-to-weight-kld-loss-vs-reconstruction-loss-in-variational-auto-encoder中的所有建议”线程&lt;/a&gt;。包括“KL成本退火”和“循环退火”。
尝试通过潜在空间的维数标准化 KL 损失权重
重构加权和KL散度加权的几种组合
使用总和减少而不是均值来获得重建损失的更高优先级

以上似乎都不起作用，我现在已经做了相当多的研究，但我不知道下一步该做什么，所以我将不胜感激任何帮助或讨论。]]></description>
      <guid>https://stats.stackexchange.com/questions/647724/shapenet-vae-kl-divergence-issues</guid>
      <pubDate>Tue, 21 May 2024 23:42:45 GMT</pubDate>
    </item>
    <item>
      <title>使用随机对照试验的双重差异或双重差异</title>
      <link>https://stats.stackexchange.com/questions/647721/difference-in-differences-or-difference-in-difference-in-differences-using-a-ran</link>
      <description><![CDATA[对于一个学术项目，我获得了随机对照试验的数据集。我需要使用这个数据集来得出“农作物收割机”技术的处理效果。
数据 - 数据来自地块级别的三波（2019 年、2020 年和 2022 年）700 个农户。因此，大约有 3500 个观测值。这些数据报告人口统计信息、地块特征以及农作物产量、成本等结果。
对这些家庭进行了一项随机对照试验（RCT），其中的处理是收获和收获后技术的好处的“技术演示”。其中包括展示“农作物收割机”的好处。 RTC 是在第一波数据收集后进行的。 2020 年和 2021 年总共进行了 2 次“技术演示”。这些演示后，一些处理过的样品采用了“作物收割机”，而另一些则没有。
样本选择 - 这些住户位于村庄内（41 个村庄），位于称为 Halqa 的较高地理单元内（总共 4 个），位于称为 tehsils 的较高地理单元内（总共 2 个）。 4 个 Halqa 中，2 个接受治疗，2 个为对照。两个 tehsil 都治疗并控制了 Halqa
该研究遵循整群随机对照试验（CRCT）设计。
在第一阶段，特赫西尔是在每个目标地区内有目的地选择的。
在每个选定的 tehsil 中，都根据足以让农作物收割机移动到村庄的金属道路的标准选择了两个 Halqas。
在村庄的选择上，在每个选定的哈尔卡内，以是否有机械运输道路为标准，选择了一些地理位置相近的村庄。
采用完全清点法列出农民名单后，在选定的两个哈尔卡中，随机将其中一个分配到治疗组。
我有两个问题。

根据我掌握的数据，差异中的差异 (DID) 或方差分析是否合适？
我处理这些数据的任务是找出“农作物收割机”的治疗效果。然而，“技术演示”包括对包括“农作物收割机”在内的多种收割技术的培训。根据对文献的一些阅读，我想知道是否需要使用三重差异（差异 - 差异 - 差异）方法。 DID 将为我提供“技术演示”的“治疗效果”，而 DDD 将通过采用“农作物收割机”来区分技术演示的治疗效果。
任何建议表示赞赏。
谢谢
]]></description>
      <guid>https://stats.stackexchange.com/questions/647721/difference-in-differences-or-difference-in-difference-in-differences-using-a-ran</guid>
      <pubDate>Tue, 21 May 2024 22:44:11 GMT</pubDate>
    </item>
    <item>
      <title>APIM 和 ANOVA 混合了？</title>
      <link>https://stats.stackexchange.com/questions/647719/apim-and-anova-mixed</link>
      <description><![CDATA[我正在提议一个研究项目，其中将包括有关夫妻满意度的二元数据。这是一项随机对照试验，旨在调查干预措施对提高夫妻满意度和一个人的治疗依从性的功效。我的问题是，我可以将 APIM 模型与 ANOVA 混合结合使用吗？如果是，那么我具体该如何使用它？我应该提到的是，我有 2 个自变量，在组之间（2 个组）以及每个参与者的不同时间点内 + 2 个因变量（夫妇满意度和治疗依从性）。我还有一个中介假设，指出夫妻满意度是干预和依从性之间的中介。谢谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/647719/apim-and-anova-mixed</guid>
      <pubDate>Tue, 21 May 2024 21:19:21 GMT</pubDate>
    </item>
    <item>
      <title>ARCH 经验残差的相关性</title>
      <link>https://stats.stackexchange.com/questions/647717/dependence-in-arch-empirical-residuals</link>
      <description><![CDATA[假设 $R_1, R_2, \dots, R_T$ 是 ARCH(1) 过程的观测值 ($R_i = \sigma_i z_i$）。然后我估计 ARCH(1) 参数 $\hat{\omega}, \hat{\alpha}$ 并计算经验残差为
$$\hat{z}_i = \frac{R_i}{\hat{\sigma}_i},$$
其中 $\hat{\sigma}^2_i = \hat{\omega} + \hat{\alpha} R^2_{i-1}$。这个经验残差显然不是独立的。然而，当 $T$ 增长时，它们会“越来越多”。独立。
我对经验残差这一属性的形式化感兴趣。例如，我想说 $\hat{z}_1, \hat{z}_2, \dots, \hat{z}_T$ 是$\beta$-混合序列。不幸的是，我无法找到有关此主题的任何材料。]]></description>
      <guid>https://stats.stackexchange.com/questions/647717/dependence-in-arch-empirical-residuals</guid>
      <pubDate>Tue, 21 May 2024 20:41:35 GMT</pubDate>
    </item>
    <item>
      <title>重复测量方差分析的样本量</title>
      <link>https://stats.stackexchange.com/questions/647712/sample-size-for-repeated-measures-anova</link>
      <description><![CDATA[我正在计算重复测量方差分析（受试者内）所需的样本量。我遇到了两个不同的包，结果也不同。
使用“WebPower”包和以下函数
wp.rmanova(n = NULL, ng = 1, nm = 4, f = 0.25, nscor = 1, alpha = 0.05, power = 0.8, type = 1)

我得到了这个结果：
重复测量方差分析

           n f ng nm nscor α 功率
    175.7464 0.25 1 4 1 0.05 0.8

注：效果内测试的功率分析
网址：http://psychstat.org/rmanova

使用“pwrss”包和以下函数
pwrss.f.rmanova(eta2 = 0.06, n.levels = 1, n.rm = 4, power = 0.80, alpha = 0.05, corr.rm = 0.50, 
类型=“内”）

我得到了这个结果：
 单向重复测量 
 方差分析（F 检验） 
 H0：eta2 = 0（或f2 = 0） 
 HA：eta2＞1。 0（或f2&gt;0） 
 ------------------------------------------ 
 级别（组）数 = 1 
 重复测量次数 = 4 
 ------------------------------------------ 
  统计功效 = 0.8 
  总计 n = 23 
 ------------------------------------------ 
 效果类型=“内部” 
 分子自由度 = 3 
 分母自由度 = 65.029 
 非中心参数 = 11.579 
 I 类错误率 = 0.05 
 II 类错误率 = 0.2 

我还使用 GPower 来比较结果，并且根据不同的效应大小规范，我还获得了不同的样本大小。当我使用默认的 GPower3 效果大小规范时，我得到 n = 24。

使用科恩效应大小规范，我得到 n = 176。

还有一个“SPSS”工具选项给了我 61 的样本量。我还读到，如果您采用 Cohen 的计算，将 n 除以测量次数 - 1，然后添加组数，您将得到 SPSS 样本量计算，结果一致：176/ (4-1) + 1 = 60。谁能告诉我哪种方法是正确的？这些计算的差异很大，从 24 到 176 不等。]]></description>
      <guid>https://stats.stackexchange.com/questions/647712/sample-size-for-repeated-measures-anova</guid>
      <pubDate>Tue, 21 May 2024 17:54:17 GMT</pubDate>
    </item>
    <item>
      <title>足够的统计数据是否意味着 𝑓 : 𝑝 𝜃 ↦ 𝑝 𝑇 | 𝜃 应该是内射的吗？反过来呢？</title>
      <link>https://stats.stackexchange.com/questions/647650/does-a-sufficient-statistic-imply-%e2%86%a6-should-be-injective-w</link>
      <description><![CDATA[维基百科说
&lt;块引用&gt;
...考虑地图
𝑓
：
𝑝
𝜃
↦
𝑝
𝑇
|
𝜃
它采用模型参数的每个分布
𝜃
其统计分布
𝑇
.当 𝑓 是满射时，称统计量 𝑇 是完整的，并且
当 𝑓 是单射时就足够了。

我认为𝑓可以是内射的，但统计量还不够。考虑给定参数 θ 的样本 X 的条件分布：（表 1）

&lt;标题&gt;


θ1
θ2


&lt;正文&gt;

x1
0.1
0.2


x2
0.2
0.2


x3
0.3
0.3


x4
0.4
0.3



这是样本 X 到统计量 T 的映射：（表 2）

&lt;标题&gt;

样本
统计


&lt;正文&gt;

x1
t1


x2
t1


x3
t2


x4
t2



给定参数 θ，得出统计量 T 的以下条件分布：（表 3）

&lt;标题&gt;


θ1
θ2


&lt;正文&gt;

t1
0.3
0.4


t2
0.7
0.6



在这种情况下𝑓：𝑝𝜃↦𝑝𝑇 | 𝜃 是单射的，因为 t1 的后验概率是 θ2 的先验概率的单调递增函数。 （由表3可推导出）
统计量 T 是不够的，因为对于给定的 T，X 的条件概率是 θ 的函数。 （由表1和表2可推导出）
我也认为相反的情况是错误的，即如果统计量足够则 𝑓 是内射的，这是错误的。我认为如果我们强制参数化是单射的（我的意思是 θ 的两个值不能给出相同的 X 分布），这可能是正确的，但不确定这通常是否被认为是正确的？
我找到了相反的证据（即足够的⟹单射）]]></description>
      <guid>https://stats.stackexchange.com/questions/647650/does-a-sufficient-statistic-imply-%e2%86%a6-should-be-injective-w</guid>
      <pubDate>Mon, 20 May 2024 21:03:12 GMT</pubDate>
    </item>
    <item>
      <title>统计测试看看一组是否比另一组生长得更快</title>
      <link>https://stats.stackexchange.com/questions/647648/statistical-test-to-see-whether-one-group-grew-faster-than-the-other</link>
      <description><![CDATA[我有 2020 年至 2023 年 2 组参与者人数的数据。我可以使用任何统计测试来测试 A 组的参与者数量是否比 B 组的百分比增长更快？比如 A 组在 2023-2020 年增长了 527%，而 B 组仅增长了 13.6%
集团年份 注册人数
2020年51
2021年120
2022年260
2023 320
乙 2020 1600
乙 2021 1800
乙 2022 2250
乙 2023 2600
]]></description>
      <guid>https://stats.stackexchange.com/questions/647648/statistical-test-to-see-whether-one-group-grew-faster-than-the-other</guid>
      <pubDate>Mon, 20 May 2024 20:56:34 GMT</pubDate>
    </item>
    <item>
      <title>组关联值汇总统计的标准化</title>
      <link>https://stats.stackexchange.com/questions/647644/standardization-of-summary-statistic-of-group-linked-values</link>
      <description><![CDATA[假设您在固定大小的测量窗口中沿着一长串值测量汇总统计量（例如算术平均值），并且这些值被分组为属于两个类之一的区域（A和&lt;代码&gt;ØA）：
&lt;预&gt;&lt;代码&gt;值：21 22 14 89 76 45 33 14 52 61  
组：|A A A |ØA ØA ØA ØA ØA ØA |A   
统计：| 21.5 | 21.5 51.5 | 51.5 60.5 | 60.5 23.5 | 23.5 56.5 | 56.5

如果您想测试 A 组区域中的值与 ØA 组区域中的值在统计上是否不同，则比较未经调整的汇总统计数据不是正确的：
&lt;前&gt;&lt;代码&gt; A = 21.5 + (51.5/2) + (56.5/2) = 75.5
ØA = (51.5/2) + 60.5 + 23.5 + (56.5/2) = 138

相反，需要按组长度对值进行标准化。 在这种计算中标准化值的数学首选形式是什么？
例如，是否只是将汇总统计数据除以实际比较次数：
&lt;前&gt;&lt;代码&gt;A = 75.5/4 = 18.875
ØA = 138/6 = 23

&lt;小时/&gt;
编辑 1：根据评论者的请求，以下是示例的替代显示：
&lt;预&gt;&lt;代码&gt;值：21 22 14 89 76 45 33 14 52 61  
x_栏: | 21.5 | 21.5 51.5 | 51.5 60.5 | 60.5 23.5 | 23.5 56.5 | 56.5
组：|一个一个| A ØA |ØA ØA |ØA ØA |ØA A | 
]]></description>
      <guid>https://stats.stackexchange.com/questions/647644/standardization-of-summary-statistic-of-group-linked-values</guid>
      <pubDate>Mon, 20 May 2024 20:11:29 GMT</pubDate>
    </item>
    <item>
      <title>荟萃分析中死亡率结果的汇总风险比或粗事件（M-H 到 RR 或 OR）？</title>
      <link>https://stats.stackexchange.com/questions/647643/pooled-hazard-ratio-or-crude-events-m-h-to-rr-or-or-for-mortality-outcomes-in</link>
      <description><![CDATA[我正在执行 MA 来评估治疗 A 相对于安慰剂（或倾向匹配对照组）相对于全因死亡的效果。
我的 MA 中包含的所有研究都报告了原始事件和 HR（95% CI）（通常是 Cox 回归模型）。因此，我可以使用带有粗事件的 M-H 模型来执行汇总效果，或者使用逆方差 (LogHR) 来执行对比度水平。
我的问题是：哪种方法是最好的方法以及我应该如何以不同的方式解释汇总结果（LogHR 或 RR/OR 与 H-M）。
&lt;小时/&gt;
@Björn
感谢您详尽的回答。按照你所说的，使用 HR 作为旨在调查死亡率的荟萃分析的民意调查效果，其结果可以应用于分析研究之外的人群，在我看来是最科学正确的策略（也因为最科学的策略之一）在数量方面的代表性研究不报告原始事件，但 HR &gt; 因此使用 HR 作为 RR 来包含在计算中，正如一些人建议的那样，这在我看来是有点不正确的近似值）。
此外，使用 HR 作为汇总效应大小，我发现异质性小于通过插入原始事件获得的异质性（可能是因为一些研究发现事件比预期少）。
不过，我想再问您四个问题：

纳入的研究报告了 HR 和上限/下限（95% CI），但没有报告标准误差 &gt;例如，全因死亡 HR 0.96（95% CI，0.78 - 1.19）p 0.21。为了计算 RevMan 上具有逆方差的汇总效应，我使用计算器插入 HR、CI 以及下限和上限 &gt;因此是导出 LogHR 和标准误差的计算器。它仍然是一个统计上可接受的程序还是一个近似值？
这种类型的荟萃分析（即使用 HR 作为汇总效应）是否应该更恰当地称为“事件发生时间荟萃分析”？
荟萃分析中包含的一些研究不是随机对照试验，而是采用倾向匹配分析的观察性研究。在这种情况下，通常会报告两个 HR 值（调整后的和未调整的）。就这些具体研究而言，使用调整后的 HR 以获得更正确地适用于外部人群的汇总效应是否更正确，还是相反？
汇总 HR 是否足以计算 NNT？现在，每个纳入研究的发病率是否可以计算各组中的合并发病率来计算 NNT？举个例子：报告的风险比为 h=0.72，95% 置信区间为 0.55 至 0.92。因此，2 年时需要治疗的人数估计为 1/(0.330.72–0.33)=8.32。

感谢您的关注。]]></description>
      <guid>https://stats.stackexchange.com/questions/647643/pooled-hazard-ratio-or-crude-events-m-h-to-rr-or-or-for-mortality-outcomes-in</guid>
      <pubDate>Mon, 20 May 2024 20:01:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么 GLM 没有误差项，为什么残差不应该是 i.i.d？</title>
      <link>https://stats.stackexchange.com/questions/647624/why-glm-dont-have-an-error-term-and-why-shouldnt-residuals-be-i-i-d</link>
      <description><![CDATA[我已经阅读了数十篇有关该主题的帖子，但我无法弄清楚这一点。根据我收集的信息，GLMS 与线性模型 (LM) 不同，其公式中不包含误差项。我想知道为什么（或者为什么 LM 包含该错误项，如果它们是奇怪的）？我觉得这是由于正态分布的附加属性，这使得在 LM 中可以通过关注 Y 的均值并添加一个以 0（误差项）为中心且方差适合的正态分布变量来对 Y 的分布进行建模$\sum_i X_i$ 的方差与 Y 的方差之间的差距。但是链接函数不是应该将非正态分布变量转换为正态分布变量吗因此可以使用错误术语？
注意：如果您可以在答案中提供连续分布的示例，而不仅仅是离散分布，那就太好了，因为我很难理解离散分布的问题。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/647624/why-glm-dont-have-an-error-term-and-why-shouldnt-residuals-be-i-i-d</guid>
      <pubDate>Mon, 20 May 2024 17:12:03 GMT</pubDate>
    </item>
    <item>
      <title>具有 BF 相关性的单尾贝叶斯相关假设，解释输出？</title>
      <link>https://stats.stackexchange.com/questions/647418/one-tailed-bayesian-correlation-hypothesis-with-bfcorrelation-interpretation-ou</link>
      <description><![CDATA[对于以下命令：
correlationBF(df$var1, df$var2, nullInterval = c(-1, 0))

我得到了结果输出
贝叶斯因子分析
--------------
[1]替代，r=0.333 -1＜rho＜0：96.40458±NA%
[2]替代，r=0.333!(-1＜rho＜0)：0.06047267±NA%

反对分母：
  空，rho = 0 
---
贝叶斯因子类型：BFcorrelation、Jeffreys-beta*

我现在想获得假设相关性  的 BF。 0. 起初我以为是 96.4，但我很困惑，因为替代假设的 BF 不应该是 1/96.4 而不是 0.06 吗？
或者我需要将两个结果相除，但为什么？
非常感谢任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/647418/one-tailed-bayesian-correlation-hypothesis-with-bfcorrelation-interpretation-ou</guid>
      <pubDate>Fri, 17 May 2024 10:23:46 GMT</pubDate>
    </item>
    <item>
      <title>用 cox 测试解释结果</title>
      <link>https://stats.stackexchange.com/questions/647375/interpreting-results-with-a-cox-test</link>
      <description><![CDATA[我正在尝试使用 lmtest 库中的 coxtest 来比较 2 个非嵌套模型。遗憾的是我找不到有关此测试结果的任何解释。
我的第一个目标是使用anova(model1, model2)来比较2个测试，但我失败了，因为我使用不同的数据库（仅不同的观察数：485 vs 500 obs，但数据来源相同）。 
一些网页描述该测试验证一个模型是否比其他模型更好。但在我的第二个和第三个例子中没有验证这一点。或者只测试两个模型是否不同？
可能我错过了什么或者我做错了什么......
这里我测试相同的模型，相同的数据库但不同的观察数：
库(lmtest)

模型1：Gasto~log(Ingreso)
模型2：Gasto~log(Ingreso)
                    估计标准。误差z值Pr(&gt;|z|)    
拟合(M1) ~ M2 -0.037 0.0033982 -1.1011e+01 &lt; 2.2e-16***
拟合(M2) ~ M1 -253.894 0.0000885 -2.8705e+06 &lt; 2.2e-16***
    ---
西尼夫。代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1&#39;&#39;1
警告消息：
1：在 coxtest(mod4, mod5) 中：适合不同子集的模型
2：在 coxtest(mod4, mod5) 中：指定不同的因变量

为什么两个模型都很显着？在什么意义上有不同？ M1和M2有什么不同？或更好？ M2与M1不同吗？或者更好？
这里我测试了不同的模型，相同的数据库。
我更改 Gasto 的名称只是为了验证模型顺序更改是否会在表中产生结果，例如：
coxtest(mod3, mod4):
    
模型 1：Gasto3 ~ Ingreso
模型2：Gasto~log(Ingreso)
                            估计标准。误差z值Pr(&gt;|z|)    
已安装(M1) ~ M2 -0.075 0.218506 -0.3454 0.7298    
已安装(M2) ~ M1 -209.031 0.010401 -20097.4191 &lt;2e-16 ***
            ---
西尼夫。代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1&#39;&#39;1
警告消息：
1：在 coxtest(mod3, mod4) 中：适合不同子集的模型
2：在 coxtest(mod3, mod4) 中：指定不同的因变量

&gt;考克斯测试
        
考克斯测试（mod4，mod3）：
    
模型1：Gasto~log(Ingreso)
模型 2：Gasto3 ~ Ingreso
估计标准。误差z值Pr(&gt;|z|)    
已安装(M1) ~ M2 -0.134 0.210933 -0.6361 0.5247    
已安装(M2) ~ M1 -253.604 0.012717 -19942.2191 &lt;2e-16 ***
            ---
西尼夫。代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1&#39;&#39;1
警告消息：
1：在 coxtest(mod4, mod3) 中：适合不同子集的模型
2：在 coxtest(mod4, mod3) 中：指定不同的因变量

在最后一个结果中，我预计 p 值位于第一个结果中，而不是最后一个结果中，因为我更改了模型的顺序。
有人可以提供一些建议或更好地解释吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647375/interpreting-results-with-a-cox-test</guid>
      <pubDate>Thu, 16 May 2024 16:40:55 GMT</pubDate>
    </item>
    <item>
      <title>寻找嘈杂多边形的角点</title>
      <link>https://stats.stackexchange.com/questions/647344/finding-the-corners-of-noisy-polygons</link>
      <description><![CDATA[我有一些多边形，例如如下所示：

如果我将一侧放大得非常近，您可以看到噪音。

数据是 x 坐标列表和相应的 y 坐标列表。
我想要一种能够找到更小、更简单、噪音更少的坐标列表的算法。
我认为多边形的边是线性方程的连续列表。
我读到了Lasso并决定尝试一下。
from sklearn.linear_model import Lasso
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

xs_name = &quot;xs.txt&quot;;
ys_name = &quot;ys.txt&quot;;

xs = np.loadtxt(xs_name).reshape(-1, 1)
ys = np.loadtxt(ys_name).reshape(-1, 1)

reg = 套索(alpha=0.1)
reg.fit(xs, ys)

供参考，xs 和 ys 如下所示：
xs

ys

但是我只得到一个系数
&lt;前&gt;&lt;代码&gt;reg.coef_
输出[31]：数组（[0.82647029]）

我希望获得每条识别线的系数列表。
我觉得我在概念上错过了一些东西。我什至不确定 Lasso 是否适合这项工作。
有谁知道我如何正确使用 Lasso，或者向我指出完成这项工作的正确工具。
&lt;小时/&gt;
编辑
x 坐标
坐标
我还认为值得一提的是，调查论文中也提到了 group lasso 破裂库
&lt;小时/&gt;
编辑
为了清楚起见，放大的区域用红色圈出

编辑
我在 R 中尝试自回归模型取得了一些成功
xs &lt;- read.table(&#39;xs.txt&#39;, sep=&quot;\n&quot;)
ys &lt;- read.table(&#39;ys.txt&#39;, sep=&quot;\n&quot;)

xs &lt;- as.numeric(as.character(unlist(xs)))
ys &lt;- as.numeric(as.character(unlist(ys)))

fastcp_xs &lt;- fastcpd::fastcpd.ar(xs, 3, r.progress = FALSE)
摘要（fastcp_xs）
情节（fastcp_xs）


然而，在这种情况下，这种方法的成功似乎主要是运气，因为在更多数据上尝试此方法会发现不好的结果。
在 ys 上尝试相同的方法：
fastcp_ys &lt;- fastcpd::fastcpd.ar(ys, 3, r.progress = FALSE)
摘要（fastcp_ys）
情节（fastcp_ys）


自回归模型无法检测 ys 的边缘。
fastcpd 库中的其他例程在我的情况下似乎给出了类似的糟糕结果。
我目前认为我最好的选择是某种形式的套索算法。因为套索的概念是拟合一系列直线。
这可能会变成线性规划问题。
也许我需要求助于使用类似 pyomo 的东西？]]></description>
      <guid>https://stats.stackexchange.com/questions/647344/finding-the-corners-of-noisy-polygons</guid>
      <pubDate>Thu, 16 May 2024 07:46:23 GMT</pubDate>
    </item>
    </channel>
</rss>