<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 20 Oct 2024 15:16:55 GMT</lastBuildDate>
    <item>
      <title>如果样本不成对，我应该使用哪种测试来评估两个分类变量的比例是否随时间发生变化？</title>
      <link>https://stats.stackexchange.com/questions/656039/which-test-should-i-use-to-evaluate-if-there-is-a-change-in-proportion-of-two-ca</link>
      <description><![CDATA[我正在分析一个包含 100 项临床试验的数据集。对于每个试验，我都有一个分类变量（报告的利益冲突：“是”/“否”）和一个序数变量（出版年份）。我想测试分类变量的“是”/“否”比率是否随时间统计不同（假设：最近的研究报告利益冲突的频率更高）。出版年份范围从 2000 年到 2020 年，如果需要，我可以考虑将它们分组（例如：对每 5 年发表的研究进行分组）。我遇到了 Cochrane Q 检验和 McNemar 检验，但据我所知，它们都要求样本配对，当然事实并非如此（每年我都有一组不同的研究）。
在这种情况下，使用哪种统计检验最好？]]></description>
      <guid>https://stats.stackexchange.com/questions/656039/which-test-should-i-use-to-evaluate-if-there-is-a-change-in-proportion-of-two-ca</guid>
      <pubDate>Sun, 20 Oct 2024 14:37:50 GMT</pubDate>
    </item>
    <item>
      <title>接收者操作特征的 AUC</title>
      <link>https://stats.stackexchange.com/questions/656038/auc-for-receiver-operating-characteristic</link>
      <description><![CDATA[我在网上看到了这个定义：
$
\text{AUROC} = \int_0^1 \text{TPR}(\text{FPR}) \, d(\text{FPR})
$
但我不确定它是否正确以及应该如何解释，尽管一般的 ROC 和 AUC 概念对我来说直观清晰。这是我的想法：
我猜使用 Riemann-Stieltjes，因为原则上不能保证您有一条可微分曲线。因此我们需要泛化，因为部分我们想要对面积求和，而可微分部分可以用黎曼积分计算。但如果我们可以将其简化为黎曼积分，该如何解读它？我猜你是在 x 轴（FPR）上从 0 到 1 积分，并向上积分 TPR 下的面积？但这不是很精确，而且我不确定如何简化公式以便人们能够看到这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/656038/auc-for-receiver-operating-characteristic</guid>
      <pubDate>Sun, 20 Oct 2024 13:44:22 GMT</pubDate>
    </item>
    <item>
      <title>Python 中 1:1 比例的二项式检验</title>
      <link>https://stats.stackexchange.com/questions/656037/binomial-test-in-python-for-11-ratio</link>
      <description><![CDATA[我收集了如下的性别比例数据：
 公司 A 公司 B 公司 C
部门 女性 男性 女性 男性 女性 男性
艺术 98 2 95 5 80 20
工程 2 98 30 70 10 90
家政 100 0 90 10 70 30

现在，我的老师要求我做一个二项式检验（然后是卡方检验），以确定性别比例是否与 1:1 有统计学上的显著差异。我该如何在 Python 中做到这一点？
我尝试在这里阅读有关这个​​概念的内容：
https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/hypothesis-testing/hypothesis-testing-with-the-binomial-distribution.html
但我不确定如何具体实现它以及在哪里使用哪些变量。因为我有 3 个不同的变量：性别、公司名称和部门。或者我应该跳过部门，对不同公司进行一般比例比较？
我猜这里可能有几种不同的方法，所以我愿意听取建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/656037/binomial-test-in-python-for-11-ratio</guid>
      <pubDate>Sun, 20 Oct 2024 13:39:34 GMT</pubDate>
    </item>
    <item>
      <title>多个数据集上多个模型的统计显著性</title>
      <link>https://stats.stackexchange.com/questions/656036/statistical-significance-of-multiple-models-over-multiple-datasets</link>
      <description><![CDATA[我有一张表格，其中列出了 6 个模型在 10 个数据集上的平均表现。虽然我在研究论文中看到过这样的表格，但它们总是以粗体显示显著结果。我不确定这些测试是如何进行的？结果与什么相比明显更好？我确实进行了 Friedman 检验和 Nemenyi 校正，也进行了 Wilcoxon 成对比较，但当涉及到下面这种类型的表格时，我不确定如何进行！

谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/656036/statistical-significance-of-multiple-models-over-multiple-datasets</guid>
      <pubDate>Sun, 20 Oct 2024 13:33:43 GMT</pubDate>
    </item>
    <item>
      <title>寻求有关固定效应 DID 回归的建议</title>
      <link>https://stats.stackexchange.com/questions/656035/seeking-advice-for-did-regression-with-fixed-effect</link>
      <description><![CDATA[由于我对此还比较陌生，因此我想寻求有关固定效应回归的 DID 的建议。我想研究从贸易优惠计划中撤出特定产品时对其征收的关税税率对该国出口的影响。我对变量有疑问，因为它是在产品层面，我目前只有 2016-2020 年每种产品的出口数据和从 2020 年开始变化的关税税率。你能解释一下我应该怎么做吗？你能否也给我展示一下我在 Stata 中应该使用什么来获取 DID 变量，即产品出口与产品关税税率变化之间的相互作用。提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/656035/seeking-advice-for-did-regression-with-fixed-effect</guid>
      <pubDate>Sun, 20 Oct 2024 12:07:36 GMT</pubDate>
    </item>
    <item>
      <title>为什么神经网络训练中的所有这些自适应方法都需要 $g_t^2$ 项？</title>
      <link>https://stats.stackexchange.com/questions/656033/why-does-all-these-adaptive-methods-in-neural-network-training-require-a-g-t2</link>
      <description><![CDATA[所有自适应学习方法，AdaGrad、AdaDelta、RMSprop、ADAM 以及后续变体都需要 $g_t^2$，即以元素方式将梯度乘以自身。
为什么需要这样做？我从未找到令人信服的论据。]]></description>
      <guid>https://stats.stackexchange.com/questions/656033/why-does-all-these-adaptive-methods-in-neural-network-training-require-a-g-t2</guid>
      <pubDate>Sun, 20 Oct 2024 09:55:16 GMT</pubDate>
    </item>
    <item>
      <title>多臂老虎机问题的 epsilon-贪婪算法的遗憾界</title>
      <link>https://stats.stackexchange.com/questions/656031/regret-bound-of-epsilon-greedy-algorithm-for-multi-armed-bandit-problem</link>
      <description><![CDATA[考虑$1$-亚高斯 MAB，其中$n\geq 2$，考虑$\epsilon$-贪婪算法：首先选择每个臂一次，然后选择$A_t=\arg\max \hat \mu_i(t-1)$，其中 pr。 $1-\epsilon_t$，否则随机均匀选择一个臂。
我们想要证明，假设$\Delta_{\min}=\min\{\Delta_i:\Delta_i&gt;0\}$，其中$\Delta_i= \max \mu_j-\mu_i$，并让$\epsilon_t=\min\{1,\frac{Cn}{t\Delta_{\min}^2}\}$，其中$C$是足够大的通用常数，证明存在$C’&gt;0$通用标准差。
$$R_T\leq C&#39;\sum_{i=1}^n(\Delta_i+\frac{\Delta_i}{\Delta_{\min}}\log\max\{e,\frac{T\Delta_{\min}^2}{n}\}).$$
我的想法是分别分析每个 arm 的遗憾，即 arm $i$ 被选中的次数的期望，并将其分为探索部分和开发部分，在第一部分中，每个 arm 都有机会以 pr. $\epsilon_t/n$ 被选中，而在开发部分，我们可以选择一个时间阈值 $t$ s.t。当$T&gt;t$时，次优臂将以足够小的概率被选中。但是，我不知道如何选择正确的方法来达到与此问题相同的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/656031/regret-bound-of-epsilon-greedy-algorithm-for-multi-armed-bandit-problem</guid>
      <pubDate>Sun, 20 Oct 2024 08:41:53 GMT</pubDate>
    </item>
    <item>
      <title>寻找 $3\theta_2^2$ 的 MVUE 的技术背后的动机</title>
      <link>https://stats.stackexchange.com/questions/656030/motivation-behind-the-technique-to-find-mvue-of-3-theta-22</link>
      <description><![CDATA[这个问题来自 Hogg 和 McKean 的《数理统计学导论》。
练习 7.7.11。
让 $X_1,X_2,\cdots,X_n$ 成为来自 $N(\theta_1,\theta_2)$ 分布的随机样本。
(a) 证明 $E[(X_1 − \theta_1)^4] = 3\theta_2^2.$
(b) 找到 $3\theta_2^2$ 的 MVUE。
我的尝试：
$N(\theta_1,\theta_2)$ 的联合完全充分统计量是 $(\overline{X},S^2)$、样本均值和样本方差。与此处或此处所做的类似，很容易证明（对于部分 (b)）
$$T = \cfrac{3(n-1)^2\Gamma\left(\frac{n-1}{2}\right)}{16\Gamma\left(\frac{n+7}{2}\right)}S^4,$$其中$S^2=\frac{\sum_{i=1}^n(X_i-\overline{X})^2}{n-1},$给定随机样本的方差样本。对于部分 (a)，众所周知，我们可以使用 mgf 技术找到中心矩（例如，参见此处）。
我的问题：为什么作者要问部分 (a)？通常，他们这样做是为了引导读者找到解决部分 (b) 的方法。最初，我以为他们要我们猜测一个函数 $T$，使得 $\mathbb{E}(​​T) = 3\theta_2^2$ 并且 T 是 $\theta_1$ 和 $\theta_2$ 的联合完全统计量函数 $\pmb{Y}$。 这样自然会使 $T$ 成为 $3\theta_2^2$ 的 MVUE。具体来说，他们在上一节相关部分中提到（第 $448$ 页）
&quot;第 $7.3$ 和 $7.4$ 节中概述的 Rao–Blackwell、Lehmann–Scheffe 理论自然延伸到这种向量情况。简而言之，假设 $\delta = g(\pmb{\theta})$ 是感兴趣的参数，并且 $\pmb{Y}$ 是 $\pmb{\theta}$ 的充分和完整统计向量。令 $T$ 为 $\pmb{Y}$ 函数的统计数据，例如 $T = T(\pmb{Y})$。如果 $E(T) = \delta$，则 $T$ 是 $\delta$ 的唯一 MVUE。&quot;
那么部分 (a) 如何促使我们猜测此函数 $T$？
编辑 1：
SE 帖子 此处 显示了 $\sigma^4 = \theta_2^2$ 的无偏估计量，似乎与部分 (a) 中的形式相似，即
$$T&#39; = \frac{n}{3\left(n-1\right)^2} \sum_{i=1}^n \left(X_i - \overline X\right)^4$$
但不是 $\theta_2^2$ 的 MVUE。添加此评论以防万一相关。]]></description>
      <guid>https://stats.stackexchange.com/questions/656030/motivation-behind-the-technique-to-find-mvue-of-3-theta-22</guid>
      <pubDate>Sun, 20 Oct 2024 07:03:17 GMT</pubDate>
    </item>
    <item>
      <title>什么时候 bagging 实际上会导致更高的方差？</title>
      <link>https://stats.stackexchange.com/questions/656007/when-can-bagging-actually-lead-to-higher-variance</link>
      <description><![CDATA[根据线性回归的高斯-马尔可夫假设，普通最小二乘估计 (OLS) 在所有无偏线性估计中具有最小方差。
在这种情况下，“Bagging”也是线性和无偏的，因此其方差必须严格更差。基于零独立变量（即只有一个偏差项）的情况，我的直觉是，当随机采样数据的模型数量趋于无穷大时，方差接近 OLS。
在决策树的设置中，与使用单个决策树相比，从 bagging（随机森林）获得的方差更低，这并不让我感到惊讶。但考虑到线性回归的情况，我看到的对此的解释似乎证明太多了。应满足哪些条件才能确保 bagging 不会使方差恶化？]]></description>
      <guid>https://stats.stackexchange.com/questions/656007/when-can-bagging-actually-lead-to-higher-variance</guid>
      <pubDate>Sat, 19 Oct 2024 15:28:15 GMT</pubDate>
    </item>
    <item>
      <title>后验预测 p 值和模型复杂度</title>
      <link>https://stats.stackexchange.com/questions/655998/posterior-predictive-p-values-and-model-complexity</link>
      <description><![CDATA[我正在执行贝叶斯后验预测检验，我发现更复杂的模型（一般模型）的后验预测 p 值比更简单的模型（嵌套模型）的后验预测 p 值略差（远离 .5）。这可能吗？显然，一切都是正确的。我希望更通用的模型始终表现出与嵌套模型相同或更好的拟合度。]]></description>
      <guid>https://stats.stackexchange.com/questions/655998/posterior-predictive-p-values-and-model-complexity</guid>
      <pubDate>Sat, 19 Oct 2024 08:53:54 GMT</pubDate>
    </item>
    <item>
      <title>基于梯度法的攻击对于神经网络来说似乎没有意义，因为训练误差是非凸的</title>
      <link>https://stats.stackexchange.com/questions/655655/the-gradient-method-based-attack-does-not-seem-make-sense-for-neural-networks-be</link>
      <description><![CDATA[有几种基于梯度的攻击方法。设$J$为训练误差，则例如投影梯度攻击为，
$$
\widetilde{x} = \Pi( x + \epsilon \nabla_x J(\theta, x, y) )
$$
快速有符号梯度法为
$$
\widetilde{x} = x + \epsilon \text{sign}( \nabla_x J(\theta, x, y) )
$$
这些方法都假设我们正在添加$\nabla_x J(\theta, x, y)$。这是在假设$\nabla_x J(\theta, x, y)$指向$J$相对于$x$的最大无穷增量方向的情况下实现的。
但这个假设是错误的，因为$J$是$x$的非凸函数。因此，添加 $\nabla_x J(\theta, x, y)$ 不一定会产生 $\widetilde x$，从而产生更大的 $J$ 值。
由于大多数这些方法都是单步的，因此不能保证 $\widetilde x$ 会增加 $J$ 的值，它甚至可能会降低 $J$ 的值。
我的推理有缺陷吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655655/the-gradient-method-based-attack-does-not-seem-make-sense-for-neural-networks-be</guid>
      <pubDate>Fri, 11 Oct 2024 14:53:11 GMT</pubDate>
    </item>
    <item>
      <title>预测的可能性::Arima 与手动复制</title>
      <link>https://stats.stackexchange.com/questions/654959/likelihood-from-forecastarima-vs-manual-replication</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654959/likelihood-from-forecastarima-vs-manual-replication</guid>
      <pubDate>Thu, 26 Sep 2024 16:07:18 GMT</pubDate>
    </item>
    <item>
      <title>PCA 是否会最大化投影数据点之间的成对平方距离？[重复]</title>
      <link>https://stats.stackexchange.com/questions/654159/does-pca-maximize-pairwise-squared-distance-between-projected-data-points</link>
      <description><![CDATA[我们有一个点数据集 $x_i$，其中 $x_i \in \mathbb{R}^n$。如果我们对保留 $k$ 个分量的数据集进行 PCA，则投影到 $k$ 个分量上的结果点 $y_i \in \mathbb{R}^k$ 将最大化向量与均值的平方距离（即 PCA 最大化保留的方差）。如果平均值$\bar{x}=0$，则 PCA 最大化范数平方和$\sum_i \|y_i \|^2$。
直观地讲，最大化点到平均值的总平方距离$\sum_i \|y_i - \bar{y} \|^2$似乎与最大化点之间的成对平方距离$\sum_i \sum_j \|y_i - y_j \|^2$有关。我尝试通过代入 $\bar{y} = \frac{1}{n}\sum_j y_j$ 来查看这两个“目标”是否等价，但得到的公式并不相同，因此目标并不等价。因此，PCA 似乎并没有最大化点之间的成对平方距离。
首先，我想知道在什么条件下最大化 $\sum_i \|y_i - \bar{y} \|^2$ 和 $\sum_i \sum_j \|y_i - y_j \|^2$ 这两个目标可能会重合（即导致相同的解决方案）。其次，我想知道是否存在一些已知的降维方法来最大化成对平方距离而不是方差。
编辑：尝试证明$\sum_i \|y_i - \bar{y} \|^2$和$\sum_i \sum_j \|y_i - y_j \|^2$并不相同：
$$\sum_i \|y_i - \bar{y} \|^2 =
\sum_i \|y_i - \frac{1}{n}\sum_j y_j\|^2 = \frac{1}{n^2}\sum_i \|\sum_j \left( y_i - y_j \right)\|^2 
$$
如果我们可以将$\sum_j$置于平方范数之外，则方差公式将成比例。但似乎我们不能：
$$\|\sum_j \left( y_i - y_j \right)\|^2 =
\langle \sum_j \left( y_i - y_j \right), \sum_k \left( y_i - y_k \right) \rangle = \\
\sum_j \|y_i - y_j \|^2 + 2 \sum_{j \neq k} \langle \left( y_i - y_j \right), \left( y_i - y_k \right) \rangle
$$
我可能遗漏了一些东西，但我不明白为什么术语$\sum_{j \neq k} \langle \left( y_i - y_j \right), \left( y_i - y_k \right) \rangle$ 应该为 0，因为方差和成对平方距离必须相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/654159/does-pca-maximize-pairwise-squared-distance-between-projected-data-points</guid>
      <pubDate>Tue, 10 Sep 2024 14:23:27 GMT</pubDate>
    </item>
    <item>
      <title>R：如何计算检测平均 beta reg 变化的功率？</title>
      <link>https://stats.stackexchange.com/questions/650829/r-how-to-calculate-power-to-detect-a-change-in-mean-beta-reg</link>
      <description><![CDATA[我有兴趣计算通过特定效应大小检测我的平均响应变量变化的功效，但我不知道如何开始。我的 Y 变量是平均植物覆盖率 0-100% 覆盖率（每个站点 10 次随机重复调查的平均值，以小数表示，包括 0 和 1），我想计算检测未来假设覆盖变化的效应大小的功效（单/配对样本检验）。每年在同一位置重复采样植物覆盖率（随机截距）。
我将这个问题输入 chatgpt，但我想验证这是正确的方法。它回复说建议我制作两个单独的模型（一个模型中我的协变量没有影响，另一个模型中它有指定的效应），然后计算每个模型的两个平均响应之间的差异。然后它说使用 t 检验计算功效。
这个答案看起来正确吗？我如何才能准确地模拟出与原始数据相似的数据（如何在 rbeta 中选择 alpha 和 beta）？我如何才能使年份协变量对 cover 产生特定的影响（chatgpt 假设了一个连续协变量并将其设置为 0.5）？此外，我知道我的回答不是概率，但我不应该使用功率计算来计算比例，因为这是 0-&gt;1 数据（即使用 pwr::pwr.p.test）？
我尝试模拟数据以便更容易发布这个问题，但它在摘要输出中没有达到预期的效果。
set.seed(123)

n &lt;- 100
x1 &lt;- rep(seq(1, 10), each = 10)
x2 &lt;- seq(1, 10)

y &lt;- rbeta(n, 2, 5) # 模拟响应变量（beta 分布）

# 创建数据框
data &lt;- data.frame(cover = y, year = x1, site = x2)
data$site &lt;- as.factor(data$site)

我认为这比 betareg 更好，因为它允许随机截距
library(glmmTMB)
# 拟合 beta 回归模型
model &lt;- glmmTMB(y ~ year + (1|site), ziformula = ~1, data = data, family=beta_family(link=&quot;logit&quot;))

Chatgpt:
# 模拟数据以进行功效计算：
# 要计算功效，通常需要在零假设和备择假设下模拟数据。

# 零假设 (H0)：假设预测变量 x1 没有影响。
# 备择假设 (H1)：假设预测变量 x1 具有一定大小的影响。
# 假设您想要计算检测 x1 的两个值之间的平均响应变量 y 的差异的功效：x1 = 0 和 x1 = 0.5。

# 在 H0 下模拟数据（x1 无影响）
data_null &lt;- data.frame(y = rbeta(n, 2, 5), x1 = rnorm(n))

# 在 H1 下模拟数据（x1 = 0.5 的影响）
data_alt &lt;- data.frame(y = rbeta(n, 2, 5), x1 = rnorm(n, mean = 0.5))

model_null &lt;- betareg(y ~ x1, data = data_null)
model_alt &lt;- betareg(y ~ x1, data = data_alt)

# 在 H0 下计算 x1 = 0.5 和 x1 = 0 之间的平均响应变量 (y) 差异
mean_y_alt &lt;- predict(model_alt, newdata = data_null)
mean_y_null &lt;- predict(model_null, newdata = data_null)
effect_size &lt;- mean(mean_y_alt - mean_y_null)

# y 的标准差
sd_y &lt;- sd(predict(model, type = &quot;response&quot;))

# 样本大小
n &lt;- nrow(data)

# 显着性水平
alpha &lt;- 0.05

# 计算功效
power &lt;- pwr.t.test(n = n, delta = effect_size, sd = sd_y, sig.level = alpha, type = &quot;two.sample&quot;)$power
power

这是对比例数据的更好测试，不是吗？
power &lt;- pwr.p.test(h = effect_size, n = n, sig.level = alpha, alternative = &quot;two.sided&quot;)$power
power
]]></description>
      <guid>https://stats.stackexchange.com/questions/650829/r-how-to-calculate-power-to-detect-a-change-in-mean-beta-reg</guid>
      <pubDate>Wed, 10 Jul 2024 19:08:56 GMT</pubDate>
    </item>
    <item>
      <title>理解 Rao-Blackwell 定理的证明</title>
      <link>https://stats.stackexchange.com/questions/650354/understanding-the-proof-of-rao-blackwell-theorem</link>
      <description><![CDATA[我对 Rao-Blackwell 定理的理解存在问题。特别是，我不明白为什么结果估计量是参数所有无偏估计量之间方差最小的估计量。该定理的证明只是表明结果估计量的方差小于我用于条件化的估计量的方差。]]></description>
      <guid>https://stats.stackexchange.com/questions/650354/understanding-the-proof-of-rao-blackwell-theorem</guid>
      <pubDate>Tue, 02 Jul 2024 20:37:46 GMT</pubDate>
    </item>
    </channel>
</rss>