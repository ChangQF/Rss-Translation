<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 09 Jan 2025 12:33:49 GMT</lastBuildDate>
    <item>
      <title>如何在 SPSS 中最好地进行医疗干预的中断时间序列分析</title>
      <link>https://stats.stackexchange.com/questions/659760/how-to-best-conduct-an-interrupted-time-series-analysis-in-spss-for-a-healthcare</link>
      <description><![CDATA[我根本不是统计学家，所以很希望得到一些帮助。我正在从事一个医疗保健项目，旨在评估急诊科的新干预措施对救护人员卸下患者并返回街道所需时间的影响。
我有一组救护车延误的数据集，这些数据集来自干预前 4 个月和干预后 4 个月。我还有 12 个月前的同一批数据，作为一年中同一时期的对照，因为冬季压力可能会影响救护车的周转延误。数据集是每次救护车到达以及从到达到离开急诊室所花费的时间。这是否可以不计算一天或一周的平均值，而只使用单独的时间戳数据来完成？
我想使用中断时间序列分析，但以前没有用过。在阅读和观看 YT 教程时，我遇到了 ARIMA 和分段回归模型。我不确定哪一个最适合我的问题，或者是否需要先测试数据以确定哪个模型最合适。我发现 YT 教程并不是特别有用，因为它们主要关注与我的问题无关的预测和预报（我的资历不足以单方面实施变更并查看新数据与预测的比较情况，所以我只想评估回顾性数据）。
有人能解释一下这些（或另一个）模型中是否有一个本质上更适合查看干预措施是否对救护车周转延迟具有统计显着影响的模型吗？我需要先测试数据的任何特征（可变性、季节性等）才能知道这一点吗？
任何帮助都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659760/how-to-best-conduct-an-interrupted-time-series-analysis-in-spss-for-a-healthcare</guid>
      <pubDate>Thu, 09 Jan 2025 10:45:10 GMT</pubDate>
    </item>
    <item>
      <title>序数量化误差</title>
      <link>https://stats.stackexchange.com/questions/659757/ordinal-quantification-error</link>
      <description><![CDATA[我有一个有六个级别的分类变量：0-5。我想确定哪个分区最能描述变量的级别（即最小化错误/最小化熵）。
该变量是一个健康变量，具有一些假定的潜在状态，即“好”、“还行”、“不好”。
因此，我想知道是否有方法可以识别量化误差，比如 0-2；3-4；5 与 0-1；2-4；5 等。
有没有一种方法可以在 R 中做到这一点？
感谢您的反馈]]></description>
      <guid>https://stats.stackexchange.com/questions/659757/ordinal-quantification-error</guid>
      <pubDate>Thu, 09 Jan 2025 10:32:14 GMT</pubDate>
    </item>
    <item>
      <title>KDE 和直方图可以使用什么返回值？</title>
      <link>https://stats.stackexchange.com/questions/659753/what-returns-to-use-for-kde-histogram</link>
      <description><![CDATA[这是一个非常简单的问题，但是，我在网上找不到直接的答案。
当尝试根据历史数据估计股票收益的概率分布时，我应该使用重叠还是不重叠的收益窗口？
假设我想在x 天历史数据样本上构建一个简单的n 天收益直方图。
我是否应该将 x 天历史样本拆分为 $\frac{x}{n}$ 个窗口并计算每个窗口的收益，从而为我的直方图获得 $\frac{x}{n}$ 个数据点？
或者我应该在滚动的 n 天窗口上计算收益，从而将样本量显著增加到 $x-n+1$，但收益不独立？
我的直觉告诉我，如果我想获得收益概率分布的简单估计（即简单的直方图），我应该使用独立收益，因此$\frac{x}{n}$。这样对吗？
使用历史数据样本来获得 n 天收益的核密度估计 (KDE) 怎么样？同样的问题（我怀疑答案也一样）：不重叠的收益更好？
PS：有人能推荐任何严格处理这个问题的教科书或论文吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659753/what-returns-to-use-for-kde-histogram</guid>
      <pubDate>Thu, 09 Jan 2025 09:43:44 GMT</pubDate>
    </item>
    <item>
      <title>部分已知的结果和样本空间</title>
      <link>https://stats.stackexchange.com/questions/659752/partially-known-outcomes-and-sample-space</link>
      <description><![CDATA[考虑一个标准的贝叶斯定理问题：
我们有两个盒子$A$和$B$，其中一个盒子里有放射性物质。我们有一个探测器，可以在不打开盒子的情况下检测出该物质的存在。这个探测器有故障：如果该物质确实存在，它会以$0.8$的概率指示该物质的存在，如果该物质不存在，它会以$0.1$的概率指示该物质的存在。材料存在于$A$和$B$中的先验概率分别为$0.3$和$0.7$。我们使用检测器检查盒子$A$，它指示材料的存在。材料实际存在于$A$中的概率是多少？此外，现在如果我们检查$B$，并且检测器指示材料也存在于盒子$B$中，那么这两个盒子现在存在的概率是多少？
我在这个问题上遇到了概念问题。首先，这里的样本空间是什么？我发现有两个随机性来源：首先，材料的位置是随机的，其次，探测器的指示也是随机的。我们用 $Xij$ 表示材料实际上存在于盒子 $X$ 中，并且根据探测器指示其存在于 $A$ 还是 $B$ 中，$i$ 和 $j$ 将是 $1$ 或 $0$。因此，$A10$ 意味着材料实际上存在于盒子 $A$ 中，探测器指示它在那里，并指示它不存在于 $B$ 中。现在，样本空间是所有此类三元组 $Xij$ 的集合吗？如果是这样，如果在检查 $A$ 之后，如果探测器指示材料在其中，我们是否应该说我们只部分得到了结果？这是因为我们仍然不知道实际的盒子，而且我们也没有关于盒子 $B$ 指示的信息。那么，如果结果本身不完全为人所知，我们如何定义各种事件的概率？总而言之，样本空间是什么，实验过程中结果是否仅部分已知，我们是否可以使用部分已知的结果定义各种条件概率？]]></description>
      <guid>https://stats.stackexchange.com/questions/659752/partially-known-outcomes-and-sample-space</guid>
      <pubDate>Thu, 09 Jan 2025 09:31:28 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Vine copula 模型中只有一个条件 copula？</title>
      <link>https://stats.stackexchange.com/questions/659751/why-is-there-a-single-conditional-copula-in-a-vine-copula-model</link>
      <description><![CDATA[假设我有 3 个变量，X1、X2 和 X3，我想将一个 vine copula 模型拟合到这个数据集。在 R 中，使用 VineCopula 包，我可以使用函数 RVineStructureSelect 执行此操作。有了 3 个变量，这个 vine copula 模型将由 3 个 copula 组成，需要进行估算。假设该算法识别出以下 copula：

C(X1, X3) 和 C(X2, X3)
C(X1, X2 | X3)

前 2 个是无条件 copula，捕获 X1-X3 和 X2-X3 之间的依赖关系。而 copula C(X1, X2 | X3) 是有条件的，因此它捕获给定 X3 的 X1 和 X2 之间的依赖关系。 RVineStructureSelect 函数将为上述每个 copula（包括条件 copula）提供特定的 copula。因此，例如，在生成的 vine copula 对象中，您可能会看到条件 copula 是具有给定参数化的 Clayton。
但直观地讲，我预计条件依赖性可以根据条件变量 X3 的级别而变化。例如，对于 X3 的低级别，Clayton 可以捕获 X1 和 X2 之间的依赖性，但随着 X3 的增加，t-copula 可以更好地捕获该条件关系。所以我不明白 RVineStructureSelect 如何为 C(X1, X2 | X3) 识别一个 copula。
我尝试使用散点图复制逻辑以了解如何表示条件依赖性，但我无法理解单个散点图（因此是单个 copula）如何捕获条件依赖性。]]></description>
      <guid>https://stats.stackexchange.com/questions/659751/why-is-there-a-single-conditional-copula-in-a-vine-copula-model</guid>
      <pubDate>Thu, 09 Jan 2025 09:30:14 GMT</pubDate>
    </item>
    <item>
      <title>交互项是否违反线性回归中的线性和可加性假设？</title>
      <link>https://stats.stackexchange.com/questions/659750/do-interaction-terms-violate-the-linearity-and-additivity-assumptions-in-linear</link>
      <description><![CDATA[在线性回归中，经常讨论的两个关键假设是可加性和线性，如 ISLR（统计学习简介）中所定义：
可加性：预测变量 $𝑋_𝑗$ 和响应 $𝑌$ 之间的关联不依赖于其他预测变量的值。
线性：与 $𝑋_j$ 的一个单位变化相关的 $𝑌$ 的变化是恒定的，无论 $𝑋_𝑗$ 的值如何。
现在考虑具有交互项的线性模型：
$$
𝑌
=
𝛽
0
+
𝛽
1
𝑋
1
+
𝛽
2
𝑋
2
+
𝛽
3
(
𝑋
1
⋅
𝑋
2
)
+
𝜖
$$
这可以重写为：
$$
Y=β 
0
​
+(β 
1
​
+β 
3
​
X 
2
​
)X 
1
​
+β 
2
​
X 
2
​
+ϵ
$$
在此公式中：
$𝑋_1$ 对 $𝑌$ 的影响现在依赖于 $𝑋_2$（即 $𝛽
1
+
𝛽
3
𝑋
2$
​
），这表明可加性假设被违反，因为 $𝑋_1$ 的影响不再独立于 $𝑋_2$。
类似地，线性假设似乎被违反，因为$𝑌$随着$𝑋_1$的一个单位增加而发生的变化不再是恒定的 - 它取决于$𝑋_2$的值。
在一次模拟口语考试中，我被问到当包含交互项时模型是否仍然是线性的。我认为该模型仍然是线性的，因为它在参数$(
𝛽
0
,
𝛽
1
,
𝛽
2
,
𝛽
3​
)$中是线性的，并且包含交互项只是“放松”了假设。但是，我对“放松”含义的解释是假设不明确。
我的问题：

在回归假设的背景下，具有交互项的模型是否仍被视为“线性”？为什么或为什么不？

“放宽”假设是什么意思？放宽假设是否意味着它没有被违反，还是意味着其他什么？

当包含交互项时，您能否阐明如何调和明显的可加性和线性违反？


提前感谢您的见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/659750/do-interaction-terms-violate-the-linearity-and-additivity-assumptions-in-linear</guid>
      <pubDate>Thu, 09 Jan 2025 09:17:01 GMT</pubDate>
    </item>
    <item>
      <title>如何解决损失不收敛的问题？[重复]</title>
      <link>https://stats.stackexchange.com/questions/659748/how-to-troubleshoot-loss-not-converging</link>
      <description><![CDATA[我正在使用 CNN 模型进行二分类任务，总训练数据为 24000 个样本（正样本与负样本比例：1:10）。
CNNDecoder(
(cnn): Sequential(
(0): Conv2d(6144, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(1): ReLU(inplace=True)
(2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
(3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(4): ReLU(inplace=True)
(5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
(6): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(7): ReLU(inplace=True)
(8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
(global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))
(fc): Linear(in_features=128, out_features=1, bias=True)
(sigmoid): Sigmoid()
)

输入特征维度为[B, 24, 256, 32, 64]，由24组256通道特征图，我使用CNN将它们的尺寸降为[B, 512, 32, 64]，然后进行卷积，直到特征图变成[B, 128]，最后输出分类概率。
loss：BceLoss，分别计算正样本和负样本的loss，这样就消除了类别不平衡的影响。
batch size：16 * 32（GPU数量）=512
学习率：1e-4
optimizer：
type：AdamW
lr：
default：1.0e-04
weight_decay：1.0e-05
betas：[0.9, 0.95]
这是我的训练loss和metric。看起来一开始准确率比较高，但是正样本的loss不收敛，而且用Wandb拿到CNN的梯度也没有发现有下降的趋势，请问这种现象最可能的原因是什么？我是否应该降低学习率，或者我的训练数据集中是否存在某种数据噪音？


]]></description>
      <guid>https://stats.stackexchange.com/questions/659748/how-to-troubleshoot-loss-not-converging</guid>
      <pubDate>Thu, 09 Jan 2025 07:27:32 GMT</pubDate>
    </item>
    <item>
      <title>我是否必须获取另一个独立于交叉验证中使用的数据集的单独测试集？</title>
      <link>https://stats.stackexchange.com/questions/659747/do-i-have-to-get-another-separate-test-set-that-is-independent-of-the-dataset-i</link>
      <description><![CDATA[我正在做什么
我正在写一篇关于使用 SVM 进行音频分类的本科论文。我的目标是确定将特征 X 添加到特征矩阵中是否可以提高分类器的性能。
我没有做什么
我没有在交叉验证后进行任何超参数调整。我在网上看到的大多数帖子都说应该有一个单独的测试集，但大多数帖子都提到这是因为使用 CV 的结果进行超参数调整，我认为这不适用于我。 (cmiiw)
我做了什么
（我将稍微简化一下，以便于理解）
我创建了 8 个 SVM 分类器 - 每个内核（线性、多边形、rbf、sigmoid）有 2 个分类器。
使用 sklearn 的 cross_validate 函数，4 个分类器（每个内核一个）与包含特征 X 的特征矩阵进行交叉验证。其他 4 个与不包含特征 X 的特征矩阵进行交叉验证，用作控制/基线。
我计算了每个分类器各个折叠的得分平均值，得到了 8 个平均得分及其派生的标准误差。我比较了 8 个平均分数，同时考虑了标准误差，以确定特征 X 是否确实提高了分类器的性能，以及哪个内核的性能最好。
我想知道什么
我这样做对吗？我不需要另一个单独的测试集吗？我觉得我不需要，但我只是一个新手，我非常怀疑自己。如果我确实需要另一个测试集，当我已经有 cross_validate 函数返回的分数时，我该如何使用它？]]></description>
      <guid>https://stats.stackexchange.com/questions/659747/do-i-have-to-get-another-separate-test-set-that-is-independent-of-the-dataset-i</guid>
      <pubDate>Thu, 09 Jan 2025 07:06:10 GMT</pubDate>
    </item>
    <item>
      <title>对于分类变量，PCA、因子分析或其他方法？</title>
      <link>https://stats.stackexchange.com/questions/659739/pca-factor-analysis-or-other-methods-for-categorical-variables</link>
      <description><![CDATA[我有关于公司政治关系的调查数据，分为两个模块，希望您就以下方面提出建议：
模块 1：此模块包含所有分类变量的调查问题。虽然我了解到从技术上讲，可以使用 PCA 处理分类变量，但一般不建议这样做。是否有其他方法更适合在此背景下分析分类数据？
模块 2：此模块包含多种变量：2 个是序数变量，1 个是分类变量。PCA 或因子分析能否有效地处理这种组合？
我一直在研究 PCA 和因子分析之间的差异，但仍然不确定哪个更合适。我的直觉是，政治联系可能不是潜在的构造，因此 PCA 在概念上似乎更有意义。但是，我想听听您的想法，PCA 或因子分析是否是更好的方法——或者另一种方法是否更合适。]]></description>
      <guid>https://stats.stackexchange.com/questions/659739/pca-factor-analysis-or-other-methods-for-categorical-variables</guid>
      <pubDate>Wed, 08 Jan 2025 23:40:48 GMT</pubDate>
    </item>
    <item>
      <title>缩小的整数格点是否可以作为概率单纯形中的无偏样本点？</title>
      <link>https://stats.stackexchange.com/questions/659737/do-scaled-down-integer-lattice-points-serve-as-unbiased-sample-points-in-the-pro</link>
      <description><![CDATA[我一直在努力证明一个看起来直观明显但实际上并不容易严格建立的陈述。
$(n-1)$维概率单纯形$X$是集合
$$
X=\left\{\mathbf{x}\in[0,1]^n:\sum_{i=1}^nx_i=1\right\}。
$$
设 $Y$ 为单纯形中按比例缩小的整数格点集：
$$
Y=X\cap\frac{\mathbb{Z}^n}s
$$
其中 $s\in\mathbb{Z}^+$。
我的主张是，当 $s\to\infty$ 时，$Y$ 可作为 $X$ 中无偏的样本点集。也就是说，对于 $P\subseteq X$ 和 $U=Y\cap P$，$P$ 的质心（未加权平均值）由以下公式给出
$$
\tag{1}
\bar{\mathbf{p}}=\frac{1}{\int_{P}dV}\int_{P}\mathbf{p}\,dV
$$
其中 $\mathbf{p}\in P$ 和 $dV$ 是 $(n-1)$ 维体积元素，并且 $\bar p$ 渐近等于
$$
\tag{2}
\bar{\mathbf{u}}=\frac1{\#U}\sum_{i=1}^{\#U}\mathbf{u}_i
$$
其中 $\mathbf{u}_i\in U$，因为 $s\to\infty$；即
$$
\tag{3}
\lim_{s\to\infty}\bar{\mathbf{u}}=\bar{\mathbf{p}}。
$$
这里，$(1)$可视为真实均值，$(2)$可视为样本均值，如果集合$U$提供的样本点在极限上无偏，则$(3)$成立。
对于我的具体情况，该语句不必对$X$中的所有子集都成立，而只对这个特定集合成立：
$$
\tag{4}
{P}=\left\{\mathbf{p}\in[0,1]^n: p_1\le p_2\le\cdots\le p_c\ge\cdots\ge p_n\text{ 和} \sum_{i=1}^n p_i=1\right\}\subset X
$$
顺便说一句，它恰好是凸的。
简而言之，我试图证明$(3)$，无论是在一般情况下，还是当$P$给出为$(4)$时。
任何帮助都将不胜感激。指导我任何相关的关键字或书籍也将很棒。]]></description>
      <guid>https://stats.stackexchange.com/questions/659737/do-scaled-down-integer-lattice-points-serve-as-unbiased-sample-points-in-the-pro</guid>
      <pubDate>Wed, 08 Jan 2025 22:56:09 GMT</pubDate>
    </item>
    <item>
      <title>FE 解释中的相互作用项</title>
      <link>https://stats.stackexchange.com/questions/659728/interaction-term-in-fe-interpretation</link>
      <description><![CDATA[我正在估算固定效应回归，如下所示：
$$
\text{unemployment}_{ict} \sim b_1 \text{wage}_{ict} + b_2 \text{heat}_{ict} + b_3 \text{wage}_{ict} \times \text{heat}_{ict} + \text{FEc} + \text{error}_{ict}
$$
其中 $i$ 为个人，$c$ 为国家，$t$ 为时间。
假设您获得以下效果：$b_1=0.7$，$b_2=1.2$, $b_3=-0.4$
现在您想要解释交互效应。一种思考方式是边际效应：
这里您已估计出给定工资和热量的失业预期值
$$
E[y|a,b]=0.7a+1.2b-0.4ab
$$
如果对上述表达式求导，则 a：
$$
\frac{d}{d a} E[y|a,b] =0.7-0.4b
$$
此表达式以 $b$（热量）递减。热量值表示温度，例如，范围从 0-40。然后您可以将 b 设置为“有趣”的值以进行解释。通常，这些有趣的值是 $b$ 中样本的平均值。
我的疑问：
在平均热量值处可视化边际效应是否有意义？
由于 FE 模型控制了国家层面的差异，因此它仅估计了国家内部的变化。使用平均热量值（捕获国家间和国家内部的变化）会扭曲解释吗？
我应该使用替代方法吗？
考虑到模型的面板结构，我正在考虑使用诸如热量增长率或其国家内部标准差之类的指标进行可视化。这些反映了模型实际捕获的国家内部变化。这种方法更合适吗？
如果有人可以对此发表评论，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/659728/interaction-term-in-fe-interpretation</guid>
      <pubDate>Wed, 08 Jan 2025 17:35:13 GMT</pubDate>
    </item>
    <item>
      <title>当得到自由度的十进制值时该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/659723/what-to-do-when-one-gets-a-decimal-value-as-degrees-of-freedom</link>
      <description><![CDATA[我正在尝试找到 2 个随机变量的样本均值差异的置信区间的 t 值。这里的方差是未知且不相等的，因此必须使用的 v 公式是：

完成此计算后，我确信它是正确的，我得到的是一个十进制值。在 t 分布表中，我只能看到 v 的整数值，所以我的问题是我应该向上舍入还是向下舍入。此外，这有什么逻辑吗，还是向上舍入或向下舍入完全是随机的？]]></description>
      <guid>https://stats.stackexchange.com/questions/659723/what-to-do-when-one-gets-a-decimal-value-as-degrees-of-freedom</guid>
      <pubDate>Wed, 08 Jan 2025 15:58:56 GMT</pubDate>
    </item>
    <item>
      <title>在汇总疾病分类的优势比时，测量工具是否需要同质性？</title>
      <link>https://stats.stackexchange.com/questions/659696/is-homogeneity-of-measurement-tools-necessary-when-pooling-odds-ratios-for-disea</link>
      <description><![CDATA[在荟萃分析中汇总估计值时，众所周知，保持研究之间的同质性至关重要，尤其是在处理连续数据时。在这种情况下，使用一致报告的工具和测量值进行有效汇总非常重要。但是，当使用不同的工具对疾病进行分类，但最终将其归类为疾病的存在或不存在，并且结果以比值比的形式进行统计呈现时，是否仍有必要保持所用工具的同质性？]]></description>
      <guid>https://stats.stackexchange.com/questions/659696/is-homogeneity-of-measurement-tools-necessary-when-pooling-odds-ratios-for-disea</guid>
      <pubDate>Wed, 08 Jan 2025 01:12:47 GMT</pubDate>
    </item>
    <item>
      <title>mgcv::gam 不能正确地从平滑中分解线性分量</title>
      <link>https://stats.stackexchange.com/questions/659680/mgcvgam-does-not-correctly-decompose-the-linear-component-from-the-smooth</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659680/mgcvgam-does-not-correctly-decompose-the-linear-component-from-the-smooth</guid>
      <pubDate>Tue, 07 Jan 2025 18:52:03 GMT</pubDate>
    </item>
    <item>
      <title>我应该将点大小（面积）比例缩放为 1/标准误差还是 1/SE^2？</title>
      <link>https://stats.stackexchange.com/questions/659678/should-i-scale-point-size-area-proportion-to-1-standard-error-or-1-se2</link>
      <description><![CDATA[我有一堆估计值，我想将它们绘制在 y 轴上，而 x 轴上则绘制其他值。我想传达每个点的不确定性（x 轴值已知，y 轴值是估计值）。误差线会使图变得非常混乱，所以我想使用点的大小来传达我们对每个点的确定程度。据我所知，建议人们将面积（而不是直径）视为信息量（例如，参见本文或此链接 - 不确定这些是否是标准参考文献）。
但是，有没有研究信息度量应该是 1/SE（标准误差的倒数）还是 1/SE^2（抽样方差的倒数）。鉴于对于误差线，我们将使用 +-SE 或置信区间（95% 的置信区间大约为 +- 1.96*SE），我猜是 1/SE？不知何故，我找不到是否有人尝试过实证测试这是否有效（例如，当人们被问到问题时，他们会根据所选的可视化做出适当的回答，即当给出基于 1/SE 或 1/SE^2 或其他东西的点大小时，他们是否表现得更好）。
更新：一位同事指出，对于元回归，我们通常根据信息缩放点。信息（或研究权重）与 1/方差成正比，因此可以说按 1/方差缩放面积是有意义的。虽然，查看流行的 metafor R 包，似乎我们默认获得了按元回归权重（即 1/方差）缩放的半径（与直径成比例）（我还仔细检查了源代码，并支持按 1/方差和 1/se 缩放直径）。奇怪的是，按 1/方差缩放半径意味着按 1/方差缩放面积（与半径^2 成比例）。这似乎夸大了点所获得的权重。相比之下，为了根据信息缩放面积，将半径或直径缩放 1/SE 似乎更有意义（或者如果您想要与 SE 成比例的面积，则可以将半径缩放 $1/\sqrt(SE)$）。]]></description>
      <guid>https://stats.stackexchange.com/questions/659678/should-i-scale-point-size-area-proportion-to-1-standard-error-or-1-se2</guid>
      <pubDate>Tue, 07 Jan 2025 17:47:22 GMT</pubDate>
    </item>
    </channel>
</rss>