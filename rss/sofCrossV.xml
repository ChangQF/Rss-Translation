<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 16 Jan 2025 12:31:58 GMT</lastBuildDate>
    <item>
      <title>是否可以将元分析 SMD（例如，Cohen's d）转换为两种条件之间的百分比变化？</title>
      <link>https://stats.stackexchange.com/questions/660092/is-it-possible-to-convert-the-meta-analytic-smd-e-g-cohens-d-to-the-percent</link>
      <description><![CDATA[是否可以将随机效应荟萃分析的平均汇总效应（以 Cohen&#39;s d 的形式）转换为两种条件之间的百分比变化。
例如：X 的 Cohen&#39;s d 对应于 Y 的百分比变化。
我知道 CLES 以及如何将 Cohen&#39;s d 转换为原始平均差异，然后再转换为百分比变化，但我想知道当我只有荟萃分析的结果时是否可行。]]></description>
      <guid>https://stats.stackexchange.com/questions/660092/is-it-possible-to-convert-the-meta-analytic-smd-e-g-cohens-d-to-the-percent</guid>
      <pubDate>Thu, 16 Jan 2025 11:08:42 GMT</pubDate>
    </item>
    <item>
      <title>统计功效分析：p 值较小的 power.t.test 结果不一致</title>
      <link>https://stats.stackexchange.com/questions/660091/statistical-power-analysis-power-t-test-inconsistent-results-for-small-p-values</link>
      <description><![CDATA[我不确定这是否是提出这个问题的正确 StackExchange，因为它也是程序化的。我愿意从 power.t.test 执行显着性水平的估计，使用非常小的 p 值（由 Bonferroni 校正为多重测试）。我面临这个问题。以下 R 代码几乎始终返回我提供的相同 P 值：
reference_sample_size &lt;- 250;
reference_pval_thres &lt;- 0.01;
ref.d &lt;- 0.8;
factor &lt;- 1;
ref.pwr &lt;- power.t.test(n=reference_sample_size, delta=ref.d, power=NULL, sig.level=reference_pval_thres/factor, type=&quot;two.sample&quot;, alternative=&quot;two.sided&quot;)$power;
power.t.test(delta=ref.d,n=reference_sample_size,sig.level=NULL, type=&quot;two.sample&quot;, alternative=&quot;two.sided&quot;, power=ref.pwr)$sig.level * factor

例如，我给它的 p 值为 0.01，我得到的 p 值为 0.009974294，考虑到算术精度，这是预期结果。但是，如果我将因子设置为 1000，则结果将完全错误，返回 p 值为 0.1220204。
有人可以解释原因并提供可能的解决方案吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660091/statistical-power-analysis-power-t-test-inconsistent-results-for-small-p-values</guid>
      <pubDate>Thu, 16 Jan 2025 10:49:39 GMT</pubDate>
    </item>
    <item>
      <title>如何在倾向匹配数据中对组 x 时间交互进行建模</title>
      <link>https://stats.stackexchange.com/questions/660088/how-to-model-group-x-time-interaction-in-propensity-matched-data</link>
      <description><![CDATA[我正在帮助某人进行分析，他们已经对一系列具有纵向结果（每年测量 10 年）的基线变量进行了倾向得分匹配。他们使用了 matchit 与最近邻居和 2:1 匹配率。我认为他们感兴趣的估计量是 group * time 交互效应，他们没有考虑到这一点。
然而，我对倾向得分没有做太多研究，我想知道如何对此进行建模。我们是否只获取匹配的数据并运行具有交互作用的标准混合模型 - 即类似于（在 R 中）：
lmer(y ~ group * time + (1|id), data = dat)

或者还有更多内容？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660088/how-to-model-group-x-time-interaction-in-propensity-matched-data</guid>
      <pubDate>Thu, 16 Jan 2025 09:28:31 GMT</pubDate>
    </item>
    <item>
      <title>F1-score、IOU 和 Dice Score 的实现</title>
      <link>https://stats.stackexchange.com/questions/660087/implementation-of-f1-score-iou-and-dice-score</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660087/implementation-of-f1-score-iou-and-dice-score</guid>
      <pubDate>Thu, 16 Jan 2025 09:19:55 GMT</pubDate>
    </item>
    <item>
      <title>statsmodels ARIMA 结果中的 p 值和临界值存在冲突</title>
      <link>https://stats.stackexchange.com/questions/660086/conflicting-p-value-and-critical-values-in-statsmodels-arima-result</link>
      <description><![CDATA[
如果我理解正确，如果 Z 落在临界值区域之外，则 p 值应该 &lt;0.05。但是，对于我的 ar.L2 特征，z = -0.596，[0.025, 0.075] 区域是 [-0.536, 0.286]。因为 -0.596 &lt; -0.536，所以 z 落在左尾内。但为什么 p 值是 0.552？我读错结果了吗？在 statsmodels 网站上找不到任何文档。]]></description>
      <guid>https://stats.stackexchange.com/questions/660086/conflicting-p-value-and-critical-values-in-statsmodels-arima-result</guid>
      <pubDate>Thu, 16 Jan 2025 09:00:50 GMT</pubDate>
    </item>
    <item>
      <title>回归分析中总体模型和样本模型的形式区别？</title>
      <link>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</link>
      <description><![CDATA[术语“样本回归模型”在回归分析中究竟指什么？假设我们有一个数据集$\{(\mathbf{x}_i,\mathbf{y}_i)\}$，我们假设一个底层回归模型形式为
$$
\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon},
$$
其中$\boldsymbol{\theta}$是真实总体参数（频率学派观点）和$\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\Sigma)$。我们所说的样本回归模型到底是什么意思？
以下是我正在探索的一些可能性：

拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}})$，从某种意义上说，我们已经选择了一个估计值$\hat{\boldsymbol{\theta}}$;
拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}}) + \hat{\boldsymbol{\epsilon}}$，其中我们有一个估计值$\hat{\boldsymbol{\theta}}$ 而且 $\hat{\boldsymbol{\epsilon}} \sim \mathcal{N}(\mathbf{0},\hat{\Sigma})$;
从字面上看，人口模型 $\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon}$，但现在以样本指数的形式写出：$\mathbf{y}_i = f(\mathbf{x}_i;\boldsymbol{\theta}) + \boldsymbol{\epsilon}_i$ 使得 $\boldsymbol{\epsilon}_i$ 是观测值，而不是随机向量。
关系 $\mathbf{y}_i = f(\mathbf{x}_i;\hat{\boldsymbol{\theta}}) + \mathbf{e}_i$，其中 $\mathbf{e}_i = \mathbf{y}_i - \hat{\mathbf{y}}_i$ 是残差。

如能提供严格说明，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</guid>
      <pubDate>Thu, 16 Jan 2025 07:27:25 GMT</pubDate>
    </item>
    <item>
      <title>对于开放式研究，能否正确计算统计显著性？</title>
      <link>https://stats.stackexchange.com/questions/660083/can-statistical-significance-be-correctly-computed-for-a-open-ended-study</link>
      <description><![CDATA[基本来说，我想做的是你在适当的研究中不应该做的事情：运行少量的测量，然后根据数据看起来是好是坏，决定是继续测量还是退出。
我知道简单的显着性检验不会适用于这种情况，但我怀疑（如果我知道要搜索哪些术语）应该有已知的方法来考虑导致的问题，例如集合的大小暗示了数据集的主要术语。
这是已知的吗？如果是这样，这种测试的正确术语是什么？

上下文是我正在使用来自有效无限域的随机数据点运行模拟，并寻找多个模拟的平均结果超过某个阈值的（罕见）点。我认为我遇到了误报问题，并且不想盲目地增加运行次数以尽可能减少误报（我已经受到计算限制，所以这基本上不是一个选择）。
我想做的是：

运行少量运行。
检查平均结果是否超过高于或低于截止值的显着性阈值。
如果是，则退出。
如果不是（即“不确定”），则进行更多运行并再次检查。

这将（我希望）允许丢弃大多数情况，其中点“极其无趣”，并且计算量甚至比我现在使用的还要少（比如可能少 10 倍），而不会增加误报率。
但我不知道如何为此构建正确的显着性检验。我能想到的最好的办法（我甚至不确定它是否有效）是使每次迭代都更大，只考虑每次迭代中的新数据并使用“多重比较问题”调整之一。但有些东西告诉我应该有一种更有效的方法来使用生成的数据。
旁注：如果允许假阴性可以带来更好的每真阳性成本，我对假阴性是相当宽容的。]]></description>
      <guid>https://stats.stackexchange.com/questions/660083/can-statistical-significance-be-correctly-computed-for-a-open-ended-study</guid>
      <pubDate>Thu, 16 Jan 2025 06:16:36 GMT</pubDate>
    </item>
    <item>
      <title>排除构成数据结构一部分的相关变量，转而采用生物学上更有意义的变量</title>
      <link>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</link>
      <description><![CDATA[我正在研究从卫星图像 (Sentinel) 中捕获的植被覆盖率数据集。数据以季度/季节为间隔捕获。使用 GAM，我正在模拟植被覆盖率如何响应环境变量，降雨量是感兴趣的关键预测变量。但是，降雨量与季度/季节具有合理的相关性，相关系数为 r = -0.73。通常，当两个变量的相关性大于 0.7 时，我会将其中一个排除在分析之外。所以，我的问题是，我可以从分析中排除季度/季节吗？
季度/季节是数据集设计/结构的一部分，通常我的理解是应该在模型中考虑数据结构。但是，连续降雨变量在生物学上是一个更有趣和更有意义的变量。
感谢建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</guid>
      <pubDate>Thu, 16 Jan 2025 03:22:55 GMT</pubDate>
    </item>
    <item>
      <title>GLM 与 XGB 对零膨胀计数数据的比较</title>
      <link>https://stats.stackexchange.com/questions/660077/comparison-of-glm-xgb-for-zero-inflated-count-data</link>
      <description><![CDATA[我最近才接触 XGB，目前正在做一个项目，为特定保险环境建模索赔数量，并比较 GLM 和 XGB。
首字母缩略词：

GLM - 广义线性模型；

XGB - 极端梯度提升；

ZIP/ZINB - 零膨胀泊松/零膨胀负二项式。


问题：

由于我正在处理 GLM 和 XGB，因此我想在建模之前假设一个分布，以便我可以根据该分布的偏差比较两个模型。例如：如果索赔计数的数据具有泊松分布，则使用泊松偏差。

但是，由于明显的零通货膨胀（索赔为 0 的观测值占总观测值的 70% 以上，占总风险暴露的 70% 以上），我被迫使用 ZIP、拟泊松 GLM、NB GLM 或 ZINB。泊松分布被证实不合适。

另一方面，对于 XGB，我只能对离散计数响应变量使用 count:poisson，它基于泊松偏差。即使通过定制用于 XGB 的损失函数，我也会遇到另一个问题：拟泊松偏差依赖于色散参数，而 NegBinomial 依赖于第二个参数。除非我从一开始就假设它们是恒定的，否则无法为 XGB 实现这些。这意味着，随着 xgb 模型的发展和树的增加，偏差将基于那些恒定的初始假设参数进行计算。甚至 GLM 也会在模型优化时针对 Quasi-Poisson 和 NegBinomial 更新这些参数。对于 XGB 的 ZI 偏差，我无法将这些偏差与梯度和 hessian 拟合到 XGB 的定制目标中。我甚至不认为可以在 XGB 中对零膨胀模型假设发生的产生过量零的单独过程进行建模。

我几乎没有找到针对此类问题的研究或实例。


问题：
(A) 由于 GLM 和 XGB 建模存在这些差异，哪个是比较这两个模型的最合适的指标？
(B) 或者甚至是最好的方法？或者最实用的？
我的建议：

获取最适合 GLM 的模型，并使用默认 count:poisson 偏差获得 XGB，使用具有常数参数 (r) 的 NegBinomial 偏差获得另一个，并在几个偏差下比较所有偏差：
1.1. Poisson 偏差
1.2. NegBinomial 偏差
1.3. 我不明白即使在模型完成后如何找到用于 XGB 模型评估的 ZIP 或 ZINB 偏差。
1.4. 使用加权基尼规范了解哪些模型可以更好地对不同风险进行分类。

]]></description>
      <guid>https://stats.stackexchange.com/questions/660077/comparison-of-glm-xgb-for-zero-inflated-count-data</guid>
      <pubDate>Thu, 16 Jan 2025 00:45:20 GMT</pubDate>
    </item>
    <item>
      <title>如何证明随机矩阵具有独立项？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660075/how-does-one-prove-a-random-matrix-has-independent-entries</link>
      <description><![CDATA[假设我有一个矩阵 $A \in \mathbb{R}^{n \times n}$，其条目都是随机变量。我怀疑它们是独立的。我将使用什么一般技术来证明这一点？
到目前为止，我已经证明条目是成对独立的，但不确定如何继续。]]></description>
      <guid>https://stats.stackexchange.com/questions/660075/how-does-one-prove-a-random-matrix-has-independent-entries</guid>
      <pubDate>Thu, 16 Jan 2025 00:34:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 s(x1, x2) 和 te()/ti() 进行连续 GAM 相互作用之间的差异</title>
      <link>https://stats.stackexchange.com/questions/660072/difference-between-using-sx1-x2-and-te-ti-for-continous-gam-interactions</link>
      <description><![CDATA[我很好奇使用 s() 或 te()/ti() 进行连续交互的 GAM 之间有什么区别？我见过各种 CV/SE/blog 帖子使用其中一种。
那么例如，两者之间有什么区别呢
gam1 &lt;- gam(Sepal.Length ~ 
s(Sepal.Width, bs = &quot;tp&quot;) + 
s(Petal.Length, bs = &quot;tp&quot;) + 
s(Sepal.Width, Petal.Length, bs = &quot;tp&quot;, k = 5), 
data = iris)

gam2 &lt;- gam(Sepal.Length ~ 
s(Sepal.Width, bs = &quot;tp&quot;) + 
s(Petal.Length, bs = &quot;tp&quot;) + 
ti(Sepal.Width, Petal.Length, bs = &quot;tp&quot;, k = 5), 
data = iris)

区别不大，但模型不同。一个比另一个更合适吗？
我意识到与之前的问题有很多相似之处，所以如果这个问题已经得到解答，请原谅。]]></description>
      <guid>https://stats.stackexchange.com/questions/660072/difference-between-using-sx1-x2-and-te-ti-for-continous-gam-interactions</guid>
      <pubDate>Wed, 15 Jan 2025 22:24:51 GMT</pubDate>
    </item>
    <item>
      <title>对于“平均值分布”的直觉？</title>
      <link>https://stats.stackexchange.com/questions/659998/intuition-for-the-mean-value-distribution</link>
      <description><![CDATA[维基百科页面均值定理分享了这一结果：

设$X$和$Y$为非负随机变量，满足$\mathbb{E}[X] &lt; \mathbb{E}[Y] &lt; \infty$和$X \leq_{\text{st}} Y$，其中$\leq_{\text{st}}$为通常的随机顺序。然后存在一个绝对连续非负随机变量$Z$，其概率密度函数为$$f_Z(x) = \frac{\Pr [Y &gt; x] - \Pr [X &gt; x]}{\mathbb{E}[Y] - \mathbb{E}[X]}$$，其中$x \geq 0$。

维基百科文章确实引用了一篇文章，但不幸的是，我这次无法访问它。给出的证明简图如下：

设 $g$ 为可测且可微函数，使得 $\mathbb{E}[g(X)] &lt; \infty$ 和 $\mathbb{E}[g(Y)] &lt; \infty$，并设其导数 $g^{\prime}$ 在区间 $[x,y]$ 上对所有 $y \geq x \geq 0$ 可测且可黎曼积分。 $\mathbb{E}[g^{\prime}(Z)]$ 是有限的，并且 $$\mathbb{E}[g(Y)] - \mathbb{E}[g(X)] = \mathbb{E}[g^{\prime}(Z)] \left( \mathbb{E}[Y] - \mathbb{E}[X] \right).$$

我可以识别诸如 $\mathbb{E}[g^{\prime}(Z)] = f_Z(x)$、$\mathbb{E}[g(Y)] = \Pr [Y &gt; x]$，且$\mathbb{E}[g(X)] = \Pr [X &gt; x]$。
但无论$g$是什么，它都不是$\mathbb{I}[X &gt; x]$或$\mathbb{I}[Y &gt; x]$。此类指示函数并不平滑，但我们上面假设 $g$ 至少有一个一阶导数。
同样，我也不确定该如何评论或思考 $Z$。
类似于混合分布，它们是分布的函数（特别是凸组合），有一个直观的解释，除了将结果作为两个分布的函数这一简单陈述之外，我们还能对 $g$ 或 $Z$ 有更深入的理解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659998/intuition-for-the-mean-value-distribution</guid>
      <pubDate>Tue, 14 Jan 2025 04:13:41 GMT</pubDate>
    </item>
    <item>
      <title>是否有可以在 R 中使用的统计分析来评估曲线区域之间的显著差异？</title>
      <link>https://stats.stackexchange.com/questions/660081/is-there-a-statistical-analysis-that-can-be-used-in-r-to-assess-significant-diff</link>
      <description><![CDATA[我想知道是否有统计分析可以确定两种处理方法中曲线/回归的区域之间的差异。我知道有几种统计分析方法可以确定两个回归/曲线之间是否存在变量总体差异，但我不知道有任何方法可以识别区域差异。
假设 X = Light_uE，Y = CellspermL，物种是处理条件（应该用于生成两个不同的图）。我如何判断 Light_uE (X) 条件下的曲线之间是否存在显着差异，从 10-20 还是 20-30 物种之间？同样，如果曲线整体不同，则不会。
我提供了一个可重现的数据框，以及绘制此数据的代码（如果您想将其可视化）。
# 生成数据框
example_curves &lt;- data.frame(
Light_uE = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 
10, 20, 30, 40, 50, 60, 70, 80, 90, 100),
CellspermL = c(1000000, 2000000, 3000000, 4000000, 5000000, 
4000000, 3000000, 2000000, 1000000, 500000,
2000000, 2500000, 3500000, 3600000, 4000000, 
3900000, 3000000, 2000000, 1000000, 500000),
物种 = c(&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, 
&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, 
&quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, 
&quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;))

print(example_curves)

# 分段绘图
library(segmented)
library(gridExtra)
library(ggplot2)

create_piecewise_plot &lt;- function(data, title, initial_psi) {
# 拟合线性模型
lm_model &lt;- lm(CellspermL ~ Light_uE, data = data)

# 应用分段函数并手动指定初始断点
seg_model &lt;- fragmented(
lm_model, 
seg.Z = ~Light_uE, 
psi = initial_psi, # 手动指定起点
control = seg.control(display = FALSE) # 禁用额外输出
)

data$fitted_values &lt;- fitted(seg_model)

p &lt;- ggplot(data, aes(x = Light_uE, y = CellspermL)) +
geom_point() +
geom_line(aes(y = fitted_values), color = &#39;blue&#39;) +
labs(
title = title,
x = &quot;Light (uE)&quot;,
y = &quot;Cells per mL&quot;
) +
theme_minimal()

return(p)
}

# 按物种创建两个不同的图
data_species_a &lt;- subset(example_curves, Species == &quot;A&quot;)
data_species_b &lt;- subset(example_curves, Species == &quot;B&quot;)

range_a &lt;- range(data_species_a$Light_uE)
range_b &lt;- range(data_species_b$Light_uE)

# 确保 initial_psi 值在范围内
plot_species_a &lt;- create_piecewise_plot(data_species_a, &quot;Species A&quot;, initial_psi = 50) # 在 range_a 内选择一个有效值
plot_species_b &lt;- create_piecewise_plot(data_species_b, &quot;Species B&quot;, initial_psi = 50) # 在 range_b 内选择一个有效值

# 使用 grid.arrange 水平排列图
grid.arrange(plot_species_a, plot_species_b, ncol = 2)

]]></description>
      <guid>https://stats.stackexchange.com/questions/660081/is-there-a-statistical-analysis-that-can-be-used-in-r-to-assess-significant-diff</guid>
      <pubDate>Mon, 13 Jan 2025 22:04:09 GMT</pubDate>
    </item>
    <item>
      <title>使用 Blackbox 方式查找依赖关系</title>
      <link>https://stats.stackexchange.com/questions/659978/finding-dependencies-in-blackbox-way</link>
      <description><![CDATA[给定一个 3 阶张量，其维度为 $x,y,z$。
其中：

$x$：图的数量（样本数量）
$y$：节点数量（假设 $5$：$a、b、c、d$ 和 $e$）
$z$：嵌入维度（例如，对于由水平轴和垂直轴组成的笛卡尔空间，嵌入维度为 $2$轴）

假设一个节点代表一个向量。问题是找出节点之间的关系，无论是有向的（依赖的）、无向的（相互依赖/双向的）还是不连接的。
因此，最初会为所有图形样本提供不连接的节点。如何根据所有图样本发现整个图中节点是否连接的见解？
可以使用随机数生成器 (RNG) 重现此数据集。
让我们为 2D 向量空间 中的 100 个样本 生成随机虚拟向量值：
a := RNG(dims=(100,2))
b := RNG(dims=(100,2))
...
e := RNG(dims=(100,2))

让我们在节点之间生成虚拟关系，比如简单的元素加法/乘法或其他。
a ← a + b + 1
b ← b × a + 2
c ← c + b × 3
d ← d + c × b + 4
e ← e + 5

或者一般来说：
a ← A(b)
b ← B(a)
c ← C(b)
d ← D(b,c)
e ← E()

问题在于找出每个函数 $A、B、C、D$ 和 $E$ 需要多少个参数以及需要哪些参数。
在这种情况下，模型推理的结果为：

函数 $A$ 需要一个参数，即节点 b。
函数 $B$ 需要一个参数，即节点 a，因此 a 和 b 具有无向关系。
函数 $C$ 需要一个参数，节点 b。（有向关系）。
函数 $D$ 需要两个参数，节点 b 和节点 c。
函数 $E$ 不需要参数，因此可以安全地将其称为无连接节点。

]]></description>
      <guid>https://stats.stackexchange.com/questions/659978/finding-dependencies-in-blackbox-way</guid>
      <pubDate>Mon, 13 Jan 2025 19:28:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么在我的混合效应模型中添加协变量后交互项保持不变？</title>
      <link>https://stats.stackexchange.com/questions/659963/why-does-the-interaction-term-remain-unchanged-after-adding-a-covariate-in-my-mi</link>
      <description><![CDATA[我的数据结构如下：

seek_score（因变量，连续）和 sek_src（因子）是受试者内变量。
pers 和 age 是受试者间变量（均为连续变量）

这是我的 lmer 代码
m.pers &lt;- lmer(seek_score ~ pers * sek_src + (1 | id), data = cln_long_sek)
m1.pers &lt;- lmer(seek_score ~ pers * sek_src + (1 | id)+age, data = cln_long_sek)

我注意到，无论我在模型中是否包含协变量 age（或其他协变量），交互项 pers * sek_src 都保持不变。我还用其他变量测试了这种行为，交互结果不受影响。
为什么添加协变量不会影响交互项？这是混合效应模型中的预期行为吗？还是我在解释中遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659963/why-does-the-interaction-term-remain-unchanged-after-adding-a-covariate-in-my-mi</guid>
      <pubDate>Mon, 13 Jan 2025 06:51:18 GMT</pubDate>
    </item>
    </channel>
</rss>