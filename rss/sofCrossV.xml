<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 05 Oct 2024 09:19:14 GMT</lastBuildDate>
    <item>
      <title>证明 $E[X]$ 的有限性等价于 $E[|X|]$ 的有限性</title>
      <link>https://stats.stackexchange.com/questions/655356/prove-that-the-finiteness-of-ex-is-equivalent-to-the-finiteness-of-ex</link>
      <description><![CDATA[我知道网上有解决方案，但我先自己尝试了一下，想问问我的方法是否有效。
证明$E[X]$的有限性等同于$E[|X|]$的有限性。注意$E[X]$的有限性意味着$|E[X]| &lt; \infty$，这意味着证明$|E[X]| &lt; \infty \iff E[|X|] &lt; \infty$。使用以下事实：$X^+ = X$ 表示 $X \geq 0$，$X^- = -X$ 表示 $X &lt; 0$。
我尝试了以下方法：
$$
X = X^+ - X^- \quad \text{and} \quad |X| = X^+ + X^-
$$
$$
|E[X]| = |E[X^+] - E[X^-]| \leq |E[X^+]| + |E[X^-]|
$$
$$
E[|X|] = E[X^+ + X^-] = E[X^+] + E[X^-] = |E[X^+] + E[X^-]| \leq |E[X^+]| + |E[X^-]|
$$
使用三角不等式两次。然后我会争论 $|E[X]| &lt; \infty \iff E[|X|] &lt; \infty$ 是否成立，因为两者都有相同的上限。但我不确定以下步骤是否有效：$E[X^+] + E[X^-] = |E[X^+] + E[X^-]|$。我的想法是，根据任务中的定义，$X^+$ 和 $X^-$ 都必须为正数。感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/655356/prove-that-the-finiteness-of-ex-is-equivalent-to-the-finiteness-of-ex</guid>
      <pubDate>Sat, 05 Oct 2024 08:00:20 GMT</pubDate>
    </item>
    <item>
      <title>帮助编码安全风险</title>
      <link>https://stats.stackexchange.com/questions/655355/help-with-coding-security-risks</link>
      <description><![CDATA[我正在研究一些数据安全风险对一些机构实施云计算的影响。基于 LR 和专家访谈，我发现了一些风险。例如其中之一就是“数据泄露”。现在，在收集数据后，我需要根据 5 点李克特量表对答案进行编码。我变得非常困惑。假设是
“数据泄露对云计算实施有显著影响”
陈述如下：

我认为对与云存储相关的潜在数据泄露的担忧会影响我们机构关于实施云计算技术的决策。
我认为我们的机构由于担心数据泄露而避免使用云计算服务进行涉及敏感数据的研究。
我认为数据泄露的风险阻碍了我们机构某些部门实施云计算服务。
我认为数据泄露的风险对我们机构主要活动中云计算的使用产生了不利影响。
请问，您有什么建议？
我是否认为这些陈述是积极的，因此得到 5 分（非常同意），还是认为它们是消极的，因此得到 1 分（非常同意）？谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/655355/help-with-coding-security-risks</guid>
      <pubDate>Sat, 05 Oct 2024 06:13:55 GMT</pubDate>
    </item>
    <item>
      <title>将 NA 重新编码为因子中的不同级别</title>
      <link>https://stats.stackexchange.com/questions/655354/recoding-nas-as-a-different-level-in-a-factor</link>
      <description><![CDATA[我收集了孕妇的数据。一些数据与女性以前的怀孕情况有关（例如询问她们以前是否生过大婴儿）。对于第一次怀孕的女性，对这类问题的回答被编码为 NA。但是，它们并不是缺少数据 - 只是无法回答。所以当我运行一个多变量模型时，例如：
m &lt;- glm(高血压 ~ 肥胖 + 年龄 + 酒精 + 孕产妇历史大婴儿 + 早产，数据 = df，家庭 = &#39;二项式&#39; )

我刚刚发现它会进行完整的案例分析，所有第一次怀孕的女性都将被排除在分析之外，因为她们在 孕产妇历史大婴儿 中有 NA。这意味着该模型仅反映怀孕超过一次的女性，这限制了其普遍性。
选项：
i. 将这些类型的协变量中的 NA 更改为因子中的不同级别（例如 3）会产生什么影响？我理解该因子级别的输出将毫无意义，但因子其他级别（以及其他协变量）的对数是否会失去准确性？
ii. 最好进行两项不同的分析：一项针对首次怀孕的女性，另一项针对怀孕超过一次的女性？
我尝试过 na.action = na.pass，但这对我的模型不起作用。]]></description>
      <guid>https://stats.stackexchange.com/questions/655354/recoding-nas-as-a-different-level-in-a-factor</guid>
      <pubDate>Sat, 05 Oct 2024 06:12:13 GMT</pubDate>
    </item>
    <item>
      <title>混合效应回归模型是否存在过度分散？</title>
      <link>https://stats.stackexchange.com/questions/655353/can-a-mixed-effects-regression-model-overdispersion</link>
      <description><![CDATA[采用常见的泊松 GLM：
$$ Y_i \sim \text{Poisson}(\lambda_i) $$
$$ \log(\lambda_i) = X_i\beta $$
$$ L(\beta | Y) = \prod_{i=1}^n \frac{e^{-\lambda_i} \lambda_i^{y_i}}{y_i!} $$
$$ = \prod_{i=1}^n \frac{e^{-\exp(X_i\beta)} \exp(X_i\beta)^{y_i}}{y_i!} $$
$$ E(Y_i) = \lambda_i = \exp(X_i\beta) $$
$$ \text{Var}(Y_i) = \lambda_i = \exp(X_i\beta) $$
如果我有计数数据，并且我认为泊松回归是一个不错的选择 - 但随后我注意到数据的平均值和方差不相等，这违反了泊松分布的假设。在这种情况下，我们可以添加过度分散参数来考虑这一点。但是，这样做后，我们不再具有确切的可能性，而具有四重似然性：
$$
E(Y) = \mu
$$
$$
\text{Var}(Y) = \phi\mu
$$
$$
Q(\mu; y) = \int_{y}^{\mu} \frac{y - t}{\phi t} dt
$$
$$
l(\mu; y) = \frac{y \log(\mu) - \mu}{\phi}
$$
$$
L(\mu; y) = \sum_{i=1}^{n} \frac{y_i \log(\mu_i) - \mu_i}{\phi}
$$
我有以下问题：假设我们定义一个基于泊松分布的混合效应回归模型：
$$ Y_i | u_i \sim \text{Poisson}(\lambda_i) $$
$$ \log(\lambda_i) = X_i\beta + u_i $$
$$ u_i \sim N(0, \sigma^2_u) $$
$$ L(\beta, \sigma^2_u | Y) = \prod_{i=1}^n \int_{-\infty}^{\infty} \frac{e^{-\exp(X_i\beta + u_i)} \exp(X_i\beta + u_i)^{y_i}}{y_i!} \cdot \frac{1}{\sqrt{2\pi\sigma^2_u}} \exp(-\frac{u_i^2}{2\sigma^2_u}) du_i $$
如果我们写出具有随机效应的泊松回归的均值和方差：
$$ E(Y_i) = E(E(Y_i|u_i)) = E(\exp(X_i\beta + u_i)) $$
$$ = \exp(X_i\beta) E(\exp(u_i)) = \exp(X_i\beta + \frac{\sigma^2_u}{2}) $$
$$ \begin{align*}
\text{Var}(Y_i) &amp;= E(\text{Var}(Y_i|u_i)) + \text{Var}(E(Y_i|u_i)) \\
&amp;= E(\lambda_i) + \text{Var}(\lambda_i) \\
&amp;= \exp(X_i\beta + \frac{\sigma^2_u}{2}) + [\exp(2X_i\beta + \sigma^2_u)](\exp(\sigma^2_u) - 1)
\end{align*} $$
我现在可以看到，这种混合效应泊松回归的均值和方差现在有一个额外的项，看起来它隐含地解释了过度分散。因此，似乎过度离散的泊松回归实际上也可以使用完全似然而不是仅仅使用拟似然来编写 - 这是正确的解释吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655353/can-a-mixed-effects-regression-model-overdispersion</guid>
      <pubDate>Sat, 05 Oct 2024 06:11:38 GMT</pubDate>
    </item>
    <item>
      <title>SLR 中 $\beta_1$ 方差推导错误</title>
      <link>https://stats.stackexchange.com/questions/655349/error-in-derivation-of-variance-of-beta-1-in-slr</link>
      <description><![CDATA[我试图通过以下方式推导简单线性回归的斜率参数方差，但是我遇到了一个我不知道如何解决的问题。定义$y_i=\beta_0+\beta_1\cdot x_i+\epsilon_i$，其中$\epsilon_i\sim N(0,\sigma^2)$。让$\hat\beta_0$和$\hat\beta_1$成为截距和斜率参数的最小二乘估计量。我的推导如下：
$
\begin{gather*} \\ 
Var(\hat\beta_1) = Var\left(\frac{\sum(x_i-\overline{x})(y_i-\overline{y})}{\sum(x_i-\overline{x})^2} \right) \\
\text{* 因为 x 是固定的，所以它们在这个推导中充当常数 
} \\
= \frac{1}{(\sum(x_i-\overline{x})^2)^2}\sum(x_i-\overline{x})^2Var(y_i-\overline{y}) \\
= \frac{1}{(\sum(x_i-\overline{x})^2)^2}\sum(x_i-\overline{x})^2[Var(y_i)-Var(\overline{y})] \\
= \frac{1}{(\sum(x_i-\overline{x})^2)^2}\sum(x_i-\overline{x})^2\left[\sigma^2-\frac{\sigma^2}{n}\right] \\
= \frac{1}{(\sum(x_i-\overline{x})^2)^2}\left[\sigma^2-\frac{\sigma^2}{n}\right]\cdot\sum(x_i-\overline{x})^2 \\
= \frac{\left[\sigma^2-\frac{\sigma^2}{n}\right]}{\sum(x_i-\overline{x})}\ne\frac{\sigma^2}{\sum(x_i-\overline{x})}
\end{gather*}
$
我唯一的想法是，我忘记考虑 $y_i$ 和 $\overline{y}$ 之间的协方差，但我认为这只是 0。任何见解都将不胜感激！
编辑：我知道有一种方法可以将 $\hat\beta_1$ 定义为一些常数的线性组合，但我很好奇是否有一个简单的修复步骤
编辑 2 :
我认为协方差可以用以下公式来解释：
$
\begin{gather*} 
Var(y_i-\overline{y}) =Var\left(y_i-\frac{\sum{y_i}}{n}\right)\\
=Var\left(y_i-\frac{y_1}{n}-\frac{y_2}{n}-\ldots-\frac{y_i}{n}-\ldots-\frac{y_n}{n}\right)\\
=Var\left(\left(1-\frac{1}{n}\right)\cdot y_i-\frac{y_1}{n}-\ldots-\frac{y_n}{n}\right)\\
=\left(1-\frac{1}{n}\right)^2\cdot Var(y_i)+\frac{1}{n^2}\cdot Var(y_1)+\ldots+\frac{1}{n^2}\cdot Var(y_n)-\frac{2}{n^2}\mathop{\sum{}\sum{}}_{j\ne k}Cov(y_j,y_k)\\
\text{**我可能对双重和的符号有些不严谨，但你明白我的意思}\\
\text{根据定义，不同响应值之间的协方差等于 0（因为 $\epsilon_i$ 是 i.i.d）。因此：}\\
=\left(\frac{n-1}{n}\right)^2\cdot \sigma^2+\frac{n-1}{n^2}\sigma^2\\
=\frac{\sigma^2}{n^2}((n-1)^2+(n-1))\\
=\frac{\sigma^2}{n^2}((n-1)(n-1+1)\\
=\frac{(n-1)\sigma^2}{n}
\end{gather*}
$]]></description>
      <guid>https://stats.stackexchange.com/questions/655349/error-in-derivation-of-variance-of-beta-1-in-slr</guid>
      <pubDate>Sat, 05 Oct 2024 03:18:17 GMT</pubDate>
    </item>
    <item>
      <title>错误类型和不确定性的术语：内在的？拟合的？</title>
      <link>https://stats.stackexchange.com/questions/655348/terminology-for-types-of-errors-and-uncertainty-intrinsic-fitting</link>
      <description><![CDATA[假设我有一系列给定变量$x_i$、$i=1,\ldots,n-1$和响应$y_i$，我们探索模型$y_i\sim \text{Normal}(\alpha x_i,\sigma^2)$，其中$y_i$独立于$y_j$，其中$i\neq j$。
我们使用最大似然法拟合参数 $\alpha$ 和 $\sigma$。
假设我们希望在给定 $x_n$ 的情况下预测 $y_n$。显然，对 $y_n$ 的最佳预测将是 $\alpha_\text{MLE}\,x_n$。据我所知，至少有两种类型的不确定性：

模型固有的不确定性，即 $\sigma$。我们不能指望以比$\sigma$更高的精度预测$y_n$，这类似于“观测误差”。
不确定性源于 MLE 估计量具有由预期 Fisher 信息给出的方差，与似然函数的二阶导数或曲率最大相关。这可以通俗地称为$\alpha_\text{MLE}$的“拟合误差/不确定性”。当然，这个“误差”会传播到$y_n$的最佳估计量，从而产生另一个不确定性来源。

这两种不确定性的正确术语是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/655348/terminology-for-types-of-errors-and-uncertainty-intrinsic-fitting</guid>
      <pubDate>Sat, 05 Oct 2024 00:35:51 GMT</pubDate>
    </item>
    <item>
      <title>已知有限总体与所有可能的引导样本均值的方差</title>
      <link>https://stats.stackexchange.com/questions/655345/variance-of-known-finite-population-from-all-possible-bootstrap-sample-means</link>
      <description><![CDATA[我知道这个问题没有什么实际意义，但我被问到这个问题，并为此苦思了一天。
如果我们从小的/有限的总体 N 中取出所有可能的引导样本大小为 n 的集合，并仅保留样本均值，我们能得到总体方差吗？我们当然有样本均值，所以我们可以得到均值的方差和样本均值的均值。
设 N = 10，n = 3；可能样本均值的引导集是一个大小为 220 的集合。我们有 220 个均值，其中袋装均值当然等于真实总体均值。但我们如何才能从中获得总体方差？这可能吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655345/variance-of-known-finite-population-from-all-possible-bootstrap-sample-means</guid>
      <pubDate>Fri, 04 Oct 2024 23:40:51 GMT</pubDate>
    </item>
    <item>
      <title>使用事后均值分离检验进行置换多元方差分析后确定哪些变量导致组间差异</title>
      <link>https://stats.stackexchange.com/questions/655341/determining-which-variables-drive-group-differences-after-a-permutational-multiv</link>
      <description><![CDATA[我有一个数据框，里面有几列不同的变量（有分类预测变量和几个不同的数字响应变量）。我做了方差的置换多元变量分析，然后做了适当的事后分析，以确定哪些组对实际上存在显著差异。
我想进一步深入研究这些结果，并确定哪些响应变量导致了分析发现的组间差异。我认为应该有一种方法可以确定（使用向量载荷）哪些向量与每对显著不同的组的显著组差异方向最一致。
虽然我有兴趣编写一个算法来找出每个变量在驱动这些组差异方面的重要性，但我的最终问题要复杂一些。是否有统计分析可以告诉我哪些变量或哪些变量显著地驱动了组间差异？换句话说，如果我知道组 A 和 B 有显著差异，并且某些变量与这种差异的方向更一致（从组 A 的质心到组 B 的质心的方向），我如何将 p 值放在每个变量上以确定是否有任何变量特别强烈地驱动组 A 和组 B 之间的差异？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/655341/determining-which-variables-drive-group-differences-after-a-permutational-multiv</guid>
      <pubDate>Fri, 04 Oct 2024 20:49:45 GMT</pubDate>
    </item>
    <item>
      <title>检查聚合频率数据是否符合泊松分布</title>
      <link>https://stats.stackexchange.com/questions/655340/checking-if-aggregate-frequency-data-is-poisson</link>
      <description><![CDATA[我随机地将每份保单的索赔数量建模为泊松分布（方差 = 均值）或负二项分布（方差 &gt; 均值）。
我想从一些数据中做一个简单的检查，看看分布是泊松分布还是负二项分布，但观察结果基于不同的基础投资组合或保单集合，我不知道单个保单的结果。在这种情况下，我无法确定是否有一个好的方法可以检查均值是否等于方差，或者我可以对泊松分布进行一些类似的检查。
假设我有投资组合 P_1、P_2、... P_n，每个投资组合包含 m_1、m_2、.... m_n 份保单。我知道每个投资组合的索赔总数，c_1、c_2、...c_n，但我不知道每个保单的索赔总数。
我可以将每份保单的平均索赔计算为 sum(c_i) / sum(m_i)。不过，我认为我无法在保单级别计算方差，以便进行通常的检查，看看方差是否等于平均值​​。我是否可以对平均值和方差进行其他一些简单的检查，以验证分布是否可能是泊松分布？或者其他一些简单的检查？
感谢您的阅读。]]></description>
      <guid>https://stats.stackexchange.com/questions/655340/checking-if-aggregate-frequency-data-is-poisson</guid>
      <pubDate>Fri, 04 Oct 2024 20:34:06 GMT</pubDate>
    </item>
    <item>
      <title>仅建模一个变量时 lrm.fit 中的奇异信息矩阵</title>
      <link>https://stats.stackexchange.com/questions/655339/singular-information-matrix-in-lrm-fit-when-only-modelling-one-variable</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655339/singular-information-matrix-in-lrm-fit-when-only-modelling-one-variable</guid>
      <pubDate>Fri, 04 Oct 2024 19:36:44 GMT</pubDate>
    </item>
    <item>
      <title>正则化逻辑回归与 XGBoost 的比较</title>
      <link>https://stats.stackexchange.com/questions/655338/comparing-regularized-logistic-regression-and-xgboost</link>
      <description><![CDATA[您知道任何有用的指标，可以比较 XGBoost 和正则化逻辑回归吗？我正在寻找一些可以像 AIC / BIC 一样惩罚模型复杂性的东西，或者以某种方式深入了解应用 XGBoost 时的权衡。应用 XGBoost 时，预测性能当然会更好，因为在 GBDT 之上进行了大量优化。我认为这并没有真正考虑到与逻辑回归相比所需的额外复杂性。]]></description>
      <guid>https://stats.stackexchange.com/questions/655338/comparing-regularized-logistic-regression-and-xgboost</guid>
      <pubDate>Fri, 04 Oct 2024 19:27:02 GMT</pubDate>
    </item>
    <item>
      <title>计算机根据高斯分布生成的样本是否有偏差？</title>
      <link>https://stats.stackexchange.com/questions/655335/are-samples-generated-by-a-computer-from-a-gaussian-distribution-biased</link>
      <description><![CDATA[最近我一直在阅读一些关于高斯过程的博客，它们使用协方差矩阵$\Sigma$来生成一系列点$(x_1, x_2 ...x_n)$，这些点组合在一起看起来像一个实函数。
但是，我不太明白为什么会出现这种现象。我的意思是，一切都是概率性的，对吧？因此可能存在一些噪声样本 - 一系列$(x_1, x_2 ...x_n)$，当放在一起时，它们看起来不像任何平滑函数，但似乎不会发生这种情况？
此外，关于计算机如何从高斯$\mathcal{N}$分布生成样本，我听说过重新参数化技巧：$x\sim \mathcal{N}(\mu, \sigma) \rightarrow x = \mu + \sigma \epsilon$，其中$\epsilon \sim \mathcal{N}(0, 1)$。但是，我们只能确保 $x$ 遵循 $\mathcal{N}$ 分布，并非使用此技巧可以正确生成 $\mathcal{N}$ 分布中的每个样本，对吗？我的意思是，这种关系是单向的，那么我们是否会偏向某些样本？]]></description>
      <guid>https://stats.stackexchange.com/questions/655335/are-samples-generated-by-a-computer-from-a-gaussian-distribution-biased</guid>
      <pubDate>Fri, 04 Oct 2024 18:56:35 GMT</pubDate>
    </item>
    <item>
      <title>关于最小充分统计量和最小充分 $\sigma$-代数的问题</title>
      <link>https://stats.stackexchange.com/questions/655334/question-about-minimal-sufficient-statistics-and-minimal-sufficient-sigma-alg</link>
      <description><![CDATA[我得出了一个关于最小充分统计数据的矛盾，但我无法确定问题出在哪里。
考虑统计模型$(\mathbb{R},\mathfrak{B}_\mathbb{R},\{P_\theta\}_{\theta\in \mathbb{R}})$，其中$P_\theta$是由密度函数$f_\theta:\mathbb{R}\to \mathbb{R}$引起的概率测度，由$f_\theta (x):=\left(\frac{2}{\pi}\right)^{1/2}e^{-\frac{(x-\theta)^2}{2}}\mathbf{1}_{[\theta,\infty)}(x)$。
很容易看出，由 $T(x):=x$ 给出的 $T:\mathbb{R}\to \mathbb{R}$ 是最小充分统计量，这意味着，使用 [1] 的定理 4，$\sigma (T):=\{T^{-1}(B):B\in\mathfrak{B}_\mathbb{R}\}$ 是最小充分$\sigma$-代数。因此，利用[2]的定理 1，我们可以得出结论：$\otimes _{i=1}^n\sigma (T)$是$(\mathbb{R}^n,\mathfrak{B}_{\mathbb{R}^n},\{P_\theta^{\otimes n}\}_{\theta\in \mathbb{R}})$的最小充分$\sigma$-代数。
因此，$S:\mathbb{R}^n\to $S(x):=x$ 给出的 \mathbb{R}^n$ 是 w.r.t 的最小充分统计数据。 $(\mathbb{R}^n,\mathfrak{B}_{\mathbb{R}^n},\{P_\theta^{\otimes n}\}_{\theta\in \mathbb{R}})$ 因为 $\sigma (S)=\otimes _{i=1}^n\sigma (T)$（这是 [1] 定理 4 证明中发现的一个论证的结果）。
您还可以证明 $\tilde T:\mathbb{R}^n\to \mathbb{R}^2$ 由 $\tilde T(x):=(\overline x,x_{(1)})$ 给出是足够的（最小）w.r.t. $(\mathbb{R}^n,\mathfrak{B}_{\mathbb{R}^n},\{P_\theta^{\otimes n}\}_{\theta\in \mathbb{R}})$，这意味着存在一个函数 $g:\mathbb{R}^2\to \mathbb{R}^n$，使得 $S=g(\tilde T)$ $\{P_\theta^{\otimes n}\}_{\theta\in\mathbb{R}}$-a.e.。然而，我认为这是荒谬的。

有人能确定在哪里吗问题？
感谢您的关注！

编辑：
使用 [[3]3] 的定理 1，您可以直接证明 $S$ 是一个充分最小统计量。
我现在刚刚意识到的一件事：由于 $S$ 是充分最小的，因此每个充分统计量 $\tilde S:\mathbb{R}^n\to\mathbb{R}^m$ 对于所有 $m\in\mathbb{N}$ 也是充分最小的。]]></description>
      <guid>https://stats.stackexchange.com/questions/655334/question-about-minimal-sufficient-statistics-and-minimal-sufficient-sigma-alg</guid>
      <pubDate>Fri, 04 Oct 2024 18:54:28 GMT</pubDate>
    </item>
    <item>
      <title>Brunner-Munzel 检验的问题 - 只有排名才重要</title>
      <link>https://stats.stackexchange.com/questions/655333/issue-with-brunner-munzel-test-only-the-rankings-matter</link>
      <description><![CDATA[当使用非参数 Brunner-Munzel 检验在两个总体之间进行测试时，我注意到检验统计量
$BM = \frac{\bar{R}_2-\bar{R}_1}{Ns}$
其中 $\bar{R}_i$ 是汇总排名 $R_{ij}$ 的平均值，$N$ 是总体规模 $n_1$ 和 $n_2$ 的总和，并且 $s = \sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}$ 其中 $s_i^2$ 是展示位置 $P_{ij}$ 的样本方差，其中 $P_{ij}=\frac{R_{ij} - R_{ij}^{*}}{N - n_i}$，其中 $R_{ij}^{*}$ 是 $x_{ij}$ 在 $X_i$ 中的总体内排名。因此，如果您将 $\begin{bmatrix}1\\1\\1\\1\\1\\1 \end{bmatrix}$ 与 $\begin{bmatrix}1\\1\\1\\1\\1\\2 \end{bmatrix}$ 进行比较，则得到的检验统计量与将 $\begin{bmatrix}1\\1\\1\\1\\1\\1 \end{bmatrix}$ 与 $\begin{bmatrix}1\\1\\1\\1\\1\\1000 \end{bmatrix}$ 进行比较时得到的检验统计量完全相同。
我的问题是：

我认为第二种情况应该比第一种情况“更加不同”，我的直觉正确吗？
是否有某种替代测试、方法或手段可以纠正这种情况？
]]></description>
      <guid>https://stats.stackexchange.com/questions/655333/issue-with-brunner-munzel-test-only-the-rankings-matter</guid>
      <pubDate>Fri, 04 Oct 2024 18:44:03 GMT</pubDate>
    </item>
    <item>
      <title>优化对数似然（针对具有自相关系统性风险的 Vasicek 损失模型）</title>
      <link>https://stats.stackexchange.com/questions/655313/optimizing-loglikelihood-for-vasicek-loss-model-with-autocorrelated-systemic-ri</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655313/optimizing-loglikelihood-for-vasicek-loss-model-with-autocorrelated-systemic-ri</guid>
      <pubDate>Fri, 04 Oct 2024 10:50:23 GMT</pubDate>
    </item>
    </channel>
</rss>