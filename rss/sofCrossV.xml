<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 30 Nov 2024 06:23:19 GMT</lastBuildDate>
    <item>
      <title>包括两组用于元分析池的后测设计研究？</title>
      <link>https://stats.stackexchange.com/questions/658055/include-two-groups-post-test-design-study-for-meta-analysis-pool</link>
      <description><![CDATA[我是荟萃分析的新手，目前正在尝试寻找干预对服务用户的影响。
我发现的大多数研究都是 RCT 或准实验研究，采用 2 组事前事后测试设计。但是，有几项研究是 2 组事后测试设计，没有可用的事前测试数据。我想知道我是否可以将这个事后测试设计研究纳入荟萃分析池？或者只是将事后测试设计研究排除在荟萃分析之外？谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658055/include-two-groups-post-test-design-study-for-meta-analysis-pool</guid>
      <pubDate>Sat, 30 Nov 2024 05:04:19 GMT</pubDate>
    </item>
    <item>
      <title>在没有相关系数 r 值的情况下进行组内荟萃分析</title>
      <link>https://stats.stackexchange.com/questions/658054/performing-within-group-meta-analysis-without-access-to-correlation-coefficient</link>
      <description><![CDATA[这个想法是对干预的单组研究进行荟萃分析，其中存在连续结果变量的基线测量和干预后测量。结果变量始终以相同的尺度进行测量，并且没有研究涉及对照组。计划是计算平均增益。
我遇到的问题是，我理解，在处理组内、干预前后情景时，计算我需要进行荟萃分析的效应大小的标准误差“需要”相关 r 值。这些 r 值从未在文献中报告过，必须进行估计，这似乎非常成问题。我有没有选择在没有相关 r 项的情况下进行荟萃分析？
我所拥有的只是干预前时间 1 的平均值、sd 和 n，以及干预后时间 2 的平均值、sd 和 n。
我正在使用 metafor 在 R 中工作 - 正在走“4a”路径。]]></description>
      <guid>https://stats.stackexchange.com/questions/658054/performing-within-group-meta-analysis-without-access-to-correlation-coefficient</guid>
      <pubDate>Sat, 30 Nov 2024 05:02:06 GMT</pubDate>
    </item>
    <item>
      <title>假设两个变量的条件独立，则它们的条件是独立的</title>
      <link>https://stats.stackexchange.com/questions/658052/conditional-independence-of-two-variables-assuming-their-conditionals-are-indepe</link>
      <description><![CDATA[设 $X, Y, Z$ 为随机变量。众所周知，$X \mathbin{\bot} Y$ 并不意味着 $X \mathbin{\bot} Y \mathbin{|} Z$，反之亦然。但是，如果随机变量 $X \mathbin{|}Z$ 与 $Y\mathbin{|}Z$ 独立，这是否意味着 $X \mathbin{\bot} Y\mathbin{|}Z$？]]></description>
      <guid>https://stats.stackexchange.com/questions/658052/conditional-independence-of-two-variables-assuming-their-conditionals-are-indepe</guid>
      <pubDate>Sat, 30 Nov 2024 01:14:14 GMT</pubDate>
    </item>
    <item>
      <title>解释一致性概率：排除同等结果和平局的作用</title>
      <link>https://stats.stackexchange.com/questions/658051/interpreting-concordance-probability-exclusion-of-equal-outcomes-and-role-of-ti</link>
      <description><![CDATA[一致概率 $P(C)$ 定义为模型预测概率正确对两个观察结果进行排序的可能性。它考虑了三种类型的成对比较：

一致对：当 $\hat{p}(X_i) &gt; \hat{p}(X_j)$ 和 $Y_i &gt; Y_j$，或 $\hat{p}(X_i) &lt; \hat{p}(X_j)$ 和 $Y_i &lt; Y_j$。
不一致对：当 $\hat{p}(X_i) &gt; \hat{p}(X_j)$ 且 $Y_i &lt; Y_j$，或 $\hat{p}(X_i) &lt; \hat{p}(X_j)$ 且 $Y_i &gt; Y_j$.
平局：当 $\hat{p}(X_i) = \hat{p}(X_j)$.

该公式通过添加其贡献的一半来合并平局：
$$
P(C) = \frac{\text{一致对的数量} + 0.5 \times \text{平局数量}}{\text{其中 } Y_i \neq Y_j} 的对总数。
$$
设：

$C$ = 一致对的数量，
$D$ = 不一致对的数量，
$T$ = 并列对的数量。

可比对的总数为 $C + D + T$，并且 $P(C)$ 变为：
$$
P(C) = \frac{C + 0.5T}{C + D + T}。
$$

问题：
在计算一致性概率$P(C)$时，我们通过为它们分配 0.5 的权重来包含平局。但是，我们仍然排除$Y_i = Y_j$的对。

如何将$P(C)$解释为“概率”当它仅以 $Y_i \neq Y_j$ 为条件时？
此外，包含 $0.5 \times \text{ties}$ 是否足以证明将其称为概率，还是仅仅是处理排名歧义的启发式方法？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658051/interpreting-concordance-probability-exclusion-of-equal-outcomes-and-role-of-ti</guid>
      <pubDate>Fri, 29 Nov 2024 23:44:55 GMT</pubDate>
    </item>
    <item>
      <title>ML 主题如何融入传统本科统计课程的估计（矩估计方法、MLE 等）？</title>
      <link>https://stats.stackexchange.com/questions/658050/how-does-ml-topics-fit-into-a-traditional-undergraduate-statistics-course-on-est</link>
      <description><![CDATA[我最近在教本科生统计学入门课程，但根据课程主任的要求，需要添加一些机器学习材料。我想知道将机器学习材料（偏差方差权衡、过拟合和欠拟合、训练和测试、正则化和模型选择、性能评估）注入估计主题（传统材料包括矩估计量、MLE、无偏性、效率、不确定性量化）的适当方法是什么，以及如何组织这部分内容的好方法？我觉得很难以一种井井有条且合乎逻辑的方式组织这些机器学习和统计学元素的混合。如果您能建议对这两大主题进行合理的安排，那就太好了。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658050/how-does-ml-topics-fit-into-a-traditional-undergraduate-statistics-course-on-est</guid>
      <pubDate>Fri, 29 Nov 2024 23:33:07 GMT</pubDate>
    </item>
    <item>
      <title>事后分析有相互作用但没有主效应</title>
      <link>https://stats.stackexchange.com/questions/658049/post-hoc-analysis-whith-interaction-but-no-main-effects</link>
      <description><![CDATA[
我正在审查一种情况，其中有两个因素（杀虫剂、除草剂），每个因素都有两个水平（不存在、存在）。杀虫剂或除草剂没有主效应，但存在交叉相互作用。
假设我使用 Tukeys-HSD 事后检验 - 4 意味着这通常会导致 6 次成对比较和相应的 p 值调整。在我概述的没有主效应但有显著交叉相互作用的情况下，事后检验的次数是否应该减少，因为只有 4 次比较具有潜在意义？]]></description>
      <guid>https://stats.stackexchange.com/questions/658049/post-hoc-analysis-whith-interaction-but-no-main-effects</guid>
      <pubDate>Fri, 29 Nov 2024 22:20:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的方差参数不会在 Metropolis-Hastings 采样器中收敛？</title>
      <link>https://stats.stackexchange.com/questions/658046/why-wont-my-variance-parameter-converge-in-my-metropolis-hastings-sampler</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658046/why-wont-my-variance-parameter-converge-in-my-metropolis-hastings-sampler</guid>
      <pubDate>Fri, 29 Nov 2024 20:22:02 GMT</pubDate>
    </item>
    <item>
      <title>似然比检验与 Wald 检验多重共线性</title>
      <link>https://stats.stackexchange.com/questions/658039/likehood-ratio-test-vs-wald-test-multicolinearity</link>
      <description><![CDATA[我想做一个项目，展示似然比检验的稳健性。我的想法是，在一个预测因子显示多重共线性的逻辑回归中，Wald 检验在 LRT 中的 p 值结果不太可靠，因为 LRT 关注的是整个模型而不是单个系数。我只是不知道如何正确证明这一点，以及这个想法有多有效。有人可以提供一些指导吗？
例如，我的场景是一个有五个预测因子的逻辑回归，其中两个显示高相关性。我运行模型并运行 Wald 检验以检查模型中的所有系数是否显著。然而，由于相关性，结果可能会受到影响。我的想法是，然后使用完整模型和另一个没有受到影响的变量的模型运行 LRT，并测试 LRT 是否告诉我完整模型更好。这个想法是表明 LRT 比 Wald 检验更稳健，因为 LRT 查看整个模型而不是单个系数。]]></description>
      <guid>https://stats.stackexchange.com/questions/658039/likehood-ratio-test-vs-wald-test-multicolinearity</guid>
      <pubDate>Fri, 29 Nov 2024 18:22:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么卡方检验会给出不直观的结果？</title>
      <link>https://stats.stackexchange.com/questions/658020/why-is-the-chi-square-test-giving-unintuitive-results</link>
      <description><![CDATA[我正在对不同年龄组之间的变量分布进行卡方检验。数据在 R 中如下所示：
 a &lt;- c(66,97, 48)
b &lt;- c(145,174,58)
c &lt;- c(129,128,58)

M &lt;- data.frame(cbind(a,b,c))
colnames(M) &lt;- c(&quot;18-34&quot;, &quot;35-49&quot;,&quot;50-66&quot;)
rownames(M) &lt;- c(&quot;Below avg&quot; , &quot;Average&quot;,&quot;Above avg&quot;)
view(M)

绘制时，最年轻组的数据分布与中间组相似，与最年长组不同。

如果我进行整体卡方检验，我会得到一个不显著的差异：
X-squared = 8.6905, df = 4, p-value = 0.06932

但是，如果我成对比较年龄组，我会得到最小和中间之间的显著差异，而不是最小和最年长之间的显著差异。
数据：M[, 1:2]
X-squared = 6.0153, df = 2, p-value = 0.04941

数据：M3[, c(1, 3)]
X-squared = 5.2093，df = 2，p 值 = 0.07393

我认为这与每个年龄组的参与者数量不平衡有关，尽管每个组的总体观察数量相当大。但我不确定是否以及如何解释这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/658020/why-is-the-chi-square-test-giving-unintuitive-results</guid>
      <pubDate>Fri, 29 Nov 2024 09:07:03 GMT</pubDate>
    </item>
    <item>
      <title>置信区间 - CLT，初级</title>
      <link>https://stats.stackexchange.com/questions/658015/confidence-interval-clt-beginner-level</link>
      <description><![CDATA[我正在参加一个关于统计学的在线课程，更准确地说是关于置信区间的课程。
下面是一个练习，他们试图根据以前收集的数据估计每个月份可以出售的鞋子数量。
如下图所示，第 7 行代表月份，B 列代表鞋子尺码。
表格表示频率分布。

1- 如果我们取鞋子尺码 6（第 8 行），他们计算出的置信区间在 [1.8-4.04] 之间。
据我所知，我知道置信区间仅在正态分布上计算。但我看不出鞋子尺码 6 的分布表如何形成正态分布？
我说得对吗？
我知道，如果样本分布不正常，我们可以使用 CLT，即具有正态分布的样本的平均值。是否可以将其应用于 6 号鞋子（第 8 行）？

2- 为什么要计算标准误差？我以为标准误差仅适用于均值样本（CLT），而第 8 行中的数据不是样本均值，而是正态分布。

此外，标准误差公式的分母代表样本均值的数量，但事实并非如此。
有人可以澄清一下歧义吗？
谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/658015/confidence-interval-clt-beginner-level</guid>
      <pubDate>Fri, 29 Nov 2024 02:32:37 GMT</pubDate>
    </item>
    <item>
      <title>应使用哪种显著性检验来检验均值差异？如何确定？</title>
      <link>https://stats.stackexchange.com/questions/658011/which-significance-test-to-use-for-a-difference-of-means-how-to-be-sure</link>
      <description><![CDATA[我有两个数据集，其中包含这项运动在美国进行的所有官方记录比赛。一个数据集是女子队的，另一个是男子队的。我试图测试男子队是否平均得分更高，我相信他们得分更高。
从数据集中，我将比赛限制为过去二十年的比赛，并且仅限于锦标赛比赛。这给出了大约 200 场比赛的女子样本和大约 300 场比赛的男子样本。我假设比赛在性别内是相互独立的，而不是在性别之间配对的。
然后我合并数据集并添加性别列。因此，这个新数据集有大约 500 行，其中有一列表示该比赛/行是男子比赛还是女子比赛。
我应该选择哪种假设检验，或者现在做出这个选择是否为时过早？
显著性水平：5%
零假设：均值之间没有差异。
备选假设：男性平均得分高于女性平均得分。
我现在在 R 中复制/模拟（？）这个数据集 5000 次，每次计算女性和男性的平均得分，然后取差值。我认为这个差值就是我所谓的检验统计量，我认为所有这 5000 个都可以用来可视化零分布。
在 R 中绘制所有这些差异会显示一个钟形直方图。我相信这是零分布的图，因此假设差异为 0。
因此：观测值是独立的，每组 200 和 300 个样本的数据集足够大，并且检验统计量遵循正态分布。因此，我可以使用非参数方差分析检验来获取 p 值。此检验不要求零分布为正态。但我认为我也可以使用双样本 t 检验，因为事实上，我的底层/零分布是正态的、独立的且较大的。我的想法正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658011/which-significance-test-to-use-for-a-difference-of-means-how-to-be-sure</guid>
      <pubDate>Fri, 29 Nov 2024 00:11:48 GMT</pubDate>
    </item>
    <item>
      <title>具有无限上限的置信区间</title>
      <link>https://stats.stackexchange.com/questions/657947/confidence-interval-with-an-infinity-upper-limit</link>
      <description><![CDATA[因此，我想尝试找到一个具有已知均值的未知分布的方差置信区间（n 非常大）。因此，我首先使用中心极限定理，使得均值为 $\mu$ 且方差为 $\sigma^2$ 的分布 X 具有
$\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}} \xrightarrow{D} N(0,1)$
现在，我们可以找到 1-$\alpha$ 置信区间，其中随机区间为：
$ \begin{align*}
Pr\left(-z_{\frac{\alpha}{2}}&lt;\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}}&lt;z_{\frac{\alpha}{2}}\right) &amp;= 1-\alpha \\
Pr\left(0&lt;\left|\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}}\right|&lt;z_{\frac{\alpha}{2}}\right) &amp;= 1-\alpha \\
Pr\left(0&lt;\left(\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}}\right)^2&lt;z_{\frac{\alpha}{2}}^2\right) &amp;= 1-\alpha \\
Pr\left(0&lt;\frac{(\bar{X}-\mu)^2}{\frac{\sigma^2}{n}}&lt;z_{\frac{\alpha}{2}}^2\right) &amp;= 1-\alpha \\
Pr\left(\frac{1}{z_{\frac{\alpha}{2}}^2}&lt;\frac{\frac{\sigma^2}{n}}{(\bar{X}-\mu)^2}&lt;\infty\right) &amp;= 1-\alpha \\
Pr\left(\frac{n(\bar{X}-\mu)^2}{z_{\frac{\alpha}{2}}^2}&lt;\sigma^2&lt;\infty\right) &amp;= 1-\alpha
\end{align*}$
因此，$\bar{x} = \frac{\sum_{i=1}^n x_i}{n}$，我们有一个 (1-$\alpha$) 置信区间，即 $\left(\frac{n(\bar{x}-\mu)^2}{z_{\frac{\alpha}{2}}^2}, \infty\right)$
这有什么问题吗？如果没有，我们可以为置信区间设置无限上限吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657947/confidence-interval-with-an-infinity-upper-limit</guid>
      <pubDate>Wed, 27 Nov 2024 17:13:58 GMT</pubDate>
    </item>
    <item>
      <title>重复测量数据的降维</title>
      <link>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</link>
      <description><![CDATA[我最近在研究一个重复测量数据集。该研究的目的是观察机构特征 (X) 对由于某种医疗状况 (Y) 导致的几家医疗机构的死亡人数的影响。Y 表示在跨越多年的时间段内每周测量的死亡人数。X 表示在整个研究过程中在多个时间点（每周、每季度、研究开始/结束）测量的连续/分类变量。变量 Y 是零膨胀的，并且由于在模型中包含太多预测因子而导致数值问题。
我的一组 X 变量 (u1、u2、...、un) 与一组其他变量 (v1、v2、...、vn) 相关。这使我无法在同一模型中同时建模 U（总共约 50 个）和 V（总共约 5 个）变量。因此，我对 U 变量进行了建模，并选择了对 Y 有显著影响的 U 变量子集。对于这个子集，我执行了 PCA，并在最终模型中使用了 PCA 分数和 V 变量。我相信这样做可以让它们（U 变量和 V 变量的 PCA 分数）彼此不相关，同时在估计 V 变量时会纳入 U 变量的净效应。
我的最终目标是获得与时间无关的 V 变量预测。
在查看了几个在线资源后，我使用了以下博客文章中建议的方法（使用 phyl.pca 计算新数据的主成分分数和计算单个数据的系统发育 PCA 分数）。简而言之，该方法涉及以下步骤：

均值聚合：通过计算每个变量在时间点的均值来聚合重复测量，即每个个体一行观察值。
降维：对聚合数据应用 PCA 以获得旋转矩阵。
分数计算：使用获得的旋转来计算完整（非聚合）数据集的新分数。

虽然博客文章专门关注系统发育 PCA，但我相信这些概念也适用于标准 PCA。此外，该博客还强调了使用协方差矩阵和相关矩阵执行 PCA 之间的区别。我选择使用协方差矩阵，据我所知，在进行 PCA 之前对数据进行缩放时，通常首选使用协方差矩阵。
下面是我的方法的简化演示：
data(iris) # 出于演示目的，我假设每个类别的“物种”代表一个独特的个体

a &lt;- 聚合（Sepal.Length ~ Species, iris, mean）
b &lt;- 聚合（Sepal.Width ~ Species, iris, mean）
c &lt;- 聚合（Petal.Length ~ Species, iris, mean）
d &lt;- 聚合（Petal.Width ~ Species, iris, mean）

iris_agg &lt;- 合并（merge（merge（a,b,&quot;Species&quot;),c,&quot;Species&quot;),d,&quot;Species&quot;）

iris_agg[-1] &lt;- lapply(iris_agg[-1], function(x) {x &lt;- as.vector(scale(x)); return(x)}) # 在执行 PCA 之前，我缩放了所有变量
iris_agg_pca &lt;- prcomp(iris_agg[-1], center = FALSE, scale. = FALSE)

iris[-5] &lt;- lapply(iris[-5], function(x) {x &lt;- as.vector(scale(x)); return(x)})
data &lt;- as.matrix(iris[-5]) # 删除非数字变量
ev &lt;- as.matrix(iris_agg_pca$rotation)
result &lt;- data %*% ev

虽然我相信这种方法是有效的（如果您不这么认为，请纠正我），但我有一些担忧：

时间点不均等：我的数据集包含在不同时间点测量的个体，我不确定这种方法是否能够适当地处理这个问题。
包含分类变量：在我的数据集中，所有分类变量都只有两个级别。我只是将分类变量编码为零和一，但我不确定这是否合适。

我很感激任何解决这些问题的见解或建议，包括缓解我的担忧的其他替代方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/657901/dimensionality-reduction-for-repeated-measures-data</guid>
      <pubDate>Tue, 26 Nov 2024 20:32:41 GMT</pubDate>
    </item>
    <item>
      <title>使用威布尔分布模拟机器维护发生</title>
      <link>https://stats.stackexchange.com/questions/657626/simulating-machine-maintenance-occurrences-using-weibull-distributions</link>
      <description><![CDATA[我有一组机器，我正在尝试模拟这组机器的维护作业的发生。我有一个适合维护作业发生间隔时间的威布尔分布，对于每台机器，在模拟开始时，我知道距离该机器上一次发生维护作业有多长时间。我想知道的是，给定分布和自上次维护以来的初始时间，如何模拟接下来 $n$ 个时间步长的作业发生情况。我已经确定了几种方法。
方法 1
生存函数 $S(t)$ 给出事件在 $t$ 时间之前未发生的概率。我想计算的是，假设已经过去 $t_0$ 天，机器在第二天需要维护的概率。即
$P(\text{明天维护}|t_{0} \text{自上次维护以来的天数})$。
因此，我想要计算
\begin{align}
P(\text{明天维护}|t_{0} \text{自上次维护以来的天数})=1-\frac{S(t_{0}+1)}{S(t_{0})}
\end{align&gt;
对于每台机器。为了将其纳入 $n$ 时间步长的模拟中，我计算了每台机器设置阈值的概率。然后我使用随机数生成器生成 0 到 1 之间的数字，如果数字低于阈值，则我说事件发生了。如果事件发生，则 $t_{0}$ 重置为 0。如果事件未发生，则我们说 $t_{0}=t_{0}+1$ 并重复计算。我们对所有 $n$ 个时间步执行此操作。
这是一种有效的方法吗？如果不是，我应该做哪些调整？通过计算概率并在每个时间戳使用随机数生成器，我是否人为地增加了说机器需要维护的机会，因为我实际上是多次“从袋子中抽取”，直到得到我想要的结果？
方法 2
我为每台机器的分布抽取随机的生命周期样本。如果该生命周期 $t^{\max}$ 位于模拟的时间范围内，即 $t_{0}+n$，那么我们可以说在 $t^{\max}-t_{0}$ 时该机器上发生了维护工作。我的直觉是这种方法不正确，因为它没有考虑到自每台机器上次维护以来的时间，并且它还不允许在一次模拟长度内对一台机器进行多次维护。
任何有关这些的帮助都将不胜感激。如果这不是正确的论坛，我深表歉意，任何指导都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/657626/simulating-machine-maintenance-occurrences-using-weibull-distributions</guid>
      <pubDate>Thu, 21 Nov 2024 16:13:43 GMT</pubDate>
    </item>
    <item>
      <title>如何重新表示概率向量，而不使其值超出 [0, 1] 的界限？</title>
      <link>https://stats.stackexchange.com/questions/657526/how-to-re-mean-a-vector-of-probabilities-without-having-values-beyond-the-0-1</link>
      <description><![CDATA[假设我们有一个概率向量 $x$。其平均值为 $\bar{x}$。现在，假设我们想将向量重新平均为 0 到 1 之间的任意值。这是某个给定的比例 $p$。
我想要做的是从 $x$ 转到 $x&#39;$，其中 $\bar{x&#39;} = p$。但是，这些表示概率，因此也需要满足 $x&#39; \in [0, 1]$。此外，$x&#39;$ 需要保留 $x$ 的相对排序。
实现此目的的一种方法是简单地降低变量的平均数并重新添加 $p$：
$x&#39; = x - \bar{x} + p$
但是，这会强制值低于 0 或高于 1，因此不再表示概率。
实现此目的的另一种方法是将 $x$ 和 $p$ 都带入逻辑空间，在那里重新定义含义，然后将其带回。为了简便起见，我使用 $logit$ 作为逻辑函数，使用 $invlogit$ 作为其逆函数：
$x&#39; = invlogit(logit(x) - \overline{logit(x)} + logit(p))$
但是，概率空间中的平均值将不再是 $p$。
如何重新表示概率向量，而不使值超出 [0, 1] 的界限？
以下是 R 中的演示。
remean &lt;- function(x, p) x - mean(x) + p

remean_logit &lt;- function(x, p) {
x &lt;- qlogis(x)
x &lt;- x - mean(x) + qlogis(p)
return(plogis(x))
}

set.seed(1839)
p &lt;- .56
x &lt;- runif(1000)

summary(x) # 平均值为 .497
summary(remean(x, p)) # 平均值正确，但最大值 &gt; 1
summary(remean_logit(x, p)) # 值在 0 和 1 之间，但平均值不正确
]]></description>
      <guid>https://stats.stackexchange.com/questions/657526/how-to-re-mean-a-vector-of-probabilities-without-having-values-beyond-the-0-1</guid>
      <pubDate>Tue, 19 Nov 2024 19:56:55 GMT</pubDate>
    </item>
    </channel>
</rss>