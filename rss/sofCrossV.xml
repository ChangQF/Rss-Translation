<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 22 Jul 2024 09:19:49 GMT</lastBuildDate>
    <item>
      <title>如何计算多元回归的 BIC？</title>
      <link>https://stats.stackexchange.com/questions/651518/how-compute-a-bic-for-multivariate-regression</link>
      <description><![CDATA[我想知道是否有可能计算多元回归的 BIC（一个预测因子 X 和 3 个响应结果 Y）。如果可以，如何计算？
在 R 中，当我运行：
M1 &lt;- lm(cbind(Y1, Y2, Y3) ~ X, data = dataset)
M0 &lt;- lm (cbind(Y1, Y2, Y3) ~1, data = dataset)
BIC(M1, M0)

我有以下输出错误：logLik.lm(X[[i]], ...) 中的错误：
&#39;logLik.lm&#39; 不支持多个响应
因此，多元回归有可能有 BIC，如果可以，我如何在 R 上计算 BIC？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/651518/how-compute-a-bic-for-multivariate-regression</guid>
      <pubDate>Mon, 22 Jul 2024 09:13:47 GMT</pubDate>
    </item>
    <item>
      <title>考克斯 PH 上的 Newton-Raphson</title>
      <link>https://stats.stackexchange.com/questions/651517/newton-raphson-on-cox-ph</link>
      <description><![CDATA[我目前正在进行研究，即将传统的优化方法 Newton-Raphson 与 SGD 优化方法在估计 Coxph 参数方面的比较。如果我想使用 Newton Raphson 作为 Coxph 的优化器怎么办？请帮帮我]]></description>
      <guid>https://stats.stackexchange.com/questions/651517/newton-raphson-on-cox-ph</guid>
      <pubDate>Mon, 22 Jul 2024 09:09:34 GMT</pubDate>
    </item>
    <item>
      <title>如何对周度指标进行“显著性”假设检验，对比测试组和对照组？</title>
      <link>https://stats.stackexchange.com/questions/651516/how-to-hypothesis-test-week-over-week-metric-for-significance-contrasting-bet</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651516/how-to-hypothesis-test-week-over-week-metric-for-significance-contrasting-bet</guid>
      <pubDate>Mon, 22 Jul 2024 08:49:20 GMT</pubDate>
    </item>
    <item>
      <title>方差-协方差矩阵的详细计算步骤，用于获取回归系数的方差[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651514/the-detailed-comuptation-steps-of-variance-covariance-matrix-to-get-the-variance</link>
      <description><![CDATA[我不明白方差-协方差矩阵获取逻辑回归回归系数方差的机制。我不熟悉矩阵代数。非常感谢您对这个主题的解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/651514/the-detailed-comuptation-steps-of-variance-covariance-matrix-to-get-the-variance</guid>
      <pubDate>Mon, 22 Jul 2024 08:34:39 GMT</pubDate>
    </item>
    <item>
      <title>评估只能转换训练数据的降维模型</title>
      <link>https://stats.stackexchange.com/questions/651512/evaluating-dimensionality-reductions-models-that-can-only-transform-train-data</link>
      <description><![CDATA[为了评估 TSNE 和 TRIMAP 等降维 (DR) 模型的性能，我做了以下工作：

在训练数据上拟合模型并转换训练数据
在验证数据上拟合新模型并转换验证数据
使用 1-NN 分类器或回归器获得数据缩减的性能分数

原因是 TSNE 和 TRIMAP 等模型无法进行样本外缩减。

有没有更好的方法来评估此类模型？

我注意到的一些缺点是不同的模型可能会旋转或变形数据。在这种情况下，距离的概念不一定是守恒的，因此最近邻居不能很好地衡量性能。]]></description>
      <guid>https://stats.stackexchange.com/questions/651512/evaluating-dimensionality-reductions-models-that-can-only-transform-train-data</guid>
      <pubDate>Mon, 22 Jul 2024 08:08:55 GMT</pubDate>
    </item>
    <item>
      <title>来自自然对数平均值的水平平均值[重复]</title>
      <link>https://stats.stackexchange.com/questions/651511/level-mean-from-natural-logarithm-mean</link>
      <description><![CDATA[假设我有一个随机样本 $X_i$，其中值 $x_i$ 严格为正。我计算变换变量 $t_i = \ln x_i$ 的平均值，即 $\bar{t} = \frac{\sum_{i=1}^n t_i}{n} \approx 9.670$。

相应的水平平均值是多少？它只是 $e^{9.670} \approx 15835.35$ 吗？
如果平均值加权 $\bar{t}_w = \frac{\sum_{i=1}^n w_i t_i}{\sum_{i=1}^n w_i}$，会有什么变化吗？

就我而言，它似乎预测过度。如果我粗略计算 $15835.35 \cdot n$，我得到的总和会比总和大得多。]]></description>
      <guid>https://stats.stackexchange.com/questions/651511/level-mean-from-natural-logarithm-mean</guid>
      <pubDate>Mon, 22 Jul 2024 08:03:10 GMT</pubDate>
    </item>
    <item>
      <title>请帮忙！AR(1) 协方差推导查询</title>
      <link>https://stats.stackexchange.com/questions/651510/pls-help-ar1-covariance-derivation-query</link>
      <description><![CDATA[
有人能解释一下为什么在推导 AR(1) 的自协方差时可以这样做吗？
为什么他们只能在 μ 前面加一个 $\phi$ ？难道不应该是：$\phi y_{t-1} + \epsilon_t - \mu$
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/651510/pls-help-ar1-covariance-derivation-query</guid>
      <pubDate>Mon, 22 Jul 2024 07:58:26 GMT</pubDate>
    </item>
    <item>
      <title>有偏差的基于物理的模型及其 ML 校正版本的公平比较方法</title>
      <link>https://stats.stackexchange.com/questions/651508/fair-comparison-method-for-a-biased-physics-based-model-and-its-ml-correction-ve</link>
      <description><![CDATA[我正在使用两个预测模型：

一个经过校准的基于物理的模型，该模型始终高估并且具有固定偏差。
一个 XGBoost 模型，该模型预测物理模型的误差以创建校正预测。（数据集包含物理模型的预测和目标变量。然后我们预测目标变量和物理模型预测之间的误差）

我正在尝试公平地比较这些模型，但我不确定最佳方法。由于物理模型中存在已知偏差，因此简单地对两者使用 MAPE 似乎没有意义。
这是我正在考虑的：
对于物理模型：

计算误差：errors = physics_model_prediction - actual_value
计算平均误差：mean_error = errors.mean()
调整误差：adjusted_errors = errors - mean_error
计算 MAPE：MAPE(adjusted_errors, actual_value)

对于校正模型：

计算 MAPE(corrected_prediction, actual_value)

这种方法有效吗？校正模型中的残差分布略有偏差，但接近正态分布，在某些值上倾向于高估。但我想知道这种方法在统计上是否合理。如果有更好的方法来比较改进，我将不胜感激！


]]></description>
      <guid>https://stats.stackexchange.com/questions/651508/fair-comparison-method-for-a-biased-physics-based-model-and-its-ml-correction-ve</guid>
      <pubDate>Mon, 22 Jul 2024 07:17:33 GMT</pubDate>
    </item>
    <item>
      <title>如何增加 MCC 中的假阴性权重？</title>
      <link>https://stats.stackexchange.com/questions/651502/how-to-increase-weight-of-false-negatives-in-mcc</link>
      <description><![CDATA[我正在研究一种能够预测糖尿病前期和糖尿病的多类别分类模型。我目前使用马修斯相关系数 (MCC) 作为评估的主要指标。但是，我想增加 MCC 中假阴性相对于假阳性的权重，因为在糖尿病分类中，最小化假阴性比减少假阳性更有价值。
我目前正在考虑两种不同的方法来实现这一目标：

修改 MCC 的公式，以增加假阴性相对于假阳性的权重。

$$
\text{Weighted_MCC} = \frac{
c \times s - \sum_{k}^{K} (p_k \times \text{fp_weight}) \times (t_k \times \text{fn_weight})
}{\sqrt{
(s^2 - \sum_{k}^{K} (p_k \times \text{fp_weight})^2) \times
(s^2 - \sum_{k}^{K} (t_k \times \text{fn_weight})^2)
}}
$$

通过几何平均值或调和平均值将 MCC 与另一个关注假阴性的指标（如召回率或 f2 分数）相结合。

哪种方法更好？]]></description>
      <guid>https://stats.stackexchange.com/questions/651502/how-to-increase-weight-of-false-negatives-in-mcc</guid>
      <pubDate>Mon, 22 Jul 2024 04:30:43 GMT</pubDate>
    </item>
    <item>
      <title>分类规则</title>
      <link>https://stats.stackexchange.com/questions/651501/classification-rule</link>
      <description><![CDATA[在分类中，MAP（最大后验概率）规则、最小误分类规则和贝叶斯决策规则之间有什么区别吗？据我所知，这三个规则似乎都是根据最大后验概率对新实例进行分类。那么它们可以互换吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651501/classification-rule</guid>
      <pubDate>Mon, 22 Jul 2024 02:33:12 GMT</pubDate>
    </item>
    <item>
      <title>梯度提升会单调地减少误差吗？</title>
      <link>https://stats.stackexchange.com/questions/651500/will-gradient-boosting-monotonically-decrease-error</link>
      <description><![CDATA[我仍在努力理解梯度提升回归，特别是 xgboost，并且试图理解是否保证每个步骤在后续迭代中产生较小的残差。如果我们保证单调地减少损失函数，那么是在每个样本级别（即样本 i 的伪残差保证在每次迭代后对所有 i 都减少）还是所有 i 的平方误差之和保证减少？
我的想法是，由于损失函数是所有平方误差之和，我们正在将其最小化，但不能保证每个样本残差在每次迭代中都会下降。我试图想出一种情况，您可以添加一棵新树，它实际上会增加误差之和（例如，如果您的回归树非常差）。我不知道是否存在新树对伪残差的预测非常差以至于实际上会增加误差的情况。]]></description>
      <guid>https://stats.stackexchange.com/questions/651500/will-gradient-boosting-monotonically-decrease-error</guid>
      <pubDate>Mon, 22 Jul 2024 02:22:52 GMT</pubDate>
    </item>
    <item>
      <title>关联后要采取的数据分析步骤[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651498/data-analysis-steps-to-take-after-correlation</link>
      <description><![CDATA[我的假设是，经济不平等与犯罪率呈显著正相关。为了验证这一点，我拥有县级各种犯罪类型的犯罪率和各种收入等级的人口百分比。我的数据集是 1,441 个县、每个县的犯罪和收入等级数据、各种收入比率（最高等级与最低等级、前 2 个等级与后 2 个等级等）以及每个县的基尼指数。我有 2018-2022 年的数据。
我用两种方法测试了我的假设。
首先，我使用 Pearson 的乘积矩、Kendall 的 Tau 和 Spearman 的 Rho 测试了基尼指数与各种犯罪类型率之间的相关性。鉴于犯罪率不呈正态分布，并且我的 n 很大，Spearman 的 Rho 是最合适的。我使用其他两个进行稳健性检验。结果证明存在非常弱的正相关关系。 Pearson 的结果表明，各种犯罪类型的相关性为 .10 &lt; r &lt; .27 (p &lt; .001)，而 Kendall 和 Spearman 的结果表明，r 和 p &gt; .10 均较低。
其次，我使用 Spearman 的 Rho 检验了各种收入阶层的百分比和收入比率与各种犯罪类型的比率之间的相关性。这些比率没有提供明确的见解 - 它们的 r 几乎总是小于 .20。然而，特定犯罪类型的比率似乎与经济不平等有某种关联。
例如，在我所有五年的数据中，最低收入阶层的人口百分比与入室盗窃/破门行窃率之间的相关性约为。 r = .32，犯罪率与最高收入阶层人口百分比的相关性约为 r = -.15。一般来说，犯罪率与中等收入阶层百分比之间的相关性接近于零（几乎所有的 p &lt; .001）。这表明，随着各县贫困或富裕家庭的集中度增加（取决于犯罪情况），某些类型的犯罪率将趋于上升或下降。这支持了我的假设，即收入不平等与至少某些犯罪率呈显着正相关。
我的问题是：我的下一步统计分析是什么？回归分析、方差分析、更多的稳健性检验？报告我的发现的最佳实践？任何建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/651498/data-analysis-steps-to-take-after-correlation</guid>
      <pubDate>Mon, 22 Jul 2024 00:08:55 GMT</pubDate>
    </item>
    <item>
      <title>使用多重比较校正和复合 DV</title>
      <link>https://stats.stackexchange.com/questions/651491/use-of-multiple-comparison-correction-and-composite-dv</link>
      <description><![CDATA[我正在研究单个 X 对复合 DV Y 的影响。我还想研究 X 对 Y 的 36 个子成分的影响。因此，我必须运行 37 个多元回归模型，特别是具有稳健聚类 SE 和年份 FE 的池化 OLS。X 是时不变的，所以我不能包括国家 FE。
我明白我应该校正多重比较，我打算使用 BH 校正。我的问题是，我是否应该调整所有模型，包括复合 Y 是 DV 的主模型？要清楚，这是一个条件过程：只有当 X 在主模型中显著时，才会针对子成分进行测试。
我很困惑，因为我确实调整了主模型的 p 值，但校正后主模型中的 X 并不显著。然而，X 对很多子成分来说都是显著的。我知道在看到不利结果时质疑模型是不科学的，但如果 X 在主模型中的初始显著影响可归因于噪音，我很难解释结果。
总而言之，我有两个问题：

如果我有一个条件过程，只有当 X 在主模型中具有显著影响时才会运行更多模型，是否需要调整主模型的 p 值以进行多重比较？如果我有一个条件过程，测试是否仍被视为同时进行的？
如果需要调整，我该如何解决由于初始效果显著而需要调整的悖论，但初始效果在调整后变得不显著，因此无需进一步测试并因此进行调整？

任何建议都值得赞赏。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651491/use-of-multiple-comparison-correction-and-composite-dv</guid>
      <pubDate>Sun, 21 Jul 2024 20:05:43 GMT</pubDate>
    </item>
    <item>
      <title>对于变量误差模型有什么好的介绍吗？</title>
      <link>https://stats.stackexchange.com/questions/651471/what-is-a-good-introduction-to-errors-in-variables-models</link>
      <description><![CDATA[我知道这个资源https://en.wikipedia.org/wiki/Errors-in-variables_models，但我不太相信维基百科上关于统计的文章，所以我正在寻找一些关于这个主题的可靠参考资料（最好是学术参考资料）。如果它能帮助我提出一些建议，我已经熟悉标准回归模型，对混合模型也有点了解。
你有什么好的建议吗？如果它只是教科书中的一章，只要它涵盖基础知识并（理想情况下）建议进一步的资源，我就会感兴趣。
理想情况下，我正在寻找最近的资源。我要求最近的资源是因为我担心太旧的资源可能会过时，或者可能会错过该主题的重要最新发展。但是，如果您知道很棒的旧资源，我会很感兴趣，但在这种情况下，知道他们可能错过了哪些有关最新发展的信息会很棒。谢谢，]]></description>
      <guid>https://stats.stackexchange.com/questions/651471/what-is-a-good-introduction-to-errors-in-variables-models</guid>
      <pubDate>Sun, 21 Jul 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>统计独立测试/测量的综合可靠性</title>
      <link>https://stats.stackexchange.com/questions/651462/combined-reliability-for-statistically-independent-tests-measurements</link>
      <description><![CDATA[我对维基百科文章“一致性”中的这句话感到困惑：
“从统计学上讲，如果三个不同的测试在给出阳性结果时，每个测试的可靠性为 90%，则所有三个测试的阳性结果的可靠性为 99.9%；五个这样的测试的可靠性为 99.999%，依此类推。这要求测试在统计上是独立的，类似于测量方法中对独立性的要求。”

这些可靠性百分比是如何计算的？例如，如果 4 个独立测试的可靠性不同，比如 77%、88%、90% 和 93%，那么它们的组合可靠性是多少？

这种现象的统计术语是什么？


谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651462/combined-reliability-for-statistically-independent-tests-measurements</guid>
      <pubDate>Sat, 20 Jul 2024 23:04:07 GMT</pubDate>
    </item>
    </channel>
</rss>