<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 19 Jan 2025 06:21:25 GMT</lastBuildDate>
    <item>
      <title>为什么在 OLS 中复制数据集会导致参数方差减少 1/2？</title>
      <link>https://stats.stackexchange.com/questions/660225/why-does-duplicating-a-dataset-reduce-the-variance-of-parameter-by-1-2-in-ols</link>
      <description><![CDATA[假设我在数据集 $D$ 和线性回归模型 $y = \beta_0 + \beta_1x + \epsilon$ 上运行 OLS。如果我现在复制数据集以获得 $D&#39;$ 并再次运行 OLS，我会得到 $y = \beta_0&#39; + \beta_1&#39;x + \epsilon$。
根据我的直觉理解，$Var(\beta_1&#39;) = \frac{1}{2} Var(\beta_1)$。但是，我在数学上很难解决这个问题。
设 $S_{XX} = \sum (x_i - \bar{x})^2$，我们知道 $Var(\beta_1) = \frac{\sigma^2}{S_{XX}}$ 和 $\sigma^2 = \frac{SSE}{n-2}$，所以
$$Var(\beta_1) = \frac{1}{(n-2)}\frac{SSE}{S_{XX}} $$
如果我们复制数据集中的每个点，我们有 $S_{XX}&#39; = 2S_{XX}$ 和 $SSE&#39; = 2*SSE$ - 这一切对我来说都很有意义。问题是，如果我们复制数据集，我们现在有 $2n$ 个点，所以自由度不会恰​​好翻倍，因为它是 $2n-2 \neq 2(n-2)$。如果我对此的理解不正确，请告诉我。这导致以下内容：
$$Var(\beta_1&#39;) = \frac{2*SSE}{(2n-2)*2S_{XX}} = \frac{1}{2n-2}\frac{SSE}{S_{XX}} &lt; \frac{1}{2(n-2)}\frac{SSE}{S_{XX}} = \frac{1}{2}Var(\beta_1)$$
我知道如果 $n$ 变得非常大，那么 $\frac{1}{2n-2} \approx \frac{1}{2(n-2)}$，但除了这个（或者可能是我推导中的错误）之外，还有什么合理的解释可以解释为什么在复制数据集后，估计值 $\beta_1$ 的方差不完全是 1/2？]]></description>
      <guid>https://stats.stackexchange.com/questions/660225/why-does-duplicating-a-dataset-reduce-the-variance-of-parameter-by-1-2-in-ols</guid>
      <pubDate>Sun, 19 Jan 2025 06:09:32 GMT</pubDate>
    </item>
    <item>
      <title>哈默斯利·克利福德定理的两个版本</title>
      <link>https://stats.stackexchange.com/questions/660224/two-versions-of-the-hammersley-clifford-theorem</link>
      <description><![CDATA[在学习蒙特卡罗方法时，我了解到完整条件$P(x_j \mid x_1, \ldots, x_{j-1}, x_{j+1}, \ldots, x_p)$在某些条件下决定联合分布。这个结果是使用书中所谓的 Hammersley-Clifford 定理（如下所述）证明的，但我注意到他们使用的形式与我在马尔可夫网络背景下熟悉的形式非常不同。

Hammersley-Clifford 定理（来自书中）
让 $(X_1, \ldots, X_p)$ 满足正性条件并具有联合密度 $f(x_1, \ldots, x_p)$。然后，对于所有 $(\xi_1, \ldots, \xi_p) \in \operatorname{supp}(f)$:
$$
f(x_1, \ldots, x_p) \propto \prod_{j=1}^p \frac{f_{X_j \mid X_{-j}}(x_j \mid x_1, \ldots, x_{j-1}, \xi_{j+1}, \ldots, \xi_p)}{f_{X_j \mid X_{-j}}(\xi_j \mid x_1, \ldots, x_{j-1}, \xi_{j+1}, \ldots, \xi_p)}。
$$

Hammersley-Clifford 定理（针对马尔可夫网络）
设 $P$ 为 $\mathcal{X}$ 上的正分布，$\mathcal{H}$ 为 $\mathcal{X}$ 上的马尔可夫网络图。如果 $\mathcal{H}$ 是 $P$ 的 I-map（即 $\mathcal{H}$ 的马尔可夫独立性作为 $P$ 中的概率独立性成立），则 $P$ 是对 $\mathcal{H}$ 进行因式分解的吉布斯分布。
因式分解意味着 $P$ 是通过因子 $\Phi = \{\phi_1(\boldsymbol{D}_1), \ldots, 参数化的吉布斯分布\phi_K(\boldsymbol{D}_K)\}$:
$$
P_{\Phi}(X_1, \ldots, X_n) = \frac{1}{Z} \prod_{k=1}^K \phi_k(\boldsymbol{D}_k),
$$
其中 $Z$ 是规范化常数，每个 $\boldsymbol{D}_k$ 对应于 $\mathcal{H}$ 的一个完整子图（团）。

我的问题是，Hammersley-Clifford 定理的这两个陈述是如何联系在一起的？它们是具有相同名称但本质上不同的定理吗，或者是否有办法从另一个定理中证明一个定理（尤其是从第二个定理中证明第一个定理）？]]></description>
      <guid>https://stats.stackexchange.com/questions/660224/two-versions-of-the-hammersley-clifford-theorem</guid>
      <pubDate>Sun, 19 Jan 2025 04:44:17 GMT</pubDate>
    </item>
    <item>
      <title>重要性抽样最优解的存在性</title>
      <link>https://stats.stackexchange.com/questions/660221/existence-of-optimum-of-importance-sampling</link>
      <description><![CDATA[众所周知，为了估计 $\mathbb E_{p(x)}[f(x)] = \int p(x) f(x)\,\mathrm dx$，我们可以对提议分布 $q(x)$ 使用重要性抽样。Wiki 声称最佳 $q$ 的形式为：$q(x) \propto p(x) |f(x)|$，并且归一化常数为 $\int p(x) |f(x)|\,\mathrm dx$。但是，可积性并不意味着绝对可积性，因此$\int p(x) |f(x)|\,\mathrm dx$可能不存在。在这种情况下，最优的$q(x)$是什么？非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660221/existence-of-optimum-of-importance-sampling</guid>
      <pubDate>Sun, 19 Jan 2025 03:46:07 GMT</pubDate>
    </item>
    <item>
      <title>R 中的可视化包含太多数据点吗？</title>
      <link>https://stats.stackexchange.com/questions/660219/visualizations-in-r-with-too-many-data-points</link>
      <description><![CDATA[我在 R 中有多个变量的模拟数据：
set.seed(123)
n &lt;- 100
x1 &lt;- rnorm(n, mean = 50, sd = 10)
x2 &lt;- x1 * 0.7 + rnorm(n, mean = 0, sd = 5)
x3 &lt;- -x1 * 0.5 + rnorm(n, mean = 70, sd = 8)
x4 &lt;- rnorm(n, mean = 40, sd = 15)
x5 &lt;- x4 * 0.6 + rnorm(n, mean = 30, sd = 7)

data &lt;- data.frame(
Variable1 = x1,
Variable2 = x2,
Variable3 = x3,
Variable4 = x4,
Variable5 = x5
)

数据$Group &lt;- cut(data$Variable1, 
breaks = 3, 
labels = c(&quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;))

然后我制作了这个可视化（平行坐标图），因为这是唯一一种可以用多个变量完成的可视化类型（据我所知）：
library(GGally)

ggparcoord(data = data,
columns = 1:5,
groupColumn = &quot;Group&quot;,
scale = &quot;uniminmax&quot;,
showPoints = TRUE,
alphaLines = 0.3,
title = &quot;模拟数据的平行坐标图&quot;) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = &quot;bold&quot;),
axis.text.x = element_text(angle = 45, hjust = 1)
) +
scale_color_brewer(palette = &quot;Set2&quot;)


我有以下问题：假设我有很多行数据。有什么办法可以让视觉效果保持完整，而不会太过拥挤？
我唯一想到的想法是使用随机抽样从原始数据集中创建一个较小的数据集，但我正在寻找其他想法。例如，是否可以对彼此非常相似的轨迹进行聚类，从而减少线条数量？（并使线条较多的轨迹的颜色更深）]]></description>
      <guid>https://stats.stackexchange.com/questions/660219/visualizations-in-r-with-too-many-data-points</guid>
      <pubDate>Sun, 19 Jan 2025 01:41:53 GMT</pubDate>
    </item>
    <item>
      <title>重建 CNN 架构</title>
      <link>https://stats.stackexchange.com/questions/660218/recreating-a-cnn-architecture</link>
      <description><![CDATA[我正尝试重新创建一个 CNN 架构，该架构可根据历史路径预测未来轨迹。该实现在本文的第 2.3 和 2.4 节中定义。我的数据是 (纬度,经度) 序列。根据论文，我已将架构设置如下：
def create_trajectory_cnn(
input_sequence_length=8, # len 输入轨迹 def by paper
input_features=2, # 纬度/经度坐标
embedding_dim=32, # 嵌入维度
n_future_steps=12, # 未来位置编号
n_conv_layers=4, # 卷积层编号
kernel_size=3, # 内核大小
dropout_rate=0.1 # 正则化
):
输入 = 输入(shape=(input_sequence_length, input_features))
# 嵌入层将坐标转换为固定大小表示
x = Dense(embedding_dim)(inputs)
for i in range(n_conv_layers):
x = Conv1D(
过滤器=embedding_dim，
kernel_size=kernel_size，
padding=&#39;same&#39;，
激活=&#39;relu&#39;，
名称=f&#39;conv_{i+1}&#39;
)(x)
x = BatchNormalization(名称=f&#39;batch_norm_{i+1}&#39;)(x) 
x = Dropout(dropout_rate，名称=f&#39;dropout_{i+1}&#39;)(x)

x = Flatten()(x)

output_dim = n_future_steps * input_features
输出 = Dense(output_dim)(x)
输出 = Reshape((n_future_steps，input_features))(输出)

模型 = 模型(输入=输入，输出=输出)
模型.编译(
优化器=tf.keras.optimizers.Adam(learning_rate=0.001)，
损失=&#39;mse&#39; # l2
)

返回模型

到目前为止，我试图获得稍微不错的结果的尝试都失败了，这让我相信我的架构存在缺陷。基于这些部分，我的实现有什么问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660218/recreating-a-cnn-architecture</guid>
      <pubDate>Sat, 18 Jan 2025 23:25:53 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证：多层次模型的研究问题是：影响实践的因素有哪些？</title>
      <link>https://stats.stackexchange.com/questions/660216/cross-validation-multilevel-model-with-the-research-question-what-are-the-fact</link>
      <description><![CDATA[有人建议我在这个平台上使用多级建模进行数据分析。该模型说明了数据结构和我的研究的理论框架。因此，我认为它很合适。
这是一个研究变量的模型：
model &lt;- glmer(
Practice ~ Zone + Age + Gender + Education + Employenment + (1 | HouseID),
data = OshingaliMLM,family = binomial(link = &quot;logit&quot;),nAGQ = 0

)

以下是该模型的结果：
&gt; summary(model)
通过最大似然拟合的广义线性混合模型（自适应高斯-埃尔米特求积法，nAGQ =
0）[glmerMod]
家庭：二项式（logit）
公式：实践 ~ 区域 + 年龄 + 性别 + 教育 + 就业 + (1 | HouseID)
数据：OshingaliMLM

AIC BIC logLik 偏差 df.resid 
269.8 322.0 -121.9 243.8 396 

缩放残差：
最小 1Q 中位数 3Q 最大 
-3.07372 -0.10274 0.03619 0.18277 2.23432 

随机效应：
组名称方差标准差。
HouseID（截距）19.88 4.459

观察数：409，组：HouseID，120

固定效应：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 0.99931 3.02924 0.330 0.74149 
ZoneRemote 农村 1.55626 1.85192 0.840 0.40071 
ZoneRural 0.01747 1.79316 0.010 0.99223 
ZoneUrban -6.14909 2.14979 -2.860 0.00423 ** 
年龄 0.01961 0.03028 0.648 0.51726 
性别男性 -6.52123 0.83623 -7.798 6.27e-15 ***
教育小学1.78766 1.27288 1.404 0.16019 
教育 中学 2.79713 1.32090 2.118 0.03421 * 
教育 高等教育 3.60507 1.91254 1.885 0.05943 . 
就业 学习者 1.68585 2.14170 0.787 0.43119 
就业 养老金领取者 -0.42052 2.11747 -0.199 0.84258 
就业 失业者 1.95405 1.84108 1.061 0.28853 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

固定效应的相关性：
（内部）ZnRmtr ZonRrl ZnUrbn Age GndrMl EdctnP EdctnS EdctnT EmplyL EmplyP
ZoneRemtrrl -0.423 
ZoneRural -0.439 0.761 
ZoneUrban -0.468 0.593 0.634 
Age -0.531 0.028 0.065 -0.006 
GenderMale -0.015 -0.053 -0.017 0.284 -0.056 
EductnPrmry -0.408 0.069 0.027 -0.001 0.089 -0.210 
EdctnScndry -0.455 0.056 -0.018 -0.058 0.157 -0.222 0.860 
EductnTrtry -0.493 0.034 -0.020 -0.128 0.141 -0.249 0.573 0.636 
EmplynmntLn -0.693 -0.076 -0.061 0.075 0.447 -0.107 0.008 0.129 0.404 
EmplynmntPn -0.327 -0.085 -0.110 0.140 -0.397 0.064 0.128 0.164 0.331 0.540 
EmplynmntUn -0.611 -0.077 -0.073 0.062 0.188 -0.169 0.065 0.108 0.396 0.899 0.700
&gt; 

研究问题是，哪些因素影响了实践？
从结果来看，城市区域和性别是影响实践的关键因素。
模型中使用的分析单位是家庭和个人。对吗？
我还想确认该模型是否正确和完整，因为它与我的研究问题有关，因为我将使用此示例作为评估其余 23 个变量的基础。]]></description>
      <guid>https://stats.stackexchange.com/questions/660216/cross-validation-multilevel-model-with-the-research-question-what-are-the-fact</guid>
      <pubDate>Sat, 18 Jan 2025 22:20:05 GMT</pubDate>
    </item>
    <item>
      <title>INLA 中的贝叶斯套索</title>
      <link>https://stats.stackexchange.com/questions/660214/bayesian-lasso-in-inla</link>
      <description><![CDATA[我正在寻找一种方法来实现贝叶斯套索，以便在 INLA 的空间模型 (BYM2) 中进行变量选择。我找不到任何讨论在 INLA 中实现贝叶斯套索的文章，更不用说空间模型了。有什么线索吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660214/bayesian-lasso-in-inla</guid>
      <pubDate>Sat, 18 Jan 2025 21:19:07 GMT</pubDate>
    </item>
    <item>
      <title>交叉熵损失的方差是什么意思？</title>
      <link>https://stats.stackexchange.com/questions/660198/what-is-the-meaning-of-the-variance-of-cross-entropy-loss</link>
      <description><![CDATA[通常我们用所有测试集的交叉熵损失的平均值作为指标，那我们可以用交叉熵损失的方差作为指标吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660198/what-is-the-meaning-of-the-variance-of-cross-entropy-loss</guid>
      <pubDate>Sat, 18 Jan 2025 12:21:24 GMT</pubDate>
    </item>
    <item>
      <title>需要有关时间序列分析中使用的数据的帮助</title>
      <link>https://stats.stackexchange.com/questions/660195/need-help-regarding-the-data-used-in-time-series-analysis</link>
      <description><![CDATA[我是时间序列的初学者。我试图通过获取过去 10 年的月度数据来预测棉花作物的价格。但价格数据仅适用于 1 月至 5 月，然后是 11 月和 12 月。由于棉花在这里是季节性作物，因此没有其他月份的市场数据。那么在这种情况下，我该如何进行时间序列分析，以及我应该使用多少个最小数据点来运行模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/660195/need-help-regarding-the-data-used-in-time-series-analysis</guid>
      <pubDate>Sat, 18 Jan 2025 10:11:48 GMT</pubDate>
    </item>
    <item>
      <title>当响应变量是“一年中的某一天”时，应使用哪种回归模型</title>
      <link>https://stats.stackexchange.com/questions/660197/which-regression-model-to-use-when-response-variable-is-day-of-the-year</link>
      <description><![CDATA[我有一个检测数据集，其中包含一年中被标记动物被重新检测到的天数（即 1 - 365），该天数是在它之前被释放的地点（即 release_location）被重新检测到的。有来自五个不同释放地点的多只被标记的动物，有些动物在被释放后的多年内被重新检测到（即 redetection_year）。示例数据（实际数据集要大得多）：
redetection_year&lt;-c(2,3,2,4,5,3,4,2,5)
redetection_day&lt;-c(25,66,340,129,12,67,200,36,248)
animal_id&lt;-c(1,1,2,3,3,4,4,4,4)
release_location&lt;-c(&quot;A&quot;,&quot;A&quot;,&quot;A&quot;,&quot;B&quot;,&quot;B&quot;,&quot;A&quot;,&quot;A&quot;,&quot;A&quot;)
df&lt;-data.frame(animal_id, release_location, redetection_day, redetection_year)

我想要在 R 中运行模型，以测试释放位置和重新检测年份（预测变量）是否预测重新检测日期（即 1-365）（响应变量）。这可以通过线性回归来实现吗？还是因为响应变量的格式而需要考虑？即它只从 1 到 365，它是循环的。
我读过一些关于 Tobit 回归的文章，这些回归适用于响应变量被审查的情况，以及许多关于当它是预测变量时如何使用“天”变量的示例，但我找不到适合我的问题的解决方案。]]></description>
      <guid>https://stats.stackexchange.com/questions/660197/which-regression-model-to-use-when-response-variable-is-day-of-the-year</guid>
      <pubDate>Sat, 18 Jan 2025 08:51:33 GMT</pubDate>
    </item>
    <item>
      <title>如何用 SE 和 P 值计算每 100,000 个比率之间的差异</title>
      <link>https://stats.stackexchange.com/questions/660173/how-to-calculate-the-difference-between-2-rates-per-100-000-with-se-and-p-value</link>
      <description><![CDATA[我有一个数据集，其中包含每年记录的每 100,000 人口年龄调整死亡率及其针对特定疾病的标准误差 (SE)。数据来自 CDC Wonder 数据库。
我旨在通过计算差异、构建置信区间 (CI) 和确定此差异的 p 值来比较两个特定年份之间的死亡率。
此外，我旨在通过以下方式计算相对比率变化：
$$
\text{相对变化} = \frac{(\text{第 2 年比率} - \text{第 1 年比率})}{\text{第 2 年比率}}
$$
这在统计上合适吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/660173/how-to-calculate-the-difference-between-2-rates-per-100-000-with-se-and-p-value</guid>
      <pubDate>Fri, 17 Jan 2025 16:46:06 GMT</pubDate>
    </item>
    <item>
      <title>针对 2 个以上类别的卡方检验（2x5 列联表）</title>
      <link>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</link>
      <description><![CDATA[我有一个 2x5 的频率表，其中有 2 列分别名为男性和女性，5 行分别名为病理 A、B、C、D 和 E。
我想确定不同病理类别的性别比例是否存在统计学差异。
例如：男性是否比女性更频繁地受到病理 A 的影响（每个类别都是如此）？
我是否可以将其他类别（例如 B + C + D + E）相加以创建新的 2x2 列联表并对其进行卡方检验？
这在统计上正确吗？如果我的 p 值小于 0.05，我可以得出的结论是：男性比女性更频繁地受到病理 A 的影响？
问题是，如果我对所有数据计算一次卡方检验，我只能对情况有一个整体了解。

感谢大家的回复。实际上，我的不同类别如下：
列：男性和女性
行：A = 无病理（健康患者），B = β-地中海贫血，C = α-地中海贫血，D = db-地中海贫血，E = 其他。
患者只能属于五个类别之一，因为他们被诊断出患有相同的测试。因此，它们是互斥的。
最初，我创建了 5 个 2x2 列联表，如我在第一篇文章中所述，并将其视为二元变量（如 Rick 所述，存在或不存在），但我不确定我能从中得出什么结论，以及将一些类别组合在一起以评估特定类别的频率在两性之间是否存在显着差异是否在统计上正确。
我不一定想计算比值比，只是想知道根据卡方检验，我的病理分布在男性还是女性中更常见。
感谢您的所有回复。我期待阅读您的结论。
此致，
Adrien]]></description>
      <guid>https://stats.stackexchange.com/questions/660160/chi-square-test-for-more-than-2-categories-2x5-contingency-table</guid>
      <pubDate>Fri, 17 Jan 2025 12:27:50 GMT</pubDate>
    </item>
    <item>
      <title>加权交叉熵的理论依据</title>
      <link>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</link>
      <description><![CDATA[假设我们正在构建一个二元分类模型，可以将其视为学习函数
$$ p : X \mapsto [0, 1] $$
其中$p(X) := \mathbb{P}(Y=1|X)$，而$\hat{p}$是某种机器学习模型（例如神经网络）。
常用的损失函数是最小化$p$和$\hat{p}$之间的负交叉熵：
$$ l(p, \hat{p}) = -y\log \hat{p}(x) - (1-y)\log(1-\hat{p}(x))$$
这当然相当于模型$Y|X \sim Bernoulli(p(X))$的最大似然估计。
在某些情况下，结果高度不平衡，这使得训练在实践中变得困难。例如，如果数据是垃圾邮件分类，其中只有 1% 的结果是垃圾邮件，那么很容易收敛到一个简单的解决方案/局部最优，它只为每个观察设置$p(X) \approx 0$。理论上，在大样本量和全局最优的情况下，这不是问题 - 但在实践中，这可能是一个大问题。
解决这个问题的一种常见方法是使用“加权交叉熵”损失，其中权重与观察到的频率成比例。例如，
$$w_0 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=0\}}, w_1 = \frac{n}{2\sum_{i=1}^{n} \mathbf{1}\{Y_i=1\}} $$
损失为
$$ l^{weighted}(p, \hat{p}) = -w_1y\log\hat{p}(x) - w_0(1-y)\log(1-\hat{p}(x)) $$
其中直觉是稀有类别的权重更高，因此模型“更加关注”对这些观察结果。

通过最小化这个加权损失函数找到的最优函数 $\hat{p}^{weighted}$ 是否有任何已知的理论性质，还是纯粹是启发式的？在全局最优值中，最优 $\hat{p}$ 和 $\hat{p}^{weighted}$ 相比如何？]]></description>
      <guid>https://stats.stackexchange.com/questions/660153/theoretical-justification-of-weighted-cross-entropy</guid>
      <pubDate>Fri, 17 Jan 2025 09:25:45 GMT</pubDate>
    </item>
    <item>
      <title>日食是否减少了新冠肺炎死亡人数？</title>
      <link>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</link>
      <description><![CDATA[我在 R 中模拟了一些现实数据，这些数据显示了 Covid-19 死亡人数随时间的变化情况，以及日食（2024 年 4 月 8 日）发生前的天数：

如果有人不太了解，仅从数据来看，可能会认为日食是降低 Covid 死亡人数的原因。此外，有人可以拟合回归模型，该模型甚至可能很好地拟合数据。
我读到过，我们在统计学中拥有所有这些复杂的技术，例如差异-差异、回归不连续性、合成控制、工具变量、倾向得分匹配等 - 所有这些方法旨在在某种程度上找出我们是否能够真正得出结论，统计模型的结果忠实地代表了自然（例如因果关系与联想关系）。
但在某种程度上，我们在决定将哪些变量纳入统计模型时是否只是使用常识？]]></description>
      <guid>https://stats.stackexchange.com/questions/660144/did-the-solar-eclipse-reduce-covid-19-deaths</guid>
      <pubDate>Fri, 17 Jan 2025 05:13:01 GMT</pubDate>
    </item>
    <item>
      <title>对序数、相关特征进行降维，并附加连续特征</title>
      <link>https://stats.stackexchange.com/questions/660005/dimension-reduction-on-ordinal-related-features-with-additional-continuous-feat</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660005/dimension-reduction-on-ordinal-related-features-with-additional-continuous-feat</guid>
      <pubDate>Tue, 14 Jan 2025 13:26:13 GMT</pubDate>
    </item>
    </channel>
</rss>