<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 22 May 2024 06:20:24 GMT</lastBuildDate>
    <item>
      <title>解释百分比回归系数</title>
      <link>https://stats.stackexchange.com/questions/647736/intepreting-regression-coefficients-in-percentage</link>
      <description><![CDATA[考虑一个简单的线性模型
$$ Y = \alpha + \beta X + \epsilon $$
假设 $\bar{Y} = 10，\hat{\beta} = 2$。标准解释是，$X$ 增加一个单位，那么我们预计结果平均会增加两个单位。
但我们假设将 $\hat{\beta}$ 解释为 $\hat{\beta}$ 的百分比变化会提供更多信息。容器&quot;&gt;$Y$。除了日志转换之外，还有什么想法吗？
注意：由于识别问题，日志转换在此上下文中不合适。我们根本无法触及回归模型。解释不必是精确的，只需近似即可。但我不确定说 $\hat{\beta} \approx 20\%$ 是否是执行此操作的最佳方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/647736/intepreting-regression-coefficients-in-percentage</guid>
      <pubDate>Wed, 22 May 2024 05:17:21 GMT</pubDate>
    </item>
    <item>
      <title>字符串概率算法</title>
      <link>https://stats.stackexchange.com/questions/647733/probability-algorithm-on-strings</link>
      <description><![CDATA[令 $x$ 为任何二进制字符串 $\in (0,1)^*.$
主要语言由以下公式给出：
$$\text{MAJ}:=\{x\in (0,1)^*:\sum_{i=1}^ {|x|}x_i&gt;\frac{ |x|}{2}\},\text{其中 $x_i$ 是 $x$ 的第 $i$ 个位置值（$0$ 或 $1$）}.$$
任何给定字符串 $x\in (0,1)^*.$ 的汉明权重由以下定义：$$wt(x)=\sum_{i=1}^{|x|}x_i=|\{i\in[|x|]:x_i=1\}|.$$
给定 $n\in \mathbb{N},$ 定义两个分布：
$$X_n=\text{$n$长字符串上的均匀分布满足} wt(x)=\left \lfloor \dfrac{n}{2} \right \r地板+1$$
$$Z_n=\text{$n$长字符串上的均匀分布满足} wt(x)=\left \lfloor \dfrac{n}{2} \right \r地板$$
并且 $$P[X_n\in \text{MAJ}]=1 \text{ 和 } P[Z_n\in \text{MAJ}]=0.$$ 
现在我想证明以下说法：
$$A:= \text{在$q$个位置查询$n$长序列字符串的算法，然后}|P[A(X_n)=1)]-P[A (Z_n)=1)]|\leq \frac{q}{n}.$$
我的顾问提供以下证明：
&lt;块引用&gt;
证明：
生成$X_n$和$Z_n$如下，示例 $i\in [n]$ 均匀随机（$i$字符串的索引）。示例 $y\in \{z\in (0,1)^n: wt(z) =\left \lfloor \dfrac{n}{2} \right \rfloor\ ,z_i=0\}.$
对于 $Z_n,$ 输出 $y.$ 对于 $ X_n,$ 输出 $$y \oplus 0^{i-1}10^{n-i}(\text{逐点复制 $y$ 并将 $1$ 放置在 $第 i$ 个条目。})$$
只要算法 $A$ 不查询第 $i$ 个位置，它的行为就会准确无误在 $X_n$ 和 $Z_n$ 上也是如此，因为它有效地查询相同的值。 $i$ 上的分布是均匀的，因此算法以 $\leq\frac{q}{ 的概率查询此位置n}.$

我的问题我不明白上面的证明， $X_n,$ 的输出如何变成 $$y \oplus 0^{i-1}10^{n-i}?$$
以及概率如何 $\leq\frac{q}{n}?$ 有人帮助我理解上面的算法。]]></description>
      <guid>https://stats.stackexchange.com/questions/647733/probability-algorithm-on-strings</guid>
      <pubDate>Wed, 22 May 2024 04:05:05 GMT</pubDate>
    </item>
    <item>
      <title>高斯联结函数的相关性</title>
      <link>https://stats.stackexchange.com/questions/647732/correlation-of-a-gaussian-copula</link>
      <description><![CDATA[假设我有一个带有相关矩阵的二维高斯联结函数
$$
R = \begin{b矩阵}
1 &amp; \rho \\
\rho &amp; 1
\end{b矩阵}
$$
对于$\rho\in[-1,1]$。系动词是
$$
C_R(u)=\Phi_R\big(\Phi^{-1}(u_1),\Phi^{-1}(u_2)\big),
$$
其中 $\Phi_R$ 是二维正态分布的 cdf，平均值为 $\mathbf{0}$&lt; /span&gt; 和协方差矩阵 $R$。假设 $U=(U_1,U_2)$ 是一个随机向量，其 cdf 为 $C_R$。&lt; /p&gt;
问题$U_1$ 和 $U_2 之间的（皮尔逊）相关系数是多少$？
想法 它应该与 $\rho$ 有关，但根据我下面的实验，它并不完全等于 &lt; span class=&quot;math-container&quot;&gt;$\rho$。 $\rho$ 和 $\text{corr}(U_1,U_2) 之间是否存在良好的表达式（或联系） $？
我使用公式计算了$\text{corr}(U_1,U_2)$数值
$$
\text{cov}(U_1,U_2)=\int_0^1\int_0^1 C_R(u_1,u_2) - u_1u_2\;杜_1 杜_2
\四边形
\文本{和}
\四边形
\text{corr}(U_1,U_2)=12\times\text{cov}(U_1,U_2),
$$
我们使用 $U_1$ 和 $U_2$ 在 $[0, 1]$。
然后我将 $\text{corr}(U_1,U_2)-\rho$ 绘制为 $ 的函数\rho$：
&lt;img alt=&quot;错误图&quot; src=&quot;https://i.sstatic.net/TMFA0hvJ.png ” /&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/647732/correlation-of-a-gaussian-copula</guid>
      <pubDate>Wed, 22 May 2024 03:11:06 GMT</pubDate>
    </item>
    <item>
      <title>3 路交互，残差图显示拟合值之间的聚类，我是否需要以不同的方式考虑分组？</title>
      <link>https://stats.stackexchange.com/questions/647731/3-way-interaction-residual-plot-showing-clustering-across-fitted-values-do-i-n</link>
      <description><![CDATA[我创建了一个三向交互的模型，分析面包 (fr2) 的味道如何随着时间 (time2) 的变化而降低，以及技能&lt;面包师的/strong&gt;（技能2）影响不同类型面包（类型）、面包篮子（id）的味道的寿命嵌套，因为它们是由相关成分制成的；
full_model &lt;- lmer(fr2 ~ time2 * Skill2 * type + (1|id), REML = F, data = data_long)
fr2 - 连续（味道）
time2 - 连续（天）
技能2 - 连续（0,1,2,3）
类型 - 分类 (1:10)
甜蜜 - 二进制 (0:1)
在评估面包类型时，三向交互会给出预期的显着结果（emtrends），其中技能随着时间的推移对口味有很大影响。然而，当我根据拟合值绘制残差时，沿着拟合值存在大量聚类。我想这是因为不同类型的面包有很多口味范围，有些在 30-40 之间，有些在 50-60 之间。当我按面包类型分别绘制模型时，残差分布得更加均匀。
我尝试记录变换、居中和标准化品味、时间和技能变量，但仍然继续进行聚类。我是否应该担心使用此模型来推断不同类型面包之间相互作用和对比的重要性？
这是伪造的数据：https://github。 com/GreenJumper/bread/blob/71cf99a481dfe96632ad62e9afec1960a7ec3308/data_long.csv


我还想将面包类型分为两类作为二元变量（甜/不甜）。我故意更改了数据，以便当面包师的技能高（强交互）时，甜面包（面包类型 2 和 5）具有更长的寿命。当我尝试对此进行建模时，残差也有点奇怪，并且残差在 qqplot 中看起来不正常。关于如何调整模型有什么想法吗？
任何帮助将不胜感激。谢谢！
sweets_model &lt;- lmer(fr2 ~ Skill2 * time2 * sweets + (1|id), REML = F, data = data_long)

]]></description>
      <guid>https://stats.stackexchange.com/questions/647731/3-way-interaction-residual-plot-showing-clustering-across-fitted-values-do-i-n</guid>
      <pubDate>Wed, 22 May 2024 02:33:11 GMT</pubDate>
    </item>
    <item>
      <title>GridSearchCV 的表现比基线更差</title>
      <link>https://stats.stackexchange.com/questions/647727/gridsearchcv-performs-worse-than-baseline</link>
      <description><![CDATA[我正在使用 scikit-learn 解决二元分类问题。我测试过的模型之一是 KNeighborsClassifier，我使用默认参数获得了 78% 的基线分数 (“recall_macro”)。此外
然后我运行一个 GridSearchCV 交叉验证器（使用包含默认值的参数网格，仅使用训练集，并针对我需要的评分指标），但我得到“优化的”得分71%。不仅如此，少数族裔的召回率也从 59% 下降到 43%。
据我了解，GridSearchCV 运行的数据与模型所拟合的数据并不完全相同，因此可能存在轻微差异，但这似乎过多。我错过了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647727/gridsearchcv-performs-worse-than-baseline</guid>
      <pubDate>Wed, 22 May 2024 00:33:29 GMT</pubDate>
    </item>
    <item>
      <title>关于综合相对风险解释的问题</title>
      <link>https://stats.stackexchange.com/questions/647726/question-about-combined-relative-risk-interpretation</link>
      <description><![CDATA[我正在查看有关吸雪茄影响的评论，但我无法解释其中的一些结果。研究链接如下：研究
具体来说，我对下面的表 3 有疑问：
&lt;img alt=&quot;表 3&quot; src=&quot;https://i.sstatic.net/OlFWCFN1.png ” /&gt;
在 Primay 雪茄系列中，对于 50-64 岁、每天使用 1-2 支的人来说，RR 为 1.1。然而，综合值为 1.02 (0.97-1.07) (95% CI)。
我知道，每天吸烟 1-2 次的人的综合 CI 可以解释为相对于从不吸烟者，全因死亡率增加 2%，但这并不具有统计意义。
我可以将组合 CI 单独推断到 50-64 组吗？换句话说，我可以说“50-64岁每天吸1-2支雪茄的人，相对于从不吸烟的人来说，全因死亡率增加了10%，但这种风险在统计上并不显着。”？]]></description>
      <guid>https://stats.stackexchange.com/questions/647726/question-about-combined-relative-risk-interpretation</guid>
      <pubDate>Wed, 22 May 2024 00:25:52 GMT</pubDate>
    </item>
    <item>
      <title>ShapeNet UAE KL 发散问题</title>
      <link>https://stats.stackexchange.com/questions/647724/shapenet-vae-kl-divergence-issues</link>
      <description><![CDATA[我正在尝试在 shapenet 上训练 VAE，但似乎无法使其工作。任何帮助或想法将不胜感激。现在的问题是，每当我应用 KL 散度损失时，网络似乎都会陷入高 KL 散度和高重建损失的困境。即使没有 KL 散度（普通自动编码器），重建也几乎是完美的。
问题设置：
输入：shapenet的64^3 TSDF
目前，我只是尝试使用大约（6.5k 椅子）的椅子类别
输出：64^3 TSDF-重建
网络架构：我主要使用与 AutoSDF，这是一个全3D卷积编码器和解码器，用于输出最终的TSDF矩阵。我尝试了各种潜在空间大小，但似乎都不起作用。
KL散度损失函数：
loss = -0.5 * torch.sum(1 + logvar.flatten(1) - mu.flatten(1).pow(2) -
                                    logvar.flatten(1).exp(), 暗淡=1)
损失 = torch.mean(损失, 暗淡=0)

其中 mu 和 logvar 是编码器的 3D 输出（尝试使用不同的潜在空间大小，如下所述）。
实验设置列表

(2*8*8*8)、(4*8*8*8*8)、(8*8* 的潜在空间8*8*8) (16*8*8*8*8) 、 (32*8*8*8) 和 ( 64*8*8*8)：它们似乎都不适用于 VAE 设置，但是 (16*8*8*8*8) 、 (32* 8*8*8) 和 (64*8*8*8) 在常规 AE 设置中效果良好。
在最终输出中添加线性层，以获得在一个实验中维度为 512 维、在另一个实验中维度为 1024 的 mu 和 logvar -&gt;让事情变得更糟
遵循此&lt;a href=&quot;https://stats.stackexchange.com/questions/332179/how-to-weight-kld-loss-vs-reconstruction-loss-in-variational-auto-encoder中的所有建议”线程&lt;/a&gt;。包括“KL成本退火”和“循环退火”。
尝试通过潜在空间的维数标准化 KL 损失权重
重构加权和KL散度加权的几种组合
使用总和减少而不是均值来获得重建损失的更高优先级

以上似乎都不起作用，我现在已经做了相当多的研究，但我不知道下一步该做什么，所以我将不胜感激任何帮助或讨论。]]></description>
      <guid>https://stats.stackexchange.com/questions/647724/shapenet-vae-kl-divergence-issues</guid>
      <pubDate>Tue, 21 May 2024 23:42:45 GMT</pubDate>
    </item>
    <item>
      <title>使用随机对照试验的双重差异或双重差异</title>
      <link>https://stats.stackexchange.com/questions/647721/difference-in-differences-or-difference-in-difference-in-differences-using-a-ran</link>
      <description><![CDATA[对于一个学术项目，我获得了一个关于随机对照试验的数据集。我需要使用此数据集来推导“作物收割机”技术的处理效果。
数据 - 数据是在地块层面上对 700 个农户进行的三波（2019 年、2020 年和 2022 年）的数据。因此，大约有 3500 个观察值。数据报告了人口统计信息、地块特征以及作物产量、成本等结果。
对这些家庭进行了一项随机对照试验 (RCT)，其中的处理是收获和收获后技术好处的“技术演示”。这包括对“作物收割机”好处的演示。RTC 是在第一波数据收集后进行的。2020 年和 2021 年共有 2 次“技术演示”。在这些演示之后，一些经过处理的样本采用了“作物收割机”，而另一些则没有。
样本选择 - 这些家庭位于村庄内（41 个村庄），位于称为 Halqa 的较高地理单位内（共 4 个），位于称为 tehsils 的较高地理单位内（共 2 个）。在 4 个 Halqa 中，2 个是治疗组，2 个是对照组。两个 tehsils 都进行了治疗和对照 Halqa

该研究采用集群随机对照试验 (CRCT) 设计。

在第一阶段，在每个目标地区内有目的地选择了 tehsils。

在每个选定的 tehsil 中，根据通往适合农作物收割机前往村庄的铺有金属道路的标准，选择了两个 Halqas。

对于村庄的选择，在每个选定的哈尔卡中，都会选择一些地理位置相近的村庄，以是否能通往运输机械的道路为标准。
使用完整枚举列出农民后，在两个选定的哈尔卡中，将一个随机分配到治疗组。
我有两个问题。

根据我拥有的数据，差异差异 (DID) 或方差分析是否合适？
我使用这些数据的任务是找到“作物收割机”的处理效果。然而，“技术演示”包括对“作物收割机”等几种收割技术的培训。根据对一些文献的阅读，我想知道我是否需要使用三重差异（差异 - 差异 - 差异）方法。 DID 会给我“技术演示”的“治疗效果”，而 DDD 会通过采用“作物收割机”来区分技术演示的治疗效果。
任何建议都值得赞赏。
谢谢
]]></description>
      <guid>https://stats.stackexchange.com/questions/647721/difference-in-differences-or-difference-in-difference-in-differences-using-a-ran</guid>
      <pubDate>Tue, 21 May 2024 22:44:11 GMT</pubDate>
    </item>
    <item>
      <title>重复测量方差分析的样本量</title>
      <link>https://stats.stackexchange.com/questions/647712/sample-size-for-repeated-measures-anova</link>
      <description><![CDATA[我正在计算重复测量方差分析（受试者内）所需的样本量。我遇到了两个不同的包，结果也不同。
使用“WebPower”包和以下函数
wp.rmanova(n = NULL, ng = 1, nm = 4, f = 0.25, nscor = 1, alpha = 0.05, power = 0.8, type = 1)

我得到了这个结果：
重复测量方差分析

           n f ng nm nscor α 功率
    175.7464 0.25 1 4 1 0.05 0.8

注：内效测试的功率分析
网址：http://psychstat.org/rmanova

使用“pwrss”包和以下函数
pwrss.f.rmanova(eta2 = 0.06, n.levels = 1, n.rm = 4, power = 0.80, alpha = 0.05, corr.rm = 0.50,
类型=“内”）

我得到了这个结果：
 单向重复测量
 方差分析（F 检验）
 H0：eta2 = 0（或f2 = 0）
 HA：eta2＞1。 0（或f2&gt;0）
 ------------------------------------------
 级别（组）数 = 1
 重复测量次数 = 4
 ------------------------------------------
  统计功效 = 0.8
  总计 n = 23
 ------------------------------------------
 效果类型=“内部”
 分子自由度 = 3
 分母自由度 = 65.029
 非中心参数 = 11.579
 I 类错误率 = 0.05
 II 类错误率 = 0.2

我还使用 GPower 来比较结果，并且根据不同的效应大小规范，我还获得了不同的样本大小。当我使用默认的 GPower3 效应大小规格时，我得到 n = 24。

使用科恩效应大小规范，我得到 n = 176。

还有一个“SPSS”工具选项给了我 61 的样本量。我还读到，如果您采用 Cohen 的计算，将 n 除以测量次数 - 1，然后添加组数，您将得到 SPSS 样本量计算，结果一致：176/ (4-1) + 1 = 60。谁能告诉我哪种方法是正确的？这些计算的差异很大，从 24 到 176 不等。]]></description>
      <guid>https://stats.stackexchange.com/questions/647712/sample-size-for-repeated-measures-anova</guid>
      <pubDate>Tue, 21 May 2024 17:54:17 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 的 RMSE 小于 SARIMA，该选择哪一个？</title>
      <link>https://stats.stackexchange.com/questions/647677/the-rmse-for-arima-is-less-than-sarima-which-one-to-prefer</link>
      <description><![CDATA[用原始数据（2 个）绘制去季节值时，没有太大差异。也是 ARIMA(1,1,0) 和 SARIMA((1,1,0),(7,1,0,12)) 的顺序。虽然评估 arima 的 rmse 小于 sarima。
可以假设数据中没有很强的季节性吗？或者可能是因为过度拟合导致 sarima 的表现不佳。
我应该选择哪种模型？（原油价格时间序列分析（印度篮子）。
这里还有 rmse：
滚动ARIMA=6.1377，
滚动SARIMA= 6.6290
]]></description>
      <guid>https://stats.stackexchange.com/questions/647677/the-rmse-for-arima-is-less-than-sarima-which-one-to-prefer</guid>
      <pubDate>Tue, 21 May 2024 10:04:57 GMT</pubDate>
    </item>
    <item>
      <title>统计测试看看一组是否比另一组增长得更快</title>
      <link>https://stats.stackexchange.com/questions/647648/statistical-test-to-see-whether-one-group-grew-faster-than-the-other</link>
      <description><![CDATA[我有 2020 年至 2023 年 2 组参与者人数的数据。我可以使用任何统计测试来测试 A 组的参与者数量是否比 B 组的百分比增长更快？比如 A 组在 2023-2020 年增长了 527%，而 B 组仅增长了 13.6%
集团年份 注册人数
2020年51
2021年120
2022年260
2023 320
乙 2020 1600
乙 2021 1800
乙 2022 2250
乙 2023 2600
]]></description>
      <guid>https://stats.stackexchange.com/questions/647648/statistical-test-to-see-whether-one-group-grew-faster-than-the-other</guid>
      <pubDate>Mon, 20 May 2024 20:56:34 GMT</pubDate>
    </item>
    <item>
      <title>获得观察模式的统计显着差异</title>
      <link>https://stats.stackexchange.com/questions/647592/getting-statistically-significant-differences-of-observation-patterns</link>
      <description><![CDATA[首先我要说的是，如果我对统计学了解更多一点，我想我可能能够找到解决问题的方法。然而，你必须原谅我，因为我不确定如何用一般统计术语来表述它，从而产生有效的谷歌搜索。解决问题。
我有一个由位置序列定义的模式。假设我有这个模式的 2 个实例，每个实例的长度都相等 $n$ （模式的长度和位置始终相同）。将此模式称为 $X$，并且在任意位置进行观察 $i=0,1,...n$&lt; /span&gt; 为 $X_i$。
在我的模式的任何位置，我对存在 3 种类型的属性（我们称之为类型）进行了不同数量的观察 $A,B,C$&lt; /跨度&gt;。我的观察也可能产生空白（无类型），这意味着没有找到类型。我可以用一个向量来表示，其中列是类型，值是观测值的数量： $X_i = (X_{iA}, X_{iB}, X_{iC}, X_ {iN})$。作为参考，观测总数的数量级 $\Sigma \ X_i = 10$。
我的模式 $X$ 因此是一个 $n*4$ 矩阵。我有两个 $X$ 实例，我想知道它们总体上是否不同（或者在我可以概括的子集中）。我知道 $X$ 的每个实例都是从不同的采样池中获取的（我提到这一点是为了防止模式随采样池的变化而变化）。如果重要的话，可以认为采样池是独立的。
感谢您为我指明正确方向的任何帮助。到目前为止，我的搜索建议我训练一个多项式逻辑回归模型，但我对如何从该模型到设置“统计上显着不同”的阈值有点不知所措，我已经看到提到过使用似然比或卡方检验，但我不确定它们使用的是什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/647592/getting-statistically-significant-differences-of-observation-patterns</guid>
      <pubDate>Mon, 20 May 2024 04:26:46 GMT</pubDate>
    </item>
    <item>
      <title>用 cox 测试解释结果</title>
      <link>https://stats.stackexchange.com/questions/647375/interpreting-results-with-a-cox-test</link>
      <description><![CDATA[我正在尝试使用 lmtest 库中的 coxtest 来比较 2 个非嵌套模型。遗憾的是我找不到有关此测试结果的任何解释。
我的第一个目标是使用anova(model1, model2)来比较2个测试，但我失败了，因为我使用不同的数据库（仅不同的观察数：485 vs 500 obs，但数据来源相同）。 
一些网页描述该测试验证一个模型是否比其他模型更好。但在我的第二个和第三个例子中没有验证这一点。或者只测试两个模型是否不同？
可能我错过了什么或者我做错了什么......
这里我测试相同的模型，相同的数据库但不同的观察数：
库(lmtest)

模型1：Gasto~log(Ingreso)
模型2：Gasto~log(Ingreso)
                    估计标准。误差z值Pr(&gt;|z|)
拟合(M1) ~ M2 -0.037 0.0033982 -1.1011e+01 &lt; 2.2e-16***
拟合(M2) ~ M1 -253.894 0.0000885 -2.8705e+06 &lt; 2.2e-16***
    ---
西尼夫。代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1&#39;&#39;1
警告消息：
1：在 coxtest(mod4, mod5) 中：适合不同子集的模型
2：在 coxtest(mod4, mod5) 中：指定不同的因变量

为什么两个模型都很显着？在什么意义上有不同？ M1和M2有什么不同？或更好？ M2与M1不同吗？或者更好？
这里我测试了不同的模型，相同的数据库。
我更改 Gasto 的名称只是为了验证模型顺序更改是否会在表中产生结果，例如：
coxtest(mod3, mod4):
    
模型 1：Gasto3 ~ Ingreso
模型2：Gasto~log(Ingreso)
                            估计标准。误差z值Pr(&gt;|z|)
已安装(M1) ~ M2 -0.075 0.218506 -0.3454 0.7298
已安装(M2) ~ M1 -209.031 0.010401 -20097.4191 &lt;2e-16 ***
            ---
西尼夫。代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1&#39;&#39;1
警告消息：
1：在 coxtest(mod3, mod4) 中：适合不同子集的模型
2：在 coxtest(mod3, mod4) 中：指定不同的因变量

&gt;考克斯测试
        
考克斯测试（mod4，mod3）：
    
模型1：Gasto~log(Ingreso)
模型 2：Gasto3 ~ Ingreso
估计标准。误差z值Pr(&gt;|z|)
已安装(M1) ~ M2 -0.134 0.210933 -0.6361 0.5247
已安装(M2) ~ M1 -253.604 0.012717 -19942.2191 &lt;2e-16 ***
            ---
西尼夫。代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1&#39;&#39;1
警告消息：
1：在 coxtest(mod4, mod3) 中：适合不同子集的模型
2：在 coxtest(mod4, mod3) 中：指定不同的因变量

在最后一个结果中，我预计 p 值位于第一个结果中，而不是最后一个结果中，因为我更改了模型的顺序。
有人可以提供一些建议或更好地解释吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647375/interpreting-results-with-a-cox-test</guid>
      <pubDate>Thu, 16 May 2024 16:40:55 GMT</pubDate>
    </item>
    <item>
      <title>寻找嘈杂多边形的角点</title>
      <link>https://stats.stackexchange.com/questions/647344/finding-the-corners-of-noisy-polygons</link>
      <description><![CDATA[我有一些多边形，例如如下所示：

如果我将一侧放大得非常近，您可以看到噪音。

数据是 x 坐标列表和相应的 y 坐标列表。
我想要一种能够找到更小、更简单、噪音更少的坐标列表的算法。
我认为多边形的边是线性方程的连续列表。
我读到了Lasso并决定尝试一下。
from sklearn.linear_model import Lasso
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

xs_name = &quot;xs.txt&quot;;
ys_name = &quot;ys.txt&quot;;

xs = np.loadtxt(xs_name).reshape(-1, 1)
ys = np.loadtxt(ys_name).reshape(-1, 1)

reg = 套索(alpha=0.1)
reg.fit(xs, ys)

供参考，xs 和 ys 如下所示：
xs

ys

但是我只得到一个系数
&lt;前&gt;&lt;代码&gt;reg.coef_
输出[31]：数组（[0.82647029]）

我希望获得每条识别线的系数列表。
我觉得我在概念上错过了一些东西。我什至不确定 Lasso 是否适合这项工作。
有谁知道我如何正确使用 Lasso，或者向我指出适合这项工作的正确工具。
&lt;小时/&gt;
编辑
x 坐标
坐标
我还认为值得一提的是，调查论文中也提到了 group lasso 破裂库
&lt;小时/&gt;
编辑
为了清楚起见，放大的区域用红色圈出

编辑
我在 R 中尝试自回归模型取得了一些成功
xs &lt;- read.table(&#39;xs.txt&#39;, sep=&quot;\n&quot;)
ys &lt;- read.table(&#39;ys.txt&#39;, sep=&quot;\n&quot;)

xs &lt;- as.numeric(as.character(unlist(xs)))
ys &lt;- as.numeric(as.character(unlist(ys)))

fastcp_xs &lt;- fastcpd::fastcpd.ar(xs, 3, r.progress = FALSE)
摘要（fastcp_xs）
情节（fastcp_xs）


然而，在这种情况下，这种方法的成功似乎主要是运气，因为在更多数据上尝试此方法会发现不好的结果。
在 ys 上尝试相同的方法：
fastcp_ys &lt;- fastcpd::fastcpd.ar(ys, 3, r.progress = FALSE)
摘要（fastcp_ys）
情节（fastcp_ys）


自回归模型无法检测 ys 的边缘。
fastcpd 库中的其他例程在我的情况下似乎给出了类似的糟糕结果。
我目前认为我最好的选择是某种形式的套索算法。因为套索的概念是拟合一系列直线。
这可能会变成线性规划问题。
也许我需要求助于使用类似 pyomo 的东西？]]></description>
      <guid>https://stats.stackexchange.com/questions/647344/finding-the-corners-of-noisy-polygons</guid>
      <pubDate>Thu, 16 May 2024 07:46:23 GMT</pubDate>
    </item>
    <item>
      <title>如何互相关两个大小差异很大的数据序列？</title>
      <link>https://stats.stackexchange.com/questions/647332/how-to-cross-correlate-two-data-sequences-with-considerable-differences-in-size</link>
      <description><![CDATA[我需要对代表视频信号的两个帧序列进行互相关。但是，视频的压缩方式不同。
第一个数据 (dados) 数组有 17167 帧，第二个数据 (dados2) 数组有 90083 帧
 frame_sizes = np.loadtxt(&#39;/home/demori/jnotebook/camera_estac_mpeg_low.txt&#39;)
frame_sizes2 = np.loadtxt(&#39;/home/demori/jnotebook/camera_estac_h263_16k.txt&#39;)

# 将 frame_sizes 转换为 DataFrame
dados = pd.DataFrame(frame_sizes, columns=[&#39;FrameSize&#39;])
dados2 = pd.DataFrame(frame_sizes2, columns=[&#39;FrameSize&#39;])

我使用 np.correlate 来制作交叉相关
 correlation = np.correlate(dados[&#39;FrameSize&#39;], dados2[&#39;FrameSize&#39;], mode=&#39;full&#39;)

lags = np.arange(-len(dados[&#39;FrameSize&#39;])+1, len(dados2[&#39;FrameSize&#39;]))
correlation /= np.max(correlation)

plt.figure(figsize=(10, 5))
plt.stem(lags, correlation)
plt.title(&#39;MPEG Low 和 H263 16k 之间的交叉相关&#39;)
plt.xlabel(&#39;Lags&#39;)
plt.ylabel(&#39;标准化交叉相关&#39;)
plt.show()

这是我得到的结果（附图片）。我不知道这是否是进行互相关的最佳方法
]]></description>
      <guid>https://stats.stackexchange.com/questions/647332/how-to-cross-correlate-two-data-sequences-with-considerable-differences-in-size</guid>
      <pubDate>Wed, 15 May 2024 21:18:26 GMT</pubDate>
    </item>
    </channel>
</rss>