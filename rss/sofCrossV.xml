<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 13 Aug 2024 15:16:11 GMT</lastBuildDate>
    <item>
      <title>我应该计算所有值的平均值还是每个时间点的平均值来分析？</title>
      <link>https://stats.stackexchange.com/questions/652720/should-i-calculate-the-average-over-all-values-or-at-each-point-in-time-to-analy</link>
      <description><![CDATA[我正在尝试分析不同车型汽车在一段时间内的维护成本。我有很多模型。某个模型的一些示例数据如下所示。例如，这可能全部用于福特汽车，并且每个 Car ID 可能代表福特汽车的特定型号。



汽车年龄（年）
维护成本（美元）
汽车ID




1
62
A


2
22
A


3
235
A


4
228
A


5
403
A


1
36
B


2
130
B


3
89
B


4
30
B


5
25
B


1
59
C


2
168
C


3
118
C


4
72
C


5
471
C


1
51
D


2
126
D


3
201
D


4
92
D


5
302
D



我想了解维护成本。具体来说，我想显示某个特定的 Car ID 相对于同类产品（即其他 Car ID）的成本是高很多还是低很多。
我想要做的是计算出平均成本和标准差，以便绘制异常值。假设任何高于或低于 3 个标准差（或可能是 2 个）的值。
问题：
我是否应该计算每年的平均值和标准差，即对于第 1 年，我将平均 62、36、59、51，并计算出这些数字的标准差，然后根据此确定异常值？
或
我是否应该计算整个数据集的平均值/标准差？
我不太确定这两个选项之间的区别是什么。当然，前者的平均线和平均值 +- 2 * s.d 将不是直线，而后者则是直线。
我之前见过一些统计过程控制图，它们具有平坦的平均线和平坦的上/下控制限（平均值 +- s.d 的某个倍数），但鉴于我有多个 Car ID，而不仅仅是查看一个 Car ID，我想知道我是否应该计算每年每个点的平均值。
我主要感兴趣的是与同一品牌的其他车型相比，哪些车型最贵或最便宜。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/652720/should-i-calculate-the-average-over-all-values-or-at-each-point-in-time-to-analy</guid>
      <pubDate>Tue, 13 Aug 2024 14:58:09 GMT</pubDate>
    </item>
    <item>
      <title>根据先前研究的项目参数计算新样本的 IRT 量表分数</title>
      <link>https://stats.stackexchange.com/questions/652718/computing-irt-scale-scores-for-new-samples-based-on-item-parameters-from-previou</link>
      <description><![CDATA[我一直想问一个问题，但由于表达不清楚而失败了——所以我会再试一次——有没有人用 R 写过一个程序，从以前的研究中获取 IRT 项目参数，以便能够为新样本计算新的 IRT 量表分数——或者可以给我指出一个资源
提前谢谢——我对 chatGPT 之类的东西没有信心 :-)]]></description>
      <guid>https://stats.stackexchange.com/questions/652718/computing-irt-scale-scores-for-new-samples-based-on-item-parameters-from-previou</guid>
      <pubDate>Tue, 13 Aug 2024 14:35:37 GMT</pubDate>
    </item>
    <item>
      <title>当必须使用抽样权重时，回归系数可以进行引导吗？</title>
      <link>https://stats.stackexchange.com/questions/652716/can-regression-coefficients-be-bootstrapped-when-sampling-weights-must-be-used</link>
      <description><![CDATA[我有非复杂调查数据 - 它有样本权重，但没有其他关于调查设计需要考虑的因素。我想使用权重获得回归系数的引导分布。我希望引导主要用于计算具有较少假设的置信区间 (CI)。
我发现了大量关于加权回归的文献（和实现），以及大量关于引导的文献，但我几乎没有找到关于将两者结合起来的文献。我的直觉是尝试这样做：使用抽样权重创建引导样本以加权引导抽样，为每个引导样本建立一个非加权模型，然后我得到了引导系数的集合。但我有一种挥之不去的感觉，这种方法对 CI 的惩罚不够。当我使用权重时，我的错误应该更大 - 但不会这样（或者会这样吗？）？]]></description>
      <guid>https://stats.stackexchange.com/questions/652716/can-regression-coefficients-be-bootstrapped-when-sampling-weights-must-be-used</guid>
      <pubDate>Tue, 13 Aug 2024 13:44:25 GMT</pubDate>
    </item>
    <item>
      <title>解释 DHARMa 中的残差与预测分位数图的含义？</title>
      <link>https://stats.stackexchange.com/questions/652715/interpreting-the-meaning-of-residual-vs-predicted-quantile-plots-in-dharma</link>
      <description><![CDATA[这些是使用 glm 拟合的逻辑回归的 DHARMa 残差。从这张图中我似乎明白没有检测到分位数偏差/问题，但我无法确定模型预测在 x 轴上全部高于 .6 是否有值得关注的原因（似乎如此）。哪些问题/预测假设会导致这些问题？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652715/interpreting-the-meaning-of-residual-vs-predicted-quantile-plots-in-dharma</guid>
      <pubDate>Tue, 13 Aug 2024 13:40:24 GMT</pubDate>
    </item>
    <item>
      <title>计算或近似亚指数分布（即指数 rv 和的分布）的对数概率密度</title>
      <link>https://stats.stackexchange.com/questions/652713/calculating-or-approximating-the-log-probability-density-for-hypoexponential-dis</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652713/calculating-or-approximating-the-log-probability-density-for-hypoexponential-dis</guid>
      <pubDate>Tue, 13 Aug 2024 12:54:25 GMT</pubDate>
    </item>
    <item>
      <title>用于计算百分位数的最佳 R 分位数方法 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/652712/optimal-r-quantile-method-for-calculating-percentile</link>
      <description><![CDATA[R 中的哪种分位数估计方法适用于计算有联系的小样本中的极端百分位数（例如，第 2 个百分位数）？&quot;]]></description>
      <guid>https://stats.stackexchange.com/questions/652712/optimal-r-quantile-method-for-calculating-percentile</guid>
      <pubDate>Tue, 13 Aug 2024 12:20:22 GMT</pubDate>
    </item>
    <item>
      <title>设计一个神经网络，利用游戏状态信息预测 2D 格斗游戏中玩家的输入</title>
      <link>https://stats.stackexchange.com/questions/652711/designing-a-neural-network-to-predict-a-players-input-in-a-2d-fighting-game-usi</link>
      <description><![CDATA[我目前正在尝试设计一个神经网络，目的是广泛模仿特定 2D 格斗游戏中某些玩家的行为。
该游戏会记录每场游戏的“重播”，从而创建一个庞大的数据库。这些重播不仅包含每帧的游戏状态（例如位置值、动作状态等），还包含玩家输入的按钮。
NN 的输入数据将是游戏状态（或一系列游戏状态），并输出该游戏状态的预测输入。
我已经在 PyTorch 中为这个问题设置了一个通用 MLP，其架构如下，将其视为一个多标签问题，其中每个按钮输入都是一个要预测的标签：
class BaseModel(nn.Module):
def __init__(self, input_size, output_size):
super(BaseModel, self).__init__()
self.block_1 = nn.Sequential(
nn.Linear(input_size, 256),
nn.ReLU(),
nn.Linear(256,128),
nn.ReLU(),
)
self.dropout = nn.Dropout(p=0.3)
self.block_2 = nn.Sequential(
nn.Linear(128,64),
nn.ReLU()
)
self.bn = nn.BatchNorm1d(64)
self.block_3 = nn.Sequential(
nn.Linear(64,32),
nn.ReLU(),
nn.Linear(32,output_size)
)

def forward(self, x):
x = self.block_1(x)
x = self.dropout(x)
x = self.block_2(x)
x = self.bn(x)
x = self.block_3(x)
return x


此问题的数据来自重播。
输入数据首先被转换成人类可读的映射（例如 {&quot;HP&quot;: 10000, &quot;x&quot;:645.4273, &quot;y&quot;:0.0000, &quot;super_meter&quot;:32.6345, etc.&gt;），然后转换成一维张量形式的数值格式（例如 [10000, 645.4273, 0.0000, 32.6345, etc.]）。
同样，按钮输入首先从重放中转换为人类可读的映射（{&quot;A&quot;: 0, &quot;B&quot;: 1, &quot;up&quot;: 0, &quot;down​​&quot;:0, &quot;left&quot;:1, etc.&gt;），然后转换为一维张量，用作训练的真值标签，也仅使用映射的值。
目前，我使用的损失函数是二元交叉熵，优化器是 Adam。输出通过 S 型函数传递，如果值超过某个阈值，则按钮被解释为按下。
当前实现效果相当差。由于大多数按钮输入对于每个游戏状态都是 0，因此模型通过预测每帧每个按钮的 0 来非常快速地实现低损失。
我应该尝试哪些架构更改来提高模型的性能/处理模型很容易实现低损失的问题？
请注意，这样做的目的是模仿玩家行为，而不是“学习”如何玩游戏。如果使用重播数据训练模型的玩家什么都不做，只是一直按下一个按钮，那么模型应该反映这种行为。类似地，如果输入的玩家是职业玩家，其动作要复杂得多，则模型也应该表示这种行为。]]></description>
      <guid>https://stats.stackexchange.com/questions/652711/designing-a-neural-network-to-predict-a-players-input-in-a-2d-fighting-game-usi</guid>
      <pubDate>Tue, 13 Aug 2024 10:37:18 GMT</pubDate>
    </item>
    <item>
      <title>元分析与混合效应模型估计效应大小</title>
      <link>https://stats.stackexchange.com/questions/652710/meta-analysis-vs-mixed-effect-model-to-estimate-effect-size</link>
      <description><![CDATA[我有来自之前三个实验的数据，我想在功效分析中使用它们来计算新研究所需的样本量。一种经典的方法是进行元分析以获得标准化均值差异的估计值（在本例中），然后可以将其输入到样本量计算中。我使用 R 包 metafor 的函数 rma（执行随机效应元分析）完成了此操作。我已经对一个演示数据集（下面的代码）进行了此操作，结果我得到了治疗效果（均值差异）的估计值为 6.86，se 为 2.238。

library(lme4)
library(metafor)

# 演示数据集：
# 治疗：分类变量：0：治疗组，1：对照组
# 研究：分类变量，表示研究编号从 1 到 3
# y：模拟测量值
y &lt;- c(15.1,14.9,12.1,17.3,14.1,16.2,15.0,16.0,25.2,23.5,27.1,20.9,29.4,25.3,24.8,25.1,
8.2,11.3,10.0,10.1,9.9,12.0,8.0,10.9,18.0,17.0,19.3,22.2,16.1,17.1,17.8,17.2,
22.0,23.1,20.9,22.1,21.8,19.9,24.6,21.9,24.5,26.4,22.1,24.1,24.0,23.7,26.5,25.8)
治疗 &lt;- as.factor(rep(c(rep(0,8),rep(1,8)),3))
研究 &lt;- as.factor(c(rep(1,16),rep(2,16),rep(3,16)))

# 使用包进行随机效应元分析metaform
rma(measure=&quot;MD&quot;,
n1i=c(8,8,8),
n2i=c(8,8,8),
m1i=c(mean(y[9:16]),mean(y[25:32]),mean(y[41:48])),
m2i=c(mean(y[1:8]),mean(y[17:24]),mean(y[33:40])),
sd1i=c(sd(y[9:16]),sd(y[25:32]),sd(y[41:48])), 
sd2i=c(sd(y[1:8]),sd(y[17:24]),sd(y[33:40]))
)

但是，由于我不仅拥有三个数据的汇总数据，荟萃分析，但实际上，除了 rma，我可以使用所有原始数据，直接用混合效应回归模型估计治疗效果。
mod &lt;- lmer(y ~ treatment + (1|study) + (1|study:treatment))
summary(mod)

这样做，我得到了略有不同的治疗效果估计值 6.904 ，其标准差为 2.231。差别不大，但确实存在。我并不惊讶，我得到了略有不同的结果，因为我从不同的信息开始：​​一种情况下“仅”使用汇总统计数据（平均值、标准差），另一种情况下使用完整的原始数据。我的问题是，哪一种是估计效果大小计算效果的“更好”方法？我看到的大多数功效计算都是基于荟萃分析（因为通常原始数据不容易获得，因为数据是从文献中提取的，而作者通常只报告汇总统计数据）。但是，凭着我天真的直觉，我会认为，如果我确实有原始数据，那么将所有原始数据作为输入的混合模型应该更精确，因为它利用了更多信息。有什么理由让我不应该根据混合模型结果来估计效应量，而是像大多数人一样使用 rma？]]></description>
      <guid>https://stats.stackexchange.com/questions/652710/meta-analysis-vs-mixed-effect-model-to-estimate-effect-size</guid>
      <pubDate>Tue, 13 Aug 2024 10:19:46 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测中的神经网络：使用前一个网络作为下一个时间间隔的起点[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652708/neural-net-in-time-series-forecasting-the-use-of-previous-net-as-a-staring-poin</link>
      <description><![CDATA[我使用 NN 进行时间序列预测，其中序列和我使用的特征非常嘈杂。我在前 T 个输入上训练网络并获得了不错的结果：网络从随机初始化的权重开始学习得很好。然后我移动到下一个估计点，例如使用移动窗口，它将是间隔 [T+1,2T] 或扩展窗口 [1,2T]。如果我从随机初始化的权重开始，网络将再次学习。但是，由于我预计分布不会发生巨大变化，我从上一步获得的网络开始训练，但损失在学习周期内未能改善。我理解这是可能的，因为分布没有太大变化，而且几乎没有新东西需要学习。然而，我想知道这个问题是否可能是由于我学习的权重偏离目标而导致的，而它们的统计特性使它们成为一个糟糕的初始点？]]></description>
      <guid>https://stats.stackexchange.com/questions/652708/neural-net-in-time-series-forecasting-the-use-of-previous-net-as-a-staring-poin</guid>
      <pubDate>Tue, 13 Aug 2024 10:07:34 GMT</pubDate>
    </item>
    <item>
      <title>同一 GAM 模型的不同结果取决于“discrete = TRUE”</title>
      <link>https://stats.stackexchange.com/questions/652707/different-results-of-the-same-gam-model-depends-on-discrete-true</link>
      <description><![CDATA[我正在使用 bam 函数拟合 GAM。
该模型的代码是：
mod_1 &lt;- bam(n ~ s(age, by = period, k = 15) + 
s(hh_size, by = period, k = 9) +
period +
s(token, bs = &quot;re&quot;) + s(Bundesland, bs = &quot;re&quot;) + s(period, bs = &quot;re&quot;),
data = halle_data_household,
method = &quot;fREML&quot;, discrete = TRUE,
family = nb(),
nthreads = c(4,1))
mod_2 &lt;- bam(n ~ s(age, by = period, k = 15) + 
s(hh_size, by = period, k = 9) +
period +
s(token, bs = &quot;re&quot;) + s(Bundesland, bs = &quot;re&quot;) + s(period, bs = &quot;re&quot;),
data = halle_data_household,
method = &quot;fREML&quot;, 
family = nb(),
nthreads = c(4,1))

两个模型的区别在于&quot;discrete = TRUE&quot;，以加快计算时间。但我得到了两个不同的结果。
mod_1 的结果
 家庭：负二项式 (13.366) 
链接函数：log 

公式：
n ~ s(age, by = period, k = 15) + s(hh_size, by = period, k = 9) + 
period + s(token, bs = &quot;re&quot;) + s(Bundesland, bs = &quot;re&quot;) + 
s(period, bs = &quot;re&quot;)

参数系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 0.5409 0.1354 3.996 6.74e-05 ***
period2 -0.1253 0.1674 -0.749 0.454 
period3 -0.1319 0.1600 -0.825 0.410 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df F p 值 
s(age):period1 1.000e+00 1.000 0.641 0.423337 
s(age):period2 4.683e+00 5.656 3.799 0.001034 ** 
s(age):period3 4.569e+00 5.444 4.928 0.000116 ***
s(hh_size):period1 1.960e+00 2.412 1.186 0.303077
s(hh_size):period2 1.000e+00 1.000 1.798 0.180227 
s(hh_size):period3 1.000e+00 1.000 5.930 0.014997 * 
s(token) 4.406e+02 859.000 1.242 &lt; 2e-16 ***
s(Bundesland) 5.429e-05 15.000 0.000 0.801883 
s(period) 1.082e-14 3.000 0.000 0.999933 
---
Signif.代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) = 0.323 偏差解释 = 42.4%
fREML = 3657.9 尺度估计 = 1 n = 2115

mod_2 的结果
 系列：负二项式 (13.32) 
链接函数：log 

公式：
n ~ s(age, by = period, k = 15) + s(hh_size, by = period, k = 9) + 
period + s(token, bs = &quot;re&quot;) + s(Bundesland, bs = &quot;re&quot;) + 
s(period, bs = &quot;re&quot;)

参数系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.32541 0.05293 6.148 9.83e-10 ***
period2 -0.12288 0.07204 -1.706 0.08824 . 
period3 -0.20909 0.06826 -3.063 0.00222 ** 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df F p 值 
s(age):period1 1.000e+00 1.000 0.641 0.423576 
s(age):period2 4.685e+00 5.661 3.801 0.001061 ** 
s(age):period3 4.568e+00 5.442 4.963 0.000117 ***
s(hh_size):period1 1.961e+00 2.417 1.036 0.311454
s(hh_size):period2 1.000e+00 1.000 1.811 0.178523 
s(hh_size):period3 1.000e+00 1.000 5.930 0.014986 * 
s(token) 4.405e+02 857.000 1.226 &lt; 2e-16 ***
s(Bundesland) 6.066e-05 15.000 0.000 0.802106 
s(period) -9.299e-16 3.000 0.000 0.031014 * 
---
Signif.代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.（调整）= 0.322 偏差解释 = 42.4%
fREML = 3406.3 尺度估计 = 1 n = 2115
]]></description>
      <guid>https://stats.stackexchange.com/questions/652707/different-results-of-the-same-gam-model-depends-on-discrete-true</guid>
      <pubDate>Tue, 13 Aug 2024 09:47:41 GMT</pubDate>
    </item>
    <item>
      <title>“添加”多个估计的置信区间</title>
      <link>https://stats.stackexchange.com/questions/652706/adding-confidence-intervals-of-multiple-estimations</link>
      <description><![CDATA[我有救护服务每季度接诊的受伤人数估计值以及置信区间。我想添加这些估计值以检索救护车接诊的年度总受伤人数估计值。如何计算这个总数的置信区间？
每个季度，每个救护服务都会进行 N 次接诊。从 N 中抽取 +-1000 个病例样本 (n)。对于此样本中的每个病例，确定该接诊是否与受伤有关 (1) 或无关 (0；即与疾病等有关)。这意味着我可以计算样本中受伤的比例：p̂ = n1/ntotal。为了估算受伤人数（我们称该统计数据为“x”），我将 p̂ 与 N 相乘。
但是，我想考虑随机抽样引入的不确定性，因此我使用 R 中的 stats::binom.test() 函数估算 p̂ 周围的置信区间 (CI)，并将找到的下限和上限乘以 N 以检索 x 周围的 CI。
因此，现在我对每项救护服务和每个季度（x1、x2、… xn）都有 x 的估算值，我可以将其相加得到年度全国估算值。但是，我不确定如何“添加”置信区间。我非常确定取和将产生过于悲观的区间。
我找到了这篇文章，它似乎表明我可以对 CIs 半径的平方和取平方根，因为我假设一年内的救护服务和季度之间存在统计独立性。但我不确定这是否正确。我正在考虑的另一种方法是将每个服务和季度的所有数据堆积起来，并使用它来计算 p̂ 和 CIs。然而，众所周知，受伤比例在服务（和季度）之间以及总乘车次数（N）之间存在显着差异。我不确定这种方法是否也会产生悲观的 CI。
那么，我如何使用数据来计算全年估计的 CI？]]></description>
      <guid>https://stats.stackexchange.com/questions/652706/adding-confidence-intervals-of-multiple-estimations</guid>
      <pubDate>Tue, 13 Aug 2024 09:34:10 GMT</pubDate>
    </item>
    <item>
      <title>数据自适应参数的推断</title>
      <link>https://stats.stackexchange.com/questions/652705/inference-for-a-data-adaptive-parameter</link>
      <description><![CDATA[您有一个连续变量 $A$ 的数据，表示药物的剂量，以及一个连续结果 $Y$ 的数据，表示某种健康结果。
我想估计 $A$ 的“最佳”剂量，即最小化 $Y$ 的剂量。我们称之为 $A_{opt}$。
估计 $A_{opt}$ 很简单。它是最小化 $E[Y|A=a]$ 的值 $a$，可以通过线性回归估算（例如）。
然后我想估算 $A_{opt}$ 下的 $Y$ 的“值”。我可以通过传入 $A_{opt}$ 从拟合回归中获取此值。但问题是 i) 我将 $A_{opt}$ 视为已知，即使它是估计的（使方差估计无效）和 ii) 使用相同的数据来识别 $A_{opt}$ 以估计该剂量的值。
引导解决了第一个问题，但没有解决第二个问题。两倍样本分割可能有效，但似乎很浪费。K 倍 CV 将导致 $A_{opt}$ 的多个值，这会使演示变得复杂。对于这个问题，我们有什么选择？我将不胜感激任何参考资料！
简要
我如何：

估计数据自适应参数（即药物的“最佳”剂量，相对于结果）
获得该最佳剂量下结果值的有效估计值和有效不确定性
]]></description>
      <guid>https://stats.stackexchange.com/questions/652705/inference-for-a-data-adaptive-parameter</guid>
      <pubDate>Tue, 13 Aug 2024 09:26:50 GMT</pubDate>
    </item>
    <item>
      <title>纵向多组增长模型的不变性检验。是否需要对所有时间点进行组不变性检验？</title>
      <link>https://stats.stackexchange.com/questions/652704/invariance-test-for-a-longitudinal-multi-group-growth-model-is-a-group-invarian</link>
      <description><![CDATA[我有 7 波数据，用于包含来自两个不同国家样本的构造。作为增长曲线分析的初步步骤，已经进行了纵向不变性测试，并支持部分强不变性。我的问题是，是否需要对我拥有的所有时间点进行组不变性测试？我计划在我的增长曲线模型中将国家变量指定为时间不变协变量。
此外，如果有关于需要保持“未释放”多少项目才能保持不变性的文献，那将非常有帮助。
感谢大家的支持]]></description>
      <guid>https://stats.stackexchange.com/questions/652704/invariance-test-for-a-longitudinal-multi-group-growth-model-is-a-group-invarian</guid>
      <pubDate>Tue, 13 Aug 2024 09:17:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么卡方检验的 p 值和 KS 检验的 p 值之间存在很大差异？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652702/why-do-i-get-a-large-difference-between-the-p-value-of-a-chi-square-test-and-the</link>
      <description><![CDATA[简介。我有数据，表示某个地理区域中哺乳动物的数量。我在这里展示了一个数据示例（有关更多信息，请参阅下面的代码）：
&gt;&gt; r1

500、1700、0、600、400、100、200、400、9700、4300、100 等。

我想使用双样本卡方检验和 KS 检验来比较两组哺乳动物的分布。
我能够重现与我的情况类似的情况，其中卡方检验的 p 值低于显着性水平 $\alpha = 0.05$，而 KS 检验的 p 值相当高（因此，两个 p 值非常不同）：
rng(0,&#39;twister&#39;);
a = 0;
b = 100;
bw = 100;
r1 = (b-a).*round(lognrnd(1,1,1000,1)) + a;
r2 = (b-a).*round(lognrnd(0.88,1.1,1000,1)) + a;
保持
h1 = histogram(r1,&#39;BinWidth&#39;,bw);
h2 = histogram(r2,&#39;BinWidth&#39;,bw);
la​​st_bin = 20;
[~,p_CS,~] = chi2gof(1:length(h1.Values(1:last_bin)), &#39;Expected&#39;, h2.Values(1:last_bin), &#39;Frequency&#39;, h1.Values(1:last_bin), &#39;EMin&#39;, 0)
[~,p_KS,~] = kstest2(r1,r2)
xlim([0 2000])

使用这个结果图和 p 值：

p_CS =
0.00029734

p_KS =
0.71613

请注意，卡方检验的输入是分箱数据，即“h1.Values”和“h2.Values”，而 KS 检验的输入是原始数据，即“r1”和“r2”。
问题。为什么卡方检验的 p 值和 KS 检验的 p 值之间会存在很大差异？
其他评论。我理解卡方检验“测量” 落入 bin“i” 的观测值数量（第一个数据集/分布）与预计落入 bin“i” 的观测值数量（第二个数据集/分布）之间的平方差，而 Kolmogorov-Smirnov 检验“测量”两个 ECDF 之间的最大距离。
也就是说，KS 检验“往往对分布中心比尾部更敏感”，但只是我的解释，卡方检验似乎对分布的每个“部分”都很敏感，因为观测值和预期值之间的平方差是针对分布的所有箱体计算的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652702/why-do-i-get-a-large-difference-between-the-p-value-of-a-chi-square-test-and-the</guid>
      <pubDate>Tue, 13 Aug 2024 09:08:18 GMT</pubDate>
    </item>
    <item>
      <title>在 KNN_classifier 中查找给定数据点 x 的 k 个最近邻居 [已迁移]</title>
      <link>https://stats.stackexchange.com/questions/652701/find-k-nearest-neighbors-of-a-given-data-point-x-in-knn-classifier</link>
      <description><![CDATA[在 python 中，knn 算法可以应用于训练数据，代码如下：
 from sklearn.neighbors import KNeighborsClassifier

KNN_classifier = KNeighborsClassifier(n_neighbors=k)
KNN_classifier.fit(X_train, y_train)
y_pred = KNN_classifier.predict(X_test)

现在对于给定的数据点 $x$，我想准确找到 knn 算法在学习过程中使用的 $x$ 的 $k$ 个邻居。是否可以访问给定数据点 $x$ 的邻居？如果有人能帮助我解决这个问题，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/652701/find-k-nearest-neighbors-of-a-given-data-point-x-in-knn-classifier</guid>
      <pubDate>Tue, 13 Aug 2024 09:05:57 GMT</pubDate>
    </item>
    </channel>
</rss>