<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 15 Nov 2024 09:19:19 GMT</lastBuildDate>
    <item>
      <title>在物种分布建模的哪个阶段需要标准化变量并检查共线性</title>
      <link>https://stats.stackexchange.com/questions/657302/at-what-stage-of-the-species-distribution-modelling-to-standardize-variables-and</link>
      <description><![CDATA[我尝试使用基于多个气候变量的广义线性模型（R 中的 glm()）对物种的分布（生态位）进行建模，然后应用该模型预测（映射）我感兴趣的领土内的分布。这些变量可作为栅格文件用于我的领土。
我的程序如下：首先使用整个目标领土的平均值和标准差对变量进行标准化，准备标准化变量的栅格；然后提取我的存在/不存在位置的标准化变量并将其用于建模。
这个顺序是否正确，或者我应该首先提取存在/不存在位置的原始变量，然后根据其平均值和标准差对该样本进行标准化？如果第二种方法更好，如何准备用于预测（映射）的栅格——我应该使用样本的平均值和标准差对它们进行标准化吗？最后一个问题在这里进行了讨论，但似乎没有明确的结论。
同样，在什么级别检查变量的共线性——完整数据集（领土）还是样本？]]></description>
      <guid>https://stats.stackexchange.com/questions/657302/at-what-stage-of-the-species-distribution-modelling-to-standardize-variables-and</guid>
      <pubDate>Fri, 15 Nov 2024 08:15:05 GMT</pubDate>
    </item>
    <item>
      <title>如何为 OBB 数据集正确实现 NMS 和 Dice Loss？</title>
      <link>https://stats.stackexchange.com/questions/657300/how-do-i-correctly-implement-nms-and-dice-loss-for-obb-dataset</link>
      <description><![CDATA[我正在构建一个模型，该模型使用文本识别从给定图像中检测盲文脚本，如本论文中所实现。我在实现用于检测模型预测的边界框的损失函数时遇到了问题。
运行模型后，它卡在了所有时期的损失为 6.3。
任何帮助都将非常有用。
损失函数定义为：
$$
loss = {loss_{cross-entropy} + \lambda * loss_{dice}}
$$
不幸的是，我的实现代码很大，完整的代码（模型的笔记本）位于这里。
def loss(bbox_predictions, class_predictions, ground_truth):
&quot;&quot;&quot;
bbox_predictions：（batch_size，786，9） -&gt; [box_probability，OBB_coordinates] 的 786 个预测
class_prediction：（batch_size，63）
ground_truth：（batch_size，N，9） -&gt; N：存在的 bbox 数量，
9：[class_name，OBB_coordinates]

OBB 格式：[x1 y1 x2 y2 x3 y3 x4 y4]
&quot;&quot;&quot;
def dice_loss(bbox_predictions, gt):
def find_intersection(box1, box2):
尝试:
box1 = [(box1[i], box1[i + 1]) for i in range(0, len(box1), 2)]
box1.append(box1[0])
box2 = [(box2[i], box2[i + 1]) for i in range(0, len(box2), 2)]
box2.append(box2[0])
box1 = shapely.geometry.Polygon(box1)
box2 = shapely.geometry.Polygon(box2)

Intersection = box1.intersection(box2)
如果 Intersection.is_valid，则返回 Intersection.area，否则为 1e-7
除外:
返回 1e-7

def find_union(box1, box2):
尝试:
box1 = [(box1[i], box1[i + 1]) for i in range(0, len(box1), 2)]
box1.append(box1[0])
box2 = [(box2[i], box2[i + 1]) for i in range(0, len(box2), 2)]
box2.append(box2[0])
box1 = shapely.geometry.Polygon(box1)
box2 = shapely.geometry.Polygon(box2)
if not box1.is_valid:
box1 = box1.buffer(0)
if not box2.is_valid:
box2 = box2.buffer(0)

union = box1.union(box2)
return union.area if union.is_valid else 1e-7
except:
return 1e-7

batch_size = bbox_predictions.size(0)
total_loss = 0

for b in range(batch_size):
pred_boxes = bbox_predictions[b] # (786, 9)
gt_boxes = gt[b] # (N, 9)

image_loss = 0
valid_preds = pred_boxes[pred_boxes[:, 0] &gt; 0.3] # 阈值概率为 0.3
for pred_box in valid_preds:
pred_coords = pred_box[1:].reshape(-1).tolist()
max_dice = 0

for gt_box in gt_boxes:
gt_coords = gt_box[1:].reshape(-1).tolist()

junction = find_intersection(pred_coords, gt_coords)
union = find_union(pred_coords, gt_coords)

dice = (2 * 交集) / (并集 + 交集)
max_dice = max(max_dice, dice)

image_loss += (1 - max_dice)

total_loss += image_loss

return total_loss / batch_size

def cross_entropy_loss(class_predictions, gt):
batch_size = class_predictions.shape[0]
total_loss = 0

for b in range(batch_size):
gt_boxes = gt[b] # (N, 9)
gt_class_labels = gt_boxes[:, 0].long() # (N,)

class_loss = 0

for gt_class in gt_class_labels:
class_probs = class_predictions[b] # (63,)
class_loss += nn. functional.cross_entropy(class_probs.unsqueeze(0), gt_class.unsqueeze(0), reduction=&#39;sum&#39;)
total_loss += class_loss

return total_loss / batch_size

loss_dice = dice_loss(bbox_predictions, ground_truth)
loss_cross_entropy = cross_entropy_loss(class_predictions, ground_truth)
LAMBDA = 1

返回 loss_cross_entropy + LAMBDA * loss_dice
]]></description>
      <guid>https://stats.stackexchange.com/questions/657300/how-do-i-correctly-implement-nms-and-dice-loss-for-obb-dataset</guid>
      <pubDate>Fri, 15 Nov 2024 07:03:35 GMT</pubDate>
    </item>
    <item>
      <title>“完美”数据的标准误差太小</title>
      <link>https://stats.stackexchange.com/questions/657299/standard-error-is-too-small-on-perfect-data</link>
      <description><![CDATA[在学习线性回归时，我遇到了这种奇怪的情况。
我正在将数据拟合到线性模型$\beta_0 + \beta_1 x$，并运行 Wald 检验来检查是否$H_0: \beta_0 = 0$。这是一个简单的 Python 函数，它返回 $\hat{\beta_0}$、$\mathrm{se}(\hat{\beta_0})$ 和 $p$-score:
import numpy as np
from scipy.stats import norm

np.random.seed(0)

def test_regress(x, y):
X = np.vstack([np.ones_like(x), x]).T
params = np.linalg.lstsq(X, y)[0]

residuals = y - X @ params
n, p = X.shape
var = np.sum(residuals**2) / (n - p)
cov = var * np.linalg.inv(X.T @ X)
se = np.sqrt(np.diag(cov))

w = (params[0]) / se[0]
p = 2 * norm.cdf(-np.abs(w))
return params[0], se[0], p

这适用于具有 i.i.d 残差的数据：
&gt;&gt;&gt; x = np.arange(1000)
&gt;&gt;&gt; y = x + np.random.normal(size=1000)
&gt;&gt;&gt; test_regress(x, y)
(np.float64(-0.035945884568210226),
np.float64(0.06244021277994775),
np.float64(0.5648282169352368))

p 值很大，因此不能拒绝零假设。
但是，它在完全没有残差的数据上失败了：
&gt;&gt;&gt; x = np.arange(1000)
&gt;&gt;&gt; y = x
&gt;&gt;&gt; test_regress(x, y)
(np.float64(1.5683571961333255e-13),
np.float64(1.1045055269032826e-14),
np.float64(9.209482575035801e-46))

$\beta_0$ 几乎为零，但标准误差太小，因此 p 值极小。
结果并不令人惊讶，而且在现实世界中确实不太可能发生。但理论上，我该如何处理这种情况？我是否需要先测试不可忽略的 $\hat{se}$？]]></description>
      <guid>https://stats.stackexchange.com/questions/657299/standard-error-is-too-small-on-perfect-data</guid>
      <pubDate>Fri, 15 Nov 2024 02:28:49 GMT</pubDate>
    </item>
    <item>
      <title>阶梯楔形设计的协变量约束随机化：R 或 SAS 实现</title>
      <link>https://stats.stackexchange.com/questions/657296/covariate-constrained-randomization-for-stepped-wedge-design-r-or-sas-implement</link>
      <description><![CDATA[我目前正在研究一个涉及 28 个集群和 12 个时间段的阶梯式楔形设计 (SWD)，并且在实施协变量约束随机化 (CCR) 方面遇到了困难。
我需要有关可以处理阶梯式楔形设计的协变量约束随机化的任何 R 或 SAS 包的建议。我将不胜感激任何有关如何在 R 或 SAS 中实现这一点的示例代码或指导，或任何有关如何在将集群分配给干预期时确保协变量平衡的建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/657296/covariate-constrained-randomization-for-stepped-wedge-design-r-or-sas-implement</guid>
      <pubDate>Fri, 15 Nov 2024 01:55:33 GMT</pubDate>
    </item>
    <item>
      <title>RMSE 的替代方法来评估稳定分布参数的拟合优度</title>
      <link>https://stats.stackexchange.com/questions/657293/alternatives-for-rmse-to-eavluate-goodness-of-fit-for-stable-distribution-parame</link>
      <description><![CDATA[我正在估计稳定分布的参数（alpha、beta、gamma、delta） 来自数值数据列表。我使用了一个包来从一种稳定分布（特别是标准 Levy 分布）生成数据。
if (!require(&quot;stable&quot;)) {
install.packages(&quot;stable&quot; , repos = &quot;http://R-Forge.R-project.org&quot;)
library(stable)
}

# 设置可重复性的种子
set.seed(123)

# 从标准 Lévy 分布生成 100 个点
levy_data &lt;- rstable （n = 100，alpha = 0.5，beta = 1，gamma = 1，delta = 0，pm = 0）

之后，我使用简单的 MLE 方法来找到四个参数.
# 执行最大似然估计 (MLE) 来估计参数
levy_fit &lt;- stable.fit(levy_data, method = 1) # 使用 method = 1 进行 MLE

# 打印估计的参数
print(levy_fit)


现在，由于对于实际数据集，我们不知道参数。因此，我们需要一种方法来衡量我们获得的理论分布与数据的拟合优度。我的教授建议使用 RMSE 来评估拟合优度，类似于机器学习模型评估。然而，由于没有依赖变量和 RMSE 比较预测值与实际观测值，我质疑它是否适合这项任务。
我相信对数似然法可能更适合在这种情况下评估优劣，我正在研究其他方法以及。我很感激任何关于以下方面的见解：

为什么 RMSE 可能不适合概率分布拟合。
测量稳定分布拟合优度的替代方法。&lt; /li&gt;
]]></description>
      <guid>https://stats.stackexchange.com/questions/657293/alternatives-for-rmse-to-eavluate-goodness-of-fit-for-stable-distribution-parame</guid>
      <pubDate>Fri, 15 Nov 2024 00:34:22 GMT</pubDate>
    </item>
    <item>
      <title>auto.arima 中非平稳模型的初始观测值的拟合值</title>
      <link>https://stats.stackexchange.com/questions/657285/fitted-values-of-initial-observations-in-auto-arima-for-non-stationary-models</link>
      <description><![CDATA[如果我理解正确的话，在 R 预测包的 auto.arima 中返回的拟合值是模型在估计参数（使用所有训练数据）后给出的一步预测。
假设我已拟合非平稳 ARIMA 模型，例如航空公司模型 $(0,1,1)(0,1,1)_{12}$。在这种情况下，如何计算前 $13$ 个拟合值？由于我们没有关于该系列初始状态的信息，我们如何计算第一个时期的一步预测？请注意，这种情况与平稳情况完全不同，在平稳情况下，我们可以使用平稳均值和方差作为初始状态。
我已经看到 auto.arima 依赖于 stats 包中的 arima 函数，所以我想问题也可以改写为：在非平稳情况下，arima 函数如何计算前几个时期的残差？
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/657285/fitted-values-of-initial-observations-in-auto-arima-for-non-stationary-models</guid>
      <pubDate>Thu, 14 Nov 2024 21:32:15 GMT</pubDate>
    </item>
    <item>
      <title>如何将从 flexsurv 包获得的回归系数的标准误差转换为来自 survivor 包的标准误差？</title>
      <link>https://stats.stackexchange.com/questions/657281/how-to-convert-the-standard-errors-of-regression-co-efficients-obtained-from-the</link>
      <description><![CDATA[我理解 flexsurv 包中使用的参数化与 survival 包中的参数化不同。我使用这两个包拟合了相同的对数正态回归模型。flexsurvreg 的文档提到，它只是 survreg 的包装器，用于对数正态分布，并且它只将结果转换为 flexsurvreg 中使用的参数化。我想了解如何对回归系数标准误差进行转换。输出中的点估计匹配，但回归系数的标准误差不匹配。 （请注意，Scale 的标准误差（在 survival 包中）与 flexsurvreg 中 sdlog 的标准误差相匹配。只是回归系数的标准误差不同）数据可在此处获得，其中独立变量 Stress box cox 已用 lambda = -2 进行变换。
输出自survival:
&gt; para_fit_logNormal.lambda &lt;- survivor::survreg(Surv(Cycles, delta) ~ Stress.boxCox, data = sheets, dist = &quot;lognormal&quot;)
&gt; 
&gt; summary(para_fit_logNormal.lambda)

调用:
survival::survreg(formula = Surv(Cycles, delta) ~ Stress.boxCox, 
data = sheets, dist = &quot;lognormal&quot;)
Value Std.误差 z p
（截距） 8.10e+05 1.76e+04 46.0 &lt;2e-16
Stress.boxCox -1.62e+06 3.52e+04 -46.0 &lt;2e-16
Log（尺度） -7.16e-01 6.69e-02 -10.7 &lt;2e-16

尺度= 0.489 

对数正态分布
Loglik（模型）= -889.6 Loglik（仅截距）= -1065.1
Chisq= 350.97，自由度为 1，p= 2.6e-78 
Newton-Raphson 迭代次数：7 
n= 125 

输出自flexsurvreg:
&gt; (para_fit_logNormal.lambda.flexsurv &lt;- flexsurv::flexsurvreg(Surv(Cycles, delta) ~ Stress.boxCox, data = sheets = LaminatePanel, dist = &quot;lnorm&quot;))
调用:
flexsurv::flexsurvreg(formula = Surv(Cycles, delta) ~ Stress.boxCox, 
data = sheets = LaminatePanel, dist = &quot;lnorm&quot;)

估计值: 
数据平均值估计 L95% U95% 
meanlog NA 8.10e+05 8.10e+05 8.10e+05
sdlog NA 4.89e-01 4.29e-01 5.57e-01
Stress.boxCox 5.00e-01 -1.62e+06 -1.62e+06 -1.62e+06
se exp(est) L95% U95% 
meanlog 2.92e+01 NA NA NA
sdlog 3.26e-02 NA NA NA
Stress.boxCox 5.85e+01 0.00e+00 0.00e+00 0.00e+00

N = 125，事件：115，删失：10
总风险时间：684875.4
对数似然 = -889.6152，df = 3
AIC = 1785.23

]]></description>
      <guid>https://stats.stackexchange.com/questions/657281/how-to-convert-the-standard-errors-of-regression-co-efficients-obtained-from-the</guid>
      <pubDate>Thu, 14 Nov 2024 21:02:08 GMT</pubDate>
    </item>
    <item>
      <title>我们可以用引导回归系数来代替数据吗？</title>
      <link>https://stats.stackexchange.com/questions/657271/can-we-bootstrap-regression-coefficients-instead-of-data</link>
      <description><![CDATA[我对在传统 bootstrap 方法可能很复杂（例如纵向/聚类数据、不规则参数，例如两个边际效应估计值的比率等）的情况下使用 bootstrap 有疑问（例如边际效应比率的置信区间？（GAM 回归））。
以下是我对传统 bootstrap 的解释：

原始模型：$y_i = X_i\beta + \epsilon_i$
原始估计：$\hat{\beta}$ 从拟合模型到 $(y_i, X_i)$，其中 $i=1,...,n$
对于 bootstrap 迭代 $b = 1,...,B$:

从 $(y_i, X_i)$ 重新取样，得到 $(y_i^{(b)}, X_i^{(b)})$
通过将模型拟合到每个 bootstrap 样本，得到 $\hat{\beta}^{(b)}$


Bootstrap 分布来自 $\{\hat{\beta}^{(1)},...,\hat{\beta}^{(B)}\}$

我在想，当这种传统的引导方法可能无法实现时，也许我们可以使用参数估计的渐近方差性质来推导引导估计？

例如，假设我对某些数据拟合回归模型。使用渐近方差性质，我知道（对于特定类型的模型）：
$$ 
\begin{pmatrix} \hat{\beta}_1 \\ \hat{\beta}_2 \end{pmatrix} \sim N\left(\begin{pmatrix} \beta_1 \\ \beta_2 \end{pmatrix}, \begin{pmatrix} \sigma_{11} &amp; \sigma_{12} \\ \sigma_{12} &amp; \sigma_{22} \end{pmatrix}\right)
$$

现在，对于$s = 1,...,S$，我从多元正态分布中抽取样本分布：

生成：
$$\begin{pmatrix} \beta_1^{(s)} \\ \beta_2^{(s)} \end{pmatrix} \sim N\left(\begin{pmatrix} \hat{\beta}_1 \\ \hat{\beta}_2 \end{pmatrix}, \begin{pmatrix} \hat{\sigma}_{11} &amp; \hat{\sigma}_{12} \\ \hat{\sigma}_{12} &amp; \hat{\sigma}_{22} \end{pmatrix}\right)$$




假设我是对某个依赖于 $\hat{\beta_1}$ 和 $\hat{\beta_2}$ 的数量 $\hat{\theta}$ 感兴趣，例如 $\hat{\theta} = \hat{\beta_1} / \hat{\beta_2}$。这是一个不规则参数，根据模型推导方差的分析公式可能非常复杂。


我现在计算比率 $\theta^{(s)} = \beta_1^{(s)}/\beta_2^{(s)}$

并且 $\theta$ 的分布来自 $\{\theta^{(1)},...,\theta^{(S)}\}$


当无法使用引导方法时，这是一种获得置信区间的统计有效方法吗？也就是说，是否有可能引导回归系数（通过模拟它们的联合分布）而不是引导数据？

注意：需要特别注意确定回归系数的正确联合概率分布。
]]></description>
      <guid>https://stats.stackexchange.com/questions/657271/can-we-bootstrap-regression-coefficients-instead-of-data</guid>
      <pubDate>Thu, 14 Nov 2024 18:40:16 GMT</pubDate>
    </item>
    <item>
      <title>证明 $X=Y$ 几乎肯定 $\implies E[X] = E[Y]$</title>
      <link>https://stats.stackexchange.com/questions/657263/prove-x-y-almost-surely-implies-ex-ey</link>
      <description><![CDATA[我不太确定我们如何从概率得到期望。以下是我目前所得到的：

几乎肯定地假设 $X=Y$。根据定义，$P(X=Y)=1 \implies P(X-Y=0)=1$;
设 $Z=X-Y$，则 $P(Z=0)=1$;
（一些中间步骤）
$E(Z) = 0 \implies E[X] = E[Y]$。
]]></description>
      <guid>https://stats.stackexchange.com/questions/657263/prove-x-y-almost-surely-implies-ex-ey</guid>
      <pubDate>Thu, 14 Nov 2024 17:47:04 GMT</pubDate>
    </item>
    <item>
      <title>R：计算 party::cforest 的 AUC</title>
      <link>https://stats.stackexchange.com/questions/657255/r-calculating-auc-for-partycforest</link>
      <description><![CDATA[我有二元结果和多个协变量。我想计算拟合森林的 AUC（我正在使用 party::cforest 来拟合随机森林）。对我来说最令人困惑的部分是如何分成训练集和测试集，因为 party::cforest 已经使用袋外数据来测试森林。
现在我有以下代码，请告诉我我做错了什么（我使用 iris 数据集作为示例）：
library(caret)
library(party)
library(pROC)

iris$Species &lt;- iris$Species %&gt;%
fct_collapse(&quot;virginica&quot; = c(&quot;virginica&quot;, &quot;versicolor&quot;))
splitIndex &lt;- createDataPartition(
iris$Species, p = .75, list = FALSE, times = 1)

train_set &lt;- iris[ splitIndex,]
test_set &lt;- iris[-splitIndex,]

crf &lt;- party::cforest(Species ~ ., data = train_set, 
control = cforest_unbiased(mtry =2, ntree = 1500))
pred_response &lt;- predict(crf, test_set,type = &quot;response&quot;,OOB = TRUE)
roc &lt;- roc(train_set$Species, as.numeric(pred_response))
auc &lt;- auc(roc)
auc
]]></description>
      <guid>https://stats.stackexchange.com/questions/657255/r-calculating-auc-for-partycforest</guid>
      <pubDate>Thu, 14 Nov 2024 15:28:12 GMT</pubDate>
    </item>
    <item>
      <title>是否存在类似 Z 分数但适用于高度偏斜分布的东西？</title>
      <link>https://stats.stackexchange.com/questions/657246/is-there-something-like-z-score-but-for-highly-skewed-distributions</link>
      <description><![CDATA[我正在分析我的 anki 评论回答时间。由于我有大量数据（超过 14 年），评论之间存在差距，不同的学习模式也不同，所以我想以群组形式进行分析。
我想创建的一个指标是我对答案的“信心”：我想知道“与典型情况相差多远”特定答案是，但我想要一个可以在群组之间一致使用的指标（并在它们之间进行比较）。
我在一个类似的问题上找到了这个答案，它建议使用百分位数，但我认为百分位数并不能完全满足我的需求 - 有些群组的典型回答时间接近中位数，但也有一些群组远离中位数。
我可以使用例如（值 - 模式）/四分位数间范围作为我的指标吗？或者我可以使用类似的东西吗？
我知道我的回答时间严重右偏。]]></description>
      <guid>https://stats.stackexchange.com/questions/657246/is-there-something-like-z-score-but-for-highly-skewed-distributions</guid>
      <pubDate>Thu, 14 Nov 2024 12:25:53 GMT</pubDate>
    </item>
    <item>
      <title>如何计算这类数据之间的差异？</title>
      <link>https://stats.stackexchange.com/questions/657277/how-to-calculate-the-difference-between-this-type-of-data</link>
      <description><![CDATA[我有一个实验，观察频率振荡随时间的变化。我无法分析数据。
我想从我的数据集中获得：谷值之前的值的平均值，图谷内的平均值。

我只尝试过绘图，并试图识别 FWHM，但不幸的是，我们想要的是最小值。
Col1 - 以秒为单位的已用时间
Col2 - 频率
时间频率
33 9986054
34 9986054
35 9986054
36 9986054
37 9986054
38 9986054
39 9986054
40 9986054
41  9986054 42 9986054 43 9986054 44 9986054 45 9986054 46 9986054 47 9986054 48 9985915.8 49 9985732.9 50 9985549.7 51 998536 6.3 52 9985183.1 53 9984999.7 54 9984816.2 55 9984632.6 56 9984449 57 9984265.4 58 9984220 59 9984219.3 60 9984218.9 61 9984218.7
]]></description>
      <guid>https://stats.stackexchange.com/questions/657277/how-to-calculate-the-difference-between-this-type-of-data</guid>
      <pubDate>Thu, 14 Nov 2024 11:55:35 GMT</pubDate>
    </item>
    <item>
      <title>“使用动态评估赌博，O.Peters”中遍历性定义存在问题</title>
      <link>https://stats.stackexchange.com/questions/657131/a-problem-with-the-definition-of-ergodicity-in-evaluating-gambles-using-dynamic</link>
      <description><![CDATA[本文介绍了一个加性时间随机过程：
$$ W_{t+ \delta t \times T} - W_t = \sum^T_{i=1} D_i $$
其中 $W_t$ 表示时间 $t$ 的财富，$\delta t$ 是时间增量的长度，$D_i$ 是 iid 离散随机变量（对应于赌博）。
作者随后指出，这个过程是平稳的（平凡遍历的），因此我们应该有：
$$ \underset{T \rightarrow \infty}{\lim} \frac{1}{\delta t~ T} ( W_{t+ \delta t T} - W_t) = \frac{1}{\delta t}\mathbb{E}[D_1]$$
这应该是遍历系统中时间平均值和集合平均值的相等。
我的问题是：
LHS 不应该是吗
$$\underset{T \rightarrow \infty}{\lim} \frac{1}{\delta t~ T} \sum^T_{i=1} ( W_{t+\delta t \times i} - W_t)$$
也就是说我们必须在每个时间步骤上求和然后取平均值。我这里漏掉了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657131/a-problem-with-the-definition-of-ergodicity-in-evaluating-gambles-using-dynamic</guid>
      <pubDate>Tue, 12 Nov 2024 09:36:24 GMT</pubDate>
    </item>
    <item>
      <title>“当我们构建条件概率时，概率的相对比例保持不变。”是什么意思？</title>
      <link>https://stats.stackexchange.com/questions/657129/what-is-meant-by-when-we-construct-conditional-probabilities-the-relative-prop</link>
      <description><![CDATA[在课程“概率论简介”中，John Tsitsiklis 陈述了以下内容：
“当我们构建条件概率时，...，概率的相对比例保持不变。
条件概率与无条件概率成比例。 &quot;
讲座可在此处找到：https://www.youtube.com/watch?v=2f9EfEga4Oo&amp;list=PLUl4u3cNGP60hI9ATjSFgLZpbNJ7myAg6&amp;index=45&amp;ab_channel=MITOpenCourseWare
以及第 8 分 20 秒的声明。
如果没有额外的假设，这似乎是错误的。
如果条件概率与无条件概率成比例概率，则存在一个数字 $a_B$，该数字取决于 $B$ s.t。
$$a_B P(A) = P(A|B) = \frac{P(A\cap B)}{P(B)}$$
对于两个事件 $A, B$，其中 $P(B) &gt; 0$。这将导致
$$a_B P(A) P(B) = P(A\cap B)$$
如果 $A$ 和 $B$ 不相交且 $a_B = 0$ 或者如果 $A$ 和 $B$ 独立且 $a_B = 1$，则该结论成立。
一般情况下该结论不成立。例如考虑 $A$ 和 $0 &lt; P(A) &lt; 1$ 且 $B = A$。则 $a_A * P(A)^2 = P(A \cap A) = P(A)$ 且因此 $a_A = 1 / P(A)$。但是
$$a_A * P(A^c) * P(A) = P(A^c) \ne 0 = P(A \cap A^c)$$
有人能帮我更好地理解 J. Tsitsiklis 的陈述或它在什么条件下成立吗？
也许他指的是以下等式：
$$\frac{P(A\cap B)}{P(C\cap B)} = \frac{P(A\cap B)P(B)}{P(C\cap B)P(B)} = \frac{P(A|B)}{P(C|B)} $$
给定 $P(C \cap B) &gt; 0$，$P(B)&gt;0$。也就是说，条件概率与感兴趣的事件与条件交点的概率成比例，但我不确定我是否遗漏了什么，而且这不是他明确说的。]]></description>
      <guid>https://stats.stackexchange.com/questions/657129/what-is-meant-by-when-we-construct-conditional-probabilities-the-relative-prop</guid>
      <pubDate>Tue, 12 Nov 2024 09:15:35 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 MatchThem 和混合效应逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/657071/matchthem-and-mixed-effects-logistic-regression-in-r</link>
      <description><![CDATA[R 中的 MatchThem 和 Logistic 回归
我正在开展一项非随机研究，以评估两种治疗方法之间并发症发生率的差异。观察到的并发症发生率在两组之间有显著差异（22% vs. 50%）。为了考虑潜在的混杂因素，我计划使用二项式 Logistic 回归模型。鉴于样本量相对较小（130 名患者，分为 53 名 vs. 77 名），并且我的一个协变量（合并症）中存在 7 个缺失值，我选择使用 MICE（链式方程多重插补）方法插补缺失数据，以避免失去这些患者。代码如下：
# 估算缺失值
new_df_imputed &lt;- mice(selected_data, m = 5, maxit = 50, method = &quot;pmm&quot;, seed = 123)

接下来，我使用 MatchThem 包执行倾向得分匹配 (PSM)：
# 在每个估算数据集中执行匹配
m.out_model1 &lt;- matchthem(Treatment_type_tumor_near_gallbladder ~ age + sex + bmi + ASA + comorbidities + Systemic_treatment_prior_local_treatment + Segments_treated_per_session + Metastasis_size_at_treatment_mm + min_distance_gallblad_mm + stage, 
data = new_df_imputed, 
method = &quot;nearest&quot;, 
distance = &quot;logit&quot;,
replace = TRUE,
ratio = 3,
caliper = 0.2) 

匹配过程实现了良好的平衡，结果令人满意：
平衡平均差异计数
count
平衡，&lt;0.1 16
不平衡，&gt;0.1 2

平均差异最大的变量
Variable Max.Diff.Adj M.Threshold
Segments_treated_per_session 0.1602 不平衡，&gt;0.1

插补的平均样本量
0 1
全部 53. 77. 
匹配（ESS） 29.34 67.8
匹配（未加权） 46.8 67.8
不匹配 6.2 9.2

之后，我实施了一个多变量使用以下代码进行分析：
结果 &lt;- with(m.out_model1, svyglm(complications ~ Treatment_type_tumor_near_gallbladder + age + sex + bmi + ASA + comorbidities + Systemic_treatment_prior_local_treatment + Segments_treated_per_session + Metastasis_size_at_treatment_mm + min_distance_gallblad_mm + stage,
family = quasibinomial()))

输出 &lt;- pool(results, dfcom = NULL)

summary(output, exponentiate = TRUE, conf.int = TRUE) %&gt;% 
mutate(across(where(is.numeric), round, digits = 3))

问题 1：
svyglm 函数是否自动考虑因为我进行了替换匹配并使用了 3:1 的比例？
问题 2：
是否可以对模型摘要执行向后消除过程？这有意义吗？
提前感谢您的任何建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/657071/matchthem-and-mixed-effects-logistic-regression-in-r</guid>
      <pubDate>Mon, 11 Nov 2024 10:50:46 GMT</pubDate>
    </item>
    </channel>
</rss>