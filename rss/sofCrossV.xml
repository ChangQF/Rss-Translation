<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 09 Jan 2024 21:12:14 GMT</lastBuildDate>
    <item>
      <title>模型如何学习 Transformer NN 架构中的权重和偏差？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/636526/how-does-the-model-learn-the-weights-and-biases-in-a-transformer-nn-architecture</link>
      <description><![CDATA[在输入嵌入矩阵和层归一化之间的转换器块中，数据被缩放为平均值 = 0，标准差 = 1。神经网络如何学习权重和偏差并将其应用于数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/636526/how-does-the-model-learn-the-weights-and-biases-in-a-transformer-nn-architecture</guid>
      <pubDate>Tue, 09 Jan 2024 18:00:11 GMT</pubDate>
    </item>
    <item>
      <title>使用神经网络求解等式系统</title>
      <link>https://stats.stackexchange.com/questions/636524/solving-a-system-of-equalities-using-a-neural-network</link>
      <description><![CDATA[假设$P$是一组对$(x, y)$，
其中 $x$ 和 $y$ 都在 $ 中\mathbb{R}^n$。
假设 $P&#39;$ 是 $P$ 的子集。
我想训练一个神经网络
$N: \mathbb{R}^n \to \mathbb{R}^m$
这样，对于 $P&#39;$ 中的任何对 $(x, y)$，
我得到 $N(x) = N(y)$。
我们将此约束称为 $C_1$。
我还想强制执行一些其他约束
在 $P \setminus P&#39;$ 上，
当
$C_1$ 也满足 $(x, y)$ in $P \setminus P&#39;$。
例如，当 $m = 1$ 时，
我将 $C_2$ 定义为 $N(x) - N(y) \geq 1$
对于 $P \setminus P&#39;$ 中的所有 $(x, y)$。
我观察到，训练后，
几乎总是发生以下情况之一：

$N$ 成为 $C_1$ 的简单答案；
例如，对于任何 $x$，$N(x) = 0$。
$N$ 满足除 $C_1$ 之外的所有约束。

为什么几乎总是这样？
有没有办法避免这种情况，
例如通过在我的损失函数中添加一些项？
编辑：添加了另一个约束的示例。]]></description>
      <guid>https://stats.stackexchange.com/questions/636524/solving-a-system-of-equalities-using-a-neural-network</guid>
      <pubDate>Tue, 09 Jan 2024 17:38:03 GMT</pubDate>
    </item>
    <item>
      <title>$p$-黑客攻击和嵌套模型</title>
      <link>https://stats.stackexchange.com/questions/636523/p-hacking-and-nested-models</link>
      <description><![CDATA[我有一个模型 $\vec{y}=X\vec{\beta}+\vec{\varepsilon}$ ，具有高斯独立误差 $\vec{\varepsilon}\sim N(\vec{0},\sigma^2I_n)$。让$n$表示$X$和$d$ 表示 $X$ 的排名。我想测试以下形式的几个假设：
T_1 中的 $\vec{\beta}\、T_2 中的 \quad \vec{\beta}\、T_3 中的 \quad \vec{\beta}\... \quad \vec{\beta}\in T_n$
其中 $T_1\subset T_2\subset T_3...$ 是子空间链。例如，在双向方差分析中，$T_1$ 可能是“所有处理和类别中的所有均值相等”的子空间。并且 $T_2$ 可能是“平均值取决于治疗而不是类别”的子空间，$T_3$可能是“均值取决于治疗和类别，以没有交互作用的因素的方式”的子空间。我的目标是在没有 $p$ 黑客攻击的情况下测试这些假设。
让$S=col(X)$，$S_{T_i}=X(T_i)$ span&gt; 和 $S&#39;_{T_i}$ 是 $T_i$ 中  的正交补集class=&quot;math-container&quot;&gt;$S$，在假设$\vec{\beta}\in T_i$下，我有：
$\frac{\|{\rm proj}_{S&#39;_{T_i}}(\vec{y}-X\beta)\|^2/\暗淡(S&#39;_{T_i})}{\hat{\sigma}^2}=\frac{\|{\rm proj}_{S&#39;_{T_i}}(\vec{y})\|^ 2/\dim(S&#39;_{T_i})}{\hat{\sigma}^2}\sim F(\dim(S&#39;_{T_i}),n-d)$
我想测试这些假设。据推测，在早期的 $T_i$ 很容易被证伪而后期的更难以证伪的假设下，个体 $每个测试的 p$ 值一开始会非常低，并且对于较大的 $T_i$ 会变得更高。
这显然与查看独立假设检验和$p$非常不同 - 通过黑客手段拒绝真实的假设。毕竟，如果 $\beta\in T_k$ 被拒绝，那么人们可能会期望 $\beta\in T_{i&lt; ;k}$ 也会被拒绝。但我仍然担心 $p$ - 黑客攻击 - 有没有一种方法可以严格执行顺序测试假设并拒绝直到某个 $p$-值是否达到？]]></description>
      <guid>https://stats.stackexchange.com/questions/636523/p-hacking-and-nested-models</guid>
      <pubDate>Tue, 09 Jan 2024 17:28:15 GMT</pubDate>
    </item>
    <item>
      <title>双变量逻辑回归的单变量方法</title>
      <link>https://stats.stackexchange.com/questions/636522/univariate-approach-to-a-bivariate-logistic-regression</link>
      <description><![CDATA[考虑这样一种情况，两个独立的代理（一组许多代理中的一个）查看同一问题并尝试用是/否响应来解决它，获得 $(Y_ {i1},Y_{i2})$ 为 $i \in {1,...,N}$。每个特工都经过严格训练，他们经常得出相同的结论。如果我们有一组任务 $X_i$ 的协变量，它们影响我们希望收集信息的每个决策，则可以将其视为同时建模的多变量问题&lt; span class=&quot;math-container&quot;&gt;$(Y_{i2},Y_{i2})$ 使用 logit 或 probit 链接函数。两个代理之间的“协议”可以从两个潜在响应变量之间的协方差矩阵推断出来。在概率示例中，这类似于：
$$(Y_1^*,Y_2^*) \sim MVN((\mu_1,\mu_2),\Sigma)$$
其中 $Y_i = \{1 \text{ if } Y_1^* &gt; 0, \text{ 0 否则}\} $, $\Sigma = \big(\begin{matrix}
  \sigma_1 &amp; \sigma_{12}\\
  \sigma_{12} &amp; \sigma_2
\end{矩阵}\大)$
和 $\mu_i = \beta X_i$。
如果多变量方法由于某种原因不可行（在我的例子中，由于软件与其他建模选择不兼容），是否可以通过组合响应向量对每个决策独立建模来解决问题到单个 $Y_j$ 中用于 $j \in 1,...,2N$ 响应并使用因子变量来区分两者？例如，概率回归将类似于：
$$\mu_j = \beta_0 + \beta_1OtherDecision_j + \beta_3FirstOrSecond_j + \beta X_j$$ 对于 $j \在 {1,...,2N}$ 中使用正态分布。
在这种方法中，$FirstOrSecond_j$变量有效地模拟了每个代理接受率的不同截距和$OtherDecision_j $ 模拟两个代理之间的协议强度。我认为它们之间的唯一区别是选择组合或划分方差元素，但我找不到任何关于之前已完成或考虑过的参考。]]></description>
      <guid>https://stats.stackexchange.com/questions/636522/univariate-approach-to-a-bivariate-logistic-regression</guid>
      <pubDate>Tue, 09 Jan 2024 17:18:34 GMT</pubDate>
    </item>
    <item>
      <title>解释物理系统非归一化协方差矩阵的特征值</title>
      <link>https://stats.stackexchange.com/questions/636521/interpreting-eigenvalues-of-non-normalized-covariance-matrix-of-physical-system</link>
      <description><![CDATA[从物理 stackexchange 交叉发布
摘要：“非标准化”特征值线性系统的时间序列测量值的协方差矩阵具有动作单位（能量 * 时间）。我们可以解释这一点以获得有意义的统计阈值吗？
最近，我一直在为永磁直流电机驱动的机构的开源系统识别工具做一些志愿者工作。这些非常接近理想的 LTI 系统，因此我们已经成功地使用 OLS 和派生技术解决了该问题。
我们的分析涉及施加驱动信号时机械系统的电压、速度和加速度的时间序列测量。我们对电机的电压平衡方程进行 OLS 拟合，其中方差最大的测量变量（通常是加速度）作为因变量，其他变量作为预测变量。然后使用该 OLS 中的参数来计算电机的控制增益。
这种方法在大多数情况下效果很好，但对于没有经验的用户来说，很难诊断何时由于采样不足而导致拟合无效，并且计算出的控制增益不可信。一种有前途的方法似乎是执行主成分分析，以确定哪些信号采样得足够好，足以保证包含在 OLS 中 - 例如，我们可以查找非归一化协方差矩阵的特征值（数据矩阵乘以其转置）低于显着性阈值，并从拟合中移除“最接近”的参数。到匹配的特征向量。
但是，虽然我们发现这在实践中效果很好，但我对如何解释上述过程的（实验确定的）阈值感到困惑。朴素的量纲分析表明，在适当的物理转换之后，“阈值”会降低。单位为焦耳 * 秒 - 动作的物理单位。这是什么意思？我们能否根据第一原理估计一个合适的阈值？
更一般地说，是否存在概念上的原因，即“动作”似乎是“样本大小”的自然单位？在这样的统计物理实验中？我知道系统识别不是“传统上”的。被视为统计物理学，但这里似乎有相似之处，我想知道类比是否可以帮助解释。]]></description>
      <guid>https://stats.stackexchange.com/questions/636521/interpreting-eigenvalues-of-non-normalized-covariance-matrix-of-physical-system</guid>
      <pubDate>Tue, 09 Jan 2024 17:10:57 GMT</pubDate>
    </item>
    <item>
      <title>用于求解最小二乘法的贝叶斯优化</title>
      <link>https://stats.stackexchange.com/questions/636516/bayesian-optimization-for-solving-least-squares</link>
      <description><![CDATA[当评估要最小化的函数（例如 $f(a)$）计算成本较高时，使用高斯过程 (GP) 的贝叶斯优化是一种有效的最小化方法.
粗略地说，该策略需要一个 GP，选择模拟 $f$ 但更容易计算。
让我们假设 $f(a) = (g(a) - y)^2$，其中  $y$ 是一组数据点，$g(a)$ 是计算密集型仿真模型的结果。
我们希望找到 $a$ 的值 $a_0$，使得计算密集型模型 $g(a)$“再现”数据$y$。
与 $g(a)$ 相比，$f(a)$ 现在有了一些新属性（例如，它在 $a=a_0$ 周围为正且凸，而 $g(a)$可能并非如此），而典型的高斯过程（以零为中心）并不是它的良好替代。文献是否提供了包含这些特性的 GP 的替代方案？或者我错过了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/636516/bayesian-optimization-for-solving-least-squares</guid>
      <pubDate>Tue, 09 Jan 2024 15:20:01 GMT</pubDate>
    </item>
    <item>
      <title>在多元回归中选择预测变量</title>
      <link>https://stats.stackexchange.com/questions/636512/choosing-predictors-in-multiple-regression</link>
      <description><![CDATA[我正在计划回归分析并提出这个（假设的）场景来传达我的查询。
我对两种不同的衡量标准（“IQ”和“SPQ”）对因变量“绩效”的影响感兴趣。方差膨胀因子表明不存在共线性问题，但两个变量相关（r = ~0.6）。
我运行单独的线性回归来预测性能：

表现 ~ 智商
性能 ~ SPQ

场景 1：分析 1) 和 2) 显示 IQ 和 SPQ 可以显着预测性能。因此，我决定在控制 SPQ 时运行多元回归来隔离 IQ 的影响（反之亦然）：

性能 ~ IQ + SPQ

问题 1- 我相信即使预测变量只是弱相关，我也需要运行此多元回归？
场景 2：分析 1) 和 2) 表明只有 IQ 可以显着预测表现。
问题 2- 我是否正确，因此我不需要运行分析 3)，因为 SPQ 不能显着预测性能？或者也许这个分析仍然有助于表明 IQ 具有独立于 SPQ 的影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/636512/choosing-predictors-in-multiple-regression</guid>
      <pubDate>Tue, 09 Jan 2024 14:56:43 GMT</pubDate>
    </item>
    <item>
      <title>验证数据集的留一性能差异</title>
      <link>https://stats.stackexchange.com/questions/636511/leave-one-out-performance-variance-on-validation-dataset</link>
      <description><![CDATA[我在留一验证方面表现良好（不留一，留二，每个类一个），但在我的验证集中尝试时，性能不太好，精度为 85%至 60%。
上下文：
我读过之前的一些答案，但是，我有一些不同的看法，我正在研究一个类似于时间序列的数据集。我正在尝试对二进制标签进行分类，我尝试了一些算法，如 knn、svm 和决策树，但它们都不起作用，所以我们开始尝试神经网络（Keras）。我在 k 折交叉验证上得到了这样的性能，学习曲线很快就会过度拟合，损失验证很容易中断，不知道还能尝试什么，欢迎对下一篇文章提出任何建议，谢谢。
一些澄清，我的数据集没有那么大，有 300 个样本，并且不完全平衡，因此当过度拟合直接仅预测一类时，已经尝试平衡数据集并获得更好的结果]]></description>
      <guid>https://stats.stackexchange.com/questions/636511/leave-one-out-performance-variance-on-validation-dataset</guid>
      <pubDate>Tue, 09 Jan 2024 14:40:27 GMT</pubDate>
    </item>
    <item>
      <title>pdf 的高度只是一个相对频率：这是正确的吗？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/636501/the-height-of-the-pdf-is-just-a-relative-frequency-is-that-correct</link>
      <description><![CDATA[我知道pdf函数不是概率，曲线下的面积之和必须为1。我理解pdf函数的高度是没有意义的，它不是概率而是概率的密度。
我可以说 pdf 的高度告诉我们随机变量的哪个值比其他值更有可能出现吗？
例如，以下答案来自 ChatGpt。
让我们考虑一个与儿童体重相关的数值示例。假设我们有一个儿童体重数据集，该数据集服从正态分布，平均值为 50 公斤，标准差为 5 公斤。
对于孩子 A，假设他们的体重是 55 公斤。我们可以使用 dnorm() 函数计算该权重下的概率密度：
dnorm(x = 55, 均值 = 50, sd = 5)
所得概率密度是一个数值，表示在给定正态分布内观察到 55 公斤体重的可能性。
对于孩子 B，假设他们的体重是 45 公斤。同样，我们可以计算出该权重下的概率密度：
dnorm(x = 45，平均值 = 50，sd = 5)
这将为我们提供 45 公斤重量在正态分布内的概率密度。
比较 Child A 和 Child B 的概率密度将深入了解分布内这些值周围权重的相对集中度。概率密度越高表明权重越接近该特定值就越有可能出现。]]></description>
      <guid>https://stats.stackexchange.com/questions/636501/the-height-of-the-pdf-is-just-a-relative-frequency-is-that-correct</guid>
      <pubDate>Tue, 09 Jan 2024 13:11:23 GMT</pubDate>
    </item>
    <item>
      <title>证明二次回归样条在结处是连续的？</title>
      <link>https://stats.stackexchange.com/questions/636499/proof-that-quadratic-regression-splines-are-continuous-at-the-knots</link>
      <description><![CDATA[标题说明了一切。有关更多信息：我有一个因变量和自变量 $y$ 和 $X$。我想在给定单个结 $k$ 的数据上拟合方形样条。我可以通过在 $X\le k$ 和 $X&gt;k$&lt; 区域中拟合 2 个单独的平方函数来实现这一点/span&gt; 的约束是它们必须在 $X=k$ 处有一个公共点，通过拟合（OLS）以下回归方程：
$$
y_t = \beta_0 + \beta_1 X_t + \beta_2 X_t^2 + \beta_3 (X_t-k)_+ + \beta_4(X_t-k)_+^2 + \varepsilon_t
$$
其中 $(X-k)_+ = max(X-k, 0)$ 是截断函数。
但是，得到的拟合在 $k$ 处是不连续的，例如：（此处 $k=2.5$跨度&gt;)

为了使拟合在 $k$ 处连续，只需删除截断函数的低阶项，即，这与上面相同，没有 &lt; span class=&quot;math-container&quot;&gt;$\beta_3 (X_t-k)_+ $ （另请参阅 此视频）：
$$
y_t = \beta_0 + \beta_1 X_t + \beta_2 X_t^2 + \beta_4(X_t-k)_+^2 + \varepsilon_t
$$
现在我在 $X=k$ 处得到一个连续函数（一阶导数）：

问题是：为什么？
如果我对 $k$ 之前和之后的函数求导，我会得到：
$$f&#39;(X)=\beta_1 + 2\beta_2 X_t + 2\beta_4 (X_t&gt;k) $$

在$k$之前：$f&#39;(k)=\beta_1 + 2\beta_2 k + 0 $&lt; /跨度&gt;
在 $k$ 之后（意思类似于 $\lim_{X\to k, X &gt; k}{ (f&#39;(X))}$: $f&#39;(k)=\beta_1 + 2\beta_2 k + 2\beta_4k $，因为 &lt; span class=&quot;math-container&quot;&gt;$ (X_t-k)_+$ 仅在 $X_t&gt;k$ 时才处于活动状态。

所以两者是不同的，一个包含 $2\beta_4k$ 另一个不包含。它们有何相同之处？]]></description>
      <guid>https://stats.stackexchange.com/questions/636499/proof-that-quadratic-regression-splines-are-continuous-at-the-knots</guid>
      <pubDate>Tue, 09 Jan 2024 12:46:31 GMT</pubDate>
    </item>
    <item>
      <title>自协方差生成函数的推导背后的逻辑？</title>
      <link>https://stats.stackexchange.com/questions/636494/the-logic-behind-the-derivation-of-the-autocovariance-generating-function</link>
      <description><![CDATA[我正在处理复杂的时间序列集，其中观察到的系统输出是许多单独的 ARMA、误差和噪声序列的总和。因此，我正在寻找识别这些单独序列的方法（或者至少从聚合自协方差和谱密度函数的各种特征推测可能的序列）。
作为此过程的一部分，我需要使用自协方差生成函数作为将 ARMA 模型的无限移动平均表示转换为其各自的自协方差和功率谱密度函数的简单方法。
但是，我正在努力理解自协方差生成函数背后的逻辑。我已阅读并注意到这篇文章（如何从自协方差生成函数中检索自协方差的信息？）但它没有解释为什么可以进行推导。我同样读过汉密尔顿的“时间序列”并遵循他对 ACVGF 的推导 - 但仍不清楚原因。
我能找到的最完整的推导是这样的：
例如，假设 $X_t$ 是一个线性过程，可以写成：
\begin{方程}
X_t = \sum_{i=0}^\infty \psi_iW_{t-i} = \psi\left(B\right)W_t
\end{方程}
然后是自协方差函数：
\begin{方程} \gamma_h=\mathrm{Cov}\left(X_t,\,X_{t+h}\right)=\mathrm{E}\left[\sum_ {i=0}^\infty \psi_iW_{t-i}\sum_{j=0}^\infty \psi_jW_{t+h-j}\right]=\sigma_w^2\sum_{i=0}^\infty \psi_i \psi_{i+h}
\end{方程}
将自协方差生成函数定义为：
\begin{方程}
g_{\gamma}\left(B\right)=\sum_{h=-\infty}^\infty
\gamma_h B^h
\end{方程}
然后：
\begin{方程}
g_{\gamma}\left(B\right)=\sigma_w^2\sum_{h=-\infty}^\infty\sum_{i=0}^\infty \psi_i\psi_{i+h}
B^h=\sigma_w^2\sum_{i=0}^\infty\sum_{j=0}^\infty \psi_i\psi_{j}B^{j-i}=\sigma_w^2\sum_{i= 0}^\infty \psi_iB^{-i}\sum_{j=0}^\infty \psi_j B^j=\sigma_w^2\psi\left(B^{-1}\right)\psi\left （明亮的）
\end{方程}
那么如果我们注意到：
\begin{方程}
g_{\gamma}\left(B\right)=\sum_{h=-\infty}^\infty
\gamma_hB^h
\end{方程}
和：
\begin{方程}
f\left(\omega\right) = \sum_{h=-\infty}^\infty
\gamma_h \mathrm{e}^{-2\pi i \omega h} = \gamma\left(\mathrm{e}^{-2\pi i \omega}\right)=\sigma_w^2\psi\左(\mathrm{e}^{-2\pi i \omega}\right)\psi\left(\mathrm{e}^{2\pi i \omega}\right)=\sigma_w^2\left| \psi\left(\mathrm{e}^{2\pi i \omega}\right)\right|^2
\end{方程}
因此，如果线性过程的形式可以表示为无限移动平均，那么谱就可以自动确定。
我们怎样才能定义自协方差生成函数呢？是什么让我们可以将后移运算符 (B) 与复数值标量互换使用？这如何允许通过这种替换直接确定光谱？
我认为这个推导中缺少一些隐含的逻辑步骤 - 它们是什么以及如何用简单的术语解释它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/636494/the-logic-behind-the-derivation-of-the-autocovariance-generating-function</guid>
      <pubDate>Tue, 09 Jan 2024 12:07:21 GMT</pubDate>
    </item>
    <item>
      <title>如何编写 ARIMA (1,1,2) 方程？</title>
      <link>https://stats.stackexchange.com/questions/636492/how-do-i-write-the-equation-of-an-arima-1-1-2</link>
      <description><![CDATA[我从函数 auto.arima() 获得了以下输出：

这是写方程的正确方法吗？

或者应该是这样的？
]]></description>
      <guid>https://stats.stackexchange.com/questions/636492/how-do-i-write-the-equation-of-an-arima-1-1-2</guid>
      <pubDate>Tue, 09 Jan 2024 11:34:57 GMT</pubDate>
    </item>
    <item>
      <title>如何在多元回归中找到标准误差[重复]</title>
      <link>https://stats.stackexchange.com/questions/636491/how-to-find-standard-error-in-multiple-regression</link>
      <description><![CDATA[我知道如何在单一回归中找到标准误差，但在多元回归中存在多个标准误差，我不明白该怎么做。我不断地寻找，但没有找到。
例如，如何分别找到 x、m 和常数的标准误差？如果您能帮助我，我将非常高兴。]]></description>
      <guid>https://stats.stackexchange.com/questions/636491/how-to-find-standard-error-in-multiple-regression</guid>
      <pubDate>Tue, 09 Jan 2024 10:45:02 GMT</pubDate>
    </item>
    <item>
      <title>潜在基础模型的 p 值</title>
      <link>https://stats.stackexchange.com/questions/636469/p-values-of-latent-basis-models</link>
      <description><![CDATA[我正在运行一个潜在的基础模型，想知道是否有人可以提供
了解如何解释基础系数的 p 值。
基础系数在T1设置为0，在T9设置为1，其他自由估计
在这个模型中。
非标准化系数如下。

我的问题是，“如何解释 T2 到 T6 的 p 值？”
他们的意思是，

时间 X 的基础系数与相邻时间点显着不同。
或


时间 X 的基系数与时间 1 显着不同（等于
增长至 0%）。

与此相关的另一个问题是，
如果答案是1.，你如何获得该时间点斜率的显着性？
感谢大家总是为我指明解决问题的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/636469/p-values-of-latent-basis-models</guid>
      <pubDate>Tue, 09 Jan 2024 02:38:22 GMT</pubDate>
    </item>
    <item>
      <title>通过因子分析获取大量缺失数据的个人水平分数</title>
      <link>https://stats.stackexchange.com/questions/636464/getting-individual-level-scores-from-factor-analysis-with-lots-of-missing-data</link>
      <description><![CDATA[我在一个环境中进行因子分析，其中有很多行，并且缺少约 90% 的数据（这是一项针对数十万人的调查，每个人都被随机询问了 10 个选项）出于篇幅原因，从约 200 个项目中提出问题（每五个主要领域中两个）。
估计因子模型非常简单：
fa_result &lt;- fa（dat_sapa，nfactors = 5，use =“pairwise”，rotate =“oblimin”，scores=“tenBerge”）

但是，如果您缺少数据，那么 psych 包似乎并不能真正用于生成分数（可以选择使用中值/均值插补进行评分，但在这种情况下这将是相当疯狂的）。
有人对如何以适合高稀疏性的方式生成因子分析分数有任何建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636464/getting-individual-level-scores-from-factor-analysis-with-lots-of-missing-data</guid>
      <pubDate>Tue, 09 Jan 2024 00:27:25 GMT</pubDate>
    </item>
    </channel>
</rss>