<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 26 Dec 2024 21:15:02 GMT</lastBuildDate>
    <item>
      <title>尾部概率期望公式</title>
      <link>https://stats.stackexchange.com/questions/659242/tail-probability-expectation-formula</link>
      <description><![CDATA[在以下论文的第一页：https://arxiv.org/pdf/2301.10985
进行了以下计算：
$K \in R^+$ 是阈值
随机变量 $X \in R^+$ 的 f(.) 密度函数
$P_K = P(X&gt;K) \in [0,1]$ 超过该值的概率
$g(x): R^+ \rightarrow R$ 影响函数
$G_K = \int_K^{\infty} g(x)f(x)dx (1)$
K 处的互补 CDF 函数：
$P_K = \int_K^{\infty} f(x) dx(2)$
错误来自于将 GK 的属性与 PK 的属性混为一谈，通常将 PK 与某个常数相关联，该常数表示与阈值 K 相关的假定影响
差异的直觉可以显示如下：
假设 g(x) = x，对于 X 具有有限首阶矩的随机变量，我们专注于正域，推广尾部概率期望公式，
$G_K = KP_K + \int_K^{\infty} P_x dx$
第一项是方程 1 的直接应用，在积分开始时使用 $g(x)=x$，这样对吗？
我很困惑为什么 x 没有出现在第二项中，有人能解释一下吗？
$G_K = \int_K^{\infty} xf(x)dx$ $\neq$ $\int_K^{\infty} f(x) dx$ $=$ $\int_K^{\infty} P_x dx$]]></description>
      <guid>https://stats.stackexchange.com/questions/659242/tail-probability-expectation-formula</guid>
      <pubDate>Thu, 26 Dec 2024 20:53:03 GMT</pubDate>
    </item>
    <item>
      <title>根据给定的累积分布 (CDF) 生成概率密度函数 (PDF)</title>
      <link>https://stats.stackexchange.com/questions/659241/make-a-probability-density-function-pdf-from-a-given-cumulative-distribution</link>
      <description><![CDATA[我有一个逆向工程问题：一台机器导出纯文本、具有 7 个百分位数 (CDF_7) 的 CDF 和一个标准差。
我使用 CDF_7 百分位数来计算 PDF。
我计算的 PDF（左，绿色）（使用导出数据 CDF_7，蓝色）与机器中的 PDF（右，红色）不同。理想情况下，PDF 应该相等。

我做错了什么？在下面的函数中，我在百分位数之间插入值。在解决这个问题时，使用标准差有用吗？有没有想过标准差在这里有什么用？
我的 Python 代码：
 import numpy as np
import matplotlib.pyplot as plt

def epdf_hist(cdf_7pct, pct, bins_std):
&quot;&quot;&quot;基于累积分布函数 (CDF) 的 7 个百分位值制作直方图 - 经验概率密度函数 (PDF)

将 7 个百分位值插值到 100 个值，然后分箱
:parameter
cdf_7pct：包含 7 个值的 1 维数组，按从高到低排序
pct：7 个百分位数，通常为 [1,5,10,50,90,95,99]
bins_std：包含箱体的 1 维数组，宽度 = 0.2
:returns
100 个插值、分箱值的 pdf，
bins
100 个插值
&quot;&quot;&quot;
d_pct = np.diff(pct)
cdf_100pct = [] # 生成 100 个值
# 在给定的百分位数值之间进行插值
for i in range(0, len(d_pct)):
arr = np.linspace(cdf_7pct[i], cdf_7pct[i + 1], num=d_pct[i], end=False) # 最后进行插值
cdf_100pct.extend(arr)
cdf_100pct.extend([cdf_7pct[-1]]) # 添加最后一个
cdf_100pct.extend([min(cdf_7pct)+(min(cdf_7pct) - min(arr))]) # 添加一个额外的
count, bins_count = np.histogram(cdf_100pct, bins=bins_std)
返回 count, bins_count, cdf_100pct

# 累积分布函数 (CDF_7) 导出数据
data = np.array([42.38, 42.31, 42.23, 42.03, 41.83,41.81,41.66])
perc = [1,5,10,50,90,95,99]
stdev = 0.15

# 来自机器的 CDF 值
targetbins = np.array([41.6,41.8, 42.0, 42.2,42.4])
c_targetperc = np.array([100,97,58,12,0])
# 来自机器的 PDF 值
p_targetperc = np.array([3,39,46,12,0])

# 计算
epdf_hist_count, epdf_hist_binscount, cdf_100pct = epdf_hist(data, perc, targetbins)
# 图
fig = plt.figure(figsize=(9, 4), layout=&quot;constrained&quot;)
axs = fig.subplots(1, 2, sharex=True, sharey=True)
axs[0].hist(cdf_100pct,bins=targetbins, density=False, color = &#39;green&#39;, alpha = 0.5, label=&quot;PDF i 计算自 CDF_7&quot;)
axs[1].bar(targetbins,p_targetperc, color=&#39;red&#39;, edgecolor=&#39;black&#39;, width=0.2, align=&#39;edge&#39;, alpha = 0.5，label=&quot;机器中的 PDF&quot;)
axs[1].plot(data,perc, &#39;bo--&#39;, label=&quot;从机器导出：CDF_7&quot;)
fig.suptitle(&quot;分布比较&quot;)
for ax in axs:
ax.grid(True)
ax.legend()
ax.set_xlabel(&quot;dB&quot;)
ax.set_ylabel(&quot;发生概率&quot;)
ax.label_outer()
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/659241/make-a-probability-density-function-pdf-from-a-given-cumulative-distribution</guid>
      <pubDate>Thu, 26 Dec 2024 19:50:59 GMT</pubDate>
    </item>
    <item>
      <title>数据中的季节性问题</title>
      <link>https://stats.stackexchange.com/questions/659240/seasonality-problem-in-a-data</link>
      <description><![CDATA[我有一个系列。我在 J-demetra 做季节性测试。数据是每月的，从 2003:01 到 2024:07。

我该如何处理这个季节性？请建议方法或程序？]]></description>
      <guid>https://stats.stackexchange.com/questions/659240/seasonality-problem-in-a-data</guid>
      <pubDate>Thu, 26 Dec 2024 19:23:11 GMT</pubDate>
    </item>
    <item>
      <title>Efron 和 Tibshirani 在教科书《引导程序简介》中所说的‘经验指数族’是什么意思？</title>
      <link>https://stats.stackexchange.com/questions/659239/what-do-efron-tibshirani-mean-by-the-empirical-exponential-family-in-the-tex</link>
      <description><![CDATA[我想了解教科书《引导法简介》（例如公式 21.84）中 Efron &amp; Tibshirani 所说的“经验指数族”是什么意思？
那里的解释对我来说太简略和/或太模糊了，而且关于这个主题的更深入的研究文章看起来很难理解。
如果能了解基础知识，我将不胜感激：分布族由分布组成。这些分布是空间上的概率测度。分布所在的空间是什么（定义在哪个空间上）？它似乎是来自经验分布的高维点乘积，但我不确定。
他们如何计算 \eta 的 Fisher 信息？ （公式 21.86）
他们是否使用经验指数族作为数据分布（x_i），从数据计算出的充分统计数据分布（q），还是两者兼而有之？
如果您能给出一个简单易懂的答案，包括或补充我误解或遗漏的任何内容，我将不胜感激。我理解答案可以深入到经验可能性、熵和散度测量等。如果您想将其作为额外内容，那就太好了，但请不要将其作为理解基本要点的先决条件。]]></description>
      <guid>https://stats.stackexchange.com/questions/659239/what-do-efron-tibshirani-mean-by-the-empirical-exponential-family-in-the-tex</guid>
      <pubDate>Thu, 26 Dec 2024 18:42:47 GMT</pubDate>
    </item>
    <item>
      <title>在重复测量的纵向数据随机截距模型中，基线是否必要？</title>
      <link>https://stats.stackexchange.com/questions/659238/is-baselining-necessary-in-a-random-intercepts-model-of-longitudinal-data-with-r</link>
      <description><![CDATA[我有 m 个样本，每个样本有 n 次重复测量。样本被平均分为治疗组和对照组。我使用随机效应建模策略，对每个个体进行随机截距。鉴于我控制了随机截距，我是否仍然需要通过他们在时间 0 即应用第一次治疗之前的测量来对每个个体的测量进行标准化？]]></description>
      <guid>https://stats.stackexchange.com/questions/659238/is-baselining-necessary-in-a-random-intercepts-model-of-longitudinal-data-with-r</guid>
      <pubDate>Thu, 26 Dec 2024 18:38:05 GMT</pubDate>
    </item>
    <item>
      <title>大尺寸 Metropolis 抽样</title>
      <link>https://stats.stackexchange.com/questions/659237/metropolis-sampling-for-large-dimension</link>
      <description><![CDATA[令 $\theta = (\theta_1, \theta_2)$ 为感兴趣的变量，密度为 $p_{\theta}$。我们假设密度以及边际密度 $p_{\theta_1}$ 和 $p_{\theta_2}$ 已知但难以生成。我决定使用 Metropolis 算法对 $\theta$ 进行采样。假设我使用一个正态提议分布，其单位矩阵作为协方差，当前值作为均值。
我有两个选择：一个是使用维度等于$\theta$的正态分布，并使用提议分布直接生成$\theta$。另一个选择是使用某种Metropolis-in-Gibbs算法，该算法在$\theta_1$中使用Metropolis步骤，然后在$\theta_2$上使用Metropolis步骤。
一般来说，哪一个更有效？在实践中，我觉得第一个效率较低，接受概率较低。但有什么理由吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659237/metropolis-sampling-for-large-dimension</guid>
      <pubDate>Thu, 26 Dec 2024 17:33:55 GMT</pubDate>
    </item>
    <item>
      <title>估计量与合并 OLS/随机效应之间</title>
      <link>https://stats.stackexchange.com/questions/659235/between-estimator-versus-pooled-ols-random-effects</link>
      <description><![CDATA[例如，我熟悉 Hausman 检验可以帮助我选择固定效应模型和随机效应模型中哪个更好。但是，是否有一个测试可以帮助我在估计模型（在 R 中使用 plm (y~x, model=&quot;between&quot;) 实现）与池化 OLS（plm(y~x, model=&quot;pooling&quot;）和随机效应模型（plm(y~x, model=&quot;random&quot;）之间进行选择？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659235/between-estimator-versus-pooled-ols-random-effects</guid>
      <pubDate>Thu, 26 Dec 2024 16:59:24 GMT</pubDate>
    </item>
    <item>
      <title>R 中的固定效应 OLS 估计以及各种规范的含义</title>
      <link>https://stats.stackexchange.com/questions/659233/fixed-effects-ols-estimation-in-r-and-what-various-specifications-mean</link>
      <description><![CDATA[我对 R 中与 feols 相关的面板数据有疑问。
假设我有线性回归模型
y_{it}=a+x_{1it}+x_{2it}+error_{it}

其中 i=1,...,T 是国家指数，t=1,...,T 是时期。
在 R 中，我运行这些模型
 模型 A feols(y~ x1| Country[x2], data = mydata) 
模型 B feols(y~ x1+Country/x2, data = mydata) 
模型 C feols(y~ x1+i(Country,x2), data = mydata) 
模型 D feols(y~ x1+i(Country,x2)|Country, data = mydata)
模型 E feols(y~ x1 |Country^year, data = mydata) 

其中我的数据包含“Country”和“year”列。
这些 R 模型对应的计量经济学规范是什么？
我的尝试：
模型 A：y_{it}=x_{1it}+a_i*x_{2it}+error_{it}，其中 a_i 是特定国家/地区的影响。

模型 B：我读到模型 B 得出的估计结果与模型 A 相同，但它的计量经济学规范是什么？

模型 C：y_{it}=x_{1it}+Country_1*x_{2it}+Country_2*x_{2it}+...+Country_N*x_{2it} +error_{it}

其中 Country_1、...、Country_N 是虚拟变量。

模型 D：y_{it}=a_i+x_{1it}+Country_1*x_{2it}+Country_2*x_{2it}+...+Country_N*x_{2it} +error_{it}

其中 Country_1、...、Country_N 为虚拟变量。

模型 E：y_{it}=a_i*lambda_t+x_{1it} +error_{it}，其中 lambda_t 为时间固定效应
]]></description>
      <guid>https://stats.stackexchange.com/questions/659233/fixed-effects-ols-estimation-in-r-and-what-various-specifications-mean</guid>
      <pubDate>Thu, 26 Dec 2024 16:31:23 GMT</pubDate>
    </item>
    <item>
      <title>有符号平方根和的最小绝对值[关闭]</title>
      <link>https://stats.stackexchange.com/questions/659230/minimum-absolute-value-of-sum-of-signed-square-roots</link>
      <description><![CDATA[假设您有从 1 到 $n$ 的整数，对每个整数取平方根，并在其前面选择一个符号，+1 或 -1。目标是最小化这个有符号平方根之和的绝对值。估计这个最小值。
这个问题出现在中心极限定理的背景下，所以我认为这应该适用于解决它。]]></description>
      <guid>https://stats.stackexchange.com/questions/659230/minimum-absolute-value-of-sum-of-signed-square-roots</guid>
      <pubDate>Thu, 26 Dec 2024 14:41:46 GMT</pubDate>
    </item>
    <item>
      <title>我如何评估 R 中形成构造的指标（权重和负荷）的相对重要性和绝对重要性？</title>
      <link>https://stats.stackexchange.com/questions/659232/how-do-i-evaluate-the-relative-and-the-absolute-importance-of-the-indicators-of</link>
      <description><![CDATA[我有一个名为identity_motives的形成性结构，我将其创建为我的数据集field_data中七个身份动机（innovatorlong_1到innovatorlong_7）的综合平均分数。
这个形成性结构是一个调节器 - 它与独立变量ID13source_1（一个具有内部来源和外部来源作为值的二元分类变量）交互以预测ID13_profit（连续变量）。
我了解到，形成性测量模型是基于以下内容进行评估的：收敛效度、指标共线性、统计显着性以及指标权重的相关性。
我已经估计了收敛效度和指标共线性。七个形成性指标的 VIF 值介于 1.10 和 1.72 之间，远低于常用的阈值 5，表明不存在多重共线性问题。
在第三步也是最后一步中，我需要评估指标权重的统计显著性和相关性（即大小）。如何在 R 中执行此操作？
我尝试使用 ChatGPT 生成代码，但不确定是否以及如何指定内部模型。我是 R 和统计学的初学者。]]></description>
      <guid>https://stats.stackexchange.com/questions/659232/how-do-i-evaluate-the-relative-and-the-absolute-importance-of-the-indicators-of</guid>
      <pubDate>Thu, 26 Dec 2024 12:52:05 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何解释行业驱动数据集中的高 Pearson 相关性但低 Spearman 相关性？[重复]</title>
      <link>https://stats.stackexchange.com/questions/659214/how-should-i-interpret-high-pearson-but-low-spearman-correlations-in-an-industry</link>
      <description><![CDATA[我有一个包含约 100,000 行和 100 列的工业锅炉数据集，我正在分析该数据集的二氧化碳排放量。在预建模阶段，我们专注于研究二氧化碳与数据集中其他特征之间的相关性。我们想了解哪些特征表现出与二氧化碳行为密切相关的趋势。从我对统计学的基本了解中，我了解到我应该为此使用 Pearson 和 Spearman 相关性等相关性度量。
有趣的是，我发现一些特征与二氧化碳的 Pearson 相关性非常高，但 Spearman 相关性非常低。我应该如何解释这些情况？当一个特征（如 xi）与二氧化碳的 Pearson 相关性很高但 Spearman 相关性很低时，这意味着什么？通常情况下，较高的 Pearson 相关性不是也意味着较高的 Spearman 相关性吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659214/how-should-i-interpret-high-pearson-but-low-spearman-correlations-in-an-industry</guid>
      <pubDate>Thu, 26 Dec 2024 08:42:42 GMT</pubDate>
    </item>
    <item>
      <title>从什么意义上说，引导法可以让你绕过线性回归方法的某些假设？</title>
      <link>https://stats.stackexchange.com/questions/659211/in-what-sense-bootstrapping-allows-you-to-bypass-certain-assumptions-of-the-line</link>
      <description><![CDATA[我读到了一个关于小样本参数估计的问题，作者问引导法是否是克服研究效力不足的一种方法。
事实并非如此。
但有人写了我的问题的内容，所以我很好奇。
在什么意义上，引导法可以让你绕过线性回归方法（高斯-马尔可夫）的至少一些假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/659211/in-what-sense-bootstrapping-allows-you-to-bypass-certain-assumptions-of-the-line</guid>
      <pubDate>Thu, 26 Dec 2024 04:21:03 GMT</pubDate>
    </item>
    <item>
      <title>当仅提供数据平均值、样本大小和 t 检验时，如何计算标准差？</title>
      <link>https://stats.stackexchange.com/questions/659205/how-to-calculate-standard-deviation-when-only-mean-of-the-data-sample-size-and</link>
      <description><![CDATA[我发现一项研究报告了两组以下数据：
平均值（7.5 和 8.68）
每组的样本量（26 和 22）
独立单尾 t 检验的 P 值（0.055）
是否有计算标准差的公式？]]></description>
      <guid>https://stats.stackexchange.com/questions/659205/how-to-calculate-standard-deviation-when-only-mean-of-the-data-sample-size-and</guid>
      <pubDate>Wed, 25 Dec 2024 22:33:00 GMT</pubDate>
    </item>
    <item>
      <title>葡萄酒数据集的多项逻辑回归分析。标准误差非常大</title>
      <link>https://stats.stackexchange.com/questions/659203/multinomial-logistic-regression-analysis-of-the-wine-dataset-very-large-standar</link>
      <description><![CDATA[我正在用 R 学习逻辑回归，并且正在测试来自 rattle 库的数据集 wine。
library ( rattle )
data ( wine )

我使用以下代码来标准化我的变量：
features &lt;- wine[, -1]
target &lt;- wine$Type 

features_norm &lt;- scale(features)

wine_norm &lt;- as.data.frame(features_norm) 
wine_norm$Type &lt;- target 

我进行了两次逐步选择，一次是针对不做任何修改就适合数据的模型，另一次是针对标准化数据。结果如下：
summary(stepwise_model)
调用：
multinom(formula = Type ~ Flavanoids + Alcohol + Proline + Hue, 
data = wine)

系数：
（截距）黄酮类酒精脯氨酸色调
2 408.93665 -19.93331 -32.79623 -0.18819766 200.13502
3 -58.70074 -75.83563 20.52408 -0.04340099 -88.04955

标准差。错误：
（截距）黄酮类化合物 酒精 脯氨酸 色调
2 0.1655570 3.207194 0.8278404 0.008278356 0.51816676
3 0.1058972 0.159733 1.3959121 0.026907262 0.05795584

残差偏差：0.9549102 
AIC：20.95491 

summary(stepwise_model_norm)
调用：
multinom(formula = Type ~ Flavanoids + Alcohol + Proline + Hue, 
data = wine_norm)

系数：
（截距）黄酮类化合物 酒精 脯氨酸 色调
2 -10.37814 -22.53536 -40.46853 -75.51493 57.92905
3 -71.76456 -90.92047 20.96044 -16.72466 -21.08734

标准差错误：
（截距）黄酮类酒精脯氨酸色调
2 9.028637 16.88702 33.99191 56.27516 43.30412
3 114.794563 136.45769 147.84533 156.41286 190.13100

残差偏差：0.4184597 
AIC：20.41846 

我发现两个模型中的系数都有点太大（特别是在第一个模型中）。然而，最令人惊讶的是，第二个模型中的标准误差与系数的实际大小相比非常大（比例比第一个模型中的大得多）。
我查看了相关矩阵，其中一些有点高，但我认为这应该不会有太大问题。我应该使用 VIF 检查更复杂的关系吗？或者你认为这可能是由于准完美分离造成的？
我按类型创建了每个变量的箱线图，它们似乎没有很好地分离。但是，按类型查看黄烷类化合物 + 脯氨酸，他们似乎将数据分为 3 个清晰的集群，每个类型一个。

我有点想不出主意了，想寻求一些建议。
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/659203/multinomial-logistic-regression-analysis-of-the-wine-dataset-very-large-standar</guid>
      <pubDate>Wed, 25 Dec 2024 18:57:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们使用梯度*输入来生成 CNN 的显著图？</title>
      <link>https://stats.stackexchange.com/questions/659175/why-we-use-gradientinput-for-producing-the-saliency-map-of-a-cnn</link>
      <description><![CDATA[为 CNN 生成显著性图的最简单方法是计算特定输入的 梯度，如此处所述。
还有另一种方法，其中显著性图等于 梯度*输入。我读到它使显著性图更清晰，但我想解释一下为什么会这样，或者只是与输入相乘背后的动机。]]></description>
      <guid>https://stats.stackexchange.com/questions/659175/why-we-use-gradientinput-for-producing-the-saliency-map-of-a-cnn</guid>
      <pubDate>Tue, 24 Dec 2024 20:29:14 GMT</pubDate>
    </item>
    </channel>
</rss>