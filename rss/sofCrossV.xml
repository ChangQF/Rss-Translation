<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 03 Dec 2024 06:27:11 GMT</lastBuildDate>
    <item>
      <title>达到 95% 置信度的某个真实平均值所需的最小样本量</title>
      <link>https://stats.stackexchange.com/questions/658181/minimum-sample-size-needed-for-a-certain-true-average-with-95-confidence</link>
      <description><![CDATA[您有 $100$ 个学生样本，评分范围为 $0/5$ 至 $5/5$。您想通过抽取子样本并观察其中的平均评分来确定整个 $100$ 个样本批次的质量至少为 $4/5$，置信度为 95%。该样本需要多大？
例如，如果我们取 100 个样本，样本平均值超过 $4/5$，那么我们 100% 确信真实平均评分确实超过 $4/5$，但我有点不知道如何使用 &lt; 100 个样本大小的置信区间。如果样本平均值至少为 4.2，o1 声称有 20 个样本。]]></description>
      <guid>https://stats.stackexchange.com/questions/658181/minimum-sample-size-needed-for-a-certain-true-average-with-95-confidence</guid>
      <pubDate>Tue, 03 Dec 2024 02:24:31 GMT</pubDate>
    </item>
    <item>
      <title>是否可以仅在患者群体中进行生存分析，并使用他们的发病年龄作为事件发生时间数据？</title>
      <link>https://stats.stackexchange.com/questions/658179/is-it-possible-to-perform-a-survival-analysis-in-a-patient-population-only-usin</link>
      <description><![CDATA[我们拥有 1,000 例患者中某种疾病的发病年龄数据。平均发病年龄为 60 岁。这些数据是通过招募到三家医院就诊的患者来调查发病年龄而获得的。
为了评估性别是否对发病年龄有影响，我们可以进行 Cox 回归分析吗？其中发病年龄被视为事件发生时间数据，而独立变量是性别？
我看过采用这种方法的论文，但我想知道是否不可能仅对患有该疾病的患者群体进行事件发生时间数据分析？我将非常感谢您提供反馈。]]></description>
      <guid>https://stats.stackexchange.com/questions/658179/is-it-possible-to-perform-a-survival-analysis-in-a-patient-population-only-usin</guid>
      <pubDate>Mon, 02 Dec 2024 23:59:07 GMT</pubDate>
    </item>
    <item>
      <title>岩池相关图 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658176/correlation-graph-for-rock-pools</link>
      <description><![CDATA[目前正在尝试找出如何显示不同岩石池之间的相关性，即它们的大小与生物多样性（香农指数）之间的关系。我该如何最好地做到这一点？我可以使用 Jamovi 和 Excel。]]></description>
      <guid>https://stats.stackexchange.com/questions/658176/correlation-graph-for-rock-pools</guid>
      <pubDate>Mon, 02 Dec 2024 21:25:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Jaynes 的多维 $A_p$ 分布采用这种形式？</title>
      <link>https://stats.stackexchange.com/questions/658170/why-does-jaynes-multi-dimensional-a-p-distribution-take-this-form</link>
      <description><![CDATA[在 Jaynes 的《概率论：科学的逻辑》第 18 章中，他引入了 $A_p$ 分布作为概率分配 $P(A|E)$ 的“内部结构”，这样 $P(A|E)$ 只是 $A_p$ 密度的一阶矩。我有点理解为什么 $A_p$ 以这种方式引入 1D 分布。但在第 18.10 节中，他引入了 K 维 $A_p$ 密度：

我不太明白为什么它采用这种形式的 delta 函数。有人能解释一下为什么它采用这种形式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658170/why-does-jaynes-multi-dimensional-a-p-distribution-take-this-form</guid>
      <pubDate>Mon, 02 Dec 2024 20:30:07 GMT</pubDate>
    </item>
    <item>
      <title>AUC与交叉熵的关系</title>
      <link>https://stats.stackexchange.com/questions/658169/relationship-between-auc-and-cross-entropy</link>
      <description><![CDATA[我理解 AUC 衡量的是模型对受试者进行排名的能力（请参阅为什么 ROC AUC 相当于两个随机选择的样本被正确排名的概率？）。
相比之下，二元交叉熵（或对数损失）衡量的是预测概率的校准。
基于这一区别，优化一个指标（例如交叉熵）不一定会导致另一个指标（例如 AUC）的最佳结果。然而，许多模型使用交叉熵作为主要目标函数，并且仍然获得不错/很好的 AUC 分数。此外，当交叉熵损失最小化时（即预测概率为正样本为 1，负样本为 0），AUC 也是最优的。
因此，我的问题是

交叉熵损失是否可以部分分解为排名组件？
交叉熵和 AUC 是否表现出一定程度的相关性？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658169/relationship-between-auc-and-cross-entropy</guid>
      <pubDate>Mon, 02 Dec 2024 20:24:01 GMT</pubDate>
    </item>
    <item>
      <title>最小绝对偏差 – 几何直觉</title>
      <link>https://stats.stackexchange.com/questions/658168/least-absolute-deviations-geometric-intuition</link>
      <description><![CDATA[我最近接触到了关于最小二乘 (OLS) 回归的几何直觉：
结果变量 $Y$ 的向量不在 $X_1, X_2, ..., X_{p-1}$ 的线性范围内：

正交向量 $Y-X\hat{B}$ 可最小化误差的 $l^2$-范数向量并解决最小二乘问题。
我的问题是：对于最小绝对偏差 (LAD) 问题，我们想要最小化 $l^1$-norm，对于哪种投影可以解决 LAD 问题，是否有任何直觉？它不一定是上面的正交向量（并且 LAD 解决方案不一定是唯一的）。
这实际上更像是一个线性代数问题：如果我们想要最小化 $l^1$-norm，投影会是什么样子？]]></description>
      <guid>https://stats.stackexchange.com/questions/658168/least-absolute-deviations-geometric-intuition</guid>
      <pubDate>Mon, 02 Dec 2024 19:56:06 GMT</pubDate>
    </item>
    <item>
      <title>如何处理 1-5 星评级中的偏见？</title>
      <link>https://stats.stackexchange.com/questions/658166/how-to-handle-bias-in-1-5-star-ratings</link>
      <description><![CDATA[我和一位朋友讨论了我在一家健康保险公司的不愉快经历，为了支持我的印象，我向她指出 trustpilot 给它的分数很低。
有 70 条评论，分布如下：{1：61、2：3、3：0、4：1、5：5}（星级：投票数）。
她的回答是：“哦，但是只有 70 条评论，所以它不算数”。
我最初的想法是 70 不是一个很小的数字；从多项分布来看，如果人们实际上总体上对这家保险公司感到满意，那么随机获得如此负面结果的可能性就很小。
经过进一步思考，我发现问题可能不在于评论的数量，而在于数据收集过程中可能存在的偏见。
由于这不是真正随机选择的调查结果，而是自发报告的结果，数据是否真的代表了整体客户群体？
例如，对保险公司更满意的人是否不太可能留下评论，反之亦然，不太满意的人是否更有可能报告他们的不满？
假设是这样，是否有任何已知的方法或途径可以减少这种偏见？
例如能否根据某种概率分布对评论进行加权？
下面是一些更多信息，仅用于说明我的进一步研究和思考过程。
我看到了一些关于贝叶斯平均值估计的帖子，例如这个，事实上，根据上述数据得出的 trustpilot 平均评分并不是通过简单的算术平均值得到的。
但是，我不确定这是否解决了我在这里讨论的偏见问题，因为它似乎更侧重于比较具有相同纯算术平均值但基于不同评论总数的评分对。从这个意义上讲，我当然不得不同意有必要进行纠正。但它是否解决了数据收集部分？
我正在讨论的保险公司示例的平均分数（不考虑贝叶斯校正或 trustpilot 所做的任何其他校正）是：
$$\frac {\sum_{n=1}^5 {votes(n) \cdot n}} {\sum_{n=1}^5 {votes(n)}} = \frac {61 \cdot 1+3 \cdot 2+ 0 \cdot 3 + 1 \cdot 4+5 \cdot 5} {70} = \frac {48} {25} \approx 1.37$$
我猜测偏差校正可能看起来像一个非常简单的例子：假设我们知道对保险公司的看法为“n 星”的人写评论的概率与 $\frac 1 n$ 成比例。
那么 $PMF(n)$ 将是 $\frac 1 n \cdot \frac {60} {137}$。
这意味着如果 $x(n)$ 人投了 $n$ 颗星，那么实际考虑该评分的人数将成比例增加 $\frac 1 {PMF(n)}$。 （顺便说一句，这是我边写边编的，如果我错了，请纠正我：这篇文章的目的是就此事征求建议）。
如果我没有记错的话，根据这个逻辑修正后的平均值将是：
$$\frac {\sum_{n=1}^5 {votes(n) \cdot n \cdot \frac 1 {PMF(n)}}} {\sum_{n=1}^5 {votes(n) \cdot \frac 1 {PMF(n)}}} = \frac {\sum_{n=1}^5 {votes(n) \cdot n^2}} {\sum_{n=1}^5 {votes(n) \cdot n }} = \frac {61 \cdot 1^2 + 3 \cdot 2^2 + 0 \cdot 3^2 + 1 \cdot 4^2 + 5 \cdot 5^2} {61 \cdot 1+3 \cdot 2+ 0 \cdot 3 + 1 \cdot 4+5 \cdot 5} = \frac {103} {48} \approx 2.14$$
我的看法是：由于对保险公司满意度较高的人不太可能撰写评论和投票，因此这种方法会给他们的投票赋予更大的权重，以更好地接近如果有可能从所有人那里获得投票，则会获得的平均水平。
这有意义吗？
根据上述问题，是否有任何旨在减少自发报告与设计民意调查可能导致的偏差的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/658166/how-to-handle-bias-in-1-5-star-ratings</guid>
      <pubDate>Mon, 02 Dec 2024 19:29:10 GMT</pubDate>
    </item>
    <item>
      <title>生态时间统计分析问题</title>
      <link>https://stats.stackexchange.com/questions/658163/ecological-temporal-statistical-analysis-question</link>
      <description><![CDATA[我在同一地点连续三个时间段内收集了无放回的动物样本：深海中相隔七年（例如，没有已知的季节性）。我想知道病毒感染的平均差异是否会随时间发生显着变化。数据不正常。我是否应该将其视为独立的（无放回采样，尽管随着时间的推移，没有固有的模式，例如季节性会导致变化），因此进行 Kruskal Wallis 检验？或者我是否需要将数据视为依赖的，因为尽管动物的采样没有放回，但它们来自同一种群？如果是后者，我们是不是说，虽然没有对任何动物进行采样，但移除一个个体在理论上可能会影响种群中另一个动物的病毒感染？可以将数据的时间方面视为独立的吗？
Friedmans 检验是否足以确定平均差异是否具有统计意义？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658163/ecological-temporal-statistical-analysis-question</guid>
      <pubDate>Mon, 02 Dec 2024 18:40:25 GMT</pubDate>
    </item>
    <item>
      <title>在 R 函数 rank_trace 中，是否存在一个共同的阈值来接受排名？</title>
      <link>https://stats.stackexchange.com/questions/658156/in-the-r-function-rank-trace-does-there-exist-a-common-threshold-value-to-accep</link>
      <description><![CDATA[在用于降阶回归的 R 包 rrr（文档）中，有一个函数 rank_trace。
它返回一个图，其中回归系数矩阵的每个秩都对应一个点。
通常，如果该点接近原点$(0,0)$，那么我们更希望这个等级是可以接受的。
我的问题是，例如在$p$值中，如果$p&gt;0.05$，即$0.05$是$p$的阈值，我们通常愿意接受一个假设。
虽然我知道这个界限不是通用的，但我仍然想知道在处理数据（例如，来自试验）时，对于$\max\{x,y\}$，是否存在一个共同的阈值，其中$(x,y)$是与某个等级相对应的点，接受这个等级？
令我困惑的是，在现代多元统计技术一书中，rrr包引用，作者说

将$C$的等级评估为步骤（3）中的两个坐标（即与该等级相对应的点的坐标）近似为零的最小等级。

但在书中的下图中，作者说最小的等级分别为$1$和$5$，两者的$x$坐标均远离零。


附加信息：函数rank_trace的方法：
让降秩回归模型为
$$Y=\mu+CX+\epsilon.$$
在rank_trace图中，对应于 $\text{rank }C=t$ 的点，由以下公式给出
$$x_t= \frac{\|\widehat{\mathbf{\Theta}} - \widehat{\mathbf{C}}^{(t)}\|}{\|\widehat{\mathbf{\Theta}}\|} ,\quad y_t= \frac{\|\widehat{\Sigma}_{\varepsilon \varepsilon} - \widehat{\Sigma}^{(t)}_{\varepsilon \varepsilon}\|}{\|\widehat{\Sigma}_{\varepsilon \varepsilon} - \widehat{\Sigma}_{\mathbf{Y}\mathbf{Y}}\|}, $$
其中范数矩阵的估计值为 $\sqrt{\sum_{i,j}a_{ij}^2}$,
$\widehat{\mathbf{\Theta}}$ 为回归系数矩阵 $C$ 在满秩条件下的估计值,
$\widehat{\Sigma}_{\varepsilon \varepsilon}$ 为 $\epsilon$ 在满秩条件下的估计值,
上标 $\cdot^{(t)}$ 表示在 $C$ 的秩为 $t$.]]></description>
      <guid>https://stats.stackexchange.com/questions/658156/in-the-r-function-rank-trace-does-there-exist-a-common-threshold-value-to-accep</guid>
      <pubDate>Mon, 02 Dec 2024 16:31:36 GMT</pubDate>
    </item>
    <item>
      <title>使用 PC 分数对存在/不存在数据进行建模</title>
      <link>https://stats.stackexchange.com/questions/658153/modelling-presence-absence-data-with-pc-scores</link>
      <description><![CDATA[我有一些动物数量与环境变量的 PCA 分数的数据，如下所示。计数数据中的 .5 是因为有两个人计数，然后我们取了平均值。
 data &lt;- data.frame(
pc1 = c(0.1, 0.3, 0.5, 2.7, 0.9, 1.1, 0.3, 1.5, 1.7, 2.9),
pc2 = c(3.1, 1.3, 2.7, 2.7, 2.1, 1.3, 2.3, 3.5, 1.7, 3.9),
count = c(0,1.5, 0, 0, 2.5, 0, 0, 1, 0.5, 0)
)

我想测试 PC 分数（环境变量）是否对计数有影响。
我使用：
lm.count &lt;- lm(count ~ pc1 + pc2, data)
summary (lm.count)

输出：
调用：
lm(formula = count ~ pc1 + pc2, data)

残差：
最小值 1Q 中位数 3Q 最大值 
-1.3547 -0.3614 -0.2009 0.5609 1.8412 

系数：
估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 1.300000 0.241209 5.390 0.000163 ***
pc1 0.004687 0.158655 0.030 0.976920 
pc2 -0.118962 0.170177 -0.699 0.497848 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

残差标准误差：12 个自由度上的 0.9342
多重 R 平方：0.0392，调整后的 R 平方：-0.1209
F 统计量：2 和 12 DF 上的 0.2448，p 值：0.7867

但我想知道大量的零计数信息是否会扭曲数据并意味着使用此模型是不正确的。 Chat GTP 建议我尝试使用逻辑模型来表示存在和不存在：
logistic_model &lt;- glm(count &gt; 0 ~ pc1 + pc2, family = binomial, data = data)
summary(logistic_model)

输出：
调用：
glm(formula = count &gt; 0 ~ pc1 + pc2, family = binomial, data = data)

偏差残差：
最小 1Q 中位数 3Q 最大 
-2.2854 0.3479 0.5064 0.5594 0.7567 

系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 1.98844 0.83717 2.375 0.0175 *
pc1 0.37118 0.52065 0.713 0.4759 
pc2 0.05496 0.52303 0.105 0.9163 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（二项式系列的分散参数取为 1）

零偏差：14 个自由度上的 11.780
残差偏差：12 个自由度上的 11.239
AIC：17.239

Fisher 评分迭代次数：5

这样好些了吗？模型摘要完全不显著，但当将模型预测与 PC1 轴绘制在一起时，相关性几乎完美。所以我确信有些事情出错了。。
这是代码（最后是真实数据图）：
predicted_probs &lt;- predict(logistic_model, type = &quot;response&quot;)
data$predicted_probs &lt;- predict_probs

plot(data$pc1, data$predicted_probs,
xlab = &quot;pc1&quot;, ylab = &quot;Predicted Probability of counts &gt; 0&quot;,
main = &quot;Logistic Regression: Predicted Probability vs PC1&quot;,
pch = 19, col = &quot;blue&quot;)

我觉得模型重要性和绘制的预测之间的不匹配表明有些事情出错了。也许模型是正确的，但绘图是错误的？或者反过来。但如果没有相关性，我预计图中的点会到处都是。
这是图：
]]></description>
      <guid>https://stats.stackexchange.com/questions/658153/modelling-presence-absence-data-with-pc-scores</guid>
      <pubDate>Mon, 02 Dec 2024 16:19:25 GMT</pubDate>
    </item>
    <item>
      <title>弗里德曼随机区组统计量的最大值</title>
      <link>https://stats.stackexchange.com/questions/658128/maximum-value-of-friedmans-randomized-block-statistic</link>
      <description><![CDATA[我正在阅读《非参数统计方法》（Hollander、Wolfe 和 Chicken 出版社）第 3 版中有关弗里德曼统计的内容。第 302 页有一个练习问题：

直接显示或通过示例说明 $S$ 的最大值是 $S_{\text{max}} = n ( k − 1 )$ 。在什么配置下可以达到这个最大值？

他们定义$S$如下：
$\frac{12}{nk(k+1)}\sum_{j=1}^k R_j^2 - 3n(k+1)$,
其中$R_j$是组$j$等级的总和，有$k$组和$n$块。查看 $S$ 的定义，我需要最大化 $\sum R_j^2$。我的猜测是，当每列的等级总和达到最大极值时，就会达到最大值。但是，对仅排名 $j$ $k$ 次的组 $Rj$ 进行代数运算，或者将排名分布为从第一组开始，排名从 1 到 $n$，然后继续将第二组一直到组 $k$，其排名从 $(k-1)n+1$ 到 $kn$，这并不能给我 $n(k-1)$。所以结果中一定有一些统计专业知识在起作用？有人能解释一下如何最大化$S$吗？
他们说，如果有大量的块，$S$ 会遵循“具有 $(k-1)$ 自由度的渐近卡方分布”。这是什么意思？与建议的最大值有什么联系吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658128/maximum-value-of-friedmans-randomized-block-statistic</guid>
      <pubDate>Mon, 02 Dec 2024 09:13:22 GMT</pubDate>
    </item>
    <item>
      <title>保持所有多元正态分布的正态性的变换</title>
      <link>https://stats.stackexchange.com/questions/657927/transformations-that-preserve-normality-for-all-multivariate-normal-distribution</link>
      <description><![CDATA[我正在寻找可测可逆函数 $f:\mathbb{R}^n \rightarrow \mathbb{R}^n$，使得对于所有（非退化）n 维高斯随机变量 $X$，我们有 $f(X)$ 仍然是高斯随机变量。我推测 $f$ 必须是仿射的。这是真的吗，还是需要对 $f$ 做出其他假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/657927/transformations-that-preserve-normality-for-all-multivariate-normal-distribution</guid>
      <pubDate>Wed, 27 Nov 2024 12:18:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么在引导均值差异时需要合并均值？</title>
      <link>https://stats.stackexchange.com/questions/657378/why-is-a-pooled-mean-necessary-in-bootstrapping-the-difference-in-means</link>
      <description><![CDATA[公式化问题
在用于测试均值差异的双样本自举程序中，为什么从每个自举观察值中减去组特定均值（以零为中心）是不够的？这种方法使两个组的共同均值等于零。相反，为什么需要使用合并的总体平均值来调整自举样本？数学上：

设 $$ X = \{x_1, x_2, \dots, x_n\} $$ 和 $$ Y = \{y_1, y_2, \dots, y_m\} $$ 为两个独立样本，且：

样本均值：
$$
\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i, \quad \bar{y} = \frac{1}{m} \sum_{j=1}^m y_j
$$
观察到的均值差异：
$$
\Delta_{\text{obs}} = \bar{x} - \bar{y}
$$


通过减去相应的组均值，可获得中心化的引导样本：

对于组 (X)：
$$
x_i^* = x_i - \bar{x}, \quad \text{for } i = 1, 2, \dots, n
$$
对于组 (Y)：
$$
y_j^* = y_j - \bar{y}, \quad \text{for } j = 1, 2, \dots, m
$$
中心化后，两个组的均值均为零：
$$
\bar{x}^* = 0, \quad \bar{y}^* = 0
$$
这可确保引导样本模拟组特定均值相等的场景。


但是，有些方法建议不要将数据集中在组特定均值$$( \bar{x}, \bar{y} )$$周围，而应通过添加合并均值来调整引导样本：
$$
\bar{z} = \frac{n \cdot \bar{x} + m \cdot \bar{y}}{n + m}
$$
调整后的引导样本变为：

对于组 (X)：
$$
x_i^* = x_i - \bar{x} + \bar{z}
$$
对于组 ( Y )：
$$
y_j^* = y_j - \bar{y} + \bar{z}
$$


问题：为什么需要对合并平均值 $$( \bar{z} )$$ 进行额外调整？如果中心引导样本的组特定平均值已经为零，这是否不能确保满足均值相等的零假设？为什么以零为中心是不够的？

]]></description>
      <guid>https://stats.stackexchange.com/questions/657378/why-is-a-pooled-mean-necessary-in-bootstrapping-the-difference-in-means</guid>
      <pubDate>Sat, 16 Nov 2024 21:36:07 GMT</pubDate>
    </item>
    <item>
      <title>缩小比例影像的验证</title>
      <link>https://stats.stackexchange.com/questions/657338/validation-of-downscaled-imagery</link>
      <description><![CDATA[如果该帖子不适合本网站，我提前表示歉意。如果是这样，那么请随意推荐其他相关网站，我会关闭这个问题。
想象一个传感器（我们称之为传感器 A），它可以从两个视角捕获图像，近天底（NN）和离天底（ON）。任务是缩小（DS）图像。假设，为了进行验证，有另一个传感器（传感器 B）可以捕获与传感器 A 相同波长的图像。传感器 B 的图像在时间分辨率方面并不规则，它可以从不同的视角（VA）获取特定区域的图像。在传感器 B 图像的元数据中，未提及 VA。
您将如何使用传感器 B 完成验证来自传感器 A 的 DS 图像的任务？我想说的是，“传统”验证测试（即 r 平方或 RMSE）可能不合适，因为（至少对我来说）这就像比较苹果和橘子。我的意思是，如果我要将 NN VA 的 DS 图像与传感器 B 的图像进行比较，并且后者的图像是从 NN 位置拍摄的，那么与 ON 和传感器 B 相比，r 平方会更高是有道理的。
您有什么建议？]]></description>
      <guid>https://stats.stackexchange.com/questions/657338/validation-of-downscaled-imagery</guid>
      <pubDate>Fri, 15 Nov 2024 23:37:03 GMT</pubDate>
    </item>
    <item>
      <title>对非随机样本进行统计测试？</title>
      <link>https://stats.stackexchange.com/questions/639007/statistical-testing-on-non-random-sample</link>
      <description><![CDATA[我正在一项观察性研究中使用非随机样本，但想进行统计测试以显示某些趋势和过程。统计测试假设随机抽样，但这在我的实验中并未实现，因此我担心结果（或解释？）无效。我有什么选择？例如，我是否应该对解释格外小心？我是否应该删除所有与统计测试相关的文本？
以及上下文：
我正在对学科 A进行科学计量/文献计量分析。学科 A 相对较新，但人们一致认为，在过去 30 年左右的时间里，它凭借自身优势发展成为一门学科。我根据其他科学计量研究和大量文献确定了一定数量的期刊，并认为这些期刊构成了学科 A 的大部分。这个列表可能不是精确的科学，而且是主观的。在我看来，识别期刊的问题已经得到描述、解释和论证。
然后，我根据这份期刊清单分析趋势，例如随时间推移的出版量、贡献国家等，以便深入了解期刊特征或学科（即所有样本期刊的综合情况）。当然，样本不是随机的，但它仍然提供了对学科的见解。
假设我想检查一个县的经济活动（以人均 GPD 衡量），并且我拟合了一个线性回归模型，该模型显示这种关系具有统计显著性。我该怎么做？我是否根本没有包括统计测试，或者我只是明确表示我们看到的是指选定的期刊集（即整个群体）。
我担心的是，根据我抽样的期刊与学科之间的差异（差异较大），我所做的可能看起来不诚实，但我不确定如何解决想要提供由统计测试支持的见解与过程中抽样缺陷之间的冲突。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/639007/statistical-testing-on-non-random-sample</guid>
      <pubDate>Sat, 10 Feb 2024 16:26:35 GMT</pubDate>
    </item>
    </channel>
</rss>