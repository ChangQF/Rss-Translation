<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 22 Jun 2024 01:03:13 GMT</lastBuildDate>
    <item>
      <title>假设检验有限样本空间高斯混合模型</title>
      <link>https://stats.stackexchange.com/questions/649693/hypothesis-test-finite-sample-spatial-gaussian-mixture-model</link>
      <description><![CDATA[我有 $n$ 对 $(x, y)$ 的观测值和三个不同的模型，我想进行比较。模型 0 嵌套在模型 1 中。模型 0 也嵌套在模型 2 中。我想对模型 1 和模型 2 分别进行假设检验，使用模型 0 作为零假设。我最初的方法是使用似然比检验，但我得到的 1 类错误率过高。我相信这个 stack overflow 答案 中解释了其原因。因此，我尝试使用该答案中建议的修正，例如 Satorra 和 Bentler 2010 修正或 Bartlett 修正，但无济于事，因为这些修正似乎都是针对与我自己的问题不同的指定问题。因此，我需要帮助，要么将修正转换为问​​题的公式，要么以与修正兼容的方式重新表述我的问题，老实说，我不介意有人仔细检查我的分析，以确保所引用的答案实际上与我的问题有关，因为也许我弄错了。
因此，我的三个模型如下：
首先，它们都是$(2n x 2n)$多元正态分布，对于观测向量$(x_{1},...,x_{n},y_{1},...,y_{n})$，它们给出第 i 行、第 j 列（矩阵为半正定）中观测 i 和 j 之间的协方差。
模型 0：
$$
\begin{bmatrix}
\sigma_{1}^{2}A_{n}+\sigma_{2}^{2}\mathbb{I}_{n} &amp; 0_{n x n} \\
0_{n x n} &amp; \sigma_{3}^{2}A_{n}+\sigma_{4}^{2}\mathbb{I}_{n} \\
\end{bmatrix},
$$
其中 $A_{n}$ 和 $\mathbb{I}_{n}$ 是 $(n x n)$ 已知矩阵（$\mathbb{I}_{n}$ 是单位矩阵），$\sigma_{1}^2、\sigma_{2}^2、\sigma_{3}^2、\sigma_{4}^2$ 是未知方差缩放因素。
模型 1：
$$
\begin{bmatrix}
\sigma_{1}^{2}A_{n}+\sigma_{2}^{2}\mathbb{I}_{n} &amp; c_{1}C_{n} \\
c_{1}C_{n} &amp; \sigma_{3}^{2}A_{n}+\sigma_{4}^{2}\mathbb{I}_{n} \\
\end{bmatrix},
$$
其中 $A_{n}$、$\mathbb{I}_{n}$ 和 $C_{n}$ 为 $(n x n)$ 已知矩阵，$\sigma_{1}^2、\sigma_{2}^2、\sigma_{3}^2、\sigma_{4}^2$ 为未知方差缩放因子，$\sigma_{1}^2、\sigma_{2}^2、\sigma_{3}^2、\sigma_{4}^2$ 为未知方差缩放因子，$c_{1}$ 是 $[-1,1]$ 中的未知相关性。
模型 2：
$$
\begin{bmatrix}
\sigma_{1}^{2}A_{n}+\sigma_{2}^{2}\mathbb{I}_{n} &amp; c_{1}K_{n} \\
c_{1}K_{n} &amp; \sigma_{3}^{2}A_{n}+\sigma_{4}^{2}\mathbb{I}_{n} \\
\end{bmatrix},
$$
其中 $A_{n}$、$\mathbb{I}_{n}$ 和 $K_{n}$ 为 $(n x n)$ 已知矩阵，$\sigma_{1}^2、\sigma_{2}^2、\sigma_{3}^2、\sigma_{4}^2$ 为未知方差缩放因子，$\sigma_{1}^2、\sigma_{2}^2、\sigma_{3}^2、\sigma_{4}^2$ 为未知方差缩放因子，$c_{1}$ 是 $[-1,1]$ 中的未知相关性。
总之，我对 X 和 Y 之间可能存在的相关性类型有几个不同的假设，我希望能够通过拒绝零假设来支持这些假设。非常感谢任何帮助，谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/649693/hypothesis-test-finite-sample-spatial-gaussian-mixture-model</guid>
      <pubDate>Sat, 22 Jun 2024 00:53:33 GMT</pubDate>
    </item>
    <item>
      <title>如何对机器学习模型执行置换检验以获得其性能的 p 值？</title>
      <link>https://stats.stackexchange.com/questions/649692/how-do-i-perform-a-permutation-test-on-a-machine-learning-model-to-obtain-a-p-va</link>
      <description><![CDATA[这个问题与上一篇文章中的问题类似。但由于没有回复，而且我很难找到答案，所以我想再问一次。
我正在 caret 中训练回归模型（SVM 线性核）。我曾多次使用名为 PRONTO 的软件，它可以运行置换测试以获得预测模型指标（R²、MSE 等）的 p 值。
如何在 R 中重现此问题？是否可以在 caret 包中执行此操作？]]></description>
      <guid>https://stats.stackexchange.com/questions/649692/how-do-i-perform-a-permutation-test-on-a-machine-learning-model-to-obtain-a-p-va</guid>
      <pubDate>Fri, 21 Jun 2024 23:31:13 GMT</pubDate>
    </item>
    <item>
      <title>我想了解一下我在这里从事的工作</title>
      <link>https://stats.stackexchange.com/questions/649690/i-would-like-some-insight-into-what-i-have-been-working-on-here</link>
      <description><![CDATA[我从事屋顶销售工作，入门级需要上门推销。我们分行的 GroupMe 聊天中会打印每日数据。我主动对这些数字进行了一些分析。有敲门、谈话、走访和偶发事件（达成的交易）。
我不会向你介绍我所做的一切，但我会告诉你，我发现敲门次数和偶发事件之间的相关性为 -0.41，这意味着我们敲的门越多，达成的交易越少；上门推销的差异也很大，远远超出了每日数字的范围。我对此非常感兴趣，因为销售工作几乎总是“数字游戏”，这意味着他们使用平均法则 - 如果你敲了很多门，最终你会达成交易。
我告诉领导层这件事，他们给了我“焚书”式的回应。他们告诉我不要分享任何“负面”信息或者告诉人们不要为了赚更多的钱而努力工作；我放弃了和他们讨论这个问题，而是自己深入研究它。
首先，我计算了平均每敲 100 扇门，有多少个意外事件被签署。它是 ~2.59。我用它作为二项分布函数中的“假定概率”，并绘制了每次敲门（0 - 100）的销售概率。我发现，最有可能产生 ~2.59 笔销售，2 笔销售的概率约为 25% 左右。负相关性告诉我，收益递减点已经存在，所以我仍然不相信越多越好。
其次，我决定对每 100 扇门进行预期值计算。当然，每扇门 2.59% 的销售概率保持不变；但是，惩罚（使用的资源，如汽油和时间等）确实会随着每扇门而增加。我称之为每扇门 1 美元的汽油，因为这就是我所花费的。这告诉我，在 52 次敲门后，你真的没有什么可获得的了。这让我意识到二项分布概率会随着试验次数的变化而变化……
第三，我回到电子表格并将试验次数改为 52；这表明最有可能的结果是 1 次销售，概率略高于 33%（这大于 100 次试验中 2 次销售的约 25% 的概率）。
由于这一切都基于我们分行的实际绩效数据，我觉得我已经证明（至少在统计上）我已经解释了负相关性，并证明了“上升和磨砺”每天尽可能多地敲门是一种策略，但这种策略会适得其反，导致销售代表产生不一致的数字（解释了高方差）。
我现在的假设是，如果所有销售代表每个周期（一天、一周或其他时间段）敲门 52 次，方差将更接近于零或至少在数据范围内，销售额将会增加，相关性可能会显示敲门次数和意外事件之间存在正相关关系，因为敲门次数通常会较低，意外事件的数量会较高。
我希望从更有经验的人那里了解我的发现是否有价值，或者我是否遗漏了什么。在非正式场合，我很乐意编写 Python 代码来绘制所有这些。]]></description>
      <guid>https://stats.stackexchange.com/questions/649690/i-would-like-some-insight-into-what-i-have-been-working-on-here</guid>
      <pubDate>Fri, 21 Jun 2024 21:04:41 GMT</pubDate>
    </item>
    <item>
      <title>与三元变量进行 3 次比较</title>
      <link>https://stats.stackexchange.com/questions/649689/making-3-comparisons-with-a-ternary-variable</link>
      <description><![CDATA[我有一项研究，我想研究三元变量 x 与二元变量 y 交互的影响。三元变量是分类变量，出于某些原因，我想对 3 个组进行 3 次比较。
我明白要进行一次比较，我必须进行 2 次对比。例如，如果我对组 1 与组 3 感兴趣，我定义 C1= (-1,0,1) 和 C2=(-1,2,-1)。如果我想测试所有的比较，那么我应该做 6 次对比吗？在这种情况下，回归量不是共线的吗？有没有更简单的方法可以做到这一点？
谢谢你的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/649689/making-3-comparisons-with-a-ternary-variable</guid>
      <pubDate>Fri, 21 Jun 2024 20:51:47 GMT</pubDate>
    </item>
    <item>
      <title>解释 SPSS PROCESS 输出的二分法 Y 值资源</title>
      <link>https://stats.stackexchange.com/questions/649687/resources-for-interpreting-spss-process-output-with-a-dichotomous-y</link>
      <description><![CDATA[我目前正在使用 SPSS 中的 PROCESS 宏扩展进行中介分析。我最近了解到，此扩展中可以使用二分 Y。话虽如此，使用逻辑回归可以改变输出。有人知道任何使用二分 Y 解释 PROCESS 宏输出的资源吗？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649687/resources-for-interpreting-spss-process-output-with-a-dichotomous-y</guid>
      <pubDate>Fri, 21 Jun 2024 20:39:42 GMT</pubDate>
    </item>
    <item>
      <title>RCT 的线性混合模型中的插补</title>
      <link>https://stats.stackexchange.com/questions/649686/imputation-in-a-linear-mixed-model-for-rct</link>
      <description><![CDATA[我有一项研究，其中参与者被随机分配到两种条件之一（参与者条件）。他们在测试前和测试后都完成了调查。我想看看条件和时间之间是否存在显著的相互作用，看看一种条件是否比另一种条件导致 DV 从测试前到测试后的变化更大。数据是长格式。
数据也被输入了 50 次，并存储在以下 mids 对象中：impmids。
有人可以确认这是否是测试所提研究问题的正确代码吗：
library(mice)
library(lme4)

P.eddi &lt;- with(impmids, lmer(EDDI_Total ~ ParticipantCondition * Time + (1|Participant_ID_New)))
BP.eddi.pooled &lt;- pool(BP.eddi)
summary(BP.eddi.pooled)

谢谢！！]]></description>
      <guid>https://stats.stackexchange.com/questions/649686/imputation-in-a-linear-mixed-model-for-rct</guid>
      <pubDate>Fri, 21 Jun 2024 19:47:04 GMT</pubDate>
    </item>
    <item>
      <title>使用什么指标来丢弃与所有其他注释者具有较低 IAA（注释者间一致性）的注释者？</title>
      <link>https://stats.stackexchange.com/questions/649685/what-is-the-best-metric-to-use-to-discard-annotators-with-low-iaa-inter-annotat</link>
      <description><![CDATA[此问题特定于在李克特量表上收集的序数数据
丢弃与其他人的注释者之间注释者一致性 (IAA) 较低的注释者的最佳指标是什么？例如，Cohen 的 Kappa、Fleiss 的 Kappa、Krippendorff 的 Alpha
是成对计算每对注释者之间的注释者一致性更好，还是可以对 1 个注释者与其他注释者进行比较？]]></description>
      <guid>https://stats.stackexchange.com/questions/649685/what-is-the-best-metric-to-use-to-discard-annotators-with-low-iaa-inter-annotat</guid>
      <pubDate>Fri, 21 Jun 2024 19:19:02 GMT</pubDate>
    </item>
    <item>
      <title>GAM 分析有两种方式：使用正态分布作为生存百分比，使用二项分布作为存活/死亡，但得到的结果截然不同</title>
      <link>https://stats.stackexchange.com/questions/649684/gam-analysis-two-ways-as-percent-survival-using-normal-dist-and-as-alive-dead-u</link>
      <description><![CDATA[我的问题与鲑鱼种群数据有关。我想了解海洋变量如何影响鲑鱼的回归。我用两种不同的方法分析了数据。第一个响应变量是返回的鲑鱼数量与外出鲑鱼数量的比例，但这是有问题的，因为我们将每年数千个数据点压缩成一个数字。
gam_hatcherySAR_cuti &lt;- gam(sar ~ s(CUTI), data = hatcherySAR, method = &quot;REML&quot;)

 out_yr SAR CUTI
1 2008 0.003664542 -0.03291667
2 2009 0.010083530 -0.04575000
3 2010 0.005462051 -0.29100000
4 2011 0.004414756 -0.12783333
5 2012 0.002900364 -0.20225000
6 2013 0.005570978 0.09850000
7 2014 0.012547544 -0.07283333
8 2015 0.006963657 0.07700000
9 2016 0.004722142 -0.04975000
10 2017 0.002127052 -0.00575000
11 2018 0.007220002 0.03550000`

系列：高斯
链接函数：身份

公式：
SAR ~ s(CUTI)

参数系数：
估计标准误差 t 值 Pr(&gt;|t|) 
（截距） 0.0059706 0.0009768 6.112 0.000177 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似重要性：
edf Ref.df F p 值
s(CUTI) 1 1 0.207 0.66

R-sq.(adj) = -0.0861 偏差解释 = 2.25%
-REML = -36.422 尺度估计 = 1.0496e-05 n = 11

因此，我想通过另一种方式对其进行分析，即使用逻辑回归方法将响应变量视为活着的还是死去的。
但是，这两种分析方法都得到了截然不同的结果，即 CUTI 在上述高斯示例中不是一个重要的预测因子，而二项式示例则非常重要。我还看到了与我评估过的许多其他海洋变量类似的结果。显然，考虑到不同的分布，我预计结果会略有不同，但不会像我看到的那么剧烈。有人能帮我理解这是为什么吗？
gam_hatcherySARbin_cuti &lt;- gam(cbind(hatcherySARbin$alive,hatcherySARbin$dead) ~ s(CUTI), data=hatcherySARbin,family=binomial(),method = &quot;REML&quot;)

 年份 存活 死亡 剪切
[19,] &quot;2008&quot; &quot;15750&quot; &quot;4282232&quot; &quot;-0.032916667&quot;
[20,] &quot;2009&quot; “42239” “4146665” “-0.04575” 
[21,] “2010” “23290” “4240634” “-0.291” 
[22,] “2011” “16367” “3682322” “-0.127833333” 
[23,] “2012” “11699” “4021761” “-0.20225” 
[24,] “2013”​​ “18701” “3338073” &quot;0.0985&quot; 
[25,] &quot;2014&quot; &quot;48229&quot; &quot;3795423&quot; &quot;-0.072833333&quot;
[26,] &quot;2015&quot; &quot;20134&quot; &quot;2870199&quot; &quot;0.077&quot; 
[27,] &quot;2016&quot; &quot;13130&quot; &quot;2786228&quot; &quot;-0.04975&quot; 
[28,] &quot;2017&quot; &quot;6219&quot; &quot;3032885&quot; &quot;-0.00575&quot; 
[29,] &quot;2018&quot; &quot;18603&quot; &quot;2558000&quot; &quot;0.0355&quot;
`

系列：二项式

链接函数：logit

公式：
cbind(hatcherySARbin$alive, hatcherySARbin$dead) ~ s(CUTI)

参数系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -5.208502 0.002349 -2217 &lt;2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df Chi.sq p 值 
s(CUTI) 8.994 9 44821 &lt;2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

R-sq.(adj) = -0.958 偏差解释 = 82.9%
-REML = 5057 尺度估计 = 1 n = 11``` 
]]></description>
      <guid>https://stats.stackexchange.com/questions/649684/gam-analysis-two-ways-as-percent-survival-using-normal-dist-and-as-alive-dead-u</guid>
      <pubDate>Fri, 21 Jun 2024 19:10:08 GMT</pubDate>
    </item>
    <item>
      <title>导致非线性回归引导问题的“重要”数据点</title>
      <link>https://stats.stackexchange.com/questions/649683/important-data-points-causing-problems-with-nonlinear-regression-bootstrapping</link>
      <description><![CDATA[我正在尝试模拟行星表面的雷达反向散射。散射回仪器的功率取决于它观察表面的角度。由此产生的功率与角度曲线的形状由表面的特性决定。
这是我的所有数据的图表，其中包含一个 5 参数模型。

上图中的每个点都显示为单个点，但这只是为了显示。这些点中的每一个实际上都是由包含数千个像素的雷达图像组成的，其中每个像素都有指定的角度和功率。
以下是实际拟合的完整数据：

请注意，每个像素在图像的平均功率附近都是嘈杂的 - 这部分是由于雷达图像固有的“斑点噪声”，并且是乘性噪声。这意味着功率测量值越大，噪声就越大。 （这不是很明显，因为绘图是以 dB 为单位的，这是一个对数刻度。）
使用 MATLAB 的 fit 函数将表面模型拟合到所有数据，对 5 个模型参数给出了非常非常严格的限制。例如，它估计表面的介电常数为 1.329（1.326, 1.332）。对于数据的稀疏性和噪声性来说，这是一个不切实际的置信度，尤其是在第一张图中看到数据点的“真实”分布时。
我尝试使用引导法获得更准确的拟合参数不确定性。我尝试的第一件事是通过从 500,000 个像素池中进行 500,000 次替换采样来创建引导样本。每个引导拟合的结果实际上与第一次拟合完全相同，拟合参数的分布同样很小（+- 0.01）。我可以理解为什么会这样（我认为）。通过选择这么多像素，每个雷达图像的分布基本上完全重建，并且最终的拟合不会改变。
然后我认为我应该将大约 30 张雷达图像中的每一个都视为一个测量值，并通过从图像集中进行替换选择来制作引导样本。如果选择了图像，则将其所有像素都包含在拟合向量中，而不仅仅是其平均值。我这样做是因为我认为像素分布中有重要的角度信息，尤其是在斜率陡峭的低角度。
但是，当我使用此方法时，控制低角度行为的参数是极其双峰的。结果几乎完全取决于引导样本中是否包含 0 度和 5 度左右的图像。如果包括它们，则有一个拟合，如果不包括它们，则有另一个拟合。在低入射角时会出现指数衰减，因此包含/排除这几个点对于模拟该行为非常重要。


我应该如何处理这个问题？这几个重要的点决定了模型该状态的行为，因此我的参数估计中的不确定性更多地与“是否包含该点”有关比任何东西都重要，这似乎在科学上没有什么用。不幸的是，我可用的数据非常有限，特别是在低入射角的情况下。
在这种情况下，引导法是否是我获取参数不确定性的正确方法？我也研究了引导残差，但我认为它无效，因为散斑噪声是乘性的，并且取决于观察的功率。统计学的这个领域对我来说很新，所以任何帮助都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649683/important-data-points-causing-problems-with-nonlinear-regression-bootstrapping</guid>
      <pubDate>Fri, 21 Jun 2024 18:50:21 GMT</pubDate>
    </item>
    <item>
      <title>这些是从我的代码生成的所谓的特征图吗？</title>
      <link>https://stats.stackexchange.com/questions/649680/are-these-generated-from-my-code-the-so-called-feature-maps</link>
      <description><![CDATA[我假设人们构建激活函数来检测图像中的特定部分的方式是通过执行网络并在每一层提取结果；当输出来自卷积层时，它被称为特征图（据我所知）。
我的问题是，实际上说这是一个特征图是否正确，这是每次运行网络到特定深度的结果（除了我丢弃的层）。
我生成的图像（这个问题是关于的。）在底部。
我是否正确地假设这里的layer.output是一个KerasTensor，它会记住到那时为止的所有变换（和权重）？
所以它在这里并不是一个真正的符号张量。
如果你想运行它，基于 keras 文档的代码，在笔记本中作为示例执行此操作，代码如下：
!pip install tensorflow[and-cuda]==2.16.1 keras==3.3.3

import os
os.environ[&quot;KERAS_BACKEND&quot;] = &quot;tensorflow&quot;

导入 numpy 作为 np
导入 tensorflow 作为 tf
导入 keras
从 keras 导入 o​​ps
从 keras 导入层
导入 imageio 作为 iio
从 PIL 导入图像
导入 matplotlib.pyplot 作为 plt
# 检索 vgg19
vgg19 = keras.applications.VGG19()
# 获取张量，可能还有历史记录
features_list = [layer.output for layer in vgg19.layers]
# 我不确定 keras 如何解释列表，但似乎
# 它将包含所有操作
feat_extraction_model = keras.Model(inputs=vgg19.input, output=features_list)
# 在互联网上的图像上进行测试（a狗。)
img=iio.imread(&quot;https://images.squarespace-cdn.com/content/v1/54822a56e4b0b30bd821480c/29708160-9b39-42d0-a5ed-4f8b9c85a267/labrador+retriever+dans+pet+care.jpeg?format=1500w&quot;)
img = Image.fromarray(img).resize((224, 224))
plt.imshow(img)

# print(img.shape)
img = tf.image.convert_image_dtype(image=img, dtype=&quot;float32&quot;)
img = tf.expand_dims(img,axis=0)
img = img.numpy().astype(&quot;float32&quot;)

extracted_features = feat_extraction_model(img)

fig = plt.figure(figsize=(20, 20))
columns = 4
rows = 7

for i, v in enumerate(extracted_features):
f = tf.squeeze(extracted_features[i])
if len(f.shape) != 3:
continue
if f.shape[-1] &gt; 3：
print(f.shape)
f = f[:,:,0:3] # 使用 3 个通道以便我们可以绘图
pil_img = keras.preprocessing.image.array_to_img(f)
fig.add_subplot(rows, columns, i+1)
plt.imshow(pil_img)
# time.sleep(10)
plt.show()


我得到了这个：
]]></description>
      <guid>https://stats.stackexchange.com/questions/649680/are-these-generated-from-my-code-the-so-called-feature-maps</guid>
      <pubDate>Fri, 21 Jun 2024 17:44:37 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑回归中交换预测变量和结果变量会有什么变化</title>
      <link>https://stats.stackexchange.com/questions/649678/what-changes-in-swapping-predictor-and-outcome-variables-in-logistic-regression</link>
      <description><![CDATA[我有一个数据集，其中包含一个表示细菌分离源的变量，该变量有 2 个因子，以及多个其他二进制变量，表示该细菌是否对某些抗生素具有耐药性（是或否）。
我一直在进行逻辑回归，最初将分离源视为预测因子。
glm &lt;- glm(antibiotic1 ~ source, data = df, family = binomial()) 
但是，我正在考虑将分离源视为结果的可能性。这样，我可以使用多个抗生素耐药性变量作为预测因子，让我可以对一些抗生素进行分组并进行多元逻辑回归，看看它是否能产生更好的见解。
glm &lt;- glm(source ~ antibiotic1 + antibiotic2, data = df, family = binomial()) 
这种方法可行吗？在可解释性方面会发生什么变化？以这种方式进行是否可取？]]></description>
      <guid>https://stats.stackexchange.com/questions/649678/what-changes-in-swapping-predictor-and-outcome-variables-in-logistic-regression</guid>
      <pubDate>Fri, 21 Jun 2024 17:12:15 GMT</pubDate>
    </item>
    <item>
      <title>心率测量 (bpm) 的 Bland-Altman 图遵循某些“线”模式</title>
      <link>https://stats.stackexchange.com/questions/649670/bland-altman-plot-for-heart-rate-measurements-bpm-follow-certain-line-patter</link>
      <description><![CDATA[我正在比较不同设备在不同活动期间（5 分钟休息、5 分钟锻炼和 5 分钟恢复）的心率测量值。
为了分析设备之间的一致性，我想制作 Bland Altman 图（使用极坐标 H10 作为黄金标准）。
但是，在使用所有参与者的数据制作 H10 与 Vantage V3 的 Bland Altman 图时，我注意到图中有一些奇怪的线条图案，我不完全确定为什么会出现这些图案/这意味着什么？

我还为每个参与者制作了图，如下所示：

创建 Bland Altman 图时对于此参与者，出现了以下线条模式：

在某种程度上，这些线条对我来说是有意义的，因为您可以清楚地看到，当开始锻炼时，平均心率会增加，设备之间的差异也会变大。而当完成锻炼时，平均心率以及差异会再次下降。
然而，在我读过的所有论文中，我都没有看到出现如此精确的线条模式，这让我怀疑我是否在这里做错了什么？
例如，我是否需要排除某些数据点，或者首先进行一些标准化？
任何想法或帮助，都将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/649670/bland-altman-plot-for-heart-rate-measurements-bpm-follow-certain-line-patter</guid>
      <pubDate>Fri, 21 Jun 2024 15:06:25 GMT</pubDate>
    </item>
    <item>
      <title>特定事件发生时间对响应的影响</title>
      <link>https://stats.stackexchange.com/questions/649668/impact-of-time-to-particular-event-on-response</link>
      <description><![CDATA[我正在尝试评估哪些变量会对结果产生影响。我的临床团队想检查特定事件发生的时间是否会影响结果。如果发生了特定事件，那么发生该事件的时间就很明显了，但如果没有发生该事件，该如何设置特定事件发生的时间。如果我将特定事件发生的时间设置为没有发生事件的患者接受治疗的最大时间，那么我会自动发现存在影响]]></description>
      <guid>https://stats.stackexchange.com/questions/649668/impact-of-time-to-particular-event-on-response</guid>
      <pubDate>Fri, 21 Jun 2024 14:42:32 GMT</pubDate>
    </item>
    <item>
      <title>不同长度合规率（按时间段）的单因素方差分析</title>
      <link>https://stats.stackexchange.com/questions/649647/one-way-anova-on-compliance-rates-by-time-period-with-different-lengths</link>
      <description><![CDATA[我对此有点困惑，因为在我的统计课上，我们很好地打包了数据，其中包含易于理解的良好、正常数据！如果这看起来太明显，请原谅。
我的数据是几个审计期 (AP) 中几类员工的一系列合规率。我们会说他们应该执行的操作是上班时刷卡。当然，合规率是他们实际刷卡的次数/他们预期刷卡的次数。
我有三个日期组要比较，但它们的长度各不相同，因为我们试图展示 COVID 期间和之后的合规性。每四个月测量一次数据，因此一年有三个 AP，从 11 月开始：

AP 1：11 月 1 日至 3 月 31 日
AP 2：4 月 1 日至 6 月 30 日
AP 3：7 月 1 日至 10 月 31 日

我正在观察 2018 年 11 月至 2022 年 10 月的数据，拆分如下：
日期组 1（COVID 之前，基线/对照）：

AP-1，2018 年 11 月 - 2019 年 3 月 31 日
AP-2，2019 年 4 月 1 日 - 2019 年 6 月 30 日
AP-3，2019 年 7 月 1 日 - 2019 年 10 月 31 日
AP-1，11 月 1 日2019 年 - 2020 年 3 月 31 日 [12 个月，共 4 个时间段]

日期组 2 (COVID)：

AP-2，2020 年 4 月 1 日 - 2020 年 6 月 30 日
AP-3，2020 年 7 月 1 日 - 2020 年 10 月 31 日
AP-1，2020 年 11 月 1 日 - 2021 年 3 月 31 日
AP-2，2021 年 4 月 1 日 - 2021 年 6 月 30 日
AP-3，2021 年 7 月 1 日 - 2021 年 10 月 31 日 [20 个月，共 5 个时间段]

日期组 3 (后疫情时代)：

AP-1，2020 年 11 月 1 日2021 - 2022 年 3 月 31 日
AP-2，2022 年 4 月 1 日 - 2022 年 6 月 31 日
AP-3，2022 年 7 月 1 日 - 2022 年 10 月 31 日 [9 个月，共 3 个时期]

所有类别员工的数据合计如下所示。



组
AP 代码
刷卡
总计条目
合规性




1
2019-1
1019
1231
0.790


1
2019-2
782
878
0.788


1
2019-3
934
1132
0.793


1
2020-1
973
1151
0.821


2
2020-2
640
749
0.834


2
2020-3
901
1075
0. 810


2
2021-1
952
1122
0.816


2
2021-2
674
807
0.800


2
2021-3
841
1001
0.804


&lt; td&gt;3
2022-1
727
857
0.820


3
2022-2
733
887
0.784


3
2022-3
868
1041
0.801



我想要使用方差分析来查看日期组 1（COVID 之前）与日期组 2 和 3（COVID 和 COVID 之后）之间的合规率是否存在显著差异。使用单向方差分析是解决方案吗？询问是因为我不习惯处理费率，而是“这是花瓣的长度”。如果有帮助的话，使用 R 工作。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649647/one-way-anova-on-compliance-rates-by-time-period-with-different-lengths</guid>
      <pubDate>Fri, 21 Jun 2024 08:33:58 GMT</pubDate>
    </item>
    <item>
      <title>统计学中的经验法则含义</title>
      <link>https://stats.stackexchange.com/questions/649644/rule-of-thumb-meaning-in-statistics</link>
      <description><![CDATA[我想知道统计学中“经验法则”一词的实际含义。为什么他们选择这个名称来计算样本量？它是否像是一种基于实践而非理论的近似值？]]></description>
      <guid>https://stats.stackexchange.com/questions/649644/rule-of-thumb-meaning-in-statistics</guid>
      <pubDate>Fri, 21 Jun 2024 07:46:05 GMT</pubDate>
    </item>
    </channel>
</rss>