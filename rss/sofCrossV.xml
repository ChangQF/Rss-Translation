<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 23 Sep 2024 21:15:34 GMT</lastBuildDate>
    <item>
      <title>我有 3 个组的配对数据，需要测试其中 2 个组是否在第三组的 10% 以内，同时控制另一个协变量</title>
      <link>https://stats.stackexchange.com/questions/654799/i-have-paired-data-with-3-groups-and-need-to-test-if-2-of-the-groups-are-within</link>
      <description><![CDATA[我有一个队列，每个成员都以 3 种不同的方式（a、b、c）进行了自我测试，并获得了连续的结果。
如果 a/b 在 c 的 10% 以内，同时控制其他变量 d，我将如何测试。这感觉像是等效性测试（tost），但我也认为这可能是一个 lme，但 10% 的临床意义让我感到困惑。]]></description>
      <guid>https://stats.stackexchange.com/questions/654799/i-have-paired-data-with-3-groups-and-need-to-test-if-2-of-the-groups-are-within</guid>
      <pubDate>Mon, 23 Sep 2024 19:54:12 GMT</pubDate>
    </item>
    <item>
      <title>我找不到合适的 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/654798/i-cant-find-a-good-fit</link>
      <description><![CDATA[我有两列。我想找到它们之间的数学关系。但不幸的是，我还是找不到合适的关系。如何使用 f 和 g 列中的数据找到数学关系，以便将数学关系乘以 f 中的数据生成 g 中的数据？
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit

dataset = pd.read_csv(&quot;data.csv&quot;)

z_data = dataset.iloc[:, 0].values 
x_data = dataset.iloc[:, 2].values 
y_data = dataset.iloc[:, 3].values

def exponential_func(x,a, b,c):
return a* x +b*np.sin(x)

params, covariance = curve_fit(exponential_func, x_data, y_data)

y_pred = exponential_func(x_data, *params)

plt.scatter(z_data,x_data, color=&#39;blue&#39;, label=&#39;f&#39;)
plt.scatter(z_data,y_data, color=&#39;black&#39;, label=&#39;g&#39;)
plt.scatter(z_data, y_pred, color=&#39;red&#39;, label=&#39;Fitted Curve&#39;)
#plt.scatter(z_data, np.poly1d(np.polyfit(x_data, y_data, 5)), color = &#39;blue&#39;)
plt.yscale(&quot;log&quot;)
plt.xlabel(&#39;X&#39;)
plt.ylabel(&#39;Y&#39;)
plt.legend()
plt.title(&#39;指数回归&#39;)
plt.show()
]]></description>
      <guid>https://stats.stackexchange.com/questions/654798/i-cant-find-a-good-fit</guid>
      <pubDate>Mon, 23 Sep 2024 18:29:46 GMT</pubDate>
    </item>
    <item>
      <title>从第一个时期开始初始验证损失就很低？</title>
      <link>https://stats.stackexchange.com/questions/654794/low-initial-validation-loss-from-the-first-epoch</link>
      <description><![CDATA[从第一个 epoch 开始，初始验证损失就很低，然后略有下降。这实际上意味着什么？这是否表明模型可以有效快速地识别此任务的模式？
我可以看到该模型在实践中有效，但结果（一些图像恢复）还不理想，所以我想进一步提高其性能。

鉴于第一个 epoch 的损失很低，我应该专注于使用更多数据进行训练还是调整架构和层以使其更加复杂等？

鉴于第一个 epoch 和最后一个 epoch 之间的差异很小，模型在这些 epoch 中几乎无法提高性能的可能性更大，还是损失的差异仍然有意义？


数据集数量为 10,000 张图像 - 0.9 用于训练，0.1 用于验证。
第一个 epoch 损失：
Epoch [1/50]，训练损失： 0.026428，验证损失：0.023727
最后一个时期和稳定期：
时期 [34/50]，训练损失：0.020682，验证损失：0.020651]]></description>
      <guid>https://stats.stackexchange.com/questions/654794/low-initial-validation-loss-from-the-first-epoch</guid>
      <pubDate>Mon, 23 Sep 2024 16:53:47 GMT</pubDate>
    </item>
    <item>
      <title>如何为支出不受控制但投资回报率可衡量的竞价策略设置 A/B 测试？</title>
      <link>https://stats.stackexchange.com/questions/654792/how-to-set-up-an-a-b-test-for-bidding-strategies-with-uncontrolled-spend-but-mea</link>
      <description><![CDATA[我正在对两种在线拍卖竞价策略进行 A/B 测试。一种策略（固定策略）只是在每次拍卖中（平均）出价固定金额。另一种策略根据过去几次拍卖的表现调整出价金额。
挑战在于我无法直接控制每种策略花费的金额。每次激活的目标费用 (CPA) 决定了总支出，这反过来又会影响转化次数，并最终影响投资回报率 (ROI)。我唯一能控制的方面是实验的持续时间。
我的目标是确定自适应策略在投资回报率方面是否能比固定策略高出至少 10%。
以下是我有几个关键问题：

在这种情况下，合适的随机化单位是什么？我们无法确定实验变体之间的美元金额或转化次数是否完全可比。

鉴于随机化单位的不确定性，简单的总利润（收入 - 支出）是否是确定实验结果的合适指标？在这种情况下，统计推断的合适方法是什么（我已阅读此帖子作为入门）。

样本大小和持续时间：如何确定适当的样本大小或实验持续时间以检测具有统计意义的 ROI 10% 提升？将随机化单位视为天数是否正确？

方差估计：鉴于支出不受目标每次转化费用直接控制，但受其影响，我应该使用哪些指标或技术来准确估计两组 ROI 的方差？

偏差缓解：如何解释可能造成偏差的支出或转化模式差异，尤其是当一种策略比另一种策略适应得更快时？

停止规则：由于我只能控制实验的运行时间，因此在实验期间和实验后应用哪些适当的停止标准或统计测试以确保结果可靠？


如能提供关于设置此类测试的最佳实践的任何指导，包括潜在的陷阱或确保稳健结果的方法，我将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/654792/how-to-set-up-an-a-b-test-for-bidding-strategies-with-uncontrolled-spend-but-mea</guid>
      <pubDate>Mon, 23 Sep 2024 16:46:42 GMT</pubDate>
    </item>
    <item>
      <title>如何在考虑不同回报模式的同时比较私募股权基金不同时期的 IRR？</title>
      <link>https://stats.stackexchange.com/questions/654788/how-to-compare-private-equity-fund-irrs-across-time-while-accounting-for-varying</link>
      <description><![CDATA[我有多个私募股权 (PE) 内部收益率 (IRR) 的时间序列，其中每个基金在开始时通常表现出较高的回报变化性，大部分回报在投资期结束时实现。这些系列也遵循典型的“J 曲线”模式，其中回报在最初几年为负或较低，而随着投资成熟和退出，正回报往往会在以后累积：

我的目标是比较 PE 基金投资组合在一段时间内的季度表现，类似于我们分析传统金融资产回报的方式，并最终构建一个包含其他变量的面板。然而，PE 回报的独特结构带来了一些挑战：

我尝试计算一阶差分来评估周期回报，但得到的序列不是方差平稳的，因为回报的波动性在基金生命周期的早期往往比后期高得多。
我还考虑过将确定性趋势拟合到时间序列中。在这里，我不确定：
(a) 我应该为每个基金的 IRR 系列拟合一个单独的趋势，还是
(b) 为所有 IRR 系列拟合一个单一的趋势，以解释 PE 回报的一般行为。

拟合单独趋势与拟合所有系列的统一趋势的优缺点是什么？在比较 PE 基金回报的长期表现时，是否有其他方法可以更好地解释其“J 曲线”性质？我希望转换后的时间序列是平稳的。
任何有关如何处理此类时间序列的指导，包括潜在的建模技术，都将不胜感激。
% 绘图数据 (MATLAB)

IRR =[-17.5000
-0.9000
-7.7000
-33.8000
-35.0115
-35.3700
-33.8000
-30.6000
-30.4000
-24.2000
-20.9000
-15.8500
-15.4000
-10.6500
-8.7500
-4.8000
-5.2000
-3.4000
-3.0500
-2.2000
-0.8500
    2.8500 3.9000 4.2500 5.4000 7.8800 6.9500 6.9500 5.4000 2.7500 2.6000 2.6300 3.3000 3.4100 3.7200 3.8000 3.7100 3.9250 4.4 000 4.4100 4.3600 4.3050 4.2300 4.4300 4.5000 4.2550 4.2500 4.2150 4.2200 4.7250 4.8100
    4.6150 4.6000 4.6500 4.7000 4.7000 4.8500 4.8000 5.0000 4.8000 4.9500 4.8000 4.9500 4.8000 4.9500 4.8000 4.9500 4.8000 4.9 500 4.8000 4.4800 4.4800 4.4800 4.4800 4.4800 4.7900 4.7900 4.6400 4.4800 4.8000 4.7900
4.7900
4.7900
4.7900
5.1000]
]]></description>
      <guid>https://stats.stackexchange.com/questions/654788/how-to-compare-private-equity-fund-irrs-across-time-while-accounting-for-varying</guid>
      <pubDate>Mon, 23 Sep 2024 15:48:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 Lavaan 对二进制变量进行引导</title>
      <link>https://stats.stackexchange.com/questions/654787/bootstrapping-of-binary-variables-using-lavaan</link>
      <description><![CDATA[我是 R 的新用户，在使用我的模型进行引导时遇到了问题。
所有外生、内生和中介变量都是二元结果。我尝试按照解决方案添加 se = &quot;bootstrap&quot;, estimator = &quot;DWLS&quot;, verbose = TRUE，但仍然不起作用。
请就此提出您的建议和意见。感谢您的时间。
这是我的代码
model19 &lt;-&#39;ls ~ a1*participation1 + health_status
health_status ~ a2*participation1
hsu~ d1*ls + d2*health_status +c1*participation1 +e1*rural + e2*female +
e3*middle+e4*oldest+e5*primary+e6*secondary+e7*higher+e8*married+
e9*all+e10*employ+e11*support+e12*pension
indirect1:=a1*d1
indirect2:=a2*d2
Overallindirect:= indirect1+ indirect2
Total:=overallindirect +c1+e1+e2+e3+e4+e5+e6+e7+e8+e9+e10+e11+e12&#39;
fit19 &lt;- sem(model19, data = old_main, ordered = c(&quot;hsu&quot;, &quot;ls&quot;, &quot;health_status&quot;),
se = &quot;bootstrap&quot;, estimator = &quot;DWLS&quot;, verbose = TRUE)
summary(fit19, unified=TRUE, ci=TRUE, fit.measures=TRUE)
]]></description>
      <guid>https://stats.stackexchange.com/questions/654787/bootstrapping-of-binary-variables-using-lavaan</guid>
      <pubDate>Mon, 23 Sep 2024 15:16:57 GMT</pubDate>
    </item>
    <item>
      <title>加权后进行 g 计算时如何决定使用哪个样条曲线？</title>
      <link>https://stats.stackexchange.com/questions/654784/how-to-decide-which-spline-to-use-when-conducting-g-computation-after-weighting</link>
      <description><![CDATA[我已经进行了统计加权（R 包 WeightIt），现在我正在使用 g 计算（R 包边际效应）来估计树木覆盖率对作物产量的影响（遵循 https://ngreifer.github.io/WeightIt/articles/estimating-effects.html）。我不希望这种关系是线性的，所以我想使用自然样条曲线，但我不确定要指定多少 df，例如，df=4 和 df=2 会导致非常不同的结果和解释。进行模型选择（例如使用 AIC）感觉不太合适，因为它是一种预测技术，不适合因果推理。那么我该如何为我的样条曲线选择正确的 df 数量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654784/how-to-decide-which-spline-to-use-when-conducting-g-computation-after-weighting</guid>
      <pubDate>Mon, 23 Sep 2024 14:43:42 GMT</pubDate>
    </item>
    <item>
      <title>矩阵的期望值=期望值矩阵？</title>
      <link>https://stats.stackexchange.com/questions/654777/expected-value-of-a-matrix-matrix-of-expected-value</link>
      <description><![CDATA[我对以下陈述感到疑惑：矩阵的期望等于期望矩阵。
例如，假设 A 是一个由 4 个随机变量组成的矩阵，W、X、Y、Z
那么，我们通常写为 E(A) = E(R.V.) 矩阵
这总是正确的吗？
如果部分/全部 R.V. 是相关的怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/654777/expected-value-of-a-matrix-matrix-of-expected-value</guid>
      <pubDate>Mon, 23 Sep 2024 13:26:45 GMT</pubDate>
    </item>
    <item>
      <title>两个比率指标之间的变异系数</title>
      <link>https://stats.stackexchange.com/questions/654776/coefficient-of-variation-between-two-ratio-metrics</link>
      <description><![CDATA[我想比较哪个指标更稳定（每次展示费用与每次视频观看费用）。
我使用了 CV（变异系数），并寻找了在使用不同货币的多个广告系列中，对于同一广告系列，哪个指标 CV 较低。这种方法合适吗？数据不呈正态分布有关系吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654776/coefficient-of-variation-between-two-ratio-metrics</guid>
      <pubDate>Mon, 23 Sep 2024 13:24:12 GMT</pubDate>
    </item>
    <item>
      <title>Tobit 模型正态性假设</title>
      <link>https://stats.stackexchange.com/questions/654764/tobit-model-normality-assumption</link>
      <description><![CDATA[对于 tobit 模型，我对正态性假设有点困惑。是不是我的因变量必须服从正态分布？还是我的模型的潜在残差必须服从正态分布？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/654764/tobit-model-normality-assumption</guid>
      <pubDate>Mon, 23 Sep 2024 09:07:10 GMT</pubDate>
    </item>
    <item>
      <title>如何简化径向图网络同时保留关键信息？</title>
      <link>https://stats.stackexchange.com/questions/654742/how-can-i-simplify-a-radial-graph-network-while-preserving-key-information</link>
      <description><![CDATA[我创建了一个径向图网络来可视化大脑区域之间的连接。每个区域都用一个圆圈表示，每个区域使用独特的颜色。圆圈边框表示组/子网络成员身份，大小反映网络度量（中介中心性）。然而，使用多种颜色似乎会增加读者的认知负荷。您能否建议一些简化可视化的方法，同时保留以下三个关键方面：
1. 确定哪个节点代表哪个大脑区域及其连接
2. 指示子网络成员身份
3. 显示节点的大小以表示网络度量尺度


这是一个变体，我使用形状和强度来表示特征，如评论中所建议的那样。请告诉我您的想法：
]]></description>
      <guid>https://stats.stackexchange.com/questions/654742/how-can-i-simplify-a-radial-graph-network-while-preserving-key-information</guid>
      <pubDate>Sun, 22 Sep 2024 22:54:05 GMT</pubDate>
    </item>
    <item>
      <title>如何使用生存分析对不同期限的分期付款进行建模？</title>
      <link>https://stats.stackexchange.com/questions/654738/how-to-model-installment-payments-with-different-durations-using-survival-analys</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654738/how-to-model-installment-payments-with-different-durations-using-survival-analys</guid>
      <pubDate>Sun, 22 Sep 2024 19:55:11 GMT</pubDate>
    </item>
    <item>
      <title>均值较小的逆高斯分布具有不可靠的样本均值</title>
      <link>https://stats.stackexchange.com/questions/654737/inverse-gaussian-with-small-mean-has-unreliable-sample-mean</link>
      <description><![CDATA[考虑一个平均值为$\mu$（如$0.001$）的逆高斯分布，我们将其方差固定为一个较大的值$\sigma^2$，比如说$0.5$。然后，如果我从该分布中抽取 $N$ 次样本，我预计样本平均值约为 $\mu$，但除非 $N$ 的值非常大，否则这种情况不会发生。
import scipy as sp

N = 1_000 # 我们至少需要使用 10_000_000，否则它会非常小，比如 1e-6 
mean = 0.001
var = 0.5
lmbda = mean**3 / var

print(f&quot;样本平均值：{sp.stats.invgauss.rvs(mu=(mean/lmbda), loc=0, scale=lmbda, size=N).mean()}&quot;)

如果您运行此脚本N 等于 1000、10_000、1_000_000，您将得到大约 1e-6，其数量级与均值的平方相同。

为什么会出现这种情况，我该如何避免？即，我可以从均值较小、方差相对较大的逆高斯中采样，而不会产生数值问题吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/654737/inverse-gaussian-with-small-mean-has-unreliable-sample-mean</guid>
      <pubDate>Sun, 22 Sep 2024 19:23:53 GMT</pubDate>
    </item>
    <item>
      <title>在加法和乘法生存模型之间进行选择</title>
      <link>https://stats.stackexchange.com/questions/654533/choosing-between-additive-and-multiplicative-survival-model</link>
      <description><![CDATA[我正在使用生存模型对住房建设时机进行研究。我现在面临的问题是选择加法生存模型还是乘法生存模型。在两者之间进行选择时我应该考虑什么，是否有任何测试统计数据可以帮助做出此决定？]]></description>
      <guid>https://stats.stackexchange.com/questions/654533/choosing-between-additive-and-multiplicative-survival-model</guid>
      <pubDate>Wed, 18 Sep 2024 07:33:59 GMT</pubDate>
    </item>
    <item>
      <title>R 中纵向数据中缺失数据的插补</title>
      <link>https://stats.stackexchange.com/questions/654483/missing-data-imputation-in-longitudinal-data-in-r</link>
      <description><![CDATA[我有非常大的数据集（大约 1000 万行），其中重复测量了大约 500 000 个个体，这些个体随时间不规则地分布。我的最终目标是进行 IPTW 并拟合具有随时间变化的协变量和竞争风险的加权 cox 回归。（比较某些药物对中风风险的影响和死亡竞争风险）。我有几个变量的缺失数据百分比很大（缺失范围从 0 到 50%），一些是连续的，一些是二进制的，一些是序数的。
我想在分析之前估算这些数据，因为完整的案例分析会有偏差，而且据我所知，ipw 包不允许在混杂因素中出现缺失数据。
问题是，由于我们有重复测量，所以这些是聚类数据，因此我们需要 2 级估算。
我正在考虑使用 R 中的 mice 包尝试 2 级多重插补和预测均值匹配。
我的问题是：

这是一种有效的方法吗？
这种方法在高端台式机上是否可以计算，比如说 5 次插补和 10 次迭代？
还有其他更有效和/或更有效的方法吗？

最重要的是，实现是否以更适合初学者的方式描述，也许是一个好的教程或示例？
附言：到目前为止，我只在 SPSS 中做过 PMM，而且它出奇地容易实现。理想情况下，我想要一种数据操作最少的方法，但我不知道这是否可行。]]></description>
      <guid>https://stats.stackexchange.com/questions/654483/missing-data-imputation-in-longitudinal-data-in-r</guid>
      <pubDate>Tue, 17 Sep 2024 13:16:17 GMT</pubDate>
    </item>
    </channel>
</rss>