<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 05 Dec 2024 21:16:55 GMT</lastBuildDate>
    <item>
      <title>我应该使用什么统计数据？</title>
      <link>https://stats.stackexchange.com/questions/658347/what-stats-should-i-use</link>
      <description><![CDATA[我有一组受试者，他们都完成了相同的游泳计时赛 (6)。我想使用 2 种不同的测量方法评估每次试验中的 1 个变量，然后查看测量结果之间的关系。]]></description>
      <guid>https://stats.stackexchange.com/questions/658347/what-stats-should-i-use</guid>
      <pubDate>Thu, 05 Dec 2024 20:00:20 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 匹配对符号秩和相关性（pearson、spearman）</title>
      <link>https://stats.stackexchange.com/questions/658344/wilcoxon-matched-pair-signed-rank-and-correlation-pearson-spearman</link>
      <description><![CDATA[根据出版物《提取重复测量设计的荟萃分析的前后相关性》[https://matthewbjane.quarto.pub/pre-post-correlations/][1]，如果配对 t 检验的 t 统计量值可用，则可以计算相关样本中前后得分之间的皮尔逊相关性。
pre_mean &lt;- 12.62
pre_sd &lt;- 3.845
post_mean &lt;- 18.33
post_sd &lt;- 5.155
paired_t &lt;- 10.52
n &lt;- 78

r &lt;- (paired_t^2*(sd_pre^2 + sd_post^2)-n*(post_mean-pre_mean)^2) / 
(2*paired_t^2*sd_pre*sd_post)

r

还提到，可以根据配对 t 检验的 p 值计算 Pearson 相关性。
pre_mean &lt;- 12.62
pre_sd &lt;- 3.845
post_mean &lt;- 18.33
post_sd &lt;- 5.155
pval &lt;- 1.5e-16 # 来自配对 t 检验
n &lt;- 78

# 从 p 值获取配对 t
paired_t &lt;- qt(pval/2, n-1, lower.tail = FALSE)

r &lt;- (paired_t^2*(sd_pre^2 + sd_post^2)-n*(post_mean-pre_mean)^2) /
(2*paired_t^2*sd_pre*sd_post)

我在网站 https://stats.stackexchange.com/questions/658191/extraction-pre-post-correlation-of-repeated-measures-design?noredirect=1#comment1237216_658191 上找到了类似的问题，但我找不到我想要的答案。
我的问题是：这些公式可以扩展到 Wilcoxon 符号秩检验 及其对应的 p 值吗？我的意思是，如果我们在运行 Wilcoxon 符号秩检验后知道 p 值（甚至可以访问 W 统计量），我们可以计算相关性（Spearman 或 Pearson）吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658344/wilcoxon-matched-pair-signed-rank-and-correlation-pearson-spearman</guid>
      <pubDate>Thu, 05 Dec 2024 19:25:03 GMT</pubDate>
    </item>
    <item>
      <title>在不估计间接影响的情况下建立纵向关系模型</title>
      <link>https://stats.stackexchange.com/questions/658343/modeling-longitidunal-relationships-without-estimating-indirect-effects</link>
      <description><![CDATA[我正在使用结构方程模型 (SEM) 分析一项三时点研究。我只关心变量的直接影响。只建模那些直接路径可以吗，还是应该包括间接路径，即使我对它们不感兴趣？就像下图中一样，我想这样建模。这对你来说合乎逻辑吗？谢谢。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658343/modeling-longitidunal-relationships-without-estimating-indirect-effects</guid>
      <pubDate>Thu, 05 Dec 2024 19:20:37 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中缩放和重新缩放具有线性核的 svr 模型的特征[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658340/how-do-i-scale-and-rescale-my-features-in-r-for-a-svr-model-with-a-linear-kernel</link>
      <description><![CDATA[scale_features &lt;- function(df, columns, scaler = NULL) {
if (is.null(scaler)) {
scaler &lt;- preProcess(df[, columns], method = c(&quot;center&quot;, &quot;scale&quot;))
}
df[, columns] &lt;- predict(scaler, df[, columns])
return(list(df = df, scaler = scaler))
}

# 缩放训练数据并保存缩放器
train_scaled &lt;- scale_features(training_data, numeric_features)
training_data &lt;- train_scaled$df
scaler &lt;- train_scaled$scaler

# 使用相同缩放器缩放验证和测试数据
validation_data &lt;- scale_features(validation_data, numeric_features, scaler)$df
test_data &lt;- scale_features(test_data, numeric_features, scaler)$df

# 第 6 步：缩放目标变量
target_mean &lt;- mean(training_data$total_quantities, na.rm = TRUE)
target_sd &lt;- sd(training_data$total_quantities, na.rm = TRUE)

scale_target &lt;- function(y, mean, sd) {
return((y - mean) / sd)
}

unscale_target &lt;- function(y_scaled, mean, sd) {
return((y_scaled * sd) + mean)
}

# 缩放训练中的目标变量数据
训练数据$total_quantities_scaled &lt;- scale_target(训练数据$total_quantities, target_mean, target_sd)

train_preds_unscaled &lt;- unscale_target(train_preds_scaled, target_mean, target_sd)```
]]></description>
      <guid>https://stats.stackexchange.com/questions/658340/how-do-i-scale-and-rescale-my-features-in-r-for-a-svr-model-with-a-linear-kernel</guid>
      <pubDate>Thu, 05 Dec 2024 18:58:48 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 变分自动编码器无法通过 Pytorch 学习 [重复]</title>
      <link>https://stats.stackexchange.com/questions/658339/lstm-variational-auto-encoder-not-learning-with-pytorch</link>
      <description><![CDATA[我正在尝试训练 LSTM 变分自动编码器，但我无法弄清楚为什么模型没有取得任何进展，损失立即停滞。
这是我的代码和训练循环。序列由 10 个数字组成，这些数字在 0 和 1 之间标准化，压缩到 5 的瓶颈中，然后解码。这些数字不是随机的 - 它们是玩家的反应时间。我曾尝试在 500、10k、100k 和 500k 个示例上进行训练，但没有成功。
我正在尝试使用 LSTM 进行编码并使用正常的密集层进行解码。如果您需要任何其他信息或发现其他信息，请告诉我。谢谢！
VAE：https://hastebin.skyra.pw/yayecitowa.py
火车：https://hastebin.skyra.pw/oyucawefuf.py
第 1 轮和第 100 轮的输出示例：https://hastebin.skyra.pw/ucodelibut
第 1 纪元的损失：21.7765
纪元损失100：21.7266]]></description>
      <guid>https://stats.stackexchange.com/questions/658339/lstm-variational-auto-encoder-not-learning-with-pytorch</guid>
      <pubDate>Thu, 05 Dec 2024 18:32:14 GMT</pubDate>
    </item>
    <item>
      <title>患者死亡率逻辑回归模型中的交互项</title>
      <link>https://stats.stackexchange.com/questions/658338/interaction-terms-in-logistic-regression-model-of-patient-mortality</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658338/interaction-terms-in-logistic-regression-model-of-patient-mortality</guid>
      <pubDate>Thu, 05 Dec 2024 18:29:48 GMT</pubDate>
    </item>
    <item>
      <title>电源状态样本量</title>
      <link>https://stats.stackexchange.com/questions/658337/statum-sample-size-for-power</link>
      <description><![CDATA[我打算进行多元回归分析，独立变量为少数民族身份（是/否）。使用 G*Power，我计算出所需的总体样本量为 543 名参与者。为了确保有足够的少数民族和非少数民族参与者，我需要使用分层随机抽样。但是，我现在不确定多少才算“足够”，或者换句话说，如何计算每个阶层的样本量才能有足够的统计能力。
我应该为每个阶层（少数民族和非少数民族）招募 543 名参与者吗？
多少过采样才算足够的过采样？
少数民族比例为 15%。总样本量为 543 只会产生约 81 名少数民族参与者。这对于具有 10 个预测因子的良好回归来说是不够的。
感谢您的指导。]]></description>
      <guid>https://stats.stackexchange.com/questions/658337/statum-sample-size-for-power</guid>
      <pubDate>Thu, 05 Dec 2024 18:14:11 GMT</pubDate>
    </item>
    <item>
      <title>将拟泊松模型与泊松模型进行比较是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/658335/does-this-comparison-of-the-quasipoisson-model-to-the-poisson-model-make-sense</link>
      <description><![CDATA[我正在尝试使用拟似然法，所以这是我的第一次尝试。我想我误解了一个关键部分，因为我确实理解为什么参数估计是相同的（因为它们都最大化了相同的对数似然函数）并且由于过度分散，标准误差是不同的，但是为什么偏差相同？
当我的教授看到我的代码时，他说你不能真正比较它们，因为它们不是“嵌套的”，但他也说要查看残差平方和。
代码如下：
&gt; library(ggplot2)
&gt; set.seed(42)
&gt; 
&gt; n &lt;- 100
&gt; x &lt;- runif(n, 0, 10)
&gt; beta_0 &lt;- 1.0
&gt; beta_1 &lt;- 0.5
&gt; mu &lt;- exp(beta_0 + beta_1 * x)
&gt; phi &lt;- 2
&gt; y_overdispersed &lt;- rnbinom(n, size = phi, mu = mu)
&gt; 数据 &lt;- data.frame(x = x, y = y_overdispersed)
&gt; 
&gt; model_quasi &lt;- glm(y ~ x, family = quasipoisson(link = &quot;log&quot;), 
data = data)
&gt; 数据$pred_quasi &lt;- predict(model_quasi, type = &quot;response&quot;)
&gt; 
&gt; model_poisson &lt;- glm(y ~ x, family = poisson(link = &quot;log&quot;), 
data = data)
&gt; data$pred_poisson &lt;- predict(model_poisson, type = &quot;response&quot;)
&gt; 
&gt; cat(&quot;准泊松模型摘要:\n&quot;)
准泊松模型摘要：
&gt; summary(model_quasi)

调用：
glm(formula = y ~ x, family = quasipoisson(link = &quot;log&quot;), 
data = data)

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.81145 0.30410 2.668 0.00892 ** 
x 0.50345 0.03593 14.012 &lt; 2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（准泊松系列的分散参数取为 29.85742）

零偏差：99 个自由度上的 12464.7
残差偏差：98 个自由度上的 2696.6
AIC：NA

Fisher 评分迭代次数：5

&gt; 
&gt; cat(&quot;\n常规泊松模型摘要:\n&quot;)

常规泊松模型摘要：
&gt; summary(model_poisson)

调用：
glm(formula = y ~ x, family = poisson(link = &quot;log&quot;), data = data)

系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 0.811453 0.055653 14.58 &lt;2e-16 ***
x 0.503446 0.006575 76.56 &lt;2e-16 ***
---
有效代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(泊松族的分散参数取为 1)

零偏差：99 个自由度上的 12464.7
残差偏差：98 个自由度上的 2696.6
AIC：3203.9

Fisher 评分迭代次数：5
]]></description>
      <guid>https://stats.stackexchange.com/questions/658335/does-this-comparison-of-the-quasipoisson-model-to-the-poisson-model-make-sense</guid>
      <pubDate>Thu, 05 Dec 2024 17:46:41 GMT</pubDate>
    </item>
    <item>
      <title>矩阵方差分析的计算问题</title>
      <link>https://stats.stackexchange.com/questions/658334/computation-question-for-anova-with-matrices</link>
      <description><![CDATA[我目前正在为期末考试做准备，遇到了这道令我难以解答的问题。线性回归模型的定义一如既往（在这种特定情况下有 2 个协变量）：
$Y_i=\beta_0+\beta_1X_{i1}+\beta_2X_{i2}+\epsilon_{i}$ 其中 $\epsilon_i \sim N(0,\sigma^2)$
问题中给出了以下内容：
$
(X^TX)^{-1}=\begin{bmatrix}
3.80427 &amp;-0.38533 &amp;-1.47616 \\
-0.38533 &amp; 0.14379 &amp;-0.00997 \\
-1.47616 &amp; -0.0097 &amp; 0.86774
\end{bmatrix} 
$
$
(Y^TX)=\begin{bmatrix}
739\\
2304.4
\\1282.8
\end{bmatrix}
$
$
(Y^TY)=100485
$
我被要求构建一个方差分析表来测试协变量是否解释响应变量（$\alpha=0.05$）。我完全明白该怎么做（简单的 F 检验，来自我的 MSR/MSE），但我不确定如何找到 SST 或 SSR
SSE 可以通过以下操作轻松找到：
$
\begin{align}
SSE = \sum(e_{i})^2=(Y-\hat{Y})^T(Y-\hat{Y})\\
=(Y^T-\hat{Y}^T)(Y-\hat{Y})\\=Y^TY-Y^T\hat{Y}\\=Y^TY-Y^TX\beta\\=Y^TY-\beta^TX^TY
\end{align}
$
其中 $\beta$ 可以按常规方式找到。问题在于找到 SSR 或 SST，因为它们都需要明确定义 $Y$ 矩阵（据我所知）。有人能给出解决此类问题的提示吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658334/computation-question-for-anova-with-matrices</guid>
      <pubDate>Thu, 05 Dec 2024 17:34:15 GMT</pubDate>
    </item>
    <item>
      <title>从混合模型中的预设 R^2 导出伽马参数</title>
      <link>https://stats.stackexchange.com/questions/658330/derive-gamma-parameters-from-preset-r2-in-mixed-models</link>
      <description><![CDATA[对于 R 中的模拟研究，我想根据预设的 $R^2$ 选择效果大小。
考虑这个两级随机截距混合模型，其中一个 L1 预测因子 $X_{ij}$ 和一个 L2 预测因子 $M_{j}$：
$y_{ij} = \beta_{0j} + \beta_{10} \cdot X_{ij} + \epsilon_{ij} $
$\beta_{0j} = \gamma_{00} + \gamma_{01} \cdot M_{j} + U_{0j}$
$\beta_{10} = \gamma_{10} $
其中：
$\epsilon \sim\ (N,\sigma^2)$ 和
$U_{oj} \sim\ (N,\tau^2) $
据我了解，在混合模型框架中有多个 $R^2$ 的定义。
按照 Snijders 和 Bosker 的方法，我了解到 $R^2$ 在第 1 级的定义为：
$R^2_{1} = 1 - \frac{\sigma^2_{\text{model}} + \tau_{0,\text{model}}^2}{\sigma^2_{\text{null}} + \tau_{0,\text{null}}^2}$
该方程表示在第 1 级解释的方差比例（组内方差和总方差相结合），比较零模型和拟合模型的方差。
我的目标是将 $R_{1}^2$ 值固定为例如$R_{1}^2 = 0.3$，并从中导出伽马参数。
但是，我不确定所有方差分量。有人知道如何做到这一点吗？
Snijders, T. A., &amp; Bosker, R. J. (1994). 两级模型中的模型方差。社会学方法与研究，22(3)，342-363。]]></description>
      <guid>https://stats.stackexchange.com/questions/658330/derive-gamma-parameters-from-preset-r2-in-mixed-models</guid>
      <pubDate>Thu, 05 Dec 2024 14:47:37 GMT</pubDate>
    </item>
    <item>
      <title>反向编码李克特数据以获得克隆巴赫的 Alpha</title>
      <link>https://stats.stackexchange.com/questions/658328/reverse-coding-likert-data-for-cronbachs-alpha</link>
      <description><![CDATA[我正在完成一项考试，考试中我们得到了李克特数据，其中有 2 个问题采用了否定措辞。数据包含缺失值，这些值是 MCAR（列表删除不合适，它会丢失 3/4 的观测值）。
在计算 Cronbach 的 alpha 之前，我对负面措辞的问题进行了反向编码（下面的代码）。
这导致 alpha 为 -0.03，并且错误表明一半的问题与第一个主成分呈负相关。
运行相同的代码，而不对负面问题进行反向编码，导致 alpha 为 0.6，并且每个问题的可靠性评估的可解释结果被删除。
我请求一些建议，关于可能导致这种情况的原因（无论是缺失数据、反向编码）还是初始数据的尺度错误。
我已附上我的代码以供参考：
# 反向代码 Q2 和 Q6
data[ , 2] = 6 - data[ , 2] #问题 2
data[ , 6] = 6 - data[ , 6] # 问题 6

计算 Cronbach&#39;s Alpha
CronbachAlpha(data[,2:10], cond=TRUE , conf.level=0.95) 
由于存在缺失数据，Cronbach&#39;s alpha=NA
用于 cronbachs alpha 的 Psych 包默认查找缺失数据的成对相关性
library(psych)
psych::alpha(data[,2:12])

尽管问题 2 和 6 是反向编码的，但似乎 Q1、Q2、Q3 和 Q6 与第一个 PC 相关，建议进行反向编码。]]></description>
      <guid>https://stats.stackexchange.com/questions/658328/reverse-coding-likert-data-for-cronbachs-alpha</guid>
      <pubDate>Thu, 05 Dec 2024 14:45:44 GMT</pubDate>
    </item>
    <item>
      <title>为何我的 GMM 实施会失败？</title>
      <link>https://stats.stackexchange.com/questions/658327/why-does-my-gmm-implementation-fail</link>
      <description><![CDATA[在使用包含许多参数和矩条件的模型时我遇到一个问题，具体来说是 13 个参数和 18 个条件。当我在 R 中运行 GMM 包时，我收到如下错误消息：

ar.ols(x, aic = aic, order.max = order.max, na.action = na.action, 中的错误：&#39;order.max&#39; 必须小于 &#39;n.used&#39;
AllArg$bw(obj, order.by = AllArg$order.by, kernel = AllArg$kernel, 中的错误：VAR(1) 估计函数的预白化失败

为什么？是因为对象函数太复杂吗？
代码如下：
data &lt;- read_excel(&quot;data.xls&quot;)

# 定义矩条件函数

moment_conditions &lt;- function(par, data) {

Y_1 &lt;- 数据$Y_1
  Y_2 &lt;- 数据$Y_2
  Y_3 &lt;- 数据$Y_3
  X_1 &lt;- 数据$X_1
  X_2 &lt;- 数据$X_2
  X_3 &lt;- 数据$X_3

  # 矩条件
  m_1 &lt;- var(Y_1) - (par[1]^2 * par[4]^2 * par[7] + par[1]^2 * par[5]^2 * par[8] +
                             参数[1]^2 * 参数[6]^2 * 参数[9] + 参数[1]^2 * 参数[10] + 参数[11])
  
  m_2 &lt;- var(Y_2) - (par[2]^2 * par[4]^2 * 参数[7] + 参数[2]^2 * 参数[5]^2 * 参数[8] +
                             par[2]^2 * par[6]^2 * par[9] + par[2]^2 * par[10] + par[12])
  
  m_3 &lt;- var(Y_3) - (par[3]^2 * par[4]^2 * par[7] + par[3]^2 * par[5]^2 * par[8] +
                             par[3]^2 * par[6]^2 * par[9] + par[3]^2 * par[10] + par[13])
  
  m_4 &lt;- cov(Y_1, Y_2) - (par[1]^2 * par[4]^2 * par[7] * par[2] + 
                                   par[1]^2 * par[5]^2 * par[8] * par[2] + 
                                   参数[1]^2 * 参数[6]^2 * 参数[9] * 参数[2] + 参数[1]^2 * 参数[10] * 参数[2])
  
  m_5 &lt;- cov(Y_1, Y_3) - (par[1]^2 * par[4]^2 * par[7] * par[3] + 
                                   par[1]^2 * par[5]^2 * par[8] * par[3] + 
                                   参数[1]^2 * 参数[6]^2 * 参数[9] * 参数[3] + 参数[1]^2 * 参数[10] * 参数[3])
  
  m_6 &lt;- cov(Y_2, Y_3) - (par[2]^2 * par[4]^2 * par[7] * par[3] + 
                                   par[2]^2 * par[5]^2 * par[8] * par[3] + 
                                   par[2]^2 * par[6]^2 * par[9] * par[3] +参数[2]^2 * 参数[10] * 参数[3])
  
  m_7 &lt;- cov(Y_1, X_1) - par[1] * par[4] * par[7]
  m_8 &lt;- cov(Y_1, X_2) - par[1] * par[5] * par[8]
  m_9 &lt;- cov(Y_1, X_3) - par[1] * par[6] * par[9]
  
  m_10 &lt;- cov(Y_2, X_1) - par[2] * par[4] * par[7]
  m_11 &lt;- cov(Y_2, X_2) - par[2] * par[5] * par[8]
  m_12 &lt;- cov(Y_2, X_3) - par[2] * par[6] * par[9]
  
  m_13 &lt;- cov(Y_3, X_1) - par[3] * par[4] * par[7]
  m_14 &lt;- cov(Y_3, X_2) - par[3] * par[5] * par[8]
  m_15 &lt;- cov(Y_3, X_3) - par[3] * par[6] * par[9]
  
  m_16 &lt;- var(X_1) - par[7]
  m_17 &lt;- var(X_2) - par[8]
  m_18 &lt;- var(X_3) - par[9]

    f &lt;- cbind(
    m_1、m_2、m_3、m_4、m_5、m_6、m_7、m_8、m_9、m_10、
    m_11、m_12、m_13、m_14、m_15、m_16、m_17、 m_18
)

return(f) 
}

gmm(moment_conditions, x = data, t0 = rep(0, 13))

]]></description>
      <guid>https://stats.stackexchange.com/questions/658327/why-does-my-gmm-implementation-fail</guid>
      <pubDate>Thu, 05 Dec 2024 14:24:13 GMT</pubDate>
    </item>
    <item>
      <title>零膨胀模型，值较低但没有零？</title>
      <link>https://stats.stackexchange.com/questions/658326/zero-inflated-model-with-low-values-but-no-zeros</link>
      <description><![CDATA[我是建模新手，这个问题可能很荒谬，但我正尝试仅使用阳性个体来模拟具有物种*生命阶段相互作用效应的病原体负荷计数数据。
即，那些具有零负荷（感染为阴性）的个体被从分析中删除，并且仅对负荷&gt; 0的阳性个体进行分析）
我已经在使用负二项式 GLM 模型（glmmTMB 包），因为有很多低计数，但是当我使用 DHarma 时，我发现仍然有零膨胀（尽管子集数据中没有零）

是否有可能对没有零的数据使用零膨胀模型？
我还能如何解决这个问题？
任何帮助都值得赞赏！]]></description>
      <guid>https://stats.stackexchange.com/questions/658326/zero-inflated-model-with-low-values-but-no-zeros</guid>
      <pubDate>Thu, 05 Dec 2024 14:15:54 GMT</pubDate>
    </item>
    <item>
      <title>数据通过了除正态性之外的所有线性检验。我的下一步应该怎么做？</title>
      <link>https://stats.stackexchange.com/questions/658300/data-passing-all-linearity-checks-except-normality-what-should-my-next-steps-be</link>
      <description><![CDATA[我需要为一系列具有相同问题的数据集构建模型。

&quot;目测&quot; 让我相信数据最适合线性回归。我的数据似乎通过了同质性假设 (leveneTest pval &gt; 0.05) 和线性假设 (需要对独立性进行更多研究)。没有点的 Cook 距离 &gt; 0.5，这表明没有高度有影响力的异常值。但是，我的线性图表未通过正态性检验。
P-val 为 &lt; 0.05 用于 shapiro.test(residuals(model)) 检查。
qq 图的尾部下降：

我试过平方根 &amp; y 的 Box-Cox 变换，以及更稳健的建模，如 rlm 和 glm（针对转换和未转换的数据），但这些都产生了类似的结果。
我承认，通常没有办法转换数据以使其正常化。
我所有的问题都围绕着同一个主题：我接下来该怎么做才能对这些数据进行建模？
我还能合理地使用线性回归来对这些数据进行建模吗？
由于我的大多数数据集都超过 500 分，我可以合理地声称 C.L.T 吗？
我可以使用其他建模方法吗？或者我完全错过了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658300/data-passing-all-linearity-checks-except-normality-what-should-my-next-steps-be</guid>
      <pubDate>Thu, 05 Dec 2024 06:29:11 GMT</pubDate>
    </item>
    <item>
      <title>是否有技术可以分析具有包含数字范围而不是单个值的预测变量的数据？</title>
      <link>https://stats.stackexchange.com/questions/658293/are-there-techniques-for-analyzing-data-that-have-predictor-variables-that-conta</link>
      <description><![CDATA[是否有分析数据的技术，其中预测变量包含数字范围而不是单个值？例如，可以从 0 至 5 厘米深度、5 至 10 厘米深度和 10 至 20 厘米深度获取土壤样本（请注意这些范围的宽度不一致）。我可以将这些组视为类别，但这样我就会丢失有关它们位置的信息；我可以对它们进行排名，但在我的示例中，排名不会考虑范围宽度的差异。
非常感谢您的回答。以下是我对它们的回复。
中点想法有些道理，因为在我给出的土壤采样示例中，提取的土壤圆柱体在其整个长度上都是一个恒定的面积，但如果响应变量是（例如）氮浓度，并且深度范围内最浅深度的氮浓度远高于该深度范围内其他地方的氮浓度，结果可能会非常偏差。如果面积随深度而变化，我可以计算形状的质心（如果可以进行该计算的话），并将其用作值而不是中点。
我喜欢随机噪声的一些想法。也许更准确的方法是将每个类别细分为小区间，并对该类别中的每个单个点（即类别中的值）使用该类别的响应变量。在我的土壤示例中，我可以使用 0 到 5 厘米深度的测量值来测量 1、2、3 和 4 厘米深度，我可以使用 5 到 10 厘米深度的测量值来测量 6、7、8 和 9 厘米深度，我可以使用 10 到 20 厘米深度的测量值来测量 11、12、13、14、15、16、17、18 和 19 厘米深度。
由于上述原因（如果由于较高值主要出现在范围的一端，每个类别内都存在差异），我对在每个类别中建模噪声有点怀疑。
在我的示例中，每个类别在两侧都有界，但我可以想象其他示例中至少有一个类别是无限制。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658293/are-there-techniques-for-analyzing-data-that-have-predictor-variables-that-conta</guid>
      <pubDate>Thu, 05 Dec 2024 01:15:37 GMT</pubDate>
    </item>
    </channel>
</rss>