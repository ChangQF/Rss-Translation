<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 03 Feb 2024 15:12:37 GMT</lastBuildDate>
    <item>
      <title>1 个问题。 6个因素。每个都有从 1 到 5 的李克特量表。我如何分析结果来回答我的假设？</title>
      <link>https://stats.stackexchange.com/questions/638481/1-question-6-factors-each-with-a-likert-scale-from-1-to-5-how-can-i-analyze-t</link>
      <description><![CDATA[希望你们一切都好。我发现自己的研究项目需要一些统计指导，我非常感谢您的专业知识。我正在开展一个项目，探索某个国家对不同方面（口味、健康、可持续性、价格）的偏好及其影响关于肉类替代品的接受度。
假设：
H0：消费者选择肉类替代品的主要动机因素不是口味，健康、可持续性和价格等其他因素同样或更有影响力。
H1：消费者选择肉类替代品的主要动机因素是口味，与健康、可持续性和价格等其他因素相比，它的重要性更大。我使用李克特量表要求受访者对六个因素的重要性进行评分因素（口味是第一位的）。李克特量表从 1 升至 5。
1 = 一点也不重要
3 = 中性
5 = 非常重要
我的调查数据中的每一行代表一名受访者。对于每个受访者，六个因素都会有一个评分（从 1 到 5）。在调查中，口味成为评价最高的因素，85% 的受访者在李克特量表中给它打 4 或 5 分。尽管对口味有明显的偏好，但我的评估人员认为这些信息还不够，他们希望我找到“统计上的显着差异”。
我对统计学的了解为零，不幸的是，我的导师都不愿意提供指导。鉴于我缺乏统计专业知识，您能否推荐一种使用李克特量表数据来检验这一假设的简单方法？我询问了 ChatGPT，它建议我使用方差分析或 Kruskal-Wallis 检验来比较因素的均值或中位数。我尝试进行 Kruskal-Wallis 测试，但结果值得怀疑。你认为这可行吗？我正在寻找一种易于理解的方法，因为我的评估人员对统计数据没有深入的了解。
感谢您提供的任何帮助或建议。预先感谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/638481/1-question-6-factors-each-with-a-likert-scale-from-1-to-5-how-can-i-analyze-t</guid>
      <pubDate>Sat, 03 Feb 2024 14:55:48 GMT</pubDate>
    </item>
    <item>
      <title>单变量还是多变量双变量分析？</title>
      <link>https://stats.stackexchange.com/questions/638479/single-or-multiple-bivariate-analysis</link>
      <description><![CDATA[对于数据结构，我们正在将多级模型拟合到数据。在拟合模型之前，我们渴望进行双变量分析，以便我们可以将那些自变量保留在与因变量相关的多级模型中。我的问题是，由于在多级模型中，有一个组变量，其中数据嵌套在每个组中，我是否需要为每个组创建不同的二元表？或者，我会创建一个双变量表，其中组是自变量吗？
也就是说，例如，我有 $x_1, x_2, x_3, x_4, x_5$ 和组变量作为自变量。在这里，组分为三类。如果在拟合多级模型之前，我想做双变量分析，我会分别对组变量的三个类别进行分析，还是只有一个统一的双变量分析，我也会检查组变量和因变量之间的关联？&lt; /p&gt;]]></description>
      <guid>https://stats.stackexchange.com/questions/638479/single-or-multiple-bivariate-analysis</guid>
      <pubDate>Sat, 03 Feb 2024 14:35:30 GMT</pubDate>
    </item>
    <item>
      <title>紧急帮助决定统计回归或其他</title>
      <link>https://stats.stackexchange.com/questions/638478/urgent-help-deciding-a-statistic-regression-or-something-else</link>
      <description><![CDATA[我需要检查口头测试中出现/不出现重复的情况是否是由于外部干扰的频率、自我干扰的频率或从原始单词到重复单词的说出的单词数而导致的。一般认知得分、受教育年限和性别也需要被视为可能的影响因素。
我首先做了二项式逻辑回归。 DV 是 1 和 0 编码，表示存在/不存在重复（跨三组），IV 是对自我和外部干扰、受教育年限、总体认知得分的单独计数。现在我的教授要我分析，在重复的那些（三组）中，我们能否检查哪些因素对重复影响最大：1.原始单词和重复之间的单词，2.内部干扰因素，3.外部干扰因素，和教育（非必要）。
可以让我知道接下来可能采取的步骤吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638478/urgent-help-deciding-a-statistic-regression-or-something-else</guid>
      <pubDate>Sat, 03 Feb 2024 14:28:15 GMT</pubDate>
    </item>
    <item>
      <title>如何使用交互效应参数计算逻辑回归的概率？</title>
      <link>https://stats.stackexchange.com/questions/638477/how-to-calculate-probability-from-logistic-regression-using-interaction-effect-p</link>
      <description><![CDATA[我有一个逻辑回归（logit 链接）模型，用于估计概率。在没有交互作用的情况下，许多参考文献中都给出了这个公式
$$p_i = \frac{1}{1 + e^{-\Sigma\beta_ix_i}}$$
但是，当模型参数包含交互效应时，我找不到关于概率估计的明确公式的参考。我目前从 R 中的分析中获得了这些系数，但需要在 C++ 应用程序中计算概率（并且无法这样做）。谁能提供具有多种交互效果的一般情况的公式（或对其/源代码的引用）？]]></description>
      <guid>https://stats.stackexchange.com/questions/638477/how-to-calculate-probability-from-logistic-regression-using-interaction-effect-p</guid>
      <pubDate>Sat, 03 Feb 2024 14:22:41 GMT</pubDate>
    </item>
    <item>
      <title>软约束定义参考</title>
      <link>https://stats.stackexchange.com/questions/638476/references-for-soft-constraints-definition</link>
      <description><![CDATA[我正在寻找一些参考资料，以清晰的方式定义或呈现“软约束”的概念。
上下文：
我正在写一篇文章。对于特定问题，我提出了一种包含一些软约束的解决方案，并将其称为“软HLPC”。在这里，我使用术语“软约束”。在某种意义上，这是违规行为导致“处罚”的一组条件。在目标值中（在我的例子中是可能性）。
现在，我需要解释一下所使用的术语。为此，我写道，我使用“软”这个词。参考“软约束”概念，但我缺乏一个很好的参考来定义这个概念。
我在网上找到了几个定义（如此处，&lt; a href=&quot;https://en.wikipedia.org/wiki/Constraint_(mathematics)#Hard_and_soft_constraints&quot; rel=&quot;nofollow noreferrer&quot;&gt;此处和此处）很好地解释了这个概念，但它是不适合用作论文参考。
任何人都可以提供一个很好的参考文献（文章或书籍）来定义/解释引用的软约束的概念吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638476/references-for-soft-constraints-definition</guid>
      <pubDate>Sat, 03 Feb 2024 14:18:03 GMT</pubDate>
    </item>
    <item>
      <title>什么是有界分布？有界分布能否满足正态性假设？</title>
      <link>https://stats.stackexchange.com/questions/638474/what-are-bounded-distributions-and-can-a-bounded-distribution-hold-the-normalit</link>
      <description><![CDATA[我听说正态分布应该是无界的，但我想澄清一下，现实世界中的大多数分布不是有界的吗？我的意思是它们不会趋向无穷大，它们有最小值和最大值。据我所知，有界分布有预定义的范围，如考试分数，但无界分布没有预定义的范围，如长度，尽管它的值不会达到无穷大，但它没有预定义的范围值。我的理解正确吗？
我还想知道如何分析有界数据，因为它们是有界的，它们不是正态的，所以我可以对它们使用 t 检验和线性回归吗？
这里是一个焦虑分数数据分布的例子，它的范围在[1:5]之间，虽然看起来很正常，但它有点轻尾，因为没有值高于5或低于1，我可以运行参数测试吗或者在这种情况下我应该做什么？

]]></description>
      <guid>https://stats.stackexchange.com/questions/638474/what-are-bounded-distributions-and-can-a-bounded-distribution-hold-the-normalit</guid>
      <pubDate>Sat, 03 Feb 2024 13:49:38 GMT</pubDate>
    </item>
    <item>
      <title>我可以计算 VAR 模型，然后仅处理一个 OLS 方程吗？</title>
      <link>https://stats.stackexchange.com/questions/638471/can-i-compute-a-var-model-and-then-work-on-only-one-ols-equation</link>
      <description><![CDATA[早上好，
我正在尝试估计六个变量之间的 VAR 模型，其中之一是铜的价格。
我感兴趣的只是铜价的方程，我运行 VAR 只是为了了解哪些变量“格兰杰原因”会影响铜价。铜价。
但是，无论我选择多少滞后，如果我测试自相关，它总是存在。
因此，我想：“如果我只对一个方程感兴趣，难道我不能使用铜价作为因变量来计算 OLS 回归并检查这个方程的正确性吗？”
如果这样做，我立即发现仅使用三个滞后就不会存在自相关，并且模型总体上是正确指定的，不存在多重共线性或异方差性。
所以，总之，计算 VAR 模型，而不是计算 VAR 模型，与计算 OLS 回归然后测试每个变量是不同的，如果联合不为零，则它是滞后的，所以基本上手动计算格兰杰因果关系检验？
这可以做到吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638471/can-i-compute-a-var-model-and-then-work-on-only-one-ols-equation</guid>
      <pubDate>Sat, 03 Feb 2024 13:04:13 GMT</pubDate>
    </item>
    <item>
      <title>潜在重复样本的标准偏差计算</title>
      <link>https://stats.stackexchange.com/questions/638464/standard-deviation-computation-for-potentially-duplicated-samples</link>
      <description><![CDATA[描述
我使用这个棋盘图像来评估其角之间的距离所获得的测量误差（2 点的所有独特组合之间的欧几里德距离，又称 630 个测量值）。测量误差计算为两点之间的已知距离与相同两点之间的估计距离之间的差异（从像素转换为毫米）。为了评估所获得的测量结果的质量，需要计算 630 个误差值集的平均值和标准差。

问题
考虑到沿同一方向（水平或垂直）的测量有时会在不同点之间执行多次（即 p[0,0]-&gt;p[2,0] 和 p[1,0]- &gt;p[2,0]，其中第一个索引是 36 点矩阵 p 中的行，第二个索引是列）是否会以计算测量的平均值或标准差的方式扭曲数据错误不正确？
对于误差的平均值和标准差，仅考虑一个点与所有其他点之间的测量值，而不是考虑 2 个点的所有唯一组合之间的测量值，是否更正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/638464/standard-deviation-computation-for-potentially-duplicated-samples</guid>
      <pubDate>Sat, 03 Feb 2024 11:22:15 GMT</pubDate>
    </item>
    <item>
      <title>如何处理实验设计中的治疗退出</title>
      <link>https://stats.stackexchange.com/questions/638461/how-to-deal-with-treatment-dropouts-in-experimental-designs</link>
      <description><![CDATA[我用一个三水平因素（高组、低组、对照组）进行了受试者间实验。由于治疗中的退出，最终分布为
对照组：85 名受试者
低组：58 名受试者
高组：70 名受试者
恢复无偏效应估计需要什么条件？
我可以采取哪些方法或解决方案？]]></description>
      <guid>https://stats.stackexchange.com/questions/638461/how-to-deal-with-treatment-dropouts-in-experimental-designs</guid>
      <pubDate>Sat, 03 Feb 2024 10:34:12 GMT</pubDate>
    </item>
    <item>
      <title>趋势栅格的区域统计[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638460/zonal-statistics-over-trend-raster</link>
      <description><![CDATA[我有一个包含每个像素的 Mann-Kendall 趋势值和 p 值的栅格。本质上，我掌握了趋势的大小和每个像素相应的显着性水平。我的目标是使用区域统计数据在特定区域内总结这些信息。
我考虑将所有非显着值 (p &lt; 0.05) 设置为 0，但这会改变平均值。所以我选择忽略 p 值，只总结趋势数据。
我应该计算平均值和标准差，同时忽略趋势的 p 值，还是应该如何将它们合并？
获得多边形（分为 3 类）的平均值和 SD 后，我想比较类别之间的趋势。我可以使用 Kruskal-Wallis（因为数据不正常）吗？如何解释空间自相关？]]></description>
      <guid>https://stats.stackexchange.com/questions/638460/zonal-statistics-over-trend-raster</guid>
      <pubDate>Sat, 03 Feb 2024 09:58:26 GMT</pubDate>
    </item>
    <item>
      <title>我不明白何时使用方差分析或 t 检验</title>
      <link>https://stats.stackexchange.com/questions/638458/i-do-not-understand-when-to-use-anova-or-t-test</link>
      <description><![CDATA[我做了一项实验，有一个自变量和 2 个因变量。基本上我测试了 diff。酶抑制剂的浓度，并通过测量 pH 和温度的变化来确定酶的活性。我知道抑制剂会降低酶的活性，并且只会降低酶的活性，因此它是 1 尾的。
我不明白 t 检验。我还听说有方差分析，我应该做哪一个？如何？我计算了 pH 值和温度的平均变化。对于 5 个酶浓度也是标准差。我不知道如何处理这些数据]]></description>
      <guid>https://stats.stackexchange.com/questions/638458/i-do-not-understand-when-to-use-anova-or-t-test</guid>
      <pubDate>Sat, 03 Feb 2024 09:43:31 GMT</pubDate>
    </item>
    <item>
      <title>在非线性最小二乘拟合中使用权重</title>
      <link>https://stats.stackexchange.com/questions/638454/use-of-weights-in-non-linear-least-square-fitting</link>
      <description><![CDATA[我希望得到您对我的问题的建议和帮助。
我在位置敏感探测器上生成了图像。每个像素的信号对应于与探测器相互作用的“粒子”的数量，因此我将信号分布视为计数统计数据。
我必须使用非线性函数来拟合这些图像的轮廓，为此我使用了在 scipy east_square 中实现的非线性最小二乘最小化（Levenberg-Marquardt 算法）。
到目前为止，我还没有对输入数据使用任何权重（对应于所有点的常数值为 1），并且拟合“视觉上”看起来非常好。另一方面，卡方非常高，我认为这是因为我没有根据输入数据的不确定性来缩放输入数据。
我的想法是使用计数统计来提供每个点的不确定性。
我正在考虑计算每个像素的 variance 标准差作为其计数数的平方根，然后将其用作拟合的权重。这样，信号最高的像素将具有较高的方差标准差和较高的权重。相反，“几乎”空的像素在拟合中的权重较低。
您认为最合理的做法是什么？
编辑：在 Sextus 的回答之后

我的拟合模型函数不一定精确，这意味着它是发生的物理现象的数学表示。因此，计算出的卡方没有理由遵循卡方分布。

到目前为止，获得的拟合相当好地遵循实验分布，并且获得的定性信息很好地描述了该现象。但由于我执行了数千次拟合，因此我一直在寻找一个拟合优度参数来快速识别失败和不良拟合。在@Sextus的评论之后，我猜想卡方不能用于此目的。在这种情况下，您有什么适合度参数可以建议吗？

目前我没有使用任何权重，相当于给所有点赋予相同的权重1。使用权重有什么好处？确定的参数的不确定性会变得更好吗？拟合优度参数会变得更好吗？为此，使用每个像素的标准差作为权重是否有意义？在这种情况下，我将假设每个像素都是独立的，并遵循泊松分布，标准差 = 均值的平方根。


再次感谢您的帮助，
托托]]></description>
      <guid>https://stats.stackexchange.com/questions/638454/use-of-weights-in-non-linear-least-square-fitting</guid>
      <pubDate>Sat, 03 Feb 2024 08:36:50 GMT</pubDate>
    </item>
    <item>
      <title>使用最小二乘法计算光速误差</title>
      <link>https://stats.stackexchange.com/questions/638453/calculating-the-error-on-the-speed-of-light-using-least-squares</link>
      <description><![CDATA[我正在尝试通过 ping 世界各地的服务器来计算光纤中的光速，并且我正在尝试找出应该使用哪种算法来计算我的两个参数。我知道这是某种类型的最小二乘法。我的最小二乘问题是距离 * 1/s + 跳数 * 时间/跳 = 时间，其中 s 是光纤中的光速。
矩阵形式
$$
[ D H ] [P T_h ]^\top = T
$$
其中 $P$ 和 $T_h$ 是我对光速和时间倒数的最佳估计每跳，$D$ 和 $H$ 都是距离和跳数的 N x 1 向量每个服务器，$T$ 是相应时间的 N x 1 向量。
我可以并且已经成功地使用 numpy 来计算线性平方最佳参数，但我不确定如何正确实现我在时间、跳数和距离上存在错误的事实。使用基本线性平方尝试不会对我的数据进行加权，但是当加权最小平方不考虑我的因变量的错误时。]]></description>
      <guid>https://stats.stackexchange.com/questions/638453/calculating-the-error-on-the-speed-of-light-using-least-squares</guid>
      <pubDate>Sat, 03 Feb 2024 07:53:27 GMT</pubDate>
    </item>
    <item>
      <title>A/B 测试：一种对照和多种变体的最佳分流比</title>
      <link>https://stats.stackexchange.com/questions/638431/a-b-test-optimal-split-ratio-for-one-control-and-multiple-variants</link>
      <description><![CDATA[我阅读了 kohavi 等人 2022 部分7 当您在 A/B 测试中进行多种处理时，均匀分配（例如，如果 1 个对照和 3 个处理，则为每个处理分配 25%）并不是执行测试（以最大化功效）的最佳方式。有人可以澄清这是真的还是我误读了？我担心的是，我误解了这种最佳分配的背景，它特别讨论的是在使用一种对照的情况下运行多个实验，而不是使用多个变体的一个实验（或者没有区别？）
此外，给予 Control 的最佳比例公式为 $\frac{1}{\sqrt{k}+1}$ 其中 $k$ 是治疗变体的数量，虽然推导很简单，但我感到困惑的部分是为什么假设 Control 应该更大？更具体地说，最佳控制大小是通过最小化 $\frac{k}{1-x}+\frac{1}{x}$ 来计算的，其中 $x$ 是控件的大小，$k$ 是处理次数，但此公式假设控件应一开始就更大，我不明白为什么会这样？]]></description>
      <guid>https://stats.stackexchange.com/questions/638431/a-b-test-optimal-split-ratio-for-one-control-and-multiple-variants</guid>
      <pubDate>Fri, 02 Feb 2024 20:54:30 GMT</pubDate>
    </item>
    <item>
      <title>不平衡类别的泛化</title>
      <link>https://stats.stackexchange.com/questions/638422/generalization-with-imbalanced-classes</link>
      <description><![CDATA[我有一个关于具有不平衡类别和泛化的学习（二元分类）的一般性问题。学习不平衡类别的一个方法是将负样本下采样到模型实际上可以学习某些内容的比率。但是，当模型部署在实际的、非常不平衡的数据上时会发生什么？为了解决这个问题，如果正例代表实际数据的 1%，我们可以使用所有正例和相同数量的下采样负例来训练二元分类器。但随后该模型是根据实际正负比为 1:100 的数据发布的。该模型还能找到积极的一面吗？难道它没有接受过与它所使用的问题相同的训练吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/638422/generalization-with-imbalanced-classes</guid>
      <pubDate>Fri, 02 Feb 2024 18:42:25 GMT</pubDate>
    </item>
    </channel>
</rss>