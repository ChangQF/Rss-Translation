<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 09 Jul 2024 09:16:06 GMT</lastBuildDate>
    <item>
      <title>多个总体均值相互作用的效应对比矩阵</title>
      <link>https://stats.stackexchange.com/questions/650720/effects-contrast-matrix-for-interaction-with-multiple-grand-means</link>
      <description><![CDATA[我想在我的 GAM（MGCV）中包含两个因素之间的相互作用：area 和 house_type，我希望进行总和为零的对比编码。
但是，我不希望将每个因素组合与所有级别的总体平均值进行比较。我想要 每个级别的总体平均值 area。因此，每个区域内的 house_types 都会与该 area 的总体平均值进行比较。
这是我尝试过的
取 house_type&#39; 的对比矩阵。有 7 种类型：它是一个 7*6 矩阵。 [house_type 对比矩阵](https://i.sstatic.net/2ZliQWM6.png)
对于 6 个级别的 area，我创建了一个由对角线上的 house_type 对比矩阵和非对角线上相同大小的零矩阵组成的矩阵。这是 42*36。
前两个子矩阵显示在此处：交互项对比矩阵的前两个子矩阵
查询

有没有更好的方法？
使用交互项运行简单线性回归，我得到 NA 系数 - 这是为什么？
此模型中是否有总体截距，还是每个 区域 级别都有一个截距来代表总体平均值？

谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/650720/effects-contrast-matrix-for-interaction-with-multiple-grand-means</guid>
      <pubDate>Tue, 09 Jul 2024 08:32:42 GMT</pubDate>
    </item>
    <item>
      <title>两种治疗方案的基因表达实验中的依赖性 FDR</title>
      <link>https://stats.stackexchange.com/questions/650719/dependent-fdrs-in-a-gene-expression-experiment-with-two-treatments</link>
      <description><![CDATA[给出以下实验。在三种条件下获得数千个基因的基因表达谱：两种具有相似表型效应的药物（= 治疗）和一个对照组。对每个基因和两个治疗对照组中的每一个进行测试。目的是比较药物：获得对两种药物和每种药物均有反应的基因列表。
直观地说，在一种治疗中具有相同 p 值但在另一种治疗中具有不同 p 值的两个基因应该具有不同的权重。这个想法是利用许多基因会同时对两种药物产生反应的事实。将同一基因的 p 值组合起来、控制 FDR 并将基因分为对两种药物均有反应和仅对一种药物有反应的基因的正确方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/650719/dependent-fdrs-in-a-gene-expression-experiment-with-two-treatments</guid>
      <pubDate>Tue, 09 Jul 2024 08:27:24 GMT</pubDate>
    </item>
    <item>
      <title>用于假设检验的 ML V REML</title>
      <link>https://stats.stackexchange.com/questions/650718/ml-v-reml-for-hypothesis-testing</link>
      <description><![CDATA[我很好奇如何通过似然比检验或任何对 REML 值有意义的检验对 REML 值进行假设检验，但这两个对现有交叉验证问题的高度赞同的答案似乎给出了相互矛盾的答案。
这个答案似乎建议使用 REML，而这个答案似乎表示 REML 基本上不应该使用。
这两个答案相互矛盾吗？如果不是，那么这两个问题的背景有什么不同，使它们分别正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/650718/ml-v-reml-for-hypothesis-testing</guid>
      <pubDate>Tue, 09 Jul 2024 08:07:54 GMT</pubDate>
    </item>
    <item>
      <title>仅了解 GLM 模型的梯度和 Hessian 矩阵时，计算 HC3 稳健 vcov 矩阵</title>
      <link>https://stats.stackexchange.com/questions/650717/calculate-hc3-robust-vcov-matrix-when-knowing-only-of-gradient-and-hessian-matri</link>
      <description><![CDATA[假设使用最大似然估计拟合广义线性模型，但我们只能从中获得两个结果：

梯度矩阵$G$是一个$n \times p$矩阵，其中每一行$g_i$表示对每个观测$i$的参数的对数似然的梯度。

Hessian矩阵$H$是一个$p \times p$矩阵，其中包含对数似然函数对参数的二阶导数。

帽子矩阵 $A$，维度为 $n \times n$。


然后，具有 HC0 稳健调整的方差-协方差矩阵 $V_{HC0}$ 可以通过以下方式找到：
$$V_{HC0} = H^{-1} (G^{T}G) H^{-1}$$
HC3 调整怎么样？如何在无法访问残差或 GLM 模型的拟合值的情况下计算 HC3 方差-协方差矩阵？]]></description>
      <guid>https://stats.stackexchange.com/questions/650717/calculate-hc3-robust-vcov-matrix-when-knowing-only-of-gradient-and-hessian-matri</guid>
      <pubDate>Tue, 09 Jul 2024 08:03:16 GMT</pubDate>
    </item>
    <item>
      <title>样本量对指标提升度的影响</title>
      <link>https://stats.stackexchange.com/questions/650716/impact-of-sample-size-on-metric-lift</link>
      <description><![CDATA[假设我们连续运行了三个随机用户拆分 AB 实验 exp_1、exp_2、exp_3。这三个实验的处理和控制完全相同。
Exp_1 在 2014 年 6 月 1 日至 2014 年 6 月 1 日期间运行了 2 周。 Exp_2 在 06/15-06/28 期间运行了 2 周，Exp_3 在 06/29-07/12 期间运行了 2 周。
Exp_1 有 2% 的用户参与了实验，Exp_2 有 50% 的用户参与了实验，Exp_3 有 100% 的用户参与了实验。
Exp_1 的主要指标提升的 95% CI 为 2.3% - 13.0%
Exp_2 的主要指标提升的 95% CI 为 6.2% - 8.4%
Exp_3 的主要指标提升的 95% CI 为 5.9% - 7.4%
从这些结果中，我们可以得出结论，所有三个实验都具有相同的指标提升吗？
如果是/否，为什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/650716/impact-of-sample-size-on-metric-lift</guid>
      <pubDate>Tue, 09 Jul 2024 07:16:34 GMT</pubDate>
    </item>
    <item>
      <title>概率流 ODE 轨迹（在扩散模型的背景下）是否代表任何分布到高斯分布之间的双射映射？</title>
      <link>https://stats.stackexchange.com/questions/650715/does-probability-flow-ode-trajectory-in-the-context-of-diffusion-models-repres</link>
      <description><![CDATA[我读过几篇关于深度学习背景下的扩散模型的论文。 尤其是这个
正如论文中所解释的，通过学习得分函数 (∇log(𝑝𝑡(𝑥)))
，概率流路径可以唯一地将数据分布（X(0)，假设是图像）中的任何数据点映射到相同维度的多元高斯分布（Prior 或 X(T)）中的某个点，如论文中的图 2 所示（也附在此处）。

我在这方面有几个问题：

我们知道，我们可以从高斯分布中随机抽取一个样本，而反向 SDE 会从数据分布中生成样本，在本例中是一幅真实的图像。这对于反向 ODE 也适用吗？

我们可以说 ODE 轨迹是从数据分布到高斯分布的双射映射吗？

我们可以说在这样的高斯分布中，每个元素（维度）都独立于其他元素吗？这个问题的动机是，我想找到一个映射或我的数据的新表示，其中每个元素都独立于其他元素（某种解开的表示，但可解释性并不重要）。这种映射可以取代 ICA 算法吗？

]]></description>
      <guid>https://stats.stackexchange.com/questions/650715/does-probability-flow-ode-trajectory-in-the-context-of-diffusion-models-repres</guid>
      <pubDate>Tue, 09 Jul 2024 07:12:59 GMT</pubDate>
    </item>
    <item>
      <title>关于基于群体的轨迹模型 (GBTM) 的分类结果问题</title>
      <link>https://stats.stackexchange.com/questions/650714/questions-on-group-based-trajectory-modeling-gbtm-for-categorical-outcomes</link>
      <description><![CDATA[我正在从事一个涉及基于组的轨迹建模 (GBTM) 的项目，有几个问题希望您能帮助我。我的数据集跟踪了几年 (2012-2016) 的治疗依从性 (二元变量：是/否)。以下是我的疑问：

GBTM 可以应用于分类结果 (治疗依从性：是/否) 吗？
应该考虑哪些变量来识别轨迹？我应该只使用时间变量 (年份) 和结果 (治疗依从性)，还是需要调整其他协变量？
如果几个组的正确分类几率 (OCC) 小于 5 且平均后验概率低于 0.7，我该怎么办？
为什么我得到的 BIC 值会随着学位的增加而随机增加？通常，BIC 会随着度数的增加而降低，但就我而言，对于 1 组，它可能是 -7800，对于 2 组，它可能是 -7600，对于 3 组，它可能是 -7700。

我是门外汉，对统计学或统计知识不多。请以我易于理解的方式回答问题。提前感谢您的帮助。非常感谢您的见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/650714/questions-on-group-based-trajectory-modeling-gbtm-for-categorical-outcomes</guid>
      <pubDate>Tue, 09 Jul 2024 06:53:32 GMT</pubDate>
    </item>
    <item>
      <title>通过 TP、TN、FP 和 FN 值判断模型</title>
      <link>https://stats.stackexchange.com/questions/650709/judging-a-model-through-the-tp-tn-fp-and-fn-values</link>
      <description><![CDATA[我正在使用多个数据集评估一个模型，该模型可以预测某个“特征”是否存在（例如，“这张图片中有一只狗”）。系统会针对每个数据集输出 TP、TN、FP 和 FN。
我想要一个指标来判断模型的工作效果，但我意识到我无法仅绘制 TP，因为例如第一个数据集有 20 个具有特征（有一只狗）的实例，而第二个数据集只有 10 个。即使模型是完美的，第二个数据集也只有 10 个 TP。
我正在考虑计算每个数据集和所有数据集的准确率、精确率和召回率。
我也对每个数据集运行了三次模型，变化很小
我也在研究精确率-召回率曲线，但似乎这些是针对不同的阈值的，显然每个数据集只有一组精确率、召回率
有什么好方法可以判断模型是否“好”？由于我的经验不足，我无法提出一个好的判断标准
起初我想绘制所有数据集中每个（TP 等）的分布
然后我想绘制一个结合所有数据集的混淆矩阵
任何建议都将不胜感激

作为一个简单的虚构示例，我想到
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confused_matrix, precision_score, recall_score, f1_score, accuracy_score

# 示例虚构数据
datasets = {
&#39;datasetA&#39;: {&#39;TP&#39;: 150, &#39;TN&#39;: 200, &#39;FP&#39;: 50, &#39;FN&#39;: 100, &#39;no_GT&#39;: 34},
&#39;数据集B&#39;：{&#39;TP&#39;：180，&#39;TN&#39;：220，&#39;FP&#39;：40，&#39;FN&#39;：81，&#39;no_GT&#39;：20}，
&#39;数据集C&#39;：{&#39;TP&#39;：160，&#39;TN&#39;：240，&#39;FP&#39;：70，&#39;FN&#39;：110，&#39;no_GT&#39;：30}，
&#39;数据集D&#39;：{&#39;TP&#39;：190，&#39;TN&#39;：250，&#39;FP&#39;：60，&#39;FN&#39;：90，&#39;no_GT&#39;：42}，
}

def calculate_metrics（TP，TN，FP，FN）：
准确度 = (TP + TN) / (TP + TN + FP + FN)
精度 = TP / (TP + FP) if (TP + FP) &gt; 0 否则 0
召回率 = TP / (TP + FN) 如果 (TP + FN) &gt; 0 否则 0
f1 = 2 * (精确度 * 召回率) / (精确度 + 召回率) 如果 (精确度 + 召回率) &gt; 0 else 0

return {
&#39;Accuracy&#39;: 准确度，
&#39;Precision&#39;: 精度，
&#39;Recall&#39;: 召回率，
&#39;F1 分数&#39;: f1
}

# 聚合计数
total_TP = sum(data[&#39;TP&#39;] for data in datasets.values())
total_TN = sum(data[&#39;TN&#39;] for data in datasets.values())
total_FP = sum(data[&#39;FP&#39;] for data in datasets.values())
total_FN = sum(data[&#39;FN&#39;] for data in datasets.values())

# 计算总体指标
overall_metrics = calculate_metrics(total_TP, total_TN, total_FP, total_FN)

# 计算每个数据集的指标
metrics_df = pd.DataFrame({dataset: calculate_metrics(data[&#39;TP&#39;], data[&#39;TN&#39;], data[&#39;FP&#39;], data[&#39;FN&#39;]) for dataset, data in datasets.items()})

# 添加总体指标
metrics_df[&#39;Overall&#39;] = Overall_metrics

print(metrics_df)

# 可视化
fig, axis = plt.subplots(2, 2, figsize=(14, 10))
axes = axis.flatten()

for i, (dataset, data) in enumerate(datasets.items()):
cm = confused_matrix([1] * data[&#39;TP&#39;] + [0] * data[&#39;TN&#39;] + [1] * data[&#39;FN&#39;] + [0] * data[&#39;FP&#39;],
[1] * (data[&#39;TP&#39;] + data[&#39;FP&#39;]) + [0] * (data[&#39;TN&#39;] + data[&#39;FN&#39;]))
sns.heatmap(cm, annot=True, fmt=&#39;d&#39;, cmap=&#39;Blues&#39;, ax=axes[i])
axes[i].set_title(f&#39;混淆矩阵 - {dataset}&#39;)
axes[i].set_xlabel(&#39;预测&#39;)
axes[i].set_ylabel(&#39;True&#39;)

plt.tight_layout()
plt.show()

我得到了
 数据集A 数据集B 数据集C 数据集D 总体
准确率 0.700000 0.767754 0.689655 0.745763 0.725696
精确率 0.750000 0.818182 0.695652 0.760000 0.755556
召回率 0.600000 0.689655 0.592593 0.678571 0.640905
F1 分数 0.666667 0.748441 0.640000 0.716981 0.693524

和
]]></description>
      <guid>https://stats.stackexchange.com/questions/650709/judging-a-model-through-the-tp-tn-fp-and-fn-values</guid>
      <pubDate>Tue, 09 Jul 2024 05:43:39 GMT</pubDate>
    </item>
    <item>
      <title>我对产权欺诈统计数据的解读是否正确？</title>
      <link>https://stats.stackexchange.com/questions/650708/am-i-interpreting-title-fraud-statistics-correctly</link>
      <description><![CDATA[每年有 10,000 起产权欺诈案件。99% 的诉讼都是庭外和解。
这是否意味着每年有 100 万人的房屋被盗或 10,000 人？我倾向于更高的数字，因为任何拥有房屋的人的产权都会被盗，这很合理，这就是为什么人们有抵押贷款让银行拥有房产的原因。]]></description>
      <guid>https://stats.stackexchange.com/questions/650708/am-i-interpreting-title-fraud-statistics-correctly</guid>
      <pubDate>Tue, 09 Jul 2024 03:10:51 GMT</pubDate>
    </item>
    <item>
      <title>R 错误：'响应是恒定的'-GAMM [关闭]</title>
      <link>https://stats.stackexchange.com/questions/650704/r-error-response-is-constant-gamm</link>
      <description><![CDATA[我正在尝试为企鹅创建一个物种分布模型，以评估不同环境变量对其分布的影响。
最初我计划使用 GLM，但在进一步阅读后，我决定使用 GAMM，因为它可以结合随机效应（例如，企鹅个体之间的差异）和分组结构（例如，岛屿之间的差异）。
我的响应变量是存在（1 = 存在，0 = 不存在）二项式。
但是，当我尝试拟合我的 GAMM 时，我得到：&quot;错误：响应为常数&quot;
我已检查我的数据中是否存在缺失数据/​​NA 值，并已将其删除。我还在表格 0 = 1000、1 = 328 中检查了我的响应变量的分布，（0/缺失值被提取为背景点，因为我的原始数据仅包含存在点）。
拟合我的模型：
gamm_model &lt;- gamm4(presence ~ s(bathy) + s(slope) + s(mean_chla), etc etc,
+ random = ~(1|Bird.ID), + family = binomial(link = &quot;logit&quot;), + data = data)

运行正常的 glm 可以正常工作，因此我认为我的数据中没有任何重大错误。
如能就此错误提供任何帮助，我们将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/650704/r-error-response-is-constant-gamm</guid>
      <pubDate>Tue, 09 Jul 2024 02:10:17 GMT</pubDate>
    </item>
    <item>
      <title>跟随领袖，后悔不已</title>
      <link>https://stats.stackexchange.com/questions/650703/follow-the-leader-tight-bound-in-regret</link>
      <description><![CDATA[在 Follow The Leader (FTL) 的情况下，如果 $p_t$ 是我的预测变量，$x_t$ 是时间 t 时的目标点，并且 $x_t$ 属于单位球，即让 $S = \{x \in R^n \mid ||x||_2 \le 1\}$ 和 $x_t \in B$，则如何证明在线二次优化的紧密界限？]]></description>
      <guid>https://stats.stackexchange.com/questions/650703/follow-the-leader-tight-bound-in-regret</guid>
      <pubDate>Tue, 09 Jul 2024 00:47:22 GMT</pubDate>
    </item>
    <item>
      <title>贝塞尔修正的有效证明</title>
      <link>https://stats.stackexchange.com/questions/650702/efficient-proof-of-bessels-correction</link>
      <description><![CDATA[我刚刚开始学习统计学的基础知识，正在维基百科页面上阅读关于贝塞尔方差估计校正为何有效的证明。我理解了一切，除了以下计算的戏剧性简化（在此处重现）：

... 这里我们有（通过独立、对称抵消和平等分配）
$$... \mathbb{E} \Big[ \displaystyle\sum_{j=1}^n\sum_{l=1}^n (x_k - x_j)(x_k - x_l) \Big] = n(n-1)\mathbb{E}[X_1^2] - n(n-1)\mathbb{E}[X_1]^2$$

我不明白计算如何如此容易地进行。页面作者所说的“通过独立、对称抵消和平等分配”究竟是什么意思？]]></description>
      <guid>https://stats.stackexchange.com/questions/650702/efficient-proof-of-bessels-correction</guid>
      <pubDate>Tue, 09 Jul 2024 00:41:52 GMT</pubDate>
    </item>
    <item>
      <title>整合多名参与者的数据进行统计分析</title>
      <link>https://stats.stackexchange.com/questions/650700/combining-data-from-multiple-participants-for-statistical-analysis</link>
      <description><![CDATA[我的问题是：是否有任何统计技术允许将多个参与者的数据组合起来形成“宏观参与者”，以计算命中率或准确率等统计数据？这个想法是随机分组来自 3 或 4 名参与者的数据来计算这些统计数据，然后对它们进行假设检验。
查询背景：我正在开展一个涉及面部表情记忆任务的项目，该任务由两个阶段组成：

编码阶段：在此阶段，参与者会接触到 8 个虚拟角色，每个角色在 8 次试验中显示四种不同的面部表情（痛苦、愤怒、悲伤、中性）之一。
回忆阶段：此阶段包括 24 次试验，分为 8 次“旧”试验（参与者回忆以前见过的角色表情组合）和 16 次“新”试验。参与者的任务是确定他们之前是否见过特定的字符-表情组合。

统计挑战：
主要的挑战来自于每个参与者每个表情的试验次数有限，这限制了信号检测理论等传统统计方法的使用。
例如，“疼痛”表情的命中率计算仅依赖于两次试验。这是因为，在回忆阶段，在所有“旧”试验中，只有两个实例具有“疼痛”的表情并且与计算其命中率相关（8 个字符/4 个表情 = 每次出现 2 次）。结果命中率被限制为 0%、50% 或 100%。由于数据的非正态分布，如此受限的数值范围不适合进行典型的统计分析，如方差分析（比较所有四种面部表情的记忆）。
将数据组合起来形成宏观参与者是否可行？任何建议或见解都将不胜感激！
命中率 = 参与者正确识别为“旧”的“旧”或以前见过的项目的比例 = 命中次数 /“旧”项目的总数]]></description>
      <guid>https://stats.stackexchange.com/questions/650700/combining-data-from-multiple-participants-for-statistical-analysis</guid>
      <pubDate>Tue, 09 Jul 2024 00:32:17 GMT</pubDate>
    </item>
    <item>
      <title>贝塔随机变量的乘积与和的分布</title>
      <link>https://stats.stackexchange.com/questions/650663/distribution-of-product-and-sum-of-beta-random-variables</link>
      <description><![CDATA[我有一组概率，我将其建模为（独立的）$p_{A,i} \sim Beta(\alpha_{A,i},\beta_{A,i})$ 和 $p_{B,i} \sim Beta(\alpha_{B,i},\beta_{B,i})$。我正在计算以下乘积：
$$Y = \sum_{i=1}^N p_{A,i}^{n_{A}}(1-p_{B,i})^{n_{B}} + p_{B,i}^{n_{B}}(1-p_{A,i})^{n_{A}},$$
其中 $n_{A}$ 和 $n_{B}$ 为整数。我想推断（近似）$Y$ 的累积分布。由于 $Y$ 因支持值 $\gt 1$ 而出现偏差，我考虑将 Beta-Prime（或对数正态）密度分布拟合到 $Y$。这样对吗？您能否就 $Y$ 的真实分布或更好的近似值提供一些见解？
PD。如果之前有人问过类似的问题，请见谅。]]></description>
      <guid>https://stats.stackexchange.com/questions/650663/distribution-of-product-and-sum-of-beta-random-variables</guid>
      <pubDate>Mon, 08 Jul 2024 08:59:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 R STM 包分析评论评级-样本平衡问题</title>
      <link>https://stats.stackexchange.com/questions/650661/analyzing-review-rating-using-r-stm-package-sample-balance-issue</link>
      <description><![CDATA[在考察主题占比差异时，由于在线评论评分呈正偏J型分布/评分分布不平衡，学者们倾向于平衡样本量，即随机选取正评分评论（即4分和5分评分），使其数量与负评分评论（即1分和2分评分）数量相等或相近。类似以下论文的做法：
论文1：酒店顾客抱怨什么？使用结构化主题模型进行文本分析
论文 2：毒品消费者的声音：使用结构化主题模型进行在线文本评论分析
除了研究主题比例（正面 vs. 负面）的差异（例如论文 1，图 2）之外，我还想使用线性回归研究主题和评分之间的关​​系。
一方面，如果我对主题比例的差异进行分析，似乎我必须删除一些评论才能实现样本平衡；另一方面，如果我只运行线性回归，则没有必要这样做。
在这种情况下，有什么解决方案可以不删除样本，同时解决样本不平衡的问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/650661/analyzing-review-rating-using-r-stm-package-sample-balance-issue</guid>
      <pubDate>Mon, 08 Jul 2024 08:17:13 GMT</pubDate>
    </item>
    </channel>
</rss>