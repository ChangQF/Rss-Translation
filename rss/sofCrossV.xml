<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sat, 13 Jan 2024 21:11:57 GMT</lastBuildDate>
    <item>
      <title>Stata命令-帮助创建二分变量[关闭]</title>
      <link>https://stats.stackexchange.com/questions/636791/stata-command-help-creating-dichotomous-variable</link>
      <description><![CDATA[我正在使用有关逮捕/指控的 NLSY-97 数据来创建暴力犯罪、财产犯罪、毒品犯罪和公共秩序犯罪的二分变量。例如，我使用某人是否因袭击而被捕 (1) 或未被捕 (0)，以及因抢劫而被捕 (1) 或 0，作为某人在 2011 年因暴力犯罪被捕的指标。这是我运行的命令：
2011年暴力犯罪=。
标签变量 violcrime2011 “2011 年曾因暴力犯罪被捕吗？”
如果arrassault==1 则替换violcrime2011 = 1 |抢劫==1
如果arrassault==0 则替换violcrime2011 = 0 |抢劫==0
标签定义 violcrime2011 0“否” 1“是”
标签值 violcrime2011 violcrime2011
自由暴力犯罪2011
我现在的问题是，在运行描述性统计（总和）之后，我对 2011 年因暴力犯罪被捕的人的平均值是 0。这是错误的，因为如果我在 2011 年犯下非袭击罪，则为 27，而非抢劫罪为 4。所以，看起来就像代码行：“replace violcrime2011 = 0 if arrassault==0 |抢劫==0”几乎覆盖了命令的其余部分。我不知道要运行什么其他命令才能生成正确的结果，显示 34 人因暴力犯罪而被捕，而不是 0。]]></description>
      <guid>https://stats.stackexchange.com/questions/636791/stata-command-help-creating-dichotomous-variable</guid>
      <pubDate>Sat, 13 Jan 2024 21:08:54 GMT</pubDate>
    </item>
    <item>
      <title>具有多重插补的时间序列 df 中的横截面变量</title>
      <link>https://stats.stackexchange.com/questions/636790/cross-sectional-variables-in-a-time-series-df-with-multiple-imputation</link>
      <description><![CDATA[我有一个包含时间序列和横截面变量的数据集，样本大小小于 100。我有三个变量 (var1、var2、var3）不随时间变化，时间序列变量（var4）随时间变化。
我计划检查 var1 和 var2、var2 和 var4 以及 var3 之间的关联 和 var4。在分析之前，我想进行多重插补（小鼠）。我的 &lt;100 个样本量和一般研究问题阻止我使用 SEM 或路径分析，因此我不认为 FIML 作为缺失数据处理方法适合我。
如果我不进行小鼠实验，我会使用宽格式数据集检查 var1 和 var2，并检查涉及 var4 的其他关联&gt; 具有长格式数据集。然而，我认为拥有多个多重插补数据集是不明智的。由于小鼠固有的差异，var2 在数据集之间将具有不同的估算值。虽然我还没有在文献中读到过这个具体问题，但这似乎是一个坏主意。此外，由于变量的横截面性质，我希望避免在长格式数据集上使用 var1 和 var2 进行分析。
是否可以同时纠正这两个问题，还是我需要在其中一个问题上做出让步？如果我有什么理解错误的地方，请指正。
set.seed(1234)
图书馆（tidyverse）
库（missMethods）
图书馆（小鼠）

id &lt;- 代表 (1:10)
var1 &lt;- 样本(1:10, 10, 替换 = TRUE)
var2 &lt;- 样本(1:20, 10, 替换 = TRUE)
var3 &lt;- 样本(10:30, 10, 替换 = TRUE)
宽 &lt;- data.frame(id, var1, var2, var3) %&gt;%
  delete_MCAR(p = .2, cols_mis = c(“var1”, “var2”, “var3”))

id &lt;-rep(1:10, 每个 = 10)
时间 &lt;- 次数(1:10, 次数 = 10)
var4 &lt;- rnorm(10)
long &lt;- data.frame(id, time, var4) %&gt;%
  delete_MCAR(p = .2, cols_mis = “var4”)

df &lt;- 合并（宽，长，by =“id”）

impulated_wide &lt;- 小鼠::小鼠（数据 = 宽，m = 5，种子 = 1234，printFlag = FALSE）
impated_long &lt;- 小鼠::小鼠（数据 = df，m = 5，种子 = 1234，printFlag = FALSE）

# 相同的分析，不同数据的不同结果
摘要(池(with(data = impulated_wide, exp = lm(var1 ~ var2))))
#&gt;项估计 std.error 统计量 df p.value
#&gt; 1（截距） 6.19456035 1.9042540 3.25301157 3.969347 0.03163845
#&gt; 2 var2 -0.01256283 0.1725381 -0.07281189 3.987911 0.94546139
摘要(池(with(data = impulated_long, exp = lm(var1 ~ var2))))
#&gt;项估计 std.error 统计量 df p.value
#&gt; 1（截距） 6.1510957 0.47795118 12.869716 93.92766 1.895427e-22
#&gt; 2 var2 -0.0441173 0.04124086 -1.069747 95.42650 2.874315e-01

# 比较数据集之间 var2 的平均值和 SD
＃＃ 宽的
impdat &lt;- 完整（impulated_wide，action =“long”，include = FALSE）
pool_mean &lt;- with(impdat, by(impdat, .imp, function(x) c(mean(x$var2), sd(x$var2))) ）
减少（“+”，pool_mean）/长度（pool_mean）
#&gt; [1] 9.380000 6.124072

＃＃ 长的
impdat &lt;- 完整（impulated_long，action =“long”，include = FALSE）
pool_mean &lt;- with(impdat, by(impdat, .imp, function(x) c(mean(x$var2), sd(x$var2))) ）
减少（“+”，pool_mean）/长度（pool_mean）
#&gt; [1] 9.816000 6.076727
]]></description>
      <guid>https://stats.stackexchange.com/questions/636790/cross-sectional-variables-in-a-time-series-df-with-multiple-imputation</guid>
      <pubDate>Sat, 13 Jan 2024 20:11:54 GMT</pubDate>
    </item>
    <item>
      <title>为什么预测间隔（通常）基于平均观测值？</title>
      <link>https://stats.stackexchange.com/questions/636789/why-are-prediction-intervals-usually-based-on-the-average-observation</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636789/why-are-prediction-intervals-usually-based-on-the-average-observation</guid>
      <pubDate>Sat, 13 Jan 2024 19:38:16 GMT</pubDate>
    </item>
    <item>
      <title>我的 NN 和 Keras 之间的反向传播梯度差异</title>
      <link>https://stats.stackexchange.com/questions/636788/backpropagation-gradients-diffrence-between-my-nn-and-keras</link>
      <description><![CDATA[我从头开始编写了一个神经网络，它可以工作，但我有一个问题。我的神经网络使用完整批次，因此使用整个矩阵计算梯度。因为我很感兴趣，所以我检查了 tensorflow.keras 是如何做到这一点的，它们计算输入的每一行的梯度，而不是直接计算整个矩阵。我的方法是错误的还是有什么不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/636788/backpropagation-gradients-diffrence-between-my-nn-and-keras</guid>
      <pubDate>Sat, 13 Jan 2024 18:58:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么超参数调整会降低训练集性能</title>
      <link>https://stats.stackexchange.com/questions/636787/why-is-hyper-parameter-tuning-decreasing-training-set-performance</link>
      <description><![CDATA[设置：我使用 hyperopt 进行 xgboost 超参数调整。在每次试验中，都会通过时间序列交叉验证（CV）来评估相应的配置。 CV 验证性能是调整过程的唯一目标（常见做法）。
事实：调整过程可以有效提高 CV 验证性能。然而，这会导致训练集的性能大幅下降。
使用默认参数：
训练表现：72.5%
验证性能：60%
hyperopt 调整后：
训练表现：57%
验证性能：62.7%
因此，调整过程将验证性能提高了 2.7%，但导致训练性能显着下降 15.5%。
想法：我可以想到两种解释：
“良好场景”：由于过度拟合噪声，原始训练性能较高 (72.5%)，而新结果 (57%) 更加真实并学习实际模式。因此，消除噪声过度拟合使验证集的性能提高了 2.7%。因此，无需采取进一步行动。
“糟糕的场景”：相反，模型从训练数据中学习有用的模式 (72.5%)，但在调整过程之后，它被迫欠拟合训练集 (57%)，以便过拟合验证集（从 60% 到 62.7%）。还要考虑训练集比验证集大几倍。如此看来，经过处理的“牺牲”是不存在的。为了获得正确的验证数据，在大量示例上进行性能测试。
可能的操作：我可以使用类似 (0.7* CV_validation + 0.3*CV_training) 的内容，而不是仅使用 CV 验证性能作为优化目标。这将迫使进程学习优化 CV_performance，而不牺牲如此大量的训练示例的性能。
问题：

您认为哪种情况更接近事实？
为什么完全关注 CV 验证性能目标（这可能会导致超参数过度拟合）而不是 CV 验证和 CV 训练性能的组合（正如我之前建议的那样）如此常见？
]]></description>
      <guid>https://stats.stackexchange.com/questions/636787/why-is-hyper-parameter-tuning-decreasing-training-set-performance</guid>
      <pubDate>Sat, 13 Jan 2024 18:40:01 GMT</pubDate>
    </item>
    <item>
      <title>仅将参数传递给 R 中 Collapse 包中的特定函数 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636786/pass-arguments-to-only-specific-functions-in-collapse-package-in-r</link>
      <description><![CDATA[我想知道如何将特定参数仅传递给折叠包中的 collap 函数中的特定函数。例如，我编写了一个自定义函数，该函数查找特定值并使用 collap 函数返回聚合因子。在下面的代码中，我想将 look 参数仅传递给 alo 函数，但它也会传递给 fsum 。但是，这段代码仍然可以工作（请参阅警告），但如果其他函数具有相同的参数，则会导致问题。如有任何帮助，我们将不胜感激。
库（折叠）
#&gt;崩溃 2.0.7，请参阅“collapse-package”或“collapse-documentation”
#&gt;
#&gt;附加包：“折叠”
#&gt;以下对象被“package:stats”屏蔽：
#&gt;
#&gt; D

alo &lt;- 函数（var，look）{
        x &lt;- 任意（var %in% 外观）
        y &lt;- data.table::fifelse(x, yes = “是”, no = “否”)
        z &lt;- 基数::因子(y, 水平 = c(“否”, “是”))
        返回（z）
}


df &lt;- data.frame(id = c(“A”, “A”, “B”, “B”, “B”),
                 x1 = c(8, 2, 7, 9, 8),
                 x2 = c(“否”,“否”,“是”,“否”,“否”))

df
#&gt;内径 x1 x2
#&gt; 1 A 8 否
#&gt; 2 A 2 否
#&gt; 3 B 7 是
#&gt; 4 B 9 否
#&gt; 5 B 8 否


df|&gt; collap(~id, FUN = fsum, catFUN = alo, Look = “是”)
#&gt; used_arg_action(match.call(), ...) 中的警告：未使用的参数（look =“Yes”）
#&gt;传递给 fsum.data.frame
#&gt;内径 x1 x2
#&gt; 1 A 10 否
#&gt; 2 B 24 是

创建于 2024 年 1 月 13 日，使用 reprex v2.1.0]]></description>
      <guid>https://stats.stackexchange.com/questions/636786/pass-arguments-to-only-specific-functions-in-collapse-package-in-r</guid>
      <pubDate>Sat, 13 Jan 2024 18:38:19 GMT</pubDate>
    </item>
    <item>
      <title>稳健的双重差分法：倾向得分有什么作用？</title>
      <link>https://stats.stackexchange.com/questions/636785/robust-difference-in-differences-what-is-the-propensity-score-doing</link>
      <description><![CDATA[Callaway 和 Sant&#39;Anna (2022) 描述一种双重稳健的双重差分 (DiD) 方法，由于多种原因，该方法在交错 DiD（多组治疗时间）中很有吸引力。它可以防止“不良比较”。在尚未治疗和已治疗之间，经典的 TWFE DiD 方法是不可知的。它允许恢复各种 ATT 聚合。
它还使用倾向得分 (PS)，但我无法理解它们的使用方式和原因。有人可以解释为什么这样做吗？ PS如何用于报告的治疗前平行趋势和治疗后系数？
帮助直觉的极端例子：假设我们只有一个治疗组，并且从未治疗和尚未治疗的组在治疗前结果趋势和协变量 (X) 的治疗前趋势上非常相似，但为正值ATT 和帖子中不同的 X。难道我们不会得到毫无意义的治疗倾向倾向评分吗？这些信息将如何在模型中使用？
来自第203页：
&lt;块引用&gt;
接下来，将广义倾向得分表示为 $p_{g,s}(X)= P(G_g =
 1|X，G_g + (1 − D_s)(1 − G_g) = 1)$。请注意， $p_{g,s}(X)$ 表示
在时间 g 首次接受治疗的概率，条件为
治疗前协变量 X 和任一组 g 的成员（在
在本例中，$G_g = 1$）或按时间划分的“尚未治疗”组的成员
s（在本例中，$(1−D_s)(1−G_g ) = 1)$。

$D_s$ 是时间 s 的治疗状态。]]></description>
      <guid>https://stats.stackexchange.com/questions/636785/robust-difference-in-differences-what-is-the-propensity-score-doing</guid>
      <pubDate>Sat, 13 Jan 2024 18:24:54 GMT</pubDate>
    </item>
    <item>
      <title>LOOCV：要报告哪些性能指标聚合？</title>
      <link>https://stats.stackexchange.com/questions/636784/loocv-which-aggregation-of-the-performance-metric-to-report</link>
      <description><![CDATA[目标变量是收入，有 81 个观测值和 10 个特征。
目标分布是这样的：标准对数变换不会产生近似正态分布，但收入**(1/4) 会产生近似正态分布。预期模型根据转换后的目标进行训练，但根据反向转换的预测值进行评估。
我选择 RMSLE 作为我的性能指标，因为它是一种相对度量，对低估的惩罚高于对高估的惩罚。
LOOCV 用于超参数调整、模型选择和最终模型验证。
但是要开始做出决策，我需要选择一种聚合方法。下面显示的是 RMSLE 分数分布的示例：

这种分布是预期的，因为从模型获得的残差近似正态，并且在进行 RMSLE 计算之前对预测值和实际值进行反向转换会将分布恢复为与原始收入分布类似的分布。
我的理解是，平均值通常是针对 LOOCV 报告的。但是，考虑到这种分布，使用/报告中位数或几何平均值更合适吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636784/loocv-which-aggregation-of-the-performance-metric-to-report</guid>
      <pubDate>Sat, 13 Jan 2024 18:14:26 GMT</pubDate>
    </item>
    <item>
      <title>该图的 F1 分数是多少？</title>
      <link>https://stats.stackexchange.com/questions/636783/what-is-f1-score-for-this-diagram</link>
      <description><![CDATA[我有这个维恩图，它表示识别我们的产品是否被分类为“A41”的数据集预测标准与否
蓝色圆圈代表机器学习模型的预测结果
黄圈代表实际的A41标准分类
绿色圆圈代表我们尝试过的另一种方法，称为“映射”。
您可以看到，通过任何一种方法或实际上未分类为 A41 的产品数量为 2011，并且不在所有维恩形状之内
现在我想知道我们模型的 F1 分数是多少。
怎么样？
]]></description>
      <guid>https://stats.stackexchange.com/questions/636783/what-is-f1-score-for-this-diagram</guid>
      <pubDate>Sat, 13 Jan 2024 17:58:48 GMT</pubDate>
    </item>
    <item>
      <title>我对 GLM 的理解正确吗？</title>
      <link>https://stats.stackexchange.com/questions/636782/is-my-understanding-of-glms-correct</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/636782/is-my-understanding-of-glms-correct</guid>
      <pubDate>Sat, 13 Jan 2024 17:47:16 GMT</pubDate>
    </item>
    <item>
      <title>样本大小是否会影响变量是分类变量还是连续变量？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/636781/does-sample-size-affect-whether-to-have-a-variable-as-categorical-or-continuous</link>
      <description><![CDATA[我有一个包含大约 5000 个观察值的数据集。我有一个自变量“通过”，它是通过的测试数量。该变量的范围从 0 到 6，但在类别 6 中只有 9 个观测值。我不确定是否应该将其视为因子或数值变量。
连续的原因：

绘制除最后一点之外的“通过”置信区间为 95% 的估计平均对数几率，可得到线性图。最后一点有一个巨大的 CI（通过 delta 方法估计，可能不适用，因为只有 9 个观测值）并且比预期高一点。
如果我将其视为连续的，我的模型最终会具有较低的 AIC。

分类的原因

我可以将已通过的 5 次和 6 次测试的数据分组，以解决只有 9 个样本的问题，因此我的 CI 绘图更加清晰。
数据仅采用离散值。

我知道将数据视为分类会消除排序，但是顺序不会反映在分类变量的系数中吗？此外，我的主要目标是解释我的数据集的模型，而不是预测“通过”&gt; 的观察结果。 6.]]></description>
      <guid>https://stats.stackexchange.com/questions/636781/does-sample-size-affect-whether-to-have-a-variable-as-categorical-or-continuous</guid>
      <pubDate>Sat, 13 Jan 2024 17:45:20 GMT</pubDate>
    </item>
    <item>
      <title>cv.glmnet 中的多项式模型如何处理多标签观察？</title>
      <link>https://stats.stackexchange.com/questions/636779/how-does-the-multinomial-model-in-cv-glmnet-deal-with-multi-label-observations</link>
      <description><![CDATA[目前我正在使用以下模型来执行多类分类：
glmnet::cv.glmnet(x = train_sparse, y = train_res, family = “多项式”, alpha = 1)

其中 train_res 是 $N$ by $K$ 矩阵。因为我们有 $N$ 个观测值和 $K$ 个可能的类别。
我想知道cv.glmnet如何处理具有多个标签的观察结果，换句话说，一行train_res有多个标签。
此包的文档内容如下：
&lt;块引用&gt;
响应变量可以是 nc &gt;= 2 水平因子，或者计数或比例的 nc 列矩阵。在内部，glmnet 将使该矩阵的行总和为 1，并将总质量吸收到该观测的权重中。

这是否意味着，例如，如果我们有两个观察标签，那么对于每个标签，该行将变成两行，每个标签的权重变量为 2？]]></description>
      <guid>https://stats.stackexchange.com/questions/636779/how-does-the-multinomial-model-in-cv-glmnet-deal-with-multi-label-observations</guid>
      <pubDate>Sat, 13 Jan 2024 17:35:02 GMT</pubDate>
    </item>
    <item>
      <title>寻找MVUE——步骤是什么</title>
      <link>https://stats.stackexchange.com/questions/636777/finding-mvue-what-are-the-steps</link>
      <description><![CDATA[我知道我可以找到足够且完整的无偏统计数据，然后使用雷曼谢菲。但是还有其他方法可以找到 MVUE 吗？

如果我找到 MLE 并使它无偏，它真的就是 MVUE 吗？

2）有关 Y_1 的信息对于证明本例中的 MVUE 是否足够重要？

如果我发现效率 = 1 的估计器是无偏的，这是否意味着我找到了 MVUE？

]]></description>
      <guid>https://stats.stackexchange.com/questions/636777/finding-mvue-what-are-the-steps</guid>
      <pubDate>Sat, 13 Jan 2024 17:15:35 GMT</pubDate>
    </item>
    <item>
      <title>混合方差分析中相同因素组合的重复及其功效分析</title>
      <link>https://stats.stackexchange.com/questions/636760/repetitions-on-the-same-combination-of-factors-in-mixed-anova-and-its-power-anal</link>
      <description><![CDATA[我正在尝试确定合适的模型并进行功耗分析。假设一个数据包含 2 个组（A，B），每组有 28 个参与者。所有这些参与者都在 8 个条件 (c1,c2,...c8) 中的每一个条件下测量 15 次，因此每个参与者总共获得 8*15=120 次连续测量。我知道样本大小应该取决于功效分析结果，因此我仅给出参考同一领域相关研究的示例数字。
模型要回答的主要问题是B组的c1和c2是否存在显着差异，c1的A和B是否存在显着差异（以及其他一些类似的比较）。因此，主要目标是测试特定的简单主效应或称为计划对比度。
我的问题与如何在阶乘实验的相同条件下处理重复测量？但更多关于功效分析。我相信我可以使用混合方差分析（组作为效应之间固定，条件作为效应内固定，参与者作为随机效应）或混合建模。然而，我通常不会在重复测量方差分析或混合方差分析中观察到重复（此处每个参与者在每种条件下都有 15 次测量）。因此我的担忧如下。

如果我可以进行混合方差分析，我计划使用 Superpower 软件包进行功效分析。但是ANOVA_design中的“n”似乎仅指参与者的数量，并且似乎没有办法考虑重复次数。同样，G*Power 软件仅允许输入“组数”（因子之间）和“测量次数”（因子内）。这是否意味着重复不会影响功率？但我的理解是，它至少会影响分母的 df 以及幂。
在混合方差分析的情况下，我倾向于测试一些简单的主效应或应称为对比（例如，B 组的 c1 和 c2 的差异）。那么重复重要吗？如果是这样，我如何在Superpower中指定这一点？ G*Power 是否不考虑事后分析，因此我们无法输入重复次数？
如果需要混合效应模型，如何使用 simr 进行计划对比和简单主效应的功效计算？

提前致谢，非常感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/636760/repetitions-on-the-same-combination-of-factors-in-mixed-anova-and-its-power-anal</guid>
      <pubDate>Sat, 13 Jan 2024 07:12:49 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归的假设：如何检查自变量是否与对数赔率（R 中）线性相关？</title>
      <link>https://stats.stackexchange.com/questions/636736/assumption-of-logistic-regression-how-to-check-if-the-independent-variables-are</link>
      <description><![CDATA[我想检查我的逻辑回归是否假设自变量和对数赔率呈线性。
我已经制作了模型并尝试构建自变量和对数赔率的线性，但我不确定这是否正确完成。此外，我不知道如何解释这一点。
我在 R 中使用了这段代码：
模型 &lt;- glm(MetabolicSyndrome ~ LEO + SBD1, data = Corrected_data_q3, family = “二项式”)
摘要（模型）

install.packages(“汽车”)
图书馆（车）

# 创建部分残差图
partial_resid_plots &lt;- crPlots(模型)

我得到了这个输出，但我不确定这是检查这个的正确方法。我不知道如何解释这一点。
]]></description>
      <guid>https://stats.stackexchange.com/questions/636736/assumption-of-logistic-regression-how-to-check-if-the-independent-variables-are</guid>
      <pubDate>Fri, 12 Jan 2024 20:07:00 GMT</pubDate>
    </item>
    </channel>
</rss>