<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 28 Aug 2024 09:17:17 GMT</lastBuildDate>
    <item>
      <title>GAM 比较的估计自由度</title>
      <link>https://stats.stackexchange.com/questions/653474/estimated-degrees-of-freedom-of-a-gam-comparison</link>
      <description><![CDATA[我想通过将该模型与不包含这些预测因子的基线模型进行比较来评估在 GAM 中包含两个平滑项的重要性。可以使用以下代码重现这种情况的模拟：
library(mgcv)
dat &lt;- gamSim(1,n=1000,dist=&quot;normal&quot;,scale=.1)

model &lt;- gam(y ~ s(x0, bs = &quot;cr&quot;, k = 20) + s(x1, bs = &quot;cr&quot;, k = 20) + te(x2, x3, bs = &quot;cr&quot;), data = dat)
baseline &lt;- gam(y ~ te(x2, x3, bs = &quot;cr&quot;), data = dat)
anova(baseline, model)

但是，我想使用交叉验证方案进行此评估。对部分数据进行模型拟合，并评估左侧折叠的对数似然。为此，我将手动计算左侧折叠的对数似然。要计算与对数似然差异相关的 p 值，我需要自由度。 如何确定此比较的正确自由度？
set.seed(123) 
nfolds &lt;- 5
dat$folds &lt;- sample(1:nfolds, size = nrow(dat), replace = TRUE)

train_data &lt;- dat[dat$folds != 1, ]
test_data &lt;- dat[dat$folds == 1, ]
test_y &lt;- test_data$y

model &lt;- gam(y ~ s(x0, bs = &quot;cr&quot;, k = 20) + s(x1, bs = &quot;cr&quot;, k = 20) + te(x2, x3, bs = &quot;cr&quot;), data = train_data)
baseline &lt;- gam(y ~ te(x2, x3, bs = &quot;cr&quot;), data = train_data)

pred_model &lt;- predict(model, test_data)
pred_baseline &lt;- predict(baseline, test_data)

stdev_model &lt;- sigma(model)
stdev_baseline &lt;- sigma(baseline)

loglik_model &lt;- sum(dnorm(test_y, pred_model, stdev_model, log=TRUE))
loglik_baseline &lt;- sum(dnorm(test_y, pred_baseline, stdev_baseline, log=TRUE))

delta &lt;- loglik_model - loglik_baseline
teststat &lt;- -2 * delta
pval &lt;- pchisq(teststat, df = , lower.tail =错误）
]]></description>
      <guid>https://stats.stackexchange.com/questions/653474/estimated-degrees-of-freedom-of-a-gam-comparison</guid>
      <pubDate>Wed, 28 Aug 2024 08:00:38 GMT</pubDate>
    </item>
    <item>
      <title>如何进行数据驱动的样本量选择</title>
      <link>https://stats.stackexchange.com/questions/653472/how-to-perform-data-driven-choice-of-sample-size</link>
      <description><![CDATA[假设我想比较两个回归模型的结果。一个是参考模型，另一个是新模型，我想知道新模型是否表现更好。每个模型都用皮尔逊相关性进行评估，假设数据集是依赖的，并且测试数据相同，我想得到配对差异的置信区间，看看它是否包含零。
但我事先不知道差异的方差，也不知道正确的样本量是多少，所以我想到了以下方法：
min_diff_to_detect
all_pearsons_ref = []
all_pearsons_new = []
alpha = 0.05

循环直到循环中断 -&gt;对于当前循环 n：
train_ref、train_new、test_data = get_new_data_split()

ref_model = train_ref_model(train_ref)
pearson_ref = assess( ref_model(test_data) )
all_pearsons_ref.append(pearson_ref)

new_model = train_new_model(train_new)
pearson_new = assess( new_model(test_data) )
all_pearsons_new.append(pearson_new)

Differences = all_pearsons_new - all_pearsons_ref # 成对差异
confidence_interval = compute_CI(0, np.std(differences), n, alpha)

如果 min_diff_to_detect 不在 confidence_interval 中：
如果 np.mean(differences) 不在 confidence_interval 中：
返回 are_different
返回are_not_different

train_data 是依赖的，而 test_data 对于两个模型是相同的。这个想法是使用数据来寻找最佳循环数 N。否则 N 将被猜测，并且可能太小而没有足够的统计能力，或者太大而需要太长时间进行训练。
但是，方差在早期循环中也有可能波动很大，从而导致 min_diff_to_detect 可能被错误检测。后一点可以通过在评估 if 条件之前引入最小循环数来缓解，但这感觉很武断，最终，我不知道这种方法是否有效。
我也知道 bootstrapping，但它需要大量的训练才能有效。
那么，第一个 if 条件可以改进以避免错误吗？最终，这是一种有效的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653472/how-to-perform-data-driven-choice-of-sample-size</guid>
      <pubDate>Wed, 28 Aug 2024 07:32:11 GMT</pubDate>
    </item>
    <item>
      <title>从头开始的部分依赖图 - XgBoost 深度 1</title>
      <link>https://stats.stackexchange.com/questions/653471/partial-dependence-plot-from-scratch-xgboost-depth-1</link>
      <description><![CDATA[有几个软件包可以为 XGBoost 等 ML 模型引入增强的可解释性，例如 PiML。网上还有很多关于可解释性不同方面的资源，例如部分依赖图。
https://selfexplainml.github.io/PiML-Toolbox/_build/html/guides/models/xgb1.html
https://medium.com/dataman-in-ai/how-is-the-partial-dependent-plot-computed-8d2001a0e556
我希望从头开始构建可解释性深度为 1 的 XGBoost 模型。
根据上面的 PiMl 链接，第一步是：“计算由唯一分割生成的每个 bin 的累积叶节点值”。
import pandas as pd
import numpy as np
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn import datasets
from sklearn.model_selection import train_test_split
iris = datasets.load_iris() 
X = iris.data 
y = iris.target 

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

y_train = np.array([0 if i==2 else 1 for i in y_train])
y_test = np.array([0 if i==2 else 1 for i in y_test])

train = xgb.DMatrix(X_train, label=y_train)

test = xgb.DMatrix(X_test, label=y_test)

params = {&#39;objective&#39;: &#39;binary:logistic&#39;, 
&#39;eval_metric&#39;: &#39;auc&#39;,
&#39;seed&#39;:10,
&#39;max_depth&#39;: 1
}

model = xgb.train(params, train, num_boost_round=10)

dump = model.get_dump()

dump 对象保存有关拆分和叶值的信息。但是，我很难理解“累积叶值”的含义。如果有人能帮助我理解这一点或指导我获取资源，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/653471/partial-dependence-plot-from-scratch-xgboost-depth-1</guid>
      <pubDate>Wed, 28 Aug 2024 06:34:30 GMT</pubDate>
    </item>
    <item>
      <title>控制一个渠道（中介）来检查另一个渠道的影响是否正确？</title>
      <link>https://stats.stackexchange.com/questions/653470/is-it-right-to-control-one-channel-mediator-to-examine-the-impact-of-another-c</link>
      <description><![CDATA[假设冲击 X 通过两个介质/通道（A 和 B）影响 Y。
让我们想象以下有向无环图 (DAG)：
X→𝐴→Y 和 X→𝐵→Y。并且 A 和 B 不相关。
如果我只想检查第二个通道 (B)。在回归中控制 A 以研究 X 通过通道 B 对 Y 的影响是否正确：
Y=𝛼+𝛽X+𝝺A+𝝴
我读过讨论“不良控制”的论文，但它们没有讨论这样的案例。]]></description>
      <guid>https://stats.stackexchange.com/questions/653470/is-it-right-to-control-one-channel-mediator-to-examine-the-impact-of-another-c</guid>
      <pubDate>Wed, 28 Aug 2024 04:00:39 GMT</pubDate>
    </item>
    <item>
      <title>R 中使用多重插补数据集 (mids) 的线性混合模型 EMMEANS 为因子变量添加了级别</title>
      <link>https://stats.stackexchange.com/questions/653467/linear-mixed-model-emmeans-using-multiply-imputed-datasets-mids-in-r-adds-leve</link>
      <description><![CDATA[我使用多重插补数据集 (mids) 在 R 中运行混合线性模型，然后尝试使用 emmeans 包获取带有 p 值的 emmeans。
fit_BAIPsy1 &lt;- 
with(data = df.mids, 
exp = lme4::lmer(
BAI_time ~ factor(Temps) + factor(Groupe) + 
factor(Psychotrope_T1) + T0_Age + factor(T0_Sexe) + 
factor(Temps) * factor(Groupe) + 
factor(Temps) * factor(Psychotrope_T1) + 
factor(Temps) * factor(Groupe) * factor(Psychotrope_T1) + 
ADIS_T0_Score_Dx_principale + (1| Subj)),
reml=TRUE
)

我使用 summary(pool(fit_BAIPsy1)) 从 mice 包中获取模型系数 + 相关统计数据时没有遇到任何问题。一切看起来都很好。
我用我的 Large Mira 对象（使用之前的模型获得）运行了这个来获得我的 emmeans：
emmeans(fit_BAIpsy1, pairwise ~ Groupe|Psychotrope_T1|Temps)
问题：
虽然 Psychotrope_T1 是一个因子 (0, 1)，但 emmeans 给了我额外的 级别 (0, 0.44, 0.48, 0.52, 0.54, [...], 1)。 
这个变量是估算的，但我检查了我的 25 个估算数据集 (df.mids)，看不到这些值。我还检查了我的 Mira 模型元素中的 25 个帧，我看到的只有 0 和 1。混合线性模型输出只给了我 2 个级别。
我检查了 emmGrid，我可以看到除了 Psychotrope_T1 和 Groupe 之外，我的网格中还添加了一个 .wgt。
我将其与另一个未估算的变量 (Psychotrope_T0，这是我的基线值) 进行了比较，我没有这个 .wgt。元素，emmeans 输出看起来很正常。
你能告诉我哪里出了错以及如何解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653467/linear-mixed-model-emmeans-using-multiply-imputed-datasets-mids-in-r-adds-leve</guid>
      <pubDate>Wed, 28 Aug 2024 02:51:25 GMT</pubDate>
    </item>
    <item>
      <title>解释 R 中逻辑回归的连续预测变量</title>
      <link>https://stats.stackexchange.com/questions/653466/interpreting-continuous-predictors-for-logistic-regression-in-r</link>
      <description><![CDATA[我将 GLM 拟合到我的数据集，但无法将系数解释为概率。通货膨胀变化的解释是否如下：通货膨胀变化增加 100% 会导致响应变量的可能性增加 99.9%？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653466/interpreting-continuous-predictors-for-logistic-regression-in-r</guid>
      <pubDate>Wed, 28 Aug 2024 02:47:05 GMT</pubDate>
    </item>
    <item>
      <title>两个 AR(1) 过程之和的持久性</title>
      <link>https://stats.stackexchange.com/questions/653465/persistence-of-the-sum-of-two-ar1-processes</link>
      <description><![CDATA[考虑一个时间序列 $y_t$，它可以分解为两个组成部分的总和：
$$y_t = x_{1,t} + x_{2,t} $$
假设每个组成部分都是独立的，并遵循平稳 AR(1) 过程：
$$\begin{align*} 
x_{1,t} &amp;= \phi_1 x_{1,t-1} + \varepsilon_{1,t} \\
x_{2,t} &amp;= \phi_2 x_{2,t-1} + \varepsilon_{2,t} \\
\end{align*}$$
其中：
$$\begin{align*} 
\varepsilon_{1,t} &amp;\sim N \left (0,\sigma_1^2 \right ) \\
\varepsilon_{2,t} &amp;\sim N \left (0,\sigma_2^2 \right ) \\
\end{align*}$$
我使用模拟来生成一系列长序列 $X_1$、$X_2$ 以及它们的和 $Y$。然后，我估计 $y_t$ 的 AR(1) 模型
$$y_t = \phi_y y_{t-1} + \varepsilon_{y,t}$$
在我的模拟/估计中，我发现 $\phi_y$ 的估计值是 $\phi_1$ 和 $\phi_2$ 的加权平均值，其中每个成分的 $\phi_i$ 的权重由其无条件方差的比例决定。也就是说，我发现：
$$
\hat{\phi}_y \approx \left ( \frac{\frac{\sigma_1^2}{1-\phi_1^2}}{\frac{\sigma_1^2}{1-\phi_1^2} +\frac{\sigma_2^2}{1-\phi_2^2}} \right ) \phi_1 + \left ( \frac{\frac{\sigma_2^2}{1-\phi_2^2}}{\frac{\sigma_1^2}{1-\phi_1^2} +\frac{\sigma_2^2}{1-\phi_2^2}} \right ) \phi_2
$$
我知道Lütkepohl (1984)（虽然我还没有获得副本），据称证明了$y_t$遵循平稳 ARMA 过程。
是否有人知道以下任一证明（或能够推导出证明）：

$y_t$遵循 AR(1) 过程。
$\phi_y \equiv \left ( \frac{\frac{\sigma_1^2}{1-\phi_1^2}}{\frac{\sigma_1^2}{1-\phi_1^2} +\frac{\sigma_2^2}{1-\phi_2^2}} \right ) \phi_1 + \left ( \frac{\frac{\sigma_2^2}{1-\phi_2^2}}{\frac{\sigma_1^2}{1-\phi_1^2} +\frac{\sigma_2^2}{1-\phi_2^2}} \right ) \phi_2$

最后，有谁知道任何相关的证明涉及更一般的情况，当$\varepsilon_{1,t}$和$\varepsilon_{2,t}$ 是相关的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653465/persistence-of-the-sum-of-two-ar1-processes</guid>
      <pubDate>Wed, 28 Aug 2024 02:09:13 GMT</pubDate>
    </item>
    <item>
      <title>如何计算交互项的风险比和 95％ 置信区间（使用 R）</title>
      <link>https://stats.stackexchange.com/questions/653462/how-to-calculate-the-risk-ratio-and-95-confidence-interval-of-an-interaction-te</link>
      <description><![CDATA[我的目标是计算交互项的风险比和 95% 置信区间。
例如，有两个变量 age 和 sex (y ~ age * sex)，我想分别计算男性和女性年龄增量的风险比和 95% 置信区间。
这是我使用 rms 包制作的一个例子。如果我的理解没有错的话，rms 包中的 summary.rms 可以很方便地通过 summary(f, age = ..., sex = &quot;Female/Male&quot;) 输出交互项的风险比。
年龄交互作用的效应可以计算为第一级（本例中为女性）coefage 的指数变换，coefage + coefage:Male 的指数变换（男性），如果还有其他级别，则 coefage + coefage:other。
至于标准误差，我在网上看到了以下计算公式：$\sqrt{\text{var}(b_1) + \text{var}(b_2) + 2\text{cov}(b_1,b_2)}$。
这个公式的结果和rms包的输出一致，但是好像有人指出这个公式没有依据（见这个）？
我的问题是，

我描述的计算方法和公式是否正确？

这个计算方法和公式是否适用于一般线性回归、逻辑回归和cox回归？（是通用方法吗？）

相互作用很常见。很多人会把数据按照分类变量分成几个子组，然后分别计算连续值的影响。但这种方法应该是错误的，对吧？应该在全样本中计算交互作用，然后按照上面的方法计算不同层次连续值的效应（有点跑题，想确认一下我的这个理解是否正确）。


require(survival)
require(rms)
n &lt;- 1000
set.seed(1)

sex &lt;- factor(sample(c(&#39;Male&#39;,&#39;Female&#39;), n, 
rep=TRUE, prob=c(.6, .4)))
age &lt;- 40 + 11*rnorm(n) + as.numeric(sex) *rnorm(n)
cens &lt;- 14*runif(n)
h &lt;- .12*exp(.04*(age-40)+.72*(sex==&#39;Female&#39;))
dt &lt;- -log(runif(n))/h
e &lt;- ifelse(dt &lt;= cens,1,0)
dt &lt;- pmin(dt, cens)
dd &lt;- datadist(age, sex)
options(datadist=&#39;dd&#39;)
S &lt;- Surv(dt,e)

f &lt;- cph(S ~ age * sex, x=TRUE, y=TRUE)
f
# 系数 S.E. Wald Z Pr(&gt;|Z|)
# 年龄 0.0273 0.0053 5.15 &lt;0.0001 
# 性别=男性 -1.4011 0.3025 -4.63 &lt;0.0001 
# 年龄 * 性别=男性 0.0174 0.0070 2.48 0.0130 

summary(f, 年龄 = c(40,41), 性别 = &quot;女性&quot;)

summary(f, 年龄 = c(40,41), 性别 = &quot;男性&quot;)
# 效应 响应：S 
# 
# 因素 低 高 差异 效应 S.E.下限 0.95 上限 0.95
# 年龄 40 41 1 0.04471 0.0046908 0.035516 0.053903 
# 风险比 40 41 1 1.04570 NA 1.036200 1.055400 
# 性别 - 女性:男性 2 1 NA 0.71319 0.0831390 0.550240 0.876140 
# 风险比 2 1 NA 2.04050 NA 1.733700 2.401600 

f$coefficients[1] + f$coefficients[3] 
# 0.04470962

v &lt;- vcov(f)
sqrt(v[&quot;年龄&quot;, &quot;年龄&quot;] + v[&quot;年龄 * 性别=男性&quot;, &quot;年龄 * 性别=男性&quot;] + 2*v[&quot;年龄&quot;, &quot;年龄 * 性别=男性&quot;])
# 0.004690838

]]></description>
      <guid>https://stats.stackexchange.com/questions/653462/how-to-calculate-the-risk-ratio-and-95-confidence-interval-of-an-interaction-te</guid>
      <pubDate>Wed, 28 Aug 2024 01:27:09 GMT</pubDate>
    </item>
    <item>
      <title>我需要做些什么来改进我的回归模型</title>
      <link>https://stats.stackexchange.com/questions/653461/what-i-have-to-do-more-to-improve-my-regression-model-in-r</link>
      <description><![CDATA[我想制作饮料销售预测模型。我正在做回归分析。所有列类型都是整数。数据的维度是 15375 行 x 400 列。因变量 $y$ 是饮料销售比例。
数据如下。

经过向后消除和改变$y$以符合正则化假设后，我使用了这个模型。
reg&lt;-lm(I(log(y+1)^0.4650181) ~ x1 + I(x2^2) + I(x3^2) + x4 + I(x5^2)...x17 ,data = train)

我认为回归模型可以改进，但我不知道我还能做些什么。看到 plot(reg) 输出后，请给我一些建议。

我已经对 $y$ 进行了对数变换和平方根变换。]]></description>
      <guid>https://stats.stackexchange.com/questions/653461/what-i-have-to-do-more-to-improve-my-regression-model-in-r</guid>
      <pubDate>Wed, 28 Aug 2024 01:24:32 GMT</pubDate>
    </item>
    <item>
      <title>如何对 $\mathbb R^2$ 中不平行的两条线进行双变量高斯条件化？</title>
      <link>https://stats.stackexchange.com/questions/653455/how-to-condition-a-bivariate-gaussian-on-two-lines-in-mathbb-r2-that-are-not</link>
      <description><![CDATA[如何对 $\mathbb{R}^2$ 中两条不平行/相交的线 $\{(x,y):a_1x+b_1y+c_1=0\}\cup\{(x,y):a_2x+b_2y+c_2=0\}$ 上的均值为 $\mu$ 和 $\Sigma$（例如 $\sigma=\sigma^2I$）的双变量高斯进行条件化？]]></description>
      <guid>https://stats.stackexchange.com/questions/653455/how-to-condition-a-bivariate-gaussian-on-two-lines-in-mathbb-r2-that-are-not</guid>
      <pubDate>Tue, 27 Aug 2024 23:31:11 GMT</pubDate>
    </item>
    <item>
      <title>在复杂抽样下，效应大小通常如何定义？</title>
      <link>https://stats.stackexchange.com/questions/653452/how-are-effect-sizes-typically-defined-under-complex-sampling</link>
      <description><![CDATA[在某些领域，引用标准化效应大小的比较是很常见的。例如，均值差异通过样本标准差进行缩放以得出效应大小。
这进而导致计算公式从其他输入中提取标准差，例如，$t$统计量乘以其自由度的平方根大约等于缩放后的均值差异。这些计算公式在复杂抽样下无效：均值的标准误差与标准差之间的关系更为复杂。即使是“均值差除以标准差”这一简单定义，也会引发一个问题：哪个标准差——估计的总体标准差？
那么，问题是：是否存在标准的、广泛使用的标准化效应大小公式，可以解释复杂抽样？
[我并不真正关心标准化效应大小是好是坏，甚至不关心在复杂抽样下如何最好地计算它们——我只是试图找出现有的标准]]]></description>
      <guid>https://stats.stackexchange.com/questions/653452/how-are-effect-sizes-typically-defined-under-complex-sampling</guid>
      <pubDate>Tue, 27 Aug 2024 23:09:45 GMT</pubDate>
    </item>
    <item>
      <title>如何计算两个成功率的 p 值，其中一个测试集是另一个测试集的子集？</title>
      <link>https://stats.stackexchange.com/questions/653468/how-do-i-calculate-the-p-value-for-two-success-rates-where-one-of-the-test-sets</link>
      <description><![CDATA[我知道这样的问题已经被问了一百次，但不幸的是，我不够聪明，无法找出哪个答案适用于我的问题。
背景：我有一个图像分类模型，在测试集上的准确率为 95.89%。现在，不幸的是，在训练期间已经看到了一些测试集。我想知道的是模型是否从中受益，从而使结果具有误导性。我为测试这一点所做的是创建一个测试集的子集，其中只有模型从未见过的图像，因此是一个未受污染的测试集。在该子集上，该模型的准确率为 95.32%，因此正如预期的那样，模型的表现更差，但我不知道这是否与污染有关，或者子集是否只是运气不好。所以我认为我的零假设是污染对模型的性能没有影响。现在我必须弄清楚该大小的随机子集执行该操作的概率有多高。我当然有集合大小，可以提供它们，但老实说，我只是想要一些关于我的场景叫什么以及有哪些方法的指针。我可以自己做计算。
我发现了一个所谓的 R 测试，听起来有点像我想要的，但我不确定，因为这两个数据集并不相互独立。一个包含另一个的全部。
我还训练了三个架构等效的模型（这是机器学习中可重复性的良好做法），所以我实际上对每个集合都有三个非常相似的准确度，并且可以为每个集合近似一个标准差，但我不知道是否以及如何编织它。
正如我所说 - 我对寻找的正确术语或链接感到满意，其余的我可以自己弄清楚。
感谢阅读！]]></description>
      <guid>https://stats.stackexchange.com/questions/653468/how-do-i-calculate-the-p-value-for-two-success-rates-where-one-of-the-test-sets</guid>
      <pubDate>Tue, 27 Aug 2024 21:16:49 GMT</pubDate>
    </item>
    <item>
      <title>有或没有聚合的混合设计方差分析？</title>
      <link>https://stats.stackexchange.com/questions/653439/mixed-design-anova-with-or-without-aggregation</link>
      <description><![CDATA[我进行了一个反应时间实验，现在想对其进行评估。这是一个重复测量实验，有两个条件（我们称之为条件 A 和条件 B）。还有两个组（我们称之为组 1 和组 2）。每个参与者在条件 1 中完成了 60 次试验，在条件 2 中完成了 60 次试验，因此每个用户有 120 个数据点。我现在想做一个混合方差分析，我想知道我是否应该使用每个参与者的试验平均值，或者我是否应该使用每个参与者的每个数据点。我曾尝试在 R 中使用 ezANOVA 和 afex 将每个数据点引入 ANOVA，但两个软件包都返回了聚合到均值的警告。
这是我的数据的样子：



ID
Group
Conditon
RT




1
Group 1
A
345


1
Group 1
A
746


1
第 1 组
A
824


1
第 1 组
B
542


1
第 1 组
B
235


1
组1
B
654


2
第 2 组
A
324


2
第 2 组
A
345


2
第 2 组
A
123


2
组2
B
623


2
第 2 组
B
235


2
第 2 组
B
654



我尝试这样计算：
afex::aov_car(RT ~ Group*Condition+ Error (ID/Condition), data = df_long)

然后我收到警告：
每个设计单元有多个观察值，使用聚合数据`fun_aggregate = mean`。

要关闭此警告，请明确传递 fun_aggregate = mean。]]></description>
      <guid>https://stats.stackexchange.com/questions/653439/mixed-design-anova-with-or-without-aggregation</guid>
      <pubDate>Tue, 27 Aug 2024 19:11:53 GMT</pubDate>
    </item>
    <item>
      <title>面板数据中的单位不变处理</title>
      <link>https://stats.stackexchange.com/questions/653438/unit-invariant-treatments-in-panel-data</link>
      <description><![CDATA[初学者，想问一个关于双向固定效应的初学者问题。如果相关的话，我正在使用 R。
与这个问题中的用户一样，我感兴趣的是估计随时间变化（但单位不变）的宏观条件如何影响公司情绪；就我而言，是在行业层面。但是，我的问题略有不同。 这个答案也可能部分回答了我的问题，尽管我发现问题和答案都令人困惑。
就我而言，我有以下数据：(1) 各个公司的 ID，(2) 每个公司所属的行业，(3) 日期 (YYYY-MM-DD)，(4) 宏观条件，(5) 公司情绪，以及 (6) 情绪所指的主题。

“处理”[宏观条件] 和响应 [情绪] 都是连续的，范围从负到正。
行业、主题和公司是分类的。

首先，我关心符号以及处理的幅度如何影响响​​应。其次，观察某些行业反应的差异也很重要，对我来说，这意味着一个交互项。我想象我想要估计的关系是这样的：
$$ Sentiment_{ijt} = Macro_{jt} + Sector_i + Macro_{jt} * Sector_i $$
其中 $i$ 是公司，$j$ 是主题，$t$ 是年度汇总。通常，我看到人们将公司和年份作为固定效应。但我怀疑教科书式的方法是否适用于此：

首先，由于每个公司只能被分配到一个部门，并且这个部门不会随时间而变化，$Sector$ 应该与公司 FE 完全共线。
其次，对我来说，重点是估计不同公司响应的差异，因此我认为我不想包含公司 FE。

我想我可以使用 topic FE 而不是公司 FE。但我从未见过这样做；单位（根据我的经验）通常是基于空间或实体的。因此，从概念上讲，我很难理解分析单位（主题年份？）甚至代表什么，或者它是否与我的实际研究问题一致。
我还读到，有 3WFE 解决方案可以解释 $Y$ 上的所有下标，但我觉得这可能是错误的方向，因为我的目标是观察行业级别的差异（以及我的预测变量上的下标与 $Y$ 上的下标不匹配）。
将 $Sentiment_{ijt}$ 建模为 $Macro_{jt} * Sector_i$ 与主题 ($i$) / 年份 ($t$) 2WFE 是否是一种合理的方法，考虑到我的研究问题？或者是否应该重构我的数据以减少$Sentiment$可能变化的维度数量？]]></description>
      <guid>https://stats.stackexchange.com/questions/653438/unit-invariant-treatments-in-panel-data</guid>
      <pubDate>Tue, 27 Aug 2024 19:05:11 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python statsmodels 计算混合线性模型 R2 和 ICC</title>
      <link>https://stats.stackexchange.com/questions/653403/mixed-linear-model-r2-and-icc-calculation-using-python-statsmodels</link>
      <description><![CDATA[我对混合线性模型还不熟悉。我建立了一个模型，该模型具有两个随机效应（Student_id 和 Subject）和一个固定效应（MAI），预测变量为 SRL。
model = combinedlm(&quot;SRL ~ MAI&quot;, data=df, groups=df[&quot;Student_id&quot;], re_formula=&quot;~1&quot;, vc_formula={&quot;Subject&quot;: &quot;0 + C(Subject)&quot;})
result = model.fit()

我想分解方差，以计算每个效应解释的方差量。即：

边际$R^2$（即$R^2_M$，方差由固定效应解释）
条件$R^2$（即$R^2_C$方差由固定+随机效应解释）
Student_id 的 ICC（即$ICC_1$，随机效应的一部分）
Subject 的 ICC（即$ICC_2$，随机效应的一部分）

在研究和查看这个问题，我发现以下五个计算是相关的：
var_f_r = result.fittedvalues.var() # 固定和随机效应方差？0.26061471675794606
var_f = result.predict(result_df).var() # 固定效应？ 0.11
var_e = result.scale # 残差方差，0.09
var_r1 = result.cov_re.iloc[0, 0] # Student_id 的随机效应，0.129
var_r2 = result.vcomp[0] # Subject 的随机效应，0.079

我会做这样的事情，但似乎不正确：
$total\_var = var\_f + var\_e + var\_{r1} + var\_{r2}$
$R^2_M = \frac{var\_f}{total\_var}$
$R^2_C = \frac{var\_f\_r}{total\_var}$
$ICC_1 = \frac{var\_r1}{total\_var}$
$ICC_2 = \frac{var\_r2}{total\_var}$
问题：

您能指出我的理解可能不正确的地方吗，并告诉我如何正确计算？
如果我们将其更改为空模型mixedlm(&quot;SRL ~ 1&quot;, data=df, groups=df[&quot;Student_id&quot;], re_formula=&quot;~1&quot;, vc_formula={&quot;Subject&quot;: &quot;0 + C(Subject)&quot;})。我们能用同样的方式进行计算吗（在这种情况下 var_f 为 0）

感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/653403/mixed-linear-model-r2-and-icc-calculation-using-python-statsmodels</guid>
      <pubDate>Tue, 27 Aug 2024 11:17:07 GMT</pubDate>
    </item>
    </channel>
</rss>