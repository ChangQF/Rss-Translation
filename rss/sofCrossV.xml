<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 06 Feb 2025 09:17:57 GMT</lastBuildDate>
    <item>
      <title>我们处理缺失的人口统计数据的方式是否与处理其他类型变量的缺失数据的方式相同？</title>
      <link>https://stats.stackexchange.com/questions/661033/do-we-handle-missing-demographic-data-the-same-way-we-handle-missing-data-for-ot</link>
      <description><![CDATA[我缺少有关人口统计变量（例如年龄、性别、种族）的数据。我已使用随机回归对所有其他感兴趣的变量（例如心理变量）的缺失数据进行估算。是否也应该估算人口统计变量，或者是否应该将它们保留为缺失并报告缺失数据？]]></description>
      <guid>https://stats.stackexchange.com/questions/661033/do-we-handle-missing-demographic-data-the-same-way-we-handle-missing-data-for-ot</guid>
      <pubDate>Thu, 06 Feb 2025 08:01:02 GMT</pubDate>
    </item>
    <item>
      <title>哪一个是正确的 SE，为什么？</title>
      <link>https://stats.stackexchange.com/questions/661030/which-one-is-the-right-se-and-why</link>
      <description><![CDATA[我不确定这是否更像是一个 stackoverflow 问题，但我认为这里可能更好，因为我正在尝试了解如何确定正确的答案。
我创建了一个可重现的小示例：
library(survey)
library(broom)
library(broom.helpers)

mtcars$weights &lt;- rnorm(dim(mtcars)[1],1,0.1)

model &lt;- svyglm(as.formula(&quot;vs ~ wt&quot;),family=quasibinomial(link=&quot;logit&quot;),design=svydesign(ids=~1,weights=~weights,data=mtcars))

假设我想在指数化系数后提取输出表，使用来自 broom 的 tidy 的输出和broom.helpers 中的 tidy_parameters 几乎完全相同，除了 SE（差异很大）之外
tidy(model,exp=TRUE,conf.int=TRUE)

给出此输出

但是，
tidy_parameters(model,exp=TRUE,conf.int=TRUE) 

给出此输出

我如何确定哪些是正确的 SE？什么可以解释两个输出之间的 SE 差异（但不能解释任何其他参数）？]]></description>
      <guid>https://stats.stackexchange.com/questions/661030/which-one-is-the-right-se-and-why</guid>
      <pubDate>Thu, 06 Feb 2025 05:33:28 GMT</pubDate>
    </item>
    <item>
      <title>使用距离和方差的遗传算法多目标聚类</title>
      <link>https://stats.stackexchange.com/questions/661029/genetic-algorithm-multi-objective-clustering-using-distance-and-variance</link>
      <description><![CDATA[我尝试使用 PyGAD 进行聚类，通过最小化 2d 点的欧几里德距离（vanilla kmeans），同时还希望最小化第三个特征（权重）的聚类间方差。我使用以下代码获得了合理的聚类，但我想知道这是否有意义。欢迎提供任何反馈。我将在下面包含聚类函数。
def cluster_data(solution, solution_idx):
global num_cluster, data
feature_vector_length = data.shape[1] - 1
cluster_centers = []
all_clusters_dists = []
clusters = []
clusters_sum_dist = []

clusters_sum_var = []

for clust_idx in range(num_clusters):
cluster_centers.append(solution[feature_vector_length*clust_idx:feature_vector_length*(clust_idx+1)])
cluster_center_dists = euclidean_distance(data[:,:-1], cluster_centers[clust_idx])
all_clusters_dists.append(numpy.array(cluster_center_dists))

cluster_centers = numpy.array(cluster_centers)
all_clusters_dists = numpy.array(all_clusters_dists) 
cluster_indices = numpy.argmin(all_clusters_dists, axis=0)
对于 clust_idx 在 range(num_clusters):
clusters.append(numpy.where(cluster_indices == clust_idx)[0])
如果 len(clu​​sters[clust_idx]) == 0:
clusters_sum_dist.append(0)
否则:
clusters_sum_dist.append(numpy.sum(all_clusters_dists[clust_idx, clusters[clust_idx]]))

clusters_sum_dist = numpy.array(clusters_sum_dist)

对于 clust_idx 在range(num_clusters):
if len(clu​​sters[clust_idx]) == 0:
clusters_sum_var.append(0)
else:
cluster_current_data = data[np.where(cluster_indices == clust_idx)[0],-1]
clusters_sum_var.append(np.std(cluster_current_data))
clusters_sum_var = np.array(clusters_sum_var)

return clusters_sum_var, cluster_centers, all_clusters_dists, cluster_indices, clusters, clusters_sum_dist

这是适应度函数
def fitness_func(ga_instance,solution, solution_idx):
clusters_sum_var,_, _, _, _, clusters_sum_dist = cluster_data(solution, solution_idx)

clusters_sum_var = rescale_linear(clusters_sum_var,clusters_sum_dist.min(),clusters_sum_dist.max())

fitness_1 =1.0 / (np.sum(clusters_sum_var) + 0.00000001)

fitness = 1.0 / (numpy.sum(clusters_sum_dist) + 0.00000001)

返回 fitness,fitness_1
]]></description>
      <guid>https://stats.stackexchange.com/questions/661029/genetic-algorithm-multi-objective-clustering-using-distance-and-variance</guid>
      <pubDate>Thu, 06 Feb 2025 04:16:40 GMT</pubDate>
    </item>
    <item>
      <title>使用引导程序生成预测区间</title>
      <link>https://stats.stackexchange.com/questions/661026/generating-prediction-intervals-using-bootstrap</link>
      <description><![CDATA[我有一些数据并拟合线性回归：
$$ y_i = \beta_0 + \beta_1x_i + \epsilon_i, \quad \epsilon_i \sim N(0, \sigma^2) $$
我想对新点 $x_{\text{new}}$ 进行预测并记录预测区间。我对以下内容有些困惑。我能想到 3 种不同的方法来做到这一点：
我已将它们概述如下：

方法 1：没有单独预测区间的引导样本
使用引导抽样。对于一个新点$x_{\text{new}}$，生成引导样本。对于每个引导样本$b = 1, \ldots, B$:

从我们的原始数据中进行替换抽样，以获得$i = 1, \ldots, n$的$(x_i^{(b)}, y_i^{(b)})$
拟合新的回归模型以获得估计值$\hat{\beta}_0^{(b)}$和$\hat{\beta}_1^{(b)}$

对于每个引导样本$b$，仅计算点预测：
$$ \hat{y}_{\text{new}}^{(b)} = \hat{\beta}_0^{(b)} + \hat{\beta}_1^{(b)}x_{\text{new}} $$
然后根据这些预测的经验分布形成预测区间：
$$ [\hat{y}_{\text{new},\text{lower}}, \hat{y}_{\text{new},\text{upper}}] = [\text{Percentile}_{2.5}(\{\hat{y}_{\text{new}}^{(b)}\}), \text{Percentile}_{97.5}(\{\hat{y}_{\text{new}}^{(b)}\})] $$

方法 2：具有单独预测区间的引导样本
对于每个引导样本 $b$，我们计算完整的预测区间：
$$ \hat{y}_{\text{new}}^{(b)} \pm t_{n-2,\alpha/2}\hat{\sigma}^{(b)}\sqrt{1 + \frac{1}{n} + \frac{(x_{\text{new}} - \bar{x}^{(b)})^2}{\sum(x_i^{(b)} - \bar{x}^{(b)})^2}} $$
其中：

$\hat{\sigma}^{(b)}$ 是自举样本的残差标准误差 $b$
$t_{n-2,\alpha/2}$ 是 t 分布的临界值
$\bar{x}^{(b)}$ 是自举样本中 x 值的平均值 $b$

这为我们提供了 $b = 1, \ldots, B$ 的区间集合 $[L^{(b)}, U^{(b)}]$。最终的预测区间是：
$$ [\text{百分位数}_{2.5}(\{L^{(b)}\}), \text{百分位数}_{97.5}(\{U^{(b)}\})] $$

方法 3：无引导，使用封闭形式预测区间
使用经典方法和封闭形式公式：
$$ \hat{y}_{\text{new}} \pm t_{n-2,\alpha/2}\hat{\sigma}\sqrt{1 + \frac{1}{n} + \frac{(x_{\text{new}} - \bar{x})^2}{\sum(x_i - \bar{x})^2}} $$
其中：

$\hat{\sigma}$ 是原始模型的残差标准误差
$\bar{x}$ 是原始 x 值的平均值


总结：

方法 1 仅捕获回归系数中的不确定性（$\beta_0$ 和 $\beta_1$）。这将是最小的。
方法 2 通过引导法考虑了系数不确定性和固有可变性（$\sigma^2$）。这将是最大的
方法 3 使用基于 t 分布假设的理论公式。这将是中间

在实践中，建议使用方法 2 来获得最现实的预测区间吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/661026/generating-prediction-intervals-using-bootstrap</guid>
      <pubDate>Thu, 06 Feb 2025 03:45:25 GMT</pubDate>
    </item>
    <item>
      <title>安德森吉尔斯模型是否严格模拟事件重复发生的风险或事件之间的时间？</title>
      <link>https://stats.stackexchange.com/questions/661025/does-the-andersen-gills-model-strictly-model-the-hazard-of-an-event-recurring-or</link>
      <description><![CDATA[如果我对协变量对复发事件间隔时间的影响感兴趣，也就是说，我想探索特定协变量是否会缩短或延长后续事件之间的间隔，那么复发事件的 Cox 比例风险模型（如 Andersen Gills 模型）是否可以做到这一点？或者，这些模型是否严格模拟事件复发的风险，并计算协变量如何增加或减少事件复发的风险？]]></description>
      <guid>https://stats.stackexchange.com/questions/661025/does-the-andersen-gills-model-strictly-model-the-hazard-of-an-event-recurring-or</guid>
      <pubDate>Thu, 06 Feb 2025 02:19:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么 CL% 的 CI 必须正确捕获参数？（证明）[关闭]</title>
      <link>https://stats.stackexchange.com/questions/661020/why-must-a-cl-of-cis-correctly-capture-the-parameter-proof</link>
      <description><![CDATA[据我所知，如果我们取一个样本，我们可以从该样本构建一个置信区间。如果我们从不同的样本中获取许多这样的置信区间，则正确的百分比将等于置信水平。有什么证据表明置信区间公式保证这是正确的？需要说明的是，我主要讨论的是比例。
我使用的公式是：
$$CI = \hat{p} \pm z^\star\sqrt{\frac{(\hat{p})(1-\hat{p})}{n}}$$
其中 $\hat{p}$ = 样本比例
$n$ = 样本大小
$z^\star$ = 置信水平的临界值
$CI$ = 置信区间
我使用了一个简单的随机样本作为样本。]]></description>
      <guid>https://stats.stackexchange.com/questions/661020/why-must-a-cl-of-cis-correctly-capture-the-parameter-proof</guid>
      <pubDate>Thu, 06 Feb 2025 00:12:59 GMT</pubDate>
    </item>
    <item>
      <title>K 均值成本函数</title>
      <link>https://stats.stackexchange.com/questions/661018/k-means-cost-function</link>
      <description><![CDATA[在《统计学习要素 (ESL)》中，他们在方程 (14.31) 中指出，k-Means 目标函数为
$$W(C) = \sum_{k=1}^KN_k \sum_{C(i)=k} ||x_i - \bar{x}_k||^2$$
其中 $K$ 是聚类的数量，$N_k$ 是聚类 $k$ 中的点的数量，$C(i)$ 是聚类分配函数。但是，从其他来源了解到 k-means 后，我总是看到成本函数被理解为
$$L(C) = \sum_{k=1}^K \sum_{C(i)=k}||x_i - \bar{x}_k||^2 $$
即不按大小对每个簇进行加权。我只想说，人们可以根据任务选择不同的权重，但我很确定 ESL 中提出的算法是局部最小化 $L(C)$ 的标准算法，而不是 $W(C)$，即他们描述的迭代步骤没有考虑簇大小。我这里遗漏了什么，还是书中有错误？]]></description>
      <guid>https://stats.stackexchange.com/questions/661018/k-means-cost-function</guid>
      <pubDate>Wed, 05 Feb 2025 22:32:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 ggcorrplot 过滤具有特定敏感性的相关矩阵数据[关闭]</title>
      <link>https://stats.stackexchange.com/questions/661017/filtering-correlation-matrix-data-with-particular-sensitivity-with-ggcorrplot</link>
      <description><![CDATA[我有一个包含大量数据集（&gt;10 列）的相关矩阵，显然它既不清晰也无意义。我想通过过滤超出特定敏感度水平的相关矩阵来从数据中得出一些意义。该函数应具有参数 M、s 和 dir，并带有以下选项：
filter(corrM, s, &#39;ge&#39;)
filter(corrM, s, &#39;gt&#39;)
filter(corrM, s, &#39;eq&#39;)
filter(corrM, s, &#39;le&#39;)
filter(corrM, s, &#39;lt&#39;)
它应仅返回 corrM 中分别等于或大于、严格大于、等于、严格小于或小于或等于 S 值的条目。例如，如果 s=0.6 和 dir=&#39;ge&#39;，则所有小于 0.6 的值都将被忽略并设置为 NULL，以便可以从矩阵图中删除它们。
所讨论的矩阵图是
model.matrix(~0+., data=M) %&gt;%
cor(use=&quot;pairwise.complete.obs&quot;) %&gt;%
ggcorrplot(show.diag=FALSE, type=&quot;lower&quot;, lab=TRUE, lab_size=2)

但我希望将 corrM 导出为 tibble，而不是 ggplot。我不能简单地使用 cor(M)，因为我有数字和非数字数据的混合，所以我使用了这里描述的技术：https://stackoverflow.com/questions/52554336/plot-the-equivalent-of-correlation-matrix-for-factors-categorical-data-and-mi。]]></description>
      <guid>https://stats.stackexchange.com/questions/661017/filtering-correlation-matrix-data-with-particular-sensitivity-with-ggcorrplot</guid>
      <pubDate>Wed, 05 Feb 2025 22:11:22 GMT</pubDate>
    </item>
    <item>
      <title>计算认知模型对实验心理学是否必要？DDM/LBA 的困难</title>
      <link>https://stats.stackexchange.com/questions/661015/are-computational-cognitive-models-necessary-for-experimental-psychology-diffic</link>
      <description><![CDATA[一段时间以来，我一直在做一个监督研究项目，不幸的是，由于不可预见的情况，我不得不在夏天毕业之前全力以赴地完成这个项目。
我最初计划使用 GDDM 研究主观奖励推理对 MDD、ADHD 和 G.A.D 患者在不确定情况下的速度/准确度权衡的影响。
当我尝试将 DDM 或 LBA 模型与我的 RT 和来自包含西蒙效应的视觉异常任务的误差数据相匹配时，我遇到了技术问题。与我的 python/R 环境的持续依赖冲突、参数估计和时间都是一个问题。实现起始偏差的奖励函数或作为作用于漂移率的函数也具有挑战性，因此实际上，我认为在未来 5-7 个月内，没有可行的方法可以实现 20-40 人的队列。
我可以使用常规统计方法或经典过程模型，还是混合线性模型来实现这一点？双向方差分析和更通用（且不太复杂）的统计方法是否有效？
如果我的假设成立，我想与我的主管一起发表论文，但我不确定如果没有 DDM 或其他证据积累/顺序抽样认知模型等模型，是否有可能这样做。
我怀疑能否在此时间范围内使用可与我的数据和其他研究的类似数据很好地匹配的通用模型完成这个项目，但建模是否有必要获得有用的结果和见解？
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661015/are-computational-cognitive-models-necessary-for-experimental-psychology-diffic</guid>
      <pubDate>Wed, 05 Feb 2025 21:32:57 GMT</pubDate>
    </item>
    <item>
      <title>通过计算检查梯度是否会爆炸或消失</title>
      <link>https://stats.stackexchange.com/questions/661007/check-through-calculations-whether-the-gradients-will-explode-or-vanish</link>
      <description><![CDATA[我正在复习旧考试题目，偶然发现了这个：

考虑一个常规的 MLP（多层感知器）架构，该架构具有 10 个完全连接的层和 ReLU 激活函数。网络的输入是一个大小为 100 的向量，其中每个维度的均值为零，标准差在整个数据集中等于 1。
每个隐藏层有 10000 个神经元，权重由均值为零、方差为 0.01 的正态分布初始化。


以下哪个选项最有可能？
a) 梯度将爆炸
b) 梯度将消失
c) 都不是。

答案中有：
a) 正确
b) 错误
a) 错误
我如何证明这些答案？我想我需要计算一些东西，但我不知道从哪里开始。
输入中的预期值都是零，权重也是如此，因此当一切都为零时很难计算任何东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/661007/check-through-calculations-whether-the-gradients-will-explode-or-vanish</guid>
      <pubDate>Wed, 05 Feb 2025 18:19:57 GMT</pubDate>
    </item>
    <item>
      <title>平滑的 AIC 选择</title>
      <link>https://stats.stackexchange.com/questions/661003/smooth-aic-selection</link>
      <description><![CDATA[假设我有一组针对相同数据的 $N$ 个模型，索引为 $n\in\{1,\dots,N\}$。
假设模型 $n\in\{1,\dots,N\}$ 具有以下对数似然：
$$L(X_n \theta_n),$$
其中 $L:\mathbb{R}^J\rightarrow \mathbb{R}$ 是某个已知函数，$X_n\in \mathbb{R}^{J\times K_n}$ 是解释变量矩阵，并且 $\theta_n\in\mathbb{R}^{K_n}$ 是模型的参数向量。
最后假设我已经通过最大似然估计了所有 $N$ 个模型，给出了估计值 $\hat{\theta}_1,\dots,\hat{\theta}_N$。
我现在想要进行模型选择。标准 AIC 方法是选择最大化的方法：
$$L(X_n\hat{\theta}_n)-K_n.$$
但假设我想平滑地选择，保持数据的连续性。
一种可能性是选择 $w_1,\dots,w_n\ge 0$ 来最大化：
$$L(w_1 X_1\hat{\theta}_1+\dots+w_N X_N\hat{\theta}_N)-w_1 K_1 -\dots-w_N K_N$$
受 $w_1+\dots+w_N=1$ 约束。 （至关重要的是，我没有重新估计$\hat{\theta}_1,\dots,\hat{\theta}_N$，从而降低了过度拟合的可能性。）
此过程在先前的文献中是否已被研究过？它有名字吗？我估计$w_1,\dots,w_N$是否会导致过度拟合？或者它最终会像人们希望的那样偏向更简单的模型。

旁白（？）：在我的确切情况下，也存在矩阵$A_1,\dots, A_{N-1}$，使得对于所有$n\in\{2,\dots,N\}$，$X_{n-1}=X_n A_{n-1}$，这意味着较低指标模型的通用性不如较高指标模型。但我不认为这从根本上简化了问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/661003/smooth-aic-selection</guid>
      <pubDate>Wed, 05 Feb 2025 16:57:04 GMT</pubDate>
    </item>
    <item>
      <title>对模拟数据重复 Anderson-Darling 检验（R） - 为什么 p 值不一致？</title>
      <link>https://stats.stackexchange.com/questions/661001/repeating-anderson-darling-test-on-simulated-data-r-why-are-p-values-not-uni</link>
      <description><![CDATA[我重复一个实验 k 次：从标准正态分布中生成 n 个值，然后对每个样本运行 AD 测试。然后，我绘制了所有 k 个实验的 p 值分布。令我惊讶的是，它并不均匀，而是在主体中出现了相当奇怪的尖峰。
set.seed(1)
mtx = matrix(rnorm(2e4 * 1e4), nrow=2e4) # n=2e4; k=1e4
ad_pval = apply(mtx, 2, \(x) nortest::ad.test(x)$p.value) # 需要几分钟！
hist(ad_pval, breaks = 50)


k 和 n 都很大。如果我使用不同的 k（例如 50k）和 n，则图像相同。
我期望 p 值具有均匀分布，因为这些是在正态性假设下生成的统计数据的某些理论 AD 分布的百分位数。
这似乎不是模拟错误。ad.test 函数不再需要其他参数。我遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/661001/repeating-anderson-darling-test-on-simulated-data-r-why-are-p-values-not-uni</guid>
      <pubDate>Wed, 05 Feb 2025 16:50:52 GMT</pubDate>
    </item>
    <item>
      <title>引导和选择调整</title>
      <link>https://stats.stackexchange.com/questions/660993/bootstrap-and-adjustment-for-selection</link>
      <description><![CDATA[假设我有许多平均值，$\{ \bar{X}^* \}_{i=1}^m$，每个平均值都是使用 $n$ 个观测值估算的。平均值是位置参数 $\{ \theta \}_{i=1}^m$ 的估计值。我对最大 $\theta$ 感兴趣，我可以使用 bootstrap 构建一个考虑选择的置信区间吗？
我可以想到几种可能的策略，估算所有 $\theta$ 的最大偏差。即，在 bootstrap 样本 $j$ 中获取最大偏差：
$$ B_j = \max_i (\bar{X}^j_i- \bar{X}_i^*), $$
或来自最大估计的偏差，
$$ B_j = \max_i (\bar{X}^j_i - \max_k \bar{X}_k^*). $$
第二个问题是，这是否可用于构建置信区间？任何参考资料都很好。
以下采用了类似的策略（用于子组识别和推断），他们声称即使子组数量无限，它也是可用的。 - Guo X, He X. Inference on selected subgroups in clinical trials.
他们使用了一种更复杂的方法，但本质上他们使用了偏差估计$ B_j = \max_i (\bar{X}^j_i - \max_k \bar{X}_k^*). $（参见论文中的算法 3）。]]></description>
      <guid>https://stats.stackexchange.com/questions/660993/bootstrap-and-adjustment-for-selection</guid>
      <pubDate>Wed, 05 Feb 2025 13:37:29 GMT</pubDate>
    </item>
    <item>
      <title>当 $y$ 已从 $x$ 计算出来时进行回归</title>
      <link>https://stats.stackexchange.com/questions/660990/regression-when-y-has-been-calculated-from-x</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/660990/regression-when-y-has-been-calculated-from-x</guid>
      <pubDate>Wed, 05 Feb 2025 12:43:17 GMT</pubDate>
    </item>
    <item>
      <title>Benjamini-Hochberg 校正跨子组进行多重检验：适用于所有层内还是跨所有层？</title>
      <link>https://stats.stackexchange.com/questions/660983/benjamini-hochberg-correction-for-multiple-testing-across-subgroups-apply-withi</link>
      <description><![CDATA[我正在研究一项研究中的单个基因（独立变量）与蛋白质组之间的关联，该研究涉及三个不同亚组（例如年轻人、中年人和老年人）的约 3,000 种蛋白质（因变量）。为了将错误发现率 (FDR) 控制在 5%，应如何应用 Benjamini-Hochberg 程序？
是否应在每个亚组中分别执行 FDR 校正（每组约 3,000 次假设检验）？
还是应将其应用于所有亚组（总共约 9,000 次假设检验）？
我希望能够解释这些方法背后的理论考虑，以及任何相关参考资料。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660983/benjamini-hochberg-correction-for-multiple-testing-across-subgroups-apply-withi</guid>
      <pubDate>Wed, 05 Feb 2025 10:10:17 GMT</pubDate>
    </item>
    </channel>
</rss>