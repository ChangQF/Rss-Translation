<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 06 Dec 2024 09:19:09 GMT</lastBuildDate>
    <item>
      <title>根据二元变量制定信用评级（最好使用 R 语言）</title>
      <link>https://stats.stackexchange.com/questions/658366/develop-credit-rating-based-on-binary-variable-in-r-preferably</link>
      <description><![CDATA[我在 R 中处理信用数据。我有一个贷款数据集，其中包含借款人和信用特定变量以及二元指标违约/不违约。第一步，我进行 logit 并获取违约概率 (PD)。接下来我想做什么：
根据这些 PD 建立类似信用评级模型的东西。例如，类别 1：PD&lt;0.2，类别 2：0.2
我认为基于 PD 和其他一些特征，我可以进行聚类分析，然后将这些聚类用作有序 logit 中的因变量或类似的东西。但我害怕相关性和其他东西。我也对证明最佳聚类数感到困惑。我该如何选择？如果您可以提供 R 代码思路就好了，但不一定]]></description>
      <guid>https://stats.stackexchange.com/questions/658366/develop-credit-rating-based-on-binary-variable-in-r-preferably</guid>
      <pubDate>Fri, 06 Dec 2024 08:49:39 GMT</pubDate>
    </item>
    <item>
      <title>分类因变量</title>
      <link>https://stats.stackexchange.com/questions/658365/categorical-dependent-variable</link>
      <description><![CDATA[我正在尝试构建机器学习模型，其中因变量是分类变量，并且有超过 60 个值。它们不是序数，也不遵循任何等级。
关于如何处理这个问题，有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658365/categorical-dependent-variable</guid>
      <pubDate>Fri, 06 Dec 2024 07:45:40 GMT</pubDate>
    </item>
    <item>
      <title>如何检验二分重复测量结果与连续调节变量之间的相互作用</title>
      <link>https://stats.stackexchange.com/questions/658364/how-to-test-for-interaction-between-dichotomous-repeated-measures-outcome-and-co</link>
      <description><![CDATA[在我的资料集中，参与者被问及在销售演示之前和之后是否计划购买（是/否）。预计人们在销售演示之后比之前更有可能回应购买意向（即“是”）。
但是，我们也有收入数据（连续变量），并希望测试收入是否与时间（销售演示之前与之后）相互作用以预测购买意向。
我们预计大多数人会在销售演示之前对购买意向回答“否”。但是，我们推测，在演示之后，收入较高的人更有可能将他们的意向改为“是”，而收入较低的人仍然会说“否”。
在这种情况下，哪种类型的测试合适？
我知道我可以将收入二分（例如中位数分割）并运行卡方检验，但如果可能的话，我希望保持收入连续。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658364/how-to-test-for-interaction-between-dichotomous-repeated-measures-outcome-and-co</guid>
      <pubDate>Fri, 06 Dec 2024 07:29:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么在用偏移量 = log(population) 计数的拟泊松 GLM 拟合之前对数据进行分组时会得到不同的标准误差？</title>
      <link>https://stats.stackexchange.com/questions/658361/why-do-i-get-different-standard-errors-when-i-group-the-data-before-fitting-a-qu</link>
      <description><![CDATA[在拟合拟泊松之前对数据进行分组在理论上是否正确，还是我应该不进行分组？
评论以及 R 代码示例发布如下。
我注意到，在拟合肿瘤计数的拟泊松 GLM 之前对数据进行分组时，我得到了不同的标准误差，偏移量 = log(Population)。如果我使用泊松系列而不是拟泊松系列，就不会发生这种情况，所以我很惊讶。
以下是 R 代码和示例数据，说明了我的问题：
## 创建分组和未分组数据集，其中按 Psych.Profile 和 Cig 分组时，肿瘤和人口的总和相同
## 分组数据
data_grouped &lt;- data.frame(Tumor = c(45,77,95,92,103,12,29,31,43,56,30,36,62,57,71)
,Pop = c(24795,32125,34706,23440,14133,11946,22781,14566,15654,10097,50711,35332,41707,26319,22978)
,Psych.Profile = factor(c(&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;), levels = c(&quot;C&quot;, &quot;B&quot;, &quot;A&quot;))
,Cig = c(0,0.5,1,1.5,2,0,0.5,1,1.5,2,0,0.5,1,1.5,2))

## 未分组数据。这个分组数据的第一行被分成 45 行，每行 1 个肿瘤，人口 = 24795/45 = 551
data_ungrouped &lt;- data.frame(Tumor = c(rep(1,45),77,95,92,103,12,29,31,43,56,30,36,62,57,71)
,Pop = c(rep(551,45),32125,34706,23440,14133,11946,22781,14566,15654,10097,50711,35332,41707,26319,22978)
,Psych.Profile = factor(c(rep(&#39;A&#39;,45),&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;,&#39;C&#39;), levels = c(&quot;C&quot;, &quot;B&quot;, &quot;A&quot;))
,Cig = c(rep(0,45),0.5,1,1.5,2,0,0.5,1,1.5,2,0,0.5,1,1.5,2))

## 将拟泊松模型拟合到每个数据集
model_grouped &lt;- glm(Tumor ~ Cig + Psych.Profile, family = quasipoisson((link = &quot;log&quot;)), offset = log(Pop), data = data_grouped)
model_ungrouped &lt;- glm(Tumor ~ Cig + Psych.Profile, family = quasipoisson((link = &quot;log&quot;)), offset = log(Pop), data = data_ungrouped)

&gt; coef(summary(model_grouped))
估计标准差。误差 t 值 Pr(&gt;|t|)
(截距) -7.3071846 0.09242152 -79.06367 1.649769e-16
Cig 0.7661623 0.05563362 13.77157 2.791780e-08
Psych.ProfileB 0.3887326 0.10225686 3.80153 2.935492e-03
Psych.ProfileA 0.7645370 0.08235288 9.28367 1.545673e-06

&gt; coef(summary(model_ungrouped))
估计标准差误差 t 值 Pr(&gt;|t|)
(截距) -7.3071846 0.04133216 -176.79175 1.814343e-77
Cig 0.7661623 0.02488011 30.79417 2.303794e-36
Psych.ProfileB 0.3887326 0.04573066 8.50048 1.343316e-11
Psych.ProfileA 0.7645370 0.03682933 20.75892 1.081513e-27

## 系数的标准误差下降。例如Cig 从 0.05563362 降至 0.02488011


对数据进行分组的一个动机是，我可以显著减少行数并更轻松地处理更大的数据集。]]></description>
      <guid>https://stats.stackexchange.com/questions/658361/why-do-i-get-different-standard-errors-when-i-group-the-data-before-fitting-a-qu</guid>
      <pubDate>Fri, 06 Dec 2024 04:01:11 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用 Nadaraya-Watson 估计量来估计随机过程的条件期望吗？</title>
      <link>https://stats.stackexchange.com/questions/658359/can-i-use-the-nadaraya-watson-estimator-to-estimate-conditional-expectation-of-s</link>
      <description><![CDATA[我想估计以下条件期望
$$
E\left[ Y(t,\beta) \mid X=x \right],
$$
其中$X$和$Y$是连续随机变量。
我想使用 Nadaraya–Watson 估计量来估计
$$
\hat{E}\left[ Y(t,\beta) \mid X=x \right]=\frac{\sum_{i=1}^nY_i(t,\beta)K_h(x-X_i)}{\sum_{i=1}^nK_h(x-X_i)}。
$$
这是真的吗？
在某些条件下它是否具有一致收敛性质？
$$
\sup_{t, \beta,x}\left|\hat{E}\left[ Y(t,\beta) \mid X=x \right]-E\left[ Y(t,\beta) \mid X=x \right]\right|\rightarrow 0 \quad a.s.
$$]]></description>
      <guid>https://stats.stackexchange.com/questions/658359/can-i-use-the-nadaraya-watson-estimator-to-estimate-conditional-expectation-of-s</guid>
      <pubDate>Fri, 06 Dec 2024 03:22:51 GMT</pubDate>
    </item>
    <item>
      <title>指定纵向分层广义加性模型 (HGAMM)</title>
      <link>https://stats.stackexchange.com/questions/658355/specify-longitudinal-hierarchical-generalized-additive-model-hgamm</link>
      <description><![CDATA[数据：两次会话（前、后）的主题测量值。每次测量在位置上都有 50 个相互关联的值。
示例：
subj_id | 会话 | 位置 | 值
1 前 1 0.1
1 前 2 0.12
..
1 前 50 0.08
2 前 1 0.04
..
30 后 50 0.12

兴趣：量化会话对值的影响，保持全局平滑常数。代表性数据的图，其中假设的效应位于位置 25 附近：

问题：我是否正确指定了模型，以便我可以汇总会话中的受试者方差？我能找到的最接近的例子是这个。Pedersen 等人的论文。 （2019）非常（非常）有帮助。
# 纵向模型，具有全局和会话平滑
fit_GSL &lt;- bam(
value ~ s(subj_id, session, bs = &quot;re&quot;) +
s(location, bs = &quot;tp&quot;, k=50) +
s(location, session, bs = &quot;fs&quot;, k = 50),
data = df_long,
family = betar(link = &quot;logit&quot;),
method = &quot;fREML&quot;,
discrete = T
)

这似乎有效，为我提供了全局和会话平滑，但我是否考虑了主题内发生的会话？


用于模拟数据和指定模型的脚本：
library(&quot;ggplot2&quot;)
library(&quot;fitdistrplus&quot;)
library(&quot;mgcv&quot;)
library(&quot;itsadug&quot;)

gen_norm &lt;- function(y_scale, n = 50, mean = 1, sd = 0.1) {
# 返回正态分布按 y_scale 缩放的值。
h_min &lt;- 平均值 - (2.5 * sd)
h_max &lt;- 平均值 + (2.5 * sd)
h_seq &lt;- seq(h_min, h_max, length = n)
set.seed(y_scale)
dist_out &lt;- y_scale * dnorm(h_seq, 平均值, sd) + rnorm(n, 0, (0.15 * y_scale))
return(dist_out)
}

# 计划主题和值的数量，缩放
# 会话不同
set.seed(12)
num_val &lt;- 50
num_subj &lt;- 60
subj_id &lt;- 100 + seq(1:num_subj)
scale_pre &lt;- runif(num_subj, 1, 3)
scale_post &lt;- runif(num_subj, 2, 5)

# 开始 df
df_long &lt;- as.data.frame(matrix(NA, nrow = 2 * num_subj * num_val, ncol = 4))
colnames(df_long) &lt;- c(&quot;subj_id&quot;, &quot;session&quot;, &quot;location&quot;, &quot;value&quot;)
df_long$subj_id &lt;- rep(rep(subj_id, each = num_val), each = 2)
df_long$session &lt;- rep(rep(c(&quot;Pre&quot;, &quot;Post&quot;), each = num_val), 2)
df_long$location &lt;- rep(seq(1, num_val), 2 * num_subj)

# 用生成的值填充 df，将值调整到预期范围
df_long &lt;- df_long[order(df_long$session, increasing = T), ]
c_start &lt;- 1
for (h_seed in c(scale_pre, scale_post)) {
c_end &lt;- c_start + num_val - 1
df_long[c_start:c_end, ]$value &lt;- gen_norm(h_seed)
c_start &lt;- c_end + 1
}
df_long$value &lt;- (df_long$value / 100) + 0.3

# 管理列类型
df_long$subj_id &lt;- factor(df_long$subj_id)
df_long$session &lt;- factor(df_long$session)

# 绘制数据
ggplot(data = df_long, aes(x = location, y = value, colour = session)) +
facet_wrap(~session) +
geom_point(size = 1, alpha = 0.3) +
theme(legend.position = &quot;none&quot;) +
labs(x = &quot;Location&quot;, y = &quot;Value&quot;) +
ggtitle(&quot;Simulated Group Tracts&quot;) +
theme(
text = element_text(family = &quot;Times New Roman&quot;)
)

# 纵向模型，具有全局和会话平滑
descdist(df_long$value, discreply = F)
fit_GSL &lt;- bam(
值 ~ s(subj_id, session, bs = &quot;re&quot;) +
s(location, bs = &quot;tp&quot;, k=50) +
s(location, session, bs = &quot;fs&quot;, k = 50),
数据 = df_long,
family = betar(link = &quot;logit&quot;),
方法 = &quot;fREML&quot;,
离散 = T
)
gam.check(fit_GSL)
plot(fit_GSL)
]]></description>
      <guid>https://stats.stackexchange.com/questions/658355/specify-longitudinal-hierarchical-generalized-additive-model-hgamm</guid>
      <pubDate>Fri, 06 Dec 2024 00:47:35 GMT</pubDate>
    </item>
    <item>
      <title>测试预测准确性 - 异常值 [附示例]</title>
      <link>https://stats.stackexchange.com/questions/658353/testing-forecasting-accuracy-outliers-with-example</link>
      <description><![CDATA[我有一个简单的模型，可以生成预测值。该模型适用于每小时数据。现在，我只对带有标记的观察结果感兴趣。我想确定预测值与实际值存在显著差异的地方。
我正在考虑以下两个指标——哪一个效果更好？ （请参阅下面代码中的选项 1 和选项 2）
或者我应该关注 RMSE、MAE 等？
# 示例数据：实际值和预测值
实际 &lt;- c(100, 110, 95, 120, 105, 130, 125)
预测 &lt;- c(102, 108, 97, 150, 103, 128, 123)

plot(actual, type = &quot;o&quot;, col = &quot;blue&quot;, pch = 16, lwd = 2,
ylim = range(c(actual, Forecasted)), ylab = &quot;Values&quot;,
xlab = &quot;Index&quot;, main = &quot;Actual vs Forecasted Values&lt;)
lines(forecasted, type = &quot;o&quot;, col = &quot;red&quot;, pch = 16, lwd = 2)

# 计算残差（实际值与预测值之间的差异）
residuals &lt;- actual - Forecasted

# 定义阈值：
# 选项 1：（例如，2 个标准差）
dynamic_threshold &lt;- 2 * sd(residuals)
dynamic_outliers &lt;- abs(residuals) &gt; dynamic_threshold

# 选项 2：（例如，基于实际数据的平均值和标准差的 2 个标准差）
upper_threshold &lt;- mean(actual)+2 * sd(actual)
lower_threshold &lt;- mean(actual)-2 * sd(actual)

outliers_forecasted &lt;- (forecasted &gt; upper_threshold) | (forecasted &lt; lower_threshold)
]]></description>
      <guid>https://stats.stackexchange.com/questions/658353/testing-forecasting-accuracy-outliers-with-example</guid>
      <pubDate>Thu, 05 Dec 2024 23:32:48 GMT</pubDate>
    </item>
    <item>
      <title>寻找适合在 SPSS 上运行的模型，同时考虑同一主题的多个测量值</title>
      <link>https://stats.stackexchange.com/questions/658351/looking-for-appropriate-model-to-run-on-spss-while-accounting-for-multiple-measu</link>
      <description><![CDATA[我有两组（A组和B组），它们具有不同的基线特征。所有受试者都经过5种不同的体重测试（每种两次），并测量结果变量。如果我的解释不清楚，下表概述了研究设计。



样本
组
0 磅
5 磅
10 磅
15 磅
20 磅




#1 试验 1
A







#1 试验2
A







#2 试验 1
A







#2 试验 2
A







#3 试验1
B







#3 试验 2
B







#4 试验 1
B







#4 试验2
B








我想知道：

5 个权重中结果变量的变化是否因组（A 或 B）而异？换句话说，是否存在交互作用？我还想知道组和权重的主要影响。

如何解释每个样本两次承受相同重量的事实。让每个受试者经历每种条件两次是增加样本量的一种方法，因为很难获得用于此类研究的样本。在输入数据时，我是否应该将它们作为单独的样本输入到 SPSS 中，或者由于它们是同一个样本，我是否需要以任何方式将它们关联起来？


我想这将是一个线性混合模型，但我不太清楚如何处理问题 2。
提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658351/looking-for-appropriate-model-to-run-on-spss-while-accounting-for-multiple-measu</guid>
      <pubDate>Thu, 05 Dec 2024 22:22:25 GMT</pubDate>
    </item>
    <item>
      <title>卡方独立性检验</title>
      <link>https://stats.stackexchange.com/questions/658350/chi-squared-test-of-independence</link>
      <description><![CDATA[考虑一个包含泊松分布的观察计数的列联表。具体来说，$O_{ij}$ 是 $Poi(\lambda_{ij})$。如果我们应用 CLT 假设 $\lambda$ 很大，那么我们得到 $\frac{O_{ij}-\lambda_{ij}}{\sqrt{\lambda_{ij}}}$ 近似为标准正态分布。
现在，在进行独立性卡方检验时，我们在构建检验统计量时使用 $\lambda_{ij}$ 的近似值，该近似值是在独立性假设下从样本中得出的，即 $E_{ij}$。但是，为什么用估计的平均值替换实际平均值仍然有效呢？此外，当我增加总观测值$(N)$和增加$\lambda_{ij}$的值时，这个检验统计量是否会变得更好？
请随时纠正我提到的任何内容。我一直在自学这些东西，所以我还没有完全理解。]]></description>
      <guid>https://stats.stackexchange.com/questions/658350/chi-squared-test-of-independence</guid>
      <pubDate>Thu, 05 Dec 2024 21:54:30 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 匹配对符号秩和相关性（Pearson、Spearman）</title>
      <link>https://stats.stackexchange.com/questions/658344/wilcoxon-matched-pair-signed-rank-and-correlation-pearson-spearman</link>
      <description><![CDATA[根据出版物《提取重复测量设计的荟萃分析的前后相关性》[https://matthewbjane.quarto.pub/pre-post-correlations/][1]，如果配对 t 检验的 t 统计量值可用，则可以计算相关样本中前后得分之间的皮尔逊相关性。
pre_mean &lt;- 12.62
pre_sd &lt;- 3.845
post_mean &lt;- 18.33
post_sd &lt;- 5.155
paired_t &lt;- 10.52
n &lt;- 78

r &lt;- (paired_t^2*(sd_pre^2 + sd_post^2)-n*(post_mean-pre_mean)^2) / 
(2*paired_t^2*sd_pre*sd_post)

r

还提到，可以根据配对 t 检验的 p 值计算 Pearson 相关性。
pre_mean &lt;- 12.62
pre_sd &lt;- 3.845
post_mean &lt;- 18.33
post_sd &lt;- 5.155
pval &lt;- 1.5e-16 # 来自配对 t 检验
n &lt;- 78

# 从 p 值获取配对 t
paired_t &lt;- qt(pval/2, n-1, lower.tail = FALSE)

r &lt;- (paired_t^2*(sd_pre^2 + sd_post^2)-n*(post_mean-pre_mean)^2) /
(2*paired_t^2*sd_pre*sd_post)

我在网站 https://stats.stackexchange.com/questions/658191/extraction-pre-post-correlation-of-repeated-measures-design?noredirect=1#comment1237216_658191 上找到了类似的问题，但我找不到我想要的答案。
我的问题是：这些公式可以扩展到 Wilcoxon 符号秩检验 及其对应的 p 值吗？我的意思是，如果我们在运行 Wilcoxon 符号秩检验后知道 p 值（甚至可以访问 W 统计量），我们可以计算相关性（Spearman 或 Pearson）吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658344/wilcoxon-matched-pair-signed-rank-and-correlation-pearson-spearman</guid>
      <pubDate>Thu, 05 Dec 2024 19:25:03 GMT</pubDate>
    </item>
    <item>
      <title>将拟泊松模型与泊松模型进行比较是否有意义？</title>
      <link>https://stats.stackexchange.com/questions/658335/does-this-comparison-of-the-quasipoisson-model-to-the-poisson-model-make-sense</link>
      <description><![CDATA[我正在尝试使用拟似然法，所以这是我的第一次尝试。我想我误解了一个关键部分，因为我确实理解为什么参数估计是相同的（因为它们都最大化了相同的对数似然函数）并且由于过度分散，标准误差是不同的，但是为什么偏差相同？
当我的教授看到我的代码时，他说你不能真正比较它们，因为它们不是“嵌套的”，但他也说要查看残差平方和。
代码如下：
&gt; library(ggplot2)
&gt; set.seed(42)
&gt; 
&gt; n &lt;- 100
&gt; x &lt;- runif(n, 0, 10)
&gt; beta_0 &lt;- 1.0
&gt; beta_1 &lt;- 0.5
&gt; mu &lt;- exp(beta_0 + beta_1 * x)
&gt; phi &lt;- 2
&gt; y_overdispersed &lt;- rnbinom(n, size = phi, mu = mu)
&gt; 数据 &lt;- data.frame(x = x, y = y_overdispersed)
&gt; 
&gt; model_quasi &lt;- glm(y ~ x, family = quasipoisson(link = &quot;log&quot;), 
data = data)
&gt; 数据$pred_quasi &lt;- predict(model_quasi, type = &quot;response&quot;)
&gt; 
&gt; model_poisson &lt;- glm(y ~ x, family = poisson(link = &quot;log&quot;), 
data = data)
&gt; data$pred_poisson &lt;- predict(model_poisson, type = &quot;response&quot;)
&gt; 
&gt; cat(&quot;准泊松模型摘要:\n&quot;)
准泊松模型摘要：
&gt; summary(model_quasi)

调用：
glm(formula = y ~ x, family = quasipoisson(link = &quot;log&quot;), 
data = data)

系数：
估计标准误差 t 值 Pr(&gt;|t|) 
(截距) 0.81145 0.30410 2.668 0.00892 ** 
x 0.50345 0.03593 14.012 &lt; 2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

（准泊松系列的分散参数取为 29.85742）

零偏差：99 个自由度上的 12464.7
残差偏差：98 个自由度上的 2696.6
AIC：NA

Fisher 评分迭代次数：5

&gt; 
&gt; cat(&quot;\n常规泊松模型摘要:\n&quot;)

常规泊松模型摘要：
&gt; summary(model_poisson)

调用：
glm(formula = y ~ x, family = poisson(link = &quot;log&quot;), data = data)

系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 0.811453 0.055653 14.58 &lt;2e-16 ***
x 0.503446 0.006575 76.56 &lt;2e-16 ***
---
有效代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(泊松族的分散参数取为 1)

零偏差：99 个自由度上的 12464.7
残差偏差：98 个自由度上的 2696.6
AIC：3203.9

Fisher 评分迭代次数：5
]]></description>
      <guid>https://stats.stackexchange.com/questions/658335/does-this-comparison-of-the-quasipoisson-model-to-the-poisson-model-make-sense</guid>
      <pubDate>Thu, 05 Dec 2024 17:46:41 GMT</pubDate>
    </item>
    <item>
      <title>零膨胀模型，值较低但没有零？</title>
      <link>https://stats.stackexchange.com/questions/658326/zero-inflated-model-with-low-values-but-no-zeros</link>
      <description><![CDATA[我是建模新手，这个问题可能很荒谬，但我正尝试仅使用阳性个体来模拟具有物种*生命阶段相互作用效应的病原体负荷计数数据。
即，那些具有零负荷（感染为阴性）的个体被从分析中删除，并且仅对负荷&gt; 0的阳性个体进行分析）
我已经在使用负二项式 GLM 模型（glmmTMB 包），因为有很多低计数，但是当我使用 DHarma 时，我发现仍然有零膨胀（尽管子集数据中没有零）

是否有可能对没有零的数据使用零膨胀模型？
我还能如何解决这个问题？
任何帮助都值得赞赏！]]></description>
      <guid>https://stats.stackexchange.com/questions/658326/zero-inflated-model-with-low-values-but-no-zeros</guid>
      <pubDate>Thu, 05 Dec 2024 14:15:54 GMT</pubDate>
    </item>
    <item>
      <title>从相反方向的回归方程进行预测[重复]</title>
      <link>https://stats.stackexchange.com/questions/658323/prediction-from-regression-equation-in-opposite-direction</link>
      <description><![CDATA[假设我有以下简单的线性回归
$y = \alpha + \beta X + \epsilon$
这里$X$是有序分类变量，假设类别用 1 到 12 表示。
现在在典型的回归方程中，我们根据$X$预测$y$的值如下
$\hat{y} = \hat{\alpha} + \hat{\beta}X$
但是这里我的问题不同，给定$y$的值，我想预测$X$。
为此，我认为我需要为 $X$ 的每个类别构建可能的 $y$ 值的连续且不重叠的区间，即 $y$ 将有 10 个重叠区间，例如
如果 $y_{Val}$ 落在 $ \left( -\inf, y_1 \right]$ 内，那么我会预测 $X = 1$ 的值
如果 $y_{Val}$ 落在 $ \left( y_1, y_2 \right]$ 然后我会预测 $X = 2$ 的值，依此类推
我的目标是最好地估计 $y_1, y_2, ..,y_9$ 的值。
我的数据如下所示
]]></description>
      <guid>https://stats.stackexchange.com/questions/658323/prediction-from-regression-equation-in-opposite-direction</guid>
      <pubDate>Thu, 05 Dec 2024 13:16:05 GMT</pubDate>
    </item>
    <item>
      <title>数据符合除正态性之外的所有线性假设。我的下一步应该怎么做？</title>
      <link>https://stats.stackexchange.com/questions/658300/data-passing-all-linearity-assumptions-except-normality-what-should-my-next-ste</link>
      <description><![CDATA[我需要为一系列具有相同问题的数据集构建模型。
编辑：下图显示了我的一个数据集的示例，其中拟合了一条线性回归线。它是体积 (y) 与日期时间 (x)，目标是确定 1. 体积是否随时间发生显着变化，以及 2.（不如 1 重要但仍然重要）如果有，则预测未来的体积可能是多少。

“目测”让我相信数据最适合线性回归。我的数据似乎通过了同质性假设 (leveneTest pval &gt; 0.05) 和线性假设 (需要对独立性进行更多研究)。 没有点的 Cook 距离 &gt; 0.5，表明没有高度有影响力的异常值。 但是，我的线性图表未通过正态性检验。
对于 shapiro.test(residuals(model)) 检查，P-val 为 &lt; 0.05。
qq 图的尾部下降：

我试过平方根 &amp; y 的 Box-Cox 变换，以及更稳健的建模，如 rlm 和 glm（针对转换和未转换的数据），但这些都产生了类似的结果。
我承认，通常没有办法转换数据以使其正常化。
我所有的问题都围绕着同一个主题：我接下来该怎么做才能对这些数据进行建模？
我还能合理地使用线性回归来对这些数据进行建模吗？
由于我的大多数数据集都超过 500 分，我可以合理地声称 C.L.T 吗？
我可以使用其他建模方法吗？或者我完全错过了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/658300/data-passing-all-linearity-assumptions-except-normality-what-should-my-next-ste</guid>
      <pubDate>Thu, 05 Dec 2024 06:29:11 GMT</pubDate>
    </item>
    <item>
      <title>单调变换保留概率直觉</title>
      <link>https://stats.stackexchange.com/questions/658283/monotonic-transformation-preserving-probabilities-intuition</link>
      <description><![CDATA[我正在努力对为什么单调变换在连续情况下保留相对概率形成深刻的直觉。虽然我从表面上理解这个想法，特别是对于离散情况（在这种情况下更容易用计数来思考），但当我试图将其扩展到连续分布时，我失去了直觉。
我认为到目前为止我理解了以下内容：

单调变换$f(x)$（例如，$f(x) = x^2$ on $x \geq 0$）保留了结果的顺序。如果$x_1 &lt; x_2$，则$f(x_1) &lt; f(x_2)$。
在离散情况下，这种顺序保持与映射的一对一性质相结合，帮助我理解了为什么相对概率不会改变——即使值被转换，计数仍然保持成比例。
在连续情况下，概率密度函数 (PDF) 根据变换的导数而变化：
$$p_Y(y) = p_X(f^{-1}(y)) \cdot \left| \frac{d}{dy} f^{-1}(y) \right|,$$
其中 $f^{-1}(y)$ 是 $f(x)$ 的倒数。但是我很难将此公式与直观/视觉理解联系起来，以了解为什么区间内的相对概率保持不变。

我遇到的问题：

对于像$f(x) = x^2$这样的变换，它会非均匀地拉伸输入空间（例如，$1 \to 1, 2 \to 4, 10 \to 100$），感觉较大的值可能会不成比例地主导概率。例如，区间 $[10, 11]$ 映射到 $[100, 121]$，这比 $[1, 2] \to [1, 4]$ 大得多。
我的直觉失败了，因为我很难理解如何通过导数 $\frac{1}{f&#39;(x)}$ (或 $\frac{1}{2\sqrt{y}}$ for $f(x) = x^2$) 进行调整来“平衡”这种拉伸效应。在离散情况下，我可以想象一对一映射就像简单的重新标记一样，其中相对计数保持不变。但对于连续情况，我无法找到相同的满足感。

我想了解：

变量变化公式如何确保相对概率（例如，$P(Y \in [a, b]) / P(Y \in [c, d])$）在单调变换下得以保留？除了信任公式之外，还有其他方法可以建立直觉吗？
我应该如何从几何角度思考这种转变？将概率视为“密度质量”有帮助吗？重新分配，如果是这样，为什么这种重新分配不会扭曲相对大小？
是否有具体示例或可视化可以帮助弥补我的直觉差距，特别是对于连续分布？

感谢您的任何见解！
更新
正如 Whuber 善意指出的那样，我最初的假设/问题是错误的，这也许就是它让我感到困惑的原因。我在下面附上了一个参考资料，我显然误解了它以得出这个结论。仍然非常感谢你的想法。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658283/monotonic-transformation-preserving-probabilities-intuition</guid>
      <pubDate>Wed, 04 Dec 2024 21:19:40 GMT</pubDate>
    </item>
    </channel>
</rss>