<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 03 Jan 2025 18:22:31 GMT</lastBuildDate>
    <item>
      <title>计数数据建模</title>
      <link>https://stats.stackexchange.com/questions/659501/modeling-count-data</link>
      <description><![CDATA[在对计数数据进行建模时，我脑海中出现了一些问题，希望能得到一些指导。

泊松模型在研究中被广泛用于对计数数据进行建模，但是当存在过度分散时，会改用其他模型（例如 NB、拟泊松）。如果不存在过度分散且变化与预期值相同，您是否默认使用泊松回归模型，还是仍可以根据 gof 进行选择？

处理零膨胀数据时需要零膨胀模型和 Hurdle 模型，或者考虑到研究使用截断泊松或 NB 模型似乎更合适。但是，如果数据中不存在 0 计数，而是存在 1 的潜在膨胀，如何处理？这是否与零膨胀类似，还是事件未在大量观察中发生（零膨胀）的情况是进行调整的具体原因？（也就是说，在建模计数方面，没有零的数据集中的一次膨胀与零膨胀数据集有何不同？）

]]></description>
      <guid>https://stats.stackexchange.com/questions/659501/modeling-count-data</guid>
      <pubDate>Fri, 03 Jan 2025 18:21:03 GMT</pubDate>
    </item>
    <item>
      <title>glmmTMB 估计含义</title>
      <link>https://stats.stackexchange.com/questions/659499/glmmtmb-estimate-meanings</link>
      <description><![CDATA[我创建了一个广义线性混合模型，以查看疏伐对连通性的影响是否显著。我有 Period == Pre（疏伐前）和 Period == Post（疏伐后）和 Treatment == 疏伐（该地点已疏伐）和 Treatment == Control（该地点未疏伐）。基本上，这意味着我们有一个收获前时期，我们在此查看基线值，然后在发生疏伐之后的收获后值中，我想知道疏伐有什么影响。我使用子流域的随机效应来解释子流域之间的差异。我还进行了 emmeans 和成对比较，我发现在收获前后时期，对照处理有显著增加，但疏伐处理没有。这是否意味着稀疏化对连通性产生了负面影响？
以下是模型：
 Connectivity_Duration ~ Treatment * Period + (1 | Subwatershed),
family = Gamma(link = &quot;log&quot;), # Gamma
data = Connectivity_occurrences_no2018
) ```
以下是结果：

Family：Gamma ( log )
公式：Connectivity_Duration ~ Treatment * Period + (1 | Subwatershed)
数据：Connectivity_occurrences_no2018

AIC BIC logLik 偏差 df.resid 
433.7 448.1 -210.8 421.7 76 

随机效应：

条件模型：
组名称方差标准差
子流域（截距）0.3853 0.6207

观测数：82，组：子流域，4

Gamma 系列的扩散估计值（sigma^2）：2.82

条件模型：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 3.5167 0.6986 5.034 4.81e-07 ***
TreatmentThinned -1.9785 0.9162 -2.160 0.03081 * 
PeriodPre -3.3751 0.6187 -5.455 4.89e-08 ***
TreatmentThinned:PeriodPre 3.0700 1.0089 3.043 0.00234 ** 
---
Signif。代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1```

```# 获取相互作用的估计边际均值
em &lt;- emmeans(glmmTMB_model_gamma, ~ Treatment * Period)

# 对治疗前后的变薄组进行成对比较
contrast(em, method = &quot;pairwise&quot;, by = &quot;Treatment&quot;)
Treatment = Control:
对比估计 SE df z.ratio p.value
Post - Pre 3.375 0.619 Inf 5.455 &lt;.0001

Treatment = Thinned:
对比估计 SE df z.ratio p.value
Post - Pre 0.305 0.797 Inf 0.383 0.7018

Treatment Period emmean SE df asymp.LCL asymp.UCL
控制后 3.517 0.699 信息 2.147 4.89
稀疏后 1.538 0.593 信息 0.376 2.70
控制前 0.142 0.818 信息 -1.462 1.75
稀疏前 1.233 0.774 信息 -0.284 2.75```

]]></description>
      <guid>https://stats.stackexchange.com/questions/659499/glmmtmb-estimate-meanings</guid>
      <pubDate>Fri, 03 Jan 2025 17:56:27 GMT</pubDate>
    </item>
    <item>
      <title>多状态模型：r Surv 函数</title>
      <link>https://stats.stackexchange.com/questions/659497/multi-state-models-r-surv-function</link>
      <description><![CDATA[我想在一个有 3 个阶段的模型中评估 Aalen-Johansen 估计量，该模型名为 1、2 和 3。可能的转换是 1-2、1-3、2-1 和 2-3。每个受试者都从第 1 阶段开始。
我的问题是，使用函数 Surv 然后使用 survfit，r 输出会创建一个初始状态 (s0)。许多受试者的轨迹是 1（初始阶段）-2-1-3。这意味着我丢失了这些信息，因为 r 认为轨迹是 (s0)-2-1-3。
我如何设置 (s0) = 1？我查看了文档，但没有找到如何设置。]]></description>
      <guid>https://stats.stackexchange.com/questions/659497/multi-state-models-r-surv-function</guid>
      <pubDate>Fri, 03 Jan 2025 17:47:25 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中的 Cox 比例风险模型中提取控制臂的方差？</title>
      <link>https://stats.stackexchange.com/questions/659495/how-to-extract-the-variance-for-the-control-arm-in-a-cox-proportional-hazards-mo</link>
      <description><![CDATA[我正在使用 R 中的 coxph() 拟合 Cox 比例风险模型，该模型包含一个因子变量 treat，其中包括多个治疗组。具体来说，treatarm_1 是控制（参考）组，我还有其他治疗组：treatarm_2、treatarm_3 和 treatarm_4。
模型摘要提供了治疗组（treatarm_2、treatarm_3、treatarm_4）的系数、标准误差和方差，但我找不到对照组（treatarm_1）的方差，该组作为参考类别。
我理解对照组没有自己的系数，因为它隐式地表示在截距中。但是，我需要计算或提取对照组的方差，因为 BUGSnet 包（我用于网络荟萃分析）的文档指定我需要在多组试验中输入对照组的方差。
有人能解释一下我如何获得对照组的方差（如果可能的话），还是我假设它的方差为零？如果有其他方法，我将不胜感激任何建议！
提前谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659495/how-to-extract-the-variance-for-the-control-arm-in-a-cox-proportional-hazards-mo</guid>
      <pubDate>Fri, 03 Jan 2025 16:37:02 GMT</pubDate>
    </item>
    <item>
      <title>Seber 和 Lee 的贝叶斯线性回归</title>
      <link>https://stats.stackexchange.com/questions/659492/bayesian-linear-regression-in-seber-and-lee</link>
      <description><![CDATA[我正在阅读 Seber 和 Lee 的《线性回归分析》（定理 3.7），贝叶斯线性回归中有些东西我不太理解。我们有以下模型：
$$\mathbf{Y} = \mathbf{X} \beta + \epsilon$$
其中 $\epsilon \sim \mathcal{N}(0, \sigma^2 I)$。
$\sigma^2$ 的先验为 $\text{Inverse Gamma} \left(\frac{d+2}{2}, \frac{a}{2}\right)$。给定 $\sigma^2$，$\beta$ 的先验为 $\mathcal{N}(\mathbf{m}, \sigma^2 \mathbf{V})$。然后后验与以下项成比例：
$$\left(\sigma^2\right)^{-(n + d + p + 2)/2} \exp\left(-\frac{1}{2\sigma^2} \left[ (\mathbf{y} - \mathbf{X} \beta)^\top (\mathbf{y} - \mathbf{X} \beta) + (\beta - \mathbf{m})^\top \mathbf{V}^{-1} (\beta - \mathbf{m}) + a \right] \right) =$$
$$\left(\sigma^2\right)^{-(n + d + p + 2)/2} \exp\left(-\frac{(Q+a)}{2\sigma^2} \right).$$
我们可以使用伽马积分对$\sigma^2$进行积分，这给出了$\beta$的后验，与$(Q+a)^{-(d+n+p)/2}$成比例。
通过一些代数运算，$Q$可以重写为
$$(\beta - \mathbf{m}^*)^\top \mathbf{V}_*^{-1} (\beta - \mathbf{m}^*)+\mathbf{y}^\top \mathbf{y} + \mathbf{m}^\top \mathbf{V}^{-1} \mathbf{m} - (\mathbf{m}^*)^\top \mathbf{V}_*^{-1} \mathbf{m}^*$$
最后：
$$(\beta - \mathbf{m}^*)^\top \mathbf{V}_*^{-1} (\beta - \mathbf{m}^*)+(\mathbf{y} - \mathbf{X}\mathbf{m})^\top (\mathbf{I} + \mathbf{X} \mathbf{V} \mathbf{X}^\top)^{-1} (\mathbf{y} - \mathbf{X}\mathbf{m}),$$
其中 $\mathbf{V}_* = (\mathbf{X}^T \mathbf{X} + \mathbf{V}^{-1})^{-1}$ 且 $\mathbf{m}^* = \mathbf{V}_* (\mathbf{X}^T\mathbf{y} + \mathbf{V}^{-1}\mathbf{m})$。
我的问题是，重写的目的是什么$\mathbf{y}^\top \mathbf{y} + \mathbf{m}^\top \mathbf{V}^{-1} \mathbf{m} - (\mathbf{m}^*)^\top \mathbf{V}_*^{-1} \mathbf{m}^*$ 等于 $(\mathbf{y} - \mathbf{X}\mathbf{m})^\top (\mathbf{I} + \mathbf{X} \mathbf{V} \mathbf{X}^\top)^{-1} (\mathbf{y} - \mathbf{X}\mathbf{m})$？我们能得到什么好处？我认为这与解释有关？]]></description>
      <guid>https://stats.stackexchange.com/questions/659492/bayesian-linear-regression-in-seber-and-lee</guid>
      <pubDate>Fri, 03 Jan 2025 14:42:23 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么程序/函数来运行卷积神经网络，以根据生成模拟运动数据的参数来训练模拟运动数据</title>
      <link>https://stats.stackexchange.com/questions/659491/what-program-function-should-i-use-to-run-a-convolutional-nn-to-train-simulated</link>
      <description><![CDATA[我被文献淹没了，我看到的每个使用 Pytorch 或 TensorFlow 的示例问题都与我的不同。我在网格上有 N 个数据模拟 - 它们是纬度和经度的矩阵。数据本身是连续的，但我将它们分成网格上的方块。它们是由具有 M 个参数的运动模型生成的。我想根据相应的模拟数据集训练模拟每个数据集的参数。
如果 A_i 是矩阵，行作为纬度，列作为经度，值作为该网格方块内的出现次数，而 P_i 是保存生成每个 A_i 的参数的向量，我该如何以编程方式运行 CNN？目标是能够预测生成给定测试集的参数。
提前谢谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/659491/what-program-function-should-i-use-to-run-a-convolutional-nn-to-train-simulated</guid>
      <pubDate>Fri, 03 Jan 2025 14:38:27 GMT</pubDate>
    </item>
    <item>
      <title>BAM mgcv 算法的可重复性</title>
      <link>https://stats.stackexchange.com/questions/659490/reproducibility-of-bam-mgcv-algorithm</link>
      <description><![CDATA[我经常处理大型空间数据集，其中 mgcv 中实现的 bam() 算法非常适合。对于我的分析来说，点估计的可重复性是一个关键问题，不幸的是，我经常看到 BAM 预测的结果取决于所用数据集中数据点的顺序。
最小可重复示例
以下内容基于由协变量 x、y 和目标变量 z 组成的 15.000 个数据点的数据集，可在此处下载：https://drive.google.com/file/d/16dZ66KmT4CrQHkVQtw7vRP065SoztUNg/view?usp=drive_link
另请注意，在执行每个代码示例之前下面，数据集已重新加载并使用相同的随机种子进行了混洗。
首先考虑使用 bam() 拟合的结果：
set.seed(1)

model1 &lt;- mgcv::bam(z ~ s(x, y, k = 100),
data = dataset,
family = Gamma(link = log),
method = &quot;REML&quot;)

dataset &lt;- dataset[sample(nrow(dataset)),]

model2 &lt;- mgcv::bam(z ~ s(x, y, k = 100),
data = dataset,
family = Gamma(link = log),
method = &quot;REML&quot;)

#calculate response on scale of linear predictor
dataset$pred_model1 &lt;- as.vector(predict.gam(model1, dataset))
dataset$pred_model2 &lt;- as.vector(predict.gam(model2, dataset))
plot(dataset$pred_model1, dataset$pred_model2)

这将生成以下图表：

现在考虑 gam() 的结果：
model1 &lt;- mgcv::gam(z ~ s(x, y, k = 100),
data = dataset,
family = Gamma(link = log),
method = &quot;REML&quot;)

数据集 &lt;- 数据集[sample(nrow(数据集)),]

模型2 &lt;- mgcv::gam(z ~ s(x, y, k = 100),
数据 = 数据集,
family = Gamma(link = log),
method = &quot;REML&quot;)

#计算线性预测器尺度上的响应
数据集$pred_model1 &lt;- as.vector(predict.gam(model1, dataset))
数据集$pred_model2 &lt;- as.vector(predict.gam(model2, dataset))

plot(数据集$pred_model1, dataset$pred_model2)


这将生成以下图表：

所以我的问题是：这种行为是预料之中的，还是我这边的一个错误？如果这只是使用 bam() 时必须忍受的事情，那么除了始终确保数据点的顺序相同之外，还能做些什么来确保可重复性？
我已经通过尝试 k=1000 个基函数来测试它是否与有限的空间分辨率有关。在这里我发现了同样的问题。然而，我确实看到将数据集大小减少到只有 1000 个数据点可以大大减少问题。然而，这不是理想的解决方案，因为我想使用所有数据。]]></description>
      <guid>https://stats.stackexchange.com/questions/659490/reproducibility-of-bam-mgcv-algorithm</guid>
      <pubDate>Fri, 03 Jan 2025 13:43:22 GMT</pubDate>
    </item>
    <item>
      <title>固定尺度参数的拉普拉斯分布的位置参数的UMVUE是多少？它是样本的中位数吗？</title>
      <link>https://stats.stackexchange.com/questions/659489/what-is-the-umvue-of-the-location-parameter-of-the-laplace-distribution-with-sca</link>
      <description><![CDATA[我正在尝试推导具有固定尺度参数的拉普拉斯分布的位置参数的 UMVUE。它是中位数吗？我一直在尝试应用莱曼-谢夫定理，但我对我的证明没有信心。样本的中位数是无偏且充分的，但我还需要证明它是完整的，以便应用莱曼-谢夫。]]></description>
      <guid>https://stats.stackexchange.com/questions/659489/what-is-the-umvue-of-the-location-parameter-of-the-laplace-distribution-with-sca</guid>
      <pubDate>Fri, 03 Jan 2025 13:43:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么均匀分布产生的“白噪声”有时会具有自相关性？</title>
      <link>https://stats.stackexchange.com/questions/659486/why-is-white-noise-generated-from-uniform-distribution-sometimes-autocorrelate</link>
      <description><![CDATA[我试图理解不同时间序列模型的属性。要成为白噪声，$w_t$ 必须满足三个条件：

$E(w_t) = 0$，
$Var(w_t) = \sigma^2$，并且
$cov(w_t, w_s) = 0$，但它不必是正态分布的。如果是，它就称为高斯噪声。

在实践中，大多数情况下使用正态分布来模拟白噪声（至少从我在 R 或 python 中的不同实现中观察到的情况来看）。我开始想知道我是否可以使用任何其他具有零均值的分布，然后执行以下操作：
library(forecast)
set.seed(7)
white_noise2 = runif(200, min = -1, max = 1) # R 中均匀分布的随机样本
tsdisplay(white_noise2, plot.type = &quot;histogram&quot;, points = FALSE)


Box.test(white_noise2, lag = 10, type = &quot;Ljung-Box&quot;) # H0：对于某些 j，p_x(j) != 0，不是 p_x(10) != 0
# 极小的 p 值 =&gt; 测试认为一定存在一些自相关 

问题

我认为这是偶然的，有时甚至对于真实的 i.i.d. 变量，我们也可以抽取具有高自相关的样本 - 这与分布的选择无关。我说得对吗？
什么样本量足以假设存在真正的自相关？我有一个粗略的想法，我应该根据检验统计量的分布（在 Ljung-Box 检验中，在滞后 h 之前缺乏自相关）知道这一点。在零假设下，即 ($H_0: \forall_{j \in \{1, ... h\}} \quad \rho_x(j) = 0$)，检验统计量 $Q = n \sum \hat \rho^2_x(j) \sim \chi^2(h)$，其中 $h$ 是我们测试的最大滞后数，我不知道下一步该怎么做。
]]></description>
      <guid>https://stats.stackexchange.com/questions/659486/why-is-white-noise-generated-from-uniform-distribution-sometimes-autocorrelate</guid>
      <pubDate>Fri, 03 Jan 2025 12:35:42 GMT</pubDate>
    </item>
    <item>
      <title>以家庭为分析单位的二元逻辑数据准备</title>
      <link>https://stats.stackexchange.com/questions/659482/data-preparation-for-binary-logistic-with-households-as-a-unit-of-analysis</link>
      <description><![CDATA[我试图对不同的因素进行二元逻辑分析，以确定哪些因素影响了研究现象。这些数据针对的是特定年龄以上的人群。这意味着不同家庭的人数各不相同。我被告知分析单位应该是家庭，这意味着 Excel 电子表格中的每一行都应该代表一个家庭，最初它代表一个人，如下所示：
实践区域年龄性别教育就业
否城市 31-50 女性中学就业
否城市 31-50 女性高等教育就业
是城市 31-50 女性高等教育就业

假设上述数据（3 人）都在一个家庭中，我如何在 Excel 电子表格中准备以家庭为分析单位的相同数据？因变量是实践。]]></description>
      <guid>https://stats.stackexchange.com/questions/659482/data-preparation-for-binary-logistic-with-households-as-a-unit-of-analysis</guid>
      <pubDate>Fri, 03 Jan 2025 09:49:13 GMT</pubDate>
    </item>
    <item>
      <title>如何估计两个坐标系之间的旋转和平移？</title>
      <link>https://stats.stackexchange.com/questions/659476/how-can-i-estimate-the-rotation-and-translation-between-two-cooordinate-frames</link>
      <description><![CDATA[我在两个坐标系（xyz 和 XYZ）中测量了 N 个点 p 的 3D 尺寸：
$$
p_i: \mathbf{x_i}, \mathbf{X_i} 
$$
坐标系相互旋转和平移：
$$
\mathbf{X_i} = T\mathbf{x_i} + \mathbf{\epsilon_i} 
$$
其中
$$
\mathbf{X_i} = 
\begin{bmatrix}X_i\\Y_i\\Z_i\\1\end{bmatrix}
$$
$$
\mathbf{x_i} = 
\begin{bmatrix}x_i\\y_i\\z_i\\1\end{bmatrix}
$$
和
$$
T=\begin{bmatrix}
R_{11} &amp; R_{12} &amp; R_{13} &amp; t_x \\ 
R_{21} &amp; R_{22} &amp; R_{23} &amp; t_y \\
R_{31} &amp; R_{32} &amp; R_{33} &amp; t_z \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
$$
其中 $R_{ij}$ 是 (正交) 3x3 旋转矩阵的元素，$\mathbf{t}=[t_x,t_y,t_z]^T$ 是平移向量，$\mathbf{\epsilon_i} \sim N(0, \sigma)$ 是随机测量误差 (噪声)。
这是多元线性回归的一个例子，
请注意：
$$
\mathbf{X}\mathbf{x^T}=T\mathbf{x}\mathbf{x^T}
$$
$$
T=\mathbf{X}\mathbf{x^T}(\mathbf{x}\mathbf{x^T})^{-1}
$$
在存在噪声的情况下，当$N&gt;4$时，上述表达式是给定$\mathbf{x_i}$和$\mathbf{X_i}$测量值的T的最小二乘估计。
但是有一个问题；
解决方案的准确性似乎取决于我用于位置的单位。
如果我使用[hm]（100 m）作为单位，准确性似乎很差。
如果我使用 [m]，精度似乎还不错，如果我使用 [mm]，精度似乎非常好：
*** Fasit ***
tx：1.000000，ty：2.000000，tz：3.000000
alpha：10.000000，beta：20.000000，gamma：30.000000

*** 单位：[hm] ***
条件编号：232324.8662558334
tx：0.599922，ty：1.755050，tz：2.623534
alpha：-28.609880，beta：50.146974，gamma：-18.499170

*** 单位：[m] ***
条件编号：31.840163979691628
tx：0.995999，ty：1.997551，tz：2.996235
alpha：9.789144，beta：20.450505，gamma：29.656265

*** 单位：[cm] ***
条件编号：27664.490644745576
tx：0.999960，ty：1.999976，tz：2.999962
alpha：9.997907，beta：20.004514，gamma：29.996574

*** 单位：[mm] ***
条件number:2765185.887452584
tx: 0.999996, ty: 1.999998, tz: 2.999996
alpha: 9.999791, beta: 20.000451, gamma: 29.999657

为什么会这样？
这是否与问题的同质性有关？
是否有一个通用程序可以用来为（同质）OLS 问题找到最佳单位（和原点）？
这是 python代码我使用了。
我注意到在上面的例子中，当 unit-&gt;mm 时答案似乎会收敛，因此在这种情况下，我可能已经猜到最佳单位是 mm，而不知道旋转和平移。
这也许可以用作启发式方法来找到最佳单位，但我更喜欢更有动力的方法。]]></description>
      <guid>https://stats.stackexchange.com/questions/659476/how-can-i-estimate-the-rotation-and-translation-between-two-cooordinate-frames</guid>
      <pubDate>Fri, 03 Jan 2025 00:11:28 GMT</pubDate>
    </item>
    <item>
      <title>如何从逻辑回归的引导程序中获取 p 值？</title>
      <link>https://stats.stackexchange.com/questions/659465/how-to-obtain-p-values-from-a-bootstrap-of-a-logistic-regression</link>
      <description><![CDATA[我有一个二元响应变量y和一组协变量(x_1, x_2, ..., x_n)。在执行多元逻辑回归时（在我的例子中使用 R 和 glm 函数：glm(y ~ x1 + x2 + x3 + ... + xn, family = binomial)），我可以获得 $p$ 值来检验协变量的系数是否显著，即 $H_0:\beta_j = 0$。
由于我的数据的维度（超过 100000 行和 5000 列），我无法执行多元逻辑回归来获取 $p$ 值（我的数据已经过过滤，即我无法执行变量选择）。我有如此庞大的数据集，以至于我必须对数据进行子采样才能容纳在我的计算机内存中。因此，我选择执行引导程序（b=引导样本数），但在子样本中（占总行数的 $p\%$）以获得多元逻辑回归的系数，如下所示：

我使用替换执行行选择，保持采样的二进制响应变量中 0/1 值的分布，以行的形式降低数据集的维数。
我将 glm 函数拟合到简化的数据集并获得系数和 p 值。
我重复此过程 b 次，获得系数和 p 值的向量。

每个变量的最终系数（在原始数据集中）是每个引导样本中获得的系数之间的平均值。
我的问题是：向量的平均值是多少每个样本中获得的 p 值是最终的 p 值吗？
恐怕不是，但在这种情况下，我如何获得逻辑回归引导程序的 p 值？
您肯定会建议我使用惩罚逻辑回归 (lasso)。我已经尝试过了，计算速度非常快。但是，使用后者，我仍然无法获得这些系数显著性的 p 值。如果您有关于如何获得这些最后的 p 值的参考，这对我也很有用。]]></description>
      <guid>https://stats.stackexchange.com/questions/659465/how-to-obtain-p-values-from-a-bootstrap-of-a-logistic-regression</guid>
      <pubDate>Thu, 02 Jan 2025 19:07:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 ARIMA/SARIMA 对重叠周期数据进行预测</title>
      <link>https://stats.stackexchange.com/questions/659459/forecasting-using-arima-sarima-for-overlapping-cycle-data</link>
      <description><![CDATA[我正在处理历史招聘周期的申请数据，并尝试使用 SARIMA 预测当前招聘周期结束时的申请数量。但是，招聘周期重叠 - 例如，2023/24 年的申请将在 2024/25 年的申请开始的同时提交。重要的是，模型对这两个周期的处理方式不同（即使它们同时发生），因为周期开始时的申请最多，而周期结束时的申请最少。另外，我不想预测 X 时间的申请数量，我想预测 Y 招聘周期中 X 时间的申请数量。
每个招聘周期的数据都遵循非常相似的时间路径，因此原则上它应该非常适合 SARIMA。但是，我不熟悉历史数据不连续时的预测，所以我不确定是否存在关于最佳处理方式的细微差别。任何建议都会非常有帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/659459/forecasting-using-arima-sarima-for-overlapping-cycle-data</guid>
      <pubDate>Thu, 02 Jan 2025 17:46:58 GMT</pubDate>
    </item>
    <item>
      <title>如何处理数据集中具有系统模式的缺失数据？</title>
      <link>https://stats.stackexchange.com/questions/659443/how-to-handle-missing-data-with-systematic-patterns-in-a-dataset</link>
      <description><![CDATA[我正在处理包含几个缺失值的数据集。以下是当前情况：
colSums(is.na(dati_train)) / nrow(dati_train) # 每列 NA 的比例
PAID POINT_OF_SALE EVENT_ID YEAR
0.00000000 0.00000000 0.00000000 0.00000000
MONTH N_SUBSCRIPTIONS PRICE PHONE_NUMBER
0.00000000 0.00000000 0.00000000 0.00000000
PROP_CONBINI PAYMENT_TYPE FAV_GENRE AGE
0.00000000 0.00000000 0.05655301 0.10076613
DAYS_FROM_PROMO BOOKS_PAID N_TRANSACTIONS N_ITEMS
0.00000000 0.32598398 0.32598398 0.00000000
DATE_LAST_PURCHASE CUSTOMER_SINCE MAIL SUBSCR_CANC
0.32598398 0.32598398 0.00000000 0.00000000
MARGIN
0.32598398


以下是缺失数据模式的可视化：

这里是变量的描述：




变量数据挑战
描述




EVENT_ID
交易ID


N_ITEMS
交易中购买的商品总数


PROP_CONBINI
“conbini”的比例交易中的商品


FAV_GENRE
最喜欢的漫画类型


PHONE_NUMBER
客户的电话号码（可用）


MAIL
客户的电子邮件地址（可用）


YEAR
交易年份


MONTH
交易月份


PAYMENT_TYPE
约定付款方法


BOOKS_PAID
之前交易中支付的漫画数量


PRICE
交易价格


N_SUBSCRIPTIONS
活跃的漫画系列订阅数量


SUBSCR_CANC
过去取消的漫画系列订阅数量


POINT_OF_SALE
销售点


AGE
客户的age


DAYS_FROM_PROMO
自上次促销结束以来的天数


MARGIN
客户的累计保证金


N_TRANSACTIONS
客户进行的交易总数


CUSTOMER_SINCE
客户首次交易的日期


DATE_LAST_PURCHASE
客户最近一次交易的日期


PAID
付款余额（目标）




如您所见，缺失值约为 33% 的变量具有相同的系统模式。
我想知道处理这种情况的最佳方法是什么。
我的问题：
我是否应该进行其他测试以更好地了解缺失数据的性质？如果是，您会推荐哪些测试？
处理此类缺失数据模式的最佳做法是什么？
我的初步计划：
删除与分析无关的变量。
创建一个“标志”变量以指示缺失数据的观察值。
我应该只为具有系统模式的变量（缺失值约为 33% 的变量）创建此标志吗？还是为所有具有缺失值的变量创建此标志？

继续使用多重插补或其他更复杂的技术来处理缺失数据。
解决缺失数据后，我计划继续进行分析。但是，由于我以前从未遇到过这样的问题，因此非常感谢任何建议。
提前感谢您的帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/659443/how-to-handle-missing-data-with-systematic-patterns-in-a-dataset</guid>
      <pubDate>Thu, 02 Jan 2025 09:11:12 GMT</pubDate>
    </item>
    <item>
      <title>如何估计两个坐标系之间的旋转？</title>
      <link>https://stats.stackexchange.com/questions/659430/how-can-i-estimate-the-rotation-between-two-cooordinate-frames</link>
      <description><![CDATA[我在两个坐标系（xyz 和 XYZ）中测量了 N 个 3D 点 p：
$$
p_i:\vec{xm_i}, \vec{Xm_i} 
$$
我将测量过程建模为：
$$
\vec{xm_i} = \vec{x_i} + \vec{\epsilon_i}
$$
$$
\vec{Xm_i} = \vec{X_i} + \vec{\epsilon&#39;_i}
$$
其中 $\vec{x_i}$ 和 $\vec{X_i}$ 是实际坐标位置（非随机变量）和$\vec{\epsilon_i} \sim \mathcal{N}(0,\sigma)$和$\vec{\epsilon_i&#39;} \sim \mathcal{N}(0,\sigma)$是测量噪声。
坐标系相对于彼此旋转：
$$
\vec{X_i} = R\vec{x_i} 
$$
其中
$$
\vec{X_i} = 
\begin{bmatrix}X_i\\Y_i\\Z_i\end{bmatrix}
$$
$$
\vec{x_i} = 
\begin{bmatrix}x_i\\y_i\\z_i\end{bmatrix}
$$
并且 $R(\alpha,\beta,\gamma)$ 是 3x3 旋转矩阵：

对于 $\alpha$、$\beta$ 和 $\gamma$ 以及为什么？
到目前为止，我所做的是最小化：
$$
\underset{\alpha,\beta,\gamma}{\mathrm{argmin}} 
\{SE(\alpha,\beta,\gamma) = \Sigma_i |R\vec{xm_i} - \vec{Xm_i}|^2\} 
$$
使用 Levenberg-Marquardt 算法 (scipy.optimize.least_squares)。
但是，我仅考虑了这种方法中的 $\vec{\epsilon&#39;_i}$ 错误。我还想考虑 $\vec{\epsilon_i}$ (总最小二乘法) 中的错误。
解决这个问题是否像最小化一样简单：
$$
\underset{\alpha,\beta,\gamma}{\mathrm{argmin}} 
\{TSE(\alpha,\beta,\gamma) = \Sigma_i [|R\vec{xm_i} - \vec{Xm_i}|^2 + |R^{-1}\vec{Xm_i} - \vec{xm_i}|^2]\} 
$$
相反？
此外，我使用 $L_2$ 范数 (最小二乘法)，因为这似乎是标准做法可以。但是为什么它比其他估计器更好呢？为什么不使用 $L_1$ 或 $L_{\infty}$ 呢？
我创建了一个 pandas 测试数据集。
这里我使用了$\alpha = 1°$、$\beta = 2°$和$\gamma = 3°$，并在$\vec{x}$和$\vec{X}$中添加了$\sigma = 0.01$的噪声。
这是我用Python实现的线性求解器。
它产生了以下输出：
实际旋转矩阵：
[[ 0.9980212 -0.05171974 0.03575975]
[ 0.05230407 0.99850932 -0.01560227]
[-0.0348995 0.01744177 0.99923861]]
估计旋转矩阵：
[[ 1.00228603 -0.06671378 0.0452653 ]
[ 0.04621024 0.97714644 -0.01505205​​]
[-0.02123221 0.01683688 1.00103115]]
alpha: 0.971802, beta: 1.886494, gamma: 3.266041

这里我取了 100 个解决方案的平均值（因为估计值是随机变量）。
结果相当不错，但有一个缺陷：
估计的旋转矩阵不正交。
每行的范数应该是 1，但第一行和最后一行都有元素 &gt; 1。
这是我从 Aksakals 的回答中实现的另一个线性求解器 2。它给出的结果与第一个线性求解器完全相同。
这是用 Python 实现的非线性求解器。
它产生了以下输出：
不对称：alpha：1.382373，beta：1.677021，gamma：3.002319
对称：alpha：1.382373，beta：1.677019，gamma：3.002318

总体最小二乘结果（对称）几乎与最小二乘结果（不对称）完全相同。这里我也取了 100 个解决方案的平均值（因为估计值是随机变量）。]]></description>
      <guid>https://stats.stackexchange.com/questions/659430/how-can-i-estimate-the-rotation-between-two-cooordinate-frames</guid>
      <pubDate>Wed, 01 Jan 2025 22:27:53 GMT</pubDate>
    </item>
    </channel>
</rss>