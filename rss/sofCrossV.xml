<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Tue, 25 Feb 2025 15:20:29 GMT</lastBuildDate>
    <item>
      <title>BAM模型中的低拟合值，导致特殊预测图</title>
      <link>https://stats.stackexchange.com/questions/661844/low-fitted-values-in-bam-models-causing-peculiar-predict-plots</link>
      <description><![CDATA[我使用湖上的肥皂smother在动物点的数据集上运行了三种型号，一个季节。
  mod_aut＆lt;  -  bam（出现〜#daynight +
                 s（x，y，bs =; so so; so; xt = list（bnd = shap_bnd_ls，nmax = 1000）） +
                 s（watertemp） +
                 s（waterdepth） +
                 s（lunar_day，bs =; cc＆quot;） +
                 s（hour_of_day，bs =; cc＆quot;） +
                 S（DISTABS） +
                 S（DistStinp）+
                 s（distlpinp）+
                 S（ABS_MAX_LS）+
                 s（inpst_max_ls）+
                 s（inplp_max_ls）+
                 ＃s（硬度）+
                 偏移（log（cumulative_count）），
               data = filter（eel.agg.70，季节==&#39;Autumn&#39;），
               family =二项式（link =＆quot; logit; quot;），
               方法=“弗雷姆”
               离散= true，
               结= lake_knots，
               重量=重量）
 
当我尝试从50 x 50个网格单元的数据框架上预测这些模型时，来自春季模型的数据看起来很奇怪
  lake_pred_aut＆lt;  -  lake_pred_df％＆gt;％ 
  dplyr :: filter（季==＆quot;秋天＆quot;）％＆gt;％
  na.omit（）

lake_pred_win＆lt;  -  lake_pred_df％＆gt;％ 
  dplyr ::过滤器（季节==;冬季＆quot;）％＆gt;％
  na.omit（）

lake_pred_spr＆lt;  -  lake_pred_df％＆gt;％ 
  dplyr :: filter（季节==; spring＆quord＆quord＆quord）％＆gt;％
  na.omit（）

pred_aut＆lt;  -  broom.mixed :: augment（mod_aut，newdata = lake_pred_aut）
pred_win＆lt;  -  broom.mixed :: augment（mod_win，newdata = lake_pred_win）
pred_spr＆lt;  -  broom.mixed :: augment（mod_spr，newdata = lake_pred_spr）

logit2prob＆lt;  -  function（logit）{
  赔率＆lt;  -  exp（logit）
  prob＆lt;  - 赔率 /（1 +赔率）
  返回（概率）
}

pred_aut_transf＆lt;  -  pred_aut％＆gt;％
  突变（
    lower = logit2prob（.fitting -1.96 * .se.fit），
    高= logit2prob（.Fitted + 1.96 * .se.fit），
    .fittit_prob = logit2prob（.fitting），
    季节=&#39;秋天&#39;
  ）

pred_win_transf＆lt;  -  pred_win％＆gt;％
  突变（
    lower = logit2prob（.fitting -1.96 * .se.fit），
    高= logit2prob（.Fitted + 1.96 * .se.fit），
    .fittit_prob = logit2prob（.fitting），
    季节=&#39;冬季&#39;
  ）

pred_spr_transf＆lt;  -  pred_spr％＆gt;％
  突变（
    lower = logit2prob（.fitting -1.96 * .se.fit），
    高= logit2prob（.Fitted + 1.96 * .se.fit），
    .fittit_prob = logit2prob（.fitting），
    季节=&#39;春天&#39;
  ）

pred＆lt;  -  bind_rows（pred_aut_transf，pred_win_transf，pred_spr_transf）

ggplot（） + 
  geom_tile（data = pred，aes（x = x，y = y，fill = .fitted_prob）） +
  geom_sf（data = shape_simp，fill = na，color =; black;） +
  facet_grid（lunar4〜季节） +
  scale_fill_viridis_c（name =＆quot;
                       选项=“涡轮”，方向= 1）+
  them_bw（） +
  主题（legend.background = element_blank（），） +
  指南（fill = guide_colourbar（
    frame.lineWidth = 0.3，
    ticks.colour =&#39;黑色&#39;，
    Frame.Colour =&#39;Black&#39;）） +
  实验室（x =“经度”
       y =“纬度”
预测图
 
   
显然，我那个月的预测值很低，但我不确定为什么。
  pred％＆gt;％ 
+ group_by（季节）％＆gt;％ 
+摘要（as_tibble（rbind（摘要（.fittit_prob））））））））
＃a tibble：3×7
  季节。 `1st qu.`中间的平均值`3rd qu.`最大。
  ＆lt; fct＆gt;     ＆lt; dbl＆gt;     ＆lt; dbl＆gt;   ＆lt; dbl＆gt;  ＆lt; dbl＆gt;     ＆lt; dbl＆gt; ＆lt; dbl＆gt;
1秋季1.18e- 9 0.0429 0.138 0.213 0.307 0.992
2冬季3.04e- 8 0.0695 0.239 0.321 0.535 0.998
3弹簧1.10E-11 0.000553 0.00195 0.0126 0.00875 0.825
 
A link to my full code and datasets if required can be found 此处。]]></description>
      <guid>https://stats.stackexchange.com/questions/661844/low-fitted-values-in-bam-models-causing-peculiar-predict-plots</guid>
      <pubDate>Tue, 25 Feb 2025 14:51:50 GMT</pubDate>
    </item>
    <item>
      <title>COX模型预测中置信区间的差异</title>
      <link>https://stats.stackexchange.com/questions/661843/differences-in-confidence-intervals-in-cox-model-predictions</link>
      <description><![CDATA[我正在尝试通过此 vignette 来自生存包装。但是，我注意到相对风险（RR）估计的置信区间（CI）的差异，具体取决于我的计算方式。
特别是，我在使用时获得不同的顺式：

  type =＆quot; lp;  in  predict&gt; predict（），然后从标准错误（SE）中计算95％CI并指出结果（如在小插图）。
  type =;风险;  in  predict&gt; predict（），然后直接从se。直接计算95％CI

在第二种情况下，置信区间更窄。
根据的帮助文件preditd.coxph ，“风险&#39;是 exp（lp）两种产生相同结果的方法。
有人知道为什么他们有所不同吗？
事先感谢您的见解！
 
 库（生存）
图书馆（dplyr）
图书馆（TinyPlot）

fit＆lt;  -  coxph（surv（未来，死亡）〜性 * splines :: ns（年龄，df = 3），data = flchain）
pdata＆lt;  -  Expand.Grid（年龄= 50:99，性= C（“ m＆quot”; f＆quot;））

lp_pred＆lt;  -  broom :: augment（fit，newdata = pdata，type.predict =＆quot; lp; lp; se = true）|＆gt; 
  突变（
    type =; lp＆quort
    conf.low = .fitting -1.96 * .se.fit，
    conf.high = .Fittit + 1.96 * .se.fit，
    跨越（c（.fited，conf.low，conf.high），exp）
  ）

firk_pred＆lt;  -  broom :: augment（
  fit，newdata = pdata，type.predict =“风险”，se = true
  ）|＆gt; 
  突变（
    类型=“风险”，
    conf.low = .fitting -1.96 * .se.fit，
    conf.high = .Fitted + 1.96 * .se.fit
  ）

pred＆lt;  -  rbind（lp_pred，firk_pred）

和（
  pread，
  TinyPlot（
    x =年龄，y =.。 
    facet = type，type =＆quord; ribbon＆quord＆quot log =&#39;y y＆quot;
  ）
）

 
    ]]></description>
      <guid>https://stats.stackexchange.com/questions/661843/differences-in-confidence-intervals-in-cox-model-predictions</guid>
      <pubDate>Tue, 25 Feb 2025 14:35:47 GMT</pubDate>
    </item>
    <item>
      <title>用Dharma的Beta GLMM（GLMMTMB）中的残留与预测的剩余与预测的解释</title>
      <link>https://stats.stackexchange.com/questions/661842/interpretation-of-residual-vs-predicted-in-beta-glmm-glmmtmb-with-dharma</link>
      <description><![CDATA[    
嗨，
我运行了一个beta glmmtmb，其中我的响应变量在0-1之间，因此我使用了beta分布。在我的模型中，我有3个连续的（数字）预测因子和3个随机效应因素，其中一个随机因素具有嵌套结构（1 | A/B）。进行模型验证，我获得了残留与预测的图，它显示了虚线的趋势线，我不知道如何解释这些后拟合结果以及模型是否需要改进以及如何改进。
任何指导都将不胜感激。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661842/interpretation-of-residual-vs-predicted-in-beta-glmm-glmmtmb-with-dharma</guid>
      <pubDate>Tue, 25 Feb 2025 13:53:37 GMT</pubDate>
    </item>
    <item>
      <title>回归您可以在其中观察到回应到错误</title>
      <link>https://stats.stackexchange.com/questions/661841/regression-where-you-observe-the-response-up-to-an-error</link>
      <description><![CDATA[考虑一个功能样本 $ x_1，\ ldots，x_n \ in \ Mathcal {x} $ ，以及在其中观察响应的地方，请考虑一个回归问题。已知分布的测量误差。
例如，一个人可以假设 $ y_i = \ nathcal {n}（\ mu_i，\ sigma_i^2）$  for span class =“ Math -container“&gt; $ i \ in \ {1，\ ldots，n \} $ 。在这里，响应将是实数上的分布而不是单个实数。然后，一个人可以训练模型， $ \ mu_ \ theta（x），\ sigma_ \ theta（x）$ 以最小化分配损失
 $$ \ sum_ {i = 1}^n d（\ mathcal {n}（\ mu_i，\ sigma_i^2），\ Mathcal {n}（\ mu_ \ theta（x_i \ theta） ），\ sigma_ \ theta（x_i）^2），$$ 
其中 $ d $ 是统计分歧。
这是否存在？是否有一种更简单的方法来查看与标准偏差的回归问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/661841/regression-where-you-observe-the-response-up-to-an-error</guid>
      <pubDate>Tue, 25 Feb 2025 13:26:00 GMT</pubDate>
    </item>
    <item>
      <title>如何在荟萃分析中使用元分析计算两个向量的相关性</title>
      <link>https://stats.stackexchange.com/questions/661840/how-to-calculate-correlation-from-two-vectors-taking-into-account-their-sd-in</link>
      <description><![CDATA[我有两个平均值及其标准偏差的向量，我知道使用了多少个样品来计算这些偏差：
  a.mean＆lt;  -  c（-0.593299457935214，1.5398906656498，0.474667240550958，0.197096899999999567 0.411565867000571，-0.182469876232944，0.085036494536958，0.583395241688231）
B.Mean＆lt; -C（-0.336308780666444，0.383283754321765，1.7076326575267，-1.1439243239297，-0.580.5801648064201919199199191991919919191991919191919199191919191999191999999999999999999999999999999999999999999999999991999999999999999999999999999 0.19131509705761，1.63985775967348，-1.8300037377404，-0.318887381847817）
A.sd &lt;- c(0.296227270018517, 0.30218840252479, 0.299951334146475, 0.299490096414611,     0.294567337015463, 0.304141284697497, 0.300261796049186，0.300960503557574，0.29733865532513，0.304327076880512）
B.sd &lt;- c(0.300106720391453, 0.297745788051714, 0.300065678745982, 0.307831487440735,     0.298219552291166, 0.298165738503535, 0.300918028906223，0.300642686972862，0.302108539079301，0.298966114971293）
A.N＆lt;  -  rep（5000，长度（a.mean））
B.N＆lt;  -  rep（5000，长度（B.Mean））
 
我如何计算这两个向量的（元）相关性，同时考虑到 a.sd 和 b.sd 向量的不确定性，使用r软件包 metafor ？
我尝试过：
 库（metafor）
escalc（measure =; cor; cor; m1i = a.mean，m2i = b.Mean，sd1i = a.sd，sd2i = b.sd，n1i = a.n，n2i = b.n）
 
但是，这会返回错误，期望在输入处计算出的相关性，但这不是我的情况 - 我有两个连续数量，我想计算荟萃分析中的相关性。&gt; 
我还试图通过在b〜a之间进行回归来做到这一点，但这也引发了错误：
  rma（mods = b〜a，m1i = a.mean，m2i = b.Mean，sd1i = a.sd，sd2i = b.sd，n1i = a.n，n2i = b.n）
 
它要求一定的措施 - 我不想要任何措施，我只想要这两个向量，我还没有找到任何“量度”。那将实现这一目标。
我看着小插图，没有看到任何似乎与此相关的例子。]]></description>
      <guid>https://stats.stackexchange.com/questions/661840/how-to-calculate-correlation-from-two-vectors-taking-into-account-their-sd-in</guid>
      <pubDate>Tue, 25 Feb 2025 13:22:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么跳过嵌入式工作？</title>
      <link>https://stats.stackexchange.com/questions/661839/why-do-skip-gram-embeddings-work</link>
      <description><![CDATA[我有一个有关跳过算法的问题。为了使问题有道理，我将描述它。不过，我可能不会完美。我将尝试给出我的书使用的解释。
创建单词嵌入是一种算法。假设您有一个带有25 000个单词的文字。您可以创建25000个矢量，这是一个热编码，这意味着它们的尺寸为25 000。然后，您查看句子或单词近距离，然后跳过这样的单词：
可以说，您有一个句子“背包可以包含书籍和铅笔”。您跳过了背包，看周围的单词，然后创建诸如（背包，包含），（背包，书籍），（书籍，背包），（铅笔，书籍）。&gt; 
您创建这样的神经网络：
您的输入向量为25000个维层（神经网络），该层产生了尺寸500的矢量，这些矢量又被送达到输出层（也是一个神经网络），该层产生了维度的维度。下一个单词的25000个概率，该向量与25 000个维输入向量有关。我们使用跨凝结训练数据。这意味着，在我们喂食它（Backs，Books）之后，该模型会自我调整，从而使“书籍”的概率;当我们给它一个“背包”一词时，变得更高一点。
 我的问题 
 为什么我们要说的是，语义上相似的单词像嵌入一样近距离togeher？我的书说，例如“电影”
和“电影”即使没有出现
通常在一起，因为他们周围的单词通常是相同的。
但是我们怎么知道算法不仅会创建两个
嵌入层中的不同嵌入式，但输出层
给出这两个不同的向量（嵌入）的值相同的值？我只能看到我们控制了复合函数，而不是第一个函数。 
 从我看到的函数g（f（x））来看，如果x和y在语义上接近，我确实看到g（f（x））将接近g（f（y） ），并且使F（x）接近f（y）的算法是很明智的，但是严格来说，我不认为它必须为了优化问题吗？  ]]></description>
      <guid>https://stats.stackexchange.com/questions/661839/why-do-skip-gram-embeddings-work</guid>
      <pubDate>Tue, 25 Feb 2025 12:35:19 GMT</pubDate>
    </item>
    <item>
      <title>最大可能性估计量何时有偏见？</title>
      <link>https://stats.stackexchange.com/questions/661838/when-is-a-maximum-likelihood-estimator-biased</link>
      <description><![CDATA[众所周知，最大似然估计器（MLE）可能会偏差。我们可以预测给定的分布和感兴趣的参数是否会产生偏见的MLE？它取决于什么属性？偏斜？
例如，正态分布和平均值 $ \ mu $ 将给出公正的mle，而 $ \ theta $  in  $ \ text {stormiforn}（0，\ theta）$ 将是偏见的（根据chatgpt）]]></description>
      <guid>https://stats.stackexchange.com/questions/661838/when-is-a-maximum-likelihood-estimator-biased</guid>
      <pubDate>Tue, 25 Feb 2025 11:40:56 GMT</pubDate>
    </item>
    <item>
      <title>使用Jackson等人时，通过每个随机效应对I2异质性估计进行分配。 （2012）伪I2方法</title>
      <link>https://stats.stackexchange.com/questions/661837/partitioning-i2-heterogeneity-estimates-by-each-random-effect-when-using-the-jac</link>
      <description><![CDATA[使用Jackson等。 （2012）计算（pseudo）i2（ https://metafor-project.org/doku.php/tips:i2_multilevel_multivariate？s [] =异质性＃jackson_et_al_2012_apprace ）  Metafor网站上的示例显示了如何通过结果分开但不是随机效果。
  #load数据
dat＆lt;  -  dat.berkey1998

#Jackson等。 （2012）方法
＃对于多元模型，Jackson等人。 （2012）描述了一种计算i2的不同方法
＃基于模型下固定效应的方差 - 稳定矩阵，具有随机效应，并且没有模型。因此，我们适合这两个模型： 

res.r＆lt;  -  rma.mv（yi，vi，mods = 〜0 +结果，随机=〜结果|试验，struct =; un＆quot; data = dat）
res.f＆lt;  -  rma.mv（yi，vi，mods = 〜0 +结果，data = dat）

＃到达两个结果的i2型统计量可以使用： 
c（100 *（vcov（res.r）[1,1] -VCOV（res.f）[1,1]） / vcov（res.r）[1,1]，，
  100 *（VCOV（RES.R）[2,2] -VCOV（RES.F）[2,2]） / VCOV（RES.R）[2,2]）
 
预先感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/661837/partitioning-i2-heterogeneity-estimates-by-each-random-effect-when-using-the-jac</guid>
      <pubDate>Tue, 25 Feb 2025 11:35:44 GMT</pubDate>
    </item>
    <item>
      <title>具有概率链接的比例序数模型的接受名称是什么？</title>
      <link>https://stats.stackexchange.com/questions/661835/what-is-the-accepted-name-for-a-proportional-ordinal-model-with-a-probit-link</link>
      <description><![CDATA[我正在使用一个序数回归模型，其中响应变量是顺序的，并且假定预测变量的效果是恒定的（即，并行或比例回归假设成立）。我知道，当使用Logistic链接函数时，此模型通常称为“比例赔率模型”。因为它直接建模了假定跨结果阈值成比例的优势比。
但是，当用概率链接替换逻辑链接时，“赔率”一词。由于概率模型是基于标准正常累积分布函数而不是赔率的倒数，因此变得不适用。然后，该模型通常称为“有序概率模型”。或“序数概率模型”，“ quot”但是这些名称并未明确强调比例（平行）假设。
文献中是否有公认的术语明确表示模型的相称性和使用概率链接函数的使用？例如，一个术语会喜欢“比例概率模型”。或“平行回归累积概率模型”适当，还是还有另一个标准命名法？
关于他人如何在文献中指代此模型的任何参考或见解将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/661835/what-is-the-accepted-name-for-a-proportional-ordinal-model-with-a-probit-link</guid>
      <pubDate>Tue, 25 Feb 2025 11:06:06 GMT</pubDate>
    </item>
    <item>
      <title>“最小化”高斯NLL的含义是什么？</title>
      <link>https://stats.stackexchange.com/questions/661834/what-does-minimising-the-gaussian-nll-mean</link>
      <description><![CDATA[我试图充分理解在模型训练期间的最小化高斯负模样（NLL）的最小值。使用MSE，它是直观的：接近0意味着更好的预测。但是高斯nll似乎不那么简单，尤其是因为它可能是负面和无限的。
在我的情况下，我的模型预测平均值 $ \ mu $  and  $ \ log（\ sigma^2） $ ，我指出要获得差异。我使用以下高斯NLL损失：
 $$ nll = \ frac {1} {2} {2} \ big [\ log（\ sigma^2）+\ frac {（y- \ mu）^2} {\ sigma^ 2}+\ log（2 \ pi）\ big]。$$  
我的主要问题是：最小化高斯NLL的含义是什么，我们如何跟踪改进？ 

仅查看上述方程式，我们可能会认为较低的损失总是更好的：对于完美的预测，NLL中的第二个任期将为零。在这种情况下，损失主要取决于 $ \ log（\ sigma^2）$ 。预测方差越小，负 $ \ log（\ sigma^2）$ 变成了，这似乎是一件好事，表明该模型有信心。遵循该逻辑，我们可以认为“最小化”。 NLL意味着我们只是希望它尽可能负面：-5的验证损失比-4之一好。但是，实际上，更负值的值也可能只是表明该模型过于自信并低估了不确定性，因此较低的值不一定更好，这将我带到了下一个点：
如果我正确理解，优化高斯NLL确实意味着使残留物的分布（预测错误）类似于： $ \ mu = 0 $ ，则表示预测平均是准确的， $ \ sigma^2 $ 匹配模型的预测不确定性。如果是这样，我们应该在培训期间如何解释或跟踪改进？如果较低的验证损失不一定更好，并且我们的目标不是尽可能接近零，那么哪些指标或方法可以帮助跟踪真正的改进？我们如何判断残差在培训时是否会融合到预测的高斯分布？
这是如何与早期停止和超参数调整相结合的，在哪里“更好”假定验证损失仅意味着较低的值？

我真的很感谢您对如何在培训期间解释高斯NLL的任何见解，尤其是如何平衡预测与不确定性估计以及如何在标准培训工作流程中起作用，例如早期停止和超参数调整。。]]></description>
      <guid>https://stats.stackexchange.com/questions/661834/what-does-minimising-the-gaussian-nll-mean</guid>
      <pubDate>Tue, 25 Feb 2025 10:42:25 GMT</pubDate>
    </item>
    <item>
      <title>独立CSCG矩阵和向量的产品的分布</title>
      <link>https://stats.stackexchange.com/questions/661833/distribution-of-a-product-of-independent-cscg-matrices-and-vectors</link>
      <description><![CDATA[ let  $ \ MathBf {X} \ sim \ Mathcal {Cn}（0，\ sigma_x^2 \ Mathbf {i}）\ in \ Mathbb {C} \ times 1} $ 是循环对称复杂的高斯（CSCG）随机向量和 $ \ Mathbf {h} \ sim \ Mathcal {Cn}（0，\ sigma_h^2 \ Mathbf {i}）\ in \ Mathbb {C} /span&gt;是一个CSCG随机矩阵，其中 $ \ Mathbf {X} $ 和 $ \ Mathbf {h} $ 在统计上是独立的。
我们可以严格地证明产品 $ \ MathBf {y} = \ MathBf {h} \ Mathbf {x} $ 也遵循CSCG分发，特别是&lt; span class =“ nath-container”&gt; $ \ mathbf {y} \ sim \ mathcal {cn}（0，0， \ sigma_h^2 \ sigma_x^2 \ mathbf {i}）$ ？]]></description>
      <guid>https://stats.stackexchange.com/questions/661833/distribution-of-a-product-of-independent-cscg-matrices-and-vectors</guid>
      <pubDate>Tue, 25 Feb 2025 10:06:23 GMT</pubDate>
    </item>
    <item>
      <title>有效且可靠的方法来诊断LightGBM模型高估，以预测使用DARTS库</title>
      <link>https://stats.stackexchange.com/questions/661832/efficient-and-reliable-ways-to-diagnose-overestimation-in-lightgbm-model-for-loa</link>
      <description><![CDATA[ 背景： 
我目前正在使用DARTS库解决负载预测问题，并且我已经培训了一个lightgbm模型，该模型的频率为“ 1H”。 （小时）。该模型将从2023-01-01 01:00至2024-12-01 00:00进行数据训练，并在12月1日至12月31日的数据上进行了验证。我已经观察到该模型的预测高估了，尤其是在12月22日和12月23日，在12月23日的高估更为明显。我正在寻求有关最有效，最可靠的方法的建议，以诊断高估的原因以及是否有任何新功能转换可能有助于减轻问题。我目前的协变量包括平均滚动，环状小时和月编码，无论圣诞节周，温度和其他一些。
    
 我尝试的是： 

模式分析：我已经检查了培训数据，发现在训练集的同一时期左右存在类似的高估模式。
功能工程：我引入了一个分类功能，以特别标记日期是12月22日还是12月23日，但这并没有大大减轻高估。

 问题： 

诊断方法：探测LightGBM模型高估原因的最有效，最可靠的方法是什么？是否有特定的诊断工具或技术可以帮助识别这种高估的根本原因？
特征转换：鉴于观察到的高估，是否有任何特征转换或工程技术有可能减少高估？例如，合并滞后功能，季节性指标或交互作用术语是否有益？
模型校准：是否有针对LightGBM模型的校准技术，可以帮助调整预测以减少高估，尤其是在这些关键时期？

任何建议都非常感谢：）]]></description>
      <guid>https://stats.stackexchange.com/questions/661832/efficient-and-reliable-ways-to-diagnose-overestimation-in-lightgbm-model-for-loa</guid>
      <pubDate>Tue, 25 Feb 2025 09:59:29 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用这种幼稚的方法计算稀疏组套索的归一化常数吗？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/661831/can-i-calculate-the-normalising-constant-of-the-sparse-group-lasso-using-this-na</link>
      <description><![CDATA[我正在尝试计算稀疏组套索的归一化常数。我想知道以下（幼稚）方法是否有效，或者计算是否更多地涉及？
稀疏组拉索的归一化常数由积分给出：
  \ begin {equination}
z（\ lambda_1，\ lambda_2）= \ int _ {\ Mathbb {r}^p}^p} \ exp \ left（ -  \ lambda_1 \ sum_ \ sum_ { | _2 \ right）d \ beta。
\ end {equation}  
我们可以使用拆分处罚
  \ begin {equination}
\ exp \ left（ -  \ lambda_1 \ sum_ {j} | \ beta_j |  -  \ lambda_2 \ sum_ {g} \ | \ | \ | \ | \ beta_g \ | _2 \ right）= \ prod_ {j} |）\ prod_ {g} \ exp（ -  \ lambda_2 \ | | \ beta_g \ | _2）。
\ end {等式}  
因此，积分可以作为独立积分的产物重写：
  \ begin {equination}
z（\ lambda_1，\ lambda_2）= \ prod_ {j} \ int _ {\ Mathbb {\ Mathbb {r}}} \ exp（ -  \ lambda_1 | \ beta_j |） r}^{m_g}}} \ exp（ -  \ lambda_2 \ | \ beta_g \ | _2）d \ beta_g。
\ end {equation}  
从这里开始，我们可以简单地使用拉索和套索的归一化常量。我怀疑这种方法无效，因为我不是100％确定积分是独立的。]]></description>
      <guid>https://stats.stackexchange.com/questions/661831/can-i-calculate-the-normalising-constant-of-the-sparse-group-lasso-using-this-na</guid>
      <pubDate>Tue, 25 Feb 2025 09:12:01 GMT</pubDate>
    </item>
    <item>
      <title>使用预旋转作为时间序列预测的可变筛选方法</title>
      <link>https://stats.stackexchange.com/questions/661830/using-pre-whitening-as-a-variable-screening-method-for-time-series-forecasting</link>
      <description><![CDATA[我正在使用大量的经济变量（类似于FRED-MD数据集中的变量），并且需要有效筛选方法的帮助。
处理包含趋势，季节性和自相关的原始经济时间序列时，确定哪些变量可能是我的目标变量有用的预测指标。
 我正在考虑这种方法： 

将Arima模型适合我的目标变量和潜在的预测变量
培训集中的变量
从这些模型中提取残差
回归预测物残差的目标残差以识别
重要的关系仅使用有希望的变量
进一步的分析和模型构建。

 我的问题是： 

这是识别潜在的有效筛选方法
有用的变量？
将简单的差异以实现平稳性
而是足够吗？
是否有选择的标准实践
我应该应该的大量时间序列变量的功能
考虑？

任何建议或对相关方法的参考都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/661830/using-pre-whitening-as-a-variable-screening-method-for-time-series-forecasting</guid>
      <pubDate>Tue, 25 Feb 2025 08:24:53 GMT</pubDate>
    </item>
    <item>
      <title>关于结构断裂点的问题[关闭]</title>
      <link>https://stats.stackexchange.com/questions/661828/question-on-structural-break-points</link>
      <description><![CDATA[你好，我有价格系列。我想确定这些单变量系列的结构断裂点。为此，我的教练建议采用递归回归并使用AR模型。
如何使用eviews或r？进行此测试
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/661828/question-on-structural-break-points</guid>
      <pubDate>Tue, 25 Feb 2025 07:58:00 GMT</pubDate>
    </item>
    </channel>
</rss>