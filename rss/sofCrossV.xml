<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 17 Jul 2024 06:22:15 GMT</lastBuildDate>
    <item>
      <title>如何对基于样本的丰度数据进行稀疏分析？</title>
      <link>https://stats.stackexchange.com/questions/651216/how-to-do-rarefaction-analysis-for-sample-based-abundance-data</link>
      <description><![CDATA[我想通过稀疏法比较不同林地的植物丰富度。数据以基于地块的方式收集。我在每个林地中设置了 4 个大小相同的地块，在每个地块的 5 个子地块中计数所有植物个体，并按地块汇总数据。所以我的数据属于 Colwell 等人 (2012) 提出的“基于样本的丰度数据”。我正在使用 R 包 iNEXT 来分析数据，但无法确定我应该使用哪种稀疏法。
iNEXT 包支持基于个体的丰度数据和基于样本单元的存在-不存在发生率数据，但似乎没有处理基于样本的丰度数据的说明。我想我应该将丰度数据转换为存在/不存在并将其作为发生率数据分析，以保留空间信息（Colwell 等人，2012 年）。但我想知道样本单元数量少（每个林地 4 个地块）是否会成为问题？例如影响引导置信区间的准确性。此外，由于稀疏化的目的是为了标准化不同样本量的数据以供比较，我的数据在样本单位的情况下样本量相等，但采样个体数量不同。按样本单位标准化是否合适？
此外，iNEXT 提供了按样本覆盖率标准化数据的选项。在我的案例中，将数据视为基于个体的数据会产生更高的估计覆盖率。例如：当将其视为基于个体的丰度数据时，两个林分的估计覆盖率达到 96% 和 98%，但当转换为存在-不存在数据时，覆盖率下降到 77% 和 91%。附件是使用不同类型的数据通过覆盖率得出的稀疏化结果示例。我希望能得到一些关于处理我的数据的最佳方法的建议。提前谢谢您。


参考文献：
Colwell, R.K., Chao, A., Gotelli, N.J., Lin, S.-Y., Mao, C.X., Chazdon, R.L.、Longino、J.T.，2012 年。基于个体和基于样本的稀疏化、外推和群落比较的模型和估计量。《植物生态学杂志》5，3-21。https://doi.org/10.1093/jpe/rtr044
Chao、A.、Gotelli、N.J.、Hsieh、T.C.、Sander、E.L.、Ma、K.H.、Colwell、R.K.、Ellison、A.M.，2014 年。使用希尔数的稀疏化和外推：物种多样性研究中的抽样和估计框架。《生态专著》84，45-67。 https://doi.org/10.1890/13-0133.1]]></description>
      <guid>https://stats.stackexchange.com/questions/651216/how-to-do-rarefaction-analysis-for-sample-based-abundance-data</guid>
      <pubDate>Wed, 17 Jul 2024 06:15:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么将阈值项纳入线性分类器的权重向量中？</title>
      <link>https://stats.stackexchange.com/questions/651215/why-is-the-threshold-term-incorporated-into-the-weight-vector-in-linear-classifi</link>
      <description><![CDATA[在线性分类器（例如感知器或逻辑回归）的上下文中，我理解决策边界由输入特征和权重的线性组合以及阈值（或偏差项）定义：
z = w * x + θ
我曾见过这样的解释，即通过定义新权重 w0 = -θ 和新输入特征 x0 = 1 将阈值 θ 引入权重向量。这样可以将决策边界写得更紧凑：
z = w0 * x0 + Σ(wi * xi)
我试图理解这种重新表述的动机和优势。为什么以这种方式将阈值纳入权重向量？这样做在数学或计算上有什么好处？
实际上，我的主要问题是，将 z 函数从 z=Σ(wi * xi) 更改为 z = w0 * x0 + Σ(wi * xi) 后，单位阶跃函数的定义没有改变，如果 z&gt;0，则给出 1。这是真的吗？为什么？
参考：Sebastian Raschka 和 Vahid MirjaLili 的《python 机器学习》第 21 页]]></description>
      <guid>https://stats.stackexchange.com/questions/651215/why-is-the-threshold-term-incorporated-into-the-weight-vector-in-linear-classifi</guid>
      <pubDate>Wed, 17 Jul 2024 05:49:21 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用主成分分析 (PCA) 中的变量作为线性回归中的结果 Y 吗？</title>
      <link>https://stats.stackexchange.com/questions/651214/can-i-use-a-variable-from-principal-component-analysis-pca-as-outcome-y-in-a-l</link>
      <description><![CDATA[(1) 我有一组 3 个预测因子，它们预测结果 Y (BF10 = 10)。每个预测因子单独都不能预测 Y (BFincl &lt; 1)
(2) 我想评估另一个预测因子是否可以一起预测这 3 个预测因子。
我可以使用主成分分析将这 3 个预测因子（成为 (2) 中的结果）转换为新变量，然后将此变量用作线性回归分析的结果吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/651214/can-i-use-a-variable-from-principal-component-analysis-pca-as-outcome-y-in-a-l</guid>
      <pubDate>Wed, 17 Jul 2024 04:51:37 GMT</pubDate>
    </item>
    <item>
      <title>对整个人口进行假设检验？</title>
      <link>https://stats.stackexchange.com/questions/651211/hypothesis-test-on-whole-population</link>
      <description><![CDATA[虽然这个问题已经在这里讨论过了 当我们拥有所有人口时，我们是否需要进行假设检验？ ，但我想就这个话题征求一些第二意见。
我为某个岛屿设置了以下内容。我尽我所能采访岛上的每个人。我非常有信心，我已经采访了岛上 99% 以上的成年人。简而言之，我实际上是在处理人口问题：

2000 年：

成年人口总数：260,000；

健康成年人数量：250,000

患病成年人数量：10,000

健康率：250,000/260,000 = 0.961


然后我明年回到同一个岛屿。上次来的一些人已经去世，一些人搬走了，一些人搬了新家，一些人上次还是青少年，现在已经成年，等等。再次，我尽我所能采访岛上的每个人。我非常有信心我已经采访了岛上 99％ 以上的成年人。简而言之，我实际上是在处理人口问题：

2001 年：

成年人口总数：265,000；

健康成年人数量：261,000

患病成年人数量：4,000

健康率：261,000/265,000 = 0.984


我的研究问题是比较 2000 年和 2001 年的健康率，看看差异是否具有统计学意义。
如果这是针对样本而不是人口，我会使用以下内容公式：

$ n_1 $ 是样本 1 中的总观测数（即 2000 年）

$ m_1 $ 是样本 1 中的成功次数。

$ \hat{p}_1 = \frac{m_1}{n_1} $ 是样本 1 的样本比例。

$ n_2 $ 是样本 2 中的总观测数（即2001 年）

$ m_2 $ 是样本 2 中的成功次数。

$ \hat{p}_2 = \frac{m_2}{n_2} $ 是样本 2 的样本比例。


我们感兴趣的是 $ \hat{p}_1 - \hat{p}_2 $
CLT 表示样本比例对于大样本（我有，即 260,000 和 265,000）具有正态分布：
$$ \hat{p}_1 \sim N\left(p_1, \frac{p_1(1 - p_1)}{n_1}\right) $$
$$ \hat{p}_2 \sim N\left(p_2, \frac{p_2(1 - p_2)}{n_2}\right) $$
这意味着样本比例的差异也是正态的：
$$ \hat{p}_1 - \hat{p}_2 $$
这个差异的平均值是 $ p_1 - p_2 $，方差是各个比例方差的总和。
因此，$ \hat{p}_1 - \hat{p}_2 $ 是：
$$ \text{Var}(\hat{p}_1 - \hat{p}_2) = \frac{p_1(1 - p_1)}{n_1} + \frac{p_2(1 - p_2)}{n_2} $$
$$ \sigma_{\hat{p}_1 - \hat{p}_2} = \sqrt{\frac{p_1(1 - p_1)}{n_1} + \frac{p_2(1 - p_2)}{n_2}} $$
现在我们定义测试统计量 - 我读到这是一个 Z 分布（我认为是因为 CLT）：
$$ Z = \frac{(\hat{p}_1 - \hat{p}_2) - (p_1 - p_2)}{\sqrt{\frac{p_1(1 - p_1)}{n_1} + \frac{p_2(1 - p_2)}{n_2}}} $$
在零假设$ H_0: p_1 - p_2 = 0$下，因此我们可以将最终的检验统计量写为：
$$ Z = \frac{(\hat{p}_1 - \hat{p}_2)}{\sqrt{\hat{p}(1 - \hat{p}) \left(\frac{1}{n_1} + \frac{1}{n_2}\right)}} $$
但是如果我们处理的是人口，现在会发生什么？我不确定如何修改上述公式以考虑人口层面的信息而不是样本层面的信息。
在我链接的问题中，一位用户写道：“我花了数年时间向客户解释，在具有真实人口普查信息的案例中，没有差异，因此统计意义毫无意义。”

我如何修改比例假设检验以在人口层面发挥作用？假设检验的概念在人口层面是否从根本上变得无效（“毫无意义”）？
或者 - 我是否可以仅在样本层面使用这些公式，并通过说我永远无法 100% 确定我是否真正采访了整个人口来证明它们？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651211/hypothesis-test-on-whole-population</guid>
      <pubDate>Wed, 17 Jul 2024 03:31:14 GMT</pubDate>
    </item>
    <item>
      <title>具有一个计数和一个连续IV的多元泊松回归？</title>
      <link>https://stats.stackexchange.com/questions/651210/multiple-poisson-regression-with-one-count-and-one-continuous-iv</link>
      <description><![CDATA[由于我的一个独立变量是连续变量，另一个是计数变量，我还能进行多元泊松回归吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651210/multiple-poisson-regression-with-one-count-and-one-continuous-iv</guid>
      <pubDate>Wed, 17 Jul 2024 03:30:36 GMT</pubDate>
    </item>
    <item>
      <title>在推理过程中，输入是如何输入到仅解码器的变压器中的？</title>
      <link>https://stats.stackexchange.com/questions/651205/how-are-the-inputs-fed-into-the-decoder-only-transformers-during-inference</link>
      <description><![CDATA[在仅用于 token 预测的解码器转换器中，我理解在训练期间，整个序列可以输入转换器并通过层进行处理。但在推理期间（当我们想要生成 token 时），究竟输入了什么到转换器中？例如，第一次输入 token，但其他后续位置呢？我们是否用一些特殊 token（例如 0）填充它们？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651205/how-are-the-inputs-fed-into-the-decoder-only-transformers-during-inference</guid>
      <pubDate>Wed, 17 Jul 2024 01:36:35 GMT</pubDate>
    </item>
    <item>
      <title>CSF 的值必须为 0 和最低可能值吗？</title>
      <link>https://stats.stackexchange.com/questions/651199/does-csf-must-have-value-0-and-lowest-possible-value</link>
      <description><![CDATA[假设 $F$ 是实值随机变量的 CDF。我知道 $F(- \infty) = 0$，因为 RV 不能取小于该值的值。
但我考虑的是一个 RV，其值肯定来自 $[0, 1]$。$F(0)$ 是否必然为 0？更具体地说，我可以在 $x = 0$ 处有某种“点质量”，以便 $x &lt; 的 CDF 为零0$，某个数 $k \in (0, 1)$ 在 0 处连续，直到在 1 之前或 1 处达到 1？
相关的 PDF 是什么？我设想一种这样的形式：$\delta(x) + f(x)$，其中 $\delta$ 是狄拉克-德尔塔函数。但是如何在 PDF 公式中指定 $k$ 的确切值？这是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/651199/does-csf-must-have-value-0-and-lowest-possible-value</guid>
      <pubDate>Tue, 16 Jul 2024 23:10:48 GMT</pubDate>
    </item>
    <item>
      <title>截距估计与 glm 和 glmm 相比有很大不同</title>
      <link>https://stats.stackexchange.com/questions/651198/intercept-estimates-very-different-comparing-glm-and-glmm</link>
      <description><![CDATA[有人能解释以下令人费解的现象吗？我正在使用 R 的 lme4 包中的 glmer 拟合二项式 glmm。数据集中的二元响应变量的平均值约为 0.1。当我使用必要的随机效应拟合仅截距的 glmm 时，我得到的截距估计值毫无意义：
&gt; history.glmer.c.9 &lt;- glmer(contaminated ~ (1|ID), family = binomial, data = inspected)
&gt; summary(history.glmer.c.9) 
通过最大似然法（拉普拉斯近似）拟合的广义线性混合模型 [&#39;glmerMod&#39;]
族：二项式（logit）
公式：污染 ~ (1 | ID)
数据：已检查

AIC BIC logLik 偏差 df.resid 
32730.4 32748.5 -16363.2 32726.4 64539 

缩放残差：
最小 1Q 中位数 3Q 最大 
-2.2088 -0.0049 -0.0049 -0.0049 4.1520 

随机效应：
组名称方差标准差
ID。 （截距）591.6 24.32 
观察数：64541，组：ID，51445

固定效应：
估计标准误差 z 值 Pr(&gt;|z|) 
（截距）-10.60404 0.07398 -143.3 &lt;2e-16 ***
---
有效代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

我认为这个截距估计值太低了 - 我期望在 -2 左右，这是我从仅截距 glm 中得到的结果。
&gt; history.glm.c.9 &lt;- glm(contaminated ~ 1, family = binomial, data = inspected)
&gt; summary(history.glm.c.9) 

调用：
glm(formula = contaminated ~ 1, family = binomial, data = inspected)

系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -1.87428 0.01159 -161.7 &lt;2e-16 ***
---
符号代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

（二项式系列的分散参数取为 1）

零偏差：64540 个自由度上的 50618
残差偏差：64540 个自由度上的 50618
AIC：50620

Fisher 评分迭代次数：4

值得注意的评论

AIC 表明 glmm 比 glm 更适合（32730
cf 50620）。
我使用 glmmTMB 得到了相同的截距估计，所以我不认为这只是 glmer。
组成员严重偏斜（见下表）；绝大多数组都是单例。
ICC 非常高，但单例污染率（即单个单元组的污染率）与较大组的污染率大致相同。
组级别的失败率也约为 0.1。

&gt;表（表（已检查$ID））

1 2 3 4 5 6 7 8 9 10 11 12 13 14 
582847 35629 7137 3268 1609 828 492 296 195 99 66 72 20 13 
15 16 17 19 25 26 
6 5 8 2 1 1 

感谢您的任何见解！]]></description>
      <guid>https://stats.stackexchange.com/questions/651198/intercept-estimates-very-different-comparing-glm-and-glmm</guid>
      <pubDate>Tue, 16 Jul 2024 22:57:37 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助理解随时间变化的优势比示例</title>
      <link>https://stats.stackexchange.com/questions/651177/need-help-understanding-odds-ratio-over-time-example</link>
      <description><![CDATA[我正尝试重新创建一篇论文，该论文比较了重复急诊就诊（即同一患者在过去 12 个月内因同一原因再次就诊）与单次急诊就诊的频率和特征。其中，“使用逻辑回归计算了随时间推移重复急诊就诊与单次急诊就诊的概率。给出了未调整的优势比；未控制其他变量。”没有提供其他详细信息。
在他们展示比值比的部分中，他们展示了一个聚类条形图，显示了 2018-2022 年每年的急诊就诊次数（单次或重复）的百分比。5 年来，每年重复就诊的百分比略有增加。他们给出的未调整的几率比为 1.108“这表明，每年，个人重复急诊就诊而不是单次急诊就诊的几率增加 11% (p&lt;.001)。&quot;
这是否意味着，为了获得未调整的几率比，我应该运行逻辑回归，其中独立变量是急诊就诊的年份，因变量为 0/1（单次/重复）？我很难理解这种情况下独立变量是什么。
我确实尝试过这个（使用 sklearn.LogisticRegression），得到的几率比是 0.99，这没有意义。我认为我应该将年份向量转换为 1-5 而不是 2018-2022，对吗？
我是不是错得离谱？
]]></description>
      <guid>https://stats.stackexchange.com/questions/651177/need-help-understanding-odds-ratio-over-time-example</guid>
      <pubDate>Tue, 16 Jul 2024 18:28:36 GMT</pubDate>
    </item>
    <item>
      <title>Cox 比例风险模型的功效分析</title>
      <link>https://stats.stackexchange.com/questions/651176/power-analysis-for-the-cox-proportional-hazards-model</link>
      <description><![CDATA[我正在尝试根据一项小型研究计算出 RCT 所需的样本量，该研究研究了指数手术后的再次手术。在这项小型研究中，有 1000 名患者，第 1 组有 700 名，第 2 组有 300 名患者。第 1 组中有 20 名再次手术，第 2 组中有 30 名再次手术。但是，第 1 组的 10 年生存率为 15%，第 2 组的 10 年生存率为 12%。因此，大多数患者不再面临再次手术的风险。我想知道如何计算 RCT 所需的样本量，以 1:1 随机分配，并观察如果对患者进行 10 年的随访，考虑到随访期间的死亡，各组之间的风险比是否会降低 0.10？我的 stata 代码目前如下所示
power cox, hratio(0.90) alpha(0.05) power(0.80)]]></description>
      <guid>https://stats.stackexchange.com/questions/651176/power-analysis-for-the-cox-proportional-hazards-model</guid>
      <pubDate>Tue, 16 Jul 2024 18:17:39 GMT</pubDate>
    </item>
    <item>
      <title>将五点李克特量表转换为均匀量表[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651175/converting-five-point-likert-scale-to-uniform-scale</link>
      <description><![CDATA[*我正在开展一个荟萃分析项目，其中包括来自不同出版物的平均值和 SD 值。它们有不同的尺度。一些是基于 0 到 100 的视觉模拟量表计算的分数平均值和 SD。一些是基于 1 到 10 的视觉模拟量表，增量为 0.5，其他是基于李克特量表（5 分制，1 到 5）的分数平均值和 SD。
所以我考虑重新缩放平均值和 SD 值（标准化平均值和 SD 的值并获取平均值和 SD 的新值）以分析和比较它们。我应该怎么做？*]]></description>
      <guid>https://stats.stackexchange.com/questions/651175/converting-five-point-likert-scale-to-uniform-scale</guid>
      <pubDate>Tue, 16 Jul 2024 18:16:09 GMT</pubDate>
    </item>
    <item>
      <title>灌注分析算生存分析吗？</title>
      <link>https://stats.stackexchange.com/questions/651173/perfusion-analysis-counts-as-survival-analysis</link>
      <description><![CDATA[在灌注分析中，患者被注射一定剂量的药物。机器会随着时间的推移检测患者体内的药物剂量。换句话说，每个患者的数据是时间点 $0=t_0 &lt; t_1 &lt; \cdots &lt; t_N$ 和剂量 $y_1, \ldots, y_N$，其中 $y_i \in [0, \infty)$ 表示时间 $t_i$ 时患者体内的剂量。 （通常，$y_i$ 也可以是某种间接的剂量测量值。）根据具体情况，可能只有一名患者或多名患者，或者患者被分成几组等。我们只强调一个假设：给定时间 $t$，任何患者在时间 $t$ 的剂量都是随机的，因此这不是机器学习任务。
当我们绘制所有对 $(t_i,y_i)$ 时，形状通常看起来像一些集中在 $[0, \infty)$ 上的分布的概率密度函数（例如对数正态分布、威布尔分布、指数分布，...）
统计学家的任务通常是调查趋势，推断例如剂量何时达到峰值，剂量何时上升等。解决问题的一种方法是与客户交谈，根据信念拟合概率密度函数，然后查看任务。
例如，假设只有一名患者，我们想要估计剂量何时达到峰值。我们可以说在与客户讨论后，用对数正态分布的概率密度函数拟合数据，选择参数以最小化最小二乘，然后查看拟合的最大值。
问题：统计员的任务名称是什么？这样的任务算生存分析吗？时间序列分析？我倾向于称之为生存分析，但我不确定，因为在这种情况下，生存分析中的典型工具似乎不可用。]]></description>
      <guid>https://stats.stackexchange.com/questions/651173/perfusion-analysis-counts-as-survival-analysis</guid>
      <pubDate>Tue, 16 Jul 2024 18:14:45 GMT</pubDate>
    </item>
    <item>
      <title>有限的结果事件。方法的选择</title>
      <link>https://stats.stackexchange.com/questions/651170/limited-outcome-events-choice-of-method</link>
      <description><![CDATA[我正在对罕见事件进行研究。我比较了两个组 A（n=50）和 B（n=200），但我发现结果事件比预期的要少，A（n=12），B（n=4）。我可以将这些数据用于任何有意义的目的吗？还是统计不确定性太大？我打算进行多变量分析（cox reg），但如果变量超过 1-2 个，这将失败？
谨致问候，
H]]></description>
      <guid>https://stats.stackexchange.com/questions/651170/limited-outcome-events-choice-of-method</guid>
      <pubDate>Tue, 16 Jul 2024 17:57:08 GMT</pubDate>
    </item>
    <item>
      <title>固定值与均匀分布混合的浓度界限</title>
      <link>https://stats.stackexchange.com/questions/651167/concentration-bounds-for-a-mixture-of-a-fixed-value-and-a-uniform-distribution</link>
      <description><![CDATA[假设我们有一个混合随机变量 $R= (1-p)X + pU$，其中 $X$ 只是一个值 $X \in [-\pi, \pi]$，$0 \leq p \leq 1$，以及 $U \sim \text{Uniform}[-\pi, \pi]$。即：单次试验以概率 $p$ 返回 $X$，否则以概率 $1-p$ 返回来自 $U$ 的样本。
我想给出（最好是双尾）浓度界限，以估计 $X$ 的附加准确度 $\epsilon$ 和置信度 $\delta$ 所需的试验次数。参数 $p$ 是预先知道的。如果我们将试验表示为 $R_i$ 并使用估计量 $\hat{R} = \frac{1}{n(1-p)} \sum_{i=1}^n R_i$，那么我认为，简单应用 Hoeffding 可以得出，
$$
n \geq \frac{2\pi p^2}{\epsilon^2(1-p)^2}\log\frac{1}{\delta},
$$
但是可以得出更严格的界限吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651167/concentration-bounds-for-a-mixture-of-a-fixed-value-and-a-uniform-distribution</guid>
      <pubDate>Tue, 16 Jul 2024 16:34:16 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R 中的 IV 回归中获得 KP F-stat？</title>
      <link>https://stats.stackexchange.com/questions/651212/how-to-get-kp-f-stat-in-iv-regression-in-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651212/how-to-get-kp-f-stat-in-iv-regression-in-r</guid>
      <pubDate>Tue, 16 Jul 2024 13:50:03 GMT</pubDate>
    </item>
    </channel>
</rss>