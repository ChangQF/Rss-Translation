<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Thu, 04 Jan 2024 06:18:21 GMT</lastBuildDate>
    <item>
      <title>根据出版物中可用的数据计算预测区间</title>
      <link>https://stats.stackexchange.com/questions/636115/calculating-prediction-interval-from-data-available-in-publication</link>
      <description><![CDATA[我有一份出版物，提供了荟萃分析的线性多元回归方程。 LOOCV 用于从所有可能的模型中选择最终模型中包含的解释变量。该出版物中提供了回归方程。我想计算一组新值的 $\hat{y}$ 并估计这些值的预测区间。
我遇到的问题是，对我来说，该出版物的信息有限。关于 LOOCV 分析，它具有以下内容；

最终所选模型的 RMSE 和平均偏差
为最终模型选择的解释变量的估计值和 SE
用于每个解释变量的数据集的摘要统计数据

本文中的自我回答建议您可以仅使用 RMSE 来近似预测间隔。我在运行模拟并将 RMSE 计算方法与 predict.lm 进行比较时得到的预测显示它们并不相同，因此我更愿意使用 RMSE 方法。
我更喜欢使用 $$\hat{y}_h \pm t_{(\alpha/2, n-p)} \times \sqrt{1 + \mathbf{x }^* (\mathbf{X}&#39;\mathbf{X})^{-1} (\mathbf{x}^*)&#39;}$$
其中 $\mathbf{x}^*$ 表示用于填充回归方程的变量矩阵
但是我没有原始数据集来计算 $(\mathbf{X}&#39;\mathbf{X})$。
我可以根据我所掌握的信息使用这个方程吗？或者我必须恢复到 RMSE 方法吗？
TIA]]></description>
      <guid>https://stats.stackexchange.com/questions/636115/calculating-prediction-interval-from-data-available-in-publication</guid>
      <pubDate>Thu, 04 Jan 2024 06:12:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么大量的审查在生存分析中是不好的？</title>
      <link>https://stats.stackexchange.com/questions/636114/why-is-large-amounts-of-censoring-bad-in-survival-analysis</link>
      <description><![CDATA[我试图理解为什么大量的审查（即许多患者被审查）在生存分析中是不可取的。
作为概念证明，假设有 5 名患者：

患者 1 在 t1 发生事件
患者 2 在 t2 发生事件
患者 3 在 t3 时退出研究
患者 4 在 t4 发生事件
当研究在 t5 结束时，患者 5 没有发生该事件

（半参数方法）这是我在这种情况下尝试编写 Cox-PH 回归的模型和可能性：
$$ h(t|X) = h_0(t) \exp(\beta^T X) $$
$$ L(\beta) = \prod_{i: \delta_i = 1} \frac{h(t_i|X_i)}{\sum_{j: t_j \geq t_i} \ exp(\beta^T X_j)} $$
$$ L(\beta) = \frac{h(t_1|X_1)}{\sum_{j: t_j \geq t_1} \exp(\beta^T X_j)} \次\frac{h(t_2|X_2)}{\sum_{j: t_j \geq t_2} \exp(\beta^T X_j)} \次\frac{h(t_4|X_4)}{\sum_{j: t_j \geq t_4} \exp(\beta^T X_j)} $$
$$ L(\beta) = \frac{h(t_1|X_1)}{\exp(\beta^T X_1) + \exp(\beta^T X_2 ) + \exp(\beta^T X_3) + \exp(\beta^T X_4) + \exp(\beta^T X_5)} \times \frac{h(t_2|X_2)}{\exp(\beta ^T X_2) + \exp(\beta^T X_3) + \exp(\beta^T X_4) + \exp(\beta^T X_5)} \times \frac{h(t_4|X_4)}{\exp (\beta^T X_3) + \exp(\beta^T X_5)} $$
（参数方法）这是我在这种情况下尝试编写 AFT 模型的模型和可能性：
$$ \log(T) = \mu + \sigma \beta^TX + \epsilon $$
$$ L(\mu, \sigma, \beta) = \prod_{i=1}^{n} \left[ \frac{1}{\sigma} f\left( \frac{\log(t_i) - \mu - \beta^T X_i}{\sigma} \right) \right]^{\​​delta_i} \left[ 1 - F\left( \frac{\ log(t_i) - \mu - \beta^T X_i}{\sigma} \right) \right]^{1-\delta_i} $$
$$ L(\mu, \sigma, \beta) = \left[ \frac{1}{\sigma} f\left( \frac{\log(t_1) ) - \mu - \beta^T X_1}{\sigma} \right) \right] \times \left[ \frac{1}{\sigma} f\left( \frac{\log(t_2) - \mu - \beta^T X_2}{\sigma} \right) \right] \times \left[ 1 - F\left( \frac{\log(t_3) - \mu - \beta^T X_3}{\sigma} \right) \right] \times \left[ \frac{1}{\sigma} f\left( \frac{\log(t_4) - \mu - \beta^T X_4}{\sigma} \right) \右] \times \left[ 1 - F\left( \frac{\log(t_5) - \mu - \beta^T X_5}{\sigma} \right) \right] $$
那么在 Cox-Ph 和 AFT 模型中，推理（例如，可能会导致高方差、高偏差、不一致性、较大的样本量来实现比较结果与较小的样本量和较少的审查）和参数估计如何当大量患者受到审查时会产生负面影响吗？数学优化是否变得困难（例如，矩阵秩不完整、矩阵逆未定义、模型不可识别）？
PS：我听说一些策略涉及使用混合分布对无事件（审查）和事件（非审查）群体进行建模，这在数据集中很大一部分数据集未开发出事件的情况下显然很有用。事件。例如，基于威布尔分布的生存函数可用于使用混合分布方法（参数）分别对无事件和事件群体进行建模。这称为治愈模型。
威布尔函数（pdf、cdf、生存和危险）：
$$ f(t|\lambda, \gamma) = \frac{\gamma}{\lambda} \left(\frac{t}{\lambda}\right )^{\gamma - 1} \exp\left[-\left(\frac{t}{\lambda}\right)^\gamma\right] $$
$$ F(t|\lambda, \gamma) = \int_0^t f(u|\lambda, \gamma) du = 1 - \exp\left[-\左(\frac{t}{\lambda}\right)^\gamma\right] $$
$$ S(t|\lambda, \gamma) = 1 - F(t|\lambda, \gamma) = \exp\left[-\left(\frac) {t}{\lambda}\right)^\gamma\right] $$
$$ h(t|\lambda, \gamma) = \frac{f(t|\lambda, \gamma)}{S(t|\lambda, \gamma) )} = \frac{\gamma}{\lambda} \left(\frac{t}{\lambda}\right)^{\gamma - 1} $$
模型和似然（$f_1(t)$、$f_2(t)$ 是两个人群的 pdf，$p(x)$ 是治愈率）：
$$ f(t) = p \cdot f_1(t) + (1 - p) \cdot f_2(t) $$
$$ S(t) = p \cdot S_1(t) + (1 - p) \cdot S_2(t) $$
$$ p(X) = \frac{\exp(X&#39;\alpha)}{1 + \exp(X&#39;\alpha)} $$
$$ L(p, \theta_1, \theta_2) = \prod_{i=1}^{n} \left[p \cdot f_1(t_i|\theta_1) + (1 - p) \cdot f_2(t_i|\theta_2)\right]^{d_i} \cdot \left[p \cdot S_1(t_i|\theta_1) + (1 - p) \cdot S_2(t_i|\ theta_2)\right]^{1-d_i} $$
（我不太确定如何继续这个......只是偏离了主题）]]></description>
      <guid>https://stats.stackexchange.com/questions/636114/why-is-large-amounts-of-censoring-bad-in-survival-analysis</guid>
      <pubDate>Thu, 04 Jan 2024 06:08:48 GMT</pubDate>
    </item>
    <item>
      <title>如何解释pairplots()</title>
      <link>https://stats.stackexchange.com/questions/636112/how-to-interpret-pairplots</link>
      <description><![CDATA[我一直在研究分类问题。我想看看有多少特征与目标变量相关。
让我分享一个例子。我使用了这个配对图
目标 = &#39;占用&#39;
sns.pairplot(df, 色调=目标)
plt.show()

一些数据背景：该数据用于预测房间的占用情况（有人/无人）。这是一个分类问题。
这是配对图：

我的问题是：

我该如何解释这一点？特别是，找出哪些特征是最强的预测因子。
例如，如果我们看到Temperature到Light（第一行的第三个子图），则可以通过色调看出这是这个协会中一个非常好的区别。我是否应该认为这两个特征（组合起来）都是很好的预测因子？
有没有一种方法可以仅针对一个目标特征来查看此类关联？ （就像这里一样，我们有一对目标特征）
]]></description>
      <guid>https://stats.stackexchange.com/questions/636112/how-to-interpret-pairplots</guid>
      <pubDate>Thu, 04 Jan 2024 04:56:46 GMT</pubDate>
    </item>
    <item>
      <title>如何统计组织数据以进行伪影分析</title>
      <link>https://stats.stackexchange.com/questions/636110/how-to-statistically-organise-data-for-artefact-analysis</link>
      <description><![CDATA[我想知道如何创建下表中的算法 - 统计数学模型，以便区分具有伪影的数据和不具有伪影的数据。
下面的数据是从许多在线电影中收集的，我正在尝试使用查找峰值来检测包含伪影和不包含伪影的视频。
谢谢！！
]]></description>
      <guid>https://stats.stackexchange.com/questions/636110/how-to-statistically-organise-data-for-artefact-analysis</guid>
      <pubDate>Thu, 04 Jan 2024 04:43:27 GMT</pubDate>
    </item>
    <item>
      <title>UMP 大小 $\alpha$ 离散分布的假设检验</title>
      <link>https://stats.stackexchange.com/questions/636109/ump-size-alpha-hypothesis-test-for-discrete-distribution</link>
      <description><![CDATA[
设 $\left(Z_1, \ldots Z_n\right)$ 为独立同分布。具有公共概率质量函数的样本
$$
p_Z(j)=\vartheta^2 I_{[j=1]}+2 \vartheta(1-\vartheta) I_{[j=2]}+(1-\vartheta)^2 I_{[j=3 ]}
$$

查找 $\alpha$ 的 UMP 大小假设检验 $H_0: \vartheta=1 / 3$ 与 $H_A: \vartheta&gt; 1/3$。给出确定拒绝区域中恒定阈值的明确公式。
$\textbf{我的尝试}:$
联合分布由下式给出：$$ p_z(\textbf{j}) = 2^{n_2}\vartheta^{2n_1 - n_2} (1 - \vartheta) ^{2n - (2n_1 + n_2)}$$
其中 $n_1 = \text{$Z_i$ 的#，使得 j = 1}$ 和 $n_2 = \text{ # $Z_i$ 使得 j = 2}$
根据因式分解定理，$$T = 2n_1 + n_2$$
对于 $\vartheta_2 &gt; \vartheta_1$ 我们可以证明，在我们的充分统计量 $2n_1 + n_2$ 中存在单调似然比，因此卡林-鲁宾定理告诉我们我们
$$\text{如果 $2n_1 + n_2$ &gt; 则拒绝 $H_0$ k}$$
$$\text{如果 $2n_1 + n_2$ = k，则以 $\gamma$ 概率拒绝 $H_0$}$$
$$\text{如果$2n_1 + n_2$ &lt;，则不拒绝$H_0$ k}$$
其中 k 是一个常数，满足：$$\alpha = P(2n_1 + n_2 &gt; k| \vartheta = \frac13) + \gamma P(2n_1 + n_2 = k| \ vartheta = \frac13)$$
$\textbf{我陷入困境的地方}$：现在我想求解 k，但辅助随机化的第二项使其变得非常困难。我也不确定 $2n_1 + n_2$ 的分布。我在这里假设它将是一个二项式，我们可以利用二项式的正态近似。
$$ \text{在$H_0$下}~ n_1 \sim bin(n, \frac19),~ n_2 \sim bin(n, \frac49) $$
$$ E_{H_0}(2n_1 + n_2) = \frac{2n}{9} + \frac{4n}{9} = \frac{2n}{3}$$ 
$$ Var_{H_0}(2n_1 + n_2) = 4Var(n_1) + Var(n_2) = \frac{32n}{81} + \frac{20n}{81} = \frac{52n}{81}$$
所以： $$\alpha = P(\frac{T - \frac{2n}{3}}{\sqrt{\frac{52n}{81}}} &gt; \frac{k - \frac{2n}{3}}{\sqrt{\frac{52n}{81}}}) + \gamma P(\frac{T - \frac{2n}{3}} {\sqrt{\frac{52n}{81}}} = \frac{k - \frac{2n}{3}}{\sqrt{\frac{52n}{81}}})$$ $$ = 1 - pnorm(\frac{k - \frac{2n}{3}}{\sqrt{\frac{52n}{81}}}) + \gamma ~ dnorm(\frac{k - \frac{2n}{3}}{\sqrt{\frac{52n}{81}}})$$
我不知道从现在开始如何求解 k 。假设有很大的 n 我可以简单地忽略辅助随机化项吗？任何帮助/建议将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/636109/ump-size-alpha-hypothesis-test-for-discrete-distribution</guid>
      <pubDate>Thu, 04 Jan 2024 03:47:42 GMT</pubDate>
    </item>
    <item>
      <title>在给定 phi 和 theta 的情况下调整 ARMA(1,1) 模拟的 sd</title>
      <link>https://stats.stackexchange.com/questions/636106/adjusting-sd-for-an-arma1-1-simulation-given-phi-and-theta</link>
      <description><![CDATA[我想生成一个均值为零、标准差为 sigma 的 ARMA(1,1) 过程模型，其中我指定 ARMA 参数 phi 和 theta。如何调整高斯分布中的 sigma 值，以便输出具有正确的标准差？在 AR(1) 模型中，对 sd 参数的调整为：
# 所需的 AR1 系数
Φ &lt;- 0.7
# y 中所需的西格玛
西格玛 &lt;- 0.5
# 调整 sigma 以考虑 phi
sigmaAdjusted &lt;- sqrt(sigma^2*(1-phi^2))
n &lt;- 500
y &lt;- arima.sim(model = list(order = c(1,0,0), ar = phi),n = n, sd=sigmaAdjusted)

如何使用 MA1 项调整模型中的 sd 参数？]]></description>
      <guid>https://stats.stackexchange.com/questions/636106/adjusting-sd-for-an-arma1-1-simulation-given-phi-and-theta</guid>
      <pubDate>Thu, 04 Jan 2024 01:48:27 GMT</pubDate>
    </item>
    <item>
      <title>θ、θ星、θ帽子有什么区别和联系？</title>
      <link>https://stats.stackexchange.com/questions/636105/whats-the-difference-and-relationship-between-theta-theta-star-and-theta-hat</link>
      <description><![CDATA[我知道 $\theta$ 是真正的分布参数（这里有很好的解释）。我还知道 $\hat\theta$ 是真实 $\theta$ 的估计器（所以例如，MLE 是 $\hat\theta$ 的示例。
但有时，我也会看到$\theta^*$。它表示什么，与 $\theta$ 和 $\hat\theta$ 的关系是什么？

在搜索过程中，我发现了这个麻省理工学院讲座，似乎对三种类型的 theta 赋予了不同的含义，但我无法真正理解其中的关系。该讲座的幻灯片示例（可在 25:50 上查看）： 


]]></description>
      <guid>https://stats.stackexchange.com/questions/636105/whats-the-difference-and-relationship-between-theta-theta-star-and-theta-hat</guid>
      <pubDate>Thu, 04 Jan 2024 00:50:08 GMT</pubDate>
    </item>
    <item>
      <title>估计不良行为者的数量</title>
      <link>https://stats.stackexchange.com/questions/636104/estimate-number-of-bad-actors</link>
      <description><![CDATA[这可能是一个愚蠢的问题，但它让我难住了。我正在尝试估计系统中不良行为者的数量。
假设我们有 100 个用户，其中一定比例的用户是不良行为者。在我们的系统中，用户正在生成剪辑，假设每个人平均生成 100 个剪辑。不良演员在一定比例的情况下会生成不良剪辑。我想知道有多少坏人。
从我们的数据库中采样剪辑以估计有多少不良演员的最有效方法是什么？我可以随机抽取 100 个剪辑并计算出不良演员的百分比吗？
&lt;小时/&gt;
我已经尝试过这个问题好几次了，但我总是被这样一个事实所困扰：你不知道坏演员会生成的剪辑的分布。我不知道如何克服这个问题并通过采样生成准确的估计。您是否首先需要找到不良演员，并计算他们可能生成的不良剪辑的百分比？]]></description>
      <guid>https://stats.stackexchange.com/questions/636104/estimate-number-of-bad-actors</guid>
      <pubDate>Thu, 04 Jan 2024 00:37:47 GMT</pubDate>
    </item>
    <item>
      <title>WLS 回归的预测区间公式</title>
      <link>https://stats.stackexchange.com/questions/636103/prediction-interval-formula-for-wls-regression</link>
      <description><![CDATA[我一直无法找到非矩阵符号公式来计算加权最小二乘回归的预测区间。对于 OLS，我有
$$y = \hat y \pm t\times \sqrt{\left(\textrm{MSE}\times(1 + 1/n + (x-\bar) x)^2/\sum (x_i-\bar x)^2)\right) }。 $$
我什至有 R 的预测区间值，但似乎无法重现它们。 R 的输出包括SE.fit 和residual.scale 但我不知道如何使用它们。请注意，权重因子未标准化。我尝试过很多事情，包括
y = yhat +/-t* SQRT(MSE*(1/WF + 1/(SUM WFi) + WF*(x-xwbar)^2/SUM(WFi*(xi-xwbar)^2)) ）
其中WF是x估计的权重因子，MSE是R的residual.scale的平方。我也尝试过
y = yhat +/- t* SQRT(MSE + se.fit^2) 使用 R 输出中的 MSE 和 se.fit。
没有任何东西可以再现 R 输出中的预测区间。我将不胜感激任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/636103/prediction-interval-formula-for-wls-regression</guid>
      <pubDate>Wed, 03 Jan 2024 23:42:47 GMT</pubDate>
    </item>
    <item>
      <title>从 GLMER 模型计算标准化回归系数</title>
      <link>https://stats.stackexchange.com/questions/636101/calculating-standardised-regression-coefficients-from-glmer-model</link>
      <description><![CDATA[我有三个独立的 glmer 模型，调查三个不同空间位置的个人和家庭层面的疟疾感染风险因素：1) 森林外，2) 森林边缘，3) 森林内。
我想要对不同空间位置的系数的相对重要性进行粗略比较，即系数的排名。
我一直在阅读《计算标准化Logistic回归系数的六种方法》梅纳德（2004）。 美国统计学家，卷。 58号第3号，其中明确指出，对于系数的简单排序（和比较），文中提到的任何方法都是可以接受的。因此，最简单的方法是将非标准化系数乘以该系数所指的预测变量的标准差。
但是，我不知道如何从 lmer 输出中提取系数的标准差。谁能给点建议吗？
其次，我在另一个论坛上读到了一篇未引用的帖子，其中提到一种可接受的、快速且肮脏的比较方法是对汇总输出中的 Wald 卡方求和，然后取每个变量的 Wald 卡方并将其除以总和。这是可以接受的措施吗？如果有的话，有什么参考资料吗？
我更喜欢前一种方法，但我需要帮助提取标准差。]]></description>
      <guid>https://stats.stackexchange.com/questions/636101/calculating-standardised-regression-coefficients-from-glmer-model</guid>
      <pubDate>Wed, 03 Jan 2024 23:05:57 GMT</pubDate>
    </item>
    <item>
      <title>使用蒙特卡罗模拟进行 Skip-Bo 博弈分析 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636089/skip-bo-game-analysis-using-monte-carlo-simulation</link>
      <description><![CDATA[我正在开展一个项目，探索纸牌游戏 Skip-Bo 中机会与技巧的影响。具体来说，我有兴趣了解玩家牌堆的大小如何影响游戏的结果。我的假设是，牌堆越小（例如，每个玩家 3 张牌），游戏就越依赖机会，这对于不同技能水平的玩家来说更加公平。相反，对于更大的牌堆，我怀疑技能和策略发挥更大的作用，可能有利于更有经验的玩家。
为了研究这个问题，我开始用 Python 编写蒙特卡罗模拟。这是我目前的方法：
随机导入

defsimulate_skip_bo（num_games，pile_size，skilled_player_advantage）：
    win_counts = {&#39;熟练玩家&#39;：0，&#39;新手玩家&#39;：0}

    对于 _ 在范围内（num_games）：
        熟练玩家堆 = 堆大小
        新手玩家堆 = 堆大小

        而 Skilled_player_pile &gt; 0 和 novice_player_pile &gt; 0:
            如果 random.random() &lt;熟练玩家优势：
                熟练玩家堆 -= 1
            别的：
                新手玩家堆 -= 1

        如果熟练玩家堆== 0：
            win_counts[&#39;熟练玩家&#39;] += 1
        别的：
            win_counts[&#39;新手玩家&#39;] += 1

    返回获胜次数

# 模拟参数
游戏数量 = 10000
小堆大小 = 3
熟练玩家优势 = 0.6

# 模拟小桩游戏
small_pile_results=simulate_skip_bo(num_games,small_pile_size,skilled_player_advantage)
打印（小堆结果）

我很确定代码没有回答问题，但我也不知道如何解决它。我该如何解决这个问题？
编辑
玩法如下：

设置：每位玩家都会收到一堆 30 张牌（“库存牌”）。该叠牌的顶牌翻面朝上。剩余的牌在游戏区域的中心形成抽牌堆。

目标：目标是成为第一个耗尽库存的玩家。这是通过将库存牌、手牌或弃牌堆中的牌打到中央游戏区的建筑牌堆上来实现的。

游戏玩法：

在每回合开始时，玩家从中央抽牌堆中抽牌，以拥有五张牌。
玩家可以将手牌、库存堆或弃牌堆中的牌打到中心的四个建筑堆中的任意一个上。
构建牌堆必须从“1”牌或 Skip-Bo（百搭）牌开始，然后按顺序构建到“12”。
如果玩家无法打出任何牌，则必须将一张牌丢弃到其四个个人弃牌堆之一中。


建造桩：

中央建筑桩由所有玩家共享。
每堆必须以“1”或 Skip-Bo 卡开始，用作通配符。
玩家按升序添加到牌堆中，直到达到“12”。
已完成的桩（达到“12”）将从中心区域移走，为新桩腾出空间。


丢弃一堆：

每个玩家最多可以拥有四个弃牌堆。
废弃的牌稍后可以打到中央建筑堆上。
策略对于决定丢弃哪张牌非常重要。


获胜：第一个成功打出库存中所有牌的玩家将赢得游戏。当这种情况发生时，无论其他玩家的位置如何，游戏都会立即结束。

]]></description>
      <guid>https://stats.stackexchange.com/questions/636089/skip-bo-game-analysis-using-monte-carlo-simulation</guid>
      <pubDate>Wed, 03 Jan 2024 19:25:43 GMT</pubDate>
    </item>
    <item>
      <title>statsmodels 中的移动平均模型使用什么数学公式？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636035/what-math-formula-is-utilized-in-statsmodels-for-the-moving-average-model</link>
      <description><![CDATA[从维基百科，我检查了移动平均模型定义和方程。

我知道这与移动平均线不同。
我尝试检查 statsmodels 的移动平均模型的实现，以查看是否使用了上述数学方程。
https://github.com/statsmodels /statsmodels/blob/main/statsmodels/tsa/statespace/sarimax.py
但是，很难检查使用什么方程来计算移动平均系数。我相信我对移动平均模型的了解还不够。
有人知道这个吗？预先感谢您。]]></description>
      <guid>https://stats.stackexchange.com/questions/636035/what-math-formula-is-utilized-in-statsmodels-for-the-moving-average-model</guid>
      <pubDate>Wed, 03 Jan 2024 06:15:29 GMT</pubDate>
    </item>
    <item>
      <title>ADI 和 CoV - 根据数据集移动阈值？</title>
      <link>https://stats.stackexchange.com/questions/635954/adi-and-cov-move-thresholds-based-on-dataset</link>
      <description><![CDATA[我目前正在从事需求预测工作。在网上研究期间，我了解到用于需求分类的方法，这有助于我们专注于具有更好预测能力的系列等。因此，需求的分类主要基于变异系数（CoV）、平均需求间隔（ADI） ）。这引导我们进行 ABC XYZ 细分等分析和需求分类，例如 - 间歇性、块状、不稳定、平滑等。
只有当它们具有固定的阈值（就像我经常在网上看到的那样）并且它们都使用相同的阈值截止值（至少基于我在网上曝光的文章）时，上述所有方法才有意义吗？您可以参考 此处和此处
1.需求平稳（ADI &lt; 1.32 且 CV² &lt; 0.49）
2.间歇性需求（ADI≥1.32且CV²＜0.49）
3.需求不稳定（ADI&lt;1.32且CV²&gt;=0.49）
4.块状需求（ADI &gt;= 1.32 且 CV² &gt;= 0.49）
所以，我的问题，
a) 是否应该提醒这些阈值以反映我们的数据集？例如：我可以在 CV 上运行 1D-Kmeans 聚类并识别数据中的自然中断，以得出 XYZ 分割或需求分类 ADI 或 CV**2？例如，我得到 0.95、2.6 和 3.31 作为 X、Y 和 Z 的 CoV 值限制。平均 CoV 为 1.67。这是正确的做法还是我应该遵守网上给出的固定限制？
b) 我们是否应该仅考虑活跃期（非零销售时间段）或完整时间段（使用客户不活跃的时间段）来计算平均销售额]]></description>
      <guid>https://stats.stackexchange.com/questions/635954/adi-and-cov-move-thresholds-based-on-dataset</guid>
      <pubDate>Mon, 01 Jan 2024 12:16:42 GMT</pubDate>
    </item>
    <item>
      <title>如何计算比例的 MDE？</title>
      <link>https://stats.stackexchange.com/questions/623502/how-to-calculate-mde-for-proportions</link>
      <description><![CDATA[在进行 AB 测试时，我们使用功效分析来计算样本大小以及 alpha、功效和 MDE（最小可检测效应）参数。
连续变量的平均 MDE 似乎很直观：使用 Cohen&#39;s D 计算标准化平均差 = (M1-M2)/合并 SD
如果我有比例，计算 MDE 的好方法是什么？考虑到我们想要检测 5% MDE，如何以相反的方式知道如何将其转化为实际的相对变化？
例如。基线转化率为 10%，我们想要检测相对 10% 的提升（又名 10% *1.1 = 11% 转化率），什么是 MDE？如果我们想检测 5% MDE，我们可以检测到基线转化率的相对变化是多少？]]></description>
      <guid>https://stats.stackexchange.com/questions/623502/how-to-calculate-mde-for-proportions</guid>
      <pubDate>Tue, 08 Aug 2023 15:06:11 GMT</pubDate>
    </item>
    <item>
      <title>时间序列变化点检测</title>
      <link>https://stats.stackexchange.com/questions/611583/change-point-detection-of-time-series</link>
      <description><![CDATA[目前，我正在开展一个研究项目，涉及使用数据挖掘来预测电力消耗。在我的分析中，我使用“AMOC”、PELT、“数据集的变化点包检测了时间序列的变化点”。和“BinSeg”方法。对于每种方法，我都使用了 var、mean 和meanvar。然而，我在识别2020年疫情期间发生的变化点时遇到了问题。
库（readxl）
图书馆（变更点）
tsdata &lt;- ts(mydata$DOM, 开始 = c(1997,1), 频率 = 12)
amoc_cp &lt;- cpt.var(tsdata, method = &quot;AMOC&quot;)
amoc_cp &lt;- cpt.mean(tsdata, method = &quot;AMOC&quot;)
amoc_cp &lt;- cpt.meanvar(tsdata, method = &quot;AMOC&quot;)

 # 使用PELT方法检测时间序列中的变化点，使用上面的var、mean和meanvar
pelt_cp &lt;- cpt.meanvar(tsdata, method = &quot;PELT&quot;)

 # 使用 BinSeg 方法使用 var 、mean 和meanvar 检测时间序列中的变化点
Binseg_cp &lt;- cpt.meanvar(tsdata, method = &quot;BinSeg&quot;)


 # 使用AMOC方法打印每个变化点的位置和值
for (i in 1:length(amoc_cp@cpts)) {
+ cat(“AMOC diff 变化点”, i, “位于位置”, amoc_cp@cpts[i], “有值”, tsdata[amoc_cp@cpts[i]], “\n”)

# 绘制具有变化点的时间序列
图（tsdata，main =“具有 AMOC_MEAN 变化点的时间序列”）
# 在变化点的位置添加垂直线
abline(v = 索引(tsdata)[ amoc_cp@cpts], col = “蓝色”)

这些代码没有将可见的变化点识别为

当对微分时间序列运行上述代码时，它清楚地表明 2020 年 3 月有一个变化点，不是也应该表明原始数据集吗？如果是这样，我该如何统计 2020 年的变化？]]></description>
      <guid>https://stats.stackexchange.com/questions/611583/change-point-detection-of-time-series</guid>
      <pubDate>Sun, 02 Apr 2023 16:49:19 GMT</pubDate>
    </item>
    </channel>
</rss>