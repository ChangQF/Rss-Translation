<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 21 Jun 2024 09:15:29 GMT</lastBuildDate>
    <item>
      <title>不同长度合规率（按时间段）的单因素方差分析</title>
      <link>https://stats.stackexchange.com/questions/649647/one-way-anova-on-compliance-rates-by-time-period-with-different-lengths</link>
      <description><![CDATA[我对此有点困惑，因为在我的统计课上，我们很好地打包了数据，其中包含易于理解的良好、正常数据！如果这看起来太明显，请原谅。
我的数据是几个审计期 (AP) 中几类员工的一系列合规率。我们会说他们应该执行的操作是上班时刷卡。当然，合规率是他们实际刷卡的次数/他们预期刷卡的次数。
我有三个日期组要比较，但它们的长度各不相同，因为我们试图展示 COVID 期间和之后的合规性。每四个月测量一次数据，因此一年有三个 AP，从 11 月开始：

AP 1：11 月 1 日至 3 月 31 日
AP 2：4 月 1 日至 6 月 30 日
AP 3：7 月 1 日至 10 月 31 日

我正在观察 2018 年 11 月至 2022 年 10 月的数据，拆分如下：
日期组 1（COVID 之前，基线/对照）：

AP-1，2018 年 11 月 - 2019 年 3 月 31 日
AP-2，2019 年 4 月 1 日 - 2019 年 6 月 30 日
AP-3，2019 年 7 月 1 日 - 2019 年 10 月 31 日
AP-1，11 月 1 日2019 年 - 2020 年 3 月 31 日 [12 个月，共 4 个时间段]

日期组 2 (COVID)：

AP-2，2020 年 4 月 1 日 - 2020 年 6 月 30 日
AP-3，2020 年 7 月 1 日 - 2020 年 10 月 31 日
AP-1，2020 年 11 月 1 日 - 2021 年 3 月 31 日
AP-2，2021 年 4 月 1 日 - 2021 年 6 月 30 日
AP-3，2021 年 7 月 1 日 - 2021 年 10 月 31 日 [20 个月，共 5 个时间段]

日期组 3 (后疫情时代)：

AP-1，2020 年 11 月 1 日2021 - 2022 年 3 月 31 日
AP-2，2022 年 4 月 1 日 - 2022 年 6 月 31 日
AP-3，2022 年 7 月 1 日 - 2022 年 10 月 31 日 [9 个月，共 3 个时期]

所有类别员工的数据合计如下所示。



组
AP 代码
刷卡
总计条目
合规性




1
2019-1
1019
1231
0.790


1
2019-2
782
878
0.788


1
2019-3
934
1132
0.793


1
2020-1
973
1151
0.821


2
2020-2
640
749
0.834


2
2020-3
901
1075
0. 810


2
2021-1
952
1122
0.816


2
2021-2
674
807
0.800


2
2021-3
841
1001
0.804


&lt; td&gt;3
2022-1
727
857
0.820


3
2022-2
733
887
0.784


3
2022-3
868
1041
0.801



我想要使用方差分析来查看日期组 1（COVID 之前）与日期组 2 和 3（COVID 和 COVID 之后）之间的合规率是否存在显著差异。使用单向方差分析是解决方案吗？询问是因为我不习惯处理费率，而是“这是花瓣的长度”。如果有帮助的话，使用 R 工作。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649647/one-way-anova-on-compliance-rates-by-time-period-with-different-lengths</guid>
      <pubDate>Fri, 21 Jun 2024 08:33:58 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 算法预测中的中性数</title>
      <link>https://stats.stackexchange.com/questions/649645/neutral-number-in-xgboost-algorithm-prediction</link>
      <description><![CDATA[机器学习算法中是否存在“中性数”的概念？
说得更清楚一点：假设我们有一个只有一个特征的逻辑回归，那么“中性数”就是该特征的值，该特征的输出预测概率等于目标为 1 的观测值与数据集中总观测值的比率。
问题是：是否有可能为具有多个特征的决策树定义一个“中性数”？那么基于 XGBoost 的预测模型呢？
我的最终目标是使用一个在 N 个特征上训练的模型，其中 M 个（当然 M &lt; N）在我的预测过程的“早期阶段”是未知的（因此它们不是缺失的，它们只是“未知的”）。
最后一个澄清（或约束）：我不需要“新的”在原始数据集上训练的模型不包括 M 个未知特征，我想利用已经训练好的模型（因为我需要我的“早期预测”更接近“最终预测”）。
提前感谢您的帮助]]></description>
      <guid>https://stats.stackexchange.com/questions/649645/neutral-number-in-xgboost-algorithm-prediction</guid>
      <pubDate>Fri, 21 Jun 2024 07:49:29 GMT</pubDate>
    </item>
    <item>
      <title>统计学中的经验法则含义</title>
      <link>https://stats.stackexchange.com/questions/649644/rule-of-thumb-meaning-in-statistics</link>
      <description><![CDATA[我想知道统计学中“经验法则”一词的实际含义。为什么他们选择这个名称来计算样本量？它是否像是一种基于实践而非理论的近似值？]]></description>
      <guid>https://stats.stackexchange.com/questions/649644/rule-of-thumb-meaning-in-statistics</guid>
      <pubDate>Fri, 21 Jun 2024 07:46:05 GMT</pubDate>
    </item>
    <item>
      <title>最佳解决方案未重复 - metaMDS 没有可靠的结果？</title>
      <link>https://stats.stackexchange.com/questions/649643/best-solution-was-not-repeated-no-reliable-result-for-metamds</link>
      <description><![CDATA[我拥有丰富的蜘蛛数据，这些数据是我在不同林地中捕获的，我想执行 NMDS。它通常有效，尽管压力值相对较高。但是，我收到消息说最佳解决方案无法重复。

```Spiders_NMDS &lt;- metaMDS(nmds_data[,7:54], k = 2, distance = &quot;horn&quot;, trymax= 100, maxit=1000 )

以下是输出的最后几行：
Run 100 stress 0.2085273
... Procrustes: rmse 0.008630914 max resid 0.05303693
*** 最佳解决方案未重复 -- monoMDS 停止标准：
100：压力比 &gt; sratmax

以及 print(Spiders_NMDS) 的输出
metaMDS(comm = nmds_data[, 7:54], distance = &quot;horn&quot;, k = 2, trymax = 100, maxit = 1000)

使用 monoMDS 进行全局多维缩放

数据：wisconsin(nmds_data[, 7:54])
距离：horn

维度：2
压力：0.208454
压力类型 1，弱关系
最佳解决方案在 100 次尝试后未重复
最佳解决方案来自第 75 次尝试（随机开始）
缩放：居中、PC 旋转、半变化缩放
物种：基于‘wisconsin(nmds_data[, 7:54])


我在另一个论坛上看到，依赖这些数据并将其用于进一步分析在统计上并不有效。是这样吗？毕竟，官方 R 网站表示您仍然可以使用这些数据，但上述论坛的担忧肯定不是毫无根据的……请参阅：https://stackoverflow.com/questions/741 ... -nmds-in-r
不幸的是，R 针对这个问题给出的建议对我没有帮助。参见：https://rdrr.io/cran/vegan/man/metaMDS.html（“结果无法重复”部分）
例如，我已经增加了 maxit 和 trymax，但仍然输出该消息。我还用 previous.best 运行了另一次迭代
metaMDS(nmds_data[,7:54], k = 2, distance = &quot;horn&quot;,trymax= 100, maxit= 100, previous.best = Spiders_NMDS)
但是，这也不会改变输出。
增加维度也不会带来任何变化，例如，在可视化方面没有用，对吗？
有人有这个问题的经验吗？有没有办法获得更可靠的结果？
我想继续使用 envfit 函数....
我的数据集通常包含许多零，并且可能有许多陷阱彼此之间的距离非常大（不共享任何物种）...也许这很重要？
感谢您的反馈 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/649643/best-solution-was-not-repeated-no-reliable-result-for-metamds</guid>
      <pubDate>Fri, 21 Jun 2024 07:44:57 GMT</pubDate>
    </item>
    <item>
      <title>宏观计量经济学 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/649642/macroeconometric</link>
      <description><![CDATA[保持静止。你能帮我吗
]]></description>
      <guid>https://stats.stackexchange.com/questions/649642/macroeconometric</guid>
      <pubDate>Fri, 21 Jun 2024 07:22:07 GMT</pubDate>
    </item>
    <item>
      <title>线性混合模型中固定效应的估计[关闭]</title>
      <link>https://stats.stackexchange.com/questions/649640/estimates-for-fixed-effects-in-linear-mixed-models</link>
      <description><![CDATA[第一次发帖，请原谅错误。我的问题是关于具有标准规范的线性混合模型：
y=XB + Zu + e
例如，请参阅维基百科：https://en.wikipedia.org/wiki/Mixed_model
有人可以解释一下为什么 SAS proc combined 不输出 B 系数及其标准误差，就像在标准回归输出中一样？
B 参数是一个有意义的统计量（底层统计模型中的可识别参数），在许多问题中测试它是有意义的。我相信，如果您假设随机效应的误差和正态分布为正态分布，则应该存在最大似然估计量。如有必要，请纠正我。
那么为什么 SAS 不能返回 B 成分的相应估计值和标准误差，并让您进行 Wald 检验呢？为什么它只提供 III 型方差分析？为什么您只能得到奇怪的“估计”和“对比”？
我相信其他人也对此感到疑惑。感谢您的帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/649640/estimates-for-fixed-effects-in-linear-mixed-models</guid>
      <pubDate>Fri, 21 Jun 2024 04:13:28 GMT</pubDate>
    </item>
    <item>
      <title>最大值的统计意义</title>
      <link>https://stats.stackexchange.com/questions/649634/the-statistical-significance-of-the-maximum-value</link>
      <description><![CDATA[问：给定一个值列表，我如何计算最大值的统计显著性？
我的考虑：我们可以计算最大值的 z 分数。
直观地讲，z 分数越高，最大值越显著。
但是，在我看来，默认的备选假设是“该值大于平均值”，与“最大值”没有直接关系。
根据@Glen_b的评论，我将丰富我的问题。
观察：值列表$x_1, x_2, \ldots, x_n$，其中 WLOG $x_1 = \max_i x_i$
假设：每个$x_i$都是来自平均值$\mu_i$和未知标准差$\sigma_i$的分布的样本
零假设： $\mu_1 \neq \max_i \mu_i$
备选假设： $\mu_1 = \max_i \mu_i$
有更好的选择吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649634/the-statistical-significance-of-the-maximum-value</guid>
      <pubDate>Fri, 21 Jun 2024 01:50:09 GMT</pubDate>
    </item>
    <item>
      <title>在数据集上使用哪种统计测试</title>
      <link>https://stats.stackexchange.com/questions/649635/which-stats-test-to-use-on-dataset</link>
      <description><![CDATA[我有一个非参数数据集，其中包含两个分类独立变量（治疗：对照、UVB 阻断、凡士林和环境：室外、温带和热带）和一个连续因变量（温度）。哪种统计测试最适合此目的，最好进行事后比较？
谢谢！
尝试过 ARTanova 和 SRH，我认为 ARTanova 不适合，SRH 不够强大。]]></description>
      <guid>https://stats.stackexchange.com/questions/649635/which-stats-test-to-use-on-dataset</guid>
      <pubDate>Fri, 21 Jun 2024 01:16:38 GMT</pubDate>
    </item>
    <item>
      <title>对于小样本量和右偏数据的均值差异的理想检验/p值计算？</title>
      <link>https://stats.stackexchange.com/questions/649632/ideal-test-p-value-calculation-for-difference-in-means-with-small-sample-size-an</link>
      <description><![CDATA[我需要比较两个不同组之间的响应变量。我的对照组有 205 个观测值，而我的比较组只有 2 个观测值（不幸的是，这是我正在处理的数据的性质，我无法获得更多观测值）。哪些方法可能适合获取均值差异的 p 值？响应变量具有右偏性，并且在 0 和 1 之间连续。我正在寻找不同的方法来处理这个问题，我担心一个组只有 2 个观测值会限制我的选择。它排除了修剪均值检验，并且重采样具有很高的方差。]]></description>
      <guid>https://stats.stackexchange.com/questions/649632/ideal-test-p-value-calculation-for-difference-in-means-with-small-sample-size-an</guid>
      <pubDate>Fri, 21 Jun 2024 00:48:12 GMT</pubDate>
    </item>
    <item>
      <title>解释 PACF 图以选择正确的滞后（AR 模型阶数）</title>
      <link>https://stats.stackexchange.com/questions/649630/interpret-the-pacf-plot-to-select-the-correct-lag-ar-model-order</link>
      <description><![CDATA[我想为食品价格通胀系列选择滞后（AR 模型阶数）。
AIC 给出 4。
SIC 给出 3。
此外，我还打印了它的 PACF 图。
我如何解释 PACF 图以选择正确的滞后？
]]></description>
      <guid>https://stats.stackexchange.com/questions/649630/interpret-the-pacf-plot-to-select-the-correct-lag-ar-model-order</guid>
      <pubDate>Thu, 20 Jun 2024 22:38:38 GMT</pubDate>
    </item>
    <item>
      <title>通过限制随机化来实现协变量平衡如何导致未观察变量的不平衡？</title>
      <link>https://stats.stackexchange.com/questions/649609/how-can-restricted-randomization-to-achieve-covariate-balance-lead-to-imbalance</link>
      <description><![CDATA[在文献中，实验设计被认为是协变量平衡和稳健性之间的权衡。例如，Harshaw 等人 (2024) 写道

为了使估计量更精确，实验者有时会限制随机化以实现治疗组之间的协变量平衡。这种方法的一个问题是，即使观察到的特征相似，未观察到的特征（包括潜在结果）在组之间可能不相似。 [...]
实验者必须权衡随机性赋予的稳健性与平衡预测重要协变量可能带来的精度提升。

这意味着减少协变量不平衡的方法（阻断、匹配对、重新随机化等）可能会意外导致未观察变量的差异大于完全随机化设计。
问题：
我不明白平衡协变量如何使另一个未观察变量变得不相似。您能否举一个玩具示例，说明平衡一个协变量会使未观察变量变得不相似？
我的想法：
如果我们使用受限随机化来平衡协变量，任何正/负相关的未观察变量也会变得更平衡。对于不相关的变量，它们不会比完全随机化设计更平衡，但也不会更差。]]></description>
      <guid>https://stats.stackexchange.com/questions/649609/how-can-restricted-randomization-to-achieve-covariate-balance-lead-to-imbalance</guid>
      <pubDate>Thu, 20 Jun 2024 16:37:02 GMT</pubDate>
    </item>
    <item>
      <title>概率的尾部界限是否可以转化为期望的界限？</title>
      <link>https://stats.stackexchange.com/questions/649605/do-tail-bounds-on-probability-translate-into-bounds-on-expectations</link>
      <description><![CDATA[假设我有一个形式为：
$$P(X \geq t) \leq \exp(-t^2).$$
我能说说$X$、$E[X]$的期望吗？具体来说，我能否得到 $E[X]$ 的界限？
这是我感兴趣的具体情况，在这些笔记中发现的非参数回归集中不等式：https://www.mit.edu/~rakhlin/courses/mathstat/rakhlin_mathstat_sp22.pdf#page=67.09
给定一个固定的数据集 $x_i$ 和函数 $f$，将经验范数定义为
$$\|f\|_n^2 = \frac{1}{n}\sum_i f(x_i)^2.$$
第 71 页的定理 6 证明了 ERM 估计量 $\hat{f}$ 的 $f$ 的界限，该界限以临界半径 $\delta_n$ 和任意常数 $s$ 为依据：
$$P(\|\hat{f} - f\|_n^2 \geq 16s\delta_n^2) \leq \exp \left(-\frac{ns\delta_n^2}{2}\right),$$
并声称该结果意味着期望的界限：
$$E \|\hat{f} - f\|_n^2 \leq C\left(\delta_n^2 + \frac{1}{n}\right).$$
我无法弄清楚期望的界限如何从尾部概率的界限得出。]]></description>
      <guid>https://stats.stackexchange.com/questions/649605/do-tail-bounds-on-probability-translate-into-bounds-on-expectations</guid>
      <pubDate>Thu, 20 Jun 2024 15:19:58 GMT</pubDate>
    </item>
    <item>
      <title>这个公式是如何推导出来的</title>
      <link>https://stats.stackexchange.com/questions/649598/how-is-this-formula-derived</link>
      <description><![CDATA[我进行了多次重复实验，我的程序返回了 EC50 及其 CI(95%) 置信区间、LogEC50 和 (LogEC50) 标准误差的值。这些对数来自 Hill 方程。在这种情况下，标准误差指的是曲线拟合，而不是 SEM。
根据 Cochrane 指南，我根据 EC50 值和 CI 计算了 SD。 https://handbook-5-1.cochrane.org/chapter_7/7_7_3_2_obtaining_standard_deviations_from_standard_errors_and.htm
我也在这里读到（https://www.ncbi.nlm.nih.gov/books/NBK91994/），可以通过将 LogEC50 的误差乘以 来计算估计值的拟合误差（百分比）将其乘以 ln(10) * 100：
%FE(EC50)= FE(Log(EC50))*​​ln(10)*100
据此我假设您可以通过将 EC50 乘以 FE(Log(EC50))*​​ln(10) 来推断绝对拟合误差。
我得到的值似乎与之前计算的 SD 非常吻合。
我不明白的是这个公式实际上做了什么
我知道 Log10(EC50) 可以重写为 ln(EC50)/ln10，所以我猜 ln(10) 会抵消，但之后呢。
我理解，由于 SE(Log(EC50)) 是从 Log(EC50) 中添加和减去的，因此我们将绝对值乘以误差值是有道理的（log(xy)=log(x)+log(y) 等等）。我似乎无法将这种直觉与公式中实际发生的事情联系起来
提前致谢]]></description>
      <guid>https://stats.stackexchange.com/questions/649598/how-is-this-formula-derived</guid>
      <pubDate>Thu, 20 Jun 2024 13:56:35 GMT</pubDate>
    </item>
    <item>
      <title>合成控制方法：单位权重、预测变量权重和 p 值</title>
      <link>https://stats.stackexchange.com/questions/649570/synthetic-control-method-units-weights-predictors-weights-and-p-values</link>
      <description><![CDATA[我正在使用 R 包“synth”，有 2 个快速问题：

我的捐赠池中有大约 100 个单位。在一些分析中，许多单位被分配了大于 0 的权重。大约有 4-5 个单位的权重较大（例如 0.30 或 0.40），但其余许多单位的权重非常小，大于 0（例如 0.001 或 0.003）。这是否表明我的模型存在问题？我在几篇论文中看到，只有少数单位被分配了大于 0 的权重。

我将结果用作治疗前期的预测因子。在某些情况下，我发现它的权重大于 0.90。我想这是有道理的，但这正常吗？那我为什么要使用其他预测因子呢？


谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649570/synthetic-control-method-units-weights-predictors-weights-and-p-values</guid>
      <pubDate>Thu, 20 Jun 2024 08:00:30 GMT</pubDate>
    </item>
    <item>
      <title>频率派预测方法是否忽略了参数值的不确定性？</title>
      <link>https://stats.stackexchange.com/questions/620113/does-the-frequentist-approach-to-forecasting-ignore-uncertainty-in-the-parameter</link>
      <description><![CDATA[我正在审查我们新的本科课程《贝叶斯统计方法》的教科书。在 Ben Lambert 的书《学生贝叶斯统计指南》第 7 章中，他指出

由于我们的模型中包含两个不确定性来源——参数不确定性和抽样变异性——贝叶斯预测分布的不确定性通常大于频率学派的不确定性。这是因为频率学派的预测方法通常基于参数的点估计（通常是最大似然值）进行预测。通过忽略参数值中的任何不确定性，频率派方法产生的预测区间过于自信。

[强调我的]
然后在章节摘要中重申：

通过将参数值中的认知不确定性作为预测的一部分，这种贝叶斯方法比等效的频率派方法更好地量化了不确定性。

如果不详细阐述这本书是如何写成的，以表明贝叶斯的一切都是好的和正确的（因此频率派的一切都是坏的和不正确的），我发现自己需要反驳这一说法。
虽然我相信我知道这个名义问题的答案，但也许我的理解是错误的......我想把它放在这里征求社区的反馈。
作为我如何相信这个断言的一个例子书中的说法不正确，我将使用多元回归的一个例子。如果你想从模型中估计一个值，则有以下公式
$$\hat{y}_o = \beta_0 + \beta x_o$$
（其中 $\beta$ 和 $x_o$ 可能是向量）。如果您希望将此估计值用作给定 $X=x_o$ 值的条件均值，则 $\hat{y}_o$ 将是点估计值，条件均值的置信区间将是
$$\hat{y}_o + t_\text{c.v.} \cdot \hat{\sigma} \sqrt{x_o^T (X·X^T)^{-1} x_o}$$
（针对上下文和所需置信水平的适当临界值）。
但是，如果您想要预测（置信）区间，则可以使用以下内容：
$$\hat{y}_o + t_\text{c.v.} \cdot \hat{\sigma} \sqrt{1 + x_o^T (X·X^T)^{-1} x_o}$$
...除非我错了，否则开方数捕捉到了作者声称不存在的“认知不确定性”。1 模拟了分布的变异性，而第二项模拟了参数估计的变异性（因为它不被认为是预测区间估计的固定值）。
同样，如果我错了，或者在其他情况下这种对频率学派方法的批评确实有效...请分享。]]></description>
      <guid>https://stats.stackexchange.com/questions/620113/does-the-frequentist-approach-to-forecasting-ignore-uncertainty-in-the-parameter</guid>
      <pubDate>Thu, 29 Jun 2023 23:30:47 GMT</pubDate>
    </item>
    </channel>
</rss>