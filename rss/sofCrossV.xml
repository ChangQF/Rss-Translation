<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 06 Mar 2024 21:12:03 GMT</lastBuildDate>
    <item>
      <title>两个随机向量之间的协方差可以生成标量吗？ [复制]</title>
      <link>https://stats.stackexchange.com/questions/642007/can-the-covariance-between-two-random-vectors-result-into-a-scalar</link>
      <description><![CDATA[这是矩阵正态分布的参数。然而，我似乎没有正确理解向我提出的答案。更准确地说，我似乎缺少两个随机向量之间协方差的定义。我的问题是：如果我们将 $\textbf{U}_{ij}$ 解释为 $i$ 之间的协方差第  行和第 $j$ 行，如何将其视为标量？
感谢任何帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/642007/can-the-covariance-between-two-random-vectors-result-into-a-scalar</guid>
      <pubDate>Wed, 06 Mar 2024 20:39:44 GMT</pubDate>
    </item>
    <item>
      <title>依次缩小模型</title>
      <link>https://stats.stackexchange.com/questions/642004/reduce-the-model-sequentially</link>
      <description><![CDATA[我收到了一个方差分析表，并要求按顺序缩小模型。

这里，Mix 和 Plasticizer 是两个主要效果，Run 是块因子，因此是随机效果。
我搜索了在线资源，说：当按顺序减少模型时，您通常首先评估高阶项的重要性，然后在必要时继续评估低阶项。解决方案给出的顺序为：增塑剂*混合、增塑剂、运行*混合
关于为什么按这个顺序有什么想法吗？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642004/reduce-the-model-sequentially</guid>
      <pubDate>Wed, 06 Mar 2024 20:26:49 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归；协变量相互影响预测结果</title>
      <link>https://stats.stackexchange.com/questions/642003/logistic-regression-covariates-effect-on-each-other-predicting-the-outcome</link>
      <description><![CDATA[我有一个逻辑回归模型，其中我的结果变量是一种具有“是”和“否”结果的疾病。我们知道，年龄与这种疾病高度相关。我有一种感兴趣的蛋白质的数据，想看看这种蛋白质 P 是否与该疾病有关。当我在逻辑模型（R 中）中单独使用蛋白质作为预测变量时，我得到了显着的 p 值。但当我在模型中添加年龄时，我的蛋白质不再显着。
我还研究了我的蛋白质与年龄的相关性，结果是不相关的（相关系数为 0.08）。那么从回归模型中忽略年龄是否安全？
疾病 ~ 蛋白质 # 显着（p 值：0.00003）
疾病 ~ 蛋白质 + 年龄 # 年龄很重要，但蛋白质不再重要（p 值 = 0.2）
]]></description>
      <guid>https://stats.stackexchange.com/questions/642003/logistic-regression-covariates-effect-on-each-other-predicting-the-outcome</guid>
      <pubDate>Wed, 06 Mar 2024 20:19:36 GMT</pubDate>
    </item>
    <item>
      <title>postMDS 在做什么？</title>
      <link>https://stats.stackexchange.com/questions/642002/what-is-postmds-doing</link>
      <description><![CDATA[我试图更好地理解 R 的 vegan 包中的 postMDS 函数实际上在做什么。我尝试阅读文档，但我有一个很难理解它。我还尝试查看 源代码，但它没有似乎正在加载。
任何人都可以用稍微更清晰的术语重新组织文档试图表达的内容吗？我目前的理解水平是，原始相异性分数适合与“足够”相似的点的排序空间。 （由阈值参数确定）。我猜测每个点簇都适合不同的线性模型，但我不确定。我还认为相异分数被视为回归中的响应变量。在那之后，我有点迷失了。任何帮助将不胜感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/642002/what-is-postmds-doing</guid>
      <pubDate>Wed, 06 Mar 2024 20:07:41 GMT</pubDate>
    </item>
    <item>
      <title>具有交互作用的混合效应线性模型的系数解释</title>
      <link>https://stats.stackexchange.com/questions/642000/interpretation-of-coefficients-from-a-mixed-effect-linear-model-with-an-interact</link>
      <description><![CDATA[我从具有交互作用的混合效应线性回归模型中获得以下输出。该模型包括：

连续结果（范围从 590 到 1401）。
组变量（二元；对照与治疗）。
连续协变量（范围从 0 到 1）。
组变量和协变量之间的交互项。

&lt;前&gt;&lt;代码&gt;&gt;总结（测试）
REML 拟合线性混合模型。 t 检验使用 Satterthwaite 方法 [&#39;lmerModLmerTest&#39;]
公式：结果 ~ 组 * 协变量 + (1 | 受试者)
   数据：ex.dat

REML 收敛准则：1942.7

缩放残差：
    最小 1Q 中值 3Q 最大
-2.8484 -0.4493 -0.0084 0.3499 3.8192

随机效果：
 组名称方差标准差
 主题（拦截）20772 144.12
 剩余 4511 67.16
obs 数量：164，组：主题，48

固定效果：
                         估计标准。误差df t值Pr(&gt;|t|)
(截距)833.73 31.85 55.31 26.175＜ 2e-16 ***
组处理 20.95 45.08 55.47 0.465 0.643903
协变量 66.99 18.68 114.30 3.586 0.000496 ***
组处理：协变量 14.14 26.49 114.39 0.534 0.594531
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

在这种情况下：我相信我可以说（+如果这些解释有任何问题，请告诉我。）：

协变量系数 66.99 表示（基线）对照组内协变量每增加一个单位，结果的平均增加。 （重要）
随着协变量每增加一个单位，治疗组的结果平均比对照组高 14.14 个单位。 （不显着）

但是，考虑到组变量的系数及其相应的 p 值，我不确定得出组间不存在显着差异的结论是否合适。
如果我不能根据这个模型得出这样的结论，我应该检查哪个模型或哪个数字来确定对照组和治疗组之间是否存在显着差异？
期待您的来信。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/642000/interpretation-of-coefficients-from-a-mixed-effect-linear-model-with-an-interact</guid>
      <pubDate>Wed, 06 Mar 2024 19:53:27 GMT</pubDate>
    </item>
    <item>
      <title>权衡调查中的问题</title>
      <link>https://stats.stackexchange.com/questions/641999/weighing-questions-within-a-survey</link>
      <description><![CDATA[我在一家公共儿童福利机构工作。我们有一种称为护理水平的工具，可以根据儿童所需的护理量对他们进行分类。这有助于我们为孩子确定适当的护理选择。护理级别1是需要“标准”护理级别的儿童。护理量（这些通常是没有发育迟缓、没有严重行为问题等的儿童）。护理等级 10 是需要持续护理的孩子。
对这些儿童进行分类的护理水平工具本质上是一项关于行为问题、诊断、创伤史、延误以及优势的调查。
我们正在重新设计调查，以更准确地反映儿童的需求，我被要求帮助分配问题的权重，以便分类准确。我没有调查设计、心理测量学或项目反应理论方面的博士学位，甚至没有硕士学位，感觉超出了我的能力范围。有没有人做过类似的事情并且可以分享他们的方法？您有什么值得推荐的书籍或文章吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/641999/weighing-questions-within-a-survey</guid>
      <pubDate>Wed, 06 Mar 2024 19:51:57 GMT</pubDate>
    </item>
    <item>
      <title>LOESS 使用线性混合模型的预测平均值</title>
      <link>https://stats.stackexchange.com/questions/641998/loess-using-predicted-means-from-a-linear-mixed-model</link>
      <description><![CDATA[使用线性混合模型的预测均值通过 LOESS 方法 (geom_smooth) 绘制平滑曲线时，需要考虑哪些方面？我的数据由 12 个时间点的纵向心理量表分数组成。
在观察期间我有大量缺失数据，因此选择使用混合线性模型。但是，我想要以图形方式表示这些分数的演变趋势。我考虑过使用预测均值来考虑缺失数据的估计值。]]></description>
      <guid>https://stats.stackexchange.com/questions/641998/loess-using-predicted-means-from-a-linear-mixed-model</guid>
      <pubDate>Wed, 06 Mar 2024 19:51:20 GMT</pubDate>
    </item>
    <item>
      <title>计算因子设计中方差分析中因子解释的方差</title>
      <link>https://stats.stackexchange.com/questions/641996/calculating-variance-explained-by-factors-in-an-anova-in-a-factorial-design</link>
      <description><![CDATA[我正在对具有三个离散固定因素（具有 10 个水平的治疗 A；具有三个水平的治疗 B；以及 4 个站点）的数据集执行方差分析，其中包括所有可能的相互作用。它是完全正交和平衡的。除了确定处理和交互作用是否具有统计显着性之外，我还想介绍每个因素和交互作用可以解释模型中的多少方差。通过这种方式，我希望能够证明每个因素在确定感兴趣特征时的相对重要性。
正确报告方差分析模型中每个简单项和交互项所描述的方差的简单方法是什么？是像每一项的平方和除以总数一样简单，还是需要根据每一项的级别数进行调整（或更复杂的东西）？]]></description>
      <guid>https://stats.stackexchange.com/questions/641996/calculating-variance-explained-by-factors-in-an-anova-in-a-factorial-design</guid>
      <pubDate>Wed, 06 Mar 2024 19:42:50 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 对紧密关联配对数据的签名排名测试</title>
      <link>https://stats.stackexchange.com/questions/641995/wilcoxon-signed-rank-test-for-heavily-tied-paired-data</link>
      <description><![CDATA[我们进行了一项实验，以测试标有景观特征高度的地图对参与者相对于无人机记录的高度估计的影响。我们要求他们在访问地图之前和之后记录高度，精确到米。除了分析无人机和参与者估计之间的差异（精确到 1m）外，我们还将数据分为三个高度范围：0-25m、25-200m 和 &gt;200m。我们预计，在查看最接近 1m 的数据时，地图前后可能存在差异，但在查看高度带时则不会。响应变量是参与者估计高度带与无人机高度带之间的差异。因此差异可能是 0、1、2，其中参与者可能超出 0 个高度带、1 个高度带等。正如您可能想象的那样，这会在数据中创建很多零和关系，我不确定如何处理这些是在 Wilcoxon 配对分析的背景下进行的。我知道处理绑定观察的不同软件包和方法（Pratt vs Wilcoxon），在考虑发布这个问题之前我已经尽可能多地阅读了，但我不确定的是有多少个零或关系使结果不可靠？当我分析数据时，我发现访问地图之前和之后的高度带估计值存在显着差异。数据集很大，但正如前面提到的，有很多联系。
重现我的数据：
 diff_hband_abs &lt;- c(rep(0, 1515),rep(1, 374),rep(2, 1))
    round_data &lt;- 代表 (c(1, 2), 每个 = 945)
    vp_data &lt;- c(rep(&#39;N&#39;, 1296),rep(&#39;Y&#39;, 594))
    df &lt;- data.frame(DiffHband_abs = diff_hband_abs, Round = round_data, VP = vp_data)

diff_hband_abs = 参与者估计高度带与无人机高度带之间的差异
round_data = 参与者无法访问地图的实验轮次（第 1 轮）和他们有权访问地图的实验轮次（第 2 轮）
vp_data = 我们收集了参与者之前是否曾经进行过鸟类飞行高度调查的信息（如果他们有 vp_data =&#39;Y&#39;；如果没有 vp_data=&#39;N&#39;）。
当对配对数据（包括使用 Pratts 方法处理关系的硬币包中的版本）运行不同的可能函数时，我得到了非常显着的 p 值，并且我不确定是否可以信任由于我的数据的性质，它们。我对这个分析的任何清晰度感兴趣，并且对其他分析的建议也非常受欢迎。我考虑过序数回归，但我的数据违反了比例优势假设。
非常感谢您的时间和考虑。]]></description>
      <guid>https://stats.stackexchange.com/questions/641995/wilcoxon-signed-rank-test-for-heavily-tied-paired-data</guid>
      <pubDate>Wed, 06 Mar 2024 19:16:46 GMT</pubDate>
    </item>
    <item>
      <title>如何推导出协变量平衡倾向得分的 GMM 估计量？</title>
      <link>https://stats.stackexchange.com/questions/641993/how-to-derive-the-gmm-estimator-for-the-covariate-balancing-propensity-score</link>
      <description><![CDATA[Imai 和 Ratkovic (2014) 描述的协变量平衡倾向得分 (CBPS) 涉及使用倾向得分 $\pi_\beta(\mathbf{X}) = P(T = 1\vert\mathbf{X})$ 拟合逻辑回归广义矩方法 (GMM)，使用协变量平衡矩条件来增强逻辑回归的常用矩条件。由于矩条件比要估计的参数多（两倍），系统被过度识别。
以下是 Imai 和 Ratkovic 定义该方法的方式（此处针对平均治疗效果 [ATE]）：
由 $p$ 索引的每个系数的逻辑回归得分条件为
$$s_{\beta_p}(T, \mathbf{X}) = (T - \pi_\beta(\mathbf{X})) X_p$$
平衡力矩条件为
$$w_{\beta_p}(T, \mathbf{X}) = \frac{T - \pi_\beta(\mathbf{X})}{\pi_\beta( \mathbf{X})(1 - \pi_\beta(\mathbf{X}))} X_p$$
当我们叠加这些时，我们得到 GMM 矩条件：
$$g_\mathbf{\beta}(T, \mathbf{X}) = \left(\array{s_{\beta_p}(T, \mathbf{X}) \ \w_{\beta_p}(T, \mathbf{X})} \right)$$
和
$$\bar{g}_\mathbf{\beta}(T, \mathbf{X}) = \frac{1}{N}\sum_{i = 1}^ N{g_\mathbf{\beta}(T_i, \mathbf{X}_i)}$$
他们估计 $\hat{\beta}$ 为
$$\hat{\beta} = \mathop{\arg \min}\limits_{\beta} \bar{g}_\mathbf{\beta}(T, \mathbf {X})^T \Sigma_\beta (T, \mathbf{X})^{-1} \bar{g}_\mathbf{\beta}(T, \mathbf{X})$$
他们使用
$$
\Sigma_\beta (T, \mathbf{X}) = \frac{1}{N}\sum_{i = 1}^N \left(\array{
\pi_\beta(\mathbf{X})(1-\pi_\beta(\mathbf{X}))X_iX_i^T &amp; X_i X_i^T \\
X_i X_i^T &amp; \frac{X_i X_i^T}{\pi_\beta(\mathbf{X})(1-\pi_\beta(\mathbf{X}))}
} \正确的）
$$
我的问题是 $\Sigma_\beta (T, \mathbf{X})$ 的这个表达式是如何导出的？ 他们声称
&lt;块引用&gt;
我们发现该协方差估计量优于矩条件的样本协方差，因为后者不会惩罚大权重。

这似乎与通常的高效 GMM 权重矩阵不同，我认为它是
$$
\Sigma_\beta (T, \mathbf{X}) = \frac{1}{N}\sum_{i = 1}^Ng_\mathbf{\beta}(T_i, \mathbf{X}_i)g_\mathbf {\beta}(T_i, \mathbf{X}_i)^T
$$
但我发现这两者并不相等。那么这个公式从何而来呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/641993/how-to-derive-the-gmm-estimator-for-the-covariate-balancing-propensity-score</guid>
      <pubDate>Wed, 06 Mar 2024 19:11:04 GMT</pubDate>
    </item>
    <item>
      <title>我很难解释方差分析结果</title>
      <link>https://stats.stackexchange.com/questions/641992/i-have-difficulty-interpreting-anovas-results</link>
      <description><![CDATA[我有一个不同生长环境中基因型表现的数据集。我想知道基因型和不同环境之间是否存在相互作用，以及无论环境如何，基因型是否可以彼此区分。
基因型*环境交互作用的方差分析（1）结果如下：
 sum_sq df F PR(&gt;F)
基因型 0.408288 103.0 3.334366 3.181776e-15
环境 2.170352 8.0 228.204205 8.152433e-175
基因型：ENV 0.654210 824.0 0.667842 1.000000e+00
残差 4.277378 3598.0 NaN NaN

这被解释为基因型和环境的贡献在响应变量中显着，但 p 值为 1 时基因型和环境的相互作用并不显着。
但是，如果我仅使用基因型作为变量运行另一个方差分析 (2)，则会得到以下结果：
 sum_sq df F PR(&gt;F)
基因型 0.167824 103.0 0.8209 0.905164
残差 8.683694 4375.0 NaN NaN

p 值为 0.9 表明不同基因型之间没有显着差异。为什么基因型在这里对响应变量没有贡献，但在方差分析 1 中却有贡献？
最后，如果我运行另一个方差分析 (3)，仅考虑基因型和环境之间的相互作用，而不考虑它们各自的项，我会得到：
 sum_sq df F PR(&gt;F)
基因型：ENV 4.860024 935.0 4.372 3.325465e-215
残差 4.277378 3598.0 NaN NaN

解释是基因型和环境相互作用之间存在显着差异，这似乎与方差分析 1 中获得的结果相矛盾。
我想回答的是不同基因型的反应是否存在显着差异。]]></description>
      <guid>https://stats.stackexchange.com/questions/641992/i-have-difficulty-interpreting-anovas-results</guid>
      <pubDate>Wed, 06 Mar 2024 19:01:00 GMT</pubDate>
    </item>
    <item>
      <title>面板数据事件研究</title>
      <link>https://stats.stackexchange.com/questions/641989/panel-data-event-study</link>
      <description><![CDATA[我希望以约 800 家公司为样本，分析冲突对公司估值（使用每日股价）的影响（因果效应）（我目前在约 365 天的样本期内拥有这些数据），因此，面板数据。
我想分析总体影响，但也要确定行业之间影响的差异。
但是，我无法决定使用最合适的方法。我试图通过生成异常收益作为我的因变量来将事件研究方法和固定效应结合起来。以下是我的回归方程：
Yit​ = α + β1​WarDummyit​ + Σβk ​控制k it​+ γj​IndustryDummyjit​+δj​(WarDummyit​×IndustryDummyjit​) + ϵit​

Yit​：因变量；公司 i 在时间 t 的异常收益。
IndustryDummyjit​：代表 20 个行业（制造、IT、服务等）的虚拟人物
WarDummyit​：战争开始前后的事件窗口为 1，否则为 0。
WarDummy×IndustryDummy：战争虚拟人和各个行业虚拟人之间的交互项；这个想法是在控制其他因素的情况下，衡量战争对 j 行业企业的不同影响。

这种方法可以被认为是有效的吗？我曾多次尝试运行它，但我不断收到此错误消息：由于共线性而省略。
这是输出：

感谢任何帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/641989/panel-data-event-study</guid>
      <pubDate>Wed, 06 Mar 2024 18:11:12 GMT</pubDate>
    </item>
    <item>
      <title>频率论概率：我们能否在数学上证明我们设置的概率等于什么，或者它们只是假设/定义？</title>
      <link>https://stats.stackexchange.com/questions/641986/frequentist-probability-can-we-prove-mathematically-what-we-are-setting-probabi</link>
      <description><![CDATA[举个例子，假设我正在模拟骰子的滚动。
我们可以使用概率的频率论定义来定义事件的概率，比如掷出 6，如 $lim_{n\to\infty}$$\frac{ n_6}{n}$，其中 n 是掷骰总数，$n_6$ 是我们获得 6 的次数。
我通常会看到一个逻辑结论，好吧，这个数字显然是 1/6，换句话说，如果我们（无限）多次掷骰子，我们会得到 6 1/6 的时间。所以我们定义 P(6) = 1/6。
我并不是质疑这个逻辑——这对我来说显然是常识。然而我想知道的是——理论上我们不知道这是真的吗？也就是说，我们不能无限次地掷骰子。那么，真正的极限是不是就不可能变成别的东西了呢？基本上，我们是否只是从逻辑上推论这是正确的（或者通俗地说，对于我们的目的而言“与真实一样好”）并定义这是概率，还是实际上存在概率更深入的数学证明理论/统计数据可以让我们根据起始假设得出 1/6 的结论？]]></description>
      <guid>https://stats.stackexchange.com/questions/641986/frequentist-probability-can-we-prove-mathematically-what-we-are-setting-probabi</guid>
      <pubDate>Wed, 06 Mar 2024 17:37:30 GMT</pubDate>
    </item>
    <item>
      <title>比较两个二维概率分布</title>
      <link>https://stats.stackexchange.com/questions/641985/comparing-two-two-dimensional-probability-distributions</link>
      <description><![CDATA[我想比较代表两个概率分布的两个等高线图。这些不是从任何已知分布中抽取的样本，而是原子过程物理计算的结果。特别是，我想知道这两个分布有多相似，以定量回答诸如“这两个分布之间有多少重叠？”、“它们在多大程度上占据（）的相同区域”之类的问题。 x,y) 平面？”，“(x,y) 平面区域中的分布强度（振幅）有多相似？”。
我已经读过有关 KL 散度和 Bhattacharya 距离的内容，但是 Bhattacharya 距离似乎假设潜在的正态分布？而且 KL 散度是不对称的，所以我不确定它对于这个目的有多大用处。它们似乎也适合从分布中抽取样本，而不是比较分布本身。
我还尝试了以下操作：获取强度大于特定值（地图最亮特征）的 (x, y) 坐标，然后对 x 值进行分箱以形成直方图。对于 y 值也是如此。这给了我两个沿轴的直方图，对于这两个分布，我计算了巴塔查亚距离、相关性等。但从物理上来说，我不确定这是否有意义？
我对统计数据非常陌生，因此我们将非常感谢任何用于搜索与此相关的通用术语。]]></description>
      <guid>https://stats.stackexchange.com/questions/641985/comparing-two-two-dimensional-probability-distributions</guid>
      <pubDate>Wed, 06 Mar 2024 17:32:46 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 keras 修改我的分类神经网络以提高准确性？</title>
      <link>https://stats.stackexchange.com/questions/641982/how-to-modify-my-classification-neural-net-with-keras-to-improve-accuracy</link>
      <description><![CDATA[我正在尝试构建一个神经网络来预测二进制输出 [0,1]。我有一个非常小的数据集，有 600 个样本，其中 200 个样本标签为 0，其中 400 个样本标签为 1。我有 23 个特征，其中一些是分类特征（我使用 pd.get_dummies 对它们进行编码）。我的目标是“状态”列值：0 表示“已终止”，“1”表示活动。我还使用标准缩放器缩放数据。我有一种感觉，我构建网络的方式是错误的。由于我的数据集非常小，我使用 dropout 和 BatchNormalization 来防止过度拟合。
我可以对分类器进行哪些更改和改进以使其更加准确？
def make_classifier(self,optimizer):
        分类器=顺序（）
        
        classifier.add(Dropout(0.2, input_shape=(24,))) # 添加dropout层以防止overfiitng
        classifier.add(Dense(50, kernel_initializer = &quot;he_normal&quot;,kernel_regularizer=keras.regularizers.l2(0.01) , input_dim=24))#activation = &quot;relu&quot;,
        classifier.add(BatchNormalization())
        classifier.add(LeakyReLU(alpha=0.2))
        
        分类器.add(Dropout(0.2))
        classifier.add(Dense(20, kernel_initializer = &quot;he_normal&quot;,kernel_regularizer=keras.regularizers.l2(0.01)))
        classifier.add(BatchNormalization())
        classifier.add(LeakyReLU(alpha=0.2))#activation = &quot;relu&quot;,
        
        
        分类器.add(Dropout(0.15))
        classifier.add(Dense(1, kernel_initializer = &quot;he_normal&quot;,activation = &quot;sigmoid&quot;,kernel_regularizer=keras.regularizers.l2(0.01)))
        classifier.compile(optimizer=optimizer,loss=“binary_crossentropy”,metrics=[“accuracy”])
        返回分类器

这就是我准备数据的方式：
 df[&#39;Status&#39;]=np.where(df[&#39;Status&#39;]==&#39;终止&#39; ,0, 1 )
    df=df.dropna()
    features = [&#39;区域&#39;, &#39;功能&#39;]
    df_final = pd.get_dummies(df,columns=features,drop_first=True)
    
    X = df_final.drop([&#39;Emp_Status&#39;],axis=1).values
    y = df_final[[&#39;Emp_Status&#39;]].values
    

    sc = 标准缩放器()
    X = sc.fit_transform(X)
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=1, stratify=y)
    
    分类器 = KerasClassifier(build_fn = self.make_classifier)
    batch_max=len(X_train)

后来我使用网格搜索：
&lt;前&gt;&lt;代码&gt;参数= {
    &#39;batch_size&#39;:[50,150,250,batch_max],#样本数
    &#39;epochs&#39;:[5,11,32,50,64,100], ## 算法中训练数据的传输次数
    &#39;优化器&#39;:[&#39;adam&#39;,&#39;rmsprop&#39;,&#39;nadam&#39;]}
    
    grid_search = GridSearchCV(估计器=分类器,
                       param_grid=参数，
                       评分=“准确度”，
                       cv=2, error_score=&#39;raise&#39;)
    
    grid_search = grid_search.fit(X_train,y_train)

    best_param = grid_search.best_params_
    best_accuracy = grid_search.best_score_
    print(&#39;网格最佳精度&#39;, best_accuracy)

目前最佳准确率为 85%
我还使用其他模型：随机森林、MLPClassifier、XGBoost、CATBoost。我确保它们不会过度拟合并且准确度在 90-95% 范围内。我希望能达到类似的精度]]></description>
      <guid>https://stats.stackexchange.com/questions/641982/how-to-modify-my-classification-neural-net-with-keras-to-improve-accuracy</guid>
      <pubDate>Wed, 06 Mar 2024 17:17:36 GMT</pubDate>
    </item>
    </channel>
</rss>