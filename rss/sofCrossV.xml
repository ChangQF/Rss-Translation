<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 14 May 2024 15:16:48 GMT</lastBuildDate>
    <item>
      <title>变异分摊</title>
      <link>https://stats.stackexchange.com/questions/647221/apportionment-of-variation</link>
      <description><![CDATA[我有一个包含数十万个网站（分类）的数据集，其中包含每个请求的二氧化碳排放量（定量）以及它们托管的数据中心（分类），以及这些数据中心是否使用可再生能源（分类：真或假）。
我正在尝试确定/分配二氧化碳排放量的可变性到网站设计（跨网站的可变性）以及它们是否托管在可再生能源使用的数据中心。
直观上，我尝试计算整个数据集的方差（网站之间的方差）以及每个数据中心内网站之间的方差，然后计算这些方差之间的方差。但我认为这是错误的做法。我强烈怀疑存在未解释的交互作用，而且方差的方差也让我觉得可疑。
我的下一个想法是尝试方差分析，但据我所知，方差分析不会分配方差。具体来说，我对这两个方差是否显着不同不感兴趣，而是对它们实际上是什么以及它们如何相互比较对总方差的贡献感兴趣。
我在维基百科上阅读了一些其他内容，例如变异系数&lt; /a&gt; 和 四分位分散系数 以及 克莱默的 V。所有这三种技术/方法听起来都可以回答我的问题，但我不确定哪一种是正确的方法（如果有）？
如何将可变性的贡献分配给网站与可再生数据中心？]]></description>
      <guid>https://stats.stackexchange.com/questions/647221/apportionment-of-variation</guid>
      <pubDate>Tue, 14 May 2024 15:09:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么 $L_1$ 权重衰减会对逻辑回归的对抗训练产生负面影响？</title>
      <link>https://stats.stackexchange.com/questions/647219/why-does-l-1-weight-decay-negatively-impact-adversarial-training-for-logistic</link>
      <description><![CDATA[我正在阅读关于快速梯度符号法的原始论文（Ian Goodfellow 等人的解释和利用对抗性示例）。
我们将对抗性示例定义为：
$$\tilde{x}=x+\eta$$
其中 $\eta=\epsilon\text{sign}\nabla_x(J(\theta,x,y)$
将对抗性示例替换为目标函数，我们的新目标变为最小化（对于 $w$）：
$$\zeta(y(\epsilon||w||_1-w^Tx-b))$$
其中 $\zeta$ 是 softplus 函数 $\log(1+\exp(z))$ 
论文接着说：
&lt;块引用&gt;
大多数
值得注意的是，$L_1$ 惩罚是在训练期间从模型的激活中减去的，而不是
添加到培训成本中。这意味着如果模型
学会做出足够自信的预测，使 ze 饱和。这并不能保证会发生——在
在欠拟合情况下，对抗性训练只会加剧欠拟合。因此我们可以查看 $L_1$
重量衰减比对抗性训练更“最坏的情况”，因为它无法在
利润良好的情况。

我有以下问题：

如果随着模型越来越有信心，惩罚开始消失，这不就等于权重衰减“停用”模型了吗？在利润好的情况下？什么会“停用”？在这种情况下意味着什么？

该论文似乎暗示，对抗性示例中的权重衰减似乎会对对抗性训练产生负面影响。然而，之前的论文指出：


&lt;块引用&gt;
对抗性扰动导致激活增加 $w^T\eta$。我们可以最大化这种增加
通过分配 η = sign($w$) 来服从 η 的最大范数约束。如果 $w$ 具有 $n$ 维度并且
权重向量的元素的平均大小为 $m$，则激活将增长 $\epsilon mn$&lt; /span&gt;.

那么权重衰减不会减少 $m$ 从而减少对抗性示例对激活函数的影响吗？这不是好事吗？那么，为什么$L_1$权重衰减会对对抗训练产生负面影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/647219/why-does-l-1-weight-decay-negatively-impact-adversarial-training-for-logistic</guid>
      <pubDate>Tue, 14 May 2024 14:55:31 GMT</pubDate>
    </item>
    <item>
      <title>面板数据残差的正态性</title>
      <link>https://stats.stackexchange.com/questions/647218/normality-of-residuals-in-panel-data</link>
      <description><![CDATA[我从包含面板数据（按国家/地区）的样本中运行了包含国家/地区和年份固定效应的线性回归。
由于我使用的是 OLS，我的残差是否必须在整个样本中看起来近似正态分布，或者每个国家/地区的残差是否必须看起来像这样？因此，问题是：正态性假设是否适用于整个样本或每个单独实体的模型残差？]]></description>
      <guid>https://stats.stackexchange.com/questions/647218/normality-of-residuals-in-panel-data</guid>
      <pubDate>Tue, 14 May 2024 14:43:58 GMT</pubDate>
    </item>
    <item>
      <title>二元高斯的指数族表达式</title>
      <link>https://stats.stackexchange.com/questions/647217/exponential-family-expression-for-bivariate-gaussian</link>
      <description><![CDATA[考虑具有以下密度的二元高斯分布：
$$f(x,y) = \frac{1}{2\pi \sqrt{1-\rho^2}}e^{-\frac{1 {2(1-\rho^2)}(x^2-2\rho xy+y^2)}$$
我们如何将其写成指数族形式，即
$$f(x,y) = e^{\eta_1 T_1(x,y)+\eta_2 T_2(x,y) - \psi(\eta_1,\eta_2)} h(x,y)$$
我可以将 $f$ 重写为
$$f(x,y) = e^{-\frac{1}{2(1-\rho^2)}(x^2+y^2) ) + \frac{\rho}{1-\rho^2}xy -\ln 2\pi - \frac{1}{2} \ln (1-\rho^2)}$$&lt; /p&gt;
所以，看起来我们可以选择 $\eta_1 = \frac{1}{1-\rho^2}$ 和 $\eta_2 = \frac{\rho}{1-\rho2}$。那么我们如何识别$\psi$呢？没有独特的方法可以将 $\ln (1-\rho^2)$ 编写为 $\eta_1 的函数$ 和 $\eta_2$。例如，它是 $-\ln \eta_1$ 或 $\ln (1-\frac{\eta_2^2 }{\eta_1^2})$。我们应该使用哪一个？]]></description>
      <guid>https://stats.stackexchange.com/questions/647217/exponential-family-expression-for-bivariate-gaussian</guid>
      <pubDate>Tue, 14 May 2024 14:16:56 GMT</pubDate>
    </item>
    <item>
      <title>从与目标变量具有最高相关系数的预测变量生成新变量</title>
      <link>https://stats.stackexchange.com/questions/647214/generating-a-new-variable-from-the-predictors-that-has-the-highest-correlation-c</link>
      <description><![CDATA[我有一个包含 $300$ 行和 $11$ 列的数据集。我的数据中有 $10$ 个预测变量（例如 $X_1, X_2,\ldots,X_{10}$）和目标变量（例如 $Y$）。我想知道是否可以从部分或全部 $10$ 预测变量创建新的数据列，以使新数据列的相关系数与 &lt; span class=&quot;math-container&quot;&gt;$Y$ 尽可能高。例如，您可以创建一个新变量 $\dfrac{10X_3+X_6}{X4}$ 并发现它与目标变量具有很高的相关性。我想到的方法是凭经验操纵预测变量并尝试它们的不同组合，例如尝试所有比率（例如 $\dfrac{X_1}{X_2}$, $\dfrac{X_1}{X_3}$, $\ldots, \dfrac{X_9}{X_{ 10}}$）并从相关矩阵中查找高度相关的变量，例如使用 这个。但我认为这需要大量的计算，而且只能尝试有限数量的组合。有系统的方法来做到这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647214/generating-a-new-variable-from-the-predictors-that-has-the-highest-correlation-c</guid>
      <pubDate>Tue, 14 May 2024 12:51:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么反向扩散过程不是高斯分布？</title>
      <link>https://stats.stackexchange.com/questions/647213/why-reverse-diffusion-process-is-not-a-gaussian-distribution</link>
      <description><![CDATA[从 x_t 到 x_{t+1} 的前向扩散过程是高斯扩散过程，当我们通过添加随机高斯噪声进入下一个状态时，这是非常合理的。但是，我不明白为什么这个过程的逆过程（从 x_{t+1} 到 x_t ）不是高斯分布？]]></description>
      <guid>https://stats.stackexchange.com/questions/647213/why-reverse-diffusion-process-is-not-a-gaussian-distribution</guid>
      <pubDate>Tue, 14 May 2024 12:27:17 GMT</pubDate>
    </item>
    <item>
      <title>预测变量的后向选择和 GLM 先前的假设</title>
      <link>https://stats.stackexchange.com/questions/647208/backward-selection-of-predictors-and-glm-previous-assumptions</link>
      <description><![CDATA[我想确定哪些环境因素（预测变量）对一个生态变量（因变量）有影响。我有一组 110 个观察结果。
因变量是连续的、正的并且包含零。
预测变量并不共线，我从 24 个变量的列表开始。
我设置了 GLM 并执行了预测变量的向后选择，仅保留重要的预测变量。我不希望最终模型做出任何预测，我只想确定重要的预测变量（因此模型拟合不相关）。因此，我一次删除一个预测变量，始终排除 p 值最高的预测变量。
问题在于，初始模型不满足残差正态性（显着 Shapiro-Wilk）和同方差性（不显着 Breuch-Pagan），并且最后一个模型不满足残差正态性（显着 Shapiro-Wilk） ）
在这里您可以看到初始模型的一些图：


第一个问题：
在执行预测变量的逐步选择时，哪些 GLM 需要满足先前的假设？每一个？第一和最后？只是最后一个？
第二个问题：
我尝试使用不同的方法使初始模型具有残差的正态性，但我找不到实现它的方法。我尝试通过平方根、倒数、自然对数、box-cox 和 yeo-johnson 变换因变量，始终保持零；我尝试在 GLM 中使用不同的族分布（高斯分布、毒分布、伽玛分布、二项分布、拟分布……基本 R 中所有可用的分布，即使它们没有多大意义）；我尝试排除异常值（尽管这是我真的不想做的事情）。什么都没起作用。有什么想法吗？
第三个问题：
（关于何时可以“忽略”GLM 中残差缺乏正态性的大主题）查看我的图和数据点，似乎缺乏正态性是由因变量的最高值引起的，因此，我在模型中包含的预测变量可能缺少与这些高值相关的内容，但它们适用于大多数值范围。从生态角度来看，这在我看来是合理的。鉴于我的目的不是建立一个预测模型，这种解释是否足以“忽略”这一点？缺乏常态？
非常感谢，我已经花了很多时间在网上寻找答案，但我没有找到我想要的东西。
编辑1：
正如所建议的，这里是我想要回答的问题的简要解释：
众所周知，一些环境变量可以对鲑鱼的丰度（因变量）产生直接影响。这些变量与河流的一些特征有关：底质、栖息地、入侵物种、河岸植被等。当然，由于这是生态学，并非每个变量总是产生影响（例如，在某些河流中，入侵物种可能非常重要，但其他人则不然）。此外，由于它是一个具有多种相互作用的复杂系统，因此很少期望找到单个变量与依赖项之间的直接相关性。
我在这里的目的是添加一个“新”一组之前从未测试过的生态变量（为了简化，我们称之为“流”），因此尚不清楚如果这些变量中的任何一个发生变化，鲑鱼是否会做出反应。
因此，前提是鲑鱼的丰度会对基质、栖息地、入侵物种和河岸植被产生反应，但我们不知道它是否也会对流量产生反应。我们不应期望鲑鱼和流量之间存在直接相关性，因为流量的影响（如果存在）将与所有其他环境因素同时起作用，可能会被它们掩盖。]]></description>
      <guid>https://stats.stackexchange.com/questions/647208/backward-selection-of-predictors-and-glm-previous-assumptions</guid>
      <pubDate>Tue, 14 May 2024 11:19:41 GMT</pubDate>
    </item>
    <item>
      <title>残差重尾分布的修正？</title>
      <link>https://stats.stackexchange.com/questions/647207/correction-for-heavy-tailed-distribution-of-residuals</link>
      <description><![CDATA[我有兴趣研究使用固定的 $x$ 对 $y$ 的影响效果法。正如正态 Q-Q 图所示，残差遵循重尾分布。为了进行推理，我需要残差的正态分布。
哪些策略可以应用于模型以使残差变得更加正态分布？我想到了对数转换。这使得残差确实更加正态分布，但重尾仍然存在。]]></description>
      <guid>https://stats.stackexchange.com/questions/647207/correction-for-heavy-tailed-distribution-of-residuals</guid>
      <pubDate>Tue, 14 May 2024 11:14:46 GMT</pubDate>
    </item>
    <item>
      <title>绘制模型调整的变化分数基线值</title>
      <link>https://stats.stackexchange.com/questions/647206/plotting-model-adjusted-baseline-values-of-change-scores</link>
      <description><![CDATA[我知道一些人不赞成使用变化评分来评估 RCT 中治疗结果的效果。但我有兴趣了解人们在绘制模型调整均值时通常会做什么，无论是在结果向量中包含基线还是在 ANCOVA 中调整基线。在后一种情况下，模型中不会估计结果的基线值，但在前一种情况下会估计结果的基线值。鉴于它们是变化分数并且基线值为零（至少在样本中），将两个治疗组中的图投影回零是否合理（如果在技术上无效）。审阅者质疑为什么学生的模型调整平均值在基线时不为零，但当然这些不是描述性平均值，这取决于模型中调整的协变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/647206/plotting-model-adjusted-baseline-values-of-change-scores</guid>
      <pubDate>Tue, 14 May 2024 11:08:49 GMT</pubDate>
    </item>
    <item>
      <title>深度学习中的统计测试[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647205/statistical-test-in-deeplearning</link>
      <description><![CDATA[在写论文期间，我评估了各种模型的性能并写下了性能平均值。
现在我正在考虑应该进行哪种类型的测试。
特别是在我的领域，许多论文不包括统计分析，即使他们坚持他们的方法是 SOTA。 （只是他们报告平均值和标准值）
我认为如果在相同的测试数据集中进行实验，则可以使用配对 t 检验（或某种配对测试策略，如 Wilcoxon 符号秩检验）。
但是，就我而言，由于测试数据数量众多（大约 1000 个），测试统计数据非常大，而且似乎显得过分重要。
这种情况下，哪种方法更合适呢？ （引导？）]]></description>
      <guid>https://stats.stackexchange.com/questions/647205/statistical-test-in-deeplearning</guid>
      <pubDate>Tue, 14 May 2024 11:07:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 sigmoid 函数进行线性逻辑回归 - 为什么需要对 y 进行变换？</title>
      <link>https://stats.stackexchange.com/questions/647197/making-linear-to-logistic-regression-with-sigmoid-function-why-is-a-transforma</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/647197/making-linear-to-logistic-regression-with-sigmoid-function-why-is-a-transforma</guid>
      <pubDate>Tue, 14 May 2024 09:42:09 GMT</pubDate>
    </item>
    <item>
      <title>二维图中的强度异常值/异常</title>
      <link>https://stats.stackexchange.com/questions/647184/intensity-outliers-anomalies-in-2d-plot</link>
      <description><![CDATA[我想知道使用哪种方法更好地查看二维图 z 值的异常值。例如，我测量的 x 和 y 值均在 1 到 16 范围内，步长为 1。接下来，我计算每对 x 和 y (x_n, y_n) 有多少个观测值。这给了我一个 16 x 16 的网格，每对 (z) 的观测值数量。因为 x 和 y 是相关的，所以我们期望看到一些模式 - 某些点组比其他点更频繁地出现。
有时，在很少有观察结果的领域，可以提出许多观察结果。这是由于设备错误造成的。传感器一次又一次地错误地标记某些值。在大数据中查找这些错误的最佳方法是什么？如果网格不是 16 x 16 而是 9000 x 9000。也可以使用原始数据 - 重复的 x 和 y 观察（在 KDE 的情况下）。
这是一些硬编码的沙箱示例：
导入 pandas 作为 pd
随机导入
将 matplotlib.pyplot 导入为 plt
# 让我们制作数据 x、y、z。
# x和y是类似于矩阵坐标的坐标
x = [i 对于范围 (1, 17) 内的 i 对于范围 (16) 内的 j]
y = 列表(范围(1, 17)) * 16


# z 是某个范围内的一组随机整数值
def r_num(基值: int, n_numbers: int):
    返回 [random.randint(base_value, base_value + 700) for i in range(n_numbers)]

def z_make():
    _z = ((r_num(2000, 16)) +
         (r_num(2000, 16)) +
         (r_num(2000, 2) + r_num(5000, 12) + r_num(2000, 2)) +
         (r_num(2000, 2) + r_num(5000, 12) + r_num(2000, 2)) +
         (r_num(2000, 2) + r_num(5000, 2) + r_num(7000, 8) + r_num(5000, 2) + r_num(2000, 2)) +
         (r_num(2000, 2) + r_num(5000, 2) + r_num(7000, 1) + r_num(9000, 6) + r_num(7000, 1) + r_num(5000, 2) + r_num(2000, 2)) +
         (r_num(2000, 2) + r_num(5000, 2) + r_num(7000, 1) + r_num(9000, 1) + r_num(10000, 4) + r_num(9000, 1) + r_num(7000, 1) + r_num(5000, 2) + r_num(2000, 2)) +
         (r_num(2000, 2) + r_num(5000, 2) + r_num(7000, 1) + r_num(9000, 1) + r_num(10000, 1) + r_num(16000, 2) + r_num(10000, 1) + r_num(9000, 1) + r_num(7000, 1) + r_num(5000, 2) + r_num(2000, 2)))
    返回_z


z1 = z_make()
z2 = z_make()
z2.reverse()
z = z1 + z2

对于 [&#39;x&#39;,&#39;y&#39;,&#39;z&#39;] 中的 i：
    print(&#39;i 的长度：&#39;, len(eval(i)))

df = pd.DataFrame({&#39;x&#39;: x, &#39;y&#39;: y, &#39;z&#39;: z})

# 设置一些异常值和异常值附近的缺失值
df.loc[(df[&#39;x&#39;] == 2) &amp; (df[&#39;y&#39;] == 6), &#39;z&#39;] = 15875
df.loc[(df[&#39;x&#39;] == 15) &amp; (df[&#39;y&#39;] == 2), &#39;z&#39;] = 14999
df.loc[(df[&#39;x&#39;] == 2) &amp; (df[&#39;y&#39;] == 7), &#39;z&#39;] = 无

plt.scatter(df.x, df.y, c=df.z, cmap=&#39;viridis&#39;, s=100, alpha=0.7)

# 添加颜色条
plt.colorbar(label=&#39;强度&#39;)

# 设置标签和标题
plt.xlabel(&#39;X 标签&#39;)
plt.ylabel(&#39;Y 标签&#39;)
plt.show()


所以我正在寻找绘图一侧的两个黄点。相邻点的 z 值低于异常值。在一种情况下，邻居甚至失踪了。
我一直在研究 KDE、轮廓和局部离群因子 (LOF)，但没有成功。我也问了类似的问题&lt; /a&gt; 在 Stack 中，但我想知道 CV 社区是否可以提出更好的解决方案。
实际上 KDE 工作得还不错，但带宽极大地影响了异常值的检测。我需要在大型散点图中找到 z 值与其邻居的 z 值不同的点（坐标）。]]></description>
      <guid>https://stats.stackexchange.com/questions/647184/intensity-outliers-anomalies-in-2d-plot</guid>
      <pubDate>Tue, 14 May 2024 06:50:16 GMT</pubDate>
    </item>
    <item>
      <title>对于什么样的分布，联合分布可以由边际分布和相关性唯一确定？</title>
      <link>https://stats.stackexchange.com/questions/647179/for-what-kind-of-distributions-the-joint-distribution-could-be-determined-uniqu</link>
      <description><![CDATA[假设 $X$ 和 $Y$ 来自同一分布$P$ 和 $\rho = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}} $ 是固定的。对于什么样的$P$我们可以唯一确定$X,Y$的联合分布？&lt; /p&gt;
我知道两个具有上述属性的分布，即

$P = N(\mu,\sigma^2)$，即正态分布
$P = Ber(p)$，即伯努利分布

此列表中还有其他发行版吗？或者我们可以用这个属性来描述分布吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647179/for-what-kind-of-distributions-the-joint-distribution-could-be-determined-uniqu</guid>
      <pubDate>Tue, 14 May 2024 01:35:06 GMT</pubDate>
    </item>
    <item>
      <title>sklearn 的“RadiusNeighborsClassifier”的“距离”选项背后的算法是什么？</title>
      <link>https://stats.stackexchange.com/questions/647170/what-is-the-algorithm-behind-the-distance-option-of-radiusneighborsclassifier</link>
      <description><![CDATA[在 scikit-learn 1.4.2 版本中，我正在测试 RadiusNeighborsClassifier，我发现选项 weights=&#39;distance&#39; 大大提高了 CCR（分类正确率） 。是否有任何期刊参考文献或有关此选项背后的算法的一些注释？]]></description>
      <guid>https://stats.stackexchange.com/questions/647170/what-is-the-algorithm-behind-the-distance-option-of-radiusneighborsclassifier</guid>
      <pubDate>Mon, 13 May 2024 21:00:00 GMT</pubDate>
    </item>
    <item>
      <title>何时需要显着性或零假设检验的基本原理</title>
      <link>https://stats.stackexchange.com/questions/647167/the-rationale-for-when-significance-or-null-hypothesis-testing-is-needed</link>
      <description><![CDATA[为什么人们有时会声称效果如此巨大且“明显”？即使样本量不大，它也不能保证任何推论统计计算？
这来自生物/医学领域，主要来自实验室设计的实验。
以下是此类实验的一个示例

这些是均值+标准差。他们通常会得出“差异太明显，所以不需要测试”的结论。在计算样本 CI 之前。
有人可以分享一些关于此事的参考资料吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647167/the-rationale-for-when-significance-or-null-hypothesis-testing-is-needed</guid>
      <pubDate>Mon, 13 May 2024 19:49:07 GMT</pubDate>
    </item>
    </channel>
</rss>