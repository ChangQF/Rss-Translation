<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 24 Jun 2024 06:21:00 GMT</lastBuildDate>
    <item>
      <title>（如何）ROC/AUC 分析适应具有两个（或更多）阈值的问题？</title>
      <link>https://stats.stackexchange.com/questions/649780/how-can-roc-auc-analysis-be-adapted-to-problems-with-two-or-more-thresholds</link>
      <description><![CDATA[(如何) ROC/AUC 分析可以适应具有两个（或更多）阈值的问题？
示例 1：
我们测量变量 $x$，如果它落入区间 $[a, b]$，则分配标签 $1$，否则标记 $0$。然后我们有两个参数 $a,b$ 控制 TPR 和 FPR。
示例 2：
如果 $x&lt;a$，我们分配类 $0$，如果 $x&gt;b$ (b&gt;a)，我们分配类 $1$。如果 x 落入区间 $[a,b]$，则决策基于将第二个变量 $y$ 与阈值 $c$ 进行比较。]]></description>
      <guid>https://stats.stackexchange.com/questions/649780/how-can-roc-auc-analysis-be-adapted-to-problems-with-two-or-more-thresholds</guid>
      <pubDate>Mon, 24 Jun 2024 05:48:03 GMT</pubDate>
    </item>
    <item>
      <title>小样本 MLE 与 OLS 效率</title>
      <link>https://stats.stackexchange.com/questions/649779/small-sample-mle-vs-ols-efficiency</link>
      <description><![CDATA[MLE 估计是渐近有效的。MLE 和 OLS 估计都是渐近正态的，并且对于许多分布，它们的极限方差是一致的（在这种情况下，一个观测值的信息是其方差的倒数）。因此，至少从大样本理论来看，我没有看到在这种情况下偏爱其中一个的明确理由。现在，直观地看，我认为，假设概率模型是正确的（并且不是正态的），MLE 对于小样本也应该更有效。在这方面有任何已知结果吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649779/small-sample-mle-vs-ols-efficiency</guid>
      <pubDate>Mon, 24 Jun 2024 03:58:46 GMT</pubDate>
    </item>
    <item>
      <title>如何实际使用 BCa 引导区间的经验影响函数？</title>
      <link>https://stats.stackexchange.com/questions/649776/how-to-actually-use-the-empirical-influence-function-for-bca-bootstrap-intervals</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/649776/how-to-actually-use-the-empirical-influence-function-for-bca-bootstrap-intervals</guid>
      <pubDate>Mon, 24 Jun 2024 03:28:34 GMT</pubDate>
    </item>
    <item>
      <title>生存分析 - 对于创建随时间变化的协变量，按失败时间进行分裂而不是按协变量变化进行分裂有什么好处吗？</title>
      <link>https://stats.stackexchange.com/questions/649774/survival-analysis-any-benefit-to-splitting-on-failure-time-instead-of-covariat</link>
      <description><![CDATA[当需要为生存模型创建随时间变化的协变量时，我习惯于使用（我所理解的）计数过程结构来处理我的数据，其中每个人可能有多行数据，每行定义一个时间间隔（开始、停止时间）并包含该间隔期间协变量的值。
然而，在阅读有关使用 tvc 的更多内容时，我遇到了一种方法，该方法涉及在每个唯一事件时间（而不是协变量变化）处分割时间，并从中创建适当的时间间隔。但是由于您要考虑所有事件来分割时间，因此数据集可能会变得非常大。
我知道 Cox 模型只关注事件时间（参数模型呢？），所以我想如果您获得了该粒度级别的协变量信息，这可能是更好的方法？但除此之外，这样做还有其他好处吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/649774/survival-analysis-any-benefit-to-splitting-on-failure-time-instead-of-covariat</guid>
      <pubDate>Mon, 24 Jun 2024 02:28:55 GMT</pubDate>
    </item>
    <item>
      <title>关于 GLM 中偏差定义的问题</title>
      <link>https://stats.stackexchange.com/questions/649772/questions-regarding-the-definition-of-the-deviance-in-the-context-of-glms</link>
      <description><![CDATA[我一直在自学 GLM，对 GLM 上下文中的偏差有一些疑问。在《广义可加模型简介》（使用 R）中，作者将模型的偏差定义为
$$
2\big(l(\hat{\beta}_{max}) - l(\hat{\beta})\big)\phi
$$
其中 $\phi$ 是尺度参数，$\hat{\beta}_{max}$ 表示饱和模型的 MLE，$\hat{\beta}$ 是拟合模型的 MLE。但是，我也看到偏差被简单地定义为
$$
2\big(l(\hat{\beta}_{max}) - l(\hat{\beta})\big),
$$
没有比例参数，这是维基百科上使用的定义。哪个定义是正确的？在 R 中，GLM 的摘要输出中使用了什么偏差定义？
任何帮助都非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649772/questions-regarding-the-definition-of-the-deviance-in-the-context-of-glms</guid>
      <pubDate>Sun, 23 Jun 2024 23:20:26 GMT</pubDate>
    </item>
    <item>
      <title>正确解读最终满足生存曲线</title>
      <link>https://stats.stackexchange.com/questions/649770/correct-interpretation-of-survival-curves-that-eventually-meet</link>
      <description><![CDATA[我有一些生存数据，我们正在尝试分析和理解这些数据。结果是疾病状态的进展。主要暴露在本质上是随时间变化的 - 最初未暴露，但一旦暴露，我们认为它们会一直保持这种状态，直到进展或审查。所以我们的数据是开始、停止格式 - 一切都很好。
我越来越被使用灵活的参数生存模型所吸引，因为它们使用简单，并且它们可以提供超出 Cox 模型的额外信息。我们最终用于此分析的灵活参数模型在对数累积基线风险的形状方面基本上简化为威布尔，但我们确实为主要暴露纳入了相互作用（时间变系数），因为它被证明具有非比例风险。
因此风险比随时间而变化。
附上随时间变化的 Kaplan Meier 和 HR 图。
生存曲线似乎在大约 17 年后汇合在一起，HR 表明暴露仅在前 5 年左右对结果有保护作用。
正确的解释方式是否类似于暴露在预防结果的短时间内有益处（相对于未暴露），但如果有足够的时间，每个人最终都会有相同程度的残疾？
如果是这样的话，我想你仍然可以合理地认为暴露在临时生活质量方面提供了好处，即使最终的净效应是中立？

]]></description>
      <guid>https://stats.stackexchange.com/questions/649770/correct-interpretation-of-survival-curves-that-eventually-meet</guid>
      <pubDate>Sun, 23 Jun 2024 22:56:43 GMT</pubDate>
    </item>
    <item>
      <title>分层 cox-ph 模型的 R 输出解释</title>
      <link>https://stats.stackexchange.com/questions/649762/interpretation-of-r-output-for-stratified-cox-ph-model</link>
      <description><![CDATA[对于以下模型：
model &lt;- coxph(formula = Surv(time, status) ~ treatment * sex + strata(sex), data = data)

这是 R 中的模型摘要（部分）：




coef
exp(coef)




treatment1
-0.15
0.86


sex_f
NA
NA


treatment1:sex_f
-0.35
0.70



如果我理解正确的话，在分层模型中，系数不能再解释为风险比，因为两者的基线不一样性别。因此，仅根据表格，我无法判断接受治疗的女性的风险比
与接受治疗的男性相比？如何获得接受治疗的女性与未接受治疗的女性的特定对数风险比，是 log(HR) = -0.15 + -0.35，还是 log(HR) = -0.35？
非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/649762/interpretation-of-r-output-for-stratified-cox-ph-model</guid>
      <pubDate>Sun, 23 Jun 2024 20:12:52 GMT</pubDate>
    </item>
    <item>
      <title>解释两阶段统计检验问题的引文</title>
      <link>https://stats.stackexchange.com/questions/649761/citations-explaining-the-problems-with-two-stage-statistical-testing</link>
      <description><![CDATA[我正在写一篇关于分析对数正态分布抽样数据的评论，我想解释一下首先运行正态性检验并使用该结果选择运行哪个检验的问题。
首先运行方差相等性检验并使用该结果选择第二个检验也会出现同样的问题。
这种“两阶段”程序（一定有更好的名称）会扭曲第二次检验的结果。
我要求引用一些论文来解释这个问题并举例说明两阶段测试如何产生误导。]]></description>
      <guid>https://stats.stackexchange.com/questions/649761/citations-explaining-the-problems-with-two-stage-statistical-testing</guid>
      <pubDate>Sun, 23 Jun 2024 20:07:09 GMT</pubDate>
    </item>
    <item>
      <title>两种测试指标的比较</title>
      <link>https://stats.stackexchange.com/questions/649760/comparison-of-two-test-metrics</link>
      <description><![CDATA[我试图比较两个测试指标（指标 A 和指标 B），以确定哪一个能更好地预测增量值，这代表欧几里得差异。我不确定如何确定哪个指标更能预测增量，以及如何从统计上验证这种差异。以下是相关详细信息和我迄今为止的方法。如有任何建议，我们将不胜感激。
指标和增量值：

指标范围：两个指标的名义范围均为 0 到 100，但其中一个指标可能会产生负值。
增量值：始终等于或大于 0。
特殊条件：当任一指标等于 100 时，增量将为 0。

当前方法：

相关性分析：

我对指标 A 和指标 B 进行了相关性分析，它们彼此高度相关。 (~0.95)


线性回归：

我已经对指标 A 和 Delta 以及指标 B 和 Delta 进行了线性回归。
我比较了这些回归的 R² 值以评估预测能力。


异方差问题：

回归的残差图显示出高度的异方差。这似乎是一个大问题。我想知道如何处理这个问题。
我认为异方差是可以预料到的，因为随着指标值的减小，增量趋于变大。



目标：

主要目标：确定哪个指标（指标 A 或指标 B）能更好地预测增量值。
统计显著性：检查两个指标之间的预测能力差异是否具有统计显著性。

建议的解决方案：

似然比检验：

我读到，计算似然比检验统计量及其 p 值可能对这种比较有用。
这种方法可能有助于确定预测能力差异的统计显著性功效。



似然比检验统计量：50.555228536421964
P 值：1.1585811876258776e-12

]]></description>
      <guid>https://stats.stackexchange.com/questions/649760/comparison-of-two-test-metrics</guid>
      <pubDate>Sun, 23 Jun 2024 19:18:46 GMT</pubDate>
    </item>
    <item>
      <title>当第 n 次尝试保证成功时，如何计算预期成功率？</title>
      <link>https://stats.stackexchange.com/questions/649754/how-to-work-out-the-expected-rate-of-success-when-there-is-a-guaranteed-success</link>
      <description><![CDATA[我希望弄清楚如何在给定成功率的情况下找到预期成功率，但在 n-1 次失败尝试后，第 n 次尝试的成功率为 100%。
直观地，我理解这会使预期成功率高于每次尝试的预期成功率，因为​​分布被锁定为不超过 n 次尝试。
示例
固定成功率 = 1%
在连续 99 次失败后，下一次尝试的成功率为 100%。
此外，有没有办法用 excel 中的图表或可以生成图表的网站来直观地呈现这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/649754/how-to-work-out-the-expected-rate-of-success-when-there-is-a-guaranteed-success</guid>
      <pubDate>Sun, 23 Jun 2024 15:48:54 GMT</pubDate>
    </item>
    <item>
      <title>卡尔曼滤波器最小化状态加权误差：我的推导有什么问题</title>
      <link>https://stats.stackexchange.com/questions/649748/kalman-filter-to-minimize-weighted-errors-on-the-states-whats-wrong-with-my-de</link>
      <description><![CDATA[我正在考虑如何实现“加权卡尔曼滤波器”。请注意，此处的权重取决于状态。基本上，经典的 KF 最小化 $\sum (x_i - \hat{x_i} )^2$，但我想最小化 $\sum w_i(x_i - \hat{x_i} )^2$，其中 $w_i$ 是外部提供的向量。
借用维基百科惯例及其推导
更新函数是
\begin{aligned}
\mathbf {P} _{k\mid k-1}&amp;=\mathbf {F} _{k}\mathbf {P} _{k-1\mid k-1}\mathbf {F} _{k}^{\textsf {T}}+\mathbf {Q} _{k},\\
\mathbf {S} _{k}&amp;=\mathbf {H} _{k}\mathbf {P} _{k\mid k-1}\mathbf {H} _{k}^{\textsf {T}}+\mathbf {R} _{k},\\
\mathbf {K} _{k}&amp;=\mathbf {P} _{k\mid k-1}\mathbf {H} _{k}^{\textsf {T}}\mathbf {S} _{k}^{-1},\\
\mathbf {P} _{k|k}&amp;=\left(\mathbf {I} -\mathbf {K} _{k}\mathbf {H} _{k}\right)\mathbf {P} _{k|k-1}。
\end{aligned&gt;
我们如何找到最佳卡尔曼增益？我们对$P_{k|k}$求导，除以$K$
\begin{align}
\mathbf{P}_{k\mid k} &amp; = \mathbf{P}_{k\mid k-1} - \mathbf{K}_k \mathbf{H}_k \mathbf{P}_{k\mid k-1} - \mathbf{P}_{k\mid k-1} \mathbf{H}_k^\textsf{T} \mathbf{K}_k^\textsf{T} + \mathbf{K}_k \left(\mathbf{H}_k \mathbf{P}_{k\mid k-1} \mathbf{H}_k^\textsf{T} + \mathbf{R}_k\right) \mathbf{K}_k^\textsf{T} \\&amp;= \mathbf{P}_{k\mid k-1} - \mathbf{K}_k \mathbf{H}_k \mathbf{P}_{k\mid k-1} - \mathbf{P}_{k\mid k-1} \mathbf{H}_k^\textsf{T} \mathbf{K}_k^\textsf{T} + \mathbf{K}_k \mathbf{S}_k\mathbf{K}_k^\textsf{T}
\end{align&gt;
$$\frac{\partial \; \operatorname{tr}(\mathbf{P}_{k\mid k})}{\partial \;\mathbf{K}_k} = -2 \left(\mathbf{H}_k \mathbf{P}_{k\mid k-1}\right)^\textsf{T} + 2 \mathbf{K}_k \mathbf{S}_k = 0.$$
\begin{align}
\mathbf{K}_k \mathbf{S}_k &amp;= \left(\mathbf{H}_k \mathbf{P}_{k\mid k-1}\right)^\textsf{T} = \mathbf{P}_{k\mid k-1} \mathbf{H}_k^\textsf{T} \\
\Rightarrow \mathbf{K}_k &amp;= \mathbf{P}_{k\mid k-1} \mathbf{H}_k^\textsf{T} \mathbf{S}_k^{-1}
\end{align&gt;
然而，这是一个“未加权”的卡尔曼滤波器。我们最小化作为平方误差之和的迹。但是，如果我们想最小化平方误差的“加权”版本，该怎么办？ 我想确保在估计某些状态时的错误比其他状态具有更多的权重...我们可以假设我们知道权重是什么
我的尝试
由于矩阵 P 的迹是需要优化的目标函数，我们希望在求导之前以某种方式将“权重”注入 $P_{k|k}$ 表达式中（例如，我们以某种方式创建一个表达式 $P^{&#39;}_{k|k} = diag(w) \cdot P_{k|k} \cdot diag(w) $ ），其中 $w$ 是一个权重向量，其长度等于状态数。然后我们对 $P^{&#39;}_{k|k}$ 求导，得到 $K$。
给定 $\mathbf{P}_{k\mid k} = \mathbf{P}_{k\mid k-1} - \mathbf{K}_k \mathbf{H}_k \mathbf{P}_{k\mid k-1} - \mathbf{P}_{k\mid k-1} \mathbf{H}_k^\textsf{T} \mathbf{K}_k^\textsf{T} + \mathbf{K}_k \mathbf{S}_k\mathbf{K}_k^\textsf{T}$
我们可以在两端乘以 $W = diag(w)$：
$tr (WP_{k|k}W^T) = tr(P_{k|k} W W^T ) = tr(P_{k|k}\Omega )$（因为矩阵乘积的迹是可传递的。这里我们让 $W W^T = \Omega$ ）。
$$
\begin{align}
\frac{\partial tr(\mathbf {P} _{k\mid k}\Omega)}{\partial \mathbf{K}_k} &amp;= \frac{\partial tr(\mathbf{P}_{k\mid k-1}\Omega - \mathbf{K}_k \mathbf{H}_k \mathbf{P}_{k\mid k-1}\Omega - \mathbf{P}_{k\mid k-1} \mathbf{H}_k^\textsf{T} \mathbf{K}_k^\textsf{T}\Omega + \mathbf{K}_k \mathbf{S}_k\mathbf{K}_k^\textsf{T}\Omega )}{\partial \mathbf{K}_k} \\
&amp;= -2(\mathbf{H}_k \mathbf{P}_{k\mid k-1}\Omega)^T+2\Omega \mathbf{K}_k \mathbf{S}_k \\
&amp;= 0
\end{align}$$
因此
$$ \Omega \mathbf{K}_k \mathbf{S}_k = (\mathbf{H}_k \mathbf{P}_{k\mid k-1}\Omega)^T $$
并且 $\Omega$ 将被抵消...似乎卡尔曼增益在有权重和无权重的情况下都相同？这似乎是错误的？]]></description>
      <guid>https://stats.stackexchange.com/questions/649748/kalman-filter-to-minimize-weighted-errors-on-the-states-whats-wrong-with-my-de</guid>
      <pubDate>Sun, 23 Jun 2024 14:07:46 GMT</pubDate>
    </item>
    <item>
      <title>GAM：平滑和因子交互作用</title>
      <link>https://stats.stackexchange.com/questions/649744/gam-smooth-and-factor-interaction</link>
      <description><![CDATA[我目前正在研究 GAM。它包括平滑因子交互。我正在尝试确定哪个函数是我需要的。
Model_gamlog2 &lt;- mgcv::gam(perpetration_all ~ dar_scale + s(dar_scale, by = age_binary) + age_binary, data = merged_all_complete, family=binomial, method = &quot;REML&quot;)

&gt; summary(Model_gamlog2)

系列：二项式 
链接函数：logit 

公式：
perpetration_all ~ dar_scale + s(dar_scale, by = age_binary) + 
age_binary

参数系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 1.7862 0.3707 4.818 1.45e-06 ***
dar_scale -0.2610 7.0429 -0.037 0.970 
age_binary2 1.7874 1.2895 1.386 0.166 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df Chi.sq p 值
s(dar_scale):age_binary1 1.000 1.000 0.010 0.920
s(dar_scale):age_binary2 1.474 2.122 2.038 0.421

排名：20/21
R-sq.(adj) = 0.0173 偏差解释 = 9.94%
-REML = 39.827 尺度估计 = 1 n = 134

这里我使用了 By= 参数。
我对此输出有一些疑问：

我是否需要 s() 作为平滑参数，或者 ti() 等是否也可以。我只希望每个 IV 级别的平滑参数在需要时有所不同。
如何查看是否存在交互？据我所知，平滑项仅告诉我每个 IV 级别的年龄与 DV 没有显着相关性，而不是它们是否不同。

或者我有以下代码：
Model_gamlog2 &lt;- mgcv::gam(perpetration_all ~ dar_scale + s(dar_scale, age_binary, bs = &quot;fs&quot;) + age_binary, data = merged_all_complete, family=binomial, method = &quot;REML&quot;)

&gt; summary(Model_gamlog2)

系列：二项式

链接函数：logit

公式：
perpetration_all ~ dar_scale + s(dar_scale, age_binary, bs = &quot;fs&quot;) + 
age_binary

参数系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) 1.8761 0.3907 4.802 1.57e-06 ***
dar_scale 0.5246 0.4452 1.178 0.2386 
age_binary2 1.2737 0.7561 1.685 0.0921 . 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

平滑项的近似显著性：
edf Ref.df Chi.sq p 值
s(dar_scale,age_binary) 3.346 17 5.558 0.125

R-sq.(adj) = 0.0508 偏差解释 = 13.9%
-REML = 42.792 尺度估计 = 1 n = 134

s(dar_scale,age_binary) 是否显示交互作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/649744/gam-smooth-and-factor-interaction</guid>
      <pubDate>Sun, 23 Jun 2024 11:33:25 GMT</pubDate>
    </item>
    <item>
      <title>如何模拟像素散粒噪声</title>
      <link>https://stats.stackexchange.com/questions/649727/how-to-model-pixel-shot-noise</link>
      <description><![CDATA[我对模拟散粒噪声对图像的影响很感兴趣。使用相机拍照时，曝光时间内入射到每个像素的光子数量（我相信）是泊松随机变量$n \sim \text{Pois}(\lambda)$，其中$\lambda$与局部光强度成比例。但是，像素的灰度值不是$n$，而是$\lfloor n / C \rfloor$之类的值，其中$C\gg 1$是某个数字，取决于相机收集光线的效率。也就是说，$n$ 在形成像素灰度值时被分箱。
对这种像素灰度值分布进行建模的合理方法是什么？
编辑：澄清一下，我不是在寻求有关对相机噪声进行建模的一般建议。我希望了解上面描述的特定模型，即分箱泊松变量。分布是什么？我怎样才能更好地理解它？]]></description>
      <guid>https://stats.stackexchange.com/questions/649727/how-to-model-pixel-shot-noise</guid>
      <pubDate>Sat, 22 Jun 2024 23:43:30 GMT</pubDate>
    </item>
    <item>
      <title>AB 测试，哪个分母用于下部漏斗指标</title>
      <link>https://stats.stackexchange.com/questions/617357/ab-testing-which-denominator-to-use-for-lower-funnel-metrics</link>
      <description><![CDATA[假设我为一个从事订阅业务的网站运行 AB 测试。该公司提供 7 天的免费试用，然后自动为用户注册订阅并向他们收费，除非他们在试用期结束前取消。
处理方式是在结帐页面显示试用提醒消息，并在试用期结束前推送通知。用户到达结帐页面将进入实验（只有测试组会在结帐页面上看到试用提醒消息并在之后收到通知），但他们只有在输入信用卡完成结帐后才会开始试用。
如果我们想看看对取消率和每位用户平均费用的影响，我应该使用实验中的所有用户作为分母，还是只使用那些开始试用的用户作为分母来计算取消率和每位用户平均费用？
我觉得我们应该使用实验中的每个人作为分母，但只有那些开始试用的人才能取消，因此使用那些开始试用的人可以让我们更好地衡量取消率。但是，如果测试组和对照组中用户开始试用的速度不同，如果我只包括那些开始试用的用户，那么取消率的结果是否会有偏差？]]></description>
      <guid>https://stats.stackexchange.com/questions/617357/ab-testing-which-denominator-to-use-for-lower-funnel-metrics</guid>
      <pubDate>Tue, 30 May 2023 20:25:39 GMT</pubDate>
    </item>
    <item>
      <title>当变量均值随时间下降时，如何解释 RI-CLPM 参数估计值</title>
      <link>https://stats.stackexchange.com/questions/616632/how-to-interpret-ri-clpm-parameter-estimates-when-means-of-variables-decrease-ov</link>
      <description><![CDATA[为了进行一项研究，我在 4 个时间点运行了 RI-CLPM，观察了这 4 个时间点上负面社交互动 (X) 和抑郁 (Y) 之间的双向关联，并将交叉滞后参数限制为随时间相等。拟合度非常好，交叉滞后路径的参数估计值表明，前一个时间点的人际 X（负面社交互动）越高，则后续时间点的人际 Y（抑郁）就越高（因此是正相关）。这些变量在人际层面上没有显著相关性。乍一看似乎很容易解释。但是，当查看我的样本的描述性统计数据时，X 和 Y 的总体平均值会随着时间的推移而下降。例如，我的整体样本中的负面互动平均分数在 T1 时为 10，在 T2 时为 8，在 T3 时为 7 等，抑郁分数也是如此。我们想知道这是否可能是由于回归平均值或被评估的影响。
我对如何解释我的发现有些困惑。鉴于变量的总体均值随着时间的推移而下降，我是否仍可以这样解释我的结果：当一个人报告的 X（例如，负面的社交互动）比平时更多时，他们也会在随后的时间点报告比平时更多的 Y（例如，抑郁），所以有点像加剧效应。或者这实际上并不代表数据，如果是这样，那么正确的解释是：鉴于 X（负面的社交互动）和 Y（抑郁）的样本均值似乎随着时间的推移而下降（例如，一种恢复效应），“正”交叉滞后路径实际上显示出这种恢复效应的某种阻碍。
所以我想更广泛地说，我想知道当变量的总体均值随着时间的推移呈下降趋势时，“正”的人际关系实际上意味着什么。希望这有意义，并乐于澄清！]]></description>
      <guid>https://stats.stackexchange.com/questions/616632/how-to-interpret-ri-clpm-parameter-estimates-when-means-of-variables-decrease-ov</guid>
      <pubDate>Tue, 23 May 2023 01:12:48 GMT</pubDate>
    </item>
    </channel>
</rss>