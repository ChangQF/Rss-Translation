<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 05 Aug 2024 03:17:42 GMT</lastBuildDate>
    <item>
      <title>缺失数据超过 50% 的填补理由</title>
      <link>https://stats.stackexchange.com/questions/652307/justification-for-imputation-with-over-50-missing-data</link>
      <description><![CDATA[我希望就以下情况获得一些建议/想法：假设我有一项前瞻性观察性研究，旨在评估按照护理标准使用药物 A 和药物 B 的人群在 2 年随访期间的 BMI 变化（主要结果）。重点不是比较 A 组和 B 组之间的 BMI，而是评估每个组内的 BMI 变化。
身高和体重测量应该每 6 个月进行一次（基线、6 个月、12 个月、18 个月和 24 个月），总共 24 个月。然而，由于退出率高，只有 40% 的参与者最终完成了整整 24 个月的随访，因此未达到主要结果的样本量目标。
考虑到研究的纵向性质，我正在考虑使用混合效应模型来解释参与者内的相关性，其中
固定效应针对时间（自基线以来的月份）、药物组及其相互作用。
随机效应：每个参与者的随机截距和斜率以解释个体差异。
但是，研究人员正在推动也进行缺失数据填补，但我不确定这是否可行，或者如何向监管机构证明这一点，因为我们必须填补超过 50% 的数据。
您将如何处理这种情况？这里是否需要进行插补？如果是，哪种插补方法最适合（也许是模式混合模型，因为缺失数据模式是 MNAR？）有没有什么文章可以推荐我阅读，了解其他人如何处理类似问题以及他们如何解决这个问题？
如能提供任何建议/参考，我将不胜感激。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652307/justification-for-imputation-with-over-50-missing-data</guid>
      <pubDate>Mon, 05 Aug 2024 02:49:05 GMT</pubDate>
    </item>
    <item>
      <title>选择轨迹模型中的组数</title>
      <link>https://stats.stackexchange.com/questions/652305/choosing-number-of-groups-in-trajectory-model</link>
      <description><![CDATA[我正在研究基于组的多轨迹模型，该模型有两个二元结果，每个结果在四个时间点进行测量。结果似乎在多大组数（四个或六个 - 五个组更差）最适合方面存在一些冲突，我不确定如何判断。
具体来说，六组解决方案具有更好的 BIC（约 100 分，因此证据确凿），并且正确分类的几率通常更高（OCC - 六组的 8.5-15 vs 四组的 5.7-12），但分配的平均后验概率 (APPA) 低于 Nagin 推荐的阈值 &gt;0.7（六组为 .54 - .81，四组为 .69-.84）。
我该如何选择/证明这个决定？]]></description>
      <guid>https://stats.stackexchange.com/questions/652305/choosing-number-of-groups-in-trajectory-model</guid>
      <pubDate>Mon, 05 Aug 2024 01:41:26 GMT</pubDate>
    </item>
    <item>
      <title>弱平稳过程混淆</title>
      <link>https://stats.stackexchange.com/questions/652301/weakly-stationary-process-confusion</link>
      <description><![CDATA[假设我抽样 $2n$ iid 正态分布 $A_k, B_k$，其中 $k=1,...n$，均值为 0，但 $Var(A_k) = Var(B_k)$。利用这些，我可以构建一个随机时间序列
$$X(t) := \sum_{k=1}^n (A_k + iB_k) e^{i\lambda_kt} + (A_k - iB_k) e^{-i\lambda_kt},$$ 其中 $0 &lt; \lambda_k$ 是某个固定（非随机）$n$ 实数序列。
现在，通过构造：

$X(t)$ 是实值。
对于所有 $t$，$E[X(t)] = 0$
$E[X(t)] = 4\sum_k Var(A_k) e^{i\lambda_k \tau}$（为此，写为 $Z_k = A_k + i B_k$，因此只有 4项）

具体来说，$X(t)$ 是一个实值、弱平稳序列。
接下来，我可以用以下代码生成其中一些：
def make_normal(lambdas, stds, T):
assert len(stds) == len(lambdas), &quot;必须为每个 lambda 提供一个 stddev。&quot;
lambdas.sort()
assert all([l &gt;= 0 for l in lambdas]), &quot;输入 lambda 必须是非负的&quot;

Z_real = np.random.normal(scale = stds)
Z_complex = np.random.normal(scale = stds)
如果 lambdas[0] == 0:
Z_real[0] /= 2
Z_complex[0] = 0

Z_real = np.concatenate([Z_real, Z_real])
Z_complex = np.concatenate([Z_complex, -Z_complex])
Z = Z_real + 1j*Z_complex

lambdas = [-l for l in lambdas] + lambdas

exps = np.exp(np.outer(lambdas, T)*1j)

返回 np.matmul(Z, exps)

lambdas = [0.1, 1, 2, 5, 10]
stds = [2, 1, 0.7, 0.5, 0.1]
T = [0.1*i for i in range(500)]
X = make_normal(lambdas, stds, T)
assert max(abs(np.imag(X))) &lt; 1e-10, &quot;TS 有点不对劲... 应该是真的！&quot;
plt.plot(T, np.real(X))


根据我见过的所有启发式方法，这绝对不是&quot;看起来是静止的&quot;。所以我的问题是以下哪项是正确的：

我的代码有问题。
我所了解的有关过程“看起来静止”的启发式方法完全是错误的 - 这个时间序列对我来说并不“看起来静止”，因为它似乎具有趋势、季节性等。我用此代码生成的几乎所有时间序列都具有这些特征。
其他东西完全错误！

感谢您的时间！:)]]></description>
      <guid>https://stats.stackexchange.com/questions/652301/weakly-stationary-process-confusion</guid>
      <pubDate>Sun, 04 Aug 2024 19:42:24 GMT</pubDate>
    </item>
    <item>
      <title>配对测量后提取重要样本</title>
      <link>https://stats.stackexchange.com/questions/652290/extraction-of-significant-samples-after-paired-measures</link>
      <description><![CDATA[我有两组时间配对值：A 和 B。我知道 B 显著高于
A（使用 Wilcoxon 检验）（我的样本量很小），但我想知道哪些样本的 B 有显著差异。
使用 B-A 的差异，我得到了时间变化的分布，并据此计算了置信区间（通过自举法）。
我不确定应该使用什么阈值来确定哪些样本在 A 和 B 之间确实有显著变化。
提前感谢 :)]]></description>
      <guid>https://stats.stackexchange.com/questions/652290/extraction-of-significant-samples-after-paired-measures</guid>
      <pubDate>Sun, 04 Aug 2024 16:12:40 GMT</pubDate>
    </item>
    <item>
      <title>嵌套 GLM 的 F 检验</title>
      <link>https://stats.stackexchange.com/questions/652281/f-test-for-nested-glm</link>
      <description><![CDATA[假设我们有两个嵌套的 GLM 模型 $M_0 \subset M_1$，分别具有 $q$ 和 $p$ 个参数。我们还知道两个模型中的弥散参数估计为相同的值，表示为 $\widehat{\phi} \neq 1$。我的目标是测试 $p-q$ 个附加参数在更大模型中的重要性。在这种情况下，适当的检验将是 F 检验（例如，参见第 4.7.6.2 节此处），其中
$$
F = \frac{D_0-D_1}{\widehat{\phi} (p-q)},
$$
其中 $D_0, D_1$ 是 $M_0$ 和 $M_1$ 的偏差。在同一本书中，偏差定义为
$$
D = 2 \phi(L_\textrm{full} - L),
$$
其中 $L_\textrm{full}$ 和 $L$ 是完整（饱和）模型和考虑模型的对数似然。简单来说，我们可以通过用 $\widehat{\phi}$ 代替 $\phi$ 来估计偏差，因此在我们的例子中
$$
F = \frac{2 \widehat{\phi} (L_\textrm{full} - L_0) - 2 \widehat{\phi}(L_\textrm{full} - L_1)}{\widehat{\phi} (p-q)} = \frac{2(L_1-L_0)}{p-q}。
$$
另一方面，我偶然发现了一个练习，其中给出了 $L_0, L_1$ 和 $\widehat{\phi}$，并且 F 比率计算为
$$
F = \frac{2(L_1-L_0)}{\widehat{\phi}(p-q)},
$$
这让我认为这里使用了缩放偏差（$D^* = D/\phi$）而不是常规偏差。
计算此统计数据的哪种方法是正确的？
我查找了很多不同的来源（例如 此处 或 此处)，但我觉得每一篇都说得不一样，我无法调和所有版本。任何帮助我都会很感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/652281/f-test-for-nested-glm</guid>
      <pubDate>Sun, 04 Aug 2024 13:05:05 GMT</pubDate>
    </item>
    <item>
      <title>在梯度下降中目标是否应该标准化？</title>
      <link>https://stats.stackexchange.com/questions/652232/should-the-target-be-standardized-in-gradient-descent</link>
      <description><![CDATA[假设我们有一个一般的损失函数，它依赖于一些参数$w$（例如神经网络权重）：
$$L_w =\frac{1}{N} \sum_i \ell(\hat{y}_i, y_i)$$
除了特征之外，标准化目标是否有好处？
也就是说，我们是否应该更倾向于优化$L_w&#39;$：
$$L_w&#39; =\frac{1}{N} \sum_i \ell\left(\hat{y}_i, \frac{y_i-\bar{y}}{\sigma} \right)$$
over $L_w$?
相关问题
在此问题的公认答案中，指出：

对输出进行归一化不会影响$f$的形状，因此通常没有必要。

其中$\hat{y} = f_w (x)$。然而，在训练期间我们优化了损失函数，因此$f$的形状无关紧要。]]></description>
      <guid>https://stats.stackexchange.com/questions/652232/should-the-target-be-standardized-in-gradient-descent</guid>
      <pubDate>Fri, 02 Aug 2024 23:09:42 GMT</pubDate>
    </item>
    <item>
      <title>假设 $Z_i$ 是独立同分布的。$N(0, 1).$ 且令 $M_n = \max\{Z_1, \ldots, Z_n\}$，表明 $P(M_n > t) \leq n(1 - \Phi(t))$</title>
      <link>https://stats.stackexchange.com/questions/652187/suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n-sh</link>
      <description><![CDATA[证明 $P(M_n &gt; t) \leq n(1 - \Phi(t))$
我的工作：
\begin{align}
&amp; P(M_n &gt; t) \leq P\left(\bigcup_{i=1}^n (Z_i &gt; t) \right) \\ \leq {} &amp; \sum_{i=1}^n P(Z_i &gt; t)= n(1 - \Phi(t))
\end{align&gt;
以上是否正确？]]></description>
      <guid>https://stats.stackexchange.com/questions/652187/suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n-sh</guid>
      <pubDate>Thu, 01 Aug 2024 22:30:21 GMT</pubDate>
    </item>
    <item>
      <title>生长曲线分析建议</title>
      <link>https://stats.stackexchange.com/questions/652146/growth-curve-analysis-advice</link>
      <description><![CDATA[我对生长曲线模型还不熟悉，需要一些指导。我有大约 50,000 只羊羔的数据，每只羊羔都有出生体重，并在出生后大约 30、60、90 和 120 天进行了两次额外测量。我想应用 Logistic、Gompertz 和 von Bertalanffy 等生长曲线模型。
我有一些顾虑：
我能否同时使用天数和所有动物记录进行生长曲线分析，还是需要为每只动物计算 A 和 K 等参数？
如果需要单独计算，每只动物进行三次测量是否足够？]]></description>
      <guid>https://stats.stackexchange.com/questions/652146/growth-curve-analysis-advice</guid>
      <pubDate>Thu, 01 Aug 2024 12:16:42 GMT</pubDate>
    </item>
    <item>
      <title>当预测变量出现错误时会发生什么？</title>
      <link>https://stats.stackexchange.com/questions/652131/what-happens-when-there-are-errors-in-the-predictor-variables</link>
      <description><![CDATA[我昨天问了这个问题，但现在无法登录我的账户了：在未来模型中使用响应变量作为预测变量？
在思考了这个问题（估计雇用新员工对工厂生产率的净成本效益影响）之后，我想到了一种看待这个问题的新方法（即当预测变量有错误时该怎么办？）。我认为也许可以使用工具变量？
方法 1：直接使用工具变量分析净收益

对员工和已处理订单之间的关系进行建模：
$$\hat{P}_t = \hat{\alpha} \hat{E}_t + \hat{\epsilon}_t$$
其中 $\hat{E}_t$ 是 $E_t$ 的仪表化版本。我们使用第一阶段回归：
$$E_t = \gamma_0 + \gamma_1 Z_t + \nu_t$$
$$\hat{E}_t = \hat{\gamma}_0 + \hat{\gamma}_1 Z_t$$
此处，$Z_t$ 为工具变量（例如，招聘的滞后预算分配）。

模型的其余部分保持不变，但在所有部分中使用 $\hat{E}_t$ 代替 $E_t$方程。


我认为工具变量$Z_t$（或$Z_{t-1}$）应该与员工人数相关，但不应直接与主方程中的误差项相关。这可能有助于解决潜在的内生性问题？
这就是工具变量的使用方式吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652131/what-happens-when-there-are-errors-in-the-predictor-variables</guid>
      <pubDate>Thu, 01 Aug 2024 05:19:04 GMT</pubDate>
    </item>
    <item>
      <title>独立样本均值乘积的 UMVUE</title>
      <link>https://stats.stackexchange.com/questions/652122/umvue-for-the-product-of-means-from-independent-samples</link>
      <description><![CDATA[设 $ x_1, \ldots, x_m $ 为从分布 $P$ 中抽取的 i.i.d. 样本，$ y_1, \ldots, y_n $ 为从分布 $Q$ 中抽取的 i.i.d. 样本。假设样本 $x_i$ 和 $y_j$ 彼此独立。假设 $\bar{X}$ 是 $\mu_X = E_{X \sim P}[X]$ 的均匀最小方差无偏估计量 (UMVUE)，而 $\bar{Y}$ 是 $\mu_Y = E_{Y \sim Q}[Y]$ 的 UMVUE。
参数 $\mu_X \mu_Y$ 的 UMVUE 是多少？ $\bar{X} \bar{Y}$ 是 $\mu_X \mu_Y$ 的 UMVUE 吗，或者有更好的估计量？]]></description>
      <guid>https://stats.stackexchange.com/questions/652122/umvue-for-the-product-of-means-from-independent-samples</guid>
      <pubDate>Thu, 01 Aug 2024 00:38:34 GMT</pubDate>
    </item>
    <item>
      <title>如何量化百分比排序数据集的重要性？</title>
      <link>https://stats.stackexchange.com/questions/652094/how-do-i-quantify-the-significance-of-a-percentage-ranked-data-set</link>
      <description><![CDATA[我正在考虑针对给定数据集的七种不同的预测模型，这些模型经过多次预测迭代，并量化每个预测模型总体上最准确的次数。
我需要某种方法来量化结果的重要性。例如，如果给定的预测模型在 7 个预测中排名第一的概率为 23%（7 个预测中平均分布为 14.2%），那么这有多重要？
我希望能够为这些结果的重要性建立某种基线。我怀疑这可能涉及某种正态分布，但我不知道如何计算。由于我总是使用百分比，并且总是考虑 7 个预测，因此一个参考表将是理想的选择 — 如果我能够指出 23% 是高度重要的，但 18% 是有点重要的或类似的情况。
就其本身而言，这些百分比缺乏足够的背景信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/652094/how-do-i-quantify-the-significance-of-a-percentage-ranked-data-set</guid>
      <pubDate>Wed, 31 Jul 2024 15:26:20 GMT</pubDate>
    </item>
    <item>
      <title>根据 AIc/BIC 标准比较具有不同规范的非嵌套模型</title>
      <link>https://stats.stackexchange.com/questions/650312/comparing-non-nested-models-with-different-specifications-based-on-aic-bic-crite</link>
      <description><![CDATA[我想确定在多元概率模型的情况下是否可以使用 AIC/BIC 标准进行模型选择。我有两个具有不同规格的模型：
例如模型 1：mvprobit（$Y_1 = a X_1 + b X_2 + c X_3），（Y_2 = a X_1 + b X_2 + c X_3 + \mathbf{s Y_1}），（Y_3 = a X_1 + b X_2 + c X_3 + \mathbf{s Y_1} + \mathbf{e Y_2}）$。
模型 2：mvprobit（$Y_1 = a X_1 + b X_2 + c X_3），（Y_3 = a X_1 + b X_2 + c X_3 + \mathbf{sY1}），（Y_2 = a X_1 + b X_2 + c X_3 + \mathbf{s Y_1} + \mathbf{e Y_3}$）。
这里（$a、b、c、s$和$e$是系数：$Y_1、Y_2、Y_3$是多元概率模型中的因变量）。
鉴于这些不同的模型规范，如果我从模型 1 和模型 2 获得 AIC/BIC 值，并根据最低 AIC/BIC 值选择更适合的模型，这种方法是否合理？
请注意，两个模型的数据和观测次数相同。]]></description>
      <guid>https://stats.stackexchange.com/questions/650312/comparing-non-nested-models-with-different-specifications-based-on-aic-bic-crite</guid>
      <pubDate>Tue, 02 Jul 2024 10:44:09 GMT</pubDate>
    </item>
    <item>
      <title>用于测量事件发生随时间变化的适当测试（RStudio）</title>
      <link>https://stats.stackexchange.com/questions/650267/appropriate-test-for-measuring-change-in-event-occurrence-over-time-rstudio</link>
      <description><![CDATA[我想看看为组织提供的降低事件发生率的培训计划是否真的具有减少事件发生率的预期效果。
每个参与研究的组织（理论上）都会让尽可能多的组织成员参加一项调查，要求他们以 1 到 5 的评分自我报告他们的经历。我说理论上是因为并非所有组织每年都进行调查，所以有些组织可能在前两年进行调查，第三年不进行调查，但在第四年再次进行调查，在选择统计测试时可能也需要考虑这一点。对于每个组织，都会计算出该组织中给出 4 或 5 评分的人员百分比的平均值。
然后，我在 RStudio 中对组织进行分组，以获得不同日历年（例如 2015、2016、2017）、注册日期的年份（注册的第一年、第二年、第三年等）和调查编号（第一次、第二次、第三次参加调查，无论他们是否在几年之间休息过等）的平均百分比。
我现在想分析这些平均值，看看这些不同的组的平均百分比是否会随着时间的推移而下降，但我不确定最合适的方法是什么。我附上了一些我制作的示例图：

最明显的方法是进行某种相关性/线性回归分析，但由于调查数字是连续的，因此并非完全独立，我不确定这样做是否正确？
我知道有可能做类似配对/重复测量方差分析的事情，但我只见过最多 3 次时间测量，而我有至少 7 个时间点，所以我不确定是否有硬性数字限制。我也没有多个组来比较平均值，这只是逐年的变化 - 但是因为并非所有组织每年都进行调查，所以我不知道是否也应该进行某种注册年份*调查数量方差分析比较来解释这一点。]]></description>
      <guid>https://stats.stackexchange.com/questions/650267/appropriate-test-for-measuring-change-in-event-occurrence-over-time-rstudio</guid>
      <pubDate>Mon, 01 Jul 2024 15:59:41 GMT</pubDate>
    </item>
    <item>
      <title>复合稀疏泊松过程</title>
      <link>https://stats.stackexchange.com/questions/635232/compound-and-thinning-poisson-process</link>
      <description><![CDATA[我在这里提出了一个问题具有变化 Lambda 的泊松分布？，我对泊松到达过程感到好奇，其中 lambda 参数根据 AR 过程或离散马尔可夫过程而变化。

我想知道：这些图中的任何一个都可以被视为细化过程或复合过程吗？
1) 细化过程：
让 $N$ 成为原始事件的数量具有速率参数$\lambda$的泊松过程。泊松稀疏过程 $N(t)$ 由以下公式给出：
$$N(t) = \sum_{i=1}^{N} X_i$$
其中：

$X_i$ 是伯努利随机变量，其为 1 的概率为 $g(t_i)$，为 0 的概率为 $1 - g(t_i)$，
$t_i$ 是原始泊松过程中第 $i$ 个事件的时间。
$g(t)$ 是一个随时间 $t$ 变化的概率分布函数。

对于原始泊松过程中的每个事件，根据概率分布 $g(t)$ 决定是保留还是丢弃。由此产生的过程 $N(t)$ 是原始泊松过程的细​​化版本。
2) 复合过程：
设 $N(t)$ 为速率为 $\lambda$ 的泊松过程，表示时间间隔 $[0, t]$ 内发生的事件数。
对于泊松过程中的每个事件，随机变量 $X_i$ 是第 $i$ 个事件的强度。随机变量 $X_1, X_2, \ldots$ 是独立且同分布的 (i.i.d.)。
复合泊松过程 $S(t)$ 定义为截至时间 $t$ 的所有事件的总和：
$$S(t) = \sum_{i=1}^{N(t)} X_i$$]]></description>
      <guid>https://stats.stackexchange.com/questions/635232/compound-and-thinning-poisson-process</guid>
      <pubDate>Tue, 19 Dec 2023 05:17:42 GMT</pubDate>
    </item>
    <item>
      <title>哪种统计检验合适？二元因变量，分类自变量</title>
      <link>https://stats.stackexchange.com/questions/591486/what-statistical-test-is-appropriate-binary-dependent-variable-categorical-ind</link>
      <description><![CDATA[我试图根据调查数据了解一个二元因变量（是否行贿以购买疫苗）与受访者居住地（城市、近郊和农村）之间的关系 - 受访者只能选择其中之一。哪些统计测试最合适？
以下是数据样本（N=5200）。我将独立变量分成不同的列，但如果需要，可以将其放回一列。理想情况下，我想知道每个预测因子的重要性和强度。如果我在这里遗漏了什么，请原谅 - 我是新手。
谢谢！！




城市
近郊
农村
（依赖）是否行贿以购买疫苗疫苗




0
0
1
0


1
0
0
0


0
0&lt; /td&gt;
1
0


1
0
0
0


0
0
1
0


0
0
1
0


0
1
0
1


0
0
1


0
0
1


0
0
1
0


0
0
1
0


0
0
1
0




后续问题 - 我假设我不能使用线性回归，但逻辑回归呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/591486/what-statistical-test-is-appropriate-binary-dependent-variable-categorical-ind</guid>
      <pubDate>Fri, 07 Oct 2022 14:10:58 GMT</pubDate>
    </item>
    </channel>
</rss>