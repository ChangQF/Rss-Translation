<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 20 Oct 2024 01:21:32 GMT</lastBuildDate>
    <item>
      <title>当损失情况保持不变时，为什么内部协变量转移会影响神经网络？</title>
      <link>https://stats.stackexchange.com/questions/656015/why-does-internal-covariate-shift-affect-neural-networks-when-the-loss-landscape</link>
      <description><![CDATA[当损失情况保持不变时，为什么内部协变量偏移会影响神经网络？在阅读有关内部协变量偏移以及批量标准化如何无法真正解决它的文章时，我突然意识到我并不真正理解为什么内部协变量偏移在实践中是一个问题。从理论上讲，这就像追逐一个奔跑的目标，这比追逐一个静态目标更难，但实际上，数学上的复杂性是什么？我的意思是，即使层之间的分布发生变化，损失情况也应该保持不变。]]></description>
      <guid>https://stats.stackexchange.com/questions/656015/why-does-internal-covariate-shift-affect-neural-networks-when-the-loss-landscape</guid>
      <pubDate>Sat, 19 Oct 2024 19:34:09 GMT</pubDate>
    </item>
    <item>
      <title>理解条件独立性的因式分解，摘自 Kevin Murphy 第 2 册</title>
      <link>https://stats.stackexchange.com/questions/656014/understanding-the-factorization-of-conditional-independence-from-kevin-murphy-bo</link>
      <description><![CDATA[我正在阅读 Kevin Murphy 的新书 2（高级主题），我想澄清一个简单的推导。在第 156-157 页，对概率图模型进行了分解。 pgm 显示如下

在下面显示的概率模型中：
$$
p(\theta, D) = p(\theta_x)p(\theta_y) \prod_{n=1}^{N} p(y_n \mid \theta_y)p(x_n \mid y_n, \theta_x) \tag{4.38}
$$
由此可知：
$$
p(\theta, D) = \left[ p(\theta_y) \prod_{n=1}^{N} p(y_n \mid \theta_y) \right] \left[ p(\theta_x) \prod_{n=1}^{N} p(x_n \mid y_n, \theta_x) \right] \tag{4.39}
$$
下一步写为：
$$
p(\theta, D) = \left[ p(\theta_y) p(D_y \mid \theta_y) \right] \left[ p(\theta_x) p(D_x \mid \theta_x) \right] \tag{4.40}
$$
其中：
$$
D_y = \{y_n\}_{n=1}^{N} \quad \text{and} \quad D_x = \{x_n, y_n\}_{n=1}^{N}。
$$
我的问题是：等式 $(4.40)$ 能否从 $(4.39)$ 得出？具体来说，方程$(4.40)$表明联合概率项$p(x_n, y_n \mid \theta_x)$，而不是$(4.39)$中的条件项$p(x_n \mid y_n, \theta_x)$。
我理解以下说法是正确的：
$$
p(x_n \mid y_n, \theta_x) = \frac{p(x_n, y_n \mid \theta_x)}{p(y_n \mid \theta_x)}。
$$
但是，除非我们假设 $y_n$ 和 $\theta_x$ 是独立的，否则方程 $(4.40)$ 怎么能成立呢？根据 d 分离规则，观察 $x_n$ 会使 $y_n$ 和 $\theta_x$ 相互依赖。有人能解释一下从 $(4.39)$ 到 $(4.40)$ 的转变的有效性吗？
PS：我已经在 math.stackoverflow 上问过这个问题，但没有得到任何答案。]]></description>
      <guid>https://stats.stackexchange.com/questions/656014/understanding-the-factorization-of-conditional-independence-from-kevin-murphy-bo</guid>
      <pubDate>Sat, 19 Oct 2024 17:56:27 GMT</pubDate>
    </item>
    <item>
      <title>使用截断正态分布规律的简化公式P(t)是否正确？</title>
      <link>https://stats.stackexchange.com/questions/656011/is-it-correct-to-use-the-simplified-formula-pt-for-the-truncated-normal-distri</link>
      <description><![CDATA[对于我们的研究，我们有一本指南，其中包含截断正态分布的公式：$$
P(t) = \frac{0.5 - \Phi \left( \frac{t - m}{\sigma} \right)}{0.5 + \Phi \left( \frac{m}{\sigma} \right)}
$$我将其用于具有以下条件的任务：
汽车发电机的运行时间遵循截断正态分布，参数为 m = 8000 小时，σ = 1000 小时。需要找到 10,000 小时无故障运行的概率、6,000 小时的故障率、10,000 小时的故障强度以及首次故障的平均时间。我得到的值为 -0.318，这对于概率来说不正确。之后，我使用了截断正态分布的标准公式：
$$P(t) = \frac{\Phi \left( \frac{t - m}{\sigma} \right) - \Phi \left( \frac{0-m}{\sigma} \right)}{1 - \Phi \left( \frac{0-m}{\sigma} \right)}
$$ 我得到了 0.9972 的结果，然后我就可以继续解决问题了。我是不是漏掉了什么？或者，由于 𝑧 的值很大，简化公式在这种情况下根本不正确？接下来，我使用以下公式解决了另一个关于正态分布的问题：$$P(t) = 0.5 - \Phi \left( \frac{t - m}{\sigma} \right)
$$ 我得到了正确的值，但它们与标准正态分布公式的结果有很大不同。使用简化公式是否正确？即使我们将它们用于学习，我也看不出与使用标准公式有什么区别，因为它们总是有效的。我遗漏了什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656011/is-it-correct-to-use-the-simplified-formula-pt-for-the-truncated-normal-distri</guid>
      <pubDate>Sat, 19 Oct 2024 17:47:11 GMT</pubDate>
    </item>
    <item>
      <title>MNAR（非随机缺失）不是一个无法证明的假设吗？</title>
      <link>https://stats.stackexchange.com/questions/656010/isnt-mnar-missing-not-at-random-just-an-unprovable-hypothesis</link>
      <description><![CDATA[如果参与者在干预或安慰剂分配后在研究中退出，并且我们根据这些退出结果分析数据，我们是否只能识别关联而不是因果关系，因为我们使用的是病例对照设计，其中病例是退出者，非病例是非退出者？
此外，除了随机分配的治疗（如药物或安慰剂）之外，难道不可能找到 MNAR 对任何变量的决定因素吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/656010/isnt-mnar-missing-not-at-random-just-an-unprovable-hypothesis</guid>
      <pubDate>Sat, 19 Oct 2024 17:40:43 GMT</pubDate>
    </item>
    <item>
      <title>OLS 线性回归为 +/-1 标​​准差，而不是平均值</title>
      <link>https://stats.stackexchange.com/questions/656008/ols-linear-regression-of-1-standard-deviation-and-not-the-mean</link>
      <description><![CDATA[我确信我忽略了一些细微差别...我知道 OLS 线性回归可用于确定观测数据 $y$ 的平均值如何依赖于独立数据 $x$。我还知道，分位数回归最小化绝对偏差，与 OLS 的平方偏差相反，可用于确定 $y$ 的中位数如何依赖于 $x$。如果我进一步以不同的方式衡量正偏差和负偏差，分位数回归可以确定 $y$ 的特定分位数/百分位数如何依赖于 $x$。在我的案例中，我使用分位数回归估计第 5 个百分位数截止值，以定义给定 $x$ 的 $y$ 观测值的正常/异常边界。
是否存在等效权重，可以确定 $y$ 的 $1.64\sigma$ 如何取决于 $x$？
我希望在筛查测试中设定一个截止值，以便我们能够将大约 5% 的筛查对象送去进一步评估。目前，截止点是 $y$ 的第 5 个百分位数，该百分位数是根据 $y$ 的 10 万个观测值计算得出的，同时忽略 $x$。我们知道 $y$ 取决于 $x$，并且第 5 个百分位数和第 50 个百分位数的分位数回归不同，但第 50 个百分位数的回归与 OLS 回归大致相同。我想通过使用 $x$ 来改进截止点。]]></description>
      <guid>https://stats.stackexchange.com/questions/656008/ols-linear-regression-of-1-standard-deviation-and-not-the-mean</guid>
      <pubDate>Sat, 19 Oct 2024 16:42:26 GMT</pubDate>
    </item>
    <item>
      <title>什么时候 bagging 实际上会导致更高的方差？</title>
      <link>https://stats.stackexchange.com/questions/656007/when-can-bagging-actually-lead-to-higher-variance</link>
      <description><![CDATA[根据线性回归的高斯-马尔可夫假设，普通最小二乘估计 (OLS) 在所有无偏线性估计中具有最小方差。
在这种情况下，“Bagging”也是线性和无偏的，因此其方差必须严格更差。基于零独立变量（即只有一个偏差项）的情况，我的直觉是，当随机采样数据的模型数量趋于无穷大时，方差接近 OLS。
在决策树的设置中，与使用单个决策树相比，从 bagging（随机森林）获得的方差更低，这并不让我感到惊讶。但考虑到线性回归的情况，我看到的对此的解释似乎证明太多了。应满足哪些条件才能确保 bagging 不会使方差恶化？]]></description>
      <guid>https://stats.stackexchange.com/questions/656007/when-can-bagging-actually-lead-to-higher-variance</guid>
      <pubDate>Sat, 19 Oct 2024 15:28:15 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中 95% 的能量减少如何影响准确性和效率？</title>
      <link>https://stats.stackexchange.com/questions/656003/how-does-a-95-energy-reduction-in-neural-networks-affect-accuracy-and-efficienc</link>
      <description><![CDATA[本月初，arXiv 上发表了一篇引人入胜的论文：
“加法是节能语言模型所需的全部”
作者提出了一种算法，$\mathcal{L}\text{-Mul}$，该算法声称可将元素浮点 (FP) 张量乘法的能耗降低高达 95%，点积的能耗降低 80%。关键创新是使用整数加法近似 FP 乘法，有可能保持几乎相同的模型精度，同时大幅提高效率
从表面上看，这似乎是一个突破性的发现。
传统上，FP 算法涉及将两个浮点数的尾数相乘，其复杂度为二次（$O(m^2)$，其中 $m$ 是尾数中的位数）。这通常是一个计算瓶颈。 $\mathcal{L}\text{-Mul}$ 使用加法的线性组合来近似这个尾数乘法，将复杂度降低到 $O(m)$，从而优化了时间效率和功耗。
阅读本文时，我发现了一些问题：

精度比较仅针对 fp8 格式，但节能效果与 fp16 和 fp32 等较大格式进行了比较，这似乎不一致。需要澄清的是，fp8（8 位浮点）、fp16（16 位浮点）和 fp32（32 位浮点）代表浮点格式中不同级别的数值精度，其中 fp8 提供的精度最低，而 fp32 提供的精度最高。位大小越低（例如 fp8），用于存储数字的位就越少，这可以减少内存和计算需求，但代价是精度。将 $\mathcal{L}\text{-Mul}$ 的节能效果与 fp16 和 fp32（本质上使用更多位和功率）进行比较，可能会对能效产生不公平的乐观看法，因为该算法以较低的精度运行。理想情况下，应在一致的水平上比较精度和能量，以避免得出误导性结论。

该论文缺乏大规模测试或实际部署，因此大多数声明都只是理论上的。

有许多拼写和语法错误，有损专业语气，给人一种仓促发布的印象。我知道作者可能不是英语母语人士，但即使粗略校对也能发现大部分错误。

这篇论文包含相当多的拼写和语法错误，这降低了其可读性和专业性。它给人一种仓促完成的印象，这对于旨在引入重大突破的技术预印本来说是不寻常的。仔细校对会加强这篇论文。

实验似乎缺乏大规模测试或实际部署结果。鉴于降低能耗的雄心勃勃的主张，大规模的实际评估将为该方法提供可信度。目前的评估仅限于基准测试，而不是功耗更为关键的大型部署设置。

该方法在硬件效率方面仍处于理论阶段。虽然它在软件模拟中显示出前景，但需要硬件级实现来确认节能效果。如果没有这一点，节能声明可能无法完全转化为实践。


我还认为两位作者都在一家公司工作，而不是在大学工作，这很有趣：BitEnergy AI：https://bitenergy.ai/
好的，最后：
神经网络中 95% 的能量减少如何影响准确性和效率？]]></description>
      <guid>https://stats.stackexchange.com/questions/656003/how-does-a-95-energy-reduction-in-neural-networks-affect-accuracy-and-efficienc</guid>
      <pubDate>Sat, 19 Oct 2024 13:48:05 GMT</pubDate>
    </item>
    <item>
      <title>两个随机变量之间差异的概率区间</title>
      <link>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</link>
      <description><![CDATA[假设 X1 和 X2 是两个随机变量，其中 X1 有 95% 的概率位于区间 [L1, R1] 内，X2 有 95% 的概率位于区间 [L2, R2] 内。这是否意味着差值 X1 - X2 有超过 95% 的概率位于区间 [L1 - R2, R1 - L2] 内？此外，X1 和 X2 可以是相关的，也可以是独立的。
(1) 有人可以澄清概率界限是否适用于这种情况吗？或者这个说法的反例。
(2) 如果有反例，是否有其他条件可以添加以使其成立？]]></description>
      <guid>https://stats.stackexchange.com/questions/655983/the-probability-interval-of-the-difference-between-two-random-variables</guid>
      <pubDate>Fri, 18 Oct 2024 19:35:37 GMT</pubDate>
    </item>
    <item>
      <title>我们如何模拟在多层次/混合效应设置中在不同层次上变化的相关随机变量？</title>
      <link>https://stats.stackexchange.com/questions/655980/how-can-we-simulate-correlated-random-variables-that-vary-at-different-levels-in</link>
      <description><![CDATA[我非常熟悉从多元正态分布中生成相关随机变量。
这个问题是关于在多级设置中执行此操作，其中变量仅在分组变量的特定级别上变化。
假设我们有一个分组因子 - group，我们希望模拟 2 个随机变量，x1 和 x2，其中 x1 在较低级别变化，x2 在较高级别变化。假设下层有 100 个（n1 = 100）观测值，上层有 20 个不同的观测值（n2 = 20，但显然每个值都重复 5 次，因此组大小都相等（即每组 5 个）。
我们如何模拟 x1 和 x2，使得 sd(x1) = 5 和 sd(x2) = 3 以及 Cov(x1,x2) = 2？
我不需要任何代码。我有一些代码，但希望得到一些关于该方法的反馈，如下所示：
在这种模拟两级分层模型数据的方法中，我们旨在生成两个随机变量，x1 和x2，其中 x1 在较低（个体）水平上变化，而 x2 在较高（组）水平上变化。关键目标是确保 x1 和 x2 的标准差分别指定为 5 和 3，并且 x2 的扩展版本（在组内个体之间复制）和 x1 之间的协方差设置为 2（出于此模拟的目的）。该过程首先在组级别生成 x2，其中包含 20 个组的 20 个不同值，每个值的标准差为 3。然后，这些组级别值在每个组内的个体之间复制，以创建扩展的 x2。为了实现 x1 和 x2 之间所需的协方差，我们计算一个将 x1 与扩展的 x2 相关联的共享分量。此共享分量来自协方差公式，将所需的协方差除以扩展的 x2 的方差。然后，我们通过向共享分量添加独立噪声来生成 x1，确保 x1 的整体方差等于 5。此方法尝试允许跨层次结构级别控制相关数据的生成，从而确保正确的标准差和协方差。这是我实现此功能的代码。
# 参数
n1 &lt;- 1000 # 1 级（个体级）的观察总数
n2 &lt;- 200 # 2 级（组级）的组总数
group_size &lt;- n1 / n2 # 每个组的大小

# 所需的标准差和协方差
sd_x1 &lt;- 5
sd_x2 &lt;- 3
cov_x1_x2 &lt;- 2

# 模拟次数
n_sim &lt;- 100

vec_sd_1 &lt;- numeric(n_sim)
vec_sd_2 &lt;- numeric(n_sim)
vec_cov &lt;- numeric(n_sim)

set.seed(15)

for (i in 1:n_sim) {

# 1. 生成组级变量 x2（sd = 3）
x2_group &lt;- rnorm(n2, mean = 0, sd = sd_x2)

# 2. 为组中的每个个体复制 x2（扩展 x2）
x2 &lt;- rep(x2_group, each = group_size) # 这使得 x2 长度为 n1

# 3. 根据扩展的 x2 计算正确的共享组件
shared_component &lt;- cov_x1_x2 / var(x2) # 与扩展的 x2 相关的 x1 部分

# 4. 生成个体级随机变量 x1
x1 &lt;- x2 * shared_component + rnorm(n1, mean = 0, sd = sqrt(sd_x1^2 - shared_component^2 * var(x2)))

# 检查结果
group &lt;- rep(1:n2, each = group_size)

# 带有模拟数据的数据框
data &lt;- data.frame(group = factor(group), x1 = x1, x2 = x2)

vec_sd_1[i]&lt;- sd(data$x1)
vec_sd_2[i] &lt;- sd(data$x2)
vec_cov[i] &lt;- cov(data$x1, data$x2) 

}

mean(vec_sd_1) 
mean(vec_sd_2)
mean(vec_cov)

结果如下：
&gt;平均值（vec_sd_1） 
[1] 4.990359
&gt; 平均值（vec_sd_2）
[1] 2.994848
&gt; 平均值（vec_cov）
[1] 2.003473

看起来不错，任何反馈都会很感激！]]></description>
      <guid>https://stats.stackexchange.com/questions/655980/how-can-we-simulate-correlated-random-variables-that-vary-at-different-levels-in</guid>
      <pubDate>Fri, 18 Oct 2024 18:23:10 GMT</pubDate>
    </item>
    <item>
      <title>GMM 估计器加权矩阵背后的直觉</title>
      <link>https://stats.stackexchange.com/questions/655920/intuition-behind-the-weighting-matrix-of-a-gmm-estimator</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/655920/intuition-behind-the-weighting-matrix-of-a-gmm-estimator</guid>
      <pubDate>Thu, 17 Oct 2024 18:14:46 GMT</pubDate>
    </item>
    <item>
      <title>条件不平衡独立变量在回归中是一个问题吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/655709/are-conditional-unbalanced-independent-variables-an-issue-in-regression</link>
      <description><![CDATA[这是一个非常具体的问题，无缘无故关闭了...
描述
我有一个具有以下特征的数据集：

Y：平衡的二元因变量（例如 50% 就业/50% 失业）
X1：平衡的二元自变量（例如 50% 治疗/50% 控制）
X2：分类自变量（例如国家）

X1 是感兴趣的变量，目标是估计 X1 对 Y 的因果影响，而不是预测。
可以观察到 X2 和 X1 以及 X2 和 Y 之间的相关性（或关系，因为变量不是度量）。
问题
如果我将 X1 和 X2 分组（例如按国家/地区进行治疗和未治疗），我可以观察到子组不平衡。在某些子组中，接近 100% 的数据来自某个 x1 类（例如治疗组），在其他子组中，接近 100% 的数据来自不同的类（例如未治疗组），在某些子组中，数据在 x2 方面是 50%/50% 平衡的。换句话说，有些子组是纯粹的。
问题：

从数学角度来看，条件子组不平衡（或在极端情况下是纯粹性）是否会成为 x1 系数/估计量及其重要性的问题？如果一个条件子组是纯粹的（例如由 100% 控制或治疗单位组成），会发生什么？

Peter Floms 的回答暗示这可能是一个分离问题。但是，从我的角度来看，分离是一种现象，定义为预测因子完美地分裂/预测独立变量。但在这种情况下，条件子组中没有方差，但结果中有方差，因此它不是完美地分割因变量。]]></description>
      <guid>https://stats.stackexchange.com/questions/655709/are-conditional-unbalanced-independent-variables-an-issue-in-regression</guid>
      <pubDate>Sun, 13 Oct 2024 00:15:01 GMT</pubDate>
    </item>
    <item>
      <title>余弦相似度对连续变量的有用性</title>
      <link>https://stats.stackexchange.com/questions/655510/cosine-similarity-usefulness-for-continuous-variables</link>
      <description><![CDATA[有人要求我识别与产品 A 相似的“同类”产品，有人建议我识别一组相关特征并计算每个可能相似的产品与产品 A 之间的余弦相似度。我将使用的特征主要是数字，尽管我也会包含一些离散变量。
这引出了一个关于余弦相似度何时有用的一般问题。例如，如果我有两个向量：
p1 = [10, 20, 40]

p2 = [1000, 2000, 4000]

在这种情况下，cosine_sim(p1, p2) = 1。
但是，如果虽然向量彼此成比例，但每个向量值的幅度差异是有意义的，该怎么办？例如，如果我考虑的特征之一是产品 A 和产品 B 的平均产品增长加速度，那么 10% 和 1000% 的加速度是有显著差异的。对于离散值，我更了解为什么这种度量有意义，但很难理解它对连续变量的用处。
我应该使用不同的相似性度量吗？我的想法正确吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/655510/cosine-similarity-usefulness-for-continuous-variables</guid>
      <pubDate>Wed, 09 Oct 2024 03:36:30 GMT</pubDate>
    </item>
    <item>
      <title>RA Fisher（或“Fisherian”）如何选择样本大小？</title>
      <link>https://stats.stackexchange.com/questions/654905/how-would-ra-fisher-or-a-fisherian-choose-sample-sizes</link>
      <description><![CDATA[正如许多其他 CV.SE 帖子（例如此处或此处）中所述，RA Fisher 和 Neyman &amp; Pearson 的统计假设检验框架在实践和解释上存在差异。
我很好奇他们在如何设计您的研究方面的差异。为了简单起见，我将重点关注样本量（但当然，功效和精度也会受到研究设计的其他方面的影响，例如阻塞等）。
在 N-P 框架下，一般方法对我来说很清楚：首先确定您想要的功效，您感兴趣的特定替代点假设 $H_A$（例如，就您想要检测的最小效应大小而言），以及您可以容忍的 I 类错误率 $\alpha$。从那里，您可以计算出实现 $\alpha$ 和 $H_A$ 所需功效所需的样本量。
但据我了解，在 Fisher 方法中，没有 $\alpha$、没有 $H_A$，也没有明确的功效计算。那么 Fisher 如何为自己的研究选择样本量？（或者他如何建议其他人规划样本量？）

我很好奇，尤其是因为 Fisher 确实写过“一个设计合理的实验”通常会产生较低的 p 值。

就我个人而言，作者更喜欢将显着性标准设定为 5%。点，并完全忽略所有未达到该水平的结果。只有当经过适当设计的实验很少失败时，科学事实才应被视为实验确定的。

-- Fisher, R. A. 田间实验的安排。《农业部期刊》，1926 年，33，第 504 页。
对我来说，这句 1926 年的引言（尤其是“很少失败”）听起来很像说精心设计的实验应该具有很高的功效：尽管他没有指定特定的$H_A$，但 Fisher 想象在相同的人群中重复使用相同设计的相同实验（尽管在这句话中，这些实验是否重复是假设的或应该实际执行的），并反复获得等于或低于 5% 显著性水平的结果。
如果 Fisher 同意设置显著性水平，并且 Fisher 也致力于实现高功效——那么他还能做什么来选择样本量来实现这些目标，同时又与 N-P 的整体方法有实质性的不同？
（当然，还有贝叶斯方法、似然法，也许还有其他非 Fisher 和非 NP 方法。但我特别想问的是，什么才算是 Fisher 但非 NP。）]]></description>
      <guid>https://stats.stackexchange.com/questions/654905/how-would-ra-fisher-or-a-fisherian-choose-sample-sizes</guid>
      <pubDate>Wed, 25 Sep 2024 18:08:15 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器神经网络的信息平面定理是什么？</title>
      <link>https://stats.stackexchange.com/questions/589944/what-is-the-information-plane-theorem-for-an-autoencoder-neural-network</link>
      <description><![CDATA[斯坦福研讨会 - 深度学习信息理论，Naftali Tishby 的第 8 张幻灯片（视频约 19 分钟）有以下（非正式陈述的）定理。

定理（信息平面）对于大型典型 $\mathbf{X}$，DNN 的样本复杂度完全由最后一个隐藏层的编码器互信息 $\mathbf{I(X;T)}$ 决定；准确度（泛化误差）由最后隐藏层的解码器信息$\mathbf{I(T;Y)}$决定。

我很难理解“样本复杂度完全确定”是什么意思。这个定理的确切表述是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/589944/what-is-the-information-plane-theorem-for-an-autoencoder-neural-network</guid>
      <pubDate>Sat, 24 Sep 2022 18:15:46 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该将训练集和验证集合并以进行最终的 NN 模型训练？如果是，何时停止训练最终模型？</title>
      <link>https://stats.stackexchange.com/questions/575350/should-i-join-train-and-validation-sets-for-final-nn-model-training-if-yes-whe</link>
      <description><![CDATA[通常我们将数据集分为 3 组：

训练集，
验证集，
测试集。

我们使用训练集来找到最佳参数（NN 的权重和偏差），使用验证集来找到最佳 NN 架构（例如隐藏层的数量、每个隐藏层中的神经元数量...）。
这是我的问题：在我们找到模型的最佳架构（使用验证集）和使用早期停止和验证集的最佳训练周期数（对于最佳模型架构）后，以下哪项更合适：

在测试集上测试最终模型（仅在训练集上训练），
合并训练和验证集（不要浪费验证数据）并在合并集（训练 + : 我们应该使用最佳的早期停止次数（因为它对于训练集来说是最佳的，但对于训练 + 验证来说不是最佳的）还是停止标准应该是其他的？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/575350/should-i-join-train-and-validation-sets-for-final-nn-model-training-if-yes-whe</guid>
      <pubDate>Sun, 15 May 2022 11:53:47 GMT</pubDate>
    </item>
    </channel>
</rss>