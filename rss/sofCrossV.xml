<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 15 Jan 2025 15:17:05 GMT</lastBuildDate>
    <item>
      <title>使用广义加性模型帮助进行电力市场预测</title>
      <link>https://stats.stackexchange.com/questions/660065/help-with-forecasting-using-generalized-additive-models-in-the-electricity-marke</link>
      <description><![CDATA[我是样条模型的新手，正在尝试了解其在电力市场预测中的应用。具体来说，我正在研究意大利电力交易所的负责实体 Gestore dei Mercati Energetici (GME) 的每小时拍卖数据。
在这种情况下，无论采用何种竞标策略，预测竞争对手的竞标行为（特别是在向市场提交供应计划之前，预测竞争对手以所有可能价格提供的总数量）非常重要。我专注于预测剩余供应曲线的任务。企业 $i$ 的利润函数为：
$$ \pi(p) = p \cdot \left(D - S_{-i}(p)\right) - C_i\left(D - S_{-i}(p)\right) $$
其中：

$D$ 为电力需求
$S_{-i}(p)$ 为企业 $i$ 竞争对手在价格为 $p$ 时的总供给函数
$C_i(q)$ 为企业的生产成本函数$i$ 给定数量 $q$

我使用的数据包括每小时拍卖结果，其中的列表示每个生产单位的价格-数量对。这些步骤创建了一个表示聚合供应函数的阶跃函数。由于广义加性模型 (GAM) 适用于平滑函数，因此我明白我需要使用样条函数将这些阶跃函数近似为平滑曲线。
我的问题：

使用 GAM 建模和预测供应函数时，我应该遵循哪些关键概念步骤？我的意思是，我如何（在实践中）创建供应函数，以及我必须遵循哪些步骤才能使用 GAM 模型来预测它？
使用广义加法模型来完成这项任务是否合理？
建议使用哪种平滑技术或样条函数（例如三次样条函数、薄板样条函数）？

如能就构建此类模型的最佳实践提供任何建议或见解，我们将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660065/help-with-forecasting-using-generalized-additive-models-in-the-electricity-marke</guid>
      <pubDate>Wed, 15 Jan 2025 14:19:20 GMT</pubDate>
    </item>
    <item>
      <title>给定 5 个随机变量，关于条件独立性的问题</title>
      <link>https://stats.stackexchange.com/questions/660063/a-question-regarding-conditional-indepence-given-5-random-variables</link>
      <description><![CDATA[设 $U,V,W,X,Y$ 为满足下列条件的 5 个随机变量：
$$P(U,V,W,X,Y) = P(U)P(V)P(W|U,V)P(X|W)P(Y|W)$$
如何得出 $ \text{给定 W，Y 条件独立于 V} $ 语句为假，而 $ \text{给定 𝑊，𝑈 和 𝑉 条件独立于 𝑊} $ 语句为真？
我的尝试
我不知何故觉得会使用以下恒等式：
$$P(U,V,W,X,Y) = P(U)P(V|U)P(W|U,V)P(X|U,V,W)P(Y|U,V,W,X)$$。但我将其等同于问题的右侧，但无法取得太大进展。
我还需要知道“给定...，...独立于...”在数学上到底是什么意思？我理解随机变量独立性的定义，但如果有人能澄清“条件独立性”是什么意思，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660063/a-question-regarding-conditional-indepence-given-5-random-variables</guid>
      <pubDate>Wed, 15 Jan 2025 14:04:10 GMT</pubDate>
    </item>
    <item>
      <title>具有重叠数据的 Kolmogorov Smirnov</title>
      <link>https://stats.stackexchange.com/questions/660060/kolmogorov-smirnov-with-overlapped-data</link>
      <description><![CDATA[我在第 11 页找到了以下文章，其中提出了一种测试重叠数据的方法。
我不清楚这是否适用于任何基础分布测试，而不仅仅是正态分布，以及为什么我们在这个测试中以这种方式使用正态分布。
https://www.cambridge.org/core/services/aop-cambridge-core/content/view/B20D66D81DB918AFD3BBDF9EDAC20863/S1357321719000151a.pdf/calibration_of_var_models_with_overlapping_data.pdf]]></description>
      <guid>https://stats.stackexchange.com/questions/660060/kolmogorov-smirnov-with-overlapped-data</guid>
      <pubDate>Wed, 15 Jan 2025 13:38:25 GMT</pubDate>
    </item>
    <item>
      <title>部分 F 检验 - 首先针对完整模型 $L_{AxB}$ 测试简化的 OLS 模型 $L_A$ 是否有效？</title>
      <link>https://stats.stackexchange.com/questions/660059/partial-f-test-is-it-valid-to-test-the-reduced-ols-model-l-a-against-the-ful</link>
      <description><![CDATA[我正在执行部分 F 检验，我想知道我是否可以使用简化模型 $L_A$ 对包含主效应和交互项的 OLS 完整模型进行部分测试。如果我得到一个不显著的 p 值，我是否只能得出同时删除 $L_B$ 和 $L_{A:B}$ 的结论，还是我可以分别对它们进行一些有教育意义的说明？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/660059/partial-f-test-is-it-valid-to-test-the-reduced-ols-model-l-a-against-the-ful</guid>
      <pubDate>Wed, 15 Jan 2025 13:35:27 GMT</pubDate>
    </item>
    <item>
      <title>如何解释/计算 R 的 mediate 包中的 ADE（控制）？</title>
      <link>https://stats.stackexchange.com/questions/660058/how-do-you-interpret-calculate-ade-control-in-rs-mediate-package</link>
      <description><![CDATA[我是因果中介分析的新手。我目前正在研究 R 的“中介”包，并研究 Tingley 等人 (2014) 的《统计软件杂志》论文。
话虽如此，我很难理解这篇论文中某些输出背后的直觉——特别是“ADE（控制）”。我知道这是对照组的平均（自然）直接效应，但原则上，我不明白你怎么会对对照组产生直接影响——因为对照组没有接受治疗。
我不太关心这里的数字输出，这就是为什么我没有提供任何输出。相反，我希望有人能简单地解释他们是如何得到对照组的自然直接效应的，以及它意味着什么（直观地）？
我目前的想法是，这是一个反事实计算，其中计算“如果对照组接受治疗”的效果同时将中介效应保持在可观察到的水平。然而，我很难证明自己是对还是错。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660058/how-do-you-interpret-calculate-ade-control-in-rs-mediate-package</guid>
      <pubDate>Wed, 15 Jan 2025 12:58:21 GMT</pubDate>
    </item>
    <item>
      <title>RKHS 与核学习中特征空间的关系</title>
      <link>https://stats.stackexchange.com/questions/660057/relation-of-rkhs-to-feature-space-in-kernel-learning</link>
      <description><![CDATA[在标准 SVM 公式中，我们通常会寻找一个向量 $w \in \mathbb{R}^D$，该向量定义 $\mathbb{R}^D$ 中的超平面。决策函数的形式如下：
$$
f(x) = \operatorname{sign}(\langle w, x \rangle + b),
$$
其中 $\langle \cdot, \cdot \rangle$ 是 $\mathbb{R}^D$ 中的标准内积，而 $b \in \mathbb{R}$ 是偏差项。
现在，假设我们有一个 p.d 内核 $k$，我们知道有一个唯一的 RKHS $H_k$，因此我们可以寻找 $f \in H_k$ 在 $H_k$ 中定义一个超平面。相应的决策函数变为：
$$
f(x) = \operatorname{sign}(\langle f, \phi_1(x) \rangle_{H_k} + b),
$$
其中 $\phi_1(x) = k(\cdot, x) \in H_k$ 是进入 RKHS 的规范特征图。现在，例如通过铰链损失公式的软边距 svm，我们可以使用表示定理来论证 $f^*$ 位于由我们的训练模式引起的规范特征图的跨度内。
问题
现在，我的问题如下。在这个公式中，我们“看”对于 RKHS 中的超平面，但在大多数标准介绍中，人们认为我们在（可能无限的）特征空间中寻找超平面。
我知道 $k$ 会诱导另一个特征图（实际上，我认为有无数个，因为内积对正交变换不变？）$\phi_2: X \to F$ 进入某个希尔伯特空间 $F$，满足：
$$
\langle \phi(x)_2, \phi(y)_2 \rangle_{F} = k(x, y)。
$$
因此，我们有两个特征图：
$$
\phi_{1}: x \mapsto k(\cdot, x) \in H_k \quad \text{(进入 RKHS 的规范映射),}
$$
$$
\phi_{2}: x \mapsto \phi_2(x) \in F \quad \text{(进入某个希尔伯特空间 $F$ 的映射)}。
$$
我们现在是否可以争辩说，找到某个 $f^* \in H_k$ 将自动导致 $g^* \in F$，如下所示：
$$
\langle \phi(x)_2, \phi(y)_2 \rangle_{F} = \langle \phi(x)_1, \phi(y)_1 \rangle_{H_k} = k(x, y) $$
因此
$$ \langle f^*, \phi_1(y) \rangle_{H_k} = \sum_{i=1}^n \alpha_i \langle \phi_1(x_i), \phi_1(y) \rangle_{H_k} = \sum_{i=1}^n \alpha_i \langle \phi_2(x_i), \phi_2(y) \rangle_{F} = \langle g^*, \phi_2(y) \rangle_{F}$$]]></description>
      <guid>https://stats.stackexchange.com/questions/660057/relation-of-rkhs-to-feature-space-in-kernel-learning</guid>
      <pubDate>Wed, 15 Jan 2025 12:18:36 GMT</pubDate>
    </item>
    <item>
      <title>使用季节性虚拟变量来表示季节性[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660054/using-seasonal-dummies-for-seasonality</link>
      <description><![CDATA[我正在研究月度国内生产者价格指数系列。我需要使用季节性虚拟变量来捕捉确定性季节性。我使用了 11 个虚拟变量和趋势。
为此，我是否需要使用系列 D-PPI 的自然对数 log(DPPI)？还是我应该使用原始数据系列 DPPI？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/660054/using-seasonal-dummies-for-seasonality</guid>
      <pubDate>Wed, 15 Jan 2025 11:06:09 GMT</pubDate>
    </item>
    <item>
      <title>BAM mgcv 算法的收敛性</title>
      <link>https://stats.stackexchange.com/questions/660053/convergence-of-bam-mgcv-algorithm</link>
      <description><![CDATA[在之前的文章中，我描述了 mgcv 的 BAM 算法的可重复性问题，并得到了非常有用的反馈：BAM mgcv 算法的可重复性
然而，可重复性并不是我观察到的唯一问题。在某些例子中，我还发现 bam() 无法收敛。
最小可重现示例
以下内容基于由协变量 x、y 和目标变量 z 组成的 20,000 个数据点的数据集，可在此处下载：https://drive.google.com/file/d/14ltM1Z4O9WW7h1jkrAp52v4meiauGsME/view?usp=sharing
以下代码尝试将基于 bam() 的空间平滑拟合到上述数据集：
set.seed(1) # 不确定这是否有区别，但设置种子以防万一

模型 &lt;- mgcv::bam(z ~ s(x, y, k = 500),
数据 = 数据集,
家庭 = tw(link=log),
方法 = &quot;fREML&quot;)

但返回以下警告消息：
警告消息：
在 bgam.fit(G, mf, chunk.size, gp, scale, gamma, method = method, :
算法没有收敛

相比之下，以下代码适合标准 gam 模型而不会引发收敛警告：
set.seed(1) #不确定这是否有区别，但设置种子以防万一

模型 &lt;- mgcv::gam(z ~ s(x, y, k = 500),
数据 = 数据集,
家庭 = tw(link=log),
方法 = &quot;REML&quot;) 

总结和问题
这是已知的 bam() 行为吗？除了简单地切换回 gam() 之外，还能做些什么来确保收敛？我曾尝试使用 maxit 关键字增加 IRLS 迭代次数，但没有成功。
我推测我的数据的“质量”可能相当差，因此有人可能会说，mgcv 很难将波动的空间平滑拟合到它并不完全令人惊讶。另一方面，gam() 似乎没有问题，因此绝对有可能实现所需的收敛。]]></description>
      <guid>https://stats.stackexchange.com/questions/660053/convergence-of-bam-mgcv-algorithm</guid>
      <pubDate>Wed, 15 Jan 2025 10:11:29 GMT</pubDate>
    </item>
    <item>
      <title>在线性误差传播过程中如何选择正确的公式？</title>
      <link>https://stats.stackexchange.com/questions/660052/how-to-choose-the-correct-formula-during-linear-error-propagation</link>
      <description><![CDATA[我正在使用线性误差传播的标准公式来估计变量中的不确定性，这些变量是根据平均实验可观测量计算出来的（使用标准偏差作为不确定性估计），但遇到了一个障碍。例如，考虑一个变量$k$，它可以计算为
$$k = 1-\frac{G\times I}{P} \tag{1}$$
作为可观测量$G$、$I$和$P$的函数。
但是，上述内容可以改写为
$$k = \frac{P-G\times I}{P} \tag{2}$$
但是，与方程 (1) 相关的传播不确定性似乎与方程 (2) 相关的不确定性不同，因为 $P$ 的值在方程 (2) 中出现了两次，而与方程 (1) 中的常数 (&quot;$1$&quot;) 相关的不确定性为零。
我遗漏了什么？在这种情况下，使用错误传播的正确方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/660052/how-to-choose-the-correct-formula-during-linear-error-propagation</guid>
      <pubDate>Wed, 15 Jan 2025 09:42:21 GMT</pubDate>
    </item>
    <item>
      <title>L2 惩罚 cox 比例风险回归的统计推断</title>
      <link>https://stats.stackexchange.com/questions/660048/statistical-inference-for-l2-penalized-cox-proportional-hazard-regression</link>
      <description><![CDATA[首先，感谢您阅读我的问题。这是我第一次在这个平台上提问，所以如果某些要求没有得到满足，我深表歉意。
我试图使用 cox 比例风险生存分析来估计多个预测因子（HR 及其 95% CI 和 p 值）对直肠癌复发概率的影响。
由于我的数据集规模小（140 个观测值）且事件计数低（7 个事件），我决定使用 glmnet 包中的岭回归。Lasso 并不可取，因为我想保留所有预测因子，因为我有证据表明它们对复发的重要性。
我搜索了文献并了解到，虽然惩罚模型的统计推断以前由于惩罚引入的偏差而并不可取，但现在已被诸如“hdi”和“selectiveInference”之类的包克服，用于 Lasso 型回归，“lmridge”用于 L2 惩罚线性回归。
我的问题如下：

有没有什么方法可以对 Cox 比例模型上的岭回归进行统计推断。到目前为止，我还没有找到任何具有此功能的文章或 R 包
如果岭回归的统计推断仍然不可接受，我该如何解释 glmnet() 提供的 HR

这是我用于拟合模型的代码：
set.seed(10)
y &lt;- with(df_cox, Surv(df_cox$recurrencetime, df_cox$recurrence)) # 响应变量
x &lt;- model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1] # 预测器
df_cox = model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1] # 预测器
df_cox = model.matrix(Surv(df_cox$recurrencetime, df_cox$recurrence) ~ ., data = df_cox)[, -1]
cv_model &lt;- cv.glmnet(
x, y,
family = &quot;cox&quot;,
alpha = 0, # 弹性网络 (alpha = 0.5 是套索和脊线的混合)
nfolds = 10 # 10 倍交叉验证
)
best_lambda &lt;- cv_model$lambda.min

# 使用最佳 lambda 拟合最终模型
final_model &lt;- glmnet(x, y, family = &quot;cox&quot;, alpha = 0, lambda = best_lambda)
]]></description>
      <guid>https://stats.stackexchange.com/questions/660048/statistical-inference-for-l2-penalized-cox-proportional-hazard-regression</guid>
      <pubDate>Wed, 15 Jan 2025 07:30:52 GMT</pubDate>
    </item>
    <item>
      <title>例如，I(X;Y|Z) < I(X;Y)</title>
      <link>https://stats.stackexchange.com/questions/660001/example-where-ixyz-ixy</link>
      <description><![CDATA[我问自己是否有可能$I(X;Y|Z)&lt;I(X;Y)$。起初这看起来很奇怪，因为知道$Z$的值怎么会导致$Y$提供的$X$信息比$Z$未知时提供的少。
然后我进入维基百科，我发现这是可能的。 $I(X;Y|Z)$ 可以等于、小于或大于 $I(X;Y)$。$I(X;Y|Z)&lt;I(X;Y)$ 背后的直觉是 $Z$ 解释了 $X$ 和 $Y$ 之间相关性的部分原因。
但是，我很难想出一个简单的例子来说明这一点。维基百科中没有数值示例，我在这个网站上也没有找到。]]></description>
      <guid>https://stats.stackexchange.com/questions/660001/example-where-ixyz-ixy</guid>
      <pubDate>Tue, 14 Jan 2025 10:01:13 GMT</pubDate>
    </item>
    <item>
      <title>连续随机变量的充分统计量的因式分解定理</title>
      <link>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics-in-case-of-continuous-random-var</link>
      <description><![CDATA[根据因式分解定理（Fisher-Neyman），我们得到一个统计量$ T(X) $充分当且仅当存在因式分解：$ f(x|\theta) = g(T(x)|\theta)h(x) $。符号遵循 Casella/Berger 第 276 页。
Casella/Berger 在离散情况下给出了证明，并指出具体因式分解的形式为：$ P(X=x | {\theta}) = P(T(X) = T(x) | {\theta})P(X=x | T(X) = T(x)) $
我的问题是：我们可以将这种解释应用于连续情况吗？它总是成立吗？因此：$ f(x|\theta) = f(T(x)|\theta)f(x|T(x)) $ 其中 $f$ 表示相应的 pdf？]]></description>
      <guid>https://stats.stackexchange.com/questions/659990/factorization-theorem-for-sufficient-statistics-in-case-of-continuous-random-var</guid>
      <pubDate>Mon, 13 Jan 2025 22:52:25 GMT</pubDate>
    </item>
    <item>
      <title>偏距离相关的解释</title>
      <link>https://stats.stackexchange.com/questions/659974/interpretation-of-partial-distance-correlation</link>
      <description><![CDATA[我想知道这里是否有人可以帮助理解部分距离相关的解释（https://projecteuclid.org/journals/annals-of-statistics/volume-42/issue-6/Partial-distance-correlation-with-methods-for-dissimilarities/10.1214/14-AOS1255.full）？我不是统计学家，所以原文对我来说有点难理解。
在第 4.2 节中，似乎暗示偏距离相关性和条件（不）依赖性并不总是相同的。但我不清楚与标准偏相关相比，偏距离相关性应该如何解释？
相关地，偏距离相关性似乎能够通过控制 Z 作为多维变量来“控制”超过 1 个变量，因为偏距离相关性（和其他能量统计数据）是针对任意不一定相等维度的随机向量定义的。同样在这种情况下，我很难理解当 z 是一个多维控制变量时，与偏相关或偏回归系数相比，对偏距离相关性的准确实质性解释应该是什么？或者，例如，假设我们有一组随机变量，它们呈正态分布，平均值为 0，标准差为 1，如果构建一个图，其中边表示“显著”的部分距离相关性，那么与边是“显著”部分相关的高斯图模型相比，这种解释会如何？（除了 pdcor 可以捕获非线性依赖关系这一事实之外，对于这个例子，假设所有依赖关系都是真正线性的）。
我的问题的第三部分涉及使用 energy R 包中 pdcor.test 中的置换测试推断部分距离相关性。我在下面进行了一个小模拟：
sim &lt;- function() {

x &lt;- rnorm(100)
y &lt;- 0.8*x + rnorm(100)
z &lt;- 0.8*y + rnorm(100)

pcor &lt;- ppcor::pcor.test(x,z,y)
pc.p &lt;- pcor$p.value

pdcor &lt;- energy::pdcor.test(x,z,y, R = 1000)
pd.p &lt;- pdcor$p.value

return(list(pcor.p = pc.p,
pd.p = pd.p))

}

sims &lt;- pbapply::pbreplicate(500, sim())

假设 x 是给定 y，条件独立于 z，x,y|z 的偏相关的零假设为真，因此，根据我的理解，P 值应该是均匀分布的。标准偏相关似乎就是这种情况，但偏距离相关产生了非常双峰的分布，边界处有高频峰值。
par(mfrow=c(2,1))
hist(as.numeric(sims[1,]), xlab = &quot;P 值&quot;, ylab = &quot;频率&quot;,
main = &quot;独立性下的偏相关 P 值&quot;)
hist(as.numeric(sims[2,]), xlab = &quot;P 值&quot;, ylab = &quot;频率&quot;,
main = &quot;独立性下的偏相关 P 值&quot;)


我在这个模拟中犯了一些明显的错误吗？
希望我的问题有意义！任何帮助都将不胜感激，在此先行致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/659974/interpretation-of-partial-distance-correlation</guid>
      <pubDate>Mon, 13 Jan 2025 18:38:55 GMT</pubDate>
    </item>
    <item>
      <title>泊松过程可以变成泊松过程回归吗？</title>
      <link>https://stats.stackexchange.com/questions/659931/can-a-poisson-process-be-made-into-a-poisson-process-regression</link>
      <description><![CDATA[这是我正在考虑的概念验证问题。
数据格式如下（模拟数据）：
patient_id dob gender hospital_visit age_at_visit
1 2019-06-21 F 2024-03-13 4
1 2019-06-21 F 2024-05-22 4
1 2019-06-21 F 2024-07-11 5
1 2019-06-21 F 2024-09-19 5
1 2019-06-21 F 2024-10-02 5
1 2019-06-21 F 2024-10-30 5
1 2019-06-21 F 2024-11-13 5
1 2019-06-21 F 2024-12-15 5
1 2019-06-21 F 2024-12-17 5
2 2007-12-13 M 2024-01-27 16
2 2007-12-13 M 2024-02-09 16
2 2007-12-13 M 2024-06-10 16
3 2024-02-01 M 2024-06-28 0
4 2014-04-12 F 2024-08-17 10
4 2014-04-12 F 2024-12-21 10
5 2010-02-20 F 2024-02-03 13
5 2010-02-20 F 2024-02-21 14
5 2010-02-20 F 2024-03-17 14
5 2010-02-20 F 2024-03-31 14
5 2010-02-20 F 2024-04-09 14

考虑 2 个泊松过程：一个标准泊松过程（速率恒定）和一个（加速）泊松过程，其中速率函数随着更多事件的发生而变化（$r$ 是速率，$n$ 是已经发生的事件数）。很明显，当我们模拟和可视化它们时，我们可以看到两者之间的差异（在 R 中）：

我想知道这是否可以用于创建模型，以确定一个人下次住院的时间，因为我们知道他已经住院了多少次（假设我们只在这个人住院时进行协变量测量）。
我认为这在我们认为未来住院取决于这个人过去去过医院的次数的情况下很有用 - 这样，对于住院频率更高的人，住院间隔时间就会减少。
例如，我们可以定义一个风险模型，如这个？
$$ \ln[h(t|n, X)] = \ln(\lambda_0) + n\ln(1+r) + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p $$
$$h(t) = \lim_{\Delta t \to 0} \frac{P(t \leq T &lt; t + \Delta t | T \geq t)}{\Delta t}$$
或者也许是对数对数链接？
$$ \log(-\log(1 - P(\text{readmission in }[t, t+\Delta t]|n, X))) = \beta_0 + \beta_n n + X\beta $$
$$ \log(-\log(1 - P(\text{readmission in }[t, t+\Delta t]|n))) = \log(\lambda_0) + n\log(1+r) + \log(\Delta t) $$
$$ \log(-\log(1 - P(\text{readmission in }[t, t+\Delta t]|n, X))) = \beta_0 + \beta_n n + X\beta + \log(\Delta t) $$
或者仅仅是一个纯随机过程？
$$ \log(\lambda_n) = \beta_0 + \beta_1n + X\beta $$
$$ \lambda_n = e^{\beta_0 + \beta_1n + X\beta} $$
$$ P(\text{readmission in }[t, t+\Delta t]|n,X) = 1 - e^{-\lambda_n\Delta t} = 1 - e^{-e^{\beta_0 + \beta_1n + X\beta}\Delta t} $$
我不明白如何对此类问题进行建模，因为它涉及纵向分析、随机过程和生存分析的概念。有什么关于如何开始的提示吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659931/can-a-poisson-process-be-made-into-a-poisson-process-regression</guid>
      <pubDate>Sun, 12 Jan 2025 21:26:18 GMT</pubDate>
    </item>
    <item>
      <title>确保 Fisher 信息矩阵严格正定的条件</title>
      <link>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</link>
      <description><![CDATA[Fisher 信息矩阵定义为：
$$I(\theta):=E\left[\left(\frac{\partial\log f(X;\theta)}{\partial \theta}\right)^2 \mid\theta\right]$$
其中 $f$ 是似然函数。
我正在寻找充分条件 - 最好是关于 $f$ 或 $\log f$ - 以确保 Fisher 矩阵严格正定。
正定性是证明最大似然估计量 (MLE) 渐近一致性的众所周知的临界条件。因此，本次调查具有重要意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/659827/conditions-that-ensure-the-fisher-information-matrix-to-be-strictly-positive-def</guid>
      <pubDate>Fri, 10 Jan 2025 14:33:43 GMT</pubDate>
    </item>
    </channel>
</rss>