<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 26 Sep 2024 01:14:59 GMT</lastBuildDate>
    <item>
      <title>如何平滑这些曲线以获取其趋势？</title>
      <link>https://stats.stackexchange.com/questions/654922/how-to-smoothen-these-curves-to-get-their-trends</link>
      <description><![CDATA[我有一组 10 个信号，如下所示：

我们可以看到，它们非常嘈杂，而大多数噪声都是异常值。我需要能够以某种方式使它们平滑，从而保留每个信号中的点数。
到目前为止，我已经尝试了双重应用中值滤波器，并且获得了接近我想要的结果，但不幸的是，它并不适用于所有滤波器，并且在信号开始时看起来并不可靠：

那么，您知道对这种情况有用的任何方法吗？我在这个领域的知识非常有限，基本上仅限于中值滤波和 Savitzky-Golay，这似乎没什么用。
我需要非常平滑的线条来保留主要趋势（不是超精确），并且没有异常值/振荡。

数据（10 个列表的列表）
链接：https://jpst.it/3VUqP]]></description>
      <guid>https://stats.stackexchange.com/questions/654922/how-to-smoothen-these-curves-to-get-their-trends</guid>
      <pubDate>Thu, 26 Sep 2024 01:10:42 GMT</pubDate>
    </item>
    <item>
      <title>DoE - 混合两种材料的因子和因子水平</title>
      <link>https://stats.stackexchange.com/questions/654919/doe-factors-and-factor-levels-for-blending-two-materials</link>
      <description><![CDATA[如何在此自定义实验设计中设置因子和因子水平？我正在为沥青混凝土混合料制作不同的骨料混合物。
A 类骨料来自 3 个采石场：A1、A2 和 A3。
B 类骨料来自 3 个不同的采石场：B1、B2 和 B3。
A 类与 B 类以不同的比例混合：1:0（所有 A 类）、2:1、1:2 和 0:1（所有 B 类）。
但这会产生一些奇怪的因子组合。例如...

A1_B1_1:0 实际上意味着混合中没有 B1。
A1_B1_1:0、A1_B2_1:0、A1_B3_1:0 彼此都是多余的。

我可以为“无”添加一个因子水平，但这样它就不会被定义为 2:1 或 1:2。
提前感谢您的帮助！
布莱恩]]></description>
      <guid>https://stats.stackexchange.com/questions/654919/doe-factors-and-factor-levels-for-blending-two-materials</guid>
      <pubDate>Wed, 25 Sep 2024 21:27:27 GMT</pubDate>
    </item>
    <item>
      <title>具有 G 幂分类预测因子的逻辑回归样本大小</title>
      <link>https://stats.stackexchange.com/questions/654915/logistic-regression-sample-size-with-categorical-predictor-in-g-power</link>
      <description><![CDATA[我想弄清楚 G 幂是否适合我的情况，以及我是否做对了。我希望计算先验样本量。
我即将使用注册数据进行队列研究，使用逻辑回归对疾病是/否进行二元结果分析。但是我的预测因子 (x) 有 3 个类别/组。据我所知，我应该“将这些视为”2 个变量（一个参考）。这些组也可能不均衡。
此外，我可能还有多达 7 个其他协变量。
我的问题：
使用 G 幂是否可行？如果可以……
当有 3 个不均匀组时，如何设置我的“x parm”？
即使预测因子有多个类别，x 分布仍然是二项式的？
解释协变量的唯一方法是使用“R2 其他 x”？或者有没有其他方法/应用程序可以做得更好？
在我的测试中，效果大小为 OR 1.27（我希望检测到 2% 的 ARR）。仍然是均等匹配的组。我需要 6703 名患者，似乎很高？或者由于差异如此之小，可能是正确的？对于 x 分布“正态”或“泊松”，样本量要低得多。
]]></description>
      <guid>https://stats.stackexchange.com/questions/654915/logistic-regression-sample-size-with-categorical-predictor-in-g-power</guid>
      <pubDate>Wed, 25 Sep 2024 20:15:55 GMT</pubDate>
    </item>
    <item>
      <title>多项逻辑回归中的参数识别</title>
      <link>https://stats.stackexchange.com/questions/654914/parameter-identification-in-multinomial-logit</link>
      <description><![CDATA[我正在估算$\beta$以下模型：
$$
p_1=\frac{\exp(\beta x_1)}{\exp(\beta x_1)+\exp(\beta x_2) + \exp(\beta x_3)}
$$
$$
p_2=\frac{\exp(\beta x_2)}{\exp(\beta x_1)+\exp(\beta x_2) + \exp(\beta x_3)}
$$
$$
p_3=\frac{\exp(\beta x_3)}{\exp(\beta x_1)+\exp(\beta x_2) + \exp(\beta x_3)}
$$
此模型中是否识别出$\beta$？
如果没有，要识别$\beta$，我是否需要将选择标准化为 1？例如：
$$
p_1=\frac{1}{1+\exp(\beta x_2) + \exp(\beta x_3)}
$$
$$
p_2=\frac{\exp(\beta x_2)}{1+\exp(\beta x_2) + \exp(\beta x_3)}
$$
$$
p_3=\frac{\exp(\beta x_3)}{1+\exp(\beta x_2) + \exp(\beta x_3)}
$$
如果在第一个模型中识别出$\beta$，则两个模型中的$\beta$测量的是不同的东西吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654914/parameter-identification-in-multinomial-logit</guid>
      <pubDate>Wed, 25 Sep 2024 20:12:15 GMT</pubDate>
    </item>
    <item>
      <title>多层次建模？</title>
      <link>https://stats.stackexchange.com/questions/654913/multi-level-modelling</link>
      <description><![CDATA[在一项教学研究中，我对写作质量进行了前测和后测测量——没有控制条件。10 个班级中有 110 名学生。我对拼写技能和手写流畅度进行了前测测量，作为协变量。我想测试：
-从前测到后测，分数是否有所提高？
-每个协变量是否预测了文本质量水平？
-每个协变量是否预测了从前测到后测的文本质量增益？
-从前测到后测，各个班级的文本质量增益是否不同？
-如果可能，测试班级之间在文本质量增益方面的差异是否受到手写和拼写的影响
只有两个时间点，我可以使用多级建模吗？在 SPSS 中？
感谢您对此提出的任何建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/654913/multi-level-modelling</guid>
      <pubDate>Wed, 25 Sep 2024 20:09:10 GMT</pubDate>
    </item>
    <item>
      <title>解释交叉表摘要</title>
      <link>https://stats.stackexchange.com/questions/654911/interpreting-cross-table-summary</link>
      <description><![CDATA[我正在生成一个简单的 2 x N 列联表，总结女性在 COVID-19 之前和期间/之后的就业状况。列代表两个时间段：1) COVID 之前和 2) COVID 期间/之后。
就业状况摘要如下：
就业状况 COVID 之前 COVID 期间/之后
缺失响应 41% 18.6%
失业（家庭主妇） 301 (8.8%) 443 (20%)
就业 1315 (49.9%) 1276 (61.4%)

数据显示，失业家庭主妇的百分比（从 COVID 之前的 8.8% 增加到 COVID 期间/之后的 20%）和就业女性的百分比（从 49.9% 增加到 61.4%）都有所增加。这似乎违反直觉，因为我们预计失业率上升与就业率下降同时发生。
我该如何解释这些结果？任何建议都非常感谢。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/654911/interpreting-cross-table-summary</guid>
      <pubDate>Wed, 25 Sep 2024 19:58:04 GMT</pubDate>
    </item>
    <item>
      <title>识别时间序列的平衡点</title>
      <link>https://stats.stackexchange.com/questions/654909/identifying-equilibrium-point-of-a-time-series</link>
      <description><![CDATA[我正在对新产品发布进行分析，特别是新产品发布的生命周期是否随着时间的推移而发生变化。
我感兴趣的一个问题是，用于确定新产品何时达到平衡的统计方法。通常，对于每种新产品，我们都会看到最初的收入激增，最终达到某种平衡点。据我所知，大多数方法都需要知道平衡点是什么，而在这种情况下，我们不知道。
任何想法都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654909/identifying-equilibrium-point-of-a-time-series</guid>
      <pubDate>Wed, 25 Sep 2024 19:09:27 GMT</pubDate>
    </item>
    <item>
      <title>RA Fisher（或“Fisherian”）如何选择样本大小？</title>
      <link>https://stats.stackexchange.com/questions/654905/how-would-ra-fisher-or-a-fisherian-choose-sample-sizes</link>
      <description><![CDATA[正如许多其他 CV.SE 帖子（例如此处或此处）中所述，RA Fisher 和 Neyman &amp; Pearson 的统计假设检验框架在实践和解释上存在差异。
我很好奇他们在如何设计您的研究方面的差异。为了简单起见，我将重点关注样本量（但当然，功效和精度也会受到研究设计的其他方面的影响，例如阻塞等）。
在 N-P 框架下，一般方法对我来说很清楚：首先确定您想要的功效，您感兴趣的特定替代点假设 $H_A$（例如，就您想要检测的最小效应大小而言），以及您可以容忍的 I 类错误率 $\alpha$。从那里，您可以计算出实现 $\alpha$ 和 $H_A$ 所需功效所需的样本量。
但据我了解，在 Fisher 方法中，没有 $\alpha$、没有 $H_A$，也没有明确的功效计算。那么 Fisher 如何为自己的研究选择样本量？（或者他如何建议其他人规划样本量？）

我很好奇，尤其是因为 Fisher 确实写过“一个设计合理的实验”通常会产生较低的 p 值。

就我个人而言，作者更喜欢将显着性标准设定为 5%。点，并完全忽略所有未达到该水平的结果。只有当经过适当设计的实验很少失败时，科学事实才应被视为实验确定的。

-- Fisher, R. A. 田间实验的安排。《农业部期刊》，1926 年，33，第 504 页。
对我来说，这句 1926 年的引言（尤其是“很少失败”）听起来很像说精心设计的实验应该具有很高的功效：尽管他没有指定特定的$H_A$，但 Fisher 想象在相同的人群中重复使用相同设计的相同实验（尽管在这句话中，这些实验是否重复是假设的或应该实际执行的），并反复获得等于或低于 5% 显著性水平的结果。
如果 Fisher 同意设置显著性水平，并且 Fisher 也致力于实现高功效——那么他还能做什么来选择样本量来实现这些目标，同时又与 N-P 的整体方法有实质性的不同？
（当然，还有贝叶斯方法、似然法，也许还有其他非 Fisher 和非 NP 方法。但我特别想问的是，什么才算是 Fisher 但非 NP。）]]></description>
      <guid>https://stats.stackexchange.com/questions/654905/how-would-ra-fisher-or-a-fisherian-choose-sample-sizes</guid>
      <pubDate>Wed, 25 Sep 2024 18:08:15 GMT</pubDate>
    </item>
    <item>
      <title>使用 SPSS 计算广义倾向得分</title>
      <link>https://stats.stackexchange.com/questions/654901/calculating-generalized-propensity-score-using-spss</link>
      <description><![CDATA[我正在为一项包含大量混杂变量的医学研究计算 Cox 回归。我已经计算了具有二进制值的变量的倾向得分，以调整混杂因素。但也有一些度量变量。为此，我需要计算广义倾向得分。我在互联网上进行了广泛搜索，但我只能找到我不理解的公式，没有实用指南。显然有不同的方法可以做到这一点。我不希望我的连续变量有子类。我了解到我必须为连续变量和可能的混杂因素计算线性回归。之后，应该计算残差的方差。但我不知道如何从那里继续。
有人知道如何在 SPSS 中计算 GPS 吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654901/calculating-generalized-propensity-score-using-spss</guid>
      <pubDate>Wed, 25 Sep 2024 16:21:34 GMT</pubDate>
    </item>
    <item>
      <title>用连续给定条件概率建模</title>
      <link>https://stats.stackexchange.com/questions/654900/modelling-conditional-probabilities-with-continuous-givens</link>
      <description><![CDATA[我目前正在努力解决这个方程式
$$ p(x; \theta) = P(Y = 1 | X = x) $$
其中 $p$ 是右侧条件概率的模型。如果 $X$ 是连续随机变量，那么这个方程式肯定没有意义。我们是否简单地将 $X$ 视为离散变量？]]></description>
      <guid>https://stats.stackexchange.com/questions/654900/modelling-conditional-probabilities-with-continuous-givens</guid>
      <pubDate>Wed, 25 Sep 2024 16:19:27 GMT</pubDate>
    </item>
    <item>
      <title>bfastlite 函数的参数调整</title>
      <link>https://stats.stackexchange.com/questions/654910/parameter-tuning-of-the-bfastlite-function</link>
      <description><![CDATA[我正在使用 bfast 包的 bfastlite() 函数来运行时间序列 (ts) 分析。我从作者的论文（表 2）中引用：

需要调整参数来优化性能，不区分季节性和趋势的中断

到目前为止，我一直在手动微调模型，也就是说，我一个接一个地更改参数，这很耗时。有人对模型的微调有更好的解决方案吗？
为了查看模型的哪些参数可以实现最佳结果，我检查了检测到的断点中的日期（目视检查）。
library(bfast)

plot(simts) # 包含模拟 NDVI 时间序列的 stl 对象
datats &lt;- ts(rowSums(simts$time.series))
# 所有组件的总和（季节、突变、剩余）
tsp(datats) &lt;- tsp(simts$time.series) # 分配正确的时间序列属性
plot(datats)

# 检测断点。默认参数
bp = bfastlite(datats)
plot(bp)

# 优化模型 ??????
bp_opt &lt;- bfastlite()

R 4.4.1，bfast 1.6.1，Windows 11。]]></description>
      <guid>https://stats.stackexchange.com/questions/654910/parameter-tuning-of-the-bfastlite-function</guid>
      <pubDate>Wed, 25 Sep 2024 14:48:51 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证不起作用[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654892/cross-validation-doesnt-work</link>
      <description><![CDATA[我目前在当地大学听一场数据科学演讲。我们是从工作单位来的，我从事 DS/ML 工作，已经 7 年了，但我的学位是计算机科学，因此我在 DS/ML 方面主要是自学的。
这个人告诉我们，DS 文章中写到的很多东西实际上都不起作用。
例如，他提到精确度、召回率和 F1 分数很少使用（相反，他更喜欢 AUC）。
但对我来说，另一个更古怪的事情是，交叉验证也不应该用于业务问题。他解释说它不起作用，因为它不代表现实生活。在现实生活中，你的目标不是预测数据分布中的随机样本，而是必须根据过去 x 年建立一个模型来预测未来 y 个月的数据。
所以他说交叉验证基本上是无用的，应该使用前向优化。
首先，它是如何工作的？它只用于验证还是也可以用于优化？怎么做？
此外，CV 真的那么没用吗？这是我读过的关于 DS 的任何文章中最被接受的验证形式。但也许这是我自学知识的不足之处。
还有什么关于很多事情的“神话”更高大上，但在现实生活中却不起作用？]]></description>
      <guid>https://stats.stackexchange.com/questions/654892/cross-validation-doesnt-work</guid>
      <pubDate>Wed, 25 Sep 2024 12:55:02 GMT</pubDate>
    </item>
    <item>
      <title>一般时间序列模型估计量的渐近性质</title>
      <link>https://stats.stackexchange.com/questions/654889/asymptotic-properties-of-estimators-for-general-time-series-model</link>
      <description><![CDATA[我的问题涉及时间序列分析中估计量的渐近性质。特别是，我对时间序列（不是 ARMA 时间序列）的估计量的行为感兴趣。因此，让 $(Y_t)_{t \in I \subset \mathbb{N}}$ 成为单变量时间序列。我们可以假设时间序列遵循以下形式的更新方程：
$Y_t = g(Y_{t-1}, ..., Y_{t-p}, f(\epsilon_{t-1}, ..., \epsilon_{t-q}), \epsilon_t)$
其中 $\epsilon_t$ 是 $iid$ 创新，其中 $\epsilon_t \sim (0, \sigma^2)$。 $f(\epsilon_{t-1}, ..., \epsilon_{t-q})$ 是某种类似于移动平均的部分，用于使时间序列具有衰减的自相关性（而不是截止）。$g$ 是处理自相关的函数。请注意，对于特殊选择，其中 $g$ 和 $f$ 是线性函数，我们得到经典的 ARMA 模型。我们可以假设 $g$ 由参数 $\phi$ 参数化，而 $f$ 由参数 $\theta$ 参数化。我感兴趣的是足以满足 $\phi$ 和 $\theta$ 的 MLE 估计量的一致性和渐近正态性的条件。在几篇论文中（对函数 $g$ 和 $f$ 做出特殊选择），我遇到了平稳性和混合条件。但是，我想知道这些条件是否足以满足我在此处给出的相当通用的模型。
任何有关论文/书籍/网站等的提示都将不胜感激。当然，直接回答也很好 :D。]]></description>
      <guid>https://stats.stackexchange.com/questions/654889/asymptotic-properties-of-estimators-for-general-time-series-model</guid>
      <pubDate>Wed, 25 Sep 2024 11:55:48 GMT</pubDate>
    </item>
    <item>
      <title>使用缺失值的 Wilcoxon 符号秩检验</title>
      <link>https://stats.stackexchange.com/questions/654879/using-wilcoxon-signed-rank-test-with-a-missing-value</link>
      <description><![CDATA[我正在研究一个问题，我应该使用 Wilcoxon 符号秩检验，$9$ 个元素。第九对中的一个值缺失，我只知道它的结果为负数。我应该如何处理该值？我在网上找到了信息，“如果数据范围内有缺失值，则整个对将被排除在分析之外”，但在符号检验的情况下，我知道如果我们不知道最后一个条目但知道它的秩，我们仍然可以使用它。但在这种情况下，我们有配对结果，所以我不确定。我应该手动完成计算，而不是使用 R。
差异如下：$−7$, $−15$, $−1$, $−17$, $−10$, $−5$, $+11$, $−6$, $X_{9}&lt;0$。
我的猜测是，我可以将其省略，因为它是负数，并且与大多数 $X_{i}$ 值没有什么不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/654879/using-wilcoxon-signed-rank-test-with-a-missing-value</guid>
      <pubDate>Wed, 25 Sep 2024 07:34:40 GMT</pubDate>
    </item>
    <item>
      <title>从多个分布中提取的一个数据集</title>
      <link>https://stats.stackexchange.com/questions/654863/one-data-set-drawn-from-multiple-distributions</link>
      <description><![CDATA[我不清楚如何拟合至少从视觉上看是从多个分布中提取的数据集。
我尝试使用 GaussianMixture，但结果看起来并不令人信服。我不擅长统计，也不想争辩说它是错误的，但这不是我所期望的。代码在这里：
import numpy as np
from pylab import *
from sklearn.mixture import GaussianMixture
from pylab import concatenate, normal
import pandas as ps

from scipy.stats import norm

df = ps.read_csv(&#39;Book6.csv&#39;)
multimodal_dist = df.E.to_numpy()

weights = np.ones_like(multimodal_dist)/float(len(multimodal_dist))
y, x, _=hist(multimodal_dist, bins=np.arange(df[&#39;E&#39;].min(), df[&#39;E&#39;].max()+1)-0.5, alpha=.5, weights=weights, label=&#39;data&#39;)

components = 2

gm = GaussianMixture(n_components=components)
gm.fit(multimodal_dist.reshape(-1, 1))

means = gm.means_
standard_deviations = gm.covariances_**0.5 
weights = gm.weights_ 

new_X = np.linspace(min(multimodal_dist), max(multimodal_dist), 100)

对于 zip(means, standard_deviations, weights) 中的平均值、标准差、权重：
print(weight,mean, std)
pdf = 2*weight * norm.pdf(new_X, mean, std)
plt.plot(new_X.reshape(-1, 1), pdf.reshape(-1, 1), alpha=0.8)

pdf_full = np.zeros(len(new_X))
对于范围(components) 中的 i：
pdf_full = pdf_full + weights[i] * norm.pdf(new_X, means[i], standard_deviations[i])

plt.plot(new_X.reshape(100,1), 2*pdf_full.reshape(-1, 1))

plt.show()

我根据 GaussianMixture 拟合系数生成的图是

整体曲线确实看起来正确，但底层分布不是我所期望的。
我期望的图是手动拟合的，没有统计支持，但我认为，应该是这样的：

我的期望是错误的，还是我没有使用好的方法，或者误用了它们？首先，在这两种情况下，我的标准化都是手动完成的。我不明白如何标准化我的拟合以匹配分布。
数据在这里。]]></description>
      <guid>https://stats.stackexchange.com/questions/654863/one-data-set-drawn-from-multiple-distributions</guid>
      <pubDate>Tue, 24 Sep 2024 20:55:32 GMT</pubDate>
    </item>
    </channel>
</rss>