<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Mon, 23 Dec 2024 06:25:36 GMT</lastBuildDate>
    <item>
      <title>单因素方差分析对比</title>
      <link>https://stats.stackexchange.com/questions/659115/contrasts-in-one-way-anova</link>
      <description><![CDATA[我正在观看一场关于方差分析的讲座，讲师给出了 3 个数据可能假设的例子：

对于假设 3 (mu2 = mu1 - 3*mu3)，对比系数的总和不为零 (-1 + 1 + 3 != 0)。在这种情况下，我们可以说它是对比吗？如果不是，那它是什么？在这种情况下，我们可以检查第三个假设与假设 1 的正交性，就像幻灯片上所做的那样 (a * c)？]]></description>
      <guid>https://stats.stackexchange.com/questions/659115/contrasts-in-one-way-anova</guid>
      <pubDate>Mon, 23 Dec 2024 05:03:38 GMT</pubDate>
    </item>
    <item>
      <title>简单线性回归中的 F 检验</title>
      <link>https://stats.stackexchange.com/questions/659114/f-test-in-simple-linear-regression</link>
      <description><![CDATA[我试图理解 F 检验对简单线性回归模型有效性的检验，但我对此有几个问题：

为什么我们要用 SSR 除以独立变量的数量，用 SSE 除以自由度的数量？为什么不用它们都除以独立变量的数量，这样我们就可以计算出每个独立变量对应的平均解释/未解释变异性？

在 $\beta_1 = 0$ 的零假设下，检验统计量的 F 是如何分布的？

]]></description>
      <guid>https://stats.stackexchange.com/questions/659114/f-test-in-simple-linear-regression</guid>
      <pubDate>Mon, 23 Dec 2024 03:14:22 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以计算/指定 SEM 全项目分割方法中的误差方差？</title>
      <link>https://stats.stackexchange.com/questions/659112/where-do-i-compute-specify-error-variance-in-sem-all-item-parceling-approach</link>
      <description><![CDATA[我是 SEM 和 lavaan 的新手。我创建了一个模型，需要为其运行 SEM。由于样本量极小且模型参数很多，我需要采用全项目包裹方法进行 SEM 和 ML 估计，尽管我知道包裹是有争议的。
先前的文献表明，如果我要为某个因子包裹所有项目，则需要计算误差方差。

有趣的是，此处引用的作为全项目包裹方法示例的四项研究使用了略有不同的方程来计算误差方差 (θε)。 Holbert (2005) 和 Theiss
and Solomon (2006) 使用了 Bollen (1989) 的程序（即 θε = [1 − α] × s2），而其他两项研究的作者修改了该方程：Dillard 和 Shen (2005) 将每个构造的误差方差固定为“1 − α2 乘以其方差”（第 156 页）（即 θε = [1 − α2] × s2）；另一方面，在 Pfau 等人（2004 年，第 341 页）的研究中，“误差项设置为每个变量的方差乘以 1 减去该变量可靠性估计的平方根”（即 θε = [1 − α1/2] × s2）。鉴于 α ≤ 1.0 且 s2 &gt; 0，
与 Bollen 的原始公式相比，
对 alpha 求平方会使误差方差增大，而对 alpha 求平方根会使误差方差减小。
所有这些作者都引用了 Bollen 作为计算过程的来源。
（Matsunaga，2014；DOI：10.1080/19312450802458935）

我的问题是，在 R 中使用 lavaan 时，如何以及在哪里指定/计算此误差方差？我想出了以下语法，它正确吗（尤其是使用 ~~）？误差方差已通过以下公式计算：θε = [1 − α] × s2
model &lt;- &#39;
Institutional_Support =~ 1*INSPT_COMP
Lesson_Preparation_Time =~ 1*LPT_COMP
Access_Use_Technology =~ 1*TECH_COMP
Self_Efficacy =~ 1*SEFF_COMP
Orchestration_Load =~ 1*TLX_COMP

# 结构模型：以 SHT 为观察变量的经验
Orchestration_Load ~ Institutional_Support + Lesson_Preparation_Time + EXP1

# 为每个地块指定固定方差
INSPT_COMP ~~ error_variances_INSPT
LPT_COMP ~~ error_variances_LPT
TECH_COMP ~~ error_variances_TECH
SEFF_COMP ~~ error_variances_SEFF
TLX_COMP ~~ error_variances_TLX
&#39;

# 使用 ML 估计量和 bootstrap 标准误差拟合 SEM 模型
fit_ml &lt;- sem(
model,
data = my_data,
estimator = &quot;ML&quot;,
se = &quot;bootstrap&quot;, # 使用 bootstrap 标准误差
bootstrap = 1000 # bootstrap 样本数
)

&#39;&#39;&#39;]]></description>
      <guid>https://stats.stackexchange.com/questions/659112/where-do-i-compute-specify-error-variance-in-sem-all-item-parceling-approach</guid>
      <pubDate>Mon, 23 Dec 2024 00:21:23 GMT</pubDate>
    </item>
    <item>
      <title>线性混合效应模型对不平衡聚类是否具有鲁棒性？</title>
      <link>https://stats.stackexchange.com/questions/659110/are-linear-mixed-effects-model-robust-to-unbalanced-clusters</link>
      <description><![CDATA[我们已拟合以下模型：
m = lmer(y ~ time + event + time_since_event + (time|id), data = df)

有些集群有 1000 多个数据点，而其他集群则少于 10 个。
lmer 模型是否考虑了这种集群大小不平衡？即使存在这种不平衡，time、event 和 time_since_event 的 $p$ 值是否可靠？
是否有必要使用 clubSandwich 之类的包来实现聚类稳健标准误差：
coef_test(m, vcov = &quot;CR2&quot;, cluster = df$id)

我们询问的原因是从 coef_test 获得的 $p$ 值无法支持我们的假设，而从 lmer 模型获得的 $p$ 值则支持我们的假设。不确定哪个是正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/659110/are-linear-mixed-effects-model-robust-to-unbalanced-clusters</guid>
      <pubDate>Sun, 22 Dec 2024 22:26:49 GMT</pubDate>
    </item>
    <item>
      <title>元分析中嵌套数据的模型简化</title>
      <link>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</link>
      <description><![CDATA[我正在对子组中不同程度的异质性进行荟萃分析。由于数据结构是嵌套的（效应大小嵌套在研究中），我通过添加研究的随机效应和研究内的效应大小来考虑这一点。轮廓似然图在其估计值处达到峰值。
比较具有不同程度异质性的模型和具有共同异质性估计值的模型的似然比检验是显著的。然而，在获得 $ \tau^2_\text{between} $ 和 $ \tau^2_\text{within} $ 的置信区间 (CI) 后，除了一个之外，$ \tau^2_\text{within} $ 的所有 CI 的下限均为零。一个显著的估计值仍然是适中的。
在这种情况下，将模型简化为标准（两级）随机效应模型，仅考虑研究之间的差异是否合适？]]></description>
      <guid>https://stats.stackexchange.com/questions/659106/model-simplification-for-nested-data-in-meta-analysis</guid>
      <pubDate>Sun, 22 Dec 2024 20:41:46 GMT</pubDate>
    </item>
    <item>
      <title>R 边际效应包：估计中断时间序列中预测的减去反事实的绝对/相对变化的 95% 可信区间</title>
      <link>https://stats.stackexchange.com/questions/659105/r-marginaleffects-package-estimate-95-ci-for-predicted-minus-counterfactual-ab</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659105/r-marginaleffects-package-estimate-95-ci-for-predicted-minus-counterfactual-ab</guid>
      <pubDate>Sun, 22 Dec 2024 20:40:03 GMT</pubDate>
    </item>
    <item>
      <title>输入目的二分变量和序数变量之间的差异</title>
      <link>https://stats.stackexchange.com/questions/659103/difference-between-dichotomous-and-ordinal-variable-for-inputation-purposes</link>
      <description><![CDATA[我正在阅读 Amelia R 包的文档。
在文档的序数部分中，写到序数变量包括二分变量，其中一个例子是性别，它应该被视为序数变量，如果 0 表示男性，1 表示女性，则输入值 0.79 是完全可以接受的。
但是在名义部分中，它说另一个名为 signed 的变量，如果一个国家在当年签署了 IMF 协议，则该变量为 1如果没有，则为 0，应将其视为名义变量，并且只接受 0 和 1 值。浮点变量不可接受。
为什么性别可以被视为序数，而有符号则不能？
输入的签名值为 0.79 有什么问题，这意味着该国签署协议的概率为 79%？
相关：我们可以将性别视为序数变量吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659103/difference-between-dichotomous-and-ordinal-variable-for-inputation-purposes</guid>
      <pubDate>Sun, 22 Dec 2024 20:10:12 GMT</pubDate>
    </item>
    <item>
      <title>去趋势波动分析</title>
      <link>https://stats.stackexchange.com/questions/659102/detrended-fluctuation-analysis</link>
      <description><![CDATA[在 R 中，我尝试实现中描述的 DFA 时间序列分析算法
https://en.wikipedia.org/wiki/Detrend_fluctuation_analysis
和
https://www.kubios.com/blog/hrv-analysis-方法/
对于运动/训练教练朋友。有运动生理学研究建议使用 RR 间隔心跳时间序列（约 200 次心跳窗口）作为 DFA 低 n 系列 alpha 系数的输入，作为个人维持最佳心脏努力量的指导，而不是分配每个人在锻炼的某些部分都有相同的功率或心率目标（大致如下：&gt;~1.2 锻炼不够努力 &lt;~0.5 锻炼太努力。
为了测试我的 R 实现，我构建了白噪声使用 R 的 rnorm 函数对序列进行分析。但是，为了获得白噪声的 ~0.5 alpha 和随机游走的 ~1.5 alpha，我必须将每个的累积和输入到算法中。
此外，对于实际锻炼数据，我还需要输入 RR 锻炼系列的累计总和，以获得与 Garmin 应用程序针对相同锻炼的 alpha 输出相匹配的结果。
目前，我让我的朋友使用并相信我的 R 例程输出，输入 RR 系列和额外的累积和。但我担心我遗漏了一些基本的东西。我认为我遗漏的概念与我的白噪声系列有关，从任意开始（不一定是相等/离散时间）采样...在某种程度上，类似于心跳 RR 系列采样创建的时间尺度，由运动员的神经系统告诉身体下一次跳动的时间控制...但是我找不到任何关于 DFA 的在线讨论或参考文献中关于这个细微差别的讨论。我读到的所有内容似乎都表明你应该输入采样的白噪声流或原始 RR 流，而不是它们的累积和（因为第一步算法是另一个减去平均值的累积和，看起来累积和开始加起来了。）
有什么见解吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659102/detrended-fluctuation-analysis</guid>
      <pubDate>Sun, 22 Dec 2024 19:53:36 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据插补生成方法背后的直觉</title>
      <link>https://stats.stackexchange.com/questions/659075/intuition-behind-generative-methods-for-imputing-missing-data</link>
      <description><![CDATA[我正在学习不同的方法来估算混合连续和分类变量的表格数据集，并且假设数据完全随机缺失。我使用频率编码器转换了分类数据，因此所有内容都是数字或 NaN。
我认为平均值、中位数等估算过于简单且容易产生偏差。我正在考虑更复杂的方法，例如确定性和生成性。
对于确定性，我尝试了 LightGBM，它非常直观。我喜欢它。基本上，对于每个具有缺失数据的特征，其非缺失数据作为对其他特征的回归，然后预测/估算缺失数据。很棒。
现在我尝试使用深度学习方法，例如 AE 或 GAN。通过查阅文献，这似乎非常可行且非常有效。但黑匣子很难理解。例如，对于 VAE，我们是否只是简单地基于整个表格数据构建一个 VAE 模型，然后“以某种方式”预测/生成/估算缺失数据？
我仍在研究这个问题以获得更清晰的解释，但我希望也尝试过估算表格数据的人可以分享一些经验。]]></description>
      <guid>https://stats.stackexchange.com/questions/659075/intuition-behind-generative-methods-for-imputing-missing-data</guid>
      <pubDate>Sun, 22 Dec 2024 01:27:59 GMT</pubDate>
    </item>
    <item>
      <title>在评估 GLM 模型时，AIC 值或预测显著性的 p 值更重要吗？</title>
      <link>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659059/when-evaluating-glm-models-is-the-aic-value-or-the-p-value-of-predictor-signifi</guid>
      <pubDate>Sat, 21 Dec 2024 15:14:21 GMT</pubDate>
    </item>
    <item>
      <title>利用二进制数据的 MSE 进行快速搜索</title>
      <link>https://stats.stackexchange.com/questions/659043/exploiting-mse-of-binary-data-for-fast-search</link>
      <description><![CDATA[我有一个巨大的二进制向量数据库。给定一个传入向量，我想在数据库中找到 MSE 最接近的向量并返回 MSE 分数。到目前为止，我一直在手动进行此搜索，但花费的时间太长了。
我可以利用 MSE 与二进制向量一起使用时的特性来加快搜索速度吗？
更多详细信息：我正在寻找。我可以利用的 MSE 或二进制向量或数据稀疏性的属性来显着加快搜索速度！我的数据集有大约 400 万个高维（~4000）二进制向量，其中大部分是稀疏的（包含大量零）。我有一个循环，逐个遍历 400 万个向量并返回 MSE 分数最低的向量。我不能使用任何其他指标，并且在考虑是否可以利用 MSE 的任何属性来加快搜索速度。即使可以使用使用 MSE 的 ML 模型，它也会很完美]]></description>
      <guid>https://stats.stackexchange.com/questions/659043/exploiting-mse-of-binary-data-for-fast-search</guid>
      <pubDate>Sat, 21 Dec 2024 01:58:16 GMT</pubDate>
    </item>
    <item>
      <title>使用麦当劳 Omega 作为非加权总和评分的可靠性度量是合理的</title>
      <link>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</link>
      <description><![CDATA[在最近的文献中，报告麦当劳欧米茄作为可靠性估计值显然比报告系数 alpha 更受欢迎（例如 McNeish，2017）。一个经常给出的论点是，系数 alpha（或 Cronbach&#39;s alpha）假设（本质上）tau-euqivalent 测量模型，即因子载荷必须相等，而麦当劳欧米茄允许不同的载荷。由于对 omega 有多种看法，为了简单起见，我们只关注单维尺度上的总 omega，如 McNeish (2017) 所指定的那样：

（其中 $\lambda_i$ 是因子载荷，$\theta_{ii}$ 是第 i 项的误差/残差方差）
在文章中，McNeish 写道：

Omega (McDonald, 1970, 1999）是常用的复合信度测量方法，可用于多种软件程序。Omega 专为同类量表而设计，其中项目与被测构造的相关程度各不相同（即，在因子分析设置中，不会假设负载相等）。换句话说，不假设 tau 等价。当量表中的项目按单位加权以形成总量表分数但量表本身为同类时，复合信度是合适的（Bentler，2007；Geldhof 等人，2014）。单位加权量表意味着量表的总分是通过将各个项目的原始分数（或反向编码的原始分数，如果适用）相加来计算的：每个项目的权重相等。

我觉得这违反直觉：例如，假设 CFA 表明同类模型（自由载荷）比更严格的 tau 等效模型更适合样本数据，因此我们决定使用 omega 而不是系数 alpha。然而，后续分析将使用基于同等权重项目计算得出的总和/平均分数，尽管我们刚刚在 CFA 中表明这种类型的测量模型无法很好地拟合我们的数据。
我的问题：
有人能否提供一些合理的解释，为什么对于由同等权重项目组成的分数，报告麦当劳的 omega 是有意义的？

来源：
McNeish，D. (2017)。感谢系数 alpha，我们将从这里开始。心理方法，23(3)，412–433。https://doi.org/10.1037/met0000144]]></description>
      <guid>https://stats.stackexchange.com/questions/659010/rational-to-use-mcdonalds-omega-as-a-reliability-measure-for-an-unweighted-sum</guid>
      <pubDate>Fri, 20 Dec 2024 12:24:36 GMT</pubDate>
    </item>
    <item>
      <title>分位数的贝叶斯区间估计</title>
      <link>https://stats.stackexchange.com/questions/658982/bayesian-interval-estimate-for-a-quantile</link>
      <description><![CDATA[这个问题是为了澄清后验分布和后验预测分布是否可用于创建分位数的区间估计。考虑以下设置：
假设我有 $X_i\stackrel{iid}{\sim} N(\mu, \sigma^2)$，其中 $i=1,...,n$。为了论证的目的，我并不关心先验的形式是什么，但让我们假设我在 $\mu$ 和 $\sigma^2$ 上都放置了先验。现在，我可以运行我的 MCMC 采样器并获取 $\mu$ 和 $\sigma^2$ 的后验样本（我们将它们称为 $\mu_{*b}$ 和 $\sigma^2_{*b}$，其中我有 $b=1,...,B$ 个）。现在，给定 $X_i$ 的分布，我可以通过以下方式获得后验样本，例如第 95 分位数：
$$q_b= \mu_{*b} + z_{0.95}\sigma_{*b}$$
其中 $z_{0.95}$ 是标准正态分布的第 95 分位数。此外，由于这是基于样本的，我有一个后验分位数的分布，并且可以取这些后验分位数样本的分位数来获得不确定性区间估计。到目前为止一切顺利。
现在，我很好奇是否有办法使用后验预测分布来做到这一点？例如，在相同的设置下，后验预测分布可能是 $y_{\text{new}}\sim N(\mu_{\text{new}}, \sigma^2_{\text{new}})$，因此我可以模拟该分布的 $y_{\text{new}}$ 值并取第 95 分位数来估计它。但是，这个估计没有像后验分布那样的不确定性量化。我想总结一下我的问题，

基于后验分布和后验预测分布的结果是否应该匹配，并且
后验预测分布是否应该为第 95 分位数产生不确定性估计（以区间的形式）？


编辑以澄清：
似乎人们没有理解我的问题的要点，但也许是我自己的错，可能不够清楚。让我用 R 代码来说明我的观点：
&gt; ### 用于生成第 95 分位数估计的代码 
&gt; ### 并附带 90% 可信区间
&gt; 
&gt; ### 为了举例说明，假设我已经完成了后验 
&gt; ### 计算，并且我有： 
&gt; 
&gt; ### p(sigma^2 | X) ~ Gamma(3, 2)
&gt; ### p(mu | sigma, X) ~ N(200, sigma)
&gt; 
&gt; 
&gt; # 后验样本数
&gt; B &lt;- 10000
&gt; 
&gt; # sigma^2* 和 mu^* 的后验样本
&gt; sigma2.star &lt;- rgamma(B, 3, 2)
&gt; mu.star &lt;- rnorm(B, 200, sqrt(sigma2.star))
&gt; 
&gt; # 第 95 分位数和 90% 可信区间的后验估计
&gt; q &lt;- mu.star + qnorm(0.95) * sigma2.star
&gt;平均值（q）
[1] 202.465
&gt; 
&gt; 分位数（q，probs = c（0.05, 0.95））
5% 95% 
200.0369 206.0277 
&gt; 
&gt; 
&gt; ### 使用后验预测分布
&gt; ynew &lt;- rnorm（B，mu.star，sqrt（sigma2.star））
&gt; 
&gt; q &lt;- 分位数（ynew，prob = 0.95）
&gt; q
95% 
202.7814 

但如您所见，使用后验预测，我仅得到 $q$ 的值的一个估计值，但没有可信区间，因为只有一个值。]]></description>
      <guid>https://stats.stackexchange.com/questions/658982/bayesian-interval-estimate-for-a-quantile</guid>
      <pubDate>Thu, 19 Dec 2024 19:37:12 GMT</pubDate>
    </item>
    <item>
      <title>McNemar 检验为 z 检验或卡方检验</title>
      <link>https://stats.stackexchange.com/questions/657582/mcnemar-test-as-z-test-or-chi-squared-test</link>
      <description><![CDATA[我是统计学入门课的助教。我们正​​在向学生介绍 McNemar 检验，以比较相关样本上的两个比例。我注意到教科书中，我们将 McNemar 检验定义为遵循 z 分布的 z 统计量：
$$
z = \frac{b-c}{\sqrt{b+c}}
$$
而其他来源，例如维基百科，将检验统计量定义为遵循卡方分布
$$
\chi_1^2 = \frac{(b-c)^2}{b+c}
$$
我从数理统计中得知，z 统计量的平方服从自由度为 1 的卡方分布。
有人知道为什么人们可能更喜欢将一种框架作为 z 检验或将另一种框架作为 z 检验吗？我认为这两个统计数据会产生相同的推论。我怀疑如果学生决定自己阅读这个主题，他们可能会感到困惑。
将测试框架为 z 检验确实允许计算与卡方框架无关的标准误差。]]></description>
      <guid>https://stats.stackexchange.com/questions/657582/mcnemar-test-as-z-test-or-chi-squared-test</guid>
      <pubDate>Wed, 20 Nov 2024 21:28:46 GMT</pubDate>
    </item>
    <item>
      <title>对训练数据进行打乱是否会导致具有图像序列的时间序列模型中的信息泄露？</title>
      <link>https://stats.stackexchange.com/questions/657190/does-shuffling-the-training-data-cause-information-leakage-in-a-time-series-mode</link>
      <description><![CDATA[我正在研究一种基于以 10 分钟为间隔捕获的图像序列的太阳能发电预测模型。我的模型作为输入接收的单个示例由一系列图像组成。我的架构结合了 CNN 和 LSTM，CNN 处理图像序列以提取特征，然后将其传递给 LSTM 以利用图像序列中的时间信息。
我使用 10 分钟的预测间隔，图像分辨率为 10 分钟。因此，每幅图像（除了前几幅和最后几幅）将出现在多个序列中。输入批次的示例：

我想知道在训练期间打乱训练数据（即打乱图像序列的整体顺序，而不是序列内的图像）是否会导致信息泄露。我担心的是，在训练期间，模型可能在预测“当前”目标的同时已经看到了“未来”图像，这可能会破坏数据的时间结构。我没有在输入中提供任何明确的时间戳或先前的目标值，只是提供图像序列。
通过改组，我希望获得更好的梯度更新和更好的批量标准化。
编辑：
下面的图显示了训练（MSE）损失。上图表示没有改组的结果，而下图包括改组。每个图包括四次独立运行，以解释由于初始化而导致的变化。

根据验证损失应用了耐心为 2 个时期的早期停止，导致运行长度不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/657190/does-shuffling-the-training-data-cause-information-leakage-in-a-time-series-mode</guid>
      <pubDate>Wed, 13 Nov 2024 09:43:07 GMT</pubDate>
    </item>
    </channel>
</rss>