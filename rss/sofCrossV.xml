<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近的30个来自Stats.stackexchange.com</description>
    <lastBuildDate>Wed, 26 Mar 2025 09:20:43 GMT</lastBuildDate>
    <item>
      <title>信息几何因果推断（IGCI）中因果机制的独立性，以确定2个变量之间的因果方向</title>
      <link>https://stats.stackexchange.com/questions/663143/independence-of-causal-mechanism-in-information-geometric-causal-inference-igci</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/663143/independence-of-causal-mechanism-in-information-geometric-causal-inference-igci</guid>
      <pubDate>Wed, 26 Mar 2025 06:31:04 GMT</pubDate>
    </item>
    <item>
      <title>如何计算加权平均优势比？</title>
      <link>https://stats.stackexchange.com/questions/663142/how-to-calculate-weighted-average-odds-ratios</link>
      <description><![CDATA[我正在对五篇有关伤口并发症的论文进行荟萃分析。我已经计算了单独的伤口并发症类型的OR，但想计算加权平均值，以获取每张纸的“总体伤口并发症”或“总体伤口并发症”。
我该怎么做？
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/663142/how-to-calculate-weighted-average-odds-ratios</guid>
      <pubDate>Wed, 26 Mar 2025 01:12:24 GMT</pubDate>
    </item>
    <item>
      <title>用距离封装估算密度 - 如何指定覆盖为数据的样带的比例。</title>
      <link>https://stats.stackexchange.com/questions/663141/estimating-density-with-distance-package-how-to-specify-the-proportion-of-the</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/663141/estimating-density-with-distance-package-how-to-specify-the-proportion-of-the</guid>
      <pubDate>Wed, 26 Mar 2025 00:29:23 GMT</pubDate>
    </item>
    <item>
      <title>具有连续和分类变量的SEM模型</title>
      <link>https://stats.stackexchange.com/questions/663138/sem-model-with-continuous-and-categorical-variables</link>
      <description><![CDATA[如何估计具有连续和分类变量（序数，二元，名义）的SEM模型？
例如，如果我有以下模型，其中“区域”和“统计”是标称变量，“满意度”，“ opucation 1”，“ chuceal”和“满意度”是序数变量，而“ y_i”是连续变量。。
 模型＆lt;  - &#39;
x1 =〜教育 +地区 +统计
x2 =〜满意度1 +满意度2 + y4
x3 = 〜y1 + y2 + y3 +性别

x2〜x1
x3〜x2
&#39;
 
我尝试将名义变量拟合为使用WLSMV估计器以及DWLS和MLR编码的虚拟变量，但它不起作用。]]></description>
      <guid>https://stats.stackexchange.com/questions/663138/sem-model-with-continuous-and-categorical-variables</guid>
      <pubDate>Tue, 25 Mar 2025 22:51:42 GMT</pubDate>
    </item>
    <item>
      <title>随机术语：简单的随机化与完整的随机化</title>
      <link>https://stats.stackexchange.com/questions/663137/randomization-terminology-simple-randomization-vs-complete-randomization</link>
      <description><![CDATA[我注意到围绕不同方式将参与者随机分为治疗组的术语相互矛盾。
感兴趣的第一个随机化过程是治疗 $ t_i $ 是一个随机的伯诺利过程，每个人 $ i $ 分配给治疗是独立的。在给定的实验中，经过处理的观察总数是随机 $ n_t $ 。
一个替代随机化过程完全产生 $ n_t $ 从 $ n $ 观察结果的观察。在这种情况下，观测值 $ t_i $ 。
在r package  randomizr 讨论一个简单的随机化，第二个随机化过程中的第一个随机化，第二个作为完整的随机化。
在文本中随机化临床试验中的随机化第3章讨论了第一个随机化的随机性随机化和第二个随机化的过程，第二个随机化步骤是按随机化的过程。
我很好奇人们是否知道为什么术语完整的随机分配具有冲突的含义。不同的学科是指这些随机过程吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663137/randomization-terminology-simple-randomization-vs-complete-randomization</guid>
      <pubDate>Tue, 25 Mar 2025 22:15:43 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用哪种型号？具有自相关或固定效果的合并OLS？</title>
      <link>https://stats.stackexchange.com/questions/663131/which-model-should-i-use-pooled-ols-with-autocorrelation-or-fixed-effects</link>
      <description><![CDATA[我正在运行回归，以查看人力资本在结构转化过程中吸收FDI的影响。我的数据范围从1970  -  2020年的巴西和韩国，想比较各国，以查看两者的效果如何变化。我试图在两种模型之间做出决定：与国家假人和固定或随机效应模型之间的合并OLS，但是，由于以下原因，我对使用的模型感到困惑：
（重要的是要注意我的自相关测试是Wooldridge，因为它是多个国家）
合并的OLS ：（代码在图像中），带有带有乡村假人的OLS，我最初具有很高的多重共线性（在创建相互作用项之前通过平均核心进行纠正），并获得了一些重要的变量，但是模型中存在自相关。由于1970  -  2020年的数据跨越某些变量，因此很难使用更多的变量来纠正此问题，此外，在聚集错误或预先预示任何自动相关测试时，我的r^2降至50％以下，我被告知，我的R^2降至50％以上，几乎所有变量都会变得微不足道。&gt; 。
随机效果：在进行Hausman测试时，它建议仅服务部门（我正在做服务和制造业）和FE制造FE的RE模型，但是，当尝试为任何一个领域运行随机效果时，我们发现Stata由于数据不足而无法执行此操作。 
 fe：这是面板数据建议的典型模型，但是我在面板数据的问题如下：比较越野差异更难比较越野的变化，因为它本质上对国家 /地区的变化有了更大的关注，这是否意味着此模型在回答我的问题方面不太有用吗？但是，我的固定效应模型中不存在自动相关性（因为我摆脱了国家的假人），并且更多的vif没有显示多重共线性（我使用基本的OLS对此进行了测试）。但是，当我运行Fe vce（rounust）时，我的错误消失了。 noreferrer“&gt;  
  一些额外的信息：对于固定效果，我分别运行了每个国家 /地区，因此，这是country_name == 1，这是正确的方法吗？此外，它可以让我比较两国吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663131/which-model-should-i-use-pooled-ols-with-autocorrelation-or-fixed-effects</guid>
      <pubDate>Tue, 25 Mar 2025 20:50:13 GMT</pubDate>
    </item>
    <item>
      <title>论文数据困境：受试者方差分析之间的2 x 2显着相互作用，但没有主要影响。我该如何解释？</title>
      <link>https://stats.stackexchange.com/questions/663129/dissertation-data-dilemma-2-x-2-between-subjects-anova-significant-interaction</link>
      <description><![CDATA[我是实验心理学的第五年博士生，应该在今年五月毕业。在我将最后的草稿发送给委员会之前，我的顾问希望我在主题方差分析之间做2 x 2。在这种情况下，我的变量涉及阅读技能（最低的一半和最高熟练读者的最高一半）和阅读跨度（在阅读跨任务中的最低和最高分数的工作记忆中的最高分数）。 
阅读技能或阅读跨度没有主要影响。但是，它们之间存在显着的相互作用（p = 0.018）。根据我的顾问的要求，我什至对阅读技能和阅读跨度进行了跟进测试，无论哪种情况都没有意义。我们甚至尝试了同时回归并获得了相同的结果（显着的相互作用，没有主要影响）。请注意，方差分析和同时回归的模型并不重要。
我已经查找了各种在线解释结果的方法，他们现在让我有些困惑（我的顾问说他现在想考虑一下）。我认为这意味着技能是参与者阅读段落需要多长时间的重要因素？如果我错了，请随时纠正我，但我有点困难。
由于我意识到这是房间里的大象，所以我的统计背景不是最好的，因为我的第一位博士学位顾问不希望我参加我的博士学位课程中的第一个统计课程以外的其他课程。我本可以参加多元和回归课程，但是她不想让我这样做，因为我已经参加了一个被公认的大师（这也让我参加了一个统计课程），这放弃了我博士学位的大部分课程要求。]]></description>
      <guid>https://stats.stackexchange.com/questions/663129/dissertation-data-dilemma-2-x-2-between-subjects-anova-significant-interaction</guid>
      <pubDate>Tue, 25 Mar 2025 20:40:12 GMT</pubDate>
    </item>
    <item>
      <title>从标准正常内核的尾部进行排斥采样</title>
      <link>https://stats.stackexchange.com/questions/663111/rejection-sampling-from-the-tail-of-standard-normal-kernel</link>
      <description><![CDATA[  使用以下算法的标准正常内核的尾巴（即 $ x \ ge r = 3.654158 $ ）：

伪随机示例xx as 美元
伪随机样品yy〜指数（1）
如果 $ 2YY＆gt;（xx）^2 $ 然后r+xx〜目标密度

   https://github.com/numpy/numpy/numpy/blob/main/numpy/random/src/src/distributions/distributions.c  
我想知道两个问题：

是 $ m = 1/r $ 适当的常数选择（即 $ mg（x）\ ge f（x）\ ge f（x）$  $ x $ x $ 它是最佳（最有效）吗？
我想从常规 $ u \ u \ le f（x）/m \ cdot g（x）$ \ cdot G（x）$       

谢谢

在这里包括Luc Devroye的一些相关材料“不均匀随机变量生成”，第382页
    

我错误地认为m = 1/r。使用M = 1/R，接受条件不会简化为 $ 2*yy＆gt;（xx）^2 $ 。相反，如果选择m为 $ f（x）/g（x）$ 的接受条件确实简化为 $ 2*yy＆gt;（xx）^2 $ 。]]></description>
      <guid>https://stats.stackexchange.com/questions/663111/rejection-sampling-from-the-tail-of-standard-normal-kernel</guid>
      <pubDate>Tue, 25 Mar 2025 12:39:01 GMT</pubDate>
    </item>
    <item>
      <title>ANOVA残差的正常程度如何？</title>
      <link>https://stats.stackexchange.com/questions/663099/how-normal-do-anova-residuals-have-to-be</link>
      <description><![CDATA[合作者用单向方差分析分析了一些数据。但是，当我查看数据时，我有这个残差QQ图。它看起来不是很正常。但是我的合作者继续进行方差分析。我读过，方差分析很健壮，但我不确定多少。
  我做了其他测试。我跟随此  并做出了一系列正常的QQ QQ QQ QQ QQ QQ QQ QQ QQ QQ Qq plots。我的数据（z）看上去根本不正常。
   i登录转换的数据，看起来更好，但仍然有一些离群值（我使用 sideen_outliers ）。
    stiend_outliers（data = table_egg，variable =＆quot; logeggs; quot; quot;）

   logeggs is.outlier is.extreme
     ＆lt; dbl＆gt; ＆lt; lgl＆gt;      ＆lt; lgl＆gt;     
 1 6.55 true false     
 2 1.84真实      
 3 6.55 true false     
 4 6.47 True False     
 5 6.72 true false     
 6 6.45 true false     
 7 6.77 True False     
 8 6.82 true false     
 9 3.77 True False     
10 4.03 True False  
 
然而，方差分析和事后的Tukey测试给出了相似的显着性结果，但具有较大的对数转换数据的p值。
 ＆gt;摘要（fit_eggs）
             DF SUM SQ平均SQ F值PR（＆GT; F）    
条件15 1913454 127564 12.3＆lt; 2e-16 ***
残差436 4522801 10373                   
---
象征。代码：0&#39;***’0.001&#39;**’0.01&#39;*’0.05&#39;。’0.1’’1
＆gt;摘要（fit_eggs2）
             DF SUM SQ平均SQ F值PR（＆GT; F）    
条件15 16.18 1.0789 5.147 1.86E-09 ***
残差436 91.39 0.2096                     
---
象征。代码：0&#39;***’0.001&#39;**’0.01&#39;*’0.05&#39;。’0.1’’1
 
我应该使用原始数据吗？我应该登录转换吗？我应该尝试其他转型吗？我应该删除异常值并重试吗？我应该只是进行Kruskal-Wallis测试吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/663099/how-normal-do-anova-residuals-have-to-be</guid>
      <pubDate>Tue, 25 Mar 2025 10:00:07 GMT</pubDate>
    </item>
    <item>
      <title>这是过度的吗？</title>
      <link>https://stats.stackexchange.com/questions/663096/is-this-overfit</link>
      <description><![CDATA[我是ML的新手，我正在开发我的第一个变异自动编码器（vae），该变量由CNN编码（4层）和CNN解码器（4层）组成。输入图像的尺寸为128x128，尺寸减小，直到获得4x4尺寸的图像（带有128个通道）。租赁尺寸为10。
我面临的问题是，火车损失在几乎2-3个时期内变得恒定，并且在训练过程中没有改善（我看到测试损失正在改善，但它具有怪异的行为，并且在几个时期的时代中会保持不变）。我尝试使用不同的学习率和批量大小，但我得到了类似的行为。此外，我可以更改VAE的结构，并减少编码器/解码器中的层数，但是减少到3层也提供了相似的行为，我在其他作品中看到的VAE模型似乎具有更多的输入尺寸的层。 。。
 问题是：这过分？我如何避免这种行为？
  &lt;img alt =“在训练vae” src =“ src =” src =“ https://i.sstatic.sstatic.net/2f5xyh3m.ppng.png.png”时的火车和测试损失]]></description>
      <guid>https://stats.stackexchange.com/questions/663096/is-this-overfit</guid>
      <pubDate>Tue, 25 Mar 2025 07:21:05 GMT</pubDate>
    </item>
    <item>
      <title>当比例中的分母也有不确定性时该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/662243/what-to-do-when-the-denominator-in-a-proportion-also-has-uncertainty</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/662243/what-to-do-when-the-denominator-in-a-proportion-also-has-uncertainty</guid>
      <pubDate>Thu, 06 Mar 2025 02:02:53 GMT</pubDate>
    </item>
    <item>
      <title>使用Jackson等人时，按每个随机效果分配$ i^2 $异质性估计。 （2012）伪 -  $ i^2 $方法</title>
      <link>https://stats.stackexchange.com/questions/661837/partitioning-i2-heterogeneity-estimates-by-each-random-effect-when-using-the</link>
      <description><![CDATA[正如Jackson等人在堆栈[1]上其他地方建立的。 （2012）[2]和Nakagawa＆amp; Santos等。 (2012) [3] methods are viable methods for calculating $I^2$-like heterogeneity estimates in multivariate meta-analytical models in the &#39;metafor&#39; R package - even where the variances are specified with a &#39;vi&#39; term rather than a full variance-covariance matrix as in the website example [4].结果有时是完全不同的，但两者都是有效的。
 nakagawa＆amp; Santos方法，再次如堆栈[5]上的另一篇文章所述，可以计算总计 $ i^2 $ 或 $ i^2 $ 每个随机效果，如下：：
  dat＆lt;  -  dat.konstantopoulos2011

＃通过〜1 |外部/内部指定的随机效应
res1＆lt;  -  rma.mv（yi，vi， 
               随机=列表（〜年|学校，〜1 |研究），
               数据= DAT）
Res1
w＆lt;  -  diag（1/res1 $ vi）
x＆lt;  -  model.matrix（res1）
p＆lt;  -  w- w％*％x％*％solve（t（x）％*％w％*％x）％*％t（x）％*％w

＃i2（总数）
100 * sum（res1  $ tau2，res1 $  sigma2）/（sum（res1  $ tau2，res1 $  sigma2）

＃i2在学校一年
100 * res1  $ tau2/（sum（res1 $  tau2，res1  $ sigma2） +（res1 $  k-res1 $ p）/sum/sum（diag（p））

＃i2学习
100 * res1  $ sigma2/（sum（res1 $  tau2，res1  $ sigma2） +（res1 $  k-res1 $ p）/sum（diag（p））
 
但是，我不清楚如何对杰克逊方法做同等的方法。有人可以澄清是否可以做到这一点，如果是这样，请如何做？
 参考 

See discussion in the comments of the question here: Computing I2使用内部|随机效应的内部规范 

  Jackson，D.，White，I。R.，＆amp; Riley，R。D.（2012）。量化研究间异质性在多元荟萃分析中的影响。医学的统计数据，31（29），3805–3820。

 中川，S。，＆amp; Santos，E。S. A.（2012）。生物荟萃分析的方法论问题和进步。进化生态学，26（5），1253–1274。

   https://metafor-project.org/doku.php/tips:i2_multilevel_multivariate?s [] = Heterogenity＃Jackson_Al_Al_Al_2012_Applace   

  
]]></description>
      <guid>https://stats.stackexchange.com/questions/661837/partitioning-i2-heterogeneity-estimates-by-each-random-effect-when-using-the</guid>
      <pubDate>Tue, 25 Feb 2025 11:35:44 GMT</pubDate>
    </item>
    <item>
      <title>$ {θ}/{2} $ in $ \ text {u}（0，\ theta）$的置信区间</title>
      <link>https://stats.stackexchange.com/questions/659276/confidence-interval-for-%ce%b8-2-in-textu0-theta</link>
      <description><![CDATA[我试图找到一个 $ {\ theta}/{2} $ 带置信度级别 $ 1- \ alpha $ （在 $ p_1 = \ alpla  $ P_2 = 1 $ ）。  因此，我对 $ {\ hat {\ theta}}}/{2} = {x _ {（n）}}/{2} $ 。  然后从我们在课堂上学到的知识：
  $$ \ MATHBB {p} \ bigG（\ dfrac {cx _ {（n）}} {2 \ theta} \ leqslant q_
= \ Mathbb {p} \ bigG（\ dfrac {x _ {（n）}}} {\ theta} \ leqslant \ dfrac {2q_ {2q_ {p_1}}} {c} {c} \ bigG）
= \ alpha
= \ bigG（\ dfrac {2q_ {p_1}}} {c} \ bigg）^n，$$  
    $ q_ {p_1} = \ tfrac {c} {2} {2} \ alpha^{{1}/{n}} $  $  and  $ q_ {p_2} = {c}/{2} $ 。  这给出了：
  $$ \ Mathbb {p} \ bigG（\ dfrac {\ dfrac {c} {2} {2} \ alpha^{{1}/{n}} \ leqslant \ dfrac \ dfrac \ dfrac { \ dfrac {c} {2} \ bigg）
= \ Mathbb {p} \ bigG（x _ {（n）} \ leqslant \ dfrac {\ theta} {2} {2} \ leqslant \ dfrac {x _ {x _ {（n）}}}
= 1- \ alpha，$$  
因此，由此产生的CI为：
  $$ \ dfrac {\ theta} {2} {2} \ in \ bigg [x _ {（n）}，\ dfrac {x _ {x _ {（n）}}}} {\ alpha^{\ alpha^{\ alpha^{1} {1} {n}}}
这看起来正确吗？还是我错过了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659276/confidence-interval-for-%ce%b8-2-in-textu0-theta</guid>
      <pubDate>Fri, 27 Dec 2024 21:45:01 GMT</pubDate>
    </item>
    <item>
      <title>随机订单符号 - 不合理符号</title>
      <link>https://stats.stackexchange.com/questions/658935/stochastic-order-symbols-unusual-notation</link>
      <description><![CDATA[教授为我们提供了以下Big-Oh-P-One的定义，与我发现的其他来源相比，这似乎有些不寻常。定义是：
让 $ z_n $ 和 $ a_n $ ， $ n = 1，2，\ ldots $ 分别是随机变量和常规的序列。符号 $ z_n = o_p（1）$ （``big oh-p-one&#39;&#39;）意味着 $ z_n $ 是概率的。确切地说，对于任何 $ \ Epsilon＆gt; 0 $ ，有一个常数 $ M_ \ Epsilon＆lt; \ infty $ 这样
 \ begin {equation}
\ limsup_ {n \ to \ infty} p（| z_n |＆gt; m_ \ epsilon）\ leq \ epsilon。
\ end {equation}  
 Q1：为什么有必要在此定义中使用最高？
 Q2：直觉似乎是 $ z_n $ 超过大常数 $ m $ 变得很小，对于足够大的 $ n $ span&gt;。这种解释正确吗？为什么这个概念在计量经济学中特别有用？]]></description>
      <guid>https://stats.stackexchange.com/questions/658935/stochastic-order-symbols-unusual-notation</guid>
      <pubDate>Wed, 18 Dec 2024 19:07:24 GMT</pubDate>
    </item>
    <item>
      <title>调解分析与序数调解人</title>
      <link>https://stats.stackexchange.com/questions/622941/mediation-analysis-with-an-ordinal-mediator</link>
      <description><![CDATA[我必须对我的研究进行调解分析，而我的IV和DV都是连续的，而中介变量是有序的（在Instagram上花费的时间），其中类别是：

每天30分钟少。
每天30分钟至3H。
每天3h至6h。
超过6h。

我将该调解人标记为序数，因为衡量类别中的差异并不相等。我正在使用SPSS和过程宏，只有在调解器连续的情况下才能使用。
那么您建议什么方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/622941/mediation-analysis-with-an-ordinal-mediator</guid>
      <pubDate>Wed, 02 Aug 2023 09:40:13 GMT</pubDate>
    </item>
    </channel>
</rss>