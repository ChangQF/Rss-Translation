<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 07 Jul 2024 12:25:59 GMT</lastBuildDate>
    <item>
      <title>评估测试图像的最佳时期是什么时候？</title>
      <link>https://stats.stackexchange.com/questions/650634/what-is-the-best-epoch-to-evaluate-the-test-images</link>
      <description><![CDATA[我为一个图像分类任务创建了一个训练集、一个验证集和一个测试集。然后，我使用训练集进行训练，并对验证集进行评估。因此，下一步是评估测试集，基本上是为了推理。为了选择最佳的 epoch 模型，我通常会检查验证损失。但是，我不确定这种方式是否正确。我将结果添加为图片，并标记了最佳的 train/val 准确率和最低的 train/val 损失。损失函数是 Cross Entrophy。

后面的步骤显然是过度拟合，但训练损失仍然越来越低，直到第 25 个 epoch。如果我只检查 val 损失，我可能会选择第 13 个 epoch。或者最高的验证准确率也可能很重要。
我读过一些文章或论坛问题，比如这个、这个、这个和其他几个，但这个话题没有真正的结论。那么，对于这种情况，有没有通用的解决方案，或者我应该以不同的方式考虑每个分类/对象检测任务并做出相应的决定？]]></description>
      <guid>https://stats.stackexchange.com/questions/650634/what-is-the-best-epoch-to-evaluate-the-test-images</guid>
      <pubDate>Sun, 07 Jul 2024 12:16:32 GMT</pubDate>
    </item>
    <item>
      <title>主观信心作为回归模型中的权重</title>
      <link>https://stats.stackexchange.com/questions/650629/subjective-confidence-as-weights-in-regression-models</link>
      <description><![CDATA[我有数据，其中受试者在某个范围内对数量进行评分（$y$），但也添加了他们对选择的确定程度的主观信心（$w$）。我最初的想法是将$w$作为权重添加到回归模型中（暂时忽略如何对其进行规范化或标准化的问题）。我的上级要求检查$w$与方差之间的关系 - 指出如果它们与方差成反比，则应加入置信度。我们检查了非加权模型的平均绝对残差（作为方差的代理），发现较高置信度的残差与较低置信度的残差大致相同。我的上级得出结论，我们不应该使用置信度评级。
虽然我同意数据和模型似乎没有表明更高的置信度评级与更低的方差相关，但我仍然不相信这是使用权重的唯一原因。如果对某些数据点有很高的置信度，那么与其他置信度较低的数据点相比，它们是否应该有更多发言权来将回归线拉近它们？]]></description>
      <guid>https://stats.stackexchange.com/questions/650629/subjective-confidence-as-weights-in-regression-models</guid>
      <pubDate>Sun, 07 Jul 2024 09:58:56 GMT</pubDate>
    </item>
    <item>
      <title>报告 clmms 中固定效应的重要性 - 何时使用 ANODE 表？</title>
      <link>https://stats.stackexchange.com/questions/650628/reporting-significance-of-fixed-effects-in-clmms-when-to-use-anode-tables</link>
      <description><![CDATA[我正在使用 clmm 研究一些用于序数结果的混合效应模型。我已经确定了最终模型，现在想展示研究结果。阅读后，我看到 ANODE 表既用于模型比较，也用于分解模型中每个固定效应的贡献。我无法找到任何关于这是否与报告相关的指导，以及最佳实践是什么。该模型是使用 R 中的序数包估计的，ANODE 表来自 RVAideMemoire。
实际上，这与模型输出中报告的 z 检验之间的结果几乎没有差异（如下所示）。但是，我想更多地了解两组输出之间的差异。有人可以提出一些建议吗？我可以找到有关模型比较的信息，但找不到关于如何报告最终模型中固定效应的重要性的具体问题的答案。
非常感谢！
 估计误差 z Pr(&gt;|z|)

Var1 -2.966 0.482 -6.152 &lt;0.001

Var2 -2.102 0.486 -4.32 &lt;0.001

Var3 -1.593 0.476 -3.349 0.001

Var4 0.973 0.474 2.051 0.040

Var5 -0.711 0.175 -4.07 &lt;0.001

偏差分析（II 型检验）

LR Chisq Df Pr(&gt;Chisq) 

Var1 29.2981 1 &lt;0.001 ***
Var2 16.2687 1 &lt;0.001 ***
Var3 10.2870 1 0.001 **
Var4 3.9415 1 0.047 *
Var5 14.5733 1 &lt;0.001 ***
]]></description>
      <guid>https://stats.stackexchange.com/questions/650628/reporting-significance-of-fixed-effects-in-clmms-when-to-use-anode-tables</guid>
      <pubDate>Sun, 07 Jul 2024 08:26:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么考虑自相关残差几乎无助于分布滞后模型中的参数估计</title>
      <link>https://stats.stackexchange.com/questions/650626/why-does-accounting-for-autocorrelated-residuals-barely-help-parameter-estimatio</link>
      <description><![CDATA[这个问题困扰了我很长时间。基本上，我有一个分布式滞后模型$$y_t=\sum_{i=0}^{p} \beta_i x_{t-i} + u_t.$$
回归问题有点错误指定，所以我最终得到自相关错误$$u_t=\alpha u_{t-1}+\epsilon_t.$$
由于我的模型中自相关程度很高，$\beta$的估计应该非常低效，但是当我使用 GLS 校正自相关时，我的$\beta$估计没有任何改善。当我的问题略有不同，并且 $$y_t= \sum_{i=1}^p \beta_i x_t^i + u_t,$$ 时，$y$ 只是同时存在的不同 $x$ 的函数，GLS 表现惊人，而最小二乘则举步维艰。
为什么 GLS 在第一个例子中表现如此糟糕，我如何让它表现得更好（我只关心参数估计）？
我在 R 中编写了两个例子：
n_sim&lt;-15
LS_R2&lt;-rep(0,n_sim)
GLS_R2&lt;-rep(0,n_sim)
ar_noise&lt;-0.7
for(sim in 1:n_sim){
n=5000
set.seed(sim)
x_vec&lt;-arima.sim(list(order=c(1,0,0),ar=c(0.5)),n=n,sd=1)
noise&lt;-arima.sim(list(order=c(1,0,0),ar=c(ar_noise)),n=n,sd=1)
y&lt;-rep(0,n)
p&lt;-150
true_beta&lt;-seq(from=5,to=0,length.out=p)+rnorm(p,sd=0.1)
for(i in p:length(y)){
y[i]&lt;-y[i]+sum(x_vec[i:(i-p+1)]*true_beta)
}
y&lt;-y+noise*var(y)/var(noise)/50

#尝试简单最小二乘法（应该非常低效）
Xmat&lt;-matrix(0,ncol = p,nrow = n)
for(i in 1:ncol(Xmat)){
Xmat[,i]&lt;-c(rep(0,i-1),x_vec[1:(length(x_vec)-i+1)])
}

XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
LS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

#尝试广义最小二乘法（应该是最优且有效的）
get_T&lt;-function(ar,N){
i_vec&lt;-c(1:N,2:N)
j_vec&lt;-c(1:N,1:(N-1))
x_vec&lt;-c(sqrt(1-ar^2),rep(1,N-1),rep(-ar,N-1))
sparseMatrix(i = i_vec, j = j_vec, x = x_vec, dims = c(N,N))
}

T1&lt;-get_T(ar_noise,length(y))

Xmat&lt;-T1%*% Xmat
y&lt;-as.numeric(T1%*% matrix(y,ncol=1))

XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
GLS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

}
LS_R2
GLS_R2
mean(LS_R2)
mean(GLS_R2)

and
n_sim&lt;-15
LS_R2&lt;-rep(0,n_sim)
GLS_R2&lt;-rep(0,n_sim)
for(sim in 1:n_sim){
n=5000
set.seed(sim)
noise&lt;-arima.sim(list(order=c(1,0,0),ar=c(ar_noise)),n=n,sd=1)
y&lt;-rep(0,n)
p&lt;-150
Xmat&lt;-matrix(0,ncol = p,nrow = n)
for(i in 1:ncol(Xmat)){
Xmat[,i]&lt;-arima.sim(list(order=c(1,0,0),ar=c(0.5)),n=n,sd=1)
}
true_beta&lt;-seq(from=5,to=0,length.out=p)+rnorm(p,sd=0.1)
for(i in p:length(y)){
y[i]&lt;-y[i]+sum(Xmat[i,]*true_beta)
}
y&lt;-y+noise*sd(y)/sd(noise)

#尝试简单最小二乘法（应该是非常低效的）
XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
LS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

#尝试广义最小二乘法（应该是最优且有效的）
get_T&lt;-function(ar,N){
i_vec&lt;-c(1:N,2:N)
j_vec&lt;-c(1:N,1:(N-1))
x_vec&lt;-c(sqrt(1-ar^2),rep(1,N-1),rep(-ar,N-1))
sparseMatrix(i = i_vec, j = j_vec, x = x_vec, dims = c(N,N))
}

T1&lt;-get_T(ar_noise,length(y))

Xmat&lt;-T1%*% Xmat
y&lt;-as.numeric(T1%*% matrix(y,ncol=1))

XXProd&lt;-crossprod(Xmat)
XyProd&lt;-crossprod(Xmat,matrix(y,ncol = 1))

est_beta&lt;-as.numeric(solve(XXProd, XyProd,tol=0))
GLS_R2[sim]&lt;-1- sum((true_beta-est_beta)^2)/sum((true_beta-mean(true_beta))^2)

}
LS_R2
GLS_R2
mean(LS_R2)
mean(GLS_R2)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/650626/why-does-accounting-for-autocorrelated-residuals-barely-help-parameter-estimatio</guid>
      <pubDate>Sun, 07 Jul 2024 07:15:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么逆倾向得分加权有效？</title>
      <link>https://stats.stackexchange.com/questions/650624/why-does-inverse-propensity-score-weighting-work</link>
      <description><![CDATA[假设某些治疗 $D = 0, 1$ 对结果 $Y = 0,1$ 的影响受到性别 $S = 0,1$ 的混淆。对 $D$ 对 $Y$ 的因果影响的无混淆估计将使我们估计层内风险，然后在计算其差异之前根据层的流行程度对这些风险进行加权。从数学上讲，我们会计算
$$ E[Y(D=d)] = \sum_s E[Y \mid D=d, S=s] P(S=s) $$
对每个 $d$ 计算差值。如果简单地写出均值估计量的简单差异，就会发现权重不正确，这是造成混杂的原因
$$ E[Y\mid D=d] = \sum_s E[Y \mid D=d, S=s] P(S=s \mid D=D) $$
请注意，通过贝叶斯规则
$$ P(S=s \mid D=D) = \dfrac{P(D=D \mid S=S) P(S=s)}{P(D=d)} $$
它是倾向得分和正确权重的函数$P(S=s)$。但是，简单地用倾向得分的倒数对 $E[Y \mid D=d]$ 的估计值进行加权，就会在 $E[Y \mid D=d]$ 的表达式中留下一个 $1/P(D=d)$ 因子。
那么，为什么 IPTW 会得出正确的因果对比估计值呢？我希望得到一个符合我在此处所写的期望加权和的答案。特别是，我希望证明 IPTW 会得出一个类似于我提出的第一个方程的表达式。]]></description>
      <guid>https://stats.stackexchange.com/questions/650624/why-does-inverse-propensity-score-weighting-work</guid>
      <pubDate>Sun, 07 Jul 2024 05:59:37 GMT</pubDate>
    </item>
    <item>
      <title>广义策略迭代 (GPI)、Actor-Critic 和 Q 学习方法之间有什么关系？</title>
      <link>https://stats.stackexchange.com/questions/650622/whats-the-relation-between-generalized-policy-iteration-gpi-actor-critic-an</link>
      <description><![CDATA[在我看来，广义策略迭代 (GPI) 和 Actor-Critic 是相同的，而 Q-learning 方法是一个独立的算法系列。我认为 GPI 和 Actor-Critic 都描述了策略评估 (critic) 和策略改进 (actor) 的迭代过程，而 Q-learning 只是使用贝尔曼最优方程进行引导。
详细说明我的理解：策略评估 (critic) 是通过蒙特卡洛或时间差分方法完成的，必要时包括函数逼近，策略改进 (actor) 可以通过贪婪 (表格情况) 或使用策略梯度定理 (大状态空间) 来完成。Q-learning 不做任何这些。它只是尝试使用贝尔曼最优方程通过迭代拟合 Q 值的贝尔曼最优方程来估计 $Q^\ast$。
如果有人能确认我的理解是否正确，或者对在线 RL 算法的分类法给出更系统/精确的总结，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/650622/whats-the-relation-between-generalized-policy-iteration-gpi-actor-critic-an</guid>
      <pubDate>Sun, 07 Jul 2024 05:24:58 GMT</pubDate>
    </item>
    <item>
      <title>故意发表错误统计方法的著名例子有哪些？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/650620/what-are-famous-examples-of-erroneous-statistical-methods-being-deliberately-pub</link>
      <description><![CDATA[是否有著名的错误统计方法发表的例子，作者从一开始就知道他们的方法是错误的，但故意隐瞒它？
例如，我想到的是人们试图测试某些期刊的同行评审过程的可靠性，或者在战争时期，出版物可能旨在鼓励敌人使用错误的方法。但我对其他可能的动机也很感兴趣。促使我提出这个问题的原因是，在社会科学中有几个这样的例子，所以我想知道它是否也发生在统计研究中。
我不认为有很多著名的例子（我从未听说过这样的案例，这就是我问这个问题的原因），因为隐藏方法不正确可能非常困难，所以我想问题的范围不是太广泛。]]></description>
      <guid>https://stats.stackexchange.com/questions/650620/what-are-famous-examples-of-erroneous-statistical-methods-being-deliberately-pub</guid>
      <pubDate>Sun, 07 Jul 2024 04:46:31 GMT</pubDate>
    </item>
    <item>
      <title>策略梯度方法中的目标函数是否正是期望值函数？</title>
      <link>https://stats.stackexchange.com/questions/650615/is-the-objective-function-in-policy-gradient-methods-exactly-the-expected-value</link>
      <description><![CDATA[
我正在阅读 DRL 中的 Spinning Up。我想知道策略梯度算法中的目标 $J_\theta$ 是否正是期望值函数 $E_{S_0}[V^\pi(S_0)]$。我从未见过有人将目标写为 V，但我觉得它们是一样的。有人可以证实这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650615/is-the-objective-function-in-policy-gradient-methods-exactly-the-expected-value</guid>
      <pubDate>Sun, 07 Jul 2024 02:45:34 GMT</pubDate>
    </item>
    <item>
      <title>拆分数据然后进行回归是否合理？</title>
      <link>https://stats.stackexchange.com/questions/650613/is-it-reasonable-to-split-the-data-and-then-perform-the-regression</link>
      <description><![CDATA[有一家商店销售圆珠笔。我已从该商店获取每笔交易的数据，包括交易 ID、颜色、每笔交易的销售数量、总价等。通过将总价除以每笔交易数量，我计算出了每笔交易中每支笔的单价。我认为每支圆珠笔的单价与其颜色和每笔交易中购买的数量有关。因此，我将使用线性回归来检验这一假设：单价 = Alpha1 x 颜色 + Alpha2 x 数量 + Beta。
原始数据图像：

问题是，我可以在执行回归之前拆分这些数据吗？例如，在原始样本数据中，第一笔交易销售了 2 支圆珠笔，因此我将把它拆分为两个条目。拆分数据如下图所示，回归方程不变：单价 = Alpha1 x 颜色 + Alpha2 x 数量 + Beta。
拆分数据图片：

我的问题是：这个操作可以吗？会有什么影响，为什么？有相关参考吗？
我觉得这个操作可能不合理，比如反而增加了蓝色笔的数据权重。但是我对统计学的理解不够，无法清晰的表达出为什么或者怎么不合理。]]></description>
      <guid>https://stats.stackexchange.com/questions/650613/is-it-reasonable-to-split-the-data-and-then-perform-the-regression</guid>
      <pubDate>Sun, 07 Jul 2024 01:30:45 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯线性回归中的滞后因变量</title>
      <link>https://stats.stackexchange.com/questions/650582/lagged-dependent-variable-in-bayesian-linear-regression</link>
      <description><![CDATA[我正在构建贝叶斯广义线性模型，以尝试模拟企业拥有的客户数量。本质上是市场组合模型。
我认为客户数量可以通过媒体支出和一些控制（傅立叶季节性、趋势、公共假期等）来解释。
我基本上是这样定义模型的（省略了一些细节，因为我认为它们对我想问的问题并不重要）：
$$y_t \sim N(\mu_t, \sigma)$$
$$\mu_t=\alpha+\beta f(X_t)+\gamma W_t$$
$$f(X_t) = \sum_{k=0}^m \lambda^k X_{t-k}$$
$$\beta \sim Exp(.)$$
$$\gamma \sim N(.)$$
$$\lambda \sim Beta(.)$$
$y_t$ 表示 $t$ 时刻的客户数量，$\alpha$ 为基线客户，$\beta$ 为各种媒体渠道的系数向量，$X_t$ 为我们的媒体支出数据，$\gamma$ 为各种控制变量的系数向量，$W_t$ 是控制变量数据。
$f(x)$ 是一个广告库存函数，它考虑了媒体支出在客户心中积累并在消散前停留一段时间的情况。
我特别感兴趣的是发现不同媒体类型的媒体支出的有效性，所以基本上是过去一段时间内的 $\beta X$。预测目前不是优先事项。
我认为 $t$ 时刻的客户数量应该受到 $t-1$ 时刻的客户数量的影响。事实上，当我运行上述模型并查看残差时，似乎有自相关的证据。因此，我觉得我应该将 $\mu_t$ 重新定义为
$$\mu_t = \alpha+\beta f(X_t)+\gamma W_t +\eta y_{t-1}$$
当我这样做时，显然媒体变量的解释力将被抑制，因此在我所观察的时间段内，媒体的有效性将降低。
这公平吗？今天的客户数量部分由昨天的客户数量决定，但昨天的客户本身部分由媒体决定。那么，我是否应该将 $t$ 时滞后变量的有效性归因于 $t-1$ 期间的媒体变量？或者这会是重复计算吗？
抱歉，如果这有点复杂，感谢您对此的任何意见。]]></description>
      <guid>https://stats.stackexchange.com/questions/650582/lagged-dependent-variable-in-bayesian-linear-regression</guid>
      <pubDate>Sat, 06 Jul 2024 08:47:59 GMT</pubDate>
    </item>
    <item>
      <title>如何将贝叶斯模型拟合到 Beta、指数和一零膨胀数据的混合中？</title>
      <link>https://stats.stackexchange.com/questions/650533/how-to-fit-a-bayesian-model-to-a-mixture-of-beta-exponential-and-one-zero-infl</link>
      <description><![CDATA[我的数据非常嘈杂，我相信这是通过多个物理过程的相互作用而产生的。在映射 $Y = f(X),$ 中，$Y$ 是一个比率 $[0, 1]$ 和 $X \ge 0.$，而 $Y$ 是 $X,$ 的函数，它也可以取 $0$（更可能在较低的 $X$ 值时）或 $1$（更可能在较高的 $X$ 值时）。 $Y$ 是每个 $X$ 间隔的指数、Beta 和零一膨胀过程的混合。指数部分在 $X$ 值较低时更明显，并随着 $X$ 的增加而缓慢消失。
如何使用贝叶斯方法对此类过程进行建模？我是贝叶斯统计的新手，希望得到任何帮助。我可以拟合零一膨胀的 Beta 模型，但它无法捕捉指数类分量。
模拟真实数据的虚拟数据：
# 设置种子以实现可重复性
set.seed(123)

# 生成 x 值
x &lt;- seq(0, 20, length.out = 1000)

# 为 y 创建非线性函数
y &lt;- 0.15 + 0.005 * x^1.05 + 1 / (2.5 + 2532 * exp(-1.611 * x))

# 添加一些随机噪声
noise_factor &lt;- 0.03
# 使用 beta 噪声创建模型（此处使用正态分布创建）
noisy_y &lt;- rnorm(length(x), mean = 0, sd = noise_factor * sqrt(x))

y &lt;- y + noisy_y

# 向数据添加零个和一个噪声
noisy_indices &lt;- sample(1:length(x), round(0.2 * length(x)))
for (i in noisy_indices) {
if (runif(1) &lt; 1 / (1 + exp(x[i]))) {
y[i] &lt;- 1
} else {
y[i] &lt;- 0
}
}

# 添加指数分布
noisy_indices &lt;- sample(1:length(x), round(0.5 * length(x)))
for (i in noisy_indices) {
if (runif(1) &lt; 100 / (1 + exp(x[i]))) {
y[i] &lt;- rexp(1, rate =4)
} else {
y[i] &lt;- y[i]
}
}

# 创建数据框
data &lt;- data.frame(x = x, y = y) |&gt;
filter(y&lt;=1 &amp; y&gt;=0)

ggplot(data, 
aes(x, y)) +
geom_point() +
xlim(0, 20) + 
ylim(0, 1)

ggplot(data = data, 
aes(x=y))+
geom_histogram()

我正在尝试制定一个将 X 映射到 Y 的函数

整个数据集中 Y 的分布。在原始数据集中，从零（@Y=0）到指数部分（Y ~ 0-0.25）的过渡非常平滑。

我尝试（在原始数据上）在 brms 中使用零一膨胀 Beta 得出此后验预测：
]]></description>
      <guid>https://stats.stackexchange.com/questions/650533/how-to-fit-a-bayesian-model-to-a-mixture-of-beta-exponential-and-one-zero-infl</guid>
      <pubDate>Fri, 05 Jul 2024 14:49:43 GMT</pubDate>
    </item>
    <item>
      <title>当我的因变量在 R 中被分数幂运算时，我应该如何反向变换 beta 系数</title>
      <link>https://stats.stackexchange.com/questions/650513/what-should-i-back-transform-beta-coefficients-when-my-dependent-variable-is-fra</link>
      <description><![CDATA[我有这个混合效应回归模型。为了在连续尺度因变量中创建正态分布，我对其进行了分数指数化：
TB_fract &lt;- TB ^ (1/1.4)

我的以下模型是这样的，其中 period 表示时间的整数值，MRN 表示单个受试者：
lme4::lmer(TB_fract ~ Surg_group_fact + (1 + period|MRN), data = full_patient_data_2, na.action = na.omit)

我的输出是这样的。 time_below_sqrt 是 TB_fract 的 DV 表示：


我显然有负 beta 估计值，这不允许转换为 1.4 次方。如果我的 DV 是具有负 beta 系数的原始值的分数值，那么我该如何解释这些结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/650513/what-should-i-back-transform-beta-coefficients-when-my-dependent-variable-is-fra</guid>
      <pubDate>Fri, 05 Jul 2024 09:14:21 GMT</pubDate>
    </item>
    <item>
      <title>对于给定平均值和标准差的正数据，偏度的下限是多少？</title>
      <link>https://stats.stackexchange.com/questions/650039/vintage-of-this-lower-bound-on-skewness-for-positive-data-with-given-mean-and-sd</link>
      <description><![CDATA[事实证明，对于任何具有给定平均值 μ 和标准差 σ 的严格正数据集，其偏度 $g_1$ 都有一个下限：
$$
g_1 &gt; \sigma/\mu - \mu/\sigma。
$$
虽然在最近的一些文献中，它被讨论为一个新的结果，但在我看来，它很可能相当古老——原因我在这篇 PubPeer 文章（其中还包含一个基本证明）中概述过。
来这里问这个问题，我遇到了 2 个问题，这个结果立即适用：请参阅我的答案这里和这里。所以这表明下限至少没有它应该的那么出名。但它可能是最近才出现的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/650039/vintage-of-this-lower-bound-on-skewness-for-positive-data-with-given-mean-and-sd</guid>
      <pubDate>Thu, 27 Jun 2024 11:01:24 GMT</pubDate>
    </item>
    <item>
      <title>如何用外行人能理解的术语解释风险比</title>
      <link>https://stats.stackexchange.com/questions/649029/how-to-explain-hazard-ratio-in-laypersons-terms</link>
      <description><![CDATA[在 Cox 回归的背景下，我最近听到有人说“两个治疗组之间的风险比为 0.70，这表明在整个随访期间，对照组中发生事件的 100 人中，只有干预组中的 70 人发生事件。”这是 HR 的有效简化吗？还是还有其他非技术性的解释？]]></description>
      <guid>https://stats.stackexchange.com/questions/649029/how-to-explain-hazard-ratio-in-laypersons-terms</guid>
      <pubDate>Tue, 11 Jun 2024 11:46:22 GMT</pubDate>
    </item>
    <item>
      <title>对于临床研究，我应该添加或更改哪些统计分析方法[关闭]</title>
      <link>https://stats.stackexchange.com/questions/642929/for-a-clinical-study-what-statistical-analysis-methods-should-i-add-or-change</link>
      <description><![CDATA[“我正在对一项临床研究进行统计分析，其中因变量是二元的（是否发生心肌梗塞）。作为一名新手，我最初学习了具体的统计分析。但是，我有兴趣加入新方法或替换现有方法，以潜在地增强或区分我的结果与以前的分析。我应该考虑添加或更改哪些其他统计方法？”]]></description>
      <guid>https://stats.stackexchange.com/questions/642929/for-a-clinical-study-what-statistical-analysis-methods-should-i-add-or-change</guid>
      <pubDate>Tue, 19 Mar 2024 08:50:26 GMT</pubDate>
    </item>
    </channel>
</rss>