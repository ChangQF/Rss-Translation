<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 28 Jul 2024 15:14:56 GMT</lastBuildDate>
    <item>
      <title>如何从数据中生成有偏随机游动？</title>
      <link>https://stats.stackexchange.com/questions/651896/how-to-generate-biased-random-walks-from-data</link>
      <description><![CDATA[假设我有以下类型的数据（作为列表的列表），其中我正在跟踪特定对象质心随时间的位置（彼此独立，因此初始位置并不重要）

我想使用此示例找到一种生成类似于此分布的随机路径的方法（例如，从更高的 x 值开始）。最好的方法是什么？这几乎就像有偏随机游走。
最初，我尝试通过将高斯分布拟合到连续位置之间的步骤来模拟质心的运动。这涉及计算平均步长和 x 和 y 方向的变化，从而捕捉典型的运动模式。通过这样做，我可以从初始位置开始，从拟合的高斯分布中迭代采样步骤，从而生成新的质心路径，确保这些新路径在统计上与原始数据中观察到的运动相似。但是，我还没有达到我需要的效果

有什么想法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651896/how-to-generate-biased-random-walks-from-data</guid>
      <pubDate>Sun, 28 Jul 2024 14:34:54 GMT</pubDate>
    </item>
    <item>
      <title>针对特定患者亚组进行 MatchIt 后的总结和情节</title>
      <link>https://stats.stackexchange.com/questions/651894/summary-and-plot-after-matchit-for-specific-patient-subgroup</link>
      <description><![CDATA[我使用 Matchit::matchit() 在数据集上实现 1 对 1 倾向得分匹配，并使用 cobalt::love.plot 显示调整前后数据集的协变量平衡。
是否可以计算并绘制数据集子集的协变量平衡。这个想法是为了表明协变量平衡不仅在整个数据集中都很好，而且对于数据的关键子集也是如此。
下面是我正在尝试做的以及我尝试过的一个例子。
library(cobalt)
library(Matchit)
data(&quot;lalonde&quot;, package = &quot;cobalt&quot;)

m.out1 &lt;- matchit(
treat ~ age + educ + race + marriage + nodegree + re74 + re75, 
data = lalonde,
method = &quot;nearest&quot;, 
distance = &quot;glm&quot;
) 
love.plot(m.out1) # 所有样本的协变量平衡
love.plot(m.out1, data = lalonde[1:10,]) # 样本子组的协变量平衡（不起作用）
]]></description>
      <guid>https://stats.stackexchange.com/questions/651894/summary-and-plot-after-matchit-for-specific-patient-subgroup</guid>
      <pubDate>Sun, 28 Jul 2024 14:14:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么HDBCSAN的性能比DBSCAN差？</title>
      <link>https://stats.stackexchange.com/questions/651893/why-hdbcsan-performs-worse-than-dbscan</link>
      <description><![CDATA[我正在开发一个主题建模系统，该系统涉及对 L2 规范化 TF-IDF 嵌入进行聚类。
对于 DBSCAN，调整后的随机数指数平均为 70%-90%（在 eps 从 0 循环到 1 以找到最佳值之后，并且我从领域知识中知道 min_samples = 2）
对于 HDBSCAN，调整后的随机数指数平均为 10%-30%（在 min_cluster_size 上循环之后，结果再次为 2）
对于 DBSCAN 和 HDBSCAN，我都使用欧几里得距离作为距离度量（与余弦相似度等其他度量相比，它效果最好）
我甚至尝试对 TF-IDF 嵌入进行降维（PCA），以尝试减少数据中的噪声，但它只提高了计算速度，而 HDBSCAN 的聚类性能仍然是相同。
在 DBSCAN 和 HDBSCAN 中，噪声点 &gt; 50%。这很奇怪，因为 HDBSCAN 在设计上应该容易受到噪声的影响。
我真的很困惑，因为 HDBSCAN 应该是 DBCSAN 的更通用版本，所以它应该在聚类中给我相同或更好的性能，对吗？

我知道 DBCSAN 更适合包含具有恒定密度的簇的数据，而 HDBSCAN 可以处理具有不同密度的簇，但恒定密度不是变化密度的特殊情况吗？所以它应该能够处理这个问题？

首先使用 HDBSCAN 的前提是避免手动选择 eps，因为万一向系统提供未标记的数据，它仍然应该能够找到最佳 eps（无需使用调整后的 rand 索引）
我尝试找到最佳 eps：

我最初的想法是使用与具有最高值的轮廓分数相对应的 eps，但结果很糟糕，因为轮廓分数假设簇是球形的，这并不总是正确的，并且轮廓分数甚至与调整后的 rand 索引不一致。我需要一个内部验证措施，当调整后的 rand 指数增加时，该内部验证措施也会针对每个 eps 值增加。

我正在考虑做什么：

在 KNN 图中找到肘部并将该值用作 eps，但我需要找到某种方法来自动找到它而无需查看图表（如果可能）

使用 OPTICS，我怀疑它不会比 HDBSCAN 更好。

使用平均距离作为 eps 的估计值？

]]></description>
      <guid>https://stats.stackexchange.com/questions/651893/why-hdbcsan-performs-worse-than-dbscan</guid>
      <pubDate>Sun, 28 Jul 2024 12:30:20 GMT</pubDate>
    </item>
    <item>
      <title>如何获得比值比的 95％ 置信区间？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651891/how-can-i-get-95-confidence-intervals-for-odds-ratios</link>
      <description><![CDATA[我已经使用 R 中的 glmer 拟合了一个随机截距逻辑模型。
假设我得到了变量 x 的某个估计 beta。
然后我可以预测感兴趣事件的 *ODDS 对于几个 x 值，保持其他协变量不变。
这是通过“预测”命令完成的。
我想获得这些 *ODDS 与变量 x 平均值的几率之间的几率比。
这可以通过几个 x 值的预测 *ODDS 与 x 平均值的预测几率之间的比率简单地完成。
问题是，我如何获得这些几率比的置信区间？]]></description>
      <guid>https://stats.stackexchange.com/questions/651891/how-can-i-get-95-confidence-intervals-for-odds-ratios</guid>
      <pubDate>Sun, 28 Jul 2024 12:08:39 GMT</pubDate>
    </item>
    <item>
      <title>寻找潜变量模型的水平曲线</title>
      <link>https://stats.stackexchange.com/questions/651887/finding-level-curves-for-a-latent-variable-model</link>
      <description><![CDATA[我有一个潜在变量模型，它使用两个高斯分布 p(z) 和 p(x|z) 表示 p(x)。p(x|z) 的均值和协方差由使用神经网络的 z 的一些函数表示。
注意：x 和 z 都是二维的。因此函数 p(x) 定义在平面上，其水平曲线将是平面上的曲线。
问题：
我想找到对应于 p(x) = 1 的 p(x) 的水平曲线（轮廓）。
有哪些（有效的）方法可以做到这一点？
到目前为止，我的思考过程：

以某种方式使用 matlab 等内置包中的轮廓查找函数。
从 p(x) 进行某种形式的采样以获得水平曲线。可能的方向：从分布 1 / (1 - p(x)) 中抽样，这将生成接近所需轮廓的高概率样本，然后使用某种方法从采样点近似曲线本身。
]]></description>
      <guid>https://stats.stackexchange.com/questions/651887/finding-level-curves-for-a-latent-variable-model</guid>
      <pubDate>Sun, 28 Jul 2024 10:55:43 GMT</pubDate>
    </item>
    <item>
      <title>Beta分布损失函数</title>
      <link>https://stats.stackexchange.com/questions/651886/beta-distribution-loss-function</link>
      <description><![CDATA[我正在尝试建立一个模型来预测两个数字的比率。该比率的分布采用 beta 分布的形式，介于 0 和 1 之间。到目前为止，我一直在 XGBoost 中使用不同的现有损失函数，但没有成功。我解决这个问题的唯一想法是：

创建我自己的可以模拟 beta 分布的损失函数。但是我不知道如何实现这一点 - 我是否需要根据均值重新参数化 beta 分布的负对数似然？
我不一定非要使用 XGBoost。我愿意尝试其他可以更好地解决这个问题的软件包（GLM 等）。

有什么建议吗？提前谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/651886/beta-distribution-loss-function</guid>
      <pubDate>Sun, 28 Jul 2024 10:40:58 GMT</pubDate>
    </item>
    <item>
      <title>不使用 RMarkdown 从 {netmeta} 创建结果表摘要</title>
      <link>https://stats.stackexchange.com/questions/651884/creating-a-summary-of-results-table-from-netmeta-without-using-rmarkdown</link>
      <description><![CDATA[我花了几个小时尝试创建一个漂亮的汇总表，我可以将其复制并粘贴到 Word 文档中，但失败了。我正在使用 netmeta 包来建模网络元分析。我尝试使用 RMarkdown、stargazer、modelsummary、xtable、gt，但似乎无法做到，也不知道我哪里做错了。
当我尝试 RMarkdown 时，我在渲染窗口中收到以下错误：
C:\Users\estua\AppData\Roaming\TinyTeX\texmf-dist\scripts\texlive\tlmgr.pl：也许应该更改存储库设置。
C:\Users\estua\AppData\Roaming\TinyTeX\texmf-dist\scripts\texlive\tlmgr.pl：更多信息：https://tug.org/texlive/acquire.html
! LaTeX 错误：未找到文件“multirow.sty”。

! 紧急停止。
&lt;read *&gt; 

错误：LaTeX 无法编译 RMarkdown.tex。请参阅 https://yihui.org/tinytex/r/#debugging 了解调试提示。请参阅 RMarkdown.log 了解更多信息。
执行暂停

当我创建一个数据框来尝试使用上述包时，它只会在表格中输出原始数据，而不是下面这些我正在寻找的摘要结果：
成对比较的数量：m = 32
治疗数量：n = 7
设计数量：d = 10

随机效应模型

治疗估计（sm = &#39;MD&#39;，比较：其他治疗与&#39;无&#39;）：
MD 95%-CI z p 值 95%-PI
ALA 1.8033 [-0.6348; 4.2414] 1.45 0.1472 [-3.8517; 7.4583]
DHAEPA 1.8189 [-2.7954; 6.4332] 0.77 0.4398 [-5.2774; 8.9152] EA 1.3625 [-3.2319； 5.9569] 0.58 0.5611 [-5.7184; 8.4433] LA 0.8687 [-1.6083； 3.3457] 0.69 0.4919 [-4.8065; 6.5439] 单不饱和脂肪酸 0.4155 [-3.7984; 4.6293] 0.19 0.8468 [-6.3760; 7.2069]无。                 。    。       。                  。
SFA 1.4090 [-1.4802； 4.2982] 0.96 0.3392 [-4.4950; 7.3130]

量化异质性/不一致性：
tau^2 = 5.4044; tau = 2.3247; I^2 = 85.7% [78.2%; 90.6%]

异质性（设计内）和不一致性（设计间）检验：
Q d.f. p 值
总计 104.62 15 &lt; 0.0001
设计内 13.80 4 0.0080
设计间 90.82 11 &lt; 0.0001
]]></description>
      <guid>https://stats.stackexchange.com/questions/651884/creating-a-summary-of-results-table-from-netmeta-without-using-rmarkdown</guid>
      <pubDate>Sun, 28 Jul 2024 10:09:08 GMT</pubDate>
    </item>
    <item>
      <title>具有随机效应的 Firth 逻辑回归[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651882/firth-logistic-regression-with-random-effects</link>
      <description><![CDATA[有没有办法在引入随机效应的同时实现 Firth 的逻辑回归？]]></description>
      <guid>https://stats.stackexchange.com/questions/651882/firth-logistic-regression-with-random-effects</guid>
      <pubDate>Sun, 28 Jul 2024 08:00:20 GMT</pubDate>
    </item>
    <item>
      <title>多重 t 检验分析或个体 t 检验</title>
      <link>https://stats.stackexchange.com/questions/651872/multiple-t-test-analysis-or-indidivual-t-tests</link>
      <description><![CDATA[我必须使用 t 检验来分析样本。我不确定我是否应该将样本视为单个 t 检验或多个 t 检验。以下是详细信息：
我有一个实验，我分析了 30 种不同代谢物在 24 和 48 小时内的浓度。因此，我想知道每种代谢物在 24 小时和 48 小时之间是否存在显着差异。我对了解代谢物是否彼此不同并不感兴趣。我考虑运行 30 个单独的 t 检验（对每个代谢物进行一次 t 检验，评估 24 和 48 小时），但我不确定这是否可以，或者我是否应该考虑所有 30 种代谢物运行多个 t 检验。如果需要多个，有人可以告诉我原因吗？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/651872/multiple-t-test-analysis-or-indidivual-t-tests</guid>
      <pubDate>Sat, 27 Jul 2024 21:05:22 GMT</pubDate>
    </item>
    <item>
      <title>在 APA 格式的句子中，下列哪项是正确的：零还是 0？一还是 1？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651868/which-is-correct-for-writing-statstics-in-a-sentence-in-apa-style-zero-or-0-on</link>
      <description><![CDATA[示例：

如果两家公司位于同一国家，则指示变量等于一，否则等于零。

或者：

如果两家公司位于同一国家，则指示变量等于1，否则等于0。
]]></description>
      <guid>https://stats.stackexchange.com/questions/651868/which-is-correct-for-writing-statstics-in-a-sentence-in-apa-style-zero-or-0-on</guid>
      <pubDate>Sat, 27 Jul 2024 18:22:37 GMT</pubDate>
    </item>
    <item>
      <title>概率分布之间的距离</title>
      <link>https://stats.stackexchange.com/questions/651853/distance-between-probability-distributions</link>
      <description><![CDATA[我试图理解概率分布之间的三种距离之间的差异，例如它们的优点和缺点是什么，它们强调什么和不强调什么，本质上从实际的角度来看：何时使用这一个而不是另一个，它很容易用数字计算/估计，等等。在这里我只对绝对连续的一维概率分布感兴趣。给定两个这样的概率分布 $P$ 和 $Q$，我感兴趣的三个距离是：

总变异距离 (TVD)：
$$
\mathsf{TVD}(P,Q)=\int_\mathbb{R}\big|p(x)-q(x)\big|\,\mathrm{d}x,
$$
其中 $p$ 是与 $P$ 相关的概率密度函数 (PDF)，而 $q$ 是与 $Q$ 相关的概率密度函数。
 Wasserstein-1 距离：
$$
\mathsf{W}_1(P,Q)=\int_0^1\big|F^{-1}(q)-G^{-1}(q)\big|\,\mathrm{d}q=\int_\mathbb{R}\big|F(x)-G(x)\big|\,\mathrm{d}x,
$$
其中 $F$ 是与 $P$ 相关的累积概率函数 (CDF)，而 $G$ 是与 $Q$ 相关的累积概率函数。
最大均值差 (MMD) 距离，其函数类被视为希尔伯特空间$\mathcal{H}$的单位球:
$$
\textsf{MMD}_\varphi(P,Q)=\big\|\mathbb{E}_{X\sim P}[\varphi(X)]-\mathbb{E}_{Y\sim Q}[\varphi(Y)]\big\|_\mathcal{H},
$$
其中$\varphi:\mathbb{R}\to\mathcal{H}$。在这篇文章中，我主要感兴趣的是 $\varphi$ 与高斯核的关系：
$$
\big\langle\varphi(x),\varphi(y)\big\rangle_\mathcal{H}=k(x,y)=\exp\left(-\frac{1}{2\sigma^2}|x-y|^2\right).
$$

我感兴趣的是这些距离之间的差异。例如，在我看来：

$\mathsf{W}_1$ 比较了分布中分位数或质量分配的差异（注意：我知道 $\mathsf{W}_1$ 的最佳传输解释，而 $\mathsf{TVD}$ 比较了质量，但在“原子级”上，因为它涉及 PDF，所以它会“更紧密”，
上面的 $\textsf{MMD}_\varphi$ 的特定实例将比较两个分布之间的所有矩，如果我们从弥散、偏度和峰度的角度考虑，那么就会强调&quot; 分布的几何形状&quot;。
在数值方面，假设 $P$ 和 $Q$ 未知，如果我得到 $P$ 和 $Q$ 的样本，那么对于 $\mathsf{TVD}$，我必须估计 PDF 并近似积分。对于 $\mathsf{W}_1$ 也是如此：需要估计 CDF 并近似积分。但是，对于 $\textsf{MMD}_\varphi$，使用核技巧很容易获得 &quot; 插件&quot;距离的估计量。

在统计/数据科学/机器学习中，哪些用例会使用一种距离而不是其他距离，为什么？有人有简单的例子可以解释这三种距离之间的差异吗？谢谢帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/651853/distance-between-probability-distributions</guid>
      <pubDate>Sat, 27 Jul 2024 06:57:39 GMT</pubDate>
    </item>
    <item>
      <title>如何使用特定人的语音样本并以任何语音作为输入实现语音转换？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651825/how-to-achieve-voice-conversion-using-voice-samples-of-a-specific-person-using-a</link>
      <description><![CDATA[我正在做一个涉及语音转换的项目，旨在将声音转换为听起来像讲 Darija（摩洛哥阿拉伯方言）的特定人的声音。我从目标人物那里收集了一组语音样本，并将它们准备在一个包含 WAV 音频文件的文件夹中。我想要一个将任何声音转换为这种特定声音的模型。是否有任何模型可以完成这项任务？]]></description>
      <guid>https://stats.stackexchange.com/questions/651825/how-to-achieve-voice-conversion-using-voice-samples-of-a-specific-person-using-a</guid>
      <pubDate>Fri, 26 Jul 2024 18:17:02 GMT</pubDate>
    </item>
    <item>
      <title>重复嵌套交叉验证的标准误差</title>
      <link>https://stats.stackexchange.com/questions/651813/standard-error-of-repeated-nested-cross-validation</link>
      <description><![CDATA[是否有与模型无关的公式来计算 K 倍交叉验证、嵌套交叉验证或重复嵌套交叉验证预测结果的标准误差？
我刚刚偶然发现了这篇文章 ht tps://stackoverflow.com/questions/34914229/which-standard-deviation-of-the-cross-validation-score#:~:text=The%20standard%20deviation%20is%20a,the%20scores%20for%20k%20folds.&amp;text=(These%20ranges%20are%20called%20confidence%20intervals.)
上面写着“K folds 的标准差 / sqrt(K) 是分数的标准误差”，但我真的找不到关于此的其他参考资料。
如果有一个通用且有效的公式（或至少是近似值），那么知道这一点会很方便，因为这将允许例如从多个插补中获得不确定性估计。
问候
Ole]]></description>
      <guid>https://stats.stackexchange.com/questions/651813/standard-error-of-repeated-nested-cross-validation</guid>
      <pubDate>Fri, 26 Jul 2024 14:18:17 GMT</pubDate>
    </item>
    <item>
      <title>在对 betadisper 进行显著的方差分析后，使用 Permutest 或 TukeyHSD 进行分组比较？</title>
      <link>https://stats.stackexchange.com/questions/651794/permutest-or-tukeyhsd-for-group-wise-comparison-after-significant-anova-of-betad</link>
      <description><![CDATA[我想使用我的蜘蛛群落数据执行 PERMANOVA，这些数据是在不同的林分中采样的。在应用 PERMANOVA 之前，我想找出各组之间的分散度是否存在差异。
为此，我使用了 betadisper
dispersion_stands_trap &lt;- 
betadisper(all_dist_trap, 
meta_distance_trap$stand)

这将返回一个重要的输出
&gt; anova(dispersion_stands_trap)
方差分析表

响应：距离
Df 总和 平方均值 平方 F 值 Pr(&gt;F) 
组 4 0.2124 0.053107 2.4785 0.04653 *
残差 149 3.1927 0.021427 
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

为了正确解释我的数据，我想知道哪些组的分散性完全不同。
我读到我可以使用 TukeyHSD 或 permutest 进行成对比较。
permutest(dispersion_stands_trap, 
pairwise=TRUE)

返回以下内容：
成对比较：
（对角线下方观察到的 p 值，对角线上方置换的 p 值）
D DB B FB F
D 0.1450000 0.0980000 0.0030000 0.399
DB 0.1502930 0.8250000 0.1040000 0.558
B 0.0987879 0.8288240 0.1640000 0.425
FB 0.0035463 0.1172937 0.1621860 0.026
F 0.3962535 0.5326374 0.3977593 0.0291775

但是当我使用
TukeyHSD(dispersion_stands_trap)

显著性比较会发生变化（显著性效应丧失F-FB):
 Tukey 均值多重比较
95% 家族置信水平

拟合：aov（公式 = 距离 ~ 组，数据 = df）

$group
diff lwr upr p adj
DB-D 0.060699868 -0.042825680 0.16422542 0.4875989
B-D 0.068575786 -0.036690784 0.17384236 0.3780614
FB-D 0.112144505 0.009417572 0.21487144 0.0248321
F-D 0.036470261 -0.066256672 0.13919719 0.8637376
B-DB 0.007875918 -0.096552782 0.11230462 0.9995769
FB-DB 0.051444637 -0.050423540 0.15331281 0.6321060
F-DB -0.024229607 -0.126097784 0.07763857 0.9651200
FB-B 0.043568719 -0.060068327 0.14720576 0.7735077
F-B -0.032105525 -0.135742571 0.07153152 0.9124905
F-FB -0.075674244 -0.176730709 0.02538222 0.2395908


这让我想到我应该依赖这两个测试中的哪一个？
我的设计有点不平衡
D 30，
DB 31，
B 29，
FB 32，
F 32
这会有问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/651794/permutest-or-tukeyhsd-for-group-wise-comparison-after-significant-anova-of-betad</guid>
      <pubDate>Fri, 26 Jul 2024 08:29:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么不使用FFT和使用FFT的自相关计算会给出不同的结果？</title>
      <link>https://stats.stackexchange.com/questions/651749/why-are-the-autocorrelation-computations-without-fft-and-with-fft-giving-differe</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/651749/why-are-the-autocorrelation-computations-without-fft-and-with-fft-giving-differe</guid>
      <pubDate>Thu, 25 Jul 2024 14:36:20 GMT</pubDate>
    </item>
    </channel>
</rss>