<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Wed, 07 Aug 2024 18:20:22 GMT</lastBuildDate>
    <item>
      <title>关于“假设 $Z_i$ 是 i.i.d. $N(0, 1).$ 且令 $M_n = \max\{Z_1, \ldots, Z_n\}$，证明 $P(M_n > t) \leq n(1 - \Phi(t))$”</title>
      <link>https://stats.stackexchange.com/questions/652454/about-suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n</link>
      <description><![CDATA[关于 https://stats.stackexchange.com/users/395275/lisa-w 的问题
假设 $Z_i$ 是 i.i.d。 $N(0, 1).$ 令 $M_n = \max\{Z_1, \ldots, Z_n\}$，表明 $P(M_n &gt; t) \leq n(1 - \Phi(t))$

我注意到独立性没有被使用。我记得通常当你有 $\max &gt; t$ 时，你通常会将概率更改为“1 减”，如 $P(\max &gt; t) = 1-P(\max \le t)$，然后使用独立性。对于 $\min &lt; t$ 也类似。我很惊讶，我没有看到这个。

https://stats.stackexchange.com/users/79698/jimb 给出了一个提示“第一步是显示 $P(M_n &gt; t)=1−(\Phi(t))^n$&#39;

好吧，我注意到 $1 - (\Phi(t))^n \le n(1-(\Phi(t))^n)$ 为真，因为 $1+x+x^2+...+x^{n-1} = \frac{1-x^n}{1-x} \le n$ 因为每当 $0 &lt; x &lt; $1+x+x^2+...+x^{n-1} \le \sum_{i=1}^{n} 1 \le n$ 1$ 所以...


$$P(M_n &gt; t)$$
$$= 1 - P(M_n \le t) \ \text{1 减 1 真好}$$
$$= 1 - P(Z_1, ..., Z_n \le t)$$
$$= 1 - P(\bigcap_{i=1}^{n} \{ Z_i \le t \})​​$$
$$= 1 - \prod_{i=1}^{n} P(\{ Z_i \le t \})​​ \ \text{独立！}$$
$$= 1 - \prod_{i=1}^{n} \Phi(t) \ \text{相同分布}$$
$$= 1 - (\Phi(t))^n \le n(1-(\Phi(t))^n)$$
问题：既然显然有更短的路径，那发生了什么？
猜测：讲师没有意识到有更短的路径？或者也许只是为了展示 $1 - (\Phi(t))^n \le n(1-(\Phi(t))^n)$ 的另一种证明，我们通过以两种不同的方式查看 $P(M_n &gt; t)$ 来做什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/652454/about-suppose-z-i-are-i-i-d-n0-1-and-let-m-n-max-z-1-ldots-z-n</guid>
      <pubDate>Wed, 07 Aug 2024 16:50:12 GMT</pubDate>
    </item>
    <item>
      <title>两组点之间的最大相关匹配正在形成团块</title>
      <link>https://stats.stackexchange.com/questions/652452/maximum-correlation-matching-between-2-sets-of-points-is-creating-clumps</link>
      <description><![CDATA[我在这里描述的是映射两组点的问题，这个问题困扰了我一段时间。任何意见都将不胜感激！
任务：
我有两组点存在于多变量特征空间中，我想通过识别两组点之间的相似点对，将这两组点映射到彼此上。
方法：
由于特征向量的“方向”比各个特征的实际值更具信息量，我将两点之间的相似性定义为它们的特征向量之间的相关性。由此，自然的（方向性）映射是将一组中的每个点分配给另一组中与其最相关的点。
直觉和问题：
我认为这个过程会给我一个大约 1:1 的映射，因为我希望每个点在另一组中都有一个明确的最近邻居。然而，我注意到，这个过程会在最终集合中产生团块/吸收点，从而收集大量源自起始集合的连接。在运行几次模拟后，我注意到这种聚集效应并不是我的数据独有的属性，而是在某种程度上在更常见的分布中出现。
问题：
我很难对这种现象出现的原因形成直觉；我也对更正式的演示感兴趣。我觉得应该对此效果进行简单的统计解释。

一个 R 模拟来说明此效果
set.seed(7)

getMaxMatch &lt;- function(mat, margin=c(&quot;row&quot;, &quot;column&quot;)){
margin &lt;- ifelse(margin==&quot;row&quot;, 1, 2)
return(apply(mat, margin, which.max))
}
printClumping &lt;- function(n, n_tot){
sprintf(&quot;匹配使用了另一组中可用点的 %s/%s (%s%%)。&quot;, n, n_tot, round(n/n_tot, 3)*100)
}

n_obs &lt;- 1000
n_feats &lt;- 200

# 2 个集合，其中每个特征和每个点都是 iid
x &lt;- matrix(runif(n_obs*n_feats), ncol = n_feats)
y &lt;- matrix(runif(n_obs*n_feats), ncol = n_feats)

# 每对点之间的成对相关性
pw_obsCorr &lt;- cor(t(x), t(y), method = &quot;pearson&quot;)

# 两个方向上的最大相关性映射 x -&gt; y 和 x &lt;- y
x_match &lt;- getMaxMatch(pw_obsCorr, &quot;row&quot;)
y_match &lt;- getMaxMatch(pw_obsCorr, &quot;column&quot;)

printClumping(length(unique(x_match)), n_obs)
# &quot;匹配使用了另一组中可用点的 619/1000 (61.9%)。&quot;
printClumping(length(unique(y_match)), n_obs)
# &quot;匹配使用了另一组中可用点的 621/1000 (62.1%)。&quot;

我仍然可以观察到上述模拟中约 62% 的聚集，方法是用其他常见分布（例如泊松、正态……）代替均匀分布，并使用 Spearman 而不是 Pearson 相关性。显然，当一组变得比另一组大时，这种聚集统计数据会受到影响，但有趣的是，它对特征数量和此模拟中的点数不敏感。

我在这里描述了一个我在处理真实数据时遇到的问题，但提供了一个简化的示例，我相信它说明了同样的效果。在我的实际用例中，我处理的是基因表达数据，其中每个观察值代表一个细胞，该细胞本身属于某些潜在亚群，每个特征代表嘈杂的基因计数，每个基因计数都遵循自己的分布并依赖于细胞亚群。
最后，对这种匹配的分析表明，尽管存在这种意外特性，但所创建的连接仍然有意义（例如，它确实将来自同一群体的细胞映射到不同集合中），但它对于下游应用来说是不切实际的，并且会产生非常粗粒度的匹配。我找到了一种使用加权二分图匹配程序的解决方法，但我很想了解更多有关此处描述的效果的信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/652452/maximum-correlation-matching-between-2-sets-of-points-is-creating-clumps</guid>
      <pubDate>Wed, 07 Aug 2024 15:47:40 GMT</pubDate>
    </item>
    <item>
      <title>依赖于另一个时间序列的时间序列的均值回归</title>
      <link>https://stats.stackexchange.com/questions/652451/mean-reversion-of-a-time-series-dependent-on-another-time-series</link>
      <description><![CDATA[我正在查看一个时间序列 $x_t$，该序列被认为依赖于另一个时间序列 $p_t$。
我想建立一个过程，在其中随机模拟 $p_t$ 并从模拟中确定 $x_t$。
为了提供背景信息，假设 $p_t$ 是“小部件”的价格，而 $x_t$ 是“精美小部件”的价格。“精美”意味着 $x_t &gt; p_t$ 或者 $x_t = p_t + \delta_t$ 其中 $\delta_t &gt; 0$。
一般理解是，随着 $p_t$ 的增加，$\delta_t$ 将减少，但随着价格稳定，$\delta_t$ 将恢复到其长期平均水平。或者，随着 $p_t$ 的减少，$delta_t$ 将在短期内增加，但随后会恢复。
使用以下内容作为资源：
http://marcoagd.usuarios.rdc.puc-rio.br/revers.html ，我发现我可以估计单个变量的 AR(1) 过程的参数：
$\delta_t - \delta_{t-1} = a + b\delta_{t-1} + \epsilon_t$
并回归以找到参数$a$ 和 $b$。
如果我希望将 $p_t$ 纳入模型，我可以使用
$\delta_t - \delta_{t-1} = a + b\delta_{t-1} + cp_{t-1} + \epsilon_t$
其中 $c$ 是 $p_t$ 对 $\delta_t$ 的影响？
抱歉，这个问题问得不好。我缺乏适当的行话来简洁地提出这个问题。我尝试搜索“协整均值回归”，但一无所获。]]></description>
      <guid>https://stats.stackexchange.com/questions/652451/mean-reversion-of-a-time-series-dependent-on-another-time-series</guid>
      <pubDate>Wed, 07 Aug 2024 15:09:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的分类模型中的最佳阈值会产生意外结果？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/652450/why-is-the-optimal-threshold-in-my-classification-model-yielding-unexpected-resu</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/652450/why-is-the-optimal-threshold-in-my-classification-model-yielding-unexpected-resu</guid>
      <pubDate>Wed, 07 Aug 2024 15:01:22 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用混合逻辑分析 DCE</title>
      <link>https://stats.stackexchange.com/questions/652448/analysing-dce-with-mixed-logit-in-r</link>
      <description><![CDATA[我正在通过调查进行离散选择实验 (DCE)。我的研究基于具有不同属性级别/类型的护肤产品。总共有四个属性（每个属性有 3 个级别/类型），我生成了 81 种不同的产品。我将它们分成 3 个不同的调查（每个调查有 9 个选择集，每个选择集有 3 种产品可供选择，受访者只能选择其中一种）。此外，他们还回答了有关他们的人口统计和对某些品牌（我在产品设计中使用的品牌）的熟悉程度的问题。这些是协变量（年龄组、收入组、居住地区、对 6 个不同品牌的使用熟悉程度）。
我以长格式扩展了数据（总共 2430 行，因为每个受访者考虑了超过 27 种具有不同属性级别的产品，总共有 90 名受访者）。我使用这段代码放入 mlogit 模型中：
expanded_data &lt;- expand_data %&gt;%
mutate(
Age = as.factor(Age),
Income = as.factor(Income),
Region = as.factor(Region),
CeraVe = as.factor(CeraVe),
Maybelline = as.factor(Maybelline),
LOreal = as.factor(LOreal),
LaMer = as.factor(LaMer),
Chanel = as.factor(Chanel),
Dior = as.factor(Dior),
Price = as.factor(Price),
Packaging = as.factor(Packaging),
Quality = as.factor(Quality),
Brand = as.factor(Brand),
ProductChoiceBinary = as.logical(ProductChoiceBinary)
)
mlogit_data &lt;- mlogit.data(expanded_data,
choice = &quot;ProductChoiceBinary&quot;,
shape = &quot;long&quot;,
id.var = &quot;UniqueChoiceID&quot;,
alt.var = &quot;ProductID&quot;)
complex_model &lt;- mlogit(ProductChoiceBinary ~ Price + Packaging + Quality + Brand | Age + Income + Region + CeraVe + Maybelline + LOreal + LaMer + Chanel + Dior,
data = mlogit_data,
random = ~ Price + Packaging + Quality + Brand | UniqueChoiceID)
但是这个错误一直出现：“solve.default(H, g[!fixed]) 中的错误：Lapack 例程 dgesv：系统完全是奇异的：U[1,1] = 0&quot;
我已经检查过没有多重共线性，这可能是数据结构的问题。但是，我的时间不多了，我真的需要结果。有人知道哪里出了问题，我该怎么办？
我不确定如何在此处上传我的结构图像。我的数据结构为 2430 行和 19 列（RespondentID、问题、产品、年龄、地区、收入、CeraVe、Maybelline、LOreal、LaMer、Chanel、Dior、ProductChoice、价格、包装、质量、品牌、ProductChoiceBinary、UniqueChoiceID）。]]></description>
      <guid>https://stats.stackexchange.com/questions/652448/analysing-dce-with-mixed-logit-in-r</guid>
      <pubDate>Wed, 07 Aug 2024 14:52:46 GMT</pubDate>
    </item>
    <item>
      <title>Surpyval Weibull 拟合优度</title>
      <link>https://stats.stackexchange.com/questions/652447/surpyval-weibull-goodness-of-fit</link>
      <description><![CDATA[我一直在使用 surpyval 将一些校准数据拟合到威布尔分布。我想评估拟合优度，但我不知道该怎么做。我以前使用过“可靠性”库，它有一个 KS 检验，但我不知道如何在 Surpyval 中执行此操作（可靠性不支持区间删失数据）。代码：
import surpyval as surv
import matplotlib.pyplot as plt
#sample data
Fail = [1,1,3,1,5,1,1,2,1,1,1,1,1]
Type = [1,1,1,2,1,1,2,1,1,2,1,2,1,2,1]
Time = [1820,1987,2176,[2373.0, 2542.0],2373,2731,[2920.0, 3093.0],2920,3279,[3472.0, 3641.0],3472,[3829.0, 4009.0],3829]

model = surv.Weibull.fit(x = Time, c =类型，n = 失败)
model.plot()
plt.show()

libraries:
matplotlib 3.6.0
numpy 1.26.0
scipy 1.14.0
surpyval 0.10.10

包含完整数据集的图。
我的完整数据集有左、右和区间数据。任何其他拟合优度方法/知识都会非常有帮助，并且包括对图像的任何见解。
]]></description>
      <guid>https://stats.stackexchange.com/questions/652447/surpyval-weibull-goodness-of-fit</guid>
      <pubDate>Wed, 07 Aug 2024 14:49:15 GMT</pubDate>
    </item>
    <item>
      <title>TTA（测试时间增强）是否与贝叶斯 DL 有某种联系？</title>
      <link>https://stats.stackexchange.com/questions/652445/is-tta-test-time-augmentation-somehow-related-to-bayesian-dl</link>
      <description><![CDATA[如果可能的话，我正在尝试为深度学习模型构建一个 UQ 方法分类法（这篇论文在我看来提供了一个很好的概述，尽管是在特定领域）。
目前有一组 UQ 方法，我将其命名为“采样”，它们都在推理过程中运行多个前向传递（贝叶斯 DL、TTA、MC dropout、集成）。据我所知，MC drop-out 被认为（至少被一些人认为）是贝叶斯 DL 的近似值，也与模型集成有些相关。我想问的是，测试时增强（TTA）如何适应这种情况？贝叶斯深度学习试图获得模型参数的分布（而 MC dropout 试图近似该分布），而 TTA 试图对输入值的分布进行采样（具有相同的 y_true）。我可以（大致）声称 TTA 也是一种贝叶斯深度学习方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652445/is-tta-test-time-augmentation-somehow-related-to-bayesian-dl</guid>
      <pubDate>Wed, 07 Aug 2024 14:28:50 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 模型的群体稳定性指数 [重复]</title>
      <link>https://stats.stackexchange.com/questions/652443/population-stability-index-for-xgboost-model</link>
      <description><![CDATA[计算 XGBoost 模型的种群稳定性指数是否有意义？
我将原始值分为 2 到 5 组，并以此方式训练模型。
我认为，如果变量 1 有组 1、组 2 和组 3，一棵树可以进行拆分 &gt;组 2，而另一棵树可以 &gt;**=**组 2。
这样，每棵树都可以对变量 1 进行不同的拆分，并且 PSI 无法完成，否则就没有多大意义了。
这样对吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/652443/population-stability-index-for-xgboost-model</guid>
      <pubDate>Wed, 07 Aug 2024 13:55:48 GMT</pubDate>
    </item>
    <item>
      <title>关于提升方法的阅读材料</title>
      <link>https://stats.stackexchange.com/questions/652442/materials-for-reading-on-boosting-methods</link>
      <description><![CDATA[我正在寻找一些关于 boosting 方法的参考资料（教科书、讲义、幻灯片），这些资料要通俗易懂，而且不是太详细。理想情况下，这些资料应该涵盖以下主题：

AdaBoost
Gradient Goosting
XgBoost
]]></description>
      <guid>https://stats.stackexchange.com/questions/652442/materials-for-reading-on-boosting-methods</guid>
      <pubDate>Wed, 07 Aug 2024 13:49:18 GMT</pubDate>
    </item>
    <item>
      <title>解释变量高度不平衡的回归</title>
      <link>https://stats.stackexchange.com/questions/652440/regression-with-highly-unbalanced-explanatory-variable</link>
      <description><![CDATA[我有一个回归问题，其中一个解释变量是分类变量，有 2 个类别。我的问题是，一个类别有 90% 的观测值，而第二个类别只有 10% 的观测值。
这种高度不平衡的分类变量的存在是否会对模型系数的统计推断造成任何问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/652440/regression-with-highly-unbalanced-explanatory-variable</guid>
      <pubDate>Wed, 07 Aug 2024 13:20:48 GMT</pubDate>
    </item>
    <item>
      <title>测试栖息地之间的群落组成是否存在显著差异？需要 PERMANOVA 样本大小吗？</title>
      <link>https://stats.stackexchange.com/questions/652437/test-for-significant-differences-in-communtiy-composition-between-habitats-requ</link>
      <description><![CDATA[我在 5 个不同的林地中采集了蜘蛛样本。我最初对每种森林类型的样本量为 32，但由于我必须汇总数据，现在每种森林类型只有 8 个样本。
我对蜘蛛数据进行了排序，以评估群落结构的差异（索引：Morisita-Horn）。颜色代表森林类型，三角形和圆圈代表区域。椭圆表示标准偏差。

我想找到一种方法来查看森林类型之间以及区域之间的差异是否具有统计意义。为此，我想使用 Permanova（vegan 包中的 adonis2）。
我首先检查了不同支架之间的分散度是否显著不同：
dispersion_stands &lt;- betadisper(horn_dist, matrix_env_plot$stand, type=&quot;centroid&quot;)
anova(dispersion_stands)

方差分析表

响应：距离
Df 总和平方均值平方 F 值 Pr(&gt;F)
组 4 0.06117 0.015292 1.0219 0.4096
残差 35 0.52376 0.014965 

但事实并非如此。 “region” 也是如此。
然后我继续运行 adonis2 函数：
perma_stands_results &lt;- adonis2(horn_dist~stand, data=matrix_env_plot, permutations=999)

&gt; print(perma_stands_results)
简化模型下对 adonis 进行置换检验
按顺序添加项（从第一个到最后一个）
置换：自由
置换数：999

adonis2(formula = horn_dist ~ stand, data = matrix_env_plot, permutations = 999)
Df SumOfSqs R2 F Pr(&gt;F) 
stand 4 1.8350 0.17689 1.8804 0.027 *
残差 35 8.5387 0.82311 
总计 39 10.3736 1.00000 
---
有效代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
&gt; 

由此可见，不同森林类型之间的群落结构确实存在显著差异。我提取了每对的距离矩阵，并再次应用了 adonis2。
D_DB_test &lt;- adonis2(D_DB_dist ~ stand, data=D_DB)

我还校正了多重检验的 p 值
&gt; p.adjust(pairwise.p, method=&quot;BH&quot;)
D_DB D_B D_FB D_F B_DB B_FB B_F F_DB F_FB 
0.05666667 0.03000000 0.05666667 0.72000000 0.72000000 0.95400000 0.08600000 0.06250000 0.10166667 
DB_FB 
0.86222222

我的问题是：

进行方差分析是否是分析分散差异的全局差异的正确方法？或者我是否首先必须检查方差分析所做的假设是否被违反（同质性方差...）
对每对森林类型运行 Peranova 是否是进行成对比较的有效方法？
每组只有 8 个样本，这是否有问题？
方差分析和 adonis 函数告诉我社区组成存在差异，但我能否得出关于差异强度的结论？

非常感谢，正如您所见，我不是统计专家，非常感谢您的每一个解释！]]></description>
      <guid>https://stats.stackexchange.com/questions/652437/test-for-significant-differences-in-communtiy-composition-between-habitats-requ</guid>
      <pubDate>Wed, 07 Aug 2024 13:00:33 GMT</pubDate>
    </item>
    <item>
      <title>具有给定标准差的样本的分布均值分布</title>
      <link>https://stats.stackexchange.com/questions/652435/distribution-of-the-mean-of-distributions-for-samples-with-a-given-standard-devi</link>
      <description><![CDATA[我有一个正态分布 $N(0, \sigma^2)$。如果我开始从该分布中选择所有分布 $N(\mu, \sigma^2/2)$，则平均值 $\mu$ 的分布参数是什么：$N(0, ?)$？标准差是多少？
换句话说，如果有一组 $N(\mu, \sigma^2/2)$ 分布，它们共同构成 $N(0, \sigma^2)$ 分布，那么 $\mu$ 的分布应该是什么？有两个极值点。如果我选​​择具有相同标准差 $\sigma^2$ 的分布，则会出现这种情况。在这种情况下，$\mu$ 的标准差将趋向于零，n-&gt;inf。如果我从 $N(0, \sigma^2)$ 中选择一个点，那么 $\mu$ 的标准差将等于 $\sigma^2$。]]></description>
      <guid>https://stats.stackexchange.com/questions/652435/distribution-of-the-mean-of-distributions-for-samples-with-a-given-standard-devi</guid>
      <pubDate>Wed, 07 Aug 2024 11:47:55 GMT</pubDate>
    </item>
    <item>
      <title>在精确匹配中丢弃观察结果后，如何解决解释/普遍性方面的潜在问题？</title>
      <link>https://stats.stackexchange.com/questions/652433/how-to-adress-potential-issues-with-interpretation-generalizability-after-discar</link>
      <description><![CDATA[如果观测值没有完全匹配，则将其丢弃，这可能会导致匹配样本中的协变量分布与原始样本不同。
我假设在某种程度的差异下（如果我错了，请纠正我），这种差异会影响对发现的可能解释，例如，ATE 不能再被解释为原始样本的 ATE。发现的有效性将仅限于匹配样本。如果意图是从样本推广到总体，这尤其成问题，因为现在我甚至不能再从匹配样本推广到原始样本，更不用说推广到总体了。
有没有办法判断匹配样本和原始样本是否差异太大？如果是这样，是否有策略来解决这个问题，或者我应该切换到不会丢弃（尽可能多的）观测值的匹配方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/652433/how-to-adress-potential-issues-with-interpretation-generalizability-after-discar</guid>
      <pubDate>Wed, 07 Aug 2024 11:32:17 GMT</pubDate>
    </item>
    <item>
      <title>帮助解释 GLM 交互效应（带偏移的泊松）</title>
      <link>https://stats.stackexchange.com/questions/652431/help-interpreting-glm-interaction-effect-poisson-with-offset</link>
      <description><![CDATA[我使用泊松 glm 和偏移变量对计数变量进行了建模。我正在研究取样年份对“老年人”（&gt; 年龄 x）与年轻人（&lt; 年龄 x）相比执行行为的次数的影响。偏移变量是 ln（观察时间）。我加入了一个交互项，因为我预计老年人类别中的个体比年轻人类别中的个体经历更严重的生物衰老，因此多年来应该表现出更严重的关系。我的模型输出似乎就是这种情况：
固定效应：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) -0.57004 0.10661 -5.347 8.96e-08 ***
Year_Scaled -0.12309 0.07831 -1.572 0.1160 
OldY -0.19841 0.14128 -1.404 0.1602 
Year_Scaled:OldY -0.21954 0.09609 -2.285 0.0223 * 

我想估计交互作用对随时间变化的比率的影响大小。但我该怎么做呢？到目前为止，我已经构建了以下方程来估计每年“老年”个体的比率：
exp(Intercept + YEAR*(Year_Scaled:OldY)) = 该年的比率
我不确定的是，我是否需要在此方程中包含不显著的项？我知道我的交互项的显著性与年轻个体的斜率有关，所以我是否需要调整我的方程来解释这个斜率？例如。
exp(Intercept + YEAR*(Year_Scaled + Year_Scaled:OldY)) = 当年的比率
同样，我是否也需要考虑旧组的截距，即使它并不显著？
exp(Intercept + OLDY + YEAR*(Year_Scaled + Year_Scaled:OldY)) = 当年的比率。
我想我想得太多了，但我需要一些建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/652431/help-interpreting-glm-interaction-effect-poisson-with-offset</guid>
      <pubDate>Wed, 07 Aug 2024 10:29:13 GMT</pubDate>
    </item>
    <item>
      <title>某个因素的主要影响是什么？</title>
      <link>https://stats.stackexchange.com/questions/652428/whats-the-main-effect-for-a-factor</link>
      <description><![CDATA[这是我在这里的第一个问题。补充一点背景信息：我正在研究实验设计，在因子主效应部分遇到了麻烦。我了解到，如果您有 $k$ 个因子，每个因子有 $2$ 个级别，例如0 和 1，重复 $n$ 次，那么因子 $A$ 的主效应为
$$
\delta A = \frac{[A1]-[A0]}{2 n}
$$
其中 $[A1]$ 是 $A=1$ 等情况下的结果总和。
第一个问题，为什么会这样？我的意思是为什么是这样而不是相反？即
$$
\delta A = \frac{[A0]-[A1]}{ 2n}
$$
第二个问题，当一个因子有两个以上的水平时，它的主要影响是什么？
第三个问题，在我的笔记中，我有因子“i”在水平“q”上的主要影响是
$$
\delta_{iq}=m_{iq}-m
$$
其中 $m$ 显然是所有实验的平均值，而 $m_{iq}$ 是因子 $i$ 等于水平 $q$ 的实验的平均值。如果这是真的，那么我不明白为什么第一个是正确的。]]></description>
      <guid>https://stats.stackexchange.com/questions/652428/whats-the-main-effect-for-a-factor</guid>
      <pubDate>Wed, 07 Aug 2024 09:09:59 GMT</pubDate>
    </item>
    </channel>
</rss>