<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 06 Sep 2024 15:17:35 GMT</lastBuildDate>
    <item>
      <title>R 包文档命名空间和说明[关闭]</title>
      <link>https://stats.stackexchange.com/questions/653972/r-package-documentation-namespace-and-description</link>
      <description><![CDATA[早上好，
我正在编写 R 包的初稿，我已经从包 corrplot 中导入了函数 corrplot，并将其添加到 NAMESPACE（使用 roxygen2）。即：
importFrom(corrplot,corrplot)

我不再需要这个函数（我使用 ggplot2），但我无法从 NAMESPACE 文件中删除它。我尝试从DESCRIPTION文件中删除包corrplot（如下所示），但当我重新记录包时，它给了我一个错误并且没有从NAMESPACE中删除该函数。
导入： 
stats,
pracma,
GB2,
acid,
methods,
tidyr,
ggplot2, 
ggcorrplot, 
gridExtra, 
grid, 
corrplot

我也尝试运行devtools::clean_all()但这也不起作用。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653972/r-package-documentation-namespace-and-description</guid>
      <pubDate>Fri, 06 Sep 2024 15:01:33 GMT</pubDate>
    </item>
    <item>
      <title>如何处理 VAR 模型中的高峰度</title>
      <link>https://stats.stackexchange.com/questions/653969/how-to-deal-with-high-kurtosis-in-var-model</link>
      <description><![CDATA[我试图在 Stata 上建立一个 VAR 模型，以找出一些变量（汇率、波动性、贸易开放度、GDP 和入学率）对 FDI 流入的影响。虽然它们中的大多数在 ADF 测试水平上不是平稳的，但它们在微分之后都是平稳的（至少在滞后 0 和 1 时是平稳的：有些在滞后 2 时不是）。
由于它们处于相同的积分阶数，我决定建立一个 VAR 模型，但 R² 太低了（19%）。当我开始进行诊断时：残差没有自相关，模型是稳定的，但这些残差的分布不正常（jarque bera 检验的 p 值为 0.0000，偏度很好，但峰度也是 0.000）
我尝试过使用对数变换（除了 FDI，因为它上面有负数），但这并没有解决问题。那么有没有什么方法可以降低峰度？异方差检验（Breusch–Pagan/Cook–Weisberg 检验）为 0.0599，但我不确定这是否与此有关]]></description>
      <guid>https://stats.stackexchange.com/questions/653969/how-to-deal-with-high-kurtosis-in-var-model</guid>
      <pubDate>Fri, 06 Sep 2024 14:21:13 GMT</pubDate>
    </item>
    <item>
      <title>如何解释独立变量编码实验组的偏相关性？</title>
      <link>https://stats.stackexchange.com/questions/653968/how-to-interpret-a-partial-correlation-where-the-independent-variable-codes-expe</link>
      <description><![CDATA[假设我有 3 个变量：实验组 (A/B)、态度和年龄。我将它们全部放入回归分析中，得到 Y 轴上实验组的偏相关，X 轴上态度的偏相关。我们可以对这张图做出任何解释吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653968/how-to-interpret-a-partial-correlation-where-the-independent-variable-codes-expe</guid>
      <pubDate>Fri, 06 Sep 2024 13:50:38 GMT</pubDate>
    </item>
    <item>
      <title>样本中未观察到任何事件时的患病率上限</title>
      <link>https://stats.stackexchange.com/questions/653965/prevalence-upper-bound-when-no-events-are-observed-in-sample</link>
      <description><![CDATA[在 2000 个观察样本中，未发现阳性病例，但我仍然希望能够提供患病率的上限。
人们似乎使用的一般规则是简单地取 3/n，但这与样本中发现 1 个病例的 95% 上限相同。
3/2000=0.15%，2000 年患病率为 1 例的 95% 上限为 0.15%。
如果观察到 0 个病例，上限肯定应该低于发现 1 个病例的情况？我可以使用其他方法来与其他频率结果在一定置信水平下的上限保持一致吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653965/prevalence-upper-bound-when-no-events-are-observed-in-sample</guid>
      <pubDate>Fri, 06 Sep 2024 12:04:43 GMT</pubDate>
    </item>
    <item>
      <title>我们是否可以将 Mann–Whitney U 检验的零值，即 $P(x_i > y_j) = P(y_j > x_i)$ 解释为等同于 $F = G$（其中 $F$ 和 $G$ 是 ECDF）？</title>
      <link>https://stats.stackexchange.com/questions/653962/can-we-interpret-the-null-of-the-mann-whitney-u-test-i-e-px-i-y-j-py-j</link>
      <description><![CDATA[简介。

让我们考虑一个 $n$ 个观测样本 $\{x_i\} = \{x_1, x_2, \ldots x_n\}$，它们来自总体 $X$，以及一个 $m$ 个观测样本 $\{y_j\} = \{y_1, y_2, \ldots y_m\}$，它们来自总体 $Y$。

让我们考虑 Mann–Whitney $\displaystyle U$ 检验（也称为 Wilcoxon 秩和检验），及其零假设和备择假设：

$H_0$：$P(x_i &gt; y_j) = P(y_j &gt; x_i) = \frac{1}{2}$ $\quad$ $\bigl($
即&quot;$x$ 和 $y$&quot; $\bigl)$
$H_A$: $P(x_i &gt; y_j) \neq P(y_j &gt; x_i)$ $\;$ $\bigl($ 即 &quot;$x$ 将
随机大于/小于 $y$&quot; $\bigl)$


让我们考虑一下 Mann &amp; Whitney (1947) 论文：




简介。设 $x$ 和 $y$ 分别为具有连续累积分布函数 $F$ 和 $G$ 的两个随机变量。
如果对于每个 $a$ 都有 $F(a) &gt; G(a)$，则变量 $x$ 将被称为随机小于 $y$。我们希望检验假设 $F = G$
与备选假设 $x$ 随机小于 $y$ 的对立面。


问题。

我们能否将 $H_0$: $P(x_i &gt; y_j) = P(y_j &gt; x_i) = \frac{1}{2}$ 解释为等同于 $F = G$?
$\bigl($或者， ... class=&quot;math-container&quot;&gt;$H_A$: $P(x_i &gt; y_j) \neq P(y_j &gt; x_i)$ 是否等同于 $F &gt; 或 &lt; G$?$\bigl)$
如果是，则零值 $P(x_i &gt; y_j) = P(y_j &gt; x_i) = \frac{1}{2}$ 将对应于 ECDFs 点位于 p-p 图，因为$F = G$。

]]></description>
      <guid>https://stats.stackexchange.com/questions/653962/can-we-interpret-the-null-of-the-mann-whitney-u-test-i-e-px-i-y-j-py-j</guid>
      <pubDate>Fri, 06 Sep 2024 10:53:17 GMT</pubDate>
    </item>
    <item>
      <title>当仅观察到数据的最大值时，统计量完整且充分</title>
      <link>https://stats.stackexchange.com/questions/653960/complete-and-sufficient-statistic-when-only-the-maximum-of-the-data-is-observed</link>
      <description><![CDATA[
我找到了联合 PDF，但之后无法应用分解。
我该如何解决这个问题？]]></description>
      <guid>https://stats.stackexchange.com/questions/653960/complete-and-sufficient-statistic-when-only-the-maximum-of-the-data-is-observed</guid>
      <pubDate>Fri, 06 Sep 2024 10:05:12 GMT</pubDate>
    </item>
    <item>
      <title>Riley 等人提出的计算样本量的公式存在错误</title>
      <link>https://stats.stackexchange.com/questions/653958/an-error-in-formula-proposed-by-riley-et-al-to-calculate-the-sample-size</link>
      <description><![CDATA[我使用以下函数来查找 cox 比例风险比（由 Riley 等人提出）的最小样本量。令人惊讶的是，估计的事件数量超过了预期的样本量。我想知道您是否知道原因？ 这是由于事件率值过高吗？估计的结果事件为 2131，估计的样本量为 1715。
 library(pmsampsize)
pmsampsize(type = &quot;s&quot;, csrsquared = 0.051, parameters = 10, rate = 0.6, timepoint = 2, meanfup = 2.07)

* s 指生存模型。
* 参数指模型中的参数数量
* 速率指事件发生率
* 平均值指平均随访时间（年）
* 时间点指预测感兴趣的时间点

注意：假设表观和平均值的差异为 0.05，可接受调整后的 R 平方 
NB：假设在时间点 = 2 时估计总体风险的误差幅度为 0.05 
NB：每个预测参数的事件数 (EPP) 假设总体事件率 = 0.6 

样本大小收缩参数 CS_Rsq Max_Rsq Nag_Rsq EPP
标准 1 1715 0.900 10 0.051 0.857 0.06 213.0
标准 2 223 0.543 10 0.051 0.857 0.06 27.7
标准 3 * 1715 0.900 10 0.051 0.857 0.06 213.0
最终 SS 1715 0.900 10 0.051 0.857 0.06 213.0

根据用户输入，新模型开发所需的最小样本量 = 1715，
相当于 3550 人次**的随访，2131 个结果事件
假设总体事件率 = 0.6，因此 EPP = 213
总体风险的 95% CI = (0.683, 0.714)，真实值为 0.699，样本量 n = 1715
其中时间的单位为平均随访时间
]]></description>
      <guid>https://stats.stackexchange.com/questions/653958/an-error-in-formula-proposed-by-riley-et-al-to-calculate-the-sample-size</guid>
      <pubDate>Fri, 06 Sep 2024 09:43:43 GMT</pubDate>
    </item>
    <item>
      <title>哪种分析适合比较重复测量设计中实验阶段之间的互相关系数？</title>
      <link>https://stats.stackexchange.com/questions/653957/which-analysis-is-suitable-for-comparing-cross-correlation-coefficients-between</link>
      <description><![CDATA[我有一个重复测量实验设计，其中有受试者内因子阶段和受试者间因子阶段顺序。我将比较时间序列数据对（针对参与者对），并想检查互相关是否根据实验阶段和阶段顺序而不同。我想知道计划 ANOVA 或 GLMM 或 LMM 是否有意义，或者是否有必要先查看互相关系数的分布，对数据应用变换，然后才得到答案？我希望有人能推荐一篇关于该主题的优秀文献。]]></description>
      <guid>https://stats.stackexchange.com/questions/653957/which-analysis-is-suitable-for-comparing-cross-correlation-coefficients-between</guid>
      <pubDate>Fri, 06 Sep 2024 09:34:58 GMT</pubDate>
    </item>
    <item>
      <title>（高斯） copula 模拟中给定相关参数与经验相关之间的差距</title>
      <link>https://stats.stackexchange.com/questions/653956/gap-between-the-given-correlation-parameter-and-the-empirical-correlation-in-ga</link>
      <description><![CDATA[现在我尝试用我希望的相关矩阵作为初始参数来模拟正常的 copula。我发现经验相关性通常低于输入的初始参数。
为了简化问题，我们考虑一个初始参数为 0.5 的双变量高斯 copula。
我在 R 中创建了以下代码作为说明：
converg_corr_copula &lt;- function(num_sim, n, param){

result &lt;- data.frame(matrix(ncol=2))[-1,]
names(result) &lt;- c(&quot;seed&quot;,&quot;corr_emp&quot;)

for (i in 1:n){

set.seed(i)
cp_gaus &lt;- normalCopula(param = param, dim = 2,dispstr = &quot;un&quot;)
copula_sim &lt;- rCopula(n = num_sim, copula = cp_gaus) %&gt;% as.data.frame()
result[nrow(result)+1,] &lt;- c(i,cor(copula_sim)[2])

}

return(c(mean(result$corr_emp),sd(result$corr_emp)))
}

lapply(c(1e2,1e3,1e4,1e5,1e6,1e7), converg_corr_copula, n = 50, param = 0.5)


从结果中我们可以看出，经验值以 0.48 为中心，标准差随着模拟次数的增加而减小。
[[1]]
[1] 0.48122020 0.06987925

[[2]]
[1] 0.47687772 0.02583187

[[3]]
[1] 0.481539045 0.007837956

[[4]]
[1] 0.48220804 0.00260011

[[5]]
[1] 0.4827420303 0.0008324203

[[6]]
[1] 0.4826076828 0.0002399406

请问有人知道为什么会这样吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/653956/gap-between-the-given-correlation-parameter-and-the-empirical-correlation-in-ga</guid>
      <pubDate>Fri, 06 Sep 2024 09:16:25 GMT</pubDate>
    </item>
    <item>
      <title>平均随访时间</title>
      <link>https://stats.stackexchange.com/questions/653952/mean-follow-up-time</link>
      <description><![CDATA[*我正在使用 R 中的 pmsampsize 函数来计算 cox 比例风险模型（试点研究）的样本量。我需要输入 meanfup 的值（type=&quot;s&quot; 选项）来指定模型开发数据集中个人预期的平均（均值）随访时间。但我仍然不确定如何计算平均（均值）随访时间。任何建议都将不胜感激。
例如：假设包括 T0、T3、T6、T9、T12、....、T24（月）患者的信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/653952/mean-follow-up-time</guid>
      <pubDate>Fri, 06 Sep 2024 06:55:48 GMT</pubDate>
    </item>
    <item>
      <title>如何解释两个模型在后验预测检验中的模型拟合度（这两个模型都捕获了 1sigma 中的观测值）？</title>
      <link>https://stats.stackexchange.com/questions/653951/how-to-interpret-model-fit-in-posterior-predictive-checks-between-two-models-tha</link>
      <description><![CDATA[我有两个模型旨在解释单个观察到的测量值$x_{obs}$：
具有 26 个参数的简单模型$f_1(\theta)$。
具有 31 个参数的复杂模型$f_2(\theta)$。
这两个模型都被认为代表了观察背后的数据生成过程，这意味着它们定义了可能性。两者使用的噪声模型是相同的。我使用贝叶斯推理，特别是基于模拟的推理 (SBI)，为每个模型获得后验分布 $p(\theta|x_{\rm obs})$，在两种情况下均使用多变量均匀先验 $p(\theta)$。我的目标是确定哪种模型更适合观察到的测量值。
在执行贝叶斯推理后，我从后验分布中抽样，对两种模型进行后验预测检查 (PPC)。以下是结果摘要：
两种模型的后验预测分布 (PPD) 都在其 1-sigma 间隔内捕获观察到的测量值。
但是，与复杂模型的 PPD 相比，简单模型的 PPD 分布范围要窄得多。
复杂模型的 PPD 还包括 2 到 3 西格玛区域内的一些非物理值，这可能是由于其先验所致。
接下来，我对这两个模型进行了贝叶斯因子 (BF) 比较，结果表明，这两个假设的偏好程度相同（即，贝叶斯因子并不强烈偏向任何一个模型）。
此外，全局覆盖图表明，两个后验分布都经过了良好的校准，这意味着没有过度拟合或欠拟合的证据。
我的解释问题：
场景 A：这是否意味着两个模型与观察结果的一致性相同（因为它们的 PPD 适合数据），但由于贝叶斯因子对两者都不利，因此应该优先选择更简单的模型？
场景 B：或者，复杂模型的 PPD 分布范围较大（以及包含非物理值）是否表明复杂模型的后验应该被认为不太合适，即使贝叶斯因子没有显示出对更简单模型的强烈偏好？
提前感谢您的反馈！]]></description>
      <guid>https://stats.stackexchange.com/questions/653951/how-to-interpret-model-fit-in-posterior-predictive-checks-between-two-models-tha</guid>
      <pubDate>Fri, 06 Sep 2024 06:28:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么置信度 > 50% 还不是“足够好”？</title>
      <link>https://stats.stackexchange.com/questions/653946/why-isnt-a-confidence-level-of-anything-50-good-enough</link>
      <description><![CDATA[我上过研究生水平的统计学课程，所以问这个问题感觉自己很蠢，但我不明白 95% 置信度背后的含义。（请对我好一点。）
我目前正在对两张图片进行 A/B 测试，用于营销。测试将运行并收集数据，直到它能够在 95% 的置信度下做出决定。
当前置信率为 76.55%，其中 A 的点击率为 2.5%，B 的点击率为 4.55%。
由于 A 和 B 在 50% 的置信度下大致相等（一个设计没有显示出比另一个更好），为什么我要等到 95% 的置信度？在 50% 的置信度下，我选择哪种设计并不重要，而在 76.55% 的置信度下，我已经显示 B 的表现优于 A。
我想我不明白为什么我现在不能做出决定。如果是在制药情况下进行测试，比如生死攸关场景中的药物，我觉得我应该等待 95%，但对于像图像选择这样低风险的事情...]]></description>
      <guid>https://stats.stackexchange.com/questions/653946/why-isnt-a-confidence-level-of-anything-50-good-enough</guid>
      <pubDate>Fri, 06 Sep 2024 01:33:52 GMT</pubDate>
    </item>
    <item>
      <title>百分比比较和数量级</title>
      <link>https://stats.stackexchange.com/questions/653917/percentages-comparison-and-order-of-magnitude</link>
      <description><![CDATA[也许这是一个过于简单的问题。
假设有以下两个案例：
案例 1：患者人数/患者总数：63.080/1.335.636 = 4.7%
案例 2：患者人数/患者总数：5.840.431/59.030.133 = 9.8%
我如何比较这两个百分比？换句话说，如果可以将案例 1 的分子和分母设置为与案例 2 具有相同的数量级，或者最好是反之亦然，那么它们可能并没有太大的不同。既然如此，它们当然是不同的，因为数量级不同。
有人能帮帮我吗？
提前谢谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/653917/percentages-comparison-and-order-of-magnitude</guid>
      <pubDate>Thu, 05 Sep 2024 14:46:51 GMT</pubDate>
    </item>
    <item>
      <title>将因子变量纳入 GAM 时产生的矛盾解释</title>
      <link>https://stats.stackexchange.com/questions/653909/contradicting-interpretations-when-including-factor-variables-into-gam</link>
      <description><![CDATA[我建立的模型是这样的：
bam(n ~ s(age, k = 10, m = 2) + 
s(hh_size, k = 7, m = 2) +
s(age, by = pp, k = 10, bs = &quot;tp&quot;, m = 1) +
s(hh_size, by = pp, k = 7, bs = &quot;tp&quot;, m = 1) +
(employment_2cat + weekend + region + marital_2cat + education_2cat)* period * place + 
s(token, k = 864, bs = &quot;re&quot;) + 
s(Bundesland, k = 16, bs = &quot;re&quot;), data = halle_data, family = nb(), method = &quot;fREML&quot;,
drop.unused.levels = FALSE)
# pp 是时期和地点之间的相互作用。

拟合模型后，使用 summary() 获得参数系数。应用 emmeans()、pairs() 和 contrast() 来获取时期和地点对每个因子变量的影响。但结果似乎不对。

从模型的summary()结果来看，可以解释为“未就业”与“就业”相比，联系人数的对数增加25.5%。但从pairs()的结果来看，就业似乎与更高级别的联系有关。对于周末变量，也出现了这种相互矛盾的解释。

从 summary() 的结果来看，周末的联系人数量比工作日多。但从pairs()的结果来看，工作日发生的接触比周末多。
------- 更新：summary(model)中的年龄和可视化 -------


这部分是关于模型中数值变量的结果。]]></description>
      <guid>https://stats.stackexchange.com/questions/653909/contradicting-interpretations-when-including-factor-variables-into-gam</guid>
      <pubDate>Thu, 05 Sep 2024 12:19:33 GMT</pubDate>
    </item>
    <item>
      <title>做t检验时，样本标准差应该用样本均值减去原假设均值来估计吗？</title>
      <link>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</link>
      <description><![CDATA[以 t 检验为例，检验实数样本$x_i$是否来自均值为 0 的分布（$H_0:\mu=0, H_a:\mu \neq 0$）。检验统计量将是$t=\frac{\bar{x}}{s/\sqrt{n}}$。
我的问题是$s^2=\frac{\sum_i(x_i - \bar{x})^2}{n-1}$还是$s^2=\frac{\sum_i x_i^2}{n}$。
在大多数文本中我看到前者，但在财务数据的背景下我有时看到后者。两者似乎也都有意义，前者使用正态样本标准差公式，后者使用零假设，也不再需要贝塞尔校正。
两者的优缺点是什么，有没有更合适的方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/653905/when-doing-a-t-test-should-sample-standard-deviation-be-estimated-by-subtractin</guid>
      <pubDate>Thu, 05 Sep 2024 10:20:49 GMT</pubDate>
    </item>
    </channel>
</rss>