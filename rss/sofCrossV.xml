<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 28 Nov 2023 12:26:18 GMT</lastBuildDate>
    <item>
      <title>大数据高斯过程的顺序推理</title>
      <link>https://stats.stackexchange.com/questions/632520/sequential-inference-of-a-gaussian-process-with-large-data</link>
      <description><![CDATA[在 Gelman 的 贝叶斯数据分析 3 中，第 504 页，章节中关于高斯过程，它说：
&lt;块引用&gt;
在单变量情况下，可以使用 O(n) 时间进行计算
顺序推理，即使n更大，计算也没有问题
超过百万。

作者在这里指的是哪些方法？
我尝试浏览书目注释中的参考文献，但无法走得太远。]]></description>
      <guid>https://stats.stackexchange.com/questions/632520/sequential-inference-of-a-gaussian-process-with-large-data</guid>
      <pubDate>Tue, 28 Nov 2023 12:12:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么欧洲央行的商户 (PMC) 数据集发送的卡支付总额远高于其 PCP（和 PAY）数据集？</title>
      <link>https://stats.stackexchange.com/questions/632519/why-is-the-ecbs-card-payments-sent-by-merchant-pmc-dataset-much-significantly</link>
      <description><![CDATA[为什么欧洲央行的卡付款是由商户发送的（PMC - https:/ /data.ecb.europa.eu/data/datasets/PMC）数据集远高于其卡支付（PCP - https://data.ecb.europa.eu/data/datasets/PCP）和支付交易（PAY - https://data.ecb.europa.eu/data/datasets/PAY) 数据集的总数？
PCP 和 PAY 数据集很接近（仍然相差数十亿，稍后将解释），但 PMC 远高于 PCP，大约是 PCP 的 10-2 倍。我的理解是PCP来自于商户的报告，PCP和PAY来自于金融机构的报告（比如发行机构和收单机构）。我找不到用于制作这些数据集的确切方法的解释。
例如，看看
2022 年通过非远程渠道发起的基于卡的支付交易价值的总和 - 来自：欧元区变化的构成，终端位于：具有 MCC 代码的世界：所有 MCC 组合 https://data.ecb.europa.eu/ data/datasets/PMC/PMC.Q.U2._Z.W0.NR.G000.N.EUR（6,990,743.529 百万欧元）以及通过远程通道发起的基于卡的支付交易发送的价值 - 来自：欧元区域变化组成，航站楼位于：具有 MCC 代码的世界：所有 MCC 组合 https://data.ecb.europa.eu/data/datasets/PMC/PMC.Q.U2._Z.W0.R.G000.N.EUR&lt; /a&gt;（1,399,941.594 万欧元），合计为 8,390,685.122 万欧元。
8.4万亿是一个令人震惊的数字，除了所有商户类别的卡支付总额外，尚不清楚它到底来自哪里。目前看来还不错。
但是，与 PCP 相比：
卡支付的价值，全部，发送 - 发自：欧元区，改变构成，获取：世界，终端位于：世界，https://data.ecb.europa.eu/data/ datasets/PCP/PCP.H.U2.W0.W0.CP0.1._T._T.PCS_ALL._Z._X._Z.N.EUR（2745631.16百万欧元）
（或“收购：不适用”（据我所知，收购者所在位置的世界总数和缺失数据）
卡支付的价值，全部，发送 - 来自：欧元区改变构成，获取：不适用，终端位于：世界，
https://data.ecb.europa.eu/data/datasets/PCP/PCP.Q.U2._Z.W0.CP0.1._T._T.PCS_ALL._Z。 _X._Z.N.EUR（2,929,052.558 百万欧元）
差异约为 5.6 万亿。什么？？
PAY 数据集也是如此：
卡支付的价值，发送 - 从：欧元区改变构成，到：世界https://data.ecb.europa.eu/data/datasets/PAY/PAY.A.U2.W0.CP0.1._Z.N.EUR 
（2,741,360.932 万欧元）
这比不适用收单机构数据的 PCP 少了 187,691.6256 万，比世界收单机构数据少了 4270.227828 万，但仍然比 PMC 数据集少了 5.6 万亿！！
如果您按国家/地区（例如塞浦路斯发行的卡，而不仅仅是整个欧盟）进行筛选，也会得到相同的结果。参见 PMC.Q.CY._Z.W0.NR.G000.N.EUR、PMC.Q.CY._Z.W0.R.G000.N.EUR（总计 58,864.13116 百万欧元），与 PAY.H.CY 进行比较.W0.CP0.1._Z.N.EUR（2022 年总计 9,691,561639 万欧元）和 PCP.A.CY.W0.W0.CP0.1._T._T.PCS_ALL._Z._X._Z.N.EUR （9,691.5616.39 百万欧元，哈利路亚，匹配的数字！）
为什么这些数字如此不同？ PMC 数据集中包含哪些 PAY 或 PCP 中未包含的内容，为什么？ “获得：不适用”是什么意思？ PCP 中的意思是什么？
我找不到此信息。]]></description>
      <guid>https://stats.stackexchange.com/questions/632519/why-is-the-ecbs-card-payments-sent-by-merchant-pmc-dataset-much-significantly</guid>
      <pubDate>Tue, 28 Nov 2023 12:11:30 GMT</pubDate>
    </item>
    <item>
      <title>如何调节 R 和 GG 图中的 y 轴</title>
      <link>https://stats.stackexchange.com/questions/632518/how-do-modulate-the-y-axis-in-r-and-gg-plot</link>
      <description><![CDATA[我在 R 中有一些代码来制作图表。
# 安装并加载必要的包
库（ggplot2）
图书馆（tidyr）

# 你的数据
数据 &lt;- read.csv(“./mae_random.csv”)

# 重塑 ggplot 的数据
data_long$Model.Names &lt;- 因子(data_long$Model.Names,levels = unique(data$Model.Names))
# 为每个模型名称定义颜色
model_colors &lt;- c(“#1f78b4”、“#33a02c”、“#e31a1c”、“#ff7f00”、“#6a3d9a”、
                  “#a6cee3”、“#b2df8a”、“#fb9a99”、“#fdbf6f”、“#cab2d6”、“#ffff99”）

# 创建具有更大尺寸和自定义颜色的分组条形图
ggplot(data_long, aes(x = 模型.名称, y = 值, fill = 模型.名称)) +
  geom_bar(位置=position_dodge2(宽度=1.2，保留=“单一”)，统计=“身份”，颜色=“黑色”)+
  实验室（标题=“分组条形图”，
       x =“型号名称”，
       y =“平均绝对误差”) +
  scale_y_continuous(breaks = seq(0, max(data_long$Value), by = 0.1)) +
  scale_fill_manual（值= model_colors）+
  theme_minimal() +
  主题（
    绘图标题 = element_text(大小 = 16, hjust = 0.5),
    axis.text.x = element_text(角度 = 45, hjust = 1),
    axis.title.x = element_text(大小 = 14),
    axis.title.y = element_text(大小 = 14),
    axis.text.y = element_text(大小 = 12),
    图例.标题 = element_text(大小 = 12),
    图例.text = element_text(大小 = 10),
    绘图.边距 = 边距(1, 1, 1, 1, “厘米”)
  ）

这会产生这种图表：

但是，我想要稍微修改一下，但我不知道如何进行：

知道如何修改代码吗？任何帮助都会很可爱。哦，CSV 文件也是这样的：
型号名称、TPE、随机、网格
支持向量机 MACCS,0.36,0.41,0.39
SVM摩根,0.27,0.28,0.27
射频MACCS，0.31，0.31，0.26
RF摩根,0.24,0.24,0.24
XGBoost MACCS,0.4,0.36,0.32
XGBoost摩根,0.37,0.42,0.34
FFNN MACCS,0.7,0.67,0.64
FFNN 摩根,0.41,0.4,0.46
GCN,0.72,0.7,0.63
DMPNN,0.63,0.63,0.59
垫,0.56,0.65,0.66
]]></description>
      <guid>https://stats.stackexchange.com/questions/632518/how-do-modulate-the-y-axis-in-r-and-gg-plot</guid>
      <pubDate>Tue, 28 Nov 2023 12:11:15 GMT</pubDate>
    </item>
    <item>
      <title>如何通过提升模型解释偏差图</title>
      <link>https://stats.stackexchange.com/questions/632517/how-to-interpret-the-deviance-plot-by-boosting-models</link>
      <description><![CDATA[该图取自Scikit-Learn 文档。
偏差是什么意思？这段情节应该如何解读？在什么情况下我们会出现过拟合/欠拟合？根据该图，我们可以对模型参数进行哪些改进？
]]></description>
      <guid>https://stats.stackexchange.com/questions/632517/how-to-interpret-the-deviance-plot-by-boosting-models</guid>
      <pubDate>Tue, 28 Nov 2023 12:02:18 GMT</pubDate>
    </item>
    <item>
      <title>费舍尔对巴纳德测试的反对真的像维基百科上提到的那样“似是而非”吗？</title>
      <link>https://stats.stackexchange.com/questions/632516/was-fishers-disapproval-of-barnards-test-really-specious-as-mentioned-on-wi</link>
      <description><![CDATA[有关巴纳德测试的维基百科文章目前表示：
&lt;块引用&gt;
G.A. 于 1945 年首次发表巴纳德测试没有
由于计算的计算困难而受到欢迎
p 值和费舍尔似是而非的反对。

遵循另一个问题，我想知道维基百科文章相对于“费舍尔似是而非的反对”是否不正确。]]></description>
      <guid>https://stats.stackexchange.com/questions/632516/was-fishers-disapproval-of-barnards-test-really-specious-as-mentioned-on-wi</guid>
      <pubDate>Tue, 28 Nov 2023 11:58:03 GMT</pubDate>
    </item>
    <item>
      <title>傅里叶系数作为分类模型的特征</title>
      <link>https://stats.stackexchange.com/questions/632514/fourier-coeficients-as-feature-to-classification-model</link>
      <description><![CDATA[我必须解决时间序列多类分类问题。其中一些类（类 0、类 1 和类 4）具有彼此非常相似的时间序列，如下所示：

0 类：原始时间序列；
Class 1：基于Class 0生成。将整个Class 0时间序列乘以0.1到0.9之间的单个随机因子；
Class 4：同样基于Class 0生成。是 Class 0 时间序列以特定的随机间隔时间乘以 0.1 到 0.9 之间的不同随机值；

问题是我的模型没有为这些类达到可接受的 f1_score 。例如，考虑一下 Class 1 时间序列由 0.8 或 0.9 因子生成的情况，它将与生成它的 Class 0 非常相似。&lt; /p&gt;
有人建议我尝试使用傅里叶系数作为模型的附加输入/特征，包括幅度和相位。考虑到我的时间序列有 n = 24 点，那么我只能得到第一个 n/2 + 1 = 13 系数（由于对称性）
这是 3 个时间序列的 np.fft.fft 的幅度和相位值的图片。一个 0 类时间序列、一个 1 类时间序列和一个 4 类时间序列。

如您所见，Class 0 和 Class 1 的相位相等，并且它们的幅度形状相似，但 Class 1由于用于生成它的随机因素，其幅度较低。
Class 4的相位与Class 0和Class 1的相位完全不同。
那么，看看这些图形，这些系数可以用来提高我的模型性能吗？如果是，这里的方法是什么？我应该将 13 幅度值和 13 相位值作为模型的输入吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/632514/fourier-coeficients-as-feature-to-classification-model</guid>
      <pubDate>Tue, 28 Nov 2023 11:38:26 GMT</pubDate>
    </item>
    <item>
      <title>零通胀的 glmmTMB 截断模型</title>
      <link>https://stats.stackexchange.com/questions/632512/glmmtmb-truncated-models-with-zero-inflation</link>
      <description><![CDATA[大家。我正在使用 R 库 glmmTMB 拟合 glmm 模型，用于预测具有过量零和过度分散的计数响应变量 (nbinom2&gt; Poisson) .
此外，我有兴趣探索样本数据的零通货膨胀部分，因此出现了零通货膨胀与障碍问题。尽管这两种方法都是有限混合的双分量模型，但它们之间存在两个基本假设

障碍模型是指计数的零与非零部分被机械地分割的模型（即，您假设产生零部分的机制与非零部分不同），这意味着假设所有样本零都是真或结构零。然后，零与非零的对数模型加上计数&gt; 的计数模型。 0 一起呈现。
零膨胀模型，另一方面，同时也分割零和非零分量，允许计数模型产生零观测值（即，true&lt; /em&gt; 零），而零膨胀分量则成为点质量额外零发生器（即假或过量 零）。这些零计数代表假缺席，例如抽样错误或测量错误（也许你没有引起足够的重视......）

两者之间的选择成为决定结果解释的关键分析设计，以研究设计和测试假设为条件。
&lt;小时/&gt;
在 glmmTMB 中实现这些时，参数 ziformula = 启用零通货膨胀模型，而 family = truncated_nbinom2() 定义障碍型号
但是，我感到很困惑，因为尝试适应障碍 truncated_nbinom2 模型会产生以下错误消息：
&#39;y&#39; 包含零（或接近于零的值）。仅当添加零膨胀时，零才与截断分布兼容

那么我的模型可以定义如下：
m0 &lt;- glmmTMB(公式 + (1 | id),
          偏移量 = log(偏移量),
          数据 = df,
          族= truncated_nbinom2(),
          zi 公式= ~ .)

它正在生成一个满足我要求的漂亮模型。
事实上，这是我能够有效适应的唯一模型。
我在其他例子中看到过此类模型，很明显glmmTMB具有截断族零膨胀的具体实现，但我从未在文献中读过有关 hurdle + zi 模型的文献因为它们总是被呈现为相互排斥的，所以重点关注它们之间的选择和比较的标准
我在这里缺少什么？

这种方法在统计上有效吗？
结果如何解释？
我猜想零通胀部分与任何其他 zi 模型相同。
但我的条件模型作为一个被截断的族，不应该能够解释真正的零计数，因此计数模型可能有偏差

如果有人能够阐明这个问题，我会很高兴
P.S：我还发现了一些关于使用此类模型进行预测的问题，这些模型被零通货膨胀截断&lt;a href=&quot;https://stackoverflow.com/questions/75006442/predicting-from-glmmtmb-with-truncated-计数&gt;此处]]></description>
      <guid>https://stats.stackexchange.com/questions/632512/glmmtmb-truncated-models-with-zero-inflation</guid>
      <pubDate>Tue, 28 Nov 2023 11:21:20 GMT</pubDate>
    </item>
    <item>
      <title>方差分析模型假设。怎么过去？</title>
      <link>https://stats.stackexchange.com/questions/632510/anova-model-assumptions-how-to-go-by</link>
      <description><![CDATA[我有一个数据框，其中包含在不同物种、不同海拔和采样月份测量的连续响应变量作为解释变量。我想分析响应变量如何随海拔和时间变化。为此，我正在考虑使用双向方差分析测试，因为我还想查看两个解释变量的相加影响。
为了做到这一点，我相信，我必须满足模型假设：残差的正态性和同质性。我尝试使用夏皮罗-威尔克检验和可视化来检查它是否存在正态分布。我还使用 Levene 的同质性检验。
# 主要效果
aov.PhiPS2.sqrt&lt;-aov(sqrt(PhiPS2) ~ 高程，data=ecophy_df)
shapiro.test(aov.PhiPS2.sqrt$残差)

＃ 相互作用
aov.PhiPS2.sqrt&lt;-aov(sqrt(PhiPS2) ~ 海拔*月份，data=ecophy_df)
绘图（aov.PhiPS2.sqrt）
shapiro.test(aov.PhiPS2.sqrt$残差)

Shapiro-Wilk 正态性检验结果如下所示：
数据：aov.PhiPS2.log$residuals
W = 0.99546，p 值 = 0.5039


但是，当运行 leveneTest(PhiPS2_sq~elevation, data =ecophy_df) 时，同质性测试完全失败，如下所示：
Levene 方差齐性检验（中心 = 中位数）
       Df F值Pr(＞F)
第 9 组 6.6826 1.002e-08 ***
      300
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
&gt; leveneTest(PhiPS2_sq~海拔*月份，数据=ecophy_df)
Levene 方差齐性检验（中心 = 中位数）
       Df F值Pr(＞F)
第 39 组 2.4877 1.077e-05 ***
      270
---
西尼夫。代码： 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

所以我的问题是：

我哪里出错了？
是否有必要同时满足这两个假设？
是否应该测试我将使用的每个模型的正态性和同质性？
]]></description>
      <guid>https://stats.stackexchange.com/questions/632510/anova-model-assumptions-how-to-go-by</guid>
      <pubDate>Tue, 28 Nov 2023 10:51:15 GMT</pubDate>
    </item>
    <item>
      <title>对每个参与者进行多次测量的统计测试，其中每个参与者都受到影响变量的影响</title>
      <link>https://stats.stackexchange.com/questions/632509/statistical-test-for-multiple-measurements-per-participant-where-each-participan</link>
      <description><![CDATA[我们研究的目的是测试偏头痛患者在头痛期间与非头痛期间使用手机的方式是否有所不同（例如，花在手机上的时间更少）。我们对患者进行了三个月的监测并记录了他们的手机使用情况。参与者自己报告了他们的头痛期。请注意，本研究中的每个参与者都患有偏头痛，并且都有头痛和非头痛时期，这与每个参与者仅属于一组的更典型情况形成对比（例如，一组偏头痛患者与一组偏头痛患者）非偏头痛患者）。
我用来测试差异的方法如下：对于每个报告的头痛期，我发现了相应的非头痛期（与头痛相同的开始和结束时间，在头痛前一周的一段时间内的一天）到头痛后一周；我还确保周末头痛与周末非头痛期完全配对，工作日同上）。
这导致每个人的每个头痛期都有几个相应的非头痛期（值得注意的是，我确保没有非头痛期出现两次）。
每个人的头痛周期次数不同（2 到 30 次之间）。
我决定为每个参与者制作一个头痛 - 非头痛对：首先，通过对相应的非头痛值进行平均，为每个头痛制作一个非头痛值，然后对所有头痛值和头痛值进行平均所有非头痛的情况。这样我就为每个人提供了一个头痛值和一个非头痛值。
然后我使用单边 Wilcoxon 符号秩检验来测试差异是否关于 $\mu  对称。 0$.
我还可以做其他测试来提高统计功效吗？我只有 17 个科目。更具体地说，我正在寻找一种测试，它允许我保留每个人的单独对，而不是必须对它们进行平均（如上所述）。]]></description>
      <guid>https://stats.stackexchange.com/questions/632509/statistical-test-for-multiple-measurements-per-participant-where-each-participan</guid>
      <pubDate>Tue, 28 Nov 2023 10:50:21 GMT</pubDate>
    </item>
    <item>
      <title>在局部投影中使用条件波动作为外生冲击</title>
      <link>https://stats.stackexchange.com/questions/632508/using-conditional-volatility-as-exogeneous-shock-in-local-projection</link>
      <description><![CDATA[我想使用局部投影模型，用一些金融资产的波动性来代表冲击，但是这样做可以吗？
我使用 GARCH 模型（更准确地说，多元 (DCC) GARCH）估计了波动性，它给出了条件波动性，显然，该波动性对于其他变量的创新来说必须是外生的。
所以，总的来说，我可以使用 cond. DCC-GARCH 模型中估计的波动性作为局部投影模型中的冲击变量 ?如果我想这样做，我该怎么办？]]></description>
      <guid>https://stats.stackexchange.com/questions/632508/using-conditional-volatility-as-exogeneous-shock-in-local-projection</guid>
      <pubDate>Tue, 28 Nov 2023 10:31:01 GMT</pubDate>
    </item>
    <item>
      <title>如何解释 LRT 与 Wald 检验的 DESeq 结果</title>
      <link>https://stats.stackexchange.com/questions/632507/how-to-interpret-deseq-results-with-lrt-vs-with-walds-test</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/632507/how-to-interpret-deseq-results-with-lrt-vs-with-walds-test</guid>
      <pubDate>Tue, 28 Nov 2023 10:12:24 GMT</pubDate>
    </item>
    <item>
      <title>对 Popoviciu 和 von Szokefalvi Nagy 不等式在无偏估计量方差上的使用的误解</title>
      <link>https://stats.stackexchange.com/questions/632506/misunderstanding-on-the-use-of-popoviciu-and-von-szokefalvi-nagys-inequalities</link>
      <description><![CDATA[令 $X_1,\cdots,X_n$ 为（在我的情况下是离散的）独立同分布。并介于 $m$ 和 $M$ 之间。我对限制无偏估计量的方差感兴趣：
$$\mathbb{V}\left[\frac1n\sum_{i=1}^nX_i\right]$$
一方面，我们有：
$$\mathbb{V}\left[\frac1n\sum_{i=1}^nX_i\right]=\frac{\sigma^2}{n}$$
其中 $\sigma^2$ 是 $X_1$ 的方差。使用波波维丘不等式，这给了我
$\sigma^2\leqslant\frac14\left(M-m\right)^2$，然后我可以将其注入到前面的公式中：
$$\mathbb{V}\left[\frac1n\sum_{i=1}^nX_i\right]\leqslant\frac{\left(M-m\right)^2}{ 4n}$$
但另一方面，根据我的理解，von Szokefalvi Nagy 的不等式给出：
$$\frac{\left(M-m\right)^2}{2n}\leqslant\mathbb{V}\left[\frac1n\sum_{i=1}^nX_i\右]$$
显然，这两个结果是不一致的。这个推理的错误在哪里呢？这两个公式哪一个是错误的？]]></description>
      <guid>https://stats.stackexchange.com/questions/632506/misunderstanding-on-the-use-of-popoviciu-and-von-szokefalvi-nagys-inequalities</guid>
      <pubDate>Tue, 28 Nov 2023 10:00:54 GMT</pubDate>
    </item>
    <item>
      <title>使用 statsmodels Logistic 回归时出现“LinAlgError：奇异矩阵”[关闭]</title>
      <link>https://stats.stackexchange.com/questions/632504/linalgerror-singular-matrix-when-using-statsmodels-logistic-regression</link>
      <description><![CDATA[我正在尝试使用逻辑回归模型来使用以下数据集从症状来预测疾病：https://www.kaggle.com/datasets/rabisingh/symptom-checker?select=Training.csv
我关注两种疾病（在数据集中标记为“预后”）：“疟疾”和“疟疾”。和“登革热”。
我使用 statsmodels smf.logit 函数来拟合我的模型，但我得到了完美的分离错误，所以我决定进行一些特征选择。

这消除了 13 列。

这消除了 3 列。

运行此代码后，没有剩下要消除的列，它们已经被消除了。
尽管如此，我仍然收到模型错误。

有人可以指导我正确的方向来解决这个问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/632504/linalgerror-singular-matrix-when-using-statsmodels-logistic-regression</guid>
      <pubDate>Tue, 28 Nov 2023 09:18:06 GMT</pubDate>
    </item>
    <item>
      <title>在荟萃分析中结合相关系数和 t 统计量</title>
      <link>https://stats.stackexchange.com/questions/632503/combining-correlation-coefficient-and-t-statistics-in-meta-analysis</link>
      <description><![CDATA[我有一些研究报告了预测变量和感兴趣的结果之间的相关系数。其他研究对预测变量进行了二分，因此提供了 t 统计量。将这两种类型的研究结合到一个荟萃分析中是否合理？
如果是这样，我可以将 r 统计量转换为 t 统计量 $r=t/(t^2 +dof)^{0.5}$ 吗？然后将所有 t 统计量转换为 Hedge 的 g 并合并？]]></description>
      <guid>https://stats.stackexchange.com/questions/632503/combining-correlation-coefficient-and-t-statistics-in-meta-analysis</guid>
      <pubDate>Tue, 28 Nov 2023 09:12:06 GMT</pubDate>
    </item>
    <item>
      <title>静态风险预测模型和寿命分层</title>
      <link>https://stats.stackexchange.com/questions/632501/static-risk-prediction-models-and-years-to-live-stratification</link>
      <description><![CDATA[一个已知的悖论是，尽管患某种疾病的绝对风险可能随着年龄的增长而增加，但每个人患某种疾病的条件概率（考虑到他当时尚未患上这种疾病）正在下降 -例如，预计寿命为 50 年的 30 岁老人比 99 岁的临终老人患癌症的可能性更高，尽管 90 岁的人患癌症的几率比 30 岁的人高得多。
这一事实可能会在设计预测模型时引发问题 - 例如，如果研究对象的随访期很长，那么在较年轻的年龄组中开始研究的患者可能比年龄较大的组患者患癌症的可能性更高，只是因为他们被关注的时间更长。
有没有公认的方法来处理这个问题？您在研究中考虑了这些问题吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/632501/static-risk-prediction-models-and-years-to-live-stratification</guid>
      <pubDate>Tue, 28 Nov 2023 08:19:34 GMT</pubDate>
    </item>
    </channel>
</rss>