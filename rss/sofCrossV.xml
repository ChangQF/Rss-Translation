<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Sun, 26 May 2024 12:24:38 GMT</lastBuildDate>
    <item>
      <title>GraphPad - 单向方差分析、Dunnett 检验、P 值</title>
      <link>https://stats.stackexchange.com/questions/648016/graphpad-one-way-anova-dunnetts-test-p-value</link>
      <description><![CDATA[我在我的论文中使用了 graphpad 来构建我的图表。我使用了单向方差分析和邓内特检验，但找不到 p 值的信息。 * 是什么意思，**，***，...我诚实地尝试在互联网上到处寻找，在软件上到处寻找，什么也没有。
有人可以快速帮助我吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/648016/graphpad-one-way-anova-dunnetts-test-p-value</guid>
      <pubDate>Sun, 26 May 2024 12:20:30 GMT</pubDate>
    </item>
    <item>
      <title>充分性原理是公理吗？</title>
      <link>https://stats.stackexchange.com/questions/648014/is-the-sufficiency-principle-an-axiom</link>
      <description><![CDATA[充足性原则如 Casella 中所定义：
&lt;块引用&gt;


其中足够的统计量定义为：
&lt;块引用&gt;


问题：充足性原理是公理吗？
到目前为止我的想法和研究：

我不确定充分性原理是否是一个数学陈述，因为不清楚“推理”是否是一个数学陈述。是一个数学对象。
根据此关于“弱似然原理”问题的答案 （我认为这是充足性原则的别名），据说 W.L.P.是“公理化的”但不是“数学主张”。

&lt;块引用&gt;
Birnbaum (1962) 开创了对各种“原则”之间的关系进行正式说明的方法。他以证据意义的概念为基础和理论基础。 W.L.P.作为公理，&amp;继续从中推导出强似然原理 &amp;另一个公理，条件性原则。他对 W.L.P. 的正式声明是关于实验 $E$ 中的参数 $\theta$ 的推断，其中 $T$ 是 $\theta$ 的充分统计量，如果 $ T(x) = T(y)$ 样本 $x$ &amp; $y$，然后 $\operatorname{Ev(E,x)} = \operatorname{Ev}(E, y )$;其中 $\operatorname{Ev(E,x)} = \operatorname{Ev}(E, y)$ 表示“证据等价”或您的“包含相同的推理有用信息”。 这不是一个经验断言，甚至不是一个数学断言，而是旨在限制（合理的）推理程序：如果它包含在您所珍视的其他基本原则中，那么一切都很好。好的;如果没有那么你可以尝试&amp;平衡它与那些或完全避免它。


上面足够统计量的定义专门针对经典或F-充足性。或者，我们可以将贝叶斯或 B-Sufficient 统计量 (wiki) 定义为：

&lt;块引用&gt;



使用充分统计量的这种替代定义，并定义“推断”作为 $\theta$ 的后验概率，即 inference = $\Pr(\theta\mid X=x)$&lt; /span&gt;，充分性原理既是数学上的，也可以通过充分统计量的定义来简单地证明。

这让我们想到，
问题 2：对于贝叶斯主义者和频率主义者来说，问题 1 的答案是否不同？]]></description>
      <guid>https://stats.stackexchange.com/questions/648014/is-the-sufficiency-principle-an-axiom</guid>
      <pubDate>Sun, 26 May 2024 11:37:06 GMT</pubDate>
    </item>
    <item>
      <title>使用 CPCV 调整的超参数避免回测中的信息泄漏</title>
      <link>https://stats.stackexchange.com/questions/648007/avoiding-information-leakage-in-backtesting-with-cpcv-tuned-hyperparameters</link>
      <description><![CDATA[我正在使用组合清除交叉验证来调整月末交易策略中应用的二元分类模型的超参数。我有 6 个月的数据，并使用 CPCV 进行 15 次分割来确定最佳超参数。调整后，我使用这些超参数在整个数据集上训练了最终模型。
我担心的是回溯测试：如果我在回溯测试期间在相同的 15 个分割上使用这些 CPCV 调整的超参数，我是否会引入信息泄漏？
我觉得我可能误解了 CPCV。有人可以澄清这种方法是否正确，或者建议如何在这种情况下正确进行回溯测试？
]]></description>
      <guid>https://stats.stackexchange.com/questions/648007/avoiding-information-leakage-in-backtesting-with-cpcv-tuned-hyperparameters</guid>
      <pubDate>Sun, 26 May 2024 09:21:05 GMT</pubDate>
    </item>
    <item>
      <title>心理物理学中的非正态数据：三路混合方差分析的替代方案？ [关闭]</title>
      <link>https://stats.stackexchange.com/questions/648005/non-normal-data-in-psychophysics-alternative-to-three-way-mixed-anova</link>
      <description><![CDATA[我正在进行一项关于人们检测信号的能力的实验。我计算信号检测理论测量 d prime 和 beta。我想调查信号“蓝色”是否有效比“红色”更好地被检测到。无论这种情况在实验的前半部分和后半部分发生变化，除了短暂休息之外，参与者没有任何区别）。
我的方差分析看起来像这样：
anova = aov(d&#39;~ color *section * color:section * 1|观察者)

因此，我计算了每个观察者和颜色实验部分（第一或第二）的每个组合的测量值。我使用每个实验部分的总体误报率。
事实证明，数据确实存在偏差。 d prime 是双峰分布。 d prime 的 Shapiro-Wilk 检验给出了 W = 0.92869，p 值 = 0.0003652，β 的相同结果给出了 W = 0.70378，p 值 = 4.312e-11。
在绘制 d prime 和 beta 时，d prime 似乎具有双峰分布，而 beta 严重向右倾斜。对于 Beta 值，似乎有些人在部分实验中采用了非常保守的响应偏差（Beta 值从 7 到 12）。然而，近 200 次试验并没有太大差异。
我尝试标准化数据（平方和对数），但没有成功。考虑到样本量较小，这种方法很难纠正它。对此有什么建议吗？我一直在寻找一种非参数替代方案，其作用与我的方差分析相同，但我找不到。如果您需要有关实验的更多详细信息，请告诉我！]]></description>
      <guid>https://stats.stackexchange.com/questions/648005/non-normal-data-in-psychophysics-alternative-to-three-way-mixed-anova</guid>
      <pubDate>Sun, 26 May 2024 09:09:22 GMT</pubDate>
    </item>
    <item>
      <title>对于两个比例的检验，$\delta = (Z_{\alpha/2} + Z_{1-\beta}) \cdot SE$ 是如何获得效果大小 $\delta$ 的？</title>
      <link>https://stats.stackexchange.com/questions/648001/for-a-test-of-two-proportions-how-is-delta-z-alpha-2-z-1-beta-cd</link>
      <description><![CDATA[在 A/B 测试中，我们经常比较两个比例 $p_1$ 和 $p_2$ ：

原假设： $H_0: p_0=p_1$
替代假设： $H_0: p_0\neq p_1$

令效应大小 $\delta = p1-p2$ 且标准误差为 $SE = \sqrt{ \frac{p_1 (1 - p_1)}{n} + \frac{p_2 (1 - p_2)}{n}}$。然后令检验统计量为 $Z=\frac{\delta}{SE}$。
我们有这个

$Z_{\alpha/2}$：这是与显着性水平相对应的 Z 分数 $\阿尔法$。对于 $\alpha = 0.05$ 的双尾测试，$Z_{\alpha/2} = 1.96$&lt; /span&gt;.
$Z_{1-\beta}$：这是与所需功率相对应的 Z 分数 $1- \beta$。

我最近在一本书中读到，可以将上面的 $Z$ 分解为：
$$
\delta = (Z_{\alpha/2} + Z_{1-\beta}) \cdot SE
$$
这怎么可能？]]></description>
      <guid>https://stats.stackexchange.com/questions/648001/for-a-test-of-two-proportions-how-is-delta-z-alpha-2-z-1-beta-cd</guid>
      <pubDate>Sun, 26 May 2024 07:48:03 GMT</pubDate>
    </item>
    <item>
      <title>具有自相关性的时间序列数据[关闭]</title>
      <link>https://stats.stackexchange.com/questions/647999/time-series-data-with-auto-correlation</link>
      <description><![CDATA[我有一个带有干预的时间序列数据集。我的数据集显示自相关。我现在使用带有 CausalImpact 包的贝叶斯模型。我的问题是：你知道我是否可以在自相关的情况下使用这个模型和包吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647999/time-series-data-with-auto-correlation</guid>
      <pubDate>Sun, 26 May 2024 07:07:53 GMT</pubDate>
    </item>
    <item>
      <title>针对小型且不平衡的数据集进行训练-验证-测试分割？</title>
      <link>https://stats.stackexchange.com/questions/647996/train-validation-test-split-for-small-and-unbalanced-dataset</link>
      <description><![CDATA[我有一个大约 100 行的数据集，每行大约有 400 个特征。其中 93 个为 0 类，7 个为 1 类。
我希望能够将 100 个示例拆分为训练集、验证集和测试集，以便我可以优化超参数并选择一个好的模型。
但是，我的 1 类行数非常少，以至于将它们混入验证或测试集的方式会导致性能指标出现巨大波动。
分割数据集以便选择良好的超参数并报告有意义的性能指标的最佳方法是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647996/train-validation-test-split-for-small-and-unbalanced-dataset</guid>
      <pubDate>Sun, 26 May 2024 03:47:26 GMT</pubDate>
    </item>
    <item>
      <title>Altiplano 分布---围绕中心的分布非常平坦？</title>
      <link>https://stats.stackexchange.com/questions/647990/altiplano-distribution-distributions-very-flat-around-the-center</link>
      <description><![CDATA[（来自Facebook帖子，参考在最后）
“大家都知道”函数 $x \mapsto \exp\left(-1/x^2 \right)$ 是无限可微的，但不是（真正的）解析的，因为它的所有零处的导数为 0，因此其麦克劳林级数同样为零。该函数在原点处非常平坦。如果我们水平翻转它，我们会得到一个密度函数，我将其称为 Altiplano 分布：
$$
f(x)= \frac{1 - e^{-1/x^2}}{2\sqrt{\pi}}
$$
这可以以通常的方式扩展到位置规模系列：

这个分布没有期望，事实上它的尾部接近柯西尾部。事实上，洛朗级数展开（无穷大）表明尾部的行为（一阶）为 $x^{-2}$。
其他有趣的围绕中心分布非常平坦的例子？之前提到过这个特定的发行版？
此示例参考
Dr. 的 Facebook 帖子墨西哥国立自治大学的阿图罗·埃尔德利。拥有 Facebook 帐户的人可能可以找到它。]]></description>
      <guid>https://stats.stackexchange.com/questions/647990/altiplano-distribution-distributions-very-flat-around-the-center</guid>
      <pubDate>Sat, 25 May 2024 22:14:10 GMT</pubDate>
    </item>
    <item>
      <title>Metropolis-Hastings 算法未收敛到全局最小值</title>
      <link>https://stats.stackexchange.com/questions/647988/metropolis-hastings-algorithm-doesnt-converge-to-the-global-minimum</link>
      <description><![CDATA[我计算了用 Metropolis Hastings 估计的 24 个参数的总均方根误差，我运行了该算法 100.000 次迭代，并且随着链向前，它达到了全局最小值，但随着它的继续，更多的样本到达了，所以RMSE 开始增加。

所以我的问题是有办法提前停止吗？所以我可以在 25000 次迭代时停止？
我使用粒子边缘都会黑斯廷斯来构建马尔可夫链并使用粒子滤波器来计算可能性。]]></description>
      <guid>https://stats.stackexchange.com/questions/647988/metropolis-hastings-algorithm-doesnt-converge-to-the-global-minimum</guid>
      <pubDate>Sat, 25 May 2024 21:13:01 GMT</pubDate>
    </item>
    <item>
      <title>学习《统计学家的实函数分析》的参考资料</title>
      <link>https://stats.stackexchange.com/questions/647956/references-to-learn-real-and-functional-analysis-for-statisticians</link>
      <description><![CDATA[我正在寻找一本能够提供实分析元素的书，用于数理统计和计量经济学理论等。
我计划使用以下 3 本高级统计理论教科书：

概率基础，作者：Jacod 和 Protter
理论统计：核心课程主题，作者：Keener Robert
数学统计 作者：Jun Shao

但是它们非常注重实分析，尽管它们都提供了测量理论概率的介绍，所以我只是缺乏实分析来开始。我有经济学背景（欧洲 LMD 系统的许可证 3），所以即使我学过一些微积分、线性代数、初等概率和统计学，我也绝不是数学家，而且我不认为我是数学家。一个“基于证明”的数学家。
我做了一些研究，找到了这些书：

经济理论和计量经济学的数学分析简介，作者：Corbae、Stinchcombe 和 Zeman。
实际分析与经济应用作者：A. Efe
高级经济学微积分
和金融：理论与方法，作者：Giulio Bottazzi

但我认为最好请一些权威人士确定一下，不要浪费时间在对我来说太沉重或对君少类型的书来说不完整的东西上。
你们中的一些人有一些适合经济学家、工程师等自学实分析的好参考吗？
谢谢你，并对我糟糕的英语感到抱歉。]]></description>
      <guid>https://stats.stackexchange.com/questions/647956/references-to-learn-real-and-functional-analysis-for-statisticians</guid>
      <pubDate>Sat, 25 May 2024 13:05:16 GMT</pubDate>
    </item>
    <item>
      <title>帮助将双指数曲线拟合到原始质谱数据和时间</title>
      <link>https://stats.stackexchange.com/questions/647906/help-fitting-doube-exponential-curve-to-raw-mass-spec-data-time</link>
      <description><![CDATA[我正在用 Python 为氦测量系统编写质谱数据缩减软件，可以手动获取双指数函数来拟合我的数据。基本上，质谱室中的气体会随时间变化，我们正尝试将原始数据拟合回 t=0。
过去，我们传统上对我们的数据使用线性拟合，因为它在足够短的时间段内通常是线性的；然而，质谱随时间测量的气体强度是双指数函数：负项表示电离消耗，正项表示从记忆中生长。消耗或内生是否占主导地位，或者数据是否只是沿着基线散乱的混乱，通常很难预测。
我正在使用以下函数：
def double_exp_func(x, a1, b1, a2, b2, c):
return -a1 * np.exp(-b1 * x) + a2 * np.exp(-b2 * x) + c

def double_exp_fit(x, y, analysis_raw_std):

# 从线性拟合中获取斜率和截距
slope, interval = np.polyfit(x, y, 1)

# 从线性拟合中获取 R^2 值
residuals = y - (slope * x + interval)
ss_res = np.sum(residuals ** 2)
ss_tot = np.sum((y - np.mean(y)) ** 2)
r_squared = 1 - (ss_res / ss_tot)

# 如果数据分散，则使用最小指数贡献进行拟合
if r_squared &lt; 0.8: # 对于高度分散的数据
p0 = [0.01, 0.01, 0.01, 0.01, 截距] # 使用最小指数贡献进行拟合
else:
if slope &gt; 0：# 对于正斜率，记忆/内生是主导过程（第二个指数占主导地位）
p0 = [1e-10，斜率，1e-12，斜率，截距]
else：# 对于负斜率，消费是主导过程（第一个指数占主导地位）
p0 = [100，100，100，100，截距]

def cost_function(params):
a1, b1, a2, b2, c = params
fitted_y = double_exp_func(x, a1, b1, a2, b2, c)
residuals = y - fitted_y
return np.sum(residuals ** 2)

initial_params = p0
fit = minimal(cost_function, initial_params, method=&#39;Nelder-Mead&#39;, options={&#39;maxiter&#39;: 100000})
optimal_params = fit.x
# 拟合数据
# fit, 协方差 = curve_fit(double_exp_func, x, y, p0, maxfev=100000)
fitted_y = double_exp_func(x, *optimized_pa​​rams)
error = np.sum((y - fitted_y) ** 2)

return optimal_params

我已将数据分成三组：

分散数据（线性 R^2 &lt; 0.8）
斜率为正的数据，记忆/内生是主要过程
斜率为负的数据，消费是主要过程

但是，您可能会注意到，p0 项中的值是……好吧，我在这里是盲目的。称它们为有根据的猜测有点夸张。
以下是我的程序对原始数据提供的一些拟合示例：



请注意，右下角的图 5 amu 始终显示平均值而不是拟合值。这是因为 5 amu 是我们的基线（5 amu 时没有气态物种），并且几乎没有测量任何内容，因此没有理由将其拟合到任何东西。其余图应具有双指数拟合。
您会注意到“拟合”大多数时候只是画出平线，但是，过去我曾使用不同的参数成功拟合了一些数据——但它并没有转化为其余的数据集。
以下是我所了解的有关过程：

指数贡献应该是平缓的——毕竟，这些数据接近线性
其中一个指数项应该锁定为负数，另一个锁定为正数，而不是让拟合参数根据需要将数据变为负数和正数。
斜率为正的数据以内生为主导过程。
斜率为负的数据以消耗为主导过程。

不过，我是 Python 新手，不是数学家，所以我需要一些建议来让这些讨厌的双指数拟合发挥作用。
我做错了什么，我该如何提高成功的机会？找到合适的吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/647906/help-fitting-doube-exponential-curve-to-raw-mass-spec-data-time</guid>
      <pubDate>Fri, 24 May 2024 15:16:06 GMT</pubDate>
    </item>
    <item>
      <title>将质量体积解释为无监督异常检测的评估标准</title>
      <link>https://stats.stackexchange.com/questions/647349/interpreting-mass-volume-as-an-evaluation-criterion-for-unsupervised-anomaly-det</link>
      <description><![CDATA[我找到了这篇论文如何评估无监督异常检测算法的质量？经过
Nicolas Goix 讨论了通过使用作者所说的质量体积和过量质量来评估无监督异常评分函数。我还从这里的论文中找到了代码，这相当不错便利。我专注于 M-V，并试图解释其含义以及为什么它有意义。
质量-体积描述如下：
$$
MV_{s}(\alpha) = \inf_{u \geq 0} Leb(s(\mathbf{U}) \geq u) ~~~ s.t. ~~~ \mathbb{P}(s((\mathbf{X})) \geq u) \geq \alpha
$$
哪里
$\alpha$ 是累积质量
$s$ 是一些异常评分函数
$\mathbf{X}$ 是我们的特征集，维度为 (N,M)
$\mathbf{U}$ 是一个随机生成的多元均匀变量，以下边界 $\inf(\mathbf{ X})$ 和上限 $\sup(\mathbf{X})$。这本质上创建了一个从最小特征值到最大特征值的矩形。
$u$ 是我们评估勒贝格度量的分位数，表示为 $Leb$。
在 Python 中的实现中，如下所示：
clf = SomeAnomalyScoringModel()


阿尔法最小值 = 0.9
阿尔法最大值 = 0.999
axis_alpha = np.arange(alpha_min, alpha_max, 0.0001)


lim_inf = X.min(轴=0)
lim_sup = X.max(轴=0)
n_生成 = 100000
unif = np.random.uniform(lim_inf, lim_sup,
                            大小=（n_生成，n_特征））
Volume_support = (lim_sup - lim_inf).prod()


s_unif = clf.decision_function(unif)  
s_x = clf.decision_function(X) 


def 质量体积（axis_alpha、volume_support、s_unif、s_X、n_generate）：
    n_samples = s_X.shape[0]
    s_X_argsort = s_X.argsort()
    质量 = 0
    点 = 0
    u = s_X[s_X_argsort[-1]]
    mv = np.zeros(axis_alpha.shape[0])
    对于范围内的 i(axis_alpha.shape[0])：
        而质量&lt; axis_alpha[i]：
            #在这里找你
            cpt += 1
            u = s_X[s_X_argsort[-cpt]]
            质量 = 1./ n​​_samples * cpt # sum(s_X &gt; u)
        mv[i] = float((s_unif &gt;= u).sum()) / n_ generated * volume_support
    返回 auc(axis_alpha, mv), mv

我对这里发生的事情有一个大概的了解。通过对 $s(x)$ 进行排序，我们正在寻找给定 $u$ =&quot;math-container&quot;&gt;$\alpha$ 通过添加 $mass$ 直到达到所需的  $\alpha$-质量。完成后，我们停止，因为我们已经达到约束 $\mathbf{P}(s(\mathbb{X})\geq q) \geq \alpha$&lt; /跨度&gt;。此时，我们计算 $Leb(s(\mathbf{U})\geq u)$。我们对所有所需的 $\alpha$ 级别重复此操作。
这里有两个问题：
我们如何解释这一点？我最好的解释是，我们将评分函数 $s$ 视为均匀分布（由设计没有离群值），并在到达真实得分分布的尾部后测量其累积密度，以勒贝格测量为代表（因此，在本例中只是面积）。但这如何表明 $s$ 是一个好模型呢？
为什么 Lebesgue 定义为 float((s_unif &gt;= u).sum()) / n_generate *volume_support？
当统一变量大于$u$时，这相当于矩形盒子的体积，那么它是二元累积密度吗？这是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/647349/interpreting-mass-volume-as-an-evaluation-criterion-for-unsupervised-anomaly-det</guid>
      <pubDate>Thu, 16 May 2024 09:45:24 GMT</pubDate>
    </item>
    <item>
      <title>群体变化的统计检验</title>
      <link>https://stats.stackexchange.com/questions/635337/statistical-test-for-group-changes</link>
      <description><![CDATA[在我们的研究中，参与者可以在基线和后续阶段选择三方之一。因此频率表如下所示：

我们的假设是，从 A 转到 C 的人比从 B 转到 C 的人更多。我们只对这些变化感兴趣，因此在基线阶段投票给 C 的人以及在 A 和 B 之间转换的人被排除在分析之外。我们对原始数据进行的操作如下：

目前的想法是使用 R 中的 binom.test() 进行二项式检验来测试我们的假设，如下所示：

成功次数：表格单元格 2
试验次数：单元格 1 + 2
假设的成功概率：单元格 3/（单元格 3 + 4）
备选假设：成功的真实概率大于假设的成功概率

我们可以这样使用二项式检验吗？如果不是，还有什么其他测试在这里更合适？

如果我理解正确，我们可以使用二项式广义线性模型，它应该会给出相同的结果。我们应该使用什么测试？]]></description>
      <guid>https://stats.stackexchange.com/questions/635337/statistical-test-for-group-changes</guid>
      <pubDate>Wed, 20 Dec 2023 12:54:17 GMT</pubDate>
    </item>
    <item>
      <title>多分类名义变量与连续变量之间的相关性/关联</title>
      <link>https://stats.stackexchange.com/questions/614573/correlation-association-between-a-polychotomous-nominal-variable-and-a-continuou</link>
      <description><![CDATA[参考关联措施如何选择
论文指出，对于多分名义变量和连续变量之间的关联；
&lt;块引用&gt;
如果名义变量有两个以上的水平，那么可以
计算连续值之间的点双列相关性
变量和名义变量的所有可能水平对；
这将导致这样的系数，其中 k 代表数字
名义变量的水平。如需进一步阅读，请参阅泰特美术馆。

但是，本文没有说明如何处理所有级别对的点二列相关性。我想要两个变量之间的聚合指标。取系数的算术平均值就足够了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/614573/correlation-association-between-a-polychotomous-nominal-variable-and-a-continuou</guid>
      <pubDate>Mon, 01 May 2023 07:32:51 GMT</pubDate>
    </item>
    <item>
      <title>3D 坐标系的选项？</title>
      <link>https://stats.stackexchange.com/questions/610623/options-for-3d-coordinate-systems</link>
      <description><![CDATA[我正在尝试使用 DNN 解决生物化学问题（例如蛋白质折叠）。是否有特别适合深度神经网络 (DNN) 处理的 2D / 3D 坐标系？
例如，如果我们训练 DNN 来预测两个物体之间的引力，笛卡尔坐标可能会比极坐标表现得更差，因为计算引力的关键值是距离，这是一个直接用极坐标表示的值，但会比极坐标差。使用笛卡尔坐标时需要 DNN 来学习毕达哥拉斯规则。
作为另一个例子，早期 Transformer 中使用的基于正弦和余弦的位置嵌入可以说是一个有趣的“坐标系”。一维。
另一个答案可能是不用担心 - 无论您选择什么坐标系（在合理范围内），DNN 都会解决这个问题。]]></description>
      <guid>https://stats.stackexchange.com/questions/610623/options-for-3d-coordinate-systems</guid>
      <pubDate>Fri, 24 Mar 2023 17:37:31 GMT</pubDate>
    </item>
    </channel>
</rss>