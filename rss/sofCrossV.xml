<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 24 Sep 2024 21:15:39 GMT</lastBuildDate>
    <item>
      <title>交叉验证和测试集准确率之间的差异</title>
      <link>https://stats.stackexchange.com/questions/654864/discrepancy-between-cross-validation-and-test-set-accuracy</link>
      <description><![CDATA[我正在研究一个名为 Spaceship Titanic 的 kaggle 数据集，目前遇到了一个让我很困惑的问题。
出于某种原因，我无法可靠地使用 5 倍 cv 准确度作为测试集准确度的代表。我的意思是，举个例子，当我从数据集中删除一个特定特征时，我的 cv 准确度从 0.7923 增加到 0.8048。但是，我的测试集准确度从 0.8026 降低到 0.7961。同样，当我根据 cv 准确度优化超参数时，我的测试集准确度会下降。
什么可能导致这种差异？此外，是否有任何建议让我以这样的方式进行验证，即其准确度的变化直接反映到测试集，不一定是幅度方面，而是方向方面？]]></description>
      <guid>https://stats.stackexchange.com/questions/654864/discrepancy-between-cross-validation-and-test-set-accuracy</guid>
      <pubDate>Tue, 24 Sep 2024 21:15:09 GMT</pubDate>
    </item>
    <item>
      <title>一个数据集来自多个分布</title>
      <link>https://stats.stackexchange.com/questions/654863/one-data-set-drown-from-multiple-distributions</link>
      <description><![CDATA[我不清楚如何拟合至少从视觉上看是从多个分布中提取的数据集。
我尝试使用 GaussianMixture，但结果看起来并不令人信服。我不擅长统计，也不想争辩说它是错误的，但这不是我所期望的。代码在这里：
import numpy as np
from pylab import *
from sklearn.mixture import GaussianMixture
from pylab import concatenate, normal
import pandas as ps

from scipy.stats import norm

df = ps.read_csv(&#39;Book6.csv&#39;)
multimodal_dist = df.E.to_numpy()

weights = np.ones_like(multimodal_dist)/float(len(multimodal_dist))
y, x, _=hist(multimodal_dist, bins=np.arange(df[&#39;E&#39;].min(), df[&#39;E&#39;].max()+1)-0.5, alpha=.5, weights=weights, label=&#39;data&#39;)

gm = GaussianMixture(n_components=2)
gm.fit(多模态分布.重塑(-1, 1))

均值 = gm.means_
标准偏差 = gm.covariances_**0.5 
权重 = gm.weights_ 

new_X = np.linspace(min(多模态分布), max(多模态分布), 100)

对于 zip(均值, 标准偏差, 权重) 中的均值, 标准差, 权重:
print(权重, 均值, 标准差)
pdf = 权重 * norm.pdf(new_X, 均值, 标准差)
plt.plot(new_X.重塑(-1, 1), pdf.重塑(-1, 1), alpha=0.8)

logprob = gm.score_samples(new_X.重塑(100,1))
pdf = np.exp(logprob)
plt.plot(new_X.reshape(100,1), 2. * pdf, &#39;-k&#39;)

plt.show()

weights = np.ones_like(multimodal_dist)/float(len(multimodal_dist))
y, x, _=hist(multimodal_dist, bins=np.arange(df[&#39;E&#39;].min(), df[&#39;E&#39;].max()+1)-0.5, alpha=.5, weights=weights, label=&#39;data&#39;)

pdf = 3.9 * 0.48 * norm.pdf(new_X, -310, 75)
plt.plot(new_X.reshape(-1, 1), pdf.reshape(-1, 1), alpha=0.8)

pdf = 3.7 * 0.52 * norm.pdf(new_X, -280, 72)
plt.plot(new_X.reshape(-1, 1), pdf.reshape(-1, 1), alpha=0.8)

plt.show()

我根据 GaussianMixture 拟合系数绘制的图是

整体曲线确实看起来正确，但底层分布不是我所期望的。
我期望的图是手动拟合的，没有统计支持，但我认为它应该是这样的：

我的期望是错误的，还是我没有使用好的方法，或者误用了它们？首先，在这两种情况下，我的标准化都是手动完成的。我不明白如何标准化我的拟合以匹配分布。
数据在这里。]]></description>
      <guid>https://stats.stackexchange.com/questions/654863/one-data-set-drown-from-multiple-distributions</guid>
      <pubDate>Tue, 24 Sep 2024 20:55:32 GMT</pubDate>
    </item>
    <item>
      <title>Excel 中带有 ARIMA(1, 0, 1) 误差计算的手动回归模型</title>
      <link>https://stats.stackexchange.com/questions/654862/manual-regression-model-with-arima1-0-1-errors-calculation-in-excel</link>
      <description><![CDATA[我试图在 Excel 中复制带有 ARIMA(1, 0, 1) 误差的回归模型，但似乎无法匹配 R 中看到的结果。
假设我有一个带有 ARIMA(1, 0, 0) 误差的回归模型。这将被定义为：
$\hat{Y_t} = (\beta_1)*X_1+(\beta_2)*X_2+\hat{e_t}$
其中
$\hat{e_t} = (ar1)*e_{t-1}$
并且
${e_t} = (ar1)*e_{t-1} + u$
我理解如何实现这一点，这里的 ar1 项只是乘以前一期的残差 $(Y_{t-1} - \hat{Y}_{t-1})$
但是，当我将移动平均项添加到我的 ARIMA 误差中时，我似乎无法匹配结果。
对于 ARIMA(1, 0, 1) 误差，我相信误差公式现在是：
$\hat{e_t} = (ar1)*e_{t-1}+ (ma1)*u_{t-1}$
或者
${e_t} = (ar1)*e_{t-1}+ (ma1)*u_{t-1} + u$
我需要根据以下内容计算我的 $u$：
$u = {e_t}-(ar1)*e_{t-1} -(ma1)*u_{t-1} $
但是我如何获取第一个 $u_{t-1}$ 值？
我似乎陷入了无限循环试图弄清楚这一点。如果有人可以提供一个简单的 Excel 示例，那将非常有帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/654862/manual-regression-model-with-arima1-0-1-errors-calculation-in-excel</guid>
      <pubDate>Tue, 24 Sep 2024 20:48:04 GMT</pubDate>
    </item>
    <item>
      <title>使用下限日期作为预测模型的特征是一个好主意吗？</title>
      <link>https://stats.stackexchange.com/questions/654860/is-using-floored-dates-as-a-feature-in-predictive-models-a-good-idea</link>
      <description><![CDATA[我正在开展一个预测建模项目，并考虑使用 Floored Date 功能来捕获数据中更广泛的时间模式。这个想法是使用 Python 中特定于日期的函数（如 pd.Timestamp.floor）将观察日期四舍五入到指定的粒度 G（例如，天、周、月）。这种方法旨在简化时间信息，减少来自确切日期的噪音，防止数据泄漏过度拟合，同时仍能捕捉不同时间尺度上的重要趋势。
我的问题：

在预测模型中使用底数日期作为特征是一种好的做法吗？
其他人是否在实际应用中探索或验证过这种方法？
在实施此功能时，我应该注意哪些潜在的陷阱或最佳实践？

其他详细信息：
定义：
底数日期功能使用 pd.Timestamp.floor 等函数将观察日期四舍五入到指定的粒度 G。例如，如果 G 设置为“W”（表示周），则所有日期都会向下舍入到各自周的开始时间。
class DateFloorTransformer(BaseEstimator, TransformerMixin):
def __init__(self, column, granularity=&#39;D&#39;):
self.column = column
self.granularity = granularity

def fit(self, X, y=None):
return self

def transform(self, X):
X = X.copy()
X[self.column] = X[self.column].dt.floor(self.granularity)
return X

# 定义管道
pipeline = Pipeline([
(&#39;date_floor&#39;, DateFloorTransformer(column=&#39;date&#39;)),
(&#39;model&#39;, RandomForestTree())
])

# 初始化 GridSearchCV
grid_search = GridSearchCV(
estimator = pipeline,
cv = TimeSeriesSplit(n_splits=5),
param_grid = {
&#39;date_floor__granularity&#39;: [&#39;D&#39;, &#39;7D&#39;, &#39;W&#39;, &#39;M&#39;]
})

动机：

简化：降低日期数据的精度以关注更广泛的时间趋势，最大限度地减少来自确切日期的噪音，同时捕捉不同时间尺度上的重要模式。
可调粒度：粒度 G（例如，‘D’ 代表天，‘W’ 代表周，‘M’ 代表月）可以使用时间序列交叉验证进行优化，以找到最佳的时间聚合级别进行预测。

优点（我认为）：

捕获时间模式：有助于识别趋势，而不会用确切的日期细节压倒模型。
粒度灵活性：可以根据数据调整 G 以适应不同的时间尺度。
降噪：丢弃可能引入噪音并导致过度拟合的不必要的时间精度。
平衡长期和短期趋势：允许模型在选定的时间尺度上学习广泛的模式和波动。

缺点（以及如何解决）：

丢失细粒度的时间信息：由于舍入，重要的细节可能会丢失。

解决方案：包括额外的时间特征，如星期几、月份或特殊事件指标，以捕捉更精细的模式。


过度拟合历史数据：模型可能会过度拟合过时的趋势。

解决方案：使用时间序列交叉验证选择最佳 G，并实施监控机制来检测概念漂移。


粒度选择挑战：不合适的 G 可能会错过相关模式。

解决方案：进行探索性数据分析以了解固有周期并系统地测试不同的粒度。


概念漂移敏感性：如果趋势随时间变化，模型可能无法捕捉到新模式。

解决方案：监控模型随时间的性能，并在检测到重大变化时重新训练模型。


数据泄露风险：处理不当可能导致数据泄露。

解决方案：使用时间序列交叉验证方法确保基于时间的训练测试分割正确。



我对使用下限日期作为预测模型特征的任何经验、研究或最佳实践特别感兴趣。非常感谢您的见解和建议！]]></description>
      <guid>https://stats.stackexchange.com/questions/654860/is-using-floored-dates-as-a-feature-in-predictive-models-a-good-idea</guid>
      <pubDate>Tue, 24 Sep 2024 19:31:43 GMT</pubDate>
    </item>
    <item>
      <title>项目焦点树在真实世界数据中识别差异项目功能的评估指标</title>
      <link>https://stats.stackexchange.com/questions/654858/evaluation-metrics-for-item-focused-tree-in-identification-of-differential-item</link>
      <description><![CDATA[我正在研究一个由患者报告的结果测量组成的真实世界数据集。我将应用 LASSO 和以项目为中心的树 (IFT)（一些具有逻辑回归基础模型的机器学习方法）来检测表现出 DIF 的项目。我将得到一些 IFT 模型的结果树，它们向我展示 DIF 项目是什么以及与 DIF 相关的协变量是什么。我需要评估 IFT 模型的拟合度，但 R 中的 DIFtree 包没有提供我需要使用的拟合统计数据。
如果有人知道这方面的参考或解决方案，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/654858/evaluation-metrics-for-item-focused-tree-in-identification-of-differential-item</guid>
      <pubDate>Tue, 24 Sep 2024 16:18:56 GMT</pubDate>
    </item>
    <item>
      <title>Stanza 在命名实体识别方面表现不佳</title>
      <link>https://stats.stackexchange.com/questions/654857/stanza-bad-performance-on-named-entity-identification</link>
      <description><![CDATA[我使用 SpaCy 和 Stanza 来识别非常短的字符串中的命名实体（品牌名称和企业名称）：
 # 构建模型

#-----stanza
sen = stanza.Pipeline (&quot;en&quot;)
smlp = stanza.MultilingualPipeline()

#----spacy
spl = spacy.load(en_core_web_lg-3.7.1)
spt = spacy.load(en_core_web_trf-3.7.3)

# 测试模型
name = &#39;The Port of Peri Peri&#39;
print(name)

# spacy
print(&#39;\n SPACY------------------------------------------------------------------&#39;)
print(&#39;spacy spl&#39;)
doc = spl(name)
for token in doc:
print(token.text, token.is_oov, token.shape_, token.tag_, token.pos_, token.dep_, token.ent_type_, token.ent_iob_)
print(&#39;-----------------&#39;)

print(&#39;spacy trf&#39;)
doc = spt(name)
for token in doc:
print(token.text, token.is_oov, token.shape_, token.tag_, token.pos_, token.dep_, token.ent_type_, token.ent_iob_)

#stanza
print(&#39;\n STANZA----------------------------------------------------------------&#39;)
print(&#39;stanza sen&#39;)
doc = sen(name)
for sent in doc.sentences:
for token in sent.tokens:
for word in token.words:
print(word.text, word.xpos, word.upos, word.deprel, token.ner)
print(&#39;-----------------&#39;)

print(&#39;stanza smlp&#39;)
doc = smlp(name)
for sent in doc.sentences:
for token in sent.tokens:
for word in token.words:
print(word.text, word.xpos, word.upos, word.deprel, token.ner)
print(&#39;-----------------&#39;)

输出：
Peri Peri 的端口

SPACY------------------------------------------------------------------
spacy spl
False Xxx DT DET det ORG B
Port False Xxxx NNP PROPN ROOT ORG I
of False xx IN ADP prep ORG I
Peri False Xxxx NNP PROPN compound ORG I
Peri False Xxxx NNP PROPN pobj ORG I
-----------------
spacy trf
True Xxx DT DET det FAC B
Port True Xxxx NNP PROPN ROOT FAC I
of True xx IN ADP prep FAC I
Peri True Xxxx NNP PROPN复合 FAC I
Peri True Xxxx NNP PROPN pobj FAC I

STANZA----------------------------------------------------------------
stanza sen
The DT DET det B-PERSON
Port NNP PROPN root I-PERSON
of IN ADP case I-PERSON
Peri NNP PROPN nmmod I-PERSON
Peri NNP PROPN nmmod E-PERSON
-----------------
stanza smlp
The DT DET det B-PERSON
Port NNP PROPN root I-PERSON
of IN ADP case I-PERSON
Peri NNP PROPN nmmod I-PERSON
Peri NNP PROPN nmmod E-PERSON
-----------------

因此，如果您查看输出行的末尾，虽然 SpaCy 将该地点标识为 ORGanization 或 FACility，但 Stanza 将其标识为 PERSON，这很荒谬：人名通常不以“The”开头或者其中有“of”。我的问题是，我可以对 Stanza 模型进行任何改进吗？或者这就是它们最好的了吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654857/stanza-bad-performance-on-named-entity-identification</guid>
      <pubDate>Tue, 24 Sep 2024 16:07:30 GMT</pubDate>
    </item>
    <item>
      <title>为制药公司微调电子邮件分类器的建议</title>
      <link>https://stats.stackexchange.com/questions/654856/advice-on-fine-tuning-an-email-classifier-for-a-pharma-company</link>
      <description><![CDATA[我是一名实习生，正在为客户（制药公司）实施二元电子邮件分类器，我需要一些关于微调模型的建议。
我使用的模型是 Longformer（因为它有一个适合我的用例的大上下文窗口），我已经使用 14 种不同的超参数组合对其进行了训练。在最新的迭代中，似乎我的模型不仅过度拟合了训练集，而且在某种程度上也过度拟合了验证集和测试集（我在单独的数据集上测试模型时发现了这一点）。
我希望实现的目标是将假阴性率 (FNR) 降低到 2% 以下。
关于数据集，我有大约 8800 个样本，每个类别的样本数量大致相等。这是在大量清理和数据增强之后的结果。
训练后，我使用验证集找到一个合理的阈值，然后将其用于预测。
以下是我最近训练的模型的一些结果：
验证集（不平衡，负（0）类占绝大多数）：
阈值：0.9
准确率：82.47%
FNR：1.91%
假阳性率（FPR）：15.61%
F1 得分：0.64
精确度：49%
召回率：91%
ROC-AUC：94%
测试集（不平衡，负（0）类）类占大多数）：
准确率：84.79%
FNR：1.51%
FPR：13.69%
给定阈值和验证数据的指标，您可以看到模型倾向于更频繁地预测模型，因此 FNR 较低。
以下是我在最近的训练循环中使用的超参数：
学习率：1.5e-5
学习率调度程序：余弦
权重衰减：0.01
时期：7
辍学率：0.35
类权重：[0.9, 1.1]
最佳模型的指标：F1分数
提前停止耐心：2
对于下一次迭代，我考虑降低学习率（至 1e-5）并增加权重衰减（0.03）和 dropout 率（0.45）来解决过度拟合问题。但我并不完全有信心。我会问我的同事，但他们来自 SWE 背景，对此不太了解。
非常感谢您的一些建议。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654856/advice-on-fine-tuning-an-email-classifier-for-a-pharma-company</guid>
      <pubDate>Tue, 24 Sep 2024 16:03:02 GMT</pubDate>
    </item>
    <item>
      <title>检验统计量适中，但 F 检验的 p 值较低</title>
      <link>https://stats.stackexchange.com/questions/654854/moderate-test-statistic-but-low-p-value-in-an-f-test</link>
      <description><![CDATA[我正在 R 中对模拟数据运行多元回归。样本大小为 100。有一个相关回归量和 18 个不相关回归量。我正在使用 Newey-West 协方差矩阵测试 18 个不相关回归量的联合显著性。
谜题 1：我发现 18 个不相关回归量具有高度统计显著性。
谜题 2：我在 18 自由度下获得了 6.8814 的检验统计量，这对我来说似乎是适中的（在 F(98, 18) 分布的右尾不远），那么这怎么会产生非常低的 p 值 4.5e-10？
我能够解决谜题 1。显然，Newey-West 是问题所在。使用 vanilla 协方差矩阵，结果更加合理。但是，我仍然对谜题 2感到困惑，而这是我的问题。
library(car)
library(sandwich)

m &lt;- 20
n &lt;- 100
set.seed(9999)
x &lt;- rnorm(m * n)
X &lt;- matrix(x, ncol = m)
X[, 2] &lt;- X[, 1] + X[, 2]
# 现在，第二列是第一列 + 一些噪音，
# 而所有其他列都是纯噪音。
# 因此，如果我们尝试预测第一列，那么只有第二列应该有用。
m1 &lt;- lm(X[, 1] ~ X[, -1])
(test &lt;- linearHypothesis(
model = m1,
hypothesis.matrix = (diag(m)[-c(1:2), ]),
rhs = rep(0, m - 2),
test = &quot;F&quot;,
vcov. = NeweyWest(m1)
))

结果：
线性假设检验

假设：

模型 1：受限模型

模型 2：X[, 1] ~ X[, -1]

注意：提供系数协方差矩阵。

Res.Df Df F Pr(&gt;F) 
1 98 
2 80 18 6.8814 4.494e-10 ***

不使用 Newey-West：

(test &lt;- linearHypothesis(
model = m1,
hypothesis.matrix = (diag(m)[-c(1:2), ]),
rhs = rep(0, m - 2),
test = &quot;F&quot;
))

结果：
线性假设检验

假设：

模型 1：受限模型
模型 2：X[, 1] ~ X[, -1]

Res.Df RSS Df Sq F 之和Pr(&gt;F)
1 98 38.856 
2 80 31.982 18 6.8739 0.9552 0.5178
]]></description>
      <guid>https://stats.stackexchange.com/questions/654854/moderate-test-statistic-but-low-p-value-in-an-f-test</guid>
      <pubDate>Tue, 24 Sep 2024 15:26:30 GMT</pubDate>
    </item>
    <item>
      <title>如果生存模型中不包含时间因素，则误差量</title>
      <link>https://stats.stackexchange.com/questions/654834/amount-of-error-if-time-is-not-included-in-a-survival-model-as-a-factor</link>
      <description><![CDATA[有两种方法可以应用该模型（离散时间比例风险）：模型 A 和模型 B。
根据 Tutz 和 Schmid 关于离散时间生存模型的说法，当时间和链接函数之间存在线性关系时，可以使用模型 A。我的问题是，如果我们错误地选择了模型 A，即使关系不是线性的，误差量会是多少？
模式 A= glm (event event ~ Time + covariates, 
family=binomial(link=&quot;cloglog&quot;), data=m)
模式 B= glm (event event ~ factor(Time) + covariates, 
family=binomial(link=&quot;cloglog&quot;), data=m)


https://link.springer.com/book/10.1007/978-3-319-28158-2
]]></description>
      <guid>https://stats.stackexchange.com/questions/654834/amount-of-error-if-time-is-not-included-in-a-survival-model-as-a-factor</guid>
      <pubDate>Tue, 24 Sep 2024 09:44:41 GMT</pubDate>
    </item>
    <item>
      <title>LMM 中的非正态数据；初学者问题</title>
      <link>https://stats.stackexchange.com/questions/654824/non-normal-data-in-a-lmm-beginners-question</link>
      <description><![CDATA[我是统计学新手，正在寻求使用 R 分析蚯蚓对凋落物碳影响的指导。
我进行了一项实验，以评估蚯蚓存在（三个水平：无蚯蚓、一些蚯蚓、许多蚯蚓）和土壤类型（四个水平：小麦、玉米、南瓜和草莓生长的土壤）对两个时间间隔（三个月和五个月）内凋落物碳形成的影响。
这总共导致
3（蚯蚓）×4（作物）×2（时间）= 24 个处理
对于第一个时间间隔，我每个处理有 2 个重复；对于第二个间隔，我每个处理有 3 个重复。
我在 R 中构建了以下线性混合模型：
lmm_model1 &lt;- lmer(Litter_derived_total_C ~ worms + (1 | Crop) + (1 | time), data = dataCN)

残差的 QQ 图显示非正态性（图 1）。对数变换在组间方差相等方面略有改善。但是，残差正态性仍然是一个问题（图 2）。
问题：
鉴于残差不呈正态分布，我应该如何进行分析？您是否推荐其他模型或变换来解决正态性问题？任何有关模型诊断或改进的建议也将不胜感激。
图 1

图 2
]]></description>
      <guid>https://stats.stackexchange.com/questions/654824/non-normal-data-in-a-lmm-beginners-question</guid>
      <pubDate>Tue, 24 Sep 2024 07:28:02 GMT</pubDate>
    </item>
    <item>
      <title>使用 simr 计算线性混合模型中计划对比的功率和样本大小？</title>
      <link>https://stats.stackexchange.com/questions/654818/calculate-power-and-sample-size-for-planned-contrasts-in-linear-mixed-models-usi</link>
      <description><![CDATA[我在 R 中使用 lmerTest 包建立了一个线性混合模型，其中我有三个分类因子（A 有 3 个级别，B 有 8 个级别，C 有 2 个级别）和一个用于主题的随机效应。我有兴趣使用 simr 对 B 级别之间的两个特定计划对比进行功效分析。这可能吗？
例如，

比较 B1 和 B2，并比较 B3 和 B4，控制所有其他变量（如果模型不包含交互项）
比较 B1 和 B2，并在特定 A 级别 A2 比较 B3 和 B4（如果考虑 A 和 B 之间的交互）

我理解 simr 可以模拟模型中所有固定效应的功效和样本大小，因此我们可以通过将 B 的参考级别设置为 B1 来将 B1 与 B 的所有其他级别进行比较。但我不确定如何设置它来计算上述特定对比的功效。我也知道 emmeans 可以设置和计算事后对比，但有没有办法将它与 simr 集成以进行功效分析和大小调整？如果没有，那么适当的方法是什么？
有人可以分享使用 simr 模拟这些计划对比的功效和样本大小的经验吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654818/calculate-power-and-sample-size-for-planned-contrasts-in-linear-mixed-models-usi</guid>
      <pubDate>Tue, 24 Sep 2024 03:16:21 GMT</pubDate>
    </item>
    <item>
      <title>我们如何在 R 中计算一个数据集中的一个记录与第二个数据集中的所有记录之间的 Gower 距离？</title>
      <link>https://stats.stackexchange.com/questions/654811/how-do-we-calculate-the-gower-distance-between-one-record-in-one-dataset-and-all</link>
      <description><![CDATA[我想计算数据集 1 的一条记录与数据集 2 的所有记录之间的 Gower 距离。第一种方法如下
library(gower)

data(iris)
dat1 &lt;- iris[1:10,]
dat2 &lt;- iris[11:30,]

# 第一种方法
gower::gower_dist(dat1[1,], dat2)

这给了我长度为 20 的结果。
0.09079365 0.09873016 0.16142857 0.29476190 0.20920635 0.33079365 
0.21936508 0.05000000 0.23952381 0.11507937 0.12095238 0.15079365 
0.16984127 0.24523810 0.16539683 0.12920635 0.17206349 0.03555556 
0.02761905 0.14063492

我可以将第一个值解释为 dat1[1,] 和 dat2[1,] 之间的 gower 距离，将第二个值解释为 dat1[1,] 和 dat2[2,] 之间的 gower 距离，依此类推吗？
让我感到困惑的是，如果我计算
gower::gower_dist(dat1[1,],dat2[1,])

这给了我
0.75

这与 0.09079365 不同。最终，我想计算 dat1 中每个观测值与 dat2 中每个观测值的 Gower 距离。如果我使用第二种方法，我将需要在 dat2 中的所有观测值上添加一个 for 循环，如下所示。
# 第二种方法
for(i in 1:nrow(dat2)) {
print(gower::gower_dist(dat1[1,],dat2[i,]))
}

由于这两种方法给出的结果不同，我应该使用哪一种方法来实现目的？]]></description>
      <guid>https://stats.stackexchange.com/questions/654811/how-do-we-calculate-the-gower-distance-between-one-record-in-one-dataset-and-all</guid>
      <pubDate>Mon, 23 Sep 2024 17:37:36 GMT</pubDate>
    </item>
    <item>
      <title>使用观察到的效应量计算功效时样本量不一致</title>
      <link>https://stats.stackexchange.com/questions/654762/inconsistency-in-sample-size-from-power-calculation-using-the-observed-effect-si</link>
      <description><![CDATA[我最初的目标是确认我的功效计算的输入是正确的。
为此，我使用了从分析中获得的数字，并将它们放入 R 的功效计算函数 power.t.test() 中。
我的预期是，我将获得与研究中使用的样本量相同的样本量（假设我使用来自分析的输入参数）。然而，始终存在微小的差异。造成这种差异的原因是什么？
详细信息
我的直觉告诉我，如果观察到的效应大小（差异和残差标准误差）与真实效应大小（$H_A$）相对应，那么在未来的一半实验中，我们应该得到比观察到的更小的 p 值，而在一半实验中，我们应该得到比观察到的更大的 p 值。因此，我们应该在具有观察到的参数（包括 p 值作为显着性水平）的功效分析中获得 50% 的功效。

或者，我也可以固定 50% 的功效，并且应该获得与观察到的相同的样本量。
下面是分析的输出，我从中获取了输入参数。
set.seed(1)
sample_size &lt;- 5
dat &lt;- data.frame(y = rnorm(sample_size*2, mean = rep(c(0,1), each = sample_size), sd = 0.8),
x = rep(c(&quot;a&quot;, &quot;b&quot;), each = sample_size))
(s &lt;- summary(lm(y ~ x, data = dat)))
## 
## 调用：
## lm(formula = y ~ x, data = dat)
## 
## 残差：
## 最小值 1Q 中位数 3Q 最大值 
## -0.7719 -0.5415 0.1018 0.3348 1.1728 
## 
## 系数：
## 估计标准误差 t 值 Pr(&gt;|t|) 
## (截距) 0.1034 0.2962 0.349 0.7360 
## xb 1.0047 0.4189 2.398 0.0433 *
## ---
## 显著性代码：0&#39;***&#39;0.001&#39;**&#39;0.01&#39;*&#39;0.05&#39;.&#39; 0.1 &#39; &#39; 1
## 
## 残差标准误差：8 个自由度上的 0.6623
## 多重 R 平方：0.4183，调整后的 R 平方：0.3456 
## F 统计量：1 和 8 DF 上的 5.752，p 值：0.04329

p 值除以 2，这样它就对应于单侧检验。
power.t.test(delta = 1.004693, sd = 0.662344, sig.level = 0.04328541/2,
power = 0.5, alternative = &quot;one.sided&quot;)
## 
## 双样本 t 检验功效计算 
##
## n = 4.759026
## delta = 1.004693
## sd = 0.662344
## sig.level = 0.02164271
## power = 0.5
## alternative = one.sided
## 
## 注意：n 是*每个*组中的数字

正如您在输出中看到的那样，样本大小略有偏差 ≈ 0.25（n = 4.76 而不是 5）。如果我针对不同的样本量重复模拟，我会得到以下图片

差异始终为 0.25（采样量越大，方差越小）。
问题

为什么功效计算会导致样本量较小？我的直觉有什么问题？
为什么是 0.25？也许与自由度以及残差标准误差（$\frac{SSR}{n-2}$）的估计方式有关？
]]></description>
      <guid>https://stats.stackexchange.com/questions/654762/inconsistency-in-sample-size-from-power-calculation-using-the-observed-effect-si</guid>
      <pubDate>Mon, 23 Sep 2024 08:36:54 GMT</pubDate>
    </item>
    <item>
      <title>离散随机变量的 CDF 分段常数？</title>
      <link>https://stats.stackexchange.com/questions/654695/cdf-of-a-discrete-random-variable-piecewise-constant</link>
      <description><![CDATA[在我的脚本中，它说：

给定$X$是一个离散随机变量，$\Bbb P(X\in D)=1,D=\{a_1,a_2,\ldots\},p_i:=\Bbb P_X(\{a_i\})&gt;0,\forall i\ge1,$我们有$F_X(x)=\sum\limits_{a_i\le x}p_i,$这意味着离散随机变量的CDF是分段常数。

我的想法
假设$X:\Omega\to\Bbb R$是一个离散随机变量，其中$\Bbb P_X(\{q_i\})=\frac1{2^i}&gt;0,$，其中$\{q_i\}_{i\in\Bbb N}$是$\Bbb Q.$的枚举，因为$\Bbb Q$是稠密的，所以对于每两个$x_1,x_2\in\Bbb R,x_1&lt;x_2,$，存在某个$q_j\in(x_1,x_2)$，意味着$q_j\in(x_1,x_2)$ class=&quot;math-container&quot;&gt;$F_X(x_1)&lt;F_X(x_2).$ 因此，它似乎与 $F_X$ 是分段常数的说法相矛盾，这让我怀疑如果该说法成立，我的随机变量 $X$ 是否存在。
问题：任何离散随机变量的 CDF 确实是分段常数吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654695/cdf-of-a-discrete-random-variable-piecewise-constant</guid>
      <pubDate>Sat, 21 Sep 2024 13:03:38 GMT</pubDate>
    </item>
    <item>
      <title>为什么 r 包/函数“plm”会报告随机效应模型的 z 统计量和固定效应模型的 t 统计量？</title>
      <link>https://stats.stackexchange.com/questions/654625/why-does-the-r-package-function-plm-report-a-z-statistic-for-a-random-effects</link>
      <description><![CDATA[从帮助文件中的 plm 包中获取示例，
data(&quot;Grunfeld&quot;, package = &quot;plm&quot;)
wi &lt;- plm(inv ~ value + capital,
data = Grunfeld, model = &quot;within&quot;, effect = &quot;twoways&quot;)
swar &lt;- plm(inv ~ value + capital,
data = Grunfeld, model = &quot;random&quot;, effect = &quot;twoways&quot;)
summary(wi)

给出输出
Twoways effects Within Model

调用：
plm(formula = inv ~ value + capital, data = Grunfeld, effect = &quot;twoways&quot;, 
model = &quot;within&quot;)

Balanced Panel: n = 10, T = 20, N = 200

残差：
最小值 第 1 区 中位数 第 3 区 最大值
-162.6094 -19.4710 -1.2669 19.1277 211.8420

系数：
估计标准误差 t 值 Pr(&gt;|t|)
值 0.117716 0.013751 8.5604 6.653e-15 ***
资本 0.357916 0.022719 15.7540 &lt; 2.2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

总平方和：1615600
残差平方和：452150
R 平方：0.72015
调整 R 平方：0.67047
F 统计量：2 和 169 DF 上的 217.442，p 值：&lt; 2.22e-16

并且
summary(swar)

给出
双向效应随机效应模型 
（Swamy-Arora 变换）

调用：
plm(formula = inv ~ value + capital, data = Grunfeld, effect = &quot;twoways&quot;, 
model = &quot;random&quot;)

平衡面板：n = 10, T = 20, N = 200

效应：
var std.dev share
idiosyncratic 2675.43 51.72 0.274
individual 7095.25 84.23 0.726
time 0.00 0.00 0.000
theta： 0.864 (id) 0 (时间) 0 (总计)

残差：
最小值 第 1 区 中位数 第 3 区 最大值
-177.1700 -19.7576 4.6048 19.4676 252.7596

系数：
估计标准误差 z 值 Pr(&gt;|z|) 
(截距) -57.865377 29.393359 -1.9687 0.04899 *
值 0.109790 0.010528 10.4285 &lt; 2e-16 ***
资本 0.308190 0.017171 17.9483 &lt; 2e-16 ***
---
显著性代码：0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

总平方和：2376000
残差平方和：547910
R 平方：0.7694
调整 R 平方：0.76706
Chisq：2 DF 上的 657.295，p 值：&lt; 2.22e-16

所以（简单的）问题是，为什么 plm 摘要会报告固定效应（即“内部”）模型的参数检验的 t 统计量，以及随机效应模型的参数检验的 z 统计量？我怀疑这只是简单的任意表现不一致，但我有兴趣知道是否有更深层次的原因。]]></description>
      <guid>https://stats.stackexchange.com/questions/654625/why-does-the-r-package-function-plm-report-a-z-statistic-for-a-random-effects</guid>
      <pubDate>Fri, 20 Sep 2024 02:56:10 GMT</pubDate>
    </item>
    </channel>
</rss>