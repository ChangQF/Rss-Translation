<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 21 Jul 2024 15:15:56 GMT</lastBuildDate>
    <item>
      <title>生存分析中不相互排斥的竞争风险</title>
      <link>https://stats.stackexchange.com/questions/651481/competing-risks-that-are-not-mutually-exclusive-in-survival-analysis</link>
      <description><![CDATA[我有 5 种类型的事件可供主体体验。但是，并非所有这些事件都相互竞争：对于事件 A、B、C、D、E，A 的发生会阻止 B 的发生。B、D 和 E 相互排斥，而 C 的发生会阻止所有其他事件。我想使用 Aalen-Johansen 估计器估计每个事件的累积发生率，但我不确定如何处理和解释这些相互竞争的情况。]]></description>
      <guid>https://stats.stackexchange.com/questions/651481/competing-risks-that-are-not-mutually-exclusive-in-survival-analysis</guid>
      <pubDate>Sun, 21 Jul 2024 15:14:12 GMT</pubDate>
    </item>
    <item>
      <title>处理具有大量异常值的数据集[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651479/dealing-with-a-dataset-with-huge-outliers</link>
      <description><![CDATA[我正在研究一个少于 100 个样本、大约 20 个特征的数据集。这个数据集与医学物理领域中与肺和心脏等器官相关的参数的多元回归问题有关。这个数据集的奇怪之处在于与肺相关的目标值有关。事实上，肺在不同的人身上有很大的差异，因此，这种类型的目标值中存在大量异常数据，这导致其中出现大量过度拟合。你认为我该如何处理这个数据集？]]></description>
      <guid>https://stats.stackexchange.com/questions/651479/dealing-with-a-dataset-with-huge-outliers</guid>
      <pubDate>Sun, 21 Jul 2024 11:55:08 GMT</pubDate>
    </item>
    <item>
      <title>具有多个时间段的 Diff-in-Diff</title>
      <link>https://stats.stackexchange.com/questions/651478/diff-in-diff-with-multiple-time-periods</link>
      <description><![CDATA[这是我在这里的第一篇帖子，我还是个新手，希望这篇文章能说清楚。
背景：
对于我的硕士论文，我想估计重复对论文引用的影响。为此，我想比较曾经重复过的论文和没有重复过的论文的引用。
我的导师告诉我，考虑到我的因变量的性质（引用是一个非负计数数字），更合适的模型是交错式差异分析，并采用泊松回归。但是，他告诉我尝试初始的“简单”差异分析来查看结果，即使结果可能有偏差。
在我的数据集中，我有大约 80 篇在不同时间点重复的论文（因此是我的治疗组），以及 160 篇从未重复的论文（对照组）。为了确保可比性，我只选取在同一期刊、卷、期上发表、涉及相同主题或 JEL 代码的实证论文。以下是一个片段：

因此，如果我们查看一个简单的 DiD 方程，并将其应用于我的数据，这就是我想要估计的：

其中，replicated 是治疗虚拟变量（如果已复制则为 1，如果从未复制则为 0），d_time 是时间虚拟变量（before=0 并且after=1)。
我在这里看到的问题是，我的对照组没有“之后”，因为这些论文从未被复制过，而且我无法获取单个处理过的论文的“之后”，因为所有论文的处理年份都不同（有些重复，但一般是 15 年）。因此，我的时间虚拟变量的构造使我的对照组的 d_time 始终为 0（replicated=0），
如果我运行这样的模型，由于交互项和 d_time 之间存在完全共线性，因此我的交互项会被省略。我在这里遗漏了什么？
现在，我知道这是“基本” DiD 模型，由于我的数据的性质，这可能会导致一些规范问题。但我想在尝试任何其他更高级的方法之前实现它。有人有什么建议吗？
（我试图理解 Callaway 和 Sant&#39;Ana 关于交错方法的论文，但我无法理解该模型的实施和解释。因为据我所知，如果在另一篇论文之后进行处理，每篇经过处理的论文都可以作为对照论文（例如：2015 年的重复论文可以作为 2010 年重复论文的对照论文，依此类推）。但是，我只想比较从未重复的论文和重复的论文，因此我不确定这是否是最好的方法）]]></description>
      <guid>https://stats.stackexchange.com/questions/651478/diff-in-diff-with-multiple-time-periods</guid>
      <pubDate>Sun, 21 Jul 2024 11:49:31 GMT</pubDate>
    </item>
    <item>
      <title>使用未观察组件模型时，首选的程序和相关方法是什么？</title>
      <link>https://stats.stackexchange.com/questions/651477/what-is-the-preferred-procedure-and-associated-methods-when-using-an-unobserved</link>
      <description><![CDATA[首先我要说的是，我的统计知识非常有限。如果您发现我的思维方式有任何错误，或者有任何好的初学者参考资料供我进一步阅读我将要描述的主题，请告诉我。
我有一个数据库，其中包含来自各个来源的按国家/地区每年的治理指标（对于那些感兴趣的人：世界银行的全球治理指标）。我想将其中一些指标组合在一起并创建一个综合指数。这需要为指标分配权重。鉴于各种来源和方法论的差异，主成分分析似乎不太合适。相反，我想到使用具有趋势成分的未观察成分模型 (UCM)，类似于全球治理指标。这样，我可以使用趋势来衡量一些潜在的治理概念。但是，由于我正在改变他们的程序，我必须自己弄清楚，而不是能够复制他们的步骤。
因此，我试图弄清楚在创建这个综合指数时要遵循哪些步骤。我有一个大概的提纲，但想知道一些更具体的步骤以及最适合执行它们的方法

标准化数据：所有数据都使用最小-最大方法标准化为 0-1 的范围
考虑缺失值：有很多缺失值，因为并非所有年份和所有国家都得到一致测量。我仍在尝试找出最佳处理方法
加权和聚合：要计算赋予值的权重，我想使用 UCM，这需要估计相关参数。我读过我可以使用 MLE 或贝叶斯方法，但我不知道在哪种情况下哪种方法更可取
根据 UCM 确定的权重，计算每个国家每年值的加权平均值

这些仍然很笼统，我想寻求帮助来充实这个过程。此外，如果您愿意成为我的陪练伙伴，向我提出一些更一般的问题，我也将不胜感激。
提前谢谢您！]]></description>
      <guid>https://stats.stackexchange.com/questions/651477/what-is-the-preferred-procedure-and-associated-methods-when-using-an-unobserved</guid>
      <pubDate>Sun, 21 Jul 2024 11:46:20 GMT</pubDate>
    </item>
    <item>
      <title>b(n,p) 的峰度 - 二项分布</title>
      <link>https://stats.stackexchange.com/questions/651472/kurtosis-of-bn-p-binomial-distribution</link>
      <description><![CDATA[所以我遇到了这个问题，正在尝试解决。
我已经研究了好几个小时了。
这是为了找到二项分布的峰度。
到目前为止，我有 M’’’’(0) = $n[(n-1)(n-2)(n-3)p^4 + 6(n-1)(n-2)p^3 +7(n-1)p^2 + p]$
然后对于 $\frac{E(X^4) - 4\mu E(X^3) + 6\mu^2 E(X^2) - 4\mu^3 E(X) + \mu^4}{\sigma^4} =$
$\frac{n[(n-1)(n-2)(n-3)p^4 + 6(n-1)(n-2)p^3 +7(n-1)p^2 + p] - 4(n[(n-1)(n-2)p^3 +3(n-1)p^2 + p + 6(np)^2(np + n(n-1)p^2 - 4(np)^3 + (np)^4}{(\sqrt{np(1-p)})^4} =$
从那里我似乎无法得到 $\frac{1-6(1-p)}{np(1-p)}$。
我知道这都是简化，但我似乎无法正确理解。]]></description>
      <guid>https://stats.stackexchange.com/questions/651472/kurtosis-of-bn-p-binomial-distribution</guid>
      <pubDate>Sun, 21 Jul 2024 06:45:53 GMT</pubDate>
    </item>
    <item>
      <title>最近（>2015 年）关于变量误差模型的学术介绍有哪些？</title>
      <link>https://stats.stackexchange.com/questions/651471/what-is-a-good-recent-2015-academic-introduction-to-errors-in-variables-mode</link>
      <description><![CDATA[我知道这个资源 https://en.wikipedia.org/wiki/Errors-in-variables_models，但我不太相信维基百科上关于统计的文章，所以我正在寻找一些关于这个主题的学术参考资料。如果它能帮助我提出一些建议，我已经熟悉标准回归模型，对混合模型也有点了解。
你有什么好的建议吗？如果它只是教科书中的一章，只要它涵盖基础知识并（理想情况下）建议进一步的资源，我就会感兴趣。如果该资源是旧资源的新版本，我也会感兴趣。干杯，]]></description>
      <guid>https://stats.stackexchange.com/questions/651471/what-is-a-good-recent-2015-academic-introduction-to-errors-in-variables-mode</guid>
      <pubDate>Sun, 21 Jul 2024 06:16:49 GMT</pubDate>
    </item>
    <item>
      <title>当 Fisher 信息矩阵不可逆时，最大似然估计量？</title>
      <link>https://stats.stackexchange.com/questions/651470/maximum-likelihood-estimator-when-the-fisher-information-matrix-is-not-invertibl</link>
      <description><![CDATA[据已知，最大似然估计 (MLE) 是渐近有效的，即$\sqrt{n\,}\,\left( \widehat{\theta \,}_{\mathrm{mle}}-\theta _0 \right) $ 在分布上收敛到多元正态分布，其均值为零，协方差矩阵为 Fisher 信息矩阵 (FIM) $\mathcal{I} $ 的逆。也就是说，我们有
$$
\sqrt{n\,}\,\left( \widehat{\theta \,}_{\mathrm{mle}}-\theta _0 \right) \,\, \xrightarrow{d}\,\, \mathcal{N} \left( 0, \mathcal{I} ^{-1} \right) \tag1.
$$
我的问题是，当 Fisher 信息矩阵不可逆时，我们是否仍然可以得到类似的 MLE 结果，即 eq(1)，其中 FIM 的逆被 moore-penrose 广义逆 取代？]]></description>
      <guid>https://stats.stackexchange.com/questions/651470/maximum-likelihood-estimator-when-the-fisher-information-matrix-is-not-invertibl</guid>
      <pubDate>Sun, 21 Jul 2024 06:15:43 GMT</pubDate>
    </item>
    <item>
      <title>分数布朗运动参数估计中的偏差估计（逆转对数变换后）</title>
      <link>https://stats.stackexchange.com/questions/651469/bias-estimation-after-reversing-the-log-transformation-in-parameter-estimation</link>
      <description><![CDATA[我正在学习这两篇文献，
1 [分数布朗运动的模拟与识别：文献和比较研究 COEURJOLLY Jean-François]
2 [通过离散样本路径变化估计分数布朗运动的参数 JEAN-FRANÇOIS COEURJOLLY]
我坚持理解 fBm 的缩放参数 $C$ 的偏差。此参数 $C$ 是通过对数据进行对数变换（以获得线性）、执行 OLS 然后再变换回来获得的。
因此，$C$ 的估计量是一个有偏估计量。
我检查了作者如何估计偏差的代码，但我无法弄清楚作者到底在做什么，因为两篇文献中都没有提到偏差估计。
从代码中我可以看出，作者试图使用渐近方差来估计方差，但它与下面的方差公式并不完全匹配
我在下面粘贴了文献和代码的相关部分。代码似乎使用了 Digamma 函数的渐近展开。
所以我想问一下这里执行的是哪种偏差校正？如果可能的话，为什么 Digamma 函数的扩展在这里？

]]></description>
      <guid>https://stats.stackexchange.com/questions/651469/bias-estimation-after-reversing-the-log-transformation-in-parameter-estimation</guid>
      <pubDate>Sun, 21 Jul 2024 04:19:33 GMT</pubDate>
    </item>
    <item>
      <title>如何计算存在双零的 k 均值聚类？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/651474/how-to-calculate-k-means-clustering-with-presence-of-double-zeroes</link>
      <description><![CDATA[我尝试使用具有双零的数据集来查找物种组合。当我运行测试时，结果不确定，并且似乎没有组是显著的。
我使用了 hellinger 变换和 chord 变换，并运行了 vegan 包中的 cascadeKM 函数，但 Calinski 标准似乎表明最佳聚类为 18 个组（这是我可以拥有的最大组数），而 SSI 标准似乎表明最佳聚类为 11 个组。
但是，当我运行 kendall.global 测试时，没有一个组是显著的？这些是否是用于我的物种丰度矩阵的最佳变换？这是否意味着没有物种彼此相关？]]></description>
      <guid>https://stats.stackexchange.com/questions/651474/how-to-calculate-k-means-clustering-with-presence-of-double-zeroes</guid>
      <pubDate>Sun, 21 Jul 2024 00:49:36 GMT</pubDate>
    </item>
    <item>
      <title>不可靠测量的方差分析</title>
      <link>https://stats.stackexchange.com/questions/651443/anova-with-unreliable-measure</link>
      <description><![CDATA[我正在做一些关于体育科学的文献综述，特别是训练对耐力的影响。
没有标准的耐力测试。有些测试包括间歇性收缩，直到筋疲力尽，然后测量最终的力量。
有些测试已成为研究的主题，以获得 ICC、LoA 或其他会话间可靠性指标，而有些则没有。有些被发现具有较低的 ICC（&lt;0.8）或非常大的 LoA（+/- 40%）。
我遇到过一些研究训练对耐力的影响的研究。他们对一组人进行耐力测试，然后让他们接受训练，并进行另一次耐力测试。然后他们进行单向方差分析以确定耐力是否有显著提高。但是，其中一些研究使用了尚未表征的耐力测试，从未进行过任何重测信度评估。
所以我的问题是：如果使用的测量方法不可靠或可靠性未知，方差分析能否得出显着差异的结论？
这对我来说似乎很奇怪，因为这就像使用不可靠的量表而不知道其标准误差一样。]]></description>
      <guid>https://stats.stackexchange.com/questions/651443/anova-with-unreliable-measure</guid>
      <pubDate>Sat, 20 Jul 2024 09:54:24 GMT</pubDate>
    </item>
    <item>
      <title>如何预测变换后的时间序列数据？</title>
      <link>https://stats.stackexchange.com/questions/651425/how-can-you-forecast-transformed-time-series-data</link>
      <description><![CDATA[我有包含趋势和季节性成分的时间序列数据。我使用以下方法从数据中删除了它：
 remove_seasonality &lt;- function(x) {
t &lt;- seq_along(x)
sin_term &lt;- sin(2 * pi * t / 52)
cos_term &lt;- cos(2 * pi * t / 52)
lm_model &lt;- lm(x ~ sin_term + cos_term)
residuals(lm_model)
}
subset_data_two$x_deseasonalized &lt;- remove_seasonality(subset_data_two$Nitrogen_Dioxide)
detrended_data &lt;- subset_data_two

split_data &lt;- function(data, train_or_test, prop) {
ordered_data &lt;- data[order(data$Date), ]
row_count &lt;- nrow(ordered_data)
train_size &lt;- round(prop * row_count)

if (train_or_test == &quot;train&quot;) {
train_data &lt;- ordered_data[1:train_size, ]
return(train_data)
} else if (train_or_test == &quot;test&quot;) {
test_data &lt;- ordered_data[(train_size + 1):row_count, ]
return(test_data)
} else {
stop(&quot;train_or_test 必须是 &#39;train&#39; 或 &#39;test&#39;&quot;)
}
}
training_data &lt;- split_data(detrended_data, &quot;train&quot;, 0.85)
test_data &lt;- split_data(detrended_data, &quot;test&quot;, 0.85)

# 3.0 拟合模型
fix &lt;- training_data[,c(&quot;Date&quot;, &quot;x_deseasonalized&quot;)]
fixed_tseries &lt;- read.zoo(fix)
three_plots(fixed_tseries, &quot;时间序列：从固定 x 到固定 x 的平稳序列&quot;)

fix_model &lt;- arima(fix$x_deseasonalized, order=c(1,0,1))
three_plots(fix_model$residuals, &quot;AR(1)MA(1) 时间序列&quot;)

# 4.0 预测
forecasted &lt;- Forecast(fix_model, h = 31)

然后我能够使用平稳数据拟合 ARMA(1,1) 模型。
我现在想预测 n 步。我知道 predict() 函数采用转换后的模型，并且我相信新的平稳 x 值 (data$x_fixed)，但我不知道在哪里应用原始趋势/季节性转换以使预测变得非平稳？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/651425/how-can-you-forecast-transformed-time-series-data</guid>
      <pubDate>Fri, 19 Jul 2024 20:05:26 GMT</pubDate>
    </item>
    <item>
      <title>帮助进行概率测试，比较两个实体之间预期数字的存在/不存在</title>
      <link>https://stats.stackexchange.com/questions/651419/help-for-a-probability-test-comparing-presence-absence-of-expected-number-betwee</link>
      <description><![CDATA[我有一个概率问题，我不知道如何解决。
在这个问题中，我有一个 VirusA 的基因组，其中有 100 个基因，我知道其中 20/100 是该病毒所特有的。
另一方面，我有另一个不完整的 VirusB（我没有对所有病毒进行测序），其中 40/100 的 VirusA 基因存在于 VirusB 中。而 VirusA 特有的基因中没有一个存在于 VirusB 中。
那么我的问题如下：
偶然看到它的概率是多少？我的意思是 VirusA 中所有独特基因都未在 VirusB 中被偶然采样的概率是多少？
我需要这个概率来表明，由于我没有在 VirusB 中获得任何 VirusA 基因，即使 VirusB 不完整，它与 VirusA 相同的概率也很低。
感谢您的帮助。
这种方法是否正确？
# VirusA 中的总基因
total_genes &lt;- 100

# VirusA 中的独特基因
unique_genes &lt;- 20

# VirusB 中存在的基因
genes_in_virusB &lt;- 40

# VirusB 中的非独特基因VirusA
non_unique_genes &lt;- total_genes - unique_genes

# 计算二项式系数
total_ways &lt;- choose(total_genes, genes_in_virusB)
non_unique_ways &lt;- choose(non_unique_genes, genes_in_virusB)

# 计算概率
probability &lt;- non_unique_ways / total_ways
print(probability)
]]></description>
      <guid>https://stats.stackexchange.com/questions/651419/help-for-a-probability-test-comparing-presence-absence-of-expected-number-betwee</guid>
      <pubDate>Fri, 19 Jul 2024 17:03:12 GMT</pubDate>
    </item>
    <item>
      <title>预测区间准确度与均方误差之间的权衡</title>
      <link>https://stats.stackexchange.com/questions/651367/tradeoff-between-prediction-interval-accuracy-mean-squared-error</link>
      <description><![CDATA[我的目标是量化气候协变量与 GDP 回归模型中的预测不确定性。我从一个模型开始，该模型以温度作为三次多项式，国家固定效应（$\alpha_i$}，年份固定效应（$\theta_t$）和国家增量时间趋势（$\gamma_i$）。
$$ 
GDP_{it} = \beta_1 * Temp_{it} + \beta_2 * Temp^2_{it} + \beta_3 * Temp^3_{it} + \alpha_i + \theta_t + \gamma_i
$$
我使用一些保留数据来收集上述模型的样本外均方误差。我还使用样本外预测的标准误差来构建 95% 的预测间隔，然后检查实际 Y（GDP）值在这些间隔内的实际百分比作为预测间隔准确度。
样本外 MSE：0.017
样本外预测间隔准确度：0.577

为了使预测间隔准确度更接近 95% 的目标，我尝试了一个具有更高次数多项式时间趋势的不同模型，如下所示：
$$ 
GDP_{it} = \beta_1 * Temp_{it} + \beta_2 * Temp^2_{it} + \beta_3 * Temp^3_{it} + \alpha_i + \theta_t + \gamma_i + \gamma^2_i + \gamma^3_i
$$
样本外 MSE： 0.018
样本外预测区间准确度：0.722

由于预测区间更宽，预测区间准确度大大提高，这可能是因为模型在训练数据中纳入了更多方差。但是，可能由于额外的模型复杂性导致过度拟合，第二个模型的 MSE 高于第一个模型。
我的问题与这个特定示例关系不大，而是与我普遍观察到的这种现象关系更大。我想知道：

是否存在一个单一的潜在现象，可以解释为什么增加模型复杂度会导致样本外预测区间更接近 95% 的目标，同时增加模型的样本外 MSE，或者这些本质上是独立的观察结果？

如果我的目标是尽可能量化模型不确定性，那么如何正确考虑以更高质量（在这种情况下意味着更宽）的样本外预测区间换取随后的样本外 MSE 增加？

]]></description>
      <guid>https://stats.stackexchange.com/questions/651367/tradeoff-between-prediction-interval-accuracy-mean-squared-error</guid>
      <pubDate>Thu, 18 Jul 2024 20:44:03 GMT</pubDate>
    </item>
    <item>
      <title>治疗前后（包括对照）的泊松双向方差分析</title>
      <link>https://stats.stackexchange.com/questions/651298/poisson-two-way-anova-test-for-before-and-after-treatment-including-a-control</link>
      <description><![CDATA[我无法确定在此实验设计中使用哪种类型的测试：
我的数据如下：

我有 10 个治疗点和 4 个对照点
我对每个治疗点和对照点进行了 128 次重复，其中 64 次是在治疗前，64 次是在治疗后
对照点位于治疗区域之外（即施工区域），治疗点是治疗发生区域
我有一年的四个季节（春、秋、夏、冬）——也许这可以视为随机变量

我想知道治疗是否导致基于计数的因变量与对照相比下降。
我认为应该采用类似泊松方差分析的重复测量方法。我也不确定要使用什么事后检验，因为站点可能有很大差异，所以我想在初始方差分析之后进行成对比较（可能是 Wilcoxon 符号秩检验）。
希望你能帮助我。]]></description>
      <guid>https://stats.stackexchange.com/questions/651298/poisson-two-way-anova-test-for-before-and-after-treatment-including-a-control</guid>
      <pubDate>Thu, 18 Jul 2024 00:56:48 GMT</pubDate>
    </item>
    <item>
      <title>交叉熵和 MLE 之间的联系</title>
      <link>https://stats.stackexchange.com/questions/650884/link-between-cross-entropy-and-mle</link>
      <description><![CDATA[有许多材料显示了MLE 和交叉熵之间的关系。
通常，这些是显示 I.I.D 数据生成过程 $D = (X,Y)$ 的关系所采取的步骤：
$$
L(D) = \prod_{i=1}^N p(x_i, y_i; \theta)
$$
将可能性除以 num。样本$N$，并在两边取$\log$，因为这两个操作都不会影响最优模型参数估计$\theta^*$
$$
\frac{1}{N} \times \log(L(D)) = \frac{1}{N} \times \sum_{i=1}^N log(p(x_i, y_i; \theta))
$$
最后，这相当于经验分布和模型分布之间的交叉熵。
$$
\frac{1}{N} \times \sum_{i=1}^N log(p(x_i, y_i; \theta)) = \mathbb{E}_{p_{data}}[log(p_{model}(x,y;\theta))]
$$
我有几个问题：

如果数据生成过程不是 I.I.D 会怎样？这种关系还成立吗？

为什么这种关系很特殊，它如何帮助参数估计？鉴于 MLE 和交叉熵都给出了完全相同的最佳模型参数 $\theta^*$。

]]></description>
      <guid>https://stats.stackexchange.com/questions/650884/link-between-cross-entropy-and-mle</guid>
      <pubDate>Thu, 11 Jul 2024 15:13:46 GMT</pubDate>
    </item>
    </channel>
</rss>