<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 17 Dec 2024 18:25:24 GMT</lastBuildDate>
    <item>
      <title>单向随机效应方差分析中的方差分量检验</title>
      <link>https://stats.stackexchange.com/questions/658891/test-of-variance-component-in-one-way-random-effects-anova</link>
      <description><![CDATA[我对以下内容对 Raudenbush 和 Bryk（2002 年，第 63-64 页）中列出的单方差分量检验的适应性有疑问。假设是关于随机效应矩阵的单个成分 $\textbf{T}$
$$
H_0:\tau_{qq} =0,
$$
其中 $\tau_{qq} = \text{Var}(\beta_{qj})$，系数 $p$ 跨越 $j$ 个组或簇。
定义 $\hat{V}_{qqj} = \hat{\sigma}^{2}(\textbf{X}_{j}^{T} \textbf{X}_{j})^{-1}$ 并在零假设下假设特定$\beta_{q}$没有方差：
$$
\beta_{qj} = \gamma_{q0} + \sum_{s = 1}^{S_{q}} \gamma_{qs} W_{sj}
$$
（即，没有添加随机效应$u_{qj}$），所得比率的分布大致为$\chi^{2}$，其中$df = J-S_{q}-1$：
$$
\frac{\sum_{j}(\hat{\beta_{qj}} - \hat{\gamma_{q0}} - \sum_{s=1}^{S_{q}}\hat{\gamma_{qs}}W_{sj})^{2}}{\hat{V}_{qqj}} 
$$
较小的值与零值一致（即，用较大的$\chi^{2}$ / 较小的$p$值拒绝）。
在具有随机效应的简单单向方差分析的情况下，上述内容简化为 (p. 71):
$$
\frac{\sum_{j} n_j(\bar{Y}_{.j} - \hat{\gamma_{00}})}{\hat{\sigma}^2}
$$
由于模型在零假设（即无随机效应）下仅为 $Y_{ij} = \gamma_{00} + r_{ij}$。
现在我的问题来了！
在多参数情况下以及一般情况下，人们可以使用基于偏差的似然比检验来检验有关 $\textbf{T}$ 结构的假设（如第 64 页以及本网站的许多地方所述）。出于教学原因（即向我的学生展示），我尝试直接实施 $\chi^{2}$ 测试，使用 lme4 或 nlme 的输出。nlme 与 R &amp; B 使用的 High School and Beyond 数据集一起分发，除了这个有点做作的例子外，这本书的结果很容易复制。他们的软件 (HLM7) 显然会吐出测试。
为了检查，我拟合了一个仅具有截距的 gls 模型（预测数学成绩），并使用 lme（基于模型偏差）计算了该模型与具有随机截距的模型的似然比检验。结果有些接近，但没有直接 $\chi^{2}$ 方法那么大：
$$
\text{LR-test}：986.12\\
\chi^{2}\text{ 来自 R&amp;B (p. 70)} 的结果：1660.2
$$
我很想了解一下这两个测试之间的差异，以及使用“lme”或“merMod”对象中的信息计算单向方差分析情况的方法。我不知道如何获得分子而不直接计算它。]]></description>
      <guid>https://stats.stackexchange.com/questions/658891/test-of-variance-component-in-one-way-random-effects-anova</guid>
      <pubDate>Tue, 17 Dec 2024 17:47:19 GMT</pubDate>
    </item>
    <item>
      <title>gam() 的 AIC 比 lm() 的 AIC 好得多，但拟合线看起来很好？</title>
      <link>https://stats.stackexchange.com/questions/658889/gams-aic-much-better-than-lms-aic-but-the-fitted-line-looks-just-fine</link>
      <description><![CDATA[我正在对变量 x 上的变量 y 进行线性回归和广义加性模型拟合。
x &lt;- c(-0.753828171223374, -0.702421304886483, -0.525922071232559, 
-0.499368711904991, -0.494072179316426, -0.408973650360027, -0.402501994567026, 
-0.393058036248241, -0.392954967411319, -0.37951900393503, -0.358729140897481, 
-0.354401065704234, -0.351959888288872, -0.347631549547629, -0.336772700038351, 
-0.331820704037377, -0.320011921562785, -0.276909999285465, -0.266889198383766, 
-0.246941396419386, -0.244771638528946, -0.241667325754278, -0.239862531253802, 
-0.239185579638141, -0.217923773010234, -0.210894666779951, -0.202232589003839, 
-0.201577138947226, -0.189989677738178, -0.170028487080187, -0.169948604137679, 
-0.1681371544387, -0.162139417875546, -0.161745070325861, -0.156213109801138, 
-0.15493800075576​​, -0.148175380031207, -0.144384450725271, -0.133817109830678, 
-0.129777063600703, -0.1292091226338, -0.125152129666695, -0.118735714834316, 
-0.111943843076971, -0.111034497847886, -0.108324755495965, -0.102007561490731, 
-0.0995348705098378, -0.0975507338173421, -0.0967166195464575, 
-0.0960915620786561, -0.0952305897001864, -0.0918858930340224, 
-0.0872704628484125, -0.0819739302598472, -0.0814370678277665, 
-0.0799673929994122, -0.0746482691048439, -0.0731783844597705, 
-0.0687800157013639, -0.0676255991392163, -0.0668859451913174, 
-0.0618632353474433, -0.0608624334403485, -0.0581546269777062, 
-0.0577473682846916, -0.0550799073614832, -0.0543448633682753, 
-0.0492788317611553, -0.0492650199318009, -0.0346679553082839, 
-0.0328026677594039, -0.0321049879170871, -0.028895963635458, 
-0.0288372399469618, -0.0253752723256008, -0.024884201232001, 
-0.0219161736261679, -0.0218622913269024, -0.0165961745229844, 
-0.0151535738668643, -0.0141964280835251, -0.011901707954635, 
-0.010745658280727, -0.00886098925906957, -0.00827629311172754, 
-0.00717935456553159, -0.00585307757528461, -0.00432924344834757, 
-0.00417077611570543, -0.00161521775514871, 0.00116096458829085, 
0.00124274561578785, 0.00405340513681626, 0.00650198240222148, 
0.00781442918023, 0.0098245558005554, 0.00983836762990968, 0.011862327044839, 
0.0127208310401385)

y &lt;- c(1.33172309918366, 1.29234488688529, 1.16009460627154、1.14061600316299、 
1.13674431384791、1.07517693128238、1.07054498210084、1.0637986685122、 
1.06372512642011、1.05415410073461、1.03940703453916、1.03634657979141、 
1.03462185255625、1.03156643151142、1.02391581222465、 1.02043391177591, 
1.01214868032632、0.982124153875601、0.975193052917491、0.961451930427496、 
0.959961824357313、0.957831458685827、0.95659374398089、0.95612965570678、 
0.941598163079392、0.93681323423608、0.930929874764137、0.93048528155551、 
0.922639340714301、0.909185402331939、0.90913171917749、0.907914724026396、 
0.903889893760358、0.903625514712141、0.899920043104334、0.899066804962311、 
0.894547051519526、0.892017427898862、0.884981322129501、0.882297290821055、 
0.881920241135721、0.87922875625951、0.87497883311667、0.870489394143986、 
0.869889033006586、0.868101033970136、0.863938556198595、0.862311509762884、 
0.861006848524175、0.860458623020468、0.860047895434157、0.859482279700875、 
0.85728643866709、0.854260154984101、0.850792740909708、0.850441606324925、 
0.849480674019862、0.846006590839454、0.84504760832673、0.842180730040725、 
0.841428948726826、0.840947417162972、0.837680564868377、0.837030262264296、 
0.835271839520591、0.835007503750959、0.833277025872084、0.832800441010304、 
0.829518862141146、0.829509922816415、0.820085081102358、0.818884005318737、 
0.818434954371892、0.816370859116157、0.816333107697294、0.814108838254362、 
0.813793540093344、0.811888986875533、0.811854428685852、0.808479950271578、 
0.807556590298442、0.806944201958174、0.805476832045287、0.804738022520511、 
0.803534187360152、0.803160868437218、0.802460691345483、0.801614476292256、
0.800642684272931, 0.800541654170489, 0.798913124672818, 0.797145614744474, 
0.797093572760474, 0.795305875213213, 0.793749883850904, 0.792916406337899, 
0.791640594006648, 0.79163183080376, 0.790348139656543, 0.78980390704364
)

库（mgcv）

model_linear &lt;- lm(y ~ x)

AIC(model_linear)

fit &lt;- Vectorize(function(x) as.numeric(coef(model_linear)[1] + coef(model_linear)[2]*x))
plot(x,y)
curve(fit, -1,0.2, n = 1000, lwd =2, col = &quot;red&quot;, add =TRUE)

model_gam &lt;- gam(y ~ s(x), method = &quot;ML&quot;)
AIC(model_gam)

我使用命令 AIC() 来计算两个模型的 AIC，如提供的可重现代码所示。线性模型的 AIC 为 -859.0262，而 gam 的 AIC 为 -2006.344，但线性模型看起来还不错。
为什么 gam 模型在没有提供更好的拟合度和更多参数的情况下会大幅改善？]]></description>
      <guid>https://stats.stackexchange.com/questions/658889/gams-aic-much-better-than-lms-aic-but-the-fitted-line-looks-just-fine</guid>
      <pubDate>Tue, 17 Dec 2024 16:21:36 GMT</pubDate>
    </item>
    <item>
      <title>如何计算最小化平均绝对误差的最佳拟合线的斜率？</title>
      <link>https://stats.stackexchange.com/questions/658887/how-to-calculate-the-slope-of-a-line-of-best-fit-that-minimizes-mean-absolute-er</link>
      <description><![CDATA[我有 25 个数据点，形式为 $(x,y)$，其中 $x$ 为 $1,2,3,...,25$，$y$ 为因变量。
我需要确定 $y$ 值是增加、减少还是保持不变。
最常用的方法是将这些点拟合成一条线。如果斜率为正，则 $y$ 增加，如果斜率为负，则 $y$ 减少，等等。
我一直在使用普通最小二乘回归来绘制线，但在某些情况下，异常值会导致问题。我不想忽略异常值，因为它们相关且重要；我只是不希望它们产生如此巨大的影响。我不想使用 Theil-Sen 回归，因为这实际上忽略了异常值。
似乎我想要的是一种最小化平均绝对误差或 L1 误差（而不是平方误差）的回归。这种回归似乎要困难得多。我读过几个资料，但一般分位数回归的微积分让我很费解。
我的问题是：如何计算使 L1 误差最小化的最佳拟合线的斜率？
我正在寻找的答案的一些限制：

我正在寻找一个输出直线斜率的过程、伪代码或实际代码。
我只需要直线的斜率。
我不是在寻找通用解决方案的名称。请不要只说“使用线性规划”或“使用梯度下降”。
我不是在寻找一个库来为我做这件事。请不要说“使用 R”或“使用 scikit”。
我只有 25 个点，而且它们是二维的，因此，只要它们能够处理这种小情况，那么无法扩展的低效解决方案也是可以的。

--- 编辑 ---
似乎我上面的约束列表不够具体。这就是我想要的：
// x 和 y 的长度保证为 25
function calculate_slope(x[], y[]) {
// 您编写此部分。
return slope;
}
]]></description>
      <guid>https://stats.stackexchange.com/questions/658887/how-to-calculate-the-slope-of-a-line-of-best-fit-that-minimizes-mean-absolute-er</guid>
      <pubDate>Tue, 17 Dec 2024 16:12:39 GMT</pubDate>
    </item>
    <item>
      <title>防止时间序列数据拆分中的数据泄露</title>
      <link>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</link>
      <description><![CDATA[我正在研究机械系统的故障检测问题，目标是确定故障类型。我使用的数据集对于每种类型的故障（目标标签）都有三种大小，每种故障大小都有四种不同的工作条件，如下图所示。请注意，数据集中的每个样本都是时间序列，由于样本数量太少而且太长，因此需要将每个样本分成固定长度的块。现在的问题是如何将每个块分配给训练集或测试集，以确保公平和无偏见的评估。

在之前的研究中，常见的做法是将所有块随机分成训练集和测试集。

使用这种方法，神经网络模型通常在测试集上实现近乎完美的性能。然而，这种方法似乎存在根本缺陷，因为将近似平稳的信号分成块会导致来自同一信号的块高度相似，而相似的块可能最终出现在两个集合中，从而导致严重的数据泄漏。为了说明这种数据泄漏，我将 t-SNE 算法应用于这些块。

在此图中，每种颜色对应特定的故障类型和故障大小。请注意，来自同一样本的块紧密聚集在一起。以下是放大版的图：

我认为应该根据故障大小来拆分块。例如，故障大小为 1 和 2 的样本块应包含在训练集中，而故障大小为 3 的样本块应包含在测试集中。这可确保测试集中不存在来自训练信号的任何信息。

现在我想问：

我关于数据泄露的说法正确吗？如果正确，是否有其他方法可以更严格地证明数据泄露，例如使用相似性指标或其他可视化？
您如何看待提议的拆分方法？基于故障大小的拆分是否足以防止数据泄露？如果不是，您会推荐哪些替代拆分策略来确保公平评估？
]]></description>
      <guid>https://stats.stackexchange.com/questions/658883/preventing-data-leakage-in-time-series-data-splitting</guid>
      <pubDate>Tue, 17 Dec 2024 15:38:37 GMT</pubDate>
    </item>
    <item>
      <title>有目的地将纵向数据建模为 iid？</title>
      <link>https://stats.stackexchange.com/questions/658882/purposefully-modelling-longitudinal-data-as-iid</link>
      <description><![CDATA[我正在考虑开展一个项目，其中有重复测量的个体（即多个个体，每个个体都有多个测量值）。响应是二进制（0,1），我正在考虑使用逻辑回归。我正在考虑考虑相关性的不同建模策略，但我也担心错误地将响应包含在模型中会违反统计假设。

1) 非标准方法：将每个人的每次测量视为具有先前响应变量和偏移变量比率的 iid。
这是我自己的想法。
这是基本模型：
$$ P(y_i = 1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1)}} $$
现在，进行以下修改以考虑相关性：

让 $x_2$ 表示人员 $i$
让 $x_3$ 表示 $i$ 个人之前测量结果中 1 与 0 的比率

这些就像个人层面的累积运行变量。例如对于个体 i，response_4 ~ f（来自时间点 1、2、3 的个体 i 的信息）。
$x_2$ 用于解释观察次数较多的个体与观察次数较少的个体（例如，一个有 3 次测量结果且所有 3 次都是 1 的个体，与同一个体有 10 次测量结果且所有测量结果仍为 1 的个体相比）：
$$ P(y_i = 1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3)}} $$
$$ \text{logit}[P(y_i = 1)] = \ln\left(\frac{P(y_i = 1)}{1 - P(y_i = 1)}\right) = \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 $$
可能有点牵强，但我会强制 $x_3$ 在 0 除法的情况下为 0。
2) 标准策略：使用纵向模型。
针对个体 $i$ 和时间点 $t$ 进行重复测量的标准逻辑回归：
$$ P(y_{it} = 1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_{it})}} $$
$$ \text{logit}[P(y_{it} = 1)] = \ln\left(\frac{P(y_{it} = 1)}{1 - P(y_{it} = 1)}\right) = \beta_0 + \beta_1x_{it} $$
现在通过使用每个个体的随机效应项$u_i$来解释同一个体测量值之间的相关性：
$$ \text{logit}(P(y_{it} = 1)) = \beta_0 + \beta_1x_{it} + u_i $$
$$ u_i \sim N(0, \sigma^2_u) $$
可以添加额外的时间效应：
$$ \text{logit}(P(y_{it} = 1)) = \beta_0 + \beta_1x_{it} + \beta_2t + u_i $$
3) 自回归误差结构
对于 AR(1) 误差结构，将误差项 $\epsilon_{it}$ 定义为：
$$ \epsilon_{it} = \rho\epsilon_{i,t-1} + \eta_{it} $$
其中：

$\rho$ 是自相关参数（其中 $|\rho| &lt; 1$)
$\epsilon_{i,t-1}$ 是来自前一个时间点的误差项
$\eta_{it}$ 是一个新的随机误差项：$\eta_{it} \sim N(0, \sigma^2_\eta)$

把所有东西放在一起：
$$ \text{logit}(P(y_{it} = 1)) = \beta_0 + \beta_1x_{it} + \rho\epsilon_{i,t-1} + \eta_{it} $$
$$ \text{Cov}(\epsilon_{is}, \epsilon_{it}) = \sigma^2_\epsilon\rho^{|t-s|} $$

我想知道第一种建模方法是否有意义？我认为使用方法 1 在计算上更简单，因为它将所有内容视为 iid。它也可能更容易解释模型，并且不需要对相关结构做出相同类型的假设。但总的来说，有人遇到过方法 1 吗？它在统计上有效吗？还是它违反了一些统计假设？]]></description>
      <guid>https://stats.stackexchange.com/questions/658882/purposefully-modelling-longitudinal-data-as-iid</guid>
      <pubDate>Tue, 17 Dec 2024 15:38:22 GMT</pubDate>
    </item>
    <item>
      <title>逆指数分布的双变量数据生成</title>
      <link>https://stats.stackexchange.com/questions/658879/bivariate-data-generation-of-inverse-exponential-distribution</link>
      <description><![CDATA[对于以下双变量逆指数分布，我必须从随机向量创建数据：$$ F_{X,Y}(x,y) =\exp({-x^{-1}-y^{-1}-\theta {(xy)}^{-1}}),0\leq\theta\leq 1, x,y&gt;0,$$。我知道如何使用均匀随机变量（我使用的是 $\texttt{R}$）从单变量创建和转换数据，但我不知道如何对随机向量执行相同操作。您有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658879/bivariate-data-generation-of-inverse-exponential-distribution</guid>
      <pubDate>Tue, 17 Dec 2024 14:10:42 GMT</pubDate>
    </item>
    <item>
      <title>将整数矩阵的行和分布得接近泊松分布，并对列总数和非零计数进行约束</title>
      <link>https://stats.stackexchange.com/questions/658878/distributing-row-sums-of-an-integer-matrix-to-be-close-to-poisson-with-constrain</link>
      <description><![CDATA[我遇到一种情况，我需要构建一个 $M$ x $N$ 矩阵，称为 $H$，表示 $M$ 个对象，这些对象可能具有 $N$ 个不同的修饰符，所有这些修饰符都可以应用于正整数数量。我知道每个修饰符都有一个指定的列总数，即 $\sum^{i\in 1:M} H_{i,j} = T_j, j\in 1:N$。还有一个二进制矩阵 $D_{i,j} \in \{1,0\}$ 表示受 $j$ 第个修饰符影响的对象，即我们知道 $H$ 中 $S_j$ 个条目的数量将非零。必然地，我们建立$S_j \leq T_j \forall j\in 1:N$，因为每个对象必须至少有一个修饰量，由$D$表示，并且该列的其余值必须为零。
我希望这个矩阵的行和大致服从泊松分布，但由于这些限制，我觉得不可能保证这是可以实现的。因此，或者，我希望有一种有效的算法能够尽可能接近地分配修饰符，使得​​从行总和的角度来看，应用的总修饰符数量大致呈指数衰减。
我相信，如果没有 $D$ 矩阵部分来限制每个修饰符的具体对象数量，那么使用每列上的多项分布（使用可选的狄利克雷先验来集中/使分布均匀）应该很容易实现这一点。有人有什么想法可以轻松实现这一点吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658878/distributing-row-sums-of-an-integer-matrix-to-be-close-to-poisson-with-constrain</guid>
      <pubDate>Tue, 17 Dec 2024 14:09:41 GMT</pubDate>
    </item>
    <item>
      <title>计算 k 模式的 SSB（簇间平方和）</title>
      <link>https://stats.stackexchange.com/questions/658877/computing-calculating-ssb-sum-of-squares-between-clusters-for-k-modes</link>
      <description><![CDATA[我正在尝试计算用于验证/计算 K 模式性能的指标。我正在做我的论文，我需要根据二元变量（疾病）对患者进行分组，我最近读到SSW 和 SSB 指标可能合适。
我只知道如何从 kmodes 函数中提取 SSW（此处回复了 K-Modes Cluster Validation），但我不知道如何计算 SSB（簇之间）...您能给出一个如何计算它的例子吗？
有人在这里回复了，但对于 K-Means：SSB - 簇之间的平方和
我可以使用 Calinski–Harabasz 指数，如果不是可以计算 K 模式]]></description>
      <guid>https://stats.stackexchange.com/questions/658877/computing-calculating-ssb-sum-of-squares-between-clusters-for-k-modes</guid>
      <pubDate>Tue, 17 Dec 2024 13:41:53 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 R 中一个变量的 mc fadden's rsquared？</title>
      <link>https://stats.stackexchange.com/questions/658874/how-to-calculate-mc-faddens-rsquared-for-just-one-variable-in-r</link>
      <description><![CDATA[对于我的逻辑回归，我使用 Mc Fadden 的 R 平方（类似于 R 平方，但用于逻辑模型）。但是，Mc Faddens R 平方计算的是整体模型的效果，而我想知道模型中单个变量的效果。我已经设法计算了线性回归模型中单个变量的偏 R 平方（使用包：sensemakr），但我不知道如何使用 Mc Faddens R 平方进行逻辑回归。有人有什么想法吗？（我在 Rstudio 工作）]]></description>
      <guid>https://stats.stackexchange.com/questions/658874/how-to-calculate-mc-faddens-rsquared-for-just-one-variable-in-r</guid>
      <pubDate>Tue, 17 Dec 2024 12:40:35 GMT</pubDate>
    </item>
    <item>
      <title>参数复发事件分析中的马丁格尔和偏差残差？</title>
      <link>https://stats.stackexchange.com/questions/658870/martingale-and-deviance-residuals-in-parametric-recurrent-event-analysis</link>
      <description><![CDATA[我正在开发一个描述重复事件过程的参数化事件发生时间模型。我不确定我对如何计算这种情况下 Martingale 和 Deviance 残差的理解是否正确，并希望有人能就此事提供指导。来自 Therneau 等人。 (1990)，在我的例子中，马丁格尔残差如下：
$$
\hat{M}_i(t) = N_i(t) - \int_{0}^{t} Y_i(s)d\hat{\Lambda_i}(s),
$$
由于对于每个时间 t，$E[\hat{M}_i(t)] = E[\hat{M}_i(t-1)] = 0$，计算每个事件/审查时间的 $\hat{M}_i(t)$ 是否合适，以便可以根据所有记录的事件时间来评估模型准确性？如果是，那么“最佳”方法是什么？计算 $\hat{M}_i(t)$ 的方法如下：

基于从 $[t-1, t]$ 开始的区间？
或者基于从 $[0,t]$ 开始的区间？

其中 t-1 和 t 分别是上一个事件时间以及当前事件时间。或者这取决于我们试图用模型回答的问题（即，如果准确预测事件 n-1 和 n 之间的时间很重要，则选择 $[t-1,t]$）？
那么对于偏差残差，Therneau 等人（1990） 将这些结果呈现为 Cox 模型，如下所示：
$$
d_i = \operatorname{sgn}(\hat{M}_i) \left[ -2\{ \hat{M}_i + \delta_i \log (\delta_i - \hat{M}_i)\} \right]^{\​​frac{1}{2}}
$$
有没有办法将这些结果转换为“纵向”设置（即针对每个记录时间，而不是基于 $\hat{M}_i$，后者是针对每个个体 i 在整个随访期间计算得出的）？并且，与此相关的是，在重复事件的情况下，计算$d_i$以及$\hat{M}_i$能带来很多好处吗？鉴于$d_i$是为了实现更正态的残差分布而开发的，这对于重复事件来说似乎不是什么大问题，因为$\hat{M}_i$可能取值的范围（在我的案例中理论上为$[-\infty,\infty]$）。
为我的问题提供一些背景信息：本文介绍了我研究领域的偏差残差，建议使用$\hat{M}_i(t)$基于从$[t-1, t]$，并且仅适用于观察到的事件时间。我不确定这是否合适，因为我们使用这种方法丢弃了数据的审查部分。这也是我能找到的唯一一个在每个个体中多次得出$\hat{M}_i$的例子，因为其他研究，如这个和这个，只基于$[0, t_{max}]$区间计算$\hat{M}_i$和$d_i$。]]></description>
      <guid>https://stats.stackexchange.com/questions/658870/martingale-and-deviance-residuals-in-parametric-recurrent-event-analysis</guid>
      <pubDate>Tue, 17 Dec 2024 11:24:19 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost - 具有 `colsamle_bytree` <1 的树所见列的顺序</title>
      <link>https://stats.stackexchange.com/questions/658867/xgboost-order-of-columns-seen-by-a-tree-with-colsamle-bytree1</link>
      <description><![CDATA[我的理解是，如果两个或多个列在拆分时提供相同的增益，XGBoost 会选择第一列。
为了确保 XGBoost 有机会查看并包含所有相关列，我认为我可以简单地传递 colsample_bytree=0.99。但是，为了使其工作，采样返回的列必须按随机顺序排列。这种方法正确吗？还是我应该在某种交叉验证方案中对列进行打乱？]]></description>
      <guid>https://stats.stackexchange.com/questions/658867/xgboost-order-of-columns-seen-by-a-tree-with-colsamle-bytree1</guid>
      <pubDate>Tue, 17 Dec 2024 11:02:34 GMT</pubDate>
    </item>
    <item>
      <title>具有交互作用的泊松回归的边际效应</title>
      <link>https://stats.stackexchange.com/questions/658861/marginal-effect-of-poisson-regression-with-interaction</link>
      <description><![CDATA[我很难理解 R 中带有泊松回归的 {marginaleffects} 包的结果。
如果我这样做：
library(marginaleffects)
mod &lt;- lm(mpg ~ hp * as.factor(gear), data = mtcars)
summary(mod)

我得到：
系数：估计标准差。误差 t 值 Pr(&gt;|t|) 
(截距) 25.307903 2.650811 9.547 5.51e-10 ***
hp -0.052240 0.014560 -3.588 0.001356 ** 
as.factor(gear)4 15.262616 3.862728 3.951 0.000531 ***
as.factor(gear)5 7.469550 3.805534 1.963 0.060451 . 
hp:as.factor(gear)4 -0.126946 0.033574 -3.781 0.000825 ***
hp:as.factor(gear)5 -0.006029 0.019276 -0.313 0.756952 

and avg_comparisons(mod, variable = &quot;hp&quot;, by = c(&quot;gear&quot;)) 返回
 术语 gear 估计 Std.误差 z Pr(&gt;|z|) S 2.5 % 97.5 %
hp 3 -0.0522 0.0146 -3.59 &lt;0.001 11.6 -0.0808 -0.0237
hp 4 -0.1792 0.0303 -5.92 &lt;0.001 28.2 -0.2385 -0.1199
hp 5 -0.0583 0.0126 -4.61 &lt;0.001 17.9 -0.0830 -0.0335

其中第一行返回在模型摘要中找到的估计值 -0.0522，因为我有相同的参考。这对我来说很有意义。
我不明白的是泊松分布会发生什么：
mod &lt;- glm(cyl ~ hp * as.factor(gear), data = tmp, family =toxic())
summary(mod)

系数：
估计标准差。误差 z 值 Pr(&gt;|z|) 
(截距) 1.5599308 0.3891456 4.009 6.11e-05 ***
hp 0.0025199 0.0020809 1.211 0.226 
as.factor(gear)4 -0.6005544 0.6561946 -0.915 0.360 
as.factor(gear)5 -0.4006457 0.6104003 -0.656 0.512 
hp:as.factor(gear)4 0.0038348 0.0058576 0.655 0.513 
hp:as.factor(gear)5 0.0005107 0.0028537 0.179 0.858 

我原本希望 avg_comparisons 返回 0.0025199，然后计算不同齿轮值的不同值，但是：
avg_comparisons(mod, variable = &quot;hp&quot;, by = c(&quot;gear&quot;))

术语 gear 估计 Std.误差 z Pr(&gt;|z|) S 2.5 % 97.5 %
hp 3 0.0188 0.0157 1.20 0.230 2.1 -0.01189 0.0496
hp 4 0.0297 0.0260 1.14 0.253 2.0 -0.02125 0.0807
hp 5 0.0182 0.0122 1.49 0.136 2.9 -0.00573 0.0421

这里，第一行估计是 0.0188，而不是 0.0025199，我不明白为什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/658861/marginal-effect-of-poisson-regression-with-interaction</guid>
      <pubDate>Tue, 17 Dec 2024 09:37:39 GMT</pubDate>
    </item>
    <item>
      <title>控制多重比较</title>
      <link>https://stats.stackexchange.com/questions/658859/control-for-multiple-comparisons</link>
      <description><![CDATA[我想选择一组特定于学生和性别的单词。因此，我让参与者根据单词的“学生化”和“女性化”程度对单词进行评分。每个单词都是一对（一个特定单词和一个控制单词；例如“女性”和“编织”）。对于每个单词，我都有 2 个评分（学生化和性别化），因此一对有 4 个评分。我总共有 100 对，其中一半有特定性别的单词，一半​​有特定的学生单词。
我知道想要测试特定单词是否特定于其自己的类别，而不是其他类别（即比较所有对的评分）。我已经运行了 LME 模型和 ANOVA，并得到了预期的效果，即学生单词在属性“学生”上的评分更高。但是，我想选择评分最高的 30 个特定单词（与合作伙伴一起），但也要确保它们只针对自己的类别 - 即，女性应该针对性别类别，但在学生气和女性气方面评分明显低于编织。此外，编织和女性应该同样像学生，因为它们应该在不感兴趣的类别中作为对照。我显然可以运行多个配对 t 检验。你会怎么做？
最好！]]></description>
      <guid>https://stats.stackexchange.com/questions/658859/control-for-multiple-comparisons</guid>
      <pubDate>Tue, 17 Dec 2024 08:39:11 GMT</pubDate>
    </item>
    <item>
      <title>如何找到跨多天的时间序列中变量之间的相关性？</title>
      <link>https://stats.stackexchange.com/questions/658852/how-do-i-find-correlation-between-variables-in-a-time-series-across-multiple-day</link>
      <description><![CDATA[我有每天的数据，包括日期/时间、事件以及触发次要事件的时间。
日期 | 时间 | 事件 | 触发次要事件
2019 年 9 月 9 日 | 上午 12:00 | A | 否
2019 年 9 月 9 日 | 上午 12:30 | A | 否
2019 年 9 月 9 日 | 上午 01:00 | | 否
2019 年 9 月 9 日 | 上午 01:30 | B | 否
...
2019 年 9 月 9 日 | 下午 03:00 | E | 否
2019 年 9 月 9 日 | 下午 03:30 | | 否
2019 年 9 月 9 日 | 下午 04:00 | | 是
2019 年 9 月 9 日 | 晚上 11:30 | C |是
2019 年 9 月 10 日 | 上午 12:00 | D | 否
2019 年 9 月 10 日 | 上午 12:30 | D | 否
...

每一天都是完全相互隔离的，我确信一天内没有任何事情会导致另一天触发次要事件 - 因此我们可以假设存在的任何相关性都是在一天内隔离的。
鉴于这些数据有多个“块”，每个月的每一天一个，持续数月 - 可以进行哪种分析才能更好地了解哪些事件更可能与触发次要事件有关？
我首先查看了时间序列的互相关，使用正常相关性，但将最后一列的数据移动 X 时间量，以查看哪个时间滞后量可以获得最佳相关性。
但让我困惑的是我发布这篇文章的原因是因为我的时间序列并不完全连续。它们是离散的时间序列数据块。所以我不知道在这种情况下该怎么做。
编辑：我需要补充一点，次要事件被触发一次，并持续一整天。因此，对于最后一列“是”或“否”，如果存在连续的“是”序列，则仅表示它在时间 t 触发，但持续到时间 t+1、t+2、t+3 等。
因此，为了进一步澄清，这并不意味着事件 A 在时间 t 触发一个次要事件，然后事件 B 在时间 t+1 触发次要事件。我希望这有意义。]]></description>
      <guid>https://stats.stackexchange.com/questions/658852/how-do-i-find-correlation-between-variables-in-a-time-series-across-multiple-day</guid>
      <pubDate>Tue, 17 Dec 2024 03:23:25 GMT</pubDate>
    </item>
    <item>
      <title>可以对使用非概率抽样收集的加权数据进行统计显着性检验方法吗？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658822/can-statistical-significance-testing-methods-be-carried-out-on-weighted-data-tha</link>
      <description><![CDATA[我正在分析使用非概率抽样方法收集的调查数据集。此数据集还包括一个权重字段，可能允许将调查结果推断到更广泛的人群。
鉴于此权重数据的存在，我是否可以使用传统的统计显着性检验方法，如卡方检验和 t 检验？（我将使用 R 的 survey 和 srvyr 包或 Python 的 samplics 包将权重值合并到我的代码中。或者这些测试是否仍然无效，因为原始数据不是从随机样本中收集的？（如果是这样，我们将非常感激与非概率抽样方法兼容的替代测试的建议。）]]></description>
      <guid>https://stats.stackexchange.com/questions/658822/can-statistical-significance-testing-methods-be-carried-out-on-weighted-data-tha</guid>
      <pubDate>Mon, 16 Dec 2024 17:39:03 GMT</pubDate>
    </item>
    </channel>
</rss>