<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sat, 14 Dec 2024 21:15:18 GMT</lastBuildDate>
    <item>
      <title>GAM(M) 用于 R 中配对对照治疗样本的纵向测量</title>
      <link>https://stats.stackexchange.com/questions/658725/gamm-for-longitudinal-measurements-from-paired-control-treatment-samples-in-r</link>
      <description><![CDATA[我有一个如下所示的测试数据集；



ID
Group
Week




X1
Healthy
0


X1
Disease
0


X1 
健康
2


X1
疾病
2


X1
健康
5


X1
健康
16


X1
疾病
16


X2
健康
0


X2
疾病
0


X2
健康
2


X2
疾病
2


X2
健康
5


X2
疾病
5


X2
健康
16


X2
疾病
16


X3
健康
0


X3
疾病
0


X3
健康
2


X3
疾病
2


X3
健康
5


X3
疾病
5


X3
健康
16


X3
疾病轻松
16


X4
疾病
0


X4
健康
2


X4
疾病
2


X4
健康y
5


X4
疾病
5


X4
健康
16


X4
疾病
16



正如上面举例说明的部分数据，我在每个时间点从每个配对站点采集了 200 个不同的测量值，但并非所有受试者都有完整的样本集。假设测量结果不遵循线性趋势，您能否建议（对于 GAM/GAMM 的新手）我如何通过使用 R 中的 GAM 或 GAMM 的配对采样策略来测试测量结果在健康组和疾病组之间是否具有显着不同的纵向趋势？]]></description>
      <guid>https://stats.stackexchange.com/questions/658725/gamm-for-longitudinal-measurements-from-paired-control-treatment-samples-in-r</guid>
      <pubDate>Sat, 14 Dec 2024 20:39:10 GMT</pubDate>
    </item>
    <item>
      <title>我是否正确推导出加权最小二乘的迭代更新？</title>
      <link>https://stats.stackexchange.com/questions/658722/have-i-correctly-derived-the-iterative-updates-for-weighted-least-squares</link>
      <description><![CDATA[我有一项练习，需要从迭代加权最小二乘更新方程 $b^{(m)} = \left( X^\top W^{(m-1)} X \right)^{-1} X^\top W^{(m-1)} z^{(m-1)}$ 中推导出 $w_i^{(m-1)}$ 和 $z_i^{(m-1)}$，其中 BeetleMortality 数据具有概率单位链接 $\phi$。然后我必须在 R 中实现它。据我所知，$w_i^{(m-1)}=\frac{1}{\text{Var}(Y)} (\frac{\partial \mu_i}{\partial \eta_i}) ^2 = \frac{\phi&#39;(\eta_i)^{(m-1)}}{n\mu_i^{(m-1)}(1 - \mu_i^{(m-1)})}$ 和 $z_i^{(m-1)} = \eta_i^{(m-1)} (y_i -\mu_i) \frac{\partial \eta_i}{\partial \mu_i}= \eta_i^{(m-1)} + \frac{y_i + \mu_i^{(m-1)}}{\phi&#39;(\eta_i)^{(m-1)}}$ 其中 $\phi&#39;$ 是正态分布 PDF。我已经在 R 中实现了这一点，我非常确定实现中的所有内容都是正确的。因此，我相信问题在于我如何得出这些值。我犯了什么错误吗？我对这一切还比较陌生，所以很可能是我犯了一些我无法发现的明显错误。任何反馈都值得赞赏！]]></description>
      <guid>https://stats.stackexchange.com/questions/658722/have-i-correctly-derived-the-iterative-updates-for-weighted-least-squares</guid>
      <pubDate>Sat, 14 Dec 2024 16:41:27 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 R 对具有连续数据（干预前后）的单臂研究进行汇总荟萃分析？</title>
      <link>https://stats.stackexchange.com/questions/658721/how-to-do-pooled-meta-analysis-of-single-arm-studies-with-continous-data-pre-po</link>
      <description><![CDATA[我尝试使用 R studio 对单组研究（无对照）进行荟萃分析，但我仍然不知道如何进行汇总分析。我只有治疗前的平均值和 SD 以及治疗数周后的平均值和 SD。我可以在 R studio 中使用干预前后的连续数据对单组研究进行汇总荟萃分析吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658721/how-to-do-pooled-meta-analysis-of-single-arm-studies-with-continous-data-pre-po</guid>
      <pubDate>Sat, 14 Dec 2024 15:24:07 GMT</pubDate>
    </item>
    <item>
      <title>PCR/PLSR 每日股票收益预测结果的合理性</title>
      <link>https://stats.stackexchange.com/questions/658720/plausibility-of-results-for-pcr-plsr-daily-stock-return-forecasting</link>
      <description><![CDATA[我正在为我的硕士学位做一个项目，但我不确定我得到的结果是否合理。
我基本上是想创建一个模型来预测标准普尔 500 指数的每日回报。
我的项目基于以下文章：https://www.sciencedirect.com/science/article/abs/pii/S0957417416305115
使用与文章中相同的方法，我创建了一个 PCR 和 PLSR 模型，将 y_t 回归到 x_t。


到目前为止一切顺利，结果是合理的。我在测试数据集上运行了模型，结果很好。
但后来我意识到，我真正想要的是回归 yt 在 x_t-1 上，以使用今天可用的数据预测第二天的回报。
我通过删除目标变量的第一行和独立变量的最后一行对数据进行了调整，然后再次运行模型。
然而，这次我得到的结果非常糟糕，我不确定这是否是我的代码问题，或者我应该做哪些更改来改进我的模型。


以下是我使用的数据的列表：

这是我在这个论坛上的第一篇帖子。如果我遗漏了什么，请告诉我，我很乐意纠正它。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658720/plausibility-of-results-for-pcr-plsr-daily-stock-return-forecasting</guid>
      <pubDate>Sat, 14 Dec 2024 14:25:23 GMT</pubDate>
    </item>
    <item>
      <title>在这种情况下，差异中的差异有效吗？</title>
      <link>https://stats.stackexchange.com/questions/658719/is-the-difference-in-difference-valid-in-this-case</link>
      <description><![CDATA[我正在评估一份报告，该报告使用倾向得分匹配和差异差异法评估 DBT 在英国的出口促进活动对公司层面结果的影响。
有些公司在 2014 年只接受过一次治疗，而其他公司在 2014 年接受过多次治疗。同时，有些公司也接受了多年的治疗。在这种情况下，是否有可能估计治疗的任何因果影响？或者 DiD 完全无效？]]></description>
      <guid>https://stats.stackexchange.com/questions/658719/is-the-difference-in-difference-valid-in-this-case</guid>
      <pubDate>Sat, 14 Dec 2024 13:15:15 GMT</pubDate>
    </item>
    <item>
      <title>比例与连续变量的“总和”和“平均值”的正确用法</title>
      <link>https://stats.stackexchange.com/questions/658715/correct-usage-of-sum-and-mean-for-proportions-vs-continuous-variables</link>
      <description><![CDATA[通过“总和”与“平均值”来聚合“比例”与“连续”度量的正确方法是什么？
例如，假设我有“time_on_site”和“converted”。从逻辑上讲，将所有转化相加是有意义的，因为我们关心该变量的总体影响。但我也可以提出想要提高转化率的理由，因为我有兴趣在我的假设小部件中捕获更大比例的用户。
这是否取决于用例（这特别适用于 AB 测试），或者是否存在何时使用哪种聚合技术的一般经验法则？
如果这个问题与主题无关，请告诉我；我对按用例进行的统计上正确的聚合感兴趣。]]></description>
      <guid>https://stats.stackexchange.com/questions/658715/correct-usage-of-sum-and-mean-for-proportions-vs-continuous-variables</guid>
      <pubDate>Sat, 14 Dec 2024 12:18:41 GMT</pubDate>
    </item>
    <item>
      <title>PS-match 和调整后的 Cox 回归之间有何区别？</title>
      <link>https://stats.stackexchange.com/questions/658713/what-are-the-differences-between-ps-match-and-adjusted-cox-regression</link>
      <description><![CDATA[这更像是以下问题的延伸：倾向评分匹配与 Cox 回归
我想知道它们之间有什么区别：

将患者与 PS 匹配并运行仅以暴露作为预测因子的 Cox 回归
运行包含所有协变量的 Cox 回归（我会在 PS 匹配中使用）

这些方法会得出不同的结论吗？我什么时候应该使用哪种方法？]]></description>
      <guid>https://stats.stackexchange.com/questions/658713/what-are-the-differences-between-ps-match-and-adjusted-cox-regression</guid>
      <pubDate>Sat, 14 Dec 2024 11:54:21 GMT</pubDate>
    </item>
    <item>
      <title>SPSS：相关样本弗里德曼的双向方差分析按等级在图表中额外的条形图[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658710/spss-related-samples-friedmans-two-way-analysis-of-variance-by-ranks-extra-bar</link>
      <description><![CDATA[我是这里的新手，在统计学方面有点外行，希望这个问题能出现在合适的地方。
我正在 SPSS 中对我进行的 3 次实验进行上述分析。
大多数比较指标都显示在类似这样的图表中，并显示 3 次迭代的预期排名。

但是，在某些情况下，对于某些指标，我得到的图表显示 4 个条形图，而不是预期的 3 个。

由于我找不到任何与此相关的信息，我希望有人能帮助我理解这意味着什么/代表什么。
非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/658710/spss-related-samples-friedmans-two-way-analysis-of-variance-by-ranks-extra-bar</guid>
      <pubDate>Sat, 14 Dec 2024 11:00:28 GMT</pubDate>
    </item>
    <item>
      <title>使用混合效应模型来了解人口？</title>
      <link>https://stats.stackexchange.com/questions/658704/using-a-mixed-effects-model-to-understand-the-population</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/658704/using-a-mixed-effects-model-to-understand-the-population</guid>
      <pubDate>Sat, 14 Dec 2024 07:39:31 GMT</pubDate>
    </item>
    <item>
      <title>拟合非线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/658694/fitting-a-nonlinear-mixed-model</link>
      <description><![CDATA[我试图拟合一个非线性混合模型 (nLMM)，以测试某些生物的丰度是否受到导致丰度显著增加的事件后的采样期的影响。
数据显示了一条重要的曲线，这些生物的丰度在事件发生后激增（事件发生在采样期：-1 和 1 之间），但随后下降。
我试图构建一个非线性混合模型，但我发现理解如何构建模型非常具有挑战性（例如，model &lt;- lmer(abundance ~ samples_period + (1 | rep), data = data）。我非常感谢任何帮助来确定丰度是否受到采样期的影响。
data &lt;- data.frame(
abundant = c(79, 72, 58, 61, 88, 123, 119, 96, 67, 78, 143, 75, 105, 46, 58, 
127, 173, 181, 67, 120, 64, 30, 49, 47, 104, 83, 146, 118, 53, 
98, 223, 257, 255, 292, 354, 133, 129, 140, 27, 55, 68, 148, 
122, 132, 77, 121, 108, 109),
rep = c(&quot;T1&quot;, &quot;T2&quot;, &quot;T3&quot;, &quot;T1&quot;, &quot;T2&quot;, &quot;T3&quot;, “T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T3”、“T1”、“T2”、“T3”、“
“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“ “T3”, “T1”, “T2”, “T3”, 
“T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”),
sampling_period_consecutive = c(1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 
6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 10, 10, 
10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 
14, 14, 15, 15, 15, 16, 16, 16),
采样周期 = c(-5, -5, -5, -4, -4, -4, -3, -3, -3, -2, -2, -2, -1, -1, 
-1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 
6, 11, 11, 11, 22, 22, 22, 34, 34, 34, 46, 46, 58, 
58, 58)
)

]]></description>
      <guid>https://stats.stackexchange.com/questions/658694/fitting-a-nonlinear-mixed-model</guid>
      <pubDate>Fri, 13 Dec 2024 19:32:50 GMT</pubDate>
    </item>
    <item>
      <title>基线和多次随访的前后设计（无控制）（元分析）</title>
      <link>https://stats.stackexchange.com/questions/658486/pre-post-design-no-control-at-baseline-and-multiple-follow-up-times-meta-anal</link>
      <description><![CDATA[我正在从事一个荟萃分析项目，需要有关选择正确统计方法的建议。我们可以查阅大约 18 篇出版物。该设计类似于治疗前后设计（无对照组）。但我们有两个以上的时间点。
在这些出版物中，受试者在治疗前后的不同时间点（T0、T1、T3、T6）来到诊所检查胆固醇值。在接受治疗之前的 T0 测量他们的胆固醇值，然后对他们进行治疗。要求他们在一个月后（T1）回来接受治疗并再次测量。这个过程在三个月和六个月时重复。
研究问题是将每个时间点的治疗效果与基线进行比较，以确定治疗需要多长时间才能见效。如果患者在 3 个月后没有出现改善，他们可能会考虑换一种治疗方法。但是，如果 3 个月时没有改善，但 6 个月时有明显改善，他们可能会考虑继续注射更多相同的药物。
出版物包括单独的配对样本检验（配对 t 检验或 Wilcoxon 符号秩检验）的结果，以比较 T1 与 T0、T3 与 T0 和 T6 与 T0（设计前后的配对样本）。因此，我们可以访问平均值和标准差（治疗前后）以及 p 值*
我们的数据是这样的（假设我们只有前、后（T1）和后（T3）：
 dat &lt;- data.frame(study=c(1,2,3,4,5,6), 
n=c( 40, 40, 10,150,150,150),
Mean_pre=c(4,2.3,3.1,6.1,2.2,3.4),
sd_pre=c(1,1.3,0.1,1.1,0.9,1.2), 
Mean_post_T1=c(2,1.3,4.1,5.1,4.2,1.4),
sd_post_T1=c(2,3.3,1.1,2.1,0.9,2.2),
r_T0_T1=c(0.4,0.5,0.3,0.3,1.5,0.7),
pvalue_T0_T1=c(0.001,0.03,0.006,0.05,0.004,0.01),
Mean_post_T3=c(1,2.3,6.1,6.1,5.2,4.4),
sd_post_T3=c(1,2.3,3.1,1.1,1.9,3.2),
r_T0_T3=c(1.4,2.5,3.3,4.3,2,1.7),
pvalue_T0_T3=c(0.003,0.01,0.004,0.05,0.004,0.04)
)

研究 n Mean_pre sd_pre Mean_post_T1 sd_post_T1 r_T0_T1 pvalue_T0_T1
1 1 40 4.0 1.0 2.0 2.0 0.4 0.001
2 2 40 2.3 1.3 1.3 3.3 0.5 0.030
3 3 10 3.1 0.1 4.1 1.1 0.3 0.006
4 4 150 6.1 1.1 5.1 2.1 0.3 0.050
5 5 150 2.2 0.9 4.2 0.9 1.5 0.004
6 6 150 3.4 1.2 1.4 2.2 0.7 0.010
Mean_post_T3 sd_post_T3 r_T0_T3 pvalue_T0_T3
1 1.0 1.0 1.4 0.003
2 2.3 2.3 2.5 0.010
3 6.1 3.1 3.3 0.004
4 6.1 1.1 4.3 0.050
5 5.2 1.9 2.0 0.004
6 4.4 3.2 1.7 0.040


现在，我想知道我们应该如何将元分析方法应用于这些类型的研究？我们是否也应该对每个比较应用单独的元分析？任何关于潜在和正确的统计技术或参考的建议都将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/658486/pre-post-design-no-control-at-baseline-and-multiple-follow-up-times-meta-anal</guid>
      <pubDate>Mon, 09 Dec 2024 13:30:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 Kahneman 等人（2021 年）的方法计算评分者间噪声</title>
      <link>https://stats.stackexchange.com/questions/649163/calculate-inter-rater-noise-using-kahneman-et-al-2021-approach</link>
      <description><![CDATA[我需要帮助根据 Kahneman 等人 (2021) 在其著作《噪音》中描述的方法计算信号和噪音。他们提供了一种量化评估相同案例的评估者之间噪音的技术。想象一下五位心理学家（评估者）评估 10 位患者（案例）的抑郁程度。设置如下：
假设您有行作为评估者，案例作为列。在零噪音的情况下，每个评估者都完全同意，因此所有差异都在案例之间（信号）。Kahneman 等人进一步将噪音分为（稍微简化）：

评估者噪音：评估者之间的稳定差异，例如不同的人有不同的方法

残余噪声：无法用任何东西解释的特殊噪声。

为了计算噪声，他们建议：

计算每列 SD 的平均值（每个案例的 SD）（总噪声）
计算每行平均值的 SD（每个评估者的平均值）（评估者噪声）

然后，您可以通过 1 - 2 = 残余噪声来计算残余噪声。
我的挑战是从数据集中计算噪声和信号。此外，我想将噪声报告为类内相关系数 (ICC)，但我正在努力使用其他分解方法复制 Kahneman 等人的方法。例如，使用带有 lme4::lmer() 的随机效应模型会给我不同的结果。
我模拟了一些数据来说明我的失败尝试。我还质疑 Kahneman 等人分析噪声的方法是否可取，因为我找不到任何其他使用此方法的研究。
最后，我需要一种合理的方法来衡量和报告不确定性。有没有办法在这里引导我找到置信区间？
# 加载必要的包
library(lme4)
library(tidyverse)
library(performance)

# 设置可重复性的种子
set.seed(1234)

# 模拟参数
n_raters &lt;- 600
n_cases &lt;- 30
n_obs &lt;- n_raters * n_cases

# 模拟随机效应
rater_effects &lt;- rnorm(n_raters, mean = 0, sd = 1) # 评估者随机效应
case_effects &lt;- rnorm(n_cases, mean = 0, sd = 2) # 案例随机效应

# 模拟 dat
dat &lt;- expand_grid(rater = factor(1:n_raters), case = factor(1:n_cases))
dat$ratereffect &lt;- rater_effects[as.numeric(dat$rater)]
dat$caseeffect &lt;- case_effects[as.numeric(dat$case)]
dat$residual &lt;- rnorm(n_obs, mean = 0, sd = 3) # 残差噪声
dat$y &lt;- dat$ratereffect + dat$caseeffect + dat$residual

dat

# 拟合混合效应模型（# 这大致从模拟中检索参数）
model &lt;- lmer(y ~ 1 + (1|rater) + (1|case), dat = dat)

# 显示模型摘要
summary(model)

performance::icc(model,by_group = TRUE)
# 噪声分解

# 评分者噪声 = 7.9 %
# 案例方差（信号） = 25 %
# 残余噪声 = 100-(7.9+25) = 67.1 %

# 仅噪声分解
# 评分者 = 7.9/(7.9+67.1) = 10.5 %
# 残余噪声 = 100 - 10.5 = 89.5 %

# Kahneman、Sibony、Cass (2021) 计算
dat &lt;- dat |&gt; 
mutate(case = paste0(&quot;case&quot;,case)) |&gt; 
select(rater,case,y) |&gt; 
pivot_wider(values_from = y,names_from = case)

# 计算每行的平均值 (rater)
dat &lt;- dat |&gt;
select(-rater) |&gt; 
rowwise() |&gt;
mutate(row_mean = mean(c_across(everything())))

# 取行平均值的标准差
sd_ratermean &lt;- sd(dat$row_mean)

# 取每个案例的标准差
sd_case &lt;- dat |&gt;
pivot_longer(everything()) |&gt;
summarise(sd_case = sd(value),.by = name) |&gt;
pull(sd_case)

# 取 case sd 的平均值
mean_case &lt;- mean(sd_case)

total_noise &lt;- mean_case
level_noise &lt;- sd_ratermean
pattern_noise &lt;- total_noise-level_noise

level_noise_percent &lt;- level_noise/total_noise
pattern_noise_percent &lt;- pattern_noise/total_noise

cat(&quot;level noise =&quot;,round(level_noise_percent,2),
&quot;\npattern noise =&quot;,round(pattern_noise_percent,2))

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/649163/calculate-inter-rater-noise-using-kahneman-et-al-2021-approach</guid>
      <pubDate>Thu, 13 Jun 2024 09:22:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么 SEM 中的 lavaan 对 beta 进行 z 检验而不是 t 检验？</title>
      <link>https://stats.stackexchange.com/questions/639695/why-does-lavaan-in-sem-do-a-z-test-instead-of-t-test-for-beta</link>
      <description><![CDATA[我一直在学习 SEM，我很好奇为什么 lavaan 使用 z 检验来测试 beta？我在这里读到 https://tdjorgensen.github.io/SEM-in-Ed-compendium/ch2.html，这是因为 SEM 中的估计量假设渐近正态性，自由度很难计算？为什么我们不能只使用常规线性回归中的相同自由度。
下面我有两个相同模型的例子，一个在 lavaan 中，另一个在基础 R 中。
基础简单回归：
lm(Petal.Length ~ Petal.Width, data = iris) |&gt; 
summary()

#&gt; 
#&gt; 调用：
#&gt; lm(formula = Petal.Length ~ Petal.Width, data = iris)
#&gt; 
#&gt; 残差：
#&gt; 最小值 1Q 中位数 3Q 最大值 
#&gt; -1.33542 -0.30347 -0.02955 0.25776 1.39453 
#&gt; 
#&gt; 系数：
#&gt; 估计标准误差 t 值 Pr(&gt;|t|) 
#&gt; (截距) 1.08356 0.07297 14.85 &lt;2e-16 ***
#&gt; Petal.Width 2.22994 0.05140 43.39 &lt;2e-16 ***
#&gt; ---
#&gt;有效代码：0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; 残差标准误差：148 个自由度上的 0.4782
#&gt; 多重 R 平方：0.9271，调整后的 R 平方：0.9266 
#&gt; F 统计量：1 和 148 DF 上的 1882，p 值：&lt; 2.2e-16

SEM 回归：
library(lavaan)
#&gt; 警告：软件包“lavaan”是在 R 版本 4.3.2 下构建的
#&gt; 这是 lavaan 0.6-17
#&gt; lavaan 是免费软件！请报告任何错误。
数据（iris）
sem（“Petal.Length ~ 1 + Petal.Width”，data = iris，）|&gt; 
summary（）

#&gt; lavaan 0.6.17 在 1 次迭代后正常结束
#&gt; 
#&gt; 估计器 ML
#&gt; 优化方法 NLMINB
#&gt; 模型参数数量 3
#&gt; 
#&gt; 观测数 150
#&gt; 
#&gt; 模型测试用户模型：
#&gt; 
#&gt; 测试统计量 0.000
#&gt; 自由度 0
#&gt; 
#&gt; 参数估计：
#&gt; 
#&gt; 标准误差标准
#&gt; 预期信息
#&gt;信息饱和 (h1) 模型结构化
#&gt; 
#&gt; 回归:
#&gt; 估计 Std.Err z 值 P(&gt;|z|)
#&gt; Petal.Length ~ 
#&gt; Petal.Width 2.230 0.051 43.679 0.000
#&gt; 
#&gt; 截距:
#&gt; 估计 Std.Err z 值 P(&gt;|z|)
#&gt; .Petal.Length 1.084 0.072 14.950 0.000
#&gt; 
#&gt; 方差:
#&gt; 估计 Std.Err z 值 P(&gt;|z|)
#&gt; .Petal.Length 0.226 0.026 8.660 0.000

```
]]></description>
      <guid>https://stats.stackexchange.com/questions/639695/why-does-lavaan-in-sem-do-a-z-test-instead-of-t-test-for-beta</guid>
      <pubDate>Tue, 20 Feb 2024 02:42:47 GMT</pubDate>
    </item>
    <item>
      <title>单个点或 1 个群体的重要性</title>
      <link>https://stats.stackexchange.com/questions/610635/significance-of-a-single-point-or-population-of-1</link>
      <description><![CDATA[这听起来可能很简单，但我搞不懂。我有一个简单的实验，15 个对照和 15 个治疗。15 个对照中有 13 个呈阳性，但治疗样本中只有一个呈阳性。这使得 SD = 0，因此 t 检验等失败。很明显样本之间存在差异，但我没有测试来验证。
我可以根据对照结果建立一个模型并模拟一些数据，但样本量太小，模型会很糟糕。我可以使用概率，因此预计 86% 为阳性，但只发现 0.06%。我可以使用假设的错误率，比如 13%（15 个中的 2 个），结果仍然远远超出预期。
有什么建议吗？我看到这个问题也有类似的问题，但对重要性还没有明确的解决方案。
谢谢

好的，谢谢你提供的零假设检验链接。这是我为了证明结果的稀有性而想出的答案。虽然解释起来仍然很棘手。但这是我的示例的概率表。本质上有 155117520 种可能的组合，但只有 225 种只有一个阳性，所以是 0.0001%。相比之下，对照组有 13 个阳性，有 11025 种可能性，可能发生的概率为 13%。所以作为对照组，这个概率是 87%。在这种情况下，SE 是 1.41，我想要一个 95% 的置信区间，所以我期望 95*1.41% 的点，也就是 1.34%。因此，要接受治疗组为对照组的零假设，我预计值为 87% +- 1.34% 或实际上为 12 到 14 个阳性值。
那么问题就变成了如何解释。我认为我的治疗组应在对照组的 95% CI 范围内。这听起来正确吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/610635/significance-of-a-single-point-or-population-of-1</guid>
      <pubDate>Fri, 24 Mar 2023 18:59:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么权重矩阵要对 CBOW/skip-gram 中的词嵌入进行编码？</title>
      <link>https://stats.stackexchange.com/questions/591005/why-should-the-weight-matrix-encode-word-embeddings-in-cbow-skip-gram</link>
      <description><![CDATA[抱歉，这个问题是初学者级别的，但我对 NLP 领域还很陌生，正在尝试更好地理解 word2vec 如何创建有用的词嵌入。
我正在寻找一个直观的解释，说明为什么在使用 word2vec 算法创建词嵌入时，权重矩阵应该包含与词嵌入相关的有用信息。据我了解，当使用 CBOW 或 skip-gram 模型时，我们将单热向量输入浅层神经网络，并训练网络预测缺失词或上下文词（取决于我们使用的是 CBOW 还是 skip-gram 方法）。然后，我们将学习到的权重矩阵的列作为词汇表中单词的向量表示。
我无法理解/内化的是，为什么网络生成的权重矩阵实际上应该具有表示每个单词的有用词嵌入的列（即，为什么网络必须包含列，使得具有相似含义的单词在嵌入空间中彼此靠近？）。似乎您可以想象网络学习创建一个权重矩阵来执行特定任务（预测缺失的单词/预测上下文单词），而矩阵与词嵌入无关。
也许我只是在这里忽略了一些愚蠢的东西，但如果有人可以对此做出解释，那将对我有很大帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/591005/why-should-the-weight-matrix-encode-word-embeddings-in-cbow-skip-gram</guid>
      <pubDate>Mon, 03 Oct 2022 20:53:26 GMT</pubDate>
    </item>
    </channel>
</rss>