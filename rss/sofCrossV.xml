<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 15 Nov 2024 18:23:22 GMT</lastBuildDate>
    <item>
      <title>威尔科克森符号秩检验总是发现随机生成的比率不同于 1？</title>
      <link>https://stats.stackexchange.com/questions/657325/wilcoxon-signed-rank-test-always-finding-randomly-generated-ratios-to-be-differe</link>
      <description><![CDATA[我需要测试实验中的一组比率（根据成对样本的条件 1/条件 2 计算）是否与一个比率有显著差异。实验中的所有测量值都是正实数，因此我认为 1 附近的分布将更符合对数正态性，因此 t 检验不合适。我的第一个想法是使用 Wilcoxon 符号秩检验（如 scipy.stats.wilcoxon 中实现的）。我想先用建模数据测试它，看看这样做是否合理，但我不明白结果。我正在使用下面的代码来测试它。
import numpy as np
from scipy.stats import wilcoxon, ttest_1samp

n_iters = int(1e4)
n_samps = int(100)
n_sig = 0
for iter in range(n_iters):
s0 = np.random.rand(n_samps)
s1 = np.random.rand(n_samps)
ratio = s0/s1
p = wilcoxon(ratio-1, alternative=&#39;greater&#39;).pvalue
# p = ttest_1samp(np.log(ratio), 0, alternative=&#39;greater&#39;).pvalue
if p &lt; 0.05：
n_sig += 1
print(n_sig/n_iters*100)

按原样运行此代码，大约一半的比率是“显著的”。随着 n_samps（每次迭代抽取的样本数量）的增加，显著的比率数量增加到 100%。考虑到我选择的 p 阈值，我预计大约 5% 的比率是显著的。如果我将 p 值计算为 p = ttest_1samp(np.log(ratio), 0, alternative=&#39;greater&#39;).pvalue（当前已注释掉），无论 n_samps 的值是多少，我总是得到 ~5% 的测试是显著的。
我误解了 Wilcoxon 检验吗？我以为它是专门用于基础分布不正常的情况。请注意，随机样本 s0 和 s1 都是使用同一函数生成的，该函数取自区间 [0, 1) 上的均匀分布，因此虽然中位数为 1，但我认为分布更符合对数正态性。]]></description>
      <guid>https://stats.stackexchange.com/questions/657325/wilcoxon-signed-rank-test-always-finding-randomly-generated-ratios-to-be-differe</guid>
      <pubDate>Fri, 15 Nov 2024 18:14:17 GMT</pubDate>
    </item>
    <item>
      <title>如果 alpha = 0.05 时 p 值为 0.0503，我们是否拒绝原假设？如果有的话，用什么方法可以验证拒绝？</title>
      <link>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</link>
      <description><![CDATA[我知道它大于 0.05，但我只是想知道，因为将其四舍五入到小数点后两位会得到 0.05。我只是想确保我没有错误地接受零假设。有没有办法说，即使这个值接近 alpha，也有足够的证据拒绝零假设？
另外，我知道我不应该这样做，但在进行事后分析后，我得到了不同治疗之间的均值结果。
感谢那些花时间回答的人！]]></description>
      <guid>https://stats.stackexchange.com/questions/657324/do-we-reject-null-if-we-have-a-pvalue-of-0-0503-at-alpha-0-05-what-way-to-val</guid>
      <pubDate>Fri, 15 Nov 2024 17:58:11 GMT</pubDate>
    </item>
    <item>
      <title>REML 与 ML 的比较</title>
      <link>https://stats.stackexchange.com/questions/657323/comparisions-between-reml-and-ml</link>
      <description><![CDATA[我有两个问题，非常感谢您的回答。
如果最大似然 (ML) 和限制最大似然 (REML) 方法在模型中具有相同的固定效应，那么这两种方法的结果是否具有可比性？
当 ML 和 REML 以相同的固定效应应用时，它们是否会产生相同的固定效应估计方差？
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/657323/comparisions-between-reml-and-ml</guid>
      <pubDate>Fri, 15 Nov 2024 17:44:11 GMT</pubDate>
    </item>
    <item>
      <title>哪个更好：带有 GPU 的 tensorflow 2.3.0 还是仅带有 CPU 的 tensorflow 2.18.0？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/657321/which-is-better-tensorflow-2-3-0-with-gpu-or-tensorflow-2-18-0-with-only-cpu</link>
      <description><![CDATA[与仅使用 CPU 的 tensorflow 2.18.0 相比，使用 GPU 运行 tensorflow 2.3.0 的速度如何？
硬件

笔记本电脑：MacBook Pro 15 英寸 2012 64 位。
操作系统：Windows 10 Pro 22H2
处理器：Intel(R) Core(TM) i7-4850HQ CPU @ 2.30GHz
GPU：GeForce GT 750M，计算能力 3.0，GeForce Game Ready 驱动程序 425.31 WHQL。

目的

在 R 中学习 keras。

为什么选择 tensorflow 2.3.0？

由于我的笔记本电脑的内部 GPU 具有 3.0 的计算能力，而大多数当前的 tensorflow 应用程序需要 3.5+ 的计算能力，因此我必须编译自己的 tensorflow 安装程序 wheel 文件“tensorflow-2.3.0-cp37-cp37m-win_amd64.whl”并使用兼容的 CUDA 10.1 和 cuDNN 7.6 来利用现有的 GPU。
因此，我需要运行 python 版本 3.7.11（默认，2021 年 7 月 27 日，09:42:29）[MSC v.1916 64 位 (AMD64)]、numpy 1.18.5、keras 2.11.0（由 pip list | grep keras 报告，但 keras:::keras_version() 报告 2.4.0）、TensorFlow v2.3.0，但不是更高版本。
tensorflow 会话检测到 1 个 CPU 和 1 个 GPU，如硬件中所述

tensorflow 2.18.0 怎么样？

我可以更新截至 2024 年 11 月 15 日，升级到 python 3.12.7、keras 3.6 和 tensorflow 2.18。
但我将无法访问 GPU，因为最新版本的软件与旧版 GPU 不兼容。

考虑到我的硬件容量和软件版本的限制，我想知道我应该选择带 GPU 的 tensorflow 2.3.0 还是只带 CPU 的 tensorflow 2.18.0。我了解某些 keras 函数（例如用于图像旋转和数据增强的 layer_random_rotation() 需要 Tensorflow 版本 &gt;=2.6）仅在更高版本的 tensorflow 中可用，但我尚未启动计算机视觉应用程序或海量数据（多个 GB）。GPU 访问是否提供了足够的优势来证明跳过最新的软件版本是合理的？]]></description>
      <guid>https://stats.stackexchange.com/questions/657321/which-is-better-tensorflow-2-3-0-with-gpu-or-tensorflow-2-18-0-with-only-cpu</guid>
      <pubDate>Fri, 15 Nov 2024 17:24:35 GMT</pubDate>
    </item>
    <item>
      <title>Skew-Normal AFT 上的 AIC 较低</title>
      <link>https://stats.stackexchange.com/questions/657319/low-aic-on-skew-normal-aft</link>
      <description><![CDATA[我对基于斜正态分布的 AFT 模型感兴趣。为此，我以以下文章为依据。运行该模型并将其与其他模型（如 Weibull、Exponential、Logistic、Gamma）进行比较时，我发现斜正态模型中的 AIC 和 BIC 更好，但绘制曲线并与 Kaplan-Meier 估计量进行比较时，SN 模型曲线（视觉上）拟合得不太好。这是怎么回事？我尝试在文献或互联网上搜索，但没有找到太多信息。我将不胜感激任何帮助或参考资料。我附上了我的代码和图片
f_x_sn = function(x,xi,sigma,alpha){
return( 1/(sigma * x) * dsn(log(x), xi,sigma,alpha ) )
}

S_x_sn = function(x,xi,sigma,alpha){
return( 1-psn( log(x),xi,sigma,alpha ) )
}

skew_normal = function( parametros ){

sigma = parametros[1]

alpha = parametros[2]

betas = parametros[3:length(parametros)] # 不含协变量

X = matrix(1, nrow(data),1 )

log_like = sum( delta*( log(f_x_sn(time, X%*%betas,sigma, alpha ) ) )) + 
sum( (1 - delta ) * log( S_x_sn(time, X%*%betas,sigma, alpha ) ) ) 

return(log_like)
}

initial_1_4 = c(1,1,1) 
resultado_1_4 = optim(par = inicial_1_4, fn = skew_normal, control = list(fnscale = -1))
resultado_1_4$par

例如，在生存 (survival::leukemia) 的数据集“白血病”中，我有
&gt; 2*3 - 2*skew_normal( resultado_1_4$par )
[1] 157.4882
&gt; AIC(ggamma_model4)
[1] 166.6783
&gt; AIC(exp_model4)
[1] 168.6359
&gt; AIC(weibull_model4)
[1] 170.3573
&gt; AIC(loglogistic_fit4)
[1] 165.1117

使用不含协变量的模型（使用 flexsurv）。图为
]]></description>
      <guid>https://stats.stackexchange.com/questions/657319/low-aic-on-skew-normal-aft</guid>
      <pubDate>Fri, 15 Nov 2024 16:13:54 GMT</pubDate>
    </item>
    <item>
      <title>泛化误差与模型复杂度呈 U 形曲线（偏差方差权衡）</title>
      <link>https://stats.stackexchange.com/questions/657317/generalization-error-as-u-shape-curve-with-respect-to-model-complexity-bias-var</link>
      <description><![CDATA[是否有任何数学著作严格证明某些学习问题的泛化误差随模型复杂度（偏差方差权衡）呈现 U 形曲线？有任何参考资料吗]]></description>
      <guid>https://stats.stackexchange.com/questions/657317/generalization-error-as-u-shape-curve-with-respect-to-model-complexity-bias-var</guid>
      <pubDate>Fri, 15 Nov 2024 15:41:58 GMT</pubDate>
    </item>
    <item>
      <title>识别聚类输出的预测因子？</title>
      <link>https://stats.stackexchange.com/questions/657316/identify-predictors-for-clustering-output</link>
      <description><![CDATA[我有一个数据集，其中包含多年前收集的变量，以及今年收集的许多作为结果变量的变量。我想将今年收集的所有变量组合起来以获得一个结果，例如反映整体功能，以将结果数量减少到一个。这可以通过 K 均值聚类实现，从而给出两个聚类解决方案。
现在我想调查多年前收集的哪些变量是结果（例如，整体功能）的预测因子，测试几种机器学习方法（逻辑回归、SVM、决策树等）。
尝试预测聚类结果是一个可行的问题吗？
我理解在完整（结果）数据集上初始化聚类然后分成训练/测试会导致一些数据泄漏。这是一个大问题吗，或者有什么方法可以解决这个问题？我担心在训练/测试集中单独进行聚类不会提供相同的聚类。]]></description>
      <guid>https://stats.stackexchange.com/questions/657316/identify-predictors-for-clustering-output</guid>
      <pubDate>Fri, 15 Nov 2024 15:20:48 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 R 中具有交互项的多项式 Logit 模型中的缺失标准差、z 值和 p 值？</title>
      <link>https://stats.stackexchange.com/questions/657322/how-to-resolve-missing-std-error-z-value-and-p-value-in-multinomial-logit-mod</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/657322/how-to-resolve-missing-std-error-z-value-and-p-value-in-multinomial-logit-mod</guid>
      <pubDate>Fri, 15 Nov 2024 15:13:32 GMT</pubDate>
    </item>
    <item>
      <title>R 中的多级模型</title>
      <link>https://stats.stackexchange.com/questions/657314/multilevel-model-in-r</link>
      <description><![CDATA[我有一项研究的数据，其中 19 名参与者（9 名男性，10 名女性）每人完成了 4 种跳跃条件（体重，20、​​25、30），同时我测量了髋部、膝盖和踝部的关节水平数据。我想看看负荷（体重，20、​​25、30）、关节（髋部、膝盖、踝部）和性别（男性、女性）对峰值关节速度、力矩、功率和功的影响，并认为多级模型是合适的。
由于我是这种分析的新手，我想知道是否有人有任何具体的指导/建议，或者可能是任何视频或文档的链接，可能对我特别有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/657314/multilevel-model-in-r</guid>
      <pubDate>Fri, 15 Nov 2024 14:46:47 GMT</pubDate>
    </item>
    <item>
      <title>看似不相关的回归系数的齐次检验中，如何选择统计显著性水平？</title>
      <link>https://stats.stackexchange.com/questions/657312/how-to-choose-the-level-of-statistical-significance-for-test-of-equaility-of-see</link>
      <description><![CDATA[可以比较看似不相关的模型的效应 [1] [2] [3]。例如，DV 可能相关，IV 可能相关。无论如何，分析师会测试已经评估过重要性的回归系数是否相等，因为它们本身具有实质性的意义。

您会选择与回归系数统计显著性水平相同或类似的统计显著性水平进行相等性检验吗？

或者，您会选择较低的显著性水平（例如 90%）还是较高的显著性水平（例如 99%）进行相等性检验？


或者，更一般地说，统计检验的选择是否表明应该选择什么统计显著性水平？
可以肯定的是，这个问题反映了频率论的观点。]]></description>
      <guid>https://stats.stackexchange.com/questions/657312/how-to-choose-the-level-of-statistical-significance-for-test-of-equaility-of-see</guid>
      <pubDate>Fri, 15 Nov 2024 12:14:48 GMT</pubDate>
    </item>
    <item>
      <title>当方差估计量不是样本方差时的 T 检验</title>
      <link>https://stats.stackexchange.com/questions/657305/t-test-when-variance-estimator-is-not-sample-variance</link>
      <description><![CDATA[众所周知，如果 $x \sim \mathcal{N}(0, \sigma^2)$，并且我们有一个 $n$ 个 $x$ 观测样本，则 $\frac{x}{\hat{\sigma}}$ 的分布（其中 $\hat{\sigma}$ 是样本方差）将遵循具有 $n-1$ 自由度的 Studnent-t 定律。
但是，如果 $\sigma$ 的 ML 估计量在功能上受到惩罚，即 $\sigma = f(\theta)$，而 $\sigma$ 的估计量 $\hat{\sigma}(\theta)$ 只能通过 $\theta$ 的 MLE 以数值方式获得？在这种情况下，我们能对 $\frac{x}{\hat{\sigma}(\theta)}$ 的分布说些什么吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/657305/t-test-when-variance-estimator-is-not-sample-variance</guid>
      <pubDate>Fri, 15 Nov 2024 10:29:48 GMT</pubDate>
    </item>
    <item>
      <title>（更完整）证明 Fisher 信息是可加的</title>
      <link>https://stats.stackexchange.com/questions/657303/more-complete-proof-the-fisher-information-is-additive</link>
      <description><![CDATA[对于独立、同分布的变量，众所周知，Fisher 信息是可加的，即
\begin{align}
\mathcal{I}_n(\theta)&amp;=\left&lt;{\left({\frac{\partial}{\partial\theta}\log f(X_1, X_2, \dots, X_n)}\right)^2}\right&gt;\\
&amp;=n\left&lt;{\left({\frac{\partial}{\partial\theta}\log f(X_1)}\right)^2}\right&gt;\\
&amp;=n\mathcal{I}_1(\theta).
\end{align&gt;
这些行不是证明，而是一个陈述。当我尝试解决这个问题时，我知道我应该使用变量是独立的，但我不知道如何做。如果我针对两个变量尝试此方法，则会得到如下结果：
\begin{align}
\left&lt;\left(\frac{\partial}{\partial\theta}\log f(X_1, X_2)\right)^2\right&gt;=&amp;\left&lt;\left(\frac{\partial}{\partial\theta}\log f(X_1)f( X_2)\right)^2\right&gt;\\
=&amp;\left&lt;\left(\frac{\partial}{\partial\theta}\log f(X_1)+\log f(X_2)\right)^2\right&gt;\\
=&amp;\mathcal I_1(\theta)+\mathcal I_2(\theta)+2\left&lt;\left(\frac{\partial}{\partial\theta}\log f(X_1)\right)\left(\frac{\partial}{\partial\theta}\log f(X_2)\right)\right&gt;
\end{align
因此最后一项应为零。如果该项分解为因子，
$$\left&lt;\left(\frac{\partial}{\partial\theta}\log f(X_1)\right)\left(\frac{\partial}{\partial\theta}\log f(X_2)\right)\right&gt;\overset{?}{=}
\left&lt;\frac{\partial}{\partial\theta}\log f(X_1)\right&gt;\left&lt;\frac{\partial}{\partial\theta}\log f(X_2)\right&gt;,
$$
我们完成了，因为我们在真实参数值处进行评估，并且分数的方差为零。但是我们如何知道这是真的？因为变量是独立的，我们只知道$\left&lt;X_1X_2\right&gt;=\left&lt;X_1\right&gt;\left&lt;X_2\right&gt;$。]]></description>
      <guid>https://stats.stackexchange.com/questions/657303/more-complete-proof-the-fisher-information-is-additive</guid>
      <pubDate>Fri, 15 Nov 2024 10:04:51 GMT</pubDate>
    </item>
    <item>
      <title>如何设置 R 包 MGCV 来运行多项式家族？</title>
      <link>https://stats.stackexchange.com/questions/657318/how-can-i-set-up-the-r-package-mgcv-to-run-a-multinomial-family</link>
      <description><![CDATA[我正在尝试使用 GAM 根据各种气候和土地使用因素对野火规模进行建模。我一直遇到的问题是，我的火灾规模数据无法很好地适应任何分布族。有很多小火灾，但很少有非常大的火灾。我尝试过伽马、逆高斯等。我和我的委员会不愿意在建模之前转换我的数据。因此，我开始将野火划分为火灾大小类别（即 &lt;500 公顷、500--1000、1000--10,000、10000-100,000、&gt;100,000。如果我理解正确的话，MGCV 有一个多项式系列，可以让我模拟火灾属于这些大小类别的概率。但是，我无论如何也想不出如何设置它。我有 6 个预测变量和 5 个分箱类别。R 文档说 K=#categories-1。
region_list &lt;- lapply(L3_data, function(region) { #L3_data 是我的按区域划分的数据
x &lt;- region
f1 &lt;- formula(binned_sizes ~ s(vpd) + s(vs)+ s(sm) +s(pdsi)+ s(percent_cover)+s(spei30), data = x)
f&lt;-replicate(4,update(f1))
f[[1]] &lt;- update(f[[1]], binned_sizes~.)
output_model &lt;- gam(f,
data = x,
family = multinom(K=4),
method = &quot;fREML&quot;)
print(summary(output_model))
})

这是我得到的错误：
gam.fit5(x, y, sp, Sl = Sl, weights = weights, offset = offset, 中的错误：
gam.fit5 中的不确定惩罚可能性]]></description>
      <guid>https://stats.stackexchange.com/questions/657318/how-can-i-set-up-the-r-package-mgcv-to-run-a-multinomial-family</guid>
      <pubDate>Fri, 15 Nov 2024 09:46:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么数据引导可以修改来自同一分布的总体的斜率？</title>
      <link>https://stats.stackexchange.com/questions/657250/why-could-data-bootstraping-modifiy-the-slope-of-a-population-comming-from-the-s</link>
      <description><![CDATA[我正在引导一些样本来计算斜率（有替换）。一旦完成，应该具有相同分布的斜率就不会具有相同的分布。要清楚，我不是要求调试代码，而是要求理解为什么我会引入偏差。
这是 R 中可重现的代码：
library(plotly)

N&lt;- 3000
x &lt;- runif(N,0,1)*5
y &lt;- x + rnorm(N, 1, .2)
y2 &lt;- x + rnorm(N, 1, .2)
t.test(y,y2)
dummy &lt;- rep(c(TRUE,FALSE),each = N)
df &lt;- data.frame(x = c(x,x), y = c(y,y2), dummy = dummy)

fig &lt;- plot_ly() %&gt;%
add_trace(x = df[df$dummy == TRUE,]$x, y = df[df$dummy == TRUE,]$y) %&gt;%
add_trace(x = df[df$dummy == FALSE,]$x, y= df[df$dummy == FALSE,]$y)
图

boot_strap &lt;- function(data, n_bootstraps){
输出 &lt;- sapply(1:n_bootstraps, function(i){
tmp &lt;- data[sample(seq_len(nrow(data)), nrow(data), replace = TRUE),]
模型 &lt;- lm(y ~ x, data = tmp)
return(coef(model)[2])
})
返回（输出）
}

for (size in c(1e2, 2e2, 5e2, 1e3, 1e4)){
sample_1 &lt;- boot_strap(df[df$dummy == TRUE,], size)
sample_2 &lt;- boot_strap(df[df$dummy == FALSE,], size) 
print(paste0(&#39;Size: &#39;, size,&#39; - Pvalue: &#39;, t.test(sample_1, sample_2)$p.value))
}

fig &lt;- plot_ly() %&gt;%
add_histogram(sample_1) %&gt;%
add_histogram(sample_2)
fig

数据：


这里我们没有差异，因为来自同一人群（如第一个 T 检验所示）是预期的
但另一方面，斜率的分布明显不同。


我的偏见在哪里？]]></description>
      <guid>https://stats.stackexchange.com/questions/657250/why-could-data-bootstraping-modifiy-the-slope-of-a-population-comming-from-the-s</guid>
      <pubDate>Thu, 14 Nov 2024 13:56:47 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有特定选择变量的模型中使用 mlogit</title>
      <link>https://stats.stackexchange.com/questions/657226/how-to-use-mlogit-for-models-where-there-are-no-choice-specific-variables</link>
      <description><![CDATA[假设有人想在两部手机和两种颜色之间建立产品选择模型，但手机 1 只有红色或绿色，而手机 2 只有蓝色或黑色。因此选择中存在嵌套。但是，没有特定于选择的变量。如果为此使用 mlogit，下面的代码是否正确？
mlogit(choice ~ 1 | gender + age, data = ddataset, 
nests = nests)

其中 ddataset 格式化为长格式，每个参与者有 4 行（每个选择一行），但性别和年龄对于每一行都具有相同的值（因为它们属于同一个人）。
注意：选择特定变量的意思是没有因选项而异的预选特征。例如，我们选择特定的选项可能是产品的价格。我们可以让每个受访者的价格有所不同。例如，对于受访者 1 来说，手机 1 的价格可能是 100，而手机 2 的价格是 150。对于受访者 2 来说，情况可能会有所不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/657226/how-to-use-mlogit-for-models-where-there-are-no-choice-specific-variables</guid>
      <pubDate>Wed, 13 Nov 2024 22:25:54 GMT</pubDate>
    </item>
    </channel>
</rss>