<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Sun, 22 Sep 2024 18:20:12 GMT</lastBuildDate>
    <item>
      <title>如何使用自动编码器提取图像特征？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/654730/how-to-extract-features-of-images-using-autoencoders</link>
      <description><![CDATA[我想使用自动编码器计算输入图像的特征。代码如下：
import keras
from keras import layer

input_img = keras.Input(shape=(28, 28, 1))

x = layer.Conv2D(16, (3, 3),activation=&#39;relu&#39;, padding=&#39;same&#39;)(input_img)
x = layer.MaxPooling2D((2, 2), padding=&#39;same&#39;)(x)
x = layer.Conv2D(8, (3, 3),activation=&#39;relu&#39;, padding=&#39;same&#39;)(x)
x = layer.MaxPooling2D((2, 2), padding=&#39;same&#39;)(x)
x = layer.Conv2D(8, (3, 3),activation=&#39;relu&#39;, padding=&#39;same&#39;)(x)
encoded = layer.MaxPooling2D((2, 2), padding=&#39;same&#39;)(x)

# 此时表示为 (4, 4, 8)，即 128 维

x = layer.Conv2D(8, (3, 3),activation=&#39;relu&#39;, padding=&#39;same&#39;)(encoded)
x = layer.UpSampling2D((2, 2))(x)
x = layer.Conv2D(8, (3, 3),activation=&#39;relu&#39;, padding=&#39;same&#39;)(x)
x = layer.UpSampling2D((2, 2))(x)
x = layer.Conv2D(16, (3, 3),activation=&#39;relu&#39;)(x)
x = layer.UpSampling2D((2, 2))(x)
decoded = layer.Conv2D(1, (3, 3),activation=&#39;sigmoid&#39;, padding=&#39;same&#39;)(x)

autoencoder = keras.Model(input_img，已解码)
autoencoder.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;)

从 keras.datasets 导入 mnist
将 numpy 导入为 np

(x_train, _), (x_test, _) = mnist.load_data()

x_train = x_train.astype(&#39;float32&#39;) / 255.
x_test = x_test.astype(&#39;float32&#39;) / 255.
x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))
x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))

从 keras.callbacks 导入 TensorBoard

autoencoder.fit(x_train, x_train,
epochs=50,
batch_size=128,
shuffle=True,
validation_data=(x_test, x_test),
callbacks=[TensorBoard(log_dir=&#39;/tmp/autoencoder&#39;)])

我想提取图像的特征。要提取图像的特征，我需要访问编码器的输出。如何编写 Python 代码来提取输入图像的特征？]]></description>
      <guid>https://stats.stackexchange.com/questions/654730/how-to-extract-features-of-images-using-autoencoders</guid>
      <pubDate>Sun, 22 Sep 2024 14:19:25 GMT</pubDate>
    </item>
    <item>
      <title>哪种条件交叉制表解释是合适的？</title>
      <link>https://stats.stackexchange.com/questions/654729/which-conditional-cross-tabulation-interpretation-is-appropriate</link>
      <description><![CDATA[假设是老年人不太可能说外语。
交叉表结果如下：

我的问题是：在下面的解释中，哪一个是正确的，为什么另一个是错误的？
解释 1：接受假设是因为在回答“是”的人中，37.3% 的人年龄在 30 岁以下，18.7% 的人年龄在 30-39 岁之间，17.5% 的人年龄在 40-49 岁之间，11.6% 的人年龄在 50-59 岁之间，只有 15% 的人年龄在 30 岁以上60.
解释 2：接受假设，因为在回答“是”的人中，70.8% 的人年龄在 30 岁以下，39.6% 的人年龄在 30-39 岁之间，42.1% 的人年龄在 40-49 岁之间，27.5% 的人年龄在 50-59 岁之间，19.3% 的人年龄在 60 岁以上。]]></description>
      <guid>https://stats.stackexchange.com/questions/654729/which-conditional-cross-tabulation-interpretation-is-appropriate</guid>
      <pubDate>Sun, 22 Sep 2024 14:13:19 GMT</pubDate>
    </item>
    <item>
      <title>我们可以手动对每个学生进行 t 检验吗？还是我应该在干预之前和之后对所有学生进行 t 检验？</title>
      <link>https://stats.stackexchange.com/questions/654724/can-we-make-a-t-test-manually-to-each-student-or-should-i-take-all-the-students</link>
      <description><![CDATA[我有一个行动研究，我应该测试干预前后学生的成绩，我的研究仅基于 6 名患有注意力缺陷多动障碍的学生。我想做一个 t 检验，看看结果是否显著为正。我有 5 个测试，一个在干预前，三个在干预中，一个在干预后，我该如何进行 t 检验呢？]]></description>
      <guid>https://stats.stackexchange.com/questions/654724/can-we-make-a-t-test-manually-to-each-student-or-should-i-take-all-the-students</guid>
      <pubDate>Sun, 22 Sep 2024 10:45:01 GMT</pubDate>
    </item>
    <item>
      <title>如何解释具有多个变量和单个变量的 GAM？</title>
      <link>https://stats.stackexchange.com/questions/654727/how-to-interpret-gams-with-multiple-vs-single-variables</link>
      <description><![CDATA[因此，我一直在尝试使用 GAM 来观察总体经济损失（由于某个事件）与各种因素之间的关系，包括事件总数、受影响的总人数、基础设施发展水平等。
以下是我迄今为止尝试过的方法：
library(mgcv)

model1&lt;-gam(total_damages~s(total_events)+s(total_affected)+s(coastlines)+s(total_gdp, k=1)+s(urban_landarea)+s(infrastructure_index), tw(link=&quot;log&quot;))

我使用了 tw(link=&quot;log&quot;)，因为 total_damages 不是正态分布的。我绘制了一个直方图来检查。我还注意到这个变量的方差比其平均值大得多。但是，如果在这里使用 tweedie 是错误的，请告诉我。
此外，我不太确定是否应该对所有独立变量使用平滑函数。我注意到 total_gdp 与 total_damages 具有线性关系，因此我设置了 k=1。但是，我不太确定对这么多变量使用平滑函数是否会产生任何影响。
我想向您展示我从这个模型中获得的结果。
summary(model1)


我认为 p 值在这种情况下用处不大。我想知道 R-sq.-adj 和“偏差解释”值在这里是否有价值。如果它们在 GAM 中具有重要意义，请告诉我。
我想在此处显示其中一个图表：
plot(model1)


该图显示了独立变量 (infrastructure_index) 和平滑“s(infrastructure_index)”之间的图。该线看起来有点直，但查看系数 (coef(model1)) 告诉我它们经常在负值和正值之间波动。我认为这意味着基础设施指数和总损害之间存在不规则关系？
我尝试对另一个 GAM 进行建模，但这次，我只专注于使用 1 个独立变量“基础设施指数”。
model2&lt;-gam(total_damages~s(infrastructure_index))

这是模型摘要：

R-sq-adj 和 Deviance Explained 值已经下降。但是图表变得更加清晰了，我觉得我对基础设施指数和总损害之间的关系有了更清晰的理解：


具有多个变量的 GAM 模型是否是理解独立变量和总损害之间关系的更好工具？

具有单个变量的 GAM 是否不太有用？为什么这两个图表相差这么大？

我什么时候应该使用具有多个变量而不是单个变量的 GAM？

]]></description>
      <guid>https://stats.stackexchange.com/questions/654727/how-to-interpret-gams-with-multiple-vs-single-variables</guid>
      <pubDate>Sun, 22 Sep 2024 10:23:32 GMT</pubDate>
    </item>
    <item>
      <title>比较 R 中的单变量线性模型</title>
      <link>https://stats.stackexchange.com/questions/654721/comparing-single-variable-linear-model-in-r</link>
      <description><![CDATA[我有一个包含 6 个特征的数据集，并且每次使用一个特征构建简单线性回归。我考虑了调整后的 R 平方值和 p 值来比较并确定这些模型中最佳的简单线性回归模型。
# Model-1
M1X1 &lt;- lm(YHousePriceOfUnitArea~X1TransactionDate, data=rev_data_clean)
summary(M1X1)

M1X2 &lt;- lm(YHousePriceOfUnitArea~X2HouseAge, data=rev_data_clean)
summary(M1X2)

M1X3 &lt;- lm(YHousePriceOfUnitArea~X3distanceToTheNearestMRTstation, data=rev_data_clean)
summary(M1X3)

M1X4 &lt;- lm(YHousePriceOfUnitArea~X4NumberOfConvenienceStores, data=rev_data_clean)
summary(M1X4)

M1X5 &lt;- lm(YHousePriceOfUnitArea~X5Latitude, data=rev_data_clean)
summary(M1X5)

M1X6 &lt;- lm(YHousePriceOfUnitArea~X6Longitude, data=rev_data_clean)
summary(M1X6)

# 比较模型 1 的最佳版本
summary(M1X1)$adj.r.squared
summary(M1X2)$adj.r.squared
summary(M1X3)$adj.r.squared
summary(M1X4)$adj.r.squared
summary(M1X5)$adj.r.squared
summary(M1X6)$adj.r.squared

# 版本的 p 值model-1
summary(M1X1)$coefficients[2, 4]
summary(M1X2)$coefficients[2, 4]
summary(M1X3)$coefficients[2, 4]
summary(M1X4)$coefficients[2, 4]
summary(M1X5)$coefficients[2, 4]
summary(M1X6)$coefficients[2, 4]

控制台输出：
# 比较 model-1 的最佳版本
&gt; summary(M1X1)$adj.r.squared
[1] 0.005246001
&gt; summary(M1X2)$adj.r.squared
[1] 0.04201891
&gt; summary(M1X3)$adj.r.squared
[1] 0.4524284
&gt; summary(M1X4)$adj.r.squared
[1] 0.3244108
&gt; summary(M1X5)$adj.r.squared
[1] 0.2967482
&gt; summary(M1X6)$adj.r.squared
[1] 0.2720662
&gt; 
&gt; # 模型 1 版本的 p 值
&gt; summary(M1X1)$coefficients[2, 4]
[1] 0.07537113
&gt; summary(M1X2)$coefficients[2, 4]
[1] 1.560426e-05
&gt; summary(M1X3)$coefficients[2, 4]
[1] 4.639825e-56
&gt; summary(M1X4)$coefficients[2, 4]
[1] 3.413483e-37
&gt; summary(M1X5)$coefficients[2, 4]
[1] 1.387761e-33
&gt; summary(M1X6)$coefficients[2, 4]
[1] 1.765191e-30

我的比较：如果调整后的 R 平方值较大且 p 值较小，则该模型较好。在这种情况下，具有较高调整 R 平方值和较低 p 值的 M1X3 模型似乎是最好的。
我想确认我的比较是对还是错。]]></description>
      <guid>https://stats.stackexchange.com/questions/654721/comparing-single-variable-linear-model-in-r</guid>
      <pubDate>Sun, 22 Sep 2024 04:37:21 GMT</pubDate>
    </item>
    <item>
      <title>生物统计学作业帮助 - 置信区间/概率</title>
      <link>https://stats.stackexchange.com/questions/654717/biostatistics-homework-help-confidence-intervals-probability</link>
      <description><![CDATA[有人能帮我解决这个问题吗？我很困惑，因为我不知道该如何处理这样的问题？
NHS 正在调查一种旨在降低血液胆固醇水平的新饮食干预措施的有效性。在一项试点研究中，他们的目标是确保参与者的胆固醇水平平均降低至少 0.25 mmol/L，概率最多为 90%。
确定他们需要的最小样本量，以确保他们能够满足此标准。
提示：他们的数据服从正态分布。]]></description>
      <guid>https://stats.stackexchange.com/questions/654717/biostatistics-homework-help-confidence-intervals-probability</guid>
      <pubDate>Sun, 22 Sep 2024 02:44:52 GMT</pubDate>
    </item>
    <item>
      <title>离散随机变量的 CDF 分段常数？</title>
      <link>https://stats.stackexchange.com/questions/654695/cdf-of-a-discrete-random-variable-piecewise-constant</link>
      <description><![CDATA[在我的脚本中，它说：

给定$X$是一个离散随机变量，$\Bbb P(X\in D)=1,D=\{a_1,a_2,\ldots\},p_i:=\Bbb P_X(\{a_i\})&gt;0,\forall i\ge1,$我们有$F_X(x)=\sum\limits_{a_i\le x}p_i,$这意味着离散随机变量的CDF是分段常数。

我的想法
假设$X:\Omega\to\Bbb R$是一个离散随机变量，其中$\Bbb P_X(\{q_i\})=\frac1{2^i}&gt;0,$，其中$\{q_i\}_{i\in\Bbb N}$是$\Bbb Q.$的枚举，因为$\Bbb Q$是稠密的，所以对于每两个$x_1,x_2\in\Bbb R,x_1&lt;x_2,$，存在某个$q_j\in(x_1,x_2)$，意味着$q_j\in(x_1,x_2)$ class=&quot;math-container&quot;&gt;$F_X(x_1)&lt;F(x_2).$ 因此，这似乎与 $F_X$ 是分段常数的说法相矛盾，这让我怀疑如果该说法成立，我的随机变量 $X$ 是否存在。
问题：任何离散随机变量的 CDF 确实是分段常数吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654695/cdf-of-a-discrete-random-variable-piecewise-constant</guid>
      <pubDate>Sat, 21 Sep 2024 13:03:38 GMT</pubDate>
    </item>
    <item>
      <title>基于汇总数据的平均差异</title>
      <link>https://stats.stackexchange.com/questions/654693/mean-difference-based-on-summary-data</link>
      <description><![CDATA[我遇到了以下问题：我想评估 5 个平衡组的平均差异，但我只有可用的汇总数据（平均值、标准差和样本大小），以及汇总数据基于正态分布数据的信息。
我愿意听取有关如何进行的建议。
这是一些示例数据（编辑：更新的数据）
data &lt;- data.frame(
group = c(&quot;probe_a&quot;, &quot;probe_b&quot;, &quot;probe_c&quot;, &quot;probe_d&quot;, &quot;control&quot;),
n = c(10, 10, 10, 10, 10), # 每组样本大小
means = c(57.6, 95.9, 102.9, 69.6, 73.8), # 组平均值
sd = c(4.2, 4.0, 2.7, 7.6, 3.6) # 每组标准差
)

我的方法包括使用 Welch 方差分析 来解释方差不等的情况（如果 Hartley 的 Fmax 表明存在这种情况），然后进行事后 Games-Howell 检验（我需要对几个数据框进行此检验，其中一些数据框的方差不等，但我不想在传统方差分析和 Welch 方差分析之间切换，因此我坚持使用更为稳健的方法）。由于我无法直接检查残差，因此我根据汇总数据和正态性假设对残差进行了模拟，并使用引导来评估是否满足正态分布残差和同方差性的假设，使用Shapiro-Wilk 和 Levene 检验。在 5% 的置信水平下，蒙特卡洛 p 值未超过此阈值，这意味着我拒绝了正态性和同方差性的零假设。这表明残差违反了 Welch 方差分析的假设。由于我的猜测不支持这些假设，我得出结论，Welch 方差分析的 p 值具有探索性，而事后结果是精确的。
编辑：澄清了步骤

检验各组间方差不等：

fmax &lt;- max(sd^2)/min(sd^2)
df &lt;- 5
k &lt;- 9

Hartley 的 Fmax 为 7.9，小于表中的临界 Fmax 值（p &lt; 0.05），表明各组间的方差不同

Welch 的方差分析

准确（Welch）方差分析结果的假设是残差呈正态分布且方差同。但是，由于无法访问基础数据，我无法直接评估残差，因此我模拟了基础数据。

使用蒙特卡罗模拟测试残差

我模拟了 5 个与我的数据汇总统计数据相匹配的正态分布组。使用这些模拟数据，我计算了残差并使用 Shapiro-Wilk 和 Levene 检验对其进行了评估。蒙特卡洛 p 值被确定为这些检验中 p 值不超过我选择的显著性水平的比例
# 相关代码片段
set.seed(578)
for (i in 1:n_sim) {
# 使用 rnorm() 为每个组生成模拟数据
simulated_data_list &lt;- lapply(1:length(means), function(j) {
stats::rnorm(n = n[j], mean = means[j], sd = sd[j])
})

# 通过减去组均值来计算残差
means_of_groups &lt;- sapply(simulated_data_list, mean)
residuals_list &lt;- mapply(function(data, mean) data - mean,
simulated_data_list, means_of_groups,
SIMPLIFY = FALSE)

# 执行正态性和同方差检验
sw_pval[i] &lt;- shapiro_wilk_test(residuals_list)
l_pval[i] &lt;- 同方差检验(residuals_list)
}
normality_prop &lt;- mean(sw_pval &lt; 0.05)
homoscedasticity_prop &lt;- mean(l_pval &lt; 0.05)

Shapiro-Wilk 检验 p 值 &lt; 0.05（表明残差非正态分布）的模拟比例：
0.29（n_sim = 5000）
Leven-Test p 值 &lt; 的模拟比例0.05（表明非同方差残差）：
0.49（n_sim = 5000）
我的问题：
这是一种有效的方法吗？
由于蒙特卡罗模拟表明（Welch）方差分析假设不成立，是否有更稳健的方法来获得精确的 p 值。]]></description>
      <guid>https://stats.stackexchange.com/questions/654693/mean-difference-based-on-summary-data</guid>
      <pubDate>Sat, 21 Sep 2024 11:32:47 GMT</pubDate>
    </item>
    <item>
      <title>证明：高斯核作为无限维特征空间中的内积</title>
      <link>https://stats.stackexchange.com/questions/654689/proof-the-gaussian-kernel-as-an-inner-product-in-infinite-dimensional-feature-s</link>
      <description><![CDATA[证明对于正整数 $d $，$ \mathbb{R}^d $ 上的高斯核：
\begin{equation}
k(x, x&#39;) = \exp(-\gamma \|x - x&#39;\|^2) \tag{1}
\end{equation&gt;
对于 $\gamma &gt; 0 $，可以表示为无限维特征空间中的内积。
为此，首先证明如果 $ k&#39; $ 是 $ X $ 上的核，则对于 $ \phi: X \to \mathbb{R} $，成立：
\begin{equation}
k&#39;&#39;(x, x&#39;) = \phi(x)k&#39;(x, x&#39;)\phi(x&#39;) \tag{2}
\end{equation&gt;
也是 $ X$ 上的核。我不太清楚如何展示它，但我认为我应该使用指数幂级数$\exp(x)=\sum_{i=0}^{\infty}\frac{x^i}{i!}$。有人能帮忙吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/654689/proof-the-gaussian-kernel-as-an-inner-product-in-infinite-dimensional-feature-s</guid>
      <pubDate>Sat, 21 Sep 2024 09:38:05 GMT</pubDate>
    </item>
    <item>
      <title>构建具有不同和未知方差的 $\mu_X-\mu_Y$ 的置信区间</title>
      <link>https://stats.stackexchange.com/questions/654688/construct-confidence-interval-for-mu-x-mu-y-with-different-and-unknown-varia</link>
      <description><![CDATA[我正在自学统计学课程，以前的考试试卷中也出现过这个问题（没有解决方案）。
问题：
给定$X_1,\ldots,X_n$是从$N(\mu_X,\sigma_X^2)$中抽取的独立随机样本，$Y_1,\ldots,Y_m$是从$N(\mu_Y,\sigma_Y^2)$中抽取的独立随机样本，假设这两个随机样本是独立的。同时给定$$U=\frac{\overline{X}-\overline{Y}-(\mu_X-\mu_Y)}{\sqrt{\frac{\sigma_X^2}{n}+\frac{\sigma_Y^2}{m}}}\sim N(0,1)$$和$$V_1=\frac{n S_X^2}{\sigma_X^2}\sim\chi_{n-1}^2,V_2=\frac{mS_Y^2}{\sigma_Y^2}\sim \chi_{m-1}^2,V=V_1+V_2$$为$90\%$找到一个置信区间class=&quot;math-container&quot;&gt;$\mu_X-\mu_Y$ 假设 $U$ 和 $V$ 是独立的，$\frac{\sigma_X^2}{\sigma_Y^2}=d$ 其中 $d$ 为某个常数。
我的尝试：
如果 $\sigma_X^2=\sigma_Y^2$，则可以轻松构造区间，因此考虑 $Z_i=\frac{X_i}{\sqrt{d}}\sim N(\frac{\mu_X}{\sqrt{d}},\sigma_Y^2)$。然后我得到了 $$U=\frac{\sqrt{d}\cdot\overline{Z}-\overline{Y}-(\mu_X-\mu_Y)}{\sqrt{\frac{d\cdot\sigma_Y^2}{n}+\frac{\sigma_Y^2}{m}}}\sim N(0,1)$$$$V_1=\frac{nS_Z^2}{\sigma_Y^2}\sim\chi^2_{n-1}$$但是我被卡住了，因为我想不出任何办法摆脱 $\overline{Z}$ 和 分母为$d$。
我的最后一个问题：由于我是 Cross Validated 的新手，有没有可以帮助我搜索问题的网站？（例如 Math Stack Exchange 的 Approach0）。]]></description>
      <guid>https://stats.stackexchange.com/questions/654688/construct-confidence-interval-for-mu-x-mu-y-with-different-and-unknown-varia</guid>
      <pubDate>Sat, 21 Sep 2024 09:35:07 GMT</pubDate>
    </item>
    <item>
      <title>当使用 hayes 过程宏（用于 R）测试并行中介模型时，如何纠正多重测试？</title>
      <link>https://stats.stackexchange.com/questions/654651/how-can-i-correct-for-multiple-testing-when-testing-a-parallel-mediation-model-u</link>
      <description><![CDATA[我知道有多种方法可以校正多重测试（例如 holm bonferroni、bonferroni 方法），但是当我使用 Hayes PROCESS 宏测试并行中介模型时，我不确定如何执行此操作。我是否需要在 PROCESS 之外单独重建回归模型，如果需要，您知道我该怎么做吗？并行中介模型包括 5 个预测因子（一个主要 IV，4 个并行中介因子）和结果变量。非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654651/how-can-i-correct-for-multiple-testing-when-testing-a-parallel-mediation-model-u</guid>
      <pubDate>Fri, 20 Sep 2024 13:23:50 GMT</pubDate>
    </item>
    <item>
      <title>当每个数据点都带来一个置信区间时，如何在两个或多个组之间进行检验？</title>
      <link>https://stats.stackexchange.com/questions/654615/how-to-run-a-test-between-two-or-more-groups-when-each-data-point-brings-a-confi</link>
      <description><![CDATA[我最近开始研究一个数据集，但作为一名应届毕业生，我的经验有限，这阻碍了我取得进展。在执行了项目所需的稀疏化之后，我现在有一个包含 24 个物种多样性指数的数据框，每个指数都伴随着由随机稀疏化过程生成的置信区间。
这 24 个多样性指数属于 2 个不同的非独立组，我需要进行比较。如果没有置信区间，我只能使用均值，我会使用配对 t 检验。
为了解释通过稀疏化获得的置信区间，我尝试使用从区间得出的方差执行加权 t 检验。但是，我对我的方法没有信心，也找不到任何支持这种方法的在线文章。
这是我的数据框：
size1 &lt;- c(32.67256,30.59280,33.56214,30.15552,29.02073,24.92427,34.79967,34.26559,29.33457,25.75716,27.91638,33.87884)
size2 &lt;-c(34.18847,30.94369,37.38462,22.96785,27.98805,31.39834,30.26401,33.59788,36.19856,31.19667,21.27245,28.87137)
尺寸 &lt;-c(尺寸1，尺寸2)
尺寸1CI05 &lt;-c(29.50177,26.23491,29.60487,25.94388,24.48941,21.78924,29.24082,28.09738,25.20056,21.21051,24.40705,30.08490)
size2CI05 &lt;-c(29.51654,23.75201,31.29203,17.60071,21.92296,26.38236,23.69115,26.15880,26.44932,26.72620,17.48761,23.76434)
sizeCI05 &lt;-c(size1CI05,size2CI05)
size1CI95 &lt;-c(35.84336,34.95070,37.51941,34.36716,33.55205,28.05929,40.35851,40.43380,33.46857,30.30381,31.42571,37.67278) 
size2CI95 &lt;-c(38.86039,38.13538,43.47722,28.33500,34.05315,36.41432,36.83687,41.03696,45.94780,35.66713,25.05730,33.97840)
sizeCI95 &lt;-c(size1CI95,size2CI95)
group &lt;- c(c(rep(&quot;1&quot;, 12), rep(&quot;2&quot;, 12))
df &lt;- data.frame(size, sizeCI05, sizeCI95, group)

我还按照要求添加了 dput 输出：
df &lt;-结构（列表（大小 = c（32.67256, 30.5928, 33.56214, 30.15552, 
29.02073, 24.92427, 34.79967, 34.26559, 29.33457, 25.75716, 27.91638, 
33.87884, 34.18847, 30.94369, 37.38462, 22.96785, 27.98805, 31.39834, 
30.26401, 33.59788, 36.19856, 31.19667, 21.27245, 28.87137), 
size05CI = c(29.5017662019491, 26.2349058385758, 29.6048735822698, 
25.9438818737996, 24.4894140422372, 21.7892435074709, 29.2408246478003, 
28.097376313181, 25.2005633026381, 21.2105115402011, 24.4070457401779, 
30.0849045894848, 29.5165407340379, 23.7520071901393, 31.2920265619889, 
17.6007091843407, 21.9229562124319, 26.3823600157115, 23.6911524798744, 
26.158796800294, 26.4493176960902, 26.7262037524753, 17.4876088906701, 
23.7643440166671), size95CI = c(35.8433590913617, 34.9506991382152、37.5194133001315、34.3671592174968、33.5520534941053、28.0592932279925、40.3585126169722、40.43380327644 11、33.4685713521404、30.303809204322、31.4257104335821、37.6727751129716、38.8603902871733、38.1353758799793、 
43.4772171945701, 28.3349990423006, 34.0531465846994, 36.4143170389483, 
36.8368654619253, 41.0369594182707, 45.9478039221974, 35.6671344715295, 
25.0572999101401, 33.9783955274194), group = c(&quot;1&quot;, &quot;1&quot;, 
&quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;2&quot;, &quot;2&quot;, 
&quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;)), class = &quot;data.frame&quot;, row.names = c(NA, 
-24L))

这是我尝试做的：
install.packages(&quot;weights&quot;, dependency=TRUE)
library(weights)
SE1 &lt;- (size1CI95-size1CI05)/3.919928
SE2 &lt;- (size2CI95-size2CI05)/3.919928
sizepaired &lt;- size1-size2
combSE &lt;- sqrt(SE1^2+SE2^2)
weights &lt;- 1/combSE^2
wtd.t.test(x=sizepaired, y=0, weight=weights)

我的方法是使用加权测试来考虑由于测试中的稀疏性而产生的置信区间（即标准偏差），其中权重来自标准偏差。但是，我不确定这是否是一种有效的方法，而且我还没有找到任何涉及此方法的科学文章。我的同事有些怀疑，不愿意使用“实验性”方法。
此外，我目前正在使用参数检验，但在我的数据中（我没有在这里包括），有些数据不遵循正态分布。因此，我应该考虑如何进行加权配对非参数检验]]></description>
      <guid>https://stats.stackexchange.com/questions/654615/how-to-run-a-test-between-two-or-more-groups-when-each-data-point-brings-a-confi</guid>
      <pubDate>Thu, 19 Sep 2024 16:36:06 GMT</pubDate>
    </item>
    <item>
      <title>关于风险模型（离散、固定间隔、固定效应时间）的问题</title>
      <link>https://stats.stackexchange.com/questions/654562/a-question-about-a-hazard-model-discrete-fixed-intervals-fixed-effect-time</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654562/a-question-about-a-hazard-model-discrete-fixed-intervals-fixed-effect-time</guid>
      <pubDate>Wed, 18 Sep 2024 18:54:52 GMT</pubDate>
    </item>
    <item>
      <title>均值的非参数检验？</title>
      <link>https://stats.stackexchange.com/questions/654515/nonparametric-test-for-means</link>
      <description><![CDATA[是否有使用两个独立样本的非参数均值相等性检验？
最流行的非参数检验是比较中位数。这是有道理的，因为它们对异常值更稳健，而在教科书中，异常值是第一种情况下使用非参数检验的动机。
但在现实世界中，使用非参数检验的另一个动机是保护自己免受应用期刊的误导性评论者的误导，他们认为数据生成过程的正态性是进行 z 检验的必要条件。
如果潜在的研究问题涉及均值而不是中位数，是否有可以部署的专门的非参数程序？（当然，可以进行引导等，但只是好奇）。]]></description>
      <guid>https://stats.stackexchange.com/questions/654515/nonparametric-test-for-means</guid>
      <pubDate>Tue, 17 Sep 2024 22:26:06 GMT</pubDate>
    </item>
    <item>
      <title>具有随时间变化的协变量（生存）的研究</title>
      <link>https://stats.stackexchange.com/questions/654405/a-study-with-a-time-varying-covariate-survival</link>
      <description><![CDATA[我们正在进行一项研究，定期对患者进行癌症复发检测。每四个月安排一次检查（T0、T4、T8、T12、T16、T20）。
以下数据可能具有适合采用离散时间格式的生存分析的结构。如果不正确，请告诉我。
ID TIME EVENT GENDER 
1 T0 0 M 
1 T4 0 M 
1 T8 0 M 
1 T12 1 M 
2 T0 0 F 
2 T4 1 F 
3 T0 0 M 
3 T4 0 M 
3 T8 1 M 
4 T0 0 F 
4 T4 1 F 

现在我们需要向模型中添加一个随时间变化的协变量，即吸烟。
每次预约时都会询问患者的吸烟习惯。
现在，我想知道当模型中存在因变量协变量时，以下数据结构是否合适。另外，可以使用以下函数：glm(event ~ Time + Gender + smoke, family = binomial(link = cloglog))吗？
 ID TIME EVENT GENDER SMOKE 
1 T0 0 M 0 
1 T4 0 M 1 
1 T8 0 M 1 
1 T12 1 M 1 
2 T0 0 F 0 
2 T4 1 F 1 
3 T0 0 M 0 
3 T4 0 M 0 
3 T8 1 M 0 
4 T0 0 F 0 
4 T4 0 F 0 


第二个问题是：当协变量变化的相对时间和事件时间间隔不一样时，我们还能使用上述公式吗？如果没有，我们如何创建具有适当结构的数据集，以及应该使用哪种统计模型？]]></description>
      <guid>https://stats.stackexchange.com/questions/654405/a-study-with-a-time-varying-covariate-survival</guid>
      <pubDate>Sun, 15 Sep 2024 20:00:50 GMT</pubDate>
    </item>
    </channel>
</rss>