<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Tue, 30 Jan 2024 15:13:46 GMT</lastBuildDate>
    <item>
      <title>数值积分的 KL 散度与 knrumsey/quack 的“kld”不同意[关闭]</title>
      <link>https://stats.stackexchange.com/questions/638117/kl-divergence-with-numerical-integration-vs-kld-from-knrumsey-quack-do-not-agr</link>
      <description><![CDATA[我正在尝试验证我的 KL 散度计算是否有效，因此我尝试比较两种不同的方法，它们应该给出足够相似的结果，但它们没有，所以我认为有些问题。
下面的代码比较了来自https://stackoverflow的数值积分.com/questions/55604403/computing-the-kl-divergence-with-kernel-密度-estimates，以及来自 Z 测试没有相关的样本量，因为我有高斯概率分布。
指数分布的值逐渐偏移 +0.2，用于跟踪 KL 散度如何响应分布变得越来越不相似。
&lt;前&gt;&lt;代码&gt;#library(ks)
#devtools::install_github(“knrumsey/quack”)
#图书馆（庸医）
#创建一个要研究的发行版，以及要集成的 kde
z1_private &lt;- reexp(1000, 1)
d1 &lt;- kde(z1_private)
设置种子(13)

#积分函数
kld_base = 函数(x,y,...){
  被积函数 = 函数(x,y,t){
    f.x = 大约(x$eval.points,x$估计,t)$y
f.y = 大约(y$eval.points,y$估计,t)$y
    tmpRatio = f.x *(log2(f.x) - log2(f.y))
    tmpRatio = ifelse(is.infinite(tmpRatio),0,ifelse(is.na(tmpRatio),0,tmpRatio))
    返回（tmpRatio）
  }
  返回（积分（被积函数，-Inf，Inf，x = x，y = y，stop.on.error = FALSE）$值）
}

#For循环逐步改变分布
KLint_metric_forward &lt;- c(0, 0, 0, 0, 0, 0, 0, 0, 0)
KLint_metric_backward &lt;- c(0, 0, 0, 0, 0, 0, 0, 0, 0)
Jeffreyint_metric &lt;- c(0, 0, 0, 0, 0, 0, 0, 0, 0)
deltaX &lt;- c(0, 0, 0, 0, 0, 0, 0, 0, 0)
for (i in 1:10) {
  z1_private_altered &lt;- z1_private+ 0.2* (i-1)
  deltaX[i] &lt;- 0.2*(i-1)
  d1_altered &lt;- kde(z1_private_altered)
KLint_metric_forward[i] &lt;- kld_base(d1, d1_altered)
KLint_metric_backward[i] &lt;- kld_base(d1_altered, d1)
Jeffreyint_metric[i] &lt;- (KLint_metric_backward[i] + KLint_metric_forward[i])/2
}

#可视化 KL 散度积分如何变化
绘图（deltaX，KLint_metric_backward）
lines(deltaX, KLint_metric_forward) #为什么这个这么奇怪，而另一个却很棒
线（deltaX，Jeffreyint_metric）

#这可视化了原始分布和后来的分布的外观
绘图（d1）
行（d1_altered[[“评估点”]]，d1_altered[[“估计”]]）

#针对基于 KL 散度的 kde 函数重复
KL_metric_forward &lt;- c(0, 0, 0, 0, 0, 0, 0, 0, 0)
KL_metric_backward &lt;- c(0, 0, 0, 0, 0, 0, 0, 0, 0)
Jeffrey_metric &lt;- c(0, 0, 0, 0, 0, 0, 0, 0, 0)
deltaX &lt;- c(0, 0, 0, 0, 0, 0, 0, 0, 0)
for (i in 1:10) {
  z1_private_altered &lt;- z1_private+ 0.2* (i-1)
  deltaX[i] &lt;- 0.2*(i-1)
  KL_metric_forward[i] &lt;- kld(z1_private, z1_private_altered)
  KL_metric_backward[i] &lt;- kld(z1_private_altered, z1_private)
  Jeffrey_metric[i] &lt;- (KL_metric_backward[i] + KL_metric_forward[i])/2
}

绘图（deltaX，KL_metric_forward，col =“红色”）
lines(deltaX, KL_metric_backward,col=“red”) #为什么这个这么奇怪而另一个却很棒
行（deltaX，Jeffrey_metric，col =“红色”）

真正奇怪的是基于 KLint_metric_forward 的数值积分，其中 KL 散度先增大后减小，这对我来说没有意义。集成代码有问题吗？坦率地说，无法弄清楚它到底做了什么，我只是将它集成到 kde 类对象变量名称中。
下面是生成的图像。
感谢您的帮助，]]></description>
      <guid>https://stats.stackexchange.com/questions/638117/kl-divergence-with-numerical-integration-vs-kld-from-knrumsey-quack-do-not-agr</guid>
      <pubDate>Tue, 30 Jan 2024 15:05:05 GMT</pubDate>
    </item>
    <item>
      <title>以因子作为交互项的线性混合模型：比较什么？</title>
      <link>https://stats.stackexchange.com/questions/638113/linear-mixed-models-with-factors-as-interaction-terms-what-is-being-compared</link>
      <description><![CDATA[我正在努力指定我的线性混合模型，因为我对交互术语相对较新。
在第一次观察后，受试者被给予药物，目的是确定该血液参数（“值”）在整个研究中不同的时间点。由于存在缺失值和不平等组，我的目标是使用线性混合模型来寻找每个时间点的差异。
我最初的想法是使用 lme4 （和 lmerTest）使用以下公式指定模型。我对他们的基线测量值进行了调整，因为我预计一旦药物进入他们的系统，这就会影响值。
summary(lmer(Value ~ Time*Group + Value_baseline + (1|Subject), dt))

固定效果：
                估计标准。误差df t值Pr(&gt;|t|)
(截距) 34.42820 2.97065 456.00000 11.589 &lt; 2e-16 ***
时间1 -1.00166 2.33505 456.00000 -0.429 0.668
时间2 -0.43548 2.33505 456.00000 -0.186 0.852
时间4 1.01085 2.33505 456.00000 0.433 0.665
时间6 -0.79818 2.33505 456.00000 -0.342 0.733
B组 2.36570 2.31682 456.00000 1.021 0.308
值_基线 0.22072 0.05590 456.00000 3.949 9.10e-05 ***
时间1：B组 23.29911 3.27618 456.00000 7.112 4.46e-12 ***
时间2：B组 21.88266 3.26768 456.00000 6.697 6.29e-11 ***
时间4：B组 22.47478 3.26768 456.00000 6.878 2.01e-11 ***
时间6：B组 0.07703 3.28502 456.00000 0.023 0.981


看看输出，我不太有信心我已经比较了我想要的组。对于 Time1:GroupB，这是否意味着 B 组在同一时间点或 A 组基线显着高于 A 组？
我的目的是测试：
（1）在时间点1，B组与A组在时间点1是否不同？
（2）在时间点2，B组与A组在时间点2是否不同？
（3）在时间点4，B组与A组在时间点4是否不同？
（4）在时间点6，B组与A组在时间点6不同吗？
这是一个玩具数据集，旨在说明问题，其效果和样本量比我实际处理的要高得多：
库(data.table)
图书馆（ggpubr）
库（lmerTest）
dt &lt;- data.table(主题 = 代表(1:100, 每个 = 5),
           组=rep(c(“A”，“B”)，每个=5，次数=50)，
           时间 = 代表(c(0,1,2,4,6), 100))

设置.种子(42)

dt[组==“A”； |时间 %in% c(0,6)，值 := rnorm(dt[Group == &quot;A&quot; | 时间 %in% c(0,6), .N],
                                                   平均值 = 45，标准差 = 10)]
设置.种子(42)
dt[is.na(值), 值 := rnorm(dt[is.na(值), .N],
                                平均值 = 70，标准差 = 15)]
dt[c(1,7, 21:25, 40, 60:77), 值 := NA_real_]
dt[, Value_baseline := Value[时间 == 0], 主题]
dt[, `:=`(组 = 因子(组), 时间 = 因子(时间))]
ggline(dt, x = “时间”, y = “值”, color = “组”, add = “mean_se”)


图像上传不起作用，但代码中包含视觉效果。服务器问题解决后将进行编辑。]]></description>
      <guid>https://stats.stackexchange.com/questions/638113/linear-mixed-models-with-factors-as-interaction-terms-what-is-being-compared</guid>
      <pubDate>Tue, 30 Jan 2024 14:28:07 GMT</pubDate>
    </item>
    <item>
      <title>具有相邻复制问题的有趣卡片矩阵</title>
      <link>https://stats.stackexchange.com/questions/638112/interesting-card-matrix-with-adjecent-copying-problem</link>
      <description><![CDATA[我正在寻找一个可以执行以下操作的计算机程序。
m x n 矩阵包含一组纸牌，例如扑克牌。
该集合是根据随机化算法生成的，该算法可以简单地将每张卡放入 13 x 4 矩阵中一次。
假设，根据随机选择机制，将一张牌制作成与相邻牌相同的牌，并随机选择该牌和相邻的牌。
所需的次数分布是怎样的：

有一列，所有牌都相等

排成一行，所有牌都相等

所有牌都相同

采用平衡的不完全块设计 (BIBD)（每对特征在每行和每列中仅出现一次）。


用于选择一张牌及其邻居的随机化算法会如何改变这种情况。
由于该网站是一个统计和数据可视化网站，因此我认为它最适合我的问题。
谢谢。
谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/638112/interesting-card-matrix-with-adjecent-copying-problem</guid>
      <pubDate>Tue, 30 Jan 2024 14:19:09 GMT</pubDate>
    </item>
    <item>
      <title>正确检查时间序列数据的自定义集群范围排列测试的完整性</title>
      <link>https://stats.stackexchange.com/questions/638108/sanity-checking-custom-cluster-extent-permutation-test-of-time-series-data-corre</link>
      <description><![CDATA[我目前正在开发针对时间序列数据的集群范围排列测试。为此，我想进行健全性测试，看看我的测试在空数据（即条件之间没有影响）上运行时是否存在任何偏差。我的做法如下：
真实观察到的过程

我有 2 个群组。
我有 25 个数据点/组。
我在各组之间的每个数据点运行 25 次测试。
我得到 25 个 p 值。
如果 p 值小于 0.05，我会将其标记为显着。
显着的 p 值可以形成聚类。
我将簇大小定义为具有显着（第一级）p 值的相邻数据点的数量（对于不显着的 p，簇大小 = 0；如果只有一个 p 显着，而其相邻的 p 不显着，则簇大小 = 1 ）。

排列过程

我随机打乱组标签，保留原始样本大小
我执行了上述（真实观察到的）程序
我按照上述方法获取簇大小，提取最大的簇大小并存储
它在一个发行版中
我重复这个过程 10000 次
我得到了零值下最大簇大小的分布

终于
我将真实观察到的簇（真实观测过程#7）的 p 值分配为等于或大于零下最大簇分布中存储的簇的比例（排列过程#5）
我的理智测试
我会在其他任何事情之前对组标签进行洗牌，即在运行第一级 ttest 之前（真正观察到的过程#3）。
我按照上述方式运行所有内容，并对我的“真实观察到的”结果进行 200 次随机洗牌，重复整个过程。数据。
我看一下“真实观察到的”簇的 pvalues（让我们在 null 下将这些簇称为 ps [NOT 表示排列循环的最大簇大小！]）
我观察到零值下的这些簇 ps 在时间上小于 1 5% - 这很好并且有意义，因为在零值下第一级 ttests 应该只在当时显着的 5% 出现。&lt; /p&gt;
我的问题
如何评估簇大小是否经常被适当地标记为重要？
我的直觉告诉我应该是（ps指“null下的cluster ps”）：
(ps &lt;= 0.05 / ps &lt; 1) = “有效测试应为 0.05”
也就是说，在大小至少为 1（即 p&lt;1）的所有簇中，分配有显着 p 值（即 p&lt;=0.05）的那些簇的比例是多少。&lt; /p&gt;
我的推理正确吗？
感谢您的时间和精力！]]></description>
      <guid>https://stats.stackexchange.com/questions/638108/sanity-checking-custom-cluster-extent-permutation-test-of-time-series-data-corre</guid>
      <pubDate>Tue, 30 Jan 2024 13:53:15 GMT</pubDate>
    </item>
    <item>
      <title>关于贝叶斯优化，请帮忙[重复]</title>
      <link>https://stats.stackexchange.com/questions/638107/about-bayesian-optimization-please-help</link>
      <description><![CDATA[在机器学习掌握网站上，我不明白这一段。
P(A|B) = P(B|A) * P(A) / P(B)
我们可以通过删除 P(B) 的归一化值来简化此计算，并将条件概率描述为比例量。这很有用，因为我们对计算特定的条件概率不感兴趣，而是对优化数量感兴趣。
*为什么他们说我们可以删除 p(B)，然后变成 P(B|A) P(A)??]]></description>
      <guid>https://stats.stackexchange.com/questions/638107/about-bayesian-optimization-please-help</guid>
      <pubDate>Tue, 30 Jan 2024 13:39:02 GMT</pubDate>
    </item>
    <item>
      <title>通过特征数量比较两组</title>
      <link>https://stats.stackexchange.com/questions/638105/comparing-two-groups-by-the-counts-of-their-features</link>
      <description><![CDATA[假设有两组不同的个体样本。我知道它们不同，但我不知道为什么。例如，在生物学中，一组患病个体和一组健康个体。
现在，对于组中的每个人都有一组特征，让我们假设有 100 个特征，其中每个特征都是独立的并代表某物的计数。因此存在特征 F_0 到 F_n。
每个组中的每个个体都有其关联的 100D 特征向量。

判断哪些特征在各组之间存在显着差异的最佳方法是什么？

现在想象一些特征具有不同的分布。我所知道的是每个特征都高于0但基本上是无界的。例如，两个组中的 F_0 对于两个组来说都非常大，假设其值约为 1e6，而 F_1 的值约为 1e2。这有关系吗？


有人建议进行成对 t 检验，例如 F_0_g1 与 F_0_g2，然后进行 bonferroni 校正。但我真的不知道我是否正确。
有人能解释一下吗？
背景：
如果有人感兴趣的话。我试图比较的群体确实是生物群体。这些特征就是所谓的基因表达，F_n 就是基因。基因与疾病的功能和形态有关。因此，从统计学的角度来看，它基本上是比较两个群体，每个群体中的每个人都有不同的特征，并且存在差异，但研究问题总是试图寻找这些差异的细节。在生物世界中，人们往往玩得有点快，然后就输掉了他们的统计数据，但我想了解我在做什么。]]></description>
      <guid>https://stats.stackexchange.com/questions/638105/comparing-two-groups-by-the-counts-of-their-features</guid>
      <pubDate>Tue, 30 Jan 2024 12:57:21 GMT</pubDate>
    </item>
    <item>
      <title>解释回归系数何时显着</title>
      <link>https://stats.stackexchange.com/questions/638104/interpreting-when-a-regression-coefficient-is-significant</link>
      <description><![CDATA[考虑以下回归模型：
$y_i=\beta_1+\beta_2x_{i,2}+\beta_3x_{i,3}+\beta_4x_{i,2}x_{i,3}+\epsilon_i ,$
其中 $\epsilon_i\sim N(0,\sigma^2).$ 这里，$x_2$&lt; /span&gt; 是二进制变量
$$X_2 =
\开始{案例}
0，&amp; \text{如果方法 1} \\
1、&amp; \text{如果方法2}
\end{案例}$$
和$x_3$是连续变量。
如果我发现 $\beta_2$ 很重要，这意味着什么？这是否意味着 $X_2$ 变量很重要？ $X_2$ 变量很重要是什么意思？是否有证据表明 $Y$ 和 $X_2$ 之间存在关联？如何知道两种方法之间是否存在差异的证据？
此外，当我发现 $\beta_4$ 显着时，解释是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/638104/interpreting-when-a-regression-coefficient-is-significant</guid>
      <pubDate>Tue, 30 Jan 2024 12:55:06 GMT</pubDate>
    </item>
    <item>
      <title>模型比较：使用原始数据还是标准化数据？</title>
      <link>https://stats.stackexchange.com/questions/638103/model-comparison-with-raw-or-normalized-data</link>
      <description><![CDATA[我制定了一个毒瘾风险指数，其公式为Index = 1/log10(a_given_variable)。计算的指数的原始值范围从-4到0。由于我希望指数以1（最低风险）到10（最高风险）的范围表示，因此我对进行了归一化&gt;索引具有以下最小-最大公式：
Index_normalized = (xi - min(x)) / (max(x) - min(x))
现在我想知道与 log10(Literature_var) 相比，我的指数是否可以很好地预测毒瘾风险，log10(Literature_var) 是文献中已知的一个很好的预测因子。为此，我想使用逻辑回归模型，使用一个数据集，其中 Addicted 是因变量（0 = 不上瘾，1 = 上瘾）和 log10(Literature_var ）和我的指数是不同单项模型中的独立连续变量。特别是，我将 log10(Literature_var) 与索引的原始版本和规范化版本（即 Index 和 Index_normalized）进行了比较，使用AIC 确定最简约的模型。在 R 中：
模型 1a： glm(Addicted ~ Index_normalized, data = df, family = “二项式”)
模型 1b： glm(上瘾 ~ 指数，data = df, family = “二项式”)
对比
模型 2： glm(Addicted ~ log10(Literature_var), data = df, family = “二项式”)
我期望相同的性能，但得到相反的结果，Index_normalized 优于 log10(Literature_var)（AIC 低得多），并且 Index 更差（AIC 更高）。
我怀疑两个提议的模型（模型 1a 或模型 1b）中哪一个是正确的。也就是说，我应该将文学变量与 Index 的原始值进行比较，还是与所需的 1 到 10 Index_normalized 的标准化值进行比较？
或者也许我应该对另一个变量 log10(Literature_var) 应用相同的标准化公式？
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/638103/model-comparison-with-raw-or-normalized-data</guid>
      <pubDate>Tue, 30 Jan 2024 12:44:56 GMT</pubDate>
    </item>
    <item>
      <title>如何在温度变化 DOE 中包含“无变化”场景</title>
      <link>https://stats.stackexchange.com/questions/638101/how-to-include-a-no-shift-scenario-in-a-temperature-shift-doe</link>
      <description><![CDATA[我目前正在为涉及三个不同时间温度变化的过程进行实验设计 (DOE)。我的挑战是将“无转变”场景作为因素之一。
我最初的想法是：

将温度变化的三个时间点（1 小时、2 小时、3 小时）视为连续因子。
引入“无转变”情景作为分类因素（是/否）。

但是，我正在努力解决如何在不创建“无转变”与时间点的不合逻辑组合的情况下实现这一点。
我的问题是：

有没有办法设置混合级别因子，将连续级别和分类级别相结合，而不会创建无效的组合？
这里是否有推荐的替代方法？

非常感谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/638101/how-to-include-a-no-shift-scenario-in-a-temperature-shift-doe</guid>
      <pubDate>Tue, 30 Jan 2024 12:24:05 GMT</pubDate>
    </item>
    <item>
      <title>本科计量经济学-线性模型</title>
      <link>https://stats.stackexchange.com/questions/638100/undergraduate-econometrics-linear-model</link>
      <description><![CDATA[我有以下模型，我试图理解：
$y_i=\beta_0+\beta_1 x_{1i} + \beta_2 x_{2i}+ u_i \sqrt{x_{2i}}_i$ &gt;
地点：
$u_i\sim i.i.d.N(0,\sigma^2)$,
$x_{1i}=x_{2i}+\epsilon_i$，
$\epsilon_i\sim N(0,1)$,
$x_{2i}\sim \chi^2_2$
我对几件事感到困惑：
(1)模型中是否存在异方差。扰动似乎是非球形的，因为尽管 $ $\sqrt{x_{2i}}$ 输入了误差项u_i$ 是同性的。
(2)模型中是否存在内生性 - 第二个回归量与误差明显相关。这违反了第三个高斯-马尔可夫假设，因此应该产生有偏差的 OLS 估计
(3) $x_{2i}$ 如何遵循 2 的卡方分布自由度是否与模型以及所选估计器的性能有关？
如果有人能为我阐明这些要点，我将非常感激，因为我不确定我是否理解如何处理此类模型规范。]]></description>
      <guid>https://stats.stackexchange.com/questions/638100/undergraduate-econometrics-linear-model</guid>
      <pubDate>Tue, 30 Jan 2024 11:53:13 GMT</pubDate>
    </item>
    <item>
      <title>R - 以相对频率作为响应变量的多项逻辑回归</title>
      <link>https://stats.stackexchange.com/questions/638102/r-multinomial-logistic-regression-with-relative-frequencies-as-response-variab</link>
      <description><![CDATA[我的同事在一项涉及分类和连续自变量的实验中观察到物种组成如何变化。实验中使用了大约相同数量的微生物，并且在实验结束时，从基因上确定了幸存的物种。根据定量遗传测量只能估计每个物种个体的相对频率（不是计数数据）。
但是，这也意味着我的响应变量不是二进制编码的 (0/1)，并且生存概率已经可用。
现在我的问题是：在这种情况下我仍然可以执行多项逻辑回归吗？我应该如何在 R 中做到这一点？或者：R 中是否已经有此实现？感谢您的建议、想法和帮助！]]></description>
      <guid>https://stats.stackexchange.com/questions/638102/r-multinomial-logistic-regression-with-relative-frequencies-as-response-variab</guid>
      <pubDate>Tue, 30 Jan 2024 10:38:00 GMT</pubDate>
    </item>
    <item>
      <title>月平均水流量箱线图</title>
      <link>https://stats.stackexchange.com/questions/638095/box-plots-of-monthly-averaged-water-flow</link>
      <description><![CDATA[我正在使用一个模型来模拟特定区域的水流。采取某些措施可以影响这些流量，从而产生多种水管理方案。我想使用箱线图比较每个场景的流量和停留时间。
然而，基于日产量的箱线图有非常多的异常值，使得箱线图难以解释。创建每月平均流量的箱线图可以提供更好、平滑的箱线图（为了清楚起见，我不是指每月一个箱线图。我的意思是每个场景的完整数据集的 1 个箱线图，但按月平均）。但是，鉴于我使用的是平均值，我不确定这是否具有代表性。制作平均值箱线图是否有用，或者它是否像平均平均值一样，并给出了情况的倾斜视图？
谢谢！
编辑：异常值与我们正在研究的内容无关。重点是“正常”。情况，而不是极端情况。丢失极端信息是可以接受的。
此外，极端情况主要出现在高侧（高流量），而低侧几乎没有。上传图像不起作用，但在豆图上，底部几乎平坦且非常宽。然后向上稍微变宽，然后呈指数上升。以顶部的细长线结束。]]></description>
      <guid>https://stats.stackexchange.com/questions/638095/box-plots-of-monthly-averaged-water-flow</guid>
      <pubDate>Tue, 30 Jan 2024 10:00:34 GMT</pubDate>
    </item>
    <item>
      <title>什么时候遍历平稳过程的函数本身是遍历平稳的？</title>
      <link>https://stats.stackexchange.com/questions/638094/when-is-a-function-of-an-ergodic-stationary-process-itself-ergodic-stationary</link>
      <description><![CDATA[我正在使用一个格式为 $f(X_1, \dots, X_n)$ 的函数，其中  $\\{X_n\\}$ 是遍历平稳过程。 “随机过程第一门课程”由卡林和泰勒陈述了一系列与遍历性等价的条件，其中之一是极限
\begin{方程}
\lim_{n \rightarrow \infty} \frac{1}{n} \sum_{j=1}^n f(X_j, X_{j+1}, \dots) = \mathbf{E}[f(X_0, X_1, \点)]
\end{方程}
如果期望存在，则任何函数 $f$ 都满足。
然而，这个函数似乎在“错误的方向”上接受无限长的输入，我想这意味着它不适用于我的情况。对于 $f$ 是所有过去观测值的函数的情况，是否存在类似的结果或能够应用此结果的条件？ 
编辑：很抱歉我不够精确。
我确实指的是一系列函数。在我看来，我有类似的操作 $f(X_1, \dots, X_n) = \sum_{i=1}^n c^{n-i} X_i$，其中 $0 &lt; c＜ 1 美元。在我看来，在这种情况下，对于序列 $\{ f(X_1, \dots, X_n) \}$ 本身是遍历的，这样
\begin{方程}
\lim_{n \rightarrow \infty} \frac{1}{n} \sum_{j=1}^n f(X_1, \dots, X_j) = \mathbf{E}[f(X_0, X_1, \dots) ]
\end{方程}
我们将 $f(X_0, X_1, \dots)$ 定义为序列的极限 $\{ f (X_1, \dots, X_n) \}$，这样这个说法就有意义了。这样的结果似乎至少适用于地理加权和的特定示例，但我想知道是否存在更一般映射的结果。
从表面上看，这看起来与我提到的结果非常相似。然而，结果似乎是指像 $f(X_j, X_{j+1}, \dots) = \sum_{i=j}^{\infty} c 这样的操作^i X_i$。函数 $f 不依赖于有限但长度递增的序列 $X_1, \dots, X_n$ $ 取决于无限序列 $X_j, X_{j+1}, \dots$。这就是我所说的它以“错误”的方式工作的意思。方向。]]></description>
      <guid>https://stats.stackexchange.com/questions/638094/when-is-a-function-of-an-ergodic-stationary-process-itself-ergodic-stationary</guid>
      <pubDate>Tue, 30 Jan 2024 09:56:25 GMT</pubDate>
    </item>
    <item>
      <title>R中的N天实现方差计算</title>
      <link>https://stats.stackexchange.com/questions/638092/n-day-realized-variance-calculation-in-r</link>
      <description><![CDATA[我正在尝试复制文章“加密周期和美国货币政策” （Che 等人，2023）。第 19 页，他们衡量了 MSCI 指数和比特币价格的 90 天方差。
在 R 中是否有一种方法，可能使用 dplyr 包和管道，以便我可以轻松集成代码，创建一个新变量作为 N 天实现的方差（每天计算总和）返回。）
如果需要，我可以提供以下代码：
require(quantmod)
startDate=as.Date(“2022-12-29”)
endDate=as.Date(“2024-01-17”)

symbol.vec=c(“BTC-USD”)
getSymbols(symbol.vec , from=startDate, to=endDate)

BTC_USD=`BTC-美元`
名称（BTC_USD）= gsub（“-”，“_”，名称（BTC_USD））
名称(BTC_USD) &lt;- c(&quot;开盘价&quot;, &quot;最高价&quot;, &quot;最低价&quot;, &quot;收盘价&quot;, &quot;成交量&quot;,
                    “调整后”）
btc &lt;- BTC_USD$收盘

btc2 &lt;- 子集(btc, !isWeekend(as.timeDate(time(btc)))==“TRUE”)

在这里，我导入比特币价格数据（并且仅保留工作日的收盘价）。但是，不知道如何计算N天实现的方差
--编辑
这里的想法是，我想要一种类似于 Miranda-Aggripino &amp; 波动率的衡量标准。 Rey (2019)（美国货币政策和全球金融周期），即不包含在 0 和1（您通过任何其他波动率测量获得的），以便我可以像 Che &amp; 1 中那样获取波动率的对数。等人。 （2023）。如果有人有解决方案，我将不胜感激！）]]></description>
      <guid>https://stats.stackexchange.com/questions/638092/n-day-realized-variance-calculation-in-r</guid>
      <pubDate>Tue, 30 Jan 2024 09:40:04 GMT</pubDate>
    </item>
    <item>
      <title>总规模是一个重要的中介因素，但子规模不是？</title>
      <link>https://stats.stackexchange.com/questions/638091/total-scale-is-a-significant-mediator-but-not-subscales</link>
      <description><![CDATA[我正在运行中介分析，其中对我正在查看的结构的总规模有显着的中介效应。但是，当我使用相同度量的子量表运行并行中介时，所有间接路径都不重要。我怎样才能最好地解释这一点？]]></description>
      <guid>https://stats.stackexchange.com/questions/638091/total-scale-is-a-significant-mediator-but-not-subscales</guid>
      <pubDate>Tue, 30 Jan 2024 08:22:41 GMT</pubDate>
    </item>
    </channel>
</rss>