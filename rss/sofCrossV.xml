<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Fri, 06 Dec 2024 18:24:39 GMT</lastBuildDate>
    <item>
      <title>meta 与 metafor 对比例的三级荟萃分析结果不同</title>
      <link>https://stats.stackexchange.com/questions/658385/different-results-meta-vs-metafor-for-three-level-meta-analysis-of-proportions</link>
      <description><![CDATA[R 包“meta”有一个函数“metaprop”，用于比例的荟萃分析，参数“cluster”允许进行三级荟萃分析。R 文档（版本 8.0-1）对此进行了如下描述：

如果使用参数 cluster 并且至少一个 cluster 提供多个估计值，则使用三级随机效应荟萃分析模型 (Van den Noortgate et al., 2013)。在内部，调用 rma.mv 进行分析，并使用参数 type = &quot;rowsum&quot; 的 weights.rma.mv 计算随机效应权重。

函数“rma.mv”来自包“metafor”，有更多用于比较子组等的选项。所以我尝试直接在“metafor”中复制结果。虽然我可以复制点估计，但合并标准误差会存在细微差异（因此置信区间也不同）。有人知道是什么导致了这种差异吗？
我在下面提供了一个可重现的示例。
# 加载 R 包
library(meta) #version 8.0-1
library(metafor) #version 4.6-0

# 示例数据集
df &lt;- data.frame(
id = c(1:10),
study = c(&quot;A et al&quot;, &quot;A et al&quot;, &quot;B et al&quot;, &quot;B et al&quot;, &quot;C et al&quot;, &quot;C et al&quot;, 
&quot;D et al&quot;, &quot;D et al&quot;, &quot;E et al&quot;, &quot;E et al&quot;),
n_positive = c(51, 103, 122, 201, 160, 112, 6211, 6187, 2339, 2470),
n_total = c(124, 140, 306, 311, 229, 219, 13597, 12868, 5070, 5809) )
df &lt;- escalc(xi = n_positive, ni = n_total, measure = &quot;PLO&quot;, data = df)

# 使用 metaprop 进行分析
metaprop1 &lt;- metaprop(event = n_positive, n = n_total, cluster = study, data = df)
# 使用 rma.mv 进行分析
rma.mv1 &lt;- rma.mv(yi = yi, V = vi, random = ~ 1 | study/id, data = df)
# 使用 metaprop 进行分析rma.mv &amp; 与 metaprop 中相同的研究权重
rma.mv2 &lt;- rma.mv(yi = yi, V = vi, random = ~ 1 | study/id, data = df, W = metaprop1[[&quot;w.random&quot;]])

# 汇总估计值比较（以 logit 形式）
paste(metaprop1[[&quot;TE.random&quot;]], metaprop1[[&quot;seTE.random&quot;]])
# 0.0899361424942118 0.150816619366075
paste(rma.mv1[[&quot;beta&quot;]], rma.mv1[[&quot;se&quot;]])
# 0.0913959137416219 0.159661208321448
paste(rma.mv2[[&quot;beta&quot;]], rma.mv2[[&quot;se&quot;]])
# 0.0899361424942119 0.159663991953103

# 尽管产生了不同的合并 SE 
# metaprop 和 rma.mv 都使用了相同的研究方差，最多精确到 16 位小数 
summary( round(df$vi, 16) == round(metaprop1[[&quot;seTE&quot;]]^2, 16) )
# 对所有 10 个估计值都为 TRUE

P.S.以下是汇总结果以 95% 置信区间的比例表示。
# 汇总结果转换为具有 95% 置信区间的比例
paste0(
round( logit2p( metaprop1[[&quot;TE.random&quot;]]), 3)*100, &quot;% (&quot;,
round( logit2p( metaprop1[[&quot;TE.random&quot;]] - 1.96*metaprop1[[&quot;seTE.random&quot;]] ), 3)*100, &quot;% to &quot;,
round( logit2p( metaprop1[[&quot;TE.random&quot;]] + 1.96*metaprop1[[&quot;seTE.random&quot;]] ), 3)*100, &quot;%)&quot; )
# &quot;52.2% (44.9% 至 59.5%)&quot;
paste0(
round( logit2p( rma.mv1[[&quot;beta&quot;]]), 3)*100, &quot;% (&quot;,
round( logit2p( rma.mv1[[&quot;beta&quot;]] - 1.96*rma.mv1[[&quot;se&quot;]] ), 3)*100, &quot;% 至 &quot;,
round( logit2p( rma.mv1[[&quot;beta&quot;]] + 1.96*rma.mv1[[&quot;se&quot;]] ), 3)*100, &quot;%)&quot; )
# &quot;52.3% (44.5% 至 60%)&quot;
paste0(
round( logit2p( rma.mv2[[&quot;beta&quot;]]), 3)*100, &quot;% (&quot;,
round( logit2p( rma.mv2[[&quot;beta&quot;]] - 1.96*rma.mv2[[&quot;se&quot;]] ), 3)*100, &quot;% 至 &quot;,
round( logit2p( rma.mv2[[&quot;beta&quot;]] + 1.96*rma.mv2[[&quot;se&quot;]] ), 3)*100, &quot;%)&quot; )
# &quot;52.2% (44.4% 至 59.9%)&quot;
]]></description>
      <guid>https://stats.stackexchange.com/questions/658385/different-results-meta-vs-metafor-for-three-level-meta-analysis-of-proportions</guid>
      <pubDate>Fri, 06 Dec 2024 18:19:37 GMT</pubDate>
    </item>
    <item>
      <title>如何找到山脊“统计上”消散的点？</title>
      <link>https://stats.stackexchange.com/questions/658384/how-to-find-the-point-where-a-ridge-statistically-dissipates</link>
      <description><![CDATA[这是我感兴趣的表面 $\mathcal{M}$ 的图像。

我想找到 $\mathcal{M}$ 上最突出的连续脊（下图中的绿线），并找到脊消散的 $x$ 坐标。特别是，我想执行假设检验 $H_0:\text{the ridge continued on } x^*$。

为了更好地举例，以下是 $x=x^*$ 上 $\mathcal{M}$ 和 $yz$ 平面之间的相交曲线。山脊几乎肯定跨越$x^* = x_\mathrm{min}$，但不会跨越$x^* = x_\mathrm{max}$。

我的第一个想法是将曲面拟合到参数模型（类似于分段回归）。但如果可能的话，我认为非参数方法会更好。
我的问题是：

如何稳健地检测“连续”脊线？
$H_0$ 和 $H_1$ 的数学公式是什么？
哪些检验统计数据和检验方法是合适的？

提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658384/how-to-find-the-point-where-a-ridge-statistically-dissipates</guid>
      <pubDate>Fri, 06 Dec 2024 16:27:10 GMT</pubDate>
    </item>
    <item>
      <title>考虑 HGAM 中的非独立性和自相关性</title>
      <link>https://stats.stackexchange.com/questions/658383/accounting-for-non-independence-and-autocorrelation-in-hgam</link>
      <description><![CDATA[我目前正在尝试拟合 HGAM，以模拟两种处理中鱼类日常活动模式的差异。数据是通过高分辨率遥测技术收集的，目前我已估算出三个湖泊（湖泊 A-C）中 30 条鱼（每种处理约 15 条）在约 35 个实验日内每小时（1-24）游动的总距离（米）。这些数据具有清晰的层次结构，我正尝试用随机效应来解释它（如果我的语法有误，请告诉我，因为我习惯于在 brms /lme4 中建模）。我正在为每个湖泊创建一个单独的模型，以降低模型复杂性。模型结构如下：
mod &lt;- gam(as.numeric(total_distance) ~ 
Treatment + exp_day_z + weight_z +
s(hour, by = Treatment, k = 22, bs = &quot;cc&quot;) + # 这是我感兴趣的交互
s(individual_ID, bs = &#39;re&#39;) + # 个体级随机截距
s(individual_ID, exp_day_z, bs = &#39;re&#39;) + # 实验日的个体级随机斜率（居中）
s(individual_ID, hour, bs = &#39;re&#39;), # 一小时的个体级随机斜率
data = filter(perch, lake == &#39;A&#39;),
method = &quot;REML&quot;,
knots=list(hour=c(0.5, 24.5)),
family = Gamma(link = &#39;log&#39;))

然而，残差中似乎仍然存在相当大的自相关性。

在阅读了 Eric Pedersen 的 HGAM 论文、观看了他的和Gavin Simpson的精彩教程，并阅读了一些较早的帖子，我决定在模型中尝试一个自回归项来解释这一点，如下所示：
perch &lt;- perch %&gt;%
allocate(individual_ID, exp_day, hour) %&gt;%
mutate(start = if_else(is.na(lag(individual_ID)) | individual_ID != lag(individual_ID), TRUE, FALSE))

mod2 &lt;- bam(as.numeric(total_distance) ~ 
Treatment + exp_day_z + weight_z +
s(hour, by = Treatment, k = 22, bs = &quot;cc&quot;) + 
s(individual_ID, bs = &#39;re&#39;) +
s(individual_ID, exp_day_z, bs = &#39;re&#39;) +
s(individual_ID, hour, bs = &#39;re&#39;),
data = filter(perch, lake == &#39;A&#39;),
method = &quot;fREML&quot;,
rho = 0.6,
AR.start = start,
discrete = TRUE,
knots=list(hour=c(0.5, 24.5)),
family = Gamma(link = &#39;log&#39;))

这似乎改善了残差自相关（注意：此 acf 图是使用 check_resid(mod2) 生成的，其中灰色条表示标准残差，黑色条表示标准化 AR1 校正残差）。

与我之前的模型相比，该模型似乎也产生了合理的预测，其 CI 略宽（注意：对比度是使用 marginaleffects 包中的 comparisons 函数估计的）。

我仍然对一些事情有点不确定：

我是否应该在同一个模型中包含随机效应和自回归项？
我的随机效应结构格式是否正确，其中小时和实验日是个体级随机斜率？
使用 bam() 函数时选择特定 rho 值的理由是什么？
最后，有点不相关，有没有办法从一个整体模型中获得湖泊和处理特定的平滑度，而不是分别对三个湖泊进行建模（我最初尝试使用 by =互动（治疗，湖泊）但这需要很长时间才能运行，但也许这是唯一的方法）？

如能提供任何帮助，我们将不胜感激！
谢谢]]></description>
      <guid>https://stats.stackexchange.com/questions/658383/accounting-for-non-independence-and-autocorrelation-in-hgam</guid>
      <pubDate>Fri, 06 Dec 2024 16:25:03 GMT</pubDate>
    </item>
    <item>
      <title>随机变量幂的零协方差和独立性</title>
      <link>https://stats.stackexchange.com/questions/658382/zero-covariance-of-powers-of-random-variables-and-independence</link>
      <description><![CDATA[我有随机变量 $X,Y$，支持 $[-\infty,\infty]$，并且 $\mathbf{E}[X]= \mathbf{E}[Y]=0$。
如果对于所有 $ i,j=1,2,3,\ldots$，$\mathbf{Cov}[X^i,Y^j]=0$，那么通过将所有其他非线性关系表示为泰勒级数展开，是否可以得出 $X$ 和 $Y$ 是独立的结论。]]></description>
      <guid>https://stats.stackexchange.com/questions/658382/zero-covariance-of-powers-of-random-variables-and-independence</guid>
      <pubDate>Fri, 06 Dec 2024 16:04:45 GMT</pubDate>
    </item>
    <item>
      <title>逆 ECDF 平滑在密度估计中的局限性</title>
      <link>https://stats.stackexchange.com/questions/658378/limitations-of-inverse-ecdf-smoothing-for-density-estimation</link>
      <description><![CDATA[我的问题是 5D 中约 25000 个样本的密度估计。我使用基于 n-最近邻的方法（基于数据的随机向量生成算法 (1986)，作者：M. S. Taylor、J. R. Thompson），但欧几里得距离度量给我带来了麻烦。因此，我对轴进行了归一化，使得边际（经验）分布的方差为 1，但结果仍然不太好。
因此，我决定将密度估计应用于 1D 边际分布，然后通过逆 CDF 变换轴。效果更好，但我不喜欢“内置噪音” （不均匀性）我从这些估计的 1D 密度中得到。
我想知道如果我只是平滑（排序的）1D 样本，例如通过应用离散余弦变换，乘以一个好的平滑核，然后变换回来，会发生什么。我的印象是，这种形式的至少适度平滑（比如具有 &lt; 10 点支持的内核）（在将数据插入某个 1D 密度估计器之前）可能不会造成太大伤害。
如果我只使用这种逆 ECDF 平滑和积极平滑，并完全省略 1D 密度估计器部分，会有什么问题吗？
一个相关的问题是我使用 2D 直方图来可视化估计的密度，因此我必须为这些直方图的轴选择合适的箱大小。在给定指定数量的箱体的情况下，使用平滑的逆 1D ECDF 来选择箱体大小可能也是一个好主意。（我目前使用了一种不太系统的方法，这又会导致箱体大小出现一些“噪音”。）]]></description>
      <guid>https://stats.stackexchange.com/questions/658378/limitations-of-inverse-ecdf-smoothing-for-density-estimation</guid>
      <pubDate>Fri, 06 Dec 2024 14:30:00 GMT</pubDate>
    </item>
    <item>
      <title>强化学习算法的最小样本统计测试</title>
      <link>https://stats.stackexchange.com/questions/658377/statistical-testing-with-minimal-samples-for-reinforcement-learning-algorithms</link>
      <description><![CDATA[我正在比较两种强化学习算法：

运行实验的计算成本极高
根据初步结果，算法 B 始终且
大大优于算法 A（当前最先进的算法）
传统方法建议每个算法运行约 10 次，以获得统计显著性，每次运行都会产生一个标量性能指标

考虑到这些限制和预期的较大效果大小，哪些统计方法可以最大限度地减少所需的运行次数，同时仍提供优越性的严格证据？我特别感兴趣的是：

具有明显优势的可提前终止的顺序测试方法
专门为具有较大影响的小样本设计的统计测试
考虑到这些限制，进行适当的功效分析

在这种情况下，建立统计显著性所需的最少运行次数是多少？&quot;]]></description>
      <guid>https://stats.stackexchange.com/questions/658377/statistical-testing-with-minimal-samples-for-reinforcement-learning-algorithms</guid>
      <pubDate>Fri, 06 Dec 2024 13:42:14 GMT</pubDate>
    </item>
    <item>
      <title>卡普兰-迈耶曲线“不可能”交叉</title>
      <link>https://stats.stackexchange.com/questions/658375/impossible-crossing-of-kaplan-meier-curves</link>
      <description><![CDATA[这是一小部分肺癌患者的照片。蓝色曲线代表总体生存率：从放射治疗到因任何原因死亡的时间。红线代表无病生存率：从放射治疗到疾病复发或死亡的时间（人们往往会这样写，“无论先发生什么”）。两者均采用 Kaplan-Meier 方法进行，审查未发生任何事件（$n = 7$）的人，或在蓝色曲线中，在已知活着的最后一天，疾病复发但未死亡（$n = 2$）的人。

当然，通常人们永远不会将这两条曲线绘制在一个图中，因为它表明两组之间的比较，而实际上这两条曲线谈论的是同 15 名患者。但是我在这里将它们放在一个图中，以清楚地表明发生了一些感觉不可能的事情：蓝色曲线（总体生存率）低于红色曲线（无复发生存率）。
需要明确的是：对于“真实”曲线，这些 KM 曲线只是笨拙的近似值，这是不可能的，因为每个 OS 事件也是一个 RFS 事件。在每个时间点，仍然活着的患者百分比应该至少与没有疾病的活着的患者百分比一样高。这不仅仅是生物学问题，也是简单的逻辑问题。
那么这里发生了什么？
（我找到了答案，见下文，但在这里发布它的原因是，这一次错误不在我的代码中。这种情况的发生是 Kaplan-Meier 方法的一个实际怪异的怪癖。在互联网上发布这个例子可能会节省其他处于同样情况的人搜索他们那边错误的时间。）]]></description>
      <guid>https://stats.stackexchange.com/questions/658375/impossible-crossing-of-kaplan-meier-curves</guid>
      <pubDate>Fri, 06 Dec 2024 13:26:21 GMT</pubDate>
    </item>
    <item>
      <title>能否说出哪个术语更大？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658373/is-it-possible-to-say-which-term-is-grater</link>
      <description><![CDATA[比较以下内容：
第一次求和：对于 X∼Binomial(n−1,p)，𝑃 ( 𝑋 ≥ 𝑘 − 1 )。
第二次求和：对于 X∼Binomial(n,p)，P(X≥k)。
。
]]></description>
      <guid>https://stats.stackexchange.com/questions/658373/is-it-possible-to-say-which-term-is-grater</guid>
      <pubDate>Fri, 06 Dec 2024 12:10:45 GMT</pubDate>
    </item>
    <item>
      <title>向非数学专业的学生教授单方面测试[关闭]</title>
      <link>https://stats.stackexchange.com/questions/658371/teaching-one-sided-tests-to-non-mathematical-students</link>
      <description><![CDATA[据我所知和教学经验，大多数参加第一门统计推断课程的学生很难理解统计检验的含义（尤其是单侧检验的方选择）。此外，许多学生会在没有进一步数学学习的情况下将统计检验应用于各种应用科学。特别是，他们可能会在查看数据后选择测试的方，这意味着 I 型错误不受控制。
顺便说一句，许多统计推断课程涉及双边置信区间，但不涉及单侧置信区间。为什么测试不是这样？
在大多数简单情况下，双边检验只不过是一种结合两种单侧检验的（平衡）多重检验方法。特别是，如果拒绝 $H_0$，它自然会给出应该接受哪种单侧替代方案。顺便说一句，这个事实很少被教授：学生被告知要接受$H_0$的补集，这个补集不太精确。
当然，有些情况下双边测试不太自然。不过，我认为非数学学生很少遇到这些情况。
因此，主要问题是：为什么我们不只教授双边测试（至少在第一步）？]]></description>
      <guid>https://stats.stackexchange.com/questions/658371/teaching-one-sided-tests-to-non-mathematical-students</guid>
      <pubDate>Fri, 06 Dec 2024 10:44:12 GMT</pubDate>
    </item>
    <item>
      <title>重测信度估计的受试者人数</title>
      <link>https://stats.stackexchange.com/questions/658368/number-of-subjects-for-test-retest-reliability-estimates</link>
      <description><![CDATA[我正在设计一项研究，旨在评估某项运动耐力测试的重测信度，我将按照 Weir (2005) 使用 ICC(3,1) 进行计算。
我想大致了解一下我应该在我的研究中招募多少个受试者，以便在估计我的测试的 ICC 时获得合理的间隔。
有没有办法可以提前计算出这样的结果？]]></description>
      <guid>https://stats.stackexchange.com/questions/658368/number-of-subjects-for-test-retest-reliability-estimates</guid>
      <pubDate>Fri, 06 Dec 2024 10:14:57 GMT</pubDate>
    </item>
    <item>
      <title>根据二元变量制定信用评级（最好使用 R 语言）</title>
      <link>https://stats.stackexchange.com/questions/658366/develop-credit-rating-based-on-binary-variable-in-r-preferably</link>
      <description><![CDATA[我在 R 中处理信用数据。我有一个贷款数据集，其中包含借款人和信用特定变量以及二元指标违约/不违约。第一步，我进行 logit 并获取违约概率 (PD)。接下来我想做什么：
根据这些 PD 建立类似信用评级模型的东西。例如，类别 1：PD&lt;0.2，类别 2：0.2
我认为基于 PD 和其他一些特征，我可以进行聚类分析，然后将这些聚类用作有序 logit 中的因变量或类似的东西。但我害怕相关性和其他东西。我也对证明最佳聚类数感到困惑。我该如何选择？如果您可以提供 R 代码思路就好了，但不一定]]></description>
      <guid>https://stats.stackexchange.com/questions/658366/develop-credit-rating-based-on-binary-variable-in-r-preferably</guid>
      <pubDate>Fri, 06 Dec 2024 08:49:39 GMT</pubDate>
    </item>
    <item>
      <title>分类因变量 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/658365/categorical-dependent-variable</link>
      <description><![CDATA[我正在尝试构建机器学习模型，其中因变量是分类变量，并且有超过 60 个值。它们不是序数，也不遵循任何等级。
关于如何处理这个问题，有什么建议吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/658365/categorical-dependent-variable</guid>
      <pubDate>Fri, 06 Dec 2024 07:45:40 GMT</pubDate>
    </item>
    <item>
      <title>如何检验二分重复测量结果与连续调节变量之间的相互作用</title>
      <link>https://stats.stackexchange.com/questions/658364/how-to-test-for-interaction-between-dichotomous-repeated-measures-outcome-and-co</link>
      <description><![CDATA[在我的资料集中，参与者被问及在销售演示之前和之后是否计划购买（是/否）。预计人们在销售演示之后比之前更有可能回应购买意向（即“是”）。
但是，我们也有收入数据（连续变量），并希望测试收入是否与时间（销售演示之前与之后）相互作用以预测购买意向。
我们预计大多数人会在销售演示之前对购买意向回答“否”。但是，我们推测，在演示之后，收入较高的人更有可能将他们的意向改为“是”，而收入较低的人仍然会说“否”。
在这种情况下，哪种类型的测试合适？
我知道我可以将收入二分（例如中位数分割）并运行卡方检验，但如果可能的话，我希望保持收入连续。
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/658364/how-to-test-for-interaction-between-dichotomous-repeated-measures-outcome-and-co</guid>
      <pubDate>Fri, 06 Dec 2024 07:29:35 GMT</pubDate>
    </item>
    <item>
      <title>测试预测准确性 - 异常值 [附示例]</title>
      <link>https://stats.stackexchange.com/questions/658353/testing-forecasting-accuracy-outliers-with-example</link>
      <description><![CDATA[我有一个简单的模型，可以生成预测值。该模型适用于每小时数据。现在，我只对带有标记的观察结果感兴趣。我想确定预测值与实际值存在显著差异的地方。
我正在考虑以下两个指标——哪一个效果更好？ （请参阅下面代码中的选项 1 和选项 2）
或者我应该关注 RMSE、MAE 等？
# 示例数据：实际值和预测值
实际 &lt;- c(100, 110, 95, 120, 105, 130, 125)
预测 &lt;- c(102, 108, 97, 150, 103, 128, 123)

plot(actual, type = &quot;o&quot;, col = &quot;blue&quot;, pch = 16, lwd = 2,
ylim = range(c(actual, Forecasted)), ylab = &quot;Values&quot;,
xlab = &quot;Index&quot;, main = &quot;Actual vs Forecasted Values&lt;)
lines(forecasted, type = &quot;o&quot;, col = &quot;red&quot;, pch = 16, lwd = 2)

# 计算残差（实际值与预测值之间的差异）
residuals &lt;- actual - Forecasted

# 定义阈值：
# 选项 1：（例如，2 个标准差）
dynamic_threshold &lt;- 2 * sd(residuals)
dynamic_outliers &lt;- abs(residuals) &gt; dynamic_threshold

# 选项 2：（例如，基于实际数据的平均值和标准差的 2 个标准差）
upper_threshold &lt;- mean(actual)+2 * sd(actual)
lower_threshold &lt;- mean(actual)-2 * sd(actual)

outliers_forecasted &lt;- (forecasted &gt; upper_threshold) | (forecasted &lt; lower_threshold)
]]></description>
      <guid>https://stats.stackexchange.com/questions/658353/testing-forecasting-accuracy-outliers-with-example</guid>
      <pubDate>Thu, 05 Dec 2024 23:32:48 GMT</pubDate>
    </item>
    <item>
      <title>Wilcoxon 匹配对符号秩和相关性（Pearson、Spearman 或 Kendall）</title>
      <link>https://stats.stackexchange.com/questions/658344/wilcoxon-matched-pair-signed-rank-and-correlation-pearson-spearman-or-kendall</link>
      <description><![CDATA[根据出版物《提取重复测量设计的元分析前后相关性》https://matthewbjane.quarto.pub/pre-post-correlations/，如果配对 t 检验的 t 统计量值可用，则可以计算相关样本中前后得分之间的 Pearson 相关性。
pre_mean &lt;- 12.62
pre_sd &lt;- 3.845
post_mean &lt;- 18.33
post_sd &lt;- 5.155
paired_t &lt;- 10.52
n &lt;- 78

r &lt;- (paired_t^2*(sd_pre^2 + sd_post^2)-n*(post_mean-pre_mean)^2) / 
(2*paired_t^2*sd_pre*sd_post)

r

还提到，可以根据配对 t 检验的 p 值计算 Pearson 相关性。
pre_mean &lt;- 12.62
pre_sd &lt;- 3.845
post_mean &lt;- 18.33
post_sd &lt;- 5.155
pval &lt;- 1.5e-16 # 来自配对 t 检验
n &lt;- 78

# 从 p 值获取配对 t
paired_t &lt;- qt(pval/2, n-1, lower.tail = FALSE)

r &lt;- (paired_t^2*(sd_pre^2 + sd_post^2)-n*(post_mean-pre_mean)^2) /
(2*paired_t^2*sd_pre*sd_post)

我在网站上找到了类似的问题
重复测量设计的提取前后相关性
但我找不到我想要的答案。
问题：这些公式可以扩展到 Wilcoxon 符号秩检验 及其对应的 p 值吗？如果我们在运行 Wilcoxon 符号秩检验后知道 p 值（甚至可以访问 W 统计量），我们可以计算相关性（Pearson、Spearman 或 Kendall）吗？
问题：如果我们的样本量很大，我们可以说 Wilcoxon 符号秩检验和配对 t 检验的结果趋于收敛吗？因为如果答案是肯定的，也许我可以将 p 值（来自 Wilcoxon 符号秩检验）放入计算相关性的公式中（基于配对 t 检验的 p 值）。
注意：在元分析领域（在重复测量设计中），相关性值（Pearson、Spearman 或 Kendall）对于计算效果大小是必要的。我们可以获得一些信息（例如平均值、标准差、p 值和检验类型——无论是配对 t 检验还是 Wilcoxon 符号秩检验），但没有一篇出版物提供前后分数之间的相关值。我们需要找到一种方法来根据我们拥有的信息计算相关值。一些参考资料提供了公式，用于在运行配对 t 检验后根据可用的 t 统计量和 p 值计算相关性。所以，我正在寻找一种方法来计算那些应用 Wilcoxon 符号秩检验 的出版物的相关值（Spearman 或 Kendall）。]]></description>
      <guid>https://stats.stackexchange.com/questions/658344/wilcoxon-matched-pair-signed-rank-and-correlation-pearson-spearman-or-kendall</guid>
      <pubDate>Thu, 05 Dec 2024 19:25:03 GMT</pubDate>
    </item>
    </channel>
</rss>