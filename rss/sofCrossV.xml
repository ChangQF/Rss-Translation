<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Fri, 12 Apr 2024 21:13:21 GMT</lastBuildDate>
    <item>
      <title>在应用回归模型后评估识别变量（例如种族）的显着性时，使用 Bonferroni 调整是否正确？</title>
      <link>https://stats.stackexchange.com/questions/644900/when-assessing-significance-of-identification-variables-e-g-race-after-apply</link>
      <description><![CDATA[我正在构建回归模型，以评估在考虑相关信用变量后，种族等特征对于银行贷款审批是否具有统计显着性。
例如，我构建了一个逻辑回归模型，响应变量是贷款是否获得批准（0/1 指标），预测变量是信用评分、贷款价值比等。想法是首先构建一个很好的模型来预测批准/拒绝，然后将竞争变量添加到模型中以查看是否有任何类别显着（这将需要进一步检查，例如文件审查）。
假设种族变量总共有六个类别，其 p 值如下。

白色：参考水平
非裔美国人：0.043
美洲印第安人：0.031
亚洲人：0.293
西班牙裔：0.019
未知：0.762

如果我只使用标准 0.05 显着性水平，那么我会得到三个潜在有问题的类别：非裔美国人、美洲印第安人和西班牙裔。
但是，我对显着性水平应用了 Bonferroni 调整；由于与参考水平有五次比较，因此 Bonferroni 调整的显着性水平为 0.01。有了这个新的显着性级别，不再有任何显着类别。
我的问题是这是否是多重比较调整的适当使用。我熟悉它的一般用法，但还没有看到它以这种方式应用于回归，特别是在我的领域，人们通常只采用基本的 0.05 显着性水平，无需调整。]]></description>
      <guid>https://stats.stackexchange.com/questions/644900/when-assessing-significance-of-identification-variables-e-g-race-after-apply</guid>
      <pubDate>Fri, 12 Apr 2024 20:14:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 确定两种算法之间灵敏度的 p 值</title>
      <link>https://stats.stackexchange.com/questions/644899/determine-p-value-for-sensitivity-between-two-algorithms-using-r</link>
      <description><![CDATA[在 R 中，我有一个如下所示的数据框（2000 多行）：
示例 AlgoA AlgoB
FP TP
TN TN
TP TP
DFNTP
电子浮点法
FT TN TN
TP TP

TN/TP 等是通过将算法与真值集进行比较而得出的。
我通过执行常规计算生成了规格/感知值，并且还生成了 95% CI。
我现在只需要看看两组之间是否存在统计差异。这种情况我该怎么办？ AlgoA 和 AlgoB 完全无关，只是两种不同的实验室方法。
通过灵敏度计算 (TP / (TP+FN))，我知道 AlgoB 具有更好的灵敏度。我想知道这是否“显着”提高了灵敏度。]]></description>
      <guid>https://stats.stackexchange.com/questions/644899/determine-p-value-for-sensitivity-between-two-algorithms-using-r</guid>
      <pubDate>Fri, 12 Apr 2024 20:14:18 GMT</pubDate>
    </item>
    <item>
      <title>气候数据极值分析+解释</title>
      <link>https://stats.stackexchange.com/questions/644902/extreme-value-analysis-on-climate-data-interpretation</link>
      <description><![CDATA[我对极值分析的了解有限。
我想了解这两个函数之间的主要区别以及它们到底在做什么。
我的第一个猜测只是聚合差异。
第一个函数计算预定义 Return_Period 值的回报水平。
第二个函数确定每年的最大赤字并计算相应的 Return_Period。
这两个函数的结果可以相关吗？如果是这样，怎么办？
如果有人能帮助我理解。
函数1：
vals &lt;- 数据 %&gt;%
    group_by(年份(日期)) %&gt;%
    总结(赤字 = max_deficit) %&gt;%
    拉动（赤字）
  
  evd_gev &lt;- extRemes::fevd(x = vals, type = “Gumbel”, method = “MLE”)
  
  # 获取给定返回周期的 Cmagnitudes
  return_period &lt;- c(2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100)
  return_level &lt;- extRemes::return.level(evd_gev, return.period = return_period)
  
  return_periods &lt;- 名称(return_level)
  return_values &lt;- as.numeric(return_level)
  
  # 将结果存储在数据框中
  return_level_df &lt;- data.frame(
    Return_Period = return_periods,
    返回级别 = 返回值，
    纬度 = unique(data$lat)[1],
    经度 = unique(data$lon)[1]
  ）
  
  返回（列表（return_level_df = return_level_df））
}

结果示例：
&lt;前&gt;&lt;代码&gt;&gt;头（返回级别_df）
  Return_Period Return_Level 纬度 经度
1 2 187.2124 35.125 -6.125
2 5 213.7497 35.125 -6.125
3 10 227.1241 35.125 -6.125
4 20 237.5110 35.125 -6.125
5 30 242.5829 35.125 -6.125
6 40 245.8131 35.125 -6.125

函数2
process_grid_cell_cwd &lt;- 函数（数据）{
  # 按年份分组并总结最大赤字
  vals &lt;- 数据 %&gt;%
    group_by(年份) %&gt;%
    总结(赤字 = max(max_deficit), .groups = &#39;drop&#39;) %&gt;%
    拉动（赤字）
  
  # 拟合 EVD Gumbel 模型
  cwd_gumbi &lt;- fevd(vals, type = “Gumbel”, method = “MLE”)
  
  # 计算给定 CWD 极值的回报期的函数
  calc_return_period &lt;- 函数（x，loc，scale）{
    1 / (1 - exp(-exp(-(x - loc) / 比例)))
  }
  
  extract_loc &lt;- 函数（mod）{
    loc &lt;- mod$results$par[ “位置”; ]
    if (!is.null(loc)){
      返回（loc）
    } 别的 {
      回报（不适用）
    }
  }
  
  extract_scale &lt;- 函数（mod）{
    比例 &lt;- mod$results$par[ “比例”; ]
    if (!is.null(scale)){
      返回（比例）
    } 别的 {
      回报（不适用）
    }
  }
  
  # 提取位置和比例
  loc &lt;- extract_loc(cwd_gumbi)
  比例 &lt;- extract_scale(cwd_gumbi)
  
  数据$Return_Period &lt;- sapply（数据$max_deficit，函数（x）calc_return_period（x，loc，scale））
  
  # 另外，保留每组第一次出现的纬度和经度
  数据 &lt;- 数据 %&gt;%
    group_by(年份) %&gt;%
    总结（Max_Deficit = max（max_deficit），
              返回周期 = max(返回周期),
              纬度 = 第一（纬度），
              经度=第一（经度），
              .groups = &#39;丢弃&#39;)
  
  返回（数据）
}

结果示例：
&lt;前&gt;&lt;代码&gt;&gt;打印（结果_df_cwd）
# 小标题：26,088 × 5
    年经纬度 max_deficit Return_Period
       
 1 2000 35.1 -6.12 192. 1.93
 2 2001 35.1 -6.12 200. 2.48
 3 2002年 35.1 -6.12 167. 1.13
 4 2003年 35.1 -6.12 232. 8.14
 5 2004年 35.1 -6.12 207. 3.10
 6 2005 35.1 -6.12 236. 9.49
 7 2006年 35.1 -6.12 152. 1.02
 8 2007年 35.1 -6.12 170. 1.16
 9 2008 35.1 -6.12 167. 1.12
10 2009 35.1 -6.12 208. 3.24
]]></description>
      <guid>https://stats.stackexchange.com/questions/644902/extreme-value-analysis-on-climate-data-interpretation</guid>
      <pubDate>Fri, 12 Apr 2024 19:30:00 GMT</pubDate>
    </item>
    <item>
      <title>如何在每周日记研究中比较压力事件类型的频率与随时间的重复测量？</title>
      <link>https://stats.stackexchange.com/questions/644898/how-to-compare-frequencies-of-type-of-stress-events-with-repeated-measurements-o</link>
      <description><![CDATA[我们希望您能帮助澄清等频卡方检验（在 SPSS 中）是否是正确的选择。研究参与者在每周日记中报告了经历过的压力事件（文本变量），随后我们将压力事件分为不同类型的压力（0=不存在，1=存在）。我们创建了至少 5 类（或更多）压力事件。我们想知道在 700 名儿童的样本中，这些类别的频率（比例）是否彼此存在显着差异，从而了解哪些类型的压力事件发生最频繁。临床医生在就诊期间每 8 周审查一次每周日记。因此，每次访问可能包含过去 8 周内的多个压力事件（主要是 1-4 个事件）。研究参与者接受了大约一年的跟踪调查，并进行了多次研究访问。我们想知道卡方检验是否正确，因为随着时间的推移，某些压力事件的重复报告可能并不相互独立？仅总结研究期间的所有事件（按类型）是否正确？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644898/how-to-compare-frequencies-of-type-of-stress-events-with-repeated-measurements-o</guid>
      <pubDate>Fri, 12 Apr 2024 19:19:39 GMT</pubDate>
    </item>
    <item>
      <title>您应该计算重建图像的 FID 还是从文本获得的图像的 FID？</title>
      <link>https://stats.stackexchange.com/questions/644897/should-you-compute-the-fid-for-the-reconstructed-images-or-for-the-image-obtaine</link>
      <description><![CDATA[我正在尝试基于 Muse 训练文本到图像模型。我正在计划如何评估结果，但我意识到 Frechet 起始距离有一些我不明白的地方。
Muse（以及我的版本）大致是这样工作的：

有一个编码器使用多个标记（假设为 64 个）来表示图像，其中每个标记可以采用多个可能值之一（假设为 8192）
有一个解码器可以获取 64 个标记并根据它们重建图像
最后一个组件是一个转换器，它接收文本标记，并生成希望与给定文本匹配的图像标记

训练后的实际图像生成如下：

您将一段文本传递给转换器
转换器生成 64 个图像标记
令牌被传递给解码器，解码器将它们转换为实际图像

我的问题是，如何计算此类模型的 FID？我看到 $2$ 的方法：

获取原始图像，将它们传递给编码器，然后重建它们。计算原始图像和重建图像之间的 FID。这只会使用编码器和解码器。
获取图像说明，使用整个模型根据这些说明生成图像，然后计算生成的图像和原始图像之间的 FID。

第二个选项对我来说似乎更合理，因为它测试了整个模型。我无法在网上找到任何有关此问题的信息，虽然在写完这个问题后我似乎不再怀疑自己的直觉，但如果有人可以确认/证实它，那将会很有帮助。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/644897/should-you-compute-the-fid-for-the-reconstructed-images-or-for-the-image-obtaine</guid>
      <pubDate>Fri, 12 Apr 2024 19:19:03 GMT</pubDate>
    </item>
    <item>
      <title>如何判断 Statsmodels 中的 GLM 模型摘要是否使用了偏移项？</title>
      <link>https://stats.stackexchange.com/questions/644896/how-to-tell-if-an-offset-term-is-used-from-glm-model-summary-in-statsmodels</link>
      <description><![CDATA[我目前正在通过 Statsmodels 中的 GLM 函数研究带有偏移项的泊松回归，但我认为 R 中的 GLM 函数也存在同样的问题，因为模型摘要非常相似。
我创建了 2 个简单模型，一个带有偏移项，另一个没有。两者的输出如下。
在我看来，没有迹象表明这两个模型中使用或未使用偏移项。此外，我从 Statsmodel 提供的 GLMResult 中搜索了属性，没有一个显示存在偏移项。

]]></description>
      <guid>https://stats.stackexchange.com/questions/644896/how-to-tell-if-an-offset-term-is-used-from-glm-model-summary-in-statsmodels</guid>
      <pubDate>Fri, 12 Apr 2024 18:46:29 GMT</pubDate>
    </item>
    <item>
      <title>气候数据极值分析+解释</title>
      <link>https://stats.stackexchange.com/questions/644894/extreme-value-analysis-on-climate-data-interpretation</link>
      <description><![CDATA[我对极值分析的了解有限。
我想了解这两个函数之间的主要区别以及它们到底在做什么。
我的第一个猜测只是聚合差异。
第一个函数计算预定义 Return_Period 值的回报水平。
第二个函数确定每年的最大赤字并计算相应的 Return_Period。
这两个函数的结果可以相关吗？如果是这样，怎么办？
如果有人能帮助我理解。
函数1：
vals &lt;- 数据 %&gt;%
    group_by(年份(日期)) %&gt;%
    总结(赤字 = max_deficit) %&gt;%
    拉动（赤字）
  
  evd_gev &lt;- extRemes::fevd(x = vals, type = “Gumbel”, method = “MLE”)
  
  # 获取给定返回周期的 Cmagnitudes
  return_period &lt;- c(2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100)
  return_level &lt;- extRemes::return.level(evd_gev, return.period = return_period)
  
  return_periods &lt;- 名称(return_level)
  return_values &lt;- as.numeric(return_level)
  
  # 将结果存储在数据框中
  return_level_df &lt;- data.frame(
    Return_Period = return_periods,
    返回级别 = 返回值，
    纬度 = unique(data$lat)[1],
    经度 = unique(data$lon)[1]
  ）
  
  返回（列表（return_level_df = return_level_df））
}

结果示例：
&lt;前&gt;&lt;代码&gt;&gt;头（返回级别_df）
  Return_Period Return_Level 纬度 经度
1 2 187.2124 35.125 -6.125
2 5 213.7497 35.125 -6.125
3 10 227.1241 35.125 -6.125
4 20 237.5110 35.125 -6.125
5 30 242.5829 35.125 -6.125
6 40 245.8131 35.125 -6.125

函数2
process_grid_cell_cwd &lt;- 函数（数据）{
  # 按年份分组并总结最大赤字
  vals &lt;- 数据 %&gt;%
    group_by(年份) %&gt;%
    总结(赤字 = max(max_deficit), .groups = &#39;drop&#39;) %&gt;%
    拉动（赤字）
  
  # 拟合 EVD Gumbel 模型
  cwd_gumbi &lt;- fevd(vals, type = “Gumbel”, method = “MLE”)
  
  # 计算给定 CWD 极值的回报期的函数
  calc_return_period &lt;- 函数（x，loc，scale）{
    1 / (1 - exp(-exp(-(x - loc) / 比例)))
  }
  
  extract_loc &lt;- 函数（mod）{
    loc &lt;- mod$results$par[ &quot;位置&quot; ]
    if (!is.null(loc)){
      返回（loc）
    } 别的 {
      回报（不适用）
    }
  }
  
  extract_scale &lt;- 函数（mod）{
    比例 &lt;- mod$results$par[ &quot;scale&quot;; ]
    if (!is.null(scale)){
      返回（比例）
    } 别的 {
      回报（不适用）
    }
  }
  
  # 提取位置和比例
  loc &lt;- extract_loc(cwd_gumbi)
  比例 &lt;- extract_scale(cwd_gumbi)
  
  数据$Return_Period &lt;- sapply(data$max_deficit, function(x) calc_return_period(x, loc, scale))
  
  # 另外，保留每组第一次出现的纬度和经度
  数据 &lt;- 数据 %&gt;%
    group_by(年份) %&gt;%
    总结（Max_Deficit = max（max_deficit），
              返回周期 = max(返回周期),
              纬度 = 第一（纬度），
              经度=第一（经度），
              .groups = &#39;丢弃&#39;)
  
  返回（数据）
}

结果示例：
&lt;前&gt;&lt;代码&gt;&gt;打印（结果_df_cwd）
# 小标题：26,088 × 5
    年经纬度 max_deficit Return_Period
       
 1 2000 35.1 -6.12 192. 1.93
 2 2001 35.1 -6.12 200. 2.48
 3 2002年 35.1 -6.12 167. 1.13
 4 2003年 35.1 -6.12 232. 8.14
 5 2004年 35.1 -6.12 207. 3.10
 6 2005 35.1 -6.12 236. 9.49
 7 2006年 35.1 -6.12 152. 1.02
 8 2007年 35.1 -6.12 170. 1.16
 9 2008 35.1 -6.12 167. 1.12
10 2009 35.1 -6.12 208. 3.24
]]></description>
      <guid>https://stats.stackexchange.com/questions/644894/extreme-value-analysis-on-climate-data-interpretation</guid>
      <pubDate>Fri, 12 Apr 2024 17:52:54 GMT</pubDate>
    </item>
    <item>
      <title>对称分布[关闭]</title>
      <link>https://stats.stackexchange.com/questions/644893/symmetric-distributions</link>
      <description><![CDATA[我对分布的对称性感兴趣。我对分布的对称性水平如何变化非常感兴趣，并且我一直在研究它是否可能，或者是否存在带有定义“对称/不对称”如何分布的参数的分布。这是。所以我想问一下你是否知道。]]></description>
      <guid>https://stats.stackexchange.com/questions/644893/symmetric-distributions</guid>
      <pubDate>Fri, 12 Apr 2024 17:22:19 GMT</pubDate>
    </item>
    <item>
      <title>强化学习，根据历史数据进行预训练</title>
      <link>https://stats.stackexchange.com/questions/644892/reinforcement-learning-pre-trained-on-historical-data</link>
      <description><![CDATA[我有一个问题，我想优化社交媒体上众多独立页面的共享模式。有几个自由度，比如文章分享数量、照片分享数量等等。我一直在考虑优化这些配置的方法，目前正在探索强化学习。
至少从概念上讲，我认为这可以用强化学习来完成，因为有一个清晰的观察空间（文章分享数、照片分享数……）、行动空间（例如，将文章分享量增加1、保持照片分享相同等）和奖励（展示次数或流量等指标的变化）。某一天的状态取决于前一天的状态以及对其应用的操作。
我一直遇到的问题是，在文献中，强化学习是在代理通过在线环境采样生成自己的训练数据的背景下设置的。但是，我不能让未经训练的预测器在生产环境中从零开始做出错误的预测。我所拥有的是大量的历史数据（共享配置和实现的指标）。是否可以在历史数据上训练强化学习预测模型，一旦取得满意的结果，再将其部署到生产中？]]></description>
      <guid>https://stats.stackexchange.com/questions/644892/reinforcement-learning-pre-trained-on-historical-data</guid>
      <pubDate>Fri, 12 Apr 2024 16:42:04 GMT</pubDate>
    </item>
    <item>
      <title>在向量随机过程的背景下，什么是谱密度矩阵</title>
      <link>https://stats.stackexchange.com/questions/644891/what-is-the-spectral-density-matrix-in-the-context-of-vector-stochastic-process</link>
      <description><![CDATA[我似乎找不到任何关于谱理论的好/易于阅读的资源，特别是对于多元随机过程。
我想知道：

任何解释光谱理论的资源
谱密度矩阵的定义
谱密度矩阵对称吗？
与协方差矩阵的关系？
]]></description>
      <guid>https://stats.stackexchange.com/questions/644891/what-is-the-spectral-density-matrix-in-the-context-of-vector-stochastic-process</guid>
      <pubDate>Fri, 12 Apr 2024 16:39:02 GMT</pubDate>
    </item>
    <item>
      <title>比较贝叶斯模型和频率论模型的 AIC 是否正确？</title>
      <link>https://stats.stackexchange.com/questions/644890/is-comparing-the-aic-of-a-bayesian-and-a-frequentist-model-right</link>
      <description><![CDATA[我正在尝试拟合一个通用线性模型，其中因变量是概率。它是零膨胀且连续的，然后遵循此处的建议 Ben 的博客Bolker，我分离了我的数据池并选择进行两种不同的回归，其中一种没有空值。
我在决定应该在 glm 中使用哪个系列时遇到一些问题。我尝试首先将因变量和自变量转换为配对线性关系，然后使用 glmmTMB 拟合 gamma 系列。
我也尝试过在不进行任何变换的情况下拟合 beta 回归，但面对收敛困难，我使用了带有 stan_betareg 的贝叶斯方法。
我的问题是：我如何决定哪一个是最好的？我可以比较两种型号的 AIC 吗？我是否需要比较频率论模型的 AIC 和贝叶斯模型的 BIC？或者我错过了什么并且推理本身是不正确的？
预先感谢您]]></description>
      <guid>https://stats.stackexchange.com/questions/644890/is-comparing-the-aic-of-a-bayesian-and-a-frequentist-model-right</guid>
      <pubDate>Fri, 12 Apr 2024 15:39:16 GMT</pubDate>
    </item>
    <item>
      <title>在（一些）心理学家所做的主题实验中</title>
      <link>https://stats.stackexchange.com/questions/644887/within-subject-experiments-done-by-some-psychologists</link>
      <description><![CDATA[预先感谢您可以将我链接到的任何回复或资源。
我接受了更多的经济/统计培训，最近我一直在与一些具有心理学背景的人一起工作。
他们进行所谓的“实验”老实说，我不认为它们是实验，每当我提出相关问题时，我都得不到满意的答案。对我来说，一个令人满意的答案更多的是一种统计解释，而不是像“我们已经做到了这一点并且它有效”这样的实际解释。或“我们需要更小的样本量”。
他们让调查参与者查看一个（或多个）控制条件并回答一个问题，然后查看多个治疗条件并回答一个问题。治疗条件都是不同的治疗，而不是相同治疗的版本。问题都是按顺序随机排列的。
另一个问题是，有时，他们有太多的控制/治疗，并不是每个人都回答所有的问题。
我认为这只是一项调查。这不是一个实验/调查实验。我熟悉联合实验和其他类型的主题内实验设计，但事实并非如此。
当参与者接受所有治疗时，这如何发挥作用？他们的答案会受到他们看到的顺序的影响。即使顺序是随机的，1/2 也会先看到一个，另外 1/2 会看到第二个。
结果不是 ATE（或相关），所以这不只是观察数据吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/644887/within-subject-experiments-done-by-some-psychologists</guid>
      <pubDate>Fri, 12 Apr 2024 14:47:15 GMT</pubDate>
    </item>
    <item>
      <title>对汇总数据使用哪些统计检验？</title>
      <link>https://stats.stackexchange.com/questions/644886/which-statistical-tests-to-use-for-aggregated-data</link>
      <description><![CDATA[我正在撰写金融学学士论文，主题是 Covid-19 对荷比卢地区（比利时、荷兰、卢森堡）不同财富群体家庭投资组合选择的影响。数据来自欧洲央行：(https:/ /www.ecb.europa.eu/stats/ecb_surveys/hfcs/html/index.en.html），包含每个国家和每个家庭财富组的分居家庭的不同财务数据（6组：底部20%） 、20-40%、40-60%、60-80%、80-90%、90-100%）。我有4波数据（2011年、2014年、2017年、2021年）。由于这些年份是自变量（2021 年是重点年份，因为现在正处于新冠疫情中期），除了使用描述性统计数据之外，我还想进行一些统计测试和回归，以测试 2021 年与其他年份之间的任何差异的显着性三波（2011、2014、2017）
我主要关注的数字包括：
A3 净财富，中位数
A4净财富，意味着
B3 实物资产，HMR 的所有权
B5 房地产资产，条件中位数
C4 金融资产，条件中位数
C5金融资产，拥有股份
D4 金融资产占总资产的比例
E5 持有债务的家庭百分比
E6 总债务，有条件中位数
F4 债务收入比中位数
F5 有偿债家庭的偿债与收入比率中位数
F6 债务资产比率中位数 - 细分
G3 经常支出低于收入
这些数字是来自大型调查的汇总数据，我不确定可以使用哪些统计测试和哪种回归。我从主管那里听说每次回归的目标是 30-50 个数据点，但是我的数据仅包含 6 个大组的数字（平均值、中位数、比率）。这将使每个国家/地区的每个财务数据有 6 个数据点，因此每个财务数据有 18 个数据点。由于这些数字是汇总数据，这 18 个数据点的数量是否足以进行回归分析？ （如果是，是哪种类型？）或者我仍然应该通过扩大我正在研究的国家/地区来争取 30-50 个数据点吗？
除了描述性统计之外，有人可以建议我对这些数据使用哪些统计测试和回归吗？提前致谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644886/which-statistical-tests-to-use-for-aggregated-data</guid>
      <pubDate>Fri, 12 Apr 2024 14:37:05 GMT</pubDate>
    </item>
    <item>
      <title>如何计算怀孕率</title>
      <link>https://stats.stackexchange.com/questions/644885/how-to-calculate-pregnant-rate</link>
      <description><![CDATA[我有两个输入，

一个月的排卵概率，例如

&lt;预&gt;&lt;代码&gt;A=[0,0,0,0,1,1,6,9,22,25,17,8,4,4,2,1,1,0,0,0,0 ,0,0,0,0,0,0,0,0,0
]/100


给定排卵日期的怀孕率，例如

&lt;前&gt;&lt;代码&gt;B=[0.03,0.06,0.09,0.18,0.27,0.33,0.42,0.2,0.08,0]

这里的0.2对应的是排卵日。所以女性在排卵日前1天怀孕的概率是42%，在排卵日怀孕的概率是20%......现在给定A和B，如何计算计算1个月的总怀孕概率？这看起来像是一个传统的条件概率问题，问题是 B 是一个窗口数组，而不是单个值。
换句话说，我们有事件 A 在一个月内发生的概率分布，我们还有事件 B 在 A 发生时发生几天的概率分布。现在如何计算事件B的总概率分布？
更新：更新了 A 的拼写错误]]></description>
      <guid>https://stats.stackexchange.com/questions/644885/how-to-calculate-pregnant-rate</guid>
      <pubDate>Fri, 12 Apr 2024 14:36:03 GMT</pubDate>
    </item>
    <item>
      <title>使用结果变量确定数据集的重要预测因子[关闭]</title>
      <link>https://stats.stackexchange.com/questions/644884/determining-significant-predictors-for-a-dataset-with-the-outcome-variable</link>
      <description><![CDATA[我正在处理数据集并尝试获取重要的预测变量？数据集包含数字和分类变量，并且有一个结果变量。
最好的方法是什么？我正在为一些分类变量制定假设，并运行费舍尔精确和卡方来确定统计数据
意义。对于数值变量，我正在检查相关矩阵并运行 T 检验以显示差异。
有人可以证明这些方法是正确的吗？另一种选择是因素分析。然而，数据集是数字变量和分类变量的组合。谢谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/644884/determining-significant-predictors-for-a-dataset-with-the-outcome-variable</guid>
      <pubDate>Fri, 12 Apr 2024 14:23:29 GMT</pubDate>
    </item>
    </channel>
</rss>