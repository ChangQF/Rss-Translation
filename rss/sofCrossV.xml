<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Tue, 20 Aug 2024 06:22:25 GMT</lastBuildDate>
    <item>
      <title>t 检验的多维变体</title>
      <link>https://stats.stackexchange.com/questions/653035/multi-dimensional-variant-of-a-t-test</link>
      <description><![CDATA[我需要比较多个维度上的多个分布的平均值，我将维度限制为 3，以尽可能避免维度问题。
用于此类比较的最佳统计测试是什么？理想情况下，我希望在 Python statsmodels 或 scipy 库中提供一些可用的东西。]]></description>
      <guid>https://stats.stackexchange.com/questions/653035/multi-dimensional-variant-of-a-t-test</guid>
      <pubDate>Tue, 20 Aug 2024 00:12:35 GMT</pubDate>
    </item>
    <item>
      <title>任何时间序列模型是否实际上都假设严格的平稳性？</title>
      <link>https://stats.stackexchange.com/questions/653034/do-any-time-series-models-actually-assume-strict-stationarity</link>
      <description><![CDATA[我正在学习时间序列课程，我们已经讨论了平稳性的主题。给出以下定义：

严格平稳性：
如果对于任何有限的时间点集$\{t_1, t_2, \ldots,
t_n\} \subset T$和任何时间移位$h$，
$(X_{t_1}, X_{t_2}, \ldots, X_{t_n})$的联合分布与
$(X_{t_1+h}, X_{t_2+h}, \ldots, X_{t_n+h})$。
弱平稳性：
如果满足以下条件，则随机过程 $\{X_t\}_{t \in T}$ 被称为弱平稳（或广义平稳）：

均值函数 $\mu(t) = E[X_t]$ 是常数，不依赖于时间 $t$。

自协方差函数 $\gamma(t,t+h)$ 仅依赖于 $h$但不是在$t$上。

方差是有限的。



然后指出，许多时间序列模型（例如 ARMA）假设弱平稳性。此外，任何时候“平稳”被使用时，我们应该假设讲师的意思是“弱平稳性”。
我的问题是：是否有任何时间序列模型实际上假设严格平稳性？

引入严格平稳性，然后立即忽略它而支持弱平稳性，这似乎不寻常。
严格平稳性是否只是作为弱平稳性的教学垫脚石来教授，还是在现实生活中有实际用例？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653034/do-any-time-series-models-actually-assume-strict-stationarity</guid>
      <pubDate>Mon, 19 Aug 2024 22:29:32 GMT</pubDate>
    </item>
    <item>
      <title>关于具有协变量的时间序列微生物组数据的统计建模的问题</title>
      <link>https://stats.stackexchange.com/questions/653032/question-on-statistical-modeling-for-time-series-microbiome-data-with-covariates</link>
      <description><![CDATA[我是一名硕士生，正在研究一个由 NSF 资助的项目，研究人类访问对岛屿生态系统的影响。我们的研究涉及三个岛屿，人类访问程度各不相同：高、中、低。主要重点是了解受游客影响的饮食与微生物组组成之间的关系。
我们从每个岛屿上的多个宿主收集了近 200 个 16S rRNA 样本和一套全面的生理数据（血细胞计数、免疫指标、能量指标、代谢组谱等）。样本每年采集一次（连续 3 年，每年一次），但我不确定各季节是否一致。
我的研究问题是：

受不同程度的人类访问影响，饮食是否与微生物组组成的变化相关？
哪些生理因素（例如血细胞计数、免疫指标）与微生物组变化最密切相关？
每个岛屿的微生物组组成每年如何变化？
不同游客率的岛屿之间的微生物组组成是否存在显着差异？

我需要你的帮助

推荐用于分析微生物组数据并将其与生理因素关联的统计方法。

还值得一提的是，我不确定哪种方法通常更有效理想。在 qiime2 中将所有数据 y1vsy2vsy3 一起处理是否更明智，还是分别处理 y1vsy2 和 y2vsy3 更好。

]]></description>
      <guid>https://stats.stackexchange.com/questions/653032/question-on-statistical-modeling-for-time-series-microbiome-data-with-covariates</guid>
      <pubDate>Mon, 19 Aug 2024 21:30:19 GMT</pubDate>
    </item>
    <item>
      <title>在变分推理和神经网络取得最新进展之后，密集贝叶斯或马尔可夫网络的推理难题是否得到了解决？</title>
      <link>https://stats.stackexchange.com/questions/653031/is-the-inferential-challenge-of-dense-bayesian-or-markov-networks-solved-after-c</link>
      <description><![CDATA[我正在尝试更多地了解图形模型，现在对基础知识有了合理的掌握。
2000 年代中期的许多论文甚至 Koller 的教科书中反复出现的一个问题是，我们希望图形模型具有稀疏性，以加快推理速度。因此，密集图形模型或“宽”图形模型使团树信念传播等方法非常缓慢。事实上，Koller 认为，贝叶斯网络结构学习的挑战之一是结构学习通常会产生密集模型，这些模型很难运行精确和近似推理算法。
然而，两项创新似乎改变了这些密集模型的演算。首先，通过变分推理，我们实际上能够离线训练推理模型。因此，我们学习模拟完整贝叶斯网络的变分分布的参数。变分分布计算速度很快，并能为提交给网络的查询提供近似答案。
其次，神经网络——即使是小型神经网络——也可以学会从密集或宽模型的精确推理中近似得出结果。同样，在离线设置中，我们可以为贝叶斯网络或马尔可夫网络生成随机查询，并计算查询的精确推理。然后这将构建一个数据集，用于训练神经网络来回答这些查询。
当然，这些方法中也有一些实际的考虑，例如对原始模型的精确或近似推理的准确性进行基准测试。但这些似乎是可以解决的问题。
因此，我的问题是，既然变分方法和神经网络方法很容易实现，这是否意味着贝叶斯或马尔可夫网络的密集性不再是使用这些模型的障碍？或者还有其他我遗漏的问题？
另外需要注意的是，当然，有些情况下变分推理或神经网络可能不起作用。在这些情况下，就需要其他算法。但从实际角度来看，我不确定变分推理或神经网络学习失败的频率有多高。因此，再次看来，可能失败的情况可能只是一类相对较少且特定的情况。]]></description>
      <guid>https://stats.stackexchange.com/questions/653031/is-the-inferential-challenge-of-dense-bayesian-or-markov-networks-solved-after-c</guid>
      <pubDate>Mon, 19 Aug 2024 21:19:53 GMT</pubDate>
    </item>
    <item>
      <title>违反莱德曼界限以下因子模型的识别</title>
      <link>https://stats.stackexchange.com/questions/653029/violation-of-the-identification-of-factor-model-below-ledermann-bound</link>
      <description><![CDATA[在Bekker 和 ten Berge, 1997中，据说当因子数量低于 ledermann 界限时，独立误差$\Sigma$的方差几乎肯定是唯一确定的。
在该定理证明的第 3 部分中，他们使用了以下内容

我想知道在什么情况下雅可比矩阵没有满行排名？]]></description>
      <guid>https://stats.stackexchange.com/questions/653029/violation-of-the-identification-of-factor-model-below-ledermann-bound</guid>
      <pubDate>Mon, 19 Aug 2024 21:01:14 GMT</pubDate>
    </item>
    <item>
      <title>在生存随机森林中，采样越大，误差越大</title>
      <link>https://stats.stackexchange.com/questions/653028/bigger-sampling-gives-bigger-errors-in-survival-random-forests</link>
      <description><![CDATA[我有一个包含 7 个分类变量的生存数据集。我使用随机生存森林（R 中的 randomForestSRC），并且尝试了不同的样本大小和树的数量。
在训练模型之前，我会随机抽取数据样本。总的来说，我有 180 万个数据点。我尝试了 1%、5%、10% 和 50% 的随机样本。由于相关的计算复杂性（每次训练都需要几个小时），我无法使用整个数据集。
我观察到，样本量越大，误差越大（以 1 减去 C 指数计算）。
以下是我的结果：

我的问题是为什么会发生这种情况。似乎，我用来训练随机森林模型的数据越多，误差就越大。
我的猜测是，我使用的数据越多，算法就越难找到解决方案，最终找到的答案就越不准确。]]></description>
      <guid>https://stats.stackexchange.com/questions/653028/bigger-sampling-gives-bigger-errors-in-survival-random-forests</guid>
      <pubDate>Mon, 19 Aug 2024 20:57:51 GMT</pubDate>
    </item>
    <item>
      <title>处理稀疏分类数据以进行贝叶斯优化</title>
      <link>https://stats.stackexchange.com/questions/653027/handling-sparse-categorical-data-for-bayesian-optimization</link>
      <description><![CDATA[我正在使用贝叶斯优化。在使用它来指导我的现实世界湿实验室化学实验的选择过程之前，我将拥有更大的灵活性，我想评估它在先前训练数据集上的有效性，在该数据集中，我追溯使用贝叶斯优化来评估它将如何导航景观。但是，由于以下原因，此训练数据集不是贝叶斯优化的典型用例：

一些变量是分类的；为了更好地表示分类变量而不是简单的独热编码，我在 tSNE 中提供了嵌入以更好地捕获相对差异。但是，该模型最终仍应建议提供的离散类别之一。

它是稀疏的。对于上下文，每行代表不同的化学混合物，其中为每种混合物测量单个功能目标值（即“target_value”）。我总共有 7 个不同的变量需要学习，即

component1_structure（3 个 tSNE 维度，但实际上是分类的）

component1_ratio（1 维，连续）

component1_weight（1 维，连续）

component2_structure（2 个 tSNE 维度，但实际上是分类的）

component2_ratio（1 维，连续）

component3_ratio（1 维，连续）

component4_ratio（1 维，连续）


这个组合空间理论上非常大。但是，我只有 1801 种不同的混合物（即这些变量的组合）具有功能数据；我希望模型严格探索/建议我拥有功能数据的这 1801 种混合物。

与顺序优化不同，每轮实验将有多种（即 10 种）不同的混合物需要测试。因此，正如本文所述，我采用了克里金信度算法。
我的目标是证明使用贝叶斯优化搜索这些训练数据是有效的；因此，最终激励将其动态地用于实际的真实世界数据集（幸运的是，上面描述的第二个约束不适用）。尽管如此，我想设想一种方法来针对这些预先存在的训练数据使用贝叶斯优化。


这是 Colab 上的一个实现示例：https://colab.research.google.com/drive/19cY54d6M7jYl1fRDpL7oGVPF832JU247?usp=sharing
正如您在 Colab 上看到的，我目前的策略是使用加权距离度量来基本上识别最接近模型建议的唯一点（在 1801 个尚未选择的点中）。然而，我怀疑这是否是一个合理的方法。
关于如何改进此策略和/或代码实现的建议将非常有帮助。
提前致谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/653027/handling-sparse-categorical-data-for-bayesian-optimization</guid>
      <pubDate>Mon, 19 Aug 2024 20:50:56 GMT</pubDate>
    </item>
    <item>
      <title>比较记录的频率</title>
      <link>https://stats.stackexchange.com/questions/653023/compare-the-frequency-of-records</link>
      <description><![CDATA[我有如下记录：
\begin{array}{}
\hline
\textrm{2024-07-27 21:52:39} \\
\textrm{2024-07-27 21:54:15} \\
\textrm{...} \\
\textrm{2024-07-28 21:58:44} \\
\textrm{2024-07-28 22:01:15} \\
\textrm{...} \\
\textrm{...} \\
\hline
\end{array&gt;
我想比较这些记录在工作日和周末的频率。
这是我的方法：

设置一个间隔 - 对于现在 15 分钟并计算这些间隔内的记录
分成两组 a) 工作日，b) 周末
结果数据如下：

\begin{array}{c}
\hline
间隔 &amp; 计数 \\ 
\hline
\textrm{00:00:00} &amp; 3450 \\
\textrm{00:15:00} &amp; 2144 \\
\textrm{...} \\
\textrm{23:45:00} &amp; 4712 \\
\hline
\end{array&gt;
工作日和周末
现在我的问题是：

我应该“规范化”吗？数据，例如将工作日的计数除以 5，将周末的计数除以 2，因为现在收集的数据涵盖不同的天数？或者可能是不同天数的总数（我总是有一整天），例如，如果只是从星期二到星期日，那么我会将其除以 4（工作日总数）和 2（周末天数总数）？
我被建议使用双样本 Kolmogorov-Smirnov 检验来确定分布是否相同，那么使用如下方法是否正确？：

weekdays = [3450, 2144, ..., 4712]
weekends = [2147, 1544, ..., 3894]

_, p_value = scipy.stats.ks_2samp(weekends, weekdays)
if p_value &lt; 0.05:
print(&quot;工作日和周末的分布不一样。&quot;)
else:
print(&quot;分布相同&quot;)
```
]]></description>
      <guid>https://stats.stackexchange.com/questions/653023/compare-the-frequency-of-records</guid>
      <pubDate>Mon, 19 Aug 2024 19:16:51 GMT</pubDate>
    </item>
    <item>
      <title>在成对 Wilcox 检验中选择 p 调整方法</title>
      <link>https://stats.stackexchange.com/questions/653019/choosing-p-adjustment-method-in-pairwise-wilcox-test</link>
      <description><![CDATA[我需要一些帮助来选择 p 调整方法，以在四个不同独立组的权重上进行成对 Wilcox 检验（使用 R）。
我一直在阅读有关不同方法的文章，并在 Google 上搜索了大量答案。我是统计学新手，不幸的是，其中许多方法变得过于复杂，但我的结论是方法取决于数据。所以我想知道是否有人可以根据我的数据给我一些提示或指导（见下面的测试结果）。
我已经测试了所有可用的方法（“bonferroni”、“holm”、“hochberg”、“hommel”、“BH”、“BY”），除了 Benjamini 和Yekutieli 方法。
如果有人知道根据数据选择方法的一般准则，请告诉我（我找不到任何准则）。
我的测试结果如下：
BH 方法（作为示例 - 除了 BY 之外，N-A 的 p.adj 值对所有值都相同）：
 .y. group1 group2 n1 n2 统计 p p.adj p.adj.signif
&lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
1 权重 S N 127 7696 478037 0.673 0.673 ns 
2 权重 S A 127 164 11542 0.113 0.226 ns 
3 权重 S T 127 195 11720 0.417 0.625 ns 
4 权重 N A 7696 164 711349 0.005 0.031 * 
5 权重 N T 7696 195 734472 0.613 0.673 ns 
6 权重 A T 164 195 14233 0.073 0.219 ns 

按方法：
 .y. group1 group2 n1 n2 统计 p p.adj p.adj.si
&lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
1 权重 S N 127 7696 478037 0.673 1 ns 
2 权重 S A 127 164 11542 0.113 0.554 ns 
3 权重 S T 127 195 11720 0.417 1 ns 
4 权重 N A 7696 164 711349 0.005 0.077 ns 
5 权重 N T 7696 195 734472 0.613 1 ns 
6 权重 A T 164 195 14233 0.073 0.536 ns 

请注意，组 N 的样本比其他组多得多。
两个问题：

哪一个我应该使用什么方法？
为什么 BY 不同？
]]></description>
      <guid>https://stats.stackexchange.com/questions/653019/choosing-p-adjustment-method-in-pairwise-wilcox-test</guid>
      <pubDate>Mon, 19 Aug 2024 16:46:59 GMT</pubDate>
    </item>
    <item>
      <title>具有相同因变量的看似不相关的回归（SUR）对于时间序列有意义吗？</title>
      <link>https://stats.stackexchange.com/questions/653018/does-seemingly-unrelated-regressions-sur-with-the-same-dependent-variable-make</link>
      <description><![CDATA[SUR 对我来说是一个新概念，我的导师提到过它，我应该在研究中探索它。
我有一个变量（我们称之为 y），它是我的因变量。我还有 6 个控制变量和一个表示不同国家情绪的变量（比如说，sentiment_country_A 和 sentiment_country_B）。
我将所有这些变量都放在一个表中，它们的值在 6 年内每三个月出现一次（30 行）。
我想知道每个国家的情绪如何影响我的因变量。所以，我想创建这两个回归：
y ~ sentiment_country_A + 控制变量
y ~ sentiment_country_B + 控制变量
我尝试对它们运行 SUR，结果得到的 R 平方非常低（0.36），而且并非所有变量的 p&lt;0.05。残差也高度相关（~0.99）。
对于我的场景，这是正确的方法吗？我应该使用其他方法吗？我没有统计学背景，因此获得一些见解将非常有帮助。]]></description>
      <guid>https://stats.stackexchange.com/questions/653018/does-seemingly-unrelated-regressions-sur-with-the-same-dependent-variable-make</guid>
      <pubDate>Mon, 19 Aug 2024 16:42:42 GMT</pubDate>
    </item>
    <item>
      <title>包含一些随机和固定效应因素的线性混合模型</title>
      <link>https://stats.stackexchange.com/questions/653005/linear-mixed-models-with-some-factors-included-as-both-random-and-fixed-effects</link>
      <description><![CDATA[我目前正在分析一项实地试验的数据，该试验最初设计用于双向方差分析。该试验涉及两个因素——土壤（2 个级别）和植物（2 个级别），在区块设计中重复 6 次。该试验包括三个采样时间和两个土壤深度的数据。
考虑到随时间和不同深度重复测量，我担心双向方差分析所需的独立性假设。虽然对每个采样和深度进行单独的双向方差分析是一种选择，但它会导致统计能力的损失，并阻碍不同采样和深度之间的交叉比较，这对我的研究至关重要。
为了应对这些挑战，我正在考虑使用具有以下结构的线性混合模型：
soil_carbon ~ (SOIL*PLANT*DEPTH*TIME) + 
(1|BLOCK) + (1|PLOT) + (1|PLOT:SAMPLING) + (1|PLOT:DEPTH)

模型说明：

(SOIL*PLANT*DEPTH*TIME)：该术语表示研究中固定效应之间的相互作用。
(1|BLOCK)：阻塞
1|PLOT)：不同图的随机效应
(1|PLOT:SAMPLING)：嵌套在 PLOT 中的 SAMPLING。考虑到采样总是在同一个图中完成的事实。
(1|PLOT:DEPTH)：嵌套在 PLOT 中的 DEPTH。考虑到在每个图中采样的深度不同。

具体问题：
a) 鉴于随机效应中的 SAMPLING 和 DEPTH 嵌套在 PLOT 中，这些因素是否也可以作为固定效应包含在模型中？我的目标是比较不同级别的深度和采样。它们应该同时包含在随机效应和固定效应中，还是只包含在随机效应中？
b) 为了检验固定效应的显著性，我正在考虑使用似然比检验来简化模型。这种方法是否适用于线性混合模型？
如果您对分析这些数据有任何其他建议或推荐，我将非常感谢您的见解。]]></description>
      <guid>https://stats.stackexchange.com/questions/653005/linear-mixed-models-with-some-factors-included-as-both-random-and-fixed-effects</guid>
      <pubDate>Mon, 19 Aug 2024 11:21:13 GMT</pubDate>
    </item>
    <item>
      <title>如果获得的样本量比功效分析中显示的大得多，该怎么办？</title>
      <link>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</link>
      <description><![CDATA[老实说，我们没想到这一点——毕竟我们一切都是按照剧本做的。
我们计划对一些心理问题进行研究，我们将问卷输入到 Qualtrics，在 G*Power 的帮助下，我们进行了功效分析以获得最小样本量，最后我们在互联网上发布了该研究的链接。然后样本量激增。几天后，我们检查了我们设法收集了多少观察结果，结果发现数量增加了四倍（所以我们匆忙停止收集数据）。功效分析表明 N = 500，我们得到了 N = 2000（当然是 2000 多）。开心吗？不，我们离幸福还很远。
问：现在我们有一个问题，如何处理超大样本（记住超强研究）。
想法是：

在第 500 次观察时截断——丢弃其余数据（听起来像是在浪费数据）
在第 500 次观察时截断，使用其余数据作为复制研究（听起来很狡猾，我们实际上没有进行复制研究，数据来自原始研究）
从我们的大数据（N = 2000）中抽取样本 - 不放回抽样，样本由N = 500 次观察组成（并丢弃休息）。
... 大家还有其他想法吗？你们遇到过这种情况吗？你们做了什么？
]]></description>
      <guid>https://stats.stackexchange.com/questions/652973/what-to-do-if-sample-size-obtained-is-much-larger-than-indicated-in-the-power-an</guid>
      <pubDate>Sun, 18 Aug 2024 14:54:41 GMT</pubDate>
    </item>
    <item>
      <title>估计未知分布分位数的高置信上限</title>
      <link>https://stats.stackexchange.com/questions/652924/estimating-high-confidence-upper-bound-for-quantile-of-unknown-distribution</link>
      <description><![CDATA[我获得了一个分布未知的随机变量 $\mathbb R$ 上的 $X$。
我想确定获得 X 的 $1-\alpha$ 分位数的高置信上限 $\hat Q_{1-\alpha}$ 所需的最小样本量 $n$。
具体来说，我对高百分位数感兴趣，比如第 95 或第 99 个百分位数。
对于给定的置信水平 $1-\epsilon$，我想确保 $\Pr(\Pr(X&gt;\hat Q_{1-\alpha})&lt;\alpha) \geq 1-\epsilon$，而不管 $X$ 的分布如何。
虽然这个问题看起来很笼统，但我不确定如何使用经典统计方法来解决它。
直观地说，我会从我的样本中估计 $1-\alpha$ 分位数。
使用 bootstrapping 等方法，我也可以获得该参数的置信区间。
但是，我不确定如何根据基础样本的大小$n$准确量化这些方法的不确定性。
我的问题有两个方面。
首先，是否有统计工具可以回答这个问题并根据样本大小估计参数估计器的置信度？我似乎缺乏查找相关信息的统计背景。如果能提供来源或关键字来为我指明正确的方向，我将不胜感激。
其次，我知道这个问题可以用 PAC-Learning 的方法来解决。
但是，尽管这个问题相对普遍，但我也找不到使用这种界限的例子。
我怀疑有更好的工具来回答这个问题，或者这个问题一开始就不是很有趣，因为人们可以简单地假设某种分布，然后使用参数方法。
如果有人能告诉我这两个假设是否正确，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/652924/estimating-high-confidence-upper-bound-for-quantile-of-unknown-distribution</guid>
      <pubDate>Fri, 16 Aug 2024 11:09:53 GMT</pubDate>
    </item>
    <item>
      <title>将后验预测作为另一个模型中的数据传播测量不确定性</title>
      <link>https://stats.stackexchange.com/questions/652893/propagating-measurement-uncertainty-with-posterior-predictions-as-data-in-anothe</link>
      <description><![CDATA[我正在研究一种建模方法，该方法结合了测量不确定性的估计，并尝试在 R 中使用 brms。我以 McElreath 的《Statistical Rethinking》第 14 章中的示例为基础。在此示例中，有不同城市的离婚率估计值 $D_{EST,i}$，以及标准误差测量值 $D_{SD,i}$。他指定了一个根据结婚年龄$A$和结婚率$R$预测离婚率的模型：
$$
D_{EST,i} \sim Normal(\mu_i, \sigma)
\\ \mu_i = \alpha + \beta_AA_i + \beta_RR_i
\\ D_{OBS,i} \sim Normal(D_{EST,i}, D_{SE,i})
\\ \alpha \sim Normal(0,10)
\\ \beta_A \sim Normal(0,10)
\\ \beta_R \sim Normal(0,10)
\\ \sigma \sim Cauchy(0,2.5)
$$
要添加我的部分，现在假设我们之前在另一组城市中拟合了一个模型，该模型将离婚率与城市中离婚律师的数量$L$联系起来。类似这样的：
$$
\\ D_{OBS,i} \sim Normal(\mu_i, \sigma)
\\ \mu_i = \alpha + \beta_LL_i
\\ \alpha \sim Normal(0,10)
\\ \beta_L \sim Normal(0,10))
\\ \sigma \sim Cauchy(0,2.5)
$$
现在，在第一个模型中，假设我们实际上根本没有测量离婚率，而只是测量了离婚律师的数量。我们可以从第一个模型中抽取后验样本，以获得新一组城市中离婚率的估计分布。
现在，在上面的模型中，在第三行中，我们不一定有正态分布。相反，我们有来自第一个模型的后验分布。
我知道可以从第一个模型的预测中近似正态分布，但我有几个担忧。首先，这些信息可能会丢失，因为如果我使用 brms::posterior_predict，我的理解是，对于每次迭代，函数都会从参数后验中获取一个参数，并计算所有新数据的预测值。这应该会导致离婚率估计值之间存在一些协变，而这些协变只会通过汇总分布平均值和 SD 而丢失。其次，如果估计值与正态分布（或任何其他参数分布）不太吻合，那么这似乎是一个问题。
所以我的问题是：跳过预测值的近似值并直接使用后验是否有效？或者有没有办法将两个模型拟合在一起？如何在 brms 中实现这一点？谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/652893/propagating-measurement-uncertainty-with-posterior-predictions-as-data-in-anothe</guid>
      <pubDate>Thu, 15 Aug 2024 19:11:00 GMT</pubDate>
    </item>
    <item>
      <title>交错采用下的 TWFE 事件研究设计</title>
      <link>https://stats.stackexchange.com/questions/580368/twfe-event-study-design-under-staggered-adoption</link>
      <description><![CDATA[此讨论对 TWFE 事件研究模型进行了出色的总结。但是，我有一个与动态 TWFE 模型相关的估计问题。在 STATA 中，我们执行以下代码以获取事件研究超前和滞后的结果：reghdfe Y F*event L*event, a(i t) cluster(i)其中 (F) 和 (L) 是事件超前和滞后，(i) 和 (t) 是单位和时间固定效应。此代码为我提供了事件超前和滞后的估计值，但没有提供总体因果参数（总体 ATT），它是作为所有处理后滞后的平均获得的单个系数。我想问一下，我需要在上面的代码中指定什么，以便我获得所有事件超前和滞后的系数（和以前一样），但也获得整体 ATT（单一参数 - 整体 ATT）]]></description>
      <guid>https://stats.stackexchange.com/questions/580368/twfe-event-study-design-under-staggered-adoption</guid>
      <pubDate>Wed, 29 Jun 2022 05:18:36 GMT</pubDate>
    </item>
    </channel>
</rss>