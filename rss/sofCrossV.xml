<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 12 Sep 2024 06:23:53 GMT</lastBuildDate>
    <item>
      <title>未赢得多数票但赢得总票数的概率</title>
      <link>https://stats.stackexchange.com/questions/654244/probability-of-winning-overall-without-winning-majority</link>
      <description><![CDATA[在以分数计分的面试中。赢 1 场、平 1 场、输 2 场且仍然赢得总分的几率是多少。]]></description>
      <guid>https://stats.stackexchange.com/questions/654244/probability-of-winning-overall-without-winning-majority</guid>
      <pubDate>Thu, 12 Sep 2024 04:44:26 GMT</pubDate>
    </item>
    <item>
      <title>理解非重复事件的概率</title>
      <link>https://stats.stackexchange.com/questions/654243/understanding-probability-in-non-repetitive-events</link>
      <description><![CDATA[在无法重复的事件（例如股票价格）的背景下，如何定义概率？具体来说，如果我开发了一个统计模型来预测股票价格并声称其准确率为 90%，那么这对该模型的可靠性和此类情景下的概率性质意味着什么？这种对概率的解释与传统的频率论方法有何不同？这对金融预测有何影响？]]></description>
      <guid>https://stats.stackexchange.com/questions/654243/understanding-probability-in-non-repetitive-events</guid>
      <pubDate>Thu, 12 Sep 2024 03:54:39 GMT</pubDate>
    </item>
    <item>
      <title>排列检验的准确率非常高</title>
      <link>https://stats.stackexchange.com/questions/654242/accuracy-for-permutation-test-is-very-high</link>
      <description><![CDATA[我对我的分类器发生了什么有点困惑。
我有一个包含 ~220 个特征和大约 4000 次试验的数据集。类别是完美平衡的，我正在使用具有 L1 范数的 SVC 执行一个简单的二元分类任务。
当我执行 LOOCV 时，我获得了不错的准确度，但是当我想检查置换数据时，我也会获得相同的 CV 准确度 +/- 2%，即 ~ 67%。
这感觉很奇怪，因为当我使用随机数据但保留基本结构（220 X 4000）运行模拟时，我的准确度不会明显高于 50%。对我来说，这意味着过度拟合不会自动发生，但它让我真的很困惑为什么我会得到这些奇怪的结果。令我惊讶的是，置换测试的平均值与“真实机会”相差甚远（50%）
我是否遗漏了某些可以解释这一点的内容？]]></description>
      <guid>https://stats.stackexchange.com/questions/654242/accuracy-for-permutation-test-is-very-high</guid>
      <pubDate>Thu, 12 Sep 2024 03:17:36 GMT</pubDate>
    </item>
    <item>
      <title>纵向回归，但每年的队列都不同？</title>
      <link>https://stats.stackexchange.com/questions/654240/longitudinal-regression-but-cohort-is-different-in-each-year</link>
      <description><![CDATA[在大多数教科书的纵向回归示例中，它们描述的是一组人被跟踪一段时间并进行测量的情况。有时人们会退出研究（例如审查），有时人们会稍后进入研究……但总的来说，该群体的大部分人保持相似。
我的问题是关于以下内容：如果一些研究人员想知道在大学食堂中去除垃圾食品是否会导致学生更健康。研究人员随机抽取了一组学生（每年 100 名男性和 100 名女性），询问他们是否通常吃垃圾食品并记录一些健康指标（例如 100 码短跑时间、仰卧起坐次数）。研究人员在去除垃圾食品前 4 年和去除垃圾食品后 4 年进行了这项工作。研究问题可能是这样的：自从垃圾食品被移除后，男学生的体质有所改善，但女学生的体质保持稳定
作为一个极端的例子，我们假设同一个学生在整个研究中从未出现过一次以上。在这个极端的例子中，纵向回归仍然可以在这里使用（例如：边际模型）......或者我们至少需要对一些相同的学生进行多次测量？
PS：假设研究人员试图确保每年的学生与前几年的学生具有相似的属性]]></description>
      <guid>https://stats.stackexchange.com/questions/654240/longitudinal-regression-but-cohort-is-different-in-each-year</guid>
      <pubDate>Thu, 12 Sep 2024 03:08:46 GMT</pubDate>
    </item>
    <item>
      <title>金融时间序列中的引导岭回归</title>
      <link>https://stats.stackexchange.com/questions/654239/bootstrapping-ridge-regression-in-financial-time-series</link>
      <description><![CDATA[我想使用岭回归来建立股票预测模型，并想使用 bootstrap 来估计系数的稳定性和可变性。但是，我担心，由于金融时间序列是按时间索引的，随机抽样不可避免地会导致数据泄露（据我所知）。在这种情况下，正确的程序是什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/654239/bootstrapping-ridge-regression-in-financial-time-series</guid>
      <pubDate>Thu, 12 Sep 2024 02:03:06 GMT</pubDate>
    </item>
    <item>
      <title>在不平衡数据上进行 R 中的训练和预测函数</title>
      <link>https://stats.stackexchange.com/questions/654235/train-and-predict-function-in-r-on-imbalanced-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654235/train-and-predict-function-in-r-on-imbalanced-data</guid>
      <pubDate>Wed, 11 Sep 2024 21:35:09 GMT</pubDate>
    </item>
    <item>
      <title>有限的期望会导致有限的熵，这是真的吗？</title>
      <link>https://stats.stackexchange.com/questions/654234/is-it-true-that-finite-expectation-leads-to-finite-entropy</link>
      <description><![CDATA[让 $X$ 成为自然数支持的随机变量，具有有限期望。证明 $H(x)&lt;\infty$。另外，给出一个自然数支持的随机变量的示例，该变量具有 $H(x)=\infty$
有什么想法可以实现吗？我尝试使用定义和收敛测试，但我不确定它是否足够正式。]]></description>
      <guid>https://stats.stackexchange.com/questions/654234/is-it-true-that-finite-expectation-leads-to-finite-entropy</guid>
      <pubDate>Wed, 11 Sep 2024 21:20:33 GMT</pubDate>
    </item>
    <item>
      <title>我应该何时应用 Benjamini-Hochberg 与 Benjamini-Yekutieli FDR 校正？</title>
      <link>https://stats.stackexchange.com/questions/654233/when-should-i-apply-benjamini-hochberg-vs-benjamini-yekutieli-fdr-correction</link>
      <description><![CDATA[我几乎没听说过有人使用 BY 程序进行 FDR 校正，BH 更为常见。但是，据我所知，BY 程序对各种依赖结构更稳健，而 BH 假设独立测试。
在大量应用中，相互依赖性是一个非常合理的假设，但作者使用 BH 进行 FDR 校正。有趣的是，BY 似乎比 BH 更严格（产生更高的调整后的 Padj 值）。
对于哪些类型的依赖结构，BH 测试仍然有效？
希望为生物科学家（即非统计学家）提供建议阅读的指针。]]></description>
      <guid>https://stats.stackexchange.com/questions/654233/when-should-i-apply-benjamini-hochberg-vs-benjamini-yekutieli-fdr-correction</guid>
      <pubDate>Wed, 11 Sep 2024 21:13:56 GMT</pubDate>
    </item>
    <item>
      <title>“我们能相信我们计算出的功效值吗？”或者“当零假设为假时，I 类错误是否会立即消失”？</title>
      <link>https://stats.stackexchange.com/questions/654232/can-we-believe-the-power-values-we-compute-or-do-type-i-errors-disappear-as</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/654232/can-we-believe-the-power-values-we-compute-or-do-type-i-errors-disappear-as</guid>
      <pubDate>Wed, 11 Sep 2024 21:05:35 GMT</pubDate>
    </item>
    <item>
      <title>比较回顾性队列和前瞻性队列</title>
      <link>https://stats.stackexchange.com/questions/654231/comparing-retrospective-and-prospective-cohorts</link>
      <description><![CDATA[我对比较回顾性队列和前瞻性队列有点困惑……
假设我有两个队列，一个是回顾性队列（用作对照），另一个是前瞻性队列（应用了程序/干预）。我可以使用常规统计检验（如卡方、CMH 等）来比较两个队列之间的各种特征（例如死亡人数）吗？不太确定我是否需要“特殊”测试……
谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/654231/comparing-retrospective-and-prospective-cohorts</guid>
      <pubDate>Wed, 11 Sep 2024 21:02:50 GMT</pubDate>
    </item>
    <item>
      <title>具有多个独立变量和因变量的 Kruskal</title>
      <link>https://stats.stackexchange.com/questions/654226/kruskal-with-multiple-independent-and-dependent-variables</link>
      <description><![CDATA[我有三个独立变量：

延迟 - 4 级序数
难度 - 2 级序数
专业度 - 2 级序数

还有三个因变量：

时间 - 度量
准确度 - 度量
挫败感 - 5 级序数

我考虑根据独立变量将其分为 16 组，然后使用 Kruskal 检验和事后 Dunn 检验对所有组进行比较。我计划以这种方式测试每个因变量。但是，此链接和 CV 上的其他问题表明此过程不准确。
我使用 Kruskal 检验，因为我的数据违反了 ANOVA 模型假设。具体来说，没有给出正态性，并且存在显着的自相关拉格朗日乘数自相关检验（时间和准确度的 p &lt; 10^40）。


我没有检查 DV 挫折的假设，因为结果对我来说看起来太差了。
请告诉我我是否做了一个大数学禁忌，因为我对此并不是 100% 肯定。
我也不确定这里是否需要多变量方法。此帖子中的评论表明，对每个 IV 进行单独的 Kurskal 测试可能是一种更好的方法。但是，我怀疑 IV 之间存在相互作用，我想找到这些相互作用。
我很高兴能得到任何有关适合这种情况的分析技术的提示。
编辑以指定我想要的内容：我不确定所描述的分析是否适合我面临的情况。我查看了多个书籍章节和博客文章，但我无法推广到这种情况。
第二次编辑：方差分析假设。]]></description>
      <guid>https://stats.stackexchange.com/questions/654226/kruskal-with-multiple-independent-and-dependent-variables</guid>
      <pubDate>Wed, 11 Sep 2024 19:31:24 GMT</pubDate>
    </item>
    <item>
      <title>Xgboost 回归中的样本权重</title>
      <link>https://stats.stackexchange.com/questions/654221/sample-weights-in-xgboost-regression</link>
      <description><![CDATA[我正在尝试使用 xgboost 的 XGBRegressor 来拟合回归模型，在训练期间，我会对最近的数据进行加权，而不是过去的数据。我想知道 xgboost 的 sample_weight 是如何工作的。
我知道对于基于树的模型，拟合基本上是将数据拆分成各种节点/桶，然后对桶内的观测值取平均值。在这里，我希望对 xgboost 更了解的人可以解释样本权重是如何发挥作用的。我相信在大多数回归中，样本权重只是在拟合过程中计算损失函数时观测值的乘数。如果 xgboost 就是这种情况，那么虽然 sample_weight 会影响算法如何选择分割，但在取每个桶内的平均值时，它仍然会对所有观测值进行相同的加权。有人知道这是真的吗？有没有办法在 xgboost 中指定我想在节点/桶内取平均值时减少某些观测值的权重？]]></description>
      <guid>https://stats.stackexchange.com/questions/654221/sample-weights-in-xgboost-regression</guid>
      <pubDate>Wed, 11 Sep 2024 17:49:42 GMT</pubDate>
    </item>
    <item>
      <title>R 调查包与 R 统计包中的 AIC 不同</title>
      <link>https://stats.stackexchange.com/questions/654245/different-aic-in-r-survey-package-vs-r-stats-package</link>
      <description><![CDATA[使用 svyglm()$aic 而不是使用 stats::AIC(model) 时，我得到的 AIC 值不同。我知道这个话题之前已经在这里讨论过了。但是，没有详细解释这种差异 — “仅”建议使用一种方法而不是另一种方法。我怀疑这与这个有关，但不幸的是我的统计数据不够强大，无法完全理解并得出结论。
如果有人能帮我一下，告诉我哪种方法是正确的（如果有的话）以及原因，我将不胜感激。如下例所示，这两种方法可以产生截然不同的结果，甚至改变对哪种模型似乎更合适的解释。
最小示例：
library(survey)

df &lt;- data.frame(
y = c(1.2, 2.4, 3.1, 4.5, 5.6, 6.3, 8.6),
a = c(0.5, 1.3, 1.7, 2.2, 3.1, 3.8, 4.0),
b = c(2.1, 2.7, 3.3, 3.8, 4.2, 4.5, 5.1),
weights = c(0.7, 1.4, 0.9, 1.1, 1.0, 0.8, 1.2)
)

weighted &lt;- svydesign(ids = ~1，数据 = df，权重 = ~weights)

A &lt;- svyglm(y ~ a + b，设计 = 加权，系列 = &quot;gaussian&quot;)

B &lt;- svyglm(y ~ a，设计 = 加权，系列 = &quot;gaussian&quot;)

AIC(A,B)[,2]
[1] 19.29119 17.03959
&gt; c(A$aic,B$aic)
[1] 15.06302 17.45406

我使用的是 R 4.4.1 和 survey 4.4-2]]></description>
      <guid>https://stats.stackexchange.com/questions/654245/different-aic-in-r-survey-package-vs-r-stats-package</guid>
      <pubDate>Wed, 11 Sep 2024 16:18:26 GMT</pubDate>
    </item>
    <item>
      <title>多级回归，模型规范</title>
      <link>https://stats.stackexchange.com/questions/653787/multilevel-regression-model-specification</link>
      <description><![CDATA[我们非常感谢您就分析我们的研究设计的最佳方式提出建议：
我们研究了教育内容的传递媒体（即增强现实与视频）对记忆（“binary_memory_score”）随时间（“时间”）的影响。我们有 20 次增强现实体验，每次体验都有三个记忆问题（每个多项选择题有四个选项）。视频是增强现实体验的屏幕录制。
我们有两种条件（增强现实与视频），我们分别随机招募（在受试者之间）。参与者被要求参与教育内容并回答记忆问题。对于这两个组，参与者被招募到五个“群组”，代表不同的教育主题（例如群组 1 = 艺术，群组 2 = 科学），这意味着群组也是一个受试者间变量。在每个队列中，所有队列参与者都经历了五种关于该队列主题的特定体验（在队列 1 中，我们有体验 1、体验 2、体验 3、体验 4、体验 5；在队列 2 中，我们有体验 6、体验 7 等）。
在完成每项体验后的初始记忆测试（time_0）之后，一些参与者在 1 个月后（gap1）或 6 个月后（gap6）再次被问到问题（time_later）。因此，我们有一个受试者内时间因素（time_0 vs time_later）和一个受试者间差距因素（gap1 vs gap6）。我们目前将记忆作为二元变量（正确答案 vs 错误答案）作为单个记忆问题（“exp_title_question”）的“分数”。以下是我们提出的使用 glmer 的分析：
binary_memory_score ~ 1 + media*time*gap + (1 | experience / experience_question) + (1 + time | id) + (1 | cohort / id), family = binomial(&quot;logit&quot;), nAGQ=0, control=glmerControl(optimizer = &quot;nloptwrap&quot;), data=combined_data_cor_screened,contrasts = list(media = contr.sum, time=contr.sum, gap=contr.sum))

我们假设，与体验增强现实的人相比，观看视频（媒体）的人在记忆任务（binary_memory_score）中的表现会更差。
我们还假设，与体验增强现实的人相比，观看视频的人的记忆分数会随着时间的推移而更快地延迟经验。
我们计划通过 emmeans 包探索媒体 * 时间 * 间隙相互作用来测试这些假设。
非常感谢您的想法或建议。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/653787/multilevel-regression-model-specification</guid>
      <pubDate>Tue, 03 Sep 2024 08:23:00 GMT</pubDate>
    </item>
    <item>
      <title>检测大型逻辑回归模型中的相互作用</title>
      <link>https://stats.stackexchange.com/questions/645493/detecting-interactions-in-large-logistic-regression-models</link>
      <description><![CDATA[我有一个数据集，其中包含数百万个二元响应观测值，其“成功”概率平均为 1% 到 2%。该数据集包含多个分类变量（约 20 个，最多 50 个类别）和数值变量（约 10 个）。我拟合了一个主效应逻辑广义线性模型 (GLM) 作为基线和一个梯度提升树 (GBT)。通过测试集上的对数损失来衡量，GBT 的表现明显优于 GLM。然而，当仅比较它们的边际效应（通过目测合适的图来衡量）时，这两个模型似乎非常相似。因此，GBT 优于 GLM 的一个潜在原因可能是包含了交互作用。我想验证这一点，并理想地找到（其中一些）相互作用。
我的问题

在 GBT 模型中查找相互作用的可能方法有哪些？
更一般：在哪里可以找到有关查找相互作用的最新信息以及当前可行和不可行信息？

我的目标非常务实：

我不需要找到所有相互作用，几个“重要”的相互作用就是一个很好的开始。
我不需要对研究结果进行假设检验。
但方法需要在给定“标准”的情况下可实施计算资源。

我迄今为止的尝试

考虑到数据集的大小和输入的数量，任何穷举搜索方法（例如逐步回归）似乎都是徒劳的。
与 Lasso 等正则化选择存在同样的问题。特别是，由于数值输入，稀疏设计矩阵是不可能的。
我知道，但还没有尝试过 Friedman 的 H 统计量。我看到的问题在于它基于方差分解而不是对数损失。它也是一种穷举搜索，并且只适用于成对交互（最好？）。此外，它的估计是基于排列的，并且一些输入显示出强烈的依赖性​​。
数据集很复杂，没有先验理由将交互限制为成对。我“猜测”的成功基于我的一般领域知识的交互以及通过纳入 GLM 进行验证的交互受到限制。
]]></description>
      <guid>https://stats.stackexchange.com/questions/645493/detecting-interactions-in-large-logistic-regression-models</guid>
      <pubDate>Sun, 21 Apr 2024 11:22:16 GMT</pubDate>
    </item>
    </channel>
</rss>