<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>来自 stats.stackexchange.com 的最新 30 条</description>
    <lastBuildDate>Thu, 16 Jan 2025 09:16:58 GMT</lastBuildDate>
    <item>
      <title>statsmodels ARIMA 结果中的 p 值和临界值存在冲突</title>
      <link>https://stats.stackexchange.com/questions/660086/conflicting-p-value-and-critical-values-in-statsmodels-arima-result</link>
      <description><![CDATA[
如果我理解正确，如果 Z 落在临界值区域之外，则 p 值应该 &lt;0.05。但是，对于我的 ar.L2 特征，z = -0.596，[0.025, 0.075] 区域是 [-0.536, 0.286]。因为 -0.596 &lt; -0.536，所以 z 落在左尾内。但为什么 p 值是 0.552？我读错结果了吗？在 statsmodels 网站上找不到任何文档。]]></description>
      <guid>https://stats.stackexchange.com/questions/660086/conflicting-p-value-and-critical-values-in-statsmodels-arima-result</guid>
      <pubDate>Thu, 16 Jan 2025 09:00:50 GMT</pubDate>
    </item>
    <item>
      <title>回归分析中总体模型和样本模型的形式区别？</title>
      <link>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</link>
      <description><![CDATA[术语“样本回归模型”在回归分析中究竟指什么？假设我们有一个数据集$\{(\mathbf{x}_i,\mathbf{y}_i)\}$，我们假设一个底层回归模型形式为
$$
\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon},
$$
其中$\boldsymbol{\theta}$是真实总体参数（频率学派观点）和$\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\Sigma)$。我们所说的样本回归模型到底是什么意思？
以下是我正在探索的一些可能性：

拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}})$，从某种意义上说，我们已经选择了一个估计值$\hat{\boldsymbol{\theta}}$;
拟合的回归模型$\hat{\mathbf{y}} = f(\mathbf{x};\hat{\boldsymbol{\theta}}) + \hat{\boldsymbol{\epsilon}}$，其中我们有一个估计值$\hat{\boldsymbol{\theta}}$ 而且 $\hat{\boldsymbol{\epsilon}} \sim \mathcal{N}(\mathbf{0},\hat{\Sigma})$;
从字面上看，人口模型 $\mathbf{y} = f(\mathbf{x};\boldsymbol{\theta}) + \boldsymbol{\epsilon}$，但现在以样本指数的形式写出：$\mathbf{y}_i = f(\mathbf{x}_i;\boldsymbol{\theta}) + \boldsymbol{\epsilon}_i$ 使得 $\boldsymbol{\epsilon}_i$ 是观测值，而不是随机向量。
关系 $\mathbf{y}_i = f(\mathbf{x}_i;\hat{\boldsymbol{\theta}}) + \mathbf{e}_i$，其中 $\mathbf{e}_i = \mathbf{y}_i - \hat{\mathbf{y}}_i$ 是残差。

如能提供严格说明，我们将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/660084/formal-difference-between-population-and-sample-model-in-regression-analysis</guid>
      <pubDate>Thu, 16 Jan 2025 07:27:25 GMT</pubDate>
    </item>
    <item>
      <title>对于开放式研究，能否正确计算统计显著性？</title>
      <link>https://stats.stackexchange.com/questions/660083/can-statistical-significance-be-correctly-computed-for-a-open-ended-study</link>
      <description><![CDATA[基本来说，我想做的是你在适当的研究中不应该做的事情：运行少量的测量，然后根据数据看起来是好是坏，决定是继续测量还是退出。
我知道简单的显着性检验不会适用于这种情况，但我怀疑（如果我知道要搜索哪些术语）应该有已知的方法来考虑导致的问题，例如集合的大小暗示了数据集的主要术语。
这是已知的吗？如果是这样，这种测试的正确术语是什么？

上下文是我正在使用来自有效无限域的随机数据点运行模拟，并寻找多个模拟的平均结果超过某个阈值的（罕见）点。我认为我遇到了误报问题，并且不想盲目地增加运行次数以尽可能减少误报（我已经受到计算限制，所以这基本上不是一个选择）。
我想做的是：

运行少量运行。
检查平均结果是否超过高于或低于截止值的显着性阈值。
如果是，则退出。
如果不是（即“不确定”），则进行更多运行并再次检查。

这将（我希望）允许丢弃大多数情况，其中点“极其无趣”，并且计算量甚至比我现在使用的还要少（比如可能少 10 倍），而不会增加误报率。
但我不知道如何为此构建正确的显着性检验。我能想到的最好的办法（我甚至不确定它是否有效）是使每次迭代都更大，只考虑每次迭代中的新数据并使用“多重比较问题”调整之一。但有些东西告诉我应该有一种更有效的方法来使用生成的数据。
旁注：如果允许假阴性可以带来更好的每真阳性成本，我对假阴性是相当宽容的。]]></description>
      <guid>https://stats.stackexchange.com/questions/660083/can-statistical-significance-be-correctly-computed-for-a-open-ended-study</guid>
      <pubDate>Thu, 16 Jan 2025 06:16:36 GMT</pubDate>
    </item>
    <item>
      <title>排除构成数据结构一部分的相关变量，转而采用生物学上更有意义的变量</title>
      <link>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</link>
      <description><![CDATA[我正在研究从卫星图像 (Sentinel) 中捕获的植被覆盖率数据集。数据以季度/季节为间隔捕获。使用 GAM，我正在模拟植被覆盖率如何响应环境变量，降雨量是感兴趣的关键预测变量。但是，降雨量与季度/季节具有合理的相关性，相关系数为 r = -0.73。通常，当两个变量的相关性大于 0.7 时，我会将其中一个排除在分析之外。所以，我的问题是，我可以从分析中排除季度/季节吗？
季度/季节是数据集设计/结构的一部分，通常我的理解是应该在模型中考虑数据结构。但是，连续降雨变量在生物学上是一个更有趣和更有意义的变量。
感谢建议。]]></description>
      <guid>https://stats.stackexchange.com/questions/660079/excluding-correlated-variables-that-form-part-of-data-structure-in-favor-of-biol</guid>
      <pubDate>Thu, 16 Jan 2025 03:22:55 GMT</pubDate>
    </item>
    <item>
      <title>GLM 与 XGB 对零膨胀计数数据的比较</title>
      <link>https://stats.stackexchange.com/questions/660077/comparison-of-glm-xgb-for-zero-inflated-count-data</link>
      <description><![CDATA[我最近才接触 XGB，目前正在做一个项目，为特定保险环境建模索赔数量，并比较 GLM 和 XGB。
首字母缩略词：

GLM - 广义线性模型；

XGB - 极端梯度提升；

ZIP/ZINB - 零膨胀泊松/零膨胀负二项式。


问题：

由于我正在处理 GLM 和 XGB，因此我想在建模之前假设一个分布，以便我可以根据该分布的偏差比较两个模型。例如：如果索赔计数的数据具有泊松分布，则使用泊松偏差。

但是，由于明显的零通货膨胀（索赔为 0 的观测值占总观测值的 70% 以上，占总风险暴露的 70% 以上），我被迫使用 ZIP、拟泊松 GLM、NB GLM 或 ZINB。泊松分布被证实不合适。

另一方面，对于 XGB，我只能对离散计数响应变量使用 count:poisson，它基于泊松偏差。即使通过定制用于 XGB 的损失函数，我也会遇到另一个问题：拟泊松偏差依赖于色散参数，而 NegBinomial 依赖于第二个参数。除非我从一开始就假设它们是恒定的，否则无法为 XGB 实现这些。这意味着，随着 xgb 模型的发展和树的增加，偏差将基于那些恒定的初始假设参数进行计算。甚至 GLM 也会在模型优化时针对 Quasi-Poisson 和 NegBinomial 更新这些参数。对于 XGB 的 ZI 偏差，我无法将这些偏差与梯度和 hessian 拟合到 XGB 的定制目标中。我甚至不认为可以在 XGB 中对零膨胀模型假设发生的产生过量零的单独过程进行建模。

我几乎没有找到针对此类问题的研究或实例。


问题：
(A) 由于 GLM 和 XGB 建模存在这些差异，哪个是比较这两个模型的最合适的指标？
(B) 或者甚至是最好的方法？或者最实用的？
我的建议：

获取最适合 GLM 的模型，并使用默认 count:poisson 偏差获得 XGB，使用具有常数参数 (r) 的 NegBinomial 偏差获得另一个，并在几个偏差下比较所有偏差：
1.1. Poisson 偏差
1.2. NegBinomial 偏差
1.3. 我不明白即使在模型完成后如何找到用于 XGB 模型评估的 ZIP 或 ZINB 偏差。
1.4. 使用加权基尼规范了解哪些模型可以更好地对不同风险进行分类。

]]></description>
      <guid>https://stats.stackexchange.com/questions/660077/comparison-of-glm-xgb-for-zero-inflated-count-data</guid>
      <pubDate>Thu, 16 Jan 2025 00:45:20 GMT</pubDate>
    </item>
    <item>
      <title>如何证明随机矩阵具有独立项？[关闭]</title>
      <link>https://stats.stackexchange.com/questions/660075/how-does-one-prove-a-random-matrix-has-independent-entries</link>
      <description><![CDATA[假设我有一个矩阵 $A \in \mathbb{R}^{n \times n}$，其条目都是随机变量。我怀疑它们是独立的。我将使用什么一般技术来证明这一点？
到目前为止，我已经证明条目是成对独立的，但不确定如何继续。]]></description>
      <guid>https://stats.stackexchange.com/questions/660075/how-does-one-prove-a-random-matrix-has-independent-entries</guid>
      <pubDate>Thu, 16 Jan 2025 00:34:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 s(x1, x2) 和 te()/ti() 进行连续 GAM 相互作用之间的差异</title>
      <link>https://stats.stackexchange.com/questions/660072/difference-between-using-sx1-x2-and-te-ti-for-continous-gam-interactions</link>
      <description><![CDATA[我很好奇使用 s() 或 te()/ti() 进行连续交互的 GAM 之间有什么区别？我见过各种 CV/SE/blog 帖子使用其中一种。
那么例如，两者之间有什么区别呢
gam1 &lt;- gam(Sepal.Length ~ 
s(Sepal.Width, bs = &quot;tp&quot;) + 
s(Petal.Length, bs = &quot;tp&quot;) + 
s(Sepal.Width, Petal.Length, bs = &quot;tp&quot;, k = 5), 
data = iris)

gam2 &lt;- gam(Sepal.Length ~ 
s(Sepal.Width, bs = &quot;tp&quot;) + 
s(Petal.Length, bs = &quot;tp&quot;) + 
ti(Sepal.Width, Petal.Length, bs = &quot;tp&quot;, k = 5), 
data = iris)

区别不大，但模型不同。一个比另一个更合适吗？
我意识到与之前的问题有很多相似之处，所以如果这个问题已经得到解答，请原谅。]]></description>
      <guid>https://stats.stackexchange.com/questions/660072/difference-between-using-sx1-x2-and-te-ti-for-continous-gam-interactions</guid>
      <pubDate>Wed, 15 Jan 2025 22:24:51 GMT</pubDate>
    </item>
    <item>
      <title>是否有可以在 R 中使用的统计分析来评估曲线区域之间的显著差异？</title>
      <link>https://stats.stackexchange.com/questions/660017/is-there-a-statistical-analysis-that-can-be-used-in-r-to-assess-significant-diff</link>
      <description><![CDATA[我想知道是否有统计分析可以确定两种处理中曲线/回归的区域之间的差异。我知道有几种统计分析可以确定两个回归/曲线之间是否存在变量差异，但我不知道有任何一种可以识别区域差异。
假设 X = Light_uE，Y = CellspermL，物种是处理条件（应用于生成两个不同的图）。我如何判断 Light_uE (X) 条件下的曲线之间是否存在显着差异，从 10-20 或 20-30 在物种之间？同样，如果曲线整体不同，则不是。 这个问题似乎与我所寻求的类似，只是它检查的是整个数据集而不是一小部分，并且使用多项式函数而不是分段回归。（我也不认为 ANOVA 适合这种情况，如果可能的话，我希望坚持使用 ggplot。）
我提供了一个可重现的数据框，以及绘制此数据的代码（如果您想将其可视化）。感谢您的帮助。
example_curves &lt;- data.frame(
Light_uE = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 
10, 20, 30, 40, 50, 60, 70, 80, 90, 100),
CellspermL = c(1000000, 2000000, 3000000, 4000000, 5000000, 
4000000, 3000000, 2000000, 1000000, 500000,
2000000, 2500000, 3500000, 3600000, 4000000, 
3900000, 3000000, 2000000, 1000000, 500000),
物种 = c(&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, 
&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, 
&quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, 
&quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;))

print(example_curves)

# 分段绘图
library(segmented)
library(gridExtra)
library(ggplot2)

create_piecewise_plot &lt;- function(data, title, initial_psi) {
# 拟合线性模型
lm_model &lt;- lm(CellspermL ~ Light_uE, data = data)

# 应用分段函数并手动指定初始断点
seg_model &lt;- fragmented(
lm_model, 
seg.Z = ~Light_uE, 
psi = initial_psi, # 手动指定起点
control = seg.control(display = FALSE) # 禁用额外输出
)

data$fitted_values &lt;- fitted(seg_model)

p &lt;- ggplot(data, aes(x = Light_uE, y =每毫升细胞数)) +
geom_point() +
geom_line(aes(y = fitted_values), color = &#39;blue&#39;) +
labs(
title = title,
x = &quot;Light (uE)&quot;,
y = &quot;每毫升细胞数&quot;
) +
theme_minimal()

return(p)
}

# 按物种创建两个不同的图
data_species_a &lt;- subset(example_curves, Species == &quot;A&quot;)
data_species_b &lt;- subset(example_curves, Species == &quot;B&quot;)

range_a &lt;- range(data_species_a$Light_uE)
range_b &lt;- range(data_species_b$Light_uE)

# 确保 initial_psi 值在范围内
plot_species_a &lt;- create_piecewise_plot(data_species_a, &quot;Species A&quot;, initial_psi = 50) # 在 range_a 内选择一个有效值
plot_species_b &lt;- create_piecewise_plot(data_species_b, &quot;Species B&quot;, initial_psi = 50) # 在 range_b 内选择一个有效值

# 使用 grid.arrange 水平排列图
grid.arrange(plot_species_a, plot_species_b, ncol = 2)
]]></description>
      <guid>https://stats.stackexchange.com/questions/660017/is-there-a-statistical-analysis-that-can-be-used-in-r-to-assess-significant-diff</guid>
      <pubDate>Tue, 14 Jan 2025 17:04:03 GMT</pubDate>
    </item>
    <item>
      <title>是否有可以在 R 中使用的统计分析来评估曲线区域之间的显著差异？</title>
      <link>https://stats.stackexchange.com/questions/660081/is-there-a-statistical-analysis-that-can-be-used-in-r-to-assess-significant-diff</link>
      <description><![CDATA[我想知道是否有统计分析可以确定两种处理方法中曲线/回归的区域之间的差异。我知道有几种统计分析方法可以确定两个回归/曲线之间是否存在变量总体差异，但我不知道有任何方法可以识别区域差异。
假设 X = Light_uE，Y = CellspermL，物种是处理条件（应该用于生成两个不同的图）。我如何判断 Light_uE (X) 条件下的曲线之间是否存在显着差异，从 10-20 还是 20-30 物种之间？同样，如果曲线整体不同，则不会。
我提供了一个可重现的数据框，以及绘制此数据的代码（如果您想将其可视化）。
# 生成数据框
example_curves &lt;- data.frame(
Light_uE = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 
10, 20, 30, 40, 50, 60, 70, 80, 90, 100),
CellspermL = c(1000000, 2000000, 3000000, 4000000, 5000000, 
4000000, 3000000, 2000000, 1000000, 500000,
2000000, 2500000, 3500000, 3600000, 4000000, 
3900000, 3000000, 2000000, 1000000, 500000),
物种 = c(&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, 
&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, 
&quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, 
&quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;))

print(example_curves)

# 分段绘图
library(segmented)
library(gridExtra)
library(ggplot2)

create_piecewise_plot &lt;- function(data, title, initial_psi) {
# 拟合线性模型
lm_model &lt;- lm(CellspermL ~ Light_uE, data = data)

# 应用分段函数并手动指定初始断点
seg_model &lt;- fragmented(
lm_model, 
seg.Z = ~Light_uE, 
psi = initial_psi, # 手动指定起点
control = seg.control(display = FALSE) # 禁用额外输出
)

data$fitted_values &lt;- fitted(seg_model)

p &lt;- ggplot(data, aes(x = Light_uE, y = CellspermL)) +
geom_point() +
geom_line(aes(y = fitted_values), color = &#39;blue&#39;) +
labs(
title = title,
x = &quot;Light (uE)&quot;,
y = &quot;Cells per mL&quot;
) +
theme_minimal()

return(p)
}

# 按物种创建两个不同的图
data_species_a &lt;- subset(example_curves, Species == &quot;A&quot;)
data_species_b &lt;- subset(example_curves, Species == &quot;B&quot;)

range_a &lt;- range(data_species_a$Light_uE)
range_b &lt;- range(data_species_b$Light_uE)

# 确保 initial_psi 值在范围内
plot_species_a &lt;- create_piecewise_plot(data_species_a, &quot;Species A&quot;, initial_psi = 50) # 在 range_a 内选择一个有效值
plot_species_b &lt;- create_piecewise_plot(data_species_b, &quot;Species B&quot;, initial_psi = 50) # 在 range_b 内选择一个有效值

# 使用 grid.arrange 水平排列图
grid.arrange(plot_species_a, plot_species_b, ncol = 2)

]]></description>
      <guid>https://stats.stackexchange.com/questions/660081/is-there-a-statistical-analysis-that-can-be-used-in-r-to-assess-significant-diff</guid>
      <pubDate>Mon, 13 Jan 2025 22:04:09 GMT</pubDate>
    </item>
    <item>
      <title>使用接受的治疗而非随机分组进行约束纵向数据分析 (cLDA)</title>
      <link>https://stats.stackexchange.com/questions/659986/constrained-longitudinal-data-analysis-clda-using-treatment-received-rather-th</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659986/constrained-longitudinal-data-analysis-clda-using-treatment-received-rather-th</guid>
      <pubDate>Mon, 13 Jan 2025 21:05:21 GMT</pubDate>
    </item>
    <item>
      <title>重复测量设计中评估基因-代谢物关系的指导</title>
      <link>https://stats.stackexchange.com/questions/659981/guidance-on-evaluating-gene-metabolite-relationships-in-repeated-measures-design</link>
      <description><![CDATA[]]></description>
      <guid>https://stats.stackexchange.com/questions/659981/guidance-on-evaluating-gene-metabolite-relationships-in-repeated-measures-design</guid>
      <pubDate>Mon, 13 Jan 2025 20:11:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 Blackbox 方式查找依赖链</title>
      <link>https://stats.stackexchange.com/questions/659978/find-dependency-chain-in-blackbox-way</link>
      <description><![CDATA[考虑五个 n 维向量 $a,b,c,d,e$，其中包含 100 个样本。因此，我们可以将其缩短为具有 3 阶张量的单个变量 $v$，即 $v_{x,y,z}$。
其中：

$x$ 是样本数 (100)
$y$ 是向量数 (5)
$z$ 是向量 dims 数（任意）。

此处的数据集是指数据集，数据可以被视为图中的一个节点。
问题是，以黑盒方式找到节点之间的洞察力，例如节点 $p$ 与节点 $q$ 之间是否有双向/单向关系（依赖），甚至没有联系（独立）。
给定 $f$ 一个接受 $v$ 作为参数的黑盒函数，它将返回见解，例如：

$a$ 的值取决于 $b$ 的值，反之亦然。 （双向关系）

$c$ 的值取决于 $b$ 的值，因此也取决于 $a$ 的值，但 $a$ 和 $b$ 本身与 $c$ 的值相对独立，不会影响 $a$ 和 $b$。

$d$ 的值取决于 $c$ 和 $b$，但它不直接依赖于 $a$。

最后，$e$ 的值完全独立（无关联），与 $a$、$b$、$c$ 或 $d$ 没有任何关系（非双向也非单向）。


这是传递给黑盒函数之前的可视化效果：

以下是传递给黑盒函数后的示例：


由于我们有 $x$ 维度，即样本维度，我认为统计、深度学习、AI、ML 或神经网络可以解决这个无监督学习问题？

通过为每个节点使用单独的 RNG，可以重现虚拟数据集。
然后我们只需执行简单的元素加法即可插入虚拟关系。

$a \leftarrow a+b+1$
$b \leftarrow b+a+2$
$c \leftarrow c+b+3$
$d \leftarrow d+c+b+4$

或者一般来说：

$a \leftarrow f_a(b)$
$b \leftarrow f_b(a)$
$c \leftarrow f_c(b)$
$d \leftarrow f_d(b,c)$
]]></description>
      <guid>https://stats.stackexchange.com/questions/659978/find-dependency-chain-in-blackbox-way</guid>
      <pubDate>Mon, 13 Jan 2025 19:28:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么在我的混合效应模型中添加协变量后交互项保持不变？</title>
      <link>https://stats.stackexchange.com/questions/659963/why-does-the-interaction-term-remain-unchanged-after-adding-a-covariate-in-my-mi</link>
      <description><![CDATA[我的数据结构如下：

seek_score（因变量，连续）和 sek_src（因子）是受试者内变量。
pers 和 age 是受试者间变量（均为连续变量）

这是我的 lmer 代码
m.pers &lt;- lmer(seek_score ~ pers * sek_src + (1 | id), data = cln_long_sek)
m1.pers &lt;- lmer(seek_score ~ pers * sek_src + (1 | id)+age, data = cln_long_sek)

我注意到，无论我在模型中是否包含协变量 age（或其他协变量），交互项 pers * sek_src 都保持不变。我还用其他变量测试了这种行为，交互结果不受影响。
为什么添加协变量不会影响交互项？这是混合效应模型中的预期行为吗，还是我在解释中遗漏了什么？]]></description>
      <guid>https://stats.stackexchange.com/questions/659963/why-does-the-interaction-term-remain-unchanged-after-adding-a-covariate-in-my-mi</guid>
      <pubDate>Mon, 13 Jan 2025 06:51:18 GMT</pubDate>
    </item>
    <item>
      <title>解释线性回归中的数据集不平衡问题</title>
      <link>https://stats.stackexchange.com/questions/659943/accounting-for-dataset-imbalance-in-linear-regression</link>
      <description><![CDATA[我有一组特征 $X$ 和一个因变量 $Y$，我想使用线性回归进行预测。目前，我正在使用普通最小二乘法计算 $\hat{\beta}$ 矩阵。但是，我注意到我的因变量 $Y$ 大约有 30% 的时间设置为零。在其他情况下，它可以取负值或正值。$Y$ 取的值通常在区间 $[-5, 5]$ 内。此外，$Y$ 的值大致呈正态分布，均值为零。
在我正在研究的问题中，当预测值的绝对值超过某个阈值时，我会做出决定。此外，
“错误”的代价比不采取行动的代价更大。换句话说，我希望能够准确预测 $|Y| &gt; 2$ 的情况，而我不太关心 $|Y| \leq 2$ 的情况。
这引出了以下问题：

在解决我的 OLS 解决方案时，我是否应该排除 $|Y| \leq 2$ 的情况？这是某人的建议。但是，我认为答案是否定的（不应该这样做），因为这会使我的结果产生偏差，而且我无法保证真实数据集中的 $|Y| \leq 2$。

还有其他方法可以解释手头的问题吗（尤其是因为大约三分之一的数据中 $Y = 0$）？


谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/659943/accounting-for-dataset-imbalance-in-linear-regression</guid>
      <pubDate>Mon, 13 Jan 2025 05:49:06 GMT</pubDate>
    </item>
    <item>
      <title>泊松过程可以变成泊松过程回归吗？</title>
      <link>https://stats.stackexchange.com/questions/659931/can-a-poisson-process-be-made-into-a-poisson-process-regression</link>
      <description><![CDATA[这是我正在考虑的概念验证问题。
数据格式如下（模拟数据）：
patient_id dob gender hospital_visit age_at_visit
1 2019-06-21 F 2024-03-13 4
1 2019-06-21 F 2024-05-22 4
1 2019-06-21 F 2024-07-11 5
1 2019-06-21 F 2024-09-19 5
1 2019-06-21 F 2024-10-02 5
1 2019-06-21 F 2024-10-30 5
1 2019-06-21 F 2024-11-13 5
1 2019-06-21 F 2024-12-15 5
1 2019-06-21 F 2024-12-17 5
2 2007-12-13 M 2024-01-27 16
2 2007-12-13 M 2024-02-09 16
2 2007-12-13 M 2024-06-10 16
3 2024-02-01 M 2024-06-28 0
4 2014-04-12 F 2024-08-17 10
4 2014-04-12 F 2024-12-21 10
5 2010-02-20 F 2024-02-03 13
5 2010-02-20 F 2024-02-21 14
5 2010-02-20 F 2024-03-17 14
5 2010-02-20 F 2024-03-31 14
5 2010-02-20 F 2024-04-09 14

考虑 2 个泊松过程：一个标准泊松过程（速率恒定）和一个（加速）泊松过程，其中速率函数随着更多事件的发生而变化（$r$ 是速率，$n$ 是已经发生的事件数）。很明显，当我们模拟和可视化它们时，我们可以看到两者之间的差异（在 R 中）：

我想知道这是否可以用于创建模型，以确定一个人下次住院的时间，因为我们知道他已经住院了多少次（假设我们只在这个人住院时进行协变量测量）。
我认为这在我们认为未来住院取决于这个人过去去过医院的次数的情况下很有用 - 这样，对于住院频率更高的人，住院间隔时间就会减少。
例如，我们可以定义一个风险模型，如这个？
$$ \ln[h(t|n, X)] = \ln(\lambda_0) + n\ln(1+r) + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p $$
$$h(t) = \lim_{\Delta t \to 0} \frac{P(t \leq T &lt; t + \Delta t | T \geq t)}{\Delta t}$$
或者也许是对数对数链接？
$$ \log(-\log(1 - P(\text{readmission in }[t, t+\Delta t]|n, X))) = \beta_0 + \beta_n n + X\beta $$
$$ \log(-\log(1 - P(\text{readmission in }[t, t+\Delta t]|n))) = \log(\lambda_0) + n\log(1+r) + \log(\Delta t) $$
$$ \log(-\log(1 - P(\text{readmission in }[t, t+\Delta t]|n, X))) = \beta_0 + \beta_n n + X\beta + \log(\Delta t) $$
或者仅仅是一个纯随机过程？
$$ \log(\lambda_n) = \beta_0 + \beta_1n + X\beta $$
$$ \lambda_n = e^{\beta_0 + \beta_1n + X\beta} $$
$$ P(\text{readmission in }[t, t+\Delta t]|n,X) = 1 - e^{-\lambda_n\Delta t} = 1 - e^{-e^{\beta_0 + \beta_1n + X\beta}\Delta t} $$
我不明白如何对此类问题进行建模，因为它涉及纵向分析、随机过程和生存分析的概念。有什么关于如何开始的提示吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/659931/can-a-poisson-process-be-made-into-a-poisson-process-regression</guid>
      <pubDate>Sun, 12 Jan 2025 21:26:18 GMT</pubDate>
    </item>
    </channel>
</rss>