<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>最近的问题 - 交叉验证</title>
    <link>https://stats.stackexchange.com/questions</link>
    <description>最近 30 个来自 stats.stackexchange.com</description>
    <lastBuildDate>Wed, 10 Jan 2024 09:14:05 GMT</lastBuildDate>
    <item>
      <title>如何解码 HuggingFace BART 模型的输出？</title>
      <link>https://stats.stackexchange.com/questions/636563/how-to-decode-output-from-huggingface-bart-model</link>
      <description><![CDATA[目前正在尝试学习如何使用 HuggingFace。
从变压器导入 BartTokenizer、BartModel

tokenizer = BartTokenizer.from_pretrained(&#39;facebook/bart-base&#39;)
模型 = BartModel.from_pretrained(&#39;facebook/bart-base&#39;)

# 对英语进行编码并通过模型运行它
input = tokenizer(“你好，我的狗很可爱”，return_tensors =“pt”)
输出=模型（**输入）

# 解码模型输出并打印英文
打印（tokenizer.batch_decode（输出，skip_special_tokens = True））

不幸的是，我被这段代码难住了。每次运行它时，我都会得到：
ValueError：以 10 为基数的 int() 的文字无效：“l”

当我尝试使用 tokenizer.batch_decode(...) 解码模型输出时
有人可以向我解释一下为什么会发生这种情况吗？由于 BART 是一种自动编码器，因此人们会认为它的输出也可以被解码，这与 BERT 的输出不同。]]></description>
      <guid>https://stats.stackexchange.com/questions/636563/how-to-decode-output-from-huggingface-bart-model</guid>
      <pubDate>Wed, 10 Jan 2024 08:55:17 GMT</pubDate>
    </item>
    <item>
      <title>使用哪个预测区间 - 使用 LOOCV 选择元回归</title>
      <link>https://stats.stackexchange.com/questions/636559/which-prediction-interval-to-use-meta-regression-selected-using-loocv</link>
      <description><![CDATA[我有一篇研究论文，使用 Metafor 中的多个预测变量进行元回归。他们对所有变量组合进行元回归，然后使用 LOOCV 根据 LOOCV 的 RMSE 选择最佳模型。我很难理解应该使用哪个预测区间来进行新的预测。
我有由 LOOCV 确定的最终模型的 RMSE，因此可以使用生成粗略的预测区间
$\hat{y} \pm t_{(1-\alpha/2, n-2)} \times RMSE$
承认它忽略了估计误差。
或者，我似乎可以使用 Riley 等人计算元回归的预测区间。
$\hat{y} \pm t_{k-2} \times \sqrt{\mathrm{Tau}^2+\mathrm{SE}(\hat{y })^2}$
我认为前者是更好的预测区间。我是对的吗？理想情况下，出版物应包括 LOOCV 分析的预测区间，但事实并非如此。它还不包括最终模型的 $\mathrm{Tau}^2$，这至少进一步向我表明 LOOCV RMSE 是可行的方法.]]></description>
      <guid>https://stats.stackexchange.com/questions/636559/which-prediction-interval-to-use-meta-regression-selected-using-loocv</guid>
      <pubDate>Wed, 10 Jan 2024 06:31:29 GMT</pubDate>
    </item>
    <item>
      <title>收敛随机变量的条件期望相对于任意过滤的收敛 [迁移]</title>
      <link>https://stats.stackexchange.com/questions/636558/convergence-of-conditional-expectation-of-convergent-random-variables-with-respe</link>
      <description><![CDATA[我已经尝试解决以下问题一段时间了，但没有成功：让 $X_1,X_2,\dots \in L_1$ 与 $X_n \uparrow X$ a.s. （和 $X \in L_1$）。表明对于任何过滤 $(F_n)$ 我们都有 $\mathbb{E}[X_n|F_n] \to \ mathbb{E}[X|F_\infty]$ a.s.其中 $F_\infty = \sigma(\bigcup_{n\geq 1} F_n)$
我最初的方法是尝试证明 $\mathbb{E}[X_n|F_n] \leq \mathbb{E}[X_{n+1}|F_{ n+1}]$ 然后应用单调收敛定理，但我一直无法证明它，甚至不知道它是否正确。我知道对于固定的 $m$ 我们有 $\mathbb{E}[X_n|F_m] \leq \mathbb{ E}[X_{n+1}|F_m]$ 但我找不到关联 $\mathbb{E}[X_n|F_n]$&lt; 的方法/span&gt; 和 $\mathbb{E}[X_{n+1}|F_{n+1}]$ 自 $\sigma$-我们所调节的代数正在改变。也许它是一种过滤这一事实在某种程度上有所帮助？但是当 $\sigma$-algebra 随 $ 变化时，我无法找到或证明条件期望的任何收敛结果n$.
我知道这是 Doob Martingales 的一个简单结果，对于固定的 $m$，我们有 $\mathbb{ E}[X_m|F_n] \to \mathbb{E}[X_m|F_\infty]$。此外，对于固定的 $m&#39;$，条件单调收敛定理告诉我们 $\mathbb{E}[X_n| F_{m&#39;}] \到 \mathbb{E}[X|F_{m&#39;}]$。但是我不知道如何同时处理 $n$ 的变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/636558/convergence-of-conditional-expectation-of-convergent-random-variables-with-respe</guid>
      <pubDate>Wed, 10 Jan 2024 06:12:30 GMT</pubDate>
    </item>
    <item>
      <title>0 拟合 Copula 的对数似然</title>
      <link>https://stats.stackexchange.com/questions/636557/log-likelihood-of-0-fitting-copula</link>
      <description><![CDATA[这个问题似乎应该有一个简单的答案，但我在互联网搜索或 ChatGPT 方面没有运气。我正在 Python 中使用统计联结函数，并且在使用 MLE 在二元高斯联结函数中拟合 Q（皮尔逊相关）参数时遇到了问题。
如果需要，我可以发送代码和/或方程，但问题实际上是抽象的。它的工作原理如下：

我正在尝试使用 MLE 找到最适合样本数据集的 Q。
Q = 0 是一个有效的搜索参数，因为它代表了我的数据不具有线性相关性的重要情况。而且，它完全落在相关性的范围内，即 -1 和 1。
但是当检查 Q = 0 的对数似然时，copula 分布是二元均匀的，并且到处都等于 1（单位立方体）。这里没有任何问题——这是预期的。
这会导致对数似然为 0，因为我所有点的 PDF 均为 1 并且 ln(1) = 0。
因为我正在使用 scipy.minimize，所以我必须翻转符号 MINIMIZE the Log Likelihood * -1，但这意味着 0 比任何其他解都小（因为 -1 * Log Likelihood 永远不会为负）。&lt; /里&gt;

那么根据 MLE，Q = 0 总是最优解吗？ ChatGPT 建议单独处理 Q = 0，但我不知道这将如何工作。先验地，Q = 0 仍然是一个有效的搜索参数，我们不能立即丢弃该解决方案。我还想继续使用 MLE，因为我最终会将我的方法推广到其他联结函数。
感谢您的回答，如果需要，我可以再次提供代码/方程。]]></description>
      <guid>https://stats.stackexchange.com/questions/636557/log-likelihood-of-0-fitting-copula</guid>
      <pubDate>Wed, 10 Jan 2024 06:05:55 GMT</pubDate>
    </item>
    <item>
      <title>自举二次抽样分析</title>
      <link>https://stats.stackexchange.com/questions/636552/bootstrapping-subsampling-analysis</link>
      <description><![CDATA[我目前正在开展引导二次抽样分析，旨在使用 PSAboot：使用 R 中的引导进行倾向得分分析，根据阅读成绩得分将阅读障碍组与对照组进行匹配。
这是我用于分析的代码片段：在此处输入图像描述

不幸的是，我遇到了一个错误：“使用 1 种方法得到 100 个引导样本。” Bootstrap 样本大小：处理 = 695 (100%)，无替换。对照=6882（100%），无需更换。 cut.default(ps, quantile(ps, seq(0, 1, 1/nstrata)), include.lowest = TRUE, 中的错误：“中断”不是唯一的&#39;
我尝试了各种方法，例如在 unique() 函数内应用 quantile()、使用 jitter、decile 和 .bincode 函数，但似乎都没有解决问题。如果您有任何建议或见解来帮助我解决这个问题，我将不胜感激。非常感谢。]]></description>
      <guid>https://stats.stackexchange.com/questions/636552/bootstrapping-subsampling-analysis</guid>
      <pubDate>Wed, 10 Jan 2024 03:31:19 GMT</pubDate>
    </item>
    <item>
      <title>使用 t 检验来测试效应大小</title>
      <link>https://stats.stackexchange.com/questions/636551/using-a-t-test-to-test-effect-size</link>
      <description><![CDATA[在我的工作中，我使用大数据并经常运行统计测试来比较组之间的差异。我面临的问题是，如果我使用 $t$ 测试来测量任何差异，由于样本量较大，结果几乎总是显着的。&lt; /p&gt;
例如，我希望衡量测试组相对于对照组的效应大小。我的两个样本量都非常大 - 我的测试有 $100,000$ 人，而我的对照有 $11,000$ 人。我的 $t$ 测试值超过 $1$ 万。
为了解释这一点，我提出了将各组的平均差异与基准值进行比较的想法。基准值可以是对照组平均值的 $10$%。因此，我将测试组与对照组之间的平均差异与基准值进行比较。通过这种方式，我可以测试各组之间的差异是否大于对照组的 $10$%，以及是否具有统计显着性。
这是一种有效的方法吗？]]></description>
      <guid>https://stats.stackexchange.com/questions/636551/using-a-t-test-to-test-effect-size</guid>
      <pubDate>Wed, 10 Jan 2024 03:17:53 GMT</pubDate>
    </item>
    <item>
      <title>帮助选择可解释的模型来衡量客户旅程接触点对满意度的影响</title>
      <link>https://stats.stackexchange.com/questions/636549/help-selecting-an-interpretable-model-to-measure-the-impact-of-customer-journey</link>
      <description><![CDATA[上下文
我正在开展一个项目，需要了解客户旅程接触点对满意度的影响。我的目标是创建一个可解释的模型，而不是纯粹的预测模型，因为我想了解每个接触点对满意度的重要性，以做出明智的业务决策。
数据
我的输入变量 (X) 是二元的，表示客户是否经历过特定接触点，而我的因变量 (y) 是连续的，范围从 0 到 10。满意度分数的分布不是正态的，在 10 处显着累积，然后快速向 0 下降。在 0 处它再次增加，类似于二项分布或 beta 分布。
类似这样的事情：

问题

您建议使用什么算法或建模方法来构建可解释的模型，以处理二进制输入和非正态分布的连续输出（例如我的满意度得分）？
在创建解释性模型而不是预测性模型时，我是否应该将数据划分为训练集、验证集和测试集？交叉验证适合这种场景吗？或者我只是用所有数据集训练模型？
根据我的目标，您是否建议使用任何特定技术或库来解决模型的可解释性问题？
如何使用所选模型评估各个接触点在影响客户满意度方面的意义或重要性？并解释它？

任何有关算法选择和建模策略的帮助或见解将不胜感激。谢谢！]]></description>
      <guid>https://stats.stackexchange.com/questions/636549/help-selecting-an-interpretable-model-to-measure-the-impact-of-customer-journey</guid>
      <pubDate>Wed, 10 Jan 2024 03:08:37 GMT</pubDate>
    </item>
    <item>
      <title>如何计算点球大战中球队获胜的概率？</title>
      <link>https://stats.stackexchange.com/questions/636548/how-to-calculate-probability-of-a-team-winning-in-penalty-kick</link>
      <description><![CDATA[我在浏览网页时看到了这张图表。我了解处罚规则，但我真的不知道如何计算图表中第一行的数字。
我的想法是将每次射击视为遵循伯努利分布的随机变量，那么成功的次数将是二项式分布。我需要计算 P(A - B) = 1。当我开始这样做时，我发现它很复杂且令人困惑。我相信有更好的方法。
你能对此给出一个想法或提示吗？
]]></description>
      <guid>https://stats.stackexchange.com/questions/636548/how-to-calculate-probability-of-a-team-winning-in-penalty-kick</guid>
      <pubDate>Wed, 10 Jan 2024 02:57:06 GMT</pubDate>
    </item>
    <item>
      <title>示例符号：何时使用大写 $N$ 与小写 $n$？</title>
      <link>https://stats.stackexchange.com/questions/636545/sample-notation-when-to-use-capital-n-vs-lowercase-n</link>
      <description><![CDATA[在统计和心理学研究中，大写 $N$ 与小写 $n$ 表示什么？
我从事心理学研究，我看到它们以两种方式使用：

大写 $N$ 代表整个样本，小写 $n$ 代表以下组那个样本。例如我们开展了一项 RCT，参与者为 $100$，控制者为 $50$，治疗费用为 50$，因此 $N = 100$ 和 $n = 50$ 在每个组中。
大写的$N$代表我们从中招募研究样本的人群，小写的n是我们的研究样本，例如我们从$162$百万选民名单中随机抽取$100$的注册选民，所以 $N = 162,000,000$ 和 $n = 100$（假设我们邀请的每个人都同意参与）&lt; /里&gt;

$N$ 和 $n$ 的常规用法是什么？是否因领域而异？我可以指出哪些资源来阐明每种资源的含义？]]></description>
      <guid>https://stats.stackexchange.com/questions/636545/sample-notation-when-to-use-capital-n-vs-lowercase-n</guid>
      <pubDate>Wed, 10 Jan 2024 02:12:07 GMT</pubDate>
    </item>
    <item>
      <title>$E[W\otimes W]$ 为 Wishart R.V. $W$</title>
      <link>https://stats.stackexchange.com/questions/636544/ew-otimes-w-for-wishart-r-v-w</link>
      <description><![CDATA[Wishart R.V. 的 $E[W\otimes W]$ 的价值是多少？ $W$？
$\otimes$ 指克罗内克乘积
我在Seber矩阵的第467页找到了$E[WAW]$的相关公式handbook，想知道能否从中提取出$E[W\otimes W]$ .
]]></description>
      <guid>https://stats.stackexchange.com/questions/636544/ew-otimes-w-for-wishart-r-v-w</guid>
      <pubDate>Wed, 10 Jan 2024 00:34:51 GMT</pubDate>
    </item>
    <item>
      <title>如何选择同时具有最佳值和低方差的点[重复]</title>
      <link>https://stats.stackexchange.com/questions/636543/how-to-choose-a-point-that-has-both-optimal-value-and-low-variance</link>
      <description><![CDATA[我有一个高斯过程回归模型，可以对特定过程的成本进行建模。训练完成后，我想找到回归预测成本最低的点 $x$ 对应的点。
简单地选择期望值最低的点$\mu(x)$似乎并不直观，因为如果最低点具有高不确定性（即高方差， $\sigma$) 那么我们最好选择一个稍微次优但不确定性较低的点。
我想提高选择最佳点的可能性，这样当我使用这些参数运行流程时，我的成本是最低的。
一个简单的解决方案可能是考虑预测均值 ($\mu$) 和方差 ( $\sigma$) 而不仅仅是平均值
$\alpha(x) = \mu(x) + \lambda \sigma(x)$
所以现在我找到了一个最佳点 $x$ wrt $\alpha$ 而不是 &lt; span class=&quot;math-container&quot;&gt;$\mu$
我想看看其他人是否能够以不同的方式解决这个问题。我在网上找不到任何类似的作品。]]></description>
      <guid>https://stats.stackexchange.com/questions/636543/how-to-choose-a-point-that-has-both-optimal-value-and-low-variance</guid>
      <pubDate>Wed, 10 Jan 2024 00:16:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 格式化此数据以进行探索性因素分析的最佳方法？</title>
      <link>https://stats.stackexchange.com/questions/636542/best-way-to-format-this-data-for-exploratory-factor-analysis-using-r</link>
      <description><![CDATA[我最初在 StackOverflow 上问过这个问题，但这更多的是一个统计问题，而不是一个编码问题。
我的问题是关于数据格式的。我有这个数据集（嗯，这只是几百行中的前两行）：
df &lt;- 结构(列表(X.Case.ID. = 310:311, 性别 = c(1L, 1L), 年龄 = c(32L,
45L)，就业 = c(1L, 1L)，教育 = c(6L, 6L)，职能 = c(6L,
6L)，A = c(1L, 1L)，部门 = 1:2，员工 = c(567L, 500L)，
    状态 = c(35L, 10L)，区域 = 3:2，收入 = 9:8，Q1 = c(2L,
    2L), Q2 = 2:1, Q3 = 1:2, Q4 = c(1L, 3L), Q5 = 3:2, Q6_C1 = c(0L,
    0L), Q6_C2 = 0:1, Q6_C3 = c(0L, 0L), Q6_C4 = 1:0, Q6_C5 = 0:1,
    Q6_C6 = c(0L, 0L), Q6_C7 = c(0L, 0L), Q6_C8 = c(0L, 0L),
    Q6_C9 = c(0L, 0L), O_Q6_C9 = c(NA, NA), Q7_C1 = 0:1, Q7_C2 = c(0L,
    0L), Q7_C3 = c(0L, 0L), Q7_C4 = c(0L, 0L), Q7_C5 = 1:0, Q7_C6 = 0:1,
    Q7_C7 = c(0L, 0L), Q7_C8 = c(0L, 0L), Q7_C9 = c(0L, 0L),
    Q7_C10 = c(0L, 0L), O_Q7_C9 = c(NA, NA), Q8 = 4:3, Q9_C1 = c(0L,
    0L), Q9_C2 = 0:1, Q9_C3 = c(0L, 0L), Q9_C4 = c(0L, 0L), Q9_C5 = c(1L,
    1L), Q9_C6 = 0:1, Q9_C7 = c(0L, 0L), Q9_C8 = c(0L, 0L), Q9_C9 = c(0L,
    0L), Q10 = c(3L, 1L), Q11_C1 = c(0L, 0L), Q11_C2 = 1:0, Q11_C3 = 0:1,
    Q11_C4 = 0:1, Q11_C5 = 1:0, Q11_C6 = c(0L, 0L), Q11_C7 = c(0L,
    0L)，Q12＝c(34L，15L)，Q13＝c(“99,994”，“700”)，Q14＝1:2，
    Q15 = 1:2，Q16_C1 = c(0L, 0L)，Q16_C2 = c(0L, 0L)，Q16_C3 = c(0L,
    0L), Q16_C4 = c(0L, 0L), Q16_C5 = c(0L, 0L), Q16_C6 = c(0L,
    0L), Q16_C7 = c(0L, 0L), Q16_C8 = c(0L, 0L), Q16_C9 = c(0L,
    0L), Q16_C10 = c(0L, 0L), Q16_C11 = c(0L, 0L), O_Q16_C11 = c(NA,
    NA), Q17_C1 = c(0L, 0L), Q17_C2 = c(0L, 0L), Q17_C3 = c(0L,
    0L), Q17_C4 = c(0L, 0L), Q17_C5 = 1:0, Q17_C6 = 0:1, Q17_C7 = c(0L,
    0L), Q17_C8 = 0:1, Q17_C9 = 0:1, Q17_C10 = 1:0, Q17_C11 = c(0L,
    0L), Q17_C12 = c(0L, 0L), O_Q17_C11 = c(NA, NA), Q18 = c(5L,
    3L), Q19_C1 = 0:1, Q19_C2 = 1:0, Q19_C3 = c(0L, 0L), Q19_C4 = 0:1,
    Q19_C5 = c(0L, 0L), Q19_C6 = c(0L, 0L), Q19_C7 = c(0L, 0L)
    ), Q19_C8 = c(0L, 0L), O_Q19_C7 = c(NA, NA), Q20_M1 = c(7L,
    1L), Q20_M2 = 2:3, Q20_M3 = 3:4, Q20_M4 = 6:5, Q20_M5 = c(5L,
    2L), Q20_M6 = c(4L, 7L), Q20_M7 = c(1L, 6L), YEARSATCOMPANY = c(7L,
    10L)，YEARSINBUS = c(12L, 10L)，办公室 = 3:2，段 = c(“企业”,
    “商业”），DEDICATED_STAFF = c（“&gt;=20”，“&lt;20”），HOURS = c（“&gt;=10000”，
    “&lt;1000”)，易受攻击=c(“易受攻击”，“不易受攻击”)，
    Hours.Adjusted = c(&quot;10000&quot;, &quot;700&quot;), Commercial.or.Enterprise = c(&quot;Enterprise&quot;,
    “商业”），Q13.num = c(99994, 700)，段 = c(2, 1
    )，专职人员 = c(2, 1)，弱势群体 = c(2, 1)，工时 = c(4,
    1)), row.names = 1:2, class = “data.frame”)

我意识到列名称和值不清楚，但我们有一些问题，例如人口统计数据，每个人都有一个单一的答案。
有类似Q1的问题：

还有像 Q6 这样的问题，它有 9 个部分（O_Q6_C9 和其他类似的问题是空的）。为了简洁起见，以下是前 3 部分。

考虑到像 Q6 这样的问题是“长”的。对于宽格式的问题，我们本质上有一对一和一对多的结构，但格式化后都是一对一的。格式化这些数据以进行探索性因素分析的最佳方法是什么？保留宽格式还是长格式会导致一对一变量重复？
我想知道对于像问题 6 这样的问题，它的所有部分都围绕一个共同的概念 - 这会带来问题吗？
我将对所有数据进行数字编码，并且不会使用所有问题。但是，我将混合使用一对一和一对多问题。除了结构的混合之外，没有任何复杂的东西，例如重复测量或复杂采样。]]></description>
      <guid>https://stats.stackexchange.com/questions/636542/best-way-to-format-this-data-for-exploratory-factor-analysis-using-r</guid>
      <pubDate>Tue, 09 Jan 2024 23:53:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的 Mice() 包执行多重插补。执行逻辑回归后无法获得分类变量的常见 p 值 [关闭]</title>
      <link>https://stats.stackexchange.com/questions/636541/performed-multiple-imputation-usig-mice-package-in-r-unable-to-get-the-common</link>
      <description><![CDATA[我使用 R 中的 mice 包对连续变量和分类变量进行了多次插补。我进行了 $5$ 插补和 $10$ 迭代，并使用 with() 运行逻辑回归code&gt; 然后是 pool() 用于结果池。但是，我无法获得分类变量的通用 $p$ 值。我查看了与此相关的不同文章，但没有任何帮助。我还使用了此链接 并遵循相同的步骤。]]></description>
      <guid>https://stats.stackexchange.com/questions/636541/performed-multiple-imputation-usig-mice-package-in-r-unable-to-get-the-common</guid>
      <pubDate>Tue, 09 Jan 2024 23:37:52 GMT</pubDate>
    </item>
    <item>
      <title>检查硬币是否随机翻转，但每次抛掷的面数可能不同</title>
      <link>https://stats.stackexchange.com/questions/636539/check-if-a-coin-flips-randomly-but-it-can-have-a-different-number-of-sides-each</link>
      <description><![CDATA[我想根据观察数据检查硬币是否随机翻转。问题是，硬币可以有两个面，也可以有三个、四个，最多九个。每次观察（每次抛掷）的边数都不同。
我可以生成观察结果，但成本相对较高，因此通常样本量较小，例如 20、30，也许 50，但如果需要，我可能会获取更多样本。
这里要应用什么统计测试？如果有任何棘手的方面，如何应用？
我需要多少观察？我是否正确地认为偏差越明显，检测它所需的观察次数就越少？
编辑回答评论：我知道每次有多少面，我可以在某种程度上控制它。硬币应该是随机翻转的，但我怀疑它不会。如果它确实不是随机翻转的，我想说：“这是可靠的统计证据，表明这枚硬币不是随机翻转的”。像往常一样，p 值可能小于 0.05。
通过“随机”，我的意思是每一方都应该有相同的“出现”概率。 （1/d，d 是边数）。另一种假设是其中一侧（正面，或“第一”面，始终相同，始终存在）具有更高的概率。
TLDR：我认为硬币偏向正面。硬币可以有多个反面，并且反面的数量可以根据观察的不同而变化。]]></description>
      <guid>https://stats.stackexchange.com/questions/636539/check-if-a-coin-flips-randomly-but-it-can-have-a-different-number-of-sides-each</guid>
      <pubDate>Tue, 09 Jan 2024 22:53:13 GMT</pubDate>
    </item>
    <item>
      <title>混合效应回归中的高相关性和最大随机结构问题</title>
      <link>https://stats.stackexchange.com/questions/636513/the-issue-of-high-correlations-and-maximal-random-structure-in-mixed-effects-reg</link>
      <description><![CDATA[我有两个问题，非常感谢您的建议。
首先，我正在研究糖摄入量对儿童和成人体重的影响。然而，存在一个问题，因为考虑到成年人通常比儿童高，身高和群体具有非常高的相关性。最初，我将其表述为 fm1，但 height 和 Group:height 之间的相关性很强，方差膨胀因子高于 20。当我将其重写为fm2时，方差膨胀因子降至10以下，表明数据更加稳定。但我不确定这种方法是否正确。我希望有人能够提供有关如何编写此代码的指导。
fm1 &lt;- lmer(响应 ~ 组 * 糖 * (体重 + 身高) + (1 | 参与者), data = kids_adults , REML = TRUE )

fm2 &lt;- lmer（响应 ~ 组 * 糖 * 体重 + 糖 * 身高 + （1 | 参与者），数据 = kids_adults ， REML = TRUE ）

其次，我应该按照 Barr、Levy、Scheepers 和 Barr 的建议应用最大随机结构吗？蒂蒂（2013）？在随机效应结构中包含身高会影响我对体重和身高的调查吗？
如果您对这些问题有任何见解或建议，我将不胜感激。]]></description>
      <guid>https://stats.stackexchange.com/questions/636513/the-issue-of-high-correlations-and-maximal-random-structure-in-mixed-effects-reg</guid>
      <pubDate>Tue, 09 Jan 2024 14:59:53 GMT</pubDate>
    </item>
    </channel>
</rss>